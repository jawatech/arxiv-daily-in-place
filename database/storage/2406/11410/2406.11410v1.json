{"2406.11410": {"publish_time": "2024-06-17", "title": "HARE: HumAn pRiors, a key to small language model Efficiency", "paper_summary": "Human priors play a crucial role in efficiently utilizing data in deep\nlearning. However, with the development of large language models (LLMs), there\nis an increasing emphasis on scaling both model size and data volume, which\noften diminishes the importance of human priors in data construction.\nInfluenced by these trends, existing Small Language Models (SLMs) mainly rely\non web-scraped large-scale training data, neglecting the proper incorporation\nof human priors. This oversight limits the training efficiency of language\nmodels in resource-constrained settings. In this paper, we propose a principle\nto leverage human priors for data construction. This principle emphasizes\nachieving high-performance SLMs by training on a concise dataset that\naccommodates both semantic diversity and data quality consistency, while\navoiding benchmark data leakage. Following this principle, we train an SLM\nnamed HARE-1.1B. Extensive experiments on large-scale benchmark datasets\ndemonstrate that HARE-1.1B performs favorably against state-of-the-art SLMs,\nvalidating the effectiveness of the proposed principle. Additionally, this\nprovides new insights into efficient language model training in\nresource-constrained environments from the view of human priors.", "paper_summary_zh": "\u4eba\u985e\u5148\u9a57\u5728\u6709\u6548\u5229\u7528\u6df1\u5ea6\u5b78\u7fd2\u4e2d\u7684\u8cc7\u6599\u626e\u6f14\u8457\u81f3\u95dc\u91cd\u8981\u7684\u89d2\u8272\u3002\u7136\u800c\uff0c\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u767c\u5c55\uff0c\u8d8a\u4f86\u8d8a\u91cd\u8996\u64f4\u5c55\u6a21\u578b\u898f\u6a21\u548c\u8cc7\u6599\u91cf\uff0c\u9019\u5e38\u5e38\u964d\u4f4e\u4e86\u4eba\u985e\u5148\u9a57\u5728\u8cc7\u6599\u5efa\u69cb\u4e2d\u7684\u91cd\u8981\u6027\u3002\u53d7\u5230\u9019\u4e9b\u8da8\u52e2\u7684\u5f71\u97ff\uff0c\u73fe\u6709\u7684\u5c0f\u578b\u8a9e\u8a00\u6a21\u578b\uff08SLM\uff09\u4e3b\u8981\u4f9d\u8cf4\u7db2\u8def\u722c\u53d6\u7684\u5927\u898f\u6a21\u8a13\u7df4\u8cc7\u6599\uff0c\u5ffd\u7565\u4e86\u9069\u7576\u7d0d\u5165\u4eba\u985e\u5148\u9a57\u3002\u9019\u7a2e\u758f\u5ffd\u9650\u5236\u4e86\u8a9e\u8a00\u6a21\u578b\u5728\u8cc7\u6e90\u53d7\u9650\u74b0\u5883\u4e2d\u7684\u8a13\u7df4\u6548\u7387\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5229\u7528\u4eba\u985e\u5148\u9a57\u9032\u884c\u8cc7\u6599\u5efa\u69cb\u7684\u539f\u5247\u3002\u6b64\u539f\u5247\u5f37\u8abf\u900f\u904e\u8a13\u7df4\u4e00\u500b\u7c21\u6f54\u7684\u8cc7\u6599\u96c6\u4f86\u9054\u6210\u9ad8\u6027\u80fd SLM\uff0c\u8a72\u8cc7\u6599\u96c6\u5305\u542b\u8a9e\u7fa9\u591a\u6a23\u6027\u548c\u8cc7\u6599\u54c1\u8cea\u4e00\u81f4\u6027\uff0c\u540c\u6642\u907f\u514d\u57fa\u6e96\u8cc7\u6599\u5916\u6d29\u3002\u9075\u5faa\u6b64\u539f\u5247\uff0c\u6211\u5011\u8a13\u7df4\u4e86\u4e00\u500b\u540d\u70ba HARE-1.1B \u7684 SLM\u3002\u5728\u5927\u578b\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\uff0cHARE-1.1B \u76f8\u5c0d\u65bc\u6700\u5148\u9032\u7684 SLM \u8868\u73fe\u826f\u597d\uff0c\u9a57\u8b49\u4e86\u6240\u63d0\u51fa\u539f\u5247\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u9019\u5f9e\u4eba\u985e\u5148\u9a57\u7684\u89d2\u5ea6\u63d0\u4f9b\u4e86\u5c0d\u8cc7\u6e90\u53d7\u9650\u74b0\u5883\u4e2d\u6709\u6548\u8a9e\u8a00\u6a21\u578b\u8a13\u7df4\u7684\u65b0\u898b\u89e3\u3002", "author": "Lingyun Zhang et.al.", "authors": "Lingyun Zhang, Bin jin, Gaojian Ge, Lunhui Liu, Xuewen Shen, Mingyong Wu, Houqian Zhang, Yongneng Jiang, Shiqi Chen, Shi Pu", "id": "2406.11410v1", "paper_url": "http://arxiv.org/abs/2406.11410v1", "repo": "https://github.com/liteai-team/hare"}}