{"2410.03663": {"publish_time": "2024-10-04", "title": "Enhance Reasoning by Learning from Mistakes: Peer-Review Knowledge Distillation from Multiple Large Language Models", "paper_summary": "Large language models (LLMs) have exhibited complex reasoning abilities by\ngenerating question rationales and demonstrated exceptional performance in\nnatural language processing (NLP) tasks. However, these reasoning capabilities\ngenerally emerge in models with tens of billions of parameters, creating\nsignificant computational challenges for real-world deployment. Recent research\nhas concentrated on improving open-source smaller models through knowledge\ndistillation (KD) from commercial LLMs. Nevertheless, most of these studies\nrely solely on the responses from one single LLM as the gold rationale for\ntraining. In this paper, we introduce a novel Mistake-Aware Peer-Review\nDistillation (MAPD) approach: 1) Instead of merely obtaining gold rationales\nfrom teachers, our method asks teachers to identify and explain the student's\nmistakes, providing customized instruction learning data. 2) We design a\nsimulated peer-review process between teacher LLMs, which selects only the\ngenerated rationales above the acceptance threshold. This reduces the chance of\nteachers guessing correctly with flawed rationale, improving instructional data\nquality. Comprehensive experiments and analysis on mathematical, commonsense,\nand logical reasoning tasks demonstrate the effectiveness of our method.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u8907\u96dc\u7684\u63a8\u7406\u80fd\u529b\uff0c\u53ef\u7522\u751f\u554f\u984c\u4f9d\u64da\uff0c\u4e26\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u8272\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u9019\u4e9b\u63a8\u7406\u80fd\u529b\u901a\u5e38\u51fa\u73fe\u5728\u6578\u5341\u5104\u500b\u53c3\u6578\u7684\u6a21\u578b\u4e2d\uff0c\u70ba\u5be6\u969b\u90e8\u7f72\u5275\u9020\u4e86\u91cd\u5927\u7684\u904b\u7b97\u6311\u6230\u3002\u6700\u8fd1\u7684\u7814\u7a76\u96c6\u4e2d\u65bc\u900f\u904e\u5546\u696d LLM \u7684\u77e5\u8b58\u63d0\u7149 (KD) \u4f86\u6539\u5584\u958b\u6e90\u7684\u5c0f\u578b\u6a21\u578b\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u9019\u4e9b\u7814\u7a76\u5927\u591a\u50c5\u4f9d\u8cf4\u55ae\u4e00 LLM \u7684\u56de\u61c9\u4f5c\u70ba\u8a13\u7df4\u7684\u9ec3\u91d1\u4f9d\u64da\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u932f\u8aa4\u611f\u77e5\u540c\u5115\u5be9\u67e5\u63d0\u7149 (MAPD) \u65b9\u6cd5\uff1a1) \u6211\u5011\u7684\u6a21\u578b\u4e26\u975e\u50c5\u5f9e\u6559\u5e2b\u90a3\u88e1\u53d6\u5f97\u9ec3\u91d1\u4f9d\u64da\uff0c\u800c\u662f\u8981\u6c42\u6559\u5e2b\u627e\u51fa\u4e26\u8aaa\u660e\u5b78\u751f\u7684\u932f\u8aa4\uff0c\u63d0\u4f9b\u5ba2\u88fd\u5316\u7684\u6559\u5b78\u5b78\u7fd2\u8cc7\u6599\u30022) \u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u5728\u6559\u5e2b LLM \u4e4b\u9593\u6a21\u64ec\u7684\u540c\u5115\u5be9\u67e5\u6d41\u7a0b\uff0c\u50c5\u9078\u64c7\u9ad8\u65bc\u63a5\u53d7\u9580\u6abb\u7684\u7522\u751f\u4f9d\u64da\u3002\u9019\u964d\u4f4e\u4e86\u6559\u5e2b\u4ee5\u6709\u7f3a\u9677\u7684\u4f9d\u64da\u6b63\u78ba\u731c\u6e2c\u7684\u6a5f\u7387\uff0c\u4e26\u6539\u5584\u4e86\u6559\u5b78\u8cc7\u6599\u7684\u54c1\u8cea\u3002\u5728\u6578\u5b78\u3001\u5e38\u8b58\u548c\u908f\u8f2f\u63a8\u7406\u4efb\u52d9\u4e0a\u7684\u5168\u9762\u5be6\u9a57\u548c\u5206\u6790\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "author": "Zhuochun Li et.al.", "authors": "Zhuochun Li, Yuelyu Ji, Rui Meng, Daqing He", "id": "2410.03663v1", "paper_url": "http://arxiv.org/abs/2410.03663v1", "repo": "null"}}