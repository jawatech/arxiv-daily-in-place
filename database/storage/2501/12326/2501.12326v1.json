{"2501.12326": {"publish_time": "2025-01-21", "title": "UI-TARS: Pioneering Automated GUI Interaction with Native Agents", "paper_summary": "This paper introduces UI-TARS, a native GUI agent model that solely perceives\nthe screenshots as input and performs human-like interactions (e.g., keyboard\nand mouse operations). Unlike prevailing agent frameworks that depend on\nheavily wrapped commercial models (e.g., GPT-4o) with expert-crafted prompts\nand workflows, UI-TARS is an end-to-end model that outperforms these\nsophisticated frameworks. Experiments demonstrate its superior performance:\nUI-TARS achieves SOTA performance in 10+ GUI agent benchmarks evaluating\nperception, grounding, and GUI task execution. Notably, in the OSWorld\nbenchmark, UI-TARS achieves scores of 24.6 with 50 steps and 22.7 with 15\nsteps, outperforming Claude (22.0 and 14.9 respectively). In AndroidWorld,\nUI-TARS achieves 46.6, surpassing GPT-4o (34.5). UI-TARS incorporates several\nkey innovations: (1) Enhanced Perception: leveraging a large-scale dataset of\nGUI screenshots for context-aware understanding of UI elements and precise\ncaptioning; (2) Unified Action Modeling, which standardizes actions into a\nunified space across platforms and achieves precise grounding and interaction\nthrough large-scale action traces; (3) System-2 Reasoning, which incorporates\ndeliberate reasoning into multi-step decision making, involving multiple\nreasoning patterns such as task decomposition, reflection thinking, milestone\nrecognition, etc. (4) Iterative Training with Reflective Online Traces, which\naddresses the data bottleneck by automatically collecting, filtering, and\nreflectively refining new interaction traces on hundreds of virtual machines.\nThrough iterative training and reflection tuning, UI-TARS continuously learns\nfrom its mistakes and adapts to unforeseen situations with minimal human\nintervention. We also analyze the evolution path of GUI agents to guide the\nfurther development of this domain.", "paper_summary_zh": "\u672c\u6587\u4ecb\u7d39\u4e86 UI-TARS\uff0c\u4e00\u7a2e\u539f\u751f GUI \u4ee3\u7406\u6a21\u578b\uff0c\u5b83\u50c5\u5c07\u87a2\u5e55\u622a\u5716\u8996\u70ba\u8f38\u5165\uff0c\u4e26\u57f7\u884c\u985e\u4f3c\u4eba\u985e\u7684\u4e92\u52d5\uff08\u4f8b\u5982\uff0c\u9375\u76e4\u548c\u6ed1\u9f20\u64cd\u4f5c\uff09\u3002\u8207\u4f9d\u8cf4\u65bc\u5c08\u5bb6\u7cbe\u5fc3\u88fd\u4f5c\u7684\u63d0\u793a\u548c\u5de5\u4f5c\u6d41\u7a0b\u7684\u76db\u884c\u4ee3\u7406\u67b6\u69cb\u4e0d\u540c\uff0cUI-TARS \u662f\u4e00\u500b\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u5176\u6548\u80fd\u512a\u65bc\u9019\u4e9b\u8907\u96dc\u7684\u67b6\u69cb\u3002\u5be6\u9a57\u8b49\u660e\u4e86\u5176\u5353\u8d8a\u7684\u6548\u80fd\uff1aUI-TARS \u5728 10 \u591a\u500b GUI \u4ee3\u7406\u57fa\u6e96\u6e2c\u8a66\u4e2d\u53d6\u5f97 SOTA \u6548\u80fd\uff0c\u8a55\u4f30\u611f\u77e5\u3001\u57fa\u790e\u548c GUI \u4efb\u52d9\u57f7\u884c\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728 OSWorld \u57fa\u6e96\u6e2c\u8a66\u4e2d\uff0cUI-TARS \u5728 50 \u500b\u6b65\u9a5f\u4e2d\u53d6\u5f97 24.6 \u5206\uff0c\u5728 15 \u500b\u6b65\u9a5f\u4e2d\u53d6\u5f97 22.7 \u5206\uff0c\u512a\u65bc Claude\uff08\u5206\u5225\u70ba 22.0 \u548c 14.9\uff09\u3002\u5728 AndroidWorld \u4e2d\uff0cUI-TARS \u53d6\u5f97 46.6 \u5206\uff0c\u8d85\u8d8a GPT-4o\uff0834.5\uff09\u3002UI-TARS \u878d\u5408\u4e86\u591a\u9805\u95dc\u9375\u5275\u65b0\uff1a(1) \u589e\u5f37\u611f\u77e5\uff1a\u5229\u7528\u5927\u898f\u6a21 GUI \u87a2\u5e55\u622a\u5716\u8cc7\u6599\u96c6\uff0c\u4ee5\u60c5\u5883\u611f\u77e5\u7684\u65b9\u5f0f\u7406\u89e3 UI \u5143\u7d20\u4e26\u9032\u884c\u7cbe\u78ba\u6a19\u984c\u8aaa\u660e\uff1b(2) \u7d71\u4e00\u52d5\u4f5c\u5efa\u6a21\uff0c\u5c07\u52d5\u4f5c\u6a19\u6e96\u5316\u5230\u8de8\u5e73\u53f0\u7684\u7d71\u4e00\u7a7a\u9593\uff0c\u4e26\u900f\u904e\u5927\u898f\u6a21\u52d5\u4f5c\u8ffd\u8e64\uff0c\u5be6\u73fe\u7cbe\u78ba\u7684\u57fa\u790e\u548c\u4e92\u52d5\uff1b(3) \u7cfb\u7d71 2 \u63a8\u7406\uff0c\u5c07\u6df1\u601d\u719f\u616e\u7684\u63a8\u7406\u7d0d\u5165\u591a\u6b65\u9a5f\u6c7a\u7b56\u5236\u5b9a\u4e2d\uff0c\u6d89\u53ca\u591a\u7a2e\u63a8\u7406\u6a21\u5f0f\uff0c\u4f8b\u5982\u4efb\u52d9\u5206\u89e3\u3001\u53cd\u601d\u601d\u8003\u3001\u91cc\u7a0b\u7891\u8b58\u5225\u7b49\uff1b(4) \u900f\u904e\u53cd\u601d\u6027\u7dda\u4e0a\u8ffd\u8e64\u9032\u884c\u53cd\u8986\u8a13\u7df4\uff0c\u900f\u904e\u5728\u6578\u767e\u53f0\u865b\u64ec\u6a5f\u5668\u4e0a\u81ea\u52d5\u6536\u96c6\u3001\u904e\u6ffe\u548c\u53cd\u601d\u6027\u5730\u7cbe\u7149\u65b0\u7684\u4e92\u52d5\u8ffd\u8e64\uff0c\u4f86\u89e3\u6c7a\u8cc7\u6599\u74f6\u9838\u554f\u984c\u3002\u900f\u904e\u53cd\u8986\u8a13\u7df4\u548c\u53cd\u601d\u8abf\u6574\uff0cUI-TARS \u4e0d\u65b7\u5f9e\u5176\u932f\u8aa4\u4e2d\u5b78\u7fd2\uff0c\u4e26\u5728\u6700\u5c11\u7684\u4eba\u70ba\u5e72\u9810\u4e0b\u9069\u61c9\u7121\u6cd5\u9810\u898b\u7684\u60c5\u6cc1\u3002\u6211\u5011\u4e5f\u5206\u6790\u4e86 GUI \u4ee3\u7406\u7684\u6f14\u9032\u8def\u5f91\uff0c\u4ee5\u5f15\u5c0e\u6b64\u9818\u57df\u7684\u9032\u4e00\u6b65\u767c\u5c55\u3002", "author": "Yujia Qin et.al.", "authors": "Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin Li, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli Ma, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao Wang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, Guang Shi", "id": "2501.12326v1", "paper_url": "http://arxiv.org/abs/2501.12326v1", "repo": "https://github.com/bytedance/ui-tars"}}