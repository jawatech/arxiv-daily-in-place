
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-27**|**Taming Data and Transformers for Audio Generation**|Moayed Haji-Ali et.al.|[2406.19388v1](http://arxiv.org/abs/2406.19388v1)|null|
|**2024-06-27**|**The Remarkable Robustness of LLMs: Stages of Inference?**|Vedang Lad et.al.|[2406.19384v1](http://arxiv.org/abs/2406.19384v1)|[link](https://github.com/vdlad/remarkable-robustness-of-llms)|
|**2024-06-27**|**Suri: Multi-constraint Instruction Following for Long-form Text Generation**|Chau Minh Pham et.al.|[2406.19371v1](http://arxiv.org/abs/2406.19371v1)|[link](https://github.com/chtmp223/suri)|
|**2024-06-27**|**Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space**|Core Francisco Park et.al.|[2406.19370v1](http://arxiv.org/abs/2406.19370v1)|null|
|**2024-06-27**|**The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models**|Xiliang Zhu et.al.|[2406.19358v1](http://arxiv.org/abs/2406.19358v1)|null|
|**2024-06-27**|**DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions**|Nigel Fernandez et.al.|[2406.19356v1](http://arxiv.org/abs/2406.19356v1)|null|
|**2024-06-27**|**Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?**|Peter Hase et.al.|[2406.19354v1](http://arxiv.org/abs/2406.19354v1)|null|
|**2024-06-27**|**IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language**|Lucky Susanto et.al.|[2406.19349v1](http://arxiv.org/abs/2406.19349v1)|null|
|**2024-06-27**|**Efficient World Models with Context-Aware Tokenization**|Vincent Micheli et.al.|[2406.19320v1](http://arxiv.org/abs/2406.19320v1)|[link](https://github.com/vmicheli/delta-iris)|
|**2024-06-27**|**Jump Starting Bandits with LLM-Generated Prior Knowledge**|Parand A. Alamdari et.al.|[2406.19317v1](http://arxiv.org/abs/2406.19317v1)|null|
|**2024-06-27**|**LiveBench: A Challenging, Contamination-Free LLM Benchmark**|Colin White et.al.|[2406.19314v1](http://arxiv.org/abs/2406.19314v1)|[link](https://github.com/livebench/livebench)|
|**2024-06-27**|**From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data**|Zheyang Xiong et.al.|[2406.19292v1](http://arxiv.org/abs/2406.19292v1)|null|
|**2024-06-27**|**HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale**|Junying Chen et.al.|[2406.19280v1](http://arxiv.org/abs/2406.19280v1)|[link](https://github.com/freedomintelligence/huatuogpt-vision)|
|**2024-06-27**|**VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation**|Yixiao Song et.al.|[2406.19276v1](http://arxiv.org/abs/2406.19276v1)|[link](https://github.com/Yixiao-Song/VeriScore)|
|**2024-06-27**|**AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning**|Praneeth Vadlapati et.al.|[2406.19271v1](http://arxiv.org/abs/2406.19271v1)|[link](https://github.com/Pro-GenAI/AutoPureData)|
|**2024-06-27**|**Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding**|Yue Fan et.al.|[2406.19263v1](http://arxiv.org/abs/2406.19263v1)|null|
|**2024-06-27**|**AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI**|Kaveen Hiniduma et.al.|[2406.19256v1](http://arxiv.org/abs/2406.19256v1)|null|
|**2024-06-27**|**Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**|Hao Fei et.al.|[2406.19255v1](http://arxiv.org/abs/2406.19255v1)|null|
|**2024-06-27**|**AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation**|Jia Fu et.al.|[2406.19251v1](http://arxiv.org/abs/2406.19251v1)|null|
|**2024-06-27**|**Application of ASV for Voice Identification after VC and Duration Predictor Improvement in TTS Models**|Borodin Kirill Nikolayevich et.al.|[2406.19243v1](http://arxiv.org/abs/2406.19243v1)|null|
|**2024-06-27**|**Revealing Fine-Grained Values and Opinions in Large Language Models**|Dustin Wright et.al.|[2406.19238v1](http://arxiv.org/abs/2406.19238v1)|[link](https://github.com/copenlu/llm-pct-tropes)|
|**2024-06-27**|**FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts**|Shubhankar Singh et.al.|[2406.19237v2](http://arxiv.org/abs/2406.19237v2)|null|
|**2024-06-27**|**Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions**|Minghan Li et.al.|[2406.19236v1](http://arxiv.org/abs/2406.19236v1)|[link](https://github.com/lpercc/ha3d_simulator)|
|**2024-06-27**|**Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation**|Yuying Li et.al.|[2406.19234v1](http://arxiv.org/abs/2406.19234v1)|null|
|**2024-06-27**|**RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs**|Ekaterina Taktasheva et.al.|[2406.19232v2](http://arxiv.org/abs/2406.19232v2)|null|
|**2024-06-27**|**Spiking Convolutional Neural Networks for Text Classification**|Changze Lv et.al.|[2406.19230v1](http://arxiv.org/abs/2406.19230v1)|[link](https://github.com/Lvchangze/snn)|
|**2024-06-27**|**Tools Fail: Detecting Silent Errors in Faulty Tools**|Jimin Sun et.al.|[2406.19228v1](http://arxiv.org/abs/2406.19228v1)|null|
|**2024-06-27**|**Aligning Teacher with Student Preferences for Tailored Training Data Generation**|Yantao Liu et.al.|[2406.19227v1](http://arxiv.org/abs/2406.19227v1)|null|
|**2024-06-27**|**Simulating Classroom Education with LLM-Empowered Agents**|Zheyuan Zhang et.al.|[2406.19226v1](http://arxiv.org/abs/2406.19226v1)|null|
|**2024-06-27**|**T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings**|Björn Deiseroth et.al.|[2406.19223v1](http://arxiv.org/abs/2406.19223v1)|null|
|**2024-06-27**|**Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos**|Zhimin Shao et.al.|[2406.19217v1](http://arxiv.org/abs/2406.19217v1)|null|
|**2024-06-27**|**SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation**|Zijun Yao et.al.|[2406.19215v1](http://arxiv.org/abs/2406.19215v1)|[link](https://github.com/thu-keg/seakr)|
|**2024-06-27**|**BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring**|Luca Benfenati et.al.|[2406.19189v1](http://arxiv.org/abs/2406.19189v1)|null|
|**2024-06-27**|**Annotation Errors and NER: A Study with OntoNotes 5.0**|Gabriel Bernier-Colborne et.al.|[2406.19172v1](http://arxiv.org/abs/2406.19172v1)|null|
|**2024-06-27**|**The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems**|Judith Sieker et.al.|[2406.19170v1](http://arxiv.org/abs/2406.19170v1)|[link](https://github.com/fawazsammani/nlxgpt)|
|**2024-06-27**|**RAVEN: Multitask Retrieval Augmented Vision-Language Learning**|Varun Nagaraj Rao et.al.|[2406.19150v1](http://arxiv.org/abs/2406.19150v1)|null|
|**2024-06-27**|**BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision**|Kit Mills Bransby et.al.|[2406.19148v1](http://arxiv.org/abs/2406.19148v1)|[link](https://github.com/kitbransby/backmix)|
|**2024-06-27**|**Resolving Discrepancies in Compute-Optimal Scaling of Language Models**|Tomer Porian et.al.|[2406.19146v1](http://arxiv.org/abs/2406.19146v1)|[link](https://github.com/formll/resolving-scaling-law-discrepencies)|
|**2024-06-27**|**YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention**|Chenxu Wang et.al.|[2406.19136v1](http://arxiv.org/abs/2406.19136v1)|[link](https://github.com/xunyoyo/YZS-Model)|
|**2024-06-27**|**DEX-TTS: Diffusion-based EXpressive Text-to-Speech with Style Modeling on Time Variability**|Hyun Joon Park et.al.|[2406.19135v1](http://arxiv.org/abs/2406.19135v1)|[link](https://github.com/winddori2002/dex-tts)|
|**2024-06-27**|**Towards Learning Abductive Reasoning using VSA Distributed Representations**|Giacomo Camposampiero et.al.|[2406.19121v1](http://arxiv.org/abs/2406.19121v1)|[link](https://github.com/ibm/abductive-rule-learner-with-context-awareness)|
|**2024-06-27**|**CHEW: A Dataset of CHanging Events in Wikipedia**|Hsuvas Borkakoty et.al.|[2406.19116v1](http://arxiv.org/abs/2406.19116v1)|null|
|**2024-06-27**|**Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction**|Blaise Agüera y Arcas et.al.|[2406.19108v1](http://arxiv.org/abs/2406.19108v1)|[link](https://github.com/paradigms-of-intelligence/cubff)|
|**2024-06-27**|**Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs**|Lokesh Mishra et.al.|[2406.19102v1](http://arxiv.org/abs/2406.19102v1)|null|
|**2024-06-27**|**Fairness and Bias in Multimodal AI: A Survey**|Tosin Adewumi et.al.|[2406.19097v1](http://arxiv.org/abs/2406.19097v1)|null|
|**2024-06-27**|**Dimensions underlying the representational alignment of deep neural networks with humans**|Florian P. Mahner et.al.|[2406.19087v1](http://arxiv.org/abs/2406.19087v1)|[link](https://github.com/florianmahner/object-dimensions)|
|**2024-06-27**|**AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries**|Irina Saparina et.al.|[2406.19073v1](http://arxiv.org/abs/2406.19073v1)|[link](https://github.com/saparina/ambrosia)|
|**2024-06-27**|**EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization**|Ondrej Sotolar et.al.|[2406.19071v1](http://arxiv.org/abs/2406.19071v1)|[link](https://github.com/ondrejsotolar/empo)|
|**2024-06-27**|**STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis**|Wenbin Li et.al.|[2406.19065v1](http://arxiv.org/abs/2406.19065v1)|[link](https://github.com/lwbxc/stbench)|
|**2024-06-27**|**Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO**|Fuseini Mumuni et.al.|[2406.19057v1](http://arxiv.org/abs/2406.19057v1)|null|
|**2024-06-27**|**A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)**|Daniel Sonntag et.al.|[2406.19054v1](http://arxiv.org/abs/2406.19054v1)|null|
|**2024-06-27**|**FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning**|Alexander Herzog et.al.|[2406.19050v1](http://arxiv.org/abs/2406.19050v1)|null|
|**2024-06-27**|**Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation**|Amartya Sanyal et.al.|[2406.19049v1](http://arxiv.org/abs/2406.19049v1)|null|
|**2024-06-27**|**Improving Weak-to-Strong Generalization with Reliability-Aware Alignment**|Yue Guo et.al.|[2406.19032v1](http://arxiv.org/abs/2406.19032v1)|[link](https://github.com/irenehere/reliablealignment)|
|**2024-06-27**|**Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes**|Joachim Schaeffer et.al.|[2406.19015v1](http://arxiv.org/abs/2406.19015v1)|null|
|**2024-06-27**|**FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity**|Zhaobin Sun et.al.|[2406.18995v1](http://arxiv.org/abs/2406.18995v1)|[link](https://github.com/szbonaldo/fedmlp)|
|**2024-06-27**|**Semi-supervised Concept Bottleneck Models**|Lijie Hu et.al.|[2406.18992v1](http://arxiv.org/abs/2406.18992v1)|null|
|**2024-06-27**|**RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton**|Fanfan Liu et.al.|[2406.18977v1](http://arxiv.org/abs/2406.18977v1)|[link](https://github.com/liufanfanlff/robouniview)|
|**2024-06-27**|**Applying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over**|Atsunori Ogawa et.al.|[2406.18972v1](http://arxiv.org/abs/2406.18972v1)|null|
|**2024-06-27**|**UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models**|Siyuan Wu et.al.|[2406.18966v2](http://arxiv.org/abs/2406.18966v2)|null|
|**2024-06-27**|**Investigating and Defending Shortcut Learning in Personalized Diffusion Models**|Yixin Liu et.al.|[2406.18944v1](http://arxiv.org/abs/2406.18944v1)|null|
|**2024-06-27**|**Federated Graph Semantic and Structural Learning**|Wenke Huang et.al.|[2406.18937v1](http://arxiv.org/abs/2406.18937v1)|[link](https://github.com/guanchengwan/fgssl)|
|**2024-06-27**|**The single-use restriction for register automata and transducers over infinite alphabets**|Rafał Stefański et.al.|[2406.18934v1](http://arxiv.org/abs/2406.18934v1)|null|
|**2024-06-27**|**Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation Network**|Yehoshua Dissen et.al.|[2406.18928v1](http://arxiv.org/abs/2406.18928v1)|null|
|**2024-06-27**|**Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding**|Jiwan Chung et.al.|[2406.18925v1](http://arxiv.org/abs/2406.18925v1)|null|
|**2024-06-27**|**Time Matters: Scaling Laws for Any Budget**|Itay Inbar et.al.|[2406.18922v1](http://arxiv.org/abs/2406.18922v1)|null|
|**2024-06-27**|**Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data**|Yiting Ran et.al.|[2406.18921v1](http://arxiv.org/abs/2406.18921v1)|null|
|**2024-06-27**|**TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**|Wen Zhang et.al.|[2406.18916v1](http://arxiv.org/abs/2406.18916v1)|null|
|**2024-06-27**|**Factor-Conditioned Speaking-Style Captioning**|Atsushi Ando et.al.|[2406.18910v1](http://arxiv.org/abs/2406.18910v1)|null|
|**2024-06-27**|**Historia Magistra Vitae: Dynamic Topic Modeling of Roman Literature using Neural Embeddings**|Michael Ginn et.al.|[2406.18907v1](http://arxiv.org/abs/2406.18907v1)|null|
|**2024-06-27**|**Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets**|Melanie Walsh et.al.|[2406.18906v1](http://arxiv.org/abs/2406.18906v1)|null|
|**2024-06-27**|**The Rise of Artificial Intelligence in Educational Measurement: Opportunities and Ethical Challenges**|Okan Bulut et.al.|[2406.18900v1](http://arxiv.org/abs/2406.18900v1)|null|
|**2024-06-27**|**Autonomous Control of a Novel Closed Chain Five Bar Active Suspension via Deep Reinforcement Learning**|Nishesh Singh et.al.|[2406.18899v1](http://arxiv.org/abs/2406.18899v1)|null|
|**2024-06-27**|**Can we teach language models to gloss endangered languages?**|Michael Ginn et.al.|[2406.18895v1](http://arxiv.org/abs/2406.18895v1)|null|
|**2024-06-27**|**SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models**|Vipul Rathore et.al.|[2406.18880v1](http://arxiv.org/abs/2406.18880v1)|[link](https://github.com/dair-iitd/SSP)|
|**2024-06-27**|**DeSTA: Enhancing Speech Language Models through Descriptive Speech-Text Alignment**|Ke-Han Lu et.al.|[2406.18871v1](http://arxiv.org/abs/2406.18871v1)|null|
|**2024-06-27**|**Efficacy of Language Model Self-Play in Non-Zero-Sum Games**|Austen Liao et.al.|[2406.18872v1](http://arxiv.org/abs/2406.18872v1)|[link](https://github.com/nickatomlin/lm-selfplay)|
|**2024-06-27**|**Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification**|Ziyu Yang et.al.|[2406.18859v1](http://arxiv.org/abs/2406.18859v1)|[link](https://github.com/ziyu-yang/human-evaluation)|
|**2024-06-27**|**FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus**|Yuxin Fu et.al.|[2406.18856v1](http://arxiv.org/abs/2406.18856v1)|null|
|**2024-06-27**|**LICO: Large Language Models for In-Context Molecular Optimization**|Tung Nguyen et.al.|[2406.18851v1](http://arxiv.org/abs/2406.18851v1)|null|
|**2024-06-27**|**Learning Retrieval Augmentation for Personalized Dialogue Generation**|Qiushi Huang et.al.|[2406.18847v1](http://arxiv.org/abs/2406.18847v1)|[link](https://github.com/hqsiswiliam/lapdog)|
|**2024-06-27**|**Retain, Blend, and Exchange: A Quality-aware Spatial-Stereo Fusion Approach for Event Stream Recognition**|Lan Chen et.al.|[2406.18845v1](http://arxiv.org/abs/2406.18845v1)|[link](https://github.com/event-ahu/efv_event_classification)|
|**2024-06-27**|**Disentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA**|Elham J. Barezi et.al.|[2406.18839v1](http://arxiv.org/abs/2406.18839v1)|null|
|**2024-06-27**|**OutlierTune: Efficient Channel-Wise Quantization for Large Language Models**|Jinguang Wang et.al.|[2406.18832v1](http://arxiv.org/abs/2406.18832v1)|null|
|**2024-06-27**|**A Survey on Privacy Attacks Against Digital Twin Systems in AI-Robotics**|Ivan A. Fernandez et.al.|[2406.18812v1](http://arxiv.org/abs/2406.18812v1)|null|
|**2024-06-27**|**Infinite Width Models That Work: Why Feature Learning Doesn't Matter as Much as You Think**|Luke Sernau et.al.|[2406.18800v1](http://arxiv.org/abs/2406.18800v1)|null|
|**2024-06-26**|**MUMU: Bootstrapping Multimodal Image Generation from Text-to-Image Data**|William Berman et.al.|[2406.18790v1](http://arxiv.org/abs/2406.18790v1)|null|
|**2024-06-26**|**Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features**|Jean Marie Tshimula et.al.|[2406.18783v1](http://arxiv.org/abs/2406.18783v1)|null|
|**2024-06-26**|**Implicit Discourse Relation Classification For Nigerian Pidgin**|Muhammed Saeed et.al.|[2406.18776v1](http://arxiv.org/abs/2406.18776v1)|null|
|**2024-06-26**|**WV-Net: A foundation model for SAR WV-mode satellite imagery trained using contrastive self-supervised learning on 10 million images**|Yannik Glaser et.al.|[2406.18765v1](http://arxiv.org/abs/2406.18765v1)|null|
|**2024-06-26**|**Conformalized Link Prediction on Graph Neural Networks**|Tianyi Zhao et.al.|[2406.18763v1](http://arxiv.org/abs/2406.18763v1)|null|
|**2024-06-26**|**Categorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism**|Shi Zong et.al.|[2406.18762v1](http://arxiv.org/abs/2406.18762v1)|null|
|**2024-06-26**|**A Stem-Agnostic Single-Decoder System for Music Source Separation Beyond Four Stems**|Karn N. Watcharasupat et.al.|[2406.18747v1](http://arxiv.org/abs/2406.18747v1)|[link](https://github.com/kwatcharasupat/query-bandit)|
|**2024-06-26**|**Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with Large Language Models**|Baharan Nouriinanloo et.al.|[2406.18740v1](http://arxiv.org/abs/2406.18740v1)|null|
|**2024-06-26**|**WavRx: a Disease-Agnostic, Generalizable, and Privacy-Preserving Speech Health Diagnostic Model**|Yi Zhu et.al.|[2406.18731v1](http://arxiv.org/abs/2406.18731v1)|[link](https://github.com/zhu00121/wavrx)|
|**2024-06-26**|**Jailbreaking LLMs with Arabic Transliteration and Arabizi**|Mansour Al Ghanim et.al.|[2406.18725v1](http://arxiv.org/abs/2406.18725v1)|null|
|**2024-06-26**|**Learn it or Leave it: Module Composition and Pruning for Continual Learning**|Mingyang Wang et.al.|[2406.18708v1](http://arxiv.org/abs/2406.18708v1)|null|
|**2024-06-26**|**Simulating The U.S. Senate: An LLM-Driven Agent Approach to Modeling Legislative Behavior and Bipartisanship**|Zachary R. Baker et.al.|[2406.18702v1](http://arxiv.org/abs/2406.18702v1)|null|
|**2024-06-26**|**Fast Optimizer Benchmark**|Simon Blauth et.al.|[2406.18701v1](http://arxiv.org/abs/2406.18701v1)|[link](https://github.com/automl/fob)|
|**2024-06-26**|**Sequence Graph Network for Online Debate Analysis**|Quan Mai et.al.|[2406.18696v1](http://arxiv.org/abs/2406.18696v1)|[link](https://github.com/quanmai/SGA)|

#### Abstracts
##### **Taming Data and Transformers for Audio Generation**
2406.19388v1 by Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, Vicente Ordonez

Generating ambient sounds and effects is a challenging problem due to data
scarcity and often insufficient caption quality, making it difficult to employ
large-scale generative models for the task. In this work, we tackle the problem
by introducing two new models. First, we propose AutoCap, a high-quality and
efficient automatic audio captioning model. We show that by leveraging metadata
available with the audio modality, we can substantially improve the quality of
captions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from
the best available captioning model at four times faster inference speed. We
then use AutoCap to caption clips from existing datasets, obtaining 761,000
audio clips with high-quality captions, forming the largest available
audio-text dataset. Second, we propose GenAu, a scalable transformer-based
audio generation architecture that we scale up to 1.25B parameters and train
with our new dataset. When compared to state-of-the-art audio generators, GenAu
obtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%
in CLAP score, indicating significantly improved quality of generated audio
compared to previous works. This shows that the quality of data is often as
important as its quantity. Besides, since AutoCap is fully automatic, new audio
samples can be added to the training dataset, unlocking the training of even
larger generative models for audio synthesis.

摘要：<paragraph>由於資料稀少且字幕品質通常不足，產生環境音效是一項具有挑戰性的問題，這使得難以使用大規模生成模型來執行此任務。在這項工作中，我們透過引入兩個新模型來解決這個問題。首先，我們提出 AutoCap，這是一個高品質且高效的自動音訊字幕模型。我們展示透過利用音訊模式中可用的元資料，我們可以大幅提升字幕品質。AutoCap 的 CIDEr 分數達到 83.2，比現有最佳字幕模型進步了 3.2%，而且推論速度快了四倍。然後我們使用 AutoCap 為現有資料集中的片段加上字幕，取得 761,000 個具有高品質字幕的音訊片段，形成最大的可用音訊文字資料集。其次，我們提出 GenAu，這是一個可擴充的基於 Transformer 的音訊生成架構，我們將其擴充到 1.25B 個參數，並使用我們的新資料集進行訓練。與最先進的音訊生成器相比，GenAu 在 FAD 分數方面獲得了 15.7% 的顯著提升，在 IS 方面提升了 22.7%，在 CLAP 分數方面提升了 13.5%，這表示與先前的作品相比，生成的音訊品質有顯著提升。這顯示資料的品質通常與其數量一樣重要。此外，由於 AutoCap 是全自動的，因此可以將新的音訊範例新增到訓練資料集，這將開啟訓練更大音訊合成生成模型的可能性。</paragraph>

##### **The Remarkable Robustness of LLMs: Stages of Inference?**
2406.19384v1 by Vedang Lad, Wes Gurnee, Max Tegmark

We demonstrate and investigate the remarkable robustness of Large Language
Models by deleting and swapping adjacent layers. We find that deleting and
swapping interventions retain 72-95\% of the original model's prediction
accuracy without fine-tuning, whereas models with more layers exhibit more
robustness. Based on the results of the layer-wise intervention and further
experiments, we hypothesize the existence of four universal stages of inference
across eight different models: detokenization, feature engineering, prediction
ensembling, and residual sharpening. The first stage integrates local
information, lifting raw token representations into higher-level contextual
representations. Next is the iterative refinement of task and entity-specific
features. Then, the second half of the model begins with a phase transition,
where hidden representations align more with the vocabulary space due to
specialized model components. Finally, the last layer sharpens the following
token distribution by eliminating obsolete features that add noise to the
prediction.

摘要：<paragraph>我們透過刪除和交換相鄰層，展示並探討大型語言模型的非凡穩健性。我們發現刪除和交換介入維持了 72-95% 的原始模型預測準確度，而沒有微調，而具有更多層的模型則表現出更高的穩健性。根據層級介入的結果和進一步的實驗，我們假設在八種不同模型中存在四個普遍的推論階段：去符號化、特徵工程、預測集成和殘差銳化。第一階段整合局部資訊，將原始符號表示提升到更高級別的上下文表示。接下來是任務和特定實體特徵的迭代改進。然後，模型的後半部分從相位轉變開始，其中隱藏表示由於專業模型組件而更符合詞彙空間。最後，最後一層透過消除增加預測雜訊的過時特徵來銳化後續符號分佈。</paragraph>

##### **Suri: Multi-constraint Instruction Following for Long-form Text Generation**
2406.19371v1 by Chau Minh Pham, Simeng Sun, Mohit Iyyer

Existing research on instruction following largely focuses on tasks with
simple instructions and short responses. In this work, we explore
multi-constraint instruction following for generating long-form text. We create
Suri, a dataset with 20K human-written long-form texts paired with
LLM-generated backtranslated instructions that contain multiple complex
constraints. Because of prohibitive challenges associated with collecting human
preference judgments on long-form texts, preference-tuning algorithms such as
DPO are infeasible in our setting; thus, we propose Instructional ORPO
(I-ORPO), an alignment method based on the ORPO algorithm. Instead of receiving
negative feedback from dispreferred responses, I-ORPO obtains negative feedback
from synthetically corrupted instructions generated by an LLM. Using Suri, we
perform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. The
resulting models, Suri-SFT and Suri-I-ORPO, generate significantly longer texts
(~5K tokens) than base models without significant quality deterioration. Our
human evaluation shows that while both SFT and I-ORPO models satisfy most
constraints, Suri-I-ORPO generations are generally preferred for their coherent
and informative incorporation of the constraints. We release our code at
https://github.com/chtmp223/suri.

摘要：現有的指令遵循研究主要集中在具有簡單指令和簡短回應的任務上。在這項工作中，我們探索多重約束指令，以產生長篇文字。我們創建了 Suri，一個包含 20K 人工撰寫長篇文字的資料集，並配對包含多重複雜約束的 LLM 生成的反向翻譯指令。由於與收集長篇文字的人類偏好判斷相關的挑戰性，因此在我們的設定中，偏好調整演算法（例如 DPO）不可行；因此，我們提出了基於 ORPO 演算法的對齊方法，即指令性 ORPO (I-ORPO)。I-ORPO 沒有從不受歡迎的回應中接收負面回饋，而是從由 LLM 生成的合成損壞指令中獲得負面回饋。使用 Suri，我們對 Mistral-7b-Instruct-v0.2 執行監督和 I-ORPO 微調。最終模型 Suri-SFT 和 Suri-I-ORPO 生成的文字比基本模型顯著更長（~5K 個符號），而品質沒有顯著下降。我們的人類評估顯示，雖然 SFT 和 I-ORPO 模型都滿足大多數約束，但 Suri-I-ORPO 生成的文字通常因其相干且具資訊性的約束納入而受到偏好。我們在 https://github.com/chtmp223/suri/ 發布我們的程式碼。

##### **Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space**
2406.19370v1 by Core Francisco Park, Maya Okawa, Andrew Lee, Ekdeep Singh Lubana, Hidenori Tanaka

Modern generative models demonstrate impressive capabilities, likely stemming
from an ability to identify and manipulate abstract concepts underlying their
training data. However, fundamental questions remain: what determines the
concepts a model learns, the order in which it learns them, and its ability to
manipulate those concepts? To address these questions, we propose analyzing a
model's learning dynamics via a framework we call the concept space, where each
axis represents an independent concept underlying the data generating process.
By characterizing learning dynamics in this space, we identify how the speed at
which a concept is learned, and hence the order of concept learning, is
controlled by properties of the data we term concept signal. Further, we
observe moments of sudden turns in the direction of a model's learning dynamics
in concept space. Surprisingly, these points precisely correspond to the
emergence of hidden capabilities, i.e., where latent interventions show the
model possesses the capability to manipulate a concept, but these capabilities
cannot yet be elicited via naive input prompting. While our results focus on
synthetically defined toy datasets, we hypothesize a general claim on emergence
of hidden capabilities may hold: generative models possess latent capabilities
that emerge suddenly and consistently during training, though a model might not
exhibit these capabilities under naive input prompting.

摘要：現代生成模型展現出令人印象深刻的能力，這很可能是因為它們能夠識別並操作其訓練資料中潛在概念的能力。然而，仍然存在一些基本問題：是什麼決定了模型學習的概念、學習的順序，以及操縱這些概念的能力？為了回答這些問題，我們建議透過一個我們稱之為概念空間的框架來分析模型的學習動態，其中每個軸線代表資料產生過程中一個獨立的概念。透過描述這個空間中的學習動態，我們可以找出學習一個概念的速度，以及概念學習的順序，是如何受到我們稱之為概念訊號的資料屬性控制的。此外，我們觀察到模型在概念空間中學習動態方向突然轉變的時刻。令人驚訝的是，這些點恰好對應於隱藏能力的出現，也就是潛在介入顯示模型具備操縱概念的能力，但這些能力還無法透過單純的輸入提示引發。雖然我們的結果著重於合成定義的玩具資料集，但我們假設了一個關於隱藏能力出現的一般性主張可能成立：生成模型具備潛在能力，這些能力在訓練期間突然且一致地出現，儘管模型在單純的輸入提示下可能不會表現出這些能力。

##### **The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models**
2406.19358v1 by Xiliang Zhu, Shayna Gardiner, Tere Roldán, David Rossouw

Sentiment analysis serves as a pivotal component in Natural Language
Processing (NLP). Advancements in multilingual pre-trained models such as XLM-R
and mT5 have contributed to the increasing interest in cross-lingual sentiment
analysis. The recent emergence in Large Language Models (LLM) has significantly
advanced general NLP tasks, however, the capability of such LLMs in
cross-lingual sentiment analysis has not been fully studied. This work
undertakes an empirical analysis to compare the cross-lingual transfer
capability of public Small Multilingual Language Models (SMLM) like XLM-R,
against English-centric LLMs such as Llama-3, in the context of sentiment
analysis across English, Spanish, French and Chinese. Our findings reveal that
among public models, SMLMs exhibit superior zero-shot cross-lingual performance
relative to LLMs. However, in few-shot cross-lingual settings, public LLMs
demonstrate an enhanced adaptive potential. In addition, we observe that
proprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but
are outpaced by public models in few-shot scenarios.

摘要：情緒分析是自然語言處理 (NLP) 中的關鍵組成部分。多語言預訓練模型（例如 XLM-R 和 mT5）的進步，促使人們對跨語言情緒分析產生越來越大的興趣。近期出現的大型語言模型 (LLM) 已大幅提升一般 NLP 任務，然而，此類 LLM 在跨語言情緒分析中的能力尚未獲得充分研究。本研究進行實證分析，以比較公開的小型多語言語言模型 (SMLM)（例如 XLM-R）與以英語為中心的 LLM（例如 Llama-3）在英語、西班牙語、法語和中文的情緒分析中的跨語言轉移能力。我們的研究結果顯示，在公開模型中，SMLM 相較於 LLM，展現出優異的零次學習跨語言效能。然而，在少次學習的跨語言設定中，公開 LLM 展現出增強的適應潛力。此外，我們觀察到專有的 GPT-3.5 和 GPT-4 在零次學習跨語言能力中領先，但在少次學習場景中卻落後於公開模型。

##### **DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions**
2406.19356v1 by Nigel Fernandez, Alexander Scarlatos, Simon Woodhead, Andrew Lan

High-quality distractors are crucial to both the assessment and pedagogical
value of multiple-choice questions (MCQs), where manually crafting ones that
anticipate knowledge deficiencies or misconceptions among real students is
difficult. Meanwhile, automated distractor generation, even with the help of
large language models (LLMs), remains challenging for subjects like math. It is
crucial to not only identify plausible distractors but also understand the
error behind them. In this paper, we introduce DiVERT (Distractor Generation
with Variational Errors Represented as Text), a novel variational approach that
learns an interpretable representation of errors behind distractors in math
MCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions
used by hundreds of thousands of students, we show that DiVERT, despite using a
base open-source LLM with 7B parameters, outperforms state-of-the-art
approaches using GPT-4o on downstream distractor generation. We also conduct a
human evaluation with math educators and find that DiVERT leads to error labels
that are of comparable quality to human-authored ones.

摘要：優質的干擾選項對於多選題 (MCQ) 的評量和教學價值至關重要，而手動製作能預期到真實學生知識不足或觀念錯誤的選項很困難。同時，自動化干擾選項生成，即使在大型語言模型 (LLM) 的協助下，對於數學等科目而言仍然具有挑戰性。不僅要找出合理的干擾選項，還要了解其背後的錯誤至關重要。在本文中，我們介紹 DiVERT（以文字表示的變異錯誤干擾選項生成），這是一種新穎的變異方法，可以學習數學多選題中干擾選項背後錯誤的可詮釋表示。透過對 1,434 個問題的真實世界數學多選題資料集進行實驗，數十萬名學生使用這些問題，我們展示了 DiVERT，儘管使用帶有 7B 參數的基本開源 LLM，但在下游干擾選項生成中優於使用 GPT-4o 的最先進方法。我們還與數學教育工作者進行了人工評量，發現 DiVERT 產生的錯誤標籤與人工編寫的標籤品質相當。

##### **Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?**
2406.19354v1 by Peter Hase, Thomas Hofweber, Xiang Zhou, Elias Stengel-Eskin, Mohit Bansal

The model editing problem concerns how language models should learn new facts
about the world over time. While empirical research on model editing has drawn
widespread attention, the conceptual foundations of model editing remain shaky
-- perhaps unsurprisingly, since model editing is essentially belief revision,
a storied problem in philosophy that has eluded succinct solutions for decades.
Model editing nonetheless demands a solution, since we need to be able to
control the knowledge within language models. With this goal in mind, this
paper critiques the standard formulation of the model editing problem and
proposes a formal testbed for model editing research. We first describe 12 open
problems with model editing, based on challenges with (1) defining the problem,
(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the
first place. Many of these challenges are extremely difficult to address, e.g.
determining far-reaching consequences of edits, labeling probabilistic
entailments between facts, and updating beliefs of agent simulators. Next, we
introduce a semi-synthetic dataset for model editing based on Wikidata, where
we can evaluate edits against labels given by an idealized Bayesian agent. This
enables us to say exactly how belief revision in language models falls short of
a desirable epistemic standard. We encourage further research exploring
settings where such a gold standard can be compared against. Our code is
publicly available at: https://github.com/peterbhase/LLM-belief-revision

摘要：模型編輯問題探討語言模型應如何隨著時間推移學習有關世界的新事實。儘管模型編輯的實證研究已引起廣泛關注，但模型編輯的概念基礎仍然不穩固——這或許不足為奇，因為模型編輯本質上是信念修正，這是一個哲學中的老生常談的問題，數十年來一直沒有簡潔的解決方案。儘管如此，模型編輯還是需要解決方案，因為我們需要能夠控制語言模型中的知識。本著這一目標，本文批判了模型編輯問題的標準表述，並提出了模型編輯研究的正式測試平台。我們首先描述了模型編輯的 12 個開放問題，這些問題基於以下挑戰：(1) 定義問題，(2) 開發基準，以及 (3) 假設 LLM 首先具有可編輯的信念。其中許多挑戰極難解決，例如確定編輯的深遠後果、標記事實之間的概率蘊涵，以及更新代理模擬器的信念。接下來，我們基於 Wikidata 介紹了一個用於模型編輯的半合成數據集，在其中我們可以根據理想貝葉斯代理給出的標籤來評估編輯。這使我們能夠確切地說明語言模型中的信念修正如何達不到理想的認識論標準。我們鼓勵進一步的研究探索可以將這種黃金標準與之進行比較的情況。我們的代碼已公開發布在：https://github.com/peterbhase/LLM-belief-revision

##### **IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language**
2406.19349v1 by Lucky Susanto, Musa Izzanardi Wijanarko, Prasetia Anugrah Pratama, Traci Hong, Ika Idris, Alham Fikri Aji, Derry Wijaya

Hate speech poses a significant threat to social harmony. Over the past two
years, Indonesia has seen a ten-fold increase in the online hate speech ratio,
underscoring the urgent need for effective detection mechanisms. However,
progress is hindered by the limited availability of labeled data for Indonesian
texts. The condition is even worse for marginalized minorities, such as Shia,
LGBTQ, and other ethnic minorities because hate speech is underreported and
less understood by detection tools. Furthermore, the lack of accommodation for
subjectivity in current datasets compounds this issue. To address this, we
introduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity
classification dataset. Comprising 43,692 entries annotated by 19 diverse
individuals, the dataset focuses on texts targeting vulnerable groups in
Indonesia, specifically during the hottest political event in the country: the
presidential election. We establish baselines for seven binary classification
tasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet)
fine-tuned for hate speech classification. Furthermore, we demonstrate how
incorporating demographic information can enhance the zero-shot performance of
the large language model, gpt-3.5-turbo. However, we also caution that an
overemphasis on demographic information can negatively impact the fine-tuned
model performance due to data fragmentation.

摘要：仇恨言論對社會和諧構成重大威脅。在過去兩年，印尼的線上仇恨言論比例增加了十倍，這凸顯了對有效偵測機制的迫切需要。然而，印尼語文本標記資料的有限取得性阻礙了進度。對於少數族群，例如什葉派、LGBTQ 和其他少數民族，情況更糟，因為仇恨言論的通報不足，且偵測工具對其了解較少。此外，現有資料集缺乏對主觀性的考量，使這個問題更加複雜。為了解決這個問題，我們引入了 IndoToxic2024，這是一個全面的印尼語仇恨言論和毒性分類資料集。資料集包含由 19 位不同個人標記的 43,692 個條目，重點在於針對印尼弱勢群體的文本，特別是在該國最熱門的政治活動：總統選舉期間。我們為七項二元分類任務建立基準，使用針對仇恨言論分類微調的 BERT 模型（IndoBERTweet），達到了 0.78 的巨觀 F1 分數。此外，我們展示了如何透過納入人口統計資訊來增強大型語言模型 gpt-3.5-turbo 的零次學習效能。然而，我們也提醒，過度強調人口統計資訊可能會因為資料分散而對微調模型效能造成負面影響。

##### **Efficient World Models with Context-Aware Tokenization**
2406.19320v1 by Vincent Micheli, Eloi Alonso, François Fleuret

Scaling up deep Reinforcement Learning (RL) methods presents a significant
challenge. Following developments in generative modelling, model-based RL
positions itself as a strong contender. Recent advances in sequence modelling
have led to effective transformer-based world models, albeit at the price of
heavy computations due to the long sequences of tokens required to accurately
simulate environments. In this work, we propose $\Delta$-IRIS, a new agent with
a world model architecture composed of a discrete autoencoder that encodes
stochastic deltas between time steps and an autoregressive transformer that
predicts future deltas by summarizing the current state of the world with
continuous tokens. In the Crafter benchmark, $\Delta$-IRIS sets a new state of
the art at multiple frame budgets, while being an order of magnitude faster to
train than previous attention-based approaches. We release our code and models
at https://github.com/vmicheli/delta-iris.

摘要：擴展深度強化學習 (RL) 方法是一項重大的挑戰。在生成式建模的發展之後，基於模型的 RL 將自身定位為強有力的競爭者。序列建模的最新進展導致了有效的基於轉換器的世界模型，儘管由於準確模擬環境所需的長序列代幣，而付出了大量計算的代價。在這項工作中，我們提出了 $\Delta$-IRIS，一種新的代理，其世界模型架構由離散自動編碼器組成，該編碼器編碼時間步長之間的隨機增量，以及一個自迴歸轉換器，該轉換器通過使用連續代幣總結世界的當前狀態來預測未來的增量。在 Crafter 基準測試中，$\Delta$-IRIS 在多個幀預算中設定了新的技術水準，同時比之前的基於注意力的方法訓練速度快一個數量級。我們在 https://github.com/vmicheli/delta-iris 上發布我們的代碼和模型。

##### **Jump Starting Bandits with LLM-Generated Prior Knowledge**
2406.19317v1 by Parand A. Alamdari, Yanshuai Cao, Kevin H. Wilson

We present substantial evidence demonstrating the benefits of integrating
Large Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.
Contextual bandits have been widely used in recommendation systems to generate
personalized suggestions based on user-specific contexts. We show that LLMs,
pre-trained on extensive corpora rich in human knowledge and preferences, can
simulate human behaviours well enough to jump-start contextual multi-armed
bandits to reduce online learning regret. We propose an initialization
algorithm for contextual bandits by prompting LLMs to produce a pre-training
dataset of approximate human preferences for the bandit. This significantly
reduces online learning regret and data-gathering costs for training such
models. Our approach is validated empirically through two sets of experiments
with different bandit setups: one which utilizes LLMs to serve as an oracle and
a real-world experiment utilizing data from a conjoint survey experiment.

摘要：我們提出大量的證據，證明將大型語言模型 (LLM) 與情境多臂老虎機架構整合起來的好處。情境多臂老虎機已廣泛用於推薦系統中，以根據使用者特定的情境產生個人化的建議。我們證明，在豐富的人類知識和偏好的廣泛語料庫上預先訓練的 LLM，能夠很好地模擬人類行為，以啟動情境多臂老虎機，減少線上學習遺憾。我們提出了一種情境多臂老虎機的初始化演算法，透過提示 LLM 產生近似人類偏好的預訓練資料集，供老虎機使用。這顯著減少了此類模型的線上學習遺憾和資料收集成本。我們的做法透過兩組具有不同老虎機設定的實驗進行實證驗證：一組利用 LLM 作為神諭，另一組實際實驗利用聯合調查實驗的資料。

##### **LiveBench: A Challenging, Contamination-Free LLM Benchmark**
2406.19314v1 by Colin White, Samuel Dooley, Manley Roberts, Arka Pal, Ben Feuer, Siddhartha Jain, Ravid Shwartz-Ziv, Neel Jain, Khalid Saifullah, Siddartha Naidu, Chinmay Hegde, Yann LeCun, Tom Goldstein, Willie Neiswanger, Micah Goldblum

Test set contamination, wherein test data from a benchmark ends up in a newer
model's training set, is a well-documented obstacle for fair LLM evaluation and
can quickly render benchmarks obsolete. To mitigate this, many recent
benchmarks crowdsource new prompts and evaluations from human or LLM judges;
however, these can introduce significant biases, and break down when scoring
hard questions. In this work, we introduce a new benchmark for LLMs designed to
be immune to both test set contamination and the pitfalls of LLM judging and
human crowdsourcing. We release LiveBench, the first benchmark that (1)
contains frequently-updated questions from recent information sources, (2)
scores answers automatically according to objective ground-truth values, and
(3) contains a wide variety of challenging tasks, spanning math, coding,
reasoning, language, instruction following, and data analysis. To achieve this,
LiveBench contains questions that are based on recently-released math
competitions, arXiv papers, news articles, and datasets, and it contains
harder, contamination-free versions of tasks from previous benchmarks such as
Big-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source
models, as well as dozens of open-source models ranging from 0.5B to 110B in
size. LiveBench is difficult, with top models achieving below 65% accuracy. We
release all questions, code, and model answers. Questions will be added and
updated on a monthly basis, and we will release new tasks and harder versions
of tasks over time so that LiveBench can distinguish between the capabilities
of LLMs as they improve in the future. We welcome community engagement and
collaboration for expanding the benchmark tasks and models.

摘要：測試集污染，基準測試中的測試資料最終出現在較新的模型訓練集中，是公平 LLM 評估的眾所周知障礙，且能快速使基準測試過時。為了減輕這一點，許多最近的基準測試從人類或 LLM 評審中群眾外包新的提示和評估；然而，這些可能會引入顯著的偏見，且在評分困難的問題時會崩潰。在這項工作中，我們為 LLM 介紹了一個新的基準測試，旨在對測試集污染和 LLM 評審和人類群眾外包的陷阱免疫。我們發布 LiveBench，這是第一個 (1) 包含來自近期資訊來源的頻繁更新問題、(2) 根據客觀基本事實值自動評分答案，以及 (3) 包含各種具有挑戰性的任務，涵蓋數學、編碼、推理、語言、遵循指示和資料分析的基準測試。為了達成這一點，LiveBench 包含基於最近發布的數學競賽、arXiv 論文、新聞文章和資料集的問題，並且它包含來自先前基準測試（例如 Big-Bench Hard、AMPS 和 IFEval）的更難、無污染的任務版本。我們評估了許多著名的閉源模型，以及數十個大小從 0.5B 到 110B 的開源模型。LiveBench 很困難，頂尖模型的準確率低於 65%。我們發布所有問題、程式碼和模型答案。問題將按月新增和更新，我們將隨著時間推移發布新的任務和更困難的任務版本，以便 LiveBench 能區分 LLM 在未來改進時的各種功能。我們歡迎社群參與和合作，以擴展基準測試任務和模型。

##### **From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data**
2406.19292v1 by Zheyang Xiong, Vasilis Papageorgiou, Kangwook Lee, Dimitris Papailiopoulos

Recent studies have shown that Large Language Models (LLMs) struggle to
accurately retrieve information and maintain reasoning capabilities when
processing long-context inputs. To address these limitations, we propose a
finetuning approach utilizing a carefully designed synthetic dataset comprising
numerical key-value retrieval tasks. Our experiments on models like GPT-3.5
Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset
significantly improves LLMs' information retrieval and reasoning capabilities
in longer-context settings. We present an analysis of the finetuned models,
illustrating the transfer of skills from synthetic to real task evaluations
(e.g., $10.5\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5
Turbo). We also find that finetuned LLMs' performance on general benchmarks
remains almost constant while LLMs finetuned on other baseline long-context
augmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B
finetuned on our synthetic data cause no performance drop while other baseline
data can cause a drop that ranges from $2.33\%$ to $6.19\%$). Our study
highlights the potential of finetuning on synthetic data for improving the
performance of LLMs on longer-context tasks.

摘要：<paragraph>最近的研究表明，大型语言模型 (LLM) 在处理长文本输入时难以准确地检索信息并维持推理能力。为了解决这些限制，我们提出了一种微调方法，利用精心设计的合成数据集，其中包含数字键值检索任务。我们对 GPT-3.5 Turbo 和 Mistral 7B 等模型进行的实验表明，在该数据集上对 LLM 进行微调可以显着提高 LLM 在较长文本环境中的信息检索和推理能力。我们对微调后的模型进行了分析，说明了从合成任务到真实任务评估的技能转移（例如，在 GPT-3.5 Turbo 的 20 个文档 MDQA 中，在位置 10 上提高了 10.5%）。我们还发现，微调后的 LLM 在一般基准上的性能几乎保持不变，而使用其他基线长文本增强数据对 LLM 进行微调可能会导致出现幻觉（例如，在 TriviaQA 上，在我们的合成数据上微调的 Mistral 7B 不会导致性能下降，而其他基线数据会导致下降 2.33% 至 6.19%）。我们的研究强调了在合成数据上进行微调以提高 LLM 在较长文本任务上的性能的潜力。</paragraph>

##### **HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale**
2406.19280v1 by Junying Chen, Ruyi Ouyang, Anningzhe Gao, Shunian Chen, Guiming Hardy Chen, Xidong Wang, Ruifei Zhang, Zhenyang Cai, Ke Ji, Guangjun Yu, Xiang Wan, Benyou Wang

The rapid development of multimodal large language models (MLLMs), such as
GPT-4V, has led to significant advancements. However, these models still face
challenges in medical multimodal capabilities due to limitations in the
quantity and quality of medical vision-text data, stemming from data privacy
concerns and high annotation costs. While pioneering approaches utilize
PubMed's large-scale, de-identified medical image-text pairs to address these
limitations, they still fall short due to inherent data noise. To tackle this,
we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in
an 'unblinded' capacity to denoise and reformat the data, resulting in the
creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our
validation demonstrates that: (1) PubMedVision can significantly enhance the
medical multimodal capabilities of current MLLMs, showing significant
improvement in benchmarks including the MMMU Health & Medicine track; (2)
manual checks by medical experts and empirical results validate the superior
data quality of our dataset compared to other data construction methods. Using
PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows
superior performance in medical multimodal scenarios among open-source MLLMs.

摘要：多模态大语言模型（MLLM）的快速发展，例如 GPT-4V，带来了重大的进步。然而，由于医疗视觉文本数据的数量和质量的限制，这些模型在医疗多模态能力方面仍然面临挑战，这源于数据隐私问题和高昂的标注成本。虽然开创性的方法利用 PubMed 的大规模、去标识化的医学图像文本对来解决这些限制，但由于固有的数据噪声，它们仍然存在不足。为了解决这个问题，我们从 PubMed 中优化了医学图像文本对，并以“非盲”的方式采用了 MLLM（GPT-4V）来对数据进行去噪和重新格式化，从而创建了包含 130 万个医学 VQA 样本的 PubMedVision 数据集。我们的验证表明：(1) PubMedVision 可以显著增强当前 MLLM 的医疗多模态能力，在包括 MMMU 健康与医学轨道在内的基准测试中显示出显著的改进；(2) 医学专家的手动检查和实证结果验证了我们数据集与其他数据构建方法相比的卓越数据质量。使用 PubMedVision，我们训练了一个 34B 医学 MLLM HuatuoGPT-Vision，它在开源 MLLM 中的医学多模态场景中表现出卓越的性能。

##### **VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation**
2406.19276v1 by Yixiao Song, Yekyung Kim, Mohit Iyyer

Existing metrics for evaluating the factuality of long-form text, such as
FACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input
text into "atomic claims" and verify each against a knowledge base like
Wikipedia. These metrics are not suitable for most generation tasks because
they assume that every claim is verifiable (i.e., can plausibly be proven true
or false). We address this issue with VERISCORE, a metric for diverse long-form
generation tasks that contain both verifiable and unverifiable content.
VERISCORE can be effectively implemented with either closed or fine-tuned
open-weight language models, and human evaluation confirms that VERISCORE's
extracted claims are more sensible than those from competing methods across
eight different long-form tasks. We use VERISCORE to evaluate generations from
16 different models across multiple long-form tasks and find that while GPT-4o
is the best-performing model overall, open-weight models such as Mixtral-8x22
are closing the gap. We show that an LM's VERISCORE on one task (e.g.,
biography generation) does not necessarily correlate to its VERISCORE on a
different task (e.g., long-form QA), highlighting the need for expanding
factuality evaluation across tasks with varying fact density.

摘要：現有的長篇文字事實性評估指標，例如 FACTSCORE (Min 等人，2023) 和 SAFE (Wei 等人，2024)，將輸入文字分解成「原子性宣稱」，並根據知識庫（例如維基百科）驗證每個宣稱。這些指標並不適合大多數生成任務，因為它們假設每個宣稱都是可驗證的（即合理地被證明為真或假）。我們使用 VERISCORE 解決此問題，VERISCORE 是適用於包含可驗證和不可驗證內容的多元長篇生成任務的指標。VERISCORE 可以有效地使用封閉或微調的開放權重語言模型實作，而人工評估確認 VERISCORE 提取的宣稱比八種不同長篇任務中競爭方法提取的宣稱更合理。我們使用 VERISCORE 評估來自 16 個不同模型在多個長篇任務中的生成，並發現儘管 GPT-4o 整體表現最佳，但 Mixtral-8x22 等開放權重模型正在縮小差距。我們表明，語言模型在一個任務（例如傳記生成）上的 VERISCORE 並不一定與其在不同任務（例如長篇問答）上的 VERISCORE 相關，這突顯了在事實密度不同的任務中擴展事實性評估的必要性。

##### **AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning**
2406.19271v1 by Praneeth Vadlapati

Up-to-date and reliable Large Language Models (LLMs) are consistently sought
after. Typically, LLMs are trained on a fixed dataset and then deployed.
However, the training data continually becomes outdated. Enable automatic
training of AI using web data involves significant concerns regarding data
quality and safety due to bias, spam, and other unsafe or unwanted text. Pure
data is essential for producing reliable models. Training a model on impure
data may result in undesirable outcomes. This research proposes a system that
collects web data and automatically filters out unwanted text with the
assistance of existing trusted AI models. In the experiment, a small sample of
web data was collected and filtered, demonstrating the system's effectiveness
in purifying the data.

摘要：持續尋找最新且可靠的大語言模型 (LLM)。通常，LLM 會在固定資料集上進行訓練，然後部署。然而，訓練資料會持續過時。使用網路資料自動訓練 AI 會涉及到資料品質和安全性的重大疑慮，因為資料會有偏見、垃圾郵件和其他不安全或不需要的文字。純淨的資料對於建立可靠的模型至關重要。使用不純淨的資料訓練模型可能會導致不良的結果。本研究提出了一個系統，可以收集網路資料，並在現有可信賴 AI 模型的協助下自動過濾掉不需要的文字。在實驗中，收集並過濾了網路資料的小樣本，證明了系統在淨化資料方面的有效性。

##### **Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding**
2406.19263v1 by Yue Fan, Lei Ding, Ching-Chen Kuo, Shan Jiang, Yang Zhao, Xinze Guan, Jie Yang, Yi Zhang, Xin Eric Wang

Graphical User Interfaces (GUIs) are central to our interaction with digital
devices. Recently, growing efforts have been made to build models for various
GUI understanding tasks. However, these efforts largely overlook an important
GUI-referring task: screen reading based on user-indicated points, which we
name the Screen Point-and-Read (SPR) task. This task is predominantly handled
by rigid accessible screen reading tools, in great need of new models driven by
advancements in Multimodal Large Language Models (MLLMs). In this paper, we
propose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,
to address the SPR task. Based on the input point coordinate and the
corresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout
Tree. Based on the tree, our ToL agent not only comprehends the content of the
indicated area but also articulates the layout and spatial relationships
between elements. Such layout information is crucial for accurately
interpreting information on the screen, distinguishing our ToL agent from other
screen reading tools. We also thoroughly evaluate the ToL agent against other
baselines on a newly proposed SPR benchmark, which includes GUIs from mobile,
web, and operating systems. Last but not least, we test the ToL agent on mobile
GUI navigation tasks, demonstrating its utility in identifying incorrect
actions along the path of agent execution trajectories. Code and data:
screen-point-and-read.github.io

摘要：圖形使用者介面 (GUI) 是我們與數位裝置互動的核心。最近，建置各種 GUI 理解任務的模型已成為一股成長中的趨勢。然而，這些努力在很大程度上忽略了一個重要的 GUI 參考任務：根據使用者指示的點進行螢幕朗讀，我們將其命名為螢幕點選朗讀 (SPR) 任務。此任務主要由僵化的無障礙螢幕朗讀工具處理，迫切需要由多模態大型語言模型 (MLLM) 的進展驅動的新模型。在本文中，我們提出一個樹狀透鏡 (ToL) 代理，利用一種新的 ToL 接地機制來處理 SPR 任務。根據輸入點座標和對應的 GUI 螢幕截圖，我們的 ToL 代理建構一個階層式配置樹。根據此樹，我們的 ToL 代理不僅理解指示區域的內容，還能清晰表達元素之間的配置和空間關係。此類配置資訊對於精準詮釋螢幕上的資訊至關重要，這使我們的 ToL 代理區別於其他螢幕朗讀工具。我們也徹底評估了 ToL 代理與其他基準在一個新提出的 SPR 評量基準上的表現，其中包含來自行動裝置、網頁和作業系統的 GUI。最後但並非最不重要的是，我們在行動裝置 GUI 導航任務中測試 ToL 代理，展示了其在識別代理執行軌跡路徑中不正確動作的效用。程式碼和資料：screen-point-and-read.github.io

##### **AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI**
2406.19256v1 by Kaveen Hiniduma, Suren Byna, Jean Luca Bez, Ravi Madduri

"Garbage In Garbage Out" is a universally agreed quote by computer scientists
from various domains, including Artificial Intelligence (AI). As data is the
fuel for AI, models trained on low-quality, biased data are often ineffective.
Computer scientists who use AI invest a considerable amount of time and effort
in preparing the data for AI. However, there are no standard methods or
frameworks for assessing the "readiness" of data for AI. To provide a
quantifiable assessment of the readiness of data for AI processes, we define
parameters of AI data readiness and introduce AIDRIN (AI Data Readiness
Inspector). AIDRIN is a framework covering a broad range of readiness
dimensions available in the literature that aid in evaluating the readiness of
data quantitatively and qualitatively. AIDRIN uses metrics in traditional data
quality assessment such as completeness, outliers, and duplicates for data
evaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,
such as feature importance, feature correlations, class imbalance, fairness,
privacy, and FAIR (Findability, Accessibility, Interoperability, and
Reusability) principle compliance. AIDRIN provides visualizations and reports
to assist data scientists in further investigating the readiness of data. The
AIDRIN framework enhances the efficiency of the machine learning pipeline to
make informed decisions on data readiness for AI applications.

摘要：「垃圾進，垃圾出」是各個領域的電腦科學家，包括人工智慧 (AI) 的普遍共識。由於資料是 AI 的燃料，因此使用品質低落、有偏差的資料訓練的模型通常沒有效率。使用 AI 的電腦科學家會花費大量時間和精力來準備 AI 的資料。然而，目前沒有標準的方法或架構來評估資料對 AI 的「準備度」。為了提供可量化的評估，說明資料對 AI 程序的準備度，我們定義 AI 資料準備度的參數，並導入 AIDRIN（AI 資料準備度檢查器）。AIDRIN 是涵蓋廣泛準備度面向的架構，可用於評估資料的準備度，無論是量化或質化。AIDRIN 使用傳統資料品質評估中的指標，例如完整性、異常值和重複值來評估資料。此外，AIDRIN 使用特定於評估 AI 資料的指標，例如特徵重要性、特徵相關性、類別失衡、公平性、隱私和 FAIR（可尋找性、可存取性、互操作性和可重複使用性）原則合規性。AIDRIN 提供視覺化和報告，以協助資料科學家進一步調查資料的準備度。AIDRIN 架構提升機器學習管線的效率，以便針對 AI 應用程式的資料準備度做出明智的決策。

##### **Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**
2406.19255v1 by Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan

While pre-training large-scale video-language models (VLMs) has shown
remarkable potential for various downstream video-language tasks, existing VLMs
can still suffer from certain commonly seen limitations, e.g., coarse-grained
cross-modal aligning , under-modeling of temporal dynamics, detached
video-language view. In this work, we target enhancing VLMs with a fine-grained
structural spatio-temporal alignment learning method (namely Finsta). First of
all, we represent the input texts and videos with fine-grained scene graph (SG)
structures, both of which are further unified into a holistic SG (HSG) for
bridging two modalities. Then, an SG-based framework is built, where the
textual SG (TSG) is encoded with a graph Transformer, while the video dynamic
SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for
spatial and temporal feature propagation. A spatial-temporal Gaussian
differential graph Transformer is further devised to strengthen the sense of
the changes in objects across spatial and temporal dimensions. Next, based on
the fine-grained structural features of TSG and DSG, we perform object-centered
spatial alignment and predicate-centered temporal alignment respectively,
enhancing the video-language grounding in both the spatiality and temporality.
We design our method as a plug&play system, which can be integrated into
existing well-trained VLMs for further representation augmentation, without
training from scratch or relying on SG annotations in downstream applications.
On 6 representative VL modeling tasks over 12 datasets in both standard and
long-form video scenarios, Finsta consistently improves the existing 13
strong-performing VLMs persistently, and refreshes the current state-of-the-art
end task performance significantly in both the fine-tuning and zero-shot
settings.

摘要：<paragraph>雖然預訓練大型視訊語言模型 (VLM) 已展現出對各種下游視訊語言任務的顯著潛力，但現有的 VLM 仍可能受到某些常見限制的影響，例如粗粒度的跨模態對齊、對時間動態的建模不足、分離的視訊語言檢視。在這項工作中，我們以具備細粒度結構化時空對齊學習方法 (即 Finsta) 的增強 VLM 為目標。首先，我們以細粒度的場景圖 (SG) 結構表示輸入文字和視訊，兩者進一步統一到一個整體 SG (HSG) 中，以橋接兩個模態。然後，建立一個基於 SG 的框架，其中文字 SG (TSG) 使用圖形 Transformer 編碼，而視訊動態 SG (DSG) 和 HSG 則使用新穎的遞迴圖形 Transformer 建模，以進行空間和時間特徵傳播。進一步設計了一個時空高斯差分圖形 Transformer，以增強物體在時空維度中變化的感覺。接下來，根據 TSG 和 DSG 的細粒度結構特徵，我們分別執行以物件為中心的空間對齊和以謂詞為中心的時序對齊，增強視訊語言在空間和時間上的基礎。我們將方法設計為一個即插即用的系統，可以整合到現有的訓練良好的 VLM 中，以進一步擴充表示，而無需從頭開始訓練或依賴下游應用程式中的 SG 標註。在 12 個資料集上的 6 個代表性 VL 建模任務中，無論是在標準視訊場景還是長格式視訊場景中，Finsta 都持續改善現有的 13 個效能強大的 VLM，並在微調和零次學習設定中顯著更新目前的最新技術最終任務效能。</paragraph>

##### **AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation**
2406.19251v1 by Jia Fu, Xiaoting Qin, Fangkai Yang, Lu Wang, Jue Zhang, Qingwei Lin, Yubo Chen, Dongmei Zhang, Saravan Rajmohan, Qi Zhang

Recent advancements in Large Language Models have transformed ML/AI
development, necessitating a reevaluation of AutoML principles for the
Retrieval-Augmented Generation (RAG) systems. To address the challenges of
hyper-parameter optimization and online adaptation in RAG, we propose the
AutoRAG-HP framework, which formulates the hyper-parameter tuning as an online
multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical
MAB (Hier-MAB) method for efficient exploration of large search spaces. We
conduct extensive experiments on tuning hyper-parameters, such as top-k
retrieved documents, prompt compression ratio, and embedding methods, using the
ALCE-ASQA and Natural Questions datasets. Our evaluation from jointly
optimization all three hyper-parameters demonstrate that MAB-based online
learning methods can achieve Recall@5 $\approx 0.8$ for scenarios with
prominent gradients in search space, using only $\sim20\%$ of the LLM API calls
required by the Grid Search approach. Additionally, the proposed Hier-MAB
approach outperforms other baselines in more challenging optimization
scenarios. The code will be made available at https://aka.ms/autorag.

摘要：大型語言模型的最新進展已轉變 ML/AI 的開發，這使得必須重新評估用於檢索增強生成 (RAG) 系統的 AutoML 原則。為了應對 RAG 中的超參數最佳化和線上調整挑戰，我們提出了 AutoRAG-HP 架構，它將超參數調整制定為一個線上多重選擇賭博機 (MAB) 問題，並引入了一種新穎的兩層階層式 MAB (Hier-MAB) 方法，用於有效地探索大型搜尋空間。我們對超參數調整進行了廣泛的實驗，例如前 k 名檢索的文件、提示壓縮率和嵌入方法，使用 ALCE-ASQA 和自然問題資料集。我們從聯合最佳化所有三個超參數的評估中證明，基於 MAB 的線上學習方法可以針對搜尋空間中具有顯著梯度的場景實現 Recall@5 $\approx 0.8$，僅使用網格搜尋方法所需的 LLM API 呼叫的 $\sim20\%$。此外，提出的 Hier-MAB 方法在更具挑戰性的最佳化場景中優於其他基準。程式碼將於 https://aka.ms/autorag 上提供。

##### **Application of ASV for Voice Identification after VC and Duration Predictor Improvement in TTS Models**
2406.19243v1 by Borodin Kirill Nikolayevich, Kudryavtsev Vasiliy Dmitrievich, Mkrtchian Grach Maratovich, Gorodnichev Mikhail Genadievich, Korzh Dmitrii Sergeevich

One of the most crucial components in the field of biometric security is the
automatic speaker verification system, which is based on the speaker's voice.
It is possible to utilise ASVs in isolation or in conjunction with other AI
models. In the contemporary era, the quality and quantity of neural networks
are increasing exponentially. Concurrently, there is a growing number of
systems that aim to manipulate data through the use of voice conversion and
text-to-speech models. The field of voice biometrics forgery is aided by a
number of challenges, including SSTC, ASVSpoof, and SingFake.
  This paper presents a system for automatic speaker verification. The primary
objective of our model is the extraction of embeddings from the target
speaker's audio in order to obtain information about important characteristics
of his voice, such as pitch, energy, and the duration of phonemes. This
information is used in our multivoice TTS pipeline, which is currently under
development. However, this model was employed within the SSTC challenge to
verify users whose voice had undergone voice conversion, where it demonstrated
an EER of 20.669.

摘要：生物特徵安全領域中最重要的組成部分之一是自動語音驗證系統，其基礎是說話者的聲音。
可以單獨使用 ASV，也可以與其他 AI 模型結合使用。在當代，神經網路的品質和數量正呈指數級增長。同時，越來越多系統旨在透過使用語音轉換和文字轉語音模型來操縱資料。語音生物特徵偽造領域受到許多挑戰的幫助，包括 SSTC、ASVSpoof 和 SingFake。
本文提出了一個自動語音驗證系統。我們模型的主要目標是從目標說話者的音訊中萃取嵌入，以取得其聲音中重要特徵的資訊，例如音高、能量和音素的持續時間。此資訊用於我們目前正在開發的多語音 TTS 管線中。然而，此模型在 SSTC 挑戰中用於驗證聲音經過語音轉換的使用者，其 EER 為 20.669。

##### **Revealing Fine-Grained Values and Opinions in Large Language Models**
2406.19238v1 by Dustin Wright, Arnav Arora, Nadav Borenstein, Srishti Yadav, Serge Belongie, Isabelle Augenstein

Uncovering latent values and opinions in large language models (LLMs) can
help identify biases and mitigate potential harm. Recently, this has been
approached by presenting LLMs with survey questions and quantifying their
stances towards morally and politically charged statements. However, the
stances generated by LLMs can vary greatly depending on how they are prompted,
and there are many ways to argue for or against a given position. In this work,
we propose to address this by analysing a large and robust dataset of 156k LLM
responses to the 62 propositions of the Political Compass Test (PCT) generated
by 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of
their generated stances and fine-grained analysis of the plain text
justifications for those stances. For fine-grained analysis, we propose to
identify tropes in the responses: semantically similar phrases that are
recurrent and consistent across different prompts, revealing patterns in the
text that a given LLM is prone to produce. We find that demographic features
added to prompts significantly affect outcomes on the PCT, reflecting bias, as
well as disparities between the results of tests when eliciting closed-form vs.
open domain responses. Additionally, patterns in the plain text rationales via
tropes show that similar justifications are repeatedly generated across models
and prompts even with disparate stances.

摘要：揭露大型語言模型 (LLM) 中的潛在價值觀和觀點有助於識別偏見並減輕潛在危害。最近，這已透過向 LLM 提出調查問題並量化它們對道德和政治敏感陳述的立場來實現。然而，LLM 產生的立場可能會根據提示方式而有很大不同，而且有很多方法可以為特定立場辯護或反對。在這項工作中，我們建議透過分析 6 個 LLM 使用 420 個提示變體產生的政治羅盤測試 (PCT) 的 62 個命題的 156k 個 LLM 回應的大型而穩健的資料集來解決這個問題。我們對它們產生的立場進行粗略分析，並對這些立場的純文字論證進行細緻分析。對於細緻分析，我們建議在回應中找出比喻：在不同的提示中重複出現且一致的語義相似片語，揭示給定 LLM 容易產生的文字模式。我們發現加入提示的人口特徵會顯著影響 PCT 的結果，反映出偏見，以及在引發封閉式與開放式領域回應時測試結果之間的差異。此外，透過比喻在純文字論證中的模式顯示，即使立場不同，類似的論證也會在模型和提示中重複產生。

##### **FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts**
2406.19237v2 by Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth

Existing benchmarks for visual question answering lack in visual grounding
and complexity, particularly in evaluating spatial reasoning skills. We
introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of
visual question-answering multimodal language models in reasoning with
flowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and
human-verified flowchart images from three distinct content sources, along with
22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,
including information localization, decision-making, and logical progression.
We conduct a thorough baseline evaluation on a suite of both open-source and
proprietary multimodal language models using various strategies, followed by an
analysis of directional bias. The results underscore the benchmark's potential
as a vital tool for advancing the field of multimodal modeling, providing a
focused and challenging environment for enhancing model performance in visual
and logical reasoning tasks.

摘要：現有的視覺問答基準在視覺基礎和複雜性方面有所欠缺，特別是在評估空間推理技能方面。我們引入了 FlowVQA，一個新的基準，旨在評估視覺問答多模態語言模型在以流程圖作為視覺內容進行推理的能力。FlowVQA 包含 2,272 個仔細生成並由人類驗證的流程圖影像，來自三個不同的內容來源，以及 22,413 個不同的問題解答配對，用於測試一系列推理任務，包括資訊定位、決策制定和邏輯進程。我們對一系列開源和專有多模態語言模型進行了徹底的基準評估，使用了各種策略，然後分析了方向偏差。結果強調了基準作為推進多模態建模領域的重要工具的潛力，為增強模型在視覺和邏輯推理任務中的效能提供了一個專注且具有挑戰性的環境。

##### **Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions**
2406.19236v1 by Minghan Li, Heng Li, Zhi-Qi Cheng, Yifei Dong, Yuxuan Zhou, Jun-Yan He, Qi Dai, Teruko Mitamura, Alexander G. Hauptmann

Vision-and-Language Navigation (VLN) aims to develop embodied agents that
navigate based on human instructions. However, current VLN frameworks often
rely on static environments and optimal expert supervision, limiting their
real-world applicability. To address this, we introduce Human-Aware
Vision-and-Language Navigation (HA-VLN), extending traditional VLN by
incorporating dynamic human activities and relaxing key assumptions. We propose
the Human-Aware 3D (HA3D) simulator, which combines dynamic human activities
with the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)
dataset, extending R2R with human activity descriptions. To tackle HA-VLN
challenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and
Non-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing
cross-modal fusion and diverse training strategies for effective navigation in
dynamic human environments. A comprehensive evaluation, including metrics
considering human activities, and systematic analysis of HA-VLN's unique
challenges, underscores the need for further research to enhance HA-VLN agents'
real-world robustness and adaptability. Ultimately, this work provides
benchmarks and insights for future research on embodied AI and Sim2Real
transfer, paving the way for more realistic and applicable VLN systems in
human-populated environments.

摘要：視覺語言導航 (VLN) 的目標是開發具備根據人類指示導航功能的具身代理。然而，目前的 VLN 架構通常依賴於靜態環境和最佳專家監督，限制了它們在現實世界中的適用性。為了解決這個問題，我們引入了具有人類意識的視覺語言導航 (HA-VLN)，透過納入動態人類活動和放寬關鍵假設來擴展傳統 VLN。我們提出了具有人類意識的 3D (HA3D) 模擬器，它將動態人類活動與 Matterport3D 資料集結合在一起，以及具有人類意識的房間到房間 (HA-R2R) 資料集，將 R2R 擴展到人類活動描述。為了應對 HA-VLN 挑戰，我們提出了專家監督跨模態 (VLN-CM) 和非專家監督決策轉換器 (VLN-DT) 代理，利用跨模態融合和多樣化的訓練策略在動態人類環境中進行有效的導航。全面的評估，包括考慮人類活動的指標，以及對 HA-VLN 獨特挑戰的系統分析，強調了進一步研究以增強 HA-VLN 代理在現實世界中的穩健性和適應性的必要性。最終，這項工作為具身 AI 和 Sim2Real 傳輸的未來研究提供了基準和見解，為在有人類居住的環境中更逼真且適用的 VLN 系統鋪平了道路。

##### **Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation**
2406.19234v1 by Yuying Li, Gaoyang Liu, Yang Yang, Chen Wang

Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that
enhances Large Language Models (LLMs) by retrieving relevant knowledge from an
external, non-parametric database. This approach aims to mitigate common LLM
issues such as hallucinations and outdated knowledge. Although existing
research has demonstrated security and privacy vulnerabilities within RAG
systems, making them susceptible to attacks like jailbreaks and prompt
injections, the security of the RAG system's external databases remains largely
underexplored. In this paper, we employ Membership Inference Attacks (MIA) to
determine whether a sample is part of the knowledge database of a RAG system,
using only black-box API access. Our core hypothesis posits that if a sample is
a member, it will exhibit significant similarity to the text generated by the
RAG system. To test this, we compute the cosine similarity and the model's
perplexity to establish a membership score, thereby building robust features.
We then introduce two novel attack strategies: a Threshold-based Attack and a
Machine Learning-based Attack, designed to accurately identify membership.
Experimental validation of our methods has achieved a ROC AUC of 82%.

摘要：檢索增強生成（RAG）是一種先進技術，它透過從外部的非參數資料庫中檢索相關知識，來增強大型語言模型（LLM）。此方法旨在減輕常見的 LLM 問題，例如幻覺和過時的知識。儘管現有的研究已證明 RAG 系統存在安全性和隱私漏洞，使其容易受到越獄和提示注入等攻擊，但 RAG 系統外部資料庫的安全性在很大程度上仍未得到探索。在本文中，我們採用成員推論攻擊（MIA）來確定範例是否為 RAG 系統知識資料庫的一部分，僅使用黑盒 API 存取。我們的核心假設是，如果範例是成員，它將與 RAG 系統產生的文字有顯著的相似性。為了測試這一點，我們計算餘弦相似性和模型的困惑度，以建立成員分數，從而建立健全的特徵。然後，我們介紹兩種新穎的攻擊策略：基於閾值的攻擊和基於機器學習的攻擊，旨在準確識別成員。我們的方法的實驗驗證已達到 82% 的 ROC AUC。

##### **RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs**
2406.19232v2 by Ekaterina Taktasheva, Maxim Bazhukov, Kirill Koncha, Alena Fenogenova, Ekaterina Artemova, Vladislav Mikhailov

Minimal pairs are a well-established approach to evaluating the grammatical
knowledge of language models. However, existing resources for minimal pairs
address a limited number of languages and lack diversity of language-specific
grammatical phenomena. This paper introduces the Russian Benchmark of
Linguistic Minimal Pairs (RuBLiMP), which includes 45k pairs of sentences that
differ in grammaticality and isolate a morphological, syntactic, or semantic
phenomenon. In contrast to existing benchmarks of linguistic minimal pairs,
RuBLiMP is created by applying linguistic perturbations to automatically
annotated sentences from open text corpora and carefully curating test data. We
describe the data collection protocol and present the results of evaluating 25
language models in various scenarios. We find that the widely used language
models for Russian are sensitive to morphological and agreement-oriented
contrasts but fall behind humans on phenomena requiring understanding of
structural relations, negation, transitivity, and tense. RuBLiMP, the codebase,
and other materials are publicly available.

摘要：最小對是評估語言模型語法知識的既定方法。然而，現有的最小對資源僅針對有限的語言，且缺乏語言特定語法現象的多樣性。本文介紹了俄語語言最小對基準 (RuBLiMP)，其中包含 45k 對語法性不同的句子，並孤立了形態、句法或語義現象。與現有的語言最小對基準不同，RuBLiMP 是通過對來自開放文本語料庫的自動標註句子應用語言擾動並仔細策劃測試數據而創建的。我們描述了數據收集協議，並展示了在各種場景中評估 25 個語言模型的結果。我們發現，廣泛使用的俄語語言模型對形態和一致性導向的對比很敏感，但在需要理解結構關係、否定、及物性和時態的現象方面落後於人類。RuBLiMP、代碼庫和其他材料已公開。

##### **Spiking Convolutional Neural Networks for Text Classification**
2406.19230v1 by Changze Lv, Jianhan Xu, Xiaoqing Zheng

Spiking neural networks (SNNs) offer a promising pathway to implement deep
neural networks (DNNs) in a more energy-efficient manner since their neurons
are sparsely activated and inferences are event-driven. However, there have
been very few works that have demonstrated the efficacy of SNNs in language
tasks partially because it is non-trivial to represent words in the forms of
spikes and to deal with variable-length texts by SNNs. This work presents a
"conversion + fine-tuning" two-step method for training SNNs for text
classification and proposes a simple but effective way to encode pre-trained
word embeddings as spike trains. We show empirically that after fine-tuning
with surrogate gradients, the converted SNNs achieve comparable results to
their DNN counterparts with much less energy consumption across multiple
datasets for both English and Chinese. We also show that such SNNs are more
robust to adversarial attacks than DNNs.

摘要：脈衝神經網路 (SNN) 提供了一種以更節能的方式實作深度神經網路 (DNN) 的有前途途徑，因為它們的神經元是稀疏啟動的，而且推論是事件驅動的。然而，很少有研究證明 SNN 在語言任務中的效力，部分原因是將字詞表示成脈衝形式並處理 SNN 的可變長度文字並非易事。這項工作提出了一個「轉換 + 微調」兩步驟方法，用於訓練 SNN 以進行文字分類，並提出了一個簡單但有效的方法，將預先訓練好的字詞嵌入編碼為脈衝序列。我們透過實證顯示，在使用代理梯度微調後，轉換後的 SNN 在多個英中文資料集上都能達到與其 DNN 對應項相當的結果，而且能耗更低。我們也顯示出，此類 SNN 比 DNN 更能抵抗對抗性攻擊。

##### **Tools Fail: Detecting Silent Errors in Faulty Tools**
2406.19228v1 by Jimin Sun, So Yeon Min, Yingshan Chang, Yonatan Bisk

Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not
in their weights, to perform tasks on the web, and even to control robots.
However, most ontologies and surveys of tool-use have assumed the core
challenge for LLMs is choosing the tool. Instead, we introduce a framework for
tools more broadly which guides us to explore a model's ability to detect
"silent" tool errors, and reflect on how to plan. This more directly aligns
with the increasingly popular use of models as tools. We provide an initial
approach to failure recovery with promising results both on a controlled
calculator setting and embodied agent planning.

摘要：工具已成為大型語言模型的支柱，讓它們能夠擷取權重中沒有的知識，在網路中執行任務，甚至控制機器人。
然而，大多數關於工具使用的本體論和調查都假設大型語言模型的核心挑戰在於選擇工具。相反，我們為更廣泛的工具引入一個架構，引導我們探索模型偵測「靜默」工具錯誤的能力，並思考如何規劃。這更直接地符合模型作為工具日益普及的使用方式。我們提供了一種故障復原的初步方法，在受控計算器設定和具體代理規劃中都獲得了有希望的結果。

##### **Aligning Teacher with Student Preferences for Tailored Training Data Generation**
2406.19227v1 by Yantao Liu, Zhao Zhang, Zijun Yao, Shulin Cao, Lei Hou, Juanzi Li

Large Language Models (LLMs) have shown significant promise as copilots in
various tasks. Local deployment of LLMs on edge devices is necessary when
handling privacy-sensitive data or latency-sensitive tasks. The computational
constraints of such devices make direct deployment of powerful large-scale LLMs
impractical, necessitating the Knowledge Distillation from large-scale models
to lightweight models. Lots of work has been done to elicit diversity and
quality training examples from LLMs, but little attention has been paid to
aligning teacher instructional content based on student preferences, akin to
"responsive teaching" in pedagogy. Thus, we propose ARTE, dubbed Aligning
TeacheR with StudenT PreferencEs, a framework that aligns the teacher model
with student preferences to generate tailored training examples for Knowledge
Distillation. Specifically, we elicit draft questions and rationales from the
teacher model, then collect student preferences on these questions and
rationales using students' performance with in-context learning as a proxy, and
finally align the teacher model with student preferences. In the end, we repeat
the first step with the aligned teacher model to elicit tailored training
examples for the student model on the target task. Extensive experiments on
academic benchmarks demonstrate the superiority of ARTE over existing
instruction-tuning datasets distilled from powerful LLMs. Moreover, we
thoroughly investigate the generalization of ARTE, including the generalization
of fine-tuned student models in reasoning ability and the generalization of
aligned teacher models to generate tailored training data across tasks and
students. In summary, our contributions lie in proposing a novel framework for
tailored training example generation, demonstrating its efficacy in
experiments, and investigating the generalization of both student & aligned
teacher models in ARTE.

摘要：大型語言模型 (LLM) 已在擔任各種任務的副駕駛方面展現出顯著的潛力。在處理隱私敏感資料或延遲敏感任務時，必須在邊緣設備上部署 LLM。此類設備的運算限制使得直接部署強大的大型 LLM 變得不切實際，因此必須將大規模模型的知識蒸餾到輕量級模型。已經做了大量工作來引發 LLM 的多樣性和高品質訓練範例，但很少有人關注根據學生的偏好來調整老師的教學內容，這類似於教學法中的「反應式教學」。因此，我們提出了 ARTE，稱為 Aligning TeacheR with StudenT PreferencEs，這是一個框架，它將教師模型與學生的偏好相結合，為知識蒸餾產生量身打造的訓練範例。具體來說，我們從教師模型中引發出草稿問題和依據，然後使用學生的表現作為情境學習的代理，收集學生對這些問題和依據的偏好，最後將教師模型與學生的偏好相結合。最後，我們使用結合的教師模型重複第一步，為目標任務上的學生模型引發量身打造的訓練範例。在學術基準上的廣泛實驗證明了 ARTE 優於從強大的 LLM 中提取的現有教學調整資料集。此外，我們徹底研究了 ARTE 的概括化，包括微調學生模型在推理能力中的概括化，以及結合的教師模型在跨任務和學生中產生量身打造的訓練資料的概括化。總之，我們的貢獻在於提出一個用於量身打造訓練範例生成的新穎框架，在實驗中展示其功效，並研究 ARTE 中學生和結合教師模型的概括化。

##### **Simulating Classroom Education with LLM-Empowered Agents**
2406.19226v1 by Zheyuan Zhang, Daniel Zhang-Li, Jifan Yu, Linlu Gong, Jinchang Zhou, Zhiyuan Liu, Lei Hou, Juanzi Li

Large language models (LLMs) have been employed in various intelligent
educational tasks to assist teaching. While preliminary explorations have
focused on independent LLM-empowered agents for specific educational tasks, the
potential for LLMs within a multi-agent collaborative framework to simulate a
classroom with real user participation remains unexplored. In this work, we
propose SimClass, a multi-agent classroom simulation framework involving user
participation. We recognize representative class roles and introduce a novel
class control mechanism for automatic classroom teaching, and conduct user
experiments in two real-world courses. Utilizing the Flanders Interactive
Analysis System and Community of Inquiry theoretical frame works from
educational analysis, we demonstrate that LLMs can simulate traditional
classroom interaction patterns effectively while enhancing user's experience.
We also observe emergent group behaviors among agents in SimClass, where agents
collaborate to create enlivening interactions in classrooms to improve user
learning process. We hope this work pioneers the application of LLM-empowered
multi-agent systems in virtual classroom teaching.

摘要：大型語言模型 (LLM) 已被用於各種智能教育任務，以協助教學。雖然初步探索已專注於針對特定教育任務的獨立 LLM 賦能代理，但 LLM 在多代理協作架構中模擬具有真實使用者參與的教室的潛力仍未被探索。在這項工作中，我們提出 SimClass，一個涉及使用者參與的多代理教室模擬框架。我們識別出具代表性的課程角色，並引入一種新穎的課程控制機制用於自動化教室教學，並在兩個真實世界的課程中進行使用者實驗。利用教育分析中的 Flanders 互動分析系統和探究社群理論架構，我們證明 LLM 可以有效模擬傳統的教室互動模式，同時增強使用者的體驗。我們還觀察到 SimClass 中代理之間出現群體行為，代理會協作在教室中創造熱絡的互動，以改善使用者的學習過程。我們希望這項工作開創了 LLM 賦能的多代理系統在虛擬教室教學中的應用。

##### **T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings**
2406.19223v1 by Björn Deiseroth, Manuel Brack, Patrick Schramowski, Kristian Kersting, Samuel Weinbach

Tokenizers are crucial for encoding information in Large Language Models, but
their development has recently stagnated, and they contain inherent weaknesses.
Major limitations include computational overhead, ineffective vocabulary use,
and unnecessarily large embedding and head layers. Additionally, their
performance is biased towards a reference corpus, leading to reduced
effectiveness for underrepresented languages.
  To remedy these issues, we propose T-FREE, which directly embeds words
through sparse activation patterns over character triplets, and does not
require a reference corpus. T-FREE inherently exploits morphological
similarities and allows for strong compression of embedding layers. In our
exhaustive experimental evaluation, we achieve competitive downstream
performance with a parameter reduction of more than 85% on these layers.
Further, T-FREE shows significant improvements in cross-lingual transfer
learning.

摘要：分詞器對於在大型語言模型中編碼資訊至關重要，但它們的發展最近停滯不前，且存在固有的弱點。主要限制包括計算開銷、無效的詞彙使用，以及不必要的龐大嵌入和頭部層。此外，它們的效能偏向參考語料庫，導致對未充分表示的語言的效能降低。為了補救這些問題，我們提出了 T-FREE，它透過字元三元組上的稀疏激活模式直接嵌入字詞，且不需要參考語料庫。T-FREE 固有地利用了形態相似性，並允許對嵌入層進行強大的壓縮。在我們詳盡的實驗評估中，我們在這些層上實現了具有競爭力的下游效能，同時參數減少了 85% 以上。此外，T-FREE 在跨語言傳輸學習中顯示出顯著的改進。

##### **Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos**
2406.19217v1 by Zhimin Shao, Jialang Xu, Danail Stoyanov, Evangelos B. Mazomenos, Yueming Jin

Despite significant advancements in robotic systems and surgical data
science, ensuring safe and optimal execution in robot-assisted minimally
invasive surgery (RMIS) remains a complex challenge. Current surgical error
detection methods involve two parts: identifying surgical gestures and then
detecting errors within each gesture clip. These methods seldom consider the
rich contextual and semantic information inherent in surgical videos, limiting
their performance due to reliance on accurate gesture identification. Motivated
by the chain-of-thought prompting in natural language processing, this letter
presents a novel and real-time end-to-end error detection framework,
Chain-of-Thought (COG) prompting, leveraging contextual information from
surgical videos. This encompasses two reasoning modules designed to mimic the
decision-making processes of expert surgeons. Concretely, we first design a
Gestural-Visual Reasoning module, which utilizes transformer and attention
architectures for gesture prompting, while the second, a Multi-Scale Temporal
Reasoning module, employs a multi-stage temporal convolutional network with
both slow and fast paths for temporal information extraction. We extensively
validate our method on the public benchmark RMIS dataset JIGSAWS. Our method
encapsulates the reasoning processes inherent to surgical activities enabling
it to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,
and 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on
average, demonstrating the great potential of our approach in enhancing the
safety and efficacy of RMIS procedures and surgical education. The code will be
available.

摘要：儘管機器人系統和手術數據科學有顯著的進展，確保機器人輔助微創手術 (RMIS) 的安全和最佳執行仍然是一項複雜的挑戰。目前的術中錯誤偵測方法包含兩個部分：識別手術手勢，然後在每個手勢片段中偵測錯誤。這些方法很少考慮手術影片中固有的豐富情境和語意資訊，由於依賴於準確的手勢識別，因此限制了它們的效能。受自然語言處理中思想鏈提示的啟發，本信件提出了一個新穎且即時的端到端錯誤偵測架構，思想鏈 (COG) 提示，利用手術影片中的情境資訊。這包含兩個推理模組，旨在模擬專家外科醫生的決策過程。具體來說，我們首先設計了一個手勢視覺推理模組，它利用Transformer和注意力架構進行手勢提示，而第二個多尺度時間推理模組採用具有慢速和快速路徑的多階段時間卷積網路進行時間資訊萃取。我們廣泛驗證了我們的方法在公開基準 RMIS 資料集 JIGSAWS 上的效能。我們的模型概括了手術活動中固有的推理過程，使其在 F1 分數上優於最先進技術 4.6%，在準確度上優於 4.6%，在 Jaccard 指數上優於 5.9%，同時平均在 6.69 毫秒內處理每個影格，證明了我們的方法在提升 RMIS 程序和手術教育的安全性和有效性方面具有巨大的潛力。程式碼將會提供。

##### **SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation**
2406.19215v1 by Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, Juanzi Li

This paper introduces Self-aware Knowledge Retrieval (SeaKR), a novel
adaptive RAG model that extracts self-aware uncertainty of LLMs from their
internal states. SeaKR activates retrieval when the LLMs present high
self-aware uncertainty for generation. To effectively integrate retrieved
knowledge snippets, SeaKR re-ranks them based on LLM's self-aware uncertainty
to preserve the snippet that reduces their uncertainty to the utmost. To
facilitate solving complex tasks that require multiple retrievals, SeaKR
utilizes their self-aware uncertainty to choose among different reasoning
strategies. Our experiments on both complex and simple Question Answering
datasets show that SeaKR outperforms existing adaptive RAG methods. We release
our code at https://github.com/THU-KEG/SeaKR.

摘要：本文介紹了自我感知知識檢索 (SeaKR)，這是一種新穎的自適應 RAG 模型，它從大型語言模型 (LLM) 的內部狀態中提取自我感知的不確定性。當 LLM 呈現出高自我感知的不確定性時，SeaKR 會啟動檢索以進行生成。為了有效整合檢索到的知識片段，SeaKR 會根據 LLM 的自我感知不確定性對它們進行重新排序，以保留最大程度降低其不確定性的片段。為了促進解決需要多重檢索的複雜任務，SeaKR 會利用其自我感知的不確定性在不同的推理策略中進行選擇。我們在複雜和簡單的問答資料集上的實驗表明，SeaKR 優於現有的自適應 RAG 方法。我們在 https://github.com/THU-KEG/SeaKR/ 上發布了我們的程式碼。

##### **BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring**
2406.19189v1 by Luca Benfenati, Thorir Mar Ingolfsson, Andrea Cossettini, Daniele Jahier Pagliari, Alessio Burrello, Luca Benini

This study presents a novel approach for EEG-based seizure detection
leveraging a BERT-based model. The model, BENDR, undergoes a two-phase training
process. Initially, it is pre-trained on the extensive Temple University
Hospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects,
to extract common EEG data patterns. Subsequently, the model is fine-tuned on
the CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24
pediatric patients, of which 198 contain seizure events. Key contributions
include optimizing fine-tuning on the CHB-MIT dataset, where the impact of
model architecture, pre-processing, and post-processing techniques are
thoroughly examined to enhance sensitivity and reduce false positives per hour
(FP/h). We also explored custom training strategies to ascertain the most
effective setup. The model undergoes a novel second pre-training phase before
subject-specific fine-tuning, enhancing its generalization capabilities. The
optimized model demonstrates substantial performance enhancements, achieving as
low as 0.23 FP/h, 2.5$\times$ lower than the baseline model, with a lower but
still acceptable sensitivity rate, showcasing the effectiveness of applying a
BERT-based approach on EEG-based seizure detection.

摘要：本研究提出了一種新的基於 EEG 的癲癇檢測方法，利用基於 BERT 的模型。該模型 BENDR 經歷了兩個階段的訓練過程。最初，它在 Temple University Hospital EEG Corpus (TUEG) 上進行預訓練，TUEG 是一個包含 10,000 多個受試者的 1.5 TB 數據集，用於提取常見的 EEG 數據模式。隨後，該模型在 CHB-MIT 頭皮 EEG 數據庫上進行微調，該數據庫包含來自 24 名兒童患者的 664 個 EEG 記錄，其中 198 個包含癲癇發作事件。主要貢獻包括優化 CHB-MIT 數據集上的微調，其中徹底檢查了模型架構、預處理和後處理技術的影響，以提高靈敏度並降低每小時誤報 (FP/h)。我們還探索了自定義訓練策略，以確定最有效的設置。該模型在特定於受試者的微調之前經歷了一個新穎的第二預訓練階段，增強了其泛化能力。優化的模型展示了顯著的性能提升，實現了低至 0.23 FP/h，比基線模型低 2.5 倍，靈敏度率較低但仍可接受，展示了在基於 EEG 的癲癇檢測中應用基於 BERT 的方法的有效性。

##### **Annotation Errors and NER: A Study with OntoNotes 5.0**
2406.19172v1 by Gabriel Bernier-Colborne, Sowmya Vajjala

Named Entity Recognition (NER) is a well-studied problem in NLP. However,
there is much less focus on studying NER datasets, compared to developing new
NER models. In this paper, we employed three simple techniques to detect
annotation errors in the OntoNotes 5.0 corpus for English NER, which is the
largest available NER corpus for English. Our techniques corrected ~10% of the
sentences in train/dev/test data. In terms of entity mentions, we corrected the
span and/or type of ~8% of mentions in the dataset, while
adding/deleting/splitting/merging a few more. These are large numbers of
changes, considering the size of OntoNotes. We used three NER libraries to
train, evaluate and compare the models trained with the original and the
re-annotated datasets, which showed an average improvement of 1.23% in overall
F-scores, with large (>10%) improvements for some of the entity types. While
our annotation error detection methods are not exhaustive and there is some
manual annotation effort involved, they are largely language agnostic and can
be employed with other NER datasets, and other sequence labelling tasks.

摘要：命名實體辨識 (NER) 是自然語言處理 (NLP) 中一個研究透徹的問題。然而，與開發新的 NER 模型相比，對 NER 資料集的研究較少。在本文中，我們採用了三種簡單的技術來偵測英文 NER 的 OntoNotes 5.0 語料庫中的標註錯誤，而這是目前最大的英文 NER 語料庫。我們的技術修正了訓練/開發/測試資料中約 10% 的句子。在實體標註方面，我們修正了資料集中約 8% 標註的範圍和/或類型，同時新增/刪除/拆分/合併了一些其他標註。考慮到 OntoNotes 的規模，這些都是大量的變更。我們使用三個 NER 函式庫來訓練、評估和比較使用原始和重新標註的資料集所訓練的模型，結果顯示整體 F 分數平均提升了 1.23%，某些實體類型的提升幅度很大 (>10%)。雖然我們的標註錯誤偵測方法並非詳盡無遺，而且需要一些手動標註工作，但它們在很大程度上與語言無關，可用於其他 NER 資料集和其他序列標籤任務。

##### **The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems**
2406.19170v1 by Judith Sieker, Simeon Junker, Ronja Utescher, Nazia Attari, Heiko Wersing, Hendrik Buschmeier, Sina Zarrieß

We examine how users perceive the limitations of an AI system when it
encounters a task that it cannot perform perfectly and whether providing
explanations alongside its answers aids users in constructing an appropriate
mental model of the system's capabilities and limitations. We employ a visual
question answer and explanation task where we control the AI system's
limitations by manipulating the visual inputs: during inference, the system
either processes full-color or grayscale images. Our goal is to determine
whether participants can perceive the limitations of the system. We hypothesize
that explanations will make limited AI capabilities more transparent to users.
However, our results show that explanations do not have this effect. Instead of
allowing users to more accurately assess the limitations of the AI system,
explanations generally increase users' perceptions of the system's competence -
regardless of its actual performance.

摘要：我們探討使用者如何感知 AI 系統的限制，當它遇到無法完美執行的任務時，以及在答案旁提供解釋是否能幫助使用者建構系統能力和限制的適當心智模型。我們採用視覺問答和解釋任務，其中我們透過操作視覺輸入來控制 AI 系統的限制：在推論期間，系統會處理全彩或灰階影像。我們的目標是確定參與者是否能感知系統的限制。我們假設解釋會讓有限的 AI 能力對使用者更透明。然而，我們的結果顯示解釋沒有這種效果。解釋並未讓使用者更準確地評估 AI 系統的限制，反倒讓使用者對系統的能力有更高的感知，而與其實際效能無關。

##### **RAVEN: Multitask Retrieval Augmented Vision-Language Learning**
2406.19150v1 by Varun Nagaraj Rao, Siddharth Choudhary, Aditya Deshpande, Ravi Kumar Satzoda, Srikar Appalaraju

The scaling of large language models to encode all the world's knowledge in
model parameters is unsustainable and has exacerbated resource barriers.
Retrieval-Augmented Generation (RAG) presents a potential solution, yet its
application to vision-language models (VLMs) is under explored. Existing
methods focus on models designed for single tasks. Furthermore, they're limited
by the need for resource intensive pre training, additional parameter
requirements, unaddressed modality prioritization and lack of clear benefit
over non-retrieval baselines. This paper introduces RAVEN, a multitask
retrieval augmented VLM framework that enhances base VLMs through efficient,
task specific fine-tuning. By integrating retrieval augmented samples without
the need for additional retrieval-specific parameters, we show that the model
acquires retrieval properties that are effective across multiple tasks. Our
results and extensive ablations across retrieved modalities for the image
captioning and VQA tasks indicate significant performance improvements compared
to non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a
+3\% accuracy on specific VQA question types. This underscores the efficacy of
applying RAG approaches to VLMs, marking a stride toward more efficient and
accessible multimodal learning.

摘要：將大型語言模型擴展為編碼所有世界知識的模型參數是不可持續的，並且加劇了資源障礙。檢索增強生成（RAG）提出了一個潛在的解決方案，但其在視覺語言模型（VLM）中的應用尚未被探索。現有方法側重於為單一任務設計的模型。此外，它們受到資源密集型預訓練、額外參數需求、未解決的模態優先級排序以及缺乏優於非檢索基準的明顯優勢的限制。本文介紹了 RAVEN，一個多任務檢索增強 VLM 框架，它通過高效的特定任務微調來增強基礎 VLM。通過整合檢索增強樣本，而無需額外的檢索特定參數，我們表明該模型獲取了跨多個任務有效的檢索屬性。我們在圖像標題和 VQA 任務的檢索模態中進行的結果和廣泛消融表明，與未檢索基準相比，性能顯著提升，在 MSCOCO 上 +1 CIDEr，在 NoCaps 上 +4 CIDEr，在特定 VQA 問題類型上準確率接近 +3%。這強調了將 RAG 方法應用於 VLM 的有效性，標誌著朝著更高效和更易於訪問的多模態學習邁出了一步。

##### **BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision**
2406.19148v1 by Kit Mills Bransby, Arian Beqiri, Woo-Jin Cho Kim, Jorge Oliveira, Agisilaos Chartsias, Alberto Gomez

Neural networks can learn spurious correlations that lead to the correct
prediction in a validation set, but generalise poorly because the predictions
are right for the wrong reason. This undesired learning of naive shortcuts
(Clever Hans effect) can happen for example in echocardiogram view
classification when background cues (e.g. metadata) are biased towards a class
and the model learns to focus on those background features instead of on the
image content. We propose a simple, yet effective random background
augmentation method called BackMix, which samples random backgrounds from other
examples in the training set. By enforcing the background to be uncorrelated
with the outcome, the model learns to focus on the data within the ultrasound
sector and becomes invariant to the regions outside this. We extend our method
in a semi-supervised setting, finding that the positive effects of BackMix are
maintained with as few as 5% of segmentation labels. A loss weighting
mechanism, wBackMix, is also proposed to increase the contribution of the
augmented examples. We validate our method on both in-distribution and
out-of-distribution datasets, demonstrating significant improvements in
classification accuracy, region focus and generalisability. Our source code is
available at: https://github.com/kitbransby/BackMix

摘要：神经网络可以学习错误的相关性，这会导致验证集中预测正确，但泛化性较差，因为预测正确的原因是错误的。这种天真捷径的不良学习（克莱弗汉斯效应）可能会发生在超声心动图视图分类中，当背景线索（例如元数据）偏向于某个类别时，模型会学习专注于那些背景特征，而不是图像内容。我们提出了一种简单但有效的随机背景增强方法，称为 BackMix，它从训练集中其他示例中采样随机背景。通过强制背景与结果无关，模型学会专注于超声扇区内的数据，并且对该区域之外的区域保持不变。我们在半监督设置中扩展了我们的方法，发现 BackMix 的积极效果在分割标签少至 5% 的情况下得以保持。还提出了一种损失加权机制 wBackMix，以增加增强示例的贡献。我们在分布内和分布外数据集上验证了我们的方法，证明了分类准确性、区域关注和泛化性的显着提高。我们的源代码可在以下位置获得：https://github.com/kitbransby/BackMix

##### **Resolving Discrepancies in Compute-Optimal Scaling of Language Models**
2406.19146v1 by Tomer Porian, Mitchell Wortsman, Jenia Jitsev, Ludwig Schmidt, Yair Carmon

Kaplan et al. and Hoffmann et al. developed influential scaling laws for the
optimal model size as a function of the compute budget, but these laws yield
substantially different predictions. We explain the discrepancy by reproducing
the Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and
identifying three factors causing the difference: last layer computational
cost, warmup duration, and scale-dependent optimizer tuning. With these factors
corrected, we obtain excellent agreement with the Hoffmann et al. (i.e.,
"Chinchilla") scaling law. Counter to a hypothesis of Hoffmann et al., we find
that careful learning rate decay is not essential for the validity of their
scaling law. As a secondary result, we derive scaling laws for the optimal
learning rate and batch size, finding that tuning the AdamW $\beta_2$ parameter
is essential at lower batch sizes.

摘要：Kaplan 等人和 Hoffmann 等人針對最佳模型大小制定了有影響力的縮放定律，作為計算預算的函數，但這些定律產生了顯著不同的預測。我們透過在兩個資料集（OpenWebText2 和 RefinedWeb）上重現 Kaplan 縮放定律，並找出導致差異的三個因素：最後一層的計算成本、熱身持續時間和依據規模調整最佳化器。在修正這些因素後，我們獲得與 Hoffmann 等人（即「Chinchilla」）縮放定律極為相符的結果。與 Hoffmann 等人的假設相反，我們發現仔細的學習率衰減對於其縮放定律的有效性並非必要。作為次要結果，我們推導出最佳學習率和批次大小的縮放定律，發現調整 AdamW $\beta_2$ 參數對於較小的批次大小至關重要。

##### **YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention**
2406.19136v1 by Chenxu Wang, Haowei Ming, Jian He, Yao Lu

The accurate prediction of drug molecule solubility is essential for
determining their therapeutic effectiveness and safety, influencing the drug's
ADME processes. Traditional solubility prediction techniques often fail to
capture the complex nature of molecular tructures, leading to notable
deviations between predictions and actual results. For example, the Discussion
on Advanced Drug-Like Compound Structures. Lusci highlighted issues in
capturing crucial cyclic structural information in molecules with ring
structures. To overcome this issue, our research introduces a novel deep
learning framework combining attention-based transformers, Long Short-Term
Memory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at
enhancing the precision of solubility predictions. Utilizing a training set of
9,943 compounds and testing on an anticancer compound dataset, our method
achieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error
(RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$)
and 0.61 (RMSE). Importantly, in an additional independent test, our model
significantly outperformed the baseline with an RMSE of 1.05 compared to 1.28,
a relative accuracy improvement of 45.9%. This research not only demonstrates
the vast potential of deep learning for improving solubility prediction
accuracy but also offers novel insights for drug design and selection in the
future. Continued efforts will be directed towards optimizing the model
architecture and extending its application to better support the drug
development process, underscoring the pivotal role of deep learning in drug
discovery.

摘要：準確預測藥物分子的溶解度對於決定其治療效果和安全性至關重要，並影響藥物的 ADME 程序。傳統的溶解度預測技術通常無法捕捉到分子結構的複雜性，導致預測與實際結果之間出現顯著偏差。例如，關於先進類藥物化合物結構的討論。Lusci 強調了捕捉具有環狀結構的分子中關鍵環狀結構信息的問題。為了克服這個問題，我們的研究引入了一種新穎的深度學習框架，結合了基於注意力的Transformer、長短期記憶 (LSTM) 網路和圖形卷積網路 (GCN)，旨在提高溶解度預測的精度。利用 9,943 個化合物的訓練集並在抗癌化合物數據集上進行測試，我們的模型達到了 0.55 的相關係數 ($R^2$) 和 0.59 的均方根誤差 (RMSE)，優於基準模型的 0.52 ($R^2$) 和 0.61 (RMSE) 分數。重要的是，在額外的獨立測試中，我們的模型顯著優於基準，RMSE 為 1.05，而基準為 1.28，相對準確度提高了 45.9%。這項研究不僅展示了深度學習在提高溶解度預測準確性方面的巨大潛力，還為未來的藥物設計和選擇提供了新見解。持續的努力將致力於優化模型架構並擴展其應用，以更好地支持藥物開發過程，強調深度學習在藥物發現中的關鍵作用。

##### **DEX-TTS: Diffusion-based EXpressive Text-to-Speech with Style Modeling on Time Variability**
2406.19135v1 by Hyun Joon Park, Jin Sob Kim, Wooseok Shin, Sung Won Han

Expressive Text-to-Speech (TTS) using reference speech has been studied
extensively to synthesize natural speech, but there are limitations to
obtaining well-represented styles and improving model generalization ability.
In this study, we present Diffusion-based EXpressive TTS (DEX-TTS), an acoustic
model designed for reference-based speech synthesis with enhanced style
representations. Based on a general diffusion TTS framework, DEX-TTS includes
encoders and adapters to handle styles extracted from reference speech. Key
innovations contain the differentiation of styles into time-invariant and
time-variant categories for effective style extraction, as well as the design
of encoders and adapters with high generalization ability. In addition, we
introduce overlapping patchify and convolution-frequency patch embedding
strategies to improve DiT-based diffusion networks for TTS. DEX-TTS yields
outstanding performance in terms of objective and subjective evaluation in
English multi-speaker and emotional multi-speaker datasets, without relying on
pre-training strategies. Lastly, the comparison results for the general TTS on
a single-speaker dataset verify the effectiveness of our enhanced diffusion
backbone. Demos are available here.

摘要：使用參考語音的表達式文字轉語音 (TTS) 已被廣泛研究用於合成自然語音，但對於取得良好的表現風格和提升模型概括能力仍存在限制。在本研究中，我們提出基於擴散的表達式 TTS (DEX-TTS)，這是一種音訊模型，設計用於基於參考的語音合成，並增強風格表現。基於一般擴散 TTS 架構，DEX-TTS 包含編碼器和適配器，用於處理從參考語音中萃取的風格。關鍵創新包含將風格區分為時間不變和時間變異類別，以進行有效的風格萃取，以及設計具備高概括能力的編碼器和適配器。此外，我們引入重疊貼片化和卷積頻率貼片嵌入策略，以改善用於 TTS 的基於 DiT 的擴散網路。DEX-TTS 在客觀和主觀評估方面產生傑出的表現，在英語多重揚聲器和情緒多重揚聲器資料集，而不依賴於預訓練策略。最後，在單一揚聲器資料集上的一般 TTS 比較結果驗證了我們增強的擴散主幹的有效性。展示範例在此處提供。

##### **Towards Learning Abductive Reasoning using VSA Distributed Representations**
2406.19121v1 by Giacomo Camposampiero, Michael Hersche, Aleksandar Terzić, Roger Wattenhofer, Abu Sebastian, Abbas Rahimi

We introduce the Abductive Rule Learner with Context-awareness (ARLC), a
model that solves abstract reasoning tasks based on Learn-VRF. ARLC features a
novel and more broadly applicable training objective for abductive reasoning,
resulting in better interpretability and higher accuracy when solving Raven's
progressive matrices (RPM). ARLC allows both programming domain knowledge and
learning the rules underlying a data distribution. We evaluate ARLC on the
I-RAVEN dataset, showcasing state-of-the-art accuracy across both
in-distribution and out-of-distribution (unseen attribute-rule pairs) tests.
ARLC surpasses neuro-symbolic and connectionist baselines, including large
language models, despite having orders of magnitude fewer parameters. We show
ARLC's robustness to post-programming training by incrementally learning from
examples on top of programmed knowledge, which only improves its performance
and does not result in catastrophic forgetting of the programmed solution. We
validate ARLC's seamless transfer learning from a 2x2 RPM constellation to
unseen constellations. Our code is available at
https://github.com/IBM/abductive-rule-learner-with-context-awareness.

摘要：我們引入了具有背景感知的演繹規則學習器 (ARLC)，這是一個基於 Learn-VRF 解決抽象推理任務的模型。ARLC 具有演繹推理的新穎且更廣泛適用的訓練目標，在解決雷文的漸進矩陣 (RPM) 時可提高可解釋性和準確性。ARLC 允許程式設計領域知識和學習資料分佈的基礎規則。我們在 I-RAVEN 資料集上評估 ARLC，展示了在分佈內和分佈外（未見屬性規則對）測試中的最先進準確性。儘管參數數量少幾個數量級，但 ARLC 超越了神經符號和連接主義基準，包括大型語言模型。我們通過在程式設計知識之上逐步從範例中學習來展示 ARLC 對程式設計後訓練的穩健性，這只會改善其效能，而不會導致程式設計解決方案的災難性遺忘。我們驗證了 ARLC 從 2x2 RPM 星群到未見星群的無縫遷移學習。我們的程式碼可在 https://github.com/IBM/abductive-rule-learner-with-context-awareness 取得。

##### **CHEW: A Dataset of CHanging Events in Wikipedia**
2406.19116v1 by Hsuvas Borkakoty, Luis Espinosa-Anke

We introduce CHEW, a novel dataset of changing events in Wikipedia expressed
in naturally occurring text. We use CHEW for probing LLMs for their timeline
understanding of Wikipedia entities and events in generative and classification
experiments. Our results suggest that LLMs, despite having temporal information
available, struggle to construct accurate timelines. We further show the
usefulness of CHEW-derived embeddings for identifying meaning shift.

摘要：我們介紹 CHEW，這是一個維基百科中關於變動事件的新穎資料集，以自然發生的文字表達。我們使用 CHEW 來探測 LLM 對維基百科實體和事件的時間序理解，並在生成和分類實驗中進行探測。我們的結果表明，儘管 LLM 具有時間資訊，但仍難以建構準確的時間序。我們進一步展示了 CHEW 衍生嵌入用於識別意義轉移的效用。

##### **Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction**
2406.19108v1 by Blaise Agüera y Arcas, Jyrki Alakuijala, James Evans, Ben Laurie, Alexander Mordvintsev, Eyvind Niklasson, Ettore Randazzo, Luca Versari

The fields of Origin of Life and Artificial Life both question what life is
and how it emerges from a distinct set of "pre-life" dynamics. One common
feature of most substrates where life emerges is a marked shift in dynamics
when self-replication appears. While there are some hypotheses regarding how
self-replicators arose in nature, we know very little about the general
dynamics, computational principles, and necessary conditions for
self-replicators to emerge. This is especially true on "computational
substrates" where interactions involve logical, mathematical, or programming
rules. In this paper we take a step towards understanding how self-replicators
arise by studying several computational substrates based on various simple
programming languages and machine instruction sets. We show that when random,
non self-replicating programs are placed in an environment lacking any explicit
fitness landscape, self-replicators tend to arise. We demonstrate how this
occurs due to random interactions and self-modification, and can happen with
and without background random mutations. We also show how increasingly complex
dynamics continue to emerge following the rise of self-replicators. Finally, we
show a counterexample of a minimalistic programming language where
self-replicators are possible, but so far have not been observed to arise.

摘要：生命起源和人工生命領域都質疑生命是什麼，以及它是如何從一組不同的「生命前」動力學中出現的。生命出現的大多數基質的一個共同特徵，是在自複製出現時動力學的顯著轉變。雖然有一些關於自複製器如何在自然界中產生的假設，但我們對自複製器出現的普遍動力學、計算原則和必要條件知之甚少。在交互涉及邏輯、數學或程式設計規則的「計算基質」上尤其如此。在本文中，我們透過研究基於各種簡單程式語言和機器指令集的幾個計算基質，朝著了解自複製器如何產生的方向邁出了一步。我們表明，當隨機、非自複製程式被放置在缺乏任何明確適應度環境中時，自複製器往往會產生。我們展示了這是如何由於隨機交互和自我修改而發生的，並且可以在有或沒有背景隨機突變的情況下發生。我們還展示了隨著自複製器的興起，如何持續出現越來越複雜的動力學。最後，我們展示了一個極簡程式語言的反例，其中自複製器是可能的，但到目前為止尚未觀察到它們的出現。

##### **Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs**
2406.19102v1 by Lokesh Mishra, Sohayl Dhibi, Yusik Kim, Cesar Berrospi Ramis, Shubham Gupta, Michele Dolfi, Peter Staar

Environment, Social, and Governance (ESG) KPIs assess an organization's
performance on issues such as climate change, greenhouse gas emissions, water
consumption, waste management, human rights, diversity, and policies. ESG
reports convey this valuable quantitative information through tables.
Unfortunately, extracting this information is difficult due to high variability
in the table structure as well as content. We propose Statements, a novel
domain agnostic data structure for extracting quantitative facts and related
information. We propose translating tables to statements as a new supervised
deep-learning universal information extraction task. We introduce SemTabNet - a
dataset of over 100K annotated tables. Investigating a family of T5-based
Statement Extraction Models, our best model generates statements which are 82%
similar to the ground-truth (compared to baseline of 21%). We demonstrate the
advantages of statements by applying our model to over 2700 tables from ESG
reports. The homogeneous nature of statements permits exploratory data analysis
on expansive information found in large collections of ESG reports.

摘要：環境、社會和治理 (ESG) KPI 評估組織在氣候變遷、溫室氣體排放、用水量、廢棄物管理、人權、多元性和政策等議題上的績效。ESG 報告透過表格傳達這些有價值的量化資訊。不幸的是，由於表格結構和內容的高度變異性，提取這些資訊很困難。我們提出陳述，一種用於提取量化事實和相關資訊的新穎領域非特定資料結構。我們建議將表格翻譯成陳述，作為一項新的監督式深度學習通用資訊提取任務。我們介紹 SemTabNet - 一個超過 10 萬個註解表格的資料集。研究一系列基於 T5 的陳述提取模型，我們最好的模型生成的陳述與真實情況有 82% 的相似度（與 21% 的基準相比）。我們展示了陳述的優點，將我們的模型應用於 ESG 報告中的 2700 多個表格。陳述的同質性允許對 ESG 報告的大量資訊集合中發現的廣泛資料進行探索性資料分析。

##### **Fairness and Bias in Multimodal AI: A Survey**
2406.19097v1 by Tosin Adewumi, Lama Alkhaled, Namrata Gurung, Goya van Boven, Irene Pagliai

The importance of addressing fairness and bias in artificial intelligence
(AI) systems cannot be over-emphasized. Mainstream media has been awashed with
news of incidents around stereotypes and bias in many of these systems in
recent years. In this survey, we fill a gap with regards to the minimal study
of fairness and bias in Large Multimodal Models (LMMs) compared to Large
Language Models (LLMs), providing 50 examples of datasets and models along with
the challenges affecting them; we identify a new category of quantifying bias
(preuse), in addition to the two well-known ones in the literature: intrinsic
and extrinsic; we critically discuss the various ways researchers are
addressing these challenges. Our method involved two slightly different search
queries on Google Scholar, which revealed that 33,400 and 538,000 links are the
results for the terms "Fairness and bias in Large Multimodal Models" and
"Fairness and bias in Large Language Models", respectively. We believe this
work contributes to filling this gap and providing insight to researchers and
other stakeholders on ways to address the challenge of fairness and bias in
multimodal A!.

摘要：在人工智能（AI）系统中解决公平性和偏差的重要性怎么强调都不为过。近年来，主流媒体充斥着许多此类系统中有关刻板印象和偏差的事件新闻。在此调查中，我们填补了与大型多模态模型（LMM）相比，在大型语言模型（LLM）中对公平性和偏差的研究最少这一差距，提供了 50 个数据集和模型的示例以及影响它们的挑战；除了文献中众所周知的内在和外在两种类别外，我们还确定了一种新的量化偏差的类别（预用）；我们批判性地讨论了研究人员解决这些挑战的各种方式。我们的方法涉及在 Google Scholar 上进行两次略有不同的搜索查询，结果显示“大型多模态模型中的公平性和偏差”和“大型语言模型中的公平性和偏差”这两个术语的搜索结果分别为 33,400 和 538,000 个链接。我们相信这项工作有助于填补这一空白，并为研究人员和其他利益相关者提供有关解决多模态人工智能中的公平性和偏差挑战的方法的见解。

##### **Dimensions underlying the representational alignment of deep neural networks with humans**
2406.19087v1 by Florian P. Mahner, Lukas Muttenthaler, Umut Güçlü, Martin N. Hebart

Determining the similarities and differences between humans and artificial
intelligence is an important goal both in machine learning and cognitive
neuroscience. However, similarities in representations only inform us about the
degree of alignment, not the factors that determine it. Drawing upon recent
developments in cognitive science, we propose a generic framework for yielding
comparable representations in humans and deep neural networks (DNN). Applying
this framework to humans and a DNN model of natural images revealed a
low-dimensional DNN embedding of both visual and semantic dimensions. In
contrast to humans, DNNs exhibited a clear dominance of visual over semantic
features, indicating divergent strategies for representing images. While
in-silico experiments showed seemingly-consistent interpretability of DNN
dimensions, a direct comparison between human and DNN representations revealed
substantial differences in how they process images. By making representations
directly comparable, our results reveal important challenges for
representational alignment, offering a means for improving their comparability.

摘要：確定人類和人工智慧之間的相似性和差異，是機器學習和認知神經科學中一個重要的目標。然而，表徵中的相似性僅能告訴我們對齊的程度，而不是決定它的因素。借鑒認知科學的最新發展，我們提出了在人類和深度神經網路（DNN）中產生可比較表徵的通用框架。將這個框架應用於人類和自然影像的 DNN 模型，揭示了視覺和語義維度的低維 DNN 嵌入。與人類相反，DNN 表現出視覺明顯優於語義特徵，表明表徵影像的不同策略。雖然電腦模擬實驗顯示 DNN 維度的可解釋性看似一致，但人類和 DNN 表徵之間的直接比較揭示了他們在處理影像方式上的重大差異。透過讓表徵直接可比較，我們的結果揭示了表徵對齊的重要挑戰，提供了一種改善其可比較性的方法。

##### **AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries**
2406.19073v1 by Irina Saparina, Mirella Lapata

Practical semantic parsers are expected to understand user utterances and map
them to executable programs, even when these are ambiguous. We introduce a new
benchmark, AMBROSIA, which we hope will inform and inspire the development of
text-to-SQL parsers capable of recognizing and interpreting ambiguous requests.
Our dataset contains questions showcasing three different types of ambiguity
(scope ambiguity, attachment ambiguity, and vagueness), their interpretations,
and corresponding SQL queries. In each case, the ambiguity persists even when
the database context is provided. This is achieved through a novel approach
that involves controlled generation of databases from scratch. We benchmark
various LLMs on AMBROSIA, revealing that even the most advanced models struggle
to identify and interpret ambiguity in questions.

摘要：實用的語義解析器預期能理解使用者的話語，並將其轉換成可執行的程式，即使這些話語有歧義。我們介紹了一個新的基準 AMBROSIA，我們希望它能提供資訊並激勵能辨識和詮釋歧義請求的文字轉 SQL 解析器的開發。我們的資料集包含展示三種不同類型歧義（範圍歧義、依附歧義和模糊性）的問題、其詮釋和對應的 SQL 查詢。在每種情況下，即使提供了資料庫背景，歧義仍然存在。這是透過一種創新的方法實現的，該方法包含從頭開始受控生成資料庫。我們在 AMBROSIA 上對各種 LLM 進行基準測試，結果顯示即使是最先進的模型也很難辨識和詮釋問題中的歧義。

##### **EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization**
2406.19071v1 by Ondrej Sotolar

Empathetic response generation is a desirable aspect of conversational
agents, crucial for facilitating engaging and emotionally intelligent
multi-turn conversations between humans and machines. Leveraging large language
models for this task has shown promising results, yet challenges persist in
ensuring both the empathetic quality of the responses and retention of the
generalization performance of the models. In this paper, we propose a novel
approach where we construct theory-driven preference datasets and use them to
align LLMs with preference optimization algorithms to address these challenges.
To measure empathetic response generation, we employ the EmpatheticDialogues
dataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and
evaluate the generalization performance on the MMLU benchmark. We make all
datasets, source code, and models publicly available.

摘要：同理回應生成是對話代理人理想的特點，對於促進人類與機器之間引人入勝且富有情感智慧的多輪對話至關重要。利用大型語言模型來執行此任務已展現出有前景的成果，然而，在確保回應的同理品質和保留模型的概化效能方面仍存在挑戰。在本文中，我們提出了一種新穎的方法，我們建構了理論驅動的偏好資料集，並使用它們將 LLM 與偏好最佳化演算法對齊，以應對這些挑戰。為了衡量同理回應生成，我們採用了 EmpatheticDialogues 資料集，使用 diff-EPITOME 和 BERTscore 指標評估同理心，並在 MMLU 基準上評估概化效能。我們公開提供所有資料集、原始碼和模型。

##### **STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis**
2406.19065v1 by Wenbin Li, Di Yao, Ruibo Zhao, Wenjie Chen, Zijie Xu, Chengxue Luo, Chang Gong, Quanliang Jing, Haining Tan, Jingping Bi

The rapid evolution of large language models (LLMs) holds promise for
reforming the methodology of spatio-temporal data mining. However, current
works for evaluating the spatio-temporal understanding capability of LLMs are
somewhat limited and biased. These works either fail to incorporate the latest
language models or only focus on assessing the memorized spatio-temporal
knowledge. To address this gap, this paper dissects LLMs' capability of
spatio-temporal data into four distinct dimensions: knowledge comprehension,
spatio-temporal reasoning, accurate computation, and downstream applications.
We curate several natural language question-answer tasks for each category and
build the benchmark dataset, namely STBench, containing 13 distinct tasks and
over 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs,
such as GPT-4o, Gemma and Mistral. Experimental results reveal that existing
LLMs show remarkable performance on knowledge comprehension and spatio-temporal
reasoning tasks, with potential for further enhancement on other tasks through
in-context learning, chain-of-though prompting, and fine-tuning. The code and
datasets of STBench are released on https://github.com/LwbXc/STBench.

摘要：大型語言模型 (LLM) 的快速發展，有望改革時空資料探勘的方法。然而，目前用於評估 LLM 時空理解能力的研究，多少有些限制和偏見。這些研究要不是沒有納入最新的語言模型，就是只著重於評估記憶的時空知識。為了彌補這個差距，本文將 LLM 對時空資料的能力剖析成四個不同的面向：知識理解、時空推理、準確運算和下游應用。我們為每個類別策劃了幾個自然語言問答任務，並建立基準資料集，也就是 STBench，其中包含 13 個不同的任務和超過 60,000 個問答配對。此外，我們評估了 13 個 LLM 的能力，例如 GPT-4o、Gemma 和 Mistral。實驗結果顯示，現有的 LLM 在知識理解和時空推理任務上表現傑出，並有潛力透過情境學習、思考鏈提示和微調，在其他任務上進一步提升。STBench 的程式碼和資料集已於 https://github.com/LwbXc/STBench 上發布。

##### **Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO**
2406.19057v1 by Fuseini Mumuni, Alhassan Mumuni

Grounding DINO and the Segment Anything Model (SAM) have achieved impressive
performance in zero-shot object detection and image segmentation, respectively.
Together, they have a great potential in revolutionizing zero-shot semantic
segmentation or data annotation. Yet, in specialized domains like medical image
segmentation, objects of interest (e.g., organs, tissues, and tumors) may not
fall in existing class names. To address this problem, the referring expression
comprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary
targets by their language descriptions. However, recent studies have
highlighted severe limitation of the REC framework in this application setting
owing to its tendency to make false positive predictions when the target is
absent in the given image. And, while this bottleneck is central to the
prospect of open-set semantic segmentation, it is still largely unknown how
much improvement can be achieved by studying the prediction errors. To this
end, we perform empirical studies on eight publicly available datasets and
reveal that these errors consistently follow a predictable pattern and can,
thus, be mitigated by a simple strategy. Specifically, we show that these false
positive detections with appreciable confidence scores generally occupy large
image areas and can usually be filtered by their relative sizes. More
importantly, we expect these observations to inspire future research in
improving REC-based detection and automated segmentation. Using this technique,
we evaluate the performance of SAM on multiple datasets from various
specialized domains and report significant improvement in segmentation
performance and annotation time savings over manual approaches.

摘要：Grounding DINO 和 Segment Anything Model (SAM) 在零次物體偵測和影像分割中分別取得令人印象深刻的表現。它們共同擁有在零次語意分割或資料標註中掀起革命的巨大潛力。然而，在醫學影像分割等專業領域中，感興趣的物體（例如器官、組織和腫瘤）可能不在現有的類別名稱中。為了解決這個問題，利用 Grounding DINO 的指涉表達理解 (REC) 能力，透過語言描述來偵測任意目標。然而，最近的研究強調了 REC 架構在這個應用設定中的嚴重限制，因為當目標不存在於給定的影像中時，它傾向於做出假陽性預測。而且，雖然此瓶頸對於開放式語意分割的前景至關重要，但透過研究預測誤差能獲得多少改善仍是未知的。為此，我們對八個公開可用的資料集進行實證研究，並揭示這些誤差始終遵循可預測的模式，因此，可以透過一個簡單的策略來減輕。具體來說，我們表明這些具有可觀置信度的假陽性偵測通常佔據較大的影像區域，並且通常可以根據它們的相對大小來過濾。更重要的是，我們預期這些觀察結果將激勵未來在改善基於 REC 的偵測和自動分割的研究。使用此技術，我們評估了 SAM 在來自各種專業領域的多個資料集上的效能，並報告在分割效能和標註時間節省上相較於手動方法有顯著的改善。

##### **A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)**
2406.19054v1 by Daniel Sonntag, Michael Barz, Thiago Gouvêa

This DFKI technical report presents the anatomy of the No-IDLE prototype
system (funded by the German Federal Ministry of Education and Research) that
provides not only basic and fundamental research in interactive machine
learning, but also reveals deeper insights into users' behaviours, needs, and
goals. Machine learning and deep learning should become accessible to millions
of end users. No-IDLE's goals and scienfific challenges centre around the
desire to increase the reach of interactive deep learning solutions for
non-experts in machine learning. One of the key innovations described in this
technical report is a methodology for interactive machine learning combined
with multimodal interaction which will become central when we start interacting
with semi-intelligent machines in the upcoming area of neural networks and
large language models.

摘要：這份德國人工智慧研究中心技術報告介紹 No-IDLE 原型系統的解剖（由德國聯邦教育暨研究部資助），該系統不僅提供互動式機器學習的基本研究，也深入探討使用者的行為、需求和目標。機器學習和深度學習應讓數百萬的最終使用者都能使用。No-IDLE 的目標和科學挑戰，重點在於擴大互動式深度學習解決方案的應用範圍，讓非機器學習專家也能使用。這份技術報告中描述的其中一項關鍵創新，是互動式機器學習方法，結合多模式互動，這將在我們開始與神經網路和大型語言模型這類半智慧機器互動時，扮演核心角色。

##### **FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning**
2406.19050v1 by Alexander Herzog, Robbie Southam, Ioannis Mavromatis, Aftab Khan

Federated Learning (FL) is a distributed machine learning approach that
enables training on decentralized data while preserving privacy. However, FL
systems often involve resource-constrained client devices with limited
computational power, memory, storage, and bandwidth. This paper introduces
FedMap, a novel method that aims to enhance the communication efficiency of FL
deployments by collaboratively learning an increasingly sparse global model
through iterative, unstructured pruning. Importantly, FedMap trains a global
model from scratch, unlike other methods reported in the literature, making it
ideal for privacy-critical use cases such as in the medical and finance
domains, where suitable pre-training data is often limited. FedMap adapts
iterative magnitude-based pruning to the FL setting, ensuring all clients prune
and refine the same subset of the global model parameters, therefore gradually
reducing the global model size and communication overhead. The iterative nature
of FedMap, forming subsequent models as subsets of predecessors, avoids
parameter reactivation issues seen in prior work, resulting in stable
performance. In this paper we provide an extensive evaluation of FedMap across
diverse settings, datasets, model architectures, and hyperparameters, assessing
performance in both IID and non-IID environments. Comparative analysis against
the baseline approach demonstrates FedMap's ability to achieve more stable
client model performance. For IID scenarios, FedMap achieves over $90$\%
pruning without significant performance degradation. In non-IID settings, it
achieves at least $~80$\% pruning while maintaining accuracy. FedMap offers a
promising solution to alleviate communication bottlenecks in FL systems while
retaining model accuracy.

摘要：联邦学习 (FL) 是一种分布式机器学习方法，可在保护隐私的同时对分散数据进行训练。然而，FL 系统通常涉及资源受限的客户端设备，其计算能力、内存、存储和带宽有限。本文介绍了 FedMap，这是一种新颖的方法，旨在通过协作学习一个不断稀疏的全局模型（通过迭代的非结构化剪枝）来提高 FL 部署的通信效率。重要的是，FedMap 从头开始训练一个全局模型，这与文献中报道的其他方法不同，使其非常适合隐私至关重要的用例，例如医疗和金融领域，其中合适的预训练数据通常有限。FedMap 将基于迭代幅度的剪枝调整到 FL 设置中，确保所有客户端都剪枝并优化全局模型参数的相同子集，从而逐渐减少全局模型大小和通信开销。FedMap 的迭代性质，将后续模型形成为前代模型的子集，避免了先前工作中看到的参数重新激活问题，从而产生了稳定的性能。在本文中，我们对 FedMap 在不同设置、数据集、模型架构和超参数中进行了广泛评估，评估了在 IID 和非 IID 环境中的性能。与基准方法的比较分析证明了 FedMap 能够实现更稳定的客户端模型性能。对于 IID 场景，FedMap 在不显着降低性能的情况下实现了超过 90% 的剪枝。在非 IID 设置中，它在保持准确性的同时实现了至少 80% 的剪枝。FedMap 为缓解 FL 系统中的通信瓶颈同时保持模型准确性提供了一个有希望的解决方案。

##### **Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation**
2406.19049v1 by Amartya Sanyal, Yaxi Hu, Yaodong Yu, Yian Ma, Yixin Wang, Bernhard Schölkopf

"Accuracy-on-the-line" is a widely observed phenomenon in machine learning,
where a model's accuracy on in-distribution (ID) and out-of-distribution (OOD)
data is positively correlated across different hyperparameters and data
configurations. But when does this useful relationship break down? In this
work, we explore its robustness. The key observation is that noisy data and the
presence of nuisance features can be sufficient to shatter the
Accuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become
negatively correlated, leading to "Accuracy-on-the-wrong-line". This phenomenon
can also occur in the presence of spurious (shortcut) features, which tend to
overshadow the more complex signal (core, non-spurious) features, resulting in
a large nuisance feature space. Moreover, scaling to larger datasets does not
mitigate this undesirable behavior and may even exacerbate it. We formally
prove a lower bound on Out-of-distribution (OOD) error in a linear
classification model, characterizing the conditions on the noise and nuisance
features for a large OOD error. We finally demonstrate this phenomenon across
both synthetic and real datasets with noisy data and nuisance features.

摘要：「準確性在線上」是機器學習中廣泛觀察到的現象，其中模型在分佈內 (ID) 和分佈外 (OOD) 資料上的準確性在不同的超參數和資料配置中呈正相關。但是這種有用的關係什麼時候會中斷？在這項工作中，我們探討其穩健性。關鍵觀察是，雜訊資料和滋擾特徵的存在足以打破「準確性在線上」現象。在這些情況下，ID 和 OOD 準確性可能會變成負相關，導致「準確性在錯誤線上」。這種現象也可能發生在存在虛假（捷徑）特徵的情況下，虛假特徵往往會掩蓋更複雜的訊號（核心、非虛假）特徵，導致大量的滋擾特徵空間。此外，擴充到更大的資料集並不會減輕這種不良行為，甚至可能使情況惡化。我們正式證明了線性分類模型中 Out-of-distribution (OOD) 誤差的下限，描述了大量 OOD 誤差的雜訊和滋擾特徵條件。我們最後在合成和真實資料集上展示了這種現象，這些資料集包含雜訊資料和滋擾特徵。

##### **Improving Weak-to-Strong Generalization with Reliability-Aware Alignment**
2406.19032v1 by Yue Guo, Yi Yang

Large language models (LLMs) are now rapidly advancing and surpassing human
abilities on many natural language tasks. However, aligning these super-human
LLMs with human knowledge remains challenging because the supervision signals
from human annotators may be wrong. This issue, known as the "super-alignment"
problem, requires enhancing weak-to-strong generalization, where a strong LLM
must generalize from imperfect supervision provided by a weaker source. To
address this issue, we propose an approach to improve weak-to-strong
generalization by involving the reliability of weak supervision signals in the
alignment process. In our method, we query the weak supervisor for multiple
answers, estimate the answer reliability, and enhance the alignment process by
filtering out uncertain data or re-weighting reliable data. Experiments on four
datasets demonstrate that our methods effectively identify the quality of weak
labels and significantly enhance weak-to-strong generalization. Our work
presents effective techniques for error-robust model alignment, reducing error
propagation from noisy supervision and enhancing the accuracy and reliability
of LLMs. Codes are publicly available at
http://github.com/Irenehere/ReliableAlignment.

摘要：大型語言模型 (LLM) 現在正快速進步，在許多自然語言任務上超越人類能力。然而，讓這些超人類 LLM 與人類知識保持一致仍然具有挑戰性，因為來自人類註釋者的監督信號可能錯誤。這個問題稱為「超級對齊」問題，需要增強從弱到強的概括能力，其中強大的 LLM 必須從較弱來源提供的並不完美的監督中進行概括。為了解決這個問題，我們提出了一種方法，透過在對齊過程中納入弱監督信號的可靠性來改善從弱到強的概括能力。在我們的方法中，我們查詢弱監督者以取得多個答案，估計答案的可靠性，並透過篩選不確定的資料或重新加權可靠的資料來增強對齊過程。在四個資料集上的實驗證明，我們的模型有效地識別弱標籤的品質，並顯著增強從弱到強的概括能力。我們的研究提出了針對錯誤穩健模型對齊的有效技術，減少來自有雜訊監督的錯誤傳播，並增強 LLM 的準確性和可靠性。程式碼已公開於 http://github.com/Irenehere/ReliableAlignment。

##### **Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes**
2406.19015v1 by Joachim Schaeffer, Eric Lenz, Duncan Gulla, Martin Z. Bazant, Richard D. Braatz, Rolf Findeisen

Health monitoring, fault analysis, and detection are critical for the safe
and sustainable operation of battery systems. We apply Gaussian process
resistance models on lithium iron phosphate battery field data to effectively
separate the time-dependent and operating point-dependent resistance. The data
set contains 29 battery systems returned to the manufacturer for warranty, each
with eight cells in series, totaling 232 cells and 131 million data rows. We
develop probabilistic fault detection rules using recursive spatiotemporal
Gaussian processes. These processes allow the quick processing of over a
million data points, enabling advanced online monitoring and furthering the
understanding of battery pack failure in the field. The analysis underlines
that often, only a single cell shows abnormal behavior or a knee point,
consistent with weakest-link failure for cells connected in series, amplified
by local resistive heating. The results further the understanding of how
batteries degrade and fail in the field and demonstrate the potential of
efficient online monitoring based on data. We open-source the code and publish
the large data set upon completion of the review of this article.

摘要：健康監控、故障分析和檢測對於電池系統的安全和可持續運作至關重要。我們將高斯過程電阻模型應用於磷酸鐵鋰電池現場數據，以有效分離時間相關和運作點相關的電阻。該數據集包含 29 個退回給製造商進行保固的電池系統，每個系統有八個串聯電池，總計 232 個電池和 1.31 億列數據。我們使用遞迴時空高斯過程開發出機率性故障檢測規則。這些過程允許快速處理超過一百萬個數據點，實現進階線上監控，並進一步了解電池組在現場的故障。分析強調，通常只有一個電池顯示出異常行為或拐點，這與串聯連接電池的弱環故障一致，並因局部電阻加熱而放大。結果進一步了解電池如何在現場退化和故障，並展示基於數據的有效線上監控的潛力。我們在完成本文審查後開源程式碼並發布大型數據集。

##### **FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity**
2406.18995v1 by Zhaobin Sun, Nannan Wu, Junjie Shi, Li Yu, Xin Yang, Kwang-Ting Cheng, Zengqiang Yan

Cross-silo federated learning (FL) enables decentralized organizations to
collaboratively train models while preserving data privacy and has made
significant progress in medical image classification. One common assumption is
task homogeneity where each client has access to all classes during training.
However, in clinical practice, given a multi-label classification task,
constrained by the level of medical knowledge and the prevalence of diseases,
each institution may diagnose only partial categories, resulting in task
heterogeneity. How to pursue effective multi-label medical image classification
under task heterogeneity is under-explored. In this paper, we first formulate
such a realistic label missing setting in the multi-label FL domain and propose
a two-stage method FedMLP to combat class missing from two aspects: pseudo
label tagging and global knowledge learning. The former utilizes a warmed-up
model to generate class prototypes and select samples with high confidence to
supplement missing labels, while the latter uses a global model as a teacher
for consistency regularization to prevent forgetting missing class knowledge.
Experiments on two publicly-available medical datasets validate the superiority
of FedMLP against the state-of-the-art both federated semi-supervised and noisy
label learning approaches under task heterogeneity. Code is available at
https://github.com/szbonaldo/FedMLP.

摘要：跨資料庫聯邦學習 (FL) 讓分散式組織能夠在保留資料隱私的同時協作訓練模型，並在醫學影像分類方面取得顯著進展。一個常見的假設是任務同質性，其中每個客戶端在訓練期間都可以存取所有類別。然而，在臨床實務中，給定一個多標籤分類任務，受限於醫學知識的層級和疾病的流行率，每個機構可能只診斷部分類別，導致任務異質性。如何在任務異質性下追求有效的多標籤醫學影像分類仍有待探討。在本文中，我們首先在多標籤 FL 領域中制定這種現實的標籤遺失設定，並提出一個兩階段方法 FedMLP 來從兩個方面解決類別遺失問題：偽標籤標記和全局知識學習。前者利用熱身模型產生類別原型，並選擇具有高度信心的樣本來補充遺失標籤，而後者使用全局模型作為教師進行一致性正則化，以防止遺忘遺失類別的知識。在兩個公開可用的醫學資料集上進行的實驗驗證了 FedMLP 在任務異質性下優於最先進的聯合半監督和雜訊標籤學習方法。程式碼可在 https://github.com/szbonaldo/FedMLP 取得。

##### **Semi-supervised Concept Bottleneck Models**
2406.18992v1 by Lijie Hu, Tianhao Huang, Huanyi Xie, Chenyang Ren, Zhengyu Hu, Lu Yu, Di Wang

Concept Bottleneck Models (CBMs) have garnered increasing attention due to
their ability to provide concept-based explanations for black-box deep learning
models while achieving high final prediction accuracy using human-like
concepts. However, the training of current CBMs heavily relies on the accuracy
and richness of annotated concepts in the dataset. These concept labels are
typically provided by experts, which can be costly and require significant
resources and effort. Additionally, concept saliency maps frequently misalign
with input saliency maps, causing concept predictions to correspond to
irrelevant input features - an issue related to annotation alignment. To
address these limitations, we propose a new framework called SSCBM
(Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical
situations where annotated data is scarce. By leveraging joint training on both
labeled and unlabeled data and aligning the unlabeled data at the concept
level, we effectively solve these issues. We proposed a strategy to generate
pseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is
both effective and efficient. With only 20% labeled data, we achieved 93.19%
(96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a
fully supervised setting) prediction accuracy.

摘要：概念瓶頸模型 (CBM) 因其能為黑箱深度學習模型提供基於概念的解釋，同時使用類人概念實現高最終預測準確性而備受關注。然而，目前 CBM 的訓練高度依賴於資料集中註釋概念的準確性和豐富性。這些概念標籤通常由專家提供，這可能很昂貴，並且需要大量的資源和精力。此外，概念顯著性圖經常與輸入顯著性圖不一致，導致概念預測對應於無關的輸入特徵，而這是一個與註釋對齊相關的問題。為了解決這些限制，我們提出了一個名為 SSCBM（半監督概念瓶頸模型）的新框架。我們的 SSCBM 適用於註釋數據稀缺的實際情況。通過在標籤數據和未標籤數據上進行聯合訓練，並在概念層級對齊未標籤數據，我們有效地解決了這些問題。我們提出了一種生成偽標籤和對齊損失的策略。實驗表明，我們的 SSCBM 既有效又高效。僅使用 20% 的標籤數據，我們就達到了 93.19%（在完全監督的設置中為 96.39%）的概念準確度和 75.51%（在完全監督的設置中為 79.82%）的預測準確度。

##### **RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton**
2406.18977v1 by Fanfan Liu, Feng Yan, Liming Zheng, Chengjian Feng, Yiyang Huang, Lin Ma

Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a
novel paradigm, aiming to enhance the model's ability to generalize to new
objects and instructions. However, due to variations in camera specifications
and mounting positions, existing methods exhibit significant performance
disparities across different robotic platforms. To address this challenge, we
propose RoboUniView in this paper, an innovative approach that decouples visual
feature extraction from action learning. We first learn a unified view
representation from multi-perspective views by pre-training on readily
accessible data, and then derive actions from this unified view representation
to control robotic manipulation. This unified view representation more
accurately mirrors the physical world and is not constrained by the robotic
platform's camera parameters. Thanks to this methodology, we achieve
state-of-the-art performance on the demanding CALVIN benchmark, enhancing the
success rate in the $D \to D$ setting from 88.7% to 96.2%, and in the $ABC \to
D$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding
adaptability and flexibility: it maintains high performance under unseen camera
parameters, can utilize multiple datasets with varying camera parameters, and
is capable of joint cross-task learning across datasets. Code is provided for
re-implementation. https://github.com/liufanfanlff/RoboUniview

摘要：利用視覺語言模型 (VLM) 進行機器人操作代表一種新典範，旨在增強模型對新物件和指令的概化能力。然而，由於相機規格和安裝位置的差異，現有方法在不同的機器人平台上表現出顯著的效能差異。為了應對這項挑戰，我們在本文中提出 RoboUniView，這是一種創新的方法，將視覺特徵提取與動作學習分開。我們首先透過預先訓練於容易取得的資料上，從多視角視圖中學習統一的視圖表示，然後從這個統一的視圖表示中推導動作，以控制機器人操作。這個統一的視圖表示更準確地反映物理世界，不受機器人平台相機參數的約束。由於這個方法，我們在要求嚴格的 CALVIN 基準上達到最先進的效能，將 $D \to D$ 設定中的成功率從 88.7% 提升到 96.2%，以及將 $ABC \to D$ 設定中的成功率從 82.4% 提升到 94.2%。此外，我們的模型展現出傑出的適應性和靈活性：它在未見的相機參數下維持高效能，可以使用具有不同相機參數的多個資料集，並且能夠跨資料集進行聯合跨任務學習。已提供程式碼供重新實作。https://github.com/liufanfanlff/RoboUniview

##### **Applying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over**
2406.18972v1 by Atsunori Ogawa, Naoyuki Kamo, Kohei Matsuura, Takanori Ashihara, Takafumi Moriya, Takatomo Kano, Naohiro Tawara, Marc Delcroix

Large language models (LLMs) have been successfully applied for rescoring
automatic speech recognition (ASR) hypotheses. However, their ability to
rescore ASR hypotheses of casual conversations has not been sufficiently
explored. In this study, we reveal it by performing N-best ASR hypotheses
rescoring using Llama2 on the CHiME-7 distant ASR (DASR) task. Llama2 is one of
the most representative LLMs, and the CHiME-7 DASR task provides datasets of
casual conversations between multiple participants. We investigate the effects
of domain adaptation of the LLM and context carry-over when performing N-best
rescoring. Experimental results show that, even without domain adaptation,
Llama2 outperforms a standard-size domain-adapted Transformer-LM, especially
when using a long context. Domain adaptation shortens the context length needed
with Llama2 to achieve its best performance, i.e., it reduces the computational
cost of Llama2.

摘要：大型語言模型 (LLM) 已成功應用於重新評分自動語音辨識 (ASR) 假設。然而，它們重新評分非正式對話的 ASR 假設的能力尚未得到充分探索。在本研究中，我們通過在 CHiME-7 遠程 ASR (DASR) 任務上使用 Llama2 執行 N 個最佳 ASR 假設重新評分來揭示它。Llama2 是最具代表性的 LLM 之一，而 CHiME-7 DASR 任務提供了多個參與者之間的非正式對話的資料集。我們在執行 N 個最佳重新評分時研究了 LLM 的領域適應和上下文延續的影響。實驗結果表明，即使沒有領域適應，Llama2 也優於標準大小的領域適應 Transformer-LM，特別是在使用長上下文時。領域適應縮短了 Llama2 達到其最佳性能所需的上下文長度，即它降低了 Llama2 的運算成本。

##### **UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models**
2406.18966v2 by Siyuan Wu, Yue Huang, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Xiangliang Zhang, Jianfeng Gao, Chaowei Xiao, Lichao Sun

Large Language Models (LLMs) such as GPT-4 and Llama3 have significantly
impacted various fields by enabling high-quality synthetic data generation and
reducing dependence on expensive human-generated datasets. Despite this,
challenges remain in the areas of generalization, controllability, diversity,
and truthfulness within the existing generative frameworks. To address these
challenges, this paper presents UniGen, a comprehensive LLM-powered framework
designed to produce diverse, accurate, and highly controllable datasets. UniGen
is adaptable, supporting all types of text datasets and enhancing the
generative process through innovative mechanisms. To augment data diversity,
UniGen incorporates an attribute-guided generation module and a group checking
feature. For accuracy, it employs a code-based mathematical assessment for
label verification alongside a retrieval-augmented generation technique for
factual validation. The framework also allows for user-specified constraints,
enabling customization of the data generation process to suit particular
requirements. Extensive experiments demonstrate the superior quality of data
generated by UniGen, and each module within UniGen plays a critical role in
this enhancement. Additionally, UniGen is applied in two practical scenarios:
benchmarking LLMs and data augmentation. The results indicate that UniGen
effectively supports dynamic and evolving benchmarking, and that data
augmentation improves LLM capabilities in various domains, including
agent-oriented abilities and reasoning skills.

摘要：大型語言模型 (LLM)，例如 GPT-4 和 Llama3，透過啟用高品質的合成資料產生，並降低對昂貴的人類產生資料集的依賴，對各個領域產生重大影響。儘管如此，在現有的生成式架構中，在概括化、可控性、多樣性和真實性方面仍存在挑戰。為了應對這些挑戰，本文提出了 UniGen，一個由 LLM 驅動的綜合架構，旨在產生多樣化、準確且高度可控的資料集。UniGen 具有適應性，支援所有類型的文字資料集，並透過創新機制增強生成式程序。為了增加資料的多樣性，UniGen 結合了屬性引導生成模組和群組檢查功能。為了準確性，它採用基於程式碼的數學評估進行標籤驗證，並結合檢索增強的生成技術進行事實驗證。該架構還允許使用者指定的約束，讓資料產生程序能夠自訂以符合特定需求。廣泛的實驗證明了 UniGen 所產生資料的優異品質，而 UniGen 中的每個模組都在這項增強中扮演關鍵角色。此外，UniGen 應用於兩個實際情境：基準測試 LLM 和資料擴充。結果表明，UniGen 有效地支援動態和不斷演進的基準測試，而資料擴充則改善了 LLM 在各種領域的能力，包括以代理為導向的能力和推理技能。

##### **Investigating and Defending Shortcut Learning in Personalized Diffusion Models**
2406.18944v1 by Yixin Liu, Ruoxi Chen, Lichao Sun

Personalized diffusion models have gained popularity for adapting pre-trained
text-to-image models to generate images of specific topics with only a few
images. However, recent studies find that these models are vulnerable to minor
adversarial perturbation, and the fine-tuning performance is largely degraded
on corrupted datasets. Such characteristics are further exploited to craft
protective perturbation on sensitive images like portraits that prevent
unauthorized generation. In response, diffusion-based purification methods have
been proposed to remove these perturbations and retain generation performance.
However, existing works lack detailed analysis of the fundamental shortcut
learning vulnerability of personalized diffusion models and also turn to
over-purifying the images cause information loss. In this paper, we take a
closer look at the fine-tuning process of personalized diffusion models through
the lens of shortcut learning and propose a hypothesis that could explain the
underlying manipulation mechanisms of existing perturbation methods.
Specifically, we find that the perturbed images are greatly shifted from their
original paired prompt in the CLIP-based latent space. As a result, training
with this mismatched image-prompt pair creates a construction that causes the
models to dump their out-of-distribution noisy patterns to the identifier, thus
causing serious performance degradation. Based on this observation, we propose
a systematic approach to retain the training performance with purification that
realigns the latent image and its semantic meaning and also introduces
contrastive learning with a negative token to decouple the learning of wanted
clean identity and the unwanted noisy pattern, that shows strong potential
capacity against further adaptive perturbation.

摘要：<paragraph>個人化擴散模型因能以少數影像將預先訓練好的文字轉影像模型調整為產生特定主題的影像而廣受歡迎。然而，最近的研究發現這些模型容易受到輕微的對抗性擾動，並且微調效能會在損壞的資料集上大幅下降。這些特性進一步被利用來在敏感的影像（例如人像）上製作防護性擾動，以防止未經授權的產生。為了解決這個問題，已經提出基於擴散的淨化方法來移除這些擾動並保留產生效能。然而，現有的方法缺乏對個人化擴散模型的根本捷徑學習脆弱性的詳細分析，而且也會過度淨化影像而導致資訊遺失。在本文中，我們透過捷徑學習的觀點仔細檢視個人化擴散模型的微調過程，並提出一個假說，可以解釋現有擾動方法的潛在操縱機制。具體來說，我們發現擾動的影像在基於 CLIP 的潛在空間中大幅偏離其原始配對提示。因此，使用這個不匹配的影像提示對訓練資料進行訓練會產生一個結構，導致模型將其分佈外的雜訊模式傾倒到識別符號中，從而導致嚴重的效能下降。基於這個觀察，我們提出一個系統化的方法，以淨化來保留訓練效能，重新調整潛在影像及其語義意義，並引入具有負面標記的對比學習，以解耦所需的乾淨身分和不需要的雜訊模式的學習，這顯示出對進一步自適應擾動的強大潛在能力。</paragraph>

##### **Federated Graph Semantic and Structural Learning**
2406.18937v1 by Wenke Huang, Guancheng Wan, Mang Ye, Bo Du

Federated graph learning collaboratively learns a global graph neural network
with distributed graphs, where the non-independent and identically distributed
property is one of the major challenges. Most relative arts focus on
traditional distributed tasks like images and voices, incapable of graph
structures. This paper firstly reveals that local client distortion is brought
by both node-level semantics and graph-level structure. First, for node-level
semantics, we find that contrasting nodes from distinct classes is beneficial
to provide a well-performing discrimination. We pull the local node towards the
global node of the same class and push it away from the global node of
different classes. Second, we postulate that a well-structural graph neural
network possesses similarity for neighbors due to the inherent adjacency
relationships. However, aligning each node with adjacent nodes hinders
discrimination due to the potential class inconsistency. We transform the
adjacency relationships into the similarity distribution and leverage the
global model to distill the relation knowledge into the local model, which
preserves the structural information and discriminability of the local model.
Empirical results on three graph datasets manifest the superiority of the
proposed method over its counterparts.

摘要：<paragraph>聯邦圖形學習透過分散式圖形協作學習全球圖形神經網路，其中非獨立且相同分佈的屬性是一項重大挑戰。大多數相關技術專注於傳統的分布式任務，例如影像和語音，無法處理圖形結構。本文首先揭示，節點層級語意和圖形層級結構都會造成局部用戶端失真。首先，對於節點層級語意，我們發現對比不同類別的節點有助於提供效能良好的區分。我們將局部節點拉向同類別的全球節點，並將其推離不同類別的全球節點。其次，我們假設結構良好的圖形神經網路由於固有的鄰接關係，因此具有鄰近節點的相似性。然而，由於潛在的類別不一致，將每個節點與鄰接節點對齊會阻礙區分。我們將鄰接關係轉換為相似性分佈，並利用全球模型將關係知識萃取到局部模型中，這保留了局部模型的結構資訊和可區分性。在三個圖形資料集上的實證結果證明了所提出的方法優於其對應方法。</paragraph>

##### **The single-use restriction for register automata and transducers over infinite alphabets**
2406.18934v1 by Rafał Stefański

This thesis studies the single-use restriction for register automata and
transducers over infinite alphabets. The restriction requires that a
read-access to a register should have the side effect of destroying its
contents. This constraint results in robust classes of languages and
transductions. For automata models, we show that one-way register automata,
two-way register automata, and orbit-finite monoids have the same expressive
power. For transducer models, we show that single-use Mealy machines and
single-use two-way transducers admit versions of the Krohn-Rhodes decomposition
theorem. Moreover, single-use Mealy machines are equivalent to an algebraic
model called local algebraic semigroup transductions. Additionally, we show
that single-use two-way transducers are equivalent to single-use streaming
string transducers (SSTs) over infinite alphabets and to regular list functions
with atoms.
  Compared with the previous work arXiv:1907.10504, this thesis offers a
coherent narrative on the single-use restriction. We introduce an abstract
notion of single-use functions and use them to define all the discussed
single-use models. We also introduce and study the algebraic models of local
semigroup transduction and local rational semigroup transduction.

摘要：本論文探討了無限字母表上註冊自動機和轉換器的單次使用限制。此限制要求對註冊器的讀取存取應具有銷毀其內容的副作用。此限制會產生強健的語言和轉換類別。對於自動機模型，我們證明了單向註冊自動機、雙向註冊自動機和軌道有限單元具有相同的表達能力。對於轉換器模型，我們證明了單次使用 Mealy 機器和單次使用雙向轉換器允許使用 Krohn-Rhodes 分解定理。此外，單次使用 Mealy 機器等於稱為局部代數半群轉換的代數模型。此外，我們證明了單次使用雙向轉換器等於無限字母表上的單次使用串流字串轉換器 (SST) 和具有原子的正則清單函數。
與前一篇論文 arXiv:1907.10504 相比，本論文提供了關於單次使用限制的連貫敘述。我們引入了單次使用函數的抽象概念，並使用它們來定義所有討論過的單次使用模型。我們還介紹並研究了局部半群轉換和局部有理半群轉換的代數模型。

##### **Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation Network**
2406.18928v1 by Yehoshua Dissen, Shiry Yonash, Israel Cohen, Joseph Keshet

In the realm of automatic speech recognition (ASR), robustness in noisy
environments remains a significant challenge. Recent ASR models, such as
Whisper, have shown promise, but their efficacy in noisy conditions can be
further enhanced. This study is focused on recovering from packet loss to
improve the word error rate (WER) of ASR models. We propose using a front-end
adaptation network connected to a frozen ASR model. The adaptation network is
trained to modify the corrupted input spectrum by minimizing the criteria of
the ASR model in addition to an enhancement loss function. Our experiments
demonstrate that the adaptation network, trained on Whisper's criteria, notably
reduces word error rates across domains and languages in packet-loss scenarios.
This improvement is achieved with minimal affect to Whisper model's
foundational performance, underscoring our method's practicality and potential
in enhancing ASR models in challenging acoustic environments.

摘要：在自動語音辨識 (ASR) 領域中，在有噪音的環境中保持穩健性仍然是一項重大的挑戰。最近的 ASR 模型，例如 Whisper，已展現前景，但它們在有噪音條件下的效能可以進一步提升。本研究專注於從封包遺失中復原，以提升 ASR 模型的字元錯誤率 (WER)。我們建議使用連接到凍結 ASR 模型的前端適應網路。適應網路經過訓練，可以透過最小化 ASR 模型的準則以及增強損失函數來修改損壞的輸入頻譜。我們的實驗證明，針對 Whisper 的準則訓練的適應網路，可以在封包遺失的情況下顯著降低跨領域和跨語言的字元錯誤率。此項進步是在對 Whisper 模型的基本效能影響最小的情況下實現的，這突顯了我們的方法在增強具挑戰性聲學環境中的 ASR 模型方面的實用性和潛力。

##### **Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding**
2406.18925v1 by Jiwan Chung, Sungjae Lee, Minseo Kim, Seungju Han, Ashkan Yousefpour, Jack Hessel, Youngjae Yu

Visual arguments, often used in advertising or social causes, rely on images
to persuade viewers to do or believe something. Understanding these arguments
requires selective vision: only specific visual stimuli within an image are
relevant to the argument, and relevance can only be understood within the
context of a broader argumentative structure. While visual arguments are
readily appreciated by human audiences, we ask: are today's AI capable of
similar understanding?
  We collect and release VisArgs, an annotated corpus designed to make explicit
the (usually implicit) structures underlying visual arguments. VisArgs includes
1,611 images accompanied by three types of textual annotations: 5,112 visual
premises (with region annotations), 5,574 commonsense premises, and reasoning
trees connecting them to a broader argument. We propose three tasks over
VisArgs to probe machine capacity for visual argument understanding:
localization of premises, identification of premises, and deduction of
conclusions. Experiments demonstrate that 1) machines cannot fully identify the
relevant visual cues. The top-performing model, GPT-4-O, achieved an accuracy
of only 78.5%, whereas humans reached 98.0%. All models showed a performance
drop, with an average decrease in accuracy of 19.5%, when the comparison set
was changed from objects outside the image to irrelevant objects within the
image. Furthermore, 2) this limitation is the greatest factor impacting their
performance in understanding visual arguments. Most models improved the most
when given relevant visual premises as additional inputs, compared to other
inputs, for deducing the conclusion of the visual argument.

摘要：視覺論證經常使用在廣告或社會議題中，利用圖片說服觀眾採取行動或相信某件事。了解這些論證需要選擇性視覺：圖像中只有特定的視覺刺激與論證相關，而相關性只能在更廣泛的論證結構中理解。雖然視覺論證很容易被人類受眾理解，但我們想知道：當今的人工智慧是否能有類似的理解？
我們收集並發布 VisArgs，這是一個帶有註釋的語料庫，旨在明確視覺論證背後（通常是隱含的）結構。VisArgs 包含 1,611 張圖片，並附有三種類型的文本註釋：5,112 個視覺前提（帶有區域註釋）、5,574 個常識前提，以及將它們與更廣泛的論證聯繫起來的推理樹。我們提出了三項關於 VisArgs 的任務，以探討機器在視覺論證理解方面的能力：前提定位、前提識別和結論推論。實驗表明 1) 機器無法完全識別相關的視覺線索。表現最好的模型 GPT-4-O 僅達到 78.5% 的準確度，而人類達到 98.0%。當比較集從圖像外部對象變為圖像內部無關對象時，所有模型都表現出性能下降，準確度平均下降 19.5%。此外，2) 這種限制是影響它們理解視覺論證表現的最大因素。與其他輸入相比，大多數模型在獲得相關視覺前提作為附加輸入時，在推論視覺論證結論方面的進步最大。

##### **Time Matters: Scaling Laws for Any Budget**
2406.18922v1 by Itay Inbar, Luke Sernau

A primary cost driver for training large models is wall-clock training time.
We show that popular time estimates based on FLOPs are poor estimates, and
construct a more accurate proxy based on memory copies. We show that with some
simple accounting, we can estimate the training speed of a transformer model
from its hyperparameters. Combined with a scaling law curve like Chinchilla,
this lets us estimate the final loss of the model. We fit our estimate to real
data with a linear regression, and apply the result to rewrite Chinchilla in
terms of a model's estimated training time as opposed to the amount of training
data. This gives an expression for the loss in terms of the model's
hyperparameters alone. We show that this expression is accurate across a wide
range of model hyperparameter values, enabling us to analytically make
architectural decisions and train models more efficiently.

摘要：大型模型訓練的主要成本驅動因素是實際訓練時間。
我們顯示基於 FLOP 的熱門時間估計值是較差的估計值，
並根據記憶體複製建構更準確的代理。我們顯示，透過一些
簡單的計算，我們可以從其超參數估計Transformer模型的訓練速度。結合類似 Chinchilla 的比例定律曲線，
這讓我們可以估計模型的最終損失。我們使用線性回歸將我們的估計值套用到真實
資料，並將結果套用在 Chinchilla 中，以模型的預估訓練時間重寫，而不是訓練
資料量。這給出了僅根據模型超參數的損失表達式。我們顯示此表達式在廣泛
的模型超參數值範圍內是準確的，使我們能夠分析性地做出
架構決策並更有效率地訓練模型。

##### **Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data**
2406.18921v1 by Yiting Ran, Xintao Wang, Rui Xu, Xinfeng Yuan, Jiaqing Liang, Yanghua Xiao, Deqing Yang

Role-playing agents (RPA) have been a popular application area for large
language models (LLMs), attracting significant interest from both industry and
academia.While existing RPAs well portray the characters' knowledge and tones,
they face challenges in capturing their minds, especially for small
role-playing language models (RPLMs). In this paper, we propose to enhance
RPLMs via personality-indicative data. Specifically, we leverage questions from
psychological scales and distill advanced RPAs to generate dialogues that grasp
the minds of characters. Experimental results validate that RPLMs trained with
our dataset exhibit advanced role-playing capabilities for both general and
personality-related evaluations. Code and data are available at
\href{https://github.com/alienet1109/RolePersonality}{this URL}.

摘要：角色扮演代理（RPA）一直是大型语言模型（LLM）的热门应用领域，吸引了业界和学术界的极大兴趣。虽然现有的 RPA 很好的描绘了角色的知识和语调，但它们在捕捉角色的心智方面面临挑战，特别是对于小型角色扮演语言模型（RPLM）。在本文中，我们提出通过人格指示数据来增强 RPLM。具体来说，我们利用心理量表的题目并提炼高级 RPA 来生成对话，以掌握角色的心智。实验结果验证了使用我们的数据集训练的 RPLM 在一般和个性相关评估中都表现出高级的角色扮演能力。代码和数据可在\href{https://github.com/alienet1109/RolePersonality}{此网址}获得。

##### **TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**
2406.18916v1 by Wen Zhang, Long Jin, Yushan Zhu, Jiaoyan Chen, Zhiwei Huang, Junjie Wang, Yin Hua, Lei Liang, Huajun Chen

Natural language question answering (QA) over structured data sources such as
tables and knowledge graphs (KGs) have been widely investigated, for example
with Large Language Models (LLMs). The main solutions include question to
formal query parsing and retrieval-based answer generation. However, current
methods of the former often suffer from weak generalization, failing to dealing
with multiple sources simultaneously, while the later is limited in
trustfulness. In this paper, we propose UnifiedTQA, a trustful QA framework
that can simultaneously support multiple types of structured data in a unified
way. To this end, it adopts an LLM-friendly and unified knowledge
representation method called Condition Graph (CG), and uses an LLM and
demonstration-based two-level method for CG querying. For enhancement, it is
also equipped with dynamic demonstration retrieval. We have evaluated
UnifiedTQA with 5 benchmarks covering 3 types of structured data. It
outperforms 2 existing unified structured data QA methods and in comparison
with the baselines that are specific to a data type, it achieves
state-of-the-art on 2 of them. Further more, we demonstrates potential of our
method for more general QA tasks, QA over mixed structured data and QA across
structured data.

摘要：自然語言問答 (QA) 透過結構化資料來源（例如表格和知識圖譜 (KGs)）已廣泛研究，例如使用大型語言模型 (LLM)。主要解決方案包括問題轉換成形式化查詢解析和基於檢索的答案產生。然而，前者的現行方法通常會產生弱泛化，無法同時處理多個來源，而後者則受到可信度的限制。在本文中，我們提出 UnifiedTQA，一個可信賴的 QA 框架，能夠以統一的方式同時支援多種類型的結構化資料。為此，它採用了一種 LLM 友善且統一的知識表示方法，稱為條件圖 (CG)，並使用 LLM 和基於示範的二階方法進行 CG 查詢。為了加強，它還配備了動態示範檢索。我們已經使用涵蓋 3 種類型結構化資料的 5 個基準評估 UnifiedTQA。它優於 2 種現有的統一結構化資料 QA 方法，並且與特定於資料類型的基線相比，它在其中 2 個基準上達到了最先進的水平。此外，我們展示了我們的方法在更通用的 QA 任務、混合結構化資料的 QA 和跨結構化資料的 QA 中的潛力。

##### **Factor-Conditioned Speaking-Style Captioning**
2406.18910v1 by Atsushi Ando, Takafumi Moriya, Shota Horiguchi, Ryo Masumura

This paper presents a novel speaking-style captioning method that generates
diverse descriptions while accurately predicting speaking-style information.
Conventional learning criteria directly use original captions that contain not
only speaking-style factor terms but also syntax words, which disturbs learning
speaking-style information. To solve this problem, we introduce
factor-conditioned captioning (FCC), which first outputs a phrase representing
speaking-style factors (e.g., gender, pitch, etc.), and then generates a
caption to ensure the model explicitly learns speaking-style factors. We also
propose greedy-then-sampling (GtS) decoding, which first predicts
speaking-style factors deterministically to guarantee semantic accuracy, and
then generates a caption based on factor-conditioned sampling to ensure
diversity. Experiments show that FCC outperforms the original caption-based
training, and with GtS, it generates more diverse captions while keeping style
prediction performance.

摘要：本文提出了一種新穎的說話風格字幕方法，它能產生多樣化的描述，同時準確預測說話風格信息。
傳統的學習標準直接使用原始字幕，其中不僅包含說話風格因子術語，還包含語法詞，這會干擾學習說話風格信息。為了解決這個問題，我們引入了因子條件字幕 (FCC)，它首先輸出一個代表說話風格因子的短語（例如，性別、音高等），然後生成一個字幕以確保模型顯式地學習說話風格因子。我們還提出了貪婪然後採樣的（GtS）解碼，它首先確定性地預測說話風格因子以保證語義準確性，然後基於因子條件採樣生成一個字幕以保證多樣性。實驗表明，FCC 優於基於原始字幕的訓練，並且使用 GtS，它會生成更多樣化的字幕，同時保持風格預測性能。

##### **Historia Magistra Vitae: Dynamic Topic Modeling of Roman Literature using Neural Embeddings**
2406.18907v1 by Michael Ginn, Mans Hulden

Dynamic topic models have been proposed as a tool for historical analysis,
but traditional approaches have had limited usefulness, being difficult to
configure, interpret, and evaluate. In this work, we experiment with a recent
approach for dynamic topic modeling using BERT embeddings. We compare topic
models built using traditional statistical models (LDA and NMF) and the
BERT-based model, modeling topics over the entire surviving corpus of Roman
literature. We find that while quantitative metrics prefer statistical models,
qualitative evaluation finds better insights from the neural model.
Furthermore, the neural topic model is less sensitive to hyperparameter
configuration and thus may make dynamic topic modeling more viable for
historical researchers.

摘要：動態主題模型已被提議作為歷史分析的工具，但傳統方法的用途有限，因為難以配置、詮釋和評估。在這項工作中，我們使用 BERT 內嵌字元向量對動態主題建模的最新方法進行實驗。我們比較使用傳統統計模型（LDA 和 NMF）和 BERT 為基礎的模型所建立的主題模型，對羅馬文學中所有現存語料庫的主題進行建模。我們發現，雖然量化指標較偏好統計模型，但定性評估發現神經模型有更好的見解。此外，神經主題模型對超參數配置不太敏感，因此可能使動態主題建模對歷史研究人員來說更可行。

##### **Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets**
2406.18906v1 by Melanie Walsh, Anna Preus, Maria Antoniak

Large language models (LLMs) can now generate and recognize text in a wide
range of styles and genres, including highly specialized, creative genres like
poetry. But what do LLMs really know about poetry? What can they know about
poetry? We develop a task to evaluate how well LLMs recognize a specific aspect
of poetry, poetic form, for more than 20 forms and formal elements in the
English language. Poetic form captures many different poetic features,
including rhyme scheme, meter, and word or line repetition. We use this task to
reflect on LLMs' current poetic capabilities, as well as the challenges and
pitfalls of creating NLP benchmarks for poetry and for other creative tasks. In
particular, we use this task to audit and reflect on the poems included in
popular pretraining datasets. Our findings have implications for NLP
researchers interested in model evaluation, digital humanities and cultural
analytics scholars, and cultural heritage professionals.

摘要：大型語言模型 (LLM) 現在可以生成和辨識各種風格和類型的文字，包括高度專業化、詩歌等創意類型。但 LLM 對於詩歌真正了解多少？它們能了解詩歌哪些方面？我們開發了一項任務，用於評估 LLM 辨識特定詩歌面向（詩歌形式）的能力，涵蓋英語中 20 多種形式和形式元素。詩歌形式捕捉了許多不同的詩歌特徵，包括押韻格律、韻律和字詞或行重複。我們使用這項任務來探討 LLM 目前的詩歌能力，以及為詩歌和其他創意任務建立 NLP 基準時所面臨的挑戰和陷阱。特別是，我們使用這項任務來審查和探討熱門預訓練資料集中的詩歌。我們的發現對有興趣進行模型評估的 NLP 研究人員、數位人文和文化分析學者以及文化遺產專業人士具有啟示意義。

##### **The Rise of Artificial Intelligence in Educational Measurement: Opportunities and Ethical Challenges**
2406.18900v1 by Okan Bulut, Maggie Beiting-Parrish, Jodi M. Casabianca, Sharon C. Slater, Hong Jiao, Dan Song, Christopher M. Ormerod, Deborah Gbemisola Fabiyi, Rodica Ivan, Cole Walsh, Oscar Rios, Joshua Wilson, Seyma N. Yildirim-Erbasli, Tarid Wongvorachan, Joyce Xinle Liu, Bin Tan, Polina Morilova

The integration of artificial intelligence (AI) in educational measurement
has revolutionized assessment methods, enabling automated scoring, rapid
content analysis, and personalized feedback through machine learning and
natural language processing. These advancements provide timely, consistent
feedback and valuable insights into student performance, thereby enhancing the
assessment experience. However, the deployment of AI in education also raises
significant ethical concerns regarding validity, reliability, transparency,
fairness, and equity. Issues such as algorithmic bias and the opacity of AI
decision-making processes pose risks of perpetuating inequalities and affecting
assessment outcomes. Responding to these concerns, various stakeholders,
including educators, policymakers, and organizations, have developed guidelines
to ensure ethical AI use in education. The National Council of Measurement in
Education's Special Interest Group on AI in Measurement and Education (AIME)
also focuses on establishing ethical standards and advancing research in this
area. In this paper, a diverse group of AIME members examines the ethical
implications of AI-powered tools in educational measurement, explores
significant challenges such as automation bias and environmental impact, and
proposes solutions to ensure AI's responsible and effective use in education.

摘要：人工智慧（AI）整合在教育測量中已徹底改變評量方法，透過機器學習和自然語言處理，能自動計分、快速內容分析和個人化回饋。這些進展提供及時、一致的回饋和對學生表現的寶貴見解，從而增強評量體驗。然而，AI 在教育中的部署也引發了關於效度、信度、透明度、公平性和公正性的重大倫理問題。演算法偏誤和 AI 決策過程的不透明性等問題，會造成延續不平等和影響評量結果的風險。為了回應這些問題，包括教育工作者、政策制定者和組織在內的各個利害關係人制定了準則，以確保在教育中使用合乎倫理的 AI。國家測量委員會的測量和教育中的 AI 專業興趣小組 (AIME) 也著重於制定倫理標準和推進這方面的研究。在本文中，一群多元的 AIME 成員探討了 AI 驅動工具在教育測量中的倫理影響，探討了自動化偏誤和環境影響等重大挑戰，並提出了解決方案，以確保 AI 在教育中的負責任和有效使用。

##### **Autonomous Control of a Novel Closed Chain Five Bar Active Suspension via Deep Reinforcement Learning**
2406.18899v1 by Nishesh Singh, Sidharth Ramesh, Abhishek Shankar, Jyotishka Duttagupta, Leander Stephen D'Souza, Sanjay Singh

Planetary exploration requires traversal in environments with rugged
terrains. In addition, Mars rovers and other planetary exploration robots often
carry sensitive scientific experiments and components onboard, which must be
protected from mechanical harm. This paper deals with an active suspension
system focused on chassis stabilisation and an efficient traversal method while
encountering unavoidable obstacles. Soft Actor-Critic (SAC) was applied along
with Proportional Integral Derivative (PID) control to stabilise the chassis
and traverse large obstacles at low speeds. The model uses the rover's distance
from surrounding obstacles, the height of the obstacle, and the chassis'
orientation to actuate the control links of the suspension accurately.
Simulations carried out in the Gazebo environment are used to validate the
proposed active system.

摘要：行星探索需要在崎嶇的地形中穿越。此外，火星探測車和其他行星探測機器人通常會攜帶敏感的科學實驗和組件，必須保護這些組件免於機械損壞。本文探討了一個主動懸吊系統，專注於底盤穩定和在遇到不可避免的障礙物時的有效穿越方法。軟性動作-評論家 (SAC) 與比例積分微分 (PID) 控制一起應用，以穩定底盤並在低速下穿越大型障礙物。該模型使用探測車與周圍障礙物的距離、障礙物的高度以及底盤的方向來準確地驅動懸吊的控制連桿。在 Gazebo 環境中進行的模擬用於驗證所提出的主動系統。

##### **Can we teach language models to gloss endangered languages?**
2406.18895v1 by Michael Ginn, Mans Hulden, Alexis Palmer

Interlinear glossed text (IGT) is a popular format in language documentation
projects, where each morpheme is labeled with a descriptive annotation.
Automating the creation of interlinear glossed text can be desirable to reduce
annotator effort and maintain consistency across annotated corpora. Prior
research has explored a number of statistical and neural methods for
automatically producing IGT.
  As large language models (LLMs) have showed promising results across
multilingual tasks, even for rare, endangered languages, it is natural to
wonder whether they can be utilized for the task of generating IGT. We explore
whether LLMs can be effective at the task of interlinear glossing with
in-context learning, without any traditional training. We propose new
approaches for selecting examples to provide in-context, observing that
targeted selection can significantly improve performance. We find that
LLM-based methods beat standard transformer baselines, despite requiring no
training at all. These approaches still underperform state-of-the-art
supervised systems for the task, but are highly practical for researchers
outside of the NLP community, requiring minimal effort to use.

摘要：跨語言任務中，大型語言模型 (LLM) 已展現出令人滿意的成果，即使是對於罕見或瀕危語言，因此自然會好奇它們是否能用於產生 IGT 的任務。我們探討 LLM 是否能有效執行跨行註釋任務，透過情境學習，而無需任何傳統訓練。我們提出新的方法，用於選擇範例以提供情境，並觀察到目標選擇能顯著提升效能。我們發現，儘管 LLM-based 方法不需要任何訓練，但仍勝過標準的 transformer 基準。這些方法在任務上的表現仍不如最先進的監督式系統，但對於 NLP 社群以外的研究人員來說非常實用，使用時所需的努力極少。

##### **SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models**
2406.18880v1 by Vipul Rathore, Aniruddha Deb, Ankish Chandresh, Parag Singla, Mausam

Recently, very large language models (LLMs) have shown exceptional
performance on several English NLP tasks with just in-context learning (ICL),
but their utility in other languages is still underexplored. We investigate
their effectiveness for NLP tasks in low-resource languages (LRLs), especially
in the setting of zero-labelled cross-lingual transfer (0-CLT), where no
labelled training data for the target language is available -- however training
data from one or more related medium-resource languages (MRLs) is utilized,
alongside the available unlabeled test data for a target language. We introduce
Self-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT
setting.
  SSP is based on the key observation that LLMs output more accurate labels if
in-context exemplars are from the target language (even if their labels are
slightly noisy). To operationalize this, since target language training data is
not available in 0-CLT, SSP operates in two stages. In Stage I, using source
MRL training data, target language's test data is noisily labeled. In Stage II,
these noisy test data points are used as exemplars in ICL for further improved
labelling. Additionally, our implementation of SSP uses a novel Integer Linear
Programming (ILP)-based exemplar selection that balances similarity, prediction
confidence (when available) and label coverage. Experiments on three tasks and
eleven LRLs (from three regions) demonstrate that SSP strongly outperforms
existing SOTA fine-tuned and prompting-based baselines in 0-CLT setup.

摘要：最近，大型语言模型 (LLM) 在仅使用语境学习 (ICL) 的情况下，在多项英文自然语言处理任务上表现出色，但它们在其他语言中的效用仍未得到充分探索。我们调查了它们在低资源语言 (LRL) 中执行自然语言处理任务的有效性，尤其是在零标记跨语言迁移 (0-CLT) 的设置中，其中没有目标语言的标记训练数据可用——但来自一个或多个相关的中等资源语言 (MRL) 的训练数据被利用，以及目标语言的可用未标记测试数据。我们引入了自监督提示 (SSP)，这是一种针对 0-CLT 设置量身定制的新型 ICL 方法。
SSP 基于一个关键观察，即如果语境示例来自目标语言（即使它们的标签有点嘈杂），LLM 输出的标签会更准确。为了实现这一点，由于在 0-CLT 中没有目标语言训练数据，SSP 分两个阶段操作。在第一阶段，使用源 MRL 训练数据，对目标语言的测试数据进行噪声标记。在第二阶段，这些嘈杂的测试数据点被用作 ICL 中的示例，以进一步改进标记。此外，我们对 SSP 的实现使用了一种新颖的基于整数线性规划 (ILP) 的示例选择，它平衡了相似性、预测置信度（如果可用）和标签覆盖率。对三个任务和十一个 LRL（来自三个区域）的实验表明，SSP 在 0-CLT 设置中明显优于现有的 SOTA 微调和基于提示的基准。

##### **DeSTA: Enhancing Speech Language Models through Descriptive Speech-Text Alignment**
2406.18871v1 by Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, He Huang, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee

Recent speech language models (SLMs) typically incorporate pre-trained speech
models to extend the capabilities from large language models (LLMs). In this
paper, we propose a Descriptive Speech-Text Alignment approach that leverages
speech captioning to bridge the gap between speech and text modalities,
enabling SLMs to interpret and generate comprehensive natural language
descriptions, thereby facilitating the capability to understand both linguistic
and non-linguistic features in speech. Enhanced with the proposed approach, our
model demonstrates superior performance on the Dynamic-SUPERB benchmark,
particularly in generalizing to unseen tasks. Moreover, we discover that the
aligned model exhibits a zero-shot instruction-following capability without
explicit speech instruction tuning. These findings highlight the potential to
reshape instruction-following SLMs by incorporating rich, descriptive speech
captions.

摘要：最近的语音語言模型 (SLM) 通常會整合預先訓練好的語音模型，以擴充大型語言模型 (LLM) 的能力。在本文中，我們提出一個描述性語音文字對齊方法，利用語音字幕來彌合語音和文字模式之間的差距，讓 SLM 能夠詮釋並產生全面的自然語言描述，進而促進理解語音中語言和非語言特徵的能力。透過建議的方法強化後，我們的模型在 Dynamic-SUPERB 基準上展現出優異的效能，特別是在推廣到未見任務時。此外，我們發現對齊模型展現出零次學習指令遵循能力，無需明確的語音指令調整。這些發現突顯出透過整合豐富的描述性語音字幕，改造指令遵循 SLM 的潛力。

##### **Efficacy of Language Model Self-Play in Non-Zero-Sum Games**
2406.18872v1 by Austen Liao, Nicholas Tomlin, Dan Klein

Game-playing agents like AlphaGo have achieved superhuman performance through
self-play, which is theoretically guaranteed to yield optimal policies in
competitive games. However, most language tasks are partially or fully
cooperative, so it is an open question whether techniques like self-play can
effectively be used to improve language models. We empirically investigate this
question in a negotiation game setting known as Deal or No Deal (DoND).
Crucially, the objective in DoND can be modified to produce a fully cooperative
game, a strictly competitive one, or anything in between. We finetune language
models in self-play over multiple rounds of filtered behavior cloning in DoND
for each of these objectives. Contrary to expectations, we find that language
model self-play leads to significant performance gains in both cooperation and
competition with humans, suggesting that self-play and related techniques have
promise despite a lack of theoretical guarantees.

摘要：像 AlphaGo 等遊戲代理已透過自玩遊戲取得超人類的表現，理論上保證在競爭遊戲中產生最佳策略。然而，大多數語言任務是部分或完全合作的，因此自玩遊戲等技術是否能有效用於改善語言模型，仍是一個開放性的問題。我們在稱為「Deal or No Deal」(DoND) 的協商遊戲設定中，對此問題進行實證調查。至關重要的是，DoND 中的目標可以修改為產生完全合作的遊戲、嚴格的競爭遊戲，或介於兩者之間的任何遊戲。我們在 DoND 中對每個目標進行多輪過濾行為複製的自玩遊戲，微調語言模型。與預期相反，我們發現語言模型自玩遊戲會在與人類的合作和競爭中帶來顯著的效能提升，這表示儘管缺乏理論保證，自玩遊戲和相關技術仍有前景。

##### **Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification**
2406.18859v1 by Ziyu Yang, Santhosh Cherian, Slobodan Vucetic

Radiology reports are highly technical documents aimed primarily at
doctor-doctor communication. There has been an increasing interest in sharing
those reports with patients, necessitating providing them patient-friendly
simplifications of the original reports. This study explores the suitability of
large language models in automatically generating those simplifications. We
examine the usefulness of chain-of-thought and self-correction prompting
mechanisms in this domain. We also propose a new evaluation protocol that
employs radiologists and laypeople, where radiologists verify the factual
correctness of simplifications, and laypeople assess simplicity and
comprehension. Our experimental results demonstrate the effectiveness of
self-correction prompting in producing high-quality simplifications. Our
findings illuminate the preferences of radiologists and laypeople regarding
text simplification, informing future research on this topic.

摘要：放射科報告是高度技術性的文件，主要用於醫生與醫生之間的溝通。人們越來越有興趣與患者分享這些報告，因此必須為患者提供原始報告的患者友善簡化版。本研究探討大型語言模型在自動產生這些簡化版的適用性。我們檢視了鏈式思考和自訂正提示機制在這個領域中的效用。我們也提出一個新的評估協定，採用放射科醫師和外行人，其中放射科醫師驗證簡化版的正確性，而外行人則評估簡潔性和理解度。我們的實驗結果證明了自訂正提示在產生高品質簡化版上的有效性。我們的發現闡明了放射科醫師和外行人對文字簡化的偏好，為未來針對此主題的研究提供資訊。

##### **FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus**
2406.18856v1 by Yuxin Fu, Shijing Si, Leyi Mai, Xi-ang Li

Large Language Models (LLMs) have stunningly advanced the field of machine
translation, though their effectiveness within the financial domain remains
largely underexplored. To probe this issue, we constructed a fine-grained
Chinese-English parallel corpus of financial news called FFN. We acquired
financial news articles spanning between January 1st, 2014, to December 31,
2023, from mainstream media websites such as CNN, FOX, and China Daily. The
dataset consists of 1,013 main text and 809 titles, all of which have been
manually corrected. We measured the translation quality of two LLMs -- ChatGPT
and ERNIE-bot, utilizing BLEU, TER and chrF scores as the evaluation metrics.
For comparison, we also trained an OpenNMT model based on our dataset. We
detail problems of LLMs and provide in-depth analysis, intending to stimulate
further research and solutions in this largely uncharted territory. Our
research underlines the need to optimize LLMs within the specific field of
financial translation to ensure accuracy and quality.

摘要：大型語言模型 (LLM) 驚人地推進了機器翻譯領域，儘管它們在金融領域的有效性在很大程度上仍未得到探索。為了探討這個問題，我們構建了一個細粒度的中英平行語料庫，稱為 FFN。我們從 CNN、FOX 和中國日報等主流媒體網站獲取了從 2014 年 1 月 1 日到 2023 年 12 月 31 日的財經新聞文章。該數據集包含 1,013 篇正文和 809 個標題，所有這些都已手動更正。我們使用 BLEU、TER 和 chrF 分數作為評估指標，測量了兩個 LLM（ChatGPT 和 ERNIE-bot）的翻譯質量。為了進行比較，我們還根據我們的數據集訓練了一個 OpenNMT 模型。我們詳細說明了 LLM 的問題並提供深入分析，旨在激勵在這個很大程度上未知的領域進行進一步的研究和解決方案。我們的研究強調了在金融翻譯的特定領域優化 LLM 以確保準確性和質量的必要性。

##### **LICO: Large Language Models for In-Context Molecular Optimization**
2406.18851v1 by Tung Nguyen, Aditya Grover

Optimizing black-box functions is a fundamental problem in science and
engineering. To solve this problem, many approaches learn a surrogate function
that estimates the underlying objective from limited historical evaluations.
Large Language Models (LLMs), with their strong pattern-matching capabilities
via pretraining on vast amounts of data, stand out as a potential candidate for
surrogate modeling. However, directly prompting a pretrained language model to
produce predictions is not feasible in many scientific domains due to the
scarcity of domain-specific data in the pretraining corpora and the challenges
of articulating complex problems in natural language. In this work, we
introduce LICO, a general-purpose model that extends arbitrary base LLMs for
black-box optimization, with a particular application to the molecular domain.
To achieve this, we equip the language model with a separate embedding layer
and prediction layer, and train the model to perform in-context predictions on
a diverse set of functions defined over the domain. Once trained, LICO can
generalize to unseen molecule properties simply via in-context prompting. LICO
achieves state-of-the-art performance on PMO, a challenging molecular
optimization benchmark comprising over 20 objective functions.

摘要：優化黑箱函數是科學和工程中的基本問題。為了解決這個問題，許多方法會學習代理函數，從有限的歷史評估中估計底層目標。大型語言模型 (LLM) 透過在大量資料上進行預訓練，具備強大的模式匹配能力，成為代理建模的潛在候選者。然而，由於預訓練語料庫中缺乏特定領域的資料，以及用自然語言表達複雜問題的挑戰，直接提示預訓練的語言模型產生預測在許多科學領域中不可行。在這項工作中，我們引入了 LICO，這是一個通用模型，它擴充了任意基礎 LLM 以進行黑箱優化，特別應用於分子領域。為此，我們為語言模型配備了一個單獨的嵌入層和預測層，並訓練模型對定義在該領域上的各種函數執行情境預測。訓練後，LICO 可以透過情境提示對未見的分子屬性進行概化。LICO 在 PMO 上取得了最先進的效能，PMO 是包含超過 20 個目標函數的具有挑戰性的分子最佳化基準。

##### **Learning Retrieval Augmentation for Personalized Dialogue Generation**
2406.18847v1 by Qiushi Huang, Shuai Fu, Xubo Liu, Wenwu Wang, Tom Ko, Yu Zhang, Lilian Tang

Personalized dialogue generation, focusing on generating highly tailored
responses by leveraging persona profiles and dialogue context, has gained
significant attention in conversational AI applications. However, persona
profiles, a prevalent setting in current personalized dialogue datasets,
typically composed of merely four to five sentences, may not offer
comprehensive descriptions of the persona about the agent, posing a challenge
to generate truly personalized dialogues. To handle this problem, we propose
$\textbf{L}$earning Retrieval $\textbf{A}$ugmentation for
$\textbf{P}$ersonalized $\textbf{D}$ial$\textbf{O}$gue $\textbf{G}$eneration
($\textbf{LAPDOG}$), which studies the potential of leveraging external
knowledge for persona dialogue generation. Specifically, the proposed LAPDOG
model consists of a story retriever and a dialogue generator. The story
retriever uses a given persona profile as queries to retrieve relevant
information from the story document, which serves as a supplementary context to
augment the persona profile. The dialogue generator utilizes both the dialogue
history and the augmented persona profile to generate personalized responses.
For optimization, we adopt a joint training framework that collaboratively
learns the story retriever and dialogue generator, where the story retriever is
optimized towards desired ultimate metrics (e.g., BLEU) to retrieve content for
the dialogue generator to generate personalized responses. Experiments
conducted on the CONVAI2 dataset with ROCStory as a supplementary data source
show that the proposed LAPDOG method substantially outperforms the baselines,
indicating the effectiveness of the proposed method. The LAPDOG model code is
publicly available for further exploration.
https://github.com/hqsiswiliam/LAPDOG

摘要：<paragraph>個性化對話生成，專注於透過運用角色檔案和對話脈絡來產生高度客製化的回應，已在對話式 AI 應用程式中獲得顯著的關注。然而，角色檔案是目前個性化對話資料集中普遍的設定，通常僅由四到五個句子組成，可能無法提供關於代理人的角色之全面描述，對產生真正個性化的對話構成挑戰。為了處理這個問題，我們提出 $\textbf{L}$earning Retrieval $\textbf{A}$ugmentation for $\textbf{P}$ersonalized $\textbf{D}$ial$\textbf{O}$gue $\textbf{G}$eneration ($\textbf{LAPDOG}$)，探討運用外部知識進行角色對話生成的潛力。具體來說，所提出的 LAPDOG 模型包含一個故事檢索器和一個對話產生器。故事檢索器使用給定的角色檔案作為查詢，從故事文件中檢索相關資訊，作為補充脈絡來擴充角色檔案。對話產生器利用對話歷程和擴充的角色檔案來產生個性化的回應。為了最佳化，我們採用一個聯合訓練架構，協同學習故事檢索器和對話產生器，其中故事檢索器針對所需的最終指標（例如 BLEU）進行最佳化，以檢索內容供對話產生器產生個性化的回應。在 CONVAI2 資料集上進行的實驗，以 ROCStory 作為補充資料來源，顯示所提出的 LAPDOG 方法大幅優於基線，表示所提出的方法有效。LAPDOG 模型程式碼已公開，可供進一步探索。
https://github.com/hqsiswiliam/LAPDOG</paragraph>

##### **Retain, Blend, and Exchange: A Quality-aware Spatial-Stereo Fusion Approach for Event Stream Recognition**
2406.18845v1 by Lan Chen, Dong Li, Xiao Wang, Pengpeng Shao, Wei Zhang, Yaowei Wang, Yonghong Tian, Jin Tang

Existing event stream-based pattern recognition models usually represent the
event stream as the point cloud, voxel, image, etc., and design various deep
neural networks to learn their features. Although considerable results can be
achieved in simple cases, however, the model performance may be limited by
monotonous modality expressions, sub-optimal fusion, and readout mechanisms. In
this paper, we propose a novel dual-stream framework for event stream-based
pattern recognition via differentiated fusion, termed EFV++. It models two
common event representations simultaneously, i.e., event images and event
voxels. The spatial and three-dimensional stereo information can be learned
separately by utilizing Transformer and Graph Neural Network (GNN). We believe
the features of each representation still contain both efficient and redundant
features and a sub-optimal solution may be obtained if we directly fuse them
without differentiation. Thus, we divide each feature into three levels and
retain high-quality features, blend medium-quality features, and exchange
low-quality features. The enhanced dual features will be fed into the fusion
Transformer together with bottleneck features. In addition, we introduce a
novel hybrid interaction readout mechanism to enhance the diversity of features
as final representations. Extensive experiments demonstrate that our proposed
framework achieves state-of-the-art performance on multiple widely used event
stream-based classification datasets. Specifically, we achieve new
state-of-the-art performance on the Bullying10k dataset, i.e., $90.51\%$, which
exceeds the second place by $+2.21\%$. The source code of this paper has been
released on
\url{https://github.com/Event-AHU/EFV_event_classification/tree/EFVpp}.

摘要：現有的基於事件串流的模式辨識模型通常將事件串流表示為點雲、體素、影像等，並設計各種深度神經網路來學習其特徵。儘管在簡單案例中可以獲得相當的結果，但模型效能可能會受到單調的模態表達、次佳融合和讀出機制的限制。在本文中，我們提出了一個新的雙串流架構，用於透過差異化融合進行基於事件串流的模式辨識，稱為 EFV++。它同時建模了兩種常見的事件表示，即事件影像和事件體素。空間和三維立體資訊可以透過使用 Transformer 和圖神經網路 (GNN) 分別學習。我們相信每個表示的特徵仍然包含有效和冗餘的特徵，如果我們在沒有區分的情況下直接融合它們，可能會獲得次佳的解決方案。因此，我們將每個特徵分成三個層級，並保留高品質特徵、混合中品質特徵，並交換低品質特徵。增強的雙重特徵將與瓶頸特徵一起輸入融合 Transformer。此外，我們引入了一個新的混合互動讀出機制，以增強特徵的多樣性作為最終表示。廣泛的實驗證明，我們提出的架構在多個廣泛使用的基於事件串流的分類資料集上達到了最先進的效能。具體來說，我們在 Bullying10k 資料集上達到了新的最先進效能，即 90.51%，比第二名高出 +2.21%。本文的原始程式碼已在 https://github.com/Event-AHU/EFV_event_classification/tree/EFVpp 上發布。

##### **Disentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA**
2406.18839v1 by Elham J. Barezi, Parisa Kordjamshidi

We study the Knowledge-Based visual question-answering problem, for which
given a question, the models need to ground it into the visual modality to find
the answer. Although many recent works use question-dependent captioners to
verbalize the given image and use Large Language Models to solve the VQA
problem, the research results show they are not reasonably performing for
multi-hop questions. Our study shows that replacing a complex question with
several simpler questions helps to extract more relevant information from the
image and provide a stronger comprehension of it. Moreover, we analyze the
decomposed questions to find out the modality of the information that is
required to answer them and use a captioner for the visual questions and LLMs
as a general knowledge source for the non-visual KB-based questions. Our
results demonstrate the positive impact of using simple questions before
retrieving visual or non-visual information. We have provided results and
analysis on three well-known VQA datasets including OKVQA, A-OKVQA, and KRVQA,
and achieved up to 2% improvement in accuracy.

摘要：我們研究了基於知識的視覺問答問題，對於此問題，給定一個問題，模型需要將其基礎化為視覺模式以找出答案。儘管許多近期研究使用依賴問題的標題說明器將給定的影像口語化，並使用大型語言模型來解決 VQA 問題，但研究結果顯示它們對於多跳問題的執行並非合理。我們的研究顯示，將複雜問題替換為幾個較簡單的問題有助於從影像中萃取出更相關的資訊，並提供對其更強的理解。此外，我們分析分解的問題，找出回答它們所需的資訊模式，並使用標題說明器進行視覺問題，並將 LLM 作為非視覺 KB-based 問題的一般知識來源。我們的結果證明了在擷取視覺或非視覺資訊之前使用簡單問題的正面影響。我們在三個著名的 VQA 資料集，包括 OKVQA、A-OKVQA 和 KRVQA，上提供了結果和分析，並在準確度上獲得了高達 2% 的提升。

##### **OutlierTune: Efficient Channel-Wise Quantization for Large Language Models**
2406.18832v1 by Jinguang Wang, Yuexi Yin, Haifeng Sun, Qi Qi, Jingyu Wang, Zirui Zhuang, Tingting Yang, Jianxin Liao

Quantizing the activations of large language models (LLMs) has been a
significant challenge due to the presence of structured outliers. Most existing
methods focus on the per-token or per-tensor quantization of activations,
making it difficult to achieve both accuracy and hardware efficiency. To
address this problem, we propose OutlierTune, an efficient per-channel
post-training quantization (PTQ) method for the activations of LLMs.
OutlierTune consists of two components: pre-execution of dequantization and
symmetrization. The pre-execution of dequantization updates the model weights
by the activation scaling factors, avoiding the internal scaling and costly
additional computational overheads brought by the per-channel activation
quantization. The symmetrization further reduces the quantization differences
arising from the weight updates by ensuring the balanced numerical ranges
across different activation channels. OutlierTune is easy to implement and
hardware-efficient, introducing almost no additional computational overheads
during the inference. Extensive experiments show that the proposed framework
outperforms existing methods across multiple different tasks. Demonstrating
better generalization, this framework improves the Int6 quantization of the
instruction-tuning LLMs, such as OPT-IML, to the same level as half-precision
(FP16). Moreover, we have shown that the proposed framework is 1.48x faster
than the FP16 implementation while reducing approximately 2x memory usage.

摘要：量化大型语言模型 (LLM) 的激活一直是一项重大挑战，原因在于存在结构化异常值。大多数现有方法专注于激活的逐令牌或逐张量量化，这使得难以同时实现准确性和硬件效率。为了解决这个问题，我们提出了 OutlierTune，这是一种针对 LLM 激活的高效逐通道后训练量化 (PTQ) 方法。OutlierTune 包含两个组件：反量化的预执行和对称化。反量化的预执行通过激活比例因子更新模型权重，避免了逐通道激活量化带来的内部比例和昂贵的额外计算开销。对称化通过确保不同激活通道之间的数值范围平衡，进一步减少了由权重更新引起的量化差异。OutlierTune 易于实现且硬件高效，在推理期间几乎没有引入额外的计算开销。大量实验表明，所提出的框架在多个不同任务中优于现有方法。该框架展示了更好的泛化能力，将指令微调 LLM（例如 OPT-IML）的 Int6 量化提升到与半精度 (FP16) 相同的水平。此外，我们已经证明，所提出的框架比 FP16 实现快 1.48 倍，同时减少了大约 2 倍的内存使用量。

##### **A Survey on Privacy Attacks Against Digital Twin Systems in AI-Robotics**
2406.18812v1 by Ivan A. Fernandez, Subash Neupane, Trisha Chakraborty, Shaswata Mitra, Sudip Mittal, Nisha Pillai, Jingdao Chen, Shahram Rahimi

Industry 4.0 has witnessed the rise of complex robots fueled by the
integration of Artificial Intelligence/Machine Learning (AI/ML) and Digital
Twin (DT) technologies. While these technologies offer numerous benefits, they
also introduce potential privacy and security risks. This paper surveys privacy
attacks targeting robots enabled by AI and DT models. Exfiltration and data
leakage of ML models are discussed in addition to the potential extraction of
models derived from first-principles (e.g., physics-based). We also discuss
design considerations with DT-integrated robotics touching on the impact of ML
model training, responsible AI and DT safeguards, data governance and ethical
considerations on the effectiveness of these attacks. We advocate for a trusted
autonomy approach, emphasizing the need to combine robotics, AI, and DT
technologies with robust ethical frameworks and trustworthiness principles for
secure and reliable AI robotic systems.

摘要：工業 4.0 見證了複雜機器人的崛起，其推動力是人工智慧/機器學習 (AI/ML) 和數位分身 (DT) 技術的整合。雖然這些技術提供了許多好處，但它們也引入了潛在的隱私和安全風險。本文探討了針對由 AI 和 DT 模型啟用機器人的隱私攻擊。除了討論從第一原理 (例如，基於物理) 衍生的模型的潛在提取之外，還討論了 ML 模型的滲透和資料外洩。我們還討論了與 DT 整合機器人相關的設計考量，觸及 ML 模型訓練、負責任的 AI 和 DT 保障措施、資料治理和道德考量對這些攻擊的有效性的影響。我們提倡一個可信賴的自主方法，強調需要結合機器人、AI 和 DT 技術，並採用強大的道德架構和可信賴原則，以建立安全和可靠的 AI 機器人系統。

##### **Infinite Width Models That Work: Why Feature Learning Doesn't Matter as Much as You Think**
2406.18800v1 by Luke Sernau

Common infinite-width architectures such as Neural Tangent Kernels (NTKs)
have historically shown weak performance compared to finite models. This has
been attributed to the absence of feature learning. We show that this is not
the case. In fact, we show that infinite width NTK models are able to access
richer features than finite models by selecting relevant subfeatures from their
(infinite) feature vector. In fact, we show experimentally that NTKs
under-perform traditional finite models even when feature learning is
artificially disabled. Instead, weak performance is due to the fact that
existing constructions depend on weak optimizers like SGD. We provide an
infinite width limit based on ADAM-like learning dynamics and demonstrate
empirically that the resulting models erase this performance gap.

摘要：常見的無限寬度架構，例如神經切線核 (NTK)，
在歷史上顯示出與有限模型相比效能較差。這
歸因於缺乏特徵學習。我們表明情況並非如此。事實上，我們表明無限寬度 NTK 模型能夠透過從其
（無限）特徵向量中選擇相關子特徵來存取比有限模型更豐富的特徵。事實上，我們透過實驗表明，即使人工停用特徵學習，NTK
的效能仍低於傳統有限模型。取而代之的是，效能不佳是因為
現有的結構依賴於 SGD 等弱優化器。我們提供一個基於類似 ADAM 的學習動態的無限寬度限制，並實證證明由此產生的模型消除了這個效能差距。

##### **MUMU: Bootstrapping Multimodal Image Generation from Text-to-Image Data**
2406.18790v1 by William Berman, Alexander Peysakhovich

We train a model to generate images from multimodal prompts of interleaved
text and images such as "a <picture of a man> man and his <picture of a dog>
dog in an <picture of a cartoon> animated style." We bootstrap a multimodal
dataset by extracting semantically meaningful image crops corresponding to
words in the image captions of synthetically generated and publicly available
text-image data. Our model, MUMU, is composed of a vision-language model
encoder with a diffusion decoder and is trained on a single 8xH100 GPU node.
Despite being only trained on crops from the same image, MUMU learns to compose
inputs from different images into a coherent output. For example, an input of a
realistic person and a cartoon will output the same person in the cartoon
style, and an input of a standing subject and a scooter will output the subject
riding the scooter. As a result, our model generalizes to tasks such as style
transfer and character consistency. Our results show the promise of using
multimodal models as general purpose controllers for image generation.

摘要：我們訓練一個模型，從穿插文字和圖片的多模態提示中產生圖片，例如「<picture of a man> 一個男人和他的 <picture of a dog> 狗以 <picture of a cartoon> 動畫風格呈現。」我們透過萃取語義上有意義的圖片裁切，對應到合成產生和公開提供的文字圖片資料中的圖片標題中的文字，來建立一個多模態資料集。我們的模型 MUMU 由一個具有擴散解碼器的視覺語言模型編碼器組成，並在一個 8xH100 GPU 節點上訓練。儘管只在同一張圖片的裁切中訓練，MUMU 學會將來自不同圖片的輸入組成一個連貫的輸出。例如，一個真實人物和一個卡通的輸入，將輸出一個以卡通風格呈現的人物，而一個站立的主體和一個滑板車的輸入，將輸出一個騎著滑板車的主體。因此，我們的模型可以廣泛應用於樣式轉移和角色一致性等任務。我們的結果顯示出使用多模態模型作為圖片產生的一般用途控制器的前景。

##### **Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features**
2406.18783v1 by Jean Marie Tshimula, D'Jeff K. Nkashama, Jean Tshibangu Muabila, René Manassé Galekwa, Hugues Kanda, Maximilien V. Dialufuma, Mbuyi Mukendi Didier, Kalala Kalonji, Serge Mundele, Patience Kinshie Lenye, Tighana Wenge Basele, Aristarque Ilunga, Christian N. Mayemba, Nathanaël M. Kasoro, Selain K. Kasereka, Hardy Mikese, Pierre-Martin Tardif, Marc Frappier, Froduald Kabanza, Belkacem Chikhaoui, Shengrui Wang, Ali Mulenda Sumbu, Xavier Ndona, Raoul Kienge-Kienge Intudi

The increasing sophistication of cyber threats necessitates innovative
approaches to cybersecurity. In this paper, we explore the potential of
psychological profiling techniques, particularly focusing on the utilization of
Large Language Models (LLMs) and psycholinguistic features. We investigate the
intersection of psychology and cybersecurity, discussing how LLMs can be
employed to analyze textual data for identifying psychological traits of threat
actors. We explore the incorporation of psycholinguistic features, such as
linguistic patterns and emotional cues, into cybersecurity frameworks. \iffalse
Through case studies and experiments, we discuss the effectiveness of these
methods in enhancing threat detection and mitigation strategies.\fi Our
research underscores the importance of integrating psychological perspectives
into cybersecurity practices to bolster defense mechanisms against evolving
threats.

摘要：網路威脅日益複雜，因此需要創新的網路安全方法。在本文中，我們探討心理側寫技術的潛力，特別專注於利用大型語言模型 (LLM) 和心理語言學特徵。我們探討心理學和網路安全的交集，討論如何運用 LLM 分析文字資料，以辨識威脅者的心理特質。我們探討將心理語言學特徵（例如語言模式和情緒線索）納入網路安全架構中。\iffalse
透過案例研究和實驗，我們討論這些方法在增強威脅偵測和緩解策略方面的成效。\fi 我們的研究強調將心理觀點整合到網路安全實務中的重要性，以加強對抗不斷演變的威脅的防禦機制。

##### **Implicit Discourse Relation Classification For Nigerian Pidgin**
2406.18776v1 by Muhammed Saeed, Peter Bourgonje, Vera Demberg

Despite attempts to make Large Language Models multi-lingual, many of the
world's languages are still severely under-resourced. This widens the
performance gap between NLP and AI applications aimed at well-financed, and
those aimed at less-resourced languages. In this paper, we focus on Nigerian
Pidgin (NP), which is spoken by nearly 100 million people, but has
comparatively very few NLP resources and corpora. We address the task of
Implicit Discourse Relation Classification (IDRC) and systematically compare an
approach translating NP data to English and then using a well-resourced IDRC
tool and back-projecting the labels versus creating a synthetic discourse
corpus for NP, in which we translate PDTB and project PDTB labels, and then
train an NP IDR classifier. The latter approach of learning a "native" NP
classifier outperforms our baseline by 13.27\% and 33.98\% in f$_{1}$ score for
4-way and 11-way classification, respectively.

摘要：儘管嘗試讓大型語言模型多語言化，但世界上許多語言仍然嚴重缺乏資源。這擴大了 NLP 和 AI 應用之間的效能差距，這些應用程式針對資金充足的語言，而那些針對資源較少的語言。在本文中，我們專注於尼日利亞皮欽語 (NP)，它有將近 1 億人使用，但比較起來，NLP 資源和語料庫非常少。我們解決隱式話語關係分類 (IDRC) 的任務，並系統性地比較一種方法，將 NP 資料翻譯成英文，然後使用資源豐富的 IDRC 工具，並將標籤反向投影，與為 NP 建立合成話語語料庫，其中我們翻譯 PDTB 並投影 PDTB 標籤，然後訓練 NP IDR 分類器。後者學習「原生」NP 分類器的做法，在 4 向和 11 向分類的 f$_{1}$ 分數中，分別比我們的基準高出 13.27% 和 33.98%。

##### **WV-Net: A foundation model for SAR WV-mode satellite imagery trained using contrastive self-supervised learning on 10 million images**
2406.18765v1 by Yannik Glaser, Justin E. Stopa, Linnea M. Wolniewicz, Ralph Foster, Doug Vandemark, Alexis Mouche, Bertrand Chapron, Peter Sadowski

The European Space Agency's Copernicus Sentinel-1 (S-1) mission is a
constellation of C-band synthetic aperture radar (SAR) satellites that provide
unprecedented monitoring of the world's oceans. S-1's wave mode (WV) captures
20x20 km image patches at 5 m pixel resolution and is unaffected by cloud cover
or time-of-day. The mission's open data policy has made SAR data easily
accessible for a range of applications, but the need for manual image
annotations is a bottleneck that hinders the use of machine learning methods.
This study uses nearly 10 million WV-mode images and contrastive
self-supervised learning to train a semantic embedding model called WV-Net. In
multiple downstream tasks, WV-Net outperforms a comparable model that was
pre-trained on natural images (ImageNet) with supervised learning. Experiments
show improvements for estimating wave height (0.50 vs 0.60 RMSE using linear
probing), estimating near-surface air temperature (0.90 vs 0.97 RMSE), and
performing multilabel-classification of geophysical and atmospheric phenomena
(0.96 vs 0.95 micro-averaged AUROC). WV-Net embeddings are also superior in an
unsupervised image-retrieval task and scale better in data-sparse settings.
Together, these results demonstrate that WV-Net embeddings can support
geophysical research by providing a convenient foundation model for a variety
of data analysis and exploration tasks.

摘要：<paragraph>歐洲太空總署的哥白尼 Sentinel-1 (S-1) 任務是一組 C 波段合成孔徑雷達 (SAR) 衛星，可提供前所未有的全球海洋監測。S-1 的波浪模式 (WV) 以 5 公尺像素解析度擷取 20x20 公里影像區塊，不受雲層覆蓋或時間影響。這項任務的開放資料政策讓 SAR 資料容易取得，可應用於各種應用程式，但手動影像註解的需求是阻礙機器學習方法使用的瓶頸。本研究使用近 1 千萬張 WV 模式影像和對比自我監督學習，訓練一個名為 WV-Net 的語意嵌入模型。在多個下游任務中，WV-Net 優於使用監督學習在自然影像 (ImageNet) 上預先訓練的類似模型。實驗顯示，在估計波浪高度 (使用線性探測時，0.50 對上 0.60 RMSE)、估計近地表空氣溫度 (0.90 對上 0.97 RMSE) 和執行地球物理和氣象現象的多標籤分類 (0.96 對上 0.95 微平均 AUROC) 方面都有所進步。WV-Net 嵌入在無監督影像檢索任務中也較為出色，且在資料稀疏的設定中具有更好的擴充性。總而言之，這些結果證明 WV-Net 嵌入可透過為各種資料分析和探索任務提供便利基礎模型，來支援地球物理研究。</paragraph>

##### **Conformalized Link Prediction on Graph Neural Networks**
2406.18763v1 by Tianyi Zhao, Jian Kang, Lu Cheng

Graph Neural Networks (GNNs) excel in diverse tasks, yet their applications
in high-stakes domains are often hampered by unreliable predictions. Although
numerous uncertainty quantification methods have been proposed to address this
limitation, they often lack \textit{rigorous} uncertainty estimates. This work
makes the first attempt to introduce a distribution-free and model-agnostic
uncertainty quantification approach to construct a predictive interval with a
statistical guarantee for GNN-based link prediction. We term it as
\textit{conformalized link prediction.} Our approach builds upon conformal
prediction (CP), a framework that promises to construct statistically robust
prediction sets or intervals. We first theoretically and empirically establish
a permutation invariance condition for the application of CP in link prediction
tasks, along with an exact test-time coverage. Leveraging the important
structural information in graphs, we then identify a novel and crucial
connection between a graph's adherence to the power law distribution and the
efficiency of CP. This insight leads to the development of a simple yet
effective sampling-based method to align the graph structure with a power law
distribution prior to the standard CP procedure. Extensive experiments
demonstrate that for conformalized link prediction, our approach achieves the
desired marginal coverage while significantly improving the efficiency of CP
compared to baseline methods.

摘要：圖神經網路 (GNN) 在各種任務中表現出色，但它們在高風險領域的應用常常受到不可靠預測的阻礙。儘管已提出許多不確定性量化方法來解決此限制，但它們常常缺乏「嚴謹」的不確定性估計。這項工作首次嘗試引入無分佈且與模型無關的不確定性量化方法，以構建具備統計保證的預測區間，用於基於 GNN 的連結預測。我們稱之為「共形連結預測」。我們的做法建立在共形預測 (CP) 之上，這是一個承諾構建統計穩健的預測集或區間的框架。我們首先從理論上和經驗上為 CP 在連結預測任務中的應用建立置換不變條件，並進行精確的測試時間覆蓋率。利用圖表中的重要結構資訊，我們接著找出圖表對冪律分佈的遵循與 CP 效率之間的全新且關鍵關聯。此見解導致開發出一種簡單但有效的基於抽樣的，在標準 CP 程序之前將圖形結構與冪律分佈對齊的方法。廣泛的實驗證明，對於共形連結預測，我們的做法達到了所需的邊際覆蓋率，同時與基線方法相比，顯著提高了 CP 的效率。

##### **Categorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism**
2406.18762v1 by Shi Zong, Jimmy Lin

There have been a huge number of benchmarks proposed to evaluate how large
language models (LLMs) behave for logic inference tasks. However, it remains an
open question how to properly evaluate this ability. In this paper, we provide
a systematic overview of prior works on the logical reasoning ability of LLMs
for analyzing categorical syllogisms. We first investigate all the possible
variations for the categorical syllogisms from a purely logical perspective and
then examine the underlying configurations (i.e., mood and figure) tested by
the existing datasets. Our results indicate that compared to template-based
synthetic datasets, crowdsourcing approaches normally sacrifice the coverage of
configurations (i.e., mood and figure) of categorical syllogisms for more
language variations, thus bringing challenges to fully testing LLMs under
different situations. We then proceed to summarize the findings and
observations for the performances of LLMs to infer the validity of syllogisms
from the current literature. The error rate breakdown analyses suggest that the
interpretation of the quantifiers seems to be the current bottleneck that
limits the performances of the LLMs and is thus worth more attention. Finally,
we discuss several points that might be worth considering when researchers plan
on the future release of categorical syllogism datasets. We hope our work will
not only provide a timely review of the current literature regarding
categorical syllogisms, but also motivate more interdisciplinary research
between communities, specifically computational linguists and logicians.

摘要：<paragraph>已經提出大量基準來評估大型語言模型 (LLM) 在邏輯推理任務中的表現。然而，如何正確評估這種能力仍然是一個開放性的問題。在本文中，我們提供了對 LLM 邏輯推理能力的先前研究的系統性概述，用於分析範疇三段論。我們首先從純粹邏輯的角度調查範疇三段論的所有可能變體，然後檢查現有數據集測試的底層配置（即情態和圖形）。我們的結果表明，與基於模板的合成數據集相比，群眾外包方法通常會犧牲範疇三段論的配置（即情態和圖形）覆蓋範圍以獲得更多語言變體，從而給在不同情況下充分測試 LLM 帶來挑戰。然後，我們繼續總結從當前文獻中推論三段論有效性的 LLM 性能的發現和觀察。錯誤率分解分析表明，量詞的解釋似乎是當前限制 LLM 性能的瓶頸，因此值得更多關注。最後，我們討論了研究人員在規劃範疇三段論數據集的未來發布時可能值得考慮的幾個要點。我們希望我們的研究不僅能及時回顧有關範疇三段論的當前文獻，還能激勵社區之間進行更多跨學科研究，特別是計算語言學家和邏輯學家。</paragraph>

##### **A Stem-Agnostic Single-Decoder System for Music Source Separation Beyond Four Stems**
2406.18747v1 by Karn N. Watcharasupat, Alexander Lerch

Despite significant recent progress across multiple subtasks of audio source
separation, few music source separation systems support separation beyond the
four-stem vocals, drums, bass, and other (VDBO) setup. Of the very few current
systems that support source separation beyond this setup, most continue to rely
on an inflexible decoder setup that can only support a fixed pre-defined set of
stems. Increasing stem support in these inflexible systems correspondingly
requires increasing computational complexity, rendering extensions of these
systems computationally infeasible for long-tail instruments. In this work, we
propose Banquet, a system that allows source separation of multiple stems using
just one decoder. A bandsplit source separation model is extended to work in a
query-based setup in tandem with a music instrument recognition PaSST model. On
the MoisesDB dataset, Banquet, at only 24.9 M trainable parameters, approached
the performance level of the significantly more complex 6-stem Hybrid
Transformer Demucs on VDBO stems and outperformed it on guitar and piano. The
query-based setup allows for the separation of narrow instrument classes such
as clean acoustic guitars, and can be successfully applied to the extraction of
less common stems such as reeds and organs. Implementation is available at
https://github.com/kwatcharasupat/query-bandit.

摘要：儘管在音訊來源分離的許多子任務中取得了重大的進展，但只有少數音樂來源分離系統支援超過四個主幹的 vocal、鼓、貝斯和其他 (VDBO) 設定的分離。在極少數支援超過此設定的來源分離系統中，大多數系統仍依賴於不靈活的解碼器設定，只能支援一組預先定義的主幹。在這些不靈活的系統中增加主幹支援度，相對應地需要增加運算複雜度，使得這些系統的擴充對長尾樂器而言在運算上不可行。在這項工作中，我們提出 Banquet，一個使用一個解碼器就能分離多個主幹的系統。一個頻段分離來源分離模型被擴充，以與音樂樂器辨識 PaSST 模型串聯在一個基於查詢的設定中運作。在 MoisesDB 資料集上，Banquet 只有 24.9 M 個可訓練參數，接近複雜度高出許多、在 VDBO 主幹上有 6 個主幹的 Hybrid Transformer Demucs 的效能等級，且在吉他與鋼琴上表現得比它好。基於查詢的設定允許分離出狹窄的樂器類別，例如乾淨的原聲吉他，且能成功應用於較不常見的主幹（例如簧片與管風琴）的萃取。實作可於 https://github.com/kwatcharasupat/query-bandit 取得。

##### **Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with Large Language Models**
2406.18740v1 by Baharan Nouriinanloo, Maxime Lamothe

Large Language Models (LLMs) have been revolutionizing a myriad of natural
language processing tasks with their diverse zero-shot capabilities. Indeed,
existing work has shown that LLMs can be used to great effect for many tasks,
such as information retrieval (IR), and passage ranking. However, current
state-of-the-art results heavily lean on the capabilities of the LLM being
used. Currently, proprietary, and very large LLMs such as GPT-4 are the highest
performing passage re-rankers. Hence, users without the resources to leverage
top of the line LLMs, or ones that are closed source, are at a disadvantage. In
this paper, we investigate the use of a pre-filtering step before passage
re-ranking in IR. Our experiments show that by using a small number of human
generated relevance scores, coupled with LLM relevance scoring, it is
effectively possible to filter out irrelevant passages before re-ranking. Our
experiments also show that this pre-filtering then allows the LLM to perform
significantly better at the re-ranking task. Indeed, our results show that
smaller models such as Mixtral can become competitive with much larger
proprietary models (e.g., ChatGPT and GPT-4).

摘要：大型語言模型 (LLM) 已憑藉其多樣化的零次學習能力，徹底改變了無數自然語言處理任務。事實上，現有研究已顯示，LLM 可用於許多任務，例如資訊檢索 (IR) 和段落排序，並能發揮極佳的效果。然而，目前的最新技術成果極度仰賴所使用的 LLM 的能力。目前，封閉原始碼且規模極大的 LLM，例如 GPT-4，是效能最高的段落重新排序器。因此，沒有資源使用頂級 LLM 或封閉原始碼 LLM 的使用者處於劣勢。在本文中，我們探討在 IR 中使用段落重新排序前的預先篩選步驟。我們的實驗顯示，透過使用少量人工產生的相關性評分，並結合 LLM 相關性評分，在重新排序前有效過濾掉不相關的段落。我們的實驗也顯示，此預先篩選讓 LLM 在重新排序任務中表現大幅提升。事實上，我們的結果顯示，較小的模型，例如 Mixtral，可與規模更大的封閉原始碼模型（例如 ChatGPT 和 GPT-4）競爭。

##### **WavRx: a Disease-Agnostic, Generalizable, and Privacy-Preserving Speech Health Diagnostic Model**
2406.18731v1 by Yi Zhu, Tiago Falk

Speech is known to carry health-related attributes, which has emerged as a
novel venue for remote and long-term health monitoring. However, existing
models are usually tailored for a specific type of disease, and have been shown
to lack generalizability across datasets. Furthermore, concerns have been
raised recently towards the leakage of speaker identity from health embeddings.
To mitigate these limitations, we propose WavRx, a speech health diagnostics
model that captures the respiration and articulation related dynamics from a
universal speech representation. Our in-domain and cross-domain experiments on
six pathological speech datasets demonstrate WavRx as a new state-of-the-art
health diagnostic model. Furthermore, we show that the amount of speaker
identity entailed in the WavRx health embeddings is significantly reduced
without extra guidance during training. An in-depth analysis of the model was
performed, thus providing physiological interpretation of its improved
generalizability and privacy-preserving ability.

摘要：語音已知會承載與健康相關的屬性，這已成為遠距和長期健康監控的新途徑。然而，現有的模型通常針對特定類型的疾病量身打造，且已顯示出缺乏跨資料集的概括性。此外，最近已對從健康嵌入中洩漏說話者身分提出疑慮。為了減輕這些限制，我們提出 WavRx，這是一種語音健康診斷模型，它會擷取來自通用語音表示的呼吸和發音相關動態。我們在六個病理性語音資料集上進行的領域內和跨領域實驗，證明 WavRx 是一種新的最先進健康診斷模型。此外，我們顯示，在訓練期間沒有額外的指導下，WavRx 健康嵌入中包含的說話者身分數量已顯著減少。對模型進行了深入分析，從而提供了其改善的概括性和隱私保護能力的生理解釋。

##### **Jailbreaking LLMs with Arabic Transliteration and Arabizi**
2406.18725v1 by Mansour Al Ghanim, Saleh Almohaimeed, Mengxin Zheng, Yan Solihin, Qian Lou

This study identifies the potential vulnerabilities of Large Language Models
(LLMs) to 'jailbreak' attacks, specifically focusing on the Arabic language and
its various forms. While most research has concentrated on English-based prompt
manipulation, our investigation broadens the scope to investigate the Arabic
language. We initially tested the AdvBench benchmark in Standardized Arabic,
finding that even with prompt manipulation techniques like prefix injection, it
was insufficient to provoke LLMs into generating unsafe content. However, when
using Arabic transliteration and chatspeak (or arabizi), we found that unsafe
content could be produced on platforms like OpenAI GPT-4 and Anthropic Claude 3
Sonnet. Our findings suggest that using Arabic and its various forms could
expose information that might remain hidden, potentially increasing the risk of
jailbreak attacks. We hypothesize that this exposure could be due to the
model's learned connection to specific words, highlighting the need for more
comprehensive safety training across all language forms.

摘要：這項研究找出大型語言模型 (LLM) 對「越獄」攻擊的潛在漏洞，特別著重於阿拉伯語及其各種形式。雖然大多數研究都集中在以英文為基礎的提示操作，但我們的調查擴大了範圍以研究阿拉伯語。我們最初在標準阿拉伯語中測試了 AdvBench 基準，發現即使使用提示操作技術（例如前綴注入），也不足以激發 LLM 產生不安全的內容。然而，當使用阿拉伯語音譯和網路語言（或阿拉伯語）時，我們發現可以在 OpenAI GPT-4 和 Anthropic Claude 3 Sonnet 等平台上產生不安全的內容。我們的研究結果表明，使用阿拉伯語及其各種形式可能會揭露可能保持隱藏的資訊，進而可能增加越獄攻擊的風險。我們假設這種揭露可能是由於模型學習與特定字詞的關聯，這凸顯了在所有語言形式中進行更全面的安全訓練的必要性。

##### **Learn it or Leave it: Module Composition and Pruning for Continual Learning**
2406.18708v1 by Mingyang Wang, Heike Adel, Lukas Lange, Jannik Strötgen, Hinrich Schütze

In real-world environments, continual learning is essential for machine
learning models, as they need to acquire new knowledge incrementally without
forgetting what they have already learned. While pretrained language models
have shown impressive capabilities on various static tasks, applying them to
continual learning poses significant challenges, including avoiding
catastrophic forgetting, facilitating knowledge transfer, and maintaining
parameter efficiency. In this paper, we introduce MoCL-P, a novel lightweight
continual learning method that addresses these challenges simultaneously.
Unlike traditional approaches that continuously expand parameters for newly
arriving tasks, MoCL-P integrates task representation-guided module composition
with adaptive pruning, effectively balancing knowledge integration and
computational overhead. Our evaluation across three continual learning
benchmarks with up to 176 tasks shows that MoCL-P achieves state-of-the-art
performance and improves parameter efficiency by up to three times,
demonstrating its potential for practical applications where resource
requirements are constrained.

摘要：在真實世界的環境中，持續學習對於機器學習模型來說至關重要，因為它們需要逐步獲取新知識，同時不會忘記已經學到的東西。儘管預訓練語言模型在各種靜態任務上表現出令人印象深刻的能力，但將它們應用於持續學習會帶來重大挑戰，包括避免災難性遺忘、促進知識轉移和維持參數效率。在本文中，我們介紹了 MoCL-P，一種新穎的輕量級持續學習方法，可以同時解決這些挑戰。與為新任務持續擴展參數的傳統方法不同，MoCL-P 將任務表示引導的模組組成與自適應剪枝相整合，有效平衡知識整合和運算負擔。我們在包含多達 176 個任務的三個持續學習基準測試中進行的評估表明，MoCL-P 達到了最先進的效能，並將參數效率提高了三倍，證明了其在資源需求受限的實際應用中的潛力。

##### **Simulating The U.S. Senate: An LLM-Driven Agent Approach to Modeling Legislative Behavior and Bipartisanship**
2406.18702v1 by Zachary R. Baker, Zarif L. Azher

This study introduces a novel approach to simulating legislative processes
using LLM-driven virtual agents, focusing on the U.S. Senate Intelligence
Committee. We developed agents representing individual senators and placed them
in simulated committee discussions. The agents demonstrated the ability to
engage in realistic debate, provide thoughtful reflections, and find bipartisan
solutions under certain conditions. Notably, the simulation also showed promise
in modeling shifts towards bipartisanship in response to external
perturbations. Our results indicate that this LLM-driven approach could become
a valuable tool for understanding and potentially improving legislative
processes, supporting a broader pattern of findings highlighting how LLM-based
agents can usefully model real-world phenomena. Future works will focus on
enhancing agent complexity, expanding the simulation scope, and exploring
applications in policy testing and negotiation.

摘要：本研究介紹一種使用 LLM 驅動虛擬代理模擬立法程序的新方法，重點在美國參議院情報委員會。我們開發了代表個別參議員的代理，並將他們置於模擬委員會討論中。這些代理展示了在特定條件下參與現實辯論、提供深思熟慮的反思和找到兩黨解決方案的能力。值得注意的是，模擬也顯示出有望在應對外部擾動時朝著兩黨合作的方向轉變。我們的結果表明，這種 LLM 驅動的方法可能成為理解和潛在改善立法程序的寶貴工具，支持更廣泛的發現模式，強調基於 LLM 的代理如何能夠對現實世界現象進行建模。未來的研究重點將放在提高代理的複雜性、擴大模擬範圍以及探索在政策測試和協商中的應用。

##### **Fast Optimizer Benchmark**
2406.18701v1 by Simon Blauth, Tobias Bürger, Zacharias Häringer, Jörg Franke, Frank Hutter

In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed
for evaluating deep learning optimizers during their development. The benchmark
supports tasks from multiple domains such as computer vision, natural language
processing, and graph learning. The focus is on convenient usage, featuring
human-readable YAML configurations, SLURM integration, and plotting utilities.
FOB can be used together with existing hyperparameter optimization (HPO) tools
as it handles training and resuming of runs. The modular design enables
integration into custom pipelines, using it simply as a collection of tasks. We
showcase an optimizer comparison as a usage example of our tool. FOB can be
found on GitHub: https://github.com/automl/FOB.

摘要：在本文中，我們提出了快速優化器基準 (FOB)，這是一個用於在開發過程中評估深度學習優化器的工具。基準支持來自多個領域的任務，例如電腦視覺、自然語言處理和圖形學習。重點在於方便使用，具有人類可讀的 YAML 配置、SLURM 整合和繪圖程式。FOB 可以與現有的超參數優化 (HPO) 工具一起使用，因為它可以處理訓練和恢復運行。模組化設計能夠整合到自訂管線中，只需將其用作任務集合即可。我們展示了一個優化器比較作為我們工具的使用範例。FOB 可以從 GitHub 找到：https://github.com/automl/FOB。

##### **Sequence Graph Network for Online Debate Analysis**
2406.18696v1 by Quan Mai, Susan Gauch, Douglas Adams, Miaoqing Huang

Online debates involve a dynamic exchange of ideas over time, where
participants need to actively consider their opponents' arguments, respond with
counterarguments, reinforce their own points, and introduce more compelling
arguments as the discussion unfolds. Modeling such a complex process is not a
simple task, as it necessitates the incorporation of both sequential
characteristics and the capability to capture interactions effectively. To
address this challenge, we employ a sequence-graph approach. Building the
conversation as a graph allows us to effectively model interactions between
participants through directed edges. Simultaneously, the propagation of
information along these edges in a sequential manner enables us to capture a
more comprehensive representation of context. We also introduce a Sequence
Graph Attention layer to illustrate the proposed information update scheme. The
experimental results show that sequence graph networks achieve superior results
to existing methods in online debates.

摘要：網路辯論涉及隨著時間推移進行的動態觀念交流，其中參與者需要積極考慮對手的論點，以反論回應、強化自己的觀點，並隨著討論的展開提出更有說服力的論點。建模如此複雜的過程並非簡單的任務，因為它需要同時納入順序特性和有效捕捉互動的能力。為了應對這一挑戰，我們採用序列圖方法。將對話建構為圖表讓我們能夠透過有向邊有效地模擬參與者之間的互動。同時，沿著這些邊以順序方式傳播資訊使我們能夠捕捉更全面的脈絡表徵。我們還引入序列圖注意力層來說明所提出的資訊更新方案。實驗結果顯示，序列圖網路在網路辯論中獲得優於現有方法的卓越成果。

