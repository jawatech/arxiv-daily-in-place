
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-19**|**DEPICT: Diffusion-Enabled Permutation Importance for Image Classification Tasks**|Sarah Jabbour et.al.|[2407.14509v1](http://arxiv.org/abs/2407.14509v1)|null|
|**2024-07-19**|**Internal Consistency and Self-Feedback in Large Language Models: A Survey**|Xun Liang et.al.|[2407.14507v1](http://arxiv.org/abs/2407.14507v1)|[link](https://github.com/iaar-shanghai/icsfsurvey)|
|**2024-07-19**|**On Pre-training of Multimodal Language Models Customized for Chart Understanding**|Wan-Cyuan Fan et.al.|[2407.14506v1](http://arxiv.org/abs/2407.14506v1)|null|
|**2024-07-19**|**Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery**|Sukrut Rao et.al.|[2407.14499v1](http://arxiv.org/abs/2407.14499v1)|[link](https://github.com/neuroexplicit-saar/discover-then-name)|
|**2024-07-19**|**Evaluating the Reliability of Self-Explanations in Large Language Models**|Korbinian Randl et.al.|[2407.14487v1](http://arxiv.org/abs/2407.14487v1)|[link](https://github.com/k-randl/self-explaining_llms)|
|**2024-07-19**|**Explainable Post hoc Portfolio Management Financial Policy of a Deep Reinforcement Learning agent**|Alejandra de la Rica Escudero et.al.|[2407.14486v1](http://arxiv.org/abs/2407.14486v1)|[link](https://github.com/aleedelarica/XDRL-for-finance)|
|**2024-07-19**|**ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities**|Peng Xu et.al.|[2407.14482v1](http://arxiv.org/abs/2407.14482v1)|null|
|**2024-07-19**|**Check-Eval: A Checklist-based Approach for Evaluating Text Quality**|Jayr Pereira et.al.|[2407.14467v1](http://arxiv.org/abs/2407.14467v1)|null|
|**2024-07-19**|**AudioInsight: Detecting Social Contexts Relevant to Social Anxiety from Speech**|Varun Reddy et.al.|[2407.14458v1](http://arxiv.org/abs/2407.14458v1)|null|
|**2024-07-19**|**The Extrapolation Power of Implicit Models**|Juliette Decugis et.al.|[2407.14430v1](http://arxiv.org/abs/2407.14430v1)|null|
|**2024-07-19**|**Mixture of Experts with Mixture of Precisions for Tuning Quality of Service**|HamidReza Imani et.al.|[2407.14417v1](http://arxiv.org/abs/2407.14417v1)|null|
|**2024-07-19**|**System-1.x: Learning to Balance Fast and Slow Planning with Language Models**|Swarnadeep Saha et.al.|[2407.14414v1](http://arxiv.org/abs/2407.14414v1)|[link](https://github.com/swarnaHub/System-1.x)|
|**2024-07-19**|**DEAL: Disentangle and Localize Concept-level Explanations for VLMs**|Tang Li et.al.|[2407.14412v1](http://arxiv.org/abs/2407.14412v1)|null|
|**2024-07-19**|**The Vision of Autonomic Computing: Can LLMs Make It a Reality?**|Zhiyang Zhang et.al.|[2407.14402v1](http://arxiv.org/abs/2407.14402v1)|null|
|**2024-07-19**|**On the Impact of PRB Load Uncertainty Forecasting for Sustainable Open RAN**|Vaishnavi Kasuluru et.al.|[2407.14400v1](http://arxiv.org/abs/2407.14400v1)|null|
|**2024-07-19**|**GLAudio Listens to the Sound of the Graph**|Aurelio Sulser et.al.|[2407.14387v1](http://arxiv.org/abs/2407.14387v1)|[link](https://github.com/AurelioSulser/GLAudio)|
|**2024-07-19**|**The Sticky Path to Expressive Querying: Decidability of Navigational Queries under Existential Rules**|Piotr Ostropolski-Nalewaja et.al.|[2407.14384v1](http://arxiv.org/abs/2407.14384v1)|null|
|**2024-07-19**|**Enhancing Cloud-Native Resource Allocation with Probabilistic Forecasting Techniques in O-RAN**|Vaishnavi Kasuluru et.al.|[2407.14377v1](http://arxiv.org/abs/2407.14377v1)|null|
|**2024-07-19**|**SCoPE: Evaluating LLMs for Software Vulnerability Detection**|José Gonçalves et.al.|[2407.14372v1](http://arxiv.org/abs/2407.14372v1)|null|
|**2024-07-19**|**Open Artificial Knowledge**|Vadim Borisov et.al.|[2407.14371v1](http://arxiv.org/abs/2407.14371v1)|null|
|**2024-07-19**|**Towards Assessing Data Replication in Music Generation with Music Similarity Metrics on Raw Audio**|Roser Batlle-Roca et.al.|[2407.14364v1](http://arxiv.org/abs/2407.14364v1)|[link](https://github.com/roserbatlleroca/mira)|
|**2024-07-19**|**Stable Audio Open**|Zach Evans et.al.|[2407.14358v1](http://arxiv.org/abs/2407.14358v1)|[link](https://github.com/stability-ai/stable-audio-tools)|
|**2024-07-19**|**Improving Retrieval in Sponsored Search by Leveraging Query Context Signals**|Akash Kumar Mohankumar et.al.|[2407.14346v1](http://arxiv.org/abs/2407.14346v1)|null|
|**2024-07-19**|**LLMs left, right, and center: Assessing GPT's capabilities to label political bias from web domains**|Raphael Hernandes et.al.|[2407.14344v1](http://arxiv.org/abs/2407.14344v1)|null|
|**2024-07-19**|**Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model**|Kun Zhao et.al.|[2407.14326v1](http://arxiv.org/abs/2407.14326v1)|null|
|**2024-07-19**|**Multimodal Misinformation Detection using Large Vision-Language Models**|Sahar Tahmasebi et.al.|[2407.14321v1](http://arxiv.org/abs/2407.14321v1)|null|
|**2024-07-19**|**EmoCAM: Toward Understanding What Drives CNN-based Emotion Recognition**|Youssef Doulfoukar et.al.|[2407.14314v1](http://arxiv.org/abs/2407.14314v1)|null|
|**2024-07-19**|**How to Engage Your Readers? Generating Guiding Questions to Promote Active Reading**|Peng Cui et.al.|[2407.14309v1](http://arxiv.org/abs/2407.14309v1)|null|
|**2024-07-19**|**Complementary Learning for Real-World Model Failure Detection**|Daniel Bogdoll et.al.|[2407.14306v1](http://arxiv.org/abs/2407.14306v1)|[link](https://github.com/daniel-bogdoll/model_contradictions)|
|**2024-07-19**|**Foundation Models for Autonomous Robots in Unstructured Environments**|Hossein Naderi et.al.|[2407.14296v1](http://arxiv.org/abs/2407.14296v1)|null|
|**2024-07-19**|**CoVoSwitch: Machine Translation of Synthetic Code-Switched Text Based on Intonation Units**|Yeeun Kang et.al.|[2407.14295v1](http://arxiv.org/abs/2407.14295v1)|[link](https://github.com/sophiayk20/covoswitch)|
|**2024-07-19**|**How to Blend Concepts in Diffusion Models**|Giorgio Longari et.al.|[2407.14280v1](http://arxiv.org/abs/2407.14280v1)|null|
|**2024-07-19**|**Hyperparameter Optimization for Driving Strategies Based on Reinforcement Learning**|Nihal Acharya Adde et.al.|[2407.14262v1](http://arxiv.org/abs/2407.14262v1)|null|
|**2024-07-19**|**Voices in a Crowd: Searching for Clusters of Unique Perspectives**|Nikolas Vitsakis et.al.|[2407.14259v1](http://arxiv.org/abs/2407.14259v1)|null|
|**2024-07-19**|**Personalized Multi-tier Federated Learning**|Sourasekhar Banerjee et.al.|[2407.14251v1](http://arxiv.org/abs/2407.14251v1)|null|
|**2024-07-19**|**Conditioning Chat-GPT for information retrieval: the Unipa-GPT case study**|Irene Siragusa et.al.|[2407.14246v1](http://arxiv.org/abs/2407.14246v1)|null|
|**2024-07-19**|**KoMA: Knowledge-driven Multi-agent Framework for Autonomous Driving with Large Language Models**|Kemou Jiang et.al.|[2407.14239v1](http://arxiv.org/abs/2407.14239v1)|null|
|**2024-07-19**|**Words2Contact: Identifying Support Contacts from Verbal Instructions Using Foundation Models**|Dionis Totsila et.al.|[2407.14229v1](http://arxiv.org/abs/2407.14229v1)|null|
|**2024-07-19**|**Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**|Suvajit Patra et.al.|[2407.14224v1](http://arxiv.org/abs/2407.14224v1)|null|
|**2024-07-19**|**Braille-to-Speech Generator: Audio Generation Based on Joint Fine-Tuning of CLIP and Fastspeech2**|Chun Xu et.al.|[2407.14212v1](http://arxiv.org/abs/2407.14212v1)|null|
|**2024-07-19**|**Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction**|José Daniel Pascual-Triana et.al.|[2407.14210v1](http://arxiv.org/abs/2407.14210v1)|null|
|**2024-07-19**|**LeKUBE: A Legal Knowledge Update BEnchmark**|Changyue Wang et.al.|[2407.14192v1](http://arxiv.org/abs/2407.14192v1)|null|
|**2024-07-19**|**Automatic Classification of News Subjects in Broadcast News: Application to a Gender Bias Representation Analysis**|Valentin Pelloin et.al.|[2407.14180v1](http://arxiv.org/abs/2407.14180v1)|[link](https://github.com/ina-foss/is24_news_topic)|
|**2024-07-19**|**PassTSL: Modeling Human-Created Passwords through Two-Stage Learning**|Yangde Wang et.al.|[2407.14145v1](http://arxiv.org/abs/2407.14145v1)|null|
|**2024-07-19**|**I Know About "Up"! Enhancing Spatial Reasoning in Visual Language Models Through 3D Reconstruction**|Zaiqiao Meng et.al.|[2407.14133v1](http://arxiv.org/abs/2407.14133v1)|null|
|**2024-07-19**|**The Cardinality of Identifying Code Sets for Soccer Ball Graph with Application to Remote Sensing**|Anna L. D. Latour et.al.|[2407.14120v1](http://arxiv.org/abs/2407.14120v1)|[link](https://github.com/latower/SBG-bounds)|
|**2024-07-19**|**A3Rank: Augmentation Alignment Analysis for Prioritizing Overconfident Failing Samples for Deep Learning Models**|Zhengyuan Wei et.al.|[2407.14114v1](http://arxiv.org/abs/2407.14114v1)|null|
|**2024-07-19**|**TorchGT: A Holistic System for Large-scale Graph Transformer Training**|Meng Zhang et.al.|[2407.14106v1](http://arxiv.org/abs/2407.14106v1)|null|
|**2024-07-19**|**ParamsDrag: Interactive Parameter Space Exploration via Image-Space Dragging**|Guan Li et.al.|[2407.14100v1](http://arxiv.org/abs/2407.14100v1)|null|
|**2024-07-19**|**On the Robustness of Fully-Spiking Neural Networks in Open-World Scenarios using Forward-Only Learning Algorithms**|Erik B. Terres-Escudero et.al.|[2407.14097v1](http://arxiv.org/abs/2407.14097v1)|null|
|**2024-07-19**|**People use fast, goal-directed simulation to reason about novel games**|Cedegao E. Zhang et.al.|[2407.14095v1](http://arxiv.org/abs/2407.14095v1)|null|
|**2024-07-19**|**Integrated Push-and-Pull Update Model for Goal-Oriented Effective Communication**|Pouya Agheli et.al.|[2407.14092v1](http://arxiv.org/abs/2407.14092v1)|null|
|**2024-07-19**|**Impact of Model Size on Fine-tuned LLM Performance in Data-to-Text Generation: A State-of-the-Art Investigation**|Joy Mahapatra et.al.|[2407.14088v1](http://arxiv.org/abs/2407.14088v1)|null|
|**2024-07-19**|**An Improved Method for Class-specific Keyword Extraction: A Case Study in the German Business Registry**|Stephen Meisenbacher et.al.|[2407.14085v1](http://arxiv.org/abs/2407.14085v1)|[link](https://github.com/sjmeis/CSKE)|
|**2024-07-19**|**DisenSemi: Semi-supervised Graph Classification via Disentangled Representation Learning**|Yifan Wang et.al.|[2407.14081v1](http://arxiv.org/abs/2407.14081v1)|[link](https://github.com/jamesyifan/DisenSemi)|
|**2024-07-19**|**Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field**|Tobias Kerner et.al.|[2407.14076v1](http://arxiv.org/abs/2407.14076v1)|null|
|**2024-07-19**|**LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference**|Qichen Fu et.al.|[2407.14057v1](http://arxiv.org/abs/2407.14057v1)|null|
|**2024-07-19**|**Rasa: Building Expressive Speech Synthesis Systems for Indian Languages in Low-resource Settings**|Praveen Srinivasa Varadhan et.al.|[2407.14056v1](http://arxiv.org/abs/2407.14056v1)|null|
|**2024-07-19**|**Quantum Hamiltonian Embedding of Images for Data Reuploading Classifiers**|Peiyong Wang et.al.|[2407.14055v1](http://arxiv.org/abs/2407.14055v1)|null|
|**2024-07-19**|**Prompted Aspect Key Point Analysis for Quantitative Review Summarization**|An Quang Tang et.al.|[2407.14049v1](http://arxiv.org/abs/2407.14049v1)|[link](https://github.com/antangrocket1312/pakpa)|
|**2024-07-19**|**ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?**|Siddhant Waghjale et.al.|[2407.14044v1](http://arxiv.org/abs/2407.14044v1)|[link](https://github.com/codeeff/ecco)|
|**2024-07-19**|**BERTer: The Efficient One**|Pradyumna Saligram et.al.|[2407.14039v1](http://arxiv.org/abs/2407.14039v1)|null|
|**2024-07-19**|**HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research**|Prerana Sanjay Kulkarni et.al.|[2407.14030v1](http://arxiv.org/abs/2407.14030v1)|null|
|**2024-07-19**|**TTA-OOD: Test-time Augmentation for Improving Out-of-Distribution Detection in Gastrointestinal Vision**|Sandesh Pokhrel et.al.|[2407.14024v1](http://arxiv.org/abs/2407.14024v1)|null|
|**2024-07-19**|**Multi-modal Relation Distillation for Unified 3D Representation Learning**|Huiqun Wang et.al.|[2407.14007v1](http://arxiv.org/abs/2407.14007v1)|null|
|**2024-07-19**|**Clinical Reading Comprehension with Encoder-Decoder Models Enhanced by Direct Preference Optimization**|Md Sultan Al Nahian et.al.|[2407.14000v1](http://arxiv.org/abs/2407.14000v1)|null|
|**2024-07-19**|**NeLLCom-X: A Comprehensive Neural-Agent Framework to Simulate Language Learning and Group Communication**|Yuchen Lian et.al.|[2407.13999v1](http://arxiv.org/abs/2407.13999v1)|null|
|**2024-07-19**|**RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering**|Rujun Han et.al.|[2407.13998v1](http://arxiv.org/abs/2407.13998v1)|[link](https://github.com/awslabs/rag-qa-arena)|
|**2024-07-19**|**LLAssist: Simple Tools for Automating Literature Review Using Large Language Models**|Christoforus Yoga Haryanto et.al.|[2407.13993v1](http://arxiv.org/abs/2407.13993v1)|[link](https://github.com/cyharyanto/llassist)|
|**2024-07-19**|**Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**|Quan Li et.al.|[2407.13989v1](http://arxiv.org/abs/2407.13989v1)|null|
|**2024-07-19**|**Reexamining Racial Disparities in Automatic Speech Recognition Performance: The Role of Confounding by Provenance**|Changye Li et.al.|[2407.13982v1](http://arxiv.org/abs/2407.13982v1)|[link](https://github.com/LinguisticAnomalies/confounding-ASR)|
|**2024-07-19**|**Optimizing Agricultural Order Fulfillment Systems: A Hybrid Tree Search Approach**|Pranay Thangeda et.al.|[2407.13968v1](http://arxiv.org/abs/2407.13968v1)|null|
|**2024-07-19**|**Knowledge Distillation Approaches for Accurate and Efficient Recommender System**|SeongKu Kang et.al.|[2407.13952v1](http://arxiv.org/abs/2407.13952v1)|null|
|**2024-07-18**|**Assurance of AI Systems From a Dependability Perspective**|Robin Bloomfield et.al.|[2407.13948v1](http://arxiv.org/abs/2407.13948v1)|null|
|**2024-07-18**|**FANTAstic SEquences and Where to Find Them: Faithful and Efficient API Call Generation through State-tracked Constrained Decoding and Reranking**|Zhuoer Wang et.al.|[2407.13945v1](http://arxiv.org/abs/2407.13945v1)|null|
|**2024-07-18**|**Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction**|Suma Bailis et.al.|[2407.13943v1](http://arxiv.org/abs/2407.13943v1)|null|
|**2024-07-18**|**Unmasking Social Bots: How Confident Are We?**|James Giroux et.al.|[2407.13929v1](http://arxiv.org/abs/2407.13929v1)|[link](https://github.com/wmdataphys/UncertaintyAwareBotDetection)|
|**2024-07-18**|**BiasDPO: Mitigating Bias in Language Models through Direct Preference Optimization**|Ahmed Allam et.al.|[2407.13928v1](http://arxiv.org/abs/2407.13928v1)|null|
|**2024-07-18**|**Synthetic Counterfactual Faces**|Guruprasad V Ramesh et.al.|[2407.13922v1](http://arxiv.org/abs/2407.13922v1)|null|
|**2024-07-18**|**DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention**|Xiaoya Tang et.al.|[2407.13920v1](http://arxiv.org/abs/2407.13920v1)|null|
|**2024-07-18**|**Crafting Efficient Fine-Tuning Strategies for Large Language Models**|Michael Oliver et.al.|[2407.13906v1](http://arxiv.org/abs/2407.13906v1)|null|
|**2024-07-18**|**Uncovering Political Bias in Emotion Inference Models: Implications for sentiment analysis in social science research**|Hubert Plisiecki et.al.|[2407.13891v1](http://arxiv.org/abs/2407.13891v1)|null|
|**2024-07-18**|**Learning Goal-Conditioned Representations for Language Reward Models**|Vaskar Nath et.al.|[2407.13887v1](http://arxiv.org/abs/2407.13887v1)|[link](https://github.com/vaskarnathscale/goal-conditioned-rm)|
|**2024-07-18**|**Enhancing Worldwide Image Geolocation by Ensembling Satellite-Based Ground-Level Attribute Predictors**|Michael J. Bianco et.al.|[2407.13862v1](http://arxiv.org/abs/2407.13862v1)|null|
|**2024-07-18**|**Phi-3 Safety Post-Training: Aligning Language Models with a "Break-Fix" Cycle**|Emman Haider et.al.|[2407.13833v1](http://arxiv.org/abs/2407.13833v1)|null|
|**2024-07-18**|**Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data**|Charles Jin et.al.|[2407.13765v1](http://arxiv.org/abs/2407.13765v1)|null|
|**2024-07-18**|**Neural Network Tire Force Modeling for Automated Drifting**|Nicholas Drake Broadbent et.al.|[2407.13760v1](http://arxiv.org/abs/2407.13760v1)|null|
|**2024-07-18**|**Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models**|Zhuo Chen et.al.|[2407.13757v1](http://arxiv.org/abs/2407.13757v1)|null|
|**2024-07-18**|**LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation**|David Schlangen et.al.|[2407.13744v1](http://arxiv.org/abs/2407.13744v1)|null|
|**2024-07-18**|**CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications**|Mirza Masfiqur Rahman et.al.|[2407.13742v1](http://arxiv.org/abs/2407.13742v1)|null|
|**2024-07-18**|**Scaling Granite Code Models to 128K Context**|Matt Stallone et.al.|[2407.13739v1](http://arxiv.org/abs/2407.13739v1)|null|
|**2024-07-18**|**Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review**|Masatoshi Uehara et.al.|[2407.13734v1](http://arxiv.org/abs/2407.13734v1)|[link](https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq)|
|**2024-07-18**|**Baba Is AI: Break the Rules to Beat the Benchmark**|Nathan Cloos et.al.|[2407.13729v1](http://arxiv.org/abs/2407.13729v1)|null|
|**2024-07-18**|**CoDefeater: Using LLMs To Find Defeaters in Assurance Cases**|Usman Gohar et.al.|[2407.13717v1](http://arxiv.org/abs/2407.13717v1)|[link](https://gitlab.com/anonymousdot/codefeater)|
|**2024-07-18**|**FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning**|Tristan Cinquin et.al.|[2407.13711v1](http://arxiv.org/abs/2407.13711v1)|null|
|**2024-07-18**|**Understanding Reference Policies in Direct Preference Optimization**|Yixin Liu et.al.|[2407.13709v1](http://arxiv.org/abs/2407.13709v1)|null|
|**2024-07-18**|**ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free Hallucination Detection**|Janek Herrlein et.al.|[2407.13702v1](http://arxiv.org/abs/2407.13702v1)|[link](https://github.com/janekh24/anhalten)|
|**2024-07-18**|**Cross-Task Attack: A Self-Supervision Generative Framework Based on Attention Shift**|Qingyuan Zeng et.al.|[2407.13700v1](http://arxiv.org/abs/2407.13700v1)|null|
|**2024-07-18**|**A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**|Shaina Raza et.al.|[2407.13699v1](http://arxiv.org/abs/2407.13699v1)|null|
|**2024-07-18**|**Benchmark Agreement Testing Done Right: A Guide for LLM Benchmark Evaluation**|Yotam Perlitz et.al.|[2407.13696v1](http://arxiv.org/abs/2407.13696v1)|[link](https://github.com/ibm/benchbench)|

#### Abstracts
##### **DEPICT: Diffusion-Enabled Permutation Importance for Image Classification Tasks**
2407.14509v1 by Sarah Jabbour, Gregory Kondas, Ella Kazerooni, Michael Sjoding, David Fouhey, Jenna Wiens

We propose a permutation-based explanation method for image classifiers.
Current image-model explanations like activation maps are limited to
instance-based explanations in the pixel space, making it difficult to
understand global model behavior. In contrast, permutation based explanations
for tabular data classifiers measure feature importance by comparing model
performance on data before and after permuting a feature. We propose an
explanation method for image-based models that permutes interpretable concepts
across dataset images. Given a dataset of images labeled with specific concepts
like captions, we permute a concept across examples in the text space and then
generate images via a text-conditioned diffusion model. Feature importance is
then reflected by the change in model performance relative to unpermuted data.
When applied to a set of concepts, the method generates a ranking of feature
importance. We show this approach recovers underlying model feature importance
on synthetic and real-world image classification tasks.

摘要：我們提出了一種基於排列的影像分類器解釋方法。
當前的影像模型解釋，例如激活映射，僅限於像素空間中的基於實例的解釋，這使得難以理解全局模型行為。相反，基於排列的表格資料分類器解釋透過比較特徵置換前後的模型效能來衡量特徵重要性。我們提出了一種基於影像的模型解釋方法，該方法會在資料集影像中置換可解釋的概念。給定標記有特定概念（例如標題）的影像資料集，我們會在文字空間中的範例中置換一個概念，然後透過文字條件擴散模型產生影像。特徵重要性會反映在模型效能相對於未置換資料的變化。當應用於一組概念時，此方法會產生特徵重要性的排名。我們展示此方法在合成和真實世界的影像分類任務中恢復了底層模型特徵重要性。

##### **Internal Consistency and Self-Feedback in Large Language Models: A Survey**
2407.14507v1 by Xun Liang, Shichao Song, Zifan Zheng, Hanyu Wang, Qingchen Yu, Xunkai Li, Rong-Hua Li, Feiyu Xiong, Zhiyu Li

Large language models (LLMs) are expected to respond accurately but often
exhibit deficient reasoning or generate hallucinatory content. To address
these, studies prefixed with ``Self-'' such as Self-Consistency, Self-Improve,
and Self-Refine have been initiated. They share a commonality: involving LLMs
evaluating and updating itself to mitigate the issues. Nonetheless, these
efforts lack a unified perspective on summarization, as existing surveys
predominantly focus on categorization without examining the motivations behind
these works.
  In this paper, we summarize a theoretical framework, termed Internal
Consistency, which offers unified explanations for phenomena such as the lack
of reasoning and the presence of hallucinations. Internal Consistency assesses
the coherence among LLMs' latent layer, decoding layer, and response layer
based on sampling methodologies. Expanding upon the Internal Consistency
framework, we introduce a streamlined yet effective theoretical framework
capable of mining Internal Consistency, named Self-Feedback. The Self-Feedback
framework consists of two modules: Self-Evaluation and Self-Update. This
framework has been employed in numerous studies.
  We systematically classify these studies by tasks and lines of work;
summarize relevant evaluation methods and benchmarks; and delve into the
concern, ``Does Self-Feedback Really Work?'' We propose several critical
viewpoints, including the ``Hourglass Evolution of Internal Consistency'',
``Consistency Is (Almost) Correctness'' hypothesis, and ``The Paradox of Latent
and Explicit Reasoning''. Furthermore, we outline promising directions for
future research. We have open-sourced the experimental code, reference list,
and statistical data, available at
\url{https://github.com/IAAR-Shanghai/ICSFSurvey}.

摘要：大型語言模型 (LLM) 預期會做出準確的回應，但經常展現出推理不足或產生幻覺內容。為了解決這些問題，已經啟動了以「Self-」為前綴的研究，例如 Self-Consistency、Self-Improve 和 Self-Refine。它們有一個共同點：讓 LLM 自我評估和更新以減輕這些問題。儘管如此，這些努力缺乏對摘要的統一觀點，因為現有調查主要集中在分類上，而沒有探討這些作品背後的動機。
在本文中，我們總結了一個稱為內部一致性的理論架構，它為推理不足和幻覺出現等現象提供了統一的解釋。內部一致性根據抽樣方法評估 LLM 的潛在層、解碼層和回應層之間的相干性。在內部一致性架構的基礎上，我們引入了一個簡化但有效的理論架構，能夠挖掘內部一致性，稱為自回饋。自回饋架構包含兩個模組：自我評估和自我更新。這個架構已經被應用於許多研究中。
我們根據任務和工作領域系統地對這些研究進行分類；總結相關的評估方法和基準；並深入探討「自回饋真的有效嗎？」這個問題。我們提出了幾個批判觀點，包括「內部一致性的沙漏演化」、「一致性（幾乎）等於正確性」假說，以及「潛在和明確推理的悖論」。此外，我們概述了未來研究的有希望的方向。我們已經開源了實驗代碼、參考清單和統計數據，可在以下網址取得：
\url{https://github.com/IAAR-Shanghai/ICSFSurvey}。

##### **On Pre-training of Multimodal Language Models Customized for Chart Understanding**
2407.14506v1 by Wan-Cyuan Fan, Yen-Chun Chen, Mengchen Liu, Lu Yuan, Leonid Sigal

Recent studies customizing Multimodal Large Language Models (MLLMs) for
domain-specific tasks have yielded promising results, especially in the field
of scientific chart comprehension. These studies generally utilize visual
instruction tuning with specialized datasets to enhance question and answer
(QA) accuracy within the chart domain. However, they often neglect the
fundamental discrepancy between natural image-caption pre-training data and
digital chart image-QA data, particularly in the models' capacity to extract
underlying numeric values from charts. This paper tackles this oversight by
exploring the training processes necessary to improve MLLMs' comprehension of
charts. We present three key findings: (1) Incorporating raw data values in
alignment pre-training markedly improves comprehension of chart data. (2)
Replacing images with their textual representation randomly during end-to-end
fine-tuning transfer the language reasoning capability to chart interpretation
skills. (3) Requiring the model to first extract the underlying chart data and
then answer the question in the fine-tuning can further improve the accuracy.
Consequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chart
comprehension. CHOPINLLM effectively interprets various types of charts,
including unannotated ones, while maintaining robust reasoning abilities.
Furthermore, we establish a new benchmark to evaluate MLLMs' understanding of
different chart types across various comprehension levels. Experimental results
show that CHOPINLLM exhibits strong performance in understanding both annotated
and unannotated charts across a wide range of types.

摘要：<paragraph>最近針對特定領域任務自訂多模態大型語言模型 (MMLM) 的研究已產生令人振奮的成果，特別是在科學圖表理解的領域中。這些研究通常利用視覺指令微調和專門的資料集，以提升圖表領域中的問答 (QA) 準確度。然而，它們常常忽略自然影像標題預訓練資料和數位圖表影像 QA 資料之間的基本差異，特別是在模型從圖表中擷取基礎數值的能力上。本文透過探討必要的訓練流程來改善 MLLM 對圖表的理解，進而解決這個疏忽。我們提出三項主要發現：(1) 在對齊預訓練中納入原始資料值顯著提升對圖表資料的理解。(2) 在端對端微調過程中隨機用文字表示取代影像，將語言推理能力轉移到圖表解讀技巧上。(3) 要求模型先擷取基礎圖表資料，然後在微調中回答問題，可以進一步提升準確度。因此，我們引入了 CHOPINLLM，一種針對深入圖表理解而量身打造的 MLLM。CHOPINLLM 有效地解讀各種類型的圖表，包括未註解的圖表，同時維持強健的推理能力。此外，我們建立了一個新的基準來評估 MLLM 對不同圖表類型在各種理解層級上的理解。實驗結果顯示，CHOPINLLM 在理解各種類型的註解和未註解圖表上展現出強大的效能。</paragraph>

##### **Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery**
2407.14499v1 by Sukrut Rao, Sweta Mahajan, Moritz Böhle, Bernt Schiele

Concept Bottleneck Models (CBMs) have recently been proposed to address the
'black-box' problem of deep neural networks, by first mapping images to a
human-understandable concept space and then linearly combining concepts for
classification. Such models typically require first coming up with a set of
concepts relevant to the task and then aligning the representations of a
feature extractor to map to these concepts. However, even with powerful
foundational feature extractors like CLIP, there are no guarantees that the
specified concepts are detectable. In this work, we leverage recent advances in
mechanistic interpretability and propose a novel CBM approach -- called
Discover-then-Name-CBM (DN-CBM) -- that inverts the typical paradigm: instead
of pre-selecting concepts based on the downstream classification task, we use
sparse autoencoders to first discover concepts learnt by the model, and then
name them and train linear probes for classification. Our concept extraction
strategy is efficient, since it is agnostic to the downstream task, and uses
concepts already known to the model. We perform a comprehensive evaluation
across multiple datasets and CLIP architectures and show that our method yields
semantically meaningful concepts, assigns appropriate names to them that make
them easy to interpret, and yields performant and interpretable CBMs. Code
available at https://github.com/neuroexplicit-saar/discover-then-name.

摘要：概念瓶颈模型（CBM）最近被提出用来解决深度神经网络的“黑箱”问题，方法是首先将图像映射到人类可以理解的概念空间，然后线性组合概念进行分类。此类模型通常需要首先提出与任务相关的一组概念，然后调整特征提取器的表示以映射到这些概念。然而，即使使用像 CLIP 这样强大的基础特征提取器，也不能保证可以检测到指定的概念。在这项工作中，我们利用机制可解释性的最新进展，提出了一种新颖的 CBM 方法——称为发现然后命名 CBM（DN-CBM）——它颠覆了典型范例：我们不根据下游分类任务预先选择概念，而是使用稀疏自动编码器首先发现模型学习到的概念，然后为它们命名并训练线性探针进行分类。我们的概念提取策略很有效，因为它与下游任务无关，并且使用模型已知概念。我们在多个数据集和 CLIP 架构上执行了全面评估，并表明我们的方法产生了语义上有意义的概念，为它们分配了适当的名称，使它们易于解释，并产生了高性能且可解释的 CBM。代码可在 https://github.com/neuroexplicit-saar/discover-then-name 获得。

##### **Evaluating the Reliability of Self-Explanations in Large Language Models**
2407.14487v1 by Korbinian Randl, John Pavlopoulos, Aron Henriksson, Tony Lindgren

This paper investigates the reliability of explanations generated by large
language models (LLMs) when prompted to explain their previous output. We
evaluate two kinds of such self-explanations - extractive and counterfactual -
using three state-of-the-art LLMs (2B to 8B parameters) on two different
classification tasks (objective and subjective). Our findings reveal, that,
while these self-explanations can correlate with human judgement, they do not
fully and accurately follow the model's decision process, indicating a gap
between perceived and actual model reasoning. We show that this gap can be
bridged because prompting LLMs for counterfactual explanations can produce
faithful, informative, and easy-to-verify results. These counterfactuals offer
a promising alternative to traditional explainability methods (e.g. SHAP,
LIME), provided that prompts are tailored to specific tasks and checked for
validity.

摘要：本論文探討大型語言模型 (LLM) 在受提示解釋其先前輸出時所產生的解釋的可靠性。我們使用三種最先進的 LLM (2B 至 8B 參數) 在兩個不同的分類任務 (客觀和主觀) 上評估兩種此類自我解釋，即萃取式和反事實式。我們的研究結果顯示，儘管這些自我解釋可以與人類判斷相關，但它們並未完全且準確地遵循模型的決策過程，這表示感知模型推理與實際模型推理之間存在差距。我們表明，這個差距可以被彌合，因為提示 LLM 進行反事實解釋可以產生忠實、有資訊且易於驗證的結果。這些反事實提供了一個有希望的傳統可解釋性方法 (例如 SHAP、LIME) 的替代方案，前提是提示針對特定任務進行調整並檢查其有效性。

##### **Explainable Post hoc Portfolio Management Financial Policy of a Deep Reinforcement Learning agent**
2407.14486v1 by Alejandra de la Rica Escudero, Eduardo C. Garrido-Merchan, Maria Coronado-Vaca

Financial portfolio management investment policies computed quantitatively by
modern portfolio theory techniques like the Markowitz model rely on a set on
assumptions that are not supported by data in high volatility markets. Hence,
quantitative researchers are looking for alternative models to tackle this
problem. Concretely, portfolio management is a problem that has been
successfully addressed recently by Deep Reinforcement Learning (DRL)
approaches. In particular, DRL algorithms train an agent by estimating the
distribution of the expected reward of every action performed by an agent given
any financial state in a simulator. However, these methods rely on Deep Neural
Networks model to represent such a distribution, that although they are
universal approximator models, they cannot explain its behaviour, given by a
set of parameters that are not interpretable. Critically, financial investors
policies require predictions to be interpretable, so DRL agents are not suited
to follow a particular policy or explain their actions. In this work, we
developed a novel Explainable Deep Reinforcement Learning (XDRL) approach for
portfolio management, integrating the Proximal Policy Optimization (PPO) with
the model agnostic explainable techniques of feature importance, SHAP and LIME
to enhance transparency in prediction time. By executing our methodology, we
can interpret in prediction time the actions of the agent to assess whether
they follow the requisites of an investment policy or to assess the risk of
following the agent suggestions. To the best of our knowledge, our proposed
approach is the first explainable post hoc portfolio management financial
policy of a DRL agent. We empirically illustrate our methodology by
successfully identifying key features influencing investment decisions, which
demonstrate the ability to explain the agent actions in prediction time.

摘要：現代投資組合理論技術（例如 Markowitz 模型）計算出的財務投資組合管理投資政策依賴於一組在高波動市場中不受數據支持的假設。因此，量化研究人員正在尋找替代模型來解決此問題。具體來說，投資組合管理是一個問題，最近已由深度強化學習 (DRL) 方法成功解決。特別是，DRL 演算法透過估計代理人在模擬器中給定任何財務狀態時執行的每個動作的預期獎勵分佈來訓練代理人。然而，這些方法依賴於深度神經網路模型來表示此類分佈，雖然它們是通用逼近模型，但它們無法解釋其行為，這由一組不可解釋的參數給出。至關重要的是，金融投資者的政策要求預測具有可解釋性，因此 DRL 代理人不適合遵循特定政策或解釋其行為。在這項工作中，我們開發了一種新穎的可解釋深度強化學習 (XDRL) 投資組合管理方法，將近端策略最佳化 (PPO) 與特徵重要性、SHAP 和 LIME 的模型不可知可解釋技術整合在一起，以增強預測時間的透明度。透過執行我們的 methodology，我們可以在預測時間解釋代理人的行為，以評估它們是否遵循投資政策的要求或評估遵循代理人建議的風險。據我們所知，我們提出的方法是 DRL 代理人的第一個可解釋的後設投資組合管理財務政策。我們透過成功識別影響投資決策的關鍵特徵來實證說明我們的 methodology，這證明了在預測時間解釋代理人行為的能力。

##### **ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities**
2407.14482v1 by Peng Xu, Wei Ping, Xianchao Wu, Zihan Liu, Mohammad Shoeybi, Bryan Catanzaro

In this work, we introduce ChatQA 2, a Llama3-based model designed to bridge
the gap between open-access LLMs and leading proprietary models (e.g.,
GPT-4-Turbo) in long-context understanding and retrieval-augmented generation
(RAG) capabilities. These two capabilities are essential for LLMs to process
large volumes of information that cannot fit into a single prompt and are
complementary to each other, depending on the downstream tasks and
computational budgets. We present a detailed continued training recipe to
extend the context window of Llama3-70B-base from 8K to 128K tokens, along with
a three-stage instruction tuning process to enhance the model's
instruction-following, RAG performance, and long-context understanding
capabilities. Our results demonstrate that the Llama3-ChatQA-2-70B model
achieves accuracy comparable to GPT-4-Turbo-2024-0409 on many long-context
understanding tasks and surpasses it on the RAG benchmark. Interestingly, we
find that the state-of-the-art long-context retriever can alleviate the top-k
context fragmentation issue in RAG, further improving RAG-based results for
long-context understanding tasks. We also provide extensive comparisons between
RAG and long-context solutions using state-of-the-art long-context LLMs.

摘要：在這項工作中，我們介紹 ChatQA 2，一種基於 Llama3 的模型，旨在彌合開放式 LLM 和領先的專有模型（例如 GPT-4-Turbo）在長期語境理解和檢索增強生成 (RAG) 能力方面的差距。這兩種能力對於 LLM 處理大量無法放入單一提示中的資訊至關重要，並且根據下游任務和計算預算，它們是互補的。我們提出了詳細的持續訓練配方，將 Llama3-70B-base 的語境視窗從 8K 擴展到 128K 個 token，並採用三階段指令調整流程來增強模型的指令遵循、RAG 效能和長期語境理解能力。我們的結果表明，Llama3-ChatQA-2-70B 模型在許多長期語境理解任務上達到了與 GPT-4-Turbo-2024-0409 相當的準確度，並且在 RAG 基準上超越了它。有趣的是，我們發現最先進的長期語境檢索器可以緩解 RAG 中的 top-k 語境碎片化問題，進一步改善了基於 RAG 的長期語境理解任務的結果。我們還提供了使用最先進的長期語境 LLM，在 RAG 和長期語境解決方案之間進行廣泛的比較。

##### **Check-Eval: A Checklist-based Approach for Evaluating Text Quality**
2407.14467v1 by Jayr Pereira, Roberto Lotufo

Evaluating the quality of text generated by large language models (LLMs)
remains a significant challenge. Traditional metrics often fail to align well
with human judgments, particularly in tasks requiring creativity and nuance. In
this paper, we propose Check-Eval, a novel evaluation framework leveraging LLMs
to assess the quality of generated text through a checklist-based approach.
Check-Eval can be employed as both a reference-free and reference-dependent
evaluation method, providing a structured and interpretable assessment of text
quality. The framework consists of two main stages: checklist generation and
checklist evaluation. We validate Check-Eval on two benchmark datasets:
Portuguese Legal Semantic Textual Similarity and SummEval. Our results
demonstrate that Check-Eval achieves higher correlations with human judgments
compared to existing metrics, such as G-Eval and GPTScore, underscoring its
potential as a more reliable and effective evaluation framework for natural
language generation tasks. The code for our experiments is available at
https://anonymous.4open.science/r/check-eval-0DB4.

摘要：評估大型語言模型（LLM）所產生的文字品質，依然是一項重大的挑戰。傳統的指標往往無法與人類的判斷準則對齊，特別是在需要創意和細微差別的任務中。在本文中，我們提出 Check-Eval，一個創新的評估架構，利用 LLM 透過基於檢查清單的方法來評估所產生文字的品質。Check-Eval 可同時作為無參考和依據參考的評估方法，提供對文字品質有條理且可解釋的評估。該架構包含兩個主要階段：檢查清單產生和檢查清單評估。我們在兩個基準資料集上驗證 Check-Eval：葡萄牙語法律語義文字相似度和 SummEval。我們的結果表明，與現有的指標（例如 G-Eval 和 GPTScore）相比，Check-Eval 與人類判斷的相關性更高，這強調了它作為自然語言產生任務更可靠且有效的評估架構的潛力。我們實驗的程式碼可在 https://anonymous.4open.science/r/check-eval-0DB4 取得。

##### **AudioInsight: Detecting Social Contexts Relevant to Social Anxiety from Speech**
2407.14458v1 by Varun Reddy, Zhiyuan Wang, Emma Toner, Max Larrazabal, Mehdi Boukhechba, Bethany A. Teachman, Laura E. Barnes

During social interactions, understanding the intricacies of the context can
be vital, particularly for socially anxious individuals. While previous
research has found that the presence of a social interaction can be detected
from ambient audio, the nuances within social contexts, which influence how
anxiety provoking interactions are, remain largely unexplored. As an
alternative to traditional, burdensome methods like self-report, this study
presents a novel approach that harnesses ambient audio segments to detect
social threat contexts. We focus on two key dimensions: number of interaction
partners (dyadic vs. group) and degree of evaluative threat (explicitly
evaluative vs. not explicitly evaluative). Building on data from a Zoom-based
social interaction study (N=52 college students, of whom the majority N=45 are
socially anxious), we employ deep learning methods to achieve strong detection
performance. Under sample-wide 5-fold Cross Validation (CV), our model
distinguished dyadic from group interactions with 90\% accuracy and detected
evaluative threat at 83\%. Using a leave-one-group-out CV, accuracies were 82\%
and 77\%, respectively. While our data are based on virtual interactions due to
pandemic constraints, our method has the potential to extend to diverse
real-world settings. This research underscores the potential of passive sensing
and AI to differentiate intricate social contexts, and may ultimately advance
the ability of context-aware digital interventions to offer personalized mental
health support.

摘要：在社交互動中，理解脈絡的複雜性至關重要，特別是對於有社交焦慮的人。雖然先前的研究發現，可以從環境音訊中偵測到社交互動的存在，但社交脈絡中的細微差別，會影響焦慮引發互動的方式，在很大程度上仍未被探討。作為傳統繁瑣方法（例如自我報告）的替代方案，本研究提出了一種新方法，利用環境音訊片段來偵測社交威脅脈絡。我們專注於兩個關鍵面向：互動夥伴的數量（成對互動與群體互動）和評量威脅的程度（明確評量與非明確評量）。根據基於 Zoom 的社交互動研究資料（N=52 名大學生，其中大多數 N=45 有社交焦慮），我們採用深度學習方法來達成強大的偵測效能。在樣本範圍內的 5 倍交叉驗證 (CV) 下，我們的模型以 90% 的準確度區分了成對互動與群體互動，並以 83% 的準確度偵測到了評量威脅。使用留一組交叉驗證，準確度分別為 82% 和 77%。儘管我們的資料是基於虛擬互動，這是因為受到疫情限制，但我們的這種方法有潛力擴展到現實世界中的各種場景。本研究強調了被動感測和 AI 在區分複雜社交脈絡方面的潛力，並且最終可能會提升情境感知數位介入提供個人化心理健康支援的能力。

##### **The Extrapolation Power of Implicit Models**
2407.14430v1 by Juliette Decugis, Alicia Y. Tsai, Max Emerling, Ashwin Ganesh, Laurent El Ghaoui

In this paper, we investigate the extrapolation capabilities of implicit deep
learning models in handling unobserved data, where traditional deep neural
networks may falter. Implicit models, distinguished by their adaptability in
layer depth and incorporation of feedback within their computational graph, are
put to the test across various extrapolation scenarios: out-of-distribution,
geographical, and temporal shifts. Our experiments consistently demonstrate
significant performance advantage with implicit models. Unlike their
non-implicit counterparts, which often rely on meticulous architectural design
for each task, implicit models demonstrate the ability to learn complex model
structures without the need for task-specific design, highlighting their
robustness in handling unseen data.

摘要：在本文中，我們探討了隱式深度學習模型在處理傳統深度神經網路可能失敗的未觀察資料時的推廣能力。隱式模型以其在層深度中的適應性和在其計算圖中加入回饋而區別於其他模型，並在各種外推情境中接受測試：分佈外、地理和時間轉移。我們的實驗持續證明隱式模型具有顯著的效能優勢。與其非隱式對應模型不同，後者通常依賴於每個任務的細緻架構設計，隱式模型展示了在無需任務特定設計的情況下學習複雜模型結構的能力，突顯了其在處理未見資料時的穩健性。

##### **Mixture of Experts with Mixture of Precisions for Tuning Quality of Service**
2407.14417v1 by HamidReza Imani, Abdolah Amirany, Tarek El-Ghazawi

The increasing demand for deploying large Mixture-of-Experts (MoE) models in
resource-constrained environments necessitates efficient approaches to address
their high memory and computational requirements challenges. Moreover, given
that tasks come in different user-defined constraints and the available
resources change over time in multi-tenant environments, it is necessary to
design an approach which provides a flexible configuration space. This paper
presents an adaptive serving approach for the efficient deployment of MoE
models, capitalizing on partial quantization of the experts. By dynamically
determining the number of quantized experts and their distribution across CPU
and GPU, our approach explores the Pareto frontier and offers a fine-grained
range of configurations for tuning throughput and model quality. Our evaluation
on an NVIDIA A100 GPU using a Mixtral 8x7B MoE model for three language
modelling benchmarks demonstrates that the throughput of token generation can
be adjusted from 0.63 to 13.00 token per second. This enhancement comes with a
marginal perplexity increase of 2.62 to 2.80, 6.48 to 7.24, and 3.24 to 3.53
for WikiText2, PTB, and C4 datasets respectively under maximum quantization.
These results highlight the practical applicability of our approach in dynamic
and accuracy-sensitive applications where both memory usage and output quality
are important.

摘要：隨著在資源受限環境中部署大型混合專家 (MoE) 模型的需求日益增加，需要有效的方法來解決其高記憶體和運算需求的挑戰。此外，由於任務具有不同的使用者定義約束，且在多租戶環境中可用資源會隨著時間而改變，因此有必要設計一種提供彈性配置空間的方法。本文提出了一種自適應服務方法，用於有效部署 MoE 模型，利用專家的部分量化。透過動態確定量化專家的數量及其在 CPU 和 GPU 上的分布，我們的做法探索了 Pareto 前緣，並提供了用於調整通量和模型品質的細粒度配置範圍。我們使用 Mixtral 8x7B MoE 模型在 NVIDIA A100 GPU 上針對三個語言建模基準進行評估，結果表明，令牌產生的通量可以從每秒 0.63 個令牌調整到 13.00 個令牌。此增強功能的困惑度略有增加，在最大量化下，對於 WikiText2、PTB 和 C4 資料集分別為 2.62 到 2.80、6.48 到 7.24 和 3.24 到 3.53。這些結果突顯了我們的方法在動態且對準確度敏感的應用中的實際適用性，在這些應用中，記憶體使用量和輸出品質都很重要。

##### **System-1.x: Learning to Balance Fast and Slow Planning with Language Models**
2407.14414v1 by Swarnadeep Saha, Archiki Prasad, Justin Chih-Yao Chen, Peter Hase, Elias Stengel-Eskin, Mohit Bansal

Language models can be used to solve long-horizon planning problems in two
distinct modes: a fast 'System-1' mode, directly generating plans without any
explicit search or backtracking, and a slow 'System-2' mode, planning
step-by-step by explicitly searching over possible actions. While System-2 is
typically more effective, it is also more computationally expensive, making it
infeasible for long plans or large action spaces. Moreover, isolated System-1
or 2 ignores the user's end goals, failing to provide ways to control the
model's behavior. To this end, we propose the System-1.x Planner, a
controllable planning framework with LLMs that is capable of generating hybrid
plans and balancing between the two planning modes based on the difficulty of
the problem at hand. System-1.x consists of (i) a controller, (ii) a System-1
Planner, and (iii) a System-2 Planner. Based on a user-specified hybridization
factor (x) governing the mixture between System-1 and 2, the controller
decomposes a problem into sub-goals, and classifies them as easy or hard to be
solved by either System-1 or 2, respectively. We fine-tune all three components
on top of a single base LLM, requiring only search traces as supervision.
Experiments with two diverse planning tasks -- Maze Navigation and Blocksworld
-- show that our System-1.x Planner outperforms a System-1 Planner, a System-2
Planner trained to approximate A* search, and also a symbolic planner (A*). We
demonstrate the following key properties of our planner: (1) controllability:
increasing the hybridization factor (e.g., System-1.75 vs 1.5) performs more
search, improving performance, (2) flexibility: by building a neuro-symbolic
variant with a neural System-1 and a symbolic System-2, we can use existing
symbolic methods, and (3) generalizability: by being able to learn from
different search algorithms, our method is robust to the choice of search
algorithm.

摘要：語言模型可用於兩種不同的模式來解決長期規劃問題：一種是快速的「系統 1」模式，直接產生計畫，而無需任何明確的搜尋或回溯；另一種是緩慢的「系統 2」模式，透過明確搜尋可能行動來逐步規劃。雖然系統 2 通常更有效，但它在計算上也更昂貴，這使得它對於長期的計畫或大型動作空間來說不可行。此外，孤立的系統 1 或 2 會忽略使用者的最終目標，無法提供控制模型行為的方法。為此，我們提出系統 1.x 規劃器，這是一個可控制的規劃架構，具備 LLM，能夠產生混合計畫，並根據手邊問題的難度在兩種規劃模式之間取得平衡。系統 1.x 包含 (i) 一個控制器，(ii) 一個系統 1 規劃器，以及 (iii) 一個系統 2 規劃器。根據使用者指定的混合因子 (x) 來控制系統 1 和 2 之間的混合，控制器將問題分解成子目標，並將它們分類為容易或難以分別由系統 1 或 2 解決。我們針對單一基礎 LLM 微調所有三個組成部分，僅需要搜尋軌跡作為監督。使用兩個不同的規劃任務（迷宮導航和積木世界）進行的實驗表明，我們的系統 1.x 規劃器優於系統 1 規劃器、訓練為近似 A* 搜尋的系統 2 規劃器，以及符號規劃器 (A*)。我們展示了規劃器的以下關鍵特性：(1) 可控性：增加混合因子（例如，系統 1.75 與 1.5）會執行更多搜尋，從而提高效能，(2) 靈活性：透過建立一個具有神經符號變體的神經系統 1 和一個符號系統 2，我們可以使用現有的符號方法，以及 (3) 概括性：透過能夠從不同的搜尋演算法中學習，我們的模型對於搜尋演算法的選擇具有穩健性。

##### **DEAL: Disentangle and Localize Concept-level Explanations for VLMs**
2407.14412v1 by Tang Li, Mengmeng Ma, Xi Peng

Large pre-trained Vision-Language Models (VLMs) have become ubiquitous
foundational components of other models and downstream tasks. Although
powerful, our empirical results reveal that such models might not be able to
identify fine-grained concepts. Specifically, the explanations of VLMs with
respect to fine-grained concepts are entangled and mislocalized. To address
this issue, we propose to DisEntAngle and Localize (DEAL) the concept-level
explanations for VLMs without human annotations. The key idea is encouraging
the concept-level explanations to be distinct while maintaining consistency
with category-level explanations. We conduct extensive experiments and ablation
studies on a wide range of benchmark datasets and vision-language models. Our
empirical results demonstrate that the proposed method significantly improves
the concept-level explanations of the model in terms of disentanglability and
localizability. Surprisingly, the improved explainability alleviates the
model's reliance on spurious correlations, which further benefits the
prediction accuracy.

摘要：大型预训练视觉语言模型 (VLM) 已成为其他模型和下游任务中无所不在的基础组件。尽管功能强大，但我们的经验结果表明，此类模型可能无法识别细粒度概念。具体而言，VLM 对细粒度概念的解释是纠缠不清且定位错误的。为了解决这个问题，我们建议对 VLM 的概念级解释进行解缠和定位 (DEAL)，而无需人工注释。其关键思想是鼓励概念级解释保持差异，同时保持与类别级解释的一致性。我们在广泛的基准数据集和视觉语言模型上进行了大量的实验和消融研究。我们的经验结果表明，所提出的方法在可解缠性和可定位性方面显著改善了模型的概念级解释。令人惊讶的是，改进的可解释性减轻了模型对虚假相关性的依赖，这进一步提高了预测准确性。

##### **The Vision of Autonomic Computing: Can LLMs Make It a Reality?**
2407.14402v1 by Zhiyang Zhang, Fangkai Yang, Xiaoting Qin, Jue Zhang, Qingwei Lin, Gong Cheng, Dongmei Zhang, Saravan Rajmohan, Qi Zhang

The Vision of Autonomic Computing (ACV), proposed over two decades ago,
envisions computing systems that self-manage akin to biological organisms,
adapting seamlessly to changing environments. Despite decades of research,
achieving ACV remains challenging due to the dynamic and complex nature of
modern computing systems. Recent advancements in Large Language Models (LLMs)
offer promising solutions to these challenges by leveraging their extensive
knowledge, language understanding, and task automation capabilities. This paper
explores the feasibility of realizing ACV through an LLM-based multi-agent
framework for microservice management. We introduce a five-level taxonomy for
autonomous service maintenance and present an online evaluation benchmark based
on the Sock Shop microservice demo project to assess our framework's
performance. Our findings demonstrate significant progress towards achieving
Level 3 autonomy, highlighting the effectiveness of LLMs in detecting and
resolving issues within microservice architectures. This study contributes to
advancing autonomic computing by pioneering the integration of LLMs into
microservice management frameworks, paving the way for more adaptive and
self-managing computing systems. The code will be made available at
https://aka.ms/ACV-LLM.

摘要：自治運算 (ACV) 的願景在二十多年前提出，
設想運算系統能像生物體一樣自我管理，
無縫適應變化的環境。儘管經過數十年的研究，
由於現代運算系統的動態和複雜性，實現 ACV 仍然具有挑戰性。
大型語言模型 (LLM) 的最新進展透過利用其廣泛的
知識、語言理解和任務自動化能力，為這些挑戰提供了有希望的解決方案。本文
探討了透過基於 LLM 的多代理架構進行微服務管理來實現 ACV 的可行性。我們引入了一個五級分類法，用於
自治服務維護，並根據 Sock Shop 微服務示範專案提出了一個線上評估基準，以評估我們的架構的
效能。我們的研究結果證明了在實現第 3 級自治方面取得了顯著進展，突顯了 LLM 在偵測和
解決微服務架構中問題的有效性。這項研究有助於推動自治運算，率先將 LLM 整合到
微服務管理架構中，為更具適應性和自我管理的運算系統鋪路。程式碼將於
https://aka.ms/ACV-LLM 上提供。

##### **On the Impact of PRB Load Uncertainty Forecasting for Sustainable Open RAN**
2407.14400v1 by Vaishnavi Kasuluru, Luis Blanco, Cristian J. Vaca-Rubio, Engin Zeydan

The transition to sustainable Open Radio Access Network (O-RAN) architectures
brings new challenges for resource management, especially in predicting the
utilization of Physical Resource Block (PRB)s. In this paper, we propose a
novel approach to characterize the PRB load using probabilistic forecasting
techniques. First, we provide background information on the O-RAN architecture
and components and emphasize the importance of energy/power consumption models
for sustainable implementations. The problem statement highlights the need for
accurate PRB load prediction to optimize resource allocation and power
efficiency. We then investigate probabilistic forecasting techniques, including
Simple-Feed-Forward (SFF), DeepAR, and Transformers, and discuss their
likelihood model assumptions. The simulation results show that DeepAR
estimators predict the PRBs with less uncertainty and effectively capture the
temporal dependencies in the dataset compared to SFF- and Transformer-based
models, leading to power savings. Different percentile selections can also
increase power savings, but at the cost of over-/under provisioning. At the
same time, the performance of the Long-Short Term Memory (LSTM) is shown to be
inferior to the probabilistic estimators with respect to all error metrics.
Finally, we outline the importance of probabilistic, prediction-based
characterization for sustainable O-RAN implementations and highlight avenues
for future research.

摘要：可持續開放無線接取網路 (O-RAN) 架構的轉變為資源管理帶來新的挑戰，特別是在預測實體資源區塊 (PRB) 的使用率方面。在本文中，我們提出了一種使用機率預測技術來描述 PRB 負載的新方法。首先，我們提供 O-RAN 架構和組件的背景資訊，並強調能源/電力消耗模型對於可持續實作的重要性。問題陳述強調了準確預測 PRB 負載以最佳化資源配置和電力效率的必要性。接著我們探討機率預測技術，包括簡單前饋 (SFF)、DeepAR 和 Transformer，並討論它們的似然模型假設。模擬結果顯示，與基於 SFF 和 Transformer 的模型相比，DeepAR 估計器能以較低的不確定性預測 PRB，並有效捕捉資料集中的時間依賴性，進而節省電力。不同的百分位數選擇也能增加電力節省，但代價是過度/不足配置。同時，顯示出長短期記憶 (LSTM) 的效能低於機率估計器，相對於所有誤差量測。最後，我們概述了機率、基於預測的描述對於可持續 O-RAN 實作的重要性，並強調未來研究的途徑。

##### **GLAudio Listens to the Sound of the Graph**
2407.14387v1 by Aurelio Sulser, Johann Wenckstern, Clara Kuempel

We propose GLAudio: Graph Learning on Audio representation of the node
features and the connectivity structure. This novel architecture propagates the
node features through the graph network according to the discrete wave equation
and then employs a sequence learning architecture to learn the target node
function from the audio wave signal. This leads to a new paradigm of learning
on graph-structured data, in which information propagation and information
processing are separated into two distinct steps. We theoretically characterize
the expressivity of our model, introducing the notion of the receptive field of
a vertex, and investigate our model's susceptibility to over-smoothing and
over-squashing both theoretically as well as experimentally on various graph
datasets.

摘要：我們提出 GLAudio：節點特徵和連接結構的音訊表示上的圖形學習。這個新穎的架構根據離散波動方程式透過圖形網路傳播節點特徵，然後採用序列學習架構從音訊波形訊號中學習目標節點函數。這導致了在圖形結構化資料上學習的新典範，其中資訊傳播和資訊處理被分為兩個不同的步驟。我們在理論上描述了我們模型的表現力，引入了頂點接受域的概念，並在理論上和實驗上研究了我們模型對過度平滑和過度壓縮的敏感性，並在各種圖形資料集上進行了研究。

##### **The Sticky Path to Expressive Querying: Decidability of Navigational Queries under Existential Rules**
2407.14384v1 by Piotr Ostropolski-Nalewaja, Sebastian Rudolph

Extensive research in the field of ontology-based query answering has led to
the identification of numerous fragments of existential rules (also known as
tuple-generating dependencies) that exhibit decidable answering of atomic and
conjunctive queries. Motivated by the increased theoretical and practical
interest in navigational queries, this paper considers the question for which
of these fragments decidability of querying extends to regular path queries
(RPQs). In fact, decidability of RPQs has recently been shown to generally hold
for the comprehensive family of all fragments that come with the guarantee of
universal models being reasonably well-shaped (that is, being of finite
cliquewidth). Yet, for the second major family of fragments, known as finite
unification sets (short: fus), which are based on first-order-rewritability,
corresponding results have been largely elusive so far. We complete the picture
by showing that RPQ answering over arbitrary fus rulesets is undecidable. On
the positive side, we establish that the problem is decidable for the prominent
fus subclass of sticky rulesets, with the caveat that a very mild extension of
the RPQ formalism turns the problem undecidable again.

摘要：在基於本体的查詢回答領域的廣泛研究中，已經找出許多存在規則片段（也稱為元組生成依賴性），其展現出原子和聯集查詢的可判定回答。在航行查詢的理論和實務興趣增加的驅使下，本文考量了這些片段中的哪一個查詢判定性可延伸到常規路徑查詢 (RPQ)。事實上，最近已顯示 RPQ 的判定性通常適用於所有片段的綜合系列，這些片段保證通用模型的形狀合理（即為有限的團寬）。然而，對於第二個主要片段系列，稱為有限統一集（簡稱 fus），其基於一階重寫性，到目前為止，對應的結果在很大程度上仍然難以捉摸。我們透過顯示在任意 fus 規則集上回答 RPQ 是不可判定的來完成這幅圖畫。在正面方面，我們建立了這個問題對於顯著的 fus 子類別（黏著規則集）是可以判定的，但有一個警告，即 RPQ 形式主義的非常輕微的延伸會再次使這個問題變得不可判定。

##### **Enhancing Cloud-Native Resource Allocation with Probabilistic Forecasting Techniques in O-RAN**
2407.14377v1 by Vaishnavi Kasuluru, Luis Blanco, Engin Zeydan, Albert Bel, Angelos Antonopoulos

The need for intelligent and efficient resource provisioning for the
productive management of resources in real-world scenarios is growing with the
evolution of telecommunications towards the 6G era. Technologies such as Open
Radio Access Network (O-RAN) can help to build interoperable solutions for the
management of complex systems. Probabilistic forecasting, in contrast to
deterministic single-point estimators, can offer a different approach to
resource allocation by quantifying the uncertainty of the generated
predictions. This paper examines the cloud-native aspects of O-RAN together
with the radio App (rApp) deployment options. The integration of probabilistic
forecasting techniques as a rApp in O-RAN is also emphasized, along with case
studies of real-world applications. Through a comparative analysis of
forecasting models using the error metric, we show the advantages of Deep
Autoregressive Recurrent network (DeepAR) over other deterministic
probabilistic estimators. Furthermore, the simplicity of Simple-Feed-Forward
(SFF) leads to a fast runtime but does not capture the temporal dependencies of
the input data. Finally, we present some aspects related to the practical
applicability of cloud-native O-RAN with probabilistic forecasting.

摘要：隨著電信朝向 6G 時代演進，對於智慧且有效率的資源配置需求日益增加，以利於在實際情況中有效管理資源。開放式無線存取網路 (O-RAN) 等技術有助於建構可互通的解決方案，用於管理複雜的系統。機率性預測與決定論單點估計器不同，它能透過量化產生的預測的不確定性，提供一種不同的資源配置方法。本文探討 O-RAN 的雲原生層面，以及無線應用程式 (rApp) 的部署選項。本文也強調將機率性預測技術整合為 O-RAN 中的 rApp，以及實際應用案例研究。透過使用誤差量測值對預測模型進行比較分析，我們展示了 Deep Autoregressive Recurrent 網路 (DeepAR) 優於其他決定論機率估計器的優勢。此外，簡易前饋 (SFF) 的簡易性可縮短執行時間，但無法擷取輸入資料的時間相依性。最後，我們提出一些與機率性預測的雲原生 O-RAN 實務應用相關的層面。

##### **SCoPE: Evaluating LLMs for Software Vulnerability Detection**
2407.14372v1 by José Gonçalves, Tiago Dias, Eva Maia, Isabel Praça

In recent years, code security has become increasingly important, especially
with the rise of interconnected technologies. Detecting vulnerabilities early
in the software development process has demonstrated numerous benefits.
Consequently, the scientific community started using machine learning for
automated detection of source code vulnerabilities. This work explores and
refines the CVEFixes dataset, which is commonly used to train models for
code-related tasks, specifically the C/C++ subset. To this purpose, the Source
Code Processing Engine (SCoPE), a framework composed of strategized techniques
that can be used to reduce the size and normalize C/C++ functions is presented.
The output generated by SCoPE was used to create a new version of CVEFixes.
This refined dataset was then employed in a feature representation analysis to
assess the effectiveness of the tool's code processing techniques, consisting
of fine-tuning three pre-trained LLMs for software vulnerability detection. The
results show that SCoPE successfully helped to identify 905 duplicates within
the evaluated subset. The LLM results corroborate with the literature regarding
their suitability for software vulnerability detection, with the best model
achieving 53% F1-score.

摘要：近年来，代码安全性变得越来越重要，尤其是在互联技术兴起之后。在软件开发过程中尽早检测到漏洞已证明有许多好处。因此，科学界开始使用机器学习来自动检测源代码漏洞。这项工作探索并改进了 CVEFixes 数据集，该数据集通常用于训练与代码相关的任务（特别是 C/C++ 子集）的模型。为此，提出了源代码处理引擎 (SCoPE)，这是一个由策略化技术组成的框架，可用于减小 C/C++ 函数的大小并对其进行规范化。由 SCoPE 生成的输出用于创建 CVEFixes 的新版本。然后在特征表示分析中使用此改进的数据集来评估该工具的代码处理技术的有效性，包括微调三个预训练的 LLM 以进行软件漏洞检测。结果表明，SCoPE 成功帮助在评估的子集中识别出 905 个重复项。LLM 的结果与文献相符，证明它们适用于软件漏洞检测，其中最好的模型达到 53% 的 F1 分数。

##### **Open Artificial Knowledge**
2407.14371v1 by Vadim Borisov, Richard H. Schreiber

The tremendous success of chat-based AI systems like ChatGPT, Claude, and
Gemini stems from Large Language Models (LLMs) trained on vast amount of
datasets. However, acquiring high-quality, diverse, and ethically sourced
training data remains a significant challenge. We introduce the Open Artificial
Knowledge (OAK) dataset, a large-scale resource of over 500 million tokens (at
the moment of writing) designed to address this issue. OAK leverages an
ensemble of state-of-the-art LLMs, including GPT4o, LLaMa3-70B, LLaMa3-8B,
Mixtral-8x7B, Gemma-7B, and Gemma-2-9B , to generate high-quality text across
diverse domains, guided by Wikipedia's main categories. Our methodology ensures
broad knowledge coverage while maintaining coherence and factual accuracy. The
OAK dataset aims to foster the development of more capable and aligned language
models while addressing critical issues of data scarcity and privacy in LLM
training, and it is freely available on www.oakdataset.org.

摘要：聊天機器人 AI 系統，例如 ChatGPT、Claude 和 Gemini 的巨大成功，源自於在大量資料集上訓練的大型語言模型 (LLM)。然而，取得高品質、多元且來源合乎道德的訓練資料仍然是一項重大的挑戰。我們引進開放人工知識 (OAK) 資料集，這是一個大型資源，包含超過 5 億個詞彙（截至撰寫本文），旨在解決這個問題。OAK 利用最先進的 LLM 組合，包括 GPT4o、LLaMa3-70B、LLaMa3-8B、Mixtral-8x7B、Gemma-7B 和 Gemma-2-9B，在不同的領域中產生高品質的文字，並以維基百科的主要類別為指導。我們的做法確保廣泛的知識涵蓋範圍，同時保持一致性和事實準確性。OAK 資料集旨在促進更強大且一致的語言模型的開發，同時解決 LLM 訓練中資料稀少性和隱私的關鍵問題，且可免費在 www.oakdataset.org 取得。

##### **Towards Assessing Data Replication in Music Generation with Music Similarity Metrics on Raw Audio**
2407.14364v1 by Roser Batlle-Roca, Wei-Hisang Liao, Xavier Serra, Yuki Mitsufuji, Emilia Gómez

Recent advancements in music generation are raising multiple concerns about
the implications of AI in creative music processes, current business models and
impacts related to intellectual property management. A relevant challenge is
the potential replication and plagiarism of the training set in AI-generated
music, which could lead to misuse of data and intellectual property rights
violations. To tackle this issue, we present the Music Replication Assessment
(MiRA) tool: a model-independent open evaluation method based on diverse audio
music similarity metrics to assess data replication of the training set. We
evaluate the ability of five metrics to identify exact replication, by
conducting a controlled replication experiment in different music genres based
on synthetic samples. Our results show that the proposed methodology can
estimate exact data replication with a proportion higher than 10%. By
introducing the MiRA tool, we intend to encourage the open evaluation of music
generative models by researchers, developers and users concerning data
replication, highlighting the importance of ethical, social, legal and economic
consequences of generative AI in the music domain.

摘要：最近音樂生成的進展引發了多重疑慮，包括 AI 在音樂創作過程中、當前商業模式的影響，以及與智慧財產管理相關的衝擊。一個相關的挑戰是 AI 生成的音樂中訓練資料集的潛在複製和抄襲，這可能導致資料濫用和智慧財產權的侵犯。為了解決這個問題，我們提出了音樂複製評估 (MiRA) 工具：一種基於多種音訊音樂相似度量度，用於評估訓練資料集資料複製的模型無關開放評估方法。我們透過在不同音樂類型中進行受控複製實驗，基於合成樣本，評估五種量度辨識精確複製的能力。我們的結果顯示，所提出的方法可以估計精確資料複製，其比例高於 10%。透過引進 MiRA 工具，我們希望鼓勵研究人員、開發人員和使用者公開評估音樂生成模型，並關注資料複製，強調生成式 AI 在音樂領域的道德、社會、法律和經濟後果的重要性。

##### **Stable Audio Open**
2407.14358v1 by Zach Evans, Julian D. Parker, CJ Carr, Zack Zukowski, Josiah Taylor, Jordi Pons

Open generative models are vitally important for the community, allowing for
fine-tunes and serving as baselines when presenting new models. However, most
current text-to-audio models are private and not accessible for artists and
researchers to build upon. Here we describe the architecture and training
process of a new open-weights text-to-audio model trained with Creative Commons
data. Our evaluation shows that the model's performance is competitive with the
state-of-the-art across various metrics. Notably, the reported FDopenl3 results
(measuring the realism of the generations) showcase its potential for
high-quality stereo sound synthesis at 44.1kHz.

摘要：開放式生成模型對社群至關重要，允許微調並在展示新模型時作為基準。然而，目前大多數文字轉語音模型都是私有的，藝術家和研究人員無法以此為基礎進行建構。在此，我們描述一個新的開放權重文字轉語音模型的架構和訓練過程，該模型是使用創意共用資料訓練的。我們的評估顯示，該模型的效能與各種指標的最新技術不相上下。值得注意的是，所報告的 FDopenl3 結果（衡量生成的真實性）展示了它在 44.1kHz 下進行高品質立體聲合成音訊的潛力。

##### **Improving Retrieval in Sponsored Search by Leveraging Query Context Signals**
2407.14346v1 by Akash Kumar Mohankumar, Gururaj K, Gagan Madan, Amit Singh

Accurately retrieving relevant bid keywords for user queries is critical in
Sponsored Search but remains challenging, particularly for short, ambiguous
queries. Existing dense and generative retrieval models often fail to capture
nuanced user intent in these cases. To address this, we propose an approach to
enhance query understanding by augmenting queries with rich contextual signals
derived from web search results and large language models, stored in an online
cache. Specifically, we use web search titles and snippets to ground queries in
real-world information and utilize GPT-4 to generate query rewrites and
explanations that clarify user intent. These signals are efficiently integrated
through a Fusion-in-Decoder based Unity architecture, enabling both dense and
generative retrieval with serving costs on par with traditional context-free
models. To address scenarios where context is unavailable in the cache, we
introduce context glancing, a curriculum learning strategy that improves model
robustness and performance even without contextual signals during inference.
Extensive offline experiments demonstrate that our context-aware approach
substantially outperforms context-free models. Furthermore, online A/B testing
on a prominent search engine across 160+ countries shows significant
improvements in user engagement and revenue.

摘要：在贊助搜尋中準確擷取與使用者查詢相關的出價關鍵字至關重要，但仍然具有挑戰性，特別是對於簡短、含糊的查詢。現有的稠密生成式檢索模型通常無法在這些情況下捕捉到細微的使用者意圖。為了解決這個問題，我們提出了一種透過豐富的脈絡訊號來增強查詢理解的方法，這些訊號來自網路搜尋結果和大型語言模型，並儲存在線上快取中。具體來說，我們使用網路搜尋標題和摘要將查詢建立在真實世界的資訊中，並利用 GPT-4 產生查詢重寫和解釋，以釐清使用者意圖。這些訊號透過基於融合解碼器的統一架構有效整合，同時支援稠密和生成式檢索，其服務成本與傳統的無脈絡模型相當。為了處理快取中沒有脈絡的場景，我們引入了脈絡瀏覽，這是一種課程學習策略，即使在推論過程中沒有脈絡訊號，也能提升模型的穩健性和效能。廣泛的離線實驗證明，我們的脈絡感知方法大幅優於無脈絡模型。此外，在超過 160 個國家/地區的知名搜尋引擎上進行的線上 A/B 測試顯示，使用者參與度和營收都有顯著提升。

##### **LLMs left, right, and center: Assessing GPT's capabilities to label political bias from web domains**
2407.14344v1 by Raphael Hernandes

This research investigates whether OpenAI's GPT-4, a state-of-the-art large
language model, can accurately classify the political bias of news sources
based solely on their URLs. Given the subjective nature of political labels,
third-party bias ratings like those from Ad Fontes Media, AllSides, and Media
Bias/Fact Check (MBFC) are often used in research to analyze news source
diversity. This study aims to determine if GPT-4 can replicate these human
ratings on a seven-degree scale ("far-left" to "far-right"). The analysis
compares GPT-4's classifications against MBFC's, and controls for website
popularity using Open PageRank scores. Findings reveal a high correlation
($\text{Spearman's } \rho = .89$, $n = 5,877$, $p < 0.001$) between GPT-4's and
MBFC's ratings, indicating the model's potential reliability. However, GPT-4
abstained from classifying approximately $\frac{2}{3}$ of the dataset,
particularly less popular and less biased sources. The study also identifies a
slight leftward skew in GPT-4's classifications compared to MBFC's. The
analysis suggests that while GPT-4 can be a scalable, cost-effective tool for
political bias classification of news websites, but its use should complement
human judgment to mitigate biases. Further research is recommended to explore
the model's performance across different settings, languages, and additional
datasets.

摘要：這項研究探討 OpenAI 的 GPT-4，一種最先進的大語言模型，是否能僅根據新聞來源的網址準確分類其政治偏見。鑑於政治標籤的主觀性質，研究中經常使用 Ad Fontes Media、AllSides 和 Media Bias/Fact Check (MBFC) 等第三方偏見評分來分析新聞來源的多樣性。本研究旨在確定 GPT-4 是否能以七級量表（「極左派」到「極右派」）複製這些人為評分。分析比較了 GPT-4 的分類與 MBFC 的分類，並使用 Open PageRank 分數控制網站的熱門程度。研究結果顯示 GPT-4 和 MBFC 的評分之間具有高度相關性（斯皮爾曼 $\rho = .89$，$n = 5,877$，$p < 0.001$），這表示該模型的潛在可靠性。然而，GPT-4 避免分類約 $\frac{2}{3}$ 的資料集，特別是不太熱門且不太有偏見的來源。本研究也發現 GPT-4 的分類與 MBFC 的分類相比，略微偏左。分析顯示，儘管 GPT-4 可以成為新聞網站政治偏見分類的可擴充、具成本效益的工具，但其使用應補充人為判斷以減輕偏見。建議進一步研究以探討該模型在不同設定、語言和額外資料集中的效能。

##### **Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model**
2407.14326v1 by Kun Zhao, Jakub Prokop, Javier Montalt Tordera, Sadegh Mohammadi

Mammography is crucial for breast cancer surveillance and early diagnosis.
However, analyzing mammography images is a demanding task for radiologists, who
often review hundreds of mammograms daily, leading to overdiagnosis and
overtreatment. Computer-Aided Diagnosis (CAD) systems have been developed to
assist in this process, but their capabilities, particularly in lesion
segmentation, remained limited. With the contemporary advances in deep learning
their performance may be improved. Recently, vision-language diffusion models
emerged, demonstrating outstanding performance in image generation and
transferability to various downstream tasks. We aim to harness their
capabilities for breast lesion segmentation in a panoptic setting, which
encompasses both semantic and instance-level predictions. Specifically, we
propose leveraging pretrained features from a Stable Diffusion model as inputs
to a state-of-the-art panoptic segmentation architecture, resulting in accurate
delineation of individual breast lesions. To bridge the gap between natural and
medical imaging domains, we incorporated a mammography-specific MAM-E diffusion
model and BiomedCLIP image and text encoders into this framework. We evaluated
our approach on two recently published mammography datasets, CDD-CESM and
VinDr-Mammo. For the instance segmentation task, we noted 40.25 AP0.1 and 46.82
AP0.05, as well as 25.44 PQ0.1 and 26.92 PQ0.05. For the semantic segmentation
task, we achieved Dice scores of 38.86 and 40.92, respectively.

摘要：乳房攝影對於乳癌監控和早期診斷至關重要。
然而，分析乳房攝影影像對放射科醫師來說是一項艱鉅的任務，他們
每天經常檢閱數百張乳房攝影影像，導致過度診斷和
過度治療。電腦輔助診斷 (CAD) 系統已開發出來以
協助此流程，但其功能，特別是在病灶
分割方面，仍然有限。隨著深度學習的當代進展
其性能可能會得到改善。最近，視覺語言擴散模型
出現，在影像生成和
可轉移到各種下游任務中展現出傑出的性能。我們旨在利用其
功能在全景設置中進行乳房病灶分割，其中
包含語義和實例級別預測。具體來說，我們
建議利用預先訓練的 Stable Diffusion 模型中的特徵作為輸入
到最先進的全景分割架構，從而精確地描繪個別乳房病灶。為了彌合自然和
醫學影像領域之間的差距，我們將乳房攝影專用的 MAM-E 擴散
模型和 BiomedCLIP 影像和文字編碼器納入這個架構中。我們評估
我們的方法在兩個最近發布的乳房攝影資料集 CDD-CESM 和
VinDr-Mammo。對於實例分割任務，我們注意到 40.25 AP0.1 和 46.82
AP0.05，以及 25.44 PQ0.1 和 26.92 PQ0.05。對於語義分割
任務，我們分別達到了 38.86 和 40.92 的 Dice 分數。

##### **Multimodal Misinformation Detection using Large Vision-Language Models**
2407.14321v1 by Sahar Tahmasebi, Eric Müller-Budack, Ralph Ewerth

The increasing proliferation of misinformation and its alarming impact have
motivated both industry and academia to develop approaches for misinformation
detection and fact checking. Recent advances on large language models (LLMs)
have shown remarkable performance in various tasks, but whether and how LLMs
could help with misinformation detection remains relatively underexplored. Most
of existing state-of-the-art approaches either do not consider evidence and
solely focus on claim related features or assume the evidence to be provided.
Few approaches consider evidence retrieval as part of the misinformation
detection but rely on fine-tuning models. In this paper, we investigate the
potential of LLMs for misinformation detection in a zero-shot setting. We
incorporate an evidence retrieval component into the process as it is crucial
to gather pertinent information from various sources to detect the veracity of
claims. To this end, we propose a novel re-ranking approach for multimodal
evidence retrieval using both LLMs and large vision-language models (LVLM). The
retrieved evidence samples (images and texts) serve as the input for an
LVLM-based approach for multimodal fact verification (LVLM4FV). To enable a
fair evaluation, we address the issue of incomplete ground truth for evidence
samples in an existing evidence retrieval dataset by annotating a more complete
set of evidence samples for both image and text retrieval. Our experimental
results on two datasets demonstrate the superiority of the proposed approach in
both evidence retrieval and fact verification tasks and also better
generalization capability across dataset compared to the supervised baseline.

摘要：<paragraph>错误訊息和警報影響的擴散增加，促使產業和學術界開發錯誤訊息偵測和事實查核的方法。大型語言模型 (LLM) 的最新進展在各種任務中展現出顯著的表現，但 LLM 是否能協助錯誤訊息偵測，以及如何協助，仍相對未被充分探討。現有的最先進方法大多不考慮證據，僅專注於與聲明相關的特徵，或假設已提供證據。少數方法將證據檢索視為錯誤訊息偵測的一部分，但依賴微調模型。在本文中，我們探討 LLM 在零次學習設定中進行錯誤訊息偵測的潛力。我們將證據檢索元件納入流程中，因為從各種來源收集相關資訊對於偵測聲明的真實性至關重要。為此，我們提出了一種使用 LLM 和大型視覺語言模型 (LVLM) 的多模態證據檢索的重新排序方法。檢索到的證據範例（影像和文字）作為 LVLM 基於多模態事實驗證 (LVLM4FV) 方法的輸入。為了進行公平的評估，我們透過為影像和文字檢索標註一組更完整的證據範例，來解決現有證據檢索資料集中證據範例不完整的問題。我們在兩個資料集上的實驗結果證明了所提出的方法在證據檢索和事實驗證任務中的優異性，並且與監督式基準相比，在資料集間也具有更好的泛化能力。</paragraph>

##### **EmoCAM: Toward Understanding What Drives CNN-based Emotion Recognition**
2407.14314v1 by Youssef Doulfoukar, Laurent Mertens, Joost Vennekens

Convolutional Neural Networks are particularly suited for image analysis
tasks, such as Image Classification, Object Recognition or Image Segmentation.
Like all Artificial Neural Networks, however, they are "black box" models, and
suffer from poor explainability. This work is concerned with the specific
downstream task of Emotion Recognition from images, and proposes a framework
that combines CAM-based techniques with Object Detection on a corpus level to
better understand on which image cues a particular model, in our case EmoNet,
relies to assign a specific emotion to an image. We demonstrate that the model
mostly focuses on human characteristics, but also explore the pronounced effect
of specific image modifications.

摘要：卷積神經網路特別適合用於影像分析任務，例如影像分類、物件辨識或影像分割。然而，和所有的人工神經網路一樣，它們是「黑箱」模型，且難以解釋。這項工作關注於從影像中辨識情緒這項特定下游任務，並提出了一個架構，將基於 CAM 的技術與物件偵測結合在語料層級，以更了解特定模型（在我們的案例中為 EmoNet）依賴哪些影像線索將特定情緒指定給影像。我們證明了模型主要關注於人類特徵，但也會探討特定影像修改的顯著影響。

##### **How to Engage Your Readers? Generating Guiding Questions to Promote Active Reading**
2407.14309v1 by Peng Cui, Vilém Zouhar, Xiaoyu Zhang, Mrinmaya Sachan

Using questions in written text is an effective strategy to enhance
readability. However, what makes an active reading question good, what the
linguistic role of these questions is, and what is their impact on human
reading remains understudied. We introduce GuidingQ, a dataset of 10K in-text
questions from textbooks and scientific articles. By analyzing the dataset, we
present a comprehensive understanding of the use, distribution, and linguistic
characteristics of these questions. Then, we explore various approaches to
generate such questions using language models. Our results highlight the
importance of capturing inter-question relationships and the challenge of
question position identification in generating these questions. Finally, we
conduct a human study to understand the implication of such questions on
reading comprehension. We find that the generated questions are of high quality
and are almost as effective as human-written questions in terms of improving
readers' memorization and comprehension.

摘要：在書面文字中使用問題是一種增強可讀性的有效策略。然而，什麼讓一個主動閱讀問題變得良好，這些問題的語言角色是什麼，以及它們對人類閱讀的影響仍然未得到充分研究。我們引入了 GuidingQ，一個來自教科書和科學文章的 10K 文本內問題的數據集。通過分析數據集，我們對這些問題的使用、分佈和語言特徵有了全面的了解。然後，我們探索了使用語言模型生成此類問題的各種方法。我們的結果強調了捕捉問題間關係的重要性，以及在生成這些問題中確定問題位置的挑戰。最後，我們進行了一項人類研究，以了解此類問題對閱讀理解的影響。我們發現，生成的問題質量很高，在提高讀者的記憶力和理解力方面幾乎與人類寫的問題一樣有效。

##### **Complementary Learning for Real-World Model Failure Detection**
2407.14306v1 by Daniel Bogdoll, Finn Sartoris, Vincent Geppert, Svetlana Pavlitska, J. Marius Zöllner

In real-world autonomous driving, deep learning models can experience
performance degradation due to distributional shifts between the training data
and the driving conditions encountered. As is typical in machine learning, it
is difficult to acquire a large and potentially representative labeled test set
to validate models in preparation for deployment in the wild. In this work, we
introduce complementary learning, where we use learned characteristics from
different training paradigms to detect model errors. We demonstrate our
approach by learning semantic and predictive motion labels in point clouds in a
supervised and self-supervised manner and detect and classify model
discrepancies subsequently. We perform a large-scale qualitative analysis and
present LidarCODA, the first dataset with labeled anomalies in lidar point
clouds, for an extensive quantitative analysis.

摘要：在真實世界的自動駕駛中，深度學習模型可能會因訓練資料與實際駕駛狀況之間的分布轉移而導致效能下降。如同機器學習常見的情況，難以取得大型且具代表性的標籤測試集，以驗證模型為實際部署做好準備。在此研究中，我們引入了互補學習，利用從不同訓練範例中學習到的特徵來偵測模型錯誤。我們透過監督式和自監督式的方式學習點雲中的語意和預測運動標籤，並進一步偵測和分類模型差異來展示我們的做法。我們執行大規模的定性分析，並提出 LidarCODA，這是第一個在雷達點雲中標記異常的資料集，用於廣泛的定量分析。

##### **Foundation Models for Autonomous Robots in Unstructured Environments**
2407.14296v1 by Hossein Naderi, Alireza Shojaei

Automating activities through robots in unstructured environments, such as
construction sites, has been a long-standing desire. However, the high degree
of unpredictable events in these settings has resulted in far less adoption
compared to more structured settings, such as manufacturing, where robots can
be hard-coded or trained on narrowly defined datasets. Recently, pretrained
foundation models, such as Large Language Models (LLMs), have demonstrated
superior generalization capabilities by providing zero-shot solutions for
problems do not present in the training data, proposing them as a potential
solution for introducing robots to unstructured environments. To this end, this
study investigates potential opportunities and challenges of pretrained
foundation models from a multi-dimensional perspective. The study
systematically reviews application of foundation models in two field of robotic
and unstructured environment and then synthesized them with deliberative acting
theory. Findings showed that linguistic capabilities of LLMs have been utilized
more than other features for improving perception in human-robot interactions.
On the other hand, findings showed that the use of LLMs demonstrated more
applications in project management and safety in construction, and natural
hazard detection in disaster management. Synthesizing these findings, we
located the current state-of-the-art in this field on a five-level scale of
automation, placing them at conditional automation. This assessment was then
used to envision future scenarios, challenges, and solutions toward autonomous
safe unstructured environments. Our study can be seen as a benchmark to track
our progress toward that future.

摘要：<paragraph>在非結構化環境（例如建築工地）中透過機器人自動化活動一直是長久以來的願景。然而，這些環境中高度不可預測的事件導致採用率遠低於結構化程度較高的環境，例如製造業，在製造業中，機器人可以被硬編碼或在狹義定義的資料集上訓練。近期，預訓練基礎模型（例如大型語言模型（LLM））已展現出優異的概化能力，能為訓練資料中不存在的問題提供零次學習的解決方案，並建議將其作為將機器人引入非結構化環境的潛在解決方案。為此，本研究從多面向的角度探討預訓練基礎模型的潛在機會和挑戰。本研究系統性地回顧了基礎模型在機器人和非結構化環境這兩個領域的應用，然後透過審議行動理論將它們綜合起來。研究結果顯示，LLM 的語言能力已被廣泛用於改善人機互動中的感知。另一方面，研究結果顯示，LLM 的使用在建築中的專案管理和安全，以及災害管理中的自然災害偵測方面展現出更多應用。綜合這些研究結果，我們將此領域的現有技術狀態置於五級自動化規模中的條件式自動化。然後，此評估被用於預想未來情境、挑戰和邁向自主安全非結構化環境的解決方案。我們的研究可以視為追蹤我們邁向那個未來的基準。</paragraph>

##### **CoVoSwitch: Machine Translation of Synthetic Code-Switched Text Based on Intonation Units**
2407.14295v1 by Yeeun Kang

Multilingual code-switching research is often hindered by the lack and
linguistically biased status of available datasets. To expand language
representation, we synthesize code-switching data by replacing intonation units
detected through PSST, a speech segmentation model fine-tuned from OpenAI's
Whisper, using a speech-to-text translation dataset, CoVoST 2. With our
dataset, CoVoSwitch, spanning 13 languages, we evaluate the code-switching
translation performance of two multilingual translation models, M2M-100 418M
and NLLB-200 600M. We reveal that the inclusion of code-switching units results
in higher translation performance than monolingual settings and that models are
better at code-switching translation into English than non-English. Further,
low-resource languages gain most from integration of code-switched units when
translating into English but much less when translating into non-English.
Translations into low-resource languages also perform worse than even raw
code-switched inputs. We find that systems excel at copying English tokens but
struggle with non-English tokens, that the off-target problem in monolingual
settings is also relevant in code-switching settings, and that models
hallucinate in code-switching translation by introducing words absent in both
of the original source sentences. CoVoSwitch and code are available at
https://github.com/sophiayk20/covoswitch.

摘要：多語言代碼轉換研究常常受到可用資料集缺乏和語言偏見狀態的阻礙。為了擴展語言表示，我們通過替換通過 PSST（一種由 OpenAI 的 Whisper 微調的語音分段模型）檢測到的語調單位，使用語音轉文本翻譯資料集 CoVoST 2 來合成代碼轉換資料。使用我們的資料集 CoVoSwitch，跨越 13 種語言，我們評估了兩個多語言翻譯模型（M2M-100 418M 和 NLLB-200 600M）的代碼轉換翻譯性能。我們發現，包含代碼轉換單元比單語語言設置產生更高的翻譯性能，並且模型在將代碼轉換翻譯成英語方面比非英語更好。此外，在翻譯成英語時，低資源語言從代碼轉換單元的整合中獲益最多，但在翻譯成非英語時獲益則少得多。翻譯成低資源語言的表現也比原始代碼轉換輸入更差。我們發現，系統擅長複製英語令牌，但在非英語令牌方面卻有困難，單語語言設置中的離題問題在代碼轉換設置中也很明顯，並且模型在代碼轉換翻譯中會出現幻覺，引入了兩個原始源句中都沒有的詞彙。CoVoSwitch 和代碼可在 https://github.com/sophiayk20/covoswitch 中找到。

##### **How to Blend Concepts in Diffusion Models**
2407.14280v1 by Giorgio Longari, Lorenzo Olearo, Simone Melzi, Rafael Peñaloza, Alessandro Raganato

For the last decade, there has been a push to use multi-dimensional (latent)
spaces to represent concepts; and yet how to manipulate these concepts or
reason with them remains largely unclear. Some recent methods exploit multiple
latent representations and their connection, making this research question even
more entangled. Our goal is to understand how operations in the latent space
affect the underlying concepts. To that end, we explore the task of concept
blending through diffusion models. Diffusion models are based on a connection
between a latent representation of textual prompts and a latent space that
enables image reconstruction and generation. This task allows us to try
different text-based combination strategies, and evaluate easily through a
visual analysis. Our conclusion is that concept blending through space
manipulation is possible, although the best strategy depends on the context of
the blend.

摘要：在過去十年中，一直有使用多維（潛在）空間來表示概念的推動；然而，如何操作這些概念或對它們進行推理在很大程度上仍然不清楚。一些最近的方法利用了多重潛在表示及其連接，使得這個研究問題更加糾結。我們的目標是了解潛在空間中的運算如何影響底層概念。為此，我們通過擴散模型探索概念混合任務。擴散模型基於文本提示的潛在表示與潛在空間之間的連接，該潛在空間能夠進行圖像重建和生成。這個任務允許我們嘗試不同的基於文本的組合策略，並通過視覺分析輕鬆地進行評估。我們的結論是，通過空間操作進行概念混合是可能的，儘管最佳策略取決於混合的上下文。

##### **Hyperparameter Optimization for Driving Strategies Based on Reinforcement Learning**
2407.14262v1 by Nihal Acharya Adde, Hanno Gottschalk, Andreas Ebert

This paper focuses on hyperparameter optimization for autonomous driving
strategies based on Reinforcement Learning. We provide a detailed description
of training the RL agent in a simulation environment. Subsequently, we employ
Efficient Global Optimization algorithm that uses Gaussian Process fitting for
hyperparameter optimization in RL. Before this optimization phase, Gaussian
process interpolation is applied to fit the surrogate model, for which the
hyperparameter set is generated using Latin hypercube sampling. To accelerate
the evaluation, parallelization techniques are employed. Following the
hyperparameter optimization procedure, a set of hyperparameters is identified,
resulting in a noteworthy enhancement in overall driving performance. There is
a substantial increase of 4\% when compared to existing manually tuned
parameters and the hyperparameters discovered during the initialization process
using Latin hypercube sampling. After the optimization, we analyze the obtained
results thoroughly and conduct a sensitivity analysis to assess the robustness
and generalization capabilities of the learned autonomous driving strategies.
The findings from this study contribute to the advancement of Gaussian process
based Bayesian optimization to optimize the hyperparameters for autonomous
driving in RL, providing valuable insights for the development of efficient and
reliable autonomous driving systems.

摘要：本文重點探討基於強化學習的自動駕駛策略的超參數最佳化。我們提供在模擬環境中訓練 RL 代理的詳細說明。隨後，我們採用高效的全球最佳化演算法，該演算法使用高斯過程擬合進行 RL 中的超參數最佳化。在這個最佳化階段之前，應用高斯過程插值來擬合代理模型，其中超參數組是使用拉丁超立方取樣產生的。為了加速評估，採用了平行化技術。在超參數最佳化程序之後，識別出一組超參數，從而顯著提升整體駕駛性能。與現有的手動調整參數和使用拉丁超立方取樣在初始化過程中發現的超參數相比，有 4% 的顯著提升。在最佳化之後，我們徹底分析獲得的結果，並進行敏感性分析，以評估學習到的自動駕駛策略的穩健性和泛化能力。本研究的發現有助於基於高斯過程的貝氏最佳化，以最佳化 RL 中自動駕駛的超參數，為高效且可靠的自動駕駛系統的開發提供有價值的見解。

##### **Voices in a Crowd: Searching for Clusters of Unique Perspectives**
2407.14259v1 by Nikolas Vitsakis, Amit Parekh, Ioannis Konstas

Language models have been shown to reproduce underlying biases existing in
their training data, which is the majority perspective by default. Proposed
solutions aim to capture minority perspectives by either modelling annotator
disagreements or grouping annotators based on shared metadata, both of which
face significant challenges. We propose a framework that trains models without
encoding annotator metadata, extracts latent embeddings informed by annotator
behaviour, and creates clusters of similar opinions, that we refer to as
voices. Resulting clusters are validated post-hoc via internal and external
quantitative metrics, as well a qualitative analysis to identify the type of
voice that each cluster represents. Our results demonstrate the strong
generalisation capability of our framework, indicated by resulting clusters
being adequately robust, while also capturing minority perspectives based on
different demographic factors throughout two distinct datasets.

摘要：語言模型已被證明會重現訓練資料中存在的潛在偏見，而這在預設上是多數觀點。提議的解決方案旨在透過建模標記員的分歧或根據共用元資料對標記員進行分組來捕捉少數觀點，這兩種方法都面臨重大挑戰。我們提出一個框架，在不編碼標記員元資料的情況下訓練模型，提取由標記員行為告知的潛在嵌入，並建立相似意見的群集，我們稱之為聲音。產生的群集透過內部和外部定量指標以及定性分析進行事後驗證，以識別每個群集所代表的聲音類型。我們的結果證明了我們框架的強大概括能力，這表示產生的群集足夠穩健，同時也捕捉了兩個不同資料集中基於不同人口因素的少數觀點。

##### **Personalized Multi-tier Federated Learning**
2407.14251v1 by Sourasekhar Banerjee, Ali Dadras, Alp Yurtsever, Monowar Bhuyan

The key challenge of personalized federated learning (PerFL) is to capture
the statistical heterogeneity properties of data with inexpensive
communications and gain customized performance for participating devices. To
address these, we introduced personalized federated learning in multi-tier
architecture (PerMFL) to obtain optimized and personalized local models when
there are known team structures across devices. We provide theoretical
guarantees of PerMFL, which offers linear convergence rates for smooth strongly
convex problems and sub-linear convergence rates for smooth non-convex
problems. We conduct numerical experiments demonstrating the robust empirical
performance of PerMFL, outperforming the state-of-the-art in multiple
personalized federated learning tasks.

摘要：個性化聯邦學習 (PerFL) 的關鍵挑戰是擷取資料的統計異質性屬性，並利用低成本通訊獲得自訂效能，以便參與裝置使用。為了解決這些問題，我們在多層架構 (PerMFL) 中引入了個性化聯邦學習，以便在裝置之間存在已知團隊結構時取得最佳化和個性化本機模型。我們提供了 PerMFL 的理論保證，它為平滑強凸問題提供了線性收斂率，並為平滑非凸問題提供了次線性收斂率。我們進行了數值實驗，證明了 PerMFL 的穩健經驗效能，在多項個性化聯邦學習任務中優於最先進技術。

##### **Conditioning Chat-GPT for information retrieval: the Unipa-GPT case study**
2407.14246v1 by Irene Siragusa, Roberto Pirrone

This paper illustrates the architecture and training of Unipa-GPT, a chatbot
relying on a Large Language Model, developed for assisting students in choosing
a bachelor/master degree course at the University of Palermo. Unipa-GPT relies
on gpt-3.5-turbo, it was presented in the context of the European Researchers'
Night (SHARPER night). In our experiments we adopted both the Retrieval
Augmented Generation (RAG) approach and fine-tuning to develop the system. The
whole architecture of Unipa-GPT is presented, both the RAG and the fine-tuned
systems are compared, and a brief discussion on their performance is reported.
Further comparison with other Large Language Models and the experimental
results during the SHARPER night are illustrated.

摘要：本文說明了 Unipa-GPT 的架構和訓練，Unipa-GPT 是一個聊天機器人，依賴於大型語言模型，用於協助學生選擇巴勒莫大學的學士/碩士學位課程。Unipa-GPT 依賴於 gpt-3.5-turbo，它是在歐洲研究人員之夜（SHARPER 之夜）的背景下提出的。在我們的實驗中，我們採用了檢索擴充生成 (RAG) 方法和微調來開發系統。Unipa-GPT 的整個架構都已提出，RAG 和微調系統都已進行比較，並簡要討論了它們的效能。進一步比較了其他大型語言模型和 SHARPER 之夜的實驗結果。

##### **KoMA: Knowledge-driven Multi-agent Framework for Autonomous Driving with Large Language Models**
2407.14239v1 by Kemou Jiang, Xuan Cai, Zhiyong Cui, Aoyong Li, Yilong Ren, Haiyang Yu, Hao Yang, Daocheng Fu, Licheng Wen, Pinlong Cai

Large language models (LLMs) as autonomous agents offer a novel avenue for
tackling real-world challenges through a knowledge-driven manner. These
LLM-enhanced methodologies excel in generalization and interpretability.
However, the complexity of driving tasks often necessitates the collaboration
of multiple, heterogeneous agents, underscoring the need for such LLM-driven
agents to engage in cooperative knowledge sharing and cognitive synergy.
Despite the promise of LLMs, current applications predominantly center around
single agent scenarios. To broaden the horizons of knowledge-driven strategies
and bolster the generalization capabilities of autonomous agents, we propose
the KoMA framework consisting of multi-agent interaction, multi-step planning,
shared-memory, and ranking-based reflection modules to enhance multi-agents'
decision-making in complex driving scenarios. Based on the framework's
generated text descriptions of driving scenarios, the multi-agent interaction
module enables LLM agents to analyze and infer the intentions of surrounding
vehicles, akin to human cognition. The multi-step planning module enables LLM
agents to analyze and obtain final action decisions layer by layer to ensure
consistent goals for short-term action decisions. The shared memory module can
accumulate collective experience to make superior decisions, and the
ranking-based reflection module can evaluate and improve agent behavior with
the aim of enhancing driving safety and efficiency. The KoMA framework not only
enhances the robustness and adaptability of autonomous driving agents but also
significantly elevates their generalization capabilities across diverse
scenarios. Empirical results demonstrate the superiority of our approach over
traditional methods, particularly in its ability to handle complex,
unpredictable driving environments without extensive retraining.

摘要：大型語言模型 (LLM) 作為自主代理提供了一條新途徑，可透過知識驅動的方式來解決現實世界的挑戰。這些增強 LLM 的方法在概括化和可解釋性方面表現出色。然而，駕駛任務的複雜性通常需要多個異質代理的協作，這強調了此類 LLM 驅動代理參與合作知識共享和認知協同作用的必要性。儘管 LLM 前景看好，但目前的應用主要集中在單一代理場景中。為了拓寬知識驅動策略的視野並提升自主代理的概括能力，我們提出了 KoMA 框架，該框架包含多代理互動、多步驟規劃、共享記憶體和基於排名反射模組，以增強多代理在複雜駕駛場景中的決策。基於框架產生的駕駛場景文字描述，多代理互動模組使 LLM 代理能夠分析和推斷周圍車輛的意圖，類似於人類認知。多步驟規劃模組使 LLM 代理能夠逐層分析和取得最終行動決策，以確保短期行動決策的一致目標。共享記憶體模組可以累積集體經驗以做出更好的決策，而基於排名的反射模組可以評估和改善代理行為，目的是提高駕駛安全性和效率。KoMA 框架不僅增強了自主駕駛代理的穩健性和適應性，而且還顯著提升了它們在不同場景中的概括能力。實證結果證明了我們的方法優於傳統方法，特別是在無需大量重新訓練的情況下處理複雜、不可預測的駕駛環境方面。

##### **Words2Contact: Identifying Support Contacts from Verbal Instructions Using Foundation Models**
2407.14229v1 by Dionis Totsila, Quentin Rouxel, Jean-Baptiste Mouret, Serena Ivaldi

This paper presents Words2Contact, a language-guided multi-contact placement
pipeline leveraging large language models and vision language models. Our
method is a key component for language-assisted teleoperation and human-robot
cooperation, where human operators can instruct the robots where to place their
support contacts before whole-body reaching or manipulation using natural
language. Words2Contact transforms the verbal instructions of a human operator
into contact placement predictions; it also deals with iterative corrections,
until the human is satisfied with the contact location identified in the
robot's field of view. We benchmark state-of-the-art LLMs and VLMs for size and
performance in contact prediction. We demonstrate the effectiveness of the
iterative correction process, showing that users, even naive, quickly learn how
to instruct the system to obtain accurate locations. Finally, we validate
Words2Contact in real-world experiments with the Talos humanoid robot,
instructed by human operators to place support contacts on different locations
and surfaces to avoid falling when reaching for distant objects.

摘要：本文提出 Words2Contact，一種利用大型語言模型和視覺語言模型的語言導向多接觸點放置管道。我們的
方法是語言輔助遙控操作和人機協作的一個關鍵組成部分，其中人類操作員可以使用自然
語言指導機器人在全身接觸或操作之前放置其支撐接觸點的位置。Words2Contact 將人類操作員的口頭指令轉換為接觸點放置預測；它還處理迭代更正，
直到人類對機器人視野中識別的接觸點位置感到滿意為止。我們對最先進的 LLM 和 VLM 的大小和
接觸點預測性能進行基準測試。我們展示了迭代更正過程的有效性，表明用戶，即使是新手，也能快速學會
如何指導系統獲取準確的位置。最後，我們在 Talos 類人機器人的真實世界實驗中驗證了 Words2Contact，
由人類操作員指導它在不同的位置和表面放置支撐接觸點，以避免在接觸遠處物體時摔倒。

##### **Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**
2407.14224v1 by Suvajit Patra, Arkadip Maitra, Megha Tiwari, K. Kumaran, Swathy Prabhu, Swami Punyeshwarananda, Soumitra Samanta

Automatic Sign Language (SL) recognition is an important task in the computer
vision community. To build a robust SL recognition system, we need a
considerable amount of data which is lacking particularly in Indian sign
language (ISL). In this paper, we propose a large-scale isolated ISL dataset
and a novel SL recognition model based on skeleton graph structure. The dataset
covers 2,002 daily used common words in the deaf community recorded by 20 (10
male and 10 female) deaf adult signers (contains 40033 videos). We propose a SL
recognition model namely Hierarchical Windowed Graph Attention Network (HWGAT)
by utilizing the human upper body skeleton graph structure. The HWGAT tries to
capture distinctive motions by giving attention to different body parts induced
by the human skeleton graph structure. The utility of the proposed dataset and
the usefulness of our model are evaluated through extensive experiments. We
pre-trained the proposed model on the proposed dataset and fine-tuned it across
different sign language datasets further boosting the performance of 1.10,
0.46, 0.78, and 6.84 percentage points on INCLUDE, LSA64, AUTSL and WLASL
respectively compared to the existing state-of-the-art skeleton-based models.

摘要：自動手語 (SL) 識別是電腦視覺社群中的重要任務。要建立強健的 SL 識別系統，我們需要大量的資料，而這在印度手語 (ISL) 中特別缺乏。在本文中，我們提出一個大規模的孤立 ISL 資料集，以及一個基於骨架圖結構的新型 SL 識別模型。該資料集涵蓋 2,002 個聾啞社群中常用的日常單字，由 20 位 (10 男 10 女) 聾啞成人手語者錄製（包含 40033 部影片）。我們提出一個 SL 識別模型，即分層視窗圖注意力網路 (HWGAT)，利用人體上半身骨架圖結構。HWGAT 嘗試透過關注由人體骨架圖結構誘導的不同身體部位來捕捉獨特的動作。透過廣泛的實驗評估所提出的資料集的效用和我們模型的有用性。我們在所提出的資料集上預訓練所提出的模型，並在不同的手語資料集上微調它，進一步提升了 INCLUDE、LSA64、AUTSL 和 WLASL 上 1.10、0.46、0.78 和 6.84 個百分點的效能，分別與現有的最先進的基於骨架的模型相比。

##### **Braille-to-Speech Generator: Audio Generation Based on Joint Fine-Tuning of CLIP and Fastspeech2**
2407.14212v1 by Chun Xu, En-Wei Sun

An increasing number of Chinese people are troubled by different degrees of
visual impairment, which has made the modal conversion between a single image
or video frame in the visual field and the audio expressing the same
information a research hotspot. Deep learning technologies such as OCR+Vocoder
and Im2Wav enable English audio synthesis or image-to-sound matching in a
self-supervised manner. However, the audio data used for training is limited
and English is not universal for visually impaired people with different
educational levels. Therefore, for the sake of solving the problems of data
volume and language applicability to improve the reading efficiency of visually
impaired people, a set of image-to-speech framework CLIP-KNN-Fastspeech2 based
on the Chinese context was constructed. The framework integrates multiple basic
models and adopts the strategy of independent pre-training and joint
fine-tuning. First, the Chinese CLIP and Fastspeech2 text-to-speech models were
pre-trained on two public datasets, MUGE and Baker, respectively, and their
convergence was verified. Subsequently, joint fine-tuning was performed using a
self-built Braille image dataset. Experimental results on multiple public
datasets such as VGGSound, Flickr8k, ImageHear, and the self-built Braille
dataset BIT-DP show that the model has improved objective indicators such as
BLEU4,FAD(Fr\'echet Audio Distance), WER(Word Error Ratio), and even inference
speed. This verifies that the constructed model still has the ability to
synthesize high-quality speech under limited data, and also proves the
effectiveness of the joint training strategy that integrates multiple basic
models.

摘要：<paragraph>越來越多的中國人飽受不同程度的視力障礙困擾，這使得視覺場景中的單幅圖像或影片幀與表達相同資訊的音訊之間的模態轉換成為研究熱點。OCR+Vocoder 和 Im2Wav 等深度學習技術以自監督的方式實現英文音訊合成或影像轉聲音的匹配。然而，用於訓練的音訊資料有限，且英文對於不同教育程度的視障人士而言並非通用。因此，為了解決資料量和語言適用性問題以提升視障人士的閱讀效率，構建了一套基於中文語境的影像轉語音框架 CLIP-KNN-Fastspeech2。該框架整合多個基礎模型，採用獨立預訓練和聯合微調的策略。首先，分別在兩個公開資料集 MUGE 和 Baker 上預訓練中文 CLIP 和 Fastspeech2 文本轉語音模型，並驗證其收斂性。隨後，使用自建的點字影像資料集進行聯合微調。在 VGGSound、Flickr8k、ImageHear 等多個公開資料集和自建點字資料集 BIT-DP 上的實驗結果表明，該模型在 BLEU4、FAD（Fréchet Audio Distance）、WER（Word Error Ratio） 等客觀指標上均有提升，甚至推理速度也有所提升。這驗證了所構建的模型在資料量受限的情況下仍具備合成高品質語音的能力，也證明了整合多個基礎模型的聯合訓練策略的有效性。</paragraph>

##### **Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction**
2407.14210v1 by José Daniel Pascual-Triana, Alberto Fernández, Paulo Novais, Francisco Herrera

Given the magnitude of data generation currently, both in quantity and speed,
the use of machine learning is increasingly important. When data include
protected features that might give rise to discrimination, special care must be
taken. Data quality is critical in these cases, as biases in training data can
be reflected in classification models. This has devastating consequences and
fails to comply with current regulations. Data-Centric Artificial Intelligence
proposes dataset modifications to improve its quality. Instance selection via
undersampling can foster balanced learning of classes and protected feature
values in the classifier. When such undersampling is done close to the decision
boundary, the effect on the classifier would be bolstered. This work proposes
Fair Overlap Number of Balls (Fair-ONB), an undersampling method that harnesses
the data morphology of the different data groups (obtained from the combination
of classes and protected feature values) to perform guided undersampling in the
areas where they overlap. It employs attributes of the ball coverage of the
groups, such as the radius, number of covered instances and density, to select
the most suitable areas for undersampling and reduce bias. Results show that
the Fair-ONB method reduces bias with low impact on the classifier's predictive
performance.

摘要：<paragraph>鉴于当前数据生成的规模，无论是在数量还是速度上，机器学习的使用变得越来越重要。当数据包含可能导致歧视的受保护特征时，必须特别小心。在这些情况下，数据质量至关重要，因为训练数据中的偏差可能会反映在分类模型中。这会产生毁灭性的后果，并且不符合当前法规。以数据为中心的 AI 提出了数据集修改以提高其质量。通过欠采样进行实例选择可以促进分类器中类和受保护特征值的平衡学习。当此类欠采样接近决策边界时，对分类器的影响将得到加强。这项工作提出了公平重叠球数 (Fair-ONB)，这是一种欠采样方法，利用不同数据组（从类和受保护特征值的组合中获得）的数据形态，在它们重叠的区域执行引导欠采样。它采用球覆盖的属性，例如半径、覆盖实例数和密度，以选择最适合欠采样的区域并减少偏差。结果表明，Fair-ONB 方法减少了偏差，对分类器的预测性能影响很小。</paragraph>

##### **LeKUBE: A Legal Knowledge Update BEnchmark**
2407.14192v1 by Changyue Wang, Weihang Su, Hu Yiran, Qingyao Ai, Yueyue Wu, Cheng Luo, Yiqun Liu, Min Zhang, Shaoping Ma

Recent advances in Large Language Models (LLMs) have significantly shaped the
applications of AI in multiple fields, including the studies of legal
intelligence. Trained on extensive legal texts, including statutes and legal
documents, the legal LLMs can capture important legal knowledge/concepts
effectively and provide important support for downstream legal applications
such as legal consultancy. Yet, the dynamic nature of legal statutes and
interpretations also poses new challenges to the use of LLMs in legal
applications. Particularly, how to update the legal knowledge of LLMs
effectively and efficiently has become an important research problem in
practice. Existing benchmarks for evaluating knowledge update methods are
mostly designed for the open domain and cannot address the specific challenges
of the legal domain, such as the nuanced application of new legal knowledge,
the complexity and lengthiness of legal regulations, and the intricate nature
of legal reasoning. To address this gap, we introduce the Legal Knowledge
Update BEnchmark, i.e. LeKUBE, which evaluates knowledge update methods for
legal LLMs across five dimensions. Specifically, we categorize the needs of
knowledge updates in the legal domain with the help of legal professionals, and
then hire annotators from law schools to create synthetic updates to the
Chinese Criminal and Civil Code as well as sets of questions of which the
answers would change after the updates. Through a comprehensive evaluation of
state-of-the-art knowledge update methods, we reveal a notable gap between
existing knowledge update methods and the unique needs of the legal domain,
emphasizing the need for further research and development of knowledge update
mechanisms tailored for legal LLMs.

摘要：大型語言模型 (LLM) 的近期進展已顯著塑造了 AI 在多個領域的應用，包括法律智能的研究。在廣泛的法律文本（包括法規和法律文件）上訓練的法律 LLM 可以有效地擷取重要的法律知識/概念，並為法律諮詢等下游法律應用提供重要的支援。然而，法律法規和解釋的動態性質也對 LLM 在法律應用中的使用提出了新的挑戰。特別是，如何有效且高效地更新 LLM 的法律知識已成為實務中重要的研究問題。現有的知識更新方法評估基準大多是為開放領域設計的，無法解決法律領域的特定挑戰，例如新法律知識的細微應用、法律法規的複雜性和冗長性，以及法律推理的複雜性。為了解決這個差距，我們引入了法律知識更新基準，即 LeKUBE，它在五個面向評估法律 LLM 的知識更新方法。具體來說，我們在法律專業人士的幫助下對法律領域中知識更新的需求進行分類，然後聘請法學院的註解者為中國刑法和民法典創建綜合更新，以及在更新後答案會改變的一組問題。透過對最先進的知識更新方法進行全面評估，我們揭示了現有知識更新方法與法律領域獨特需求之間的顯著差距，強調需要進一步研究和開發專為法律 LLM 量身打造的知識更新機制。

##### **Automatic Classification of News Subjects in Broadcast News: Application to a Gender Bias Representation Analysis**
2407.14180v1 by Valentin Pelloin, Lena Dodson, Émile Chapuis, Nicolas Hervé, David Doukhan

This paper introduces a computational framework designed to delineate gender
distribution biases in topics covered by French TV and radio news. We
transcribe a dataset of 11.7k hours, broadcasted in 2023 on 21 French channels.
A Large Language Model (LLM) is used in few-shot conversation mode to obtain a
topic classification on those transcriptions. Using the generated LLM
annotations, we explore the finetuning of a specialized smaller classification
model, to reduce the computational cost. To evaluate the performances of these
models, we construct and annotate a dataset of 804 dialogues. This dataset is
made available free of charge for research purposes. We show that women are
notably underrepresented in subjects such as sports, politics and conflicts.
Conversely, on topics such as weather, commercials and health, women have more
speaking time than their overall average across all subjects. We also observe
representations differences between private and public service channels.

摘要：本論文介紹一個計算框架，用於描繪法國電視和廣播新聞報導主題中的性別分配偏見。我們轉錄了 2023 年在 21 個法國頻道播放的 11.7k 小時資料集。在小樣本對話模式中使用大型語言模型 (LLM) 來獲得這些轉錄的主题分類。使用生成的 LLM 注釋，我們探討了專門的較小分類模型的微調，以降低計算成本。為了評估這些模型的效能，我們構建並註釋了一個包含 804 個對話的資料集。此資料集免費提供給研究用途。我們顯示女性在體育、政治和衝突等主題中顯著代表不足。相反，在天氣、廣告和健康等主題中，女性的發言時間比她們在所有主題中的平均發言時間更多。我們還觀察到私人和公共服務頻道之間的代表差異。

##### **PassTSL: Modeling Human-Created Passwords through Two-Stage Learning**
2407.14145v1 by Yangde Wang, Haozhang Li, Weidong Qiu, Shujun Li, Peng Tang

Textual passwords are still the most widely used user authentication
mechanism. Due to the close connections between textual passwords and natural
languages, advanced technologies in natural language processing (NLP) and
machine learning (ML) could be used to model passwords for different purposes
such as studying human password-creation behaviors and developing more advanced
password cracking methods for informing better defence mechanisms. In this
paper, we propose PassTSL (modeling human-created Passwords through Two-Stage
Learning), inspired by the popular pretraining-finetuning framework in NLP and
deep learning (DL). We report how different pretraining settings affected
PassTSL and proved its effectiveness by applying it to six large leaked
password databases. Experimental results showed that it outperforms five
state-of-the-art (SOTA) password cracking methods on password guessing by a
significant margin ranging from 4.11% to 64.69% at the maximum point. Based on
PassTSL, we also implemented a password strength meter (PSM), and our
experiments showed that it was able to estimate password strength more
accurately, causing fewer unsafe errors (overestimating the password strength)
than two other SOTA PSMs when they produce the same rate of safe errors
(underestimating the password strength): a neural-network based method and
zxcvbn. Furthermore, we explored multiple finetuning settings, and our
evaluations showed that, even a small amount of additional training data, e.g.,
only 0.1% of the pretrained data, can lead to over 3% improvement in password
guessing on average. We also proposed a heuristic approach to selecting
finetuning passwords based on JS (Jensen-Shannon) divergence and experimental
results validated its usefulness. In summary, our contributions demonstrate the
potential and feasibility of applying advanced NLP and ML methods to password
modeling and cracking.

摘要：文字密碼仍是最廣泛使用的使用者驗證機制。由於文字密碼與自然語言之間的緊密關聯，自然語言處理 (NLP) 和機器學習 (ML) 的先進技術可用於建模密碼，以達成不同的目的，例如研究人類密碼建立行為，以及開發更進階的密碼破解方法，以提供更佳的防禦機制。在本文中，我們提出 PassTSL（透過兩階段學習建模人類建立的密碼），其靈感來自 NLP 和深度學習 (DL) 中廣泛使用的預訓練微調架構。我們報告了不同的預訓練設定如何影響 PassTSL，並透過將其應用於六個大型外洩密碼資料庫來證明其有效性。實驗結果顯示，它在密碼猜測方面優於五種最先進 (SOTA) 的密碼破解方法，最大點的顯著幅度介於 4.11% 到 64.69%。基於 PassTSL，我們也實作了一個密碼強度計 (PSM)，而我們的實驗顯示，它能夠更準確地估計密碼強度，當產生相同比率的安全錯誤（低估密碼強度）時，造成的非安全錯誤（高估密碼強度）比其他兩個 SOTA PSM 少：一種基於神經網路的方法和 zxcvbn。此外，我們探討了多種微調設定，而我們的評估顯示，即使少量的額外訓練資料，例如僅為預訓練資料的 0.1%，平均而言也能讓密碼猜測的準確率提升超過 3%。我們也提出了一種啟發式方法來根據 JS（Jensen-Shannon）距離選擇微調密碼，而實驗結果驗證了其效用。總之，我們的貢獻證明了將先進的 NLP 和 ML 方法應用於密碼建模和破解的可能性和可行性。

##### **I Know About "Up"! Enhancing Spatial Reasoning in Visual Language Models Through 3D Reconstruction**
2407.14133v1 by Zaiqiao Meng, Hao Zhou, Yifang Chen

Visual Language Models (VLMs) are essential for various tasks, particularly
visual reasoning tasks, due to their robust multi-modal information
integration, visual reasoning capabilities, and contextual awareness. However,
existing \VLMs{}' visual spatial reasoning capabilities are often inadequate,
struggling even with basic tasks such as distinguishing left from right. To
address this, we propose the \ours{} model, designed to enhance the visual
spatial reasoning abilities of VLMS. ZeroVLM employs Zero-1-to-3, a 3D
reconstruction model for obtaining different views of the input images and
incorporates a prompting mechanism to further improve visual spatial reasoning.
Experimental results on four visual spatial reasoning datasets show that our
\ours{} achieves up to 19.48% accuracy improvement, which indicates the
effectiveness of the 3D reconstruction and prompting mechanisms of our ZeroVLM.

摘要：視覺語言模型 (VLM) 由於其強大的多模式資訊整合、視覺推理能力和情境感知，對於各種任務來說至關重要，特別是視覺推理任務。然而，現有的 \VLMs{} 的視覺空間推理能力通常不足，甚至難以應付區分左右等基本任務。為了解決這個問題，我們提出了 \ours{} 模型，旨在增強 VLM 的視覺空間推理能力。ZeroVLM 採用 Zero-1-to-3，這是一個 3D 重建模型，用於取得輸入影像的不同視角，並結合提示機制進一步改善視覺空間推理。在四個視覺空間推理資料集上的實驗結果顯示，我們的 \ours{} 的準確率提高了 19.48%，這表示我們 ZeroVLM 的 3D 重建和提示機制是有效的。

##### **The Cardinality of Identifying Code Sets for Soccer Ball Graph with Application to Remote Sensing**
2407.14120v1 by Anna L. D. Latour, Arunabha Sen, Kaustav Basu, Chenyang Zhou, Kuldeep S. Meel

In the context of satellite monitoring of the earth, we can assume that the
surface of the earth is divided into a set of regions. We assume that the
impact of a big social/environmental event spills into neighboring regions.
Using Identifying Code Sets (ICSes), we can deploy sensors in such a way that
the region in which an event takes place can be uniquely identified, even with
fewer sensors than regions. As Earth is almost a sphere, we use a soccer ball
as a model. We construct a Soccer Ball Graph (SBG), and provide human-oriented,
analytical proofs that 1) the SBG has at least 26 ICSes of cardinality ten,
implying that there are at least 26 different ways to deploy ten satellites to
monitor the Earth and 2) that the cardinality of the minimum Identifying Code
Set (MICS) for the SBG is at least nine. We then provide a machine-oriented
formal proof that the cardinality of the MICS for the SBG is in fact ten,
meaning that one must deploy at least ten satellites to monitor the Earth in
the SBG model. We also provide machine-oriented proof that there are exactly 26
ICSes of cardinality ten for the SBG.

摘要：在衛星監測地球的脈絡中，我們可以假設地球表面被劃分為一系列區域。我們假設大型社會/環境事件的影響會擴散到鄰近區域。使用識別碼集 (ICS)，我們可以部署感測器，讓事件發生的區域得以被唯一識別，即使感測器比區域少。由於地球幾乎是一個球體，我們使用足球作為模型。我們建構一個足球圖形 (SBG)，並提供以人為導向的分析證明，說明 1) SBG 至少有 26 個基數為 10 的 ICS，這表示至少有 26 種不同的方式可以部署 10 顆衛星來監測地球，以及 2) SBG 的最小識別碼集 (MICS) 的基數至少為 9。然後我們提供一個以機器為導向的形式化證明，說明 SBG 的 MICS 的基數實際上為 10，這表示必須部署至少 10 顆衛星才能在 SBG 模型中監測地球。我們也提供以機器為導向的證明，說明 SBG 確實有 26 個基數為 10 的 ICS。

##### **A3Rank: Augmentation Alignment Analysis for Prioritizing Overconfident Failing Samples for Deep Learning Models**
2407.14114v1 by Zhengyuan Wei, Haipeng Wang, Qilin Zhou, W. K. Chan

Sharpening deep learning models by training them with examples close to the
decision boundary is a well-known best practice. Nonetheless, these models are
still error-prone in producing predictions. In practice, the inference of the
deep learning models in many application systems is guarded by a rejector, such
as a confidence-based rejector, to filter out samples with insufficient
prediction confidence. Such confidence-based rejectors cannot effectively guard
against failing samples with high confidence. Existing test case prioritization
techniques effectively distinguish confusing samples from confident samples to
identify failing samples among the confusing ones, yet prioritizing the failing
ones high among many confident ones is challenging. In this paper, we propose
$A^3$Rank, a novel test case prioritization technique with augmentation
alignment analysis, to address this problem. $A^3$Rank generates augmented
versions of each test case and assesses the extent of the prediction result for
the test case misaligned with these of the augmented versions and vice versa.
Our experiment shows that $A^3$Rank can effectively rank failing samples
escaping from the checking of confidence-based rejectors, which significantly
outperforms the peer techniques by 163.63\% in the detection ratio of
top-ranked samples. We also provide a framework to construct a detector devoted
to augmenting these rejectors to defend these failing samples, and our detector
can achieve a significantly higher defense success rate.

摘要：透過訓練深度學習模型，讓它們使用接近決策邊界的範例進行訓練，這項做法是眾所周知的最佳實務。儘管如此，這些模型在產生預測時仍容易出錯。在實務上，許多應用系統的深度學習模型推論都受到拒絕器的保護，例如基於信心的拒絕器，以過濾掉預測信心不足的樣本。這種基於信心的拒絕器無法有效防範具有高信心的失敗樣本。現有的測試案例優先順序技術可有效區分令人困惑的樣本和有信心的樣本，以識別令人困惑的樣本中的失敗樣本，但要在許多有信心的樣本中將失敗的樣本優先排序在較高位置卻是一項挑戰。在本文中，我們提出 $A^3$Rank，這是一種結合擴充比對分析的新測試案例優先順序技術，以解決這個問題。$A^3$Rank 會產生每個測試案例的擴充版本，並評估測試案例的預測結果與這些擴充版本的預測結果之間的錯位程度，反之亦然。我們的實驗顯示，$A^3$Rank 可以有效地對逃脫基於信心的拒絕器檢查的失敗樣本進行排名，在排名前幾名的樣本的檢測率方面，其顯著優於同儕技術 163.63%。我們還提供了一個架構，用於建構一個偵測器，專門用於擴充這些拒絕器以防禦這些失敗樣本，而我們的偵測器可以達到顯著更高的防禦成功率。

##### **TorchGT: A Holistic System for Large-scale Graph Transformer Training**
2407.14106v1 by Meng Zhang, Jie Sun, Qinghao Hu, Peng Sun, Zeke Wang, Yonggang Wen, Tianwei Zhang

Graph Transformer is a new architecture that surpasses GNNs in graph
learning. While there emerge inspiring algorithm advancements, their practical
adoption is still limited, particularly on real-world graphs involving up to
millions of nodes. We observe existing graph transformers fail on large-scale
graphs mainly due to heavy computation, limited scalability and inferior model
quality. Motivated by these observations, we propose TorchGT, the first
efficient, scalable, and accurate graph transformer training system. TorchGT
optimizes training at different levels. At algorithm level, by harnessing the
graph sparsity, TorchGT introduces a Dual-interleaved Attention which is
computation-efficient and accuracy-maintained. At runtime level, TorchGT scales
training across workers with a communication-light Cluster-aware Graph
Parallelism. At kernel level, an Elastic Computation Reformation further
optimizes the computation by reducing memory access latency in a dynamic way.
Extensive experiments demonstrate that TorchGT boosts training by up to 62.7x
and supports graph sequence lengths of up to 1M.

摘要：圖形Transformer是一種超越圖形學習中 GNN 的新架構。雖然出現了令人振奮的演算法進展，但它們的實際採用仍然有限，特別是在涉及數百萬個節點的真實世界圖形上。我們觀察到現有的圖形Transformer在大型圖形上失敗，主要是由於繁重的計算、有限的可擴充性和較差的模型品質。受到這些觀察結果的啟發，我們提出了 TorchGT，這是第一個高效、可擴充且準確的圖形Transformer訓練系統。TorchGT 在不同層級最佳化訓練。在演算法層級，通過利用圖形稀疏性，TorchGT 引入了一個計算效率高且準確性得以維持的雙交錯注意力。在執行階段，TorchGT 使用具備通訊負載低的叢集感知圖形並行性，擴充了跨工作者的訓練。在核心層級，彈性運算改造進一步最佳化運算，以動態方式減少記憶體存取延遲。廣泛的實驗證明，TorchGT 將訓練提升了 62.7 倍，並支援長達 1M 的圖形序列長度。

##### **ParamsDrag: Interactive Parameter Space Exploration via Image-Space Dragging**
2407.14100v1 by Guan Li, Yang Liu, Guihua Shan, Shiyu Cheng, Weiqun Cao, Junpeng Wang, Ko-Chih Wang

Numerical simulation serves as a cornerstone in scientific modeling, yet the
process of fine-tuning simulation parameters poses significant challenges.
Conventionally, parameter adjustment relies on extensive numerical simulations,
data analysis, and expert insights, resulting in substantial computational
costs and low efficiency. The emergence of deep learning in recent years has
provided promising avenues for more efficient exploration of parameter spaces.
However, existing approaches often lack intuitive methods for precise parameter
adjustment and optimization. To tackle these challenges, we introduce
ParamsDrag, a model that facilitates parameter space exploration through direct
interaction with visualizations. Inspired by DragGAN, our ParamsDrag model
operates in three steps. First, the generative component of ParamsDrag
generates visualizations based on the input simulation parameters. Second, by
directly dragging structure-related features in the visualizations, users can
intuitively understand the controlling effect of different parameters. Third,
with the understanding from the earlier step, users can steer ParamsDrag to
produce dynamic visual outcomes. Through experiments conducted on real-world
simulations and comparisons with state-of-the-art deep learning-based
approaches, we demonstrate the efficacy of our solution.

摘要：數值模擬是科學建模的基石，然而微調模擬參數的過程會帶來重大的挑戰。傳統上，參數調整依賴於大量的數值模擬、資料分析和專家見解，導致大量的運算成本和低效率。近年來深度學習的出現為更有效率的參數空間探索提供了有希望的途徑。然而，現有的方法通常缺乏用於精確參數調整和最佳化的直觀方法。為了應對這些挑戰，我們引入了 ParamsDrag，這是一個透過與視覺化進行直接互動來促進參數空間探索的模型。我們的 ParamsDrag 模型受到 DragGAN 的啟發，分為三個步驟進行。首先，ParamsDrag 的生成元件會根據輸入的模擬參數來產生視覺化。其次，透過直接拖曳視覺化中的結構相關特徵，使用者可以直觀地瞭解不同參數的控制效果。第三，透過對前一步的理解，使用者可以引導 ParamsDrag 產生動態的視覺化結果。透過在真實世界的模擬和與最先進的基於深度學習的方法進行比較中進行的實驗，我們證明了我們解決方案的效能。

##### **On the Robustness of Fully-Spiking Neural Networks in Open-World Scenarios using Forward-Only Learning Algorithms**
2407.14097v1 by Erik B. Terres-Escudero, Javier Del Ser, Aitor Martínez-Seras, Pablo Garcia-Bringas

In the last decade, Artificial Intelligence (AI) models have rapidly
integrated into production pipelines propelled by their excellent modeling
performance. However, the development of these models has not been matched by
advancements in algorithms ensuring their safety, failing to guarantee robust
behavior against Out-of-Distribution (OoD) inputs outside their learning
domain. Furthermore, there is a growing concern with the sustainability of AI
models and their required energy consumption in both training and inference
phases. To mitigate these issues, this work explores the use of the
Forward-Forward Algorithm (FFA), a biologically plausible alternative to
Backpropagation, adapted to the spiking domain to enhance the overall energy
efficiency of the model. By capitalizing on the highly expressive topology
emerging from the latent space of models trained with FFA, we develop a novel
FF-SCP algorithm for OoD Detection. Our approach measures the likelihood of a
sample belonging to the in-distribution (ID) data by using the distance from
the latent representation of samples to class-representative manifolds.
Additionally, to provide deeper insights into our OoD pipeline, we propose a
gradient-free attribution technique that highlights the features of a sample
pushing it away from the distribution of any class. Multiple experiments using
our spiking FFA adaptation demonstrate that the achieved accuracy levels are
comparable to those seen in analog networks trained via back-propagation.
Furthermore, OoD detection experiments on multiple datasets prove that FF-SCP
outperforms avant-garde OoD detectors within the spiking domain in terms of
several metrics used in this area. We also present a qualitative analysis of
our explainability technique, exposing the precision by which the method
detects OoD features, such as embedded artifacts or missing regions.

摘要：<paragraph>在过去十年中，人工智能 (AI) 模型已迅速整合到生產管道中，其優秀的建模效能推動了這項整合。然而，這些模型的開發並未與確保其安全性的演算法進展相匹配，無法保證其對學習領域外的異常分佈 (OoD) 輸入具有穩健的行為。此外，對於 AI 模型的可持續性及其在訓練和推論階段所需的能源消耗，也日益受到關注。為了減輕這些問題，本研究探討了前饋前饋演算法 (FFA) 的用途，這是一種生物學上合理的替代後向傳播的演算法，適用於尖峰域，以提高模型的整體能源效率。透過利用從使用 FFA 訓練的模型潛在空間中產生的高度表現拓撲，我們開發了一種用於 OoD 偵測的新型 FF-SCP 演算法。我們的做法是透過從樣本的潛在表示到類別代表流形的距離，來測量樣本屬於內部分佈 (ID) 資料的可能性。此外，為了更深入地了解我們的 OoD 管道，我們提出了一種無梯度的歸因技術，它突出了樣本的特徵，將其推離任何類別的分布。使用我們的尖峰 FFA 改編進行的多項實驗證明，所達到的準確度等級與透過反向傳播訓練的類比網路中所見到的準確度等級相當。此外，在多個資料集上進行的 OoD 偵測實驗證明，FF-SCP 在尖峰域中優於前衛的 OoD 偵測器，就這個領域中使用的多項指標而言。我們還對我們的可解釋性技術進行了定性分析，揭露了該方法偵測 OoD 特徵（例如嵌入人工製品或遺失區域）的精確度。</paragraph>

##### **People use fast, goal-directed simulation to reason about novel games**
2407.14095v1 by Cedegao E. Zhang, Katherine M. Collins, Lionel Wong, Adrian Weller, Joshua B. Tenenbaum

We can evaluate features of problems and their potential solutions well
before we can effectively solve them. When considering a game we have never
played, for instance, we might infer whether it is likely to be challenging,
fair, or fun simply from hearing the game rules, prior to deciding whether to
invest time in learning the game or trying to play it well. Many studies of
game play have focused on optimality and expertise, characterizing how people
and computational models play based on moderate to extensive search and after
playing a game dozens (if not thousands or millions) of times. Here, we study
how people reason about a range of simple but novel connect-n style board
games. We ask people to judge how fair and how fun the games are from very
little experience: just thinking about the game for a minute or so, before they
have ever actually played with anyone else, and we propose a resource-limited
model that captures their judgments using only a small number of partial game
simulations and almost no lookahead search.

摘要：在我們能有效地解決問題之前，我們就能很好地評估問題的特徵及其潛在的解決方案。例如，在考慮我們從未玩過的遊戲時，我們可能會從聽遊戲規則中推斷出它可能具有挑戰性、公平性或趣味性，然後再決定是否花時間學習遊戲或嘗試玩好它。許多遊戲玩法研究都集中在最佳性和專業知識上，描述了人們和計算模型如何基於中等至廣泛的搜索以及在玩過幾十次（如果不是數千次或數百萬次）遊戲後進行遊戲。在這裡，我們研究了人們如何推理一系列簡單但新穎的連連看樣式的棋盤遊戲。我們要求人們判斷遊戲的公平性和趣味性，而他們幾乎沒有經驗：只需思考遊戲一分鐘左右，在他們實際與其他人一起玩之前，我們提出了一個資源受限的模型，它僅使用少量部分遊戲模擬和幾乎沒有預見搜索來捕捉他們的判斷。

##### **Integrated Push-and-Pull Update Model for Goal-Oriented Effective Communication**
2407.14092v1 by Pouya Agheli, Nikolaos Pappas, Petar Popovski, Marios Kountouris

This paper studies decision-making for goal-oriented effective communication.
We consider an end-to-end status update system where a sensing agent (SA)
observes a source, generates and transmits updates to an actuation agent (AA),
while the AA takes actions to accomplish a goal at the endpoint. We integrate
the push- and pull-based update communication models to obtain a push-and-pull
model, which allows the transmission controller at the SA to decide to push an
update to the AA and the query controller at the AA to pull updates by raising
queries at specific time instances. To gauge effectiveness, we utilize a grade
of effectiveness (GoE) metric incorporating updates' freshness, usefulness, and
timeliness of actions as qualitative attributes. We then derive effect-aware
policies to maximize the expected discounted sum of updates' effectiveness
subject to induced costs. The effect-aware policy at the SA considers the
potential effectiveness of communicated updates at the endpoint, while at the
AA, it accounts for the probabilistic evolution of the source and importance of
generated updates. Our results show the proposed push-and-pull model
outperforms models solely based on push- or pull-based updates both in terms of
efficiency and effectiveness. Additionally, using effect-aware policies at both
agents enhances effectiveness compared to periodic and/or probabilistic
effect-agnostic policies at either or both agents.

摘要：本論文研究以目標為導向的有效溝通的決策制定。
我們考慮一個端到端的狀態更新系統，其中感測代理 (SA)
觀察來源，產生並傳輸更新給執行代理 (AA)，
而 AA 則採取行動以達成端點的目標。我們整合
基於推播和拉取的更新通訊模型以取得推播和拉取
模型，這允許 SA 的傳輸控制器決定推播一個
更新給 AA，以及 AA 的查詢控制器在特定時間實例中提出
查詢以拉取更新。為了衡量有效性，我們利用有效性等級
(GoE) 指標，其中包含更新的新鮮度、實用性和動作的時效性，
作為定性屬性。然後，我們衍生出考量效應的政策，以最大化預期
更新有效性的折現總和，但需符合誘發成本。SA 的考量效應政策
考慮在端點傳輸更新的潛在有效性，而在 AA 中，它考量來源的
機率演進和產生更新的重要性。我們的結果顯示，所提出的推播和拉取
模型在效率和有效性方面都優於僅基於推播或拉取更新的模型。此外，
在兩個代理都使用考量效應的政策，與其中任一代理或兩個代理都使用
週期性和/或機率性非效應感知政策相比，可增進有效性。

##### **Impact of Model Size on Fine-tuned LLM Performance in Data-to-Text Generation: A State-of-the-Art Investigation**
2407.14088v1 by Joy Mahapatra, Utpal Garain

Data-to-text (D2T) generation aims to generate human-readable text from
semi-structured data, such as tables and graphs. The recent success of D2T is
largely attributed to advancements in LLMs. Despite the success of LLMs, no
research has been conducted to illustrate the impact of model size on the
performance of fine-tuned LLMs for D2T tasks. D2T model performance is
typically assessed based on three key qualities: \textit{readability}
(indicates fluency and coherence), \textit{informativeness} (measures content
similarity), and \textit{faithfulness} (assesses consistency of factual
information). It is currently uncertain whether increasing the size of LLMs
effectively improves performance in D2T tasks across these three qualities. The
objective of this study is to investigate the performance of fine-tuned LLMs in
D2T tasks in terms of model size. Through extensive comparative analysis, we
aim to elucidate both the advantages and limitations of scaling model sizes
across five widely used D2T datasets (E2E, ViGGo, WikiTableText, DART, and
WebNLG) and twelve state-of-the-art LLMs with varying sizes from five different
LLM families (T5, BART, OPT, BLOOM, and Llama 2). To comprehensively cover all
the three essential qualities of D2T models, we incorporate six widely
recognized automatic metrics -- \textsc{BLEU}, \textsc{METEOR},
\textsc{BERTScore}, \textsc{MoverScore}, \textsc{Parent}, and
\textsc{BARTScore}. We also provide an in-depth analysis of LLM performance
concerning model size in the presence of source-reference divergence, a
critical aspect of D2T tasks. Our investigation reveals that increasing LLM
size enhances \textit{readability} and \textit{informativeness} in D2T tasks,
but larger (in terms of size) LLMs may sacrifice \textit{faithfulness}.
Moreover, small-sized LLMs show more resilience than larger ones when
source-reference divergence is present.

摘要：資料轉文字 (D2T) 生成旨在從表格和圖表等半結構化資料中產生人類可讀的文字。近期 D2T 的成功在很大程度上歸功於 LLM 的進步。儘管 LLM 取得成功，但尚未進行任何研究來說明模型大小對微調 LLM 在 D2T 任務中的效能有何影響。D2T 模型效能通常根據三個關鍵品質進行評估：\textit{可讀性}（表示流暢度和連貫性）、\textit{資訊性}（衡量內容相似性）和\textit{忠實性}（評估事實資訊的一致性）。目前尚不確定增加 LLM 的大小是否能有效提升 D2T 任務中這三項品質的效能。本研究的目標是探討微調 LLM 在 D2T 任務中的效能，並考量模型大小。透過廣泛的比較分析，我們旨在闡明擴充模型大小在五個廣泛使用的 D2T 資料集（E2E、ViGGo、WikiTableText、DART 和 WebNLG）和十二個最先進的 LLM（來自五個不同 LLM 家族的 T5、BART、OPT、BLOOM 和 Llama 2）中的優點和限制。為了全面涵蓋 D2T 模型的所有三個基本品質，我們納入了六項廣泛認可的自動化指標——\textsc{BLEU}、\textsc{METEOR}、\textsc{BERTScore}、\textsc{MoverScore}、\textsc{Parent} 和 \textsc{BARTScore}。我們還針對 LLM 效能提供深入分析，探討模型大小在存在來源參考差異（D2T 任務的一個關鍵面向）時的影響。我們的研究揭示，增加 LLM 大小會增強 D2T 任務中的\textit{可讀性}和\textit{資訊性}，但較大的（就大小而言）LLM 可能會犧牲\textit{忠實性}。此外，當存在來源參考差異時，小型 LLM 比大型 LLM 表現出更強的韌性。

##### **An Improved Method for Class-specific Keyword Extraction: A Case Study in the German Business Registry**
2407.14085v1 by Stephen Meisenbacher, Tim Schopf, Weixin Yan, Patrick Holl, Florian Matthes

The task of $\textit{keyword extraction}$ is often an important initial step
in unsupervised information extraction, forming the basis for tasks such as
topic modeling or document classification. While recent methods have proven to
be quite effective in the extraction of keywords, the identification of
$\textit{class-specific}$ keywords, or only those pertaining to a predefined
class, remains challenging. In this work, we propose an improved method for
class-specific keyword extraction, which builds upon the popular
$\textbf{KeyBERT}$ library to identify only keywords related to a class
described by $\textit{seed keywords}$. We test this method using a dataset of
German business registry entries, where the goal is to classify each business
according to an economic sector. Our results reveal that our method greatly
improves upon previous approaches, setting a new standard for
$\textit{class-specific}$ keyword extraction.

摘要：<paragraph>$\textit{關鍵字萃取}$ 的任務通常是無監督資訊萃取中重要的第一步，形成主題模型或文件分類等任務的基礎。雖然最近的方法已證明在關鍵字萃取方面相當有效，但 $\textit{類別特定}$ 關鍵字（或僅屬於預定義類別的關鍵字）的辨識仍然具有挑戰性。在這項工作中，我們提出了一種改進的類別特定關鍵字萃取方法，它建立在廣受歡迎的 $\textbf{KeyBERT}$ 函式庫上，僅辨識與 $\textit{種子關鍵字}$ 所描述類別相關的關鍵字。我們使用一個德國商業註冊條目的資料集來測試此方法，目標是根據經濟部門對每個企業進行分類。我們的結果顯示，我們的這種方法大大改進了先前的做法，為 $\textit{類別特定}$ 關鍵字萃取樹立了新的標準。</paragraph>

##### **DisenSemi: Semi-supervised Graph Classification via Disentangled Representation Learning**
2407.14081v1 by Yifan Wang, Xiao Luo, Chong Chen, Xian-Sheng Hua, Ming Zhang, Wei Ju

Graph classification is a critical task in numerous multimedia applications,
where graphs are employed to represent diverse types of multimedia data,
including images, videos, and social networks. Nevertheless, in real-world
scenarios, labeled graph data can be limited or scarce. To address this issue,
we focus on the problem of semi-supervised graph classification, which involves
both supervised and unsupervised models learning from labeled and unlabeled
data. In contrast to recent approaches that transfer the entire knowledge from
the unsupervised model to the supervised one, we argue that an effective
transfer should only retain the relevant semantics that align well with the
supervised task. In this paper, we propose a novel framework named DisenSemi,
which learns disentangled representation for semi-supervised graph
classification. Specifically, a disentangled graph encoder is proposed to
generate factor-wise graph representations for both supervised and unsupervised
models. Then we train two models via supervised objective and mutual
information (MI)-based constraints respectively. To ensure the meaningful
transfer of knowledge from the unsupervised encoder to the supervised one, we
further define an MI-based disentangled consistency regularization between two
models and identify the corresponding rationale that aligns well with the
current graph classification task. Experimental results on a range of publicly
accessible datasets reveal the effectiveness of our DisenSemi.

摘要：圖形分類在眾多多媒體應用中是一項重要的任務，
其中圖形用於表示各種類型的多媒體數據，
包括圖像、影片和社交網路。儘管如此，在實際
場景中，標籤圖形數據可能有限或稀少。為了解決這個問題，
我們專注於半監督圖形分類問題，其中涉及
監督式和非監督式模型從標籤和未標籤
數據中學習。與最近將整個知識從
非監督式模型轉移到監督式模型的方法相反，我們認為有效的
轉移應該只保留與監督式任務密切對齊的相關語義。在本文中，我們提出一個名為 DisenSemi 的新框架，
它學習 disentangled 表示法用於半監督圖形
分類。具體來說，提出了一個 disentangled 圖形編碼器來
為監督式和非監督式模型生成基於因子的圖形表示。然後我們通過監督式目標和基於互信息 (MI) 的約束分別訓練兩個模型。為了確保從非監督式編碼器到監督式編碼器的知識有意義地轉移，我們
進一步定義了兩個模型之間基於 MI 的 disentangled 一致性正則化，並找出與
當前圖形分類任務密切對齊的相應依據。在各種公開
可存取的資料集上的實驗結果揭示了我們 DisenSemi 的有效性。

##### **Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field**
2407.14076v1 by Tobias Kerner

There are many cases where LLMs are used for specific tasks in a single
domain. These usually require less general, but more domain-specific knowledge.
Highly capable, general-purpose state-of-the-art language models like GPT-4 or
Claude-3-opus can often be used for such tasks, but they are very large and
cannot be run locally, even if they were not proprietary. This can be a problem
when working with sensitive data. This paper focuses on domain-specific and
mixed-domain pretraining as potentially more efficient methods than general
pretraining for specialized language models. We will take a look at work
related to domain-specific pretraining, specifically in the medical area, and
compare benchmark results of specialized language models to general-purpose
language models.

摘要：在許多情況下，LLM 被用於單一領域中的特定任務。這些任務通常需要較少的通用知識，但需要更多特定領域的知識。功能強大、用途廣泛的最新語言模型，例如 GPT-4 或 Claude-3-opus，通常可用於此類任務，但它們非常龐大，即使不是專有軟體，也無法在本地執行。在處理敏感資料時，這可能會造成問題。本文重點探討特定領域和混合領域的預訓練，作為比一般預訓練更有效率的專業語言模型潛在方法。我們將探討與特定領域預訓練相關的工作，特別是在醫療領域，並比較專業語言模型與通用語言模型的基準測試結果。

##### **LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference**
2407.14057v1 by Qichen Fu, Minsik Cho, Thomas Merth, Sachin Mehta, Mohammad Rastegari, Mahyar Najibi

The inference of transformer-based large language models consists of two
sequential stages: 1) a prefilling stage to compute the KV cache of prompts and
generate the first token, and 2) a decoding stage to generate subsequent
tokens. For long prompts, the KV cache must be computed for all tokens during
the prefilling stage, which can significantly increase the time needed to
generate the first token. Consequently, the prefilling stage may become a
bottleneck in the generation process. An open question remains whether all
prompt tokens are essential for generating the first token. To answer this, we
introduce a novel method, LazyLLM, that selectively computes the KV for tokens
important for the next token prediction in both the prefilling and decoding
stages. Contrary to static pruning approaches that prune the prompt at once,
LazyLLM allows language models to dynamically select different subsets of
tokens from the context in different generation steps, even though they might
be pruned in previous steps. Extensive experiments on standard datasets across
various tasks demonstrate that LazyLLM is a generic method that can be
seamlessly integrated with existing language models to significantly accelerate
the generation without fine-tuning. For instance, in the multi-document
question-answering task, LazyLLM accelerates the prefilling stage of the LLama
2 7B model by 2.34x while maintaining accuracy.

摘要：基於 Transformer 的大型語言模型的推論包含兩個順序階段：1) 預填充階段，用於計算提示的 KV 快取並產生第一個符號，以及 2) 解碼階段，用於產生後續符號。對於長提示，必須在預填充階段為所有符號計算 KV 快取，這會大幅增加產生第一個符號所需的時間。因此，預填充階段可能會成為產生過程中的瓶頸。一個開放性的問題仍然是，所有提示符號對於產生第一個符號是否都是必要的。為了回答這個問題，我們引入了一個新方法，LazyLLM，它在預填充和解碼階段有選擇地計算對於下一個符號預測很重要的符號的 KV。與一次修剪提示的靜態修剪方法相反，LazyLLM 允許語言模型在不同的產生步驟中從上下文中動態選擇符號的不同子集，即使它們可能在先前的步驟中被修剪。在各種任務上對標準資料集進行的廣泛實驗表明，LazyLLM 是一種通用方法，可以無縫地與現有語言模型整合，以在不進行微調的情況下顯著加速產生。例如，在多文件問答任務中，LazyLLM 將 LLama 2 7B 模型的預填充階段加速了 2.34 倍，同時保持了準確性。

##### **Rasa: Building Expressive Speech Synthesis Systems for Indian Languages in Low-resource Settings**
2407.14056v1 by Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra

We release Rasa, the first multilingual expressive TTS dataset for any Indian
language, which contains 10 hours of neutral speech and 1-3 hours of expressive
speech for each of the 6 Ekman emotions covering 3 languages: Assamese,
Bengali, & Tamil. Our ablation studies reveal that just 1 hour of neutral and
30 minutes of expressive data can yield a Fair system as indicated by MUSHRA
scores. Increasing neutral data to 10 hours, with minimal expressive data,
significantly enhances expressiveness. This offers a practical recipe for
resource-constrained languages, prioritizing easily obtainable neutral data
alongside smaller amounts of expressive data. We show the importance of
syllabically balanced data and pooling emotions to enhance expressiveness. We
also highlight challenges in generating specific emotions, e.g., fear and
surprise.

摘要：我們發布 Rasa，這是第一個針對任何印度語言的多語言表達式 TTS 資料集，其中包含 10 小時的自然語音和 1-3 小時的表達式語音，涵蓋 3 種語言的 6 種 Ekman 情緒：阿薩姆語、孟加拉語和泰米爾語。我們的消融研究表明，僅 1 小時的自然語音和 30 分鐘的表達式資料即可產生一個公平的系統，如 MUSHRA 分數所示。將自然資料增加到 10 小時，並使用最少的表達式資料，可以顯著增強表達力。這為資源受限的語言提供了一個實用的方法，優先考慮易於取得的自然資料以及較少量的表達式資料。我們展示了音節平衡資料和匯集情緒以增強表達力的重要性。我們還強調了產生特定情緒（例如恐懼和驚訝）的挑戰。

##### **Quantum Hamiltonian Embedding of Images for Data Reuploading Classifiers**
2407.14055v1 by Peiyong Wang, Casey R. Myers, Lloyd C. L. Hollenberg, Udaya Parampalli

When applying quantum computing to machine learning tasks, one of the first
considerations is the design of the quantum machine learning model itself.
Conventionally, the design of quantum machine learning algorithms relies on the
``quantisation" of classical learning algorithms, such as using quantum linear
algebra to implement important subroutines of classical algorithms, if not the
entire algorithm, seeking to achieve quantum advantage through possible
run-time accelerations brought by quantum computing. However, recent research
has started questioning whether quantum advantage via speedup is the right goal
for quantum machine learning [1]. Research also has been undertaken to exploit
properties that are unique to quantum systems, such as quantum contextuality,
to better design quantum machine learning models [2]. In this paper, we take an
alternative approach by incorporating the heuristics and empirical evidences
from the design of classical deep learning algorithms to the design of quantum
neural networks. We first construct a model based on the data reuploading
circuit [3] with the quantum Hamiltonian data embedding unitary [4]. Through
numerical experiments on images datasets, including the famous MNIST and
FashionMNIST datasets, we demonstrate that our model outperforms the quantum
convolutional neural network (QCNN)[5] by a large margin (up to over 40% on
MNIST test set). Based on the model design process and numerical results, we
then laid out six principles for designing quantum machine learning models,
especially quantum neural networks.

摘要：<paragraph>在將量子運算應用於機器學習任務時，首先要考慮的是量子機器學習模型本身的設計。傳統上，量子機器學習演算法的設計依賴於經典學習演算法的「量子化」，例如使用量子線性代數來實作經典演算法的重要子常式，如果不是整個演算法，則尋求透過量子運算帶來的可能執行時間加速來獲得量子優勢。然而，最近的研究開始質疑透過加速的量子優勢是否是量子機器學習的正確目標 [1]。研究也已進行，以利用量子系統獨有的特性，例如量子脈絡性，來更好地設計量子機器學習模型 [2]。在本文中，我們透過將經典深度學習演算法設計中的啟發法和實證證據納入量子神經網路的設計中，採取了一種替代方法。我們首先根據資料重新上傳電路 [3] 構築一個模型，並使用量子哈密頓資料嵌入酉 [4]。透過在影像資料集（包括著名的 MNIST 和 FashionMNIST 資料集）上進行數值實驗，我們證明我們的模型在很大程度上優於量子卷積神經網路 (QCNN)[5]（在 MNIST 測試集上最多超過 40%）。根據模型設計過程和數值結果，我們接著提出了設計量子機器學習模型，特別是量子神經網路的六項原則。</paragraph>

##### **Prompted Aspect Key Point Analysis for Quantitative Review Summarization**
2407.14049v1 by An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Erik Cambria

Key Point Analysis (KPA) aims for quantitative summarization that provides
key points (KPs) as succinct textual summaries and quantities measuring their
prevalence. KPA studies for arguments and reviews have been reported in the
literature. A majority of KPA studies for reviews adopt supervised learning to
extract short sentences as KPs before matching KPs to review comments for
quantification of KP prevalence. Recent abstractive approaches still generate
KPs based on sentences, often leading to KPs with overlapping and hallucinated
opinions, and inaccurate quantification. In this paper, we propose Prompted
Aspect Key Point Analysis (PAKPA) for quantitative review summarization. PAKPA
employs aspect sentiment analysis and prompted in-context learning with Large
Language Models (LLMs) to generate and quantify KPs grounded in aspects for
business entities, which achieves faithful KPs with accurate quantification,
and removes the need for large amounts of annotated data for supervised
training. Experiments on the popular review dataset Yelp and the
aspect-oriented review summarization dataset SPACE show that our framework
achieves state-of-the-art performance. Source code and data are available at:
https://github.com/antangrocket1312/PAKPA

摘要：關鍵點分析 (KPA) 旨在進行量化摘要，提供關鍵點 (KP) 作為簡潔的文字摘要，並量化測量其流行程度。文獻中已報導了針對論點和評論的 KPA 研究。大多數針對評論的 KPA 研究採用監督式學習，先將短句萃取為 KP，再比對評論中的評論，以量化 KP 的流行程度。最近的抽象式方法仍根據句子產生 KP，這通常會導致 KP 出現重疊和虛構的意見，以及不準確的量化。在本文中，我們提出提示式面向關鍵點分析 (PAKPA)，用於量化評論摘要。PAKPA 採用面向的意見分析和提示式情境學習，搭配大型語言模型 (LLM)，以產生和量化以商業實體面向為基礎的 KP，這可達成具有準確量化的忠實 KP，並消除監督式訓練大量標註資料的需求。在熱門評論資料集 Yelp 和面向評論摘要資料集 SPACE 上的實驗顯示，我們的架構達到了最先進的效能。原始碼和資料可取得：https://github.com/antangrocket1312/PAKPA

##### **ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?**
2407.14044v1 by Siddhant Waghjale, Vishruth Veerendranath, Zora Zhiruo Wang, Daniel Fried

Although large language models (LLMs) have been largely successful in
generating functionally correct programs, conditioning models to produce
efficient solutions while ensuring correctness remains a challenge. Further,
unreliability in benchmarking code efficiency is a hurdle across varying
hardware specifications for popular interpreted languages such as Python. In
this paper, we present ECCO, a reproducible benchmark for evaluating program
efficiency via two paradigms: natural language (NL) based code generation and
history-based code editing. On ECCO, we adapt and thoroughly investigate the
three most promising existing LLM-based approaches: in-context learning,
iterative refinement with execution or NL feedback, and fine-tuning conditioned
on execution and editing history. While most methods degrade functional
correctness and moderately increase program efficiency, we find that adding
execution information often helps maintain functional correctness, and NL
feedback enhances more on efficiency. We release our benchmark to support
future work on LLM-based generation of efficient code.

摘要：儘管大型語言模型 (LLM) 在產生功能正確的程式上已獲得極大的成功，但訓練模型以產生有效率的解決方案，同時確保正確性仍然是一個挑戰。此外，對 Python 等流行直譯語言來說，在不同硬體規格上的基準代碼效率不可靠，是一個障礙。在本文中，我們提出 ECCO，一個可重製的基準，用於透過兩種範例來評估程式效率：基於自然語言 (NL) 的程式碼產生和基於歷史的程式碼編輯。在 ECCO 上，我們改編並徹底研究了三種最有前途的現有 LLM 基礎方法：情境中學習、透過執行或 NL 回饋的迭代精煉，以及基於執行和編輯歷史的微調。儘管大多數方法會降低功能正確性並適度提高程式效率，但我們發現，新增執行資訊通常有助於維持功能正確性，而 NL 回饋更能提升效率。我們釋出我們的基準，以支援未來基於 LLM 產生有效率程式碼的工作。

##### **BERTer: The Efficient One**
2407.14039v1 by Pradyumna Saligram, Andrew Lanpouthakoun

We explore advanced fine-tuning techniques to boost BERT's performance in
sentiment analysis, paraphrase detection, and semantic textual similarity. Our
approach leverages SMART regularization to combat overfitting, improves
hyperparameter choices, employs a cross-embedding Siamese architecture for
improved sentence embeddings, and introduces innovative early exiting methods.
Our fine-tuning findings currently reveal substantial improvements in model
efficiency and effectiveness when combining multiple fine-tuning architectures,
achieving a state-of-the-art performance score of on the test set, surpassing
current benchmarks and highlighting BERT's adaptability in multifaceted
linguistic tasks.

摘要：我們探索進階微調技術，以提升 BERT 在情緒分析、同義詞偵測和語意文本相似度中的效能。我們的做法利用 SMART 正規化來對抗過度擬合，改善超參數選擇，採用跨嵌入式 Siamese 架構來改善句子嵌入，並導入創新的早期退出方法。我們的微調發現目前顯示，在結合多個微調架構時，模型的效率和效能有顯著的提升，在測試集中達到最先進的效能評分，超越目前的基準，並突顯 BERT 在多面向語言任務中的適應性。

##### **HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research**
2407.14030v1 by Prerana Sanjay Kulkarni, Muskaan Jain, Disha Sheshanarayana, Srinivasan Parthiban

Despite advancements in drug development strategies, 90% of clinical trials
fail. This suggests overlooked aspects in target validation and drug
optimization. In order to address this, we introduce HeCiX-KG,
Hetionet-Clinicaltrials neXus Knowledge Graph, a novel fusion of data from
ClinicalTrials.gov and Hetionet in a single knowledge graph. HeCiX-KG combines
data on previously conducted clinical trials from ClinicalTrials.gov, and
domain expertise on diseases and genes from Hetionet. This offers a thorough
resource for clinical researchers. Further, we introduce HeCiX, a system that
uses LangChain to integrate HeCiX-KG with GPT-4, and increase its usability.
HeCiX shows high performance during evaluation against a range of clinically
relevant issues, proving this model to be promising for enhancing the
effectiveness of clinical research. Thus, this approach provides a more
holistic view of clinical trials and existing biological data.

摘要：儘管藥物開發策略有進展，90% 的臨床試驗都失敗了。這表示在目標驗證和藥物最佳化方面有被忽略的層面。為了解決這個問題，我們引進了 HeCiX-KG，Hetionet-Clinicaltrials neXus 知識圖譜，這是一個將 ClinicalTrials.gov 和 Hetionet 的資料融合在單一知識圖譜中的新穎融合。HeCiX-KG 結合了來自 ClinicalTrials.gov 的先前執行臨床試驗資料，以及來自 Hetionet 的疾病和基因領域專業知識。這為臨床研究人員提供了豐富的資源。此外，我們引進了 HeCiX，一個使用 LangChain 將 HeCiX-KG 與 GPT-4 整合，並提高其可用性的系統。HeCiX 在針對一系列臨床相關問題的評估中表現出高性能，證明了這個模型有望提高臨床研究的有效性。因此，這種方法提供了對臨床試驗和現有生物資料更全面的看法。

##### **TTA-OOD: Test-time Augmentation for Improving Out-of-Distribution Detection in Gastrointestinal Vision**
2407.14024v1 by Sandesh Pokhrel, Sanjay Bhandari, Eduard Vazquez, Tryphon Lambrou, Prashnna Gyawali, Binod Bhattarai

Deep learning has significantly advanced the field of gastrointestinal
vision, enhancing disease diagnosis capabilities. One major challenge in
automating diagnosis within gastrointestinal settings is the detection of
abnormal cases in endoscopic images. Due to the sparsity of data, this process
of distinguishing normal from abnormal cases has faced significant challenges,
particularly with rare and unseen conditions. To address this issue, we frame
abnormality detection as an out-of-distribution (OOD) detection problem. In
this setup, a model trained on In-Distribution (ID) data, which represents a
healthy GI tract, can accurately identify healthy cases, while abnormalities
are detected as OOD, regardless of their class. We introduce a test-time
augmentation segment into the OOD detection pipeline, which enhances the
distinction between ID and OOD examples, thereby improving the effectiveness of
existing OOD methods with the same model. This augmentation shifts the pixel
space, which translates into a more distinct semantic representation for OOD
examples compared to ID examples. We evaluated our method against existing
state-of-the-art OOD scores, showing improvements with test-time augmentation
over the baseline approach.

摘要：深度學習顯著提升了胃腸道影像領域，增強了疾病診斷能力。在胃腸道環境中自動化診斷的一項重大挑戰是內視鏡影像中異常病例的偵測。由於資料稀疏，這種將正常病例與異常病例區分的過程面臨重大挑戰，特別是罕見且前所未見的情況。為了解決這個問題，我們將異常偵測設定為一個離群值（OOD）偵測問題。在此設定中，針對分布內（ID）資料（代表健康的胃腸道）訓練的模型可以準確識別健康病例，而異常則被偵測為 OOD，不論其類別為何。我們在 OOD 偵測管線中引入測試時間擴充區段，增強 ID 和 OOD 範例之間的區別，從而提升同一個模型中現有 OOD 方法的有效性。這種擴充轉移了像素空間，相較於 ID 範例，這轉化為 OOD 範例更為明確的語義表示。我們針對現有的最先進 OOD 分數評估了我們的方法，顯示出測試時間擴充優於基準方法。

##### **Multi-modal Relation Distillation for Unified 3D Representation Learning**
2407.14007v1 by Huiqun Wang, Yiping Bao, Panwang Pan, Zeming Li, Xiao Liu, Ruijie Yang, Di Huang

Recent advancements in multi-modal pre-training for 3D point clouds have
demonstrated promising results by aligning heterogeneous features across 3D
shapes and their corresponding 2D images and language descriptions. However,
current straightforward solutions often overlook intricate structural relations
among samples, potentially limiting the full capabilities of multi-modal
learning. To address this issue, we introduce Multi-modal Relation Distillation
(MRD), a tri-modal pre-training framework, which is designed to effectively
distill reputable large Vision-Language Models (VLM) into 3D backbones. MRD
aims to capture both intra-relations within each modality as well as
cross-relations between different modalities and produce more discriminative 3D
shape representations. Notably, MRD achieves significant improvements in
downstream zero-shot classification tasks and cross-modality retrieval tasks,
delivering new state-of-the-art performance.

摘要：最近在 3D 点云的多模态预训练方面取得的进展已通过对 3D 形状及其对应的 2D 图像和语言描述中的异构特征进行对齐，展示了有希望的结果。然而，当前的直接解决方案通常会忽略样本之间的复杂结构关系，这可能会限制多模态学习的全部功能。为了解决这个问题，我们引入了多模态关系蒸馏 (MRD)，这是一个三模态预训练框架，旨在将信誉良好的大型视觉语言模型 (VLM) 有效地蒸馏到 3D 骨干中。MRD 旨在捕获每个模态内的内部关系以及不同模态之间的交叉关系，并生成更具辨别力的 3D 形状表示。值得注意的是，MRD 在下游零样本分类任务和跨模态检索任务中取得了显着改进，提供了新的最先进的性能。

##### **Clinical Reading Comprehension with Encoder-Decoder Models Enhanced by Direct Preference Optimization**
2407.14000v1 by Md Sultan Al Nahian, Ramakanth Kavuluru

Extractive question answering over clinical text is a crucial need to help
deal with the deluge of clinical text generated in hospitals. While encoder
models (e.g., BERT) have been popular for this reading comprehension task,
recently encoder-decoder models (e.g., T5) are on the rise. There is also the
emergence of preference optimization techniques to align decoder-only LLMs with
human preferences. In this paper, we combine encoder-decoder models with the
direct preference optimization (DPO) method to improve over prior state of the
art for the RadQA radiology question answering task by 12-15 F1 points. To the
best of our knowledge, this effort is the first to show that DPO method also
works for reading comprehension via novel heuristics to generate preference
data without human inputs.

摘要：萃取式臨床文字問答對於處理醫院產生的龐大臨床文字至關重要。雖然編碼器模型（例如 BERT）一直廣受歡迎，用於此閱讀理解任務，但最近編碼器-解碼器模型（例如 T5）正在興起。此外，偏好最佳化技術也浮現，用於將僅解碼器 LLM 與人類偏好對齊。在本文中，我們將編碼器-解碼器模型與直接偏好最佳化 (DPO) 方法結合，以將 RadQA 放射學問答任務的先前技術水準提升 12-15 個 F1 點。據我們所知，此努力是第一個顯示 DPO 方法也適用於閱讀理解，透過新穎啟發法來產生偏好資料，而無需人類輸入。

##### **NeLLCom-X: A Comprehensive Neural-Agent Framework to Simulate Language Learning and Group Communication**
2407.13999v1 by Yuchen Lian, Tessa Verhoef, Arianna Bisazza

Recent advances in computational linguistics include simulating the emergence
of human-like languages with interacting neural network agents, starting from
sets of random symbols. The recently introduced NeLLCom framework (Lian et al.,
2023) allows agents to first learn an artificial language and then use it to
communicate, with the aim of studying the emergence of specific linguistics
properties. We extend this framework (NeLLCom-X) by introducing more realistic
role-alternating agents and group communication in order to investigate the
interplay between language learnability, communication pressures, and group
size effects. We validate NeLLCom-X by replicating key findings from prior
research simulating the emergence of a word-order/case-marking trade-off. Next,
we investigate how interaction affects linguistic convergence and emergence of
the trade-off. The novel framework facilitates future simulations of diverse
linguistic aspects, emphasizing the importance of interaction and group
dynamics in language evolution.

摘要：最近在計算語言學上的進展包括模擬人類語言的出現，其中互動的神經網路代理從一組隨機符號開始。最近推出的 NeLLCom 框架（Lian 等人，2023 年）允許代理先學習一種人造語言，然後使用它來溝通，目的是研究特定語言學特性的出現。我們通過引入更逼真的角色交替代理和群組溝通來擴充這個框架（NeLLCom-X），以研究語言可學習性、溝通壓力和群組規模效應之間的交互作用。我們透過複製先前研究的關鍵發現，模擬詞序/格標記權衡的出現來驗證 NeLLCom-X。接下來，我們研究互動如何影響語言融合和權衡的出現。這個新穎的框架有助於未來模擬各種語言面向，強調互動和群組動態在語言演化中的重要性。

##### **RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering**
2407.13998v1 by Rujun Han, Yuhao Zhang, Peng Qi, Yumo Xu, Jenyuan Wang, Lan Liu, William Yang Wang, Bonan Min, Vittorio Castelli

Question answering based on retrieval augmented generation (RAG-QA) is an
important research topic in NLP and has a wide range of real-world
applications. However, most existing datasets for this task are either
constructed using a single source corpus or consist of short extractive
answers, which fall short of evaluating large language model (LLM) based RAG-QA
systems on cross-domain generalization. To address these limitations, we create
Long-form RobustQA (LFRQA), a new dataset comprising human-written long-form
answers that integrate short extractive answers from multiple documents into a
single, coherent narrative, covering 26K queries and large corpora across seven
different domains. We further propose RAG-QA Arena by directly comparing
model-generated answers against LFRQA's answers using LLMs as evaluators. We
show via extensive experiments that RAG-QA Arena and human judgments on answer
quality are highly correlated. Moreover, only 41.3% of the most competitive
LLM's answers are preferred to LFRQA's answers, demonstrating RAG-QA Arena as a
challenging evaluation platform for future research.

摘要：基於擷取擴充生成（RAG-QA）的問題解答是 NLP 中一個重要的研究主題，並有廣泛的真實世界應用。然而，大多數現有的資料集不是使用單一來源語料庫建構，就是由簡短的抽取式答案組成，這無法評估基於大型語言模型（LLM）的 RAG-QA 系統在跨網域概括上的表現。為了解決這些限制，我們建立了長篇 RobustQA（LFRQA），一個新的資料集，包含人工撰寫的長篇答案，將來自多個文件的簡短抽取式答案整合到一個單一的連貫敘述中，涵蓋 26K 個查詢和橫跨七個不同網域的大型語料庫。我們進一步提出 RAG-QA Arena，透過使用 LLM 作為評估器，直接比較模型產生的答案和 LFRQA 的答案。我們透過廣泛的實驗證明，RAG-QA Arena 和人類對答案品質的判斷高度相關。此外，只有 41.3% 最具競爭力的 LLM 答案優於 LFRQA 的答案，這證明了 RAG-QA Arena 是未來研究具有挑戰性的評估平台。

##### **LLAssist: Simple Tools for Automating Literature Review Using Large Language Models**
2407.13993v1 by Christoforus Yoga Haryanto

This paper introduces LLAssist, an open-source tool designed to streamline
literature reviews in academic research. In an era of exponential growth in
scientific publications, researchers face mounting challenges in efficiently
processing vast volumes of literature. LLAssist addresses this issue by
leveraging Large Language Models (LLMs) and Natural Language Processing (NLP)
techniques to automate key aspects of the review process. Specifically, it
extracts important information from research articles and evaluates their
relevance to user-defined research questions. The goal of LLAssist is to
significantly reduce the time and effort required for comprehensive literature
reviews, allowing researchers to focus more on analyzing and synthesizing
information rather than on initial screening tasks. By automating parts of the
literature review workflow, LLAssist aims to help researchers manage the
growing volume of academic publications more efficiently.

摘要：本文介紹 LLAssist，這是一款開放原始碼工具，旨在簡化學術研究中的文獻回顧。在科學出版物呈指數增長的時代，研究人員在有效處理大量文獻方面面臨著越來越大的挑戰。LLAssist 透過利用大型語言模型 (LLM) 和自然語言處理 (NLP) 技術自動化回顧過程中的關鍵方面，來解決這個問題。具體來說，它從研究文章中萃取出重要資訊，並評估其與使用者定義的研究問題相關性。LLAssist 的目標是大幅減少全面文獻回顧所需的時間和精力，讓研究人員能更專注於分析和綜合資訊，而非初始篩選任務。透過自動化文獻回顧工作流程的一部分，LLAssist 旨在幫助研究人員更有效地管理日益增長的學術出版物數量。

##### **Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**
2407.13989v1 by Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang

Graphs have emerged as critical data structures for content analysis in
various domains, such as social network analysis, bioinformatics, and
recommendation systems. Node classification, a fundamental task in this
context, is typically tackled using graph neural networks (GNNs).
Unfortunately, conventional GNNs still face challenges in scenarios with few
labeled nodes, despite the prevalence of few-shot node classification tasks in
real-world applications. To address this challenge, various approaches have
been proposed, including graph meta-learning, transfer learning, and methods
based on Large Language Models (LLMs). However, traditional meta-learning and
transfer learning methods often require prior knowledge from base classes or
fail to exploit the potential advantages of unlabeled nodes. Meanwhile,
LLM-based methods may overlook the zero-shot capabilities of LLMs and rely
heavily on the quality of generated contexts. In this paper, we propose a novel
approach that integrates LLMs and GNNs, leveraging the zero-shot inference and
reasoning capabilities of LLMs and employing a Graph-LLM-based active learning
paradigm to enhance GNNs' performance. Extensive experiments demonstrate the
effectiveness of our model in improving node classification accuracy with
considerably limited labeled data, surpassing state-of-the-art baselines by
significant margins.

摘要：圖表已成為各種領域中內容分析的關鍵數據結構，例如社交網路分析、生物資訊學和推薦系統。節點分類是此脈絡中的基本任務，通常使用圖形神經網路 (GNN) 來處理。不幸的是，儘管現實世界應用中普遍存在少樣本節點分類任務，但傳統的 GNN 在標記節點很少的情況下仍面臨挑戰。為了應對這一挑戰，已提出各種方法，包括圖形元學習、遷移學習和基於大型語言模型 (LLM) 的方法。然而，傳統的元學習和遷移學習方法通常需要來自基礎類別的先驗知識，或者無法利用未標記節點的潛在優勢。同時，基於 LLM 的方法可能會忽視 LLM 的零樣本能力，並且過度依賴生成語境的品質。在本文中，我們提出了一種新的方法，它整合了 LLM 和 GNN，利用 LLM 的零樣本推論和推理能力，並採用基於 Graph-LLM 的主動學習範例來增強 GNN 的效能。廣泛的實驗證明了我們的模型在改進節點分類準確度方面的有效性，標記數據相當有限，顯著超越了最先進的基準。

##### **Reexamining Racial Disparities in Automatic Speech Recognition Performance: The Role of Confounding by Provenance**
2407.13982v1 by Changye Li, Trevor Cohen, Serguei Pakhomov

Automatic speech recognition (ASR) models trained on large amounts of audio
data are now widely used to convert speech to written text in a variety of
applications from video captioning to automated assistants used in healthcare
and other domains. As such, it is important that ASR models and their use is
fair and equitable. Prior work examining the performance of commercial ASR
systems on the Corpus of Regional African American Language (CORAAL)
demonstrated significantly worse ASR performance on African American English
(AAE). The current study seeks to understand the factors underlying this
disparity by examining the performance of the current state-of-the-art neural
network based ASR system (Whisper, OpenAI) on the CORAAL dataset. Two key
findings have been identified as a result of the current study. The first
confirms prior findings of significant dialectal variation even across
neighboring communities, and worse ASR performance on AAE that can be improved
to some extent with fine-tuning of ASR models. The second is a novel finding
not discussed in prior work on CORAAL: differences in audio recording practices
within the dataset have a significant impact on ASR accuracy resulting in a
``confounding by provenance'' effect in which both language use and recording
quality differ by study location. These findings highlight the need for further
systematic investigation to disentangle the effects of recording quality and
inherent linguistic diversity when examining the fairness and bias present in
neural ASR models, as any bias in ASR accuracy may have negative downstream
effects on disparities in various domains of life in which ASR technology is
used.

摘要：<paragraph>訓練大量音訊資料的自動語音辨識 (ASR) 模型現在廣泛用於將語音轉換為書面文字，應用於從影片字幕到醫療保健和其他領域中使用的自動化助理程式。因此，ASR 模型及其使用方式的公平性和公正性非常重要。先前針對商業 ASR 系統在非洲裔美國人語言語料庫 (CORAAL) 上的效能進行研究，結果顯示非洲裔美國英語 (AAE) 的 ASR 效能顯著較差。目前的研究旨在透過檢視基於神經網路的最新 ASR 系統 (Whisper，OpenAI) 在 CORAAL 資料集上的效能，了解造成此差異的因素。目前的研究已找出兩個主要發現。第一個發現證實了先前的發現，即使在鄰近的社群中，方言差異也很顯著，而 AAE 的 ASR 效能較差，但透過微調 ASR 模型，效能可以獲得一定程度的改善。第二個發現是先前針對 CORAAL 的研究中未討論過的新發現：資料集中音訊錄製方式的差異對 ASR 準確度有顯著影響，導致「來源混淆」效應，其中語言使用和錄音品質因研究地點而異。這些發現突顯了進一步進行系統性調查的必要性，以釐清在檢視神經 ASR 模型中的公平性和偏差時，錄音品質和固有的語言多樣性的影響，因為 ASR 準確度的任何偏差都可能對 ASR 技術所使用的各種生活領域的差異產生負面的下游影響。</paragraph>

##### **Optimizing Agricultural Order Fulfillment Systems: A Hybrid Tree Search Approach**
2407.13968v1 by Pranay Thangeda, Hoda Helmi, Melkior Ornik

Efficient order fulfillment is vital in the agricultural industry,
particularly due to the seasonal nature of seed supply chains. This paper
addresses the challenge of optimizing seed orders fulfillment in a centralized
warehouse where orders are processed in waves, taking into account the
unpredictable arrival of seed stocks and strict order deadlines. We model the
wave scheduling problem as a Markov decision process and propose an adaptive
hybrid tree search algorithm that combines Monte Carlo tree search with
domain-specific knowledge to efficiently navigate the complex, dynamic
environment of seed distribution. By leveraging historical data and stochastic
modeling, our method enables forecast-informed scheduling decisions that
balance immediate requirements with long-term operational efficiency. The key
idea is that we can augment Monte Carlo tree search algorithm with
problem-specific side information that dynamically reduces the number of
candidate actions at each decision step to handle the large state and action
spaces that render traditional solution methods computationally intractable.
Extensive simulations with realistic parameters-including a diverse range of
products, a high volume of orders, and authentic seasonal durations-demonstrate
that the proposed approach significantly outperforms existing industry standard
methods.

摘要：在農業產業中，有效率的訂單履行至關重要，特別是因為種子供應鏈的季節性。本文探討了在中央倉庫中優化種子訂單履行的挑戰，其中訂單分批處理，並考量了種子庫存的不可預測到貨時間和嚴格的訂單截止日期。我們將波浪排程問題建模為馬可夫決策過程，並提出一個自適應的混合樹狀搜尋演算法，結合蒙地卡羅樹狀搜尋和特定領域的知識，以有效率的方式在種子配送的複雜動態環境中導航。透過利用歷史資料和隨機建模，我們的演算法能做出基於預測的排程決策，在即時需求與長期營運效率之間取得平衡。關鍵概念是，我們可以使用特定問題的額外資訊來擴充蒙地卡羅樹狀搜尋演算法，在每個決策步驟中動態減少候選動作的數量，以處理傳統解決方法在運算上難以處理的大型狀態和動作空間。廣泛的模擬包含了實際的參數，包括多樣化的產品、大量的訂單和真實的季節持續時間，證明了所提出的方法明顯優於現有的產業標準方法。

##### **Knowledge Distillation Approaches for Accurate and Efficient Recommender System**
2407.13952v1 by SeongKu Kang

Despite its breakthrough in classification problems, Knowledge distillation
(KD) to recommendation models and ranking problems has not been studied well in
the previous literature. This dissertation is devoted to developing knowledge
distillation methods for recommender systems to fully improve the performance
of a compact model. We propose novel distillation methods designed for
recommender systems. The proposed methods are categorized according to their
knowledge sources as follows: (1) Latent knowledge: we propose two methods that
transfer latent knowledge of user/item representation. They effectively
transfer knowledge of niche tastes with a balanced distillation strategy that
prevents the KD process from being biased towards a small number of large
preference groups. Also, we propose a new method that transfers user/item
relations in the representation space. The proposed method selectively
transfers essential relations considering the limited capacity of the compact
model. (2) Ranking knowledge: we propose three methods that transfer ranking
knowledge from the recommendation results. They formulate the KD process as a
ranking matching problem and transfer the knowledge via a listwise learning
strategy. Further, we present a new learning framework that compresses the
ranking knowledge of heterogeneous recommendation models. The proposed
framework is developed to ease the computational burdens of model ensemble
which is a dominant solution for many recommendation applications. We validate
the benefit of our proposed methods and frameworks through extensive
experiments. To summarize, this dissertation sheds light on knowledge
distillation approaches for a better accuracy-efficiency trade-off of the
recommendation models.

摘要：儘管在分類問題上取得突破，但知識蒸餾 (KD) 在推薦模型和排名問題上的應用尚未在先前的文獻中得到充分探討。本論文致力於開發推薦系統的知識蒸餾方法，以全面提升精簡模型的效能。我們提出專為推薦系統設計的新穎蒸餾方法。所提出的方法根據其知識來源分類如下：(1) 潛在知識：我們提出兩種方法，用於傳輸使用者/專案表徵的潛在知識。它們透過平衡蒸餾策略有效傳輸利基品味的知識，防止 KD 程序偏向少數大型偏好群組。此外，我們提出一個新的方法，用於傳輸表徵空間中的使用者/專案關係。所提出的方法在考慮精簡模型的有限容量下，有選擇性地傳輸必要的關係。(2) 排名知識：我們提出三種方法，用於傳輸推薦結果中的排名知識。它們將 KD 程序制定為排名配對問題，並透過清單學習策略傳輸知識。此外，我們提出一個新的學習架構，用於壓縮異質推薦模型的排名知識。所提出的架構旨在減輕模型整合的運算負擔，而模型整合是許多推薦應用程式的主流解決方案。我們透過廣泛的實驗驗證了所提出的方法和架構的優點。總之，本論文闡明了知識蒸餾方法，以改善推薦模型的準確性與效率折衷。

##### **Assurance of AI Systems From a Dependability Perspective**
2407.13948v1 by Robin Bloomfield, John Rushby

We outline the principles of classical assurance for computer-based systems
that pose significant risks. We then consider application of these principles
to systems that employ Artificial Intelligence (AI) and Machine Learning (ML).
A key element in this "dependability" perspective is a requirement to have
near-complete understanding of the behavior of critical components, and this is
considered infeasible for AI and ML. Hence the dependability perspective aims
to minimize trust in AI and ML elements by using "defense in depth" with a
hierarchy of less complex systems, some of which may be highly assured
conventionally engineered components, to "guard" them. This may be contrasted
with the "trustworthy" perspective that seeks to apply assurance to the AI and
ML elements themselves. In cyber-physical and many other systems, it is
difficult to provide guards that do not depend on AI and ML to perceive their
environment (e.g., other vehicles sharing the road with a self-driving car), so
both perspectives are needed and there is a continuum or spectrum between them.
We focus on architectures toward the dependability end of the continuum and
invite others to consider additional points along the spectrum. For guards that
require perception using AI and ML, we examine ways to minimize the trust
placed in these elements; they include diversity, defense in depth,
explanations, and micro-ODDs. We also examine methods to enforce acceptable
behavior, given a model of the world. These include classical cyber-physical
calculations and envelopes, and normative rules based on overarching
principles, constitutions, ethics, or reputation. We apply our perspective to
autonomous systems, AI systems for specific functions, generic AI such as Large
Language Models, and to Artificial General Intelligence (AGI), and we propose
current best practice and an agenda for research.

摘要：<paragraph>我們概述了對構成重大風險的電腦系統的傳統保證原則。我們接著考慮將這些原則應用於採用人工智慧 (AI) 和機器學習 (ML) 的系統。這個「可靠性」觀點中的關鍵要素是需要近乎完全理解關鍵元件的行為，而這被認為對 AI 和 ML 來說是不可行的。因此，可靠性觀點旨在透過「縱深防禦」來最小化對 AI 和 ML 元件的信任，並採用較不複雜系統的層級，其中一些系統可能是經過高度保證的傳統工程元件，以「保護」它們。這可能與「值得信賴」觀點形成對比，後者尋求對 AI 和 ML 元件本身施加保證。在網路實體系統和許多其他系統中，很難提供不依賴 AI 和 ML 來感知其環境的防護（例如，與自駕車共用道路的其他車輛），因此需要這兩種觀點，且它們之間存在連續體或光譜。我們專注於連續體中偏向可靠性的架構，並邀請其他人考慮光譜中的其他觀點。對於需要使用 AI 和 ML 來感知的防護，我們探討了最小化對這些元件的信任的方法；它們包括多樣性、縱深防禦、解釋和微型 ODD。我們也探討了在給定世界模型的情況下強制執行可接受行為的方法。這些方法包括傳統的網路實體計算和封套，以及基於統籌原則、憲法、道德或聲譽的規範性規則。我們將我們的觀點應用於自主系統、特定功能的 AI 系統、通用 AI（例如大型語言模型）和人工通用智慧 (AGI)，並提出目前的最佳實務和研究議程。</paragraph>

##### **FANTAstic SEquences and Where to Find Them: Faithful and Efficient API Call Generation through State-tracked Constrained Decoding and Reranking**
2407.13945v1 by Zhuoer Wang, Leonardo F. R. Ribeiro, Alexandros Papangelis, Rohan Mukherjee, Tzu-Yen Wang, Xinyan Zhao, Arijit Biswas, James Caverlee, Angeliki Metallinou

API call generation is the cornerstone of large language models' tool-using
ability that provides access to the larger world. However, existing supervised
and in-context learning approaches suffer from high training costs, poor data
efficiency, and generated API calls that can be unfaithful to the API
documentation and the user's request. To address these limitations, we propose
an output-side optimization approach called FANTASE. Two of the unique
contributions of FANTASE are its State-Tracked Constrained Decoding (SCD) and
Reranking components. SCD dynamically incorporates appropriate API constraints
in the form of Token Search Trie for efficient and guaranteed generation
faithfulness with respect to the API documentation. The Reranking component
efficiently brings in the supervised signal by leveraging a lightweight model
as the discriminator to rerank the beam-searched candidate generations of the
large language model. We demonstrate the superior performance of FANTASE in API
call generation accuracy, inference efficiency, and context efficiency with
DSTC8 and API Bank datasets.

摘要：API 呼叫生成是大型語言模型工具使用能力的基石，可存取更廣大的世界。然而，現有的監督式和情境內學習方法有訓練成本高、資料效率差，以及產生的 API 呼叫可能不符合 API 文件和使用者要求的問題。為了解決這些限制，我們提出了一種稱為 FANTASE 的輸出端最佳化方法。FANTASE 的兩個獨特貢獻是其狀態追蹤約束解碼 (SCD) 和重新排序元件。SCD 以 Token 搜尋 Trie 的形式動態納入適當的 API 約束，以確保產生結果與 API 文件相符，且效率高。重新排序元件透過利用輕量級模型作為判別器，有效地引入監督訊號，以重新排序大型語言模型的波束搜尋候選產生結果。我們在 DSTC8 和 API Bank 資料集上展示了 FANTASE 在 API 呼叫產生準確性、推論效率和情境效率方面的卓越效能。

##### **Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction**
2407.13943v1 by Suma Bailis, Jane Friedhoff, Feiyang Chen

This paper introduces Werewolf Arena, a novel framework for evaluating large
language models (LLMs) through the lens of the classic social deduction game,
Werewolf. In Werewolf Arena, LLMs compete against each other, navigating the
game's complex dynamics of deception, deduction, and persuasion. The framework
introduces a dynamic turn-taking system based on bidding, mirroring real-world
discussions where individuals strategically choose when to speak. We
demonstrate the framework's utility through an arena-style tournament featuring
Gemini and GPT models. Our results reveal distinct strengths and weaknesses in
the models' strategic reasoning and communication. These findings highlight
Werewolf Arena's potential as a challenging and scalable LLM benchmark.

摘要：本論文介紹了狼人競技場，一個透過經典社交推理遊戲狼人的角度來評估大型語言模型 (LLM) 的新穎架構。在狼人競技場中，LLM 彼此競爭，探索遊戲中複雜的欺騙、推理和說服動態。該架構引入了基於競標的動態回合制系統，反映了現實世界的討論，其中個人策略性地選擇發言時機。我們透過一場以 Gemini 和 GPT 模型為主的競技場式錦標賽展示了該架構的效用。我們的結果揭示了模型在策略推理和溝通方面的不同優缺點。這些發現突出了狼人競技場作為一個具有挑戰性和可擴展性的 LLM 基準的潛力。

##### **Unmasking Social Bots: How Confident Are We?**
2407.13929v1 by James Giroux, Ariyarathne Gangani, Alexander C. Nwala, Cristiano Fanelli

Social bots remain a major vector for spreading disinformation on social
media and a menace to the public. Despite the progress made in developing
multiple sophisticated social bot detection algorithms and tools, bot detection
remains a challenging, unsolved problem that is fraught with uncertainty due to
the heterogeneity of bot behaviors, training data, and detection algorithms.
Detection models often disagree on whether to label the same account as bot or
human-controlled. However, they do not provide any measure of uncertainty to
indicate how much we should trust their results. We propose to address both bot
detection and the quantification of uncertainty at the account level - a novel
feature of this research. This dual focus is crucial as it allows us to
leverage additional information related to the quantified uncertainty of each
prediction, thereby enhancing decision-making and improving the reliability of
bot classifications. Specifically, our approach facilitates targeted
interventions for bots when predictions are made with high confidence and
suggests caution (e.g., gathering more data) when predictions are uncertain.

摘要：社交機器人仍然是社群媒體上散播錯誤資訊的主要媒介，也是公眾的威脅。儘管在開發多種精密的社交機器人偵測演算法和工具方面已取得進展，但機器人偵測仍然是一個充滿挑戰且未解決的問題，由於機器人行為、訓練資料和偵測演算法的多樣性，因此充滿了不確定性。偵測模型通常會對是否將同一個帳戶標記為機器人或人類控制而意見分歧。然而，它們並未提供任何不確定性測量來表示我們應該相信其結果的程度。我們提議在帳戶層級同時處理機器人偵測和不確定性量化，這是本研究的一項新功能。這種雙重關注至關重要，因為它允許我們利用與每個預測的不確定性量化相關的額外資訊，從而增強決策制定並提高機器人分類的可靠性。具體來說，當以高度信心進行預測時，我們的做法有助於針對機器人進行有針對性的干預，並且當預測不確定時建議採取謹慎措施（例如，收集更多資料）。

##### **BiasDPO: Mitigating Bias in Language Models through Direct Preference Optimization**
2407.13928v1 by Ahmed Allam

Large Language Models (LLMs) have become pivotal in advancing natural
language processing, yet their potential to perpetuate biases poses significant
concerns. This paper introduces a new framework employing Direct Preference
Optimization (DPO) to mitigate gender, racial, and religious biases in
LLM-generated English text. By developing a loss function that favors less
biased over biased completions, our approach cultivates a preference for
respectful and non-discriminatory language in LLMs. We also contribute a
manually designed dataset for training LLMs to recognize and correct biases.
This dataset encompasses a diverse range of prompts paired with both biased and
unbiased completions. Implementing this approach on the Microsoft Phi-2 model,
we demonstrate substantial reductions in biased outputs as our model
outperforms the baseline model on almost all bias benchmarks. Our model also
achieves better performance compared to other open-source models on most
benchmarks. By reducing biases in the language generated by the model, our
study marks a significant step towards developing more ethical and socially
responsible LLMs. We publicly release BiasDPO dataset on HuggingFace.

摘要：大型語言模型 (LLM) 已成為推進自然語言處理的關鍵，但其潛在的偏見延續性引發了重大的擔憂。本文介紹了一個採用直接偏好最佳化 (DPO) 的新框架，以減輕 LLM 生成的英文文本中的性別、種族和宗教偏見。通過開發一個偏好較少偏見而非偏見完成的損失函數，我們的做法培養了對 LLM 中尊重和非歧視性語言的偏好。我們還提供了一個手動設計的數據集，用於訓練 LLM 識別和糾正偏差。此數據集包含與有偏見和無偏見完成配對的各種提示。在 Microsoft Phi-2 模型上實施此方法，我們證明了偏見輸出的顯著減少，因為我們的模型在幾乎所有偏見基準上都優於基線模型。與大多數基準上的其他開源模型相比，我們的模型也取得了更好的性能。通過減少模型生成的語言中的偏見，我們的研究標誌著朝著開發更具道德和社會責任感的 LLM 邁出的重要一步。我們在 HuggingFace 上公開發布了 BiasDPO 數據集。

##### **Synthetic Counterfactual Faces**
2407.13922v1 by Guruprasad V Ramesh, Harrison Rosenberg, Ashish Hooda, Kassem Fawaz

Computer vision systems have been deployed in various applications involving
biometrics like human faces. These systems can identify social media users,
search for missing persons, and verify identity of individuals. While computer
vision models are often evaluated for accuracy on available benchmarks, more
annotated data is necessary to learn about their robustness and fairness
against semantic distributional shifts in input data, especially in face data.
Among annotated data, counterfactual examples grant strong explainability
characteristics. Because collecting natural face data is prohibitively
expensive, we put forth a generative AI-based framework to construct targeted,
counterfactual, high-quality synthetic face data. Our synthetic data pipeline
has many use cases, including face recognition systems sensitivity evaluations
and image understanding system probes. The pipeline is validated with multiple
user studies. We showcase the efficacy of our face generation pipeline on a
leading commercial vision model. We identify facial attributes that cause
vision systems to fail.

摘要：電腦視覺系統已部署在各種應用程式中，涉及生物特徵識別，例如人臉。這些系統可以識別社群媒體使用者、搜尋失蹤人口，並驗證個人身分。儘管電腦視覺模型通常會針對可用基準進行準確性評估，但需要更多註解資料才能了解其穩健性和公平性，以應對輸入資料中的語義分佈轉移，特別是在人臉資料中。在註解資料中，反事實範例提供了強大的可解釋性特徵。由於收集自然人臉資料的成本高得令人望而卻步，因此我們提出了基於生成式 AI 的架構來建構目標導向、反事實、高品質的合成人臉資料。我們的合成資料管道有許多用途，包括人臉辨識系統敏感度評估和影像理解系統探測。此管道已通過多項使用者研究驗證。我們在領先的商業視覺模型上展示了我們的人臉生成管道的效能。我們識別出導致視覺系統失敗的人臉屬性。

##### **DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention**
2407.13920v1 by Xiaoya Tang, Bodong Zhang, Beatrice S. Knudsen, Tolga Tasdizen

We here propose a novel hierarchical transformer model that adeptly
integrates the feature extraction capabilities of Convolutional Neural Networks
(CNNs) with the advanced representational potential of Vision Transformers
(ViTs). Addressing the lack of inductive biases and dependence on extensive
training datasets in ViTs, our model employs a CNN backbone to generate
hierarchical visual representations. These representations are then adapted for
transformer input through an innovative patch tokenization. We also introduce a
'scale attention' mechanism that captures cross-scale dependencies,
complementing patch attention to enhance spatial understanding and preserve
global perception. Our approach significantly outperforms baseline models on
small and medium-sized medical datasets, demonstrating its efficiency and
generalizability. The components are designed as plug-and-play for different
CNN architectures and can be adapted for multiple applications. The code is
available at https://github.com/xiaoyatang/DuoFormer.git.

摘要：我們在此提出一個新穎的分層Transformer模型，它巧妙地整合了卷積神經網路 (CNN) 的特徵擷取能力，以及視覺Transformer (ViT) 的先進表示潛力。針對 ViT 中缺乏歸納偏誤和依賴於廣泛訓練資料集的問題，我們的模型採用 CNN 主幹來產生分層視覺表示。這些表示接著透過創新的區塊標記化，調整為Transformer輸入。我們也引入「尺度注意力」機制，它捕捉跨尺度依賴性，補充區塊注意力以增強空間理解並保留全局感知。我們的做法在小型和中型的醫學資料集上，明顯優於基線模型，證明了它的效率和可概化性。這些組件被設計成即插即用，適用於不同的 CNN 架構，並且可以調整為多種應用程式。程式碼可在 https://github.com/xiaoyatang/DuoFormer.git 取得。

##### **Crafting Efficient Fine-Tuning Strategies for Large Language Models**
2407.13906v1 by Michael Oliver, Guan Wang

This paper addresses the challenges of efficiently fine-tuning large language
models (LLMs) by exploring data efficiency and hyperparameter optimization. We
investigate the minimum data required for effective fine-tuning and propose a
novel hyperparameter optimization method that leverages early-stage model
performance. Our experiments demonstrate that fine-tuning with as few as 200
samples can improve model accuracy from 70\% to 88\% in a product attribute
extraction task. We identify a saturation point of approximately 6,500 samples,
beyond which additional data yields diminishing returns. Our proposed bayesian
hyperparameter optimization method, which evaluates models at 20\% of total
training time, correlates strongly with final model performance, with 4 out of
5 top early-stage models remaining in the top 5 at completion. This approach
led to a 2\% improvement in accuracy over baseline models when evaluated on an
independent test set. These findings offer actionable insights for
practitioners, potentially reducing computational load and dependency on
extensive datasets while enhancing overall performance of fine-tuned LLMs.

摘要：本文探討有效微調大型語言模型 (LLM) 所面臨的挑戰，方法是探索資料效率和超參數最佳化。我們探討有效微調所需的最低資料量，並提出一個創新的超參數最佳化方法，該方法利用早期階段的模型效能。我們的實驗證明，在產品屬性萃取任務中，使用僅 200 個範例進行微調，就能將模型準確度從 70% 提升至 88%。我們找出一個約 6,500 個範例的飽和點，超過此點後，額外的資料會產生遞減報酬。我們提出的貝氏超參數最佳化方法，會在總訓練時間的 20% 評估模型，與最終模型效能高度相關，5 個頂尖早期階段模型中有 4 個在完成時仍維持在頂尖 5 名。此方法在獨立測試集上評估時，準確度比基準模型提升了 2%。這些發現為實務工作者提供可行的見解，有可能在提升微調 LLM 的整體效能的同時，降低運算負載和對龐大資料集的依賴性。

##### **Uncovering Political Bias in Emotion Inference Models: Implications for sentiment analysis in social science research**
2407.13891v1 by Hubert Plisiecki, Paweł Lenartowicz, Maria Flakus, Artur Pokropek

This paper investigates the presence of political bias in emotion inference
models used for sentiment analysis (SA) in social science research. Machine
learning models often reflect biases in their training data, impacting the
validity of their outcomes. While previous research has highlighted gender and
race biases, our study focuses on political bias - an underexplored yet
pervasive issue that can skew the interpretation of text data across a wide
array of studies. We conducted a bias audit on a Polish sentiment analysis
model developed in our lab. By analyzing valence predictions for names and
sentences involving Polish politicians, we uncovered systematic differences
influenced by political affiliations. Our findings indicate that annotations by
human raters propagate political biases into the model's predictions. To
mitigate this, we pruned the training dataset of texts mentioning these
politicians and observed a reduction in bias, though not its complete
elimination. Given the significant implications of political bias in SA, our
study emphasizes caution in employing these models for social science research.
We recommend a critical examination of SA results and propose using
lexicon-based systems as a more ideologically neutral alternative. This paper
underscores the necessity for ongoing scrutiny and methodological adjustments
to ensure the reliability and impartiality of the use of machine learning in
academic and applied contexts.

摘要：這篇論文探討了用於社會科學研究的情感分析 (SA) 中的情緒推論模型中政治偏見的存在。機器學習模型通常會反映其訓練資料中的偏見，進而影響其結果的有效性。雖然先前的研究強調了性別和種族偏見，但我們的研究著重於政治偏見，這是一個尚未充分探討但普遍存在的問題，可能會扭曲各種研究中對文字資料的詮釋。我們對我們實驗室開發的波蘭語情緒分析模型進行了偏見審計。透過分析涉及波蘭政治人物的名字和句子的情緒預測，我們發現了受政治派系影響的系統性差異。我們的研究結果指出，人類評分者的註解會將政治偏見傳播到模型的預測中。為了減輕這種情況，我們刪除了訓練資料集中提到這些政治人物的文字，並觀察到偏見有所減少，但並未完全消除。鑑於政治偏見在 SA 中的重大影響，我們的研究強調在社會科學研究中採用這些模型時應保持謹慎。我們建議批判性地檢視 SA 結果，並建議使用基於詞彙的系統作為更具意識形態中立性的替代方案。這篇論文強調了持續審查和方法調整的必要性，以確保機器學習在學術和應用環境中使用的可靠性和公正性。

##### **Learning Goal-Conditioned Representations for Language Reward Models**
2407.13887v1 by Vaskar Nath, Dylan Slack, Jeff Da, Yuntao Ma, Hugh Zhang, Spencer Whitehead, Sean Hendryx

Techniques that learn improved representations via offline data or
self-supervised objectives have shown impressive results in traditional
reinforcement learning (RL). Nevertheless, it is unclear how improved
representation learning can benefit reinforcement learning from human feedback
(RLHF) on language models (LMs). In this work, we propose training reward
models (RMs) in a contrastive, $\textit{goal-conditioned}$ fashion by
increasing the representation similarity of future states along sampled
preferred trajectories and decreasing the similarity along randomly sampled
dispreferred trajectories. This objective significantly improves RM performance
by up to 0.09 AUROC across challenging benchmarks, such as MATH and GSM8k.
These findings extend to general alignment as well -- on the Helpful-Harmless
dataset, we observe $2.3\%$ increase in accuracy. Beyond improving reward model
performance, we show this way of training RM representations enables improved
$\textit{steerability}$ because it allows us to evaluate the likelihood of an
action achieving a particular goal-state (e.g., whether a solution is correct
or helpful). Leveraging this insight, we find that we can filter up to $55\%$
of generated tokens during majority voting by discarding trajectories likely to
end up in an "incorrect" state, which leads to significant cost savings. We
additionally find that these representations can perform fine-grained control
by conditioning on desired future goal-states. For example, we show that
steering a Llama 3 model towards helpful generations with our approach improves
helpfulness by $9.6\%$ over a supervised-fine-tuning trained baseline.
Similarly, steering the model towards complex generations improves complexity
by $21.6\%$ over the baseline. Overall, we find that training RMs in this
contrastive, goal-conditioned fashion significantly improves performance and
enables model steerability.

摘要：<paragraph>透過離線資料或自我監督目標學習到改良表徵的技術，在傳統的強化學習 (RL) 中已展現出令人印象深刻的成果。儘管如此，目前尚不清楚改良的表徵學習如何能從語言模型 (LM) 上的人類回饋 (RLHF) 中受益。在這項工作中，我們建議以對比、$\textit{目標制約}$的方式訓練獎勵模型 (RM)，方法是增加沿著取樣偏好軌跡的未來狀態的表徵相似性，並減少沿著隨機取樣非偏好軌跡的相似性。此目標顯著改善 RM 效能，在 MATH 和 GSM8k 等具挑戰性的基準測試中提升了高達 0.09 AUROC。這些發現也延伸到一般對齊——在 Helpful-Harmless 資料集上，我們觀察到準確度增加了 $2.3\%$。除了改善獎勵模型效能之外，我們展示了這種訓練 RM 表徵的方式能改善$\textit{可控性}$，因為它讓我們能夠評估動作達成特定目標狀態的可能性（例如，某個解是否正確或有幫助）。利用此洞見，我們發現我們可以在多數投票期間過濾掉高達 $55\%$ 的已產生權杖，方法是捨棄可能會結束在「不正確」狀態的軌跡，這能大幅節省成本。我們另外發現，這些表徵可以透過制約在理想的未來目標狀態上來執行細微控制。例如，我們展示了使用我們的做法將 Llama 3 模型導向有幫助的生成，能比經過監督微調訓練的基準線改善 $9.6\%$ 的有幫助性。類似地，將模型導向複雜的生成能比基準線改善 $21.6\%$ 的複雜性。整體而言，我們發現以這種對比、目標制約的方式訓練 RM 能顯著改善效能，並讓模型具備可控性。</paragraph>

##### **Enhancing Worldwide Image Geolocation by Ensembling Satellite-Based Ground-Level Attribute Predictors**
2407.13862v1 by Michael J. Bianco, David Eigen, Michael Gormish

Geolocating images of a ground-level scene entails estimating the location on
Earth where the picture was taken, in absence of GPS or other location
metadata. Typically, methods are evaluated by measuring the Great Circle
Distance (GCD) between a predicted location and ground truth. However, this
measurement is limited because it only evaluates a single point, not estimates
of regions or score heatmaps. This is especially important in applications to
rural, wilderness and under-sampled areas, where finding the exact location may
not be possible, and when used in aggregate systems that progressively narrow
down locations.
  In this paper, we introduce a novel metric, Recall vs Area (RvA), which
measures the accuracy of estimated distributions of locations. RvA treats image
geolocation results similarly to document retrieval, measuring recall as a
function of area: For a ranked list of (possibly non-contiguous) predicted
regions, we measure the accumulated area required for the region to contain the
ground truth coordinate. This produces a curve similar to a precision-recall
curve, where "precision" is replaced by square kilometers area, allowing
evaluation of performance for different downstream search area budgets.
  Following directly from this view of the problem, we then examine a simple
ensembling approach to global-scale image geolocation, which incorporates
information from multiple sources to help address domain shift, and can readily
incorporate multiple models, attribute predictors, and data sources. We study
its effectiveness by combining the geolocation models GeoEstimation and the
current SOTA GeoCLIP, with attribute predictors based on ORNL LandScan and
ESA-CCI Land Cover. We find significant improvements in image geolocation for
areas that are under-represented in the training set, particularly non-urban
areas, on both Im2GPS3k and Street View images.

摘要：<paragraph>定位地面場景的影像，需要在沒有 GPS 或其他位置資訊的情況下，估計影像拍攝的地球位置。一般來說，方法會透過測量預測位置與實際位置之間的大圓距離 (GCD) 來進行評估。然而，這種測量方式有其限制，因為它只評估單一位置，而不是區域或分數熱圖的估計值。這在應用於鄉村、荒野和取樣不足的地區時尤其重要，因為在這些地區可能無法找到確切的位置，而且當用於逐步縮小位置範圍的集合系統時更是如此。
在本文中，我們引入了新的指標，即召回率與面積 (RvA)，用來測量位置估計分佈的準確性。RvA 將影像地理定位結果視為文件檢索，將召回率視為面積的函數：對於一份排名清單（可能是不相鄰的）預測區域，我們測量區域包含實際位置座標所需的累積面積。這會產生類似於精準度-召回率曲線的曲線，其中「精準度」以平方公里為單位，允許評估不同下游搜尋區域預算的效能。
直接從這個問題的觀點出發，我們接著檢視一種簡單的全球規模影像地理定位整體方法，它整合了來自多個來源的資訊，以協助解決領域轉移，並且可以輕鬆整合多個模型、屬性預測器和資料來源。我們透過結合 GeoEstimation 和目前 SOTA GeoCLIP 的地理定位模型，以及基於 ORNL LandScan 和 ESA-CCI Land Cover 的屬性預測器，來研究其有效性。我們發現，對於訓練集中代表性不足的地區，特別是非都會區，在 Im2GPS3k 和街景影像中，影像地理定位都有顯著的改善。</paragraph>

##### **Phi-3 Safety Post-Training: Aligning Language Models with a "Break-Fix" Cycle**
2407.13833v1 by Emman Haider, Daniel Perez-Becker, Thomas Portet, Piyush Madan, Amit Garg, David Majercak, Wen Wen, Dongwoo Kim, Ziyi Yang, Jianwen Zhang, Hiteshi Sharma, Blake Bullwinkel, Martin Pouliot, Amanda Minnich, Shiven Chawla, Solianna Herrera, Shahed Warreth, Maggie Engler, Gary Lopez, Nina Chikanov, Raja Sekhar Rao Dheekonda, Bolor-Erdene Jagdagdorj, Roman Lutz, Richard Lundeen, Tori Westerhoff, Pete Bryan, Christian Seifert, Ram Shankar Siva Kumar, Andrew Berkley, Alex Kessler

Recent innovations in language model training have demonstrated that it is
possible to create highly performant models that are small enough to run on a
smartphone. As these models are deployed in an increasing number of domains, it
is critical to ensure that they are aligned with human preferences and safety
considerations. In this report, we present our methodology for safety aligning
the Phi-3 series of language models. We utilized a "break-fix" cycle,
performing multiple rounds of dataset curation, safety post-training,
benchmarking, red teaming, and vulnerability identification to cover a variety
of harm areas in both single and multi-turn scenarios. Our results indicate
that this approach iteratively improved the performance of the Phi-3 models
across a wide range of responsible AI benchmarks.

摘要：語言模型訓練的最新創新證明了建立高效能模型的可能性，這些模型小到可以在智慧型手機上執行。由於這些模型部署在越來越多的領域中，因此確保它們與人類偏好和安全考量保持一致至關重要。在此報告中，我們提出了一種安全調整 Phi-3 系列語言模型的方法。我們利用「中斷修復」循環，執行多輪資料集策劃、安全訓練後、基準測試、紅隊測試和漏洞辨識，以涵蓋單輪和多輪場景中的各種危害領域。我們的結果表明，這種方法反覆改善了 Phi-3 模型在各種負責任 AI 基準測試中的效能。

##### **Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data**
2407.13765v1 by Charles Jin

As language models (LMs) deliver increasing performance on a range of NLP
tasks, probing classifiers have become an indispensable technique in the effort
to better understand their inner workings. A typical setup involves (1)
defining an auxiliary task consisting of a dataset of text annotated with
labels, then (2) supervising small classifiers to predict the labels from the
representations of a pretrained LM as it processed the dataset. A high probing
accuracy is interpreted as evidence that the LM has learned to perform the
auxiliary task as an unsupervised byproduct of its original pretraining
objective. Despite the widespread usage of probes, however, the robust design
and analysis of probing experiments remains a challenge. We develop a formal
perspective on probing using structural causal models (SCM). Specifically,
given an SCM which explains the distribution of tokens observed during
training, we frame the central hypothesis as whether the LM has learned to
represent the latent variables of the SCM. Empirically, we extend a recent
study of LMs in the context of a synthetic grid-world navigation task, where
having an exact model of the underlying causal structure allows us to draw
strong inferences from the result of probing experiments. Our techniques
provide robust empirical evidence for the ability of LMs to learn the latent
causal concepts underlying text.

摘要：隨著語言模型 (LM) 在一系列自然語言處理 (NLP) 任務中提供越來越高的效能，探索分類器已成為更深入了解其內部運作的必要技術。典型的設定包括 (1) 定義一項輔助任務，該任務包含標有標籤的文字資料集，然後 (2) 監督小型分類器，以預測預訓練 LM 在處理資料集時表徵的標籤。高的探索準確度被解釋為 LM 已學會執行輔助任務的證據，作為其原始預訓練目標的非監督副產品。然而，儘管廣泛使用探測，但探測實驗的穩健設計和分析仍然是一個挑戰。我們使用結構因果模型 (SCM) 開發了探測的正式觀點。具體來說，給定一個解釋在訓練期間觀察到的代幣分佈的 SCM，我們將中心假設設定為 LM 是否已學會表徵 SCM 的潛在變數。根據經驗，我們擴展了最近在合成網格世界導航任務背景下的 LM 研究，其中擁有基礎因果結構的精確模型使我們能夠從探測實驗的結果中得出強有力的推論。我們的技術為 LM 學習文字背後潛在因果概念的能力提供了穩健的實證證據。

##### **Neural Network Tire Force Modeling for Automated Drifting**
2407.13760v1 by Nicholas Drake Broadbent, Trey Weber, Daiki Mori, J. Christian Gerdes

Automated drifting presents a challenge problem for vehicle control,
requiring models and control algorithms that can precisely handle nonlinear,
coupled tire forces at the friction limits. We present a neural network
architecture for predicting front tire lateral force as a drop-in replacement
for physics-based approaches. With a full-scale automated vehicle purpose-built
for the drifting application, we deploy these models in a nonlinear model
predictive controller tuned for tracking a reference drifting trajectory, for
direct comparisons of model performance. The neural network tire model exhibits
significantly improved path tracking performance over the brush tire model in
cases where front-axle braking force is applied, suggesting the neural
network's ability to express previously unmodeled, latent dynamics in the
drifting condition.

摘要：自動漂移對於車輛控制是一個具有挑戰性的問題，
需要模型和控制演算法，能夠精確處理非線性、
耦合的輪胎力在摩擦極限下。我們提出一個神經網路
架構，用於預測前輪橫向力，作為基於物理方法的替代方案。
使用專為漂移應用而建的全尺寸自動駕駛車輛，我們在非線性模型
預測控制器中部署這些模型，針對追蹤參考漂移軌跡進行調整，以
直接比較模型效能。神經網路輪胎模型在施加前軸煞車力的情況下，
表現出顯著改善的路徑追蹤效能，這表示神經網路能夠表達以前未建模的、
在漂移條件下的潛在動態。

##### **Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models**
2407.13757v1 by Zhuo Chen, Jiawei Liu, Haotan Liu, Qikai Cheng, Fan Zhang, Wei Lu, Xiaozhong Liu

Retrieval-Augmented Generation (RAG) is applied to solve hallucination
problems and real-time constraints of large language models, but it also
induces vulnerabilities against retrieval corruption attacks. Existing research
mainly explores the unreliability of RAG in white-box and closed-domain QA
tasks. In this paper, we aim to reveal the vulnerabilities of
Retrieval-Enhanced Generative (RAG) models when faced with black-box attacks
for opinion manipulation. We explore the impact of such attacks on user
cognition and decision-making, providing new insight to enhance the reliability
and security of RAG models. We manipulate the ranking results of the retrieval
model in RAG with instruction and use these results as data to train a
surrogate model. By employing adversarial retrieval attack methods to the
surrogate model, black-box transfer attacks on RAG are further realized.
Experiments conducted on opinion datasets across multiple topics show that the
proposed attack strategy can significantly alter the opinion polarity of the
content generated by RAG. This demonstrates the model's vulnerability and, more
importantly, reveals the potential negative impact on user cognition and
decision-making, making it easier to mislead users into accepting incorrect or
biased information.

摘要：檢索增強生成 (RAG) 用於解決大型語言模型的幻覺問題和即時約束，但它也會引發對檢索破壞攻擊的漏洞。現有研究主要探討 RAG 在白盒和封閉域 QA 任務中的不可靠性。在本文中，我們旨在揭示檢索增強生成 (RAG) 模型在面對意見操縱的黑盒攻擊時的漏洞。我們探討了此類攻擊對使用者認知和決策制定的影響，並提供新的見解來增強 RAG 模型的可靠性和安全性。我們使用說明操縱 RAG 中檢索模型的排名結果，並使用這些結果作為資料來訓練代理模型。通過對代理模型採用對抗性檢索攻擊方法，進一步實現了對 RAG 的黑盒傳輸攻擊。在多個主題的意見資料集上進行的實驗表明，所提出的攻擊策略可以顯著改變 RAG 生成的內容的意見極性。這證明了模型的脆弱性，更重要的是，揭示了對使用者認知和決策制定的潛在負面影響，使得誤導使用者接受不正確或有偏見的資訊變得更加容易。

##### **LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation**
2407.13744v1 by David Schlangen

Natural Language Processing has moved rather quickly from modelling specific
tasks to taking more general pre-trained models and fine-tuning them for
specific tasks, to a point where we now have what appear to be inherently
generalist models. This paper argues that the resultant loss of clarity on what
these models model leads to metaphors like "artificial general intelligences"
that are not helpful for evaluating their strengths and weaknesses. The
proposal is to see their generality, and their potential value, in their
ability to approximate specialist function, based on a natural language
specification. This framing brings to the fore questions of the quality of the
approximation, but beyond that, also questions of discoverability, stability,
and protectability of these functions. As the paper will show, this framing
hence brings together in one conceptual framework various aspects of
evaluation, both from a practical and a theoretical perspective, as well as
questions often relegated to a secondary status (such as "prompt injection" and
"jailbreaking").

摘要：自然語言處理已經從建模特定任務相當快速地轉移到採用更通用的預訓練模型，並針對特定任務微調它們，進展到我們現在擁有看似本質上是通才模型的地步。這篇論文認為，對於這些模型建模的內容缺乏明確性，導致出現「人工通用智慧」等比喻，而這對於評估它們的優缺點沒有幫助。建議在它們近似專家功能的能力中，根據自然語言規格，了解它們的通用性和潛在價值。此架構凸顯了近似品質的問題，但除此之外，也凸顯了這些功能的可發現性、穩定性和可保護性的問題。正如本文將展示的，此架構因此在一個概念架構中彙整了評估的各個方面，無論是從實務或理論的角度，以及經常降級為次要狀態的問題（例如「提示注入」和「越獄」）。

##### **CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications**
2407.13742v1 by Mirza Masfiqur Rahman, Imtiaz Karim, Elisa Bertino

In recent years, there has been a growing focus on scrutinizing the security
of cellular networks, often attributing security vulnerabilities to issues in
the underlying protocol design descriptions. These protocol design
specifications, typically extensive documents that are thousands of pages long,
can harbor inaccuracies, underspecifications, implicit assumptions, and
internal inconsistencies. In light of the evolving landscape, we introduce
CellularLint--a semi-automatic framework for inconsistency detection within the
standards of 4G and 5G, capitalizing on a suite of natural language processing
techniques. Our proposed method uses a revamped few-shot learning mechanism on
domain-adapted large language models. Pre-trained on a vast corpus of cellular
network protocols, this method enables CellularLint to simultaneously detect
inconsistencies at various levels of semantics and practical use cases. In
doing so, CellularLint significantly advances the automated analysis of
protocol specifications in a scalable fashion. In our investigation, we focused
on the Non-Access Stratum (NAS) and the security specifications of 4G and 5G
networks, ultimately uncovering 157 inconsistencies with 82.67% accuracy. After
verification of these inconsistencies on open-source implementations and 17
commercial devices, we confirm that they indeed have a substantial impact on
design decisions, potentially leading to concerns related to privacy,
integrity, availability, and interoperability.

摘要：近年来，人们越来越关注对蜂窝网络的安全性进行审查，通常将安全漏洞归因于底层协议设计描述中的问题。这些协议设计规范通常是长达数千页的大型文档，可能存在不准确、欠规范、隐含假设和内部不一致的情况。鉴于不断变化的格局，我们引入了 CellularLint——一个用于检测 4G 和 5G 标准中不一致性的半自动框架，它利用了一套自然语言处理技术。我们提出的方法在经过领域适应的大语言模型上使用改进的少样本学习机制。这种方法经过大量蜂窝网络协议语料库的预训练，使 CellularLint 能够同时检测语义和实际用例中不同层面的不一致性。通过这样做，CellularLint 以可扩展的方式极大地推进了协议规范的自动化分析。在我们的调查中，我们重点关注了 4G 和 5G 网络的非接入层 (NAS) 和安全规范，最终发现了 157 个不一致性，准确率为 82.67%。在对开源实现和 17 个商用设备验证了这些不一致性之后，我们确认它们确实对设计决策产生了重大影响，可能导致与隐私、完整性、可用性和互操作性相关的问题。

##### **Scaling Granite Code Models to 128K Context**
2407.13739v1 by Matt Stallone, Vaibhav Saxena, Leonid Karlinsky, Bridget McGinn, Tim Bula, Mayank Mishra, Adriana Meza Soria, Gaoyuan Zhang, Aditya Prasad, Yikang Shen, Saptha Surendran, Shanmukha Guttula, Hima Patel, Parameswaran Selvam, Xuan-Hong Dang, Yan Koyfman, Atin Sood, Rogerio Feris, Nirmit Desai, David D. Cox, Ruchir Puri, Rameswar Panda

This paper introduces long-context Granite code models that support effective
context windows of up to 128K tokens. Our solution for scaling context length
of Granite 3B/8B code models from 2K/4K to 128K consists of a light-weight
continual pretraining by gradually increasing its RoPE base frequency with
repository-level file packing and length-upsampled long-context data.
Additionally, we also release instruction-tuned models with long-context
support which are derived by further finetuning the long context base models on
a mix of permissively licensed short and long-context instruction-response
pairs. While comparing to the original short-context Granite code models, our
long-context models achieve significant improvements on long-context tasks
without any noticeable performance degradation on regular code completion
benchmarks (e.g., HumanEval). We release all our long-context Granite code
models under an Apache 2.0 license for both research and commercial use.

摘要：本文介绍了支持高达 128K 令牌的有效上下文窗口的长上下文 Granite 代码模型。我们针对将 Granite 3B/8B 代码模型的上下文长度从 2K/4K 扩展到 128K 的解决方案包括通过逐渐增加其 RoPE 基本频率，并结合存储库级别的文件打包和长度上采样的长上下文数据，进行轻量级的持续预训练。此外，我们还发布了具有长上下文支持的指令调整模型，这些模型是通过对长上下文基础模型进行进一步微调而得出的，微调基于许可宽松的短上下文和长上下文指令-响应对的混合。在与原始短上下文 Granite 代码模型进行比较时，我们的长上下文模型在长上下文任务中取得了显著的改进，而在常规代码完成基准（例如 HumanEval）上没有任何明显的性能下降。我们根据 Apache 2.0 许可证发布我们所有长上下文 Granite 代码模型，供研究和商业用途。

##### **Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review**
2407.13734v1 by Masatoshi Uehara, Yulai Zhao, Tommaso Biancalani, Sergey Levine

This tutorial provides a comprehensive survey of methods for fine-tuning
diffusion models to optimize downstream reward functions. While diffusion
models are widely known to provide excellent generative modeling capability,
practical applications in domains such as biology require generating samples
that maximize some desired metric (e.g., translation efficiency in RNA, docking
score in molecules, stability in protein). In these cases, the diffusion model
can be optimized not only to generate realistic samples but also to explicitly
maximize the measure of interest. Such methods are based on concepts from
reinforcement learning (RL). We explain the application of various RL
algorithms, including PPO, differentiable optimization, reward-weighted MLE,
value-weighted sampling, and path consistency learning, tailored specifically
for fine-tuning diffusion models. We aim to explore fundamental aspects such as
the strengths and limitations of different RL-based fine-tuning algorithms
across various scenarios, the benefits of RL-based fine-tuning compared to
non-RL-based approaches, and the formal objectives of RL-based fine-tuning
(target distributions). Additionally, we aim to examine their connections with
related topics such as classifier guidance, Gflownets, flow-based diffusion
models, path integral control theory, and sampling from unnormalized
distributions such as MCMC. The code of this tutorial is available at
https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq

摘要：本教程提供了全面調查微調擴散模型以優化下游回報函數的方法。雖然廣為人知的是，擴散模型提供了優異的生成建模能力，但生物學等領域的實際應用需要生成最大化某些所需指標的樣本（例如，RNA 中的轉譯效率、分子中的對接分數、蛋白質中的穩定性）。在這些情況下，擴散模型不僅可以最佳化以生成逼真的樣本，還可以明確最大化感興趣的測量。此類方法基於強化學習 (RL) 的概念。我們說明了各種 RL 演算法的應用，包括 PPO、可微分最佳化、回報加權 MLE、值加權取樣和路徑一致性學習，這些演算法專門針對微調擴散模型而量身打造。我們的目標是探討基本面向，例如在各種場景中基於 RL 的不同微調演算法的優缺點、與非基於 RL 的方法相比，基於 RL 的微調的優點，以及基於 RL 的微調（目標分佈）的形式化目標。此外，我們的目標是探討它們與相關主題的關聯性，例如分類器指導、Gflownet、基於流的擴散模型、路徑積分控制理論，以及從未正規化的分佈（例如 MCMC）中取樣。本教程的程式碼可在 https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq 取得

##### **Baba Is AI: Break the Rules to Beat the Benchmark**
2407.13729v1 by Nathan Cloos, Meagan Jens, Michelangelo Naim, Yen-Ling Kuo, Ignacio Cases, Andrei Barbu, Christopher J. Cueva

Humans solve problems by following existing rules and procedures, and also by
leaps of creativity to redefine those rules and objectives. To probe these
abilities, we developed a new benchmark based on the game Baba Is You where an
agent manipulates both objects in the environment and rules, represented by
movable tiles with words written on them, to reach a specified goal and win the
game. We test three state-of-the-art multi-modal large language models (OpenAI
GPT-4o, Google Gemini-1.5-Pro and Gemini-1.5-Flash) and find that they fail
dramatically when generalization requires that the rules of the game must be
manipulated and combined.

摘要：人類解決問題的方式是遵循現有的規則和程序，並透過創意的飛躍重新定義這些規則和目標。為了探究這些能力，我們開發了一個新的基準，基於遊戲「Baba Is You」，其中代理人同時操縱環境中的物件和規則，這些規則由寫有文字的可移動磁磚表示，以達成特定目標並贏得遊戲。我們測試了三個最先進的多模態大型語言模型（OpenAI GPT-4o、Google Gemini-1.5-Pro 和 Gemini-1.5-Flash），並發現當概化需要操縱和組合遊戲規則時，它們會大幅失敗。

##### **CoDefeater: Using LLMs To Find Defeaters in Assurance Cases**
2407.13717v1 by Usman Gohar, Michael C. Hunter, Robyn R. Lutz, Myra B. Cohen

Constructing assurance cases is a widely used, and sometimes required,
process toward demonstrating that safety-critical systems will operate safely
in their planned environment. To mitigate the risk of errors and missing edge
cases, the concept of defeaters - arguments or evidence that challenge claims
in an assurance case - has been introduced. Defeaters can provide timely
detection of weaknesses in the arguments, prompting further investigation and
timely mitigations. However, capturing defeaters relies on expert judgment,
experience, and creativity and must be done iteratively due to evolving
requirements and regulations. This paper proposes CoDefeater, an automated
process to leverage large language models (LLMs) for finding defeaters. Initial
results on two systems show that LLMs can efficiently find known and unforeseen
feasible defeaters to support safety analysts in enhancing the completeness and
confidence of assurance cases.

摘要：建構保證案例是一種廣泛使用，有時甚至必要的流程，用於證明安全關鍵系統會在其計畫環境中安全運作。為了減輕錯誤和遺漏邊緣案例的風險，已導入了反駁者的概念，也就是挑戰保證案例中主張的論點或證據。反駁者可以即時偵測論點中的弱點，促使進一步調查和及時緩解。然而，擷取反駁者依賴於專家判斷、經驗和創造力，並且必須隨著不斷變化的需求和法規反覆進行。本文提出 CoDefeater，這是一個自動化流程，利用大型語言模型 (LLM) 來尋找反駁者。針對兩個系統的初步結果顯示，LLM 可以有效找出已知和未預見到的可行反駁者，以協助安全分析師提升保證案例的完整性和信心。

##### **FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning**
2407.13711v1 by Tristan Cinquin, Marvin Pförtner, Vincent Fortuin, Philipp Hennig, Robert Bamler

Laplace approximations are popular techniques for endowing deep networks with
epistemic uncertainty estimates as they can be applied without altering the
predictions of the neural network, and they scale to large models and datasets.
While the choice of prior strongly affects the resulting posterior
distribution, computational tractability and lack of interpretability of weight
space typically limit the Laplace approximation to isotropic Gaussian priors,
which are known to cause pathological behavior as depth increases. As a remedy,
we directly place a prior on function space. More precisely, since Lebesgue
densities do not exist on infinite-dimensional function spaces, we have to
recast training as finding the so-called weak mode of the posterior measure
under a Gaussian process (GP) prior restricted to the space of functions
representable by the neural network. Through the GP prior, one can express
structured and interpretable inductive biases, such as regularity or
periodicity, directly in function space, while still exploiting the implicit
inductive biases that allow deep networks to generalize. After model
linearization, the training objective induces a negative log-posterior density
to which we apply a Laplace approximation, leveraging highly scalable methods
from matrix-free linear algebra. Our method provides improved results where
prior knowledge is abundant, e.g., in many scientific inference tasks. At the
same time, it stays competitive for black-box regression and classification
tasks where neural networks typically excel.

摘要：拉普拉斯近似是赋予深度网络认知不确定性估计的流行技术，因为它们可以在不改变神经网络预测的情况下应用，并且可以扩展到大型模型和数据集。虽然先验的选择强烈影响最终的后验分布，但计算可处理性和权重空间的可解释性缺乏通常将拉普拉斯近似限制为各向同性高斯先验，已知随着深度增加，各向同性高斯先验会导致病态行为。作为补救措施，我们直接在函数空间上放置先验。更准确地说，由于勒贝格密度不存在于无限维函数空间上，我们必须将训练重新表述为在限制为神经网络可表示的函数空间的高斯过程 (GP) 先验下找到后验测度的所谓弱模式。通过 GP 先验，人们可以在函数空间中直接表达结构化且可解释的归纳偏差，例如规律性或周期性，同时仍然利用允许深度网络泛化的隐式归纳偏差。在模型线性化之后，训练目标会引起负对数后验密度，我们对其应用拉普拉斯近似，利用无矩阵线性代数中高度可扩展的方法。我们的方法在先验知识丰富的情况下（例如在许多科学推理任务中）提供了改进的结果。同时，它在黑盒回归和分类任务中保持竞争力，而神经网络通常在这些任务中表现出色。

##### **Understanding Reference Policies in Direct Preference Optimization**
2407.13709v1 by Yixin Liu, Pengfei Liu, Arman Cohan

Direct Preference Optimization (DPO) has become a widely used training method
for the instruction fine-tuning of large language models (LLMs). In this work,
we explore an under-investigated aspect of DPO - its dependency on the
reference model or policy. Such reference policies, typically instantiated as
the model to be further fine-tuned, are important since they can impose an
upper limit on DPO's effectiveness. Therefore, we address three related
research questions in this work. First, we explore the optimal strength of the
KL-divergence constraint in DPO, which penalizes deviations from the reference
policy, and find that DPO is sensitive to this strength. Next, we examine the
necessity of reference policies for instruction fine-tuning by providing both
theoretical and empirical comparisons between DPO and related learning
objectives, demonstrating DPO's superiority. Additionally, we investigate
whether DPO benefits from stronger reference policies, finding that a stronger
reference policy can lead to improved performance, but only when it is similar
to the model being fine-tuned. Our findings highlight the confounding role of
reference policies in DPO and offer insights for best practices, while also
identifying open research questions for future studies.

摘要：直接偏好優化（DPO）已成為廣泛使用的訓練方法，用於大型語言模型（LLM）的指令微調。在這項工作中，我們探討了 DPO 一個未經調查的面向 - 它對參考模型或政策的依賴性。此類參考政策通常被例示為要進一步微調的模型，它們很重要，因為它們可以對 DPO 的有效性施加上限。因此，我們在這項工作中解決了三個相關的研究問題。首先，我們探討了 DPO 中 KL-divergence 約束的最佳強度，它會懲罰與參考政策的偏差，並發現 DPO 對此強度很敏感。接下來，我們透過提供 DPO 與相關學習目標之間的理論和實證比較來檢驗指令微調對參考政策的必要性，證明了 DPO 的優越性。此外，我們探討了 DPO 是否受益於更強的參考政策，發現更強的參考政策可以帶來更好的效能，但僅當它類似於要微調的模型時。我們的研究結果突出了參考政策在 DPO 中的混淆作用，並為最佳實務提供了見解，同時也找出未來研究的開放式研究問題。

##### **ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free Hallucination Detection**
2407.13702v1 by Janek Herrlein, Chia-Chien Hung, Goran Glavaš

Research on token-level reference-free hallucination detection has
predominantly focused on English, primarily due to the scarcity of robust
datasets in other languages. This has hindered systematic investigations into
the effectiveness of cross-lingual transfer for this important NLP application.
To address this gap, we introduce ANHALTEN, a new evaluation dataset that
extends the English hallucination detection dataset to German. To the best of
our knowledge, this is the first work that explores cross-lingual transfer for
token-level reference-free hallucination detection. ANHALTEN contains gold
annotations in German that are parallel (i.e., directly comparable to the
original English instances). We benchmark several prominent cross-lingual
transfer approaches, demonstrating that larger context length leads to better
hallucination detection in German, even without succeeding context.
Importantly, we show that the sample-efficient few-shot transfer is the most
effective approach in most setups. This highlights the practical benefits of
minimal annotation effort in the target language for reference-free
hallucination detection. Aiming to catalyze future research on cross-lingual
token-level reference-free hallucination detection, we make ANHALTEN publicly
available: https://github.com/janekh24/anhalten

摘要：有關代幣層級無參考幻覺檢測的研究主要集中於英文，這主要是由於其他語言缺乏穩健的資料集。這阻礙了對這種重要的 NLP 應用程式進行跨語言轉移有效性的系統性調查。為了解決這個差距，我們引入了 ANHALTEN，這是一個新的評量資料集，將英文幻覺檢測資料集擴展到德文。據我們所知，這是第一個探討代幣層級無參考幻覺檢測的跨語言轉移的工作。ANHALTEN 包含德文的黃金註解，這些註解是平行的（即可以直接與原始英文實例進行比較）。我們對幾種著名的跨語言轉移方法進行基準測試，證明較大的脈絡長度會導致在德文中進行更好的幻覺檢測，即使沒有後續脈絡。重要的是，我們表明樣本效率高的少次數轉移在大多數設定中是最有效的方法。這突顯了在目標語言中進行無參考幻覺檢測時，最小註解工作量的實際好處。為了催化未來對跨語言代幣層級無參考幻覺檢測的研究，我們公開了 ANHALTEN：https://github.com/janekh24/anhalten

##### **Cross-Task Attack: A Self-Supervision Generative Framework Based on Attention Shift**
2407.13700v1 by Qingyuan Zeng, Yunpeng Gong, Min Jiang

Studying adversarial attacks on artificial intelligence (AI) systems helps
discover model shortcomings, enabling the construction of a more robust system.
Most existing adversarial attack methods only concentrate on single-task
single-model or single-task cross-model scenarios, overlooking the multi-task
characteristic of artificial intelligence systems. As a result, most of the
existing attacks do not pose a practical threat to a comprehensive and
collaborative AI system. However, implementing cross-task attacks is highly
demanding and challenging due to the difficulty in obtaining the real labels of
different tasks for the same picture and harmonizing the loss functions across
different tasks. To address this issue, we propose a self-supervised Cross-Task
Attack framework (CTA), which utilizes co-attention and anti-attention maps to
generate cross-task adversarial perturbation. Specifically, the co-attention
map reflects the area to which different visual task models pay attention,
while the anti-attention map reflects the area that different visual task
models neglect. CTA generates cross-task perturbations by shifting the
attention area of samples away from the co-attention map and closer to the
anti-attention map. We conduct extensive experiments on multiple vision tasks
and the experimental results confirm the effectiveness of the proposed design
for adversarial attacks.

摘要：研究人工智慧 (AI) 系統的對抗攻擊有助於
發現模型的缺點，從而能夠建構更強大的系統。
現有的對抗攻擊方法大多只專注於單一任務
單一模型或單一任務跨模型場景，忽略了人工智慧系統的多任務
特性。因此，現有的攻擊大多對全面且
協作式 AI 系統不構成實際威脅。然而，由於難以取得
同一張圖片不同任務的真實標籤，以及調和不同任務的損失函數，因此實作跨任務攻擊非常
要求且具有挑戰性。為了解決這個問題，我們提出一個自我監督的跨任務
攻擊架構 (CTA)，它利用共同注意和反注意地圖來
產生跨任務對抗擾動。特別是，共同注意地圖反映不同視覺任務模型注意到的區域，
而反注意地圖反映不同視覺任務模型忽略的區域。CTA 透過將
樣本的注意區域從共同注意地圖移開並靠近
反注意地圖來產生跨任務擾動。我們對多個視覺任務進行廣泛的實驗
並且實驗結果證實了所提出的設計對於對抗攻擊的有效性。

##### **A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**
2407.13699v1 by Shaina Raza, Mizanur Rahman, Safiullah Kamawal, Armin Toroghi, Ananya Raval, Farshad Navah, Amirmohammad Kazemeini

Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends

摘要：推薦系統 (RS) 在提升使用者體驗中扮演著不可或缺的角色，透過提供個人化的商品建議。這項調查回顧了 RS 在 2017 年到 2024 年間的進展，有效地將理論進展與實際應用連結起來。我們探討了從傳統的 RS 技術，例如基於內容和協同過濾，到涉及深度學習、基於圖形的模型、強化學習和大語言模型等先進方法的發展。我們也討論了專門的系統，例如情境感知、基於評論和公平感知的 RS。這項調查的主要目標是將理論與實務結合起來。它解決了各個領域的挑戰，包括電子商務、醫療保健和金融，強調了對可擴充、即時和可信賴的解決方案的需求。透過這項調查，我們促進了學術研究和產業實務之間更強大的夥伴關係。這項調查提供的見解旨在引導產業專業人士優化 RS 部署，並激勵未來的研究方向，特別是在解決新興的技術和社會趨勢方面。

##### **Benchmark Agreement Testing Done Right: A Guide for LLM Benchmark Evaluation**
2407.13696v1 by Yotam Perlitz, Ariel Gera, Ofir Arviv, Asaf Yehudai, Elron Bandel, Eyal Shnarch, Michal Shmueli-Scheuer, Leshem Choshen

Recent advancements in Language Models (LMs) have catalyzed the creation of
multiple benchmarks, designed to assess these models' general capabilities. A
crucial task, however, is assessing the validity of the benchmarks themselves.
This is most commonly done via Benchmark Agreement Testing (BAT), where new
benchmarks are validated against established ones using some agreement metric
(e.g., rank correlation). Despite the crucial role of BAT for benchmark
builders and consumers, there are no standardized procedures for such agreement
testing. This deficiency can lead to invalid conclusions, fostering mistrust in
benchmarks and upending the ability to properly choose the appropriate
benchmark to use. By analyzing over 40 prominent benchmarks, we demonstrate how
some overlooked methodological choices can significantly influence BAT results,
potentially undermining the validity of conclusions. To address these
inconsistencies, we propose a set of best practices for BAT and demonstrate how
utilizing these methodologies greatly improves BAT robustness and validity. To
foster adoption and facilitate future research,, we introduce BenchBench, a
python package for BAT, and release the BenchBench-leaderboard, a
meta-benchmark designed to evaluate benchmarks using their peers. Our findings
underscore the necessity for standardized BAT, ensuring the robustness and
validity of benchmark evaluations in the evolving landscape of language model
research.
  BenchBench Package: https://github.com/IBM/BenchBench
  Leaderboard: https://huggingface.co/spaces/per/BenchBench

摘要：<paragraph>語言模型 (LM) 的最新進展催化了多個基準的建立，這些基準旨在評估這些模型的一般能力。然而，一項至關重要的任務是評估基準本身的有效性。這通常通過基準協議測試 (BAT) 來完成，其中使用一些協議指標（例如，等級相關性）根據已建立的基準驗證新的基準。儘管 BAT 對基準構建者和消費者扮演著至關重要的角色，但對於此類協議測試並沒有標準化的程序。這種缺陷可能會導致無效的結論，造成對基準的不信任，並破壞適當地選擇適當基準使用的能力。通過分析超過 40 個重要的基準，我們展示了一些被忽視的方法論選擇如何顯著影響 BAT 結果，並可能破壞結論的有效性。為了解決這些不一致之處，我們提出了一套 BAT 的最佳實務範例，並展示了利用這些方法論如何大幅改善 BAT 的穩健性和有效性。為了促進採用和促進未來的研究，我們引入了 BenchBench，一個用於 BAT 的 python 套件，並發布了 BenchBench-leaderboard，一個元基準，旨在使用同儕評估基準。我們的發現強調了標準化 BAT 的必要性，確保了基準評估在語言模型研究不斷變化的環境中的穩健性和有效性。
BenchBench 套件：https://github.com/IBM/BenchBench
排行榜：https://huggingface.co/spaces/per/BenchBench</paragraph>

