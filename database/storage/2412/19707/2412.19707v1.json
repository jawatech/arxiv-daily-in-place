{"2412.19707": {"publish_time": "2024-12-27", "title": "Toward Adaptive Reasoning in Large Language Models with Thought Rollback", "paper_summary": "Large language models (LLMs) have been routinely used to solve various tasks\nusing step-by-step reasoning. However, the structure of intermediate reasoning\nsteps, or thoughts, is rigid and unidirectional, such as chains, trees, or\nacyclic-directed graphs. Consequently, the resulting inflexible and\nforward-only reasoning may not address challenging tasks and fail when the LLM\nfrequently gives false responses, i.e., ``hallucinations''. This paper proposes\na new reasoning framework, called Thought Rollback (TR), allowing LLMs to\nadaptively build thought structure while maintaining effective reasoning toward\nproblem-solving under ``hallucinations''. The core mechanism of TR is rolling\nback thoughts, which allows LLMs to perform error analysis on thoughts, and\nthus roll back to any previously mistaken thought for revision. Subsequently,\nby including such trial-and-error in the prompt to guide the LLM, each rollback\nleads to one more reliable reasoning path. Therefore, starting with a simple\nprompt without human annotations, LLM with TR adaptively and gradually explores\nthoughts for a correct solution. Comprehensive experiments on mathematical\nproblems and multi-task reasoning demonstrate the state-of-the-art performance\nof TR in terms of problem-solving rate and interaction cost. For instance, the\nsolving rate of GPT-4 with TR outperforms the current best by $9\\%$ on the MATH\ndataset.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u5df2\u5e38\u898f\u7528\u65bc\u89e3\u6c7a\u5404\u7a2e\u4efb\u52d9\uff0c\u4f7f\u7528\u9010\u6b65\u63a8\u7406\u3002\u7136\u800c\uff0c\u4e2d\u9593\u63a8\u7406\u6b65\u9a5f\u6216\u60f3\u6cd5\u7684\u7d50\u69cb\u662f\u50f5\u5316\u4e14\u55ae\u5411\u7684\uff0c\u4f8b\u5982\u93c8\u3001\u6a39\u6216\u7121\u74b0\u6709\u5411\u5716\u3002\u56e0\u6b64\uff0c\u7522\u751f\u7684\u50f5\u5316\u4e14\u50c5\u5411\u524d\u63a8\u7406\u53ef\u80fd\u7121\u6cd5\u89e3\u6c7a\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\uff0c\u4e26\u4e14\u7576 LLM \u983b\u7e41\u7d66\u51fa\u932f\u8aa4\u7684\u56de\u61c9\uff08\u5373\u300c\u5e7b\u89ba\u300d\uff09\u6642\u6703\u5931\u6557\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u63a8\u7406\u6846\u67b6\uff0c\u7a31\u70ba Thought Rollback\uff08TR\uff09\uff0c\u5141\u8a31 LLM \u5728\u89e3\u6c7a\u300c\u5e7b\u89ba\u300d\u554f\u984c\u6642\u81ea\u9069\u61c9\u5730\u69cb\u5efa\u601d\u60f3\u7d50\u69cb\uff0c\u540c\u6642\u4fdd\u6301\u6709\u6548\u7684\u63a8\u7406\u3002TR \u7684\u6838\u5fc3\u6a5f\u5236\u662f\u56de\u6efe\u601d\u60f3\uff0c\u5b83\u5141\u8a31 LLM \u5c0d\u601d\u60f3\u57f7\u884c\u932f\u8aa4\u5206\u6790\uff0c\u4e26\u56e0\u6b64\u56de\u6efe\u5230\u4efb\u4f55\u5148\u524d\u932f\u8aa4\u7684\u601d\u60f3\u9032\u884c\u4fee\u6539\u3002\u96a8\u5f8c\uff0c\u901a\u904e\u5728\u63d0\u793a\u4e2d\u5305\u542b\u6b64\u985e\u8a66\u932f\u4f86\u6307\u5c0e LLM\uff0c\u6bcf\u6b21\u56de\u6efe\u90fd\u6703\u5c0e\u81f4\u4e00\u689d\u66f4\u53ef\u9760\u7684\u63a8\u7406\u8def\u5f91\u3002\u56e0\u6b64\uff0c\u5f9e\u4e00\u500b\u6c92\u6709\u4eba\u5de5\u8a3b\u91cb\u7684\u7c21\u55ae\u63d0\u793a\u958b\u59cb\uff0c\u5e36\u6709 TR \u7684 LLM \u81ea\u9069\u61c9\u5730\u9010\u6f38\u63a2\u7d22\u601d\u60f3\u4ee5\u7372\u5f97\u6b63\u78ba\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u5728\u6578\u5b78\u554f\u984c\u548c\u591a\u4efb\u52d9\u63a8\u7406\u4e0a\u7684\u7d9c\u5408\u5be6\u9a57\u8b49\u660e\u4e86 TR \u5728\u554f\u984c\u89e3\u6c7a\u7387\u548c\u4ea4\u4e92\u6210\u672c\u65b9\u9762\u7684\u6700\u5148\u9032\u6027\u80fd\u3002\u4f8b\u5982\uff0c\u5e36\u6709 TR \u7684 GPT-4 \u7684\u6c42\u89e3\u7387\u5728 MATH \u6578\u64da\u96c6\u4e0a\u6bd4\u76ee\u524d\u7684\u6700\u4f73\u6027\u80fd\u9ad8\u51fa 9%\u3002", "author": "Sijia Chen et.al.", "authors": "Sijia Chen, Baochun Li", "id": "2412.19707v1", "paper_url": "http://arxiv.org/abs/2412.19707v1", "repo": "https://github.com/iQua/llmpebase"}}