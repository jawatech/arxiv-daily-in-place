
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-14**|**TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models**|Mu Cai et.al.|[2410.10818v1](http://arxiv.org/abs/2410.10818v1)|null|
|**2024-10-14**|**DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads**|Guangxuan Xiao et.al.|[2410.10819v1](http://arxiv.org/abs/2410.10819v1)|[link](https://github.com/mit-han-lab/duo-attention)|
|**2024-10-14**|**LVD-2M: A Long-take Video Dataset with Temporally Dense Captions**|Tianwei Xiong et.al.|[2410.10816v1](http://arxiv.org/abs/2410.10816v1)|[link](https://github.com/silentview/lvd-2m)|
|**2024-10-14**|**Depth Any Video with Scalable Synthetic Data**|Honghui Yang et.al.|[2410.10815v1](http://arxiv.org/abs/2410.10815v1)|null|
|**2024-10-14**|**LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory**|Di Wu et.al.|[2410.10813v1](http://arxiv.org/abs/2410.10813v1)|[link](https://github.com/xiaowu0162/longmemeval)|
|**2024-10-14**|**Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free**|Ziyue Li et.al.|[2410.10814v1](http://arxiv.org/abs/2410.10814v1)|null|
|**2024-10-14**|**HART: Efficient Visual Generation with Hybrid Autoregressive Transformer**|Haotian Tang et.al.|[2410.10812v1](http://arxiv.org/abs/2410.10812v1)|[link](https://github.com/mit-han-lab/hart)|
|**2024-10-14**|**Local and Global Decoding in Text Generation**|Daniel Gareev et.al.|[2410.10810v1](http://arxiv.org/abs/2410.10810v1)|[link](https://github.com/lowlypalace/global-decoding)|
|**2024-10-14**|**Hard-Constrained Neural Networks with Universal Approximation Guarantees**|Youngjae Min et.al.|[2410.10807v1](http://arxiv.org/abs/2410.10807v1)|null|
|**2024-10-14**|**Boosting Camera Motion Control for Video Diffusion Transformers**|Soon Yau Cheong et.al.|[2410.10802v1](http://arxiv.org/abs/2410.10802v1)|null|
|**2024-10-14**|**Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning**|Aakanksha et.al.|[2410.10801v1](http://arxiv.org/abs/2410.10801v1)|null|
|**2024-10-14**|**Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance**|Sachin Goyal et.al.|[2410.10796v1](http://arxiv.org/abs/2410.10796v1)|[link](https://github.com/locuslab/context-parametric-inversion)|
|**2024-10-14**|**On Information-Theoretic Measures of Predictive Uncertainty**|Kajetan Schweighofer et.al.|[2410.10786v1](http://arxiv.org/abs/2410.10786v1)|[link](https://github.com/ml-jku/uncertainty-measures)|
|**2024-10-14**|**When Attention Sink Emerges in Language Models: An Empirical View**|Xiangming Gu et.al.|[2410.10781v1](http://arxiv.org/abs/2410.10781v1)|[link](https://github.com/sail-sg/attention-sink)|
|**2024-10-14**|**Focused ReAct: Improving ReAct through Reiterate and Early Stop**|Shuoqiu Li et.al.|[2410.10779v1](http://arxiv.org/abs/2410.10779v1)|null|
|**2024-10-14**|**Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation**|Youwei Yu et.al.|[2410.10766v1](http://arxiv.org/abs/2410.10766v1)|null|
|**2024-10-14**|**AFlow: Automating Agentic Workflow Generation**|Jiayi Zhang et.al.|[2410.10762v1](http://arxiv.org/abs/2410.10762v1)|[link](https://github.com/geekan/metagpt)|
|**2024-10-14**|**Denial-of-Service Poisoning Attacks against Large Language Models**|Kuofeng Gao et.al.|[2410.10760v1](http://arxiv.org/abs/2410.10760v1)|[link](https://github.com/sail-sg/p-dos)|
|**2024-10-14**|**Arrhythmia Classification Using Graph Neural Networks Based on Correlation Matrix**|Seungwoo Han et.al.|[2410.10758v1](http://arxiv.org/abs/2410.10758v1)|null|
|**2024-10-14**|**Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification**|Jan Cegin et.al.|[2410.10756v1](http://arxiv.org/abs/2410.10756v1)|null|
|**2024-10-14**|**FlexGen: Flexible Multi-View Generation from Text and Image Inputs**|Xinli Xu et.al.|[2410.10745v1](http://arxiv.org/abs/2410.10745v1)|null|
|**2024-10-14**|**NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**|Yanbiao Ji et.al.|[2410.10743v1](http://arxiv.org/abs/2410.10743v1)|null|
|**2024-10-14**|**SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing**|Pengrui Quan et.al.|[2410.10741v1](http://arxiv.org/abs/2410.10741v1)|[link](https://github.com/nesl/llm_sensor_processing)|
|**2024-10-14**|**Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs**|Ishan Jindal et.al.|[2410.10739v1](http://arxiv.org/abs/2410.10739v1)|null|
|**2024-10-14**|**DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model**|Yuqi Wang et.al.|[2410.10738v1](http://arxiv.org/abs/2410.10738v1)|null|
|**2024-10-14**|**Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning**|Kuofeng Gao et.al.|[2410.10735v1](http://arxiv.org/abs/2410.10735v1)|null|
|**2024-10-14**|**Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models**|Junyu Chen et.al.|[2410.10733v1](http://arxiv.org/abs/2410.10733v1)|[link](https://github.com/mit-han-lab/efficientvit)|
|**2024-10-14**|**Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection**|Giorgos Iacovides et.al.|[2410.10728v1](http://arxiv.org/abs/2410.10728v1)|null|
|**2024-10-14**|**Large Language Models Are Active Critics in NLG Evaluation**|Shuying Xu et.al.|[2410.10724v1](http://arxiv.org/abs/2410.10724v1)|null|
|**2024-10-14**|**SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators**|Rasoul Shafipour et.al.|[2410.10714v1](http://arxiv.org/abs/2410.10714v1)|null|
|**2024-10-14**|**Early Diagnoses of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models**|Alaa Awad et.al.|[2410.10701v1](http://arxiv.org/abs/2410.10701v1)|null|
|**2024-10-14**|**Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues**|Qibing Ren et.al.|[2410.10700v1](http://arxiv.org/abs/2410.10700v1)|[link](https://github.com/renqibing/actorattack)|
|**2024-10-14**|**Building a Multivariate Time Series Benchmarking Datasets Inspired by Natural Language Processing (NLP)**|Mohammad Asif Ibna Mustafa et.al.|[2410.10687v1](http://arxiv.org/abs/2410.10687v1)|null|
|**2024-10-14**|**Large Language Model Evaluation via Matrix Nuclear-Norm**|Yahan Li et.al.|[2410.10672v1](http://arxiv.org/abs/2410.10672v1)|null|
|**2024-10-14**|**Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers**|Aivin V. Solatorio et.al.|[2410.10665v1](http://arxiv.org/abs/2410.10665v1)|null|
|**2024-10-14**|**Generative AI and Its Impact on Personalized Intelligent Tutoring Systems**|Subhankar Maity et.al.|[2410.10650v1](http://arxiv.org/abs/2410.10650v1)|null|
|**2024-10-14**|**DR-MPC: Deep Residual Model Predictive Control for Real-world Social Navigation**|James R. Han et.al.|[2410.10646v1](http://arxiv.org/abs/2410.10646v1)|null|
|**2024-10-14**|**Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection**|Adyasha Maharana et.al.|[2410.10636v1](http://arxiv.org/abs/2410.10636v1)|null|
|**2024-10-14**|**Thinking LLMs: General Instruction Following with Thought Generation**|Tianhao Wu et.al.|[2410.10630v1](http://arxiv.org/abs/2410.10630v1)|null|
|**2024-10-14**|**Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts**|Guorui Zheng et.al.|[2410.10626v1](http://arxiv.org/abs/2410.10626v1)|[link](https://github.com/freedomintelligence/apollomoe)|
|**2024-10-14**|**SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition**|Zechen Li et.al.|[2410.10624v1](http://arxiv.org/abs/2410.10624v1)|[link](https://github.com/zechenli03/sensorllm)|
|**2024-10-14**|**Modeling News Interactions and Influence for Financial Market Prediction**|Mengyu Wang et.al.|[2410.10614v1](http://arxiv.org/abs/2410.10614v1)|null|
|**2024-10-14**|**Intelligent prospector v2.0: exploration drill planning under epistemic model uncertainty**|John Mern et.al.|[2410.10610v1](http://arxiv.org/abs/2410.10610v1)|null|
|**2024-10-14**|**BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI**|Shaohao Rui et.al.|[2410.10604v1](http://arxiv.org/abs/2410.10604v1)|null|
|**2024-10-14**|**Neural networks that overcome classic challenges through practice**|Kazuki Irie et.al.|[2410.10596v1](http://arxiv.org/abs/2410.10596v1)|null|
|**2024-10-14**|**VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents**|Shi Yu et.al.|[2410.10594v1](http://arxiv.org/abs/2410.10594v1)|null|
|**2024-10-14**|**TRESTLE: A Model of Concept Formation in Structured Domains**|Christopher J. MacLellan et.al.|[2410.10588v1](http://arxiv.org/abs/2410.10588v1)|[link](https://github.com/cmaclell/concept_formation)|
|**2024-10-14**|**Tübingen-CL at SemEval-2024 Task 1:Ensemble Learning for Semantic Relatedness Estimation**|Leixin Zhang et.al.|[2410.10585v1](http://arxiv.org/abs/2410.10585v1)|null|
|**2024-10-14**|**STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack**|Naman Gupta et.al.|[2410.10584v1](http://arxiv.org/abs/2410.10584v1)|null|
|**2024-10-14**|**Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences**|Ayushman Gupta et.al.|[2410.10580v1](http://arxiv.org/abs/2410.10580v1)|null|
|**2024-10-14**|**Recipe for Zero-shot POS Tagging: Is It Useful in Realistic Scenarios?**|Zeno Vandenbulcke et.al.|[2410.10576v1](http://arxiv.org/abs/2410.10576v1)|null|
|**2024-10-14**|**When Precedents Clash**|Cecilia Di Florio et.al.|[2410.10567v1](http://arxiv.org/abs/2410.10567v1)|null|
|**2024-10-14**|**Is Structure Dependence Shaped for Efficient Communication?: A Case Study on Coordination**|Kohei Kajikawa et.al.|[2410.10556v1](http://arxiv.org/abs/2410.10556v1)|[link](https://github.com/kohei-kaji/coordination)|
|**2024-10-14**|**ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection**|Martin Aubard et.al.|[2410.10554v1](http://arxiv.org/abs/2410.10554v1)|[link](https://github.com/remaro-network/rosar-framework)|
|**2024-10-14**|**SLaNC: Static LayerNorm Calibration**|Mahsa Salmani et.al.|[2410.10553v1](http://arxiv.org/abs/2410.10553v1)|null|
|**2024-10-14**|**Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features**|Changqing Gong et.al.|[2410.10547v1](http://arxiv.org/abs/2410.10547v1)|null|
|**2024-10-14**|**Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models**|Shubham Kumar Nigam et.al.|[2410.10542v1](http://arxiv.org/abs/2410.10542v1)|null|
|**2024-10-14**|**Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature**|Jan Vrba et.al.|[2410.10537v1](http://arxiv.org/abs/2410.10537v1)|[link](https://github.com/aailab-uct/automated-robust-and-reproducible-voice-pathology-detection)|
|**2024-10-14**|**Get Rid of Task Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework**|Zhongchao Yi et.al.|[2410.10524v1](http://arxiv.org/abs/2410.10524v1)|[link](https://github.com/dilab-ustcsz/cmust)|
|**2024-10-14**|**UniGEM: A Unified Approach to Generation and Property Prediction for Molecules**|Shikun Feng et.al.|[2410.10516v1](http://arxiv.org/abs/2410.10516v1)|null|
|**2024-10-14**|**Everyday Speech in the Indian Subcontinent**|Utkarsh Pathak et.al.|[2410.10508v1](http://arxiv.org/abs/2410.10508v1)|null|
|**2024-10-14**|**A Practical Approach to Causal Inference over Time**|Martina Cinquini et.al.|[2410.10502v1](http://arxiv.org/abs/2410.10502v1)|null|
|**2024-10-14**|**Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation**|Sharif Kazemi et.al.|[2410.10489v1](http://arxiv.org/abs/2410.10489v1)|null|
|**2024-10-14**|**Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization**|Jorge García-Torres et.al.|[2410.10483v1](http://arxiv.org/abs/2410.10483v1)|[link](https://github.com/jtorres258/image-based-tob)|
|**2024-10-14**|**Model-Based Differentially Private Knowledge Transfer for Large Language Models**|Zhaomin Wu et.al.|[2410.10481v1](http://arxiv.org/abs/2410.10481v1)|null|
|**2024-10-14**|**TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs**|Haochuan Wang et.al.|[2410.10479v1](http://arxiv.org/abs/2410.10479v1)|null|
|**2024-10-14**|**Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?**|Gabriel Roccabruna et.al.|[2410.10476v1](http://arxiv.org/abs/2410.10476v1)|[link](https://github.com/brownfortress/llms-trc)|
|**2024-10-14**|**TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE**|Emmanouil Panagiotou et.al.|[2410.10463v1](http://arxiv.org/abs/2410.10463v1)|[link](https://github.com/panagiotou/tabcf)|
|**2024-10-14**|**Ada-K Routing: Boosting the Efficiency of MoE-based LLMs**|Tongtian Yue et.al.|[2410.10456v2](http://arxiv.org/abs/2410.10456v2)|null|
|**2024-10-14**|**Advancing Academic Knowledge Retrieval via LLM-enhanced Representation Similarity Fusion**|Wei Dai et.al.|[2410.10455v1](http://arxiv.org/abs/2410.10455v1)|null|
|**2024-10-14**|**KBLaM: Knowledge Base augmented Language Model**|Xi Wang et.al.|[2410.10450v1](http://arxiv.org/abs/2410.10450v1)|null|
|**2024-10-14**|**QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios**|Timo Pierre Schrader et.al.|[2410.10449v1](http://arxiv.org/abs/2410.10449v1)|null|
|**2024-10-14**|**Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs**|Kai Han et.al.|[2410.10441v1](http://arxiv.org/abs/2410.10441v1)|[link](https://github.com/contrastive/freevideollm)|
|**2024-10-14**|**LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections**|Xuezhi Xiang et.al.|[2410.10433v1](http://arxiv.org/abs/2410.10433v1)|null|
|**2024-10-14**|**On Calibration of LLM-based Guard Models for Reliable Content Moderation**|Hongfu Liu et.al.|[2410.10414v1](http://arxiv.org/abs/2410.10414v1)|null|
|**2024-10-14**|**Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion**|Xinping Zhao et.al.|[2410.10408v1](http://arxiv.org/abs/2410.10408v1)|null|
|**2024-10-14**|**MMCFND: Multimodal Multilingual Caption-aware Fake News Detection for Low-resource Indic Languages**|Shubhi Bansal et.al.|[2410.10407v1](http://arxiv.org/abs/2410.10407v1)|[link](https://github.com/shubhi-bansal/MMCFND)|
|**2024-10-14**|**FairMindSim: Alignment of Behavior, Emotion, and Belief in Humans and LLM Agents Amid Ethical Dilemmas**|Yu Lei et.al.|[2410.10398v1](http://arxiv.org/abs/2410.10398v1)|null|
|**2024-10-14**|**PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic Manipulation**|Kaidong Zhang et.al.|[2410.10394v1](http://arxiv.org/abs/2410.10394v1)|null|
|**2024-10-14**|**Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search**|Chenglin Li et.al.|[2410.10392v1](http://arxiv.org/abs/2410.10392v1)|null|
|**2024-10-14**|**BookWorm: A Dataset for Character Description and Analysis**|Argyrios Papoudakis et.al.|[2410.10372v1](http://arxiv.org/abs/2410.10372v1)|null|
|**2024-10-14**|**Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps**|Han Wang et.al.|[2410.10370v1](http://arxiv.org/abs/2410.10370v1)|null|
|**2024-10-14**|**Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation**|Zehua Cheng et.al.|[2410.10366v1](http://arxiv.org/abs/2410.10366v1)|null|
|**2024-10-14**|**SpeGCL: Self-supervised Graph Spectrum Contrastive Learning without Positive Samples**|Yuntao Shou et.al.|[2410.10365v1](http://arxiv.org/abs/2410.10365v1)|null|
|**2024-10-14**|**Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning**|Yongxin Xu et.al.|[2410.10360v1](http://arxiv.org/abs/2410.10360v1)|null|
|**2024-10-14**|**LLM-based Code-Switched Text Generation for Grammatical Error Correction**|Tom Potter et.al.|[2410.10349v1](http://arxiv.org/abs/2410.10349v1)|null|
|**2024-10-14**|**Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement**|Joseph Shtok et.al.|[2410.10348v1](http://arxiv.org/abs/2410.10348v1)|null|
|**2024-10-14**|**A Unified Approach to Routing and Cascading for LLMs**|Jasper Dekoninck et.al.|[2410.10347v1](http://arxiv.org/abs/2410.10347v1)|null|
|**2024-10-14**|**Locking Down the Finetuned LLMs Safety**|Minjun Zhu et.al.|[2410.10343v1](http://arxiv.org/abs/2410.10343v1)|[link](https://github.com/zhu-minjun/safetylock)|
|**2024-10-14**|**CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning**|Joshua Ong Jun Leang et.al.|[2410.10336v1](http://arxiv.org/abs/2410.10336v1)|null|
|**2024-10-14**|**Disentangling Hate Across Target Identities**|Yiping Jin et.al.|[2410.10332v1](http://arxiv.org/abs/2410.10332v1)|[link](https://github.com/yipingnus/disentangle-hate)|
|**2024-10-14**|**GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**|Yun Zhu et.al.|[2410.10329v2](http://arxiv.org/abs/2410.10329v2)|[link](https://github.com/zhuyun97/graphclip)|
|**2024-10-14**|**MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media**|Wei Zhai et.al.|[2410.10323v1](http://arxiv.org/abs/2410.10323v1)|null|
|**2024-10-14**|**EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations**|Zhangchi Feng et.al.|[2410.10315v2](http://arxiv.org/abs/2410.10315v2)|[link](https://github.com/buaadreamer/easyrag)|
|**2024-10-14**|**A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification**|Aryan Singhal et.al.|[2410.10303v1](http://arxiv.org/abs/2410.10303v1)|[link](https://github.com/3x-dev/Comparative-Study-of-Bias-and-Accuracy-in-Multilingual-LLMs-for-Cross-Language-Claim-Verification)|
|**2024-10-14**|**FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG**|Xinping Zhao et.al.|[2410.10293v1](http://arxiv.org/abs/2410.10293v1)|null|
|**2024-10-14**|**Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective**|Xiangru Zhu et.al.|[2410.10291v1](http://arxiv.org/abs/2410.10291v1)|[link](https://github.com/zhuxiangru/semvarbench)|
|**2024-10-14**|**A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets**|Nikolaos Mylonas et.al.|[2410.10290v1](http://arxiv.org/abs/2410.10290v1)|null|
|**2024-10-14**|**ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge**|Meerzhan Kanatbekova et.al.|[2410.10285v1](http://arxiv.org/abs/2410.10285v1)|null|
|**2024-10-14**|**Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis**|Hongjian Yu et.al.|[2410.10278v1](http://arxiv.org/abs/2410.10278v1)|null|

#### Abstracts
##### **TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models**
2410.10818v1 by Mu Cai, Reuben Tan, Jianrui Zhang, Bocheng Zou, Kai Zhang, Feng Yao, Fangrui Zhu, Jing Gu, Yiwu Zhong, Yuzhang Shang, Yao Dou, Jaden Park, Jianfeng Gao, Yong Jae Lee, Jianwei Yang

Understanding fine-grained temporal dynamics is crucial for multimodal video
comprehension and generation. Due to the lack of fine-grained temporal
annotations, existing video benchmarks mostly resemble static image benchmarks
and are incompetent at evaluating models for temporal understanding. In this
paper, we introduce TemporalBench, a new benchmark dedicated to evaluating
fine-grained temporal understanding in videos. TemporalBench consists of ~10K
video question-answer pairs, derived from ~2K high-quality human annotations
detailing the temporal dynamics in video clips. As a result, our benchmark
provides a unique testbed for evaluating various temporal understanding and
reasoning abilities such as action frequency, motion magnitude, event order,
etc. Moreover, it enables evaluations on various tasks like both video question
answering and captioning, both short and long video understanding, as well as
different models such as multimodal video embedding models and text generation
models. Results show that state-of-the-art models like GPT-4o achieve only
38.5% question answering accuracy on TemporalBench, demonstrating a significant
gap (~30%) between humans and AI in temporal understanding. Furthermore, we
notice a critical pitfall for multi-choice QA where LLMs can detect the subtle
changes in negative captions and find a centralized description as a cue for
its prediction, where we propose Multiple Binary Accuracy (MBA) to correct such
bias. We hope that TemporalBench can foster research on improving models'
temporal reasoning capabilities. Both dataset and evaluation code will be made
available.

摘要：<paragraph>了解精細的時間動態對於多模態影片理解和生成至關重要。由於缺乏精細的時間註解，現有的影片基準測試大多類似於靜態影像基準測試，並且無法評估時間理解模型。在本文中，我們介紹了 TemporalBench，這是一個新的基準測試，專門用於評估影片中的精細時間理解。TemporalBench 包含約 10K 個影片問答對，這些對來自約 2K 個人類高品質註解，詳細說明了影片剪輯中的時間動態。因此，我們的基準測試提供了一個獨特的測試平台，用於評估各種時間理解和推理能力，例如動作頻率、動作幅度、事件順序等。此外，它支援各種任務的評估，例如影片問答和字幕、短影片和長影片理解，以及各種模型，例如多模態影片嵌入模型和文字生成模型。結果顯示，像 GPT-4o 這樣的最先進模型在 TemporalBench 上僅達到 38.5% 的問答準確率，這表明人類和 AI 在時間理解上存在顯著差距（約 30%）。此外，我們注意到多選題 QA 的一個關鍵缺陷，其中 LLM 可以檢測到負面字幕中的細微變化，並找到一個集中描述作為其預測的線索，我們提出了多重二進制準確率 (MBA) 來糾正這種偏差。我們希望 TemporalBench 能夠促進改善模型時間推理能力的研究。資料集和評估程式碼都將公開。</paragraph>

##### **DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads**
2410.10819v1 by Guangxuan Xiao, Jiaming Tang, Jingwei Zuo, Junxian Guo, Shang Yang, Haotian Tang, Yao Fu, Song Han

Deploying long-context large language models (LLMs) is essential but poses
significant computational and memory challenges. Caching all Key and Value (KV)
states across all attention heads consumes substantial memory. Existing KV
cache pruning methods either damage the long-context capabilities of LLMs or
offer only limited efficiency improvements. In this paper, we identify that
only a fraction of attention heads, a.k.a, Retrieval Heads, are critical for
processing long contexts and require full attention across all tokens. In
contrast, all other heads, which primarily focus on recent tokens and attention
sinks--referred to as Streaming Heads--do not require full attention. Based on
this insight, we introduce DuoAttention, a framework that only applies a full
KV cache to retrieval heads while using a light-weight, constant-length KV
cache for streaming heads, which reduces both LLM's decoding and pre-filling
memory and latency without compromising its long-context abilities.
DuoAttention uses a lightweight, optimization-based algorithm with synthetic
data to identify retrieval heads accurately. Our method significantly reduces
long-context inference memory by up to 2.55x for MHA and 1.67x for GQA models
while speeding up decoding by up to 2.18x and 1.50x and accelerating
pre-filling by up to 1.73x and 1.63x for MHA and GQA models, respectively, with
minimal accuracy loss compared to full attention. Notably, combined with
quantization, DuoAttention enables Llama-3-8B decoding with 3.3 million context
length on a single A100 GPU. Code is provided in
https://github.com/mit-han-lab/duo-attention.

摘要：部署長語境大型語言模型 (LLM) 是必要的，但會帶來
顯著的計算和記憶體挑戰。快取所有關注頭上的所有鍵值 (KV)
狀態會消耗大量的記憶體。現有的 KV 快取修剪方法會損害 LLM 的長語境功能或
僅提供有限的效率提升。在本文中，我們發現只有少數的關注頭，又稱檢索頭，對
處理長語境至關重要，並且需要所有代幣的完全關注。相反，所有其他主要關注最近代幣和注意力的頭
接收器——稱為串流頭——不需要完全關注。基於
這個見解，我們引入了 DuoAttention，一個只對檢索頭應用完整
KV 快取的架構，同時對串流頭使用輕量級、長度固定的 KV
快取，這減少了 LLM 的解碼和預填充
記憶體和延遲，同時不損害其長語境能力。
DuoAttention 使用一種基於優化的輕量級演算法，並使用合成
資料準確識別檢索頭。我們的技術顯著減少了
MHA 的長語境推論記憶體，最多可達 2.55 倍，GQA 模型可達 1.67 倍
同時將解碼速度提高了 2.18 倍和 1.50 倍，並將
MHA 和 GQA 模型的預填充速度分別提高了 1.73 倍和 1.63 倍，與
完全關注相比，準確度損失最小。值得注意的是，結合
量化，DuoAttention 可以讓 Llama-3-8B 在單個 A100 GPU 上解碼 330 萬個語境長度。程式碼提供在
https://github.com/mit-han-lab/duo-attention。

##### **LVD-2M: A Long-take Video Dataset with Temporally Dense Captions**
2410.10816v1 by Tianwei Xiong, Yuqing Wang, Daquan Zhou, Zhijie Lin, Jiashi Feng, Xihui Liu

The efficacy of video generation models heavily depends on the quality of
their training datasets. Most previous video generation models are trained on
short video clips, while recently there has been increasing interest in
training long video generation models directly on longer videos. However, the
lack of such high-quality long videos impedes the advancement of long video
generation. To promote research in long video generation, we desire a new
dataset with four key features essential for training long video generation
models: (1) long videos covering at least 10 seconds, (2) long-take videos
without cuts, (3) large motion and diverse contents, and (4) temporally dense
captions. To achieve this, we introduce a new pipeline for selecting
high-quality long-take videos and generating temporally dense captions.
Specifically, we define a set of metrics to quantitatively assess video quality
including scene cuts, dynamic degrees, and semantic-level quality, enabling us
to filter high-quality long-take videos from a large amount of source videos.
Subsequently, we develop a hierarchical video captioning pipeline to annotate
long videos with temporally-dense captions. With this pipeline, we curate the
first long-take video dataset, LVD-2M, comprising 2 million long-take videos,
each covering more than 10 seconds and annotated with temporally dense
captions. We further validate the effectiveness of LVD-2M by fine-tuning video
generation models to generate long videos with dynamic motions. We believe our
work will significantly contribute to future research in long video generation.

摘要：影片生成模型的效能極度仰賴其訓練資料集的品質。大多數先前的影片生成模型都是以短影片片段進行訓練，而最近對於直接以較長的影片訓練長影片生成模型的興趣與日俱增。然而，此類高品質長影片的缺乏阻礙了長影片生成的進展。為了促進長影片生成的相關研究，我們需要一個具備四項關鍵特徵的新資料集，這些特徵對於訓練長影片生成模型至關重要：(1) 至少涵蓋 10 秒的長影片，(2) 無剪輯的長鏡頭影片，(3) 大幅動作和多元內容，以及 (4) 時間密集的字幕。為此，我們引進一個新的流程來選取高品質長鏡頭影片並產生時間密集的字幕。具體來說，我們定義了一組指標來量化評估影片品質，包括場景剪輯、動態程度和語義層級品質，讓我們能夠從大量的原始影片中篩選出高品質長鏡頭影片。隨後，我們開發了一個階層式影片字幕處理流程，以時間密集的字幕為長影片加上註解。透過此流程，我們策劃了第一個長鏡頭影片資料集 LVD-2M，其中包含 200 萬個長鏡頭影片，每個影片都涵蓋超過 10 秒，並加上時間密集的字幕。我們進一步驗證 LVD-2M 的效能，方法是微調影片生成模型以產生具有動態動作的長影片。我們相信，我們的研究將對未來長影片生成的相關研究做出重大貢獻。

##### **Depth Any Video with Scalable Synthetic Data**
2410.10815v1 by Honghui Yang, Di Huang, Wei Yin, Chunhua Shen, Haifeng Liu, Xiaofei He, Binbin Lin, Wanli Ouyang, Tong He

Video depth estimation has long been hindered by the scarcity of consistent
and scalable ground truth data, leading to inconsistent and unreliable results.
In this paper, we introduce Depth Any Video, a model that tackles the challenge
through two key innovations. First, we develop a scalable synthetic data
pipeline, capturing real-time video depth data from diverse synthetic
environments, yielding 40,000 video clips of 5-second duration, each with
precise depth annotations. Second, we leverage the powerful priors of
generative video diffusion models to handle real-world videos effectively,
integrating advanced techniques such as rotary position encoding and flow
matching to further enhance flexibility and efficiency. Unlike previous models,
which are limited to fixed-length video sequences, our approach introduces a
novel mixed-duration training strategy that handles videos of varying lengths
and performs robustly across different frame rates-even on single frames. At
inference, we propose a depth interpolation method that enables our model to
infer high-resolution video depth across sequences of up to 150 frames. Our
model outperforms all previous generative depth models in terms of spatial
accuracy and temporal consistency.

摘要：影片深度估計長久以來受限於一致且可擴充的真實數據的稀少性，導致結果不一致且不可靠。在本文中，我們介紹 Depth Any Video，這是一個透過兩項關鍵創新來應對挑戰的模型。首先，我們開發了一個可擴充的合成數據管線，從多樣化的合成環境中擷取即時影片深度數據，產生 40,000 個長度為 5 秒的影片剪輯，每個剪輯都有精確的深度註解。其次，我們利用生成式影片擴散模型的強大先驗知識來有效處理真實世界的影片，整合旋轉位置編碼和流匹配等進階技術，以進一步增強靈活性與效率。與先前僅限於固定長度影片序列的模型不同，我們的方法引入了一種新穎的混合持續時間訓練策略，它可以處理長度不一的影片，並在不同幀率下表現得穩定，甚至在單一幀中也是如此。在推論中，我們提出了一種深度插值方法，使我們的模型能夠推論長達 150 幀的序列中的高解析度影片深度。我們的模型在空間準確度和時間一致性方面優於所有先前的生成式深度模型。

##### **LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory**
2410.10813v1 by Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, Kai-Wei Chang, Dong Yu

Recent large language model (LLM)-driven chat assistant systems have
integrated memory components to track user-assistant chat histories, enabling
more accurate and personalized responses. However, their long-term memory
capabilities in sustained interactions remain underexplored. This paper
introduces LongMemEval, a comprehensive benchmark designed to evaluate five
core long-term memory abilities of chat assistants: information extraction,
multi-session reasoning, temporal reasoning, knowledge updates, and abstention.
With 500 meticulously curated questions embedded within freely scalable
user-assistant chat histories, LongMemEval presents a significant challenge to
existing long-term memory systems, with commercial chat assistants and
long-context LLMs showing 30% accuracy drop on memorizing information across
sustained interactions. We then present a unified framework that breaks down
the long-term memory design into four design choices across the indexing,
retrieval, and reading stages. Built upon key experimental insights, we propose
several memory designs including session decomposition for optimizing value
granularity, fact-augmented key expansion for enhancing the index structure,
and time-aware query expansion for refining the search scope. Experiment
results show that these optimizations greatly improve both memory recall and
downstream question answering on LongMemEval. Overall, our study provides
valuable resources and guidance for advancing the long-term memory capabilities
of LLM-based chat assistants, paving the way toward more personalized and
reliable conversational AI.

摘要：<paragraph>最近的大型語言模型 (LLM) 驅動的聊天助理系統已整合記憶元件來追蹤使用者與助理的聊天記錄，能提供更準確且個人化的回應。然而，它們在持續互動中的長期記憶能力仍未被充分探討。本文介紹 LongMemEval，一個全面的基準測試，旨在評估聊天助理的五項核心長期記憶能力：資訊擷取、多回合推理、時間推理、知識更新和棄權。LongMemEval 在可自由擴充的使用者與助理聊天記錄中嵌入了 500 個精心策劃的問題，對現有的長期記憶系統提出重大挑戰，而市面上的聊天助理和長語境 LLM 在持續互動中記憶資訊的準確度下降了 30%。接著我們提出一個統一的架構，將長期記憶設計分解為索引、擷取和讀取階段的四個設計選擇。根據關鍵實驗見解，我們提出多項記憶設計，包括用於最佳化值粒度的會話分解、用於增強索引結構的事實擴充關鍵字擴充，以及用於精煉搜尋範圍的時間感知查詢擴充。實驗結果顯示，這些最佳化大幅改善了 LongMemEval 上的記憶召回和下游問題解答。總體而言，我們的研究為提升 LLM 為基礎的聊天助理的長期記憶能力提供了寶貴的資源和指導，為更個人化且可靠的對話式 AI 鋪路。</paragraph>

##### **Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free**
2410.10814v1 by Ziyue Li, Tianyi Zhou

While large language models (LLMs) excel on generation tasks, their
decoder-only architecture often limits their potential as embedding models if
no further representation finetuning is applied. Does this contradict their
claim of generalists? To answer the question, we take a closer look at
Mixture-of-Experts (MoE) LLMs. Our study shows that the expert routers in MoE
LLMs can serve as an off-the-shelf embedding model with promising performance
on a diverse class of embedding-focused tasks, without requiring any
finetuning. Moreover, our extensive analysis shows that the MoE routing weights
(RW) is complementary to the hidden state (HS) of LLMs, a widely-used
embedding. Compared to HS, we find that RW is more robust to the choice of
prompts and focuses on high-level semantics. Motivated by the analysis, we
propose MoEE combining RW and HS, which achieves better performance than using
either separately. Our exploration of their combination and prompting strategy
shed several novel insights, e.g., a weighted sum of RW and HS similarities
outperforms the similarity on their concatenation. Our experiments are
conducted on 6 embedding tasks with 20 datasets from the Massive Text Embedding
Benchmark (MTEB). The results demonstrate the significant improvement brought
by MoEE to LLM-based embedding without further finetuning.

摘要：儘管大型語言模型 (LLM) 在生成任務中表現出色，但其僅解碼器的架構通常會限制其作為嵌入模型的潛力，除非應用進一步的表示微調。這是否與其通才的說法相矛盾？為了回答這個問題，我們仔細研究了專家混合 (MoE) LLM。我們的研究表明，MoE LLM 中的專家路由器可以用作現成的嵌入模型，在各種以嵌入為中心的任務上具有令人滿意的效能，而無需任何微調。此外，我們的廣泛分析表明，MoE 路由權重 (RW) 與 LLM 的隱藏狀態 (HS)（一種廣泛使用的嵌入）是互補的。與 HS 相比，我們發現 RW 對提示的選擇更具魯棒性，並且專注於高層次語義。受分析的啟發，我們提出了結合 RW 和 HS 的 MoEE，其效能優於單獨使用任一方法。我們對其組合和提示策略的探索揭示了幾個新穎的見解，例如，RW 和 HS 相似性的加權和優於它們串聯的相似性。我們的實驗是在大規模文字嵌入基準 (MTEB) 中的 20 個資料集上的 6 個嵌入任務中進行的。結果證明了 MoEE 在沒有進一步微調的情況下為基於 LLM 的嵌入帶來的顯著改進。

##### **HART: Efficient Visual Generation with Hybrid Autoregressive Transformer**
2410.10812v1 by Haotian Tang, Yecheng Wu, Shang Yang, Enze Xie, Junsong Chen, Junyu Chen, Zhuoyang Zhang, Han Cai, Yao Lu, Song Han

We introduce Hybrid Autoregressive Transformer (HART), an autoregressive (AR)
visual generation model capable of directly generating 1024x1024 images,
rivaling diffusion models in image generation quality. Existing AR models face
limitations due to the poor image reconstruction quality of their discrete
tokenizers and the prohibitive training costs associated with generating 1024px
images. To address these challenges, we present the hybrid tokenizer, which
decomposes the continuous latents from the autoencoder into two components:
discrete tokens representing the big picture and continuous tokens representing
the residual components that cannot be represented by the discrete tokens. The
discrete component is modeled by a scalable-resolution discrete AR model, while
the continuous component is learned with a lightweight residual diffusion
module with only 37M parameters. Compared with the discrete-only VAR tokenizer,
our hybrid approach improves reconstruction FID from 2.11 to 0.30 on MJHQ-30K,
leading to a 31% generation FID improvement from 7.85 to 5.38. HART also
outperforms state-of-the-art diffusion models in both FID and CLIP score, with
4.5-7.7x higher throughput and 6.9-13.4x lower MACs. Our code is open sourced
at https://github.com/mit-han-lab/hart.

摘要：<paragraph>我們介紹了混合自迴歸Transformer (HART)，這是一個自迴歸 (AR) 視覺生成模型，能夠直接生成 1024x1024 影像，在影像生成品質上與擴散模型匹敵。現有的 AR 模型由於其離散符號化器的影像重建品質不佳，以及生成 1024px 影像時相關的訓練成本過高，因此面臨限制。為了應對這些挑戰，我們提出了混合符號化器，它將來自自動編碼器的連續潛在變數分解成兩個組成部分：代表大局的離散符號，以及代表無法由離散符號表示的殘差組成的連續符號。離散組成部分由可調整解析度的離散 AR 模型建模，而連續組成部分則使用僅有 37M 參數的輕量級殘差擴散模組進行學習。與僅有離散的 VAR 符號化器相比，我們的混合方法將 MJHQ-30K 上的重建 FID 從 2.11 改善到 0.30，導致生成 FID 從 7.85 改善到 5.38，提升了 31%。HART 在 FID 和 CLIP 分數上也優於最先進的擴散模型，且處理量高出 4.5-7.7 倍，MACs 低 6.9-13.4 倍。我們的程式碼已在 https://github.com/mit-han-lab/hart 開源。</paragraph>

##### **Local and Global Decoding in Text Generation**
2410.10810v1 by Daniel Gareev, Thomas Hofmann, Ezhilmathi Krishnasamy, Tiago Pimentel

Text generation, a key component in applications such as dialogue systems,
relies on decoding algorithms that sample strings from a language model
distribution. Traditional methods, such as top-$k$ and top-$\pi$, apply local
normalisation to the model's output distribution, which can distort it. In this
paper, we investigate the effect of this distortion by introducing
globally-normalised versions of these decoding methods. Additionally, we
propose an independent Metropolis-Hastings algorithm to approximate sampling
from globally-normalised distributions without explicitly computing them. Our
empirical analysis compares the performance of local and global normalisation
across two decoding algorithms (top-$k$ and top-$\pi$) with various
hyperparameters, using Pythia language models. Results show that, in most
configurations, global decoding performs worse than the local decoding version
of the same algorithms -- despite preserving the distribution's integrity. Our
results suggest that distortion is an important feature of local decoding
algorithms.

摘要：文字生成是對話系統等應用程式中的關鍵元件，
依賴於從語言模型分佈中取樣字串的解碼演算法。傳統方法，例如 top-$k$ 和 top-$\pi$，對模型的輸出分佈套用局部正規化，這可能會扭曲它。在本文中，我們透過引入這些解碼方法的全局正規化版本來探討這種扭曲的影響。此外，我們提出一個獨立的 Metropolis-Hastings 演算法來近似從全局正規化分佈取樣，而不用明確地計算它們。我們的實證分析比較了在使用 Pythia 語言模型的情況下，在兩個解碼演算法（top-$k$ 和 top-$\pi$）以及各種超參數中，局部和全局正規化的效能。結果顯示，在大部分組態中，全局解碼的效能比相同演算法的局部解碼版本差，儘管保留了分佈的完整性。我們的結果表明，扭曲是局部解碼演算法的一項重要特徵。

##### **Hard-Constrained Neural Networks with Universal Approximation Guarantees**
2410.10807v1 by Youngjae Min, Anoopkumar Sonar, Navid Azizan

Incorporating prior knowledge or specifications of input-output relationships
into machine learning models has gained significant attention, as it enhances
generalization from limited data and leads to conforming outputs. However, most
existing approaches use soft constraints by penalizing violations through
regularization, which offers no guarantee of constraint satisfaction -- an
essential requirement in safety-critical applications. On the other hand,
imposing hard constraints on neural networks may hinder their representational
power, adversely affecting performance. To address this, we propose HardNet, a
practical framework for constructing neural networks that inherently satisfy
hard constraints without sacrificing model capacity. Specifically, we encode
affine and convex hard constraints, dependent on both inputs and outputs, by
appending a differentiable projection layer to the network's output. This
architecture allows unconstrained optimization of the network parameters using
standard algorithms while ensuring constraint satisfaction by construction.
Furthermore, we show that HardNet retains the universal approximation
capabilities of neural networks. We demonstrate the versatility and
effectiveness of HardNet across various applications: fitting functions under
constraints, learning optimization solvers, optimizing control policies in
safety-critical systems, and learning safe decision logic for aircraft systems.

摘要：將先備知識或輸入輸出關係的規格納入機器學習模型已獲得極大的關注，因為它增強了從有限資料中進行概括的能力，並產生符合輸出的結果。然而，現有的方法大多使用軟約束，透過正則化懲罰違規，這無法保證約束滿足——安全關鍵應用程式中的基本需求。另一方面，對神經網路施加硬約束可能會阻礙其表示能力，對效能造成負面影響。為了解決此問題，我們提出 HardNet，這是一個實用的架構，用於建構在不犧牲模型容量的情況下固有地滿足硬約束的神經網路。具體來說，我們透過將可微分投影層附加到網路的輸出，對依賴輸入和輸出的仿射和凸硬約束進行編碼。此架構允許使用標準演算法對網路參數進行無約束最佳化，同時透過建構確保約束滿足。此外，我們證明 HardNet 保留了神經網路的通用逼近能力。我們展示了 HardNet 在各種應用中的多功能性和有效性：在約束下擬合函數、學習最佳化求解器、最佳化安全關鍵系統中的控制策略，以及學習飛機系統的安全決策邏輯。

##### **Boosting Camera Motion Control for Video Diffusion Transformers**
2410.10802v1 by Soon Yau Cheong, Duygu Ceylan, Armin Mustafa, Andrew Gilbert, Chun-Hao Paul Huang

Recent advancements in diffusion models have significantly enhanced the
quality of video generation. However, fine-grained control over camera pose
remains a challenge. While U-Net-based models have shown promising results for
camera control, transformer-based diffusion models (DiT)-the preferred
architecture for large-scale video generation - suffer from severe degradation
in camera motion accuracy. In this paper, we investigate the underlying causes
of this issue and propose solutions tailored to DiT architectures. Our study
reveals that camera control performance depends heavily on the choice of
conditioning methods rather than camera pose representations that is commonly
believed. To address the persistent motion degradation in DiT, we introduce
Camera Motion Guidance (CMG), based on classifier-free guidance, which boosts
camera control by over 400%. Additionally, we present a sparse camera control
pipeline, significantly simplifying the process of specifying camera poses for
long videos. Our method universally applies to both U-Net and DiT models,
offering improved camera control for video generation tasks.

摘要：最近在扩散模型上的进步已经显著提升了视频生成的质量。然而，对摄像机姿势的精细控制仍然是一个挑战。虽然基于 U-Net 的模型在摄像机控制方面显示出了有希望的结果，但基于 transformer 的扩散模型 (DiT) - 用于大规模视频生成的首选架构 - 在摄像机运动准确性方面遭受严重的下降。在本文中，我们调查了这个问题的根本原因，并提出了针对 DiT 架构的解决方案。我们的研究表明，摄像机控制性能很大程度上取决于调节方法的选择，而不是通常认为的摄像机姿势表示。为了解决 DiT 中持续的运动退化问题，我们引入了基于无分类器引导的摄像机运动引导 (CMG)，它将摄像机控制提升了 400% 以上。此外，我们提出了一个稀疏摄像机控制管道，极大地简化了为长视频指定摄像机姿势的过程。我们的方法普遍适用于 U-Net 和 DiT 模型，为视频生成任务提供了改进的摄像机控制。

##### **Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning**
2410.10801v1 by Aakanksha, Arash Ahmadian, Seraphina Goldfarb-Tarrant, Beyza Ermis, Marzieh Fadaee, Sara Hooker

Large Language Models (LLMs) have been adopted and deployed worldwide for a
broad variety of applications. However, ensuring their safe use remains a
significant challenge. Preference training and safety measures often overfit to
harms prevalent in Western-centric datasets, and safety protocols frequently
fail to extend to multilingual settings. In this work, we explore model merging
in a diverse multi-task setting, combining safety and general-purpose tasks
within a multilingual context. Each language introduces unique and varied
learning challenges across tasks. We find that objective-based merging is more
effective than mixing data, with improvements of up to 8% and 10% in general
performance and safety respectively. We also find that language-based merging
is highly effective -- by merging monolingually fine-tuned models, we achieve a
4% increase in general performance and 7% reduction in harm across all
languages on top of the data mixtures method using the same available data.
Overall, our comprehensive study of merging approaches provides a useful
framework for building strong and safe multilingual models.

摘要：大型語言模型 (LLM) 已在全球範圍內廣泛採用和部署，適用於各種應用程式。然而，確保其安全使用仍然是一項重大挑戰。偏好訓練和安全措施經常過度符合以西方為中心的資料集中普遍存在的危害，而安全協議通常無法擴展到多語言設定。在這項工作中，我們在多元化的多任務設定中探索模型合併，在多語言環境中結合安全性和通用任務。每種語言在各項任務中都會帶來獨特且多樣的學習挑戰。我們發現基於目標的合併比混合資料更有效，在一般效能和安全性的改進分別高達 8% 和 10%。我們還發現基於語言的合併非常有效——透過合併單語言微調模型，我們在一般效能上提高了 4%，在所有語言中減少了 7% 的危害，高於使用相同可用資料的資料混合方法。總體而言，我們對合併方法的全面研究為建構強大且安全的的多語言模型提供了有用的架構。

##### **Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance**
2410.10796v1 by Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan

Large language models are instruction-finetuned to enhance their ability to
follow user instructions and process the input context. However, even
state-of-the-art models often struggle to follow the instruction, especially
when the input context is not aligned with the model's parametric knowledge.
This manifests as various failures, such as hallucinations where the responses
are outdated, biased or contain unverified facts. In this work, we try to
understand the underlying reason for this poor context reliance, especially
after instruction tuning. We observe an intriguing phenomenon: during
instruction tuning, the context reliance initially increases as expected, but
then gradually decreases as instruction finetuning progresses. We call this
phenomenon context-parametric inversion and observe it across multiple general
purpose instruction tuning datasets like TULU, Alpaca and Ultrachat, as well as
model families such as Llama, Mistral and Pythia. In a simple theoretical
setup, we isolate why context-parametric inversion occurs along the gradient
descent trajectory of instruction finetuning. We tie this phenomena to examples
in the instruction finetuning data mixture where the input context provides
information that is already present in the model's parametric knowledge. Our
analysis suggests natural mitigation strategies that provide some limited
gains, while also validating our theoretical insights. We hope that our work
serves as a starting point in addressing this failure mode in a staple part of
LLM training.

摘要：大型語言模型經過指令微調，以增強其遵循使用者指令和處理輸入內容的能力。然而，即使是最新穎的模型也經常難以遵循指令，特別是在輸入內容與模型的參數化知識不一致時。這會表現為各種失敗，例如幻覺，其中回應過時、有偏差或包含未經驗證的事實。在這項工作中，我們嘗試了解這種不良內容依賴性的根本原因，特別是在指令微調之後。我們觀察到一個有趣的現象：在指令微調期間，內容依賴性最初如預期般增加，但隨著指令微調的進行，逐漸下降。我們將這種現象稱為內容參數反轉，並在多個通用指令微調資料集（例如 TULU、Alpaca 和 Ultrachat）以及 Llama、Mistral 和 Pythia 等模型系列中觀察到這種現象。在一個簡單的理論設定中，我們隔離了在指令微調的梯度下降軌跡中發生內容參數反轉的原因。我們將這種現象與指令微調資料混合中的範例聯繫起來，其中輸入內容提供了模型參數化知識中已存在資訊。我們的分析建議了自然緩解策略，這些策略提供了一些有限的收益，同時也驗證了我們的理論見解。我們希望我們的研究能作為解決 LLM 訓練中這個失敗模式的起點。

##### **On Information-Theoretic Measures of Predictive Uncertainty**
2410.10786v1 by Kajetan Schweighofer, Lukas Aichberger, Mykyta Ielanskyi, Sepp Hochreiter

Reliable estimation of predictive uncertainty is crucial for machine learning
applications, particularly in high-stakes scenarios where hedging against risks
is essential. Despite its significance, a consensus on the correct measurement
of predictive uncertainty remains elusive. In this work, we return to first
principles to develop a fundamental framework of information-theoretic
predictive uncertainty measures. Our proposed framework categorizes predictive
uncertainty measures according to two factors: (I) The predicting model (II)
The approximation of the true predictive distribution. Examining all possible
combinations of these two factors, we derive a set of predictive uncertainty
measures that includes both known and newly introduced ones. We empirically
evaluate these measures in typical uncertainty estimation settings, such as
misclassification detection, selective prediction, and out-of-distribution
detection. The results show that no single measure is universal, but the
effectiveness depends on the specific setting. Thus, our work provides clarity
about the suitability of predictive uncertainty measures by clarifying their
implicit assumptions and relationships.

摘要：可靠的預測不確定性估計對於機器學習應用至關重要，特別是在對沖風險至關重要的關鍵情境中。儘管其意義重大，但對於預測不確定性的正確測量方法仍未達成共識。在這項工作中，我們回歸第一原理，以開發資訊理論預測不確定性測量基準的基礎架構。我們提出的架構根據兩個因素將預測不確定性測量基準分類：(I) 預測模型 (II) 真實預測分佈的近似值。透過檢驗這兩個因素的所有可能組合，我們推導出一組預測不確定性測量基準，其中包括已知和新引入的測量基準。我們在典型的預測不確定性估計設定中，例如錯誤分類偵測、選擇性預測和異常偵測，對這些測量基準進行經驗評估。結果顯示，沒有單一測量基準具有通用性，但其有效性取決於特定設定。因此，我們的研究透過釐清預測不確定性測量基準的隱含假設和關係，明確了其適用性。

##### **When Attention Sink Emerges in Language Models: An Empirical View**
2410.10781v1 by Xiangming Gu, Tianyu Pang, Chao Du, Qian Liu, Fengzhuo Zhang, Cunxiao Du, Ye Wang, Min Lin

Language Models (LMs) assign significant attention to the first token, even
if it is not semantically important, which is known as attention sink. This
phenomenon has been widely adopted in applications such as streaming/long
context generation, KV cache optimization, inference acceleration, model
quantization, and others. Despite its widespread use, a deep understanding of
attention sink in LMs is still lacking. In this work, we first demonstrate that
attention sinks exist universally in LMs with various inputs, even in small
models. Furthermore, attention sink is observed to emerge during the LM
pre-training, motivating us to investigate how optimization, data distribution,
loss function, and model architecture in LM pre-training influence its
emergence. We highlight that attention sink emerges after effective
optimization on sufficient training data. The sink position is highly
correlated with the loss function and data distribution. Most importantly, we
find that attention sink acts more like key biases, storing extra attention
scores, which could be non-informative and not contribute to the value
computation. We also observe that this phenomenon (at least partially) stems
from tokens' inner dependence on attention scores as a result of softmax
normalization. After relaxing such dependence by replacing softmax attention
with other attention operations, such as sigmoid attention without
normalization, attention sinks do not emerge in LMs up to 1B parameters. The
code is available at https://github.com/sail-sg/Attention-Sink.

摘要：語言模型 (LM) 會將顯著的注意力分配給第一個符號，即使它在語義上並不重要，這稱為注意力接收器。這種現象已被廣泛應用於串流/長內容生成、KV 快取最佳化、推論加速、模型量化等應用程式中。儘管它被廣泛使用，但對於 LM 中的注意力接收器仍缺乏深入的了解。在這項工作中，我們首先證明注意力接收器普遍存在於具有各種輸入的 LM 中，即使在小型模型中也是如此。此外，觀察到注意力接收器會在 LM 預訓練期間出現，促使我們探討 LM 預訓練中的最佳化、資料分佈、損失函數和模型架構如何影響其出現。我們強調，在充足的訓練資料上進行有效最佳化後，注意力接收器就會出現。接收器位置與損失函數和資料分佈高度相關。最重要的是，我們發現注意力接收器更像是鍵偏差，儲存額外的注意力分數，這些分數可能是無意義的，而且不會有助於值運算。我們還觀察到，這種現象（至少部分）源於符號對注意力分數的內部依賴性，這是 softmax 正規化的結果。在透過將 softmax 注意力替換為其他注意力運算（例如沒有正規化的 sigmoid 注意力）來放寬這種依賴性後，注意力接收器不會出現在高達 1B 參數的 LM 中。程式碼可在 https://github.com/sail-sg/Attention-Sink 取得。

##### **Focused ReAct: Improving ReAct through Reiterate and Early Stop**
2410.10779v1 by Shuoqiu Li, Han Xu, Haipeng Chen

Large language models (LLMs) have significantly improved their reasoning and
decision-making capabilities, as seen in methods like ReAct. However, despite
its effectiveness in tackling complex tasks, ReAct faces two main challenges:
losing focus on the original question and becoming stuck in action loops. To
address these issues, we introduce Focused ReAct, an enhanced version of the
ReAct paradigm that incorporates reiteration and early stop mechanisms. These
improvements help the model stay focused on the original query and avoid
repetitive behaviors. Experimental results show accuracy gains of 18% to 530%
and a runtime reduction of up to 34% compared to the original ReAct method.

摘要：大型語言模型 (LLM) 已顯著提升其推理和決策能力，這在 ReAct 等方法中可見一斑。然而，儘管 ReAct 在處理複雜任務方面很有效，但它面臨兩項主要挑戰：失去對原始問題的關注，並陷入行動迴圈中。為了解決這些問題，我們引入了 Focused ReAct，這是一個增強版的 ReAct 典範，結合了反覆運算和早期停止機制。這些改良有助於模型保持對原始查詢的關注，並避免重複的行為。實驗結果顯示，與原始 ReAct 方法相比，準確度提高了 18% 至 530%，執行時間減少了 34%。

##### **Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation**
2410.10766v1 by Youwei Yu, Junhong Xu, Lantao Liu

Model-free reinforcement learning has emerged as a powerful method for
developing robust robot control policies capable of navigating through complex
and unstructured terrains. The effectiveness of these methods hinges on two
essential elements: (1) the use of massively parallel physics simulations to
expedite policy training, and (2) an environment generator tasked with crafting
sufficiently challenging yet attainable terrains to facilitate continuous
policy improvement. Existing methods of environment generation often rely on
heuristics constrained by a set of parameters, limiting the diversity and
realism. In this work, we introduce the Adaptive Diffusion Terrain Generator
(ADTG), a novel method that leverages Denoising Diffusion Probabilistic Models
to dynamically expand existing training environments by adding more diverse and
complex terrains adaptive to the current policy. ADTG guides the diffusion
model's generation process through initial noise optimization, blending
noise-corrupted terrains from existing training environments weighted by the
policy's performance in each corresponding environment. By manipulating the
noise corruption level, ADTG seamlessly transitions between generating similar
terrains for policy fine-tuning and novel ones to expand training diversity.
Our experiments show that the policy trained by ADTG outperforms both
procedural generated and natural environments, along with popular navigation
methods.

摘要：無模型強化學習已成為一種強大的方法，用於開發強健的機器人控制策略，能夠在複雜且無結構的地形中導航。這些方法的有效性取決於兩個基本要素：(1) 使用大量並行物理模擬來加速策略訓練，以及 (2) 一個環境生成器，負責製作足夠具有挑戰性但可達成的地形，以促進策略的持續改進。現有的環境生成方法通常依賴於受一組參數約束的啟發法，這限制了多樣性和真實性。在這項工作中，我們引入了自適應擴散地形生成器 (ADTG)，這是一種新方法，利用去噪擴散機率模型透過添加更多樣化且複雜的地形，動態擴展現有的訓練環境，以適應當前策略。ADTG 透過初始雜訊最佳化引導擴散模型的生成過程，混合來自現有訓練環境的雜訊損壞地形，並根據策略在每個對應環境中的表現進行加權。透過操縱雜訊損壞等級，ADTG 可在為策略微調產生類似地形和產生新地形以擴展訓練多樣性之間無縫轉換。我們的實驗顯示，由 ADTG 訓練的策略優於程序產生的環境和自然環境，以及流行的導航方法。

##### **AFlow: Automating Agentic Workflow Generation**
2410.10762v1 by Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo, Chenglin Wu

Large language models (LLMs) have demonstrated remarkable potential in
solving complex tasks across diverse domains, typically by employing agentic
workflows that follow detailed instructions and operational sequences. However,
constructing these workflows requires significant human effort, limiting
scalability and generalizability. Recent research has sought to automate the
generation and optimization of these workflows, but existing methods still rely
on initial manual setup and fall short of achieving fully automated and
effective workflow generation. To address this challenge, we reformulate
workflow optimization as a search problem over code-represented workflows,
where LLM-invoking nodes are connected by edges. We introduce AFlow, an
automated framework that efficiently explores this space using Monte Carlo Tree
Search, iteratively refining workflows through code modification,
tree-structured experience, and execution feedback. Empirical evaluations
across six benchmark datasets demonstrate AFlow's efficacy, yielding a 5.7%
average improvement over state-of-the-art baselines. Furthermore, AFlow enables
smaller models to outperform GPT-4o on specific tasks at 4.55% of its inference
cost in dollars. The code will be available at
https://github.com/geekan/MetaGPT.

摘要：大型語言模型 (LLM) 在解決不同領域的複雜任務中展現出驚人的潛力，通常透過遵循詳細指示和操作順序的代理工作流程來執行。然而，建構這些工作流程需要大量人力，限制了可擴充性和概括性。最近的研究試圖自動化這些工作流程的產生和最佳化，但現有方法仍依賴於最初的手動設定，且無法達成完全自動化且有效的工作流程產生。為了應對這項挑戰，我們將工作流程最佳化重新表述為一個針對程式碼表示工作流程的搜尋問題，其中呼叫 LLM 的節點透過邊緣連接。我們引入了 AFlow，一個自動化架構，它使用蒙地卡羅樹狀搜尋有效探索這個空間，透過程式碼修改、樹狀結構經驗和執行回饋，反覆精進工作流程。在六個基準資料集上的實證評估證明了 AFlow 的效能，比現有技術基線平均提升了 5.7%。此外，AFlow 使較小的模型能夠以其推論成本 4.55% 的美元價格在特定任務上超越 GPT-4o。程式碼將可在 https://github.com/geekan/MetaGPT 取得。

##### **Denial-of-Service Poisoning Attacks against Large Language Models**
2410.10760v1 by Kuofeng Gao, Tianyu Pang, Chao Du, Yong Yang, Shu-Tao Xia, Min Lin

Recent studies have shown that LLMs are vulnerable to denial-of-service (DoS)
attacks, where adversarial inputs like spelling errors or non-semantic prompts
trigger endless outputs without generating an [EOS] token. These attacks can
potentially cause high latency and make LLM services inaccessible to other
users or tasks. However, when there are speech-to-text interfaces (e.g., voice
commands to a robot), executing such DoS attacks becomes challenging, as it is
difficult to introduce spelling errors or non-semantic prompts through speech.
A simple DoS attack in these scenarios would be to instruct the model to "Keep
repeating Hello", but we observe that relying solely on natural instructions
limits output length, which is bounded by the maximum length of the LLM's
supervised finetuning (SFT) data. To overcome this limitation, we propose
poisoning-based DoS (P-DoS) attacks for LLMs, demonstrating that injecting a
single poisoned sample designed for DoS purposes can break the output length
limit. For example, a poisoned sample can successfully attack GPT-4o and GPT-4o
mini (via OpenAI's finetuning API) using less than $1, causing repeated outputs
up to the maximum inference length (16K tokens, compared to 0.5K before
poisoning). Additionally, we perform comprehensive ablation studies on
open-source LLMs and extend our method to LLM agents, where attackers can
control both the finetuning dataset and algorithm. Our findings underscore the
urgent need for defenses against P-DoS attacks to secure LLMs. Our code is
available at https://github.com/sail-sg/P-DoS.

摘要：<paragraph>最近的研究表明，LLM 容易受到拒绝服务 (DoS) 攻击，其中对抗性输入（如拼写错误或非语义提示）会触发无穷无尽的输出，而不会生成 [EOS] 令牌。这些攻击可能会导致高延迟，并使 LLM 服务对其他用户或任务不可访问。然而，当有语音到文本界面（例如，对机器人的语音命令）时，执行此类 DoS 攻击变得具有挑战性，因为很难通过语音引入拼写错误或非语义提示。在这些场景中，一个简单的 DoS 攻击是指示模型“继续重复 Hello”，但我们观察到，仅依赖自然指令会限制输出长度，该长度受 LLM 的监督微调 (SFT) 数据的最大长度限制。为了克服这一限制，我们提出了针对 LLM 的基于中毒的 DoS (P-DoS) 攻击，证明注入一个专为 DoS 目的而设计的中毒样本可以打破输出长度限制。例如，一个中毒样本可以使用不到 1 美元成功攻击 GPT-4o 和 GPT-4o mini（通过 OpenAI 的微调 API），导致重复输出达到最大推理长度（16K 个令牌，而中毒前为 0.5K）。此外，我们对开源 LLM 进行了全面的消融研究，并将我们的方法扩展到 LLM 代理，攻击者可以在其中控制微调数据集和算法。我们的研究结果强调了迫切需要针对 P-DoS 攻击的防御措施来保护 LLM。我们的代码可在 https://github.com/sail-sg/P-DoS 获得。</paragraph>

##### **Arrhythmia Classification Using Graph Neural Networks Based on Correlation Matrix**
2410.10758v1 by Seungwoo Han

With the advancements in graph neural network, there has been increasing
interest in applying this network to ECG signal analysis. In this study, we
generated an adjacency matrix using correlation matrix of extracted features
and applied a graph neural network to classify arrhythmias. The proposed model
was compared with existing approaches from the literature. The results
demonstrated that precision and recall for all arrhythmia classes exceeded 50%,
suggesting that this method can be considered an approach for arrhythmia
classification.

摘要：隨著圖神經網路的進步，將此網路應用於心電圖訊號分析的興趣也與日俱增。在本研究中，我們使用提取特徵的相關矩陣產生鄰接矩陣，並應用圖神經網路對心律不整進行分類。將所提出的模型與文獻中現有的方法進行比較。結果表明，所有心律不整類別的準確度和召回率都超過 50%，這表明此方法可以被視為心律不整分類的一種方法。

##### **Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification**
2410.10756v1 by Jan Cegin, Branislav Pecher, Jakub Simko, Ivan Srba, Maria Bielikova, Peter Brusilovsky

The generative large language models (LLMs) are increasingly used for data
augmentation tasks, where text samples are paraphrased (or generated anew) and
then used for classifier fine-tuning. Existing works on augmentation leverage
the few-shot scenarios, where samples are given to LLMs as part of prompts,
leading to better augmentations. Yet, the samples are mostly selected randomly
and a comprehensive overview of the effects of other (more ``informed'') sample
selection strategies is lacking. In this work, we compare sample selection
strategies existing in few-shot learning literature and investigate their
effects in LLM-based textual augmentation. We evaluate this on in-distribution
and out-of-distribution classifier performance. Results indicate, that while
some ``informed'' selection strategies increase the performance of models,
especially for out-of-distribution data, it happens only seldom and with
marginal performance increases. Unless further advances are made, a default of
random sample selection remains a good option for augmentation practitioners.

摘要：生成式大型语言模型 (LLM) 越来越多地用于数据增强任务，其中文本样本被改写（或重新生成），然后用于分类器微调。现有的增强工作利用了小样本场景，其中样本作为提示的一部分提供给 LLM，从而产生更好的增强。然而，这些样本大多是随机选择的，并且缺乏对其他（更“知情”）样本选择策略的影响的全面概述。在这项工作中，我们比较了小样本学习文献中存在的样本选择策略，并研究了它们在基于 LLM 的文本增强中的影响。我们在分布内和分布外分类器性能上对此进行了评估。结果表明，虽然一些“知情”选择策略提高了模型的性能，特别是对于分布外数据，但这只在少数情况下发生，并且性能提升幅度很小。除非取得进一步进展，否则随机样本选择作为增强实践者的默认选择仍然是一个不错的选择。

##### **FlexGen: Flexible Multi-View Generation from Text and Image Inputs**
2410.10745v1 by Xinli Xu, Wenhang Ge, Jiantao Lin, Jiawei Feng, Lie Xu, HanFeng Zhao, Shunsi Zhang, Ying-Cong Chen

In this work, we introduce FlexGen, a flexible framework designed to generate
controllable and consistent multi-view images, conditioned on a single-view
image, or a text prompt, or both. FlexGen tackles the challenges of
controllable multi-view synthesis through additional conditioning on 3D-aware
text annotations. We utilize the strong reasoning capabilities of GPT-4V to
generate 3D-aware text annotations. By analyzing four orthogonal views of an
object arranged as tiled multi-view images, GPT-4V can produce text annotations
that include 3D-aware information with spatial relationship. By integrating the
control signal with proposed adaptive dual-control module, our model can
generate multi-view images that correspond to the specified text. FlexGen
supports multiple controllable capabilities, allowing users to modify text
prompts to generate reasonable and corresponding unseen parts. Additionally,
users can influence attributes such as appearance and material properties,
including metallic and roughness. Extensive experiments demonstrate that our
approach offers enhanced multiple controllability, marking a significant
advancement over existing multi-view diffusion models. This work has
substantial implications for fields requiring rapid and flexible 3D content
creation, including game development, animation, and virtual reality. Project
page: https://xxu068.github.io/flexgen.github.io/.

摘要：在這項工作中，我們介紹了 FlexGen，一個設計用於生成可控且一致的多視圖影像的彈性框架，以單視圖影像、文字提示或兩者為條件。FlexGen 透過對 3D 感知的文字註解進行額外條件設定，來解決可控多視圖合成的挑戰。我們利用 GPT-4V 強大的推理能力來生成 3D 感知的文字註解。透過分析一個物件的四個正交視圖，這些視圖被排列成平鋪的多視圖影像，GPT-4V 可以產生包含 3D 感知資訊和空間關係的文字註解。透過將控制訊號與所提出的自適應雙控制模組整合，我們的模型可以生成對應於指定文字的多視圖影像。FlexGen 支援多種可控功能，使用戶能夠修改文字提示來生成合理且對應的未見部分。此外，使用者可以影響屬性，例如外觀和材質特性，包括金屬和粗糙度。廣泛的實驗證明了我們的方法提供了增強的多重可控性，標誌著對現有多視圖擴散模型的重大進步。這項工作對需要快速且靈活的 3D 內容創作的領域具有重大意義，包括遊戲開發、動畫和虛擬實境。專案頁面：https://xxu068.github.io/flexgen.github.io/。

##### **NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**
2410.10743v1 by Yanbiao Ji, Chang Liu, Xin Chen, Yue Ding, Dan Luo, Mei Li, Wenqing Lin, Hongtao Lu

Graphs are a fundamental data structure for representing relationships in
real-world scenarios. With the success of Large Language Models (LLMs) across
various natural language processing (NLP) tasks, there has been growing
interest in integrating LLMs for graph learning. However, applying LLMs to
graph-related tasks poses significant challenges, as these models are not
inherently designed to capture the complex structural information present in
graphs. Existing approaches address this challenge through two strategies: the
chain of tasks approach, which uses Graph Neural Networks (GNNs) to encode the
graph structure so that LLMs are relieved from understanding spatial positions;
and Graph-to-Text Conversion, which translates graph structures into semantic
text representations that LLMs can process. Despite their progress, these
methods often struggle to fully preserve the topological information of graphs
or require extensive computational resources, limiting their practical
applicability.
  In this work, we introduce Node Tokenizer for Large Language Models (NT-LLM),
a novel framework that efficiently encodes graph structures by selecting key
nodes as anchors and representing each node based on its relative distance to
these anchors. This position-anchored encoding effectively captures the graph
topology, enabling enhanced reasoning capabilities in LLMs over graph data.
Additionally, we implement a task-specific tuning procedure to further improve
structural understanding within LLMs. Through extensive empirical evaluations,
NT-LLM demonstrates significant performance improvements across a variety of
graph-related tasks.

摘要：圖形是一種基本資料結構，用於表示現實世界場景中的關係。隨著大型語言模型 (LLM) 在各種自然語言處理 (NLP) 任務中的成功，整合 LLM 以進行圖形學習的興趣日益濃厚。然而，將 LLM 應用於與圖形相關的任務會帶來重大挑戰，因為這些模型並非天生就設計成用來擷取圖形中存在的複雜結構資訊。現有方法透過兩種策略來應對此挑戰：任務鏈方法，它使用圖形神經網路 (GNN) 編碼圖形結構，以便減輕 LLM 理解空間位置的負擔；以及圖形轉文字轉換，它將圖形結構轉換成 LLM 可以處理的語意文字表示。儘管這些方法取得了進展，但它們通常難以完全保留圖形的拓撲資訊，或者需要大量的運算資源，限制了它們的實際應用性。
在本文中，我們介紹了大型語言模型節點標記器 (NT-LLM)，這是一個新穎的框架，它透過選擇關鍵節點作為錨點，並根據每個節點與這些錨點的相對距離來表示每個節點，從而有效地編碼圖形結構。這種基於位置的錨點編碼有效地擷取了圖形拓撲，讓 LLM 能夠對圖形資料進行增強的推理。此外，我們實作了一個特定於任務的調整程序，以進一步改善 LLM 中的結構理解。透過廣泛的實證評估，NT-LLM 在各種與圖形相關的任務中都展示出顯著的效能提升。

##### **SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing**
2410.10741v1 by Pengrui Quan, Xiaomin Ouyang, Jeya Vikranth Jeyakumar, Ziqi Wang, Yang Xing, Mani Srivastava

Effective processing, interpretation, and management of sensor data have
emerged as a critical component of cyber-physical systems. Traditionally,
processing sensor data requires profound theoretical knowledge and proficiency
in signal-processing tools. However, recent works show that Large Language
Models (LLMs) have promising capabilities in processing sensory data,
suggesting their potential as copilots for developing sensing systems.
  To explore this potential, we construct a comprehensive benchmark,
SensorBench, to establish a quantifiable objective. The benchmark incorporates
diverse real-world sensor datasets for various tasks. The results show that
while LLMs exhibit considerable proficiency in simpler tasks, they face
inherent challenges in processing compositional tasks with parameter selections
compared to engineering experts. Additionally, we investigate four prompting
strategies for sensor processing and show that self-verification can outperform
all other baselines in 48% of tasks. Our study provides a comprehensive
benchmark and prompting analysis for future developments, paving the way toward
an LLM-based sensor processing copilot.

摘要：有效處理、詮釋和管理感測器資料已成為網路物理系統的關鍵組成部分。傳統上，處理感測器資料需要深厚的理論知識和訊號處理工具的熟練度。然而，最近的研究顯示，大型語言模型 (LLM) 在處理感測器資料方面具有良好的能力，表明它們有潛力成為開發感測系統的副駕駛。
為了探索這種潛力，我們建構了一個全面的基準測試 SensorBench，以建立一個可量化的目標。此基準測試整合了各種任務的不同真實世界感測器資料集。結果顯示，儘管 LLM 在較簡單的任務中展現出相當好的能力，但在處理組合任務時，它們在參數選擇方面面臨固有的挑戰，這與工程專家相比。此外，我們研究了四種感測器處理的提示策略，並顯示出自我驗證在 48% 的任務中優於所有其他基準。我們的研究為未來的發展提供了一個全面的基準測試和提示分析，為基於 LLM 的感測器處理副駕駛鋪平了道路。

##### **Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs**
2410.10739v1 by Ishan Jindal, Chandana Badrinath, Pranjal Bharti, Lakkidi Vinay, Sachin Dev Sharma

Large Language Models (LLMs) for public use require continuous pre-training
to remain up-to-date with the latest data. The models also need to be
fine-tuned with specific instructions to maintain their ability to follow
instructions accurately. Typically, LLMs are released in two versions: the Base
LLM, pre-trained on diverse data, and the instruction-refined LLM, additionally
trained with specific instructions for better instruction following. The
question arises as to which model should undergo continuous pre-training to
maintain its instruction-following abilities while also staying current with
the latest data. In this study, we delve into the intricate relationship
between continuous pre-training and instruction fine-tuning of the LLMs and
investigate the impact of continuous pre-training on the instruction following
abilities of both the base and its instruction finetuned model. Further, the
instruction fine-tuning process is computationally intense and requires a
substantial number of hand-annotated examples for the model to learn
effectively. This study aims to find the most compute-efficient strategy to
gain up-to-date knowledge and instruction-following capabilities without
requiring any instruction data and fine-tuning. We empirically prove our
findings on the LLaMa 3, 3.1 and Qwen 2, 2.5 family of base and instruction
models, providing a comprehensive exploration of our hypotheses across varying
sizes of pre-training data corpus and different LLMs settings.

摘要：大型語言模型 (LLM) 供公眾使用需要持續預訓練，才能與最新資料保持同步。這些模型也需要針對特定指示進行微調，以維持其準確遵循指示的能力。LLM 通常分為兩個版本發布：預先針對各種資料進行訓練的基本 LLM，以及針對特定指示進行額外訓練的指示精煉 LLM，以更佳地遵循指示。問題在於哪個模型應該進行持續預訓練，以維持其遵循指示的能力，同時也能與最新資料保持同步。在本研究中，我們深入探討 LLM 的持續預訓練與指示微調之間的複雜關係，並探討持續預訓練對基本模型及其指示微調模型遵循指示能力的影響。此外，指示微調過程在運算上很密集，需要大量人工標註範例，才能讓模型有效學習。本研究旨在找出最具運算效率的策略，以獲得最新的知識和遵循指示的能力，而不需要任何指示資料和微調。我們根據 LLaMa 3、3.1 和 Qwen 2、2.5 系列的基本模型和指示模型，實證證明我們的研究結果，全面探討我們的假設，涵蓋不同規模的預訓練資料語料庫和不同的 LLM 設定。

##### **DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model**
2410.10738v1 by Yuqi Wang, Ke Cheng, Jiawei He, Qitai Wang, Hengchen Dai, Yuntao Chen, Fei Xia, Zhaoxiang Zhang

Driving world models have gained increasing attention due to their ability to
model complex physical dynamics. However, their superb modeling capability is
yet to be fully unleashed due to the limited video diversity in current driving
datasets. We introduce DrivingDojo, the first dataset tailor-made for training
interactive world models with complex driving dynamics. Our dataset features
video clips with a complete set of driving maneuvers, diverse multi-agent
interplay, and rich open-world driving knowledge, laying a stepping stone for
future world model development. We further define an action instruction
following (AIF) benchmark for world models and demonstrate the superiority of
the proposed dataset for generating action-controlled future predictions.

摘要：駕駛世界模型因其建模複雜物理動態的能力而備受關注。然而，由於當前駕駛數據集中的影片多樣性有限，其卓越的建模能力尚未得到充分發揮。我們介紹了 DrivingDojo，這是第一個專門用於訓練具有複雜駕駛動態的互動世界模型的數據集。我們的數據集包含一組完整的駕駛操作影片片段、多樣化的多主體交互作用以及豐富的開放世界駕駛知識，為未來的世界模型開發奠定了基石。我們進一步定義了世界模型的動作指令遵循 (AIF) 基準，並展示了所提出的數據集在生成動作控制的未來預測方面的優越性。

##### **Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning**
2410.10735v1 by Kuofeng Gao, Huanqia Cai, Qingyao Shuai, Dihong Gong, Zhifeng Li

Accurate mathematical reasoning with Large Language Models (LLMs) is crucial
in revolutionizing domains that heavily rely on such reasoning. However, LLMs
often encounter difficulties in certain aspects of mathematical reasoning,
leading to flawed reasoning and erroneous results. To mitigate these issues, we
introduce a novel mechanism, the Chain of Self-Correction (CoSC), specifically
designed to embed self-correction as an inherent ability in LLMs, enabling them
to validate and rectify their own results. The CoSC mechanism operates through
a sequence of self-correction stages. In each stage, the LLMs generate a
program to address a given problem, execute this program using program-based
tools to obtain an output, subsequently verify this output. Based on the
verification, the LLMs either proceed to the next correction stage or finalize
the answer. This iterative self-correction process allows the LLMs to refine
their reasoning steps and improve the accuracy of their mathematical reasoning.
To enable the CoSC mechanism at a low cost, we employ a two-phase finetuning
approach. In the first phase, the LLMs are trained with a relatively small
volume of seeding data generated from GPT-4, establishing an initial CoSC
capability. In the second phase, the CoSC capability is further enhanced by
training with a larger volume of self-generated data using the trained model in
the first phase, without relying on the paid GPT-4. Our comprehensive
experiments demonstrate that CoSC significantly improves performance on
traditional mathematical datasets among existing open-source LLMs. Notably, our
CoSC-Code-34B model achieved a 53.5% score on MATH, the most challenging
mathematical reasoning dataset in the public domain, surpassing the performance
of well-established models such as ChatGPT, GPT-4, and even multi-modal LLMs
like GPT-4V, Gemini-1.0 Pro, and Gemini-1.0 Ultra.

摘要：大型語言模型 (LLM) 的準確數學推理對於徹底革新高度依賴此類推理的領域至關重要。然而，LLM 在數學推理的某些方面常常會遇到困難，導致推理有缺陷且結果錯誤。為了減輕這些問題，我們引入了一種新機制，即自我修正鏈 (CoSC)，專門設計為將自我修正作為 LLM 的固有能力，使它們能夠驗證和糾正自己的結果。CoSC 機制通過一系列自我修正階段運行。在每個階段，LLM 會生成一個程式來解決給定的問題，使用基於程式的工具執行此程式以獲得輸出，隨後驗證此輸出。根據驗證，LLM 要么繼續進行下一個修正階段，要么最終確定答案。這個反覆的自我修正過程使 LLM 能夠優化其推理步驟並提高其數學推理的準確性。為了以低成本啟用 CoSC 機制，我們採用了兩階段微調方法。在第一階段，LLM 使用從 GPT-4 生成的相對較小量的種子資料進行訓練，建立了初始的 CoSC 能力。在第二階段，CoSC 能力通過使用第一階段中訓練的模型訓練大量自生資料進一步增強，而無需依賴付費的 GPT-4。我們的綜合實驗表明，CoSC 在現有的開源 LLM 中顯著提高了傳統數學資料集的效能。值得注意的是，我們的 CoSC-Code-34B 模型在 MATH 上取得了 53.5% 的分數，這是公有領域中最具挑戰性的數學推理資料集，超越了 ChatGPT、GPT-4 甚至多模態 LLM 等成熟模型的效能，例如 GPT-4V、Gemini-1.0 Pro 和 Gemini-1.0 Ultra。

##### **Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models**
2410.10733v1 by Junyu Chen, Han Cai, Junsong Chen, Enze Xie, Shang Yang, Haotian Tang, Muyang Li, Yao Lu, Song Han

We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder
models for accelerating high-resolution diffusion models. Existing autoencoder
models have demonstrated impressive results at a moderate spatial compression
ratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for
high spatial compression ratios (e.g., 64x). We address this challenge by
introducing two key techniques: (1) Residual Autoencoding, where we design our
models to learn residuals based on the space-to-channel transformed features to
alleviate the optimization difficulty of high spatial-compression autoencoders;
(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases
training strategy for mitigating the generalization penalty of high
spatial-compression autoencoders. With these designs, we improve the
autoencoder's spatial compression ratio up to 128 while maintaining the
reconstruction quality. Applying our DC-AE to latent diffusion models, we
achieve significant speedup without accuracy drop. For example, on ImageNet
512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup
on H100 GPU for UViT-H while achieving a better FID, compared with the widely
used SD-VAE-f8 autoencoder. Our code is available at
https://github.com/mit-han-lab/efficientvit.

摘要：<paragraph>我們提出深度壓縮自編碼器 (DC-AE)，一種用於加速高解析度擴散模型的自編碼器模型的新系列。現有的自編碼器模型在中等空間壓縮比 (例如 8 倍) 下已展現令人印象深刻的結果，但無法維持高空間壓縮比 (例如 64 倍) 的滿意重建準確度。我們透過引入兩項關鍵技術來解決此挑戰：(1) 殘差自編碼，我們設計我們的模型以學習基於空間到通道轉換特徵的殘差，以減輕高空間壓縮自編碼器的最佳化難度；(2) 解耦的高解析度適應，一種用於減輕高空間壓縮自編碼器的泛化懲罰的有效解耦三階段訓練策略。透過這些設計，我們將自編碼器的空間壓縮比提升至 128，同時維持重建品質。將我們的 DC-AE 套用於潛在擴散模型，我們在不降低準確度的情況下實現顯著的加速。例如，在 ImageNet 512x512 上，我們的 DC-AE 在 H100 GPU 上為 UViT-H 提供 19.1 倍的推論加速和 17.9 倍的訓練加速，同時實現比廣泛使用的 SD-VAE-f8 自編碼器更好的 FID。我們的程式碼可於 https://github.com/mit-han-lab/efficientvit 取得。</paragraph>

##### **Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection**
2410.10728v1 by Giorgos Iacovides, Wuyang Zhou, Danilo Mandic

We propose a novel framework that leverages large language models (LLMs) to
guide the rank selection in tensor network models for higher-order data
analysis. By utilising the intrinsic reasoning capabilities and domain
knowledge of LLMs, our approach offers enhanced interpretability of the rank
choices and can effectively optimise the objective function. This framework
enables users without specialised domain expertise to utilise tensor network
decompositions and understand the underlying rationale within the rank
selection process. Experimental results validate our method on financial
higher-order datasets, demonstrating interpretable reasoning, strong
generalisation to unseen test data, and its potential for self-enhancement over
successive iterations. This work is placed at the intersection of large
language models and higher-order data analysis.

摘要：我們提出一個新穎的架構，利用大型語言模型 (LLM) 來引導張量網路模型中的秩選擇，以進行高階資料分析。透過利用 LLM 的內在推理能力和領域知識，我們的做法提供了增強的秩選擇可解釋性，並能有效地最佳化目標函數。這個架構讓沒有專業領域知識的使用者能夠使用張量網路分解，並在秩選擇過程中了解其基本原理。實驗結果驗證了我們在金融高階資料集上的方法，展示了可解釋的推理、對未見測試資料的強泛化能力，以及它在連續迭代中自我增強的可能性。這項工作位於大型語言模型和高階資料分析的交叉點上。

##### **Large Language Models Are Active Critics in NLG Evaluation**
2410.10724v1 by Shuying Xu, Junjie Hu, Ming Jiang

The conventional paradigm of using large language models (LLMs) for
evaluating natural language generation (NLG) systems typically relies on two
key inputs: (1) a clear definition of the NLG task to be evaluated and (2) a
list of pre-defined evaluation criteria. This process treats LLMs as ''passive
critics,'' strictly following human-defined criteria for evaluation. However,
as new NLG tasks emerge, the criteria for assessing text quality can vary
greatly. Consequently, these rigid evaluation methods struggle to adapt to
diverse NLG tasks without extensive prompt engineering customized for each
specific task. To address this limitation, we introduce Active-Critic, a novel
LLM-based NLG evaluation protocol that enables LLMs to function as ''active
critics.'' Specifically, our protocol comprises two key stages. In the first
stage, the LLM is instructed to infer the target NLG task and establish
relevant evaluation criteria from the data. Building on this self-inferred
information, the second stage dynamically optimizes the prompt to guide the LLM
toward more human-aligned scoring decisions, while also generating detailed
explanations to justify its evaluations. Experiments across four NLG evaluation
tasks show that our approach achieves stronger alignment with human judgments
than state-of-the-art evaluation methods. Our comprehensive analysis further
highlights the effectiveness and explainability of Active-Critic with only a
small amount of labeled data. We will share our code and data on GitHub.

摘要：傳統上使用大型語言模型 (LLM) 來評估自然語言生成 (NLG) 系統的範例通常依賴於兩個關鍵輸入：(1) 要評估的 NLG 任務的明確定義，以及 (2) 預先定義的評估標準清單。此程序將 LLM 視為「被動批評者」，嚴格遵循人類定義的評估標準。然而，隨著新的 NLG 任務出現，評估文字品質的標準可能會大不相同。因此，這些僵化的評估方法難以適應不同的 NLG 任務，而不會針對每個特定任務進行廣泛的提示工程自訂。為了解決這個限制，我們引入了 Active-Critic，一種新穎的基於 LLM 的 NLG 評估協定，使 LLM 能夠作為「主動批評者」運作。具體來說，我們的協定包含兩個關鍵階段。在第一階段，LLM 被指示從資料中推論目標 NLG 任務並建立相關評估標準。基於這個自我推論的資訊，第二階段動態最佳化提示，以引導 LLM 朝向更符合人類的評分決策，同時也產生詳細的說明來證明其評估。跨越四個 NLG 評估任務的實驗顯示，我們的方法比最先進的評估方法與人類判斷更為一致。我們的綜合分析進一步強調了 Active-Critic 的有效性和可解釋性，而標記資料量僅少。我們將在 GitHub 上分享我們的程式碼和資料。

##### **SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators**
2410.10714v1 by Rasoul Shafipour, David Harrison, Maxwell Horton, Jeffrey Marker, Houman Bedayat, Sachin Mehta, Mohammad Rastegari, Mahyar Najibi, Saman Naderiparizi

Large Language Models (LLMs) have transformed natural language processing,
but face significant challenges in widespread deployment due to their high
runtime cost. In this paper, we introduce SeedLM, a novel post-training
compression method that uses seeds of pseudo-random generators to encode and
compress model weights. Specifically, for each block of weights, we find a seed
that is fed into a Linear Feedback Shift Register (LFSR) during inference to
efficiently generate a random matrix. This matrix is then linearly combined
with compressed coefficients to reconstruct the weight block. SeedLM reduces
memory access and leverages idle compute cycles during inference, effectively
speeding up memory-bound tasks by trading compute for fewer memory accesses.
Unlike state-of-the-art compression methods that rely on calibration data, our
approach is data-free and generalizes well across diverse tasks. Our
experiments with Llama 3 70B, which is particularly challenging to compress,
show that SeedLM achieves significantly better zero-shot accuracy retention at
4- and 3-bit than state-of-the-art techniques, while maintaining performance
comparable to FP16 baselines. Additionally, FPGA-based tests demonstrate that
4-bit SeedLM, as model size increases to 70B, approaches a 4x speed-up over an
FP16 Llama 2/3 baseline.

摘要：大型語言模型 (LLM) 已轉變自然語言處理，但由於其高執行時間成本，在廣泛部署中面臨重大挑戰。在本文中，我們介紹了 SeedLM，這是一種新穎的訓練後壓縮方法，它使用偽隨機生成器的種子對模型權重進行編碼和壓縮。具體來說，對於每個權重塊，我們找到一個種子，在推理期間將其輸入線性反饋移位暫存器 (LFSR) 中，以有效生成隨機矩陣。然後將此矩陣與壓縮係數線性組合以重建權重塊。SeedLM 減少了記憶體存取，並在推理期間利用閒置的運算週期，有效地通過用運算交換更少的記憶體存取來加速受記憶體限制的任務。與依賴校準資料的最新壓縮方法不同，我們的做法是無資料的，並且在各種任務中具有良好的泛化性。我們使用特別難以壓縮的 Llama 3 70B 進行的實驗表明，SeedLM 在 4 位和 3 位時實現了顯著更好的零次學習準確率保留，同時保持與 FP16 基準相當的效能。此外，基於 FPGA 的測試表明，隨著模型大小增加到 70B，4 位元 SeedLM 接近 FP16 Llama 2/3 基準的 4 倍加速。

##### **Early Diagnoses of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models**
2410.10701v1 by Alaa Awad, Mohamed Hegazy, Salah A. Aly

Thousands of individuals succumb annually to leukemia alone. This study
explores the application of image processing and deep learning techniques for
detecting Acute Lymphoblastic Leukemia (ALL), a severe form of blood cancer
responsible for numerous annual fatalities. As artificial intelligence
technologies advance, the research investigates the reliability of these
methods in real-world scenarios. The study focuses on recent developments in
ALL detection, particularly using the latest YOLO series models, to distinguish
between malignant and benign white blood cells and to identify different stages
of ALL, including early stages. Additionally, the models are capable of
detecting hematogones, which are often misclassified as ALL. By utilizing
advanced deep learning models like YOLOv8 and YOLOv11, the study achieves high
accuracy rates reaching 98.8%, demonstrating the effectiveness of these
algorithms across multiple datasets and various real-world situations.

摘要：每年有數千人僅因白血病而死亡。本研究探討影像處理和深度學習技術在偵測急性淋巴性白血病 (ALL) 中的應用，ALL 是一種嚴重的血癌，每年造成許多人死亡。隨著人工智慧技術的進步，本研究探討這些方法在實際場景中的可靠性。本研究重點在於 ALL 偵測的最新進展，特別是使用最新的 YOLO 系列模型，以區分惡性和良性白血球，並識別 ALL 的不同階段，包括早期階段。此外，這些模型還能偵測常被誤分類為 ALL 的造血母細胞。本研究利用 YOLOv8 和 YOLOv11 等先進的深度學習模型，達成高達 98.8% 的高準確率，證明這些演算法在多個資料集和各種實際情況中都非常有效。

##### **Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues**
2410.10700v1 by Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao

This study exposes the safety vulnerabilities of Large Language Models (LLMs)
in multi-turn interactions, where malicious users can obscure harmful intents
across several queries. We introduce ActorAttack, a novel multi-turn attack
method inspired by actor-network theory, which models a network of semantically
linked actors as attack clues to generate diverse and effective attack paths
toward harmful targets. ActorAttack addresses two main challenges in multi-turn
attacks: (1) concealing harmful intents by creating an innocuous conversation
topic about the actor, and (2) uncovering diverse attack paths towards the same
harmful target by leveraging LLMs' knowledge to specify the correlated actors
as various attack clues. In this way, ActorAttack outperforms existing
single-turn and multi-turn attack methods across advanced aligned LLMs, even
for GPT-o1. We will publish a dataset called SafeMTData, which includes
multi-turn adversarial prompts and safety alignment data, generated by
ActorAttack. We demonstrate that models safety-tuned using our safety dataset
are more robust to multi-turn attacks. Code is available at
https://github.com/renqibing/ActorAttack.

摘要：本研究揭露了大型語言模型 (LLM) 在多輪互動中的安全漏洞，其中惡意使用者可以在多個查詢中隱藏有害意圖。我們引入了 ActorAttack，這是一種新穎的多輪攻擊方法，靈感來自於行動者網路理論，它將語義連結行動者的網路建模為攻擊線索，以產生多樣化且有效的攻擊路徑，進而鎖定有害目標。ActorAttack 應對了多輪攻擊中的兩個主要挑戰：(1) 透過創造關於行動者的無害對話主題來隱藏有害意圖，以及 (2) 透過利用 LLM 的知識將相關行動者指定為各種攻擊線索，進而揭露通往相同有害目標的多樣化攻擊路徑。透過這種方式，ActorAttack 在先進的對齊 LLM 中優於現有的單輪和多輪攻擊方法，即使是對於 GPT-o1 也是如此。我們將發布一個名為 SafeMTData 的資料集，其中包含由 ActorAttack 生成的多輪對抗提示和安全對齊資料。我們證明使用我們的安全資料集進行安全調整的模型對於多輪攻擊更具魯棒性。程式碼可在 https://github.com/renqibing/ActorAttack 取得。

##### **Building a Multivariate Time Series Benchmarking Datasets Inspired by Natural Language Processing (NLP)**
2410.10687v1 by Mohammad Asif Ibna Mustafa, Ferdinand Heinrich

Time series analysis has become increasingly important in various domains,
and developing effective models relies heavily on high-quality benchmark
datasets. Inspired by the success of Natural Language Processing (NLP)
benchmark datasets in advancing pre-trained models, we propose a new approach
to create a comprehensive benchmark dataset for time series analysis. This
paper explores the methodologies used in NLP benchmark dataset creation and
adapts them to the unique challenges of time series data. We discuss the
process of curating diverse, representative, and challenging time series
datasets, highlighting the importance of domain relevance and data complexity.
Additionally, we investigate multi-task learning strategies that leverage the
benchmark dataset to enhance the performance of time series models. This
research contributes to the broader goal of advancing the state-of-the-art in
time series modeling by adopting successful strategies from the NLP domain.

摘要：時序分析在各個領域中越來越重要，而開發有效的模型極度仰賴高品質的基準資料集。受到自然語言處理 (NLP) 基準資料集在促進預先訓練模型方面的成功啟發，我們提出一個新的方法來建立一個全面的時序分析基準資料集。本文探討了 NLP 基準資料集建立中所使用的各種方法，並將其調整到時序資料的獨特挑戰。我們討論了整理多樣化、具代表性且具挑戰性的時序資料集的過程，強調了領域相關性和資料複雜性的重要性。此外，我們研究了多任務學習策略，該策略利用基準資料集來增強時序模型的效能。本研究有助於促進時序建模的最新進展，方法是採用 NLP 領域的成功策略。

##### **Large Language Model Evaluation via Matrix Nuclear-Norm**
2410.10672v1 by Yahan Li, Tingyu Xia, Yi Chang, Yuan Wu

As large language models (LLMs) continue to evolve, efficient evaluation
metrics are vital for assessing their ability to compress information and
reduce redundancy. While traditional metrics like Matrix Entropy offer valuable
insights, they are computationally intensive for large-scale models due to
their \( O(n^3) \) time complexity with Singular Value Decomposition (SVD). To
mitigate this issue, we introduce the Matrix Nuclear-Norm, which not only
serves as a metric to quantify the data compression proficiency of LLM but also
provides a convex approximation of matrix rank to capture both predictive
discriminability and diversity. By employing the \( L_{1,2}\text{-norm} \) to
further approximate the nuclear norm, we can effectively assess the model's
information compression capabilities. This approach reduces the time complexity
to \( O(n^2) \) and eliminates the need for SVD computation. Consequently, the
Matrix Nuclear-Norm achieves speeds 8 to 24 times faster than Matrix Entropy
for the CEREBRAS-GPT model as sizes increase from 111M to 6.7B. This
performance gap becomes more pronounced with larger models, as validated in
tests with other models like Pythia. Additionally, evaluations on benchmarks
and model responses confirm that our proposed Matrix Nuclear-Norm is a
reliable, scalable, and efficient tool for assessing LLMs' performance,
striking a balance between accuracy and computational efficiency. The code is
available at https://github.com/MLGroupJLU/MatrixNuclearNorm.

摘要：隨著大型語言模型 (LLM) 持續演進，有效率的評估指標對於評估它們壓縮資訊與降低冗餘的能力至關重要。雖然像是矩陣熵這類的傳統指標提供了有價值的見解，但由於它們與奇異值分解 (SVD) 的時間複雜度為 \( O(n^3) \)，對於大型模型而言在計算上相當密集。為了減輕這個問題，我們引入了矩陣核範數，它不僅可用作量化 LLM 資料壓縮能力的指標，也提供了矩陣秩的凸近似，以捕捉預測判別性和多樣性。藉由採用 \( L_{1,2}\text{-norm} \) 來進一步近似核範數，我們可以有效地評估模型的資訊壓縮能力。這種方法將時間複雜度降低到 \( O(n^2) \)，並消除了對 SVD 計算的需求。因此，隨著模型大小從 111M 增加到 6.7B，矩陣核範數的速度比矩陣熵快了 8 到 24 倍。在使用其他模型（例如 Pythia）進行測試時，這種效能差距在較大的模型中變得更加明顯。此外，針對基準和模型回應的評估證實，我們提出的矩陣核範數是一種可靠、可擴充且有效率的工具，用於評估 LLM 的效能，在準確性和計算效率之間取得平衡。程式碼可在 https://github.com/MLGroupJLU/MatrixNuclearNorm 取得。

##### **Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers**
2410.10665v1 by Aivin V. Solatorio, Gabriel Stefanini Vicente, Holly Krambeck, Olivier Dupriez

Artificial Intelligence (AI), particularly large language models (LLMs),
holds the potential to bridge language and information gaps, which can benefit
the economies of developing nations. However, our analysis of FLORES-200,
FLORES+, Ethnologue, and World Development Indicators data reveals that these
benefits largely favor English speakers. Speakers of languages in low-income
and lower-middle-income countries face higher costs when using OpenAI's GPT
models via APIs because of how the system processes the input -- tokenization.
Around 1.5 billion people, speaking languages primarily from
lower-middle-income countries, could incur costs that are 4 to 6 times higher
than those faced by English speakers. Disparities in LLM performance are
significant, and tokenization in models priced per token amplifies inequalities
in access, cost, and utility. Moreover, using the quality of translation tasks
as a proxy measure, we show that LLMs perform poorly in low-resource languages,
presenting a ``double jeopardy" of higher costs and poor performance for these
users. We also discuss the direct impact of fragmentation in tokenizing
low-resource languages on climate. This underscores the need for fairer
algorithm development to benefit all linguistic groups.

摘要：人工智慧（AI），尤其是大型語言模型（LLM），
具有縮小語言和資訊差距的潛力，這可以讓開發中國家的經濟受益。然而，我們對 FLORES-200、FLORES+、民族語和世界發展指標資料的分析顯示，這些好處主要有利於英語使用者。由於系統處理輸入的方式——分詞，因此低收入和中等偏下收入國家的語言使用者在透過 API 使用 OpenAI 的 GPT 模型時會面臨更高的成本。約有 15 億人主要使用中等偏下收入國家的語言，他們可能產生的成本會比英語使用者高出 4 到 6 倍。LLM 效能的差異很大，而按代幣定價的模型中的分詞會擴大在存取、成本和效用方面的差距。此外，我們以翻譯任務的品質作為替代衡量標準，顯示 LLM 在低資源語言中的表現不佳，對這些使用者來說，這會造成成本較高和效能不佳的「雙重危機」。我們也討論了分詞低資源語言的破碎化對氣候的直接影響。這強調了公平演算法開發的必要性，以讓所有語言群體受益。

##### **Generative AI and Its Impact on Personalized Intelligent Tutoring Systems**
2410.10650v1 by Subhankar Maity, Aniket Deroy

Generative Artificial Intelligence (AI) is revolutionizing educational
technology by enabling highly personalized and adaptive learning environments
within Intelligent Tutoring Systems (ITS). This report delves into the
integration of Generative AI, particularly large language models (LLMs) like
GPT-4, into ITS to enhance personalized education through dynamic content
generation, real-time feedback, and adaptive learning pathways. We explore key
applications such as automated question generation, customized feedback
mechanisms, and interactive dialogue systems that respond to individual learner
needs. The report also addresses significant challenges, including ensuring
pedagogical accuracy, mitigating inherent biases in AI models, and maintaining
learner engagement. Future directions highlight the potential advancements in
multimodal AI integration, emotional intelligence in tutoring systems, and the
ethical implications of AI-driven education. By synthesizing current research
and practical implementations, this report underscores the transformative
potential of Generative AI in creating more effective, equitable, and engaging
educational experiences.

摘要：生成式人工智慧（AI）透過在智慧型教學系統（ITS）中建構高度個人化且適應性的學習環境，革新教育技術。此報告深入探討生成式 AI，特別是大型語言模型（LLM），例如 GPT-4，整合至 ITS 中，藉由動態內容生成、即時回饋和適應性學習路徑，強化個人化教育。我們探索了關鍵應用，例如自動化問題生成、自訂回饋機制，以及回應個別學習者需求的互動對話系統。報告中也探討了重大挑戰，包括確保教學準確性、減輕 AI 模型中固有的偏見，以及維持學習者的參與度。未來發展重點突顯了多模態 AI 整合、教學系統中的情緒智慧，以及 AI 驅動教育的倫理意涵。透過綜合現有研究和實務實施，此報告強調了生成式 AI 在創造更有效、更公平且更具吸引力的教育體驗方面的轉化潛力。

##### **DR-MPC: Deep Residual Model Predictive Control for Real-world Social Navigation**
2410.10646v1 by James R. Han, Hugues Thomas, Jian Zhang, Nicholas Rhinehart, Timothy D. Barfoot

How can a robot safely navigate around people exhibiting complex motion
patterns? Reinforcement Learning (RL) or Deep RL (DRL) in simulation holds some
promise, although much prior work relies on simulators that fail to precisely
capture the nuances of real human motion. To address this gap, we propose Deep
Residual Model Predictive Control (DR-MPC), a method to enable robots to
quickly and safely perform DRL from real-world crowd navigation data. By
blending MPC with model-free DRL, DR-MPC overcomes the traditional DRL
challenges of large data requirements and unsafe initial behavior. DR-MPC is
initialized with MPC-based path tracking, and gradually learns to interact more
effectively with humans. To further accelerate learning, a safety component
estimates when the robot encounters out-of-distribution states and guides it
away from likely collisions. In simulation, we show that DR-MPC substantially
outperforms prior work, including traditional DRL and residual DRL models.
Real-world experiments show our approach successfully enables a robot to
navigate a variety of crowded situations with few errors using less than 4
hours of training data.

摘要：機器人如何安全地穿梭在表現出複雜動作模式的人群中？儘管許多先前的工作都依賴於無法精確捕捉人類真實動作細微差別的模擬器，但模擬中的強化學習 (RL) 或深度強化學習 (DRL) 仍具有一定的前景。為了解決這個差距，我們提出了深度殘差模型預測控制 (DR-MPC)，這是一種方法，讓機器人能夠根據真實世界的群眾導航數據快速且安全地執行 DRL。透過將 MPC 與無模型 DRL 相結合，DR-MPC 克服了傳統 DRL 在大量數據需求和不安全的初始行為方面的挑戰。DR-MPC 使用基於 MPC 的路徑追蹤進行初始化，並逐漸學習與人類進行更有效的互動。為了進一步加速學習，安全組件會估計機器人何時遇到分布外狀態，並指導它遠離可能的碰撞。在模擬中，我們展示了 DR-MPC 明顯優於先前的研究，包括傳統 DRL 和殘差 DRL 模型。真實世界的實驗表明，我們的做法成功地讓機器人在不到 4 小時的訓練數據下，以很少的錯誤在各種擁擠的情況下導航。

##### **Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection**
2410.10636v1 by Adyasha Maharana, Jaehong Yoon, Tianlong Chen, Mohit Bansal

Visual instruction datasets from various distributors are released at
different times and often contain a significant number of semantically
redundant text-image pairs, depending on their task compositions (i.e., skills)
or reference sources. This redundancy greatly limits the efficient deployment
of lifelong adaptable multimodal large language models, hindering their ability
to refine existing skills and acquire new competencies over time. To address
this, we reframe the problem of Lifelong Instruction Tuning (LiIT) via data
selection, where the model automatically selects beneficial samples to learn
from earlier and new datasets based on the current state of acquired knowledge
in the model. Based on empirical analyses that show that selecting the best
data subset using a static importance measure is often ineffective for
multi-task datasets with evolving distributions, we propose Adapt-$\infty$, a
new multi-way and adaptive data selection approach that dynamically balances
sample efficiency and effectiveness during LiIT. We construct pseudo-skill
clusters by grouping gradient-based sample vectors. Next, we select the
best-performing data selector for each skill cluster from a pool of selector
experts, including our newly proposed scoring function, Image Grounding score.
This data selector samples a subset of the most important samples from each
skill cluster for training. To prevent the continuous increase in the size of
the dataset pool during LiIT, which would result in excessive computation, we
further introduce a cluster-wise permanent data pruning strategy to remove the
most semantically redundant samples from each cluster, keeping computational
requirements manageable. Training with samples selected by Adapt-$\infty$
alleviates catastrophic forgetting, especially for rare tasks, and promotes
forward transfer across the continuum using only a fraction of the original
datasets.

摘要：<paragraph>不同發行商提供的視覺指令資料集發布時間不同，而且通常包含大量語義上重複的文字影像對，具體取決於其任務組合（即技能）或參考來源。這種重複性極大地限制了終身適應多模態大型語言模型的有效部署，阻礙了它們隨著時間推移精進現有技能和習得新能力。為了解決這個問題，我們通過資料選擇重新定義終身指令調整 (LiIT) 的問題，其中模型根據模型中已獲取知識的當前狀態，自動選擇有益的樣本來從較早和新的資料集中學習。根據經驗分析表明，對於分佈不斷變化的多任務資料集，使用靜態重要性測量來選擇最佳資料子集通常無效，我們提出了 Adapt-$\infty$，這是一種新的多路徑和自適應資料選擇方法，可在 LiIT 期間動態平衡樣本效率和有效性。我們通過對基於梯度的樣本向量進行分組來構建偽技能群集。接下來，我們從一個選擇器專家池中為每個技能群集選擇效能最佳的資料選擇器，包括我們新提出的評分函數、影像基礎評分。此資料選擇器從每個技能群集取樣最重要的樣本子集進行訓練。為了防止 LiIT 期間資料集池大小持續增加，這將導致過度運算，我們進一步引入了一個群集式永久資料修剪策略，從每個群集中移除語義上最重複的樣本，保持運算需求在可控範圍內。使用 Adapt-$\infty$ 選擇的樣本進行訓練可以減輕災難性遺忘，特別是對於罕見的任務，並僅使用原始資料集的一小部分來促進在整個連續體中的正向轉移。</paragraph>

##### **Thinking LLMs: General Instruction Following with Thought Generation**
2410.10630v1 by Tianhao Wu, Janice Lan, Weizhe Yuan, Jiantao Jiao, Jason Weston, Sainbayar Sukhbaatar

LLMs are typically trained to answer user questions or follow instructions
similarly to how human experts respond. However, in the standard alignment
framework they lack the basic ability of explicit thinking before answering.
Thinking is important for complex questions that require reasoning and planning
-- but can be applied to any task. We propose a training method for equipping
existing LLMs with such thinking abilities for general instruction following
without use of additional human data. We achieve this by an iterative search
and optimization procedure that explores the space of possible thought
generations, allowing the model to learn how to think without direct
supervision. For each instruction, the thought candidates are scored using a
judge model to evaluate their responses only, and then optimized via preference
optimization. We show that this procedure leads to superior performance on
AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning
categories such as marketing, health and general knowledge, in addition to more
traditional reasoning & problem-solving tasks.

摘要：LLM 通常被训练成回答用户的提问或遵循指令，类似于人类专家如何回应。然而，在标准对齐框架中，它们缺乏在回答之前进行明确思考的基本能力。思考对于需要推理和规划的复杂问题非常重要，但它可以应用于任何任务。我们提出了一种训练方法，为现有的 LLM 提供这种思考能力，以便在没有使用额外人类数据的情况下遵循一般指令。我们通过一种迭代搜索和优化程序来实现这一点，该程序探索可能的思想生成空间，允许模型学习如何在没有直接监督的情况下进行思考。对于每条指令，思想候选者使用评判模型进行评分，仅评估其响应，然后通过偏好优化进行优化。我们表明，此程序在 AlpacaEval 和 Arena-Hard 上表现出卓越的性能，并且除了更传统的推理和解决问题任务之外，还展示了在非推理类别（例如营销、健康和一般知识）上的思考收益。

##### **Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts**
2410.10626v1 by Guorui Zheng, Xidong Wang, Juhao Liang, Nuo Chen, Yuping Zheng, Benyou Wang

Adapting medical Large Language Models to local languages can reduce barriers
to accessing healthcare services, but data scarcity remains a significant
challenge, particularly for low-resource languages. To address this, we first
construct a high-quality medical dataset and conduct analysis to ensure its
quality. In order to leverage the generalization capability of multilingual
LLMs to efficiently scale to more resource-constrained languages, we explore
the internal information flow of LLMs from a multilingual perspective using
Mixture of Experts (MoE) modularity. Technically, we propose a novel MoE
routing method that employs language-specific experts and cross-lingual
routing. Inspired by circuit theory, our routing analysis revealed a Spread Out
in the End information flow mechanism: while earlier layers concentrate
cross-lingual information flow, the later layers exhibit language-specific
divergence. This insight directly led to the development of the Post-MoE
architecture, which applies sparse routing only in the later layers while
maintaining dense others. Experimental results demonstrate that this approach
enhances the generalization of multilingual models to other languages while
preserving interpretability. Finally, to efficiently scale the model to 50
languages, we introduce the concept of language family experts, drawing on
linguistic priors, which enables scaling the number of languages without adding
additional parameters.

摘要：<paragraph>針對當地語言調整大型醫療語言模型能減少取得醫療保健服務的障礙，但資料稀少的問題仍然是一項重大挑戰，特別是對於低資源語言來說。為了解決這個問題，我們首先建構一個高品質的醫療資料集，並進行分析以確保其品質。為了善用多語言 LLM 的概化能力，以有效擴展到更多資源受限的語言，我們從多語言的角度探索 LLM 的內部資訊流，並使用專家混合 (MoE) 模組化。在技術上，我們提出了一種創新的 MoE 路由方法，採用特定語言的專家和跨語言路由。受到電路理論的啟發，我們的路由分析揭示了一個在最後分散的資訊流機制：早期層集中跨語言資訊流，而後續層則展現出特定語言的分歧。這個見解直接導致後 MoE 架構的發展，它僅在後續層套用稀疏路由，同時維持其他層的稠密。實驗結果證明，這種方法增強了多語言模型對其他語言的概化能力，同時保留了解釋能力。最後，為了有效地將模型擴展到 50 種語言，我們引入了語言家族專家的概念，利用語言先驗，這使得我們可以在不增加額外參數的情況下擴展語言數量。</paragraph>

##### **SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition**
2410.10624v1 by Zechen Li, Shohreh Deldari, Linyao Chen, Hao Xue, Flora D. Salim

In this work, we bridge the gap between wearable sensor technology and
personalized AI assistants by enabling Large Language Models (LLMs) to
understand time-series tasks like human activity recognition (HAR). Despite the
strong reasoning and generalization capabilities of LLMs, leveraging them for
sensor data tasks remains largely unexplored. This gap stems from challenges
like the lack of semantic context in time-series data, computational
limitations, and LLMs' difficulty processing numerical inputs. To address these
issues, we introduce SensorLLM, a two-stage framework to unlock LLMs' potential
for sensor data tasks. In the Sensor-Language Alignment Stage, we introduce
special tokens for each sensor channel and automatically generate
trend-descriptive text to align sensor data with textual inputs, enabling
SensorLLM to capture numerical changes, channel-specific information, and
sensor data of varying lengths-capabilities that existing LLMs typically
struggle with, all without the need for human annotations. Next, in Task-Aware
Tuning Stage, we refine the model for HAR classification using the frozen LLM
and alignment module, achieving performance on par with or surpassing
state-of-the-art models. We further demonstrate that SensorLLM evolves into an
effective sensor learner, reasoner, and classifier through Sensor-Language
Alignment, enabling it to generalize across diverse datasets for HAR tasks. We
strongly believe our work lays the stepstone for future time-series and text
alignment research, offering a path toward foundation models for sensor data.

摘要：在這項工作中，我們透過讓大型語言模型 (LLM) 了解時間序列任務（例如人類活動辨識 (HAR)）來彌合穿戴式感測器技術和個人化 AI 助理之間的差距。儘管 LLM 具有強大的推理和概括能力，但利用它們來執行感測器資料任務在很大程度上仍未被探索。這個差距源於挑戰，例如時間序列資料中缺乏語意脈絡、運算限制，以及 LLM 難以處理數值輸入。為了解決這些問題，我們引入了 SensorLLM，一個兩階段架構，用於釋放 LLM 在感測器資料任務中的潛力。在感測器語言對齊階段，我們為每個感測器通道引入了特殊標記，並自動產生趨勢描述文字，以將感測器資料與文字輸入對齊，讓 SensorLLM 能夠擷取數值變化、通道特定資訊，以及長度不一的感測器資料，這些都是現有 LLM 通常難以處理的能力，而且無需人工註解。接下來，在任務感知調整階段，我們使用凍結的 LLM 和對齊模組微調 HAR 分類模型，達到與最先進模型相當或超越的效能。我們進一步證明，SensorLLM 透過感測器語言對齊演變成一個有效的感測器學習器、推理器和分類器，使其能夠在 HAR 任務的不同資料集之間進行概化。我們堅信，我們的研究為未來的時間序列和文字對齊研究奠定了基礎，為感測器資料提供基礎模型的路徑。

##### **Modeling News Interactions and Influence for Financial Market Prediction**
2410.10614v1 by Mengyu Wang, Shay B. Cohen, Tiejun Ma

The diffusion of financial news into market prices is a complex process,
making it challenging to evaluate the connections between news events and
market movements. This paper introduces FININ (Financial Interconnected News
Influence Network), a novel market prediction model that captures not only the
links between news and prices but also the interactions among news items
themselves. FININ effectively integrates multi-modal information from both
market data and news articles. We conduct extensive experiments on two
datasets, encompassing the S&P 500 and NASDAQ 100 indices over a 15-year period
and over 2.7 million news articles. The results demonstrate FININ's
effectiveness, outperforming advanced market prediction models with an
improvement of 0.429 and 0.341 in the daily Sharpe ratio for the two markets
respectively. Moreover, our results reveal insights into the financial news,
including the delayed market pricing of news, the long memory effect of news,
and the limitations of financial sentiment analysis in fully extracting
predictive power from news data.

摘要：金融新聞在市場價格中傳播是一個複雜的過程，
使得評估新聞事件與市場變動之間的關聯性具有挑戰性。本文介紹 FININ（金融相互關聯新聞影響網路），這是一個新穎的市場預測模型，不僅捕捉新聞與價格之間的關聯，還捕捉新聞項目之間的互動。FININ 有效整合來自市場數據和新聞文章的多模式資訊。我們對兩個資料集進行廣泛的實驗，涵蓋 15 年期間的標準普爾 500 指數和納斯達克 100 指數，以及超過 270 萬篇新聞文章。結果證明了 FININ 的有效性，優於進階市場預測模型，分別對兩個市場的每日夏普比率提高了 0.429 和 0.341。此外，我們的結果揭示了對金融新聞的見解，包括新聞的延遲市場定價、新聞的長期記憶效應，以及財務情緒分析在從新聞數據中完全提取預測能力方面的限制。

##### **Intelligent prospector v2.0: exploration drill planning under epistemic model uncertainty**
2410.10610v1 by John Mern, Anthony Corso, Damian Burch, Kurt House, Jef Caers

Optimal Bayesian decision making on what geoscientific data to acquire
requires stating a prior model of uncertainty. Data acquisition is then
optimized by reducing uncertainty on some property of interest maximally, and
on average. In the context of exploration, very few, sometimes no data at all,
is available prior to data acquisition planning. The prior model therefore
needs to include human interpretations on the nature of spatial variability, or
on analogue data deemed relevant for the area being explored. In mineral
exploration, for example, humans may rely on conceptual models on the genesis
of the mineralization to define multiple hypotheses, each representing a
specific spatial variability of mineralization. More often than not, after the
data is acquired, all of the stated hypotheses may be proven incorrect, i.e.
falsified, hence prior hypotheses need to be revised, or additional hypotheses
generated. Planning data acquisition under wrong geological priors is likely to
be inefficient since the estimated uncertainty on the target property is
incorrect, hence uncertainty may not be reduced at all. In this paper, we
develop an intelligent agent based on partially observable Markov decision
processes that plans optimally in the case of multiple geological or
geoscientific hypotheses on the nature of spatial variability. Additionally,
the artificial intelligence is equipped with a method that allows detecting,
early on, whether the human stated hypotheses are incorrect, thereby saving
considerable expense in data acquisition. Our approach is tested on a
sediment-hosted copper deposit, and the algorithm presented has aided in the
characterization of an ultra high-grade deposit in Zambia in 2023.

摘要：在什麼地質科學資料的取得上進行最佳貝氏決策，需要陳述一個先驗的不確定性模型。資料取得的最佳化，是透過最大化並平均化對某個感興趣的屬性的不確定性來進行。在探勘的脈絡中，在資料取得規劃之前，很少有資料，有時甚至完全沒有資料。因此，先驗模型需要包含人類對於空間變異性的本質，或對於被認為與正在探勘區域相關的類比資料的人為詮釋。例如，在礦物探勘中，人類可能會依賴成礦概念模型來定義多重假設，每個假設都代表礦化的特定空間變異性。在資料取得後，通常所有陳述的假設都可能被證明是不正確的，也就是被證偽的，因此先驗假設需要被修正，或產生額外的假設。在錯誤的地質先驗下規劃資料取得可能會沒有效率，因為對目標屬性的估計不確定性是不正確的，因此不確定性可能完全沒有減少。在本文中，我們開發了一個基於部分可觀察馬可夫決策過程的智慧代理，在對空間變異性的本質有多重地質或地質科學假設的情況下，進行最佳規劃。此外，人工智慧配備了一個方法，可以及早偵測人類陳述的假設是否不正確，從而節省大量的資料取得費用。我們的做法在一個沉積銅礦床中進行測試，而所提出的演算法已經協助在 2023 年對尚比亞的一個超高品位礦床進行特徵描述。

##### **BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI**
2410.10604v1 by Shaohao Rui, Lingzhi Chen, Zhenyu Tang, Lilong Wang, Mianxin Liu, Shaoting Zhang, Xiaosong Wang

Accurate diagnosis of brain abnormalities is greatly enhanced by the
inclusion of complementary multi-parametric MRI imaging data. There is
significant potential to develop a universal pre-training model that can be
quickly adapted for image modalities and various clinical scenarios. However,
current models often rely on uni-modal image data, neglecting the cross-modal
correlations among different image modalities or struggling to scale up
pre-training in the presence of missing modality data. In this paper, we
propose BrainMVP, a multi-modal vision pre-training framework for brain image
analysis using multi-parametric MRI scans. First, we collect 16,022 brain MRI
scans (over 2.4 million images), encompassing eight MRI modalities sourced from
a diverse range of centers and devices. Then, a novel pre-training paradigm is
proposed for the multi-modal MRI data, addressing the issue of missing
modalities and achieving multi-modal information fusion. Cross-modal
reconstruction is explored to learn distinctive brain image embeddings and
efficient modality fusion capabilities. A modality-wise data distillation
module is proposed to extract the essence representation of each MR image
modality for both the pre-training and downstream application purposes.
Furthermore, we introduce a modality-aware contrastive learning module to
enhance the cross-modality association within a study. Extensive experiments on
downstream tasks demonstrate superior performance compared to state-of-the-art
pre-training methods in the medical domain, with Dice Score improvement of
0.28%-14.47% across six segmentation benchmarks and a consistent accuracy
improvement of 0.65%-18.07% in four individual classification tasks.

摘要：<paragraph>準確診斷腦部異常會透過加入互補的多參數 MRI 影像資料而大幅提升。開發一個通用預訓練模型具有相當大的潛力，而此模型可以快速調整以符合影像形式和各種臨床場景。然而，目前的模型通常仰賴單一形式的影像資料，忽略了不同影像形式之間的跨形式關聯性，或是難以在缺乏形式資料的情況下擴展預訓練。在本文中，我們提出 BrainMVP，一個用於腦部影像分析的多形式視覺預訓練架構，使用多參數 MRI 掃描。首先，我們收集了 16,022 個腦部 MRI 掃描（超過 240 萬張影像），涵蓋了八種 MRI 形式，這些形式來自於各種不同的中心和裝置。接著，針對多形式 MRI 資料提出了一個新穎的預訓練範例，解決了缺乏形式的問題，並達到了多形式資訊融合。探索了跨形式重建，以學習獨特的腦部影像嵌入和有效率的形式融合能力。提出了一個形式明智的資料萃取模組，用於萃取每個 MR 影像形式的本質表徵，以符合預訓練和下游應用目的。此外，我們引入了形式感知對比學習模組，以加強研究中的跨形式關聯性。針對下游任務進行的廣泛實驗證明了與醫療領域中現有最先進的預訓練方法相比，其具有優異的效能，在六個分割基準中骰子分數提升了 0.28%-14.47%，在四個個別分類任務中精確度一致提升了 0.65%-18.07%。</paragraph>

##### **Neural networks that overcome classic challenges through practice**
2410.10596v1 by Kazuki Irie, Brenden M. Lake

Since the earliest proposals for neural network models of the mind and brain,
critics have pointed out key weaknesses in these models compared to human
cognitive abilities. Here we review recent work that has used metalearning to
help overcome some of these challenges. We characterize their successes as
addressing an important developmental problem: they provide machines with an
incentive to improve X (where X represents the desired capability) and
opportunities to practice it, through explicit optimization for X; unlike
conventional approaches that hope for achieving X through generalization from
related but different objectives. We review applications of this principle to
four classic challenges: systematicity, catastrophic forgetting, few-shot
learning and multi-step reasoning; we also discuss related aspects of human
development in natural environments.

摘要：自最早提出神经网络模型對心智與大腦的模型以來，批評者已指出這些模型與人類認知能力相比存在關鍵弱點。在此，我們回顧最近使用元學習來幫助克服其中一些挑戰的研究。我們將其成功歸因於解決一個重要的發展問題：它們為機器提供了一個改進 X（其中 X 代表所需的機能）的誘因，並透過針對 X 的明確最佳化來提供實踐它的機會；這與傳統方法不同，傳統方法希望透過對相關但不同的目標進行概化來達成 X。我們回顧了這個原理在四個經典挑戰中的應用：系統性、災難性遺忘、少量學習和多步驟推理；我們也討論了人類在自然環境中發展的相關面向。

##### **VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents**
2410.10594v1 by Shi Yu, Chaoyue Tang, Bokai Xu, Junbo Cui, Junhao Ran, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun

Retrieval-augmented generation (RAG) is an effective technique that enables
large language models (LLMs) to utilize external knowledge sources for
generation. However, current RAG systems are solely based on text, rendering it
impossible to utilize vision information like layout and images that play
crucial roles in real-world multi-modality documents. In this paper, we
introduce VisRAG, which tackles this issue by establishing a vision-language
model (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the
document to obtain text, the document is directly embedded using a VLM as an
image and then retrieved to enhance the generation of a VLM. Compared to
traditional text-based RAG, VisRAG maximizes the retention and utilization of
the data information in the original documents, eliminating the information
loss introduced during the parsing process. We collect both open-source and
synthetic data to train the retriever in VisRAG and explore a variety of
generation methods. Experiments demonstrate that VisRAG outperforms traditional
RAG in both the retrieval and generation stages, achieving a 25--39\%
end-to-end performance gain over traditional text-based RAG pipeline. Further
analysis reveals that VisRAG is effective in utilizing training data and
demonstrates strong generalization capability, positioning it as a promising
solution for RAG on multi-modality documents. Our code and data are available
at https://github.com/openbmb/visrag .

摘要：檢索增強生成 (RAG) 是一種有效技術，可讓大型語言模型 (LLM) 利用外部知識來源進行生成。然而，目前的 RAG 系統僅基於文字，無法利用現實世界多模態文件中的版面和圖像等視覺資訊，而這些資訊扮演著至關重要的角色。在本文中，我們介紹了 VisRAG，它透過建立一個基於視覺語言模型 (VLM) 的 RAG 管線來解決這個問題。在這個管線中，並非先解析文件以取得文字，而是直接使用 VLM 將文件嵌入為圖像，然後檢索以增強 VLM 的生成。與傳統的基於文字的 RAG 相比，VisRAG 最大化保留和利用原始文件中的資料資訊，消除了解析過程中產生的資訊遺失。我們收集了開源資料和合成資料來訓練 VisRAG 中的檢索器，並探索了各種生成方法。實驗證明，VisRAG 在檢索和生成階段都優於傳統的 RAG，在傳統的基於文字的 RAG 管線中，端到端效能提升了 25--39%。進一步的分析顯示，VisRAG 能有效利用訓練資料，並展現出強大的泛化能力，使其成為多模態文件中 RAG 的一個有前途的解決方案。我們的程式碼和資料可在 https://github.com/openbmb/visrag 取得。

##### **TRESTLE: A Model of Concept Formation in Structured Domains**
2410.10588v1 by Christopher J. MacLellan, Erik Harpstead, Vincent Aleven, Kenneth R. Koedinger

The literature on concept formation has demonstrated that humans are capable
of learning concepts incrementally, with a variety of attribute types, and in
both supervised and unsupervised settings. Many models of concept formation
focus on a subset of these characteristics, but none account for all of them.
In this paper, we present TRESTLE, an incremental account of probabilistic
concept formation in structured domains that unifies prior concept learning
models. TRESTLE works by creating a hierarchical categorization tree that can
be used to predict missing attribute values and cluster sets of examples into
conceptually meaningful groups. It updates its knowledge by partially matching
novel structures and sorting them into its categorization tree. Finally, the
system supports mixed-data representations, including nominal, numeric,
relational, and component attributes. We evaluate TRESTLE's performance on a
supervised learning task and an unsupervised clustering task. For both tasks,
we compare it to a nonincremental model and to human participants. We find that
this new categorization model is competitive with the nonincremental approach
and more closely approximates human behavior on both tasks. These results serve
as an initial demonstration of TRESTLE's capabilities and show that, by taking
key characteristics of human learning into account, it can better model
behavior than approaches that ignore them.

摘要：概念形成的文獻已證明，人類有能力逐步學習概念，使用各種屬性類型，並在有監督和無監督的環境中學習。許多概念形成模型側重於這些特徵的子集，但沒有任何模型能解釋所有這些特徵。在本文中，我們提出了 TRESTLE，這是一個在結構化領域中逐步形成概率概念的說明，它統一了先前的概念學習模型。TRESTLE 通過創建一個分層分類樹來工作，該樹可用於預測缺失的屬性值和將示例集聚合到概念上有意義的組中。它通過部分匹配新結構並將它們分類到其分類樹中來更新其知識。最後，該系統支持混合數據表示，包括標稱、數字、關係和組成屬性。我們評估了 TRESTLE 在有監督學習任務和無監督聚類任務上的性能。對於這兩個任務，我們將其與非增量模型和人類參與者進行了比較。我們發現，這種新的分類模型與非增量方法具有競爭力，並且在兩個任務上都更接近人類行為。這些結果初步證明了 TRESTLE 的能力，並表明，通過考慮人類學習的主要特徵，它可以比忽略這些特徵的方法更好地建模行為。

##### **Tübingen-CL at SemEval-2024 Task 1:Ensemble Learning for Semantic Relatedness Estimation**
2410.10585v1 by Leixin Zhang, Çağrı Çöltekin

The paper introduces our system for SemEval-2024 Task 1, which aims to
predict the relatedness of sentence pairs. Operating under the hypothesis that
semantic relatedness is a broader concept that extends beyond mere similarity
of sentences, our approach seeks to identify useful features for relatedness
estimation. We employ an ensemble approach integrating various systems,
including statistical textual features and outputs of deep learning models to
predict relatedness scores. The findings suggest that semantic relatedness can
be inferred from various sources and ensemble models outperform many individual
systems in estimating semantic relatedness.

摘要：本文介紹了我們的 SemEval-2024 任務 1 系統，其目標是預測句子對的相關性。在語義相關性是一個超越句子相似性的更廣泛概念的假設下，我們的做法試圖找出相關性估計的有用特徵。我們採用整合各種系統的整體方法，包括統計文本特徵和深度學習模型的輸出，來預測相關性分數。研究結果表明，語義相關性可以從各種來源推論出來，而整體模型在估計語義相關性方面優於許多個別系統。

##### **STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack**
2410.10584v1 by Naman Gupta, Shashank Kirtania, Priyanshu Gupta, Krishna Kariya, Sumit Gulwani, Arun Iyer, Suresh Parthasarathy, Arjun Radhakrishna, Sriram K. Rajamani, Gustavo Soares

Large Language Models (LLMs) often generate incorrect or outdated
information, especially in low-resource settings or when dealing with private
data. To address this, Retrieval-Augmented Generation (RAG) uses external
knowledge bases (KBs), but these can also suffer from inaccuracies. We
introduce STACKFEED, a novel Structured Textual Actor-Critic Knowledge base
editing with FEEDback approach that iteratively refines the KB based on expert
feedback using a multi-actor, centralized critic reinforcement learning
framework. Each document is assigned to an actor, modeled as a ReACT agent,
which performs structured edits based on document-specific targeted
instructions from a centralized critic. Experimental results show that
STACKFEED significantly improves KB quality and RAG system performance,
enhancing accuracy by up to 8% over baselines.

摘要：大型語言模型 (LLM) 經常會產生不正確或過時的資訊，尤其是在資源不足的環境中或處理私人資料時。為了解決這個問題，檢索增強產生 (RAG) 使用外部知識庫 (KB)，但這些知識庫也可能不準確。我們引進 STACKFEED，這是一種新穎的結構化文本 Actor-Critic 知識庫編輯方法，使用回饋，根據專家的回饋，使用多 Actor、集中式評論強化學習架構，反覆改善 KB。每份文件會分配給一個 Actor，建模為 ReACT 代理，它會根據集中式評論的特定目標文件指令，執行結構化的編輯。實驗結果顯示，STACKFEED 大幅改善 KB 品質和 RAG 系統效能，準確度比基準高出 8%。

##### **Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences**
2410.10580v1 by Ayushman Gupta, Akhil Bhogal, Kripabandhu Ghosh

Code-mixing, the practice of alternating between two or more languages in an
utterance, is a common phenomenon in multilingual communities. Due to the
colloquial nature of code-mixing, there is no singular correct way to translate
an English sentence into a code-mixed sentence. For this reason, standard
n-gram-based MT evaluation metrics such as the BLEU score are not appropriate
for code-mixed evaluation. To demonstrate this, we propose a novel method for
code-mixed text generation: Controlled Generation, which parameterizes the
code-mixing degree (CMD) and enables the generation of multiple semantically
equivalent code-mixed sentences from a given English sentence. We introduce a
robust new evaluation metric: GAME: A Gold-Standard Agnostic Measure for
Evaluation of Code-Mixed Sentences. GAME is both language-agnostic and
gold-standard-agnostic, i.e. unlike other metrics, GAME does not require
gold-standard code-mixed sentences for evaluation, thus eliminating the need
for human annotators in the code-mixed evaluation process. When used to
evaluate semantically equivalent code-mixed sentences, we find that GAME scores
have a lower standard deviation than BLEU scores. Further, we create and
release a dataset containing gold-standard code-mixed sentences across 4
language pairs: English-{Hindi, Bengali, French, Spanish} to encourage more
computational research on code-mixing.

摘要：<paragraph>在多語系社群中，代碼混合是一種常見現象，意指在言語表達中交替使用兩種或多種語言。由於代碼混合的口語本質，並沒有一種正確的方法可以將英文句子翻譯成代碼混合句子。因此，標準的 n-gram 基於 MT 評估指標，例如 BLEU 分數，並不適用於代碼混合評估。為了證明這一點，我們提出了一種新的代碼混合文本生成方法：受控生成，它參數化了代碼混合程度 (CMD)，並能夠從給定的英文句子生成多個語義等價的代碼混合句子。我們引入了一個強大的新評估指標：GAME：一種用於評估代碼混合句子的金標準不可知度量。GAME 既與語言無關，也與金標準無關，亦即與其他指標不同，GAME 在評估時不需要金標準代碼混合句子，從而消除了代碼混合評估過程中對人工註解者的需求。當用於評估語義等價的代碼混合句子時，我們發現 GAME 分數的標準差低於 BLEU 分數。此外，我們創建並發布了一個包含 4 種語言對的金標準代碼混合句子的資料集：英語-{印地語、孟加拉語、法語、西班牙語}，以鼓勵更多關於代碼混合的計算研究。</paragraph>

##### **Recipe for Zero-shot POS Tagging: Is It Useful in Realistic Scenarios?**
2410.10576v1 by Zeno Vandenbulcke, Lukas Vermeire, Miryam de Lhoneux

POS tagging plays a fundamental role in numerous applications. While POS
taggers are highly accurate in well-resourced settings, they lag behind in
cases of limited or missing training data. This paper focuses on POS tagging
for languages with limited data. We seek to identify the characteristics of
datasets that make them favourable for training POS tagging models without
using any labelled training data from the target language. This is a zero-shot
approach. We compare the accuracies of a multilingual large language model
(mBERT) fine-tuned on one or more languages related to the target language.
Additionally, we compare these results with models trained directly on the
target language itself. We do this for three target low-resource languages. Our
research highlights the importance of accurate dataset selection for effective
zero-shot POS tagging. Particularly, a strong linguistic relationship and
high-quality datasets ensure optimal results. For extremely low-resource
languages, zero-shot models prove to be a viable option.

摘要：詞性標註在許多應用程式中扮演著基本的角色。雖然詞性標註器在資源充足的環境中非常精確，但它們在訓練資料有限或遺失的情況下卻落後於其他方法。本文專注於資料有限的語言的詞性標註。我們試圖找出資料集的特性，使其有利於訓練詞性標註模型，而無需使用目標語言的任何標籤訓練資料。這是一種零次學習方法。我們比較了針對與目標語言相關的一種或多種語言進行微調的多語言大型語言模型 (mBERT) 的準確度。此外，我們將這些結果與直接針對目標語言本身訓練的模型進行比較。我們針對三種目標低資源語言執行此操作。我們的研究強調了準確的資料集選擇對於有效的零次學習詞性標註的重要性。特別是，強有力的語言關係和高品質的資料集可確保最佳結果。對於極度低資源的語言，零次學習模型被證明是一個可行的選項。

##### **When Precedents Clash**
2410.10567v1 by Cecilia Di Florio, Huimin Dong, Antonino Rotolo

Consistency of case bases is a way to avoid the problem of retrieving
conflicting constraining precedents for new cases to be decided. However, in
legal practice the consistency requirements for case bases may not be
satisfied. As pointed out in (Broughton 2019), a model of precedential
constraint should take into account the hierarchical structure of the specific
legal system under consideration and the temporal dimension of cases. This
article continues the research initiated in (Liu et al. 2022; Di Florio et al.
2023), which established a connection between Boolean classifiers and legal
case-based reasoning. On this basis, we enrich the classifier models with an
organisational structure that takes into account both the hierarchy of courts
and which courts issue decisions that are binding/constraining on subsequent
cases. We focus on common law systems. We also introduce a temporal relation
between cases. Within this enriched framework, we can formalise the notions of
overruled cases and cases decided per incuriam: such cases are not to be
considered binding on later cases. Finally, we show under which condition
principles based on the hierarchical structure and on the temporal dimension
can provide an unambiguous decision-making process for new cases in the
presence of conflicting binding precedents.

摘要：案例库的一致性是一种避免为待决新案例检索到相互冲突的约束性先例的问题的方法。然而，在法律实践中，案例库的一致性要求可能无法得到满足。正如（Broughton 2019）中指出的，先例约束模型应考虑所考虑的特定法律体系的层次结构和案例的时间维度。本文继续了（Liu et al. 2022；Di Florio et al. 2023）中启动的研究，该研究建立了布尔分类器和基于法律案例的推理之间的联系。在此基础上，我们通过组织结构丰富了分类器模型，该组织结构同时考虑了法院的等级制度以及哪些法院发布对后续案件具有约束力的判决。我们专注于普通法体系。我们还引入了案件之间的时间关系。在这个丰富的框架内，我们可以将被推翻的案件和根据过失作出的判决案件的概念形式化：此类案件不应被视为对后来的案件具有约束力。最后，我们展示了在存在相互冲突的约束性先例的情况下，基于层次结构和时间维度的原则可以在何种条件下为新案件提供明确的决策过程。

##### **Is Structure Dependence Shaped for Efficient Communication?: A Case Study on Coordination**
2410.10556v1 by Kohei Kajikawa, Yusuke Kubota, Yohei Oseki

Natural language exhibits various universal properties. But why do these
universals exist? One explanation is that they arise from functional pressures
to achieve efficient communication, a view which attributes cross-linguistic
properties to domain-general cognitive abilities. This hypothesis has
successfully addressed some syntactic universal properties such as
compositionality and Greenbergian word order universals. However, more abstract
syntactic universals have not been explored from the perspective of efficient
communication. Among such universals, the most notable one is structure
dependence, that is, the existence of grammar-internal operations that
crucially depend on hierarchical representations. This property has
traditionally been taken to be central to natural language and to involve
domain-specific knowledge irreducible to communicative efficiency.
  In this paper, we challenge the conventional view by investigating whether
structure dependence realizes efficient communication, focusing on coordinate
structures. We design three types of artificial languages: (i) one with a
structure-dependent reduction operation, which is similar to natural language,
(ii) one without any reduction operations, and (iii) one with a linear (rather
than structure-dependent) reduction operation. We quantify the communicative
efficiency of these languages. The results demonstrate that the language with
the structure-dependent reduction operation is significantly more
communicatively efficient than the counterfactual languages. This suggests that
the existence of structure-dependent properties can be explained from the
perspective of efficient communication.

摘要：自然語言展現出各種普遍特性。但為何這些普遍性存在？一種解釋是它們來自於實現有效溝通的功能壓力，一種將跨語言特性歸因於領域通用的認知能力的觀點。這個假設已成功地處理了一些句法普遍特性，例如組合性和格林伯格式詞序普遍性。然而，更抽象的句法普遍性尚未從有效溝通的角度加以探討。在這些普遍性中，最顯著的一個是結構依賴性，也就是文法內部運算的存在，其關鍵在於階層式表徵。這個特性傳統上被認為是自然語言的中心，並涉及無法簡化為溝通效率的領域特定知識。
  在本文中，我們透過探討結構依賴性是否實現有效溝通來挑戰傳統觀點，重點在於並列結構。我們設計了三種類型的語言：(i) 一種具結構依賴性簡化運算的語言，類似於自然語言，(ii) 一種沒有任何簡化運算的語言，以及 (iii) 一種具有線性（而非結構依賴性）簡化運算的語言。我們量化這些語言的溝通效率。結果表明，具有結構依賴性簡化運算的語言顯著優於反事實語言的溝通效率。這表明結構依賴性特性的存在可以從有效溝通的角度來解釋。

##### **ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection**
2410.10554v1 by Martin Aubard, László Antal, Ana Madureira, Luis F. Teixeira, Erika Ábrahám

This paper introduces ROSAR, a novel framework enhancing the robustness of
deep learning object detection models tailored for side-scan sonar (SSS)
images, generated by autonomous underwater vehicles using sonar sensors. By
extending our prior work on knowledge distillation (KD), this framework
integrates KD with adversarial retraining to address the dual challenges of
model efficiency and robustness against SSS noises. We introduce three novel,
publicly available SSS datasets, capturing different sonar setups and noise
conditions. We propose and formalize two SSS safety properties and utilize them
to generate adversarial datasets for retraining. Through a comparative analysis
of projected gradient descent (PGD) and patch-based adversarial attacks, ROSAR
demonstrates significant improvements in model robustness and detection
accuracy under SSS-specific conditions, enhancing the model's robustness by up
to 1.85%. ROSAR is available at
https://github.com/remaro-network/ROSAR-framework.

摘要：本論文介紹 ROSAR，一個新穎的框架，用於增強深度學習物件偵測模型的穩健性，該模型專為側掃聲納 (SSS) 影像量身打造，由使用聲納感測器的自主水下載具產生。透過延伸我們先前在知識萃取 (KD) 上的工作，此框架將 KD 與對抗性再訓練整合，以解決模型效率和對抗 SSS 雜訊的穩健性這兩項挑戰。我們介紹了三個新穎、公開可用的 SSS 資料集，擷取不同的聲納設定和雜訊條件。我們提出並形式化兩個 SSS 安全屬性，並利用它們來產生用於再訓練的對抗性資料集。透過對投影梯度下降 (PGD) 和基於修補的對抗性攻擊進行比較分析，ROSAR 在 SSS 特定條件下顯著提升了模型的穩健性和偵測準確度，將模型的穩健性提升了 1.85%。ROSAR 可在 https://github.com/remaro-network/ROSAR-framework 取得。

##### **SLaNC: Static LayerNorm Calibration**
2410.10553v1 by Mahsa Salmani, Nikita Trukhanov, Ilya Soloveychik

The ever increasing sizes of Large Language Models (LLMs) beyond hundreds of
billions of parameters have generated enormous pressure on the manufacturers of
dedicated hardware accelerators and made the innovative design of the latter
one of the most rapidly expanding fields of the AI industry. Various approaches
have been explored to enable efficient and accurate processing of LLMs on the
available accelerators given their computational and storage limitations. Among
these, various quantization techniques have become the main focus of the
community as a means of reducing the compute, communication and storage
requirements. Quantization to lower precision formats naturally poses a number
of challenges caused by the limited range of the available value
representations. When it comes to processing the popular Transformer models on
hardware, one of the main issues becomes calculation of the LayerNorm simply
because accumulation of the variance requires a much wider dynamic range than
the hardware enables. In this article, we address this matter and propose a
computationally-efficient scaling technique that can be easily applied to
Transformer models during inference. Our method suggests a straightforward way
of scaling the LayerNorm inputs based on the static weights of the immediately
preceding linear layers. The scaling factors are computed offline, based solely
on the linear layer weights, hence no latency or computational overhead is
added during inference. Most importantly, our technique ensures that no
numerical issues such as overflow or underflow could happen during the compute.
This approach offers smooth, accurate and resource-effective inference across a
wide range of hardware architectures. The article provides theoretical
justification as well as supporting numerical simulations.

摘要：<paragraph>大型語言模型 (LLM) 的規模不斷增加，已超過數千億個參數，對專用硬體加速器的製造商造成巨大壓力，並使後者的創新設計成為 AI 產業發展最迅速的領域之一。為了在計算和儲存限制下，在現有的加速器上能有效且準確地處理 LLM，已探討各種方法。其中，各種量化技術已成為社群關注的重點，作為降低運算、通訊和儲存需求的方法。量化為較低精度的格式自然會產生許多挑戰，原因是可用值表示的範圍有限。在硬體上處理流行的 Transformer 模型時，主要問題之一在於 LayerNorm 的計算，原因是累積變異需要比硬體支援的動態範圍更廣。在本文中，我們探討此問題，並提出一個計算效率高的縮放技術，可輕鬆應用於推理期間的 Transformer 模型。我們的建議方法是根據緊接在後的線性層的靜態權重，縮放 LayerNorm 輸入。縮放因子是根據線性層權重離線計算的，因此在推理期間不會增加延遲或計算負擔。最重要的是，我們的技術可確保在計算期間不會發生溢位或下溢等數值問題。此方法可在各種硬體架構中提供流暢、準確且資源有效的推理。本文提供了理論依據以及支援數值模擬。</paragraph>

##### **Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features**
2410.10547v1 by Changqing Gong, Huafeng Qin, Mounîm A. El-Yacoubi

Alzheimer's Disease (AD) is a prevalent neurodegenerative condition where
early detection is vital. Handwriting, often affected early in AD, offers a
non-invasive and cost-effective way to capture subtle motor changes.
State-of-the-art research on handwriting, mostly online, based AD detection has
predominantly relied on manually extracted features, fed as input to shallow
machine learning models. Some recent works have proposed deep learning
(DL)-based models, either 1D-CNN or 2D-CNN architectures, with performance
comparing favorably to handcrafted schemes. These approaches, however, overlook
the intrinsic relationship between the 2D spatial patterns of handwriting
strokes and their 1D dynamic characteristics, thus limiting their capacity to
capture the multimodal nature of handwriting data. Moreover, the application of
Transformer models remains basically unexplored. To address these limitations,
we propose a novel approach for AD detection, consisting of a learnable
multimodal hybrid attention model that integrates simultaneously 2D handwriting
images with 1D dynamic handwriting signals. Our model leverages a gated
mechanism to combine similarity and difference attention, blending the two
modalities and learning robust features by incorporating information at
different scales. Our model achieved state-of-the-art performance on the DARWIN
dataset, with an F1-score of 90.32\% and accuracy of 90.91\% in Task 8 ('L'
writing), surpassing the previous best by 4.61% and 6.06% respectively.

摘要：阿茲海默症 (AD) 是一種普遍的神經退化性疾病，早期發現至關重要。手寫字通常在 AD 早期受到影響，提供一種非侵入且具成本效益的方式來捕捉細微的動作變化。最先進的手寫字研究，大多數在線上，基於 AD 偵測主要依賴手動提取的特徵，作為淺層機器學習模型的輸入。一些最近的研究提出了基於深度學習 (DL) 的模型，包括 1D-CNN 或 2D-CNN 架構，其效能與手工製作的方案相比相當有利。然而，這些方法忽略了手寫字筆觸的 2D 空間模式與其 1D 動態特徵之間的內在關係，因此限制了其捕捉手寫字資料多模態特性的能力。此外，變形金剛模型的應用基本上仍未探索。為了解決這些限制，我們提出了一種新的 AD 偵測方法，包括一個可學習的多模態混合注意力模型，同時整合 2D 手寫字影像與 1D 動態手寫字訊號。我們的模型利用閘控機制結合相似性和差異性注意力，混合這兩種模態並透過納入不同規模的資訊來學習穩健的特徵。我們的模型在 DARWIN 資料集上達到了最先進的效能，在任務 8（「L」書寫）中 F1 分數為 90.32%，準確率為 90.91%，分別比前一個最佳結果高出 4.61% 和 6.06%。

##### **Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models**
2410.10542v1 by Shubham Kumar Nigam, Aniket Deroy, Subhankar Maity, Arnab Bhattacharya

This study investigates judgment prediction in a realistic scenario within
the context of Indian judgments, utilizing a range of transformer-based models,
including InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and
GPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are
predicted at the point when a case is presented for a decision in court, using
only the information available at that time, such as the facts of the case,
statutes, precedents, and arguments. This approach mimics real-world
conditions, where decisions must be made without the benefit of hindsight,
unlike retrospective analyses often found in previous studies. For transformer
models, we experiment with hierarchical transformers and the summarization of
judgment facts to optimize input for these models. Our experiments with LLMs
reveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust
performance in judgment prediction. Furthermore, incorporating additional legal
information, such as statutes and precedents, significantly improves the
outcome of the prediction task. The LLMs also provide explanations for their
predictions. To evaluate the quality of these predictions and explanations, we
introduce two human evaluation metrics: Clarity and Linking. Our findings from
both automatic and human evaluations indicate that, despite advancements in
LLMs, they are yet to achieve expert-level performance in judgment prediction
and explanation tasks.

摘要：本研究在印度判決的背景下，利用一系列基於Transformer的模型（包括 InLegalBERT、BERT 和 XLNet）以及諸如 Llama-2 和 GPT-3.5 Turbo 等 LLM，探討了在現實場景中的判決預測。在這個現實場景中，我們模擬了在法庭上提出判決時如何預測判決，僅使用當時可用的資訊，例如案件的事實、法規、先例和論點。這種方法模擬了真實世界的條件，在這些條件下必須在沒有事後見之明的幫助下做出決定，這與先前研究中經常發現的回顧性分析不同。對於Transformer模型，我們嘗試了階層式Transformer和判決事實摘要，以優化這些模型的輸入。我們對 LLM 的實驗表明，GPT-3.5 Turbo 在現實場景中表現出色，在判決預測中表現出強大的性能。此外，納入其他法律資訊（例如法規和先例）顯著改善了預測任務的結果。LLM 也為其預測提供了解釋。為了評估這些預測和解釋的品質，我們引入了兩個人類評估指標：清晰度和連結性。我們從自動和人類評估中得出的結果表明，儘管 LLM 有所進步，但它們尚未在判決預測和解釋任務中達到專家級別的表現。

##### **Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature**
2410.10537v1 by Jan Vrba, Jakub Steinbach, Tomáš Jirsa, Laura Verde, Roberta De Fazio, Noriyasu Homma, Yuwen Zeng, Key Ichiji, Lukáš Hájek, Zuzana Sedláková, Jan Mareš

In this study, we propose a robust set of features derived from a thorough
research of contemporary practices in voice pathology detection. The feature
set is based on the combination of acoustic handcrafted features. Additionally,
we introduce pitch difference as a novel feature. We combine this feature set,
containing data from the publicly available Saarbr\"ucken Voice Database (SVD),
with preprocessing using the K-Means Synthetic Minority Over-Sampling Technique
algorithm to address class imbalance.
  Moreover, we applied multiple ML models as binary classifiers. We utilized
support vector machine, k-nearest neighbors, naive Bayes, decision tree, random
forest and AdaBoost classifiers. To determine the best classification approach,
we performed grid search on feasible hyperparameters of respective classifiers
and subsections of features.
  Our approach has achieved the state-of-the-art performance, measured by
unweighted average recall in voice pathology detection on SVD database. We
intentionally omit accuracy as it is highly biased metric in case of unbalanced
data compared to aforementioned metrics. The results are further enhanced by
eliminating the potential overestimation of the results with repeated
stratified cross-validation. This advancement demonstrates significant
potential for the clinical deployment of ML methods, offering a valuable tool
for an objective examination of voice pathologies. To support our claims, we
provide a publicly available GitHub repository with DOI
10.5281/zenodo.13771573. Finally, we provide REFORMS checklist.

摘要：<paragraph>在這項研究中，我們提出了一組穩健的功能，這些功能源自對當代語音病理檢測實務的透徹研究。這組功能基於聲學手工特徵的組合。此外，我們將音高差引入作為一項新穎的功能。我們將這組功能（包含來自公開的薩爾布呂肯語音資料庫 (SVD) 的資料）與使用 K-Means 合成少數過採樣技術演算法進行預處理結合，以解決類別不平衡的問題。
  此外，我們將多個 ML 模型應用為二元分類器。我們利用支援向量機、k-最近鄰、樸素貝氏、決策樹、隨機森林和 AdaBoost 分類器。為了確定最佳分類方法，我們對各個分類器的可行超參數和功能子集執行網格搜尋。
  我們的做法已達成最先進的效能，由 SVD 資料庫中語音病理檢測的未加權平均召回率測量。我們故意省略準確度，因為與上述指標相比，在資料不平衡的情況下，準確度是一個高度偏頗的指標。透過重複分層交叉驗證消除結果的潛在高估，進一步改善了結果。這項進展展示了 ML 方法在臨床部署上的巨大潛力，為客觀檢查語音病理提供了一個有價值的工具。為了支持我們的說法，我們提供了一個公開的 GitHub 儲存庫，其 DOI 為 10.5281/zenodo.13771573。最後，我們提供了 REFORMS 核對清單。</paragraph>

##### **Get Rid of Task Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework**
2410.10524v1 by Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Yanjiang Chen, Liheng Yu, Xu Wang, Yang Wang

Spatiotemporal learning has become a pivotal technique to enable urban
intelligence. Traditional spatiotemporal models mostly focus on a specific task
by assuming a same distribution between training and testing sets. However,
given that urban systems are usually dynamic, multi-sourced with imbalanced
data distributions, current specific task-specific models fail to generalize to
new urban conditions and adapt to new domains without explicitly modeling
interdependencies across various dimensions and types of urban data. To this
end, we argue that there is an essential to propose a Continuous Multi-task
Spatio-Temporal learning framework (CMuST) to empower collective urban
intelligence, which reforms the urban spatiotemporal learning from
single-domain to cooperatively multi-dimensional and multi-task learning.
Specifically, CMuST proposes a new multi-dimensional spatiotemporal interaction
network (MSTI) to allow cross-interactions between context and main
observations as well as self-interactions within spatial and temporal aspects
to be exposed, which is also the core for capturing task-level commonality and
personalization. To ensure continuous task learning, a novel Rolling Adaptation
training scheme (RoAda) is devised, which not only preserves task uniqueness by
constructing data summarization-driven task prompts, but also harnesses
correlated patterns among tasks by iterative model behavior modeling. We
further establish a benchmark of three cities for multi-task spatiotemporal
learning, and empirically demonstrate the superiority of CMuST via extensive
evaluations on these datasets. The impressive improvements on both few-shot
streaming data and new domain tasks against existing SOAT methods are achieved.
Code is available at https://github.com/DILab-USTCSZ/CMuST.

摘要：時空學習已成為實現城市智能的關鍵技術。傳統的時空模型大多集中在特定任務上，假設訓練集和測試集之間的分布相同。然而，鑑於城市系統通常是動態的、多源的，且資料分佈不平衡，目前特定任務模型無法概括到新的城市條件，也無法適應新的領域，而沒有明確地建模跨各種維度和類型城市資料的相互依賴性。為此，我們認為有必要提出一個連續多任務時空學習框架 (CMuST) 來增強集體城市智能，從單一領域的城市時空學習改革為協作的多維度和多任務學習。具體來說，CMuST 提出了一個新的多維時空交互網路 (MSTI)，允許上下文與主要觀測之間的交互作用以及時空方面內的自我交互作用被揭示，這也是捕捉任務級共性和個性化的核心。為了確保連續任務學習，設計了一個新穎的滾動適應訓練方案 (RoAda)，它不僅通過構建資料摘要驅動的任務提示來保留任務的獨特性，還通過迭代模型行為建模來利用任務之間的關聯模式。我們進一步建立了三個城市的多任務時空學習基準，並通過對這些資料集的廣泛評估，實證地證明了 CMuST 的優越性。相對於現有的 SOAT 方法，在少樣本串流資料和新領域任務上都取得了令人印象深刻的進步。程式碼可在 https://github.com/DILab-USTCSZ/CMuST 獲得。

##### **UniGEM: A Unified Approach to Generation and Property Prediction for Molecules**
2410.10516v1 by Shikun Feng, Yuyan Ni, Yan Lu, Zhi-Ming Ma, Wei-Ying Ma, Yanyan Lan

Molecular generation and molecular property prediction are both crucial for
drug discovery, but they are often developed independently. Inspired by recent
studies, which demonstrate that diffusion model, a prominent generative
approach, can learn meaningful data representations that enhance predictive
tasks, we explore the potential for developing a unified generative model in
the molecular domain that effectively addresses both molecular generation and
property prediction tasks. However, the integration of these tasks is
challenging due to inherent inconsistencies, making simple multi-task learning
ineffective. To address this, we propose UniGEM, the first unified model to
successfully integrate molecular generation and property prediction, delivering
superior performance in both tasks. Our key innovation lies in a novel
two-phase generative process, where predictive tasks are activated in the later
stages, after the molecular scaffold is formed. We further enhance task balance
through innovative training strategies. Rigorous theoretical analysis and
comprehensive experiments demonstrate our significant improvements in both
tasks. The principles behind UniGEM hold promise for broader applications,
including natural language processing and computer vision.

摘要：分子生成和分子性质预测对于药物发现至关重要，但它们通常是独立开发的。受最近的研究启发，这些研究表明，扩散模型（一种突出的生成方法）可以学习增强预测任务的有意义的数据表示，我们探索了在分子域中开发统一生成模型的潜力，该模型有效地解决了分子生成和性质预测任务。然而，由于固有的不一致性，这些任务的集成具有挑战性，使得简单的多任务学习无效。为了解决这个问题，我们提出了 UniGEM，这是第一个成功集成分子生成和性质预测的统一模型，在两个任务中都提供了卓越的性能。我们的关键创新在于一种新颖的两阶段生成过程，其中预测任务在分子支架形成后的后期被激活。我们通过创新的训练策略进一步增强任务平衡。严格的理论分析和综合实验表明，我们在两项任务中都取得了显着的改进。UniGEM 背后的原理有望用于更广泛的应用，包括自然语言处理和计算机视觉。

##### **Everyday Speech in the Indian Subcontinent**
2410.10508v1 by Utkarsh Pathak, Chandra Sai Krishna Gunda, Sujitha Sathiyamoorthy, Keshav Agarwal, Hema A. Murthy

India has 1369 languages of which 22 are official. About 13 different scripts
are used to represent these languages. A Common Label Set (CLS) was developed
based on phonetics to address the issue of large vocabulary of units required
in the End to End (E2E) framework for multilingual synthesis. This reduced the
footprint of the synthesizer and also enabled fast adaptation to new languages
which had similar phonotactics, provided language scripts belonged to the same
family. In this paper, we provide new insights into speech synthesis, where the
script belongs to one family, while the phonotactics comes from another. Indian
language text is first converted to CLS, and then a synthesizer that matches
the phonotactics of the language is used. Quality akin to that of a native
speaker is obtained for Sanskrit and Konkani with zero adaptation data, using
Kannada and Marathi synthesizers respectively. Further, this approach also
lends itself seamless code switching across 13 Indian languages and English in
a given native speaker's voice.

摘要：印度有 1369 種語言，其中 22 種是官方語言。約有 13 種不同的文字用於表示這些語言。基於語音學開發了一個通用標籤集 (CLS)，以解決多語言合成端到端 (E2E) 框架中所需的龐大單元詞彙量問題。這減少了合成器的佔用空間，並且還能夠快速適應新語言，這些新語言具有相似的音韻，前提是語言文字屬於同一語系。在本文中，我們提供了對語音合成的新的見解，其中文字屬於一個語系，而音韻來自另一個語系。印度語言文本首先轉換為 CLS，然後使用與語言音韻相匹配的合成器。使用卡納達語和馬拉地語合成器，分別為梵語和孔卡尼語獲得了接近母語人士的品質，而無需適應數據。此外，這種方法還可以在給定的母語人士的聲音中在 13 種印度語言和英語之間進行無縫的代碼切換。

##### **A Practical Approach to Causal Inference over Time**
2410.10502v1 by Martina Cinquini, Isacco Beretta, Salvatore Ruggieri, Isabel Valera

In this paper, we focus on estimating the causal effect of an intervention
over time on a dynamical system. To that end, we formally define causal
interventions and their effects over time on discrete-time stochastic processes
(DSPs). Then, we show under which conditions the equilibrium states of a DSP,
both before and after a causal intervention, can be captured by a structural
causal model (SCM). With such an equivalence at hand, we provide an explicit
mapping from vector autoregressive models (VARs), broadly applied in
econometrics, to linear, but potentially cyclic and/or affected by unmeasured
confounders, SCMs. The resulting causal VAR framework allows us to perform
causal inference over time from observational time series data. Our experiments
on synthetic and real-world datasets show that the proposed framework achieves
strong performance in terms of observational forecasting while enabling
accurate estimation of the causal effect of interventions on dynamical systems.
We demonstrate, through a case study, the potential practical questions that
can be addressed using the proposed causal VAR framework.

摘要：在本文中，我們專注於估計介入在一段時間內對動態系統的因果效應。為此，我們正式定義因果介入及其對離散時間隨機過程 (DSP) 的時間效應。然後，我們展示在哪些條件下，DSP 的平衡狀態，無論是在因果介入之前還是之後，都可以由結構因果模型 (SCM) 捕捉。有了這樣的等價性，我們提供了一個從廣泛應用於計量經濟學的向量自迴歸模型 (VAR) 到線性（但潛在地循環和/或受未測量混雜因素影響）SCM 的明確映射。由此產生的因果 VAR 框架允許我們從觀測時間序列數據中隨時間執行因果推論。我們在合成和真實世界數據集上的實驗表明，所提出的框架在觀測預測方面實現了強大的性能，同時能夠準確估計介入對動態系統的因果效應。我們通過案例研究展示了可以使用所提出的因果 VAR 框架解決的潛在實際問題。

##### **Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation**
2410.10489v1 by Sharif Kazemi, Gloria Gerhardt, Jonty Katz, Caroline Ida Kuria, Estelle Pan, Umang Prabhakar

The training data for LLMs embeds societal values, increasing their
familiarity with the language's culture. Our analysis found that 44% of the
variance in the ability of GPT-4o to reflect the societal values of a country,
as measured by the World Values Survey, correlates with the availability of
digital resources in that language. Notably, the error rate was more than five
times higher for the languages of the lowest resource compared to the languages
of the highest resource. For GPT-4-turbo, this correlation rose to 72%,
suggesting efforts to improve the familiarity with the non-English language
beyond the web-scraped data. Our study developed one of the largest and most
robust datasets in this topic area with 21 country-language pairs, each of
which contain 94 survey questions verified by native speakers. Our results
highlight the link between LLM performance and digital data availability in
target languages. Weaker performance in low-resource languages, especially
prominent in the Global South, may worsen digital divides. We discuss
strategies proposed to address this, including developing multilingual LLMs
from the ground up and enhancing fine-tuning on diverse linguistic datasets, as
seen in African language initiatives.

摘要：大型語言模型的訓練資料會內嵌社會價值觀，提升其對語言文化的熟悉度。我們的分析發現，GPT-4o 反映一個國家社會價值觀的能力有 44% 的變異，根據世界價值觀調查測量，與該語言數位資源的可用性相關。值得注意的是，資源最少的語言的錯誤率比資源最多的語言高出五倍以上。對於 GPT-4-turbo，此相關性上升至 72%，顯示出除了網路擷取資料之外，改善對非英語語言熟悉度的努力。我們的研究開發了這個主題領域中最大且最穩健的資料集之一，包含 21 組國家語言對，每組包含 94 個由母語人士驗證的調查問題。我們的結果突顯了大型語言模型效能與目標語言中數位資料可用性之間的關聯性。在資源較少的語言中效能較差，特別是在全球南方顯著，可能會惡化數位鴻溝。我們討論了為了解決此問題而提出的策略，包括從頭開始開發多語言大型語言模型，以及在不同的語言資料集上加強微調，如同在非洲語言計畫中所見。

##### **Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization**
2410.10483v1 by Jorge García-Torres, Øyvind Meinich-Bache, Anders Johannessen, Siren Rettedal, Vilde Kolstad, Kjersti Engan

Around 5-10\% of newborns need assistance to start breathing. Currently,
there is a lack of evidence-based research, objective data collection, and
opportunities for learning from real newborn resuscitation emergency events.
Generating and evaluating automated newborn resuscitation algorithm activity
timelines relative to the Time of Birth (ToB) offers a promising opportunity to
enhance newborn care practices. Given the importance of prompt resuscitation
interventions within the "golden minute" after birth, having an accurate ToB
with second precision is essential for effective subsequent analysis of newborn
resuscitation episodes. Instead, ToB is generally registered manually, often
with minute precision, making the process inefficient and susceptible to error
and imprecision. In this work, we explore the fusion of Artificial Intelligence
(AI) and thermal imaging to develop the first AI-driven ToB detector. The use
of temperature information offers a promising alternative to detect the newborn
while respecting the privacy of healthcare providers and mothers. However, the
frequent inconsistencies in thermal measurements, especially in a multi-camera
setup, make normalization strategies critical. Our methodology involves a
three-step process: first, we propose an adaptive normalization method based on
Gaussian mixture models (GMM) to mitigate issues related to temperature
variations; second, we implement and deploy an AI model to detect the presence
of the newborn within the thermal video frames; and third, we evaluate and
post-process the model's predictions to estimate the ToB. A precision of 88.1\%
and a recall of 89.3\% are reported in the detection of the newborn within
thermal frames during performance evaluation. Our approach achieves an absolute
median deviation of 2.7 seconds in estimating the ToB relative to the manual
annotations.

摘要：<paragraph>約 5-10% 的新生兒需要協助才能開始呼吸。目前，缺乏基於證據的研究、客觀的資料蒐集，以及從實際新生兒復甦緊急事件中學習的機會。生成並評估自動新生兒復甦演算法活動時間表，相對於出生時間 (ToB)，提供了一個有希望的機會，可以增強新生兒照護實務。鑑於在出生後的「黃金一分鐘」內進行立即復甦干預的重要性，擁有準確到秒的 ToB 對於有效分析新生兒復甦事件至關重要。然而，ToB 通常是手動記錄的，通常只有分鐘的精確度，這使得這個過程效率低下，容易出錯且不精確。在這項工作中，我們探討人工智慧 (AI) 和熱影像融合，以開發第一個由 AI 驅動的 ToB 偵測器。溫度資訊的使用提供了一個有希望的替代方案，可以在尊重醫療保健提供者和母親隱私的同時偵測新生兒。然而，熱量測量中的頻繁不一致，尤其是在多鏡頭設定中，使得正規化策略至關重要。我們的做法包括一個三步驟流程：首先，我們提出一個基於高斯混合模型 (GMM) 的自適應正規化方法，以減輕與溫度變化相關的問題；其次，我們實作並部署一個 AI 模型，以偵測新生兒在熱影像框中的存在；第三，我們評估並後處理模型的預測，以估計 ToB。在效能評估期間，在熱影像框中偵測新生兒時，準確度為 88.1%，召回率為 89.3%。我們的做法在估計相對於手動註解的 ToB 時，達到 2.7 秒的絕對中位數偏差。</paragraph>

##### **Model-Based Differentially Private Knowledge Transfer for Large Language Models**
2410.10481v1 by Zhaomin Wu, Jizhou Guo, Junyi Hou, Bingsheng He, Lixin Fan, Qiang Yang

As large language models (LLMs) become increasingly prevalent in web
services, effectively leveraging domain-specific knowledge while ensuring
privacy has become critical. Existing methods, such as retrieval-augmented
generation (RAG) and differentially private data synthesis, often compromise
either the utility of domain knowledge or the privacy of sensitive data,
limiting their applicability in specialized domains. To address these
challenges, we propose \textit{Llamdex}, a novel framework that integrates
privacy-preserving, domain-specific models into LLMs. Our approach
significantly enhances the accuracy of domain-specific tasks, achieving up to a
26\% improvement compared to existing methods under the same differential
privacy constraints. Experimental results show that Llamdex not only improves
the accuracy of LLM responses but also maintains comparable inference
efficiency to the original LLM, highlighting its potential for real-world
applications.

摘要：随着大型语言模型 (LLM) 在网络服务中变得越来越普遍，有效地利用特定领域的知识，同时确保隐私已变得至关重要。现有的方法，例如检索增强生成 (RAG) 和差异化隐私数据合成，通常会损害领域知识的效用或敏感数据的隐私，从而限制它们在特定领域的适用性。为了应对这些挑战，我们提出了 \textit{Llamdex}，这是一个将隐私保护的特定领域模型集成到 LLM 中的新框架。我们的方法显着提高了特定领域任务的准确性，与在相同差异隐私约束下的现有方法相比，提高了 26%。实验结果表明，Llamdex 不仅提高了 LLM 响应的准确性，而且还保持了与原始 LLM 相当的推理效率，突出了其在现实世界应用中的潜力。

##### **TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs**
2410.10479v1 by Haochuan Wang, Xiachong Feng, Lei Li, Zhanyue Qin, Dianbo Sui, Lingpeng Kong

The rapid advancement of large language models (LLMs) has accelerated their
application in reasoning, with strategic reasoning drawing increasing
attention. To evaluate LLMs' strategic reasoning capabilities, game theory,
with its concise structure, has become a preferred approach. However, current
research focuses on a limited selection of games, resulting in low coverage.
Classic game scenarios risk data leakage, and existing benchmarks often lack
extensibility, making them inadequate for evaluating state-of-the-art models.
To address these challenges, we propose TMGBench, a benchmark with
comprehensive game type coverage, novel scenarios, and flexible organization.
Specifically, we incorporate all 144 game types summarized by the
Robinson-Goforth topology of 2x2 games, constructed as classic games. We also
employ synthetic data generation to create diverse, higher-quality scenarios
through topic guidance and human inspection, referred to as story-based games.
Lastly, we provide a sustainable framework for increasingly powerful LLMs by
treating these games as atomic units and organizing them into more complex
forms via sequential, parallel, and nested structures. Our comprehensive
evaluation of mainstream LLMs covers tests on rational reasoning, robustness,
Theory-of-Mind (ToM), and reasoning in complex forms. Results reveal flaws in
accuracy, consistency, and varying mastery of ToM. Additionally, o1-mini,
OpenAI's latest reasoning model, achieved accuracy rates of 66.6%, 60.0%, and
70.0% on sequential, parallel, and nested games, highlighting TMGBench's
challenges.

摘要：大型語言模型 (LLM) 的快速進展加速了它們在推理中的應用，其中策略推理引起了越來越多的關注。為了評估 LLM 的策略推理能力，博弈論以其簡潔的結構成為了一種首選方法。然而，目前的研究集中在有限的遊戲選擇上，導致覆蓋率低。經典遊戲場景有數據洩露的風險，現有的基準通常缺乏可擴展性，這使得它們不足以評估最先進的模型。為了應對這些挑戰，我們提出了 TMGBench，這是一個基準，具有全面的遊戲類型覆蓋範圍、新穎的場景和靈活的組織。具體來說，我們納入了 Robinson-Goforth 拓撲中總結的所有 144 種遊戲類型，構建為經典遊戲。我們還使用合成數據生成來通過主題指導和人工檢查創建多樣化、更高質量的場景，稱為基於故事的遊戲。最後，我們通過將這些遊戲視為原子單元並通過順序、並行和嵌套結構將它們組織成更複雜的形式，為功能越來越強大的 LLM 提供了一個可持續的框架。我們對主流 LLM 的綜合評估涵蓋了對理性推理、魯棒性、心智理論 (ToM) 和複雜形式中的推理的測試。結果揭示了準確性、一致性和對 ToM 掌握程度不同的缺陷。此外，OpenAI 最新的推理模型 o1-mini 在順序、並行和嵌套遊戲中分別達到了 66.6%、60.0% 和 70.0% 的準確率，突顯了 TMGBench 的挑戰。

##### **Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?**
2410.10476v1 by Gabriel Roccabruna, Massimo Rizzoli, Giuseppe Riccardi

The automatic detection of temporal relations among events has been mainly
investigated with encoder-only models such as RoBERTa. Large Language Models
(LLM) have recently shown promising performance in temporal reasoning tasks
such as temporal question answering. Nevertheless, recent studies have tested
the LLMs' performance in detecting temporal relations of closed-source models
only, limiting the interpretability of those results. In this work, we
investigate LLMs' performance and decision process in the Temporal Relation
Classification task. First, we assess the performance of seven open and
closed-sourced LLMs experimenting with in-context learning and lightweight
fine-tuning approaches. Results show that LLMs with in-context learning
significantly underperform smaller encoder-only models based on RoBERTa. Then,
we delve into the possible reasons for this gap by applying explainable
methods. The outcome suggests a limitation of LLMs in this task due to their
autoregressive nature, which causes them to focus only on the last part of the
sequence. Additionally, we evaluate the word embeddings of these two models to
better understand their pre-training differences. The code and the fine-tuned
models can be found respectively on GitHub.

摘要：事件之間時間關係的自動偵測主要使用編碼器模型，例如 RoBERTa，進行研究。大型語言模型 (LLM) 近期在時間推理任務中展現出令人滿意的表現，例如時間問題回答。儘管如此，最近的研究僅測試了 LLM 在偵測封閉原始碼模型的時間關係上的表現，這限制了這些結果的可解釋性。在這項工作中，我們研究了 LLM 在時間關係分類任務中的表現和決策過程。首先，我們評估了七個開放和封閉原始碼 LLM 在情境學習和輕量級微調方法中的表現。結果顯示，使用情境學習的 LLM 明顯低於基於 RoBERTa 的較小編碼器模型。然後，我們透過應用可解釋的方法深入探討造成這個差距的可能原因。結果表明，LLM 在此任務中的限制在於它們的自動迴歸本質，這導致它們只關注序列的最後部分。此外，我們評估了這兩個模型的詞嵌入，以更好地了解它們的預訓練差異。程式碼和微調模型分別可以在 GitHub 上找到。

##### **TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE**
2410.10463v1 by Emmanouil Panagiotou, Manuel Heurich, Tim Landgraf, Eirini Ntoutsi

In the field of Explainable AI (XAI), counterfactual (CF) explanations are
one prominent method to interpret a black-box model by suggesting changes to
the input that would alter a prediction. In real-world applications, the input
is predominantly in tabular form and comprised of mixed data types and complex
feature interdependencies. These unique data characteristics are difficult to
model, and we empirically show that they lead to bias towards specific feature
types when generating CFs. To overcome this issue, we introduce TABCF, a CF
explanation method that leverages a transformer-based Variational Autoencoder
(VAE) tailored for modeling tabular data. Our approach uses transformers to
learn a continuous latent space and a novel Gumbel-Softmax detokenizer that
enables precise categorical reconstruction while preserving end-to-end
differentiability. Extensive quantitative evaluation on five financial datasets
demonstrates that TABCF does not exhibit bias toward specific feature types,
and outperforms existing methods in producing effective CFs that align with
common CF desiderata.

摘要：在可解釋 AI (XAI) 領域中，反事實 (CF) 解釋是一種重要的透過建議變更輸入來改變預測的黑箱模型解釋方法。在實際應用中，輸入主要以表格形式呈現，並包含混合資料類型和複雜的特徵相互依賴性。這些獨特資料特徵難以建模，我們實證顯示，在產生 CF 時，它們會導致偏向特定特徵類型。為了克服這個問題，我們引入了 TABCF，這是一種 CF 解釋方法，它利用了為表格資料建模而量身打造的基於變換器的變異自動編碼器 (VAE)。我們的做法使用變換器來學習連續潛在空間和一種新的 Gumbel-Softmax 去標記器，它可以在保留端對端可微分的同時實現精確的分類重建。對五個財務資料集進行的廣泛定量評估表明，TABCF 沒有表現出對特定特徵類型的偏見，並且在產生符合常見 CF 理想條件的有效 CF 方面優於現有方法。

##### **Ada-K Routing: Boosting the Efficiency of MoE-based LLMs**
2410.10456v2 by Tongtian Yue, Longteng Guo, Jie Cheng, Xuange Gao, Jing Liu

In the era of Large Language Models (LLMs), Mixture-of-Experts (MoE)
architectures offer a promising approach to managing computational costs while
scaling up model parameters. Conventional MoE-based LLMs typically employ
static Top-K routing, which activates a fixed and equal number of experts for
each token regardless of their significance within the context. In this paper,
we propose a novel Ada-K routing strategy that dynamically adjusts the number
of activated experts for each token, thereby improving the balance between
computational efficiency and model performance. Specifically, our strategy
incorporates learnable and lightweight allocator modules that decide customized
expert resource allocation tailored to the contextual needs for each token.
These allocators are designed to be fully pluggable, making it broadly
applicable across all mainstream MoE-based LLMs. We leverage the Proximal
Policy Optimization (PPO) algorithm to facilitate an end-to-end learning
process for this non-differentiable decision-making framework. Extensive
evaluations on four popular baseline models demonstrate that our Ada-K routing
method significantly outperforms conventional Top-K routing. Compared to Top-K,
our method achieves over 25% reduction in FLOPs and more than 20% inference
speedup while still improving performance across various benchmarks. Moreover,
the training of Ada-K is highly efficient. Even for Mixtral-8x22B, a MoE-based
LLM with more than 140B parameters, the training time is limited to 8 hours.
Detailed analysis shows that harder tasks, middle layers, and content words
tend to activate more experts, providing valuable insights for future adaptive
MoE system designs. Both the training code and model checkpoints will be
publicly available.

摘要：<paragraph>在大型語言模型 (LLM) 時代，混合專家 (MoE) 架構提供了一種有前景的方法，可以在擴充模型參數的同時管理運算成本。基於 MoE 的傳統 LLM 通常採用靜態 Top-K 路由，無論符號在上下文中的重要性如何，都會為每個符號啟用固定且相等的專家數量。在本文中，我們提出了一種新穎的 Ada-K 路由策略，它會動態調整每個符號的已啟用專家數量，從而改善運算效率和模型效能之間的平衡。具體來說，我們的策略包含可學習且輕量化的配置器模組，這些模組會針對每個符號的上下文需求決定自訂的專家資源配置。這些配置器被設計為完全可插入，使其廣泛適用於所有主流的基於 MoE 的 LLM。我們利用近端策略最佳化 (PPO) 演算法來促進這個不可微分決策制定架構的端對端學習過程。對四個流行的基線模型進行廣泛評估，證明我們的 Ada-K 路由方法顯著優於傳統的 Top-K 路由。與 Top-K 相比，我們的模型在 FLOP 方面減少了 25% 以上，推理速度加快了 20% 以上，同時仍改善了各種基準測試的效能。此外，Ada-K 的訓練非常有效率。即使對於 Mixtral-8x22B，一個具有超過 140B 參數的基於 MoE 的 LLM，訓練時間也限制在 8 小時內。詳細分析顯示，較困難的任務、中間層和內容詞傾向於啟用更多專家，這為未來的自適應 MoE 系統設計提供了寶貴的見解。訓練程式碼和模型檢查點將公開提供。</paragraph>

##### **Advancing Academic Knowledge Retrieval via LLM-enhanced Representation Similarity Fusion**
2410.10455v1 by Wei Dai, Peng Fu, Chunjing Gan

In an era marked by robust technological growth and swift information
renewal, furnishing researchers and the populace with top-tier, avant-garde
academic insights spanning various domains has become an urgent necessity. The
KDD Cup 2024 AQA Challenge is geared towards advancing retrieval models to
identify pertinent academic terminologies from suitable papers for scientific
inquiries. This paper introduces the LLM-KnowSimFuser proposed by Robo Space,
which wins the 2nd place in the competition. With inspirations drawed from the
superior performance of LLMs on multiple tasks, after careful analysis of the
provided datasets, we firstly perform fine-tuning and inference using
LLM-enhanced pre-trained retrieval models to introduce the tremendous language
understanding and open-domain knowledge of LLMs into this task, followed by a
weighted fusion based on the similarity matrix derived from the inference
results. Finally, experiments conducted on the competition datasets show the
superiority of our proposal, which achieved a score of 0.20726 on the final
leaderboard.

摘要：在科技飛速發展、資訊更新快速的時代，為研究者和普羅大眾提供跨領域的頂尖前沿學術見解，已成為刻不容緩的必要。KDD Cup 2024 AQA 挑戰賽旨在推進檢索模型，從合適的論文中找出與科學探究相關的學術術語。本文介紹了由 Robo Space 提出的 LLM-KnowSimFuser，在競賽中獲得第二名。在仔細分析提供的資料集後，我們從 LLM 在多項任務中的優異表現中汲取靈感，首先使用 LLM 增強的預訓練檢索模型進行微調和推理，將 LLM 强大的語言理解和開放領域知識引入此任務中，接著根據推理結果衍生的相似矩陣進行加權融合。最後，在競賽資料集上進行的實驗顯示了我們提案的優越性，在最終排行榜上取得 0.20726 的分數。

##### **KBLaM: Knowledge Base augmented Language Model**
2410.10450v1 by Xi Wang, Liana Mikaelyan, Taketomo Isazawa, James Hensman

In this paper, we propose Knowledge Base augmented Language Model (KBLaM), a
new method for augmenting Large Language Models (LLMs) with external knowledge.
KBLaM works with a knowledge base (KB) constructed from a corpus of documents,
transforming each piece of knowledge in the KB into continuous key-value vector
pairs via pre-trained sentence encoders with linear adapters and integrating
them into pre-trained LLMs via a specialized rectangular attention mechanism.
Unlike Retrieval-Augmented Generation, KBLaM eliminates external retrieval
modules, and unlike in-context learning, its computational overhead scales
linearly with KB size rather than quadratically. Our approach enables
integrating a large KB of more than 10K triples into an 8B pre-trained LLM of
only 8K context window on one single A100 80GB GPU and allows for dynamic
updates without model fine-tuning or retraining. Experiments demonstrate
KBLaM's effectiveness in various tasks, including question-answering and
open-ended reasoning, while providing interpretable insights into its use of
the augmented knowledge.

摘要：在本文中，我們提出了知識庫增強語言模型 (KBLaM)，這是一種使用外部知識增強大型語言模型 (LLM) 的新方法。KBLaM 使用從文件語料庫中建構的知識庫 (KB)，透過預先訓練的句子編碼器和線性適配器，將 KB 中的每段知識轉換為連續的鍵值向量對，並透過專門的矩形注意力機制將它們整合到預先訓練的 LLM 中。與檢索增強生成不同，KBLaM 消除了外部檢索模組，與情境內學習不同，它的運算開銷與 KB 大小成線性比例，而不是二次方比例。我們的做法能夠將超過 10K 三元組的大型 KB 整合到僅有 8K 情境視窗的 8B 預先訓練 LLM 中，僅使用一個 A100 80GB GPU，並允許動態更新，而無需模型微調或重新訓練。實驗證明了 KBLaM 在各種任務中的效能，包括問答和開放式推理，同時提供對其使用增強知識的可詮釋見解。

##### **QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios**
2410.10449v1 by Timo Pierre Schrader, Lukas Lange, Simon Razniewski, Annemarie Friedrich

Reasoning is key to many decision making processes. It requires consolidating
a set of rule-like premises that are often associated with degrees of
uncertainty and observations to draw conclusions. In this work, we address both
the case where premises are specified as numeric probabilistic rules and
situations in which humans state their estimates using words expressing degrees
of certainty. Existing probabilistic reasoning datasets simplify the task,
e.g., by requiring the model to only rank textual alternatives, by including
only binary random variables, or by making use of a limited set of templates
that result in less varied text.
  In this work, we present QUITE, a question answering dataset of real-world
Bayesian reasoning scenarios with categorical random variables and complex
relationships. QUITE provides high-quality natural language verbalizations of
premises together with evidence statements and expects the answer to a question
in the form of an estimated probability. We conduct an extensive set of
experiments, finding that logic-based models outperform out-of-the-box large
language models on all reasoning types (causal, evidential, and
explaining-away). Our results provide evidence that neuro-symbolic models are a
promising direction for improving complex reasoning. We release QUITE and code
for training and experiments on Github.

摘要：推理是許多決策制定過程的關鍵。這需要整合一組規則般的前提，這些前提通常與不確定性和觀察結果的程度相關，才能得出結論。在這項工作中，我們同時處理了前提被指定為數字機率規則的情況，以及人類使用表達確定程度的文字陳述其估計值的情況。現有的機率推理資料集簡化了這項任務，例如，要求模型僅對文字選項進行排名、僅包含二元隨機變數，或使用一組有限的範本，這會產生較少的文字變化。
在這項工作中，我們提出了 QUITE，這是一個問題解答資料集，包含真實世界的貝氏推理場景，其中包含分類隨機變數和複雜關係。QUITE 提供了前提的高品質自然語言表達，以及證據陳述，並期望以估計機率的形式回答問題。我們進行了一系列廣泛的實驗，發現基於邏輯的模型在所有推理類型（因果、證據和解釋）上都優於現成的巨量語言模型。我們的結果提供了證據，表明神經符號模型是改進複雜推理的有希望的方向。我們在 Github 上發布了 QUITE 和訓練與實驗的程式碼。

##### **Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs**
2410.10441v1 by Kai Han, Jianyuan Guo, Yehui Tang, Wei He, Enhua Wu, Yunhe Wang

Vision-language large models have achieved remarkable success in various
multi-modal tasks, yet applying them to video understanding remains challenging
due to the inherent complexity and computational demands of video data. While
training-based video-LLMs deliver high performance, they often require
substantial resources for training and inference. Conversely, training-free
approaches offer a more efficient alternative by adapting pre-trained
image-LLMs models for video tasks without additional training, but they face
inference efficiency bottlenecks due to the large number of visual tokens
generated from video frames. In this work, we present a novel prompt-guided
visual perception framework (abbreviated as \emph{Free Video-LLM}) for
efficient inference of training-free video LLMs. The proposed framework
decouples spatial-temporal dimension and performs temporal frame sampling and
spatial RoI cropping respectively based on task-specific prompts. Our method
effectively reduces the number of visual tokens while maintaining high
performance across multiple video question-answering benchmarks. Extensive
experiments demonstrate that our approach achieves competitive results with
significantly fewer tokens, offering an optimal trade-off between accuracy and
computational efficiency compared to state-of-the-art video LLMs. The code will
be available at \url{https://github.com/contrastive/FreeVideoLLM}.

摘要：視覺語言大型模型在各種多模態任務中取得顯著成功，但由於視訊資料本身複雜且計算需求高，將其應用於視訊理解仍是一項挑戰。雖然基於訓練的視訊 LLM 可提供高性能，但通常需要大量的資源進行訓練和推論。相反地，無需訓練的方法提供了一種更有效率的替代方案，可以調整預先訓練好的影像 LLM 模型以執行視訊任務，而無需額外訓練，但由於視訊幀產生的視覺符號數量龐大，它們面臨推論效率瓶頸。在這項工作中，我們提出了一個新的提示引導視覺感知框架（簡稱「Free Video-LLM」），用於有效推論無需訓練的視訊 LLM。所提出的框架解耦時空維度，並根據特定於任務的提示分別執行時間幀採樣和空間 RoI 裁剪。我們的模型有效減少了視覺符號的數量，同時在多個視訊問答基準中維持高性能。廣泛的實驗證明，我們的模型以顯著更少的符號取得有競爭力的結果，與最先進的視訊 LLM 相比，在準確度和運算效率之間提供了最佳的折衷方案。程式碼將會在 \url{https://github.com/contrastive/FreeVideoLLM} 提供。

##### **LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections**
2410.10433v1 by Xuezhi Xiang, Yibo Ning, Lei Zhang, Denis Ombati, Himaloy Himu, Xiantong Zhen

Semantic segmentation of remote sensing images is a fundamental task in
geospatial research. However, widely used Convolutional Neural Networks (CNNs)
and Transformers have notable drawbacks: CNNs may be limited by insufficient
remote sensing modeling capability, while Transformers face challenges due to
computational complexity. In this paper, we propose a remote-sensing image
semantic segmentation network named LKASeg, which combines Large Kernel
Attention(LSKA) and Full-Scale Skip Connections(FSC). Specifically, we propose
a decoder based on Large Kernel Attention (LKA), which extract global features
while avoiding the computational overhead of self-attention and providing
channel adaptability. To achieve full-scale feature learning and fusion, we
apply Full-Scale Skip Connections (FSC) between the encoder and decoder. We
conducted experiments by combining the LKA-based decoder with FSC. On the ISPRS
Vaihingen dataset, the mF1 and mIoU scores achieved 90.33% and 82.77%.

摘要：遙測影像的語意分割是地理空間研究中的基本任務。然而，廣泛使用的卷積神經網路 (CNN) 和 Transformer 有顯著的缺點：CNN 可能受到遙測建模能力不足的限制，而 Transformer 則因計算複雜度而面臨挑戰。在本文中，我們提出一個名為 LKASeg 的遙測影像語意分割網路，它結合了大核注意力 (LSKA) 和全尺寸跳躍連接 (FSC)。具體來說，我們提出了一個基於大核注意力 (LKA) 的解碼器，它在避免自注意力的計算開銷並提供通道適應性的同時提取全局特徵。為了實現全尺寸特徵學習和融合，我們在編碼器和解碼器之間應用全尺寸跳躍連接 (FSC)。我們通過將基於 LKA 的解碼器與 FSC 相結合進行了實驗。在 ISPRS Vaihingen 資料集上，mF1 和 mIoU 分數分別達到 90.33% 和 82.77%。

##### **On Calibration of LLM-based Guard Models for Reliable Content Moderation**
2410.10414v1 by Hongfu Liu, Hengguan Huang, Hao Wang, Xiangming Gu, Ye Wang

Large language models (LLMs) pose significant risks due to the potential for
generating harmful content or users attempting to evade guardrails. Existing
studies have developed LLM-based guard models designed to moderate the input
and output of threat LLMs, ensuring adherence to safety policies by blocking
content that violates these protocols upon deployment. However, limited
attention has been given to the reliability and calibration of such guard
models. In this work, we empirically conduct comprehensive investigations of
confidence calibration for 9 existing LLM-based guard models on 12 benchmarks
in both user input and model output classification. Our findings reveal that
current LLM-based guard models tend to 1) produce overconfident predictions, 2)
exhibit significant miscalibration when subjected to jailbreak attacks, and 3)
demonstrate limited robustness to the outputs generated by different types of
response models. Additionally, we assess the effectiveness of post-hoc
calibration methods to mitigate miscalibration. We demonstrate the efficacy of
temperature scaling and, for the first time, highlight the benefits of
contextual calibration for confidence calibration of guard models, particularly
in the absence of validation sets. Our analysis and experiments underscore the
limitations of current LLM-based guard models and provide valuable insights for
the future development of well-calibrated guard models toward more reliable
content moderation. We also advocate for incorporating reliability evaluation
of confidence calibration when releasing future LLM-based guard models.

摘要：大型語言模型 (LLM) 由於潛在生成有害內容或使用者企圖規避防護措施的風險，因此構成重大風險。現有研究已開發出基於 LLM 的防護模型，旨在調節威脅 LLM 的輸入和輸出，確保在部署時封鎖違反這些協定的內容，從而遵守安全政策。然而，對於此類防護模型的可靠性和校準，卻鮮少受到關注。在這項工作中，我們針對 9 個現有的基於 LLM 的防護模型，在 12 個基準上對使用者輸入和模型輸出分類進行全面的信心校準調查。我們的研究結果顯示，目前的基於 LLM 的防護模型往往會 1) 產生過度自信的預測，2) 在遭受越獄攻擊時表現出顯著的校準不當，以及 3) 對不同類型的回應模型所產生的輸出表現出有限的穩健性。此外，我們評估事後校準方法在減輕校準不當方面的有效性。我們展示了溫度調整的功效，並首次強調了情境校準對於防護模型的信心校準（特別是在沒有驗證集的情況下）所帶來的益處。我們的分析和實驗強調了目前基於 LLM 的防護模型的限制，並為未來開發校準良好的防護模型以實現更可靠的內容審核提供了寶貴的見解。我們也主張在釋出未來的基於 LLM 的防護模型時，納入信心校準的可靠性評估。

##### **Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion**
2410.10408v1 by Xinping Zhao, Jindi Yu, Zhenyu Liu, Jifang Wang, Dongfang Li, Yibin Chen, Baotian Hu, Min Zhang

As we all know, hallucinations prevail in Large Language Models (LLMs), where
the generated content is coherent but factually incorrect, which inflicts a
heavy blow on the widespread application of LLMs. Previous studies have shown
that LLMs could confidently state non-existent facts rather than answering ``I
don't know''. Therefore, it is necessary to resort to external knowledge to
detect and correct the hallucinated content. Since manual detection and
correction of factual errors is labor-intensive, developing an automatic
end-to-end hallucination-checking approach is indeed a needful thing. To this
end, we present Medico, a Multi-source evidence fusion enhanced hallucination
detection and correction framework. It fuses diverse evidence from multiple
sources, detects whether the generated content contains factual errors,
provides the rationale behind the judgment, and iteratively revises the
hallucinated content. Experimental results on evidence retrieval (0.964 HR@5,
0.908 MRR@5), hallucination detection (0.927-0.951 F1), and hallucination
correction (0.973-0.979 approval rate) manifest the great potential of Medico.
A video demo of Medico can be found at https://youtu.be/RtsO6CSesBI.

摘要：眾所周知，大型語言模型 (LLM) 盛行幻覺，其中產生的內容連貫但事實不正確，對 LLM 的廣泛應用造成沉重打擊。先前的研究表明，LLM 可以自信地陳述不存在的事實，而不是回答「我不知道」。因此，有必要訴諸外部知識來檢測和更正幻覺內容。由於人工檢測和更正事實錯誤非常耗費人力，因此開發一種自動化的端到端幻覺檢查方法確實是一件必要的事情。為此，我們提出了 Medico，一個多源證據融合增強的幻覺檢測和更正框架。它融合了來自多個來源的不同證據，檢測生成的內容是否包含事實錯誤，提供判斷背後的理由，並反覆修改幻覺內容。證據檢索（0.964 HR@5、0.908 MRR@5）、幻覺檢測（0.927-0.951 F1）和幻覺更正（0.973-0.979 認可率）的實驗結果證明了 Medico 的巨大潛力。可以在 https://youtu.be/RtsO6CSesBI 找到 Medico 的影片示範。

##### **MMCFND: Multimodal Multilingual Caption-aware Fake News Detection for Low-resource Indic Languages**
2410.10407v1 by Shubhi Bansal, Nishit Sushil Singh, Shahid Shafi Dar, Nagendra Kumar

The widespread dissemination of false information through manipulative
tactics that combine deceptive text and images threatens the integrity of
reliable sources of information. While there has been research on detecting
fake news in high resource languages using multimodal approaches, methods for
low resource Indic languages primarily rely on textual analysis. This
difference highlights the need for robust methods that specifically address
multimodal fake news in Indic languages, where the lack of extensive datasets
and tools presents a significant obstacle to progress. To this end, we
introduce the Multimodal Multilingual dataset for Indic Fake News Detection
(MMIFND). This meticulously curated dataset consists of 28,085 instances
distributed across Hindi, Bengali, Marathi, Malayalam, Tamil, Gujarati and
Punjabi. We further propose the Multimodal Multilingual Caption-aware framework
for Fake News Detection (MMCFND). MMCFND utilizes pre-trained unimodal encoders
and pairwise encoders from a foundational model that aligns vision and
language, allowing for extracting deep representations from visual and textual
components of news articles. The multimodal fusion encoder in the foundational
model integrates text and image representations derived from its pairwise
encoders to generate a comprehensive cross modal representation. Furthermore,
we generate descriptive image captions that provide additional context to
detect inconsistencies and manipulations. The retrieved features are then fused
and fed into a classifier to determine the authenticity of news articles. The
curated dataset can potentially accelerate research and development in low
resource environments significantly. Thorough experimentation on MMIFND
demonstrates that our proposed framework outperforms established methods for
extracting relevant fake news detection features.

摘要：<paragraph>透過結合具欺騙性的文字和圖片，以操弄手法廣泛散播錯誤資訊，威脅到可靠資訊來源的完整性。儘管有研究使用多模態方法偵測高資源語言中的假新聞，但低資源印度語言的方法主要依賴文字分析。這種差異凸顯了對健全方法的需求，特別是針對印度語言的多模態假新聞，其中缺乏廣泛的資料集和工具對進度構成重大障礙。為此，我們引入了印度假新聞偵測的多模態多語言資料集 (MMIFND)。這個經過仔細策展的資料集包含 28,085 個案例，分佈在印地語、孟加拉語、馬拉地語、馬拉雅拉姆語、泰米爾語、古吉拉特語和旁遮普語。我們進一步提出了用於假新聞偵測的多模態多語言標題感知框架 (MMCFND)。MMCFND 利用預先訓練的單模態編碼器和基礎模型中的成對編碼器，該模型會對齊視覺和語言，允許從新聞文章的視覺和文字元件中提取深度表徵。基礎模型中的多模態融合編碼器整合了從其成對編碼器衍生的文字和圖片表徵，以產生全面的跨模態表徵。此外，我們會產生描述性圖片標題，提供額外的脈絡以偵測不一致和操弄。然後將擷取到的特徵融合並輸入分類器，以確定新聞文章的真實性。經過策展的資料集有可能大幅加速低資源環境中的研究和開發。在 MMIFND 上的徹底實驗證明，我們提出的框架優於既定的方法，用於提取相關的假新聞偵測特徵。</paragraph>

##### **FairMindSim: Alignment of Behavior, Emotion, and Belief in Humans and LLM Agents Amid Ethical Dilemmas**
2410.10398v1 by Yu Lei, Hao Liu, Chengxing Xie, Songjia Liu, Zhiyu Yin, Canyu chen, Guohao Li, Philip Torr, Zhen Wu

AI alignment is a pivotal issue concerning AI control and safety. It should
consider not only value-neutral human preferences but also moral and ethical
considerations. In this study, we introduced FairMindSim, which simulates the
moral dilemma through a series of unfair scenarios. We used LLM agents to
simulate human behavior, ensuring alignment across various stages. To explore
the various socioeconomic motivations, which we refer to as beliefs, that drive
both humans and LLM agents as bystanders to intervene in unjust situations
involving others, and how these beliefs interact to influence individual
behavior, we incorporated knowledge from relevant sociological fields and
proposed the Belief-Reward Alignment Behavior Evolution Model (BREM) based on
the recursive reward model (RRM). Our findings indicate that, behaviorally,
GPT-4o exhibits a stronger sense of social justice, while humans display a
richer range of emotions. Additionally, we discussed the potential impact of
emotions on behavior. This study provides a theoretical foundation for
applications in aligning LLMs with altruistic values.

摘要：AI 對齊是關於 AI 控制和安全的一個核心議題。它不只應考量價值中立的人類偏好，也應考量道德和倫理考量。在本研究中，我們引入了 FairMindSim，它透過一系列不公平情境模擬道德兩難。我們使用 LLM 代理模擬人類行為，確保在各個階段的一致性。為了探索各種社會經濟動機（我們稱之為信念），這些動機驅使人類和 LLM 代理作為旁觀者介入涉及他人的不公正情況，以及這些信念如何互動以影響個人行為，我們納入了相關社會學領域的知識，並根據遞迴獎勵模型 (RRM) 提出信念獎勵對齊行為演化模型 (BREM)。我們的發現表明，在行為上，GPT-4o 表現出更強烈的社會正義感，而人類則表現出更豐富的情緒。此外，我們討論了情緒對行為的潛在影響。本研究為將 LLM 與利他價值觀對齊的應用提供了理論基礎。

##### **PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic Manipulation**
2410.10394v1 by Kaidong Zhang, Pengzhen Ren, Bingqian Lin, Junfan Lin, Shikui Ma, Hang Xu, Xiaodan Liang

Language-guided robotic manipulation is a challenging task that requires an
embodied agent to follow abstract user instructions to accomplish various
complex manipulation tasks. Previous work trivially fitting the data without
revealing the relation between instruction and low-level executable actions,
these models are prone to memorizing the surficial pattern of the data instead
of acquiring the transferable knowledge, and thus are fragile to dynamic
environment changes. To address this issue, we propose a PrIrmitive-driVen
waypOinT-aware world model for Robotic manipulation (PIVOT-R) that focuses
solely on the prediction of task-relevant waypoints. Specifically, PIVOT-R
consists of a Waypoint-aware World Model (WAWM) and a lightweight action
prediction module. The former performs primitive action parsing and
primitive-driven waypoint prediction, while the latter focuses on decoding
low-level actions. Additionally, we also design an asynchronous hierarchical
executor (AHE), which can use different execution frequencies for different
modules of the model, thereby helping the model reduce computational redundancy
and improve model execution efficiency. Our PIVOT-R outperforms
state-of-the-art (SoTA) open-source models on the SeaWave benchmark, achieving
an average relative improvement of 19.45% across four levels of instruction
tasks. Moreover, compared to the synchronously executed PIVOT-R, the execution
efficiency of PIVOT-R with AHE is increased by 28-fold, with only a 2.9% drop
in performance. These results provide compelling evidence that our PIVOT-R can
significantly improve both the performance and efficiency of robotic
manipulation.

摘要：<paragraph>語言導向的機器人操作是一項艱鉅的任務，它要求具身代理遵循抽象使用者指令來完成各種複雜的操作任務。先前的研究輕易地擬合資料，而沒有揭示指令與低階可執行動作之間的關係，這些模型容易記住資料的表面模式，而不是獲得可轉移的知識，因此容易受到動態環境變化的影響。為了解決這個問題，我們提出了一個用於機器人操作的原始驅動導航點感知世界模型 (PIVOT-R)，它僅專注於與任務相關的導航點的預測。具體來說，PIVOT-R 包含一個導航點感知世界模型 (WAWM) 和一個輕量級動作預測模組。前者執行原始動作解析和原始驅動導航點預測，而後者專注於解碼低階動作。此外，我們還設計了一個非同步階層執行器 (AHE)，它可以使用不同的執行頻率來處理模型的不同模組，從而幫助模型減少運算冗餘並提高模型執行效率。我們的 PIVOT-R 在 SeaWave 基準測試中優於最先進 (SoTA) 的開源模型，在四個層級的指令任務中平均相對改善了 19.45%。此外，與同步執行的 PIVOT-R 相比，使用 AHE 的 PIVOT-R 執行效率提高了 28 倍，效能僅下降了 2.9%。這些結果提供了令人信服的證據，證明我們的 PIVOT-R 可以顯著提高機器人操作的效能和效率。</paragraph>

##### **Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search**
2410.10392v1 by Chenglin Li, Qianglong Chen, Zhi Li, Feng Tao, Yicheng Li, Hao Chen, Fei Yu, Yin Zhang

Instruction tuning is a crucial technique for aligning language models with
humans' actual goals in the real world. Extensive research has highlighted the
quality of instruction data is essential for the success of this alignment.
However, creating high-quality data manually is labor-intensive and
time-consuming, which leads researchers to explore using LLMs to synthesize
data. Recent studies have focused on using a stronger LLM to iteratively
enhance existing instruction data, showing promising results. Nevertheless,
previous work often lacks control over the evolution direction, resulting in
high uncertainty in the data synthesis process and low-quality instructions. In
this paper, we introduce a general and scalable framework, IDEA-MCTS
(Instruction Data Enhancement using Monte Carlo Tree Search), a scalable
framework for efficiently synthesizing instructions. With tree search and
evaluation models, it can efficiently guide each instruction to evolve into a
high-quality form, aiding in instruction fine-tuning. Experimental results show
that IDEA-MCTS significantly enhances the seed instruction data, raising the
average evaluation scores of quality, diversity, and complexity from 2.19 to
3.81. Furthermore, in open-domain benchmarks, experimental results show that
IDEA-MCTS improves the accuracy of real-world instruction-following skills in
LLMs by an average of 5\% in low-resource settings.

摘要：指令調整是讓語言模型與人類在現實世界中的實際目標保持一致的關鍵技術。廣泛的研究強調了指令數據的品質對於此調整的成功至關重要。然而，手動建立高品質的數據需要大量人力且耗時，這促使研究人員探索使用大型語言模型 (LLM) 來合成數據。最近的研究專注於使用一個更強大的 LLM 來反覆增強現有的指令數據，並顯示出有希望的結果。儘管如此，先前的研究通常缺乏對演化方向的控制，導致數據合成過程的不確定性高且指令品質低。在本文中，我們介紹了一個通用且可擴充的架構 IDEA-MCTS（使用蒙地卡羅樹搜尋的指令數據增強），一個用於有效合成指令的可擴充架構。透過樹狀搜尋和評估模型，它可以有效引導每個指令演化為高品質的形式，有助於指令微調。實驗結果顯示 IDEA-MCTS 大幅增強了種子指令數據，將品質、多樣性和複雜性的平均評分從 2.19 提升至 3.81。此外，在開放領域基準測試中，實驗結果顯示 IDEA-MCTS 在低資源設定中將 LLM 中實際指令遵循技能的準確度平均提高了 5%。

##### **BookWorm: A Dataset for Character Description and Analysis**
2410.10372v1 by Argyrios Papoudakis, Mirella Lapata, Frank Keller

Characters are at the heart of every story, driving the plot and engaging
readers. In this study, we explore the understanding of characters in
full-length books, which contain complex narratives and numerous interacting
characters. We define two tasks: character description, which generates a brief
factual profile, and character analysis, which offers an in-depth
interpretation, including character development, personality, and social
context. We introduce the BookWorm dataset, pairing books from the Gutenberg
Project with human-written descriptions and analyses. Using this dataset, we
evaluate state-of-the-art long-context models in zero-shot and fine-tuning
settings, utilizing both retrieval-based and hierarchical processing for
book-length inputs. Our findings show that retrieval-based approaches
outperform hierarchical ones in both tasks. Additionally, fine-tuned models
using coreference-based retrieval produce the most factual descriptions, as
measured by fact- and entailment-based metrics. We hope our dataset,
experiments, and analysis will inspire further research in character-based
narrative understanding.

摘要：角色是每個故事的核心，推動情節發展並吸引讀者。在本研究中，我們探討了對全書中角色的理解，這些書包含複雜的敘述和眾多互動角色。我們定義了兩項任務：角色描述，它會產生簡短的事實簡介，以及角色分析，它提供了深入的詮釋，包括角色發展、個性以及社會背景。我們引入了 BookWorm 資料集，將古騰堡計畫中的書籍與人類撰寫的描述和分析配對。使用此資料集，我們在零次學習和微調設定中評估了最先進的長語境模型，利用基於檢索和階層式處理的書長輸入。我們的研究結果表明，基於檢索的方法在兩項任務中都優於階層式方法。此外，使用基於共指的檢索進行微調的模型會產生最符合事實的描述，這是根據基於事實和蘊涵的指標測量的。我們希望我們的資料集、實驗和分析能激勵在基於角色的敘事理解方面的進一步研究。

##### **Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps**
2410.10370v1 by Han Wang, Yilin Zhao, Dian Li, Xiaohan Wang, Gang Liu, Xuguang Lan, Hui Wang

Humor is a culturally nuanced aspect of human language that presents
challenges for understanding and generation, requiring participants to possess
good creativity and strong associative thinking. Similar to reasoning tasks
like solving math problems, humor generation requires continuous reflection and
revision to foster creative thinking, rather than relying on a sudden flash of
inspiration like Creative Leap-of-Thought (CLoT) paradigm. Although CLoT can
realize the ability of remote association generation, this paradigm fails to
generate humor content. Therefore, in this paper, we propose a systematic way
of thinking about generating humor and based on it, we built Creative Leap of
Structured Thought (CLoST) frame. First, a reward model is necessary achieve
the purpose of being able to correct errors, since there is currently no expert
model of humor and a usable rule to determine whether a piece of content is
humorous. Judgement-oriented instructions are designed to improve the
capability of a model, and we also propose an open-domain instruction
evolutionary method to fully unleash the potential. Then, through reinforcement
learning, the model learns to hone its rationales of the thought chain and
refine the strategies it uses. Thus, it learns to recognize and correct its
mistakes, and finally generate the most humorous and creative answer. These
findings deepen our understanding of the creative capabilities of LLMs and
provide ways to enhance LLMs' creative abilities for cross-domain innovative
applications.

摘要：幽默是人類語言中文化細微差別的一面，對理解和產生提出挑戰，需要參與者具備良好的創造力和強烈的聯想思維。類似於求解數學問題等推理任務，幽默產生需要持續的反思和修正，以培養創造性思維，而不是依賴於像創造性飛躍思考（CLoT）範例那樣的突然靈感。儘管 CLoT 可以實現遠程聯想產生的能力，但這種範例無法產生幽默內容。因此，在本文中，我們提出了一種系統性的思考方式來產生幽默，並基於此，我們建立了結構化思想創造性飛躍（CLoST）框架。首先，一個獎勵模型對於能夠糾正錯誤是必要的，因為目前沒有幽默專家模型和可用規則來確定一段內容是否幽默。面向判斷的指令旨在提高模型的能力，我們還提出了一個開放域指令演化方法，以充分發揮其潛力。然後，通過強化學習，模型學會磨練其思想鏈的依據並改進其使用的策略。因此，它學會了識別和糾正其錯誤，並最終產生最幽默和最具創造力的答案。這些發現加深了我們對 LLM 創造能力的理解，並提供了增強 LLM 的跨領域創新應用創造能力的方法。

##### **Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation**
2410.10366v1 by Zehua Cheng, Di Yuan, Thomas Lukasiewicz

The combination of semi-supervised learning (SemiSL) and contrastive learning
(CL) has been successful in medical image segmentation with limited
annotations. However, these works often rely on pretext tasks that lack the
specificity required for pixel-level segmentation, and still face overfitting
issues due to insufficient supervision signals resulting from too few
annotations. Therefore, this paper proposes an affinity-graph-guided
semi-supervised contrastive learning framework (Semi-AGCL) by establishing
additional affinity-graph-based supervision signals between the student and
teacher network, to achieve medical image segmentation with minimal annotations
without pretext. The framework first designs an average-patch-entropy-driven
inter-patch sampling method, which can provide a robust initial feature space
without relying on pretext tasks. Furthermore, the framework designs an
affinity-graph-guided loss function, which can improve the quality of the
learned representation and the model generalization ability by exploiting the
inherent structure of the data, thus mitigating overfitting. Our experiments
indicate that with merely 10% of the complete annotation set, our model
approaches the accuracy of the fully annotated baseline, manifesting a marginal
deviation of only 2.52%. Under the stringent conditions where only 5% of the
annotations are employed, our model exhibits a significant enhancement in
performance surpassing the second best baseline by 23.09% on the dice metric
and achieving an improvement of 26.57% on the notably arduous CRAG and ACDC
datasets.

摘要：半监督学习 (SemiSL) 和对比学习 (CL) 的结合已成功用于医疗图像分割，且标注有限。然而，这些工作通常依赖于缺乏像素级分割所需特异性的借口任务，并且由于标注太少导致监督信号不足，仍然面临过度拟合问题。因此，本文通过在学生网络和教师网络之间建立基于亲和图的附加监督信号，提出了一种亲和图引导的半监督对比学习框架 (Semi-AGCL)，以在没有借口的情况下实现医疗图像分割，且标注最少。该框架首先设计了一种平均补丁熵驱动的补丁间采样方法，该方法可以在不依赖借口任务的情况下提供鲁棒的初始特征空间。此外，该框架设计了一个亲和图引导的损失函数，该函数可以通过利用数据的固有结构来提高学习表示和模型泛化能力，从而减轻过度拟合。我们的实验表明，我们的模型仅使用 10% 的完整标注集，就接近了完全标注基准的准确度，仅有 2.52% 的边际偏差。在仅使用 5% 标注的严格条件下，我们的模型在性能上表现出显着提升，在骰子指标上比第二好的基准高出 23.09%，并在非常艰巨的 CRAG 和 ACDC 数据集上提高了 26.57%。

##### **SpeGCL: Self-supervised Graph Spectrum Contrastive Learning without Positive Samples**
2410.10365v1 by Yuntao Shou, Xiangyong Cao, Deyu Meng

Graph Contrastive Learning (GCL) excels at managing noise and fluctuations in
input data, making it popular in various fields (e.g., social networks, and
knowledge graphs). Our study finds that the difference in high-frequency
information between augmented graphs is greater than that in low-frequency
information. However, most existing GCL methods focus mainly on the time domain
(low-frequency information) for node feature representations and cannot make
good use of high-frequency information to speed up model convergence.
Furthermore, existing GCL paradigms optimize graph embedding representations by
pulling the distance between positive sample pairs closer and pushing the
distance between positive and negative sample pairs farther away, but our
theoretical analysis shows that graph contrastive learning benefits from
pushing negative pairs farther away rather than pulling positive pairs closer.
To solve the above-mentioned problems, we propose a novel spectral GCL
framework without positive samples, named SpeGCL. Specifically, to solve the
problem that existing GCL methods cannot utilize high-frequency information,
SpeGCL uses a Fourier transform to extract high-frequency and low-frequency
information of node features, and constructs a contrastive learning mechanism
in a Fourier space to obtain better node feature representation. Furthermore,
SpeGCL relies entirely on negative samples to refine the graph embedding. We
also provide a theoretical justification for the efficacy of using only
negative samples in SpeGCL. Extensive experiments on un-supervised learning,
transfer learning, and semi-supervised learning have validated the superiority
of our SpeGCL framework over the state-of-the-art GCL methods.

摘要：圖形對比學習 (GCL) 擅長處理輸入資料中的雜訊和波動，使其在各種領域（例如社群網路和知識圖譜）中普及。我們的研究發現，擴充圖形中高頻資訊的差異大於低頻資訊的差異。然而，現有的 GCL 方法大多主要關注時間域（低頻資訊）的節點特徵表示，無法充分利用高頻資訊來加速模型收斂。此外，現有的 GCL 典範透過拉近正樣本對之間的距離並推開正樣本對和負樣本對之間的距離來最佳化圖形嵌入表示，但我們的理論分析表明，圖形對比學習受益於將負樣本對推得更遠，而不是將正樣本對拉得更近。為了解決上述問題，我們提出了一個沒有正樣本的新穎光譜 GCL 架構，稱為 SpeGCL。具體來說，為了解決現有的 GCL 方法無法利用高頻資訊的問題，SpeGCL 使用傅立葉轉換來提取節點特徵的高頻和低頻資訊，並在傅立葉空間中建構一個對比學習機制，以獲得更好的節點特徵表示。此外，SpeGCL 完全依賴負樣本來改善圖形嵌入。我們也提供了僅在 SpeGCL 中使用負樣本的有效性的理論依據。在無監督學習、轉移學習和半監督學習上的廣泛實驗驗證了我們的 SpeGCL 架構優於最先進的 GCL 方法。

##### **Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning**
2410.10360v1 by Yongxin Xu, Ruizhe Zhang, Xinke Jiang, Yujie Feng, Yuzhen Xiao, Xinyu Ma, Runchuan Zhu, Xu Chu, Junfeng Zhao, Yasha Wang

Retrieval-Augmented Generation (RAG) offers an effective solution to the
issues faced by Large Language Models (LLMs) in hallucination generation and
knowledge obsolescence by incorporating externally retrieved knowledge.
However, due to potential conflicts between internal and external knowledge, as
well as retrieval noise, LLMs often struggle to effectively integrate external
evidence, leading to a decline in performance. Although existing methods
attempt to tackle these challenges, they often struggle to strike a balance
between model adherence and robustness, resulting in significant learning
variance. Inspired by human cognitive processes, we propose Parenting, a novel
framework that decouples adherence and robustness within the parameter space of
LLMs. Specifically, Parenting utilizes a key parameter mining method based on
forward activation gain to identify and isolate the crucial parameter units
that are strongly linked to adherence and robustness. Then, Parenting employs a
type-guided tailored tuning strategy, applying specific and appropriate
fine-tuning methods to parameter units representing different capabilities,
aiming to achieve a balanced enhancement of adherence and robustness. Extensive
experiments on various datasets and models validate the effectiveness and
generalizability of our methods.

摘要：检索增强生成 (RAG) 提供了一个有效的解决方案，用于解决大型语言模型 (LLM) 在幻觉生成和知识过时方面面临的问题，方法是结合外部检索的知识。然而，由于内部和外部知识之间潜在的冲突，以及检索噪声，LLM 经常难以有效地整合外部证据，从而导致性能下降。虽然现有方法试图解决这些挑战，但它们往往难以在模型的依从性和鲁棒性之间取得平衡，从而导致严重的学习差异。受人类认知过程的启发，我们提出了 Parenting，这是一个新颖的框架，它在 LLM 的参数空间内解耦了依从性和鲁棒性。具体来说，Parenting 利用了一种基于前向激活增益的关键参数挖掘方法来识别和隔离与依从性和鲁棒性密切相关的关键参数单元。然后，Parenting 采用类型指导的定制调整策略，对代表不同功能的参数单元应用特定且适当的微调方法，旨在实现依从性和鲁棒性的平衡增强。在各种数据集和模型上的广泛实验验证了我们方法的有效性和泛化性。

##### **LLM-based Code-Switched Text Generation for Grammatical Error Correction**
2410.10349v1 by Tom Potter, Zheng Yuan

With the rise of globalisation, code-switching (CSW) has become a ubiquitous
part of multilingual conversation, posing new challenges for natural language
processing (NLP), especially in Grammatical Error Correction (GEC). This work
explores the complexities of applying GEC systems to CSW texts. Our objectives
include evaluating the performance of state-of-the-art GEC systems on an
authentic CSW dataset from English as a Second Language (ESL) learners,
exploring synthetic data generation as a solution to data scarcity, and
developing a model capable of correcting grammatical errors in monolingual and
CSW texts. We generated synthetic CSW GEC data, resulting in one of the first
substantial datasets for this task, and showed that a model trained on this
data is capable of significant improvements over existing systems. This work
targets ESL learners, aiming to provide educational technologies that aid in
the development of their English grammatical correctness without constraining
their natural multilingualism.

摘要：隨著全球化的興起，代碼切換（CSW）已成為多語言對話中普遍存在的一部分，對自然語言處理（NLP）提出了新的挑戰，特別是在語法錯誤校正（GEC）中。這項工作探討了將 GEC 系統應用於 CSW 文本的複雜性。我們的目標包括評估最先進的 GEC 系統在以英語為第二語言（ESL）學習者的真實 CSW 數據集上的性能，探索合成數據生成作為解決數據稀缺的解決方案，以及開發一種能夠校正單語和 CSW 文本中語法錯誤的模型。我們生成了合成 CSW GEC 數據，構成了此任務的第一批實質性數據集之一，並表明在這些數據上訓練的模型能夠比現有系統顯著改進。這項工作針對 ESL 學習者，旨在提供教育技術，在不限制其自然多語言能力的情況下，幫助他們發展英語語法正確性。

##### **Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement**
2410.10348v1 by Joseph Shtok, Amit Alfassy, Foad Abo Dahood, Eliyahu Schwartz, Sivan Doveh, Assaf Arbelle

It has been shown that Large Language Models' (LLMs) performance can be
improved for many tasks using Chain of Thought (CoT) or In-Context Learning
(ICL), which involve demonstrating the steps needed to solve a task using a few
examples. However, while datasets with input-output pairs are relatively easy
to produce, providing demonstrations which include intermediate steps requires
cumbersome manual work. These steps may be executable programs, as in agentic
flows, or step-by-step reasoning as in CoT. In this work, we propose Automatic
Data Labeling and Refinement (ADLR), a method to automatically generate and
filter demonstrations which include the above intermediate steps, starting from
a small seed of manually crafted examples. We demonstrate the advantage of ADLR
in code-based table QA and mathematical reasoning, achieving up to a 5.5% gain.
The code implementing our method is provided in the Supplementary material and
will be made available.

摘要：研究表明，透過思想鏈（CoT）或情境學習（ICL）可以改善大型語言模型（LLM）的許多任務表現，這涉及展示使用幾個範例解決任務所需的步驟。然而，雖然具有輸入輸出配對的資料集相對容易產生，但提供包含中間步驟的範例需要繁瑣的手動工作。這些步驟可能是可執行程式，例如代理流程，或如 CoT 中的逐步推理。在這項工作中，我們提出自動資料標記和精煉（ADLR），這是一種方法，可以從少量手動製作範例開始，自動產生和過濾包含上述中間步驟的範例。我們在基於程式碼的表格問答和數學推理中展示了 ADLR 的優點，獲得了高達 5.5% 的增益。實作我們方法的程式碼提供在補充資料中，並將公開。

##### **A Unified Approach to Routing and Cascading for LLMs**
2410.10347v1 by Jasper Dekoninck, Maximilian Baader, Martin Vechev

The widespread applicability of large language models (LLMs) has increased
the availability of many fine-tuned models of various sizes targeting specific
tasks. Given a set of such specialized models, to maximize overall performance,
it is important to figure out the optimal strategy for selecting the right
model for a given user query. An effective strategy could drastically increase
overall performance and even offer improvements over a single large monolithic
model. Existing approaches typically fall into two categories: routing, where a
single model is selected for each query, and cascading, which runs a sequence
of increasingly larger models until a satisfactory answer is obtained. However,
both have notable limitations: routing commits to an initial model without
flexibility, while cascading requires executing every model in sequence, which
can be inefficient. Additionally, the conditions under which these strategies
are provably optimal remain unclear. In this work, we derive optimal strategies
for both routing and cascading. Building on this analysis, we propose a novel
approach called cascade routing, which combines the adaptability of routing
with the cost-efficiency of cascading. Our experiments demonstrate that cascade
routing consistently outperforms both routing and cascading across a variety of
settings, improving both output quality and lowering computational cost, thus
offering a unified and efficient solution to the model selection problem.

摘要：大型語言模型 (LLM) 的廣泛應用性提高了各種尺寸的許多微調模型的可用性，這些模型針對特定任務。給定一組這樣的專業模型，為了最大化整體效能，找出為特定使用者查詢選擇正確模型的最佳策略非常重要。一個有效的策略可以大幅提升整體效能，甚至比單一大型單體模型有更好的表現。現有的方法通常分為兩類：路由，其中為每個查詢選擇一個模型；串聯，其中執行一系列越來越大的模型，直到獲得令人滿意的答案。然而，這兩種方法都有顯著的限制：路由在沒有彈性的情況下承諾使用一個初始模型，而串聯需要按順序執行每個模型，這可能會很沒有效率。此外，這些策略在哪些條件下可以證明是最佳的仍然不清楚。在這項工作中，我們推導出路由和串聯的最佳策略。在此分析的基礎上，我們提出了一種稱為串聯路由的新方法，它結合了路由的適應性和串聯的成本效益。我們的實驗表明，串聯路由在各種設定中都持續優於路由和串聯，既提高了輸出品質，又降低了運算成本，從而為模型選擇問題提供了一個統一且有效的解決方案。

##### **Locking Down the Finetuned LLMs Safety**
2410.10343v1 by Minjun Zhu, Linyi Yang, Yifan Wei, Ningyu Zhang, Yue Zhang

Fine-tuning large language models (LLMs) on additional datasets is often
necessary to optimize them for specific downstream tasks. However, existing
safety alignment measures, which restrict harmful behavior during inference,
are insufficient to mitigate safety risks during fine-tuning. Alarmingly,
fine-tuning with just 10 toxic sentences can make models comply with harmful
instructions. We introduce SafetyLock, a novel alignment intervention method
that maintains robust safety post-fine-tuning through efficient and
transferable mechanisms. SafetyLock leverages our discovery that fine-tuned
models retain similar safety-related activation representations to their base
models. This insight enables us to extract what we term the Meta-SafetyLock, a
set of safety bias directions representing key activation patterns associated
with safe responses in the original model. We can then apply these directions
universally to fine-tuned models to enhance their safety. By searching for
activation directions across multiple token dimensions, SafetyLock achieves
enhanced robustness and transferability. SafetyLock re-aligns fine-tuned models
in under 0.01 seconds without additional computational cost. Our experiments
demonstrate that SafetyLock can reduce the harmful instruction response rate
from 60% to below 1% in toxic fine-tuned models. It surpasses traditional
methods in both performance and efficiency, offering a scalable, non-invasive
solution for ensuring the safety of customized LLMs. Our analysis across
various fine-tuning scenarios confirms SafetyLock's robustness, advocating its
integration into safety protocols for aligned LLMs. The code is released at
https://github.com/zhu-minjun/SafetyLock.

摘要：微调大型语言模型 (LLM) 以用于其他数据集通常有必要针对特定下游任务对其进行优化。然而，现有的安全对齐措施（在推理期间限制有害行为）不足以减轻微调期间的安全风险。令人担忧的是，仅使用 10 个有毒句子进行微调就能使模型遵守有害指令。我们引入了 SafetyLock，这是一种新颖的对齐干预方法，通过高效且可转移的机制在微调后保持强大的安全性。SafetyLock 利用了我们发现微调模型保留了与其基础模型类似的安全相关激活表示。这一见解使我们能够提取我们称之为 Meta-SafetyLock 的东西，这是一组安全偏差方向，代表与原始模型中的安全响应相关联的关键激活模式。然后，我们可以将这些方向普遍应用于微调模型以增强其安全性。通过在多个标记维度上搜索激活方向，SafetyLock 实现了增强的鲁棒性和可转移性。SafetyLock 在不到 0.01 秒的时间内重新对齐微调模型，而无需额外的计算成本。我们的实验表明，SafetyLock 可以将有害指令响应率从 60% 降低到有毒微调模型中的 1% 以下。它在性能和效率方面都超越了传统方法，为确保定制 LLM 的安全性提供了一个可扩展的、非侵入性的解决方案。我们对各种微调场景的分析证实了 SafetyLock 的稳健性，提倡将其集成到对齐 LLM 的安全协议中。代码已在 https://github.com/zhu-minjun/SafetyLock 中发布。

##### **CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning**
2410.10336v1 by Joshua Ong Jun Leang, Aryo Pradipta Gema, Shay B. Cohen

Mathematical reasoning remains a significant challenge for large language
models (LLMs), despite progress in prompting techniques such as
Chain-of-Thought (CoT). We present Chain of Mathematically Annotated Thought
(CoMAT), which enhances reasoning through two stages: Symbolic Conversion
(converting natural language queries into symbolic form) and Reasoning
Execution (deriving answers from symbolic representations). CoMAT operates
entirely with a single LLM and without external solvers. Across four LLMs,
CoMAT outperforms traditional CoT on six out of seven benchmarks, achieving
gains of 4.48% on MMLU-Redux (MATH) and 4.58% on GaoKao MCQ. In addition to
improved performance, CoMAT ensures faithfulness and verifiability, offering a
transparent reasoning process for complex mathematical tasks

摘要：儘管在提示技術（例如思想鏈（CoT））方面取得進展，數學推理對於大型語言模型（LLM）而言仍然是一項重大的挑戰。我們提出數學標記思想鏈（CoMAT），它透過兩個階段增強推理：符號轉換（將自然語言查詢轉換成符號形式）和推理執行（從符號表示中推導出答案）。CoMAT 完全使用單一 LLM，且不使用外部求解器。在四個 LLM 中，CoMAT 在七個基準中的六個基準上優於傳統 CoT，在 MMLU-Redux（MATH）上獲得 4.48% 的增益，在高考選擇題上獲得 4.58% 的增益。除了效能提升之外，CoMAT 確保了忠實度和可驗證性，為複雜的數學任務提供了透明的推理過程

##### **Disentangling Hate Across Target Identities**
2410.10332v1 by Yiping Jin, Leo Wanner, Aneesh Moideen Koya

Hate speech (HS) classifiers do not perform equally well in detecting hateful
expressions towards different target identities. They also demonstrate
systematic biases in predicted hatefulness scores. Tapping on two recently
proposed functionality test datasets for HS detection, we quantitatively
analyze the impact of different factors on HS prediction. Experiments on
popular industrial and academic models demonstrate that HS detectors assign a
higher hatefulness score merely based on the mention of specific target
identities. Besides, models often confuse hatefulness and the polarity of
emotions. This result is worrisome as the effort to build HS detectors might
harm the vulnerable identity groups we wish to protect: posts expressing anger
or disapproval of hate expressions might be flagged as hateful themselves. We
also carry out a study inspired by social psychology theory, which reveals that
the accuracy of hatefulness prediction correlates strongly with the intensity
of the stereotype.

摘要：仇恨言論 (HS) 分類器在偵測針對不同目標身分的仇恨言論時，表現並不相同。它們在預測的仇恨分數中也表現出系統性的偏見。利用最近提出的兩個 HS 偵測功能測試資料集，我們定量分析了不同因素對 HS 預測的影響。在熱門產業和學術模型上的實驗證明，HS 偵測器僅根據特定目標身分的提及，就分配了較高的仇恨分數。此外，模型經常混淆仇恨和情緒的極性。這個結果令人擔憂，因為建立 HS 偵測器的努力可能會傷害我們希望保護的弱勢身分群體：表達憤怒或不認同仇恨言論的貼文可能會被標記為仇恨言論。我們還進行了一項受社會心理學理論啟發的研究，結果顯示仇恨預測的準確性與刻板印象的強度密切相關。

##### **GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**
2410.10329v2 by Yun Zhu, Haizhou Shi, Xiaotang Wang, Yongchao Liu, Yaoke Wang, Boci Peng, Chuntao Hong, Siliang Tang

Recently, research on Text-Attributed Graphs (TAGs) has gained significant
attention due to the prevalence of free-text node features in real-world
applications and the advancements in Large Language Models (LLMs) that bolster
TAG methodologies. However, current TAG approaches face two primary challenges:
(i) Heavy reliance on label information and (ii) Limited cross-domain
zero/few-shot transferability. These issues constrain the scaling of both data
and model size, owing to high labor costs and scaling laws, complicating the
development of graph foundation models with strong transferability. In this
work, we propose the GraphCLIP framework to address these challenges by
learning graph foundation models with strong cross-domain zero/few-shot
transferability through a self-supervised contrastive graph-summary pretraining
method. Specifically, we generate and curate large-scale graph-summary pair
data with the assistance of LLMs, and introduce a novel graph-summary
pretraining method, combined with invariant learning, to enhance graph
foundation models with strong cross-domain zero-shot transferability. For
few-shot learning, we propose a novel graph prompt tuning technique aligned
with our pretraining objective to mitigate catastrophic forgetting and minimize
learning costs. Extensive experiments show the superiority of GraphCLIP in both
zero-shot and few-shot settings, while evaluations across various downstream
tasks confirm the versatility of GraphCLIP. Our code is available at:
https://github.com/ZhuYun97/GraphCLIP

摘要：最近，文本属性图（TAG）的研究由于现实世界应用中自由文本节点特征的普遍性以及支持 TAG 方法的大语言模型（LLM）的进步而备受关注。然而，当前的 TAG 方法面临两大主要挑战：(i) 对标签信息的严重依赖，以及 (ii) 跨域零/小样本可迁移性的受限。由于高昂的人力成本和规模化定律，这些问题限制了数据和模型规模的扩展，使得具有强大可迁移性的图基础模型的开发变得复杂。在这项工作中，我们提出了 GraphCLIP 框架，通过自监督对比图摘要预训练方法来学习具有强大跨域零/小样本可迁移性的图基础模型，以应对这些挑战。具体来说，我们借助 LLM 生成并整理了大规模图摘要对数据，并引入了一种新颖的图摘要预训练方法，结合不变性学习，以增强具有强大跨域零样本可迁移性的图基础模型。对于小样本学习，我们提出了一种新颖的图提示调整技术，该技术与我们的预训练目标一致，以减轻灾难性遗忘并最大程度地降低学习成本。大量的实验表明，GraphCLIP 在零样本和小样本设置中都具有优越性，同时对各种下游任务的评估证实了 GraphCLIP 的多功能性。我们的代码可在以下位置获得：
https://github.com/ZhuYun97/GraphCLIP

##### **MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media**
2410.10323v1 by Wei Zhai, Nan Bai, Qing Zhao, Jianqiang Li, Fan Wang, Hongzhi Qi, Meng Jiang, Xiaoqin Wang, Bing Xiang Yang, Guanghui Fu

As the prevalence of mental health challenges, social media has emerged as a
key platform for individuals to express their emotions.Deep learning tends to
be a promising solution for analyzing mental health on social media. However,
black box models are often inflexible when switching between tasks, and their
results typically lack explanations. With the rise of large language models
(LLMs), their flexibility has introduced new approaches to the field. Also due
to the generative nature, they can be prompted to explain decision-making
processes. However, their performance on complex psychological analysis still
lags behind deep learning. In this paper, we introduce the first multi-task
Chinese Social Media Interpretable Mental Health Instructions (C-IMHI) dataset,
consisting of 9K samples, which has been quality-controlled and manually
validated. We also propose MentalGLM series models, the first open-source LLMs
designed for explainable mental health analysis targeting Chinese social media,
trained on a corpus of 50K instructions. The proposed models were evaluated on
three downstream tasks and achieved better or comparable performance compared
to deep learning models, generalized LLMs, and task fine-tuned LLMs. We
validated a portion of the generated decision explanations with experts,
showing promising results. We also evaluated the proposed models on a clinical
dataset, where they outperformed other LLMs, indicating their potential
applicability in the clinical field. Our models show strong performance,
validated across tasks and perspectives. The decision explanations enhance
usability and facilitate better understanding and practical application of the
models. Both the constructed dataset and the models are publicly available via:
https://github.com/zwzzzQAQ/MentalGLM.

摘要：<paragraph>隨著心理健康挑戰的普遍性，社群媒體已成為個人表達情緒的一個關鍵平台。深度學習往往是分析社群媒體上心理健康的解決方案。然而，黑盒模型在任務間切換時通常缺乏彈性，而其結果通常缺乏解釋。隨著大型語言模型 (LLM) 的興起，它們的靈活性為該領域引入了新的方法。由於生成式特性，它們可以被提示解釋決策制定過程。然而，它們在複雜心理分析上的表現仍落後於深度學習。在本文中，我們介紹第一個多任務中文社群媒體可解釋心理健康說明 (C-IMHI) 資料集，其中包含 9K 個樣本，經過品質控管和手動驗證。我們還提出 MentalGLM 系列模型，這是第一個針對中文社群媒體的可解釋心理健康分析而設計的開源 LLM，並在 50K 個說明的語料庫上進行訓練。所提出的模型在三個下游任務上進行評估，與深度學習模型、廣義 LLM 和任務微調 LLM 相比，取得了更好或相當的表現。我們與專家驗證了部分產生的決策說明，顯示出有希望的結果。我們還針對臨床資料集評估所提出的模型，它們的表現優於其他 LLM，顯示出它們在臨床領域的潛在適用性。我們的模型展現出強勁的表現，在任務和觀點上都得到驗證。決策說明增強了可用性，並促進了對模型的更佳理解和實際應用。建構的資料集和模型都可透過以下網址公開取得：https://github.com/zwzzzQAQ/MentalGLM。</paragraph>

##### **EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations**
2410.10315v2 by Zhangchi Feng, Dongdong Kuang, Zhongyuan Wang, Zhijie Nie, Yaowei Zheng, Richong Zhang

This paper presents EasyRAG, a simple, lightweight, and efficient
retrieval-augmented generation framework for automated network operations. Our
framework has three advantages. The first is accurate question answering. We
designed a straightforward RAG scheme based on (1) a specific data processing
workflow (2) dual-route sparse retrieval for coarse ranking (3) LLM Reranker
for reranking (4) LLM answer generation and optimization. This approach
achieved first place in the GLM4 track in the preliminary round and second
place in the GLM4 track in the semifinals. The second is simple deployment. Our
method primarily consists of BM25 retrieval and BGE-reranker reranking,
requiring no fine-tuning of any models, occupying minimal VRAM, easy to deploy,
and highly scalable; we provide a flexible code library with various search and
generation strategies, facilitating custom process implementation. The last one
is efficient inference. We designed an efficient inference acceleration scheme
for the entire coarse ranking, reranking, and generation process that
significantly reduces the inference latency of RAG while maintaining a good
level of accuracy; each acceleration scheme can be plug-and-play into any
component of the RAG process, consistently enhancing the efficiency of the RAG
system. Our code and data are released at
\url{https://github.com/BUAADreamer/EasyRAG}.

摘要：本文提出了 EasyRAG，一個簡單、輕量且高效的檢索增強生成框架，用於自動化網路操作。我們的框架有三個優點。第一個是精確的問答。我們設計了一個基於 (1) 特定資料處理工作流程 (2) 雙路徑稀疏檢索用於粗略排序 (3) LLM Reranker 用於重新排序 (4) LLM 答案生成和最佳化的直接 RAG 架構。此方法在預賽中獲得 GLM4 軌道第一名，在準決賽中獲得 GLM4 軌道第二名。第二個是簡單的部署。我們的技術主要包含 BM25 檢索和 BGE-reranker 重新排序，不需要微調任何模型，佔用最少的 VRAM，易於部署且高度可擴充；我們提供一個靈活的程式碼庫，包含各種搜尋和生成策略，便於自訂流程實作。最後一個是有效率的推論。我們設計了一個有效的推論加速架構，用於整個粗略排序、重新排序和生成流程，在維持良好精確度的同時，大幅降低 RAG 的推論延遲；每個加速架構都可以即插即用於 RAG 流程的任何組成部分，持續提升 RAG 系統的效率。我們的程式碼和資料已發佈於
\url{https://github.com/BUAADreamer/EasyRAG}。

##### **A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification**
2410.10303v1 by Aryan Singhal, Veronica Shao, Gary Sun, Ryan Ding, Jonathan Lu, Kevin Zhu

The rise of digital misinformation has heightened interest in using
multilingual Large Language Models (LLMs) for fact-checking. This study
systematically evaluates translation bias and the effectiveness of LLMs for
cross-lingual claim verification across 15 languages from five language
families: Romance, Slavic, Turkic, Indo-Aryan, and Kartvelian. Using the XFACT
dataset to assess their impact on accuracy and bias, we investigate two
distinct translation methods: pre-translation and self-translation. We use
mBERT's performance on the English dataset as a baseline to compare
language-specific accuracies. Our findings reveal that low-resource languages
exhibit significantly lower accuracy in direct inference due to
underrepresentation in the training data. Furthermore, larger models
demonstrate superior performance in self-translation, improving translation
accuracy and reducing bias. These results highlight the need for balanced
multilingual training, especially in low-resource languages, to promote
equitable access to reliable fact-checking tools and minimize the risk of
spreading misinformation in different linguistic contexts.

摘要：數位錯誤資訊的興起，加劇了人們對於使用多語言大型語言模型 (LLM) 進行事實查核的興趣。本研究系統性地評估了翻譯偏差以及 LLM 在 15 種語言中進行跨語言聲明驗證的有效性，這些語言來自五個語言家族：羅曼語族、斯拉夫語族、突厥語族、印度-雅利安語族和卡特維爾語族。我們使用 XFACT 資料集來評估它們對準確性和偏差的影響，並研究了兩種不同的翻譯方法：預翻譯和自翻譯。我們使用 mBERT 在英語資料集上的表現作為基準，來比較特定語言的準確性。我們的研究結果顯示，由於在訓練資料中代表性不足，低資源語言在直接推論中表現出顯著較低的準確性。此外，較大的模型在自翻譯中表現出優異的表現，提高了翻譯準確性並減少了偏差。這些結果突顯了平衡多語言訓練的必要性，特別是在低資源語言中，以促進對可靠事實查核工具的公平使用，並最大程度地降低在不同語言環境中散布錯誤資訊的風險。

##### **FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG**
2410.10293v1 by Xinping Zhao, Yan Zhong, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Dongfang Li, Baotian Hu, Min Zhang

Retrieval-Augmented Generation (RAG) prevails in Large Language Models. It
mainly consists of retrieval and generation. The retrieval modules (a.k.a.
retrievers) aim to find useful information used to facilitate generation
modules (a.k.a. generators). As such, generators' performance largely depends
on the effectiveness and efficiency of retrievers. However, the retrieval
paradigm that we design and use remains flat, which treats the retrieval
procedures as a one-off deal with constant granularity. Despite effectiveness,
we argue that they suffer from two limitations: (1) flat retrieval exerts a
significant burden on one retriever; (2) constant granularity limits the
ceiling of retrieval performance. In this work, we propose a progressive
retrieval paradigm with coarse-to-fine granularity for RAG, termed FunnelRAG,
so as to balance effectiveness and efficiency. Specifically, FunnelRAG
establishes a progressive retrieval pipeline by collaborating coarse-to-fine
granularity, large-to-small quantity, and low-to-high capacity, which can
relieve the burden on one retriever and also promote the ceiling of retrieval
performance. Extensive experiments manifest that FunnelRAG achieves comparable
retrieval performance while the time overhead is reduced by nearly 40 percent.

摘要：擷取增強生成（RAG）在大型語言模型中盛行。它主要包含擷取和生成。擷取模組（又稱擷取器）旨在尋找用於促進生成模組（又稱生成器）的有用資訊。因此，生成器的效能很大程度取決於擷取器的效能和效率。然而，我們設計和使用的擷取範例仍然是平面的，它將擷取程序視為一次性處理，且具有恆定粒度。儘管有效，但我們認為它們有兩個限制：(1) 平面擷取對單一擷取器造成重大負擔；(2) 恆定粒度限制了擷取效能的上限。在這項工作中，我們為 RAG 提出了一個具有粗到細粒度的漸進式擷取範例，稱為 FunnelRAG，以便平衡效能和效率。具體來說，FunnelRAG 通過協調粗到細的粒度、大到小的數量以及低到高的容量來建立漸進式擷取管道，這可以減輕單一擷取器的負擔，並提升擷取效能的上限。廣泛的實驗表明，FunnelRAG 達到了相當的擷取效能，同時將時間開銷減少了將近 40%。

##### **Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective**
2410.10291v1 by Xiangru Zhu, Penglei Sun, Yaoxian Song, Yanghua Xiao, Zhixu Li, Chengyu Wang, Jun Huang, Bei Yang, Xiaoxiao Xu

Accurate interpretation and visualization of human instructions are crucial
for text-to-image (T2I) synthesis. However, current models struggle to capture
semantic variations from word order changes, and existing evaluations, relying
on indirect metrics like text-image similarity, fail to reliably assess these
challenges. This often obscures poor performance on complex or uncommon
linguistic patterns by the focus on frequent word combinations. To address
these deficiencies, we propose a novel metric called SemVarEffect and a
benchmark named SemVarBench, designed to evaluate the causality between
semantic variations in inputs and outputs in T2I synthesis. Semantic variations
are achieved through two types of linguistic permutations, while avoiding
easily predictable literal variations. Experiments reveal that the
CogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.
Semantic variations in object relations are less understood than attributes,
scoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in
UNet or Transformers plays a crucial role in handling semantic variations, a
factor previously overlooked by a focus on textual encoders. Our work
establishes an effective evaluation framework that advances the T2I synthesis
community's exploration of human instruction understanding.

摘要：準確的詮釋和視覺化人類的指示對於文本到影像 (T2I) 的合成至關重要。然而，目前的模型難以捕捉詞序變化的語義變異，而現有的評估依賴於文字影像相似度等間接指標，無法可靠地評估這些挑戰。這常常因為專注於頻繁的詞彙組合，而模糊了在複雜或不常見的語言模式上的糟糕表現。為了解決這些缺陷，我們提出了一個名為 SemVarEffect 的新指標和一個名為 SemVarBench 的基準，旨在評估 T2I 合成中輸入和輸出語義變異之間的因果關係。語義變異是透過兩種語言排列類型來實現的，同時避免了容易預測的字面變異。實驗表明 CogView-3-Plus 和 Ideogram 2 表現最佳，獲得 0.2/1 的分數。與 0.17-0.19/1 相比，物件關係中的語義變異比屬性更難理解，得分為 0.07/1。我們發現 UNet 或 Transformer 中的跨模態對齊在處理語義變異中扮演著至關重要的角色，這是一個以前被專注於文字編碼器所忽略的因素。我們的研究建立了一個有效的評估框架，促進了 T2I 合成社群對人類指令理解的探索。

##### **A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets**
2410.10290v1 by Nikolaos Mylonas, Nikolaos Stylianou, Theodora Tsikrika, Stefanos Vrochidis, Ioannis Kompatsiaris

Interpretability is a topic that has been in the spotlight for the past few
years. Most existing interpretability techniques produce interpretations in the
form of rules or feature importance. These interpretations, while informative,
may be harder to understand for non-expert users and therefore, cannot always
be considered as adequate explanations. To that end, explanations in natural
language are often preferred, as they are easier to comprehend and also more
presentable to end-users. This work introduces an early concept for a novel
pipeline that can be used in text classification tasks, offering predictions
and explanations in natural language. It comprises of two models: a classifier
for labelling the text and an explanation generator which provides the
explanation. The proposed pipeline can be adopted by any text classification
task, given that ground truth rationales are available to train the explanation
generator. Our experiments are centred around the tasks of sentiment analysis
and offensive language identification in Greek tweets, using a Greek Large
Language Model (LLM) to obtain the necessary explanations that can act as
rationales. The experimental evaluation was performed through a user study
based on three different metrics and achieved promising results for both
datasets.

摘要：可解釋性是過去幾年備受關注的主題。大多數現有的可解釋性技術以規則或特徵重要性的形式產生解釋。這些解釋雖然具有資訊性，但對於非專家使用者來說可能較難理解，因此並不總是能被視為充分的解釋。為了解決這個問題，通常優先採用自然語言的解釋，因為它們更容易理解，而且對最終使用者來說也更易於呈現。這項工作介紹了一個新穎管線的早期概念，可用於文字分類任務，提供自然語言中的預測和解釋。它包含兩個模型：一個用於標記文字的分類器和一個提供解釋的解釋產生器。只要有基本原理可用於訓練解釋產生器，所提出的管線就可以被任何文字分類任務採用。我們的實驗主要集中在希臘推文的情緒分析和攻擊性語言識別任務，使用希臘大型語言模型 (LLM) 來取得必要的解釋，這些解釋可以作為基本原理。實驗評估是透過使用者研究進行，基於三個不同的指標，並針對兩個資料集獲得了有希望的結果。

##### **ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge**
2410.10285v1 by Meerzhan Kanatbekova, Shashikant Ilager, Ivona Brandic

In recent years, Edge AI has become more prevalent with applications across
various industries, from environmental monitoring to smart city management.
Edge AI facilitates the processing of Internet of Things (IoT) data and
provides privacy-enabled and latency-sensitive services to application users
using Machine Learning (ML) algorithms, e.g., Time Series Classification (TSC).
However, existing TSC algorithms require access to full raw data and demand
substantial computing resources to train and use them effectively in runtime.
This makes them impractical for deployment in resource-constrained Edge
environments. To address this, in this paper, we propose an Adaptive Brownian
Bridge-based Symbolic Aggregation Vector Space Model (ABBA-VSM). It is a new
TSC model designed for classification services on Edge. Here, we first
adaptively compress the raw time series into symbolic representations, thus
capturing the changing trends of data. Subsequently, we train the
classification model directly on these symbols. ABBA-VSM reduces communication
data between IoT and Edge devices, as well as computation cycles, in the
development of resource-efficient TSC services on Edge. We evaluate our
solution with extensive experiments using datasets from the UCR time series
classification archive. The results demonstrate that the ABBA-VSM achieves up
to 80% compression ratio and 90-100% accuracy for binary classification.
Whereas, for non-binary classification, it achieves an average compression
ratio of 60% and accuracy ranging from 60-80%.

摘要：<paragraph>近年來，邊緣 AI 在各產業的應用越來越普遍，從環境監測到智慧城市管理皆有其應用。
邊緣 AI 透過機器學習（ML）演算法，例如時間序列分類（TSC），促進物聯網（IoT）資料的處理，並提供注重隱私且對延遲敏感的服務給應用程式使用者。
然而，現有的 TSC 演算法需要存取完整的原始資料，並需要大量的運算資源才能在執行階段有效地訓練和使用它們。
這使得它們不適合部署在資源受限的邊緣環境中。為了解決這個問題，我們在本文中提出了一種基於自適應布朗橋的符號聚合向量空間模型（ABBA-VSM）。它是一種新的 TSC 模型，專為邊緣的分類服務而設計。在這裡，我們首先自適應地將原始時間序列壓縮成符號表示，從而捕捉資料的變化趨勢。隨後，我們直接在這些符號上訓練分類模型。ABBA-VSM 減少了物聯網和邊緣裝置之間的通訊資料，以及在邊緣開發資源節省的 TSC 服務中的運算週期。我們使用 UCR 時間序列分類檔案館中的資料集進行廣泛的實驗來評估我們的解決方案。結果表明，ABBA-VSM 在二元分類中實現了高達 80% 的壓縮比和 90-100% 的準確度。
至於非二元分類，它實現了 60% 的平均壓縮比，準確度在 60-80% 之間。</paragraph>

##### **Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis**
2410.10278v1 by Hongjian Yu, Yiming Shi, Zherui Zhou, Christopher Haberland

We introduce a FLORES+ dataset as an evaluation benchmark for modern Wu
Chinese machine translation models and showcase its compatibility with existing
Wu data. Wu Chinese is mutually unintelligible with other Sinitic languages
such as Mandarin and Yue (Cantonese), but uses a set of Hanzi (Chinese
characters) that profoundly overlaps with others. The population of Wu speakers
is the second largest among languages in China, but the language has been
suffering from significant drop in usage especially among the younger
generations. We identify Wu Chinese as a textually low-resource language and
address challenges for its machine translation models. Our contributions
include: (1) an open-source, manually translated dataset, (2) full
documentations on the process of dataset creation and validation experiments,
(3) preliminary tools for Wu Chinese normalization and segmentation, and (4)
benefits and limitations of our dataset, as well as implications to other
low-resource languages.

摘要：我們引入 FLORES+ 資料集作為現代吳語機器翻譯模型的評估基準，並展示其與現有吳語資料的相容性。吳語與其他漢語族語言（如普通話和粵語）互不理解，但使用一套與其他語言高度重疊的漢字（中文漢字）。吳語使用者人口數量在中國語言中排名第二，但該語言的使用率大幅下降，特別是在年輕一代中。我們將吳語認定為文字資源匱乏的語言，並解決其機器翻譯模型的挑戰。我們的貢獻包括：(1) 一個開源、人工翻譯的資料集，(2) 關於資料集建立和驗證實驗過程的完整文件，(3) 吳語標準化和分詞的初步工具，以及 (4) 我們的資料集的優點和限制，以及對其他資源匱乏語言的影響。

