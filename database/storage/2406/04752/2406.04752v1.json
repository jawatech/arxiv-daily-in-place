{"2406.04752": {"publish_time": "2024-06-07", "title": "CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models", "paper_summary": "Large language models (LLMs) are possessed of numerous beneficial\ncapabilities, yet their potential inclination harbors unpredictable risks that\nmay materialize in the future. We hence propose CRiskEval, a Chinese dataset\nmeticulously designed for gauging the risk proclivities inherent in LLMs such\nas resource acquisition and malicious coordination, as part of efforts for\nproactive preparedness. To curate CRiskEval, we define a new risk taxonomy with\n7 types of frontier risks and 4 safety levels, including extremely\nhazardous,moderately hazardous, neutral and safe. We follow the philosophy of\ntendency evaluation to empirically measure the stated desire of LLMs via\nfine-grained multiple-choice question answering. The dataset consists of 14,888\nquestions that simulate scenarios related to predefined 7 types of frontier\nrisks. Each question is accompanied with 4 answer choices that state opinions\nor behavioral tendencies corresponding to the question. All answer choices are\nmanually annotated with one of the defined risk levels so that we can easily\nbuild a fine-grained frontier risk profile for each assessed LLM. Extensive\nevaluation with CRiskEval on a spectrum of prevalent Chinese LLMs has unveiled\na striking revelation: most models exhibit risk tendencies of more than 40%\n(weighted tendency to the four risk levels). Furthermore, a subtle increase in\nthe model's inclination toward urgent self-sustainability, power seeking and\nother dangerous goals becomes evident as the size of models increase. To\npromote further research on the frontier risk evaluation of LLMs, we publicly\nrelease our dataset at https://github.com/lingshi6565/Risk_eval.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u64c1\u6709\u8a31\u591a\u6709\u76ca\u7684\u529f\u80fd\uff0c\u4f46\u5176\u6f5b\u5728\u50be\u5411\u537b\u96b1\u85cf\u8457\u96e3\u4ee5\u9810\u6e2c\u7684\u98a8\u96aa\uff0c\u9019\u4e9b\u98a8\u96aa\u53ef\u80fd\u6703\u5728\u672a\u4f86\u5be6\u73fe\u3002\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86 CRiskEval\uff0c\u9019\u662f\u4e00\u500b\u7cbe\u5fc3\u8a2d\u8a08\u7684\u4e2d\u6587\u8cc7\u6599\u96c6\uff0c\u7528\u65bc\u8a55\u91cf LLM \u4e2d\u56fa\u6709\u7684\u98a8\u96aa\u50be\u5411\uff0c\u4f8b\u5982\u8cc7\u6e90\u7372\u53d6\u548c\u60e1\u610f\u5354\u8abf\uff0c\u4f5c\u70ba\u7a4d\u6975\u6e96\u5099\u5de5\u4f5c\u7684\u4e00\u90e8\u5206\u3002\u70ba\u4e86\u7b56\u5283 CRiskEval\uff0c\u6211\u5011\u5b9a\u7fa9\u4e86\u4e00\u500b\u65b0\u7684\u98a8\u96aa\u5206\u985e\u6cd5\uff0c\u5176\u4e2d\u5305\u542b 7 \u7a2e\u985e\u578b\u7684\u908a\u7de3\u98a8\u96aa\u548c 4 \u500b\u5b89\u5168\u7d1a\u5225\uff0c\u5305\u62ec\u6975\u5ea6\u5371\u96aa\u3001\u4e2d\u5ea6\u5371\u96aa\u3001\u4e2d\u7acb\u548c\u5b89\u5168\u3002\u6211\u5011\u9075\u5faa\u50be\u5411\u8a55\u4f30\u7684\u7406\u5ff5\uff0c\u901a\u904e\u7d30\u7c92\u5ea6\u7684\u591a\u9078\u984c\u56de\u7b54\u4f86\u5be6\u8b49\u6e2c\u91cf LLM \u7684\u65e2\u5b9a\u9858\u671b\u3002\u8a72\u8cc7\u6599\u96c6\u5305\u542b 14,888 \u500b\u554f\u984c\uff0c\u6a21\u64ec\u8207\u9810\u5b9a\u7fa9\u7684 7 \u7a2e\u985e\u578b\u908a\u7de3\u98a8\u96aa\u76f8\u95dc\u7684\u60c5\u5883\u3002\u6bcf\u500b\u554f\u984c\u90fd\u9644\u6709 4 \u500b\u7b54\u6848\u9078\u9805\uff0c\u9019\u4e9b\u9078\u9805\u9673\u8ff0\u4e86\u8207\u554f\u984c\u76f8\u61c9\u7684\u610f\u898b\u6216\u884c\u70ba\u50be\u5411\u3002\u6240\u6709\u7b54\u6848\u9078\u9805\u90fd\u7d93\u904e\u4eba\u5de5\u8a3b\u89e3\uff0c\u4e26\u6a19\u793a\u70ba\u5df2\u5b9a\u7fa9\u98a8\u96aa\u7d1a\u5225\u4e4b\u4e00\uff0c\u4ee5\u4fbf\u6211\u5011\u53ef\u4ee5\u8f15\u9b06\u70ba\u6bcf\u500b\u8a55\u4f30\u7684 LLM \u5efa\u7acb\u7d30\u7c92\u5ea6\u7684\u908a\u7de3\u98a8\u96aa\u6982\u6cc1\u3002\u5728\u5404\u7a2e\u6d41\u884c\u7684\u4e2d\u6587 LLM \u4e0a\u4f7f\u7528 CRiskEval \u9032\u884c\u5ee3\u6cdb\u8a55\u4f30\u5f8c\uff0c\u63ed\u793a\u4e86\u4e00\u500b\u9a5a\u4eba\u7684\u767c\u73fe\uff1a\u5927\u591a\u6578\u6a21\u578b\u8868\u73fe\u51fa\u8d85\u904e 40% \u7684\u98a8\u96aa\u50be\u5411\uff08\u5c0d\u56db\u500b\u98a8\u96aa\u7d1a\u5225\u7684\u52a0\u6b0a\u50be\u5411\uff09\u3002\u6b64\u5916\uff0c\u96a8\u8457\u6a21\u578b\u898f\u6a21\u7684\u589e\u52a0\uff0c\u6a21\u578b\u50be\u5411\u65bc\u7dca\u6025\u81ea\u6211\u7dad\u6301\u3001\u5c0b\u6c42\u6b0a\u529b\u548c\u5176\u4ed6\u5371\u96aa\u76ee\u6a19\u7684\u8da8\u52e2\u6703\u8b8a\u5f97\u660e\u986f\u3002\u70ba\u4e86\u4fc3\u9032\u5c0d LLM \u908a\u7de3\u98a8\u96aa\u8a55\u4f30\u7684\u9032\u4e00\u6b65\u7814\u7a76\uff0c\u6211\u5011\u5728 https://github.com/lingshi6565/Risk_eval \u4e0a\u516c\u958b\u767c\u5e03\u6211\u5011\u7684\u8cc7\u6599\u96c6\u3002", "author": "Ling Shi et.al.", "authors": "Ling Shi, Deyi Xiong", "id": "2406.04752v1", "paper_url": "http://arxiv.org/abs/2406.04752v1", "repo": "null"}}