{"2409.11299": {"publish_time": "2024-09-17", "title": "TTT-Unet: Enhancing U-Net with Test-Time Training Layers for Biomedical Image Segmentation", "paper_summary": "Biomedical image segmentation is crucial for accurately diagnosing and\nanalyzing various diseases. However, Convolutional Neural Networks (CNNs) and\nTransformers, the most commonly used architectures for this task, struggle to\neffectively capture long-range dependencies due to the inherent locality of\nCNNs and the computational complexity of Transformers. To address this\nlimitation, we introduce TTT-Unet, a novel framework that integrates Test-Time\nTraining (TTT) layers into the traditional U-Net architecture for biomedical\nimage segmentation. TTT-Unet dynamically adjusts model parameters during the\ntesting time, enhancing the model's ability to capture both local and\nlong-range features. We evaluate TTT-Unet on multiple medical imaging datasets,\nincluding 3D abdominal organ segmentation in CT and MR images, instrument\nsegmentation in endoscopy images, and cell segmentation in microscopy images.\nThe results demonstrate that TTT-Unet consistently outperforms state-of-the-art\nCNN-based and Transformer-based segmentation models across all tasks. The code\nis available at https://github.com/rongzhou7/TTT-Unet.", "paper_summary_zh": "\u751f\u7269\u533b\u5b66\u5f71\u50cf\u5206\u5272\u5bf9\u4e8e\u51c6\u786e\u8bca\u65ad\u548c\u5206\u6790\u5404\u79cd\u75be\u75c5\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc (CNN) \u548c Transformer\uff0c\u662f\u6b64\u4efb\u52a1\u6700\u5e38\u7528\u7684\u67b6\u6784\uff0c\u7531\u4e8e CNN \u7684\u56fa\u6709\u5c40\u90e8\u6027\u548c Transformer \u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u96be\u4ee5\u6709\u6548\u6355\u6349\u8fdc\u7a0b\u4f9d\u8d56\u5173\u7cfb\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u6211\u4eec\u5f15\u5165\u4e86 TTT-Unet\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5b83\u5c06\u6d4b\u8bd5\u65f6\u8bad\u7ec3 (TTT) \u5c42\u96c6\u6210\u5230\u7528\u4e8e\u751f\u7269\u533b\u5b66\u5f71\u50cf\u5206\u5272\u7684\u4f20\u7edf U-Net \u67b6\u6784\u4e2d\u3002TTT-Unet \u5728\u6d4b\u8bd5\u65f6\u52a8\u6001\u8c03\u6574\u6a21\u578b\u53c2\u6570\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u6355\u6349\u5c40\u90e8\u548c\u8fdc\u7a0b\u7279\u5f81\u7684\u80fd\u529b\u3002\u6211\u4eec\u5728\u591a\u4e2a\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86 TTT-Unet\uff0c\u5305\u62ec CT \u548c MR \u5f71\u50cf\u4e2d\u7684 3D \u8179\u90e8\u5668\u5b98\u5206\u5272\u3001\u5185\u7aa5\u955c\u5f71\u50cf\u4e2d\u7684\u4eea\u5668\u5206\u5272\u4ee5\u53ca\u663e\u5fae\u955c\u5f71\u50cf\u4e2d\u7684\u7ec6\u80de\u5206\u5272\u3002\u7ed3\u679c\u8868\u660e\uff0cTTT-Unet \u5728\u6240\u6709\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e CNN \u548c\u57fa\u4e8e Transformer \u7684\u5206\u5272\u6a21\u578b\u3002\u4ee3\u7801\u53ef\u5728 https://github.com/rongzhou7/TTT-Unet \u83b7\u5f97\u3002", "author": "Rong Zhou et.al.", "authors": "Rong Zhou, Zhengqing Yuan, Zhiling Yan, Weixiang Sun, Kai Zhang, Yiwei Li, Yanfang Ye, Xiang Li, Lifang He, Lichao Sun", "id": "2409.11299v2", "paper_url": "http://arxiv.org/abs/2409.11299v2", "repo": "null"}}