
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-22**|**Estimating the Conformal Prediction Threshold from Noisy Labels**|Coby Penso et.al.|[2501.12749v1](http://arxiv.org/abs/2501.12749v1)|[link](https://github.com/cobypenso/noise-aware-conformal-prediction)|
|**2025-01-21**|**Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition**|Juan Andres Medina Florez et.al.|[2501.12538v1](http://arxiv.org/abs/2501.12538v1)|null|
|**2025-01-21**|**Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**|Jiaqi Guo et.al.|[2501.12524v1](http://arxiv.org/abs/2501.12524v1)|null|
|**2025-01-21**|**FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**|Phuoc Duong Huy Chu et.al.|[2501.12336v1](http://arxiv.org/abs/2501.12336v1)|null|
|**2025-01-21**|**CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**|Cristiano Patrício et.al.|[2501.12266v1](http://arxiv.org/abs/2501.12266v1)|null|
|**2025-01-21**|**Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**|Stefan Lenz et.al.|[2501.12106v1](http://arxiv.org/abs/2501.12106v1)|[link](https://github.com/stefan-m-lenz/urollmeval)|
|**2025-01-21**|**Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET**|Fatih Aksu et.al.|[2501.12425v1](http://arxiv.org/abs/2501.12425v1)|null|
|**2025-01-21**|**Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**|Shramana Dey et.al.|[2501.12048v1](http://arxiv.org/abs/2501.12048v1)|null|
|**2025-01-21**|**Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis**|Yonghao Zhao et.al.|[2501.12421v1](http://arxiv.org/abs/2501.12421v1)|null|
|**2025-01-21**|**Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**|Saeid Ataei et.al.|[2501.11836v1](http://arxiv.org/abs/2501.11836v1)|null|
|**2025-01-20**|**GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**|Wenjie Kang et.al.|[2501.11715v1](http://arxiv.org/abs/2501.11715v1)|null|
|**2025-01-20**|**Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**|Brian E. Perron et.al.|[2501.11705v1](http://arxiv.org/abs/2501.11705v1)|null|
|**2025-01-20**|**Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data**|Majid Farhadloo et.al.|[2501.11695v1](http://arxiv.org/abs/2501.11695v1)|null|
|**2025-01-20**|**Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications**|Yuxing Lu et.al.|[2501.11632v2](http://arxiv.org/abs/2501.11632v2)|null|
|**2025-01-20**|**Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**|Chaoqing Tang et.al.|[2501.11592v1](http://arxiv.org/abs/2501.11592v1)|null|
|**2025-01-20**|**Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation on Non-Contrast Cardiac Computed Tomography**|Jakub Nalepa et.al.|[2501.11428v1](http://arxiv.org/abs/2501.11428v1)|null|
|**2025-01-20**|**RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?**|Haotian Xu et.al.|[2501.11284v1](http://arxiv.org/abs/2501.11284v1)|null|
|**2025-01-20**|**Spatiotemporal Air Quality Mapping in Urban Areas Using Sparse Sensor Data, Satellite Imagery, Meteorological Factors, and Spatial Features**|Osama Ahmad et.al.|[2501.11270v1](http://arxiv.org/abs/2501.11270v1)|null|
|**2025-01-19**|**Clinical trial cohort selection using Large Language Models on n2c2 Challenges**|Chi-en Amy Tai et.al.|[2501.11114v1](http://arxiv.org/abs/2501.11114v1)|null|
|**2025-01-19**|**Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**|Mohaiminul Islam Bhuiyan et.al.|[2501.11094v1](http://arxiv.org/abs/2501.11094v1)|null|
|**2025-01-18**|**No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling**|Young Seok Jeon et.al.|[2501.10814v1](http://arxiv.org/abs/2501.10814v1)|null|
|**2025-01-18**|**Efficient Auto-Labeling of Large-Scale Poultry Datasets (ALPD) Using Semi-Supervised Models, Active Learning, and Prompt-then-Detect Approach**|Ramesh Bahadur Bist et.al.|[2501.10809v1](http://arxiv.org/abs/2501.10809v1)|null|
|**2025-01-18**|**MedFILIP: Medical Fine-grained Language-Image Pre-training**|Xinjie Liang et.al.|[2501.10775v1](http://arxiv.org/abs/2501.10775v1)|[link](https://github.com/perceptioncomputinglab/medfilip)|
|**2025-01-18**|**Enhancing Diagnostic in 3D COVID-19 Pneumonia CT-scans through Explainable Uncertainty Bayesian Quantification**|Juan Manuel Liscano Fierro et.al.|[2501.10770v1](http://arxiv.org/abs/2501.10770v1)|null|
|**2025-01-18**|**In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review**|Amelia Jiménez-Sánchez et.al.|[2501.10727v1](http://arxiv.org/abs/2501.10727v1)|null|
|**2025-01-17**|**An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach**|Navya Martin Kollapally et.al.|[2501.10300v1](http://arxiv.org/abs/2501.10300v1)|null|
|**2025-01-17**|**SEANN: A Domain-Informed Neural Network for Epidemiological Insights**|Jean-Baptiste Guimbaud et.al.|[2501.10273v1](http://arxiv.org/abs/2501.10273v1)|null|
|**2025-01-17**|**Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide**|Elena Albu et.al.|[2501.10240v1](http://arxiv.org/abs/2501.10240v1)|null|
|**2025-01-17**|**Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education**|William Hersh et.al.|[2501.10186v1](http://arxiv.org/abs/2501.10186v1)|null|
|**2025-01-17**|**CSSDM Ontology to Enable Continuity of Care Data Interoperability**|Subhashis Das et.al.|[2501.10160v1](http://arxiv.org/abs/2501.10160v1)|null|
|**2025-01-17**|**landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images**|Jef Jonkers et.al.|[2501.10098v1](http://arxiv.org/abs/2501.10098v1)|[link](https://github.com/predict-idlab/landmarker)|
|**2025-01-17**|**Deep Learning for Early Alzheimer Disease Detection with MRI Scans**|Mohammad Rafsan et.al.|[2501.09999v1](http://arxiv.org/abs/2501.09999v1)|[link](https://github.com/rafusan/dl-alzheimer)|
|**2025-01-17**|**Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics**|Xigui Li et.al.|[2501.09980v1](http://arxiv.org/abs/2501.09980v1)|[link](https://github.com/xigui-li/aneumo)|
|**2025-01-17**|**Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude**|Yile Yan et.al.|[2501.10484v1](http://arxiv.org/abs/2501.10484v1)|null|
|**2025-01-16**|**Bridging Language Barriers in Healthcare: A Study on Arabic LLMs**|Nada Saadi et.al.|[2501.09825v1](http://arxiv.org/abs/2501.09825v1)|null|
|**2025-01-16**|**KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**|Hajung Kim et.al.|[2501.09744v1](http://arxiv.org/abs/2501.09744v1)|null|
|**2025-01-16**|**Electronic Health Records: Towards Digital Twins in Healthcare**|Muhammet Alkan et.al.|[2501.09640v1](http://arxiv.org/abs/2501.09640v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v1](http://arxiv.org/abs/2501.09628v1)|null|
|**2025-01-16**|**IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients**|Simone Macciò et.al.|[2501.09595v1](http://arxiv.org/abs/2501.09595v1)|null|
|**2025-01-16**|**Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation**|Mohaiminul Islam Bhuiyan et.al.|[2501.09309v1](http://arxiv.org/abs/2501.09309v1)|null|
|**2025-01-16**|**Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics**|Yuanyuan Wei et.al.|[2501.09218v1](http://arxiv.org/abs/2501.09218v1)|null|
|**2025-01-15**|**AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning**|Assaf Lahiany et.al.|[2501.09160v1](http://arxiv.org/abs/2501.09160v1)|null|
|**2025-01-15**|**Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval**|Demetrio Deanda et.al.|[2501.09134v1](http://arxiv.org/abs/2501.09134v1)|null|
|**2025-01-15**|**Generative Medical Image Anonymization Based on Latent Code Projection and Optimization**|Huiyu Li et.al.|[2501.09114v1](http://arxiv.org/abs/2501.09114v1)|[link](https://github.com/huiyu-li/gmia)|
|**2025-01-15**|**Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**|Emma Croxford et.al.|[2501.08977v2](http://arxiv.org/abs/2501.08977v2)|null|
|**2025-01-15**|**An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**|Francisco Mauro et.al.|[2501.08962v1](http://arxiv.org/abs/2501.08962v1)|null|
|**2025-01-15**|**Improving the Efficiency of Self-Supervised Adversarial Training through Latent Clustering-Based Selection**|Somrita Ghosh et.al.|[2501.10466v1](http://arxiv.org/abs/2501.10466v1)|null|
|**2025-01-15**|**Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**|Balasundaram Kadirvelu et.al.|[2501.08851v1](http://arxiv.org/abs/2501.08851v1)|null|
|**2025-01-15**|**Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities**|Adam Goodge et.al.|[2501.09045v1](http://arxiv.org/abs/2501.09045v1)|null|
|**2025-01-14**|**ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**|Ziyuan Huang et.al.|[2501.08324v1](http://arxiv.org/abs/2501.08324v1)|null|
|**2025-01-14**|**A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**|Amir Reza Takhsha et.al.|[2501.08241v1](http://arxiv.org/abs/2501.08241v1)|null|
|**2025-01-14**|**ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**|Mohita Chowdhury et.al.|[2501.08208v1](http://arxiv.org/abs/2501.08208v1)|null|
|**2025-01-14**|**Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**|Rewina Bedemariam et.al.|[2501.08167v2](http://arxiv.org/abs/2501.08167v2)|null|
|**2025-01-14**|**FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**|Nurit Cohen-Inger et.al.|[2501.08155v1](http://arxiv.org/abs/2501.08155v1)|[link](https://github.com/nuritci/fairttts)|
|**2025-01-14**|**Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features**|E. Sarfati et.al.|[2501.08097v1](http://arxiv.org/abs/2501.08097v1)|null|
|**2025-01-14**|**Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**|Alvaro Pastor-Naranjo et.al.|[2501.08042v1](http://arxiv.org/abs/2501.08042v1)|null|
|**2025-01-14**|**Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**|Wentao Cui et.al.|[2501.07970v1](http://arxiv.org/abs/2501.07970v1)|null|
|**2025-01-14**|**Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**|Waqar Hussain et.al.|[2501.07931v1](http://arxiv.org/abs/2501.07931v1)|null|
|**2025-01-13**|**Large Language Models for Interpretable Mental Health Diagnosis**|Brian Hyeongseok Kim et.al.|[2501.07653v1](http://arxiv.org/abs/2501.07653v1)|null|
|**2025-01-13**|**RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**|Difei Gu et.al.|[2501.07525v1](http://arxiv.org/abs/2501.07525v1)|[link](https://github.com/difeigu/radalign)|
|**2025-01-13**|**A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**|Yihao Liu et.al.|[2501.07468v1](http://arxiv.org/abs/2501.07468v1)|null|
|**2025-01-13**|**Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**|Xiyue Zhu et.al.|[2501.07430v1](http://arxiv.org/abs/2501.07430v1)|null|
|**2025-01-13**|**Synthetic Data and Health Privacy**|Gwénolé Abgrall et.al.|[2501.09031v1](http://arxiv.org/abs/2501.09031v1)|null|
|**2025-01-13**|**Natural Language-Assisted Multi-modal Medication Recommendation**|Jie Tan et.al.|[2501.07166v1](http://arxiv.org/abs/2501.07166v1)|[link](https://github.com/jtan1102/nla-mmr_cikm_2024)|
|**2025-01-13**|**CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**|Jinlin Li et.al.|[2501.07157v1](http://arxiv.org/abs/2501.07157v1)|[link](https://github.com/jinlin2021/curegraph)|
|**2025-01-13**|**UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**|Xuhui Guo et.al.|[2501.07017v2](http://arxiv.org/abs/2501.07017v2)|null|
|**2025-01-13**|**Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**|Karine Karine et.al.|[2501.06980v1](http://arxiv.org/abs/2501.06980v1)|null|
|**2025-01-12**|**Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**|Xinyao Ma et.al.|[2501.06964v1](http://arxiv.org/abs/2501.06964v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-12**|**A Foundational Generative Model for Breast Ultrasound Image Analysis**|Haojun Yu et.al.|[2501.06869v1](http://arxiv.org/abs/2501.06869v1)|null|
|**2025-01-12**|**A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**|Noureldin Zahran et.al.|[2501.06859v1](http://arxiv.org/abs/2501.06859v1)|null|
|**2025-01-12**|**MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**|Yiqing Zhang et.al.|[2501.06823v1](http://arxiv.org/abs/2501.06823v1)|null|
|**2025-01-12**|**PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation**|Zhonghao Yan et.al.|[2501.06692v1](http://arxiv.org/abs/2501.06692v1)|null|
|**2025-01-12**|**Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels**|Erjian Guo et.al.|[2501.06678v1](http://arxiv.org/abs/2501.06678v1)|[link](https://github.com/erjian96/clcs)|
|**2025-01-11**|**MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**|Ye Chen et.al.|[2501.06465v2](http://arxiv.org/abs/2501.06465v2)|null|
|**2025-01-11**|**Deep Learning on Hester Davis Scores for Inpatient Fall Prediction**|Hojjat Salehinejad et.al.|[2501.06432v1](http://arxiv.org/abs/2501.06432v1)|null|
|**2025-01-10**|**Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts**|Elizabeth Schaefer et.al.|[2501.06365v1](http://arxiv.org/abs/2501.06365v1)|null|
|**2025-01-10**|**Scale-up Unlearnable Examples Learning with High-Performance Computing**|Yanfan Zhu et.al.|[2501.06080v1](http://arxiv.org/abs/2501.06080v1)|[link](https://github.com/hrlblab/ue_hpc)|
|**2025-01-10**|**AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**|Johann Wenckstern et.al.|[2501.06039v1](http://arxiv.org/abs/2501.06039v1)|[link](https://github.com/bunnelab/virtues)|
|**2025-01-10**|**DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**|Yongfan Lai et.al.|[2501.05932v1](http://arxiv.org/abs/2501.05932v1)|[link](https://github.com/raiiyf/diffusets_exp)|
|**2025-01-10**|**AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India**|Amit Kr Dey et.al.|[2501.05826v2](http://arxiv.org/abs/2501.05826v2)|null|
|**2025-01-10**|**Large Language Models for Bioinformatics**|Wei Ruan et.al.|[2501.06271v1](http://arxiv.org/abs/2501.06271v1)|null|
|**2025-01-09**|**From Simple to Complex Skills: The Case of In-Hand Object Reorientation**|Haozhi Qi et.al.|[2501.05439v1](http://arxiv.org/abs/2501.05439v1)|null|
|**2025-01-09**|**Strategy Masking: A Method for Guardrails in Value-based Reinforcement Learning Agents**|Jonathan Keane et.al.|[2501.05501v2](http://arxiv.org/abs/2501.05501v2)|null|
|**2025-01-09**|**Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics**|Maximilian Alber et.al.|[2501.05409v2](http://arxiv.org/abs/2501.05409v2)|null|
|**2025-01-09**|**An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**|Drago Plecko et.al.|[2501.05197v1](http://arxiv.org/abs/2501.05197v1)|null|
|**2025-01-09**|**Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**|Lei Li et.al.|[2501.04958v1](http://arxiv.org/abs/2501.04958v1)|[link](https://github.com/yinghemedical/imbalance-aware_domain_adaptation)|
|**2025-01-09**|**Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**|Michail Ouroutzoglou et.al.|[2501.04896v1](http://arxiv.org/abs/2501.04896v1)|null|
|**2025-01-08**|**MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**|Daniele Molino et.al.|[2501.04614v2](http://arxiv.org/abs/2501.04614v2)|null|
|**2025-01-08**|**A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**|Zephan M. Enciso et.al.|[2501.04577v2](http://arxiv.org/abs/2501.04577v2)|null|
|**2025-01-08**|**Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**|Ren Tasai et.al.|[2501.04217v1](http://arxiv.org/abs/2501.04217v1)|null|
|**2025-01-07**|**Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**|Rancy Chepchirchir et.al.|[2501.04734v1](http://arxiv.org/abs/2501.04734v1)|[link](https://github.com/CAMERA-MRI/SPARK2023/tree/main/SPARK_BTS_KIFARU)|
|**2025-01-07**|**Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**|Ramya Jonnala et.al.|[2501.03904v1](http://arxiv.org/abs/2501.03904v1)|null|
|**2025-01-07**|**SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**|Runci Bai et.al.|[2501.03836v2](http://arxiv.org/abs/2501.03836v2)|null|
|**2025-01-07**|**SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**|Siyuan Zhao et.al.|[2501.03764v1](http://arxiv.org/abs/2501.03764v1)|null|
|**2025-01-07**|**Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**|Xiaotong Guo et.al.|[2501.03722v1](http://arxiv.org/abs/2501.03722v1)|null|
|**2025-01-07**|**Can Deep Learning Trigger Alerts from Mobile-Captured Images?**|Pritisha Sarkar et.al.|[2501.03499v1](http://arxiv.org/abs/2501.03499v1)|null|
|**2025-01-07**|**Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**|Xiao Wang et.al.|[2501.03458v1](http://arxiv.org/abs/2501.03458v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2025-01-06**|**Existential Crisis: A Social Robot's Reason for Being**|Dora Medgyesy et.al.|[2501.03376v1](http://arxiv.org/abs/2501.03376v1)|null|
|**2025-01-06**|**Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**|Susu Sun et.al.|[2501.02922v1](http://arxiv.org/abs/2501.02922v1)|null|

#### Abstracts
##### **Estimating the Conformal Prediction Threshold from Noisy Labels**
2501.12749v1 by Coby Penso, Jacob Goldberger, Ethan Fetaya

Conformal Prediction (CP) is a method to control prediction uncertainty by
producing a small prediction set, ensuring a predetermined probability that the
true class lies within this set. This is commonly done by defining a score,
based on the model predictions, and setting a threshold on this score using a
validation set. In this study, we address the problem of CP calibration when we
only have access to a validation set with noisy labels. We show how we can
estimate the noise-free conformal threshold based on the noisy labeled data.
Our solution is flexible and can accommodate various modeling assumptions
regarding the label contamination process, without needing any information
about the underlying data distribution or the internal mechanisms of the
machine learning classifier. We develop a coverage guarantee for uniform noise
that is effective even in tasks with a large number of classes. We dub our
approach Noise-Aware Conformal Prediction (NACP) and show on several natural
and medical image classification datasets, including ImageNet, that it
significantly outperforms current noisy label methods and achieves results
comparable to those obtained with a clean validation set.

摘要：共形预测 (CP) 是一種透過產生一個小型預測集合來控制預測不確定性的方法，確保真正的類別落在這個集合內的預先確定的機率。這通常是透過定義一個基於模型預測的分數來完成，並使用驗證集合對這個分數設定一個閾值。在本研究中，我們探討了當我們只能存取具有雜訊標籤的驗證集合時，CP 校正的問題。我們展示了如何根據雜訊標籤資料估計無雜訊的共形閾值。我們的解決方案具有彈性，並且可以適應關於標籤污染過程的各種建模假設，而不需要任何關於底層資料分佈或機器學習分類器內部機制的資訊。我們開發了一個對於均勻雜訊的覆蓋保證，即使在具有大量類別的任務中也很有效。我們將我們的做法稱為雜訊感知共形預測 (NACP)，並在幾個自然和醫學影像分類資料集（包括 ImageNet）上展示了它顯著優於目前的雜訊標籤方法，並且達到了與使用乾淨驗證集合獲得的結果相當的結果。

##### **Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition**
2501.12538v1 by Juan Andres Medina Florez, Shaina Raza, Rashida Lynn, Zahra Shakeri, Brendan T. Smith, Elham Dolatabadi

Understanding the prevalence, disparities, and symptom variations of Post
COVID-19 Condition (PCC) for vulnerable populations is crucial to improving
care and addressing intersecting inequities. This study aims to develop a
comprehensive framework for integrating social determinants of health (SDOH)
into PCC research by leveraging NLP techniques to analyze disparities and
variations in SDOH representation within PCC case reports. Following
construction of a PCC Case Report Corpus, comprising over 7,000 case reports
from the LitCOVID repository, a subset of 709 reports were annotated with 26
core SDOH-related entity types using pre-trained named entity recognition (NER)
models, human review, and data augmentation to improve quality, diversity and
representation of entity types. An NLP pipeline integrating NER, natural
language inference (NLI), trigram and frequency analyses was developed to
extract and analyze these entities. Both encoder-only transformer models and
RNN-based models were assessed for the NER objective.
  Fine-tuned encoder-only BERT models outperformed traditional RNN-based models
in generalizability to distinct sentence structures and greater class sparsity.
Exploratory analysis revealed variability in entity richness, with prevalent
entities like condition, age, and access to care, and underrepresentation of
sensitive categories like race and housing status. Trigram analysis highlighted
frequent co-occurrences among entities, including age, gender, and condition.
The NLI objective (entailment and contradiction analysis) showed attributes
like "Experienced violence or abuse" and "Has medical insurance" had high
entailment rates (82.4%-80.3%), while attributes such as "Is
female-identifying," "Is married," and "Has a terminal condition" exhibited
high contradiction rates (70.8%-98.5%).

摘要：<paragraph>了解弱勢群體的後 COVID-19 狀況 (PCC) 的流行率、差異和症狀變化對於改善照護和解決交叉不平等至關重要。本研究旨在透過利用自然語言處理技術分析 PCC 病例報告中 SDOH 的表現差異和變化，開發一個整合健康社會決定因素 (SDOH) 進入 PCC 研究的綜合架構。在建構一個 PCC 病例報告語料庫（包含來自 LitCOVID 資料庫的 7,000 多個病例報告）後，使用預先訓練的名稱實體辨識 (NER) 模型、人工審查和資料擴充對 709 份報告進行註解，其中包含 26 個核心 SDOH 相關實體類型，以提高實體類型的品質、多樣性和表現。開發了一個整合 NER、自然語言推論 (NLI)、三元組和頻率分析的 NLP 管線，以萃取和分析這些實體。針對 NER 目標評估了僅編碼器轉換器模型和基於 RNN 的模型。微調後的僅編碼器 BERT 模型在一般化到不同的句子結構和更大的類別稀疏性方面優於傳統的基於 RNN 的模型。探索性分析顯示實體豐富度存在變異性，普遍的實體包括狀況、年齡和取得照護的管道，而種族和居住狀況等敏感類別的表現則不足。三元組分析強調了實體之間的頻繁共現，包括年齡、性別和狀況。NLI 目標（蘊涵和矛盾分析）顯示「經歷過暴力或虐待」和「有醫療保險」等屬性具有很高的蘊涵率（82.4%-80.3%），而「認同自己是女性」、「已婚」和「有末期疾病」等屬性則表現出很高的矛盾率（70.8%-98.5%）。</paragraph>

##### **Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**
2501.12524v1 by Jiaqi Guo, Yunnan Wu, Evangelos Kaimakamis, Georgios Petmezas, Vasileios E. Papageorgiou, Nicos Maglaveras, Aggelos K. Katsaggelos

With the advent of the COVID-19 pandemic, ultrasound imaging has emerged as a
promising technique for COVID-19 detection, due to its non-invasive nature,
affordability, and portability. In response, researchers have focused on
developing AI-based scoring systems to provide real-time diagnostic support.
However, the limited size and lack of proper annotation in publicly available
ultrasound datasets pose significant challenges for training a robust AI model.
This paper proposes MeDiVLAD, a novel pipeline to address the above issue for
multi-level lung-ultrasound (LUS) severity scoring. In particular, we leverage
self-knowledge distillation to pretrain a vision transformer (ViT) without
label and aggregate frame-level features via dual-level VLAD aggregation. We
show that with minimal finetuning, MeDiVLAD outperforms conventional
fully-supervised methods in both frame- and video-level scoring, while offering
classification reasoning with exceptional quality. This superior performance
enables key applications such as the automatic identification of critical lung
pathology areas and provides a robust solution for broader medical video
classification tasks.

摘要：隨著 COVID-19 大流行的到來，超音波影像已成為一種有前途的 COVID-19 檢測技術，因為它具有非侵入性、價格實惠且可攜帶等特性。有鑑於此，研究人員專注於開發基於 AI 的評分系統，以提供即時的診斷支援。然而，公開可用的超音波資料集規模有限且缺乏適當的註解，這對訓練穩健的 AI 模型構成重大挑戰。本文提出 MeDiVLAD，這是一種新穎的管道，用於解決上述多層級肺部超音波 (LUS) 嚴重度評分的議題。具體來說，我們利用自我知識蒸餾技術，在沒有標籤的情況下預訓練視覺轉換器 (ViT)，並透過雙層級 VLAD 聚合來彙總幀級特徵。我們證明，透過最小的微調，MeDiVLAD 在幀級和影片級評分中都優於傳統的全監督式方法，同時提供品質極佳的分類推理。這種優異的效能支援了關鍵應用，例如自動識別肺部病灶區域，並為更廣泛的醫學影片分類任務提供穩健的解決方案。

##### **FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**
2501.12336v1 by Phuoc Duong Huy Chu

This paper presents results of our system for CoMeDi Shared Task, focusing on
Subtask 2: Disagreement Ranking. Our system leverages sentence embeddings
generated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep
neural regression model incorporating batch normalization and dropout for
improved generalization. By predicting the mean of pairwise judgment
differences between annotators, our method explicitly targets disagreement
ranking, diverging from traditional "gold label" aggregation approaches. We
optimized our system with a customized architecture and training procedure,
achieving competitive performance in Spearman correlation against mean
disagreement labels. Our results highlight the importance of robust embeddings,
effective model architecture, and careful handling of judgment differences for
ranking disagreement in multilingual contexts. These findings provide insights
into the use of contextualized representations for ordinal judgment tasks and
open avenues for further refinement of disagreement prediction models.

摘要：本文展示了我們在 CoMeDi 共享任務系統中的結果，重點在
子任務 2：分歧排名。我們的系統利用 paraphrase-xlm-r-multilingual-v1 模型產生的句子嵌入，結合深度
神經迴歸模型，並加入批次正規化和中斷以改善概化。透過預測註解者之間成對判斷差異的平均值，我們的
方法明確針對分歧排名，偏離傳統的「黃金標籤」聚合方法。我們使用自訂架構和訓練程序優化系統，
在與平均分歧標籤的 Spearman 相關性中獲得競爭力表現。我們的結果強調了穩健嵌入、有效模型架構和
謹慎處理判斷差異對於在多語言環境中對分歧進行排名的重要性。這些發現提供了使用情境化表徵進行序數判斷任務的見解，並為進一步優化分歧預測模型開闢了道路。

##### **CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**
2501.12266v1 by Cristiano Patrício, Isabel Rio-Torto, Jaime S. Cardoso, Luís F. Teixeira, João C. Neves

The main challenges limiting the adoption of deep learning-based solutions in
medical workflows are the availability of annotated data and the lack of
interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the
latter by constraining the final disease prediction on a set of predefined and
human-interpretable concepts. However, the increased interpretability achieved
through these concept-based explanations implies a higher annotation burden.
Moreover, if a new concept needs to be added, the whole system needs to be
retrained. Inspired by the remarkable performance shown by Large
Vision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet
effective, methodology, CBVLM, which tackles both of the aforementioned
challenges. First, for each concept, we prompt the LVLM to answer if the
concept is present in the input image. Then, we ask the LVLM to classify the
image based on the previous concept predictions. Moreover, in both stages, we
incorporate a retrieval module responsible for selecting the best examples for
in-context learning. By grounding the final diagnosis on the predicted
concepts, we ensure explainability, and by leveraging the few-shot capabilities
of LVLMs, we drastically lower the annotation cost. We validate our approach
with extensive experiments across four medical datasets and twelve LVLMs (both
generic and medical) and show that CBVLM consistently outperforms CBMs and
task-specific supervised methods without requiring any training and using just
a few annotated examples. More information on our project page:
https://cristianopatricio.github.io/CBVLM/.

摘要：限制在醫療工作流程中採用基於深度學習的解決方案的主要挑戰是標記資料的可用性以及此類系統的可解釋性不足。概念瓶頸模型 (CBM) 透過限制一組預定義且人類可解釋的概念對最終疾病預測，來解決後者。然而，透過這些基於概念的解釋所實現的可解釋性提升，意味著更高的標記負擔。此外，如果需要新增一個新概念，則需要重新訓練整個系統。受到大型視覺語言模型 (LVLMs) 在小樣本設定中展現的卓越效能啟發，我們提出了一個簡單但有效的 CBVLM 方法，來解決上述兩個挑戰。首先，對於每個概念，我們提示 LVLM 回答輸入影像中是否包含該概念。然後，我們要求 LVLM 根據先前的概念預測對影像進行分類。此外，在兩個階段中，我們都納入一個檢索模組，負責選出最適合於情境學習的範例。透過將最終診斷建立在預測概念之上，我們確保了可解釋性，並透過利用 LVLMs 的小樣本能力，我們大幅降低了標記成本。我們透過四個醫療資料集和十二個 LVLM（通用和醫療）的廣泛實驗驗證了我們的作法，並顯示 CBVLM 在無需任何訓練且僅使用少數標記範例的情況下，始終優於 CBM 和特定於任務的監督式方法。更多資訊請見我們的專案頁面：https://cristianopatricio.github.io/CBVLM/。

##### **Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**
2501.12106v1 by Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Torsten Panholzer

Tumor documentation in Germany is largely done manually, requiring reading
patient records and entering data into structured databases. Large language
models (LLMs) could potentially enhance this process by improving efficiency
and reliability. This evaluation tests eleven different open source LLMs with
sizes ranging from 1-70 billion model parameters on three basic tasks of the
tumor documentation process: identifying tumor diagnoses, assigning ICD-10
codes, and extracting the date of first diagnosis. For evaluating the LLMs on
these tasks, a dataset of annotated text snippets based on anonymized doctors'
notes from urology was prepared. Different prompting strategies were used to
investigate the effect of the number of examples in few-shot prompting and to
explore the capabilities of the LLMs in general. The models Llama 3.1 8B,
Mistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.
Models with less extensive training data or having fewer than 7 billion
parameters showed notably lower performance, while larger models did not
display performance gains. Examples from a different medical domain than
urology could also improve the outcome in few-shot prompting, which
demonstrates the ability of LLMs to handle tasks needed for tumor
documentation. Open source LLMs show a strong potential for automating tumor
documentation. Models from 7-12 billion parameters could offer an optimal
balance between performance and resource efficiency. With tailored fine-tuning
and well-designed prompting, these models might become important tools for
clinical documentation in the future. The code for the evaluation is available
from https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset
as a new valuable resource that addresses the shortage of authentic and easily
accessible benchmarks in German-language medical NLP.

摘要：德國的腫瘤文件記錄大部分是手動完成，需要閱讀病歷並將資料輸入結構化的資料庫中。大型語言模型 (LLM) 可能透過提升效率和可靠性來增強此程序。此評量測試了 11 個不同的開源 LLM，模型參數大小從 10 億到 700 億不等，針對腫瘤文件記錄程序的三項基本任務：識別腫瘤診斷、指定 ICD-10 代碼，以及擷取首次診斷日期。為了針對這些任務評估 LLM，準備了一個基於泌尿科醫生匿名筆記的註解文字片段資料集。使用不同的提示策略來調查少量提示中範例數量的影響，並探索 LLM 的一般能力。Llama 3.1 8B、Mistral 7B 和 Mistral NeMo 12 B 等模型在這些任務中表現相當好。訓練資料較少或參數少於 70 億的模型表現明顯較差，而較大的模型並未展現效能提升。與泌尿科不同的醫療領域的範例也可以改善少量提示的結果，這證明了 LLM 處理腫瘤文件記錄所需任務的能力。開源 LLM 在自動化腫瘤文件記錄方面顯示出強大的潛力。參數介於 70 億到 120 億的模型可以在效能和資源效率之間提供最佳平衡。透過量身打造微調和精心設計的提示，這些模型未來可能會成為臨床文件記錄的重要工具。評估程式碼可從 https://github.com/stefan-m-lenz/UroLlmEval 取得。我們也釋出資料集作為一個新的有價值資源，用於解決德語醫療自然語言處理中真實且易於取得的基準短缺問題。

##### **Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET**
2501.12425v1 by Fatih Aksu, Fabrizia Gelardi, Arturo Chiti, Paolo Soda

Accurate classification of histological subtypes of non-small cell lung
cancer (NSCLC) is essential in the era of precision medicine, yet current
invasive techniques are not always feasible and may lead to clinical
complications. This study presents a multi-stage intermediate fusion approach
to classify NSCLC subtypes from CT and PET images. Our method integrates the
two modalities at different stages of feature extraction, using voxel-wise
fusion to exploit complementary information across varying abstraction levels
while preserving spatial correlations. We compare our method against unimodal
approaches using only CT or PET images to demonstrate the benefits of modality
fusion, and further benchmark it against early and late fusion techniques to
highlight the advantages of intermediate fusion during feature extraction.
Additionally, we compare our model with the only existing intermediate fusion
method for histological subtype classification using PET/CT images. Our results
demonstrate that the proposed method outperforms all alternatives across key
metrics, with an accuracy and AUC equal to 0.724 and 0.681, respectively. This
non-invasive approach has the potential to significantly improve diagnostic
accuracy, facilitate more informed treatment decisions, and advance
personalized care in lung cancer management.

摘要：在精準醫療的時代，準確分類非小細胞肺癌 (NSCLC) 的組織學亞型至關重要，但目前的侵入性技術並不總是可行，且可能會導致臨床併發症。本研究提出了一種多階段中間融合方法，從電腦斷層 (CT) 和正子斷層掃描 (PET) 影像中分類 NSCLC 亞型。我們的技術在特徵萃取的不同階段整合這兩種方式，利用逐體素融合來利用不同抽象層級的互補資訊，同時保留空間相關性。我們將我們的技術與僅使用電腦斷層或正子斷層掃描影像的單一模式方法進行比較，以證明模式融合的優點，並進一步將其與早期和晚期融合技術進行比較，以強調特徵萃取期間中間融合的優點。此外，我們將我們的模型與唯一現有的中間融合方法進行比較，該方法使用正子斷層掃描/電腦斷層掃描影像進行組織學亞型分類。我們的結果表明，所提出的方法在所有替代方案中表現優異，準確率和 AUC 分別等於 0.724 和 0.681。這種非侵入性方法有可能顯著提高診斷準確率，促進更明智的治療決策，並推進肺癌管理中的個人化照護。

##### **Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**
2501.12048v1 by Shramana Dey, Pallabi Dutta, Riddhasree Bhattacharyya, Surochita Pal, Sushmita Mitra, Rajiv Raman

The prevalence of ocular illnesses is growing globally, presenting a
substantial public health challenge. Early detection and timely intervention
are crucial for averting visual impairment and enhancing patient prognosis.
This research introduces a new framework called Class Extension with Limited
Data (CELD) to train a classifier to categorize retinal fundus images. The
classifier is initially trained to identify relevant features concerning
Healthy and Diabetic Retinopathy (DR) classes and later fine-tuned to adapt to
the task of classifying the input images into three classes: Healthy, DR, and
Glaucoma. This strategy allows the model to gradually enhance its
classification capabilities, which is beneficial in situations where there are
only a limited number of labeled datasets available. Perturbation methods are
also used to identify the input image characteristics responsible for
influencing the models decision-making process. We achieve an overall accuracy
of 91% on publicly available datasets.

摘要：全球眼疾患病率持續上升，對公共衛生造成重大挑戰。早期發現和及時干預對於預防視力障礙和改善患者預後至關重要。本研究提出了一個名為有限數據類別擴展 (CELD) 的新框架，用於訓練分類器對視網膜眼底圖像進行分類。該分類器最初接受訓練以識別與健康和糖尿病視網膜病變 (DR) 類別相關的特徵，然後進行微調以適應將輸入圖像分類為三類的任務：健康、DR 和青光眼。此策略允許模型逐步增強其分類能力，這在標記數據集數量有限的情況下是有益的。擾動方法也用於識別負責影響模型決策過程的輸入圖像特徵。我們在公開數據集上實現了 91% 的整體準確度。

##### **Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis**
2501.12421v1 by Yonghao Zhao, Changtao Li, Chi Shu, Qingbin Wu, Hong Li, Chuan Xu, Tianrui Li, Ziqiang Wang, Zhipeng Luo, Yazhou He

Survival prognosis is crucial for medical informatics. Practitioners often
confront small-sized clinical data, especially cancer patient cases, which can
be insufficient to induce useful patterns for survival predictions. This study
deals with small sample survival analysis by leveraging transfer learning, a
useful machine learning technique that can enhance the target analysis with
related knowledge pre-learned from other data. We propose and develop various
transfer learning methods designed for common survival models. For parametric
models such as DeepSurv, Cox-CC (Cox-based neural networks), and DeepHit
(end-to-end deep learning model), we apply standard transfer learning
techniques like pretraining and fine-tuning. For non-parametric models such as
Random Survival Forest, we propose a new transfer survival forest (TSF) model
that transfers tree structures from source tasks and fine-tunes them with
target data. We evaluated the transfer learning methods on colorectal cancer
(CRC) prognosis. The source data are 27,379 SEER CRC stage I patients, and the
target data are 728 CRC stage I patients from the West China Hospital. When
enhanced by transfer learning, Cox-CC's $C^{td}$ value was boosted from 0.7868
to 0.8111, DeepHit's from 0.8085 to 0.8135, DeepSurv's from 0.7722 to 0.8043,
and RSF's from 0.7940 to 0.8297 (the highest performance). All models trained
with data as small as 50 demonstrated even more significant improvement.
Conclusions: Therefore, the current survival models used for cancer prognosis
can be enhanced and improved by properly designed transfer learning techniques.
The source code used in this study is available at
https://github.com/YonghaoZhao722/TSF.

摘要：<paragraph>存活預測對醫療資訊學至關重要。實務工作者經常面對小規模的臨床資料，特別是癌症病患個案，這些資料可能不足以誘發有用的模式來進行存活預測。此研究透過利用轉移學習來處理小樣本存活分析，這是一種有用的機器學習技術，可以透過從其他資料預先學習到的相關知識來增強目標分析。我們提出並開發各種專為常見存活模型設計的轉移學習方法。對於參數化模型，例如 DeepSurv、Cox-CC（基於 Cox 的神經網路）和 DeepHit（端到端深度學習模型），我們應用標準轉移學習技術，例如預訓練和微調。對於非參數化模型，例如隨機存活森林，我們提出一個新的轉移存活森林（TSF）模型，它從來源任務傳輸樹狀結構，並使用目標資料微調它們。我們在結直腸癌（CRC）預後上評估了轉移學習方法。來源資料為 27,379 名 SEER CRC 第一期患者，目標資料為來自中國西部醫院的 728 名 CRC 第一期患者。在透過轉移學習增強後，Cox-CC 的 $C^{td}$ 值從 0.7868 提升到 0.8111，DeepHit 的從 0.8085 提升到 0.8135，DeepSurv 的從 0.7722 提升到 0.8043，RSF 的從 0.7940 提升到 0.8297（最高效能）。所有以小至 50 的資料訓練的模型都展示出更顯著的進步。結論：因此，目前用於癌症預後的存活模型可以透過適當設計的轉移學習技術來增強和改善。本研究中使用的原始碼可在 https://github.com/YonghaoZhao722/TSF 取得。</paragraph>

##### **Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**
2501.11836v1 by Saeid Ataei, Saeed Adibnazari, Seyyed Taghi Ataei

Structural integrity is vital for maintaining the safety and longevity of
concrete infrastructures such as bridges, tunnels, and walls. Traditional
methods for detecting damages like cracks and spalls are labor-intensive,
time-consuming, and prone to human error. To address these challenges, this
study explores advanced data-driven techniques using deep learning for
automated damage detection and analysis. Two state-of-the-art instance
segmentation models, YOLO-v7 instance segmentation and Mask R-CNN, were
evaluated using a dataset comprising 400 images, augmented to 10,995 images
through geometric and color-based transformations to enhance robustness. The
models were trained and validated using a dataset split into 90% training set,
validation and test set 10%. Performance metrics such as precision, recall,
mean average precision (mAP@0.5), and frames per second (FPS) were used for
evaluation. YOLO-v7 achieved a superior mAP@0.5 of 96.1% and processed 40 FPS,
outperforming Mask R-CNN, which achieved a mAP@0.5 of 92.1% with a slower
processing speed of 18 FPS. The findings recommend YOLO-v7 instance
segmentation model for real-time, high-speed structural health monitoring,
while Mask R-CNN is better suited for detailed offline assessments. This study
demonstrates the potential of deep learning to revolutionize infrastructure
maintenance, offering a scalable and efficient solution for automated damage
detection.

摘要：結構完整性對於維護橋樑、隧道和牆壁等混凝土基礎設施的安全性和使用壽命至關重要。傳統的損壞檢測方法，例如裂縫和剝落，需要大量人工，耗時且容易出現人為錯誤。為了應對這些挑戰，本研究探討了使用深度學習的先進數據驅動技術，用於自動損壞檢測和分析。使用包含 400 張圖像的數據集評估了兩個最先進的實例分割模型，YOLO-v7 實例分割和 Mask R-CNN，通過幾何和基於顏色的轉換擴展到 10,995 張圖像，以增強魯棒性。使用分為 90% 訓練集、驗證和測試集 10% 的數據集訓練和驗證模型。使用精確度、召回率、平均平均精確度 (mAP@0.5) 和每秒幀數 (FPS) 等性能指標進行評估。YOLO-v7 達到了 96.1% 的優異 mAP@0.5，並處理了 40 FPS，優於 Mask R-CNN，後者以 18 FPS 的較慢處理速度達到了 92.1% 的 mAP@0.5。研究結果推薦使用 YOLO-v7 實例分割模型進行實時、高速結構健康監測，而 Mask R-CNN 更適合詳細的離線評估。本研究展示了深度學習在基礎設施維護方面具有革命性的潛力，為自動損壞檢測提供了一個可擴展且高效的解決方案。

##### **GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**
2501.11715v1 by Wenjie Kang, Lize Jiskoot, Peter De Deyn, Geert Biessels, Huiberdina Koek, Jurgen Claassen, Huub Middelkoop, Wiesje Flier, Willemijn J. Jansen, Stefan Klein, Esther Bron

Deep learning methods based on Convolutional Neural Networks (CNNs) have
shown great potential to improve early and accurate diagnosis of Alzheimer's
disease (AD) dementia based on imaging data. However, these methods have yet to
be widely adopted in clinical practice, possibly due to the limited
interpretability of deep learning models. The Explainable Boosting Machine
(EBM) is a glass-box model but cannot learn features directly from input
imaging data. In this study, we propose a novel interpretable model that
combines CNNs and EBMs for the diagnosis and prediction of AD. We develop an
innovative training strategy that alternatingly trains the CNN component as a
feature extractor and the EBM component as the output block to form an
end-to-end model. The model takes imaging data as input and provides both
predictions and interpretable feature importance measures. We validated the
proposed model on the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset and the Health-RI Parelsnoer Neurodegenerative Diseases Biobank (PND)
as an external testing set. The proposed model achieved an area-under-the-curve
(AUC) of 0.956 for AD and control classification, and 0.694 for the prediction
of conversion of mild cognitive impairment (MCI) to AD on the ADNI cohort. The
proposed model is a glass-box model that achieves a comparable performance with
other state-of-the-art black-box models. Our code is publicly available at:
https://anonymous.4open.science/r/GL-ICNN.

摘要：<paragraph>基於卷積神經網路 (CNN) 的深度學習方法已顯示出極大的潛力，可根據影像資料改善阿茲海默症 (AD) 失智症的早期準確診斷。然而，這些方法尚未廣泛應用於臨床實務中，這可能是由於深度學習模型的可解釋性有限。可解釋提升機 (EBM) 是個玻璃盒模型，但無法直接從輸入影像資料中學習特徵。在這項研究中，我們提出一個結合 CNN 和 EBM 的新可解釋模型，用於診斷和預測 AD。我們開發了一種創新的訓練策略，交替訓練 CNN 組件作為特徵萃取器，並訓練 EBM 組件作為輸出區塊，以形成端對端模型。此模型將影像資料作為輸入，並提供預測和可解釋的特徵重要性測量。我們在阿茲海默症神經影像倡議 (ADNI) 資料集和 Health-RI Parelsnoer 神經退化疾病生物資料庫 (PND) 上驗證了所提出的模型，作為外部測試集。所提出的模型在 AD 和對照分類中達到了 0.956 的曲線下面積 (AUC)，並在 ADNI 隊列中預測輕度認知障礙 (MCI) 轉化為 AD 時達到了 0.694。所提出的模型是一個玻璃盒模型，其效能與其他最先進的黑盒模型相當。我們的程式碼可在以下網址公開取得：https://anonymous.4open.science/r/GL-ICNN。</paragraph>

##### **Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**
2501.11705v1 by Brian E. Perron, Lauri Goldkind, Zia Qi, Bryan G. Victor

This paper examines the responsible integration of artificial intelligence
(AI) in human services organizations (HSOs), proposing a nuanced framework for
evaluating AI applications across multiple dimensions of risk. The authors
argue that ethical concerns about AI deployment -- including professional
judgment displacement, environmental impact, model bias, and data laborer
exploitation -- vary significantly based on implementation context and specific
use cases. They challenge the binary view of AI adoption, demonstrating how
different applications present varying levels of risk that can often be
effectively managed through careful implementation strategies. The paper
highlights promising solutions, such as local large language models, that can
facilitate responsible AI integration while addressing common ethical concerns.
The authors propose a dimensional risk assessment approach that considers
factors like data sensitivity, professional oversight requirements, and
potential impact on client wellbeing. They conclude by outlining a path forward
that emphasizes empirical evaluation, starting with lower-risk applications and
building evidence-based understanding through careful experimentation. This
approach enables organizations to maintain high ethical standards while
thoughtfully exploring how AI might enhance their capacity to serve clients and
communities effectively.

摘要：本文探討了人工智慧 (AI) 在人類服務組織 (HSO) 中負責任的整合，提出了一個細緻的框架，用於評估 AI 應用在多個風險維度。作者認為，對 AI 部署的道德考量——包括專業判斷的取代、環境影響、模型偏差和資料工作者的剝削——會根據實施背景和具體使用案例而有顯著的不同。他們挑戰了 AI 採用二元論的觀點，說明了不同的應用如何呈現不同程度的風險，而這些風險通常可以透過仔細的實施策略來有效管理。本文重點介紹了有前景的解決方案，例如本地大型語言模型，它可以在解決常見的道德問題的同時，促進負責任的 AI 整合。作者提出了一種維度風險評估方法，該方法考慮了資料敏感度、專業監督需求和對客戶福祉的潛在影響等因素。他們最後概述了一條前進的道路，強調實證評估，從低風險應用開始，並透過仔細的實驗建立基於證據的理解。這種方法使組織能夠在深思熟慮地探討 AI 如何增強其有效服務客戶和社群的能力的同時，維持高道德標準。

##### **Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data**
2501.11695v1 by Majid Farhadloo, Arun Sharma, Alexey Leontovich, Svetomir N. Markovic, Shashi Shekhar

Given multi-type point maps from different place-types (e.g., tumor regions),
our objective is to develop a classifier trained on the source place-type to
accurately distinguish between two classes of the target place-type based on
their point arrangements. This problem is societally important for many
applications, such as generating clinical hypotheses for designing new
immunotherapies for cancer treatment. The challenge lies in the spatial
variability, the inherent heterogeneity and variation observed in spatial
properties or arrangements across different locations (i.e., place-types).
Previous techniques focus on self-supervised tasks to learn domain-invariant
features and mitigate domain differences; however, they often neglect the
underlying spatial arrangements among data points, leading to significant
discrepancies across different place-types. We explore a novel multi-task
self-learning framework that targets spatial arrangements, such as spatial
mix-up masking and spatial contrastive predictive coding, for
spatially-delineated domain-adapted AI classification. Experimental results on
real-world datasets (e.g., oncology data) show that the proposed framework
provides higher prediction accuracy than baseline methods.

摘要：從不同類型的點圖（例如，腫瘤區域）中給定多類型點圖，
我們的目標是開發一個在來源類型上訓練的分類器，以
根據其點排列準確區分目標類型中的兩類。這個問題對於許多
應用來說具有社會重要性，例如為癌症治療設計新的免疫療法而生成臨床假設。挑戰在於空間
變異性、固有的異質性和在不同位置（即類型）中觀察到的空間
屬性或排列的變化。先前的技術專注於自監督任務以學習不變領域
特徵並減輕領域差異；然而，它們通常忽視數據點之間的
底層空間排列，導致不同類型之間存在顯著差異。我們探索了一種新穎的多任務
自學習框架，以針對空間排列，例如空間混合掩蔽和空間對比預測編碼，用於
空間劃分的領域適應 AI 分類。在
真實世界數據集（例如，腫瘤學數據）上的實驗結果表明，所提出的框架
提供的預測準確度高於基線方法。

##### **Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications**
2501.11632v2 by Yuxing Lu, Sin Yee Goi, Xukai Zhao, Jinzhuo Wang

Biomedical knowledge graphs (BKGs) have emerged as powerful tools for
organizing and leveraging the vast and complex data found across the biomedical
field. Yet, current reviews of BKGs often limit their scope to specific domains
or methods, overlooking the broader landscape and the rapid technological
progress reshaping it. In this survey, we address this gap by offering a
systematic review of BKGs from three core perspectives: domains, tasks, and
applications. We begin by examining how BKGs are constructed from diverse data
sources, including molecular interactions, pharmacological datasets, and
clinical records. Next, we discuss the essential tasks enabled by BKGs,
focusing on knowledge management, retrieval, reasoning, and interpretation.
Finally, we highlight real-world applications in precision medicine, drug
discovery, and scientific research, illustrating the translational impact of
BKGs across multiple sectors. By synthesizing these perspectives into a unified
framework, this survey not only clarifies the current state of BKG research but
also establishes a foundation for future exploration, enabling both innovative
methodological advances and practical implementations.

摘要：生物医学知识图谱（BKG）已成为组织和利用生物医学领域中发现的庞大且复杂数据的强大工具。然而，当前对 BKG 的审查通常将其范围限制在特定领域或方法，忽视了更广泛的格局和正在重塑它的快速技术进步。在这项调查中，我们通过从三个核心角度（领域、任务和应用）对 BKG 进行系统审查来解决这一差距。我们首先检查如何从包括分子相互作用、药理数据集和临床记录在内的各种数据源构建 BKG。接下来，我们讨论 BKG 启用的基本任务，重点关注知识管理、检索、推理和解释。最后，我们重点介绍了精准医疗、药物发现和科学研究中的实际应用，说明了 BKG 在多个领域的转化影响。通过将这些观点综合到一个统一的框架中，本调查不仅阐明了 BKG 研究的现状，还为未来的探索奠定了基础，既促进了创新方法的进步，也促进了实际实施。

##### **Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**
2501.11592v1 by Chaoqing Tang, Huanze Zhuang, Guiyun Tian, Zhenli Zeng, Yi Ding, Wenzhong Liu, Xiang Bai

Pre-trained large models attract widespread attention in recent years, but
they face challenges in applications that require high interpretability or have
limited resources, such as physical sensing, medical imaging, and
bioinformatics. Compressed Sensing (CS) is a well-proved theory that drives
many recent breakthroughs in these applications. However, as a typical
under-determined linear system, CS suffers from excessively long sparse
reconstruction times when using traditional iterative methods, particularly
with large-scale data. Current AI methods like deep unfolding fail to
substitute them because pre-trained models exhibit poor generality beyond their
training conditions and dataset distributions, or lack interpretability.
Instead of following the big model fervor, this paper proposes ultra-small
artificial neural models called coefficients learning (CL), enabling
training-free and rapid sparse reconstruction while perfectly inheriting the
generality and interpretability of traditional iterative methods, bringing new
feature of incorporating prior knowledges. In CL, a signal of length $n$ only
needs a minimal of $n$ trainable parameters. A case study model called CLOMP is
implemented for evaluation. Experiments are conducted on both synthetic and
real one-dimensional and two-dimensional signals, demonstrating significant
improvements in efficiency and accuracy. Compared to representative iterative
methods, CLOMP improves efficiency by 100 to 1000 folds for large-scale data.
Test results on eight diverse image datasets indicate that CLOMP improves
structural similarity index by 292%, 98%, 45% for sampling rates of 0.1, 0.3,
0.5, respectively. We believe this method can truly usher CS reconstruction
into the AI era, benefiting countless under-determined linear systems that rely
on sparse solution.

摘要：<paragraph>预训练大型模型近年来备受关注，但它们在需要高可解释性或资源有限的应用中面临挑战，例如物理传感、医学影像和生物信息学。压缩感知 (CS) 是一项经过充分验证的理论，推动了这些应用中的许多最新突破。然而，作为典型的欠定线性系统，CS 在使用传统迭代方法时会产生过长的稀疏重建时间，尤其是在处理大规模数据时。当前的深度展开等 AI 方法无法替代它们，因为预训练模型在其训练条件和数据集分布之外表现出较差的泛化性，或缺乏可解释性。本文没有追随大型模型热潮，而是提出了称为系数学习 (CL) 的超小型人工神经网络模型，实现无训练且快速的稀疏重建，同时完美继承了传统迭代方法的泛化性和可解释性，带来了融合先验知识的新特性。在 CL 中，长度为 $n$ 的信号只需要最少 $n$ 个可训练参数。实现了一个称为 CLOMP 的案例研究模型以进行评估。在合成和真实的一维和二维信号上进行了实验，证明了效率和准确性的显着提高。与具有代表性的迭代方法相比，CLOMP 将大规模数据的效率提高了 100 到 1000 倍。在八个不同的图像数据集上的测试结果表明，CLOMP 分别将采样率为 0.1、0.3、0.5 的结构相似性指数提高了 292%、98%、45%。我们相信这种方法可以真正将 CS 重建带入 AI 时代，使依赖稀疏解的无数欠定线性系统受益。</paragraph>

##### **Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation on Non-Contrast Cardiac Computed Tomography**
2501.11428v1 by Jakub Nalepa, Tomasz Bartczak, Mariusz Bujny, Jarosław Gośliński, Katarzyna Jesionek, Wojciech Malara, Filip Malawski, Karol Miszalski-Jamka, Patrycja Rewa, Marcin Kostur

Despite coronary artery calcium scoring being considered a largely solved
problem within the realm of medical artificial intelligence, this paper argues
that significant improvements can still be made. By shifting the focus from
pathology detection to a deeper understanding of anatomy, the novel algorithm
proposed in the paper both achieves high accuracy in coronary artery calcium
scoring and offers enhanced interpretability of the results. This approach not
only aids in the precise quantification of calcifications in coronary arteries,
but also provides valuable insights into the underlying anatomical structures.
Through this anatomically-informed methodology, the paper shows how a nuanced
understanding of the heart's anatomy can lead to more accurate and
interpretable results in the field of cardiovascular health. We demonstrate the
superior accuracy of the proposed method by evaluating it on an open-source
multi-vendor dataset, where we obtain results at the inter-observer level,
surpassing the current state of the art. Finally, the qualitative analyses show
the practical value of the algorithm in such tasks as labeling coronary artery
calcifications, identifying aortic calcifications, and filtering out false
positive detections due to noise.

摘要：儘管冠狀動脈鈣化評分在醫學人工智慧領域被認為是一個已解決的問題，但本文論證仍有顯著進步的空間。透過將焦點從病理檢測轉移到對解剖結構的更深入理解，本文提出的新演算法在冠狀動脈鈣化評分中獲得高準確度，並提供了增強的結果可解釋性。這種方法不僅有助於精確量化冠狀動脈的鈣化，還提供了對底層解剖結構的寶貴見解。透過這種解剖學方法，本文展示了對心臟解剖結構的細緻理解如何能導致心血管健康領域更準確且可解釋的結果。我們透過在開放原始碼的多廠商資料集上評估所提出的方法，證明了其優越的準確度，我們在觀察者間層級獲得的結果超越了目前的技術水準。最後，定性分析顯示了該演算法在標記冠狀動脈鈣化、識別主動脈鈣化以及過濾掉因雜訊而產生的假陽性偵測等任務中的實用價值。

##### **RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?**
2501.11284v1 by Haotian Xu, Xing Wu, Weinong Wang, Zhongzhi Li, Da Zheng, Boyuan Chen, Yi Hu, Shijia Kang, Jiaming Ji, Yingying Zhang, Zhijiang Guo, Yaodong Yang, Muhan Zhang, Debing Zhang

Can scaling transform reasoning? In this work, we explore the untapped
potential of scaling Long Chain-of-Thought (Long-CoT) data to 1000k samples,
pioneering the development of a slow-thinking model, RedStar. Through extensive
experiments with various LLMs and different sizes, we uncover the ingredients
for specialization and scale for Long-CoT training. Surprisingly, even smaller
models show significant performance gains with limited data, revealing the
sample efficiency of Long-CoT and the critical role of sample difficulty in the
learning process. Our findings demonstrate that Long-CoT reasoning can be
effectively triggered with just a few thousand examples, while larger models
achieve unparalleled improvements. We also introduce reinforcement learning
(RL)-scale training as a promising direction for advancing slow-thinking
systems. RedStar shines across domains: on the MATH-Hard benchmark,
RedStar-code-math boosts performance from 66.2\% to 81.6\%, and on the USA Math
Olympiad (AIME), it solves 46.7\% of problems using only 21k mixed-code-math
datasets. In multimodal tasks like GeoQA and MathVista-GEO, RedStar-Geo
achieves competitive results with minimal Long-CoT data, outperforming other
slow-thinking systems like QvQ-Preview. Compared to QwQ, RedStar strikes the
perfect balance between reasoning and generalizability. Our work highlights
that, with careful tuning, scaling Long-CoT can unlock extraordinary reasoning
capabilities-even with limited dataset and set a new standard for slow-thinking
models across diverse challenges. Our data and models are released at
https://huggingface.co/RedStar-Reasoning.

摘要：<paragraph>縮放可以轉換推理嗎？在這項工作中，我們探索將長鏈思考（Long-CoT）資料縮放到 1000k 範例的未開發潛力，率先開發慢思考模型 RedStar。透過使用各種 LLM 和不同大小進行廣泛實驗，我們揭示了 Long-CoT 訓練的專業化和規模要素。令人驚訝的是，即使較小的模型在資料有限的情況下也展現出顯著的效能提升，揭示了 Long-CoT 的範例效率和範例難度在學習過程中扮演的關鍵角色。我們的發現證明，只要有數千個範例，就可以有效觸發 Long-CoT 推理，而較大的模型則可獲得無與倫比的改進。我們還導入強化學習 (RL) 規模訓練，作為推進慢思考系統的一個有前途的方向。RedStar 在各個領域中表現出色：在 MATH-Hard 基準測試中，RedStar-code-math 將效能從 66.2% 提升至 81.6%，而在美國數學奧林匹克（AIME）中，它僅使用 21k 個混合程式碼數學資料集就解決了 46.7% 的問題。在 GeoQA 和 MathVista-GEO 等多模態任務中，RedStar-Geo 在 Long-CoT 資料最少的情況下取得競爭力的結果，優於其他慢思考系統，例如 QvQ-Preview。與 QwQ 相比，RedStar 在推理和概括性之間取得了完美的平衡。我們的研究重點在於，透過仔細調整，縮放 Long-CoT 可以解鎖非凡的推理能力，即使在資料集有限的情況下，也能為各種挑戰設定慢思考模型的新標準。我們的資料和模型已於 https://huggingface.co/RedStar-Reasoning 發布。</paragraph>

##### **Spatiotemporal Air Quality Mapping in Urban Areas Using Sparse Sensor Data, Satellite Imagery, Meteorological Factors, and Spatial Features**
2501.11270v1 by Osama Ahmad, Zubair Khalid, Muhammad Tahir, Momin Uppal

Monitoring air pollution is crucial for protecting human health from exposure
to harmful substances. Traditional methods of air quality monitoring, such as
ground-based sensors and satellite-based remote sensing, face limitations due
to high deployment costs, sparse sensor coverage, and environmental
interferences. To address these challenges, this paper proposes a framework for
high-resolution spatiotemporal Air Quality Index (AQI) mapping using sparse
sensor data, satellite imagery, and various spatiotemporal factors. By
leveraging Graph Neural Networks (GNNs), we estimate AQI values at unmonitored
locations based on both spatial and temporal dependencies. The framework
incorporates a wide range of environmental features, including meteorological
data, road networks, points of interest (PoIs), population density, and urban
green spaces, which enhance prediction accuracy. We illustrate the use of our
approach through a case study in Lahore, Pakistan, where multi-resolution data
is used to generate the air quality index map at a fine spatiotemporal scale.

摘要：監控空氣污染對於保護人類健康免於接觸有害物質至關重要。傳統的空氣品質監測方法，例如地面感測器和衛星遙測，由於部署成本高、感測器覆蓋範圍稀疏以及環境干擾而面臨限制。為了應對這些挑戰，本文提出了一個使用稀疏感測器資料、衛星影像和各種時空因子來繪製高解析度時空空氣品質指數 (AQI) 的架構。透過利用圖形神經網路 (GNN)，我們根據空間和時間依賴性來估計未監控地點的 AQI 值。該架構結合了廣泛的環境特徵，包括氣象資料、道路網路、興趣點 (PoI)、人口密度和城市綠地，這些特徵增強了預測準確度。我們透過巴基斯坦拉合爾的一個案例研究來說明我們方法的使用，其中使用多解析度資料來生成精細時空尺度的空氣品質指數地圖。

##### **Clinical trial cohort selection using Large Language Models on n2c2 Challenges**
2501.11114v1 by Chi-en Amy Tai, Xavier Tannier

Clinical trials are a critical process in the medical field for introducing
new treatments and innovations. However, cohort selection for clinical trials
is a time-consuming process that often requires manual review of patient text
records for specific keywords. Though there have been studies on standardizing
the information across the various platforms, Natural Language Processing (NLP)
tools remain crucial for spotting eligibility criteria in textual reports.
Recently, pre-trained large language models (LLMs) have gained popularity for
various NLP tasks due to their ability to acquire a nuanced understanding of
text. In this paper, we study the performance of large language models on
clinical trial cohort selection and leverage the n2c2 challenges to benchmark
their performance. Our results are promising with regard to the incorporation
of LLMs for simple cohort selection tasks, but also highlight the difficulties
encountered by these models as soon as fine-grained knowledge and reasoning are
required.

摘要：臨床試驗是醫學領域中引入新療法和創新的關鍵過程。然而，臨床試驗的患者群體選擇是一個耗時的過程，通常需要人工審查病患的文字記錄，以尋找特定的關鍵字。儘管有研究針對不同平台上的資訊進行標準化，自然語言處理 (NLP) 工具對於在文字報告中找出符合資格的標準仍然至關重要。最近，預先訓練的大型語言模型 (LLM) 因其獲取細緻文本理解的能力而廣受各種 NLP 任務歡迎。在本文中，我們研究大型語言模型在臨床試驗患者群體選擇上的表現，並利用 n2c2 挑戰來評量其表現。我們的結果對於將 LLM 納入簡單的患者群體選擇任務而言是很有希望的，但也強調了這些模型在需要具備細緻知識和推理能力時所遇到的困難。

##### **Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**
2501.11094v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

Suicidal ideation detection is crucial for preventing suicides, a leading
cause of death worldwide. Many individuals express suicidal thoughts on social
media, offering a vital opportunity for early detection through advanced
machine learning techniques. The identification of suicidal ideation in social
media text is improved by utilising a hybrid framework that integrates
Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory
(BiLSTM), enhanced with an attention mechanism. To enhance the interpretability
of the model's predictions, Explainable AI (XAI) methods are applied, with a
particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At
first, the model managed to reach an accuracy of 92.81%. By applying
fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The
SHAP analysis revealed key features influencing the model's predictions, such
as terms related to mental health struggles. This level of transparency boosts
the model's credibility while helping mental health professionals understand
and trust the predictions. This work highlights the potential for improving the
accuracy and interpretability of detecting suicidal tendencies, making a
valuable contribution to the progress of mental health monitoring systems. It
emphasizes the significance of blending powerful machine learning methods with
explainability to develop reliable and impactful mental health solutions.

摘要：自殺意念偵測對於預防自殺至關重要，而自殺是全球主要的死亡原因。許多人在社群媒體上表達自殺念頭，這提供了透過進階機器學習技術進行早期偵測的重要機會。透過整合卷積神經網路 (CNN) 和雙向長短期記憶 (BiLSTM) 的混合架構，並加入注意力機制，可以提升在社群媒體文字中辨識自殺意念的能力。為了加強模型預測的可解釋性，我們採用可解釋人工智慧 (XAI) 方法，特別著重於 SHapley 加法解釋 (SHAP)。一開始，模型成功達到 92.81% 的準確度。透過套用微調和早期停止技術，準確度提升至 94.29%。SHAP 分析揭露了影響模型預測的關鍵特徵，例如與心理健康困境相關的詞彙。這種透明度提升了模型的可信度，同時協助心理健康專業人員理解和信賴預測結果。這項工作突顯了提升偵測自殺傾向的準確度和可解釋性的潛力，為心理健康監控系統的進展做出寶貴的貢獻。它強調了將強大的機器學習方法與可解釋性相結合以開發可靠且有影響力的心理健康解決方案的重要性。

##### **No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling**
2501.10814v1 by Young Seok Jeon, Hongfei Yang, Huazhu Fu, Mengling Feng

3D models are favored over 2D for 3D medical image segmentation tasks due to
their ability to leverage inter-slice relationship, yielding higher
segmentation accuracy. However, 3D models demand significantly more GPU memory
with increased model size and intermediate tensors. A common solution is to use
patch-based training and make whole-volume predictions with sliding window (SW)
inference. SW inference reduces memory usage but is slower due to equal
resource allocation across patches and less accurate as it overlooks global
features beyond patches.
  We propose NMSW-Net (No-More-Sliding-Window-Net), a novel framework that
enhances efficiency and accuracy of any given 3D segmentation model by
eliminating SW inference and incorporating global predictions when necessary.
NMSW-Net incorporates a differentiable Top-k module to sample only the relevant
patches that enhance segmentation accuracy, thereby minimizing redundant
computations. Additionally, it learns to leverage coarse global predictions
when patch prediction alone is insufficient. NMSW-Net is model-agnostic, making
it compatible with any 3D segmentation model that previously relied on SW
inference.
  Evaluated across 3 tasks with 3 segmentation backbones, NMSW-Net achieves
competitive or sometimes superior accuracy compared to SW, while reducing
computational complexity by 90% (87.5 to 7.95 TFLOPS), delivering 4x faster
inference on the H100 GPU (19.0 to 4.3 sec), and 7x faster inference on the
Intel Xeon Gold CPU (1710 to 230 seconds).

摘要：<paragraph>3D 模型在 3D 医学影像分割任务中优于 2D，因为
它们能够利用切片间关系，从而产生更高的
分割精度。然而，3D 模型需要大量 GPU 内存
随着模型大小和中间张量的增加。一种常见的解决方案是使用
基于 patch 的训练并使用滑动窗口 (SW)
推理进行全卷预测。SW 推理减少了内存使用量，但由于
在 patch 之间平均分配资源并且由于忽略了 patch 之外的全局
特征而导致速度较慢且准确度较低。
我们提出了 NMSW-Net（无滑动窗口网络），这是一种新颖的框架，它
通过消除 SW 推理并在必要时合并全局预测来提高任何给定 3D 分割模型的效率和准确性。
NMSW-Net 结合了一个可微分的 Top-k 模块来仅采样相关
patch，以提高分割精度，从而最大限度地减少冗余
计算。此外，它学会了在仅 patch 预测不足时利用粗略的全局预测。NMSW-Net 与模型无关，使其
与以前依赖 SW 的任何 3D 分割模型兼容
推理。
在 3 个带有 3 个分割主干的任务中进行评估，NMSW-Net 实现了
与 SW 相比具有竞争力或有时更高的准确性，同时减少
计算复杂度降低了 90%（87.5 到 7.95 TFLOPS），在 H100 GPU 上提供 4 倍更快的
推理（19.0 到 4.3 秒），以及在
英特尔至强金 CPU 上推理速度提高 7 倍（1710 到 230 秒）。</paragraph>

##### **Efficient Auto-Labeling of Large-Scale Poultry Datasets (ALPD) Using Semi-Supervised Models, Active Learning, and Prompt-then-Detect Approach**
2501.10809v1 by Ramesh Bahadur Bist, Lilong Chai, Shawna Weimer, Hannah Atungulua, Chantel Pennicott, Xiao Yang, Sachin Subedi, Chaitanya Pallerla, Yang Tian, Dongyi Wang

The rapid growth of AI in poultry farming has highlighted the challenge of
efficiently labeling large, diverse datasets. Manual annotation is
time-consuming, making it impractical for modern systems that continuously
generate data. This study explores semi-supervised auto-labeling methods,
integrating active learning, and prompt-then-detect paradigm to develop an
efficient framework for auto-labeling of large poultry datasets aimed at
advancing AI-driven behavior and health monitoring. Viideo data were collected
from broilers and laying hens housed at the University of Arkansas and the
University of Georgia. The collected videos were converted into images,
pre-processed, augmented, and labeled. Various machine learning models,
including zero-shot models like Grounding DINO, YOLO-World, and CLIP, and
supervised models like YOLO and Faster-RCNN, were utilized for broilers, hens,
and behavior detection. The results showed that YOLOv8s-World and YOLOv9s
performed better when compared performance metrics for broiler and hen
detection under supervised learning, while among the semi-supervised model,
YOLOv8s-ALPD achieved the highest precision (96.1%) and recall (99.0%) with an
RMSE of 1.9. The hybrid YOLO-World model, incorporating the optimal YOLOv8s
backbone, demonstrated the highest overall performance. It achieved a precision
of 99.2%, recall of 99.4%, and an F1 score of 98.7% for breed detection,
alongside a precision of 88.4%, recall of 83.1%, and an F1 score of 84.5% for
individual behavior detection. Additionally, semi-supervised models showed
significant improvements in behavior detection, achieving up to 31% improvement
in precision and 16% in F1-score. The semi-supervised models with minimal
active learning reduced annotation time by over 80% compared to full manual
labeling. Moreover, integrating zero-shot models enhanced detection and
behavior identification.

摘要：<paragraph>家禽养殖中人工智能的快速增长凸显了高效标注大型、多样化数据集的挑战。手动标注非常耗时，对于持续生成数据的现代系统而言不切实际。本研究探索了半监督自动标注方法，集成了主动学习和提示再检测范式，以开发一个高效的框架，用于自动标注大型家禽数据集，旨在推进人工智能驱动的行为和健康监测。视频数据是从阿肯色大学和佐治亚大学饲养的肉鸡和蛋鸡中收集的。收集的视频被转换成图像，经过预处理、增强和标注。各种机器学习模型，包括 Grounding DINO、YOLO-World 和 CLIP 等零样本学习模型，以及 YOLO 和 Faster-RCNN 等监督模型，被用于肉鸡、母鸡和行为检测。结果表明，在监督学习下，YOLOv8s-World 和 YOLOv9s 在肉鸡和母鸡检测的性能指标比较中表现得更好，而在半监督模型中，YOLOv8s-ALPD 以 1.9 的 RMSE 实现了最高的精度 (96.1%) 和召回率 (99.0%)。结合了最佳 YOLOv8s 主干网络的混合 YOLO-World 模型展示了最高的整体性能。它在品种检测中实现了 99.2% 的精度、99.4% 的召回率和 98.7% 的 F1 分数，在个体行为检测中实现了 88.4% 的精度、83.1% 的召回率和 84.5% 的 F1 分数。此外，半监督模型在行为检测中显示出显著的改进，在精度上提高了 31%，在 F1 分数上提高了 16%。与完全手动标注相比，具有最少主动学习的半监督模型将标注时间减少了 80% 以上。此外，集成零样本学习模型增强了检测和行为识别。</paragraph>

##### **MedFILIP: Medical Fine-grained Language-Image Pre-training**
2501.10775v1 by Xinjie Liang, Xiangyu Li, Fanding Li, Jie Jiang, Qing Dong, Wei Wang, Kuanquan Wang, Suyu Dong, Gongning Luo, Shuo Li

Medical vision-language pretraining (VLP) that leverages naturally-paired
medical image-report data is crucial for medical image analysis. However,
existing methods struggle to accurately characterize associations between
images and diseases, leading to inaccurate or incomplete diagnostic results. In
this work, we propose MedFILIP, a fine-grained VLP model, introduces medical
image-specific knowledge through contrastive learning, specifically: 1) An
information extractor based on a large language model is proposed to decouple
comprehensive disease details from reports, which excels in extracting disease
deals through flexible prompt engineering, thereby effectively reducing text
complexity while retaining rich information at a tiny cost. 2) A knowledge
injector is proposed to construct relationships between categories and visual
attributes, which help the model to make judgments based on image features, and
fosters knowledge extrapolation to unfamiliar disease categories. 3) A semantic
similarity matrix based on fine-grained annotations is proposed, providing
smoother, information-richer labels, thus allowing fine-grained image-text
alignment. 4) We validate MedFILIP on numerous datasets, e.g., RSNA-Pneumonia,
NIH ChestX-ray14, VinBigData, and COVID-19. For single-label, multi-label, and
fine-grained classification, our model achieves state-of-the-art performance,
the classification accuracy has increased by a maximum of 6.69\%. The code is
available in https://github.com/PerceptionComputingLab/MedFILIP.

摘要：醫學影像語言預訓練（VLP）利用自然配對的醫學影像報告數據，對於醫學影像分析至關重要。然而，現有方法難以準確描述影像與疾病之間的關聯性，導致診斷結果不準確或不完整。在這項工作中，我們提出 MedFILIP，一個細粒度的 VLP 模型，透過對比學習引入醫學影像特定知識，具體來說：1) 提出一個基於大型語言模型的資訊萃取器，從報告中解耦全面的疾病細節，透過靈活的提示工程，在提取疾病交易方面表現出色，從而有效降低文字複雜性，同時以極小的代價保留豐富的資訊。2) 提出一個知識注入器，用於建構類別與視覺屬性之間的關係，這有助於模型根據影像特徵進行判斷，並促進知識外推到不熟悉的疾病類別。3) 提出一個基於細粒度註解的語義相似矩陣，提供更平滑、資訊更豐富的標籤，從而允許進行細粒度的影像文字對齊。4) 我們在許多資料集上驗證 MedFILIP，例如 RSNA-Pneumonia、NIH ChestX-ray14、VinBigData 和 COVID-19。對於單標籤、多標籤和細粒度分類，我們的模型達到了最先進的效能，分類準確率最高提高了 6.69%。程式碼可在 https://github.com/PerceptionComputingLab/MedFILIP 中取得。

##### **Enhancing Diagnostic in 3D COVID-19 Pneumonia CT-scans through Explainable Uncertainty Bayesian Quantification**
2501.10770v1 by Juan Manuel Liscano Fierro, Hector J. Hortua

Accurately classifying COVID-19 pneumonia in 3D CT scans remains a
significant challenge in the field of medical image analysis. Although
deterministic neural networks have shown promising results in this area, they
provide only point estimates outputs yielding poor diagnostic in clinical
decision-making. In this paper, we explore the use of Bayesian neural networks
for classifying COVID-19 pneumonia in 3D CT scans providing uncertainties in
their predictions. We compare deterministic networks and their Bayesian
counterpart, enhancing the decision-making accuracy under uncertainty
information. Remarkably, our findings reveal that lightweight architectures
achieve the highest accuracy of 96\% after developing extensive hyperparameter
tuning. Furthermore, the Bayesian counterpart of these architectures via
Multiplied Normalizing Flow technique kept a similar performance along with
calibrated uncertainty estimates. Finally, we have developed a 3D-visualization
approach to explain the neural network outcomes based on SHAP values. We
conclude that explainability along with uncertainty quantification will offer
better clinical decisions in medical image analysis, contributing to ongoing
efforts for improving the diagnosis and treatment of COVID-19 pneumonia.

摘要：準確分類 3D 電腦斷層掃描中的 COVID-19 肺炎在醫學影像分析領域中仍是一項重大挑戰。儘管確定性神經網路已在此領域中展現出令人滿意的結果，但它們僅提供點估計輸出，在臨床決策中產生不良的診斷。在本文中，我們探討使用貝氏神經網路來分類 3D 電腦斷層掃描中的 COVID-19 肺炎，並在預測中提供不確定性。我們比較確定性網路及其貝氏對應網路，在不確定性資訊下提升決策的準確性。值得注意的是，我們的發現顯示，在經過廣泛的超參數調整後，輕量級架構可達到 96% 的最高準確度。此外，這些架構的貝氏對應網路透過乘法正規化流技術，在校準不確定性估計的同時，維持類似的效能。最後，我們已開發出 3D 視覺化方法，以根據 SHAP 值來解釋神經網路的結果。我們得出結論，可解釋性與不確定性量化將在醫學影像分析中提供更好的臨床決策，有助於持續改善 COVID-19 肺炎的診斷和治療。

##### **In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review**
2501.10727v1 by Amelia Jiménez-Sánchez, Natalia-Rozalia Avlona, Sarah de Boer, Víctor M. Campello, Aasa Feragen, Enzo Ferrante, Melanie Ganz, Judy Wawira Gichoya, Camila González, Steff Groefsema, Alessa Hering, Adam Hulman, Leo Joskowicz, Dovile Juodelyte, Melih Kandemir, Thijs Kooi, Jorge del Pozo Lérida, Livie Yumeng Li, Andre Pacheco, Tim Rädsch, Mauricio Reyes, Théo Sourget, Bram van Ginneken, David Wen, Nina Weng, Jack Junchi Xu, Hubert Dariusz Zając, Maria A. Zuluaga, Veronika Cheplygina

Datasets play a critical role in medical imaging research, yet issues such as
label quality, shortcuts, and metadata are often overlooked. This lack of
attention may harm the generalizability of algorithms and, consequently,
negatively impact patient outcomes. While existing medical imaging literature
reviews mostly focus on machine learning (ML) methods, with only a few focusing
on datasets for specific applications, these reviews remain static -- they are
published once and not updated thereafter. This fails to account for emerging
evidence, such as biases, shortcuts, and additional annotations that other
researchers may contribute after the dataset is published. We refer to these
newly discovered findings of datasets as research artifacts. To address this
gap, we propose a living review that continuously tracks public datasets and
their associated research artifacts across multiple medical imaging
applications. Our approach includes a framework for the living review to
monitor data documentation artifacts, and an SQL database to visualize the
citation relationships between research artifact and dataset. Lastly, we
discuss key considerations for creating medical imaging datasets, review best
practices for data annotation, discuss the significance of shortcuts and
demographic diversity, and emphasize the importance of managing datasets
throughout their entire lifecycle. Our demo is publicly available at
http://130.226.140.142.

摘要：<paragraph>資料集在醫學影像研究中扮演著至關重要的角色，然而標籤品質、捷徑和元資料等問題卻常常被忽略。這種缺乏關注的現象可能會損害演算法的概括性，進而對病患的治療結果造成負面影響。雖然現有的醫學影像文獻回顧大多集中於機器學習 (ML) 方法，只有少數回顧著重於特定應用程式的資料集，但這些回顧仍然是靜態的——它們只會發表一次，之後不會再更新。這無法考量新出現的證據，例如偏誤、捷徑和資料集在發表後其他研究人員可能提供的額外註解。我們將這些新發現的資料集發現稱為研究成果。為了解決這個問題，我們提出一個持續追蹤公開資料集及其與多個醫學影像應用程式相關的研究成果的動態回顧。我們的做法包括一個用於監控資料文件成果的動態回顧架構，以及一個用於視覺化研究成果與資料集之間引用關係的 SQL 資料庫。最後，我們討論建立醫學影像資料集時的主要考量因素，回顧資料註解的最佳實務，探討捷徑和人口統計多樣性的重要性，並強調在資料集的整個生命週期中管理資料集的重要性。我們的示範可於 http://130.226.140.142 公開取得。</paragraph>

##### **An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach**
2501.10300v1 by Navya Martin Kollapally, James Geller, Patricia Morreale, Daehan Kwak

The use of computational ontologies is well-established in the field of
Medical Informatics. The topic of Social Determinants of Health (SDoH) has also
received extensive attention. Work at the intersection of ontologies and SDoH
has been published. However, a standardized framework for Social Determinants
of Education (SDoEd) is lacking. In this paper, we are closing the gap by
introducing an SDoEd ontology for creating a precise conceptualization of the
interplay between life circumstances of students and their possible educational
achievements. The ontology was developed utilizing suggestions from
ChatGPT-3.5-010422 and validated using peer-reviewed research articles. The
first version of developed ontology was evaluated by human experts in the field
of education and validated using standard ontology evaluation software. This
version of the SDoEd ontology contains 231 domain concepts, 10 object
properties, and 24 data properties

摘要：在醫學資訊學領域中，計算本體的使用已經相當普遍。社會健康決定因素（SDoH）的主題也受到廣泛的關注。本體與 SDoH 交集處的工作已經發表。然而，社會教育決定因素（SDoEd）的標準化架構卻付之闕如。在本文中，我們透過引入 SDoEd 本體來填補這個缺口，以建立學生生活環境與其可能教育成就之間相互作用的精確概念化。本體是利用 ChatGPT-3.5-010422 的建議開發的，並使用同行評審的研究文章進行驗證。開發本體的第一個版本由教育領域的人類專家評估，並使用標準本體評估軟體進行驗證。此版本的 SDoEd 本體包含 231 個網域概念、10 個物件屬性和 24 個資料屬性

##### **SEANN: A Domain-Informed Neural Network for Epidemiological Insights**
2501.10273v1 by Jean-Baptiste Guimbaud, Marc Plantevit, Léa Maître, Rémy Cazabet

In epidemiology, traditional statistical methods such as logistic regression,
linear regression, and other parametric models are commonly employed to
investigate associations between predictors and health outcomes. However,
non-parametric machine learning techniques, such as deep neural networks
(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for
this task. Despite their potential, these methods face challenges due to the
limited availability of high-quality, high-quantity data in this field. To
address these challenges, we introduce SEANN, a novel approach for informed
DNNs that leverages a prevalent form of domain-specific knowledge: Pooled
Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,
in different forms, and represent a quantitative form of a scientific
consensus. By direct integration within the learning procedure using a custom
loss, we experimentally demonstrate significant improvements in the
generalizability of predictive performances and the scientific plausibility of
extracted relationships compared to a domain-knowledge agnostic neural network
in a scarce and noisy data setting.

摘要：在流行病學中，傳統的統計方法，例如邏輯迴歸、線性迴歸和其他參數模型通常用於調查預測因子與健康結果之間的關聯。然而，非參數機器學習技術，例如深度神經網路 (DNN)，結合可解釋的 AI (XAI) 工具，為這項任務提供了新的機會。儘管這些方法具有潛力，但由於該領域缺乏高品質、高數量資料，因此這些方法面臨挑戰。為了應對這些挑戰，我們引入了 SEANN，這是一種新穎的方法，用於獲取知識的 DNN，它利用了一種流行的領域特定知識形式：彙總效應量 (PES)。PES 通常以不同的形式出現在已發表的 Meta 分析研究中，並代表科學共識的量化形式。通過使用自訂損失函數直接整合在學習程序中，我們以實驗方式證明了預測效能的概括性以及與從缺乏領域知識的神經網路中提取的關係相比，科學合理性的顯著提升，且是在稀少且有雜訊的資料設定中。

##### **Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide**
2501.10240v1 by Elena Albu, Shan Gao, Pieter Stijnen, Frank E. Rademakers, Bas C T van Bussel, Taya Collyer, Tina Hernandez-Boussard, Laure Wynants, Ben Van Calster

Dynamic predictive modeling using electronic health record (EHR) data has
gained significant attention in recent years. The reliability and
trustworthiness of such models depend heavily on the quality of the underlying
data, which is largely determined by the stages preceding the model
development: data extraction from EHR systems and data preparation. We list
over forty challenges encountered during these stages and provide actionable
recommendations for addressing them. These challenges are organized into four
categories: cohort definition, outcome definition, feature engineering, and
data cleaning. This list is designed to serve as a practical guide for data
extraction engineers and researchers, supporting better practices and improving
the quality and real-world applicability of dynamic prediction models in
clinical settings.

摘要：近年來，使用電子健康記錄 (EHR) 資料的動態預測模型獲得了極大的關注。此類模型的可靠性和可信度在很大程度上取決於基礎資料的品質，而這在很大程度上取決於模型開發之前的階段：從 EHR 系統中提取資料和資料準備。我們列出了這些階段中遇到的四十多項挑戰，並提供了具體可行的建議來解決這些挑戰。這些挑戰分為四類：群組定義、結果定義、特徵工程和資料清理。此清單旨在作為資料提取工程師和研究人員的實用指南，支援更好的實務，並改善動態預測模型在臨床環境中的品質和實際應用性。

##### **Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education**
2501.10186v1 by William Hersh

Generative AI has had a profound impact on biomedicine and health, both in
professional work and in education. Based on large language models (LLMs),
generative AI has been found to perform as well as humans in simulated
situations taking medical board exams, answering clinical questions, solving
clinical cases, applying clinical reasoning, and summarizing information.
Generative AI is also being used widely in education, performing well in
academic courses and their assessments. This review summarizes the successes of
LLMs and highlights some of their challenges in the context of education, most
notably aspects that may undermines the acquisition of knowledge and skills for
professional work. It then provides recommendations for best practices
overcoming shortcomings for LLM use in education. Although there are challenges
for use of generative AI in education, all students and faculty, in biomedicine
and health and beyond, must have understanding and be competent in its use.

摘要：生成式 AI 對生物醫學和健康領域產生了深遠的影響，無論是在專業工作還是教育方面。基於大型語言模型 (LLM)，發現生成式 AI 在模擬醫療委員會考試、回答臨床問題、解決臨床案例、應用臨床推理和總結資訊等情況下，表現得與人類一樣好。生成式 AI 也廣泛應用於教育中，在學術課程及其評估中表現良好。本篇評論總結了 LLM 的成功，並強調了它們在教育背景下的一些挑戰，最值得注意的是可能損害專業工作知識和技能習得的方面。然後，它針對克服 LLM 在教育中使用的缺點提供了最佳實務建議。儘管生成式 AI 在教育中使用存在挑戰，但生物醫學和健康領域以及其他領域的所有學生和教職員工都必須了解並熟練使用它。

##### **CSSDM Ontology to Enable Continuity of Care Data Interoperability**
2501.10160v1 by Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez, Pamela Hussey

The rapid advancement of digital technologies and recent global pandemic
scenarios have led to a growing focus on how these technologies can enhance
healthcare service delivery and workflow to address crises. Action plans that
consolidate existing digital transformation programs are being reviewed to
establish core infrastructure and foundations for sustainable healthcare
solutions. Reforming health and social care to personalize home care, for
example, can help avoid treatment in overcrowded acute hospital settings and
improve the experiences and outcomes for both healthcare professionals and
service users. In this information-intensive domain, addressing the
interoperability challenge through standards-based roadmaps is crucial for
enabling effective connections between health and social care services. This
approach facilitates safe and trustworthy data workflows between different
healthcare system providers. In this paper, we present a methodology for
extracting, transforming, and loading data through a semi-automated process
using a Common Semantic Standardized Data Model (CSSDM) to create personalized
healthcare knowledge graph (KG). The CSSDM is grounded in the formal ontology
of ISO 13940 ContSys and incorporates FHIR-based specifications to support
structural attributes for generating KGs. We propose that the CSSDM facilitates
data harmonization and linking, offering an alternative approach to
interoperability. This approach promotes a novel form of collaboration between
companies developing health information systems and cloud-enabled health
services. Consequently, it provides multiple stakeholders with access to
high-quality data and information sharing.

摘要：數位科技快速進步和最近的全球大流行病情境已導致越來越多人專注於這些科技如何增強醫療保健服務提供和工作流程以應對危機。整合現有數位轉型計畫的行動計畫正被檢視，以建立永續醫療保健解決方案的核心基礎架構和基礎。例如，改革醫療和社會照護以個人化居家照護，有助於避免在人滿為患的急性醫院環境中接受治療，並改善醫療保健專業人員和服務使用者的經驗和結果。在這個資訊密集的領域，透過基於標準的路徑圖來解決互通性挑戰，對於促成醫療保健服務和社會照護服務之間的有效連結至關重要。此方法促成不同醫療保健系統供應商之間安全且值得信賴的資料工作流程。在本文中，我們提出一個方法，透過半自動化流程使用通用語意標準化資料模型 (CSSDM) 來萃取、轉換和載入資料，以建立個人化的醫療保健知識圖譜 (KG)。CSSDM 以 ISO 13940 ContSys 的正式本体論為基礎，並結合基於 FHIR 的規格來支援用於產生 KG 的結構屬性。我們提出 CSSDM 促進資料調和和連結，提供一種互通性的替代方法。此方法促成開發醫療資訊系統和雲端醫療服務的公司之間的一種新型合作形式。因此，它提供多個利害關係人存取高品質資料和資訊共享。

##### **landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images**
2501.10098v1 by Jef Jonkers, Luc Duchateau, Glenn Van Wallendael, Sofie Van Hoecke

Anatomical landmark localization in 2D/3D images is a critical task in
medical imaging. Although many general-purpose tools exist for landmark
localization in classical computer vision tasks, such as pose estimation, they
lack the specialized features and modularity necessary for anatomical landmark
localization applications in the medical domain. Therefore, we introduce
landmarker, a Python package built on PyTorch. The package provides a
comprehensive, flexible toolkit for developing and evaluating landmark
localization algorithms, supporting a range of methodologies, including static
and adaptive heatmap regression. landmarker enhances the accuracy of landmark
identification, streamlines research and development processes, and supports
various image formats and preprocessing pipelines. Its modular design allows
users to customize and extend the toolkit for specific datasets and
applications, accelerating innovation in medical imaging. landmarker addresses
a critical need for precision and customization in landmark localization tasks
not adequately met by existing general-purpose pose estimation tools.

摘要：在 2D/3D 影像中進行解剖標誌定位是醫學影像中的一項關鍵任務。儘管有許多通用工具可用於經典電腦視覺任務中的標誌定位，例如姿勢估計，但它們缺乏解剖標誌定位應用在醫學領域中所需的專業功能和模組化。因此，我們引入了 landmarker，一個建立在 PyTorch 上的 Python 套件。該套件提供了一個全面且靈活的工具包，用於開發和評估標誌定位演算法，支援各種方法，包括靜態和自適應熱圖回歸。landmarker 提升了標誌識別的準確性，簡化了研究和開發流程，並支援各種影像格式和前處理管道。其模組化設計使用戶能夠自訂和延伸工具包，以適用於特定資料集和應用，加速醫學影像的創新。landmarker 滿足了現有通用姿勢估計工具無法充分滿足的標誌定位任務中對於精確度和自訂化的關鍵需求。

##### **Deep Learning for Early Alzheimer Disease Detection with MRI Scans**
2501.09999v1 by Mohammad Rafsan, Tamer Oraby, Upal Roy, Sanjeev Kumar, Hansapani Rodrigo

Alzheimer's Disease is a neurodegenerative condition characterized by
dementia and impairment in neurological function. The study primarily focuses
on the individuals above age 40, affecting their memory, behavior, and
cognitive processes of the brain. Alzheimer's disease requires diagnosis by a
detailed assessment of MRI scans and neuropsychological tests of the patients.
This project compares existing deep learning models in the pursuit of enhancing
the accuracy and efficiency of AD diagnosis, specifically focusing on the
Convolutional Neural Network, Bayesian Convolutional Neural Network, and the
U-net model with the Open Access Series of Imaging Studies brain MRI dataset.
Besides, to ensure robustness and reliability in the model evaluations, we
address the challenge of imbalance in data. We then perform rigorous evaluation
to determine strengths and weaknesses for each model by considering
sensitivity, specificity, and computational efficiency. This comparative
analysis would shed light on the future role of AI in revolutionizing AD
diagnostics but also paved ways for future innovation in medical imaging and
the management of neurodegenerative diseases.

摘要：阿茲海默症是一種神經退化性疾病，特徵為失智和神經功能受損。本研究主要針對 40 歲以上的個人，影響他們的記憶力、行為和認知過程。阿茲海默症需要透過詳細評估病患的 MRI 掃描和神經心理測試來診斷。本專案比較現有的深度學習模型，以尋求提升 AD 診斷的準確性和效率，特別著重於卷積神經網路、貝氏卷積神經網路和 U-net 模型，以及開放取用影像研究系列的腦部 MRI 資料集。此外，為了確保模型評估的穩健性和可靠性，我們解決了資料不平衡的挑戰。接著我們執行嚴謹的評估，透過考量敏感度、特異度和計算效率來確定每個模型的優缺點。此比較分析將闡明 AI 在革新 AD 診斷方面的未來角色，也為醫學影像和神經退化性疾病管理的未來創新鋪路。

##### **Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics**
2501.09980v1 by Xigui Li, Yuanye Zhou, Feiyang Xiao, Xin Guo, Yichi Zhang, Chen Jiang, Jianchao Ge, Xiansheng Wang, Qimeng Wang, Taiwei Zhang, Chensen Lin, Yuan Cheng, Yuan Qi

Intracranial aneurysm (IA) is a common cerebrovascular disease that is
usually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if
ruptured. Although clinical practice is usually based on individual factors and
morphological features of the aneurysm, its pathophysiology and hemodynamic
mechanisms remain controversial. To address the limitations of current
research, this study constructed a comprehensive hemodynamic dataset of
intracranial aneurysms. The dataset is based on 466 real aneurysm models, and
10,000 synthetic models were generated by resection and deformation operations,
including 466 aneurysm-free models and 9,534 deformed aneurysm models. The
dataset also provides medical image-like segmentation mask files to support
insightful analysis. In addition, the dataset contains hemodynamic data
measured at eight steady-state flow rates (0.001 to 0.004 kg/s), including
critical parameters such as flow velocity, pressure, and wall shear stress,
providing a valuable resource for investigating aneurysm pathogenesis and
clinical prediction. This dataset will help advance the understanding of the
pathologic features and hemodynamic mechanisms of intracranial aneurysms and
support in-depth research in related fields. Dataset hosted at
https://github.com/Xigui-Li/Aneumo.

摘要：顱內動脈瘤（IA）是一種常見的腦血管疾病，通常無症狀，但如果破裂可能會導致嚴重的蛛網膜下腔出血（SAH）。儘管臨床實務通常基於個體因素和動脈瘤的形態特徵，但其病理生理學和血流動力學機制仍存在爭議。為了解決當前研究的限制，本研究構建了一個顱內動脈瘤的全面血流動力學數據集。該數據集基於 466 個真實動脈瘤模型，並通過切除和變形操作生成了 10,000 個合成模型，包括 466 個無動脈瘤模型和 9,534 個變形動脈瘤模型。該數據集還提供了類醫學影像的分割遮罩檔案，以支持深入分析。此外，該數據集包含在八個穩態流速（0.001 至 0.004 kg/s）下測量的血流動力學數據，包括流速、壓力和壁面剪應力等關鍵參數，為研究動脈瘤發病機制和臨床預測提供了寶貴的資源。此數據集將有助於增進對顱內動脈瘤病理特徵和血流動力學機制的了解，並支持相關領域的深入研究。數據集託管於 https://github.com/Xigui-Li/Aneumo。

##### **Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude**
2501.10484v1 by Yile Yan, Yuqi Zhu, Wentao Xu

Recent advances in Large Language Models (LLMs) have enabled human-like
responses across various tasks, raising questions about their ethical
decision-making capabilities and potential biases. This study investigates
protected attributes in LLMs through systematic evaluation of their responses
to ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5
Sonnet - we analyzed their decision-making patterns across multiple protected
attributes including age, gender, race, appearance, and disability status.
Through 11,200 experimental trials involving both single-factor and two-factor
protected attribute combinations, we evaluated the models' ethical preferences,
sensitivity, stability, and clustering of preferences. Our findings reveal
significant protected attributeses in both models, with consistent preferences
for certain features (e.g., "good-looking") and systematic neglect of others.
Notably, while GPT-3.5 Turbo showed stronger preferences aligned with
traditional power structures, Claude 3.5 Sonnet demonstrated more diverse
protected attribute choices. We also found that ethical sensitivity
significantly decreases in more complex scenarios involving multiple protected
attributes. Additionally, linguistic referents heavily influence the models'
ethical evaluations, as demonstrated by differing responses to racial
descriptors (e.g., "Yellow" versus "Asian"). These findings highlight critical
concerns about the potential impact of LLM biases in autonomous decision-making
systems and emphasize the need for careful consideration of protected
attributes in AI development. Our study contributes to the growing body of
research on AI ethics by providing a systematic framework for evaluating
protected attributes in LLMs' ethical decision-making capabilities.

摘要：大型語言模型 (LLM) 近期的進展，讓人們在各種任務中都能做出類似人類的回應，這也引發了人們對其道德決策能力和潛在偏見的質疑。本研究透過系統性地評估 LLM 對道德困境的回應，來探討受保護屬性在 LLM 中的表現。我們使用兩個著名的模型 - GPT-3.5 Turbo 和 Claude 3.5 Sonnet - 分析了它們在多個受保護屬性（包括年齡、性別、種族、外貌和殘疾狀態）上的決策模式。透過 11,200 次實驗試驗（包括單因素和雙因素受保護屬性組合），我們評估了模型的道德偏好、敏感度、穩定性和偏好群集。我們的研究結果揭示了這兩個模型中顯著的受保護屬性，它們對某些特徵（例如「好看」）有持續的偏好，並且系統性地忽略其他特徵。值得注意的是，雖然 GPT-3.5 Turbo 表現出與傳統權力結構一致的強烈偏好，但 Claude 3.5 Sonnet 則表現出更多樣化的受保護屬性選擇。我們還發現，在涉及多個受保護屬性的更複雜場景中，道德敏感度會顯著降低。此外，語言指稱會嚴重影響模型的道德評估，這從對種族描述符（例如「黃色」與「亞洲人」）的不同回應中可以看出。這些發現突顯了 LLM 偏見在自主決策系統中潛在影響的關鍵問題，並強調在 AI 開發中仔細考慮受保護屬性的必要性。我們的研究透過提供一個系統性的架構來評估 LLM 道德決策能力中的受保護屬性，為 AI 倫理領域的研究做出了貢獻。

##### **Bridging Language Barriers in Healthcare: A Study on Arabic LLMs**
2501.09825v1 by Nada Saadi, Tathagata Raha, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, Praveen K Kanithi

This paper investigates the challenges of developing large language models
(LLMs) proficient in both multilingual understanding and medical knowledge. We
demonstrate that simply translating medical data does not guarantee strong
performance on clinical tasks in the target language. Our experiments reveal
that the optimal language mix in training data varies significantly across
different medical tasks. We find that larger models with carefully calibrated
language ratios achieve superior performance on native-language clinical tasks.
Furthermore, our results suggest that relying solely on fine-tuning may not be
the most effective approach for incorporating new language knowledge into LLMs.
Instead, data and computationally intensive pretraining methods may still be
necessary to achieve optimal performance in multilingual medical settings.
These findings provide valuable guidance for building effective and inclusive
medical AI systems for diverse linguistic communities.

摘要：本文探討了開發既精通多語言理解又精通醫療知識的大型語言模型 (LLM) 的挑戰。我們證明，僅翻譯醫療資料並不能保證在目標語言的臨床任務中表現出色。我們的實驗揭示，訓練資料中的最佳語言組合因不同的醫療任務而異。我們發現，具有仔細校準語言比例的較大模型在母語臨床任務中表現更佳。此外，我們的結果表明，僅依賴微調可能不是將新的語言知識納入 LLM 的最有效方法。相反，資料和計算密集型預訓練方法對於在多語言醫療環境中實現最佳效能可能仍然必要。這些發現為建立有效且包容性的醫療 AI 系統，以服務於不同的語言社群，提供了有價值的指導方針。

##### **KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**
2501.09744v1 by Hajung Kim, Chanhwi Kim, Jiwoong Sohn, Tim Beck, Marek Rei, Sunkyu Kim, T Ian Simpson, Joram M Posma, Antoine Lain, Mujeen Sung, Jaewoo Kang

The objective of BioCreative8 Track 3 is to extract phenotypic key medical
findings embedded within EHR texts and subsequently normalize these findings to
their Human Phenotype Ontology (HPO) terms. However, the presence of diverse
surface forms in phenotypic findings makes it challenging to accurately
normalize them to the correct HPO terms. To address this challenge, we explored
various models for named entity recognition and implemented data augmentation
techniques such as synonym marginalization to enhance the normalization step.
Our pipeline resulted in an exact extraction and normalization F1 score 2.6\%
higher than the mean score of all submissions received in response to the
challenge. Furthermore, in terms of the normalization F1 score, our approach
surpassed the average performance by 1.9\%. These findings contribute to the
advancement of automated medical data extraction and normalization techniques,
showcasing potential pathways for future research and application in the
biomedical domain.

摘要：BioCreative8 軌道 3 的目標是從電子病歷文本中萃取表型關鍵醫療發現，並將這些發現標準化為人類表型本体 (HPO) 條款。然而，表型發現中存在多樣化的表面形式，這使得將其準確標準化為正確的 HPO 條款具有挑戰性。為了應對這一挑戰，我們探討了命名實體識別的各種模型，並實作了資料擴充技術，例如同義詞邊緣化，以增強標準化步驟。我們的管道產生了精確的萃取和標準化 F1 分數，比回應挑戰所收到的所有提交的平均分數高 2.6%。此外，在標準化 F1 分數方面，我們的做法比平均表現高出 1.9%。這些發現有助於自動化醫療資料萃取和標準化技術的進展，展示了生物醫學領域未來研究和應用的潛在途徑。

##### **Electronic Health Records: Towards Digital Twins in Healthcare**
2501.09640v1 by Muhammet Alkan, Hester Huijsdens, Yola Jones, Fani Deligianni

The pivotal shift from traditional paper-based records to sophisticated
Electronic Health Records (EHR), enabled systematic collection and analysis of
patient data through descriptive statistics, providing insight into patterns
and trends across patient populations. This evolution continued toward
predictive analytics, allowing healthcare providers to anticipate patient
outcomes and potential complications before they occur. This progression from
basic digital record-keeping to sophisticated predictive modelling and digital
twins reflects healthcare's broader evolution toward more integrated,
patient-centred approaches that combine data-driven insights with personalized
care delivery. This chapter explores the evolution and significance of
healthcare information systems, beginning with an examination of the
implementation of EHR in the UK and the USA. It provides a comprehensive
overview of the International Classification of Diseases (ICD) system, tracing
its development from ICD-9 to ICD-10. Central to this discussion is the
MIMIC-III database, a landmark achievement in healthcare data sharing and
arguably the most comprehensive critical care database freely available to
researchers worldwide. MIMIC-III has democratized access to high-quality
healthcare data, enabling unprecedented opportunities for research and
analysis. The chapter examines its structure, clinical outcome analysis
capabilities, and practical applications through case studies, with a
particular focus on mortality and length of stay metrics, vital signs
extraction, and ICD coding. Through detailed entity-relationship diagrams and
practical examples, the text illustrates MIMIC's complex data structure and
demonstrates how different querying approaches can lead to subtly different
results, emphasizing the critical importance of understanding the database's
architecture for accurate data extraction.

摘要：從傳統紙本記錄轉變為先進的電子健康記錄（EHR），促使透過描述性統計系統性地收集和分析病患資料，進而深入了解病患族群的模式和趨勢。這項演進持續朝向預測分析發展，讓醫療保健提供者能夠在病患出現結果和潛在併發症之前預測這些狀況。從基本的數位記錄保存進展到先進的預測模型和數位雙胞胎，反映了醫療保健朝向更整合、以病患為中心的做法所做的更廣泛演進，這些做法結合了資料驅動的見解與個人化照護服務。本章探討醫療保健資訊系統的演進和重要性，從審查英國和美國實施 EHR 開始。它提供了疾病國際分類（ICD）系統的全面概述，追溯其從 ICD-9 發展到 ICD-10 的過程。此討論的核心是 MIMIC-III 資料庫，這是醫療保健資料共享的一項里程碑式成就，可以說是全球研究人員可以免費取得的最全面的重症照護資料庫。MIMIC-III 民主化了對高品質醫療保健資料的存取，為研究和分析創造了前所未有的機會。本章透過案例研究探討其結構、臨床結果分析能力和實際應用，特別關注死亡率和住院時間指標、生命徵象萃取和 ICD 編碼。透過詳細的實體關係圖和實務範例，本文說明了 MIMIC 複雜的資料結構，並展示了不同的查詢方法如何導致細微不同的結果，強調了了解資料庫架構對於準確萃取資料至關重要的重要性。

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v1 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

摘要：隨著人工智慧 (AI) 在醫療保健中的應用日益普及，本章探討了開發可靠且符合道德標準的臨床決策支援系統 (CDSS) 的關鍵面向。從傳統統計模型到複雜機器學習方法的基本轉變開始，這項工作審查了嚴謹的驗證策略和效能評估方法，包括模型校準和決策曲線分析的關鍵角色。本章強調，在醫療保健中建立值得信賴的 AI 系統不只是技術上的準確性；它需要仔細考量公平性、可解釋性和隱私權。本章強調了透過 AI 確保公平的醫療保健服務的挑戰，並討論了識別和減輕臨床預測模型中偏差的方法。接著，本章深入探討可解釋性，作為以人為中心的 CDSS 的基石。這種關注反映了醫療保健專業人員不僅必須信任 AI 建議，還必須理解其背後的推理。討論進一步分析了醫療 AI 系統中的隱私漏洞，從深度學習模型中的資料外洩到針對模型解釋的複雜攻擊。本文探討了隱私保護策略，例如差分隱私和聯合學習，同時承認隱私保護和模型效能之間的固有取捨。這種從技術驗證到道德考量的進展，反映了開發 AI 系統的多面向挑戰，這些系統可以無縫且可靠地整合到日常臨床實務中，同時維持最高的病患照護和資料保護標準。

##### **IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients**
2501.09595v1 by Simone Macciò, Alessandro Carfì, Alessio Capitanelli, Peppino Tropea, Massimo Corbo, Fulvio Mastrogiovanni, Michela Picardi

Effective fall risk assessment is critical for post-stroke patients. The
present study proposes a novel, data-informed fall risk assessment method based
on the instrumented Timed Up and Go (ITUG) test data, bringing in many mobility
measures that traditional clinical scales fail to capture. IFRA, which stands
for Instrumented Fall Risk Assessment, has been developed using a two-step
process: first, features with the highest predictive power among those
collected in a ITUG test have been identified using machine learning
techniques; then, a strategy is proposed to stratify patients into low, medium,
or high-risk strata. The dataset used in our analysis consists of 142
participants, out of which 93 were used for training (15 synthetically
generated), 17 for validation and 32 to test the resulting IFRA scale (22
non-fallers and 10 fallers). Features considered in the IFRA scale include gait
speed, vertical acceleration during sit-to-walk transition, and turning angular
velocity, which align well with established literature on the risk of fall in
neurological patients. In a comparison with traditional clinical scales such as
the traditional Timed Up & Go and the Mini-BESTest, IFRA demonstrates
competitive performance, being the only scale to correctly assign more than
half of the fallers to the high-risk stratum (Fischer's Exact test p = 0.004).
Despite the dataset's limited size, this is the first proof-of-concept study to
pave the way for future evidence regarding the use of IFRA tool for continuous
patient monitoring and fall prevention both in clinical stroke rehabilitation
and at home post-discharge.

摘要：<paragraph>對中風後患者而言，有效的跌倒風險評估至關重要。本研究提出一個創新的、基於資料的跌倒風險評估方法，該方法基於儀器化的計時起身及行走 (ITUG) 測試資料，納入了許多傳統臨床量表未能捕捉到的活動能力測量指標。IFRA，代表儀器化跌倒風險評估，已使用兩步驟流程開發：首先，已使用機器學習技術識別出在 ITUG 測試中收集的那些具有最高預測能力的特徵；然後，提出了一項策略將患者分層為低風險、中風險或高風險等級。我們的分析中使用的資料集包含 142 名參與者，其中 93 名用於訓練（15 名合成產生），17 名用於驗證，32 名用於測試產生的 IFRA 量表（22 名非跌倒者和 10 名跌倒者）。IFRA 量表中考慮的特徵包括步態速度、坐到走過渡期間的垂直加速度和轉彎角速度，這些特徵與已建立的神經病患跌倒風險文獻非常吻合。與傳統臨床量表（例如傳統的計時起身及行走和迷你 BESTest）相比，IFRA 表現出競爭優勢，是唯一將超過一半的跌倒者正確分配到高風險階層的量表（Fisher 精確檢定 p = 0.004）。儘管資料集規模有限，但這是第一個概念驗證研究，為未來關於在臨床中風康復和出院後居家跌倒預防中使用 IFRA 工具的證據鋪路。</paragraph>

##### **Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation**
2501.09309v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

This review underscores the critical need for effective strategies to
identify and support individuals with suicidal ideation, exploiting
technological innovations in ML and DL to further suicide prevention efforts.
The study details the application of these technologies in analyzing vast
amounts of unstructured social media data to detect linguistic patterns,
keywords, phrases, tones, and contextual cues associated with suicidal
thoughts. It explores various ML and DL models like SVMs, CNNs, LSTM, neural
networks, and their effectiveness in interpreting complex data patterns and
emotional nuances within text data. The review discusses the potential of these
technologies to serve as a life-saving tool by identifying at-risk individuals
through their digital traces. Furthermore, it evaluates the real-world
effectiveness, limitations, and ethical considerations of employing these
technologies for suicide prevention, stressing the importance of responsible
development and usage. The study aims to fill critical knowledge gaps by
analyzing recent studies, methodologies, tools, and techniques in this field.
It highlights the importance of synthesizing current literature to inform
practical tools and suicide prevention efforts, guiding innovation in reliable,
ethical systems for early intervention. This research synthesis evaluates the
intersection of technology and mental health, advocating for the ethical and
responsible application of ML, DL, and NLP to offer life-saving potential
worldwide while addressing challenges like generalizability, biases, privacy,
and the need for further research to ensure these technologies do not
exacerbate existing inequities and harms.

摘要：這篇評論強調了有效策略的重要需求，以透過利用機器學習和深度學習的技術創新來識別和支持有自殺意念的人，進一步促進自殺防治工作。這項研究詳細說明了這些技術在分析大量非結構化社群媒體資料中的應用，以偵測與自殺念頭相關的語言模式、關鍵字、詞組、語氣和脈絡線索。它探討了各種機器學習和深度學習模型，例如支援向量機、卷積神經網路、長短期記憶網路、神經網路，以及它們在解讀文字資料中的複雜資料模式和情緒細微差別方面的效能。這篇評論討論了這些技術作為救命工具的潛力，透過數位足跡來識別有風險的個人。此外，它評估了採用這些技術進行自殺防治的實際效能、限制和道德考量，強調負責任的開發和使用的重要性。這項研究旨在透過分析這個領域的近期研究、方法、工具和技術，填補重要的知識差距。它強調了綜合現有文獻對於提供實用工具和自殺防治工作的重要性，引導在早期介入中建立可靠的、符合道德的系統的創新。這項研究綜合評估了技術和心理健康之間的交集，倡導道德且負責任地應用機器學習、深度學習和自然語言處理，以提供全球性的救命潛力，同時解決概括性、偏誤、隱私等挑戰，並需要進一步研究以確保這些技術不會加劇現有的不平等和傷害。

##### **Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics**
2501.09218v1 by Yuanyuan Wei, Yucheng Wu, Fuyang Qu, Yao Mu, Yi-Ping Ho, Ho-Pui Ho, Wu Yuan, Mingkun Xu

Accurate molecular quantification is essential for advancing research and
diagnostics in fields such as infectious diseases, cancer biology, and genetic
disorders. Droplet digital PCR (ddPCR) has emerged as a gold standard for
achieving absolute quantification. While computational ddPCR technologies have
advanced significantly, achieving automatic interpretation and consistent
adaptability across diverse operational environments remains a challenge. To
address these limitations, we introduce the intelligent interpretable droplet
digital PCR (I2ddPCR) assay, a comprehensive framework integrating front-end
predictive models (for droplet segmentation and classification) with GPT-4o
multimodal large language model (MLLM, for context-aware explanations and
recommendations) to automate and enhance ddPCR image analysis. This approach
surpasses the state-of-the-art models, affording 99.05% accuracy in processing
complex ddPCR images containing over 300 droplets per image with varying
signal-to-noise ratios (SNRs). By combining specialized neural networks and
large language models, the I2ddPCR assay offers a robust and adaptable solution
for absolute molecular quantification, achieving a sensitivity capable of
detecting low-abundance targets as low as 90.32 copies/{\mu}L. Furthermore, it
improves model's transparency through detailed explanation and troubleshooting
guidance, empowering users to make informed decisions. This innovative
framework has the potential to benefit molecular diagnostics, disease research,
and clinical applications, especially in resource-constrained settings.

摘要：準確的分子量化對於推進傳染病、癌症生物學和遺傳疾病等領域的研究和診斷至關重要。飛沫數位 PCR (ddPCR) 已成為實現絕對量化的黃金標準。儘管運算式 ddPCR 技術已大幅進步，但在不同操作環境中實現自動化解讀和一致的適應性仍然是一項挑戰。為了解決這些限制，我們引入了智慧可解讀飛沫數位 PCR (I2ddPCR) 分析，一個整合前瞻性預測模型（用於飛沫分割和分類）與 GPT-4o 多模態大型語言模型（MLLM，用於情境感知解釋和建議）的綜合架構，以自動化並增強 ddPCR 影像分析。此方法超越了最先進的模型，在處理每張影像含有超過 300 個飛沫且信噪比 (SNR) 不同的複雜 ddPCR 影像時，準確度高達 99.05%。透過結合專門的神經網路和大型語言模型，I2ddPCR 分析提供了一個強健且適應性高的絕對分子量化解決方案，靈敏度高，能偵測低至 90.32 個拷貝數/{\mu}L 的低豐度目標。此外，它透過詳細的說明和故障排除指南來提升模型的透明度，使用戶能夠做出明智的決策。這個創新的架構有潛力造福分子診斷、疾病研究和臨床應用，特別是在資源受限的環境中。

##### **AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning**
2501.09160v1 by Assaf Lahiany, Oren Gal

Current visual SLAM systems face significant challenges in balancing
computational efficiency with robust loop closure handling. Traditional
approaches require careful manual tuning and incur substantial computational
overhead, while learning-based methods either lack explicit loop closure
capabilities or implement them through computationally expensive methods. We
present AutoLoop, a novel approach that combines automated curriculum learning
with efficient fine-tuning for visual SLAM systems. Our method employs a DDPG
(Deep Deterministic Policy Gradient) agent to dynamically adjust loop closure
weights during training, eliminating the need for manual hyperparameter search
while significantly reducing the required training steps. The approach
pre-computes potential loop closure pairs offline and leverages them through an
agent-guided curriculum, allowing the model to adapt efficiently to new
scenarios. Experiments conducted on TartanAir for training and validated across
multiple benchmarks including KITTI, EuRoC, ICL-NUIM and TUM RGB-D demonstrate
that AutoLoop achieves comparable or superior performance while reducing
training time by an order of magnitude compared to traditional approaches.
AutoLoop provides a practical solution for rapid adaptation of visual SLAM
systems, automating the weight tuning process that traditionally requires
multiple manual iterations. Our results show that this automated curriculum
strategy not only accelerates training but also maintains or improves the
model's performance across diverse environmental conditions.

摘要：當前的視覺 SLAM 系統在平衡運算效率與穩健的迴路閉合處理上，面臨重大挑戰。傳統方法需要仔細的手動調整，並會產生大量的運算負擔，而基於學習的方法則缺乏明確的迴路閉合功能，或透過運算成本高昂的方法來實作。我們提出 AutoLoop，這是一種新穎的方法，它結合了自動化的課程學習與視覺 SLAM 系統的有效微調。我們的方法採用 DDPG（深度確定性策略梯度）代理，在訓練過程中動態調整迴路閉合權重，消除了人工超參數搜尋的需要，同時大幅減少了所需的訓練步驟。此方法會離線預先計算潛在的迴路閉合對，並透過代理導向的課程來利用它們，讓模型能夠有效地適應新的場景。在 TartanAir 上進行的實驗，用於訓練並驗證跨多個基準，包括 KITTI、EuRoC、ICL-NUIM 和 TUM RGB-D，證明 AutoLoop 達到相當或更佳的效能，同時將訓練時間減少了一個數量級，與傳統方法相比。AutoLoop 提供了一個實用的解決方案，用於快速適應視覺 SLAM 系統，自動化傳統上需要多次人工反覆運算的權重調整過程。我們的結果表明，這種自動化的課程策略不僅加速了訓練，還維持或改善了模型在各種環境條件下的效能。

##### **Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval**
2501.09134v1 by Demetrio Deanda, Yuktha Priya Masupalli, Jeong Yang, Young Lee, Zechun Cao, Gongbo Liang

Medical images and reports offer invaluable insights into patient health. The
heterogeneity and complexity of these data hinder effective analysis. To bridge
this gap, we investigate contrastive learning models for cross-domain
retrieval, which associates medical images with their corresponding clinical
reports. This study benchmarks the robustness of four state-of-the-art
contrastive learning models: CLIP, CXR-RePaiR, MedCLIP, and CXR-CLIP. We
introduce an occlusion retrieval task to evaluate model performance under
varying levels of image corruption. Our findings reveal that all evaluated
models are highly sensitive to out-of-distribution data, as evidenced by the
proportional decrease in performance with increasing occlusion levels. While
MedCLIP exhibits slightly more robustness, its overall performance remains
significantly behind CXR-CLIP and CXR-RePaiR. CLIP, trained on a
general-purpose dataset, struggles with medical image-report retrieval,
highlighting the importance of domain-specific training data. The evaluation of
this work suggests that more effort needs to be spent on improving the
robustness of these models. By addressing these limitations, we can develop
more reliable cross-domain retrieval models for medical applications.

摘要：醫療影像和報告提供寶貴的見解，深入了解患者健康。這些數據的異質性和複雜性阻礙了有效的分析。為了彌補這個差距，我們研究對比學習模型進行跨領域檢索，將醫學影像與其對應的臨床報告聯繫起來。本研究對四種最先進的對比學習模型的健壯性進行了基準測試：CLIP、CXR-RePaiR、MedCLIP 和 CXR-CLIP。我們引入遮擋檢索任務，以評估模型在不同程度的影像損壞下的性能。我們的研究結果表明，所有評估的模型對分佈外數據都高度敏感，這從隨著遮擋程度的增加而導致的性能成比例下降就可以證明。雖然 MedCLIP 表現出稍高的健壯性，但其整體性能仍遠遠落後於 CXR-CLIP 和 CXR-RePaiR。CLIP 在通用數據集上進行訓練，在醫學影像報告檢索中遇到困難，突顯了特定領域訓練數據的重要性。這項工作的評估表明，需要花費更多精力來提高這些模型的健壯性。通過解決這些限制，我們可以為醫療應用開發更可靠的跨領域檢索模型。

##### **Generative Medical Image Anonymization Based on Latent Code Projection and Optimization**
2501.09114v1 by Huiyu Li, Nicholas Ayache, Hervé Delingette

Medical image anonymization aims to protect patient privacy by removing
identifying information, while preserving the data utility to solve downstream
tasks. In this paper, we address the medical image anonymization problem with a
two-stage solution: latent code projection and optimization. In the projection
stage, we design a streamlined encoder to project input images into a latent
space and propose a co-training scheme to enhance the projection process. In
the optimization stage, we refine the latent code using two deep loss functions
designed to address the trade-off between identity protection and data utility
dedicated to medical images. Through a comprehensive set of qualitative and
quantitative experiments, we showcase the effectiveness of our approach on the
MIMIC-CXR chest X-ray dataset by generating anonymized synthetic images that
can serve as training set for detecting lung pathologies. Source codes are
available at https://github.com/Huiyu-Li/GMIA.

摘要：醫學影像匿名化旨在透過移除識別資訊來保護病患隱私，同時保留資料效用以解決下游任務。在本文中，我們透過兩階段解決方案來解決醫學影像匿名化問題：潛在碼投影和最佳化。在投影階段，我們設計一個簡化的編碼器，將輸入影像投影到潛在空間，並提出一個共同訓練架構來提升投影程序。在最佳化階段，我們使用兩個深度損失函數來調整潛在碼，這些函數旨在解決身分保護與專門用於醫學影像的資料效用之間的權衡。透過一組全面的定性和定量實驗，我們展示了我們方法在 MIMIC-CXR 胸部 X 光影像資料集上的有效性，方法是產生可作為訓練集來偵測肺部病理的匿名合成影像。原始碼可於 https://github.com/Huiyu-Li/GMIA 取得。

##### **Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**
2501.08977v2 by Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First, Miranda Schnier, Kyle Burton, Cris G. Ebby, Jillian Gorskic, Matthew Kalscheur, Samy Khalil, Marie Pisani, Tyler Rubeor, Peter Stetson, Frank Liao, Cherodeep Goswami, Brian Patterson, Majid Afshar

As Large Language Models (LLMs) are integrated into electronic health record
(EHR) workflows, validated instruments are essential to evaluate their
performance before implementation. Existing instruments for provider
documentation quality are often unsuitable for the complexities of
LLM-generated text and lack validation on real-world data. The Provider
Documentation Summarization Quality Instrument (PDSQI-9) was developed to
evaluate LLM-generated clinical summaries. Multi-document summaries were
generated from real-world EHR data across multiple specialties using several
LLMs (GPT-4o, Mixtral 8x7b, and Llama 3-8b). Validation included Pearson
correlation for substantive validity, factor analysis and Cronbach's alpha for
structural validity, inter-rater reliability (ICC and Krippendorff's alpha) for
generalizability, a semi-Delphi process for content validity, and comparisons
of high-versus low-quality summaries for discriminant validity. Seven physician
raters evaluated 779 summaries and answered 8,329 questions, achieving over 80%
power for inter-rater reliability. The PDSQI-9 demonstrated strong internal
consistency (Cronbach's alpha = 0.879; 95% CI: 0.867-0.891) and high
inter-rater reliability (ICC = 0.867; 95% CI: 0.867-0.868), supporting
structural validity and generalizability. Factor analysis identified a 4-factor
model explaining 58% of the variance, representing organization, clarity,
accuracy, and utility. Substantive validity was supported by correlations
between note length and scores for Succinct (rho = -0.200, p = 0.029) and
Organized ($\rho = -0.190$, $p = 0.037$). Discriminant validity distinguished
high- from low-quality summaries ($p < 0.001$). The PDSQI-9 demonstrates robust
construct validity, supporting its use in clinical practice to evaluate
LLM-generated summaries and facilitate safer integration of LLMs into
healthcare workflows.

摘要：<paragraph>隨著大型語言模型 (LLM) 整合到電子病歷
(EHR) 工作流程中，在實施之前，經過驗證的儀器對於評估其
效能至關重要。現有的提供者文件品質儀器通常不適合
LLM 生成的文字的複雜性，且缺乏對真實世界資料的驗證。提供者
文件摘要品質儀器 (PDSQI-9) 是為了評估 LLM 生成的臨床摘要而
開發的。使用多個 LLM（GPT-4o、Mixtral 8x7b 和 Llama 3-8b），
從跨多個專科的真實世界 EHR 資料中產生了多文件摘要。驗證包括
皮爾森相關性（實質效度）、因子分析和克朗巴赫 α（結構效度）、
評分者間信度（ICC 和 Krippendorff α）（概化性）、內容效度的半德爾
菲程序，以及比較高品質和低品質摘要（判別效度）。七位醫師
評分者評估了 779 份摘要並回答了 8,329 個問題，評分者間信度達
到了 80% 以上。PDSQI-9 表現出強大的內部一致性（克朗巴赫 α =
0.879；95% CI：0.867-0.891）和高評分者間信度（ICC = 0.867；95%
CI：0.867-0.868），支持結構效度和概化性。因子分析識別出一個
4 因子模型，解釋了 58% 的變異，代表組織、清晰度、準確性和實用
性。實質效度受到備忘錄長度與簡潔（rho = -0.200，p = 0.029）和
條理（$\rho = -0.190$，$p = 0.037$）的分數之間相關性的支持。判別
效度區分了高品質和低品質摘要（$p < 0.001$）。PDSQI-9 展示了強健
的建構效度，支持在臨床實務中使用它來評估 LLM 生成的摘要，並
促進 LLM 更安全的整合到醫療保健工作流程中。</paragraph>

##### **An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**
2501.08962v1 by Francisco Mauro, Emanoel Thyago, Othon Vinicius, Rodrigo Abreu, Kelvin Cunha, José Gabriel, Rafael Barros, Thales Bezerra, Manoel Henriques, Natalia Lopes, Érico Moutinho, Jéssica Guido, Tsang Ing Ren, Paulo Borba

AI algorithms have become valuable in aiding professionals in healthcare. The
increasing confidence obtained by these models is helpful in critical decision
demands. In clinical dermatology, classification models can detect malignant
lesions on patients' skin using only RGB images as input. However, most
learning-based methods employ data acquired from dermoscopic datasets on
training, which are large and validated by a gold standard. Clinical models aim
to deal with classification on users' smartphone cameras that do not contain
the corresponding resolution provided by dermoscopy. Also, clinical
applications bring new challenges. It can contain captures from uncontrolled
environments, skin tone variations, viewpoint changes, noises in data and
labels, and unbalanced classes. A possible alternative would be to use transfer
learning to deal with the clinical images. However, as the number of samples is
low, it can cause degradations on the model's performance; the source
distribution used in training differs from the test set. This work aims to
evaluate the gap between dermoscopic and clinical samples and understand how
the dataset variations impact training. It assesses the main differences
between distributions that disturb the model's prediction. Finally, from
experiments on different architectures, we argue how to combine the data from
divergent distributions, decreasing the impact on the model's final accuracy.

摘要：AI 演算法已成為協助醫療保健專業人員的寶貴工具。這些模型獲得的信心日益提升，有助於關鍵決策需求。在臨床皮膚科，分類模型僅使用 RGB 影像作為輸入，即可偵測患者皮膚上的惡性病灶。然而，大多數基於學習的方法採用從皮膚鏡資料集取得的資料進行訓練，這些資料集龐大且已通過金標準驗證。臨床模型旨在處理使用者智慧型手機相機上的分類，這些相機不包含皮膚鏡提供的對應解析度。此外，臨床應用程式帶來新的挑戰。它可能包含來自不受控環境的擷取、膚色變化、視點變更、資料和標籤中的雜訊，以及不平衡的類別。一種可能的替代方案是使用遷移學習來處理臨床影像。然而，由於樣本數量少，可能會導致模型效能下降；訓練中使用的來源分佈與測試集不同。這項工作旨在評估皮膚鏡和臨床樣本之間的差距，並了解資料集變化如何影響訓練。它評估會干擾模型預測的主要分佈差異。最後，從不同架構的實驗中，我們論證如何結合來自不同分佈的資料，降低對模型最終準確度的影響。

##### **Improving the Efficiency of Self-Supervised Adversarial Training through Latent Clustering-Based Selection**
2501.10466v1 by Somrita Ghosh, Yuelin Xu, Xiao Zhang

Compared with standard learning, adversarially robust learning is widely
recognized to demand significantly more training examples. Recent works propose
the use of self-supervised adversarial training (SSAT) with external or
synthetically generated unlabeled data to enhance model robustness. However,
SSAT requires a substantial amount of extra unlabeled data, significantly
increasing memory usage and model training times. To address these challenges,
we propose novel methods to strategically select a small subset of unlabeled
data essential for SSAT and robustness improvement. Our selection prioritizes
data points near the model's decision boundary based on latent clustering-based
techniques, efficiently identifying a critical subset of unlabeled data with a
higher concentration of boundary-adjacent points. While focusing on
near-boundary data, our methods are designed to maintain a balanced ratio
between boundary and non-boundary data points to avoid overfitting. Our
experiments on image benchmarks show that integrating our selection strategies
into self-supervised adversarial training can largely reduce memory and
computational requirements while achieving high model robustness. In
particular, our latent clustering-based selection method with k-means is the
most effective, achieving nearly identical test-time robust accuracies with 5
to 10 times less external or generated unlabeled data when applied to image
benchmarks. Additionally, we validate the generalizability of our approach
across various application scenarios, including a real-world medical dataset
for COVID-19 chest X-ray classification.

摘要：與標準學習相比，對抗性穩健學習廣泛被認為需要更多訓練範例。近期研究提出使用具有外部或合成產生標籤資料的自監督對抗訓練 (SSAT) 來增強模型穩健性。然而，SSAT 需要大量的額外未標籤資料，顯著增加記憶體使用量和模型訓練時間。為了應對這些挑戰，我們提出新穎的方法來策略性地選擇一小部分未標籤資料，這對 SSAT 和穩健性改進至關重要。我們的選擇基於潛在群集技術，優先考慮模型決策邊界附近的資料點，有效地識別出一組關鍵的未標籤資料子集，其中包含較高濃度的邊界相鄰點。雖然專注於近邊界資料，但我們的模型旨在保持邊界和非邊界資料點之間的平衡比率，以避免過度擬合。我們在影像基準上的實驗表明，將我們的選擇策略整合到自監督對抗訓練中，可以在實現高模型穩健性的同時，大幅減少記憶體和計算需求。特別是，我們基於 k 平均值的潛在群集選擇方法最有效，在應用於影像基準時，以少 5 到 10 倍的外部或生成未標籤資料，達到幾乎相同的測試時間穩健準確度。此外，我們驗證了我們的方法在各種應用場景中的通用性，包括用於 COVID-19 胸部 X 光分類的真實世界醫療資料集。

##### **Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**
2501.08851v1 by Balasundaram Kadirvelu, Teresa Bellido Bel, Aglaia Freccero, Martina Di Simplicio, Dasha Nicholls, A Aldo Faisal

Background: Adolescents are particularly vulnerable to mental disorders, with
over 75% of cases manifesting before the age of 25. Research indicates that
only 18 to 34% of young people experiencing high levels of depression or
anxiety symptoms seek support. Digital tools leveraging smartphones offer
scalable and early intervention opportunities. Objective: Using a novel machine
learning framework, this study evaluated the feasibility of integrating active
and passive smartphone data to predict mental disorders in non-clinical
adolescents. Specifically, we investigated the utility of the Mindcraft app in
predicting risks for internalising and externalising disorders, eating
disorders, insomnia and suicidal ideation. Methods: Participants (N=103; mean
age 16.1 years) were recruited from three London schools. Participants
completed the Strengths and Difficulties Questionnaire, the Eating Disorders-15
Questionnaire, Sleep Condition Indicator Questionnaire and indicated the
presence/absence of suicidal ideation. They used the Mindcraft app for 14 days,
contributing active data via self-reports and passive data from smartphone
sensors. A contrastive pretraining phase was applied to enhance user-specific
feature stability, followed by supervised fine-tuning. The model evaluation
employed leave-one-subject-out cross-validation using balanced accuracy as the
primary metric. Results: The integration of active and passive data achieved
superior performance compared to individual data sources, with mean balanced
accuracies of 0.71 for SDQ-High risk, 0.67 for insomnia, 0.77 for suicidal
ideation and 0.70 for eating disorders. The contrastive learning framework
stabilised daily behavioural representations, enhancing predictive robustness.
This study demonstrates the potential of integrating active and passive
smartphone data with advanced machine-learning techniques for predicting mental
health risks.

摘要：<paragraph>背景：青少年特别容易罹患精神疾病，75% 以上的病例在 25 岁之前显现。研究表明，只有 18% 到 34% 经历高度抑郁或焦虑症状的年轻人寻求支持。利用智能手机的数位工具提供可扩展的早期介入机会。目标：本研究使用新颖的机器学习框架，评估将主动和被动智能手机数据整合来预测非临床青少年精神疾病的可行性。具体来说，我们调查了 Mindcraft 应用程序在预测内化和外化障碍、饮食失调、失眠和自杀意念方面的效用。方法：参与者（N=103；平均年龄 16.1 岁）来自伦敦的三所学校。参与者完成了优势和困难问卷、进食障碍-15 问卷、睡眠状况指标问卷，并指出了是否存在自杀意念。他们使用 Mindcraft 应用程序 14 天，通过自我报告提供主动数据，并从智能手机传感器提供被动数据。应用对比预训练阶段来增强特定用户的特征稳定性，然后进行监督微调。模型评估采用留一法交叉验证，使用平衡准确度作为主要指标。结果：与个别数据源相比，主动和被动数据的整合实现了更好的性能，SDQ 高风险的平均平衡准确度为 0.71，失眠为 0.67，自杀意念为 0.77，饮食失调为 0.70。对比学习框架稳定了每日行为表征，增强了预测鲁棒性。本研究展示了将主动和被动智能手机数据与先进机器学习技术相结合以预测心理健康风险的潜力。</paragraph>

##### **Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities**
2501.09045v1 by Adam Goodge, Wee Siong Ng, Bryan Hooi, See Kiong Ng

Foundation models have revolutionized artificial intelligence, setting new
benchmarks in performance and enabling transformative capabilities across a
wide range of vision and language tasks. However, despite the prevalence of
spatio-temporal data in critical domains such as transportation, public health,
and environmental monitoring, spatio-temporal foundation models (STFMs) have
not yet achieved comparable success. In this paper, we articulate a vision for
the future of STFMs, outlining their essential characteristics and the
generalization capabilities necessary for broad applicability. We critically
assess the current state of research, identifying gaps relative to these ideal
traits, and highlight key challenges that impede their progress. Finally, we
explore potential opportunities and directions to advance research towards the
aim of effective and broadly applicable STFMs.

摘要：基礎模型徹底改變了人工智慧，在效能上樹立新的基準，並在廣泛的視覺和語言任務中實現轉型能力。然而，儘管時空資料普遍存在於運輸、公共衛生和環境監控等關鍵領域，但時空基礎模型 (STFM) 尚未取得同等成就。在本文中，我們闡述了對 STFM 未來的願景，概述了其基本特徵和廣泛適用的必要概括能力。我們批判性地評估了當前研究的狀態，找出相對於這些理想特質的差距，並強調阻礙其進展的關鍵挑戰。最後，我們探討了推進研究的潛在機會和方向，以實現有效且廣泛適用的 STFM。

##### **ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**
2501.08324v1 by Ziyuan Huang, Vishaldeep Kaur Sekhon, Ouyang Guo, Mark Newman, Roozbeh Sadeghian, Maria L. Vaida, Cynthia Jo, Doyle Ward, Vanni Bucci, John P. Haran

The Alzheimer's Disease Analysis Model Generation 1 (ADAM) is a multi-agent
large language model (LLM) framework designed to integrate and analyze
multi-modal data, including microbiome profiles, clinical datasets, and
external knowledge bases, to enhance the understanding and detection of
Alzheimer's disease (AD). By leveraging retrieval-augmented generation (RAG)
techniques along with its multi-agent architecture, ADAM-1 synthesizes insights
from diverse data sources and contextualizes findings using literature-driven
evidence. Comparative evaluation against XGBoost revealed similar mean F1
scores but significantly reduced variance for ADAM-1, highlighting its
robustness and consistency, particularly in small laboratory datasets. While
currently tailored for binary classification tasks, future iterations aim to
incorporate additional data modalities, such as neuroimaging and biomarkers, to
broaden the scalability and applicability for Alzheimer's research and
diagnostics.

摘要：阿茲海默症分析模型生成 1 (ADAM) 是一個多代理大型語言模型 (LLM) 架構，旨在整合和分析多模式數據，包括微生物組特徵、臨床數據集和外部知識庫，以增進對阿茲海默症 (AD) 的理解和偵測。透過利用擷取增強生成 (RAG) 技術以及其多代理架構，ADAM-1 從不同的數據來源中綜合見解，並使用文獻驅動的證據對發現進行情境化。與 XGBoost 的比較評估顯示類似的平均 F1 分數，但 ADAM-1 的變異顯著降低，突顯其穩健性和一致性，特別是在小型實驗室數據集中。雖然目前針對二元分類任務進行調整，但未來的迭代旨在納入其他數據模式，例如神經影像和生物標記，以擴大阿茲海默症研究和診斷的可擴充性和適用性。

##### **A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**
2501.08241v1 by Amir Reza Takhsha, Maryam Rastgarpour, Mozhgan Naderi

The COVID-19 pandemic has profoundly impacted billions globally. It
challenges public health and healthcare systems due to its rapid spread and
severe respiratory effects. An effective strategy to mitigate the COVID-19
pandemic involves integrating testing to identify infected individuals. While
RT-PCR is considered the gold standard for diagnosing COVID-19, it has some
limitations such as the risk of false negatives. To address this problem, this
paper introduces a novel Deep Learning Diagnosis System that integrates
pre-trained Deep Convolutional Neural Networks (DCNNs) within an ensemble
learning framework to achieve precise identification of COVID-19 cases from
Chest X-ray (CXR) images. We combine feature vectors from the final hidden
layers of pre-trained DCNNs using the Choquet integral to capture interactions
between different DCNNs that a linear approach cannot. We employed
Sugeno-$\lambda$ measure theory to derive fuzzy measures for subsets of
networks to enable aggregation. We utilized Differential Evolution to estimate
fuzzy densities. We developed a TensorFlow-based layer for Choquet operation to
facilitate efficient aggregation, due to the intricacies involved in
aggregating feature vectors. Experimental results on the COVIDx dataset show
that our ensemble model achieved 98\% accuracy in three-class classification
and 99.50\% in binary classification, outperforming its components-DenseNet-201
(97\% for three-class, 98.75\% for binary), Inception-v3 (96.25\% for
three-class, 98.50\% for binary), and Xception (94.50\% for three-class, 98\%
for binary)-and surpassing many previous methods.

摘要：新冠肺炎疫情已对全球数十亿人产生深远影响。由于其传播迅速且呼吸道症状严重，它对公共卫生和医疗保健系统构成挑战。减轻新冠肺炎疫情的有效策略包括整合检测以识别受感染者。虽然 RT-PCR 被认为是诊断新冠肺炎的黄金标准，但它也有一些限制，例如假阴性的风险。为了解决这个问题，本文介绍了一种新颖的深度学习诊断系统，该系统将预训练的深度卷积神经网络 (DCNN) 集成到集成学习框架中，以从胸部 X 射线 (CXR) 图像中精确识别新冠肺炎病例。我们使用 Choquet 积分结合来自预训练 DCNN 的最后一个隐藏层的特征向量，以捕获线性方法无法实现的不同 DCNN 之间的交互。我们采用 Sugeno-$\lambda$ 测度理论来导出网络子集的模糊测度以实现聚合。我们利用差分进化来估计模糊密度。由于聚合特征向量的复杂性，我们开发了一个基于 TensorFlow 的 Choquet 操作层以促进高效聚合。COVIDx 数据集上的实验结果表明，我们的集成模型在三类分类中达到 98% 的准确率，在二元分类中达到 99.50%，优于其组件 DenseNet-201（三类为 97%，二元为 98.75%）、Inception-v3（三类为 96.25%，二元为 98.50%）和 Xception（三类为 94.50%，二元为 98%），并超越了许多以前的方法。

##### **ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**
2501.08208v1 by Mohita Chowdhury, Yajie Vera He, Aisling Higham, Ernest Lim

Large Language Models (LLMs) have shown impressive potential in clinical
question answering (QA), with Retrieval Augmented Generation (RAG) emerging as
a leading approach for ensuring the factual accuracy of model responses.
However, current automated RAG metrics perform poorly in clinical and
conversational use cases. Using clinical human evaluations of responses is
expensive, unscalable, and not conducive to the continuous iterative
development of RAG systems. To address these challenges, we introduce ASTRID -
an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging
RAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy
(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is
designed to better capture the faithfulness of a model's response to the
knowledge base without penalising conversational elements. To validate our
triad, we curate a dataset of over 200 real-world patient questions posed to an
LLM-based QA agent during surgical follow-up for cataract surgery - the highest
volume operation in the world - augmented with clinician-selected questions for
emergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate
that CF can predict human ratings of faithfulness better than existing
definitions for conversational use cases. Furthermore, we show that evaluation
using our triad consisting of CF, RA, and CR exhibits alignment with clinician
assessment for inappropriate, harmful, or unhelpful responses. Finally, using
nine different LLMs, we demonstrate that the three metrics can closely agree
with human evaluations, highlighting the potential of these metrics for use in
LLM-driven automated evaluation pipelines. We also publish the prompts and
datasets for these experiments, providing valuable resources for further
research and development.

摘要：大型語言模型 (LLM) 在臨床問答 (QA) 中展現了令人印象深刻的潛力，其中檢索增強生成 (RAG) 成為確保模型回應事實準確性的領先方法。然而，目前的自動化 RAG 指標在臨床和對話式用例中表現不佳。使用臨床人類對回應的評估既昂貴又不具可擴充性，也不利於 RAG 系統的持續迭代開發。為了應對這些挑戰，我們引入了 ASTRID - 一種用於評估利用 RAG 的臨床 QA 系統的自動化且可擴充的 TRIaD - 包含三個指標：脈絡相關性 (CR)、拒絕準確性 (RA) 和對話忠實度 (CF)。我們新穎的評估指標 CF 旨在更好地捕捉模型對知識庫的回應的忠實度，同時不懲罰對話元素。為了驗證我們的三元組，我們策劃了一個數據集，其中包含在白內障手術術後隨訪期間向 LLM 基於 QA 的代理提出的 200 多個真實世界的患者問題 - 世界上手術量最大的手術 - 並增加了臨床醫生選擇的問題，用於緊急、臨床和非臨床領域外情境。我們證明，與對話式用例現有定義相比，CF 可以更好地預測人類對忠實度的評分。此外，我們表明使用由 CF、RA 和 CR 組成的三元組進行評估與臨床醫生對不適當、有害或無益的回應的評估保持一致。最後，使用九種不同的 LLM，我們證明這三個指標可以與人類評估緊密一致，突顯了這些指標在 LLM 驅動的自動化評估管道中使用的潛力。我們還公佈了這些實驗的提示和數據集，為進一步的研究和開發提供了寶貴的資源。

##### **Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**
2501.08167v2 by Rewina Bedemariam, Natalie Perez, Sreyoshi Bhaduri, Satya Kapoor, Alex Gil, Elizabeth Conjar, Ikkei Itoku, David Theil, Aman Chadha, Naumaan Nayyar

Rapid advancements in large language models have unlocked remarkable
capabilities when it comes to processing and summarizing unstructured text
data. This has implications for the analysis of rich, open-ended datasets, such
as survey responses, where LLMs hold the promise of efficiently distilling key
themes and sentiments. However, as organizations increasingly turn to these
powerful AI systems to make sense of textual feedback, a critical question
arises, can we trust LLMs to accurately represent the perspectives contained
within these text based datasets? While LLMs excel at generating human-like
summaries, there is a risk that their outputs may inadvertently diverge from
the true substance of the original responses. Discrepancies between the
LLM-generated outputs and the actual themes present in the data could lead to
flawed decision-making, with far-reaching consequences for organizations. This
research investigates the effectiveness of LLM-as-judge models to evaluate the
thematic alignment of summaries generated by other LLMs. We utilized an
Anthropic Claude model to generate thematic summaries from open-ended survey
responses, with Amazon's Titan Express, Nova Pro, and Meta's Llama serving as
judges. This LLM-as-judge approach was compared to human evaluations using
Cohen's kappa, Spearman's rho, and Krippendorff's alpha, validating a scalable
alternative to traditional human centric evaluation methods. Our findings
reveal that while LLM-as-judge offer a scalable solution comparable to human
raters, humans may still excel at detecting subtle, context-specific nuances.
Our research contributes to the growing body of knowledge on AI assisted text
analysis. Further, we provide recommendations for future research, emphasizing
the need for careful consideration when generalizing LLM-as-judge models across
various contexts and use cases.

摘要：大型語言模型的快速進步，在處理和總結非結構化文字資料方面，解鎖了非凡的能力。這對豐富、開放式資料集的分析有影響，例如調查回應，其中 LLM 承諾有效地提煉出關鍵主題和情緒。然而，隨著組織越來越依賴這些強大的 AI 系統來理解文字回饋，一個關鍵問題出現了，我們能相信 LLM 能準確地代表這些基於文字的資料集所包含的觀點嗎？雖然 LLM 在生成類似人類的摘要方面表現出色，但存在其輸出可能無意間偏離原始回應的真實內容的風險。LLM 生成的輸出與資料中存在的實際主題之間的差異可能導致有缺陷的決策制定，對組織產生深遠影響。本研究調查了 LLM 作為評審模型評估其他 LLM 生成的摘要的主題對齊性的有效性。我們利用 Anthropic Claude 模型從開放式調查回應中生成主題摘要，而 Amazon 的 Titan Express、Nova Pro 和 Meta 的 Llama 則作為評審。這種 LLM 作為評審的方法使用 Cohen's kappa、Spearman's rho 和 Krippendorff's alpha 與人類評估進行比較，驗證了傳統以人類為中心的評估方法的可擴充替代方案。我們的研究結果表明，雖然 LLM 作為評審提供了與人類評分者相當的可擴充解決方案，但人類在檢測微妙的、特定於上下文的細微差別方面仍然可能表現出色。我們的研究有助於擴充關於 AI 輔助文字分析的知識體系。此外，我們提供了對未來研究的建議，強調在各種背景和使用案例中概括 LLM 作為評審模型時需要仔細考量。

##### **FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**
2501.08155v1 by Nurit Cohen-Inger, Lior Rokach, Bracha Shapira, Seffi Cohen

Algorithmic decision-making has become deeply ingrained in many domains, yet
biases in machine learning models can still produce discriminatory outcomes,
often harming unprivileged groups. Achieving fair classification is inherently
challenging, requiring a careful balance between predictive performance and
ethical considerations. We present FairTTTS, a novel post-processing bias
mitigation method inspired by the Tree Test Time Simulation (TTTS) method.
Originally developed to enhance accuracy and robustness against adversarial
inputs through probabilistic decision-path adjustments, TTTS serves as the
foundation for FairTTTS. By building on this accuracy-enhancing technique,
FairTTTS mitigates bias and improves predictive performance. FairTTTS uses a
distance-based heuristic to adjust decisions at protected attribute nodes,
ensuring fairness for unprivileged samples. This fairness-oriented adjustment
occurs as a post-processing step, allowing FairTTTS to be applied to
pre-trained models, diverse datasets, and various fairness metrics without
retraining. Extensive evaluation on seven benchmark datasets shows that
FairTTTS outperforms traditional methods in fairness improvement, achieving a
20.96% average increase over the baseline compared to 18.78% for related work,
and further enhances accuracy by 0.55%. In contrast, competing methods
typically reduce accuracy by 0.42%. These results confirm that FairTTTS
effectively promotes more equitable decision-making while simultaneously
improving predictive performance.

摘要：演算法決策制定已深植於許多領域中，然而機器學習模型中的偏見仍可能產生歧視性的結果，通常會傷害未受保障的群體。達成公平分類本質上具有挑戰性，需要在預測效能與道德考量之間取得仔細的平衡。我們提出 FairTTTS，這是一種新穎的後處理偏誤緩解方法，其靈感來自樹測試時間模擬 (TTTS) 方法。TTTS 最初是為了透過機率決策路徑調整來增強針對對抗輸入的準確度和穩健性而開發，並作為 FairTTTS 的基礎。透過建立在這種增強準確度的技術之上，FairTTTS 可以減輕偏誤並改善預測效能。FairTTTS 使用基於距離的啟發法來調整受保護屬性節點的決策，確保未受保障樣本的公平性。這種以公平性為導向的調整會在後處理步驟中發生，允許 FairTTTS 套用至預先訓練的模型、多樣化的資料集和各種公平性指標，而無需重新訓練。在七個基準資料集上的廣泛評估顯示，FairTTTS 在公平性改善方面優於傳統方法，與相關工作的 18.78% 相比，平均提升了 20.96%，並進一步將準確度提升了 0.55%。相反地，競爭方法通常會將準確度降低 0.42%。這些結果證實，FairTTTS 有效地促進了更公平的決策制定，同時也改善了預測效能。

##### **Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features**
2501.08097v1 by E. Sarfati, A. Bône, M-M. Rohé, C. Aubé, M. Ronot, P. Gori, I. Bloch

Hepatocellular carcinoma is the most spread primary liver cancer across the
world ($\sim$80\% of the liver tumors). The gold standard for HCC diagnosis is
liver biopsy. However, in the clinical routine, expert radiologists provide a
visual diagnosis by interpreting hepatic CT-scans according to a standardized
protocol, the LI-RADS, which uses five radiological criteria with an associated
decision tree. In this paper, we propose an automatic approach to predict
histology-proven HCC from CT images in order to reduce radiologists'
inter-variability. We first show that standard deep learning methods fail to
accurately predict HCC from CT-scans on a challenging database, and propose a
two-step approach inspired by the LI-RADS system to improve the performance. We
achieve improvements from 6 to 18 points of AUC with respect to deep learning
baselines trained with different architectures. We also provide clinical
validation of our method, achieving results that outperform non-expert
radiologists and are on par with expert ones.

摘要：肝細胞癌是最常見的原發性肝癌，遍布全球（約佔肝臟腫瘤的 80%）。HCC 診斷的黃金標準是肝臟活檢。然而，在臨床常規中，專家放射科醫師會根據標準化協定 LI-RADS 來解讀肝臟電腦斷層掃描，提供視覺診斷，此協定使用五項放射學標準，並附有相關決策樹。在本文中，我們提出了一種自動化方法，用於從電腦斷層影像預測組織病理學證實的 HCC，以減少放射科醫師的變異性。我們首先表明，標準深度學習方法無法準確地從具有挑戰性的資料庫中的電腦斷層掃描預測 HCC，並提出了一個受 LI-RADS 系統啟發的兩步驟方法來改善效能。相較於使用不同架構訓練的深度學習基準，我們在 AUC 中獲得了 6 到 18 個點的進步。我們也提供了我們方法的臨床驗證，所獲得的結果優於非專家放射科醫師，且與專家相當。

##### **Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**
2501.08042v1 by Alvaro Pastor-Naranjo, Pablo Meseguer, Rocío del Amor, Jose Antonio Lopez-Guerrero, Samuel Navarro, Katia Scotlandi, Antonio Llombart-Bosch, Isidro Machado, Valery Naranjo

Ewing's sarcoma (ES), characterized by a high density of small round blue
cells without structural organization, presents a significant health concern,
particularly among adolescents aged 10 to 19. Artificial intelligence-based
systems for automated analysis of histopathological images are promising to
contribute to an accurate diagnosis of ES. In this context, this study explores
the feature extraction ability of different pre-training strategies for
distinguishing ES from other soft tissue or bone sarcomas with similar
morphology in digitized tissue microarrays for the first time, as far as we
know. Vision-language supervision (VLS) is compared to fully-supervised
ImageNet pre-training within a multiple instance learning paradigm. Our
findings indicate a substantial improvement in diagnostic accuracy with the
adaption of VLS using an in-domain dataset. Notably, these models not only
enhance the accuracy of predicted classes but also drastically reduce the
number of trainable parameters and computational costs.

摘要：尤因氏肉瘤 (ES) 的特征是高密度的无结构组织的小圆形蓝色细胞，对健康构成重大威胁，尤其是在 10 至 19 岁的青少年中。基于人工智能的组织病理学图像自动分析系统有望有助于 ES 的准确诊断。在此背景下，本研究首次探讨了不同预训练策略的特征提取能力，以区分 ES 与数字化组织微阵列中形态相似的其他软组织或骨肉瘤，据我们所知。视觉语言监督 (VLS) 与多实例学习范式中的完全监督 ImageNet 预训练进行了比较。我们的研究结果表明，使用域内数据集调整 VLS 可大幅提高诊断准确性。值得注意的是，这些模型不仅提高了预测类别的准确性，还大幅减少了可训练参数和计算成本。

##### **Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**
2501.07970v1 by Wentao Cui, Shoubo Li, Chen Fang, Qingqing Long, Chengrui Wang, Xuezhi Wang, Yuanchun Zhou

Discovering gene-disease associations is crucial for understanding disease
mechanisms, yet identifying these associations remains challenging due to the
time and cost of biological experiments. Computational methods are increasingly
vital for efficient and scalable gene-disease association prediction.
Graph-based learning models, which leverage node features and network
relationships, are commonly employed for biomolecular predictions. However,
existing methods often struggle to effectively integrate node features,
heterogeneous structures, and semantic information. To address these
challenges, we propose COmprehensive MEtapath-based heterogeneous graph
Transformer(COMET) for predicting gene-disease associations. COMET integrates
diverse datasets to construct comprehensive heterogeneous networks,
initializing node features with BioGPT. We define seven Metapaths and utilize a
transformer framework to aggregate Metapath instances, capturing global
contexts and long-distance dependencies. Through intra- and inter-metapath
aggregation using attention mechanisms, COMET fuses latent vectors from
multiple Metapaths to enhance GDA prediction accuracy. Our method demonstrates
superior robustness compared to state-of-the-art approaches. Ablation studies
and visualizations validate COMET's effectiveness, providing valuable insights
for advancing human health research.

摘要：發現基因疾病關聯對於理解疾病機制至關重要，但由於生物實驗的時間和成本，識別這些關聯仍然具有挑戰性。計算方法對於高效且可擴充的基因疾病關聯預測越來越重要。基於圖的學習模型利用節點特徵和網路關係，通常用於生物分子預測。然而，現有方法通常難以有效整合節點特徵、異質結構和語義資訊。為了應對這些挑戰，我們提出了基於綜合元路徑的異質圖轉換器 (COMET)，用於預測基因疾病關聯。COMET 整合了不同的資料集來構建全面的異質網路，使用 BioGPT 初始化節點特徵。我們定義了七個元路徑，並利用轉換器框架來聚合元路徑實例，擷取全局上下文和長距離依賴關係。通過使用注意機制進行元路徑內部和元路徑間聚合，COMET 融合了來自多個元路徑的潛在向量，以增強 GDA 預測準確性。與最先進的方法相比，我們的模型展示了卓越的穩健性。消融研究和視覺化驗證了 COMET 的有效性，為推進人類健康研究提供了有價值的見解。

##### **Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**
2501.07931v1 by Waqar Hussain, John Grundy

Given their ability for advanced reasoning, extensive contextual
understanding, and robust question-answering abilities, large language models
have become prominent in healthcare management research. Despite adeptly
handling a broad spectrum of healthcare inquiries, these models face
significant challenges in delivering accurate and practical advice for chronic
conditions such as diabetes. We evaluate the responses of ChatGPT versions 3.5
and 4 to diabetes patient queries, assessing their depth of medical knowledge
and their capacity to deliver personalized, context-specific advice for
diabetes self-management. Our findings reveal discrepancies in accuracy and
embedded biases, emphasizing the models' limitations in providing tailored
advice unless activated by sophisticated prompting techniques. Additionally, we
observe that both models often provide advice without seeking necessary
clarification, a practice that can result in potentially dangerous advice. This
underscores the limited practical effectiveness of these models without human
oversight in clinical settings. To address these issues, we propose a
commonsense evaluation layer for prompt evaluation and incorporating
disease-specific external memory using an advanced Retrieval Augmented
Generation technique. This approach aims to improve information quality and
reduce misinformation risks, contributing to more reliable AI applications in
healthcare settings. Our findings seek to influence the future direction of AI
in healthcare, enhancing both the scope and quality of its integration.

摘要：由於大型語言模型具有先進推理能力、廣泛的背景理解能力和強大的問題回答能力，因此在醫療保健管理研究中變得突出。儘管這些模型能熟練地處理廣泛的醫療保健查詢，但在提供慢性疾病（例如糖尿病）的準確且實用的建議方面，這些模型面臨著重大的挑戰。我們評估了 ChatGPT 版本 3.5 和 4 對糖尿病患者查詢的回應，評估了他們的醫學知識深度以及提供針對糖尿病自我管理的個性化、特定於背景的建議的能力。我們的研究結果揭示了準確性和內嵌偏差的差異，強調了這些模型在未經複雜提示技術啟用時提供定制建議的局限性。此外，我們觀察到這兩個模型通常在不尋求必要的澄清的情況下提供建議，這種做法可能會導致潛在的危險建議。這凸顯了這些模型在沒有臨床環境中的人工監督的情況下實用有效性有限。為了解決這些問題，我們提出了一個常識評估層，用於提示評估和使用先進的檢索增強生成技術整合特定疾病的外部記憶體。這種方法旨在提高資訊品質並降低錯誤資訊風險，有助於在醫療保健環境中建立更可靠的人工智慧應用程式。我們的研究結果旨在影響人工智慧在醫療保健中的未來方向，同時提升其整合的範圍和品質。

##### **Large Language Models for Interpretable Mental Health Diagnosis**
2501.07653v1 by Brian Hyeongseok Kim, Chao Wang

We propose a clinical decision support system (CDSS) for mental health
diagnosis that combines the strengths of large language models (LLMs) and
constraint logic programming (CLP). Having a CDSS is important because of the
high complexity of diagnostic manuals used by mental health professionals and
the danger of diagnostic errors. Our CDSS is a software tool that uses an LLM
to translate diagnostic manuals to a logic program and solves the program using
an off-the-shelf CLP engine to query a patient's diagnosis based on the encoded
rules and provided data. By giving domain experts the opportunity to inspect
the LLM-generated logic program, and making modifications when needed, our CDSS
ensures that the diagnosis is not only accurate but also interpretable. We
experimentally compare it with two baseline approaches of using LLMs:
diagnosing patients using the LLM-only approach, and using the LLM-generated
logic program but without expert inspection. The results show that, while LLMs
are extremely useful in generating candidate logic programs, these programs
still require expert inspection and modification to guarantee faithfulness to
the official diagnostic manuals. Additionally, ethical concerns arise from the
direct use of patient data in LLMs, underscoring the need for a safer hybrid
approach like our proposed method.

摘要：<paragraph>我們提出一個用於心理健康診斷的臨床決策支援系統 (CDSS)，它結合了大型語言模型 (LLM) 和約束邏輯程式設計 (CLP) 的優點。擁有 CDSS 很重要，因為心理健康專業人士使用的診斷手冊非常複雜，而且診斷錯誤很危險。我們的 CDSS 是一個軟體工具，它使用 LLM 將診斷手冊轉換成邏輯程式，並使用現成的 CLP 引擎解決程式，以根據編碼規則和提供的資料查詢病人的診斷。透過讓領域專家有機會檢查 LLM 生成的邏輯程式，並在需要時進行修改，我們的 CDSS 可確保診斷不僅準確，而且可解讀。我們以實驗的方式將其與兩種使用 LLM 的基線方法進行比較：僅使用 LLM 方法診斷病人，以及使用 LLM 生成的邏輯程式，但沒有專家檢查。結果顯示，雖然 LLM 在產生候選邏輯程式方面非常有用，但這些程式仍然需要專家檢查和修改，以確保對官方診斷手冊的忠實度。此外，直接在 LLM 中使用病人資料會引發倫理問題，這強調了需要一種更安全的混合方法，例如我們提出的方法。</paragraph>

##### **RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**
2501.07525v1 by Difei Gu, Yunhe Gao, Yang Zhou, Mu Zhou, Dimitris Metaxas

Automated chest radiographs interpretation requires both accurate disease
classification and detailed radiology report generation, presenting a
significant challenge in the clinical workflow. Current approaches either focus
on classification accuracy at the expense of interpretability or generate
detailed but potentially unreliable reports through image captioning
techniques. In this study, we present RadAlign, a novel framework that combines
the predictive accuracy of vision-language models (VLMs) with the reasoning
capabilities of large language models (LLMs). Inspired by the radiologist's
workflow, RadAlign first employs a specialized VLM to align visual features
with key medical concepts, achieving superior disease classification with an
average AUC of 0.885 across multiple diseases. These recognized medical
conditions, represented as text-based concepts in the aligned visual-language
space, are then used to prompt LLM-based report generation. Enhanced by a
retrieval-augmented generation mechanism that grounds outputs in similar
historical cases, RadAlign delivers superior report quality with a GREEN score
of 0.678, outperforming state-of-the-art methods' 0.634. Our framework
maintains strong clinical interpretability while reducing hallucinations,
advancing automated medical imaging and report analysis through integrated
predictive and generative AI. Code is available at
https://github.com/difeigu/RadAlign.

摘要：自動化胸部 X 光片解讀需要精準的疾病分類和詳細的放射科報告生成，這對臨床工作流程構成重大挑戰。目前的做法要不就是以犧牲可解讀性為代價專注於分類準確性，要不就是透過影像標題技術產生詳細但可能不可靠的報告。在這項研究中，我們提出 RadAlign，一個結合了視覺語言模型 (VLM) 的預測準確性和大型語言模型 (LLM) 的推理能力的新穎架構。受到放射科醫師工作流程的啟發，RadAlign 首先採用專門的 VLM 將視覺特徵與關鍵醫療概念對齊，在多種疾病中達成優異的疾病分類，平均 AUC 為 0.885。這些識別出的醫療狀況會在對齊的視覺語言空間中表示為基於文字的概念，然後用來提示基於 LLM 的報告生成。透過一種將輸出結果建立在類似過往案例中的檢索增強生成機制，RadAlign 提供優異的報告品質，GREEN 分數為 0.678，優於最先進方法的 0.634。我們的架構維持強大的臨床可解讀性，同時減少幻覺，透過整合預測和生成式 AI，推進自動化醫學影像和報告分析。程式碼可於 https://github.com/difeigu/RadAlign 取得。

##### **A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**
2501.07468v1 by Yihao Liu, Xu Cao, Tingting Chen, Yankai Jiang, Junjie You, Minghua Wu, Xiaosong Wang, Mengling Feng, Yaochu Jin, Jintai Chen

Healthcare systems worldwide face persistent challenges in efficiency,
accessibility, and personalization. Powered by modern AI technologies such as
multimodal large language models and world models, Embodied AI (EmAI)
represents a transformative frontier, offering enhanced autonomy and the
ability to interact with the physical world to address these challenges. As an
interdisciplinary and rapidly evolving research domain, "EmAI in healthcare"
spans diverse fields such as algorithms, robotics, and biomedicine. This
complexity underscores the importance of timely reviews and analyses to track
advancements, address challenges, and foster cross-disciplinary collaboration.
In this paper, we provide a comprehensive overview of the "brain" of EmAI for
healthcare, wherein we introduce foundational AI algorithms for perception,
actuation, planning, and memory, and focus on presenting the healthcare
applications spanning clinical interventions, daily care & companionship,
infrastructure support, and biomedical research. Despite its promise, the
development of EmAI for healthcare is hindered by critical challenges such as
safety concerns, gaps between simulation platforms and real-world applications,
the absence of standardized benchmarks, and uneven progress across
interdisciplinary domains. We discuss the technical barriers and explore
ethical considerations, offering a forward-looking perspective on the future of
EmAI in healthcare. A hierarchical framework of intelligent levels for EmAI
systems is also introduced to guide further development. By providing
systematic insights, this work aims to inspire innovation and practical
applications, paving the way for a new era of intelligent, patient-centered
healthcare.

摘要：<paragraph>全球醫療保健系統在效率、可及性和個人化方面持續面臨挑戰。體現式 AI (EmAI) 由多模態大型語言模型和世界模型等現代 AI 技術提供支持，代表了一個轉型前沿，提供增強的自主性，以及與物理世界互動以應對這些挑戰的能力。作為一個跨學科且快速發展的研究領域，「醫療保健中的 EmAI」涵蓋了演算法、機器人和生物醫學等多元領域。這種複雜性突顯了及時審查和分析的重要性，以追蹤進展、應對挑戰並促進跨學科合作。在本文中，我們提供了 EmAI 在醫療保健中的「大腦」的全面概述，我們在其中介紹了感知、執行、規劃和記憶的基本 AI 演算法，並專注於呈現涵蓋臨床干預、日常照護和陪伴、基礎設施支援和生物醫學研究的醫療保健應用。儘管前景看好，但 EmAI 在醫療保健中的發展受到關鍵挑戰的阻礙，例如安全問題、模擬平台和實際應用之間的差距、缺乏標準化基準，以及跨學科領域進展不均。我們討論了技術障礙並探討了道德考量，對 EmAI 在醫療保健中的未來提供了前瞻性的觀點。還引入了 EmAI 系統的智慧層級架構，以指導進一步的發展。透過提供系統性的見解，這項工作旨在激發創新和實用應用，為智慧且以患者為中心的醫療保健新時代鋪路。</paragraph>

##### **Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**
2501.07430v1 by Xiyue Zhu, Dou Hoon Kwark, Ruike Zhu, Kaiwen Hong, Yiqi Tao, Shirui Luo, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko

Despite success in volume-to-volume translations in medical images, most
existing models struggle to effectively capture the inherent volumetric
distribution using 3D representations. The current state-of-the-art approach
combines multiple 2D-based networks through weighted averaging, thereby
neglecting the 3D spatial structures. Directly training 3D models in medical
imaging presents significant challenges due to high computational demands and
the need for large-scale datasets. To address these challenges, we introduce
Diff-Ensembler, a novel hybrid 2D-3D model for efficient and effective
volumetric translations by ensembling perpendicularly trained 2D diffusion
models with a 3D network in each diffusion step. Moreover, our model can
naturally be used to ensemble diffusion models conditioned on different
modalities, allowing flexible and accurate fusion of input conditions.
Extensive experiments demonstrate that Diff-Ensembler attains superior accuracy
and volumetric realism in 3D medical image super-resolution and modality
translation. We further demonstrate the strength of our model's volumetric
realism using tumor segmentation as a downstream task.

摘要：儘管在醫學影像中體積到體積的翻譯取得成功，但現有的模型大多難以有效地使用 3D 呈現來擷取固有的體積分佈。目前最先進的方法是透過加權平均來結合多個基於 2D 的網路，因此忽略了 3D 空間結構。在醫學影像中直接訓練 3D 模型會產生顯著的挑戰，原因在於高運算需求和大規模資料集的需求。為了應對這些挑戰，我們引入了 Diff-Ensembler，這是一個新穎的混合 2D-3D 模型，可透過在每個擴散步驟中將垂直訓練的 2D 擴散模型與 3D 網路結合，來有效率且有效地進行體積轉換。此外，我們的模型可以自然地用於結合基於不同形式的擴散模型，從而靈活且準確地融合輸入條件。廣泛的實驗證明，Diff-Ensembler 在 3D 醫學影像超解析度和形式轉換中達到了更高的準確度和體積真實感。我們進一步使用腫瘤分割作為下游任務，來證明我們模型的體積真實感。

##### **Synthetic Data and Health Privacy**
2501.09031v1 by Gwénolé Abgrall, Xavier Monnet, Anmol Arora

This Viewpoint discusses generative artificial intelligence and safeguarding
privacy by using synthetic data as a substitute for private health data.

摘要：此觀點探討生成式人工智慧以及使用合成資料取代私人健康資料以保護隱私。

##### **Natural Language-Assisted Multi-modal Medication Recommendation**
2501.07166v1 by Jie Tan, Yu Rong, Kangfei Zhao, Tian Bian, Tingyang Xu, Junzhou Huang, Hong Cheng, Helen Meng

Combinatorial medication recommendation(CMR) is a fundamental task of
healthcare, which offers opportunities for clinical physicians to provide more
precise prescriptions for patients with intricate health conditions,
particularly in the scenarios of long-term medical care. Previous research
efforts have sought to extract meaningful information from electronic health
records (EHRs) to facilitate combinatorial medication recommendations. Existing
learning-based approaches further consider the chemical structures of
medications, but ignore the textual medication descriptions in which the
functionalities are clearly described. Furthermore, the textual knowledge
derived from the EHRs of patients remains largely underutilized. To address
these issues, we introduce the Natural Language-Assisted Multi-modal Medication
Recommendation(NLA-MMR), a multi-modal alignment framework designed to learn
knowledge from the patient view and medication view jointly. Specifically,
NLA-MMR formulates CMR as an alignment problem from patient and medication
modalities. In this vein, we employ pretrained language models(PLMs) to extract
in-domain knowledge regarding patients and medications, serving as the
foundational representation for both modalities. In the medication modality, we
exploit both chemical structures and textual descriptions to create medication
representations. In the patient modality, we generate the patient
representations based on textual descriptions of diagnosis, procedure, and
symptom. Extensive experiments conducted on three publicly accessible datasets
demonstrate that NLA-MMR achieves new state-of-the-art performance, with a
notable average improvement of 4.72% in Jaccard score. Our source code is
publicly available on https://github.com/jtan1102/NLA-MMR_CIKM_2024.

摘要：組合式藥物推薦 (CMR) 是醫療保健的一項基本任務，它為臨床醫生提供了針對具有複雜健康狀況的患者提供更精確處方的機會，特別是在長期醫療保健的情況下。先前的研究工作試圖從電子健康記錄 (EHR) 中提取有意義的資訊，以促進組合式藥物推薦。現有的基於學習的方法進一步考慮了藥物的化學結構，但忽略了功能清楚描述於其中的文本藥物說明。此外，從患者的 EHR 中衍生的文本知識在很大程度上仍未得到充分利用。為了解決這些問題，我們引入了自然語言輔助多模式藥物推薦 (NLA-MMR)，這是一個多模式對齊框架，旨在從患者視角和藥物視角共同學習知識。具體來說，NLA-MMR 將 CMR 構建為患者和藥物模式的對齊問題。在此脈絡中，我們採用預訓練語言模型 (PLM) 來提取有關患者和藥物的領域內知識，作為這兩種模式的基本表示。在藥物模式中，我們利用化學結構和文本說明來建立藥物表示。在患者模式中，我們根據診斷、程序和症狀的文字說明來生成患者表示。在三個公開存取的資料集上進行的廣泛實驗表明，NLA-MMR 達到了新的最先進效能，傑卡德指數平均改進了 4.72%。我們的原始碼公開於 https://github.com/jtan1102/NLA-MMR_CIKM_2024。

##### **CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**
2501.07157v1 by Jinlin Li, Xiao Zhou

The early detection and prediction of health status decline among the elderly
at the neighborhood level are of great significance for urban planning and
public health policymaking. While existing studies affirm the connection
between living environments and health outcomes, most rely on single data
modalities or simplistic feature concatenation of multi-modal information,
limiting their ability to comprehensively profile the health-oriented urban
environments. To fill this gap, we propose CureGraph, a contrastive multi-modal
representation learning framework for urban health prediction that employs
graph-based techniques to infer the prevalence of common chronic diseases among
the elderly within the urban living circles of each neighborhood. CureGraph
leverages rich multi-modal information, including photos and textual reviews of
residential areas and their surrounding points of interest, to generate urban
neighborhood embeddings. By integrating pre-trained visual and textual encoders
with graph modeling techniques, CureGraph captures cross-modal spatial
dependencies, offering a comprehensive understanding of urban environments
tailored to elderly health considerations. Extensive experiments on real-world
datasets demonstrate that CureGraph improves the best baseline by $28\%$ on
average in terms of $R^2$ across elderly disease risk prediction tasks.
Moreover, the model enables the identification of stage-wise chronic disease
progression and supports comparative public health analysis across
neighborhoods, offering actionable insights for sustainable urban development
and enhanced quality of life. The code is publicly available at
https://github.com/jinlin2021/CureGraph.

摘要：在鄰里層級早期偵測和預測老年人的健康狀況下降對城市規劃和公共衛生政策制定具有重大意義。儘管現有研究肯定了生活環境與健康結果之間的關聯性，但大多依賴單一資料模式或多模式資訊的簡化特徵串接，限制了他們全面描繪以健康為導向的城市環境的能力。為了填補這個差距，我們提出了 CureGraph，一個用於城市健康預測的對比式多模式表示學習架構，它採用基於圖形技術來推論每個鄰里城市生活圈中老年人常見慢性疾病的流行率。CureGraph 利用豐富的多模式資訊，包括住宅區及其周圍景點的照片和文字評論，來產生城市鄰里嵌入。透過整合預先訓練的視覺和文字編碼器與圖形建模技術，CureGraph 捕捉跨模式空間依賴性，提供對城市環境的全面理解，專門針對老年人的健康考量。在真實世界資料集上的廣泛實驗證明，CureGraph 在老年人疾病風險預測任務中，平均在 R2 方面將最佳基準線提高了 28%。此外，該模型能夠識別階段性的慢性疾病進程，並支援跨鄰里的比較公共衛生分析，為永續的城市發展和提升生活品質提供可行的見解。程式碼已公開於 https://github.com/jinlin2021/CureGraph。

##### **UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**
2501.07017v2 by Xuhui Guo, Tanmoy Dam, Rohan Dhamdhere, Gourav Modanwal, Anant Madabhushi

3D medical image segmentation has progressed considerably due to
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), yet these
methods struggle to balance long-range dependency acquisition with
computational efficiency. To address this challenge, we propose UNETVL (U-Net
Vision-LSTM), a novel architecture that leverages recent advancements in
temporal information processing. UNETVL incorporates Vision-LSTM (ViL) for
improved scalability and memory functions, alongside an efficient Chebyshev
Kolmogorov-Arnold Networks (KAN) to handle complex and long-range dependency
patterns more effectively. We validated our method on the ACDC and AMOS2022
(post challenge Task 2) benchmark datasets, showing a significant improvement
in mean Dice score compared to recent state-of-the-art approaches, especially
over its predecessor, UNETR, with increases of 7.3% on ACDC and 15.6% on AMOS,
respectively. Extensive ablation studies were conducted to demonstrate the
impact of each component in UNETVL, providing a comprehensive understanding of
its architecture. Our code is available at https://github.com/tgrex6/UNETVL,
facilitating further research and applications in this domain.

摘要：3D 醫學影像分割由於卷積神經網路 (CNN) 和視覺Transformer (ViT) 而進步許多，然而這些方法難以平衡長程依賴關係擷取與運算效率。為了應對這個挑戰，我們提出 UNETVL (U-Net 視覺 LSTM)，這是一種新穎的架構，它利用時間資訊處理的最新進展。UNETVL 結合視覺 LSTM (ViL) 以提升可擴充性和記憶功能，並結合高效的切比雪夫 Kolmogorov-Arnold 網路 (KAN) 以更有效率地處理複雜且長程的依賴關係模式。我們在 ACDC 和 AMOS2022（挑戰任務 2 之後）基準資料集驗證了我們的方法，與最近的最新技術方法相比，平均 Dice 分數有顯著提升，特別是與其前身 UNETR 相比，在 ACDC 上提升了 7.3%，在 AMOS 上提升了 15.6%。我們進行了廣泛的消融研究，以展示 UNETVL 中每個元件的影響，提供對其架構的全面理解。我們的程式碼可在 https://github.com/tgrex6/UNETVL 取得，促進進一步的在這方面的研究和應用。

##### **Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**
2501.06980v1 by Karine Karine, Benjamin M. Marlin

Reinforcement learning (RL) is increasingly being used in the healthcare
domain, particularly for the development of personalized health adaptive
interventions. Inspired by the success of Large Language Models (LLMs), we are
interested in using LLMs to update the RL policy in real time, with the goal of
accelerating personalization. We use the text-based user preference to
influence the action selection on the fly, in order to immediately incorporate
the user preference. We use the term "user preference" as a broad term to refer
to a user personal preference, constraint, health status, or a statement
expressing like or dislike, etc. Our novel approach is a hybrid method that
combines the LLM response and the RL action selection to improve the RL policy.
Given an LLM prompt that incorporates the user preference, the LLM acts as a
filter in the typical RL action selection. We investigate different prompting
strategies and action selection strategies. To evaluate our approach, we
implement a simulation environment that generates the text-based user
preferences and models the constraints that impact behavioral dynamics. We show
that our approach is able to take into account the text-based user preferences,
while improving the RL policy, thus improving personalization in adaptive
intervention.

摘要：強化學習（RL）在醫療領域的應用日益廣泛，特別是用於開發個人化健康適應性干預措施。受到大型語言模型（LLM）成功的啟發，我們有興趣使用 LLM 即時更新 RL 政策，目標是加速個人化。我們使用基於文字的使用者偏好來影響行動選擇，以便立即納入使用者偏好。我們使用「使用者偏好」一詞作為廣義詞，用來指使用者的個人偏好、限制、健康狀況或表達好惡的陳述等。我們的新穎方法是一種混合方法，結合了 LLM 回應和 RL 行動選擇以改善 RL 政策。給定包含使用者偏好的 LLM 提示，LLM 在典型的 RL 行動選擇中充當過濾器。我們研究了不同的提示策略和行動選擇策略。為了評估我們的做法，我們實作了一個模擬環境，用於產生基於文字的使用者偏好，並對影響行為動態的限制進行建模。我們展示了我們的做法能夠考量基於文字的使用者偏好，同時改善 RL 政策，從而改善適應性干預中的個人化。

##### **Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**
2501.06964v1 by Xinyao Ma, Rui Zhu, Zihao Wang, Jingwei Xiong, Qingyu Chen, Haixu Tang, L. Jean Camp, Lucila Ohno-Machado

Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing scenarios, particularly in simulating domain-specific experts
using tailored prompts. This ability enables LLMs to adopt the persona of
individuals with specific backgrounds, offering a cost-effective and efficient
alternative to traditional, resource-intensive user studies. By mimicking human
behavior, LLMs can anticipate responses based on concrete demographic or
professional profiles. In this paper, we evaluate the effectiveness of LLMs in
simulating individuals with diverse backgrounds and analyze the consistency of
these simulated behaviors compared to real-world outcomes. In particular, we
explore the potential of LLMs to interpret and respond to discharge summaries
provided to patients leaving the Intensive Care Unit (ICU). We evaluate and
compare with human responses the comprehensibility of discharge summaries among
individuals with varying educational backgrounds, using this analysis to assess
the strengths and limitations of LLM-driven simulations. Notably, when LLMs are
primed with educational background information, they deliver accurate and
actionable medical guidance 88% of the time. However, when other information is
provided, performance significantly drops, falling below random chance levels.
This preliminary study shows the potential benefits and pitfalls of
automatically generating patient-specific health information from diverse
populations. While LLMs show promise in simulating health personas, our results
highlight critical gaps that must be addressed before they can be reliably used
in clinical settings. Our findings suggest that a straightforward
query-response model could outperform a more tailored approach in delivering
health information. This is a crucial first step in understanding how LLMs can
be optimized for personalized health communication while maintaining accuracy.

摘要：大型語言模型（LLM）在角色扮演場景中展現了令人印象深刻的能力，特別是在模擬特定領域的專家時，會使用量身打造的提示。這種能力使 LLM 能夠採用具有特定背景的個人角色，提供一種經濟實惠且有效率的替代方案，用於傳統且資源密集的使用者研究。透過模擬人類行為，LLM 能夠根據具體的人口統計或專業特徵預測反應。在本文中，我們評估了 LLM 在模擬具有不同背景的個人方面的有效性，並分析了這些模擬行為與實際結果相比的一致性。特別是，我們探討了 LLM 解釋和回應提供給離開加護病房 (ICU) 患者的出院摘要的潛力。我們評估並與人類的反應比較了不同教育背景的個人對出院摘要的可理解性，並使用此分析來評估 LLM 驅動模擬的優點和限制。值得注意的是，當 LLM 被植入教育背景資訊時，他們在 88% 的時間內都能提供準確且可行的醫療指導。但是，當提供其他資訊時，效能會顯著下降，低於隨機機會的等級。這項初步研究顯示了自動產生來自不同群體的特定於患者的健康資訊的潛在好處和缺點。儘管 LLM 在模擬健康角色方面顯示出前景，但我們的結果突出了在臨床環境中可靠使用之前必須解決的關鍵差距。我們的研究結果表明，在提供健康資訊方面，一個直接的查詢回應模型可以優於一個更量身打造的方法。這是了解如何針對個人化健康溝通優化 LLM 同時維持準確性的第一步。

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

摘要：随着深度学习模型在医学数据中获得关注，确保透明且值得信赖的决策至关重要。在皮肤癌诊断中，虽然病灶检测和分类的进步提高了准确性，但这些方法的黑盒性质对理解其决策过程构成了挑战，导致医生之间的信任问题。本研究利用在不同皮肤病变数据集上训练的 CLIP（对比语言图像预训练）模型，以捕捉视觉特征和诊断标准术语之间的有意义关系。为了进一步提高透明度，我们提出了一种名为 MedGrad E-CLIP 的方法，该方法通过结合专为皮肤病变等复杂医学影像设计的加权熵机制，建立在基于梯度的 E-CLIP 之上。此方法突出了与特定诊断描述相关联的关键图像区域。开发的集成管道不仅通过匹配相应的描述对皮肤病变进行分类，还添加了一层专门为医学数据开发的基本可解释性。通过直观地解释图像中不同特征与诊断标准的关系，这种方法展示了高级视觉语言模型在医学图像分析中的潜力，最终提高了透明度、稳健性和对人工智能驱动的诊断系统的信任。

##### **A Foundational Generative Model for Breast Ultrasound Image Analysis**
2501.06869v1 by Haojun Yu, Youcheng Li, Nan Zhang, Zihan Niu, Xuantong Gong, Yanwen Luo, Haotian Ye, Siyu He, Quanlin Wu, Wangyan Qin, Mengyuan Zhou, Jie Han, Jia Tao, Ziwei Zhao, Di Dai, Di He, Dong Wang, Binghui Tang, Ling Huo, James Zou, Qingli Zhu, Yong Wang, Liwei Wang

Foundational models have emerged as powerful tools for addressing various
tasks in clinical settings. However, their potential development to breast
ultrasound analysis remains untapped. In this paper, we present BUSGen, the
first foundational generative model specifically designed for breast ultrasound
image analysis. Pretrained on over 3.5 million breast ultrasound images, BUSGen
has acquired extensive knowledge of breast structures, pathological features,
and clinical variations. With few-shot adaptation, BUSGen can generate
repositories of realistic and informative task-specific data, facilitating the
development of models for a wide range of downstream tasks. Extensive
experiments highlight BUSGen's exceptional adaptability, significantly
exceeding real-data-trained foundational models in breast cancer screening,
diagnosis, and prognosis. In breast cancer early diagnosis, our approach
outperformed all board-certified radiologists (n=9), achieving an average
sensitivity improvement of 16.5% (P-value<0.0001). Additionally, we
characterized the scaling effect of using generated data which was as effective
as the collected real-world data for training diagnostic models. Moreover,
extensive experiments demonstrated that our approach improved the
generalization ability of downstream models. Importantly, BUSGen protected
patient privacy by enabling fully de-identified data sharing, making progress
forward in secure medical data utilization. An online demo of BUSGen is
available at https://aibus.bio.

摘要：基礎模型已成為解決臨床環境中各種任務的強大工具。然而，它們在乳房超音波分析的潛在發展仍未開發。在本文中，我們提出 BUSGen，這是第一個專門設計用於乳房超音波影像分析的基礎生成模型。BUSGen 在超過 350 萬張乳房超音波影像上進行預訓練，已獲得乳房結構、病理特徵和臨床變異的廣泛知識。透過少量適應，BUSGen 可以產生逼真且具有資訊性的特定任務資料儲存庫，促進開發廣泛的下游任務模型。廣泛的實驗突顯了 BUSGen 的出色適應性，在乳癌篩檢、診斷和預後方面顯著超越以真實資料訓練的基礎模型。在乳癌早期診斷中，我們的做法優於所有通過認證的放射科醫師 (n=9)，平均敏感度提高了 16.5%（P 值 <0.0001）。此外，我們描述了使用生成資料的規模效應，其與收集的真實世界資料一樣有效，可用於訓練診斷模型。此外，廣泛的實驗證明，我們的做法改善了下游模型的泛化能力。重要的是，BUSGen 保護了患者隱私，因為它能夠完全去識別資料共享，在安全醫療資料利用方面取得進展。BUSGen 的線上示範可在 https://aibus.bio 取得。

##### **A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**
2501.06859v1 by Noureldin Zahran, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda

Mental health disorders pose a growing public health concern in the Arab
world, emphasizing the need for accessible diagnostic and intervention tools.
Large language models (LLMs) offer a promising approach, but their application
in Arabic contexts faces challenges including limited labeled datasets,
linguistic complexity, and translation biases. This study comprehensively
evaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual
ones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA),
investigating the impact of prompt design, language configuration (native
Arabic vs. translated English, and vice versa), and few-shot prompting on
diagnostic performance. We find that prompt engineering significantly
influences LLM scores mainly due to reduced instruction following, with our
structured prompt outperforming a less structured variant on multi-class
datasets, with an average difference of 14.5\%. While language influence on
performance was modest, model selection proved crucial: Phi-3.5 MoE excelled in
balanced accuracy, particularly for binary classification, while Mistral NeMo
showed superior performance in mean absolute error for severity prediction
tasks. Few-shot prompting consistently improved performance, with particularly
substantial gains observed for GPT-4o Mini on multi-class classification,
boosting accuracy by an average factor of 1.58. These findings underscore the
importance of prompt optimization, multilingual analysis, and few-shot learning
for developing culturally sensitive and effective LLM-based mental health tools
for Arabic-speaking populations.

摘要：<paragraph>心理健康障礙在阿拉伯世界中構成日益嚴重的公共衛生問題，強調了對可及的診斷和干預工具的需求。大型語言模型 (LLM) 提供了一種有前途的方法，但它們在阿拉伯語環境中的應用面臨著挑戰，包括標記資料集有限、語言複雜性和翻譯偏差。本研究全面評估了 8 個 LLM，包括一般多語言模型和雙語模型，在不同的心理健康資料集（例如 AraDepSu、Dreaddit、MedMCQA）上，探討提示設計、語言配置（阿拉伯語原文與翻譯後的英語，反之亦然）和少次提示對診斷表現的影響。我們發現提示工程顯著影響 LLM 分數，主要是由於減少了說明遵循，我們的結構化提示在多類資料集上優於結構較不嚴謹的變體，平均差異為 14.5%。雖然語言對表現的影響不大，但模型選擇被證明至關重要：Phi-3.5 MoE 在平衡準確度方面表現出色，特別是在二元分類方面，而 Mistral NeMo 在嚴重性預測任務的平均絕對誤差方面表現出優異的表現。少次提示始終改善表現，特別是在 GPT-4o Mini 上觀察到多類分類的顯著增益，將準確度提高了平均 1.58 倍。這些發現強調了提示最佳化、多語言分析和少次學習對於開發適合文化且有效的基於 LLM 的心理健康工具以服務阿拉伯語人口的重要性。</paragraph>

##### **MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**
2501.06823v1 by Yiqing Zhang, Xiaozhong Liu, Fabricio Murai

Clinical trials are the gold standard for assessing the effectiveness and
safety of drugs for treating diseases. Given the vast design space of drug
molecules, elevated financial cost, and multi-year timeline of these trials,
research on clinical trial outcome prediction has gained immense traction.
Accurate predictions must leverage data of diverse modes such as drug
molecules, target diseases, and eligibility criteria to infer successes and
failures. Previous Deep Learning approaches for this task, such as HINT, often
require wet lab data from synthesized molecules and/or rely on prior knowledge
to encode interactions as part of the model architecture. To address these
limitations, we propose a light-weight attention-based model, MEXA-CTP, to
integrate readily-available multi-modal data and generate effective
representations via specialized modules dubbed "mode experts", while avoiding
human biases in model design. We optimize MEXA-CTP with the Cauchy loss to
capture relevant interactions across modes. Our experiments on the Trial
Outcome Prediction (TOP) benchmark demonstrate that MEXA-CTP improves upon
existing approaches by, respectively, up to 11.3% in F1 score, 12.2% in PR-AUC,
and 2.5% in ROC-AUC, compared to HINT. Ablation studies are provided to
quantify the effectiveness of each component in our proposed method.

摘要：臨床試驗是評估治療疾病的藥物有效性和安全性的黃金標準。鑑於藥物分子的廣泛設計空間、高昂的財務成本和這些試驗多年的時間表，臨床試驗結果預測的研究獲得了巨大的關注。準確的預測必須利用藥物分子、目標疾病和符合資格標準等多種模式的數據來推斷成功和失敗。此任務的先前深度學習方法（例如 HINT）通常需要合成分子的濕實驗室數據和/或依賴於先驗知識將交互編碼為模型架構的一部分。為了解決這些限制，我們提出了一個輕量級的基於注意力的模型 MEXA-CTP，以整合現成的多模式數據並通過稱為「模式專家」的專用模組產生有效的表示，同時避免模型設計中的人為偏差。我們使用柯西損失函數最佳化 MEXA-CTP，以捕捉跨模式相關的交互。我們在試驗結果預測 (TOP) 基準上的實驗表明，與 HINT 相比，MEXA-CTP 分別在 F1 分數上提高了 11.3%、PR-AUC 上提高了 12.2%、ROC-AUC 上提高了 2.5%。提供了消融研究來量化我們提出的方法中每個組件的有效性。

##### **PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation**
2501.06692v1 by Zhonghao Yan, Zijin Yin, Tianyu Lin, Xiangzhu Zeng, Kongming Liang, Zhanyu Ma

The Segment Anything Model (SAM) has demonstrated strong and versatile
segmentation capabilities, along with intuitive prompt-based interactions.
However, customizing SAM for medical image segmentation requires massive
amounts of pixel-level annotations and precise point- or box-based prompt
designs. To address these challenges, we introduce PGP-SAM, a novel
prototype-based few-shot tuning approach that uses limited samples to replace
tedious manual prompts. Our key idea is to leverage inter- and intra-class
prototypes to capture class-specific knowledge and relationships. We propose
two main components: (1) a plug-and-play contextual modulation module that
integrates multi-scale information, and (2) a class-guided cross-attention
mechanism that fuses prototypes and features for automatic prompt generation.
Experiments on a public multi-organ dataset and a private ventricle dataset
demonstrate that PGP-SAM achieves superior mean Dice scores compared with
existing prompt-free SAM variants, while using only 10\% of the 2D slices.

摘要：分段任何模型 (SAM) 已展示出强大且多功能的分段能力，以及直观的基于提示的交互。
然而，针对医学影像分段定制 SAM 需要大量像素级注释和精确的基于点或框的提示设计。为了应对这些挑战，我们引入了 PGP-SAM，一种新颖的基于原型的少量镜头微调方法，它使用有限的样本来替换繁琐的手动提示。我们的关键思想是利用类间和类内原型来捕捉特定于类的知识和关系。我们提出了两个主要组件：(1) 一个即插即用的上下文调制模块，它集成了多尺度信息，以及 (2) 一个类指导的交叉注意机制，它融合了原型和特征以进行自动提示生成。在公共多器官数据集和私人心室数据集上的实验表明，PGP-SAM 与现有的无提示 SAM 变体相比实现了卓越的平均 Dice 分数，同时仅使用了 2D 切片的 10%。

##### **Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels**
2501.06678v1 by Erjian Guo, Zicheng Wang, Zhen Zhao, Luping Zhou

Accurate medical image segmentation is often hindered by noisy labels in
training data, due to the challenges of annotating medical images. Prior
research works addressing noisy labels tend to make class-dependent
assumptions, overlooking the pixel-dependent nature of most noisy labels.
Furthermore, existing methods typically apply fixed thresholds to filter out
noisy labels, risking the removal of minority classes and consequently
degrading segmentation performance. To bridge these gaps, our proposed
framework, Collaborative Learning with Curriculum Selection (CLCS), addresses
pixel-dependent noisy labels with class imbalance. CLCS advances the existing
works by i) treating noisy labels as pixel-dependent and addressing them
through a collaborative learning framework, and ii) employing a curriculum
dynamic thresholding approach adapting to model learning progress to select
clean data samples to mitigate the class imbalance issue, and iii) applying a
noise balance loss to noisy data samples to improve data utilization instead of
discarding them outright. Specifically, our CLCS contains two modules:
Curriculum Noisy Label Sample Selection (CNS) and Noise Balance Loss (NBL). In
the CNS module, we designed a two-branch network with discrepancy loss for
collaborative learning so that different feature representations of the same
instance could be extracted from distinct views and used to vote the class
probabilities of pixels. Besides, a curriculum dynamic threshold is adopted to
select clean-label samples through probability voting. In the NBL module,
instead of directly dropping the suspiciously noisy labels, we further adopt a
robust loss to leverage such instances to boost the performance.

摘要：<paragraph>准确的医学影像分割通常会受到训练数据中标签有噪声的阻碍，这是因为对医学影像进行注释具有挑战性。解决标签有噪声的先前研究工作倾向于做出类相关的假设，而忽略了大多数标签有噪声的像素相关性质。此外，现有方法通常应用固定阈值来过滤掉标签有噪声，这有将少数类别的标签移除的风险，从而降低分割性能。为了弥合这些差距，我们提出的框架，即具有课程选择的协作学习 (CLCS)，解决了类别不平衡的像素相关标签有噪声的问题。CLCS 通过以下方式提升了现有工作：i) 将标签有噪声视为像素相关，并通过协作学习框架解决它们，ii) 采用课程动态阈值化方法，适应模型学习进度，选择干净的数据样本以减轻类别不平衡问题，以及 iii) 对标签有噪声的数据样本应用噪声平衡损失，以提高数据利用率，而不是直接丢弃它们。具体而言，我们的 CLCS 包含两个模块：课程标签有噪声样本选择 (CNS) 和噪声平衡损失 (NBL)。在 CNS 模块中，我们设计了一个具有差异损失的两分支网络，用于协作学习，以便可以从不同的视图中提取同一实例的不同特征表示，并用于投票像素的类别概率。此外，采用课程动态阈值通过概率投票选择干净标签样本。在 NBL 模块中，我们没有直接丢弃可疑的标签有噪声，而是进一步采用鲁棒损失来利用此类实例以提升性能。</paragraph>

##### **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**
2501.06465v2 by Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang

We introduce the world's first clinical terminology for the Chinese
healthcare community, namely MedCT, accompanied by a clinical foundation model
MedBERT and an entity linking model MedLink. The MedCT system enables
standardized and programmable representation of Chinese clinical data,
successively stimulating the development of new medicines, treatment pathways,
and better patient outcomes for the populous Chinese community. Moreover, the
MedCT knowledge graph provides a principled mechanism to minimize the
hallucination problem of large language models (LLMs), therefore achieving
significant levels of accuracy and safety in LLM-based clinical applications.
By leveraging the LLMs' emergent capabilities of generativeness and
expressiveness, we were able to rapidly built a production-quality terminology
system and deployed to real-world clinical field within three months, while
classical terminologies like SNOMED CT have gone through more than twenty years
development. Our experiments show that the MedCT system achieves
state-of-the-art (SOTA) performance in semantic matching and entity linking
tasks, not only for Chinese but also for English. We also conducted a
longitudinal field experiment by applying MedCT and LLMs in a representative
spectrum of clinical tasks, including electronic health record (EHR)
auto-generation and medical document search for diagnostic decision making. Our
study shows a multitude of values of MedCT for clinical workflows and patient
outcomes, especially in the new genre of clinical LLM applications. We present
our approach in sufficient engineering detail, such that implementing a
clinical terminology for other non-English societies should be readily
reproducible. We openly release our terminology, models and algorithms, along
with real-world clinical datasets for the development.

摘要：<paragraph>我們為中文醫療社群引入了全球首創的臨床術語，即 MedCT，並附帶臨床基礎模型 MedBERT 和實體連結模型 MedLink。MedCT 系統能標準化並以程式設計方式呈現中文臨床資料，進而刺激新藥、治療途徑的開發，並為人口眾多的華人社群帶來更好的病人治療成果。此外，MedCT 知識圖譜提供一個有原則的機制，以最小化大型語言模型 (LLM) 的幻覺問題，因此在基於 LLM 的臨床應用中達到了顯著的準確性和安全性。透過利用 LLM 生成和表達能力的新興功能，我們得以快速建置一個生產品質的術語系統，並在三個月內部署到實際臨床領域，而像 SNOMED CT 這樣的傳統術語系統則經歷了二十多年的開發。我們的實驗顯示，MedCT 系統在語義匹配和實體連結任務中達到了最先進 (SOTA) 的效能，不只適用於中文，也適用於英文。我們還透過在具代表性的臨床任務中應用 MedCT 和 LLM 來進行縱向實地實驗，包括電子健康紀錄 (EHR) 自動產生和用於診斷決策的醫療文件搜尋。我們的研究顯示 MedCT 對臨床工作流程和病人治療成果有許多價值，特別是在新型態的臨床 LLM 應用中。我們以充分的工程細節說明了我們的做法，因此實作其他非英語社會的臨床術語應易於複製。我們開放釋出我們的術語、模型和演算法，以及用於開發的實際臨床資料集。</paragraph>

##### **Deep Learning on Hester Davis Scores for Inpatient Fall Prediction**
2501.06432v1 by Hojjat Salehinejad, Ricky Rojas, Kingsley Iheasirim, Mohammed Yousufuddin, Bijan Borah

Fall risk prediction among hospitalized patients is a critical aspect of
patient safety in clinical settings, and accurate models can help prevent
adverse events. The Hester Davis Score (HDS) is commonly used to assess fall
risk, with current clinical practice relying on a threshold-based approach. In
this method, a patient is classified as high-risk when their HDS exceeds a
predefined threshold. However, this approach may fail to capture dynamic
patterns in fall risk over time. In this study, we model the threshold-based
approach and propose two machine learning approaches for enhanced fall
prediction: One-step ahead fall prediction and sequence-to-point fall
prediction. The one-step ahead model uses the HDS at the current timestamp to
predict the risk at the next timestamp, while the sequence-to-point model
leverages all preceding HDS values to predict fall risk using deep learning. We
compare these approaches to assess their accuracy in fall risk prediction,
demonstrating that deep learning can outperform the traditional threshold-based
method by capturing temporal patterns and improving prediction reliability.
These findings highlight the potential for data-driven approaches to enhance
patient safety through more reliable fall prevention strategies.

摘要：住院患者的跌倒風險預測是臨床環境中患者安全的重要面向，精確的模型有助於預防不良事件。Hester Davis 評分 (HDS) 常用於評估跌倒風險，目前的臨床實務依賴於基於閾值的評估方式。在此方法中，當患者的 HDS 超過預先定義的閾值時，會將其歸類為高風險。然而，此方法可能無法捕捉隨著時間推移而產生的動態跌倒風險模式。在本研究中，我們對基於閾值的評估方式進行建模，並提出兩種機器學習評估方式以加強跌倒預測：單步前瞻跌倒預測和序列對點跌倒預測。單步前瞻模型使用當前時間戳記的 HDS 預測下一個時間戳記的風險，而序列對點模型則利用所有前一個 HDS 值使用深度學習來預測跌倒風險。我們比較這些評估方式以評估其在跌倒風險預測中的準確性，證明深度學習可以透過捕捉時間模式和提升預測可靠性，優於傳統的基於閾值的評估方式。這些發現強調了資料驅動評估方式在透過更可靠的跌倒預防策略來加強患者安全方面的潛力。

##### **Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts**
2501.06365v1 by Elizabeth Schaefer, Kirk Roberts

This paper presents a pipeline for mitigating gender bias in large language
models (LLMs) used in medical literature by neutralizing gendered occupational
pronouns. A dataset of 379,000 PubMed abstracts from 1965-1980 was processed to
identify and modify pronouns tied to professions. We developed a BERT-based
model, ``Modern Occupational Bias Elimination with Refined Training,'' or
``MOBERT,'' trained on these neutralized abstracts, and compared its
performance with ``1965Bert,'' trained on the original dataset. MOBERT achieved
a 70\% inclusive replacement rate, while 1965Bert reached only 4\%. A further
analysis of MOBERT revealed that pronoun replacement accuracy correlated with
the frequency of occupational terms in the training data. We propose expanding
the dataset and refining the pipeline to improve performance and ensure more
equitable language modeling in medical applications.

摘要：本文提出了一個管道，用於緩解大型語言模型 (LLM) 中的性別偏見，這些模型透過中和性別職業代名詞，用於醫學文獻中。我們處理了 1965 年至 1980 年間 379,000 篇 PubMed 文摘的資料集，以識別和修改與職業相關的代名詞。我們開發了一個 BERT-based 模型，稱為「採用精緻訓練的現代職業偏見消除」或「MOBERT」，並在這些中和的文摘上進行訓練，並將其效能與在原始資料集上訓練的「1965Bert」進行比較。MOBERT 達到了 70% 的包容性替換率，而 1965Bert 僅達到 4%。進一步分析 MOBERT 顯示，代名詞替換的準確性與訓練資料中職業術語的頻率相關。我們建議擴充資料集並精緻化管道，以提升效能並確保在醫學應用中進行更公平的語言建模。

##### **Scale-up Unlearnable Examples Learning with High-Performance Computing**
2501.06080v1 by Yanfan Zhu, Issac Lyngaas, Murali Gopalakrishnan Meena, Mary Ellen I. Koran, Bradley Malin, Daniel Moyer, Shunxing Bao, Anuj Kapadia, Xiao Wang, Bennett Landman, Yuankai Huo

Recent advancements in AI models are structured to retain user interactions,
which could inadvertently include sensitive healthcare data. In the healthcare
field, particularly when radiologists use AI-driven diagnostic tools hosted on
online platforms, there is a risk that medical imaging data may be repurposed
for future AI training without explicit consent, spotlighting critical privacy
and intellectual property concerns around healthcare data usage. Addressing
these privacy challenges, a novel approach known as Unlearnable Examples (UEs)
has been introduced, aiming to make data unlearnable to deep learning models. A
prominent method within this area, called Unlearnable Clustering (UC), has
shown improved UE performance with larger batch sizes but was previously
limited by computational resources. To push the boundaries of UE performance
with theoretically unlimited resources, we scaled up UC learning across various
datasets using Distributed Data Parallel (DDP) training on the Summit
supercomputer. Our goal was to examine UE efficacy at high-performance
computing (HPC) levels to prevent unauthorized learning and enhance data
security, particularly exploring the impact of batch size on UE's
unlearnability. Utilizing the robust computational capabilities of the Summit,
extensive experiments were conducted on diverse datasets such as Pets,
MedMNist, Flowers, and Flowers102. Our findings reveal that both overly large
and overly small batch sizes can lead to performance instability and affect
accuracy. However, the relationship between batch size and unlearnability
varied across datasets, highlighting the necessity for tailored batch size
strategies to achieve optimal data protection. Our results underscore the
critical role of selecting appropriate batch sizes based on the specific
characteristics of each dataset to prevent learning and ensure data security in
deep learning applications.

摘要：<paragraph>最近在 AI 模型中的進展被建構為保留使用者互動，
這可能無意間包含敏感的醫療保健資料。在醫療保健
領域，特別是當放射科醫師使用線上平台上提供的 AI 驅動診斷工具時，有風險是醫療影像資料可能會被重新用於未來的 AI 訓練，而未經明確同意，這突顯了與醫療保健資料使用相關的隱私和智慧財產權問題。為了應對
這些隱私挑戰，已導入一種稱為不可學習範例 (UE) 的新方法，旨在讓資料對深度學習模型不可學習。這個領域內一種著名的稱為不可學習聚類 (UC) 的方法，已顯示出在較大的批次大小下有改善的 UE 效能，但先前受到運算資源的限制。為了在理論上無限制資源的情況下推動 UE 效能的界線，我們在 Summit 超級電腦上使用分散式資料平行 (DDP) 訓練，擴大了各種資料集的 UC 學習。我們的目標是檢查 UE 在高效能運算 (HPC) 層級的效能，以防止未經授權的學習，並增強資料安全性，特別是探討批次大小對 UE 不可學習性的影響。利用 Summit 強大的運算能力，在各種資料集上進行了廣泛的實驗，例如 Pets、MedMNist、Flowers 和 Flowers102。我們的研究結果顯示，過大或過小的批次大小都可能導致效能不穩定，並影響準確度。然而，批次大小與不可學習性之間的關係在各個資料集之間有所不同，這突顯了根據特定資料集的特徵量身打造批次大小策略以達成最佳資料保護的必要性。我們的結果強調了根據每個資料集的特定特徵選擇適當批次大小以防止學習，並確保深度學習應用程式中資料安全性的關鍵作用。</paragraph>

##### **AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**
2501.06039v1 by Johann Wenckstern, Eeshaan Jain, Kiril Vasilev, Matteo Pariset, Andreas Wicki, Gabriele Gut, Charlotte Bunne

Spatial proteomics technologies have transformed our understanding of complex
tissue architectures by enabling simultaneous analysis of multiple molecular
markers and their spatial organization. The high dimensionality of these data,
varying marker combinations across experiments and heterogeneous study designs
pose unique challenges for computational analysis. Here, we present Virtual
Tissues (VirTues), a foundation model framework for biological tissues that
operates across the molecular, cellular and tissue scale. VirTues introduces
innovations in transformer architecture design, including a novel tokenization
scheme that captures both spatial and marker dimensions, and attention
mechanisms that scale to high-dimensional multiplex data while maintaining
interpretability. Trained on diverse cancer and non-cancer tissue datasets,
VirTues demonstrates strong generalization capabilities without task-specific
fine-tuning, enabling cross-study analysis and novel marker integration. As a
generalist model, VirTues outperforms existing approaches across clinical
diagnostics, biological discovery and patient case retrieval tasks, while
providing insights into tissue function and disease mechanisms.

摘要：空間蛋白質組學技術透過同時分析多個分子標記及其空間組織，轉變了我們對複雜組織結構的理解。這些數據的高維度、實驗中不同的標記組合和異質的研究設計，對計算分析構成了獨特的挑戰。在此，我們提出虛擬組織 (VirTues)，一個適用於分子、細胞和組織層級的生物組織基礎模型架構。VirTues 在Transformer架構設計中引進創新，包括一種新的標記化架構，它捕捉空間和標記維度，以及在維持可解釋性的同時擴展到高維度多重數據的注意力機制。VirTues 在多樣化的癌症和非癌症組織數據集上訓練，展示了強大的泛化能力，無需特定任務微調，從而實現跨研究分析和新的標記整合。作為一個通才模型，VirTues 在臨床診斷、生物發現和患者病例檢索任務中優於現有方法，同時提供了組織功能和疾病機制的見解。

##### **DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**
2501.05932v1 by Yongfan Lai, Jiabo Chen, Deyun Zhang, Yue Wang, Shijia Geng, Hongyan Li, Shenda Hong

Heart disease remains a significant threat to human health. As a non-invasive
diagnostic tool, the electrocardiogram (ECG) is one of the most widely used
methods for cardiac screening. However, the scarcity of high-quality ECG data,
driven by privacy concerns and limited medical resources, creates a pressing
need for effective ECG signal generation. Existing approaches for generating
ECG signals typically rely on small training datasets, lack comprehensive
evaluation frameworks, and overlook potential applications beyond data
augmentation. To address these challenges, we propose DiffuSETS, a novel
framework capable of generating ECG signals with high semantic alignment and
fidelity. DiffuSETS accepts various modalities of clinical text reports and
patient-specific information as inputs, enabling the creation of clinically
meaningful ECG signals. Additionally, to address the lack of standardized
evaluation in ECG generation, we introduce a comprehensive benchmarking
methodology to assess the effectiveness of generative models in this domain.
Our model achieve excellent results in tests, proving its superiority in the
task of ECG generation. Furthermore, we showcase its potential to mitigate data
scarcity while exploring novel applications in cardiology education and medical
knowledge discovery, highlighting the broader impact of our work.

摘要：心脏病仍然是人类健康的一大威胁。作为一种非侵入性诊断工具，心电图 (ECG) 是心脏筛查最广泛使用的方法之一。然而，由于隐私问题和医疗资源有限，高质量 ECG 数据的稀缺对有效的 ECG 信号生成提出了迫切需求。现有用于生成 ECG 信号的方法通常依赖于小型训练数据集，缺乏全面的评估框架，并且忽视了数据增强之外的潜在应用。为了应对这些挑战，我们提出了 DiffuSETS，这是一个能够生成具有高度语义对齐和保真度的 ECG 信号的新框架。DiffuSETS 接受各种形式的临床文本报告和患者特定信息作为输入，从而能够创建具有临床意义的 ECG 信号。此外，为了解决 ECG 生成中缺乏标准化评估的问题，我们引入了一种全面的基准测试方法来评估生成模型在此领域的有效性。我们的模型在测试中取得了优异的成果，证明了其在 ECG 生成任务中的优越性。此外，我们展示了其在缓解数据稀缺的同时在心脏病学教育和医学知识发现中探索新应用的潜力，突出了我们工作的更广泛影响。

##### **AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India**
2501.05826v2 by Amit Kr Dey, Pradeep Walia, Girish Somvanshi, Abrar Ali, Sagarnil Das, Pallabi Paul, Minakhi Ghosh

Purpose: Diabetic retinopathy (DR) is a major cause of vision loss,
particularly in India, where access to retina specialists is limited in rural
areas. This study aims to evaluate the Artificial Intelligence-based Diabetic
Retinopathy Screening System (AIDRSS) for DR detection and prevalence
assessment, addressing the growing need for scalable, automated screening
solutions in resource-limited settings.
  Approach: A multicentric, cross-sectional study was conducted in Kolkata,
India, involving 5,029 participants and 10,058 macula-centric retinal fundus
images. The AIDRSS employed a deep learning algorithm with 50 million trainable
parameters, integrated with Contrast Limited Adaptive Histogram Equalization
(CLAHE) preprocessing for enhanced image quality. DR was graded using the
International Clinical Diabetic Retinopathy (ICDR) Scale, categorizing disease
into five stages (DR0 to DR4). Statistical metrics including sensitivity,
specificity, and prevalence rates were evaluated against expert retina
specialist assessments.
  Results: The prevalence of DR in the general population was 13.7%, rising to
38.2% among individuals with elevated random blood glucose levels. The AIDRSS
achieved an overall sensitivity of 92%, specificity of 88%, and 100%
sensitivity for detecting referable DR (DR3 and DR4). These results demonstrate
the system's robust performance in accurately identifying and grading DR in a
diverse population.
  Conclusions: AIDRSS provides a reliable, scalable solution for early DR
detection in resource-constrained environments. Its integration of advanced AI
techniques ensures high diagnostic accuracy, with potential to significantly
reduce the burden of diabetes-related vision loss in underserved regions.

摘要：<paragraph>目的：糖尿病视网膜病变 (DR) 是视力丧失的主要原因，特别是在印度，那里的农村地区眼科专家数量有限。本研究旨在评估基于人工智能的糖尿病视网膜病变筛查系统 (AIDRSS) 的 DR 检测和流行情况评估，以满足资源有限的环境中对可扩展自动化筛查解决方案不断增长的需求。
方法：在印度加尔各答进行了一项多中心横断面研究，涉及 5,029 名参与者和 10,058 张黄斑中心视网膜眼底图像。AIDRSS 采用了一个深度学习算法，具有 5000 万个可训练参数，并集成了对比度限制自适应直方图均衡化 (CLAHE) 预处理，以提高图像质量。DR 使用国际临床糖尿病视网膜病变 (ICDR) 量表进行分级，将疾病分为五个阶段（DR0 至 DR4）。针对专家视网膜专家评估，评估了包括敏感性、特异性和患病率在内的统计指标。
结果：一般人群中 DR 的患病率为 13.7%，在随机血糖水平升高的个体中上升至 38.2%。AIDRSS 的总体敏感性达到 92%，特异性达到 88%，检测可转诊 DR（DR3 和 DR4）的敏感性达到 100%。这些结果表明该系统在准确识别和分级不同人群中的 DR 方面具有强大的性能。
结论：AIDRSS 为资源受限环境中的早期 DR 检测提供了一种可靠且可扩展的解决方案。它集成了先进的人工智能技术，确保了较高的诊断准确性，有可能显著减少服务不足地区与糖尿病相关的视力丧失负担。</paragraph>

##### **Large Language Models for Bioinformatics**
2501.06271v1 by Wei Ruan, Yanjun Lyu, Jing Zhang, Jiazhang Cai, Peng Shu, Yang Ge, Yao Lu, Shang Gao, Yue Wang, Peilong Wang, Lin Zhao, Tao Wang, Yufang Liu, Luyang Fang, Ziyu Liu, Zhengliang Liu, Yiwei Li, Zihao Wu, Junhao Chen, Hanqi Jiang, Yi Pan, Zhenyuan Yang, Jingyuan Chen, Shizhe Liang, Wei Zhang, Terry Ma, Yuan Dou, Jianli Zhang, Xinyu Gong, Qi Gan, Yusong Zou, Zebang Chen, Yuanxin Qian, Shuo Yu, Jin Lu, Kenan Song, Xianqiao Wang, Andrea Sikora, Gang Li, Xiang Li, Quanzheng Li, Yingfeng Wang, Lu Zhang, Yohannes Abate, Lifang He, Wenxuan Zhong, Rongjie Liu, Chao Huang, Wei Liu, Ye Shen, Ping Ma, Hongtu Zhu, Yajun Yan, Dajiang Zhu, Tianming Liu

With the rapid advancements in large language model (LLM) technology and the
emergence of bioinformatics-specific language models (BioLMs), there is a
growing need for a comprehensive analysis of the current landscape,
computational characteristics, and diverse applications. This survey aims to
address this need by providing a thorough review of BioLMs, focusing on their
evolution, classification, and distinguishing features, alongside a detailed
examination of training methodologies, datasets, and evaluation frameworks. We
explore the wide-ranging applications of BioLMs in critical areas such as
disease diagnosis, drug discovery, and vaccine development, highlighting their
impact and transformative potential in bioinformatics. We identify key
challenges and limitations inherent in BioLMs, including data privacy and
security concerns, interpretability issues, biases in training data and model
outputs, and domain adaptation complexities. Finally, we highlight emerging
trends and future directions, offering valuable insights to guide researchers
and clinicians toward advancing BioLMs for increasingly sophisticated
biological and clinical applications.

摘要：隨著大型語言模型（LLM）技術的快速進展和生物資訊學特定語言模型（BioLM）的出現，對於當前情勢、計算特徵和多元應用進行全面分析的需求日益增加。本調查旨在透過提供對 BioLM 的全面檢視，著重於其演進、分類和區別特徵，以及對訓練方法、資料集和評估架構的詳細探討，來滿足此需求。我們探討 BioLM 在疾病診斷、藥物發現和疫苗開發等關鍵領域的廣泛應用，強調其在生物資訊學中的影響和轉型潛力。我們找出 BioLM 固有的關鍵挑戰和限制，包括資料隱私和安全性問題、可解釋性問題、訓練資料和模型輸出的偏差，以及領域適應的複雜性。最後，我們重點介紹新興趨勢和未來方向，提供有價值的見解，以指導研究人員和臨床醫生將 BioLM 應用於日益複雜的生物和臨床應用。

##### **From Simple to Complex Skills: The Case of In-Hand Object Reorientation**
2501.05439v1 by Haozhi Qi, Brent Yi, Mike Lambeta, Yi Ma, Roberto Calandra, Jitendra Malik

Learning policies in simulation and transferring them to the real world has
become a promising approach in dexterous manipulation. However, bridging the
sim-to-real gap for each new task requires substantial human effort, such as
careful reward engineering, hyperparameter tuning, and system identification.
In this work, we present a system that leverages low-level skills to address
these challenges for more complex tasks. Specifically, we introduce a
hierarchical policy for in-hand object reorientation based on previously
acquired rotation skills. This hierarchical policy learns to select which
low-level skill to execute based on feedback from both the environment and the
low-level skill policies themselves. Compared to learning from scratch, the
hierarchical policy is more robust to out-of-distribution changes and transfers
easily from simulation to real-world environments. Additionally, we propose a
generalizable object pose estimator that uses proprioceptive information,
low-level skill predictions, and control errors as inputs to estimate the
object pose over time. We demonstrate that our system can reorient objects,
including symmetrical and textureless ones, to a desired pose.

摘要：在模擬中學習策略並將其轉移到現實世界已成為靈巧操作中一種有前景的方法。然而，對於每項新任務來說，彌合模擬到現實的差距需要大量的人力，例如仔細的獎勵工程、超參數調整和系統識別。在這項工作中，我們提出了一個利用低層技能來應對更複雜任務的挑戰的系統。具體來說，我們引入了一個基於先前獲得的旋轉技能的手中物體重新定向的分層策略。這種分層策略學習根據環境和低層技能策略本身的回饋選擇執行哪種低層技能。與從頭開始學習相比，分層策略對分佈外變化更強健，並且可以輕鬆地從模擬轉移到現實世界環境。此外，我們提出了一個可泛化的物體姿勢估計器，它使用 proprioceptive 信息、低層技能預測和控制誤差作為輸入來估計物體姿勢。我們證明了我們的系統可以將物體（包括對稱和無紋理的物體）重新定向到所需的姿勢。

##### **Strategy Masking: A Method for Guardrails in Value-based Reinforcement Learning Agents**
2501.05501v2 by Jonathan Keane, Sam Keyser, Jeremy Kedziora

The use of reward functions to structure AI learning and decision making is
core to the current reinforcement learning paradigm; however, without careful
design of reward functions, agents can learn to solve problems in ways that may
be considered "undesirable" or "unethical." Without thorough understanding of
the incentives a reward function creates, it can be difficult to impose
principled yet general control mechanisms over its behavior. In this paper, we
study methods for constructing guardrails for AI agents that use reward
functions to learn decision making. We introduce a novel approach, which we
call strategy masking, to explicitly learn and then suppress undesirable AI
agent behavior. We apply our method to study lying in AI agents and show that
it can be used to effectively modify agent behavior by suppressing lying
post-training without compromising agent ability to perform effectively.

摘要：使用獎勵函數來建構 AI 學習和決策制定是目前強化學習範例的核心；然而，在沒有仔細設計獎勵函數的情況下，代理人可能會學到以可能被視為「不受歡迎」或「不道德」的方式來解決問題。在沒有徹底了解獎勵函數所創造的誘因的情況下，很難對其行為施加有原則但又通用的控制機制。在本文中，我們研究了為使用獎勵函數來學習決策制定的 AI 代理建立護欄的方法。我們介紹了一種新穎的方法，我們稱之為策略遮罩，用於明確學習並抑制不受歡迎的 AI 代理行為。我們將我們的這種方法應用於研究 AI 代理中的說謊行為，並表明它可用於通過在訓練後抑制說謊來有效修改代理行為，同時不損害代理有效執行的能力。

##### **Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics**
2501.05409v2 by Maximilian Alber, Stephan Tietz, Jonas Dippel, Timo Milbich, Timothée Lesort, Panos Korfiatis, Moritz Krügener, Beatriz Perez Cancer, Neelay Shah, Alexander Möllers, Philipp Seegerer, Alexandra Carpen-Amarie, Kai Standvoss, Gabriel Dernbach, Edwin de Jong, Simon Schallenberg, Andreas Kunft, Helmut Hoffer von Ankershoffen, Gavin Schaeferle, Patrick Duffy, Matt Redlon, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert Müller, Frederick Klauschen, Andrew Norgan

Recent advances in digital pathology have demonstrated the effectiveness of
foundation models across diverse applications. In this report, we present
Atlas, a novel vision foundation model based on the RudolfV approach. Our model
was trained on a dataset comprising 1.2 million histopathology whole slide
images, collected from two medical institutions: Mayo Clinic and Charit\'e -
Universt\"atsmedizin Berlin. Comprehensive evaluations show that Atlas achieves
state-of-the-art performance across twenty-one public benchmark datasets, even
though it is neither the largest model by parameter count nor by training
dataset size.

摘要：最近在數位病理學的進展已展現基礎模型在各種應用上的有效性。在此報告中，我們提出 Atlas，一種基於 RudolfV 方法的新穎視覺基礎模型。我們的模型訓練於一個包含 120 萬張組織病理全玻片影像的資料集，這些影像收集自兩個醫療機構：梅約診所和柏林夏里特大學醫學中心。全面的評估顯示，Atlas 在 21 個公開基準資料集上達到了最先進的效能，即使它既不是參數數量最大的模型，也不是訓練資料集規模最大的模型。

##### **An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**
2501.05197v1 by Drago Plecko, Paul Secombe, Andrea Clarke, Amelia Fiske, Samarra Toby, Donisha Duff, David Pilcher, Leo Anthony Celi, Rinaldo Bellomo, Elias Bareinboim

The new era of large-scale data collection and analysis presents an
opportunity for diagnosing and understanding the causes of health inequities.
In this study, we describe a framework for systematically analyzing health
disparities using causal inference. The framework is illustrated by
investigating racial and ethnic disparities in intensive care unit (ICU)
outcome between majority and minority groups in Australia (Indigenous vs.
Non-Indigenous) and the United States (African-American vs. White). We
demonstrate that commonly used statistical measures for quantifying inequity
are insufficient, and focus on attributing the observed disparity to the causal
mechanisms that generate it. We find that minority patients are younger at
admission, have worse chronic health, are more likely to be admitted for urgent
and non-elective reasons, and have higher illness severity. At the same time,
however, we find a protective direct effect of belonging to a minority group,
with minority patients showing improved survival compared to their majority
counterparts, with all other variables kept equal. We demonstrate that this
protective effect is related to the increased probability of being admitted to
ICU, with minority patients having an increased risk of ICU admission. We also
find that minority patients, while showing improved survival, are more likely
to be readmitted to ICU. Thus, due to worse access to primary health care,
minority patients are more likely to end up in ICU for preventable conditions,
causing a reduction in the mortality rates and creating an effect that appears
to be protective. Since the baseline risk of ICU admission may serve as proxy
for lack of access to primary care, we developed the Indigenous Intensive Care
Equity (IICE) Radar, a monitoring system for tracking the over-utilization of
ICU resources by the Indigenous population of Australia across geographical
areas.

摘要：大型資料收集和分析的新時代，提供了診斷和了解健康不平等成因的機會。在這項研究中，我們描述了一個使用因果推論系統分析健康差距的架構。這個架構透過調查澳洲（原住民對非原住民）和美國（非裔美國人對白人）中，重症加護病房（ICU）結果在種族和族群上的差異來加以說明。我們證明了通常用於量化不平等的統計測量是不夠的，並專注於將觀察到的差異歸因於產生它的因果機制。我們發現，少數族裔患者在入院時較年輕，慢性健康狀況較差，更有可能因緊急和非選擇性原因而入院，且疾病嚴重程度較高。然而，同時我們發現屬於少數族裔群體具有保護性的直接影響，與多數族裔的對照組相比，少數族裔患者在其他所有變數保持相同的情況下，存活率有所改善。我們證明這種保護效應與被送進 ICU 的機率增加有關，少數族裔患者的 ICU 入院風險增加。我們也發現，少數族裔患者雖然存活率有所改善，但更有可能再次入院到 ICU。因此，由於較難獲得初級醫療保健，少數族裔患者更有可能因可預防的疾病而進入 ICU，導致死亡率降低並產生看似具有保護作用的效應。由於 ICU 入院的基本風險可能作為缺乏初級照護的指標，因此我們開發了原住民重症監護公平性（IICE）雷達，這是一個監控系統，用於追蹤澳洲原住民人口在不同地理區域過度使用 ICU 資源的情況。

##### **Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**
2501.04958v1 by Lei Li, Xinglin Zhang, Jun Liang, Tao Chen

Deep learning models in medical imaging face dual challenges: domain shift,
where models perform poorly when deployed in settings different from their
training environment, and class imbalance, where certain disease conditions are
naturally underrepresented. We present Imbalance-Aware Domain Adaptation
(IADA), a novel framework that simultaneously tackles both challenges through
three key components: (1) adaptive feature learning with class-specific
attention mechanisms, (2) balanced domain alignment with dynamic weighting, and
(3) adaptive threshold optimization. Our theoretical analysis establishes
convergence guarantees and complexity bounds. Through extensive experiments on
embryo development assessment across four imaging modalities, IADA demonstrates
significant improvements over existing methods, achieving up to 25.19\% higher
accuracy while maintaining balanced performance across classes. In challenging
scenarios with low-quality imaging systems, IADA shows robust generalization
with AUC improvements of up to 12.56\%. These results demonstrate IADA's
potential for developing reliable and equitable medical imaging systems for
diverse clinical settings. The code is made public available at
\url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}

摘要：<paragraph>醫療影像中的深度學習模型面臨雙重挑戰：領域轉移，模型在與其訓練環境不同的設定中部署時表現不佳，以及類別不平衡，某些疾病狀況在自然界中代表性不足。我們提出不平衡感知域適應 (IADA)，這是一個新穎的框架，透過三個關鍵組成部分同時應對這兩個挑戰：(1) 具有類別特定注意力機制的自適應特徵學習，(2) 具有動態加權的平衡域對齊，以及 (3) 自適應閾值最佳化。我們的理論分析建立了收斂保證和複雜度界限。透過對四種影像模式的胚胎發育評估進行廣泛的實驗，IADA 證明了對現有方法的顯著改進，在維持類別間平衡性能的同時，準確度提高了 25.19%。在低品質影像系統的挑戰性場景中，IADA 以高達 12.56% 的 AUC 改進顯示出強大的泛化能力。這些結果證明了 IADA 在為不同的臨床設定開發可靠且公平的醫療影像系統方面的潛力。程式碼已公開於 \url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}</paragraph>

##### **Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**
2501.04896v1 by Michail Ouroutzoglou, Mingmin Zhao, Joshua Hellerstein, Hariharan Rahul, Asima Badic, Brian S. Kim, Dina Katabi

Chronic itch affects 13% of the US population, is highly debilitating, and
underlies many medical conditions. A major challenge in clinical care and new
therapeutics development is the lack of an objective measure for quantifying
itch, leading to reliance on subjective measures like patients' self-assessment
of itch severity. In this paper, we show that a home radio device paired with
artificial intelligence (AI) can concurrently capture scratching and evaluate
its impact on sleep quality by analyzing radio signals bouncing in the
environment. The device eliminates the need for wearable sensors or skin
contact, enabling monitoring of chronic itch over extended periods at home
without burdening patients or interfering with their skin condition. To
validate the technology, we conducted an observational clinical study of
chronic pruritus patients, monitored at home for one month using both the radio
device and an infrared camera. Comparing the output of the device to ground
truth data from the camera demonstrates its feasibility and accuracy (ROC AUC =
0.997, sensitivity = 0.825, specificity = 0.997). The results reveal a
significant correlation between scratching and low sleep quality, manifested as
a reduction in sleep efficiency (R = 0.6, p < 0.001) and an increase in sleep
latency (R = 0.68, p < 0.001). Our study underscores the potential of passive,
long-term, at-home monitoring of chronic scratching and its sleep implications,
offering a valuable tool for both clinical care of chronic itch patients and
pharmaceutical clinical trials.

摘要：慢性搔癢影響美國 13% 的人口，會嚴重衰弱，且是許多疾病的根本原因。臨床護理和新療法開發的一大挑戰是缺乏客觀的指標來量化搔癢，導致依賴於患者自我評估搔癢嚴重程度等主觀指標。在本文中，我們展示了一種與人工智慧 (AI) 配對的家用無線電裝置，可透過分析在環境中彈跳的無線電訊號，同時擷取抓撓並評估其對睡眠品質的影響。此裝置消除了對穿戴式感測器或皮膚接觸的需求，讓患者在家中長時間監控慢性搔癢，而不會造成負擔或干擾其皮膚狀況。為了驗證這項技術，我們對慢性搔癢症患者進行了一項觀察性臨床研究，使用無線電裝置和紅外線攝影機在家中監控一個月。將裝置的輸出與攝影機的真實數據進行比較，證明了其可行性和準確性 (ROC AUC = 0.997，靈敏度 = 0.825，特異度 = 0.997)。結果顯示抓撓與睡眠品質低下之間存在顯著相關性，表現為睡眠效率降低 (R = 0.6，p < 0.001) 和睡眠潛伏期增加 (R = 0.68，p < 0.001)。我們的研究強調了被動、長期、在家中監控慢性抓撓及其對睡眠的影響的潛力，為慢性搔癢症患者的臨床護理和藥廠臨床試驗提供了有價值的工具。

##### **MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**
2501.04614v2 by Daniele Molino, Francesco Di Feola, Eliodoro Faiella, Deborah Fazzini, Domiziana Santucci, Linlin Shen, Valerio Guarrasi, Paolo Soda

Artificial Intelligence is revolutionizing medical practice, enhancing
diagnostic accuracy and healthcare delivery. However, its adaptation in medical
settings still faces significant challenges, related to data availability and
privacy constraints. Synthetic data has emerged as a promising solution to
mitigate these issues, addressing data scarcity while preserving privacy.
Recently, Latent Diffusion Models have emerged as a powerful tool for
generating high-quality synthetic data. Meanwhile, the integration of different
modalities has gained interest, emphasizing the need of models capable of
handle multimodal medical data. Existing approaches struggle to integrate
complementary information and lack the ability to generate modalities
simultaneously. To address this challenge, we present MedCoDi-M, a
6.77-billion-parameter model, designed for multimodal medical data generation,
that, following Foundation Model paradigm, exploits contrastive learning and
large quantity of data to build a shared latent space which capture the
relationships between different data modalities. Further, we introduce the
Multi-Prompt training technique, which significantly boosts MedCoDi-M's
generation under different settings. We extensively validate MedCoDi-M: first
we benchmark it against five competitors on the MIMIC-CXR dataset, a
state-of-the-art dataset for Chest X-ray and radiological report generation.
Secondly, we perform a Visual Turing Test with expert radiologists to assess
the realism and clinical relevance of the generated data, ensuring alignment
with real-world scenarios. Finally, we assess the utility of MedCoDi-M in
addressing key challenges in the medical field, such as anonymization, data
scarcity and imbalance learning. The results are promising, demonstrating the
applicability of MedCoDi-M in medical contexts. Project page is at
https://cosbidev.github.io/MedCoDi-M/.

摘要：人工智能正在革新醫療實務，提升診斷準確度和醫療保健服務。然而，它在醫療場景中的應用仍面臨著重大挑戰，這與資料可用性和隱私限制有關。合成資料已成為緩解這些問題的潛在解決方案，它在保護隱私的同時解決了資料短缺的問題。最近，潛在擴散模型已成為產生高品質合成資料的強大工具。同時，整合不同模態已引起興趣，強調了需要能夠處理多模態醫療資料的模型。現有方法難以整合補充資訊，並且缺乏同時產生模態的能力。為了應對這一挑戰，我們提出了 MedCoDi-M，這是一個 67.7 億參數的模型，專為多模態醫療資料產生而設計，它遵循基礎模型範例，利用對比學習和大量的資料來建立一個共享潛在空間，以捕捉不同資料模態之間的關係。此外，我們引入了多提示訓練技術，它顯著提升了 MedCoDi-M 在不同設定下的產生。我們廣泛驗證了 MedCoDi-M：首先，我們在 MIMIC-CXR 資料集上對它與五個競爭者進行了基準測試，這是胸部 X 光和放射報告產生領域的最新資料集。其次，我們與放射科專家進行了視覺圖靈測試，以評估產生資料的真實性和臨床相關性，確保與真實場景保持一致。最後，我們評估了 MedCoDi-M 在解決醫療領域關鍵挑戰中的效用，例如匿名化、資料短缺和不平衡學習。結果令人滿意，證明了 MedCoDi-M 在醫療環境中的適用性。專案頁面位於 https://cosbidev.github.io/MedCoDi-M/。

##### **A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**
2501.04577v2 by Zephan M. Enciso, Boyang Cheng, Likai Pei, Jianbo Liu, Steven Davis, Michael Niemier, Ningyuan Cao

Uncertainty estimation is an indispensable capability for AI-enabled,
safety-critical applications, e.g. autonomous vehicles or medical diagnosis.
Bayesian neural networks (BNNs) use Bayesian statistics to provide both
classification predictions and uncertainty estimation, but they suffer from
high computational overhead associated with random number generation and
repeated sample iterations. Furthermore, BNNs are not immediately amenable to
acceleration through compute-in-memory architectures due to the frequent memory
writes necessary after each RNG operation. To address these challenges, we
present an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into the
SRAM memory words. This integration reduces RNG overhead and enables
fully-parallel compute-in-memory operations for BNNs. The prototype chip
achieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughput
while occupying 0.45 mm2, bringing AI uncertainty estimation to edge
computation.

摘要：不確定性估計對於 AI 啟用、安全至上的應用程式而言，例如自動駕駛車輛或醫療診斷，不可或缺。貝氏神經網路 (BNN) 使用貝氏統計提供分類預測和不確定性估計，但它們會因為隨機數字產生和重複取樣迭代而造成巨大的運算負擔。此外，BNN 並非立即適用於透過運算於記憶體架構進行加速，因為每次 RNG 作業後都需要頻繁寫入記憶體。為了解決這些挑戰，我們提出了一種 ASIC，將 360 fJ/取樣的高斯 RNG 直接整合到 SRAM 記憶體字中。這種整合可降低 RNG 負擔，並為 BNN 啟用完全並行的運算於記憶體作業。原型晶片可達到 5.12 GSa/s RNG 處理量和 102 GOp/s 神經網路處理量，同時佔用 0.45 mm2，將 AI 不確定性估計帶入邊緣運算。

##### **Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**
2501.04217v1 by Ren Tasai, Guang Li, Ren Togo, Minghui Tang, Takaaki Yoshimura, Hiroyuki Sugimori, Kenji Hirata, Takahiro Ogawa, Kohsuke Kudo, Miki Haseyama

We propose a novel continual self-supervised learning method (CSSL)
considering medical domain knowledge in chest CT images. Our approach addresses
the challenge of sequential learning by effectively capturing the relationship
between previously learned knowledge and new information at different stages.
By incorporating an enhanced DER into CSSL and maintaining both diversity and
representativeness within the rehearsal buffer of DER, the risk of data
interference during pretraining is reduced, enabling the model to learn more
richer and robust feature representations. In addition, we incorporate a mixup
strategy and feature distillation to further enhance the model's ability to
learn meaningful representations. We validate our method using chest CT images
obtained under two different imaging conditions, demonstrating superior
performance compared to state-of-the-art methods.

摘要：我們提出了一種新的持續自我監督學習方法 (CSSL)，考量了胸部電腦斷層影像中的醫學領域知識。我們的做法透過有效捕捉先前學習的知識與不同階段的新資訊之間的關係，來解決循序學習的挑戰。透過將增強的 DER 納入 CSSL，並在 DER 的排練緩衝區內維持多樣性和代表性，預訓練期間資料干擾的風險降低，使模型能夠學習更豐富且強健的特徵表徵。此外，我們納入混淆策略和特徵萃取，進一步增強模型學習有意義表徵的能力。我們使用在兩種不同影像條件下取得的胸部電腦斷層影像驗證我們的模型，證明與現有技術相比具有優異的效能。

##### **Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**
2501.04734v1 by Rancy Chepchirchir, Jill Sunday, Raymond Confidence, Dong Zhang, Talha Chaudhry, Udunna C. Anazodo, Kendi Muchungi, Yujing Zou

In Sub-Saharan Africa (SSA), the utilization of lower-quality Magnetic
Resonance Imaging (MRI) technology raises questions about the applicability of
machine learning methods for clinical tasks. This study aims to provide a
robust deep learning-based brain tumor segmentation (BraTS) method tailored for
the SSA population using a threefold approach. Firstly, the impact of domain
shift from the SSA training data on model efficacy was examined, revealing no
significant effect. Secondly, a comparative analysis of 3D and 2D
full-resolution models using the nnU-Net framework indicates similar
performance of both the models trained for 300 epochs achieving a five-fold
cross-validation score of 0.93. Lastly, addressing the performance gap observed
in SSA validation as opposed to the relatively larger BraTS glioma (GLI)
validation set, two strategies are proposed: fine-tuning SSA cases using the
GLI+SSA best-pretrained 2D fullres model at 300 epochs, and introducing a novel
neural style transfer-based data augmentation technique for the SSA cases. This
investigation underscores the potential of enhancing brain tumor prediction
within SSA's unique healthcare landscape.

摘要：在撒哈拉以南非洲 (SSA)，低质量磁共振成像 (MRI) 技术的使用引发了有关机器学习方法在临床任务中适用性的问题。本研究旨在提供一种针对 SSA 人群量身定制的鲁棒深度学习脑肿瘤分割 (BraTS) 方法，采用三重方法。首先，检查了 SSA 训练数据对模型效能的域偏移影响，结果显示没有显着影响。其次，使用 nnU-Net 框架对 3D 和 2D 全分辨率模型进行比较分析，表明针对 300 个 epoch 训练的两个模型的性能相似，实现了 0.93 的五重交叉验证分数。最后，针对 SSA 验证中观察到的性能差距，而不是相对较大的 BraTS 神经胶质瘤 (GLI) 验证集，提出了两种策略：使用 GLI+SSA 最佳预训练的 2D 全分辨率模型在 300 个 epoch 对 SSA 病例进行微调，并为 SSA 病例引入一种新颖的神经风格迁移数据增强技术。这项调查强调了在 SSA 独特的医疗保健环境中提高脑肿瘤预测潜力的可能性。

##### **Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**
2501.03904v1 by Ramya Jonnala, Gongbo Liang, Jeong Yang, Izzat Alsmadi

The integration of large language models (LLMs) into public transit systems
presents a transformative opportunity to enhance urban mobility. This study
explores the potential of LLMs to revolutionize public transportation
management within the context of San Antonio's transit system. Leveraging the
capabilities of LLMs in natural language processing and data analysis, we
investigate their capabilities to optimize route planning, reduce wait times,
and provide personalized travel assistance. By utilizing the General Transit
Feed Specification (GTFS) and other relevant data, this research aims to
demonstrate how LLMs can potentially improve resource allocation, elevate
passenger satisfaction, and inform data-driven decision-making in transit
operations. A comparative analysis of different ChatGPT models was conducted to
assess their ability to understand transportation information, retrieve
relevant data, and provide comprehensive responses. Findings from this study
suggest that while LLMs hold immense promise for public transit, careful
engineering and fine-tuning are essential to realizing their full potential.
San Antonio serves as a case study to inform the development of LLM-powered
transit systems in other urban environments.

摘要：大型語言模型 (LLM) 整合到公共交通系統中，為提升城市流動性帶來轉型契機。本研究探討 LLM 在聖安東尼奧交通系統脈絡下，革新大眾運輸管理的潛力。利用 LLM 在自然語言處理和資料分析方面的能力，我們探討其在優化路線規劃、縮短等候時間，以及提供個人化旅遊協助方面的能力。透過利用通用大眾運輸資料規範 (GTFS) 和其他相關資料，本研究旨在證明 LLM 如何潛在提升資源配置、提升乘客滿意度，以及在交通營運中提供資料驅動的決策。針對不同的 ChatGPT 模型進行比較分析，以評估其理解交通資訊、擷取相關資料，以及提供全面回應的能力。本研究的發現顯示，儘管 LLM 對大眾運輸極具前景，但精密的工程和微調對於實現其全部潛力至關重要。聖安東尼奧作為一個案例研究，為在其他都市環境中開發由 LLM 驅動的交通系統提供參考。

##### **SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**
2501.03836v2 by Runci Bai

Brain tumors can result in neurological dysfunction, alterations in cognitive
and psychological states, increased intracranial pressure, and the occurrence
of seizures, thereby presenting a substantial risk to human life and health.
The You Only Look Once(YOLO) series models have demonstrated superior accuracy
in object detection for medical imaging. In this paper, we develop a novel
SCC-YOLO architecture by integrating the SCConv attention mechanism into
YOLOv9. The SCConv module reconstructs an efficient convolutional module by
reducing spatial and channel redundancy among features, thereby enhancing the
learning of image features. We investigate the impact of intergrating different
attention mechanisms with the YOLOv9 model on brain tumor image detection using
both the Br35H dataset and our self-made dataset(Brain_Tumor_Dataset).
Experimental results show that on the Br35H dataset, SCC-YOLO achieved a 0.3%
improvement in mAp50 compared to YOLOv9, while on our self-made dataset,
SCC-YOLO exhibited a 0.5% improvement over YOLOv9. SCC-YOLO has reached
state-of-the-art performance in brain tumor detection. Source code is available
at : https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

摘要：腦瘤可能導致神經功能障礙、認知和心理狀態改變、顱內壓升高和癲癇發作，從而對人類生命和健康構成重大風險。You Only Look Once (YOLO) 系列模型已證明在醫學影像的目標檢測中具有優異的準確度。在本文中，我們通過將 SCConv 注意力機制整合到 YOLOv9 中，開發了一種新穎的 SCC-YOLO 架構。SCConv 模組通過減少特徵之間的空間和通道冗餘來重建一個高效的卷積模組，從而增強影像特徵的學習。我們使用 Br35H 資料集和我們自製的資料集 (Brain_Tumor_Dataset) 調查了將不同的注意力機制與 YOLOv9 模型整合對腦瘤影像檢測的影響。實驗結果表明，在 Br35H 資料集上，與 YOLOv9 相比，SCC-YOLO 在 mAP50 上提高了 0.3%，而在我們自製的資料集上，SCC-YOLO 比 YOLOv9 提高了 0.5%。SCC-YOLO 已達到腦瘤檢測的最新效能。原始碼可在以下網址取得：https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

##### **SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**
2501.03764v1 by Siyuan Zhao, Chenyu Liu, Yi Ding, Xinliang Zhou

In practical sleep stage classification, a key challenge is the variability
of EEG data across different subjects and environments. Differences in
physiology, age, health status, and recording conditions can lead to domain
shifts between data. These domain shifts often result in decreased model
accuracy and reliability, particularly when the model is applied to new data
with characteristics different from those it was originally trained on, which
is a typical manifestation of negative transfer. To address this, we propose
SelectiveFinetuning in this paper. Our method utilizes a pretrained Multi
Resolution Convolutional Neural Network (MRCNN) to extract EEG features,
capturing the distinctive characteristics of different sleep stages. To
mitigate the effect of domain shifts, we introduce a domain aligning mechanism
that employs Earth Mover Distance (EMD) to evaluate and select source domain
data closely matching the target domain. By finetuning the model with selective
source data, our SelectiveFinetuning enhances the model's performance on target
domain that exhibits domain shifts compared to the data used for training.
Experimental results show that our method outperforms existing baselines,
offering greater robustness and adaptability in practical scenarios where data
distributions are often unpredictable.

摘要：在實際的睡眠階段分類中，一個關鍵的挑戰是腦電圖數據在不同受試者和環境中的變異性。生理、年齡、健康狀況和記錄條件的差異可能導致數據之間的領域偏移。這些領域偏移通常會導致模型準確度和可靠性下降，特別是當模型應用於與其最初訓練時不同的特徵的新數據時，這是負遷移的典型表現。為了解決這個問題，我們在本文中提出選擇性微調。我們的模型利用預訓練的多解析度卷積神經網路 (MRCNN) 來提取腦電圖特徵，捕捉不同睡眠階段的獨特特徵。為了減輕領域偏移的影響，我們引入了一個領域對齊機制，它採用地球移動距離 (EMD) 來評估和選擇與目標領域緊密匹配的源領域數據。通過使用選擇性源數據微調模型，我們的選擇性微調增強了模型在與用於訓練的數據相比表現出領域偏移的目標領域上的性能。實驗結果表明，我們的模型優於現有的基準，在數據分佈通常不可預測的實際場景中提供了更大的穩健性和適應性。

##### **Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**
2501.03722v1 by Xiaotong Guo, Deqian Yang, Dan Wang, Haochen Zhao, Yuan Li, Zhilin Sui, Tao Zhou, Lijun Zhang, Yanda Meng

Accurate segmentation of pulmonary structures iscrucial in clinical
diagnosis, disease study, and treatment planning. Significant progress has been
made in deep learning-based segmentation techniques, but most require much
labeled data for training. Consequently, developing precise segmentation
methods that demand fewer labeled datasets is paramount in medical image
analysis. The emergence of pre-trained vision-language foundation models, such
as CLIP, recently opened the door for universal computer vision tasks.
Exploiting the generalization ability of these pre-trained foundation models on
downstream tasks, such as segmentation, leads to unexpected performance with a
relatively small amount of labeled data. However, exploring these models for
pulmonary artery-vein segmentation is still limited. This paper proposes a
novel framework called Language-guided self-adaptive Cross-Attention Fusion
Framework. Our method adopts pre-trained CLIP as a strong feature extractor for
generating the segmentation of 3D CT scans, while adaptively aggregating the
cross-modality of text and image representations. We propose a s pecially
designed adapter module to fine-tune pre-trained CLIP with a self-adaptive
learning strategy to effectively fuse the two modalities of embeddings. We
extensively validate our method on a local dataset, which is the largest
pulmonary artery-vein CT dataset to date and consists of 718 labeled data in
total. The experiments show that our method outperformed other state-of-the-art
methods by a large margin. Our data and code will be made publicly available
upon acceptance.

摘要：精確分割肺部結構在臨床診斷、疾病研究和治療計畫中至關重要。基於深度學習的分割技術已取得重大進展，但大多數技術在訓練時需要大量的標記資料。因此，開發精確的分割方法，以減少標記資料集的需求，在醫學影像分析中至關重要。預訓練的視覺語言基礎模型（例如 CLIP）的出現，最近為通用電腦視覺任務開啟了大門。利用這些預訓練基礎模型在分割等下游任務中的泛化能力，即使標記資料量相對較少，也能產生意想不到的效能。然而，探索這些模型在肺動脈靜脈分割中的應用仍然有限。本文提出了一個名為語言引導自適應交叉注意力融合框架的新框架。我們的模型採用預訓練的 CLIP 作為強大的特徵萃取器，用於產生 3D 電腦斷層掃描的分割，同時自適應地聚合文本和影像表徵的跨模態。我們提出了一個特別設計的適配器模組，以自適應學習策略微調預訓練的 CLIP，以有效融合兩種嵌入模態。我們在一個本地資料集上廣泛驗證了我們的模型，這是迄今為止最大的肺動脈靜脈電腦斷層掃描資料集，總共包含 718 個標記資料。實驗表明，我們的模型以大幅優於其他最先進模型。我們的資料和程式碼將在獲得接受後公開。

##### **Can Deep Learning Trigger Alerts from Mobile-Captured Images?**
2501.03499v1 by Pritisha Sarkar, Duranta Durbaar Vishal Saha, Mousumi Saha

Our research presents a comprehensive approach to leveraging mobile camera
image data for real-time air quality assessment and recommendation. We develop
a regression-based Convolutional Neural Network model and tailor it explicitly
for air quality prediction by exploiting the inherent relationship between
output parameters. As a result, the Mean Squared Error of 0.0077 and 0.0112
obtained for 2 and 5 pollutants respectively outperforms existing models.
Furthermore, we aim to verify the common practice of augmenting the original
dataset with a view to introducing more variation in the training phase. It is
one of our most significant contributions that our experimental results
demonstrate minimal accuracy differences between the original and augmented
datasets. Finally, a real-time, user-friendly dashboard is implemented which
dynamically displays the Air Quality Index and pollutant values derived from
captured mobile camera images. Users' health conditions are considered to
recommend whether a location is suitable based on current air quality metrics.
Overall, this research contributes to verification of data augmentation
techniques, CNN-based regression modelling for air quality prediction, and
user-centric air quality monitoring through mobile technology. The proposed
system offers practical solutions for individuals to make informed
environmental health and well-being decisions.

摘要：我們的研究提出了一種利用行動裝置相機影像資料進行即時空氣品質評估和建議的全面性方法。我們開發了一種基於迴歸的卷積神經網路模型，並透過利用輸出參數之間的內在關係，針對空氣品質預測量身打造。因此，分別針對 2 和 5 種污染物取得的平均平方誤差為 0.0077 和 0.0112，優於現有的模型。此外，我們旨在驗證擴充原始資料集的常見做法，以期在訓練階段引入更多變異。我們的實驗結果顯示原始資料集和擴充資料集之間的準確度差異極小，這是我們最重要的貢獻之一。最後，我們實作了一個即時、使用者友善的儀表板，可動態顯示從擷取的行動裝置相機影像中衍生的空氣品質指數和污染物數值。考量使用者的健康狀況，建議是否根據目前的空氣品質指標選擇適合的地點。整體而言，這項研究有助於驗證資料擴充技術、基於 CNN 的迴歸模型（用於空氣品質預測）以及透過行動技術進行以使用者為中心的空氣品質監控。所提出的系統為個人提供實際的解決方案，以便做出明智的環境健康和福祉決策。

##### **Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**
2501.03458v1 by Xiao Wang, Fuling Wang, Haowen Wang, Bo Jiang, Chuanfu Li, Yaowei Wang, Yonghong Tian, Jin Tang

X-ray image based medical report generation achieves significant progress in
recent years with the help of the large language model, however, these models
have not fully exploited the effective information in visual image regions,
resulting in reports that are linguistically sound but insufficient in
describing key diseases. In this paper, we propose a novel associative
memory-enhanced X-ray report generation model that effectively mimics the
process of professional doctors writing medical reports. It considers both the
mining of global and local visual information and associates historical report
information to better complete the writing of the current report. Specifically,
given an X-ray image, we first utilize a classification model along with its
activation maps to accomplish the mining of visual regions highly associated
with diseases and the learning of disease query tokens. Then, we employ a
visual Hopfield network to establish memory associations for disease-related
tokens, and a report Hopfield network to retrieve report memory information.
This process facilitates the generation of high-quality reports based on a
large language model and achieves state-of-the-art performance on multiple
benchmark datasets, including the IU X-ray, MIMIC-CXR, and Chexpert Plus. The
source code of this work is released on
\url{https://github.com/Event-AHU/Medical_Image_Analysis}.

摘要：近年來，在大型語言模型的幫助下，基於 X 光影像的醫療報告生成取得了顯著進展，然而，這些模型並未充分利用視覺影像區域中的有效資訊，導致報告在語言上雖然流暢，但在描述關鍵疾病方面卻不足。在本文中，我們提出了一個新穎的聯想式記憶增強 X 光報告生成模型，有效地模擬專業醫生撰寫醫療報告的過程。它同時考慮了對全局和局部視覺資訊的挖掘，並聯繫歷史報告資訊，以更好地完成當前報告的撰寫。具體來說，給定一張 X 光影像，我們首先利用分類模型及其激活映射來完成與疾病高度相關的視覺區域的挖掘和疾病查詢令牌的學習。然後，我們採用視覺霍普菲爾德網路來建立與疾病相關的令牌的記憶聯繫，並採用報告霍普菲爾德網路來檢索報告記憶資訊。這個過程有助於基於大型語言模型生成高品質的報告，並在包括 IU X 射線、MIMIC-CXR 和 Chexpert Plus 在內的多個基準資料集上實現了最先進的效能。此項工作的原始碼已發佈在\url{https://github.com/Event-AHU/Medical_Image_Analysis}。

##### **Existential Crisis: A Social Robot's Reason for Being**
2501.03376v1 by Dora Medgyesy, Joella Galas, Julian van Pol, Rustam Eynaliyev, Thijs Vollebregt

As Robots become ever more important in our daily lives there's growing need
for understanding how they're perceived by people. This study aims to
investigate how the user perception of robots is influenced by displays of
personality. Using LLMs and speech to text technology, we designed a
within-subject study to compare two conditions: a personality-driven robot and
a purely task-oriented, personality-neutral robot. Twelve participants,
recruited from Socially Intelligent Robotics course at Vrije Universiteit
Amsterdam, interacted with a robot Nao tasked with asking them a set of medical
questions under both conditions. After completing both interactions, the
participants completed a user experience questionnaire measuring their
emotional states and robot perception using standardized questionnaires from
the SRI and Psychology literature.

摘要：隨著機器人在我們日常生活中的重要性日益提升，對於了解人們如何感知機器人的需求也日益增加。本研究旨在探討機器人的使用者感知如何受到人格表現的影響。我們使用大型語言模型 (LLM) 和語音轉文字技術，設計了一項受試者內研究，以比較兩種情況：一種是人格驅動的機器人，另一種是純粹以任務為導向、人格中立的機器人。我們從阿姆斯特丹自由大學的社交智能機器人課程中招募了 12 名參與者，他們與機器人 Nao 互動，在兩種情況下都向他們詢問一系列醫療問題。在完成這兩種互動後，參與者完成了一份使用者體驗問卷，使用來自 SRI 和心理學文獻的標準化問卷測量他們的情緒狀態和機器人感知。

##### **Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**
2501.02922v1 by Susu Sun, Leslie Tessier, Frédérique Meeuwsen, Clément Grisi, Dominique van Midden, Geert Litjens, Christian F. Baumgartner

Multiple Instance Learning (MIL) methods allow for gigapixel Whole-Slide
Image (WSI) analysis with only slide-level annotations. Interpretability is
crucial for safely deploying such algorithms in high-stakes medical domains.
Traditional MIL methods offer explanations by highlighting salient regions.
However, such spatial heatmaps provide limited insights for end users. To
address this, we propose a novel inherently interpretable WSI-classification
approach that uses human-understandable pathology concepts to generate
explanations. Our proposed Concept MIL model leverages recent advances in
vision-language models to directly predict pathology concepts based on image
features. The model's predictions are obtained through a linear combination of
the concepts identified on the top-K patches of a WSI, enabling inherent
explanations by tracing each concept's influence on the prediction. In contrast
to traditional concept-based interpretable models, our approach eliminates the
need for costly human annotations by leveraging the vision-language model. We
validate our method on two widely used pathology datasets: Camelyon16 and
PANDA. On both datasets, Concept MIL achieves AUC and accuracy scores over 0.9,
putting it on par with state-of-the-art models. We further find that 87.1\%
(Camelyon16) and 85.3\% (PANDA) of the top 20 patches fall within the tumor
region. A user study shows that the concepts identified by our model align with
the concepts used by pathologists, making it a promising strategy for
human-interpretable WSI classification.

摘要：多實例學習 (MIL) 方法僅使用玻片層級註解，即可進行吉像素全玻片影像 (WSI) 分析。可解釋性對於在高風險醫療領域安全部署此類演算法至關重要。傳統的 MIL 方法透過強調顯著區域來提供說明。然而，此類空間熱圖為最終使用者提供的見解有限。為了解決此問題，我們提出了一種新穎且本質上可解釋的 WSI 分類方法，該方法使用人類可理解的病理概念來產生說明。我們提出的概念 MIL 模型利用視覺語言模型的最新進展，根據影像特徵直接預測病理概念。該模型的預測是透過線性組合 WSI 頂部 K 個區塊上識別的概念而獲得的，透過追蹤每個概念對預測的影響，可以提供內在說明。與傳統基於概念的可解釋模型相比，我們的做法透過利用視覺語言模型，消除了對昂貴的人工註解的需求。我們在兩個廣泛使用的病理資料集：Camelyon16 和 PANDA 上驗證了我們的模型。在兩個資料集上，概念 MIL 的 AUC 和準確率都超過 0.9，與最先進的模型不相上下。我們進一步發現，前 20 個區塊中有 87.1%（Camelyon16）和 85.3%（PANDA）落在腫瘤區域內。一項使用者研究表明，我們的模型識別的概念與病理學家使用的概念一致，使其成為人類可解釋 WSI 分類的一種有前途的策略。

