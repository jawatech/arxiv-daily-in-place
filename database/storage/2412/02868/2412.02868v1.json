{"2412.02868": {"publish_time": "2024-12-03", "title": "A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications", "paper_summary": "Large Language Models (LLMs) have shown impressive capabilities in natural\nlanguage processing, yet their use in sensitive domains like healthcare,\nparticularly with Electronic Health Records (EHR), faces significant challenges\ndue to privacy concerns and limited computational resources. This paper\npresents a compact LLM framework designed for local deployment in settings with\nstrict privacy requirements and limited access to high-performance GPUs. We\nintroduce a novel preprocessing technique that uses information extraction\nmethods, e.g., regular expressions, to filter and emphasize critical\ninformation in clinical notes, enhancing the performance of smaller LLMs on EHR\ndata. Our framework is evaluated using zero-shot and few-shot learning\nparadigms on both private and publicly available (MIMIC-IV) datasets, and we\nalso compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The\nresults demonstrate that our preprocessing approach significantly boosts the\nprediction accuracy of smaller LLMs, making them suitable for high-privacy,\nresource-constrained applications. This study offers valuable insights into\noptimizing LLM performance for sensitive, data-intensive tasks while addressing\ncomputational and privacy limitations.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u65b9\u9762\u5c55\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u7136\u800c\u5b83\u5011\u5728\u91ab\u7642\u4fdd\u5065\u7b49\u654f\u611f\u9818\u57df\u7684\u4f7f\u7528\uff0c\u7279\u5225\u662f\u96fb\u5b50\u5065\u5eb7\u7d00\u9304 (EHR)\uff0c\u7531\u65bc\u96b1\u79c1\u554f\u984c\u548c\u6709\u9650\u7684\u904b\u7b97\u8cc7\u6e90\u800c\u9762\u81e8\u91cd\u5927\u6311\u6230\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u7dca\u6e4a\u7684 LLM \u6846\u67b6\uff0c\u65e8\u5728\u5728\u5177\u6709\u56b4\u683c\u96b1\u79c1\u8981\u6c42\u548c\u6709\u9650\u4f7f\u7528\u9ad8\u6027\u80fd GPU \u7684\u74b0\u5883\u4e2d\u9032\u884c\u672c\u5730\u90e8\u7f72\u3002\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u9810\u8655\u7406\u6280\u8853\uff0c\u5b83\u4f7f\u7528\u8cc7\u8a0a\u8403\u53d6\u65b9\u6cd5\uff0c\u4f8b\u5982\u6b63\u898f\u8868\u793a\u6cd5\uff0c\u4f86\u904e\u6ffe\u548c\u5f37\u8abf\u81e8\u5e8a\u7b46\u8a18\u4e2d\u7684\u95dc\u9375\u8cc7\u8a0a\uff0c\u589e\u5f37\u8f03\u5c0f LLM \u5728 EHR \u8cc7\u6599\u4e0a\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u6846\u67b6\u4f7f\u7528\u96f6\u6b21\u5b78\u7fd2\u548c\u5c11\u6b21\u5b78\u7fd2\u7bc4\u4f8b\u5728\u79c1\u4eba\u548c\u516c\u958b\u53ef\u7528\u7684 (MIMIC-IV) \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u8a55\u4f30\uff0c\u6211\u5011\u4e5f\u6bd4\u8f03\u5b83\u5728 MIMIC-IV \u8cc7\u6599\u96c6\u4e0a\u8207\u5fae\u8abf LLM \u7684\u6548\u80fd\u3002\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u9810\u8655\u7406\u65b9\u6cd5\u986f\u8457\u63d0\u5347\u4e86\u8f03\u5c0f LLM \u7684\u9810\u6e2c\u6e96\u78ba\u5ea6\uff0c\u4f7f\u5176\u9069\u7528\u65bc\u9ad8\u5ea6\u96b1\u79c1\u3001\u8cc7\u6e90\u53d7\u9650\u7684\u61c9\u7528\u7a0b\u5f0f\u3002\u9019\u9805\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf6\u8cb4\u7684\u898b\u89e3\uff0c\u7528\u65bc\u6700\u4f73\u5316 LLM \u6548\u80fd\u4ee5\u61c9\u5c0d\u654f\u611f\u3001\u8cc7\u6599\u5bc6\u96c6\u578b\u4efb\u52d9\uff0c\u540c\u6642\u89e3\u6c7a\u904b\u7b97\u548c\u96b1\u79c1\u9650\u5236\u3002", "author": "Yixiang Qu et.al.", "authors": "Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu", "id": "2412.02868v1", "paper_url": "http://arxiv.org/abs/2412.02868v1", "repo": "null"}}