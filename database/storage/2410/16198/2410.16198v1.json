{"2410.16198": {"publish_time": "2024-10-21", "title": "Improve Vision Language Model Chain-of-thought Reasoning", "paper_summary": "Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial\nfor improving interpretability and trustworthiness. However, current training\nrecipes lack robust CoT reasoning data, relying on datasets dominated by short\nannotations with minimal rationales. In this work, we show that training VLM on\nshort answers does not generalize well to reasoning tasks that require more\ndetailed responses. To address this, we propose a two-fold approach. First, we\ndistill rationales from GPT-4o model to enrich the training data and fine-tune\nVLMs, boosting their CoT performance. Second, we apply reinforcement learning\nto further calibrate reasoning quality. Specifically, we construct positive\n(correct) and negative (incorrect) pairs of model-generated reasoning chains,\nby comparing their predictions with annotated short answers. Using this\npairwise data, we apply the Direct Preference Optimization algorithm to refine\nthe model's reasoning abilities. Our experiments demonstrate significant\nimprovements in CoT reasoning on benchmark datasets and better generalization\nto direct answer prediction as well. This work emphasizes the importance of\nincorporating detailed rationales in training and leveraging reinforcement\nlearning to strengthen the reasoning capabilities of VLMs.", "paper_summary_zh": "\u5728\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u4e2d\uff0c\u601d\u60f3\u93c8 (CoT) \u63a8\u7406\u5c0d\u65bc\u63d0\u5347\u53ef\u89e3\u91cb\u6027\u548c\u53ef\u4fe1\u5ea6\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u8a13\u7df4\u7bc4\u4f8b\u7f3a\u4e4f\u7a69\u5065\u7684 CoT \u63a8\u7406\u8cc7\u6599\uff0c\u4f9d\u8cf4\u65bc\u7531\u7c21\u77ed\u8a3b\u89e3\uff08\u63d0\u4f9b\u6700\u5c11\u7406\u7531\uff09\u6240\u4e3b\u5c0e\u7684\u8cc7\u6599\u96c6\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u5728\u7c21\u77ed\u7b54\u6848\u4e0a\u8a13\u7df4 VLM \u7121\u6cd5\u5ee3\u6cdb\u61c9\u7528\u65bc\u9700\u8981\u66f4\u8a73\u7d30\u56de\u61c9\u7684\u63a8\u7406\u4efb\u52d9\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u96d9\u7ba1\u9f4a\u4e0b\u7684\u65b9\u6cd5\u3002\u9996\u5148\uff0c\u6211\u5011\u5f9e GPT-4o \u6a21\u578b\u4e2d\u8403\u53d6\u51fa\u7406\u7531\uff0c\u4ee5\u8c50\u5bcc\u8a13\u7df4\u8cc7\u6599\u4e26\u5fae\u8abf VLM\uff0c\u63d0\u5347\u5176 CoT \u6548\u80fd\u3002\u5176\u6b21\uff0c\u6211\u5011\u904b\u7528\u5f37\u5316\u5b78\u7fd2\u9032\u4e00\u6b65\u6821\u6e96\u63a8\u7406\u54c1\u8cea\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u900f\u904e\u6bd4\u8f03\u6a21\u578b\u7522\u751f\u7684\u63a8\u7406\u93c8\u8207\u8a3b\u89e3\u7684\u7c21\u77ed\u7b54\u6848\uff0c\u5efa\u69cb\u6b63\u5411\uff08\u6b63\u78ba\uff09\u548c\u8ca0\u5411\uff08\u4e0d\u6b63\u78ba\uff09\u7684\u6210\u5c0d\u8cc7\u6599\u3002\u4f7f\u7528\u6b64\u6210\u5c0d\u8cc7\u6599\uff0c\u6211\u5011\u904b\u7528\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316\u6f14\u7b97\u6cd5\u4f86\u6539\u5584\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u5728\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u7684 CoT \u63a8\u7406\u6709\u986f\u8457\u7684\u9032\u6b65\uff0c\u4e26\u4e14\u5728\u76f4\u63a5\u7b54\u6848\u9810\u6e2c\u4e0a\u4e5f\u6709\u66f4\u597d\u7684\u5ee3\u6cdb\u6027\u3002\u9019\u9805\u5de5\u4f5c\u5f37\u8abf\u4e86\u5728\u8a13\u7df4\u4e2d\u7d0d\u5165\u8a73\u7d30\u7406\u7531\uff0c\u4e26\u5229\u7528\u5f37\u5316\u5b78\u7fd2\u4f86\u5f37\u5316 VLM \u63a8\u7406\u80fd\u529b\u7684\u91cd\u8981\u6027\u3002", "author": "Ruohong Zhang et.al.", "authors": "Ruohong Zhang, Bowen Zhang, Yanghao Li, Haotian Zhang, Zhiqing Sun, Zhe Gan, Yinfei Yang, Ruoming Pang, Yiming Yang", "id": "2410.16198v1", "paper_url": "http://arxiv.org/abs/2410.16198v1", "repo": "null"}}