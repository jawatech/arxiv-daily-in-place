{"2412.10982": {"publish_time": "2024-12-14", "title": "MedG-KRP: Medical Graph Knowledge Representation Probing", "paper_summary": "Large language models (LLMs) have recently emerged as powerful tools, finding\nmany medical applications. LLMs' ability to coalesce vast amounts of\ninformation from many sources to generate a response-a process similar to that\nof a human expert-has led many to see potential in deploying LLMs for clinical\nuse. However, medicine is a setting where accurate reasoning is paramount. Many\nresearchers are questioning the effectiveness of multiple choice question\nanswering (MCQA) benchmarks, frequently used to test LLMs. Researchers and\nclinicians alike must have complete confidence in LLMs' abilities for them to\nbe deployed in a medical setting. To address this need for understanding, we\nintroduce a knowledge graph (KG)-based method to evaluate the biomedical\nreasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts\nin order to better understand how they reason. We test GPT-4, Llama3-70b, and\nPalmyraMed-70b, a specialized medical model. We enlist a panel of medical\nstudents to review a total of 60 LLM-generated graphs and compare these graphs\nto BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human\nreview but worst in our ground truth comparison; vice-versa with PalmyraMed,\nthe medical model. Our work provides a means of visualizing the medical\nreasoning pathways of LLMs so they can be implemented in clinical settings\nsafely and effectively.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8fd1\u671f\u5df2\u6210\u70ba\u5f37\u5927\u7684\u5de5\u5177\uff0c\u5728\u8a31\u591a\u91ab\u7642\u61c9\u7528\u4e2d\u767c\u63ee\u4f5c\u7528\u3002LLM \u80fd\u5920\u5f9e\u8a31\u591a\u4f86\u6e90\u5f59\u6574\u5927\u91cf\u8cc7\u8a0a\u4ee5\u7522\u751f\u56de\u61c9\uff08\u985e\u4f3c\u4eba\u985e\u5c08\u5bb6\u7684\u6d41\u7a0b\uff09\uff0c\u56e0\u6b64\u8a31\u591a\u4eba\u770b\u5230\u5c07 LLM \u90e8\u7f72\u65bc\u81e8\u5e8a\u7528\u9014\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u91ab\u5b78\u662f\u4e00\u500b\u6e96\u78ba\u63a8\u7406\u81f3\u95dc\u91cd\u8981\u7684\u9818\u57df\u3002\u8a31\u591a\u7814\u7a76\u4eba\u54e1\u8cea\u7591\u591a\u91cd\u9078\u64c7\u984c\u7b54\u984c (MCQA) \u8a55\u91cf\u57fa\u6e96\u7684\u6709\u6548\u6027\uff0c\u800c\u9019\u9805\u8a55\u91cf\u57fa\u6e96\u7d93\u5e38\u88ab\u7528\u65bc\u6e2c\u8a66 LLM\u3002\u7814\u7a76\u4eba\u54e1\u548c\u81e8\u5e8a\u91ab\u751f\u90fd\u5fc5\u9808\u5c0d LLM \u7684\u80fd\u529b\u6709\u5b8c\u5168\u7684\u4fe1\u5fc3\uff0c\u624d\u80fd\u5c07\u5176\u90e8\u7f72\u65bc\u91ab\u7642\u5834\u666f\u3002\u70ba\u4e86\u6eff\u8db3\u9019\u7a2e\u7406\u89e3\u9700\u6c42\uff0c\u6211\u5011\u5f15\u9032\u4e00\u500b\u57fa\u65bc\u77e5\u8b58\u5716\u8b5c (KG) \u7684\u65b9\u6cd5\u4f86\u8a55\u4f30 LLM \u7684\u751f\u7269\u91ab\u5b78\u63a8\u7406\u80fd\u529b\u3002\u57fa\u672c\u4e0a\uff0c\u6211\u5011\u7e6a\u88fd LLM \u5982\u4f55\u9023\u7d50\u91ab\u7642\u6982\u5ff5\uff0c\u4ee5\u4fbf\u66f4\u4e86\u89e3\u5b83\u5011\u7684\u63a8\u7406\u65b9\u5f0f\u3002\u6211\u5011\u6e2c\u8a66\u4e86 GPT-4\u3001Llama3-70b \u548c PalmyraMed-70b\uff08\u4e00\u7a2e\u5c08\u696d\u91ab\u7642\u6a21\u578b\uff09\u3002\u6211\u5011\u5fb5\u6c42\u4e00\u7d44\u91ab\u5b78\u751f\u5be9\u67e5\u7e3d\u5171 60 \u500b LLM \u751f\u6210\u7684\u5716\u8868\uff0c\u4e26\u5c07\u9019\u4e9b\u5716\u8868\u8207 BIOS\uff08\u4e00\u500b\u5927\u578b\u751f\u7269\u91ab\u5b78 KG\uff09\u9032\u884c\u6bd4\u8f03\u3002\u6211\u5011\u89c0\u5bdf\u5230 GPT-4 \u5728\u6211\u5011\u7684\u4eba\u985e\u5be9\u67e5\u4e2d\u8868\u73fe\u6700\u4f73\uff0c\u4f46\u5728\u6211\u5011\u7684\u5730\u9762\u5be6\u6cc1\u6bd4\u8f03\u4e2d\u8868\u73fe\u6700\u5dee\uff1b\u800c\u91ab\u7642\u6a21\u578b PalmyraMed \u5247\u76f8\u53cd\u3002\u6211\u5011\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u7a2e\u53ef\u8996\u5316 LLM \u91ab\u7642\u63a8\u7406\u8def\u5f91\u7684\u65b9\u6cd5\uff0c\u4ee5\u4fbf\u5b83\u5011\u80fd\u5b89\u5168\u6709\u6548\u5730\u5be6\u4f5c\u65bc\u81e8\u5e8a\u5834\u666f\u3002", "author": "Gabriel R. Rosenbaum et.al.", "authors": "Gabriel R. Rosenbaum, Lavender Yao Jiang, Ivaxi Sheth, Jaden Stryker, Anton Alyakin, Daniel Alexander Alber, Nicolas K. Goff, Young Joon, Kwon, John Markert, Mustafa Nasir-Moin, Jan Moritz Niehues, Karl L. Sangwon, Eunice Yang, Eric Karl Oermann", "id": "2412.10982v1", "paper_url": "http://arxiv.org/abs/2412.10982v1", "repo": "null"}}