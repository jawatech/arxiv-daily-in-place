{"2212.08821": {"publish_time": "2022-12-17", "title": "Context-dependent Explainability and Contestability for Trustworthy Medical Artificial Intelligence: Misclassification Identification of Morbidity Recognition Models in Preterm Infants", "paper_summary": "Although machine learning (ML) models of AI achieve high performances in\nmedicine, they are not free of errors. Empowering clinicians to identify\nincorrect model recommendations is crucial for engendering trust in medical AI.\nExplainable AI (XAI) aims to address this requirement by clarifying AI\nreasoning to support the end users. Several studies on biomedical imaging\nachieved promising results recently. Nevertheless, solutions for models using\ntabular data are not sufficient to meet the requirements of clinicians yet.\nThis paper proposes a methodology to support clinicians in identifying failures\nof ML models trained with tabular data. We built our methodology on three main\npillars: decomposing the feature set by leveraging clinical context latent\nspace, assessing the clinical association of global explanations, and Latent\nSpace Similarity (LSS) based local explanations. We demonstrated our\nmethodology on ML-based recognition of preterm infant morbidities caused by\ninfection. The risk of mortality, lifelong disability, and antibiotic\nresistance due to model failures was an open research question in this domain.\nWe achieved to identify misclassification cases of two models with our\napproach. By contextualizing local explanations, our solution provides\nclinicians with actionable insights to support their autonomy for informed\nfinal decisions.", "paper_summary_zh": "", "author": "Isil Guzey et.al.", "authors": "Isil Guzey,Ozlem Ucar,Nukhet Aladag Ciftdemir,Betul Acunas", "id": "2212.08821v1", "paper_url": "http://arxiv.org/abs/2212.08821v1", "repo": "null"}}