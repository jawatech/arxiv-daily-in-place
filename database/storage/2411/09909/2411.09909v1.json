{"2411.09909": {"publish_time": "2024-11-15", "title": "AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference", "paper_summary": "Scaling Large Language Models (LLMs) with extended context lengths has\nincreased the need for efficient low-bit quantization to manage their\nsubstantial computational demands. However, reducing precision to 4 bits\nfrequently degrades performance due to activation outliers. To address this, we\npropose Asymmetric Microscaling 4-bit Floating-Point (AMXFP4) for efficient LLM\ninference. This novel data format leverages asymmetric shared scales to\nmitigate outliers while naturally capturing the asymmetry introduced by\ngroup-wise quantization. Unlike conventional 4-bit quantization methods that\nrely on data rotation and costly calibration, AMXFP4 uses asymmetric shared\nscales for direct 4-bit casting, achieving near-ideal quantization accuracy\nacross various LLM tasks, including multi-turn conversations, long-context\nreasoning, and visual question answering. Our AMXFP4 format significantly\noutperforms MXFP4 and other leading quantization techniques, enabling robust,\ncalibration-free 4-bit inference.", "paper_summary_zh": "\u64f4\u5c55\u4e0a\u4e0b\u6587\u9577\u5ea6\u7684\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u64f4\u5c55\uff0c\u589e\u52a0\u4e86\u5c0d\u6709\u6548\u4f4e\u4f4d\u5143\u91cf\u5316\u7ba1\u7406\u5176\u5927\u91cf\u904b\u7b97\u9700\u6c42\u7684\u9700\u6c42\u3002\u7136\u800c\uff0c\u5c07\u7cbe\u5ea6\u964d\u4f4e\u5230 4 \u4f4d\u5143\u7d93\u5e38\u6703\u56e0\u70ba\u555f\u52d5\u503c\u7570\u5e38\u503c\u800c\u964d\u4f4e\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u975e\u5c0d\u7a31\u5fae\u7e2e 4 \u4f4d\u5143\u6d6e\u9ede\u6578 (AMXFP4) \u4ee5\u9032\u884c\u6709\u6548\u7684 LLM \u63a8\u8ad6\u3002\u9019\u7a2e\u65b0\u7a4e\u7684\u8cc7\u6599\u683c\u5f0f\u5229\u7528\u975e\u5c0d\u7a31\u5171\u4eab\u6bd4\u4f8b\u4f86\u6e1b\u8f15\u7570\u5e38\u503c\uff0c\u540c\u6642\u81ea\u7136\u6355\u6349\u7fa4\u7d44\u91cf\u5316\u5f15\u5165\u7684\u975e\u5c0d\u7a31\u6027\u3002\u8207\u4f9d\u8cf4\u8cc7\u6599\u65cb\u8f49\u548c\u6602\u8cb4\u6821\u6e96\u7684\u50b3\u7d71 4 \u4f4d\u5143\u91cf\u5316\u65b9\u6cd5\u4e0d\u540c\uff0cAMXFP4 \u4f7f\u7528\u975e\u5c0d\u7a31\u5171\u4eab\u6bd4\u4f8b\u9032\u884c\u76f4\u63a5 4 \u4f4d\u5143\u8f49\u63db\uff0c\u5728\u5404\u7a2e LLM \u4efb\u52d9\u4e2d\u5be6\u73fe\u63a5\u8fd1\u7406\u60f3\u7684\u91cf\u5316\u7cbe\u5ea6\uff0c\u5305\u62ec\u591a\u8f2a\u5c0d\u8a71\u3001\u9577\u8108\u7d61\u63a8\u7406\u548c\u8996\u89ba\u554f\u7b54\u3002\u6211\u5011\u7684 AMXFP4 \u683c\u5f0f\u660e\u986f\u512a\u65bc MXFP4 \u548c\u5176\u4ed6\u9818\u5148\u7684\u91cf\u5316\u6280\u8853\uff0c\u5be6\u73fe\u5f37\u5065\u3001\u7121\u9700\u6821\u6e96\u7684 4 \u4f4d\u5143\u63a8\u8ad6\u3002", "author": "Janghwan Lee et.al.", "authors": "Janghwan Lee, Jiwoong Park, Jinseok Kim, Yongjik Kim, Jungju Oh, Jinwook Oh, Jungwook Choi", "id": "2411.09909v1", "paper_url": "http://arxiv.org/abs/2411.09909v1", "repo": "null"}}