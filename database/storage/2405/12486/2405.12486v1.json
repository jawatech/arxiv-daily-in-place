{"2405.12486": {"publish_time": "2024-05-21", "title": "Time Matters: Enhancing Pre-trained News Recommendation Models with Robust User Dwell Time Injection", "paper_summary": "Large Language Models (LLMs) have revolutionized text comprehension, leading\nto State-of-the-Art (SOTA) news recommendation models that utilize LLMs for\nin-depth news understanding. Despite this, accurately modeling user preferences\nremains challenging due to the inherent uncertainty of click behaviors.\nTechniques like multi-head attention in Transformers seek to alleviate this by\ncapturing interactions among clicks, yet they fall short in integrating\nexplicit feedback signals. User Dwell Time emerges as a powerful indicator,\noffering the potential to enhance the weak signals emanating from clicks.\nNonetheless, its real-world applicability is questionable, especially when\ndwell time data collection is subject to delays. To bridge this gap, this paper\nproposes two novel and robust dwell time injection strategies, namely Dwell\ntime Weight (DweW) and Dwell time Aware (DweA). Dwe} concentrates on refining\nEffective User Clicks through detailed analysis of dwell time, integrating with\ninitial behavioral inputs to construct a more robust user preference. DweA\nempowers the model with awareness of dwell time information, thereby\nfacilitating autonomous adjustment of attention values in user modeling. This\nenhancement sharpens the model's ability to accurately identify user\npreferences. In our experiment using the real-world news dataset from MSN\nwebsite, we validated that our two strategies significantly improve\nrecommendation performance, favoring high-quality news. Crucially, our\napproaches exhibit robustness to user dwell time information, maintaining their\nability to recommend high-quality content even in extreme cases where dwell\ntime data is entirely missing.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5fb9\u5e95\u6539\u8b8a\u6587\u5b57\u7406\u89e3\uff0c\u9032\u800c\u7522\u751f\u5229\u7528 LLM \u6df1\u5165\u7406\u89e3\u65b0\u805e\u7684\u6700\u65b0\u63a8\u85a6\u6a21\u578b\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u7531\u65bc\u9ede\u64ca\u884c\u70ba\u7684\u5167\u5728\u4e0d\u78ba\u5b9a\u6027\uff0c\u7cbe\u78ba\u5efa\u6a21\u4f7f\u7528\u8005\u504f\u597d\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002Transformer\u4e2d\u7684\u591a\u982d\u6ce8\u610f\u529b\u7b49\u6280\u8853\u8a66\u5716\u900f\u904e\u6355\u6349\u9ede\u64ca\u4e4b\u9593\u7684\u4e92\u52d5\u4f86\u6e1b\u8f15\u9019\u7a2e\u60c5\u6cc1\uff0c\u4f46\u5b83\u5011\u5728\u6574\u5408\u660e\u78ba\u7684\u56de\u994b\u8a0a\u865f\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002\u4f7f\u7528\u8005\u505c\u7559\u6642\u9593\u6210\u70ba\u4e00\u500b\u5f37\u6709\u529b\u7684\u6307\u6a19\uff0c\u63d0\u4f9b\u589e\u5f37\u4f86\u81ea\u9ede\u64ca\u7684\u5f31\u8a0a\u865f\u7684\u6f5b\u529b\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u5b83\u7684\u5be6\u969b\u61c9\u7528\u6027\u4ecd\u6709\u7591\u554f\uff0c\u7279\u5225\u662f\u5728\u505c\u7559\u6642\u9593\u8cc7\u6599\u6536\u96c6\u6703\u5ef6\u9072\u6642\u3002\u70ba\u4e86\u5f4c\u88dc\u9019\u500b\u5dee\u8ddd\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u5169\u7a2e\u65b0\u7a4e\u4e14\u5f37\u5927\u7684\u505c\u7559\u6642\u9593\u6ce8\u5165\u7b56\u7565\uff0c\u5373\u505c\u7559\u6642\u9593\u52a0\u6b0a (DweW) \u548c\u505c\u7559\u6642\u9593\u611f\u77e5 (DweA)\u3002Dwe} \u5c08\u6ce8\u65bc\u900f\u904e\u8a73\u7d30\u5206\u6790\u505c\u7559\u6642\u9593\u4f86\u7cbe\u7149\u6709\u6548\u7684\u4f7f\u7528\u8005\u9ede\u64ca\uff0c\u4e26\u8207\u521d\u59cb\u884c\u70ba\u8f38\u5165\u6574\u5408\uff0c\u4ee5\u5efa\u69cb\u66f4\u5f37\u5927\u7684\u4f7f\u7528\u8005\u504f\u597d\u3002DweA \u8b93\u6a21\u578b\u5177\u5099\u505c\u7559\u6642\u9593\u8cc7\u8a0a\u7684\u611f\u77e5\uff0c\u5f9e\u800c\u4fc3\u9032\u4f7f\u7528\u8005\u5efa\u6a21\u4e2d\u6ce8\u610f\u529b\u503c\u7684\u81ea\u4e3b\u8abf\u6574\u3002\u9019\u7a2e\u589e\u5f37\u4f7f\u6a21\u578b\u66f4\u7cbe\u6e96\u5730\u8b58\u5225\u4f7f\u7528\u8005\u504f\u597d\u7684\u80fd\u529b\u66f4\u70ba\u654f\u92b3\u3002\u5728\u6211\u5011\u4f7f\u7528\u4f86\u81ea MSN \u7db2\u7ad9\u7684\u771f\u5be6\u4e16\u754c\u65b0\u805e\u8cc7\u6599\u96c6\u9032\u884c\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u9a57\u8b49\u4e86\u6211\u5011\u7684\u5169\u7a2e\u7b56\u7565\u986f\u8457\u6539\u5584\u4e86\u63a8\u85a6\u6548\u80fd\uff0c\u504f\u597d\u9ad8\u54c1\u8cea\u7684\u65b0\u805e\u3002\u81f3\u95dc\u91cd\u8981\u7684\u662f\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5c55\u73fe\u51fa\u5c0d\u4f7f\u7528\u8005\u505c\u7559\u6642\u9593\u8cc7\u8a0a\u7684\u7a69\u5065\u6027\uff0c\u5373\u4f7f\u5728\u505c\u7559\u6642\u9593\u8cc7\u6599\u5b8c\u5168\u907a\u5931\u7684\u6975\u7aef\u60c5\u6cc1\u4e0b\uff0c\u5b83\u5011\u4ecd\u80fd\u63a8\u85a6\u9ad8\u54c1\u8cea\u7684\u5167\u5bb9\u3002", "author": "Hao Jiang et.al.", "authors": "Hao Jiang, Chuanzhen Li, Mingxiao An", "id": "2405.12486v1", "paper_url": "http://arxiv.org/abs/2405.12486v1", "repo": "null"}}