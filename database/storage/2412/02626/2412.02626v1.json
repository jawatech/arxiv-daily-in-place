{"2412.02626": {"publish_time": "2024-12-03", "title": "Time-Reversal Provides Unsupervised Feedback to LLMs", "paper_summary": "Large Language Models (LLMs) are typically trained to predict in the forward\ndirection of time. However, recent works have shown that prompting these models\nto look back and critique their own generations can produce useful feedback.\nMotivated by this, we explore the question of whether LLMs can be empowered to\nthink (predict and score) backwards to provide unsupervised feedback that\ncomplements forward LLMs. Towards this, we introduce Time Reversed Language\nModels (TRLMs), which can score and generate queries when conditioned on\nresponses, effectively functioning in the reverse direction of time. Further,\nto effectively infer in the response to query direction, we pre-train and\nfine-tune a language model (TRLM-Ba) in the reverse token order from scratch.\nWe show empirically (and theoretically in a stylized setting) that\ntime-reversed models can indeed complement forward model predictions when used\nto score the query given response for re-ranking multiple forward generations.\nWe obtain up to 5\\% improvement on the widely used AlpacaEval Leaderboard over\nthe competent baseline of best-of-N re-ranking using self log-perplexity\nscores. We further show that TRLM scoring outperforms conventional forward\nscoring of response given query, resulting in significant gains in applications\nsuch as citation generation and passage retrieval. We next leverage the\ngenerative ability of TRLM to augment or provide unsupervised feedback to input\nsafety filters of LLMs, demonstrating a drastic reduction in false negative\nrate with negligible impact on false positive rates against several attacks\npublished on the popular JailbreakBench leaderboard.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u901a\u5e38\u6703\u63a5\u53d7\u8a13\u7df4\u4ee5\u9810\u6e2c\u6642\u9593\u7684\u6b63\u5411\u65b9\u5411\u3002\u7136\u800c\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u63d0\u793a\u9019\u4e9b\u6a21\u578b\u56de\u9867\u4e26\u6279\u8a55\u5b83\u5011\u81ea\u5df1\u7684\u4e16\u4ee3\u53ef\u4ee5\u7522\u751f\u6709\u7528\u7684\u56de\u994b\u3002\u53d7\u6b64\u555f\u767c\uff0c\u6211\u5011\u63a2\u8a0e\u4e86 LLM \u80fd\u5426\u88ab\u8ce6\u4e88\u5411\u5f8c\u601d\u8003\uff08\u9810\u6e2c\u548c\u8a55\u5206\uff09\u7684\u80fd\u529b\uff0c\u4ee5\u63d0\u4f9b\u88dc\u5145\u6b63\u5411 LLM \u7684\u7121\u76e3\u7763\u56de\u994b\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86\u6642\u9593\u53cd\u5411\u8a9e\u8a00\u6a21\u578b\uff08TRLM\uff09\uff0c\u5b83\u53ef\u4ee5\u5728\u56de\u61c9\u7684\u689d\u4ef6\u4e0b\u8a55\u5206\u548c\u7522\u751f\u67e5\u8a62\uff0c\u6709\u6548\u5730\u904b\u4f5c\u65bc\u6642\u9593\u7684\u53cd\u5411\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u6709\u6548\u5730\u63a8\u8ad6\u5c0d\u67e5\u8a62\u65b9\u5411\u7684\u56de\u61c9\uff0c\u6211\u5011\u5f9e\u982d\u958b\u59cb\u4ee5\u53cd\u5411\u7b26\u865f\u9806\u5e8f\u9810\u5148\u8a13\u7df4\u548c\u5fae\u8abf\u8a9e\u8a00\u6a21\u578b\uff08TRLM-Ba\uff09\u3002\u6211\u5011\u900f\u904e\u7d93\u9a57\uff08\u4ee5\u53ca\u5728\u6a23\u5f0f\u5316\u8a2d\u5b9a\u4e2d\u7684\u7406\u8ad6\uff09\u8868\u660e\uff0c\u6642\u9593\u53cd\u5411\u6a21\u578b\u78ba\u5be6\u53ef\u4ee5\u5728\u7528\u65bc\u8a55\u5206\u67e5\u8a62\u7d66\u5b9a\u7684\u56de\u61c9\u4ee5\u91cd\u65b0\u6392\u5217\u591a\u500b\u6b63\u5411\u751f\u6210\u6642\uff0c\u88dc\u5145\u6b63\u5411\u6a21\u578b\u9810\u6e2c\u3002\u6211\u5011\u5728\u5ee3\u6cdb\u4f7f\u7528\u7684 AlpacaEval \u6392\u884c\u699c\u4e0a\u7372\u5f97\u4e86\u9ad8\u9054 5% \u7684\u6539\u9032\uff0c\u512a\u65bc\u4f7f\u7528\u81ea\u6211\u5c0d\u6578\u56f0\u60d1\u5ea6\u8a55\u5206\u7684\u6700\u4f73 N \u6b21\u91cd\u65b0\u6392\u5217\u7684\u57fa\u6e96\u3002\u6211\u5011\u9032\u4e00\u6b65\u8868\u660e\uff0cTRLM \u8a55\u5206\u512a\u65bc\u5c0d\u7d66\u5b9a\u67e5\u8a62\u7684\u50b3\u7d71\u6b63\u5411\u8a55\u5206\uff0c\u5f9e\u800c\u986f\u8457\u63d0\u5347\u4e86\u5f15\u7528\u751f\u6210\u548c\u6bb5\u843d\u6aa2\u7d22\u7b49\u61c9\u7528\u3002\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u5229\u7528 TRLM \u7684\u751f\u6210\u80fd\u529b\u4f86\u64f4\u5145\u6216\u63d0\u4f9b\u7121\u76e3\u7763\u56de\u994b\u7d66 LLM \u7684\u8f38\u5165\u5b89\u5168\u904e\u6ffe\u5668\uff0c\u8b49\u660e\u5728\u91dd\u5c0d\u6d41\u884c\u7684 JailbreakBench \u6392\u884c\u699c\u4e0a\u767c\u5e03\u7684\u5e7e\u6b21\u653b\u64ca\u4e2d\uff0c\u5047\u9670\u6027\u7387\u5927\u5e45\u964d\u4f4e\uff0c\u800c\u5047\u967d\u6027\u7387\u5e7e\u4e4e\u6c92\u6709\u5f71\u97ff\u3002", "author": "Yerram Varun et.al.", "authors": "Yerram Varun, Rahul Madhavan, Sravanti Addepalli, Arun Suggala, Karthikeyan Shanmugam, Prateek Jain", "id": "2412.02626v1", "paper_url": "http://arxiv.org/abs/2412.02626v1", "repo": "null"}}