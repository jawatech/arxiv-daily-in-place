{"2408.09949": {"publish_time": "2024-08-19", "title": "C${^2}$RL: Content and Context Representation Learning for Gloss-free Sign Language Translation and Retrieval", "paper_summary": "Sign Language Representation Learning (SLRL) is crucial for a range of sign\nlanguage-related downstream tasks such as Sign Language Translation (SLT) and\nSign Language Retrieval (SLRet). Recently, many gloss-based and gloss-free SLRL\nmethods have been proposed, showing promising performance. Among them, the\ngloss-free approach shows promise for strong scalability without relying on\ngloss annotations. However, it currently faces suboptimal solutions due to\nchallenges in encoding the intricate, context-sensitive characteristics of sign\nlanguage videos, mainly struggling to discern essential sign features using a\nnon-monotonic video-text alignment strategy. Therefore, we introduce an\ninnovative pretraining paradigm for gloss-free SLRL, called C${^2}$RL, in this\npaper. Specifically, rather than merely incorporating a non-monotonic semantic\nalignment of video and text to learn language-oriented sign features, we\nemphasize two pivotal aspects of SLRL: Implicit Content Learning (ICL) and\nExplicit Context Learning (ECL). ICL delves into the content of communication,\ncapturing the nuances, emphasis, timing, and rhythm of the signs. In contrast,\nECL focuses on understanding the contextual meaning of signs and converting\nthem into equivalent sentences. Despite its simplicity, extensive experiments\nconfirm that the joint optimization of ICL and ECL results in robust sign\nlanguage representation and significant performance gains in gloss-free SLT and\nSLRet tasks. Notably, C${^2}$RL improves the BLEU-4 score by +5.3 on P14T,\n+10.6 on CSL-daily, +6.2 on OpenASL, and +1.3 on How2Sign. It also boosts the\nR@1 score by +8.3 on P14T, +14.4 on CSL-daily, and +5.9 on How2Sign.\nAdditionally, we set a new baseline for the OpenASL dataset in the SLRet task.", "paper_summary_zh": "\u624b\u8a9e\u8868\u5fb5\u5b78\u7fd2 (SLRL) \u5c0d\u65bc\u4e00\u7cfb\u5217\u624b\u8a9e\u76f8\u95dc\u7684\u4e0b\u6e38\u4efb\u52d9\u81f3\u95dc\u91cd\u8981\uff0c\u4f8b\u5982\u624b\u8a9e\u7ffb\u8b6f (SLT) \u548c\u624b\u8a9e\u6aa2\u7d22 (SLRet)\u3002\u6700\u8fd1\uff0c\u5df2\u7d93\u63d0\u51fa\u4e86\u8a31\u591a\u57fa\u65bc\u624b\u52e2\u548c\u4e0d\u57fa\u65bc\u624b\u52e2\u7684 SLRL \u65b9\u6cd5\uff0c\u8868\u73fe\u51fa\u4ee4\u4eba\u6eff\u610f\u7684\u6548\u80fd\u3002\u5176\u4e2d\uff0c\u4e0d\u57fa\u65bc\u624b\u52e2\u7684\u65b9\u6cd5\u986f\u793a\u51fa\u5f37\u5927\u7684\u53ef\u64f4\u5145\u6027\uff0c\u800c\u4e0d\u4f9d\u8cf4\u624b\u52e2\u8a3b\u89e3\u3002\u7136\u800c\uff0c\u7531\u65bc\u5728\u7de8\u78bc\u624b\u8a9e\u5f71\u7247\u7684\u8907\u96dc\u3001\u5c0d\u60c5\u5883\u654f\u611f\u7684\u7279\u5fb5\u6642\u9047\u5230\u6311\u6230\uff0c\u76ee\u524d\u9762\u81e8\u6b21\u4f73\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4e3b\u8981\u5728\u65bc\u4f7f\u7528\u975e\u55ae\u8abf\u7684\u5f71\u7247\u6587\u5b57\u5c0d\u9f4a\u7b56\u7565\u4f86\u8fa8\u5225\u5fc5\u8981\u7684\u7b26\u865f\u7279\u5fb5\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5728\u672c\u6587\u4e2d\u4ecb\u7d39\u4e86\u4e00\u7a2e\u5275\u65b0\u7684\u7121\u624b\u52e2 SLRL \u9810\u8a13\u7df4\u7bc4\u4f8b\uff0c\u7a31\u70ba C${^2}$RL\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u4e0d\u50c5\u50c5\u5c07\u5f71\u7247\u548c\u6587\u5b57\u7684\u975e\u55ae\u8abf\u8a9e\u7fa9\u5c0d\u9f4a\u6574\u5408\u8d77\u4f86\u4ee5\u5b78\u7fd2\u4ee5\u8a9e\u8a00\u70ba\u5c0e\u5411\u7684\u624b\u52e2\u7279\u5fb5\uff0c\u6211\u5011\u9084\u5f37\u8abf\u4e86 SLRL \u7684\u5169\u500b\u95dc\u9375\u65b9\u9762\uff1a\u96b1\u542b\u5167\u5bb9\u5b78\u7fd2 (ICL) \u548c\u660e\u78ba\u60c5\u5883\u5b78\u7fd2 (ECL)\u3002ICL \u6df1\u5165\u63a2\u8a0e\u6e9d\u901a\u7684\u5167\u5bb9\uff0c\u6355\u6349\u624b\u52e2\u7684\u7d30\u5fae\u5dee\u5225\u3001\u5f37\u8abf\u3001\u6642\u6a5f\u548c\u7bc0\u594f\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0cECL \u5c08\u6ce8\u65bc\u7406\u89e3\u624b\u52e2\u7684\u4e0a\u4e0b\u6587\u542b\u7fa9\uff0c\u4e26\u5c07\u5176\u8f49\u63db\u70ba\u7b49\u6548\u7684\u53e5\u5b50\u3002\u5118\u7ba1\u5176\u7c21\u55ae\u6027\uff0c\u4f46\u5927\u91cf\u7684\u5be6\u9a57\u8b49\u5be6\uff0cICL \u548c ECL \u7684\u806f\u5408\u6700\u4f73\u5316\u6703\u7522\u751f\u5f37\u5065\u7684\u624b\u8a9e\u8868\u5fb5\uff0c\u4e26\u5728\u7121\u624b\u52e2 SLT \u548c SLRet \u4efb\u52d9\u4e2d\u986f\u8457\u63d0\u5347\u6548\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cC${^2}$RL \u5728 P14T \u4e0a\u5c07 BLEU-4 \u5206\u6578\u63d0\u9ad8\u4e86 +5.3\uff0c\u5728 CSL-daily \u4e0a\u63d0\u9ad8\u4e86 +10.6\uff0c\u5728 OpenASL \u4e0a\u63d0\u9ad8\u4e86 +6.2\uff0c\u5728 How2Sign \u4e0a\u63d0\u9ad8\u4e86 +1.3\u3002\u5b83\u9084\u5c07 P14T \u4e0a\u7684 R@1 \u5206\u6578\u63d0\u9ad8\u4e86 +8.3\uff0cCSL-daily \u4e0a\u63d0\u9ad8\u4e86 +14.4\uff0cHow2Sign \u4e0a\u63d0\u9ad8\u4e86 +5.9\u3002\u6b64\u5916\uff0c\u6211\u5011\u5728 SLRet \u4efb\u52d9\u4e2d\u70ba OpenASL \u8cc7\u6599\u96c6\u8a2d\u5b9a\u4e86\u4e00\u500b\u65b0\u7684\u57fa\u6e96\u3002", "author": "Zhigang Chen et.al.", "authors": "Zhigang Chen, Benjia Zhou, Yiqing Huang, Jun Wan, Yibo Hu, Hailin Shi, Yanyan Liang, Zhen Lei, Du Zhang", "id": "2408.09949v1", "paper_url": "http://arxiv.org/abs/2408.09949v1", "repo": "null"}}