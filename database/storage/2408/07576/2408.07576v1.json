{"2408.07576": {"publish_time": "2024-08-14", "title": "MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient Semantic Segmentation", "paper_summary": "Beyond the Transformer, it is important to explore how to exploit the\ncapacity of the MetaFormer, an architecture that is fundamental to the\nperformance improvements of the Transformer. Previous studies have exploited it\nonly for the backbone network. Unlike previous studies, we explore the capacity\nof the Metaformer architecture more extensively in the semantic segmentation\ntask. We propose a powerful semantic segmentation network, MetaSeg, which\nleverages the Metaformer architecture from the backbone to the decoder. Our\nMetaSeg shows that the MetaFormer architecture plays a significant role in\ncapturing the useful contexts for the decoder as well as for the backbone. In\naddition, recent segmentation methods have shown that using a CNN-based\nbackbone for extracting the spatial information and a decoder for extracting\nthe global information is more effective than using a transformer-based\nbackbone with a CNN-based decoder. This motivates us to adopt the CNN-based\nbackbone using the MetaFormer block and design our MetaFormer-based decoder,\nwhich consists of a novel self-attention module to capture the global contexts.\nTo consider both the global contexts extraction and the computational\nefficiency of the self-attention for semantic segmentation, we propose a\nChannel Reduction Attention (CRA) module that reduces the channel dimension of\nthe query and key into the one dimension. In this way, our proposed MetaSeg\noutperforms the previous state-of-the-art methods with more efficient\ncomputational costs on popular semantic segmentation and a medical image\nsegmentation benchmark, including ADE20K, Cityscapes, COCO-stuff, and Synapse.\nThe code is available at \\url{https://github.com/hyunwoo137/MetaSeg}.", "paper_summary_zh": "\u9664\u4e86 Transformer \u4e4b\u5916\uff0c\u63a2\u7d22\u5982\u4f55\u5229\u7528 MetaFormer \u7684\u5bb9\u91cf\u975e\u5e38\u91cd\u8981\uff0cMetaFormer \u662f Transformer \u6027\u80fd\u63d0\u5347\u7684\u57fa\u7840\u67b6\u6784\u3002\u5148\u524d\u7684\u7814\u7a76\u4ec5\u5c06\u5176\u7528\u4e8e\u4e3b\u5e72\u7f51\u7edc\u3002\u4e0e\u5148\u524d\u7684\u7814\u7a76\u4e0d\u540c\uff0c\u6211\u4eec\u5728\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\u66f4\u5e7f\u6cdb\u5730\u63a2\u7d22\u4e86 Metaformer \u67b6\u6784\u7684\u5bb9\u91cf\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u8bed\u4e49\u5206\u5272\u7f51\u7edc MetaSeg\uff0c\u5b83\u5229\u7528\u4e86\u4ece\u4e3b\u5e72\u5230\u89e3\u7801\u5668\u7684 Metaformer \u67b6\u6784\u3002\u6211\u4eec\u7684 MetaSeg \u8868\u660e\uff0cMetaFormer \u67b6\u6784\u5728\u4e3a\u89e3\u7801\u5668\u548c\u4e3b\u5e72\u6355\u83b7\u6709\u7528\u4e0a\u4e0b\u6587\u65b9\u9762\u53d1\u6325\u4e86\u91cd\u8981\u4f5c\u7528\u3002\u6b64\u5916\uff0c\u6700\u8fd1\u7684\u5206\u5272\u65b9\u6cd5\u8868\u660e\uff0c\u4f7f\u7528\u57fa\u4e8e CNN \u7684\u4e3b\u5e72\u6765\u63d0\u53d6\u7a7a\u95f4\u4fe1\u606f\u548c\u4f7f\u7528\u89e3\u7801\u5668\u6765\u63d0\u53d6\u5168\u5c40\u4fe1\u606f\u6bd4\u4f7f\u7528\u57fa\u4e8e Transformer \u7684\u4e3b\u5e72\u548c\u57fa\u4e8e CNN \u7684\u89e3\u7801\u5668\u66f4\u6709\u6548\u3002\u8fd9\u4fc3\u4f7f\u6211\u4eec\u91c7\u7528\u4f7f\u7528 MetaFormer \u5757\u7684\u57fa\u4e8e CNN \u7684\u4e3b\u5e72\u5e76\u8bbe\u8ba1\u6211\u4eec\u57fa\u4e8e MetaFormer \u7684\u89e3\u7801\u5668\uff0c\u8be5\u89e3\u7801\u5668\u5305\u542b\u4e00\u4e2a\u65b0\u9896\u7684\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u6765\u6355\u83b7\u5168\u5c40\u4e0a\u4e0b\u6587\u3002\u4e3a\u4e86\u540c\u65f6\u8003\u8651\u5168\u5c40\u4e0a\u4e0b\u6587\u63d0\u53d6\u548c\u8bed\u4e49\u5206\u5272\u7684\u81ea\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u901a\u9053\u7f29\u51cf\u6ce8\u610f\u529b (CRA) \u6a21\u5757\uff0c\u8be5\u6a21\u5757\u5c06\u67e5\u8be2\u548c\u952e\u7684\u901a\u9053\u7ef4\u5ea6\u7f29\u51cf\u4e3a\u4e00\u4e2a\u7ef4\u5ea6\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u6211\u4eec\u63d0\u51fa\u7684 MetaSeg \u5728\u6d41\u884c\u7684\u8bed\u4e49\u5206\u5272\u548c\u533b\u5b66\u56fe\u50cf\u5206\u5272\u57fa\u51c6\uff08\u5305\u62ec ADE20K\u3001Cityscapes\u3001COCO-stuff \u548c Synapse\uff09\u4e0a\u4ee5\u66f4\u9ad8\u7684\u8ba1\u7b97\u6210\u672c\u8d85\u8d8a\u4e86\u4ee5\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002\u4ee3\u7801\u53ef\u5728 \\url{https://github.com/hyunwoo137/MetaSeg} \u83b7\u5f97\u3002", "author": "Beoungwoo Kang et.al.", "authors": "Beoungwoo Kang, Seunghun Moon, Yubin Cho, Hyunwoo Yu, Suk-Ju Kang", "id": "2408.07576v1", "paper_url": "http://arxiv.org/abs/2408.07576v1", "repo": "https://github.com/hyunwoo137/metaseg"}}