{"2411.15096": {"publish_time": "2024-11-22", "title": "RED: Effective Trajectory Representation Learning with Comprehensive Information", "paper_summary": "Trajectory representation learning (TRL) maps trajectories to vectors that\ncan then be used for various downstream tasks, including trajectory similarity\ncomputation, trajectory classification, and travel-time estimation. However,\nexisting TRL methods often produce vectors that, when used in downstream tasks,\nyield insufficiently accurate results. A key reason is that they fail to\nutilize the comprehensive information encompassed by trajectories. We propose a\nself-supervised TRL framework, called RED, which effectively exploits multiple\ntypes of trajectory information. Overall, RED adopts the Transformer as the\nbackbone model and masks the constituting paths in trajectories to train a\nmasked autoencoder (MAE). In particular, RED considers the moving patterns of\ntrajectories by employing a Road-aware masking strategy} that retains key paths\nof trajectories during masking, thereby preserving crucial information of the\ntrajectories. RED also adopts a spatial-temporal-user joint Embedding scheme to\nencode comprehensive information when preparing the trajectories as model\ninputs. To conduct training, RED adopts Dual-objective task learning}: the\nTransformer encoder predicts the next segment in a trajectory, and the\nTransformer decoder reconstructs the entire trajectory. RED also considers the\nspatial-temporal correlations of trajectories by modifying the attention\nmechanism of the Transformer. We compare RED with 9 state-of-the-art TRL\nmethods for 4 downstream tasks on 3 real-world datasets, finding that RED can\nusually improve the accuracy of the best-performing baseline by over 5%.", "paper_summary_zh": "\u8ecc\u8de1\u8868\u793a\u5b78\u7fd2 (TRL) \u5c07\u8ecc\u8de1\u5c0d\u61c9\u5230\u5411\u91cf\uff0c\u7136\u5f8c\u53ef\u5c07\u9019\u4e9b\u5411\u91cf\u7528\u65bc\u5404\u7a2e\u4e0b\u6e38\u4efb\u52d9\uff0c\u5305\u62ec\u8ecc\u8de1\u76f8\u4f3c\u6027\u904b\u7b97\u3001\u8ecc\u8de1\u5206\u985e\u548c\u65c5\u904a\u6642\u9593\u4f30\u8a08\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 TRL \u65b9\u6cd5\u901a\u5e38\u6703\u7522\u751f\u5411\u91cf\uff0c\u7576\u7528\u65bc\u4e0b\u6e38\u4efb\u52d9\u6642\uff0c\u7522\u751f\u7684\u7d50\u679c\u6e96\u78ba\u5ea6\u4e0d\u8db3\u3002\u4e00\u500b\u95dc\u9375\u539f\u56e0\u662f\u5b83\u5011\u672a\u80fd\u5229\u7528\u8ecc\u8de1\u6240\u5305\u542b\u7684\u7d9c\u5408\u8cc7\u8a0a\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u81ea\u76e3\u7763 TRL \u6846\u67b6\uff0c\u7a31\u70ba RED\uff0c\u5b83\u6709\u6548\u5229\u7528\u591a\u7a2e\u985e\u578b\u7684\u8ecc\u8de1\u8cc7\u8a0a\u3002\u7e3d\u7684\u4f86\u8aaa\uff0cRED \u63a1\u7528 Transformer \u4f5c\u70ba\u4e3b\u5e79\u6a21\u578b\uff0c\u4e26\u906e\u853d\u8ecc\u8de1\u4e2d\u7684\u69cb\u6210\u8def\u5f91\u4f86\u8a13\u7df4\u906e\u853d\u81ea\u52d5\u7de8\u78bc\u5668 (MAE)\u3002\u7279\u5225\u662f\uff0cRED \u900f\u904e\u63a1\u7528\u9053\u8def\u611f\u77e5\u906e\u853d\u7b56\u7565\u4f86\u8003\u616e\u8ecc\u8de1\u7684\u79fb\u52d5\u6a21\u5f0f\uff0c\u8a72\u7b56\u7565\u5728\u906e\u853d\u904e\u7a0b\u4e2d\u4fdd\u7559\u8ecc\u8de1\u7684\u4e3b\u8981\u8def\u5f91\uff0c\u5f9e\u800c\u4fdd\u7559\u8ecc\u8de1\u7684\u95dc\u9375\u8cc7\u8a0a\u3002RED \u9084\u63a1\u7528\u6642\u7a7a\u4f7f\u7528\u8005\u806f\u5408\u5d4c\u5165\u67b6\u69cb\uff0c\u5728\u6e96\u5099\u8ecc\u8de1\u4f5c\u70ba\u6a21\u578b\u8f38\u5165\u6642\u7de8\u78bc\u7d9c\u5408\u8cc7\u8a0a\u3002\u70ba\u4e86\u9032\u884c\u8a13\u7df4\uff0cRED \u63a1\u7528\u96d9\u76ee\u6a19\u4efb\u52d9\u5b78\u7fd2\uff1aTransformer \u7de8\u78bc\u5668\u9810\u6e2c\u8ecc\u8de1\u4e2d\u7684\u4e0b\u4e00\u500b\u5340\u6bb5\uff0c\u800c Transformer \u89e3\u78bc\u5668\u91cd\u5efa\u6574\u500b\u8ecc\u8de1\u3002RED \u9084\u900f\u904e\u4fee\u6539 Transformer \u7684\u6ce8\u610f\u529b\u6a5f\u5236\u4f86\u8003\u616e\u8ecc\u8de1\u7684\u6642\u7a7a\u95dc\u806f\u6027\u3002\u6211\u5011\u5c07 RED \u8207 9 \u7a2e\u6700\u5148\u9032\u7684 TRL \u65b9\u6cd5\u6bd4\u8f03\uff0c\u91dd\u5c0d 3 \u500b\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u7684 4 \u500b\u4e0b\u6e38\u4efb\u52d9\u9032\u884c\u6bd4\u8f03\uff0c\u767c\u73fe RED \u901a\u5e38\u53ef\u4ee5\u5c07\u6548\u80fd\u6700\u4f73\u7684\u57fa\u6e96\u6e96\u78ba\u5ea6\u63d0\u5347\u8d85\u904e 5%\u3002", "author": "Silin Zhou et.al.", "authors": "Silin Zhou, Shuo Shang, Lisi Chen, Christian S. Jensen, Panos Kalnis", "id": "2411.15096v1", "paper_url": "http://arxiv.org/abs/2411.15096v1", "repo": "null"}}