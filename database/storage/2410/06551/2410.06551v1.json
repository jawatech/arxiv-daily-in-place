{"2410.06551": {"publish_time": "2024-10-09", "title": "InstantIR: Blind Image Restoration with Instant Generative Reference", "paper_summary": "Handling test-time unknown degradation is the major challenge in Blind Image\nRestoration (BIR), necessitating high model generalization. An effective\nstrategy is to incorporate prior knowledge, either from human input or\ngenerative model. In this paper, we introduce Instant-reference Image\nRestoration (InstantIR), a novel diffusion-based BIR method which dynamically\nadjusts generation condition during inference. We first extract a compact\nrepresentation of the input via a pre-trained vision encoder. At each\ngeneration step, this representation is used to decode current diffusion latent\nand instantiate it in the generative prior. The degraded image is then encoded\nwith this reference, providing robust generation condition. We observe the\nvariance of generative references fluctuate with degradation intensity, which\nwe further leverage as an indicator for developing a sampling algorithm\nadaptive to input quality. Extensive experiments demonstrate InstantIR achieves\nstate-of-the-art performance and offering outstanding visual quality. Through\nmodulating generative references with textual description, InstantIR can\nrestore extreme degradation and additionally feature creative restoration.", "paper_summary_zh": "\u8655\u7406\u6e2c\u8a66\u6642\u9593\u672a\u77e5\u7684\u9000\u5316\u662f\u76f2\u5716\u50cf\u4fee\u5fa9 (BIR) \u4e2d\u7684\u4e3b\u8981\u6311\u6230\uff0c\u9700\u8981\u5f88\u9ad8\u7684\u6a21\u578b\u6982\u5316\u80fd\u529b\u3002\u4e00\u500b\u6709\u6548\u7684\u7b56\u7565\u662f\u7d0d\u5165\u5148\u9a57\u77e5\u8b58\uff0c\u7121\u8ad6\u662f\u4f86\u81ea\u4eba\u985e\u8f38\u5165\u6216\u751f\u6210\u6a21\u578b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u5373\u6642\u53c3\u8003\u5716\u50cf\u4fee\u5fa9 (InstantIR)\uff0c\u9019\u662f\u4e00\u7a2e\u57fa\u65bc\u64f4\u6563\u7684\u65b0\u578b BIR \u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u63a8\u7406\u904e\u7a0b\u4e2d\u52d5\u614b\u8abf\u6574\u751f\u6210\u689d\u4ef6\u3002\u6211\u5011\u9996\u5148\u901a\u904e\u9810\u8a13\u7df4\u7684\u8996\u89ba\u7de8\u78bc\u5668\u63d0\u53d6\u8f38\u5165\u7684\u7dca\u6e4a\u8868\u793a\u3002\u5728\u6bcf\u500b\u751f\u6210\u6b65\u9a5f\u4e2d\uff0c\u6b64\u8868\u793a\u7528\u65bc\u89e3\u78bc\u7576\u524d\u7684\u64f4\u6563\u6f5b\u5728\uff0c\u4e26\u5728\u751f\u6210\u5148\u9a57\u4e2d\u5be6\u4f8b\u5316\u5b83\u3002\u7136\u5f8c\u4f7f\u7528\u6b64\u53c3\u8003\u5c0d\u964d\u7d1a\u7684\u5716\u50cf\u9032\u884c\u7de8\u78bc\uff0c\u5f9e\u800c\u63d0\u4f9b\u7a69\u5065\u7684\u751f\u6210\u689d\u4ef6\u3002\u6211\u5011\u89c0\u5bdf\u5230\u751f\u6210\u53c3\u8003\u7684\u65b9\u5dee\u96a8\u964d\u89e3\u5f37\u5ea6\u800c\u6ce2\u52d5\uff0c\u6211\u5011\u9032\u4e00\u6b65\u5229\u7528\u5b83\u4f5c\u70ba\u958b\u767c\u9069\u61c9\u8f38\u5165\u8cea\u91cf\u7684\u63a1\u6a23\u6f14\u7b97\u6cd5\u7684\u6307\u6a19\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8868\u660e\uff0cInstantIR \u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6027\u80fd\uff0c\u4e26\u63d0\u4f9b\u4e86\u51fa\u8272\u7684\u8996\u89ba\u54c1\u8cea\u3002\u901a\u904e\u7528\u6587\u5b57\u63cf\u8ff0\u8abf\u7bc0\u751f\u6210\u53c3\u8003\uff0cInstantIR \u53ef\u4ee5\u4fee\u5fa9\u6975\u7aef\u7684\u9000\u5316\uff0c\u4e26\u53e6\u5916\u63d0\u4f9b\u5275\u610f\u7684\u4fee\u5fa9\u3002", "author": "Jen-Yuan Huang et.al.", "authors": "Jen-Yuan Huang, Haofan Wang, Qixun Wang, Xu Bai, Hao Ai, Peng Xing, Jen-Tse Huang", "id": "2410.06551v1", "paper_url": "http://arxiv.org/abs/2410.06551v1", "repo": "null"}}