{"2411.03025": {"publish_time": "2024-11-05", "title": "DA-MoE: Addressing Depth-Sensitivity in Graph-Level Analysis through Mixture of Experts", "paper_summary": "Graph neural networks (GNNs) are gaining popularity for processing\ngraph-structured data. In real-world scenarios, graph data within the same\ndataset can vary significantly in scale. This variability leads to\ndepth-sensitivity, where the optimal depth of GNN layers depends on the scale\nof the graph data. Empirically, fewer layers are sufficient for message passing\nin smaller graphs, while larger graphs typically require deeper networks to\ncapture long-range dependencies and global features. However, existing methods\ngenerally use a fixed number of GNN layers to generate representations for all\ngraphs, overlooking the depth-sensitivity issue in graph structure data. To\naddress this challenge, we propose the depth adaptive mixture of expert\n(DA-MoE) method, which incorporates two main improvements to GNN backbone:\n\\textbf{1)} DA-MoE employs different GNN layers, each considered an expert with\nits own parameters. Such a design allows the model to flexibly aggregate\ninformation at different scales, effectively addressing the depth-sensitivity\nissue in graph data. \\textbf{2)} DA-MoE utilizes GNN to capture the structural\ninformation instead of the linear projections in the gating network. Thus, the\ngating network enables the model to capture complex patterns and dependencies\nwithin the data. By leveraging these improvements, each expert in DA-MoE\nspecifically learns distinct graph patterns at different scales. Furthermore,\ncomprehensive experiments on the TU dataset and open graph benchmark (OGB) have\nshown that DA-MoE consistently surpasses existing baselines on various tasks,\nincluding graph, node, and link-level analyses. The code are available at\n\\url{https://github.com/Celin-Yao/DA-MoE}.", "paper_summary_zh": "\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u5728\u8655\u7406\u5716\u5f62\u7d50\u69cb\u8cc7\u6599\u65b9\u9762\u8d8a\u4f86\u8d8a\u53d7\u6b61\u8fce\u3002\u5728\u771f\u5be6\u4e16\u754c\u7684\u5834\u666f\u4e2d\uff0c\u540c\u4e00\u500b\u8cc7\u6599\u96c6\u5167\u7684\u5716\u5f62\u8cc7\u6599\u5728\u898f\u6a21\u4e0a\u53ef\u80fd\u6703\u6709\u986f\u8457\u7684\u5dee\u7570\u3002\u9019\u7a2e\u8b8a\u7570\u6027\u6703\u5c0e\u81f4\u6df1\u5ea6\u654f\u611f\u6027\uff0c\u5176\u4e2d GNN \u5c64\u7684\u6700\u4f73\u6df1\u5ea6\u53d6\u6c7a\u65bc\u5716\u5f62\u8cc7\u6599\u7684\u898f\u6a21\u3002\u6839\u64da\u7d93\u9a57\uff0c\u8f03\u5c0f\u7684\u5716\u5f62\u5728\u8a0a\u606f\u50b3\u905e\u4e2d\u9700\u8981\u8f03\u5c11\u7684\u5c64\uff0c\u800c\u8f03\u5927\u7684\u5716\u5f62\u901a\u5e38\u9700\u8981\u66f4\u6df1\u7684\u7db2\u8def\u4f86\u64f7\u53d6\u9577\u8ddd\u96e2\u4f9d\u8cf4\u95dc\u4fc2\u548c\u5168\u57df\u7279\u5fb5\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u56fa\u5b9a\u6578\u91cf\u7684 GNN \u5c64\u4f86\u70ba\u6240\u6709\u5716\u5f62\u7522\u751f\u8868\u793a\uff0c\u5ffd\u7565\u4e86\u5716\u5f62\u7d50\u69cb\u8cc7\u6599\u4e2d\u7684\u6df1\u5ea6\u654f\u611f\u6027\u554f\u984c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u6df1\u5ea6\u81ea\u9069\u61c9\u5c08\u5bb6\u6df7\u5408 (DA-MoE) \u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u5c0d GNN \u9aa8\u5e79\u9032\u884c\u4e86\u5169\u9805\u4e3b\u8981\u6539\u9032\uff1a\n**1) ** DA-MoE \u4f7f\u7528\u4e0d\u540c\u7684 GNN \u5c64\uff0c\u6bcf\u500b\u5c64\u90fd\u88ab\u8996\u70ba\u4e00\u500b\u5177\u6709\u81ea\u5df1\u53c3\u6578\u7684\u5c08\u5bb6\u3002\u9019\u7a2e\u8a2d\u8a08\u5141\u8a31\u6a21\u578b\u9748\u6d3b\u5730\u5f59\u7e3d\u4e0d\u540c\u898f\u6a21\u7684\u8cc7\u8a0a\uff0c\u6709\u6548\u5730\u89e3\u6c7a\u4e86\u5716\u5f62\u8cc7\u6599\u4e2d\u7684\u6df1\u5ea6\u654f\u611f\u6027\u554f\u984c\u3002**2) ** DA-MoE \u5229\u7528 GNN \u64f7\u53d6\u7d50\u69cb\u8cc7\u8a0a\uff0c\u800c\u4e0d\u662f\u9598\u63a7\u7db2\u8def\u4e2d\u7684\u7dda\u6027\u6295\u5f71\u3002\u56e0\u6b64\uff0c\u9598\u63a7\u7db2\u8def\u4f7f\u6a21\u578b\u80fd\u5920\u64f7\u53d6\u8cc7\u6599\u4e2d\u7684\u8907\u96dc\u6a21\u5f0f\u548c\u4f9d\u8cf4\u95dc\u4fc2\u3002\u900f\u904e\u5229\u7528\u9019\u4e9b\u6539\u9032\uff0cDA-MoE \u4e2d\u7684\u6bcf\u500b\u5c08\u5bb6\u90fd\u80fd\u7279\u5225\u5b78\u7fd2\u4e0d\u540c\u898f\u6a21\u7684\u7279\u5b9a\u5716\u5f62\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u5728 TU \u8cc7\u6599\u96c6\u548c\u958b\u653e\u5716\u5f62\u57fa\u6e96 (OGB) \u4e0a\u9032\u884c\u7684\u5168\u9762\u5be6\u9a57\u8868\u660e\uff0cDA-MoE \u5728\u5404\u7a2e\u4efb\u52d9\u4e0a\u90fd\u6301\u7e8c\u8d85\u8d8a\u73fe\u6709\u7684\u57fa\u6e96\uff0c\u5305\u62ec\u5716\u5f62\u3001\u7bc0\u9ede\u548c\u9023\u7d50\u5c64\u7d1a\u5206\u6790\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728\n\\url{https://github.com/Celin-Yao/DA-MoE} \u53d6\u5f97\u3002", "author": "Zelin Yao et.al.", "authors": "Zelin Yao, Chuang Liu, Xianke Meng, Yibing Zhan, Jia Wu, Shirui Pan, Wenbin Hu", "id": "2411.03025v1", "paper_url": "http://arxiv.org/abs/2411.03025v1", "repo": "https://github.com/celin-yao/da-moe"}}