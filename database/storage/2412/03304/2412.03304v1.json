{"2412.03304": {"publish_time": "2024-12-04", "title": "Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation", "paper_summary": "Cultural biases in multilingual datasets pose significant challenges for\ntheir effectiveness as global benchmarks. These biases stem not only from\nlanguage but also from the cultural knowledge required to interpret questions,\nreducing the practical utility of translated datasets like MMLU. Furthermore,\ntranslation often introduces artifacts that can distort the meaning or clarity\nof questions in the target language. A common practice in multilingual\nevaluation is to rely on machine-translated evaluation sets, but simply\ntranslating a dataset is insufficient to address these challenges. In this\nwork, we trace the impact of both of these issues on multilingual evaluations\nand ensuing model performances. Our large-scale evaluation of state-of-the-art\nopen and proprietary models illustrates that progress on MMLU depends heavily\non learning Western-centric concepts, with 28% of all questions requiring\nculturally sensitive knowledge. Moreover, for questions requiring geographic\nknowledge, an astounding 84.9% focus on either North American or European\nregions. Rankings of model evaluations change depending on whether they are\nevaluated on the full portion or the subset of questions annotated as\nculturally sensitive, showing the distortion to model rankings when blindly\nrelying on translated MMLU. We release Global-MMLU, an improved MMLU with\nevaluation coverage across 42 languages -- with improved overall quality by\nengaging with compensated professional and community annotators to verify\ntranslation quality while also rigorously evaluating cultural biases present in\nthe original dataset. This comprehensive Global-MMLU set also includes\ndesignated subsets labeled as culturally sensitive and culturally agnostic to\nallow for more holistic, complete evaluation.", "paper_summary_zh": "\u591a\u8a9e\u7cfb\u8cc7\u6599\u96c6\u4e2d\u7684\u6587\u5316\u504f\u898b\u5c0d\u5176\u4f5c\u70ba\u5168\u7403\u57fa\u6e96\u7684\u6709\u6548\u6027\u69cb\u6210\u91cd\u5927\u6311\u6230\u3002\u9019\u4e9b\u504f\u898b\u4e0d\u50c5\u6e90\u81ea\u8a9e\u8a00\uff0c\u4e5f\u6e90\u81ea\u8a6e\u91cb\u554f\u984c\u6240\u9700\u7684\u6587\u5316\u77e5\u8b58\uff0c\u964d\u4f4e\u4e86 MMLU \u7b49\u7ffb\u8b6f\u8cc7\u6599\u96c6\u7684\u5be6\u969b\u6548\u7528\u3002\u6b64\u5916\uff0c\u7ffb\u8b6f\u901a\u5e38\u6703\u5f15\u5165\u4eba\u5de5\u88fd\u54c1\uff0c\u53ef\u80fd\u626d\u66f2\u76ee\u6a19\u8a9e\u8a00\u4e2d\u554f\u984c\u7684\u610f\u7fa9\u6216\u6e05\u6670\u5ea6\u3002\u591a\u8a9e\u7cfb\u8a55\u4f30\u4e2d\u7684\u4e00\u7a2e\u5e38\u898b\u505a\u6cd5\u662f\u4f9d\u8cf4\u6a5f\u5668\u7ffb\u8b6f\u7684\u8a55\u4f30\u96c6\uff0c\u4f46\u50c5\u7ffb\u8b6f\u8cc7\u6599\u96c6\u4e0d\u8db3\u4ee5\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u8ffd\u8e64\u4e86\u9019\u5169\u500b\u554f\u984c\u5c0d\u591a\u8a9e\u7cfb\u8a55\u4f30\u548c\u5f8c\u7e8c\u6a21\u578b\u6548\u80fd\u7684\u5f71\u97ff\u3002\u6211\u5011\u5c0d\u6700\u5148\u9032\u7684\u958b\u653e\u548c\u5c08\u6709\u6a21\u578b\u9032\u884c\u5927\u898f\u6a21\u8a55\u4f30\uff0c\u8aaa\u660e MMLU \u7684\u9032\u5c55\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u6c7a\u65bc\u5b78\u7fd2\u4ee5\u897f\u65b9\u70ba\u4e2d\u5fc3\u7684\u89c0\u5ff5\uff0c\u5176\u4e2d 28% \u7684\u554f\u984c\u9700\u8981\u6587\u5316\u654f\u611f\u7684\u77e5\u8b58\u3002\u6b64\u5916\uff0c\u5c0d\u65bc\u9700\u8981\u5730\u7406\u77e5\u8b58\u7684\u554f\u984c\uff0c\u9a5a\u4eba\u7684 84.9% \u5c08\u6ce8\u65bc\u5317\u7f8e\u6216\u6b50\u6d32\u5730\u5340\u3002\u6a21\u578b\u8a55\u4f30\u7684\u6392\u540d\u6703\u6839\u64da\u5b83\u5011\u662f\u5728\u5168\u90e8\u90e8\u5206\u9084\u662f\u6a19\u8a3b\u70ba\u6587\u5316\u654f\u611f\u7684\u5b50\u96c6\u554f\u984c\u4e0a\u9032\u884c\u8a55\u4f30\u800c\u6539\u8b8a\uff0c\u986f\u793a\u51fa\u5728\u76f2\u76ee\u4f9d\u8cf4\u7ffb\u8b6f\u7684 MMLU \u6642\u5c0d\u6a21\u578b\u6392\u540d\u7684\u626d\u66f2\u3002\u6211\u5011\u767c\u5e03\u4e86 Global-MMLU\uff0c\u9019\u662f\u4e00\u500b\u6539\u9032\u7684 MMLU\uff0c\u5176\u8a55\u4f30\u6db5\u84cb 42 \u7a2e\u8a9e\u8a00\u2014\u2014\u900f\u904e\u8207\u7372\u5f97\u5831\u916c\u7684\u5c08\u696d\u548c\u793e\u7fa4\u8a3b\u89e3\u54e1\u5408\u4f5c\uff0c\u9a57\u8b49\u7ffb\u8b6f\u54c1\u8cea\uff0c\u540c\u6642\u56b4\u683c\u8a55\u4f30\u539f\u59cb\u8cc7\u6599\u96c6\u4e2d\u5b58\u5728\u7684\u6587\u5316\u504f\u898b\uff0c\u5f9e\u800c\u63d0\u9ad8\u6574\u9ad4\u54c1\u8cea\u3002\u9019\u500b\u5168\u9762\u7684 Global-MMLU \u96c6\u9084\u5305\u62ec\u6a19\u793a\u70ba\u6587\u5316\u654f\u611f\u548c\u6587\u5316\u4e0d\u53ef\u77e5\u8ad6\u7684\u6307\u5b9a\u5b50\u96c6\uff0c\u4ee5\u9032\u884c\u66f4\u5168\u9762\u3001\u5b8c\u6574\u7684\u8a55\u4f30\u3002", "author": "Shivalika Singh et.al.", "authors": "Shivalika Singh, Angelika Romanou, Cl\u00e9mentine Fourrier, David I. Adelani, Jian Gang Ngui, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre, Wei-Yin Ko, Madeline Smith, Antoine Bosselut, Alice Oh, Andre F. T. Martins, Leshem Choshen, Daphne Ippolito, Enzo Ferrante, Marzieh Fadaee, Beyza Ermis, Sara Hooker", "id": "2412.03304v1", "paper_url": "http://arxiv.org/abs/2412.03304v1", "repo": "null"}}