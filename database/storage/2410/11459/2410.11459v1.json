{"2410.11459": {"publish_time": "2024-10-15", "title": "Jigsaw Puzzles: Splitting Harmful Questions to Jailbreak Large Language Models", "paper_summary": "Large language models (LLMs) have exhibited outstanding performance in\nengaging with humans and addressing complex questions by leveraging their vast\nimplicit knowledge and robust reasoning capabilities. However, such models are\nvulnerable to jailbreak attacks, leading to the generation of harmful\nresponses. Despite recent research on single-turn jailbreak strategies to\nfacilitate the development of defence mechanisms, the challenge of revealing\nvulnerabilities under multi-turn setting remains relatively under-explored. In\nthis work, we propose Jigsaw Puzzles (JSP), a straightforward yet effective\nmulti-turn jailbreak strategy against the advanced LLMs. JSP splits questions\ninto harmless fractions as the input of each turn, and requests LLMs to\nreconstruct and respond to questions under multi-turn interaction. Our\nexperimental results demonstrate that the proposed JSP jailbreak bypasses\noriginal safeguards against explicitly harmful content, achieving an average\nattack success rate of 93.76% on 189 harmful queries across 5 advanced LLMs\n(Gemini-1.5-Pro, Llama-3.1-70B, GPT-4, GPT-4o, GPT-4o-mini). Moreover, JSP\nachieves a state-of-the-art attack success rate of 92% on GPT-4 on the harmful\nquery benchmark, and exhibits strong resistant to defence strategies. Warning:\nthis paper contains offensive examples.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u8207\u4eba\u985e\u4e92\u52d5\u548c\u89e3\u6c7a\u8907\u96dc\u554f\u984c\u4e0a\u8868\u73fe\u51fa\u8272\uff0c\u5229\u7528\u5176\u5ee3\u6cdb\u7684\u96b1\u542b\u77e5\u8b58\u548c\u5f37\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002\u7136\u800c\uff0c\u6b64\u985e\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u8d8a\u7344\u653b\u64ca\uff0c\u5c0e\u81f4\u7522\u751f\u6709\u5bb3\u7684\u56de\u61c9\u3002\u5118\u7ba1\u6700\u8fd1\u91dd\u5c0d\u55ae\u56de\u5408\u8d8a\u7344\u7b56\u7565\u7684\u7814\u7a76\u4fc3\u9032\u4e86\u9632\u79a6\u6a5f\u5236\u7684\u958b\u767c\uff0c\u4f46\u5728\u591a\u56de\u5408\u8a2d\u7f6e\u4e0b\u63ed\u9732\u6f0f\u6d1e\u7684\u6311\u6230\u4ecd\u76f8\u5c0d\u672a\u88ab\u63a2\u7d22\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u62fc\u5716 (JSP)\uff0c\u4e00\u7a2e\u91dd\u5c0d\u9ad8\u7d1a LLM \u7684\u7c21\u55ae\u4f46\u6709\u6548\u7684\u591a\u56de\u5408\u8d8a\u7344\u7b56\u7565\u3002JSP \u5c07\u554f\u984c\u62c6\u5206\u70ba\u7121\u5bb3\u7684\u90e8\u5206\u4f5c\u70ba\u6bcf\u500b\u56de\u5408\u7684\u8f38\u5165\uff0c\u4e26\u8981\u6c42 LLM \u5728\u591a\u56de\u5408\u4e92\u52d5\u4e0b\u91cd\u5efa\u548c\u56de\u7b54\u554f\u984c\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684 JSP \u8d8a\u7344\u7e5e\u904e\u4e86\u91dd\u5c0d\u660e\u986f\u6709\u5bb3\u5167\u5bb9\u7684\u539f\u59cb\u9632\u8b77\u63aa\u65bd\uff0c\u5728 5 \u500b\u9ad8\u7d1a LLM\uff08Gemini-1.5-Pro\u3001Llama-3.1-70B\u3001GPT-4\u3001GPT-4o\u3001GPT-4o-mini\uff09\u4e0a\u7684 189 \u500b\u6709\u5bb3\u67e5\u8a62\u4e2d\u5be6\u73fe\u4e86 93.76% \u7684\u5e73\u5747\u653b\u64ca\u6210\u529f\u7387\u3002\u6b64\u5916\uff0cJSP \u5728\u6709\u5bb3\u67e5\u8a62\u57fa\u6e96\u4e0a\u5c0d GPT-4 \u5b9e\u73b0\u4e86 92% \u7684\u6700\u5148\u9032\u653b\u64ca\u6210\u529f\u7387\uff0c\u4e26\u5c0d\u9632\u79a6\u7b56\u7565\u8868\u73fe\u51fa\u5f37\u5927\u7684\u62b5\u6297\u529b\u3002\u8b66\u544a\uff1a\u672c\u6587\u5305\u542b\u5192\u72af\u6027\u793a\u4f8b\u3002", "author": "Hao Yang et.al.", "authors": "Hao Yang, Lizhen Qu, Ehsan Shareghi, Gholamreza Haffari", "id": "2410.11459v1", "paper_url": "http://arxiv.org/abs/2410.11459v1", "repo": "null"}}