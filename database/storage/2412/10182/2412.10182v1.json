{"2412.10182": {"publish_time": "2024-12-13", "title": "Multi-Head Encoding for Extreme Label Classification", "paper_summary": "The number of categories of instances in the real world is normally huge, and\neach instance may contain multiple labels. To distinguish these massive labels\nutilizing machine learning, eXtreme Label Classification (XLC) has been\nestablished. However, as the number of categories increases, the number of\nparameters and nonlinear operations in the classifier also rises. This results\nin a Classifier Computational Overload Problem (CCOP). To address this, we\npropose a Multi-Head Encoding (MHE) mechanism, which replaces the vanilla\nclassifier with a multi-head classifier. During the training process, MHE\ndecomposes extreme labels into the product of multiple short local labels, with\neach head trained on these local labels. During testing, the predicted labels\ncan be directly calculated from the local predictions of each head. This\nreduces the computational load geometrically. Then, according to the\ncharacteristics of different XLC tasks, e.g., single-label, multi-label, and\nmodel pretraining tasks, three MHE-based implementations, i.e., Multi-Head\nProduct, Multi-Head Cascade, and Multi-Head Sampling, are proposed to more\neffectively cope with CCOP. Moreover, we theoretically demonstrate that MHE can\nachieve performance approximately equivalent to that of the vanilla classifier\nby generalizing the low-rank approximation problem from Frobenius-norm to\nCross-Entropy. Experimental results show that the proposed methods achieve\nstate-of-the-art performance while significantly streamlining the training and\ninference processes of XLC tasks. The source code has been made public at\nhttps://github.com/Anoise/MHE.", "paper_summary_zh": "<paragraph>\u73fe\u5be6\u4e16\u754c\u4e2d\u5be6\u4f8b\u985e\u5225\u7684\u6578\u91cf\u901a\u5e38\u9f90\u5927\uff0c\u4e14\u6bcf\u500b\u5be6\u4f8b\u53ef\u80fd\u5305\u542b\u591a\u500b\u6a19\u7c64\u3002\u70ba\u4e86\u5229\u7528\u6a5f\u5668\u5b78\u7fd2\u4f86\u5340\u5206\u9019\u4e9b\u5927\u91cf\u7684\u6a19\u7c64\uff0c\u5df2\u5efa\u7acb\u6975\u7aef\u6a19\u7c64\u5206\u985e (XLC)\u3002\u7136\u800c\uff0c\u96a8\u8457\u985e\u5225\u6578\u91cf\u7684\u589e\u52a0\uff0c\u5206\u985e\u5668\u4e2d\u7684\u53c3\u6578\u548c\u975e\u7dda\u6027\u904b\u7b97\u6578\u91cf\u4e5f\u6703\u589e\u52a0\u3002\u9019\u5c0e\u81f4\u5206\u985e\u5668\u8a08\u7b97\u904e\u8f09\u554f\u984c (CCOP)\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u591a\u982d\u7de8\u78bc (MHE) \u6a5f\u5236\uff0c\u5b83\u4ee5\u4e00\u500b\u591a\u982d\u5206\u985e\u5668\u53d6\u4ee3\u4e86\u9999\u8349\u5206\u985e\u5668\u3002\u5728\u8a13\u7df4\u904e\u7a0b\u4e2d\uff0cMHE \u5c07\u6975\u7aef\u6a19\u7c64\u5206\u89e3\u70ba\u591a\u500b\u8f03\u77ed\u7684\u5c40\u90e8\u6a19\u7c64\u7684\u4e58\u7a4d\uff0c\u6bcf\u500b\u982d\u90e8\u90fd\u5728\u9019\u4e9b\u5c40\u90e8\u6a19\u7c64\u4e0a\u9032\u884c\u8a13\u7df4\u3002\u5728\u6e2c\u8a66\u671f\u9593\uff0c\u53ef\u4ee5\u6839\u64da\u6bcf\u500b\u982d\u90e8\u7684\u5c40\u90e8\u9810\u6e2c\u76f4\u63a5\u8a08\u7b97\u9810\u6e2c\u6a19\u7c64\u3002\u9019\u5728\u5e7e\u4f55\u4e0a\u6e1b\u5c11\u4e86\u8a08\u7b97\u8ca0\u8f09\u3002\u7136\u5f8c\uff0c\u6839\u64da\u4e0d\u540c\u7684 XLC \u4efb\u52d9\u7684\u7279\u5fb5\uff0c\u4f8b\u5982\u55ae\u6a19\u7c64\u3001\u591a\u6a19\u7c64\u548c\u6a21\u578b\u9810\u8a13\u7df4\u4efb\u52d9\uff0c\u63d0\u51fa\u4e86\u4e09\u7a2e\u57fa\u65bc MHE \u7684\u5be6\u73fe\uff0c\u5373\u591a\u982d\u4e58\u7a4d\u3001\u591a\u982d\u4e32\u806f\u548c\u591a\u982d\u62bd\u6a23\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u61c9\u5c0d CCOP\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f9e\u7406\u8ad6\u4e0a\u8b49\u660e\u4e86 MHE \u53ef\u4ee5\u901a\u904e\u5c07\u4f4e\u79e9\u903c\u8fd1\u554f\u984c\u5f9e Frobenius \u7bc4\u6578\u63a8\u5ee3\u5230\u4ea4\u53c9\u71b5\u4f86\u5be6\u73fe\u8207\u9999\u8349\u5206\u985e\u5668\u8fd1\u4f3c\u7684\u6027\u80fd\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u986f\u8457\u7c21\u5316 XLC \u4efb\u52d9\u7684\u8a13\u7df4\u548c\u63a8\u7406\u904e\u7a0b\u7684\u540c\u6642\uff0c\u5be6\u73fe\u4e86\u6700\u5148\u9032\u7684\u6027\u80fd\u3002\u6e90\u4ee3\u78bc\u5df2\u516c\u958b\u5728 https://github.com/Anoise/MHE\u3002</paragraph>", "author": "Daojun Liang et.al.", "authors": "Daojun Liang, Haixia Zhang, Dongfeng Yuan, Minggao Zhang", "id": "2412.10182v1", "paper_url": "http://arxiv.org/abs/2412.10182v1", "repo": "https://github.com/anoise/mhe"}}