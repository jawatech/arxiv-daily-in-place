{"2407.19813": {"publish_time": "2024-07-29", "title": "Improving Retrieval Augmented Language Model with Self-Reasoning", "paper_summary": "The Retrieval-Augmented Language Model (RALM) has shown remarkable\nperformance on knowledge-intensive tasks by incorporating external knowledge\nduring inference, which mitigates the factual hallucinations inherited in large\nlanguage models (LLMs). Despite these advancements, challenges persist in the\nimplementation of RALMs, particularly concerning their reliability and\ntraceability. To be specific, the irrelevant document retrieval may result in\nunhelpful response generation or even deteriorate the performance of LLMs,\nwhile the lack of proper citations in generated outputs complicates efforts to\nverify the trustworthiness of the models. To this end, we propose a novel\nself-reasoning framework aimed at improving the reliability and traceability of\nRALMs, whose core idea is to leverage reasoning trajectories generated by the\nLLM itself. The framework involves constructing self-reason trajectories with\nthree processes: a relevance-aware process, an evidence-aware selective\nprocess, and a trajectory analysis process. We have evaluated our framework\nacross four public datasets (two short-form QA datasets, one long-form QA\ndataset, and one fact verification dataset) to demonstrate the superiority of\nour method, which can outperform existing state-of-art models and can achieve\ncomparable performance with GPT-4, while only using 2,000 training samples.", "paper_summary_zh": "\u6aa2\u7d22\u589e\u5f37\u8a9e\u8a00\u6a21\u578b (RALM) \u5728\u77e5\u8b58\u5bc6\u96c6\u578b\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u8868\u73fe\uff0c\u65b9\u6cd5\u662f\u5728\u63a8\u8ad6\u904e\u7a0b\u4e2d\u7d0d\u5165\u5916\u90e8\u77e5\u8b58\uff0c\u9019\u6e1b\u8f15\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7e7c\u627f\u800c\u4f86\u7684\u865b\u69cb\u4e8b\u5be6\u3002\u5118\u7ba1\u6709\u9019\u4e9b\u9032\u5c55\uff0c\u5728 RALM \u7684\u5be6\u4f5c\u4e2d\u4ecd\u7136\u5b58\u5728\u6311\u6230\uff0c\u7279\u5225\u662f\u95dc\u65bc\u5b83\u5011\u7684\u53ef\u9760\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u4e0d\u76f8\u95dc\u7684\u6587\u4ef6\u6aa2\u7d22\u53ef\u80fd\u6703\u5c0e\u81f4\u7121\u76ca\u7684\u56de\u61c9\u7522\u751f\uff0c\u751a\u81f3\u6703\u964d\u4f4e LLM \u7684\u6548\u80fd\uff0c\u800c\u7522\u751f\u7684\u8f38\u51fa\u4e2d\u7f3a\u4e4f\u9069\u7576\u7684\u5f15\u6587\uff0c\u4f7f\u5f97\u9a57\u8b49\u6a21\u578b\u53ef\u4fe1\u5ea6\u7684\u52aa\u529b\u8b8a\u5f97\u8907\u96dc\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u81ea\u63a8\u7406\u67b6\u69cb\uff0c\u65e8\u5728\u63d0\u9ad8 RALM \u7684\u53ef\u9760\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5229\u7528 LLM \u672c\u8eab\u7522\u751f\u7684\u63a8\u7406\u8ecc\u8de1\u3002\u8a72\u6846\u67b6\u6d89\u53ca\u4f7f\u7528\u4e09\u500b\u6d41\u7a0b\u4f86\u5efa\u69cb\u81ea\u63a8\u7406\u8ecc\u8de1\uff1a\u8207\u76f8\u95dc\u6027\u76f8\u95dc\u7684\u6d41\u7a0b\u3001\u8207\u8b49\u64da\u76f8\u95dc\u7684\u9078\u64c7\u6027\u6d41\u7a0b\u548c\u8ecc\u8de1\u5206\u6790\u6d41\u7a0b\u3002\u6211\u5011\u5df2\u7d93\u5728\u56db\u500b\u516c\u958b\u6578\u64da\u96c6\uff08\u5169\u500b\u7c21\u77ed\u554f\u7b54\u6578\u64da\u96c6\u3001\u4e00\u500b\u9577\u7bc7\u554f\u7b54\u6578\u64da\u96c6\u548c\u4e00\u500b\u4e8b\u5be6\u9a57\u8b49\u6578\u64da\u96c6\uff09\u4e2d\u8a55\u4f30\u4e86\u6211\u5011\u7684\u6846\u67b6\uff0c\u4ee5\u8b49\u660e\u6211\u5011\u7684\u65b9\u6cd5\u7684\u512a\u8d8a\u6027\uff0c\u5b83\u53ef\u4ee5\u512a\u65bc\u73fe\u6709\u7684\u6700\u5148\u9032\u6a21\u578b\uff0c\u4e26\u4e14\u53ef\u4ee5\u9054\u5230\u8207 GPT-4 \u76f8\u7576\u7684\u6548\u80fd\uff0c\u800c\u53ea\u4f7f\u7528 2,000 \u500b\u8a13\u7df4\u6a23\u672c\u3002", "author": "Yuan Xia et.al.", "authors": "Yuan Xia, Jingbo Zhou, Zhenhui Shi, Jun Chen, Haifeng Huang", "id": "2407.19813v1", "paper_url": "http://arxiv.org/abs/2407.19813v1", "repo": "null"}}