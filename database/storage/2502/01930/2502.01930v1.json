{"2502.01930": {"publish_time": "2025-02-04", "title": "Distributionally Robust Direct Preference Optimization", "paper_summary": "A major challenge in aligning large language models (LLMs) with human\npreferences is the issue of distribution shift. LLM alignment algorithms rely\non static preference datasets, assuming that they accurately represent\nreal-world user preferences. However, user preferences vary significantly\nacross geographical regions, demographics, linguistic patterns, and evolving\ncultural trends. This preference distribution shift leads to catastrophic\nalignment failures in many real-world applications. We address this problem\nusing the principled framework of distributionally robust optimization, and\ndevelop two novel distributionally robust direct preference optimization (DPO)\nalgorithms, namely, Wasserstein DPO (WDPO) and Kullback-Leibler DPO (KLDPO). We\ncharacterize the sample complexity of learning the optimal policy parameters\nfor WDPO and KLDPO. Moreover, we propose scalable gradient descent-style\nlearning algorithms by developing suitable approximations for the challenging\nminimax loss functions of WDPO and KLDPO. Our empirical experiments demonstrate\nthe superior performance of WDPO and KLDPO in substantially improving the\nalignment when there is a preference distribution shift.", "paper_summary_zh": "\u5728\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u4eba\u985e\u504f\u597d\u76f8\u7b26\u6642\uff0c\u4e00\u500b\u4e3b\u8981\u7684\u6311\u6230\u5728\u65bc\u5206\u4f48\u8f49\u79fb\u7684\u554f\u984c\u3002LLM \u8a13\u7df4\u6f14\u7b97\u6cd5\u4f9d\u8cf4\u65bc\u975c\u614b\u504f\u597d\u8cc7\u6599\u96c6\uff0c\u5047\u8a2d\u5b83\u5011\u6e96\u78ba\u5730\u4ee3\u8868\u4e86\u771f\u5be6\u4e16\u754c\u7684\u4f7f\u7528\u8005\u504f\u597d\u3002\u7136\u800c\uff0c\u4f7f\u7528\u8005\u504f\u597d\u56e0\u5730\u7406\u5340\u57df\u3001\u4eba\u53e3\u7d71\u8a08\u3001\u8a9e\u8a00\u6a21\u5f0f\u548c\u4e0d\u65b7\u6f14\u8b8a\u7684\u6587\u5316\u8da8\u52e2\u800c\u7570\u3002\u9019\u7a2e\u504f\u597d\u5206\u4f48\u8f49\u79fb\u5c0e\u81f4\u8a31\u591a\u771f\u5be6\u4e16\u754c\u61c9\u7528\u7a0b\u5f0f\u51fa\u73fe\u707d\u96e3\u6027\u7684\u8a13\u7df4\u5931\u6557\u3002\u6211\u5011\u4f7f\u7528\u5206\u4f48\u7a69\u5065\u6700\u4f73\u5316\u7684\u539f\u5247\u6846\u67b6\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u4e26\u958b\u767c\u4e86\u5169\u7a2e\u65b0\u7a4e\u7684\u5206\u4f48\u7a69\u5065\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u6f14\u7b97\u6cd5\uff0c\u5373 Wasserstein DPO (WDPO) \u548c Kullback-Leibler DPO (KLDPO)\u3002\u6211\u5011\u63cf\u8ff0\u4e86\u5b78\u7fd2 WDPO \u548c KLDPO \u6700\u4f73\u7b56\u7565\u53c3\u6578\u7684\u6a23\u672c\u8907\u96dc\u5ea6\u3002\u6b64\u5916\uff0c\u6211\u5011\u900f\u904e\u70ba WDPO \u548c KLDPO \u5177\u6709\u6311\u6230\u6027\u7684\u6975\u5c0f\u6975\u5927\u640d\u5931\u51fd\u6578\u958b\u767c\u5408\u9069\u7684\u8fd1\u4f3c\u503c\uff0c\u63d0\u51fa\u4e86\u53ef\u64f4\u5145\u7684\u68af\u5ea6\u4e0b\u964d\u5f0f\u5b78\u7fd2\u6f14\u7b97\u6cd5\u3002\u6211\u5011\u7684\u5be6\u8b49\u5be6\u9a57\u8b49\u660e\u4e86 WDPO \u548c KLDPO \u5728\u504f\u597d\u5206\u4f48\u8f49\u79fb\u6642\u5927\u5e45\u6539\u5584\u8a13\u7df4\u7684\u5353\u8d8a\u6548\u80fd\u3002", "author": "Zaiyan Xu et.al.", "authors": "Zaiyan Xu, Sushil Vemuri, Kishan Panaganti, Dileep Kalathil, Rahul Jain, Deepak Ramachandran", "id": "2502.01930v1", "paper_url": "http://arxiv.org/abs/2502.01930v1", "repo": "null"}}