{"2412.13540": {"publish_time": "2024-12-18", "title": "Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning", "paper_summary": "Large Vision-Language Models (LVLMs) have demonstrated remarkable performance\nacross diverse tasks. Despite great success, recent studies show that LVLMs\nencounter substantial limitations when engaging with visual graphs. To study\nthe reason behind these limitations, we propose VGCure, a comprehensive\nbenchmark covering 22 tasks for examining the fundamental graph understanding\nand reasoning capacities of LVLMs. Extensive evaluations conducted on 14 LVLMs\nreveal that LVLMs are weak in basic graph understanding and reasoning tasks,\nparticularly those concerning relational or structurally complex information.\nBased on this observation, we propose a structure-aware fine-tuning framework\nto enhance LVLMs with structure learning abilities through 3 self-supervised\nlearning tasks. Experiments validate the effectiveness of our method in\nimproving LVLMs' zero-shot performance on fundamental graph learning tasks, as\nwell as enhancing the robustness of LVLMs against complex visual graphs.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u5df2\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u8868\u73fe\u3002\u5118\u7ba1\u7372\u5f97\u5de8\u5927\u7684\u6210\u529f\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u986f\u793a\uff0cLVLMs \u5728\u8655\u7406\u8996\u89ba\u5716\u5f62\u6642\u6703\u9047\u5230\u91cd\u5927\u7684\u9650\u5236\u3002\u70ba\u4e86\u7814\u7a76\u9019\u4e9b\u9650\u5236\u80cc\u5f8c\u7684\u539f\u56e0\uff0c\u6211\u5011\u63d0\u51fa\u4e86 VGCure\uff0c\u9019\u662f\u4e00\u500b\u6db5\u84cb 22 \u9805\u4efb\u52d9\u7684\u7d9c\u5408\u57fa\u6e96\uff0c\u7528\u65bc\u6aa2\u67e5 LVLMs \u7684\u57fa\u672c\u5716\u5f62\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002\u5c0d 14 \u500b LVLMs \u9032\u884c\u7684\u5ee3\u6cdb\u8a55\u4f30\u986f\u793a\uff0cLVLMs \u5728\u57fa\u672c\u7684\u5716\u5f62\u7406\u89e3\u548c\u63a8\u7406\u4efb\u52d9\u4e2d\u8f03\u5f31\uff0c\u7279\u5225\u662f\u90a3\u4e9b\u6d89\u53ca\u95dc\u4fc2\u6216\u7d50\u69cb\u8907\u96dc\u8cc7\u8a0a\u7684\u4efb\u52d9\u3002\u57fa\u65bc\u6b64\u89c0\u5bdf\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7d50\u69cb\u611f\u77e5\u5fae\u8abf\u6846\u67b6\uff0c\u4ee5\u900f\u904e 3 \u500b\u81ea\u6211\u76e3\u7763\u5b78\u7fd2\u4efb\u52d9\u4f86\u589e\u5f37 LVLMs \u7684\u7d50\u69cb\u5b78\u7fd2\u80fd\u529b\u3002\u5be6\u9a57\u9a57\u8b49\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u63d0\u5347 LVLMs \u5728\u57fa\u672c\u5716\u5f62\u5b78\u7fd2\u4efb\u52d9\u4e0a\u7684\u96f6\u6b21\u5b78\u7fd2\u8868\u73fe\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u589e\u5f37 LVLMs \u5c0d\u8907\u96dc\u8996\u89ba\u5716\u5f62\u7684\u9b6f\u68d2\u6027\u3002", "author": "Yingjie Zhu et.al.", "authors": "Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Min Zhang", "id": "2412.13540v1", "paper_url": "http://arxiv.org/abs/2412.13540v1", "repo": "https://github.com/aaandy-zhu/vgcure"}}