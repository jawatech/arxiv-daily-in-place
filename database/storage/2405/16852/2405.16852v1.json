{"2405.16852": {"publish_time": "2024-05-27", "title": "EM Distillation for One-step Diffusion Models", "paper_summary": "While diffusion models can learn complex distributions, sampling requires a\ncomputationally expensive iterative process. Existing distillation methods\nenable efficient sampling, but have notable limitations, such as performance\ndegradation with very few sampling steps, reliance on training data access, or\nmode-seeking optimization that may fail to capture the full distribution. We\npropose EM Distillation (EMD), a maximum likelihood-based approach that\ndistills a diffusion model to a one-step generator model with minimal loss of\nperceptual quality. Our approach is derived through the lens of\nExpectation-Maximization (EM), where the generator parameters are updated using\nsamples from the joint distribution of the diffusion teacher prior and inferred\ngenerator latents. We develop a reparametrized sampling scheme and a noise\ncancellation technique that together stabilizes the distillation process. We\nfurther reveal an interesting connection of our method with existing methods\nthat minimize mode-seeking KL. EMD outperforms existing one-step generative\nmethods in terms of FID scores on ImageNet-64 and ImageNet-128, and compares\nfavorably with prior work on distilling text-to-image diffusion models.", "paper_summary_zh": "\u5118\u7ba1\u64f4\u6563\u6a21\u578b\u53ef\u4ee5\u5b78\u7fd2\u8907\u96dc\u7684\u5206\u5e03\uff0c\u4f46\u53d6\u6a23\u9700\u8981\u4e00\u500b\u8a08\u7b97\u6210\u672c\u6602\u8cb4\u7684\u8fed\u4ee3\u904e\u7a0b\u3002\u73fe\u6709\u7684\u84b8\u993e\u65b9\u6cd5\u80fd\u5920\u9032\u884c\u6709\u6548\u7387\u7684\u53d6\u6a23\uff0c\u4f46\u6709\u660e\u986f\u7684\u9650\u5236\uff0c\u4f8b\u5982\u5728\u53d6\u6a23\u6b65\u9a5f\u975e\u5e38\u5c11\u6642\u6548\u80fd\u4e0b\u964d\u3001\u4f9d\u8cf4\u8a13\u7df4\u8cc7\u6599\u5b58\u53d6\uff0c\u6216\u662f\u5c0b\u6c42\u6a21\u5f0f\u7684\u6700\u4f73\u5316\u53ef\u80fd\u6703\u7121\u6cd5\u6355\u6349\u5230\u5b8c\u6574\u7684\u5206\u5e03\u3002\u6211\u5011\u63d0\u51fa EM \u84b8\u993e (EMD)\uff0c\u4e00\u7a2e\u57fa\u65bc\u6700\u5927\u4f3c\u7136\u4f30\u8a08\u7684\u65b9\u6cd5\uff0c\u5c07\u64f4\u6563\u6a21\u578b\u84b8\u993e\u6210\u4e00\u500b\u6b65\u9a5f\u751f\u6210\u5668\u6a21\u578b\uff0c\u540c\u6642\u5c07\u611f\u77e5\u54c1\u8cea\u7684\u640d\u5931\u964d\u5230\u6700\u4f4e\u3002\u6211\u5011\u7684\u505a\u6cd5\u662f\u900f\u904e\u671f\u671b\u6700\u5927\u5316 (EM) \u7684\u89c0\u9ede\u884d\u751f\u800c\u4f86\uff0c\u5176\u4e2d\u751f\u6210\u5668\u53c3\u6578\u4f7f\u7528\u64f4\u6563\u6559\u5e2b\u5148\u9a57\u548c\u63a8\u8ad6\u751f\u6210\u5668\u6f5b\u5728\u8b8a\u6578\u7684\u806f\u5408\u5206\u5e03\u4e2d\u7684\u6a23\u672c\u4f86\u66f4\u65b0\u3002\u6211\u5011\u958b\u767c\u51fa\u4e00\u500b\u91cd\u65b0\u53c3\u6578\u5316\u7684\u53d6\u6a23\u65b9\u6848\u548c\u4e00\u500b\u96dc\u8a0a\u6d88\u9664\u6280\u8853\uff0c\u5b83\u5011\u5171\u540c\u7a69\u5b9a\u84b8\u993e\u904e\u7a0b\u3002\u6211\u5011\u9032\u4e00\u6b65\u63ed\u793a\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u8207\u6700\u5c0f\u5316\u5c0b\u6c42\u6a21\u5f0f KL \u7684\u73fe\u6709\u65b9\u6cd5\u4e4b\u9593\u7684\u6709\u8da3\u9023\u7d50\u3002EMD \u5728 ImageNet-64 \u548c ImageNet-128 \u4e0a\u7684 FID \u5206\u6578\u65b9\u9762\u512a\u65bc\u73fe\u6709\u7684\u55ae\u6b65\u751f\u6210\u65b9\u6cd5\uff0c\u4e26\u4e14\u8207\u5148\u524d\u84b8\u993e\u6587\u672c\u5230\u5f71\u50cf\u64f4\u6563\u6a21\u578b\u7684\u7814\u7a76\u76f8\u6bd4\uff0c\u8868\u73fe\u4e5f\u76f8\u7576\u4e0d\u932f\u3002", "author": "Sirui Xie et.al.", "authors": "Sirui Xie, Zhisheng Xiao, Diederik P Kingma, Tingbo Hou, Ying Nian Wu, Kevin Patrick Murphy, Tim Salimans, Ben Poole, Ruiqi Gao", "id": "2405.16852v1", "paper_url": "http://arxiv.org/abs/2405.16852v1", "repo": "null"}}