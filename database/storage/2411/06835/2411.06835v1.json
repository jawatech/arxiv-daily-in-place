{"2411.06835": {"publish_time": "2024-11-11", "title": "HarmLevelBench: Evaluating Harm-Level Compliance and the Impact of Quantization on Model Alignment", "paper_summary": "With the introduction of the transformers architecture, LLMs have\nrevolutionized the NLP field with ever more powerful models. Nevertheless,\ntheir development came up with several challenges. The exponential growth in\ncomputational power and reasoning capabilities of language models has\nheightened concerns about their security. As models become more powerful,\nensuring their safety has become a crucial focus in research. This paper aims\nto address gaps in the current literature on jailbreaking techniques and the\nevaluation of LLM vulnerabilities. Our contributions include the creation of a\nnovel dataset designed to assess the harmfulness of model outputs across\nmultiple harm levels, as well as a focus on fine-grained harm-level analysis.\nUsing this framework, we provide a comprehensive benchmark of state-of-the-art\njailbreaking attacks, specifically targeting the Vicuna 13B v1.5 model.\nAdditionally, we examine how quantization techniques, such as AWQ and GPTQ,\ninfluence the alignment and robustness of models, revealing trade-offs between\nenhanced robustness with regards to transfer attacks and potential increases in\nvulnerability on direct ones. This study aims to demonstrate the influence of\nharmful input queries on the complexity of jailbreaking techniques, as well as\nto deepen our understanding of LLM vulnerabilities and improve methods for\nassessing model robustness when confronted with harmful content, particularly\nin the context of compression strategies.", "paper_summary_zh": "\u96a8\u8457Transformer\u67b6\u69cb\u7684\u5f15\u5165\uff0cLLM \u5df2\u900f\u904e\u66f4\u5f37\u5927\u7684\u6a21\u578b\u5fb9\u5e95\u6539\u8b8a NLP \u9818\u57df\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u5b83\u5011\u7684\u958b\u767c\u4ecd\u9762\u81e8\u8a31\u591a\u6311\u6230\u3002\u8a9e\u8a00\u6a21\u578b\u5728\u8a08\u7b97\u80fd\u529b\u548c\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u6307\u6578\u6210\u9577\uff0c\u5df2\u52a0\u5287\u4eba\u5011\u5c0d\u5176\u5b89\u5168\u6027\u7684\u7591\u616e\u3002\u96a8\u8457\u6a21\u578b\u8b8a\u5f97\u66f4\u5f37\u5927\uff0c\u78ba\u4fdd\u5176\u5b89\u5168\u6027\u5df2\u6210\u70ba\u7814\u7a76\u4e2d\u7684\u95dc\u9375\u7126\u9ede\u3002\u672c\u6587\u65e8\u5728\u89e3\u6c7a\u7576\u524d\u6709\u95dc\u8d8a\u7344\u6280\u8853\u548c LLM \u6f0f\u6d1e\u8a55\u4f30\u6587\u737b\u4e2d\u7684\u5dee\u8ddd\u3002\u6211\u5011\u7684\u8ca2\u737b\u5305\u62ec\u5efa\u7acb\u4e00\u500b\u65b0\u7a4e\u7684\u8cc7\u6599\u96c6\uff0c\u65e8\u5728\u8a55\u4f30\u6a21\u578b\u8f38\u51fa\u5728\u591a\u500b\u5371\u5bb3\u5c64\u7d1a\u4e2d\u7684\u5371\u5bb3\u6027\uff0c\u4ee5\u53ca\u5c08\u6ce8\u65bc\u7d30\u5fae\u7684\u5371\u5bb3\u5c64\u7d1a\u5206\u6790\u3002\u4f7f\u7528\u6b64\u67b6\u69cb\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u6700\u5148\u9032\u8d8a\u7344\u653b\u64ca\u7684\u5168\u9762\u57fa\u6e96\uff0c\u7279\u5225\u91dd\u5c0d Vicuna 13B v1.5 \u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u91cf\u5316\u6280\u8853\uff08\u4f8b\u5982 AWQ \u548c GPTQ\uff09\u5982\u4f55\u5f71\u97ff\u6a21\u578b\u7684\u5c0d\u9f4a\u548c\u7a69\u5065\u6027\uff0c\u63ed\u793a\u4e86\u5728\u91dd\u5c0d\u8f49\u79fb\u653b\u64ca\u7684\u589e\u5f37\u7a69\u5065\u6027\u8207\u76f4\u63a5\u653b\u64ca\u7684\u6f5b\u5728\u6f0f\u6d1e\u589e\u52a0\u4e4b\u9593\u7684\u6b0a\u8861\u3002\u672c\u7814\u7a76\u65e8\u5728\u8b49\u660e\u6709\u5bb3\u8f38\u5165\u67e5\u8a62\u5c0d\u8d8a\u7344\u6280\u8853\u8907\u96dc\u6027\u7684\u5f71\u97ff\uff0c\u4ee5\u53ca\u52a0\u6df1\u6211\u5011\u5c0d LLM \u6f0f\u6d1e\u7684\u7406\u89e3\uff0c\u4e26\u6539\u5584\u5728\u9762\u5c0d\u6709\u5bb3\u5167\u5bb9\u6642\u8a55\u4f30\u6a21\u578b\u7a69\u5065\u6027\u7684\u65b9\u6cd5\uff0c\u7279\u5225\u662f\u5728\u58d3\u7e2e\u7b56\u7565\u7684\u80cc\u666f\u4e0b\u3002", "author": "Yannis Belkhiter et.al.", "authors": "Yannis Belkhiter, Giulio Zizzo, Sergio Maffeis", "id": "2411.06835v1", "paper_url": "http://arxiv.org/abs/2411.06835v1", "repo": "null"}}