{"2408.07846": {"publish_time": "2024-08-14", "title": "A System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites", "paper_summary": "Unit tests represent the most basic level of testing within the software\ntesting lifecycle and are crucial to ensuring software correctness. Designing\nand creating unit tests is a costly and labor-intensive process that is ripe\nfor automation. Recently, Large Language Models (LLMs) have been applied to\nvarious aspects of software development, including unit test generation.\nAlthough several empirical studies evaluating LLMs' capabilities in test code\ngeneration exist, they primarily focus on simple scenarios, such as the\nstraightforward generation of unit tests for individual methods. These\nevaluations often involve independent and small-scale test units, providing a\nlimited view of LLMs' performance in real-world software development scenarios.\nMoreover, previous studies do not approach the problem at a suitable scale for\nreal-life applications. Generated unit tests are often evaluated via manual\nintegration into the original projects, a process that limits the number of\ntests executed and reduces overall efficiency. To address these gaps, we have\ndeveloped an approach for generating and evaluating more real-life complexity\ntest suites. Our approach focuses on class-level test code generation and\nautomates the entire process from test generation to test assessment. In this\nwork, we present \\textsc{AgoneTest}: an automated system for generating test\nsuites for Java projects and a comprehensive and principled methodology for\nevaluating the generated test suites. Starting from a state-of-the-art dataset\n(i.e., \\textsc{Methods2Test}), we built a new dataset for comparing\nhuman-written tests with those generated by LLMs. Our key contributions include\na scalable automated software system, a new dataset, and a detailed methodology\nfor evaluating test quality.", "paper_summary_zh": "\u55ae\u5143\u6e2c\u8a66\u4ee3\u8868\u8edf\u9ad4\u6e2c\u8a66\u751f\u547d\u9031\u671f\u4e2d\u6e2c\u8a66\u7684\u6700\u57fa\u672c\u5c64\u7d1a\uff0c\u5c0d\u65bc\u78ba\u4fdd\u8edf\u9ad4\u6b63\u78ba\u6027\u81f3\u95dc\u91cd\u8981\u3002\u8a2d\u8a08\u548c\u5efa\u7acb\u55ae\u5143\u6e2c\u8a66\u662f\u4e00\u9805\u6210\u672c\u9ad8\u6602\u4e14\u52de\u529b\u5bc6\u96c6\u7684\u7a0b\u5e8f\uff0c\u975e\u5e38\u9069\u5408\u81ea\u52d5\u5316\u3002\u6700\u8fd1\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u61c9\u7528\u65bc\u8edf\u9ad4\u958b\u767c\u7684\u5404\u500b\u65b9\u9762\uff0c\u5305\u62ec\u55ae\u5143\u6e2c\u8a66\u7522\u751f\u3002\u5118\u7ba1\u6709\u5e7e\u9805\u5be6\u8b49\u7814\u7a76\u8a55\u4f30 LLM \u5728\u6e2c\u8a66\u7a0b\u5f0f\u78bc\u7522\u751f\u4e2d\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u4e3b\u8981\u8457\u91cd\u65bc\u7c21\u55ae\u7684\u5834\u666f\uff0c\u4f8b\u5982\u91dd\u5c0d\u500b\u5225\u65b9\u6cd5\u7522\u751f\u55ae\u5143\u6e2c\u8a66\u3002\u9019\u4e9b\u8a55\u4f30\u901a\u5e38\u6d89\u53ca\u7368\u7acb\u4e14\u5c0f\u898f\u6a21\u7684\u6e2c\u8a66\u55ae\u5143\uff0c\u63d0\u4f9b LLM \u5728\u771f\u5be6\u8edf\u9ad4\u958b\u767c\u5834\u666f\u4e2d\u6548\u80fd\u7684\u6709\u9650\u8996\u91ce\u3002\u6b64\u5916\uff0c\u5148\u524d\u7684\u7814\u7a76\u4e26\u672a\u4ee5\u9069\u5408\u5be6\u969b\u61c9\u7528\u7a0b\u5f0f\u898f\u6a21\u7684\u65b9\u5f0f\u4f86\u63a2\u8a0e\u554f\u984c\u3002\u7522\u751f\u7684\u55ae\u5143\u6e2c\u8a66\u901a\u5e38\u900f\u904e\u624b\u52d5\u6574\u5408\u5230\u539f\u59cb\u5c08\u6848\u4e2d\u4f86\u8a55\u4f30\uff0c\u9019\u500b\u7a0b\u5e8f\u9650\u5236\u4e86\u57f7\u884c\u6e2c\u8a66\u7684\u6578\u91cf\uff0c\u4e26\u964d\u4f4e\u4e86\u6574\u9ad4\u6548\u7387\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u5dee\u8ddd\uff0c\u6211\u5011\u5df2\u958b\u767c\u51fa\u4e00\u7a2e\u65b9\u6cd5\u4f86\u7522\u751f\u548c\u8a55\u4f30\u66f4\u771f\u5be6\u8907\u96dc\u6027\u7684\u6e2c\u8a66\u5957\u4ef6\u3002\u6211\u5011\u7684\u505a\u6cd5\u8457\u91cd\u65bc\u985e\u5225\u5c64\u7d1a\u7684\u6e2c\u8a66\u7a0b\u5f0f\u78bc\u7522\u751f\uff0c\u4e26\u81ea\u52d5\u5316\u5f9e\u6e2c\u8a66\u7522\u751f\u5230\u6e2c\u8a66\u8a55\u4f30\u7684\u6574\u500b\u7a0b\u5e8f\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa \\textsc{AgoneTest}\uff1a\u4e00\u500b\u7528\u65bc\u70ba Java \u5c08\u6848\u7522\u751f\u6e2c\u8a66\u5957\u4ef6\u7684\u81ea\u52d5\u5316\u7cfb\u7d71\uff0c\u4ee5\u53ca\u4e00\u500b\u7528\u65bc\u8a55\u4f30\u7522\u751f\u6e2c\u8a66\u5957\u4ef6\u7684\u5168\u9762\u4e14\u6709\u539f\u5247\u7684\u65b9\u6cd5\u3002\u5f9e\u6700\u5148\u9032\u7684\u8cc7\u6599\u96c6 (\u5373 \\textsc{Methods2Test}) \u958b\u59cb\uff0c\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b\u65b0\u7684\u8cc7\u6599\u96c6\uff0c\u7528\u65bc\u6bd4\u8f03\u4eba\u70ba\u7de8\u5beb\u7684\u6e2c\u8a66\u8207 LLM \u7522\u751f\u7684\u6e2c\u8a66\u3002\u6211\u5011\u7684\u95dc\u9375\u8ca2\u737b\u5305\u62ec\u4e00\u500b\u53ef\u64f4\u5145\u7684\u81ea\u52d5\u5316\u8edf\u9ad4\u7cfb\u7d71\u3001\u4e00\u500b\u65b0\u7684\u8cc7\u6599\u96c6\uff0c\u4ee5\u53ca\u4e00\u500b\u7528\u65bc\u8a55\u4f30\u6e2c\u8a66\u54c1\u8cea\u7684\u8a73\u7d30\u65b9\u6cd5\u3002", "author": "Andrea Lops et.al.", "authors": "Andrea Lops, Fedelucio Narducci, Azzurra Ragone, Michelantonio Trizio, Claudio Bartolini", "id": "2408.07846v1", "paper_url": "http://arxiv.org/abs/2408.07846v1", "repo": "null"}}