{"2412.18544": {"publish_time": "2024-12-24", "title": "Consistency Checks for Language Model Forecasters", "paper_summary": "Forecasting is a task that is difficult to evaluate: the ground truth can\nonly be known in the future. Recent work showing LLM forecasters rapidly\napproaching human-level performance begs the question: how can we benchmark and\nevaluate these forecasters instantaneously? Following the consistency check\nframework, we measure the performance of forecasters in terms of the\nconsistency of their predictions on different logically-related questions. We\npropose a new, general consistency metric based on arbitrage: for example, if a\nforecasting AI illogically predicts that both the Democratic and Republican\nparties have 60% probability of winning the 2024 US presidential election, an\narbitrageur can trade against the forecaster's predictions and make a profit.\nWe build an automated evaluation system that generates a set of base questions,\ninstantiates consistency checks from these questions, elicits the predictions\nof the forecaster, and measures the consistency of the predictions. We then\nbuild a standard, proper-scoring-rule forecasting benchmark, and show that our\n(instantaneous) consistency metrics correlate with LLM forecasters' ground\ntruth Brier scores (which are only known in the future). We also release a\nconsistency benchmark that resolves in 2028, providing a long-term evaluation\ntool for forecasting.", "paper_summary_zh": "\u9810\u6e2c\u662f\u4e00\u9805\u96e3\u4ee5\u8a55\u4f30\u7684\u4efb\u52d9\uff1a\u53ea\u6709\u5728\u672a\u4f86\u624d\u80fd\u77e5\u9053\u771f\u5be6\u60c5\u6cc1\u3002\u6700\u8fd1\u7684\u7814\u7a76\u986f\u793a\uff0cLLM \u9810\u6e2c\u54e1\u6b63\u8fc5\u901f\u63a5\u8fd1\u4eba\u985e\u5c64\u7d1a\u7684\u8868\u73fe\uff0c\u9019\u5f15\u767c\u4e86\u4e00\u500b\u554f\u984c\uff1a\u6211\u5011\u5982\u4f55\u7acb\u5373\u5c0d\u9019\u4e9b\u9810\u6e2c\u54e1\u9032\u884c\u57fa\u6e96\u6e2c\u8a66\u548c\u8a55\u4f30\uff1f\u9075\u5faa\u4e00\u81f4\u6027\u6aa2\u67e5\u67b6\u69cb\uff0c\u6211\u5011\u6839\u64da\u9810\u6e2c\u54e1\u5728\u4e0d\u540c\u908f\u8f2f\u76f8\u95dc\u554f\u984c\u4e0a\u7684\u9810\u6e2c\u4e00\u81f4\u6027\u4f86\u8861\u91cf\u5176\u8868\u73fe\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u3001\u57fa\u65bc\u5957\u5229\u7684\u901a\u7528\u4e00\u81f4\u6027\u6307\u6a19\uff1a\u4f8b\u5982\uff0c\u5982\u679c\u4e00\u500b\u9810\u6e2c AI \u6c92\u6709\u908f\u8f2f\u5730\u9810\u6e2c\u6c11\u4e3b\u9ee8\u548c\u5171\u548c\u9ee8\u5728 2024 \u5e74\u7f8e\u570b\u7e3d\u7d71\u5927\u9078\u4e2d\u90fd\u6709 60% \u7684\u7372\u52dd\u6a5f\u7387\uff0c\u5957\u5229\u8005\u53ef\u4ee5\u91dd\u5c0d\u9810\u6e2c\u54e1\u7684\u9810\u6e2c\u9032\u884c\u4ea4\u6613\u4e26\u7372\u5229\u3002\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b\u81ea\u52d5\u5316\u8a55\u4f30\u7cfb\u7d71\uff0c\u7528\u65bc\u7522\u751f\u4e00\u7d44\u57fa\u672c\u554f\u984c\uff0c\u5f9e\u9019\u4e9b\u554f\u984c\u4e2d\u5be6\u4f8b\u5316\u4e00\u81f4\u6027\u6aa2\u67e5\uff0c\u5f15\u51fa\u9810\u6e2c\u54e1\u7684\u9810\u6e2c\uff0c\u4e26\u8861\u91cf\u9810\u6e2c\u7684\u4e00\u81f4\u6027\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b\u6a19\u6e96\u7684\u3001\u9069\u7576\u8a08\u5206\u898f\u5247\u9810\u6e2c\u57fa\u6e96\uff0c\u4e26\u8868\u660e\u6211\u5011\u7684\uff08\u5373\u6642\uff09\u4e00\u81f4\u6027\u6307\u6a19\u8207 LLM \u9810\u6e2c\u54e1\u7684\u771f\u5be6\u5e03\u8cf4\u723e\u5f97\u5206\uff08\u50c5\u5728\u672a\u4f86\u624d\u77e5\u9053\uff09\u76f8\u95dc\u3002\u6211\u5011\u9084\u767c\u5e03\u4e86\u4e00\u500b\u5728 2028 \u5e74\u89e3\u6c7a\u7684\u4e00\u81f4\u6027\u57fa\u6e96\uff0c\u63d0\u4f9b\u4e86\u4e00\u500b\u7528\u65bc\u9810\u6e2c\u7684\u9577\u671f\u8a55\u4f30\u5de5\u5177\u3002", "author": "Daniel Paleka et.al.", "authors": "Daniel Paleka, Abhimanyu Pallavi Sudhir, Alejandro Alvarez, Vineeth Bhat, Adam Shen, Evan Wang, Florian Tram\u00e8r", "id": "2412.18544v1", "paper_url": "http://arxiv.org/abs/2412.18544v1", "repo": "null"}}