{"2410.12443": {"publish_time": "2024-10-16", "title": "Reconstruction of Differentially Private Text Sanitization via Large Language Models", "paper_summary": "Differential privacy (DP) is the de facto privacy standard against privacy\nleakage attacks, including many recently discovered ones against large language\nmodels (LLMs). However, we discovered that LLMs could reconstruct the\naltered/removed privacy from given DP-sanitized prompts. We propose two attacks\n(black-box and white-box) based on the accessibility to LLMs and show that LLMs\ncould connect the pair of DP-sanitized text and the corresponding private\ntraining data of LLMs by giving sample text pairs as instructions (in the\nblack-box attacks) or fine-tuning data (in the white-box attacks). To\nillustrate our findings, we conduct comprehensive experiments on modern LLMs\n(e.g., LLaMA-2, LLaMA-3, ChatGPT-3.5, ChatGPT-4, ChatGPT-4o, Claude-3,\nClaude-3.5, OPT, GPT-Neo, GPT-J, Gemma-2, and Pythia) using commonly used\ndatasets (such as WikiMIA, Pile-CC, and Pile-Wiki) against both word-level and\nsentence-level DP. The experimental results show promising recovery rates,\ne.g., the black-box attacks against the word-level DP over WikiMIA dataset gave\n72.18% on LLaMA-2 (70B), 82.39% on LLaMA-3 (70B), 75.35% on Gemma-2, 91.2% on\nChatGPT-4o, and 94.01% on Claude-3.5 (Sonnet). More urgently, this study\nindicates that these well-known LLMs have emerged as a new security risk for\nexisting DP text sanitization approaches in the current environment.", "paper_summary_zh": "\u5dee\u5206\u96b1\u79c1 (DP) \u662f\u91dd\u5c0d\u96b1\u79c1\u5916\u6d29\u653b\u64ca\u7684\u4e8b\u5be6\u96b1\u79c1\u6a19\u6e96\uff0c\u5305\u62ec\u6700\u8fd1\u91dd\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u767c\u73fe\u7684\u8a31\u591a\u653b\u64ca\u3002\u7136\u800c\uff0c\u6211\u5011\u767c\u73fe LLM \u53ef\u4ee5\u5f9e\u7d66\u5b9a\u7684 DP \u6e05\u7406\u63d0\u793a\u4e2d\u91cd\u5efa\u5df2\u8b8a\u66f4/\u79fb\u9664\u7684\u96b1\u79c1\u3002\u6211\u5011\u63d0\u51fa\u4e86\u5169\u7a2e\u653b\u64ca\uff08\u9ed1\u76d2\u548c\u767d\u76d2\uff09\uff0c\u57fa\u65bc\u5c0d LLM \u7684\u53ef\u8a2a\u554f\u6027\uff0c\u4e26\u5c55\u793a LLM \u53ef\u4ee5\u901a\u904e\u63d0\u4f9b\u7bc4\u4f8b\u6587\u5b57\u5c0d\u4f5c\u70ba\u6307\u4ee4\uff08\u5728\u9ed1\u76d2\u653b\u64ca\u4e2d\uff09\u6216\u5fae\u8abf\u8cc7\u6599\uff08\u5728\u767d\u76d2\u653b\u64ca\u4e2d\uff09\u4f86\u9023\u63a5 DP \u6e05\u7406\u6587\u5b57\u548c\u5c0d\u61c9\u7684 LLM \u79c1\u4eba\u8a13\u7df4\u8cc7\u6599\u3002\u70ba\u4e86\u8aaa\u660e\u6211\u5011\u7684\u767c\u73fe\uff0c\u6211\u5011\u5c0d\u73fe\u4ee3 LLM\uff08\u4f8b\u5982 LLaMA-2\u3001LLaMA-3\u3001ChatGPT-3.5\u3001ChatGPT-4\u3001ChatGPT-4o\u3001Claude-3\u3001Claude-3.5\u3001OPT\u3001GPT-Neo\u3001GPT-J\u3001Gemma-2 \u548c Pythia\uff09\u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\uff0c\u4f7f\u7528\u5e38\u7528\u7684\u8cc7\u6599\u96c6\uff08\u4f8b\u5982 WikiMIA\u3001Pile-CC \u548c Pile-Wiki\uff09\u91dd\u5c0d\u5b57\u5143\u7d1a\u548c\u53e5\u5b50\u7d1a DP\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\u51fa\u6709\u5e0c\u671b\u7684\u6062\u5fa9\u7387\uff0c\u4f8b\u5982\uff0c\u91dd\u5c0d WikiMIA \u8cc7\u6599\u96c6\u7684\u5b57\u5143\u7d1a DP \u7684\u9ed1\u76d2\u653b\u64ca\u5728 LLaMA-2 (70B) \u4e0a\u7372\u5f97 72.18%\uff0c\u5728 LLaMA-3 (70B) \u4e0a\u7372\u5f97 82.39%\uff0c\u5728 Gemma-2 \u4e0a\u7372\u5f97 75.35%\uff0c\u5728 ChatGPT-4o \u4e0a\u7372\u5f97 91.2%\uff0c\u5728 Claude-3.5 (Sonnet) \u4e0a\u7372\u5f97 94.01%\u3002\u66f4\u7dca\u6025\u7684\u662f\uff0c\u9019\u9805\u7814\u7a76\u8868\u660e\uff0c\u9019\u4e9b\u773e\u6240\u5468\u77e5\u7684 LLM \u5df2\u6210\u70ba\u7576\u524d\u74b0\u5883\u4e2d\u73fe\u6709 DP \u6587\u5b57\u6e05\u7406\u65b9\u6cd5\u7684\u65b0\u5b89\u5168\u98a8\u96aa\u3002", "author": "Shuchao Pang et.al.", "authors": "Shuchao Pang, Zhigang Lu, Haichen Wang, Peng Fu, Yongbin Zhou, Minhui Xue, Bo Li", "id": "2410.12443v1", "paper_url": "http://arxiv.org/abs/2410.12443v1", "repo": "null"}}