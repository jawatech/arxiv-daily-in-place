{"2311.02115": {"publish_time": "2023-11-03", "title": "Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging", "paper_summary": "Artificial intelligence (AI) models trained using medical images for clinical\ntasks often exhibit bias in the form of disparities in performance between\nsubgroups. Since not all sources of biases in real-world medical imaging data\nare easily identifiable, it is challenging to comprehensively assess how those\nbiases are encoded in models, and how capable bias mitigation methods are at\nameliorating performance disparities. In this article, we introduce a novel\nanalysis framework for systematically and objectively investigating the impact\nof biases in medical images on AI models. We developed and tested this\nframework for conducting controlled in silico trials to assess bias in medical\nimaging AI using a tool for generating synthetic magnetic resonance images with\nknown disease effects and sources of bias. The feasibility is showcased by\nusing three counterfactual bias scenarios to measure the impact of simulated\nbias effects on a convolutional neural network (CNN) classifier and the\nefficacy of three bias mitigation strategies. The analysis revealed that the\nsimulated biases resulted in expected subgroup performance disparities when the\nCNN was trained on the synthetic datasets. Moreover, reweighing was identified\nas the most successful bias mitigation strategy for this setup, and we\ndemonstrated how explainable AI methods can aid in investigating the\nmanifestation of bias in the model using this framework. Developing fair AI\nmodels is a considerable challenge given that many and often unknown sources of\nbiases can be present in medical imaging datasets. In this work, we present a\nnovel methodology to objectively study the impact of biases and mitigation\nstrategies on deep learning pipelines, which can support the development of\nclinical AI that is robust and responsible.", "paper_summary_zh": "<paragraph>\u4f7f\u7528\u91ab\u7642\u5f71\u50cf\u8a13\u7df4\u7684\u4eba\u5de5\u667a\u6167 (AI) \u6a21\u578b\uff0c\u7528\u65bc\u81e8\u5e8a\u4efb\u52d9\u6642\uff0c\u5e38\u6703\u5728\u6548\u80fd\u4e0a\u5c55\u73fe\u51fa\u6b21\u7fa4\u9ad4\u4e4b\u9593\u7684\u5dee\u7570\uff0c\u5f62\u6210\u504f\u898b\u3002\u7531\u65bc\u4e26\u975e\u6240\u6709\u771f\u5be6\u4e16\u754c\u91ab\u7642\u5f71\u50cf\u8cc7\u6599\u4e2d\u7684\u504f\u898b\u4f86\u6e90\u90fd\u5bb9\u6613\u8fa8\u8b58\uff0c\u56e0\u6b64\u5168\u9762\u8a55\u4f30\u9019\u4e9b\u504f\u898b\u662f\u5982\u4f55\u7de8\u78bc\u5230\u6a21\u578b\u4e2d\uff0c\u4ee5\u53ca\u504f\u898b\u7de9\u89e3\u65b9\u6cd5\u5728\u6539\u5584\u6548\u80fd\u5dee\u7570\u65b9\u9762\u7684\u80fd\u529b\uff0c\u662f\u4e00\u9805\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u5206\u6790\u67b6\u69cb\uff0c\u7528\u65bc\u7cfb\u7d71\u5316\u4e14\u5ba2\u89c0\u5730\u8abf\u67e5\u91ab\u7642\u5f71\u50cf\u4e2d\u7684\u504f\u898b\u5c0d AI \u6a21\u578b\u7684\u5f71\u97ff\u3002\u6211\u5011\u958b\u767c\u4e26\u6e2c\u8a66\u4e86\u9019\u500b\u67b6\u69cb\uff0c\u4ee5\u9032\u884c\u53d7\u63a7\u7684\u96fb\u8166\u6a21\u64ec\u8a66\u9a57\uff0c\u4f7f\u7528\u4e00\u500b\u5de5\u5177\u4f86\u8a55\u4f30\u91ab\u7642\u5f71\u50cf AI \u4e2d\u7684\u504f\u898b\uff0c\u8a72\u5de5\u5177\u7528\u65bc\u7522\u751f\u5177\u6709\u5df2\u77e5\u75be\u75c5\u5f71\u97ff\u548c\u504f\u898b\u4f86\u6e90\u7684\u5408\u6210\u78c1\u5171\u632f\u5f71\u50cf\u3002\u53ef\u884c\u6027\u900f\u904e\u4f7f\u7528\u4e09\u500b\u53cd\u4e8b\u5be6\u504f\u898b\u60c5\u5883\u4f86\u8861\u91cf\u6a21\u64ec\u504f\u898b\u6548\u61c9\u5c0d\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u5206\u985e\u5668\u548c\u4e09\u500b\u504f\u898b\u7de9\u89e3\u7b56\u7565\u7684\u5f71\u97ff\uff0c\u4e26\u5c55\u793a\u51fa\u4f86\u3002\u5206\u6790\u986f\u793a\uff0c\u7576 CNN \u5728\u5408\u6210\u8cc7\u6599\u96c6\u4e0a\u53d7\u8a13\u6642\uff0c\u6a21\u64ec\u504f\u898b\u6703\u5c0e\u81f4\u9810\u671f\u7684\u6b21\u7fa4\u9ad4\u6548\u80fd\u5dee\u7570\u3002\u6b64\u5916\uff0c\u91cd\u65b0\u52a0\u6b0a\u88ab\u8a8d\u70ba\u662f\u6b64\u8a2d\u5b9a\u4e2d\u6700\u6210\u529f\u7684\u504f\u898b\u7de9\u89e3\u7b56\u7565\uff0c\u6211\u5011\u5c55\u793a\u4e86\u89e3\u91cb\u6027 AI \u65b9\u6cd5\u5982\u4f55\u5354\u52a9\u4f7f\u7528\u9019\u500b\u67b6\u69cb\u8abf\u67e5\u6a21\u578b\u4e2d\u504f\u898b\u7684\u8868\u73fe\u3002\u958b\u767c\u516c\u5e73\u7684 AI \u6a21\u578b\u662f\u4e00\u9805\u91cd\u5927\u7684\u6311\u6230\uff0c\u56e0\u70ba\u91ab\u7642\u5f71\u50cf\u8cc7\u6599\u96c6\u4e2d\u53ef\u80fd\u5b58\u5728\u8a31\u591a\u4e14\u7d93\u5e38\u672a\u77e5\u7684\u504f\u898b\u4f86\u6e90\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u7528\u65bc\u5ba2\u89c0\u5730\u7814\u7a76\u504f\u898b\u548c\u7de9\u89e3\u7b56\u7565\u5c0d\u6df1\u5ea6\u5b78\u7fd2\u7ba1\u7dda\u7684\u5f71\u97ff\uff0c\u9019\u53ef\u4ee5\u652f\u63f4\u5065\u5168\u4e14\u8ca0\u8cac\u4efb\u7684\u81e8\u5e8a AI \u7684\u958b\u767c\u3002</paragraph>", "author": "Emma A. M. Stanley et.al.", "authors": "Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert", "id": "2311.02115v2", "paper_url": "http://arxiv.org/abs/2311.02115v2", "repo": "https://github.com/estanley16/simba"}}