{"2410.19134": {"publish_time": "2024-10-24", "title": "AlignCap: Aligning Speech Emotion Captioning to Human Preferences", "paper_summary": "Speech Emotion Captioning (SEC) has gradually become an active research task.\nThe emotional content conveyed through human speech are often complex, and\nclassifying them into fixed categories may not be enough to fully capture\nspeech emotions. Describing speech emotions through natural language may be a\nmore effective approach. However, existing SEC methods often produce\nhallucinations and lose generalization on unseen speech. To overcome these\nproblems, we propose AlignCap, which Aligning Speech Emotion Captioning to\nHuman Preferences based on large language model (LLM) with two properties: 1)\nSpeech-Text Alignment, which minimizing the divergence between the LLM's\nresponse prediction distributions for speech and text inputs using knowledge\ndistillation (KD) Regularization. 2) Human Preference Alignment, where we\ndesign Preference Optimization (PO) Regularization to eliminate factuality and\nfaithfulness hallucinations. We also extract emotional clues as a prompt for\nenriching fine-grained information under KD-Regularization. Experiments\ndemonstrate that AlignCap presents stronger performance to other\nstate-of-the-art methods on Zero-shot SEC task.", "paper_summary_zh": "\u8a9e\u97f3\u60c5\u7dd2\u6a19\u984c (SEC) \u5df2\u9010\u6f38\u6210\u70ba\u4e00\u9805\u6d3b\u8e8d\u7684\u7814\u7a76\u4efb\u52d9\u3002\n\u4eba\u985e\u8a00\u8a9e\u50b3\u9054\u7684\u60c5\u7dd2\u5167\u5bb9\u901a\u5e38\u5f88\u8907\u96dc\uff0c\n\u5c07\u5176\u5206\u985e\u70ba\u56fa\u5b9a\u985e\u5225\u53ef\u80fd\u4e0d\u8db3\u4ee5\u5b8c\u5168\u6355\u6349\n\u8a00\u8a9e\u60c5\u7dd2\u3002\u900f\u904e\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u8a00\u8a9e\u60c5\u7dd2\u53ef\u80fd\u662f\n\u4e00\u7a2e\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 SEC \u65b9\u6cd5\u7d93\u5e38\u7522\u751f\n\u5e7b\u89ba\uff0c\u4e26\u5728\u672a\u898b\u904e\u7684\u8a00\u8a9e\u4e0a\u5931\u53bb\u6982\u62ec\u6027\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\n\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 AlignCap\uff0c\u5b83\u57fa\u65bc\u5177\u6709\u5169\u500b\u7279\u6027\u7684\n\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c07\u8a00\u8a9e\u60c5\u7dd2\u6a19\u984c\u8207\u4eba\u985e\u504f\u597d\u5c0d\u9f4a\uff1a1)\n\u8a00\u8a9e\u6587\u5b57\u5c0d\u9f4a\uff0c\u5b83\u4f7f\u7528\u77e5\u8b58\u63d0\u7149 (KD) \u6b63\u5247\u5316\u6700\u5c0f\u5316 LLM\n\u7684\u56de\u61c9\u9810\u6e2c\u5206\u4f48\u8207\u8a00\u8a9e\u548c\u6587\u5b57\u8f38\u5165\u4e4b\u9593\u7684\u5dee\u7570\u30022) \u4eba\u985e\u504f\u597d\u5c0d\u9f4a\uff0c\n\u6211\u5011\u8a2d\u8a08\u4e86\u504f\u597d\u6700\u4f73\u5316 (PO) \u6b63\u5247\u5316\u4f86\u6d88\u9664\u4e8b\u5be6\u6027\u548c\n\u5fe0\u5be6\u5ea6\u5e7b\u89ba\u3002\u6211\u5011\u9084\u63d0\u53d6\u60c5\u7dd2\u7dda\u7d22\u4f5c\u70ba\u63d0\u793a\uff0c\u4ee5\u8c50\u5bcc\nKD \u6b63\u5247\u5316\u4e0b\u7684\u7d30\u7c92\u5ea6\u8cc7\u8a0a\u3002\u5be6\u9a57\u8b49\u660e\uff0cAlignCap \u5728\n\u96f6\u6b21 SEC \u4efb\u52d9\u4e0a\u8868\u73fe\u51fa\u6bd4\u5176\u4ed6\u6700\u5148\u9032\u65b9\u6cd5\u66f4\u5f37\u7684\u6548\u80fd\u3002", "author": "Ziqi Liang et.al.", "authors": "Ziqi Liang, Haoxiang Shi, Hanhui Chen", "id": "2410.19134v1", "paper_url": "http://arxiv.org/abs/2410.19134v1", "repo": "null"}}