# arxiv-daily
 Automated deployment @ 2024-06-19 08:56:08 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-17**|**mDPO: Conditional Preference Optimization for Multimodal Large Language Models**|Fei Wang et.al.|[2406.11839v1](http://arxiv.org/abs/2406.11839v1)|null|
|**2024-06-17**|**MMDU: A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs**|Ziyu Liu et.al.|[2406.11833v1](http://arxiv.org/abs/2406.11833v1)|[link](https://github.com/liuziyu77/mmdu)|
|**2024-06-17**|**Language Modeling with Editable External Knowledge**|Belinda Z. Li et.al.|[2406.11830v1](http://arxiv.org/abs/2406.11830v1)|[link](https://github.com/belindal/erase)|
|**2024-06-17**|**WPO: Enhancing RLHF with Weighted Preference Optimization**|Wenxuan Zhou et.al.|[2406.11827v1](http://arxiv.org/abs/2406.11827v1)|[link](https://github.com/wzhouad/wpo)|
|**2024-06-17**|**On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning**|Geewook Kim et.al.|[2406.11823v1](http://arxiv.org/abs/2406.11823v1)|[link](https://github.com/naver-ai/elva)|
|**2024-06-17**|**Embodied Instruction Following in Unknown Environments**|Zhenyu Wu et.al.|[2406.11818v1](http://arxiv.org/abs/2406.11818v1)|null|
|**2024-06-17**|**Iterative Length-Regularized Direct Preference Optimization: A Case Study on Improving 7B Language Models to GPT-4 Level**|Jie Liu et.al.|[2406.11817v1](http://arxiv.org/abs/2406.11817v1)|null|
|**2024-06-17**|**How Do Large Language Models Acquire Factual Knowledge During Pretraining?**|Hoyeon Chang et.al.|[2406.11813v1](http://arxiv.org/abs/2406.11813v1)|null|
|**2024-06-17**|**RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen Reference Content**|Joao Monteiro et.al.|[2406.11811v1](http://arxiv.org/abs/2406.11811v1)|null|
|**2024-06-17**|**Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations**|Rima Hazra et.al.|[2406.11801v1](http://arxiv.org/abs/2406.11801v1)|[link](https://github.com/declare-lab/safety-arithmetic)|
|**2024-06-17**|**DataComp-LM: In search of the next generation of training sets for language models**|Jeffrey Li et.al.|[2406.11794v1](http://arxiv.org/abs/2406.11794v1)|null|
|**2024-06-17**|**A Brief Survey on Leveraging Large Scale Vision Models for Enhanced Robot Grasping**|Abhi Kamboj et.al.|[2406.11786v1](http://arxiv.org/abs/2406.11786v1)|null|
|**2024-06-17**|**CELL your Model: Contrastive Explanation Methods for Large Language Models**|Ronny Luss et.al.|[2406.11785v1](http://arxiv.org/abs/2406.11785v1)|null|
|**2024-06-17**|**MDCR: A Dataset for Multi-Document Conditional Reasoning**|Peter Baile Chen et.al.|[2406.11784v1](http://arxiv.org/abs/2406.11784v1)|null|
|**2024-06-17**|**Split, Unlearn, Merge: Leveraging Data Attributes for More Effective Unlearning in LLMs**|Swanand Ravindra Kadhe et.al.|[2406.11780v1](http://arxiv.org/abs/2406.11780v1)|null|
|**2024-06-17**|**Improving Multi-Agent Debate with Sparse Communication Topology**|Yunxuan Li et.al.|[2406.11776v1](http://arxiv.org/abs/2406.11776v1)|null|
|**2024-06-17**|**Task Me Anything**|Jieyu Zhang et.al.|[2406.11775v1](http://arxiv.org/abs/2406.11775v1)|[link](https://github.com/jieyuz2/taskmeanything)|
|**2024-06-17**|**GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities**|Sreyan Ghosh et.al.|[2406.11768v1](http://arxiv.org/abs/2406.11768v1)|null|
|**2024-06-17**|**STAR: SocioTechnical Approach to Red Teaming Language Models**|Laura Weidinger et.al.|[2406.11757v1](http://arxiv.org/abs/2406.11757v1)|null|
|**2024-06-17**|**DustNet: skillful neural network predictions of Saharan dust**|Trish E. Nowak et.al.|[2406.11754v1](http://arxiv.org/abs/2406.11754v1)|null|
|**2024-06-17**|**A Semantic-based Layer Freezing Approach to Efficient Fine-Tuning of Language Models**|Jian Gu et.al.|[2406.11753v1](http://arxiv.org/abs/2406.11753v1)|null|
|**2024-06-17**|**Multi-Layer Ranking with Large Language Models for News Source Recommendation**|Wenjia Zhang et.al.|[2406.11745v1](http://arxiv.org/abs/2406.11745v1)|null|
|**2024-06-17**|**Transcendence: Generative Models Can Outperform The Experts That Train Them**|Edwin Zhang et.al.|[2406.11741v1](http://arxiv.org/abs/2406.11741v1)|null|
|**2024-06-17**|**Imagination Policy: Using Generative Point Cloud Models for Learning Manipulation Policies**|Haojie Huang et.al.|[2406.11740v1](http://arxiv.org/abs/2406.11740v1)|null|
|**2024-06-17**|**Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models**|Fangzhi Xu et.al.|[2406.11736v1](http://arxiv.org/abs/2406.11736v1)|null|
|**2024-06-17**|**1000 African Voices: Advancing inclusive multi-speaker multi-accent speech synthesis**|Sewade Ogun et.al.|[2406.11727v1](http://arxiv.org/abs/2406.11727v1)|null|
|**2024-06-17**|**Zero-Shot Generalization during Instruction Tuning: Insights from Similarity and Granularity**|Bingxiang He et.al.|[2406.11721v1](http://arxiv.org/abs/2406.11721v1)|[link](https://github.com/hbx-hbx/dynamics_of_zero-shot_generalization)|
|**2024-06-17**|**Refusal in Language Models Is Mediated by a Single Direction**|Andy Arditi et.al.|[2406.11717v1](http://arxiv.org/abs/2406.11717v1)|null|
|**2024-06-17**|**Measuring memorization in RLHF for code completion**|Aneesh Pappu et.al.|[2406.11715v1](http://arxiv.org/abs/2406.11715v1)|null|
|**2024-06-17**|**Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging**|Priyanka Kargupta et.al.|[2406.11709v1](http://arxiv.org/abs/2406.11709v1)|null|
|**2024-06-17**|**Prompts as Auto-Optimized Training Hyperparameters: Training Best-in-Class IR Models from Scratch with 10 Gold Labels**|Jasper Xian et.al.|[2406.11706v1](http://arxiv.org/abs/2406.11706v1)|null|
|**2024-06-17**|**Nemotron-4 340B Technical Report**|Nvidia et.al.|[2406.11704v1](http://arxiv.org/abs/2406.11704v1)|[link](https://github.com/nvidia/nemo-aligner)|
|**2024-06-17**|**Meta Reasoning for Large Language Models**|Peizhong Gao et.al.|[2406.11698v1](http://arxiv.org/abs/2406.11698v1)|null|
|**2024-06-17**|**Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs**|Krista Opsahl-Ong et.al.|[2406.11695v1](http://arxiv.org/abs/2406.11695v1)|[link](https://github.com/stanfordnlp/dspy)|
|**2024-06-17**|**Tokenization Falling Short: The Curse of Tokenization**|Yekun Chai et.al.|[2406.11687v1](http://arxiv.org/abs/2406.11687v1)|null|
|**2024-06-17**|**HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing**|Jing Chen et.al.|[2406.11683v1](http://arxiv.org/abs/2406.11683v1)|null|
|**2024-06-17**|**Knowledge-to-Jailbreak: One Knowledge Point Worth One Attack**|Shangqing Tu et.al.|[2406.11682v1](http://arxiv.org/abs/2406.11682v1)|[link](https://github.com/thu-keg/knowledge-to-jailbreak)|
|**2024-06-17**|**R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models**|Shangqing Tu et.al.|[2406.11681v1](http://arxiv.org/abs/2406.11681v1)|[link](https://github.com/thu-keg/r-eval)|
|**2024-06-17**|**TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy**|Yiqun Chen et.al.|[2406.11678v1](http://arxiv.org/abs/2406.11678v1)|[link](https://github.com/chenyiqun/TourRank)|
|**2024-06-17**|**BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models**|Yibin Wang et.al.|[2406.11675v1](http://arxiv.org/abs/2406.11675v1)|null|
|**2024-06-17**|**Endor: Hardware-Friendly Sparse Format for Offloaded LLM Inference**|Donghyeon Joo et.al.|[2406.11674v1](http://arxiv.org/abs/2406.11674v1)|null|
|**2024-06-17**|**Benchmarking of LLM Detection: Comparing Two Competing Approaches**|Thorsten Pr√∂hl et.al.|[2406.11670v1](http://arxiv.org/abs/2406.11670v1)|null|
|**2024-06-17**|**"Not Aligned" is Not "Malicious": Being Careful about Hallucinations of Large Language Models' Jailbreak**|Lingrui Mei et.al.|[2406.11668v1](http://arxiv.org/abs/2406.11668v1)|[link](https://github.com/Meirtz/BabyBLUE-llm)|
|**2024-06-17**|**See It from My Perspective: Diagnosing the Western Cultural Bias of Large Vision-Language Models in Image Understanding**|Amith Ananthram et.al.|[2406.11665v1](http://arxiv.org/abs/2406.11665v1)|[link](https://github.com/amith-ananthram/see-it-from-my-perspective)|
|**2024-06-17**|**Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting**|Sagnik Mukherjee et.al.|[2406.11661v1](http://arxiv.org/abs/2406.11661v1)|null|
|**2024-06-17**|**Can LLM be a Personalized Judge?**|Yijiang River Dong et.al.|[2406.11657v1](http://arxiv.org/abs/2406.11657v1)|[link](https://github.com/dong-river/personalized-judge)|
|**2024-06-17**|**A Two-dimensional Zero-shot Dialogue State Tracking Evaluation Method using GPT-4**|Ming Gu et.al.|[2406.11651v1](http://arxiv.org/abs/2406.11651v1)|[link](https://github.com/SLEEPWALKERG/LLM-DST-EVAL)|
|**2024-06-17**|**YOLO-FEDER FusionNet: A Novel Deep Learning Architecture for Drone Detection**|Tamara R. Lenhard et.al.|[2406.11641v1](http://arxiv.org/abs/2406.11641v1)|null|
|**2024-06-17**|**Linear Bellman Completeness Suffices for Efficient Online Reinforcement Learning with Few Actions**|Noah Golowich et.al.|[2406.11640v2](http://arxiv.org/abs/2406.11640v2)|null|
|**2024-06-17**|**MASAI: Modular Architecture for Software-engineering AI Agents**|Daman Arora et.al.|[2406.11638v1](http://arxiv.org/abs/2406.11638v1)|null|
|**2024-06-17**|**The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance**|Kyle Moore et.al.|[2406.11634v1](http://arxiv.org/abs/2406.11634v1)|null|
|**2024-06-17**|**Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation**|Boxuan Lyu et.al.|[2406.11632v1](http://arxiv.org/abs/2406.11632v1)|null|
|**2024-06-17**|**Can Many-Shot In-Context Learning Help Long-Context LLM Judges? See More, Judge Better!**|Mingyang Song et.al.|[2406.11629v1](http://arxiv.org/abs/2406.11629v1)|[link](https://github.com/nick7nlp/SeeMoreJudgeBetter)|
|**2024-06-17**|**Words in Motion: Representation Engineering for Motion Forecasting**|Omer Sahin Tas et.al.|[2406.11624v1](http://arxiv.org/abs/2406.11624v1)|[link](https://github.com/kit-mrt/future-motion)|
|**2024-06-17**|**Building Knowledge-Guided Lexica to Model Cultural Variation**|Shreya Havaldar et.al.|[2406.11622v1](http://arxiv.org/abs/2406.11622v1)|null|
|**2024-06-17**|**DELLA-Merging: Reducing Interference in Model Merging through Magnitude-Based Sampling**|Pala Tej Deep et.al.|[2406.11617v1](http://arxiv.org/abs/2406.11617v1)|[link](https://github.com/declare-lab/della)|
|**2024-06-17**|**Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces**|Yihuai Hong et.al.|[2406.11614v1](http://arxiv.org/abs/2406.11614v1)|[link](https://github.com/yihuaihong/conceptvectors)|
|**2024-06-17**|**Long Code Arena: a Set of Benchmarks for Long-Context Code Models**|Egor Bogomolov et.al.|[2406.11612v1](http://arxiv.org/abs/2406.11612v1)|[link](https://github.com/jetbrains-research/lca-baselines)|
|**2024-06-17**|**Understanding "Democratization" in NLP and ML Research**|Arjun Subramonian et.al.|[2406.11598v1](http://arxiv.org/abs/2406.11598v1)|[link](https://github.com/ArjunSubramonian/democratization-nlp)|
|**2024-06-17**|**CoSQA+: Enhancing Code Search Dataset with Matching Code**|Jing Gong et.al.|[2406.11589v1](http://arxiv.org/abs/2406.11589v1)|[link](https://github.com/DeepSoftwareAnalytics/CoSQA_Plus)|
|**2024-06-17**|**Style Transfer with Multi-iteration Preference Optimization**|Shuai Liu et.al.|[2406.11581v1](http://arxiv.org/abs/2406.11581v1)|null|
|**2024-06-17**|**Error Span Annotation: A Balanced Approach for Human Evaluation of Machine Translation**|Tom Kocmi et.al.|[2406.11580v1](http://arxiv.org/abs/2406.11580v1)|[link](https://github.com/wmt-conference/ErrorSpanAnnotations)|
|**2024-06-17**|**Mathematical Entities: Corpora and Benchmarks**|Jacob Collard et.al.|[2406.11577v1](http://arxiv.org/abs/2406.11577v1)|null|
|**2024-06-17**|**Towards an End-to-End Framework for Invasive Brain Signal Decoding with Large Language Models**|Sheng Feng et.al.|[2406.11568v1](http://arxiv.org/abs/2406.11568v1)|[link](https://github.com/fsfrancis15/brainllm)|
|**2024-06-17**|**Quaternion Generative Adversarial Neural Networks and Applications to Color Image Inpainting**|Duan Wang et.al.|[2406.11567v1](http://arxiv.org/abs/2406.11567v1)|null|
|**2024-06-17**|**MEMLA: Enhancing Multilingual Knowledge Editing with Neuron-Masked Low-Rank Adaptation**|Jiakuan Xie et.al.|[2406.11566v1](http://arxiv.org/abs/2406.11566v1)|null|
|**2024-06-17**|**Extrinsic Evaluation of Cultural Competence in Large Language Models**|Shaily Bhatt et.al.|[2406.11565v1](http://arxiv.org/abs/2406.11565v1)|null|
|**2024-06-17**|**Input Conditioned Graph Generation for Language Agents**|Lukas Vierling et.al.|[2406.11555v1](http://arxiv.org/abs/2406.11555v1)|[link](https://github.com/lukasvierling/dynamicgptswarm)|
|**2024-06-17**|**AIC MLLM: Autonomous Interactive Correction MLLM for Robust Robotic Manipulation**|Chuyan Xiong et.al.|[2406.11548v1](http://arxiv.org/abs/2406.11548v1)|null|
|**2024-06-17**|**GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations**|Rick Wilming et.al.|[2406.11547v1](http://arxiv.org/abs/2406.11547v1)|[link](https://github.com/braindatalab/gecobench)|
|**2024-06-17**|**GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement**|Yifan Yang et.al.|[2406.11546v1](http://arxiv.org/abs/2406.11546v1)|[link](https://github.com/SpeechColab/GigaSpeech2)|
|**2024-06-17**|**Do Parameters Reveal More than Loss for Membership Inference?**|Anshuman Suri et.al.|[2406.11544v1](http://arxiv.org/abs/2406.11544v1)|[link](https://github.com/iamgroot42/iha_hild)|
|**2024-06-17**|**Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**|Artur Jurgas et.al.|[2406.11538v1](http://arxiv.org/abs/2406.11538v1)|null|
|**2024-06-17**|**Explainable Artificial Intelligence and Multicollinearity : A Mini Review of Current Approaches**|Ahmed M Salih et.al.|[2406.11524v1](http://arxiv.org/abs/2406.11524v1)|[link](https://github.com/christophM/paper_conditional_subgroups)|
|**2024-06-17**|**FullCert: Deterministic End-to-End Certification for Training and Inference of Neural Networks**|Tobias Lorenz et.al.|[2406.11522v1](http://arxiv.org/abs/2406.11522v1)|null|
|**2024-06-17**|**Revisiting Spurious Correlation in Domain Generalization**|Bin Qin et.al.|[2406.11517v1](http://arxiv.org/abs/2406.11517v1)|null|
|**2024-06-17**|**Counterfactual Debating with Preset Stances for Hallucination Elimination of LLMs**|Yi Fang et.al.|[2406.11514v1](http://arxiv.org/abs/2406.11514v1)|null|
|**2024-06-17**|**On the Feasibility of Fidelity$^-$ for Graph Pruning**|Yong-Min Shin et.al.|[2406.11504v1](http://arxiv.org/abs/2406.11504v1)|null|
|**2024-06-17**|**GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation**|Shihao Cai et.al.|[2406.11503v1](http://arxiv.org/abs/2406.11503v1)|null|
|**2024-06-17**|**Teleporter Theory: A General and Simple Approach for Modeling Cross-World Counterfactual Causality**|Jiangmeng Li et.al.|[2406.11501v2](http://arxiv.org/abs/2406.11501v2)|null|
|**2024-06-17**|**CrAM: Credibility-Aware Attention Modification in LLMs for Combating Misinformation in RAG**|Boyi Deng et.al.|[2406.11497v1](http://arxiv.org/abs/2406.11497v1)|null|
|**2024-06-17**|**Analysing zero-shot temporal relation extraction on clinical notes using temporal consistency**|Vasiliki Kougia et.al.|[2406.11486v1](http://arxiv.org/abs/2406.11486v1)|null|
|**2024-06-17**|**Constrained Reinforcement Learning with Average Reward Objective: Model-Based and Model-Free Algorithms**|Vaneet Aggarwal et.al.|[2406.11481v1](http://arxiv.org/abs/2406.11481v1)|null|
|**2024-06-17**|**Vocabulary Expansion for Low-resource Cross-lingual Transfer**|Atsuki Yamaguchi et.al.|[2406.11477v1](http://arxiv.org/abs/2406.11477v1)|null|
|**2024-06-17**|**How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment**|Heyan Huang et.al.|[2406.11474v1](http://arxiv.org/abs/2406.11474v1)|null|
|**2024-06-17**|**Promises, Outlooks and Challenges of Diffusion Language Modeling**|Justin Deschenaux et.al.|[2406.11473v1](http://arxiv.org/abs/2406.11473v1)|null|
|**2024-06-17**|**Automating Easy Read Text Segmentation**|Jes√∫s Calleja et.al.|[2406.11464v1](http://arxiv.org/abs/2406.11464v1)|null|
|**2024-06-17**|**TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation**|Jinyuan Fang et.al.|[2406.11460v1](http://arxiv.org/abs/2406.11460v1)|[link](https://github.com/jyfang6/trace)|
|**2024-06-17**|**Adaptive Reinforcement Learning Planning: Harnessing Large Language Models for Complex Information Extraction**|Zepeng Ding et.al.|[2406.11455v1](http://arxiv.org/abs/2406.11455v1)|null|
|**2024-06-17**|**GPT-Powered Elicitation Interview Script Generator for Requirements Engineering Training**|Binnur G√∂rer et.al.|[2406.11439v1](http://arxiv.org/abs/2406.11439v1)|null|
|**2024-06-17**|**Analysing the Behaviour of Tree-Based Neural Networks in Regression Tasks**|Peter Samoaa et.al.|[2406.11437v1](http://arxiv.org/abs/2406.11437v1)|[link](https://github.com/petersamoaa/tree_based_nn_error_analysis)|
|**2024-06-17**|**AnyTrans: Translate AnyText in the Image with Large Scale Models**|Zhipeng Qian et.al.|[2406.11432v1](http://arxiv.org/abs/2406.11432v1)|null|
|**2024-06-17**|**Super(ficial)-alignment: Strong Models May Deceive Weak Models in Weak-to-Strong Generalization**|Wenkai Yang et.al.|[2406.11431v1](http://arxiv.org/abs/2406.11431v1)|[link](https://github.com/keven980716/weak-to-strong-deception)|
|**2024-06-17**|**A Simple and Effective $L_2$ Norm-Based Strategy for KV Cache Compression**|Alessio Devoto et.al.|[2406.11430v1](http://arxiv.org/abs/2406.11430v1)|null|
|**2024-06-17**|**DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with Diffusion Transformer**|Keon Lee et.al.|[2406.11427v1](http://arxiv.org/abs/2406.11427v1)|null|
|**2024-06-17**|**Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG Systems: A Comparative Study of Performance and Scalability**|Gautam B et.al.|[2406.11424v1](http://arxiv.org/abs/2406.11424v1)|[link](https://github.com/amaze18/RAGbot-OpenSource-Comparison/blob/main/Hybrid_Topk_similarity_expt.ipynb)|
|**2024-06-17**|**Dredge Word, Social Media, and Webgraph Networks for Unreliable Website Classification and Identification**|Evan M. Williams et.al.|[2406.11423v1](http://arxiv.org/abs/2406.11423v1)|null|
|**2024-06-17**|**BAMBINO-LM: (Bilingual-)Human-Inspired Continual Pretraining of BabyLM**|Zhewen Shen et.al.|[2406.11418v1](http://arxiv.org/abs/2406.11418v1)|null|
|**2024-06-17**|**Formally Certified Approximate Model Counting**|Yong Kiam Tan et.al.|[2406.11414v1](http://arxiv.org/abs/2406.11414v1)|null|
|**2024-06-17**|**HARE: HumAn pRiors, a key to small language model Efficiency**|Lingyun Zhang et.al.|[2406.11410v2](http://arxiv.org/abs/2406.11410v2)|[link](https://github.com/liteai-team/hare)|

#### Abstracts
##### **mDPO: Conditional Preference Optimization for Multimodal Large Language Models**
2406.11839v1 by Fei Wang, Wenxuan Zhou, James Y. Huang, Nan Xu, Sheng Zhang, Hoifung Poon, Muhao Chen

Direct preference optimization (DPO) has shown to be an effective method for
large language model (LLM) alignment. Recent works have attempted to apply DPO
to multimodal scenarios but have found it challenging to achieve consistent
improvement. Through a comparative experiment, we identify the unconditional
preference problem in multimodal preference optimization, where the model
overlooks the image condition. To address this problem, we propose mDPO, a
multimodal DPO objective that prevents the over-prioritization of language-only
preferences by also optimizing image preference. Moreover, we introduce a
reward anchor that forces the reward to be positive for chosen responses,
thereby avoiding the decrease in their likelihood -- an intrinsic problem of
relative preference optimization. Experiments on two multimodal LLMs of
different sizes and three widely used benchmarks demonstrate that mDPO
effectively addresses the unconditional preference problem in multimodal
preference optimization and significantly improves model performance,
particularly in reducing hallucination.

ÊëòË¶ÅÔºöÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) Â∑≤Ë¢´Ë≠âÊòéÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞çÈΩäÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤ÂòóË©¶Â∞á DPO ÊáâÁî®ÊñºÂ§öÊ®°ÊÖãÂ†¥ÊôØÔºå‰ΩÜÁôºÁèæÈõ£‰ª•ÈÅîÊàê‰∏ÄËá¥ÁöÑÊîπÂñÑ„ÄÇÈÄèÈÅéÊØîËºÉÂØ¶È©óÔºåÊàëÂÄëÊâæÂá∫Â§öÊ®°ÊÖãÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ‰∏≠ÁöÑÁÑ°Ê¢ù‰ª∂ÂÅèÂ•ΩÂïèÈ°åÔºåÂÖ∂‰∏≠Ê®°ÂûãÂøΩÁï•‰∫ÜÂΩ±ÂÉèÊ¢ù‰ª∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ mDPOÔºå‰∏ÄÁ®ÆÂ§öÊ®°ÊÖã DPO ÁõÆÊ®ôÔºåÈÄèÈÅéÊúÄ‰Ω≥ÂåñÂΩ±ÂÉèÂÅèÂ•Ω‰æÜÈò≤Ê≠¢ÈÅéÂ∫¶ÂÑ™ÂÖàËÄÉÊÖÆÂÉÖË™ûË®ÄÁöÑÂÅèÂ•Ω„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁçéÂãµÈå®ÈªûÔºåÂº∑Âà∂ÁçéÂãµÂ∞çÊâÄÈÅ∏ÂõûÊáâÁÇ∫Ê≠£ÂÄºÔºåÂæûËÄåÈÅøÂÖçÂÖ∂ÂèØËÉΩÊÄßÈôç‰Ωé‚Äî‚ÄîÈÄôÊòØÁõ∏Â∞çÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÁöÑÂÖßÂú®ÂïèÈ°å„ÄÇÂú®‰∏çÂêåÂ§ßÂ∞èÁöÑÂÖ©ÂÄãÂ§öÊ®°ÊÖã LLM Âíå‰∏âÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÂü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óË≠âÊòéÔºåmDPO ÊúâÊïàÂú∞Ëß£Ê±∫‰∫ÜÂ§öÊ®°ÊÖãÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ‰∏≠ÁöÑÁÑ°Ê¢ù‰ª∂ÂÅèÂ•ΩÂïèÈ°åÔºå‰∏¶È°ØËëóÊîπÂñÑ‰∫ÜÊ®°ÂûãÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Ê∏õÂ∞ëÂπªË¶∫ÊñπÈù¢„ÄÇ

##### **MMDU: A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs**
2406.11833v1 by Ziyu Liu, Tao Chu, Yuhang Zang, Xilin Wei, Xiaoyi Dong, Pan Zhang, Zijian Liang, Yuanjun Xiong, Yu Qiao, Dahua Lin, Jiaqi Wang

Generating natural and meaningful responses to communicate with multi-modal
human inputs is a fundamental capability of Large Vision-Language
Models(LVLMs). While current open-source LVLMs demonstrate promising
performance in simplified scenarios such as single-turn single-image input,
they fall short in real-world conversation scenarios such as following
instructions in a long context history with multi-turn and multi-images.
Existing LVLM benchmarks primarily focus on single-choice questions or
short-form responses, which do not adequately assess the capabilities of LVLMs
in real-world human-AI interaction applications. Therefore, we introduce MMDU,
a comprehensive benchmark, and MMDU-45k, a large-scale instruction tuning
dataset, designed to evaluate and improve LVLMs' abilities in multi-turn and
multi-image conversations. We employ the clustering algorithm to ffnd the
relevant images and textual descriptions from the open-source Wikipedia and
construct the question-answer pairs by human annotators with the assistance of
the GPT-4o model. MMDU has a maximum of 18k image+text tokens, 20 images, and
27 turns, which is at least 5x longer than previous benchmarks and poses
challenges to current LVLMs. Our in-depth analysis of 15 representative LVLMs
using MMDU reveals that open-source LVLMs lag behind closed-source counterparts
due to limited conversational instruction tuning data. We demonstrate that
ffne-tuning open-source LVLMs on MMDU-45k signiffcantly address this gap,
generating longer and more accurate conversations, and improving scores on MMDU
and existing benchmarks (MMStar: +1.1%, MathVista: +1.5%, ChartQA:+1.2%). Our
contributions pave the way for bridging the gap between current LVLM models and
real-world application demands. This project is available at
https://github.com/Liuziyu77/MMDU.

ÊëòË¶ÅÔºöÁîüÊàêËá™ÁÑ∂‰∏îÊúâÊÑèÁæ©ÁöÑÂõûÊáâÔºåËàáÂ§öÊ®°ÊÖã‰∫∫È°ûËº∏ÂÖ•ÈÄ≤Ë°åÊ∫ùÈÄöÔºåÊòØÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) ÁöÑÂü∫Êú¨ËÉΩÂäõ„ÄÇÈõñÁÑ∂ÁõÆÂâçÁöÑÈñãÊ∫ê LVLMs Âú®Á∞°ÂåñÁöÑÂ†¥ÊôØ‰∏≠Â±ïÁèæÂá∫ÊúâÂ∏åÊúõÁöÑË°®ÁèæÔºå‰æãÂ¶ÇÂñÆÊ¨°Ëº™ÊèõÂñÆ‰∏ÄÂΩ±ÂÉèËº∏ÂÖ•Ôºå‰ΩÜÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÂ∞çË©±Â†¥ÊôØ‰∏≠ÂçªË°®Áèæ‰∏ç‰Ω≥Ôºå‰æãÂ¶ÇÂú®ÂÖ∑ÊúâÂ§öËº™ÊèõÂíåÂ§öÂΩ±ÂÉèÁöÑÈï∑Ë™ûÂ¢ÉÊ≠∑Âè≤‰∏≠ÈÅµÂæ™ÊåáÁ§∫„ÄÇÁèæÊúâÁöÑ LVLM Âü∫Ê∫ñ‰∏ªË¶ÅÈóúÊ≥®ÂñÆÈÅ∏È°åÊàñÁü≠ÁØáÂõûÊáâÔºåÈÄô‰∏¶‰∏çËÉΩÂÖÖÂàÜË©ï‰º∞ LVLMs Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑ‰∫∫Â∑•Êô∫ÊÖß‰∫íÂãïÊáâÁî®‰∏≠ÁöÑËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MMDUÔºå‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰ª•Âèä MMDU-45kÔºå‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÊåá‰ª§Ë™øÊï¥Ë≥áÊñôÈõÜÔºåÊó®Âú®Ë©ï‰º∞ÂíåÊèêÂçá LVLMs Âú®Â§öËº™ÊèõÂíåÂ§öÂΩ±ÂÉèÂ∞çË©±‰∏≠ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÊé°Áî®Áæ§ÈõÜÊºîÁÆóÊ≥ïÂæûÈñãÊ∫êÁ∂≠Âü∫ÁôæÁßë‰∏≠ÊâæÂá∫Áõ∏ÈóúÁöÑÂΩ±ÂÉèÂíåÊñáÂ≠óÊèèËø∞Ôºå‰∏¶Âú® GPT-4o Ê®°ÂûãÁöÑÂçîÂä©‰∏ãÔºåÁî±‰∫∫Â∑•Ë®ªËß£ËÄÖÂª∫ÊßãÂïèÁ≠îÈÖçÂ∞ç„ÄÇMMDU ÊúÄÂ§öÊúâ 18k ÂÄãÂΩ±ÂÉè + ÊñáÂ≠óÁ¨¶Ëôü„ÄÅ20 ÂÄãÂΩ±ÂÉèÂíå 27 ÂÄãËº™ÊèõÔºåÈÄôËá≥Â∞ëÊØîÂÖàÂâçÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶Èï∑ 5 ÂÄçÔºå‰∏¶Â∞çÁõÆÂâçÁöÑ LVLMs ÊßãÊàêÊåëÊà∞„ÄÇÊàëÂÄë‰ΩøÁî® MMDU Â∞ç 15 ÂÄãÂÖ∑‰ª£Ë°®ÊÄßÁöÑ LVLMs ÈÄ≤Ë°åÊ∑±ÂÖ•ÂàÜÊûêÔºåÁôºÁèæÈñãÊ∫ê LVLMs Áî±ÊñºÂ∞çË©±ÂºèÊåá‰ª§Ë™øÊï¥Ë≥áÊñôÊúâÈôêÔºåËÄåËêΩÂæåÊñºÈñâÊ∫êÂ∞çÊáâÁ®ãÂºè„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÂú® MMDU-45k ‰∏äÂæÆË™øÈñãÊ∫ê LVLMs ÂèØ‰ª•È°ØËëóËß£Ê±∫Ê≠§Â∑ÆË∑ùÔºåÁî¢ÁîüÊõ¥Èï∑‰∏îÊõ¥Ê∫ñÁ¢∫ÁöÑÂ∞çË©±Ôºå‰∏¶ÊèêÂçá MMDU ÂíåÁèæÊúâÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÂàÜÊï∏ (MMStarÔºö+1.1%ÔºåMathVistaÔºö+1.5%ÔºåChartQAÔºö+1.2%)„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÁÇ∫Á∏ÆÂ∞èÁõÆÂâç LVLM Ê®°ÂûãËàáÁèæÂØ¶‰∏ñÁïåÊáâÁî®ÈúÄÊ±Ç‰πãÈñìÁöÑÂ∑ÆË∑ùÈã™Ë∑Ø„ÄÇÈÄôÂÄãÂ∞àÊ°àÂèØÂú® https://github.com/Liuziyu77/MMDU ÂèñÂæó„ÄÇ

##### **Language Modeling with Editable External Knowledge**
2406.11830v1 by Belinda Z. Li, Emmy Liu, Alexis Ross, Abbas Zeitoun, Graham Neubig, Jacob Andreas

When the world changes, so does the text that humans write about it. How do
we build language models that can be easily updated to reflect these changes?
One popular approach is retrieval-augmented generation, in which new documents
are inserted into a knowledge base and retrieved during prediction for
downstream tasks. Most prior work on these systems have focused on improving
behavior during prediction through better retrieval or reasoning. This paper
introduces ERASE, which instead improves model behavior when new documents are
acquired, by incrementally deleting or rewriting other entries in the knowledge
base each time a document is added. In two new benchmark datasets evaluating
models' ability to answer questions about a stream of news articles or
conversations, ERASE improves accuracy relative to conventional
retrieval-augmented generation by 7-13% (Mixtral-8x7B) and 6-10% (Llama-3-8B)
absolute. Code and data are available at https://github.com/belindal/ERASE

ÊëòË¶ÅÔºöÁï∂‰∏ñÁïåÊîπËÆäÔºå‰∫∫È°ûÂ∞çÂÆÉÁöÑÊñáÂ≠óÊõ∏ÂØ´‰πüË∑üËëóÊîπËÆä„ÄÇÊàëÂÄëÂ¶Ç‰ΩïÂª∫ÊßãÂèØ‰ª•ËºïÊòìÊõ¥Êñ∞‰ª•ÂèçÊò†ÈÄô‰∫õÊîπËÆäÁöÑË™ûË®ÄÊ®°ÂûãÔºü‰∏ÄÁ®ÆÂª£ÂèóÊ≠°ËøéÁöÑÊñπÊ≥ïÊòØÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºåÂÖ∂‰∏≠Êñ∞ÁöÑÊñá‰ª∂ÊúÉÊèíÂÖ•Âà∞Áü•Ë≠òÂ∫´‰∏≠Ôºå‰∏¶Âú®È†êÊ∏¨‰∏≠Ê™¢Á¥¢‰ª•ÈÄ≤Ë°å‰∏ãÊ∏∏‰ªªÂãô„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÁöÑÂ§ßÈÉ®ÂàÜÂÖàÂâçÂ∑•‰ΩúÈÉΩÂ∞àÊ≥®ÊñºÈÄèÈÅéÊõ¥Â•ΩÁöÑÊ™¢Á¥¢ÊàñÊé®ÁêÜ‰æÜÊîπÂñÑÈ†êÊ∏¨ÊúüÈñìÁöÑË°åÁÇ∫„ÄÇÊú¨Êñá‰ªãÁ¥π ERASEÔºåÂÆÉÂú®ÂèñÂæóÊñ∞Êñá‰ª∂ÊôÇÊîπÂñÑÊ®°ÂûãË°åÁÇ∫ÔºåÈÄèÈÅéÊØèÊ¨°Êñ∞Â¢ûÊñá‰ª∂ÊôÇÈÅûÂ¢ûÂà™Èô§ÊàñÊîπÂØ´Áü•Ë≠òÂ∫´‰∏≠ÁöÑÂÖ∂‰ªñÊ¢ùÁõÆ„ÄÇÂú®ÂÖ©ÂÄãÊñ∞ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜË©ï‰º∞Ê®°ÂûãÂõûÁ≠îÊñ∞ËÅûÊñáÁ´†ÊàñÂ∞çË©±‰∏≤ÊµÅÂïèÈ°åÁöÑËÉΩÂäõÔºåERASE Áõ∏ËºÉÊñºÂÇ≥Áµ±ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºåÊ∫ñÁ¢∫ÊÄßÊèêÂçá 7-13%ÔºàMixtral-8x7BÔºâÂíå 6-10%ÔºàLlama-3-8BÔºâÁµïÂ∞çÂÄº„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÊñº https://github.com/belindal/ERASE ÂèñÂæó

##### **WPO: Enhancing RLHF with Weighted Preference Optimization**
2406.11827v1 by Wenxuan Zhou, Ravi Agrawal, Shujian Zhang, Sathish Reddy Indurthi, Sanqiang Zhao, Kaiqiang Song, Silei Xu, Chenguang Zhu

Reinforcement learning from human feedback (RLHF) is a promising solution to
align large language models (LLMs) more closely with human values. Off-policy
preference optimization, where the preference data is obtained from other
models, is widely adopted due to its cost efficiency and scalability. However,
off-policy preference optimization often suffers from a distributional gap
between the policy used for data collection and the target policy, leading to
suboptimal optimization. In this paper, we propose a novel strategy to mitigate
this problem by simulating on-policy learning with off-policy preference data.
Our Weighted Preference Optimization (WPO) method adapts off-policy data to
resemble on-policy data more closely by reweighting preference pairs according
to their probability under the current policy. This method not only addresses
the distributional gap problem but also enhances the optimization process
without incurring additional costs. We validate our method on instruction
following benchmarks including Alpaca Eval 2 and MT-bench. WPO not only
outperforms Direct Preference Optimization (DPO) by up to 5.6% on Alpaca Eval 2
but also establishes a remarkable length-controlled winning rate against
GPT-4-turbo of 48.6% based on Llama-3-8B-Instruct, making it the strongest 8B
model on the leaderboard. We will release the code and models at
https://github.com/wzhouad/WPO.

ÊëòË¶ÅÔºö‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) ÊòØËÆìÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êõ¥Á¨¶Âêà‰∫∫È°ûÂÉπÂÄºËßÄÁöÑÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÈõ¢Á∑öÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºàÂÅèÂ•ΩÊï∏ÊìöÂæûÂÖ∂‰ªñÊ®°ÂûãÂèñÂæóÔºâÂõ†ÂÖ∂ÊàêÊú¨ÊïàÁõäÂíåÂèØÊì¥ÂÖÖÊÄßËÄåÂª£Ê≥õÊé°Áî®„ÄÇÁÑ∂ËÄåÔºåÈõ¢Á∑öÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÁ∂ìÂ∏∏ÊúÉÂõ†Áî®ÊñºÊï∏ÊìöÊî∂ÈõÜÁöÑÊîøÁ≠ñÂíåÁõÆÊ®ôÊîøÁ≠ñ‰πãÈñìÁöÑÂàÜÈÖçÂ∑ÆË∑ùËÄåÂèóËã¶ÔºåÂ∞éËá¥Ê¨°‰Ω≥ÊúÄ‰Ω≥Âåñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÁ≠ñÁï•ÔºåÈÄèÈÅéÊ®°Êì¨Âú®Á∑öÊîøÁ≠ñÂ≠∏ÁøíËàáÈõ¢Á∑öÂÅèÂ•ΩÊï∏Êìö‰æÜÊ∏õËºïÊ≠§ÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂä†Ê¨äÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (WPO) ÊñπÊ≥ïÊúÉË™øÊï¥Èõ¢Á∑öÊï∏ÊìöÔºå‰ΩøÂÖ∂Êõ¥Êé•ËøëÂú®Á∑öÊîøÁ≠ñÊï∏ÊìöÔºåÊñπÊ≥ïÊòØÊ†πÊìöÁï∂ÂâçÊîøÁ≠ñÁöÑÊ©üÁéáÈáçÊñ∞Âä†Ê¨äÂÅèÂ•ΩÈÖçÂ∞ç„ÄÇÊ≠§ÊñπÊ≥ï‰∏çÂÉÖËß£Ê±∫‰∫ÜÂàÜÈÖçÂ∑ÆË∑ùÂïèÈ°åÔºåÈÇÑÂ¢ûÂº∑‰∫ÜÊúÄ‰Ω≥ÂåñÊµÅÁ®ãÔºåËÄå‰∏çÊúÉÁî¢ÁîüÈ°çÂ§ñÊàêÊú¨„ÄÇÊàëÂÄëÂú®ÂåÖÊã¨ Alpaca Eval 2 Âíå MT-bench Âú®ÂÖßÁöÑÊåá‰ª§ÈÅµÂæ™Âü∫Ê∫ñ‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°Âûã„ÄÇWPO ‰∏çÂÉÖÂú® Alpaca Eval 2 ‰∏äÊØîÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) È´òÂá∫ 5.6%ÔºåÈÇÑÊ†πÊìö Llama-3-8B-Instruct Âª∫Á´ã‰∫ÜËàá GPT-4-turbo Áõ∏ÊäóË°°ÁöÑ 48.6% Èï∑Â∫¶ÊéßÂà∂Áç≤ÂãùÁéáÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÊéíË°åÊ¶ú‰∏äÊúÄÂº∑Â§ßÁöÑ 8B Ê®°Âûã„ÄÇÊàëÂÄëÂ∞áÂú® https://github.com/wzhouad/WPO ÈáãÂá∫Á®ãÂºèÁ¢ºÂíåÊ®°Âûã„ÄÇ

##### **On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning**
2406.11823v1 by Geewook Kim, Minjoon Seo

Recent advancements in language and vision assistants have showcased
impressive capabilities but suffer from a lack of transparency, limiting
broader research and reproducibility. While open-source models handle general
image tasks effectively, they face challenges with the high computational
demands of complex visually-situated text understanding. Such tasks often
require increased token inputs and large vision modules to harness
high-resolution information. Striking a balance between model size and data
importance remains an open question. This study aims to redefine the design of
vision-language models by identifying key components and creating efficient
models with constrained inference costs. By strategically formulating datasets,
optimizing vision modules, and enhancing supervision techniques, we achieve
significant improvements in inference throughput while maintaining high
performance. Extensive experiments across models ranging from 160M to 13B
parameters offer insights into model optimization. We will fully open-source
our codebase, models, and datasets at https://github.com/naver-ai/elva .

ÊëòË¶ÅÔºöË™ûË®ÄÂíåË¶ñË¶∫Âä©ÁêÜÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ±ïÁ§∫‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºå‰ΩÜÁº∫‰πèÈÄèÊòéÂ∫¶ÔºåÈôêÂà∂‰∫ÜÊõ¥Âª£Ê≥õÁöÑÁ†îÁ©∂ÂíåÂèØË§áË£ΩÊÄß„ÄÇÈõñÁÑ∂ÈñãÊ∫êÊ®°ÂûãÊúâÊïàÂú∞ËôïÁêÜ‰∏ÄËà¨ÂΩ±ÂÉè‰ªªÂãôÔºå‰ΩÜÂÆÉÂÄëÂú®Ë§áÈõúÁöÑË¶ñË¶∫ÊÉÖÂ¢ÉÊñáÊú¨ÁêÜËß£ÁöÑÈ´òË®àÁÆóÈúÄÊ±ÇÊñπÈù¢Èù¢Ëá®ÊåëÊà∞„ÄÇÊ≠§È°û‰ªªÂãôÈÄöÂ∏∏ÈúÄË¶ÅÂ¢ûÂä†ÁöÑÊ®ôË®òËº∏ÂÖ•ÂíåÂ§ßÂûãË¶ñË¶∫Ê®°ÁµÑÔºå‰ª•Âà©Áî®È´òËß£ÊûêÂ∫¶Ë≥áË®ä„ÄÇÂú®Ê®°ÂûãÂ§ßÂ∞èÂíåË≥áÊñôÈáçË¶ÅÊÄß‰πãÈñìÂèñÂæóÂπ≥Ë°°‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊú™Ëß£Ê±∫ÁöÑÂïèÈ°å„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈÄèÈÅéË≠òÂà•ÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÂíåÂª∫Á´ãÂÖ∑ÊúâÂèóÈôêÊé®Ë´ñÊàêÊú¨ÁöÑÊúâÊïàÁéáÊ®°ÂûãÔºåÈáçÊñ∞ÂÆöÁæ©Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑË®≠Ë®à„ÄÇÈÄèÈÅéÁ≠ñÁï•ÊÄßÂú∞Âà∂ÂÆöË≥áÊñôÈõÜ„ÄÅÊúÄ‰Ω≥ÂåñË¶ñË¶∫Ê®°ÁµÑÂíåÂ¢ûÂº∑Áõ£Áù£ÊäÄË°ìÔºåÊàëÂÄëÂú®Á∂≠ÊåÅÈ´òÊÄßËÉΩÁöÑÂêåÊôÇÔºåÈ°ØËëóÊîπÂñÑ‰∫ÜÊé®Ë´ñËôïÁêÜÈáè„ÄÇÂæû 160M Âà∞ 13B ÂèÉÊï∏ÁöÑÊ®°ÂûãÁöÑÂª£Ê≥õÂØ¶È©óÊèê‰æõ‰∫ÜÊ®°ÂûãÊúÄ‰Ω≥ÂåñÁöÑË¶ãËß£„ÄÇÊàëÂÄëÂ∞áÂú® https://github.com/naver-ai/elva ÂÆåÂÖ®ÈñãÊîæÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∫´„ÄÅÊ®°ÂûãÂíåË≥áÊñôÈõÜ„ÄÇ

##### **Embodied Instruction Following in Unknown Environments**
2406.11818v1 by Zhenyu Wu, Ziwei Wang, Xiuwei Xu, Jiwen Lu, Haibin Yan

Enabling embodied agents to complete complex human instructions from natural
language is crucial to autonomous systems in household services. Conventional
methods can only accomplish human instructions in the known environment where
all interactive objects are provided to the embodied agent, and directly
deploying the existing approaches for the unknown environment usually generates
infeasible plans that manipulate non-existing objects. On the contrary, we
propose an embodied instruction following (EIF) method for complex tasks in the
unknown environment, where the agent efficiently explores the unknown
environment to generate feasible plans with existing objects to accomplish
abstract instructions. Specifically, we build a hierarchical embodied
instruction following framework including the high-level task planner and the
low-level exploration controller with multimodal large language models. We then
construct a semantic representation map of the scene with dynamic region
attention to demonstrate the known visual clues, where the goal of task
planning and scene exploration is aligned for human instruction. For the task
planner, we generate the feasible step-by-step plans for human goal
accomplishment according to the task completion process and the known visual
clues. For the exploration controller, the optimal navigation or object
interaction policy is predicted based on the generated step-wise plans and the
known visual clues. The experimental results demonstrate that our method can
achieve 45.09% success rate in 204 complex human instructions such as making
breakfast and tidying rooms in large house-level scenes.

ÊëòË¶ÅÔºöËÆìÂÖ∑Ë∫´‰ª£ÁêÜ‰∫∫ÂÆåÊàêËá™ÁÑ∂Ë™ûË®Ä‰∏≠ÁöÑË§áÈõú‰∫∫È°ûÊåáÁ§∫Â∞çÊñºÂÆ∂Â∫≠ÊúçÂãô‰∏≠ÁöÑËá™‰∏ªÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÂè™ËÉΩÂú®Â∑≤Áü•Áí∞Â¢É‰∏≠ÂÆåÊàê‰∫∫È°ûÊåáÁ§∫ÔºåÂÖ∂‰∏≠ÊâÄÊúâ‰∫íÂãïÂ∞çË±°ÈÉΩÊèê‰æõÁµ¶ÂÖ∑Ë∫´‰ª£ÁêÜ‰∫∫Ôºå‰∏¶‰∏îÁõ¥Êé•ÈÉ®ÁΩ≤ÁèæÊúâÊñπÊ≥ï‰æÜÊáâÂ∞çÊú™Áü•Áí∞Â¢ÉÈÄöÂ∏∏ÊúÉÁî¢Áîü‰∏çÂèØË°åÁöÑË®àÁï´ÔºåÈÄô‰∫õË®àÁï´ÊúÉÊìç‰Ωú‰∏çÂ≠òÂú®ÁöÑÂ∞çË±°„ÄÇÁõ∏ÂèçÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂú®Êú™Áü•Áí∞Â¢É‰∏≠Âü∑Ë°åË§áÈõú‰ªªÂãôÁöÑÂÖ∑Ë∫´Êåá‰ª§ÈÅµÂæ™ (EIF) ÊñπÊ≥ïÔºåÂÖ∂‰∏≠‰ª£ÁêÜ‰∫∫ÊúâÊïàÂú∞Êé¢Á¥¢Êú™Áü•Áí∞Â¢É‰ª•ÁîüÊàêÂèØË°åÁöÑË®àÁï´Ôºå‰∏¶‰ΩøÁî®ÁèæÊúâÂ∞çË±°‰æÜÂÆåÊàêÊäΩË±°Êåá‰ª§„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂàÜÂ±§ÂÖ∑Ë∫´Êåá‰ª§ÈÅµÂæ™Êû∂ÊßãÔºåÂåÖÊã¨È´òÁ¥ö‰ªªÂãôË¶èÂäÉÂô®ÂíåÂÖ∑ÊúâÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑ‰ΩéÁ¥öÊé¢Á¥¢ÊéßÂà∂Âô®„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊßãÂª∫‰∏ÄÂÄãÂ†¥ÊôØÁöÑË™ûÁæ©Ë°®Á§∫ÂúñÔºå‰∏¶‰ΩøÁî®ÂãïÊÖãÂçÄÂüüÊ≥®ÊÑè‰æÜÂ±ïÁ§∫Â∑≤Áü•ÁöÑË¶ñË¶∫Á∑öÁ¥¢ÔºåÂÖ∂‰∏≠‰ªªÂãôË¶èÂäÉÂíåÂ†¥ÊôØÊé¢Á¥¢ÁöÑÁõÆÊ®ôËàá‰∫∫È°ûÊåá‰ª§‰øùÊåÅ‰∏ÄËá¥„ÄÇÂ∞çÊñº‰ªªÂãôË¶èÂäÉÂô®ÔºåÊàëÂÄëÊ†πÊìö‰ªªÂãôÂÆåÊàêÈÅéÁ®ãÂíåÂ∑≤Áü•ÁöÑË¶ñË¶∫Á∑öÁ¥¢‰æÜÁîüÊàêÂèØË°åÁöÑÈÄêÊ≠•Ë®àÁï´Ôºå‰ª•ÂÆåÊàê‰∫∫È°ûÁõÆÊ®ô„ÄÇÂ∞çÊñºÊé¢Á¥¢ÊéßÂà∂Âô®ÔºåÊúÄ‰Ω≥Â∞éËà™ÊàñÂ∞çË±°‰∫íÂãïÁ≠ñÁï•ÊòØÊ†πÊìöÁîüÊàêÁöÑÈÄêÊ≠•Ë®àÁï´ÂíåÂ∑≤Áü•ÁöÑË¶ñË¶∫Á∑öÁ¥¢‰æÜÈ†êÊ∏¨ÁöÑ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Âú® 204 Ê¢ùË§áÈõúÁöÑ‰∫∫È°ûÊåá‰ª§‰∏≠ÂØ¶Áèæ 45.09% ÁöÑÊàêÂäüÁéáÔºå‰æãÂ¶ÇÂú®Â§ßÂûãÊàøÂ±ãÂ†¥ÊôØ‰∏≠Ë£Ω‰ΩúÊó©È§êÂíåÊï¥ÁêÜÊàøÈñì„ÄÇ

##### **Iterative Length-Regularized Direct Preference Optimization: A Case Study on Improving 7B Language Models to GPT-4 Level**
2406.11817v1 by Jie Liu, Zhanhui Zhou, Jiaheng Liu, Xingyuan Bu, Chao Yang, Han-Sen Zhong, Wanli Ouyang

Direct Preference Optimization (DPO), a standard method for aligning language
models with human preferences, is traditionally applied to offline preferences.
Recent studies show that DPO benefits from iterative training with online
preferences labeled by a trained reward model. In this work, we identify a
pitfall of vanilla iterative DPO - improved response quality can lead to
increased verbosity. To address this, we introduce iterative length-regularized
DPO (iLR-DPO) to penalize response length. Our empirical results show that
iLR-DPO can enhance a 7B model to perform on par with GPT-4 without increasing
verbosity. Specifically, our 7B model achieves a $50.5\%$ length-controlled win
rate against $\texttt{GPT-4 Preview}$ on AlpacaEval 2.0, and excels across
standard benchmarks including MT-Bench, Arena-Hard and OpenLLM Leaderboard.
These results demonstrate the effectiveness of iterative DPO in aligning
language models with human feedback.

ÊëòË¶ÅÔºöÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºàDPOÔºâÊòØ‰∏ÄÁ®ÆÂ∞áË™ûË®ÄÊ®°ÂûãËàá‰∫∫È°ûÂÅèÂ•ΩÂ∞çÈΩäÁöÑÊ®ôÊ∫ñÊñπÊ≥ïÔºåÂÇ≥Áµ±‰∏äÊáâÁî®ÊñºÈõ¢Á∑öÂÅèÂ•Ω„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåDPO ÂèóÁõäÊñº‰ΩøÁî®ÂèóÈÅéË®ìÁ∑¥ÁöÑÁçéÂãµÊ®°ÂûãÊ®ôË®òÁöÑÁ∑ö‰∏äÂÅèÂ•ΩÁöÑÂèçË¶ÜË®ìÁ∑¥„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁôºÁèæ‰∫ÜÈ¶ôËçâÂèçË¶Ü DPO ÁöÑ‰∏ÄÂÄãÈô∑Èò± - ÊîπÂñÑÁöÑÂõûÊáâÂìÅË≥™ÂèØËÉΩÂ∞éËá¥ÂÜóÈï∑„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂèçË¶ÜÈï∑Â∫¶Ê≠£Ë¶èÂåñÁöÑ DPO (iLR-DPO) ‰æÜÊá≤ÁΩ∞ÂõûÊáâÈï∑Â∫¶„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁµêÊûúË°®ÊòéÔºåiLR-DPO ÂèØ‰ª•Â¢ûÂº∑ 7B Ê®°ÂûãÔºå‰ΩøÂÖ∂Âú®‰∏çÂ¢ûÂä†ÂÜóÈï∑ÁöÑÊÉÖÊ≥Å‰∏ãËàá GPT-4 Áõ∏Â™≤Áæé„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑ 7B Ê®°ÂûãÂú® AlpacaEval 2.0 ‰∏äÂØ¶Áèæ‰∫ÜÂ∞ç $\texttt{GPT-4 È†êË¶Ω}$ ÁöÑ $50.5\%$ Èï∑Â∫¶ÊéßÂà∂ÂãùÁéáÔºå‰∏¶Âú®ÂåÖÊã¨ MT-Bench„ÄÅArena-Hard Âíå OpenLLM ÊéíË°åÊ¶úÂú®ÂÖßÁöÑÊ®ôÊ∫ñÂü∫Ê∫ñ‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÈÄô‰∫õÁµêÊûúË≠âÊòé‰∫ÜÂèçË¶Ü DPO Âú®Â∞áË™ûË®ÄÊ®°ÂûãËàá‰∫∫È°ûÂõûÈ•ãÂ∞çÈΩäÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **How Do Large Language Models Acquire Factual Knowledge During Pretraining?**
2406.11813v1 by Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, Minjoon Seo

Despite the recent observation that large language models (LLMs) can store
substantial factual knowledge, there is a limited understanding of the
mechanisms of how they acquire factual knowledge through pretraining. This work
addresses this gap by studying how LLMs acquire factual knowledge during
pretraining. The findings reveal several important insights into the dynamics
of factual knowledge acquisition during pretraining. First, counterintuitively,
we observe that pretraining on more data shows no significant improvement in
the model's capability to acquire and maintain factual knowledge. Next, there
is a power-law relationship between training steps and forgetting of
memorization and generalization of factual knowledge, and LLMs trained with
duplicated training data exhibit faster forgetting. Third, training LLMs with
larger batch sizes can enhance the models' robustness to forgetting. Overall,
our observations suggest that factual knowledge acquisition in LLM pretraining
occurs by progressively increasing the probability of factual knowledge
presented in the pretraining data at each step. However, this increase is
diluted by subsequent forgetting. Based on this interpretation, we demonstrate
that we can provide plausible explanations for recently observed behaviors of
LLMs, such as the poor performance of LLMs on long-tail knowledge and the
benefits of deduplicating the pretraining corpus.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊúÄËøëËßÄÂØüÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂÑ≤Â≠òÂ§ßÈáèÁöÑÂØ¶ÈöõÁü•Ë≠òÔºå‰ΩÜÂ∞çÊñº LLM Âú®È†êË®ìÁ∑¥ÈÅéÁ®ã‰∏≠Â¶Ç‰ΩïÁç≤ÂèñÂØ¶ÈöõÁü•Ë≠òÁöÑÊ©üÂà∂ÔºåÁêÜËß£‰ªçÁÑ∂ÊúâÈôê„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÈÄèÈÅéÊé¢Ë®é LLM Âú®È†êË®ìÁ∑¥ÊúüÈñìÂ¶Ç‰ΩïÁç≤ÂèñÂØ¶ÈöõÁü•Ë≠òÔºå‰æÜÊé¢Ë®éÈÄôÂÄãÁü•Ë≠òÁº∫Âè£„ÄÇÁ†îÁ©∂ÁµêÊûúÊè≠Èú≤‰∫ÜÂπæÂÄãÈáçË¶ÅÁöÑË¶ãËß£ÔºåË™™ÊòéÂú®È†êË®ìÁ∑¥ÊúüÈñìÁç≤ÂèñÂØ¶ÈöõÁü•Ë≠òÁöÑÂãïÊÖã„ÄÇÈ¶ñÂÖàÔºåËàáÁõ¥Ë¶∫Áõ∏ÂèçÔºåÊàëÂÄëËßÄÂØüÂà∞‰ΩøÁî®Êõ¥Â§öË≥áÊñôÈÄ≤Ë°åÈ†êË®ìÁ∑¥‰∏¶Êú™È°ØËëóÊèêÂçáÊ®°ÂûãÁç≤ÂèñÂíåÁ∂≠Ë≠∑ÂØ¶ÈöõÁü•Ë≠òÁöÑËÉΩÂäõ„ÄÇÂÖ∂Ê¨°ÔºåË®ìÁ∑¥Ê≠•È©üËàáÈÅ∫Âøò„ÄÅË®òÊÜ∂ÂíåÂØ¶ÈöõÁü•Ë≠òÁöÑÊ¶ÇÂåñ‰πãÈñìÂ≠òÂú®ÂÜ™ÂæãÈóú‰øÇÔºåËÄå‰ΩøÁî®ÈáçË§áË®ìÁ∑¥Ë≥áÊñôË®ìÁ∑¥ÁöÑ LLM ÈÅ∫ÂøòÂæóÊõ¥Âø´„ÄÇÁ¨¨‰∏âÔºå‰ΩøÁî®ËºÉÂ§ßÁöÑÊâπÊ¨°Â§ßÂ∞èË®ìÁ∑¥ LLM ËÉΩÂ§†ÊèêÂçáÊ®°ÂûãÂ∞çÈÅ∫ÂøòÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑËßÄÂØüÁµêÊûúÈ°ØÁ§∫ÔºåLLM È†êË®ìÁ∑¥‰∏≠ÁöÑÂØ¶ÈöõÁü•Ë≠òÁç≤ÂèñÊòØÈÄèÈÅéÂú®ÊØèÂÄãÊ≠•È©üÈÄêÊ≠•Â¢ûÂä†È†êË®ìÁ∑¥Ë≥áÊñô‰∏≠ÂëàÁèæÁöÑÂØ¶ÈöõÁü•Ë≠òÊ©üÁéáËÄåÁôºÁîüÁöÑ„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÂ¢ûÂä†ÊúÉË¢´Èö®ÂæåÁöÑÈÅ∫ÂøòÊâÄÁ®ÄÈáã„ÄÇÊ†πÊìöÈÄôÂÄãËß£ÈáãÔºåÊàëÂÄëË≠âÊòéÊàëÂÄëÂèØ‰ª•Â∞çÊúÄËøëËßÄÂØüÂà∞ÁöÑ LLM Ë°åÁÇ∫Êèê‰æõÂêàÁêÜÁöÑËß£ÈáãÔºå‰æãÂ¶Ç LLM Âú®Èï∑Â∞æÁü•Ë≠ò‰∏äÁöÑË°®Áèæ‰∏ç‰Ω≥Ôºå‰ª•ÂèäÂ∞çÈ†êË®ìÁ∑¥Ë™ûÊñôÂ∫´ÈÄ≤Ë°åÈáçË§áË≥áÊñôÂà™Èô§ÁöÑÂ•ΩËôï„ÄÇ

##### **RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen Reference Content**
2406.11811v1 by Joao Monteiro, Pierre-Andre Noel, Etienne Marcotte, Sai Rajeswar, Valentina Zantedeschi, David Vazquez, Nicolas Chapados, Christopher Pal, Perouz Taslakian

Large Language Models (LLMs) are trained on vast amounts of data, most of
which is automatically scraped from the internet. This data includes
encyclopedic documents that harbor a vast amount of general knowledge (e.g.,
Wikipedia) but also potentially overlap with benchmark datasets used for
evaluating LLMs. Consequently, evaluating models on test splits that might have
leaked into the training set is prone to misleading conclusions. To foster
sound evaluation of language models, we introduce a new test dataset named
RepLiQA, suited for question-answering and topic retrieval tasks. RepLiQA is a
collection of five splits of test sets, four of which have not been released to
the internet or exposed to LLM APIs prior to this publication. Each sample in
RepLiQA comprises (1) a reference document crafted by a human annotator and
depicting an imaginary scenario (e.g., a news article) absent from the
internet; (2) a question about the document's topic; (3) a ground-truth answer
derived directly from the information in the document; and (4) the paragraph
extracted from the reference document containing the answer. As such, accurate
answers can only be generated if a model can find relevant content within the
provided document. We run a large-scale benchmark comprising several
state-of-the-art LLMs to uncover differences in performance across models of
various types and sizes in a context-conditional language modeling setting.
Released splits of RepLiQA can be found here:
https://huggingface.co/datasets/ServiceNow/repliqa.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÂú®Â§ßÈáèÁöÑË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÔºåÂÖ∂‰∏≠Â§ßÈÉ®ÂàÜÊòØÂæûÁ∂≤Ë∑Ø‰∏äËá™ÂãïÊäìÂèñÁöÑ„ÄÇÈÄô‰∫õË≥áÊñôÂåÖÊã¨ÂåÖÂê´Â§ßÈáè‰∏ÄËà¨Áü•Ë≠òÁöÑÁôæÁßëÂÖ®Êõ∏Êñá‰ª∂Ôºà‰æãÂ¶ÇÁ∂≠Âü∫ÁôæÁßëÔºâÔºå‰ΩÜ‰πüÂèØËÉΩËàáÁî®ÊñºË©ï‰º∞ LLM ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜÈáçÁñä„ÄÇÂõ†Ê≠§ÔºåÂú®ÂèØËÉΩÂ∑≤Ê¥©ÊºèÂà∞Ë®ìÁ∑¥ÈõÜ‰∏≠ÁöÑÊ∏¨Ë©¶ÂàÜÂâ≤‰∏äË©ï‰º∞Ê®°ÂûãÂÆπÊòìÂ∞éËá¥Ë™§Â∞éÊÄßÁöÑÁµêË´ñ„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Ë™ûË®ÄÊ®°ÂûãÁöÑÂÅ•ÂÖ®Ë©ï‰º∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂêçÁÇ∫ RepLiQA ÁöÑÊñ∞Ê∏¨Ë©¶Ë≥áÊñôÈõÜÔºåÈÅ©Áî®ÊñºÂïèÁ≠îÂíå‰∏ªÈ°åÊ™¢Á¥¢‰ªªÂãô„ÄÇRepLiQA ÊòØÁî±‰∫îÂÄãÊ∏¨Ë©¶ÈõÜÂàÜÂâ≤ÁµÑÊàêÁöÑÈõÜÂêàÔºåÂÖ∂‰∏≠ÂõõÂÄãÂú®Êú¨Ê¨°ÁôºÂ∏É‰πãÂâçÂ∞öÊú™ÁôºÂ∏ÉÂà∞Á∂≤Ë∑Ø‰∏äÊàñÂÖ¨ÈñãÁµ¶ LLM API„ÄÇRepLiQA ‰∏≠ÁöÑÊØèÂÄãÁØÑ‰æãÂåÖÂê´ (1) Áî±‰∫∫È°ûË®ªËß£ËÄÖÁ∑®ÂØ´ÁöÑÂèÉËÄÉÊñá‰ª∂ÔºåÊèèËø∞‰∏ÄÂÄã‰∏çÂ≠òÂú®ÊñºÁ∂≤Ë∑Ø‰∏ä„ÄÅËôõÊßãÁöÑÊÉÖÂ¢ÉÔºà‰æãÂ¶ÇÊñ∞ËÅûÊñáÁ´†ÔºâÔºõ(2) ÈóúÊñºÊñá‰ª∂‰∏ªÈ°åÁöÑÂïèÈ°åÔºõ(3) Áõ¥Êé•ÂæûÊñá‰ª∂‰∏≠ÁöÑË≥áË®äË°çÁîüÁöÑÂü∫Êú¨‰∫ãÂØ¶Á≠îÊ°àÔºõ‰ª•Âèä (4) ÂæûÂåÖÂê´Á≠îÊ°àÁöÑÂèÉËÄÉÊñá‰ª∂‰∏≠ÊëòÈåÑÁöÑÊÆµËêΩ„ÄÇÂõ†Ê≠§ÔºåÂè™ÊúâÁï∂Ê®°ÂûãÂèØ‰ª•Âú®Êèê‰æõÁöÑÊñá‰ª∂‰∏≠ÊâæÂà∞Áõ∏ÈóúÂÖßÂÆπÊôÇÔºåÊâçËÉΩÁî¢ÁîüÊ∫ñÁ¢∫ÁöÑÁ≠îÊ°à„ÄÇÊàëÂÄëÂü∑Ë°å‰∫Ü‰∏ÄÈ†ÖÂ§ßË¶èÊ®°Âü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂÖ∂‰∏≠ÂåÖÂê´Â§öÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLMÔºå‰ª•Âú®ÊÉÖÂ¢ÉÊ¢ù‰ª∂Ë™ûË®ÄÂª∫Ê®°Ë®≠ÂÆö‰∏≠Êè≠Á§∫ÂêÑÁ®ÆÈ°ûÂûãÂíåË¶èÊ®°ÁöÑÊ®°Âûã‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆÁï∞„ÄÇRepLiQA ÁöÑÂ∑≤ÁôºÂ∏ÉÂàÜÂâ≤ÂèØ‰ª•Âú®Ê≠§ËôïÊâæÂà∞Ôºöhttps://huggingface.co/datasets/ServiceNow/repliqa„ÄÇ

##### **Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations**
2406.11801v1 by Rima Hazra, Sayan Layek, Somnath Banerjee, Soujanya Poria

Ensuring the safe alignment of large language models (LLMs) with human values
is critical as they become integral to applications like translation and
question answering. Current alignment methods struggle with dynamic user
intentions and complex objectives, making models vulnerable to generating
harmful content. We propose Safety Arithmetic, a training-free framework
enhancing LLM safety across different scenarios: Base models, Supervised
fine-tuned models (SFT), and Edited models. Safety Arithmetic involves Harm
Direction Removal to avoid harmful content and Safety Alignment to promote safe
responses. Additionally, we present NoIntentEdit, a dataset highlighting edit
instances that could compromise model safety if used unintentionally. Our
experiments show that Safety Arithmetic significantly improves safety measures,
reduces over-safety, and maintains model utility, outperforming existing
methods in ensuring safe content generation.

ÊëòË¶ÅÔºöÁ¢∫‰øùÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëàá‰∫∫È°ûÂÉπÂÄºËßÄÂÆâÂÖ®‰∏ÄËá¥ÔºåÂ∞çÊñºÂÆÉÂÄëÊàêÁÇ∫ÁøªË≠ØÂíåÂïèÁ≠îÁ≠âÊáâÁî®Á®ãÂºè‰∏çÂèØÊàñÁº∫ÁöÑ‰∏ÄÈÉ®ÂàÜËá≥ÈóúÈáçË¶Å„ÄÇÁõÆÂâçÁöÑÂ∞çÈΩäÊñπÂºèÊñπÊ≥ïÈõ£‰ª•ÊáâÂ∞çÂãïÊÖã‰ΩøÁî®ËÄÖÊÑèÂúñÂíåË§áÈõúÁõÆÊ®ôÔºå‰ΩøÂæóÊ®°ÂûãÂÆπÊòìÁî¢ÁîüÊúâÂÆ≥ÂÖßÂÆπ„ÄÇÊàëÂÄëÊèêÂá∫ÂÆâÂÖ®ÁÆóË°ìÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖçË®ìÁ∑¥Ê°ÜÊû∂ÔºåÂèØÂ¢ûÂº∑ LLM Âú®‰∏çÂêåÂ†¥ÊôØ‰∏≠ÁöÑÂÆâÂÖ®ÊÄßÔºöÂü∫Á§éÊ®°Âûã„ÄÅÁõ£Áù£ÂæÆË™øÊ®°Âûã (SFT) ÂíåÁ∑®ËºØÊ®°Âûã„ÄÇÂÆâÂÖ®ÁÆóË°ìÊ∂âÂèäÂç±ÂÆ≥ÊñπÂêëÁßªÈô§Ôºå‰ª•ÈÅøÂÖçÊúâÂÆ≥ÂÖßÂÆπÔºå‰ª•ÂèäÂÆâÂÖ®Â∞çÈΩäÔºå‰ª•‰øÉÈÄ≤ÂÆâÂÖ®ÂõûÊáâ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ NoIntentEditÔºåÈÄôÊòØ‰∏ÄÂÄãË≥áÊñôÈõÜÔºåÈáçÈªûÊ®ôÁ§∫Âá∫Â¶ÇÊûúÁÑ°ÊÑè‰∏≠‰ΩøÁî®ÔºåÂèØËÉΩÊúÉÊêçÂÆ≥Ê®°ÂûãÂÆâÂÖ®ÊÄßÁöÑÁ∑®ËºØÂØ¶‰æã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÂÆâÂÖ®ÁÆóË°ìÈ°ØËëóÊîπÂñÑ‰∫ÜÂÆâÂÖ®Êé™ÊñΩÔºåÊ∏õÂ∞ë‰∫ÜÈÅéÂ∫¶ÂÆâÂÖ®ÊÄßÔºå‰∏¶Á∂≠ÊåÅÊ®°ÂûãÊïàÁî®ÔºåÂú®Á¢∫‰øùÂÆâÂÖ®ÂÖßÂÆπÁîüÊàêÊñπÈù¢ÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **DataComp-LM: In search of the next generation of training sets for language models**
2406.11794v1 by Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Gadre, Hritik Bansal, Etash Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas Muenninghoff, Reinhard Heckel, Jean Mercat, Mayee Chen, Suchin Gururangan, Mitchell Wortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Abbas, Cheng-Yu Hsieh, Dhruba Ghosh, Josh Gardner, Maciej Kilian, Hanlin Zhang, Rulin Shao, Sarah Pratt, Sunny Sanyal, Gabriel Ilharco, Giannis Daras, Kalyani Marathe, Aaron Gokaslan, Jieyu Zhang, Khyathi Chandu, Thao Nguyen, Igor Vasiljevic, Sham Kakade, Shuran Song, Sujay Sanghavi, Fartash Faghri, Sewoong Oh, Luke Zettlemoyer, Kyle Lo, Alaaeldin El-Nouby, Hadi Pouransari, Alexander Toshev, Stephanie Wang, Dirk Groeneveld, Luca Soldani, Pang Wei Koh, Jenia Jitsev, Thomas Kollar, Alexandros G. Dimakis, Yair Carmon, Achal Dave, Ludwig Schmidt, Vaishaal Shankar

We introduce DataComp for Language Models (DCLM), a testbed for controlled
dataset experiments with the goal of improving language models. As part of
DCLM, we provide a standardized corpus of 240T tokens extracted from Common
Crawl, effective pretraining recipes based on the OpenLM framework, and a broad
suite of 53 downstream evaluations. Participants in the DCLM benchmark can
experiment with data curation strategies such as deduplication, filtering, and
data mixing at model scales ranging from 412M to 7B parameters. As a baseline
for DCLM, we conduct extensive experiments and find that model-based filtering
is key to assembling a high-quality training set. The resulting dataset,
DCLM-Baseline enables training a 7B parameter language model from scratch to
64% 5-shot accuracy on MMLU with 2.6T training tokens. Compared to MAP-Neo, the
previous state-of-the-art in open-data language models, DCLM-Baseline
represents a 6.6 percentage point improvement on MMLU while being trained with
40% less compute. Our baseline model is also comparable to Mistral-7B-v0.3 and
Llama 3 8B on MMLU (63% & 66%), and performs similarly on an average of 53
natural language understanding tasks while being trained with 6.6x less compute
than Llama 3 8B. Our results highlight the importance of dataset design for
training language models and offer a starting point for further research on
data curation.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÁÇ∫Ë™ûË®ÄÊ®°Âûã (DCLM) ÂºïÂÖ• DataCompÔºå‰∏ÄÂÄãÁî®ÊñºÊéßÂà∂Ë≥áÊñôÈõÜÂØ¶È©óÁöÑÊ∏¨Ë©¶Âπ≥Âè∞ÔºåÁõÆÊ®ôÊòØÊîπÈÄ≤Ë™ûË®ÄÊ®°Âûã„ÄÇ‰ΩúÁÇ∫ DCLM ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÊàëÂÄëÊèê‰æõ‰∏ÄÂÄãÊ®ôÊ∫ñË™ûÊñôÂ∫´ÔºåÂåÖÂê´Âæû Common Crawl ‰∏≠ÊèêÂèñÁöÑ 240T ÂÄãÁ¨¶ËôüÔºåÂü∫Êñº OpenLM Ê°ÜÊû∂ÁöÑÊúâÊïàÈ†êË®ìÁ∑¥ÈÖçÊñπÔºå‰ª•ÂèäÂª£Ê≥õÁöÑ 53 ÂÄã‰∏ãÊ∏∏Ë©ï‰º∞„ÄÇDCLM Âü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÂèÉËàáËÄÖÂèØ‰ª•ÂòóË©¶Ë≥áÊñôÁ≠ñÂ±ïÁ≠ñÁï•Ôºå‰æãÂ¶ÇÂéªÈáç„ÄÅÈÅéÊøæÂíåË≥áÊñôÊ∑∑ÂêàÔºåÊ®°ÂûãË¶èÊ®°Âæû 412M Âà∞ 7B ÂÄãÂèÉÊï∏„ÄÇ‰ΩúÁÇ∫ DCLM ÁöÑÂü∫Ê∫ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÁôºÁèæÂü∫ÊñºÊ®°ÂûãÁöÑÈÅéÊøæÊòØÁµÑË£ùÈ´òÂìÅË≥™Ë®ìÁ∑¥ÈõÜÁöÑÈóúÈçµ„ÄÇÁî±Ê≠§Áî¢ÁîüÁöÑË≥áÊñôÈõÜ DCLM-Baseline ËÉΩÂ§†ÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥‰∏ÄÂÄã 7B ÂèÉÊï∏Ë™ûË®ÄÊ®°ÂûãÔºåÂú® MMLU ‰∏ä‰ª• 2.6T ÂÄãË®ìÁ∑¥Á¨¶ËôüÈÅîÂà∞ 64% ÁöÑ 5 Ê¨°Ê∫ñÁ¢∫Â∫¶„ÄÇËàá MAP-Neo Áõ∏ÊØîÔºåDCLM-Baseline ÊòØÈñãÊîæË≥áÊñôË™ûË®ÄÊ®°Âûã‰∏≠ÂÖàÂâçÁöÑÊúÄÊñ∞ÊäÄË°ìÔºåÂú® MMLU ‰∏äÊèêÈ´ò‰∫Ü 6.6 ÂÄãÁôæÂàÜÈªûÔºåÂêåÊôÇË®ìÁ∑¥ÊôÇÈÅãÁÆóÈáèÊ∏õÂ∞ë‰∫Ü 40%„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÊ®°Âûã‰πüËàá MMLU ‰∏äÁöÑ Mistral-7B-v0.3 Âíå Llama 3 8B Áõ∏Áï∂Ôºà63% Âíå 66%ÔºâÔºå‰∏¶‰∏îÂú®Âπ≥Âùá 53 ÂÄãËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£‰ªªÂãô‰∏äÁöÑË°®ÁèæÈ°û‰ººÔºåÂêåÊôÇË®ìÁ∑¥ÊôÇÈÅãÁÆóÈáèÊØî Llama 3 8B Â∞ë 6.6 ÂÄç„ÄÇÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫ÜË≥áÊñôÈõÜË®≠Ë®àÂ∞çË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶ÁÇ∫Ë≥áÊñôÁ≠ñÂ±ïÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãËµ∑Èªû„ÄÇ</paragraph>

##### **A Brief Survey on Leveraging Large Scale Vision Models for Enhanced Robot Grasping**
2406.11786v1 by Abhi Kamboj, Katherine Driggs-Campbell

Robotic grasping presents a difficult motor task in real-world scenarios,
constituting a major hurdle to the deployment of capable robots across various
industries. Notably, the scarcity of data makes grasping particularly
challenging for learned models. Recent advancements in computer vision have
witnessed a growth of successful unsupervised training mechanisms predicated on
massive amounts of data sourced from the Internet, and now nearly all prominent
models leverage pretrained backbone networks. Against this backdrop, we begin
to investigate the potential benefits of large-scale visual pretraining in
enhancing robot grasping performance. This preliminary literature review sheds
light on critical challenges and delineates prospective directions for future
research in visual pretraining for robotic manipulation.

ÊëòË¶ÅÔºöÊ©üÂô®‰∫∫ÊäìÊè°Âú®ÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÂëàÁèæÂá∫Âõ∞Èõ£ÁöÑÈÅãÂãï‰ªªÂãôÔºå
ÊßãÊàêÊ©üÂô®‰∫∫Âú®ÂêÑÂÄãÁî¢Ê•≠‰∏≠ÈÉ®ÁΩ≤ÁöÑÈáçÂ§ßÈöúÁ§ô„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊï∏ÊìöÁöÑÁ®ÄÁº∫ÊÄß‰ΩøÂæóÊäìÊè°Â∞çÂ≠∏ÁøíÊ®°ÂûãÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊúÄËøëÂú®ÈõªËÖ¶Ë¶ñË¶∫ÊñπÈù¢ÁöÑÈÄ≤Â±ïË¶ãË≠â‰∫ÜÊàêÂäüÁÑ°Áõ£Áù£Ë®ìÁ∑¥Ê©üÂà∂ÁöÑÊàêÈï∑ÔºåÈÄô‰∫õÊ©üÂà∂Âª∫Á´ãÂú®ÂæûÁ∂≤ÈöõÁ∂≤Ë∑Ø‰∏äÂèñÂæóÁöÑÂ§ßÈáèÊï∏ÊìöÔºåËÄåÁèæÂú®Âπæ‰πéÊâÄÊúâËëóÂêçÁöÑÊ®°ÂûãÈÉΩÂà©Áî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑ‰∏ªÂππÁ∂≤Ë∑Ø„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåÊàëÂÄëÈñãÂßãÊé¢Ë®éÂ§ßË¶èÊ®°Ë¶ñË¶∫È†êË®ìÁ∑¥Âú®ÊèêÂçáÊ©üÂô®‰∫∫ÊäìÊè°ÊïàËÉΩÊñπÈù¢ÁöÑÊΩõÂú®Â•ΩËôï„ÄÇÈÄôÁØáÂàùÊ≠•ÊñáÁçªÂõûÈ°ßÈó°Êòé‰∫ÜÈóúÈçµÊåëÊà∞Ôºå‰∏¶ÂãæÂãíÂá∫Ê©üÂô®‰∫∫Êìç‰ΩúË¶ñË¶∫È†êË®ìÁ∑¥Êú™‰æÜÁ†îÁ©∂ÁöÑÈ†êÊúüÊñπÂêë„ÄÇ

##### **CELL your Model: Contrastive Explanation Methods for Large Language Models**
2406.11785v1 by Ronny Luss, Erik Miehling, Amit Dhurandhar

The advent of black-box deep neural network classification models has sparked
the need to explain their decisions. However, in the case of generative AI such
as large language models (LLMs), there is no class prediction to explain.
Rather, one can ask why an LLM output a particular response to a given prompt.
In this paper, we answer this question by proposing, to the best of our
knowledge, the first contrastive explanation methods requiring simply
black-box/query access. Our explanations suggest that an LLM outputs a reply to
a given prompt because if the prompt was slightly modified, the LLM would have
given a different response that is either less preferable or contradicts the
original response. The key insight is that contrastive explanations simply
require a distance function that has meaning to the user and not necessarily a
real valued representation of a specific response (viz. class label). We offer
two algorithms for finding contrastive explanations: i) A myopic algorithm,
which although effective in creating contrasts, requires many model calls and
ii) A budgeted algorithm, our main algorithmic contribution, which
intelligently creates contrasts adhering to a query budget, necessary for
longer contexts. We show the efficacy of these methods on diverse natural
language tasks such as open-text generation, automated red teaming, and
explaining conversational degradation.

ÊëòË¶ÅÔºöÈö®ËëóÈªëÁÆ±Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÂàÜÈ°ûÊ®°ÂûãÁöÑÂá∫ÁèæÔºåËß£ÈáãÂÖ∂Ê±∫Á≠ñÁöÑÈúÄÊ±Ç‰πüÈö®‰πãÁî¢Áîü„ÄÇÁÑ∂ËÄåÔºåÂú®ÁîüÊàêÂºè AIÔºà‰æãÂ¶ÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºâÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊ≤íÊúâÈ°ûÂà•È†êÊ∏¨ÂèØ‰ª•Ëß£Èáã„ÄÇÁõ∏ÂèçÔºåÂèØ‰ª•Ë©¢Âïè LLM ÁÇ∫‰ΩïÂ∞çÁâπÂÆöÊèêÁ§∫Ëº∏Âá∫ÁâπÂÆöÂõûÊáâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÊèêÂá∫ÔºàÊìöÊàëÂÄëÊâÄÁü•ÔºâÁ¨¨‰∏ÄÂÄãÂè™Ë¶ÅÊ±ÇÈªëÁÆ±/Êü•Ë©¢Â≠òÂèñÊ¨äÁöÑÂ∞çÊØîËß£ÈáãÊñπÊ≥ï‰æÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÁöÑËß£ÈáãË°®ÊòéÔºåLLM Â∞çÁâπÂÆöÊèêÁ§∫Ëº∏Âá∫ÁöÑÂõûË¶ÜÊòØÂõ†ÁÇ∫ÔºåÂ¶ÇÊûúÊèêÁ§∫Á®ç‰Ωú‰øÆÊîπÔºåLLM ÊúÉÁµ¶Âá∫‰∏çÂêåÁöÑÂõûË¶ÜÔºåËÄåË©≤ÂõûË¶ÜËºÉ‰∏çÁêÜÊÉ≥ÊàñËàáÂéüÂßãÂõûË¶ÜÁõ∏ÁüõÁõæ„ÄÇÈóúÈçµË¶ãËß£Âú®ÊñºÔºåÂ∞çÊØîËß£ÈáãÂÉÖÈúÄË¶ÅÂ∞ç‰ΩøÁî®ËÄÖÊúâÊÑèÁæ©ÁöÑË∑ùÈõ¢ÂáΩÊï∏ÔºåËÄå‰∏ç‰∏ÄÂÆöÈúÄË¶ÅÁâπÂÆöÂõûË¶ÜÁöÑÂØ¶ÂÄºË°®Á§∫ÔºàÂç≥È°ûÂà•Ê®ôÁ±§Ôºâ„ÄÇÊàëÂÄëÊèê‰æõ‰∫ÜÂÖ©Á®ÆÂ∞ãÊâæÂ∞çÊØîËß£ÈáãÁöÑÊºîÁÆóÊ≥ïÔºöi) ‰∏ÄÁ®ÆËøëË¶ñÊºîÁÆóÊ≥ïÔºåÈõñÁÑ∂Âú®Âª∫Á´ãÂ∞çÊØîÊñπÈù¢ÊúâÊïàÔºå‰ΩÜÈúÄË¶ÅË®±Â§öÊ®°ÂûãÂëºÂè´Ôºå‰ª•Âèä ii) ‰∏ÄÁ®ÆÈ†êÁÆóÊºîÁÆóÊ≥ïÔºåÈÄôÊòØÊàëÂÄë‰∏ªË¶ÅÁöÑÊºîÁÆóÊ≥ïË≤¢ÁçªÔºåÂÆÉÂèØ‰ª•Êô∫ÊÖßÂú∞Âª∫Á´ãÁ¨¶ÂêàÊü•Ë©¢È†êÁÆóÁöÑÂ∞çÊØîÔºåÈÄôÂ∞çÊñºËºÉÈï∑ÁöÑËÑàÁµ°ÊòØÂøÖË¶ÅÁöÑ„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®Ä‰ªªÂãô‰∏äÂ±ïÁ§∫‰∫ÜÈÄô‰∫õÊñπÊ≥ïÁöÑÊïàËÉΩÔºå‰æãÂ¶ÇÈñãÊîæÊñáÂ≠óÁîüÊàê„ÄÅËá™ÂãïÂåñÁ¥ÖÈöäÊ∏¨Ë©¶Ôºå‰ª•ÂèäËß£ÈáãÂ∞çË©±ÂºèÈÄÄÂåñ„ÄÇ

##### **MDCR: A Dataset for Multi-Document Conditional Reasoning**
2406.11784v1 by Peter Baile Chen, Yi Zhang, Chunwei Liu, Sejal Gupta, Yoon Kim, Michael Cafarella

The same real-life questions posed to different individuals may lead to
different answers based on their unique situations. For instance, whether a
student is eligible for a scholarship depends on eligibility conditions, such
as major or degree required. ConditionalQA was proposed to evaluate models'
capability of reading a document and answering eligibility questions,
considering unmentioned conditions. However, it is limited to questions on
single documents, neglecting harder cases that may require cross-document
reasoning and optimization, for example, "What is the maximum number of
scholarships attainable?" Such questions over multiple documents are not only
more challenging due to more context having to understand, but also because the
model has to (1) explore all possible combinations of unmentioned conditions
and (2) understand the relationship between conditions across documents, to
reason about the optimal outcome. To evaluate models' capability of answering
such questions, we propose a new dataset MDCR, which can reflect real-world
challenges and serve as a new test bed for complex conditional reasoning that
requires optimization. We evaluate this dataset using the most recent LLMs and
demonstrate their limitations in solving this task. We believe this dataset
will facilitate future research in answering optimization questions with
unknown conditions.

ÊëòË¶ÅÔºöÁõ∏ÂêåÁöÑÁúüÂØ¶ÁîüÊ¥ªÂïèÈ°åÂêë‰∏çÂêåÁöÑ‰∫∫ÊèêÂá∫ÊôÇÔºåÂèØËÉΩÊúÉÊ†πÊìö‰ªñÂÄëÁç®ÁâπÁöÑÊÉÖÊ≥ÅËÄåÂ∞éËá¥‰∏çÂêåÁöÑÁ≠îÊ°à„ÄÇ‰æãÂ¶ÇÔºåÂ≠∏ÁîüÊòØÂê¶ÊúâË≥áÊ†ºÁç≤ÂæóÁçéÂ≠∏ÈáëÂèñÊ±∫ÊñºË≥áÊ†ºÊ¢ù‰ª∂Ôºå‰æãÂ¶ÇÊâÄÈúÄÁöÑÂ∞àÊ•≠ÊàñÂ≠∏‰Ωç„ÄÇConditionalQA Ë¢´ÊèêË≠∞Áî®ÊñºË©ï‰º∞Ê®°ÂûãÈñ±ËÆÄÊñá‰ª∂ÂíåÂõûÁ≠îË≥áÊ†ºÂïèÈ°åÁöÑËÉΩÂäõÔºåËÄÉÊÖÆÊú™ÊèêÂà∞ÁöÑÊ¢ù‰ª∂„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÉÖÈôêÊñºÂñÆ‰∏ÄÊñá‰ª∂ÁöÑÂïèÈ°åÔºåÂøΩË¶ñ‰∫ÜÂèØËÉΩÈúÄË¶ÅË∑®Êñá‰ª∂Êé®ÁêÜÂíåÂÑ™ÂåñÁöÑÊõ¥Âõ∞Èõ£ÁöÑÊÉÖÊ≥ÅÔºå‰æãÂ¶ÇÔºå„ÄåÂèØ‰ª•Áç≤ÂæóÁöÑÊúÄÂ§ßÁçéÂ≠∏ÈáëÊï∏ÈáèÊòØÂ§öÂ∞ëÔºü„ÄçÊ≠§È°ûË∑®Â§öÂÄãÊñá‰ª∂ÁöÑÂïèÈ°å‰∏çÂÉÖÁî±ÊñºÂøÖÈ†àÁêÜËß£ÁöÑÂÖßÂÆπÊõ¥Â§öËÄåÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÔºåÈÇÑÂõ†ÁÇ∫Ê®°ÂûãÂøÖÈ†à (1) Êé¢Á¥¢Êú™ÊèêÂèäÊ¢ù‰ª∂ÁöÑÊâÄÊúâÂèØËÉΩÁµÑÂêàÔºå‰ª•Âèä (2) ‰∫ÜËß£Ë∑®Êñá‰ª∂Ê¢ù‰ª∂‰πãÈñìÁöÑÈóú‰øÇÔºåÊâçËÉΩÂ∞çÊúÄ‰Ω≥ÁµêÊûúÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞Ê®°ÂûãÂõûÁ≠îÊ≠§È°ûÂïèÈ°åÁöÑËÉΩÂäõÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜ MDCRÔºåÂÆÉÂèØ‰ª•ÂèçÊò†ÁèæÂØ¶‰∏ñÁïåÁöÑÊåëÊà∞Ôºå‰∏¶‰ΩúÁÇ∫Ë§áÈõúÊ¢ù‰ª∂Êé®ÁêÜÁöÑÊñ∞Ê∏¨Ë©¶Âπ≥Âè∞ÔºåÈúÄË¶ÅÈÄ≤Ë°åÂÑ™Âåñ„ÄÇÊàëÂÄë‰ΩøÁî®ÊúÄÊñ∞ÁöÑ LLM Ë©ï‰º∞Ê≠§Ë≥áÊñôÈõÜÔºå‰∏¶Â±ïÁ§∫ÂÆÉÂÄëÂú®Ëß£Ê±∫Ê≠§‰ªªÂãôÊôÇÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÁõ∏‰ø°Ê≠§Ë≥áÊñôÈõÜÂ∞á‰øÉÈÄ≤Êú™‰æÜÂú®ÂõûÁ≠îÂÖ∑ÊúâÊú™Áü•Ê¢ù‰ª∂ÁöÑÂÑ™ÂåñÂïèÈ°åÊñπÈù¢ÁöÑÁ†îÁ©∂„ÄÇ

##### **Split, Unlearn, Merge: Leveraging Data Attributes for More Effective Unlearning in LLMs**
2406.11780v1 by Swanand Ravindra Kadhe, Farhan Ahmed, Dennis Wei, Nathalie Baracaldo, Inkit Padhi

Large language models (LLMs) have shown to pose social and ethical risks such
as generating toxic language or facilitating malicious use of hazardous
knowledge. Machine unlearning is a promising approach to improve LLM safety by
directly removing harmful behaviors and knowledge. In this paper, we propose
"SPlit, UNlearn, MerGE" (SPUNGE), a framework that can be used with any
unlearning method to amplify its effectiveness. SPUNGE leverages data
attributes during unlearning by splitting unlearning data into subsets based on
specific attribute values, unlearning each subset separately, and merging the
unlearned models. We empirically demonstrate that SPUNGE significantly improves
the performance of two recent unlearning methods on state-of-the-art LLMs while
maintaining their general capabilities on standard academic benchmarks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤È°ØÁ§∫ÊúÉÈÄ†ÊàêÁ§æÊúÉÂíåÈÅìÂæ∑È¢®Èö™Ôºå‰æãÂ¶ÇÁî¢ÁîüÊúâÊØíË™ûË®ÄÊàñ‰øÉÈÄ≤ÊÉ°ÊÑè‰ΩøÁî®Âç±Èö™Áü•Ë≠ò„ÄÇÊ©üÂô®ÈÅ∫ÂøòÊòØ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂèØÈÄèÈÅéÁõ¥Êé•ÁßªÈô§ÊúâÂÆ≥Ë°åÁÇ∫ÂíåÁü•Ë≠ò‰æÜÊîπÂñÑ LLM ÁöÑÂÆâÂÖ®ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫„ÄåSPlit, UNlearn, MerGE„ÄçÔºàSPUNGEÔºâÔºå‰∏ÄÂÄãÂèØËàá‰ªª‰ΩïÈÅ∫ÂøòÊñπÊ≥ï‰∏ÄËµ∑‰ΩøÁî®‰ª•Êì¥Â§ßÂÖ∂ÊúâÊïàÊÄßÁöÑÊ°ÜÊû∂„ÄÇSPUNGE Âú®ÈÅ∫ÂøòÈÅéÁ®ã‰∏≠Âà©Áî®Ë≥áÊñôÂ±¨ÊÄßÔºåÈÄèÈÅéÊ†πÊìöÁâπÂÆöÂ±¨ÊÄßÂÄºÂ∞áÈÅ∫ÂøòË≥áÊñôÂàÜÂâ≤ÊàêÂ≠êÈõÜ„ÄÅÂÄãÂà•ÈÅ∫ÂøòÊØèÂÄãÂ≠êÈõÜÔºåÁÑ∂ÂæåÂêà‰ΩµÂ∑≤ÈÅ∫ÂøòÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÈÄèÈÅéÂØ¶Ë≠âË≠âÊòéÔºåSPUNGE Âú®ÊúÄÂÖàÈÄ≤ÁöÑ LLM ‰∏äÈ°ØËëóÊîπÂñÑ‰∫ÜÂÖ©Á®ÆÊúÄÊñ∞ÈÅ∫ÂøòÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÂêåÊôÇÂú®Ê®ôÊ∫ñÂ≠∏Ë°ìÂü∫Ê∫ñ‰∏äÁ∂≠ÊåÅÂÖ∂‰∏ÄËà¨ËÉΩÂäõ„ÄÇ

##### **Improving Multi-Agent Debate with Sparse Communication Topology**
2406.11776v1 by Yunxuan Li, Yibing Du, Jiageng Zhang, Le Hou, Peter Grabowski, Yeqing Li, Eugene Ie

Multi-agent debate has proven effective in improving large language models
quality for reasoning and factuality tasks. While various role-playing
strategies in multi-agent debates have been explored, in terms of the
communication among agents, existing approaches adopt a brute force algorithm
-- each agent can communicate with all other agents. In this paper, we
systematically investigate the effect of communication connectivity in
multi-agent systems. Our experiments on GPT and Mistral models reveal that
multi-agent debates leveraging sparse communication topology can achieve
comparable or superior performance while significantly reducing computational
costs. Furthermore, we extend the multi-agent debate framework to multimodal
reasoning and alignment labeling tasks, showcasing its broad applicability and
effectiveness. Our findings underscore the importance of communication
connectivity on enhancing the efficiency and effectiveness of the "society of
minds" approach.

ÊëòË¶ÅÔºöÂ§ö‰∏ªÈ´îËæØË´ñÂ∑≤Ë¢´Ë≠âÂØ¶ËÉΩÊúâÊïàÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Êé®ÁêÜÂíå‰∫ãÂØ¶ÊÄß‰ªªÂãô‰∏≠ÁöÑÂìÅË≥™„ÄÇÂÑòÁÆ°Â∑≤Êé¢Ë®éÈÅéÂ§ö‰∏ªÈ´îËæØË´ñ‰∏≠ÂêÑÁ®ÆËßíËâ≤ÊâÆÊºîÁ≠ñÁï•Ôºå‰ΩÜÂú®‰∏ªÈ´îÈñìÁöÑÊ∫ùÈÄöÊñπÈù¢ÔºåÁèæÊúâÊñπÊ≥ïÊé°Áî®Ë†ªÂäõÊºîÁÆóÊ≥ï‚Äî‚ÄîÊØèÂÄã‰∏ªÈ´îÈÉΩÂèØ‰ª•ËàáÊâÄÊúâÂÖ∂‰ªñ‰∏ªÈ´îÊ∫ùÈÄö„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Êé¢Ë®é‰∫ÜÊ∫ùÈÄöÈÄ£ÈÄöÊÄßÂú®Â§ö‰∏ªÈ´îÁ≥ªÁµ±‰∏≠ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂú® GPT Âíå Mistral Ê®°Âûã‰∏äÁöÑÂØ¶È©óÊè≠Á§∫ÔºåÂà©Áî®Á®ÄÁñèÊ∫ùÈÄöÊãìÊí≤ÁöÑÂ§ö‰∏ªÈ´îËæØË´ñÂèØ‰ª•Âú®Â§ßÂπÖÈôç‰ΩéÈÅãÁÆóÊàêÊú¨ÁöÑÂêåÊôÇÔºåÈÅîÂà∞ÂèØÊØîËºÉÊàñÊõ¥‰Ω≥ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞áÂ§ö‰∏ªÈ´îËæØË´ñÊû∂ÊßãÂª∂‰º∏Âà∞Â§öÊ®°ÊÖãÊé®ÁêÜÂíåÊØîÂ∞çÊ®ôË®ò‰ªªÂãôÔºåÂ±ïÁ§∫ÂÖ∂Âª£Ê≥õÁöÑÈÅ©Áî®ÊÄßÂíåÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÊ∫ùÈÄöÈÄ£ÈÄöÊÄßÂ∞çÊñºÊèêÂçá„ÄåÂøÉÊô∫Á§æÊúÉ„ÄçÊñπÊ≥ïÁöÑÊïàÁéáÂíåÊúâÊïàÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Task Me Anything**
2406.11775v1 by Jieyu Zhang, Weikai Huang, Zixian Ma, Oscar Michel, Dong He, Tanmay Gupta, Wei-Chiu Ma, Ali Farhadi, Aniruddha Kembhavi, Ranjay Krishna

Benchmarks for large multimodal language models (MLMs) now serve to
simultaneously assess the general capabilities of models instead of evaluating
for a specific capability. As a result, when a developer wants to identify
which models to use for their application, they are overwhelmed by the number
of benchmarks and remain uncertain about which benchmark's results are most
reflective of their specific use case. This paper introduces Task-Me-Anything,
a benchmark generation engine which produces a benchmark tailored to a user's
needs. Task-Me-Anything maintains an extendable taxonomy of visual assets and
can programmatically generate a vast number of task instances. Additionally, it
algorithmically addresses user queries regarding MLM performance efficiently
within a computational budget. It contains 113K images, 10K videos, 2K 3D
object assets, over 365 object categories, 655 attributes, and 335
relationships. It can generate 750M image/video question-answering pairs, which
focus on evaluating MLM perceptual capabilities. Task-Me-Anything reveals
critical insights: open-source MLMs excel in object and attribute recognition
but lack spatial and temporal understanding; each model exhibits unique
strengths and weaknesses; larger models generally perform better, though
exceptions exist; and GPT4o demonstrates challenges in recognizing
rotating/moving objects and distinguishing colors.

ÊëòË¶ÅÔºöÂ§ßÂûãÂ§öÊ®°ÊÄÅËØ≠Ë®ÄÊ®°Âûã (MLM) ÁöÑÂü∫ÂáÜÁé∞Âú®ÂèØÁî®‰∫éÂêåÊó∂ËØÑ‰º∞Ê®°ÂûãÁöÑÈÄöÁî®ÂäüËÉΩÔºåËÄå‰∏çÊòØËØÑ‰º∞ÁâπÂÆöÂäüËÉΩ„ÄÇÂõ†Ê≠§ÔºåÂΩìÂºÄÂèë‰∫∫ÂëòÊÉ≥Ë¶ÅÁ°ÆÂÆö‰∏∫ÂÖ∂Â∫îÁî®Á®ãÂ∫è‰ΩøÁî®Âì™‰∫õÊ®°ÂûãÊó∂Ôºå‰ªñ‰ª¨‰ºöË¢´Âü∫ÂáÜÊï∞ÈáèÊâÄÊ∑πÊ≤°ÔºåÂπ∂‰∏î‰ªçÁÑ∂‰∏çÁ°ÆÂÆöÂì™‰∏™Âü∫ÂáÜÁöÑÁªìÊûúÊúÄËÉΩÂèçÊò†ÂÖ∂ÁâπÂÆöÁî®‰æã„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü Task-Me-AnythingÔºåËøôÊòØ‰∏Ä‰∏™Âü∫ÂáÜÁîüÊàêÂºïÊìéÔºåÂèØ‰ª•Ê†πÊçÆÁî®Êà∑ÁöÑÈúÄÊ±ÇÁîüÊàêÂÆöÂà∂Âü∫ÂáÜ„ÄÇTask-Me-Anything Áª¥Êä§‰∫Ü‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑÂèØËßÜËµÑ‰∫ßÂàÜÁ±ªÊ≥ïÔºåÂπ∂‰∏îÂèØ‰ª•‰ª•ÁºñÁ®ãÊñπÂºèÁîüÊàêÂ§ßÈáè‰ªªÂä°ÂÆû‰æã„ÄÇÊ≠§Â§ñÔºåÂÆÉÂú®ËÆ°ÁÆóÈ¢ÑÁÆóÂÜÖÈÄöËøáÁÆóÊ≥ïÈ´òÊïàÂú∞Â§ÑÁêÜÁî®Êà∑ÂÖ≥‰∫é MLM ÊÄßËÉΩÁöÑÊü•ËØ¢„ÄÇÂÆÉÂåÖÂê´ 113K Âº†ÂõæÂÉè„ÄÅ10K ‰∏™ËßÜÈ¢ë„ÄÅ2K ‰∏™ 3D ÂØπË±°ËµÑ‰∫ß„ÄÅË∂ÖËøá 365 ‰∏™ÂØπË±°Á±ªÂà´„ÄÅ655 ‰∏™Â±ûÊÄßÂíå 335 ‰∏™ÂÖ≥Á≥ª„ÄÇÂÆÉÂèØ‰ª•ÁîüÊàê 750M ‰∏™ÂõæÂÉè/ËßÜÈ¢ëÈóÆÁ≠îÂØπÔºåÈáçÁÇπÊòØËØÑ‰º∞ MLM ÊÑüÁü•ËÉΩÂäõ„ÄÇTask-Me-Anything Êè≠Á§∫‰∫ÜÂÖ≥ÈîÆËßÅËß£ÔºöÂºÄÊ∫ê MLM Âú®ÂØπË±°ÂíåÂ±ûÊÄßËØÜÂà´ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÁº∫‰πèÁ©∫Èó¥ÂíåÊó∂Èó¥ÁêÜËß£ÔºõÊØè‰∏™Ê®°ÂûãÈÉΩË°®Áé∞Âá∫Áã¨ÁâπÁöÑ‰ºòÂäøÂíåÂä£ÂäøÔºõËæÉÂ§ßÁöÑÊ®°ÂûãÈÄöÂ∏∏Ë°®Áé∞ÂæóÊõ¥Â•ΩÔºåÂ∞ΩÁÆ°Â≠òÂú®‰æãÂ§ñÔºõGPT4o Âú®ËØÜÂà´ÊóãËΩ¨/ÁßªÂä®Áâ©‰ΩìÂíåÂå∫ÂàÜÈ¢úËâ≤ÊñπÈù¢Ë°®Áé∞Âá∫ÊåëÊàò„ÄÇ

##### **GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities**
2406.11768v1 by Sreyan Ghosh, Sonal Kumar, Ashish Seth, Chandra Kiran Reddy Evuru, Utkarsh Tyagi, S Sakshi, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha

Perceiving and understanding non-speech sounds and non-verbal speech is
essential to making decisions that help us interact with our surroundings. In
this paper, we propose GAMA, a novel General-purpose Large Audio-Language Model
(LALM) with Advanced Audio Understanding and Complex Reasoning Abilities. We
build GAMA by integrating an LLM with multiple types of audio representations,
including features from a custom Audio Q-Former, a multi-layer aggregator that
aggregates features from multiple layers of an audio encoder. We fine-tune GAMA
on a large-scale audio-language dataset, which augments it with audio
understanding capabilities. Next, we propose CompA-R (Instruction-Tuning for
Complex Audio Reasoning), a synthetically generated instruction-tuning (IT)
dataset with instructions that require the model to perform complex reasoning
on the input audio. We instruction-tune GAMA with CompA-R to endow it with
complex reasoning abilities, where we further add a soft prompt as input with
high-level semantic evidence by leveraging event tags of the input audio.
Finally, we also propose CompA-R-test, a human-labeled evaluation dataset for
evaluating the capabilities of LALMs on open-ended audio question-answering
that requires complex reasoning. Through automated and expert human
evaluations, we show that GAMA outperforms all other LALMs in literature on
diverse audio understanding tasks by margins of 1%-84%. Further, GAMA IT-ed on
CompA-R proves to be superior in its complex reasoning and instruction
following capabilities.

ÊëòË¶ÅÔºö<paragraph>ÊÑüÁü•ÂíåÁêÜËß£ÈùûË™ûË®ÄËÅ≤Èü≥ÂíåÈùûË™ûË®ÄË®ÄË™ûÂ∞çÊñºÂÅöÂá∫ÊúâÂä©ÊñºÊàëÂÄëËàáÂë®ÂúçÁí∞Â¢É‰∫íÂãïÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ GAMAÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈÄöÁî®Â§ßÂûãÈü≥Ë®äË™ûË®ÄÊ®°Âûã (LALM)ÔºåÂÖ∑ÂÇôÂÖàÈÄ≤ÁöÑÈü≥Ë®äÁêÜËß£ÂíåË§áÈõúÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞á LLM ËàáÂ§öÁ®ÆÈ°ûÂûãÁöÑÈü≥Ë®äË°®ÂæµÊï¥ÂêàÂú®‰∏ÄËµ∑‰æÜÂª∫Êßã GAMAÔºåÂåÖÊã¨‰æÜËá™Ëá™Ë®ÇÈü≥Ë®ä Q-Former ÁöÑÁâπÂæµÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÂ±§ËÅöÂêàÂô®ÔºåÂèØ‰ª•ËÅöÂêàÈü≥Ë®äÁ∑®Á¢ºÂô®ÁöÑÂ§öÂ±§ÁâπÂæµ„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÈü≥Ë®äË™ûË®ÄË≥áÊñôÈõÜ‰∏äÂæÆË™ø GAMAÔºåÈÄôË≥¶‰∫àÂÆÉÈü≥Ë®äÁêÜËß£ËÉΩÂäõ„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÊèêÂá∫ CompA-RÔºàË§áÈõúÈü≥Ë®äÊé®ÁêÜÁöÑÊåá‰ª§ÂæÆË™øÔºâÔºå‰∏ÄÂÄãÂêàÊàêÁî¢ÁîüÁöÑÊåá‰ª§ÂæÆË™ø (IT) Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÈúÄË¶ÅÊ®°ÂûãÂ∞çËº∏ÂÖ•Èü≥Ë®äÂü∑Ë°åË§áÈõúÊé®ÁêÜÁöÑÊåá‰ª§„ÄÇÊàëÂÄë‰ΩøÁî® CompA-R Â∞ç GAMA ÈÄ≤Ë°åÊåá‰ª§ÂæÆË™øÔºåË≥¶‰∫àÂÆÉË§áÈõúÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ê∑ªÂä†‰∏ÄÂÄãËªüÊèêÁ§∫‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰∏¶ÈÄèÈÅéÂà©Áî®Ëº∏ÂÖ•Èü≥Ë®äÁöÑ‰∫ã‰ª∂Ê®ôÁ±§‰æÜÁç≤ÂèñÈ´òÂ±§Á¥öË™ûÁæ©Ë≠âÊìö„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü CompA-R-testÔºå‰∏ÄÂÄã‰∫∫Â∑•Ê®ôË®òÁöÑË©ï‰º∞Ë≥áÊñôÈõÜÔºåÁî®ÊñºË©ï‰º∞ LALM Âú®ÈúÄË¶ÅË§áÈõúÊé®ÁêÜÁöÑÈñãÊîæÂºèÈü≥Ë®äÂïèÁ≠î‰∏äÁöÑËÉΩÂäõ„ÄÇÈÄèÈÅéËá™ÂãïÂåñÂíåÂ∞àÂÆ∂‰∫∫Â∑•Ë©ï‰º∞ÔºåÊàëÂÄëË°®Êòé GAMA Âú®ÂêÑÁ®ÆÈü≥Ë®äÁêÜËß£‰ªªÂãô‰∏äÂÑ™ÊñºÊñáÁçª‰∏≠ÁöÑÊâÄÊúâÂÖ∂‰ªñ LALMÔºåÂπÖÂ∫¶ÁÇ∫ 1%-84%„ÄÇÊ≠§Â§ñÔºåÂú® CompA-R ‰∏äÈÄ≤Ë°å IT ÁöÑ GAMA Ë≠âÊòéÂÖ∂Âú®Ë§áÈõúÊé®ÁêÜÂíåÊåá‰ª§ÈÅµÂæ™ËÉΩÂäõÊñπÈù¢ÂÖ∑ÊúâÂÑ™Ë∂äÊÄß„ÄÇ</paragraph>

##### **STAR: SocioTechnical Approach to Red Teaming Language Models**
2406.11757v1 by Laura Weidinger, John Mellor, Bernat Guillen Pegueroles, Nahema Marchal, Ravin Kumar, Kristian Lum, Canfer Akbulut, Mark Diaz, Stevie Bergman, Mikel Rodriguez, Verena Rieser, William Isaac

This research introduces STAR, a sociotechnical framework that improves on
current best practices for red teaming safety of large language models. STAR
makes two key contributions: it enhances steerability by generating
parameterised instructions for human red teamers, leading to improved coverage
of the risk surface. Parameterised instructions also provide more detailed
insights into model failures at no increased cost. Second, STAR improves signal
quality by matching demographics to assess harms for specific groups, resulting
in more sensitive annotations. STAR further employs a novel step of arbitration
to leverage diverse viewpoints and improve label reliability, treating
disagreement not as noise but as a valuable contribution to signal quality.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü STARÔºå‰∏ÄÁ®ÆÁ§æÊúÉÊäÄË°ìÊ°ÜÊû∂ÔºåÊîπÈÄ≤‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁ¥ÖÈöäÂÆâÂÖ®ÊÄßÁöÑÁèæÊúâÊúÄ‰Ω≥ÂØ¶Âãô„ÄÇSTAR ÂÅöÂá∫ÂÖ©È†Ö‰∏ªË¶ÅË≤¢ÁçªÔºöÂÆÉÈÄèÈÅéÁÇ∫‰∫∫È°ûÁ¥ÖÈöäÂì°Áî¢ÁîüÂèÉÊï∏ÂåñÊåá‰ª§‰æÜÂ¢ûÂº∑ÂèØÂ∞éÂêëÊÄßÔºåÈÄ≤ËÄåÊîπÂñÑÈ¢®Èö™Ë°®Èù¢ÁöÑË¶ÜËìãÁØÑÂúç„ÄÇÂèÉÊï∏ÂåñÊåá‰ª§‰πü‰ª•ÁÑ°Â¢ûÂä†ÊàêÊú¨ÁöÑÊñπÂºèÊèê‰æõÊõ¥Ë©≥Á¥∞ÁöÑÊ®°ÂûãÂ§±ÊïóË¶ãËß£„ÄÇÂÖ∂Ê¨°ÔºåSTAR ÈÄèÈÅéÊØîÂ∞ç‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰æÜË©ï‰º∞ÁâπÂÆöÁæ§È´îÁöÑÂç±ÂÆ≥ÔºåÈÄ≤ËÄåÊîπÂñÑ‰ø°ËôüÂìÅË≥™ÔºåÁî¢ÁîüÊõ¥ÈùàÊïèÁöÑË®ªËß£„ÄÇSTAR ÈÄ≤‰∏ÄÊ≠•Êé°Áî®‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ‰ª≤Ë£ÅÊ≠•È©üÔºå‰ª•Âà©Áî®‰∏çÂêåÁöÑËßÄÈªû‰∏¶ÊîπÂñÑÊ®ôÁ±§ÂèØÈù†ÊÄßÔºåÂ∞áÂàÜÊ≠ßË¶ñÁÇ∫‰ø°ËôüÂìÅË≥™ÁöÑÂØ∂Ë≤¥Ë≤¢ÁçªÔºåËÄå‰∏çÊòØÈõúË®ä„ÄÇ

##### **DustNet: skillful neural network predictions of Saharan dust**
2406.11754v1 by Trish E. Nowak, Andy T. Augousti, Benno I. Simmons, Stefan Siegert

Suspended in the atmosphere are millions of tonnes of mineral dust which
interacts with weather and climate. Accurate representation of mineral dust in
weather models is vital, yet remains challenging. Large scale weather models
use high power supercomputers and take hours to complete the forecast. Such
computational burden allows them to only include monthly climatological means
of mineral dust as input states inhibiting their forecasting accuracy. Here, we
introduce DustNet a simple, accurate and super fast forecasting model for
24-hours ahead predictions of aerosol optical depth AOD. DustNet trains in less
than 8 minutes and creates predictions in 2 seconds on a desktop computer.
Created by DustNet predictions outperform the state-of-the-art physics-based
model on coarse 1 x 1 degree resolution at 95% of grid locations when compared
to ground truth satellite data. Our results show DustNet has a potential for
fast and accurate AOD forecasting which could transform our understanding of
dust impacts on weather patterns.

ÊëòË¶ÅÔºöÊá∏ÊµÆÂú®Â§ßÊ∞£‰∏≠ÁöÑÁ§¶Áâ©Â°µÊúâÊï∏ÁôæËê¨Âô∏ÔºåÊúÉËàáÂ§©Ê∞£ÂíåÊ∞£ÂÄôÁõ∏‰∫í‰ΩúÁî®„ÄÇÂú®Â§©Ê∞£Ê®°Âûã‰∏≠Ê∫ñÁ¢∫ÂëàÁèæÁ§¶Áâ©Â°µËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂ§ßË¶èÊ®°Â§©Ê∞£Ê®°Âûã‰ΩøÁî®È´òÂäüÁéáË∂ÖÁ¥öÈõªËÖ¶ÔºåÈúÄË¶ÅÊï∏Â∞èÊôÇÊâçËÉΩÂÆåÊàêÈ†êÊ∏¨„ÄÇÈÄôÁ®ÆË®àÁÆóË≤†ÊìîÂè™ËÉΩËÆìÂÆÉÂÄëÂ∞áÁ§¶Áâ©Â°µÁöÑÊØèÊúàÊ∞£ÂÄôÂπ≥ÂùáÂÄº‰ΩúÁÇ∫Ëº∏ÂÖ•ÁãÄÊÖãÔºåÂæûËÄåÊäëÂà∂‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π DustNetÔºåÈÄôÊòØ‰∏ÄÂÄãÁ∞°ÂñÆ„ÄÅÊ∫ñÁ¢∫‰∏îË∂ÖÁ¥öÂø´ÈÄüÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÁî®ÊñºÈ†êÊ∏¨ 24 Â∞èÊôÇÂæåÁöÑÊ∞£Ê∫∂ËÜ†ÂÖâÂ≠∏ÂéöÂ∫¶ AOD„ÄÇDustNet ÁöÑË®ìÁ∑¥ÊôÇÈñì‰∏çÂà∞ 8 ÂàÜÈêòÔºå‰∏¶ÂèØ‰ª•Âú®Ê°å‰∏äÂûãÈõªËÖ¶‰∏äÊñº 2 ÁßíÂÖßÂª∫Á´ãÈ†êÊ∏¨„ÄÇËàáÂú∞Èù¢ÁúüÂØ¶Ë°õÊòüÊï∏ÊìöÁõ∏ÊØîÔºåDustNet È†êÊ∏¨Âú®ËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºÁâ©ÁêÜÊ®°ÂûãÁöÑÁ≤óÁï• 1 x 1 Â∫¶Ëß£ÊûêÂ∫¶‰∏≠ÔºåÊñº 95% ÁöÑÁ∂≤Ê†º‰ΩçÁΩÆË°®ÁèæÂÑ™Áï∞„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåDustNet ÂÖ∑ÊúâÂø´ÈÄü‰∏îÊ∫ñÁ¢∫ÁöÑ AOD È†êÊ∏¨ÊΩõÂäõÔºåÈÄôÂèØ‰ª•ÊîπËÆäÊàëÂÄëÂ∞çÁÅ∞Â°µÂ∞çÂ§©Ê∞£Ê®°ÂºèÂΩ±ÈüøÁöÑÁêÜËß£„ÄÇ

##### **A Semantic-based Layer Freezing Approach to Efficient Fine-Tuning of Language Models**
2406.11753v1 by Jian Gu, Aldeida Aleti, Chunyang Chen, Hongyu Zhang

Finetuning language models (LMs) is crucial for adapting the models to
downstream data and tasks. However, full finetuning is usually costly. Existing
work, such as parameter-efficient finetuning (PEFT), often focuses on
\textit{how to finetune} but neglects the issue of \textit{where to finetune}.
As a pioneering work on answering where to finetune (at the layer level), we
conduct a semantic analysis of the LM inference process. We first propose a
virtual transition of the latent representation and then trace its factual
transition. Based on the deviation in transitions, we estimate the gain of
finetuning each model layer, and further, narrow down the scope for finetuning.
We perform extensive experiments across well-known LMs and datasets. The
results show that our approach is effective and efficient, and outperforms the
existing baselines. Our approach is orthogonal to existing efficient
techniques, such as PEFT methods, offering practical values on LM finetuning.

ÊëòË¶ÅÔºöÂæÆË™øË™ûË®ÄÊ®°Âûã (LM) Â∞çÊñºË™øÊï¥Ê®°Âûã‰ª•ÈÅ©Êáâ‰∏ãÊ∏∏Ë≥áÊñôÂíå‰ªªÂãôËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂÆåÊï¥ÁöÑÂæÆË™øÈÄöÂ∏∏ÊàêÊú¨ÂæàÈ´ò„ÄÇÁèæÊúâÁöÑÂ∑•‰ΩúÔºå‰æãÂ¶ÇÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT)ÔºåÈÄöÂ∏∏ÂÅ¥ÈáçÊñº„ÄåÂ¶Ç‰ΩïÂæÆË™ø„ÄçÔºå‰ΩÜÂøΩÁï•‰∫Ü„ÄåÂú®Âì™Ë£°ÂæÆË™ø„ÄçÁöÑÂïèÈ°å„ÄÇ‰ΩúÁÇ∫ÂõûÁ≠îÂú®Âì™Ë£°ÂæÆË™øÔºàÂú®Â±§Á¥öÔºâÁöÑÈñãÂâµÊÄßÂ∑•‰ΩúÔºåÊàëÂÄëÂ∞ç LM Êé®Ë´ñÈÅéÁ®ãÈÄ≤Ë°å‰∫ÜË™ûÁæ©ÂàÜÊûê„ÄÇÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫ÊΩõÂú®Ë°®ÂæµÁöÑËôõÊì¨ËΩâÊèõÔºåÁÑ∂ÂæåËøΩËπ§ÂÖ∂‰∫ãÂØ¶ËΩâÊèõ„ÄÇÊ†πÊìöËΩâÊèõ‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÊàëÂÄë‰º∞Ë®àÂæÆË™øÊØèÂÄãÊ®°ÂûãÂ±§ÁöÑÂ¢ûÁõäÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Á∏ÆÂ∞èÂæÆË™øÁöÑÁØÑÂúç„ÄÇÊàëÂÄëÂ∞çËëóÂêçÁöÑ LM ÂíåË≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊïà‰∏îÈ´òÊïàÔºå‰∏¶‰∏îÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËàáÁèæÊúâÁöÑÈ´òÊïàÊäÄË°ìÔºà‰æãÂ¶Ç PEFT ÊñπÊ≥ïÔºâÊ≠£‰∫§ÔºåÁÇ∫ LM ÂæÆË™øÊèê‰æõ‰∫ÜÂØ¶Áî®ÁöÑÂÉπÂÄº„ÄÇ

##### **Multi-Layer Ranking with Large Language Models for News Source Recommendation**
2406.11745v1 by Wenjia Zhang, Lin Gui, Rob Procter, Yulan He

To seek reliable information sources for news events, we introduce a novel
task of expert recommendation, which aims to identify trustworthy sources based
on their previously quoted statements. To achieve this, we built a novel
dataset, called NewsQuote, consisting of 23,571 quote-speaker pairs sourced
from a collection of news articles. We formulate the recommendation task as the
retrieval of experts based on their likelihood of being associated with a given
query. We also propose a multi-layer ranking framework employing Large Language
Models to improve the recommendation performance. Our results show that
employing an in-context learning based LLM ranker and a multi-layer
ranking-based filter significantly improve both the predictive quality and
behavioural quality of the recommender system.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÂ∞ãÊâæÊñ∞ËÅû‰∫ã‰ª∂ÁöÑÂèØÈù†Ë≥áË®ä‰æÜÊ∫êÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÂ∞àÂÆ∂Êé®Ëñ¶ÁöÑÊñ∞‰ªªÂãôÔºåÁõÆÊ®ôÊòØÊ†πÊìö‰ªñÂÄë‰πãÂâçÂºïÁî®ÁöÑËÅ≤Êòé‰æÜË≠òÂà•ÂèØ‰ø°Ë≥¥ÁöÑ‰æÜÊ∫ê„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÊ≠§ÁõÆÁöÑÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ NewsQuote ÁöÑÊñ∞Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂæûÊñ∞ËÅûÊñáÁ´†ÈõÜÂêà‰∏≠ÂèñÂæóÁöÑ 23,571 Â∞çÂºïËø∞-ÁôºË®ÄËÄÖ„ÄÇÊàëÂÄëÂ∞áÊé®Ëñ¶‰ªªÂãôÂà∂ÂÆöÁÇ∫Ê†πÊìöÂ∞àÂÆ∂ËàáÁâπÂÆöÊü•Ë©¢Áõ∏ÈóúÁöÑÂèØËÉΩÊÄß‰æÜÊ™¢Á¥¢Â∞àÂÆ∂„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ§öÂ±§Á¥öÊéíÂêçÊû∂ÊßãÔºåÊé°Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã‰æÜÊîπÂñÑÊé®Ëñ¶ÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÊé°Áî®Âü∫ÊñºÊÉÖÂ¢ÉÂ≠∏ÁøíÁöÑ LLM ÊéíÂêçÂô®ÂíåÂü∫ÊñºÂ§öÂ±§Á¥öÊéíÂêçÁöÑÁØ©ÈÅ∏Âô®ÔºåÂèØ‰ª•È°ØËëóÊîπÂñÑÊé®Ëñ¶Á≥ªÁµ±ÁöÑÈ†êÊ∏¨ÂìÅË≥™ÂíåË°åÁÇ∫ÂìÅË≥™„ÄÇ

##### **Transcendence: Generative Models Can Outperform The Experts That Train Them**
2406.11741v1 by Edwin Zhang, Vincent Zhu, Naomi Saphra, Anat Kleiman, Benjamin L. Edelman, Milind Tambe, Sham M. Kakade, Eran Malach

Generative models are trained with the simple objective of imitating the
conditional probability distribution induced by the data they are trained on.
Therefore, when trained on data generated by humans, we may not expect the
artificial model to outperform the humans on their original objectives. In this
work, we study the phenomenon of transcendence: when a generative model
achieves capabilities that surpass the abilities of the experts generating its
data. We demonstrate transcendence by training an autoregressive transformer to
play chess from game transcripts, and show that the trained model can sometimes
achieve better performance than all players in the dataset. We theoretically
prove that transcendence is enabled by low-temperature sampling, and rigorously
assess this experimentally. Finally, we discuss other sources of transcendence,
laying the groundwork for future investigation of this phenomenon in a broader
setting.

ÊëòË¶ÅÔºöÁîüÊàêÊ®°ÂûãÁöÑË®ìÁ∑¥ÁõÆÊ®ôÂæàÁ∞°ÂñÆÔºåÂ∞±ÊòØÊ®°‰ªøË®ìÁ∑¥Ë≥áÊñôÊâÄÂºïÁôºÁöÑÊ¢ù‰ª∂Ê©üÁéáÂàÜ‰Ωà„ÄÇÂõ†Ê≠§ÔºåÁï∂ÊàëÂÄë‰ΩøÁî®‰∫∫È°ûÁî¢ÁîüÁöÑË≥áÊñôÈÄ≤Ë°åË®ìÁ∑¥ÊôÇÔºåÊàëÂÄëÂèØËÉΩ‰∏çÊúÉÊúüÊúõ‰∫∫Â∑•Ê®°ÂûãÂú®ÂéüÊú¨ÁöÑÁõÆÊ®ô‰∏äË∂ÖË∂ä‰∫∫È°û„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éË∂ÖË∂äÁèæË±°ÔºöÁï∂ÁîüÊàêÊ®°ÂûãÈÅîÂà∞ÁöÑËÉΩÂäõË∂ÖË∂äÁî¢ÁîüÂÖ∂Ë≥áÊñôÁöÑÂ∞àÂÆ∂ËÉΩÂäõ„ÄÇÊàëÂÄëÈÄèÈÅéË®ìÁ∑¥‰∏ÄÂÄãËá™Ëø¥Ê≠∏TransformerÂæûÈÅäÊà≤Ë®òÈåÑ‰∏≠‰∏ãÊ£ã‰æÜË≠âÊòéË∂ÖË∂äÔºå‰∏¶È°ØÁ§∫Ë®ìÁ∑¥Âá∫‰æÜÁöÑÊ®°ÂûãÊúâÊôÇÂèØ‰ª•Âú®Ë≥áÊñôÈõÜ‰∏≠ÈÅîÊàêÊØîÊâÄÊúâÁé©ÂÆ∂Êõ¥Â•ΩÁöÑË°®Áèæ„ÄÇÊàëÂÄëÂú®ÁêÜË´ñ‰∏äË≠âÊòé‰∫ÜË∂ÖË∂äÊòØÁî±‰ΩéÊ∫´ÂèñÊ®£ÊâÄ‰øÉÊàêÔºå‰∏¶Âö¥Ê†ºÂú∞‰ª•ÂØ¶È©óË©ï‰º∞ÈÄô‰∏ÄÈªû„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñË∂ÖË∂äÁöÑÂÖ∂‰ªñ‰æÜÊ∫êÔºåÁÇ∫Êú™‰æÜÂú®Êõ¥Âª£Ê≥õÁöÑË®≠ÂÆö‰∏≠Êé¢Ë®éÊ≠§ÁèæË±°Â•†ÂÆöÂü∫Á§é„ÄÇ

##### **Imagination Policy: Using Generative Point Cloud Models for Learning Manipulation Policies**
2406.11740v1 by Haojie Huang, Karl Schmeckpeper, Dian Wang, Ondrej Biza, Yaoyao Qian, Haotian Liu, Mingxi Jia, Robert Platt, Robin Walters

Humans can imagine goal states during planning and perform actions to match
those goals. In this work, we propose Imagination Policy, a novel multi-task
key-frame policy network for solving high-precision pick and place tasks.
Instead of learning actions directly, Imagination Policy generates point clouds
to imagine desired states which are then translated to actions using rigid
action estimation. This transforms action inference into a local generative
task. We leverage pick and place symmetries underlying the tasks in the
generation process and achieve extremely high sample efficiency and
generalizability to unseen configurations. Finally, we demonstrate
state-of-the-art performance across various tasks on the RLbench benchmark
compared with several strong baselines.

ÊëòË¶ÅÔºö‰∫∫È°ûÂèØ‰ª•Âú®Ë¶èÂäÉÊúüÈñìÊÉ≥ÂÉèÁõÆÊ®ôÁãÄÊÖãÔºå‰∏¶Âü∑Ë°åÂãï‰Ωú‰ª•Á¨¶ÂêàÈÄô‰∫õÁõÆÊ®ô„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÊÉ≥ÂÉèÁ≠ñÁï•Ôºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§ö‰ªªÂãôÈóúÈçµÂΩ±Ê†ºÁ≠ñÁï•Á∂≤Ë∑ØÔºåÁî®ÊñºËß£Ê±∫È´òÁ≤æÂ∫¶ÁöÑÂèñÊîæ‰ªªÂãô„ÄÇÊÉ≥ÂÉèÁ≠ñÁï•‰∏¶ÈùûÁõ¥Êé•Â≠∏ÁøíÂãï‰ΩúÔºåËÄåÊòØÁî¢ÁîüÈªûÈõ≤‰ª•ÊÉ≥ÂÉèÊúüÊúõÁöÑÁãÄÊÖãÔºåÁÑ∂Âæå‰ΩøÁî®ÂâõÊÄßÂãï‰Ωú‰º∞Ë®àÂ∞áÂÖ∂ËΩâÊèõÁÇ∫Âãï‰Ωú„ÄÇÈÄôÂ∞áÂãï‰ΩúÊé®Ë´ñËΩâËÆäÁÇ∫‰∏ÄÂÄãÂ±ÄÈÉ®ÁîüÊàê‰ªªÂãô„ÄÇÊàëÂÄëÂà©Áî®ÂèñÊîæÂ∞çÁ®±ÊÄßÂú®ÁîüÊàêÈÅéÁ®ã‰∏≠‰ΩúÁÇ∫‰ªªÂãôÁöÑÂü∫Á§éÔºå‰∏¶ÂØ¶ÁèæÊ•µÈ´òÁöÑÊ®£Êú¨ÊïàÁéáÂíåÂ∞çÊú™Ë¶ãÈÖçÁΩÆÁöÑ‰∏ÄËà¨ÂåñËÉΩÂäõ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú® RLbench Âü∫Ê∫ñ‰∏äÂêÑÁ®Æ‰ªªÂãôÁöÑÊúÄÊñ∞ÊïàËÉΩÔºå‰∏¶ËàáÂπæÂÄãÂº∑Â§ßÁöÑÂü∫Ê∫ñÈÄ≤Ë°åÊØîËºÉ„ÄÇ

##### **Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models**
2406.11736v1 by Fangzhi Xu, Qiushi Sun, Kanzhi Cheng, Jun Liu, Yu Qiao, Zhiyong Wu

One of the primary driving forces contributing to the superior performance of
Large Language Models (LLMs) is the extensive availability of human-annotated
natural language data, which is used for alignment fine-tuning. This inspired
researchers to investigate self-training methods to mitigate the extensive
reliance on human annotations. However, the current success of self-training
has been primarily observed in natural language scenarios, rather than in the
increasingly important neural-symbolic scenarios. To this end, we propose an
environment-guided neural-symbolic self-training framework named ENVISIONS. It
aims to overcome two main challenges: (1) the scarcity of symbolic data, and
(2) the limited proficiency of LLMs in processing symbolic language. Extensive
evaluations conducted on three distinct domains demonstrate the effectiveness
of our approach. Additionally, we have conducted a comprehensive analysis to
uncover the factors contributing to ENVISIONS's success, thereby offering
valuable insights for future research in this area. Code will be available at
\url{https://github.com/xufangzhi/ENVISIONS}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊïàËÉΩÂçìË∂äÔºåÂÖ∂‰∏≠‰∏ÄÈ†Ö‰∏ªË¶ÅÈ©ÖÂãïÂäõÂú®ÊñºÂ§ßÈáèÂèØ‰æõÂèñÂæóÁöÑ‰∫∫Â∑•Ê®ôË®ªËá™ÁÑ∂Ë™ûË®ÄË≥áÊñôÔºåÈÄô‰∫õË≥áÊñôÁî®ÊñºÊØîÂ∞çÂæÆË™ø„ÄÇÈÄôÂïüÁôºÁ†îÁ©∂‰∫∫Âì°Êé¢Á©∂Ëá™Ë®ìÁ∑¥ÊñπÊ≥ïÔºå‰ª•Ê∏õËºïÂ∞ç‰∫∫Â∑•Ê®ôË®ªÁöÑÂª£Ê≥õ‰æùË≥¥„ÄÇÁÑ∂ËÄåÔºåËá™Ë®ìÁ∑¥ÁõÆÂâçÁöÑÊàêÂäü‰∏ªË¶ÅË¶ãÊñºËá™ÁÑ∂Ë™ûË®ÄÂ†¥ÊôØÔºåËÄåÈùûÊó•ÁõäÈáçË¶ÅÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÂ†¥ÊôØ„ÄÇÊúâÈëëÊñºÊ≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ ENVISIONS ÁöÑÁí∞Â¢ÉÂºïÂ∞éÁ•ûÁ∂ìÁ¨¶ËôüËá™Ë®ìÁ∑¥Êû∂Êßã„ÄÇÂÖ∂ÁõÆÊ®ôÊòØÂÖãÊúçÂÖ©È†Ö‰∏ªË¶ÅÊåëÊà∞Ôºö(1) Á¨¶ËôüË≥áÊñôÁöÑÁ®ÄÂ∞ëÊÄßÔºå‰ª•Âèä (2) LLM ËôïÁêÜÁ¨¶ËôüË™ûË®ÄÁöÑÁÜüÁ∑¥Â∫¶ÊúâÈôê„ÄÇÂú®‰∏âÂÄã‰∏çÂêåÈ†òÂüüÈÄ≤Ë°åÁöÑÂª£Ê≥õË©ï‰º∞Ë≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÂàÜÊûêÔºå‰ª•ÊâæÂá∫‰øÉÊàê ENVISIONS ÊàêÂäüÁöÑÂéüÂõ†ÔºåÈÄ≤ËÄåÁÇ∫Ê≠§È†òÂüüÁöÑÊú™‰æÜÁ†îÁ©∂Êèê‰æõÂØ∂Ë≤¥Ë¶ãËß£„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÊñº\url{https://github.com/xufangzhi/ENVISIONS} Êèê‰æõ„ÄÇ

##### **1000 African Voices: Advancing inclusive multi-speaker multi-accent speech synthesis**
2406.11727v1 by Sewade Ogun, Abraham T. Owodunni, Tobi Olatunji, Eniola Alese, Babatunde Oladimeji, Tejumade Afonja, Kayode Olaleye, Naome A. Etori, Tosin Adewumi

Recent advances in speech synthesis have enabled many useful applications
like audio directions in Google Maps, screen readers, and automated content
generation on platforms like TikTok. However, these systems are mostly
dominated by voices sourced from data-rich geographies with personas
representative of their source data. Although 3000 of the world's languages are
domiciled in Africa, African voices and personas are under-represented in these
systems. As speech synthesis becomes increasingly democratized, it is desirable
to increase the representation of African English accents. We present Afro-TTS,
the first pan-African accented English speech synthesis system able to generate
speech in 86 African accents, with 1000 personas representing the rich
phonological diversity across the continent for downstream application in
Education, Public Health, and Automated Content Creation. Speaker interpolation
retains naturalness and accentedness, enabling the creation of new voices.

ÊëòË¶ÅÔºöËøëÊúüÂú®Ë™ûÈü≥ÂêàÊàêÊñπÈù¢ÁöÑÈÄ≤Â±ïÂ∑≤ÂïüÁî®Ë®±Â§öÊúâÁî®ÁöÑÊáâÁî®Á®ãÂºèÔºå
‰æãÂ¶Ç Google Âú∞Âúñ‰∏≠ÁöÑË™ûÈü≥ÊåáÁ§∫„ÄÅËû¢ÂπïÈñ±ËÆÄÂô®Ôºå‰ª•Âèä TikTok Á≠âÂπ≥Âè∞‰∏äÁöÑËá™ÂãïÂåñÂÖßÂÆπÁî¢Áîü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ≥ªÁµ±Â§ßÂ§öÁî±‰æÜËá™Ë≥áÊñôË±êÂØåÂú∞ÂçÄÁöÑËÅ≤Èü≥‰∏ªÂ∞éÔºåÈÄô‰∫õËßíËâ≤‰ª£Ë°®ÂÖ∂ÂéüÂßãË≥áÊñô„ÄÇÂÑòÁÆ°‰∏ñÁïå‰∏äÊúâ 3000 Á®ÆË™ûË®ÄÂú®ÈùûÊ¥≤‰ΩøÁî®Ôºå‰ΩÜÈÄô‰∫õÁ≥ªÁµ±‰∏≠ÈùûÊ¥≤ÁöÑËÅ≤Èü≥ÂíåËßíËâ≤ÂçªÈÆÆÂ∞ëË¢´‰ª£Ë°®„ÄÇÈö®ËëóË™ûÈü≥ÂêàÊàêÊó•ÁõäÊ∞ë‰∏ªÂåñÔºåÂ¢ûÂä†ÈùûÊ¥≤Ëã±Ë™ûÂè£Èü≥ÁöÑ‰ª£Ë°®ÊÄßÊòØÂÄºÂæóÊúüÂæÖÁöÑ„ÄÇÊàëÂÄëÊèêÂá∫ Afro-TTSÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊ≥õÈùûÊ¥≤Âè£Èü≥Ëã±Ë™ûË™ûÈü≥ÂêàÊàêÁ≥ªÁµ±ÔºåËÉΩÂ§†‰ª• 86 Á®ÆÈùûÊ¥≤Âè£Èü≥Áî¢ÁîüË™ûÈü≥Ôºå‰∏¶Êúâ 1000 ÂÄãËßíËâ≤‰ª£Ë°®Êï¥ÂÄãÂ§ßÈô∏Ë±êÂØåÁöÑÈü≥ÈüªÂ§öÊ®£ÊÄßÔºå‰ª•ÊáâÁî®ÊñºÊïôËÇ≤„ÄÅÂÖ¨ÂÖ±Ë°õÁîüÂíåËá™ÂãïÂåñÂÖßÂÆπÂª∫Á´ãÁöÑ‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºè„ÄÇË™™Ë©±ËÄÖÂÖßÊèí‰øùÁïô‰∫ÜËá™ÁÑ∂ÊÄßÂíåÂè£Èü≥ÔºåËÉΩÂ§†ÂâµÈÄ†Âá∫Êñ∞ÁöÑËÅ≤Èü≥„ÄÇ

##### **Zero-Shot Generalization during Instruction Tuning: Insights from Similarity and Granularity**
2406.11721v1 by Bingxiang He, Ning Ding, Cheng Qian, Jia Deng, Ganqu Cui, Lifan Yuan, Huan-ang Gao, Huimin Chen, Zhiyuan Liu, Maosong Sun

Understanding alignment techniques begins with comprehending zero-shot
generalization brought by instruction tuning, but little of the mechanism has
been understood. Existing work has largely been confined to the task level,
without considering that tasks are artificially defined and, to LLMs, merely
consist of tokens and representations. This line of research has been limited
to examining transfer between tasks from a task-pair perspective, with few
studies focusing on understanding zero-shot generalization from the perspective
of the data itself. To bridge this gap, we first demonstrate through multiple
metrics that zero-shot generalization during instruction tuning happens very
early. Next, we investigate the facilitation of zero-shot generalization from
both data similarity and granularity perspectives, confirming that encountering
highly similar and fine-grained training data earlier during instruction
tuning, without the constraints of defined "tasks", enables better
generalization. Finally, we propose a more grounded training data arrangement
method, Test-centric Multi-turn Arrangement, and show its effectiveness in
promoting continual learning and further loss reduction. For the first time, we
show that zero-shot generalization during instruction tuning is a form of
similarity-based generalization between training and test data at the instance
level. We hope our analysis will advance the understanding of zero-shot
generalization during instruction tuning and contribute to the development of
more aligned LLMs. Our code is released at
https://github.com/HBX-hbx/dynamics_of_zero-shot_generalization.

ÊëòË¶ÅÔºöÁêÜËß£Â∞çÈΩäÊäÄË°ìÂßãÊñºÁêÜËß£Êåá‰ª§Ë™øÊï¥Â∏∂‰æÜÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÔºå‰ΩÜÂ∞çÊ©üÂà∂‰∫ÜËß£ÁîöÂ∞ë„ÄÇÁèæÊúâÂ∑•‰ΩúÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂ±ÄÈôêÊñº‰ªªÂãôÂ±§Èù¢ÔºåËÄåÊ≤íÊúâËÄÉÊÖÆÂà∞‰ªªÂãôÊòØ‰∫∫Â∑•ÂÆöÁæ©ÁöÑÔºåËÄå‰∏îÂ∞çÊñº LLM ‰æÜË™™ÔºåÂÉÖÂÉÖÁî±Ê®ôË®òÂíåË°®Á§∫ÁµÑÊàê„ÄÇÈÄôÊ¢ùÁ†îÁ©∂Ë∑ØÁ∑öÂÉÖÈôêÊñºÂæû‰ªªÂãôÂ∞çÁöÑËßíÂ∫¶ÂØ©Ë¶ñ‰ªªÂãô‰πãÈñìÁöÑËΩâÁßªÔºåÂæàÂ∞ëÊúâÁ†îÁ©∂Â∞àÊ≥®ÊñºÂæûÊï∏ÊìöÊú¨Ë∫´ÁöÑËßíÂ∫¶ÁêÜËß£Èõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñ„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÈ¶ñÂÖàÈÄöÈÅéÂ§öÈ†ÖÊåáÊ®ôË≠âÊòéÔºåÂú®Êåá‰ª§Ë™øÊï¥ÊúüÈñìÔºåÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÁôºÁîüÂæóÂæàÊó©„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÂæûÊï∏ÊìöÁõ∏‰ººÊÄßÂíåÁ≤íÂ∫¶ËßíÂ∫¶Á†îÁ©∂Èõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÁöÑ‰øÉÈÄ≤‰ΩúÁî®ÔºåÁ¢∫Ë™çÂú®Êåá‰ª§Ë™øÊï¥ÊúüÈñìÊõ¥Êó©Âú∞ÈÅáÂà∞È´òÂ∫¶Áõ∏‰ºº‰∏îÁ¥∞Á≤íÂ∫¶ÁöÑË®ìÁ∑¥Êï∏ÊìöÔºå‰∏çÂèóÂÆöÁæ©ÁöÑ„Äå‰ªªÂãô„ÄçÁ¥ÑÊùüÔºåÂèØ‰ª•ÂØ¶ÁèæÊõ¥Â•ΩÁöÑÊ≥õÂåñ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊõ¥Á¥ÆÂØ¶ÁöÑË®ìÁ∑¥Êï∏ÊìöÊéíÂàóÊñπÊ≥ïÔºåÂç≥‰ª•Ê∏¨Ë©¶ÁÇ∫‰∏≠ÂøÉÁöÑÂ§öÊ¨°ÊéíÂàóÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂÖ∂Âú®‰øÉÈÄ≤ÊåÅÁ∫åÂ≠∏ÁøíÂíåÈÄ≤‰∏ÄÊ≠•ÊêçÂ§±Ê∏õÂ∞ëÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÈ¶ñÊ¨°Ë°®ÊòéÔºåÂú®Êåá‰ª§Ë™øÊï¥ÊúüÈñìÔºåÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÊòØÂú®ÂØ¶‰æãÂ±§Èù¢‰∏äË®ìÁ∑¥Êï∏ÊìöÂíåÊ∏¨Ë©¶Êï∏Êìö‰πãÈñìÂü∫ÊñºÁõ∏‰ººÊÄßÁöÑÊ≥õÂåñÂΩ¢Âºè„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÂàÜÊûêÂ∞á‰øÉÈÄ≤Â∞çÊåá‰ª§Ë™øÊï¥ÊúüÈñìÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÁöÑÁêÜËß£Ôºå‰∏¶ÊúâÂä©ÊñºÈñãÁôºÊõ¥Â§öÂ∞çÈΩäÁöÑ LLM„ÄÇÊàëÂÄëÁöÑ‰ª£Á¢ºÁôºÂ∏ÉÂú® https://github.com/HBX-hbx/dynamics_of_zero-shot_generalization„ÄÇ

##### **Refusal in Language Models Is Mediated by a Single Direction**
2406.11717v1 by Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Rimsky, Wes Gurnee, Neel Nanda

Conversational large language models are fine-tuned for both
instruction-following and safety, resulting in models that obey benign requests
but refuse harmful ones. While this refusal behavior is widespread across chat
models, its underlying mechanisms remain poorly understood. In this work, we
show that refusal is mediated by a one-dimensional subspace, across 13 popular
open-source chat models up to 72B parameters in size. Specifically, for each
model, we find a single direction such that erasing this direction from the
model's residual stream activations prevents it from refusing harmful
instructions, while adding this direction elicits refusal on even harmless
instructions. Leveraging this insight, we propose a novel white-box jailbreak
method that surgically disables refusal with minimal effect on other
capabilities. Finally, we mechanistically analyze how adversarial suffixes
suppress propagation of the refusal-mediating direction. Our findings
underscore the brittleness of current safety fine-tuning methods. More broadly,
our work showcases how an understanding of model internals can be leveraged to
develop practical methods for controlling model behavior.

ÊëòË¶ÅÔºöÂ∞çË©±ÂºèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁ∂ìÈÅéÂæÆË™øÔºåÂêåÊôÇÂÖ∑ÂÇôÈÅµÂæ™ÊåáÁ§∫ÂíåÂÆâÂÖ®ÊÄßÔºåÂõ†Ê≠§Áî¢ÁîüÁöÑÊ®°ÂûãÊúÉÈÅµÂÆàËâØÊÄßË¶ÅÊ±ÇÔºå‰ΩÜÊãíÁµïÊúâÂÆ≥Ë¶ÅÊ±Ç„ÄÇÈõñÁÑ∂ÈÄôÁ®ÆÊãíÁµïË°åÁÇ∫Âú®ËÅäÂ§©Ê®°Âûã‰∏≠ÂæàÊôÆÈÅçÔºå‰ΩÜÂÖ∂Â∫ïÂ±§Ê©üÂà∂‰ªçÈÆÆÁÇ∫‰∫∫Áü•„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫ÊãíÁµïÊòØÁî±‰∏ÄÁ∂≠Â≠êÁ©∫ÈñìË™øËß£ÁöÑÔºåË∑®Ë∂ä 13 ÂÄãÊµÅË°åÁöÑÈñãÊ∫êËÅäÂ§©Ê®°ÂûãÔºåÂèÉÊï∏Ë¶èÊ®°È´òÈÅî 72B„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂ∞çÊñºÊØèÂÄãÊ®°ÂûãÔºåÊàëÂÄëÊâæÂà∞‰∏ÄÂÄãÂñÆ‰∏ÄÊñπÂêëÔºåÂæûÊ®°ÂûãÁöÑÊÆòÂ∑ÆÊµÅÊøÄÊ¥ª‰∏≠Êì¶Èô§Ê≠§ÊñπÂêëÂèØÈò≤Ê≠¢ÂÆÉÊãíÁµïÊúâÂÆ≥Êåá‰ª§ÔºåËÄåÊ∑ªÂä†Ê≠§ÊñπÂêëÊúÉÂºïÁôºÊãíÁµïÔºåÂç≥‰ΩøÊòØÁÑ°ÂÆ≥Êåá‰ª§„ÄÇÂà©Áî®Ê≠§Ë¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁôΩÁõíË∂äÁçÑÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÈÄöÈÅéÊâãË°ìÁ¶ÅÁî®ÊãíÁµïÔºåÂ∞çÂÖ∂‰ªñÂäüËÉΩÁöÑÂΩ±ÈüøÊúÄÂ∞è„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ©üÊ¢∞Âú∞ÂàÜÊûê‰∫ÜÂ∞çÊäóÊÄßÂæåÁ∂¥Â¶Ç‰ΩïÊäëÂà∂ÊãíÁµïË™øËß£ÊñπÂêëÁöÑÂÇ≥Êí≠„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂº∑Ë™ø‰∫ÜÁï∂ÂâçÂÆâÂÖ®ÂæÆË™øÊñπÊ≥ïÁöÑËÑÜÂº±ÊÄß„ÄÇÊõ¥Âª£Ê≥õÂú∞Ë™™ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂà©Áî®Â∞çÊ®°ÂûãÂÖßÈÉ®ÁöÑÁêÜËß£‰æÜÈñãÁôºÊéßÂà∂Ê®°ÂûãË°åÁÇ∫ÁöÑÂØ¶Áî®ÊñπÊ≥ï„ÄÇ

##### **Measuring memorization in RLHF for code completion**
2406.11715v1 by Aneesh Pappu, Billy Porter, Ilia Shumailov, Jamie Hayes

Reinforcement learning with human feedback (RLHF) has become the dominant
method to align large models to user preferences. Unlike fine-tuning, for which
there are many studies regarding training data memorization, it is not clear
how memorization is affected by or introduced in the RLHF alignment process.
Understanding this relationship is important as real user data may be collected
and used to align large models; if user data is memorized during RLHF and later
regurgitated, this could raise privacy concerns. In this work, we analyze how
training data memorization can surface and propagate through each phase of
RLHF. We focus our study on code completion models, as code completion is one
of the most popular use cases for large language models. We find that RLHF
significantly decreases the chance that data used for reward modeling and
reinforcement learning is memorized, in comparison to aligning via directly
fine-tuning on this data, but that examples already memorized during the
fine-tuning stage of RLHF, will, in the majority of cases, remain memorized
after RLHF.

ÊëòË¶ÅÔºö‰∫∫È°ûÂõûÈ•ãÂ¢ûÂº∑Â≠∏ÁøíÔºàRLHFÔºâÂ∑≤ÊàêÁÇ∫Ë™øÊï¥Â§ßÂûãÊ®°Âûã‰ª•Á¨¶Âêà‰ΩøÁî®ËÄÖÂÅèÂ•ΩÁöÑ‰∏ªË¶ÅÊñπÊ≥ï„ÄÇËàáÂæÆË™ø‰∏çÂêåÔºåÂ∞çÊñºÂæÆË™øÊúâË®±Â§öÈóúÊñºË®ìÁ∑¥Ë≥áÊñôË®òÊÜ∂ÁöÑÁ†îÁ©∂Ôºå‰ΩÜÂ∞ö‰∏çÊ∏ÖÊ•öË®òÊÜ∂ÊòØÂ¶Ç‰ΩïÂèóÂà∞ RLHF Ë™øÊï¥Á®ãÂ∫èÂΩ±ÈüøÊàñÂºïÂÖ•ÁöÑ„ÄÇ‰∫ÜËß£ÈÄôÁ®ÆÈóú‰øÇÂæàÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂèØËÉΩÊúÉÊî∂ÈõÜÁúüÂØ¶‰ΩøÁî®ËÄÖË≥áÊñô‰∏¶Áî®ÊñºË™øÊï¥Â§ßÂûãÊ®°ÂûãÔºõÂ¶ÇÊûú‰ΩøÁî®ËÄÖË≥áÊñôÂú® RLHF ÊúüÈñìË¢´Ë®òÊÜ∂‰∏ã‰æÜ‰∏¶Á®çÂæåÂÜçÈáçË§áÔºåÈÄôÂèØËÉΩÊúÉÂºïÁôºÈö±ÁßÅÂïèÈ°å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂàÜÊûêË®ìÁ∑¥Ë≥áÊñôË®òÊÜ∂Â¶Ç‰ΩïÂú® RLHF ÁöÑÊØèÂÄãÈöéÊÆµÊµÆÁèæ‰∏¶ÂÇ≥Êí≠„ÄÇÊàëÂÄëÂ∞áÁ†îÁ©∂ÈáçÈªûÊîæÂú®Á®ãÂºèÁ¢ºÂÆåÊàêÊ®°Âûã‰∏äÔºåÂõ†ÁÇ∫Á®ãÂºèÁ¢ºÂÆåÊàêÊòØÂ§ßË™ûË®ÄÊ®°ÂûãÊúÄÂèóÊ≠°ËøéÁöÑÁî®‰æã‰πã‰∏Ä„ÄÇÊàëÂÄëÁôºÁèæÔºåËàáÁõ¥Êé•Â∞çÊ≠§Ë≥áÊñôÈÄ≤Ë°åÂæÆË™øÁöÑË™øÊï¥ÊñπÂºèÁõ∏ÊØîÔºåRLHF ÊúÉÈ°ØËëóÈôç‰ΩéÁî®ÊñºÁçéÂãµÂª∫Ê®°ÂíåÂ¢ûÂº∑Â≠∏ÁøíÁöÑË≥áÊñôË¢´Ë®òÊÜ∂ÁöÑÊ©üÁéáÔºå‰ΩÜ RLHF ÂæÆË™øÈöéÊÆµ‰∏≠Â∑≤Ë®òÊÜ∂ÁöÑÁØÑ‰æãÂú®Â§ßÈÉ®ÂàÜÊÉÖÊ≥Å‰∏ãÔºåRLHF ‰πãÂæå‰ªçÊúÉ‰øùÊåÅË®òÊÜ∂„ÄÇ

##### **Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging**
2406.11709v1 by Priyanka Kargupta, Ishika Agarwal, Dilek Hakkani-Tur, Jiawei Han

Socratic questioning is an effective teaching strategy, encouraging critical
thinking and problem-solving. The conversational capabilities of large language
models (LLMs) show great potential for providing scalable, real-time student
guidance. However, current LLMs often give away solutions directly, making them
ineffective instructors. We tackle this issue in the code debugging domain with
TreeInstruct, an Instructor agent guided by a novel state space-based planning
algorithm. TreeInstruct asks probing questions to help students independently
identify and resolve errors. It estimates a student's conceptual and
syntactical knowledge to dynamically construct a question tree based on their
responses and current knowledge state, effectively addressing both independent
and dependent mistakes concurrently in a multi-turn interaction setting. In
addition to using an existing single-bug debugging benchmark, we construct a
more challenging multi-bug dataset of 150 coding problems, incorrect solutions,
and bug fixes -- all carefully constructed and annotated by experts. Extensive
evaluation shows TreeInstruct's state-of-the-art performance on both datasets,
proving it to be a more effective instructor than baselines. Furthermore, a
real-world case study with five students of varying skill levels further
demonstrates TreeInstruct's ability to guide students to debug their code
efficiently with minimal turns and highly Socratic questioning.

ÊëòË¶ÅÔºöËòáÊ†ºÊãâÂ∫ïÂºèÊèêÂïèÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑÊïôÂ≠∏Á≠ñÁï•ÔºåÈºìÂãµÊâπÂà§ÊÄßÊÄùËÄÉÂíåÂïèÈ°åËß£Ê±∫„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂ∞çË©±ËÉΩÂäõÈ°ØÁ§∫Âá∫Êèê‰æõÂèØÊì¥ÂÖÖ„ÄÅÂç≥ÊôÇÁöÑÂ≠∏ÁîüÊåáÂ∞éÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑ LLM Á∂ìÂ∏∏Áõ¥Êé•Êèê‰æõËß£Ê±∫ÊñπÊ°àÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÊàêÁÇ∫ÁÑ°ÊïàÁöÑÊåáÂ∞éËÄÖ„ÄÇÊàëÂÄëÂú®Á®ãÂºèÁ¢ºÂÅµÈåØÈ†òÂüü‰∏≠‰ΩøÁî® TreeInstruct ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåTreeInstruct ÊòØ‰∏ÄÂÄãÊåáÂ∞é‰ª£ÁêÜÔºåÁî±‰∏ÄÂÄãÊñ∞Á©éÁöÑÂü∫ÊñºÁãÄÊÖãÁ©∫ÈñìÁöÑË¶èÂäÉÊºîÁÆóÊ≥ïÊâÄÂºïÂ∞é„ÄÇTreeInstruct ÊúÉÊèêÂá∫Êé¢Ê∏¨ÊÄßÂïèÈ°åÔºå‰ª•Âπ´Âä©Â≠∏ÁîüÁç®Á´ãË≠òÂà•ÂíåËß£Ê±∫ÈåØË™§„ÄÇÂÆÉÊúÉ‰º∞Ë®àÂ≠∏ÁîüÁöÑÊ¶ÇÂøµÊÄßÂíåÂè•Ê≥ïÁü•Ë≠òÔºå‰ª•Ê†πÊìö‰ªñÂÄëÁöÑÂõûÊáâÂíåÁï∂ÂâçÁöÑÁü•Ë≠òÁãÄÊÖãÂãïÊÖãÊßãÂª∫‰∏ÄÂÄãÂïèÈ°åÊ®πÔºåÊúâÊïàÂú∞ÂêåÊôÇÂú®Â§öËº™‰∫íÂãïË®≠ÂÆö‰∏≠Ëß£Ê±∫Áç®Á´ãÂíå‰æùË≥¥ÁöÑÈåØË™§„ÄÇÈô§‰∫Ü‰ΩøÁî®ÁèæÊúâÁöÑÂñÆ‰∏ÄÈåØË™§ÂÅµÈåØÂü∫Ê∫ñ‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÊßãÂª∫‰∫Ü‰∏ÄÂÄãÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÁöÑ 150 ÂÄãÁ∑®Á¢ºÂïèÈ°å„ÄÅ‰∏çÊ≠£Á¢∫ÁöÑËß£Ê±∫ÊñπÊ°àÂíåÈåØË™§‰øÆÊ≠£ÁöÑÂ§öÈåØË™§Ë≥áÊñôÈõÜÔºåÈÄô‰∫õË≥áÊñôÈõÜÈÉΩÊòØÁî±Â∞àÂÆ∂‰ªîÁ¥∞ÊßãÂª∫ÂíåË®ªËß£ÁöÑ„ÄÇÂª£Ê≥õÁöÑË©ï‰º∞È°ØÁ§∫ TreeInstruct Âú®ÂÖ©ÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÊïàËÉΩÈÉΩÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊ∞¥Âπ≥ÔºåË≠âÊòéÂÆÉÊØîÂü∫Ê∫ñÊõ¥ÊúâÊïàÁöÑÊåáÂ∞éËÄÖ„ÄÇÊ≠§Â§ñÔºå‰∏ÄÂÄãÂåÖÂê´‰∫îÂêç‰∏çÂêåÊäÄËÉΩÁ≠âÁ¥öÂ≠∏ÁîüÁöÑÁúüÂØ¶Ê°à‰æãÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Ë≠âÊòé‰∫Ü TreeInstruct ËÉΩÂ§†ÊåáÂ∞éÂ≠∏Áîü‰ª•ÊúÄÂ∞ëÁöÑËº™Ê¨°ÂíåÈ´òÂ∫¶ËòáÊ†ºÊãâÂ∫ïÂºèÁöÑÊèêÂïèÊúâÊïàÂú∞ÂÅµÈåØ‰ªñÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÇ

##### **Prompts as Auto-Optimized Training Hyperparameters: Training Best-in-Class IR Models from Scratch with 10 Gold Labels**
2406.11706v1 by Jasper Xian, Saron Samuel, Faraz Khoubsirat, Ronak Pradeep, Md Arafat Sultan, Radu Florian, Salim Roukos, Avirup Sil, Christopher Potts, Omar Khattab

We develop a method for training small-scale (under 100M parameter) neural
information retrieval models with as few as 10 gold relevance labels. The
method depends on generating synthetic queries for documents using a language
model (LM), and the key step is that we automatically optimize the LM prompt
that is used to generate these queries based on training quality. In
experiments with the BIRCO benchmark, we find that models trained with our
method outperform RankZephyr and are competitive with RankLLama, both of which
are 7B parameter models trained on over 100K labels. These findings point to
the power of automatic prompt optimization for synthetic dataset generation.

ÊëòË¶ÅÔºöÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂèØ‰ª•Áî®Â∞ëËá≥ 10 ÂÄãÈªÉÈáëÁõ∏ÈóúÊ®ôÁ±§‰æÜË®ìÁ∑¥Â∞èË¶èÊ®°ÔºàÂ∞èÊñº 100M ÂèÉÊï∏ÔºâÁ•ûÁ∂ìË≥áË®äÊ™¢Á¥¢Ê®°Âûã„ÄÇ
Ë©≤ÊñπÊ≥ï‰æùË≥¥Êñº‰ΩøÁî®Ë™ûË®ÄÊ®°Âûã (LM) ÁÇ∫Êñá‰ª∂ÁîüÊàêÂêàÊàêÊü•Ë©¢ÔºåÈóúÈçµÊ≠•È©üÊòØÊàëÂÄëÊ†πÊìöË®ìÁ∑¥ÂìÅË≥™Ëá™ÂãïÊúÄ‰Ω≥ÂåñÁî®ÊñºÁîüÊàêÈÄô‰∫õÊü•Ë©¢ÁöÑ LM ÊèêÁ§∫„ÄÇ
Âú®‰ΩøÁî® BIRCO Âü∫Ê∫ñÈÄ≤Ë°åÁöÑÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁôºÁèæ‰ΩøÁî®ÊàëÂÄëÁöÑÊñπÊ≥ïË®ìÁ∑¥ÁöÑÊ®°ÂûãÂÑ™Êñº RankZephyrÔºå‰∏¶‰∏îËàá RankLLama Á´∂Áà≠ÔºåËÄå RankZephyr Âíå RankLLama ÈÉΩÊòØÂü∫ÊñºË∂ÖÈÅé 100K ÂÄãÊ®ôÁ±§Ë®ìÁ∑¥ÁöÑ 7B ÂèÉÊï∏Ê®°Âûã„ÄÇ
ÈÄô‰∫õÁôºÁèæÊåáÂá∫‰∫ÜËá™ÂãïÊèêÁ§∫ÊúÄ‰Ω≥ÂåñÂ∞çÊñºÂêàÊàêË≥áÊñôÈõÜÁîüÊàêÁöÑÂäõÈáè„ÄÇ

##### **Nemotron-4 340B Technical Report**
2406.11704v1 by Nvidia, :, Bo Adler, Niket Agarwal, Ashwath Aithal, Dong H. Anh, Pallab Bhattacharya, Annika Brundyn, Jared Casper, Bryan Catanzaro, Sharon Clay, Jonathan Cohen, Sirshak Das, Ayush Dattagupta, Olivier Delalleau, Leon Derczynski, Yi Dong, Daniel Egert, Ellie Evans, Aleksander Ficek, Denys Fridman, Shaona Ghosh, Boris Ginsburg, Igor Gitman, Tomasz Grzegorzek, Robert Hero, Jining Huang, Vibhu Jawa, Joseph Jennings, Aastha Jhunjhunwala, John Kamalu, Sadaf Khan, Oleksii Kuchaiev, Patrick LeGresley, Hui Li, Jiwei Liu, Zihan Liu, Eileen Long, Ameya Sunil Mahabaleshwarkar, Somshubra Majumdar, James Maki, Miguel Martinez, Maer Rodrigues de Melo, Ivan Moshkov, Deepak Narayanan, Sean Narenthiran, Jesus Navarro, Phong Nguyen, Osvald Nitski, Vahid Noroozi, Guruprasad Nutheti, Christopher Parisien, Jupinder Parmar, Mostofa Patwary, Krzysztof Pawelec, Wei Ping, Shrimai Prabhumoye, Rajarshi Roy, Trisha Saar, Vasanth Rao Naik Sabavat, Sanjeev Satheesh, Jane Polak Scowcroft, Jason Sewall, Pavel Shamis, Gerald Shen, Mohammad Shoeybi, Dave Sizer, Misha Smelyanskiy, Felipe Soares, Makesh Narsimhan Sreedhar, Dan Su, Sandeep Subramanian, Shengyang Sun, Shubham Toshniwal, Hao Wang, Zhilin Wang, Jiaxuan You, Jiaqi Zeng, Jimmy Zhang, Jing Zhang, Vivienne Zhang, Yian Zhang, Chen Zhu

We release the Nemotron-4 340B model family, including Nemotron-4-340B-Base,
Nemotron-4-340B-Instruct, and Nemotron-4-340B-Reward. Our models are open
access under the NVIDIA Open Model License Agreement, a permissive model
license that allows distribution, modification, and use of the models and its
outputs. These models perform competitively to open access models on a wide
range of evaluation benchmarks, and were sized to fit on a single DGX H100 with
8 GPUs when deployed in FP8 precision. We believe that the community can
benefit from these models in various research studies and commercial
applications, especially for generating synthetic data to train smaller
language models. Notably, over 98% of data used in our model alignment process
is synthetically generated, showcasing the effectiveness of these models in
generating synthetic data. To further support open research and facilitate
model development, we are also open-sourcing the synthetic data generation
pipeline used in our model alignment process.

ÊëòË¶ÅÔºöÊàëÂÄëÁôºÂ∏É Nemotron-4 340B Ê®°ÂûãÁ≥ªÂàóÔºåÂåÖÊã¨ Nemotron-4-340B-Base„ÄÅ
Nemotron-4-340B-Instruct Âíå Nemotron-4-340B-Reward„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú® NVIDIA ÈñãÊîæÊ®°ÂûãÊéàÊ¨äÂçîË≠∞‰∏ãÈñãÊîæÂèñÁî®ÔºåÈÄôÊòØ‰∏ÄÂÄãÂØ¨È¨ÜÁöÑÊ®°ÂûãÊéàÊ¨äÔºåÂÖÅË®±ÂàÜÁôº„ÄÅ‰øÆÊîπÂíå‰ΩøÁî®Ê®°ÂûãÂèäÂÖ∂Ëº∏Âá∫„ÄÇÈÄô‰∫õÊ®°ÂûãÂú®Âª£Ê≥õÁöÑË©ï‰º∞Âü∫Ê∫ñ‰∏äÂü∑Ë°åËàáÈñãÊîæÂèñÁî®Ê®°ÂûãÁ´∂Áà≠Ôºå‰∏¶‰∏îÂú®ÈÉ®ÁΩ≤ FP8 Á≤æÂ∫¶ÊôÇÂ§ßÂ∞èÈÅ©ÂêàÂñÆÂÄãÈÖçÂÇô 8 ÂÄã GPU ÁöÑ DGX H100„ÄÇÊàëÂÄëÁõ∏‰ø°Á§æÁæ§ÂèØ‰ª•Âú®ÂêÑÁ®ÆÁ†îÁ©∂ÂíåÂïÜÊ•≠ÊáâÁî®‰∏≠ÂèóÁõäÊñºÈÄô‰∫õÊ®°ÂûãÔºåÁâπÂà•ÊòØÁÇ∫‰∫ÜÁî¢ÁîüÁî®ÊñºË®ìÁ∑¥ËºÉÂ∞èË™ûË®ÄÊ®°ÂûãÁöÑÂêàÊàêË≥áÊñô„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÊ®°ÂûãÊØîÂ∞çÈÅéÁ®ã‰∏≠‰ΩøÁî®ÁöÑË≥áÊñôÊúâË∂ÖÈÅé 98% ÊòØÂêàÊàêÁî¢ÁîüÁöÑÔºåÂ±ïÁ§∫‰∫ÜÈÄô‰∫õÊ®°ÂûãÂú®Áî¢ÁîüÂêàÊàêË≥áÊñôÊñπÈù¢ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊîØÊè¥ÈñãÊîæÁ†îÁ©∂Âíå‰øÉÈÄ≤Ê®°ÂûãÈñãÁôºÔºåÊàëÂÄë‰πüÈñãÊîæÂéüÂßãÁ¢ºÔºåÂú®ÊàëÂÄëÁöÑÊ®°ÂûãÊØîÂ∞çÈÅéÁ®ã‰∏≠‰ΩøÁî®ÂêàÊàêË≥áÊñôÁî¢ÁîüÁÆ°ÈÅì„ÄÇ

##### **Meta Reasoning for Large Language Models**
2406.11698v1 by Peizhong Gao, Ao Xie, Shaoguang Mao, Wenshan Wu, Yan Xia, Haipeng Mi, Furu Wei

We introduce Meta-Reasoning Prompting (MRP), a novel and efficient system
prompting method for large language models (LLMs) inspired by human
meta-reasoning. Traditional in-context learning-based reasoning techniques,
such as Tree-of-Thoughts, show promise but lack consistent state-of-the-art
performance across diverse tasks due to their specialized nature. MRP addresses
this limitation by guiding LLMs to dynamically select and apply different
reasoning methods based on the specific requirements of each task, optimizing
both performance and computational efficiency. With MRP, LLM reasoning operates
in two phases. Initially, the LLM identifies the most appropriate reasoning
method using task input cues and objective descriptions of available methods.
Subsequently, it applies the chosen method to complete the task. This dynamic
strategy mirrors human meta-reasoning, allowing the model to excel in a wide
range of problem domains. We evaluate the effectiveness of MRP through
comprehensive benchmarks. The results demonstrate that MRP achieves or
approaches state-of-the-art performance across diverse tasks. MRP represents a
significant advancement in enabling LLMs to identify cognitive challenges
across problems and leverage benefits across different reasoning approaches,
enhancing their ability to handle diverse and complex problem domains
efficiently. Every LLM deserves a Meta-Reasoning Prompting to unlock its full
potential and ensure adaptability in an ever-evolving landscape of challenges
and applications.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖÉÊé®ÁêÜÊèêÁ§∫ÔºàMRPÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÊúâÊïàÁéáÁöÑÁ≥ªÁµ±ÊèêÁ§∫ÊñπÊ≥ïÔºåÈÅ©Áî®ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºåÂÖ∂ÈùàÊÑü‰æÜËá™‰∫∫È°ûÁöÑÂÖÉÊé®ÁêÜ„ÄÇÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊÉÖÂ¢ÉÂ≠∏ÁøíÁöÑÊé®ÁêÜÊäÄË°ìÔºå‰æãÂ¶ÇÊÄùÊÉ≥Ê®πÔºåÈ°ØÁ§∫Âá∫‰∏ÄÂÆöÁöÑÊΩõÂäõÔºå‰ΩÜÁî±ÊñºÂÖ∂Â∞àÊ•≠ÊÄßË≥™ÔºåÂú®‰∏çÂêåÁöÑ‰ªªÂãô‰∏≠Áº∫‰πè‰∏ÄËá¥ÁöÑÊúÄÊñ∞ÊäÄË°ìÊïàËÉΩ„ÄÇMRP ÈÄèÈÅéÂºïÂ∞é LLM Ê†πÊìöÊØèÂÄã‰ªªÂãôÁöÑÁâπÂÆöÈúÄÊ±ÇÂãïÊÖãÈÅ∏Êìá‰∏¶ÊáâÁî®‰∏çÂêåÁöÑÊé®ÁêÜÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÂêåÊôÇÊúÄ‰Ω≥ÂåñÊïàËÉΩÂíåÈÅãÁÆóÊïàÁéá„ÄÇÈÄèÈÅé MRPÔºåLLM Êé®ÁêÜÂàÜÁÇ∫ÂÖ©ÂÄãÈöéÊÆµ„ÄÇÊúÄÂàùÔºåLLM ‰ΩøÁî®‰ªªÂãôËº∏ÂÖ•ÊèêÁ§∫ÂíåÂèØÁî®ÊñπÊ≥ïÁöÑÂÆ¢ËßÄÊèèËø∞‰æÜË≠òÂà•ÊúÄÂêàÈÅ©ÁöÑÊé®ÁêÜÊñπÊ≥ï„ÄÇÈö®ÂæåÔºåÂÆÉÊáâÁî®ÊâÄÈÅ∏ÊñπÊ≥ï‰æÜÂÆåÊàê‰ªªÂãô„ÄÇÈÄôÁ®ÆÂãïÊÖãÁ≠ñÁï•ÂèçÊò†‰∫Ü‰∫∫È°ûÁöÑÂÖÉÊé®ÁêÜÔºåËÆìÊ®°ÂûãËÉΩÂ§†Âú®Âª£Ê≥õÁöÑÂïèÈ°åÈ†òÂüü‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÊàëÂÄëÈÄèÈÅéÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶‰æÜË©ï‰º∞ MRP ÁöÑÊúâÊïàÊÄß„ÄÇÁµêÊûúË°®ÊòéÔºåMRP Âú®‰∏çÂêåÁöÑ‰ªªÂãô‰∏≠ÈÅîÂà∞ÊàñÊé•ËøëÊúÄÊñ∞ÊäÄË°ìÊïàËÉΩ„ÄÇMRP ‰ª£Ë°®‰∫ÜËÆì LLM ËÉΩÂ§†Ë≠òÂà•‰∏çÂêåÂïèÈ°åÁöÑË™çÁü•ÊåëÊà∞Ôºå‰∏¶Âà©Áî®‰∏çÂêåÊé®ÁêÜÊñπÊ≥ïÁöÑÂÑ™ÈªûÁöÑÈáçÂ§ßÈÄ≤Â±ïÔºåÈÄ≤ËÄåÂ¢ûÂº∑ÂÆÉÂÄëÊúâÊïàËôïÁêÜ‰∏çÂêå‰∏îË§áÈõúÂïèÈ°åÈ†òÂüüÁöÑËÉΩÂäõ„ÄÇÊØèÂÄã LLM ÈÉΩÊáâÂÖ∑ÂÇôÂÖÉÊé®ÁêÜÊèêÁ§∫Ôºå‰ª•ÁôºÊèÆÂÖ∂ÂÖ®ÈÉ®ÊΩõÂäõÔºå‰∏¶Á¢∫‰øùÂú®‰∏çÊñ∑ËÆäÂåñÁöÑÊåëÊà∞ÂíåÊáâÁî®Áí∞Â¢É‰∏≠ÈÅ©Êáâ„ÄÇ

##### **Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs**
2406.11695v1 by Krista Opsahl-Ong, Michael J Ryan, Josh Purtell, David Broman, Christopher Potts, Matei Zaharia, Omar Khattab

Language Model Programs, i.e. sophisticated pipelines of modular language
model (LM) calls, are increasingly advancing NLP tasks, but they require
crafting prompts that are jointly effective for all modules. We study prompt
optimization for LM programs, i.e. how to update these prompts to maximize a
downstream metric without access to module-level labels or gradients. To make
this tractable, we factorize our problem into optimizing the free-form
instructions and few-shot demonstrations of every module and introduce several
strategies to craft task-grounded instructions and navigate credit assignment
across modules. Our strategies include (i) program- and data-aware techniques
for proposing effective instructions, (ii) a stochastic mini-batch evaluation
function for learning a surrogate model of our objective, and (iii) a
meta-optimization procedure in which we refine how LMs construct proposals over
time. Using these insights we develop MIPRO, a novel optimizer that outperforms
baselines on five of six diverse LM programs using a best-in-class open-source
model (Llama-3-8B), by as high as 12.9% accuracy. We will release our new
optimizers and benchmark in DSPy at https://github.com/stanfordnlp/dspy

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÁ®ãÂºèÔºåÂç≥Ê®°ÁµÑÂåñË™ûË®ÄÊ®°Âûã (LM) ÂëºÂè´ÁöÑË§áÈõúÁÆ°Á∑öÔºåÊ≠£Êó•ÁõäÊèêÂçá NLP ‰ªªÂãôÔºå‰ΩÜÂÆÉÂÄëÈúÄË¶ÅË£Ω‰ΩúÂ∞çÊâÄÊúâÊ®°ÁµÑÈÉΩÂÖ±ÂêåÊúâÊïàÁöÑÊèêÁ§∫„ÄÇÊàëÂÄëÁ†îÁ©∂ LM Á®ãÂºèÁöÑÊèêÁ§∫ÊúÄ‰Ω≥ÂåñÔºåÂç≥Â¶Ç‰ΩïÂú®Ê≤íÊúâÊ®°ÁµÑÂ±§Á¥öÊ®ôÁ±§ÊàñÊ¢ØÂ∫¶ÁöÑÁãÄÊ≥Å‰∏ãÊõ¥Êñ∞ÈÄô‰∫õÊèêÁ§∫Ôºå‰ª•ÊúÄÂ§ßÂåñ‰∏ãÊ∏∏ÊåáÊ®ô„ÄÇÁÇ∫‰∫Ü‰ΩøÈÄôÂÄãÂïèÈ°åÂèØËôïÁêÜÔºåÊàëÂÄëÂ∞áÂïèÈ°åÂàÜËß£ÁÇ∫ÊúÄ‰Ω≥ÂåñÊØè‰∏ÄÂÄãÊ®°ÁµÑÁöÑËá™Áî±ÂΩ¢ÂºèË™™ÊòéÂíåÂ∞ëÈáèÁ§∫ÁØÑÔºå‰∏¶ÂºïÂÖ•Â§öÁ®ÆÁ≠ñÁï•‰æÜË£Ω‰Ωú‰ª•‰ªªÂãôÁÇ∫Âü∫Á§éÁöÑË™™ÊòéÔºå‰∏¶Âú®Ê®°ÁµÑÈñìÂ∞éËà™‰ø°Áî®ÂàÜÈÖç„ÄÇÊàëÂÄëÁöÑÁ≠ñÁï•ÂåÖÊã¨Ôºö(i) ÊèêÂá∫ÊúâÊïàË™™ÊòéÁöÑÁ®ãÂºèÂíåË≥áÊñôÊÑüÁü•ÊäÄË°ìÔºå(ii) Â≠∏ÁøíÁõÆÊ®ôÊõø‰ª£Ê®°ÂûãÁöÑÈö®Ê©üÂ∞èÊâπÊ¨°Ë©ï‰º∞ÂáΩÊï∏Ôºå‰ª•Âèä (iii) ÊàëÂÄëÂú®ÂÖ∂‰∏≠Á≤æÈÄ≤ LM Èö®ËëóÊôÇÈñìÊé®ÁßªÂª∫ÊßãÊèêÊ°àÊñπÂºèÁöÑÂÖÉÊúÄ‰Ω≥ÂåñÁ®ãÂ∫è„ÄÇÂà©Áî®ÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÈñãÁôº‰∫Ü MIPROÔºå‰∏ÄÁ®ÆÊñ∞ÁöÑÊúÄ‰Ω≥ÂåñÂô®ÔºåÂÆÉÂú®‰ΩøÁî®ÊúÄ‰Ω≥ÈñãÊîæÂéüÂßãÁ¢ºÊ®°Âûã (Llama-3-8B) ÁöÑÂÖ≠ÂÄã‰∏çÂêåÁöÑ LM Á®ãÂºè‰∏≠ÁöÑ‰∫îÂÄãÁ®ãÂºè‰∏≠ÂÑ™ÊñºÂü∫Ê∫ñÔºåÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 12.9%„ÄÇÊàëÂÄëÂ∞áÂú® https://github.com/stanfordnlp/dspy ‰∏äÁôºÂ∏ÉÊàëÂÄëÁöÑÊñ∞ÁöÑÊúÄ‰Ω≥ÂåñÂô®Âíå DSPy Âü∫Ê∫ñ

##### **Tokenization Falling Short: The Curse of Tokenization**
2406.11687v1 by Yekun Chai, Yewei Fang, Qiwei Peng, Xuhong Li

Language models typically tokenize raw text into sequences of subword
identifiers from a predefined vocabulary, a process inherently sensitive to
typographical errors, length variations, and largely oblivious to the internal
structure of tokens-issues we term the curse of tokenization. In this study, we
delve into these drawbacks and demonstrate that large language models (LLMs)
remain susceptible to these problems. This study systematically investigates
these challenges and their impact on LLMs through three critical research
questions: (1) complex problem solving, (2) token structure probing, and (3)
resilience to typographical variation. Our findings reveal that scaling model
parameters can mitigate the issue of tokenization; however, LLMs still suffer
from biases induced by typos and other text format variations. Our experiments
show that subword regularization such as BPE-dropout can mitigate this issue.
We will release our code and data to facilitate further research.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÈÄöÂ∏∏Â∞áÂéüÂßãÊñáÂ≠óÂàÜË©ûÊàêÈ†êÂÖàÂÆöÁæ©Ë©ûÂΩôË°®‰∏≠Â≠êÂ≠óË©ûÁöÑÂ∫èÂàóÔºåÈÄôÂÄãÈÅéÁ®ãÂ∞çÂç∞Âà∑ÈåØË™§„ÄÅÈï∑Â∫¶ËÆäÂåñÂæàÊïèÊÑüÔºåËÄå‰∏îÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂøΩÁï•‰∫ÜË©ûÂΩôÁöÑÂÖßÈÉ®ÁµêÊßãÔºåÊàëÂÄëÁ®±ÈÄôÂÄãÂïèÈ°åÁÇ∫ÂàÜË©ûÁöÑË©õÂíí„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®é‰∫ÜÈÄô‰∫õÁº∫ÈªûÔºå‰∏¶Ë≠âÊòéÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ªçÁÑ∂ÂÆπÊòìÂèóÂà∞ÈÄô‰∫õÂïèÈ°åÁöÑÂΩ±Èüø„ÄÇÊú¨Á†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Êé¢Ë®é‰∫ÜÈÄô‰∫õÊåëÊà∞ÂèäÂÖ∂Â∞ç LLM ÁöÑÂΩ±ÈüøÔºåÈÄèÈÅé‰∏âÂÄãÈáçË¶ÅÁöÑÁ†îÁ©∂ÂïèÈ°åÔºö(1) Ë§áÈõúÂïèÈ°åËß£Ê±∫Ôºå(2) Ë©ûÂΩôÁµêÊßãÊé¢Ê∏¨Ôºå‰ª•Âèä (3) Â∞çÂç∞Âà∑ËÆäÁï∞ÁöÑÈüåÊÄß„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåË™øÊï¥Ê®°ÂûãÂèÉÊï∏ÂèØ‰ª•Ê∏õËºïÂàÜË©ûÁöÑÂïèÈ°åÔºõÁÑ∂ËÄåÔºåLLM ‰ªçÁÑ∂ÊúÉÂèóÂà∞Âç∞Âà∑ÈåØË™§ÂíåÂÖ∂‰ªñÊñáÂ≠óÊ†ºÂºèËÆäÁï∞ÊâÄÁî¢ÁîüÁöÑÂÅèÂ∑ÆÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÂ≠êÂ≠óË©ûÊ≠£Ë¶èÂåñÔºà‰æãÂ¶Ç BPE-dropoutÔºâÂèØ‰ª•Ê∏õËºïÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÂ∞áÈáãÂá∫ÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÔºå‰ª•Âà©ÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

##### **HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing**
2406.11683v1 by Jing Chen, Xinyu Zhu, Cheng Yang, Chufan Shi, Yadong Xi, Yuxiang Zhang, Junjie Wang, Jiashu Pu, Rongsheng Zhang, Yujiu Yang, Tian Feng

Generative AI has demonstrated unprecedented creativity in the field of
computer vision, yet such phenomena have not been observed in natural language
processing. In particular, large language models (LLMs) can hardly produce
written works at the level of human experts due to the extremely high
complexity of literature writing. In this paper, we present HoLLMwood, an
automated framework for unleashing the creativity of LLMs and exploring their
potential in screenwriting, which is a highly demanding task. Mimicking the
human creative process, we assign LLMs to different roles involved in the
real-world scenario. In addition to the common practice of treating LLMs as
${Writer}$, we also apply LLMs as ${Editor}$, who is responsible for providing
feedback and revision advice to ${Writer}$. Besides, to enrich the characters
and deepen the plots, we introduce a role-playing mechanism and adopt LLMs as
${Actors}$ that can communicate and interact with each other. Evaluations on
automatically generated screenplays show that HoLLMwood substantially
outperforms strong baselines in terms of coherence, relevance, interestingness
and overall quality.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI Â∑≤Âú®ÈõªËÖ¶Ë¶ñË¶∫È†òÂüüÂ±ïÁèæÂá∫ÂâçÊâÄÊú™ÊúâÁöÑÂâµÈÄ†ÂäõÔºå‰ΩÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠Â∞öÊú™ËßÄÂØüÂà∞ÈÄôÁ®ÆÁèæË±°„ÄÇÁâπÂà•ÊòØÔºåÁî±ÊñºÊñáÂ≠∏ÂØ´‰ΩúÊ•µÈ´òÁöÑË§áÈõúÊÄßÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Èõ£‰ª•Áî¢Áîü‰∫∫È°ûÂ∞àÂÆ∂Á≠âÁ¥öÁöÑÊõ∏Èù¢‰ΩúÂìÅ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ HoLLMwoodÔºå‰∏ÄÂÄãËá™ÂãïÂåñÊ°ÜÊû∂ÔºåÁî®ÊñºÈáãÊîæ LLM ÁöÑÂâµÈÄ†Âäõ‰∏¶Êé¢Á¥¢ÂÆÉÂÄëÂú®Á∑®Âäá‰∏≠ÁöÑÊΩõÂäõÔºåÈÄôÊòØ‰∏ÄÈ†ÖË¶ÅÊ±ÇÂæàÈ´òÁöÑ‰ªªÂãô„ÄÇÊ®°‰ªø‰∫∫È°ûÁöÑÂâµÈÄ†ÈÅéÁ®ãÔºåÊàëÂÄëÂ∞á LLM ÂàÜÈÖçÂà∞ÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠Ê∂âÂèäÁöÑ‰∏çÂêåËßíËâ≤„ÄÇÈô§‰∫ÜÂ∞á LLM Ë¶ñÁÇ∫ ${Writer}$ ÁöÑÂ∏∏Ë¶ãÂÅöÊ≥ïÂ§ñÔºåÊàëÂÄëÈÇÑÂ∞á LLM Áî®‰Ωú ${Editor}ÔºåË≤†Ë≤¨Âêë ${Writer}$ Êèê‰æõÂõûÈ•ãÂíå‰øÆÊîπÂª∫Ë≠∞„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜË±êÂØåËßíËâ≤‰∏¶Âä†Ê∑±ÂäáÊÉÖÔºåÊàëÂÄëÂºïÂÖ•ËßíËâ≤ÊâÆÊºîÊ©üÂà∂Ôºå‰∏¶Êé°Áî® LLM ‰ΩúÁÇ∫ ${Actors}ÔºåÂÆÉÂÄëÂèØ‰ª•Áõ∏‰∫íÊ∫ùÈÄöÂíå‰∫íÂãï„ÄÇÂ∞çËá™ÂãïÁîüÊàêÁöÑÂäáÊú¨ÈÄ≤Ë°åË©ï‰º∞Ë°®ÊòéÔºåHoLLMwood Âú®ÈÄ£Ë≤´ÊÄß„ÄÅÁõ∏ÈóúÊÄß„ÄÅË∂£Âë≥ÊÄßÂíåÊï¥È´îÂìÅË≥™ÊñπÈù¢ÊòéÈ°ØÂÑ™ÊñºÂº∑Â§ßÁöÑÂü∫Ê∫ñ„ÄÇ

##### **Knowledge-to-Jailbreak: One Knowledge Point Worth One Attack**
2406.11682v1 by Shangqing Tu, Zhuoran Pan, Wenxuan Wang, Zhexin Zhang, Yuliang Sun, Jifan Yu, Hongning Wang, Lei Hou, Juanzi Li

Large language models (LLMs) have been increasingly applied to various
domains, which triggers increasing concerns about LLMs' safety on specialized
domains, e.g. medicine. However, testing the domain-specific safety of LLMs is
challenging due to the lack of domain knowledge-driven attacks in existing
benchmarks. To bridge this gap, we propose a new task, knowledge-to-jailbreak,
which aims to generate jailbreaks from domain knowledge to evaluate the safety
of LLMs when applied to those domains. We collect a large-scale dataset with
12,974 knowledge-jailbreak pairs and fine-tune a large language model as
jailbreak-generator, to produce domain knowledge-specific jailbreaks.
Experiments on 13 domains and 8 target LLMs demonstrate the effectiveness of
jailbreak-generator in generating jailbreaks that are both relevant to the
given knowledge and harmful to the target LLMs. We also apply our method to an
out-of-domain knowledge base, showing that jailbreak-generator can generate
jailbreaks that are comparable in harmfulness to those crafted by human
experts. Data and code: https://github.com/THU-KEG/Knowledge-to-Jailbreak/.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂ∑≤Ë∂äÊù•Ë∂äÂ§öÂú∞Â∫îÁî®‰∫éÂêÑÁßçÈ¢ÜÂüüÔºåËøôÂºïÂèë‰∫Ü‰∫∫‰ª¨ÂØπ LLM Âú®‰∏ì‰∏öÈ¢ÜÂüüÔºà‰æãÂ¶ÇÂåªÂ≠¶Ôºâ‰∏äÁöÑÂÆâÂÖ®ÊÄßÊó•ÁõäÊãÖÂøß„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÁé∞ÊúâÂü∫ÂáÜÁº∫‰πèÈ¢ÜÂüüÁü•ËØÜÈ©±Âä®ÁöÑÊîªÂáªÔºåÂõ†Ê≠§ÊµãËØï LLM ÁöÑÁâπÂÆöÈ¢ÜÂüüÂÆâÂÖ®ÊÄßÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇ‰∏∫‰∫ÜÂº•ÂêàËøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞‰ªªÂä°ÔºåÂç≥Áü•ËØÜÂà∞Ë∂äÁã±ÔºåÂÖ∂ÁõÆÁöÑÊòØ‰ªéÈ¢ÜÂüüÁü•ËØÜ‰∏≠ÁîüÊàêË∂äÁã±Ôºå‰ª•ËØÑ‰º∞ LLM Â∫îÁî®‰∫éËøô‰∫õÈ¢ÜÂüüÊó∂ÁöÑÂÆâÂÖ®ÊÄß„ÄÇÊàë‰ª¨Êî∂ÈõÜ‰∫Ü‰∏Ä‰∏™ÂåÖÂê´ 12,974 ‰∏™Áü•ËØÜË∂äÁã±ÂØπÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÂπ∂ÂæÆË∞É‰∫Ü‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰Ωú‰∏∫Ë∂äÁã±ÁîüÊàêÂô®Ôºå‰ª•‰∫ßÁîüÁâπÂÆö‰∫éÈ¢ÜÂüüÁü•ËØÜÁöÑË∂äÁã±„ÄÇÂú® 13 ‰∏™È¢ÜÂüüÂíå 8 ‰∏™ÁõÆÊ†á LLM ‰∏äÁöÑÂÆûÈ™åË°®Êòé‰∫ÜË∂äÁã±ÁîüÊàêÂô®Âú®ÁîüÊàê‰∏éÁªôÂÆöÁü•ËØÜÁõ∏ÂÖ≥‰∏îÂØπÁõÆÊ†á LLM ÊúâÂÆ≥ÁöÑË∂äÁã±ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàë‰ª¨ËøòÂ∞ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÂ∫îÁî®‰∫éÂüüÂ§ñÁü•ËØÜÂ∫ìÔºåË°®ÊòéË∂äÁã±ÁîüÊàêÂô®ÂèØ‰ª•ÁîüÊàê‰∏é‰∫∫Á±ª‰∏ìÂÆ∂Âà∂‰ΩúÁöÑË∂äÁã±Âú®Âç±ÂÆ≥ÊÄßÊñπÈù¢Áõ∏ÂΩìÁöÑË∂äÁã±„ÄÇÊï∞ÊçÆÂíå‰ª£Á†ÅÔºöhttps://github.com/THU-KEG/Knowledge-to-Jailbreak/„ÄÇ

##### **R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models**
2406.11681v1 by Shangqing Tu, Yuanchun Wang, Jifan Yu, Yuyang Xie, Yaran Shi, Xiaozhi Wang, Jing Zhang, Lei Hou, Juanzi Li

Large language models have achieved remarkable success on general NLP tasks,
but they may fall short for domain-specific problems. Recently, various
Retrieval-Augmented Large Language Models (RALLMs) are proposed to address this
shortcoming. However, existing evaluation tools only provide a few baselines
and evaluate them on various domains without mining the depth of domain
knowledge. In this paper, we address the challenges of evaluating RALLMs by
introducing the R-Eval toolkit, a Python toolkit designed to streamline the
evaluation of different RAG workflows in conjunction with LLMs. Our toolkit,
which supports popular built-in RAG workflows and allows for the incorporation
of customized testing data on the specific domain, is designed to be
user-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs
across three task levels and two representative domains, revealing significant
variations in the effectiveness of RALLMs across different tasks and domains.
Our analysis emphasizes the importance of considering both task and domain
requirements when choosing a RAG workflow and LLM combination. We are committed
to continuously maintaining our platform at https://github.com/THU-KEG/R-Eval
to facilitate both the industry and the researchers.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÈÄöÁî®ÁöÑ NLP ‰ªªÂãô‰∏äÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºå
‰ΩÜÂÆÉÂÄëÂú®ÁâπÂÆöÈ†òÂüüÁöÑÂïèÈ°å‰∏äÂèØËÉΩË°®Áèæ‰∏ç‰Ω≥„ÄÇÊúÄËøëÔºåÊèêÂá∫‰∫ÜÂêÑÁ®Æ
Ê™¢Á¥¢Â¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (RALLM) ‰æÜËß£Ê±∫ÈÄôÂÄã
Áº∫Èªû„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑË©ï‰º∞Â∑•ÂÖ∑Âè™Êèê‰æõ‰∫Ü‰∏Ä‰∫õÂü∫Ê∫ñÔºå
‰∏¶Âú®ÂêÑÁ®ÆÈ†òÂüüÂ∞çÂÆÉÂÄëÈÄ≤Ë°åË©ï‰º∞ÔºåËÄåÊ≤íÊúâÊåñÊéòÈ†òÂüü
Áü•Ë≠òÁöÑÊ∑±Â∫¶„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëËß£Ê±∫‰∫ÜË©ï‰º∞ RALLM ÁöÑÊåëÊà∞Ôºå
ÂºïÂÖ•‰∫Ü R-Eval Â∑•ÂÖ∑ÂåÖÔºåÈÄôÊòØ‰∏ÄÂÄã Python Â∑•ÂÖ∑ÂåÖÔºåÊó®Âú®Á∞°Âåñ
Ë©ï‰º∞‰∏çÂêåÁöÑ RAG Â∑•‰ΩúÊµÅÁ®ã‰ª•Âèä LLM„ÄÇÊàëÂÄëÁöÑÂ∑•ÂÖ∑ÂåÖÔºå
ÂÆÉÊîØÊåÅÊµÅË°åÁöÑÂÖßÂª∫ RAG Â∑•‰ΩúÊµÅÁ®ãÔºå‰∏¶ÂÖÅË®±Âú®ÁâπÂÆöÈ†òÂüüÊï¥Âêà
Ëá™Ë®ÇÁöÑÊ∏¨Ë©¶Êï∏ÊìöÔºåÊó®Âú®ÊàêÁÇ∫‰ΩøÁî®ËÄÖÂèãÂñÑ„ÄÅÊ®°ÁµÑÂåñÂíåÂèØÊì¥ÂÖÖÁöÑ„ÄÇÊàëÂÄëÂ∞ç 21 ÂÄã RALLM
ÈÄ≤Ë°å‰∫ÜË©ï‰º∞ÔºåÊ∂µËìã‰∏âÂÄã‰ªªÂãôÂ±§Á¥öÂíåÂÖ©ÂÄã‰ª£Ë°®ÊÄßÈ†òÂüüÔºåÊè≠Á§∫‰∫Ü RALLM
Âú®‰∏çÂêå‰ªªÂãôÂíåÈ†òÂüü‰∏≠ÁöÑÊúâÊïàÊÄßÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇ
ÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™ø‰∫ÜÂú®ÈÅ∏Êìá RAG Â∑•‰ΩúÊµÅÁ®ãÂíå LLM ÁµÑÂêàÊôÇËÄÉÊÖÆ‰ªªÂãôÂíåÈ†òÂüü
ÈúÄÊ±ÇÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëËá¥ÂäõÊñºÊåÅÁ∫åÁ∂≠Ë≠∑ÊàëÂÄëÁöÑÂπ≥Âè∞ÔºåÁ∂≤ÂùÄÁÇ∫ https://github.com/THU-KEG/R-EvalÔºå
‰ª•‰øÉÈÄ≤Áî¢Ê•≠ÂíåÁ†îÁ©∂‰∫∫Âì°„ÄÇ

##### **TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy**
2406.11678v1 by Yiqun Chen, Qi Liu, Yi Zhang, Weiwei Sun, Daiting Shi, Jiaxin Mao, Dawei Yin

Large Language Models (LLMs) are increasingly employed in zero-shot documents
ranking, yielding commendable results. However, several significant challenges
still persist in LLMs for ranking: (1) LLMs are constrained by limited input
length, precluding them from processing a large number of documents
simultaneously; (2) The output document sequence is influenced by the input
order of documents, resulting in inconsistent ranking outcomes; (3) Achieving a
balance between cost and ranking performance is quite challenging. To tackle
these issues, we introduce a novel documents ranking method called TourRank,
which is inspired by the tournament mechanism. This approach alleviates the
impact of LLM's limited input length through intelligent grouping, while the
tournament-like points system ensures robust ranking, mitigating the influence
of the document input sequence. We test TourRank with different LLMs on the
TREC DL datasets and the BEIR benchmark. Experimental results show that
TourRank achieves state-of-the-art performance at a reasonable cost.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)  zunehmend in Zero-Shot-Dokumenten eingesetzt
Ranking, was zu lobenswerten Ergebnissen f√ºhrt. Allerdings bestehen bei LLMs f√ºr das Ranking immer noch mehrere erhebliche Herausforderungen: (1) LLMs sind durch eine begrenzte Eingabel√§nge eingeschr√§nkt, was sie daran hindert, eine gro√üe Anzahl von Dokumenten gleichzeitig zu verarbeiten; (2) Die Ausgabe-Dokumentsequenz wird durch die Eingabereihenfolge der Dokumente beeinflusst, was zu inkonsistenten Ranking-Ergebnissen f√ºhrt; (3) Es ist eine ziemliche Herausforderung, ein Gleichgewicht zwischen Kosten und Ranking-Leistung zu erreichen. Um diese Probleme anzugehen, stellen wir eine neuartige Dokumenten-Ranking-Methode namens TourRank vor, die vom Turniermechanismus inspiriert ist. Dieser Ansatz mildert die Auswirkungen der begrenzten Eingabel√§nge von LLM durch intelligente Gruppierung, w√§hrend das turnier√§hnliche Punktesystem ein robustes Ranking gew√§hrleistet und den Einfluss der Dokumenteneingabesequenz abschw√§cht. Wir testen TourRank mit verschiedenen LLMs auf den TREC DL-Datens√§tzen und dem BEIR-Benchmark. Experimentelle Ergebnisse zeigen, dass TourRank zu einem vern√ºnftigen Preis eine hochmoderne Leistung erzielt.

##### **BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models**
2406.11675v1 by Yibin Wang, Haizhou Shi, Ligong Han, Dimitris Metaxas, Hao Wang

Large Language Models (LLMs) often suffer from overconfidence during
inference, particularly when adapted to downstream domain-specific tasks with
limited data. Previous work addresses this issue by employing approximate
Bayesian estimation after the LLMs are trained, enabling them to quantify
uncertainty. However, such post-training approaches' performance is severely
limited by the parameters learned during training. In this paper, we go beyond
post-training Bayesianization and propose Bayesian Low-Rank Adaptation by
Backpropagation (BLoB), an algorithm that continuously and jointly adjusts both
the mean and covariance of LLM parameters throughout the whole fine-tuning
process. Our empirical results verify the effectiveness of BLoB in terms of
generalization and uncertainty estimation, when evaluated on both
in-distribution and out-of-distribution data.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êé®Ë´ñÊúüÈñìÁ∂ìÂ∏∏ÈÅéÊñºËá™‰ø°ÔºåÁâπÂà•ÊòØÂú®ÈÅ©ÊáâÂÖ∑ÊúâÊúâÈôêÊï∏ÊìöÁöÑ‰∏ãÊ∏∏ÁâπÂÆöÈ†òÂüü‰ªªÂãôÊôÇ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÈÄèÈÅéÂú® LLM Ë®ìÁ∑¥ÂæåÊé°Áî®Ëøë‰ººË≤ùÊ∞è‰º∞Ë®à‰æÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºå‰ΩøÂÖ∂ËÉΩÂ§†ÈáèÂåñ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûË®ìÁ∑¥ÂæåÊñπÊ≥ïÁöÑÊïàËÉΩÂèóÂà∞Ë®ìÁ∑¥ÊúüÈñìÊâÄÂ≠∏ÁøíÂèÉÊï∏ÁöÑÂö¥ÈáçÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË∂ÖË∂ä‰∫ÜË®ìÁ∑¥ÂæåÁöÑË≤ùÊ∞èÂåñÔºå‰∏¶ÊèêÂá∫ÈÄèÈÅéÂèçÂêëÂÇ≥Êí≠ÁöÑË≤ùÊ∞è‰ΩéÈöéÈÅ©Êáâ (BLoB)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊºîÁÆóÊ≥ïÔºåÂèØÂú®Êï¥ÂÄãÂæÆË™øÈÅéÁ®ã‰∏≠ÊåÅÁ∫å‰∏îÂêåÊôÇË™øÊï¥ LLM ÂèÉÊï∏ÁöÑÂπ≥ÂùáÂÄºÂíåÂÖ±ËÆäÁï∞Êï∏„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁµêÊûúÈ©óË≠â‰∫Ü BLoB Âú®Ê≥õÂåñÂíå‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊñπÈù¢ÁöÑÊïàËÉΩÔºåÂú®ÂàÜ‰ΩàÂÖßÂíåÂàÜ‰ΩàÂ§ñÊï∏Êìö‰∏äÈÄ≤Ë°åË©ï‰º∞ÊôÇÁöÜËÉΩÈ©óË≠â„ÄÇ

##### **Endor: Hardware-Friendly Sparse Format for Offloaded LLM Inference**
2406.11674v1 by Donghyeon Joo, Ramyad Hadidi, Soheil Feizi, Bahar Asgari

The increasing size of large language models (LLMs) challenges their usage on
resource-constrained platforms. For example, memory on modern GPUs is
insufficient to hold LLMs that are hundreds of Gigabytes in size. Offloading is
a popular method to escape this constraint by storing weights of an LLM model
to host CPU memory and SSD, then loading each weight to GPU before every use.
In our case study of offloaded inference, we found that due to the low
bandwidth between storage devices and GPU, the latency of transferring large
model weights from its offloaded location to GPU memory becomes the critical
bottleneck with actual compute taking nearly 0% of runtime. To effectively
reduce the weight transfer latency, we propose a novel sparse format that
compresses the unstructured sparse pattern of pruned LLM weights to non-zero
values with high compression ratio and low decompression overhead. Endor
achieves this by expressing the positions of non-zero elements with a bitmap.
Compared to offloaded inference using the popular Huggingface Accelerate,
applying Endor accelerates OPT-66B by 1.70x and Llama2-70B by 1.78x. When
direct weight transfer from SSD to GPU is leveraged, Endor achieves 2.25x
speedup on OPT-66B and 2.37x speedup on Llama2-70B.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÂ∞∫ÂØ∏Ë∂äÊù•Ë∂äÂ§ßÔºåÂØπËµÑÊ∫êÂèóÈôêÂπ≥Âè∞‰∏äÁöÑ‰ΩøÁî®ÊûÑÊàêÊåëÊàò„ÄÇ‰æãÂ¶ÇÔºåÁé∞‰ª£ GPU ‰∏äÁöÑÂÜÖÂ≠ò‰∏çË∂≥‰ª•ÂÆπÁ∫≥Êï∞Áôæ GB Â§ßÂ∞èÁöÑ LLM„ÄÇÂç∏ËΩΩÊòØ‰∏ÄÁßçÊµÅË°åÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•ÈÄöËøáÂ∞Ü LLM Ê®°ÂûãÁöÑÊùÉÈáçÂ≠òÂÇ®Âà∞‰∏ªÊú∫ CPU ÂÜÖÂ≠òÂíå SSD ‰∏≠Êù•ÊëÜËÑ±Ê≠§ÈôêÂà∂ÔºåÁÑ∂ÂêéÂú®ÊØèÊ¨°‰ΩøÁî®‰πãÂâçÂ∞ÜÊØè‰∏™ÊùÉÈáçÂä†ËΩΩÂà∞ GPU ‰∏≠„ÄÇÂú®Êàë‰ª¨ÁöÑÂç∏ËΩΩÊé®ÁêÜÊ°à‰æãÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÂèëÁé∞Áî±‰∫éÂ≠òÂÇ®ËÆæÂ§áÂíå GPU ‰πãÈó¥ÁöÑÂ∏¶ÂÆΩËæÉ‰ΩéÔºåÂ∞ÜÂ§ßÂûãÊ®°ÂûãÊùÉÈáç‰ªéÂÖ∂Âç∏ËΩΩ‰ΩçÁΩÆ‰º†ËæìÂà∞ GPU ÂÜÖÂ≠òÁöÑÂª∂ËøüÊàê‰∏∫ÂÖ≥ÈîÆÁì∂È¢àÔºåÂÆûÈôÖËÆ°ÁÆó‰ªÖÂç†ËøêË°åÊó∂ÁöÑ 0%„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂáèÂ∞ëÊùÉÈáç‰º†ËæìÂª∂ËøüÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁ®ÄÁñèÊ†ºÂºèÔºåËØ•Ê†ºÂºèÂ∞Ü‰øÆÂâ™ÁöÑ LLM ÊùÉÈáçÁöÑÈùûÁªìÊûÑÂåñÁ®ÄÁñèÊ®°ÂºèÂéãÁº©‰∏∫ÈùûÈõ∂ÂÄºÔºåÂÖ∑ÊúâÈ´òÂéãÁº©ÊØîÂíå‰ΩéËß£ÂéãÁº©ÂºÄÈîÄ„ÄÇEndor ÈÄöËøá‰ΩøÁî®‰ΩçÂõæË°®Á§∫ÈùûÈõ∂ÂÖÉÁ¥†ÁöÑ‰ΩçÁΩÆÊù•ÂÆûÁé∞Ëøô‰∏ÄÁÇπ„ÄÇ‰∏é‰ΩøÁî®ÊµÅË°åÁöÑ Huggingface Accelerate ËøõË°åÂç∏ËΩΩÊé®ÁêÜÁõ∏ÊØîÔºåÂ∫îÁî® Endor ÂèØÂ∞Ü OPT-66B Âä†ÈÄü 1.70 ÂÄçÔºåÂ∞Ü Llama2-70B Âä†ÈÄü 1.78 ÂÄç„ÄÇÂΩìÂà©Áî®‰ªé SSD Âà∞ GPU ÁöÑÁõ¥Êé•ÊùÉÈáç‰º†ËæìÊó∂ÔºåEndor Âú® OPT-66B ‰∏äÂÆûÁé∞‰∫Ü 2.25 ÂÄçÁöÑÂä†ÈÄüÔºåÂú® Llama2-70B ‰∏äÂÆûÁé∞‰∫Ü 2.37 ÂÄçÁöÑÂä†ÈÄü„ÄÇ

##### **Benchmarking of LLM Detection: Comparing Two Competing Approaches**
2406.11670v1 by Thorsten Pr√∂hl, Erik Putzier, R√ºdiger Zarnekow

This article gives an overview of the field of LLM text recognition.
Different approaches and implemented detectors for the recognition of
LLM-generated text are presented. In addition to discussing the
implementations, the article focuses on benchmarking the detectors. Although
there are numerous software products for the recognition of LLM-generated text,
with a focus on ChatGPT-like LLMs, the quality of the recognition (recognition
rate) is not clear. Furthermore, while it can be seen that scientific
contributions presenting their novel approaches strive for some kind of
comparison with other approaches, the construction and independence of the
evaluation dataset is often not comprehensible. As a result, discrepancies in
the performance evaluation of LLM detectors are often visible due to the
different benchmarking datasets. This article describes the creation of an
evaluation dataset and uses this dataset to investigate the different
detectors. The selected detectors are benchmarked against each other.

ÊëòË¶ÅÔºöÊú¨ÊñáÊ¶ÇËø∞‰∫Ü LLM ÊñáÊú¨ËØÜÂà´ÁöÑÈ¢ÜÂüü„ÄÇ
‰ªãÁªç‰∫ÜÁî®‰∫éËØÜÂà´ LLM ÁîüÊàêÁöÑÊñáÊú¨ÁöÑ‰∏çÂêåÊñπÊ≥ïÂíåÂ∑≤ÂÆûÁé∞ÁöÑÊ£ÄÊµãÂô®„ÄÇÈô§‰∫ÜËÆ®ËÆ∫
ÂÆûÁé∞‰πãÂ§ñÔºåÊú¨ÊñáÈáçÁÇπÂÖ≥Ê≥®Ê£ÄÊµãÂô®ÁöÑÂü∫ÂáÜÊµãËØï„ÄÇËôΩÁÑ∂
ÊúâËÆ∏Â§öÁî®‰∫éËØÜÂà´ LLM ÁîüÊàêÁöÑÊñáÊú¨ÁöÑËΩØ‰ª∂‰∫ßÂìÅÔºå
‰∏ìÊ≥®‰∫éÁ±ª‰ºº ChatGPT ÁöÑ LLMÔºå‰ΩÜËØÜÂà´Ë¥®ÈáèÔºàËØÜÂà´
ÁéáÔºâÂ∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÊ≠§Â§ñÔºåËôΩÁÑ∂ÂèØ‰ª•ÁúãÂá∫ÁßëÂ≠¶
Ë¥°ÁåÆËÄÖÂú®ÊèêÂá∫ÂÖ∂Êñ∞ÊñπÊ≥ïÊó∂Âä™Âäõ‰∏éÂÖ∂‰ªñÊñπÊ≥ïËøõË°åÊüêÁßç
ÊØîËæÉÔºå‰ΩÜËØÑ‰º∞Êï∞ÊçÆÈõÜÁöÑÊûÑÂª∫ÂíåÁã¨Á´ãÊÄßÈÄöÂ∏∏Èöæ‰ª•ÁêÜËß£„ÄÇÂõ†Ê≠§ÔºåÁî±‰∫é
‰∏çÂêåÁöÑÂü∫ÂáÜÊï∞ÊçÆÈõÜÔºåLLM Ê£ÄÊµãÂô®ÁöÑÊÄßËÉΩËØÑ‰º∞‰∏≠ÁªèÂ∏∏‰ºöÂá∫Áé∞Â∑ÆÂºÇ„ÄÇÊú¨Êñá‰ªãÁªç‰∫ÜËØÑ‰º∞Êï∞ÊçÆÈõÜÁöÑÂàõÂª∫ÔºåÂπ∂‰ΩøÁî®Ê≠§Êï∞ÊçÆÈõÜÊù•Ë∞ÉÊü•‰∏çÂêåÁöÑ
Ê£ÄÊµãÂô®„ÄÇÈÄâÂÆöÁöÑÊ£ÄÊµãÂô®Áõ∏‰∫íËøõË°åÂü∫ÂáÜÊµãËØï„ÄÇ

##### **"Not Aligned" is Not "Malicious": Being Careful about Hallucinations of Large Language Models' Jailbreak**
2406.11668v1 by Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Jiayi Mao, Xueqi Cheng

"Jailbreak" is a major safety concern of Large Language Models (LLMs), which
occurs when malicious prompts lead LLMs to produce harmful outputs, raising
issues about the reliability and safety of LLMs. Therefore, an effective
evaluation of jailbreaks is very crucial to develop its mitigation strategies.
However, our research reveals that many jailbreaks identified by current
evaluations may actually be hallucinations-erroneous outputs that are mistaken
for genuine safety breaches. This finding suggests that some perceived
vulnerabilities might not represent actual threats, indicating a need for more
precise red teaming benchmarks. To address this problem, we propose the
$\textbf{B}$enchmark for reli$\textbf{AB}$ilit$\textbf{Y}$ and
jail$\textbf{B}$reak ha$\textbf{L}$l$\textbf{U}$cination $\textbf{E}$valuation
(BabyBLUE). BabyBLUE introduces a specialized validation framework including
various evaluators to enhance existing jailbreak benchmarks, ensuring outputs
are useful malicious instructions. Additionally, BabyBLUE presents a new
dataset as an augmentation to the existing red teaming benchmarks, specifically
addressing hallucinations in jailbreaks, aiming to evaluate the true potential
of jailbroken LLM outputs to cause harm to human society.

ÊëòË¶ÅÔºö„ÄåË∂äÁçÑ„ÄçÊòØÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑ‰∏ªË¶ÅÂÆâÂÖ®ÂïèÈ°åÔºåÂÆÉÁôºÁîüÂú®ÊÉ°ÊÑèÊèêÁ§∫Â∞éËá¥ LLM Áî¢ÁîüÊúâÂÆ≥Ëº∏Âá∫ÊôÇÔºåÂºïÁôº‰∫ÜÈóúÊñº LLM ÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄßÂïèÈ°å„ÄÇÂõ†Ê≠§ÔºåÂ∞çË∂äÁçÑÈÄ≤Ë°åÊúâÊïàÁöÑË©ï‰º∞Â∞çÊñºÂà∂ÂÆöÂÖ∂Á∑©Ëß£Á≠ñÁï•Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÁï∂ÂâçË©ï‰º∞‰∏≠Ë≠òÂà•Âá∫ÁöÑË®±Â§öË∂äÁçÑÂØ¶Èöõ‰∏äÂèØËÉΩÊòØÂπªË¶∫‚Äî‚ÄîÈåØË™§ÁöÑËº∏Âá∫ÔºåË¢´Ë™§Ë™çÁÇ∫ÁúüÊ≠£ÁöÑÂÆâÂÖ®ÊºèÊ¥û„ÄÇÈÄô‰∏ÄÁôºÁèæË°®ÊòéÔºå‰∏Ä‰∫õÊÑüÁü•Âà∞ÁöÑÊºèÊ¥ûÂèØËÉΩ‰∏¶‰∏çËÉΩ‰ª£Ë°®ÂØ¶ÈöõÂ®ÅËÑÖÔºåÈÄôË°®ÊòéÈúÄË¶ÅÊõ¥Á≤æÁ¢∫ÁöÑÁ¥ÖÈöäÂü∫Ê∫ñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü$\textbf{B}$enchmark for reli$\textbf{AB}$ilit$\textbf{Y}$ and jail$\textbf{B}$reak ha$\textbf{L}$l$\textbf{U}$cination $\textbf{E}$valuationÔºàBabyBLUEÔºâ„ÄÇBabyBLUE ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂ∞àÈñÄÁöÑÈ©óË≠âÊ°ÜÊû∂ÔºåÂåÖÊã¨ÂêÑÁ®ÆË©ï‰º∞Âô®Ôºå‰ª•Â¢ûÂº∑ÁèæÊúâÁöÑË∂äÁçÑÂü∫Ê∫ñÔºåÁ¢∫‰øùËº∏Âá∫ÊòØÊúâÁî®ÁöÑÊÉ°ÊÑèÊåá‰ª§„ÄÇÊ≠§Â§ñÔºåBabyBLUE ÈÇÑÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞Êï∏ÊìöÈõÜ‰ΩúÁÇ∫Â∞çÁèæÊúâÁ¥ÖÈöäÂü∫Ê∫ñÁöÑÊì¥ÂÖÖÔºåÁâπÂà•ÈáùÂ∞çË∂äÁçÑ‰∏≠ÁöÑÂπªË¶∫ÔºåÊó®Âú®Ë©ï‰º∞Ë∂äÁçÑ LLM Ëº∏Âá∫Â∞ç‰∫∫È°ûÁ§æÊúÉÈÄ†ÊàêÂÇ∑ÂÆ≥ÁöÑÁúüÊ≠£ÊΩõÂäõ„ÄÇ

##### **See It from My Perspective: Diagnosing the Western Cultural Bias of Large Vision-Language Models in Image Understanding**
2406.11665v1 by Amith Ananthram, Elias Stengel-Eskin, Carl Vondrick, Mohit Bansal, Kathleen McKeown

Vision-language models (VLMs) can respond to queries about images in many
languages. However, beyond language, culture affects how we see things. For
example, individuals from Western cultures focus more on the central figure in
an image while individuals from Eastern cultures attend more to scene context.
In this work, we present a novel investigation that demonstrates and localizes
VLMs' Western bias in image understanding. We evaluate large VLMs across
subjective and objective visual tasks with culturally diverse images and
annotations. We find that VLMs perform better on the Western subset than the
Eastern subset of each task. Controlled experimentation tracing the source of
this bias highlights the importance of a diverse language mix in text-only
pre-training for building equitable VLMs, even when inference is performed in
English. Moreover, while prompting in the language of a target culture can lead
to reductions in bias, it is not a substitute for building AI more
representative of the world's languages.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ËÉΩ‰ª•Â§öÁ®ÆË™ûË®ÄÂõûÁ≠îÈóúÊñºÂΩ±ÂÉèÁöÑÊü•Ë©¢„ÄÇÁÑ∂ËÄåÔºåÈô§‰∫ÜË™ûË®Ä‰πãÂ§ñÔºåÊñáÂåñ‰πüÊúÉÂΩ±ÈüøÊàëÂÄëÁúãÂæÖ‰∫ãÁâ©ÁöÑÊñπÂºè„ÄÇ‰æãÂ¶ÇÔºå‰æÜËá™Ë•øÊñπÊñáÂåñÁöÑ‰∫∫ÊúÉÊõ¥Â∞àÊ≥®ÊñºÂΩ±ÂÉè‰∏≠ÁöÑ‰∏≠Â§Æ‰∫∫Áâ©ÔºåËÄå‰æÜËá™Êù±ÊñπÊñáÂåñÁöÑ‰∫∫ÂâáÊúÉÊõ¥ÈóúÊ≥®Â†¥ÊôØËÉåÊôØ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÊñ∞Á©éÁöÑÁ†îÁ©∂ÔºåÂ±ïÁ§∫‰∏¶ÂÆö‰Ωç‰∫Ü VLM Âú®ÂΩ±ÂÉèÁêÜËß£‰∏≠ÁöÑË•øÊñπÂÅèË¶ã„ÄÇÊàëÂÄëÂú®ÂÖ∑ÊúâÊñáÂåñÂ§öÂÖÉÊÄßÂΩ±ÂÉèÂíåË®ªËß£ÁöÑ‰∏ªËßÄÂíåÂÆ¢ËßÄË¶ñË¶∫‰ªªÂãô‰∏≠Ë©ï‰º∞‰∫ÜÂ§ßÂûã VLM„ÄÇÊàëÂÄëÁôºÁèæÔºåVLM Âú®ÊØèÂÄã‰ªªÂãôÁöÑË•øÊñπÂ≠êÈõÜ‰∏äË°®ÁèæÂÑ™ÊñºÊù±ÊñπÂ≠êÈõÜ„ÄÇËøΩËπ§Ê≠§ÂÅèË¶ã‰æÜÊ∫êÁöÑÂèóÊéßÂØ¶È©óÂº∑Ë™ø‰∫ÜÂú®ÂÉÖÊñáÂ≠óÈ†êË®ìÁ∑¥‰∏≠‰ΩøÁî®Â§öÊ®£ÂåñË™ûË®ÄÁµÑÂêàÂ∞çÊñºÂª∫ÊßãÂÖ¨Âπ≥ÁöÑ VLM ÁöÑÈáçË¶ÅÊÄßÔºåÂç≥‰ΩøÊòØÂú®Ëã±Ë™û‰∏≠Âü∑Ë°åÊé®Ë´ñÊôÇ‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊ≠§Â§ñÔºåÂÑòÁÆ°‰ΩøÁî®ÁõÆÊ®ôÊñáÂåñÁöÑË™ûË®ÄÊèêÁ§∫ÂèØ‰ª•Ê∏õÂ∞ëÂÅèË¶ãÔºå‰ΩÜÂÆÉ‰∏¶‰∏çËÉΩÂèñ‰ª£Âª∫ÊßãÊõ¥ËÉΩ‰ª£Ë°®‰∏ñÁïåË™ûË®ÄÁöÑ AI„ÄÇ

##### **Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting**
2406.11661v1 by Sagnik Mukherjee, Muhammad Farid Adilazuarda, Sunayana Sitaram, Kalika Bali, Alham Fikri Aji, Monojit Choudhury

Socio-demographic prompting is a commonly employed approach to study cultural
biases in LLMs as well as for aligning models to certain cultures. In this
paper, we systematically probe four LLMs (Llama 3, Mistral v0.2, GPT-3.5 Turbo
and GPT-4) with prompts that are conditioned on culturally sensitive and
non-sensitive cues, on datasets that are supposed to be culturally sensitive
(EtiCor and CALI) or neutral (MMLU and ETHICS). We observe that all models
except GPT-4 show significant variations in their responses on both kinds of
datasets for both kinds of prompts, casting doubt on the robustness of the
culturally-conditioned prompting as a method for eliciting cultural bias in
models or as an alignment strategy. The work also calls rethinking the control
experiment design to tease apart the cultural conditioning of responses from
"placebo effect", i.e., random perturbations of model responses due to
arbitrary tokens in the prompt.

ÊëòË¶ÅÔºöÁ§æÊúÉ‰∫∫Âè£ÊèêÁ§∫ÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÊé°Áî®ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÁ†îÁ©∂ LLM ‰∏≠ÁöÑÊñáÂåñÂÅèË¶ãÔºå‰ª•ÂèäÂ∞áÊ®°ÂûãËàáÁâπÂÆöÊñáÂåñÂ∞çÈΩä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Êé¢Êü•‰∫ÜÂõõÂÄã LLMÔºàLlama 3„ÄÅMistral v0.2„ÄÅGPT-3.5 Turbo Âíå GPT-4ÔºâÔºåÊèêÁ§∫ÂÆÉÂÄë‰ª•ÊñáÂåñÊïèÊÑüÂíå‰∏çÊïèÊÑüÁöÑÁ∑öÁ¥¢ÁÇ∫Ê¢ù‰ª∂ÔºåÂú®ÂÅáË®≠ÁÇ∫ÊñáÂåñÊïèÊÑüÔºàEtiCor Âíå CALIÔºâÊàñ‰∏≠Á´ãÔºàMMLU Âíå ETHICSÔºâÁöÑÊï∏ÊìöÈõÜ‰∏ä„ÄÇÊàëÂÄëËßÄÂØüÂà∞Èô§‰∫Ü GPT-4 ‰πãÂ§ñÔºåÊâÄÊúâÊ®°ÂûãÂú®ÂÖ©Á®ÆÊèêÁ§∫ÁöÑÂÖ©Á®ÆÊï∏ÊìöÈõÜ‰∏äÁöÑÂõûÊáâÈÉΩÂá∫ÁèæÈ°ØËëóÂ∑ÆÁï∞ÔºåÈÄôÂ∞çÊñáÂåñÊ¢ù‰ª∂ÊèêÁ§∫‰ΩúÁÇ∫ÂºïÁôºÊ®°Âûã‰∏≠ÊñáÂåñÂÅèË¶ãÁöÑÊñπÊ≥ïÊàñ‰ΩúÁÇ∫Â∞çÈΩäÁ≠ñÁï•ÁöÑÁ©©ÂÅ•ÊÄßÊèêÂá∫Ë≥™Áñë„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰πüË¶ÅÊ±ÇÈáçÊñ∞ÊÄùËÄÉÂ∞çÁÖßÂØ¶È©óË®≠Ë®àÔºå‰ª•ÂçÄÂàÜÂõûÊáâÁöÑÊñáÂåñÊ¢ù‰ª∂Âíå„ÄåÂÆâÊÖ∞ÂäëÊïàÊáâ„ÄçÔºåÂç≥ÊèêÁ§∫‰∏≠‰ªªÊÑèÁ¨¶ËôüÂ∞éËá¥Ê®°ÂûãÂõûÊáâÁöÑÈö®Ê©üÊìæÂãï„ÄÇ

##### **Can LLM be a Personalized Judge?**
2406.11657v1 by Yijiang River Dong, Tiancheng Hu, Nigel Collier

Ensuring that large language models (LLMs) reflect diverse user values and
preferences is crucial as their user bases expand globally. It is therefore
encouraging to see the growing interest in LLM personalization within the
research community. However, current works often rely on the LLM-as-a-Judge
approach for evaluation without thoroughly examining its validity. In this
paper, we investigate the reliability of LLM-as-a-Personalized-Judge, asking
LLMs to judge user preferences based on personas. Our findings suggest that
directly applying LLM-as-a-Personalized-Judge is less reliable than previously
assumed, showing low and inconsistent agreement with human ground truth. The
personas typically used are often overly simplistic, resulting in low
predictive power. To address these issues, we introduce verbal uncertainty
estimation into the LLM-as-a-Personalized-Judge pipeline, allowing the model to
express low confidence on uncertain judgments. This adjustment leads to much
higher agreement (above 80%) on high-certainty samples for binary tasks.
Through human evaluation, we find that the LLM-as-a-Personalized-Judge achieves
comparable performance to third-party humans evaluation and even surpasses
human performance on high-certainty samples. Our work indicates that
certainty-enhanced LLM-as-a-Personalized-Judge offers a promising direction for
developing more reliable and scalable methods for evaluating LLM
personalization.

ÊëòË¶ÅÔºöÁ¢∫‰øùÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂèçÊò†Â§öÊ®£ÂåñÁöÑ‰ΩøÁî®ËÄÖÂÉπÂÄºËßÄÂíåÂÅèÂ•ΩÔºåÈö®ËëóÂÖ∂‰ΩøÁî®ËÄÖÂü∫Á§éÂú®ÂÖ®ÁêÉÊì¥Â±ïÔºåÈÄôÈªûËá≥ÈóúÈáçË¶Å„ÄÇÂõ†Ê≠§ÔºåÁúãÂà∞Á†îÁ©∂Á§æÁæ§Â∞ç LLM ÂÄã‰∫∫ÂåñË∂ä‰æÜË∂äÊÑüËààË∂£Ôºå‰ª§‰∫∫ÊÑüÂà∞ÊåØÂ•Æ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑËëó‰ΩúÂ∏∏‰æùË≥¥ LLM ‰ΩúÁÇ∫Ë©ï‰º∞ÁöÑË©ïÂà§ËÄÖÔºåËÄåÊú™ÂæπÂ∫ïÊ™¢Ë¶ñÂÖ∂ÊúâÊïàÊÄß„ÄÇÂú®Êú¨Ë´ñÊñá‰∏≠ÔºåÊàëÂÄëË™øÊü•‰∫Ü LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÁöÑÂèØÈù†ÊÄßÔºåË¶ÅÊ±Ç LLM Ê†πÊìöËßíËâ≤‰æÜÂà§Êñ∑‰ΩøÁî®ËÄÖÁöÑÂÅèÂ•Ω„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÁõ¥Êé•ÊáâÁî® LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÔºåÂÖ∂ÂèØÈù†ÊÄß‰ΩéÊñºÂÖàÂâçÁöÑÂÅáË®≠ÔºåËàá‰∫∫È°ûÁöÑÁúüÂØ¶ÊÉÖÊ≥ÅÈ°ØÁ§∫Âá∫‰Ωé‰∏î‰∏ç‰∏ÄËá¥ÁöÑÁõ∏Á¨¶ÊÄß„ÄÇÈÄöÂ∏∏ÊâÄ‰ΩøÁî®ÁöÑËßíËâ≤ÂæÄÂæÄÈÅéÊñºÁ∞°ÂåñÔºåÂ∞éËá¥È†êÊ∏¨ËÉΩÂäõ‰Ωé„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂú® LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÁöÑÁÆ°Á∑ö‰∏≠ÂºïÂÖ•‰∫ÜÂè£È†≠‰∏çÁ¢∫ÂÆöÊÄßË©ï‰º∞ÔºåËÆìÊ®°ÂûãËÉΩÂ§†Â∞ç‰∏çÁ¢∫ÂÆöÁöÑÂà§Êñ∑Ë°®ÈÅî‰Ωé‰ø°ÂøÉ„ÄÇÊ≠§Ë™øÊï¥Â∞éËá¥‰∫åÂÖÉ‰ªªÂãô‰∏≠Â∞çÈ´òÁ¢∫ÂÆöÊÄßÊ®£Êú¨ÁöÑÁõ∏Á¨¶ÊÄßÂ§ßÂπÖÊèêÂçá (Ë∂ÖÈÅé 80%)„ÄÇÈÄèÈÅé‰∫∫ÁÇ∫Ë©ï‰º∞ÔºåÊàëÂÄëÁôºÁèæ LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÈÅîÂà∞‰∫ÜËàáÁ¨¨‰∏âÊñπ‰∫∫È°ûË©ï‰º∞Áõ∏Áï∂ÁöÑË°®ÁèæÔºåÁîöËá≥Âú®È´òÁ¢∫ÂÆöÊÄßÊ®£Êú¨‰∏äË∂ÖË∂ä‰∫Ü‰∫∫È°ûË°®Áèæ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÊåáÂá∫ÔºåÁ¢∫ÂÆöÊÄßÂ¢ûÂº∑ÁöÑ LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÁÇ∫ÈñãÁôºÊõ¥ÂèØÈù†‰∏îÂèØÊì¥ÂÖÖÁöÑÊñπÊ≥ï‰æÜË©ï‰º∞ LLM ÂÄã‰∫∫ÂåñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊñπÂêë„ÄÇ

##### **A Two-dimensional Zero-shot Dialogue State Tracking Evaluation Method using GPT-4**
2406.11651v1 by Ming Gu, Yan Yang

Dialogue state tracking (DST) is evaluated by exact matching methods, which
rely on large amounts of labeled data and ignore semantic consistency, leading
to over-evaluation. Currently, leveraging large language models (LLM) in
evaluating natural language processing tasks has achieved promising results.
However, using LLM for DST evaluation is still under explored. In this paper,
we propose a two-dimensional zero-shot evaluation method for DST using GPT-4,
which divides the evaluation into two dimensions: accuracy and completeness.
Furthermore, we also design two manual reasoning paths in prompting to further
improve the accuracy of evaluation. Experimental results show that our method
achieves better performance compared to the baselines, and is consistent with
traditional exact matching based methods.

ÊëòË¶ÅÔºöÂ∞çË©±ÁãÄÊÖãËøΩËπ§ (DST) ÊòØÁî±Á≤æÁ¢∫ÊØîÂ∞çÊñπÊ≥ïË©ï‰º∞ÔºåÂÆÉ‰æùË≥¥Â§ßÈáèÁöÑÊ®ôÁ±§Ë≥áÊñôÔºå‰∏¶ÂøΩÁï•Ë™ûÊÑè‰∏ÄËá¥ÊÄßÔºåÈÄôÂ∞éËá¥Ë©ï‰º∞ÈÅéÈ´ò„ÄÇÁõÆÂâçÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜË©ï‰º∞Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÂ∑≤ÂèñÂæó‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî® LLM ÈÄ≤Ë°å DST Ë©ï‰º∞‰ªçËôïÊñºÊé¢Á¥¢ÈöéÊÆµ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄã‰ΩøÁî® GPT-4 ÁöÑ‰∫åÁ∂≠Èõ∂Ê¨°Ë©ï‰º∞ÊñπÊ≥ïÔºåÂ∞áË©ï‰º∞ÂàÜÁÇ∫ÂÖ©ÂÄãÈù¢ÂêëÔºöÊ∫ñÁ¢∫ÊÄßÂíåÂÆåÊï¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑË®≠Ë®à‰∫ÜÂÖ©ÂÄãÊâãÂãïÊé®ÁêÜË∑ØÂæëÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òË©ï‰º∞ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÂü∫Á∑öÁõ∏ÊØîÔºåÊàëÂÄëÁöÑË©ï‰º∞ÊñπÊ≥ïË°®ÁèæÊõ¥Â•ΩÔºå‰∏¶‰∏îËàáÂÇ≥Áµ±ÁöÑÂü∫ÊñºÁ≤æÁ¢∫ÊØîÂ∞çÁöÑÊñπÊ≥ï‰∏ÄËá¥„ÄÇ

##### **YOLO-FEDER FusionNet: A Novel Deep Learning Architecture for Drone Detection**
2406.11641v1 by Tamara R. Lenhard, Andreas Weinmann, Stefan J√§ger, Tobias Koch

Predominant methods for image-based drone detection frequently rely on
employing generic object detection algorithms like YOLOv5. While proficient in
identifying drones against homogeneous backgrounds, these algorithms often
struggle in complex, highly textured environments. In such scenarios, drones
seamlessly integrate into the background, creating camouflage effects that
adversely affect the detection quality. To address this issue, we introduce a
novel deep learning architecture called YOLO-FEDER FusionNet. Unlike
conventional approaches, YOLO-FEDER FusionNet combines generic object detection
methods with the specialized strength of camouflage object detection techniques
to enhance drone detection capabilities. Comprehensive evaluations of
YOLO-FEDER FusionNet show the efficiency of the proposed model and demonstrate
substantial improvements in both reducing missed detections and false alarms.

ÊëòË¶ÅÔºöÂü∫ÊñºÂΩ±ÂÉèÁöÑÁÑ°‰∫∫Ê©üÂÅµÊ∏¨ÁöÑÂ∏∏Ë¶ãÊñπÊ≥ïÁ∂ìÂ∏∏‰æùË≥¥‰ΩøÁî® YOLOv5 Á≠âÈÄöÁî®Áâ©‰ª∂ÂÅµÊ∏¨ÊºîÁÆóÊ≥ï„ÄÇÈÄô‰∫õÊºîÁÆóÊ≥ïÈõñÁÑ∂Á≤æÊñºÂú®ÂùáÂãªËÉåÊôØ‰∏≠Ëæ®Ë≠òÁÑ°‰∫∫Ê©üÔºå‰ΩÜÂú®Ë§áÈõú„ÄÅÁ¥ãÁêÜË±êÂØåÁöÑÁí∞Â¢É‰∏≠ÂçªÂ∏∏Â∏∏Âäõ‰∏çÂæûÂøÉ„ÄÇÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÁÑ°‰∫∫Ê©üËÉΩÁÑ°Á∏´ËûçÂÖ•ËÉåÊôØÔºåÁî¢ÁîüÂÅΩË£ùÊïàÊûúÔºåÂ∞çÂÅµÊ∏¨ÂìÅË≥™ÈÄ†ÊàêË≤†Èù¢ÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∏ÄÁ®ÆÁ®±ÁÇ∫ YOLO-FEDER FusionNet ÁöÑÂâµÊñ∞Ê∑±Â∫¶Â≠∏ÁøíÊû∂Êßã„ÄÇËàáÂÇ≥Áµ±ÊñπÊ≥ï‰∏çÂêåÔºåYOLO-FEDER FusionNet ÁµêÂêà‰∫ÜÈÄöÁî®Áâ©‰ª∂ÂÅµÊ∏¨ÊñπÊ≥ïËàáÂÅΩË£ùÁâ©‰ª∂ÂÅµÊ∏¨ÊäÄË°ìÁöÑÂ∞àÈñÄÂÑ™Âã¢Ôºå‰ª•Â¢ûÂº∑ÁÑ°‰∫∫Ê©üÂÅµÊ∏¨ËÉΩÂäõ„ÄÇÂ∞ç YOLO-FEDER FusionNet ÁöÑÂÖ®Èù¢Ë©ï‰º∞È°ØÁ§∫‰∫ÜÊâÄÊèêË≠∞Ê®°ÂûãÁöÑÊïàÁéáÔºå‰∏¶Ë≠âÊòéÂú®Ê∏õÂ∞ëÊºèÂÅµÊ∏¨ÂíåË™§Â†±ÊñπÈù¢ÈÉΩÊúâÈ°ØËëóÁöÑÊîπÂñÑ„ÄÇ

##### **Linear Bellman Completeness Suffices for Efficient Online Reinforcement Learning with Few Actions**
2406.11640v2 by Noah Golowich, Ankur Moitra

One of the most natural approaches to reinforcement learning (RL) with
function approximation is value iteration, which inductively generates
approximations to the optimal value function by solving a sequence of
regression problems. To ensure the success of value iteration, it is typically
assumed that Bellman completeness holds, which ensures that these regression
problems are well-specified. We study the problem of learning an optimal policy
under Bellman completeness in the online model of RL with linear function
approximation. In the linear setting, while statistically efficient algorithms
are known under Bellman completeness (e.g., Jiang et al. (2017); Zanette et al.
(2020)), these algorithms all rely on the principle of global optimism which
requires solving a nonconvex optimization problem. In particular, it has
remained open as to whether computationally efficient algorithms exist. In this
paper we give the first polynomial-time algorithm for RL under linear Bellman
completeness when the number of actions is any constant.

ÊëòË¶ÅÔºöÊúÄËá™ÁÑ∂Âº∑ÂåñÂ≠∏Áøí (RL) ÁöÑÊñπÊ≥ï‰πã‰∏ÄÔºåÂÖ∑ÊúâÂäüËÉΩËøë‰ººÂÄºËø≠‰ª£ÔºåÂèØÈÄèÈÅéËß£Ê±∫‰∏ÄÁ≥ªÂàóÂõûÊ≠∏ÂïèÈ°åÔºåÊÑüÊáâÁî¢ÁîüÊúÄ‰Ω≥ÂÉπÂÄºÂáΩÊï∏ÁöÑËøë‰ººÂÄº„ÄÇÁÇ∫Á¢∫‰øùÂÄºËø≠‰ª£ÁöÑÊàêÂäüÔºåÈÄöÂ∏∏ÂÅáË®≠Ë≤ùÁàæÊõºÂÆåÂÇôÊÄßÊàêÁ´ãÔºåÈÄôÂèØÁ¢∫‰øùÈÄô‰∫õÂõûÊ≠∏ÂïèÈ°åÊúâÊòéÁ¢∫ÁöÑË¶èÁØÑ„ÄÇÊàëÂÄëÁ†îÁ©∂Âú®Á∑ö RL Ê®°Âûã‰∏≠ÔºåÂú®Á∑öÊÄßÂáΩÊï∏Ëøë‰ºº‰∏≠Â≠∏ÁøíÊúÄ‰Ω≥Á≠ñÁï•ÁöÑÂïèÈ°åÔºå‰∏¶ÂÖ∑ÊúâË≤ùÁàæÊõºÂÆåÂÇôÊÄß„ÄÇÂú®Á∑öÊÄßË®≠ÁΩÆ‰∏≠ÔºåÈõñÁÑ∂Âú®Ë≤ùÁàæÊõºÂÆåÂÇôÊÄß‰∏ãÂ∑≤Áü•ÂÖ∑ÊúâÁµ±Ë®àÊïàÁéáÁöÑÊºîÁÆóÊ≥ïÔºà‰æãÂ¶ÇÔºåJiang Á≠â‰∫∫ (2017)ÔºõZanette Á≠â‰∫∫ (2020)ÔºâÔºå‰ΩÜÈÄô‰∫õÊºîÁÆóÊ≥ïÈÉΩ‰æùË≥¥ÊñºÂÖ®Â±ÄÊ®ÇËßÄ‰∏ªÁæ©ÂéüÂâáÔºåÈúÄË¶ÅËß£Ê±∫ÈùûÂá∏ÊúÄ‰Ω≥ÂåñÂïèÈ°å„ÄÇÁâπÂà•ÊòØÔºåÂú®Ë®àÁÆó‰∏äÊòØÂê¶ÂÖ∑ÊúâÊïàÁéáÁöÑÊºîÁÆóÊ≥ïÔºå‰ªçÊòØÊá∏ËÄåÊú™Êú™Ê±∫ÁöÑÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁµ¶Âá∫‰∫ÜÂú®Á∑öÊÄßË≤ùÁàæÊõºÂÆåÂÇôÊÄß‰∏ã RL ÁöÑÁ¨¨‰∏ÄÂÄãÂ§öÈ†ÖÂºèÊôÇÈñìÊºîÁÆóÊ≥ïÔºåÁï∂Âãï‰ΩúÊï∏ÈáèÁÇ∫‰ªª‰ΩïÂ∏∏Êï∏ÊôÇ„ÄÇ

##### **MASAI: Modular Architecture for Software-engineering AI Agents**
2406.11638v1 by Daman Arora, Atharv Sonwane, Nalin Wadhwa, Abhav Mehrotra, Saiteja Utpala, Ramakrishna Bairi, Aditya Kanade, Nagarajan Natarajan

A common method to solve complex problems in software engineering, is to
divide the problem into multiple sub-problems. Inspired by this, we propose a
Modular Architecture for Software-engineering AI (MASAI) agents, where
different LLM-powered sub-agents are instantiated with well-defined objectives
and strategies tuned to achieve those objectives. Our modular architecture
offers several advantages: (1) employing and tuning different problem-solving
strategies across sub-agents, (2) enabling sub-agents to gather information
from different sources scattered throughout a repository, and (3) avoiding
unnecessarily long trajectories which inflate costs and add extraneous context.
MASAI enabled us to achieve the highest performance (28.33% resolution rate) on
the popular and highly challenging SWE-bench Lite dataset consisting of 300
GitHub issues from 11 Python repositories. We conduct a comprehensive
evaluation of MASAI relative to other agentic methods and analyze the effects
of our design decisions and their contribution to the success of MASAI.

ÊëòË¶ÅÔºöÂú®ËªüÈ´îÂ∑•Á®ã‰∏≠ÔºåËß£Ê±∫Ë§áÈõúÂïèÈ°åÁöÑ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÊñπÊ≥ïÔºåÊòØÂ∞áÂïèÈ°åÂàÜËß£ÊàêÂ§öÂÄãÂ≠êÂïèÈ°å„ÄÇÂèóÂà∞Ê≠§ÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫ËªüÈ´îÂ∑•Á®ã AIÔºàMASAIÔºâ‰ª£ÁêÜÊ®°ÁµÑÂåñÊû∂ÊßãÔºåÂÖ∂‰∏≠‰∏çÂêåÁöÑ LLM È©ÖÂãïÂ≠ê‰ª£ÁêÜÊúÉ‰ª•ÊòéÁ¢∫ÁöÑÁõÆÊ®ôÂíåÁ≠ñÁï•ÂØ¶‰æãÂåñÔºå‰ª•ÈÅîÊàêÈÄô‰∫õÁõÆÊ®ô„ÄÇÊàëÂÄëÁöÑÊ®°ÁµÑÂåñÊû∂ÊßãÊèê‰æõ‰∫ÜÂ§öÈ†ÖÂÑ™ÈªûÔºö(1) Êé°Áî®ÂíåË™øÊï¥Ë∑®Â≠ê‰ª£ÁêÜÁöÑ‰∏çÂêåÂïèÈ°åËß£Ê±∫Á≠ñÁï•Ôºå(2) ËÆìÂ≠ê‰ª£ÁêÜÂæûÊï£‰ΩàÂú®Êï¥ÂÄãÂÑ≤Â≠òÂ∫´ÁöÑ‰∏çÂêå‰æÜÊ∫êÊî∂ÈõÜË≥áË®äÔºå‰ª•Âèä (3) ÈÅøÂÖç‰∏çÂøÖË¶ÅÁöÑÈï∑ËªåË∑°ÔºåÈÄôÊúÉÂ¢ûÂä†ÊàêÊú¨‰∏¶Â¢ûÂä†ÁÑ°ÈóúÁöÑÂÖßÂÆπ„ÄÇMASAI ËÆìÊàëÂÄëÂú®Áî±‰æÜËá™ 11 ÂÄã Python ÂÑ≤Â≠òÂ∫´ÁöÑ 300 ÂÄã GitHub ÂïèÈ°åÁµÑÊàêÁöÑÁÜ±ÈñÄ‰∏îÊ•µÂÖ∑ÊåëÊà∞ÊÄßÁöÑ SWE-bench Lite Ë≥áÊñôÈõÜ‰∏äÔºåÈÅîÂà∞ÊúÄÈ´òÊïàËÉΩÔºà28.33% Ëß£ÊûêÁéáÔºâ„ÄÇÊàëÂÄëÂ∞ç MASAI Áõ∏Â∞çÊñºÂÖ∂‰ªñ‰ª£ÁêÜÊñπÊ≥ïÈÄ≤Ë°åÂÖ®Èù¢Ë©ï‰º∞Ôºå‰∏¶ÂàÜÊûêÊàëÂÄëÁöÑË®≠Ë®àÊ±∫Á≠ñÂèäÂÖ∂Â∞ç MASAI ÊàêÂäüÊâÄÂÅöÁöÑË≤¢Áçª„ÄÇ

##### **The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance**
2406.11634v1 by Kyle Moore, Jesse Roberts, Thao Pham, Oseremhen Ewaleifoh, Doug Fisher

Cloze testing is a common method for measuring the behavior of large language
models on a number of benchmark tasks. Using the MMLU dataset, we show that the
base-rate probability (BRP) differences across answer tokens are significant
and affect task performance ie. guess A if uncertain. We find that
counterfactual prompting does sufficiently mitigate the BRP effect. The BRP
effect is found to have a similar effect to test taking strategies employed by
humans leading to the conflation of task performance and test-taking ability.
We propose the Nvr-X-MMLU task, a variation of MMLU, which helps to
disambiguate test-taking ability from task performance and reports the latter.

ÊëòË¶ÅÔºöÂÆåÂΩ¢Â°´Á©∫Ê∏¨Ë©¶ÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÊñπÊ≥ïÔºåÁî®ÊñºË°°ÈáèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Ë®±Â§öÂü∫Ê∫ñ‰ªªÂãô‰∏äÁöÑË°åÁÇ∫„ÄÇ‰ΩøÁî® MMLU Ë≥áÊñôÈõÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÁ≠îÊ°àÁ¨¶Ëôü‰πãÈñìÁöÑÂü∫Á§éÊ©üÁéá (BRP) Â∑ÆÁï∞ÂÖ∑ÊúâÈ°ØËëóÊÑèÁæ©Ôºå‰∏¶ÂΩ±Èüø‰ªªÂãôÂü∑Ë°åÔºå‰æãÂ¶ÇÂú®‰∏çÁ¢∫ÂÆöÊôÇÁåúÊ∏¨ A„ÄÇÊàëÂÄëÁôºÁèæÂèç‰∫ãÂØ¶ÊèêÁ§∫Á¢∫ÂØ¶ÂèØ‰ª•ÂÖÖÂàÜÊ∏õËºï BRP ÊïàÊáâ„ÄÇÁôºÁèæ BRP ÊïàÊáâÂ∞ç‰∫∫È°ûÊé°Áî®ÁöÑÊáâË©¶Á≠ñÁï•ÂÖ∑ÊúâÈ°û‰ººÁöÑÊïàÊáâÔºåÂ∞éËá¥‰ªªÂãôÂü∑Ë°åÂíåÊáâË©¶ËÉΩÂäõÊ∑∑Ê∑Ü„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü Nvr-X-MMLU ‰ªªÂãôÔºåÈÄôÊòØ MMLU ÁöÑ‰∏ÄÁ®ÆËÆäÈ´îÔºåÊúâÂä©ÊñºÊ∂àÈô§ÊáâË©¶ËÉΩÂäõËàá‰ªªÂãôÂü∑Ë°å‰πãÈñìÁöÑÊ≠ßÁæ©Ôºå‰∏¶Â†±ÂëäÂæåËÄÖ„ÄÇ

##### **Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation**
2406.11632v1 by Boxuan Lyu, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura

Maximum a posteriori decoding, a commonly used method for neural machine
translation (NMT), aims to maximize the estimated posterior probability.
However, high estimated probability does not always lead to high translation
quality. Minimum Bayes Risk (MBR) decoding offers an alternative by seeking
hypotheses with the highest expected utility.
  In this work, we show that Quality Estimation (QE) reranking, which uses a QE
model as a reranker, can be viewed as a variant of MBR. Inspired by this, we
propose source-based MBR (sMBR) decoding, a novel approach that utilizes
synthetic sources generated by backward translation as ``support hypotheses''
and a reference-free quality estimation metric as the utility function, marking
the first work to solely use sources in MBR decoding. Experiments show that
sMBR significantly outperforms QE reranking and is competitive with standard
MBR decoding. Furthermore, sMBR calls the utility function fewer times compared
to MBR. Our findings suggest that sMBR is a promising approach for high-quality
NMT decoding.

ÊëòË¶ÅÔºöÊúÄÂ§ßÂæåÈ©óËß£Á¢ºÊòØÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÔºàNMTÔºâ‰∏≠Â∏∏Áî®ÁöÑÊñπÊ≥ïÔºåÊó®Âú®ÊúÄÂ§ßÂåñ‰º∞Ë®àÂæåÈ©óÊ©üÁéá„ÄÇ
ÁÑ∂ËÄåÔºåÈ´ò‰º∞Ë®àÊ©üÁéá‰∏¶‰∏çÁ∏ΩÊòØËÉΩÂ∏∂‰æÜÈ´òÁøªË≠ØÂìÅË≥™„ÄÇÊúÄÂ∞èË≤ùÊ∞èÈ¢®Èö™ÔºàMBRÔºâËß£Á¢ºÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊõø‰ª£ÊñπÊ°àÔºåÊñπÊ≥ïÊòØÂ∞ãÊâæÂÖ∑ÊúâÊúÄÈ´òÈ†êÊúüÊïàÁî®ÁöÑÂÅáË®≠„ÄÇ
Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË™™ÊòéÂìÅË≥™Ë©ï‰º∞ÔºàQEÔºâÈáçÊñ∞ÊéíÂ∫èÔºà‰ΩøÁî® QE Ê®°Âûã‰ΩúÁÇ∫ÈáçÊñ∞ÊéíÂ∫èÂô®ÔºâÂèØ‰ª•Ë¶ñÁÇ∫ MBR ÁöÑ‰∏ÄÁ®ÆËÆäÈ´î„ÄÇÂèóÂà∞Ê≠§ÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫Âü∫Êñº‰æÜÊ∫êÁöÑ MBRÔºàsMBRÔºâËß£Á¢ºÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂà©Áî®ÂèçÂêëÁøªË≠ØÁî¢ÁîüÁöÑÂêàÊàê‰æÜÊ∫ê‰ΩúÁÇ∫„ÄåÊîØÊè¥ÂÅáË®≠„ÄçÔºå‰∏¶‰ΩøÁî®ÁÑ°ÂèÉËÄÉÂìÅË≥™Ë©ï‰º∞ÊåáÊ®ô‰ΩúÁÇ∫ÊïàÁî®ÂáΩÊï∏ÔºåÊ®ôÁ§∫Âá∫ÂÉÖÂú® MBR Ëß£Á¢º‰∏≠‰ΩøÁî®‰æÜÊ∫êÁöÑÁ¨¨‰∏ÄÈ†ÖÂ∑•‰Ωú„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåsMBR ÊòéÈ°ØÂÑ™Êñº QE ÈáçÊñ∞ÊéíÂ∫èÔºå‰∏¶‰∏îËàáÊ®ôÊ∫ñ MBR Ëß£Á¢ºÂÖ∑ÊúâÁ´∂Áà≠Âäõ„ÄÇÊ≠§Â§ñÔºåËàá MBR Áõ∏ÊØîÔºåsMBR ÂëºÂè´ÊïàÁî®ÂáΩÊï∏ÁöÑÊ¨°Êï∏ËºÉÂ∞ë„ÄÇÊàëÂÄëÁöÑÁôºÁèæË°®ÊòéÔºåsMBR ÊòØ‰∏ÄÁ®ÆÊúâÊúõÁî®ÊñºÈ´òÂìÅË≥™ NMT Ëß£Á¢ºÁöÑÊñπÊ≥ï„ÄÇ

##### **Can Many-Shot In-Context Learning Help Long-Context LLM Judges? See More, Judge Better!**
2406.11629v1 by Mingyang Song, Mao Zheng, Xuan Luo

Leveraging Large Language Models (LLMs) as judges for evaluating the
performance of LLMs has recently garnered attention. Nonetheless, this type of
approach concurrently introduces potential biases from LLMs, raising concerns
about the reliability of the evaluation results. To mitigate this issue, we
propose and study two versions of many-shot in-context prompts, Reinforced and
Unsupervised ICL, for helping GPT-4o-as-a-Judge in single answer grading. Based
on the designed prompts, we investigate the impact of scaling the number of
in-context examples on the agreement and quality of the evaluation.
Furthermore, we first reveal the symbol bias in GPT-4o-as-a-Judge for pairwise
comparison and then propose a simple yet effective approach to mitigate it.
Experimental results show that advanced long-context LLMs, such as GPT-4o,
perform better in the many-shot regime than in the zero-shot regime. Meanwhile,
the experimental results further verify the effectiveness of the symbol bias
mitigation approach.

ÊëòË¶ÅÔºöÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰Ωú‰∏∫ËØÑÂßîÊù•ËØÑ‰º∞ LLM ÁöÑÊÄßËÉΩÊúÄËøëÂºïËµ∑‰∫ÜÂÖ≥Ê≥®„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåËøôÁßçÁ±ªÂûãÁöÑËØÑ‰º∞ÂêåÊó∂ÂºïÂÖ•‰∫Ü LLM ÁöÑÊΩúÂú®ÂÅèÂ∑ÆÔºåÂºïËµ∑‰∫Ü‰∫∫‰ª¨ÂØπËØÑ‰º∞ÁªìÊûúÂèØÈù†ÊÄßÁöÑÊãÖÂøß„ÄÇ‰∏∫‰∫ÜÁºìËß£Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏§ÁßçÁâàÊú¨ÁöÑÂ§öÈïúÂ§¥‰∏ä‰∏ãÊñáÊèêÁ§∫ÔºåÂº∫ÂåñÂíåÊó†ÁõëÁù£ ICLÔºå‰ª•Â∏ÆÂä© GPT-4o-as-a-Judge ËøõË°åÂçï‰∏ÄÁ≠îÊ°àËØÑÂàÜ„ÄÇÂü∫‰∫éËÆæËÆ°ÁöÑÊèêÁ§∫ÔºåÊàë‰ª¨Á†îÁ©∂‰∫ÜÊâ©Â±ï‰∏ä‰∏ãÊñáÁ§∫‰æãÊï∞ÈáèÂØπËØÑ‰º∞ÁöÑ‰∏ÄËá¥ÊÄßÂíåË¥®ÈáèÁöÑÂΩ±Âìç„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨È¶ñÂÖàÊè≠Á§∫‰∫Ü GPT-4o-as-a-Judge Âú®ÊàêÂØπÊØîËæÉ‰∏≠ÁöÑÁ¨¶Âè∑ÂÅèÂ∑ÆÔºåÁÑ∂ÂêéÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçï‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÊù•ÁºìËß£ÂÆÉ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂÖàËøõÁöÑÈïø‰∏ä‰∏ãÊñá LLMÔºå‰æãÂ¶Ç GPT-4oÔºåÂú®Â§öÈïúÂ§¥Ê®°Âºè‰∏ãÁöÑË°®Áé∞‰ºò‰∫éÈõ∂ÈïúÂ§¥Ê®°Âºè„ÄÇÂêåÊó∂ÔºåÂÆûÈ™åÁªìÊûúËøõ‰∏ÄÊ≠•È™åËØÅ‰∫ÜÁ¨¶Âè∑ÂÅèÂ∑ÆÁºìËß£ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Words in Motion: Representation Engineering for Motion Forecasting**
2406.11624v1 by Omer Sahin Tas, Royden Wagner

Motion forecasting transforms sequences of past movements and environment
context into future motion. Recent methods rely on learned representations,
resulting in hidden states that are difficult to interpret. In this work, we
use natural language to quantize motion features in a human-interpretable way,
and measure the degree to which they are embedded in hidden states. Our
experiments reveal that hidden states of motion sequences are arranged with
respect to our discrete sets of motion features. Following these insights, we
fit control vectors to motion features, which allow for controlling motion
forecasts at inference. Consequently, our method enables controlling
transformer-based motion forecasting models with textual inputs, providing a
unique interface to interact with and understand these models. Our
implementation is available at https://github.com/kit-mrt/future-motion

ÊëòË¶ÅÔºöÂãï‰ΩúÈ†êÊ∏¨Â∞áÈÅéÂéªÂãï‰ΩúÂíåÁí∞Â¢ÉËÉåÊôØÂ∫èÂàóËΩâÊèõÁÇ∫Êú™‰æÜÂãï‰Ωú„ÄÇÊúÄËøëÁöÑÊñπÊ≥ï‰æùË≥¥ÊñºÂ≠∏ÁøíË°®ÂæµÔºåÂ∞éËá¥Èõ£‰ª•Ëß£ÈáãÁöÑÈö±ËóèÁãÄÊÖã„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®Ä‰ª•‰∫∫È°ûÂèØËß£ÈáãÁöÑÊñπÂºèÈáèÂåñÂãï‰ΩúÁâπÂæµÔºå‰∏¶Ë°°ÈáèÂÆÉÂÄëÂµåÂÖ•Èö±ËóèÁãÄÊÖãÁöÑÁ®ãÂ∫¶„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÂãï‰ΩúÂ∫èÂàóÁöÑÈö±ËóèÁãÄÊÖãÊ†πÊìöÊàëÂÄëÈõ¢Êï£ÁöÑÂãï‰ΩúÁâπÂæµÈõÜÈÄ≤Ë°åÊéíÂàó„ÄÇÊ†πÊìöÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÂ∞áÊéßÂà∂ÂêëÈáèÊì¨ÂêàÂà∞Âãï‰ΩúÁâπÂæµÔºåÈÄôÂÖÅË®±Âú®Êé®ÁêÜÊôÇÊéßÂà∂Âãï‰ΩúÈ†êÊ∏¨„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÊñπ‰ΩøÊàëÂÄëËÉΩÂ§†‰ΩøÁî®ÊñáÊú¨Ëº∏ÂÖ•ÊéßÂà∂Âü∫ÊñºËΩâÊèõÂô®ÁöÑÂãï‰ΩúÈ†êÊ∏¨Ê®°ÂûãÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãËàáÈÄô‰∫õÊ®°Âûã‰∫íÂãïÂíåÁêÜËß£ÁöÑÁç®Áâπ‰ªãÈù¢„ÄÇÊàëÂÄëÁöÑÂØ¶‰ΩúÂèØÂú® https://github.com/kit-mrt/future-motion ÂèñÂæó

##### **Building Knowledge-Guided Lexica to Model Cultural Variation**
2406.11622v1 by Shreya Havaldar, Salvatore Giorgi, Sunny Rai, Thomas Talhelm, Sharath Chandra Guntuku, Lyle Ungar

Cultural variation exists between nations (e.g., the United States vs.
China), but also within regions (e.g., California vs. Texas, Los Angeles vs.
San Francisco). Measuring this regional cultural variation can illuminate how
and why people think and behave differently. Historically, it has been
difficult to computationally model cultural variation due to a lack of training
data and scalability constraints. In this work, we introduce a new research
problem for the NLP community: How do we measure variation in cultural
constructs across regions using language? We then provide a scalable solution:
building knowledge-guided lexica to model cultural variation, encouraging
future work at the intersection of NLP and cultural understanding. We also
highlight modern LLMs' failure to measure cultural variation or generate
culturally varied language.

ÊëòË¶ÅÔºöÊñáÂåñÂ∑ÆÁï∞Â≠òÂú®ÊñºÂúãÂÆ∂‰πãÈñìÔºà‰æãÂ¶ÇÁæéÂúãËàá‰∏≠ÂúãÔºâÔºå‰πüÂ≠òÂú®ÊñºÂú∞ÂçÄ‰πãÈñìÔºà‰æãÂ¶ÇÂä†Â∑ûËàáÂæ∑Â∑ûÔºåÊ¥õÊùâÁ£ØËàáËàäÈáëÂ±±Ôºâ„ÄÇË°°ÈáèÈÄôÁ®ÆÂçÄÂüüÊñáÂåñÂ∑ÆÁï∞ÂèØ‰ª•Èó°Êòé‰∫∫ÂÄëÊÄùËÄÉÂíåË°åÁÇ∫ÊñπÂºè‰∏çÂêåÁöÑÂéüÂõ†ÂíåÊñπÂºè„ÄÇÁî±ÊñºÁº∫‰πèË®ìÁ∑¥Êï∏ÊìöÂíåÂèØÊì¥ÂÖÖÊÄßÈôêÂà∂ÔºåÂú®Ê≠∑Âè≤‰∏äÔºåË®àÁÆóÊñáÂåñÂ∑ÆÁï∞‰∏ÄÁõ¥ÂæàÂõ∞Èõ£„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁÇ∫ NLP Á§æÁæ§ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂ÂïèÈ°åÔºöÊàëÂÄëÂ¶Ç‰Ωï‰ΩøÁî®Ë™ûË®Ä‰æÜË°°Èáè‰∏çÂêåÂú∞ÂçÄÊñáÂåñÂª∫ÊßãÁöÑÂ∑ÆÁï∞ÔºüÁÑ∂ÂæåÊàëÂÄëÊèê‰æõ‰∏ÄÂÄãÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°àÔºöÂª∫ÊßãÁü•Ë≠òÂºïÂ∞éÁöÑË©ûÂΩô‰æÜÂª∫Ê®°ÊñáÂåñÂ∑ÆÁï∞ÔºåÈºìÂãµÂú® NLP ÂíåÊñáÂåñÁêÜËß£ÁöÑ‰∫§ÈõÜ‰∏≠ÈÄ≤Ë°åÊú™‰æÜÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄë‰πüÂº∑Ë™øÁèæ‰ª£ LLM ÁÑ°Ê≥ïË°°ÈáèÊñáÂåñÂ∑ÆÁï∞ÊàñÁî¢ÁîüÊñáÂåñÂ§öÊ®£ÂåñÁöÑË™ûË®Ä„ÄÇ

##### **DELLA-Merging: Reducing Interference in Model Merging through Magnitude-Based Sampling**
2406.11617v1 by Pala Tej Deep, Rishabh Bhardwaj, Soujanya Poria

With the proliferation of domain-specific models, model merging has emerged
as a set of techniques that combine the capabilities of multiple models into
one that can multitask without the cost of additional training. In this paper,
we propose a new model merging technique, Drop and rEscaLe via sampLing with
mAgnitude (DELLA-Merging), that employs a novel pruning technique, MAGPRUNE,
which shows significant advantages over DARE and TIES. MAGPRUNE first ranks the
parameters in order of their magnitude and assigns higher dropout probabilities
(p) to parameters with lower ranks corresponding to lower magnitudes. To
approximate the original embeddings, MAGPRUNE employs a rescaling operation on
the parameters that survive the random dropping by 1/(1 - p). On three
different expert models considered for merging (LM, Math, Code) and
corresponding benchmark datasets (AlpacaEval, GSM8K, MBPP), DELLA shows an
average improvement of 2.4 points over baseline methods employing delta
parameter pruning (an improvement of 3.6 points over TIES, 1.2 points over
DARE), and 11.1 points over the no-pruning baseline (TA). We release the source
code at: https://github.com/declare-lab/della.

ÊëòË¶ÅÔºöÈö®ËëóÁâπÂÆöÈ†òÂüüÊ®°ÂûãÁöÑÊøÄÂ¢ûÔºåÊ®°ÂûãÂêà‰ΩµÂ∑≤ÊàêÁÇ∫‰∏ÄÁµÑÊäÄË°ìÔºåÂÆÉÂ∞áÂ§öÂÄãÊ®°ÂûãÁöÑÂäüËÉΩÁµêÂêàÂà∞‰∏ÄÂÄãÊ®°Âûã‰∏≠ÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñË®ìÁ∑¥ÊàêÊú¨Âç≥ÂèØÂü∑Ë°åÂ§ö‰ªªÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊ®°ÂûãÂêà‰ΩµÊäÄË°ìÔºåÂç≥ÈÄöÈÅéÂÖ∑ÊúâÂπÖÂ∫¶ÁöÑÊé°Ê®£ÈÄ≤Ë°åÂà™Èô§ÂíåÁ∏ÆÊîæ (DELLA-Merging)ÔºåÂÆÉÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂâ™ÊûùÊäÄË°ì MAGPRUNEÔºåËàá DARE Âíå TIES Áõ∏ÊØîÔºåÂÆÉÈ°ØÁ§∫Âá∫È°ØËëóÁöÑÂÑ™Âã¢„ÄÇMAGPRUNE È¶ñÂÖàÊåâÂπÖÂ∫¶Â∞çÂèÉÊï∏ÈÄ≤Ë°åÊéíÂ∫èÔºå‰∏¶Â∞áËºÉÈ´òÁöÑ‰∏≠Êñ∑Ê©üÁéá (p) ÂàÜÈÖçÁµ¶ÂπÖÂ∫¶ËºÉ‰Ωé„ÄÅÂ∞çÊáâÊñºËºÉ‰ΩéÂπÖÂ∫¶ÁöÑÂèÉÊï∏„ÄÇÁÇ∫‰∫ÜËøë‰ººÂéüÂßãÂµåÂÖ•ÔºåMAGPRUNE Â∞çÈÄöÈÅé 1/(1 - p) Èö®Ê©üÂà™Èô§ËÄåÂ≠òÊ¥ªÁöÑÂèÉÊï∏Êé°Áî®Á∏ÆÊîæÊìç‰Ωú„ÄÇÂ∞çÊñºÂêà‰ΩµËÄÉÊÖÆÁöÑ‰∏âÂÄã‰∏çÂêåÁöÑÂ∞àÂÆ∂Ê®°Âûã (LM„ÄÅMath„ÄÅCode) ÂíåÂ∞çÊáâÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ (AlpacaEval„ÄÅGSM8K„ÄÅMBPP)ÔºåDELLA È°ØÁ§∫ÊØîÊé°Áî® delta ÂèÉÊï∏Ââ™ÊûùÁöÑÂü∫Êú¨ÊñπÊ≥ïÂπ≥ÂùáÊèêÈ´ò 2.4 ÂàÜÔºàÊØî TIES ÊèêÈ´ò 3.6 ÂàÜÔºåÊØî DARE ÊèêÈ´ò 1.2 ÂàÜÔºâÔºå‰∏¶‰∏îÊØî‰∏çÂâ™ÊûùÁöÑÂü∫Êú¨Á∑ö (TA) È´ò 11.1 ÂàÜ„ÄÇÊàëÂÄëÂú®‰ª•‰∏ã‰ΩçÁΩÆÈáãÂá∫ÂéüÂßãÁ¢ºÔºöhttps://github.com/declare-lab/della„ÄÇ

##### **Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces**
2406.11614v1 by Yihuai Hong, Lei Yu, Shauli Ravfogel, Haiqin Yang, Mor Geva

The task of "unlearning" certain concepts in large language models (LLMs) has
attracted immense attention recently, due to its importance for mitigating
undesirable model behaviours, such as the generation of harmful, private, or
incorrect information. Current protocols to evaluate unlearning methods largely
rely on behavioral tests, without monitoring the presence of unlearned
knowledge within the model's parameters. This residual knowledge can be
adversarially exploited to recover the erased information post-unlearning. We
argue that unlearning should also be evaluated internally, by considering
changes in the parametric knowledge traces of the unlearned concepts. To this
end, we propose a general methodology for eliciting directions in the parameter
space (termed "concept vectors") that encode concrete concepts, and construct
ConceptVectors, a benchmark dataset containing hundreds of common concepts and
their parametric knowledge traces within two open-source LLMs. Evaluation on
ConceptVectors shows that existing unlearning methods minimally impact concept
vectors, while directly ablating these vectors demonstrably removes the
associated knowledge from the LLMs and significantly reduces their
susceptibility to adversarial manipulation. Our results highlight limitations
in behavioral-based unlearning evaluations and call for future work to include
parametric-based evaluations. To support this, we release our code and
benchmark at https://github.com/yihuaihong/ConceptVectors.

ÊëòË¶ÅÔºö„ÄåÂèñÊ∂àÂ≠∏Áøí„ÄçÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠Êüê‰∫õÊ¶ÇÂøµÁöÑ‰ªªÂãôÊúÄËøëÂÇôÂèóÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÈÄôÂ∞çÊñºÊ∏õËºï‰∏çËâØÁöÑÊ®°ÂûãË°åÁÇ∫Ôºà‰æãÂ¶ÇÁî¢ÁîüÊúâÂÆ≥„ÄÅÁßÅ‰∫∫Êàñ‰∏çÊ≠£Á¢∫ÁöÑË≥áË®äÔºâÈùûÂ∏∏ÈáçË¶Å„ÄÇÁõÆÂâçÁî®ÊñºË©ï‰º∞ÂèñÊ∂àÂ≠∏ÁøíÊñπÊ≥ïÁöÑÂçîÂÆö‰∏ªË¶Å‰æùË≥¥Ë°åÁÇ∫Ê∏¨Ë©¶ÔºåËÄå‰∏çÊúÉÁõ£ÊéßÊ®°ÂûãÂèÉÊï∏‰∏≠Êú™Â≠∏ÁøíÁü•Ë≠òÁöÑÂ≠òÂú®„ÄÇÈÄôÁ®ÆÊÆòÁïôÁü•Ë≠òÂèØ‰ª•Ë¢´Â∞çÊâãÂà©Áî®Ôºå‰ª•‰æøÂú®ÂèñÊ∂àÂ≠∏ÁøíÂæåÊÅ¢Âæ©Â∑≤Âà™Èô§ÁöÑË≥áË®ä„ÄÇÊàëÂÄëË™çÁÇ∫ÂèñÊ∂àÂ≠∏Áøí‰πüÊáâË©≤Âú®ÂÖßÈÉ®ÈÄ≤Ë°åË©ï‰º∞ÔºåÊñπÊ≥ïÊòØËÄÉÊÖÆÊú™Â≠∏ÁøíÊ¶ÇÂøµÁöÑÂèÉÊï∏ÂåñÁü•Ë≠òËªåË∑°ÁöÑËÆäÂåñ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈÄöÁî®ÊñπÊ≥ïÔºåÁî®ÊñºÂú®ÂèÉÊï∏Á©∫Èñì‰∏≠ÂºïÂá∫Á∑®Á¢ºÂÖ∑È´îÊ¶ÇÂøµÁöÑÊñπÂêëÔºàÁ®±ÁÇ∫„ÄåÊ¶ÇÂøµÂêëÈáè„ÄçÔºâÔºå‰∏¶Âª∫Êßã ConceptVectorsÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜÔºåÂåÖÂê´Êï∏ÁôæÂÄãÂ∏∏Ë¶ãÊ¶ÇÂøµÂèäÂÖ∂Âú®ÂÖ©ÂÄãÈñãÊ∫ê LLM ‰∏≠ÁöÑÂèÉÊï∏ÂåñÁü•Ë≠òËªåË∑°„ÄÇÂ∞ç ConceptVectors ÁöÑË©ï‰º∞È°ØÁ§∫ÔºåÁèæÊúâÁöÑÂèñÊ∂àÂ≠∏ÁøíÊñπÊ≥ïÂ∞çÊ¶ÇÂøµÂêëÈáèÂΩ±ÈüøÊúÄÂ∞èÔºåËÄåÁõ¥Êé•Ê∂àËûçÈÄô‰∫õÂêëÈáèÂâáÊòéÈ°ØÂæû LLM ‰∏≠ÁßªÈô§‰∫ÜÁõ∏ÈóúÁü•Ë≠òÔºå‰∏¶Â§ßÂπÖÈôç‰Ωé‰∫ÜÂÆÉÂÄëÂ∞çÂ∞çÊâãÊìçÁ∏±ÁöÑÊïèÊÑüÊÄß„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁ™ÅÂá∫‰∫ÜÂü∫ÊñºË°åÁÇ∫ÁöÑÂèñÊ∂àÂ≠∏ÁøíË©ï‰º∞ÁöÑÈôêÂà∂Ôºå‰∏¶ÂëºÁ±≤Êú™‰æÜÁöÑÁ†îÁ©∂Á¥çÂÖ•Âü∫ÊñºÂèÉÊï∏ÁöÑË©ï‰º∞„ÄÇÁÇ∫‰∫ÜÊîØÊåÅÈÄô‰∏ÄÈªûÔºåÊàëÂÄëÂú® https://github.com/yihuaihong/ConceptVectors ‰∏äÈáãÂá∫ÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÂü∫Ê∫ñ„ÄÇ

##### **Long Code Arena: a Set of Benchmarks for Long-Context Code Models**
2406.11612v1 by Egor Bogomolov, Aleksandra Eliseeva, Timur Galimzyanov, Evgeniy Glukhov, Anton Shapkin, Maria Tigina, Yaroslav Golubev, Alexander Kovrigin, Arie van Deursen, Maliheh Izadi, Timofey Bryksin

Nowadays, the fields of code and natural language processing are evolving
rapidly. In particular, models become better at processing long context windows
- supported context sizes have increased by orders of magnitude over the last
few years. However, there is a shortage of benchmarks for code processing that
go beyond a single file of context, while the most popular ones are limited to
a single method. With this work, we aim to close this gap by introducing Long
Code Arena, a suite of six benchmarks for code processing tasks that require
project-wide context. These tasks cover different aspects of code processing:
library-based code generation, CI builds repair, project-level code completion,
commit message generation, bug localization, and module summarization. For each
task, we provide a manually verified dataset for testing, an evaluation suite,
and open-source baseline solutions based on popular LLMs to showcase the usage
of the dataset and to simplify adoption by other researchers. We publish the
benchmark page on HuggingFace Spaces with the leaderboard, links to HuggingFace
Hub for all the datasets, and link to the GitHub repository with baselines:
https://huggingface.co/spaces/JetBrains-Research/long-code-arena.

ÊëòË¶ÅÔºöÂ¶Ç‰ªäÔºå‰ª£Á†ÅÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÈ¢ÜÂüüÊ≠£Âú®Âø´ÈÄüÂèëÂ±ï„ÄÇÂ∞§ÂÖ∂ÊòØÔºåÊ®°ÂûãÂú®Â§ÑÁêÜÈïø‰∏ä‰∏ãÊñáÁ™óÂè£ÊñπÈù¢ÂèòÂæóÊõ¥Â•ΩÔºåÂú®ËøáÂéªÂá†Âπ¥‰∏≠ÔºåÊîØÊåÅÁöÑ‰∏ä‰∏ãÊñáÂ§ßÂ∞èÂ∑≤ÁªèÂ¢ûÂä†‰∫ÜÂá†‰∏™Êï∞ÈáèÁ∫ß„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éË∂ÖÂá∫Âçï‰∏™‰∏ä‰∏ãÊñáÊñá‰ª∂ÁöÑ‰ª£Á†ÅÂ§ÑÁêÜÂü∫ÂáÜÂç¥ÂæàÂåÆ‰πèÔºåËÄåÊúÄÊµÅË°åÁöÑÂü∫ÂáÜ‰ªÖÈôê‰∫éÂçï‰∏™ÊñπÊ≥ï„ÄÇÈÄöËøáËøôÈ°πÂ∑•‰ΩúÔºåÊàë‰ª¨Êó®Âú®ÈÄöËøáÂºïÂÖ• Long Code Arena Êù•Âº•Ë°•Ëøô‰∏ÄÂ∑ÆË∑ùÔºåËøôÊòØ‰∏ÄÂ•óÈíàÂØπÈúÄË¶ÅÈ°πÁõÆËåÉÂõ¥‰∏ä‰∏ãÊñáÁöÑ‰ª£Á†ÅÂ§ÑÁêÜ‰ªªÂä°ÁöÑÂÖ≠‰∏™Âü∫ÂáÜ„ÄÇËøô‰∫õ‰ªªÂä°Ê∂µÁõñ‰∫Ü‰ª£Á†ÅÂ§ÑÁêÜÁöÑ‰∏çÂêåÊñπÈù¢ÔºöÂü∫‰∫éÂ∫ìÁöÑ‰ª£Á†ÅÁîüÊàê„ÄÅCI ÊûÑÂª∫‰øÆÂ§ç„ÄÅÈ°πÁõÆÁ∫ß‰ª£Á†ÅÂÆåÊàê„ÄÅÊèê‰∫§Ê∂àÊÅØÁîüÊàê„ÄÅÈîôËØØÂÆö‰ΩçÂíåÊ®°ÂùóÊëòË¶Å„ÄÇÂØπ‰∫éÊØè‰∏™‰ªªÂä°ÔºåÊàë‰ª¨Êèê‰æõ‰∏Ä‰∏™ÊâãÂä®È™åËØÅÁöÑÊï∞ÊçÆÈõÜÁî®‰∫éÊµãËØï„ÄÅ‰∏Ä‰∏™ËØÑ‰º∞Â•ó‰ª∂ÂíåÂü∫‰∫éÊµÅË°å LLM ÁöÑÂºÄÊ∫êÂü∫Á∫øËß£ÂÜ≥ÊñπÊ°àÔºå‰ª•Â±ïÁ§∫Êï∞ÊçÆÈõÜÁöÑ‰ΩøÁî®Âπ∂ÁÆÄÂåñÂÖ∂‰ªñÁ†îÁ©∂‰∫∫ÂëòÁöÑÈááÁî®„ÄÇÊàë‰ª¨Âú® HuggingFace Spaces ‰∏äÂèëÂ∏ÉÂü∫ÂáÜÈ°µÈù¢ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊéíË°åÊ¶ú„ÄÅÊåáÂêëÊâÄÊúâÊï∞ÊçÆÈõÜÁöÑ HuggingFace Hub ÁöÑÈìæÊé•Ôºå‰ª•ÂèäÊåáÂêëÂ∏¶ÊúâÂü∫Á∫øÁöÑ GitHub Â≠òÂÇ®Â∫ìÁöÑÈìæÊé•Ôºöhttps://huggingface.co/spaces/JetBrains-Research/long-code-arena„ÄÇ

##### **Understanding "Democratization" in NLP and ML Research**
2406.11598v1 by Arjun Subramonian, Vagrant Gautam, Dietrich Klakow, Zeerak Talat

Recent improvements in natural language processing (NLP) and machine learning
(ML) and increased mainstream adoption have led to researchers frequently
discussing the "democratization" of artificial intelligence. In this paper, we
seek to clarify how democratization is understood in NLP and ML publications,
through large-scale mixed-methods analyses of papers using the keyword
"democra*" published in NLP and adjacent venues. We find that democratization
is most frequently used to convey (ease of) access to or use of technologies,
without meaningfully engaging with theories of democratization, while research
using other invocations of "democra*" tends to be grounded in theories of
deliberation and debate. Based on our findings, we call for researchers to
enrich their use of the term democratization with appropriate theory, towards
democratic technologies beyond superficial access.

ÊëòË¶ÅÔºö<paragraph>Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ËøëÊúüÁöÑÈÄ≤Â±ïÔºå‰ª•Âèä‰∏ªÊµÅÊáâÁî®ÁöÑÂ¢ûÂä†ÔºåÂ∑≤Â∞éËá¥Á†îÁ©∂‰∫∫Âì°È†ªÁπÅÂú∞Ë®éË´ñ‰∫∫Â∑•Êô∫ÊÖßÁöÑ„ÄåÊ∞ë‰∏ªÂåñ„Äç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË©¶ÂúñÈáêÊ∏ÖÂú® NLP Âíå ML Âá∫ÁâàÁâ©‰∏≠ÔºåÊ∞ë‰∏ªÂåñÊòØÂ¶Ç‰ΩïË¢´ÁêÜËß£ÁöÑÔºåÈÄèÈÅé‰ΩøÁî®ÈóúÈçµÂ≠ó„Äådemocra*„ÄçÂú® NLP ÂíåÁõ∏ÈóúÈ†òÂüüÁôºË°®ÁöÑË´ñÊñáÈÄ≤Ë°åÂ§ßË¶èÊ®°ÁöÑÊ∑∑ÂêàÊñπÊ≥ïÂàÜÊûê„ÄÇÊàëÂÄëÁôºÁèæÊ∞ë‰∏ªÂåñÊúÄÂ∏∏Ë¢´Áî®‰æÜÂÇ≥ÈÅîÔºàÂÆπÊòìÔºâÂèñÂæóÊàñ‰ΩøÁî®ÊäÄË°ìÔºåËÄåÊ≤íÊúâÊúâÊÑèÁæ©Âú∞Êé¢Ë®éÊ∞ë‰∏ªÂåñÁêÜË´ñÔºåËÄå‰ΩøÁî®ÂÖ∂‰ªñ„Äådemocra*„ÄçÁöÑÂëºÁ±≤ÁöÑÁ†îÁ©∂ÂâáÂÇæÂêëÊñº‰ª•ÂØ©Ë≠∞ÂíåËæØË´ñÁöÑÁêÜË´ñÁÇ∫Âü∫Á§é„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÁôºÁèæÔºåÊàëÂÄëÂëºÁ±≤Á†îÁ©∂‰∫∫Âì°‰ª•ÈÅ©Áï∂ÁöÑÁêÜË´ñË±êÂØå‰ªñÂÄëÂ∞çÊ∞ë‰∏ªÂåñ‰∏ÄË©ûÁöÑ‰ΩøÁî®ÔºåÊúùÂêëË∂ÖË∂äË°®Èù¢ÂèñÂæóÁöÑÊ∞ë‰∏ªÊäÄË°ì„ÄÇ</paragraph>

##### **CoSQA+: Enhancing Code Search Dataset with Matching Code**
2406.11589v1 by Jing Gong, Yanghui Wu, Linxi Liang, Zibin Zheng, Yanlin Wang

Semantic code search, retrieving code that matches a given natural language
query, is an important task to improve productivity in software engineering.
Existing code search datasets are problematic: either using unrealistic
queries, or with mismatched codes, and typically using one-to-one query-code
pairing, which fails to reflect the reality that a query might have multiple
valid code matches. This paper introduces CoSQA+, pairing high-quality queries
(reused from CoSQA) with multiple suitable codes. We collect code candidates
from diverse sources and form candidate pairs by pairing queries with these
codes. Utilizing the power of large language models (LLMs), we automate pair
annotation, filtering, and code generation for queries without suitable
matches. Through extensive experiments, CoSQA+ has demonstrated superior
quality over CoSQA. Models trained on CoSQA+ exhibit improved performance.
Furthermore, we propose a new metric Mean Multi-choice Reciprocal Rank (MMRR),
to assess one-to-N code search performance. We provide the code and data at
https://github.com/DeepSoftwareAnalytics/CoSQA_Plus.

ÊëòË¶ÅÔºöË™ûÊÑèÁ®ãÂºèÁ¢ºÊêúÂ∞ãÔºåÊì∑ÂèñËàáÁµ¶ÂÆöÁöÑËá™ÁÑ∂Ë™ûË®ÄÊü•Ë©¢Áõ∏Á¨¶ÁöÑÁ®ãÂºèÁ¢ºÔºåÊòØÊèêÂçáËªüÈ´îÂ∑•Á®ãÁîüÁî¢ÂäõÁöÑÈáçË¶Å‰ªªÂãô„ÄÇ
ÁèæÊúâÁöÑÁ®ãÂºèÁ¢ºÊêúÂ∞ãË≥áÊñôÈõÜÂ≠òÂú®ÂïèÈ°åÔºö‰∏çÊòØ‰ΩøÁî®‰∏çÂàáÂØ¶ÈöõÁöÑÊü•Ë©¢ÔºåÂ∞±ÊòØÁ®ãÂºèÁ¢º‰∏çÂåπÈÖçÔºåËÄå‰∏îÈÄöÂ∏∏‰ΩøÁî®‰∏ÄÂ∞ç‰∏ÄÁöÑÊü•Ë©¢Á®ãÂºèÁ¢ºÈÖçÂ∞çÔºåÁÑ°Ê≥ïÂèçÊò†Êü•Ë©¢ÂèØËÉΩÊúâÂ§öÂÄãÊúâÊïàÁ®ãÂºèÁ¢ºÈÖçÂ∞çÁöÑÁèæÂØ¶„ÄÇÊú¨Êñá‰ªãÁ¥π CoSQA+ÔºåÂ∞áÈ´òÂìÅË≥™Êü•Ë©¢ÔºàÈáçÊñ∞‰ΩøÁî®Ëá™ CoSQAÔºâËàáÂ§öÂÄãÂêàÈÅ©ÁöÑÁ®ãÂºèÁ¢ºÈÖçÂ∞ç„ÄÇÊàëÂÄëÂæû‰∏çÂêåÁöÑ‰æÜÊ∫êÊî∂ÈõÜÁ®ãÂºèÁ¢ºÂÄôÈÅ∏È†ÖÔºå‰∏¶ÈÄèÈÅéÂ∞áÊü•Ë©¢ËàáÈÄô‰∫õÁ®ãÂºèÁ¢ºÈÖçÂ∞ç‰æÜÂΩ¢ÊàêÂÄôÈÅ∏ÈÖçÂ∞ç„ÄÇÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂäüËÉΩÔºåÊàëÂÄëËá™ÂãïÂü∑Ë°åÈÖçÂ∞çË®ªËß£„ÄÅÁØ©ÈÅ∏Ôºå‰ª•ÂèäÁÇ∫Ê≤íÊúâÂêàÈÅ©ÈÖçÂ∞çÁöÑÊü•Ë©¢Áî¢ÁîüÁ®ãÂºèÁ¢º„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåCoSQA+ Â∑≤Ë≠âÊòéÂÖ∂ÂìÅË≥™ÂÑ™Êñº CoSQA„ÄÇÂú® CoSQA+ ‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãË°®ÁèæÂá∫Êõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊåáÊ®ôÂπ≥ÂùáÂ§öÈÅ∏ÂÄíÊï∏ÊéíÂêç (MMRR)ÔºåÁî®ÊñºË©ï‰º∞‰∏ÄÂ∞çÂ§öÁ®ãÂºèÁ¢ºÊêúÂ∞ãÊïàËÉΩ„ÄÇÊàëÂÄëÂú® https://github.com/DeepSoftwareAnalytics/CoSQA_Plus Êèê‰æõÁ®ãÂºèÁ¢ºÂíåË≥áÊñô„ÄÇ

##### **Style Transfer with Multi-iteration Preference Optimization**
2406.11581v1 by Shuai Liu, Jonathan May

Numerous recent techniques for text style transfer characterize their
approaches as variants of reinforcement learning and preference optimization.
In this work, we consider the relationship between these approaches and a class
of optimization approaches developed primarily for (non-neural) statistical
machine translation, formerly known as 'tuning'. Inspired by these techniques
from the past, we improve upon established preference optimization approaches,
incorporating multiple iterations of exploration and optimization, and choosing
contrastive examples by following a 'hope' vs 'fear' sampling strategy.
Cognizant of the difference between machine translation and style transfer,
however, we further tailor our framework with a new pseudo-parallel generation
method and a dynamic weighted reward aggregation method to tackle the lack of
parallel data and the need for a multi-objective reward. We evaluate our model
on two commonly used text style transfer datasets. Through automatic and human
evaluation results we show the effectiveness and the superiority of our model
compared to state-of-the-art baselines.

ÊëòË¶ÅÔºöÊúÄËøëË®±Â§öÊñáÊú¨Ê®£ÂºèËΩâÁßªÊäÄË°ìÂ∞áÂÖ∂ÊñπÊ≥ïÊèèËø∞ÁÇ∫Âº∑ÂåñÂ≠∏ÁøíÂíåÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÁöÑËÆäÈ´î„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëËÄÉÊÖÆÈÄô‰∫õÊñπÊ≥ïËàá‰∏ªË¶ÅÁÇ∫ÔºàÈùûÁ•ûÁ∂ìÔºâÁµ±Ë®àÊ©üÂô®ÁøªË≠ØÈñãÁôºÁöÑ‰∏ÄÈ°ûÊúÄ‰Ω≥ÂåñÊñπÊ≥ï‰πãÈñìÁöÑÈóú‰øÇÔºå‰ª•ÂâçÁ®±ÁÇ∫„ÄåË™øÊï¥„Äç„ÄÇÂèóÂà∞ÈÅéÂéªÈÄô‰∫õÊäÄË°ìÁöÑÂïüÁôºÔºåÊàëÂÄëÊîπÈÄ≤Êó¢ÊúâÁöÑÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÔºåÁ¥çÂÖ•Â§öÈáçÊé¢Á¥¢ÂíåÊúÄ‰Ω≥ÂåñÁöÑÂèçË¶ÜÈÅãÁÆóÔºå‰∏¶ÈÅµÂæ™„ÄåÂ∏åÊúõ„ÄçËàá„ÄåÊÅêÊáº„ÄçÂèñÊ®£Á≠ñÁï•‰æÜÈÅ∏ÊìáÂ∞çÊØîÁØÑ‰æã„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëË™çÁü•Âà∞Ê©üÂô®ÁøªË≠ØËàáÊ®£ÂºèËΩâÁßª‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºåÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÊñ∞ÁöÑÂÅΩÂπ≥Ë°åÁî¢ÁîüÊñπÊ≥ïÂíåÂãïÊÖãÂä†Ê¨äÂõûÈ•ãÂΩôÁ∏ΩÊñπÊ≥ïË™øÊï¥ÊàëÂÄëÁöÑÊû∂ÊßãÔºå‰ª•Ëß£Ê±∫Áº∫‰πèÂπ≥Ë°åË≥áÊñôÂíåÈúÄË¶ÅÂ§öÁõÆÊ®ôÂõûÈ•ãÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÂ∏∏Áî®ÁöÑÊñáÊú¨Ê®£ÂºèËΩâÁßªË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÈÄèÈÅéËá™ÂãïÂíå‰∫∫Â∑•Ë©ï‰º∞ÁµêÊûúÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÁöÑÊúâÊïàÊÄßÂíåÂÑ™Ë∂äÊÄß„ÄÇ

##### **Error Span Annotation: A Balanced Approach for Human Evaluation of Machine Translation**
2406.11580v1 by Tom Kocmi, Vil√©m Zouhar, Eleftherios Avramidis, Roman Grundkiewicz, Marzena Karpinska, Maja Popoviƒá, Mrinmaya Sachan, Mariya Shmatova

High-quality Machine Translation (MT) evaluation relies heavily on human
judgments. Comprehensive error classification methods, such as Multidimensional
Quality Metrics (MQM), are expensive as they are time-consuming and can only be
done by experts, whose availability may be limited especially for low-resource
languages. On the other hand, just assigning overall scores, like Direct
Assessment (DA), is simpler and faster and can be done by translators of any
level, but are less reliable. In this paper, we introduce Error Span Annotation
(ESA), a human evaluation protocol which combines the continuous rating of DA
with the high-level error severity span marking of MQM. We validate ESA by
comparing it to MQM and DA for 12 MT systems and one human reference
translation (English to German) from WMT23. The results show that ESA offers
faster and cheaper annotations than MQM at the same quality level, without the
requirement of expensive MQM experts.

ÊëòË¶ÅÔºöÈ´òÂìÅË≥™Ê©üÂô®ÁøªË≠Ø (MT) Ë©ïÈáèÈ´òÂ∫¶‰æùË≥¥Êñº‰∫∫È°ûÁöÑÂà§Êñ∑„ÄÇÂÖ®Èù¢ÁöÑÈåØË™§ÂàÜÈ°ûÊñπÊ≥ïÔºà‰æãÂ¶ÇÂ§öÁ∂≠Â∫¶ÂìÅË≥™ÊåáÊ®ô (MQM)ÔºâÊàêÊú¨È´òÊòÇÔºåÂõ†ÁÇ∫ÂÆÉÂÄëËÄóÊôÇ‰∏îÂè™ËÉΩÁî±Â∞àÂÆ∂Âü∑Ë°åÔºåËÄåÂ∞àÂÆ∂ÁöÑÂèØÁî®ÊÄßÂèØËÉΩÊúâÈôêÔºåÁâπÂà•ÊòØÂ∞çÊñº‰ΩéË≥áÊ∫êË™ûË®Ä„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂÉÖÊåáÂÆöÊï¥È´îÂàÜÊï∏Ôºà‰æãÂ¶ÇÁõ¥Êé•Ë©ïÈáè (DA)ÔºâËºÉÁÇ∫Á∞°ÂñÆ‰∏îÂø´ÈÄüÔºå‰∏îÂèØÁî±‰ªª‰ΩïÂ±§Á¥öÁöÑÁøªË≠Ø‰∫∫Âì°Âü∑Ë°åÔºå‰ΩÜÂèØÈù†ÊÄßËºÉ‰Ωé„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥πÈåØË™§ÁØÑÂúçÊ®ôË®ª (ESA)ÔºåÈÄôÊòØ‰∏ÄÁ®Æ‰∫∫È°ûË©ïÈáèÂçîÂÆöÔºåÁµêÂêà DA ÁöÑÈÄ£Á∫åË©ïÂàÜËàá MQM ÁöÑÈ´òÂ±§Á¥öÈåØË™§Âö¥ÈáçÊÄßÁØÑÂúçÊ®ôË®ò„ÄÇÊàëÂÄëÈÄèÈÅéÊØîËºÉ ESA Ëàá MQM Âíå DA Â∞ç 12 ÂÄãÊ©üÂô®ÁøªË≠ØÁ≥ªÁµ±Âíå‰∏ÄÂÄã‰∫∫È°ûÂèÉËÄÉÁøªË≠ØÔºàËã±Ë≠ØÂæ∑ÔºâÂæû WMT23 È©óË≠â ESA„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåESA Êèê‰æõÊØî MQM Êõ¥Âø´ÈÄü‰∏îÊõ¥‰æøÂÆúÁöÑÊ®ôË®ªÔºåÂìÅË≥™Ê∞¥Ê∫ñÁõ∏ÂêåÔºå‰∏î‰∏çÈúÄË¶ÅÊòÇË≤¥ÁöÑ MQM Â∞àÂÆ∂„ÄÇ

##### **Mathematical Entities: Corpora and Benchmarks**
2406.11577v1 by Jacob Collard, Valeria de Paiva, Eswaran Subrahmanian

Mathematics is a highly specialized domain with its own unique set of
challenges. Despite this, there has been relatively little research on natural
language processing for mathematical texts, and there are few mathematical
language resources aimed at NLP. In this paper, we aim to provide annotated
corpora that can be used to study the language of mathematics in different
contexts, ranging from fundamental concepts found in textbooks to advanced
research mathematics. We preprocess the corpora with a neural parsing model and
some manual intervention to provide part-of-speech tags, lemmas, and dependency
trees. In total, we provide 182397 sentences across three corpora. We then aim
to test and evaluate several noteworthy natural language processing models
using these corpora, to show how well they can adapt to the domain of
mathematics and provide useful tools for exploring mathematical language. We
evaluate several neural and symbolic models against benchmarks that we extract
from the corpus metadata to show that terminology extraction and definition
extraction do not easily generalize to mathematics, and that additional work is
needed to achieve good performance on these metrics. Finally, we provide a
learning assistant that grants access to the content of these corpora in a
context-sensitive manner, utilizing text search and entity linking. Though our
corpora and benchmarks provide useful metrics for evaluating mathematical
language processing, further work is necessary to adapt models to mathematics
in order to provide more effective learning assistants and apply NLP methods to
different mathematical domains.

ÊëòË¶ÅÔºöÊï∏Â≠∏ÊòØ‰∏ÄÂÄãÈ´òÂ∫¶Â∞àÊ•≠ÁöÑÈ†òÂüüÔºåÊúâÂÖ∂Áç®ÁâπÁöÑ‰∏ÄÁµÑÊåëÊà∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈáùÂ∞çÊï∏Â≠∏ÊñáÊú¨ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÁ†îÁ©∂Áõ∏Â∞çËºÉÂ∞ëÔºåËÄå‰∏îÈáùÂ∞ç NLP ÁöÑÊï∏Â≠∏Ë™ûË®ÄË≥áÊ∫ê‰πüÂæàÂ∞ë„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊó®Âú®Êèê‰æõË®ªËß£Ë™ûÊñôÂ∫´ÔºåÂèØÁî®‰∫éÁ†îÁ©∂‰∏çÂêåËÑàÁµ°‰∏≠ÁöÑÊï∏Â≠∏Ë™ûË®ÄÔºåÂæûÊïôÁßëÊõ∏‰∏≠ÁôºÁèæÁöÑÂü∫Êú¨Ê¶ÇÂøµÂà∞ÂÖàÈÄ≤ÁöÑÁ†îÁ©∂Êï∏Â≠∏„ÄÇÊàëÂÄë‰ΩøÁî®Á•ûÁ∂ìÂè•Ê≥ïÂàÜÊûêÊ®°ÂûãÂíå‰∏Ä‰∫õÊâãÂãïÂπ≤È†êÂ∞çË™ûÊñôÂ∫´ÈÄ≤Ë°åÈ†êËôïÁêÜÔºå‰ª•Êèê‰æõË©ûÊÄßÊ®ôË®ò„ÄÅË©ûÂππÂíå‰æùË≥¥Ê®π„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÂú®‰∏âÂÄãË™ûÊñôÂ∫´‰∏≠Êèê‰æõ‰∫Ü 182397 ÂÄãÂè•Â≠ê„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊó®Âú®‰ΩøÁî®ÈÄô‰∫õË™ûÊñôÂ∫´Ê∏¨Ë©¶ÂíåË©ï‰º∞ÂπæÂÄãÂÄºÂæóÊ≥®ÊÑèÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊ®°ÂûãÔºå‰ª•Â±ïÁ§∫ÂÆÉÂÄëÂ¶Ç‰ΩïÈÅ©ÊáâÊï∏Â≠∏È†òÂüü‰∏¶Êèê‰æõÊé¢Á¥¢Êï∏Â≠∏Ë™ûË®ÄÁöÑÊúâÁî®Â∑•ÂÖ∑„ÄÇÊàëÂÄëÊ†πÊìöÂæûË™ûÊñôÂ∫´ÂÖÉÊï∏Êìö‰∏≠ÊèêÂèñÁöÑÂü∫Ê∫ñË©ï‰º∞‰∫ÜÂπæÂÄãÁ•ûÁ∂ìÂíåÁ¨¶ËôüÊ®°ÂûãÔºå‰ª•Ë°®ÊòéË°ìË™ûÊèêÂèñÂíåÂÆöÁæ©ÊèêÂèñ‰∏çÊòìÊñºÊé®Âª£Âà∞Êï∏Â≠∏Ôºå‰∏¶‰∏îÈúÄË¶ÅÈ°çÂ§ñÁöÑÁ†îÁ©∂ÊâçËÉΩÂú®ÈÄô‰∫õÊåáÊ®ô‰∏äÂèñÂæóËâØÂ•ΩÁöÑË°®Áèæ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂ≠∏ÁøíÂä©ÁêÜÔºåÂÆÉ‰ª•‰∏ä‰∏ãÊñáÊïèÊÑüÁöÑÊñπÂºèÊéà‰∫àË®™ÂïèÈÄô‰∫õË™ûÊñôÂ∫´ÂÖßÂÆπÁöÑÊ¨äÈôêÔºåÂà©Áî®ÊñáÊú¨ÊêúÁ¥¢ÂíåÂØ¶È´îÈÄ£Áµê„ÄÇÂÑòÁÆ°ÊàëÂÄëÁöÑË™ûÊñôÂ∫´ÂíåÂü∫Ê∫ñÁÇ∫Ë©ï‰º∞Êï∏Â≠∏Ë™ûË®ÄËôïÁêÜÊèê‰æõ‰∫ÜÊúâÁî®ÁöÑÊåáÊ®ôÔºå‰ΩÜÈÅ©ÊáâÊ®°Âûã‰ª•ÈÅ©ÊáâÊï∏Â≠∏‰ª•Êèê‰æõÊõ¥ÊúâÊïàÁöÑÂ≠∏ÁøíÂä©ÁêÜ‰∏¶Â∞á NLP ÊñπÊ≥ïÊáâÁî®Êñº‰∏çÂêåÁöÑÊï∏Â≠∏È†òÂüü‰ªçÁÑ∂ÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂„ÄÇ

##### **Towards an End-to-End Framework for Invasive Brain Signal Decoding with Large Language Models**
2406.11568v1 by Sheng Feng, Heyang Liu, Yu Wang, Yanfeng Wang

In this paper, we introduce a groundbreaking end-to-end (E2E) framework for
decoding invasive brain signals, marking a significant advancement in the field
of speech neuroprosthesis. Our methodology leverages the comprehensive
reasoning abilities of large language models (LLMs) to facilitate direct
decoding. By fully integrating LLMs, we achieve results comparable to the
state-of-the-art cascade models. Our findings underscore the immense potential
of E2E frameworks in speech neuroprosthesis, particularly as the technology
behind brain-computer interfaces (BCIs) and the availability of relevant
datasets continue to evolve. This work not only showcases the efficacy of
combining LLMs with E2E decoding for enhancing speech neuroprosthesis but also
sets a new direction for future research in BCI applications, underscoring the
impact of LLMs in decoding complex neural signals for communication
restoration. Code will be made available at
https://github.com/FsFrancis15/BrainLLM.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁ™ÅÁ†¥ÊÄßÁöÑÁ´ØÂà∞Á´Ø (E2E) Ê°ÜÊû∂ÔºåÁî®ÊñºËß£Á¢º‰æµÂÖ•ÊÄßËÖ¶‰ø°ËôüÔºåÊ®ôË™åËëóË™ûÈü≥Á•ûÁ∂ìÂÅáÈ´îÈ†òÂüüÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂÖ®Èù¢Êé®ÁêÜËÉΩÂäõÔºå‰ª•‰øÉÈÄ≤Áõ¥Êé•Ëß£Á¢º„ÄÇÈÄöÈÅéÂÆåÂÖ®Êï¥Âêà LLMÔºåÊàëÂÄëÂèñÂæó‰∫ÜËàáÊúÄÂÖàÈÄ≤ÁöÑ‰∏≤ËÅØÊ®°ÂûãÁõ∏Áï∂ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫Ü E2E Ê°ÜÊû∂Âú®Ë™ûÈü≥Á•ûÁ∂ìÂÅáÈ´î‰∏≠ÁöÑÂ∑®Â§ßÊΩõÂäõÔºåÁâπÂà•ÊòØÈö®ËëóËÖ¶Ê©ü‰ªãÈù¢ (BCI) ÊäÄË°ìÂíåÁõ∏ÈóúË≥áÊñôÈõÜÂèØÁî®ÊÄßÁöÑÊåÅÁ∫åÁôºÂ±ï„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰∏çÂÉÖÂ±ïÁ§∫‰∫ÜÂ∞á LLM Ëàá E2E Ëß£Á¢ºÁõ∏ÁµêÂêà‰ª•Â¢ûÂº∑Ë™ûÈü≥Á•ûÁ∂ìÂÅáÈ´îÁöÑÂäüÊïàÔºåËÄå‰∏î‰πüÁÇ∫ BCI ÊáâÁî®‰∏≠ÁöÑÊú™‰æÜÁ†îÁ©∂Ë®≠ÂÆö‰∫Ü‰∏ÄÂÄãÊñ∞ÊñπÂêëÔºåÂº∑Ë™ø‰∫Ü LLM Âú®Ëß£Á¢ºË§áÈõúÁ•ûÁ∂ì‰ø°Ëôü‰ª•ÊÅ¢Âæ©Ê∫ùÈÄöÊñπÈù¢ÁöÑÂΩ±ÈüøÂäõ„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÂú® https://github.com/FsFrancis15/BrainLLM ‰∏äÊèê‰æõ„ÄÇ

##### **Quaternion Generative Adversarial Neural Networks and Applications to Color Image Inpainting**
2406.11567v1 by Duan Wang, Dandan Zhu, Meixiang Zhao, Zhigang Jia

Color image inpainting is a challenging task in imaging science. The existing
method is based on real operation, and the red, green and blue channels of the
color image are processed separately, ignoring the correlation between each
channel. In order to make full use of the correlation between each channel,
this paper proposes a Quaternion Generative Adversarial Neural Network (QGAN)
model and related theory, and applies it to solve the problem of color image
inpainting with large area missing. Firstly, the definition of quaternion
deconvolution is given and the quaternion batch normalization is proposed.
Secondly, the above two innovative modules are applied to generate adversarial
networks to improve stability. Finally, QGAN is applied to color image
inpainting and compared with other state-of-the-art algorithms. The
experimental results show that QGAN has superiority in color image inpainting
with large area missing.

ÊëòË¶ÅÔºöÂΩ©Ëâ≤ÂΩ±ÂÉè‰øÆÂæ©Âú®ÂΩ±ÂÉèÁßëÂ≠∏‰∏≠ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïÂü∫ÊñºÂØ¶Êï∏ÈÅãÁÆóÔºå‰∏¶‰∏îÂàÜÂà•ËôïÁêÜÂΩ©Ëâ≤ÂΩ±ÂÉèÁöÑÁ¥Ö„ÄÅÁ∂†„ÄÅËóçÈÄöÈÅìÔºåÂøΩÁï•ÂêÑÈÄöÈÅì‰πãÈñìÁöÑÈóúËÅØÊÄß„ÄÇÁÇ∫‰∫ÜÂÖÖÂàÜÂà©Áî®ÂêÑÈÄöÈÅì‰πãÈñìÁöÑÈóúËÅØÊÄßÔºåÊú¨ÊñáÊèêÂá∫ÂõõÂÖÉÊï∏ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (QGAN) Ê®°ÂûãÂèäÁõ∏ÈóúÁêÜË´ñÔºå‰∏¶ÊáâÁî®ÊñºËß£Ê±∫Â§ßÈù¢Á©çÁº∫Â§±ÁöÑÂΩ©Ëâ≤ÂΩ±ÂÉè‰øÆÂæ©ÂïèÈ°å„ÄÇÈ¶ñÂÖàÔºåÁµ¶Âá∫ÂõõÂÖÉÊï∏ÂèçÊë∫Á©çÁöÑÂÆöÁæ©Ôºå‰∏¶ÊèêÂá∫ÂõõÂÖÉÊï∏ÊâπÊ¨°Ê≠£Ë¶èÂåñ„ÄÇÂÖ∂Ê¨°ÔºåÂ∞á‰∏äËø∞ÂÖ©ÂÄãÂâµÊñ∞ÁöÑÊ®°ÁµÑÊáâÁî®ÊñºÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑ØÔºå‰ª•ÊèêÂçáÁ©©ÂÆöÊÄß„ÄÇÊúÄÂæåÔºåÂ∞á QGAN ÊáâÁî®ÊñºÂΩ©Ëâ≤ÂΩ±ÂÉè‰øÆÂæ©Ôºå‰∏¶ËàáÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÊºîÁÆóÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåQGAN Âú®Â§ßÈù¢Á©çÁº∫Â§±ÁöÑÂΩ©Ëâ≤ÂΩ±ÂÉè‰øÆÂæ©‰∏≠ÂÖ∑ÊúâÂÑ™Ë∂äÊÄß„ÄÇ

##### **MEMLA: Enhancing Multilingual Knowledge Editing with Neuron-Masked Low-Rank Adaptation**
2406.11566v1 by Jiakuan Xie, Pengfei Cao, Yuheng Chen, Yubo Chen, Kang Liu, Jun Zhao

Knowledge editing aims to adjust the knowledge within large language models
(LLMs) to prevent their responses from becoming obsolete or inaccurate.
However, existing works on knowledge editing are primarily conducted in a
single language, which is inadequate for multilingual language models. In this
paper, we focus on multilingual knowledge editing (MKE), which requires
propagating updates across multiple languages. This necessity poses a
significant challenge for the task. Furthermore, the limited availability of a
comprehensive dataset for MKE exacerbates this challenge, hindering progress in
this area. Hence, we introduce the Multilingual Knowledge Editing Benchmark
(MKEB), a novel dataset comprising 12 languages and providing a complete
evaluation framework. Additionally, we propose a method that enhances
Multilingual knowledge Editing with neuron-Masked Low-Rank Adaptation (MEMLA).
Specifically, we identify two categories of knowledge neurons to improve
editing precision. Moreover, we perform LoRA-based editing with neuron masks to
efficiently modify parameters and facilitate the propagation of updates across
multiple languages. Experiments demonstrate that our method outperforms
existing baselines and significantly enhances the multi-hop reasoning
capability of the edited model, with minimal impact on its downstream task
performance. The dataset and code will be made publicly available.

ÊëòË¶ÅÔºöÁü•Ë≠òÁ∑®ËºØÊó®Âú®Ë™øÊï¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÁü•Ë≠òÔºå‰ª•Èò≤Ê≠¢ÂÖ∂ÂõûÊáâÈÅéÊôÇÊàñ‰∏çÊ∫ñÁ¢∫„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁü•Ë≠òÁ∑®ËºØÂ∑•‰Ωú‰∏ªË¶Å‰ª•ÂñÆ‰∏ÄË™ûË®ÄÈÄ≤Ë°åÔºåÈÄôÂ∞çÊñºÂ§öË™ûË®ÄË™ûË®ÄÊ®°Âûã‰æÜË™™ÊòØ‰∏çÂ§†ÁöÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂ§öË™ûË®ÄÁü•Ë≠òÁ∑®ËºØ (MKE)ÔºåÈÄôÈúÄË¶ÅË∑®Â§öÁ®ÆË™ûË®ÄÂÇ≥Êí≠Êõ¥Êñ∞„ÄÇÈÄôÁ®ÆÂøÖË¶ÅÊÄßÂ∞çÈÄôÈ†Ö‰ªªÂãôÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåÁ∂úÂêà MKE Êï∏ÊìöÈõÜÁöÑÂèØÁî®ÊÄßÊúâÈôêÔºåÂä†Âäá‰∫ÜÈÄô‰∏ÄÊåëÊà∞ÔºåÈòªÁ§ô‰∫ÜË©≤È†òÂüüÁöÑÈÄ≤Â±ï„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂ§öË™ûË®ÄÁü•Ë≠òÁ∑®ËºØÂü∫Ê∫ñ (MKEB)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´ 12 Á®ÆË™ûË®ÄÁöÑÊñ∞Á©éÊï∏ÊìöÈõÜÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂÆåÊï¥ÁöÑË©ï‰º∞Ê°ÜÊû∂„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Á•ûÁ∂ìÂÖÉÊé©Á¢º‰ΩéÁß©ÈÅ©Êáâ (MEMLA) Â¢ûÂº∑‰∫ÜÂ§öË™ûË®ÄÁü•Ë≠òÁ∑®ËºØ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË≠òÂà•Âá∫ÂÖ©È°ûÁü•Ë≠òÁ•ûÁ∂ìÂÖÉ‰ª•ÊèêÈ´òÁ∑®ËºØÁ≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ΩøÁî®Á•ûÁ∂ìÂÖÉÊé©Á¢ºÂü∑Ë°åÂü∫Êñº LoRA ÁöÑÁ∑®ËºØÔºå‰ª•ÊúâÊïà‰øÆÊîπÂèÉÊï∏‰∏¶‰øÉÈÄ≤Ë∑®Â§öÁ®ÆË™ûË®ÄÁöÑÊõ¥Êñ∞ÂÇ≥Êí≠„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Ê∫ñÔºå‰∏¶È°ØËëóÂ¢ûÂº∑‰∫ÜÂ∑≤Á∑®ËºØÊ®°ÂûãÁöÑÂ§öË∑≥Êé®ÁêÜËÉΩÂäõÔºåÂêåÊôÇÂ∞çÂÖ∂‰∏ãÊ∏∏‰ªªÂãôÊÄßËÉΩÁöÑÂΩ±ÈüøÂæàÂ∞è„ÄÇË©≤Êï∏ÊìöÈõÜÂíå‰ª£Á¢ºÂ∞áÂÖ¨ÈñãÁôºÂ∏É„ÄÇ

##### **Extrinsic Evaluation of Cultural Competence in Large Language Models**
2406.11565v1 by Shaily Bhatt, Fernando Diaz

Productive interactions between diverse users and language technologies
require outputs from the latter to be culturally relevant and sensitive. Prior
works have evaluated models' knowledge of cultural norms, values, and
artifacts, without considering how this knowledge manifests in downstream
applications. In this work, we focus on extrinsic evaluation of cultural
competence in two text generation tasks, open-ended question answering and
story generation. We quantitatively and qualitatively evaluate model outputs
when an explicit cue of culture, specifically nationality, is perturbed in the
prompts. Although we find that model outputs do vary when varying nationalities
and feature culturally relevant words, we also find weak correlations between
text similarity of outputs for different countries and the cultural values of
these countries. Finally, we discuss important considerations in designing
comprehensive evaluation of cultural competence in user-facing tasks.

ÊëòË¶ÅÔºöÁîüÁî¢ÊÄßÁöÑ‰∫íÂãïÔºåÂ≠òÂú®ÊñºÂ§öÂÖÉÁöÑ‰ΩøÁî®ËÄÖÂíåË™ûË®ÄÁßëÊäÄ‰πãÈñìÔºåÈúÄË¶ÅÂæåËÄÖÁöÑËº∏Âá∫Âú®ÊñáÂåñ‰∏äÁõ∏Èóú‰∏îÊïèÊÑü„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤Á∂ìË©ï‰º∞‰∫ÜÊ®°ÂûãÂ∞çÊñáÂåñË¶èÁØÑ„ÄÅÂÉπÂÄºËßÄÂíå‰∫∫Â∑•Ë£ΩÂìÅÁöÑÁü•Ë≠òÔºåËÄåÊ≤íÊúâËÄÉÊÖÆÂà∞ÈÄô‰∫õÁü•Ë≠òÂ¶Ç‰ΩïË°®ÁèæÂú®‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºè‰∏≠„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÊñáÂåñËÉΩÂäõÁöÑÂ§ñÈÉ®Ë©ï‰º∞ÔºåÂú®ÂÖ©ÂÄãÊñáÊú¨ÁîüÊàê‰ªªÂãô‰∏≠ÔºåÈñãÊîæÂºèÂïèÁ≠îÂíåÊïÖ‰∫ãÁîüÊàê„ÄÇÊàëÂÄëÂú®ÊèêÁ§∫‰∏≠ÊìæÂãï‰∫ÜÊñáÂåñÁöÑÊòéÁ¢∫Á∑öÁ¥¢ÔºåÁâπÂà•ÊòØÂúãÁ±çÔºå‰∏¶Â∞çÊ®°ÂûãËº∏Âá∫ÈÄ≤Ë°åÈáèÂåñÂíåË≥™ÂåñË©ï‰º∞„ÄÇÂÑòÁÆ°ÊàëÂÄëÁôºÁèæÔºåÁï∂ÂúãÁ±ç‰∏çÂêå‰∏îÂÖ∑ÊúâÊñáÂåñÁõ∏ÈóúË©ûÂΩôÊôÇÔºåÊ®°ÂûãËº∏Âá∫Á¢∫ÂØ¶ÊúÉÊúâÊâÄ‰∏çÂêåÔºå‰ΩÜÊàëÂÄë‰πüÁôºÁèæ‰∏çÂêåÂúãÂÆ∂ÁöÑËº∏Âá∫ÊñáÊú¨Áõ∏‰ººÂ∫¶ËàáÈÄô‰∫õÂúãÂÆ∂ÁöÑÊñáÂåñÂÉπÂÄºËßÄ‰πãÈñìÁöÑÁõ∏ÈóúÊÄßËºÉÂº±„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÂú®‰ΩøÁî®ËÄÖÈù¢Â∞çÁöÑ‰ªªÂãô‰∏≠Ë®≠Ë®àÊñáÂåñËÉΩÂäõÂÖ®Èù¢Ë©ï‰º∞ÊôÇÁöÑÈáçË¶ÅËÄÉÈáèÂõ†Á¥†„ÄÇ

##### **Input Conditioned Graph Generation for Language Agents**
2406.11555v1 by Lukas Vierling, Jie Fu, Kai Chen

Recent progress in Large Language Models (LLMs) and language agents has
demonstrated significant promise for various future applications across
multiple disciplines. While traditional approaches to language agents often
rely on fixed, handcrafted designs, our research aims to develop both learnable
and dynamic agents. Our method uses an existing framework that abstracts
language agents as graphs. Within this graph framework, we aim to learn a model
that can generate edges for every given input to the language agent. This
allows us to generate edges that represent the flow of communication within the
graph based on the given input, thereby adjusting the internal communication of
a language agent. We learn to generate these edges using a pretrained LLM that
is fine-tuned with reinforcement learning. This LLM can be fine-tuned on
several datasets simultaneously, and we hypothesize that the model learns to
adapt to these different domains during training, achieving good overall
performance when encountering data from different domains during deployment. We
demonstrate that our approach surpasses the previous static approach by nearly
6% accuracy on a combined dataset of MMLU and CMMLU, and by more than 10% when
trained with a sparsity-inducing loss. It also performs superior in additional
experiments conducted with the MMLU and Mini Crossword Puzzles datasets. The
code is available at https://github.com/lukasVierling/DynamicGPTSwarm.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂíåËØ≠Ë®Ä‰ª£ÁêÜÊúÄËøëÁöÑËøõÂ±ïÂ∑≤Â±ïÁ§∫Âá∫ÂØπË∑®Â§ö‰∏™Â≠¶ÁßëÁöÑÂêÑÁßçÊú™Êù•Â∫îÁî®ÁöÑÈáçÂ§ßÂâçÊôØ„ÄÇËôΩÁÑ∂‰º†ÁªüÁöÑËØ≠Ë®Ä‰ª£ÁêÜÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂõ∫ÂÆöÁöÑÊâãÂ∑•ËÆæËÆ°Ôºå‰ΩÜÊàë‰ª¨ÁöÑÁ†îÁ©∂Êó®Âú®ÂºÄÂèëÂèØÂ≠¶‰π†ÂíåÂä®ÊÄÅÁöÑ‰ª£ÁêÜ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ΩøÁî®‰∫Ü‰∏Ä‰∏™Áé∞ÊúâÁöÑÊ°ÜÊû∂ÔºåÂ∞ÜËØ≠Ë®Ä‰ª£ÁêÜÊäΩË±°‰∏∫Âõæ„ÄÇÂú®Ëøô‰∏™ÂõæÊ°ÜÊû∂ÂÜÖÔºåÊàë‰ª¨Êó®Âú®Â≠¶‰π†‰∏Ä‰∏™Ê®°ÂûãÔºåËØ•Ê®°ÂûãÂèØ‰ª•‰∏∫ËØ≠Ë®Ä‰ª£ÁêÜÁöÑÊØè‰∏™ÁªôÂÆöËæìÂÖ•ÁîüÊàêËæπ„ÄÇËøô‰ΩøÊàë‰ª¨ËÉΩÂ§üÁîüÊàê‰ª£Ë°®Âõæ‰∏≠Âü∫‰∫éÁªôÂÆöËæìÂÖ•ÁöÑÈÄö‰ø°ÊµÅÁöÑËæπÔºå‰ªéËÄåË∞ÉÊï¥ËØ≠Ë®Ä‰ª£ÁêÜÁöÑÂÜÖÈÉ®ÈÄö‰ø°„ÄÇÊàë‰ª¨Â≠¶‰π†‰ΩøÁî®ÁªèËøáÂº∫ÂåñÂ≠¶‰π†ÂæÆË∞ÉÁöÑÈ¢ÑËÆ≠ÁªÉ LLM Êù•ÁîüÊàêËøô‰∫õËæπ„ÄÇËØ• LLM ÂèØ‰ª•ÂêåÊó∂Âú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°åÂæÆË∞ÉÔºåÊàë‰ª¨ÂÅáËÆæËØ•Ê®°ÂûãÂú®ËÆ≠ÁªÉÊúüÈó¥Â≠¶‰π†ÈÄÇÂ∫îËøô‰∫õ‰∏çÂêåÁöÑÂüüÔºåÂú®ÈÉ®ÁΩ≤ÊúüÈó¥ÈÅáÂà∞Êù•Ëá™‰∏çÂêåÂüüÁöÑÊï∞ÊçÆÊó∂ÂÆûÁé∞ËâØÂ•ΩÁöÑÊï¥‰ΩìÊÄßËÉΩ„ÄÇÊàë‰ª¨ËØÅÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú® MMLU Âíå CMMLU ÁöÑÁªÑÂêàÊï∞ÊçÆÈõÜ‰∏äÊØîÂÖàÂâçÁöÑÈùôÊÄÅÊñπÊ≥ïÈ´òÂá∫Ëøë 6% ÁöÑÂáÜÁ°ÆÂ∫¶ÔºåÂπ∂‰∏îÂú®‰ΩøÁî®Á®ÄÁñèÊÄßËØ±ÂØºÊçüÂ§±ËøõË°åËÆ≠ÁªÉÊó∂È´òÂá∫ 10% ‰ª•‰∏ä„ÄÇÂÆÉËøòÂú®‰ΩøÁî® MMLU ÂíåËø∑‰Ω†Â°´Â≠óÊ∏∏ÊàèÊï∞ÊçÆÈõÜËøõË°åÁöÑÂÖ∂‰ªñÂÆûÈ™å‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/lukasVierling/DynamicGPTSwarm Ëé∑Âæó„ÄÇ

##### **AIC MLLM: Autonomous Interactive Correction MLLM for Robust Robotic Manipulation**
2406.11548v1 by Chuyan Xiong, Chengyu Shen, Xiaoqi Li, Kaichen Zhou, Jiaming Liu, Ruiping Wang, Hao Dong

The ability to reflect on and correct failures is crucial for robotic systems
to interact stably with real-life objects.Observing the generalization and
reasoning capabilities of Multimodal Large Language Models (MLLMs), previous
approaches have aimed to utilize these models to enhance robotic systems
accordingly.However, these methods typically focus on high-level planning
corrections using an additional MLLM, with limited utilization of failed
samples to correct low-level contact poses. To address this gap, we propose an
Autonomous Interactive Correction (AIC) MLLM, which makes use of previous
low-level interaction experiences to correct SE(3) pose predictions.
Specifically, AIC MLLM is initially fine-tuned to acquire both pose prediction
and feedback prompt comprehension abilities.We carefully design two types of
prompt instructions through interactions with objects: 1) visual masks to
highlight unmovable parts for position correction, and 2)textual descriptions
to indicate potential directions for rotation correction.During inference, a
Feedback Information Extraction module is introduced to recognize the failure
cause, allowing AIC MLLM to adaptively correct the pose prediction using the
corresponding prompts.To further enhance manipulation stability, we devise a
Test Time Adaptation strategy that enables AIC MLLM to better adapt to the
current scene configuration.Finally, extensive experiments are conducted in
both simulated and real-world environments to evaluate the proposed method. The
results demonstrate that our AIC MLLM can efficiently correct failure samples
by leveraging interaction experience prompts.Real-world demonstration can be
found at https://sites.google.com/view/aic-mllm

ÊëòË¶ÅÔºöÊ©üÂô®‰∫∫Á≥ªÁµ±Ëã•Ë¶ÅËàáÁèæÂØ¶ÁîüÊ¥ª‰∏≠ÁöÑÁâ©È´îÁ©©ÂÆö‰∫íÂãïÔºåÂøÖÈ†àÂÖ∑ÂÇôÂèçÁúÅÂíå‰øÆÊ≠£Â§±ÊïóÁöÑËÉΩÂäõ„ÄÇËßÄÂØüÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÊ¶ÇÂåñÂíåÊé®ÁêÜËÉΩÂäõÔºåÂÖàÂâçÁöÑÂÅöÊ≥ïÊó®Âú®Âà©Áî®ÈÄô‰∫õÊ®°Âûã‰æÜÁõ∏ÊáâÂú∞Âº∑ÂåñÊ©üÂô®‰∫∫Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ËëóÈáçÊñº‰ΩøÁî®È°çÂ§ñÁöÑ MLLM ÈÄ≤Ë°åÈ´òÂ±§Á¥öË¶èÂäÉ‰øÆÊ≠£ÔºåËÄåÂÉÖÊúâÈôêÂú∞Âà©Áî®Â§±ÊïóÊ®£Êú¨‰æÜ‰øÆÊ≠£‰ΩéÂ±§Á¥öÊé•Ëß∏ÂßøÂã¢„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫Ëá™Ê≤ª‰∫íÂãï‰øÆÊ≠£ (AIC) MLLMÔºåÂÆÉÂà©Áî®ÂÖàÂâçÁöÑ‰ΩéÂ±§Á¥ö‰∫íÂãïÁ∂ìÈ©ó‰æÜ‰øÆÊ≠£ SE(3) ÂßøÂã¢È†êÊ∏¨„ÄÇÂÖ∑È´î‰æÜË™™ÔºåAIC MLLM ÊúÄÂàùÁ∂ìÈÅéÂæÆË™øÔºå‰ª•Áç≤ÂæóÂßøÂã¢È†êÊ∏¨ÂíåÂõûÈ•ãÊèêÁ§∫ÁêÜËß£ËÉΩÂäõ„ÄÇÊàëÂÄëÈÄèÈÅéËàáÁâ©È´î‰∫íÂãïÔºå‰ªîÁ¥∞Ë®≠Ë®àÂÖ©Á®ÆÈ°ûÂûãÁöÑÊèêÁ§∫Êåá‰ª§Ôºö1) Ë¶ñË¶∫ÈÅÆÁΩ©ÔºåÁî®ÊñºÁ™ÅÂá∫‰∏çÂèØÁßªÂãïÁöÑÈÉ®ÂàÜ‰ª•ÈÄ≤Ë°å‰ΩçÁΩÆ‰øÆÊ≠£Ôºå‰ª•Âèä 2) ÊñáÂ≠óÊèèËø∞ÔºåÁî®ÊñºÊåáÁ§∫ÊóãËΩâ‰øÆÊ≠£ÁöÑÊΩõÂú®ÊñπÂêë„ÄÇÂú®Êé®ÁêÜÊúüÈñìÔºåÂºïÂÖ•‰∫ÜÂõûÈ•ãË≥áË®äÊèêÂèñÊ®°ÁµÑÔºå‰ª•Ë≠òÂà•Â§±ÊïóÂéüÂõ†ÔºåËÆì AIC MLLM ËÉΩÂ§†‰ΩøÁî®Â∞çÊáâÁöÑÊèêÁ§∫Ëá™ÈÅ©ÊáâÂú∞‰øÆÊ≠£ÂßøÂã¢È†êÊ∏¨„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑Êìç‰ΩúÁ©©ÂÆöÊÄßÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊ∏¨Ë©¶ÊôÇÈñìÈÅ©ÊáâÁ≠ñÁï•ÔºåËÆì AIC MLLM ËÉΩÂ§†Êõ¥Â•ΩÂú∞ÈÅ©ÊáâÁï∂ÂâçÁöÑÂ†¥ÊôØÁµÑÊÖã„ÄÇÊúÄÂæåÔºåÂú®Ê®°Êì¨ÂíåÁúüÂØ¶‰∏ñÁïåÁí∞Â¢É‰∏≠ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•Ë©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑ AIC MLLM ËÉΩÂ§†ÈÄèÈÅéÂà©Áî®‰∫íÂãïÁ∂ìÈ©óÊèêÁ§∫ÊúâÊïàÂú∞‰øÆÊ≠£Â§±ÊïóÊ®£Êú¨„ÄÇÂèØ‰ª•Âú® https://sites.google.com/view/aic-mllm ÊâæÂà∞ÂØ¶ÈöõÊìç‰ΩúÁ§∫ÁØÑ

##### **GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations**
2406.11547v1 by Rick Wilming, Artur Dox, Hjalmar Schulz, Marta Oliveira, Benedict Clark, Stefan Haufe

Large pre-trained language models have become popular for many applications
and form an important backbone of many downstream tasks in natural language
processing (NLP). Applying 'explainable artificial intelligence' (XAI)
techniques to enrich such models' outputs is considered crucial for assuring
their quality and shedding light on their inner workings. However, large
language models are trained on a plethora of data containing a variety of
biases, such as gender biases, affecting model weights and, potentially,
behavior. Currently, it is unclear to what extent such biases also impact model
explanations in possibly unfavorable ways. We create a gender-controlled text
dataset, GECO, in which otherwise identical sentences appear in male and female
forms. This gives rise to ground-truth 'world explanations' for gender
classification tasks, enabling the objective evaluation of the correctness of
XAI methods. We also provide GECOBench, a rigorous quantitative evaluation
framework benchmarking popular XAI methods, applying them to pre-trained
language models fine-tuned to different degrees. This allows us to investigate
how pre-training induces undesirable bias in model explanations and to what
extent fine-tuning can mitigate such explanation bias. We show a clear
dependency between explanation performance and the number of fine-tuned layers,
where XAI methods are observed to particularly benefit from fine-tuning or
complete retraining of embedding layers. Remarkably, this relationship holds
for models achieving similar classification performance on the same task. With
that, we highlight the utility of the proposed gender-controlled dataset and
novel benchmarking approach for research and development of novel XAI methods.
All code including dataset generation, model training, evaluation and
visualization is available at: https://github.com/braindatalab/gecobench

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂ∑≤Âª£Ê≥õÊáâÁî®ÊñºË®±Â§öÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰∏¶ÊßãÊàêËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠Ë®±Â§ö‰∏ãÊ∏∏‰ªªÂãôÁöÑÈáçË¶ÅÈ™®Âππ„ÄÇÂ∞á„ÄåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß„Äç(XAI) ÊäÄË°ìÊáâÁî®ÊñºË±êÂØåÊ≠§È°ûÊ®°ÂûãÁöÑËº∏Âá∫ÔºåË¢´Ë™çÁÇ∫Â∞çÊñºÁ¢∫‰øùÂÖ∂ÂìÅË≥™‰∏¶Èó°ÊòéÂÖ∂ÂÖßÈÉ®ÈÅã‰ΩúËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊòØÂú®ÂåÖÂê´ÂêÑÁ®ÆÂÅèÂ∑ÆÁöÑÈæêÂ§ßË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÔºå‰æãÂ¶ÇÊÄßÂà•ÂÅèÂ∑ÆÔºåÊúÉÂΩ±ÈüøÊ®°ÂûãÊ¨äÈáçÂíåÊΩõÂú®Ë°åÁÇ∫„ÄÇÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öÊ≠§È°ûÂÅèÂ∑ÆÂú®‰ΩïÁ®ÆÁ®ãÂ∫¶‰∏ä‰πüÊúÉ‰ª•ÂèØËÉΩ‰∏çÂà©ÁöÑÂΩ±ÈüøÊ®°ÂûãËß£Èáã„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊÄßÂà•ÊéßÂà∂ÊñáÂ≠óË≥áÊñôÈõÜ GECOÔºåÂÖ∂‰∏≠ÂéüÊú¨Áõ∏ÂêåÁöÑÂè•Â≠ê‰ª•Áî∑ÊÄßÂíåÂ•≥ÊÄßÂΩ¢ÂºèÂá∫Áèæ„ÄÇÈÄôÁî¢Áîü‰∫ÜÊÄßÂà•ÂàÜÈ°û‰ªªÂãôÁöÑÁúüÂØ¶„Äå‰∏ñÁïåËß£Èáã„ÄçÔºå‰ΩøÊàëÂÄëËÉΩÂ§†ÂÆ¢ËßÄË©ï‰º∞ XAI ÊñπÊ≥ïÁöÑÊ≠£Á¢∫ÊÄß„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫Ü GECOBenchÔºåÈÄôÊòØ‰∏ÄÂÄãÂö¥Ë¨πÁöÑÈáèÂåñË©ï‰º∞Êû∂ÊßãÔºåÁî®ÊñºÂ∞çÊµÅË°åÁöÑ XAI ÊñπÊ≥ïÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂ∞áÂÆÉÂÄëÊáâÁî®ÊñºÁ∂ìÈÅé‰∏çÂêåÁ®ãÂ∫¶ÂæÆË™øÁöÑÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã„ÄÇÈÄô‰ΩøÊàëÂÄëËÉΩÂ§†Á†îÁ©∂È†êË®ìÁ∑¥Â¶Ç‰ΩïÂ∞éËá¥Ê®°ÂûãËß£Èáã‰∏≠Âá∫Áèæ‰∏çËâØÂÅèÂ∑ÆÔºå‰ª•ÂèäÂæÆË™øÂèØ‰ª•Âú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÊ∏õËºïÈÄôÁ®ÆËß£ÈáãÂÅèÂ∑Æ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜËß£ÈáãÊïàËÉΩËàáÂæÆË™øÂ±§Êï∏‰πãÈñìÁöÑÊòéÈ°Ø‰æùË≥¥Èóú‰øÇÔºåÂÖ∂‰∏≠ËßÄÂØüÂà∞ XAI ÊñπÊ≥ïÁâπÂà•ÂèóÁõäÊñºÂæÆË™øÊàñÂµåÂÖ•Â±§ÁöÑÂÆåÊï¥ÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÈÄôÁ®ÆÈóú‰øÇÈÅ©Áî®ÊñºÂú®Âêå‰∏Ä‰ªªÂãô‰∏äÂØ¶ÁèæÈ°û‰ººÂàÜÈ°ûÊïàËÉΩÁöÑÊ®°Âûã„ÄÇÊúâ‰∫ÜÈÄô‰∫õÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊâÄÊèêÂá∫ÁöÑÊÄßÂà•ÊéßÂà∂Ë≥áÊñôÈõÜÂíåÊñ∞Âü∫Ê∫ñÊ∏¨Ë©¶ÊñπÊ≥ïÂ∞çÊñ∞ XAI ÊñπÊ≥ïÁöÑÁ†îÁ©∂ÂíåÈñãÁôºÁöÑÊïàÁî®„ÄÇÊâÄÊúâÁ®ãÂºèÁ¢ºÔºåÂåÖÊã¨Ë≥áÊñôÈõÜÁîüÊàê„ÄÅÊ®°ÂûãË®ìÁ∑¥„ÄÅË©ï‰º∞ÂíåË¶ñË¶∫ÂåñÔºåÈÉΩÂèØ‰ª•Âú®‰ª•‰∏ã‰ΩçÁΩÆÂèñÂæóÔºöhttps://github.com/braindatalab/gecobench</paragraph>

##### **GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement**
2406.11546v1 by Yifan Yang, Zheshu Song, Jianheng Zhuo, Mingyu Cui, Jinpeng Li, Bo Yang, Yexing Du, Ziyang Ma, Xunying Liu, Ziyuan Wang, Ke Li, Shuai Fan, Kai Yu, Wei-Qiang Zhang, Guoguo Chen, Xie Chen

The evolution of speech technology has been spurred by the rapid increase in
dataset sizes. Traditional speech models generally depend on a large amount of
labeled training data, which is scarce for low-resource languages. This paper
presents GigaSpeech 2, a large-scale, multi-domain, multilingual speech
recognition corpus. It is designed for low-resource languages and does not rely
on paired speech and text data. GigaSpeech 2 comprises about 30,000 hours of
automatically transcribed speech, including Thai, Indonesian, and Vietnamese,
gathered from unlabeled YouTube videos. We also introduce an automated pipeline
for data crawling, transcription, and label refinement. Specifically, this
pipeline uses Whisper for initial transcription and TorchAudio for forced
alignment, combined with multi-dimensional filtering for data quality
assurance. A modified Noisy Student Training is developed to further refine
flawed pseudo labels iteratively, thus enhancing model performance.
Experimental results on our manually transcribed evaluation set and two public
test sets from Common Voice and FLEURS confirm our corpus's high quality and
broad applicability. Notably, ASR models trained on GigaSpeech 2 can reduce the
word error rate for Thai, Indonesian, and Vietnamese on our challenging and
realistic YouTube test set by 25% to 40% compared to the Whisper large-v3
model, with merely 10% model parameters. Furthermore, our ASR models trained on
Gigaspeech 2 yield superior performance compared to commercial services. We
believe that our newly introduced corpus and pipeline will open a new avenue
for low-resource speech recognition and significantly facilitate research in
this area.

ÊëòË¶ÅÔºö<paragraph>Ë™ûÈü≥ÊäÄË°ìÁöÑÊºîÈÄ≤ÂèóÂà∞Ë≥áÊñôÈõÜË¶èÊ®°Âø´ÈÄüÂ¢ûÂä†ÁöÑÂà∫ÊøÄ„ÄÇÂÇ≥Áµ±ÁöÑË™ûÈü≥Ê®°ÂûãÈÄöÂ∏∏‰æùË≥¥ÊñºÂ§ßÈáèÁöÑÊ®ôË®òË®ìÁ∑¥Ë≥áÊñôÔºåËÄåÈÄôÂ∞ç‰ΩéË≥áÊ∫êË™ûË®Ä‰æÜË™™ÂæàÁ®ÄÂ∞ë„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü GigaSpeech 2Ôºå‰∏ÄÂÄãÂ§ßÂûã„ÄÅÂ§öÈ†òÂüü„ÄÅÂ§öË™ûË®ÄÁöÑË™ûÈü≥Ëæ®Ë≠òË™ûÊñôÂ∫´„ÄÇÂÆÉÊòØÁÇ∫‰ΩéË≥áÊ∫êË™ûË®ÄË®≠Ë®àÁöÑÔºå‰∏î‰∏ç‰æùË≥¥ÊàêÂ∞çÁöÑË™ûÈü≥ÂíåÊñáÂ≠óË≥áÊñô„ÄÇGigaSpeech 2 ÂåÖÂê´Á¥Ñ 30,000 Â∞èÊôÇÁöÑËá™ÂãïËΩâÈåÑË™ûÈü≥ÔºåÂåÖÊã¨Ê≥∞Ë™û„ÄÅÂç∞Â∞ºË™ûÂíåË∂äÂçóË™ûÔºåÈÄô‰∫õË™ûÈü≥ÊòØÂæûÊú™Ê®ôË®òÁöÑ YouTube ÂΩ±Áâá‰∏≠Êî∂ÈõÜ‰æÜÁöÑ„ÄÇÊàëÂÄëÈÇÑÂ∞éÂÖ•‰∫Ü‰∏ÄÂÄãÁî®ÊñºË≥áÊñôÁà¨Âèñ„ÄÅËΩâÈåÑÂíåÊ®ôÁ±§Á≤æÁÖâÁöÑËá™ÂãïÂåñÁÆ°ÈÅì„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈÄôÂÄãÁÆ°ÈÅì‰ΩøÁî® Whisper ÈÄ≤Ë°åÂàùÂßãËΩâÈåÑÔºå‰∏¶‰ΩøÁî® TorchAudio ÈÄ≤Ë°åÂº∑Âà∂ÊØîÂ∞çÔºåÁµêÂêàÂ§öÁ∂≠Â∫¶ÈÅéÊøæ‰æÜÁ¢∫‰øùË≥áÊñôÂìÅË≥™„ÄÇÈñãÁôº‰∫Ü‰∏ÄÂÄãÊîπËâØÁöÑ Noisy Student TrainingÔºåÁî®ÊñºÈÄ≤‰∏ÄÊ≠•ÂèçË¶ÜÁ≤æÁÖâÊúâÁº∫Èô∑ÁöÑÂÅΩÊ®ôÁ±§ÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÊïàËÉΩ„ÄÇÊàëÂÄëÊâãÂãïËΩâÈåÑÁöÑË©ï‰º∞ÈõÜÂíå‰æÜËá™ Common Voice Âíå FLEURS ÁöÑÂÖ©ÂÄãÂÖ¨ÈñãÊ∏¨Ë©¶ÈõÜÁöÑÂØ¶È©óÁµêÊûúË≠âÂØ¶‰∫ÜÊàëÂÄëË™ûÊñôÂ∫´ÁöÑÈ´òÂìÅË≥™ÂíåÂª£Ê≥õÁöÑÈÅ©Áî®ÊÄß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú® GigaSpeech 2 ‰∏äË®ìÁ∑¥ÁöÑ ASR Ê®°ÂûãÂèØ‰ª•Â∞áÊàëÂÄëÂÖ∑ÊúâÊåëÊà∞ÊÄßÂíåÂØ¶ÈöõÊÄßÁöÑ YouTube Ê∏¨Ë©¶ÈõÜ‰∏äÊ≥∞Ë™û„ÄÅÂç∞Â∞ºË™ûÂíåË∂äÂçóË™ûÁöÑÂ≠óÂÖÉÈåØË™§ÁéáÈôç‰Ωé 25% Âà∞ 40%ÔºåËÄå Whisper large-v3 Ê®°ÂûãÂÉÖÊúâ 10% ÁöÑÊ®°ÂûãÂèÉÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú® Gigaspeech 2 ‰∏äË®ìÁ∑¥ÁöÑ ASR Ê®°ÂûãËàáÂïÜÊ•≠ÊúçÂãôÁõ∏ÊØîÔºåË°®ÁèæÂá∫Êõ¥ÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁõ∏‰ø°ÊàëÂÄëÊñ∞Êé®Âá∫ÁöÑË™ûÊñôÂ∫´ÂíåÁÆ°ÈÅìÂ∞áÁÇ∫‰ΩéË≥áÊ∫êË™ûÈü≥Ëæ®Ë≠òÈñãÂïü‰∏ÄÊ¢ùÊñ∞ÈÄîÂæëÔºå‰∏¶È°ØËëó‰øÉÈÄ≤ÈÄôÊñπÈù¢ÁöÑÁ†îÁ©∂„ÄÇ</paragraph>

##### **Do Parameters Reveal More than Loss for Membership Inference?**
2406.11544v1 by Anshuman Suri, Xiao Zhang, David Evans

Membership inference attacks aim to infer whether an individual record was
used to train a model, serving as a key tool for disclosure auditing. While
such evaluations are useful to demonstrate risk, they are computationally
expensive and often make strong assumptions about potential adversaries' access
to models and training environments, and thus do not provide very tight bounds
on leakage from potential attacks. We show how prior claims around black-box
access being sufficient for optimal membership inference do not hold for most
useful settings such as stochastic gradient descent, and that optimal
membership inference indeed requires white-box access. We validate our findings
with a new white-box inference attack IHA (Inverse Hessian Attack) that
explicitly uses model parameters by taking advantage of computing
inverse-Hessian vector products. Our results show that both audits and
adversaries may be able to benefit from access to model parameters, and we
advocate for further research into white-box methods for membership privacy
auditing.

ÊëòË¶ÅÔºöÊàêÂì°Êé®Ë´ñÊîªÊìäÊó®Âú®Êé®Ë´ñÂÄãÂà•Ë®òÈåÑÊòØÂê¶Áî®ÊñºË®ìÁ∑¥Ê®°ÂûãÔºå‰ΩúÁÇ∫Êè≠Èú≤Á®ΩÊ†∏ÁöÑÈóúÈçµÂ∑•ÂÖ∑„ÄÇÈõñÁÑ∂Ê≠§È°ûË©ï‰º∞ÊúâÂä©ÊñºË≠âÊòéÈ¢®Èö™Ôºå‰ΩÜÂÆÉÂÄëÂú®Ë®àÁÆó‰∏äÂæàÊòÇË≤¥ÔºåËÄå‰∏îÈÄöÂ∏∏Â∞çÊΩõÂú®Â∞çÊâãË®™ÂïèÊ®°ÂûãÂíåË®ìÁ∑¥Áí∞Â¢ÉÂÅöÂá∫Âº∑ÊúâÂäõÁöÑÂÅáË®≠ÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÊèê‰æõÈùûÂ∏∏Âö¥Ê†ºÁöÑÊΩõÂú®ÊîªÊìäÊ¥©ÊºèÁØÑÂúç„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊúâÈóúÈªëÁõíÂ≠òÂèñË∂≥‰ª•ÈÄ≤Ë°åÊúÄ‰Ω≥ÊàêÂì°Êé®Ë´ñÁöÑÂÖàÂâçË™™Ê≥ï‰∏¶‰∏çÈÅ©Áî®ÊñºÂ§ßÂ§öÊï∏ÊúâÁî®ÁöÑË®≠ÂÆöÔºå‰æãÂ¶ÇÈö®Ê©üÊ¢ØÂ∫¶‰∏ãÈôçÔºå‰ª•ÂèäÊúÄ‰Ω≥ÊàêÂì°Êé®Ë´ñÁ¢∫ÂØ¶ÈúÄË¶ÅÁôΩÁõíÂ≠òÂèñ„ÄÇÊàëÂÄë‰ΩøÁî®Êñ∞ÁöÑÁôΩÁõíÊé®Ë´ñÊîªÊìä IHAÔºàÈÄÜÊµ∑Ê£ÆÊîªÊìäÔºâÈ©óË≠âÊàëÂÄëÁöÑÁôºÁèæÔºåË©≤ÊîªÊìäÈÄèÈÅéÂà©Áî®Ë®àÁÆóÈÄÜÊµ∑Ê£ÆÂêëÈáèÁ©çÔºåÊòéÁ¢∫‰ΩøÁî®Ê®°ÂûãÂèÉÊï∏„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÁ®ΩÊ†∏ÂíåÂ∞çÊâãÈÉΩÂèØ‰ª•ÂæûË®™ÂïèÊ®°ÂûãÂèÉÊï∏‰∏≠ÂèóÁõäÔºåÊàëÂÄë‰∏ªÂºµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÁôΩÁõíÊñπÊ≥ï‰ª•ÈÄ≤Ë°åÊàêÂì°Èö±ÁßÅÁ®ΩÊ†∏„ÄÇ

##### **Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**
2406.11538v1 by Artur Jurgas, Marek Wodzinski, Marina D'Amato, Jeroen van der Laak, Manfredo Atzori, Henning M√ºller

The problem of artifacts in whole slide image acquisition, prevalent in both
clinical workflows and research-oriented settings, necessitates human
intervention and re-scanning. Overcoming this challenge requires developing
quality control algorithms, that are hindered by the limited availability of
relevant annotated data in histopathology. The manual annotation of
ground-truth for artifact detection methods is expensive and time-consuming.
This work addresses the issue by proposing a method dedicated to augmenting
whole slide images with artifacts. The tool seamlessly generates and blends
artifacts from an external library to a given histopathology dataset. The
augmented datasets are then utilized to train artifact classification methods.
The evaluation shows their usefulness in classification of the artifacts, where
they show an improvement from 0.10 to 0.01 AUROC depending on the artifact
type. The framework, model, weights, and ground-truth annotations are freely
released to facilitate open science and reproducible research.

ÊëòË¶ÅÔºöÂú®Ëá®Â∫ä‰∏äÊàñÁ†îÁ©∂‰∏≠ÔºåÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉèÊì∑ÂèñÊôÇÁî¢ÁîüÁöÑÂÅΩÂÉèÂïèÈ°åÔºåÈúÄË¶Å‰∫∫ÁÇ∫‰ªãÂÖ•ÂíåÈáçÊñ∞ÊéÉÊèè„ÄÇÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÈúÄË¶ÅÈñãÁôºÂìÅË≥™ÊéßÁÆ°ÊºîÁÆóÊ≥ïÔºå‰ΩÜÁµÑÁπîÁóÖÁêÜÂ≠∏‰∏≠Áõ∏ÈóúË®ªËß£Ë≥áÊñôÊúâÈôêÔºåÈòªÁ§ô‰∫ÜÊºîÁÆóÊ≥ïÁöÑÁôºÂ±ï„ÄÇ‰∫∫Â∑•Ë®ªËß£ÂÅΩÂÉèÂÅµÊ∏¨ÊñπÊ≥ïÁöÑÁúüÂØ¶ÊÉÖÊ≥ÅÊó¢ÊòÇË≤¥ÂèàË≤ªÊôÇ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈÄôÂÄãÊñπÊ≥ïÂ∞àÈñÄÁî®‰æÜÂ¢ûÂä†ÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉè‰∏≠ÁöÑÂÅΩÂÉè„ÄÇÈÄôÂÄãÂ∑•ÂÖ∑ÂèØ‰ª•ÁÑ°Á∏´Âú∞ÂæûÂ§ñÈÉ®Ë≥áÊñôÂ∫´Áî¢Áîü‰∏¶Ê∑∑ÂêàÂÅΩÂÉèÂà∞Áµ¶ÂÆöÁöÑÁµÑÁπîÁóÖÁêÜÂ≠∏Ë≥áÊñôÈõÜ„ÄÇÁÑ∂Âæå‰ΩøÁî®Êì¥ÂÖÖÂæåÁöÑË≥áÊñôÈõÜ‰æÜË®ìÁ∑¥ÂÅΩÂÉèÂàÜÈ°ûÊñπÊ≥ï„ÄÇË©ï‰º∞È°ØÁ§∫Âá∫ÂÆÉÂÄëÂú®ÂÅΩÂÉèÂàÜÈ°û‰∏≠ÁöÑÊïàÁî®ÔºåÂú®‰∏çÂêåÁöÑÂÅΩÂÉèÈ°ûÂûã‰∏≠ÔºåÂÆÉÂÄëÁöÑ AUROC Âæû 0.10 ÈÄ≤Ê≠•Âà∞ 0.01„ÄÇÈÄôÂÄãÊû∂Êßã„ÄÅÊ®°Âûã„ÄÅÊ¨äÈáçÂíåÁúüÂØ¶Ë®ªËß£ÊòØÂÖçË≤ªÈáãÂá∫ÁöÑÔºå‰ª•Âà©ÊñºÈñãÊîæÁßëÂ≠∏ÂíåÂèØÈáçË£ΩÁöÑÁ†îÁ©∂„ÄÇ

##### **Explainable Artificial Intelligence and Multicollinearity : A Mini Review of Current Approaches**
2406.11524v1 by Ahmed M Salih

Explainable Artificial Intelligence (XAI) methods help to understand the
internal mechanism of machine learning models and how they reach a specific
decision or made a specific action. The list of informative features is one of
the most common output of XAI methods. Multicollinearity is one of the big
issue that should be considered when XAI generates the explanation in terms of
the most informative features in an AI system. No review has been dedicated to
investigate the current approaches to handle such significant issue. In this
paper, we provide a review of the current state-of-the-art approaches in
relation to the XAI in the context of recent advances in dealing with the
multicollinearity issue. To do so, we searched in three repositories that are:
Web of Science, Scopus and IEEE Xplore to find pertinent published papers.
After excluding irrelevant papers, seven papers were considered in the review.
In addition, we discuss the current XAI methods and their limitations in
dealing with the multicollinearity and suggest future directions.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÊñπÊ≥ïÊúâÂä©ÊñºÁêÜËß£Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÂÖßÈÉ®Ê©üÂà∂Ôºå‰ª•ÂèäÂÆÉÂÄëÂ¶Ç‰ΩïÈÅîÊàêÁâπÂÆöÊ±∫Á≠ñÊàñÊé°ÂèñÁâπÂÆöË°åÂãï„ÄÇË≥áË®äÊÄßÁâπÂæµÊ∏ÖÂñÆÊòØ XAI ÊñπÊ≥ïÊúÄÂ∏∏Ë¶ãÁöÑËº∏Âá∫‰πã‰∏Ä„ÄÇÂ§öÈáçÂÖ±Á∑öÊÄßÊòØ XAI Âú® AI Á≥ªÁµ±‰∏≠Ê†πÊìöË≥áË®äÊÄßÁâπÂæµÁî¢ÁîüËß£ÈáãÊôÇÊáâËÄÉÊÖÆÁöÑ‰∏ªË¶ÅÂïèÈ°å‰πã‰∏Ä„ÄÇÁõÆÂâçÈÇÑÊ≤íÊúâ‰ªª‰ΩïË©ïË´ñÂ∞àÈñÄÊé¢Ë®éËôïÁêÜÊ≠§È°ûÈáçÂ§ßÂïèÈ°åÁöÑÁèæÊúâÊñπÊ≥ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂõûÈ°ß‰∫ÜËàá XAI Áõ∏ÈóúÁöÑÁèæÊúâÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÔºå‰ª•ÂèäÂú®ËôïÁêÜÂ§öÈáçÂÖ±Á∑öÊÄßÂïèÈ°åÊñπÈù¢ÂèñÂæóÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂú® Web of Science„ÄÅScopus Âíå IEEE Xplore ‰∏âÂÄãË≥áÊñôÂ∫´‰∏≠ÊêúÂ∞ãÁõ∏ÈóúÂ∑≤ÁôºË°®ÁöÑË´ñÊñá„ÄÇÂú®ÊéíÈô§ÁÑ°ÈóúË´ñÊñáÂæåÔºåÊàëÂÄëÂú®Ë©ïË´ñ‰∏≠ËÄÉÊÖÆ‰∫Ü‰∏ÉÁØáË´ñÊñá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜÁèæÊúâÁöÑ XAI ÊñπÊ≥ïÂèäÂÖ∂Âú®ËôïÁêÜÂ§öÈáçÂÖ±Á∑öÊÄßÊñπÈù¢ÁöÑÈôêÂà∂Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊú™‰æÜÁöÑÊñπÂêë„ÄÇ

##### **FullCert: Deterministic End-to-End Certification for Training and Inference of Neural Networks**
2406.11522v1 by Tobias Lorenz, Marta Kwiatkowska, Mario Fritz

Modern machine learning models are sensitive to the manipulation of both the
training data (poisoning attacks) and inference data (adversarial examples).
Recognizing this issue, the community has developed many empirical defenses
against both attacks and, more recently, provable certification methods against
inference-time attacks. However, such guarantees are still largely lacking for
training-time attacks. In this work, we present FullCert, the first end-to-end
certifier with sound, deterministic bounds, which proves robustness against
both training-time and inference-time attacks. We first bound all possible
perturbations an adversary can make to the training data under the considered
threat model. Using these constraints, we bound the perturbations' influence on
the model's parameters. Finally, we bound the impact of these parameter changes
on the model's prediction, resulting in joint robustness guarantees against
poisoning and adversarial examples. To facilitate this novel certification
paradigm, we combine our theoretical work with a new open-source library
BoundFlow, which enables model training on bounded datasets. We experimentally
demonstrate FullCert's feasibility on two different datasets.

ÊëòË¶ÅÔºöÁèæ‰ª£Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂ∞çÊñºË®ìÁ∑¥Êï∏ÊìöÔºà‰∏≠ÊØíÊîªÊìäÔºâÂíåÊé®Ë´ñÊï∏ÊìöÔºàÂ∞çÊäóÁØÑ‰æãÔºâÁöÑÊìçÁ∏±ÂæàÊïèÊÑü„ÄÇË™çË≠òÂà∞ÈÄôÂÄãÂïèÈ°åÔºåÁ§æÁæ§Â∑≤Á∂ìÈáùÂ∞çÈÄôÂÖ©Á®ÆÊîªÊìäÈñãÁôºÂá∫Ë®±Â§öÁ∂ìÈ©óÈò≤Á¶¶Êé™ÊñΩÔºåËÄå‰∏îÊúÄËøëÈÇÑÈáùÂ∞çÊé®Ë´ñÊôÇÈñìÊîªÊìäÈñãÁôºÂá∫ÂèØË≠âÊòéË™çË≠âÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºË®ìÁ∑¥ÊôÇÈñìÊîªÊìäÔºåÊ≠§È°ûÊìî‰øù‰ªçÁÑ∂Âö¥Èáç‰∏çË∂≥„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ FullCertÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂÖ∑ÊúâÂÅ•ÂÖ®„ÄÅÁ¢∫ÂÆöÊÄßÁïåÁ∑öÁöÑÁ´ØÂ∞çÁ´ØË™çË≠âÂô®ÔºåÂÆÉË≠âÊòé‰∫ÜÂ∞çË®ìÁ∑¥ÊôÇÈñìÂíåÊé®Ë´ñÊôÇÈñìÊîªÊìäÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÈ¶ñÂÖàÁïåÂÆöÂú®ÊâÄËÄÉÊÖÆÁöÑÂ®ÅËÑÖÊ®°Âûã‰∏ãÔºåÂ∞çÊâãÂ∞çË®ìÁ∑¥Êï∏ÊìöÂèØ‰ª•ÈÄ≤Ë°åÁöÑÊâÄÊúâÊìæÂãï„ÄÇ‰ΩøÁî®ÈÄô‰∫õÁ¥ÑÊùüÊ¢ù‰ª∂ÔºåÊàëÂÄëÁïåÂÆöÊìæÂãïÂ∞çÊ®°ÂûãÂèÉÊï∏ÁöÑÂΩ±Èüø„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁïåÂÆöÈÄô‰∫õÂèÉÊï∏ËÆäÊõ¥Â∞çÊ®°ÂûãÈ†êÊ∏¨ÁöÑÂΩ±ÈüøÔºåÂæûËÄåÈáùÂ∞ç‰∏≠ÊØíÂíåÂ∞çÊäóÁØÑ‰æãÁî¢ÁîüËÅØÂêàÁ©©ÂÅ•ÊÄßÊìî‰øù„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÈÄôÁ®ÆÊñ∞Á©éÁöÑË™çË≠âÁØÑ‰æãÔºåÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁêÜË´ñÂ∑•‰ΩúËàá‰∏ÄÂÄãÊñ∞ÁöÑÈñãÊîæÂéüÂßãÁ¢ºÂáΩÂºèÂ∫´ BoundFlow ÁµêÂêàËµ∑‰æÜÔºåÂÆÉÂèØ‰ª•Âú®ÊúâÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ®°ÂûãË®ìÁ∑¥„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄã‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰∏ä‰ª•ÂØ¶È©óÊñπÂºèË≠âÊòé‰∫Ü FullCert ÁöÑÂèØË°åÊÄß„ÄÇ

##### **Revisiting Spurious Correlation in Domain Generalization**
2406.11517v1 by Bin Qin, Jiangmeng Li, Yi Li, Xuesong Wu, Yupeng Wang, Wenwen Qiang, Jianwen Cao

Without loss of generality, existing machine learning techniques may learn
spurious correlation dependent on the domain, which exacerbates the
generalization of models in out-of-distribution (OOD) scenarios. To address
this issue, recent works build a structural causal model (SCM) to describe the
causality within data generation process, thereby motivating methods to avoid
the learning of spurious correlation by models. However, from the machine
learning viewpoint, such a theoretical analysis omits the nuanced difference
between the data generation process and representation learning process,
resulting in that the causal analysis based on the former cannot well adapt to
the latter. To this end, we explore to build a SCM for representation learning
process and further conduct a thorough analysis of the mechanisms underlying
spurious correlation. We underscore that adjusting erroneous covariates
introduces bias, thus necessitating the correct selection of spurious
correlation mechanisms based on practical application scenarios. In this
regard, we substantiate the correctness of the proposed SCM and further propose
to control confounding bias in OOD generalization by introducing a propensity
score weighted estimator, which can be integrated into any existing OOD method
as a plug-and-play module. The empirical results comprehensively demonstrate
the effectiveness of our method on synthetic and large-scale real OOD datasets.

ÊëòË¶ÅÔºöÂú®‰∏çÂ§±‰∏ÄËà¨ÊÄßÁöÑÂâçÊèê‰∏ãÔºåÁé∞ÊúâÁöÑÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÂèØËÉΩ‰ºöÂ≠¶‰π†
‰æùËµñ‰∫éÈ¢ÜÂüüÁöÑËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºåËøô‰ºöÂä†ÂâßÊ®°ÂûãÂú®ÂàÜÂ∏ÉÂ§ñ (OOD) Âú∫ÊôØ‰∏≠ÁöÑÊ≥õÂåñ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥
Ëøô‰∏™ÈóÆÈ¢òÔºåÊúÄËøëÁöÑÂ∑•‰ΩúÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÁªìÊûÑÂõ†ÊûúÊ®°Âûã (SCM) Êù•ÊèèËø∞
Êï∞ÊçÆÁîüÊàêËøáÁ®ã‰∏≠ÁöÑÂõ†ÊûúÂÖ≥Á≥ªÔºå‰ªéËÄåÊøÄÂèëÊñπÊ≥ïÊù•ÈÅøÂÖç
Ê®°ÂûãÂ≠¶‰π†ËôöÂÅáÁõ∏ÂÖ≥ÊÄß„ÄÇÁÑ∂ËÄåÔºå‰ªéÊú∫Âô®ÁöÑËßíÂ∫¶Êù•Áúã
Â≠¶‰π†ËßÇÁÇπÔºåËøôÁßçÁêÜËÆ∫ÂàÜÊûêÂøΩÁï•‰∫ÜÊï∞ÊçÆÁîüÊàêËøáÁ®ãÂíåË°®Á§∫Â≠¶‰π†ËøáÁ®ã‰πãÈó¥ÁöÑÁªÜÂæÆÂ∑ÆÂà´Ôºå
ÂØºËá¥Âü∫‰∫éÂâçËÄÖÁöÑÂõ†ÊûúÂàÜÊûê‰∏çËÉΩÂæàÂ•ΩÂú∞ÈÄÇÂ∫îÂêéËÄÖ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨Êé¢Á¥¢ÊûÑÂª∫‰∏Ä‰∏™ SCM ‰ª•ËøõË°åË°®Á§∫Â≠¶‰π†
ËøáÁ®ãÂπ∂Ëøõ‰∏ÄÊ≠•ÂØπËôöÂÅáÁõ∏ÂÖ≥ÊÄßËÉåÂêéÁöÑÊú∫Âà∂ËøõË°åÂΩªÂ∫ïÂàÜÊûê„ÄÇÊàë‰ª¨Âº∫Ë∞ÉË∞ÉÊï¥ÈîôËØØÁöÑÂçèÂèòÈáè
‰ºöÂºïÂÖ•ÂÅèÂ∑ÆÔºåÂõ†Ê≠§ÈúÄË¶ÅÊ†πÊçÆÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØÊ≠£Á°ÆÈÄâÊã©ËôöÂÅá
Áõ∏ÂÖ≥Êú∫Âà∂„ÄÇÂú®ËøôÊñπÈù¢ÔºåÊàë‰ª¨ËØÅÂÆû‰∫ÜÊâÄÊèêÂá∫ÁöÑ SCM ÁöÑÊ≠£Á°ÆÊÄßÔºåÂπ∂Ëøõ‰∏ÄÊ≠•ÊèêÂá∫
ÈÄöËøáÂºïÂÖ•ÂÄæÂêëÂæóÂàÜÂä†ÊùÉ‰º∞ËÆ°ÈáèÊù•ÊéßÂà∂ OOD Ê≥õÂåñ‰∏≠ÁöÑÊ∑∑ÊùÇÂÅèÂ∑ÆÔºåËØ•‰º∞ËÆ°ÈáèÂèØ‰ª•ÈõÜÊàêÂà∞‰ªª‰ΩïÁé∞ÊúâÁöÑ OOD ÊñπÊ≥ï‰∏≠
‰Ωú‰∏∫‰∏Ä‰∏™Âç≥ÊèíÂç≥Áî®ÁöÑÊ®°Âùó„ÄÇÁªèÈ™åÁªìÊûúÂÖ®Èù¢ËØÅÊòé‰∫Ü
Êàë‰ª¨ÊñπÊ≥ïÂú®ÂêàÊàêÂíåÂ§ßÂûãÁúüÂÆû OOD Êï∞ÊçÆÈõÜ‰∏äÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Counterfactual Debating with Preset Stances for Hallucination Elimination of LLMs**
2406.11514v1 by Yi Fang, Moxin Li, Wenjie Wang, Hui Lin, Fuli Feng

Large Language Models (LLMs) excel in various natural language processing
tasks but struggle with hallucination issues. Existing solutions have
considered utilizing LLMs' inherent reasoning abilities to alleviate
hallucination, such as self-correction and diverse sampling methods. However,
these methods often overtrust LLMs' initial answers due to inherent biases. The
key to alleviating this issue lies in overriding LLMs' inherent biases for
answer inspection. To this end, we propose a CounterFactual Multi-Agent Debate
(CFMAD) framework. CFMAD presets the stances of LLMs to override their inherent
biases by compelling LLMs to generate justifications for a predetermined
answer's correctness. The LLMs with different predetermined stances are engaged
with a skeptical critic for counterfactual debate on the rationality of
generated justifications. Finally, the debate process is evaluated by a
third-party judge to determine the final answer. Extensive experiments on four
datasets of three tasks demonstrate the superiority of CFMAD over existing
methods.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂçªÈ£ΩÂèóÂπªË¶∫ÂïèÈ°åÊâÄËã¶„ÄÇÁèæÊúâÁöÑËß£Ê±∫ÊñπÊ°àÂ∑≤ËÄÉÊÖÆÂà©Áî® LLM ÂÖßÂú®ÁöÑÊé®ÁêÜËÉΩÂäõ‰æÜÊ∏õËºïÂπªË¶∫Ôºå‰æãÂ¶ÇËá™Êàë‰øÆÊ≠£ÂíåÂ§öÊ®£ÂåñÊäΩÊ®£ÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁî±ÊñºÂÖßÂú®ÂÅèË¶ãÔºåÂ∏∏Â∏∏ÈÅéÂ∫¶‰ø°‰ªª LLM ÁöÑÂàùÂßãÁ≠îÊ°à„ÄÇËß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÈóúÈçµÂú®ÊñºË¶ÜÂØ´ LLM Âõ∫ÊúâÁöÑÂÅèË¶ã‰ª•ÈÄ≤Ë°åÁ≠îÊ°àÊ™¢Êü•„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèç‰∫ãÂØ¶Â§ö‰∏ªÈ´îËæØË´ñ (CFMAD) Ê°ÜÊû∂„ÄÇCFMAD È†êË®≠ LLM ÁöÑÁ´ãÂ†¥‰ª•Ë¶ÜÂØ´ÂÖ∂ÂÖßÂú®ÂÅèË¶ãÔºåÂº∑Ëø´ LLM ÁÇ∫È†êÂÖàÁ¢∫ÂÆöÁöÑÁ≠îÊ°àÊ≠£Á¢∫ÊÄßÁî¢Áîü‰æùÊìö„ÄÇÂÖ∑Êúâ‰∏çÂêåÈ†êÂÖàÁ¢∫ÂÆöÁ´ãÂ†¥ÁöÑ LLM Ëàá‰∏Ä‰ΩçÊá∑ÁñëË´ñËÄÖÈÄ≤Ë°åÂèç‰∫ãÂØ¶ËæØË´ñÔºåÈáùÂ∞çÂ∑≤Áî¢Áîü‰æùÊìöÁöÑÂêàÁêÜÊÄßÈÄ≤Ë°åËæØË´ñ„ÄÇÊúÄÂæåÔºåËæØË´ñÈÅéÁ®ãÁî±Á¨¨‰∏âÊñπË©ïÂØ©ÈÄ≤Ë°åË©ï‰º∞Ôºå‰ª•Á¢∫ÂÆöÊúÄÁµÇÁ≠îÊ°à„ÄÇÂú®‰∏âÂÄã‰ªªÂãôÁöÑÂõõÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü CFMAD ÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **On the Feasibility of Fidelity$^-$ for Graph Pruning**
2406.11504v1 by Yong-Min Shin, Won-Yong Shin

As one of popular quantitative metrics to assess the quality of explanation
of graph neural networks (GNNs), fidelity measures the output difference after
removing unimportant parts of the input graph. Fidelity has been widely used
due to its straightforward interpretation that the underlying model should
produce similar predictions when features deemed unimportant from the
explanation are removed. This raises a natural question: "Does fidelity induce
a global (soft) mask for graph pruning?" To solve this, we aim to explore the
potential of the fidelity measure to be used for graph pruning, eventually
enhancing the GNN models for better efficiency. To this end, we propose
Fidelity$^-$-inspired Pruning (FiP), an effective framework to construct global
edge masks from local explanations. Our empirical observations using 7 edge
attribution methods demonstrate that, surprisingly, general eXplainable AI
methods outperform methods tailored to GNNs in terms of graph pruning
performance.

ÊëòË¶ÅÔºö‰ΩúÁÇ∫Ë©ï‰º∞ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Ëß£ÈáãÂìÅË≥™ÁöÑÁÜ±ÈñÄÂÆöÈáèÊåáÊ®ô‰πã‰∏ÄÔºå‰øùÁúüÂ∫¶Ë°°ÈáèÁßªÈô§Ëº∏ÂÖ•ÂúñÂΩ¢‰∏≠‰∏çÈáçË¶ÅÈÉ®ÂàÜÂæåËº∏Âá∫ÁöÑÂ∑ÆÁï∞„ÄÇ‰øùÁúüÂ∫¶Âª£Ê≥õ‰ΩøÁî®ÔºåÂõ†ÁÇ∫ÂÖ∂Áõ¥ËßÄÁöÑËß£ÈáãÊòØÔºåÁï∂ÂæûËß£Èáã‰∏≠ÁßªÈô§Ë¢´Ë™çÁÇ∫‰∏çÈáçË¶ÅÁöÑÁâπÂæµÊôÇÔºåÂ∫ïÂ±§Ê®°ÂûãÊáâÁî¢ÁîüÈ°û‰ººÁöÑÈ†êÊ∏¨„ÄÇÈÄôÂºïÁôº‰∫Ü‰∏ÄÂÄãËá™ÁÑ∂ÁöÑÂïèÈ°åÔºö„Äå‰øùÁúüÂ∫¶ÊòØÂê¶ÊúÉÁÇ∫ÂúñÂΩ¢Ââ™ÊûùË™òÁôº‰∏ÄÂÄãÂÖ®Â±Ä (Ëªü) Êé©Á¢ºÔºü„ÄçÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊó®Âú®Êé¢Á¥¢‰øùÁúüÂ∫¶Ê∏¨ÈáèÂú®ÂúñÂΩ¢Ââ™Êûù‰∏≠ÁöÑÊΩõÂäõÔºåÊúÄÁµÇÂ¢ûÂº∑ GNN Ê®°Âûã‰ª•ÊèêÈ´òÊïàÁéá„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰øùÁúüÂ∫¶$^-$- ÂïüÁôºÂâ™Êûù (FiP)Ôºå‰∏ÄÂÄãÂæûÂ±ÄÈÉ®Ëß£ÈáãÊßãÈÄ†ÂÖ®Â±ÄÈÇäÁ∑£Êé©Á¢ºÁöÑÊúâÊïàÊ°ÜÊû∂„ÄÇÊàëÂÄë‰ΩøÁî® 7 Á®ÆÈÇäÁ∑£Ê≠∏Âõ†ÊñπÊ≥ïÁöÑÁ∂ìÈ©óËßÄÂØüË°®ÊòéÔºå‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºå‰∏ÄËà¨ÂèØËß£ÈáãÁöÑ AI ÊñπÊ≥ïÂú®ÂúñÂΩ¢Ââ™ÊûùÊïàËÉΩÊñπÈù¢ÂÑ™ÊñºÈáùÂ∞ç GNN ÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇ

##### **GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation**
2406.11503v1 by Shihao Cai, Keqin Bao, Hangyu Guo, Jizhi Zhang, Jun Song, Bo Zheng

Large language models have seen widespread adoption in math problem-solving.
However, in geometry problems that usually require visual aids for better
understanding, even the most advanced multi-modal models currently still face
challenges in effectively using image information. High-quality data is crucial
for enhancing the geometric capabilities of multi-modal models, yet existing
open-source datasets and related efforts are either too challenging for direct
model learning or suffer from misalignment between text and images. To overcome
this issue, we introduce a novel pipeline that leverages GPT-4 and GPT-4V to
generate relatively basic geometry problems with aligned text and images,
facilitating model learning. We have produced a dataset of 4.9K geometry
problems and combined it with 19K open-source data to form our GeoGPT4V
dataset. Experimental results demonstrate that the GeoGPT4V dataset
significantly improves the geometry performance of various models on the
MathVista and MathVision benchmarks. The code is available at
https://github.com/Lanyu0303/GeoGPT4V_Project

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ∑≤Ë¢´Âª£Ê≥õÊé°Áî®ÊñºÊï∏Â≠∏ÂïèÈ°åÊ±ÇËß£„ÄÇ
ÁÑ∂ËÄåÔºåÂú®ÈÄöÂ∏∏ÈúÄË¶ÅË¶ñË¶∫ËºîÂä©Â∑•ÂÖ∑ÊâçËÉΩÊõ¥‰Ω≥ÁêÜËß£ÁöÑÂπæ‰ΩïÂïèÈ°å‰∏≠ÔºåÂç≥‰ΩøÊòØÊúÄÂÖàÈÄ≤ÁöÑÂ§öÊ®°ÊÖãÊ®°ÂûãÁõÆÂâç‰ªçÈù¢Ëá®ÊúâÊïà‰ΩøÁî®ÂΩ±ÂÉèË≥áË®äÁöÑÊåëÊà∞„ÄÇÈ´òÂìÅË≥™Ë≥áÊñôÂ∞çÊñºÊèêÂçáÂ§öÊ®°ÊÖãÊ®°ÂûãÁöÑÂπæ‰ΩïËÉΩÂäõËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁèæÊúâÁöÑÈñãÊ∫êË≥áÊñôÈõÜÂíåÁõ∏ÈóúÂ∑•‰ΩúÔºåË¶Å‰∏çÂ∞±ÊòØÂ∞çÊ®°ÂûãÂ≠∏ÁøíËÄåË®ÄÈÅéÊñºÂõ∞Èõ£ÔºåË¶Å‰∏çÂ∞±ÊòØÊñáÊú¨ÂíåÂΩ±ÂÉè‰πãÈñìÂ≠òÂú®ÈåØ‰ΩçÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÁÆ°ÈÅìÔºåÂà©Áî® GPT-4 Âíå GPT-4V ‰æÜÁî¢ÁîüÂÖ∑ÊúâÂ∞çÈΩäÊñáÊú¨ÂíåÂΩ±ÂÉèÁöÑÁõ∏Â∞çÂü∫Á§éÁöÑÂπæ‰ΩïÂïèÈ°åÔºå‰øÉÈÄ≤Ê®°ÂûãÂ≠∏Áøí„ÄÇÊàëÂÄëÂ∑≤Á∂ìÁî¢Áîü‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 4.9K ÂÄãÂπæ‰ΩïÂïèÈ°åÁöÑË≥áÊñôÈõÜÔºå‰∏¶Â∞áÂÖ∂Ëàá 19K ÂÄãÈñãÊ∫êË≥áÊñôÁµêÂêàÔºå‰ª•ÂΩ¢ÊàêÊàëÂÄëÁöÑ GeoGPT4V Ë≥áÊñôÈõÜ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåGeoGPT4V Ë≥áÊñôÈõÜÈ°ØËëóÊèêÂçá‰∫ÜÂêÑÁ®ÆÊ®°ÂûãÂú® MathVista Âíå MathVision Âü∫Ê∫ñ‰∏äÁöÑÂπæ‰ΩïÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Lanyu0303/GeoGPT4V_Project ÂèñÂæó

##### **Teleporter Theory: A General and Simple Approach for Modeling Cross-World Counterfactual Causality**
2406.11501v2 by Jiangmeng Li, Bin Qin, Qirui Ji, Yi Li, Wenwen Qiang, Jianwen Cao, Fanjiang Xu

Leveraging the development of structural causal model (SCM), researchers can
establish graphical models for exploring the causal mechanisms behind machine
learning techniques. As the complexity of machine learning applications rises,
single-world interventionism causal analysis encounters theoretical adaptation
limitations. Accordingly, cross-world counterfactual approach extends our
understanding of causality beyond observed data, enabling hypothetical
reasoning about alternative scenarios. However, the joint involvement of
cross-world variables, encompassing counterfactual variables and real-world
variables, challenges the construction of the graphical model. Twin network is
a subtle attempt, establishing a symbiotic relationship, to bridge the gap
between graphical modeling and the introduction of counterfactuals albeit with
room for improvement in generalization. In this regard, we demonstrate the
theoretical breakdowns of twin networks in certain cross-world counterfactual
scenarios. To this end, we propose a novel teleporter theory to establish a
general and simple graphical representation of counterfactuals, which provides
criteria for determining teleporter variables to connect multiple worlds. In
theoretical application, we determine that introducing the proposed teleporter
theory can directly obtain the conditional independence between counterfactual
variables and real-world variables from the cross-world SCM without requiring
complex algebraic derivations. Accordingly, we can further identify
counterfactual causal effects through cross-world symbolic derivation. We
demonstrate the generality of the teleporter theory to the practical
application. Adhering to the proposed theory, we build a plug-and-play module,
and the effectiveness of which are substantiated by experiments on benchmarks.

ÊëòË¶ÅÔºö<paragraph>ËóâÁî±ÁµêÊßãÂõ†ÊûúÊ®°Âûã (SCM) ÁöÑÁôºÂ±ïÔºåÁ†îÁ©∂‰∫∫Âì°ÂèØ‰ª•Âª∫Á´ãÂúñÂΩ¢Ê®°ÂûãÔºåÁî®‰ª•Êé¢Á¥¢Ê©üÂô®Â≠∏ÁøíÊäÄË°ìËÉåÂæåÁöÑÂõ†ÊûúÊ©üÂà∂„ÄÇÈö®ËëóÊ©üÂô®Â≠∏ÁøíÊáâÁî®Ë§áÈõúÂ∫¶ÁöÑÊèêÂçáÔºåÂñÆ‰∏Ä‰∏ñÁïå‰ªãÂÖ•‰∏ªÁæ©Âõ†ÊûúÂàÜÊûêÈÅ≠ÈÅá‰∫ÜÁêÜË´ñÈÅ©ÊáâÈôêÂà∂„ÄÇÂõ†Ê≠§ÔºåË∑®‰∏ñÁïåÂèç‰∫ãÂØ¶ÊñπÊ≥ïÂ∞áÊàëÂÄëÂ∞çÂõ†ÊûúÈóú‰øÇÁöÑÁêÜËß£Âª∂‰º∏Ëá≥ËßÄÂØüË≥áÊñô‰πãÂ§ñÔºåÈÄ≤ËÄåÂ∞çÊõø‰ª£ÊÉÖÂ¢ÉÈÄ≤Ë°åÂÅáË®≠ÊÄßÊé®ÁêÜ„ÄÇÁÑ∂ËÄåÔºåË∑®‰∏ñÁïåËÆäÊï∏ÁöÑÂÖ±ÂêåÂèÉËàáÔºåÂåÖÂê´Âèç‰∫ãÂØ¶ËÆäÊï∏ËàáÁúüÂØ¶‰∏ñÁïåËÆäÊï∏ÔºåÂ∞çÂúñÂΩ¢Ê®°ÂûãÁöÑÂª∫ÊßãÊèêÂá∫‰∫ÜÊåëÊà∞„ÄÇÈõôÁ∂≤Ë∑ØÊòØ‰∏ÄÂÄãÂ∑ßÂ¶ôÁöÑÂòóË©¶ÔºåÂª∫Á´ã‰∫ÜÂÖ±ÁîüÈóú‰øÇÔºåÁî®‰ª•ÂΩåÂêàÂúñÂΩ¢Âª∫Ê®°ËàáÂèç‰∫ãÂØ¶Âºï‰ªã‰πãÈñìÁöÑÈ¥ªÊ∫ùÔºåÂÑòÁÆ°Âú®Ê¶ÇÂåñÊñπÈù¢‰ªçÊúâÊîπÈÄ≤Á©∫Èñì„ÄÇÊúâÈëëÊñºÊ≠§ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈõôÁ∂≤Ë∑ØÂú®ÁâπÂÆöË∑®‰∏ñÁïåÂèç‰∫ãÂØ¶ÊÉÖÂ¢É‰∏≠ÁöÑÁêÜË´ñÊÄßÁº∫Èô∑„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÇ≥ÈÄÅÁêÜË´ñÔºåÁî®‰ª•Âª∫Á´ãÂèç‰∫ãÂØ¶ÁöÑ‰∏ÄËà¨‰∏îÁ∞°ÂñÆÁöÑÂúñÂΩ¢Ë°®Á§∫ÔºåÈÄôÊèê‰æõ‰∫ÜÂà§ÂÆöÂÇ≥ÈÄÅËÆäÊï∏‰ª•ÈÄ£ÁµêÂ§öÂÄã‰∏ñÁïåÁöÑÊ∫ñÂâá„ÄÇÂú®ÁêÜË´ñÊáâÁî®‰∏≠ÔºåÊàëÂÄëÂà§ÂÆöÂ∞éÂÖ•ÊâÄÊèêÂá∫ÁöÑÂÇ≥ÈÄÅÁêÜË´ñÔºåÂèØ‰ª•Áõ¥Êé•ÂæûË∑®‰∏ñÁïå SCM ‰∏≠ÂèñÂæóÂèç‰∫ãÂØ¶ËÆäÊï∏ËàáÁúüÂØ¶‰∏ñÁïåËÆäÊï∏‰πãÈñìÁöÑÊ¢ù‰ª∂Áç®Á´ãÊÄßÔºåËÄåÁÑ°ÈúÄË§áÈõúÁöÑ‰ª£Êï∏Êé®Â∞é„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéË∑®‰∏ñÁïåÁ¨¶ËôüÊé®Â∞é‰æÜË≠òÂà•Âèç‰∫ãÂØ¶Âõ†ÊûúÊïàÊáâ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂÇ≥ÈÄÅÁêÜË´ñÂ∞çÂØ¶ÈöõÊáâÁî®ÁöÑÊôÆÈÅçÊÄß„ÄÇÈÅµÂæ™ÊâÄÊèêÂá∫ÁöÑÁêÜË´ñÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂç≥ÊèíÂç≥Áî®ÁöÑÊ®°ÁµÑÔºåËÄåÂÖ∂ÊïàËÉΩÂ∑≤ÈÄèÈÅéÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÂØ¶È©óÁç≤ÂæóË≠âÂØ¶„ÄÇ</paragraph>

##### **CrAM: Credibility-Aware Attention Modification in LLMs for Combating Misinformation in RAG**
2406.11497v1 by Boyi Deng, Wenjie Wang, Fengbin Zhu, Qifan Wang, Fuli Feng

Retrieval-Augmented Generation (RAG) can alleviate hallucinations of Large
Language Models (LLMs) by referencing external documents. However, the
misinformation in external documents may mislead LLMs' generation. To address
this issue, we explore the task of "credibility-aware RAG", in which LLMs
automatically adjust the influence of retrieved documents based on their
credibility scores to counteract misinformation. To this end, we introduce a
plug-and-play method named $\textbf{Cr}$edibility-aware $\textbf{A}$ttention
$\textbf{M}$odification (CrAM). CrAM identifies influential attention heads in
LLMs and adjusts their attention scores based on the credibility of the
documents, thereby reducing the impact of low-credibility documents.
Experiments on Natual Questions and TriviaQA using Llama2-13B, Llama3-8B, and
Qwen-7B show that CrAM improves the RAG performance of LLMs against
misinformation pollution by over 20%, even surpassing supervised fine-tuning
methods.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ËÉΩÈÄèÈÅéÂèÉÁÖßÂ§ñÈÉ®Êñá‰ª∂Ê∏õËºïÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂπªË¶∫„ÄÇÁÑ∂ËÄåÔºåÂ§ñÈÉ®Êñá‰ª∂‰∏≠ÁöÑÈåØË™§Ë≥áË®äÂèØËÉΩÊúÉË™§Â∞é LLM ÁöÑÁîüÊàê„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü„ÄåÂèØ‰ø°Â∫¶ÊÑüÁü• RAG„ÄçÁöÑ‰ªªÂãôÔºåÂÖ∂‰∏≠ LLM ÊúÉÊ†πÊìöÊ™¢Á¥¢Êñá‰ª∂ÁöÑÂèØ‰ø°Â∫¶Ë©ïÂàÜËá™ÂãïË™øÊï¥Ê™¢Á¥¢Êñá‰ª∂ÁöÑÂΩ±ÈüøÂäõÔºå‰ª•Â∞çÊäóÈåØË™§Ë≥áË®ä„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁ®±ÁÇ∫ $\textbf{Cr}$edibility-aware $\textbf{A}$ttention $\textbf{M}$odification (CrAM) ÁöÑÂç≥ÊèíÂç≥Áî®ÊñπÊ≥ï„ÄÇCrAM ÊúÉÊâæÂá∫ LLM ‰∏≠ÊúâÂΩ±ÈüøÂäõÁöÑÊ≥®ÊÑèÂäõÈ†≠ÈÉ®Ôºå‰∏¶Ê†πÊìöÊñá‰ª∂ÁöÑÂèØ‰ø°Â∫¶Ë™øÊï¥ÂÖ∂Ê≥®ÊÑèÂäõË©ïÂàÜÔºåÂæûËÄåÈôç‰Ωé‰ΩéÂèØ‰ø°Â∫¶Êñá‰ª∂ÁöÑÂΩ±Èüø„ÄÇÂú®‰ΩøÁî® Llama2-13B„ÄÅLlama3-8B Âíå Qwen-7B ÈÄ≤Ë°åÁöÑ Natual Questions Âíå TriviaQA ÂØ¶È©ó‰∏≠ÔºåÁµêÊûúÈ°ØÁ§∫ CrAM Â∞á LLM Âú®Â∞çÊäóÈåØË™§Ë≥áË®äÊ±°ÊüìÊñπÈù¢ÁöÑ RAG ÊïàËÉΩÊèêÂçá‰∫Ü 20% ‰ª•‰∏äÔºåÁîöËá≥Ë∂ÖË∂ä‰∫ÜÁõ£Áù£ÂæÆË™øÊñπÊ≥ï„ÄÇ

##### **Analysing zero-shot temporal relation extraction on clinical notes using temporal consistency**
2406.11486v1 by Vasiliki Kougia, Anastasiia Sedova, Andreas Stephan, Klim Zaporojets, Benjamin Roth

This paper presents the first study for temporal relation extraction in a
zero-shot setting focusing on biomedical text. We employ two types of prompts
and five LLMs (GPT-3.5, Mixtral, Llama 2, Gemma, and PMC-LLaMA) to obtain
responses about the temporal relations between two events. Our experiments
demonstrate that LLMs struggle in the zero-shot setting performing worse than
fine-tuned specialized models in terms of F1 score, showing that this is a
challenging task for LLMs. We further contribute a novel comprehensive temporal
analysis by calculating consistency scores for each LLM. Our findings reveal
that LLMs face challenges in providing responses consistent to the temporal
properties of uniqueness and transitivity. Moreover, we study the relation
between the temporal consistency of an LLM and its accuracy and whether the
latter can be improved by solving temporal inconsistencies. Our analysis shows
that even when temporal consistency is achieved, the predictions can remain
inaccurate.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫Á¨¨‰∏ÄÂÄãÂ∞àÊ≥®ÊñºÁîüÁâ©ÈÜ´Â≠∏ÊñáÊú¨ÁöÑÈõ∂Ê¨°Â≠∏Áøí‰∏≠ÊôÇÈñìÈóú‰øÇËêÉÂèñÁ†îÁ©∂„ÄÇÊàëÂÄëÊé°Áî®ÂÖ©Á®ÆÊèêÁ§∫Âíå‰∫îÁ®Æ LLMÔºàGPT-3.5„ÄÅMixtral„ÄÅLlama 2„ÄÅGemma Âíå PMC-LLaMAÔºâ‰æÜÂèñÂæóÈóúÊñºÂÖ©ÂÄã‰∫ã‰ª∂‰πãÈñìÊôÇÈñìÈóú‰øÇÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÔºåLLM Âú®Èõ∂Ê¨°Â≠∏Áøí‰∏≠Ë°®Áèæ‰∏ç‰Ω≥ÔºåÂú® F1 ÂàÜÊï∏ÊñπÈù¢Ë°®ÁèæÊØîÂæÆË™øÁöÑÂ∞àÊ•≠Ê®°ÂûãÂ∑ÆÔºåÈÄôË°®Á§∫ÈÄôÂ∞ç LLM ‰æÜË™™ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë≤¢Áçª‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÖ®Èù¢ÊôÇÈñìÂàÜÊûêÔºåËóâÁî±Ë®àÁÆóÊØèÂÄã LLM ÁöÑ‰∏ÄËá¥ÊÄßÂàÜÊï∏„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåLLM Âú®Êèê‰æõËàáÂîØ‰∏ÄÊÄßÂíåÈÅûÁßªÊÄßÊôÇÈñìÂ±¨ÊÄß‰∏ÄËá¥ÁöÑÂõûÊáâÊôÇÈù¢Ëá®ÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü LLM ÁöÑÊôÇÈñì‰∏ÄËá¥ÊÄßËàáÂÖ∂Ê∫ñÁ¢∫ÊÄß‰πãÈñìÁöÑÈóú‰øÇÔºå‰ª•ÂèäÂæåËÄÖÊòØÂê¶ËÉΩËóâÁî±Ëß£Ê±∫ÊôÇÈñì‰∏ç‰∏ÄËá¥ÊÄßËÄåÂæóÂà∞ÊîπÂñÑ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂç≥‰ΩøÈÅîÂà∞‰∫ÜÊôÇÈñì‰∏ÄËá¥ÊÄßÔºåÈ†êÊ∏¨‰ªçÂèØËÉΩ‰∏çÊ∫ñÁ¢∫„ÄÇ

##### **Constrained Reinforcement Learning with Average Reward Objective: Model-Based and Model-Free Algorithms**
2406.11481v1 by Vaneet Aggarwal, Washim Uddin Mondal, Qinbo Bai

Reinforcement Learning (RL) serves as a versatile framework for sequential
decision-making, finding applications across diverse domains such as robotics,
autonomous driving, recommendation systems, supply chain optimization, biology,
mechanics, and finance. The primary objective in these applications is to
maximize the average reward. Real-world scenarios often necessitate adherence
to specific constraints during the learning process.
  This monograph focuses on the exploration of various model-based and
model-free approaches for Constrained RL within the context of average reward
Markov Decision Processes (MDPs). The investigation commences with an
examination of model-based strategies, delving into two foundational methods -
optimism in the face of uncertainty and posterior sampling. Subsequently, the
discussion transitions to parametrized model-free approaches, where the
primal-dual policy gradient-based algorithm is explored as a solution for
constrained MDPs. The monograph provides regret guarantees and analyzes
constraint violation for each of the discussed setups.
  For the above exploration, we assume the underlying MDP to be ergodic.
Further, this monograph extends its discussion to encompass results tailored
for weakly communicating MDPs, thereby broadening the scope of its findings and
their relevance to a wider range of practical scenarios.

ÊëòË¶ÅÔºöÂº∑ÂåñÂ≠∏Áøí (RL) ÊòØ‰∏ÄÂÄãÈÄöÁî®ÁöÑÊ°ÜÊû∂ÔºåÂèØÁî®ÊñºÈ†ÜÂ∫èÊ±∫Á≠ñÂà∂ÂÆöÔºå‰∏¶Âú®Ê©üÂô®‰∫∫ÊäÄË°ì„ÄÅËá™ÂãïÈßïÈßõ„ÄÅÊé®Ëñ¶Á≥ªÁµ±„ÄÅ‰æõÊáâÈèàÊúÄ‰Ω≥Âåñ„ÄÅÁîüÁâ©Â≠∏„ÄÅÂäõÂ≠∏ÂíåÈáëËûçÁ≠â‰∏çÂêåÈ†òÂüü‰∏≠ÊâæÂà∞ÊáâÁî®„ÄÇÈÄô‰∫õÊáâÁî®‰∏≠ÁöÑ‰∏ªË¶ÅÁõÆÊ®ôÊòØÊúÄÂ§ßÂåñÂπ≥ÂùáÁçéÂãµ„ÄÇÁèæÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØÈÄöÂ∏∏ÈúÄË¶ÅÂú®Â≠∏ÁøíÈÅéÁ®ã‰∏≠ÈÅµÂÆàÁâπÂÆöÁöÑÁ¥ÑÊùü„ÄÇ
Êú¨Â∞àÈ°åÂÅ¥ÈáçÊñºÊé¢Á¥¢ÂêÑÁ®ÆÂü∫ÊñºÊ®°ÂûãÂíåÁÑ°Ê®°ÂûãÁöÑÊñπÊ≥ïÔºå‰ª•Âú®Âπ≥ÂùáÁçéÂãµÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (MDP) ÁöÑËÉåÊôØ‰∏ãÈÄ≤Ë°åÁ¥ÑÊùü RL„ÄÇË™øÊü•ÂæûÂ∞çÂü∫ÊñºÊ®°ÂûãÁöÑÁ≠ñÁï•ÁöÑÊ™¢Êü•ÈñãÂßãÔºåÊ∑±ÂÖ•Êé¢Ë®éÂÖ©Á®ÆÂü∫Á§éÊñπÊ≥ï‚Äî‚ÄîÈù¢Â∞ç‰∏çÁ¢∫ÂÆöÊÄßÂíåÂæåÈ©óÊäΩÊ®£ÁöÑÊ®ÇËßÄ‰∏ªÁæ©„ÄÇÈö®ÂæåÔºåË®éË´ñÈÅéÊ∏°Âà∞ÂèÉÊï∏ÂåñÁöÑÁÑ°Ê®°ÂûãÊñπÊ≥ïÔºåÂÖ∂‰∏≠Âü∫ÊñºÂéüÂßãÂ∞çÂÅ∂Á≠ñÁï•Ê¢ØÂ∫¶ÁöÑÊºîÁÆóÊ≥ïË¢´Êé¢Á¥¢ÁÇ∫Á¥ÑÊùü MDP ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊú¨Â∞àÈ°åÊèê‰æõ‰∫ÜÂæåÊÇî‰øùË≠âÔºå‰∏¶ÂàÜÊûê‰∫ÜÊØèÂÄãË®éË´ñË®≠ÂÆöÁöÑÁ¥ÑÊùüÈÅïË¶è„ÄÇ
Â∞çÊñº‰∏äËø∞Êé¢Á¥¢ÔºåÊàëÂÄëÂÅáË®≠Âü∫Á§é MDP ÊòØ ergodic„ÄÇÊ≠§Â§ñÔºåÊú¨Â∞àÈ°åÂ∞áÂÖ∂Ë®éË´ñÊì¥Â±ïÂà∞ÂåÖÂê´ÈáùÂ∞çÂº±ÈÄö‰ø° MDP ÈáèË∫´ÊâìÈÄ†ÁöÑÁµêÊûúÔºåÂæûËÄåÊì¥Â§ß‰∫ÜÂÖ∂ÁôºÁèæÁöÑÁØÑÂúçÂèäÂÖ∂ËàáÊõ¥Âª£Ê≥õÂØ¶ÈöõÂ†¥ÊôØÁõ∏ÈóúÊÄß„ÄÇ

##### **Vocabulary Expansion for Low-resource Cross-lingual Transfer**
2406.11477v1 by Atsuki Yamaguchi, Aline Villavicencio, Nikolaos Aletras

Large language models (LLMs) have shown remarkable capabilities in many
languages beyond English. Yet, LLMs require more inference steps when
generating non-English text due to their reliance on English-centric
tokenizers, vocabulary, and pre-training data, resulting in higher usage costs
to non-English speakers. Vocabulary expansion with target language tokens is a
widely used cross-lingual vocabulary adaptation approach to remedy this issue.
Despite its effectiveness in inference speedup, the majority of previous work
has focused on high-resource settings assuming access to a substantial amount
of target language data to effectively initialize the embeddings of the new
tokens and adapt the LLM to the target language. However, vocabulary expansion
for LLMs in low-resource settings (i.e. languages and compute) has yet to be
explored. In this paper, we investigate sample-efficient adaptation strategies
from different angles, including target vocabulary size and initialization
methods, and the amount of target data available for adaptation. Extensive
experiments across typologically diverse languages, tasks and models show that
simpler heuristic-based embedding initialization is more efficient and robust
to changes in target vocabulary size and adaptation data in low-resource
settings, outperforming a popular random initialization and a more
sophisticated state-of-the-art approach that relies on external data and model.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®Ëã±Ë™û‰ª•Â§ñÁöÑË®±Â§öË™ûË®Ä‰∏≠Â±ïÁèæÂá∫ÂçìË∂äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº‰æùË≥¥‰ª•Ëã±Ë™ûÁÇ∫‰∏≠ÂøÉÁöÑÊ®ôË®òÂåñÂô®„ÄÅË©ûÂΩôÂíåÈ†êË®ìÁ∑¥Ë≥áÊñôÔºåLLM Âú®Áî¢ÁîüÈùûËã±Ë™ûÊñáÊú¨ÊôÇÈúÄË¶ÅÊõ¥Â§öÁöÑÊé®Ë´ñÊ≠•È©üÔºåÂ∞éËá¥ÈùûËã±Ë™û‰ΩøÁî®ËÄÖ‰ΩøÁî®ÊàêÊú¨ËºÉÈ´ò„ÄÇ‰ΩøÁî®ÁõÆÊ®ôË™ûË®ÄÊ®ôË®òÊì¥ÂÖÖË©ûÂΩôÊòØ‰∏ÄÁ®ÆÂª£Ê≥õ‰ΩøÁî®ÁöÑË∑®Ë™ûË®ÄË©ûÂΩôÈÅ©ÊáâÊñπÊ≥ïÔºåÁî®‰æÜËß£Ê±∫Ê≠§ÂïèÈ°å„ÄÇÂÑòÁÆ°ÂÖ∂Âú®Êé®Ë´ñÂä†ÈÄüÊñπÈù¢ÂæàÊúâÊïàÔºå‰ΩÜÂ§ßÂ§öÊï∏ÂÖàÂâçÁöÑÁ†îÁ©∂ÈÉΩÈõÜ‰∏≠Âú®ÂÅáË®≠ÂèØ‰ª•Â≠òÂèñÂ§ßÈáèÁõÆÊ®ôË™ûË®ÄË≥áÊñôÁöÑÈ´òË≥áÊ∫êË®≠ÂÆöÔºå‰ª•ÊúâÊïàÂàùÂßãÂåñÊñ∞Ê®ôË®òÁöÑÂµåÂÖ•‰∏¶Â∞á LLM ÈÅ©ÊáâÂà∞ÁõÆÊ®ôË™ûË®Ä„ÄÇÁÑ∂ËÄåÔºåÂú®‰ΩéË≥áÊ∫êË®≠ÂÆöÔºà‰æãÂ¶ÇË™ûË®ÄÂíåÈÅãÁÆóÔºâ‰∏≠ÈáùÂ∞ç LLM Êì¥ÂÖÖË©ûÂΩôÂ∞öÊú™Ë¢´Êé¢Ë®é„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂæû‰∏çÂêåÁöÑËßíÂ∫¶Êé¢Ë®éÊ®£Êú¨ÊúâÊïàÈÅ©ÊáâÁ≠ñÁï•ÔºåÂåÖÊã¨ÁõÆÊ®ôË©ûÂΩôÂ§ßÂ∞èÂíåÂàùÂßãÂåñÊñπÊ≥ïÔºå‰ª•ÂèäÂèØÁî®ÊñºÈÅ©ÊáâÁöÑÁõÆÊ®ôË≥áÊñôÈáè„ÄÇË∑®ÂûãÊÖãÂ§öÊ®£Ë™ûË®Ä„ÄÅ‰ªªÂãôÂíåÊ®°ÂûãÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåÂú®‰ΩéË≥áÊ∫êË®≠ÂÆö‰∏≠ÔºåÂü∫ÊñºÂïüÁôºÂºèÁöÑÂµåÂÖ•ÂàùÂßãÂåñËºÉÁÇ∫ÊúâÊïà‰∏îÂº∑ÂÅ•Ôºå‰∏îËÉΩÂõ†ÊáâÁõÆÊ®ôË©ûÂΩôÂ§ßÂ∞èÂíåÈÅ©ÊáâË≥áÊñôÁöÑËÆäÂåñÔºåÂÑ™ÊñºÊµÅË°åÁöÑÈö®Ê©üÂàùÂßãÂåñÂíå‰æùË≥¥Â§ñÈÉ®Ë≥áÊñôÂíåÊ®°ÂûãÁöÑÊõ¥Á≤æÂØÜÁöÑÊúÄÊñ∞ÊñπÊ≥ï„ÄÇ

##### **How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment**
2406.11474v1 by Heyan Huang, Yinghao Li, Huashan Sun, Yu Bai, Yang Gao

Recent studies have demonstrated that In-Context Learning (ICL), through the
use of specific demonstrations, can align Large Language Models (LLMs) with
human preferences known as In-Context Alignment (ICA), indicating that models
can comprehend human instructions without requiring parameter adjustments.
However, the exploration of the mechanism and applicability of ICA remains
limited. In this paper, we begin by dividing the context text used in ICA into
three categories: format, system prompt, and example. Through ablation
experiments, we investigate the effectiveness of each part in enabling ICA to
function effectively. We then examine how variants in these parts impact the
model's alignment performance. Our findings indicate that the example part is
crucial for enhancing the model's alignment capabilities, with changes in
examples significantly affecting alignment performance. We also conduct a
comprehensive evaluation of ICA's zero-shot capabilities in various alignment
tasks. The results indicate that compared to parameter fine-tuning methods, ICA
demonstrates superior performance in knowledge-based tasks and tool-use tasks.
However, it still exhibits certain limitations in areas such as multi-turn
dialogues and instruction following.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÈÄöËøá‰ΩøÁî®ÁâπÂÆöÊºîÁ§∫ÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π† (ICL) ÂèØ‰ª•Â∞ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏éÁß∞‰∏∫‰∏ä‰∏ãÊñáÂØπÈΩê (ICA) ÁöÑ‰∫∫Á±ªÂÅèÂ•ΩÁõ∏ÁªìÂêàÔºåË°®ÊòéÊ®°ÂûãÂèØ‰ª•ÁêÜËß£‰∫∫Á±ªÊåá‰ª§ËÄåÊó†ÈúÄÂèÇÊï∞Ë∞ÉÊï¥„ÄÇ
ÁÑ∂ËÄåÔºåÂØπ ICA Êú∫Âà∂ÂíåÈÄÇÁî®ÊÄßÁöÑÊé¢Á¥¢‰ªçÁÑ∂ÊúâÈôê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨È¶ñÂÖàÂ∞Ü ICA ‰∏≠‰ΩøÁî®ÁöÑ‰∏ä‰∏ãÊñáÊñáÊú¨ÂàÜ‰∏∫‰∏âÁ±ªÔºöÊ†ºÂºè„ÄÅÁ≥ªÁªüÊèêÁ§∫ÂíåÁ§∫‰æã„ÄÇÈÄöËøáÊ∂àËûçÂÆûÈ™åÔºåÊàë‰ª¨Á†îÁ©∂‰∫ÜÊØèÈÉ®ÂàÜÂú®‰Ωø ICA ÊúâÊïàËøêË°å‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ÂêéÊàë‰ª¨Á†îÁ©∂Ëøô‰∫õÈÉ®ÂàÜ‰∏≠ÁöÑÂèò‰ΩìÂ¶Ç‰ΩïÂΩ±ÂìçÊ®°ÂûãÁöÑÂØπÈΩêÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÁ§∫‰æãÈÉ®ÂàÜÂØπ‰∫éÂ¢ûÂº∫Ê®°ÂûãÁöÑÂØπÈΩêËÉΩÂäõËá≥ÂÖ≥ÈáçË¶ÅÔºåÁ§∫‰æã‰∏≠ÁöÑÂèòÂåñ‰ºöÊòæÁùÄÂΩ±ÂìçÂØπÈΩêÊÄßËÉΩ„ÄÇÊàë‰ª¨ËøòÂØπ ICA Âú®ÂêÑÁßçÂØπÈΩê‰ªªÂä°‰∏≠ÁöÑÈõ∂Ê†∑Êú¨ËÉΩÂäõËøõË°å‰∫ÜÂÖ®Èù¢ËØÑ‰º∞„ÄÇÁªìÊûúË°®ÊòéÔºå‰∏éÂèÇÊï∞ÂæÆË∞ÉÊñπÊ≥ïÁõ∏ÊØîÔºåICA Âú®Âü∫‰∫éÁü•ËØÜÁöÑ‰ªªÂä°ÂíåÂ∑•ÂÖ∑‰ΩøÁî®‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫‰ºòÂºÇÁöÑÊÄßËÉΩ„ÄÇ
ÁÑ∂ËÄåÔºåÂÆÉÂú®Â§öËΩÆÂØπËØùÂíåÊåá‰ª§ÈÅµÂæ™Á≠âÈ¢ÜÂüü‰ªçÁÑ∂Ë°®Áé∞Âá∫‰∏ÄÂÆöÁöÑÂ±ÄÈôêÊÄß„ÄÇ

##### **Promises, Outlooks and Challenges of Diffusion Language Modeling**
2406.11473v1 by Justin Deschenaux, Caglar Gulcehre

The modern autoregressive Large Language Models (LLMs) have achieved
outstanding performance on NLP benchmarks, and they are deployed in the real
world. However, they still suffer from limitations of the autoregressive
training paradigm. For example, autoregressive token generation is notably slow
and can be prone to \textit{exposure bias}. The diffusion-based language models
were proposed as an alternative to autoregressive generation to address some of
these limitations. We evaluate the recently proposed Score Entropy Discrete
Diffusion (SEDD) approach and show it is a promising alternative to
autoregressive generation but it has some short-comings too. We empirically
demonstrate the advantages and challenges of SEDD, and observe that SEDD
generally matches autoregressive models in perplexity and on benchmarks such as
HellaSwag, Arc or WinoGrande. Additionally, we show that in terms of inference
latency, SEDD can be up to 4.5$\times$ more efficient than GPT-2. While SEDD
allows conditioning on tokens at abitrary positions, SEDD appears slightly
weaker than GPT-2 for conditional generation given short prompts. Finally, we
reproduced the main results from the original SEDD paper.

ÊëòË¶ÅÔºö<paragraph>Áèæ‰ª£ÁöÑËá™Ëø¥Ê≠∏Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú® NLP Âü∫Ê∫ñ‰∏äÂèñÂæó‰∫ÜÂÇëÂá∫ÁöÑË°®ÁèæÔºå‰∏¶Â∑≤ÈÉ®ÁΩ≤Âú®ÁèæÂØ¶‰∏ñÁïå‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄë‰ªçÁÑ∂ÂèóÂà∞Ëá™Ëø¥Ê≠∏Ë®ìÁ∑¥ÁØÑ‰æãÁöÑÈôêÂà∂„ÄÇ‰æãÂ¶ÇÔºåËá™Ëø¥Ê≠∏Ê¨äÊùñÁîüÊàêÊòéÈ°ØÁ∑©ÊÖ¢Ôºå‰∏îÂèØËÉΩÂÆπÊòìÂá∫Áèæ„ÄåÊõùÂÖâÂÅèÂ∑Æ„Äç„ÄÇÂü∫ÊñºÊì¥Êï£ÁöÑË™ûË®ÄÊ®°ÂûãË¢´ÊèêÂá∫‰ΩúÁÇ∫Ëá™Ëø¥Ê≠∏ÁîüÊàêÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰ª•Ëß£Ê±∫ÂÖ∂‰∏≠‰∏Ä‰∫õÈôêÂà∂„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÊúÄËøëÊèêÂá∫ÁöÑÂàÜÊï∏ÁÜµÈõ¢Êï£Êì¥Êï£ (SEDD) ÊñπÊ≥ïÔºå‰∏¶Â±ïÁ§∫ÂÆÉÊòØ‰∏ÄÁ®ÆÂæàÊúâÂâçÈÄîÁöÑËá™Ëø¥Ê≠∏ÁîüÊàêÊõø‰ª£ÊñπÊ°àÔºå‰ΩÜÂÆÉ‰πüÊúâ‰∏Ä‰∫õÁº∫Èªû„ÄÇÊàëÂÄë‰ª•Á∂ìÈ©óÊñπÂºèË≠âÊòé‰∫Ü SEDD ÁöÑÂÑ™ÈªûÂíåÊåëÊà∞Ôºå‰∏¶ËßÄÂØüÂà∞ SEDD ÈÄöÂ∏∏Âú®Âõ∞ÊÉëÂ∫¶Âíå HellaSwag„ÄÅArc Êàñ WinoGrande Á≠âÂü∫Ê∫ñ‰∏äËàáËá™Ëø¥Ê≠∏Ê®°ÂûãÁõ∏ÂåπÈÖç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÂú®Êé®ÁêÜÂª∂ÈÅ≤ÊñπÈù¢ÔºåSEDD ÁöÑÊïàÁéáÂèØ‰ª•ÊØî GPT-2 È´òÈÅî 4.5 ÂÄç„ÄÇÈõñÁÑ∂ SEDD ÂÖÅË®±Âú®‰ªªÊÑè‰ΩçÁΩÆÂ∞çÊ¨äÊùñÈÄ≤Ë°åÊ¢ù‰ª∂Ë®≠ÂÆöÔºå‰ΩÜÂ∞çÊñºÁµ¶ÂÆöÁ∞°Áü≠ÊèêÁ§∫ÁöÑÊ¢ù‰ª∂ÁîüÊàêÔºåSEDD ‰ºº‰πéÊØî GPT-2 Á®çÂº±„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈáçÁèæ‰∫ÜÂéüÂßã SEDD Ë´ñÊñá‰∏≠ÁöÑ‰∏ªË¶ÅÁµêÊûú„ÄÇ</paragraph>

##### **Automating Easy Read Text Segmentation**
2406.11464v1 by Jes√∫s Calleja, Thierry Etchegoyhen, David Ponce

Easy Read text is one of the main forms of access to information for people
with reading difficulties. One of the key characteristics of this type of text
is the requirement to split sentences into smaller grammatical segments, to
facilitate reading. Automated segmentation methods could foster the creation of
Easy Read content, but their viability has yet to be addressed. In this work,
we study novel methods for the task, leveraging masked and generative language
models, along with constituent parsing. We conduct comprehensive automatic and
human evaluations in three languages, analysing the strengths and weaknesses of
the proposed alternatives, under scarce resource limitations. Our results
highlight the viability of automated ER segmentation and remaining deficiencies
compared to expert-driven human segmentation.

ÊëòË¶ÅÔºöÁ∞°ÊòìÈñ±ËÆÄÊñáÊú¨ÊòØÈñ±ËÆÄÂõ∞Èõ£ËÄÖÁç≤ÂèñË≥áË®äÁöÑ‰∏ªË¶ÅÂΩ¢Âºè‰πã‰∏Ä„ÄÇÊ≠§È°ûÊñáÊú¨ÁöÑ‰∏ÄÂÄãÈóúÈçµÁâπÂæµÊòØÂøÖÈ†àÂ∞áÂè•Â≠êÊãÜÂàÜÊàêËºÉÂ∞èÁöÑË™ûÊ≥ïÂçÄÂ°äÔºå‰ª•Âà©Èñ±ËÆÄ„ÄÇËá™ÂãïÂåñÂàÜÊÆµÊñπÊ≥ïÊúâÂä©ÊñºÂª∫Á´ãÁ∞°ÊòìÈñ±ËÆÄÂÖßÂÆπÔºå‰ΩÜÂÖ∂ÂèØË°åÊÄßÂ∞öÊú™Áç≤ÂæóÊé¢Ë®é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂Ê≠§‰ªªÂãôÁöÑÊñ∞ÊñπÊ≥ïÔºåÂà©Áî®ÈÅÆËîΩÂºèÂíåÁîüÊàêÂºèË™ûË®ÄÊ®°ÂûãÔºå‰ª•ÂèäÊàêÂàÜÂàÜÊûê„ÄÇÊàëÂÄëÂú®‰∏âÁ®ÆË™ûË®Ä‰∏≠ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑËá™ÂãïÂåñÂíå‰∫∫Â∑•Ë©ï‰º∞ÔºåÂàÜÊûêÊâÄÊèêÂá∫Êõø‰ª£ÊñπÊ°àÂú®Ë≥áÊ∫êÊúâÈôêÊÉÖÊ≥Å‰∏ãÁöÑÂÑ™ÈªûÂíåÁº∫Èªû„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁ™ÅÈ°Ø‰∫ÜËá™ÂãïÂåñ ER ÂàÜÊÆµÁöÑÂèØË°åÊÄßÔºå‰ª•ÂèäËàáÂ∞àÂÆ∂‰∏ªÂ∞éÁöÑ‰∫∫Â∑•ÂàÜÊÆµÁõ∏ÊØî‰ªçÂ≠òÂú®ÁöÑ‰∏çË∂≥„ÄÇ

##### **TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation**
2406.11460v1 by Jinyuan Fang, Zaiqiao Meng, Craig Macdonald

Retrieval-augmented generation (RAG) offers an effective approach for
addressing question answering (QA) tasks. However, the imperfections of the
retrievers in RAG models often result in the retrieval of irrelevant
information, which could introduce noises and degrade the performance,
especially when handling multi-hop questions that require multiple steps of
reasoning. To enhance the multi-hop reasoning ability of RAG models, we propose
TRACE. TRACE constructs knowledge-grounded reasoning chains, which are a series
of logically connected knowledge triples, to identify and integrate supporting
evidence from the retrieved documents for answering questions. Specifically,
TRACE employs a KG Generator to create a knowledge graph (KG) from the
retrieved documents, and then uses an Autoregressive Reasoning Chain
Constructor to build reasoning chains. Experimental results on three multi-hop
QA datasets show that TRACE achieves an average performance improvement of up
to 14.03% compared to using all the retrieved documents. Moreover, the results
indicate that using reasoning chains as context, rather than the entire
documents, is often sufficient to correctly answer questions.

ÊëòË¶ÅÔºöÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) Êèê‰æõ‰∫Ü‰∏ÄÁßçËß£ÂÜ≥ÈóÆÈ¢òËß£Á≠î (QA) ‰ªªÂä°ÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåRAG Ê®°Âûã‰∏≠ÁöÑÊ£ÄÁ¥¢Âô®ÁöÑ‰∏çÂÆåÂñÑÈÄöÂ∏∏‰ºöÂØºËá¥Ê£ÄÁ¥¢Âà∞‰∏çÁõ∏ÂÖ≥ÁöÑËÆØÊÅØÔºåËøôÂèØËÉΩ‰ºöÂºïÂÖ•ÊùÇËÆØÂπ∂Èôç‰ΩéÊïàËÉΩÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÈúÄË¶ÅÂ§öÊ≠•È™§Êé®ÁêÜÁöÑÂ§öË∑≥ÈóÆÈ¢òÊó∂„ÄÇ‰∏∫‰∫ÜÂ¢ûÂº∫ RAG Ê®°ÂûãÁöÑÂ§öË∑≥Êé®ÁêÜËÉΩÂäõÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü TRACE„ÄÇTRACE ÊûÑÂª∫‰∫Ü‰ª•Áü•ËØÜ‰∏∫Âü∫Á°ÄÁöÑÊé®ÁêÜÈìæÔºåËøôÊòØ‰∏ÄÁ≥ªÂàóÈÄªËæëËøûÊé•ÁöÑÁü•ËØÜ‰∏âÂÖÉÁªÑÔºå‰ª•ËØÜÂà´ÂíåÊï¥ÂêàÊù•Ëá™Ê£ÄÁ¥¢Âà∞ÁöÑÊñá‰ª∂‰ª•ÂõûÁ≠îÈóÆÈ¢òÁöÑÊîØÊåÅËØÅÊçÆ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåTRACE ‰ΩøÁî® KG ÁîüÊàêÂô®‰ªéÊ£ÄÁ¥¢Âà∞ÁöÑÊñá‰ª∂‰∏≠ÂàõÂª∫Áü•ËØÜÂõæ (KG)ÔºåÁÑ∂Âêé‰ΩøÁî®Ëá™ÂõûÂΩíÊé®ÁêÜÈìæÊûÑÈÄ†Âô®ÊûÑÂª∫Êé®ÁêÜÈìæ„ÄÇÂú®‰∏â‰∏™Â§öË∑≥ QA Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏é‰ΩøÁî®ÊâÄÊúâÊ£ÄÁ¥¢Âà∞ÁöÑÊñá‰ª∂Áõ∏ÊØîÔºåTRACE ÁöÑÂπ≥ÂùáÊÄßËÉΩÊèêÂçáÈ´òËææ 14.03%„ÄÇÊ≠§Â§ñÔºåÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®Êé®ÁêÜÈìæ‰Ωú‰∏∫‰∏ä‰∏ãÊñáÔºåËÄå‰∏çÊòØÊï¥‰∏™Êñá‰ª∂ÔºåÈÄöÂ∏∏Ë∂≥‰ª•Ê≠£Á°ÆÂõûÁ≠îÈóÆÈ¢ò„ÄÇ

##### **Adaptive Reinforcement Learning Planning: Harnessing Large Language Models for Complex Information Extraction**
2406.11455v1 by Zepeng Ding, Ruiyang Ke, Wenhao Huang, Guochao Jiang, Yanda Li, Deqing Yang, Yanghua Xiao, Jiaqing Liang

Existing research on large language models (LLMs) shows that they can solve
information extraction tasks through multi-step planning. However, their
extraction behavior on complex sentences and tasks is unstable, emerging issues
such as false positives and missing elements. We observe that decomposing
complex extraction tasks and extracting them step by step can effectively
improve LLMs' performance, and the extraction orders of entities significantly
affect the final results of LLMs. This paper proposes a two-stage multi-step
method for LLM-based information extraction and adopts the RL framework to
execute the multi-step planning. We regard sequential extraction as a Markov
decision process, build an LLM-based extraction environment, design a decision
module to adaptively provide the optimal order for sequential entity extraction
on different sentences, and utilize the DDQN algorithm to train the decision
model. We also design the rewards and evaluation metrics suitable for the
extraction results of LLMs. We conduct extensive experiments on multiple public
datasets to demonstrate the effectiveness of our method in improving the
information extraction capabilities of LLMs.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁ†îÁ©∂Ë°®ÊòéÔºåÂÆÉÂÄëÂèØ‰ª•ÈÄèÈÅéÂ§öÊ≠•È©üË¶èÂäÉ‰æÜËß£Ê±∫Ë≥áË®äËêÉÂèñ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®Ë§áÈõúÂè•Â≠êÂíå‰ªªÂãô‰∏äÁöÑËêÉÂèñË°åÁÇ∫‰∏¶‰∏çÁ©©ÂÆöÔºåÂá∫Áèæ‰∫ÜË´∏Â¶ÇÂÅáÈôΩÊÄßÂíåÈÅ∫ÊºèÂÖÉÁ¥†Á≠âÂïèÈ°å„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåÂ∞áË§áÈõúÁöÑËêÉÂèñ‰ªªÂãôÂàÜËß£‰∏¶ÈÄêÊ≠•ËêÉÂèñÂèØ‰ª•ÊúâÊïàÂú∞ÊèêÂçá LLM ÁöÑÊïàËÉΩÔºåËÄåÂØ¶È´îÁöÑËêÉÂèñÈ†ÜÂ∫èÊúÉÈ°ØËëóÂΩ±Èüø LLM ÁöÑÊúÄÁµÇÁµêÊûú„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑË≥áË®äËêÉÂèñÁöÑÂÖ©ÈöéÊÆµÂ§öÊ≠•È©üÊñπÊ≥ïÔºå‰∏¶Êé°Áî® RL Ê°ÜÊû∂‰æÜÂü∑Ë°åÂ§öÊ≠•È©üË¶èÂäÉ„ÄÇÊàëÂÄëÂ∞áÈ†ÜÂ∫èËêÉÂèñË¶ñÁÇ∫‰∏ÄÂÄãÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ãÔºåÂª∫Á´ã‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑËêÉÂèñÁí∞Â¢ÉÔºåË®≠Ë®à‰∏ÄÂÄãÊ±∫Á≠ñÊ®°ÁµÑÔºå‰ª•Ëá™ÈÅ©ÊáâÁöÑÊñπÂºèÊèê‰æõ‰∏çÂêåÂè•Â≠ê‰∏≠È†ÜÂ∫èÂØ¶È´îËêÉÂèñÁöÑÊúÄ‰Ω≥È†ÜÂ∫èÔºå‰∏¶Âà©Áî® DDQN ÊºîÁÆóÊ≥ï‰æÜË®ìÁ∑¥Ê±∫Á≠ñÊ®°Âûã„ÄÇÊàëÂÄëÈÇÑË®≠Ë®à‰∫ÜÈÅ©Âêà LLM ËêÉÂèñÁµêÊûúÁöÑÁçéÂãµÂíåË©ï‰º∞ÊåáÊ®ô„ÄÇÊàëÂÄëÂú®Â§öÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•Ë≠âÊòéÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÊèêÂçá LLM ÁöÑË≥áË®äËêÉÂèñËÉΩÂäõÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **GPT-Powered Elicitation Interview Script Generator for Requirements Engineering Training**
2406.11439v1 by Binnur G√∂rer, Fatma Ba≈üak Aydemir

Elicitation interviews are the most common requirements elicitation
technique, and proficiency in conducting these interviews is crucial for
requirements elicitation. Traditional training methods, typically limited to
textbook learning, may not sufficiently address the practical complexities of
interviewing techniques. Practical training with various interview scenarios is
important for understanding how to apply theoretical knowledge in real-world
contexts. However, there is a shortage of educational interview material, as
creating interview scripts requires both technical expertise and creativity. To
address this issue, we develop a specialized GPT agent for auto-generating
interview scripts. The GPT agent is equipped with a dedicated knowledge base
tailored to the guidelines and best practices of requirements elicitation
interview procedures. We employ a prompt chaining approach to mitigate the
output length constraint of GPT to be able to generate thorough and detailed
interview scripts. This involves dividing the interview into sections and
crafting distinct prompts for each, allowing for the generation of complete
content for each section. The generated scripts are assessed through standard
natural language generation evaluation metrics and an expert judgment study,
confirming their applicability in requirements engineering training.

ÊëòË¶ÅÔºöÂºïÂá∫ÂºèË®™Ë´áÊòØÊúÄÂ∏∏Ë¶ãÁöÑÈúÄÊ±ÇÂºïÂá∫ÊäÄË°ìÔºåËÄåÁ≤æÈÄöÈÄ≤Ë°åÈÄô‰∫õË®™Ë´áÂ∞çÊñºÈúÄÊ±ÇÂºïÂá∫Ëá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑÂüπË®ìÊñπÊ≥ïÈÄöÂ∏∏ÂÉÖÈôêÊñºÊïôÁßëÊõ∏Â≠∏ÁøíÔºåÂèØËÉΩÁÑ°Ê≥ïÂÖÖÂàÜËß£Ê±∫Ë®™Ë´áÊäÄÂ∑ßÁöÑÂØ¶ÈöõË§áÈõúÊÄß„ÄÇÈÄèÈÅéÂêÑÁ®ÆË®™Ë´áÂ†¥ÊôØÁöÑÂØ¶ÈöõÂüπË®ìÂ∞çÊñºÁêÜËß£Â¶Ç‰ΩïÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÊáâÁî®ÁêÜË´ñÁü•Ë≠òÈùûÂ∏∏ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÊïôËÇ≤Ë®™Ë´áË≥áÊñôÂçªÂæàÁº∫‰πèÔºåÂõ†ÁÇ∫Âª∫Á´ãË®™Ë´áËÖ≥Êú¨ÈúÄË¶ÅÊäÄË°ìÂ∞àÊ•≠Áü•Ë≠òÂíåÂâµÈÄ†Âäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂ∞àÈñÄÁöÑ GPT ‰ª£ÁêÜÔºåÁî®ÊñºËá™ÂãïÁî¢ÁîüË®™Ë´áËÖ≥Êú¨„ÄÇGPT ‰ª£ÁêÜÈÖçÂÇô‰∫Ü‰∏ÄÂÄãÂ∞àÈñÄÁöÑÁü•Ë≠òÂ∫´ÔºåÂ∞àÈñÄÈáùÂ∞çÈúÄÊ±ÇÂºïÂá∫Ë®™Ë´áÁ®ãÂ∫èÁöÑÊ∫ñÂâáÂíåÊúÄ‰Ω≥ÂØ¶Âãô„ÄÇÊàëÂÄëÊé°Áî®ÊèêÁ§∫‰∏≤Êé•ÊñπÊ≥ï‰æÜÊ∏õËºï GPT ÁöÑËº∏Âá∫Èï∑Â∫¶ÈôêÂà∂Ôºå‰ª•‰æøËÉΩÂ§†Áî¢ÁîüÂÖ®Èù¢‰∏îË©≥Á¥∞ÁöÑË®™Ë´áËÖ≥Êú¨„ÄÇÈÄôÂåÖÊã¨Â∞áË®™Ë´áÂàÜÁÇ∫ÂπæÂÄãÈÉ®ÂàÜÔºå‰∏¶ÁÇ∫ÊØèÂÄãÈÉ®ÂàÜË£Ω‰Ωú‰∏çÂêåÁöÑÊèêÁ§∫Ôºå‰ª•‰æøÁÇ∫ÊØèÂÄãÈÉ®ÂàÜÁî¢ÁîüÂÆåÊï¥ÁöÑÂÖßÂÆπ„ÄÇÁî¢ÁîüÁöÑËÖ≥Êú¨ÈÄöÈÅéÊ®ôÊ∫ñËá™ÁÑ∂Ë™ûË®ÄÁîüÊàêË©ï‰º∞ÊåáÊ®ôÂíåÂ∞àÂÆ∂Âà§Êñ∑Á†îÁ©∂ÈÄ≤Ë°åË©ï‰º∞ÔºåË≠âÂØ¶‰∫ÜÂÆÉÂÄëÂú®ÈúÄÊ±ÇÂ∑•Á®ãÂüπË®ì‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇ

##### **Analysing the Behaviour of Tree-Based Neural Networks in Regression Tasks**
2406.11437v1 by Peter Samoaa, Mehrdad Farahani, Antonio Longa, Philipp Leitner, Morteza Haghir Chehreghani

The landscape of deep learning has vastly expanded the frontiers of source
code analysis, particularly through the utilization of structural
representations such as Abstract Syntax Trees (ASTs). While these methodologies
have demonstrated effectiveness in classification tasks, their efficacy in
regression applications, such as execution time prediction from source code,
remains underexplored. This paper endeavours to decode the behaviour of
tree-based neural network models in the context of such regression challenges.
We extend the application of established models--tree-based Convolutional
Neural Networks (CNNs), Code2Vec, and Transformer-based methods--to predict the
execution time of source code by parsing it to an AST. Our comparative analysis
reveals that while these models are benchmarks in code representation, they
exhibit limitations when tasked with regression. To address these deficiencies,
we propose a novel dual-transformer approach that operates on both source code
tokens and AST representations, employing cross-attention mechanisms to enhance
interpretability between the two domains. Furthermore, we explore the
adaptation of Graph Neural Networks (GNNs) to this tree-based problem,
theorizing the inherent compatibility due to the graphical nature of ASTs.
Empirical evaluations on real-world datasets showcase that our dual-transformer
model outperforms all other tree-based neural networks and the GNN-based
models. Moreover, our proposed dual transformer demonstrates remarkable
adaptability and robust performance across diverse datasets.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈ†òÂüüÂ∑≤Á∂ìÂ§ßÂπÖÊì¥Â±ï‰∫ÜÂéüÂßãÁ¢ºÂàÜÊûêÁöÑÁñÜÁïåÔºåÁâπÂà•ÊòØÈÄèÈÅé‰ΩøÁî®ÁµêÊßãÂåñË°®Á§∫Ê≥ïÔºå‰æãÂ¶ÇÊäΩË±°Ë™ûÊ≥ïÊ®π (AST)„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊñπÊ≥ïÂ∑≤Ë≠âÊòéÂú®ÂàÜÈ°û‰ªªÂãô‰∏≠ÊúâÊïàÔºå‰ΩÜÂÆÉÂÄëÂú®ÂõûÊ≠∏ÊáâÁî®‰∏≠ÁöÑÊïàËÉΩÔºå‰æãÂ¶ÇÂæûÂéüÂßãÁ¢º‰∏≠È†êÊ∏¨Âü∑Ë°åÊôÇÈñìÔºå‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨ÊñáË©¶ÂúñËß£Á¢ºÊ®πÁãÄÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÂú®ÈÄôÁ®ÆÂõûÊ≠∏ÊåëÊà∞‰∏≠ÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÊì¥Â±ï‰∫ÜÊó¢ÂÆöÊ®°ÂûãÁöÑÊáâÁî®‚Äî‚ÄîÂü∫ÊñºÊ®πÁãÄÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN)„ÄÅCode2Vec ÂíåÂü∫Êñº Transformer ÁöÑÊñπÊ≥ï‚Äî‚ÄîÈÄèÈÅéÂ∞áÂéüÂßãÁ¢ºËß£ÊûêÊàê AST ‰æÜÈ†êÊ∏¨ÂÖ∂Âü∑Ë°åÊôÇÈñì„ÄÇÊàëÂÄëÁöÑÊØîËºÉÂàÜÊûêÈ°ØÁ§∫ÔºåÂÑòÁÆ°ÈÄô‰∫õÊ®°ÂûãÊòØÁ®ãÂºèÁ¢ºË°®Á§∫Ê≥ïÁöÑÂü∫Ê∫ñÔºå‰ΩÜÂÆÉÂÄëÂú®Âü∑Ë°åÂõûÊ≠∏‰ªªÂãôÊôÇË°®ÁèæÂá∫ÈôêÂà∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÁº∫Èô∑ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈõô Transformer ÊñπÊ≥ïÔºåÂÆÉÂêåÊôÇ‰ΩúÁî®ÊñºÂéüÂßãÁ¢º‰ª£Á¢ºÂíå AST Ë°®Á§∫Ê≥ïÔºå‰∏¶Êé°Áî®Ë∑®Ê≥®ÊÑèÂäõÊ©üÂà∂‰æÜÂ¢ûÂº∑ÂÖ©ÂÄãÈ†òÂüü‰πãÈñìÁöÑÂèØËß£ÈáãÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ∞áÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÈÅ©ÊáâÂà∞ÈÄôÂÄãÂü∫ÊñºÊ®πÁãÄÁöÑÂïèÈ°åÔºå‰∏¶Ê†πÊìö AST ÁöÑÂúñÂΩ¢ÊÄßË≥™ÔºåÁêÜË´ñÂåñÂÖ∂ÂÖßÂú®Áõ∏ÂÆπÊÄß„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶Ë≠âË©ï‰º∞È°ØÁ§∫ÔºåÊàëÂÄëÁöÑÈõô Transformer Ê®°ÂûãÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñÂü∫ÊñºÊ®πÁãÄÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÂíåÂü∫Êñº GNN ÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ÁöÑÈõô Transformer Âú®‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫È°ØËëóÁöÑÈÅ©ÊáâÊÄßÂíåÁ©©ÂÅ•ÁöÑÊïàËÉΩ„ÄÇ

##### **AnyTrans: Translate AnyText in the Image with Large Scale Models**
2406.11432v1 by Zhipeng Qian, Pei Zhang, Baosong Yang, Kai Fan, Yiwei Ma, Derek F. Wong, Xiaoshuai Sun, Rongrong Ji

This paper introduces AnyTrans, an all-encompassing framework for the
task-Translate AnyText in the Image (TATI), which includes multilingual text
translation and text fusion within images. Our framework leverages the
strengths of large-scale models, such as Large Language Models (LLMs) and
text-guided diffusion models, to incorporate contextual cues from both textual
and visual elements during translation. The few-shot learning capability of
LLMs allows for the translation of fragmented texts by considering the overall
context. Meanwhile, the advanced inpainting and editing abilities of diffusion
models make it possible to fuse translated text seamlessly into the original
image while preserving its style and realism. Additionally, our framework can
be constructed entirely using open-source models and requires no training,
making it highly accessible and easily expandable. To encourage advancement in
the TATI task, we have meticulously compiled a test dataset called MTIT6, which
consists of multilingual text image translation data from six language pairs.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü AnyTransÔºå‰∏ÄÁ®ÆÁî®Êñº„ÄåÂúñÂÉè‰∏≠ÁöÑ‰ªª‰ΩïÊñáÂ≠óÁøªË≠Ø (TATI)„Äç‰ªªÂãôÁöÑÂÖ®Èù¢ÊÄßÊû∂ÊßãÔºåÂÖ∂‰∏≠ÂåÖÊã¨Â§öË™ûË®ÄÊñáÂ≠óÁøªË≠ØÂíåÂúñÂÉè‰∏≠ÁöÑÊñáÂ≠óËûçÂêà„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂà©Áî®‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÊñáÂ≠óÂºïÂ∞éÊì¥Êï£Ê®°ÂûãÁ≠âÂ§ßË¶èÊ®°Ê®°ÂûãÁöÑÂÑ™Âã¢ÔºåÂú®ÁøªË≠ØÈÅéÁ®ã‰∏≠Á¥çÂÖ•‰∫ÜÊñáÂ≠óÂíåË¶ñË¶∫ÂÖÉÁ¥†ÁöÑËÉåÊôØÁ∑öÁ¥¢„ÄÇLLM ÁöÑÂ∞ëÈáèÂ≠∏ÁøíËÉΩÂäõÂÖÅË®±ÈÄèÈÅéËÄÉÊÖÆÊï¥È´îËÉåÊôØ‰æÜÁøªË≠ØÁâáÊÆµÊñáÂ≠ó„ÄÇÂêåÊôÇÔºåÊì¥Êï£Ê®°ÂûãÁöÑÂÖàÈÄ≤‰øÆÂæ©ÂíåÁ∑®ËºØËÉΩÂäõËÆìÁøªË≠ØÂæåÁöÑÊñáÂ≠óËÉΩÂ§†ÁÑ°Á∏´ËûçÂêàÂà∞ÂéüÂßãÂúñÂÉè‰∏≠ÔºåÂêåÊôÇ‰øùÁïôÂÖ∂È¢®Ê†ºÂíåÁúüÂØ¶ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•‰ΩøÁî®ÂÆåÂÖ®ÈñãÊîæÂéüÂßãÁ¢ºÁöÑÊ®°ÂûãÂª∫ÊßãÔºå‰∏¶‰∏î‰∏çÈúÄË¶ÅË®ìÁ∑¥ÔºåÈÄôËÆìÂÆÉÈ´òÂ∫¶ÊòìÊñºÂ≠òÂèñ‰∏îÂÆπÊòìÊì¥ÂÖÖ„ÄÇÁÇ∫‰∫ÜÈºìÂãµ TATI ‰ªªÂãôÁöÑÈÄ≤Â±ïÔºåÊàëÂÄëÁ≤æÂøÉÁ∑®Âà∂‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ MTIT6 ÁöÑÊ∏¨Ë©¶Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™ÂÖ≠Á®ÆË™ûË®ÄÈÖçÂ∞çÁöÑÂ§öË™ûË®ÄÊñáÂ≠óÂúñÂÉèÁøªË≠ØË≥áÊñô„ÄÇ

##### **Super(ficial)-alignment: Strong Models May Deceive Weak Models in Weak-to-Strong Generalization**
2406.11431v1 by Wenkai Yang, Shiqi Shen, Guangyao Shen, Zhi Gong, Yankai Lin

Superalignment, where humans are weak supervisors of superhuman models, has
become an important and widely discussed issue in the current era of rapid
development of Large Language Models (LLMs). The recent work preliminarily
studies this problem by using weak models to supervise strong models. It
discovers that weakly supervised strong students can consistently outperform
weak teachers towards the alignment target, leading to a weak-to-strong
generalization phenomenon. However, we are concerned that behind such a
promising phenomenon, whether there exists an issue of weak-to-strong
deception, where strong models may deceive weak models by exhibiting
well-aligned in areas known to weak models but producing misaligned behaviors
in cases weak models do not know. We then take an initial step towards
exploring this security issue in a specific but realistic multi-objective
alignment case, where there may be some alignment targets conflicting with each
other (e.g., helpfulness v.s. harmlessness). Such a conflict is likely to cause
strong models to deceive weak models in one alignment dimension to gain high
reward in other alignment dimension. Our experiments on both the reward
modeling task and the preference optimization scenario indicate: (1) the
weak-to-strong deception exists; (2) the deception phenomenon may intensify as
the capability gap between weak and strong models increases. We also discuss
potential solutions and find bootstrapping with an intermediate model can
mitigate the deception to some extent. Our work highlights the urgent need to
pay more attention to the true reliability of superalignment.

ÊëòË¶ÅÔºöË∂ÖÂ∞çÈΩäÔºà‰∫∫È°ûÊòØË∂Ö‰∫∫È°ûÊ®°ÂûãÁöÑÂº±Áõ£Áù£ËÄÖÔºâÂ∑≤ÊàêÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âø´ÈÄüÁôºÂ±ïÁöÑÁï∂ÂâçÊôÇ‰ª£‰∏≠‰∏ÄÂÄãÈáçË¶Å‰∏îÂª£Ê≥õË®éË´ñÁöÑÂïèÈ°å„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÂàùÊ≠•ÈÄèÈÅé‰ΩøÁî®Âº±Ê®°ÂûãÁõ£Áù£Âº∑Ê®°Âûã‰æÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°å„ÄÇÂÆÉÁôºÁèæÂº±Áõ£Áù£ÁöÑÂº∑Â≠∏ÁîüÂèØ‰ª•ÊåÅÁ∫åÂú®Â∞çÈΩäÁõÆÊ®ô‰∏äÂÑ™ÊñºÂº±ÊïôÂ∏´ÔºåÂ∞éËá¥Âº±Âà∞Âº∑ÁöÑÊ¶ÇÂåñÁèæË±°„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÊìîÂøÉÂú®ÈÄôÊ®£‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÁèæË±°ËÉåÂæåÔºåÊòØÂê¶Â≠òÂú®Âº±Âà∞Âº∑ÁöÑÊ¨∫È®ôÂïèÈ°åÔºåÂÖ∂‰∏≠Âº∑Ê®°ÂûãÂèØËÉΩÈÄèÈÅéÂú®Âº±Ê®°ÂûãÂ∑≤Áü•ÁöÑÈ†òÂüüË°®ÁèæÂá∫ËâØÂ•ΩÂ∞çÈΩäÔºå‰ΩÜÂú®Âº±Ê®°Âûã‰∏çÁü•ÈÅìÁöÑÊÉÖÊ≥Å‰∏ãÁî¢ÁîüÂ§±Ë°°Ë°åÁÇ∫‰æÜÊ¨∫È®ôÂº±Ê®°Âûã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé°ÂèñÂàùÊ≠•Ê≠•È©üÂú®ÁâπÂÆö‰ΩÜÂØ¶ÈöõÁöÑÂ§öÁõÆÊ®ôÂ∞çÈΩäÊ°à‰æã‰∏≠Êé¢Ë®éÈÄôÂÄãÂÆâÂÖ®ÂïèÈ°åÔºåÂÖ∂‰∏≠ÂèØËÉΩÊúâ‰∏Ä‰∫õÂ∞çÈΩäÁõÆÊ®ôÁõ∏‰∫íË°ùÁ™ÅÔºà‰æãÂ¶ÇÔºåÊúâÁõäÊÄß v.s. ÁÑ°ÂÆ≥ÊÄßÔºâ„ÄÇÈÄôÁ®ÆË°ùÁ™ÅÂèØËÉΩÊúÉÂ∞éËá¥Âº∑Ê®°ÂûãÂú®‰∏ÄÂÄãÂ∞çÈΩäÁ∂≠Â∫¶Ê¨∫È®ôÂº±Ê®°ÂûãÔºå‰ª•Âú®ÂÖ∂‰ªñÂ∞çÈΩäÁ∂≠Â∫¶Áç≤ÂæóÈ´òÂõûÂ†±„ÄÇÊàëÂÄëÂú®ÂõûÂ†±Âª∫Ê®°‰ªªÂãôÂíåÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊÉÖÂ¢É‰∏≠ÁöÑÂØ¶È©óË°®ÊòéÔºö(1) Âº±Âà∞Âº∑ÁöÑÊ¨∫È®ôÂ≠òÂú®Ôºõ(2) Èö®ËëóÂº±Ê®°ÂûãÂíåÂº∑Ê®°Âûã‰πãÈñìËÉΩÂäõÂ∑ÆË∑ùÁöÑÂ¢ûÂä†ÔºåÊ¨∫È®ôÁèæË±°ÂèØËÉΩÊúÉÂä†Âäá„ÄÇÊàëÂÄë‰πüË®éË´ñÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰∏¶ÁôºÁèæ‰ΩøÁî®‰∏≠‰ªãÊ®°ÂûãÈÄ≤Ë°åËá™ËàâÂèØÂú®ÊüêÁ®ÆÁ®ãÂ∫¶‰∏äÊ∏õËºïÊ¨∫È®ô„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™øËø´ÂàáÈúÄË¶ÅÊõ¥Ê≥®ÊÑèË∂ÖÂ∞çÈΩäÁöÑÁúüÂØ¶ÂèØÈù†ÊÄß„ÄÇ

##### **A Simple and Effective $L_2$ Norm-Based Strategy for KV Cache Compression**
2406.11430v1 by Alessio Devoto, Yu Zhao, Simone Scardapane, Pasquale Minervini

The deployment of large language models (LLMs) is often hindered by the
extensive memory requirements of the Key-Value (KV) cache, especially as
context lengths increase. Existing approaches to reduce the KV cache size
involve either fine-tuning the model to learn a compression strategy or
leveraging attention scores to reduce the sequence length. We analyse the
attention distributions in decoder-only Transformers-based models and observe
that attention allocation patterns stay consistent across most layers.
Surprisingly, we find a clear correlation between the $L_2$ and the attention
scores over cached KV pairs, where a low $L_2$ of a key embedding usually leads
to a high attention score during decoding. This finding indicates that the
influence of a KV pair is potentially determined by the key embedding itself
before being queried. Based on this observation, we compress the KV cache based
on the $L_2$ of key embeddings. Our experimental results show that this simple
strategy can reduce the KV cache size by 50% on language modelling and
needle-in-a-haystack tasks and 90% on passkey retrieval tasks without losing
accuracy.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÉ®ÁΩ≤ÈÄöÂ∏∏ÂèóÂà∞ Key-Value (KV) Âø´ÂèñÂª£Ê≥õÁöÑË®òÊÜ∂È´îÈúÄÊ±ÇÊâÄÈòªÁ§ôÔºåÁâπÂà•ÊòØÂú®ËÑàÁµ°Èï∑Â∫¶Â¢ûÂä†ÊôÇ„ÄÇÁèæÊúâÁöÑÊ∏õÂ∞ë KV Âø´ÂèñÂ§ßÂ∞èÁöÑÊñπÊ≥ïÂåÖÊã¨ÂæÆË™øÊ®°Âûã‰ª•Â≠∏ÁøíÂ£ìÁ∏ÆÁ≠ñÁï•ÊàñÂà©Áî®Ê≥®ÊÑèÂäõÂàÜÊï∏‰æÜÊ∏õÂ∞ëÂ∫èÂàóÈï∑Â∫¶„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÂÉÖËß£Á¢ºÂô® Transformer Âü∫Á§éÊ®°Âûã‰∏≠ÁöÑÊ≥®ÊÑèÂäõÂàÜ‰ΩàÔºå‰∏¶ËßÄÂØüÂà∞Ê≥®ÊÑèÂäõÂàÜÈÖçÊ®°ÂºèÂú®Â§ßÈÉ®ÂàÜÂ±§‰∏≠‰øùÊåÅ‰∏ÄËá¥„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæ $L_2$ ÂíåÂø´Âèñ KV Â∞çÁöÑÊ≥®ÊÑèÂäõÂàÜÊï∏‰πãÈñìÂ≠òÂú®ÊòéÈ°ØÁöÑÈóúËÅØÊÄßÔºåÂÖ∂‰∏≠ÈçµÂµåÂÖ•ÁöÑ‰Ωé $L_2$ ÈÄöÂ∏∏ÊúÉÂ∞éËá¥Ëß£Á¢ºÊúüÈñìÁöÑÈ´òÊ≥®ÊÑèÂäõÂàÜÊï∏„ÄÇÈÄô‰∏ÄÁôºÁèæË°®ÊòéÔºåKV Â∞çÁöÑÂΩ±ÈüøÂèØËÉΩÂú®Êü•Ë©¢‰πãÂâçÂ∞±Áî±ÈçµÂµåÂÖ•Êú¨Ë∫´Ê±∫ÂÆö„ÄÇÂü∫ÊñºÈÄô‰∏ÄËßÄÂØüÔºåÊàëÂÄëÊ†πÊìöÈçµÂµåÂÖ•ÁöÑ $L_2$ Â£ìÁ∏Æ KV Âø´Âèñ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÈÄôÁ®ÆÁ∞°ÂñÆÁöÑÁ≠ñÁï•ÂèØ‰ª•Âú®Ë™ûË®ÄÂª∫Ê®°ÂíåÂ§ßÊµ∑ÊíàÈáù‰ªªÂãô‰∏≠Â∞á KV Âø´ÂèñÂ§ßÂ∞èÊ∏õÂ∞ë 50%ÔºåÂú®ÂØÜÈë∞Ê™¢Á¥¢‰ªªÂãô‰∏≠Ê∏õÂ∞ë 90%ÔºåËÄå‰∏çÊúÉÈôç‰ΩéÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with Diffusion Transformer**
2406.11427v1 by Keon Lee, Dong Won Kim, Jaehyeon Kim, Jaewoong Cho

Large-scale diffusion models have shown outstanding generative abilities
across multiple modalities including images, videos, and audio. However,
text-to-speech (TTS) systems typically involve domain-specific modeling factors
(e.g., phonemes and phoneme-level durations) to ensure precise temporal
alignments between text and speech, which hinders the efficiency and
scalability of diffusion models for TTS. In this work, we present an efficient
and scalable Diffusion Transformer (DiT) that utilizes off-the-shelf
pre-trained text and speech encoders. Our approach addresses the challenge of
text-speech alignment via cross-attention mechanisms with the prediction of the
total length of speech representations. To achieve this, we enhance the DiT
architecture to suit TTS and improve the alignment by incorporating semantic
guidance into the latent space of speech. We scale the training dataset and the
model size to 82K hours and 790M parameters, respectively. Our extensive
experiments demonstrate that the large-scale diffusion model for TTS without
domain-specific modeling not only simplifies the training pipeline but also
yields superior or comparable zero-shot performance to state-of-the-art TTS
models in terms of naturalness, intelligibility, and speaker similarity. Our
speech samples are available at https://ditto-tts.github.io.

ÊëòË¶ÅÔºöÂ§ßÂûãÊì¥Êï£Ê®°ÂûãÂ∑≤Â±ïÁèæÂá∫Ë∑®Ë∂äÂ§öÁ®ÆÊ®°ÊÖãÔºàÂåÖÂê´ÂΩ±ÂÉè„ÄÅÂΩ±ÁâáÂíåÈü≥Ë®äÔºâÁöÑÂá∫Ëâ≤ÁîüÊàêËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊñáÂ≠óËΩâË™ûÈü≥ÔºàTTSÔºâÁ≥ªÁµ±ÈÄöÂ∏∏ÂåÖÂê´ÁâπÂÆöÊñºÈ†òÂüüÁöÑÂª∫Ê®°Âõ†Â≠êÔºà‰æãÂ¶ÇÈü≥Á¥†ÂíåÈü≥Á¥†Â±§Á¥öÁöÑÊåÅÁ∫åÊôÇÈñìÔºâÔºå‰ª•Á¢∫‰øùÊñáÂ≠óËàáË™ûÈü≥‰πãÈñìÁ≤æÁ¢∫ÁöÑÊôÇÈñìÂ∞çÈΩäÔºåÈÄôÊúÉÈòªÁ§ôÊì¥Êï£Ê®°ÂûãÂú® TTS ‰∏≠ÁöÑÊïàÁéáÂíåÂèØÊì¥ÂÖÖÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊúâÊïà‰∏îÂèØÊì¥ÂÖÖÁöÑÊì¥Êï£TransformerÔºàDiTÔºâÔºåÂÆÉÂà©Áî®ÁèæÊàêÁöÑÈ†êË®ìÁ∑¥ÊñáÂ≠óÂíåË™ûÈü≥Á∑®Á¢ºÂô®„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄèÈÅé‰∫§ÂèâÊ≥®ÊÑèÂäõÊ©üÂà∂‰ª•ÂèäÈ†êÊ∏¨Ë™ûÈü≥Ë°®ÂæµÁöÑÁ∏ΩÈï∑Â∫¶Ôºå‰æÜËß£Ê±∫ÊñáÂ≠óË™ûÈü≥Â∞çÈΩäÁöÑÊåëÊà∞„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÁöÑÔºåÊàëÂÄëÂ¢ûÂº∑‰∫Ü DiT Êû∂Êßã‰ª•ÈÅ©Áî®Êñº TTSÔºå‰∏¶ÈÄèÈÅéÂ∞áË™ûÊÑèÂºïÂ∞éÁ¥çÂÖ•Ë™ûÈü≥ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠‰æÜÊîπÂñÑÂ∞çÈΩä„ÄÇÊàëÂÄëÂ∞áË®ìÁ∑¥Ë≥áÊñôÈõÜÂíåÊ®°ÂûãÂ§ßÂ∞èÂàÜÂà•Êì¥ÂÖÖÂà∞ 82K Â∞èÊôÇÂíå 790M ÂèÉÊï∏„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÂ§ßÂûãÊì¥Êï£Ê®°ÂûãÁî®Êñº TTSÔºåÂç≥‰ΩøÊ≤íÊúâÁâπÂÆöÊñºÈ†òÂüüÁöÑÂª∫Ê®°Ôºå‰∏çÂÉÖÁ∞°Âåñ‰∫ÜË®ìÁ∑¥ÊµÅÁ®ãÔºåÈÇÑËÉΩÁî¢ÁîüÂÑ™ÊñºÊàñÂ™≤ÁæéÁèæÊúâ TTS Ê®°ÂûãÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊïàËÉΩÔºåÂú®Ëá™ÁÑ∂Â∫¶„ÄÅÊ∏ÖÊô∞Â∫¶ÂíåË™™Ë©±ËÄÖÁõ∏‰ººÊÄßÊñπÈù¢ÁöÜÊòØÂ¶ÇÊ≠§„ÄÇÊàëÂÄëÁöÑË™ûÈü≥ÁØÑ‰æãÂèØÊñº https://ditto-tts.github.io/ ÂèñÂæó„ÄÇ

##### **Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG Systems: A Comparative Study of Performance and Scalability**
2406.11424v1 by Gautam B, Anupam Purwar

This paper presents an analysis of open-source large language models (LLMs)
and their application in Retrieval-Augmented Generation (RAG) tasks, specific
for enterprise-specific data sets scraped from their websites. With the
increasing reliance on LLMs in natural language processing, it is crucial to
evaluate their performance, accessibility, and integration within specific
organizational contexts. This study examines various open-source LLMs, explores
their integration into RAG frameworks using enterprise-specific data, and
assesses the performance of different open-source embeddings in enhancing the
retrieval and generation process. Our findings indicate that open-source LLMs,
combined with effective embedding techniques, can significantly improve the
accuracy and efficiency of RAG systems, offering a viable alternative to
proprietary solutions for enterprises.

ÊëòË¶ÅÔºöÊú¨ÊñáÂàÜÊûê‰∫ÜÈñãÊ∫êÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèäÂÖ∂Âú®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ‰ªªÂãô‰∏≠ÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÈáùÂ∞çÂæûÂÖ∂Á∂≤Á´ô‰∏≠Êì∑ÂèñÁöÑÁâπÂÆö‰ºÅÊ•≠Êï∏ÊìöÈõÜ„ÄÇÈö®ËëóËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂ∞ç LLM ÁöÑ‰æùË≥¥ÊÄßË∂ä‰æÜË∂äÈ´òÔºåË©ï‰º∞ÂÖ∂Âú®ÁâπÂÆöÁµÑÁπîÁí∞Â¢É‰∏≠ÁöÑÊïàËÉΩ„ÄÅÂèØÂèäÊÄßÂíåÊï¥ÂêàËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂Ê™¢Ë¶ñ‰∫ÜÂêÑÁ®ÆÈñãÊ∫ê LLMÔºåÊé¢Ë®éÂÆÉÂÄë‰ΩøÁî®ÁâπÂÆö‰ºÅÊ•≠Êï∏ÊìöÊï¥ÂêàÂà∞ RAG Êû∂Êßã‰∏≠Ôºå‰∏¶Ë©ï‰º∞‰∏çÂêåÈñãÊ∫êÂµåÂÖ•Â∞çÂä†Âº∑Ê™¢Á¥¢ÂíåÁîüÊàêÈÅéÁ®ãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈñãÊ∫ê LLM ËàáÊúâÊïàÁöÑÂµåÂÖ•ÊäÄË°ìÁõ∏ÁµêÂêàÔºåÂèØ‰ª•È°ØËëóÊèêÈ´ò RAG Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéáÔºåÁÇ∫‰ºÅÊ•≠Êèê‰æõÂèØË°åÁöÑÂ∞àÊúâËß£Ê±∫ÊñπÊ°àÊõø‰ª£ÊñπÊ°à„ÄÇ

##### **Dredge Word, Social Media, and Webgraph Networks for Unreliable Website Classification and Identification**
2406.11423v1 by Evan M. Williams, Peter Carragher, Kathleen M. Carley

In an attempt to mimic the complex paths through which unreliable content
spreads between search engines and social media, we explore the impact of
incorporating both webgraph and large-scale social media contexts into website
credibility classification and discovery systems. We further explore the usage
of what we define as \textit{dredge words} on social media -- terms or phrases
for which unreliable domains rank highly. Through comprehensive graph neural
network ablations, we demonstrate that curriculum-based heterogeneous graph
models that leverage context from both webgraphs and social media data
outperform homogeneous and single-mode approaches. We further demonstrate that
the incorporation of dredge words into our model strongly associates unreliable
websites with social media and online commerce platforms. Finally, we show our
heterogeneous model greatly outperforms competing systems in the top-k
identification of unlabeled unreliable websites. We demonstrate the strong
unreliability signals present in the diverse paths that users follow to uncover
unreliable content, and we release a novel dataset of dredge words.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÊ®°Êì¨‰∏çÂèØÈù†ÂÖßÂÆπÂú®ÊêúÂ∞ãÂºïÊìéÂíåÁ§æÁæ§Â™íÈ´î‰πãÈñìÂÇ≥Êí≠ÁöÑË§áÈõúË∑ØÂæëÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ∞áÁ∂≤Ë∑ØÂúñÂíåÂ§ßÂûãÁ§æÁæ§Â™íÈ´îËÉåÊôØÁ¥çÂÖ•Á∂≤Á´ôÂèØ‰ø°Â∫¶ÂàÜÈ°ûÂíåÁôºÁèæÁ≥ªÁµ±ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫ÜÊàëÂÄëÂÆöÁæ©ÁÇ∫Á§æÁæ§Â™íÈ´î‰∏äÁöÑ„ÄåÊíàËÄôÂ≠êË©ûÂΩô„ÄçÁöÑ‰ΩøÁî®‚Äî‚Äî‰∏çÂèØÈù†Á∂≤ÂüüÊéíÂêçÂæàÈ´òÁöÑË©ûÂΩôÊàñÁâáË™û„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÊ∂àËûçÔºåÊàëÂÄëË≠âÊòé‰∫ÜÂà©Áî®Á∂≤Ë∑ØÂúñÂíåÁ§æÁæ§Â™íÈ´îË≥áÊñôÁöÑËÉåÊôØÁöÑË™≤Á®ãÂºèÁï∞Ë≥™ÂúñÂΩ¢Ê®°ÂûãÔºåÂÑ™ÊñºÂêåË≥™ÂíåÂñÆ‰∏ÄÊ®°ÂºèÊñπÊ≥ï„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë≠âÊòéÔºåÂ∞áÊíàËÄôÂ≠êË©ûÂΩôÁ¥çÂÖ•ÊàëÂÄëÁöÑÊ®°ÂûãÔºåÂ∞á‰∏çÂèØÈù†Á∂≤Á´ôËàáÁ§æÁæ§Â™íÈ´îÂíåÁ∑ö‰∏äÂïÜÂãôÂπ≥Âè∞Á∑äÂØÜËÅØÁπ´Âú®‰∏ÄËµ∑„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫ÊàëÂÄëÁöÑÁï∞Ë≥™Ê®°ÂûãÂú®Êú™Ê®ôË®ò‰∏çÂèØÈù†Á∂≤Á´ôÁöÑ top-k Ë≠òÂà•‰∏≠ÔºåÂ§ßÂπÖÂÑ™ÊñºÁ´∂Áà≠Á≥ªÁµ±„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰ΩøÁî®ËÄÖËøΩËπ§‰ª•Êè≠Èú≤‰∏çÂèØÈù†ÂÖßÂÆπÊôÇÔºåÂêÑÁ®ÆË∑ØÂæë‰∏≠Â≠òÂú®Âº∑ÁÉàÁöÑ‰∏çÂèØÈù†‰ø°ËôüÔºå‰∏¶ÈáãÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊíàËÄôÂ≠êË©ûÂΩôË≥áÊñôÈõÜ„ÄÇ

##### **BAMBINO-LM: (Bilingual-)Human-Inspired Continual Pretraining of BabyLM**
2406.11418v1 by Zhewen Shen, Aditya Joshi, Ruey-Cheng Chen

Children from bilingual backgrounds benefit from interactions with parents
and teachers to re-acquire their heritage language. In this paper, we
investigate how this insight from behavioral study can be incorporated into the
learning of small-scale language models. We introduce BAMBINO-LM, a continual
pretraining strategy for BabyLM that uses a novel combination of alternation
and PPO-based perplexity reward induced from a parent Italian model. Upon
evaluation on zero-shot classification tasks for English and Italian,
BAMBINO-LM improves the Italian language capability of a BabyLM baseline. Our
ablation analysis demonstrates that employing both the alternation strategy and
PPO-based modeling is key to this effectiveness gain. We also show that, as a
side effect, the proposed method leads to similar degradation in L1
effectiveness as human children would have had in an equivalent learning
scenario.

ÊëòË¶ÅÔºö<paragraph>‰æÜËá™ÈõôË™ûËÉåÊôØÁöÑÂÖíÁ´•ÂæûËàáÁà∂ÊØçÂíåËÄÅÂ∏´ÁöÑ‰∫íÂãï‰∏≠ÂèóÁõäÔºå‰ª•ÈáçÊñ∞ÁøíÂæó‰ªñÂÄëÁöÑÂÇ≥Áµ±Ë™ûË®Ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ¶Ç‰ΩïÂ∞áË°åÁÇ∫Á†îÁ©∂‰∏≠ÁöÑÈÄô‰∏ÄË¶ãËß£ËûçÂÖ•Â∞èË¶èÊ®°Ë™ûË®ÄÊ®°ÂûãÁöÑÂ≠∏Áøí‰∏≠„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü BAMBINO-LMÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈáùÂ∞ç BabyLM ÁöÑÊåÅÁ∫åÈ†êË®ìÁ∑¥Á≠ñÁï•ÔºåÂÆÉ‰ΩøÁî®‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ‰∫§ÊõøÁµÑÂêàÂíåÂü∫Êñº PPO ÁöÑÂõ∞ÊÉëÁçéÂãµÔºåÈÄô‰∫õÁçéÂãµ‰æÜËá™Êñº‰∏ÄÂÄãÊÑèÂ§ßÂà©Ë™ûÁà∂‰ª£Ê®°Âûã„ÄÇÂú®Â∞çËã±Ë™ûÂíåÊÑèÂ§ßÂà©Ë™ûÁöÑÈõ∂Ê¨°ÂàÜÈ°û‰ªªÂãôÈÄ≤Ë°åË©ï‰º∞ÂæåÔºåBAMBINO-LM ÊèêÂçá‰∫Ü BabyLM Âü∫Ê∫ñÁöÑÊÑèÂ§ßÂà©Ë™ûËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊ∂àËûçÂàÜÊûêË°®ÊòéÔºåÊé°Áî®‰∫§ÊõøÁ≠ñÁï•ÂíåÂü∫Êñº PPO ÁöÑÂª∫Ê®°Â∞çÊñºÈÄôÁ®ÆÊúâÊïàÊÄßÊèêÂçáËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÈÇÑË°®ÊòéÔºå‰ΩúÁÇ∫‰∏ÄÂÄãÂâØ‰ΩúÁî®ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∞éËá¥‰∫ÜËàá‰∫∫È°ûÂÖíÁ´•Âú®Á≠âÊïàÂ≠∏ÁøíÂ†¥ÊôØ‰∏≠ÊúÉÂá∫ÁèæÁöÑÈ°û‰ººÁöÑ L1 ÊúâÊïàÊÄß‰∏ãÈôç„ÄÇ</paragraph>

##### **Formally Certified Approximate Model Counting**
2406.11414v1 by Yong Kiam Tan, Jiong Yang, Mate Soos, Magnus O. Myreen, Kuldeep S. Meel

Approximate model counting is the task of approximating the number of
solutions to an input Boolean formula. The state-of-the-art approximate model
counter for formulas in conjunctive normal form (CNF), ApproxMC, provides a
scalable means of obtaining model counts with probably approximately correct
(PAC)-style guarantees. Nevertheless, the validity of ApproxMC's approximation
relies on a careful theoretical analysis of its randomized algorithm and the
correctness of its highly optimized implementation, especially the latter's
stateful interactions with an incremental CNF satisfiability solver capable of
natively handling parity (XOR) constraints.
  We present the first certification framework for approximate model counting
with formally verified guarantees on the quality of its output approximation.
Our approach combines: (i) a static, once-off, formal proof of the algorithm's
PAC guarantee in the Isabelle/HOL proof assistant; and (ii) dynamic, per-run,
verification of ApproxMC's calls to an external CNF-XOR solver using proof
certificates. We detail our general approach to establish a rigorous connection
between these two parts of the verification, including our blueprint for
turning the formalized, randomized algorithm into a verified proof checker, and
our design of proof certificates for both ApproxMC and its internal CNF-XOR
solving steps. Experimentally, we show that certificate generation adds little
overhead to an approximate counter implementation, and that our certificate
checker is able to fully certify $84.7\%$ of instances with generated
certificates when given the same time and memory limits as the counter.

ÊëòË¶ÅÔºöËøë‰ººÊ®°ÂûãË®àÊï∏ÊòØËøë‰ººËº∏ÂÖ•Â∏ÉÊûóÂÖ¨ÂºèÁöÑËß£ÁöÑÊï∏ÈáèÁöÑÂ∑•‰Ωú„ÄÇËÅØÈõÜÁØÑÂºè (CNF) ‰∏≠ÂÖ¨ÂºèÁöÑÊúÄÊñ∞Ëøë‰ººÊ®°ÂûãË®àÊï∏Âô® ApproxMC Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂèñÂæóÊ®°ÂûãË®àÊï∏Ôºå‰∏¶ÂÖ∑ÊúâÂèØËÉΩËøë‰ººÊ≠£Á¢∫ (PAC) ÂºèÁöÑ‰øùË≠â„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåApproxMC Ëøë‰ººÁöÑÊúâÊïàÊÄß‰æùË≥¥ÊñºÂÖ∂Èö®Ê©üÊºîÁÆóÊ≥ïÁöÑ‰ªîÁ¥∞ÁêÜË´ñÂàÜÊûêÔºå‰ª•ÂèäÂÖ∂È´òÂ∫¶ÊúÄ‰Ω≥ÂåñÂØ¶‰ΩúÁöÑÊ≠£Á¢∫ÊÄßÔºåÁâπÂà•ÊòØÂæåËÄÖËàáÂéüÁîüËôïÁêÜÂ•áÂÅ∂Ê†°È©ó (XOR) Á¥ÑÊùüÁöÑÂ¢ûÈáè CNF ÂèØÊªøË∂≥ÊÄßÊ±ÇËß£Âô®ÁöÑÊúâÁãÄÊÖã‰∫íÂãï„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËøë‰ººÊ®°ÂûãË®àÊï∏ÁöÑÁ¨¨‰∏ÄÂÄãË™çË≠âÊû∂ÊßãÔºåÂÖ∂Ëº∏Âá∫Ëøë‰ººÁöÑÂìÅË≥™ÂÖ∑ÊúâÊ≠£ÂºèÈ©óË≠âÁöÑ‰øùË≠â„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÁµêÂêàÔºö(i) Âú® Isabelle/HOL Ë≠âÊòéËºîÂä©Â∑•ÂÖ∑‰∏≠ÊºîÁÆóÊ≥ïÁöÑ PAC ‰øùË≠âÁöÑÈùúÊÖã„ÄÅ‰∏ÄÊ¨°ÊÄßÁöÑÊ≠£ÂºèË≠âÊòéÔºõ‰ª•Âèä (ii) ApproxMC Â∞çÂ§ñÈÉ® CNF-XOR Ê±ÇËß£Âô®ÂëºÂè´ÁöÑÂãïÊÖã„ÄÅÊØèÊ¨°Âü∑Ë°åÈ©óË≠âÔºå‰ΩøÁî®Ë≠âÊòéË≠âÊõ∏„ÄÇÊàëÂÄëË©≥Á¥∞Ë™™Êòé‰∫ÜÊàëÂÄëÂª∫Á´ãÈ©óË≠âÈÄôÂÖ©ÂÄãÈÉ®ÂàÜ‰πãÈñìÂö¥Ë¨πÈÄ£Êé•ÁöÑÈÄöÁî®ÂÅöÊ≥ïÔºåÂåÖÊã¨ÊàëÂÄëÂ∞áÂΩ¢ÂºèÂåñÈö®Ê©üÊºîÁÆóÊ≥ïËΩâËÆäÊàêÈ©óË≠âË≠âÊòéÊ™¢Êü•Âô®ÁöÑËóçÂúñÔºå‰ª•ÂèäÊàëÂÄëÁÇ∫ ApproxMC ÂèäÂÖ∂ÂÖßÈÉ® CNF-XOR Ê±ÇËß£Ê≠•È©üË®≠Ë®àÁöÑË≠âÊòéË≠âÊõ∏„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÈ°ØÁ§∫Ë≠âÊõ∏Áî¢ÁîüÁÇ∫Ëøë‰ººË®àÊï∏Âô®ÂØ¶‰ΩúÂ¢ûÂä†ÂæàÂ∞ëÁöÑÈñãÈä∑ÔºåËÄå‰∏îÊàëÂÄëÁöÑË≠âÊõ∏Ê™¢Êü•Âô®ËÉΩÂ§†Âú®ËàáË®àÊï∏Âô®Áµ¶‰∫àÁõ∏ÂêåÊôÇÈñìÂíåË®òÊÜ∂È´îÈôêÂà∂ÊôÇÔºåÂÆåÂÖ®Ë™çË≠â $84.7\%$ ÂÄãÂÖ∑ÊúâÁî¢ÁîüË≠âÊõ∏ÁöÑÂØ¶‰æã„ÄÇ

##### **HARE: HumAn pRiors, a key to small language model Efficiency**
2406.11410v2 by Lingyun Zhang, Bin jin, Gaojian Ge, Lunhui Liu, Xuewen Shen, Mingyong Wu, Houqian Zhang, Yongneng Jiang, Shiqi Chen, Shi Pu

Human priors play a crucial role in efficiently utilizing data in deep
learning. However, with the development of large language models (LLMs), there
is an increasing emphasis on scaling both model size and data volume, which
often diminishes the importance of human priors in data construction.
Influenced by these trends, existing Small Language Models (SLMs) mainly rely
on web-scraped large-scale training data, neglecting the proper incorporation
of human priors. This oversight limits the training efficiency of language
models in resource-constrained settings. In this paper, we propose a principle
to leverage human priors for data construction. This principle emphasizes
achieving high-performance SLMs by training on a concise dataset that
accommodates both semantic diversity and data quality consistency, while
avoiding benchmark data leakage. Following this principle, we train an SLM
named HARE-1.1B. Extensive experiments on large-scale benchmark datasets
demonstrate that HARE-1.1B performs favorably against state-of-the-art SLMs,
validating the effectiveness of the proposed principle. Additionally, this
provides new insights into efficient language model training in
resource-constrained environments from the view of human priors.

ÊëòË¶ÅÔºö‰∫∫È°ûÂÖàÈ©óÁü•Ë≠òÂú®Ê∑±Â∫¶Â≠∏Áøí‰∏≠ÊúâÊïàÂà©Áî®Ë≥áÊñôÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁôºÂ±ïÔºå‰∫∫ÂÄëË∂ä‰æÜË∂äÈáçË¶ñÊì¥Â±ïÊ®°ÂûãË¶èÊ®°ÂíåË≥áÊñôÈáèÔºåÈÄôÂ∏∏Â∏∏ÊúÉÈôç‰Ωé‰∫∫È°ûÂÖàÈ©óÁü•Ë≠òÂú®Ë≥áÊñôÂª∫Êßã‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÂú®ÈÄô‰∫õË∂®Âã¢ÁöÑÂΩ±Èüø‰∏ãÔºåÁèæÊúâÁöÑÂ∞èÂûãË™ûË®ÄÊ®°Âûã (SLM) ‰∏ªË¶Å‰æùË≥¥ÊñºÁ∂≤Ë∑ØÁà¨ÂèñÁöÑÂ§ßË¶èÊ®°Ë®ìÁ∑¥Ë≥áÊñôÔºåËÄåÂøΩÁï•‰∫ÜÈÅ©Áï∂Âú∞Á¥çÂÖ•‰∫∫È°ûÂÖàÈ©óÁü•Ë≠ò„ÄÇÈÄôÁ®ÆÁñèÂøΩÈôêÂà∂‰∫ÜË™ûË®ÄÊ®°ÂûãÂú®Ë≥áÊ∫êÂèóÈôêÁí∞Â¢É‰∏≠ÁöÑË®ìÁ∑¥ÊïàÁéá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂà©Áî®‰∫∫È°ûÂÖàÈ©óÁü•Ë≠òÈÄ≤Ë°åË≥áÊñôÂª∫ÊßãÁöÑÂéüÂâá„ÄÇÊ≠§ÂéüÂâáÂº∑Ë™øÈÄèÈÅéË®ìÁ∑¥‰∏ÄÂÄãÁ∞°ÊΩîÁöÑË≥áÊñôÈõÜ‰æÜÈÅîÊàêÈ´òÊÄßËÉΩ SLMÔºåË©≤Ë≥áÊñôÈõÜÂåÖÂê´Ë™ûÊÑèÂ§öÊ®£ÊÄßÂíåË≥áÊñôÂìÅË≥™‰∏ÄËá¥ÊÄßÔºåÂêåÊôÇÈÅøÂÖçÂü∫Ê∫ñË≥áÊñôÂ§ñÊ¥©„ÄÇÈÅµÂæ™Ê≠§ÂéüÂâáÔºåÊàëÂÄëË®ìÁ∑¥‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ HARE-1.1B ÁöÑ SLM„ÄÇÂú®Â§ßÂûãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåHARE-1.1B ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑ SLMÔºåÈ©óË≠â‰∫ÜÊâÄÊèêÂá∫ÂéüÂâáÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÈÄôÂæû‰∫∫È°ûÂÖàÈ©óÁü•Ë≠òÁöÑËßíÂ∫¶ÁÇ∫Âú®Ë≥áÊ∫êÂèóÈôêÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÊúâÊïàË™ûË®ÄÊ®°ÂûãË®ìÁ∑¥Êèê‰æõ‰∫ÜÊñ∞ÁöÑË¶ãËß£„ÄÇ


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-17**|**Input Conditioned Graph Generation for Language Agents**|Lukas Vierling et.al.|[2406.11555v1](http://arxiv.org/abs/2406.11555v1)|[link](https://github.com/lukasvierling/dynamicgptswarm)|
|**2024-06-17**|**Large Language Models and Knowledge Graphs for Astronomical Entity Disambiguation**|Golnaz Shapurian et.al.|[2406.11400v1](http://arxiv.org/abs/2406.11400v1)|null|
|**2024-06-17**|**How Good are LLMs at Relation Extraction under Low-Resource Scenario? Comprehensive Evaluation**|Dawulie Jinensibieke et.al.|[2406.11162v1](http://arxiv.org/abs/2406.11162v1)|[link](https://github.com/victor812-hub/entity_datasets)|
|**2024-06-17**|**Move Beyond Triples: Contextual Knowledge Graph Representation and Reasoning**|Chengjin Xu et.al.|[2406.11160v1](http://arxiv.org/abs/2406.11160v1)|null|
|**2024-06-17**|**Are Large Language Models a Good Replacement of Taxonomies?**|Yushi Sun et.al.|[2406.11131v1](http://arxiv.org/abs/2406.11131v1)|[link](https://github.com/ysunbp/taxoglimpse)|
|**2024-06-16**|**DocNet: Semantic Structure in Inductive Bias Detection Models**|Jessica Zhu et.al.|[2406.10965v1](http://arxiv.org/abs/2406.10965v1)|null|
|**2024-06-16**|**Light Up the Shadows: Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models**|Yikai Zhang et.al.|[2406.10902v1](http://arxiv.org/abs/2406.10902v1)|[link](https://github.com/ykzhang721/COG)|
|**2024-06-16**|**KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs**|Aihua Pei et.al.|[2406.10802v1](http://arxiv.org/abs/2406.10802v1)|null|
|**2024-06-15**|**A Comprehensive Survey of Foundation Models in Medicine**|Wasif Khan et.al.|[2406.10729v1](http://arxiv.org/abs/2406.10729v1)|null|
|**2024-06-15**|**SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**|Ziije Zhong et.al.|[2406.10710v1](http://arxiv.org/abs/2406.10710v1)|null|
|**2024-06-15**|**Large Language Models as Event Forecasters**|Libo Zhang et.al.|[2406.10492v1](http://arxiv.org/abs/2406.10492v1)|null|
|**2024-06-15**|**Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning**|Wenjun Li et.al.|[2406.10479v1](http://arxiv.org/abs/2406.10479v1)|null|
|**2024-06-14**|**Precision Empowers, Excess Distracts: Visual Question Answering With Dynamically Infused Knowledge In Language Models**|Manas Jhalani et.al.|[2406.09994v1](http://arxiv.org/abs/2406.09994v1)|null|
|**2024-06-14**|**DAG-Plan: Generating Directed Acyclic Dependency Graphs for Dual-Arm Cooperative Planning**|Zeyu Gao et.al.|[2406.09953v1](http://arxiv.org/abs/2406.09953v1)|null|
|**2024-06-14**|**TEG-DB: A Comprehensive Dataset and Benchmark of Textual-Edge Graphs**|Zhuofeng Li et.al.|[2406.10310v1](http://arxiv.org/abs/2406.10310v1)|null|
|**2024-06-13**|**Automated Molecular Concept Generation and Labeling with Large Language Models**|Shichang Zhang et.al.|[2406.09612v1](http://arxiv.org/abs/2406.09612v1)|null|
|**2024-06-13**|**Cross-Modality Program Representation Learning for Electronic Design Automation with High-Level Synthesis**|Zongyue Qin et.al.|[2406.09606v1](http://arxiv.org/abs/2406.09606v1)|null|
|**2024-06-13**|**Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models**|Yushi Hu et.al.|[2406.09403v1](http://arxiv.org/abs/2406.09403v1)|null|
|**2024-06-13**|**Transformers meet Neural Algorithmic Reasoners**|Wilfried Bounsi et.al.|[2406.09308v1](http://arxiv.org/abs/2406.09308v1)|null|
|**2024-06-13**|**SememeLM: A Sememe Knowledge Enhanced Method for Long-tail Relation Representation**|Shuyi Li et.al.|[2406.10297v1](http://arxiv.org/abs/2406.10297v1)|null|
|**2024-06-13**|**ContraSolver: Self-Alignment of Language Models by Resolving Internal Preference Contradictions**|Xu Zhang et.al.|[2406.08842v1](http://arxiv.org/abs/2406.08842v1)|null|
|**2024-06-12**|**Research Trends for the Interplay between Large Language Models and Knowledge Graphs**|Hanieh Khorashadizadeh et.al.|[2406.08223v1](http://arxiv.org/abs/2406.08223v1)|null|
|**2024-06-12**|**SHACL2FOL: An FOL Toolkit for SHACL Decision Problems**|Paolo Pareti et.al.|[2406.08018v1](http://arxiv.org/abs/2406.08018v1)|[link](https://github.com/paolo7/shacl2fol)|
|**2024-06-11**|**Efficient Parallel Multi-Hop Reasoning: A Scalable Approach for Knowledge Graph Analysis**|Jesmin Jahan Tithi et.al.|[2406.07727v1](http://arxiv.org/abs/2406.07727v1)|null|
|**2024-06-11**|**TextGrad: Automatic "Differentiation" via Text**|Mert Yuksekgonul et.al.|[2406.07496v1](http://arxiv.org/abs/2406.07496v1)|[link](https://github.com/zou-group/textgrad)|
|**2024-06-11**|**CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**|Frederic Kirstein et.al.|[2406.07494v2](http://arxiv.org/abs/2406.07494v2)|null|
|**2024-06-11**|**Large Language Models for Constrained-Based Causal Discovery**|Kai-Hendrik Cohrs et.al.|[2406.07378v1](http://arxiv.org/abs/2406.07378v1)|[link](https://github.com/ipl-uv/causal_gpt)|
|**2024-06-11**|**Scaling Large-Language-Model-based Multi-Agent Collaboration**|Chen Qian et.al.|[2406.07155v1](http://arxiv.org/abs/2406.07155v1)|[link](https://github.com/openbmb/chatdev)|
|**2024-06-11**|**Mining Frequent Structures in Conceptual Models**|Mattia Fumagalli et.al.|[2406.07129v1](http://arxiv.org/abs/2406.07129v1)|[link](https://github.com/unibz-core/cm-mining_experimentdata)|
|**2024-06-11**|**Beyond Bare Queries: Open-Vocabulary Object Retrieval with 3D Scene Graph**|Sergey Linok et.al.|[2406.07113v2](http://arxiv.org/abs/2406.07113v2)|null|
|**2024-06-11**|**DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs**|Haishuo Fang et.al.|[2406.07080v1](http://arxiv.org/abs/2406.07080v1)|[link](https://github.com/UKPLab/acl2024-DARA)|
|**2024-06-11**|**Improving Multi-hop Logical Reasoning in Knowledge Graphs with Context-Aware Query Representation Learning**|Jeonghoon Kim et.al.|[2406.07034v1](http://arxiv.org/abs/2406.07034v1)|[link](https://github.com/kjh9503/caqr)|
|**2024-06-10**|**MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension**|Khiem Le et.al.|[2406.06777v2](http://arxiv.org/abs/2406.06777v2)|null|
|**2024-06-10**|**The Curse of Popularity: Popular Entities have Catastrophic Side Effects when Deleting Knowledge from Language Models**|Ryosuke Takahashi et.al.|[2406.06032v1](http://arxiv.org/abs/2406.06032v1)|null|
|**2024-06-10**|**HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs**|Pranoy Panda et.al.|[2406.06027v1](http://arxiv.org/abs/2406.06027v1)|null|
|**2024-06-08**|**Generalist Multimodal AI: A Review of Architectures, Challenges and Opportunities**|Sai Munikoti et.al.|[2406.05496v1](http://arxiv.org/abs/2406.05496v1)|null|
|**2024-06-07**|**TLEX: An Efficient Method for Extracting Exact Timelines from TimeML Temporal Graphs**|Mustafa Ocal et.al.|[2406.05265v1](http://arxiv.org/abs/2406.05265v1)|null|
|**2024-06-07**|**LinkQ: An LLM-Assisted Visual Interface for Knowledge Graph Question-Answering**|Harry Li et.al.|[2406.06621v1](http://arxiv.org/abs/2406.06621v1)|[link](https://github.com/mit-ll/linkq)|
|**2024-06-07**|**Compositional Generalization with Grounded Language Models**|Sondre Wold et.al.|[2406.04989v1](http://arxiv.org/abs/2406.04989v1)|[link](https://github.com/ltgoslo/text-graph-generalization)|
|**2024-06-07**|**CRAG -- Comprehensive RAG Benchmark**|Xiao Yang et.al.|[2406.04744v1](http://arxiv.org/abs/2406.04744v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-07**|**OCDB: Revisiting Causal Discovery with a Comprehensive Benchmark and Evaluation Framework**|Wei Zhou et.al.|[2406.04598v1](http://arxiv.org/abs/2406.04598v1)|null|
|**2024-06-06**|**ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions**|Sreyan Ghosh et.al.|[2406.04286v1](http://arxiv.org/abs/2406.04286v1)|[link](https://github.com/sreyan88/abex)|
|**2024-06-06**|**Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**|Ling Yang et.al.|[2406.04271v1](http://arxiv.org/abs/2406.04271v1)|[link](https://github.com/yangling0818/buffer-of-thought-llm)|
|**2024-06-06**|**Transformers need glasses! Information over-squashing in language tasks**|Federico Barbero et.al.|[2406.04267v1](http://arxiv.org/abs/2406.04267v1)|null|
|**2024-06-06**|**The CLRS-Text Algorithmic Reasoning Language Benchmark**|Larisa Markeeva et.al.|[2406.04229v1](http://arxiv.org/abs/2406.04229v1)|[link](https://github.com/google-deepmind/clrs)|
|**2024-06-06**|**Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech**|Neemesh Yadav et.al.|[2406.03953v1](http://arxiv.org/abs/2406.03953v1)|null|
|**2024-06-06**|**Performance of large language models in numerical vs. semantic medical knowledge: Benchmarking on evidence-based Q&As**|Eden Avnat et.al.|[2406.03855v1](http://arxiv.org/abs/2406.03855v1)|null|
|**2024-06-06**|**Are Large Language Models the New Interface for Data Pipelines?**|Sylvio Barbon Junior et.al.|[2406.06596v1](http://arxiv.org/abs/2406.06596v1)|null|
|**2024-06-06**|**Efficient Knowledge Infusion via KG-LLM Alignment**|Zhouyu Jiang et.al.|[2406.03746v1](http://arxiv.org/abs/2406.03746v1)|null|
|**2024-06-06**|**FastGAS: Fast Graph-based Annotation Selection for In-Context Learning**|Zihan Chen et.al.|[2406.03730v1](http://arxiv.org/abs/2406.03730v1)|null|
|**2024-06-06**|**A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions**|Lei Liu et.al.|[2406.03712v1](http://arxiv.org/abs/2406.03712v1)|null|
|**2024-06-05**|**Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning**|Yang Wu et.al.|[2406.03600v1](http://arxiv.org/abs/2406.03600v1)|null|
|**2024-06-04**|**XRec: Large Language Models for Explainable Recommendation**|Qiyao Ma et.al.|[2406.02377v1](http://arxiv.org/abs/2406.02377v1)|[link](https://github.com/hkuds/xrec)|
|**2024-06-04**|**Exploring Effects of Hyperdimensional Vectors for Tsetlin Machines**|Vojtech Halenka et.al.|[2406.02648v1](http://arxiv.org/abs/2406.02648v1)|null|
|**2024-06-04**|**UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models**|Zhuoyang Li et.al.|[2406.02110v1](http://arxiv.org/abs/2406.02110v1)|null|
|**2024-06-04**|**Multimodal Reasoning with Multimodal Knowledge Graph**|Junlin Lee et.al.|[2406.02030v2](http://arxiv.org/abs/2406.02030v2)|null|
|**2024-06-04**|**ST-DPGAN: A Privacy-preserving Framework for Spatiotemporal Data Generation**|Wei Shao et.al.|[2406.03404v1](http://arxiv.org/abs/2406.03404v1)|null|
|**2024-06-03**|**Helix: Distributed Serving of Large Language Models via Max-Flow on Heterogeneous GPUs**|Yixuan Mei et.al.|[2406.01566v1](http://arxiv.org/abs/2406.01566v1)|null|
|**2024-06-03**|**Graph Neural Network Enhanced Retrieval for Question Answering of LLMs**|Zijian Li et.al.|[2406.06572v1](http://arxiv.org/abs/2406.06572v1)|null|
|**2024-06-03**|**How to Understand Whole Software Repository?**|Yingwei Ma et.al.|[2406.01422v1](http://arxiv.org/abs/2406.01422v1)|null|
|**2024-06-03**|**FactGenius: Combining Zero-Shot Prompting and Fuzzy Relation Mining to Improve Fact Verification with Knowledge Graphs**|Sushant Gautam et.al.|[2406.01311v1](http://arxiv.org/abs/2406.01311v1)|[link](https://github.com/sushantgautam/factgenius)|
|**2024-06-03**|**Augmented Commonsense Knowledge for Remote Object Grounding**|Bahram Mohammadi et.al.|[2406.01256v1](http://arxiv.org/abs/2406.01256v1)|[link](https://github.com/Bahram-Mohammadi/ACK)|
|**2024-06-03**|**EffiQA: Efficient Question-Answering with Strategic Multi-Model Collaboration on Knowledge Graphs**|Zixuan Dong et.al.|[2406.01238v1](http://arxiv.org/abs/2406.01238v1)|null|
|**2024-06-03**|**Explore then Determine: A GNN-LLM Synergy Framework for Reasoning over Knowledge Graph**|Guangyi Liu et.al.|[2406.01145v1](http://arxiv.org/abs/2406.01145v1)|null|
|**2024-06-03**|**RAG Enabled Conversations about Household Electricity Monitoring**|Carolina Fortuna et.al.|[2406.06566v1](http://arxiv.org/abs/2406.06566v1)|null|
|**2024-06-03**|**MACT: Model-Agnostic Cross-Lingual Training for Discourse Representation Structure Parsing**|Jiangming Liu et.al.|[2406.01052v1](http://arxiv.org/abs/2406.01052v1)|[link](https://github.com/LeonCrashCode/DRS-Cross-Lingual-Training)|
|**2024-06-03**|**LLM and GNN are Complementary: Distilling LLM for Multimodal Graph Learning**|Junjie Xu et.al.|[2406.01032v1](http://arxiv.org/abs/2406.01032v1)|null|
|**2024-06-02**|**Presence or Absence: Are Unknown Word Usages in Dictionaries?**|Xianghe Ma et.al.|[2406.00656v1](http://arxiv.org/abs/2406.00656v1)|[link](https://github.com/xiaohemaikoo/axolotl24-abdn-nlp)|
|**2024-06-02**|**Harnessing Business and Media Insights with Large Language Models**|Yujia Bao et.al.|[2406.06559v1](http://arxiv.org/abs/2406.06559v1)|null|
|**2024-06-02**|**D-FaST: Cognitive Signal Decoding with Disentangled Frequency-Spatial-Temporal Attention**|Weiguo Chen et.al.|[2406.02602v1](http://arxiv.org/abs/2406.02602v1)|null|
|**2024-06-01**|**KGLink: A column type annotation method that combines knowledge graph and pre-trained language model**|Yubo Wang et.al.|[2406.00318v1](http://arxiv.org/abs/2406.00318v1)|[link](https://github.com/Wyb0627/KBLink)|
|**2024-05-31**|**Joint Embeddings for Graph Instruction Tuning**|Vlad Argatu et.al.|[2405.20684v1](http://arxiv.org/abs/2405.20684v1)|null|
|**2024-05-30**|**KerasCV and KerasNLP: Vision and Language Power-Ups**|Matthew Watson et.al.|[2405.20247v3](http://arxiv.org/abs/2405.20247v3)|null|
|**2024-05-30**|**Grokfast: Accelerated Grokking by Amplifying Slow Gradients**|Jaerin Lee et.al.|[2405.20233v2](http://arxiv.org/abs/2405.20233v2)|[link](https://github.com/ironjr/grokfast)|
|**2024-05-30**|**Reasoning about concepts with LLMs: Inconsistencies abound**|Rosario Uceda-Sosa et.al.|[2405.20163v1](http://arxiv.org/abs/2405.20163v1)|null|
|**2024-05-30**|**GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning**|Costas Mavromatis et.al.|[2405.20139v1](http://arxiv.org/abs/2405.20139v1)|[link](https://github.com/cmavro/gnn-rag)|
|**2024-05-30**|**MM-Lego: Modular Biomedical Multimodal Models with Minimal Fine-Tuning**|Konstantin Hemker et.al.|[2405.19950v1](http://arxiv.org/abs/2405.19950v1)|null|
|**2024-05-30**|**KNOW: A Real-World Ontology for Knowledge Capture with Large Language Models**|Arto Bendiken et.al.|[2405.19877v1](http://arxiv.org/abs/2405.19877v1)|null|
|**2024-05-30**|**Unsupervised Mutual Learning of Dialogue Discourse Parsing and Topic Segmentation**|Jiahui Xu et.al.|[2405.19799v2](http://arxiv.org/abs/2405.19799v2)|[link](https://github.com/jeff-sue/urt)|
|**2024-05-30**|**Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion**|Wei Cheng et.al.|[2405.19782v1](http://arxiv.org/abs/2405.19782v1)|[link](https://github.com/nju-websoft/DraCo)|
|**2024-05-30**|**Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback**|Jingwei Sun et.al.|[2405.19686v1](http://arxiv.org/abs/2405.19686v1)|null|
|**2024-05-29**|**MASSIVE Multilingual Abstract Meaning Representation: A Dataset and Baselines for Hallucination Detection**|Michael Regan et.al.|[2405.19285v1](http://arxiv.org/abs/2405.19285v1)|null|
|**2024-05-29**|**PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications**|Dingkang Yang et.al.|[2405.19266v2](http://arxiv.org/abs/2405.19266v2)|null|
|**2024-05-29**|**Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation**|Jose Tupayachi et.al.|[2405.19255v1](http://arxiv.org/abs/2405.19255v1)|null|
|**2024-05-29**|**Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery**|Sounak Lahiri et.al.|[2405.19164v1](http://arxiv.org/abs/2405.19164v1)|null|
|**2024-05-28**|**Unleashing the Potential of Text-attributed Graphs: Automatic Relation Decomposition via Large Language Models**|Hyunjin Seo et.al.|[2405.18581v1](http://arxiv.org/abs/2405.18581v1)|null|
|**2024-05-28**|**Don't Forget to Connect! Improving RAG with Graph-based Reranking**|Jialin Dong et.al.|[2405.18414v1](http://arxiv.org/abs/2405.18414v1)|null|
|**2024-05-28**|**Knowledge Circuits in Pretrained Transformers**|Yunzhi Yao et.al.|[2405.17969v1](http://arxiv.org/abs/2405.17969v1)|[link](https://github.com/zjunlp/knowledgecircuits)|
|**2024-05-28**|**Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs**|Yong Qi et.al.|[2405.17846v1](http://arxiv.org/abs/2405.17846v1)|null|
|**2024-05-27**|**Cost-efficient Knowledge-based Question Answering with Large Language Models**|Junnan Dong et.al.|[2405.17337v1](http://arxiv.org/abs/2405.17337v1)|null|
|**2024-05-27**|**Assessing LLMs Suitability for Knowledge Graph Completion**|Vasile Ionut Remus Iga et.al.|[2405.17249v1](http://arxiv.org/abs/2405.17249v1)|[link](https://github.com/ionutiga/llms-for-kgc)|
|**2024-05-27**|**EMERGE: Integrating RAG for Improved Multimodal EHR Predictive Modeling**|Yinghao Zhu et.al.|[2406.00036v1](http://arxiv.org/abs/2406.00036v1)|null|
|**2024-05-27**|**Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning**|Xun Liang et.al.|[2405.16933v1](http://arxiv.org/abs/2405.16933v1)|[link](https://github.com/iaar-shanghai/pgrag)|
|**2024-05-27**|**Entity Alignment with Noisy Annotations from Large Language Models**|Shengyuan Chen et.al.|[2405.16806v2](http://arxiv.org/abs/2405.16806v2)|null|
|**2024-05-27**|**TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing Graph and Text Mutual Transformations**|Zheng Zhang et.al.|[2405.16800v1](http://arxiv.org/abs/2405.16800v1)|null|
|**2024-05-26**|**KG-FIT: Knowledge Graph Fine-Tuning Upon Open-World Knowledge**|Pengcheng Jiang et.al.|[2405.16412v2](http://arxiv.org/abs/2405.16412v2)|[link](https://github.com/pat-jj/KG-FIT)|
|**2024-05-26**|**Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level**|Runlin Lei et.al.|[2405.16405v1](http://arxiv.org/abs/2405.16405v1)|null|
|**2024-05-25**|**COLT: Towards Completeness-Oriented Tool Retrieval for Large Language Models**|Changle Qu et.al.|[2405.16089v1](http://arxiv.org/abs/2405.16089v1)|null|
|**2024-05-24**|**Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias**|Andres Algaba et.al.|[2405.15739v2](http://arxiv.org/abs/2405.15739v2)|[link](https://github.com/andresalgaba/llm_citation_patterns)|

#### Abstracts
##### **Input Conditioned Graph Generation for Language Agents**
2406.11555v1 by Lukas Vierling, Jie Fu, Kai Chen

Recent progress in Large Language Models (LLMs) and language agents has
demonstrated significant promise for various future applications across
multiple disciplines. While traditional approaches to language agents often
rely on fixed, handcrafted designs, our research aims to develop both learnable
and dynamic agents. Our method uses an existing framework that abstracts
language agents as graphs. Within this graph framework, we aim to learn a model
that can generate edges for every given input to the language agent. This
allows us to generate edges that represent the flow of communication within the
graph based on the given input, thereby adjusting the internal communication of
a language agent. We learn to generate these edges using a pretrained LLM that
is fine-tuned with reinforcement learning. This LLM can be fine-tuned on
several datasets simultaneously, and we hypothesize that the model learns to
adapt to these different domains during training, achieving good overall
performance when encountering data from different domains during deployment. We
demonstrate that our approach surpasses the previous static approach by nearly
6% accuracy on a combined dataset of MMLU and CMMLU, and by more than 10% when
trained with a sparsity-inducing loss. It also performs superior in additional
experiments conducted with the MMLU and Mini Crossword Puzzles datasets. The
code is available at https://github.com/lukasVierling/DynamicGPTSwarm.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂíåËØ≠Ë®Ä‰ª£ÁêÜÊúÄËøëÁöÑËøõÂ±ïÂ∑≤Â±ïÁ§∫Âá∫ÂØπË∑®Â§ö‰∏™Â≠¶ÁßëÁöÑÂêÑÁßçÊú™Êù•Â∫îÁî®ÁöÑÈáçÂ§ßÂâçÊôØ„ÄÇËôΩÁÑ∂‰º†ÁªüÁöÑËØ≠Ë®Ä‰ª£ÁêÜÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂõ∫ÂÆöÁöÑÊâãÂ∑•ËÆæËÆ°Ôºå‰ΩÜÊàë‰ª¨ÁöÑÁ†îÁ©∂Êó®Âú®ÂºÄÂèëÂèØÂ≠¶‰π†ÂíåÂä®ÊÄÅÁöÑ‰ª£ÁêÜ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ΩøÁî®‰∫Ü‰∏Ä‰∏™Áé∞ÊúâÁöÑÊ°ÜÊû∂ÔºåÂ∞ÜËØ≠Ë®Ä‰ª£ÁêÜÊäΩË±°‰∏∫Âõæ„ÄÇÂú®Ëøô‰∏™ÂõæÊ°ÜÊû∂ÂÜÖÔºåÊàë‰ª¨Êó®Âú®Â≠¶‰π†‰∏Ä‰∏™Ê®°ÂûãÔºåËØ•Ê®°ÂûãÂèØ‰ª•‰∏∫ËØ≠Ë®Ä‰ª£ÁêÜÁöÑÊØè‰∏™ÁªôÂÆöËæìÂÖ•ÁîüÊàêËæπ„ÄÇËøô‰ΩøÊàë‰ª¨ËÉΩÂ§üÁîüÊàê‰ª£Ë°®Âõæ‰∏≠Âü∫‰∫éÁªôÂÆöËæìÂÖ•ÁöÑÈÄö‰ø°ÊµÅÁöÑËæπÔºå‰ªéËÄåË∞ÉÊï¥ËØ≠Ë®Ä‰ª£ÁêÜÁöÑÂÜÖÈÉ®ÈÄö‰ø°„ÄÇÊàë‰ª¨Â≠¶‰π†‰ΩøÁî®ÁªèËøáÂº∫ÂåñÂ≠¶‰π†ÂæÆË∞ÉÁöÑÈ¢ÑËÆ≠ÁªÉ LLM Êù•ÁîüÊàêËøô‰∫õËæπ„ÄÇËØ• LLM ÂèØ‰ª•ÂêåÊó∂Âú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°åÂæÆË∞ÉÔºåÊàë‰ª¨ÂÅáËÆæËØ•Ê®°ÂûãÂú®ËÆ≠ÁªÉÊúüÈó¥Â≠¶‰π†ÈÄÇÂ∫îËøô‰∫õ‰∏çÂêåÁöÑÂüüÔºåÂú®ÈÉ®ÁΩ≤ÊúüÈó¥ÈÅáÂà∞Êù•Ëá™‰∏çÂêåÂüüÁöÑÊï∞ÊçÆÊó∂ÂÆûÁé∞ËâØÂ•ΩÁöÑÊï¥‰ΩìÊÄßËÉΩ„ÄÇÊàë‰ª¨ËØÅÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú® MMLU Âíå CMMLU ÁöÑÁªÑÂêàÊï∞ÊçÆÈõÜ‰∏äÊØîÂÖàÂâçÁöÑÈùôÊÄÅÊñπÊ≥ïÈ´òÂá∫Ëøë 6% ÁöÑÂáÜÁ°ÆÂ∫¶ÔºåÂπ∂‰∏îÂú®‰ΩøÁî®Á®ÄÁñèÊÄßËØ±ÂØºÊçüÂ§±ËøõË°åËÆ≠ÁªÉÊó∂È´òÂá∫ 10% ‰ª•‰∏ä„ÄÇÂÆÉËøòÂú®‰ΩøÁî® MMLU ÂíåËø∑‰Ω†Â°´Â≠óÊ∏∏ÊàèÊï∞ÊçÆÈõÜËøõË°åÁöÑÂÖ∂‰ªñÂÆûÈ™å‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/lukasVierling/DynamicGPTSwarm Ëé∑Âæó„ÄÇ

##### **Large Language Models and Knowledge Graphs for Astronomical Entity Disambiguation**
2406.11400v1 by Golnaz Shapurian

This paper presents an experiment conducted during a hackathon, focusing on
using large language models (LLMs) and knowledge graph clustering to extract
entities and relationships from astronomical text. The study demonstrates an
approach to disambiguate entities that can appear in various contexts within
the astronomical domain. By collecting excerpts around specific entities and
leveraging the GPT-4 language model, relevant entities and relationships are
extracted. The extracted information is then used to construct a knowledge
graph, which is clustered using the Leiden algorithm. The resulting Leiden
communities are utilized to identify the percentage of association of unknown
excerpts to each community, thereby enabling disambiguation. The experiment
showcases the potential of combining LLMs and knowledge graph clustering
techniques for information extraction in astronomical research. The results
highlight the effectiveness of the approach in identifying and disambiguating
entities, as well as grouping them into meaningful clusters based on their
relationships.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫ÜÂú®ÈªëÂÆ¢È¶¨ÊãâÊùæ‰∏≠ÈÄ≤Ë°åÁöÑÂØ¶È©óÔºåÈáçÈªûÂú®Êñº‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁü•Ë≠òÂúñË≠úËÅöÈ°ûÔºåÂæûÂ§©ÊñáÊñáÊú¨‰∏≠ÊèêÂèñÂØ¶È´îÂíåÈóú‰øÇ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Â±ïÁ§∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂèØ‰ª•Ê∂àÈô§Âú®Â§©ÊñáÈ†òÂüü‰∏≠ÂêÑÁ®ÆË™ûÂ¢É‰∏≠Âá∫ÁèæÁöÑÂØ¶È´îÊ≠ßÁæ©ÊÄß„ÄÇÈÄèÈÅéÊî∂ÈõÜÁâπÂÆöÂØ¶È´îÂë®ÂúçÁöÑÊëòÈåÑÔºå‰∏¶Âà©Áî® GPT-4 Ë™ûË®ÄÊ®°ÂûãÔºåÂèØ‰ª•ÊèêÂèñÁõ∏ÈóúÂØ¶È´îÂíåÈóú‰øÇ„ÄÇÁÑ∂Âæå‰ΩøÁî®ÊèêÂèñÁöÑË≥áË®ä‰æÜÂª∫ÊßãÁü•Ë≠òÂúñË≠úÔºå‰∏¶‰ΩøÁî® Leiden ÊºîÁÆóÊ≥ïÈÄ≤Ë°åËÅöÈ°û„ÄÇÁµêÊûúÁî¢ÁîüÁöÑ Leiden Á§æÁæ§Áî®ÊñºË≠òÂà•Êú™Áü•ÊëòÈåÑËàáÊØèÂÄãÁ§æÁæ§ÁöÑÈóúËÅØÁôæÂàÜÊØîÔºåÂæûËÄåÊ∂àÈô§Ê≠ßÁæ©ÊÄß„ÄÇË©≤ÂØ¶È©óÂ±ïÁ§∫‰∫ÜÁµêÂêà LLM ÂíåÁü•Ë≠òÂúñË≠úËÅöÈ°ûÊäÄË°ìÂú®Â§©ÊñáÁ†îÁ©∂‰∏≠ÈÄ≤Ë°åË≥áË®äÊèêÂèñÁöÑÊΩõÂäõ„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜË©≤ÊñπÊ≥ïÂú®Ë≠òÂà•ÂíåÊ∂àÈô§ÂØ¶È´îÊ≠ßÁæ©ÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºå‰ª•ÂèäÊ†πÊìöÂØ¶È´î‰πãÈñìÁöÑÈóú‰øÇÂ∞áÂØ¶È´îÂàÜÁµÑÂà∞ÊúâÊÑèÁæ©ÁöÑÁæ§ÈõÜ‰∏≠„ÄÇ

##### **How Good are LLMs at Relation Extraction under Low-Resource Scenario? Comprehensive Evaluation**
2406.11162v1 by Dawulie Jinensibieke, Mieradilijiang Maimaiti, Wentao Xiao, Yuanhang Zheng, Xiangbo Wang

Relation Extraction (RE) serves as a crucial technology for transforming
unstructured text into structured information, especially within the framework
of Knowledge Graph development. Its importance is emphasized by its essential
role in various downstream tasks. Besides the conventional RE methods which are
based on neural networks and pre-trained language models, large language models
(LLMs) are also utilized in the research field of RE. However, on low-resource
languages (LRLs), both conventional RE methods and LLM-based methods perform
poorly on RE due to the data scarcity issues. To this end, this paper
constructs low-resource relation extraction datasets in 10 LRLs in three
regions (Central Asia, Southeast Asia and Middle East). The corpora are
constructed by translating the original publicly available English RE datasets
(NYT10, FewRel and CrossRE) using an effective multilingual machine
translation. Then, we use the language perplexity (PPL) to filter out the
low-quality data from the translated datasets. Finally, we conduct an empirical
study and validate the performance of several open-source LLMs on these
generated LRL RE datasets.

ÊëòË¶ÅÔºöÈóú‰øÇÊäΩÂèñ (RE) ÊòØ‰∏ÄÁ®ÆÂ∞áÈùûÁµêÊßãÂåñÊñáÊú¨ËΩâÊèõÁÇ∫ÁµêÊßãÂåñË≥áË®äÁöÑÈóúÈçµÊäÄË°ìÔºåÁâπÂà•ÊòØÂú®Áü•Ë≠òÂúñË≠úÈñãÁôºÁöÑÊû∂Êßã‰∏≠„ÄÇÂÆÉÂú®ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤ÔºåÁ™ÅÈ°Ø‰∫ÜÂÆÉÁöÑÈáçË¶ÅÊÄß„ÄÇÈô§‰∫ÜÂü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÂíåÈ†êÂÖàË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÂÇ≥Áµ± RE ÊñπÊ≥ïÂ§ñÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰πüË¢´Áî®Êñº RE ÁöÑÁ†îÁ©∂È†òÂüü‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂú®‰ΩéË≥áÊ∫êË™ûË®Ä (LRL) ‰∏≠ÔºåÁî±ÊñºË≥áÊñôÁ®ÄÂ∞ëÁöÑÂïèÈ°åÔºåÂÇ≥Áµ± RE ÊñπÊ≥ïÂíåÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÂú® RE ‰∏äÁöÑË°®ÁèæÈÉΩÂæàÂ∑Æ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÂú®‰∏âÂÄãÂçÄÂüüÔºà‰∏≠‰∫û„ÄÅÊù±Âçó‰∫ûÂíå‰∏≠Êù±Ôºâ‰∏≠ÁöÑ 10 Á®Æ LRL ‰∏≠Âª∫Êßã‰∫Ü‰ΩéË≥áÊ∫êÈóú‰øÇÊäΩÂèñË≥áÊñôÈõÜ„ÄÇË™ûÊñôÂ∫´ÊòØÈÄèÈÅé‰ΩøÁî®ÊúâÊïàÁöÑÂ§öË™ûË®ÄÊ©üÂô®ÁøªË≠ØÔºå‰æÜÁøªË≠ØÂéüÂßãÂÖ¨ÈñãÁöÑËã±Êñá RE Ë≥áÊñôÈõÜÔºàNYT10„ÄÅFewRel Âíå CrossREÔºâËÄåÂª∫ÊßãÁöÑ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®Ë™ûË®ÄÂõ∞ÊÉëÂ∫¶ (PPL) ÂæûÁøªË≠ØÂæåÁöÑË≥áÊñôÈõÜ‰∏≠ÁØ©ÈÅ∏Âá∫‰ΩéÂìÅË≥™ÁöÑË≥áÊñô„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂØ¶Ë≠âÁ†îÁ©∂Ôºå‰∏¶È©óË≠â‰∫ÜÂπæÂÄãÈñãÊ∫ê LLM Âú®ÈÄô‰∫õÁîüÊàêÁöÑ LRL RE Ë≥áÊñôÈõÜ‰∏äÁöÑÊïàËÉΩ„ÄÇ

##### **Move Beyond Triples: Contextual Knowledge Graph Representation and Reasoning**
2406.11160v1 by Chengjin Xu, Muzhi Li, Cehao Yang, Xuhui Jiang, Lumingyuan Tang, Yiyan Qi, Jian Guo

Knowledge Graphs (KGs) are foundational structures in many AI applications,
representing entities and their interrelations through triples. However,
triple-based KGs lack the contextual information of relational knowledge, like
temporal dynamics and provenance details, which are crucial for comprehensive
knowledge representation and effective reasoning. Instead, \textbf{Contextual
Knowledge Graphs} (CKGs) expand upon the conventional structure by
incorporating additional information such as time validity, geographic
location, and source provenance. This integration provides a more nuanced and
accurate understanding of knowledge, enabling KGs to offer richer insights and
support more sophisticated reasoning processes. In this work, we first discuss
the inherent limitations of triple-based KGs and introduce the concept of
contextual KGs, highlighting their advantages in knowledge representation and
reasoning. We then present \textbf{KGR$^3$, a context-enriched KG reasoning
paradigm} that leverages large language models (LLMs) to retrieve candidate
entities and related contexts, rank them based on the retrieved information,
and reason whether sufficient information has been obtained to answer a query.
Our experimental results demonstrate that KGR$^3$ significantly improves
performance on KG completion (KGC) and KG question answering (KGQA) tasks,
validating the effectiveness of incorporating contextual information on KG
representation and reasoning.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) ÊòØË®±Â§ö AI ÊáâÁî®‰∏≠ÁöÑÂü∫Á§éÁµêÊßãÔºåÈÄèÈÅé‰∏âÂÖÉÁµÑË°®Á§∫ÂØ¶È´îÂèäÂÖ∂Áõ∏‰∫íÈóú‰øÇ„ÄÇÁÑ∂ËÄåÔºåÂü∫Êñº‰∏âÂÖÉÁµÑÁöÑ KG Áº∫‰πèÈóú‰øÇÁü•Ë≠òÁöÑËÉåÊôØË≥áË®äÔºå‰æãÂ¶ÇÊôÇÈñìÂãïÊÖãÂíå‰æÜÊ∫êË©≥Á¥∞Ë≥áÊñôÔºåÈÄô‰∫õÂ∞çÊñºÂÖ®Èù¢ÁöÑÁü•Ë≠òË°®Á§∫ÂíåÊúâÊïàÊé®ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÁõ∏ÂèçÂú∞Ôºå**ËÉåÊôØÁü•Ë≠òÂúñË≠ú** (CKG) ÈÄèÈÅéÊï¥ÂêàÊôÇÈñìÊúâÊïàÊÄß„ÄÅÂú∞ÁêÜ‰ΩçÁΩÆÂíå‰æÜÊ∫êÂá∫ËôïÁ≠âÈ°çÂ§ñË≥áË®äÔºå‰æÜÊì¥ÂÖÖÂÇ≥Áµ±ÁµêÊßã„ÄÇÈÄôÁ®ÆÊï¥ÂêàÊèê‰æõ‰∫ÜÂ∞çÁü•Ë≠òÊõ¥Á¥∞Á∑ª‰∏îÊ∫ñÁ¢∫ÁöÑÁêÜËß£Ôºå‰Ωø KG ËÉΩÂ§†Êèê‰æõÊõ¥Ë±êÂØåÁöÑË¶ãËß£‰∏¶ÊîØÊè¥Êõ¥Á≤æÂØÜÁöÑÊé®ÁêÜÊµÅÁ®ã„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàË®éË´ñÂü∫Êñº‰∏âÂÖÉÁµÑÁöÑ KG ÁöÑÂÖßÂú®ÈôêÂà∂Ôºå‰∏¶‰ªãÁ¥πËÉåÊôØ KG ÁöÑÊ¶ÇÂøµÔºåÂº∑Ë™øÂÆÉÂÄëÂú®Áü•Ë≠òË°®Á§∫ÂíåÊé®ÁêÜ‰∏äÁöÑÂÑ™Èªû„ÄÇÁÑ∂ÂæåÊàëÂÄëÊèêÂá∫**KGR$^3$Ôºå‰∏ÄÁ®ÆËÉåÊôØË±êÂØåÁöÑ KG Êé®ÁêÜÁØÑ‰æã**ÔºåÂÆÉÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÊì∑ÂèñÂÄôÈÅ∏ÂØ¶È´îÂíåÁõ∏ÈóúËÉåÊôØÔºåÊ†πÊìöÊì∑ÂèñÁöÑË≥áË®äÂ∞çÂÆÉÂÄëÈÄ≤Ë°åÊéíÂêçÔºå‰∏¶Êé®Ë´ñÊòØÂê¶Â∑≤ÂèñÂæóË∂≥Â§†ÁöÑË≥áË®ä‰æÜÂõûÁ≠îÊü•Ë©¢„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåKGR$^3$ Â§ßÂπÖÊèêÂçá‰∫Ü KG ÂÆåÊàê (KGC) Âíå KG ÂïèÈ°åËß£Á≠î (KGQA) ‰ªªÂãôÁöÑÊïàËÉΩÔºåÈ©óË≠â‰∫ÜÂ∞áËÉåÊôØË≥áË®äÁ¥çÂÖ• KG Ë°®Á§∫ÂíåÊé®ÁêÜÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Are Large Language Models a Good Replacement of Taxonomies?**
2406.11131v1 by Yushi Sun, Hao Xin, Kai Sun, Yifan Ethan Xu, Xiao Yang, Xin Luna Dong, Nan Tang, Lei Chen

Large language models (LLMs) demonstrate an impressive ability to internalize
knowledge and answer natural language questions. Although previous studies
validate that LLMs perform well on general knowledge while presenting poor
performance on long-tail nuanced knowledge, the community is still doubtful
about whether the traditional knowledge graphs should be replaced by LLMs. In
this paper, we ask if the schema of knowledge graph (i.e., taxonomy) is made
obsolete by LLMs. Intuitively, LLMs should perform well on common taxonomies
and at taxonomy levels that are common to people. Unfortunately, there lacks a
comprehensive benchmark that evaluates the LLMs over a wide range of taxonomies
from common to specialized domains and at levels from root to leaf so that we
can draw a confident conclusion. To narrow the research gap, we constructed a
novel taxonomy hierarchical structure discovery benchmark named TaxoGlimpse to
evaluate the performance of LLMs over taxonomies. TaxoGlimpse covers ten
representative taxonomies from common to specialized domains with in-depth
experiments of different levels of entities in this taxonomy from root to leaf.
Our comprehensive experiments of eighteen state-of-the-art LLMs under three
prompting settings validate that LLMs can still not well capture the knowledge
of specialized taxonomies and leaf-level entities.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ë°®ÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÂÖßÂåñÁü•Ë≠òÂíåÂõûÁ≠îËá™ÁÑ∂Ë™ûË®ÄÂïèÈ°åÁöÑËÉΩÂäõ„ÄÇÂÑòÁÆ°ÂÖàÂâçÁöÑÁ†îÁ©∂È©óË≠â‰∫Ü LLM Âú®‰∏ÄËà¨Áü•Ë≠ò‰∏äË°®ÁèæËâØÂ•ΩÔºå‰ΩÜÂú®Èï∑Â∞æÁ¥∞Á∑ªÁü•Ë≠ò‰∏äË°®Áèæ‰∏ç‰Ω≥Ôºå‰ΩÜÁ§æÁæ§‰ªçÊá∑ÁñëÂÇ≥Áµ±Áü•Ë≠òÂúñË≠úÊòØÂê¶ÊáâÁî± LLM Âèñ‰ª£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÁü•Ë≠òÂúñË≠úÊû∂ÊßãÔºàÂç≥ÂàÜÈ°ûÊ≥ïÔºâÊòØÂê¶Âõ† LLM ËÄåÈÅéÊôÇ„ÄÇÁõ¥Ë¶∫‰∏äÔºåLLM ÊáâË©≤Âú®Â∏∏Ë¶ãÂàÜÈ°ûÊ≥ïÂíåÂ∞ç‰∫∫‰æÜË™™ÂæàÂ∏∏Ë¶ãÁöÑÂàÜÈ°ûÊ≥ïÂ±§Á¥ö‰∏äË°®ÁèæËâØÂ•Ω„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÁº∫‰πè‰∏ÄÂÄãÁ∂úÂêàÂü∫Ê∫ñ‰æÜË©ï‰º∞ LLM Âú®Âæû‰∏ÄËà¨Âà∞Â∞àÊ•≠È†òÂüüÁöÑÂêÑÁ®ÆÂàÜÈ°ûÊ≥ï‰ª•ÂèäÂæûÊ†πÂà∞ËëâÁöÑÂ±§Á¥ö‰∏äÔºå‰ª•‰æøÊàëÂÄëÂèØ‰ª•ÂæóÂá∫Á¢∫‰ø°ÁöÑÁµêË´ñ„ÄÇÁÇ∫‰∫ÜÁ∏ÆÂ∞èÁ†îÁ©∂Â∑ÆË∑ùÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ TaxoGlimpse ÁöÑÊñ∞ÂàÜÈ°ûÊ≥ïÈöéÂ±§ÁµêÊßãÁôºÁèæÂü∫Ê∫ñÔºå‰ª•Ë©ï‰º∞ LLM Âú®ÂàÜÈ°ûÊ≥ï‰∏äÁöÑË°®Áèæ„ÄÇTaxoGlimpse Ê∂µËìã‰∫ÜÂæû‰∏ÄËà¨Âà∞Â∞àÊ•≠È†òÂüüÁöÑÂçÅÂÄã‰ª£Ë°®ÊÄßÂàÜÈ°ûÊ≥ïÔºå‰∏¶Â∞çË©≤ÂàÜÈ°ûÊ≥ï‰∏≠ÂæûÊ†πÂà∞ËëâÁöÑ‰∏çÂêåÂ±§Á¥öÂØ¶È´îÈÄ≤Ë°å‰∫ÜÊ∑±ÂÖ•ÂØ¶È©ó„ÄÇÊàëÂÄëÂ∞ç 18 ÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLM Âú®‰∏âÁ®ÆÊèêÁ§∫Ë®≠ÁΩÆ‰∏ãÁöÑÁ∂úÂêàÂØ¶È©óÈ©óË≠â‰∫Ü LLM ‰ªçÁÑ∂ÁÑ°Ê≥ïÂæàÂ•ΩÂú∞ÊéåÊè°Â∞àÊ•≠ÂàÜÈ°ûÊ≥ïÂíåËëâÁ¥öÂØ¶È´îÁöÑÁü•Ë≠ò„ÄÇ

##### **DocNet: Semantic Structure in Inductive Bias Detection Models**
2406.10965v1 by Jessica Zhu, Iain Cruickshank, Michel Cukier

News will have biases so long as people have opinions. However, as social
media becomes the primary entry point for news and partisan gaps increase, it
is increasingly important for informed citizens to be able to identify bias.
People will be able to take action to avoid polarizing echo chambers if they
know how the news they are consuming is biased. In this paper, we explore an
often overlooked aspect of bias detection in documents: the semantic structure
of news articles. We present DocNet, a novel, inductive, and low-resource
document embedding and bias detection model that outperforms large language
models. We also demonstrate that the semantic structure of news articles from
opposing partisan sides, as represented in document-level graph embeddings,
have significant similarities. These results can be used to advance bias
detection in low-resource environments. Our code and data are made available at
https://github.com/nlpresearchanon.

ÊëòË¶ÅÔºöÊñ∞ËÅûÊúÉÂ≠òÂú®ÂÅèË¶ãÔºåÂè™Ë¶Å‰∫∫ÂÄëÊúâÊÑèË¶ã„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁ§æÁæ§Â™íÈ´îÊàêÁÇ∫Êñ∞ËÅûÁöÑ‰∏ªË¶ÅÂÖ•Âè£Ôºå‰∏îÈª®Ê¥æÂ∑ÆË∑ùÊì¥Â§ßÔºåÂ∞çÊñºÊúâÁü•Ë≠òÁöÑÂÖ¨Ê∞ë‰æÜË™™ÔºåËÉΩÂ§†Ëæ®Ë≠òÂÅèË¶ãËÆäÂæóÊÑà‰æÜÊÑàÈáçË¶Å„ÄÇÂ¶ÇÊûú‰∫∫ÂÄëÁü•ÈÅì‰ªñÂÄëÊâÄÊé•Êî∂ÁöÑÊñ∞ËÅûÂ¶Ç‰ΩïÂÅèÈ†óÔºå‰ªñÂÄëÂ∞±ËÉΩÊé°ÂèñË°åÂãï‰æÜÈÅøÂÖçÂÖ©Ê•µÂåñÁöÑÂêåÊ∫´Â±§„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÊñá‰ª∂ÂÅèË¶ãÂÅµÊ∏¨‰∏≠Á∂ìÂ∏∏Ë¢´ÂøΩÁï•ÁöÑ‰∏ÄÈù¢ÔºöÊñ∞ËÅûÊñáÁ´†ÁöÑË™ûÊÑèÁµêÊßã„ÄÇÊàëÂÄëÊèêÂá∫ DocNetÔºå‰∏ÄÂÄãÊñ∞Á©é„ÄÅÊ≠∏Á¥ç‰∏î‰ΩéË≥áÊ∫êÁöÑÊñá‰ª∂ÂµåÂÖ•ÂíåÂÅèË¶ãÂÅµÊ∏¨Ê®°ÂûãÔºåÂÖ∂Ë°®ÁèæÂÑ™ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÇÊàëÂÄë‰πüË≠âÊòéÔºå‰æÜËá™Â∞çÁ´ãÈª®Ê¥æÈô£ÁáüÁöÑÊñ∞ËÅûÊñáÁ´†ÁöÑË™ûÊÑèÁµêÊßãÔºåÂ¶ÇÊñá‰ª∂Â±§Á¥öÂúñÂµåÂÖ•‰∏≠ÊâÄÂëàÁèæÁöÑÔºåÂÖ∑ÊúâÈ°ØËëóÁöÑÁõ∏‰ººÊÄß„ÄÇÈÄô‰∫õÁµêÊûúÂèØÁî®ÊñºÊé®ÈÄ≤‰ΩéË≥áÊ∫êÁí∞Â¢É‰∏≠ÁöÑÂÅèË¶ãÂÅµÊ∏¨„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/nlpresearchanon ÂèñÂæó„ÄÇ

##### **Light Up the Shadows: Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models**
2406.10902v1 by Yikai Zhang, Qianyu He, Xintao Wang, Siyu Yuan, Jiaqing Liang, Yanghua Xiao

Multi-Modal Knowledge Graphs (MMKGs) have proven valuable for various
downstream tasks. However, scaling them up is challenging because building
large-scale MMKGs often introduces mismatched images (i.e., noise). Most
entities in KGs belong to the long tail, meaning there are few images of them
available online. This scarcity makes it difficult to determine whether a found
image matches the entity. To address this, we draw on the Triangle of Reference
Theory and suggest enhancing vision-language models with concept guidance.
Specifically, we introduce COG, a two-stage framework with COncept-Guided
vision-language models. The framework comprises a Concept Integration module,
which effectively identifies image-text pairs of long-tailed entities, and an
Evidence Fusion module, which offers explainability and enables human
verification. To demonstrate the effectiveness of COG, we create a dataset of
25k image-text pairs of long-tailed entities. Our comprehensive experiments
show that COG not only improves the accuracy of recognizing long-tailed
image-text pairs compared to baselines but also offers flexibility and
explainability.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÁü•ËØÜÂõæË∞± (MMKG) Â∑≤Ë¢´ËØÅÊòéÂØπÂêÑÁßç‰∏ãÊ∏∏‰ªªÂä°ÂæàÊúâ‰ª∑ÂÄº„ÄÇÁÑ∂ËÄåÔºåÊâ©Â±ïÂÆÉ‰ª¨ÂÖ∑ÊúâÊåëÊàòÊÄßÔºåÂõ†‰∏∫ÊûÑÂª∫Â§ßËßÑÊ®° MMKG ÁªèÂ∏∏‰ºöÂºïÂÖ•‰∏çÂåπÈÖçÁöÑÂõæÂÉèÔºàÂç≥Âô™Â£∞Ôºâ„ÄÇÁü•ËØÜÂõæË∞±‰∏≠ÁöÑÂ§ßÂ§öÊï∞ÂÆû‰ΩìÈÉΩÂ±û‰∫éÈïøÂ∞æÔºåËøôÊÑèÂë≥ÁùÄÁΩë‰∏äÂæàÂ∞ëÊúâÂÆÉ‰ª¨ÁöÑÂõæÂÉè„ÄÇËøôÁßçÁ®ÄÁº∫ÊÄß‰ΩøÂæóÈöæ‰ª•Á°ÆÂÆöÊâæÂà∞ÁöÑÂõæÂÉèÊòØÂê¶‰∏éÂÆû‰ΩìÂåπÈÖç„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂÄüÈâ¥‰∫Ü‰∏âËßíÂèÇÁÖßÁêÜËÆ∫ÔºåÂπ∂Âª∫ËÆÆÁî®Ê¶ÇÂøµÊåáÂØºÊù•Â¢ûÂº∫ËßÜËßâËØ≠Ë®ÄÊ®°Âûã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü COGÔºåËøôÊòØ‰∏Ä‰∏™Â∏¶ÊúâÊ¶ÇÂøµÊåáÂØºËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∏§Èò∂ÊÆµÊ°ÜÊû∂„ÄÇËØ•Ê°ÜÊû∂ÂåÖÂê´‰∏Ä‰∏™Ê¶ÇÂøµÈõÜÊàêÊ®°ÂùóÔºåËØ•Ê®°ÂùóÊúâÊïàÂú∞ËØÜÂà´ÈïøÂ∞æÂÆû‰ΩìÁöÑÂõæÂÉèÊñáÊú¨ÂØπÔºå‰ª•Âèä‰∏Ä‰∏™ËØÅÊçÆËûçÂêàÊ®°ÂùóÔºåËØ•Ê®°ÂùóÊèê‰æõÂèØËß£ÈáäÊÄßÂπ∂ÊîØÊåÅ‰∫∫Â∑•È™åËØÅ„ÄÇ‰∏∫‰∫ÜËØÅÊòé COG ÁöÑÊúâÊïàÊÄßÔºåÊàë‰ª¨ÂàõÂª∫‰∫Ü‰∏Ä‰∏™Áî± 25k ‰∏™ÈïøÂ∞æÂÆû‰ΩìÁöÑÂõæÂÉèÊñáÊú¨ÂØπÁªÑÊàêÁöÑÊï∞ÊçÆÈõÜ„ÄÇÊàë‰ª¨ÁöÑÁªºÂêàÂÆûÈ™åË°®ÊòéÔºå‰∏éÂü∫Á∫øÁõ∏ÊØîÔºåCOG ‰∏ç‰ªÖÊèêÈ´ò‰∫ÜËØÜÂà´ÈïøÂ∞æÂõæÂÉèÊñáÊú¨ÂØπÁöÑÂáÜÁ°ÆÊÄßÔºåËøòÊèê‰æõ‰∫ÜÁÅµÊ¥ªÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇ

##### **KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs**
2406.10802v1 by Aihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, Ju Jia, Lina Wang

Existing frameworks for assessing robustness of large language models (LLMs)
overly depend on specific benchmarks, increasing costs and failing to evaluate
performance of LLMs in professional domains due to dataset limitations. This
paper proposes a framework that systematically evaluates the robustness of LLMs
under adversarial attack scenarios by leveraging knowledge graphs (KGs). Our
framework generates original prompts from the triplets of knowledge graphs and
creates adversarial prompts by poisoning, assessing the robustness of LLMs
through the results of these adversarial attacks. We systematically evaluate
the effectiveness of this framework and its modules. Experiments show that
adversarial robustness of the ChatGPT family ranks as GPT-4-turbo > GPT-4o >
GPT-3.5-turbo, and the robustness of large language models is influenced by the
professional domains in which they operate.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÁî®ÊñºË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Á©©ÂÅ•ÊÄßÁöÑÊ°ÜÊû∂ÈÅéÊñº‰æùË≥¥ÁâπÂÆöÂü∫Ê∫ñÔºåÈÄôÊúÉÂ¢ûÂä†ÊàêÊú¨ÔºåËÄå‰∏îÁî±ÊñºË≥áÊñôÈõÜÁöÑÈôêÂà∂ÔºåÁÑ°Ê≥ïË©ï‰º∞ LLM Âú®Â∞àÊ•≠È†òÂüüÁöÑÊïàËÉΩ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊ°ÜÊû∂ÔºåÂà©Áî®Áü•Ë≠òÂúñË≠ú (KG) Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞ LLM Âú®Â∞çÊäóÊîªÊìäÂ†¥ÊôØ‰∏ãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂ÂæûÁü•Ë≠òÂúñË≠úÁöÑ‰∏âÂÖÉÁµÑ‰∏≠Áî¢ÁîüÂéüÂßãÊèêÁ§∫Ôºå‰∏¶ÈÄèÈÅéÊäïÊØíÂª∫Á´ãÂ∞çÊäóÊèêÁ§∫ÔºåÈÄèÈÅéÈÄô‰∫õÂ∞çÊäóÊîªÊìäÁöÑÁµêÊûú‰æÜË©ï‰º∞ LLM ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞‰∫ÜÊ≠§Ê°ÜÊû∂ÂèäÂÖ∂Ê®°ÁµÑÁöÑÊúâÊïàÊÄß„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåChatGPT ÂÆ∂ÊóèÁöÑÂ∞çÊäóÁ©©ÂÅ•ÊÄßÊéíÂêçÁÇ∫ GPT-4-turbo > GPT-4o > GPT-3.5-turboÔºåËÄå‰∏îÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÁ©©ÂÅ•ÊÄßÊúÉÂèóÂà∞ÂÖ∂ÈÅã‰ΩúÁöÑÂ∞àÊ•≠È†òÂüüÂΩ±Èüø„ÄÇ

##### **A Comprehensive Survey of Foundation Models in Medicine**
2406.10729v1 by Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, Ruogu Fang

Foundation models (FMs) are large-scale deep-learning models trained on
extensive datasets using self-supervised techniques. These models serve as a
base for various downstream tasks, including healthcare. FMs have been adopted
with great success across various domains within healthcare, including natural
language processing (NLP), computer vision, graph learning, biology, and omics.
Existing healthcare-based surveys have not yet included all of these domains.
Therefore, this survey provides a comprehensive overview of FMs in healthcare.
We focus on the history, learning strategies, flagship models, applications,
and challenges of FMs. We explore how FMs such as the BERT and GPT families are
reshaping various healthcare domains, including clinical large language models,
medical image analysis, and omics data. Furthermore, we provide a detailed
taxonomy of healthcare applications facilitated by FMs, such as clinical NLP,
medical computer vision, graph learning, and other biology-related tasks.
Despite the promising opportunities FMs provide, they also have several
associated challenges, which are explained in detail. We also outline potential
future directions to provide researchers and practitioners with insights into
the potential and limitations of FMs in healthcare to advance their deployment
and mitigate associated risks.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°Âûã (FM) ÊòØ‰ΩøÁî®Ëá™ÊàëÁõ£Áù£ÊäÄË°ìÂú®Âª£Ê≥õÊï∏ÊìöÈõÜ‰∏äË®ìÁ∑¥ÁöÑÂ§ßË¶èÊ®°Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄô‰∫õÊ®°Âûã‰ΩúÁÇ∫ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãôÁöÑÂü∫Á§éÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇFM Â∑≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÂêÑÁ®ÆÈ†òÂüü‰∏≠Ë¢´Âª£Ê≥õÊé°Áî®ÔºåÂåÖÊã¨Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP)„ÄÅÈõªËÖ¶Ë¶ñË¶∫„ÄÅÂúñÂΩ¢Â≠∏Áøí„ÄÅÁîüÁâ©Â≠∏ÂíåÁµÑÂ≠∏„ÄÇÁèæÊúâÁöÑÂü∫ÊñºÈÜ´ÁôÇ‰øùÂÅ•ÁöÑË™øÊü•Â∞öÊú™Ê∂µËìãÊâÄÊúâÈÄô‰∫õÈ†òÂüü„ÄÇÂõ†Ê≠§ÔºåÊú¨Ë™øÊü•Êèê‰æõ‰∫Ü FM Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÖ®Èù¢Ê¶ÇËø∞„ÄÇÊàëÂÄëÂ∞àÊ≥®Êñº FM ÁöÑÊ≠∑Âè≤„ÄÅÂ≠∏ÁøíÁ≠ñÁï•„ÄÅÊóóËâ¶Ê®°Âûã„ÄÅÊáâÁî®ÂíåÊåëÊà∞„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü BERT Âíå GPT ÂÆ∂ÊóèÁ≠â FM Â¶Ç‰ΩïÈáçÂ°ëÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÂåÖÊã¨Ëá®Â∫äÂ§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÅÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÂíåÁµÑÂ≠∏Êï∏Êìö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÁî± FM ‰øÉÈÄ≤ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®Ë©≥Á¥∞ÂàÜÈ°ûÊ≥ïÔºå‰æãÂ¶ÇËá®Â∫ä NLP„ÄÅÈÜ´Â≠∏ÈõªËÖ¶Ë¶ñË¶∫„ÄÅÂúñÂΩ¢Â≠∏ÁøíÂíåÂÖ∂‰ªñËàáÁîüÁâ©Áõ∏ÈóúÁöÑ‰ªªÂãô„ÄÇÂÑòÁÆ° FM Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÊ©üÊúÉÔºå‰ΩÜÂÆÉÂÄë‰πüÈù¢Ëá®Ëëó‰∏Ä‰∫õÁõ∏ÈóúÁöÑÊåëÊà∞ÔºåÈÄô‰∫õÊåëÊà∞Âú®Êñá‰∏≠ÈÉΩÊúâË©≥Á¥∞Ë™™Êòé„ÄÇÊàëÂÄëÈÇÑÊ¶ÇËø∞‰∫ÜÊΩõÂú®ÁöÑÊú™‰æÜÊñπÂêëÔºåÁÇ∫Á†îÁ©∂‰∫∫Âì°ÂíåÂæûÊ•≠ËÄÖÊèê‰æõÊúâÈóú FM Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊΩõÂäõÂíåÂ±ÄÈôêÊÄßÁöÑË¶ãËß£Ôºå‰ª•Êé®ÈÄ≤ÂÖ∂ÈÉ®ÁΩ≤‰∏¶Ê∏õËºïÁõ∏ÈóúÈ¢®Èö™„ÄÇ

##### **SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**
2406.10710v1 by Ziije Zhong, Linqing Zhong, Zhaoze Sun, Qingyun Jin, Zengchang Qin, Xiaofan Zhang

Integrating Large Language Models (LLMs) with existing Knowledge Graph (KG)
databases presents a promising avenue for enhancing LLMs' efficacy and
mitigating their "hallucinations". Given that most KGs reside in graph
databases accessible solely through specialized query languages (e.g., Cypher),
there exists a critical need to bridge the divide between LLMs and KG databases
by automating the translation of natural language into Cypher queries (commonly
termed the "Text2Cypher" task). Prior efforts tried to bolster LLMs'
proficiency in Cypher generation through Supervised Fine-Tuning. However, these
explorations are hindered by the lack of annotated datasets of Query-Cypher
pairs, resulting from the labor-intensive and domain-specific nature of
annotating such datasets. In this study, we propose SyntheT2C, a methodology
for constructing a synthetic Query-Cypher pair dataset, comprising two distinct
pipelines: (1) LLM-based prompting and (2) template-filling. SyntheT2C
facilitates the generation of extensive Query-Cypher pairs with values sampled
from an underlying Neo4j graph database. Subsequently, SyntheT2C is applied to
two medical databases, culminating in the creation of a synthetic dataset,
MedT2C. Comprehensive experiments demonstrate that the MedT2C dataset
effectively enhances the performance of backbone LLMs on the Text2Cypher task.
Both the SyntheT2C codebase and the MedT2C dataset will be released soon.

ÊëòË¶ÅÔºö<paragraph>Â∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÁèæÊúâÁöÑÁü•Ë≠òÂúñË≠ú (KG) Ë≥áÊñôÂ∫´Êï¥ÂêàÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊèêÂçá LLM ÊïàËÉΩ‰∏¶Ê∏õËºïÂÖ∂„ÄåÂπªË¶∫„ÄçÁöÑÈÄîÂæë„ÄÇÁî±ÊñºÂ§ßÂ§öÊï∏ KG ÈÉΩÂ≠òÂú®ÊñºÂÉÖËÉΩÈÄèÈÅéÂ∞àÁî®Êü•Ë©¢Ë™ûË®ÄÔºà‰æãÂ¶Ç CypherÔºâÂ≠òÂèñÁöÑÂúñÂΩ¢Ë≥áÊñôÂ∫´‰∏≠ÔºåÂõ†Ê≠§Ëø´ÂàáÈúÄË¶ÅËá™ÂãïÂåñÂ∞áËá™ÁÑ∂Ë™ûË®ÄËΩâÊèõÁÇ∫ Cypher Êü•Ë©¢Ôºå‰ª•ÂΩåÂêà LLM Ëàá KG Ë≥áÊñôÂ∫´‰πãÈñìÁöÑÈ¥ªÊ∫ùÔºàÈÄöÂ∏∏Á®±ÁÇ∫„ÄåText2Cypher„Äç‰ªªÂãôÔºâ„ÄÇÂÖàÂâçÁöÑÂä™ÂäõÂòóË©¶ÈÄèÈÅéÁõ£Áù£ÂæÆË™ø‰æÜÊèêÂçá LLM Âú® Cypher ÁîüÊàêÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊé¢Á¥¢ÂèóÂà∞Áº∫‰πèÊü•Ë©¢-Cypher ÈÖçÂ∞çÁöÑË®ªËß£Ë≥áÊñôÈõÜÁöÑÈòªÁ§ôÔºåÈÄôÊòØÂõ†ÁÇ∫Ê≠§È°ûË≥áÊñôÈõÜÁöÑË®ªËß£ÈúÄË¶ÅÂ§ßÈáè‰∫∫Âäõ‰∏îÂÖ∑ÊúâÁâπÂÆöÈ†òÂüüÁöÑÊÄßË≥™„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü SyntheT2CÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁî®ÊñºÂª∫ÊßãÂêàÊàêÊü•Ë©¢-Cypher ÈÖçÂ∞çË≥áÊñôÈõÜÁöÑÊñπÊ≥ïÔºåÂåÖÂê´ÂÖ©ÂÄã‰∏çÂêåÁöÑÁÆ°ÈÅìÔºö(1) Âü∫Êñº LLM ÁöÑÊèêÁ§∫Âíå (2) ÁØÑÊú¨Â°´ÂØ´„ÄÇSyntheT2C ‰øÉÈÄ≤‰∫ÜÂ§ßÈáèÊü•Ë©¢-Cypher ÈÖçÂ∞çÁöÑÁî¢ÁîüÔºåÂÖ∂ÂÄºÂèñÊ®£Ëá™Âü∫Á§éÁöÑ Neo4j ÂúñÂΩ¢Ë≥áÊñôÂ∫´„ÄÇÈö®ÂæåÔºåÂ∞á SyntheT2C ÊáâÁî®ÊñºÂÖ©ÂÄãÈÜ´ÁôÇË≥áÊñôÂ∫´ÔºåÊúÄÁµÇÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂêàÊàêË≥áÊñôÈõÜ MedT2C„ÄÇÂÖ®Èù¢ÁöÑÂØ¶È©óË≠âÊòéÔºåMedT2C Ë≥áÊñôÈõÜÊúâÊïàÊèêÂçá‰∫Ü‰∏ªÂππ LLM Âú® Text2Cypher ‰ªªÂãô‰∏äÁöÑÊïàËÉΩ„ÄÇSyntheT2C Á®ãÂºèÁ¢ºÂ∫´Âíå MedT2C Ë≥áÊñôÈõÜÈÉΩÂ∞áÂæàÂø´ÈáãÂá∫„ÄÇ</paragraph>

##### **Large Language Models as Event Forecasters**
2406.10492v1 by Libo Zhang, Yue Ning

Key elements of human events are extracted as quadruples that consist of
subject, relation, object, and timestamp. This representation can be extended
to a quintuple by adding a fifth element: a textual summary that briefly
describes the event. These quadruples or quintuples, when organized within a
specific domain, form a temporal knowledge graph (TKG). Current learning
frameworks focus on a few TKG-related tasks, such as predicting an object given
a subject and a relation or forecasting the occurrences of multiple types of
events (i.e., relation) in the next time window. They typically rely on complex
structural and sequential models like graph neural networks (GNNs) and
recurrent neural networks (RNNs) to update intermediate embeddings. However,
these methods often neglect the contextual information inherent in each
quintuple, which can be effectively captured through concise textual
descriptions. In this paper, we investigate how large language models (LLMs)
can streamline the design of TKG learning frameworks while maintaining
competitive accuracy in prediction and forecasting tasks. We develop multiple
prompt templates to frame the object prediction (OP) task as a standard
question-answering (QA) task, suitable for instruction fine-tuning with an
encoder-decoder generative LLM. For multi-event forecasting (MEF), we design
simple yet effective prompt templates for each TKG quintuple. This novel
approach removes the need for GNNs and RNNs, instead utilizing an encoder-only
LLM to generate fixed intermediate embeddings, which are subsequently processed
by a prediction head with a self-attention mechanism to forecast potential
future relations. Extensive experiments on multiple real-world datasets using
various evaluation metrics validate the effectiveness and robustness of our
approach.

ÊëòË¶ÅÔºö<paragraph>‰∫∫È°û‰∫ã‰ª∂ÁöÑ‰∏ªË¶ÅÂÖÉÁ¥†Ë¢´ËêÉÂèñÁÇ∫Áî±‰∏ªË©û„ÄÅÈóú‰øÇ„ÄÅÂèóË©ûÂíåÊôÇÈñìÊà≥ÁµÑÊàêÁöÑÂõõÂÖÉÁµÑ„ÄÇÊ≠§Ë°®Á§∫Ê≥ïÂèØÈÄèÈÅéÊñ∞Â¢ûÁ¨¨‰∫îÂÄãÂÖÉÁ¥†‰æÜÂª∂‰º∏ÁÇ∫‰∫îÂÖÉÁµÑÔºöÁ∞°Ë¶ÅÊèèËø∞‰∫ã‰ª∂ÁöÑÊñáÂ≠óÊëòË¶Å„ÄÇÈÄô‰∫õÂõõÂÖÉÁµÑÊàñ‰∫îÂÖÉÁµÑÂú®ÁâπÂÆöÈ†òÂüü‰∏≠ÁµÑÁπîÊôÇÔºåÊúÉÂΩ¢ÊàêÊôÇÂ∫èÁü•Ë≠òÂúñË≠ú (TKG)„ÄÇÁõÆÂâçÁöÑÂ≠∏ÁøíÊû∂ÊßãÂ∞àÊ≥®Êñº‰∏Ä‰∫õËàá TKG Áõ∏ÈóúÁöÑ‰ªªÂãôÔºå‰æãÂ¶ÇÂú®Áµ¶ÂÆö‰∏ªË©ûÂíåÈóú‰øÇÁöÑÊÉÖÊ≥Å‰∏ãÈ†êÊ∏¨ÂèóË©ûÔºåÊàñÈ†êÊ∏¨‰∏ã‰∏ÄÂÄãÊôÇÈñìË¶ñÁ™ó‰∏≠Â§öÁ®ÆÈ°ûÂûã‰∫ã‰ª∂ÔºàÂç≥Èóú‰øÇÔºâÁöÑÁôºÁîü„ÄÇÂÆÉÂÄëÈÄöÂ∏∏‰æùË≥¥ÊñºË§áÈõúÁöÑÁµêÊßãÂíåÂ∫èÂàóÊ®°ÂûãÔºå‰æãÂ¶ÇÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÂíåÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑Ø (RNN)Ôºå‰æÜÊõ¥Êñ∞‰∏≠ÈñìÂµåÂÖ•„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁ∂ìÂ∏∏ÂøΩÁï•ÊØèÂÄã‰∫îÂÖÉÁµÑ‰∏≠Âõ∫ÊúâÁöÑËÑàÁµ°Ë≥áË®äÔºåËÄåÈÄô‰∫õË≥áË®äÂèØÈÄèÈÅéÁ∞°ÊΩîÁöÑÊñáÂ≠óÊèèËø∞ÊúâÊïàÊì∑Âèñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â¶Ç‰ΩïÁ∞°Âåñ TKG Â≠∏ÁøíÊû∂ÊßãÁöÑË®≠Ë®àÔºåÂêåÊôÇÂú®È†êÊ∏¨ÂíåÈ†êÊ∏¨‰ªªÂãô‰∏≠Á∂≠ÊåÅÂÖ∑Á´∂Áà≠ÂäõÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÈñãÁôºÂ§öÂÄãÊèêÁ§∫ÁØÑÊú¨ÔºåÂ∞áÁâ©‰ª∂È†êÊ∏¨ (OP) ‰ªªÂãôË®≠ÂÆöÁÇ∫Ê®ôÊ∫ñÂïèÁ≠î (QA) ‰ªªÂãôÔºåÈÅ©Áî®Êñº‰ΩøÁî®Á∑®Á¢ºÂô®-Ëß£Á¢ºÂô®ÁîüÊàêÂºè LLM ÈÄ≤Ë°åÊåá‰ª§ÂæÆË™ø„ÄÇÂ∞çÊñºÂ§ö‰∫ã‰ª∂È†êÊ∏¨ (MEF)ÔºåÊàëÂÄëÁÇ∫ÊØèÂÄã TKG ‰∫îÂÖÉÁµÑË®≠Ë®àÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊèêÁ§∫ÁØÑÊú¨„ÄÇÈÄôÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÊ∂àÈô§‰∫ÜÂ∞ç GNN Âíå RNN ÁöÑÈúÄÊ±ÇÔºåËÄåÊòØÂà©Áî®ÂÉÖÁ∑®Á¢ºÂô® LLM ‰æÜÁî¢ÁîüÂõ∫ÂÆöÁöÑ‰∏≠ÈñìÂµåÂÖ•ÔºåÁÑ∂ÂæåÁî±ÂÖ∑ÊúâËá™Ê≥®ÊÑèÂäõÊ©üÂà∂ÁöÑÈ†êÊ∏¨È†≠ËôïÁêÜÈÄô‰∫õÂµåÂÖ•Ôºå‰ª•È†êÊ∏¨ÊΩõÂú®ÁöÑÊú™‰æÜÈóú‰øÇ„ÄÇ‰ΩøÁî®ÂêÑÁ®ÆË©ï‰º∞ÊåáÊ®ôÂ∞çÂ§öÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÇ</paragraph>

##### **Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning**
2406.10479v1 by Wenjun Li, Changyu Chen, Pradeep Varakantham

Large language models (LLMs) have demonstrated impressive task-solving
capabilities, achieved through either prompting techniques or system designs.
However, concerns have arisen regarding their proficiency in planning tasks, as
they often struggle to generate valid plans. This paper investigates the impact
of fine-tuning on LLMs' planning capabilities. Our findings indicate that LLMs
can achieve good performance in planning through substantial (thousands of
specific examples) fine-tuning. However, fine-tuning is associated with
significant economic and computational costs. To address this challenge, we
propose the Maximum Diversity Fine-Tuning (MDFT) strategy to improve the sample
efficiency of fine-tuning in the planning domain. Specifically, our algorithm,
referred to as MDFT-g, encodes the planning task instances with their graph
representations and selects a subset of samples in the vector space that
maximizes data diversity. We empirically demonstrate that MDFT-g consistently
outperforms existing baselines at various scales across multiple benchmark
domains.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ‰ªªÂãôËß£Ê±∫ËÉΩÂäõÔºåÈÄôÊòØÈÄèÈÅéÊèêÁ§∫ÊäÄË°ìÊàñÁ≥ªÁµ±Ë®≠Ë®à‰æÜÈÅîÊàê„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñº LLM Âú®Ë¶èÂäÉ‰ªªÂãô‰∏≠ÁöÑËÉΩÂäõÔºåÂ∑≤Áî¢ÁîüÁñëÊÖÆÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁ∂ìÂ∏∏Èõ£‰ª•Áî¢ÁîüÊúâÊïàÁöÑË®àÁï´„ÄÇÊú¨ÊñáÊé¢Ë®éÂæÆË™øÂ∞ç LLM Ë¶èÂäÉËÉΩÂäõÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåLLM ÂèØ‰ª•ÈÄèÈÅéÂ§ßÈáèÁöÑÂæÆË™øÔºàÊï∏ÂçÉÂÄãÂÖ∑È´îÁØÑ‰æãÔºâÂú®Ë¶èÂäÉ‰∏≠Áç≤ÂæóËâØÂ•ΩÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÂæÆË™øËàáÈ°ØËëóÁöÑÁ∂ìÊøüÂíåÈÅãÁÆóÊàêÊú¨Áõ∏Èóú„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ÊúÄÂ§ßÂ§öÊ®£ÊÄßÂæÆË™ø (MDFT) Á≠ñÁï•Ôºå‰ª•ÊèêÂçáË¶èÂäÉÈ†òÂüüÂæÆË™øÁöÑÊ®£Êú¨ÊïàÁéá„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁ®±ÁÇ∫ MDFT-g ÁöÑÊºîÁÆóÊ≥ïÔºå‰ª•ÂúñÂΩ¢Ë°®Á§∫Â∞çË¶èÂäÉ‰ªªÂãôÂØ¶‰æãÈÄ≤Ë°åÁ∑®Á¢ºÔºå‰∏¶Âú®ÂêëÈáèÁ©∫Èñì‰∏≠ÈÅ∏Êìá‰∏ÄÂÄãÊ®£Êú¨Â≠êÈõÜÔºå‰ª•ÊúÄÂ§ßÂåñË≥áÊñôÂ§öÊ®£ÊÄß„ÄÇÊàëÂÄëÂØ¶Ë≠âË≠âÊòéÔºåMDFT-g Âú®Â§öÂÄãÂü∫Ê∫ñÈ†òÂüüÁöÑ‰∏çÂêåË¶èÊ®°‰∏≠ÔºåÂßãÁµÇÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Ê∫ñ„ÄÇ

##### **Precision Empowers, Excess Distracts: Visual Question Answering With Dynamically Infused Knowledge In Language Models**
2406.09994v1 by Manas Jhalani, Annervaz K M, Pushpak Bhattacharyya

In the realm of multimodal tasks, Visual Question Answering (VQA) plays a
crucial role by addressing natural language questions grounded in visual
content. Knowledge-Based Visual Question Answering (KBVQA) advances this
concept by adding external knowledge along with images to respond to questions.
We introduce an approach for KBVQA, augmenting the existing vision-language
transformer encoder-decoder (OFA) model. Our main contribution involves
enhancing questions by incorporating relevant external knowledge extracted from
knowledge graphs, using a dynamic triple extraction method. We supply a
flexible number of triples from the knowledge graph as context, tailored to
meet the requirements for answering the question. Our model, enriched with
knowledge, demonstrates an average improvement of 4.75\% in Exact Match Score
over the state-of-the-art on three different KBVQA datasets. Through
experiments and analysis, we demonstrate that furnishing variable triples for
each question improves the reasoning capabilities of the language model in
contrast to supplying a fixed number of triples. This is illustrated even for
recent large language models. Additionally, we highlight the model's
generalization capability by showcasing its SOTA-beating performance on a small
dataset, achieved through straightforward fine-tuning.

ÊëòË¶ÅÔºöÂú®Â§öÊ®°ÊÄÅ‰ªªÂä°È¢ÜÂüüÔºåËßÜËßâÈóÆÁ≠îÔºàVQAÔºâÈÄöËøáËß£ÂÜ≥Âü∫‰∫éËßÜËßâÂÜÖÂÆπÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÈóÆÈ¢òÔºåÊâÆÊºîÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂü∫‰∫éÁü•ËØÜÁöÑËßÜËßâÈóÆÁ≠îÔºàKBVQAÔºâÈÄöËøáÊ∑ªÂä†Â§ñÈÉ®Áü•ËØÜ‰ª•ÂèäÂõæÂÉèÊù•ÂõûÁ≠îÈóÆÈ¢òÔºå‰ªéËÄåÊé®Ëøõ‰∫ÜËøô‰∏ÄÊ¶ÇÂøµ„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÁî®‰∫é KBVQA ÁöÑÊñπÊ≥ïÔºåÂ¢ûÂº∫‰∫ÜÁé∞ÊúâÁöÑËßÜËßâËØ≠Ë®Ä transformer ÁºñÁ†ÅÂô®Ëß£Á†ÅÂô® (OFA) Ê®°Âûã„ÄÇÊàë‰ª¨ÁöÑ‰∏ªË¶ÅË¥°ÁåÆÊ∂âÂèäÈÄöËøá‰ΩøÁî®Âä®ÊÄÅ‰∏âÂÖÉÁªÑÊèêÂèñÊñπÊ≥ïÔºåÊï¥Âêà‰ªéÁü•ËØÜÂõæË∞±‰∏≠ÊèêÂèñÁöÑÁõ∏ÂÖ≥Â§ñÈÉ®Áü•ËØÜÊù•Â¢ûÂº∫ÈóÆÈ¢ò„ÄÇÊàë‰ª¨Êèê‰æõÊù•Ëá™Áü•ËØÜÂõæË∞±ÁöÑÁÅµÊ¥ªÊï∞ÈáèÁöÑ‰∏âÂÖÉÁªÑ‰Ωú‰∏∫‰∏ä‰∏ãÊñáÔºå‰ª•Êª°Ë∂≥ÂõûÁ≠îÈóÆÈ¢òÁöÑË¶ÅÊ±Ç„ÄÇÊàë‰ª¨ÁªèËøáÁü•ËØÜ‰∏∞ÂØåÁöÑÊ®°ÂûãÂú®‰∏â‰∏™‰∏çÂêåÁöÑ KBVQA Êï∞ÊçÆÈõÜ‰∏äÔºåÂú®Á≤æÁ°ÆÂåπÈÖçÂàÜÊï∞ÊñπÈù¢Â±ïÁ§∫‰∫ÜÊØîÊúÄÂÖàËøõÊ∞¥Âπ≥Âπ≥ÂùáÊèêÈ´ò 4.75%„ÄÇÈÄöËøáÂÆûÈ™åÂíåÂàÜÊûêÔºåÊàë‰ª¨ËØÅÊòé‰∏∫ÊØè‰∏™ÈóÆÈ¢òÊèê‰æõÂèØÂèò‰∏âÂÖÉÁªÑÊèêÈ´ò‰∫ÜËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåËøô‰∏éÊèê‰æõÂõ∫ÂÆöÊï∞ÈáèÁöÑ‰∏âÂÖÉÁªÑÂΩ¢ÊàêÂØπÊØî„ÄÇÂç≥‰ΩøÂØπ‰∫éÊúÄËøëÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåËøô‰∏ÄÁÇπ‰πüÂæóÂà∞‰∫ÜËØ¥Êòé„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÈÄöËøáÂ±ïÁ§∫Ê®°ÂûãÂú®Â∞èÂûãÊï∞ÊçÆÈõÜ‰∏äÁöÑ SOTA ÂáªË¥•ÊÄßËÉΩÔºåÁ™ÅÂá∫‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÔºåËøôÊòØÈÄöËøáÁõ¥Êé•ÂæÆË∞ÉÂÆûÁé∞ÁöÑ„ÄÇ

##### **DAG-Plan: Generating Directed Acyclic Dependency Graphs for Dual-Arm Cooperative Planning**
2406.09953v1 by Zeyu Gao, Yao Mu, Jinye Qu, Mengkang Hu, Lingyue Guo, Ping Luo, Yanfeng Lu

Dual-arm robots offer enhanced versatility and efficiency over single-arm
counterparts by enabling concurrent manipulation of multiple objects or
cooperative execution of tasks using both arms. However, effectively
coordinating the two arms for complex long-horizon tasks remains a significant
challenge. Existing task planning methods predominantly focus on single-arm
robots or rely on predefined bimanual operations, failing to fully leverage the
capabilities of dual-arm systems. To address this limitation, we introduce
DAG-Plan, a structured task planning framework tailored for dual-arm robots.
DAG-Plan harnesses large language models (LLMs) to decompose intricate tasks
into actionable sub-tasks represented as nodes within a directed acyclic graph
(DAG). Critically, DAG-Plan dynamically assigns these sub-tasks to the
appropriate arm based on real-time environmental observations, enabling
parallel and adaptive execution. We evaluate DAG-Plan on the novel Dual-Arm
Kitchen Benchmark, comprising 9 sequential tasks with 78 sub-tasks and 26
objects. Extensive experiments demonstrate the superiority of DAG-Plan over
directly using LLM to generate plans, achieving nearly 50% higher efficiency
compared to the single-arm task planning baseline and nearly double the success
rate of the dual-arm task planning baseline.

ÊëòË¶ÅÔºöÈõôËáÇÊ©üÂô®‰∫∫ÈÄèÈÅéÂêåÊôÇÊìçÊéßÂ§öÂÄãÁâ©‰ª∂Êàñ‰ΩøÁî®ÈõôËáÇÂçîÂêåÂü∑Ë°å‰ªªÂãôÔºåÊèê‰æõÊØîÂñÆËáÇÊ©üÂô®‰∫∫Êõ¥È´òÁöÑÈùàÊ¥ªÊÄßËàáÊïàÁéá„ÄÇÁÑ∂ËÄåÔºåË¶ÅÊúâÊïàÂçîË™øÈõôËáÇ‰ª•Âü∑Ë°åË§áÈõú‰∏îÊôÇÈñìË∑®Â∫¶Èï∑ÁöÑ‰ªªÂãôÔºå‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÁèæÊúâÁöÑ‰ªªÂãôË¶èÂäÉÊñπÊ≥ï‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂñÆËáÇÊ©üÂô®‰∫∫ÔºåÊàñ‰æùË≥¥ÊñºÈ†êÂÖàÂÆöÁæ©ÁöÑÈõôÊâãÊìç‰ΩúÔºåÁÑ°Ê≥ïÂÖÖÂàÜÂà©Áî®ÈõôËáÇÁ≥ªÁµ±ÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü DAG-PlanÔºå‰∏ÄÂÄãÂ∞àÈñÄÁÇ∫ÈõôËáÇÊ©üÂô®‰∫∫ÈáèË∫´ÊâìÈÄ†ÁöÑÁµêÊßãÂåñ‰ªªÂãôË¶èÂäÉÊû∂Êßã„ÄÇDAG-Plan Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞áË§áÈõúÁöÑ‰ªªÂãôÂàÜËß£ÊàêÂèØÊìç‰ΩúÁöÑÂ≠ê‰ªªÂãôÔºå‰∏¶Â∞áÂÖ∂Ë°®Á§∫ÁÇ∫ÊúâÂêëÁÑ°Áí∞Âúñ (DAG) ‰∏≠ÁöÑÁØÄÈªû„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåDAG-Plan ÊúÉÊ†πÊìöÂç≥ÊôÇÁöÑÁí∞Â¢ÉËßÄÂØüÂãïÊÖãÂú∞Â∞áÈÄô‰∫õÂ≠ê‰ªªÂãôÂàÜÈÖçÁµ¶ÈÅ©Áï∂ÁöÑÊâãËáÇÔºåÂæûËÄåÂØ¶Áèæ‰∏¶Ë°åÂíåËá™ÈÅ©ÊáâÁöÑÂü∑Ë°å„ÄÇÊàëÂÄëÂú®Êñ∞ÁöÑÈõôËáÇÂªöÊàøÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Ë©ï‰º∞‰∫Ü DAG-PlanÔºåÂÖ∂‰∏≠ÂåÖÂê´ 9 ÂÄãÈ†ÜÂ∫è‰ªªÂãô„ÄÅ78 ÂÄãÂ≠ê‰ªªÂãôÂíå 26 ÂÄãÁâ©‰ª∂„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫Ü DAG-Plan ÂÑ™ÊñºÁõ¥Êé•‰ΩøÁî® LLM ‰æÜÁî¢ÁîüË®àÁï´ÔºåËàáÂñÆËáÇ‰ªªÂãôË¶èÂäÉÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåÊïàÁéáÊèêÈ´ò‰∫ÜËøë 50%ÔºåËÄåËàáÈõôËáÇ‰ªªÂãôË¶èÂäÉÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåÊàêÂäüÁéáÂπæ‰πéÊèêÈ´ò‰∫Ü‰∏ÄÂÄç„ÄÇ

##### **TEG-DB: A Comprehensive Dataset and Benchmark of Textual-Edge Graphs**
2406.10310v1 by Zhuofeng Li, Zixing Gou, Xiangnan Zhang, Zhongyuan Liu, Sirui Li, Yuntong Hu, Chen Ling, Zheng Zhang, Liang Zhao

Text-Attributed Graphs (TAGs) augment graph structures with natural language
descriptions, facilitating detailed depictions of data and their
interconnections across various real-world settings. However, existing TAG
datasets predominantly feature textual information only at the nodes, with
edges typically represented by mere binary or categorical attributes. This lack
of rich textual edge annotations significantly limits the exploration of
contextual relationships between entities, hindering deeper insights into
graph-structured data. To address this gap, we introduce Textual-Edge Graphs
Datasets and Benchmark (TEG-DB), a comprehensive and diverse collection of
benchmark textual-edge datasets featuring rich textual descriptions on nodes
and edges. The TEG-DB datasets are large-scale and encompass a wide range of
domains, from citation networks to social networks. In addition, we conduct
extensive benchmark experiments on TEG-DB to assess the extent to which current
techniques, including pre-trained language models, graph neural networks, and
their combinations, can utilize textual node and edge information. Our goal is
to elicit advancements in textual-edge graph research, specifically in
developing methodologies that exploit rich textual node and edge descriptions
to enhance graph analysis and provide deeper insights into complex real-world
networks. The entire TEG-DB project is publicly accessible as an open-source
repository on Github, accessible at
https://github.com/Zhuofeng-Li/TEG-Benchmark.

ÊëòË¶ÅÔºöÊñáÂ≠óÊ®ôË®ªÂúñÔºàTAGÔºâ‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÊèèËø∞Êì¥ÂÖÖÂúñÂΩ¢ÁµêÊßãÔºåÂçîÂä©Ë©≥Á¥∞ÊèèÁπ™Ë≥áÊñôÂèäÂÖ∂Âú®ÂêÑÁ®ÆÁúüÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠ÁöÑÁõ∏‰∫íÈÄ£Áµê„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ TAG Ë≥áÊñôÈõÜ‰∏ªË¶ÅÂÉÖÂú®ÁØÄÈªû‰∏≠ÂëàÁèæÊñáÂ≠óË≥áË®äÔºåÈÇäÁ∑£ÈÄöÂ∏∏ÂÉÖ‰ª•‰∫åÈÄ≤‰ΩçÊàñÂàÜÈ°ûÂ±¨ÊÄßË°®Á§∫„ÄÇÈÄôÁ®ÆÁº∫‰πèË±êÂØåÁöÑÊñáÂ≠óÈÇäÁ∑£Ë®ªËß£ÔºåÊúÉÂ§ßÂπÖÈôêÂà∂Êé¢Á¥¢ÂØ¶È´îÈñìÁöÑËÑàÁµ°Èóú‰øÇÔºåÈòªÁ§ôÊ∑±ÂÖ•‰∫ÜËß£ÂúñÂΩ¢ÁµêÊßãË≥áÊñô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§Â∑ÆË∑ùÔºåÊàëÂÄëÂºïÈÄ≤ÊñáÂ≠óÈÇäÁ∑£ÂúñÂΩ¢Ë≥áÊñôÈõÜËàáÂü∫Ê∫ñÔºàTEG-DBÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ®Èù¢‰∏îÂ§öÊ®£ÂåñÁöÑÂü∫Ê∫ñÊñáÂ≠óÈÇäÁ∑£Ë≥áÊñôÈõÜÈõÜÂêàÔºåÂú®ÁØÄÈªûÂíåÈÇäÁ∑£‰∏äÂÖ∑ÊúâË±êÂØåÁöÑÊñáÂ≠óÊèèËø∞„ÄÇTEG-DB Ë≥áÊñôÈõÜË¶èÊ®°ÈæêÂ§ßÔºåÊ∂µËìãÂæûÂºïÊñáÁ∂≤Ë∑ØÂà∞Á§æ‰∫§Á∂≤Ë∑ØÁöÑÂª£Ê≥õÈ†òÂüü„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú® TEG-DB ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂü∫Ê∫ñÂØ¶È©óÔºå‰ª•Ë©ï‰º∞ÁõÆÂâçÊäÄË°ìÔºàÂåÖÊã¨È†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°Âûã„ÄÅÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÂèäÂÖ∂ÁµÑÂêàÔºâÂú®‰ΩïÁ®ÆÁ®ãÂ∫¶‰∏äËÉΩÂà©Áî®ÊñáÂ≠óÁØÄÈªûÂíåÈÇäÁ∑£Ë≥áË®ä„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÂºïÁôºÊñáÂ≠óÈÇäÁ∑£ÂúñÂΩ¢Á†îÁ©∂ÁöÑÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂú®ÈñãÁôºÂà©Áî®Ë±êÂØåÊñáÂ≠óÁØÄÈªûÂíåÈÇäÁ∑£ÊèèËø∞‰æÜÂ¢ûÂº∑ÂúñÂΩ¢ÂàÜÊûê‰∏¶Êèê‰æõÂ∞çË§áÈõúÁúüÂØ¶‰∏ñÁïåÁ∂≤Ë∑ØÊõ¥Ê∑±ÂÖ•Ë¶ãËß£ÁöÑÊñπÊ≥ïË´ñ„ÄÇÊï¥ÂÄã TEG-DB Â∞àÊ°à‰ª•ÈñãÊ∫êÂÑ≤Â≠òÂ∫´ÁöÑÂΩ¢ÂºèÂÖ¨ÈñãÊñº GithubÔºåÂèØÊñº https://github.com/Zhuofeng-Li/TEG-Benchmark ÂèñÂæó„ÄÇ

##### **Automated Molecular Concept Generation and Labeling with Large Language Models**
2406.09612v1 by Shichang Zhang, Botao Xia, Zimin Zhang, Qianli Wu, Fang Sun, Ziniu Hu, Yizhou Sun

Artificial intelligence (AI) is significantly transforming scientific
research. Explainable AI methods, such as concept-based models (CMs), are
promising for driving new scientific discoveries because they make predictions
based on meaningful concepts and offer insights into the prediction process. In
molecular science, however, explainable CMs are not as common compared to
black-box models like Graph Neural Networks (GNNs), primarily due to their
requirement for predefined concepts and manual label for each instance, which
demand domain knowledge and can be labor-intensive. This paper introduces a
novel framework for Automated Molecular Concept (AutoMolCo) generation and
labeling. AutoMolCo leverages the knowledge in Large Language Models (LLMs) to
automatically generate predictive molecular concepts and label them for each
molecule. Such procedures are repeated through iterative interactions with LLMs
to refine concepts, enabling simple linear models on the refined concepts to
outperform GNNs and LLM in-context learning on several benchmarks. The whole
AutoMolCo framework is automated without any human knowledge inputs in either
concept generation, labeling, or refinement, thereby surpassing the limitations
of extant CMs while maintaining their explainability and allowing easy
intervention. Through systematic experiments on MoleculeNet and High-Throughput
Experimentation (HTE) datasets, we demonstrate that the AutoMolCo-induced
explainable CMs are beneficial and promising for molecular science research.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÊ≠£Âú®È°ØËëóÂú∞ËΩâËÆäÁßëÂ≠∏Á†îÁ©∂„ÄÇÂèØËß£ÈáãÁöÑ AI ÊñπÊ≥ïÔºå‰æãÂ¶ÇÂü∫ÊñºÊ¶ÇÂøµÁöÑÊ®°ÂûãÔºàCMÔºâÔºåÂ∞çÊñºÊé®ÂãïÊñ∞ÁöÑÁßëÂ≠∏ÁôºÁèæÂæàÊúâÂ∏åÊúõÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊ†πÊìöÊúâÊÑèÁæ©ÁöÑÊ¶ÇÂøµÈÄ≤Ë°åÈ†êÊ∏¨Ôºå‰∏¶Êèê‰æõÂ∞çÈ†êÊ∏¨ÈÅéÁ®ãÁöÑË¶ãËß£„ÄÇÁÑ∂ËÄåÔºåÂú®ÂàÜÂ≠êÁßëÂ≠∏‰∏≠ÔºåÂèØËß£ÈáãÁöÑ CM ‰∏¶‰∏çÂÉèÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàGNNÔºâÈÄôÊ®£ÁöÑÈªëÁÆ±Ê®°ÂûãÈÇ£È∫ºÂ∏∏Ë¶ãÔºåÈÄô‰∏ªË¶ÅÊòØÁî±ÊñºÂÆÉÂÄëÈúÄË¶ÅÈ†êÂÆöÁæ©ÁöÑÊ¶ÇÂøµÂíåÊØèÂÄãÂØ¶‰æãÁöÑÊâãÂãïÊ®ôÁ±§ÔºåÈÄôÈúÄË¶ÅÈ†òÂüüÁü•Ë≠ò‰∏¶‰∏îÂèØËÉΩÈúÄË¶ÅÂ§ßÈáè‰∫∫Â∑•„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁî®ÊñºËá™ÂãïÂàÜÂ≠êÊ¶ÇÂøµÔºàAutoMolCoÔºâÁîüÊàêÂíåÊ®ôÁ±§ÁöÑÂÖ®Êñ∞Ê°ÜÊû∂„ÄÇAutoMolCo Âà©Áî®Â§ßË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰∏≠ÁöÑÁü•Ë≠òËá™ÂãïÁîüÊàêÈ†êÊ∏¨ÂàÜÂ≠êÊ¶ÇÂøµ‰∏¶ÁÇ∫ÊØèÂÄãÂàÜÂ≠êÊ®ôË®òÂÆÉÂÄë„ÄÇÊ≠§È°ûÁ®ãÂ∫èÈÄöÈÅéËàá LLM ÁöÑÂèçË¶Ü‰∫§‰∫í‰æÜÈáçË§áÔºå‰ª•ÂÑ™ÂåñÊ¶ÇÂøµÔºå‰ΩøÂü∫ÊñºÂÑ™ÂåñÊ¶ÇÂøµÁöÑÁ∞°ÂñÆÁ∑öÊÄßÊ®°ÂûãÂú®ÂπæÂÄãÂü∫Ê∫ñ‰∏äÂÑ™Êñº GNN Âíå LLM ÁöÑ‰∏ä‰∏ãÊñáÂ≠∏Áøí„ÄÇÊï¥ÂÄã AutoMolCo Ê°ÜÊû∂ÊòØËá™ÂãïÂåñÁöÑÔºåÂú®Ê¶ÇÂøµÁîüÊàê„ÄÅÊ®ôË®òÊàñÂÑ™Âåñ‰∏≠ÈÉΩÊ≤íÊúâ‰ªª‰Ωï‰∫∫Â∑•Áü•Ë≠òËº∏ÂÖ•ÔºåÂæûËÄåË∂ÖË∂ä‰∫ÜÁèæÊúâ CM ÁöÑÈôêÂà∂ÔºåÂêåÊôÇ‰øùÊåÅ‰∫ÜÂÆÉÂÄëÁöÑÂèØËß£ÈáãÊÄß‰∏¶ÂÖÅË®±ËºïÈ¨ÜÂπ≤È†ê„ÄÇÈÄöÈÅéÂ∞ç MoleculeNet ÂíåÈ´òÈÄöÈáèÂØ¶È©óÔºàHTEÔºâÊï∏ÊìöÈõÜÈÄ≤Ë°åÁ≥ªÁµ±ÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé‰∫Ü AutoMolCo Ë™òÂ∞éÁöÑÂèØËß£Èáã CM Â∞çÂàÜÂ≠êÁßëÂ≠∏Á†îÁ©∂ÊòØÊúâÁõä‰∏îÊúâÂ∏åÊúõÁöÑ„ÄÇ

##### **Cross-Modality Program Representation Learning for Electronic Design Automation with High-Level Synthesis**
2406.09606v1 by Zongyue Qin, Yunsheng Bai, Atefeh Sograbizadeh, Zijian Ding, Ziniu Hu, Yizhou Sun, Jason Cong

In recent years, domain-specific accelerators (DSAs) have gained popularity
for applications such as deep learning and autonomous driving. To facilitate
DSA designs, programmers use high-level synthesis (HLS) to compile a high-level
description written in C/C++ into a design with low-level hardware description
languages that eventually synthesize DSAs on circuits. However, creating a
high-quality HLS design still demands significant domain knowledge,
particularly in microarchitecture decisions expressed as \textit{pragmas}.
Thus, it is desirable to automate such decisions with the help of machine
learning for predicting the quality of HLS designs, requiring a deeper
understanding of the program that consists of original code and pragmas.
Naturally, these programs can be considered as sequence data. In addition,
these programs can be compiled and converted into a control data flow graph
(CDFG). But existing works either fail to leverage both modalities or combine
the two in shallow or coarse ways. We propose ProgSG, a model that allows
interaction between the source code sequence modality and the graph modality in
a deep and fine-grained way. To alleviate the scarcity of labeled designs, a
pre-training method is proposed based on a suite of compiler's data flow
analysis tasks. Experimental results show that ProgSG reduces the RMSE of
design performance predictions by up to $22\%$, and identifies designs with an
average of $1.10\times$ and $1.26\times$ (up to $8.17\times$ and $13.31\times$)
performance improvement in design space exploration (DSE) task compared to HARP
and AutoDSE, respectively.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÁâπÂÆöÈ†òÂüüÂä†ÈÄüÂô®ÔºàDSAÔºâÂú®Ê∑±Â∫¶Â≠∏ÁøíÂíåËá™ÂãïÈßïÈßõÁ≠âÊáâÁî®‰∏≠Ë∂ä‰æÜË∂äÂèóÊ≠°Ëøé„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ DSA Ë®≠Ë®àÔºåÁ®ãÂºèË®≠Ë®à‰∫∫Âì°‰ΩøÁî®È´òÈöéÁ∂úÂêàÔºàHLSÔºâÂ∞á‰ª• C/C++ Á∑®ÂØ´ÁöÑÈ´òÈöéÊèèËø∞Á∑®Ë≠ØÊàê‰ΩéÈöéÁ°¨È´îÊèèËø∞Ë™ûË®ÄÁöÑË®≠Ë®àÔºåÊúÄÁµÇÂú®ÈõªË∑Ø‰∏≠ÂêàÊàê DSA„ÄÇÁÑ∂ËÄåÔºåË¶ÅÂª∫Á´ãÈ´òÂìÅË≥™ÁöÑ HLS Ë®≠Ë®àÔºå‰ªçÁÑ∂ÈúÄË¶ÅÂ§ßÈáèÁöÑÈ†òÂüüÁü•Ë≠òÔºåÁâπÂà•ÊòØÂú®Ë°®Á§∫ÁÇ∫„ÄåÊåá‰ª§„ÄçÁöÑÂæÆÊû∂ÊßãÊ±∫Á≠ñ‰∏≠„ÄÇÂõ†Ê≠§ÔºåÂæàÂ∏åÊúõËóâÂä©Ê©üÂô®Â≠∏ÁøíËá™ÂãïÂåñÈÄô‰∫õÊ±∫Á≠ñÔºå‰ª•È†êÊ∏¨ HLS Ë®≠Ë®àÁöÑÂìÅË≥™ÔºåÈÄôÈúÄË¶ÅÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÂåÖÂê´ÂéüÂßãÁ®ãÂºèÁ¢ºÂíåÊåá‰ª§ÁöÑÁ®ãÂºè„ÄÇËá™ÁÑ∂Âú∞ÔºåÈÄô‰∫õÁ®ãÂºèÂèØ‰ª•Ë¶ñÁÇ∫Â∫èÂàóË≥áÊñô„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÁ®ãÂºèÂèØ‰ª•Á∑®Ë≠Ø‰∏¶ËΩâÊèõÊàêÊéßÂà∂Ë≥áÊñôÊµÅÁ®ãÂúñÔºàCDFGÔºâ„ÄÇ‰ΩÜÁèæÊúâÁöÑ‰ΩúÂìÅ‰∏çÊòØÁÑ°Ê≥ïÂêåÊôÇÂà©Áî®ÈÄôÂÖ©Á®ÆÊñπÂºèÔºåÂ∞±ÊòØ‰ª•Ê∑∫Â±§ÊàñÁ≤óÁï•ÁöÑÊñπÂºèÂ∞áÂÆÉÂÄëÁµêÂêàÂú®‰∏ÄËµ∑„ÄÇÊàëÂÄëÊèêÂá∫ ProgSGÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖÅË®±‰ª•Ê∑±ÂÖ•‰∏îÁ¥∞Á∑ªÁöÑÊñπÂºèÂú®ÂéüÂßãÁ¢ºÂ∫èÂàóÊñπÂºèÂíåÂúñÂΩ¢ÊñπÂºè‰πãÈñìÈÄ≤Ë°å‰∫íÂãïÁöÑÊ®°Âûã„ÄÇÁÇ∫‰∫ÜÁ∑©Ëß£Ê®ôË®òË®≠Ë®àÁöÑÁ®ÄÁº∫ÊÄßÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁ∑®Ë≠ØÂô®Ë≥áÊñôÊµÅÂàÜÊûê‰ªªÂãôÂ•ó‰ª∂ÁöÑÈ†êË®ìÁ∑¥ÊñπÊ≥ï„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåProgSG Â∞áË®≠Ë®àÊïàËÉΩÈ†êÊ∏¨ÁöÑ RMSE Èôç‰Ωé‰∫ÜÂ§öÈÅî 22%Ôºå‰∏¶Ë≠òÂà•Âá∫Ë®≠Ë®àÂú®Ë®≠Ë®àÁ©∫ÈñìÊé¢Á¥¢ÔºàDSEÔºâ‰ªªÂãô‰∏≠Âπ≥ÂùáÊïàËÉΩÊèêÂçá 1.10 ÂÄçÂíå 1.26 ÂÄçÔºàÊúÄÈ´ò 8.17 ÂÄçÂíå 13.31 ÂÄçÔºâÔºåÂàÜÂà•Ëàá HARP Âíå AutoDSE Áõ∏ÊØî„ÄÇ</paragraph>

##### **Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models**
2406.09403v1 by Yushi Hu, Weijia Shi, Xingyu Fu, Dan Roth, Mari Ostendorf, Luke Zettlemoyer, Noah A Smith, Ranjay Krishna

Humans draw to facilitate reasoning: we draw auxiliary lines when solving
geometry problems; we mark and circle when reasoning on maps; we use sketches
to amplify our ideas and relieve our limited-capacity working memory. However,
such actions are missing in current multimodal language models (LMs). Current
chain-of-thought and tool-use paradigms only use text as intermediate reasoning
steps. In this work, we introduce Sketchpad, a framework that gives multimodal
LMs a visual sketchpad and tools to draw on the sketchpad. The LM conducts
planning and reasoning according to the visual artifacts it has drawn.
Different from prior work, which uses text-to-image models to enable LMs to
draw, Sketchpad enables LMs to draw with lines, boxes, marks, etc., which is
closer to human sketching and better facilitates reasoning. Sketchpad can also
use specialist vision models during the sketching process (e.g., draw bounding
boxes with object detection models, draw masks with segmentation models), to
further enhance visual perception and reasoning. We experiment with a wide
range of math tasks (including geometry, functions, graphs, and chess) and
complex visual reasoning tasks. Sketchpad substantially improves performance on
all tasks over strong base models with no sketching, yielding an average gain
of 12.7% on math tasks, and 8.6% on vision tasks. GPT-4o with Sketchpad sets a
new state of the art on all tasks, including V*Bench (80.3%), BLINK spatial
reasoning (83.9%), and visual correspondence (80.8%). All codes and data are in
https://visualsketchpad.github.io/.

ÊëòË¶ÅÔºö<paragraph>‰∫∫È°ûÂà©Áî®Áπ™Áï´‰æÜ‰øÉÈÄ≤Êé®ÁêÜÔºöÊàëÂÄëÂú®Ëß£Ê±∫Âπæ‰ΩïÂïèÈ°åÊôÇÊúÉÁï´ËºîÂä©Á∑öÔºõÂú®Á†îÁ©∂Âú∞ÂúñÊôÇÊúÉÊ®ôË®òÂíåÁï´ÂúàÔºõÊàëÂÄë‰ΩøÁî®ËçâÂúñ‰æÜÊì¥Â±ïÊàëÂÄëÁöÑÊÉ≥Ê≥ï‰∏¶Ê∏õËºïÊàëÂÄëÂÆπÈáèÊúâÈôêÁöÑÂ∑•‰ΩúË®òÊÜ∂„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÊ®°ÊÖãË™ûË®ÄÊ®°Âûã (LM) ‰∏≠Áº∫Â∞ëÊ≠§È°ûÂãï‰Ωú„ÄÇÁõÆÂâçÁöÑÊÄùËÄÉÈèàÂíåÂ∑•ÂÖ∑‰ΩøÁî®ÁØÑ‰æãÂÉÖÂ∞áÊñáÂ≠óÁî®‰Ωú‰∏≠ÈñìÊé®ÁêÜÊ≠•È©ü„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü SketchpadÔºå‰∏ÄÂÄãÊ°ÜÊû∂ÔºåÂÆÉÁÇ∫Â§öÊ®°ÊÖã LM Êèê‰æõ‰∫Ü‰∏ÄÂÄãË¶ñË¶∫ËçâÂúñÊú¨ÂíåÂèØ‰ª•Âú®ËçâÂúñÊú¨‰∏äÁπ™Áï´ÁöÑÂ∑•ÂÖ∑„ÄÇLM Ê†πÊìöÂÆÉÁπ™Ë£ΩÁöÑË¶ñË¶∫Â∑•‰ª∂ÈÄ≤Ë°åË¶èÂäÉÂíåÊé®ÁêÜ„ÄÇ‰∏çÂêåÊñº‰ª•Ââç‰ΩøÁî®ÊñáÂ≠óËΩâÂúñÂÉèÊ®°Âûã‰Ωø LM ËÉΩÂ§†Áπ™Áï´ÁöÑÂÖàÂâçÂ∑•‰ΩúÔºåSketchpad ‰Ωø LM ËÉΩÂ§†‰ΩøÁî®Á∑öÊ¢ù„ÄÅÊñπÂ°ä„ÄÅÊ®ôË®òÁ≠âÈÄ≤Ë°åÁπ™Áï´ÔºåÈÄôÊõ¥Êé•ËøëÊñº‰∫∫È°ûÁöÑÁ¥†ÊèèÔºå‰∏¶‰∏îÊõ¥Â•ΩÂú∞‰øÉÈÄ≤‰∫ÜÊé®ÁêÜ„ÄÇSketchpad ‰πüÂèØ‰ª•Âú®Á¥†ÊèèÈÅéÁ®ã‰∏≠‰ΩøÁî®Â∞àÂÆ∂Ë¶ñË¶∫Ê®°ÂûãÔºà‰æãÂ¶ÇÔºå‰ΩøÁî®Áâ©‰ª∂ÂÅµÊ∏¨Ê®°ÂûãÁπ™Ë£ΩÈÇäÁïåÊ°ÜÔºå‰ΩøÁî®ÂàÜÂâ≤Ê®°ÂûãÁπ™Ë£ΩÈÅÆÁΩ©ÔºâÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑Ë¶ñË¶∫ÊÑüÁü•ÂíåÊé®ÁêÜ„ÄÇÊàëÂÄë‰ΩøÁî®Âª£Ê≥õÁöÑÊï∏Â≠∏‰ªªÂãôÔºàÂåÖÊã¨Âπæ‰Ωï„ÄÅÂáΩÊï∏„ÄÅÂúñÂΩ¢ÂíåË•øÊ¥ãÊ£ãÔºâÂíåË§áÈõúÁöÑË¶ñË¶∫Êé®ÁêÜ‰ªªÂãôÈÄ≤Ë°å‰∫ÜÂØ¶È©ó„ÄÇSketchpad Â§ßÂπÖÊèêÂçá‰∫ÜÊâÄÊúâ‰ªªÂãôÂú®Ê≤íÊúâÁ¥†ÊèèÁöÑÊÉÖÊ≥Å‰∏ãÂº∑Â§ßÁöÑÂü∫Á§éÊ®°ÂûãÁöÑÊïàËÉΩÔºåÂú®Êï∏Â≠∏‰ªªÂãô‰∏äÂπ≥ÂùáÊèêÂçá 12.7%ÔºåÂú®Ë¶ñË¶∫‰ªªÂãô‰∏äÊèêÂçá 8.6%„ÄÇÈÖçÂÇô Sketchpad ÁöÑ GPT-4o Âú®ÊâÄÊúâ‰ªªÂãô‰∏äÈÉΩÂâµ‰∏ã‰∫ÜÊñ∞ÁöÑÊäÄË°ìÊ∞¥Ê∫ñÔºåÂåÖÊã¨ V*Bench (80.3%)„ÄÅBLINK Á©∫ÈñìÊé®ÁêÜ (83.9%) ÂíåË¶ñË¶∫Â∞çÊáâ (80.8%)„ÄÇÊâÄÊúâÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈÉΩÂèØ‰ª•Âú® https://visualsketchpad.github.io/ ‰∏≠ÊâæÂà∞„ÄÇ</paragraph>

##### **Transformers meet Neural Algorithmic Reasoners**
2406.09308v1 by Wilfried Bounsi, Borja Ibarz, Andrew Dudzik, Jessica B. Hamrick, Larisa Markeeva, Alex Vitvitskyi, Razvan Pascanu, Petar Veliƒçkoviƒá

Transformers have revolutionized machine learning with their simple yet
effective architecture. Pre-training Transformers on massive text datasets from
the Internet has led to unmatched generalization for natural language
understanding (NLU) tasks. However, such language models remain fragile when
tasked with algorithmic forms of reasoning, where computations must be precise
and robust. To address this limitation, we propose a novel approach that
combines the Transformer's language understanding with the robustness of graph
neural network (GNN)-based neural algorithmic reasoners (NARs). Such NARs
proved effective as generic solvers for algorithmic tasks, when specified in
graph form. To make their embeddings accessible to a Transformer, we propose a
hybrid architecture with a two-phase training procedure, allowing the tokens in
the language model to cross-attend to the node embeddings from the NAR. We
evaluate our resulting TransNAR model on CLRS-Text, the text-based version of
the CLRS-30 benchmark, and demonstrate significant gains over Transformer-only
models for algorithmic reasoning, both in and out of distribution.

ÊëòË¶ÅÔºöTransformer ÊÜëËóâÂÖ∂Á∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊû∂ÊßãÔºåÂæπÂ∫ïÊîπËÆä‰∫ÜÊ©üÂô®Â≠∏Áøí„ÄÇÂú®Á∂≤ÈöõÁ∂≤Ë∑Ø‰∏äÁöÑÂ§ßÈáèÊñáÂ≠óË≥áÊñôÈõÜ‰∏äÂ∞ç Transformer ÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÔºåÂ∑≤ÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ (NLU) ‰ªªÂãôÂ∏∂‰æÜ‰∫ÜÁÑ°ËàáÂÄ´ÊØîÁöÑÊ≥õÂåñ„ÄÇÁÑ∂ËÄåÔºåÂú®ÈúÄË¶ÅÊºîÁÆóÊ≥ïÂΩ¢ÂºèÊé®ÁêÜÁöÑ‰ªªÂãô‰∏≠ÔºåÊ≠§È°ûË™ûË®ÄÊ®°Âûã‰ªçÁÑ∂ËÑÜÂº±ÔºåÂõ†ÁÇ∫Ë®àÁÆóÂøÖÈ†àÁ≤æÁ¢∫‰∏îÁ©©ÂÅ•„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÁµêÂêà‰∫Ü Transformer ÁöÑË™ûË®ÄÁêÜËß£ËàáÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁÇ∫Âü∫Á§éÁöÑÁ•ûÁ∂ìÊºîÁÆóÊ≥ïÊé®ÁêÜÂô® (NAR) ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊ≠§È°û NAR Ë¢´Ë≠âÊòéÂú®‰ª•ÂúñÂΩ¢ÂΩ¢ÂºèÊåáÂÆöÊôÇÔºåÂèØ‰ΩúÁÇ∫ÊºîÁÆóÊ≥ï‰ªªÂãôÁöÑÈÄöÁî®Ëß£ÁÆóÂô®„ÄÇÁÇ∫‰∫ÜËÆì Transformer ÂèØ‰ª•Â≠òÂèñÂÖ∂ÂµåÂÖ•ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ∑ÊúâÂÖ©ÈöéÊÆµË®ìÁ∑¥Á®ãÂ∫èÁöÑÊ∑∑ÂêàÊû∂ÊßãÔºåËÆìË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÁ¨¶ËôüÂèØ‰ª•‰∫§ÂèâÈóúÊ≥® NAR ‰∏≠ÁöÑÁØÄÈªûÂµåÂÖ•„ÄÇÊàëÂÄëÂú® CLRS-TextÔºàCLRS-30 Âü∫Ê∫ñÁöÑÊñáÂ≠óÁâàÊú¨Ôºâ‰∏äË©ï‰º∞ÊàëÂÄëÂæóÂà∞ÁöÑ TransNAR Ê®°ÂûãÔºå‰∏¶Ë≠âÊòé‰∫ÜÂú®ÊºîÁÆóÊ≥ïÊé®ÁêÜ‰∏≠ÔºåÁÑ°Ë´ñÊòØÂú®ÂàÜ‰ΩàÂÖßÊàñÂàÜ‰ΩàÂ§ñÔºåÈÉΩÊØîÂÉÖ‰ΩøÁî® Transformer ÁöÑÊ®°ÂûãÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇ

##### **SememeLM: A Sememe Knowledge Enhanced Method for Long-tail Relation Representation**
2406.10297v1 by Shuyi Li, Shaojuan Wu, Xiaowang Zhang, Zhiyong Feng

Recognizing relations between two words is a fundamental task with the broad
applications. Different from extracting relations from text, it is difficult to
identify relations among words without their contexts. Especially for long-tail
relations, it becomes more difficult due to inadequate semantic features.
Existing approaches based on language models (LMs) utilize rich knowledge of
LMs to enhance the semantic features of relations. However, they capture
uncommon relations while overlooking less frequent but meaningful ones since
knowledge of LMs seriously relies on trained data where often represents common
relations. On the other hand, long-tail relations are often uncommon in
training data. It is interesting but not trivial to use external knowledge to
enrich LMs due to collecting corpus containing long-tail relationships is
hardly feasible. In this paper, we propose a sememe knowledge enhanced method
(SememeLM) to enhance the representation of long-tail relations, in which
sememes can break the contextual constraints between wors. Firstly, we present
a sememe relation graph and propose a graph encoding method. Moreover, since
external knowledge base possibly consisting of massive irrelevant knowledge,
the noise is introduced. We propose a consistency alignment module, which
aligns the introduced knowledge with LMs, reduces the noise and integrates the
knowledge into the language model. Finally, we conducted experiments on word
analogy datasets, which evaluates the ability to distinguish relation
representations subtle differences, including long-tail relations. Extensive
experiments show that our approach outperforms some state-of-the-art methods.

ÊëòË¶ÅÔºö<paragraph>Ëæ®Ë≠òÂÖ©ÂÄãË©ûÂΩô‰πãÈñìÁöÑÈóú‰øÇÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÂª£Ê≥õÊáâÁî®ÊÄßÁöÑÂü∫Êú¨‰ªªÂãô„ÄÇËàáÂæûÊñáÊú¨‰∏≠Êì∑ÂèñÈóú‰øÇ‰∏çÂêåÔºåÂú®Ê≤íÊúâ‰∏ä‰∏ãÊñáÁöÑÊÉÖÊ≥Å‰∏ãËæ®Ë≠òË©ûÂΩô‰πãÈñìÁöÑÈóú‰øÇÂæàÂõ∞Èõ£„ÄÇÁâπÂà•ÊòØÂ∞çÊñºÈï∑Â∞æÈóú‰øÇÔºåÁî±ÊñºË™ûÊÑèÁâπÂæµ‰∏çË∂≥ÔºåËæ®Ë≠òÈõ£Â∫¶Êõ¥È´ò„ÄÇÁèæÊúâÁöÑÂü∫ÊñºË™ûË®ÄÊ®°Âûã (LM) ÁöÑÊñπÊ≥ïÂà©Áî® LM ÁöÑË±êÂØåÁü•Ë≠ò‰æÜÂ¢ûÂº∑Èóú‰øÇÁöÑË™ûÊÑèÁâπÂæµ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÊúÉÊì∑Âèñ‰∏çÂ∏∏Ë¶ãÁöÑÈóú‰øÇÔºåÂêåÊôÇÂøΩÁï•È†ªÁéáËºÉ‰Ωé‰ΩÜÊúâÊÑèÁæ©ÁöÑÈóú‰øÇÔºåÂõ†ÁÇ∫ LM ÁöÑÁü•Ë≠òÂö¥Èáç‰æùË≥¥ÊñºË®ìÁ∑¥Ë≥áÊñôÔºåËÄåË®ìÁ∑¥Ë≥áÊñôÈÄöÂ∏∏‰ª£Ë°®Â∏∏Ë¶ãÁöÑÈóú‰øÇ„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÈï∑Â∞æÈóú‰øÇÂú®Ë®ìÁ∑¥Ë≥áÊñô‰∏≠ÈÄöÂ∏∏‰∏çÂ∏∏Ë¶ã„ÄÇÁî±ÊñºÊî∂ÈõÜÂåÖÂê´Èï∑Â∞æÈóú‰øÇÁöÑË™ûÊñôÂ∫´Âπæ‰πé‰∏çÂèØË°åÔºåÂõ†Ê≠§‰ΩøÁî®Â§ñÈÉ®Áü•Ë≠ò‰æÜË±êÂØå LM ÂæàÊúâË∂£Ôºå‰ΩÜ‰∏¶‰∏çÂÆπÊòì„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË™ûÁæ©ÁâπÂæµÁü•Ë≠òÂ¢ûÂº∑ÊñπÊ≥ï (SememeLM) ‰æÜÂ¢ûÂº∑Èï∑Â∞æÈóú‰øÇÁöÑË°®Á§∫ÔºåÂÖ∂‰∏≠Ë™ûÁæ©ÁâπÂæµÂèØ‰ª•ÊâìÁ†¥Ë©ûÂΩô‰πãÈñìÁöÑ‰∏ä‰∏ãÊñáÈôêÂà∂„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãË™ûÁæ©ÁâπÂæµÈóú‰øÇÂúñÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÂúñÂΩ¢Á∑®Á¢ºÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÂ§ñÈÉ®Áü•Ë≠òÂ∫´ÂèØËÉΩÂåÖÂê´Â§ßÈáèÁÑ°ÈóúÁöÑÁü•Ë≠òÔºåÂõ†Ê≠§ÊúÉÂºïÂÖ•ÈõúË®ä„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄã‰∏ÄËá¥ÊÄßÂ∞çÈΩäÊ®°ÁµÑÔºåÂÆÉÂ∞áÂºïÂÖ•ÁöÑÁü•Ë≠òËàá LM Â∞çÈΩäÔºåÊ∏õÂ∞ëÈõúË®ä‰∏¶Â∞áÁü•Ë≠òÊï¥ÂêàÂà∞Ë™ûË®ÄÊ®°Âûã‰∏≠„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞çË©ûÂΩôÈ°ûÊØîË≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂØ¶È©óÔºåË©ï‰º∞‰∫ÜÂçÄÂàÜÈóú‰øÇË°®Á§∫Á¥∞ÂæÆÂ∑ÆÁï∞ÁöÑËÉΩÂäõÔºåÂåÖÊã¨Èï∑Â∞æÈóú‰øÇ„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂÑ™Êñº‰∏Ä‰∫õÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ</paragraph>

##### **ContraSolver: Self-Alignment of Language Models by Resolving Internal Preference Contradictions**
2406.08842v1 by Xu Zhang, Xunjian Yin, Xiaojun Wan

While substantial advancements have been made in developing large language
models (LLMs), achieving control over their behavior can be difficult. Direct
preference optimization (DPO) assumes the existence of a latent reward function
to evaluate the responses of LLMs. This assumption indicates a strict
preference ordering of different responses to the same input. However, there
always exist contradictions of preference in LLMs according to our experimental
observations. In this paper, we construct a graph structure of the preference
relationship among different responses with self-annotation to find
contradictions in the preference order. We propose ContraSolver, an algorithm
that traverses all edges on the preference graph to identify those that might
cause contradictions. ContraSolver initializes the graph with a maximum
spanning tree and identifies contradictory edges, prioritizing the resolution
of low-confidence preferences while preserving high-confidence ones.
Experimental results on four different generation tasks show that the
performance of different LLMs can be largely improved through our completely
unsupervised self-alignment. Furthermore, by analyzing the preference graphs of
LLMs with and without self-alignment by ContraSolver, we quantify the reduction
in contradictions, suggesting that resolving preference contradictions is
crucial for achieving better alignment performance.

ÊëòË¶ÅÔºöÂÑòÁÆ°Âú®ÈñãÁôºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊñπÈù¢Â∑≤Á∂ìÂèñÂæóÂØ¶Ë≥™ÊÄßÈÄ≤Â±ïÔºå‰ΩÜË¶ÅÊéßÂà∂ÂÖ∂Ë°åÁÇ∫ÂèØËÉΩÊúÉÂæàÂõ∞Èõ£„ÄÇÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) ÂÅáË®≠Â≠òÂú®‰∏ÄÂÄãÊΩõÂú®ÁöÑÁçéÂãµÂáΩÊï∏‰æÜË©ï‰º∞ LLM ÁöÑÂõûÊáâ„ÄÇÊ≠§ÂÅáË®≠Ë°®Á§∫Â∞çÁõ∏ÂêåËº∏ÂÖ•ÁöÑ‰∏çÂêåÂõûÊáâÊúâÂö¥Ê†ºÁöÑÂÅèÂ•ΩÊéíÂ∫è„ÄÇÁÑ∂ËÄåÔºåÊ†πÊìöÊàëÂÄëÁöÑÂØ¶È©óËßÄÂØüÔºåÂú® LLM ‰∏≠ÂßãÁµÇÂ≠òÂú®ÂÅèÂ•ΩÁöÑÁüõÁõæ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂÅèÂ•ΩÈóú‰øÇÂúñÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏çÂêåÂõûÊáâÁöÑËá™ÊàëË®ªËß£Ôºå‰ª•ÊâæÂá∫ÂÅèÂ•ΩÈ†ÜÂ∫è‰∏≠ÁöÑÁüõÁõæ„ÄÇÊàëÂÄëÊèêÂá∫ ContraSolverÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊºîÁÆóÊ≥ïÔºåÁî®ÊñºÈÅçÊ≠∑ÂÅèÂ•ΩÂúñ‰∏äÁöÑÊâÄÊúâÈÇäÁ∑£Ôºå‰ª•ÊâæÂá∫ÂèØËÉΩÂ∞éËá¥ÁüõÁõæÁöÑÈÇäÁ∑£„ÄÇContraSolver ‰ΩøÁî®ÊúÄÂ§ßÁîüÊàêÊ®πÂàùÂßãÂåñÂúñÂΩ¢Ôºå‰∏¶ÊâæÂá∫ÁüõÁõæÁöÑÈÇäÁ∑£ÔºåÂÑ™ÂÖàËß£Ê±∫‰Ωé‰ø°ÂøÉÁöÑÂÅèÂ•ΩÔºåÂêåÊôÇ‰øùÁïôÈ´ò‰ø°ÂøÉÁöÑÂÅèÂ•Ω„ÄÇÂú®ÂõõÈ†Ö‰∏çÂêåÁöÑÁîüÊàê‰ªªÂãô‰∏äÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÈÄèÈÅéÊàëÂÄëÂÆåÂÖ®ÁÑ°Áõ£Áù£ÁöÑËá™Â∞çÈΩäÔºåÂèØ‰ª•Â§ßÂπÖÊîπÂñÑ‰∏çÂêå LLM ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÂàÜÊûê‰ΩøÁî® ContraSolver ÈÄ≤Ë°åËá™Â∞çÈΩäÂíåÊú™ÈÄ≤Ë°åËá™Â∞çÈΩäÁöÑ LLM ÁöÑÂÅèÂ•ΩÂúñÔºåÊàëÂÄëÈáèÂåñ‰∫ÜÁüõÁõæÁöÑÊ∏õÂ∞ëÔºåÈÄôË°®Á§∫Ëß£Ê±∫ÂÅèÂ•ΩÁüõÁõæÂ∞çÊñºÈÅîÊàêÊõ¥Â•ΩÁöÑÂ∞çÈΩäÊïàËÉΩËá≥ÈóúÈáçË¶Å„ÄÇ

##### **Research Trends for the Interplay between Large Language Models and Knowledge Graphs**
2406.08223v1 by Hanieh Khorashadizadeh, Fatima Zahra Amara, Morteza Ezzabady, Fr√©d√©ric Ieng, Sanju Tiwari, Nandana Mihindukulasooriya, Jinghua Groppe, Soror Sahri, Farah Benamara, Sven Groppe

This survey investigates the synergistic relationship between Large Language
Models (LLMs) and Knowledge Graphs (KGs), which is crucial for advancing AI's
capabilities in understanding, reasoning, and language processing. It aims to
address gaps in current research by exploring areas such as KG Question
Answering, ontology generation, KG validation, and the enhancement of KG
accuracy and consistency through LLMs. The paper further examines the roles of
LLMs in generating descriptive texts and natural language queries for KGs.
Through a structured analysis that includes categorizing LLM-KG interactions,
examining methodologies, and investigating collaborative uses and potential
biases, this study seeks to provide new insights into the combined potential of
LLMs and KGs. It highlights the importance of their interaction for improving
AI applications and outlines future research directions.

ÊëòË¶ÅÔºöÈÄôÈ†ÖË™øÊü•Êé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÁü•Ë≠òÂúñË≠ú (KG) ‰πãÈñìÁöÑÂçîÂêåÈóú‰øÇÔºåÈÄôÂ∞çÊèêÂçá AI Âú®ÁêÜËß£„ÄÅÊé®ÁêÜÂíåË™ûË®ÄËôïÁêÜÊñπÈù¢ÁöÑËÉΩÂäõËá≥ÈóúÈáçË¶Å„ÄÇÂÆÉÊó®Âú®ÈÄèÈÅéÊé¢Ë®éÁü•Ë≠òÂúñË≠úÂïèÁ≠î„ÄÅÊú¨‰ΩìÁîüÊàê„ÄÅÁü•Ë≠òÂúñË≠úÈ©óË≠âÔºå‰ª•ÂèäÈÄèÈÅé LLM Â¢ûÂº∑Áü•Ë≠òÂúñË≠úÁöÑÊ∫ñÁ¢∫ÊÄßÂíå‰∏ÄËá¥ÊÄßÁ≠âÈ†òÂüüÔºå‰æÜËß£Ê±∫Áï∂ÂâçÁ†îÁ©∂‰∏≠ÁöÑÂ∑ÆË∑ù„ÄÇÊú¨ÊñáÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é LLM Âú®ÁÇ∫Áü•Ë≠òÂúñË≠úÁî¢ÁîüÊèèËø∞ÊÄßÊñáÂ≠óÂíåËá™ÁÑ∂Ë™ûË®ÄÊü•Ë©¢ÊñπÈù¢ÁöÑ‰ΩúÁî®„ÄÇÈÄèÈÅé‰∏ÄÈ†ÖÁµêÊßãÂåñÂàÜÊûêÔºåÂåÖÊã¨ÂàÜÈ°û LLM-KG ‰∫íÂãï„ÄÅÊ™¢Ë¶ñÊñπÊ≥ï„ÄÅ‰ª•ÂèäÊé¢Ë®éÂçî‰ΩúÁî®ÈÄîÂíåÊΩõÂú®ÂÅèÂ∑ÆÔºåÊú¨Á†îÁ©∂Êó®Âú®Êèê‰æõ LLM ÂíåÁü•Ë≠òÂúñË≠úÁµêÂêàÊΩõÂäõÁöÑÊñ∞Ë¶ãËß£„ÄÇÂÆÉÂº∑Ë™ø‰∫ÜÂÆÉÂÄë‰∫íÂãïÂ∞çÊñºÊîπÂñÑ AI ÊáâÁî®Á®ãÂºèÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶Ê¶ÇËø∞‰∫ÜÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇ

##### **SHACL2FOL: An FOL Toolkit for SHACL Decision Problems**
2406.08018v1 by Paolo Pareti

Recent studies on the Shapes Constraint Language (SHACL), a W3C specification
for validating RDF graphs, rely on translating the language into first-order
logic in order to provide formally-grounded solutions to the validation,
containment and satisfiability decision problems. Continuing on this line of
research, we introduce SHACL2FOL, the first automatic tool that (i) translates
SHACL documents into FOL sentences and (ii) computes the answer to the two
static analysis problems of satisfiability and containment; it also allow to
test the validity of a graph with respect to a set of constraints. By
integrating with existing theorem provers, such as E and Vampire, the tool
computes the answer to the aforementioned decision problems and outputs the
corresponding first-order logic theories in the standard TPTP format. We
believe this tool can contribute to further theoretical studies of SHACL, by
providing an automatic first-order logic interpretation of its semantics, while
also benefiting SHACL practitioners, by supplying static analysis capabilities
to help the creation and management of SHACL constraints.

ÊëòË¶ÅÔºöÊúÄËøëÂ∞çÂΩ¢ÁãÄÁ¥ÑÊùüË™ûË®Ä (SHACL) ÁöÑÁ†îÁ©∂ÔºåW3C Ë¶èÁØÑÁî®ÊñºÈ©óË≠â RDF ÂúñÂΩ¢Ôºå‰æùË≥¥ÊñºÂ∞áË™ûË®ÄËΩâË≠ØÊàê‰∏ÄÈöéÈÇèËºØÔºå‰ª•‰æøÈáùÂ∞çÈ©óË≠â„ÄÅÂåÖÂê´ÂíåÂèØÊªøË∂≥ÊÄßÊ±∫Á≠ñÂïèÈ°åÊèê‰æõÊ≠£Âºè‰æùÊìöÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂª∂Á∫åÈÄôÊ¢ùÁ†îÁ©∂Ë∑ØÁ∑öÔºåÊàëÂÄë‰ªãÁ¥π SHACL2FOLÔºåÁ¨¨‰∏ÄÂÄãËá™ÂãïÂ∑•ÂÖ∑Ôºö(i) Â∞á SHACL Êñá‰ª∂ËΩâË≠ØÊàê FOL Âè•Â≠êÔºå‰ª•Âèä (ii) Ë®àÁÆóÂèØÊªøË∂≥ÊÄßÂíåÂåÖÂê´ÈÄôÂÖ©ÂÄãÈùúÊÖãÂàÜÊûêÂïèÈ°åÁöÑÁ≠îÊ°àÔºõÂÆÉ‰πüÂÖÅË®±Ê∏¨Ë©¶ÂúñÂΩ¢Áõ∏Â∞çÊñº‰∏ÄÁµÑÁ¥ÑÊùüÁöÑÊúâÊïàÊÄß„ÄÇËóâÁî±Êï¥ÂêàÁèæÊúâÁöÑÂÆöÁêÜË≠âÊòéÂô®Ôºå‰æãÂ¶Ç E Âíå VampireÔºåÊ≠§Â∑•ÂÖ∑Ë®àÁÆóÂâçËø∞Ê±∫Á≠ñÂïèÈ°åÁöÑÁ≠îÊ°àÔºå‰∏¶Ëº∏Âá∫Ê®ôÊ∫ñ TPTP Ê†ºÂºè‰∏≠Â∞çÊáâÁöÑ‰∏ÄÈöéÈÇèËºØÁêÜË´ñ„ÄÇÊàëÂÄëÁõ∏‰ø°Ê≠§Â∑•ÂÖ∑ÊúâÂä©ÊñºÈÄ≤‰∏ÄÊ≠•ÁöÑ SHACL ÁêÜË´ñÁ†îÁ©∂ÔºåËóâÁî±Êèê‰æõÂÖ∂Ë™ûÊÑèÁöÑËá™Âãï‰∏ÄÈöéÈÇèËºØË©ÆÈáãÔºåÂêåÊôÇ‰πüËÆì SHACL ÂæûÊ•≠‰∫∫Âì°ÂèóÁõäÔºåËóâÁî±Êèê‰æõÈùúÊÖãÂàÜÊûêÂäüËÉΩ‰æÜÂçîÂä©Âª∫Á´ãÂíåÁÆ°ÁêÜ SHACL Á¥ÑÊùü„ÄÇ

##### **Efficient Parallel Multi-Hop Reasoning: A Scalable Approach for Knowledge Graph Analysis**
2406.07727v1 by Jesmin Jahan Tithi, Fabio Checconi, Fabrizio Petrini

Multi-hop reasoning (MHR) is a process in artificial intelligence and natural
language processing where a system needs to make multiple inferential steps to
arrive at a conclusion or answer. In the context of knowledge graphs or
databases, it involves traversing multiple linked entities and relationships to
understand complex queries or perform tasks requiring a deeper understanding.
Multi-hop reasoning is a critical function in various applications, including
question answering, knowledge base completion, and link prediction. It has
garnered significant interest in artificial intelligence, machine learning, and
graph analytics.
  This paper focuses on optimizing MHR for time efficiency on large-scale
graphs, diverging from the traditional emphasis on accuracy which is an
orthogonal goal. We introduce a novel parallel algorithm that harnesses
domain-specific learned embeddings to efficiently identify the top K paths
between vertices in a knowledge graph to find the best answers to a three-hop
query. Our contributions are: (1) We present a new parallel algorithm to
enhance MHR performance, scalability and efficiency. (2) We demonstrate the
algorithm's superior performance on leading-edge Intel and AMD architectures
through empirical results.
  We showcase the algorithm's practicality through a case study on identifying
academic affiliations of potential Turing Award laureates in Deep Learning,
highlighting its capability to handle intricate entity relationships. This
demonstrates the potential of our approach to enabling high-performance MHR,
useful to navigate the growing complexity of modern knowledge graphs.

ÊëòË¶ÅÔºöÂ§öË∑≥Êé®ÁêÜ (MHR) ÊòØ‰∫∫Â∑•Êô∫ÊÖßÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÁöÑ‰∏ÄÂÄãÈÅéÁ®ãÔºåÁ≥ªÁµ±ÈúÄË¶ÅÂü∑Ë°åÂ§öÂÄãÊé®ÁêÜÊ≠•È©üÊâçËÉΩÂæóÂá∫ÁµêË´ñÊàñÁ≠îÊ°à„ÄÇÂú®Áü•Ë≠òÂúñË°®ÊàñË≥áÊñôÂ∫´ÁöÑËÉåÊôØ‰∏ãÔºåÂÆÉÊ∂âÂèäÈÅçÊ≠∑Â§öÂÄãÈÄ£ÁµêÂØ¶È´îÂíåÈóú‰øÇÔºå‰ª•‰∫ÜËß£Ë§áÈõúÁöÑÊü•Ë©¢ÊàñÂü∑Ë°åÈúÄË¶ÅÊõ¥Ê∑±ÂÖ•ÁêÜËß£ÁöÑ‰ªªÂãô„ÄÇÂ§öË∑≥Êé®ÁêÜÊòØÂêÑÁ®ÆÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµÂäüËÉΩÔºåÂåÖÊã¨ÂïèÁ≠î„ÄÅÁü•Ë≠òÂ∫´ÂÆåÊàêÂíåÈÄ£ÁµêÈ†êÊ∏¨„ÄÇÂÆÉÂú®‰∫∫Â∑•Êô∫ÊÖß„ÄÅÊ©üÂô®Â≠∏ÁøíÂíåÂúñÂΩ¢ÂàÜÊûê‰∏≠ÂºïËµ∑‰∫ÜÊ•µÂ§ßÁöÑËààË∂£„ÄÇ
Êú¨ÊñáÈáçÈªûÂú®ÊñºÈáùÂ∞çÂ§ßË¶èÊ®°ÂúñË°®ÊúÄ‰Ω≥Âåñ MHR ÁöÑÊôÇÈñìÊïàÁéáÔºåËàáÂÇ≥Áµ±‰∏äÂº∑Ë™øÊ∫ñÁ¢∫ÊÄßÁöÑÊ≠£‰∫§ÁõÆÊ®ô‰∏çÂêå„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ‰∏¶Ë°åÊºîÁÆóÊ≥ïÔºåÂà©Áî®ÁâπÂÆöÊñºÈ†òÂüüÁöÑÂ≠∏ÁøíÂµåÂÖ•‰æÜÊúâÊïàÁéáÂú∞Ë≠òÂà•Áü•Ë≠òÂúñË°®‰∏≠È†ÇÈªû‰πãÈñìÁöÑÈ†ÇÂ∞ñ K Ë∑ØÂæëÔºå‰ª•ÊâæÂá∫‰∏âË∑≥Êü•Ë©¢ÁöÑÊúÄ‰Ω≥Á≠îÊ°à„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂ¶Ç‰∏ãÔºö(1) ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ‰∏¶Ë°åÊºîÁÆóÊ≥ïÔºå‰ª•Â¢ûÂº∑ MHR ÁöÑÊïàËÉΩ„ÄÅÂèØÊì¥ÂÖÖÊÄßÂíåÊïàÁéá„ÄÇ(2) ÊàëÂÄëÈÄèÈÅéÂØ¶Ë≠âÁµêÊûúË≠âÊòé‰∫ÜË©≤ÊºîÁÆóÊ≥ïÂú®È†òÂÖàÁöÑ Intel Âíå AMD Êû∂Êßã‰∏äÁöÑÂçìË∂äÊïàËÉΩ„ÄÇ
ÊàëÂÄëÈÄèÈÅé‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂Â±ïÁ§∫‰∫ÜË©≤ÊºîÁÆóÊ≥ïÁöÑÂØ¶Áî®ÊÄßÔºåË©≤Á†îÁ©∂Ë≠òÂà•‰∫ÜÊ∑±Â∫¶Â≠∏Áøí‰∏≠ÊΩõÂú®ÁöÑÂúñÈùàÁçéÂæó‰∏ªÁöÑÂ≠∏Ë°ìÈóú‰øÇÔºåÁ™ÅÈ°Ø‰∫ÜÂÆÉËôïÁêÜË§áÈõúÂØ¶È´îÈóú‰øÇÁöÑËÉΩÂäõ„ÄÇÈÄôË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÂØ¶ÁèæÈ´òÊÄßËÉΩ MHR ÁöÑÊΩõÂäõÔºåÊúâÂä©ÊñºÊáâÂ∞çÁèæ‰ª£Áü•Ë≠òÂúñË°®Êó•ÁõäÂ¢ûÈï∑ÁöÑË§áÈõúÊÄß„ÄÇ

##### **TextGrad: Automatic "Differentiation" via Text**
2406.07496v1 by Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Zhi Huang, Carlos Guestrin, James Zou

AI is undergoing a paradigm shift, with breakthroughs achieved by systems
orchestrating multiple large language models (LLMs) and other complex
components. As a result, developing principled and automated optimization
methods for compound AI systems is one of the most important new challenges.
Neural networks faced a similar challenge in its early days until
backpropagation and automatic differentiation transformed the field by making
optimization turn-key. Inspired by this, we introduce TextGrad, a powerful
framework performing automatic ``differentiation'' via text. TextGrad
backpropagates textual feedback provided by LLMs to improve individual
components of a compound AI system. In our framework, LLMs provide rich,
general, natural language suggestions to optimize variables in computation
graphs, ranging from code snippets to molecular structures. TextGrad follows
PyTorch's syntax and abstraction and is flexible and easy-to-use. It works
out-of-the-box for a variety of tasks, where the users only provide the
objective function without tuning components or prompts of the framework. We
showcase TextGrad's effectiveness and generality across a diverse range of
applications, from question answering and molecule optimization to radiotherapy
treatment planning. Without modifying the framework, TextGrad improves the
zero-shot accuracy of GPT-4o in Google-Proof Question Answering from $51\%$ to
$55\%$, yields $20\%$ relative performance gain in optimizing LeetCode-Hard
coding problem solutions, improves prompts for reasoning, designs new druglike
small molecules with desirable in silico binding, and designs radiation
oncology treatment plans with high specificity. TextGrad lays a foundation to
accelerate the development of the next-generation of AI systems.

ÊëòË¶ÅÔºö<paragraph>AI Ê≠£Á∂ìÊ≠∑‰∏ÄÂ†¥ÂÖ∏ÁØÑËΩâÁßªÔºåÁ™ÅÁ†¥‰æÜËá™ÊñºÁ≥ªÁµ±Á∑®ÊéíÂ§öÂÄãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÂÖ∂‰ªñË§áÈõúÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂõ†Ê≠§ÔºåÁÇ∫Ë§áÂêàÂºè AI Á≥ªÁµ±ÈñãÁôºÂéüÂâáÂåñ‰∏îËá™ÂãïÂåñÁöÑÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÔºåÊòØÂÖ∂‰∏≠‰∏ÄÈ†ÖÊúÄÈáçË¶ÅÁöÑÊñ∞ÊåëÊà∞„ÄÇÁ•ûÁ∂ìÁ∂≤Ë∑ØÂú®Êó©ÊúüÈù¢Ëá®È°û‰ººÁöÑÊåëÊà∞ÔºåÁõ¥Âà∞ÂèçÂêëÂÇ≥Êí≠ÂíåËá™ÂãïÂæÆÂàÜÈÄèÈÅéËÆìÊúÄ‰Ω≥ÂåñËÆäÂæóÂÆπÊòìÔºåÈÄ≤ËÄåËΩâËÆä‰∫ÜÈÄôÂÄãÈ†òÂüü„ÄÇÂèóÂà∞Ê≠§ÂïüÁôºÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü TextGradÔºå‰∏ÄÂÄãÂº∑Â§ßÁöÑÊ°ÜÊû∂ÔºåÈÄèÈÅéÊñáÂ≠óÂü∑Ë°åËá™Âãï„ÄåÂæÆÂàÜ„Äç„ÄÇTextGrad ÂèçÂêëÂÇ≥Êí≠ LLM Êèê‰æõÁöÑÊñáÂ≠óÂõûÈ•ãÔºå‰ª•ÊîπÂñÑË§áÂêàÂºè AI Á≥ªÁµ±ÁöÑÂÄãÂà•ÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂú®ÊàëÂÄëÁöÑÊ°ÜÊû∂‰∏≠ÔºåLLM Êèê‰æõË±êÂØå„ÄÅÈÄöÁî®„ÄÅËá™ÁÑ∂ÁöÑË™ûË®ÄÂª∫Ë≠∞Ôºå‰æÜÊúÄ‰Ω≥ÂåñÈÅãÁÆóÂúñ‰∏≠ÁöÑËÆäÊï∏ÔºåÁØÑÂúçÂæûÁ®ãÂºèÁ¢ºÁâáÊÆµÂà∞ÂàÜÂ≠êÁµêÊßã„ÄÇTextGrad ÈÅµÂæ™ PyTorch ÁöÑË™ûÊ≥ïÂíåÊäΩË±°Ôºå‰∏îÈùàÊ¥ª‰∏îÊòìÊñº‰ΩøÁî®„ÄÇÂÆÉÈÅ©Áî®ÊñºÂêÑÁ®Æ‰ªªÂãôÔºå‰ΩøÁî®ËÄÖÂè™ÈúÄÊèê‰æõÁõÆÊ®ôÂáΩÊï∏ÔºåËÄåÁÑ°ÈúÄË™øÊï¥Ê°ÜÊû∂ÁöÑÁµÑÊàêÈÉ®ÂàÜÊàñÊèêÁ§∫„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü TextGrad Âú®ÂêÑÁ®ÆÊáâÁî®‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÊôÆÈÅçÊÄßÔºåÂæûÂïèÁ≠îÂíåÂàÜÂ≠êÊúÄ‰Ω≥ÂåñÂà∞ÊîæÂ∞ÑÊ≤ªÁôÇË®àÁï´„ÄÇÂú®‰∏ç‰øÆÊîπÊ°ÜÊû∂ÁöÑÊÉÖÊ≥Å‰∏ãÔºåTextGrad Â∞á Google-Proof ÂïèÁ≠î‰∏≠ GPT-4o ÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊ∫ñÁ¢∫Â∫¶Âæû 51% ÊèêÂçáËá≥ 55%ÔºåÂú®ÊúÄ‰Ω≥Âåñ LeetCode-Hard Á∑®Á¢ºÂïèÈ°åËß£Á≠î‰∏≠Áî¢Áîü 20% ÁöÑÁõ∏Â∞çÊïàËÉΩÊèêÂçáÔºåÊîπÂñÑÊé®ÁêÜÊèêÁ§∫ÔºåË®≠Ë®àÂÖ∑ÊúâÁêÜÊÉ≥ÁöÑÁüΩÂü∫ÁµêÂêàÁöÑÊñ∞Ëó•Áâ©Â∞èÂàÜÂ≠êÔºå‰∏¶Ë®≠Ë®àÂá∫ÂÖ∑ÊúâÈ´òÁâπÁï∞ÊÄßÁöÑÊîæÂ∞ÑËÖ´Áò§Ê≤ªÁôÇË®àÁï´„ÄÇTextGrad ÁÇ∫Âä†ÈÄüÈñãÁôº‰∏ã‰∏Ä‰ª£ AI Á≥ªÁµ±Â•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ</paragraph>

##### **CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**
2406.07494v2 by Frederic Kirstein, Jan Philip Wahle, Bela Gipp, Terry Ruas

Abstractive dialogue summarization is the task of distilling conversations
into informative and concise summaries. Although reviews have been conducted on
this topic, there is a lack of comprehensive work detailing the challenges of
dialogue summarization, unifying the differing understanding of the task, and
aligning proposed techniques, datasets, and evaluation metrics with the
challenges. This article summarizes the research on Transformer-based
abstractive summarization for English dialogues by systematically reviewing
1262 unique research papers published between 2019 and 2024, relying on the
Semantic Scholar and DBLP databases. We cover the main challenges present in
dialog summarization (i.e., language, structure, comprehension, speaker,
salience, and factuality) and link them to corresponding techniques such as
graph-based approaches, additional training tasks, and planning strategies,
which typically overly rely on BART-based encoder-decoder models. We find that
while some challenges, like language, have seen considerable progress, mainly
due to training methods, others, such as comprehension, factuality, and
salience, remain difficult and hold significant research opportunities. We
investigate how these approaches are typically assessed, covering the datasets
for the subdomains of dialogue (e.g., meeting, medical), the established
automatic metrics and human evaluation approaches for assessing scores and
annotator agreement. We observe that only a few datasets span across all
subdomains. The ROUGE metric is the most used, while human evaluation is
frequently reported without sufficient detail on inner-annotator agreement and
annotation guidelines. Additionally, we discuss the possible implications of
the recently explored large language models and conclude that despite a
potential shift in relevance and difficulty, our described challenge taxonomy
remains relevant.

ÊëòË¶ÅÔºö<paragraph>ÊäΩË±°ÂºèÂ∞çË©±ÊëòË¶ÅÊòØÂ∞áÂ∞çË©±ÊøÉÁ∏ÆÊàêÂÖ∑ÊúâË≥áË®äÊÄß‰∏îÁ∞°ÊΩîÁöÑÊëòË¶Å„ÄÇÂÑòÁÆ°Â∑≤ÈáùÂ∞çÊ≠§‰∏ªÈ°åÈÄ≤Ë°åÂØ©Êü•Ôºå‰ΩÜ‰ªçÁº∫‰πèË©≥Á¥∞Ë™™ÊòéÂ∞çË©±ÊëòË¶ÅÊåëÊà∞„ÄÅÁµ±‰∏ÄÂ∞ç‰ªªÂãôÁöÑ‰∏çÂêåÁêÜËß£Ôºå‰ª•ÂèäÂ∞áÂª∫Ë≠∞ÁöÑÊäÄË°ì„ÄÅË≥áÊñôÈõÜÂíåË©ï‰º∞ÊåáÊ®ôËàáÊåëÊà∞Áõ∏Á¨¶ÁöÑÂÖ®Èù¢ÊÄßÁ†îÁ©∂„ÄÇÊú¨ÊñáÈÄèÈÅéÁ≥ªÁµ±ÊÄßÂú∞Ê™¢Èñ± 2019 Âπ¥Ëá≥ 2024 Âπ¥ÈñìÁôºË°®ÁöÑ 1262 ÁØáÁç®ÁâπÁ†îÁ©∂Ë´ñÊñáÔºå‰æùË≥¥Ë™ûÁæ©Â≠∏ËÄÖÂíå DBLP Ë≥áÊñôÂ∫´ÔºåÁ∏ΩÁµê‰∫ÜÂü∫Êñº Transformer ÁöÑËã±Ë™ûÂ∞çË©±ÊäΩË±°ÂºèÊëòË¶ÅÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÊ∂µËìãÂ∞çË©±ÊëòË¶Å‰∏≠Âá∫ÁèæÁöÑ‰∏ªË¶ÅÊåëÊà∞ÔºàÂç≥Ë™ûË®Ä„ÄÅÁµêÊßã„ÄÅÁêÜËß£„ÄÅË™™Ë©±ËÄÖ„ÄÅÈ°ØËëóÊÄßÂíåÁúüÂØ¶ÊÄßÔºâÔºå‰∏¶Â∞áÂÆÉÂÄëÈÄ£ÁµêÂà∞Â∞çÊáâÁöÑÊäÄË°ìÔºå‰æãÂ¶ÇÂü∫ÊñºÂúñÂΩ¢ÁöÑÊñπÊ≥ï„ÄÅÈ°çÂ§ñÁöÑË®ìÁ∑¥‰ªªÂãôÂíåË¶èÂäÉÁ≠ñÁï•ÔºåÈÄô‰∫õÁ≠ñÁï•ÈÄöÂ∏∏ÈÅéÂ∫¶‰æùË≥¥ÊñºÂü∫Êñº BART ÁöÑÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Ê®°Âûã„ÄÇÊàëÂÄëÁôºÁèæÔºåÈõñÁÑ∂Ë™ûË®ÄÁ≠â‰∏Ä‰∫õÊåëÊà∞Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÂæó‰∫ÜÈÄ≤Â±ïÔºåÈÄô‰∏ªË¶ÅÊòØÁî±ÊñºË®ìÁ∑¥ÊñπÊ≥ïÔºå‰ΩÜÂÖ∂‰ªñÊåëÊà∞Ôºå‰æãÂ¶ÇÁêÜËß£„ÄÅÁúüÂØ¶ÊÄßÂíåÈ°ØËëóÊÄßÔºå‰ªçÁÑ∂ÂæàÂõ∞Èõ£Ôºå‰∏¶ÂÖ∑ÊúâÈáçÂ§ßÁöÑÁ†îÁ©∂Ê©üÊúÉ„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄöÂ∏∏Â¶Ç‰ΩïË©ï‰º∞ÈÄô‰∫õÊñπÊ≥ïÔºåÊ∂µËìã‰∫ÜÂ∞çË©±Â≠êÈ†òÂüüÔºà‰æãÂ¶ÇÊúÉË≠∞„ÄÅÈÜ´ÁôÇÔºâÁöÑË≥áÊñôÈõÜÔºåÊó¢ÂÆöÁöÑËá™ÂãïÂåñÊåáÊ®ôÂíåÁî®ÊñºË©ï‰º∞ÂàÜÊï∏ÂíåË®ªËß£ËÄÖ‰∏ÄËá¥ÊÄßÁöÑË©ï‰º∞ÊñπÊ≥ï„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåÂè™ÊúâÂ∞ëÊï∏Ë≥áÊñôÈõÜË∑®Ë∂äÊâÄÊúâÂ≠êÈ†òÂüü„ÄÇROUGE ÊåáÊ®ô‰ΩøÁî®ÊúÄÈ†ªÁπÅÔºåËÄå‰∫∫È°ûË©ï‰º∞ÈÄöÂ∏∏Âú®Ê≤íÊúâË∂≥Â§†ÁöÑË®ªËß£ËÄÖÂÖßÈÉ®‰∏ÄËá¥ÊÄßÂíåË®ªËß£ÊåáÂçóÁöÑË©≥Á¥∞Ë≥áË®ä‰∏ãÈÄ≤Ë°åÂ†±Âëä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜËøëÊúüÊé¢Á¥¢ÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÁöÑÂèØËÉΩÂΩ±ÈüøÔºå‰∏¶ÂæóÂá∫ÁµêË´ñÔºåÂÑòÁÆ°Áõ∏ÈóúÊÄßÂíåÈõ£Â∫¶ÂèØËÉΩÁôºÁîüËΩâËÆäÔºå‰ΩÜÊàëÂÄëÊâÄÊèèËø∞ÁöÑÊåëÊà∞ÂàÜÈ°ûÊ≥ï‰ªçÁÑ∂Áõ∏Èóú„ÄÇ</paragraph>

##### **Large Language Models for Constrained-Based Causal Discovery**
2406.07378v1 by Kai-Hendrik Cohrs, Gherardo Varando, Emiliano Diaz, Vasileios Sitokonstantinou, Gustau Camps-Valls

Causality is essential for understanding complex systems, such as the
economy, the brain, and the climate. Constructing causal graphs often relies on
either data-driven or expert-driven approaches, both fraught with challenges.
The former methods, like the celebrated PC algorithm, face issues with data
requirements and assumptions of causal sufficiency, while the latter demand
substantial time and domain knowledge. This work explores the capabilities of
Large Language Models (LLMs) as an alternative to domain experts for causal
graph generation. We frame conditional independence queries as prompts to LLMs
and employ the PC algorithm with the answers. The performance of the LLM-based
conditional independence oracle on systems with known causal graphs shows a
high degree of variability. We improve the performance through a proposed
statistical-inspired voting schema that allows some control over false-positive
and false-negative rates. Inspecting the chain-of-thought argumentation, we
find causal reasoning to justify its answer to a probabilistic query. We show
evidence that knowledge-based CIT could eventually become a complementary tool
for data-driven causal discovery.

ÊëòË¶ÅÔºöÂõ†ÊûúÈóú‰øÇÂ∞çÊñºÁêÜËß£Ë§áÈõúÁöÑÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶ÅÔºå‰æãÂ¶ÇÁ∂ìÊøü„ÄÅÂ§ßËÖ¶ÂíåÊ∞£ÂÄô„ÄÇÂª∫ÊßãÂõ†ÊûúÂúñË°®ÈÄöÂ∏∏‰æùË≥¥ÊñºË≥áÊñôÈ©ÖÂãïÊàñÂ∞àÂÆ∂È©ÖÂãïÁöÑÊñπÊ≥ïÔºåÈÄôÂÖ©Á®ÆÊñπÊ≥ïÈÉΩÂÖÖÊªø‰∫ÜÊåëÊà∞„ÄÇÂâçËÄÖÊñπÊ≥ïÔºå‰æãÂ¶ÇËëóÂêçÁöÑ PC ÊºîÁÆóÊ≥ïÔºåÈù¢Ëá®Ë≥áÊñôÈúÄÊ±ÇÂíåÂõ†ÊûúÂÖÖË∂≥ÊÄßÁöÑÂÅáË®≠ÂïèÈ°åÔºåËÄåÂæåËÄÖÂâáÈúÄË¶ÅÂ§ßÈáèÁöÑÊôÇÈñìÂíåÈ†òÂüüÁü•Ë≠ò„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊé¢Ë®é‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ΩúÁÇ∫Âõ†ÊûúÂúñÁîüÊàêÈ†òÂüüÂ∞àÂÆ∂ÁöÑÊõø‰ª£ÊñπÊ°àÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂ∞áÊ¢ù‰ª∂Áç®Á´ãÊü•Ë©¢Ë®≠ÂÆöÁÇ∫ LLM ÁöÑÊèêÁ§∫Ôºå‰∏¶‰ΩøÁî® PC ÊºîÁÆóÊ≥ïÊê≠ÈÖçÁ≠îÊ°à„ÄÇÂü∫Êñº LLM ÁöÑÊ¢ù‰ª∂Áç®Á´ãÁ•ûË´≠Âú®ÂÖ∑ÊúâÂ∑≤Áü•Âõ†ÊûúÂúñË°®ÁöÑÁ≥ªÁµ±‰∏äÁöÑÊïàËÉΩÈ°ØÁ§∫Âá∫È´òÂ∫¶ÁöÑËÆäÁï∞ÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÊèêË≠∞ÁöÑÁµ±Ë®àÂïüÁôºÂºèÊäïÁ•®Êû∂Êßã‰æÜÊîπÂñÑÊïàËÉΩÔºåË©≤Êû∂ÊßãÂÖÅË®±Â∞çÂÅáÈôΩÊÄßÂíåÂÅáÈô∞ÊÄßÁéáÈÄ≤Ë°å‰∏Ä‰∫õÊéßÂà∂„ÄÇÊ™¢Êü•ÊÄùËÄÉÈèàË´ñË≠âÔºåÊàëÂÄëÁôºÁèæÂõ†ÊûúÊé®ÁêÜÂèØ‰ª•Ë≠âÊòéÂÖ∂Â∞çÊ©üÁéáÊü•Ë©¢ÁöÑÂõûÁ≠î„ÄÇÊàëÂÄëÈ°ØÁ§∫Âü∫ÊñºÁü•Ë≠òÁöÑ CIT ÊúÄÁµÇÂèØËÉΩÊàêÁÇ∫Ë≥áÊñôÈ©ÖÂãïÂõ†ÊûúÁôºÁèæÁöÑË£úÂÖÖÂ∑•ÂÖ∑ÁöÑË≠âÊìö„ÄÇ

##### **Scaling Large-Language-Model-based Multi-Agent Collaboration**
2406.07155v1 by Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun

Pioneering advancements in large language model-powered agents have
underscored the design pattern of multi-agent collaboration, demonstrating that
collective intelligence can surpass the capabilities of each individual.
Inspired by the neural scaling law, which posits that increasing neurons leads
to emergent abilities, this study investigates whether a similar principle
applies to increasing agents in multi-agent collaboration. Technically, we
propose multi-agent collaboration networks (MacNet), which utilize directed
acyclic graphs to organize agents and streamline their interactive reasoning
via topological ordering, with solutions derived from their dialogues.
Extensive experiments show that MacNet consistently outperforms baseline
models, enabling effective agent collaboration across various network
topologies and supporting cooperation among more than a thousand agents.
Notably, we observed a small-world collaboration phenomenon, where topologies
resembling small-world properties achieved superior performance. Additionally,
we identified a collaborative scaling law, indicating that normalized solution
quality follows a logistic growth pattern as scaling agents, with collaborative
emergence occurring much earlier than previously observed instances of neural
emergence. The code and data will be available at
https://github.com/OpenBMB/ChatDev.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈ©±Âä®ÁöÑ‰ª£ÁêÜÁöÑÂºÄÂàõÊÄßËøõÊ≠•Âº∫Ë∞É‰∫ÜÂ§ö‰ª£ÁêÜÂçè‰ΩúÁöÑËÆæËÆ°Ê®°ÂºèÔºåËØÅÊòé‰∫ÜÈõÜ‰ΩìÊô∫ËÉΩÂèØ‰ª•Ë∂ÖË∂äÊØè‰∏™‰∏™‰ΩìÁöÑËÉΩÂäõ„ÄÇÂèóÁ•ûÁªèÁΩëÁªúÊâ©Â±ïÂÆöÂæãÁöÑÂêØÂèëÔºåËØ•ÂÆöÂæãËÆ§‰∏∫Â¢ûÂä†Á•ûÁªèÂÖÉ‰ºöÂØºËá¥ËÉΩÂäõÁöÑÊ∂åÁé∞ÔºåÊú¨Á†îÁ©∂Ë∞ÉÊü•‰∫ÜÁ±ª‰ººÁöÑÂéüÁêÜÊòØÂê¶ÈÄÇÁî®‰∫éÂ¢ûÂä†Â§ö‰ª£ÁêÜÂçè‰Ωú‰∏≠ÁöÑ‰ª£ÁêÜ„ÄÇÂú®ÊäÄÊúØ‰∏äÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂ§ö‰ª£ÁêÜÂçè‰ΩúÁΩëÁªúÔºàMacNetÔºâÔºåÂÆÉÂà©Áî®ÊúâÂêëÊó†ÁéØÂõæÊù•ÁªÑÁªá‰ª£ÁêÜÂπ∂ÈÄöËøáÊãìÊâëÊéíÂ∫èÁÆÄÂåñÂÆÉ‰ª¨ÁöÑ‰∫§‰∫íÊé®ÁêÜÔºåËß£ÂÜ≥ÊñπÊ°àÊù•Ëá™ÂÆÉ‰ª¨ÁöÑÂØπËØù„ÄÇÂπøÊ≥õÁöÑÂÆûÈ™åË°®ÊòéÔºåMacNet ÂßãÁªà‰ºò‰∫éÂü∫Á∫øÊ®°ÂûãÔºåËÉΩÂ§üÂú®ÂêÑÁßçÁΩëÁªúÊãìÊâë‰∏≠ÂÆûÁé∞ÊúâÊïàÁöÑ‰ª£ÁêÜÂçè‰ΩúÔºåÂπ∂ÊîØÊåÅ‰∏ÄÂçÉÂ§ö‰∏™‰ª£ÁêÜ‰πãÈó¥ÁöÑÂêà‰Ωú„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàë‰ª¨ËßÇÂØüÂà∞‰∫Ü‰∏ÄÁßçÂ∞è‰∏ñÁïåÂçè‰ΩúÁé∞Ë±°ÔºåÂÖ∂‰∏≠Á±ª‰ºº‰∫éÂ∞è‰∏ñÁïåÂ±ûÊÄßÁöÑÊãìÊâëÁªìÊûÑÂèñÂæó‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Á°ÆÂÆö‰∫Ü‰∏Ä‰∏™Âçè‰ΩúÊâ©Â±ïÂÆöÂæãÔºåË°®ÊòéÂΩí‰∏ÄÂåñËß£ÂÜ≥ÊñπÊ°àË¥®ÈáèÈÅµÂæ™ÈÄªËæëÂ¢ûÈïøÊ®°Âºè‰Ωú‰∏∫Êâ©Â±ï‰ª£ÁêÜÔºåÂçè‰ΩúÊ∂åÁé∞ÊØîÂÖàÂâçËßÇÂØüÂà∞ÁöÑÁ•ûÁªèÊ∂åÁé∞ÂÆû‰æãÂèëÁîüÂæóÊõ¥Êó©„ÄÇ‰ª£Á†ÅÂíåÊï∞ÊçÆÂ∞ÜÂèØÂú® https://github.com/OpenBMB/ChatDev Ëé∑Âæó„ÄÇ</paragraph>

##### **Mining Frequent Structures in Conceptual Models**
2406.07129v1 by Mattia Fumagalli, Tiago Prince Sales, Pedro Paulo F. Barcelos, Giovanni Micale, Vadim Zaytsev, Diego Calvanese, Giancarlo Guizzardi

The problem of using structured methods to represent knowledge is well-known
in conceptual modeling and has been studied for many years. It has been proven
that adopting modeling patterns represents an effective structural method.
Patterns are, indeed, generalizable recurrent structures that can be exploited
as solutions to design problems. They aid in understanding and improving the
process of creating models. The undeniable value of using patterns in
conceptual modeling was demonstrated in several experimental studies. However,
discovering patterns in conceptual models is widely recognized as a highly
complex task and a systematic solution to pattern identification is currently
lacking. In this paper, we propose a general approach to the problem of
discovering frequent structures, as they occur in conceptual modeling
languages. As proof of concept for our scientific contribution, we provide an
implementation of the approach, by focusing on UML class diagrams, in
particular OntoUML models. This implementation comprises an exploratory tool,
which, through the combination of a frequent subgraph mining algorithm and
graph manipulation techniques, can process multiple conceptual models and
discover recurrent structures according to multiple criteria. The primary
objective is to offer a support facility for language engineers. This can be
employed to leverage both good and bad modeling practices, to evolve and
maintain the conceptual modeling language, and to promote the reuse of encoded
experience in designing better models with the given language.

ÊëòË¶ÅÔºöÁµêÊßãÂåñÊñπÊ≥ïÁî®ÊñºË°®Á§∫Áü•Ë≠òÁöÑÂïèÈ°åÂú®Ê¶ÇÂøµÂª∫Ê®°‰∏≠ÊòØÁúæÊâÄÂë®Áü•ÁöÑÔºå‰∏¶‰∏îÂ∑≤Á∂ìÁ†îÁ©∂Â§öÂπ¥„ÄÇÂ∑≤Á∂ìË≠âÊòéÊé°Áî®Âª∫Ê®°Ê®°Âºè‰ª£Ë°®‰∏ÄÁ®ÆÊúâÊïàÁöÑÁµêÊßãÂåñÊñπÊ≥ï„ÄÇÊ®°ÂºèÁ¢∫ÂØ¶ÊòØÂèØÊ¶ÇÊã¨ÁöÑÈÅûËø¥ÁµêÊßãÔºåÂèØ‰ª•‰ΩúÁÇ∫Ë®≠Ë®àÂïèÈ°åÁöÑËß£Ê±∫ÊñπÊ°àÂä†‰ª•Âà©Áî®„ÄÇÂÆÉÂÄëÊúâÂä©ÊñºÁêÜËß£ÂíåÊîπÈÄ≤Âª∫Á´ãÊ®°ÂûãÁöÑÈÅéÁ®ã„ÄÇÂú®Â§öÈ†ÖÂØ¶È©óÁ†îÁ©∂‰∏≠Ë≠âÊòé‰∫ÜÂú®Ê¶ÇÂøµÂª∫Ê®°‰∏≠‰ΩøÁî®Ê®°ÂºèÁöÑ‰∏çÂèØÂê¶Ë™çÂÉπÂÄº„ÄÇÁÑ∂ËÄåÔºåÁôºÁèæÊ¶ÇÂøµÊ®°Âûã‰∏≠ÁöÑÊ®°ÂºèË¢´Âª£Ê≥õË™çÁÇ∫ÊòØ‰∏ÄÈ†ÖÈ´òÂ∫¶Ë§áÈõúÁöÑ‰ªªÂãôÔºåËÄå‰∏îÁõÆÂâçÁº∫‰πèÊ®°ÂºèË≠òÂà•ÁöÑÁ≥ªÁµ±ÊÄßËß£Ê±∫ÊñπÊ°à„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁôºÁèæÈ†ªÁπÅÁµêÊßãÂïèÈ°åÁöÑ‰∏ÄËà¨ÊñπÊ≥ïÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂá∫ÁèæÂú®Ê¶ÇÂøµÂª∫Ê®°Ë™ûË®Ä‰∏≠„ÄÇ‰ΩúÁÇ∫ÊàëÂÄëÁßëÂ≠∏Ë≤¢ÁçªÁöÑÊ¶ÇÂøµÈ©óË≠âÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÁöÑÂØ¶ÁèæÔºåÈáçÈªûÈóúÊ≥® UML È°ûÂà•ÂúñÔºåÁâπÂà•ÊòØ OntoUML Ê®°Âûã„ÄÇÊ≠§ÂØ¶ÁèæÂåÖÂê´‰∏ÄÂÄãÊé¢Á¥¢Â∑•ÂÖ∑ÔºåË©≤Â∑•ÂÖ∑ÈÄöÈÅéÁµêÂêàÈ†ªÁπÅÂ≠êÂúñÊåñÊéòÊºîÁÆóÊ≥ïÂíåÂúñÂΩ¢ËôïÁêÜÊäÄË°ìÔºåÂèØ‰ª•ËôïÁêÜÂ§öÂÄãÊ¶ÇÂøµÊ®°ÂûãÔºå‰∏¶Ê†πÊìöÂ§öÂÄãÊ®ôÊ∫ñÁôºÁèæÈÅûËø¥ÁµêÊßã„ÄÇ‰∏ªË¶ÅÁõÆÊ®ôÊòØÁÇ∫Ë™ûË®ÄÂ∑•Á®ãÂ∏´Êèê‰æõÊîØÊè¥Â∑•ÂÖ∑„ÄÇÈÄôÂèØ‰ª•Áî®‰æÜÂà©Áî®Â•ΩÁöÑÂíåÂ£ûÁöÑÂª∫Ê®°ÂØ¶ÂãôÔºå‰æÜÊºîÈÄ≤ÂíåÁ∂≠Ë≠∑Ê¶ÇÂøµÂª∫Ê®°Ë™ûË®ÄÔºå‰∏¶‰øÉÈÄ≤Âú®Ë®≠Ë®àÊõ¥Â•ΩÁöÑÊ®°ÂûãÊôÇÂ∞çÁ∑®Á¢ºÁ∂ìÈ©óÁöÑÂÜçÂà©Áî®„ÄÇ

##### **Beyond Bare Queries: Open-Vocabulary Object Retrieval with 3D Scene Graph**
2406.07113v2 by Sergey Linok, Tatiana Zemskova, Svetlana Ladanova, Roman Titkov, Dmitry Yudin

Locating objects referred to in natural language poses a significant
challenge for autonomous agents. Existing CLIP-based open-vocabulary methods
successfully perform 3D object retrieval with simple (bare) queries but cannot
cope with ambiguous descriptions that demand an understanding of object
relations. To tackle this problem, we propose a modular approach called BBQ
(Beyond Bare Queries), which constructs 3D scene spatial graph representation
with metric edges and utilizes a large language model as a human-to-agent
interface through our deductive scene reasoning algorithm. BBQ employs robust
DINO-powered associations to form 3D objects, an advanced raycasting algorithm
to project them to 2D, and a vision-language model to describe them as graph
nodes. On Replica and ScanNet datasets, we show that the designed method
accurately constructs 3D object-centric maps. We have demonstrated that their
quality takes a leading place for open-vocabulary 3D semantic segmentation
against other zero-shot methods. Also, we show that leveraging spatial
relations is especially effective for scenes containing multiple entities of
the same semantic class. On Sr3D and Nr3D benchmarks, our deductive approach
demonstrates a significant improvement, enabling retrieving objects by complex
queries compared to other state-of-the-art methods. Considering our design
solutions, we achieved a processing speed approximately x3 times faster than
the closest analog. This promising performance enables our approach for usage
in applied intelligent robotics projects. We make the code publicly available
at linukc.github.io/bbq/.

ÊëòË¶ÅÔºö<paragraph>Â∞çÊñºËá™‰∏ª‰ª£ÁêÜËÄåË®ÄÔºåÂÆö‰ΩçËá™ÁÑ∂Ë™ûË®Ä‰∏≠ÊâÄÊåáÊ∂âÁöÑÁâ©‰ª∂ÊúÉÂ∏∂‰æÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÁèæÊúâÁöÑÂü∫Êñº CLIP ÁöÑÈñãÊîæÂºèË©ûÂΩôÊñπÊ≥ïÂèØ‰ª•ÊàêÂäüÂú∞‰ΩøÁî®Á∞°ÂñÆÔºàË£∏ÔºâÊü•Ë©¢‰æÜÂü∑Ë°å 3D Áâ©‰ª∂Êì∑ÂèñÔºå‰ΩÜÁÑ°Ê≥ïÊáâÂ∞çÈúÄË¶ÅÁêÜËß£Áâ©‰ª∂Èóú‰øÇÁöÑÊ®°Á®úÂÖ©ÂèØÁöÑÊèèËø∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ BBQÔºàË∂ÖË∂äË£∏Êü•Ë©¢ÔºâÁöÑÊ®°ÁµÑÂåñÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊßãÂª∫‰∫ÜÂÖ∑ÊúâÂ∫¶ÈáèÈÇäÁ∑£ÁöÑ 3D Â†¥ÊôØÁ©∫ÈñìÂúñÂΩ¢Ë°®Á§∫Ôºå‰∏¶ÈÄèÈÅéÊàëÂÄëÊºîÁππÂ†¥ÊôØÊé®ÁêÜÊºîÁÆóÊ≥ïÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁî®‰Ωú‰∫∫Âà∞‰ª£ÁêÜ‰ªãÈù¢„ÄÇBBQ ‰ΩøÁî®Âº∑Â§ßÁöÑ DINO È©ÖÂãïÈóúËÅØ‰æÜÂΩ¢Êàê 3D Áâ©‰ª∂Ôºå‰∏ÄÁ®ÆÈÄ≤ÈöéÁöÑÂÖâÁ∑öÊäïÂ∞ÑÊºîÁÆóÊ≥ïÂ∞áÂÆÉÂÄëÊäïÂΩ±Âà∞ 2DÔºå‰ª•Âèä‰∏ÄÂÄãË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÂ∞áÂÆÉÂÄëÊèèËø∞ÁÇ∫ÂúñÂΩ¢ÁØÄÈªû„ÄÇÂú® Replica Âíå ScanNet Ë≥áÊñôÈõÜ‰∏äÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊâÄË®≠Ë®àÁöÑÊñπÊ≥ïÂèØ‰ª•Ê∫ñÁ¢∫Âú∞Âª∫Êßã 3D Áâ©‰ª∂ÁÇ∫‰∏≠ÂøÉÁöÑÂ∞çÊáâ„ÄÇÊàëÂÄëÂ∑≤Á∂ìË≠âÊòéÔºåÂÆÉÂÄëÁöÑÂìÅË≥™Âú®ÈñãÊîæÂºèË©ûÂΩô 3D Ë™ûÊÑèÂàÜÂâ≤‰∏≠È†òÂÖàÊñºÂÖ∂‰ªñÈõ∂Ê¨°Â≠∏ÁøíÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂà©Áî®Á©∫ÈñìÈóú‰øÇÂ∞çÊñºÂåÖÂê´Â§öÂÄãÂÖ∑ÊúâÁõ∏ÂêåË™ûÊÑèÈ°ûÂà•ÁöÑÂØ¶È´îÁöÑÂ†¥ÊôØÁâπÂà•ÊúâÊïà„ÄÇÂú® Sr3D Âíå Nr3D Âü∫Ê∫ñ‰∏äÔºåÊàëÂÄëÁöÑÊºîÁππÊñπÊ≥ïÂ±ïÁ§∫‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤ÔºåËàáÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËÉΩÂ§†ÈÄèÈÅéË§áÈõúÁöÑÊü•Ë©¢‰æÜÊì∑ÂèñÁâ©‰ª∂„ÄÇËÄÉÈáèÊàëÂÄëÁöÑË®≠Ë®àËß£Ê±∫ÊñπÊ°àÔºåÊàëÂÄëÈÅîÂà∞‰∫ÜÊØîÊúÄÊé•ËøëÁöÑÈ°ûÊØîÂø´Á¥Ñ 3 ÂÄçÁöÑËôïÁêÜÈÄüÂ∫¶„ÄÇÈÄôÁ®ÆÊúâÂâçÈÄîÁöÑÊïàËÉΩ‰ΩøÊàëÂÄëÁöÑÂÅöÊ≥ïËÉΩÂ§†Áî®ÊñºÊáâÁî®Êô∫ÊÖßÊ©üÂô®‰∫∫Â∞àÊ°à‰∏≠„ÄÇÊàëÂÄëÂú® linukc.github.io/bbq/ ÂÖ¨ÈñãÁ®ãÂºèÁ¢º„ÄÇ</paragraph>

##### **DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs**
2406.07080v1 by Haishuo Fang, Xiaodan Zhu, Iryna Gurevych

Answering Questions over Knowledge Graphs (KGQA) is key to well-functioning
autonomous language agents in various real-life applications. To improve the
neural-symbolic reasoning capabilities of language agents powered by Large
Language Models (LLMs) in KGQA, we propose the DecompositionAlignment-Reasoning
Agent (DARA) framework. DARA effectively parses questions into formal queries
through a dual mechanism: high-level iterative task decomposition and low-level
task grounding. Importantly, DARA can be efficiently trained with a small
number of high-quality reasoning trajectories. Our experimental results
demonstrate that DARA fine-tuned on LLMs (e.g. Llama-2-7B, Mistral) outperforms
both in-context learning-based agents with GPT-4 and alternative fine-tuned
agents, across different benchmarks in zero-shot evaluation, making such models
more accessible for real-life applications. We also show that DARA attains
performance comparable to state-of-the-art enumerating-and-ranking-based
methods for KGQA.

ÊëòË¶ÅÔºöÂõûÁ≠îÁü•Ë≠òÂúñË°®ÔºàKGQAÔºâ‰∏äÁöÑÂïèÈ°åÊòØÂêÑÁ®ÆÁèæÂØ¶ÁîüÊ¥ªÊáâÁî®‰∏≠ÈÅã‰ΩúËâØÂ•ΩÁöÑËá™‰∏ªË™ûË®Ä‰ª£ÁêÜÁöÑÈóúÈçµ„ÄÇÁÇ∫‰∫ÜÊîπÂñÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú® KGQA ‰∏≠È©ÖÂãïÁöÑË™ûË®Ä‰ª£ÁêÜÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÊé®ÁêÜËÉΩÂäõÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂàÜËß£Â∞çÈΩäÊé®ÁêÜ‰ª£ÁêÜÔºàDARAÔºâÊ°ÜÊû∂„ÄÇDARA ÈÄöÈÅéÈõôÈáçÊ©üÂà∂ÊúâÊïàÂú∞Â∞áÂïèÈ°åËß£ÊûêÁÇ∫Ê≠£ÂºèÊü•Ë©¢ÔºöÈ´òÁ¥öÂà•Ëø≠‰ª£‰ªªÂãôÂàÜËß£Âíå‰ΩéÁ¥öÂà•‰ªªÂãôÂü∫Á§é„ÄÇÈáçË¶ÅÁöÑÊòØÔºåDARA ÂèØ‰ª•‰ΩøÁî®Â∞ëÈáèÁöÑÈ´òÂìÅË≥™Êé®ÁêÜËªåË∑°ÈÄ≤Ë°åÊúâÊïàË®ìÁ∑¥„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂú® LLMÔºà‰æãÂ¶Ç Llama-2-7B„ÄÅMistralÔºâ‰∏äÂæÆË™øÁöÑ DARA Âú®Èõ∂Ê¨°Ë©ï‰º∞ÁöÑ‰∏çÂêåÂü∫Ê∫ñ‰∏äÂÑ™ÊñºÂü∫Êñº‰∏ä‰∏ãÊñá‰∏≠Â≠∏ÁøíÁöÑ‰ª£ÁêÜÔºà‰ΩøÁî® GPT-4ÔºâÂíåÊõø‰ª£ÂæÆË™ø‰ª£ÁêÜÔºåÈÄô‰ΩøÂæóÊ≠§È°ûÊ®°ÂûãÊõ¥ÊòìÊñºÊáâÁî®ÊñºÁèæÂØ¶ÁîüÊ¥ª‰∏≠„ÄÇÊàëÂÄëÈÇÑË°®ÊòéÔºåDARA Áç≤Âæó‰∫ÜËàá KGQA ÁöÑÊúÄÂÖàÈÄ≤ÂàóËàâÂíåÊéíÂêçÊñπÊ≥ïÁõ∏Áï∂ÁöÑÊÄßËÉΩ„ÄÇ

##### **Improving Multi-hop Logical Reasoning in Knowledge Graphs with Context-Aware Query Representation Learning**
2406.07034v1 by Jeonghoon Kim, Heesoo Jung, Hyeju Jang, Hogun Park

Multi-hop logical reasoning on knowledge graphs is a pivotal task in natural
language processing, with numerous approaches aiming to answer First-Order
Logic (FOL) queries. Recent geometry (e.g., box, cone) and probability (e.g.,
beta distribution)-based methodologies have effectively addressed complex FOL
queries. However, a common challenge across these methods lies in determining
accurate geometric bounds or probability parameters for these queries. The
challenge arises because existing methods rely on linear sequential operations
within their computation graphs, overlooking the logical structure of the query
and the relation-induced information that can be gleaned from the relations of
the query, which we call the context of the query. To address the problem, we
propose a model-agnostic methodology that enhances the effectiveness of
existing multi-hop logical reasoning approaches by fully integrating the
context of the FOL query graph. Our approach distinctively discerns (1) the
structural context inherent to the query structure and (2) the relation-induced
context unique to each node in the query graph as delineated in the
corresponding knowledge graph. This dual-context paradigm helps nodes within a
query graph attain refined internal representations throughout the multi-hop
reasoning steps. Through experiments on two datasets, our method consistently
enhances the three multi-hop reasoning foundation models, achieving performance
improvements of up to 19.5%. Our code is available at
https://github.com/kjh9503/caqr.

ÊëòË¶ÅÔºöÂ§öË∑≥ÈÇèËºØÊé®ÁêÜÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÁöÑÈóúÈçµ‰ªªÂãôÔºåË®±Â§öÊñπÊ≥ïÊó®Âú®ÂõûÁ≠î‰∏ÄÈöéÈÇèËºØ (FOL) Êü•Ë©¢„ÄÇÊúÄËøëÁöÑÂπæ‰ΩïÂΩ¢ÁãÄÔºà‰æãÂ¶ÇÔºåÁõíÂ≠ê„ÄÅÂúìÈåêÔºâÂíåÊ©üÁéáÔºà‰æãÂ¶ÇÔºåË≤ùÂ°îÂàÜ‰ΩàÔºâÊñπÊ≥ïÊúâÊïàÂú∞Ëß£Ê±∫‰∫ÜË§áÈõúÁöÑ FOL Êü•Ë©¢„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁöÑÂÖ±ÂêåÊåëÊà∞Âú®ÊñºÔºåÁÇ∫ÈÄô‰∫õÊü•Ë©¢Á¢∫ÂÆöÊ∫ñÁ¢∫ÁöÑÂπæ‰ΩïÁïåÈôêÊàñÊ©üÁéáÂèÉÊï∏„ÄÇÊåëÊà∞Âá∫ÁèæÁöÑÂéüÂõ†Âú®ÊñºÔºåÁèæÊúâÊñπÊ≥ï‰æùË≥¥ÊñºÂÖ∂ÈÅãÁÆóÂúñÂΩ¢‰∏≠ÁöÑÁ∑öÊÄßÈ†ÜÂ∫èÈÅãÁÆóÔºåÂøΩÁï•‰∫ÜÊü•Ë©¢ÁöÑÈÇèËºØÁµêÊßã‰ª•ÂèäÂèØ‰ª•ÂæûÊü•Ë©¢Èóú‰øÇ‰∏≠Êî∂ÈõÜÂà∞ÁöÑÈóú‰øÇË™òÂ∞éË≥áË®äÔºåÊàëÂÄëÁ®±‰πãÁÇ∫Êü•Ë©¢ÁöÑËÉåÊôØ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÂÆåÂÖ®Êï¥Âêà FOL Êü•Ë©¢ÂúñÂΩ¢ÁöÑËÉåÊôØÔºå‰æÜÊèêÂçáÁèæÊúâÂ§öË∑≥ÈÇèËºØÊé®ÁêÜÊñπÊ≥ïÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÁç®ÁâπÂú∞Ëæ®Âà•‰∫Ü (1) Êü•Ë©¢ÁµêÊßãÂõ∫ÊúâÁöÑÁµêÊßãËÉåÊôØÔºå‰ª•Âèä (2) Êü•Ë©¢ÂúñÂΩ¢‰∏≠ÊØèÂÄãÁØÄÈªûÁç®ÊúâÁöÑÈóú‰øÇË™òÂ∞éËÉåÊôØÔºåÂ¶ÇÂ∞çÊáâÁöÑÁü•Ë≠òÂúñÂΩ¢‰∏≠ÊâÄÊèèÁπ™ÁöÑ„ÄÇÈÄôÁ®ÆÈõôÈáçËÉåÊôØÁØÑ‰æãÊúâÂä©ÊñºÊü•Ë©¢ÂúñÂΩ¢‰∏≠ÁöÑÁØÄÈªûÂú®Â§öË∑≥Êé®ÁêÜÊ≠•È©ü‰∏≠Áç≤ÂæóÁ≤æÁ∑ªÁöÑÂÖßÈÉ®Ë°®Á§∫„ÄÇÈÄèÈÅéÂú®ÂÖ©ÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂØ¶È©óÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊåÅÁ∫åÂ¢ûÂº∑‰∏âÁ®ÆÂ§öË∑≥Êé®ÁêÜÂü∫Á§éÊ®°ÂûãÔºåÊïàËÉΩÊèêÂçáÊúÄÈ´òÈÅî 19.5%„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/kjh9503/caqr ÂèñÂæó„ÄÇ

##### **MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension**
2406.06777v2 by Khiem Le, Zhichun Guo, Kaiwen Dong, Xiaobao Huang, Bozhao Nan, Roshni Iyer, Xiangliang Zhang, Olaf Wiest, Wei Wang, Nitesh V. Chawla

Recently, Large Language Models (LLMs) with their strong task-handling
capabilities have shown remarkable advancements across a spectrum of fields,
moving beyond natural language understanding. However, their proficiency within
the chemistry domain remains restricted, especially in solving professional
molecule-related tasks. This challenge is attributed to their inherent
limitations in comprehending molecules using only common textual
representations, i.e., SMILES strings. In this study, we seek to enhance the
ability of LLMs to comprehend molecules by designing and equipping them with a
multi-modal external module, namely MolX. In particular, instead of directly
using a SMILES string to represent a molecule, we utilize specific encoders to
extract fine-grained features from both SMILES string and 2D molecular graph
representations for feeding into an LLM. Moreover, a human-defined molecular
fingerprint is incorporated to leverage its embedded domain knowledge. Then, to
establish an alignment between MolX and the LLM's textual input space, the
whole model in which the LLM is frozen, is pre-trained with a versatile
strategy including a diverse set of tasks. Extensive experimental evaluations
demonstrate that our proposed method only introduces a small number of
trainable parameters while outperforming baselines on various downstream
molecule-related tasks ranging from molecule-to-text translation to
retrosynthesis, with and without fine-tuning the LLM.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºåÂÖ∑ÊúâÂº∫Â§ß‰ªªÂä°Â§ÑÁêÜËÉΩÂäõÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®ÂêÑ‰∏™È¢ÜÂüüÈÉΩÂèñÂæó‰∫ÜÊòæÁùÄËøõÊ≠•ÔºåË∂ÖË∂ä‰∫ÜËá™ÁÑ∂ËØ≠Ë®ÄÁêÜËß£„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨Âú®ÂåñÂ≠¶È¢ÜÂüüÁöÑÁÜüÁªÉÁ®ãÂ∫¶‰ªçÁÑ∂ÂèóÂà∞ÈôêÂà∂ÔºåÂ∞§ÂÖ∂ÊòØÂú®Ëß£ÂÜ≥‰∏ì‰∏öÁöÑÂàÜÂ≠êÁõ∏ÂÖ≥‰ªªÂä°ÊñπÈù¢„ÄÇËøô‰∏ÄÊåëÊàòÂΩíÂõ†‰∫éÂÆÉ‰ª¨Âú®‰ªÖ‰ΩøÁî®Â∏∏ËßÅÊñáÊú¨Ë°®Á§∫ÔºàÂç≥ SMILES Â≠óÁ¨¶‰∏≤ÔºâÁêÜËß£ÂàÜÂ≠êÊñπÈù¢ÁöÑÂõ∫ÊúâÂ±ÄÈôêÊÄß„ÄÇÂú®ËøôÈ°πÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÂØªÊ±ÇÈÄöËøáËÆæËÆ°Âíå‰∏∫ÂÖ∂ÈÖçÂ§á‰∏Ä‰∏™Â§öÊ®°ÊÄÅÂ§ñÈÉ®Ê®°ÂùóÔºàÂç≥ MolXÔºâÊù•Â¢ûÂº∫ LLM ÁêÜËß£ÂàÜÂ≠êÁöÑËÉΩÂäõ„ÄÇÁâπÂà´ÊòØÔºåÊàë‰ª¨Âà©Áî®ÁâπÂÆöÁºñÁ†ÅÂô®‰ªé SMILES Â≠óÁ¨¶‰∏≤Âíå 2D ÂàÜÂ≠êÂõæË°®Á§∫‰∏≠ÊèêÂèñÁªÜÁ≤íÂ∫¶ÁâπÂæÅ‰ª•ËæìÂÖ• LLMÔºåËÄå‰∏çÊòØÁõ¥Êé•‰ΩøÁî® SMILES Â≠óÁ¨¶‰∏≤Êù•Ë°®Á§∫ÂàÜÂ≠ê„ÄÇÊ≠§Â§ñÔºåËøòÁ∫≥ÂÖ•‰∫Ü‰∫∫Á±ªÂÆö‰πâÁöÑÂàÜÂ≠êÊåáÁ∫π‰ª•Âà©Áî®ÂÖ∂ÂµåÂÖ•ÁöÑÈ¢ÜÂüüÁü•ËØÜ„ÄÇÁÑ∂ÂêéÔºå‰∏∫‰∫ÜÂú® MolX Âíå LLM ÁöÑÊñáÊú¨ËæìÂÖ•Á©∫Èó¥‰πãÈó¥Âª∫Á´ã‰∏Ä‰∏™ÂØπÈΩêÔºåÊï¥‰∏™Ê®°ÂûãÔºàÂÖ∂‰∏≠ LLM Ë¢´ÂÜªÁªìÔºâ‰ΩøÁî®ÂåÖÊã¨ÂêÑÁßç‰ªªÂä°Âú®ÂÜÖÁöÑ‰∏Ä‰∏™ÈÄöÁî®Á≠ñÁï•ËøõË°åÈ¢ÑËÆ≠ÁªÉ„ÄÇÂπøÊ≥õÁöÑÂÆûÈ™åËØÑ‰º∞Ë°®ÊòéÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ï‰ªÖÂºïÂÖ•‰∫ÜÂ∞ëÈáèÂèØËÆ≠ÁªÉÂèÇÊï∞ÔºåÂêåÊó∂Âú®ÂêÑÁßç‰∏ãÊ∏∏ÂàÜÂ≠êÁõ∏ÂÖ≥‰ªªÂä°ÔºàÂåÖÊã¨ÂàÜÂ≠êÂà∞ÊñáÊú¨ÁøªËØëÂà∞ÈÄÜÂêàÊàêÔºâ‰∏≠‰ºò‰∫éÂü∫Á∫øÔºåÊó†ËÆ∫ÊòØÂê¶ÂØπ LLM ËøõË°åÂæÆË∞É„ÄÇ</paragraph>

##### **The Curse of Popularity: Popular Entities have Catastrophic Side Effects when Deleting Knowledge from Language Models**
2406.06032v1 by Ryosuke Takahashi, Go Kamoda, Benjamin Heinzerling, Keisuke Sakaguchi, Kentaro Inui

Language models (LMs) encode world knowledge in their internal parameters
through training. However, LMs may learn personal and confidential information
from the training data, leading to privacy concerns such as data leakage.
Therefore, research on knowledge deletion from LMs is essential. This study
focuses on the knowledge stored in LMs and analyzes the relationship between
the side effects of knowledge deletion and the entities related to the
knowledge. Our findings reveal that deleting knowledge related to popular
entities can have catastrophic side effects. Furthermore, this research is the
first to analyze knowledge deletion in models trained on synthetic knowledge
graphs, indicating a new direction for controlled experiments.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°Âûã (LM) ÈÄèÈÅéË®ìÁ∑¥Â∞á‰∏ñÁïåÁü•Ë≠òÁ∑®Á¢ºÂú®ÂÖ∂ÂÖßÈÉ®ÂèÉÊï∏‰∏≠„ÄÇÁÑ∂ËÄåÔºåLM ÂèØËÉΩÊúÉÂæûË®ìÁ∑¥Ë≥áÊñô‰∏≠Â≠∏ÁøíÂà∞ÂÄã‰∫∫ÂíåÊ©üÂØÜË≥áË®äÔºåÂ∞éËá¥Ë≥áÊñôÂ§ñÊ¥©Á≠âÈö±ÁßÅÂïèÈ°å„ÄÇÂõ†Ê≠§ÔºåÁ†îÁ©∂Âæû LM ‰∏≠Âà™Èô§Áü•Ë≠òËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ËëóÈáçÊñºÂÑ≤Â≠òÂú® LM ‰∏≠ÁöÑÁü•Ë≠òÔºå‰∏¶ÂàÜÊûêÁü•Ë≠òÂà™Èô§ÁöÑÂâØ‰ΩúÁî®ËàáËàáÁü•Ë≠òÁõ∏ÈóúÁöÑÂØ¶È´î‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫ÔºåÂà™Èô§ËàáÁÜ±ÈñÄÂØ¶È´îÁõ∏ÈóúÁöÑÁü•Ë≠òÂèØËÉΩÊúÉÈÄ†ÊàêÁÅΩÈõ£ÊÄßÁöÑÂâØ‰ΩúÁî®„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂È¶ñÊ¨°ÂàÜÊûêÂú®ÂêàÊàêÁü•Ë≠òÂúñË≠ú‰∏äË®ìÁ∑¥ÁöÑÊ®°Âûã‰∏≠ÁöÑÁü•Ë≠òÂà™Èô§ÔºåÊåáÂá∫ÂèóÊéßÂØ¶È©óÁöÑÊñ∞ÊñπÂêë„ÄÇ

##### **HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs**
2406.06027v1 by Pranoy Panda, Ankush Agarwal, Chaitanya Devaguptapu, Manohar Kaul, Prathosh A P

Given unstructured text, Large Language Models (LLMs) are adept at answering
simple (single-hop) questions. However, as the complexity of the questions
increase, the performance of LLMs degrade. We believe this is due to the
overhead associated with understanding the complex question followed by
filtering and aggregating unstructured information in the raw text. Recent
methods try to reduce this burden by integrating structured knowledge triples
into the raw text, aiming to provide a structured overview that simplifies
information processing. However, this simplistic approach is query-agnostic and
the extracted facts are ambiguous as they lack context. To address these
drawbacks and to enable LLMs to answer complex (multi-hop) questions with ease,
we propose to use a knowledge graph (KG) that is context-aware and is distilled
to contain query-relevant information. The use of our compressed distilled KG
as input to the LLM results in our method utilizing up to $67\%$ fewer tokens
to represent the query relevant information present in the supporting
documents, compared to the state-of-the-art (SoTA) method. Our experiments show
consistent improvements over the SoTA across several metrics (EM, F1,
BERTScore, and Human Eval) on two popular benchmark datasets (HotpotQA and
MuSiQue).

ÊëòË¶ÅÔºöÁµ¶ÂÆöÈùûÁµêÊßãÂåñÊñáÊú¨ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊìÖÈï∑ÂõûÁ≠îÁ∞°ÂñÆÔºàÂñÆË∑≥ÔºâÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÂïèÈ°åÁöÑË§áÈõúÊÄßÂ¢ûÂä†ÔºåLLM ÁöÑÊïàËÉΩÊúÉ‰∏ãÈôç„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄôÊòØÂõ†ÁÇ∫ÁêÜËß£Ë§áÈõúÂïèÈ°åÊâÄ‰º¥Èö®ÁöÑÈñãÈä∑ÔºåÊé•ËëóÂú®ÂéüÂßãÊñáÊú¨‰∏≠ÈÅéÊøæÂíåÂΩôÁ∏ΩÈùûÁµêÊßãÂåñË≥áË®ä„ÄÇÊúÄËøëÁöÑÊñπÊ≥ïÂòóË©¶ÈÄèÈÅéÂ∞áÁµêÊßãÂåñÁü•Ë≠ò‰∏âÂÖÉÁµÑÊï¥ÂêàÂà∞ÂéüÂßãÊñáÊú¨‰∏≠‰æÜÊ∏õËºïÈÄôÂÄãË≤†ÊìîÔºåÁõÆÁöÑÊòØÊèê‰æõ‰∏ÄÂÄãÁ∞°ÂåñË≥áË®äËôïÁêÜÁöÑÁµêÊßãÂåñÊ¶ÇËßÄ„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÁ∞°ÂåñÁöÑÊñπÂºèËàáÊü•Ë©¢ÁÑ°ÈóúÔºåËÄå‰∏îÊèêÂèñÁöÑ‰∫ãÂØ¶Ê®°Á®úÂÖ©ÂèØÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁº∫‰πèËÉåÊôØ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÁº∫ÈªûÔºå‰∏¶‰Ωø LLM ËÉΩÂ§†ËºïÈ¨ÜÂõûÁ≠îË§áÈõúÔºàÂ§öË∑≥ÔºâÂïèÈ°åÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®‰∏ÄÂÄãËàáËÉåÊôØÁõ∏Èóú‰∏îÁ∂ìÈÅéÊèêÁÖâ‰ª•ÂåÖÂê´ËàáÊü•Ë©¢Áõ∏ÈóúË≥áË®äÁöÑÁü•Ë≠òÂúñË≠ú (KG)„ÄÇÂ∞áÊàëÂÄëÂ£ìÁ∏ÆÊèêÁÖâÁöÑ KG Áî®‰Ωú LLM ÁöÑËº∏ÂÖ•Ôºå‰ΩøÂæóÊàëÂÄëÁöÑÊ®°Âûã‰ΩøÁî®ÊØîÊúÄÂÖàÈÄ≤ (SoTA) ÊñπÊ≥ïÊ∏õÂ∞ëÂ§öÈÅî $67\%$ ÁöÑÊ®ôË®ò‰æÜË°®Á§∫ÊîØÊè¥Êñá‰ª∂‰∏≠ÁöÑËàáÊü•Ë©¢Áõ∏ÈóúÁöÑË≥áË®ä„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÂú®ÂÖ©ÂÄãÊµÅË°åÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜÔºàHotpotQA Âíå MuSiQueÔºâ‰∏äÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®Â§öÈ†ÖÊåáÊ®ôÔºàEM„ÄÅF1„ÄÅBERTScore Âíå‰∫∫Â∑•Ë©ï‰º∞Ôºâ‰∏≠ÈÉΩÊØî SoTA ÊúâÈ°ØËëóÁöÑÊîπÂñÑ„ÄÇ

##### **Generalist Multimodal AI: A Review of Architectures, Challenges and Opportunities**
2406.05496v1 by Sai Munikoti, Ian Stewart, Sameera Horawalavithana, Henry Kvinge, Tegan Emerson, Sandra E Thompson, Karl Pazdernik

Multimodal models are expected to be a critical component to future advances
in artificial intelligence. This field is starting to grow rapidly with a surge
of new design elements motivated by the success of foundation models in natural
language processing (NLP) and vision. It is widely hoped that further extending
the foundation models to multiple modalities (e.g., text, image, video, sensor,
time series, graph, etc.) will ultimately lead to generalist multimodal models,
i.e. one model across different data modalities and tasks. However, there is
little research that systematically analyzes recent multimodal models
(particularly the ones that work beyond text and vision) with respect to the
underling architecture proposed. Therefore, this work provides a fresh
perspective on generalist multimodal models (GMMs) via a novel architecture and
training configuration specific taxonomy. This includes factors such as
Unifiability, Modularity, and Adaptability that are pertinent and essential to
the wide adoption and application of GMMs. The review further highlights key
challenges and prospects for the field and guide the researchers into the new
advancements.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÊ®°ÂûãÈ¢ÑËÆ°Â∞ÜÊàê‰∏∫‰∫∫Â∑•Êô∫ËÉΩÊú™Êù•ÂèëÂ±ïÁöÑÂÖ≥ÈîÆÁªÑÊàêÈÉ®ÂàÜ„ÄÇÈöèÁùÄËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ (NLP) ÂíåËßÜËßâÈ¢ÜÂüüÁöÑÂ∫ïÂ±ÇÊ®°ÂûãÂèñÂæóÊàêÂäüÔºåËøô‰∏ÄÈ¢ÜÂüüÂºÄÂßãËøÖÈÄüÂèëÂ±ïÔºåÂπ∂Ê∂åÁé∞Âá∫Â§ßÈáèÂèóÂÖ∂ÂêØÂèëÁöÑÊñ∞ËÆæËÆ°ÂÖÉÁ¥†„ÄÇ‰∫∫‰ª¨ÊôÆÈÅçÂ∏åÊúõÔºåÂ∞ÜÂ∫ïÂ±ÇÊ®°ÂûãËøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞Â§öÁßçÊ®°ÊÄÅÔºà‰æãÂ¶ÇÔºåÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅËßÜÈ¢ë„ÄÅ‰º†ÊÑüÂô®„ÄÅÊó∂Èó¥Â∫èÂàó„ÄÅÂõæÂΩ¢Á≠âÔºâÊúÄÁªàÂ∞Ü‰∫ßÁîüÈÄöÁî®Â§öÊ®°ÊÄÅÊ®°ÂûãÔºåÂç≥‰∏Ä‰∏™Ë∑®‰∏çÂêåÊï∞ÊçÆÊ®°ÊÄÅÂíå‰ªªÂä°ÁöÑÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÂæàÂ∞ëÊúâÁ†îÁ©∂Á≥ªÁªüÂú∞ÂàÜÊûêÊúÄËøëÁöÑÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºàÁâπÂà´ÊòØÈÇ£‰∫õÂú®ÊñáÊú¨ÂíåËßÜËßâ‰πãÂ§ñÂ∑•‰ΩúÁöÑÊ®°ÂûãÔºâ‰∏éÂÖ∂ÊèêÂá∫ÁöÑÂ∫ïÂ±ÇÊû∂ÊûÑ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂõ†Ê≠§ÔºåËøôÈ°πÂ∑•‰ΩúÈÄöËøá‰∏ÄÁßçÊñ∞È¢ñÁöÑÊû∂ÊûÑÂíåËÆ≠ÁªÉÈÖçÁΩÆÁâπÂÆöÂàÜÁ±ªÊ≥ïÔºå‰∏∫ÈÄöÁî®Â§öÊ®°ÊÄÅÊ®°Âûã (GMM) Êèê‰æõ‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑËßÜËßí„ÄÇËøôÂåÖÊã¨Áªü‰∏ÄÊÄß„ÄÅÊ®°ÂùóÂåñÂíåÈÄÇÂ∫îÊÄßÁ≠âÂõ†Á¥†ÔºåËøô‰∫õÂõ†Á¥†‰∏é GMM ÁöÑÂπøÊ≥õÈááÁî®ÂíåÂ∫îÁî®ÂØÜÂàáÁõ∏ÂÖ≥‰∏îËá≥ÂÖ≥ÈáçË¶Å„ÄÇËØ•ÁªºËø∞Ëøõ‰∏ÄÊ≠•Âº∫Ë∞É‰∫ÜËØ•È¢ÜÂüüÁöÑÂÖ≥ÈîÆÊåëÊàòÂíåÂâçÊôØÔºåÂπ∂ÊåáÂØºÁ†îÁ©∂‰∫∫Âëò‰∫ÜËß£Êñ∞ÁöÑËøõÂ±ï„ÄÇ

##### **TLEX: An Efficient Method for Extracting Exact Timelines from TimeML Temporal Graphs**
2406.05265v1 by Mustafa Ocal, Ning Xie, Mark Finlayson

A timeline provides a total ordering of events and times, and is useful for a
number of natural language understanding tasks. However, qualitative temporal
graphs that can be derived directly from text -- such as TimeML annotations --
usually explicitly reveal only partial orderings of events and times. In this
work, we apply prior work on solving point algebra problems to the task of
extracting timelines from TimeML annotated texts, and develop an exact,
end-to-end solution which we call TLEX (TimeLine EXtraction). TLEX transforms
TimeML annotations into a collection of timelines arranged in a
trunk-and-branch structure. Like what has been done in prior work, TLEX checks
the consistency of the temporal graph and solves it; however, it adds two novel
functionalities. First, it identifies specific relations involved in an
inconsistency (which could then be manually corrected) and, second, TLEX
performs a novel identification of sections of the timelines that have
indeterminate order, information critical for downstream tasks such as aligning
events from different timelines. We provide detailed descriptions and analysis
of the algorithmic components in TLEX, and conduct experimental evaluations by
applying TLEX to 385 TimeML annotated texts from four corpora. We show that 123
of the texts are inconsistent, 181 of them have more than one ``real world'' or
main timeline, and there are 2,541 indeterminate sections across all four
corpora. A sampling evaluation showed that TLEX is 98--100% accurate with 95%
confidence along five dimensions: the ordering of time-points, the number of
main timelines, the placement of time-points on main versus subordinate
timelines, the connecting point of branch timelines, and the location of the
indeterminate sections. We provide a reference implementation of TLEX, the
extracted timelines for all texts, and the manual corrections of the
inconsistent texts.

ÊëòË¶ÅÔºöÊôÇÈñìËª∏Êèê‰æõ‰∫ã‰ª∂ÂíåÊôÇÈñìÁöÑÁ∏ΩÈ´îÈ†ÜÂ∫èÔºå‰∏¶ÂèØÁî®ÊñºË®±Â§öËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÂèØÁõ¥Êé•ÂæûÊñáÊú¨‰∏≠Ë°çÁîüÁöÑÂÆöÊÄßÊôÇÈñìÂúñË°®Ôºà‰æãÂ¶Ç TimeML Ê®ôË®ªÔºâÈÄöÂ∏∏Âè™ÊòéÁ¢∫Êè≠Á§∫‰∫ã‰ª∂ÂíåÊôÇÈñìÁöÑÈÉ®ÂàÜÈ†ÜÂ∫è„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞áÂÖàÂâçËß£Ê±∫Èªû‰ª£Êï∏ÂïèÈ°åÁöÑÂ∑•‰ΩúÊáâÁî®ÊñºÂæû TimeML Ê®ôË®ªÊñáÊú¨‰∏≠ÊèêÂèñÊôÇÈñìËª∏ÁöÑ‰ªªÂãôÔºå‰∏¶ÈñãÁôº‰∫Ü‰∏ÄÂÄãÁ≤æÁ¢∫ÁöÑÁ´ØÂà∞Á´ØËß£Ê±∫ÊñπÊ°àÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ TLEXÔºàÊôÇÈñìÁ∑öÊèêÂèñÔºâ„ÄÇTLEX Â∞á TimeML Ê®ôË®ªËΩâÊèõÁÇ∫‰∏ÄÁ≥ªÂàóÊôÇÈñìËª∏Ôºå‰∏¶‰ª•‰∏ªÂππÁµêÊßãÊéíÂàó„ÄÇËàáÂÖàÂâçÁöÑÂ∑•‰Ωú‰∏ÄÊ®£ÔºåTLEX Ê™¢Êü•ÊôÇÈñìÂúñË°®ÁöÑËá™Ê¥ΩÊÄß‰∏¶Ëß£Ê±∫ÂÆÉÔºõÁÑ∂ËÄåÔºåÂÆÉÂ¢ûÂä†‰∫ÜÂÖ©ÂÄãÊñ∞Á©éÁöÑÂäüËÉΩ„ÄÇÈ¶ñÂÖàÔºåÂÆÉË≠òÂà•Âá∫‰∏ç‰∏ÄËá¥‰∏≠Ê∂âÂèäÁöÑÂÖ∑È´îÈóú‰øÇÔºàÁÑ∂ÂæåÂèØ‰ª•ÊâãÂãïÊõ¥Ê≠£ÔºâÔºåÂÖ∂Ê¨°ÔºåTLEX Â∞çÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÈ†ÜÂ∫èÁöÑÊôÇÈñìËª∏ÈÉ®ÂàÜÈÄ≤Ë°å‰∫ÜÊñ∞ÁöÑË≠òÂà•ÔºåÈÄô‰∫õ‰ø°ÊÅØÂ∞çÊñº‰∏ãÊ∏∏‰ªªÂãôÔºà‰æãÂ¶ÇÂ∞çÈΩä‰æÜËá™‰∏çÂêåÊôÇÈñìËª∏ÁöÑ‰∫ã‰ª∂ÔºâËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü TLEX ‰∏≠ÊºîÁÆóÊ≥ïÁµÑÊàêÁöÑË©≥Á¥∞ÊèèËø∞ÂíåÂàÜÊûêÔºå‰∏¶ÈÄöÈÅéÂ∞á TLEX ÊáâÁî®Êñº‰æÜËá™ÂõõÂÄãË™ûÊñôÂ∫´ÁöÑ 385 ÂÄã TimeML Ê®ôË®ªÊñáÊú¨ÈÄ≤Ë°åÂØ¶È©óË©ï‰º∞„ÄÇÊàëÂÄëË°®Êòé 123 ÂÄãÊñáÊú¨ÊòØ‰∏ç‰∏ÄËá¥ÁöÑÔºåÂÖ∂‰∏≠ 181 ÂÄãÊúâÂ§öÂÄã„ÄåÁúüÂØ¶‰∏ñÁïå„ÄçÊàñ‰∏ªÊôÇÈñìËª∏Ôºå‰∏¶‰∏îÂú®ÊâÄÊúâÂõõÂÄãË™ûÊñôÂ∫´‰∏≠ÂÖ±Êúâ 2,541 ÂÄã‰∏çÁ¢∫ÂÆöÈÉ®ÂàÜ„ÄÇÊäΩÊ®£Ë©ï‰º∞Ë°®ÊòéÔºåTLEX Âú®‰∫îÂÄãÁ∂≠Â∫¶‰∏äÂÖ∑Êúâ 98-100% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÁΩÆ‰ø°Â∫¶ÁÇ∫ 95%ÔºöÊôÇÈñìÈªûÁöÑÈ†ÜÂ∫è„ÄÅ‰∏ªÊôÇÈñìËª∏ÁöÑÊï∏Èáè„ÄÅÊôÇÈñìÈªûÂú®‰∏ªÊôÇÈñìËª∏ËàáÂæûÂ±¨ÊôÇÈñìËª∏‰∏äÁöÑ‰ΩçÁΩÆ„ÄÅÂàÜÊîØÊôÇÈñìËª∏ÁöÑÈÄ£Êé•Èªû‰ª•Âèä‰∏çÁ¢∫ÂÆöÈÉ®ÂàÜÁöÑ‰ΩçÁΩÆ„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü TLEX ÁöÑÂèÉËÄÉÂØ¶Áèæ„ÄÅÊâÄÊúâÊñáÊú¨ÁöÑÊèêÂèñÊôÇÈñìËª∏‰ª•Âèä‰∏ç‰∏ÄËá¥ÊñáÊú¨ÁöÑÊâãÂãïÊõ¥Ê≠£„ÄÇ

##### **LinkQ: An LLM-Assisted Visual Interface for Knowledge Graph Question-Answering**
2406.06621v1 by Harry Li, Gabriel Appleby, Ashley Suh

We present LinkQ, a system that leverages a large language model (LLM) to
facilitate knowledge graph (KG) query construction through natural language
question-answering. Traditional approaches often require detailed knowledge of
complex graph querying languages, limiting the ability for users -- even
experts -- to acquire valuable insights from KG data. LinkQ simplifies this
process by first interpreting a user's question, then converting it into a
well-formed KG query. By using the LLM to construct a query instead of directly
answering the user's question, LinkQ guards against the LLM hallucinating or
generating false, erroneous information. By integrating an LLM into LinkQ,
users are able to conduct both exploratory and confirmatory data analysis, with
the LLM helping to iteratively refine open-ended questions into precise ones.
To demonstrate the efficacy of LinkQ, we conducted a qualitative study with
five KG practitioners and distill their feedback. Our results indicate that
practitioners find LinkQ effective for KG question-answering, and desire future
LLM-assisted systems for the exploratory analysis of graph databases.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫ LinkQÔºåÈÄôÊòØ‰∏ÄÂÄãÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄèÈÅéËá™ÁÑ∂Ë™ûË®ÄÂïèÁ≠î‰æÜ‰øÉÈÄ≤Áü•Ë≠òÂúñË≠ú (KG) Êü•Ë©¢Âª∫ÊßãÁöÑÁ≥ªÁµ±„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ∞çË§áÈõúÁöÑÂúñÂΩ¢Êü•Ë©¢Ë™ûË®ÄÊúâË©≥Á¥∞ÁöÑ‰∫ÜËß£ÔºåÈÄôÊúÉÈôêÂà∂‰ΩøÁî®ËÄÖÔºàÁîöËá≥ÊòØÂ∞àÂÆ∂ÔºâÂæû KG Ë≥áÊñô‰∏≠Áç≤ÂèñÊúâÂÉπÂÄºË¶ãËß£ÁöÑËÉΩÂäõ„ÄÇLinkQ ÈÄèÈÅéÂÖàË©ÆÈáã‰ΩøÁî®ËÄÖÁöÑÂïèÈ°åÔºåÁÑ∂ÂæåÂ∞áÂÖ∂ËΩâÊèõÊàêÊ†ºÂºèËâØÂ•ΩÁöÑ KG Êü•Ë©¢Ôºå‰æÜÁ∞°ÂåñÈÄôÂÄãÈÅéÁ®ã„ÄÇÈÄèÈÅé‰ΩøÁî® LLM ‰æÜÂª∫ÊßãÊü•Ë©¢ÔºåËÄå‰∏çÊòØÁõ¥Êé•ÂõûÁ≠î‰ΩøÁî®ËÄÖÁöÑÂïèÈ°åÔºåLinkQ ÂèØ‰ª•Èò≤Ê≠¢ LLM Âá∫ÁèæÂπªË¶∫ÊàñÁî¢ÁîüÈåØË™§„ÄÅ‰∏çÂØ¶ÁöÑË≥áË®ä„ÄÇÈÄèÈÅéÂ∞á LLM Êï¥ÂêàÂà∞ LinkQ ‰∏≠Ôºå‰ΩøÁî®ËÄÖÂèØ‰ª•ÈÄ≤Ë°åÊé¢Á¥¢ÊÄßÂíåÈ©óË≠âÊÄßË≥áÊñôÂàÜÊûêÔºåËÄå LLM ÂâáÊúâÂä©ÊñºÂèçË¶ÜÂ∞áÈñãÊîæÂºèÂïèÈ°åÁ≤æÁÖâÊàêÁ≤æÁ¢∫ÁöÑÂïèÈ°å„ÄÇÁÇ∫‰∫ÜË≠âÊòé LinkQ ÁöÑÊïàËÉΩÔºåÊàëÂÄëËàá‰∫î‰Ωç KG ÂØ¶ÂãôÂ∑•‰ΩúËÄÖÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂÆöÊÄßÁ†îÁ©∂Ôºå‰∏¶Êï¥ÁêÜ‰ªñÂÄëÁöÑÂõûÈ•ã„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÂØ¶ÂãôÂ∑•‰ΩúËÄÖË™çÁÇ∫ LinkQ Â∞çÊñº KG ÂïèÁ≠îÂæàÊúâÁî®Ôºå‰∏¶Â∏åÊúõÊú™‰æÜÊúâ LLM ËºîÂä©ÁöÑÁ≥ªÁµ±ÔºåÁî®ÊñºÂúñÂΩ¢Ë≥áÊñôÂ∫´ÁöÑÊé¢Á¥¢ÊÄßÂàÜÊûê„ÄÇ</paragraph>

##### **Compositional Generalization with Grounded Language Models**
2406.04989v1 by Sondre Wold, √âtienne Simon, Lucas Georges Gabriel Charpentier, Egor V. Kostylev, Erik Velldal, Lilja √òvrelid

Grounded language models use external sources of information, such as
knowledge graphs, to meet some of the general challenges associated with
pre-training. By extending previous work on compositional generalization in
semantic parsing, we allow for a controlled evaluation of the degree to which
these models learn and generalize from patterns in knowledge graphs. We develop
a procedure for generating natural language questions paired with knowledge
graphs that targets different aspects of compositionality and further avoids
grounding the language models in information already encoded implicitly in
their weights. We evaluate existing methods for combining language models with
knowledge graphs and find them to struggle with generalization to sequences of
unseen lengths and to novel combinations of seen base components. While our
experimental results provide some insight into the expressive power of these
models, we hope our work and released datasets motivate future research on how
to better combine language models with structured knowledge representations.

ÊëòË¶ÅÔºöÊé•Âú∞Ë™ûË®ÄÊ®°Âûã‰ΩøÁî®Â§ñÈÉ®Ë≥áË®ä‰æÜÊ∫êÔºå‰æãÂ¶ÇÁü•Ë≠òÂúñË≠úÔºå‰ª•Âõ†ÊáâËàáÈ†êË®ìÁ∑¥Áõ∏ÈóúÁöÑ‰∏Ä‰∫õ‰∏ÄËà¨ÊåëÊà∞„ÄÇËóâÁî±Êì¥Â±ïË™ûÊÑèÂâñÊûê‰∏≠ÁµÑÂêàÊ¶ÇÊã¨ÁöÑÂÖàÂâçÂ∑•‰ΩúÔºåÊàëÂÄëÂÖÅË®±Â∞çÈÄô‰∫õÊ®°ÂûãÂæûÁü•Ë≠òÂúñË≠ú‰∏≠ÁöÑÊ®°ÂºèÂ≠∏ÁøíÂíåÊ¶ÇÊã¨ÁöÑÁ®ãÂ∫¶ÈÄ≤Ë°åÂèóÊéßË©ï‰º∞„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÁ®ãÂ∫èÔºåÁî®ÊñºÁî¢ÁîüËàáÁü•Ë≠òÂúñË≠úÈÖçÂ∞çÁöÑËá™ÁÑ∂Ë™ûË®ÄÂïèÈ°åÔºåÈáùÂ∞çÁµÑÂêàÊÄßÁöÑ‰∏çÂêåÈù¢ÂêëÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÈÅøÂÖçÂ∞áË™ûË®ÄÊ®°ÂûãÊé•Âú∞Âà∞ÂÖ∂Ê¨äÈáç‰∏≠Â∑≤Èö±Âê´Á∑®Á¢ºÁöÑË≥áË®ä„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂ∞áË™ûË®ÄÊ®°ÂûãËàáÁü•Ë≠òÂúñË≠úÁµêÂêàÁöÑÁèæÊúâÊñπÊ≥ïÔºåÁôºÁèæÂÆÉÂÄëÈõ£‰ª•Ê¶ÇÊã¨Âà∞Èï∑Â∫¶Êú™Ë¶ãÁöÑÂ∫èÂàóÂíåÂ∑≤Ë¶ãÂü∫Á§éÁµÑ‰ª∂ÁöÑÊñ∞ÁµÑÂêà„ÄÇÈõñÁÑ∂ÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÊèê‰æõ‰∫Ü‰∏Ä‰∫õË¶ãËß£ÔºåË™™Êòé‰∫ÜÈÄô‰∫õÊ®°ÂûãÁöÑË°®ÈÅîËÉΩÂäõÔºå‰ΩÜÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÂ∑•‰ΩúÂíåÁôºÂ∏ÉÁöÑË≥áÊñôÈõÜËÉΩÊøÄÂãµÊú™‰æÜÁ†îÁ©∂Â¶Ç‰ΩïÂ∞áË™ûË®ÄÊ®°ÂûãËàáÁµêÊßãÂåñÁü•Ë≠òË°®ÂæµÊõ¥Â•ΩÂú∞ÁµêÂêà„ÄÇ

##### **CRAG -- Comprehensive RAG Benchmark**
2406.04744v1 by Xiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla, Xiangsen Chen, Sajal Choudhary, Rongze Daniel Gui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong, Brian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan, Chenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang, Lei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah, Rakesh Wanga, Anuj Kumar, Wen-tau Yih, Xin Luna Dong

Retrieval-Augmented Generation (RAG) has recently emerged as a promising
solution to alleviate Large Language Model (LLM)'s deficiency in lack of
knowledge. Existing RAG datasets, however, do not adequately represent the
diverse and dynamic nature of real-world Question Answering (QA) tasks. To
bridge this gap, we introduce the Comprehensive RAG Benchmark (CRAG), a factual
question answering benchmark of 4,409 question-answer pairs and mock APIs to
simulate web and Knowledge Graph (KG) search. CRAG is designed to encapsulate a
diverse array of questions across five domains and eight question categories,
reflecting varied entity popularity from popular to long-tail, and temporal
dynamisms ranging from years to seconds. Our evaluation on this benchmark
highlights the gap to fully trustworthy QA. Whereas most advanced LLMs achieve
<=34% accuracy on CRAG, adding RAG in a straightforward manner improves the
accuracy only to 44%. State-of-the-art industry RAG solutions only answer 63%
questions without any hallucination. CRAG also reveals much lower accuracy in
answering questions regarding facts with higher dynamism, lower popularity, or
higher complexity, suggesting future research directions. The CRAG benchmark
laid the groundwork for a KDD Cup 2024 challenge, attracting thousands of
participants and submissions within the first 50 days of the competition. We
commit to maintaining CRAG to serve research communities in advancing RAG
solutions and general QA solutions.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊúÄËøë‰ΩúÁÇ∫‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÂá∫ÁèæÔºå‰ª•Á∑©Ëß£Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Áü•Ë≠òÁº∫‰πèÊñπÈù¢ÁöÑÁº∫Èô∑„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ RAG Ë≥áÊñôÈõÜ‰∏¶‰∏çËÉΩÂÖÖÂàÜ‰ª£Ë°®ÁèæÂØ¶‰∏ñÁïåÂïèÁ≠î (QA) ‰ªªÂãôÁöÑÂ§öÊ®£ÊÄßÂíåÂãïÊÖãÊÄß„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁ∂úÂêà RAG Âü∫Ê∫ñ (CRAG)ÔºåÈÄôÊòØ‰∏ÄÂÄãÁî± 4,409 ÂÄãÂïèÁ≠îÂ∞çÂíåÊ®°Êì¨Á∂≤Ë∑ØÂíåÁü•Ë≠òÂúñË≠ú (KG) ÊêúÂ∞ãÁöÑÊ®°Êì¨ API ÁµÑÊàêÁöÑÂü∫Êñº‰∫ãÂØ¶ÁöÑÂïèÁ≠îÂü∫Ê∫ñ„ÄÇCRAG Ë¢´Ë®≠Ë®àÊàêÂõäÊã¨Ë∑®Ë∂ä‰∫îÂÄãÈ†òÂüüÂíåÂÖ´ÂÄãÂïèÈ°åÈ°ûÂà•ÁöÑÂêÑÁ®ÆÂïèÈ°åÔºåÂèçÊò†‰∫ÜÂæûÊµÅË°åÂà∞Èï∑Â∞æÁöÑÂêÑÁ®ÆÂØ¶È´îÊµÅË°åÂ∫¶Ôºå‰ª•ÂèäÂæûÂπ¥Âà∞ÁßíÁöÑÊôÇÈñìÂãïÊÖã„ÄÇÊàëÂÄëÂ∞çÊ≠§Âü∫Ê∫ñÁöÑË©ï‰º∞Á™ÅÂá∫‰∫ÜÂÆåÂÖ®ÂÄºÂæó‰ø°Ë≥¥ÁöÑ QA ÁöÑÂ∑ÆË∑ù„ÄÇÂÑòÁÆ°Â§ßÂ§öÊï∏ÂÖàÈÄ≤ÁöÑ LLM Âú® CRAG ‰∏äÁöÑÊ∫ñÁ¢∫Áéá‰ΩéÊñºÁ≠âÊñº 34%Ôºå‰ΩÜ‰ª•‰∏ÄÁ®ÆÁõ¥Êé•ÁöÑÊñπÂºèÊ∑ªÂä† RAG ÂÉÖÂ∞áÊ∫ñÁ¢∫ÁéáÊèêÈ´òÂà∞ 44%„ÄÇÊúÄÂÖàÈÄ≤ÁöÑÁî¢Ê•≠ RAG Ëß£Ê±∫ÊñπÊ°àÂÉÖÂõûÁ≠î 63% ÁöÑÂïèÈ°åÔºå‰∏îÊ≤íÊúâ‰ªª‰ΩïÂπªË¶∫„ÄÇCRAG ÈÇÑÈ°ØÁ§∫Âú®ÂõûÁ≠îÂÖ∑ÊúâÊõ¥È´òÂãïÊÖãÊÄß„ÄÅËºÉ‰ΩéÊµÅË°åÂ∫¶ÊàñÊõ¥È´òË§áÈõúÊÄßÁöÑ‰∫ãÂØ¶Áõ∏ÈóúÂïèÈ°åÊôÇÊ∫ñÁ¢∫ÁéáË¶Å‰ΩéÂæóÂ§öÔºåÈÄôË°®Êòé‰∫ÜÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇCRAG Âü∫Ê∫ñÁÇ∫ 2024 Âπ¥ KDD ÊùØÊåëÊà∞Ë≥ΩÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåÂú®ÊØîË≥ΩÈñãÂßãÂæåÁöÑÂâç 50 Â§©ÂÖßÂê∏Âºï‰∫ÜÊï∏ÂçÉÂêçÂèÉËàáËÄÖÂíåÊèê‰∫§„ÄÇÊàëÂÄëÊâøË´æÁ∂≠Ë≠∑ CRAGÔºå‰ª•ÊúçÂãôÊñºÁ†îÁ©∂Á§æÁæ§ÔºåÊé®ÈÄ≤ RAG Ëß£Ê±∫ÊñπÊ°àÂíå‰∏ÄËà¨ QA Ëß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

ÊëòË¶ÅÔºöËá™Ê≥®ÊÑèÂäõÊ©üÂà∂Â∑≤Ë¢´Êé°Áî®ÊñºÂ§öÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑË®äÊÅØÂÇ≥ÈÅûÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MPNN)Ôºà‰æãÂ¶Ç GATÔºâÔºåÂÆÉÂèØ‰ª•Ëá™ÈÅ©ÊáâÂú∞ÊéßÂà∂Ê≤øËëóÂ∫ïÂ±§ÂúñÂΩ¢ÈÇäÁ∑£ÊµÅÂãïÁöÑË≥áË®äÈáè„ÄÇÈÄôÁ®ÆÊ≥®ÊÑèÂäõÁöÑ‰ΩøÁî®‰ΩøÂæóÊ≠§È°ûÊ®°ÂûãÊàêÁÇ∫ÂèØËß£Èáã AI (XAI) Á†îÁ©∂ÁöÑÂü∫Á∑öÔºåÂõ†ÁÇ∫ÈÄèÈÅéÊ≥®ÊÑèÂäõÁöÑË©ÆÈáãÂ∑≤Âú®ÂêÑÁ®ÆÈ†òÂüüÔºà‰æãÂ¶ÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂíåÈõªËÖ¶Ë¶ñË¶∫Ôºâ‰∏≠ÊôÆÂèä„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂ÈÄöÂ∏∏‰ΩøÁî®Â§©ÁúüÁöÑË®àÁÆóÊñπÊ≥ïÂæûÊ≥®ÊÑèÂäõ‰∏≠Êé®Â∞éÂá∫Ê≠∏Âõ†ÂàÜÊï∏Ôºå‰∏¶‰∏îÊ≤íÊúâËÄÉÊÖÆÂà∞ÈÇäÁ∑£Ê≠∏Âõ†ÁöÑÁ≤æÁ¢∫‰∏î‰ªîÁ¥∞ÁöÑË®àÁÆó„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊó®Âú®Â°´Ë£úÊ≥®ÊÑèÂäõÂïüÁî® MPNN ÁöÑÂª£Ê≥õ‰ΩøÁî®ËàáÂÆÉÂÄëÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÁöÑÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÈÄôÂÄã‰∏ªÈ°åÂ∑≤Âú®ÂÖ∂‰ªñÈ†òÂüüÁ©çÊ•µÁ†îÁ©∂„ÄÇÁÇ∫Ê≠§Ôºå‰ΩúÁÇ∫Á¨¨‰∏ÄÊ¨°ÂòóË©¶ÔºåÊàëÂÄëÂ∞á GNN ‰∏≠Ê≥®ÊÑèÂäõÊ¨äÈáçÁöÑÈÇäÁ∑£Ê≠∏Âõ†ÂïèÈ°åÂΩ¢ÂºèÂåñ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫ GATTÔºå‰∏ÄÁ®ÆÂª∫Á´ãÂú®Ë®àÁÆóÊ®π‰∏äÁöÑÈÇäÁ∑£Ê≠∏Âõ†Ë®àÁÆóÊñπÊ≥ï„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Ë©ï‰º∞ GAT ÁöÑÊ≠∏Âõ†ÊôÇÊâÄÂÖ∑ÊúâÁöÑÊïàÊûú„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄëÊÜëÁ∂ìÈ©óÈ©óË≠â‰∫ÜÂÉÖÂ∞çÂúñÊ≥®ÊÑèÂäõÂ±§‰∏äÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÂèñÂπ≥ÂùáÂÄº‰∏çË∂≥‰ª•Ë©ÆÈáã GAT Ê®°ÂûãÁöÑË°åÁÇ∫„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº https://github.com/jordan7186/GAtt/tree/main„ÄÇ

##### **OCDB: Revisiting Causal Discovery with a Comprehensive Benchmark and Evaluation Framework**
2406.04598v1 by Wei Zhou, Hong Huang, Guowen Zhang, Ruize Shi, Kehan Yin, Yuanyuan Lin, Bang Liu

Large language models (LLMs) have excelled in various natural language
processing tasks, but challenges in interpretability and trustworthiness
persist, limiting their use in high-stakes fields. Causal discovery offers a
promising approach to improve transparency and reliability. However, current
evaluations are often one-sided and lack assessments focused on
interpretability performance. Additionally, these evaluations rely on synthetic
data and lack comprehensive assessments of real-world datasets. These lead to
promising methods potentially being overlooked. To address these issues, we
propose a flexible evaluation framework with metrics for evaluating differences
in causal structures and causal effects, which are crucial attributes that help
improve the interpretability of LLMs. We introduce the Open Causal Discovery
Benchmark (OCDB), based on real data, to promote fair comparisons and drive
optimization of algorithms. Additionally, our new metrics account for
undirected edges, enabling fair comparisons between Directed Acyclic Graphs
(DAGs) and Completed Partially Directed Acyclic Graphs (CPDAGs). Experimental
results show significant shortcomings in existing algorithms' generalization
capabilities on real data, highlighting the potential for performance
improvement and the importance of our framework in advancing causal discovery
techniques.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÊñπÈù¢ÁöÑÊåëÊà∞‰ªçÁÑ∂Â≠òÂú®ÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®È´òÈ¢®Èö™È†òÂüü‰∏≠ÁöÑ‰ΩøÁî®„ÄÇÂõ†ÊûúÁôºÁèæÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÊñπÊ≥ï‰æÜÊèêÈ´òÈÄèÊòéÂ∫¶ÂíåÂèØÈù†ÊÄß„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑË©ï‰º∞ÈÄöÂ∏∏ÊòØ‰∏ÄÊñπÈù¢ÁöÑÔºåÁº∫‰πèÈáùÂ∞çÂèØËß£ÈáãÊÄßË°®ÁèæÁöÑË©ï‰º∞„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õË©ï‰º∞‰æùË≥¥ÊñºÂêàÊàêÊï∏ÊìöÔºå‰∏¶‰∏îÁº∫‰πèÂ∞çÁèæÂØ¶‰∏ñÁïåÊï∏ÊìöÈõÜÁöÑÂÖ®Èù¢Ë©ï‰º∞„ÄÇÈÄôÂ∞éËá¥ÊúâÂâçÊôØÁöÑÊñπÊ≥ïÂèØËÉΩË¢´ÂøΩË¶ñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈùàÊ¥ªÁöÑË©ï‰º∞Ê°ÜÊû∂ÔºåÂÖ∂‰∏≠ÂåÖÂê´Áî®ÊñºË©ï‰º∞Âõ†ÊûúÁµêÊßãÂíåÂõ†ÊûúÊïàÊáâÂ∑ÆÁï∞ÁöÑÊåáÊ®ôÔºåÈÄô‰∫õÈÉΩÊòØÊúâÂä©ÊñºÊèêÈ´ò LLM ÂèØËß£ÈáãÊÄßÁöÑÈóúÈçµÂ±¨ÊÄß„ÄÇÊàëÂÄëÂü∫ÊñºÁúüÂØ¶Êï∏ÊìöÂºïÂÖ•‰∫ÜÈñãÊîæÂõ†ÊûúÁôºÁèæÂü∫Ê∫ñ (OCDB)Ôºå‰ª•‰øÉÈÄ≤ÂÖ¨Âπ≥ÁöÑÊØîËºÉ‰∏¶Êé®ÂãïÁÆóÊ≥ïÁöÑÂÑ™Âåñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊñ∞ÊåáÊ®ôËÄÉÊÖÆ‰∫ÜÁÑ°ÂêëÈÇäÔºåÂæûËÄåÂèØ‰ª•Âú®ÊúâÂêëÁÑ°Áí∞Âúñ (DAG) ÂíåÂ∑≤ÂÆåÊàêÁöÑÈÉ®ÂàÜÊúâÂêëÁÑ°Áí∞Âúñ (CPDAG) ‰πãÈñìÈÄ≤Ë°åÂÖ¨Âπ≥ÁöÑÊØîËºÉ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÁèæÊúâÁÆóÊ≥ïÂú®ÁúüÂØ¶Êï∏Êìö‰∏äÁöÑÊ≥õÂåñËÉΩÂäõÂ≠òÂú®È°ØËëóÁº∫Èô∑ÔºåÁ™ÅÂá∫‰∫ÜÊÄßËÉΩÊîπÈÄ≤ÁöÑÊΩõÂäõ‰ª•ÂèäÊàëÂÄëÊ°ÜÊû∂Âú®Êé®ÈÄ≤Âõ†ÊûúÁôºÁèæÊäÄË°ì‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions**
2406.04286v1 by Sreyan Ghosh, Utkarsh Tyagi, Sonal Kumar, C. K. Evuru, S Ramaneswaran, S Sakshi, Dinesh Manocha

We present ABEX, a novel and effective generative data augmentation
methodology for low-resource Natural Language Understanding (NLU) tasks. ABEX
is based on ABstract-and-EXpand, a novel paradigm for generating diverse forms
of an input document -- we first convert a document into its concise, abstract
description and then generate new documents based on expanding the resultant
abstraction. To learn the task of expanding abstract descriptions, we first
train BART on a large-scale synthetic dataset with abstract-document pairs.
Next, to generate abstract descriptions for a document, we propose a simple,
controllable, and training-free method based on editing AMR graphs. ABEX brings
the best of both worlds: by expanding from abstract representations, it
preserves the original semantic properties of the documents, like style and
meaning, thereby maintaining alignment with the original label and data
distribution. At the same time, the fundamental process of elaborating on
abstract descriptions facilitates diverse generations. We demonstrate the
effectiveness of ABEX on 4 NLU tasks spanning 12 datasets and 4 low-resource
settings. ABEX outperforms all our baselines qualitatively with improvements of
0.04% - 38.8%. Qualitatively, ABEX outperforms all prior methods from
literature in terms of context and length diversity.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ ABEXÔºå‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÊúâÊïàÁöÑÁîüÊàêÂºèË≥áÊñôÊì¥Â¢ûÊñπÊ≥ïÔºåÈÅ©Áî®Êñº‰ΩéË≥áÊ∫êËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ (NLU) ‰ªªÂãô„ÄÇABEX Âª∫Á´ãÂú® ABstract-and-EXpand ‰πã‰∏äÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁî®ÊñºÁî¢ÁîüËº∏ÂÖ•Êñá‰ª∂‰∏çÂêåÂΩ¢ÂºèÁöÑÊñ∞Á©éÁØÑ‰æã - ÊàëÂÄëÈ¶ñÂÖàÂ∞áÊñá‰ª∂ËΩâÊèõÊàêÁ∞°ÊΩîÁöÑÊäΩË±°ÊèèËø∞ÔºåÁÑ∂ÂæåÊ†πÊìöÊì¥Â±ïÊâÄÂæóÊäΩË±°Áî¢ÁîüÊñ∞Êñá‰ª∂„ÄÇÁÇ∫‰∫ÜÂ≠∏ÁøíÊì¥Â±ïÊäΩË±°ÊèèËø∞ÁöÑ‰ªªÂãôÔºåÊàëÂÄëÈ¶ñÂÖàÂú®ÂÖ∑ÊúâÊäΩË±°Êñá‰ª∂ÈÖçÂ∞çÁöÑÂ§ßË¶èÊ®°ÂêàÊàêË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ BART„ÄÇÊé•‰∏ã‰æÜÔºåÁÇ∫‰∫ÜÁî¢ÁîüÊñá‰ª∂ÁöÑÊäΩË±°ÊèèËø∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ∞°ÂñÆ„ÄÅÂèØÊéß‰∏îÁÑ°ÈúÄË®ìÁ∑¥ÁöÑÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂü∫ÊñºÁ∑®ËºØ AMR ÂúñË°®„ÄÇABEX Â∏∂‰æÜ‰∫ÜÂÖ©ÂÖ®ÂÖ∂ÁæéÁöÑÂÑ™ÈªûÔºöÈÄöÈÅéÂæûÊäΩË±°Ë°®Á§∫‰∏≠Êì¥Â±ïÔºåÂÆÉ‰øùÁïô‰∫ÜÊñá‰ª∂ÁöÑÂéüÂßãË™ûÁæ©Â±¨ÊÄßÔºå‰æãÂ¶ÇÈ¢®Ê†ºÂíåÊÑèÁæ©ÔºåÂæûËÄå‰øùÊåÅËàáÂéüÂßãÊ®ôÁ±§ÂíåË≥áÊñôÂàÜ‰ΩàÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂêåÊôÇÔºåÈó°Ëø∞ÊäΩË±°ÊèèËø∞ÁöÑÂü∫Êú¨ÈÅéÁ®ã‰øÉÈÄ≤‰∫ÜÂ§öÊ®£ÂåñÁöÑÁîüÊàê„ÄÇÊàëÂÄëÂú®Ê©´Ë∑® 12 ÂÄãË≥áÊñôÈõÜÂíå 4 ÂÄã‰ΩéË≥áÊ∫êË®≠ÂÆöÁöÑ 4 ÂÄã NLU ‰ªªÂãô‰∏äÂ±ïÁ§∫‰∫Ü ABEX ÁöÑÊúâÊïàÊÄß„ÄÇABEX Âú®Ë≥™Èáè‰∏äÂÑ™ÊñºÊàëÂÄëÊâÄÊúâÁöÑÂü∫Ê∫ñÔºåÊîπÈÄ≤‰∫Ü 0.04% - 38.8%„ÄÇÂú®Ë≥™Èáè‰∏äÔºåABEX Âú®ËÉåÊôØÂíåÈï∑Â∫¶Â§öÊ®£ÊÄßÊñπÈù¢ÂÑ™ÊñºÊñáÁçª‰∏≠ÁöÑÊâÄÊúâÂÖàÂâçÊñπÊ≥ï„ÄÇ

##### **Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**
2406.04271v1 by Ling Yang, Zhaochen Yu, Tianjun Zhang, Shiyi Cao, Minkai Xu, Wentao Zhang, Joseph E. Gonzalez, Bin Cui

We introduce Buffer of Thoughts (BoT), a novel and versatile
thought-augmented reasoning approach for enhancing accuracy, efficiency and
robustness of large language models (LLMs). Specifically, we propose
meta-buffer to store a series of informative high-level thoughts, namely
thought-template, distilled from the problem-solving processes across various
tasks. Then for each problem, we retrieve a relevant thought-template and
adaptively instantiate it with specific reasoning structures to conduct
efficient reasoning. To guarantee the scalability and stability, we further
propose buffer-manager to dynamically update the meta-buffer, thus enhancing
the capacity of meta-buffer as more tasks are solved. We conduct extensive
experiments on 10 challenging reasoning-intensive tasks, and achieve
significant performance improvements over previous SOTA methods: 11% on Game of
24, 20% on Geometric Shapes and 51% on Checkmate-in-One. Further analysis
demonstrate the superior generalization ability and model robustness of our
BoT, while requiring only 12% of the cost of multi-query prompting methods
(e.g., tree/graph of thoughts) on average. Notably, we find that our
Llama3-8B+BoT has the potential to surpass Llama3-70B model. Our project is
available at: https://github.com/YangLing0818/buffer-of-thought-llm

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥π‰∫ÜÊÄùÊÉ≥Á∑©Ë°ùÂçÄ (BoT)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÈÄöÁî®ÁöÑÊÄùÊÉ≥Â¢ûÂº∑Êé®ÁêÜÊñπÊ≥ïÔºåÁî®ÊñºÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÊïàÁéáÂíåÁ©©ÂÅ•ÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫ÂÖÉÁ∑©Ë°ùÂçÄÔºåÁî®ÊñºÂÑ≤Â≠ò‰∏ÄÁ≥ªÂàóÊúâÊÑèÁæ©ÁöÑÈ´òÈöéÊÄùÊÉ≥ÔºåÂç≥ÊÄùÊÉ≥ÁØÑÊú¨ÔºåÂæûÂêÑÁ®Æ‰ªªÂãôÁöÑËß£Ê±∫ÂïèÈ°åÈÅéÁ®ã‰∏≠ÊèêÁÖâÂá∫‰æÜ„ÄÇÁÑ∂ÂæåÔºåÂ∞çÊñºÊØèÂÄãÂïèÈ°åÔºåÊàëÂÄëÊúÉÊì∑Âèñ‰∏ÄÂÄãÁõ∏ÈóúÁöÑÊÄùÊÉ≥ÁØÑÊú¨Ôºå‰∏¶‰ª•ÁâπÂÆöÁöÑÊé®ÁêÜÁµêÊßãËá™ÈÅ©ÊáâÂú∞ÂØ¶‰æãÂåñÂÆÉÔºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁéáÁöÑÊé®ÁêÜ„ÄÇÁÇ∫‰∫Ü‰øùË≠âÂèØÊì¥ÂÖÖÊÄßÂíåÁ©©ÂÆöÊÄßÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫ÜÁ∑©Ë°ùÂçÄÁÆ°ÁêÜÂì°ÔºåÁî®ÊñºÂãïÊÖãÊõ¥Êñ∞ÂÖÉÁ∑©Ë°ùÂçÄÔºåÂæûËÄåÈö®ËëóÊõ¥Â§ö‰ªªÂãôÁöÑËß£Ê±∫ËÄåÊèêÂçáÂÖÉÁ∑©Ë°ùÂçÄÁöÑÂÆπÈáè„ÄÇÊàëÂÄëÂú® 10 È†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÊé®ÁêÜÂØÜÈõÜÂûã‰ªªÂãô‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰∏¶‰∏îÁõ∏ËºÉÊñºÂÖàÂâçÁöÑ SOTA ÊñπÊ≥ïÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºö24 ÁöÑÈÅäÊà≤ÊèêÂçá‰∫Ü 11%ÔºåÂπæ‰ΩïÂΩ¢ÁãÄÊèêÂçá‰∫Ü 20%Ôºå‰∏ÄÊãõÂ∞áÊ≠ªÊèêÂçá‰∫Ü 51%„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêË≠âÊòé‰∫ÜÊàëÂÄë BoT ÁöÑÂÑ™Áï∞Ê≥õÂåñËÉΩÂäõÂíåÊ®°ÂûãÁ©©ÂÅ•ÊÄßÔºåÂêåÊôÇÂπ≥ÂùáÂè™ÈúÄË¶ÅÂ§öÊü•Ë©¢ÊèêÁ§∫ÊñπÊ≥ïÔºà‰æãÂ¶ÇÊÄùÊÉ≥Ê®π/ÂúñÔºâÊàêÊú¨ÁöÑ 12%„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæÊàëÂÄëÁöÑ Llama3-8B+BoT ÊúâÂèØËÉΩË∂ÖË∂ä Llama3-70B Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÂ∞àÊ°àÂèØÊñº‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://github.com/YangLing0818/buffer-of-thought-llm</paragraph>

##### **Transformers need glasses! Information over-squashing in language tasks**
2406.04267v1 by Federico Barbero, Andrea Banino, Steven Kapturowski, Dharshan Kumaran, Jo√£o G. M. Ara√∫jo, Alex Vitvitskyi, Razvan Pascanu, Petar Veliƒçkoviƒá

We study how information propagates in decoder-only Transformers, which are
the architectural backbone of most existing frontier large language models
(LLMs). We rely on a theoretical signal propagation analysis -- specifically,
we analyse the representations of the last token in the final layer of the
Transformer, as this is the representation used for next-token prediction. Our
analysis reveals a representational collapse phenomenon: we prove that certain
distinct sequences of inputs to the Transformer can yield arbitrarily close
representations in the final token. This effect is exacerbated by the
low-precision floating-point formats frequently used in modern LLMs. As a
result, the model is provably unable to respond to these sequences in different
ways -- leading to errors in, e.g., tasks involving counting or copying.
Further, we show that decoder-only Transformer language models can lose
sensitivity to specific tokens in the input, which relates to the well-known
phenomenon of over-squashing in graph neural networks. We provide empirical
evidence supporting our claims on contemporary LLMs. Our theory also points to
simple solutions towards ameliorating these issues.

ÊëòË¶ÅÔºöÊàëÂÄëÁ†îÁ©∂Ë≥áË®äÂú®ÂÉÖËß£Á¢ºÂô® Transformer ‰∏≠Â¶Ç‰ΩïÂÇ≥Êí≠ÔºåËÄåÂÉÖËß£Á¢ºÂô® Transformer ÊòØÁèæÊúâÊúÄÂâçÊ≤øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊû∂Êßã‰∏ªÂππ„ÄÇÊàëÂÄë‰æùË≥¥ÊñºÁêÜË´ñË®äËôüÂÇ≥Êí≠ÂàÜÊûêÔºåÁâπÂà•ÊòØÔºåÊàëÂÄëÂàÜÊûê Transformer ÊúÄÂæå‰∏ÄÂ±§‰∏≠ÊúÄÂæå‰∏ÄÂÄã‰ª£Âπ£ÁöÑË°®ÂæµÔºåÂõ†ÁÇ∫ÈÄôÊòØÁî®Êñº‰∏ã‰∏ÄÂÄã‰ª£Âπ£È†êÊ∏¨ÁöÑË°®Âæµ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊè≠Á§∫‰∫Ü‰∏ÄÂÄãË°®ÂæµÂ¥©ÊΩ∞ÁèæË±°ÔºöÊàëÂÄëË≠âÊòéËº∏ÂÖ•Âà∞ Transformer ÁöÑÊüê‰∫õ‰∏çÂêåÈ†ÜÂ∫èÂ∫èÂàóÂèØ‰ª•Âú®ÊúÄÂæå‰∏ÄÂÄã‰ª£Âπ£‰∏≠Áî¢Áîü‰ªªÊÑèÊé•ËøëÁöÑË°®Âæµ„ÄÇÈÄôÁ®ÆÊïàÊáâÊúÉÂõ†Áèæ‰ª£ LLM ‰∏≠Á∂ìÂ∏∏‰ΩøÁî®ÁöÑ‰ΩéÁ≤æÂ∫¶ÊµÆÈªûÊ†ºÂºèËÄåÂä†Âäá„ÄÇÁµêÊûúÔºåË©≤Ê®°ÂûãÁÑ°Ê≥ïÂ∞çÈÄô‰∫õÂ∫èÂàó‰ª•‰∏çÂêåÁöÑÊñπÂºèÂÅöÂá∫ÂõûÊáâÔºåÂ∞éËá¥ÈåØË™§Ôºå‰æãÂ¶ÇÊ∂âÂèäË®àÊï∏ÊàñË§áË£ΩÁöÑ‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÂÉÖËß£Á¢ºÂô® Transformer Ë™ûË®ÄÊ®°ÂûãÂèØËÉΩÊúÉÂ∞çËº∏ÂÖ•‰∏≠ÁöÑÁâπÂÆö‰ª£Âπ£Â§±ÂéªÊïèÊÑüÊÄßÔºåÈÄôËàáÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ÁúæÊâÄÂë®Áü•ÁöÑÈÅéÂ∫¶Â£ìÁ∏ÆÁèæË±°ÊúâÈóú„ÄÇÊàëÂÄëÊèê‰æõÁ∂ìÈ©óË≠âÊìöÊîØÊåÅÊàëÂÄëÂ∞çÁï∂‰ª£ LLM ÁöÑË™™Ê≥ï„ÄÇÊàëÂÄëÁöÑÁêÜË´ñ‰πüÊåáÂá∫‰∫ÜÊîπÂñÑÈÄô‰∫õÂïèÈ°åÁöÑÁ∞°ÂñÆËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **The CLRS-Text Algorithmic Reasoning Language Benchmark**
2406.04229v1 by Larisa Markeeva, Sean McLeish, Borja Ibarz, Wilfried Bounsi, Olga Kozlova, Alex Vitvitskyi, Charles Blundell, Tom Goldstein, Avi Schwarzschild, Petar Veliƒçkoviƒá

Eliciting reasoning capabilities from language models (LMs) is a critical
direction on the path towards building intelligent systems. Most recent studies
dedicated to reasoning focus on out-of-distribution performance on
procedurally-generated synthetic benchmarks, bespoke-built to evaluate specific
skills only. This trend makes results hard to transfer across publications,
slowing down progress. Three years ago, a similar issue was identified and
rectified in the field of neural algorithmic reasoning, with the advent of the
CLRS benchmark. CLRS is a dataset generator comprising graph execution traces
of classical algorithms from the Introduction to Algorithms textbook. Inspired
by this, we propose CLRS-Text -- a textual version of these algorithmic traces.
Out of the box, CLRS-Text is capable of procedurally generating trace data for
thirty diverse, challenging algorithmic tasks across any desirable input
distribution, while offering a standard pipeline in which any additional
algorithmic tasks may be created in the benchmark. We fine-tune and evaluate
various LMs as generalist executors on this benchmark, validating prior work
and revealing a novel, interesting challenge for the LM reasoning community.
Our code is available at
https://github.com/google-deepmind/clrs/tree/master/clrs/_src/clrs_text.

ÊëòË¶ÅÔºöÂºïÂá∫ËØ≠Ë®ÄÊ®°Âûã (LM) ÁöÑÊé®ÁêÜËÉΩÂäõÊòØÂª∫ÊûÑÊô∫ËÉΩÁ≥ªÁªüË∑ØÂæÑ‰∏äÁöÑÂÖ≥ÈîÆÊñπÂêë„ÄÇÂ§ßÂ§öÊï∞ÊúÄËøë‰∏ìÊ≥®‰∫éÊé®ÁêÜÁöÑÁ†îÁ©∂ÈÉΩÂÖ≥Ê≥®Á®ãÂ∫èÁîüÊàêÂêàÊàêÂü∫ÂáÜÁöÑÂàÜÂ∏ÉÂ§ñÊÄßËÉΩÔºå‰ªÖ‰∏∫ËØÑ‰º∞ÁâπÂÆöÊäÄËÉΩËÄåÂÆöÂà∂ÊûÑÂª∫„ÄÇËøôÁßçË∂ãÂäø‰ΩøÂæóÁªìÊûúÈöæ‰ª•Âú®Âá∫ÁâàÁâ©‰πãÈó¥ËΩ¨ÁßªÔºå‰ªéËÄåÂáèÁºì‰∫ÜËøõÂ∫¶„ÄÇ‰∏âÂπ¥ÂâçÔºåÂú®Á•ûÁªèÁÆóÊ≥ïÊé®ÁêÜÈ¢ÜÂüüÂèëÁé∞‰∫ÜÁ±ª‰ººÁöÑÈóÆÈ¢òÂπ∂Âä†‰ª•Á∫†Ê≠£ÔºåÈöèÁùÄ CLRS Âü∫ÂáÜÁöÑÂá∫Áé∞„ÄÇCLRS ÊòØ‰∏Ä‰∏™Êï∞ÊçÆÈõÜÁîüÊàêÂô®ÔºåÂåÖÂê´Êù•Ëá™ÁÆóÊ≥ïÂØºËÆ∫ÊïôÁßë‰π¶ÁöÑÁªèÂÖ∏ÁÆóÊ≥ïÁöÑÂõæÂΩ¢ÊâßË°åËΩ®Ëøπ„ÄÇÂèóÊ≠§ÂêØÂèëÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü CLRS-Text‚Äî‚ÄîËøô‰∫õÁÆóÊ≥ïËΩ®ËøπÁöÑÊñáÊú¨ÁâàÊú¨„ÄÇÂºÄÁÆ±Âç≥Áî®ÔºåCLRS-Text ËÉΩÂ§ü‰∏∫‰∏âÂçÅ‰∏™‰∏çÂêåÁöÑ„ÄÅÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÁÆóÊ≥ï‰ªªÂä°Á®ãÂ∫èÁîüÊàêËΩ®ËøπÊï∞ÊçÆÔºåË∑®Ë∂ä‰ªª‰ΩïÁêÜÊÉ≥ÁöÑËæìÂÖ•ÂàÜÂ∏ÉÔºåÂêåÊó∂Êèê‰æõ‰∏Ä‰∏™Ê†áÂáÜÁÆ°ÈÅìÔºåÂèØ‰ª•Âú®Âü∫ÂáÜ‰∏≠ÂàõÂª∫‰ªª‰ΩïÂÖ∂‰ªñÁÆóÊ≥ï‰ªªÂä°„ÄÇÊàë‰ª¨ÂØπÂêÑÁßç LM ËøõË°åÂæÆË∞ÉÂíåËØÑ‰º∞Ôºå‰Ωú‰∏∫Ê≠§Âü∫ÂáÜ‰∏äÁöÑÈÄöÊâçÊâßË°åÂô®ÔºåÈ™åËØÅ‰∫ÜÂÖàÂâçÁöÑÂ∑•‰ΩúÂπ∂Êè≠Á§∫‰∫Ü LM Êé®ÁêÜÁ§æÂå∫‰∏Ä‰∏™Êñ∞È¢ñ„ÄÅÊúâË∂£ÁöÑÊåëÊàò„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú® https://github.com/google-deepmind/clrs/tree/master/clrs/_src/clrs_text Ëé∑Âæó„ÄÇ

##### **Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech**
2406.03953v1 by Neemesh Yadav, Sarah Masud, Vikram Goyal, Vikram Goyal, Md Shad Akhtar, Tanmoy Chakraborty

Employing language models to generate explanations for an incoming implicit
hate post is an active area of research. The explanation is intended to make
explicit the underlying stereotype and aid content moderators. The training
often combines top-k relevant knowledge graph (KG) tuples to provide world
knowledge and improve performance on standard metrics. Interestingly, our study
presents conflicting evidence for the role of the quality of KG tuples in
generating implicit explanations. Consequently, simpler models incorporating
external toxicity signals outperform KG-infused models. Compared to the
KG-based setup, we observe a comparable performance for SBIC (LatentHatred)
datasets with a performance variation of +0.44 (+0.49), +1.83 (-1.56), and
-4.59 (+0.77) in BLEU, ROUGE-L, and BERTScore. Further human evaluation and
error analysis reveal that our proposed setup produces more precise
explanations than zero-shot GPT-3.5, highlighting the intricate nature of the
task.

ÊëòË¶ÅÔºöÂà©Áî®Ë™ûË®ÄÊ®°ÂûãÁÇ∫‰∏ÄÂÄãÊöóÁ§∫ÊÄßÁöÑ‰ªáÊÅ®ÊñáÁ´†Áî¢ÁîüËß£ÈáãÊòØ‰∏ÄÂÄãÊ¥ªË∫çÁöÑÁ†îÁ©∂È†òÂüü„ÄÇÈÄôÂÄãËß£ÈáãÁöÑÁõÆÁöÑÊòØË¶ÅÊòéÁ¢∫ÊΩõÂú®ÁöÑÂàªÊùøÂç∞Ë±°‰∏¶ÂçîÂä©ÂÖßÂÆπÁÆ°ÁêÜÂì°„ÄÇË®ìÁ∑¥ÈÄöÂ∏∏ÁµêÂêàÂâç k ÂÄãÁõ∏ÈóúÁü•Ë≠òÂúñË≠ú (KG) ÂÖÉÁµÑ‰ª•Êèê‰æõ‰∏ñÁïåÁü•Ë≠ò‰∏¶ÊîπÂñÑÊ®ôÊ∫ñÊåáÊ®ôÁöÑÊïàËÉΩ„ÄÇÊúâË∂£ÁöÑÊòØÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÊèêÂá∫ÁüõÁõæÁöÑË≠âÊìöÔºåË™™Êòé KG ÂÖÉÁµÑÁöÑÂìÅË≥™Âú®Áî¢ÁîüÊöóÁ§∫ÊÄßËß£Èáã‰∏≠ÊâÄÊâÆÊºîÁöÑËßíËâ≤„ÄÇÂõ†Ê≠§ÔºåÁµêÂêàÂ§ñÈÉ®ÊØíÊÄßË®äËôüÁöÑËºÉÁ∞°ÂñÆÊ®°ÂûãÂÑ™ÊñºËûçÂÖ• KG ÁöÑÊ®°Âûã„ÄÇËàáÂü∫Êñº KG ÁöÑË®≠ÂÆöÁõ∏ÊØîÔºåÊàëÂÄëËßÄÂØüÂà∞ SBIC (LatentHatred) Ë≥áÊñôÈõÜÊúâÁõ∏ËøëÁöÑÊïàËÉΩÔºåÂú® BLEU„ÄÅROUGE-L Âíå BERTScore ‰∏≠ÊïàËÉΩËÆäÂåñÁÇ∫ +0.44 (+0.49)„ÄÅ+1.83 (-1.56) Âíå -4.59 (+0.77)„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑ‰∫∫È°ûË©ï‰º∞ÂíåÈåØË™§ÂàÜÊûêÈ°ØÁ§∫ÔºåÊàëÂÄëÊèêÂá∫ÁöÑË®≠ÂÆöÁî¢ÁîüÊØîÈõ∂Ê¨°Â≠∏Áøí GPT-3.5 Êõ¥Á≤æÁ¢∫ÁöÑËß£ÈáãÔºåÁ™ÅÈ°ØÂá∫Ê≠§‰ªªÂãôÁöÑË§áÈõúÊú¨Ë≥™„ÄÇ

##### **Performance of large language models in numerical vs. semantic medical knowledge: Benchmarking on evidence-based Q&As**
2406.03855v1 by Eden Avnat, Michal Levy, Daniel Herstain, Elia Yanko, Daniel Ben Joya, Michal Tzuchman Katz, Dafna Eshel, Sahar Laros, Yael Dagan, Shahar Barami, Joseph Mermelstein, Shahar Ovadia, Noam Shomron, Varda Shalev, Raja-Elie E. Abdulnour

Clinical problem-solving requires processing of semantic medical knowledge
such as illness scripts and numerical medical knowledge of diagnostic tests for
evidence-based decision-making. As large language models (LLMs) show promising
results in many aspects of language-based clinical practice, their ability to
generate non-language evidence-based answers to clinical questions is
inherently limited by tokenization. Therefore, we evaluated LLMs' performance
on two question types: numeric (correlating findings) and semantic
(differentiating entities) while examining differences within and between LLMs
in medical aspects and comparing their performance to humans. To generate
straightforward multi-choice questions and answers (QAs) based on
evidence-based medicine (EBM), we used a comprehensive medical knowledge graph
(encompassed data from more than 50,00 peer-reviewed articles) and created the
"EBMQA". EBMQA contains 105,000 QAs labeled with medical and non-medical topics
and classified into numerical or semantic questions. We benchmarked this
dataset using more than 24,500 QAs on two state-of-the-art LLMs: Chat-GPT4 and
Claude3-Opus. We evaluated the LLMs accuracy on semantic and numerical question
types and according to sub-labeled topics. For validation, six medical experts
were tested on 100 numerical EBMQA questions. We found that both LLMs excelled
more in semantic than numerical QAs, with Claude3 surpassing GPT4 in numerical
QAs. However, both LLMs showed inter and intra gaps in different medical
aspects and remained inferior to humans. Thus, their medical advice should be
addressed carefully.

ÊëòË¶ÅÔºö<paragraph>Ëá®Â∫äÂïèÈ°åËß£Ê±∫ÈúÄË¶ÅËôïÁêÜË™ûÁæ©ÈÜ´Â≠∏Áü•Ë≠òÔºå‰æãÂ¶ÇÁñæÁóÖËÖ≥Êú¨ÂíåÁî®ÊñºÂæ™Ë≠âÊ±∫Á≠ñÁöÑË®∫Êñ∑Ê∏¨Ë©¶ÁöÑÊï∏ÂÄºÈÜ´Â≠∏Áü•Ë≠ò„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë™ûË®ÄÂü∫Á§éËá®Â∫äÂØ¶ÂãôÁöÑË®±Â§öÊñπÈù¢È°ØÁ§∫Âá∫‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûúÔºåÂÆÉÂÄëÁî¢ÁîüÈùûË™ûË®ÄÂæ™Ë≠âÁ≠îÊ°àÁöÑËÉΩÂäõÂú®ÊñºËá®Â∫äÂïèÈ°åÊú¨Ë≥™‰∏äÂèóÂà∞Ê®ôË®òÂåñÁöÑÈôêÂà∂„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëË©ï‰º∞‰∫Ü LLM Âú®ÂÖ©Á®ÆÂïèÈ°åÈ°ûÂûã‰∏äÁöÑË°®ÁèæÔºöÊï∏ÂÄºÔºàÁõ∏ÈóúÁôºÁèæÔºâÂíåË™ûÁæ©ÔºàÂçÄÂàÜÂØ¶È´îÔºâÔºåÂêåÊôÇÊ™¢Êü• LLM Âú®ÈÜ´Â≠∏ÊñπÈù¢ÁöÑÂ∑ÆÁï∞Ôºå‰∏¶Â∞áÂÖ∂Ë°®ÁèæËàá‰∫∫È°ûÈÄ≤Ë°åÊØîËºÉ„ÄÇÁÇ∫‰∫ÜÊ†πÊìöÂæ™Ë≠âÈÜ´Â≠∏ (EBM) Áî¢ÁîüÁõ¥Êé•ÁöÑÂ§öÈÅ∏È°åÂíåÁ≠îÊ°à (QA)ÔºåÊàëÂÄë‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÈÜ´Â≠∏Áü•Ë≠òÂúñË≠úÔºàÂåÖÂê´‰æÜËá™ 50,000 Â§öÁØáÂêåË°åË©ïÂØ©ÊñáÁ´†ÁöÑË≥áÊñôÔºâÔºå‰∏¶Âª∫Á´ã‰∫Ü„ÄåEBMQA„Äç„ÄÇEBMQA ÂåÖÂê´ 105,000 ÂÄãÊ®ôË®òÊúâÈÜ´Â≠∏ÂíåÈùûÈÜ´Â≠∏‰∏ªÈ°åÁöÑ QAÔºå‰∏¶ÂàÜÈ°ûÁÇ∫Êï∏ÂÄºÊàñË™ûÁæ©ÂïèÈ°å„ÄÇÊàëÂÄë‰ΩøÁî®Ë∂ÖÈÅé 24,500 ÂÄã QA Âú®ÂÖ©ÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLMÔºöChat-GPT4 Âíå Claude3-Opus ‰∏äÂ∞çÊ≠§Ë≥áÊñôÈõÜÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü LLM Âú®Ë™ûÁæ©ÂíåÊï∏ÂÄºÂïèÈ°åÈ°ûÂûã‰ª•ÂèäÊ†πÊìöÊ¨°Ê®ôÁ±§‰∏ªÈ°åÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÔºåÂÖ≠‰ΩçÈÜ´Â≠∏Â∞àÂÆ∂Êé•Âèó‰∫Ü 100 ÂÄãÊï∏ÂÄº EBMQA ÂïèÈ°åÁöÑÊ∏¨Ë©¶„ÄÇÊàëÂÄëÁôºÁèæÈÄôÂÖ©ÂÄã LLM Âú®Ë™ûÁæ© QA ‰∏äÈÉΩÊØîÂú®Êï∏ÂÄº QA ‰∏äË°®ÁèæÂæóÊõ¥Âá∫Ëâ≤ÔºåËÄå Claude3 Âú®Êï∏ÂÄº QA ‰∏äË∂ÖË∂ä‰∫Ü GPT4„ÄÇÁÑ∂ËÄåÔºåÈÄôÂÖ©ÂÄã LLM Âú®‰∏çÂêåÁöÑÈÜ´Â≠∏ÊñπÈù¢ÈÉΩË°®ÁèæÂá∫ÂÖßÈÉ®ÂíåÂ§ñÈÉ®ÁöÑÂ∑ÆË∑ùÔºå‰∏¶‰∏î‰ªçÁÑ∂ÈÅúÊñº‰∫∫È°û„ÄÇÂõ†Ê≠§ÔºåÂÆÉÂÄëÁöÑÈÜ´ÁôÇÂª∫Ë≠∞ÊáâË¨πÊÖéÂ∞çÂæÖ„ÄÇ</paragraph>

##### **Are Large Language Models the New Interface for Data Pipelines?**
2406.06596v1 by Sylvio Barbon Junior, Paolo Ceravolo, Sven Groppe, Mustafa Jarrar, Samira Maghool, Florence S√®des, Soror Sahri, Maurice Van Keulen

A Language Model is a term that encompasses various types of models designed
to understand and generate human communication. Large Language Models (LLMs)
have gained significant attention due to their ability to process text with
human-like fluency and coherence, making them valuable for a wide range of
data-related tasks fashioned as pipelines. The capabilities of LLMs in natural
language understanding and generation, combined with their scalability,
versatility, and state-of-the-art performance, enable innovative applications
across various AI-related fields, including eXplainable Artificial Intelligence
(XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG).
Furthermore, we believe these models can extract valuable insights and make
data-driven decisions at scale, a practice commonly referred to as Big Data
Analytics (BDA). In this position paper, we provide some discussions in the
direction of unlocking synergies among these technologies, which can lead to
more powerful and intelligent AI solutions, driving improvements in data
pipelines across a wide range of applications and domains integrating humans,
computers, and knowledge.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÊòØ‰∏ÄÂÄãË°ìË™ûÔºåÊ∂µËìãÂêÑÁ®ÆÊó®Âú®ÁêÜËß£ÂíåÁî¢Áîü‰∫∫È°ûÊ∫ùÈÄöÁöÑÊ®°Âûã„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âõ†ÂÖ∂‰ª•È°û‰ºº‰∫∫È°ûÁöÑÊµÅÂà©Â∫¶ÂíåÈÄ£Ë≤´ÊÄßËôïÁêÜÊñáÂ≠óÁöÑËÉΩÂäõËÄåÂÇôÂèóÈóúÊ≥®ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂ∞çÊñºÂª£Ê≥õÁöÑË≥áÊñôÁõ∏Èóú‰ªªÂãôÔºà‰ª•ÁÆ°ÈÅìÂΩ¢ÂºèË®≠Ë®àÔºâÊ•µÂÖ∑ÂÉπÂÄº„ÄÇLLM Âú®Ëá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÁîüÊàêÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂä†‰∏äÂÖ∂ÂèØÊì¥ÂÖÖÊÄß„ÄÅÂ§öÂäüËÉΩÊÄßÂíåÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂèØ‰ª•Âú®ÂêÑÁ®ÆËàá AI Áõ∏ÈóúÁöÑÈ†òÂüü‰∏≠ÂïüÁî®ÂâµÊñ∞ÊáâÁî®ÔºåÂåÖÊã¨ÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)„ÄÅËá™ÂãïÊ©üÂô®Â≠∏Áøí (AutoML) ÂíåÁü•Ë≠òÂúñË≠ú (KG)„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁõ∏‰ø°ÈÄô‰∫õÊ®°ÂûãÂèØ‰ª•ÊèêÂèñÊúâÂÉπÂÄºÁöÑË¶ãËß£Ôºå‰∏¶Â§ßË¶èÊ®°ÂÅöÂá∫Ë≥áÊñôÈ©ÖÂãïÁöÑÊ±∫Á≠ñÔºåÈÄôÁ®ÆÂÅöÊ≥ïÈÄöÂ∏∏Á®±ÁÇ∫Â§ßÊï∏ÊìöÂàÜÊûê (BDA)„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏Ä‰∫õÈóúÊñºËß£ÈéñÈÄô‰∫õÊäÄË°ì‰πãÈñìÁöÑÂçîÂêå‰ΩúÁî®ÁöÑË®éË´ñÔºåÈÄôÂèØ‰ª•Â∞éËá¥Êõ¥Âº∑Â§ß‰∏îÊõ¥Êô∫ÊÖßÁöÑ AI Ëß£Ê±∫ÊñπÊ°àÔºåÊé®ÂãïÂêÑÁ®ÆÊáâÁî®ÂíåÈ†òÂüüÁöÑË≥áÊñôÁÆ°ÈÅìÊîπÈÄ≤ÔºåÊï¥Âêà‰∫∫È°û„ÄÅÈõªËÖ¶ÂíåÁü•Ë≠ò„ÄÇ

##### **Efficient Knowledge Infusion via KG-LLM Alignment**
2406.03746v1 by Zhouyu Jiang, Ling Zhong, Mengshu Sun, Jun Xu, Rui Sun, Hui Cai, Shuhan Luo, Zhiqiang Zhang

To tackle the problem of domain-specific knowledge scarcity within large
language models (LLMs), knowledge graph-retrievalaugmented method has been
proven to be an effective and efficient technique for knowledge infusion.
However, existing approaches face two primary challenges: knowledge mismatch
between public available knowledge graphs and the specific domain of the task
at hand, and poor information compliance of LLMs with knowledge graphs. In this
paper, we leverage a small set of labeled samples and a large-scale corpus to
efficiently construct domain-specific knowledge graphs by an LLM, addressing
the issue of knowledge mismatch. Additionally, we propose a three-stage KG-LLM
alignment strategyto enhance the LLM's capability to utilize information from
knowledge graphs. We conduct experiments with a limited-sample setting on two
biomedical question-answering datasets, and the results demonstrate that our
approach outperforms existing baselines.

ÊëòË¶ÅÔºöÈáùÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁâπÂÆöÈ†òÂüüÁü•Ë≠òÁ®ÄÁº∫ÁöÑÂïèÈ°åÔºåÁü•Ë≠òÂúñË≠úÊì∑ÂèñÂ¢ûÂº∑ÊñπÊ≥ïÂ∑≤Ë¢´Ë≠âÊòéÊòØ‰∏ÄÁ®ÆÊúâÊïà‰∏îÈ´òÊïàÁöÑÁü•Ë≠òÊ≥®ÂÖ•ÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÈù¢Ëá®ÂÖ©ÂÄã‰∏ªË¶ÅÊåëÊà∞ÔºöÂÖ¨ÈñãÂèØÁî®ÁöÑÁü•Ë≠òÂúñË≠úËàá‰ªªÂãôÁâπÂÆöÈ†òÂüü‰πãÈñìÁöÑÁü•Ë≠ò‰∏çÂåπÈÖçÔºå‰ª•Âèä LLM ËàáÁü•Ë≠òÂúñË≠úÁöÑË≥áË®äÁõ∏ÂÆπÊÄß‰∏ç‰Ω≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂà©Áî®‰∏ÄÁµÑÊ®ôË®òÊ®£Êú¨Âíå‰∏ÄÂÄãÂ§ßË¶èÊ®°Ë™ûÊñôÂ∫´ÔºåÁî± LLM ÊúâÊïàÂú∞Âª∫ÊßãÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÂúñË≠úÔºåËß£Ê±∫Áü•Ë≠ò‰∏çÂåπÈÖçÁöÑÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰∏âÈöéÊÆµÁöÑ KG-LLM Â∞çÈΩäÁ≠ñÁï•Ôºå‰ª•Â¢ûÂº∑ LLM Âà©Áî®Áü•Ë≠òÂúñË≠ú‰∏≠Ë≥áË®äÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÁîüÁâ©ÈÜ´Â≠∏ÂïèÁ≠îË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊúâÈôêÊ®£Êú¨Ë®≠ÂÆöÁöÑÂØ¶È©óÔºåÁµêÊûúË°®ÊòéÊàëÂÄëÁöÑÂÅöÊ≥ïÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Á∑ö„ÄÇ

##### **FastGAS: Fast Graph-based Annotation Selection for In-Context Learning**
2406.03730v1 by Zihan Chen, Song Wang, Cong Shen, Jundong Li

In-context learning (ICL) empowers large language models (LLMs) to tackle new
tasks by using a series of training instances as prompts. Since generating the
prompts needs to sample from a vast pool of instances and annotate them (e.g.,
add labels in classification task), existing methods have proposed to select a
subset of unlabeled examples for annotation, thus enhancing the quality of
prompts and concurrently mitigating annotation costs. However, these methods
often require a long time to select instances due to their complexity,
hindering their practical viability. To address this limitation, we propose a
graph-based selection method, FastGAS, designed to efficiently identify
high-quality instances while minimizing computational overhead. Initially, we
construct a data similarity graph based on instance similarities. Subsequently,
employing a graph partitioning algorithm, we partition the graph into pieces.
Within each piece (i.e., subgraph), we adopt a greedy approach to pick the most
representative nodes. By aggregating nodes from diverse pieces and annotating
the corresponding instances, we identify a set of diverse and representative
instances for ICL. Compared to prior approaches, our method not only exhibits
superior performance on different tasks but also significantly reduces
selection time. In addition, we demonstrate the efficacy of our approach in
LLMs of larger sizes.

ÊëòË¶ÅÔºöÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) Ë≥¶ËÉΩÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ΩøÁî®‰∏ÄÁ≥ªÂàóË®ìÁ∑¥ÂØ¶‰æã‰ΩúÁÇ∫ÊèêÁ§∫‰æÜËôïÁêÜÊñ∞‰ªªÂãô„ÄÇÁî±ÊñºÁî¢ÁîüÊèêÁ§∫ÈúÄË¶ÅÂæûÂ§ßÈáèÁöÑÂØ¶‰æã‰∏≠ÊäΩÊ®£‰∏¶Ë®ªËß£ÂÆÉÂÄëÔºà‰æãÂ¶ÇÔºåÂú®ÂàÜÈ°û‰ªªÂãô‰∏≠Êñ∞Â¢ûÊ®ôÁ±§ÔºâÔºåÁèæÊúâÊñπÊ≥ïÂ∑≤ÊèêÂá∫ÈÅ∏Êìá‰∏ÄÂÄãÊú™Ê®ôË®òÁØÑ‰æãÁöÑÂ≠êÈõÜÈÄ≤Ë°åË®ªËß£ÔºåÂæûËÄåÊèêÂçáÊèêÁ§∫ÁöÑÂìÅË≥™‰∏¶ÂêåÊôÇÈôç‰ΩéË®ªËß£ÊàêÊú¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁî±ÊñºÂÖ∂Ë§áÈõúÊÄßÔºåÈÄöÂ∏∏ÈúÄË¶ÅÂæàÈï∑ÁöÑÊôÇÈñì‰æÜÈÅ∏ÊìáÂØ¶‰æãÔºåÈòªÁ§ô‰∫ÜÂÆÉÂÄëÁöÑÂØ¶Áî®ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂúñÂΩ¢ÁöÑÈÅ∏ÊìáÊñπÊ≥ï FastGASÔºåÊó®Âú®ÊúâÊïàÂú∞Ë≠òÂà•È´òÂìÅË≥™ÂØ¶‰æãÔºåÂêåÊôÇÂ∞áÈÅãÁÆóÈñãÈä∑ÈôçÂà∞ÊúÄ‰Ωé„ÄÇÊúÄÂàùÔºåÊàëÂÄëÊ†πÊìöÂØ¶‰æãÁõ∏‰ººÊÄßÂª∫Êßã‰∏ÄÂÄãË≥áÊñôÁõ∏‰ººÊÄßÂúñÂΩ¢„ÄÇÊé•ËëóÔºåÊé°Áî®ÂúñÂΩ¢ÂàÜÂâ≤ÊºîÁÆóÊ≥ïÔºåÂ∞áÂúñÂΩ¢ÂàÜÂâ≤ÊàêÂ§öÂÄãÈÉ®ÂàÜ„ÄÇÂú®ÊØèÂÄãÈÉ®ÂàÜÔºàÂç≥Â≠êÂúñÔºâ‰∏≠ÔºåÊàëÂÄëÊé°Áî®Ë≤™Â©™Ê≥ï‰æÜÊåëÈÅ∏ÊúÄÂÖ∑‰ª£Ë°®ÊÄßÁöÑÁØÄÈªû„ÄÇÈÄèÈÅéÂΩôÁ∏Ω‰æÜËá™‰∏çÂêåÈÉ®ÂàÜÁöÑÁØÄÈªû‰∏¶Ë®ªËß£Â∞çÊáâÁöÑÂØ¶‰æãÔºåÊàëÂÄëË≠òÂà•Âá∫‰∏ÄÁµÑÂ§öÂÖÉ‰∏îÂÖ∑‰ª£Ë°®ÊÄßÁöÑÂØ¶‰æãÔºåÁî®Êñº ICL„ÄÇËàáÂÖàÂâçÁöÑÂÅöÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÂú®‰∏çÂêåÁöÑ‰ªªÂãô‰∏äÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåËÄå‰∏îÈÇÑÂ§ßÂπÖÊ∏õÂ∞ë‰∫ÜÈÅ∏ÊìáÊôÇÈñì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Êõ¥Â§ßË¶èÊ®°ÁöÑ LLM ‰∏≠ÁöÑÊïàËÉΩ„ÄÇ

##### **A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions**
2406.03712v1 by Lei Liu, Xiaoyan Yang, Junchi Lei, Xiaoyang Liu, Yue Shen, Zhiqiang Zhang, Peng Wei, Jinjie Gu, Zhixuan Chu, Zhan Qin, Kui Ren

Large language models (LLMs), such as GPT series models, have received
substantial attention due to their impressive capabilities for generating and
understanding human-level language. More recently, LLMs have emerged as an
innovative and powerful adjunct in the medical field, transforming traditional
practices and heralding a new era of enhanced healthcare services. This survey
provides a comprehensive overview of Medical Large Language Models (Med-LLMs),
outlining their evolution from general to the medical-specific domain (i.e,
Technology and Application), as well as their transformative impact on
healthcare (e.g., Trustworthiness and Safety). Concretely, starting from the
fundamental history and technology of LLMs, we first delve into the progressive
adaptation and refinements of general LLM models in the medical domain,
especially emphasizing the advanced algorithms that boost the LLMs' performance
in handling complicated medical environments, including clinical reasoning,
knowledge graph, retrieval-augmented generation, human alignment, and
multi-modal learning. Secondly, we explore the extensive applications of
Med-LLMs across domains such as clinical decision support, report generation,
and medical education, illustrating their potential to streamline healthcare
services and augment patient outcomes. Finally, recognizing the imperative and
responsible innovation, we discuss the challenges of ensuring fairness,
accountability, privacy, and robustness in Med-LLMs applications. Finally, we
conduct a concise discussion for anticipating possible future trajectories of
Med-LLMs, identifying avenues for the prudent expansion of Med-LLMs. By
consolidating above-mentioned insights, this review seeks to provide a
comprehensive investigation of the potential strengths and limitations of
Med-LLMs for professionals and researchers, ensuring a responsible landscape in
the healthcare setting.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºå‰æãÂ¶Ç GPT Á≥ªÂàóÊ®°ÂûãÔºåÁî±ÊñºÂÖ∂‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁîüÊàêÂíåÁêÜËß£‰∫∫È°ûË™ûË®ÄÁöÑËÉΩÂäõËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÊúÄËøëÔºåLLM Â∑≤ÊàêÁÇ∫ÈÜ´ÁôÇÈ†òÂüüÁöÑÂâµÊñ∞‰∏îÂº∑Â§ßÁöÑËºîÂä©Â∑•ÂÖ∑ÔºåËΩâËÆä‰∫ÜÂÇ≥Áµ±ÂÅöÊ≥ïÔºå‰∏¶È†êÁ§∫ËëóÂ¢ûÂº∑ÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãôÁöÑÊñ∞ÊôÇ‰ª£„ÄÇÈÄôÈ†ÖË™øÊü•ÂÖ®Èù¢Ê¶ÇËø∞‰∫ÜÈÜ´ÁôÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàMed-LLMÔºâÔºåÊ¶ÇËø∞‰∫ÜÂÆÉÂÄëÂæû‰∏ÄËà¨È†òÂüüÂà∞ÈÜ´ÁôÇÁâπÂÆöÈ†òÂüüÔºàÂç≥ÊäÄË°ìÂíåÊáâÁî®ÔºâÁöÑÊºîËÆäÔºå‰ª•ÂèäÂÆÉÂÄëÂ∞çÈÜ´ÁôÇ‰øùÂÅ•ÁöÑËÆäÈù©ÊÄßÂΩ±ÈüøÔºà‰æãÂ¶ÇÔºåÂèØ‰ø°Â∫¶ÂíåÂÆâÂÖ®ÊÄßÔºâ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂæû LLM ÁöÑÂü∫Êú¨Ê≠∑Âè≤ÂíåÊäÄË°ìÈñãÂßãÔºåÊàëÂÄëÈ¶ñÂÖàÊ∑±ÂÖ•Êé¢Ë®éÈÄöÁî® LLM Ê®°ÂûãÂú®ÈÜ´ÁôÇÈ†òÂüüÁöÑÈÄêÊ≠•ÈÅ©ÊáâÂíåÊîπÈÄ≤ÔºåÁâπÂà•Âº∑Ë™ø‰∫ÜÊèêÂçá LLM Âú®ËôïÁêÜË§áÈõúÈÜ´ÁôÇÁí∞Â¢É‰∏≠ÁöÑÊïàËÉΩÁöÑÂÖàÈÄ≤ÊºîÁÆóÊ≥ïÔºåÂåÖÊã¨Ëá®Â∫äÊé®ÁêÜ„ÄÅÁü•Ë≠òÂúñË≠ú„ÄÅÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê„ÄÅ‰∫∫È°ûÂ∞çÈΩäÂíåÂ§öÊ®°ÂºèÂ≠∏Áøí„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü Med-LLM Âú®Ëá®Â∫äÊ±∫Á≠ñÊîØÊè¥„ÄÅÂ†±ÂëäÁîüÊàêÂíåÈÜ´Â≠∏ÊïôËÇ≤Á≠âÈ†òÂüüÁöÑÂª£Ê≥õÊáâÁî®ÔºåË™™ÊòéÂÆÉÂÄëÁ∞°ÂåñÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãôÂíåÊîπÂñÑÊÇ£ËÄÖÈ†êÂæåÁöÑÊΩõÂäõ„ÄÇÊúÄÂæåÔºåË™çË≠òÂà∞ÂøÖË¶ÅÁöÑÂíåË≤†Ë≤¨‰ªªÁöÑÂâµÊñ∞ÔºåÊàëÂÄëË®éË´ñ‰∫ÜÁ¢∫‰øù Med-LLM ÊáâÁî®‰∏≠ÁöÑÂÖ¨Âπ≥ÊÄß„ÄÅÂïèË≤¨Âà∂„ÄÅÈö±ÁßÅÂíåÂÅ•ÂÖ®ÊÄßÁöÑÊåëÊà∞„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞çÈ†êÊ∏¨ Med-LLM ÁöÑÂèØËÉΩÊú™‰æÜËªåË∑°ÈÄ≤Ë°å‰∫ÜÁ∞°ÊΩîÁöÑË®éË´ñÔºåÊâæÂá∫ Med-LLM ÂØ©ÊÖéÊì¥Â±ïÁöÑÈÄîÂæë„ÄÇÈÄöÈÅéÊï¥Âêà‰∏äËø∞Ë¶ãËß£ÔºåÊú¨Á∂úËø∞Êó®Âú®Â∞ç Med-LLM ÁöÑÊΩõÂú®ÂÑ™Âã¢ÂíåÂ±ÄÈôêÊÄßÈÄ≤Ë°åÂÖ®Èù¢ÁöÑË™øÊü•Ôºå‰ª•Á¢∫‰øùÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÁöÑË≤†Ë≤¨‰ªªÁöÑÊ†ºÂ±Ä„ÄÇ

##### **Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning**
2406.03600v1 by Yang Wu, Chenghao Wang, Ece Gumusel, Xiaozhong Liu

The integration of generative Large Language Models (LLMs) into various
applications, including the legal domain, has been accelerated by their
expansive and versatile nature. However, when facing a legal case, users
without a legal background often struggle to formulate professional queries and
may inadvertently overlook critical legal factors when presenting their case
narrative to LLMs. To address this issue, we propose the Diagnostic Legal Large
Language Model (D3LM), which utilizes adaptive lawyer-like diagnostic questions
to collect additional case information and then provides high-quality feedback.
D3LM incorporates an innovative graph-based Positive-Unlabeled Reinforcement
Learning (PURL) algorithm, enabling the generation of critical questions and
enhancing user-LLM interactions. Moreover, an integrated LLM-based stopping
criterion facilitates precise Court Views Generation (CVG). Our research also
introduces a new English-language CVG dataset based on the US case law
database, enriching the realm of LLM research and deployment with a vital
dimension. D3LM surpasses classical LLMs by delivering outstanding performance
and a remarkable user experience in the legal domain.

ÊëòË¶ÅÔºöÁîüÊàêÂºèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊï¥ÂêàÂà∞ÂêÑÁ®ÆÊáâÁî®Á®ãÂºè‰∏≠ÔºåÂåÖÊã¨Ê≥ïÂæãÈ†òÂüüÔºåÂÖ∂Âª£Ê≥õ‰∏îÂ§öÂäüËÉΩÁöÑÁâπÊÄßÂä†ÈÄü‰∫ÜÊ≠§‰∏ÄÊï¥Âêà„ÄÇÁÑ∂ËÄåÔºåÂú®Èù¢Â∞çÊ≥ïÂæãÊ°à‰ª∂ÊôÇÔºåÊ≤íÊúâÊ≥ïÂæãËÉåÊôØÁöÑ‰ΩøÁî®ËÄÖÂ∏∏Â∏∏Èõ£‰ª•Êì¨ÂÆöÂ∞àÊ•≠ÁöÑÊü•Ë©¢ÔºåËÄå‰∏îÂú®Âêë LLM ÊèêÂá∫‰ªñÂÄëÁöÑÊ°à‰ª∂ÊïòËø∞ÊôÇÔºåÂèØËÉΩÊúÉ‰∏çÁ∂ìÊÑèÂú∞ÂøΩÁï•ÈóúÈçµÁöÑÊ≥ïÂæãÂõ†Á¥†„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜË®∫Êñ∑ÂºèÊ≥ïÂæãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàD3LMÔºâÔºåÂÆÉÂà©Áî®ÈÅ©ÊáâÊÄßÁöÑÂæãÂ∏´ÂºèË®∫Êñ∑ÂïèÈ°å‰æÜÊî∂ÈõÜÈ°çÂ§ñÁöÑÊ°à‰ª∂Ë≥áË®äÔºåÁÑ∂ÂæåÊèê‰æõÈ´òÂìÅË≥™ÁöÑÂõûÈ•ã„ÄÇD3LM Êï¥Âêà‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂü∫ÊñºÂúñÂΩ¢ÁöÑÊ≠£Ê®ôÁ±§Êú™Ê®ôÁ±§Âº∑ÂåñÂ≠∏ÁøíÔºàPURLÔºâÊºîÁÆóÊ≥ïÔºåËÉΩÂ§†Áî¢ÁîüÈóúÈçµÂïèÈ°å‰∏¶Âä†Âº∑‰ΩøÁî®ËÄÖËàá LLM ÁöÑ‰∫íÂãï„ÄÇÊ≠§Â§ñÔºå‰∏ÄÂÄãÊï¥ÂêàÁöÑÂü∫Êñº LLM ÁöÑÂÅúÊ≠¢Ê∫ñÂâá‰øÉËøõ‰∫ÜÁ≤æÁ¢∫ÁöÑÊ≥ïÈô¢ËßÄÈªûÁî¢ÁîüÔºàCVGÔºâ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÇÑÂºïÂÖ•‰∫ÜÊñ∞ÁöÑËã±Ë™û CVG Ë≥áÊñôÈõÜÔºåË©≤Ë≥áÊñôÈõÜÂü∫ÊñºÁæéÂúãÊ°à‰æãÊ≥ïË≥áÊñôÂ∫´ÔºåÁÇ∫ LLM Á†îÁ©∂ÂíåÈÉ®ÁΩ≤È†òÂüüÂ¢ûÊ∑ª‰∫Ü‰∏ÄÂÄãÈáçË¶ÅÁöÑÈù¢Âêë„ÄÇD3LM Ë∂ÖË∂ä‰∫ÜÂÇ≥Áµ±ÁöÑ LLMÔºåÂú®Ê≥ïÂæãÈ†òÂüü‰∏≠Êèê‰æõ‰∫ÜÂÇëÂá∫ÁöÑÊïàËÉΩÂíåÂçìË∂äÁöÑ‰ΩøÁî®ËÄÖÈ´îÈ©ó„ÄÇ

##### **XRec: Large Language Models for Explainable Recommendation**
2406.02377v1 by Qiyao Ma, Xubin Ren, Chao Huang

Recommender systems help users navigate information overload by providing
personalized recommendations aligned with their preferences. Collaborative
Filtering (CF) is a widely adopted approach, but while advanced techniques like
graph neural networks (GNNs) and self-supervised learning (SSL) have enhanced
CF models for better user representations, they often lack the ability to
provide explanations for the recommended items. Explainable recommendations aim
to address this gap by offering transparency and insights into the
recommendation decision-making process, enhancing users' understanding. This
work leverages the language capabilities of Large Language Models (LLMs) to
push the boundaries of explainable recommender systems. We introduce a
model-agnostic framework called XRec, which enables LLMs to provide
comprehensive explanations for user behaviors in recommender systems. By
integrating collaborative signals and designing a lightweight collaborative
adaptor, the framework empowers LLMs to understand complex patterns in
user-item interactions and gain a deeper understanding of user preferences. Our
extensive experiments demonstrate the effectiveness of XRec, showcasing its
ability to generate comprehensive and meaningful explanations that outperform
baseline approaches in explainable recommender systems. We open-source our
model implementation at https://github.com/HKUDS/XRec.

ÊëòË¶ÅÔºöÊé®Ëñ¶Á≥ªÁµ±ÈÄèÈÅéÊèê‰æõÁ¨¶Âêà‰ΩøÁî®ËÄÖÂÅèÂ•ΩÁöÑÂÄã‰∫∫ÂåñÊé®Ëñ¶ÔºåÂçîÂä©‰ΩøÁî®ËÄÖÂú®Ë≥áË®äÁàÜÁÇ∏‰∏≠ËºïÈ¨ÜÁÄèË¶Ω„ÄÇÂçîÂêåÈÅéÊøæ (CF) ÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÊé°Áî®ÁöÑÊñπÊ≥ïÔºå‰ΩÜÂÑòÁÆ°ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÂíåËá™Áõ£Áù£Â≠∏Áøí (SSL) Á≠âÈÄ≤ÈöéÊäÄË°ìÂ∑≤Â¢ûÂº∑ CF Ê®°Âûã‰ª•Êèê‰æõÊõ¥Â•ΩÁöÑ‰ΩøÁî®ËÄÖË°®ÂæµÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏Áº∫‰πèÊèê‰æõÊé®Ëñ¶È†ÖÁõÆËß£ÈáãÁöÑËÉΩÂäõ„ÄÇÂèØËß£ÈáãÊé®Ëñ¶Êó®Âú®ÈÄèÈÅéÊèê‰æõÈÄèÊòéÂ∫¶ÂíåË¶ãËß£‰æÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºå‰ª•‰∫ÜËß£Êé®Ëñ¶Ê±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãÔºåÈÄ≤ËÄåÂ¢ûÈÄ≤‰ΩøÁî®ËÄÖÁöÑÁêÜËß£„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑË™ûË®ÄËÉΩÂäõÔºå‰æÜÁ™ÅÁ†¥ÂèØËß£ÈáãÊé®Ëñ¶Á≥ªÁµ±ÁöÑÁïåÈôê„ÄÇÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãÂêçÁÇ∫ XRec ÁöÑËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÊû∂ÊßãÔºåËÆì LLM ËÉΩÂ§†ÁÇ∫Êé®Ëñ¶Á≥ªÁµ±‰∏≠ÁöÑ‰ΩøÁî®ËÄÖË°åÁÇ∫Êèê‰æõÂÖ®Èù¢ÁöÑËß£Èáã„ÄÇÈÄèÈÅéÊï¥ÂêàÂçîÂêå‰ø°ËôüÂíåË®≠Ë®à‰∏ÄÂÄãËºïÈáèÁ¥öÂçîÂêåÈÅ©ÈÖçÂô®ÔºåÊ≠§Êû∂ÊßãË≥¶ËÉΩ LLM ‰∫ÜËß£‰ΩøÁî®ËÄÖËàáÈ†ÖÁõÆ‰∫íÂãï‰∏≠ÁöÑË§áÈõúÊ®°ÂºèÔºå‰∏¶Êõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£‰ΩøÁî®ËÄÖÂÅèÂ•Ω„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫Ü XRec ÁöÑÊúâÊïàÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÆÉÁî¢ÁîüÂÖ®Èù¢‰∏îÊúâÊÑèÁæ©ÁöÑËß£ÈáãÁöÑËÉΩÂäõÔºåÂú®ÂèØËß£ÈáãÊé®Ëñ¶Á≥ªÁµ±‰∏≠ÂÑ™ÊñºÂü∫Ê∫ñÊñπÊ≥ï„ÄÇÊàëÂÄëÂú® https://github.com/HKUDS/XRec ÈñãÊ∫êÊàëÂÄëÁöÑÊ®°ÂûãÂØ¶‰Ωú„ÄÇ

##### **Exploring Effects of Hyperdimensional Vectors for Tsetlin Machines**
2406.02648v1 by Vojtech Halenka, Ahmed K. Kadhim, Paul F. A. Clarke, Bimal Bhattarai, Rupsa Saha, Ole-Christoffer Granmo, Lei Jiao, Per-Arne Andersen

Tsetlin machines (TMs) have been successful in several application domains,
operating with high efficiency on Boolean representations of the input data.
However, Booleanizing complex data structures such as sequences, graphs,
images, signal spectra, chemical compounds, and natural language is not
trivial. In this paper, we propose a hypervector (HV) based method for
expressing arbitrarily large sets of concepts associated with any input data.
Using a hyperdimensional space to build vectors drastically expands the
capacity and flexibility of the TM. We demonstrate how images, chemical
compounds, and natural language text are encoded according to the proposed
method, and how the resulting HV-powered TM can achieve significantly higher
accuracy and faster learning on well-known benchmarks. Our results open up a
new research direction for TMs, namely how to expand and exploit the benefits
of operating in hyperspace, including new booleanization strategies,
optimization of TM inference and learning, as well as new TM applications.

ÊëòË¶ÅÔºöTsetlin Ê©üÂô® (TM) Â∑≤Âú®Â§öÂÄãÊáâÁî®È†òÂüü‰∏≠Áç≤ÂæóÊàêÂäüÔºå
‰ΩøÁî®Â∏ÉÊûóË°®Á§∫Ê≥ïÂ∞çËº∏ÂÖ•Êï∏ÊìöÈÄ≤Ë°åÈ´òÊïàÈÅãÁÆó„ÄÇ
ÁÑ∂ËÄåÔºåÂ∏ÉÊûóÂåñË§áÈõúÁöÑÊï∏ÊìöÁµêÊßãÔºà‰æãÂ¶ÇÂ∫èÂàó„ÄÅÂúñÂΩ¢„ÄÅ
ÂΩ±ÂÉè„ÄÅË®äËôüÈ†ªË≠ú„ÄÅÂåñÂ≠∏ÂåñÂêàÁâ©ÂíåËá™ÁÑ∂Ë™ûË®ÄÔºâ‰∏¶ÈùûÊòì‰∫ã„ÄÇ
Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºË∂ÖÂêëÈáèÁöÑ (HV) ÊñπÊ≥ïÔºåÁî®Êñº
Ë°®ÈÅîËàá‰ªª‰ΩïËº∏ÂÖ•Êï∏ÊìöÈóúËÅØÁöÑ‰ªªÊÑèÂ§ßÂûãÊ¶ÇÂøµÈõÜ„ÄÇ
‰ΩøÁî®Ë∂ÖÁ∂≠Á©∫Èñì‰æÜÂª∫ÊßãÂêëÈáèÂ§ßÂπÖÊì¥Â±ï‰∫Ü
TM ÁöÑÂÆπÈáèÂíåÈùàÊ¥ªÊÄß„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂΩ±ÂÉè„ÄÅÂåñÂ≠∏
ÂåñÂêàÁâ©ÂíåËá™ÁÑ∂Ë™ûË®ÄÊñáÂ≠óÊòØÂ¶Ç‰ΩïÊ†πÊìöÊâÄÊèêÂá∫ÁöÑ
ÊñπÊ≥ïÈÄ≤Ë°åÁ∑®Á¢ºÔºå‰ª•ÂèäÁî±Ê≠§Áî¢ÁîüÁöÑ HV È©ÖÂãï TM Â¶Ç‰ΩïÂú®ÁúæÊâÄÂë®Áü•ÁöÑÂü∫Ê∫ñ‰∏äÂØ¶ÁèæÈ°ØËëóÊõ¥È´òÁöÑ
Ê∫ñÁ¢∫Â∫¶ÂíåÊõ¥Âø´ÁöÑÂ≠∏Áøí„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁÇ∫ TM ÈñãÂïü‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÂç≥Â¶Ç‰ΩïÊì¥Â±ïÂíåÂà©Áî®Âú®Ë∂ÖÁ©∫Èñì‰∏≠ÈÅã‰ΩúÁöÑÂÑ™ÈªûÔºåÂåÖÊã¨Êñ∞ÁöÑÂ∏ÉÊûóÂåñÁ≠ñÁï•„ÄÅ
TM Êé®Ë´ñÂíåÂ≠∏ÁøíÁöÑÊúÄ‰Ω≥ÂåñÔºå‰ª•ÂèäÊñ∞ÁöÑ TM ÊáâÁî®„ÄÇ

##### **UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models**
2406.02110v1 by Zhuoyang Li, Liran Deng, Hui Liu, Qiaoqiao Liu, Junzhao Du

OwnThink stands as the most extensive Chinese open-domain knowledge graph
introduced in recent times. Despite prior attempts in question answering over
OwnThink (OQA), existing studies have faced limitations in model representation
capabilities, posing challenges in further enhancing overall accuracy in
question answering. In this paper, we introduce UniOQA, a unified framework
that integrates two complementary parallel workflows. Unlike conventional
approaches, UniOQA harnesses large language models (LLMs) for precise question
answering and incorporates a direct-answer-prediction process as a
cost-effective complement. Initially, to bolster representation capacity, we
fine-tune an LLM to translate questions into the Cypher query language (CQL),
tackling issues associated with restricted semantic understanding and
hallucinations. Subsequently, we introduce the Entity and Relation Replacement
algorithm to ensure the executability of the generated CQL. Concurrently, to
augment overall accuracy in question answering, we further adapt the
Retrieval-Augmented Generation (RAG) process to the knowledge graph.
Ultimately, we optimize answer accuracy through a dynamic decision algorithm.
Experimental findings illustrate that UniOQA notably advances SpCQL Logical
Accuracy to 21.2% and Execution Accuracy to 54.9%, achieving the new
state-of-the-art results on this benchmark. Through ablation experiments, we
delve into the superior representation capacity of UniOQA and quantify its
performance breakthrough.

ÊëòË¶ÅÔºöOwnThink ÊòØËøë‰æÜ‰ªãÁ¥πÁöÑÊúÄÂª£Ê≥õÁöÑ‰∏≠ÊñáÈñãÊîæÈ†òÂüüÁü•Ë≠òÂúñË≠ú„ÄÇÂÑòÁÆ°ÂÖàÂâçÂòóË©¶Âú® OwnThinkÔºàOQAÔºâ‰∏äÈÄ≤Ë°åÂïèÈ°åËß£Á≠îÔºå‰ΩÜÁèæÊúâÁ†îÁ©∂Âú®Ê®°ÂûãË°®Á§∫ËÉΩÂäõÊñπÈù¢Èù¢Ëá®ÈôêÂà∂ÔºåÂ∞çÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÂïèÈ°åËß£Á≠îÁöÑÊï¥È´îÊ∫ñÁ¢∫ÊÄßÊßãÊàêÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü UniOQAÔºåÈÄôÊòØ‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊ°ÜÊû∂ÔºåÂÆÉÊï¥Âêà‰∫ÜÂÖ©ÂÄã‰∫íË£úÁöÑ‰∏¶Ë°åÂ∑•‰ΩúÊµÅÁ®ã„ÄÇËàáÂÇ≥Áµ±ÊñπÊ≥ï‰∏çÂêåÔºåUniOQA Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÁ≤æÊ∫ñÂïèÈ°åËß£Á≠îÔºå‰∏¶Â∞áÁõ¥Êé•Á≠îÊ°àÈ†êÊ∏¨ÈÅéÁ®ã‰ΩúÁÇ∫‰∏ÄÁ®ÆÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÁöÑË£úÂÖÖ„ÄÇÊúÄÂàùÔºåÁÇ∫‰∫ÜÂä†Âº∑Ë°®Á§∫ËÉΩÂäõÔºåÊàëÂÄëÂæÆË™ø LLM ‰ª•Â∞áÂïèÈ°åËΩâÊèõÁÇ∫ Cypher Êü•Ë©¢Ë™ûË®Ä (CQL)ÔºåËß£Ê±∫ËàáÂèóÈôêË™ûÁæ©ÁêÜËß£ÂíåÂπªË¶∫Áõ∏ÈóúÁöÑÂïèÈ°å„ÄÇÈö®ÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂØ¶È´îÂíåÈóú‰øÇÊõøÊèõÊºîÁÆóÊ≥ïÔºå‰ª•Á¢∫‰øùÁîüÊàêÁöÑ CQL ÁöÑÂèØÂü∑Ë°åÊÄß„ÄÇÂêåÊôÇÔºåÁÇ∫‰∫ÜÊèêÈ´òÂïèÈ°åËß£Á≠îÁöÑÊï¥È´îÊ∫ñÁ¢∫ÊÄßÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â∞áÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÈÅéÁ®ãÈÅ©ÊáâÂà∞Áü•Ë≠òÂúñË≠ú„ÄÇÊúÄÁµÇÔºåÊàëÂÄëÈÄèÈÅéÂãïÊÖãÊ±∫Á≠ñÊºîÁÆóÊ≥ïÊúÄ‰Ω≥ÂåñÁ≠îÊ°àÊ∫ñÁ¢∫ÊÄß„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåUniOQA Â∞á SpCQL ÈÇèËºØÊ∫ñÁ¢∫Â∫¶È°ØËëóÊèêÂçáËá≥ 21.2%ÔºåÂü∑Ë°åÊ∫ñÁ¢∫Â∫¶ÊèêÂçáËá≥ 54.9%ÔºåÂú®ÈÄôÂÄãÂü∫Ê∫ñ‰∏äÂèñÂæó‰∫ÜÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÁµêÊûú„ÄÇÈÄèÈÅéÊ∂àËûçÂØ¶È©óÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®é UniOQA ÁöÑÂÑ™Áï∞Ë°®Á§∫ËÉΩÂäõÔºå‰∏¶ÈáèÂåñÂÖ∂ÊïàËÉΩÁ™ÅÁ†¥„ÄÇ

##### **Multimodal Reasoning with Multimodal Knowledge Graph**
2406.02030v2 by Junlin Lee, Yequan Wang, Jing Li, Min Zhang

Multimodal reasoning with large language models (LLMs) often suffers from
hallucinations and the presence of deficient or outdated knowledge within LLMs.
Some approaches have sought to mitigate these issues by employing textual
knowledge graphs, but their singular modality of knowledge limits comprehensive
cross-modal understanding. In this paper, we propose the Multimodal Reasoning
with Multimodal Knowledge Graph (MR-MKG) method, which leverages multimodal
knowledge graphs (MMKGs) to learn rich and semantic knowledge across
modalities, significantly enhancing the multimodal reasoning capabilities of
LLMs. In particular, a relation graph attention network is utilized for
encoding MMKGs and a cross-modal alignment module is designed for optimizing
image-text alignment. A MMKG-grounded dataset is constructed to equip LLMs with
initial expertise in multimodal reasoning through pretraining. Remarkably,
MR-MKG achieves superior performance while training on only a small fraction of
parameters, approximately 2.25% of the LLM's parameter size. Experimental
results on multimodal question answering and multimodal analogy reasoning tasks
demonstrate that our MR-MKG method outperforms previous state-of-the-art
models.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÊé®ÁêÜ‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁªèÂ∏∏‰ºöÂá∫Áé∞ÂπªËßâÔºåÂπ∂‰∏î LLM ‰∏≠Â≠òÂú®Áü•ËØÜÁº∫Èô∑ÊàñËøáÊó∂ÁöÑÈóÆÈ¢ò„ÄÇ‰∏Ä‰∫õÊñπÊ≥ïËØïÂõæÈÄöËøá‰ΩøÁî®ÊñáÊú¨Áü•ËØÜÂõæË∞±Êù•ÁºìËß£Ëøô‰∫õÈóÆÈ¢òÔºå‰ΩÜÂÆÉ‰ª¨Âçï‰∏ÄÁöÑÁü•ËØÜÊ®°ÂºèÈôêÂà∂‰∫ÜÂÖ®Èù¢ÁöÑË∑®Ê®°ÊÄÅÁêÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂ§öÊ®°ÊÄÅÁü•ËØÜÂõæË∞± (MR-MKG) ÊñπÊ≥ïÁöÑÂ§öÊ®°ÊÄÅÊé®ÁêÜÔºåËØ•ÊñπÊ≥ïÂà©Áî®Â§öÊ®°ÊÄÅÁü•ËØÜÂõæË∞± (MMKG) Êù•Â≠¶‰π†Ë∑®Ê®°ÊÄÅÁöÑ‰∏∞ÂØåËØ≠‰πâÁü•ËØÜÔºå‰ªéËÄåÊòæËëóÂ¢ûÂº∫ LLM ÁöÑÂ§öÊ®°ÊÄÅÊé®ÁêÜËÉΩÂäõ„ÄÇÁâπÂà´ÊòØÔºåÂÖ≥Á≥ªÂõæË∞±Ê≥®ÊÑèÂäõÁΩëÁªúÁî®‰∫éÁºñÁ†Å MMKGÔºåÂπ∂‰∏îË∑®Ê®°ÊÄÅÂØπÈΩêÊ®°ÂùóËÆæËÆ°Áî®‰∫é‰ºòÂåñÂõæÂÉèÊñáÊú¨ÂØπÈΩê„ÄÇÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫é MMKG ÁöÑÊï∞ÊçÆÈõÜÔºå‰ª•ÈÄöËøáÈ¢ÑËÆ≠ÁªÉ‰∏∫ LLM Êèê‰æõÂ§öÊ®°ÊÄÅÊé®ÁêÜÁöÑÂàùÂßã‰∏ì‰∏öÁü•ËØÜ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåMR-MKG Âú®‰ªÖËÆ≠ÁªÉ LLM ÂèÇÊï∞ËßÑÊ®°ÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜÔºàÁ∫¶‰∏∫ 2.25%ÔºâÊó∂Â∞±ÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇÂ§öÊ®°ÊÄÅÈóÆÈ¢òËß£Á≠îÂíåÂ§öÊ®°ÊÄÅÁ±ªÊØîÊé®ÁêÜ‰ªªÂä°ÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑ MR-MKG ÊñπÊ≥ï‰ºò‰∫é‰ª•ÂâçÊúÄÂÖàËøõÁöÑÊ®°Âûã„ÄÇ

##### **ST-DPGAN: A Privacy-preserving Framework for Spatiotemporal Data Generation**
2406.03404v1 by Wei Shao, Rongyi Zhu, Cai Yang, Chandra Thapa, Muhammad Ejaz Ahmed, Seyit Camtepe, Rui Zhang, DuYong Kim, Hamid Menouar, Flora D. Salim

Spatiotemporal data is prevalent in a wide range of edge devices, such as
those used in personal communication and financial transactions. Recent
advancements have sparked a growing interest in integrating spatiotemporal
analysis with large-scale language models. However, spatiotemporal data often
contains sensitive information, making it unsuitable for open third-party
access. To address this challenge, we propose a Graph-GAN-based model for
generating privacy-protected spatiotemporal data. Our approach incorporates
spatial and temporal attention blocks in the discriminator and a spatiotemporal
deconvolution structure in the generator. These enhancements enable efficient
training under Gaussian noise to achieve differential privacy. Extensive
experiments conducted on three real-world spatiotemporal datasets validate the
efficacy of our model. Our method provides a privacy guarantee while
maintaining the data utility. The prediction model trained on our generated
data maintains a competitive performance compared to the model trained on the
original data.

ÊëòË¶ÅÔºöÊôÇÁ©∫Ë≥áÊñôÂú®Âª£Ê≥õÁöÑÈÇäÁ∑£Ë£ùÁΩÆ‰∏≠ÂæàÊôÆÈÅçÔºå‰æãÂ¶ÇÁî®ÊñºÂÄã‰∫∫ÈÄöË®äÂíåÈáëËûç‰∫§ÊòìÁöÑË£ùÁΩÆ„ÄÇÊúÄËøëÁöÑÈÄ≤Â±ïÊøÄÁôº‰∫ÜÂ∞áÊôÇÁ©∫ÂàÜÊûêËàáÂ§ßË¶èÊ®°Ë™ûË®ÄÊ®°ÂûãÊï¥ÂêàÂú®‰∏ÄËµ∑ÁöÑËààË∂£„ÄÇÁÑ∂ËÄåÔºåÊôÇÁ©∫Ë≥áÊñôÈÄöÂ∏∏ÂåÖÂê´ÊïèÊÑüË≥áË®äÔºå‰ΩøÂÖ∂‰∏çÈÅ©ÂêàÈñãÊîæÁöÑÁ¨¨‰∏âÊñπÂ≠òÂèñ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫Êñº Graph-GAN ÁöÑÊ®°ÂûãÔºåÁî®ÊñºÁî¢ÁîüÂèóÈö±ÁßÅ‰øùË≠∑ÁöÑÊôÇÁ©∫Ë≥áÊñô„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÁ©∫ÈñìÂíåÊôÇÈñìÊ≥®ÊÑèÂäõÂçÄÂ°äÁ¥çÂÖ•Âà§Âà•Âô®Ôºå‰ª•ÂèäÂ∞áÊôÇÁ©∫ÂèçÊë∫Á©çÁµêÊßãÁ¥çÂÖ•ÁîüÊàêÂô®„ÄÇÈÄô‰∫õÂ¢ûÂº∑ÂäüËÉΩËÉΩÂ§†Âú®È´òÊñØÂô™ËÅ≤‰∏ãÈÄ≤Ë°åÊúâÊïàË®ìÁ∑¥Ôºå‰ª•ÂØ¶ÁèæÂ∑ÆÂàÜÈö±ÁßÅ„ÄÇÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÊôÇÁ©∫Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Á∂≠ÊåÅË≥áÊñôÊïàÁî®ÁöÑÂêåÊôÇÊèê‰æõÈö±ÁßÅ‰øùË≠â„ÄÇÂú®ÊàëÂÄëÁî¢ÁîüÁöÑË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåËàáÂú®ÂéüÂßãË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåÁ∂≠ÊåÅÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇ

##### **Helix: Distributed Serving of Large Language Models via Max-Flow on Heterogeneous GPUs**
2406.01566v1 by Yixuan Mei, Yonghao Zhuang, Xupeng Miao, Juncheng Yang, Zhihao Jia, Rashmi Vinayak

This paper introduces Helix, a distributed system for high-throughput,
low-latency large language model (LLM) serving on heterogeneous GPU clusters. A
key idea behind Helix is to formulate inference computation of LLMs over
heterogeneous GPUs and network connections as a max-flow problem for a
directed, weighted graph, whose nodes represent GPU instances and edges capture
both GPU and network heterogeneity through their capacities. Helix then uses a
mixed integer linear programming (MILP) algorithm to discover highly optimized
strategies to serve LLMs. This approach allows Helix to jointly optimize model
placement and request scheduling, two highly entangled tasks in heterogeneous
LLM serving. Our evaluation on several heterogeneous cluster settings ranging
from 24 to 42 GPU nodes shows that Helix improves serving throughput by up to
2.7$\times$ and reduces prompting and decoding latency by up to 2.8$\times$ and
1.3$\times$, respectively, compared to best existing approaches.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π HelixÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁî®ÊñºÁï∞Ë≥™ GPU ÈõÜÁæ§‰∏äÊèê‰æõÈ´òÂêûÂêêÈáè„ÄÅ‰ΩéÂª∂ÈÅ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúçÂãôÁöÑÂàÜÂ∏ÉÂºèÁ≥ªÁµ±„ÄÇHelix ËÉåÂæåÁöÑ‰∏ÄÂÄãÈóúÈçµÊ¶ÇÂøµÊòØÂ∞á LLM Âú®Áï∞Ë≥™ GPU ÂíåÁ∂≤Ë∑ØÈÄ£Á∑ö‰∏äÁöÑÊé®Ë´ñË®àÁÆóË°®Ëø∞ÁÇ∫‰∏ÄÂÄãÊúâÂêëÂä†Ê¨äÂúñÁöÑÊúÄÂ§ßÊµÅÂïèÈ°åÔºåÂÖ∂ÁØÄÈªûË°®Á§∫ GPU ÂØ¶‰æãÔºåÈÇäÁ∑£ÂâáÈÄèÈÅéÂÖ∂ÂÆπÈáèÊì∑Âèñ GPU ÂíåÁ∂≤Ë∑ØÁï∞Ë≥™ÊÄß„ÄÇÊé•ËëóÔºåHelix ‰ΩøÁî®Ê∑∑ÂêàÊï¥Êï∏Á∑öÊÄßË¶èÂäÉ (MILP) ÊºîÁÆóÊ≥ïÊâæÂá∫È´òÂ∫¶ÊúÄ‰Ω≥ÂåñÁöÑÁ≠ñÁï•‰æÜÊèê‰æõ LLM ÊúçÂãô„ÄÇÈÄôÁ®ÆÊñπÊ≥ïËÆì Helix ËÉΩÂ§†ÂêåÊôÇÊúÄ‰Ω≥ÂåñÊ®°ÂûãÈÖçÁΩÆÂíåË¶ÅÊ±ÇÊéíÁ®ãÔºåÈÄôÂÖ©ÂÄãÂú®Áï∞Ë≥™ LLM ÊúçÂãô‰∏≠È´òÂ∫¶Á≥æÁµêÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëÂú®Âæû 24 Âà∞ 42 ÂÄã GPU ÁØÄÈªûÁöÑÂπæÂÄãÁï∞Ë≥™ÈõÜÁæ§Ë®≠ÂÆö‰∏≠ÈÄ≤Ë°åË©ï‰º∞ÔºåÁµêÊûúÈ°ØÁ§∫ Helix Â∞áÊúçÂãôÂêûÂêêÈáèÊèêÂçá‰∫ÜÂ§öÈÅî 2.7 ÂÄçÔºå‰∏¶Â∞áÊèêÁ§∫ÂíåËß£Á¢ºÂª∂ÈÅ≤ÂàÜÂà•Èôç‰Ωé‰∫ÜÂ§öÈÅî 2.8 ÂÄçÂíå 1.3 ÂÄçÔºåËàáÁèæÊúâÊúÄ‰Ω≥ÊñπÊ≥ïÁõ∏ÊØî„ÄÇ

##### **Graph Neural Network Enhanced Retrieval for Question Answering of LLMs**
2406.06572v1 by Zijian Li, Qingyan Guo, Jiawei Shao, Lei Song, Jiang Bian, Jun Zhang, Rui Wang

Retrieval augmented generation has revolutionized large language model (LLM)
outputs by providing factual supports. Nevertheless, it struggles to capture
all the necessary knowledge for complex reasoning questions. Existing retrieval
methods typically divide reference documents into passages, treating them in
isolation. These passages, however, are often interrelated, such as passages
that are contiguous or share the same keywords. Therefore, recognizing the
relatedness is crucial for enhancing the retrieval process. In this paper, we
propose a novel retrieval method, called GNN-Ret, which leverages graph neural
networks (GNNs) to enhance retrieval by considering the relatedness between
passages. Specifically, we first construct a graph of passages by connecting
passages that are structure-related and keyword-related. A graph neural network
(GNN) is then leveraged to exploit the relationships between passages and
improve the retrieval of supporting passages. Furthermore, we extend our method
to handle multi-hop reasoning questions using a recurrent graph neural network
(RGNN), named RGNN-Ret. At each step, RGNN-Ret integrates the graphs of
passages from previous steps, thereby enhancing the retrieval of supporting
passages. Extensive experiments on benchmark datasets demonstrate that GNN-Ret
achieves higher accuracy for question answering with a single query of LLMs
than strong baselines that require multiple queries, and RGNN-Ret further
improves accuracy and achieves state-of-the-art performance, with up to 10.4%
accuracy improvement on the 2WikiMQA dataset.

ÊëòË¶ÅÔºö<paragraph>Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÂ∑≤ÈÄèÈÅéÊèê‰æõ‰∫ãÂØ¶ÊîØÊè¥ÔºåÈù©Êñ∞‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëº∏Âá∫„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂÆÉ‰ªçÈõ£‰ª•Êì∑ÂèñË§áÈõúÊé®ÁêÜÂïèÈ°åÊâÄÈúÄÁöÑÊâÄÊúâÁü•Ë≠ò„ÄÇÁèæÊúâÁöÑÊ™¢Á¥¢ÊñπÊ≥ïÈÄöÂ∏∏Â∞áÂèÉËÄÉÊñá‰ª∂ÂàÜÊàêÊÆµËêΩÔºå‰∏¶Â∞áÂÆÉÂÄëÂ≠§Á´ãËôïÁêÜ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊÆµËêΩÈÄöÂ∏∏ÊòØÁõ∏‰∫íÈóúËÅØÁöÑÔºå‰æãÂ¶ÇÈÄ£Á∫åÁöÑÊÆµËêΩÊàñÂÖ±Áî®Áõ∏ÂêåÈóúÈçµÂ≠óÁöÑÊÆµËêΩ„ÄÇÂõ†Ê≠§ÔºåË≠òÂà•Áõ∏ÈóúÊÄßÂ∞çÊñºÂ¢ûÂº∑Ê™¢Á¥¢Á®ãÂ∫èËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫ GNN-Ret ÁöÑÊñ∞Ê™¢Á¥¢ÊñπÊ≥ïÔºåÂÆÉÂà©Áî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰æÜÂ¢ûÂº∑Ê™¢Á¥¢ÔºåÊñπÊ≥ïÊòØËÄÉÊÖÆÊÆµËêΩ‰πãÈñìÁöÑÁõ∏ÈóúÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÈÄèÈÅéÈÄ£Êé•ÁµêÊßãÁõ∏ÈóúÂíåÈóúÈçµÂ≠óÁõ∏ÈóúÁöÑÊÆµËêΩ‰æÜÂª∫ÊßãÊÆµËêΩÁöÑÂúñÂΩ¢„ÄÇÁÑ∂ÂæåÂà©Áî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰æÜÂà©Áî®ÊÆµËêΩ‰πãÈñìÁöÑÈóú‰øÇÔºå‰∏¶ÊîπÂñÑÊîØÊè¥ÊÆµËêΩÁöÑÊ™¢Á¥¢„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊì¥ÂÖÖ‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºå‰ª•‰ΩøÁî®ÂêçÁÇ∫ RGNN-Ret ÁöÑÈÅûËø¥ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜËôïÁêÜÂ§öË∑≥Êé®ÁêÜÂïèÈ°å„ÄÇÂú®ÊØè‰∏ÄÊ≠•È©ü‰∏≠ÔºåRGNN-Ret ÈÉΩÊúÉÊï¥ÂêàÂâç‰∏ÄÊ≠•È©ü‰∏≠ÊÆµËêΩÁöÑÂúñÂΩ¢ÔºåÂæûËÄåÂ¢ûÂº∑ÊîØÊè¥ÊÆµËêΩÁöÑÊ™¢Á¥¢„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåGNN-Ret Âú®‰ΩøÁî® LLM ÁöÑÂñÆ‰∏ÄÊü•Ë©¢‰æÜÂõûÁ≠îÂïèÈ°åÊôÇÔºåÊØîÈúÄË¶ÅÂ§öÂÄãÊü•Ë©¢ÁöÑÂº∑Â§ßÂü∫Ê∫ñÁ∑öÁç≤ÂæóÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåËÄå RGNN-Ret ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´ò‰∫ÜÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂú® 2WikiMQA Ë≥áÊñôÈõÜ‰∏äÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 10.4%„ÄÇ</paragraph>

##### **How to Understand Whole Software Repository?**
2406.01422v1 by Yingwei Ma, Qingping Yang, Rongyu Cao, Binhua Li, Fei Huang, Yongbin Li

Recently, Large Language Model (LLM) based agents have advanced the
significant development of Automatic Software Engineering (ASE). Although
verified effectiveness, the designs of the existing methods mainly focus on the
local information of codes, e.g., issues, classes, and functions, leading to
limitations in capturing the global context and interdependencies within the
software system. From the practical experiences of the human SE developers, we
argue that an excellent understanding of the whole repository will be the
critical path to ASE. However, understanding the whole repository raises
various challenges, e.g., the extremely long code input, the noisy code
information, the complex dependency relationships, etc. To this end, we develop
a novel ASE method named RepoUnderstander by guiding agents to comprehensively
understand the whole repositories. Specifically, we first condense the critical
information of the whole repository into the repository knowledge graph in a
top-to-down mode to decrease the complexity of repository. Subsequently, we
empower the agents the ability of understanding whole repository by proposing a
Monte Carlo tree search based repository exploration strategy. In addition, to
better utilize the repository-level knowledge, we guide the agents to
summarize, analyze, and plan. Then, they can manipulate the tools to
dynamically acquire information and generate the patches to solve the
real-world GitHub issues. Extensive experiments demonstrate the superiority and
effectiveness of the proposed RepoUnderstander. It achieved 18.5\% relative
improvement on the SWE-bench Lite benchmark compared to SWE-agent.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºåÂü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑ‰ª£ÁêÜÊèêÂçá‰∫ÜËá™Âä®ËΩØ‰ª∂Â∑•Á®ã (ASE) ÁöÑÈáçÂ§ßÂèëÂ±ï„ÄÇÂ∞ΩÁÆ°ÁªèËøáÈ™åËØÅÊúâÊïàÔºå‰ΩÜÁé∞ÊúâÊñπÊ≥ïÁöÑËÆæËÆ°‰∏ªË¶Å‰æßÈáç‰∫é‰ª£Á†ÅÁöÑÂ±ÄÈÉ®‰ø°ÊÅØÔºå‰æãÂ¶ÇÈóÆÈ¢ò„ÄÅÁ±ªÂíåÂáΩÊï∞ÔºåÂØºËá¥Êó†Ê≥ïÊçïÊçâËΩØ‰ª∂Á≥ªÁªü‰∏≠ÁöÑÂÖ®Â±Ä‰∏ä‰∏ãÊñáÂíåÁõ∏‰∫í‰æùËµñÂÖ≥Á≥ª„ÄÇ‰ªé‰∫∫Á±ª SE ÂºÄÂèë‰∫∫ÂëòÁöÑÂÆûÈôÖÁªèÈ™åÊù•ÁúãÔºåÊàë‰ª¨ËÆ§‰∏∫ÂØπÊï¥‰∏™Â≠òÂÇ®Â∫ìÁöÑÂá∫Ëâ≤ÁêÜËß£Â∞ÜÊàê‰∏∫ ASE ÁöÑÂÖ≥ÈîÆË∑ØÂæÑ„ÄÇÁÑ∂ËÄåÔºåÁêÜËß£Êï¥‰∏™Â≠òÂÇ®Â∫ìÂ∏¶Êù•‰∫ÜÂêÑÁßçÊåëÊàòÔºå‰æãÂ¶ÇÊûÅÈïøÁöÑ‰ª£Á†ÅËæìÂÖ•„ÄÅÂòàÊùÇÁöÑ‰ª£Á†Å‰ø°ÊÅØ„ÄÅÂ§çÊùÇÁöÑ‰æùËµñÂÖ≥Á≥ªÁ≠â„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏ÄÁßçÂêç‰∏∫ RepoUnderstander ÁöÑÊñ∞ ASE ÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÈÄöËøáÊåáÂØº‰ª£ÁêÜÂÖ®Èù¢ÁêÜËß£Êï¥‰∏™Â≠òÂÇ®Â∫ì„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨È¶ñÂÖà‰ªé‰∏äÂà∞‰∏ãÊ®°ÂºèÂ∞ÜÊï¥‰∏™Â≠òÂÇ®Â∫ìÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØÊµìÁº©Âà∞Â≠òÂÇ®Â∫ìÁü•ËØÜÂõæ‰∏≠Ôºå‰ª•Èôç‰ΩéÂ≠òÂÇ®Â∫ìÁöÑÂ§çÊùÇÊÄß„ÄÇÈöèÂêéÔºåÊàë‰ª¨ÈÄöËøáÊèêÂá∫Âü∫‰∫éËíôÁâπÂç°ÁΩóÊ†ëÊêúÁ¥¢ÁöÑÂ≠òÂÇ®Â∫ìÊé¢Á¥¢Á≠ñÁï•ÔºåËµã‰∫à‰ª£ÁêÜÁêÜËß£Êï¥‰∏™Â≠òÂÇ®Â∫ìÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞Âà©Áî®Â≠òÂÇ®Â∫ìÁ∫ßÂà´ÁöÑÁü•ËØÜÔºåÊàë‰ª¨ÊåáÂØº‰ª£ÁêÜÊÄªÁªì„ÄÅÂàÜÊûêÂíåËßÑÂàí„ÄÇÁÑ∂ÂêéÔºå‰ªñ‰ª¨ÂèØ‰ª•Êìç‰ΩúÂ∑•ÂÖ∑Âä®ÊÄÅËé∑Âèñ‰ø°ÊÅØÂπ∂ÁîüÊàêË°•‰∏ÅÊù•Ëß£ÂÜ≥Áé∞ÂÆû‰∏ñÁïåÁöÑ GitHub ÈóÆÈ¢ò„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åËØÅÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑ RepoUnderstander ÁöÑ‰ºòË∂äÊÄßÂíåÊúâÊïàÊÄß„ÄÇ‰∏é SWE-agent Áõ∏ÊØîÔºåÂÆÉÂú® SWE-bench Lite Âü∫ÂáÜ‰∏äÂÆûÁé∞‰∫Ü 18.5% ÁöÑÁõ∏ÂØπÊîπËøõ„ÄÇ</paragraph>

##### **FactGenius: Combining Zero-Shot Prompting and Fuzzy Relation Mining to Improve Fact Verification with Knowledge Graphs**
2406.01311v1 by Sushant Gautam

Fact-checking is a crucial natural language processing (NLP) task that
verifies the truthfulness of claims by considering reliable evidence.
Traditional methods are often limited by labour-intensive data curation and
rule-based approaches. In this paper, we present FactGenius, a novel method
that enhances fact-checking by combining zero-shot prompting of large language
models (LLMs) with fuzzy text matching on knowledge graphs (KGs). Leveraging
DBpedia, a structured linked data dataset derived from Wikipedia, FactGenius
refines LLM-generated connections using similarity measures to ensure accuracy.
The evaluation of FactGenius on the FactKG, a benchmark dataset for fact
verification, demonstrates that it significantly outperforms existing
baselines, particularly when fine-tuning RoBERTa as a classifier. The two-stage
approach of filtering and validating connections proves crucial, achieving
superior performance across various reasoning types and establishing FactGenius
as a promising tool for robust fact-checking. The code and materials are
available at https://github.com/SushantGautam/FactGenius.

ÊëòË¶ÅÔºö‰∫ãÂØ¶Êü•Ê†∏ÊòØ‰∏ÄÈ†ÖÈóúÈçµÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãôÔºåÂÆÉÈÄèÈÅéËÄÉÈáèÂèØÈù†ÁöÑË≠âÊìö‰æÜÈ©óË≠â‰∏ªÂºµÁöÑÁúüÂØ¶ÊÄß„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏ÂèóÂà∞ÂãûÂäõÂØÜÈõÜÂûãË≥áÊñôÊï¥ÁêÜÂíåÂü∫ÊñºË¶èÂâáÁöÑÊñπÊ≥ïÁöÑÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü FactGeniusÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÈÄèÈÅéÁµêÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈõ∂Ê¨°ÊèêÁ§∫ÂíåÁü•Ë≠òÂúñË≠ú (KG) ‰∏äÁöÑÊ®°Á≥äÊñáÂ≠óÊØîÂ∞ç‰æÜÂ¢ûÂº∑‰∫ãÂØ¶Êü•Ê†∏„ÄÇFactGenius ÈÄèÈÅéÂà©Áî®ÁµêÊßãÂåñÈÄ£ÁµêË≥áÊñôÈõÜ DBpediaÔºàË°çÁîüËá™Á∂≠Âü∫ÁôæÁßëÔºâÔºå‰ΩøÁî®Áõ∏‰ººÊÄßÊ∏¨Èáè‰æÜÊîπÂñÑ LLM ÁîüÊàêÁöÑÈÄ£Áµê‰ª•Á¢∫‰øùÊ∫ñÁ¢∫ÊÄß„ÄÇÂú® FactKGÔºà‰∏ÄÂÄãÁî®Êñº‰∫ãÂØ¶È©óË≠âÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜÔºâ‰∏äÂ∞ç FactGenius ÈÄ≤Ë°åË©ï‰º∞ÔºåÁµêÊûúÈ°ØÁ§∫ÂÆÉÈ°ØËëóÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Á∑öÔºåÁâπÂà•ÊòØÂú®ÂæÆË™ø RoBERTa ‰ΩúÁÇ∫ÂàÜÈ°ûÂô®ÊôÇ„ÄÇÈÅéÊøæÂíåÈ©óË≠âÈÄ£ÁµêÁöÑÂÖ©ÈöéÊÆµÊñπÊ≥ïË¢´Ë≠âÊòéËá≥ÈóúÈáçË¶ÅÔºåÂú®ÂêÑÁ®ÆÊé®ÁêÜÈ°ûÂûã‰∏≠ÈÉΩËÉΩÂèñÂæóÂÑ™Áï∞ÁöÑÊïàËÉΩÔºå‰∏¶Á¢∫Á´ã FactGenius ‰ΩúÁÇ∫Âº∑ÂÅ•‰∫ãÂØ¶Êü•Ê†∏ÁöÑÊúâÂâçÈÄîÂ∑•ÂÖ∑„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÊñº https://github.com/SushantGautam/FactGenius ÂèñÂæó„ÄÇ

##### **Augmented Commonsense Knowledge for Remote Object Grounding**
2406.01256v1 by Bahram Mohammadi, Yicong Hong, Yuankai Qi, Qi Wu, Shirui Pan, Javen Qinfeng Shi

The vision-and-language navigation (VLN) task necessitates an agent to
perceive the surroundings, follow natural language instructions, and act in
photo-realistic unseen environments. Most of the existing methods employ the
entire image or object features to represent navigable viewpoints. However,
these representations are insufficient for proper action prediction, especially
for the REVERIE task, which uses concise high-level instructions, such as
''Bring me the blue cushion in the master bedroom''. To address enhancing
representation, we propose an augmented commonsense knowledge model (ACK) to
leverage commonsense information as a spatio-temporal knowledge graph for
improving agent navigation. Specifically, the proposed approach involves
constructing a knowledge base by retrieving commonsense information from
ConceptNet, followed by a refinement module to remove noisy and irrelevant
knowledge. We further present ACK which consists of knowledge graph-aware
cross-modal and concept aggregation modules to enhance visual representation
and visual-textual data alignment by integrating visible objects, commonsense
knowledge, and concept history, which includes object and knowledge temporal
information. Moreover, we add a new pipeline for the commonsense-based
decision-making process which leads to more accurate local action prediction.
Experimental results demonstrate our proposed model noticeably outperforms the
baseline and archives the state-of-the-art on the REVERIE benchmark.

ÊëòË¶ÅÔºöË¶ñË¶∫ËàáË™ûË®ÄÂ∞éËà™ (VLN) ‰ªªÂãôÈúÄË¶Å‰ª£ÁêÜÊÑüÁü•Áí∞Â¢É„ÄÅÈÅµÂæ™Ëá™ÁÑ∂Ë™ûË®ÄÊåá‰ª§Ôºå‰∏¶Âú®ÂØ´ÂØ¶ÁöÑÊú™Ë¶ãÁí∞Â¢É‰∏≠Êé°ÂèñË°åÂãï„ÄÇÁèæÊúâÊñπÊ≥ïÂ§ßÂ§ö‰ΩøÁî®Êï¥ÂÄãÂΩ±ÂÉèÊàñÁâ©‰ª∂ÁâπÂæµ‰æÜË°®Á§∫ÂèØÂ∞éËà™Ë¶ñÈªû„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õË°®Á§∫Â∞çÊñºÈÅ©Áï∂ÁöÑÂãï‰ΩúÈ†êÊ∏¨‰æÜË™™ÊòØ‰∏çÂ§†ÁöÑÔºåÁâπÂà•ÊòØÂ∞çÊñº‰ΩøÁî®Á∞°ÊΩîÁöÑÈ´òÈöéÊåá‰ª§ÁöÑ REVERIE ‰ªªÂãôÔºå‰æãÂ¶Ç„ÄåÂπ´ÊàëÊãø‰∏ªËá•ÂÆ§ÁöÑËóçËâ≤Èù†Â¢ä„Äç„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑Ë°®Á§∫ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊì¥Â¢ûÂ∏∏Ë≠òÁü•Ë≠òÊ®°Âûã (ACK)Ôºå‰ª•Âà©Áî®Â∏∏Ë≠òË≥áË®ä‰ΩúÁÇ∫ÊôÇÁ©∫Áü•Ë≠òÂúñË≠úÔºåÁî®ÊñºÊîπÂñÑ‰ª£ÁêÜÂ∞éËà™„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂåÖÊã¨ÈÄèÈÅéÂæû ConceptNet Êì∑ÂèñÂ∏∏Ë≠òË≥áË®ä‰æÜÂª∫Êßã‰∏ÄÂÄãÁü•Ë≠òÂ∫´ÔºåÊé•Ëëó‰ΩøÁî®‰∏ÄÂÄãÁ≤æÁÖâÊ®°ÁµÑ‰æÜÁßªÈô§ÊúâÈõúË®äÂíå‰∏çÁõ∏ÈóúÁöÑÁü•Ë≠ò„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫ ACKÔºåÂÆÉÂåÖÂê´‰∫ÜÁü•Ë≠òÂúñË≠úÊÑüÁü•ÁöÑË∑®Ê®°ÊÖãÂíåÊ¶ÇÂøµËÅöÂêàÊ®°ÁµÑÔºå‰ª•ÈÄèÈÅéÊï¥ÂêàÂèØË¶ãÁâ©‰ª∂„ÄÅÂ∏∏Ë≠òÁü•Ë≠òÂíåÊ¶ÇÂøµÊ≠∑Á®ãÔºàÂåÖÊã¨Áâ©‰ª∂ÂíåÁü•Ë≠òÁöÑÊôÇÈñìË≥áË®äÔºâ‰æÜÂ¢ûÂº∑Ë¶ñË¶∫Ë°®Á§∫ÂíåË¶ñË¶∫ÊñáÂ≠óË≥áÊñôÂ∞çÈΩä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁÇ∫Âü∫ÊñºÂ∏∏Ë≠òÁöÑÊ±∫Á≠ñÂà∂ÂÆöÁ®ãÂ∫èÊñ∞Â¢û‰∏ÄÂÄãÊñ∞ÁÆ°Á∑öÔºåÈÄôÊúÉÂ∞éËá¥Êõ¥Ê∫ñÁ¢∫ÁöÑÂ±ÄÈÉ®Âãï‰ΩúÈ†êÊ∏¨„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÈ°ØËëóÂÑ™ÊñºÂü∫Á∑öÔºå‰∏¶Âú® REVERIE Âü∫Ê∫ñ‰∏äÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÁãÄÊÖã„ÄÇ

##### **EffiQA: Efficient Question-Answering with Strategic Multi-Model Collaboration on Knowledge Graphs**
2406.01238v1 by Zixuan Dong, Baoyun Peng, Yufei Wang, Jia Fu, Xiaodong Wang, Yongxue Shan, Xin Zhou

While large language models (LLMs) have shown remarkable capabilities in
natural language processing, they struggle with complex, multi-step reasoning
tasks involving knowledge graphs (KGs). Existing approaches that integrate LLMs
and KGs either underutilize the reasoning abilities of LLMs or suffer from
prohibitive computational costs due to tight coupling. To address these
limitations, we propose a novel collaborative framework named EffiQA that can
strike a balance between performance and efficiency via an iterative paradigm.
EffiQA consists of three stages: global planning, efficient KG exploration, and
self-reflection. Specifically, EffiQA leverages the commonsense capability of
LLMs to explore potential reasoning pathways through global planning. Then, it
offloads semantic pruning to a small plug-in model for efficient KG
exploration. Finally, the exploration results are fed to LLMs for
self-reflection to further improve the global planning and efficient KG
exploration. Empirical evidence on multiple KBQA benchmarks shows EffiQA's
effectiveness, achieving an optimal balance between reasoning accuracy and
computational costs. We hope the proposed new framework will pave the way for
efficient, knowledge-intensive querying by redefining the integration of LLMs
and KGs, fostering future research on knowledge-based question answering.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠Â±ïÁèæÂá∫ÂçìË∂äÁöÑËÉΩÂäõÔºå‰ΩÜÂÆÉÂÄëÂú®Ê∂âÂèäÁü•Ë≠òÂúñË≠úÔºàKGÔºâÁöÑË§áÈõúÂ§öÊ≠•È©üÊé®ÁêÜ‰ªªÂãô‰∏≠‰ªçÊúâÂõ∞Èõ£„ÄÇÁèæÊúâÁöÑÊï¥Âêà LLM Âíå KG ÁöÑÊñπÊ≥ïÔºå‰∏çÊòØ‰Ωé‰º∞ LLM ÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂ∞±ÊòØÂõ†ÁÇ∫Á∑äÂØÜÁµêÂêàËÄåÂ∞éËá¥È´òÊòÇÁöÑÈÅãÁÆóÊàêÊú¨„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ EffiQA ÁöÑÂâµÊñ∞Âçî‰ΩúÊû∂ÊßãÔºåÂÆÉÂèØ‰ª•ÈÄèÈÅé‰∏ÄÂÄãÂèçË¶ÜÈÅãÁÆóÁöÑÊ®°ÂºèÔºåÂú®ÊïàËÉΩÂíåÊïàÁéá‰πãÈñìÂèñÂæóÂπ≥Ë°°„ÄÇEffiQA ÂåÖÂê´‰∏âÂÄãÈöéÊÆµÔºöÂÖ®ÂüüË¶èÂäÉ„ÄÅÈ´òÊïà KG Êé¢Á¥¢ÂíåËá™ÊàëÂèçÁúÅ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåEffiQA Âà©Áî® LLM ÁöÑÂ∏∏Ë≠òËÉΩÂäõÔºåÈÄèÈÅéÂÖ®ÂüüË¶èÂäÉ‰æÜÊé¢Á¥¢ÊΩõÂú®ÁöÑÊé®ÁêÜË∑ØÂæë„ÄÇÁÑ∂ÂæåÔºåÂÆÉÂ∞áË™ûÁæ©Ââ™ÊûùÂç∏ËºâÁµ¶‰∏ÄÂÄãÂ∞èÂûãÂ§ñÊéõÁ®ãÂºèÊ®°ÂûãÔºå‰ª•ÈÄ≤Ë°åÈ´òÊïàÁöÑ KG Êé¢Á¥¢„ÄÇÊúÄÂæåÔºåÂ∞áÊé¢Á¥¢ÁµêÊûúÂõûÈ•ãÁµ¶ LLM ‰ª•ÈÄ≤Ë°åËá™ÊàëÂèçÁúÅÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑÂÖ®ÂüüË¶èÂäÉÂíåÈ´òÊïà KG Êé¢Á¥¢„ÄÇÂú®Â§öÂÄã KBQA Âü∫Ê∫ñ‰∏äÁöÑÂØ¶Ë≠âË≠âÊìöÈ°ØÁ§∫‰∫Ü EffiQA ÁöÑÊúâÊïàÊÄßÔºåÂú®Êé®ÁêÜÊ∫ñÁ¢∫ÊÄßÂíåÈÅãÁÆóÊàêÊú¨‰πãÈñìÂèñÂæó‰∫ÜÊúÄ‰Ω≥Âπ≥Ë°°„ÄÇÊàëÂÄëÂ∏åÊúõÊâÄÊèêÂá∫ÁöÑÊñ∞Êû∂ÊßãÔºåÈÄèÈÅéÈáçÊñ∞ÂÆöÁæ© LLM Âíå KG ÁöÑÊï¥ÂêàÔºåÁÇ∫È´òÊïà„ÄÅÁü•Ë≠òÂØÜÈõÜÁöÑÊü•Ë©¢Èã™Ë∑ØÔºå‰øÉÈÄ≤Êú™‰æÜÂü∫ÊñºÁü•Ë≠òÁöÑÂïèÁ≠îÁ†îÁ©∂„ÄÇ

##### **Explore then Determine: A GNN-LLM Synergy Framework for Reasoning over Knowledge Graph**
2406.01145v1 by Guangyi Liu, Yongqi Zhang, Yong Li, Quanming Yao

The task of reasoning over Knowledge Graphs (KGs) poses a significant
challenge for Large Language Models (LLMs) due to the complex structure and
large amounts of irrelevant information. Existing LLM reasoning methods
overlook the importance of compositional learning on KG to supply with precise
knowledge. Besides, the fine-tuning and frequent interaction with LLMs incur
substantial time and resource costs. This paper focuses on the Question
Answering over Knowledge Graph (KGQA) task and proposes an
Explore-then-Determine (EtD) framework that synergizes LLMs with graph neural
networks (GNNs) for reasoning over KGs. The Explore stage employs a lightweight
GNN to explore promising candidates and relevant fine-grained knowledge to the
questions, while the Determine stage utilizes the explored information to
construct a knowledge-enhanced multiple-choice prompt, guiding a frozen LLM to
determine the final answer. Extensive experiments on three benchmark KGQA
datasets demonstrate that EtD achieves state-of-the-art performance and
generates faithful reasoning results.

ÊëòË¶ÅÔºöÁî±ÊñºÁü•Ë≠òÂúñË≠ú (KG) ÁöÑË§áÈõúÁµêÊßãÂíåÂ§ßÈáèÁöÑÁÑ°ÈóúË≥áË®äÔºåÂ∞çÁü•Ë≠òÂúñË≠ú (KG) ÈÄ≤Ë°åÊé®ÁêÜÁöÑ‰ªªÂãôÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÁèæÊúâÁöÑ LLM Êé®ÁêÜÊñπÊ≥ïÂøΩÁï•‰∫ÜÂú® KG ‰∏äÈÄ≤Ë°åÁµÑÂêàÂ≠∏Áøí‰ª•Êèê‰æõÁ≤æÁ¢∫Áü•Ë≠òÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÂ∞ç LLM ÈÄ≤Ë°åÂæÆË™øÂíåÈ†ªÁπÅ‰∫íÂãïÊúÉÁî¢ÁîüÂ§ßÈáèÁöÑÊôÇÈñìÂíåË≥áÊ∫êÊàêÊú¨„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥®Áü•Ë≠òÂúñË≠ú (KGQA) ‰∏äÁöÑÂïèÈ°åËß£Á≠î‰ªªÂãôÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊé¢Á¥¢ÁÑ∂ÂæåÁ¢∫ÂÆö (EtD) Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Â∞á LLM ËàáÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÂçîÂêå‰ΩúÁî®‰ª•Â∞ç KG ÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÊé¢Á¥¢ÈöéÊÆµÊé°Áî®ËºïÈáèÁ¥ö GNN ‰æÜÊé¢Á¥¢ÊúâÂ∏åÊúõÁöÑÂÄôÈÅ∏ËÄÖÂíåËàáÂïèÈ°åÁõ∏ÈóúÁöÑÁ≤æÁ¥∞Áü•Ë≠òÔºåËÄåÁ¢∫ÂÆöÈöéÊÆµÂà©Áî®Êé¢Á¥¢ÁöÑË≥áË®ä‰æÜÊßãÂª∫Áü•Ë≠òÂ¢ûÂº∑ÁöÑÂ§öÈÅ∏ÊèêÁ§∫ÔºåÊåáÂ∞éÂáçÁµêÁöÑ LLM ‰æÜÁ¢∫ÂÆöÊúÄÁµÇÁ≠îÊ°à„ÄÇÂú®‰∏âÂÄãÂü∫Ê∫ñ KGQA Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåEtD ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰∏¶Áî¢Áîü‰∫ÜÂø†ÂØ¶ÁöÑÊé®ÁêÜÁµêÊûú„ÄÇ

##### **RAG Enabled Conversations about Household Electricity Monitoring**
2406.06566v1 by Carolina Fortuna, Vid Han≈æel, Bla≈æ Bertalaniƒç

In this paper, we investigate the integration of Retrieval Augmented
Generation (RAG) with large language models (LLMs) such as ChatGPT, Gemini, and
Llama to enhance the accuracy and specificity of responses to complex questions
about electricity datasets. Recognizing the limitations of LLMs in generating
precise and contextually relevant answers due to their dependency on the
patterns in training data rather than factual understanding, we propose a
solution that leverages a specialized electricity knowledge graph. This
approach facilitates the retrieval of accurate, real-time data which is then
synthesized with the generative capabilities of LLMs. Our findings illustrate
that the RAG approach not only reduces the incidence of incorrect information
typically generated by LLMs but also significantly improves the quality of the
output by grounding responses in verifiable data. This paper details our
methodology, presents a comparative analysis of responses with and without RAG,
and discusses the implications of our findings for future applications of AI in
specialized sectors like energy data analysis.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºà‰æãÂ¶Ç ChatGPT„ÄÅGemini Âíå LlamaÔºâÁöÑÊï¥ÂêàÔºå‰ª•Â¢ûÂº∑Â∞çÊúâÈóúÈõªÂäõË≥áÊñôÈõÜÁöÑË§áÈõúÂïèÈ°åÁöÑÂõûÊáâÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁâπÁï∞ÊÄß„ÄÇÁî±Êñº LLM ‰ª∞Ë≥¥Ë®ìÁ∑¥Ë≥áÊñô‰∏≠ÁöÑÊ®°ÂºèÔºåËÄå‰∏çÊòØ‰∫ãÂØ¶ÁêÜËß£ÔºåÂõ†Ê≠§ÊàëÂÄë‰∫ÜËß£Âà∞ LLM Âú®ÁîüÊàêÁ≤æÁ¢∫‰∏îËàáËÑàÁµ°Áõ∏ÈóúÁöÑÁ≠îÊ°àÊñπÈù¢ÁöÑÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂà©Áî®Â∞àÊ•≠ÈõªÂäõÁü•Ë≠òÂúñË°®ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊúâÂä©ÊñºÊ™¢Á¥¢Ê∫ñÁ¢∫ÁöÑÂç≥ÊôÇË≥áÊñôÔºåÁÑ∂ÂæåÂ∞áÂÖ∂Ëàá LLM ÁöÑÁîüÊàêËÉΩÂäõÁµêÂêàËµ∑‰æÜ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåRAG ÊñπÊ≥ï‰∏çÂÉÖÊ∏õÂ∞ë‰∫Ü LLM ÈÄöÂ∏∏Áî¢ÁîüÁöÑ‰∏çÊ≠£Á¢∫Ë≥áË®äÁöÑÁôºÁîüÁéáÔºåËÄå‰∏îÈÄèÈÅéÂ∞áÂõûÊáâÂª∫Á´ãÂú®ÂèØÈ©óË≠âÁöÑË≥áÊñô‰∏äÔºåÈÇÑËÉΩÈ°ØËëóÊîπÂñÑËº∏Âá∫ÁöÑÂìÅË≥™„ÄÇÊú¨ÊñáË©≥Á¥∞Ë™™Êòé‰∫ÜÊàëÂÄëÁöÑÁ†îÁ©∂ÊñπÊ≥ïÔºåÊèê‰æõ‰∫Ü‰ΩøÁî®Âíå‰∏ç‰ΩøÁî® RAG ÁöÑÂõûÊáâÁöÑÊØîËºÉÂàÜÊûêÔºå‰∏¶Ë®éË´ñ‰∫ÜÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂ∞ç AI Âú®ËÉΩÊ∫êË≥áÊñôÂàÜÊûêÁ≠âÂ∞àÊ•≠È†òÂüüÁöÑÊú™‰æÜÊáâÁî®‰πãÂΩ±Èüø„ÄÇ

##### **MACT: Model-Agnostic Cross-Lingual Training for Discourse Representation Structure Parsing**
2406.01052v1 by Jiangming Liu

Discourse Representation Structure (DRS) is an innovative semantic
representation designed to capture the meaning of texts with arbitrary lengths
across languages. The semantic representation parsing is essential for
achieving natural language understanding through logical forms. Nevertheless,
the performance of DRS parsing models remains constrained when trained
exclusively on monolingual data. To tackle this issue, we introduce a
cross-lingual training strategy. The proposed method is model-agnostic yet
highly effective. It leverages cross-lingual training data and fully exploits
the alignments between languages encoded in pre-trained language models. The
experiments conducted on the standard benchmarks demonstrate that models
trained using the cross-lingual training method exhibit significant
improvements in DRS clause and graph parsing in English, German, Italian and
Dutch. Comparing our final models to previous works, we achieve
state-of-the-art results in the standard benchmarks. Furthermore, the detailed
analysis provides deep insights into the performance of the parsers, offering
inspiration for future research in DRS parsing. We keep updating new results on
benchmarks to the appendix.

ÊëòË¶ÅÔºöË™ûÁØáË°®Á§∫ÁµêÊßã (DRS) ÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑË™ûÊÑèË°®Á§∫ÔºåÊó®Âú®Êì∑Âèñ‰ªªÊÑèÈï∑Â∫¶ÁöÑË∑®Ë™ûË®ÄÊñáÊú¨Âê´Áæ©„ÄÇË™ûÊÑèË°®Á§∫Ëß£ÊûêÂ∞çÊñºÈÄèÈÅéÈÇèËºØÂΩ¢ÂºèÈÅîÊàêËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂÉÖ‰ΩøÁî®ÂñÆË™ûÁ≥ªË≥áÊñôÈÄ≤Ë°åË®ìÁ∑¥ÊôÇÔºåDRS Ëß£ÊûêÊ®°ÂûãÁöÑÊïàËÉΩ‰ªçÁÑ∂ÂèóÂà∞ÈôêÂà∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∫ÜË∑®Ë™ûË®ÄË®ìÁ∑¥Á≠ñÁï•„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïËàáÊ®°ÂûãÁÑ°ÈóúÔºå‰ΩÜÈùûÂ∏∏ÊúâÊïà„ÄÇÂÆÉÂà©Áî®Ë∑®Ë™ûË®ÄË®ìÁ∑¥Ë≥áÊñôÔºå‰∏¶ÂÖÖÂàÜÂà©Áî®È†êÂÖàË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã‰∏≠Á∑®Á¢ºÁöÑË™ûË®Ä‰πãÈñìÁöÑÂ∞çÈΩä„ÄÇÂú®Ê®ôÊ∫ñÂü∫Ê∫ñ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòéÔºå‰ΩøÁî®Ë∑®Ë™ûË®ÄË®ìÁ∑¥ÊñπÊ≥ïË®ìÁ∑¥ÁöÑÊ®°ÂûãÂú®Ëã±Êñá„ÄÅÂæ∑Êñá„ÄÅÁæ©Â§ßÂà©ÊñáÂíåËç∑Ëò≠ÊñáÁöÑ DRS Â≠êÂè•ÂíåÂúñÂΩ¢Ëß£Êûê‰∏≠Â±ïÁèæÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÂ∞áÊàëÂÄëÁöÑÊúÄÁµÇÊ®°ÂûãËàáÂÖàÂâçÁöÑÁ†îÁ©∂ÈÄ≤Ë°åÊØîËºÉÔºåÊàëÂÄëÂú®Ê®ôÊ∫ñÂü∫Ê∫ñ‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇÊ≠§Â§ñÔºåË©≥Á¥∞ÁöÑÂàÜÊûêÊèê‰æõ‰∫ÜÂ∞çËß£ÊûêÂô®ÊïàËÉΩÁöÑÊ∑±ÂÖ•Ë¶ãËß£ÔºåÁÇ∫ DRS Ëß£ÊûêÁöÑÊú™‰æÜÁ†îÁ©∂Êèê‰æõ‰∫ÜÈùàÊÑü„ÄÇÊàëÂÄëÊúÉÊåÅÁ∫åÂ∞áÊñ∞ÁöÑÂü∫Ê∫ñÁµêÊûúÊõ¥Êñ∞Âà∞ÈôÑÈåÑ‰∏≠„ÄÇ

##### **LLM and GNN are Complementary: Distilling LLM for Multimodal Graph Learning**
2406.01032v1 by Junjie Xu, Zongyu Wu, Minhua Lin, Xiang Zhang, Suhang Wang

Recent progress in Graph Neural Networks (GNNs) has greatly enhanced the
ability to model complex molecular structures for predicting properties.
Nevertheless, molecular data encompasses more than just graph structures,
including textual and visual information that GNNs do not handle well. To
bridge this gap, we present an innovative framework that utilizes multimodal
molecular data to extract insights from Large Language Models (LLMs). We
introduce GALLON (Graph Learning from Large Language Model Distillation), a
framework that synergizes the capabilities of LLMs and GNNs by distilling
multimodal knowledge into a unified Multilayer Perceptron (MLP). This method
integrates the rich textual and visual data of molecules with the structural
analysis power of GNNs. Extensive experiments reveal that our distilled MLP
model notably improves the accuracy and efficiency of molecular property
predictions.

ÊëòË¶ÅÔºöÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ§ßÂπÖÊèêÂçá‰∫ÜÂª∫Ê®°Ë§áÈõúÂàÜÂ≠êÁµêÊßã‰ª•È†êÊ∏¨ÁâπÊÄßÁöÑËÉΩÂäõ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂàÜÂ≠êË≥áÊñô‰∏çÂè™ÂåÖÂê´ÂúñÂΩ¢ÁµêÊßãÔºåÈÇÑÂåÖÊã¨ GNN ÁÑ°Ê≥ïÂ¶•ÂñÑËôïÁêÜÁöÑÊñáÂ≠óÂíåË¶ñË¶∫Ë≥áË®ä„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊû∂ÊßãÔºåÂà©Áî®Â§öÊ®°ÊÖãÂàÜÂ≠êË≥áÊñôÂæûÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÊèêÂèñË¶ãËß£„ÄÇÊàëÂÄë‰ªãÁ¥π GALLONÔºàÂ§ßÂûãË™ûË®ÄÊ®°ÂûãËêÉÂèñÁöÑÂúñÂΩ¢Â≠∏ÁøíÔºâÔºå‰∏ÄÂÄãÈÄèÈÅéÂ∞áÂ§öÊ®°ÊÖãÁü•Ë≠òËêÉÂèñÂà∞Áµ±‰∏ÄÁöÑÂ§öÂ±§ÊÑüÁü•Âô® (MLP) ‰∏≠ÔºåÂ∞á LLM Âíå GNN ÁöÑÂäüËÉΩÁµêÂêàËµ∑‰æÜÁöÑÊû∂Êßã„ÄÇÊ≠§ÊñπÊ≥ïÂ∞áÂàÜÂ≠êË±êÂØåÁöÑÊñáÂ≠óÂíåË¶ñË¶∫Ë≥áÊñôËàá GNN ÁöÑÁµêÊßãÂàÜÊûêËÉΩÂäõÊï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëËêÉÂèñÁöÑ MLP Ê®°ÂûãÈ°ØËëóÊèêÂçá‰∫ÜÂàÜÂ≠êÁâπÊÄßÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫Â∫¶ÂíåÊïàÁéá„ÄÇ

##### **Presence or Absence: Are Unknown Word Usages in Dictionaries?**
2406.00656v1 by Xianghe Ma, Dominik Schlechtweg, Wei Zhao

In this work, we outline the components and results of our system submitted
to the AXOLOTL-24 shared task for Finnish, Russian and German languages. Our
system is fully unsupervised. It leverages a graph-based clustering approach to
predict mappings between unknown word usages and dictionary entries for Subtask
1, and generates dictionary-like definitions for those novel word usages
through the state-of-the-art Large Language Models such as GPT-4 and LLaMA-3
for Subtask 2. In Subtask 1, our system outperforms the baseline system by a
large margin, and it offers interpretability for the mapping results by
distinguishing between matched and unmatched (novel) word usages through our
graph-based clustering approach. Our system ranks first in Finnish and German,
and ranks second in Russian on the Subtask 2 test-phase leaderboard. These
results show the potential of our system in managing dictionary entries,
particularly for updating dictionaries to include novel sense entries. Our code
and data are made publicly
available\footnote{\url{https://github.com/xiaohemaikoo/axolotl24-ABDN-NLP}}.

ÊëòË¶ÅÔºöÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÊàëÂÄëÊèê‰∫§Áµ¶Ëä¨Ëò≠Ë™û„ÄÅ‰øÑË™ûÂíåÂæ∑Ë™ûË™ûË®ÄÁöÑ AXOLOTL-24 ÂÖ±‰∫´‰ªªÂãôÁöÑÁ≥ªÁµ±ÁµÑÊàêÂíåÁµêÊûú„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±ÂÆåÂÖ®Ê≤íÊúâÁõ£Áù£„ÄÇÂÆÉÂà©Áî®Âü∫ÊñºÂúñÂΩ¢ÁöÑÁæ§ÈõÜÊñπÊ≥ï‰æÜÈ†êÊ∏¨Â≠ê‰ªªÂãô 1 ‰∏≠Êú™Áü•ÂñÆË©ûÁî®Ê≥ïÂíåÂ≠óÂÖ∏Ê¢ùÁõÆ‰πãÈñìÁöÑÂ∞çÊáâÈóú‰øÇÔºå‰∏¶ÈÄöÈÅé GPT-4 Âíå LLaMA-3 Á≠âÊúÄÂÖàÈÄ≤ÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÁÇ∫ÈÄô‰∫õÊñ∞ÂñÆË©ûÁî®Ê≥ïÁîüÊàêÈ°û‰ººÂ≠óÂÖ∏ÁöÑÂÆöÁæ©ÔºåÁî®ÊñºÂ≠ê‰ªªÂãô 2„ÄÇÂú®Â≠ê‰ªªÂãô 1 ‰∏≠ÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±‰ª•Â§ßÂπÖÂÑ™ÊñºÂü∫Ê∫ñÁ≥ªÁµ±Ôºå‰∏¶‰∏îÈÄöÈÅéÊàëÂÄëÁöÑÂü∫ÊñºÂúñÂΩ¢ÁöÑÁæ§ÈõÜÊñπÊ≥ïÂçÄÂàÜÂåπÈÖçÂíå‰∏çÂåπÈÖçÔºàÊñ∞Á©éÔºâÂñÆË©ûÁî®Ê≥ïÔºåÁÇ∫Êò†Â∞ÑÁµêÊûúÊèê‰æõ‰∫ÜËß£ÈáãÊÄß„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Âú®Ëä¨Ëò≠Ë™ûÂíåÂæ∑Ë™û‰∏≠ÊéíÂêçÁ¨¨‰∏ÄÔºåÂú®Â≠ê‰ªªÂãô 2 Ê∏¨Ë©¶ÈöéÊÆµÊéíË°åÊ¶ú‰∏≠ÊéíÂêçÁ¨¨‰∫å„ÄÇÈÄô‰∫õÁµêÊûúÈ°ØÁ§∫‰∫ÜÊàëÂÄëÁöÑÁ≥ªÁµ±Âú®ÁÆ°ÁêÜÂ≠óÂÖ∏Ê¢ùÁõÆÊñπÈù¢ÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÂ∞çÊñºÊõ¥Êñ∞Â≠óÂÖ∏‰ª•ÂåÖÂê´Êñ∞ÁöÑÊÑèÁæ©Ê¢ùÁõÆ„ÄÇÊàëÂÄëÁöÑ‰ª£Á¢ºÂíåÊï∏ÊìöÂ∑≤ÂÖ¨Èñã\footnote{\url{https://github.com/xiaohemaikoo/axolotl24-ABDN-NLP}}„ÄÇ

##### **Harnessing Business and Media Insights with Large Language Models**
2406.06559v1 by Yujia Bao, Ankit Parag Shah, Neeru Narang, Jonathan Rivers, Rajeev Maksey, Lan Guan, Louise N. Barrere, Shelley Evenson, Rahul Basole, Connie Miao, Ankit Mehta, Fabien Boulay, Su Min Park, Natalie E. Pearson, Eldhose Joy, Tiger He, Sumiran Thakur, Koustav Ghosal, Josh On, Phoebe Morrison, Tim Major, Eva Siqi Wang, Gina Escobar, Jiaheng Wei, Tharindu Cyril Weerasooriya, Queena Song, Daria Lashkevich, Clare Chen, Gyuhak Kim, Dengpan Yin, Don Hejna, Mo Nomeli, Wei Wei

This paper introduces Fortune Analytics Language Model (FALM). FALM empowers
users with direct access to comprehensive business analysis, including market
trends, company performance metrics, and expert insights. Unlike generic LLMs,
FALM leverages a curated knowledge base built from professional journalism,
enabling it to deliver precise and in-depth answers to intricate business
questions. Users can further leverage natural language queries to directly
visualize financial data, generating insightful charts and graphs to understand
trends across diverse business sectors clearly. FALM fosters user trust and
ensures output accuracy through three novel methods: 1) Time-aware reasoning
guarantees accurate event registration and prioritizes recent updates. 2)
Thematic trend analysis explicitly examines topic evolution over time,
providing insights into emerging business landscapes. 3) Content referencing
and task decomposition enhance answer fidelity and data visualization accuracy.
We conduct both automated and human evaluations, demonstrating FALM's
significant performance improvements over baseline methods while prioritizing
responsible AI practices. These benchmarks establish FALM as a cutting-edge LLM
in the business and media domains, with exceptional accuracy and
trustworthiness.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥πË≤°ÂØåÂàÜÊûêË™ûË®ÄÊ®°Âûã (FALM)„ÄÇFALM Ë≥¶‰∫à‰ΩøÁî®ËÄÖÁõ¥Êé•Â≠òÂèñÂÖ®Èù¢ÁöÑÂïÜÊ•≠ÂàÜÊûêÔºåÂåÖÊã¨Â∏ÇÂ†¥Ë∂®Âã¢„ÄÅÂÖ¨Âè∏Á∏æÊïàÊåáÊ®ôÂíåÂ∞àÂÆ∂Ë¶ãËß£„ÄÇËàá‰∏ÄËà¨ LLM ‰∏çÂêåÔºåFALM ÈÄèÈÅéÂæûÂ∞àÊ•≠Êñ∞ËÅûÁ∑®Á∫ÇÁöÑÁü•Ë≠òÂ∫´ÔºåÊèê‰æõÁ≤æÊ∫ñ‰∏îÊ∑±ÂÖ•ÁöÑÁ≠îÊ°à‰ª•ÊáâÂ∞çË§áÈõúÁöÑÂïÜÊ•≠ÂïèÈ°å„ÄÇ‰ΩøÁî®ËÄÖÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•Âà©Áî®Ëá™ÁÑ∂Ë™ûË®ÄÊü•Ë©¢Áõ¥Êé•Ë¶ñË¶∫ÂåñË≤°ÂãôË≥áÊñôÔºåÁî¢ÁîüÊúâË¶ãÂú∞ÁöÑÂúñË°®ÂíåÂúñÂΩ¢Ôºå‰ª•Ê∏ÖÊ•ö‰∫ÜËß£‰∏çÂêåÂïÜÊ•≠ÈÉ®ÈñÄÁöÑË∂®Âã¢„ÄÇFALM ÈÄèÈÅé‰∏âÁ®ÆÂâµÊñ∞ÊñπÊ≥ïÂüπÈ§ä‰ΩøÁî®ËÄÖ‰ø°‰ªª‰∏¶Á¢∫‰øùËº∏Âá∫Ê∫ñÁ¢∫ÊÄßÔºö1) ÊôÇÈñìÊÑüÁü•Êé®ÁêÜ‰øùË≠âÊ∫ñÁ¢∫ÁöÑ‰∫ã‰ª∂Ë®ªÂÜä‰∏¶ÂÑ™ÂÖàËôïÁêÜÊúÄËøëÁöÑÊõ¥Êñ∞„ÄÇ2) ‰∏ªÈ°åË∂®Âã¢ÂàÜÊûêÊòéÁ¢∫Âú∞Ê™¢Êü•‰∏ªÈ°åÈö®ÊôÇÈñìÁöÑÊºîËÆäÔºåÊèê‰æõÂ∞çÊñ∞ËààÂïÜÊ•≠Áí∞Â¢ÉÁöÑË¶ãËß£„ÄÇ3) ÂÖßÂÆπÂèÉËÄÉÂíå‰ªªÂãôÂàÜËß£Â¢ûÂº∑Á≠îÊ°à‰øùÁúüÂ∫¶ÂíåË≥áÊñôË¶ñË¶∫ÂåñÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÈÄ≤Ë°åËá™ÂãïÂåñÂíå‰∫∫Â∑•Ë©ï‰º∞ÔºåË≠âÊòé FALM Âú®ÂÑ™ÂÖàËÄÉÊÖÆË≤†Ë≤¨‰ªªÁöÑ AI ÂØ¶ÂãôÁöÑÂêåÊôÇÔºåÂú®ÊïàËÉΩ‰∏äÂ§ßÂπÖÂÑ™ÊñºÂü∫Ê∫ñÊñπÊ≥ï„ÄÇÈÄô‰∫õÂü∫Ê∫ñÂ∞á FALM ÂÆö‰ΩçÁÇ∫ÂïÜÊ•≠ÂíåÂ™íÈ´îÈ†òÂüü‰∏≠Â∞ñÁ´ØÁöÑ LLMÔºåÂÖ∑ÊúâÂçìË∂äÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØ‰ø°Â∫¶„ÄÇ

##### **D-FaST: Cognitive Signal Decoding with Disentangled Frequency-Spatial-Temporal Attention**
2406.02602v1 by Weiguo Chen, Changjian Wang, Kele Xu, Yuan Yuan, Yanru Bai, Dongsong Zhang

Cognitive Language Processing (CLP), situated at the intersection of Natural
Language Processing (NLP) and cognitive science, plays a progressively pivotal
role in the domains of artificial intelligence, cognitive intelligence, and
brain science. Among the essential areas of investigation in CLP, Cognitive
Signal Decoding (CSD) has made remarkable achievements, yet there still exist
challenges related to insufficient global dynamic representation capability and
deficiencies in multi-domain feature integration. In this paper, we introduce a
novel paradigm for CLP referred to as Disentangled Frequency-Spatial-Temporal
Attention(D-FaST). Specifically, we present an novel cognitive signal decoder
that operates on disentangled frequency-space-time domain attention. This
decoder encompasses three key components: frequency domain feature extraction
employing multi-view attention, spatial domain feature extraction utilizing
dynamic brain connection graph attention, and temporal feature extraction
relying on local time sliding window attention. These components are integrated
within a novel disentangled framework. Additionally, to encourage advancements
in this field, we have created a new CLP dataset, MNRED. Subsequently, we
conducted an extensive series of experiments, evaluating D-FaST's performance
on MNRED, as well as on publicly available datasets including ZuCo, BCIC IV-2A,
and BCIC IV-2B. Our experimental results demonstrate that D-FaST outperforms
existing methods significantly on both our datasets and traditional CSD
datasets including establishing a state-of-the-art accuracy score 78.72% on
MNRED, pushing the accuracy score on ZuCo to 78.35%, accuracy score on BCIC
IV-2A to 74.85% and accuracy score on BCIC IV-2B to 76.81%.

ÊëòË¶ÅÔºö<paragraph>Ë™çÁü•Ë™ûË®ÄËôïÁêÜ (CLP) ‰ªãÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåË™çÁü•ÁßëÂ≠∏ÁöÑ‰∫§ÂèâÈªûÔºåÂú®‰∫∫Â∑•Êô∫ÊÖß„ÄÅË™çÁü•Êô∫ÊÖßÂíåËÖ¶ÁßëÂ≠∏È†òÂüüÊâÆÊºîËëóË∂ä‰æÜË∂äÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂú® CLP ÁöÑÂü∫Êú¨Á†îÁ©∂È†òÂüü‰∏≠ÔºåË™çÁü•‰ø°ËôüËß£Á¢º (CSD) Â∑≤ÂèñÂæóÈ°ØËëóÁöÑÊàêÂ∞±Ôºå‰ΩÜ‰ªçÂ≠òÂú®ËàáÂÖ®ÁêÉÂãïÊÖãË°®ÂæµËÉΩÂäõ‰∏çË∂≥ÂíåÂ§öÈ†òÂüüÁâπÂæµÊï¥ÂêàÁº∫Èô∑Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫Ëß£Á≥æÈ†ªÁéáÊôÇÁ©∫Ê≥®ÊÑè (D-FaST) ÁöÑ CLP Êñ∞ÁØÑ‰æã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂú®Ëß£Á≥æÈ†ªÁéáÊôÇÁ©∫ÂüüÊ≥®ÊÑè‰∏äÈÅã‰ΩúÁöÑÊñ∞Ë™çÁü•‰ø°ËôüËß£Á¢ºÂô®„ÄÇÊ≠§Ëß£Á¢ºÂô®ÂåÖÂê´‰∏âÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºöÊé°Áî®Â§öË¶ñËßíÊ≥®ÊÑèÁöÑÈ†ªÂüüÁâπÂæµÊèêÂèñ„ÄÅÂà©Áî®ÂãïÊÖãËÖ¶ÈÄ£Êé•ÂúñÊ≥®ÊÑèÁöÑÁ©∫ÂüüÁâπÂæµÊèêÂèñÔºå‰ª•Âèä‰æùË≥¥ÊñºÂ±ÄÈÉ®ÊôÇÈñìÊªëÂãïË¶ñÁ™óÊ≥®ÊÑèÁöÑÊôÇÈñìÁâπÂæµÊèêÂèñ„ÄÇÈÄô‰∫õÁµÑÊàêÈÉ®ÂàÜÊï¥ÂêàÂú®‰∏ÄÂÄãÊñ∞ÁöÑËß£Á≥æÊ°ÜÊû∂ÂÖß„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫Ü‰øÉÈÄ≤Ë©≤È†òÂüüÁöÑÈÄ≤Â±ïÔºåÊàëÂÄëÂâµÂª∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ CLP Ë≥áÊñôÈõÜ MNRED„ÄÇÈö®ÂæåÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÁ≥ªÂàóÂª£Ê≥õÁöÑÂØ¶È©óÔºåË©ï‰º∞ D-FaST Âú® MNRED ‰∏äÁöÑÊïàËÉΩÔºå‰ª•ÂèäÂú®ÂåÖÊã¨ ZuCo„ÄÅBCIC IV-2A Âíå BCIC IV-2B Âú®ÂÖßÁöÑÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåD-FaST Âú®ÊàëÂÄëËá™Â∑±ÁöÑË≥áÊñôÈõÜÂíåÂÇ≥Áµ± CSD Ë≥áÊñôÈõÜ‰∏äÈÉΩÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåÂåÖÊã¨Âú® MNRED ‰∏äÂª∫Á´ã‰∫Ü 78.72% ÁöÑÊúÄÊñ∞Ê∫ñÁ¢∫Â∫¶ÂàÜÊï∏ÔºåÂ∞á ZuCo ‰∏äÁöÑÊ∫ñÁ¢∫Â∫¶ÂàÜÊï∏Êé®È´òËá≥ 78.35%ÔºåBCIC IV-2A ‰∏äÁöÑÊ∫ñÁ¢∫Â∫¶ÂàÜÊï∏Êé®È´òËá≥ 74.85%ÔºåBCIC IV-2B ‰∏äÁöÑÊ∫ñÁ¢∫Â∫¶ÂàÜÊï∏Êé®È´òËá≥ 76.81%„ÄÇ</paragraph>

##### **KGLink: A column type annotation method that combines knowledge graph and pre-trained language model**
2406.00318v1 by Yubo Wang, Hao Xin, Lei Chen

The semantic annotation of tabular data plays a crucial role in various
downstream tasks. Previous research has proposed knowledge graph (KG)-based and
deep learning-based methods, each with its inherent limitations. KG-based
methods encounter difficulties annotating columns when there is no match for
column cells in the KG. Moreover, KG-based methods can provide multiple
predictions for one column, making it challenging to determine the semantic
type with the most suitable granularity for the dataset. This type granularity
issue limits their scalability.
  On the other hand, deep learning-based methods face challenges related to the
valuable context missing issue. This occurs when the information within the
table is insufficient for determining the correct column type.
  This paper presents KGLink, a method that combines WikiData KG information
with a pre-trained deep learning language model for table column annotation,
effectively addressing both type granularity and valuable context missing
issues. Through comprehensive experiments on widely used tabular datasets
encompassing numeric and string columns with varying type granularity, we
showcase the effectiveness and efficiency of KGLink. By leveraging the
strengths of KGLink, we successfully surmount challenges related to type
granularity and valuable context issues, establishing it as a robust solution
for the semantic annotation of tabular data.

ÊëòË¶ÅÔºöË°®Ê†ºË≥áÊñôÁöÑË™ûÊÑèÊ®ôË®ªÂú®ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÊâÆÊºîÈóúÈçµËßíËâ≤„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÊèêÂá∫‰∫ÜÂü∫ÊñºÁü•Ë≠òÂúñË≠ú (KG) ÂíåÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÊØèÁ®ÆÊñπÊ≥ïÈÉΩÊúâÂÖ∂Âõ∫ÊúâÁöÑÈôêÂà∂„ÄÇÁï∂ KG ‰∏≠Ê≤íÊúâËàáÊ¨Ñ‰ΩçÂÑ≤Â≠òÊ†ºÁõ∏Á¨¶ÊôÇÔºåÂü∫Êñº KG ÁöÑÊñπÊ≥ïÊúÉÈÅáÂà∞Ê®ôË®ªÊ¨Ñ‰ΩçÁöÑÂõ∞Èõ£„ÄÇÊ≠§Â§ñÔºåÂü∫Êñº KG ÁöÑÊñπÊ≥ïÂèØ‰ª•ÁÇ∫‰∏ÄÂÄãÊ¨Ñ‰ΩçÊèê‰æõÂ§öÂÄãÈ†êÊ∏¨ÔºåÈÄô‰ΩøÂæóÈõ£‰ª•Á¢∫ÂÆöÂ∞çË≥áÊñôÈõÜÊúÄÈÅ©ÂêàÁöÑË™ûÊÑèÈ°ûÂûãËàáÁ≤íÂ∫¶„ÄÇÈÄôÁ®ÆÈ°ûÂûãÁ≤íÂ∫¶ÂïèÈ°åÈôêÂà∂‰∫ÜÂÖ∂ÂèØÊì¥ÂÖÖÊÄß„ÄÇ
Âè¶‰∏ÄÊñπÈù¢ÔºåÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÈù¢Ëá®ËàáÈÅ∫Â§±ÊúâÂÉπÂÄºÁöÑÂÖßÂÆπÁõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÁï∂Ë°®Ê†º‰∏≠ÁöÑË≥áË®ä‰∏çË∂≥‰ª•Á¢∫ÂÆöÊ≠£Á¢∫ÁöÑÊ¨Ñ‰ΩçÈ°ûÂûãÊôÇÔºåÂ∞±ÊúÉÁôºÁîüÈÄôÁ®ÆÊÉÖÊ≥Å„ÄÇ
Êú¨ÊñáÊèêÂá∫ KGLinkÔºå‰∏ÄÁ®ÆÁµêÂêà WikiData KG Ë≥áË®äËàáÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ∑±Â∫¶Â≠∏ÁøíË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åË°®Ê†ºÊ¨Ñ‰ΩçÊ®ôË®ªÁöÑÊñπÊ≥ïÔºåÊúâÊïàÂú∞Ëß£Ê±∫È°ûÂûãÁ≤íÂ∫¶ÂíåÈÅ∫Â§±ÊúâÂÉπÂÄºÁöÑÂÖßÂÆπÈÄôÂÖ©ÂÄãÂïèÈ°å„ÄÇÈÄèÈÅéÂú®Âª£Ê≥õ‰ΩøÁî®ÁöÑË°®Ê†ºË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ∑Êúâ‰∏çÂêåÈ°ûÂûãÁ≤íÂ∫¶ÁöÑÊï∏Â≠óÂíåÂ≠ó‰∏≤Ê¨Ñ‰ΩçÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü KGLink ÁöÑÊúâÊïàÊÄßÂíåÊïàÁéá„ÄÇÈÄèÈÅéÂà©Áî® KGLink ÁöÑÂÑ™ÈªûÔºåÊàëÂÄëÊàêÂäüÂÖãÊúç‰∫ÜËàáÈ°ûÂûãÁ≤íÂ∫¶ÂíåÊúâÂÉπÂÄºÁöÑÂÖßÂÆπÂïèÈ°åÁõ∏ÈóúÁöÑÊåëÊà∞ÔºåÂ∞áÂÖ∂Á¢∫Á´ãÁÇ∫Ë°®Ê†ºË≥áÊñôË™ûÊÑèÊ®ôË®ªÁöÑÂº∑Â§ßËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Joint Embeddings for Graph Instruction Tuning**
2405.20684v1 by Vlad Argatu, Aaron Haag, Oliver Lohse

Large Language Models (LLMs) have achieved impressive performance in text
understanding and have become an essential tool for building smart assistants.
Originally focusing on text, they have been enhanced with multimodal
capabilities in recent works that successfully built visual instruction
following assistants. As far as the graph modality goes, however, no such
assistants have yet been developed. Graph structures are complex in that they
represent relation between different features and are permutation invariant.
Moreover, representing them in purely textual form does not always lead to good
LLM performance even for finetuned models. As a result, there is a need to
develop a new method to integrate graphs in LLMs for general graph
understanding. This work explores the integration of the graph modality in LLM
for general graph instruction following tasks. It aims at producing a deep
learning model that enhances an underlying LLM with graph embeddings and trains
it to understand them and to produce, given an instruction, an answer grounded
in the graph representation. The approach performs significantly better than a
graph to text approach and remains consistent even for larger graphs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÊñáÂ≠óÁêÜËß£ÊñπÈù¢ÂèñÂæó‰ª§‰∫∫È©öËâ∑ÁöÑË°®ÁèæÔºå‰∏¶Â∑≤ÊàêÁÇ∫Âª∫ÊßãÊô∫ÊÖßÂä©ÁêÜÁöÑÂøÖË¶ÅÂ∑•ÂÖ∑„ÄÇÂéüÊú¨Â∞àÊ≥®ÊñºÊñáÂ≠óÔºåÂÆÉÂÄëÂú®ËøëÊúüÁöÑ‰ΩúÂìÅ‰∏≠Â∑≤ÈÄèÈÅéÂ§öÊ®°ÂºèÂäüËÉΩÂæóÂà∞Âä†Âº∑ÔºåÊàêÂäüÂª∫ÊßãÂá∫Ë¶ñË¶∫Êåá‰ª§ËøΩËπ§Âä©ÁêÜ„ÄÇÁÑ∂ËÄåÔºåÂ∞±ÂúñÂΩ¢Ê®°ÂºèËÄåË®ÄÔºåÁõÆÂâçÂ∞öÊú™ÈñãÁôºÂá∫Ê≠§È°ûÂä©ÁêÜ„ÄÇÂúñÂΩ¢ÁµêÊßãÂæàË§áÈõúÔºåÂú®ÊñºÂÆÉÂÄëË°®Á§∫‰∏çÂêåÁâπÂæµ‰πãÈñìÁöÑÈóú‰øÇÔºå‰∏îÂÖ∑ÊúâÊéíÂàó‰∏çËÆäÊÄß„ÄÇÊ≠§Â§ñÔºåÂç≥‰ΩøÂ∞çÊñºÂæÆË™øÊ®°ÂûãÔºåÂ∞áÂÆÉÂÄëË°®Á§∫ÊàêÁ¥îÁ≤πÁöÑÊñáÂ≠óÂΩ¢Âºè‰∏¶ÈùûÁ∏ΩÊòØËÉΩÂ∏∂‰æÜËâØÂ•ΩÁöÑ LLM ÊïàËÉΩ„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶ÅÈñãÁôº‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂ∞áÂúñÂΩ¢Êï¥ÂêàÂà∞ LLM ‰∏≠Ôºå‰ª•ÈÄ≤Ë°å‰∏ÄËà¨ÁöÑÂúñÂΩ¢ÁêÜËß£„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é LLM ‰∏≠ÂúñÂΩ¢Ê®°ÂºèÁöÑÊï¥ÂêàÔºå‰ª•ÈÄ≤Ë°å‰∏ÄËà¨ÁöÑÂúñÂΩ¢Êåá‰ª§ËøΩËπ§‰ªªÂãô„ÄÇÂÖ∂ÁõÆÊ®ôÊòØÁî¢Áîü‰∏ÄÂÄãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÈÄèÈÅéÂúñÂΩ¢ÂµåÂÖ•Â¢ûÂº∑Âü∫Á§é LLMÔºå‰∏¶Ë®ìÁ∑¥ÂÆÉ‰∫ÜËß£ÂúñÂΩ¢ÂµåÂÖ•Ôºå‰∏¶Ê†πÊìöÊåá‰ª§Áî¢Áîü‰ª•ÂúñÂΩ¢Ë°®Á§∫ÁÇ∫Âü∫Á§éÁöÑÁ≠îÊ°à„ÄÇÊ≠§ÊñπÊ≥ïÁöÑË°®ÁèæÈ°ØËëóÂÑ™ÊñºÊñáÂ≠óÂà∞ÊñáÂ≠óÁöÑÊñπÊ≥ïÔºåÂç≥‰ΩøÂ∞çÊñºËºÉÂ§ßÁöÑÂúñÂΩ¢‰πüËÉΩ‰øùÊåÅ‰∏ÄËá¥ÊÄß„ÄÇ

##### **KerasCV and KerasNLP: Vision and Language Power-Ups**
2405.20247v3 by Matthew Watson, Divyashree Shivakumar Sreepathihalli, Francois Chollet, Martin Gorner, Kiranbir Sodhia, Ramesh Sampath, Tirth Patel, Haifeng Jin, Neel Kovelamudi, Gabriel Rasskin, Samaneh Saadat, Luke Wood, Chen Qian, Jonathan Bischof, Ian Stenbit, Abheesht Sharma, Anshuman Mishra

We present the Keras domain packages KerasCV and KerasNLP, extensions of the
Keras API for Computer Vision and Natural Language Processing workflows,
capable of running on either JAX, TensorFlow, or PyTorch. These domain packages
are designed to enable fast experimentation, with a focus on ease-of-use and
performance. We adopt a modular, layered design: at the library's lowest level
of abstraction, we provide building blocks for creating models and data
preprocessing pipelines, and at the library's highest level of abstraction, we
provide pretrained ``task" models for popular architectures such as Stable
Diffusion, YOLOv8, GPT2, BERT, Mistral, CLIP, Gemma, T5, etc. Task models have
built-in preprocessing, pretrained weights, and can be fine-tuned on raw
inputs. To enable efficient training, we support XLA compilation for all
models, and run all preprocessing via a compiled graph of TensorFlow operations
using the tf.data API. The libraries are fully open-source (Apache 2.0 license)
and available on GitHub.

ÊëòË¶ÅÔºöÊàëÂÄëÂ±ïÁ§∫ Keras È†òÂüüÂ•ó‰ª∂ KerasCV Âíå KerasNLPÔºåÂÆÉÂÄëÊòØ Keras API ÁöÑÂª∂‰º∏ÔºåÈÅ©Áî®ÊñºÈõªËÖ¶Ë¶ñË¶∫ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂ∑•‰ΩúÊµÅÁ®ãÔºåÂèØ‰ª•Âú® JAX„ÄÅTensorFlow Êàñ PyTorch ‰∏äÂü∑Ë°å„ÄÇÈÄô‰∫õÈ†òÂüüÂ•ó‰ª∂Êó®Âú®ÂØ¶ÁèæÂø´ÈÄüÂØ¶È©óÔºåËëóÈáçÊñºÊòìÁî®ÊÄßÂíåÊïàËÉΩ„ÄÇÊàëÂÄëÊé°Áî®Ê®°ÁµÑÂåñ„ÄÅÂàÜÂ±§Ë®≠Ë®àÔºöÂú®Á®ãÂºèÂ∫´ÊúÄ‰ΩéÁöÑÊäΩË±°Â±§Á¥öÔºåÊàëÂÄëÊèê‰æõÂª∫Á´ãÊ®°ÂûãÂíåË≥áÊñôÈ†êËôïÁêÜÁÆ°Á∑öÁöÑÂª∫ÊßãÂçÄÂ°äÔºåÂú®Á®ãÂºèÂ∫´ÊúÄÈ´òÁöÑÊäΩË±°Â±§Á¥öÔºåÊàëÂÄëÊèê‰æõÈ†êÂÖàË®ìÁ∑¥Â•ΩÁöÑ„Äå‰ªªÂãô„ÄçÊ®°ÂûãÔºåÈÅ©Áî®ÊñºÁÜ±ÈñÄÊû∂ÊßãÔºå‰æãÂ¶Ç Stable Diffusion„ÄÅYOLOv8„ÄÅGPT2„ÄÅBERT„ÄÅMistral„ÄÅCLIP„ÄÅGemma„ÄÅT5 Á≠â„ÄÇ‰ªªÂãôÊ®°ÂûãÂÖ∑ÂÇôÂÖßÂª∫È†êËôïÁêÜ„ÄÅÈ†êÂÖàË®ìÁ∑¥Â•ΩÁöÑÊ¨äÈáçÔºåÂèØ‰ª•Âú®ÂéüÂßãËº∏ÂÖ•‰∏äÈÄ≤Ë°åÂæÆË™ø„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÈ´òÊïàË®ìÁ∑¥ÔºåÊàëÂÄëÊîØÊè¥ÊâÄÊúâÊ®°ÂûãÁöÑ XLA Á∑®Ë≠ØÔºå‰∏¶‰ΩøÁî® tf.data API ÈÄèÈÅé TensorFlow ‰ΩúÊ•≠ÁöÑÁ∑®Ë≠ØÂúñË°®Âü∑Ë°åÊâÄÊúâÈ†êËôïÁêÜ„ÄÇÈÄô‰∫õÁ®ãÂºèÂ∫´ÂÆåÂÖ®ÈñãÊîæÂéüÂßãÁ¢ºÔºàApache 2.0 ÊéàÊ¨äÔºâÔºå‰∏¶Âú® GitHub ‰∏äÊèê‰æõ„ÄÇ

##### **Grokfast: Accelerated Grokking by Amplifying Slow Gradients**
2405.20233v2 by Jaerin Lee, Bong Gyun Kang, Kihoon Kim, Kyoung Mu Lee

One puzzling artifact in machine learning dubbed grokking is where delayed
generalization is achieved tenfolds of iterations after near perfect
overfitting to the training data. Focusing on the long delay itself on behalf
of machine learning practitioners, our goal is to accelerate generalization of
a model under grokking phenomenon. By regarding a series of gradients of a
parameter over training iterations as a random signal over time, we can
spectrally decompose the parameter trajectories under gradient descent into two
components: the fast-varying, overfitting-yielding component and the
slow-varying, generalization-inducing component. This analysis allows us to
accelerate the grokking phenomenon more than $\times 50$ with only a few lines
of code that amplifies the slow-varying components of gradients. The
experiments show that our algorithm applies to diverse tasks involving images,
languages, and graphs, enabling practical availability of this peculiar
artifact of sudden generalization. Our code is available at
https://github.com/ironjr/grokfast.

ÊëòË¶ÅÔºöÂú®Ê©üÂô®Â≠∏Áøí‰∏≠Ôºå‰∏ÄÂÄã‰ª§‰∫∫Ë≤ªËß£ÁöÑ‰∫∫Â∑•Ë£ΩÂìÅË¢´Á®±ÁÇ∫„ÄåÈ†ìÊÇü„ÄçÔºåÂú®Ëøë‰πéÂÆåÁæéÂú∞ÈÅéÂ∫¶Êì¨ÂêàË®ìÁ∑¥Ë≥áÊñôÂæåÔºåÂª∂ÈÅ≤ÁöÑÊ≥õÂåñÂú®ÂèçË¶ÜÈÅãÁÆóÂçÅÂÄçÂæåÊâçÂæó‰ª•ÂØ¶Áèæ„ÄÇÂ∞àÊ≥®ÊñºÊ©üÂô®Â≠∏ÁøíÂæûÊ•≠ËÄÖÊú¨Ë∫´ÁöÑÈï∑ÊôÇÈñìÂª∂ÈÅ≤ÔºåÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÂä†ÈÄüÂú®È†ìÊÇüÁèæË±°‰∏ãÊ®°ÂûãÁöÑÊ≥õÂåñ„ÄÇÈÄèÈÅéÂ∞áÂèÉÊï∏Âú®Ë®ìÁ∑¥ÂèçË¶ÜÈÅãÁÆó‰∏≠ÁöÑ‰∏ÄÁ≥ªÂàóÊ¢ØÂ∫¶Ë¶ñÁÇ∫Èö®ÊôÇÈñìËÆäÂåñÁöÑÈö®Ê©üË®äËôüÔºåÊàëÂÄëÂèØ‰ª•Â∞áÊ¢ØÂ∫¶‰∏ãÈôç‰∏ãÁöÑÂèÉÊï∏ËªåË∑°ÂàÜËß£ÁÇ∫ÂÖ©ÂÄãÁµÑÊàêÈÉ®ÂàÜÔºöËÆäÂåñÂø´ÈÄüÁöÑÈÅéÂ∫¶Êì¨ÂêàÁî¢ÁîüÁµÑÊàêÈÉ®ÂàÜÂíåËÆäÂåñÁ∑©ÊÖ¢ÁöÑÊ≥õÂåñË™òÁôºÁµÑÊàêÈÉ®ÂàÜ„ÄÇÈÄôÂÄãÂàÜÊûêËÆìÊàëÂÄëËÉΩÂ§†‰ª•ÂÉÖÂÉÖÂπæË°åÁ®ãÂºèÁ¢º‰æÜÂä†ÈÄüÈ†ìÊÇüÁèæË±°Ë∂ÖÈÅé 50 ÂÄçÔºåÈÄô‰∫õÁ®ãÂºèÁ¢ºÊúÉÊîæÂ§ßÊ¢ØÂ∫¶ÁöÑËÆäÂåñÁ∑©ÊÖ¢ÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂØ¶È©óÈ°ØÁ§∫ÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÈÅ©Áî®ÊñºÊ∂âÂèäÂΩ±ÂÉè„ÄÅË™ûË®ÄÂíåÂúñÂΩ¢ÁöÑÂêÑÁ®Æ‰ªªÂãôÔºåËÆìÈÄôÂÄãÁ™ÅÁÑ∂Ê≥õÂåñÁöÑÁâπÊÆä‰∫∫Â∑•Ë£ΩÂìÅÂæó‰ª•ÂØ¶Èöõ‰ΩøÁî®„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØ‰ª•Âú® https://github.com/ironjr/grokfast ÂèñÂæó„ÄÇ

##### **Reasoning about concepts with LLMs: Inconsistencies abound**
2405.20163v1 by Rosario Uceda-Sosa, Karthikeyan Natesan Ramamurthy, Maria Chang, Moninder Singh

The ability to summarize and organize knowledge into abstract concepts is key
to learning and reasoning. Many industrial applications rely on the consistent
and systematic use of concepts, especially when dealing with decision-critical
knowledge. However, we demonstrate that, when methodically questioned, large
language models (LLMs) often display and demonstrate significant
inconsistencies in their knowledge. Computationally, the basic aspects of the
conceptualization of a given domain can be represented as Is-A hierarchies in a
knowledge graph (KG) or ontology, together with a few properties or axioms that
enable straightforward reasoning. We show that even simple ontologies can be
used to reveal conceptual inconsistencies across several LLMs. We also propose
strategies that domain experts can use to evaluate and improve the coverage of
key domain concepts in LLMs of various sizes. In particular, we have been able
to significantly enhance the performance of LLMs of various sizes with openly
available weights using simple knowledge-graph (KG) based prompting strategies.

ÊëòË¶ÅÔºöÊëòË¶ÅÂíåÁµÑÁπîÁü•Ë≠òÊàêÁÇ∫ÊäΩË±°Ê¶ÇÂøµÁöÑËÉΩÂäõÊòØÂ≠∏ÁøíÂíåÊé®ÁêÜÁöÑÈóúÈçµ„ÄÇË®±Â§öÁî¢Ê•≠ÊáâÁî®‰ª∞Ë≥¥Ê¶ÇÂøµÁöÑ‰∏ÄËá¥‰∏îÁ≥ªÁµ±ÊÄß‰ΩøÁî®ÔºåÁâπÂà•ÊòØÂú®ËôïÁêÜÊ±∫Á≠ñÈóúÈçµÁü•Ë≠òÊôÇ„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëË≠âÊòéÔºåÁï∂Á∂ìÈÅéÊúâÁ≥ªÁµ±Âú∞Ë≥™ÁñëÊôÇÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Á∂ìÂ∏∏È°ØÁ§∫‰∏¶Â±ïÁ§∫ÂÖ∂Áü•Ë≠ò‰∏≠ÁöÑÈáçÂ§ß‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÂú®Ë®àÁÆó‰∏äÔºåÁµ¶ÂÆöÈ†òÂüüÁöÑÊ¶ÇÂøµÂåñÁöÑÂü∫Êú¨Èù¢ÂêëÂèØ‰ª•Áî®Áü•Ë≠òÂúñË≠ú (KG) ÊàñÊú¨È´îË´ñ‰∏≠ÁöÑ Is-A ÈöéÂ±§‰æÜË°®Á§∫Ôºå‰ª•Âèä‰∏Ä‰∫õÂ±¨ÊÄßÊàñÂÖ¨ÁêÜÔºåÈÄô‰∫õÂ±¨ÊÄßÊàñÂÖ¨ÁêÜËÉΩÈÄ≤Ë°åÁõ¥Êé•Êé®ÁêÜ„ÄÇÊàëÂÄëË≠âÊòéÔºåÂç≥‰ΩøÊòØÁ∞°ÂñÆÁöÑÊú¨È´îË´ñ‰πüËÉΩÁî®‰æÜÊè≠Èú≤Ë∑®Â§öÂÄã LLM ÁöÑÊ¶ÇÂøµ‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÊàëÂÄë‰πüÊèêÂá∫È†òÂüüÂ∞àÂÆ∂ÂèØ‰ª•Áî®‰æÜË©ï‰º∞ÂíåÊîπÂñÑÂêÑÁ®ÆË¶èÊ®° LLM ‰∏≠ÈóúÈçµÈ†òÂüüÊ¶ÇÂøµÊ∂µËìãÁØÑÂúçÁöÑÁ≠ñÁï•„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂ∑≤Á∂ìËÉΩÂ§†‰ΩøÁî®Âü∫ÊñºÁ∞°ÂñÆÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÊèêÁ§∫Á≠ñÁï•ÔºåÂ§ßÂπÖÊèêÂçáÂêÑÁ®ÆË¶èÊ®° LLM ÁöÑÊÄßËÉΩÔºåÈÄô‰∫õ LLM ‰ΩøÁî®ÈñãÊîæÂèØÁî®ÁöÑÊ¨äÈáç„ÄÇ

##### **GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning**
2405.20139v1 by Costas Mavromatis, George Karypis

Knowledge Graphs (KGs) represent human-crafted factual knowledge in the form
of triplets (head, relation, tail), which collectively form a graph. Question
Answering over KGs (KGQA) is the task of answering natural questions grounding
the reasoning to the information provided by the KG. Large Language Models
(LLMs) are the state-of-the-art models for QA tasks due to their remarkable
ability to understand natural language. On the other hand, Graph Neural
Networks (GNNs) have been widely used for KGQA as they can handle the complex
graph information stored in the KG. In this work, we introduce GNN-RAG, a novel
method for combining language understanding abilities of LLMs with the
reasoning abilities of GNNs in a retrieval-augmented generation (RAG) style.
First, a GNN reasons over a dense KG subgraph to retrieve answer candidates for
a given question. Second, the shortest paths in the KG that connect question
entities and answer candidates are extracted to represent KG reasoning paths.
The extracted paths are verbalized and given as input for LLM reasoning with
RAG. In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to
extract useful graph information, while the LLM leverages its natural language
processing ability for ultimate KGQA. Furthermore, we develop a retrieval
augmentation (RA) technique to further boost KGQA performance with GNN-RAG.
Experimental results show that GNN-RAG achieves state-of-the-art performance in
two widely used KGQA benchmarks (WebQSP and CWQ), outperforming or matching
GPT-4 performance with a 7B tuned LLM. In addition, GNN-RAG excels on multi-hop
and multi-entity questions outperforming competing approaches by 8.9--15.5%
points at answer F1.

ÊëòË¶ÅÔºö<paragraph>Áü•Ë≠òÂúñË≠ú (KG) ‰ª•‰∏âÂÖÉÁµÑ (‰∏ªË©û„ÄÅÈóú‰øÇ„ÄÅË≥ìË©û) ÁöÑÂΩ¢ÂºèË°®Á§∫‰∫∫Â∑•Âª∫Á´ãÁöÑ‰∫ãÂØ¶Áü•Ë≠òÔºåÈÄô‰∫õ‰∏âÂÖÉÁµÑÂÖ±ÂêåÂΩ¢Êàê‰∏ÄÂÄãÂúñÂΩ¢„ÄÇÂú® KG ‰∏äÈÄ≤Ë°åÂïèÁ≠î (KGQA) ÊòØÂõûÁ≠îËá™ÁÑ∂ÂïèÈ°åÁöÑ‰ªªÂãôÔºåÂ∞áÊé®ÁêÜÂü∫Á§éÂª∫Á´ãÂú® KG Êèê‰æõÁöÑË≥áË®ä‰∏ä„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî±ÊñºÂÖ∂ÁêÜËß£Ëá™ÁÑ∂Ë™ûË®ÄÁöÑÈùûÂá°ËÉΩÂäõÔºåÊàêÁÇ∫ÂïèÁ≠î‰ªªÂãôÁöÑÊúÄÊñ∞ÊäÄË°ì„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Â∑≤Âª£Ê≥õÁî®Êñº KGQAÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂèØ‰ª•ËôïÁêÜÂÑ≤Â≠òÂú® KG ‰∏≠ÁöÑË§áÈõúÂúñÂΩ¢Ë≥áË®ä„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü GNN-RAGÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÁµêÂêà‰∫Ü LLM ÁöÑË™ûË®ÄÁêÜËß£ËÉΩÂäõÂíå GNN ÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊé°Áî®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÁöÑÊñπÂºè„ÄÇÈ¶ñÂÖàÔºåGNN Âú®‰∏ÄÂÄãÂØÜÈõÜÁöÑ KG Â≠êÂúñ‰∏≠ÈÄ≤Ë°åÊé®ÁêÜÔºå‰ª•Ê™¢Á¥¢Áµ¶ÂÆöÂïèÈ°åÁöÑÁ≠îÊ°àÂÄôÈÅ∏„ÄÇÂÖ∂Ê¨°ÔºåÊèêÂèñ KG ‰∏≠ÈÄ£Êé•ÂïèÈ°åÂØ¶È´îÂíåÁ≠îÊ°àÂÄôÈÅ∏ÁöÑÊúÄÁü≠Ë∑ØÂæëÔºå‰ª•Ë°®Á§∫ KG Êé®ÁêÜË∑ØÂæë„ÄÇÊèêÂèñÁöÑË∑ØÂæëÊúÉË¢´Âè£È†≠ÂåñÔºå‰∏¶‰ΩúÁÇ∫Ëº∏ÂÖ•Êèê‰æõÁµ¶ LLMÔºå‰ª•‰æø‰ΩøÁî® RAG ÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÂú®ÊàëÂÄëÁöÑ GNN-RAG Ê°ÜÊû∂‰∏≠ÔºåGNN ‰ΩúÁÇ∫‰∏ÄÂÄãÂØÜÈõÜÂ≠êÂúñÊé®ÁêÜÂô®ÔºåÁî®ÊñºÊèêÂèñÊúâÁî®ÁöÑÂúñÂΩ¢Ë≥áË®äÔºåËÄå LLM ÂâáÂà©Áî®ÂÖ∂Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜËÉΩÂäõÈÄ≤Ë°åÊúÄÁµÇÁöÑ KGQA„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊ™¢Á¥¢Â¢ûÂº∑ (RA) ÊäÄË°ìÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÂçá GNN-RAG ÁöÑ KGQA ÊïàËÉΩ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåGNN-RAG Âú®ÂÖ©ÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑ KGQA Âü∫Ê∫ñ (WebQSP Âíå CWQ) ‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂú®‰ΩøÁî® 7B Ë™øÊï¥ÂæåÁöÑ LLM ‰∏≠Ë∂ÖË∂äÊàñÂåπÈÖç GPT-4 ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåGNN-RAG Âú®Â§öË∑≥ÂíåÂ§öÂØ¶È´îÂïèÈ°å‰∏äË°®ÁèæÂá∫Ëâ≤ÔºåÂú®Á≠îÊ°à F1 ‰∏äÊØîÁ´∂Áà≠ÊñπÊ≥ïÈ´òÂá∫ 8.9--15.5%„ÄÇ</paragraph>

##### **MM-Lego: Modular Biomedical Multimodal Models with Minimal Fine-Tuning**
2405.19950v1 by Konstantin Hemker, Nikola Simidjievski, Mateja Jamnik

Learning holistic computational representations in physical, chemical or
biological systems requires the ability to process information from different
distributions and modalities within the same model. Thus, the demand for
multimodal machine learning models has sharply risen for modalities that go
beyond vision and language, such as sequences, graphs, time series, or tabular
data. While there are many available multimodal fusion and alignment
approaches, most of them require end-to-end training, scale quadratically with
the number of modalities, cannot handle cases of high modality imbalance in the
training set, or are highly topology-specific, making them too restrictive for
many biomedical learning tasks. This paper presents Multimodal Lego (MM-Lego),
a modular and general-purpose fusion and model merging framework to turn any
set of encoders into a competitive multimodal model with no or minimal
fine-tuning. We achieve this by introducing a wrapper for unimodal encoders
that enforces lightweight dimensionality assumptions between modalities and
harmonises their representations by learning features in the frequency domain
to enable model merging with little signal interference. We show that MM-Lego
1) can be used as a model merging method which achieves competitive performance
with end-to-end fusion models without any fine-tuning, 2) can operate on any
unimodal encoder, and 3) is a model fusion method that, with minimal
fine-tuning, achieves state-of-the-art results on six benchmarked multimodal
biomedical tasks.

ÊëòË¶ÅÔºöÂú®Áâ©ÁêÜ„ÄÅÂåñÂ≠∏ÊàñÁîüÁâ©Á≥ªÁµ±‰∏≠Â≠∏ÁøíÊï¥È´îË®àÁÆóË°®Á§∫Ê≥ïÈúÄË¶ÅËôïÁêÜ‰æÜËá™Âêå‰∏ÄÊ®°Âûã‰∏≠‰∏çÂêåÂàÜ‰ΩàÂíåÊ®°ÂºèÁöÑË≥áË®äÁöÑËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåÂ∞çÊñºË∂ÖË∂äË¶ñË¶∫ÂíåË™ûË®ÄÁöÑÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÈúÄÊ±ÇÊÄ•Âäá‰∏äÂçáÔºå‰æãÂ¶ÇÂ∫èÂàó„ÄÅÂúñÂΩ¢„ÄÅÊôÇÈñìÂ∫èÂàóÊàñË°®Ê†ºË≥áÊñô„ÄÇÂÑòÁÆ°ÊúâË®±Â§öÂèØÁî®ÁöÑÂ§öÊ®°ÊÖãËûçÂêàÂíåÂ∞çÈΩäÊñπÊ≥ïÔºå‰ΩÜÂÆÉÂÄëÂ§ßÂ§öÈúÄË¶ÅÁ´ØÂà∞Á´ØË®ìÁ∑¥„ÄÅÈö®ËëóÊ®°ÊÖãÊï∏ÈáèÁöÑÂ¢ûÂä†ËÄåÂëà‰∫åÊ¨°ÊñπÊì¥ÂÖÖ„ÄÅÁÑ°Ê≥ïËôïÁêÜË®ìÁ∑¥ÈõÜ‰∏≠È´òÊ®°ÊÖã‰∏çÂπ≥Ë°°ÁöÑÊÉÖÊ≥ÅÔºåÊàñÂÖ∑ÊúâÈ´òÂ∫¶ÊãìÊí≤ÁâπÂÆöÊÄßÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂ∞çÊñºË®±Â§öÁîüÁâ©ÈÜ´Â≠∏Â≠∏Áøí‰ªªÂãô‰æÜË™™ÈÅéÊñºÂö¥Ê†º„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜÂ§öÊ®°ÊÖãÊ®ÇÈ´òÔºàMM-LegoÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÊ®°ÁµÑÂåñ‰∏îÈÄöÁî®ÁöÑËûçÂêàÂíåÊ®°ÂûãÂêà‰ΩµÊ°ÜÊû∂ÔºåÂèØ‰ª•Â∞á‰ªª‰Ωï‰∏ÄÁµÑÁ∑®Á¢ºÂô®ËΩâÊèõÁÇ∫ÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÂ§öÊ®°ÊÖãÊ®°ÂûãÔºåËÄåÁÑ°ÈúÄÊàñÂè™ÈúÄÊúÄÂ∞ëÁöÑÂæÆË™ø„ÄÇÊàëÂÄëÈÄöÈÅéÂºïÂÖ•‰∏ÄÂÄãÂñÆÊ®°ÊÖãÁ∑®Á¢ºÂô®ÁöÑÂåÖË£ùÂô®‰æÜÂØ¶ÁèæÈÄô‰∏ÄÈªûÔºåË©≤ÂåÖË£ùÂô®Âú®Ê®°ÊÖã‰πãÈñìÂü∑Ë°åËºïÈáèÁ¥öÁ∂≠Â∫¶ÂÅáË®≠Ôºå‰∏¶ÈÄöÈÅéÂú®È†ªÂüü‰∏≠Â≠∏ÁøíÁâπÂæµ‰æÜÂçîË™øÂÆÉÂÄëÁöÑË°®Á§∫ÔºåÂæûËÄåÂØ¶ÁèæÊ®°ÂûãÂêà‰ΩµÔºåÂêåÊôÇÂπæ‰πé‰∏çÊúÉÁî¢ÁîüË®äËôüÂπ≤Êìæ„ÄÇÊàëÂÄëË°®Êòé MM-Lego 1) ÂèØ‰ª•Áî®‰ΩúÊ®°ÂûãÂêà‰ΩµÊñπÊ≥ïÔºåÂú®‰∏çÈÄ≤Ë°å‰ªª‰ΩïÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæËàáÁ´ØÂà∞Á´ØËûçÂêàÊ®°ÂûãÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩÔºå2) ÂèØ‰ª•Êìç‰Ωú‰ªª‰ΩïÂñÆÊ®°ÊÖãÁ∑®Á¢ºÂô®Ôºå‰ª•Âèä 3) ÊòØ‰∏ÄÁ®ÆÊ®°ÂûãËûçÂêàÊñπÊ≥ïÔºåÂú®ÊúÄÂ∞èÁöÑÂæÆË™ø‰∏ãÔºåÂú®ÂÖ≠ÂÄãÂü∫Ê∫ñÂ§öÊ®°ÊÖãÁîüÁâ©ÈÜ´Â≠∏‰ªªÂãô‰∏äÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇ

##### **KNOW: A Real-World Ontology for Knowledge Capture with Large Language Models**
2405.19877v1 by Arto Bendiken

We present KNOW--the Knowledge Navigator Ontology for the World--the first
ontology designed to capture everyday knowledge to augment large language
models (LLMs) in real-world generative AI use cases such as personal AI
assistants. Our domain is human life, both its everyday concerns and its major
milestones. We have limited the initial scope of the modeled concepts to only
established human universals: spacetime (places, events) plus social (people,
groups, organizations). The inclusion criteria for modeled concepts are
pragmatic, beginning with universality and utility. We compare and contrast
previous work such as Schema.org and Cyc--as well as attempts at a synthesis of
knowledge graphs and language models--noting how LLMs already encode internally
much of the commonsense tacit knowledge that took decades to capture in the Cyc
project. We also make available code-generated software libraries for the 12
most popular programming languages, enabling the direct use of ontology
concepts in software engineering. We emphasize simplicity and developer
experience in promoting AI interoperability.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫Ü KNOWÔºåÂç≥‰∏ñÁïåÁü•Ë≠òÂ∞éËà™Êú¨‰ΩìÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊó®Âú®Êì∑ÂèñÊó•Â∏∏Áü•Ë≠ò‰ª•Êì¥ÂÖÖÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂØ¶ÈöõÁîüÊàêÂºè AI ‰ΩøÁî®Ê°à‰æã‰∏≠ÁöÑÊú¨‰ΩìÔºå‰æãÂ¶ÇÂÄã‰∫∫ AI Âä©ÁêÜ„ÄÇÊàëÂÄëÁöÑÈ†òÂüüÊòØ‰∫∫È°ûÁîüÊ¥ªÔºåÂåÖÊã¨ÂÖ∂Êó•Â∏∏ÈóúÂàáÂíåÈáçÂ§ßÈáåÁ®ãÁ¢ë„ÄÇÊàëÂÄëÂ∑≤Â∞áÂª∫Ê®°Ê¶ÇÂøµÁöÑÂàùÂßãÁØÑÂúçÈôêÂà∂ÁÇ∫ÂÉÖÂª∫Á´ã‰∫∫È°ûÊôÆÈÅçÊÄßÔºöÊôÇÁ©∫ÔºàÂú∞Èªû„ÄÅ‰∫ã‰ª∂ÔºâÂä†‰∏äÁ§æÊúÉÔºà‰∫∫„ÄÅÁæ§ÁµÑ„ÄÅÁµÑÁπîÔºâ„ÄÇÂª∫Ê®°Ê¶ÇÂøµÁöÑÁ¥çÂÖ•Ê®ôÊ∫ñÂæàÂãôÂØ¶ÔºåÂæûÊôÆÈÅçÊÄßÂíåÂØ¶Áî®ÊÄßÈñãÂßã„ÄÇÊàëÂÄëÊØîËºÉÂíåÂ∞çÊØîÂÖàÂâçÁöÑ‰ΩúÂìÅÔºå‰æãÂ¶Ç Schema.org Âíå CycÔºå‰ª•ÂèäÁü•Ë≠òÂúñË≠úÂíåË™ûË®ÄÊ®°ÂûãÁöÑÁ∂úÂêàÂòóË©¶Ôºå‰∏¶Ê≥®ÊÑèÂà∞ LLM Â∑≤ÂÖßÈÉ®Á∑®Á¢º‰∫ÜË®±Â§öÂ∏∏Ë≠òÊÄßÁöÑÈªòË™çÁü•Ë≠òÔºåËÄåÈÄô‰∫õÁü•Ë≠òËä±Ë≤ª‰∫ÜÊï∏ÂçÅÂπ¥ÊâçÂú® Cyc È†ÖÁõÆ‰∏≠Ë¢´Êì∑Âèñ„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫Ü 12 Á®ÆÊúÄÂèóÊ≠°ËøéÁöÑÁ®ãÂºèË®≠Ë®àË™ûË®ÄÁöÑÁ®ãÂºèÁ¢ºÁîüÊàêËªüÈ´îÂáΩÂºèÂ∫´ÔºåËÆìÂª∫Ê®°Ê¶ÇÂøµËÉΩÂ§†Áõ¥Êé•Áî®ÊñºËªüÈ´îÂ∑•Á®ã‰∏≠„ÄÇÊàëÂÄëÂº∑Ë™øÁ∞°ÊΩîÊÄßÂíåÈñãÁôº‰∫∫Âì°Á∂ìÈ©óÂú®‰øÉÈÄ≤ AI ‰∫íÊìç‰ΩúÊÄß‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Unsupervised Mutual Learning of Dialogue Discourse Parsing and Topic Segmentation**
2405.19799v2 by Jiahui Xu, Feng Jiang, Anningzhe Gao, Haizhou Li

The advancement of large language models (LLMs) has propelled the development
of dialogue systems. Unlike the popular ChatGPT-like assistant model, which
only satisfies the user's preferences, task-oriented dialogue systems have also
faced new requirements and challenges in the broader business field. They are
expected to provide correct responses at each dialogue turn, at the same time,
achieve the overall goal defined by the task. By understanding rhetorical
structures and topic structures via topic segmentation and discourse parsing, a
dialogue system may do a better planning to achieve both objectives. However,
while both structures belong to discourse structure in linguistics, rhetorical
structure and topic structure are mostly modeled separately or with one
assisting the other in the prior work. The interaction between these two
structures has not been considered for joint modeling and mutual learning.
Furthermore, unsupervised learning techniques to achieve the above are not well
explored. To fill this gap, we propose an unsupervised mutual learning
framework of two structures leveraging the global and local connections between
them. We extend the topic modeling between non-adjacent discourse units to
ensure global structural relevance with rhetorical structures. We also
incorporate rhetorical structures into the topic structure through a graph
neural network model to ensure local coherence consistency. Finally, we utilize
the similarity between the two fused structures for mutual learning. The
experimental results demonstrate that our methods outperform all strong
baselines on two dialogue rhetorical datasets (STAC and Molweni), as well as
dialogue topic datasets (Doc2Dial and TIAGE). We provide our code at
https://github.com/Jeff-Sue/URT.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Â±ïÊé®Âãï‰∫ÜÂ∞çË©±Á≥ªÁµ±ÁöÑÁôºÂ±ï„ÄÇËàáÂè™ÊªøË∂≥‰ΩøÁî®ËÄÖÂÅèÂ•ΩÁöÑÊµÅË°å ChatGPT È°ûÂûãÂä©ÁêÜÊ®°Âûã‰∏çÂêåÔºå‰ªªÂãôÂ∞éÂêëÂ∞çË©±Á≥ªÁµ±Âú®Êõ¥Âª£Ê≥õÁöÑÂïÜÊ•≠È†òÂüü‰∏≠‰πüÈù¢Ëá®Êñ∞ÁöÑÈúÄÊ±ÇÂíåÊåëÊà∞„ÄÇÂÆÉÂÄëÈ†êÊúüÂú®ÊØèÂÄãÂ∞çË©±ÂõûÂêà‰∏≠Êèê‰æõÊ≠£Á¢∫ÁöÑÂõûÊáâÔºåÂêåÊôÇÈÅîÊàê‰ªªÂãôÂÆöÁæ©ÁöÑÊï¥È´îÁõÆÊ®ô„ÄÇÈÄèÈÅé‰∏ªÈ°åÂàÜÊÆµÂíåË™ûÁØáËß£Êûê‰∫ÜËß£Ë™ûÁØáÁµêÊßãÂíå‰∏ªÈ°åÁµêÊßãÔºåÂ∞çË©±Á≥ªÁµ±ÂèØ‰ª•Êõ¥Â•ΩÂú∞Ë¶èÂäÉ‰ª•ÈÅîÊàêÈÄôÂÖ©ÂÄãÁõÆÊ®ô„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°ÈÄôÂÖ©ÂÄãÁµêÊßãÈÉΩÂ±¨ÊñºË™ûË®ÄÂ≠∏‰∏≠ÁöÑË™ûÁØáÁµêÊßãÔºå‰ΩÜË™ûÁØáÁµêÊßãÂíå‰∏ªÈ°åÁµêÊßãÂ§ßÂ§öÊòØÂàÜÈñãÂª∫Ê®°ÔºåÊàñÂú®ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏≠‰ª•‰∏ÄÂÄãÂçîÂä©Âè¶‰∏ÄÂÄã„ÄÇÈÄôÂÖ©ÂÄãÁµêÊßã‰πãÈñìÁöÑ‰∫íÂãïÂ∞öÊú™ËÄÉÊÖÆÈÄ≤Ë°åËÅØÂêàÂª∫Ê®°ÂíåÁõ∏‰∫íÂ≠∏Áøí„ÄÇÊ≠§Â§ñÔºåÂ∞öÊú™ÂÖÖÂàÜÊé¢Á¥¢Áî®ÊñºÈÅîÊàê‰∏äËø∞ÁõÆÊ®ôÁöÑÈùûÁõ£Áù£ÂºèÂ≠∏ÁøíÊäÄË°ì„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈùûÁõ£Áù£ÂºèÁõ∏‰∫íÂ≠∏ÁøíÊû∂ÊßãÔºåÂà©Áî®ÂÆÉÂÄë‰πãÈñìÁöÑÂÖ®Â±ÄÂíåÂ±ÄÈÉ®ÈÄ£Êé•„ÄÇÊàëÂÄëÊì¥ÂÖÖÈùûÁõ∏ÈÑ∞Ë™ûÁØáÂñÆÂÖÉ‰πãÈñìÁöÑ‰∏ªÈ°åÂª∫Ê®°Ôºå‰ª•Á¢∫‰øùËàáË™ûÁØáÁµêÊßãÁöÑÂÖ®Â±ÄÁµêÊßãÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÈÇÑÈÄèÈÅéÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÂ∞áË™ûÁØáÁµêÊßãÁ¥çÂÖ•‰∏ªÈ°åÁµêÊßãÔºå‰ª•Á¢∫‰øùÂ±ÄÈÉ®Áõ∏ÂÆπÊÄß‰∏ÄËá¥ÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂà©Áî®ÈÄôÂÖ©ÂÄãËûçÂêàÁµêÊßã‰πãÈñìÁöÑÁõ∏‰ººÊÄßÈÄ≤Ë°åÁõ∏‰∫íÂ≠∏Áøí„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂÖ©ÂÄãÂ∞çË©±Ë™ûÁØáË≥áÊñôÈõÜ (STAC Âíå Molweni) ‰ª•ÂèäÂ∞çË©±‰∏ªÈ°åË≥áÊñôÈõÜ (Doc2Dial Âíå TIAGE) ‰∏äÂÑ™ÊñºÊâÄÊúâÂº∑Â§ßÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÂú® https://github.com/Jeff-Sue/URT Êèê‰æõÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÇ

##### **Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion**
2405.19782v1 by Wei Cheng, Yuhan Wu, Wei Hu

Recent years have witnessed the deployment of code language models (LMs) in
various code intelligence tasks such as code completion. Yet, it is challenging
for pre-trained LMs to generate correct completions in private repositories.
Previous studies retrieve cross-file context based on import relations or text
similarity, which is insufficiently relevant to completion targets. In this
paper, we propose a dataflow-guided retrieval augmentation approach, called
DraCo, for repository-level code completion. DraCo parses a private repository
into code entities and establishes their relations through an extended dataflow
analysis, forming a repo-specific context graph. Whenever triggering code
completion, DraCo precisely retrieves relevant background knowledge from the
repo-specific context graph and generates well-formed prompts to query code
LMs. Furthermore, we construct a large Python dataset, ReccEval, with more
diverse completion targets. Our experiments demonstrate the superior accuracy
and applicable efficiency of DraCo, improving code exact match by 3.43% and
identifier F1-score by 3.27% on average compared to the state-of-the-art
approach.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•Ôºå‰ª£Á†ÅËØ≠Ë®ÄÊ®°Âûã (LM) Â∑≤Ë¢´ÈÉ®ÁΩ≤Âú®ÂêÑÁßç‰ª£Á†ÅÊô∫ËÉΩ‰ªªÂä°‰∏≠Ôºå‰æãÂ¶Ç‰ª£Á†ÅË°•ÂÖ®„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éÈ¢ÑËÆ≠ÁªÉÁöÑ LM Êù•ËØ¥ÔºåÂú®ÁßÅÊúâÂ≠òÂÇ®Â∫ì‰∏≠ÁîüÊàêÊ≠£Á°ÆÁöÑË°•ÂÖ®ÊòØ‰∏ÄÈ°πÊåëÊàò„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Âü∫‰∫éÂØºÂÖ•ÂÖ≥Á≥ªÊàñÊñáÊú¨Áõ∏‰ººÊÄßÊ£ÄÁ¥¢Ë∑®Êñá‰ª∂‰∏ä‰∏ãÊñáÔºåËøô‰∏éË°•ÂÖ®ÁõÆÊ†áÁöÑÁõ∏ÂÖ≥ÊÄß‰∏çË∂≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊï∞ÊçÆÊµÅÂºïÂØºÂºèÊ£ÄÁ¥¢Â¢ûÂº∫ÊñπÊ≥ïÔºåÁß∞‰∏∫ DraCoÔºåÁî®‰∫éÂ≠òÂÇ®Â∫ìÁ∫ßÂà´ÁöÑ‰ª£Á†ÅË°•ÂÖ®„ÄÇDraCo Â∞ÜÁßÅÊúâÂ≠òÂÇ®Â∫ìËß£Êûê‰∏∫‰ª£Á†ÅÂÆû‰ΩìÔºåÂπ∂ÈÄöËøáÊâ©Â±ïÁöÑÊï∞ÊçÆÊµÅÂàÜÊûêÂª∫Á´ãÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂΩ¢ÊàêÁâπÂÆö‰∫éÂ≠òÂÇ®Â∫ìÁöÑ‰∏ä‰∏ãÊñáÂõæ„ÄÇÊØèÂΩìËß¶Âèë‰ª£Á†ÅË°•ÂÖ®Êó∂ÔºåDraCo ÈÉΩ‰ºö‰ªéÁâπÂÆö‰∫éÂ≠òÂÇ®Â∫ìÁöÑ‰∏ä‰∏ãÊñáÂõæ‰∏≠Á≤æÁ°ÆÂú∞Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÁöÑËÉåÊôØÁü•ËØÜÔºåÂπ∂ÁîüÊàêÊ†ºÂºèËâØÂ•ΩÁöÑÊèêÁ§∫Êù•Êü•ËØ¢‰ª£Á†Å LM„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Â§ßÂûã Python Êï∞ÊçÆÈõÜ ReccEvalÔºåÂÖ∂‰∏≠ÂåÖÂê´Êõ¥Â§öÊ†∑ÂåñÁöÑË°•ÂÖ®ÁõÆÊ†á„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åË°®Êòé‰∫Ü DraCo ÁöÑÂçìË∂äÂáÜÁ°ÆÊÄßÂíåÈÄÇÁî®ÊïàÁéáÔºå‰∏éÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂπ≥ÂùáÊèêÈ´ò‰∫Ü 3.43% ÁöÑ‰ª£Á†ÅÂÆåÂÖ®ÂåπÈÖçÂíå 3.27% ÁöÑÊ†áËØÜÁ¨¶ F1 ÂàÜÊï∞„ÄÇ

##### **Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback**
2405.19686v1 by Jingwei Sun, Zhixu Du, Yiran Chen

Large language models (LLMs) have demonstrated remarkable proficiency in a
range of natural language processing tasks. Once deployed, LLMs encounter users
with personalized factual knowledge, and such personalized knowledge is
consistently reflected through users' interactions with the LLMs. To enhance
user experience, real-time model personalization is essential, allowing LLMs to
adapt user-specific knowledge based on user feedback during human-LLM
interactions. Existing methods mostly require back-propagation to finetune the
model parameters, which incurs high computational and memory costs. In
addition, these methods suffer from low interpretability, which will cause
unforeseen impacts on model performance during long-term use, where the user's
personalized knowledge is accumulated extensively.To address these challenges,
we propose Knowledge Graph Tuning (KGT), a novel approach that leverages
knowledge graphs (KGs) to personalize LLMs. KGT extracts personalized factual
knowledge triples from users' queries and feedback and optimizes KGs without
modifying the LLM parameters. Our method improves computational and memory
efficiency by avoiding back-propagation and ensures interpretability by making
the KG adjustments comprehensible to humans.Experiments with state-of-the-art
LLMs, including GPT-2, Llama2, and Llama3, show that KGT significantly improves
personalization performance while reducing latency and GPU memory costs.
Ultimately, KGT offers a promising solution of effective, efficient, and
interpretable real-time LLM personalization during user interactions with the
LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Ë≠âÊòéÂú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠ÂÖ∑ÊúâÂçìË∂äÁöÑËÉΩÂäõ„ÄÇ‰∏ÄÊó¶ÈÉ®ÁΩ≤ÔºåLLM ÊúÉÈÅáÂà∞ÊìÅÊúâÂÄã‰∫∫Âåñ‰∫ãÂØ¶Áü•Ë≠òÁöÑ‰ΩøÁî®ËÄÖÔºåËÄåÈÄôÁ®ÆÂÄã‰∫∫ÂåñÁü•Ë≠òÊúÉÊåÅÁ∫åÂèçÊò†Âú®‰ΩøÁî®ËÄÖËàá LLM ÁöÑ‰∫íÂãï‰∏≠„ÄÇÁÇ∫‰∫ÜÊèêÂçá‰ΩøÁî®ËÄÖÈ´îÈ©óÔºåÂç≥ÊôÇÊ®°ÂûãÂÄã‰∫∫ÂåñËá≥ÈóúÈáçË¶ÅÔºåÈÄôËÆì LLM ËÉΩÂú®‰∫∫È°ûËàá LLM ÁöÑ‰∫íÂãï‰∏≠Ê†πÊìö‰ΩøÁî®ËÄÖÁöÑÂõûÈ•ãË™øÊï¥‰ΩøÁî®ËÄÖÁâπÂÆöÁöÑÁü•Ë≠ò„ÄÇÁèæÊúâÊñπÊ≥ïÂ§ßÂ§öÈúÄË¶ÅÂèçÂêëÂÇ≥Êí≠‰æÜÂæÆË™øÊ®°ÂûãÂèÉÊï∏ÔºåÈÄôÊúÉÁî¢ÁîüÈ´òÈÅãÁÆóÂíåË®òÊÜ∂È´îÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊñπÊ≥ïÁöÑÂèØËß£ÈáãÊÄß‰ΩéÔºåÈÄôÊúÉÂú®Èï∑Êúü‰ΩøÁî®ÊúüÈñìÂ∞çÊ®°ÂûãÊïàËÉΩÈÄ†ÊàêÁÑ°Ê≥ïÈ†êË¶ãÁöÑÂΩ±ÈüøÔºåËÄå‰ΩøÁî®ËÄÖÁöÑÂÄã‰∫∫ÂåñÁü•Ë≠òÊúÉÂ§ßÈáèÁ¥ØÁ©ç„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫Áü•Ë≠òÂúñË≠úË™øÊï¥ (KGT)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂà©Áî®Áü•Ë≠òÂúñË≠ú (KG) ‰æÜÂÄã‰∫∫Âåñ LLM„ÄÇKGT Âæû‰ΩøÁî®ËÄÖÁöÑÊü•Ë©¢ÂíåÂõûÈ•ã‰∏≠ËêÉÂèñÂÄã‰∫∫ÂåñÁöÑ‰∫ãÂØ¶Áü•Ë≠ò‰∏âÂÖÉÁµÑÔºå‰∏¶Âú®‰∏ç‰øÆÊîπ LLM ÂèÉÊï∏ÁöÑÊÉÖÊ≥Å‰∏ãÊúÄ‰Ω≥Âåñ KG„ÄÇÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïÈÄèÈÅéÈÅøÂÖçÂèçÂêëÂÇ≥Êí≠‰æÜÊèêÂçáÈÅãÁÆóÂíåË®òÊÜ∂È´îÊïàÁéáÔºå‰∏¶ÈÄèÈÅéËÆì KG Ë™øÊï¥Â∞ç‰∫∫È°û‰æÜË™™ÊòìÊñºÁêÜËß£‰æÜÁ¢∫‰øùÂèØËß£ÈáãÊÄß„ÄÇ‰ΩøÁî®ÂåÖÂê´ GPT-2„ÄÅLlama2 Âíå Llama3 Âú®ÂÖßÁöÑÊúÄÊñ∞ LLM ÈÄ≤Ë°åÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåKGT Âú®Èôç‰ΩéÂª∂ÈÅ≤Âíå GPU Ë®òÊÜ∂È´îÊàêÊú¨ÁöÑÂêåÊôÇÔºåÂ§ßÂπÖÊèêÂçáÂÄã‰∫∫ÂåñÊïàËÉΩ„ÄÇÊúÄÁµÇÔºåKGT Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂèØ‰ª•Âú®‰ΩøÁî®ËÄÖËàá LLM ‰∫íÂãïÊúüÈñìÈÄ≤Ë°åÊúâÊïà„ÄÅÈ´òÊïà‰∏îÂèØËß£ÈáãÁöÑÂç≥ÊôÇ LLM ÂÄã‰∫∫Âåñ„ÄÇ

##### **MASSIVE Multilingual Abstract Meaning Representation: A Dataset and Baselines for Hallucination Detection**
2405.19285v1 by Michael Regan, Shira Wein, George Baker, Emilio Monti

Abstract Meaning Representation (AMR) is a semantic formalism that captures
the core meaning of an utterance. There has been substantial work developing
AMR corpora in English and more recently across languages, though the limited
size of existing datasets and the cost of collecting more annotations are
prohibitive. With both engineering and scientific questions in mind, we
introduce MASSIVE-AMR, a dataset with more than 84,000 text-to-graph
annotations, currently the largest and most diverse of its kind: AMR graphs for
1,685 information-seeking utterances mapped to 50+ typologically diverse
languages. We describe how we built our resource and its unique features before
reporting on experiments using large language models for multilingual AMR and
SPARQL parsing as well as applying AMRs for hallucination detection in the
context of knowledge base question answering, with results shedding light on
persistent issues using LLMs for structured parsing.

ÊëòË¶ÅÔºöÊäΩË±°Ë™ûÊÑèË°®Á§∫ÔºàAMRÔºâÊòØ‰∏ÄÁ®ÆË™ûÊÑèÂΩ¢ÂºèÂåñÔºåÁî®ÊñºÊçïÊçâË™ûÂè•ÁöÑÊ†∏ÂøÉÂê´Áæ©„ÄÇ
ÁõÆÂâçÂ∑≤ÊúâÂ§ßÈáèÂ∑•‰ΩúËá¥ÂäõÊñºÈñãÁôºËã±Êñá AMR Ë™ûÊñôÂ∫´ÔºåÊúÄËøëÊõ¥Êì¥Â±ïÂà∞Ë∑®Ë™ûË®ÄÔºåÂÑòÁÆ°ÁèæÊúâË≥áÊñôÈõÜË¶èÊ®°ÊúâÈôêÔºå‰∏îÊî∂ÈõÜÊõ¥Â§öÊ®ôË®ªÁöÑÊàêÊú¨ÈÅéÈ´ò„ÄÇ
ËÄÉÈáèÂà∞Â∑•Á®ãÂíåÁßëÂ≠∏ÊñπÈù¢ÁöÑÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MASSIVE-AMRÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´Ë∂ÖÈÅé 84,000 ÂÄãÊñáÂ≠óËΩâÂúñÂΩ¢Ê®ôË®ªÁöÑË≥áÊñôÈõÜÔºåÁõÆÂâçÊòØÂêåÈ°ûË≥áÊñôÈõÜ‰∏≠Ë¶èÊ®°ÊúÄÂ§ß‰∏îÊúÄÂ§öÊ®£ÂåñÁöÑÔºöAMR ÂúñÂΩ¢Ê∂µËìã 1,685 ÂÄãË≥áË®äÂ∞ãÊ±ÇË™ûÂè•ÔºåÂ∞çÊáâÂà∞ 50 Â§öÁ®ÆË™ûË®ÄÈ°ûÂûãÂ§öÊ®£ÁöÑË™ûË®Ä„ÄÇ
ÊàëÂÄëÂ∞áË™™ÊòéÂ¶Ç‰ΩïÂª∫ÊßãË≥áÊ∫êÂèäÂÖ∂Áç®ÁâπÂäüËÉΩÔºåÁÑ∂ÂæåÂÜçÂ†±Âëä‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÂ§öË™ûË®Ä AMR Âíå SPARQL Ëß£ÊûêÁöÑÂØ¶È©óÔºå‰ª•ÂèäÂú®Áü•Ë≠òÂ∫´ÂïèÁ≠îÁöÑËÉåÊôØ‰∏ãÊáâÁî® AMR ÈÄ≤Ë°åÂπªË¶∫ÂÅµÊ∏¨ÔºåÁµêÊûúÊúâÂä©ÊñºÈáêÊ∏Ö‰ΩøÁî® LLM ÈÄ≤Ë°åÁµêÊßãÂåñËß£ÊûêÊôÇÊåÅÁ∫åÂ≠òÂú®ÁöÑÂïèÈ°å„ÄÇ

##### **PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications**
2405.19266v2 by Dingkang Yang, Jinjie Wei, Dongling Xiao, Shunli Wang, Tong Wu, Gang Li, Mingcheng Li, Shuaibing Wang, Jiawei Chen, Yue Jiang, Qingyao Xu, Ke Li, Peng Zhai, Lihua Zhang

Developing intelligent pediatric consultation systems offers promising
prospects for improving diagnostic efficiency, especially in China, where
healthcare resources are scarce. Despite recent advances in Large Language
Models (LLMs) for Chinese medicine, their performance is sub-optimal in
pediatric applications due to inadequate instruction data and vulnerable
training procedures. To address the above issues, this paper builds PedCorpus,
a high-quality dataset of over 300,000 multi-task instructions from pediatric
textbooks, guidelines, and knowledge graph resources to fulfil diverse
diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the
first Chinese pediatric LLM assistant built on a systematic and robust training
pipeline. In the continuous pre-training phase, we introduce a hybrid
instruction pre-training mechanism to mitigate the internal-injected knowledge
inconsistency of LLMs for medical domain adaptation. Immediately, the
full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the
general medical knowledge schema into the models. After that, we devise a
direct following preference optimization to enhance the generation of
pediatrician-like humanistic responses. In the parameter-efficient secondary
SFT phase, a mixture of universal-specific experts strategy is presented to
resolve the competency conflict between medical generalist and pediatric
expertise mastery. Extensive results based on the metrics, GPT-4, and doctor
evaluations on distinct doctor downstream tasks show that PediatricsGPT
consistently outperforms previous Chinese medical LLMs. Our model and dataset
will be open-source for community development.

ÊëòË¶ÅÔºö<paragraph>ÈñãÁôºÊô∫ËÉΩÂÖíÁßëË´ÆË©¢Á≥ªÁµ±ÔºåËÉΩÊúâÊïàÊèêÂçáË®∫Êñ∑ÊïàÁéáÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇË≥áÊ∫êÁõ∏Â∞çÁº∫‰πèÁöÑ‰∏≠Âúã„ÄÇÂÑòÁÆ°‰∏≠ÊñáÈÜ´Â≠∏ÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËøë‰æÜÊúâÈï∑Ë∂≥ÈÄ≤Â±ïÔºå‰ΩÜÁî±ÊñºË®ìÁ∑¥Ë≥áÊñô‰∏çË∂≥‰∏îË®ìÁ∑¥Á®ãÂ∫è‰∏çÂÆåÂñÑÔºåÂÖ∂Âú®ÂÖíÁßëÊáâÁî®‰∏≠ÁöÑË°®Áèæ‰∏¶Êú™ÈÅîÂà∞ÊúÄ‰Ω≥Âåñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫‰∏äËø∞ÂïèÈ°åÔºåÊú¨ÊñáÂª∫Á´ã‰∫Ü PedCorpusÔºå‰∏ÄÂÄãÂåÖÂê´Ë∂ÖÈÅé 30 Ëê¨Ê¢ù‰æÜËá™ÂÖíÁßëÊïôÁßëÊõ∏„ÄÅÊåáÂçóÂíåÁü•Ë≠òÂúñË≠úË≥áÊ∫êÁöÑÂ§ö‰ªªÂãôÊåá‰ª§ÁöÑÈ´òÂìÅË≥™Ë≥áÊñôÈõÜÔºå‰ª•ÊªøË∂≥Â§öÊ®£ÂåñÁöÑË®∫Êñ∑ÈúÄÊ±Ç„ÄÇÂú®Ë®≠Ë®àËâØÂ•ΩÁöÑ PedCorpus ‰∏äÔºåÊàëÂÄëÊèêÂá∫‰∫Ü PediatricsGPTÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂª∫ÊßãÂú®Á≥ªÁµ±Âåñ‰∏îÁ©©ÂÅ•ÁöÑË®ìÁ∑¥ÊµÅÁ®ã‰∏äÁöÑ‰∏≠ÊñáÂÖíÁßë LLM Âä©ÁêÜ„ÄÇÂú®ÊåÅÁ∫åÁöÑÈ†êË®ìÁ∑¥ÈöéÊÆµÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊ∑∑ÂêàÊåá‰ª§È†êË®ìÁ∑¥Ê©üÂà∂Ôºå‰ª•Ê∏õËºï LLM Âú®ÈÜ´Â≠∏È†òÂüüÈÅ©ÊáâÊôÇÂÖßÈÉ®Ê≥®ÂÖ•Áü•Ë≠òÁöÑ‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÁ∑äÊé•ËëóÔºåÊàëÂÄëÂà©Áî®ÂÖ®ÂèÉÊï∏Áõ£Áù£ÂæÆË™øÔºàSFTÔºâÂ∞á‰∏ÄËà¨ÁöÑÈÜ´Â≠∏Áü•Ë≠òÊû∂ÊßãÁ¥çÂÖ•Ê®°Âûã‰∏≠„ÄÇÈö®ÂæåÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁõ¥Êé•ÈÅµÂæ™ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºå‰ª•Â¢ûÂº∑È°ûÂÖíÁßëÈÜ´Â∏´ÁöÑ‰∫∫ÊñáÂõûÊáâÁîüÊàê„ÄÇÂú®ÂèÉÊï∏ÊïàÁéáÁöÑÊ¨°Ë¶Å SFT ÈöéÊÆµÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈÄöÁî®Â∞àÂÆ∂Á≠ñÁï•ÁöÑÊ∑∑ÂêàÔºå‰ª•Ëß£Ê±∫ÂÖ®ÁßëÈÜ´Â∏´ÂíåÂÖíÁßëÂ∞àÂÆ∂ÊéåÊè°ËÉΩÂäõ‰πãÈñìÁöÑË°ùÁ™Å„ÄÇÊ†πÊìö GPT-4„ÄÅÈÜ´ÁîüË©ï‰º∞Âú®‰∏çÂêåÈÜ´Áîü‰∏ãÊ∏∏‰ªªÂãô‰∏äÁöÑÊåáÊ®ôÔºåÂª£Ê≥õÁöÑÁµêÊûúÈ°ØÁ§∫ PediatricsGPT ÊåÅÁ∫åÂÑ™ÊñºÂÖàÂâçÁöÑ‰∏≠ÊñáÈÜ´Â≠∏ LLM„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂíåË≥áÊñôÈõÜÂ∞áÈñãÊîæÂéüÂßãÁ¢º‰æõÁ§æÁæ§ÈñãÁôº„ÄÇ</paragraph>

##### **Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation**
2405.19255v1 by Jose Tupayachi, Haowen Xu, Olufemi A. Omitaomu, Mustafa Can Camur, Aliza Sharmin, Xueping Li

The incorporation of Artificial Intelligence (AI) models into various
optimization systems is on the rise. Yet, addressing complex urban and
environmental management problems normally requires in-depth domain science and
informatics expertise. This expertise is essential for deriving data and
simulation-driven for informed decision support. In this context, we
investigate the potential of leveraging the pre-trained Large Language Models
(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated
workflow that encompasses natural language processing, methontology-based
prompt tuning, and transformers. This workflow automates the creation of
scenario-based ontology using existing research articles and technical manuals
of urban datasets and simulations. The outcomes of our methodology are
knowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).
These facilitate the development of urban decision support systems by enhancing
the data and metadata modeling, the integration of complex datasets, the
coupling of multi-domain simulation models, and the formulation of
decision-making metrics and workflow. The feasibility of our methodology is
evaluated through a comparative analysis that juxtaposes our AI-generated
ontology with the well-known Pizza Ontology employed in tutorials for popular
ontology software (e.g., prot\'eg\'e). We close with a real-world case study of
optimizing the complex urban system of multi-modal freight transportation by
generating anthologies of various domain data and simulations to support
informed decision-making.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩ (AI) Ê®°ÂûãÊï¥ÂêàÂà∞ÂêÑÁ®ÆÊúÄ‰Ω≥ÂåñÁ≥ªÁµ±‰∏≠Ê≠£ÊñπËààÊú™Ëâæ„ÄÇÁÑ∂ËÄåÔºåËß£Ê±∫Ë§áÈõúÁöÑÈÉΩÂ∏ÇÂíåÁí∞Â¢ÉÁÆ°ÁêÜÂïèÈ°åÈÄöÂ∏∏ÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÈ†òÂüüÁßëÂ≠∏ÂíåË≥áË®äÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÈÄôÁ®ÆÂ∞àÊ•≠Áü•Ë≠òÂ∞çÊñºÂæûË≥áÊñôÂíåÊ®°Êì¨‰∏≠Êé®Â∞éÂá∫Ë≥áÊñôÈ©ÖÂãïÁöÑÊòéÊô∫Ê±∫Á≠ñÊîØÊè¥Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Ê≠§ËÑàÁµ°‰∏ãÔºåÊàëÂÄëÊé¢Ë®éÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÊé°Áî® ChatGPT API ‰ΩúÁÇ∫Êé®ÁêÜÊ†∏ÂøÉÔºåÊàëÂÄëÊ¶ÇËø∞‰∏ÄÂÄãÊï¥ÂêàÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåÂÖ∂‰∏≠ÂåÖÂê´Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÅÂü∫ÊñºÊñπÊ≥ïË´ñÁöÑÊèêÁ§∫Ë™øÊï¥ÂíåËΩâÊèõÂô®„ÄÇÊ≠§Â∑•‰ΩúÊµÅÁ®ãËá™ÂãïÂåñ‰ΩøÁî®ÁèæÊúâÁ†îÁ©∂ÊñáÁ´†ÂíåÈÉΩÂ∏ÇË≥áÊñôÈõÜÂèäÊ®°Êì¨ÊäÄË°ìÊâãÂÜäÂª∫Á´ãÂü∫ÊñºÊÉÖÂ¢ÉÁöÑÊú¨‰Ωì„ÄÇÊàëÂÄëÊñπÊ≥ïË´ñÁöÑÊàêÊûúÊòØÂª£Ê≥õÊé°Áî®ÁöÑÊú¨‰ΩìË™ûË®ÄÔºà‰æãÂ¶Ç OWL„ÄÅRDF„ÄÅSPARQLÔºâ‰∏≠ÁöÑÁü•Ë≠òÂúñË≠ú„ÄÇÈÄô‰∫õÁü•Ë≠òÂúñË≠úÈÄèÈÅéÂ¢ûÂº∑Ë≥áÊñôÂíåÂÖÉË≥áÊñôÂª∫Ê®°„ÄÅÊï¥ÂêàË§áÈõúÁöÑË≥áÊñôÈõÜ„ÄÅÁµêÂêàÂ§öÈ†òÂüüÊ®°Êì¨Ê®°ÂûãÔºå‰ª•ÂèäÂà∂ÂÆöÊ±∫Á≠ñÊåáÊ®ôÂíåÂ∑•‰ΩúÊµÅÁ®ãÔºå‰øÉÈÄ≤ÈÉΩÂ∏ÇÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁöÑÁôºÂ±ï„ÄÇÊàëÂÄëÈÄèÈÅéÊØîËºÉÂàÜÊûêË©ï‰º∞ÊàëÂÄëÊñπÊ≥ïË´ñÁöÑÂèØË°åÊÄßÔºåË©≤ÂàÜÊûêÂ∞áÊàëÂÄë AI ÁîüÊàêÁöÑÊú¨‰ΩìËàáÂª£Ê≥õÁî®ÊñºÁÜ±ÈñÄÊú¨‰ΩìËªüÈ´î (‰æãÂ¶Ç prot\'eg\'e) ÊïôÂ≠∏Ë™≤Á®ãÁöÑÁü•Âêç Pizza Êú¨‰Ωì‰∏¶ÁΩÆ„ÄÇÊàëÂÄë‰ª•‰∏ÄÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÊ°à‰æãÁ†îÁ©∂‰ΩúÁµêÔºåÈÄèÈÅéÁî¢ÁîüÂêÑÁ®ÆÈ†òÂüüË≥áÊñôÂíåÊ®°Êì¨ÁöÑÈÅ∏ÈõÜ‰æÜÊúÄ‰Ω≥ÂåñÂ§öÂºèËÅØÈÅãË≤®ÈÅãÁöÑË§áÈõúÈÉΩÂ∏ÇÁ≥ªÁµ±Ôºå‰ª•ÊîØÊè¥ÊòéÊô∫ÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÇ

##### **Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery**
2405.19164v1 by Sounak Lahiri, Sumit Pai, Tim Weninger, Sanmitra Bhattacharya

Electronic Discovery (eDiscovery) involves identifying relevant documents
from a vast collection based on legal production requests. The integration of
artificial intelligence (AI) and natural language processing (NLP) has
transformed this process, helping document review and enhance efficiency and
cost-effectiveness. Although traditional approaches like BM25 or fine-tuned
pre-trained models are common in eDiscovery, they face performance,
computational, and interpretability challenges. In contrast, Large Language
Model (LLM)-based methods prioritize interpretability but sacrifice performance
and throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid
approach that combines the strengths of two worlds: a heterogeneous graph-based
method for accurate document relevance prediction and subsequent LLM-driven
approach for reasoning. Graph representational learning generates embeddings
and predicts links, ranking the corpus for a given request, and the LLMs
provide reasoning for document relevance. Our approach handles datasets with
balanced and imbalanced distributions, outperforming baselines in F1-score,
precision, and recall by an average of 12%, 3%, and 16%, respectively. In an
enterprise context, our approach drastically reduces document review costs by
99.9% compared to manual processes and by 95% compared to LLM-based
classification methods

ÊëòË¶ÅÔºöÈõªÂ≠êÁôºÁèæ (eDiscovery) Ê∂âÂèäÊ†πÊìöÊ≥ïÂæãË£Ω‰ΩúË¶ÅÊ±ÇÂæûÂ§ßÈáèÈõÜÂêà‰∏≠Ë≠òÂà•Áõ∏ÈóúÊñá‰ª∂„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÁöÑÊï¥ÂêàÂ∑≤ËΩâËÆäÊ≠§Á®ãÂ∫èÔºåÂçîÂä©Êñá‰ª∂Ê™¢Èñ±‰∏¶ÊèêÂçáÊïàÁéáÂíåÊàêÊú¨ÊïàÁõä„ÄÇÂÑòÁÆ°ÂÇ≥Áµ±ÊñπÊ≥ïÔºà‰æãÂ¶Ç BM25 ÊàñÂæÆË™øÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºâÂú®ÈõªÂ≠êÁôºÁèæ‰∏≠ÂæàÂ∏∏Ë¶ãÔºå‰ΩÜÂÆÉÂÄëÈù¢Ëá®ÊïàËÉΩ„ÄÅÈÅãÁÆóÂíåÂèØËß£ÈáãÊÄßÊñπÈù¢ÁöÑÊåëÊà∞„ÄÇÁõ∏Â∞çÂú∞ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫Âü∫Á§éÁöÑÊñπÊ≥ïÂÑ™ÂÖàËÄÉÈáèÂèØËß£ÈáãÊÄßÔºå‰ΩÜÁäßÁâ≤ÊïàËÉΩÂíåËôïÁêÜÈáè„ÄÇÊú¨Êñá‰ªãÁ¥π DISCOvery Graph (DISCOG)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁµêÂêàÂÖ©ÂÄã‰∏ñÁïåÁöÑÂÑ™Âã¢ÁöÑÊ∑∑ÂêàÊñπÊ≥ïÔºö‰∏ÄÁ®ÆÁî®ÊñºÊ∫ñÁ¢∫Êñá‰ª∂Áõ∏ÈóúÊÄßÈ†êÊ∏¨ÁöÑÁï∞Ë≥™ÂúñÂΩ¢ÁÇ∫Âü∫Á§éÁöÑÊñπÊ≥ïÂíåÂæåÁ∫åÁöÑ LLM È©ÖÂãïÊñπÊ≥ïÁî®ÊñºÊé®ÁêÜ„ÄÇÂúñÂΩ¢Ë°®ÂæµÂ≠∏ÁøíÊúÉÁî¢ÁîüÂµåÂÖ•ÂíåÈ†êÊ∏¨ÈÄ£ÁµêÔºåÈáùÂ∞çÁâπÂÆöË¶ÅÊ±ÇÂ∞çË™ûÊñôÂ∫´ÈÄ≤Ë°åÊéíÂêçÔºåËÄå LLM ÂâáÊèê‰æõÊñá‰ª∂Áõ∏ÈóúÊÄßÁöÑÊé®ÁêÜ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËôïÁêÜÂÖ∑ÊúâÂπ≥Ë°°Âíå‰∏çÂπ≥Ë°°ÂàÜ‰ΩàÁöÑË≥áÊñôÈõÜÔºåÂú® F1 ÂàÜÊï∏„ÄÅÊ∫ñÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéáÊñπÈù¢ÂÑ™ÊñºÂü∫Ê∫ñÔºåÂπ≥ÂùáÂàÜÂà•È´òÂá∫ 12%„ÄÅ3% Âíå 16%„ÄÇÂú®‰ºÅÊ•≠Áí∞Â¢É‰∏≠ÔºåËàáÊâãÂãïÁ®ãÂ∫èÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ§ßÂπÖÊ∏õÂ∞ëÊñá‰ª∂ÂØ©Êü•ÊàêÊú¨ 99.9%ÔºåËàáÂü∫Êñº LLM ÁöÑÂàÜÈ°ûÊñπÊ≥ïÁõ∏ÊØîÔºåÊ∏õÂ∞ë 95%„ÄÇ

##### **Unleashing the Potential of Text-attributed Graphs: Automatic Relation Decomposition via Large Language Models**
2405.18581v1 by Hyunjin Seo, Taewon Kim, June Yong Yang, Eunho Yang

Recent advancements in text-attributed graphs (TAGs) have significantly
improved the quality of node features by using the textual modeling
capabilities of language models. Despite this success, utilizing text
attributes to enhance the predefined graph structure remains largely
unexplored. Our extensive analysis reveals that conventional edges on TAGs,
treated as a single relation (e.g., hyperlinks) in previous literature,
actually encompass mixed semantics (e.g., "advised by" and "participates in").
This simplification hinders the representation learning process of Graph Neural
Networks (GNNs) on downstream tasks, even when integrated with advanced node
features. In contrast, we discover that decomposing these edges into distinct
semantic relations significantly enhances the performance of GNNs. Despite
this, manually identifying and labeling of edges to corresponding semantic
relations is labor-intensive, often requiring domain expertise. To this end, we
introduce RoSE (Relation-oriented Semantic Edge-decomposition), a novel
framework that leverages the capability of Large Language Models (LLMs) to
decompose the graph structure by analyzing raw text attributes - in a fully
automated manner. RoSE operates in two stages: (1) identifying meaningful
relations using an LLM-based generator and discriminator, and (2) categorizing
each edge into corresponding relations by analyzing textual contents associated
with connected nodes via an LLM-based decomposer. Extensive experiments
demonstrate that our model-agnostic framework significantly enhances node
classification performance across various datasets, with improvements of up to
16% on the Wisconsin dataset.

ÊëòË¶ÅÔºöÊñáÊú¨Â±ûÊÄßÂõæ (TAG) ÁöÑÊúÄÊñ∞ËøõÂ±ïÊòæËëóÊèêÂçá‰∫ÜËäÇÁÇπÁâπÂæÅÁöÑË¥®ÈáèÔºåÊñπÊ≥ïÊòØÂà©Áî®ËØ≠Ë®ÄÊ®°ÂûãÁöÑÊñáÊú¨Âª∫Ê®°ËÉΩÂäõ„ÄÇÂ∞ΩÁÆ°ÂèñÂæó‰∫ÜËøô‰∏ÄÊàêÂäüÔºå‰ΩÜÂà©Áî®ÊñáÊú¨Â±ûÊÄßÊù•Â¢ûÂº∫È¢ÑÂÆö‰πâÁöÑÂõæÁªìÊûÑÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™ÂæóÂà∞Êé¢Á¥¢„ÄÇÊàë‰ª¨ÁöÑÂπøÊ≥õÂàÜÊûêË°®ÊòéÔºåTAG ‰∏äÁöÑ‰º†ÁªüËæπÂú®ÂÖàÂâçÁöÑÊñáÁåÆ‰∏≠Ë¢´ËßÜ‰∏∫Âçï‰∏ÄÂÖ≥Á≥ªÔºà‰æãÂ¶ÇË∂ÖÈìæÊé•ÔºâÔºåÂÆûÈôÖ‰∏äÂåÖÂê´Ê∑∑ÂêàËØ≠‰πâÔºà‰æãÂ¶Ç‚ÄúÂª∫ËÆÆ‚ÄùÂíå‚ÄúÂèÇ‰∏é‚ÄùÔºâ„ÄÇËøôÁßçÁÆÄÂåñÈòªÁ¢ç‰∫ÜÂõæÁ•ûÁªèÁΩëÁªú (GNN) Âú®‰∏ãÊ∏∏‰ªªÂä°‰∏≠ÁöÑË°®Á§∫Â≠¶‰π†ËøáÁ®ãÔºåÂç≥‰Ωø‰∏éÈ´òÁ∫ßËäÇÁÇπÁâπÂæÅÈõÜÊàê‰πüÊòØÂ¶ÇÊ≠§„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÊàë‰ª¨ÂèëÁé∞Â∞ÜËøô‰∫õËæπÂàÜËß£‰∏∫‰∏çÂêåÁöÑËØ≠‰πâÂÖ≥Á≥ª‰ºöÊòæËëóÂ¢ûÂº∫ GNN ÁöÑÊÄßËÉΩ„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåÊâãÂä®ËØÜÂà´ÂíåÊ†áËÆ∞ÂØπÂ∫îËØ≠‰πâÂÖ≥Á≥ªÁöÑËæπÊòØ‰∏ÄÈ°πÂä≥Âä®ÂØÜÈõÜÂûãÂ∑•‰ΩúÔºåÈÄöÂ∏∏ÈúÄË¶ÅÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü RoSEÔºàÈù¢ÂêëÂÖ≥Á≥ªÁöÑËØ≠‰πâËæπÂàÜËß£ÔºâÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑËÉΩÂäõ‰ª•ÂÖ®Ëá™Âä®ÁöÑÊñπÂºèÈÄöËøáÂàÜÊûêÂéüÂßãÊñáÊú¨Â±ûÊÄßÊù•ÂàÜËß£ÂõæÁªìÊûÑ„ÄÇRoSE ÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöÔºà1Ôºâ‰ΩøÁî®Âü∫‰∫é LLM ÁöÑÁîüÊàêÂô®ÂíåÈâ¥Âà´Âô®ËØÜÂà´ÊúâÊÑè‰πâÁöÑÂÖ≥Á≥ªÔºå‰ª•ÂèäÔºà2ÔºâÈÄöËøáÂü∫‰∫é LLM ÁöÑÂàÜËß£Âô®ÂàÜÊûê‰∏éËøûÊé•ËäÇÁÇπÂÖ≥ËÅîÁöÑÊñáÊú¨ÂÜÖÂÆπÔºåÂ∞ÜÊØè‰∏™ËæπÂàÜÁ±ªÂà∞Áõ∏Â∫îÁöÑËØ≠‰πâÂÖ≥Á≥ª‰∏≠„ÄÇÂπøÊ≥õÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÊó†ÂÖ≥Ê°ÜÊû∂ÊòæËëóÂ¢ûÂº∫‰∫ÜÂêÑ‰∏™Êï∞ÊçÆÈõÜ‰∏äÁöÑËäÇÁÇπÂàÜÁ±ªÊÄßËÉΩÔºåÂú® Wisconsin Êï∞ÊçÆÈõÜ‰∏äÊèêÈ´ò‰∫Ü 16%„ÄÇ

##### **Don't Forget to Connect! Improving RAG with Graph-based Reranking**
2405.18414v1 by Jialin Dong, Bahare Fatemi, Bryan Perozzi, Lin F. Yang, Anton Tsitsulin

Retrieval Augmented Generation (RAG) has greatly improved the performance of
Large Language Model (LLM) responses by grounding generation with context from
existing documents. These systems work well when documents are clearly relevant
to a question context. But what about when a document has partial information,
or less obvious connections to the context? And how should we reason about
connections between documents? In this work, we seek to answer these two core
questions about RAG generation. We introduce G-RAG, a reranker based on graph
neural networks (GNNs) between the retriever and reader in RAG. Our method
combines both connections between documents and semantic information (via
Abstract Meaning Representation graphs) to provide a context-informed ranker
for RAG. G-RAG outperforms state-of-the-art approaches while having smaller
computational footprint. Additionally, we assess the performance of PaLM 2 as a
reranker and find it to significantly underperform G-RAG. This result
emphasizes the importance of reranking for RAG even when using Large Language
Models.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Â∑≤Â§ßÂπÖÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂõûÊáâÁöÑÊïàËÉΩÔºåÊñπÊ≥ïÊòØÂ∞áÁîüÊàêÂü∫Á§éÊñºÁèæÊúâÊñá‰ª∂‰∏≠ÁöÑÂÖßÂÆπ„ÄÇÁï∂Êñá‰ª∂ËàáÂïèÈ°åÂÖßÂÆπÊòéÁ¢∫Áõ∏ÈóúÊôÇÔºåÈÄô‰∫õÁ≥ªÁµ±ÈÅã‰ΩúËâØÂ•Ω„ÄÇ‰ΩÜÁï∂Êñá‰ª∂ÊúâÈÉ®ÂàÜË≥áË®äÊàñËàáÂÖßÂÆπÁöÑÈóúËÅØÊÄßËºÉ‰∏çÈ°ØËëóÊôÇÂë¢ÔºüÊàëÂÄëÂèàË©≤Â¶Ç‰ΩïÊé®Ë´ñÊñá‰ª∂‰πãÈñìÁöÑÈóúËÅØÊÄßÔºüÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞ãÊ±ÇÂõûÁ≠îÈÄôÂÖ©ÂÄãÈóúÊñº RAG ÁîüÊàêÁöÑÊ†∏ÂøÉÂïèÈ°å„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü G-RAGÔºå‰∏ÄÁ®ÆÂü∫Êñº RAG ‰∏≠Ê™¢Á¥¢Âô®ÂíåËÆÄÂèñÂô®‰πãÈñìÁöÑÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÈáçÊñ∞ÊéíÂ∫èÂô®„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÁµêÂêà‰∫ÜÊñá‰ª∂‰πãÈñìÁöÑÈóúËÅØÊÄßËàáË™ûÁæ©Ë≥áË®äÔºàÈÄèÈÅéÊäΩË±°ÊÑèÁæ©Ë°®ÂæµÂúñÂΩ¢ÔºâÔºåÁÇ∫ RAG Êèê‰æõ‰∏ÄÂÄãÊúâËÑàÁµ°ÁöÑÊéíÂ∫èÂô®„ÄÇG-RAG ÁöÑË°®ÁèæË∂ÖË∂äÁèæÊúâÊäÄË°ìÔºåÂêåÊôÇÈÅãÁÆóË≥áÊ∫êÈúÄÊ±ÇËºÉÂ∞è„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË©ï‰º∞‰∫Ü PaLM 2 ‰ΩúÁÇ∫ÈáçÊñ∞ÊéíÂ∫èÂô®ÁöÑË°®ÁèæÔºåÁôºÁèæÂÖ∂Ë°®ÁèæÈ°ØËëó‰ΩéÊñº G-RAG„ÄÇÈÄôÂÄãÁµêÊûúÂº∑Ë™ø‰∫ÜÈáçÊñ∞ÊéíÂ∫èÂ∞ç RAG ÁöÑÈáçË¶ÅÊÄßÔºåÂç≥‰ΩøÂú®‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÊôÇ‰πüÊòØÂ¶ÇÊ≠§„ÄÇ

##### **Knowledge Circuits in Pretrained Transformers**
2405.17969v1 by Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, Huajun Chen

The remarkable capabilities of modern large language models are rooted in
their vast repositories of knowledge encoded within their parameters, enabling
them to perceive the world and engage in reasoning. The inner workings of how
these models store knowledge have long been a subject of intense interest and
investigation among researchers. To date, most studies have concentrated on
isolated components within these models, such as the Multilayer Perceptrons and
attention head. In this paper, we delve into the computation graph of the
language model to uncover the knowledge circuits that are instrumental in
articulating specific knowledge. The experiments, conducted with GPT2 and
TinyLLAMA, has allowed us to observe how certain information heads, relation
heads, and Multilayer Perceptrons collaboratively encode knowledge within the
model. Moreover, we evaluate the impact of current knowledge editing techniques
on these knowledge circuits, providing deeper insights into the functioning and
constraints of these editing methodologies. Finally, we utilize knowledge
circuits to analyze and interpret language model behaviors such as
hallucinations and in-context learning. We believe the knowledge circuit holds
potential for advancing our understanding of Transformers and guiding the
improved design of knowledge editing. Code and data are available in
https://github.com/zjunlp/KnowledgeCircuits.

ÊëòË¶ÅÔºöÁèæ‰ª£Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂçìË∂äËÉΩÂäõÊ∫êÊñºÂÖ∂ÂèÉÊï∏‰∏≠Á∑®Á¢ºÁöÑÈæêÂ§ßÁü•Ë≠òÂ∫´ÔºåËÆìÂÆÉÂÄëËÉΩÂ§†ÊÑüÁü•‰∏ñÁïå‰∏¶ÂèÉËàáÊé®ÁêÜ„ÄÇÈÄô‰∫õÊ®°ÂûãÂ¶Ç‰ΩïÂÑ≤Â≠òÁü•Ë≠òÁöÑÂÖßÈÉ®ÈÅã‰ΩúÊñπÂºè‰∏ÄÁõ¥ÊòØÁ†îÁ©∂‰∫∫Âì°È´òÂ∫¶ÈóúÊ≥®ÂíåÁ†îÁ©∂ÁöÑ‰∏ªÈ°å„ÄÇËøÑ‰ªäÁÇ∫Ê≠¢ÔºåÂ§ßÂ§öÊï∏Á†îÁ©∂ÈÉΩÈõÜ‰∏≠Âú®ÈÄô‰∫õÊ®°Âûã‰∏≠ÁöÑÂ≠§Á´ãÂÖÉ‰ª∂Ôºå‰æãÂ¶ÇÂ§öÂ±§ÊÑüÁü•Âô®ÂíåÊ≥®ÊÑèÂäõÈ†≠„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®éË™ûË®ÄÊ®°ÂûãÁöÑË®àÁÆóÂúñÔºå‰ª•Êè≠Á§∫Ë°®ÈÅîÁâπÂÆöÁü•Ë≠ò‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑÁü•Ë≠òÈõªË∑Ø„ÄÇ‰ΩøÁî® GPT2 Âíå TinyLLAMA ÈÄ≤Ë°åÁöÑÂØ¶È©óËÆìÊàëÂÄëËÉΩÂ§†ËßÄÂØüÊüê‰∫õË≥áË®äÈ†≠„ÄÅÈóú‰øÇÈ†≠ÂíåÂ§öÂ±§ÊÑüÁü•Âô®Â¶Ç‰ΩïÂú®Ê®°Âûã‰∏≠ÂçîÂêåÁ∑®Á¢ºÁü•Ë≠ò„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÁï∂ÂâçÁü•Ë≠òÁ∑®ËºØÊäÄË°ìÂ∞çÈÄô‰∫õÁü•Ë≠òÈõªË∑ØÁöÑÂΩ±ÈüøÔºåÂ∞çÈÄô‰∫õÁ∑®ËºØÊñπÊ≥ïÁöÑÂäüËÉΩÂíåÈôêÂà∂Êèê‰æõ‰∫ÜÊõ¥Ê∑±ÂÖ•ÁöÑË¶ãËß£„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂà©Áî®Áü•Ë≠òÈõªË∑ØÂàÜÊûêÂíåË©ÆÈáãË™ûË®ÄÊ®°ÂûãË°åÁÇ∫Ôºå‰æãÂ¶ÇÂπªË¶∫ÂíåÊÉÖÂ¢ÉÂ≠∏Áøí„ÄÇÊàëÂÄëÁõ∏‰ø°Áü•Ë≠òÈõªË∑ØÊúâÊΩõÂäõ‰øÉÈÄ≤ÊàëÂÄëÂ∞ç Transformer ÁöÑÁêÜËß£Ôºå‰∏¶ÊåáÂ∞éÁü•Ë≠òÁ∑®ËºØÁöÑÊîπÈÄ≤Ë®≠Ë®à„ÄÇ‰ª£Á¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/zjunlp/KnowledgeCircuits ‰∏≠ÂèñÂæó„ÄÇ

##### **Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs**
2405.17846v1 by Yong Qi, Gabriel Kyebambo, Siyuan Xie, Wei Shen, Shenghui Wang, Bitao Xie, Bin He, Zhipeng Wang, Shuo Jiang

Safety limitations in service robotics across various industries have raised
significant concerns about the need for robust mechanisms ensuring that robots
adhere to safe practices, thereby preventing actions that might harm humans or
cause property damage. Despite advances, including the integration of Knowledge
Graphs (KGs) with Large Language Models (LLMs), challenges in ensuring
consistent safety in autonomous robot actions persist. In this paper, we
propose a novel integration of Large Language Models with Embodied Robotic
Control Prompts (ERCPs) and Embodied Knowledge Graphs (EKGs) to enhance the
safety framework for service robots. ERCPs are designed as predefined
instructions that ensure LLMs generate safe and precise responses. These
responses are subsequently validated by EKGs, which provide a comprehensive
knowledge base ensuring that the actions of the robot are continuously aligned
with safety protocols, thereby promoting safer operational practices in varied
contexts. Our experimental setup involved diverse real-world tasks, where
robots equipped with our framework demonstrated significantly higher compliance
with safety standards compared to traditional methods. This integration fosters
secure human-robot interactions and positions our methodology at the forefront
of AI-driven safety innovations in service robotics.

ÊëòË¶ÅÔºöÂêÑÁî¢Ê•≠‰∏≠ÁöÑÊúçÂãôÊ©üÂô®‰∫∫ÂÆâÂÖ®ÈôêÂà∂Â∑≤ÂºïÁôºÈáçÂ§ßÁñëÊÖÆÔºåË™çÁÇ∫ÊúâÂøÖË¶ÅÂª∫Á´ãÂº∑ÂÅ•ÁöÑÊ©üÂà∂ÔºåÁ¢∫‰øùÊ©üÂô®‰∫∫ÈÅµÂÆàÂÆâÂÖ®Ë¶èÁØÑÔºåÈÄ≤ËÄåÈò≤Ê≠¢ÂèØËÉΩÂÇ∑ÂÆ≥‰∫∫È°ûÊàñÈÄ†ÊàêË≤°Áî¢ÊêçÂ§±ÁöÑË°åÁÇ∫„ÄÇÂÑòÁÆ°ÊúâÈÄ≤Â±ïÔºåÂåÖÊã¨Â∞áÁü•Ë≠òÂúñË≠ú (KG) ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÔºå‰ΩÜ‰ªçÊúâÊåëÊà∞Â≠òÂú®ÊñºÁ¢∫‰øùËá™‰∏ªÊ©üÂô®‰∫∫Ë°åÁÇ∫ÁöÑ‰∏ÄËá¥ÊÄßÂÆâÂÖ®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Â∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãËàáÂÖ∑È´îÊ©üÂô®‰∫∫ÊéßÂà∂ÊèêÁ§∫ (ERCP) ÂíåÂÖ∑È´îÁü•Ë≠òÂúñË≠ú (EKG) ÈÄ≤Ë°åÂâµÊñ∞Êï¥ÂêàÔºå‰ª•Â¢ûÂº∑ÊúçÂãôÊ©üÂô®‰∫∫ÁöÑÂÆâÂÖ®Êû∂Êßã„ÄÇERCP Ë¢´Ë®≠Ë®àÁÇ∫È†êÂÖàÂÆöÁæ©ÁöÑÊåá‰ª§ÔºåÂèØÁ¢∫‰øù LLM Áî¢ÁîüÂÆâÂÖ®‰∏îÁ≤æÁ¢∫ÁöÑÂõûÊáâ„ÄÇÈÄô‰∫õÂõûÊáâÈö®ÂæåÁî± EKG È©óË≠âÔºåEKG Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÁü•Ë≠òÂ∫´ÔºåÁ¢∫‰øùÊ©üÂô®‰∫∫ÁöÑË°åÁÇ∫ÊåÅÁ∫åÁ¨¶ÂêàÂÆâÂÖ®ÂçîÂÆöÔºåÈÄ≤ËÄå‰øÉÈÄ≤Âú®ÂêÑÁ®ÆÊÉÖÂ¢É‰∏≠Êõ¥ÂÆâÂÖ®ÁöÑÈÅã‰ΩúÂØ¶Âãô„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË®≠ÁΩÆÊ∂âÂèäÂ§öÊ®£ÂåñÁöÑÁúüÂØ¶‰∏ñÁïå‰ªªÂãôÔºåÈÖçÂÇôÊàëÂÄëÊû∂ÊßãÁöÑÊ©üÂô®‰∫∫ËàáÂÇ≥Áµ±ÊñπÊ≥ïÁõ∏ÊØîÔºåÂ±ïÁèæÂá∫È°ØËëóÊõ¥È´òÁöÑÂÆâÂÖ®Ê®ôÊ∫ñÈÅµÂæ™Â∫¶„ÄÇÊ≠§Êï¥Âêà‰øÉÈÄ≤‰∫ÜÂÆâÂÖ®ÁöÑ‰∫∫Ê©ü‰∫íÂãïÔºå‰∏¶Â∞áÊàëÂÄëÁöÑÊäÄË°ìÂÆö‰ΩçÊñºÊúçÂãôÊ©üÂô®‰∫∫‰∏≠ AI È©ÖÂãïÂÆâÂÖ®ÂâµÊñ∞ÁöÑÊúÄÂâçÁ∑ö„ÄÇ

##### **Cost-efficient Knowledge-based Question Answering with Large Language Models**
2405.17337v1 by Junnan Dong, Qinggang Zhang, Chuang Zhou, Hao Chen, Daochen Zha, Xiao Huang

Knowledge-based question answering (KBQA) is widely used in many scenarios
that necessitate domain knowledge. Large language models (LLMs) bring
opportunities to KBQA, while their costs are significantly higher and absence
of domain-specific knowledge during pre-training. We are motivated to combine
LLMs and prior small models on knowledge graphs (KGMs) for both inferential
accuracy and cost saving. However, it remains challenging since accuracy and
cost are not readily combined in the optimization as two distinct metrics. It
is also laborious for model selection since different models excel in diverse
knowledge. To this end, we propose Coke, a novel cost-efficient strategy for
KBQA with LLMs, modeled as a tailored multi-armed bandit problem to minimize
calls to LLMs within limited budgets. We first formulate the accuracy
expectation with a cluster-level Thompson Sampling for either KGMs or LLMs. A
context-aware policy is optimized to further distinguish the expert model
subject to the question semantics. The overall decision is bounded by the cost
regret according to historical expenditure on failures. Extensive experiments
showcase the superior performance of Coke, which moves the Pareto frontier with
up to 20.89% saving of GPT-4 fees while achieving a 2.74% higher accuracy on
the benchmark datasets.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÁü•Ë≠òÁöÑÂïèÁ≠î (KBQA) Âª£Ê≥õÊáâÁî®ÊñºË®±Â§öÈúÄË¶ÅÈ†òÂüüÁü•Ë≠òÁöÑÂ†¥ÊôØ‰∏≠„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫ KBQA Â∏∂‰æÜ‰∫ÜÊ©üÊúÉÔºå‰ΩÜÂÖ∂ÊàêÊú¨È°ØËëóÊèêÈ´òÔºå‰∏îÂú®È†êË®ìÁ∑¥ÊúüÈñìÁº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠ò„ÄÇÊàëÂÄëÊúâÂãïÂäõÂ∞á LLM ÂíåÂÖàÂâçÁöÑÁü•Ë≠òÂúñË≠ú (KGM) ‰∏äÁöÑÂ∞èÊ®°ÂûãÁµêÂêàËµ∑‰æÜÔºå‰ª•ÊèêÈ´òÊé®ÁêÜÊ∫ñÁ¢∫ÊÄßÂíåÁØÄÁúÅÊàêÊú¨„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊ∫ñÁ¢∫ÊÄßÂíåÊàêÊú¨ÁÑ°Ê≥ïÂú®ÂÑ™Âåñ‰∏≠‰ΩúÁÇ∫ÂÖ©ÂÄã‰∏çÂêåÁöÑÊåáÊ®ôËºïÊòìÂú∞ÁµêÂêàÂú®‰∏ÄËµ∑ÔºåÂõ†Ê≠§ÈÄô‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁî±Êñº‰∏çÂêåÁöÑÊ®°ÂûãÊìÖÈï∑Êñº‰∏çÂêåÁöÑÁü•Ë≠òÔºåÂõ†Ê≠§Ê®°ÂûãÈÅ∏Êìá‰πüÂæàË≤ªÂäõ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü CokeÔºå‰∏ÄÁ®ÆÈáùÂ∞ç LLM ÁöÑÊñ∞Á©é‰∏îÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÁöÑ KBQA Á≠ñÁï•ÔºåÂÆÉË¢´Âª∫Ê®°ÁÇ∫‰∏ÄÂÄãÂÆöÂà∂ÁöÑÂ§öËáÇË≥≠ÂçöÊ©üÂïèÈ°åÔºå‰ª•Âú®ÊúâÈôêÁöÑÈ†êÁÆóÂÖßÊúÄÂ§ßÁ®ãÂ∫¶Âú∞Ê∏õÂ∞ëÂ∞ç LLM ÁöÑÂëºÂè´„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®ÈáùÂ∞ç KGM Êàñ LLM ÁöÑÁæ§ÈõÜÁ¥ö Thompson Êé°Ê®£‰æÜÂà∂ÂÆöÊ∫ñÁ¢∫ÊÄßÊúüÊúõ„ÄÇÂÑ™Âåñ‰∫Ü‰∏ÄÂÄã‰∏ä‰∏ãÊñáÊÑüÁü•Á≠ñÁï•Ôºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÂçÄÂàÜÂïèÈ°åË™ûÁæ©ÁöÑ‰∏ªÈ°åÊ®°Âûã„ÄÇÊ†πÊìöÂ§±ÊïóÁöÑÊ≠∑Âè≤ÊîØÂá∫ÔºåÁ∏ΩÈ´îÊ±∫Á≠ñÂèóÂà∞ÊàêÊú¨ÈÅ∫ÊÜæÁöÑÁ¥ÑÊùü„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óÂ±ïÁ§∫‰∫Ü Coke ÁöÑÂÑ™Ë∂äÊÄßËÉΩÔºåÂÆÉÂ∞áÂ∏ïÁ¥ØÊâòÂâçÊ≤øÁßªÂãï‰∫ÜÂ§öÈÅî 20.89%ÔºåÂêåÊôÇÂú®Âü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äÂØ¶Áèæ‰∫Ü 2.74% ÁöÑÊõ¥È´òÊ∫ñÁ¢∫ÊÄß„ÄÇ</paragraph>

##### **Assessing LLMs Suitability for Knowledge Graph Completion**
2405.17249v1 by Vasile Ionut Remus Iga, Gheorghe Cosmin Silaghi

Recent work shown the capability of Large Language Models (LLMs) to solve
tasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in
Zero- or Few-Shot paradigms. However, they are known to hallucinate answers, or
output results in a non-deterministic manner, thus leading to wrongly reasoned
responses, even if they satisfy the user's demands. To highlight opportunities
and challenges in knowledge graphs-related tasks, we experiment with two
distinguished LLMs, namely Mixtral-8x7B-Instruct-v0.1, and gpt-3.5-turbo-0125,
on Knowledge Graph Completion for static knowledge graphs, using prompts
constructed following the TELeR taxonomy, in Zero- and One-Shot contexts, on a
Task-Oriented Dialogue system use case. When evaluated using both strict and
flexible metrics measurement manners, our results show that LLMs could be fit
for such a task if prompts encapsulate sufficient information and relevant
examples.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂ÊòæÁ§∫ÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂÖ∑Â§áËß£ÂÜ≥Áü•ËØÜÂõæË∞±Áõ∏ÂÖ≥‰ªªÂä°ÁöÑËÉΩÂäõÔºå‰æãÂ¶ÇÁü•ËØÜÂõæË∞±Ë°•ÂÖ®ÔºåÂç≥‰ΩøÂú®Èõ∂Ê¨°ÊàñÂ∞èÊ†∑Êú¨ÁöÑÊÉÖÂÜµ‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇÁÑ∂ËÄåÔºå‰ºóÊâÄÂë®Áü•ÔºåÂÆÉ‰ª¨‰ºö‰∫ßÁîüÂπªËßâÁ≠îÊ°àÔºåÊàñ‰ª•ÈùûÁ°ÆÂÆöÊÄßÁöÑÊñπÂºèËæìÂá∫ÁªìÊûúÔºå‰ªéËÄåÂØºËá¥Êé®ÁêÜÈîôËØØÁöÑÂìçÂ∫îÔºåÂç≥‰ΩøÂÆÉ‰ª¨Êª°Ë∂≥‰∫ÜÁî®Êà∑ÁöÑÈúÄÊ±Ç„ÄÇ‰∏∫‰∫ÜÁ™ÅÂá∫Áü•ËØÜÂõæË∞±Áõ∏ÂÖ≥‰ªªÂä°‰∏≠ÁöÑÊú∫ÈÅáÂíåÊåëÊàòÔºåÊàë‰ª¨ÂØπ‰∏§ÁßçÊù∞Âá∫ÁöÑ LLM ËøõË°å‰∫ÜÂÆûÈ™åÔºåÂàÜÂà´ÊòØ Mixtral-8x7B-Instruct-v0.1 Âíå gpt-3.5-turbo-0125ÔºåÂú®ÈùôÊÄÅÁü•ËØÜÂõæË∞±ÁöÑÁü•ËØÜÂõæË∞±Ë°•ÂÖ®‰∏äÔºå‰ΩøÁî®Ê†πÊçÆ TELeR ÂàÜÁ±ªÊ≥ïÊûÑÂª∫ÁöÑÊèêÁ§∫ÔºåÂú®Èõ∂Ê¨°Âíå‰∏ÄÊ¨°‰∏ä‰∏ãÊñá‰∏≠ÔºåÂú®Èù¢Âêë‰ªªÂä°ÁöÑÂØπËØùÁ≥ªÁªüÁî®‰æã‰∏≠„ÄÇÂΩì‰ΩøÁî®‰∏•Ê†ºÂíåÁÅµÊ¥ªÁöÑÂ∫¶ÈáèÊñπÂºèËøõË°åËØÑ‰º∞Êó∂ÔºåÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåÂ¶ÇÊûúÊèêÁ§∫ÂåÖÂê´Ë∂≥Â§üÁöÑ‰ø°ÊÅØÂíåÁõ∏ÂÖ≥Á§∫‰æãÔºåÂàô LLM ÈÄÇÁî®‰∫éÊ≠§Á±ª‰ªªÂä°„ÄÇ

##### **EMERGE: Integrating RAG for Improved Multimodal EHR Predictive Modeling**
2406.00036v1 by Yinghao Zhu, Changyu Ren, Zixiang Wang, Xiaochen Zheng, Shiyun Xie, Junlan Feng, Xi Zhu, Zhoujun Li, Liantao Ma, Chengwei Pan

The integration of multimodal Electronic Health Records (EHR) data has
notably advanced clinical predictive capabilities. However, current models that
utilize clinical notes and multivariate time-series EHR data often lack the
necessary medical context for precise clinical tasks. Previous methods using
knowledge graphs (KGs) primarily focus on structured knowledge extraction. To
address this, we propose EMERGE, a Retrieval-Augmented Generation (RAG) driven
framework aimed at enhancing multimodal EHR predictive modeling. Our approach
extracts entities from both time-series data and clinical notes by prompting
Large Language Models (LLMs) and aligns them with professional PrimeKG to
ensure consistency. Beyond triplet relationships, we include entities'
definitions and descriptions to provide richer semantics. The extracted
knowledge is then used to generate task-relevant summaries of patients' health
statuses. These summaries are fused with other modalities utilizing an adaptive
multimodal fusion network with cross-attention. Extensive experiments on the
MIMIC-III and MIMIC-IV datasets for in-hospital mortality and 30-day
readmission tasks demonstrate the superior performance of the EMERGE framework
compared to baseline models. Comprehensive ablation studies and analyses
underscore the efficacy of each designed module and the framework's robustness
to data sparsity. EMERGE significantly enhances the use of multimodal EHR data
in healthcare, bridging the gap with nuanced medical contexts crucial for
informed clinical predictions.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑÔºàEHRÔºâË≥áÊñôÁöÑÊï¥ÂêàÈ°ØËëóÂú∞ÊèêÂçá‰∫ÜËá®Â∫äÈ†êÊ∏¨ËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÂà©Áî®Ëá®Â∫äÁ≠ÜË®òÂíåÂ§öËÆäÊï∏ÊôÇÈñìÂ∫èÂàó EHR Ë≥áÊñôÁöÑÊ®°ÂûãÔºåÈÄöÂ∏∏Áº∫‰πèÁ≤æÁ¢∫Ëá®Â∫ä‰ªªÂãôÊâÄÈúÄÁöÑÈÜ´ÁôÇËÉåÊôØ„ÄÇÂÖàÂâç‰ΩøÁî®Áü•Ë≠òÂúñË≠ú (KG) ÁöÑÊñπÊ≥ï‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÁµêÊßãÂåñÁü•Ë≠òËêÉÂèñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ EMERGEÔºå‰∏ÄÂÄã‰ª•Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÁÇ∫‰∏ªÁöÑÊû∂ÊßãÔºåÊó®Âú®Â¢ûÂº∑Â§öÊ®°ÊÖã EHR È†êÊ∏¨Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÈÄèÈÅéÊèêÁ§∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæûÊôÇÈñìÂ∫èÂàóË≥áÊñôÂíåËá®Â∫äÁ≠ÜË®ò‰∏≠ËêÉÂèñÂØ¶È´îÔºå‰∏¶Â∞áÂÆÉÂÄëËàáÂ∞àÊ•≠ PrimeKG ÊØîÂ∞çÔºå‰ª•Á¢∫‰øù‰∏ÄËá¥ÊÄß„ÄÇÈô§‰∫Ü‰∏âÂÖÉÈóú‰øÇ‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÂåÖÂê´ÂØ¶È´îÁöÑÂÆöÁæ©ÂíåÊèèËø∞Ôºå‰ª•Êèê‰æõÊõ¥Ë±êÂØåÁöÑË™ûÊÑè„ÄÇËêÉÂèñÁöÑÁü•Ë≠òÊé•ËëóÁî®ÊñºÁî¢ÁîüËàá‰ªªÂãôÁõ∏ÈóúÁöÑÊÇ£ËÄÖÂÅ•Â∫∑ÁãÄÊÖãÊëòË¶Å„ÄÇÈÄô‰∫õÊëòË¶ÅÂà©Áî®ÂÖ∑Êúâ‰∫§ÂèâÊ≥®ÊÑèÂäõÁöÑËá™ÈÅ©ÊáâÂ§öÊ®°ÊÖãËûçÂêàÁ∂≤Ë∑ØËàáÂÖ∂‰ªñÊ®°ÊÖãËûçÂêà„ÄÇÂú® MIMIC-III Âíå MIMIC-IV Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÔºåÈáùÂ∞çÈô¢ÂÖßÊ≠ª‰∫°ÁéáÂíå 30 Â§©ÂÜçÂÖ•Èô¢‰ªªÂãôÔºåË≠âÊòé‰∫Ü EMERGE Ê°ÜÊû∂ËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÂÖ∑ÊúâÂÑ™Ë∂äÁöÑÊïàËÉΩ„ÄÇÂÖ®Èù¢ÁöÑÊ∂àËûçÁ†îÁ©∂ÂíåÂàÜÊûêÂº∑Ë™ø‰∫ÜÊØèÂÄãË®≠Ë®àÊ®°ÁµÑÁöÑÂäüÊïàÔºå‰ª•ÂèäË©≤Ê°ÜÊû∂Â∞çË≥áÊñôÁ®ÄÁñèÊÄßÁöÑÁ©©ÂÅ•ÊÄß„ÄÇEMERGE Â§ßÂπÖÊèêÂçá‰∫ÜÂ§öÊ®°ÊÖã EHR Ë≥áÊñôÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ‰ΩøÁî®ÔºåÂΩåË£ú‰∫ÜÂ∞çÊòéÊô∫Ëá®Â∫äÈ†êÊ∏¨Ëá≥ÈóúÈáçË¶ÅÁöÑÁ¥∞ÂæÆÈÜ´ÁôÇËÉåÊôØÁöÑÂ∑ÆË∑ù„ÄÇ

##### **Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning**
2405.16933v1 by Xun Liang, Simin Niu, Zhiyu li, Sensen Zhang, Shichao Song, Hanyu Wang, Jiawei Yang, Feiyu Xiong, Bo Tang, Chenyang Xi

Retrieval-Augmented Generation (RAG) offers a cost-effective approach to
injecting real-time knowledge into large language models (LLMs). Nevertheless,
constructing and validating high-quality knowledge repositories require
considerable effort. We propose a pre-retrieval framework named Pseudo-Graph
Retrieval-Augmented Generation (PG-RAG), which conceptualizes LLMs as students
by providing them with abundant raw reading materials and encouraging them to
engage in autonomous reading to record factual information in their own words.
The resulting concise, well-organized mental indices are interconnected through
common topics or complementary facts to form a pseudo-graph database. During
the retrieval phase, PG-RAG mimics the human behavior in flipping through
notes, identifying fact paths and subsequently exploring the related contexts.
Adhering to the principle of the path taken by many is the best, it integrates
highly corroborated fact paths to provide a structured and refined sub-graph
assisting LLMs. We validated PG-RAG on three specialized question-answering
datasets. In single-document tasks, PG-RAG significantly outperformed the
current best baseline, KGP-LLaMA, across all key evaluation metrics, with an
average overall performance improvement of 11.6%. Specifically, its BLEU score
increased by approximately 14.3%, and the QE-F1 metric improved by 23.7%. In
multi-document scenarios, the average metrics of PG-RAG were at least 2.35%
higher than the best baseline. Notably, the BLEU score and QE-F1 metric showed
stable improvements of around 7.55% and 12.75%, respectively. Our code:
https://github.com/IAAR-Shanghai/PGRAG.

ÊëòË¶ÅÔºö<paragraph>Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Â∞áÂç≥ÊôÇÁü•Ë≠òÊ≥®ÂÖ•Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂª∫ÊßãÂíåÈ©óË≠âÈ´òÂìÅË≥™ÁöÑÁü•Ë≠òÂÑ≤Â≠òÂ∫´ÈúÄË¶ÅÁõ∏Áï∂Â§ßÁöÑÂä™Âäõ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ÂÅΩÂúñÂΩ¢Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàPG-RAGÔºâÁöÑÈ†êÊ™¢Á¥¢Êû∂ÊßãÔºåÂÆÉÂ∞á LLM Ê¶ÇÂøµÂåñÁÇ∫Â≠∏ÁîüÔºåÁÇ∫‰ªñÂÄëÊèê‰æõË±êÂØåÁöÑÂéüÂßãÈñ±ËÆÄÊùêÊñôÔºå‰∏¶ÈºìÂãµ‰ªñÂÄëÂæû‰∫ãËá™‰∏ªÈñ±ËÆÄÔºåÁî®Ëá™Â∑±ÁöÑË©±Ë®òÈåÑ‰∫ãÂØ¶Ë≥áË®ä„ÄÇÁî±Ê≠§Áî¢ÁîüÁöÑÁ∞°ÊΩî„ÄÅÁµÑÁπîËâØÂ•ΩÁöÑÂøÉÊô∫Á¥¢ÂºïÈÄöÈÅéÂÖ±ÂêåÁöÑ‰∏ªÈ°åÊàñË£úÂÖÖ‰∫ãÂØ¶Áõ∏‰∫íÈÄ£Êé•ÔºåÂΩ¢Êàê‰∏ÄÂÄãÂÅΩÂúñÂΩ¢Ë≥áÊñôÂ∫´„ÄÇÂú®Ê™¢Á¥¢ÈöéÊÆµÔºåPG-RAG Ê®°‰ªø‰∫∫È°ûÂú®ÁøªÈñ±Á≠ÜË®ò„ÄÅË≠òÂà•‰∫ãÂØ¶Ë∑ØÂæë‰∏¶Èö®ÂæåÊé¢Á¥¢Áõ∏ÈóúËÉåÊôØ‰∏≠ÁöÑË°åÁÇ∫„ÄÇÈÅµÂæ™Áúæ‰∫∫Ëµ∞ÁöÑË∑ØÊòØÊúÄÂ•ΩÁöÑÂéüÂâáÔºåÂÆÉÊï¥Âêà‰∫ÜÈ´òÂ∫¶Ë≠âÂØ¶ÁöÑ‰∫ãÂØ¶Ë∑ØÂæëÔºå‰ª•Êèê‰æõ‰∏ÄÂÄãÁµêÊßãÂåñ‰∏îÁ≤æÁÖâÁöÑÂ≠êÂúñÔºåÂçîÂä© LLM„ÄÇÊàëÂÄëÂú®‰∏âÂÄãÂ∞àÊ•≠ÂïèÁ≠îË≥áÊñôÈõÜ‰∏äÈ©óË≠â‰∫Ü PG-RAG„ÄÇÂú®ÂñÆ‰∏ÄÊñá‰ª∂‰ªªÂãô‰∏≠ÔºåPG-RAG Âú®ÊâÄÊúâÈóúÈçµË©ï‰º∞ÊåáÊ®ô‰∏äÈÉΩÈ°ØËëóÂÑ™ÊñºÁõÆÂâçÁöÑÊúÄ‰Ω≥Âü∫Ê∫ñ KGP-LLaMAÔºåÂπ≥ÂùáÊï¥È´îÊïàËÉΩÊèêÂçá‰∫Ü 11.6%„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂÆÉÁöÑ BLEU ÂàÜÊï∏ÊèêÈ´ò‰∫ÜÂ§ßÁ¥Ñ 14.3%ÔºåQE-F1 ÊåáÊ®ôÊèêÈ´ò‰∫Ü 23.7%„ÄÇÂú®Â§öÊñá‰ª∂Â†¥ÊôØ‰∏≠ÔºåPG-RAG ÁöÑÂπ≥ÂùáÊåáÊ®ôËá≥Â∞ëÊØîÊúÄ‰Ω≥Âü∫Ê∫ñÈ´ò 2.35%„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåBLEU ÂàÜÊï∏Âíå QE-F1 ÊåáÊ®ôÂàÜÂà•È°ØÁ§∫Âá∫Á¥Ñ 7.55% Âíå 12.75% ÁöÑÁ©©ÂÆöÊèêÂçá„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºöhttps://github.com/IAAR-Shanghai/PGRAG„ÄÇ</paragraph>

##### **Entity Alignment with Noisy Annotations from Large Language Models**
2405.16806v2 by Shengyuan Chen, Qinggang Zhang, Junnan Dong, Wen Hua, Qing Li, Xiao Huang

Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying
equivalent entity pairs. While existing methods heavily rely on human-generated
labels, it is prohibitively expensive to incorporate cross-domain experts for
annotation in real-world scenarios. The advent of Large Language Models (LLMs)
presents new avenues for automating EA with annotations, inspired by their
comprehensive capability to process semantic information. However, it is
nontrivial to directly apply LLMs for EA since the annotation space in
real-world KGs is large. LLMs could also generate noisy labels that may mislead
the alignment. To this end, we propose a unified framework, LLM4EA, to
effectively leverage LLMs for EA. Specifically, we design a novel active
learning policy to significantly reduce the annotation space by prioritizing
the most valuable entities based on the entire inter-KG and intra-KG structure.
Moreover, we introduce an unsupervised label refiner to continuously enhance
label accuracy through in-depth probabilistic reasoning. We iteratively
optimize the policy based on the feedback from a base EA model. Extensive
experiments demonstrate the advantages of LLM4EA on four benchmark datasets in
terms of effectiveness, robustness, and efficiency. Codes are available via
https://github.com/chensyCN/llm4ea_official.

ÊëòË¶ÅÔºöÂØ¶È´îÊØîÂ∞ç (EA) Êó®Âú®ÈÄèÈÅéË≠òÂà•Á≠âÊïàÁöÑÂØ¶È´îÂ∞ç‰æÜÂêà‰ΩµÂÖ©ÂÄãÁü•Ë≠òÂúñË≠ú (KG)„ÄÇÈõñÁÑ∂ÁèæÊúâÊñπÊ≥ïÊ•µÂ∫¶‰æùË≥¥‰∫∫Â∑•Áî¢ÁîüÁöÑÊ®ôÁ±§Ôºå‰ΩÜÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØ‰∏≠ÔºåË¶ÅÁ¥çÂÖ•Ë∑®È†òÂüüÁöÑÂ∞àÂÆ∂ÈÄ≤Ë°åË®ªËß£ÊòØÈõ£‰ª•Ë≤†ÊìîÁöÑÊàêÊú¨„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÁÇ∫Ëá™ÂãïÂåñ EA Êèê‰æõ‰∫ÜÊñ∞ÁöÑÈÄîÂæëÔºåÂÖ∂ÈùàÊÑü‰æÜËá™Êñº LLM ÂÖ®Èù¢ËôïÁêÜË™ûÁæ©Ë≥áË®äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁèæÂØ¶‰∏ñÁïå KG ‰∏≠ÁöÑË®ªËß£Á©∫ÈñìÂæàÂ§ßÔºåÂõ†Ê≠§Áõ¥Êé•ÊáâÁî® LLM Êñº EA ‰∏¶ÈùûÊòì‰∫ã„ÄÇLLM ‰πüÊúâÂèØËÉΩÁî¢ÁîüÈõúË®äÊ®ôÁ±§ÔºåÈÄ≤ËÄåË™§Â∞éÊØîÂ∞ç„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊû∂Êßã LLM4EAÔºå‰ª•ÊúâÊïàÂà©Áî® LLM ÈÄ≤Ë°å EA„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ‰∏ªÂãïÂ≠∏ÁøíÊîøÁ≠ñÔºåÈÄèÈÅéÊ†πÊìöÊï¥ÂÄãË∑® KG ÂíåÂÖßÈÉ® KG ÁµêÊßãÔºåÂÑ™ÂÖàËôïÁêÜÊúÄÊúâÂÉπÂÄºÁöÑÂØ¶È´îÔºåÂæûËÄåÂ§ßÂπÖÊ∏õÂ∞ëË®ªËß£Á©∫Èñì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁÑ°Áõ£Áù£Ê®ôÁ±§Á≤æÁÖâÂô®Ôºå‰ª•ÈÄèÈÅéÊ∑±ÂÖ•ÁöÑÊ©üÁéáÊé®ÁêÜÊåÅÁ∫åÊèêÂçáÊ®ôÁ±§ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÊ†πÊìöÂü∫Á§é EA Ê®°ÂûãÁöÑÂõûÈ•ãÔºåÂèçË¶ÜÊúÄ‰Ω≥ÂåñÊîøÁ≠ñ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫Ü LLM4EA Âú®ÂõõÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂÑ™Âã¢ÔºåÂåÖÊã¨Âú®ÊïàËÉΩ„ÄÅÁ©©ÂÅ•ÊÄßÂíåÊïàÁéáÊñπÈù¢„ÄÇÁ®ãÂºèÁ¢ºÂèØÈÄèÈÅé https://github.com/chensyCN/llm4ea_official ÂèñÂæó„ÄÇ

##### **TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing Graph and Text Mutual Transformations**
2405.16800v1 by Zheng Zhang, Yuntong Hu, Bo Pan, Chen Ling, Liang Zhao

Text-Attributed Graphs (TAGs) enhance graph structures with natural language
descriptions, enabling detailed representation of data and their relationships
across a broad spectrum of real-world scenarios. Despite the potential for
deeper insights, existing TAG representation learning primarily relies on
supervised methods, necessitating extensive labeled data and limiting
applicability across diverse contexts. This paper introduces a new
self-supervised learning framework, Text-And-Graph Multi-View Alignment (TAGA),
which overcomes these constraints by integrating TAGs' structural and semantic
dimensions. TAGA constructs two complementary views: Text-of-Graph view, which
organizes node texts into structured documents based on graph topology, and the
Graph-of-Text view, which converts textual nodes and connections into graph
data. By aligning representations from both views, TAGA captures joint textual
and structural information. In addition, a novel structure-preserving random
walk algorithm is proposed for efficient training on large-sized TAGs. Our
framework demonstrates strong performance in zero-shot and few-shot scenarios
across eight real-world datasets.

ÊëòË¶ÅÔºöÊñáÊú¨Â±ûÊÄßÂõæ (TAG) ‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞Â¢ûÂº∫ÂõæÁªìÊûÑÔºåËÉΩÂ§üËØ¶ÁªÜË°®Á§∫Êï∞ÊçÆÂèäÂÖ∂Âú®ÂπøÊ≥õÁöÑÁúüÂÆû‰∏ñÁïåÂú∫ÊôØ‰∏≠ÁöÑÂÖ≥Á≥ª„ÄÇÂ∞ΩÁÆ°ÊúâÊõ¥Ê∑±ÂÖ•ËßÅËß£ÁöÑÊΩúÂäõÔºå‰ΩÜÁé∞ÊúâÁöÑ TAG Ë°®Á§∫Â≠¶‰π†‰∏ªË¶Å‰æùËµñ‰∫éÁõëÁù£ÊñπÊ≥ïÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑÊ†áËÆ∞Êï∞ÊçÆÔºåÂπ∂ÈôêÂà∂‰∫ÜÂú®‰∏çÂêå‰∏ä‰∏ãÊñá‰∏≠ÁöÑÈÄÇÁî®ÊÄß„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑËá™ÁõëÁù£Â≠¶‰π†Ê°ÜÊû∂ÔºåÊñáÊú¨ÂíåÂõæÂ§öËßÜÂõæÂØπÈΩê (TAGA)ÔºåÈÄöËøáÊï¥Âêà TAG ÁöÑÁªìÊûÑÂíåËØ≠‰πâÁª¥Â∫¶Êù•ÂÖãÊúçËøô‰∫õÈôêÂà∂„ÄÇTAGA ÊûÑÂª∫‰∫Ü‰∏§‰∏™‰∫íË°•ÁöÑËßÜÂõæÔºöÂõæÊñáÊú¨ËßÜÂõæÔºåÂÆÉÊ†πÊçÆÂõæÊãìÊâëÂ∞ÜËäÇÁÇπÊñáÊú¨ÁªÑÁªáÊàêÁªìÊûÑÂåñÊñáÊ°£ÔºõÊñáÊú¨ÂõæËßÜÂõæÔºåÂÆÉÂ∞ÜÊñáÊú¨ËäÇÁÇπÂíåËøûÊé•ËΩ¨Êç¢‰∏∫ÂõæÊï∞ÊçÆ„ÄÇÈÄöËøáÂØπÈΩêÊù•Ëá™‰∏§‰∏™ËßÜÂõæÁöÑË°®Á§∫ÔºåTAGA ÊçïËé∑‰∫ÜËÅîÂêàÊñáÊú¨ÂíåÁªìÊûÑ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁªìÊûÑ‰øùÊåÅÈöèÊú∫Ê∏∏Ëµ∞ÁÆóÊ≥ïÔºåÁî®‰∫éÂØπÂ§ßÂûã TAG ËøõË°åÈ´òÊïàËÆ≠ÁªÉ„ÄÇÊàë‰ª¨ÁöÑÊ°ÜÊû∂Âú®ÂÖ´‰∏™ÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÈõÜÁöÑÈõ∂Ê†∑Êú¨ÂíåÂ∞ëÊ†∑Êú¨Âú∫ÊôØ‰∏≠Â±ïÁ§∫‰∫ÜÂº∫Â§ßÁöÑÊÄßËÉΩ„ÄÇ

##### **KG-FIT: Knowledge Graph Fine-Tuning Upon Open-World Knowledge**
2405.16412v2 by Pengcheng Jiang, Lang Cao, Cao Xiao, Parminder Bhatia, Jimeng Sun, Jiawei Han

Knowledge Graph Embedding (KGE) techniques are crucial in learning compact
representations of entities and relations within a knowledge graph,
facilitating efficient reasoning and knowledge discovery. While existing
methods typically focus either on training KGE models solely based on graph
structure or fine-tuning pre-trained language models with classification data
in KG, KG-FIT leverages LLM-guided refinement to construct a semantically
coherent hierarchical structure of entity clusters. By incorporating this
hierarchical knowledge along with textual information during the fine-tuning
process, KG-FIT effectively captures both global semantics from the LLM and
local semantics from the KG. Extensive experiments on the benchmark datasets
FB15K-237, YAGO3-10, and PrimeKG demonstrate the superiority of KG-FIT over
state-of-the-art pre-trained language model-based methods, achieving
improvements of 14.4%, 13.5%, and 11.9% in the Hits@10 metric for the link
prediction task, respectively. Furthermore, KG-FIT yields substantial
performance gains of 12.6%, 6.7%, and 17.7% compared to the structure-based
base models upon which it is built. These results highlight the effectiveness
of KG-FIT in incorporating open-world knowledge from LLMs to significantly
enhance the expressiveness and informativeness of KG embeddings.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñÂµåÂÖ• (KGE) ÊäÄË°ìÂ∞çÊñºÂ≠∏ÁøíÁü•Ë≠òÂúñ‰∏≠ÂØ¶È´îÂíåÈóú‰øÇÁöÑÁ∑äÊπäË°®Á§∫Ëá≥ÈóúÈáçË¶ÅÔºåÊúâÂä©ÊñºÈ´òÊïàÊé®ÁêÜÂíåÁü•Ë≠òÁôºÁèæ„ÄÇÈõñÁÑ∂ÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂÅ¥ÈáçÊñºÂÉÖÂü∫ÊñºÂúñÂΩ¢ÁµêÊßãË®ìÁ∑¥ KGE Ê®°ÂûãÊàñ‰ΩøÁî® KG ‰∏≠ÁöÑÂàÜÈ°ûÊï∏ÊìöÂæÆË™øÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÔºå‰ΩÜ KG-FIT Âà©Áî® LLM ÂºïÂ∞éÁöÑÂÑ™Âåñ‰æÜÊßãÂª∫ÂØ¶È´îÁæ§ÈõÜÁöÑË™ûÁæ©‰∏ÄËá¥ÂàÜÂ±§ÁµêÊßã„ÄÇÈÄèÈÅéÂú®ÂæÆË™øÈÅéÁ®ã‰∏≠Â∞áÊ≠§ÂàÜÂ±§Áü•Ë≠òËàáÊñáÊú¨Ë≥áË®äÁµêÂêàÔºåKG-FIT ÊúâÊïàÂú∞Êì∑Âèñ‰∫Ü LLM ÁöÑÂÖ®Â±ÄË™ûÁæ©Âíå KG ÁöÑÂ±ÄÈÉ®Ë™ûÁæ©„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ FB15K-237„ÄÅYAGO3-10 Âíå PrimeKG ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü KG-FIT ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÊñπÊ≥ïÔºåÂú®ÈÄ£ÁµêÈ†êÊ∏¨‰ªªÂãô‰∏≠ÔºåHits@10 ÊåáÊ®ôÂàÜÂà•ÊèêÂçá‰∫Ü 14.4%„ÄÅ13.5% Âíå 11.9%„ÄÇÊ≠§Â§ñÔºåËàáÂÖ∂Âª∫Á´ãÁöÑÂü∫ÊñºÁµêÊßãÁöÑÂü∫Á§éÊ®°ÂûãÁõ∏ÊØîÔºåKG-FIT Áî¢Áîü‰∫Ü 12.6%„ÄÅ6.7% Âíå 17.7% ÁöÑÈ°ØËëóÊïàËÉΩÊèêÂçá„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫Ü KG-FIT Âú®ÁµêÂêà‰æÜËá™ LLM ÁöÑÈñãÊîæ‰∏ñÁïåÁü•Ë≠ò‰ª•È°ØËëóÂ¢ûÂº∑ KG ÂµåÂÖ•ÁöÑË°®ÁèæÂäõÂíåË≥áË®äÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level**
2405.16405v1 by Runlin Lei, Yuwei Hu, Yuchen Ren, Zhewei Wei

Graph Neural Networks (GNNs) excel across various applications but remain
vulnerable to adversarial attacks, particularly Graph Injection Attacks (GIAs),
which inject malicious nodes into the original graph and pose realistic
threats. Text-attributed graphs (TAGs), where nodes are associated with textual
features, are crucial due to their prevalence in real-world applications and
are commonly used to evaluate these vulnerabilities. However, existing research
only focuses on embedding-level GIAs, which inject node embeddings rather than
actual textual content, limiting their applicability and simplifying detection.
In this paper, we pioneer the exploration of GIAs at the text level, presenting
three novel attack designs that inject textual content into the graph. Through
theoretical and empirical analysis, we demonstrate that text interpretability,
a factor previously overlooked at the embedding level, plays a crucial role in
attack strength. Among the designs we investigate, the Word-frequency-based
Text-level GIA (WTGIA) is particularly notable for its balance between
performance and interpretability. Despite the success of WTGIA, we discover
that defenders can easily enhance their defenses with customized text embedding
methods or large language model (LLM)--based predictors. These insights
underscore the necessity for further research into the potential and practical
significance of text-level GIAs.

ÊëòË¶ÅÔºöÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Âú®ÂêÑÁ®ÆÊáâÁî®‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜ‰ªçÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìäÔºåÁâπÂà•ÊòØÂúñÂΩ¢Ê≥®ÂÖ•ÊîªÊìä (GIA)ÔºåÂÆÉÊúÉÂ∞áÊÉ°ÊÑèÁØÄÈªûÊ≥®ÂÖ•ÂéüÂßãÂúñÂΩ¢‰∏¶ÊßãÊàêÁèæÂØ¶Â®ÅËÑÖ„ÄÇÊñáÂ≠óÂ±¨ÊÄßÂúñÂΩ¢ (TAG) Áî±ÊñºÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÂæàÊôÆÈÅçÔºåÂõ†Ê≠§Ëá≥ÈóúÈáçË¶ÅÔºå‰∏¶‰∏îÈÄöÂ∏∏Áî®ÊñºË©ï‰º∞ÈÄô‰∫õÊºèÊ¥û„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂ÂÉÖÈóúÊ≥®ÂµåÂÖ•Â±§Á¥öÁöÑ GIAÔºåÂÆÉÊ≥®ÂÖ•ÁØÄÈªûÂµåÂÖ•ËÄåÈùûÂØ¶ÈöõÊñáÊú¨ÂÖßÂÆπÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÈÅ©Áî®ÊÄß‰∏¶Á∞°Âåñ‰∫ÜÊ™¢Ê∏¨„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁéáÂÖàÊé¢Á¥¢ÊñáÊú¨Â±§Á¥öÁöÑ GIAÔºåÊèêÂá∫‰∫Ü‰∏âÁ®ÆÂ∞áÊñáÊú¨ÂÖßÂÆπÊ≥®ÂÖ•ÂúñÂΩ¢ÁöÑÂâµÊñ∞ÊîªÊìäË®≠Ë®à„ÄÇÈÄèÈÅéÁêÜË´ñÂíåÂØ¶Ë≠âÂàÜÊûêÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊñáÊú¨ÂèØËß£ÈáãÊÄßÔºàÂú®ÂµåÂÖ•Â±§Á¥ö‰ª•ÂâçË¢´ÂøΩÁï•ÁöÑÂõ†Á¥†ÔºâÂú®ÊîªÊìäÂº∑Â∫¶‰∏≠ÊâÆÊºî‰∫ÜËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂú®ÊàëÂÄëË™øÊü•ÁöÑË®≠Ë®à‰∏≠ÔºåÂü∫ÊñºË©ûÈ†ªÁöÑÊñáÊú¨Â±§Á¥ö GIA (WTGIA) ÁâπÂà•‰ª•ÂÖ∂ÊïàËÉΩÂíåÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÂπ≥Ë°°ËÄåËëóÁ®±„ÄÇÂÑòÁÆ° WTGIA ÊàêÂäüÁöÑÔºåÊàëÂÄëÁôºÁèæÈò≤Á¶¶ËÄÖÂèØ‰ª•ÈÄèÈÅéËá™Ë®ÇÊñáÂ≠óÂµåÂÖ•ÊñπÊ≥ïÊàñÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫Âü∫Á§éÁöÑÈ†êÊ∏¨Âô®ËºïÈ¨ÜÂä†Âº∑‰ªñÂÄëÁöÑÈò≤Á¶¶„ÄÇÈÄô‰∫õË¶ãËß£Âº∑Ë™øÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÊñáÊú¨Â±§Á¥ö GIA ÁöÑÊΩõÂäõÂíåÂØ¶ÈöõÊÑèÁæ©ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **COLT: Towards Completeness-Oriented Tool Retrieval for Large Language Models**
2405.16089v1 by Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen

Recently, the integration of external tools with Large Language Models (LLMs)
has emerged as a promising approach to overcome the inherent constraints of
their pre-training data. However, realworld applications often involve a
diverse range of tools, making it infeasible to incorporate all tools directly
into LLMs due to constraints on input length and response time. Therefore, to
fully exploit the potential of tool-augmented LLMs, it is crucial to develop an
effective tool retrieval system. Existing tool retrieval methods techniques
mainly rely on semantic matching between user queries and tool descriptions,
which often results in the selection of redundant tools. As a result, these
methods fail to provide a complete set of diverse tools necessary for
addressing the multifaceted problems encountered by LLMs. In this paper, we
propose a novel modelagnostic COllaborative Learning-based Tool Retrieval
approach, COLT, which captures not only the semantic similarities between user
queries and tool descriptions but also takes into account the collaborative
information of tools. Specifically, we first fine-tune the PLM-based retrieval
models to capture the semantic relationships between queries and tools in the
semantic learning stage. Subsequently, we construct three bipartite graphs
among queries, scenes, and tools and introduce a dual-view graph collaborative
learning framework to capture the intricate collaborative relationships among
tools during the collaborative learning stage. Extensive experiments on both
the open benchmark and the newly introduced ToolLens dataset show that COLT
achieves superior performance. Notably, the performance of BERT-mini (11M) with
our proposed model framework outperforms BERT-large (340M), which has 30 times
more parameters. Additionally, we plan to publicly release the ToolLens dataset
to support further research in tool retrieval.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºåÂ§ñÈÉ®Â∑•ÂÖ∑‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÊï¥ÂêàÂ∑≤Êàê‰∏∫ÂÖãÊúçÂÖ∂È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÂõ∫ÊúâÁ∫¶ÊùüÁöÑ‰∏ÄÁßçÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁé∞ÂÆû‰∏ñÁïåÁöÑÂ∫îÁî®Á®ãÂ∫èÈÄöÂ∏∏Ê∂âÂèäÂêÑÁßçÂ∑•ÂÖ∑ÔºåÁî±‰∫éËæìÂÖ•ÈïøÂ∫¶ÂíåÂìçÂ∫îÊó∂Èó¥ÁöÑÈôêÂà∂ÔºåÂ∞ÜÊâÄÊúâÂ∑•ÂÖ∑Áõ¥Êé•Êï¥ÂêàÂà∞ LLM ‰∏≠ÊòØ‰∏çÂèØË°åÁöÑ„ÄÇÂõ†Ê≠§Ôºå‰∏∫‰∫ÜÂÖÖÂàÜÂà©Áî®Â∑•ÂÖ∑Â¢ûÂº∫Âûã LLM ÁöÑÊΩúÂäõÔºåËá≥ÂÖ≥ÈáçË¶ÅÁöÑÊòØÂºÄÂèë‰∏Ä‰∏™ÊúâÊïàÁöÑÂ∑•ÂÖ∑Ê£ÄÁ¥¢Á≥ªÁªü„ÄÇÁé∞ÊúâÁöÑÂ∑•ÂÖ∑Ê£ÄÁ¥¢ÊñπÊ≥ïÊäÄÊúØ‰∏ªË¶Å‰æùËµñ‰∫éÁî®Êà∑Êü•ËØ¢ÂíåÂ∑•ÂÖ∑ÊèèËø∞‰πãÈó¥ÁöÑËØ≠‰πâÂåπÈÖçÔºåËøôÈÄöÂ∏∏‰ºöÂØºËá¥ÈÄâÊã©ÂÜó‰ΩôÂ∑•ÂÖ∑„ÄÇÂõ†Ê≠§ÔºåËøô‰∫õÊñπÊ≥ïÊó†Ê≥ïÊèê‰æõËß£ÂÜ≥ LLM ÈÅáÂà∞ÁöÑÂ§öÊñπÈù¢ÈóÆÈ¢òÊâÄÈúÄÁöÑÂÆåÊï¥‰∏îÂ§öÊ†∑ÂåñÁöÑÂ∑•ÂÖ∑ÈõÜ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑ‰∏éÊ®°ÂûãÊó†ÂÖ≥ÁöÑÂü∫‰∫éÂçè‰ΩúÂ≠¶‰π†ÁöÑÂ∑•ÂÖ∑Ê£ÄÁ¥¢ÊñπÊ≥ï COLTÔºåÂÆÉ‰∏ç‰ªÖÊçïËé∑‰∫ÜÁî®Êà∑Êü•ËØ¢ÂíåÂ∑•ÂÖ∑ÊèèËø∞‰πãÈó¥ÁöÑËØ≠‰πâÁõ∏‰ººÊÄßÔºåËøòËÄÉËôë‰∫ÜÂ∑•ÂÖ∑ÁöÑÂçè‰Ωú‰ø°ÊÅØ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨È¶ñÂÖàÂæÆË∞ÉÂü∫‰∫é PLM ÁöÑÊ£ÄÁ¥¢Ê®°ÂûãÔºå‰ª•Âú®ËØ≠‰πâÂ≠¶‰π†Èò∂ÊÆµÊçïËé∑Êü•ËØ¢ÂíåÂ∑•ÂÖ∑‰πãÈó¥ÁöÑËØ≠‰πâÂÖ≥Á≥ª„ÄÇÈöèÂêéÔºåÊàë‰ª¨Âú®Êü•ËØ¢„ÄÅÂú∫ÊôØÂíåÂ∑•ÂÖ∑‰πãÈó¥ÊûÑÂª∫‰∫Ü‰∏â‰∏™‰∫åÂàÜÂõæÔºåÂπ∂ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÂèåËßÜÂõæÂõæÂçè‰ΩúÂ≠¶‰π†Ê°ÜÊû∂Ôºå‰ª•Âú®Âçè‰ΩúÂ≠¶‰π†Èò∂ÊÆµÊçïËé∑Â∑•ÂÖ∑‰πãÈó¥ÈîôÁªºÂ§çÊùÇÁöÑÂçè‰ΩúÂÖ≥Á≥ª„ÄÇÂú®ÂºÄÊîæÂü∫ÂáÜÂíåÊñ∞ÂºïÂÖ•ÁöÑ ToolLens Êï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåCOLT ÂèñÂæó‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑÊ®°ÂûãÊ°ÜÊû∂‰∏≠ BERT-miniÔºà11MÔºâÁöÑÊÄßËÉΩ‰ºò‰∫é BERT-largeÔºà340MÔºâÔºåËÄåÂêéËÄÖÁöÑÂèÇÊï∞Â§ö 30 ÂÄç„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆ°ÂàíÂÖ¨ÂºÄÂèëÂ∏É ToolLens Êï∞ÊçÆÈõÜÔºå‰ª•ÊîØÊåÅÂ∑•ÂÖ∑Ê£ÄÁ¥¢ÁöÑËøõ‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ</paragraph>

##### **Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias**
2405.15739v2 by Andres Algaba, Carmen Mazijn, Vincent Holst, Floriano Tori, Sylvia Wenmackers, Vincent Ginis

Citation practices are crucial in shaping the structure of scientific
knowledge, yet they are often influenced by contemporary norms and biases. The
emergence of Large Language Models (LLMs) like GPT-4 introduces a new dynamic
to these practices. Interestingly, the characteristics and potential biases of
references recommended by LLMs that entirely rely on their parametric
knowledge, and not on search or retrieval-augmented generation, remain
unexplored. Here, we analyze these characteristics in an experiment using a
dataset of 166 papers from AAAI, NeurIPS, ICML, and ICLR, published after
GPT-4's knowledge cut-off date, encompassing 3,066 references in total. In our
experiment, GPT-4 was tasked with suggesting scholarly references for the
anonymized in-text citations within these papers. Our findings reveal a
remarkable similarity between human and LLM citation patterns, but with a more
pronounced high citation bias in GPT-4, which persists even after controlling
for publication year, title length, number of authors, and venue. Additionally,
we observe a large consistency between the characteristics of GPT-4's existing
and non-existent generated references, indicating the model's internalization
of citation patterns. By analyzing citation graphs, we show that the references
recommended by GPT-4 are embedded in the relevant citation context, suggesting
an even deeper conceptual internalization of the citation networks. While LLMs
can aid in citation generation, they may also amplify existing biases and
introduce new ones, potentially skewing scientific knowledge dissemination. Our
results underscore the need for identifying the model's biases and for
developing balanced methods to interact with LLMs in general.

ÊëòË¶ÅÔºö<paragraph>ÂºïË≠âÂØ¶ÂãôÂ∞çÊñºÂΩ¢Â°ëÁßëÂ≠∏Áü•Ë≠òÁöÑÁµêÊßãËá≥ÈóúÈáçË¶ÅÔºåÁÑ∂ËÄåÂæÄÂæÄÊúÉÂèóÂà∞Áï∂‰ª£Ë¶èÁØÑÂíåÂÅèË¶ãÁöÑÂΩ±Èüø„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â¶Ç GPT-4 ÁöÑÂá∫ÁèæÔºåÁÇ∫ÈÄô‰∫õÂØ¶ÂãôÂ∏∂‰æÜ‰∫ÜÊñ∞ÁöÑÂãïÊÖã„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂÆåÂÖ®‰æùË≥¥ÂÖ∂ÂèÉÊï∏ÂåñÁü•Ë≠òÔºàËÄåÈùûÊêúÂ∞ãÊàñÊ™¢Á¥¢Â¢ûÂº∑ÁöÑÁîüÊàêÔºâÁöÑ LLM ÊâÄÊé®Ëñ¶ÁöÑÂèÉËÄÉÊñáÁçªÔºåÂÖ∂ÁâπÊÄßÂíåÊΩõÂú®ÂÅèË¶ã‰ªçÊú™Ë¢´Êé¢Ë®é„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄãÂåÖÂê´ 166 ÁØáË´ñÊñáÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åÂØ¶È©óÔºåÂàÜÊûêÈÄô‰∫õÁâπÊÄßÔºåÈÄô‰∫õË´ñÊñá‰æÜËá™ AAAI„ÄÅNeurIPS„ÄÅICML Âíå ICLRÔºå‰∏¶Êñº GPT-4 Áü•Ë≠òÊà™Ê≠¢Êó•ÊúüÂæåÁôºË°®ÔºåÁ∏ΩÂÖ±Ê∂µËìã 3,066 ÁØáÂèÉËÄÉÊñáÁçª„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåGPT-4 ÁöÑ‰ªªÂãôÊòØÁÇ∫ÈÄô‰∫õË´ñÊñá‰∏≠ÂåøÂêçÁöÑÂÖßÊñáÂºïÊñáÂª∫Ë≠∞Â≠∏Ë°ìÂèÉËÄÉÊñáÁçª„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫Ôºå‰∫∫È°ûÂíå LLM ÁöÑÂºïË≠âÊ®°ÂºèÊúâÈ°ØËëóÁöÑÁõ∏‰ººÊÄßÔºå‰ΩÜ GPT-4 ÁöÑÈ´òÂºïË≠âÂÅèË¶ãËºÉÁÇ∫ÊòéÈ°ØÔºåÂç≥‰ΩøÂú®ÊéßÂà∂‰∫ÜÂá∫ÁâàÂπ¥‰ªΩ„ÄÅÊ®ôÈ°åÈï∑Â∫¶„ÄÅ‰ΩúËÄÖ‰∫∫Êï∏ÂíåÁôºË°®Âú∞ÈªûÂæåÔºåÈÄôÁ®ÆÂÅèË¶ã‰ªçÁÑ∂Â≠òÂú®„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëËßÄÂØüÂà∞ GPT-4 ÁèæÊúâÂíå‰∏çÂ≠òÂú®ÁöÑÁîüÊàêÂèÉËÄÉÊñáÁçª‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄßÂæàÈ´òÔºåÈÄôË°®Á§∫Ê®°ÂûãÂÖßÂåñ‰∫ÜÂºïË≠âÊ®°Âºè„ÄÇÈÄèÈÅéÂàÜÊûêÂºïË≠âÂúñÔºåÊàëÂÄëÁôºÁèæ GPT-4 Êé®Ëñ¶ÁöÑÂèÉËÄÉÊñáÁçªÂµåÂÖ•Âú®Áõ∏ÈóúÁöÑÂºïË≠âËÑàÁµ°‰∏≠ÔºåÈÄôË°®Á§∫Â∞çÂºïË≠âÁ∂≤Ë∑ØÊúâÊõ¥Ê∑±ÂÖ•ÁöÑÊ¶ÇÂøµÂÖßÂåñ„ÄÇÈõñÁÑ∂ LLM ÂèØ‰ª•ÂçîÂä©ÁîüÊàêÂºïË≠âÔºå‰ΩÜÂÆÉÂÄë‰πüÂèØËÉΩÊîæÂ§ßÁèæÊúâÁöÑÂÅèË¶ã‰∏¶ÂºïÂÖ•Êñ∞ÁöÑÂÅèË¶ãÔºåÈÄ≤ËÄåÂèØËÉΩÊâ≠Êõ≤ÁßëÂ≠∏Áü•Ë≠òÁöÑÂÇ≥Êí≠„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜË≠òÂà•Ê®°ÂûãÂÅèË¶ãÂíåÈñãÁôºËàá LLM ‰∫íÂãïÁöÑÂπ≥Ë°°ÊñπÊ≥ïÁöÑÈúÄÊ±Ç„ÄÇ</paragraph>


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-17**|**Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**|Artur Jurgas et.al.|[2406.11538v1](http://arxiv.org/abs/2406.11538v1)|null|
|**2024-06-17**|**Formally Certified Approximate Model Counting**|Yong Kiam Tan et.al.|[2406.11414v1](http://arxiv.org/abs/2406.11414v1)|null|
|**2024-06-17**|**Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection**|Sungwon Park et.al.|[2406.11260v1](http://arxiv.org/abs/2406.11260v1)|null|
|**2024-06-17**|**Scorecards for Synthetic Medical Data Evaluation and Reporting**|Ghada Zamzmi et.al.|[2406.11143v1](http://arxiv.org/abs/2406.11143v1)|null|
|**2024-06-17**|**Diffusion Models in Low-Level Vision: A Survey**|Chunming He et.al.|[2406.11138v1](http://arxiv.org/abs/2406.11138v1)|null|
|**2024-06-17**|**Towards Understanding Emotions for Engaged Mental Health Conversations**|Kellie Yu Hui Sim et.al.|[2406.11135v1](http://arxiv.org/abs/2406.11135v1)|null|
|**2024-06-16**|**Boosting Medical Image Classification with Segmentation Foundation Model**|Pengfei Gu et.al.|[2406.11026v1](http://arxiv.org/abs/2406.11026v1)|null|
|**2024-06-16**|**ALPS: An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model**|Song Zhang et.al.|[2406.10855v1](http://arxiv.org/abs/2406.10855v1)|[link](https://github.com/strivezs/alps)|
|**2024-06-15**|**A Comprehensive Survey of Foundation Models in Medicine**|Wasif Khan et.al.|[2406.10729v1](http://arxiv.org/abs/2406.10729v1)|null|
|**2024-06-15**|**SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**|Ziije Zhong et.al.|[2406.10710v1](http://arxiv.org/abs/2406.10710v1)|null|
|**2024-06-15**|**Applications of Generative AI in Healthcare: algorithmic, ethical, legal and societal considerations**|Onyekachukwu R. Okonji et.al.|[2406.10632v1](http://arxiv.org/abs/2406.10632v1)|null|
|**2024-06-15**|**Public Computer Vision Datasets for Precision Livestock Farming: A Systematic Survey**|Anil Bhujel et.al.|[2406.10628v1](http://arxiv.org/abs/2406.10628v1)|null|
|**2024-06-15**|**Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation**|Pengfei Gu et.al.|[2406.10519v1](http://arxiv.org/abs/2406.10519v1)|null|
|**2024-06-14**|**Biomarker based Cancer Classification using an Ensemble with Pre-trained Models**|Chongmin Lee et.al.|[2406.10087v1](http://arxiv.org/abs/2406.10087v1)|null|
|**2024-06-14**|**FZI-WIM at SemEval-2024 Task 2: Self-Consistent CoT for Complex NLI in Biomedical Domain**|Jin Liu et.al.|[2406.10040v1](http://arxiv.org/abs/2406.10040v1)|[link](https://github.com/jens5588/fzi-wim-nli4ct)|
|**2024-06-14**|**CliBench: Multifaceted Evaluation of Large Language Models in Clinical Decisions on Diagnoses, Procedures, Lab Tests Orders and Prescriptions**|Mingyu Derek Ma et.al.|[2406.09923v1](http://arxiv.org/abs/2406.09923v1)|[link](https://github.com/clibench/clibench)|
|**2024-06-14**|**A Survey on Large Language Models from General Purpose to Medical Applications: Datasets, Methodologies, and Evaluations**|Jinqiang Wang et.al.|[2406.10303v1](http://arxiv.org/abs/2406.10303v1)|null|
|**2024-06-13**|**Investigating potential causes of Sepsis with Bayesian network structure learning**|Bruno Petrungaro et.al.|[2406.09207v1](http://arxiv.org/abs/2406.09207v1)|null|
|**2024-06-13**|**INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance**|Chenwei Lin et.al.|[2406.09105v1](http://arxiv.org/abs/2406.09105v1)|[link](https://github.com/fdu-ins/ins-mmbench)|
|**2024-06-13**|**Deep learning empowered sensor fusion to improve infant movement classification**|Tomas Kulvicius et.al.|[2406.09014v2](http://arxiv.org/abs/2406.09014v2)|null|
|**2024-06-13**|**Efficient Multi-View Fusion and Flexible Adaptation to View Missing in Cardiovascular System Signals**|Qihan Hu et.al.|[2406.08930v1](http://arxiv.org/abs/2406.08930v1)|null|
|**2024-06-13**|**Computer Vision Approaches for Automated Bee Counting Application**|Simon Bilik et.al.|[2406.08898v1](http://arxiv.org/abs/2406.08898v1)|null|
|**2024-06-13**|**Automatically Labeling $200B Life-Saving Datasets: A Large Clinical Trial Outcome Benchmark**|Chufan Gao et.al.|[2406.10292v1](http://arxiv.org/abs/2406.10292v1)|null|
|**2024-06-12**|**Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory Analysis**|Attrayee Chakraborty et.al.|[2406.08695v1](http://arxiv.org/abs/2406.08695v1)|null|
|**2024-06-12**|**Advancing High Resolution Vision-Language Models in Biomedicine**|Zekai Chen et.al.|[2406.09454v1](http://arxiv.org/abs/2406.09454v1)|[link](https://github.com/standardmodelbio/llama3-med)|
|**2024-06-12**|**AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images**|Ayush Roy et.al.|[2406.08425v1](http://arxiv.org/abs/2406.08425v1)|[link](https://github.com/ayushroy2001/awgunet)|
|**2024-06-12**|**2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction**|Tianqi Chen et.al.|[2406.08374v2](http://arxiv.org/abs/2406.08374v2)|null|
|**2024-06-12**|**Making AI Intelligible: Philosophical Foundations**|Herman Cappelen et.al.|[2406.08134v1](http://arxiv.org/abs/2406.08134v1)|null|
|**2024-06-12**|**Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks**|Peizhi Niu et.al.|[2406.07917v1](http://arxiv.org/abs/2406.07917v1)|null|
|**2024-06-11**|**Beyond Words: On Large Language Models Actionability in Mission-Critical Risk Analysis**|Matteo Esposito et.al.|[2406.10273v1](http://arxiv.org/abs/2406.10273v1)|null|
|**2024-06-11**|**Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis**|David Ortiz-Perez et.al.|[2406.07542v1](http://arxiv.org/abs/2406.07542v1)|[link](https://github.com/davidorp/taukadial)|
|**2024-06-11**|**CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**|Frederic Kirstein et.al.|[2406.07494v2](http://arxiv.org/abs/2406.07494v2)|null|
|**2024-06-11**|**Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images**|Che Liu et.al.|[2406.07146v2](http://arxiv.org/abs/2406.07146v2)|null|
|**2024-06-11**|**Unlocking the Potential of the Metaverse for Innovative and Immersive Digital Care**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v1](http://arxiv.org/abs/2406.07114v1)|null|
|**2024-06-11**|**Heterogeneous Learning Rate Scheduling for Neural Architecture Search on Long-Tailed Datasets**|Chenxia Tang et.al.|[2406.07028v1](http://arxiv.org/abs/2406.07028v1)|null|
|**2024-06-10**|**Taxes Are All You Need: Integration of Taxonomical Hierarchy Relationships into the Contrastive Loss**|Kiran Kokilepersaud et.al.|[2406.06848v1](http://arxiv.org/abs/2406.06848v1)|null|
|**2024-06-10**|**SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature**|David Wadden et.al.|[2406.07835v1](http://arxiv.org/abs/2406.07835v1)|null|
|**2024-06-10**|**BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification**|June-Woo Kim et.al.|[2406.06786v2](http://arxiv.org/abs/2406.06786v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Merlin: A Vision Language Foundation Model for 3D Computed Tomography**|Louis Blankemeier et.al.|[2406.06512v1](http://arxiv.org/abs/2406.06512v1)|null|
|**2024-06-10**|**Towards a Personal Health Large Language Model**|Justin Cosentino et.al.|[2406.06474v1](http://arxiv.org/abs/2406.06474v1)|null|
|**2024-06-10**|**Transforming Wearable Data into Health Insights using Large Language Model Agents**|Mike A. Merrill et.al.|[2406.06464v2](http://arxiv.org/abs/2406.06464v2)|null|
|**2024-06-10**|**A Large Language Model Pipeline for Breast Cancer Oncology**|Tristen Pool et.al.|[2406.06455v2](http://arxiv.org/abs/2406.06455v2)|null|
|**2024-06-10**|**Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain**|Brian Hu et.al.|[2406.06435v1](http://arxiv.org/abs/2406.06435v1)|[link](https://github.com/itm-kitware/llm-alignable-dm)|
|**2024-06-10**|**Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models**|Marek Wodzinski et.al.|[2406.06372v1](http://arxiv.org/abs/2406.06372v1)|null|
|**2024-06-10**|**MedExQA: Medical Question Answering Benchmark with Multiple Explanations**|Yunsoo Kim et.al.|[2406.06331v1](http://arxiv.org/abs/2406.06331v1)|null|
|**2024-06-10**|**BrainChat: Decoding Semantic Information from fMRI using Vision-language Pretrained Models**|Wanaiu Huang et.al.|[2406.07584v1](http://arxiv.org/abs/2406.07584v1)|null|
|**2024-06-10**|**A Dual-View Approach to Classifying Radiology Reports by Co-Training**|Yutong Han et.al.|[2406.05995v1](http://arxiv.org/abs/2406.05995v1)|[link](https://github.com/manga-uofa/radiology-cotrain)|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-10**|**Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context**|Jingru Jia et.al.|[2406.05972v1](http://arxiv.org/abs/2406.05972v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-09**|**From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR**|Ran Xu et.al.|[2406.05682v1](http://arxiv.org/abs/2406.05682v1)|null|
|**2024-06-09**|**CCSI: Continual Class-Specific Impression for Data-free Class Incremental Learning**|Sana Ayromlou et.al.|[2406.05631v1](http://arxiv.org/abs/2406.05631v1)|[link](https://github.com/ubc-tea/continual-impression-ccsi)|
|**2024-06-09**|**Which Backbone to Use: A Resource-efficient Domain Specific Comparison for Computer Vision**|Pranav Jeevan et.al.|[2406.05612v1](http://arxiv.org/abs/2406.05612v1)|[link](https://github.com/pranavphoenix/Backbones)|
|**2024-06-08**|**I-SIRch: AI-Powered Concept Annotation Tool For Equitable Extraction And Analysis Of Safety Insights From Maternity Investigations**|Mohit Kumar Singh et.al.|[2406.05505v1](http://arxiv.org/abs/2406.05505v1)|null|
|**2024-06-08**|**DeviceBERT: Applied Transfer Learning With Targeted Annotations and Vocabulary Enrichment to Identify Medical Device and Component Terminology in FDA Recall Summaries**|Miriam Farrington et.al.|[2406.05307v1](http://arxiv.org/abs/2406.05307v1)|null|
|**2024-06-07**|**Analyzing the factors that are involved in length of inpatient stay at the hospital for diabetes patients**|Jorden Lam et.al.|[2406.05189v1](http://arxiv.org/abs/2406.05189v1)|null|
|**2024-06-07**|**Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study**|Deepa Tilwani et.al.|[2406.05002v1](http://arxiv.org/abs/2406.05002v1)|[link](https://github.com/lina-usc/jansen-rit-model-benchmarking-deep-learning)|
|**2024-06-07**|**DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation**|Weiqi Zhang et.al.|[2406.06620v1](http://arxiv.org/abs/2406.06620v1)|null|
|**2024-06-07**|**CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling**|Matthew Fortier et.al.|[2406.04940v1](http://arxiv.org/abs/2406.04940v1)|null|
|**2024-06-07**|**PANDORA: Deep graph learning based COVID-19 infection risk level forecasting**|Shuo Yu et.al.|[2406.06618v1](http://arxiv.org/abs/2406.06618v1)|null|
|**2024-06-07**|**Transforming Dental Diagnostics with Artificial Intelligence: Advanced Integration of ChatGPT and Large Language Models for Patient Care**|Masoumeh Farhadi Nia et.al.|[2406.06616v1](http://arxiv.org/abs/2406.06616v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-06**|**Rare Class Prediction Model for Smart Industry in Semiconductor Manufacturing**|Abdelrahman Farrag et.al.|[2406.04533v1](http://arxiv.org/abs/2406.04533v1)|null|
|**2024-06-06**|**Single Exposure Quantitative Phase Imaging with a Conventional Microscope using Diffusion Models**|Gabriel della Maggiora et.al.|[2406.04388v1](http://arxiv.org/abs/2406.04388v1)|null|
|**2024-06-06**|**Promoting Fairness and Diversity in Speech Datasets for Mental Health and Neurological Disorders Research**|Eleonora Mancini et.al.|[2406.04116v1](http://arxiv.org/abs/2406.04116v1)|null|
|**2024-06-06**|**Leveraging SPD Matrices on Riemannian Manifolds in Quantum Classical Hybrid Models for Structural Health Monitoring**|Azadeh Alavi et.al.|[2406.04055v1](http://arxiv.org/abs/2406.04055v1)|null|
|**2024-06-05**|**Speech-based Clinical Depression Screening: An Empirical Study**|Yangbin Chen et.al.|[2406.03510v2](http://arxiv.org/abs/2406.03510v2)|null|
|**2024-06-05**|**Robust Prediction Model for Multidimensional and Unbalanced Datasets**|Pooja Thakar et.al.|[2406.03507v1](http://arxiv.org/abs/2406.03507v1)|null|
|**2024-06-05**|**Stochastic Diffusion: A Diffusion Probabilistic Model for Stochastic Time Series Forecasting**|Yuansan Liu et.al.|[2406.02827v1](http://arxiv.org/abs/2406.02827v1)|null|
|**2024-06-04**|**Pancreatic Tumor Segmentation as Anomaly Detection in CT Images Using Denoising Diffusion Models**|Reza Babaei et.al.|[2406.02653v1](http://arxiv.org/abs/2406.02653v1)|null|
|**2024-06-04**|**Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems**|Jason Hu et.al.|[2406.02462v1](http://arxiv.org/abs/2406.02462v1)|null|
|**2024-06-04**|**Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data**|Maxime Griot et.al.|[2406.02394v1](http://arxiv.org/abs/2406.02394v1)|[link](https://github.com/maximegmd/glianorex-gen)|
|**2024-06-04**|**LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing**|Maojun Sun et.al.|[2406.02350v2](http://arxiv.org/abs/2406.02350v2)|[link](https://github.com/stephen-smj/llamacare)|
|**2024-06-04**|**A Comparative Study of Sampling Methods with Cross-Validation in the FedHome Framework**|Arash Ahmadi et.al.|[2406.01950v1](http://arxiv.org/abs/2406.01950v1)|null|
|**2024-06-03**|**Enhancing Clinical Documentation with Synthetic Data: Leveraging Generative Models for Improved Accuracy**|Anjanava Biswas et.al.|[2406.06569v1](http://arxiv.org/abs/2406.06569v1)|null|
|**2024-06-03**|**Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization**|Firas Khader et.al.|[2406.01314v1](http://arxiv.org/abs/2406.01314v1)|null|
|**2024-06-03**|**TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models in Traditional Chinese Medicine**|Wenjing Yue et.al.|[2406.01126v1](http://arxiv.org/abs/2406.01126v1)|null|
|**2024-06-03**|**Effective Subset Selection Through The Lens of Neural Network Pruning**|Noga Bar et.al.|[2406.01086v1](http://arxiv.org/abs/2406.01086v1)|null|
|**2024-06-03**|**Causal prompting model-based offline reinforcement learning**|Xuehui Yu et.al.|[2406.01065v1](http://arxiv.org/abs/2406.01065v1)|null|
|**2024-06-03**|**Synthetic Data Generation for 3D Myocardium Deformation Analysis**|Shahar Zuler et.al.|[2406.01040v1](http://arxiv.org/abs/2406.01040v1)|[link](https://github.com/shaharzuler/cardio_volume_skewer)|
|**2024-06-03**|**MEDIQ: Question-Asking LLMs for Adaptive and Reliable Clinical Reasoning**|Shuyue Stella Li et.al.|[2406.00922v2](http://arxiv.org/abs/2406.00922v2)|[link](https://github.com/stellali7/mediq)|
|**2024-06-02**|**Bayesian Joint Additive Factor Models for Multiview Learning**|Niccolo Anceschi et.al.|[2406.00778v1](http://arxiv.org/abs/2406.00778v1)|[link](https://github.com/niccoloanceschi/jafar)|
|**2024-06-02**|**An Early Investigation into the Utility of Multimodal Large Language Models in Medical Imaging**|Sulaiman Khan et.al.|[2406.00667v1](http://arxiv.org/abs/2406.00667v1)|null|
|**2024-06-02**|**SimSAM: Zero-shot Medical Image Segmentation via Simulated Interaction**|Benjamin Towle et.al.|[2406.00663v1](http://arxiv.org/abs/2406.00663v1)|[link](https://github.com/benjamintowle/simsam)|
|**2024-06-02**|**Multimodal Deep Learning for Low-Resource Settings: A Vector Embedding Alignment Approach for Healthcare Applications**|David Restrepo et.al.|[2406.02601v1](http://arxiv.org/abs/2406.02601v1)|null|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models**|Sarthak Harne et.al.|[2406.00314v2](http://arxiv.org/abs/2406.00314v2)|[link](https://github.com/sarthakharne/case)|
|**2024-06-01**|**Lightening Anything in Medical Images**|Ben Fei et.al.|[2406.10236v1](http://arxiv.org/abs/2406.10236v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-31**|**DYNA: Disease-Specific Language Model for Variant Pathogenicity**|Huixin Zhan et.al.|[2406.00164v1](http://arxiv.org/abs/2406.00164v1)|null|
|**2024-05-31**|**Recurrent neural networks: vanishing and exploding gradients are not the end of the story**|Nicolas Zucchet et.al.|[2405.21064v1](http://arxiv.org/abs/2405.21064v1)|null|
|**2024-05-31**|**Generative Adversarial Networks in Ultrasound Imaging: Extending Field of View Beyond Conventional Limits**|Matej Gazda et.al.|[2405.20981v1](http://arxiv.org/abs/2405.20981v1)|null|
|**2024-05-31**|**OR-Bench: An Over-Refusal Benchmark for Large Language Models**|Justin Cui et.al.|[2405.20947v1](http://arxiv.org/abs/2405.20947v1)|null|
|**2024-05-31**|**ABodyBuilder3: Improved and scalable antibody structure predictions**|Henry Kenlay et.al.|[2405.20863v1](http://arxiv.org/abs/2405.20863v1)|[link](https://github.com/exscientia/abodybuilder3)|
|**2024-05-31**|**Maximum Temperature Prediction Using Remote Sensing Data Via Convolutional Neural Network**|Lorenzo Innocenti et.al.|[2405.20731v1](http://arxiv.org/abs/2405.20731v1)|null|
|**2024-05-31**|**GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models**|Mohammed-Khalil Ghali et.al.|[2405.20585v1](http://arxiv.org/abs/2405.20585v1)|null|
|**2024-05-31**|**The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes**|Alissa A. Valentine et.al.|[2405.20582v1](http://arxiv.org/abs/2405.20582v1)|null|
|**2024-05-31**|**Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study**|Haroon Miah et.al.|[2405.20562v1](http://arxiv.org/abs/2405.20562v1)|null|

#### Abstracts
##### **Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**
2406.11538v1 by Artur Jurgas, Marek Wodzinski, Marina D'Amato, Jeroen van der Laak, Manfredo Atzori, Henning M√ºller

The problem of artifacts in whole slide image acquisition, prevalent in both
clinical workflows and research-oriented settings, necessitates human
intervention and re-scanning. Overcoming this challenge requires developing
quality control algorithms, that are hindered by the limited availability of
relevant annotated data in histopathology. The manual annotation of
ground-truth for artifact detection methods is expensive and time-consuming.
This work addresses the issue by proposing a method dedicated to augmenting
whole slide images with artifacts. The tool seamlessly generates and blends
artifacts from an external library to a given histopathology dataset. The
augmented datasets are then utilized to train artifact classification methods.
The evaluation shows their usefulness in classification of the artifacts, where
they show an improvement from 0.10 to 0.01 AUROC depending on the artifact
type. The framework, model, weights, and ground-truth annotations are freely
released to facilitate open science and reproducible research.

ÊëòË¶ÅÔºöÂú®Ëá®Â∫ä‰∏äÊàñÁ†îÁ©∂‰∏≠ÔºåÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉèÊì∑ÂèñÊôÇÁî¢ÁîüÁöÑÂÅΩÂÉèÂïèÈ°åÔºåÈúÄË¶Å‰∫∫ÁÇ∫‰ªãÂÖ•ÂíåÈáçÊñ∞ÊéÉÊèè„ÄÇÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÈúÄË¶ÅÈñãÁôºÂìÅË≥™ÊéßÁÆ°ÊºîÁÆóÊ≥ïÔºå‰ΩÜÁµÑÁπîÁóÖÁêÜÂ≠∏‰∏≠Áõ∏ÈóúË®ªËß£Ë≥áÊñôÊúâÈôêÔºåÈòªÁ§ô‰∫ÜÊºîÁÆóÊ≥ïÁöÑÁôºÂ±ï„ÄÇ‰∫∫Â∑•Ë®ªËß£ÂÅΩÂÉèÂÅµÊ∏¨ÊñπÊ≥ïÁöÑÁúüÂØ¶ÊÉÖÊ≥ÅÊó¢ÊòÇË≤¥ÂèàË≤ªÊôÇ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈÄôÂÄãÊñπÊ≥ïÂ∞àÈñÄÁî®‰æÜÂ¢ûÂä†ÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉè‰∏≠ÁöÑÂÅΩÂÉè„ÄÇÈÄôÂÄãÂ∑•ÂÖ∑ÂèØ‰ª•ÁÑ°Á∏´Âú∞ÂæûÂ§ñÈÉ®Ë≥áÊñôÂ∫´Áî¢Áîü‰∏¶Ê∑∑ÂêàÂÅΩÂÉèÂà∞Áµ¶ÂÆöÁöÑÁµÑÁπîÁóÖÁêÜÂ≠∏Ë≥áÊñôÈõÜ„ÄÇÁÑ∂Âæå‰ΩøÁî®Êì¥ÂÖÖÂæåÁöÑË≥áÊñôÈõÜ‰æÜË®ìÁ∑¥ÂÅΩÂÉèÂàÜÈ°ûÊñπÊ≥ï„ÄÇË©ï‰º∞È°ØÁ§∫Âá∫ÂÆÉÂÄëÂú®ÂÅΩÂÉèÂàÜÈ°û‰∏≠ÁöÑÊïàÁî®ÔºåÂú®‰∏çÂêåÁöÑÂÅΩÂÉèÈ°ûÂûã‰∏≠ÔºåÂÆÉÂÄëÁöÑ AUROC Âæû 0.10 ÈÄ≤Ê≠•Âà∞ 0.01„ÄÇÈÄôÂÄãÊû∂Êßã„ÄÅÊ®°Âûã„ÄÅÊ¨äÈáçÂíåÁúüÂØ¶Ë®ªËß£ÊòØÂÖçË≤ªÈáãÂá∫ÁöÑÔºå‰ª•Âà©ÊñºÈñãÊîæÁßëÂ≠∏ÂíåÂèØÈáçË£ΩÁöÑÁ†îÁ©∂„ÄÇ

##### **Formally Certified Approximate Model Counting**
2406.11414v1 by Yong Kiam Tan, Jiong Yang, Mate Soos, Magnus O. Myreen, Kuldeep S. Meel

Approximate model counting is the task of approximating the number of
solutions to an input Boolean formula. The state-of-the-art approximate model
counter for formulas in conjunctive normal form (CNF), ApproxMC, provides a
scalable means of obtaining model counts with probably approximately correct
(PAC)-style guarantees. Nevertheless, the validity of ApproxMC's approximation
relies on a careful theoretical analysis of its randomized algorithm and the
correctness of its highly optimized implementation, especially the latter's
stateful interactions with an incremental CNF satisfiability solver capable of
natively handling parity (XOR) constraints.
  We present the first certification framework for approximate model counting
with formally verified guarantees on the quality of its output approximation.
Our approach combines: (i) a static, once-off, formal proof of the algorithm's
PAC guarantee in the Isabelle/HOL proof assistant; and (ii) dynamic, per-run,
verification of ApproxMC's calls to an external CNF-XOR solver using proof
certificates. We detail our general approach to establish a rigorous connection
between these two parts of the verification, including our blueprint for
turning the formalized, randomized algorithm into a verified proof checker, and
our design of proof certificates for both ApproxMC and its internal CNF-XOR
solving steps. Experimentally, we show that certificate generation adds little
overhead to an approximate counter implementation, and that our certificate
checker is able to fully certify $84.7\%$ of instances with generated
certificates when given the same time and memory limits as the counter.

ÊëòË¶ÅÔºöËøë‰ººÊ®°ÂûãË®àÊï∏ÊòØËøë‰ººËº∏ÂÖ•Â∏ÉÊûóÂÖ¨ÂºèÁöÑËß£ÁöÑÊï∏ÈáèÁöÑÂ∑•‰Ωú„ÄÇËÅØÈõÜÁØÑÂºè (CNF) ‰∏≠ÂÖ¨ÂºèÁöÑÊúÄÊñ∞Ëøë‰ººÊ®°ÂûãË®àÊï∏Âô® ApproxMC Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂèñÂæóÊ®°ÂûãË®àÊï∏Ôºå‰∏¶ÂÖ∑ÊúâÂèØËÉΩËøë‰ººÊ≠£Á¢∫ (PAC) ÂºèÁöÑ‰øùË≠â„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåApproxMC Ëøë‰ººÁöÑÊúâÊïàÊÄß‰æùË≥¥ÊñºÂÖ∂Èö®Ê©üÊºîÁÆóÊ≥ïÁöÑ‰ªîÁ¥∞ÁêÜË´ñÂàÜÊûêÔºå‰ª•ÂèäÂÖ∂È´òÂ∫¶ÊúÄ‰Ω≥ÂåñÂØ¶‰ΩúÁöÑÊ≠£Á¢∫ÊÄßÔºåÁâπÂà•ÊòØÂæåËÄÖËàáÂéüÁîüËôïÁêÜÂ•áÂÅ∂Ê†°È©ó (XOR) Á¥ÑÊùüÁöÑÂ¢ûÈáè CNF ÂèØÊªøË∂≥ÊÄßÊ±ÇËß£Âô®ÁöÑÊúâÁãÄÊÖã‰∫íÂãï„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËøë‰ººÊ®°ÂûãË®àÊï∏ÁöÑÁ¨¨‰∏ÄÂÄãË™çË≠âÊû∂ÊßãÔºåÂÖ∂Ëº∏Âá∫Ëøë‰ººÁöÑÂìÅË≥™ÂÖ∑ÊúâÊ≠£ÂºèÈ©óË≠âÁöÑ‰øùË≠â„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÁµêÂêàÔºö(i) Âú® Isabelle/HOL Ë≠âÊòéËºîÂä©Â∑•ÂÖ∑‰∏≠ÊºîÁÆóÊ≥ïÁöÑ PAC ‰øùË≠âÁöÑÈùúÊÖã„ÄÅ‰∏ÄÊ¨°ÊÄßÁöÑÊ≠£ÂºèË≠âÊòéÔºõ‰ª•Âèä (ii) ApproxMC Â∞çÂ§ñÈÉ® CNF-XOR Ê±ÇËß£Âô®ÂëºÂè´ÁöÑÂãïÊÖã„ÄÅÊØèÊ¨°Âü∑Ë°åÈ©óË≠âÔºå‰ΩøÁî®Ë≠âÊòéË≠âÊõ∏„ÄÇÊàëÂÄëË©≥Á¥∞Ë™™Êòé‰∫ÜÊàëÂÄëÂª∫Á´ãÈ©óË≠âÈÄôÂÖ©ÂÄãÈÉ®ÂàÜ‰πãÈñìÂö¥Ë¨πÈÄ£Êé•ÁöÑÈÄöÁî®ÂÅöÊ≥ïÔºåÂåÖÊã¨ÊàëÂÄëÂ∞áÂΩ¢ÂºèÂåñÈö®Ê©üÊºîÁÆóÊ≥ïËΩâËÆäÊàêÈ©óË≠âË≠âÊòéÊ™¢Êü•Âô®ÁöÑËóçÂúñÔºå‰ª•ÂèäÊàëÂÄëÁÇ∫ ApproxMC ÂèäÂÖ∂ÂÖßÈÉ® CNF-XOR Ê±ÇËß£Ê≠•È©üË®≠Ë®àÁöÑË≠âÊòéË≠âÊõ∏„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÈ°ØÁ§∫Ë≠âÊõ∏Áî¢ÁîüÁÇ∫Ëøë‰ººË®àÊï∏Âô®ÂØ¶‰ΩúÂ¢ûÂä†ÂæàÂ∞ëÁöÑÈñãÈä∑ÔºåËÄå‰∏îÊàëÂÄëÁöÑË≠âÊõ∏Ê™¢Êü•Âô®ËÉΩÂ§†Âú®ËàáË®àÊï∏Âô®Áµ¶‰∫àÁõ∏ÂêåÊôÇÈñìÂíåË®òÊÜ∂È´îÈôêÂà∂ÊôÇÔºåÂÆåÂÖ®Ë™çË≠â $84.7\%$ ÂÄãÂÖ∑ÊúâÁî¢ÁîüË≠âÊõ∏ÁöÑÂØ¶‰æã„ÄÇ

##### **Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection**
2406.11260v1 by Sungwon Park, Sungwon Han, Meeyoung Cha

The spread of fake news negatively impacts individuals and is regarded as a
significant social challenge that needs to be addressed. A number of
algorithmic and insightful features have been identified for detecting fake
news. However, with the recent LLMs and their advanced generation capabilities,
many of the detectable features (e.g., style-conversion attacks) can be
altered, making it more challenging to distinguish from real news. This study
proposes adversarial style augmentation, AdStyle, to train a fake news detector
that remains robust against various style-conversion attacks. Our model's key
mechanism is the careful use of LLMs to automatically generate a diverse yet
coherent range of style-conversion attack prompts. This improves the generation
of prompts that are particularly difficult for the detector to handle.
Experiments show that our augmentation strategy improves robustness and
detection performance when tested on fake news benchmark datasets.

ÊëòË¶ÅÔºöÂÅáÊñ∞ËÅûÁöÑÊï£Â∏ÉÂ∞çÂÄã‰∫∫ÈÄ†ÊàêË≤†Èù¢ÂΩ±ÈüøÔºå‰∏¶Ë¢´Ë¶ñÁÇ∫ÈúÄË¶ÅËß£Ê±∫ÁöÑÈáçÂ§ßÁ§æÊúÉÊåëÊà∞„ÄÇÂ∑≤Á∂ìÊâæÂá∫Ë®±Â§öÊºîÁÆóÊ≥ïÂíåÊúâË¶ãÂú∞ÁöÑÂäüËÉΩ‰æÜÂÅµÊ∏¨ÂÅáÊñ∞ËÅû„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóËøëÊúüÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèäÂÖ∂ÂÖàÈÄ≤ÁöÑÁî¢ÁîüËÉΩÂäõÔºåË®±Â§öÂèØÂÅµÊ∏¨ÁöÑÂäüËÉΩÔºà‰æãÂ¶ÇÈ¢®Ê†ºËΩâÊèõÊîªÊìäÔºâÈÉΩÂèØËÉΩË¢´ÊîπËÆäÔºå‰ΩøÂæóËàáÁúüÂØ¶Êñ∞ËÅûÁöÑÂçÄÂà•Êõ¥ÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫Â∞çÊäóÂºèÈ¢®Ê†ºÊì¥ÂÖÖÔºåAdStyleÔºå‰æÜË®ìÁ∑¥‰∏ÄÂÄãÂ∞çÂêÑÁ®ÆÈ¢®Ê†ºËΩâÊèõÊîªÊìä‰øùÊåÅÁ©©ÂÅ•ÁöÑÂÅáÊñ∞ËÅûÂÅµÊ∏¨Âô®„ÄÇÊàëÂÄëÊ®°ÂûãÁöÑÈóúÈçµÊ©üÂà∂ÊòØÂ∞èÂøÉÂú∞‰ΩøÁî® LLM Ëá™ÂãïÁî¢ÁîüÂ§öÊ®£‰∏îÈÄ£Ë≤´ÁöÑÈ¢®Ê†ºËΩâÊèõÊîªÊìäÊèêÁ§∫ÁØÑÂúç„ÄÇÈÄôÊîπÂñÑ‰∫ÜÊèêÁ§∫ÁöÑÁî¢ÁîüÔºåÁâπÂà•ÊòØÂ∞çÊñºÂÅµÊ∏¨Âô®Èõ£‰ª•ËôïÁêÜÁöÑÊèêÁ§∫„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåÁï∂Âú®ÂÅáÊñ∞ËÅûÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÊôÇÔºåÊàëÂÄëÁöÑÊì¥ÂÖÖÁ≠ñÁï•ÊîπÂñÑ‰∫ÜÁ©©ÂÅ•ÊÄßÂíåÂÅµÊ∏¨ÊïàËÉΩ„ÄÇ

##### **Scorecards for Synthetic Medical Data Evaluation and Reporting**
2406.11143v1 by Ghada Zamzmi, Adarsh Subbaswamy, Elena Sizikova, Edward Margerrison, Jana Delfino, Aldo Badano

The growing utilization of synthetic medical data (SMD) in training and
testing AI-driven tools in healthcare necessitates a systematic framework for
assessing SMD quality. The current lack of a standardized methodology to
evaluate SMD, particularly in terms of its applicability in various medical
scenarios, is a significant hindrance to its broader acceptance and utilization
in healthcare applications. Here, we outline an evaluation framework designed
to meet the unique requirements of medical applications, and introduce the
concept of SMD scorecards, which can serve as comprehensive reports that
accompany artificially generated datasets. This can help standardize evaluation
and enable SMD developers to assess and further enhance the quality of SMDs by
identifying areas in need of attention and ensuring that the synthetic data
more accurately approximate patient data.

ÊëòË¶ÅÔºöÈö®ËëóÂêàÊàêÈÜ´ÁôÇË≥áÊñô (SMD) Âú®Ë®ìÁ∑¥ÂíåÊ∏¨Ë©¶ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÂ∑•ÂÖ∑ÁöÑÂà©Áî®ÁéáÊó•ÁõäÊèêÈ´òÔºåÈúÄË¶Å‰∏ÄÂÄãÁ≥ªÁµ±ÊÄßÁöÑÊû∂Êßã‰æÜË©ï‰º∞ SMD ÁöÑÂìÅË≥™„ÄÇÁõÆÂâçÁº∫‰πèÊ®ôÊ∫ñÂåñÁöÑË©ï‰º∞ SMD ÁöÑÊñπÊ≥ïÔºåÁâπÂà•ÊòØÂú®ÂÖ∂ÊñºÂêÑÁ®ÆÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÁöÑÈÅ©Áî®ÊÄßÊñπÈù¢ÔºåÈÄôÂö¥ÈáçÈòªÁ§ô‰∫ÜÂÖ∂Âú®ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠ÁöÑÊõ¥Âª£Ê≥õÊé•ÂèóÂíåÂà©Áî®„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊ¶ÇËø∞‰∫Ü‰∏ÄÂÄãË©ï‰º∞Êû∂ÊßãÔºåÊó®Âú®ÊªøË∂≥ÈÜ´ÁôÇÊáâÁî®ÁöÑÁç®ÁâπÈúÄÊ±ÇÔºå‰∏¶ÂºïÂÖ•‰∫Ü SMD Ë®òÂàÜÂç°ÁöÑÊ¶ÇÂøµÔºåÂÆÉÂèØ‰ª•‰ΩúÁÇ∫‰∫∫Â∑•ÁîüÊàêË≥áÊñôÈõÜÁöÑÁ∂úÂêàÂ†±Âëä„ÄÇÈÄôÊúâÂä©ÊñºÊ®ôÊ∫ñÂåñË©ï‰º∞Ôºå‰∏¶‰Ωø SMD ÈñãÁôº‰∫∫Âì°ËÉΩÂ§†Ë©ï‰º∞ÂíåÈÄ≤‰∏ÄÊ≠•ÊèêÈ´ò SMD ÁöÑÂìÅË≥™ÔºåÊñπÊ≥ïÊòØÊâæÂá∫ÈúÄË¶ÅÈóúÊ≥®ÁöÑÈ†òÂüüÔºå‰∏¶Á¢∫‰øùÂêàÊàêË≥áÊñôÊõ¥Ê∫ñÁ¢∫Âú∞Ëøë‰ººÊñºÊÇ£ËÄÖË≥áÊñô„ÄÇ

##### **Diffusion Models in Low-Level Vision: A Survey**
2406.11138v1 by Chunming He, Yuqi Shen, Chengyu Fang, Fengyang Xiao, Longxiang Tang, Yulun Zhang, Wangmeng Zuo, Zhenhua Guo, Xiu Li

Deep generative models have garnered significant attention in low-level
vision tasks due to their generative capabilities. Among them, diffusion
model-based solutions, characterized by a forward diffusion process and a
reverse denoising process, have emerged as widely acclaimed for their ability
to produce samples of superior quality and diversity. This ensures the
generation of visually compelling results with intricate texture information.
Despite their remarkable success, a noticeable gap exists in a comprehensive
survey that amalgamates these pioneering diffusion model-based works and
organizes the corresponding threads. This paper proposes the comprehensive
review of diffusion model-based techniques. We present three generic diffusion
modeling frameworks and explore their correlations with other deep generative
models, establishing the theoretical foundation. Following this, we introduce a
multi-perspective categorization of diffusion models, considering both the
underlying framework and the target task. Additionally, we summarize extended
diffusion models applied in other tasks, including medical, remote sensing, and
video scenarios. Moreover, we provide an overview of commonly used benchmarks
and evaluation metrics. We conduct a thorough evaluation, encompassing both
performance and efficiency, of diffusion model-based techniques in three
prominent tasks. Finally, we elucidate the limitations of current diffusion
models and propose seven intriguing directions for future research. This
comprehensive examination aims to facilitate a profound understanding of the
landscape surrounding denoising diffusion models in the context of low-level
vision tasks. A curated list of diffusion model-based techniques in over 20
low-level vision tasks can be found at
https://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision.

ÊëòË¶ÅÔºöÊ∑±Â∫¶ÁîüÊàêÊ®°ÂûãÂú®‰ΩéÂ±ÇÊ¨°ËßÜËßâ‰ªªÂä°‰∏≠Ëé∑Âæó‰∫ÜÊòæËëóÁöÑÂÖ≥Ê≥®ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÂÖ∑ÊúâÁîüÊàêËÉΩÂäõ„ÄÇÂÖ∂‰∏≠Ôºå‰ª•Ê≠£ÂêëÊâ©Êï£ËøáÁ®ãÂíåÂèçÂêëÂéªÂô™ËøáÁ®ã‰∏∫ÁâπÂæÅÁöÑÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÂõ†ÂÖ∂ÁîüÊàêÊõ¥È´òË¥®ÈáèÂíåÂ§öÊ†∑ÊÄßÊ†∑Êú¨ÁöÑËÉΩÂäõËÄåÂ§áÂèóËµûË™â„ÄÇËøôÁ°Æ‰øù‰∫ÜÁîüÊàêËßÜËßâ‰∏äÂºï‰∫∫Ê≥®ÁõÆÁöÑÁªìÊûúÔºåÂπ∂ÂÖ∑ÊúâÂ§çÊùÇÁ∫πÁêÜ‰ø°ÊÅØ„ÄÇÂ∞ΩÁÆ°ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊàêÂäüÔºå‰ΩÜÂú®Â∞ÜËøô‰∫õÂºÄÂàõÊÄßÁöÑÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÂ∑•‰ΩúÊ±áÈõÜËµ∑Êù•Âπ∂ÁªÑÁªáÁõ∏Â∫îÁöÑÁ∫øÁ®ãÁöÑÁªºÂêàË∞ÉÊü•‰∏≠Ôºå‰ªçÁÑ∂Â≠òÂú®ÊòéÊòæÁöÑÂ∑ÆË∑ù„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÊäÄÊúØÁöÑÂÖ®Èù¢ÁªºËø∞„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏â‰∏™ÈÄöÁî®ÁöÑÊâ©Êï£Âª∫Ê®°Ê°ÜÊû∂ÔºåÂπ∂Êé¢ËÆ®‰∫ÜÂÆÉ‰ª¨‰∏éÂÖ∂‰ªñÊ∑±Â∫¶ÁîüÊàêÊ®°ÂûãÁöÑÁõ∏ÂÖ≥ÊÄßÔºåÂª∫Á´ã‰∫ÜÁêÜËÆ∫Âü∫Á°Ä„ÄÇÂú®Ê≠§Âü∫Á°Ä‰∏äÔºåÊàë‰ª¨‰ªãÁªç‰∫ÜÊâ©Êï£Ê®°ÂûãÁöÑÂ§öËßÜËßíÂàÜÁ±ªÔºåÂêåÊó∂ËÄÉËôë‰∫ÜÂ∫ïÂ±ÇÊ°ÜÊû∂ÂíåÁõÆÊ†á‰ªªÂä°„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊÄªÁªì‰∫ÜÂ∫îÁî®‰∫éÂÖ∂‰ªñ‰ªªÂä°ÁöÑÊâ©Â±ïÊâ©Êï£Ê®°ÂûãÔºåÂåÖÊã¨ÂåªÂ≠¶„ÄÅÈÅ•ÊÑüÂíåËßÜÈ¢ëÂú∫ÊôØ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Ê¶ÇËø∞‰∫ÜÂ∏∏Áî®ÁöÑÂü∫ÂáÜÂíåËØÑ‰º∞ÊåáÊ†á„ÄÇÊàë‰ª¨ÂØπÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÊäÄÊúØÂú®‰∏â‰∏™Á™ÅÂá∫ÁöÑ‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩÂíåÊïàÁéáËøõË°å‰∫ÜÂΩªÂ∫ïÁöÑËØÑ‰º∞„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÈòêÊòé‰∫ÜÂΩìÂâçÊâ©Êï£Ê®°ÂûãÁöÑÂ±ÄÈôêÊÄßÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏É‰∏™Êú™Êù•Á†îÁ©∂ÁöÑÊúâË∂£ÊñπÂêë„ÄÇËøôÊ¨°ÂÖ®Èù¢Ê£ÄÊü•Êó®Âú®‰øÉËøõÂØπ‰ΩéÂ±ÇÊ¨°ËßÜËßâ‰ªªÂä°ËÉåÊôØ‰∏ãÂéªÂô™Êâ©Êï£Ê®°ÂûãÂë®Âõ¥ÁéØÂ¢ÉÁöÑÊ∑±ÂÖ•ÁêÜËß£„ÄÇÂèØ‰ª•Âú® https://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision ÊâæÂà∞Ë∂ÖËøá 20 ‰∏™‰ΩéÂ±ÇÊ¨°ËßÜËßâ‰ªªÂä°‰∏≠Âü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÊäÄÊúØÁöÑÁ≤æÈÄâÂàóË°®„ÄÇ

##### **Towards Understanding Emotions for Engaged Mental Health Conversations**
2406.11135v1 by Kellie Yu Hui Sim, Kohleen Tijing Fortuno, Kenny Tsu Wei Choo

Providing timely support and intervention is crucial in mental health
settings. As the need to engage youth comfortable with texting increases,
mental health providers are exploring and adopting text-based media such as
chatbots, community-based forums, online therapies with licensed professionals,
and helplines operated by trained responders. To support these text-based media
for mental health--particularly for crisis care--we are developing a system to
perform passive emotion-sensing using a combination of keystroke dynamics and
sentiment analysis. Our early studies of this system posit that the analysis of
short text messages and keyboard typing patterns can provide emotion
information that may be used to support both clients and responders. We use our
preliminary findings to discuss the way forward for applying AI to support
mental health providers in providing better care.

ÊëòË¶ÅÔºöÂú®ÂøÉÁêÜÂÅ•Â∫∑Áí∞Â¢É‰∏≠Êèê‰æõÂèäÊôÇÁöÑÊîØÊè¥Âíå‰ªãÂÖ•Ëá≥ÈóúÈáçË¶Å„ÄÇÈö®ËëóËàáÈùíÂ∞ëÂπ¥‰∫íÂãïÊôÇÔºå‰ΩøÁî®ÊñáÂ≠óË®äÊÅØÁöÑÈúÄÊ±ÇÂ¢ûÂä†ÔºåÂøÉÁêÜÂÅ•Â∫∑ÊúçÂãôÊèê‰æõËÄÖÊ≠£Âú®Êé¢Á¥¢ÂíåÊé°Áî®Âü∫ÊñºÊñáÂ≠óË®äÊÅØÁöÑÂ™íÈ´îÔºå‰æãÂ¶ÇËÅäÂ§©Ê©üÂô®‰∫∫„ÄÅÁ§æÁæ§Ë´ñÂ£á„ÄÅÁî±ÊåÅÁÖßÂ∞àÊ•≠‰∫∫Âì°Êèê‰æõÁöÑÁ∑ö‰∏äÁôÇÊ≥ïÔºå‰ª•ÂèäÁî±ÂèóÈÅéË®ìÁ∑¥ÁöÑÂõûÊáâËÄÖÁáüÈÅãÁöÑÊ±ÇÂä©Â∞àÁ∑ö„ÄÇÁÇ∫‰∫ÜÊîØÊè¥ÈÄô‰∫õÁî®ÊñºÂøÉÁêÜÂÅ•Â∫∑ÁöÑÂü∫ÊñºÊñáÂ≠óË®äÊÅØÁöÑÂ™íÈ´î‚Äî‚ÄîÁâπÂà•ÊòØÂç±Ê©üÁÖßË≠∑‚Äî‚ÄîÊàëÂÄëÊ≠£Âú®ÈñãÁôº‰∏ÄÂÄãÁ≥ªÁµ±Ôºå‰ΩøÁî®ÊåâÈçµÂãïÂäõÂ≠∏ÂíåÊÉÖÁ∑íÂàÜÊûêÁöÑÁµÑÂêà‰æÜÂü∑Ë°åË¢´ÂãïÊÉÖÁ∑íÊÑüÊ∏¨„ÄÇÊàëÂÄëÂ∞çÈÄôÂÄãÁ≥ªÁµ±ÁöÑÊó©ÊúüÁ†îÁ©∂ÂÅáË®≠ÔºåÂ∞çÁ∞°Áü≠ÊñáÂ≠óË®äÊÅØÂíåÈçµÁõ§Ëº∏ÂÖ•Ê®°ÂºèÁöÑÂàÜÊûêÂèØ‰ª•Êèê‰æõÊÉÖÁ∑íË≥áË®äÔºåÂèØÁî®ÊñºÊîØÊè¥ÂÄãÊ°àÂíåÂõûÊáâËÄÖ„ÄÇÊàëÂÄë‰ΩøÁî®ÊàëÂÄëÁöÑÂàùÊ≠•ÁôºÁèæ‰æÜË®éË´ñÂ∞á AI ÊáâÁî®ÊñºÊîØÊè¥ÂøÉÁêÜÂÅ•Â∫∑ÊúçÂãôÊèê‰æõËÄÖÊèê‰æõÊõ¥Â•ΩÁÖßË≠∑ÁöÑÊú™‰æÜÊñπÂêë„ÄÇ

##### **Boosting Medical Image Classification with Segmentation Foundation Model**
2406.11026v1 by Pengfei Gu, Zihan Zhao, Hongxiao Wang, Yaopeng Peng, Yizhe Zhang, Nishchal Sapkota, Chaoli Wang, Danny Z. Chen

The Segment Anything Model (SAM) exhibits impressive capabilities in
zero-shot segmentation for natural images. Recently, SAM has gained a great
deal of attention for its applications in medical image segmentation. However,
to our best knowledge, no studies have shown how to harness the power of SAM
for medical image classification. To fill this gap and make SAM a true
``foundation model'' for medical image analysis, it is highly desirable to
customize SAM specifically for medical image classification. In this paper, we
introduce SAMAug-C, an innovative augmentation method based on SAM for
augmenting classification datasets by generating variants of the original
images. The augmented datasets can be used to train a deep learning
classification model, thereby boosting the classification performance.
Furthermore, we propose a novel framework that simultaneously processes raw and
SAMAug-C augmented image input, capitalizing on the complementary information
that is offered by both. Experiments on three public datasets validate the
effectiveness of our new approach.

ÊëòË¶ÅÔºö‰ªª‰ΩïÂçÄÊÆµÊ®°Âûã (SAM) Âú®Ëá™ÁÑ∂ÂΩ±ÂÉèÁöÑÈõ∂ÁôºÂ∞ÑÂçÄÊÆµ‰∏≠Â±ïÁèæ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõ„ÄÇÊúÄËøëÔºåSAM Âõ†ÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂçÄÊÆµ‰∏≠ÁöÑÊáâÁî®ËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÊìöÊàëÂÄëÊâÄÁü•ÔºåÊ≤íÊúâÁ†îÁ©∂È°ØÁ§∫Â¶Ç‰ΩïÂà©Áî® SAM ÁöÑÂäõÈáèÈÄ≤Ë°åÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩÔºå‰∏¶ËÆì SAM ÊàêÁÇ∫ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÁöÑÁúüÊ≠£„ÄåÂü∫Á§éÊ®°Âûã„ÄçÔºåÈùûÂ∏∏Â∏åÊúõÈáùÂ∞çÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°ûÂÆ¢Ë£ΩÂåñ SAM„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π SAMAug-CÔºå‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊì¥ÂÖÖÊñπÊ≥ïÔºåÂü∫Êñº SAMÔºåÈÄèÈÅéÁî¢ÁîüÂéüÂßãÂΩ±ÂÉèÁöÑËÆäÈ´î‰æÜÊì¥ÂÖÖÂàÜÈ°ûË≥áÊñôÈõÜ„ÄÇÊì¥ÂÖÖÁöÑË≥áÊñôÈõÜÂèØÁî®ÊñºË®ìÁ∑¥Ê∑±Â∫¶Â≠∏ÁøíÂàÜÈ°ûÊ®°ÂûãÔºåÂæûËÄåÊèêÂçáÂàÜÈ°ûÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÂêåÊôÇËôïÁêÜÂéüÂßãÂíå SAMAug-C Êì¥ÂÖÖÂΩ±ÂÉèËº∏ÂÖ•ÔºåÂà©Áî®ÂÖ©ËÄÖÊèê‰æõÁöÑ‰∫íË£úË≥áË®ä„ÄÇÂú®‰∏âÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÊñ∞ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **ALPS: An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model**
2406.10855v1 by Song Zhang, Qingzhong Wang, Junyi Liu, Haoyi Xiong

In the fast-growing field of Remote Sensing (RS) image analysis, the gap
between massive unlabeled datasets and the ability to fully utilize these
datasets for advanced RS analytics presents a significant challenge. To fill
the gap, our work introduces an innovative auto-labeling framework named ALPS
(Automatic Labeling for Pre-training in Segmentation), leveraging the Segment
Anything Model (SAM) to predict precise pseudo-labels for RS images without
necessitating prior annotations or additional prompts. The proposed pipeline
significantly reduces the labor and resource demands traditionally associated
with annotating RS datasets. By constructing two comprehensive pseudo-labeled
RS datasets via ALPS for pre-training purposes, our approach enhances the
performance of downstream tasks across various benchmarks, including iSAID and
ISPRS Potsdam. Experiments demonstrate the effectiveness of our framework,
showcasing its ability to generalize well across multiple tasks even under the
scarcity of extensively annotated datasets, offering a scalable solution to
automatic segmentation and annotation challenges in the field. In addition, the
proposed a pipeline is flexible and can be applied to medical image
segmentation, remarkably boosting the performance. Note that ALPS utilizes
pre-trained SAM to semi-automatically annotate RS images without additional
manual annotations. Though every component in the pipeline has bee well
explored, integrating clustering algorithms with SAM and novel pseudo-label
alignment significantly enhances RS segmentation, as an off-the-shelf tool for
pre-training data preparation. Our source code is available at:
https://github.com/StriveZs/ALPS.

ÊëòË¶ÅÔºö<paragraph>Âú®Âø´ÈÄüÁôºÂ±ïÁöÑÈÅôÊÑü (RS) ÂΩ±ÂÉèÂàÜÊûêÈ†òÂüü‰∏≠ÔºåÊµ∑ÈáèÊú™Ê®ôÁ±§Ë≥áÊñôÈõÜËàáÂÖÖÂàÜÂà©Áî®ÈÄô‰∫õË≥áÊñôÈõÜÈÄ≤Ë°åÈÄ≤Èöé RS ÂàÜÊûêÁöÑËÉΩÂäõ‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫ÜÂêçÁÇ∫ ALPS (ÂàÜÊÆµÈ†êË®ìÁ∑¥Ëá™ÂãïÊ®ôÁ±§) ÁöÑÂâµÊñ∞Ëá™ÂãïÊ®ôÁ±§Ê°ÜÊû∂ÔºåÂà©Áî®‰ªª‰ΩïÂàÜÊÆµÊ®°Âûã (SAM) ‰æÜÈ†êÊ∏¨ RS ÂΩ±ÂÉèÁöÑÁ≤æÁ¢∫ÂÅΩÊ®ôÁ±§ÔºåËÄå‰∏çÈúÄË¶Å‰∫ãÂÖàË®ªËß£ÊàñÈ°çÂ§ñÁöÑÊèêÁ§∫„ÄÇÊâÄÊèêÂá∫ÁöÑÁÆ°Á∑öÂ§ßÂπÖÊ∏õÂ∞ë‰∫ÜÂÇ≥Áµ±‰∏äËàáË®ªËß£ RS Ë≥áÊñôÈõÜÁõ∏ÈóúÁöÑ‰∫∫ÂäõÂíåË≥áÊ∫êÈúÄÊ±Ç„ÄÇÈÄèÈÅé ALPS ÁÇ∫È†êË®ìÁ∑¥ÁõÆÁöÑÂª∫ÊßãÂÖ©ÂÄãÂÖ®Èù¢ÁöÑÂÅΩÊ®ôÁ±§ RS Ë≥áÊñôÈõÜÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ¢ûÂº∑‰∫ÜÂêÑÁ®ÆÂü∫Ê∫ñÔºàÂåÖÊã¨ iSAID Âíå ISPRS PotsdamÔºâ‰∏≠‰∏ãÊ∏∏‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊ°ÜÊû∂ÁöÑÊúâÊïàÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âç≥‰ΩøÂú®Âª£Ê≥õË®ªËß£Ë≥áÊñôÈõÜÁ®ÄÁº∫ÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰πüËÉΩË∑®Â§öÂÄã‰ªªÂãôÈÄ≤Ë°åËâØÂ•ΩÊ¶ÇÂåñÁöÑËÉΩÂäõÔºåÁÇ∫Ë©≤È†òÂüüÁöÑËá™ÂãïÂàÜÊÆµÂíåË®ªËß£ÊåëÊà∞Êèê‰æõ‰∫ÜÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊ≠§Â§ñÔºåÊâÄÊèêÂá∫ÁöÑÁÆ°Á∑öÂÖ∑ÊúâÂΩàÊÄßÔºå‰∏îÂèØÊáâÁî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊÆµÔºåÈ°ØËëóÊèêÂçáÊïàËÉΩ„ÄÇË´ãÊ≥®ÊÑèÔºåALPS Âà©Áî®È†êË®ìÁ∑¥ÁöÑ SAM ‰æÜÂçäËá™ÂãïË®ªËß£ RS ÂΩ±ÂÉèÔºåËÄå‰∏çÈúÄË¶ÅÈ°çÂ§ñÁöÑÊ®ôÁ±§„ÄÇÂÑòÁÆ°ÁÆ°Á∑ö‰∏≠ÁöÑÊØèÂÄãÂÖÉ‰ª∂ÈÉΩÂ∑≤ÂÖÖÂàÜÊé¢Ë®éÔºå‰ΩÜÂ∞áÂàÜÁæ§ÊºîÁÆóÊ≥ïËàá SAM Êï¥ÂêàÔºå‰ª•ÂèäÊñ∞Á©éÁöÑÂÅΩÊ®ôÁ±§ÊØîÂ∞çÔºåÈ°ØËëóÂ¢ûÂº∑‰∫Ü RS ÂàÜÊÆµÔºå‰ΩúÁÇ∫È†êË®ìÁ∑¥Ë≥áÊñôÊ∫ñÂÇôÁöÑÁèæÊàêÂ∑•ÂÖ∑„ÄÇÊàëÂÄëÁöÑÂéüÂßãÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://github.com/StriveZs/ALPS„ÄÇ</paragraph>

##### **A Comprehensive Survey of Foundation Models in Medicine**
2406.10729v1 by Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, Ruogu Fang

Foundation models (FMs) are large-scale deep-learning models trained on
extensive datasets using self-supervised techniques. These models serve as a
base for various downstream tasks, including healthcare. FMs have been adopted
with great success across various domains within healthcare, including natural
language processing (NLP), computer vision, graph learning, biology, and omics.
Existing healthcare-based surveys have not yet included all of these domains.
Therefore, this survey provides a comprehensive overview of FMs in healthcare.
We focus on the history, learning strategies, flagship models, applications,
and challenges of FMs. We explore how FMs such as the BERT and GPT families are
reshaping various healthcare domains, including clinical large language models,
medical image analysis, and omics data. Furthermore, we provide a detailed
taxonomy of healthcare applications facilitated by FMs, such as clinical NLP,
medical computer vision, graph learning, and other biology-related tasks.
Despite the promising opportunities FMs provide, they also have several
associated challenges, which are explained in detail. We also outline potential
future directions to provide researchers and practitioners with insights into
the potential and limitations of FMs in healthcare to advance their deployment
and mitigate associated risks.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°Âûã (FM) ÊòØ‰ΩøÁî®Ëá™ÊàëÁõ£Áù£ÊäÄË°ìÂú®Âª£Ê≥õÊï∏ÊìöÈõÜ‰∏äË®ìÁ∑¥ÁöÑÂ§ßË¶èÊ®°Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄô‰∫õÊ®°Âûã‰ΩúÁÇ∫ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãôÁöÑÂü∫Á§éÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇFM Â∑≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÂêÑÁ®ÆÈ†òÂüü‰∏≠Ë¢´Âª£Ê≥õÊé°Áî®ÔºåÂåÖÊã¨Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP)„ÄÅÈõªËÖ¶Ë¶ñË¶∫„ÄÅÂúñÂΩ¢Â≠∏Áøí„ÄÅÁîüÁâ©Â≠∏ÂíåÁµÑÂ≠∏„ÄÇÁèæÊúâÁöÑÂü∫ÊñºÈÜ´ÁôÇ‰øùÂÅ•ÁöÑË™øÊü•Â∞öÊú™Ê∂µËìãÊâÄÊúâÈÄô‰∫õÈ†òÂüü„ÄÇÂõ†Ê≠§ÔºåÊú¨Ë™øÊü•Êèê‰æõ‰∫Ü FM Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÖ®Èù¢Ê¶ÇËø∞„ÄÇÊàëÂÄëÂ∞àÊ≥®Êñº FM ÁöÑÊ≠∑Âè≤„ÄÅÂ≠∏ÁøíÁ≠ñÁï•„ÄÅÊóóËâ¶Ê®°Âûã„ÄÅÊáâÁî®ÂíåÊåëÊà∞„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü BERT Âíå GPT ÂÆ∂ÊóèÁ≠â FM Â¶Ç‰ΩïÈáçÂ°ëÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÂåÖÊã¨Ëá®Â∫äÂ§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÅÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÂíåÁµÑÂ≠∏Êï∏Êìö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÁî± FM ‰øÉÈÄ≤ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®Ë©≥Á¥∞ÂàÜÈ°ûÊ≥ïÔºå‰æãÂ¶ÇËá®Â∫ä NLP„ÄÅÈÜ´Â≠∏ÈõªËÖ¶Ë¶ñË¶∫„ÄÅÂúñÂΩ¢Â≠∏ÁøíÂíåÂÖ∂‰ªñËàáÁîüÁâ©Áõ∏ÈóúÁöÑ‰ªªÂãô„ÄÇÂÑòÁÆ° FM Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÊ©üÊúÉÔºå‰ΩÜÂÆÉÂÄë‰πüÈù¢Ëá®Ëëó‰∏Ä‰∫õÁõ∏ÈóúÁöÑÊåëÊà∞ÔºåÈÄô‰∫õÊåëÊà∞Âú®Êñá‰∏≠ÈÉΩÊúâË©≥Á¥∞Ë™™Êòé„ÄÇÊàëÂÄëÈÇÑÊ¶ÇËø∞‰∫ÜÊΩõÂú®ÁöÑÊú™‰æÜÊñπÂêëÔºåÁÇ∫Á†îÁ©∂‰∫∫Âì°ÂíåÂæûÊ•≠ËÄÖÊèê‰æõÊúâÈóú FM Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊΩõÂäõÂíåÂ±ÄÈôêÊÄßÁöÑË¶ãËß£Ôºå‰ª•Êé®ÈÄ≤ÂÖ∂ÈÉ®ÁΩ≤‰∏¶Ê∏õËºïÁõ∏ÈóúÈ¢®Èö™„ÄÇ

##### **SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**
2406.10710v1 by Ziije Zhong, Linqing Zhong, Zhaoze Sun, Qingyun Jin, Zengchang Qin, Xiaofan Zhang

Integrating Large Language Models (LLMs) with existing Knowledge Graph (KG)
databases presents a promising avenue for enhancing LLMs' efficacy and
mitigating their "hallucinations". Given that most KGs reside in graph
databases accessible solely through specialized query languages (e.g., Cypher),
there exists a critical need to bridge the divide between LLMs and KG databases
by automating the translation of natural language into Cypher queries (commonly
termed the "Text2Cypher" task). Prior efforts tried to bolster LLMs'
proficiency in Cypher generation through Supervised Fine-Tuning. However, these
explorations are hindered by the lack of annotated datasets of Query-Cypher
pairs, resulting from the labor-intensive and domain-specific nature of
annotating such datasets. In this study, we propose SyntheT2C, a methodology
for constructing a synthetic Query-Cypher pair dataset, comprising two distinct
pipelines: (1) LLM-based prompting and (2) template-filling. SyntheT2C
facilitates the generation of extensive Query-Cypher pairs with values sampled
from an underlying Neo4j graph database. Subsequently, SyntheT2C is applied to
two medical databases, culminating in the creation of a synthetic dataset,
MedT2C. Comprehensive experiments demonstrate that the MedT2C dataset
effectively enhances the performance of backbone LLMs on the Text2Cypher task.
Both the SyntheT2C codebase and the MedT2C dataset will be released soon.

ÊëòË¶ÅÔºö<paragraph>Â∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÁèæÊúâÁöÑÁü•Ë≠òÂúñË≠ú (KG) Ë≥áÊñôÂ∫´Êï¥ÂêàÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊèêÂçá LLM ÊïàËÉΩ‰∏¶Ê∏õËºïÂÖ∂„ÄåÂπªË¶∫„ÄçÁöÑÈÄîÂæë„ÄÇÁî±ÊñºÂ§ßÂ§öÊï∏ KG ÈÉΩÂ≠òÂú®ÊñºÂÉÖËÉΩÈÄèÈÅéÂ∞àÁî®Êü•Ë©¢Ë™ûË®ÄÔºà‰æãÂ¶Ç CypherÔºâÂ≠òÂèñÁöÑÂúñÂΩ¢Ë≥áÊñôÂ∫´‰∏≠ÔºåÂõ†Ê≠§Ëø´ÂàáÈúÄË¶ÅËá™ÂãïÂåñÂ∞áËá™ÁÑ∂Ë™ûË®ÄËΩâÊèõÁÇ∫ Cypher Êü•Ë©¢Ôºå‰ª•ÂΩåÂêà LLM Ëàá KG Ë≥áÊñôÂ∫´‰πãÈñìÁöÑÈ¥ªÊ∫ùÔºàÈÄöÂ∏∏Á®±ÁÇ∫„ÄåText2Cypher„Äç‰ªªÂãôÔºâ„ÄÇÂÖàÂâçÁöÑÂä™ÂäõÂòóË©¶ÈÄèÈÅéÁõ£Áù£ÂæÆË™ø‰æÜÊèêÂçá LLM Âú® Cypher ÁîüÊàêÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊé¢Á¥¢ÂèóÂà∞Áº∫‰πèÊü•Ë©¢-Cypher ÈÖçÂ∞çÁöÑË®ªËß£Ë≥áÊñôÈõÜÁöÑÈòªÁ§ôÔºåÈÄôÊòØÂõ†ÁÇ∫Ê≠§È°ûË≥áÊñôÈõÜÁöÑË®ªËß£ÈúÄË¶ÅÂ§ßÈáè‰∫∫Âäõ‰∏îÂÖ∑ÊúâÁâπÂÆöÈ†òÂüüÁöÑÊÄßË≥™„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü SyntheT2CÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁî®ÊñºÂª∫ÊßãÂêàÊàêÊü•Ë©¢-Cypher ÈÖçÂ∞çË≥áÊñôÈõÜÁöÑÊñπÊ≥ïÔºåÂåÖÂê´ÂÖ©ÂÄã‰∏çÂêåÁöÑÁÆ°ÈÅìÔºö(1) Âü∫Êñº LLM ÁöÑÊèêÁ§∫Âíå (2) ÁØÑÊú¨Â°´ÂØ´„ÄÇSyntheT2C ‰øÉÈÄ≤‰∫ÜÂ§ßÈáèÊü•Ë©¢-Cypher ÈÖçÂ∞çÁöÑÁî¢ÁîüÔºåÂÖ∂ÂÄºÂèñÊ®£Ëá™Âü∫Á§éÁöÑ Neo4j ÂúñÂΩ¢Ë≥áÊñôÂ∫´„ÄÇÈö®ÂæåÔºåÂ∞á SyntheT2C ÊáâÁî®ÊñºÂÖ©ÂÄãÈÜ´ÁôÇË≥áÊñôÂ∫´ÔºåÊúÄÁµÇÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂêàÊàêË≥áÊñôÈõÜ MedT2C„ÄÇÂÖ®Èù¢ÁöÑÂØ¶È©óË≠âÊòéÔºåMedT2C Ë≥áÊñôÈõÜÊúâÊïàÊèêÂçá‰∫Ü‰∏ªÂππ LLM Âú® Text2Cypher ‰ªªÂãô‰∏äÁöÑÊïàËÉΩ„ÄÇSyntheT2C Á®ãÂºèÁ¢ºÂ∫´Âíå MedT2C Ë≥áÊñôÈõÜÈÉΩÂ∞áÂæàÂø´ÈáãÂá∫„ÄÇ</paragraph>

##### **Applications of Generative AI in Healthcare: algorithmic, ethical, legal and societal considerations**
2406.10632v1 by Onyekachukwu R. Okonji, Kamol Yunusov, Bonnie Gordon

Generative AI is rapidly transforming medical imaging and text analysis,
offering immense potential for enhanced diagnosis and personalized care.
However, this transformative technology raises crucial ethical, societal, and
legal questions. This paper delves into these complexities, examining issues of
accuracy, informed consent, data privacy, and algorithmic limitations in the
context of generative AI's application to medical imaging and text. We explore
the legal landscape surrounding liability and accountability, emphasizing the
need for robust regulatory frameworks. Furthermore, we dissect the algorithmic
challenges, including data biases, model limitations, and workflow integration.
By critically analyzing these challenges and proposing responsible solutions,
we aim to foster a roadmap for ethical and responsible implementation of
generative AI in healthcare, ensuring its transformative potential serves
humanity with utmost care and precision.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI Ê≠£Âú®Âø´ÈÄüËΩâËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊñáÂ≠óÂàÜÊûêÔºå
Êèê‰æõÂ¢ûÂº∑Ë®∫Êñ∑ÂíåÂÄã‰∫∫ÂåñÁÖßË≠∑ÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇ
ÁÑ∂ËÄåÔºåÈÄôÈ†ÖËÆäÈù©ÊÄßÊäÄË°ìÊèêÂá∫‰∫ÜÈóúÈçµÁöÑÂÄ´ÁêÜ„ÄÅÁ§æÊúÉÂíå
Ê≥ïÂæãÂïèÈ°å„ÄÇÊú¨ÊñáÊ∑±ÂÖ•Êé¢Ë®éÈÄô‰∫õË§áÈõúÊÄßÔºåÂØ©Êü•Ê∫ñÁ¢∫ÊÄß„ÄÅÁü•ÊÉÖÂêåÊÑè„ÄÅË≥áÊñôÈö±ÁßÅÂíåÊºîÁÆóÊ≥ïÈôêÂà∂Á≠âÂïèÈ°å
Âú®ÁîüÊàêÂºè AI ÊáâÁî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊñáÂ≠óÁöÑËÉåÊôØ‰∏ã„ÄÇÊàëÂÄëÊé¢Ë®é
Ë≤¨‰ªªÂíåÂïèË≤¨ÁöÑÊ≥ïÂæãÁí∞Â¢ÉÔºåÂº∑Ë™øÂÅ•ÂÖ®Áõ£ÁÆ°Êû∂ÊßãÁöÑÂøÖË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂâñÊûêÊºîÁÆóÊ≥ï
ÊåëÊà∞ÔºåÂåÖÊã¨Ë≥áÊñôÂÅèÂ∑Æ„ÄÅÊ®°ÂûãÈôêÂà∂ÂíåÂ∑•‰ΩúÊµÅÁ®ãÊï¥Âêà„ÄÇ
ÈÄöÈÅéÊâπÂà§ÊÄßÂàÜÊûêÈÄô‰∫õÊåëÊà∞‰∏¶ÊèêÂá∫Ë≤†Ë≤¨‰ªªÁöÑËß£Ê±∫ÊñπÊ°àÔºå
ÊàëÂÄëÊó®Âú®ÂüπÈ§äÁîüÊàêÂºè AI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÈÅìÂæ∑ÂíåË≤†Ë≤¨‰ªªÂØ¶ÊñΩÁöÑË∑ØÁ∑öÂúñÔºåÁ¢∫‰øùÂÖ∂ËÆäÈù©ÊΩõÂäõÊúçÂãô
‰∫∫È°û‰ª•ÊúÄÂ§ßÁöÑÈóúÊá∑ÂíåÁ≤æÁ¢∫Â∫¶„ÄÇ

##### **Public Computer Vision Datasets for Precision Livestock Farming: A Systematic Survey**
2406.10628v1 by Anil Bhujel, Yibin Wang, Yuzhen Lu, Daniel Morris, Mukesh Dangol

Technology-driven precision livestock farming (PLF) empowers practitioners to
monitor and analyze animal growth and health conditions for improved
productivity and welfare. Computer vision (CV) is indispensable in PLF by using
cameras and computer algorithms to supplement or supersede manual efforts for
livestock data acquisition. Data availability is crucial for developing
innovative monitoring and analysis systems through artificial
intelligence-based techniques. However, data curation processes are tedious,
time-consuming, and resource intensive. This study presents the first
systematic survey of publicly available livestock CV datasets
(https://github.com/Anil-Bhujel/Public-Computer-Vision-Dataset-A-Systematic-Survey).
Among 58 public datasets identified and analyzed, encompassing different
species of livestock, almost half of them are for cattle, followed by swine,
poultry, and other animals. Individual animal detection and color imaging are
the dominant application and imaging modality for livestock. The
characteristics and baseline applications of the datasets are discussed,
emphasizing the implications for animal welfare advocates. Challenges and
opportunities are also discussed to inspire further efforts in developing
livestock CV datasets. This study highlights that the limited quantity of
high-quality annotated datasets collected from diverse environments, animals,
and applications, the absence of contextual metadata, are a real bottleneck in
PLF.

ÊëòË¶ÅÔºö<paragraph>‰ª•ÁßëÊäÄÁÇ∫‰∏ªÁöÑÁ≤æÊ∫ñÁïúÁâßÈ§äÊÆñ (PLF) ËÆìÂæûÊ•≠‰∫∫Âì°Âæó‰ª•Áõ£ÊéßÂíåÂàÜÊûêÂãïÁâ©ÁöÑÁîüÈï∑ÂíåÂÅ•Â∫∑ÁãÄÊ≥ÅÔºå‰ª•ÊèêÈ´òÁîüÁî¢ÂäõÂíåÁ¶èÂà©„ÄÇÈõªËÖ¶Ë¶ñË¶∫ (CV) Âú® PLF ‰∏≠‰∏çÂèØÊàñÁº∫ÔºåÂÆÉÂà©Áî®Áõ∏Ê©üÂíåÈõªËÖ¶ÊºîÁÆóÊ≥ï‰æÜË£úÂÖÖÊàñÂèñ‰ª£‰∫∫Â∑•Êî∂ÈõÜÁïúÁâßË≥áÊñôÁöÑÂ∑•‰Ωú„ÄÇË≥áÊñôÂèñÂæóÂ∞çÊñºÈÄèÈÅé‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÈñãÁôºÂâµÊñ∞ÁöÑÁõ£ÊéßÂíåÂàÜÊûêÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåË≥áÊñôÊï¥ÁêÜÁöÑÁ®ãÂ∫èÁπÅÁë£„ÄÅËÄóÊôÇ‰∏îËÄóË≤ªË≥áÊ∫ê„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫ÂÖ¨ÈñãÂèñÂæóÁöÑÁïúÁâß CV Ë≥áÊñôÈõÜÁöÑÈ¶ñÊ¨°Á≥ªÁµ±ÊÄßË™øÊü• (https://github.com/Anil-Bhujel/Public-Computer-Vision-Dataset-A-Systematic-Survey)„ÄÇÂú®Ëæ®Ë≠òÂíåÂàÜÊûêÁöÑ 58 ÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÔºåÊ∂µËìã‰∏çÂêåÁ®ÆÈ°ûÁöÑÁâ≤ÁïúÔºåÂÖ∂‰∏≠Â∞áËøë‰∏ÄÂçäÊòØÁâõÈöªÔºåÂÖ∂Ê¨°ÊòØË±¨Èöª„ÄÅÂÆ∂Á¶ΩÂíåÂÖ∂‰ªñÂãïÁâ©„ÄÇÂÄãÂà•ÂãïÁâ©ÂÅµÊ∏¨ÂíåÂΩ©Ëâ≤ÂΩ±ÂÉèËôïÁêÜÊòØÁïúÁâßÊ•≠‰∏≠‰∏ªË¶ÅÁöÑÊáâÁî®ÂíåÂΩ±ÂÉèÊ®°Âºè„ÄÇÊú¨ÊñáË®éË´ñ‰∫ÜÈÄô‰∫õË≥áÊñôÈõÜÁöÑÁâπÂæµÂíåÂü∫Á§éÊáâÁî®Ôºå‰∏¶Âº∑Ë™øÂÖ∂Â∞çÂãïÁâ©Á¶èÂà©ÂÄ°Â∞éËÄÖÁöÑÊÑèÁæ©„ÄÇ‰πüË®éË´ñ‰∫ÜÊåëÊà∞ÂíåÊ©üÊúÉÔºå‰ª•ÊøÄÂãµÈÄ≤‰∏ÄÊ≠•ÈñãÁôºÁïúÁâß CV Ë≥áÊñôÈõÜ„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™øÔºåÂæûÂêÑÁ®ÆÁí∞Â¢É„ÄÅÂãïÁâ©ÂíåÊáâÁî®‰∏≠Êî∂ÈõÜÁöÑÈ´òÂìÅË≥™Ë®ªËß£Ë≥áÊñôÈõÜÊï∏ÈáèÊúâÈôêÔºå‰ª•ÂèäÁº∫‰πèËÑàÁµ°ÊÄßÂÖÉË≥áÊñôÔºåÊòØ PLF ‰∏≠ÁúüÊ≠£ÁöÑÁì∂È†∏„ÄÇ</paragraph>

##### **Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation**
2406.10519v1 by Pengfei Gu, Yejia Zhang, Huimin Li, Hongxiao Wang, Yizhe Zhang, Chaoli Wang, Danny Z. Chen

Masked Autoencoders (MAEs) have been shown to be effective in pre-training
Vision Transformers (ViTs) for natural and medical image analysis problems. By
reconstructing missing pixel/voxel information in visible patches, a ViT
encoder can aggregate contextual information for downstream tasks. But,
existing MAE pre-training methods, which were specifically developed with the
ViT architecture, lack the ability to capture geometric shape and spatial
information, which is critical for medical image segmentation tasks. In this
paper, we propose a novel extension of known MAEs for self pre-training (i.e.,
models pre-trained on the same target dataset) for 3D medical image
segmentation. (1) We propose a new topological loss to preserve geometric shape
information by computing topological signatures of both the input and
reconstructed volumes, learning geometric shape information. (2) We introduce a
pre-text task that predicts the positions of the centers and eight corners of
3D crops, enabling the MAE to aggregate spatial information. (3) We extend the
MAE pre-training strategy to a hybrid state-of-the-art (SOTA) medical image
segmentation architecture and co-pretrain it alongside the ViT. (4) We develop
a fine-tuned model for downstream segmentation tasks by complementing the
pre-trained ViT encoder with our pre-trained SOTA model. Extensive experiments
on five public 3D segmentation datasets show the effectiveness of our new
approach.

ÊëòË¶ÅÔºöËíôÈù¢Ëá™ÂãïÁ∑®Á¢ºÂô® (MAE) Â∑≤Ë¢´Ë≠âÊòéÂèØÊúâÊïàÁî®ÊñºËá™ÁÑ∂ÂíåÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÂïèÈ°åÁöÑ Vision Transformer (ViT) È†êË®ìÁ∑¥„ÄÇÈÄèÈÅéÈáçÂª∫ÂèØË¶ãË£ú‰∏Å‰∏≠ÈÅ∫Â§±ÁöÑÂÉèÁ¥†/È´îÁ¥†Ë≥áË®äÔºåViT Á∑®Á¢ºÂô®ÂèØ‰ª•ÂΩôÁ∏Ω‰∏ãÊ∏∏‰ªªÂãôÁöÑËÑàÁµ°Ë≥áË®ä„ÄÇ‰ΩÜÊòØÔºåÂ∞àÈñÄÈáùÂ∞ç ViT Êû∂ÊßãÈñãÁôºÁöÑÁèæÊúâ MAE È†êË®ìÁ∑¥ÊñπÊ≥ïÁº∫‰πèÊì∑ÂèñÂπæ‰ΩïÂΩ¢ÁãÄÂíåÁ©∫ÈñìË≥áË®äÁöÑËÉΩÂäõÔºåËÄåÈÄôÂ∞çÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤‰ªªÂãôËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Â∑≤Áü• MAE ÁöÑÊñ∞Âª∂‰º∏ÔºåÁî®Êñº 3D ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÁöÑËá™È†êË®ìÁ∑¥ÔºàÂç≥Âú®Âêå‰∏ÄÁõÆÊ®ôË≥áÊñôÈõÜ‰∏äÈ†êË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºâ„ÄÇÔºà1ÔºâÊàëÂÄëÊèêÂá∫Êñ∞ÁöÑÊãìÊí≤ÊêçÂ§±‰æÜ‰øùÁïôÂπæ‰ΩïÂΩ¢ÁãÄË≥áË®äÔºåÊñπÊ≥ïÊòØË®àÁÆóËº∏ÂÖ•ÂíåÈáçÂª∫È´îÁ©çÁöÑÊãìÊí≤ÁâπÂæµÔºåÂ≠∏ÁøíÂπæ‰ΩïÂΩ¢ÁãÄË≥áË®ä„ÄÇÔºà2ÔºâÊàëÂÄëÂºïÂÖ•È†êÊñáÊú¨‰ªªÂãôÔºåÁî®ÊñºÈ†êÊ∏¨ 3D Ë£ÅÂâ™ÁöÑ‰∏≠ÂøÉÂíåÂÖ´ÂÄãËßíÁöÑ‰ΩçÁΩÆÔºå‰Ωø MAE ËÉΩÂ§†ÂΩôÁ∏ΩÁ©∫ÈñìË≥áË®ä„ÄÇÔºà3ÔºâÊàëÂÄëÂ∞á MAE È†êË®ìÁ∑¥Á≠ñÁï•Âª∂‰º∏Âà∞Ê∑∑ÂêàÁöÑÊúÄÊñ∞ (SOTA) ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Êû∂ÊßãÔºå‰∏¶Ëàá ViT ‰∏ÄËµ∑È†êË®ìÁ∑¥ÂÆÉ„ÄÇÔºà4ÔºâÊàëÂÄëÈÄèÈÅéË£úÂÖÖÈ†êË®ìÁ∑¥ÁöÑ ViT Á∑®Á¢ºÂô®ËàáÊàëÂÄëÁöÑÈ†êË®ìÁ∑¥ SOTA Ê®°ÂûãÔºåÁÇ∫‰∏ãÊ∏∏ÂàÜÂâ≤‰ªªÂãôÈñãÁôºÂæÆË™øÊ®°Âûã„ÄÇÂú®‰∫îÂÄãÂÖ¨Èñã 3D ÂàÜÂâ≤Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫‰∫ÜÊàëÂÄëÊñ∞ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Biomarker based Cancer Classification using an Ensemble with Pre-trained Models**
2406.10087v1 by Chongmin Lee, Jihie Kim

Certain cancer types, namely pancreatic cancer is difficult to detect at an
early stage; sparking the importance of discovering the causal relationship
between biomarkers and cancer to identify cancer efficiently. By allowing for
the detection and monitoring of specific biomarkers through a non-invasive
method, liquid biopsies enhance the precision and efficacy of medical
interventions, advocating the move towards personalized healthcare. Several
machine learning algorithms such as Random Forest, SVM are utilized for
classification, yet causing inefficiency due to the need for conducting
hyperparameter tuning. We leverage a meta-trained Hyperfast model for
classifying cancer, accomplishing the highest AUC of 0.9929 and simultaneously
achieving robustness especially on highly imbalanced datasets compared to other
ML algorithms in several binary classification tasks (e.g. breast invasive
carcinoma; BRCA vs. non-BRCA). We also propose a novel ensemble model combining
pre-trained Hyperfast model, XGBoost, and LightGBM for multi-class
classification tasks, achieving an incremental increase in accuracy (0.9464)
while merely using 500 PCA features; distinguishable from previous studies
where they used more than 2,000 features for similar results.

ÊëòË¶ÅÔºöÊüê‰∫õÁ±ªÂûãÁöÑÁôåÁóáÔºå‰æãÂ¶ÇËÉ∞ËáüÁôåÔºåÂú®Êó©ÊúüÈöéÊÆµÈõ£‰ª•Ê™¢Ê∏¨Âá∫‰æÜÔºõÈÄôÈªûÂá∏È°Ø‰∫ÜÊâæÂá∫ÁîüÁâ©Ê®ôË®òËàáÁôåÁóá‰πãÈñìÁöÑÂõ†ÊûúÈóú‰øÇ‰ª•ÊúâÊïàËæ®Ë≠òÁôåÁóáÁöÑÈáçË¶ÅÊÄß„ÄÇÊ∂≤ÊÖãÂàáÁâáÈÄèÈÅéÈùû‰æµÂÖ•ÊÄßÊñπÊ≥ïÊ™¢Ê∏¨ÂíåÁõ£ÊéßÁâπÂÆöÁîüÁâ©Ê®ôË®òÔºåÈÄ≤ËÄåÊèêÂçáÈÜ´ÁôÇ‰ªãÂÖ•ÁöÑÁ≤æÊ∫ñÂ∫¶ÂíåÊïàËÉΩÔºå‰∏¶ÂÄ°Â∞éÊúùÂêëÂÄã‰∫∫ÂåñÈÜ´ÁôÇ‰øùÂÅ•ÈÇÅÈÄ≤„ÄÇÈö®Ê©üÊ£ÆÊûó„ÄÅSVM Á≠âÂ§öÁ®ÆÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÁî®ÊñºÂàÜÈ°ûÔºå‰ΩÜÁî±ÊñºÈúÄË¶ÅÈÄ≤Ë°åË∂ÖÂèÉÊï∏Ë™øÊï¥ÔºåÂõ†Ê≠§ÈÄ†ÊàêÊïàÁéá‰∏çÂΩ∞„ÄÇÊàëÂÄëÂà©Áî®Á∂ìÈÅéÂÖÉË®ìÁ∑¥ÁöÑ Hyperfast Ê®°Âûã‰æÜÂàÜÈ°ûÁôåÁóáÔºåÈÅîÂà∞‰∫Ü 0.9929 ÁöÑÊúÄÈ´ò AUCÔºåÂêåÊôÇÂú®Â§öÈ†Ö‰∫åÂÖÉÂàÜÈ°û‰ªªÂãô‰∏≠Ôºà‰æãÂ¶Ç‰π≥ÊàøÊµ∏ÊΩ§ÊÄßÁôåÔºõBRCA ËàáÈùû BRCAÔºâÂØ¶Áèæ‰∫ÜÁ©©ÂÅ•ÊÄßÔºåÁâπÂà•ÊòØÂú®È´òÂ∫¶‰∏çÂπ≥Ë°°ÁöÑË≥áÊñôÈõÜ‰∏äÔºåÂÑ™ÊñºÂÖ∂‰ªñ ML ÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊï¥ÂêàÊ®°ÂûãÔºåÁµêÂêàÈ†êÂÖàË®ìÁ∑¥ÁöÑ Hyperfast Ê®°Âûã„ÄÅXGBoost Âíå LightGBMÔºåÁî®ÊñºÂ§öÈ°ûÂà•ÂàÜÈ°û‰ªªÂãôÔºåÂÉÖ‰ΩøÁî® 500 ÂÄã PCA ÁâπÂæµ‰æøÈÅîÂà∞‰∫ÜÁ≤æÊ∫ñÂ∫¶ÁöÑÂ¢ûÈáèÊèêÂçáÔºà0.9464ÔºâÔºõÈÄôÈªûÊúâÂà•ÊñºÂÖàÂâçÁöÑÁ†îÁ©∂ÔºåÂÆÉÂÄë‰ΩøÁî®Ë∂ÖÈÅé 2,000 ÂÄãÁâπÂæµ‰æÜÁç≤ÂæóÈ°û‰ººÁöÑÁµêÊûú„ÄÇ

##### **FZI-WIM at SemEval-2024 Task 2: Self-Consistent CoT for Complex NLI in Biomedical Domain**
2406.10040v1 by Jin Liu, Steffen Thoma

This paper describes the inference system of FZI-WIM at the SemEval-2024 Task
2: Safe Biomedical Natural Language Inference for Clinical Trials. Our system
utilizes the chain of thought (CoT) paradigm to tackle this complex reasoning
problem and further improves the CoT performance with self-consistency. Instead
of greedy decoding, we sample multiple reasoning chains with the same prompt
and make the final verification with majority voting. The self-consistent CoT
system achieves a baseline F1 score of 0.80 (1st), faithfulness score of 0.90
(3rd), and consistency score of 0.73 (12th). We release the code and data
publicly https://github.com/jens5588/FZI-WIM-NLI4CT.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊèèËø∞‰∫Ü FZI-WIM Âú® SemEval-2024 ‰ªªÂãô 2ÔºöËá®Â∫äË©¶È©óÁöÑÂÆâÂÖ®ÁîüÁâ©ÈÜ´Â≠∏Ëá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ‰∏≠ÁöÑÊé®Ë´ñÁ≥ªÁµ±„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Âà©Áî®ÊÄùËÄÉÈèàÔºàCoTÔºâÁØÑ‰æã‰æÜËß£Ê±∫ÈÄôÂÄãË§áÈõúÁöÑÊé®ÁêÜÂïèÈ°åÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéËá™Ê¥ΩÊÄß‰æÜÊèêÂçá CoT ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄë‰ΩøÁî®Áõ∏ÂêåÁöÑÊèêÁ§∫ÂèñÊ®£Â§öÂÄãÊé®ÁêÜÈèàÔºåËÄåÈùûË≤™Â©™Ëß£Á¢ºÔºå‰∏¶ÈÄèÈÅéÂ§öÊï∏Ê±∫ÈÄ≤Ë°åÊúÄÁµÇÈ©óË≠â„ÄÇËá™Ê¥ΩÁöÑ CoT Á≥ªÁµ±ÈÅîÂà∞Âü∫Á∑ö F1 ÂàÜÊï∏ 0.80ÔºàÁ¨¨ 1 ÂêçÔºâ„ÄÅÂø†ÂØ¶Â∫¶ÂàÜÊï∏ 0.90ÔºàÁ¨¨ 3 ÂêçÔºâÂíå‰∏ÄËá¥ÊÄßÂàÜÊï∏ 0.73ÔºàÁ¨¨ 12 ÂêçÔºâ„ÄÇÊàëÂÄëÂÖ¨ÈñãÁôºÂ∏ÉÁ®ãÂºèÁ¢ºÂíåË≥áÊñô https://github.com/jens5588/FZI-WIM-NLI4CT„ÄÇ

##### **CliBench: Multifaceted Evaluation of Large Language Models in Clinical Decisions on Diagnoses, Procedures, Lab Tests Orders and Prescriptions**
2406.09923v1 by Mingyu Derek Ma, Chenchen Ye, Yu Yan, Xiaoxuan Wang, Peipei Ping, Timothy S Chang, Wei Wang

The integration of Artificial Intelligence (AI), especially Large Language
Models (LLMs), into the clinical diagnosis process offers significant potential
to improve the efficiency and accessibility of medical care. While LLMs have
shown some promise in the medical domain, their application in clinical
diagnosis remains underexplored, especially in real-world clinical practice,
where highly sophisticated, patient-specific decisions need to be made. Current
evaluations of LLMs in this field are often narrow in scope, focusing on
specific diseases or specialties and employing simplified diagnostic tasks. To
bridge this gap, we introduce CliBench, a novel benchmark developed from the
MIMIC IV dataset, offering a comprehensive and realistic assessment of LLMs'
capabilities in clinical diagnosis. This benchmark not only covers diagnoses
from a diverse range of medical cases across various specialties but also
incorporates tasks of clinical significance: treatment procedure
identification, lab test ordering and medication prescriptions. Supported by
structured output ontologies, CliBench enables a precise and multi-granular
evaluation, offering an in-depth understanding of LLM's capability on diverse
clinical tasks of desired granularity. We conduct a zero-shot evaluation of
leading LLMs to assess their proficiency in clinical decision-making. Our
preliminary results shed light on the potential and limitations of current LLMs
in clinical settings, providing valuable insights for future advancements in
LLM-powered healthcare.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÔºåÂ∞§ÂÖ∂ÊòØÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºåÊï¥ÂêàÂà∞Ëá®Â∫äË®∫Êñ∑ÈÅéÁ®ã‰∏≠ÔºåÊèê‰æõ‰∫ÜÈ°ØËëóÁöÑÊΩõÂäõÔºåÂèØ‰ª•ÊèêÈ´òÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÊïàÁéáÂíåÂèØÂèäÊÄß„ÄÇÈõñÁÑ∂ LLM Âú®ÈÜ´ÁôÇÈ†òÂüüÈ°ØÁ§∫Âá∫‰∏Ä‰∫õÂâçÊôØÔºå‰ΩÜÂÆÉÂÄëÂú®Ëá®Â∫äË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÂØ¶Âãô‰∏≠ÔºåÈúÄË¶ÅÂÅöÂá∫È´òÂ∫¶Ë§áÈõú„ÄÅÈáùÂ∞çÁâπÂÆöÊÇ£ËÄÖÁöÑÊ±∫Á≠ñ„ÄÇÁõÆÂâçÂú®ÈÄôÂÄãÈ†òÂüüÂ∞ç LLM ÁöÑË©ï‰º∞ÈÄöÂ∏∏ÁØÑÂúçÁãπÁ™ÑÔºåËëóÈáçÊñºÁâπÂÆöÁñæÁóÖÊàñÂ∞àÁßëÔºå‰∏¶Êé°Áî®Á∞°ÂåñÁöÑË®∫Êñ∑‰ªªÂãô„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü CliBenchÔºåÈÄôÊòØ‰∏ÄÂÄãÂæû MIMIC IV Ë≥áÊñôÈõÜÈñãÁôºÁöÑÊñ∞Âü∫Ê∫ñÔºåÊèê‰æõ‰∫ÜÂ∞ç LLM Âú®Ëá®Â∫äË®∫Êñ∑‰∏≠ËÉΩÂäõÁöÑÂÖ®Èù¢‰∏îÂØ¶ÈöõÁöÑË©ï‰º∞„ÄÇÊ≠§Âü∫Ê∫ñ‰∏çÂÉÖÊ∂µËìã‰∫ÜÂêÑÁ®ÆÂ∞àÁßë‰∏≠ÂêÑÁ®ÆÈÜ´ÁôÇÊ°à‰æãÁöÑË®∫Êñ∑ÔºåÈÇÑÁ¥çÂÖ•‰∫ÜÂÖ∑ÊúâËá®Â∫äÊÑèÁæ©ÁöÑ‰ªªÂãôÔºöÊ≤ªÁôÇÁ®ãÂ∫èË≠òÂà•„ÄÅÂØ¶È©óÂÆ§Ê™¢È©óË®ÇË≥ºÂíåËó•Áâ©ËôïÊñπ„ÄÇÂú®ÁµêÊßãÂåñËº∏Âá∫Êú¨‰ΩìÁöÑÊîØÊåÅ‰∏ãÔºåCliBench ËÉΩÂ§†ÈÄ≤Ë°åÁ≤æÁ¢∫‰∏îÂ§öÁ≤íÂ∫¶ÁöÑË©ï‰º∞ÔºåÊèê‰æõÂ∞ç LLM Âú®ÂêÑÁ®ÆÊâÄÈúÄÁ≤íÂ∫¶ÁöÑËá®Â∫ä‰ªªÂãô‰∏äÁöÑËÉΩÂäõÁöÑÊ∑±ÂÖ•‰∫ÜËß£„ÄÇÊàëÂÄëÂ∞çÈ†òÂÖàÁöÑ LLM ÈÄ≤Ë°å‰∫ÜÈõ∂Ê¨°Â≠∏ÁøíË©ï‰º∞Ôºå‰ª•Ë©ï‰º∞ÂÆÉÂÄëÂú®Ëá®Â∫äÊ±∫Á≠ñ‰∏≠ÁöÑÁÜüÁ∑¥Á®ãÂ∫¶„ÄÇÊàëÂÄëÁöÑÂàùÊ≠•ÁµêÊûúÊè≠Á§∫‰∫ÜÁï∂Ââç LLM Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊΩõÂäõÂíåÂ±ÄÈôêÊÄßÔºåÁÇ∫ LLM È©ÖÂãïÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÊú™‰æÜÈÄ≤Â±ïÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£„ÄÇ

##### **A Survey on Large Language Models from General Purpose to Medical Applications: Datasets, Methodologies, and Evaluations**
2406.10303v1 by Jinqiang Wang, Huansheng Ning, Yi Peng, Qikai Wei, Daniel Tesfai, Wenwei Mao, Tao Zhu, Runhe Huang

Large Language Models (LLMs) have demonstrated surprising performance across
various natural language processing tasks. Recently, medical LLMs enhanced with
domain-specific knowledge have exhibited excellent capabilities in medical
consultation and diagnosis. These models can smoothly simulate doctor-patient
dialogues and provide professional medical advice. Most medical LLMs are
developed through continued training of open-source general LLMs, which require
significantly fewer computational resources than training LLMs from scratch.
Additionally, this approach offers better protection of patient privacy
compared to API-based solutions. This survey systematically explores how to
train medical LLMs based on general LLMs. It covers: (a) how to acquire
training corpus and construct customized medical training sets, (b) how to
choose a appropriate training paradigm, (c) how to choose a suitable evaluation
benchmark, and (d) existing challenges and promising future research directions
are discussed. This survey can provide guidance for the development of LLMs
focused on various medical applications, such as medical education, diagnostic
planning, and clinical assistants.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫È©ö‰∫∫ÁöÑË°®Áèæ„ÄÇÊúÄËøëÔºåÂ¢ûÂº∑‰∫ÜÁâπÂÆöÈ†òÂüüÁü•Ë≠òÁöÑÈÜ´ÁôÇ LLM Â∑≤Âú®ÈÜ´ÁôÇË´ÆË©¢ÂíåË®∫Êñ∑ÊñπÈù¢Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑËÉΩÂäõ„ÄÇÈÄô‰∫õÊ®°ÂûãÂèØ‰ª•È†ÜÂà©Ê®°Êì¨ÈÜ´ÁóÖÂ∞çË©±‰∏¶Êèê‰æõÂ∞àÊ•≠ÁöÑÈÜ´ÁôÇÂª∫Ë≠∞„ÄÇÂ§ßÂ§öÊï∏ÈÜ´ÁôÇ LLM ÈÉΩÊòØÈÄèÈÅéÊåÅÁ∫åË®ìÁ∑¥ÈñãÊ∫êÁöÑ‰∏ÄËà¨ LLM ËÄåÈñãÁôºÁöÑÔºåËàáÂæûÈ†≠Ë®ìÁ∑¥ LLM Áõ∏ÊØîÔºåÊâÄÈúÄÈÅãÁÆóË≥áÊ∫êÊòéÈ°ØËºÉÂ∞ë„ÄÇÊ≠§Â§ñÔºåËàáÂü∫Êñº API ÁöÑËß£Ê±∫ÊñπÊ°àÁõ∏ÊØîÔºåÈÄôÁ®ÆÊñπÊ≥ïÊèê‰æõ‰∫ÜÊõ¥Â•ΩÁöÑÁóÖÊÇ£Èö±ÁßÅ‰øùË≠∑„ÄÇÈÄôÈ†ÖË™øÊü•Á≥ªÁµ±ÊÄßÂú∞Êé¢Ë®éÂ¶Ç‰ΩïÊ†πÊìö‰∏ÄËà¨ LLM Ë®ìÁ∑¥ÈÜ´ÁôÇ LLM„ÄÇÂÆÉÊ∂µËìãÔºö(a) Â¶Ç‰ΩïÂèñÂæóË®ìÁ∑¥Ë™ûÊñôÂ∫´‰∏¶Âª∫ÊßãÂÆ¢Ë£ΩÂåñÁöÑÈÜ´ÁôÇË®ìÁ∑¥ÁµÑÔºå(b) Â¶Ç‰ΩïÈÅ∏ÊìáÈÅ©Áï∂ÁöÑË®ìÁ∑¥ÁØÑ‰æãÔºå(c) Â¶Ç‰ΩïÈÅ∏ÊìáÂêàÈÅ©ÁöÑË©ïÈáèÂü∫Ê∫ñÔºå‰ª•Âèä (d) Ë®éË´ñÁèæÊúâÁöÑÊåëÊà∞ÂíåÊúâÂâçÊôØÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêë„ÄÇÈÄôÈ†ÖË™øÊü•ÂèØ‰ª•ÁÇ∫ÈáùÂ∞çÂêÑÁ®ÆÈÜ´ÁôÇÊáâÁî®Ôºà‰æãÂ¶ÇÈÜ´Â≠∏ÊïôËÇ≤„ÄÅË®∫Êñ∑Ë¶èÂäÉÂíåËá®Â∫äÂä©ÁêÜÔºâÁöÑ LLM ÈñãÁôºÊèê‰æõÊåáÂ∞é„ÄÇ

##### **Investigating potential causes of Sepsis with Bayesian network structure learning**
2406.09207v1 by Bruno Petrungaro, Neville K. Kitson, Anthony C. Constantinou

Sepsis is a life-threatening and serious global health issue. This study
combines knowledge with available hospital data to investigate the potential
causes of Sepsis that can be affected by policy decisions. We investigate the
underlying causal structure of this problem by combining clinical expertise
with score-based, constraint-based, and hybrid structure learning algorithms. A
novel approach to model averaging and knowledge-based constraints was
implemented to arrive at a consensus structure for causal inference. The
structure learning process highlighted the importance of exploring data-driven
approaches alongside clinical expertise. This includes discovering unexpected,
although reasonable, relationships from a clinical perspective. Hypothetical
interventions on Chronic Obstructive Pulmonary Disease, Alcohol dependence, and
Diabetes suggest that the presence of any of these risk factors in patients
increases the likelihood of Sepsis. This finding, alongside measuring the
effect of these risk factors on Sepsis, has potential policy implications.
Recognising the importance of prediction in improving Sepsis related health
outcomes, the model built is also assessed in its ability to predict Sepsis.
The predictions generated by the consensus model were assessed for their
accuracy, sensitivity, and specificity. These three indicators all had results
around 70%, and the AUC was 80%, which means the causal structure of the model
is reasonably accurate given that the models were trained on data available for
commissioning purposes only.

ÊëòË¶ÅÔºöÊïóË°ÄÁóáÊòØ‰∏ÄÂÄãÂç±ÂèäÁîüÂëΩ‰∏îÂö¥ÈáçÁöÑÂÖ®ÁêÉÊÄßÂÅ•Â∫∑ÂïèÈ°å„ÄÇÊú¨Á†îÁ©∂ÁµêÂêàÁü•Ë≠òËàáÁèæÊúâÁöÑÈÜ´Èô¢Ë≥áÊñôÔºåÊé¢Ë®éÂèØÂèóÊîøÁ≠ñÊ±∫Á≠ñÂΩ±ÈüøÁöÑÊïóË°ÄÁóáÊΩõÂú®ÊàêÂõ†„ÄÇÊàëÂÄëÁµêÂêàËá®Â∫äÂ∞àÊ•≠Áü•Ë≠òËàáÂü∫ÊñºÂàÜÊï∏„ÄÅÂü∫ÊñºÁ¥ÑÊùüÂíåÊ∑∑ÂêàÁµêÊßãÂ≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÊé¢Ë®éÈÄôÂÄãÂïèÈ°åÁöÑÊ†πÊú¨Âõ†ÊûúÁµêÊßã„ÄÇÂØ¶‰Ωú‰∫Ü‰∏ÄÁ®ÆÊ®°ÂûãÂπ≥ÂùáÂíåÂü∫ÊñºÁü•Ë≠òÁöÑÁ¥ÑÊùüÁöÑÊñ∞ÊñπÊ≥ïÔºå‰ª•ÈÅîÊàêÂõ†ÊûúÊé®Ë´ñÁöÑÂÖ±Ë≠òÁµêÊßã„ÄÇÁµêÊßãÂ≠∏ÁøíÈÅéÁ®ãÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫äÂ∞àÊ•≠Áü•Ë≠òÁöÑÂü∫Á§é‰∏äÊé¢Á¥¢Ë≥áÊñôÈ©ÖÂãïÊñπÊ≥ïÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÂåÖÊã¨ÂæûËá®Â∫äËßÄÈªûÁôºÁèæÂá∫‰πéÊÑèÊñôÔºå‰ΩÜÂêàÁêÜÁöÑÈóú‰øÇ„ÄÇÂ∞çÊÖ¢ÊÄßÈòªÂ°ûÊÄßËÇ∫ÁñæÁóÖ„ÄÅÈÖíÁ≤æ‰æùË≥¥ÂíåÁ≥ñÂ∞øÁóÖÁöÑÂÅáË®≠ÊÄßÂπ≤È†êË°®ÊòéÔºåÊÇ£ËÄÖÂ≠òÂú®‰ªª‰ΩïÈÄô‰∫õÈ¢®Èö™Âõ†Á¥†ÈÉΩÊúÉÂ¢ûÂä†ÊïóË°ÄÁóáÁöÑÂèØËÉΩÊÄß„ÄÇÈÄôÂÄãÁôºÁèæÔºå‰ª•ÂèäÊ∏¨ÈáèÈÄô‰∫õÈ¢®Èö™Âõ†Á¥†Â∞çÊïóË°ÄÁóáÁöÑÂΩ±ÈüøÔºåÂÖ∑ÊúâÊΩõÂú®ÁöÑÊîøÁ≠ñÂΩ±Èüø„ÄÇË™çË≠òÂà∞È†êÊ∏¨Âú®ÊîπÂñÑÊïóË°ÄÁóáÁõ∏ÈóúÂÅ•Â∫∑ÁµêÊûú‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºåÊâÄÂª∫Á´ãÁöÑÊ®°Âûã‰πüË©ï‰º∞‰∫ÜÂÖ∂È†êÊ∏¨ÊïóË°ÄÁóáÁöÑËÉΩÂäõ„ÄÇË©ï‰º∞ÂÖ±Ë≠òÊ®°ÂûãÁî¢ÁîüÁöÑÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÊïèÊÑüÊÄßÂíåÁâπÁï∞ÊÄß„ÄÇÈÄô‰∏âÂÄãÊåáÊ®ôÁöÑÁµêÊûúÈÉΩÂú® 70% Â∑¶Âè≥ÔºåËÄå AUC ÁÇ∫ 80%ÔºåÈÄôË°®Á§∫Ê®°ÂûãÁöÑÂõ†ÊûúÁµêÊßãÁõ∏Áï∂Ê∫ñÁ¢∫ÔºåÂõ†ÁÇ∫Ê®°ÂûãÂÉÖÊ†πÊìöÂèØÁî®ÊñºÂßîË®óÁõÆÁöÑÁöÑË≥áÊñôÈÄ≤Ë°åË®ìÁ∑¥„ÄÇ

##### **INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance**
2406.09105v1 by Chenwei Lin, Hanjia Lyu, Xian Xu, Jiebo Luo

Large Vision-Language Models (LVLMs) have demonstrated outstanding
performance in various general multimodal applications such as image
recognition and visual reasoning, and have also shown promising potential in
specialized domains. However, the application potential of LVLMs in the
insurance domain-characterized by rich application scenarios and abundant
multimodal data-has not been effectively explored. There is no systematic
review of multimodal tasks in the insurance domain, nor a benchmark
specifically designed to evaluate the capabilities of LVLMs in insurance. This
gap hinders the development of LVLMs within the insurance domain. In this
paper, we systematically review and distill multimodal tasks for four
representative types of insurance: auto insurance, property insurance, health
insurance, and agricultural insurance. We propose INS-MMBench, the first
comprehensive LVLMs benchmark tailored for the insurance domain. INS-MMBench
comprises a total of 2.2K thoroughly designed multiple-choice questions,
covering 12 meta-tasks and 22 fundamental tasks. Furthermore, we evaluate
multiple representative LVLMs, including closed-source models such as GPT-4o
and open-source models like BLIP-2. This evaluation not only validates the
effectiveness of our benchmark but also provides an in-depth performance
analysis of current LVLMs on various multimodal tasks in the insurance domain.
We hope that INS-MMBench will facilitate the further application of LVLMs in
the insurance domain and inspire interdisciplinary development. Our dataset and
evaluation code are available at https://github.com/FDU-INS/INS-MMBench.

ÊëòË¶ÅÔºöÂ§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã (LVLMs) Â∑≤Âú®ÂõæÂÉèËØÜÂà´ÂíåËßÜËßâÊé®ÁêÜÁ≠âÂêÑÁßçÈÄöÁî®Â§öÊ®°ÊÄÅÂ∫îÁî®Á®ãÂ∫è‰∏≠Â±ïÁ§∫‰∫ÜÂá∫Ëâ≤ÁöÑÊÄßËÉΩÔºåÂπ∂‰∏îÂú®‰∏ìÈó®ÁöÑÈ¢ÜÂüü‰∏≠‰πüÊòæÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÊΩúÂäõ„ÄÇÁÑ∂ËÄåÔºåLVLMs Âú®‰øùÈô©È¢ÜÂüüÔºà‰ª•‰∏∞ÂØåÁöÑÂ∫îÁî®Âú∫ÊôØÂíåÂ§ßÈáèÂ§öÊ®°ÊÄÅÊï∞ÊçÆ‰∏∫ÁâπÂæÅÔºâÁöÑÂ∫îÁî®ÊΩúÂäõÂ∞öÊú™ÂæóÂà∞ÊúâÊïàÊé¢Á¥¢„ÄÇÁõÆÂâçËøòÊ≤°ÊúâÂØπ‰øùÈô©È¢ÜÂüüÁöÑÊ®°ÊÄÅ‰ªªÂä°ËøõË°åÁ≥ªÁªüÁöÑÂÆ°Êü•Ôºå‰πüÊ≤°Êúâ‰∏ìÈó®ËÆæËÆ°Áî®Êù•ËØÑ‰º∞ LVLMs Âú®‰øùÈô©‰∏≠ÁöÑËÉΩÂäõÁöÑÂü∫ÂáÜ„ÄÇËøôÁßçÂ∑ÆË∑ùÈòªÁ¢ç‰∫Ü LVLMs Âú®‰øùÈô©È¢ÜÂüüÁöÑÂºÄÂèë„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Á≥ªÁªüÂú∞ÂÆ°Êü•ÂíåÊèêÁÇº‰∫ÜÂõõÁßç‰ª£Ë°®ÊÄß‰øùÈô©Á±ªÂûãÁöÑÂ§öÊ®°ÊÄÅ‰ªªÂä°ÔºöÊ±ΩËΩ¶‰øùÈô©„ÄÅË¥¢‰∫ß‰øùÈô©„ÄÅÂÅ•Â∫∑‰øùÈô©ÂíåÂÜú‰∏ö‰øùÈô©„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü INS-MMBenchÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÈíàÂØπ‰øùÈô©È¢ÜÂüüÂÆöÂà∂ÁöÑÁªºÂêà LVLMs Âü∫ÂáÜ„ÄÇINS-MMBench ÂåÖÂê´ÊÄªÂÖ± 2.2K ‰∏™ÁªèËøáÁ≤æÂøÉËÆæËÆ°ÁöÑÂçïÈÄâÈ¢òÔºåÊ∂µÁõñ 12 ‰∏™ÂÖÉ‰ªªÂä°Âíå 22 ‰∏™Âü∫Êú¨‰ªªÂä°„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËØÑ‰º∞‰∫ÜÂ§öÁßç‰ª£Ë°®ÊÄß LVLMsÔºåÂåÖÊã¨Â∞ÅÈó≠Ê∫êÊ®°ÂûãÔºàÂ¶Ç GPT-4oÔºâÂíåÂºÄÊîæÊ∫êÊ®°ÂûãÔºàÂ¶Ç BLIP-2Ôºâ„ÄÇÊ≠§ËØÑ‰º∞‰∏ç‰ªÖÈ™åËØÅ‰∫ÜÊàë‰ª¨Âü∫ÂáÜÁöÑÊúâÊïàÊÄßÔºåËøòÊèê‰æõ‰∫ÜÂΩìÂâç LVLMs Âú®‰øùÈô©È¢ÜÂüüÂêÑÁßçÂ§öÊ®°ÊÄÅ‰ªªÂä°‰∏äÁöÑÊ∑±ÂÖ•ÊÄßËÉΩÂàÜÊûê„ÄÇÊàë‰ª¨Â∏åÊúõ INS-MMBench Â∞Ü‰øÉËøõ LVLMs Âú®‰øùÈô©È¢ÜÂüüÁöÑËøõ‰∏ÄÊ≠•Â∫îÁî®ÔºåÂπ∂ÊøÄÂèëË∑®Â≠¶ÁßëÂèëÂ±ï„ÄÇÊàë‰ª¨ÁöÑÊï∞ÊçÆÈõÜÂíåËØÑ‰º∞‰ª£Á†ÅÂèØÂú® https://github.com/FDU-INS/INS-MMBench Ëé∑Âæó„ÄÇ

##### **Deep learning empowered sensor fusion to improve infant movement classification**
2406.09014v2 by Tomas Kulvicius, Dajie Zhang, Luise Poustka, Sven B√∂lte, Lennart Jahn, Sarah Fl√ºgge, Marc Kraft, Markus Zweckstetter, Karin Nielsen-Saines, Florentin W√∂rg√∂tter, Peter B Marschik

There is a recent boom in the development of AI solutions to facilitate and
enhance diagnostic procedures for established clinical tools. To assess the
integrity of the developing nervous system, the Prechtl general movement
assessment (GMA) is recognized for its clinical value in diagnosing
neurological impairments in early infancy. GMA has been increasingly augmented
through machine learning approaches intending to scale-up its application,
circumvent costs in the training of human assessors and further standardize
classification of spontaneous motor patterns. Available deep learning tools,
all of which are based on single sensor modalities, are however still
considerably inferior to that of well-trained human assessors. These approaches
are hardly comparable as all models are designed, trained and evaluated on
proprietary/silo-data sets. With this study we propose a sensor fusion approach
for assessing fidgety movements (FMs) comparing three different sensor
modalities (pressure, inertial, and visual sensors). Various combinations and
two sensor fusion approaches (late and early fusion) for infant movement
classification were tested to evaluate whether a multi-sensor system
outperforms single modality assessments. The performance of the three-sensor
fusion (classification accuracy of 94.5\%) was significantly higher than that
of any single modality evaluated, suggesting the sensor fusion approach is a
promising avenue for automated classification of infant motor patterns. The
development of a robust sensor fusion system may significantly enhance AI-based
early recognition of neurofunctions, ultimately facilitating automated early
detection of neurodevelopmental conditions.

ÊëòË¶ÅÔºöËøë‰æÜÔºå‰øÉÈÄ≤‰∏¶ÊèêÂçáÊó¢ÊúâËá®Â∫äÂ∑•ÂÖ∑ÁöÑË®∫Êñ∑Á®ãÂ∫èÁöÑ‰∫∫Â∑•Êô∫ÊÖßËß£Ê±∫ÊñπÊ°àÁôºÂ±ïËì¨ÂãÉ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÁôºËÇ≤‰∏≠Á•ûÁ∂ìÁ≥ªÁµ±ÁöÑÂÆåÊï¥ÊÄßÔºåPrechtl ÂÖ®Ëà¨Âãï‰ΩúË©ï‰º∞ (GMA) Âõ†ÂÖ∂Âú®Ë®∫Êñ∑Â¨∞ÂÖíÊó©ÊúüÁ•ûÁ∂ìÊêçÂÇ∑ÁöÑËá®Â∫äÂÉπÂÄºËÄåÂèóÂà∞ËÇØÂÆö„ÄÇGMA Â∑≤ÈÄèÈÅéÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÊåÅÁ∫åÊì¥ÂÖÖÔºåÊó®Âú®Êì¥Â§ßÂÖ∂ÊáâÁî®ÁØÑÂúçÔºåË¶èÈÅø‰∫∫È°ûË©ï‰º∞‰∫∫Âì°ÂüπË®ìÁöÑÊàêÊú¨Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Ê®ôÊ∫ñÂåñËá™ÁôºÊÄßÂãï‰ΩúÊ®°ÂºèÁöÑÂàÜÈ°û„ÄÇÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÂ∑•ÂÖ∑ÔºåÂÖ®ÈÉ®ÈÉΩÂü∫ÊñºÂñÆ‰∏ÄÊÑüÊ∏¨Âô®Ê®°ÂºèÔºå‰ΩÜ‰ªçÈÅ†ÈÅúÊñºË®ìÁ∑¥ÊúâÁ¥†ÁöÑ‰∫∫È°ûË©ï‰º∞‰∫∫Âì°„ÄÇÈÄô‰∫õÊñπÊ≥ïÈõ£‰ª•ÊØîËºÉÔºåÂõ†ÁÇ∫ÊâÄÊúâÊ®°ÂûãÈÉΩÊòØÂú®Â∞àÊúâ/Â≠§Á´ãË≥áÊñôÈõÜ‰∏äË®≠Ë®à„ÄÅË®ìÁ∑¥ÂíåË©ï‰º∞ÁöÑ„ÄÇÈÄèÈÅéÈÄôÈ†ÖÁ†îÁ©∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊÑüÊ∏¨Âô®ËûçÂêàÊñπÊ≥ïÔºåÁî®ÊñºË©ï‰º∞ÂùêÁ´ã‰∏çÂÆâÁöÑÂãï‰Ωú (FM)Ôºå‰∏¶ÊØîËºÉ‰∏âÁ®Æ‰∏çÂêåÁöÑÊÑüÊ∏¨Âô®Ê®°ÂºèÔºàÂ£ìÂäõ„ÄÅÊÖ£ÊÄßÂíåË¶ñË¶∫ÊÑüÊ∏¨Âô®Ôºâ„ÄÇÊ∏¨Ë©¶‰∫ÜÂêÑÁ®ÆÁµÑÂêàÂíåÂÖ©Á®ÆÊÑüÊ∏¨Âô®ËûçÂêàÊñπÊ≥ïÔºàÂæåËûçÂêàÂíåÊó©ËûçÂêàÔºâÔºåÁî®ÊñºÂ¨∞ÂÖíÂãï‰ΩúÂàÜÈ°ûÔºå‰ª•Ë©ï‰º∞Â§öÊÑüÊ∏¨Âô®Á≥ªÁµ±ÊòØÂê¶ÂÑ™ÊñºÂñÆ‰∏ÄÊ®°ÂºèË©ï‰º∞„ÄÇ‰∏âÊÑüÊ∏¨Âô®ËûçÂêàÁöÑÊïàËÉΩÔºàÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 94.5%ÔºâÈ°ØËëóÈ´òÊñºË©ï‰º∞ÁöÑ‰ªª‰ΩïÂñÆ‰∏ÄÊ®°ÂºèÔºåÈÄôË°®Á§∫ÊÑüÊ∏¨Âô®ËûçÂêàÊñπÊ≥ïÊòØËá™ÂãïÂåñÂàÜÈ°ûÂ¨∞ÂÖíÂãï‰ΩúÊ®°ÂºèÁöÑ‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇÂÅ•ÂÖ®ÁöÑÊÑüÊ∏¨Âô®ËûçÂêàÁ≥ªÁµ±ÁöÑÁôºÂ±ïÂèØËÉΩÊúÉÈ°ØËëóÊèêÂçáÂü∫Êñº‰∫∫Â∑•Êô∫ÊÖßÁöÑÊó©ÊúüÁ•ûÁ∂ìÂäüËÉΩËæ®Ë≠òÔºåÊúÄÁµÇ‰øÉÈÄ≤Á•ûÁ∂ìÁôºÂ±ïÁãÄÊ≥ÅÁöÑËá™ÂãïÂåñÊó©ÊúüÂÅµÊ∏¨„ÄÇ

##### **Efficient Multi-View Fusion and Flexible Adaptation to View Missing in Cardiovascular System Signals**
2406.08930v1 by Qihan Hu, Daomiao Wang, Hong Wu, Jian Liu, Cuiwei Yang

The progression of deep learning and the widespread adoption of sensors have
facilitated automatic multi-view fusion (MVF) about the cardiovascular system
(CVS) signals. However, prevalent MVF model architecture often amalgamates CVS
signals from the same temporal step but different views into a unified
representation, disregarding the asynchronous nature of cardiovascular events
and the inherent heterogeneity across views, leading to catastrophic view
confusion. Efficient training strategies specifically tailored for MVF models
to attain comprehensive representations need simultaneous consideration.
Crucially, real-world data frequently arrives with incomplete views, an aspect
rarely noticed by researchers. Thus, the View-Centric Transformer (VCT) and
Multitask Masked Autoencoder (M2AE) are specifically designed to emphasize the
centrality of each view and harness unlabeled data to achieve superior fused
representations. Additionally, we systematically define the missing-view
problem for the first time and introduce prompt techniques to aid pretrained
MVF models in flexibly adapting to various missing-view scenarios. Rigorous
experiments involving atrial fibrillation detection, blood pressure estimation,
and sleep staging-typical health monitoring tasks-demonstrate the remarkable
advantage of our method in MVF compared to prevailing methodologies. Notably,
the prompt technique requires finetuning less than 3% of the entire model's
data, substantially fortifying the model's resilience to view missing while
circumventing the need for complete retraining. The results demonstrate the
effectiveness of our approaches, highlighting their potential for practical
applications in cardiovascular health monitoring. Codes and models are released
at URL.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈÄ≤Â±ïÂíåÊÑüÊ∏¨Âô®ÁöÑÂª£Ê≥õÊé°Áî®Ôºå‰øÉÈÄ≤‰∫ÜÂøÉË°ÄÁÆ°Á≥ªÁµ± (CVS) Ë®äËôüÁöÑËá™ÂãïÂ§öË¶ñËßíËûçÂêà (MVF)„ÄÇÁÑ∂ËÄåÔºåÊôÆÈÅçÁöÑ MVF Ê®°ÂûãÊû∂ÊßãÁ∂ìÂ∏∏Â∞á‰æÜËá™Áõ∏ÂêåÊôÇÈñìÊ≠•È©ü‰ΩÜ‰∏çÂêåË¶ñËßíÁöÑ CVS Ë®äËôüËûçÂêàÁÇ∫Áµ±‰∏ÄÁöÑË°®Á§∫ÔºåÂøΩË¶ñ‰∫ÜÂøÉË°ÄÁÆ°‰∫ã‰ª∂ÁöÑÈùûÂêåÊ≠•ÊÄßË≥™ÂíåË¶ñËßí‰πãÈñìÁöÑÂÖßÂú®Áï∞Ë≥™ÊÄßÔºåÂ∞éËá¥ÁÅΩÈõ£ÊÄßÁöÑË¶ñËßíÊ∑∑Ê∑Ü„ÄÇÈúÄË¶ÅÂêåÊôÇËÄÉÊÖÆÂ∞àÈñÄÈáùÂ∞ç MVF Ê®°ÂûãÈáèË∫´ÊâìÈÄ†ÁöÑÊúâÊïàË®ìÁ∑¥Á≠ñÁï•Ôºå‰ª•Áç≤ÂæóÂÖ®Èù¢ÁöÑË°®Á§∫„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÁúüÂØ¶‰∏ñÁïåÁöÑË≥áÊñôÁ∂ìÂ∏∏ÊúÉÂá∫Áèæ‰∏çÂÆåÊï¥ÁöÑË¶ñËßíÔºåÁ†îÁ©∂‰∫∫Âì°ÂæàÂ∞ëÊ≥®ÊÑèÂà∞ÈÄôÂÄãÈù¢Âêë„ÄÇÂõ†Ê≠§ÔºåË¶ñËßí‰∏≠ÂøÉTransformer (VCT) ÂíåÂ§ö‰ªªÂãôÈÅÆÁΩ©ÂºèËá™ÂãïÁ∑®Á¢ºÂô® (M2AE) Ë¢´ÁâπÂà•Ë®≠Ë®àÁÇ∫Âº∑Ë™øÊØèÂÄãË¶ñËßíÁöÑ‰∏≠ÂøÉÊÄßÔºå‰∏¶Âà©Áî®Êú™Ê®ôË®òÁöÑË≥áÊñô‰æÜÂØ¶ÁèæÂÑ™Ë∂äÁöÑËûçÂêàË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞È¶ñÊ¨°ÂÆöÁæ©‰∫ÜÁº∫Â§±Ë¶ñËßíÂïèÈ°åÔºå‰∏¶ÂºïÂÖ•‰∫ÜÊèêÁ§∫ÊäÄË°ìÔºå‰ª•Âπ´Âä©È†êË®ìÁ∑¥ÁöÑ MVF Ê®°ÂûãÈùàÊ¥ªÈÅ©ÊáâÂêÑÁ®ÆÁº∫Â§±Ë¶ñËßíÂ†¥ÊôØ„ÄÇÊ∂âÂèäÂøÉÊàøÈ°´ÂãïÂÅµÊ∏¨„ÄÅË°ÄÂ£ì‰º∞Ë®àÂíåÁù°Áú†ÂàÜÊúüÁöÑÂö¥Ë¨πÂØ¶È©óÔºàÂÖ∏ÂûãÁöÑÂÅ•Â∫∑Áõ£Ê∏¨‰ªªÂãôÔºâË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú® MVF ‰∏≠ËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÂÖ∑ÊúâÈ°ØËëóÂÑ™Âã¢„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊèêÁ§∫ÊäÄË°ìÈúÄË¶ÅÂæÆË™ø‰∏çÂà∞Êï¥ÂÄãÊ®°ÂûãË≥áÊñôÁöÑ 3%ÔºåÈÄôÂ§ßÂ§ßÂä†Âº∑‰∫ÜÊ®°ÂûãÂ∞çË¶ñËßíÁº∫Â§±ÁöÑÂæ©ÂéüÂäõÔºåÂêåÊôÇÈÅøÂÖç‰∫ÜÈáçÊñ∞Ë®ìÁ∑¥ÁöÑÈúÄË¶Å„ÄÇÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÁ™ÅÂá∫‰∫ÜÂÆÉÂÄëÂú®ÂøÉË°ÄÁÆ°ÂÅ•Â∫∑Áõ£Ê∏¨‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®ÊΩõÂäõ„ÄÇÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂ∑≤Âú® URL ‰∏≠ÁôºÂ∏É„ÄÇ

##### **Computer Vision Approaches for Automated Bee Counting Application**
2406.08898v1 by Simon Bilik, Ilona Janakova, Adam Ligocki, Dominik Ficek, Karel Horak

Many application from the bee colony health state monitoring could be
efficiently solved using a computer vision techniques. One of such challenges
is an efficient way for counting the number of incoming and outcoming bees,
which could be used to further analyse many trends, such as the bee colony
health state, blooming periods, or for investigating the effects of
agricultural spraying. In this paper, we compare three methods for the
automated bee counting over two own datasets. The best performing method is
based on the ResNet-50 convolutional neural network classifier, which achieved
accuracy of 87% over the BUT1 dataset and the accuracy of 93% over the BUT2
dataset.

ÊëòË¶ÅÔºöË®±Â§öÊáâÁî®Á®ãÂºèÂæûËúúËúÇÁæ§È´îÂÅ•Â∫∑ÁãÄÊÖãÁõ£Êéß‰∏≠ÔºåËÉΩÊúâÊïàÁéáÂú∞‰ΩøÁî®ÈõªËÖ¶Ë¶ñË¶∫ÊäÄË°ìËß£Ê±∫„ÄÇÂÖ∂‰∏≠‰∏ÄÂÄãÊåëÊà∞ÊòØÊúâÊïàÁéáÂú∞Ë®àÁÆóÈÄ≤Âá∫ËúÇÁæ§ÁöÑÊï∏ÈáèÔºåÈÄôËÉΩÁî®‰æÜÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêË®±Â§öË∂®Âã¢Ôºå‰æãÂ¶ÇËúúËúÇÁæ§È´îÂÅ•Â∫∑ÁãÄÊÖã„ÄÅÈñãËä±ÊúüÔºåÊàñÁî®ÊñºË™øÊü•Ëæ≤Ê•≠Âô¥ÁÅëÁöÑÂΩ±Èüø„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∫Ü‰∏âÂÄãËá™ÂãïÂåñË®àÁÆóËúúËúÇÊï∏ÈáèÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®ÂÖ©ÂÄãÊàëÂÄëËá™Â∑±ÁöÑË≥áÊñôÈõÜ„ÄÇË°®ÁèæÊúÄÂ•ΩÁöÑÊñπÊ≥ïÊòØÂü∫Êñº ResNet-50 Êç≤Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÂàÜÈ°ûÂô®ÔºåÂú® BUT1 Ë≥áÊñôÈõÜ‰∏äÈÅîÂà∞ 87% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂú® BUT2 Ë≥áÊñôÈõÜ‰∏äÈÅîÂà∞ 93% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Automatically Labeling $200B Life-Saving Datasets: A Large Clinical Trial Outcome Benchmark**
2406.10292v1 by Chufan Gao, Jathurshan Pradeepkumar, Trisha Das, Shivashankar Thati, Jimeng Sun

The global cost of drug discovery and development exceeds $200 billion
annually. The main results of drug discovery and development are the outcomes
of clinical trials, which directly influence the regulatory approval of new
drug candidates and ultimately affect patient outcomes. Despite their
significance, large-scale, high-quality clinical trial outcome data are not
readily available to the public. Suppose a large clinical trial outcome dataset
is provided; machine learning researchers can potentially develop accurate
prediction models using past trials and outcome labels, which could help
prioritize and optimize therapeutic programs, ultimately benefiting patients.
This paper introduces Clinical Trial Outcome (CTO) dataset, the largest trial
outcome dataset with around 479K clinical trials, aggregating outcomes from
multiple sources of weakly supervised labels, minimizing the noise from
individual sources, and eliminating the need for human annotation. These
sources include large language model (LLM) decisions on trial-related
documents, news headline sentiments, stock prices of trial sponsors, trial
linkages across phases, and other signals such as patient dropout rates and
adverse events. CTO's labels show unprecedented agreement with supervised
clinical trial outcome labels from test split of the supervised TOP dataset,
with a 91 F1.

ÊëòË¶ÅÔºöÂÖ®ÁêÉËó•Áâ©ÁôºÁèæÂíåÈñãÁôºÁöÑÊàêÊú¨ÊØèÂπ¥Ë∂ÖÈÅé 2000 ÂÑÑÁæéÂÖÉ„ÄÇËó•Áâ©ÁôºÁèæÂíåÈñãÁôºÁöÑ‰∏ªË¶ÅÊàêÊûúÊòØËá®Â∫äË©¶È©óÁöÑÁµêÊûúÔºåÂÆÉÁõ¥Êé•ÂΩ±ÈüøÊñ∞Ëó•ÂÄôÈÅ∏ËÄÖÁöÑÊ≥ïË¶èÊ†∏ÂáÜÔºå‰∏¶ÊúÄÁµÇÂΩ±ÈüøÊÇ£ËÄÖÁöÑÁµêÊûú„ÄÇÂÑòÁÆ°ÂÆÉÂÄëÂæàÈáçË¶ÅÔºå‰ΩÜÂ§ßÂûã„ÄÅÈ´òÂìÅË≥™ÁöÑËá®Â∫äË©¶È©óÁµêÊûúÊï∏Êìö‰∏¶‰∏çÂÆπÊòìËÆìÂÖ¨ÁúæÂèñÂæó„ÄÇÂÅáË®≠Êèê‰æõ‰∫ÜÂ§ßÂûãËá®Â∫äË©¶È©óÁµêÊûúÊï∏ÊìöÈõÜÔºõÊ©üÂô®Â≠∏ÁøíÁ†îÁ©∂‰∫∫Âì°ÊúâÂèØËÉΩ‰ΩøÁî®ÈÅéÂéªÁöÑË©¶È©óÂíåÁµêÊûúÊ®ôÁ±§ÈñãÁôºÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÈÄôÊúâÂä©ÊñºÂÑ™ÂÖàËÄÉÊÖÆÂíåÊúÄ‰Ω≥ÂåñÊ≤ªÁôÇË®àÁï´ÔºåÊúÄÁµÇ‰ΩøÊÇ£ËÄÖÂèóÁõä„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫ÜËá®Â∫äË©¶È©óÁµêÊûú (CTO) Êï∏ÊìöÈõÜÔºåÈÄôÊòØÊúÄÂ§ßÁöÑË©¶È©óÁµêÊûúÊï∏ÊìöÈõÜÔºåÂåÖÂê´Á¥Ñ 479K ÂÄãËá®Â∫äË©¶È©óÔºåÂΩôÁ∏Ω‰∫Ü‰æÜËá™Â§öÂÄã‰æÜÊ∫êÁöÑÂº±Áõ£Áù£Ê®ôÁ±§ÁöÑÁµêÊûúÔºåÊúÄÂ§ßÈôêÂ∫¶Âú∞Ê∏õÂ∞ë‰∫Ü‰æÜËá™ÂÄãÂà•‰æÜÊ∫êÁöÑÈõúË®äÔºå‰∏¶Ê∂àÈô§‰∫Ü‰∫∫Â∑•Ë®ªËß£ÁöÑÈúÄË¶Å„ÄÇÈÄô‰∫õ‰æÜÊ∫êÂåÖÊã¨Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞çË©¶È©óÁõ∏ÈóúÊñá‰ª∂ÁöÑÊ±∫ÂÆö„ÄÅÊñ∞ËÅûÊ®ôÈ°åÊÉÖÁ∑í„ÄÅË©¶È©óË¥äÂä©ÂïÜÁöÑËÇ°Á•®ÂÉπÊ†º„ÄÅË∑®ÈöéÊÆµË©¶È©óÈÄ£ÁµêÔºå‰ª•ÂèäÂÖ∂‰ªñ‰ø°ËôüÔºå‰æãÂ¶ÇÊÇ£ËÄÖËºüÂ≠∏ÁéáÂíå‰∏çËâØ‰∫ã‰ª∂„ÄÇCTO ÁöÑÊ®ôÁ±§È°ØÁ§∫Âá∫Ëàá‰æÜËá™Áõ£Áù£Âºè TOP Êï∏ÊìöÈõÜÊ∏¨Ë©¶ÂàÜÂâ≤ÁöÑÁõ£Áù£ÂºèËá®Â∫äË©¶È©óÁµêÊûúÊ®ôÁ±§ÂâçÊâÄÊú™ÊúâÁöÑÂêªÂêàÂ∫¶ÔºåF1 ÁÇ∫ 91„ÄÇ

##### **Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory Analysis**
2406.08695v1 by Attrayee Chakraborty, Mandar Karhade

Artificial Intelligence (AI) is being adopted across the world and promises a
new revolution in healthcare. While AI-enabled medical devices in North America
dominate 42.3% of the global market, the use of AI-enabled medical devices in
other countries is still a story waiting to be unfolded. We aim to delve deeper
into global regulatory approaches towards AI use in healthcare, with a focus on
how common themes are emerging globally. We compare these themes to the World
Health Organization's (WHO) regulatory considerations and principles on ethical
use of AI for healthcare applications. Our work seeks to take a global
perspective on AI policy by analyzing 14 legal jurisdictions including
countries representative of various regions in the world (North America, South
America, South East Asia, Middle East, Africa, Australia, and the
Asia-Pacific). Our eventual goal is to foster a global conversation on the
ethical use of AI in healthcare and the regulations that will guide it. We
propose solutions to promote international harmonization of AI regulations and
examine the requirements for regulating generative AI, using China and
Singapore as examples of countries with well-developed policies in this area.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÊ≠£Âú®ÂÖ®ÁêÉËåÉÂõ¥ÂÜÖÂæóÂà∞Êé°Áî®Ôºå‰∏¶ÊâøË´æÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÊéÄËµ∑‰∏ÄÂ†¥Êñ∞ÁöÑÈù©ÂëΩ„ÄÇÂÑòÁÆ°ÂåóÁæéÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈÜ´ÁôÇË®≠ÂÇô‰∏ªÂ∞é‰∫ÜÂÖ®ÁêÉÂ∏ÇÂ†¥ÁöÑ 42.3%Ôºå‰ΩÜÂÖ∂‰ªñÂúãÂÆ∂/Âú∞ÂçÄÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈÜ´ÁôÇË®≠ÂÇôÁöÑ‰ΩøÁî®ÊÉÖÊ≥Å‰ªçÊòØ‰∏ÄÂÄãÊúâÂæÖÂ±ïÈñãÁöÑÊïÖ‰∫ã„ÄÇÊàëÂÄëÊó®Âú®Ê∑±ÂÖ•Êé¢Ë®éÂÖ®ÁêÉÂ∞çÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ AI ‰ΩøÁî®ÁöÑÊ≥ïË¶èÊñπÊ≥ïÔºåÈáçÈªûÈóúÊ≥®ÂÖ®ÁêÉÁØÑÂúçÂÖßÂ¶Ç‰ΩïÂá∫ÁèæÂÖ±ÂêåÁöÑ‰∏ªÈ°å„ÄÇÊàëÂÄëÂ∞áÈÄô‰∫õ‰∏ªÈ°åËàá‰∏ñÁïåË°õÁîüÁµÑÁπî (WHO) Â∞çÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠ AI ÈÅìÂæ∑‰ΩøÁî®ÁöÑÊ≥ïË¶èËÄÉÈáèÂíåÂéüÂâáÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êó®Âú®ÈÄöÈÅéÂàÜÊûê 14 ÂÄãÊ≥ïÂüüÔºàÂåÖÊã¨‰ª£Ë°®‰∏ñÁïåÂêÑÂú∞‰∏çÂêåÂú∞ÂçÄÁöÑÂúãÂÆ∂/Âú∞ÂçÄÔºàÂåóÁæé„ÄÅÂçóÁæé„ÄÅÊù±Âçó‰∫û„ÄÅ‰∏≠Êù±„ÄÅÈùûÊ¥≤„ÄÅÊæ≥Â§ßÂà©‰∫ûÂíå‰∫ûÂ§™Âú∞ÂçÄÔºâÔºâ‰æÜÂ∞ç AI ÊîøÁ≠ñÊé°ÂèñÂÖ®ÁêÉËßÄÈªû„ÄÇÊàëÂÄëÁöÑÊúÄÁµÇÁõÆÊ®ôÊòØ‰øÉÈÄ≤ÈóúÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ AI ÈÅìÂæ∑‰ΩøÁî®ÂíåÂ∞áÊåáÂ∞éÂÆÉÁöÑÊ≥ïË¶èÁöÑÂÖ®ÁêÉÂ∞çË©±„ÄÇÊàëÂÄëÊèêÂá∫Ëß£Ê±∫ÊñπÊ°à‰ª•‰øÉÈÄ≤ AI Ê≥ïË¶èÁöÑÂúãÈöõÂçîË™øÔºå‰∏¶‰ª•‰∏≠ÂúãÂíåÊñ∞Âä†Âù°ÁÇ∫‰æãÔºåÊé¢Ë®é‰∫ÜÂ∞çÁîüÊàêÂºè AI ÈÄ≤Ë°åÁõ£ÁÆ°ÁöÑË¶ÅÊ±ÇÔºåÈÄô‰∫õÂúãÂÆ∂/Âú∞ÂçÄÂú®ÈÄô‰∏ÄÈ†òÂüüÊìÅÊúâÂÆåÂñÑÁöÑÊîøÁ≠ñ„ÄÇ

##### **Advancing High Resolution Vision-Language Models in Biomedicine**
2406.09454v1 by Zekai Chen, Arda Pekis, Kevin Brown

Multi-modal learning has significantly advanced generative AI, especially in
vision-language modeling. Innovations like GPT-4V and open-source projects such
as LLaVA have enabled robust conversational agents capable of zero-shot task
completions. However, applying these technologies in the biomedical field
presents unique challenges. Recent initiatives like LLaVA-Med have started to
adapt instruction-tuning for biomedical contexts using large datasets such as
PMC-15M. Our research offers three key contributions: (i) we present a new
instruct dataset enriched with medical image-text pairs from Claude3-Opus and
LLaMA3 70B, (ii) we propose a novel image encoding strategy using hierarchical
representations to improve fine-grained biomedical visual comprehension, and
(iii) we develop the Llama3-Med model, which achieves state-of-the-art
zero-shot performance on biomedical visual question answering benchmarks, with
an average performance improvement of over 10% compared to previous methods.
These advancements provide more accurate and reliable tools for medical
professionals, bridging gaps in current multi-modal conversational assistants
and promoting further innovations in medical AI.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂ≠¶‰π†Â∑≤Â§ßÂπÖÊèêÂçáÁîüÊàêÂºè AIÔºåÂ∞§ÂÖ∂ÊòØÂú®ËßÜËßâËØ≠Ë®ÄÂª∫Ê®°ÊñπÈù¢„ÄÇGPT-4V Á≠âÂàõÊñ∞Âíå LLaVA Á≠âÂºÄÊ∫êÈ°πÁõÆÂ∑≤ËÆ©ÂÅ•ÂÖ®ÁöÑÂØπËØù‰ª£ÁêÜËÉΩÂ§üÂÆåÊàêÈõ∂Ê¨°Â≠¶‰π†‰ªªÂä°„ÄÇÁÑ∂ËÄåÔºåÂú®ÁîüÁâ©ÂåªÂ≠¶È¢ÜÂüüÂ∫îÁî®Ëøô‰∫õÊäÄÊúØÊèêÂá∫‰∫ÜÁã¨ÁâπÁöÑÊåëÊàò„ÄÇLLaVA-Med Á≠âËøëÊúüËÆ°ÂàíÂ∑≤ÂºÄÂßã‰ΩøÁî® PMC-15M Á≠âÂ§ßÂûãÊï∞ÊçÆÈõÜÔºå‰∏∫ÁîüÁâ©ÂåªÂ≠¶ËØ≠Â¢ÉË∞ÉÊï¥Êåá‰ª§„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂Êèê‰æõ‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆË¥°ÁåÆÔºö(i) Êàë‰ª¨Â±ïÁ§∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÊåá‰ª§Êï∞ÊçÆÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Êù•Ëá™ Claude3-Opus Âíå LLaMA3 70B ÁöÑÂåªÂ≠¶ÂõæÂÉè-ÊñáÊú¨ÂØπÔºå(ii) Êàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂõæÂÉèÁºñÁ†ÅÁ≠ñÁï•Ôºå‰ΩøÁî®ÂàÜÂ±ÇË°®Á§∫Êù•ÊîπÂñÑÁªÜÁ≤íÂ∫¶ÁöÑÁîüÁâ©ÂåªÂ≠¶ËßÜËßâÁêÜËß£Ôºå‰ª•Âèä (iii) Êàë‰ª¨ÂºÄÂèë‰∫Ü Llama3-Med Ê®°ÂûãÔºåËØ•Ê®°ÂûãÂú®ÁîüÁâ©ÂåªÂ≠¶ËßÜËßâÈóÆÁ≠îÂü∫ÂáÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÈõ∂Ê¨°Â≠¶‰π†ÊÄßËÉΩÔºå‰∏é‰πãÂâçÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂπ≥ÂùáÊÄßËÉΩÊèêÂçá‰∫Ü 10% ‰ª•‰∏ä„ÄÇËøô‰∫õËøõÊ≠•‰∏∫ÂåªÂ≠¶‰∏ì‰∏ö‰∫∫Â£´Êèê‰æõ‰∫ÜÊõ¥ÂáÜÁ°ÆÂíåÂèØÈù†ÁöÑÂ∑•ÂÖ∑ÔºåÂº•Ë°•‰∫ÜÂΩìÂâçÂ§öÊ®°ÊÄÅÂØπËØùÂä©ÁêÜ‰∏≠ÁöÑÂ∑ÆË∑ùÔºåÂπ∂‰øÉËøõ‰∫ÜÂåªÂ≠¶ AI ÁöÑËøõ‰∏ÄÊ≠•ÂàõÊñ∞„ÄÇ

##### **AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images**
2406.08425v1 by Ayush Roy, Payel Pramanik, Dmitrii Kaplun, Sergei Antonov, Ram Sarkar

Accurate nuclei segmentation in histopathological images is crucial for
cancer diagnosis. Automating this process offers valuable support to clinical
experts, as manual annotation is time-consuming and prone to human errors.
However, automating nuclei segmentation presents challenges due to uncertain
cell boundaries, intricate staining, and diverse structures. In this paper, we
present a segmentation approach that combines the U-Net architecture with a
DenseNet-121 backbone, harnessing the strengths of both to capture
comprehensive contextual and spatial information. Our model introduces the
Wavelet-guided channel attention module to enhance cell boundary delineation,
along with a learnable weighted global attention module for channel-specific
attention. The decoder module, composed of an upsample block and convolution
block, further refines segmentation in handling staining patterns. The
experimental results conducted on two publicly accessible histopathology
datasets, namely Monuseg and TNBC, underscore the superiority of our proposed
model, demonstrating its potential to advance histopathological image analysis
and cancer diagnosis. The code is made available at:
https://github.com/AyushRoy2001/AWGUNET.

ÊëòË¶ÅÔºöÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉè‰∏≠Á≤æÁ¢∫ÁöÑÁ¥∞ËÉûÊ†∏ÂàÜÂâ≤Â∞çÊñºÁôåÁóáË®∫Êñ∑Ëá≥ÈóúÈáçË¶Å„ÄÇËá™ÂãïÂåñÊ≠§Á®ãÂ∫èÂèØÁÇ∫Ëá®Â∫äÂ∞àÂÆ∂Êèê‰æõÊúâÂÉπÂÄºÁöÑÊîØÊè¥ÔºåÂõ†ÁÇ∫ÊâãÂãïË®ªËß£Êó¢ËÄóÊôÇÂèàÂÆπÊòìÁôºÁîü‰∫∫ÁÇ∫ÈåØË™§„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁ¥∞ËÉûÈÇäÁïå‰∏çÁ¢∫ÂÆö„ÄÅÊüìËâ≤Ë§áÈõú‰∏îÁµêÊßãÂ§öÊ®£ÔºåËá™ÂãïÂåñÁ¥∞ËÉûÊ†∏ÂàÜÂâ≤ÊúÉÁî¢ÁîüÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂàÜÂâ≤ÊñπÊ≥ïÔºåÂ∞á U-Net Êû∂ÊßãËàá DenseNet-121 ‰∏ªÂππÁµêÂêàÔºåÂà©Áî®ÂÖ©ËÄÖÁöÑÂÑ™Âã¢‰æÜÊì∑ÂèñÂÖ®Èù¢ÁöÑ‰∏ä‰∏ãÊñáÂíåÁ©∫ÈñìË≥áË®ä„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂºïÂÖ•‰∫ÜÂ∞èÊ≥¢Â∞éÂêëÈÄöÈÅìÊ≥®ÊÑèÊ®°ÁµÑÔºå‰ª•Â¢ûÂº∑Á¥∞ËÉûÈÇäÁïåÁöÑÊèèÁπ™Ôºå‰ª•Âèä‰∏ÄÂÄãÂèØÂ≠∏ÁøíÁöÑÂä†Ê¨äÂÖ®Â±ÄÊ≥®ÊÑèÊ®°ÁµÑÔºåÁî®ÊñºÁâπÂÆöÈÄöÈÅìÁöÑÊ≥®ÊÑè„ÄÇËß£Á¢ºÂô®Ê®°ÁµÑÁî±‰∏äÊé°Ê®£ÂçÄÂ°äÂíåÂç∑Á©çÂçÄÂ°äÁµÑÊàêÔºåÈÄ≤‰∏ÄÊ≠•ÂÑ™Âåñ‰∫ÜËôïÁêÜÊüìËâ≤Ê®°ÂºèÁöÑÂàÜÂâ≤„ÄÇÂú®ÂÖ©ÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑÁµÑÁπîÁóÖÁêÜÂ≠∏Ë≥áÊñôÈõÜÔºàÂç≥ Monuseg Âíå TNBCÔºâ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÁµêÊûúÔºåÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÁöÑÂÑ™Ë∂äÊÄßÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Êé®ÈÄ≤ÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉèÂàÜÊûêÂíåÁôåÁóáË®∫Êñ∑ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆÂèñÂæóÔºöhttps://github.com/AyushRoy2001/AWGUNET„ÄÇ

##### **2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction**
2406.08374v2 by Tianqi Chen, Jun Hou, Yinchi Zhou, Huidong Xie, Xiongchao Chen, Qiong Liu, Xueqi Guo, Menghua Xia, James S. Duncan, Chi Liu, Bo Zhou

Positron Emission Tomography (PET) is an important clinical imaging tool but
inevitably introduces radiation hazards to patients and healthcare providers.
Reducing the tracer injection dose and eliminating the CT acquisition for
attenuation correction can reduce the overall radiation dose, but often results
in PET with high noise and bias. Thus, it is desirable to develop 3D methods to
translate the non-attenuation-corrected low-dose PET (NAC-LDPET) into
attenuation-corrected standard-dose PET (AC-SDPET). Recently, diffusion models
have emerged as a new state-of-the-art deep learning method for image-to-image
translation, better than traditional CNN-based methods. However, due to the
high computation cost and memory burden, it is largely limited to 2D
applications. To address these challenges, we developed a novel 2.5D Multi-view
Averaging Diffusion Model (MADM) for 3D image-to-image translation with
application on NAC-LDPET to AC-SDPET translation. Specifically, MADM employs
separate diffusion models for axial, coronal, and sagittal views, whose outputs
are averaged in each sampling step to ensure the 3D generation quality from
multiple views. To accelerate the 3D sampling process, we also proposed a
strategy to use the CNN-based 3D generation as a prior for the diffusion model.
Our experimental results on human patient studies suggested that MADM can
generate high-quality 3D translation images, outperforming previous CNN-based
and Diffusion-based baseline methods.

ÊëòË¶ÅÔºöÊ≠£Â≠êÁôºÂ∞ÑÊñ∑Â±§ÊîùÂΩ± (PET) ÊòØ‰∏ÄÁ®ÆÈáçË¶ÅÁöÑËá®Â∫äÂΩ±ÂÉèÂ∑•ÂÖ∑Ôºå‰ΩÜ‰∏çÂèØÈÅøÂÖçÂú∞ÊúÉÂ∞çÊÇ£ËÄÖÂíåÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖÈÄ†ÊàêËºªÂ∞ÑÂç±ÂÆ≥„ÄÇÈôç‰ΩéÁ§∫Ëπ§ÂäëÊ≥®Â∞ÑÂäëÈáè‰∏¶Ê∂àÈô§Ë°∞Ê∏õÊ†°Ê≠£ÁöÑ CT Êé°ÈõÜÂèØ‰ª•Èôç‰ΩéÊï¥È´îËºªÂ∞ÑÂäëÈáèÔºå‰ΩÜÈÄöÂ∏∏ÊúÉÂ∞éËá¥ PET ÈõúË®äÂíåÂÅèÂ∑ÆÈÅéÈ´ò„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶ÅÈñãÁôº 3D ÊñπÊ≥ïÔºåÂ∞áÈùûË°∞Ê∏õÊ†°Ê≠£‰ΩéÂäëÈáè PET (NAC-LDPET) ËΩâÊèõÁÇ∫Ë°∞Ê∏õÊ†°Ê≠£Ê®ôÊ∫ñÂäëÈáè PET (AC-SDPET)„ÄÇÊúÄËøëÔºåÊì¥Êï£Ê®°ÂûãÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊñ∞ÁöÑÊúÄÂÖàÈÄ≤Ê∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÁî®ÊñºÂΩ±ÂÉèÂà∞ÂΩ±ÂÉèËΩâÊèõÔºåÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÂü∫Êñº CNN ÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈÅãÁÆóÊàêÊú¨ÂíåË®òÊÜ∂È´îË≤†ÊìîÈÅéÈ´òÔºåÂÆÉÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂÉÖÈôêÊñº 2D ÊáâÁî®„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ 2.5D Â§öË¶ñÂúñÂπ≥ÂùáÊì¥Êï£Ê®°Âûã (MADM)ÔºåÁî®Êñº 3D ÂΩ±ÂÉèÂà∞ÂΩ±ÂÉèËΩâÊèõÔºå‰∏¶ÊáâÁî®Êñº NAC-LDPET Âà∞ AC-SDPET ÁöÑËΩâÊèõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåMADM Â∞çËª∏Âêë„ÄÅÂÜ†ÁãÄÂíåÁü¢ÁãÄË¶ñÂúñÊé°Áî®‰∫ÜÂñÆÁç®ÁöÑÊì¥Êï£Ê®°ÂûãÔºåÂÖ∂Ëº∏Âá∫Âú®ÊØèÂÄãÊé°Ê®£Ê≠•È©ü‰∏≠ÂèñÂπ≥ÂùáÂÄºÔºå‰ª•Á¢∫‰øùÂæûÂ§öÂÄãË¶ñÂúñÁîüÊàê 3D ÁöÑÂìÅË≥™„ÄÇÁÇ∫‰∫ÜÂä†ÈÄü 3D Êé°Ê®£ÈÅéÁ®ãÔºåÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ≠ñÁï•Ôºå‰ΩøÁî®Âü∫Êñº CNN ÁöÑ 3D ÁîüÊàê‰ΩúÁÇ∫Êì¥Êï£Ê®°ÂûãÁöÑÂÖàÈ©ó„ÄÇÊàëÂÄëÂú®‰∫∫È´îÊÇ£ËÄÖÁ†îÁ©∂‰∏≠ÈÄ≤Ë°åÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåMADM ÂèØ‰ª•ÁîüÊàêÈ´òÂìÅË≥™ÁöÑ 3D ËΩâÊèõÂΩ±ÂÉèÔºåÂÑ™ÊñºÂÖàÂâçÁöÑÂü∫Êñº CNN ÂíåÂü∫ÊñºÊì¥Êï£ÁöÑÂü∫Ê∫ñÊñπÊ≥ï„ÄÇ

##### **Making AI Intelligible: Philosophical Foundations**
2406.08134v1 by Herman Cappelen, Josh Dever

Can humans and artificial intelligences share concepts and communicate?
'Making AI Intelligible' shows that philosophical work on the metaphysics of
meaning can help answer these questions. Herman Cappelen and Josh Dever use the
externalist tradition in philosophy to create models of how AIs and humans can
understand each other. In doing so, they illustrate ways in which that
philosophical tradition can be improved.
  The questions addressed in the book are not only theoretically interesting,
but the answers have pressing practical implications. Many important decisions
about human life are now influenced by AI. In giving that power to AI, we
presuppose that AIs can track features of the world that we care about (for
example, creditworthiness, recidivism, cancer, and combatants). If AIs can
share our concepts, that will go some way towards justifying this reliance on
AI. This ground-breaking study offers insight into how to take some first steps
towards achieving Interpretable AI.

ÊëòË¶ÅÔºö‰∫∫È°ûËàá‰∫∫Â∑•Êô∫ÊÖßËÉΩÂÖ±‰∫´Ê¶ÇÂøµ‰∏¶Ê∫ùÈÄöÂóéÔºü
„ÄåËÆì‰∫∫Â∑•Êô∫ÊÖßÊòìÊñºÁêÜËß£„Äç‰∏ÄÊõ∏Ë°®ÊòéÔºåÈóúÊñºÊÑèÁæ©ÁöÑÂΩ¢‰∏äÂ≠∏Âì≤Â≠∏Ëëó‰ΩúÊúâÂä©ÊñºÂõûÁ≠îÈÄô‰∫õÂïèÈ°å„ÄÇËµ´ÁàæÊõº¬∑Âç°‰Ω©ÂÄ´ÂíåÂñ¨Â∏å¬∑Âæ∑ÂºóÂà©Áî®Âì≤Â≠∏‰∏≠ÁöÑÂ§ñÂú®‰∏ªÁæ©ÂÇ≥Áµ±ÔºåÂª∫Á´ã‰∫ÜÈóúÊñº‰∫∫Â∑•Êô∫ÊÖßÂíå‰∫∫È°ûÂ¶Ç‰ΩïÁêÜËß£ÂΩºÊ≠§ÁöÑÊ®°Âûã„ÄÇÂú®ÈÄôÊ®£ÂÅöÁöÑÈÅéÁ®ã‰∏≠Ôºå‰ªñÂÄëË™™Êòé‰∫ÜÂì≤Â≠∏ÂÇ≥Áµ±ÂèØ‰ª•ÂæóÂà∞ÊîπÂñÑÁöÑÊñπÂºè„ÄÇ
Êõ∏‰∏≠Êé¢Ë®éÁöÑÂïèÈ°å‰∏çÂÉÖÂú®ÁêÜË´ñ‰∏äÂæàÊúâË∂£ÔºåËÄå‰∏îÁ≠îÊ°àÂÖ∑ÊúâËø´ÂàáÁöÑÂØ¶ÈöõÊÑèÁæ©„ÄÇË®±Â§öÈóúÊñº‰∫∫È°ûÁîüÊ¥ªÁöÑÈáçË¶ÅÊ±∫ÂÆöÁèæÂú®ÈÉΩÂèóÂà∞‰∫∫Â∑•Êô∫ÊÖßÁöÑÂΩ±Èüø„ÄÇÂú®Â∞áÈÄôÁ®ÆÂäõÈáèË≥¶‰∫à‰∫∫Â∑•Êô∫ÊÖßÊôÇÔºåÊàëÂÄëÈ†êË®≠‰∫∫Â∑•Êô∫ÊÖßÂèØ‰ª•ËøΩËπ§ÊàëÂÄëÈóúÂøÉÁöÑ‰∏ñÁïåÁâπÂæµÔºà‰æãÂ¶ÇÔºå‰ø°Áî®Ë©ïÂàÜ„ÄÅÁ¥ØÁäØÁéá„ÄÅÁôåÁóáÂíåÊà∞È¨•‰∫∫Âì°Ôºâ„ÄÇÂ¶ÇÊûú‰∫∫Â∑•Êô∫ÊÖßËÉΩÂÖ±‰∫´ÊàëÂÄëÁöÑÊ¶ÇÂøµÔºåÈÄôÂ∞áÊúâÂä©ÊñºË≠âÊòé‰æùË≥¥‰∫∫Â∑•Êô∫ÊÖßÁöÑÂêàÁêÜÊÄß„ÄÇÈÄôÈ†ÖÈñãÂâµÊÄßÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÂ¶Ç‰ΩïÊé°Âèñ‰∏Ä‰∫õÁ¨¨‰∏ÄÊ≠•‰æÜÂØ¶ÁèæÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÁöÑË¶ãËß£„ÄÇ

##### **Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks**
2406.07917v1 by Peizhi Niu, Chao Pan, Siheng Chen, Olgica Milenkovic

Graph neural networks (GNNs) have become instrumental in diverse real-world
applications, offering powerful graph learning capabilities for tasks such as
social networks and medical data analysis. Despite their successes, GNNs are
vulnerable to adversarial attacks, including membership inference attacks
(MIA), which threaten privacy by identifying whether a record was part of the
model's training data. While existing research has explored MIA in GNNs under
graph inductive learning settings, the more common and challenging graph
transductive learning setting remains understudied in this context. This paper
addresses this gap and proposes an effective two-stage defense, Graph
Transductive Defense (GTD), tailored to graph transductive learning
characteristics. The gist of our approach is a combination of a train-test
alternate training schedule and flattening strategy, which successfully reduces
the difference between the training and testing loss distributions. Extensive
empirical results demonstrate the superior performance of our method (a
decrease in attack AUROC by $9.42\%$ and an increase in utility performance by
$18.08\%$ on average compared to LBP), highlighting its potential for seamless
integration into various classification models with minimal overhead.

ÊëòË¶ÅÔºöÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Â∑≤ÊàêÁÇ∫ÂêÑÁ®ÆÁúüÂØ¶‰∏ñÁïåÊáâÁî®‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÁÇ∫Á§æ‰∫§Á∂≤Ë∑ØÂíåÈÜ´ÁôÇÊï∏ÊìöÂàÜÊûêÁ≠â‰ªªÂãôÊèê‰æõÂº∑Â§ßÁöÑÂúñÂΩ¢Â≠∏ÁøíËÉΩÂäõ„ÄÇÂÑòÁÆ°ÂèñÂæóÊàêÂäüÔºåGNN ‰ªçÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìäÔºåÂåÖÊã¨ÊàêÂì°Êé®Ë´ñÊîªÊìä (MIA)ÔºåÈÄôÊúÉÈÄèÈÅéËæ®Ë≠òË®òÈåÑÊòØÂê¶ÁÇ∫Ê®°ÂûãË®ìÁ∑¥Ë≥áÊñôÁöÑ‰∏ÄÈÉ®ÂàÜ‰æÜÂ®ÅËÑÖÈö±ÁßÅ„ÄÇÈõñÁÑ∂ÁèæÊúâÁ†îÁ©∂Â∑≤Êé¢Ë®éÂúñÂΩ¢Ê≠∏Á¥çÂ≠∏ÁøíË®≠ÂÆö‰∏ãÁöÑ GNN ‰∏≠ÁöÑ MIAÔºå‰ΩÜÊõ¥Â∏∏Ë¶ã‰∏îÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÁöÑÂúñÂΩ¢ËΩâÂ∞éÂ≠∏ÁøíË®≠ÂÆöÂú®Ê≠§ËÉåÊôØ‰∏ã‰ªçÊú™Áç≤ÂæóÂÖÖÂàÜÁ†îÁ©∂„ÄÇÊú¨ÊñáÊé¢Ë®éÊ≠§Â∑ÆË∑ùÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÊúâÊïàÁöÑÂàÜÂÖ©ÈöéÊÆµÈò≤Á¶¶Ê©üÂà∂ÔºåÂúñÂΩ¢ËΩâÂ∞éÈò≤Á¶¶ (GTD)ÔºåÂ∞àÈñÄÈáùÂ∞çÂúñÂΩ¢ËΩâÂ∞éÂ≠∏ÁøíÁâπÊÄßÈáèË∫´ÊâìÈÄ†„ÄÇÊàëÂÄëÊñπÊ≥ïÁöÑË¶ÅÈªûÊòØÁµêÂêàË®ìÁ∑¥Ê∏¨Ë©¶‰∫§ÊõøË®ìÁ∑¥ÊôÇÁ®ãÂíåÊâÅÂπ≥ÂåñÁ≠ñÁï•ÔºåÊàêÂäüÁ∏ÆÂ∞èË®ìÁ∑¥ÂíåÊ∏¨Ë©¶ÊêçÂ§±ÂàÜ‰Ωà‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÂª£Ê≥õÁöÑÂØ¶Ë≠âÁµêÊûúË≠âÊòéÊàëÂÄëÊñπÊ≥ïÁöÑÂÑ™Áï∞ÊïàËÉΩÔºàËàá LBP Áõ∏ÊØîÔºåÊîªÊìä AUROC Ê∏õÂ∞ë 9.42%ÔºåÊïàÁî®ÊïàËÉΩÂπ≥ÂùáÂ¢ûÂä† 18.08%ÔºâÔºåÁ™ÅÈ°ØÂÖ∂Âú®ÂêÑÁ®ÆÂàÜÈ°ûÊ®°Âûã‰∏≠ÁÑ°Á∏´Êï¥ÂêàÁöÑÊΩõÂäõÔºå‰∏îÈñãÈä∑Ê•µÂ∞è„ÄÇ

##### **Beyond Words: On Large Language Models Actionability in Mission-Critical Risk Analysis**
2406.10273v1 by Matteo Esposito, Francesco Palagiano, Valentina Lenarduzzi

Context. Risk analysis assesses potential risks in specific scenarios. Risk
analysis principles are context-less; the same methodology can be applied to a
risk connected to health and information technology security. Risk analysis
requires a vast knowledge of national and international regulations and
standards and is time and effort-intensive. A large language model can quickly
summarize information in less time than a human and can be fine-tuned to
specific tasks. Aim. Our empirical study aims to investigate the effectiveness
of Retrieval-Augmented Generation and fine-tuned LLM in Risk analysis. To our
knowledge, no prior study has explored its capabilities in risk analysis.
Method. We manually curated \totalscenarios unique scenarios leading to
\totalsamples representative samples from over 50 mission-critical analyses
archived by the industrial context team in the last five years. We compared the
base GPT-3.5 and GPT-4 models versus their Retrieval-Augmented Generation and
fine-tuned counterparts. We employ two human experts as competitors of the
models and three other three human experts to review the models and the former
human expert's analysis. The reviewers analyzed 5,000 scenario analyses.
Results and Conclusions. HEs demonstrated higher accuracy, but LLMs are quicker
and more actionable. Moreover, our findings show that RAG-assisted LLMs have
the lowest hallucination rates, effectively uncovering hidden risks and
complementing human expertise. Thus, the choice of model depends on specific
needs, with FTMs for accuracy, RAG for hidden risks discovery, and base models
for comprehensiveness and actionability. Therefore, experts can leverage LLMs
for an effective complementing companion in risk analysis within a condensed
timeframe. They can also save costs by averting unnecessary expenses associated
with implementing unwarranted countermeasures.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØ„ÄÇÈ¢®Èö™ÂàÜÊûêË©ï‰º∞ÁâπÂÆöÊÉÖÂ¢É‰∏≠ÁöÑÊΩõÂú®È¢®Èö™„ÄÇÈ¢®Èö™ÂàÜÊûêÂéüÂâáËàáÊÉÖÂ¢ÉÁÑ°ÈóúÔºõÁõ∏ÂêåÁöÑÂàÜÊûêÊñπÊ≥ïÂèØ‰ª•ÊáâÁî®ÊñºËàáÂÅ•Â∫∑ÂíåË≥áË®äÊäÄË°ìÂÆâÂÖ®Áõ∏ÈóúÁöÑÈ¢®Èö™„ÄÇÈ¢®Èö™ÂàÜÊûêÈúÄË¶ÅÂÖ∑ÂÇôÂª£Ê≥õÁöÑÂúãÂÆ∂ÂíåÂúãÈöõÊ≥ïË¶èÂèäÊ®ôÊ∫ñÁü•Ë≠òÔºåËÄå‰∏îÈúÄË¶ÅËÄóË≤ªÂ§ßÈáèÊôÇÈñìÂíåÁ≤æÂäõ„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂèØ‰ª•Âú®ÊØî‰∫∫È°ûÊõ¥Áü≠ÁöÑÊôÇÈñìÂÖßÂø´ÈÄüÊëòË¶ÅË≥áË®äÔºå‰∏¶‰∏îÂèØ‰ª•ÈáùÂ∞çÁâπÂÆö‰ªªÂãôÈÄ≤Ë°åÂæÆË™ø„ÄÇÁõÆÊ®ô„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁ†îÁ©∂Êó®Âú®Êé¢Ë®éÊ™¢Á¥¢Â¢ûÂº∑ÂºèÁîüÊàêÂíåÂæÆË™ø LLM Âú®È¢®Èö™ÂàÜÊûê‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÊ≤íÊúâÂÖàÂâçÁöÑÁ†îÁ©∂Êé¢Ë®éÂÖ∂Âú®È¢®Èö™ÂàÜÊûê‰∏≠ÁöÑËÉΩÂäõ„ÄÇÊñπÊ≥ï„ÄÇÊàëÂÄëÊâãÂãïÁ≠ñÂäÉ‰∫Ü \totalscenarios ÂÄãÂ∞éËá¥ \totalsamples ÂÄã‰ª£Ë°®ÊÄßÊ®£Êú¨ÁöÑÁç®ÁâπÊÉÖÂ¢ÉÔºåÈÄô‰∫õÊ®£Êú¨‰æÜËá™Áî¢Ê•≠ÊÉÖÂ¢ÉÂ∞èÁµÑÂú®ÈÅéÂéª‰∫îÂπ¥‰∏≠Ê≠∏Ê™îÁöÑ 50 Â§öÈ†Ö‰ªªÂãôÈóúÈçµÂàÜÊûê„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÂü∫Êú¨ GPT-3.5 Âíå GPT-4 Ê®°ÂûãËàáÂÖ∂Ê™¢Á¥¢Â¢ûÂº∑ÂºèÁîüÊàêÂíåÂæÆË™øÁöÑÂ∞çÊáâÊ®°Âûã„ÄÇÊàëÂÄëËÅòË´ãÂÖ©‰Ωç‰∫∫È°ûÂ∞àÂÆ∂‰ΩúÁÇ∫Ê®°ÂûãÁöÑÁ´∂Áà≠ËÄÖÔºå‰∏¶ËÅòË´ãÂè¶Â§ñ‰∏â‰Ωç‰∫∫È°ûÂ∞àÂÆ∂‰æÜÂØ©Êü•Ê®°ÂûãÂíåÂâç‰∏Ä‰Ωç‰∫∫È°ûÂ∞àÂÆ∂ÁöÑÂàÜÊûê„ÄÇÂØ©Êü•‰∫∫Âì°ÂàÜÊûê‰∫Ü 5,000 ÂÄãÊÉÖÂ¢ÉÂàÜÊûê„ÄÇÁµêÊûúÂíåÁµêË´ñ„ÄÇ‰∫∫È°ûÂ∞àÂÆ∂Â±ïÁèæÂá∫ËºÉÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰ΩÜ LLM ËºÉÂø´‰∏îÊõ¥ÂÖ∑ÂèØÊìç‰ΩúÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåRAG ËºîÂä©ÁöÑ LLM ÂÖ∑ÊúâÊúÄ‰ΩéÁöÑÂπªË¶∫ÁéáÔºåËÉΩÊúâÊïàÊè≠Èú≤Èö±ËóèÈ¢®Èö™‰∏¶Ë£úÂÖÖ‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÂõ†Ê≠§ÔºåÊ®°ÂûãÁöÑÈÅ∏ÊìáÂèñÊ±∫ÊñºÁâπÂÆöÈúÄÊ±ÇÔºåFTM ÈÅ©Áî®ÊñºÊ∫ñÁ¢∫ÊÄßÔºåRAG ÈÅ©Áî®ÊñºÈö±ËóèÈ¢®Èö™ÁôºÁèæÔºåËÄåÂü∫Êú¨Ê®°ÂûãÈÅ©Áî®ÊñºÂÖ®Èù¢ÊÄßÂíåÂèØÊìç‰ΩúÊÄß„ÄÇÂõ†Ê≠§ÔºåÂ∞àÂÆ∂ÂèØ‰ª•Âú®È¢®Èö™ÂàÜÊûê‰∏≠Âà©Áî® LLM ‰ΩúÁÇ∫‰∏ÄÂÄãÊúâÊïàÁöÑË£úÂÖÖÂ§•‰º¥Ôºå‰∏¶Âú®Á∏ÆÁü≠ÁöÑÊôÇÈñìÁØÑÂúçÂÖß„ÄÇ‰ªñÂÄëÈÇÑÂèØ‰ª•ÈÄèÈÅéÈÅøÂÖçËàáÂØ¶ÊñΩ‰∏çÂøÖË¶ÅÁöÑÂ∞çÁ≠ñÁõ∏ÈóúÁöÑ‰∏çÂøÖË¶ÅÈñãÊîØ‰æÜÁØÄÁúÅÊàêÊú¨„ÄÇ</paragraph>

##### **Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis**
2406.07542v1 by David Ortiz-Perez, Jose Garcia-Rodriguez, David Tom√°s

Cognitive decline is a natural process that occurs as individuals age. Early
diagnosis of anomalous decline is crucial for initiating professional treatment
that can enhance the quality of life of those affected. To address this issue,
we propose a multimodal model capable of predicting Mild Cognitive Impairment
and cognitive scores. The TAUKADIAL dataset is used to conduct the evaluation,
which comprises audio recordings of clinical interviews. The proposed model
demonstrates the ability to transcribe and differentiate between languages used
in the interviews. Subsequently, the model extracts audio and text features,
combining them into a multimodal architecture to achieve robust and generalized
results. Our approach involves in-depth research to implement various features
obtained from the proposed modalities.

ÊëòË¶ÅÔºöË™çÁü•ËÉΩÂäõ‰∏ãÈôçÊòØÂÄã‰∫∫Èö®ËëóÂπ¥ÈΩ°Â¢ûÈï∑ËÄåÁôºÁîüÁöÑËá™ÁÑ∂ÈÅéÁ®ã„ÄÇÂèäÊó©Ë®∫Êñ∑Áï∞Â∏∏‰∏ãÈôçÂ∞çÊñºÂïüÂãïÂ∞àÊ•≠Ê≤ªÁôÇËá≥ÈóúÈáçË¶ÅÔºåÂèØÊèêÂçáÂèóÂΩ±ÈüøËÄÖÁöÑÁîüÊ¥ªÂìÅË≥™„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂ§öÊ®°ÊÖãÊ®°ÂûãÔºåËÉΩÂ§†È†êÊ∏¨ËºïÂ∫¶Ë™çÁü•ÈöúÁ§ôÂíåË™çÁü•Ë©ïÂàÜ„ÄÇTAUKADIAL Ë≥áÊñôÈõÜÁî®ÊñºÈÄ≤Ë°åË©ï‰º∞ÔºåÂÖ∂‰∏≠ÂåÖÂê´Ëá®Â∫äË®™Ë´áÁöÑÈü≥Ë®äÈåÑË£Ω„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜËΩâÈåÑÂíåÂçÄÂàÜË®™Ë´á‰∏≠ÊâÄÁî®Ë™ûË®ÄÁöÑËÉΩÂäõ„ÄÇÈö®ÂæåÔºåÊ®°ÂûãÊúÉÊì∑ÂèñÈü≥Ë®äÂíåÊñáÂ≠óÁâπÂæµÔºåÂ∞áÂÆÉÂÄëÁµÑÂêàÊàêÂ§öÊ®°ÊÖãÊû∂ÊßãÔºå‰ª•ÈÅîÊàêÁ©©ÂÅ•‰∏îÂª£Ê≥õÁöÑÁµêÊûú„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèäÊ∑±ÂÖ•Á†îÁ©∂Ôºå‰ª•ÂØ¶‰ΩúÂæûÊâÄÊèêÂá∫ÁöÑÊ®°ÊÖã‰∏≠ÂèñÂæóÁöÑÂêÑÁ®ÆÁâπÂæµ„ÄÇ

##### **CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**
2406.07494v2 by Frederic Kirstein, Jan Philip Wahle, Bela Gipp, Terry Ruas

Abstractive dialogue summarization is the task of distilling conversations
into informative and concise summaries. Although reviews have been conducted on
this topic, there is a lack of comprehensive work detailing the challenges of
dialogue summarization, unifying the differing understanding of the task, and
aligning proposed techniques, datasets, and evaluation metrics with the
challenges. This article summarizes the research on Transformer-based
abstractive summarization for English dialogues by systematically reviewing
1262 unique research papers published between 2019 and 2024, relying on the
Semantic Scholar and DBLP databases. We cover the main challenges present in
dialog summarization (i.e., language, structure, comprehension, speaker,
salience, and factuality) and link them to corresponding techniques such as
graph-based approaches, additional training tasks, and planning strategies,
which typically overly rely on BART-based encoder-decoder models. We find that
while some challenges, like language, have seen considerable progress, mainly
due to training methods, others, such as comprehension, factuality, and
salience, remain difficult and hold significant research opportunities. We
investigate how these approaches are typically assessed, covering the datasets
for the subdomains of dialogue (e.g., meeting, medical), the established
automatic metrics and human evaluation approaches for assessing scores and
annotator agreement. We observe that only a few datasets span across all
subdomains. The ROUGE metric is the most used, while human evaluation is
frequently reported without sufficient detail on inner-annotator agreement and
annotation guidelines. Additionally, we discuss the possible implications of
the recently explored large language models and conclude that despite a
potential shift in relevance and difficulty, our described challenge taxonomy
remains relevant.

ÊëòË¶ÅÔºö<paragraph>ÊäΩË±°ÂºèÂ∞çË©±ÊëòË¶ÅÊòØÂ∞áÂ∞çË©±ÊøÉÁ∏ÆÊàêÂÖ∑ÊúâË≥áË®äÊÄß‰∏îÁ∞°ÊΩîÁöÑÊëòË¶Å„ÄÇÂÑòÁÆ°Â∑≤ÈáùÂ∞çÊ≠§‰∏ªÈ°åÈÄ≤Ë°åÂØ©Êü•Ôºå‰ΩÜ‰ªçÁº∫‰πèË©≥Á¥∞Ë™™ÊòéÂ∞çË©±ÊëòË¶ÅÊåëÊà∞„ÄÅÁµ±‰∏ÄÂ∞ç‰ªªÂãôÁöÑ‰∏çÂêåÁêÜËß£Ôºå‰ª•ÂèäÂ∞áÂª∫Ë≠∞ÁöÑÊäÄË°ì„ÄÅË≥áÊñôÈõÜÂíåË©ï‰º∞ÊåáÊ®ôËàáÊåëÊà∞Áõ∏Á¨¶ÁöÑÂÖ®Èù¢ÊÄßÁ†îÁ©∂„ÄÇÊú¨ÊñáÈÄèÈÅéÁ≥ªÁµ±ÊÄßÂú∞Ê™¢Èñ± 2019 Âπ¥Ëá≥ 2024 Âπ¥ÈñìÁôºË°®ÁöÑ 1262 ÁØáÁç®ÁâπÁ†îÁ©∂Ë´ñÊñáÔºå‰æùË≥¥Ë™ûÁæ©Â≠∏ËÄÖÂíå DBLP Ë≥áÊñôÂ∫´ÔºåÁ∏ΩÁµê‰∫ÜÂü∫Êñº Transformer ÁöÑËã±Ë™ûÂ∞çË©±ÊäΩË±°ÂºèÊëòË¶ÅÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÊ∂µËìãÂ∞çË©±ÊëòË¶Å‰∏≠Âá∫ÁèæÁöÑ‰∏ªË¶ÅÊåëÊà∞ÔºàÂç≥Ë™ûË®Ä„ÄÅÁµêÊßã„ÄÅÁêÜËß£„ÄÅË™™Ë©±ËÄÖ„ÄÅÈ°ØËëóÊÄßÂíåÁúüÂØ¶ÊÄßÔºâÔºå‰∏¶Â∞áÂÆÉÂÄëÈÄ£ÁµêÂà∞Â∞çÊáâÁöÑÊäÄË°ìÔºå‰æãÂ¶ÇÂü∫ÊñºÂúñÂΩ¢ÁöÑÊñπÊ≥ï„ÄÅÈ°çÂ§ñÁöÑË®ìÁ∑¥‰ªªÂãôÂíåË¶èÂäÉÁ≠ñÁï•ÔºåÈÄô‰∫õÁ≠ñÁï•ÈÄöÂ∏∏ÈÅéÂ∫¶‰æùË≥¥ÊñºÂü∫Êñº BART ÁöÑÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Ê®°Âûã„ÄÇÊàëÂÄëÁôºÁèæÔºåÈõñÁÑ∂Ë™ûË®ÄÁ≠â‰∏Ä‰∫õÊåëÊà∞Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÂæó‰∫ÜÈÄ≤Â±ïÔºåÈÄô‰∏ªË¶ÅÊòØÁî±ÊñºË®ìÁ∑¥ÊñπÊ≥ïÔºå‰ΩÜÂÖ∂‰ªñÊåëÊà∞Ôºå‰æãÂ¶ÇÁêÜËß£„ÄÅÁúüÂØ¶ÊÄßÂíåÈ°ØËëóÊÄßÔºå‰ªçÁÑ∂ÂæàÂõ∞Èõ£Ôºå‰∏¶ÂÖ∑ÊúâÈáçÂ§ßÁöÑÁ†îÁ©∂Ê©üÊúÉ„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄöÂ∏∏Â¶Ç‰ΩïË©ï‰º∞ÈÄô‰∫õÊñπÊ≥ïÔºåÊ∂µËìã‰∫ÜÂ∞çË©±Â≠êÈ†òÂüüÔºà‰æãÂ¶ÇÊúÉË≠∞„ÄÅÈÜ´ÁôÇÔºâÁöÑË≥áÊñôÈõÜÔºåÊó¢ÂÆöÁöÑËá™ÂãïÂåñÊåáÊ®ôÂíåÁî®ÊñºË©ï‰º∞ÂàÜÊï∏ÂíåË®ªËß£ËÄÖ‰∏ÄËá¥ÊÄßÁöÑË©ï‰º∞ÊñπÊ≥ï„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåÂè™ÊúâÂ∞ëÊï∏Ë≥áÊñôÈõÜË∑®Ë∂äÊâÄÊúâÂ≠êÈ†òÂüü„ÄÇROUGE ÊåáÊ®ô‰ΩøÁî®ÊúÄÈ†ªÁπÅÔºåËÄå‰∫∫È°ûË©ï‰º∞ÈÄöÂ∏∏Âú®Ê≤íÊúâË∂≥Â§†ÁöÑË®ªËß£ËÄÖÂÖßÈÉ®‰∏ÄËá¥ÊÄßÂíåË®ªËß£ÊåáÂçóÁöÑË©≥Á¥∞Ë≥áË®ä‰∏ãÈÄ≤Ë°åÂ†±Âëä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜËøëÊúüÊé¢Á¥¢ÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÁöÑÂèØËÉΩÂΩ±ÈüøÔºå‰∏¶ÂæóÂá∫ÁµêË´ñÔºåÂÑòÁÆ°Áõ∏ÈóúÊÄßÂíåÈõ£Â∫¶ÂèØËÉΩÁôºÁîüËΩâËÆäÔºå‰ΩÜÊàëÂÄëÊâÄÊèèËø∞ÁöÑÊåëÊà∞ÂàÜÈ°ûÊ≥ï‰ªçÁÑ∂Áõ∏Èóú„ÄÇ</paragraph>

##### **Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images**
2406.07146v2 by Che Liu, Zhongwei Wan, Yuqi Wang, Hui Shen, Haozhe Wang, Kangyu Zheng, Mi Zhang, Rossella Arcucci

Automatic radiology report generation can significantly benefit the
labor-intensive process of report writing by radiologists, especially for 3D
radiographs like CT scans, which are crucial for broad clinical diagnostics yet
underexplored compared to 2D radiographs. Existing methods often handle 3D
volumes either slice-wise or with aggressive downsampling due to current GPU
memory limitations, which results in a loss of the inherent 3D nature and
critical details. To overcome these issues, we introduce a novel framework that
efficiently and effectively generates radiology reports for high-resolution
(HR) 3D volumes, based on large language models (LLMs). Specifically, our
framework utilizes low-resolution (LR) visual tokens as queries to mine
information from HR tokens, preserving detailed HR information while reducing
computational costs by only processing HR informed LR visual queries. Further
benefiting the field, we curate and release BIMCV-RG, a new dataset with 5,328
HR 3D volumes and paired reports, establishing the first benchmarks for report
generation from 3D HR medical images. Our method consistently surpasses
existing methods on this benchmark across three different settings:
normal-resolution, high-resolution inputs, and zero-shot domain transfer, all
at an acceptable computational cost, trainable on a single A100-80G.

ÊëòË¶ÅÔºöËá™ÂãïÊîæÂ∞ÑÁ∑öÂ†±ÂëäÁîüÊàêÂèØ‰ª•Â§ßÂπÖÈôç‰ΩéÊîæÂ∞ÑÁßëÈÜ´Â∏´Êí∞ÂØ´Â†±ÂëäÁöÑÂãûÂäõÂØÜÈõÜÁ®ãÂ∫èÔºåÁâπÂà•ÊòØÂ∞çÊñº 3D Â∞ÑÁ∑öÁÖßÁâáÔºà‰æãÂ¶ÇÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÔºâÔºåÈÄôÂ∞çÂª£Ê≥õÁöÑËá®Â∫äË®∫Êñ∑Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜËàá 2D Â∞ÑÁ∑öÁÖßÁâáÁõ∏ÊØîÔºå‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏ÊúÉ‰ª•ÂàáÁâáÊñπÂºèÊàñÈÄèÈÅéÊøÄÈÄ≤ÁöÑÈôçÊé°Ê®£‰æÜËôïÁêÜ 3D È´îÁ©çÔºåÈÄôÊòØÂõ†ÁÇ∫ÁõÆÂâçÁöÑ GPU Ë®òÊÜ∂È´îÊúâÈôêÔºåÈÄôÊúÉÂ∞éËá¥Âõ∫ÊúâÁöÑ 3D ÁâπÊÄßÂíåÈóúÈçµÁ¥∞ÁØÄÈÅ∫Â§±„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Êû∂ÊßãÔºåÂèØÊúâÊïàÁéá‰∏îÊúâÊïàÂú∞ÁÇ∫È´òËß£ÊûêÂ∫¶ (HR) 3D È´îÁ©çÁîüÊàêÊîæÂ∞ÑÁ∑öÂ†±ÂëäÔºåÂÖ∂Âü∫Á§éÊòØÂ§ßË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂà©Áî®‰ΩéËß£ÊûêÂ∫¶ (LR) Ë¶ñË¶∫Ê®ôË®ò‰ΩúÁÇ∫Êü•Ë©¢ÔºåÂæû HR Ê®ôË®ò‰∏≠ÊåñÊéòË≥áË®äÔºåÂêåÊôÇ‰øùÁïôË©≥Á¥∞ÁöÑ HR Ë≥áË®äÔºå‰∏¶ÈÄèÈÅéÂÉÖËôïÁêÜ HR Ë≥áË®äÁöÑ LR Ë¶ñË¶∫Êü•Ë©¢‰æÜÈôç‰ΩéÈÅãÁÆóÊàêÊú¨„ÄÇÊàëÂÄëÊï¥ÁêÜ‰∏¶ÁôºÂ∏É BIMCV-RGÔºå‰∏ÄÂÄãÂåÖÂê´ 5,328 ÂÄã HR 3D È´îÁ©çÂíåÈÖçÂ∞çÂ†±ÂëäÁöÑÊñ∞Ë≥áÊñôÈõÜÔºåÈÄ≤‰∏ÄÊ≠•ÈÄ†Á¶èÈÄôÂÄãÈ†òÂüüÔºåÁÇ∫Âæû 3D HR ÈÜ´Â≠∏ÂΩ±ÂÉèÁîüÊàêÂ†±ÂëäÂª∫Á´ã‰∫ÜÁ¨¨‰∏ÄÂÄãÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®‰∏âÂÄã‰∏çÂêåÁöÑË®≠ÂÆö‰∏≠ÊåÅÁ∫åË∂ÖË∂äÁèæÊúâÁöÑÊ®°ÂûãÔºöÊ≠£Â∏∏Ëß£ÊûêÂ∫¶„ÄÅÈ´òËß£ÊûêÂ∫¶Ëº∏ÂÖ•ÂíåÈõ∂Ê¨°Â≠∏ÁøíÈ†òÂüüËΩâÁßªÔºåÊâÄÊúâË®≠ÂÆöÁöÑÈÅãÁÆóÊàêÊú¨ÈÉΩÂú®ÂèØÊé•ÂèóÁöÑÁØÑÂúçÂÖßÔºå‰∏îÂèØ‰ª•Âú®ÂñÆÂÄã A100-80G ‰∏äË®ìÁ∑¥„ÄÇ

##### **Unlocking the Potential of the Metaverse for Innovative and Immersive Digital Care**
2406.07114v1 by Fatemeh Ebrahimzadeh, Ramin Safa

The Metaverse, a persistent, immersive virtual environment, has the immense
potential to revolutionize healthcare by transforming patient care, medical
education, and research. This paper explores the applications, benefits, and
challenges associated with this transformative technology, highlighting its
ability to improve patient engagement, communication, access to information,
and health outcomes. The paper also examines how the analysis of Metaverse data
using machine learning techniques can unlock insights to further enhance
healthcare applications. The discussion summarizes key findings, analyzes the
significance and practical implications of Metaverse integration, and
identifies areas for future research. It underscores the role of major tech
companies in developing Metaverse-based solutions and the importance of
addressing emerging opportunities and challenges to unlock the transformative
potential of this technology in healthcare. The paper concludes by emphasizing
the need for collaboration between stakeholders to ensure the ethical and
effective implementation of these technologies, ultimately leading to a more
accessible, personalized, and efficient healthcare system.

ÊëòË¶ÅÔºöÂÖÉÂÆáÂÆôÔºå‰∏ÄÂÄãÊåÅÁ∫åÊÄßÁöÑÊ≤âÊµ∏ÂºèËôõÊì¨Áí∞Â¢ÉÔºåÂÖ∑ÊúâÈÄöÈÅéËΩâËÆäÊÇ£ËÄÖÁÖßË≠∑„ÄÅÈÜ´ÁôÇÊïôËÇ≤ÂíåÁ†îÁ©∂‰æÜÂæπÂ∫ïÊîπËÆäÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜËàáÈÄôÈ†ÖËÆäÈù©ÊÄßÊäÄË°ìÁõ∏ÈóúÁöÑÊáâÁî®„ÄÅÂÑ™ÈªûÂíåÊåëÊà∞ÔºåÈáçÈªûË™™ÊòéÂÖ∂ÊîπÂñÑÊÇ£ËÄÖÂèÉËàáÂ∫¶„ÄÅÊ∫ùÈÄö„ÄÅÁç≤ÂèñË≥áË®äÂíåÂÅ•Â∫∑ÁµêÊûúÁöÑËÉΩÂäõ„ÄÇÊú¨ÊñáÈÇÑÊé¢Ë®é‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Ê©üÂô®Â≠∏ÁøíÊäÄË°ìÂàÜÊûêÂÖÉÂÆáÂÆôË≥áÊñôÔºå‰ª•Ëß£ÈéñË¶ãËß£ÔºåÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇË®éË´ñÁ∏ΩÁµê‰∫Ü‰∏ªË¶ÅÁôºÁèæÔºåÂàÜÊûê‰∫ÜÂÖÉÂÆáÂÆôÊï¥ÂêàÁöÑÊÑèÁæ©ÂíåÂØ¶ÈöõÂΩ±ÈüøÔºå‰∏¶ÊâæÂá∫Êú™‰æÜÁ†îÁ©∂È†òÂüü„ÄÇÂÆÉÂº∑Ë™ø‰∫ÜÂ§ßÂûãÁßëÊäÄÂÖ¨Âè∏Âú®ÈñãÁôºÂü∫ÊñºÂÖÉÂÆáÂÆôÁöÑËß£Ê±∫ÊñπÊ°à‰∏≠ÁöÑ‰ΩúÁî®Ôºå‰ª•ÂèäËß£Ê±∫Êñ∞ËààÊ©üÊúÉÂíåÊåëÊà∞‰ª•ÈáãÊîæÈÄôÈ†ÖÊäÄË°ìÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑËΩâÂûãÊΩõÂäõÁöÑÈáçË¶ÅÊÄß„ÄÇÊú¨ÊñáÊúÄÂæåÂº∑Ë™ø‰∫ÜÂà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÂêà‰ΩúÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Á¢∫‰øùÈÄô‰∫õÊäÄË°ìÁöÑÈÅìÂæ∑ÂíåÊúâÊïàÂØ¶ÊñΩÔºåÊúÄÁµÇÂª∫Á´ã‰∏ÄÂÄãÊõ¥ÊòìÊñº‰ΩøÁî®„ÄÅÊõ¥ÂÄãÊÄßÂåñÂíåÊõ¥ÊúâÊïàÁöÑÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±„ÄÇ

##### **Heterogeneous Learning Rate Scheduling for Neural Architecture Search on Long-Tailed Datasets**
2406.07028v1 by Chenxia Tang

In this paper, we attempt to address the challenge of applying Neural
Architecture Search (NAS) algorithms, specifically the Differentiable
Architecture Search (DARTS), to long-tailed datasets where class distribution
is highly imbalanced. We observe that traditional re-sampling and re-weighting
techniques, which are effective in standard classification tasks, lead to
performance degradation when combined with DARTS. To mitigate this, we propose
a novel adaptive learning rate scheduling strategy tailored for the
architecture parameters of DARTS when integrated with the Bilateral Branch
Network (BBN) for handling imbalanced datasets. Our approach dynamically
adjusts the learning rate of the architecture parameters based on the training
epoch, preventing the disruption of well-trained representations in the later
stages of training. Additionally, we explore the impact of branch mixing
factors on the algorithm's performance. Through extensive experiments on the
CIFAR-10 dataset with an artificially induced long-tailed distribution, we
demonstrate that our method achieves comparable accuracy to using DARTS alone.
And the experiment results suggest that re-sampling methods inherently harm the
performance of the DARTS algorithm. Our findings highlight the importance of
careful data augment when applying DNAS to imbalanced learning scenarios.

ÊëòË¶ÅÔºö<paragraph>Âú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ùËØïËß£ÂÜ≥Â∞ÜÁ•ûÁªèÊû∂ÊûÑÊêúÁ¥¢ (NAS) ÁÆóÊ≥ïÔºàÁâπÂà´ÊòØÂèØÂæÆÊû∂ÊûÑÊêúÁ¥¢ (DARTS)ÔºâÂ∫îÁî®‰∫éÈïøÂ∞æÊï∞ÊçÆÈõÜÁöÑÊåëÊàòÔºåÂÖ∂‰∏≠Á±ªÂàÜÂ∏ÉÈ´òÂ∫¶‰∏çÂπ≥Ë°°„ÄÇÊàë‰ª¨ËßÇÂØüÂà∞‰º†ÁªüÁöÑÈáçÊñ∞ÈááÊ†∑ÂíåÈáçÊñ∞Âä†ÊùÉÊäÄÊúØÔºàÂú®Ê†áÂáÜÂàÜÁ±ª‰ªªÂä°‰∏≠ÊúâÊïàÔºâ‰∏é DARTS ÁªìÂêà‰ΩøÁî®Êó∂‰ºöÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇ‰∏∫‰∫ÜÁºìËß£Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËá™ÈÄÇÂ∫îÂ≠¶‰π†ÁéáË∞ÉÂ∫¶Á≠ñÁï•ÔºåËØ•Á≠ñÁï•ÈíàÂØπ DARTS ÁöÑÊû∂ÊûÑÂèÇÊï∞ÈáèË∫´ÂÆöÂà∂ÔºåÂπ∂‰∏éÂèåËæπÂàÜÊîØÁΩëÁªú (BBN) ÈõÜÊàê‰ª•Â§ÑÁêÜ‰∏çÂπ≥Ë°°Êï∞ÊçÆÈõÜ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÊ†πÊçÆËÆ≠ÁªÉÊó∂ÊúüÂä®ÊÄÅË∞ÉÊï¥Êû∂ÊûÑÂèÇÊï∞ÁöÑÂ≠¶‰π†ÁéáÔºåÈò≤Ê≠¢Âú®ËÆ≠ÁªÉÂêéÊúüÁ†¥ÂùèËÆ≠ÁªÉËâØÂ•ΩÁöÑË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Êé¢ËÆ®‰∫ÜÂàÜÊîØÊ∑∑ÂêàÂõ†Â≠êÂØπÁÆóÊ≥ïÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇÈÄöËøáÂú®‰∫∫Â∑•ËØ±ÂØºÁöÑÈïøÂ∞æÂàÜÂ∏ÉÁöÑ CIFAR-10 Êï∞ÊçÆÈõÜ‰∏äËøõË°åÂπøÊ≥õÁöÑÂÆûÈ™åÔºåÊàë‰ª¨ËØÅÊòé‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ï‰∏éÂçïÁã¨‰ΩøÁî® DARTS ÂÆûÁé∞‰∫ÜÁõ∏ÂΩìÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÈáçÊñ∞ÈááÊ†∑ÊñπÊ≥ïÊú¨Ë¥®‰∏ä‰ºöÊçüÂÆ≥ DARTS ÁÆóÊ≥ïÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúÁ™ÅÂá∫‰∫ÜÂú®Â∞Ü DNAS Â∫îÁî®‰∫é‰∏çÂπ≥Ë°°Â≠¶‰π†Âú∫ÊôØÊó∂‰ªîÁªÜËøõË°åÊï∞ÊçÆÊâ©ÂÖÖÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Taxes Are All You Need: Integration of Taxonomical Hierarchy Relationships into the Contrastive Loss**
2406.06848v1 by Kiran Kokilepersaud, Yavuz Yarici, Mohit Prabhushankar, Ghassan AlRegib

In this work, we propose a novel supervised contrastive loss that enables the
integration of taxonomic hierarchy information during the representation
learning process. A supervised contrastive loss operates by enforcing that
images with the same class label (positive samples) project closer to each
other than images with differing class labels (negative samples). The advantage
of this approach is that it directly penalizes the structure of the
representation space itself. This enables greater flexibility with respect to
encoding semantic concepts. However, the standard supervised contrastive loss
only enforces semantic structure based on the downstream task (i.e. the class
label). In reality, the class label is only one level of a \emph{hierarchy of
different semantic relationships known as a taxonomy}. For example, the class
label is oftentimes the species of an animal, but between different classes
there are higher order relationships such as all animals with wings being
``birds". We show that by explicitly accounting for these relationships with a
weighting penalty in the contrastive loss we can out-perform the supervised
contrastive loss. Additionally, we demonstrate the adaptability of the notion
of a taxonomy by integrating our loss into medical and noise-based settings
that show performance improvements by as much as 7%.

ÊëòË¶ÅÔºöÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁõ£Áù£Â∞çÊØîÊêçÂ§±ÔºåÂÆÉÂèØ‰ª•Âú®Ë°®Á§∫Â≠∏ÁøíÈÅéÁ®ã‰∏≠Êï¥ÂêàÂàÜÈ°ûÂ±§Á¥öË≥áË®ä„ÄÇÁõ£Áù£Â∞çÊØîÊêçÂ§±ÈÄèÈÅéÂº∑Âà∂ÂÖ∑ÊúâÁõ∏ÂêåÈ°ûÂà•Ê®ôÁ±§ÔºàÊ≠£Ê®£Êú¨ÔºâÁöÑÂΩ±ÂÉèÊØîÂÖ∑Êúâ‰∏çÂêåÈ°ûÂà•Ê®ôÁ±§ÔºàË≤†Ê®£Êú¨ÔºâÁöÑÂΩ±ÂÉèÊõ¥Êé•ËøëÂΩºÊ≠§‰æÜÈÅã‰Ωú„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁöÑÂÑ™ÈªûÊòØÂÆÉÁõ¥Êé•Êá≤ÁΩ∞Ë°®Á§∫Á©∫ÈñìÊú¨Ë∫´ÁöÑÁµêÊßã„ÄÇÈÄô‰ΩøÂæóÂú®Á∑®Á¢ºË™ûÊÑèÊ¶ÇÂøµÊñπÈù¢ÂÖ∑ÊúâÊõ¥Â§ßÁöÑÈùàÊ¥ªÊÄß„ÄÇÁÑ∂ËÄåÔºåÊ®ôÊ∫ñÁöÑÁõ£Áù£Â∞çÊØîÊêçÂ§±ÂÉÖÊ†πÊìö‰∏ãÊ∏∏‰ªªÂãôÔºàÂç≥È°ûÂà•Ê®ôÁ±§Ôºâ‰æÜÂº∑Âà∂Ë™ûÊÑèÁµêÊßã„ÄÇÂØ¶Èöõ‰∏äÔºåÈ°ûÂà•Ê®ôÁ±§Âè™ÊòØÁ®±ÁÇ∫ÂàÜÈ°ûÊ≥ïÁöÑ‰∏ÄÁ®Æ‰∏çÂêåË™ûÊÑèÈóú‰øÇÂ±§Á¥ö‰∏≠ÁöÑÂÖ∂‰∏≠‰∏ÄÂ±§„ÄÇ‰æãÂ¶ÇÔºåÈ°ûÂà•Ê®ôÁ±§ÈÄöÂ∏∏ÊòØÂãïÁâ©ÁöÑÁâ©Á®ÆÔºå‰ΩÜÂú®‰∏çÂêåÁöÑÈ°ûÂà•‰πãÈñìÂ≠òÂú®Êõ¥È´òÈöéÁöÑÈóú‰øÇÔºå‰æãÂ¶ÇÊâÄÊúâÊúâÁøÖËÜÄÁöÑÂãïÁâ©ÈÉΩÊòØ„ÄåÈ≥•È°û„Äç„ÄÇÊàëÂÄëË°®ÊòéÔºåÈÄèÈÅéÂú®Â∞çÊØîÊêçÂ§±‰∏≠‰ΩøÁî®Âä†Ê¨äÊá≤ÁΩ∞‰æÜÊòéÁ¢∫Ë™™ÊòéÈÄô‰∫õÈóú‰øÇÔºåÊàëÂÄëÂèØ‰ª•ÂÑ™ÊñºÁõ£Áù£Â∞çÊØîÊêçÂ§±„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂàÜÈ°ûÊ≥ïÊ¶ÇÂøµÁöÑÈÅ©ÊáâÊÄßÔºåÊñπÊ≥ïÊòØÂ∞áÊàëÂÄëÁöÑÊêçÂ§±Êï¥ÂêàÂà∞ÈÜ´ÁôÇÂíåÂü∫ÊñºÈõúË®äÁöÑË®≠ÂÆö‰∏≠ÔºåÈÄô‰∫õË®≠ÂÆöÈ°ØÁ§∫ÊïàËÉΩÊèêÂçá‰∫Ü 7%„ÄÇ

##### **SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature**
2406.07835v1 by David Wadden, Kejian Shi, Jacob Morrison, Aakanksha Naik, Shruti Singh, Nitzan Barzilay, Kyle Lo, Tom Hope, Luca Soldaini, Shannon Zejiang Shen, Doug Downey, Hannaneh Hajishirzi, Arman Cohan

We present SciRIFF (Scientific Resource for Instruction-Following and
Finetuning), a dataset of 137K instruction-following demonstrations for 54
tasks covering five essential scientific literature understanding capabilities:
information extraction, summarization, question answering, claim verification,
and classification. SciRIFF demonstrations are notable for their long input
contexts, detailed task specifications, and complex structured outputs. While
instruction-following resources are available in specific domains such as
clinical medicine and chemistry, SciRIFF is the first dataset focused on
extracting and synthesizing information from research literature across a wide
range of scientific fields. To demonstrate the utility of SciRIFF, we develop a
sample-efficient strategy to adapt a general instruction-following model for
science by performing additional finetuning on a mix of general-domain and
SciRIFF demonstrations. In evaluations on nine held-out scientific tasks, our
model -- called SciTulu -- improves over a strong LLM baseline by 28.1% and
6.5% at the 7B and 70B scales respectively, while maintaining general
instruction-following performance within 2% of the baseline. We are optimistic
that SciRIFF will facilitate the development and evaluation of LLMs to help
researchers navigate the ever-growing body of scientific literature. We release
our dataset, model checkpoints, and data processing and evaluation code to
enable further research.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫ SciRIFFÔºàÁßëÂ≠∏Ë≥áÊ∫êÔºåÁî®ÊñºÈÅµÂæ™Ë™™ÊòéÂíåÂæÆË™øÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´ 137K ÈÅµÂæ™Ë™™ÊòéÁöÑÁ§∫ÁØÑË≥áÊñôÈõÜÔºåÊ∂µËìã 54 È†Ö‰ªªÂãôÔºåÊ∂µËìã‰∫îÈ†ÖÈáçË¶ÅÁöÑÁßëÂ≠∏ÊñáÁçªÁêÜËß£ËÉΩÂäõÔºöË≥áË®äÊì∑Âèñ„ÄÅÊëòË¶Å„ÄÅÂïèÁ≠î„ÄÅËÅ≤ÊòéÈ©óË≠âÂíåÂàÜÈ°û„ÄÇSciRIFF Á§∫ÁØÑ‰ª•ÂÖ∂Èï∑ÁöÑËº∏ÂÖ•ÂÖßÂÆπ„ÄÅË©≥Á¥∞ÁöÑ‰ªªÂãôË¶èÊ†ºÂíåË§áÈõúÁöÑÁµêÊßãÂåñËº∏Âá∫ËÄåËÅûÂêç„ÄÇÈõñÁÑ∂ÁâπÂÆöÈ†òÂüüÔºà‰æãÂ¶ÇËá®Â∫äÈÜ´Â≠∏ÂíåÂåñÂ≠∏ÔºâÊúâÈÅµÂæ™Ë™™ÊòéÁöÑË≥áÊ∫êÔºå‰ΩÜ SciRIFF ÊòØÁ¨¨‰∏ÄÂÄãÂ∞àÊ≥®ÊñºÂæûÂêÑÁ®ÆÁßëÂ≠∏È†òÂüüÁöÑÁ†îÁ©∂ÊñáÁçª‰∏≠ÊèêÂèñÂíåÁ∂úÂêàË≥áË®äÁöÑË≥áÊñôÈõÜ„ÄÇÁÇ∫‰∫ÜÂ±ïÁ§∫ SciRIFF ÁöÑÊïàÁî®ÔºåÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÁ®ÆÊ®£Êú¨ÊúâÊïàÁéáÁöÑÁ≠ñÁï•ÔºåÈÄèÈÅéÂú®‰∏ÄËà¨È†òÂüüÂíå SciRIFF Á§∫ÁØÑÁöÑÁµÑÂêà‰∏äÂü∑Ë°åÈ°çÂ§ñÁöÑÂæÆË™øÔºå‰æÜË™øÊï¥‰∏ÄËà¨ÈÅµÂæ™Ë™™ÊòéÁöÑÊ®°Âûã‰ª•ÈÅ©ÊáâÁßëÂ≠∏„ÄÇÂú®‰πùÈ†ÖÂ∑≤Êö´ÂÅúÁöÑÁßëÂ≠∏‰ªªÂãôÁöÑË©ï‰º∞‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÔºàÁ®±ÁÇ∫ SciTuluÔºâÂú® 7B Âíå 70B Ë¶èÊ®°ÂàÜÂà•ÊØîÂº∑Â§ßÁöÑ LLM Âü∫Ê∫ñÊèêÈ´ò‰∫Ü 28.1% Âíå 6.5%ÔºåÂêåÊôÇÂ∞á‰∏ÄËà¨ÈÅµÂæ™Ë™™ÊòéÁöÑÊïàËÉΩÁ∂≠ÊåÅÂú®Âü∫Ê∫ñÁöÑ 2% ‰ª•ÂÖß„ÄÇÊàëÂÄëÊ®ÇËßÄÂú∞Ë™çÁÇ∫ SciRIFF Â∞áÊúâÂä©ÊñºÈñãÁôºÂíåË©ï‰º∞ LLMÔºå‰ª•Âπ´Âä©Á†îÁ©∂‰∫∫Âì°ÁÄèË¶Ω‰∏çÊñ∑Â¢ûÈï∑ÁöÑÁßëÂ≠∏ÊñáÁçª„ÄÇÊàëÂÄëÈáãÂá∫ÊàëÂÄëÁöÑË≥áÊñôÈõÜ„ÄÅÊ®°ÂûãÊ™¢Êü•ÈªûÔºå‰ª•ÂèäË≥áÊñôËôïÁêÜÂíåË©ï‰º∞Á®ãÂºèÁ¢ºÔºå‰ª•Âà©ÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂„ÄÇ</paragraph>

##### **BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification**
2406.06786v2 by June-Woo Kim, Miika Toikkanen, Yera Choi, Seoung-Eun Moon, Ho-Young Jung

Respiratory sound classification (RSC) is challenging due to varied acoustic
signatures, primarily influenced by patient demographics and recording
environments. To address this issue, we introduce a text-audio multimodal model
that utilizes metadata of respiratory sounds, which provides useful
complementary information for RSC. Specifically, we fine-tune a pretrained
text-audio multimodal model using free-text descriptions derived from the sound
samples' metadata which includes the gender and age of patients, type of
recording devices, and recording location on the patient's body. Our method
achieves state-of-the-art performance on the ICBHI dataset, surpassing the
previous best result by a notable margin of 1.17%. This result validates the
effectiveness of leveraging metadata and respiratory sound samples in enhancing
RSC performance. Additionally, we investigate the model performance in the case
where metadata is partially unavailable, which may occur in real-world clinical
setting.

ÊëòË¶ÅÔºöÂëºÂê∏Èü≥ÂàÜÈ°û (RSC) Áî±Êñº‰∏çÂêåÁöÑËÅ≤Â≠∏ÁâπÂæµËÄåÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºå‰∏ªË¶ÅÂèóÊÇ£ËÄÖ‰∫∫Âè£Áµ±Ë®àË≥áÊñôÂíåÈåÑÈü≥Áí∞Â¢ÉÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÊñáÊú¨Èü≥Ë®äÂ§öÊ®°ÊÖãÊ®°ÂûãÔºåÂÆÉÂà©Áî®ÂëºÂê∏Èü≥ÁöÑÂÖÉË≥áÊñôÔºåÊèê‰æõÊúâÁî®ÁöÑË£úÂÖÖË≥áË®ä‰ª•ÈÄ≤Ë°å RSC„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî®ÂæûÈü≥Ë®äÁØÑ‰æãÂÖÉË≥áÊñô‰∏≠Ë°çÁîüÁöÑËá™Áî±ÊñáÂ≠óÊèèËø∞ÔºåÂæÆË™øÈ†êÂÖàË®ìÁ∑¥Â•ΩÁöÑÊñáÊú¨Èü≥Ë®äÂ§öÊ®°ÊÖãÊ®°ÂûãÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÊÇ£ËÄÖÁöÑÊÄßÂà•ÂíåÂπ¥ÈΩ°„ÄÅÈåÑÈü≥Ë£ùÁΩÆÈ°ûÂûã‰ª•ÂèäÊÇ£ËÄÖË∫´È´î‰∏äÁöÑÈåÑÈü≥‰ΩçÁΩÆ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú® ICBHI Ë≥áÊñôÈõÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰ª• 1.17% ÁöÑÈ°ØËëóÂπÖÂ∫¶Ë∂ÖË∂ä‰∫ÜÂÖàÂâçÁöÑÊúÄ‰Ω≥ÁµêÊûú„ÄÇÊ≠§ÁµêÊûúÈ©óË≠â‰∫ÜÂà©Áî®ÂÖÉË≥áÊñôÂíåÂëºÂê∏Èü≥ÁØÑ‰æã‰æÜÂ¢ûÂº∑ RSC ÊïàËÉΩÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂú®ÂÖÉË≥áÊñôÈÉ®ÂàÜ‰∏çÂèØÁî®ÁöÑÊÉÖÊ≥Å‰∏ãÊ®°ÂûãÊïàËÉΩÔºåÈÄôÂèØËÉΩÊúÉÁôºÁîüÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÁí∞Â¢É‰∏≠„ÄÇ

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

ÊëòË¶ÅÔºöÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁöÑÊÖ¢ÊÄßÁñæÁóÖÔºåÊ≤íÊúâÂ∑≤Áü•ÁöÑÊúÄÁµÇÁôÇÊ≥ï‰∏îÁôºÁóÖÁéáÂæàÈ´ò„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÈÄ≤Ë°åÊÄßÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÁï∞Ë≥™ÊÄßÁñæÁóÖÔºåÊúÉÈ°ØËëóÂΩ±ÈüøËÖéËáüÁµêÊßãÂíåÂäüËÉΩÔºåÊúÄÁµÇÂ∞éËá¥ËÖéË°∞Á´≠„ÄÇÈö®ËëóÊôÇÈñìÁöÑÊé®ÁßªÔºåÊÖ¢ÊÄßËÖéËáüÁóÖÂ∑≤ÂæûÂΩ±ÈüøÂ∞ëÊï∏‰∫∫ÁöÑËá¥ÂëΩÁñæÁóÖËΩâËÆäÁÇ∫‰∏ÄÁ®ÆÂö¥ÈáçÁ®ãÂ∫¶‰∏çÂêåÁöÑÂ∏∏Ë¶ãÁñæÁóÖ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÊ®ôÊòØ‰ΩøÁî®ÈõÜÊàêÂ≠∏ÁøíÂíåÂèØËß£ÈáãÁöÑ AI ÈÄ≤Ë°åÊó©ÊúüÈ†êÂæåÂíå CKD Ê™¢Ê∏¨Ôºå‰∏¶Ë¶ñË¶∫Âåñ‰∏ªÂ∞éÁâπÂæµ„ÄÅÁâπÂæµÂàÜÊï∏ÂíåË°®ÁèæÂá∫ÁöÑÂÄº„ÄÇÁÇ∫Ê≠§ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ AI È©ÖÂãïÁöÑÈ†êÊ∏¨ÂàÜÊûêÊñπÊ≥ïÔºå‰ª•Âπ´Âä©Ëá®Â∫äÈÜ´ÁîüÁÇ∫ÂÄãÂà•ÊÇ£ËÄÖÈñãÂÖ∑ÁîüÊ¥ªÊñπÂºè‰øÆÊîπÂª∫Ë≠∞Ôºå‰ª•Èôç‰ΩéÈÄôÁ®ÆÁñæÁóÖÁöÑÈÄ≤Â±ïÈÄüÂ∫¶„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÊòØÂæû CKD ÊÇ£ËÄÖÂíåÂÅ•Â∫∑ÂèóË©¶ËÄÖÁöÑË∫´È´îÁîüÂëΩÈ´îÂæµ‰∏≠Êî∂ÈõÜÁöÑÔºå‰ª•Ê∫ñÁ¢∫ÈñãÁôºÊàëÂÄëÊèêÂá∫ÁöÑ AI È©ÖÂãïÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®ÈÄôÊñπÈù¢ÔºåÊèê‰æõ‰∫ÜË°ÄÊ∂≤ÂíåÂ∞øÊ∂≤Ê™¢Ê∏¨ÁµêÊûúÔºå‰∏¶ÊáâÁî®Âü∫ÊñºÈõÜÊàêÊ®πÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨Êú™ÁôºÁèæÁöÑ CKD ÁóÖ‰æã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ∂ìÈÅéËàáËÖéËáüÁßëÈÜ´ÁîüÁöÑÈï∑ÊúüË´ÆË©¢ÂæåÂæóÂà∞È©óË≠â„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂíåËß£ÈáãÁµêÊûúËàáÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ÁèæÊúâÁöÑÂèØËß£Èáã AI ÊáâÁî®ÈÄ≤Ë°å‰∫ÜÊØîËºÉÔºåÂåÖÊã¨ CKD„ÄÇÊØîËºÉË°®ÊòéÔºåÊàëÂÄëÈñãÁôºÁöÑ AI Ê®°ÂûãÔºåÁâπÂà•ÊòØÈö®Ê©üÊ£ÆÊûóÊ®°ÂûãÔºåÂ∑≤Á∂ìÁ¢∫ÂÆö‰∫ÜÊØî XgBoost Êõ¥Â§ö‰ΩúÁÇ∫ÈáçË¶ÅË≤¢ÁçªËÄÖÁöÑÁâπÂæµ„ÄÇÂèØËß£ÈáãÊÄß (I) Ë°°ÈáèÈáçË¶ÅÁâπÂæµËàáÊé©ËìãÁâπÂæµÁöÑÊØîÁéáÔºåË°®ÊòéÊàëÂÄëÁöÑ XgBoost Ê®°ÂûãÂú®ÈÄôÂÄãÊåáÊ®ô‰∏≠Áç≤Âæó‰∫ÜÊõ¥È´òÁöÑÂàÜÊï∏ÔºåÁâπÂà•ÊòØ 98% ÁöÑ‰øùÁúüÂ∫¶Ôºå‰∏¶‰∏îÂú® FII ÊåáÊï∏‰∏≠Ëá™ÁÑ∂È´òÊñºÁ´∂Áà≠Ê®°Âûã„ÄÇ

##### **Merlin: A Vision Language Foundation Model for 3D Computed Tomography**
2406.06512v1 by Louis Blankemeier, Joseph Paul Cohen, Ashwin Kumar, Dave Van Veen, Syed Jamal Safdar Gardezi, Magdalini Paschali, Zhihong Chen, Jean-Benoit Delbrouck, Eduardo Reis, Cesar Truyts, Christian Bluethgen, Malte Engmann Kjeldskov Jensen, Sophie Ostmeier, Maya Varma, Jeya Maria Jose Valanarasu, Zhongnan Fang, Zepeng Huo, Zaid Nabulsi, Diego Ardila, Wei-Hung Weng, Edson Amaro Junior, Neera Ahuja, Jason Fries, Nigam H. Shah, Andrew Johnston, Robert D. Boutin, Andrew Wentland, Curtis P. Langlotz, Jason Hom, Sergios Gatidis, Akshay S. Chaudhari

Over 85 million computed tomography (CT) scans are performed annually in the
US, of which approximately one quarter focus on the abdomen. Given the current
radiologist shortage, there is a large impetus to use artificial intelligence
to alleviate the burden of interpreting these complex imaging studies. Prior
state-of-the-art approaches for automated medical image interpretation leverage
vision language models (VLMs). However, current medical VLMs are generally
limited to 2D images and short reports, and do not leverage electronic health
record (EHR) data for supervision. We introduce Merlin - a 3D VLM that we train
using paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes
(1.8+ million codes), and radiology reports (6+ million tokens). We evaluate
Merlin on 6 task types and 752 individual tasks. The non-adapted
(off-the-shelf) tasks include zero-shot findings classification (31 findings),
phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval
(image to findings and image to impressions), while model adapted tasks include
5-year disease prediction (6 diseases), radiology report generation, and 3D
semantic segmentation (20 organs). We perform internal validation on a test set
of 5,137 CTs, and external validation on 7,000 clinical CTs and on two public
CT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevant
evaluations, we assess the efficacy of various network architectures and
training strategies to depict that Merlin has favorable performance to existing
task-specific baselines. We derive data scaling laws to empirically assess
training data needs for requisite downstream task performance. Furthermore,
unlike conventional VLMs that require hundreds of GPUs for training, we perform
all training on a single GPU.

ÊëòË¶ÅÔºö<paragraph>ÁæéÂúãÊØèÂπ¥Âü∑Ë°åË∂ÖÈÅé 8500 Ëê¨Ê¨°ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT)ÔºåÂÖ∂‰∏≠Á¥ÑÂõõÂàÜ‰πã‰∏ÄÈáùÂ∞çËÖπÈÉ®„ÄÇÈëëÊñºÁõÆÂâçÊîæÂ∞ÑÁßëÈÜ´Â∏´Áü≠Áº∫ÔºåÂõ†Ê≠§ÊúâÂæàÂ§ßÁöÑÂãïÂäõ‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖß‰æÜÊ∏õËºïË©ÆÈáãÈÄô‰∫õË§áÈõúÂΩ±ÂÉèÁ†îÁ©∂ÁöÑË≤†Êìî„ÄÇÂÖàÂâçËá™ÂãïÂåñÈÜ´Â≠∏ÂΩ±ÂÉèË©ÆÈáãÁöÑÊúÄÊñ∞ÊñπÊ≥ïÂà©Áî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÈÜ´Â≠∏ VLM ÈÄöÂ∏∏ÂÉÖÈôêÊñº 2D ÂΩ±ÂÉèÂíåÁ∞°Áü≠Â†±ÂëäÔºåËÄå‰∏î‰∏çÊúÉÂà©Áî®ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Ë≥áÊñôÈÄ≤Ë°åÁõ£Áù£„ÄÇÊàëÂÄë‰ªãÁ¥π MerlinÔºåÈÄôÊòØ‰∏ÄÂÄã 3D VLMÔºåÊàëÂÄë‰ΩøÁî®ÈÖçÂ∞çÁöÑ CT ÊéÉÊèèÔºà‰æÜËá™ 15,331 ÂÄã CT ÁöÑ 600 Â§öËê¨ÂºµÂΩ±ÂÉèÔºâ„ÄÅEHR Ë®∫Êñ∑Á¢ºÔºà180 Â§öËê¨ÂÄãÁ¢ºÔºâÂíåÊîæÂ∞ÑÁßëÂ†±ÂëäÔºà600 Â§öËê¨ÂÄã‰ª£Á¢ºÔºâ‰æÜË®ìÁ∑¥ÂÆÉ„ÄÇÊàëÂÄëÂú® 6 ÂÄã‰ªªÂãôÈ°ûÂûãÂíå 752 ÂÄãÂÄãÂà•‰ªªÂãô‰∏äË©ï‰º∞ Merlin„ÄÇÈùûÈÅ©ÊáâÂûãÔºàÁèæÊàêÁöÑÔºâ‰ªªÂãôÂåÖÊã¨Èõ∂Ê¨°Â≠∏ÁøíÁµêÊûúÂàÜÈ°ûÔºà31 ÂÄãÁµêÊûúÔºâ„ÄÅË°®ÂûãÂàÜÈ°ûÔºà692 ÂÄãË°®ÂûãÔºâÂíåÈõ∂Ê¨°Â≠∏ÁøíË∑®Ê®°ÊÖãÊ™¢Á¥¢ÔºàÂΩ±ÂÉèÂà∞ÁµêÊûúÂíåÂΩ±ÂÉèÂà∞Âç∞Ë±°ÔºâÔºåËÄåÊ®°ÂûãÈÅ©Êáâ‰ªªÂãôÂåÖÊã¨ 5 Âπ¥ÁñæÁóÖÈ†êÊ∏¨Ôºà6 Á®ÆÁñæÁóÖÔºâ„ÄÅÊîæÂ∞ÑÁßëÂ†±ÂëäÁî¢ÁîüÂíå 3D Ë™ûÊÑèÂàÜÂâ≤Ôºà20 ÂÄãÂô®ÂÆòÔºâ„ÄÇÊàëÂÄëÂú® 5,137 ÂÄã CT ÁöÑÊ∏¨Ë©¶ÈõÜ‰∏äÂü∑Ë°åÂÖßÈÉ®È©óË≠âÔºå‰∏¶Âú® 7,000 ÂÄãËá®Â∫ä CT ÂíåÂÖ©ÂÄãÂÖ¨Èñã CT Ë≥áÊñôÈõÜÔºàVerSe„ÄÅTotalSegmentatorÔºâ‰∏äÂü∑Ë°åÂ§ñÈÉ®È©óË≠â„ÄÇÈô§‰∫ÜÈÄô‰∫õËàáËá®Â∫äÁõ∏ÈóúÁöÑË©ï‰º∞‰πãÂ§ñÔºåÊàëÂÄëÈÇÑË©ï‰º∞ÂêÑÁ®ÆÁ∂≤Ë∑ØÊû∂ÊßãÂíåË®ìÁ∑¥Á≠ñÁï•ÁöÑÊïàËÉΩÔºå‰ª•Ë™™Êòé Merlin Âú®ÁèæÊúâÁöÑÁâπÂÆö‰ªªÂãôÂü∫Á∑ö‰∏äÂÖ∑ÊúâËâØÂ•ΩÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÊé®Â∞éÂá∫Ë≥áÊñôÊì¥ÂÖÖÊ≥ïÂâáÔºå‰ª•Ê†πÊìöÁ∂ìÈ©óË©ï‰º∞‰∏ãÊ∏∏‰ªªÂãôÊïàËÉΩÊâÄÈúÄÁöÑË®ìÁ∑¥Ë≥áÊñôÈúÄÊ±Ç„ÄÇÊ≠§Â§ñÔºåËàáÈúÄË¶ÅÊï∏ÁôæÂÄã GPU ÊâçËÉΩÈÄ≤Ë°åË®ìÁ∑¥ÁöÑÂÇ≥Áµ± VLM ‰∏çÂêåÔºåÊàëÂÄëÂú®ÂñÆ‰∏Ä GPU ‰∏äÂü∑Ë°åÊâÄÊúâË®ìÁ∑¥„ÄÇ</paragraph>

##### **Towards a Personal Health Large Language Model**
2406.06474v1 by Justin Cosentino, Anastasiya Belyaeva, Xin Liu, Nicholas A. Furlotte, Zhun Yang, Chace Lee, Erik Schenck, Yojan Patel, Jian Cui, Logan Douglas Schneider, Robby Bryant, Ryan G. Gomes, Allen Jiang, Roy Lee, Yun Liu, Javier Perez, Jameson K. Rogers, Cathy Speed, Shyam Tailor, Megan Walker, Jeffrey Yu, Tim Althoff, Conor Heneghan, John Hernandez, Mark Malhotra, Leor Stern, Yossi Matias, Greg S. Corrado, Shwetak Patel, Shravya Shetty, Jiening Zhan, Shruthi Prabhakara, Daniel McDuff, Cory Y. McLean

In health, most large language model (LLM) research has focused on clinical
tasks. However, mobile and wearable devices, which are rarely integrated into
such tasks, provide rich, longitudinal data for personal health monitoring.
Here we present Personal Health Large Language Model (PH-LLM), fine-tuned from
Gemini for understanding and reasoning over numerical time-series personal
health data. We created and curated three datasets that test 1) production of
personalized insights and recommendations from sleep patterns, physical
activity, and physiological responses, 2) expert domain knowledge, and 3)
prediction of self-reported sleep outcomes. For the first task we designed 857
case studies in collaboration with domain experts to assess real-world
scenarios in sleep and fitness. Through comprehensive evaluation of
domain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not
statistically different from expert performance in fitness and, while experts
remain superior for sleep, fine-tuning PH-LLM provided significant improvements
in using relevant domain knowledge and personalizing information for sleep
insights. We evaluated PH-LLM domain knowledge using multiple choice sleep
medicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% on
fitness, exceeding average scores from a sample of human experts. Finally, we
trained PH-LLM to predict self-reported sleep quality outcomes from textual and
multimodal encoding representations of wearable data, and demonstrate that
multimodal encoding is required to match performance of specialized
discriminative models. Although further development and evaluation are
necessary in the safety-critical personal health domain, these results
demonstrate both the broad knowledge and capabilities of Gemini models and the
benefit of contextualizing physiological data for personal health applications
as done with PH-LLM.

ÊëòË¶ÅÔºöÂú®ÂÅ•Â∫∑È†òÂüüÔºåÂ§ßÂ§öÊï∏Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Á†îÁ©∂ÈÉΩÂ∞àÊ≥®ÊñºËá®Â∫ä‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåË°åÂãïË£ùÁΩÆÂíåÁ©øÊà¥ÂºèË£ùÁΩÆÂæàÂ∞ëÊï¥ÂêàÂà∞Ê≠§È°û‰ªªÂãô‰∏≠Ôºå‰ΩÜÂÆÉÂÄëÊúÉÊèê‰æõË±êÂØåÁöÑÁ∏±ÂêëË≥áÊñôÔºåÁî®ÊñºÂÄã‰∫∫ÂÅ•Â∫∑Áõ£Êéß„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëÊèêÂá∫ÂÄã‰∫∫ÂÅ•Â∫∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (PH-LLM)ÔºåÁ∂ìÈÅé Gemini ÂæÆË™øÔºåÁî®ÊñºÁêÜËß£ÂíåÊé®ÁêÜÊï∏ÂÄºÊôÇÈñìÂ∫èÂàóÂÄã‰∫∫ÂÅ•Â∫∑Ë≥áÊñô„ÄÇÊàëÂÄëÂª∫Á´ã‰∏¶Á≠ñÂäÉ‰∫Ü‰∏âÂÄãÊ∏¨Ë©¶Ë≥áÊñôÈõÜÔºåÁî®ÊñºÊ∏¨Ë©¶ 1) ÂæûÁù°Áú†Ê®°Âºè„ÄÅË∫´È´îÊ¥ªÂãïÂíåÁîüÁêÜÂèçÊáâ‰∏≠Áî¢ÁîüÂÄã‰∫∫ÂåñË¶ãËß£ÂíåÂª∫Ë≠∞Ôºå2) Â∞àÂÆ∂È†òÂüüÁü•Ë≠òÔºå‰ª•Âèä 3) È†êÊ∏¨Ëá™ÊàëÂ†±ÂëäÁöÑÁù°Áú†ÁµêÊûú„ÄÇÂ∞çÊñºÁ¨¨‰∏ÄÂÄã‰ªªÂãôÔºåÊàëÂÄëËàáÈ†òÂüüÂ∞àÂÆ∂Âêà‰ΩúË®≠Ë®à‰∫Ü 857 ÂÄãÊ°à‰æãÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞Áù°Áú†ÂíåÂÅ•Ë∫´ÁöÑÁúüÂØ¶ÊÉÖÊ≥Å„ÄÇÈÄèÈÅéÂ∞çÁâπÂÆöÈ†òÂüüË©ïÂàÜÊ®ôÊ∫ñÁöÑÂÖ®Èù¢Ë©ï‰º∞ÔºåÊàëÂÄëËßÄÂØüÂà∞ Gemini Ultra 1.0 Âíå PH-LLM Âú®ÂÅ•Ë∫´ÊñπÈù¢ÁöÑË°®ÁèæËàáÂ∞àÂÆ∂Ë°®ÁèæÊ≤íÊúâÁµ±Ë®àÂ≠∏Â∑ÆÁï∞ÔºåËÄåÂ∞àÂÆ∂Âú®Áù°Áú†ÊñπÈù¢ÁöÑË°®Áèæ‰ªçÁÑ∂ËºÉ‰Ω≥Ôºå‰ΩÜÂæÆË™ø PH-LLM Âú®‰ΩøÁî®Áõ∏ÈóúÈ†òÂüüÁü•Ë≠òÂíåÂÄã‰∫∫ÂåñÁù°Áú†Ë¶ãËß£Ë≥áË®äÊñπÈù¢Êèê‰æõ‰∫ÜÈ°ØËëóÊîπÈÄ≤„ÄÇÊàëÂÄë‰ΩøÁî®Â§öÈÅ∏È°åÁù°Áú†ÈÜ´Â≠∏ÂíåÂÅ•Ë∫´Ê™¢Êü•Ë©ï‰º∞ PH-LLM È†òÂüüÁü•Ë≠ò„ÄÇPH-LLM Âú®Áù°Áú†ÊñπÈù¢ÈÅîÂà∞ 79%ÔºåÂú®ÂÅ•Ë∫´ÊñπÈù¢ÈÅîÂà∞ 88%ÔºåË∂ÖÈÅé‰∫ÜÈÉ®ÂàÜ‰∫∫È°ûÂ∞àÂÆ∂ÁöÑÂπ≥ÂùáÂàÜÊï∏„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®ìÁ∑¥ PH-LLM ÂæûÂèØÁ©øÊà¥Ë≥áÊñôÁöÑÊñáÂ≠óÂíåÂ§öÊ®°ÊÖãÁ∑®Á¢ºË°®Á§∫‰∏≠È†êÊ∏¨Ëá™ÊàëÂ†±ÂëäÁöÑÁù°Áú†ÂìÅË≥™ÁµêÊûúÔºå‰∏¶Ë≠âÊòéÂ§öÊ®°ÊÖãÁ∑®Á¢ºÂ∞çÊñºÂåπÈÖçÁâπÊÆäËæ®Âà•Ê®°ÂûãÁöÑÊïàËÉΩÊòØÂøÖË¶ÅÁöÑ„ÄÇÂÑòÁÆ°Âú®ÂÆâÂÖ®ÈóúÈçµÁöÑÂÄã‰∫∫ÂÅ•Â∫∑È†òÂüü‰∏≠ÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÈñãÁôºÂíåË©ï‰º∞Ôºå‰ΩÜÈÄô‰∫õÁµêÊûúË≠âÊòé‰∫Ü Gemini Ê®°ÂûãÁöÑÂª£Ê≥õÁü•Ë≠òÂíåÂäüËÉΩÔºå‰ª•Âèä‰ΩøÁî® PH-LLM Â∞çÁîüÁêÜË≥áÊñôÈÄ≤Ë°åÊÉÖÂ¢ÉÂåñ‰ª•Áî®ÊñºÂÄã‰∫∫ÂÅ•Â∫∑ÊáâÁî®Á®ãÂºèÁöÑÂÑ™Èªû„ÄÇ

##### **Transforming Wearable Data into Health Insights using Large Language Model Agents**
2406.06464v2 by Mike A. Merrill, Akshay Paruchuri, Naghmeh Rezaei, Geza Kovacs, Javier Perez, Yun Liu, Erik Schenck, Nova Hammerquist, Jake Sunshine, Shyam Tailor, Kumar Ayush, Hao-Wei Su, Qian He, Cory Y. McLean, Mark Malhotra, Shwetak Patel, Jiening Zhan, Tim Althoff, Daniel McDuff, Xin Liu

Despite the proliferation of wearable health trackers and the importance of
sleep and exercise to health, deriving actionable personalized insights from
wearable data remains a challenge because doing so requires non-trivial
open-ended analysis of these data. The recent rise of large language model
(LLM) agents, which can use tools to reason about and interact with the world,
presents a promising opportunity to enable such personalized analysis at scale.
Yet, the application of LLM agents in analyzing personal health is still
largely untapped. In this paper, we introduce the Personal Health Insights
Agent (PHIA), an agent system that leverages state-of-the-art code generation
and information retrieval tools to analyze and interpret behavioral health data
from wearables. We curate two benchmark question-answering datasets of over
4000 health insights questions. Based on 650 hours of human and expert
evaluation we find that PHIA can accurately address over 84% of factual
numerical questions and more than 83% of crowd-sourced open-ended questions.
This work has implications for advancing behavioral health across the
population, potentially enabling individuals to interpret their own wearable
data, and paving the way for a new era of accessible, personalized wellness
regimens that are informed by data-driven insights.

ÊëòË¶ÅÔºöÂÑòÁÆ°Á©øÊà¥ÂºèÂÅ•Â∫∑ËøΩËπ§Âô®Â§ßÈáèÊôÆÂèäÔºå‰∏îÁù°Áú†ÂíåÈÅãÂãïÂ∞çÂÅ•Â∫∑Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂæûÁ©øÊà¥ÂºèË≥áÊñô‰∏≠Ë°çÁîüÂá∫ÂèØÊìç‰ΩúÁöÑÂÄã‰∫∫ÂåñË¶ãËß£‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÂõ†ÁÇ∫ÈÄôÊ®£ÂÅöÈúÄË¶ÅÂ∞çÈÄô‰∫õË≥áÊñôÈÄ≤Ë°åÈùûÂπ≥Âá°ÁöÑÈñãÊîæÂºèÂàÜÊûê„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ª£ÁêÜÁ®ãÂºèËøë‰æÜÂ¥õËµ∑ÔºåÂÆÉÂèØ‰ª•‰ΩøÁî®Â∑•ÂÖ∑Â∞ç‰∏ñÁïåÈÄ≤Ë°åÊé®ÁêÜÂíå‰∫íÂãïÔºåÊèê‰æõ‰∫ÜÂ§ßË¶èÊ®°ÂïüÁî®Ê≠§È°ûÂÄã‰∫∫ÂåñÂàÜÊûêÁöÑÁµï‰Ω≥Ê©üÊúÉ„ÄÇÁÑ∂ËÄåÔºåLLM ‰ª£ÁêÜÁ®ãÂºèÂú®ÂàÜÊûêÂÄã‰∫∫ÂÅ•Â∫∑ÊñπÈù¢ÁöÑÊáâÁî®‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÈñãÁôº„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂÄã‰∫∫ÂÅ•Â∫∑Ë¶ãËß£‰ª£ÁêÜÁ®ãÂºè (PHIA)ÔºåÈÄôÊòØ‰∏ÄÂÄã‰ª£ÁêÜÁ≥ªÁµ±ÔºåÂÆÉÂà©Áî®ÊúÄÂÖàÈÄ≤ÁöÑÁ®ãÂºèÁ¢ºÁîüÊàêÂíåË≥áË®äÊ™¢Á¥¢Â∑•ÂÖ∑‰æÜÂàÜÊûêÂíåË©ÆÈáã‰æÜËá™Á©øÊà¥ÂºèË£ùÁΩÆÁöÑË°åÁÇ∫ÂÅ•Â∫∑Ë≥áÊñô„ÄÇÊàëÂÄëÊï¥ÁêÜ‰∫ÜÂÖ©ÂÄãÂü∫ÂáÜÂïèÁ≠îË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë∂ÖÈÅé 4000 ÂÄãÂÅ•Â∫∑Ë¶ãËß£ÂïèÈ°å„ÄÇÊ†πÊìö 650 Â∞èÊôÇÁöÑ‰∫∫È°ûÂíåÂ∞àÂÆ∂Ë©ï‰º∞ÔºåÊàëÂÄëÁôºÁèæ PHIA ËÉΩÂ§†Ê∫ñÁ¢∫ÂõûÁ≠îË∂ÖÈÅé 84% ÁöÑ‰∫ãÂØ¶ÊÄßÊï∏Â≠óÂïèÈ°åÂíåË∂ÖÈÅé 83% ÁöÑÁæ§ÁúæÂ§ñÂåÖÈñãÊîæÂºèÂïèÈ°å„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂ∞ç‰øÉÈÄ≤ÂÖ®È´î‰∫∫Âè£ÁöÑË°åÁÇ∫ÂÅ•Â∫∑ÂÖ∑ÊúâÂΩ±ÈüøÔºåÊΩõÂú®Âú∞‰ΩøÂÄã‰∫∫ËÉΩÂ§†Ë©ÆÈáãËá™Â∑±ÁöÑÁ©øÊà¥ÂºèË≥áÊñôÔºå‰∏¶ÁÇ∫‰∏ÄÂÄãÁî±Ë≥áÊñôÈ©ÖÂãïÁöÑË¶ãËß£ÊâÄÂëäÁü•ÁöÑÂèØÂ≠òÂèñ„ÄÅÂÄã‰∫∫ÂåñÂÅ•Â∫∑È§äÁîüÊ≥ïÁöÑÊñ∞ÊôÇ‰ª£Èã™Ë∑Ø„ÄÇ

##### **A Large Language Model Pipeline for Breast Cancer Oncology**
2406.06455v2 by Tristen Pool, Dennis Trujillo

Large language models (LLMs) have demonstrated potential in the innovation of
many disciplines. However, how they can best be developed for oncology remains
underdeveloped. State-of-the-art OpenAI models were fine-tuned on a clinical
dataset and clinical guidelines text corpus for two important cancer treatment
factors, adjuvant radiation therapy and chemotherapy, using a novel Langchain
prompt engineering pipeline. A high accuracy (0.85+) was achieved in the
classification of adjuvant radiation therapy and chemotherapy for breast cancer
patients. Furthermore, a confidence interval was formed from observational data
on the quality of treatment from human oncologists to estimate the proportion
of scenarios in which the model must outperform the original oncologist in its
treatment prediction to be a better solution overall as 8.2% to 13.3%. Due to
indeterminacy in the outcomes of cancer treatment decisions, future
investigation, potentially a clinical trial, would be required to determine if
this threshold was met by the models. Nevertheless, with 85% of U.S. cancer
patients receiving treatment at local community facilities, these kinds of
models could play an important part in expanding access to quality care with
outcomes that lie, at minimum, close to a human oncologist.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁ§∫Âá∫Âú®Ë®±Â§öÂ≠∏ÁßëÂâµÊñ∞ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂ¶Ç‰ΩïÊâçËÉΩÊúÄ‰Ω≥ÈñãÁôºÂÆÉÂÄë‰ª•ÊáâÁî®ÊñºËÖ´Áò§Â≠∏‰ªçÊú™ÊàêÁÜü„ÄÇÊúÄÂÖàÈÄ≤ÁöÑ OpenAI Ê®°ÂûãÁ∂ìÈÅéÂæÆË™øÔºåÈáùÂ∞çËá®Â∫äÊï∏ÊìöÈõÜÂíåËá®Â∫äÊåáÂçóÊñáÊú¨Ë™ûÊñôÂ∫´Ôºå‰ΩøÁî®Êñ∞Á©éÁöÑ Langchain ÊèêÁ§∫Â∑•Á®ãÁÆ°ÈÅìÔºåÈáùÂ∞çÂÖ©ÂÄãÈáçË¶ÅÁöÑÁôåÁóáÊ≤ªÁôÇÂõ†Á¥†ÔºåËºîÂä©ÊîæÂ∞ÑÊ≤ªÁôÇÂíåÂåñÁôÇ„ÄÇÂú®‰π≥ËÖ∫ÁôåÊÇ£ËÄÖÁöÑËºîÂä©ÊîæÂ∞ÑÊ≤ªÁôÇÂíåÂåñÁôÇÂàÜÈ°û‰∏≠ÔºåÈÅîÂà∞‰∫ÜÂæàÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶ (0.85+)„ÄÇÊ≠§Â§ñÔºåÊ†πÊìö‰∫∫È°ûËÖ´Áò§Â≠∏ÂÆ∂Â∞çÊ≤ªÁôÇÂìÅË≥™ÁöÑËßÄÂØüÊï∏ÊìöÂΩ¢Êàê‰∫Ü‰∏ÄÂÄã‰ø°ÂøÉÂçÄÈñìÔºå‰ª•‰º∞Ë®àÊ®°ÂûãÂøÖÈ†àÂú®ÂÖ∂Ê≤ªÁôÇÈ†êÊ∏¨‰∏≠ÂÑ™ÊñºÂéüÂßãËÖ´Áò§Â≠∏ÂÆ∂ÁöÑÊÉÖÂ¢ÉÊØî‰æãÔºåÊâçËÉΩÊï¥È´î‰∏äÊàêÁÇ∫Êõ¥Â•ΩÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁÇ∫ 8.2% Ëá≥ 13.3%„ÄÇÁî±ÊñºÁôåÁóáÊ≤ªÁôÇÊ±∫Á≠ñÁµêÊûúÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•Ë™øÊü•ÔºåÂèØËÉΩÊòØËá®Â∫äË©¶È©óÔºå‰ª•Á¢∫ÂÆöÊ®°ÂûãÊòØÂê¶ÈÅîÂà∞Ê≠§ÈñÄÊ™ª„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁî±Êñº 85% ÁöÑÁæéÂúãÁôåÁóáÊÇ£ËÄÖÂú®Áï∂Âú∞Á§æÂçÄË®≠ÊñΩÊé•ÂèóÊ≤ªÁôÇÔºåÈÄô‰∫õÊ®°ÂûãÂèØ‰ª•Âú®Êì¥Â§ßÁç≤ÂæóÂÑ™Ë≥™ÁÖßË≠∑ÁöÑÊ©üÊúÉ‰∏≠ÊâÆÊºîÈáçË¶ÅËßíËâ≤ÔºåÂÖ∂ÁµêÊûúËá≥Â∞ëÊé•Ëøë‰∫∫È°ûËÖ´Áò§Â≠∏ÂÆ∂„ÄÇ

##### **Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain**
2406.06435v1 by Brian Hu, Bill Ray, Alice Leung, Amy Summerville, David Joy, Christopher Funk, Arslan Basharat

In difficult decision-making scenarios, it is common to have conflicting
opinions among expert human decision-makers as there may not be a single right
answer. Such decisions may be guided by different attributes that can be used
to characterize an individual's decision. We introduce a novel dataset for
medical triage decision-making, labeled with a set of decision-maker attributes
(DMAs). This dataset consists of 62 scenarios, covering six different DMAs,
including ethical principles such as fairness and moral desert. We present a
novel software framework for human-aligned decision-making by utilizing these
DMAs, paving the way for trustworthy AI with better guardrails. Specifically,
we demonstrate how large language models (LLMs) can serve as ethical
decision-makers, and how their decisions can be aligned to different DMAs using
zero-shot prompting. Our experiments focus on different open-source models with
varying sizes and training techniques, such as Falcon, Mistral, and Llama 2.
Finally, we also introduce a new form of weighted self-consistency that
improves the overall quantified performance. Our results provide new research
directions in the use of LLMs as alignable decision-makers. The dataset and
open-source software are publicly available at:
https://github.com/ITM-Kitware/llm-alignable-dm.

ÊëòË¶ÅÔºöÂú®Âõ∞Èõ£ÁöÑÊ±∫Á≠ñÊÉÖÂ¢É‰∏≠ÔºåÂ∞àÂÆ∂‰∫∫È°ûÊ±∫Á≠ñËÄÖ‰πãÈñìÁî¢ÁîüÁõ∏‰∫íË°ùÁ™ÅÁöÑÊÑèË¶ãÊòØÂæàÂ∏∏Ë¶ãÁöÑÔºåÂõ†ÁÇ∫ÂèØËÉΩÊ≤íÊúâÂñÆ‰∏ÄÁöÑÊ≠£Á¢∫Á≠îÊ°à„ÄÇÊ≠§È°ûÊ±∫Á≠ñÂèØËÉΩÂèóÂà∞Áî®ÊñºÊèèËø∞ÂÄã‰∫∫Ê±∫Á≠ñÁöÑ‰∏çÂêåÂ±¨ÊÄßÁöÑÊåáÂ∞é„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÈÜ´ÁôÇÂàÜÊµÅÊ±∫Á≠ñÂà∂ÂÆöË≥áÊñôÈõÜÔºå‰∏¶Ê®ôË®ò‰∫Ü‰∏ÄÁµÑÊ±∫Á≠ñËÄÖÂ±¨ÊÄß (DMA)„ÄÇÊ≠§Ë≥áÊñôÈõÜÂåÖÂê´ 62 ÂÄãÊÉÖÂ¢ÉÔºåÊ∂µËìãÂÖ≠ÂÄã‰∏çÂêåÁöÑ DMAÔºåÂåÖÊã¨ÂÖ¨Âπ≥ÊÄßÂíåÈÅìÂæ∑Ê≤ôÊº†Á≠âÈÅìÂæ∑ÂéüÂâá„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑËªüÈ´îÊû∂ÊßãÔºåÁî®ÊñºÈÄèÈÅéÂà©Áî®ÈÄô‰∫õ DMA ÈÄ≤Ë°åËàá‰∫∫È°û‰∏ÄËá¥ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÔºåÁÇ∫ÂÖ∑ÊúâÊõ¥Â•ΩË≠∑Ê¨ÑÁöÑÂÄºÂæó‰ø°Ë≥¥ÁöÑ AI Èã™Âπ≥ÈÅìË∑Ø„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â¶Ç‰Ωï‰ΩúÁÇ∫ÈÅìÂæ∑Ê±∫Á≠ñËÄÖÔºå‰ª•ÂèäÂ¶Ç‰Ωï‰ΩøÁî®Èõ∂Ê¨°ÊèêÁ§∫Â∞áÂÖ∂Ê±∫Á≠ñËàá‰∏çÂêåÁöÑ DMA Â∞çÈΩä„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈáçÈªûÈóúÊ≥®ÂÖ∑Êúâ‰∏çÂêåÂ§ßÂ∞èÂíåË®ìÁ∑¥ÊäÄË°ìÁöÑ‰∏çÂêåÈñãÊ∫êÊ®°ÂûãÔºå‰æãÂ¶Ç Falcon„ÄÅMistral Âíå Llama 2„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂä†Ê¨äËá™‰∏ÄËá¥ÊÄßÂΩ¢ÂºèÔºåÂÆÉÊîπÈÄ≤‰∫ÜÊï¥È´îÈáèÂåñÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁÇ∫ LLM ‰ΩúÁÇ∫ÂèØÂ∞çÈΩäÊ±∫Á≠ñËÄÖÁöÑ‰ΩøÁî®Êèê‰æõ‰∫ÜÊñ∞ÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇË≥áÊñôÈõÜÂíåÈñãÊ∫êËªüÈ´îÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆÂÖ¨ÈñãÂèñÂæóÔºö
https://github.com/ITM-Kitware/llm-alignable-dm„ÄÇ

##### **Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models**
2406.06372v1 by Marek Wodzinski, Kamil Kwarciak, Mateusz Daniol, Daria Hemmerling

Modeling and manufacturing of personalized cranial implants are important
research areas that may decrease the waiting time for patients suffering from
cranial damage. The modeling of personalized implants may be partially
automated by the use of deep learning-based methods. However, this task suffers
from difficulties with generalizability into data from previously unseen
distributions that make it difficult to use the research outcomes in real
clinical settings. Due to difficulties with acquiring ground-truth annotations,
different techniques to improve the heterogeneity of datasets used for training
the deep networks have to be considered and introduced. In this work, we
present a large-scale study of several augmentation techniques, varying from
classical geometric transformations, image registration, variational
autoencoders, and generative adversarial networks, to the most recent advances
in latent diffusion models. We show that the use of heavy data augmentation
significantly increases both the quantitative and qualitative outcomes,
resulting in an average Dice Score above 0.94 for the SkullBreak and above 0.96
for the SkullFix datasets. Moreover, we show that the synthetically augmented
network successfully reconstructs real clinical defects. The work is a
considerable contribution to the field of artificial intelligence in the
automatic modeling of personalized cranial implants.

ÊëòË¶ÅÔºöÂÆ¢Ë£ΩÂåñÈ°±È™®Ê§çÂÖ•Áâ©ÁöÑÂª∫Ê®°ÂíåË£ΩÈÄ†ÊòØÈáçË¶ÅÁöÑÁ†îÁ©∂È†òÂüüÔºåÂèØËÉΩÊúÉÁ∏ÆÁü≠ÈÅ≠ÂèóÈ°±È™®ÊêçÂÇ∑ÊÇ£ËÄÖÁöÑÁ≠âÂæÖÊôÇÈñì„ÄÇÂÆ¢Ë£ΩÂåñÊ§çÂÖ•Áâ©ÁöÑÂª∫Ê®°ÂèØ‰ª•ÈÄèÈÅé‰ΩøÁî®Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ï‰æÜÈÉ®ÂàÜËá™ÂãïÂåñ„ÄÇÁÑ∂ËÄåÔºåÊ≠§‰ªªÂãôÊúÉÂèóÂà∞ÂÖàÂâçÊú™Ë¶ãÈÅéÂàÜ‰ΩàË≥áÊñôÁöÑÊ¶ÇÊã¨ÊÄßÂõ∞Èõ£ÂΩ±ÈüøÔºåÈÄô‰ΩøÂæóÂú®ÂØ¶ÈöõËá®Â∫äÁí∞Â¢É‰∏≠‰ΩøÁî®Á†îÁ©∂ÁµêÊûúËÆäÂæóÂõ∞Èõ£„ÄÇÁî±ÊñºÈõ£‰ª•ÂèñÂæóÂú∞Èù¢ÂØ¶Ê≥ÅË®ªËß£ÔºåÂøÖÈ†àËÄÉÈáè‰∏¶ÂºïÂÖ•‰∏çÂêåÁöÑÊäÄË°ì‰æÜÊîπÂñÑÁî®ÊñºË®ìÁ∑¥Ê∑±Â∫¶Á∂≤Ë∑ØÁöÑË≥áÊñôÈõÜÁï∞Ë≥™ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Â§öÁ®ÆÊì¥ÂÖÖÊäÄË°ìÁöÑÂ§ßË¶èÊ®°Á†îÁ©∂ÔºåÂæûÂè§ÂÖ∏Âπæ‰ΩïËΩâÊèõ„ÄÅÂΩ±ÂÉèÈÖçÊ∫ñ„ÄÅËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô®ÂíåÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑ØÔºåÂà∞ÊΩõÂú®Êì¥Êï£Ê®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÊàëÂÄëÈ°ØÁ§∫‰ΩøÁî®Â§ßÈáèË≥áÊñôÊì¥ÂÖÖÊúÉÈ°ØËëóÂ¢ûÂä†ÈáèÂåñÂíåË≥™ÂåñÁµêÊûúÔºåÂ∞éËá¥ SkullBreak ÁöÑÂπ≥Âùá Dice ÂàÜÊï∏È´òÊñº 0.94ÔºåËÄå SkullFix Ë≥áÊñôÈõÜÂâáÈ´òÊñº 0.96„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ°ØÁ§∫ÂêàÊàêÊì¥ÂÖÖÁ∂≤Ë∑ØÊàêÂäüÈáçÂª∫ÁúüÂØ¶ÁöÑËá®Â∫äÁº∫Èô∑„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫‰∫∫Â∑•Êô∫ÊÖßÂú®ÂÆ¢Ë£ΩÂåñÈ°±È™®Ê§çÂÖ•Áâ©Ëá™ÂãïÂª∫Ê®°È†òÂüüÂÅöÂá∫‰∫ÜÈáçÂ§ßË≤¢Áçª„ÄÇ

##### **MedExQA: Medical Question Answering Benchmark with Multiple Explanations**
2406.06331v1 by Yunsoo Kim, Jinge Wu, Yusuf Abdulle, Honghan Wu

This paper introduces MedExQA, a novel benchmark in medical
question-answering, to evaluate large language models' (LLMs) understanding of
medical knowledge through explanations. By constructing datasets across five
distinct medical specialties that are underrepresented in current datasets and
further incorporating multiple explanations for each question-answer pair, we
address a major gap in current medical QA benchmarks which is the absence of
comprehensive assessments of LLMs' ability to generate nuanced medical
explanations. Our work highlights the importance of explainability in medical
LLMs, proposes an effective methodology for evaluating models beyond
classification accuracy, and sheds light on one specific domain, speech
language pathology, where current LLMs including GPT4 lack good understanding.
Our results show generation evaluation with multiple explanations aligns better
with human assessment, highlighting an opportunity for a more robust automated
comprehension assessment for LLMs. To diversify open-source medical LLMs
(currently mostly based on Llama2), this work also proposes a new medical
model, MedPhi-2, based on Phi-2 (2.7B). The model outperformed medical LLMs
based on Llama2-70B in generating explanations, showing its effectiveness in
the resource-constrained medical domain. We will share our benchmark datasets
and the trained model.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁªç‰∫Ü MedExQAÔºåËøôÊòØ‰∏Ä‰∏™ÂåªÂ≠¶ÈóÆÁ≠îÈ¢ÜÂüüÁöÑÊñ∞Âü∫ÂáÜÔºåÁî®‰∫éÈÄöËøáËß£ÈáäËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂØπÂåªÂ≠¶Áü•ËØÜÁöÑÁêÜËß£„ÄÇÈÄöËøáÂú®ÂΩìÂâçÊï∞ÊçÆÈõÜ‰∏≠ÁöÑ‰∫î‰∏™‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑ‰∏çÂêåÂåªÂ≠¶‰∏ì‰∏öÈ¢ÜÂüüÊûÑÂª∫Êï∞ÊçÆÈõÜÔºåÂπ∂‰∏∫ÊØè‰∏™ÈóÆÈ¢ò-Á≠îÊ°àÂØπËøõ‰∏ÄÊ≠•Á∫≥ÂÖ•Â§ö‰∏™Ëß£ÈáäÔºåÊàë‰ª¨Ëß£ÂÜ≥‰∫ÜÂΩìÂâçÂåªÂ≠¶ÈóÆÁ≠îÂü∫ÂáÜ‰∏≠ÁöÑ‰∏ÄÂ§ßÁº∫Èô∑ÔºåÂç≥Áº∫‰πèÂØπ LLM ÁîüÊàêÁªÜÂæÆÂåªÂ≠¶Ëß£ÈáäÁöÑËÉΩÂäõÁöÑÂÖ®Èù¢ËØÑ‰º∞„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÂº∫Ë∞É‰∫ÜÂèØËß£ÈáäÊÄßÂú®ÂåªÂ≠¶ LLM ‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçË∂ÖË∂äÂàÜÁ±ªÂáÜÁ°ÆÂ∫¶Êù•ËØÑ‰º∞Ê®°ÂûãÁöÑÊúâÊïàÊñπÊ≥ïÔºåÂπ∂ÈòêÊòé‰∫Ü‰∏Ä‰∏™ÁâπÂÆöÈ¢ÜÂüüÔºåÂç≥ËØ≠Ë®ÄÁóÖÁêÜÂ≠¶ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ GPT4 Âú®ÂÜÖÁöÑÂΩìÂâç LLM Áº∫‰πèËâØÂ•ΩÁöÑÁêÜËß£„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®Â§ö‰∏™Ëß£ÈáäËøõË°åÁîüÊàêËØÑ‰º∞‰∏é‰∫∫Á±ªËØÑ‰º∞Êõ¥‰∏ÄËá¥ÔºåÁ™ÅÊòæ‰∫ÜÂØπ LLM ËøõË°åÊõ¥Á®≥ÂÅ•ÁöÑËá™Âä®ÁêÜËß£ËØÑ‰º∞ÁöÑÊú∫‰ºö„ÄÇ‰∏∫‰∫Ü‰ΩøÂºÄÊ∫êÂåªÂ≠¶ LLM Â§öÊ†∑ÂåñÔºàÁõÆÂâç‰∏ªË¶ÅÂü∫‰∫é Llama2ÔºâÔºåËøôÈ°πÂ∑•‰ΩúËøòÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂåªÂ≠¶Ê®°Âûã MedPhi-2ÔºåÂü∫‰∫é Phi-2 (2.7B)„ÄÇËØ•Ê®°ÂûãÂú®ÁîüÊàêËß£ÈáäÊñπÈù¢‰ºò‰∫éÂü∫‰∫é Llama2-70B ÁöÑÂåªÂ≠¶ LLMÔºåÊòæÁ§∫‰∫ÜÂÖ∂Âú®ËµÑÊ∫êÂèóÈôêÁöÑÂåªÂ≠¶È¢ÜÂüüÁöÑÊúâÊïàÊÄß„ÄÇÊàë‰ª¨Â∞ÜÂàÜ‰∫´Êàë‰ª¨ÁöÑÂü∫ÂáÜÊï∞ÊçÆÈõÜÂíåËÆ≠ÁªÉÂ•ΩÁöÑÊ®°Âûã„ÄÇ

##### **BrainChat: Decoding Semantic Information from fMRI using Vision-language Pretrained Models**
2406.07584v1 by Wanaiu Huang

Semantic information is vital for human interaction, and decoding it from
brain activity enables non-invasive clinical augmentative and alternative
communication. While there has been significant progress in reconstructing
visual images, few studies have focused on the language aspect. To address this
gap, leveraging the powerful capabilities of the decoder-based vision-language
pretrained model CoCa, this paper proposes BrainChat, a simple yet effective
generative framework aimed at rapidly accomplishing semantic information
decoding tasks from brain activity, including fMRI question answering and fMRI
captioning. BrainChat employs the self-supervised approach of Masked Brain
Modeling to encode sparse fMRI data, obtaining a more compact embedding
representation in the latent space. Subsequently, BrainChat bridges the gap
between modalities by applying contrastive loss, resulting in aligned
representations of fMRI, image, and text embeddings. Furthermore, the fMRI
embeddings are mapped to the generative Brain Decoder via cross-attention
layers, where they guide the generation of textual content about fMRI in a
regressive manner by minimizing caption loss. Empirically, BrainChat exceeds
the performance of existing state-of-the-art methods in the fMRI captioning
task and, for the first time, implements fMRI question answering. Additionally,
BrainChat is highly flexible and can achieve high performance without image
data, making it better suited for real-world scenarios with limited data.

ÊëòË¶ÅÔºöË™ûÁæ©Ë≥áË®äÂ∞çÊñº‰∫∫È°û‰∫íÂãïËá≥ÈóúÈáçË¶ÅÔºåËÄåÂæûÂ§ßËÖ¶Ê¥ªÂãï‰∏≠Ëß£Á¢ºË™ûÁæ©Ë≥áË®äÂâáËÉΩÂØ¶ÁèæÈùû‰æµÂÖ•ÊÄßÁöÑËá®Â∫äÊì¥Â¢ûÂíåÊõø‰ª£Ê∫ùÈÄö„ÄÇÂÑòÁÆ°Âú®ÈáçÂª∫Ë¶ñË¶∫ÂΩ±ÂÉèÊñπÈù¢Â∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜÈÆÆÂ∞ëÊúâÁ†îÁ©∂ÈóúÊ≥®Ë™ûË®ÄÈù¢Âêë„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãËêΩÂ∑ÆÔºåÊú¨ÊñáÂà©Áî®Á∑®Á¢ºÂô®ÁÇ∫Âü∫Á§éÁöÑË¶ñË¶∫Ë™ûË®ÄÈ†êË®ìÁ∑¥Ê®°Âûã CoCa ÁöÑÂº∑Â§ßÂäüËÉΩÔºåÊèêÂá∫ BrainChatÔºåÈÄôÊòØ‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÁîüÊàêÂºèÊû∂ÊßãÔºåÊó®Âú®Âø´ÈÄüÂÆåÊàêÂ§ßËÖ¶Ê¥ªÂãïÁöÑË™ûÁæ©Ë≥áË®äËß£Á¢º‰ªªÂãôÔºåÂåÖÊã¨ fMRI ÂïèÁ≠îÂíå fMRI Ê®ôÈ°å„ÄÇBrainChat Êé°Áî®ÈÅÆÁΩ©Â§ßËÖ¶Âª∫Ê®°ÁöÑËá™ÊàëÁõ£Áù£ÊñπÊ≥ï‰æÜÁ∑®Á¢ºÁ®ÄÁñèÁöÑ fMRI Ë≥áÊñôÔºåÂú®ÊΩõÂú®Á©∫Èñì‰∏≠ÂèñÂæóÊõ¥Á∑äÊπäÁöÑÂµåÂÖ•Ë°®Á§∫„ÄÇÈö®ÂæåÔºåBrainChat ÈÄèÈÅéÂ•óÁî®Â∞çÊØîÊêçÂ§±‰æÜÂΩåÂêàÊ®°ÊÖã‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÁî¢Áîü fMRI„ÄÅÂΩ±ÂÉèÂíåÊñáÂ≠óÂµåÂÖ•ÁöÑÂ∞çÈΩäË°®Á§∫„ÄÇÊ≠§Â§ñÔºåfMRI ÂµåÂÖ•ÈÄèÈÅé‰∫§ÂèâÊ≥®ÊÑèÂäõÂ±§Â∞çÊáâÂà∞ÁîüÊàêÂºèÂ§ßËÖ¶Ëß£Á¢ºÂô®ÔºåÂÖ∂‰∏≠ÂÆÉÂÄë‰ª•ÈÅûÊ∏õÊñπÂºèÂºïÂ∞éÁî¢ÁîüÊúâÈóú fMRI ÁöÑÊñáÂ≠óÂÖßÂÆπÔºåËóâÊ≠§ÊúÄÂ∞èÂåñÊ®ôÈ°åÊêçÂ§±„ÄÇÊ†πÊìöÁ∂ìÈ©óÔºåBrainChat Âú® fMRI Ê®ôÈ°å‰ªªÂãô‰∏≠Ë∂ÖË∂äÁèæÊúâÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁöÑÊïàËÉΩÔºå‰∏¶È¶ñÊ¨°ÂØ¶‰Ωú fMRI ÂïèÁ≠î„ÄÇÊ≠§Â§ñÔºåBrainChat ÂÖ∑ÊúâÈ´òÂ∫¶ÂΩàÊÄßÔºå‰∏îÁÑ°ÈúÄÂΩ±ÂÉèË≥áÊñôÂ∞±ËÉΩÈÅîÊàêÈ´òÊïàËÉΩÔºå‰ΩøÂÖ∂Êõ¥ÈÅ©ÂêàË≥áÊñôÊúâÈôêÁöÑÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ„ÄÇ

##### **A Dual-View Approach to Classifying Radiology Reports by Co-Training**
2406.05995v1 by Yutong Han, Yan Yuan, Lili Mou

Radiology report analysis provides valuable information that can aid with
public health initiatives, and has been attracting increasing attention from
the research community. In this work, we present a novel insight that the
structure of a radiology report (namely, the Findings and Impression sections)
offers different views of a radiology scan. Based on this intuition, we further
propose a co-training approach, where two machine learning models are built
upon the Findings and Impression sections, respectively, and use each other's
information to boost performance with massive unlabeled data in a
semi-supervised manner. We conducted experiments in a public health
surveillance study, and results show that our co-training approach is able to
improve performance using the dual views and surpass competing supervised and
semi-supervised methods.

ÊëòË¶ÅÔºöÊîæÂ∞ÑÂ≠∏Â†±ÂëäÂàÜÊûêÊèê‰æõÊúâÂÉπÂÄºÁöÑË≥áË®äÔºåÊúâÂä©ÊñºÂÖ¨ÂÖ±Ë°õÁîüË®àÁï´Ôºå‰∏¶Â∑≤Âê∏ÂºïÁ†îÁ©∂Á§æÁæ§Ë∂ä‰æÜË∂äÂ§öÁöÑÈóúÊ≥®„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑË¶ãËß£ÔºåÂç≥ÊîæÂ∞ÑÂ≠∏Â†±ÂëäÁöÑÁµêÊßãÔºàÂç≥„ÄåÁôºÁèæ„ÄçÂíå„ÄåÂç∞Ë±°„ÄçÈÉ®ÂàÜÔºâÊèê‰æõÊîæÂ∞ÑÂ≠∏ÊéÉÊèèÁöÑ‰∏çÂêåËßÄÈªû„ÄÇÂü∫ÊñºÈÄôÂÄãÁõ¥Ë¶∫ÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∏ÄÂÄãÂÖ±ÂêåË®ìÁ∑¥ÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂÖ©ÂÄãÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂàÜÂà•Âª∫Á´ãÂú®„ÄåÁôºÁèæ„ÄçÂíå„ÄåÂç∞Ë±°„ÄçÈÉ®ÂàÜ‰πã‰∏äÔºå‰∏¶‰ΩøÁî®ÂΩºÊ≠§ÁöÑË≥áË®ä‰ª•Â§ßÈáèÊú™Ê®ôË®òË≥áÊñô‰ª•ÂçäÁõ£Áù£ÁöÑÊñπÂºèÊèêÂçáÊïàËÉΩ„ÄÇÊàëÂÄëÂú®ÂÖ¨ÂÖ±Ë°õÁîüÁõ£Ê∏¨Á†îÁ©∂‰∏≠ÈÄ≤Ë°åÂØ¶È©óÔºåÁµêÊûúÈ°ØÁ§∫ÊàëÂÄëÁöÑÂÖ±ÂêåË®ìÁ∑¥ÊñπÊ≥ïËÉΩÂ§†‰ΩøÁî®ÈõôÈáçËßÄÈªû‰æÜÊèêÂçáÊïàËÉΩÔºå‰∏¶Ë∂ÖË∂äÁ´∂Áà≠ÁöÑÁõ£Áù£ÂºèÂíåÂçäÁõ£Áù£ÂºèÊñπÊ≥ï„ÄÇ

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

ÊëòË¶ÅÔºöÂøÉÁêÜÂÅ•Â∫∑ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖË§áÈõú‰∏îÊôÆÈÅçÁöÑÂÖ®ÁêÉÊåëÊà∞ÔºåÂΩ±Èüø‰∫ÜÊï∏ÁôæËê¨‰∫∫ÁöÑÁîüÊ¥ªÔºå‰∏¶Á∂ìÂ∏∏Â∞éËá¥Âö¥ÈáçÁöÑÂæåÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂæπÂ∫ïÁöÑË™øÊü•Ôºå‰ª•Êé¢Á¥¢Êï∏ÊìöÁßëÂ≠∏„ÄÅ‰∫∫Â∑•Êô∫ÊÖßÂíåÂøÉÁêÜ‰øùÂÅ•ÁöÑ‰∫§ÈõÜÔºåÈáçÈªûÈóúÊ≥®ÈÄöÈÅéÁ∑ö‰∏äÁ§æ‰∫§Â™íÈ´î (OSM) ÈÄ≤Ë°åÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨ÁöÑÊúÄÊñ∞ÁôºÂ±ï„ÄÇÂæàÂ§ß‰∏ÄÈÉ®ÂàÜ‰∫∫Âè£Á©çÊ•µÂèÉËàá OSM Âπ≥Âè∞ÔºåÂâµÈÄ†‰∫Ü‰∏ÄÂÄãÈæêÂ§ßÁöÑ‰∫∫Âì°Ë≥áÊñôÂ∫´ÔºåÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÂàÜÊûêÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÇ≥Áµ±ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÅÊúÄÂÖàÈÄ≤ÁöÑË≥áÊñôÂíå AI È©ÖÂãïÁöÑÁ†îÁ©∂Ôºå‰ª•ÂèäÂøÉÁêÜ‰øùÂÅ•‰∏≠ÂèØËß£Èáã AI (XAI) Ê®°ÂûãÁöÑÂá∫Áèæ„ÄÇÊàëÂÄëÂõûÈ°ß‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºåÁâπÂà•ÊòØÈÇ£‰∫õÂü∫ÊñºÁèæ‰ª£Ê∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÂêåÊôÇÂº∑Ë™ø‰∫ÜÈÜ´ÁôÇ‰øùÂÅ• AI Ê®°Âûã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÂØ¶È©óË®≠Ë®àÈÉ®ÂàÜÊèê‰æõ‰∫ÜÂ∞çÊôÆÈÅçÂÅöÊ≥ïÁöÑË¶ãËß£ÔºåÂåÖÊã¨ÂèØÁî®ÁöÑË≥áÊñôÈõÜÂíåË©ï‰º∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÈÇÑÊâæÂá∫Ë©≤È†òÂüüÁöÑ‰∏ªË¶ÅÂïèÈ°åÂíåÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊúâÂ∏åÊúõÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêë„ÄÇÁî±ÊñºÂøÉÁêÜÂÅ•Â∫∑Ê±∫Á≠ñÈúÄË¶ÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈÅìÂæ∑ËÄÉÈáèÔºåÊú¨ÊñáÊúâÂä©ÊñºÊé®ÈÄ≤ÂøÉÁêÜ‰øùÂÅ•‰∏≠ÈÄèÈÅéÁ§æ‰∫§Â™íÈ´îÊé®ÈÄ≤ XAI ÁöÑÊåÅÁ∫åË®éË´ñ„ÄÇÈÄôË£°ÊèêÂá∫ÁöÑÂÖ®Èù¢Ê¶ÇËø∞Êó®Âú®ÂºïÂ∞éÁ†îÁ©∂‰∫∫Âì°„ÄÅÂæûÊ•≠‰∫∫Âì°ÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖÁôºÂ±ïÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨È†òÂüü„ÄÇ

##### **Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context**
2406.05972v1 by Jingru Jia, Zehua Yuan, Junhao Pan, Paul McNamara, Deming Chen

When making decisions under uncertainty, individuals often deviate from
rational behavior, which can be evaluated across three dimensions: risk
preference, probability weighting, and loss aversion. Given the widespread use
of large language models (LLMs) in decision-making processes, it is crucial to
assess whether their behavior aligns with human norms and ethical expectations
or exhibits potential biases. Several empirical studies have investigated the
rationality and social behavior performance of LLMs, yet their internal
decision-making tendencies and capabilities remain inadequately understood.
This paper proposes a framework, grounded in behavioral economics, to evaluate
the decision-making behaviors of LLMs. Through a multiple-choice-list
experiment, we estimate the degree of risk preference, probability weighting,
and loss aversion in a context-free setting for three commercial LLMs:
ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro. Our results reveal that
LLMs generally exhibit patterns similar to humans, such as risk aversion and
loss aversion, with a tendency to overweight small probabilities. However,
there are significant variations in the degree to which these behaviors are
expressed across different LLMs. We also explore their behavior when embedded
with socio-demographic features, uncovering significant disparities. For
instance, when modeled with attributes of sexual minority groups or physical
disabilities, Claude-3-Opus displays increased risk aversion, leading to more
conservative choices. These findings underscore the need for careful
consideration of the ethical implications and potential biases in deploying
LLMs in decision-making scenarios. Therefore, this study advocates for
developing standards and guidelines to ensure that LLMs operate within ethical
boundaries while enhancing their utility in complex decision-making
environments.

ÊëòË¶ÅÔºö<paragraph>Âú®‰∏çÁ¢∫ÂÆöÊÉÖÊ≥Å‰∏ãÂÅöÂá∫Ê±∫Á≠ñÊôÇÔºåÂÄã‰∫∫ÈÄöÂ∏∏ÊúÉÂÅèÈõ¢ÁêÜÊÄßË°åÁÇ∫ÔºåÈÄôÂèØ‰ª•Áî®‰∏âÂÄãÈù¢Âêë‰æÜË©ï‰º∞ÔºöÈ¢®Èö™ÂÅèÂ•Ω„ÄÅÊ©üÁéáÂä†Ê¨äÂíåÊêçÂ§±Ë¶èÈÅø„ÄÇÈëíÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ê±∫Á≠ñÈÅéÁ®ã‰∏≠Ë¢´Âª£Ê≥õ‰ΩøÁî®ÔºåÂõ†Ê≠§Ë©ï‰º∞ÂÖ∂Ë°åÁÇ∫ÊòØÂê¶Á¨¶Âêà‰∫∫È°ûË¶èÁØÑÂíåÈÅìÂæ∑ÊúüÊúõÊàñË°®ÁèæÂá∫ÊΩõÂú®ÂÅèË¶ãËá≥ÈóúÈáçË¶Å„ÄÇÂ§öÈ†ÖÂØ¶Ë≠âÁ†îÁ©∂Ë™øÊü•‰∫Ü LLM ÁöÑÁêÜÊÄßËàáÁ§æÊúÉË°åÁÇ∫Ë°®ÁèæÔºå‰ΩÜÂÖ∂ÂÖßÈÉ®Ê±∫Á≠ñÂÇæÂêëÂíåËÉΩÂäõ‰ªçÊú™Ë¢´ÂÖÖÂàÜÁêÜËß£„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË°åÁÇ∫Á∂ìÊøüÂ≠∏ÁöÑÊû∂ÊßãÔºåÁî®ÊñºË©ï‰º∞ LLM ÁöÑÊ±∫Á≠ñË°åÁÇ∫„ÄÇÈÄèÈÅéÂ§öÈÅ∏È°åÂØ¶È©óÔºåÊàëÂÄë‰º∞Ë®à‰∫Ü‰∏âÂÄãÂïÜÊ•≠ LLMÔºöChatGPT-4.0-Turbo„ÄÅClaude-3-Opus Âíå Gemini-1.0-pro Âú®ÁÑ°ËÉåÊôØË®≠ÂÆö‰∏ãÁöÑÈ¢®Èö™ÂÅèÂ•Ω„ÄÅÊ©üÁéáÂä†Ê¨äÂíåÊêçÂ§±Ë¶èÈÅøÁ®ãÂ∫¶„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåLLM ÈÄöÂ∏∏Ë°®ÁèæÂá∫È°û‰ººÊñº‰∫∫È°ûÁöÑÊ®°ÂºèÔºå‰æãÂ¶ÇÈ¢®Èö™Ë¶èÈÅøÂíåÊêçÂ§±Ë¶èÈÅøÔºå‰∏¶ÂÇæÂêëÊñºÈ´ò‰º∞Â∞èÊ©üÁéá„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õË°åÁÇ∫Âú®‰∏çÂêå LLM ‰∏≠Ë°®ÁèæÁöÑÁ®ãÂ∫¶Â≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄë‰πüÊé¢Ë®é‰∫ÜÂÆÉÂÄëÂú®ÂµåÂÖ•Á§æÊúÉ‰∫∫Âè£ÁâπÂæµÊôÇÁöÑË°åÁÇ∫ÔºåÁôºÁèæ‰∫ÜÈ°ØËëóÁöÑÂ∑ÆÁï∞„ÄÇ‰æãÂ¶ÇÔºåÁï∂‰ª•ÊÄßÂ∞ëÊï∏Áæ§È´îÊàñË∫´È´îÊÆòÁñæÁöÑÂ±¨ÊÄßÂª∫Ê®°ÊôÇÔºåClaude-3-Opus ÊúÉË°®ÁèæÂá∫Êõ¥È´òÁöÑÈ¢®Èö™Ë¶èÈÅøÔºåÂ∞éËá¥Êõ¥‰øùÂÆàÁöÑÈÅ∏Êìá„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÂú®Ê±∫Á≠ñÂ†¥ÊôØ‰∏≠ÈÉ®ÁΩ≤ LLM ÊôÇÔºåÈúÄË¶Å‰ªîÁ¥∞ËÄÉÈáèÂÖ∂ÈÅìÂæ∑ÊÑèÊ∂µÂíåÊΩõÂú®ÂÅèË¶ã„ÄÇÂõ†Ê≠§ÔºåÊú¨Á†îÁ©∂‰∏ªÂºµÂà∂ÂÆöÊ®ôÊ∫ñÂíåÊ∫ñÂâáÔºå‰ª•Á¢∫‰øù LLM Âú®ÈÅìÂæ∑ÁïåÈôêÂÖßÈÅã‰ΩúÔºåÂêåÊôÇÊèêÂçáÂÖ∂Âú®Ë§áÈõúÊ±∫Á≠ñÁí∞Â¢É‰∏≠ÁöÑÊïàÁî®„ÄÇ</paragraph>

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁôÇÁÖßË≠∑‰∏≠ÈúÄË¶Å AI ËºîÂä©ÁöÑËá®Â∫äË®∫Êñ∑„ÄÇÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏î‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂΩ±ÂÉèÂàÜÊûê„ÄÇÊúÄËøëÈñãÁôºÁöÑÂãïÊÖã‰∏çÁ¢∫ÂÆöÂõ†ÊûúÈóú‰øÇÂúñ (DUCG) ÊñπÊ≥ïÊòØÂõ†ÊûúÈ©ÖÂãïÁöÑ„ÄÅÂèØËß£ÈáãÁöÑÔºå‰∏¶‰∏îÂú®‰∏çÂêåÁöÑÊáâÁî®Â†¥ÊôØ‰∏≠ÊòØ‰∏çËÆäÁöÑÔºåÊ≤íÊúâË≥áÊñôÊî∂ÈõÜ„ÄÅÊ®ôË®ò„ÄÅÊì¨Âêà„ÄÅÈö±ÁßÅ„ÄÅÂÅèË¶ã„ÄÅÊ¶ÇÂåñ„ÄÅÈ´òÊàêÊú¨ÂíåÈ´òËÉΩËÄóÁöÑÂïèÈ°å„ÄÇÈÄöÈÅéËá®Â∫äÂ∞àÂÆ∂Âíå DUCG ÊäÄË°ì‰∫∫Âì°‰πãÈñìÁöÑÂØÜÂàáÂêà‰ΩúÔºåÊßãÂª∫‰∫ÜÊ∂µËìã 54 ÂÄã‰∏ªË®¥ÁöÑ 46 ÂÄã DUCG Ê®°Âûã„ÄÇÂèØ‰ª•Âú®Ê≤íÊúâÂàÜÊµÅÁöÑÊÉÖÊ≥Å‰∏ãË®∫Êñ∑Âá∫ 1,000 Â§öÁ®ÆÁñæÁóÖ„ÄÇÂú®ÊáâÁî®ÊñºÂØ¶Èöõ‰∏ñÁïå‰πãÂâçÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Áî±Á¨¨‰∏âÊñπÈÜ´Èô¢ÂõûÊ∫ØÊÄßÈ©óË≠â„ÄÇÈ©óË≠âÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 95%ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÁΩïË¶ãÁñæÁóÖÂú®ÂÖßÁöÑÊØèÁ®ÆÁñæÁóÖÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 80%„ÄÇÈ©óË≠âÂæåÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Âú®‰∏≠ÂúãÂØ¶ÈöõÊáâÁî®„ÄÇÂ∑≤Á∂ìÂü∑Ë°å‰∫ÜË∂ÖÈÅé‰∏ÄÁôæËê¨ÂÄãÁúüÂØ¶Ë®∫Êñ∑Ê°à‰æãÔºåÂÉÖÁôºÁèæ 17 ÂÄã‰∏çÊ≠£Á¢∫ÁöÑË®∫Êñ∑„ÄÇÁî±Êñº DUCG ÁöÑÈÄèÊòéÊÄßÔºåÁôºÁèæ‰∏¶Á≥æÊ≠£‰∫ÜÂ∞éËá¥‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÁöÑÈåØË™§„ÄÇÈ†ªÁπÅÊáâÁî® DUCG ÁöÑËá®Â∫äÈÜ´ÁîüÁöÑË®∫Êñ∑ËÉΩÂäõÂæóÂà∞‰∫ÜÈ°ØËëóÊèêÈ´ò„ÄÇÂú®‰ªãÁ¥π‰∫ÜÂâçÈù¢ÊèêÂá∫ÁöÑ DUCG ÊñπÊ≥ïË´ñ‰πãÂæåÔºåÊèêÂá∫‰∫ÜÊΩõÂú®ÂÅ•Â∫∑Ê™¢Êü•ÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÔºå‰∏¶ÊèêÂèñ‰∫Ü DUCG ÁöÑÈóúÈçµÊÄùÊÉ≥„ÄÇ</paragraph>

##### **From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR**
2406.05682v1 by Ran Xu, Yiwen Lu, Chang Liu, Yong Chen, Yan Sun, Xiao Hu, Joyce C Ho, Carl Yang

Electronic Health Records (EHRs) contain rich patient information and are
crucial for clinical research and practice. In recent years, deep learning
models have been applied to EHRs, but they often rely on massive features,
which may not be readily available for all patients. We propose HTP-Star, which
leverages hypergraph structures with a pretrain-then-finetune framework for
modeling EHR data, enabling seamless integration of additional features.
Additionally, we design two techniques, namely (1) Smoothness-inducing
Regularization and (2) Group-balanced Reweighting, to enhance the model's
robustness during fine-tuning. Through experiments conducted on two real EHR
datasets, we demonstrate that HTP-Star consistently outperforms various
baselines while striking a balance between patients with basic and extra
features.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ÂåÖÂê´Ë±êÂØåÁöÑÊÇ£ËÄÖË≥áË®äÔºåÂ∞çÊñºËá®Â∫äÁ†îÁ©∂ÂíåÂØ¶ÂãôËá≥ÈóúÈáçË¶Å„ÄÇËøëÂπ¥‰æÜÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂ∑≤ÊáâÁî®Êñº EHRÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏‰æùË≥¥Â§ßÈáèÁâπÂæµÔºåËÄåÈÄô‰∫õÁâπÂæµÂèØËÉΩ‰∏¶ÈùûÊâÄÊúâÊÇ£ËÄÖÈÉΩËÉΩËºïÊòìÂèñÂæó„ÄÇÊàëÂÄëÊèêÂá∫ HTP-StarÔºåÂÆÉÂà©Áî®Ë∂ÖÂúñÁµêÊßãÊê≠ÈÖçÈ†êË®ìÁ∑¥ÂÜçÂæÆË™øÊû∂Êßã‰æÜÂª∫Ê®° EHR Ë≥áÊñôÔºåËÆìÈ°çÂ§ñÁâπÂæµËÉΩÁÑ°Á∏´Êï¥Âêà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÂÖ©Á®ÆÊäÄË°ìÔºåÂç≥ (1) Âπ≥ÊªëË™òÂ∞éÊ≠£ÂâáÂåñÂíå (2) Áæ§ÁµÑÂπ≥Ë°°ÈáçÊñ∞Âä†Ê¨äÔºå‰ª•Â¢ûÂº∑Ê®°ÂûãÂú®ÂæÆË™øÊúüÈñìÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÈÄèÈÅéÂú®ÂÖ©ÂÄãÁúüÂØ¶ EHR Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé HTP-Star Âú®ÁÇ∫ÂÖ∑ÊúâÂü∫Êú¨ÂíåÈ°çÂ§ñÁâπÂæµÁöÑÊÇ£ËÄÖÂèñÂæóÂπ≥Ë°°ÁöÑÂêåÊôÇÔºåÂßãÁµÇÂÑ™ÊñºÂêÑÁ®ÆÂü∫Á∑ö„ÄÇ

##### **CCSI: Continual Class-Specific Impression for Data-free Class Incremental Learning**
2406.05631v1 by Sana Ayromlou, Teresa Tsang, Purang Abolmaesumi, Xiaoxiao Li

In real-world clinical settings, traditional deep learning-based
classification methods struggle with diagnosing newly introduced disease types
because they require samples from all disease classes for offline training.
Class incremental learning offers a promising solution by adapting a deep
network trained on specific disease classes to handle new diseases. However,
catastrophic forgetting occurs, decreasing the performance of earlier classes
when adapting the model to new data. Prior proposed methodologies to overcome
this require perpetual storage of previous samples, posing potential practical
concerns regarding privacy and storage regulations in healthcare. To this end,
we propose a novel data-free class incremental learning framework that utilizes
data synthesis on learned classes instead of data storage from previous
classes. Our key contributions include acquiring synthetic data known as
Continual Class-Specific Impression (CCSI) for previously inaccessible trained
classes and presenting a methodology to effectively utilize this data for
updating networks when introducing new classes. We obtain CCSI by employing
data inversion over gradients of the trained classification model on previous
classes starting from the mean image of each class inspired by common landmarks
shared among medical images and utilizing continual normalization layers
statistics as a regularizer in this pixel-wise optimization process.
Subsequently, we update the network by combining the synthesized data with new
class data and incorporate several losses, including an intra-domain
contrastive loss to generalize the deep network trained on the synthesized data
to real data, a margin loss to increase separation among previous classes and
new ones, and a cosine-normalized cross-entropy loss to alleviate the adverse
effects of imbalanced distributions in training data.

ÊëòË¶ÅÔºö<paragraph>Âú®ÁúüÂØ¶‰∏ñÁïåËá®Â∫äÁí∞Â¢É‰∏≠ÔºåÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÂàÜÈ°ûÊñπÊ≥ïÈõ£‰ª•Ë®∫Êñ∑Êñ∞ÂºïÂÖ•ÁöÑÁñæÁóÖÈ°ûÂûãÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÈúÄË¶ÅÈõ¢Á∑öË®ìÁ∑¥ÊâÄÊúâÁñæÁóÖÈ°ûÂà•ÁöÑÊ®£Êú¨„ÄÇÈ°ûÂà•Â¢ûÈáèÂ≠∏ÁøíÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÔºåÈÄöÈÅéË™øÊï¥Âú®ÁâπÂÆöÁñæÁóÖÈ°ûÂà•‰∏äË®ìÁ∑¥ÁöÑÊ∑±Â∫¶Á∂≤Ë∑Ø‰æÜËôïÁêÜÊñ∞ÁñæÁóÖ„ÄÇÁÑ∂ËÄåÔºåÊúÉÁôºÁîüÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÔºåÂú®Â∞áÊ®°ÂûãË™øÊï¥Âà∞Êñ∞Êï∏ÊìöÊôÇÈôç‰ΩéÊó©ÊúüÈ°ûÂà•ÁöÑÊÄßËÉΩ„ÄÇÂÖàÂâçÊèêÂá∫ÁöÑÂÖãÊúçÊ≠§ÂïèÈ°åÁöÑÊñπÊ≥ïË´ñÈúÄË¶ÅÊåÅÁ∫åÂÑ≤Â≠òÂÖàÂâçÁöÑÊ®£Êú¨ÔºåÂ∞çÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈö±ÁßÅÂíåÂÑ≤Â≠òÊ≥ïË¶èÈÄ†ÊàêÊΩõÂú®ÁöÑÂØ¶ÈöõÂïèÈ°å„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÁÑ°Êï∏ÊìöÈ°ûÂà•Â¢ûÈáèÂ≠∏ÁøíÊ°ÜÊû∂ÔºåÂà©Áî®Â∑≤Â≠∏ÁøíÈ°ûÂà•ÁöÑÊï∏ÊìöÂêàÊàêÔºåËÄå‰∏çÊòØÂÖàÂâçÈ°ûÂà•ÁöÑÊï∏ÊìöÂÑ≤Â≠ò„ÄÇÊàëÂÄëÁöÑÈóúÈçµË≤¢ÁçªÂåÖÊã¨Áç≤ÂèñÂêàÊàêÊï∏ÊìöÔºåÁ®±ÁÇ∫ÈÄ£Á∫åÈ°ûÂà•ÁâπÂÆöÂç∞Ë±° (CCSI)ÔºåÁî®ÊñºÂÖàÂâçÁÑ°Ê≥ïÂ≠òÂèñÁöÑÂ∑≤Ë®ìÁ∑¥È°ûÂà•Ôºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÊñπÊ≥ïË´ñÔºåÂú®ÂºïÂÖ•Êñ∞È°ûÂà•ÊôÇÊúâÊïàÂú∞Âà©Áî®Ê≠§Êï∏Êìö‰æÜÊõ¥Êñ∞Á∂≤Ë∑Ø„ÄÇÊàëÂÄëÈÄöÈÅéÂ∞çÂÖàÂâçÈ°ûÂà•ÁöÑË®ìÁ∑¥ÂàÜÈ°ûÊ®°ÂûãÁöÑÊ¢ØÂ∫¶ÈÄ≤Ë°åÊï∏ÊìöÂèçÊºî‰æÜÁç≤Âèñ CCSIÔºåÂæûÊØèÂÄãÈ°ûÂà•ÁöÑÂπ≥ÂùáÂΩ±ÂÉèÈñãÂßãÔºåÈùàÊÑü‰æÜËá™ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÂÖ±‰∫´ÁöÑÂÖ±ÂêåÂú∞Ê®ôÔºå‰∏¶Âà©Áî®ÈÄ£Á∫åÊ≠£Ë¶èÂåñÂ±§Áµ±Ë®à‰ΩúÁÇ∫Ê≠§ÈÄêÂÉèÁ¥†ÊúÄ‰Ω≥ÂåñÈÅéÁ®ã‰∏≠ÁöÑÊ≠£ÂâáÂåñÂô®„ÄÇÈö®ÂæåÔºåÊàëÂÄëÈÄöÈÅéÂ∞áÂêàÊàêÊï∏ÊìöËàáÊñ∞È°ûÂà•Êï∏ÊìöÁµêÂêà‰æÜÊõ¥Êñ∞Á∂≤Ë∑ØÔºå‰∏¶ÁµêÂêàÂ§öÁ®ÆÊêçÂ§±ÔºåÂåÖÊã¨ÂüüÂÖßÂ∞çÊØîÊêçÂ§±Ôºå‰ª•Â∞áÂú®ÂêàÊàêÊï∏Êìö‰∏äË®ìÁ∑¥ÁöÑÊ∑±Â∫¶Á∂≤Ë∑ØÊé®Âª£Âà∞ÁúüÂØ¶Êï∏ÊìöÔºåÈÇäÈöõÊêçÂ§±‰ª•Â¢ûÂä†ÂÖàÂâçÈ°ûÂà•ÂíåÊñ∞È°ûÂà•‰πãÈñìÁöÑÂàÜÈõ¢Ôºå‰ª•ÂèäÈ§òÂº¶Ê≠£Ë¶èÂåñ‰∫§ÂèâÁÜµÊêçÂ§±‰ª•Ê∏õËºïË®ìÁ∑¥Êï∏Êìö‰∏≠‰∏çÂπ≥Ë°°ÂàÜ‰ΩàÁöÑ‰∏çÂà©ÂΩ±Èüø„ÄÇ</paragraph>

##### **Which Backbone to Use: A Resource-efficient Domain Specific Comparison for Computer Vision**
2406.05612v1 by Pranav Jeevan, Amit Sethi

In contemporary computer vision applications, particularly image
classification, architectural backbones pre-trained on large datasets like
ImageNet are commonly employed as feature extractors. Despite the widespread
use of these pre-trained convolutional neural networks (CNNs), there remains a
gap in understanding the performance of various resource-efficient backbones
across diverse domains and dataset sizes. Our study systematically evaluates
multiple lightweight, pre-trained CNN backbones under consistent training
settings across a variety of datasets, including natural images, medical
images, galaxy images, and remote sensing images. This comprehensive analysis
aims to aid machine learning practitioners in selecting the most suitable
backbone for their specific problem, especially in scenarios involving small
datasets where fine-tuning a pre-trained network is crucial. Even though
attention-based architectures are gaining popularity, we observed that they
tend to perform poorly under low data finetuning tasks compared to CNNs. We
also observed that some CNN architectures such as ConvNeXt, RegNet and
EfficientNet performs well compared to others on a diverse set of domains
consistently. Our findings provide actionable insights into the performance
trade-offs and effectiveness of different backbones, facilitating informed
decision-making in model selection for a broad spectrum of computer vision
domains. Our code is available here: https://github.com/pranavphoenix/Backbones

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂‰ª£ÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®‰∏≠ÔºåÁâπÂà•ÊòØÂΩ±ÂÉèÂàÜÈ°ûÔºåÈ†êÂÖàÂú®Â§ßÂûãË≥áÊñôÈõÜÔºà‰æãÂ¶Ç ImageNetÔºâ‰∏äË®ìÁ∑¥ÁöÑÊû∂Êßã‰∏ªÂππÈÄöÂ∏∏Áî®‰ΩúÁâπÂæµËêÉÂèñÂô®„ÄÇÂÑòÁÆ°Âª£Ê≥õ‰ΩøÁî®ÈÄô‰∫õÈ†êÂÖàË®ìÁ∑¥ÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN)Ôºå‰ΩÜÂ∞çÊñºÂêÑÁ®ÆË≥áÊ∫êÊïàÁéá‰∏ªÂππÂú®‰∏çÂêåÁ∂≤ÂüüÂíåË≥áÊñôÈõÜÂ§ßÂ∞è‰∏äÁöÑÊïàËÉΩ‰ªçÁº∫‰πè‰∫ÜËß£„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞Â§öÂÄãËºïÈáèÁ¥ö„ÄÅÈ†êÂÖàË®ìÁ∑¥ÁöÑ CNN ‰∏ªÂππÔºåÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜÔºàÂåÖÊã¨Ëá™ÁÑ∂ÂΩ±ÂÉè„ÄÅÈÜ´Â≠∏ÂΩ±ÂÉè„ÄÅÊòüÁ≥ªÂΩ±ÂÉèÂíåÈÅôÊ∏¨ÂΩ±ÂÉèÔºâ‰∏äÊé°Áî®‰∏ÄËá¥ÁöÑË®ìÁ∑¥Ë®≠ÂÆö„ÄÇÈÄôÈ†ÖÂÖ®Èù¢ÁöÑÂàÜÊûêÊó®Âú®ÂçîÂä©Ê©üÂô®Â≠∏ÁøíÂæûÊ•≠‰∫∫Âì°ÁÇ∫ÂÖ∂ÁâπÂÆöÂïèÈ°åÈÅ∏ÊìáÊúÄÂêàÈÅ©ÁöÑ‰∏ªÂππÔºåÁâπÂà•ÊòØÂú®Ê∂âÂèäÂ∞èÂûãË≥áÊñôÈõÜÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂÖ∂‰∏≠ÂæÆË™øÈ†êÂÖàË®ìÁ∑¥ÁöÑÁ∂≤Ë∑ØËá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°Âü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÊû∂ÊßãË∂ä‰æÜË∂äÂèóÊ≠°ËøéÔºå‰ΩÜÊàëÂÄëËßÄÂØüÂà∞ÔºåËàá CNN Áõ∏ÊØîÔºåÂÆÉÂÄëÂú®‰ΩéË≥áÊñôÈáèÂæÆË™ø‰ªªÂãô‰∏≠ÁöÑË°®ÁèæÂæÄÂæÄËºÉÂ∑Æ„ÄÇÊàëÂÄëÈÇÑËßÄÂØüÂà∞ÔºåËàáÂÖ∂‰ªñÊû∂ÊßãÁõ∏ÊØîÔºåÊüê‰∫õ CNN Êû∂ÊßãÔºà‰æãÂ¶Ç ConvNeXt„ÄÅRegNet Âíå EfficientNetÔºâÂú®ÂêÑÁ®ÆÁ∂≤Âüü‰∏äË°®ÁèæËâØÂ•Ω‰∏î‰∏ÄËá¥„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊèê‰æõ‰∫ÜÂèØÊìç‰ΩúÁöÑË¶ãËß£ÔºåË™™Êòé‰∏çÂêå‰∏ªÂππÁöÑÊïàËÉΩÂèñÊç®ÂíåÊúâÊïàÊÄßÔºåÊúâÂä©ÊñºÂú®Âª£Ê≥õÁöÑÈõªËÖ¶Ë¶ñË¶∫Á∂≤Âüü‰∏≠ÈÄ≤Ë°åÊ®°ÂûãÈÅ∏ÊìáÁöÑÊòéÊô∫Ê±∫Á≠ñ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú®Ê≠§ÂèñÂæóÔºöhttps://github.com/pranavphoenix/Backbones</paragraph>

##### **I-SIRch: AI-Powered Concept Annotation Tool For Equitable Extraction And Analysis Of Safety Insights From Maternity Investigations**
2406.05505v1 by Mohit Kumar Singh, Georgina Cosma, Patrick Waterson, Jonathan Back, Gyuchan Thomas Jun

Maternity care is a complex system involving treatments and interactions
between patients, providers, and the care environment. To improve patient
safety and outcomes, understanding the human factors (e.g. individuals
decisions, local facilities) influencing healthcare delivery is crucial.
However, most current tools for analysing healthcare data focus only on
biomedical concepts (e.g. health conditions, procedures and tests), overlooking
the importance of human factors. We developed a new approach called I-SIRch,
using artificial intelligence to automatically identify and label human factors
concepts in maternity healthcare investigation reports describing adverse
maternity incidents produced by England's Healthcare Safety Investigation
Branch (HSIB). These incident investigation reports aim to identify
opportunities for learning and improving maternal safety across the entire
healthcare system. I-SIRch was trained using real data and tested on both real
and simulated data to evaluate its performance in identifying human factors
concepts. When applied to real reports, the model achieved a high level of
accuracy, correctly identifying relevant concepts in 90\% of the sentences from
97 reports. Applying I-SIRch to analyse these reports revealed that certain
human factors disproportionately affected mothers from different ethnic groups.
Our work demonstrates the potential of using automated tools to identify human
factors concepts in maternity incident investigation reports, rather than
focusing solely on biomedical concepts. This approach opens up new
possibilities for understanding the complex interplay between social,
technical, and organisational factors influencing maternal safety and
population health outcomes. By taking a more comprehensive view of maternal
healthcare delivery, we can develop targeted interventions to address
disparities and improve maternal outcomes.

ÊëòË¶ÅÔºöÁî¢ÁßëÁÖßË≠∑ÊòØ‰∏ÄÂÄãË§áÈõúÁöÑÁ≥ªÁµ±ÔºåÊ∂âÂèäÊÇ£ËÄÖ„ÄÅÊèê‰æõËÄÖÂíåÁÖßË≠∑Áí∞Â¢É‰πãÈñìÁöÑÊ≤ªÁôÇÂíå‰∫íÂãï„ÄÇÁÇ∫‰∫ÜÊîπÂñÑÊÇ£ËÄÖÂÆâÂÖ®ÂíåÁÖßË≠∑ÁµêÊûúÔºå‰∫ÜËß£ÂΩ±ÈüøÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãôÁöÑ‰∫∫ÁÇ∫Âõ†Á¥†Ôºà‰æãÂ¶ÇÂÄã‰∫∫Ê±∫Á≠ñ„ÄÅÁï∂Âú∞Ë®≠ÊñΩÔºâËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÂ§ßÂ§öÊï∏Áî®ÊñºÂàÜÊûêÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÁöÑÂ∑•ÂÖ∑Âè™ÈóúÊ≥®ÁîüÁâ©ÈÜ´Â≠∏Ê¶ÇÂøµÔºà‰æãÂ¶ÇÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÅÁ®ãÂ∫èÂíåÊ™¢È©óÔºâÔºåËÄåÂøΩÁï•‰∫Ü‰∫∫ÁÇ∫Âõ†Á¥†ÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ I-SIRch ÁöÑÊñ∞ÊñπÊ≥ïÔºåÂà©Áî®‰∫∫Â∑•Êô∫ÊÖßËá™ÂãïË≠òÂà•ÂíåÊ®ôË®òËã±ÂúãÈÜ´ÁôÇÂÆâÂÖ®Ë™øÊü•ÈÉ®ÈñÄ (HSIB) Áî¢ÁîüÁöÑÊèèËø∞‰∏çËâØÁî¢Áßë‰∫ã‰ª∂ÁöÑÁî¢ÁßëÈÜ´ÁôÇ‰øùÂÅ•Ë™øÊü•Â†±Âëä‰∏≠ÁöÑ‰∫∫ÁÇ∫Âõ†Á¥†Ê¶ÇÂøµ„ÄÇÈÄô‰∫õ‰∫ã‰ª∂Ë™øÊü•Â†±ÂëäÊó®Âú®ÊâæÂá∫Ê©üÊúÉÔºå‰ª•Â≠∏Áøí‰∏¶ÊîπÂñÑÊï¥ÂÄãÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±‰∏≠ÁöÑÁî¢Â©¶ÂÆâÂÖ®„ÄÇI-SIRch ‰ΩøÁî®ÁúüÂØ¶Ë≥áÊñôÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰∏¶Âú®ÁúüÂØ¶ÂíåÊ®°Êì¨Ë≥áÊñô‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶Ôºå‰ª•Ë©ï‰º∞ÂÖ∂Âú®Ë≠òÂà•‰∫∫ÁÇ∫Âõ†Á¥†Ê¶ÇÂøµÊñπÈù¢ÁöÑË°®Áèæ„ÄÇÁï∂ÊáâÁî®ÊñºÁúüÂØ¶Â†±ÂëäÊôÇÔºåË©≤Ê®°ÂûãÈÅîÂà∞‰∫ÜÂæàÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂú® 97 ‰ªΩÂ†±ÂëäÁöÑ 90% ÁöÑÂè•Â≠ê‰∏≠Ê≠£Á¢∫Ë≠òÂà•‰∫ÜÁõ∏ÈóúÊ¶ÇÂøµ„ÄÇÂ∞á I-SIRch ÊáâÁî®ÊñºÂàÜÊûêÈÄô‰∫õÂ†±ÂëäÈ°ØÁ§∫ÔºåÊüê‰∫õ‰∫∫ÁÇ∫Âõ†Á¥†Â∞ç‰∏çÂêåÁ®ÆÊóèÁæ§È´îÁöÑÊØçË¶™Áî¢Áîü‰∫Ü‰∏çÊàêÊØî‰æãÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë≠âÊòé‰∫Ü‰ΩøÁî®Ëá™ÂãïÂåñÂ∑•ÂÖ∑‰æÜË≠òÂà•‰∫∫ÁÇ∫Âõ†Á¥†Ê¶ÇÂøµÂú®Áî¢Áßë‰∫ã‰ª∂Ë™øÊü•Â†±Âëä‰∏≠ÁöÑÊΩõÂäõÔºåËÄå‰∏çÊòØÂÉÖÈóúÊ≥®ÁîüÁâ©ÈÜ´Â≠∏Ê¶ÇÂøµ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁÇ∫ÁêÜËß£ÂΩ±ÈüøÁî¢Â©¶ÂÆâÂÖ®Âíå‰∫∫Âè£ÂÅ•Â∫∑ÁµêÊûúÁöÑÁ§æÊúÉ„ÄÅÊäÄË°ìÂíåÁµÑÁπîÂõ†Á¥†‰πãÈñìÁöÑË§áÈõúÁõ∏‰∫í‰ΩúÁî®ÈñãÈó¢‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇÈÄöÈÅéÊõ¥ÂÖ®Èù¢Âú∞‰∫ÜËß£Áî¢ÁßëÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãôÔºåÊàëÂÄëÂèØ‰ª•Âà∂ÂÆöÊúâÈáùÂ∞çÊÄßÁöÑÂπ≤È†êÊé™ÊñΩ‰æÜËß£Ê±∫Â∑ÆÁï∞‰∏¶ÊîπÂñÑÁî¢Â©¶ÁµêÊûú„ÄÇ

##### **DeviceBERT: Applied Transfer Learning With Targeted Annotations and Vocabulary Enrichment to Identify Medical Device and Component Terminology in FDA Recall Summaries**
2406.05307v1 by Miriam Farrington

FDA Medical Device recalls are critical and time-sensitive events, requiring
swift identification of impacted devices to inform the public of a recall event
and ensure patient safety. The OpenFDA device recall dataset contains valuable
information about ongoing device recall actions, but manually extracting
relevant device information from the recall action summaries is a
time-consuming task. Named Entity Recognition (NER) is a task in Natural
Language Processing (NLP) that involves identifying and categorizing named
entities in unstructured text. Existing NER models, including domain-specific
models like BioBERT, struggle to correctly identify medical device trade names,
part numbers and component terms within these summaries. To address this, we
propose DeviceBERT, a medical device annotation, pre-processing and enrichment
pipeline, which builds on BioBERT to identify and label medical device
terminology in the device recall summaries with improved accuracy. Furthermore,
we demonstrate that our approach can be applied effectively for performing
entity recognition tasks where training data is limited or sparse.

ÊëòË¶ÅÔºöÈ£üÂìÅËó•Áâ©ÁÆ°ÁêÜÂ±ÄÈÜ´ÁôÇÂô®ÊùêÂè¨ÂõûÊòØÈóúÈçµ‰∏îÊôÇÈñìÊïèÊÑüÁöÑ‰∫ã‰ª∂ÔºåÈúÄË¶ÅËøÖÈÄüÊâæÂá∫ÂèóÂΩ±ÈüøÁöÑÂô®ÊùêÔºå‰ª•ÂëäÁü•Â§ßÁúæÂè¨Âõû‰∫ã‰ª∂‰∏¶Á¢∫‰øùÁóÖÊÇ£ÂÆâÂÖ®„ÄÇOpenFDA Âô®ÊùêÂè¨ÂõûË≥áÊñôÈõÜÂåÖÂê´ÊúâÈóúÊåÅÁ∫åÈÄ≤Ë°åÂô®ÊùêÂè¨ÂõûË°åÂãïÁöÑÂØ∂Ë≤¥Ë≥áË®äÔºå‰ΩÜÊâãÂãïÂæûÂè¨ÂõûË°åÂãïÊëòË¶Å‰∏≠Êì∑ÂèñÁõ∏ÈóúÂô®ÊùêË≥áË®äÊòØ‰∏ÄÈ†ÖËÄóÊôÇÁöÑ‰ªªÂãô„ÄÇÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (NER) ÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠ÁöÑ‰∏ÄÈ†Ö‰ªªÂãôÔºåÊ∂âÂèäÂú®ÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠Ëæ®Ë≠òÂíåÂàÜÈ°ûÂëΩÂêçÂØ¶È´î„ÄÇÁèæÊúâÁöÑ NER Ê®°ÂûãÔºàÂåÖÊã¨ÂÉè BioBERT ÈÄôÈ°ûÁâπÂÆöÈ†òÂüüÊ®°ÂûãÔºâÈõ£‰ª•Ê≠£Á¢∫Ëæ®Ë≠òÈÄô‰∫õÊëòË¶Å‰∏≠ÁöÑÈÜ´ÁôÇÂô®ÊùêÂïÜÂìÅÂêç„ÄÅÈõ∂‰ª∂Á∑®ËôüÂíåÁµÑÊàêË°ìË™û„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ DeviceBERTÔºåÈÄôÊòØ‰∏ÄÂÄãÈÜ´ÁôÇÂô®ÊùêË®ªËß£„ÄÅÂâçËôïÁêÜÂíåË±êÂØåËôïÁêÜÁÆ°Á∑öÔºåÂÆÉÂª∫ÊßãÊñº BioBERT ‰πã‰∏äÔºå‰ª•Êõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶Ëæ®Ë≠òÂíåÊ®ôË®òÂô®ÊùêÂè¨ÂõûÊëòË¶Å‰∏≠ÁöÑÈÜ´ÁôÇÂô®ÊùêË°ìË™û„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòéÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÊúâÊïàÊáâÁî®ÊñºÂü∑Ë°åË®ìÁ∑¥Ë≥áÊñôÂèóÈôêÊàñÁ®ÄÁñèÁöÑÂØ¶È´îËæ®Ë≠ò‰ªªÂãô„ÄÇ

##### **Analyzing the factors that are involved in length of inpatient stay at the hospital for diabetes patients**
2406.05189v1 by Jorden Lam, Kunpeng Xu

The paper investigates the escalating concerns surrounding the surge in
diabetes cases, exacerbated by the COVID-19 pandemic, and the subsequent strain
on medical resources. The research aims to construct a predictive model
quantifying factors influencing inpatient hospital stay durations for diabetes
patients, offering insights to hospital administrators for improved patient
management strategies. The literature review highlights the increasing
prevalence of diabetes, emphasizing the need for continued attention and
analysis of urban-rural disparities in healthcare access. International studies
underscore the financial implications and healthcare burden associated with
diabetes-related hospitalizations and complications, emphasizing the
significance of effective management strategies. The methodology involves a
quantitative approach, utilizing a dataset comprising 10,000 observations of
diabetic inpatient encounters in U.S. hospitals from 1999 to 2008. Predictive
modeling techniques, particularly Generalized Linear Models (GLM), are employed
to develop a model predicting hospital stay durations based on patient
demographics, admission types, medical history, and treatment regimen. The
results highlight the influence of age, medical history, and treatment regimen
on hospital stay durations for diabetes patients. Despite model limitations,
such as heteroscedasticity and deviations from normality in residual analysis,
the findings offer valuable insights for hospital administrators in patient
management. The paper concludes with recommendations for future research to
address model limitations and explore the implications of predictive models on
healthcare management strategies, ensuring equitable patient care and resource
allocation.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫ÜÁ≥ñÂ∞øÁóÖÁóÖ‰æãÊøÄÂ¢ûÂºïÁôºÁöÑÊó•ÁõäÂö¥ÈáçÁöÑÂïèÈ°åÔºåËÄå COVID-19 Â§ßÊµÅË°å‰ΩøÂïèÈ°åÊõ¥Âä†ÊÉ°ÂåñÔºå‰∏¶Â∞çÈÜ´ÁôÇË≥áÊ∫êÈÄ†ÊàêÂæåÁ∫åË≤†Êìî„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Âª∫Êßã‰∏ÄÂÄãÈ†êÊ∏¨Ê®°ÂûãÔºåÈáèÂåñÂΩ±ÈüøÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖ‰ΩèÈô¢Â§©Êï∏ÁöÑÂõ†Á¥†Ôºå‰∏¶Êèê‰æõË¶ãËß£Áµ¶ÈÜ´Èô¢ÁÆ°ÁêÜÂì°Ôºå‰ª•ÊîπÂñÑÁóÖÊÇ£ÁÆ°ÁêÜÁ≠ñÁï•„ÄÇÊñáÁçªÂõûÈ°ßÂº∑Ë™ø‰∫ÜÁ≥ñÂ∞øÁóÖÊÇ£ÁóÖÁéáÁöÑ‰∏äÂçáÔºå‰∏¶Âº∑Ë™øÈúÄË¶ÅÊåÅÁ∫åÈóúÊ≥®ÂíåÂàÜÊûêÂüéÈÑâ‰πãÈñìÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÂèñÂæóÊñπÈù¢ÁöÑÂ∑ÆÁï∞„ÄÇÂúãÈöõÁ†îÁ©∂Âº∑Ë™ø‰∫ÜËàáÁ≥ñÂ∞øÁóÖÁõ∏ÈóúÁöÑ‰ΩèÈô¢Âíå‰ΩµÁôºÁóáÊâÄÂ∏∂‰æÜÁöÑË≤°ÂãôÂΩ±ÈüøÂíåÈÜ´ÁôÇË≤†ÊìîÔºå‰∏¶Âº∑Ë™ø‰∫ÜÊúâÊïàÁÆ°ÁêÜÁ≠ñÁï•ÁöÑÈáçË¶ÅÊÄß„ÄÇÊñπÊ≥ïÊ∂âÂèä‰∏ÄÁ®ÆÈáèÂåñÊñπÊ≥ïÔºåÂà©Áî®‰∏ÄÂÄãË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫Ü 1999 Âπ¥Ëá≥ 2008 Âπ¥ÈñìÁæéÂúãÈÜ´Èô¢‰∏≠ 10,000 Á≠ÜÁ≥ñÂ∞øÁóÖ‰ΩèÈô¢ÊÇ£ËÄÖÁöÑËßÄÂØüÁµêÊûú„ÄÇÈ†êÊ∏¨Ê®°ÂûãÊäÄË°ìÔºåÂ∞§ÂÖ∂ÊòØÂª£Áæ©Á∑öÊÄßÊ®°Âûã (GLM)ÔºåË¢´Áî®ÊñºÈñãÁôº‰∏ÄÂÄãÊ®°ÂûãÔºåÊ†πÊìöÊÇ£ËÄÖ‰∫∫Âè£Áµ±Ë®àË≥áÊñô„ÄÅÂÖ•Èô¢È°ûÂûã„ÄÅÁóÖÂè≤ÂíåÊ≤ªÁôÇÊñπÊ°à‰æÜÈ†êÊ∏¨‰ΩèÈô¢Â§©Êï∏„ÄÇÁµêÊûúÈáçÈªûË™™Êòé‰∫ÜÂπ¥ÈΩ°„ÄÅÁóÖÂè≤ÂíåÊ≤ªÁôÇÊñπÊ°àÂ∞çÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖ‰ΩèÈô¢Â§©Êï∏ÁöÑÂΩ±Èüø„ÄÇÂÑòÁÆ°Ê®°ÂûãÊúâÂÖ∂ÈôêÂà∂Ôºå‰æãÂ¶ÇÊÆòÂ∑ÆÂàÜÊûê‰∏≠ÁöÑÁï∞Ë≥™ËÆäÁï∞Êï∏ÂíåÂ∏∏ÊÖãÂàÜ‰ΩàÂÅèÂ∑ÆÔºå‰ΩÜÁ†îÁ©∂ÁµêÊûú‰ªçÁÇ∫ÈÜ´Èô¢ÁÆ°ÁêÜÂì°Âú®ÁóÖÊÇ£ÁÆ°ÁêÜÊñπÈù¢Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£„ÄÇÊú¨ÊñáÊúÄÂæåÊèêÂá∫‰∫ÜÊú™‰æÜÁ†îÁ©∂Âª∫Ë≠∞Ôºå‰ª•Ëß£Ê±∫Ê®°ÂûãÈôêÂà∂‰∏¶Êé¢Ë®éÈ†êÊ∏¨Ê®°ÂûãÂ∞çÈÜ´ÁôÇÁÆ°ÁêÜÁ≠ñÁï•ÁöÑÂΩ±ÈüøÔºåÁ¢∫‰øùÂÖ¨Âπ≥ÁöÑÁóÖÊÇ£ÁÖßË≠∑ÂíåË≥áÊ∫êÂàÜÈÖç„ÄÇ

##### **Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study**
2406.05002v1 by Deepa Tilwani, Christian O'Reilly

The study of effective connectivity (EC) is essential in understanding how
the brain integrates and responds to various sensory inputs. Model-driven
estimation of EC is a powerful approach that requires estimating global and
local parameters of a generative model of neural activity. Insights gathered
through this process can be used in various applications, such as studying
neurodevelopmental disorders. However, accurately determining EC through
generative models remains a significant challenge due to the complexity of
brain dynamics and the inherent noise in neural recordings, e.g., in
electroencephalography (EEG). Current model-driven methods to study EC are
computationally complex and cannot scale to all brain regions as required by
whole-brain analyses. To facilitate EC assessment, an inference algorithm must
exhibit reliable prediction of parameters in the presence of noise. Further,
the relationship between the model parameters and the neural recordings must be
learnable. To progress toward these objectives, we benchmarked the performance
of a Bi-LSTM model for parameter inference from the Jansen-Rit neural mass
model (JR-NMM) simulated EEG under various noise conditions. Additionally, our
study explores how the JR-NMM reacts to changes in key biological parameters
(i.e., sensitivity analysis) like synaptic gains and time constants, a crucial
step in understanding the connection between neural mechanisms and observed
brain activity. Our results indicate that we can predict the local JR-NMM
parameters from EEG, supporting the feasibility of our deep-learning-based
inference approach. In future work, we plan to extend this framework to
estimate local and global parameters from real EEG in clinically relevant
applications.

ÊëòË¶ÅÔºöÊúâÊïàËøûÈÄöÊÄß (EC) ÁöÑÁ†îÁ©∂ÂØπ‰∫éÁêÜËß£Â§ßËÑëÂ¶Ç‰ΩïÊï¥ÂêàÂíåÂìçÂ∫îÂêÑÁßçÊÑüÂÆòËæìÂÖ•Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇEC ÁöÑÊ®°ÂûãÈ©±Âä®‰º∞ËÆ°ÊòØ‰∏ÄÁßçÂº∫Â§ßÁöÑÊñπÊ≥ïÔºåÈúÄË¶Å‰º∞ËÆ°Á•ûÁªèÊ¥ªÂä®ÁîüÊàêÊ®°ÂûãÁöÑÂÖ®Â±ÄÂíåÂ±ÄÈÉ®ÂèÇÊï∞„ÄÇÈÄöËøáÊ≠§ËøáÁ®ãÊî∂ÈõÜÁöÑËßÅËß£ÂèØÁî®‰∫éÂêÑÁßçÂ∫îÁî®‰∏≠Ôºå‰æãÂ¶ÇÁ†îÁ©∂Á•ûÁªèÂèëËÇ≤ÈöúÁ¢ç„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÂ§ßËÑëÂä®ÂäõÂ≠¶Â§çÊùÇ‰∏îÁ•ûÁªèËÆ∞ÂΩï‰∏≠Âõ∫ÊúâÂô™Â£∞Ôºà‰æãÂ¶ÇËÑëÁîµÂõæ (EEG) ‰∏≠ÁöÑÂô™Â£∞ÔºâÔºåÈÄöËøáÁîüÊàêÊ®°ÂûãÂáÜÁ°ÆÁ°ÆÂÆö EC ‰ªçÁÑ∂ÊòØ‰∏ÄÈ°πÈáçÂ§ßÊåëÊàò„ÄÇÂΩìÂâçÁî®‰∫éÁ†îÁ©∂ EC ÁöÑÊ®°ÂûãÈ©±Âä®ÊñπÊ≥ïËÆ°ÁÆóÂ§çÊùÇÔºåÂπ∂‰∏îÊó†Ê≥ïÊâ©Â±ïÂà∞ÂÖ®ËÑëÂàÜÊûêÊâÄÈúÄÁöÑÊâÄÊúâÂ§ßËÑëÂå∫Âüü„ÄÇ‰∏∫‰∫Ü‰øÉËøõ EC ËØÑ‰º∞ÔºåÊé®ÁêÜÁÆóÊ≥ïÂøÖÈ°ªÂú®Â≠òÂú®Âô™Â£∞ÁöÑÊÉÖÂÜµ‰∏ãÂØπÂèÇÊï∞ËøõË°åÂèØÈù†È¢ÑÊµã„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÂèÇÊï∞‰∏éÁ•ûÁªèËÆ∞ÂΩï‰πãÈó¥ÁöÑÂÖ≥Á≥ªÂøÖÈ°ªÊòØÂèØÂ≠¶‰π†ÁöÑ„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞Ëøô‰∫õÁõÆÊ†áÔºåÊàë‰ª¨ÂØπÂèåÂêë LSTM Ê®°ÂûãÂú®ÂêÑÁßçÂô™Â£∞Êù°‰ª∂‰∏ã‰ªé Jansen-Rit Á•ûÁªèË¥®ÈáèÊ®°Âûã (JR-NMM) Ê®°ÊãüËÑëÁîµÂõæ‰∏≠ËøõË°åÂèÇÊï∞Êé®ÁêÜÁöÑÊÄßËÉΩËøõË°å‰∫ÜÂü∫ÂáÜÊµãËØï„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÁ†îÁ©∂Êé¢Á¥¢‰∫Ü JR-NMM Â¶Ç‰ΩïÂØπÂÖ≥ÈîÆÁîüÁâ©Â≠¶ÂèÇÊï∞ÔºàÂç≥ÊïèÊÑüÊÄßÂàÜÊûêÔºâÁöÑÂèòÂåñÂÅöÂá∫ÂèçÂ∫îÔºå‰æãÂ¶ÇÁ™ÅËß¶Â¢ûÁõäÂíåÊó∂Èó¥Â∏∏Êï∞ÔºåËøôÊòØÁêÜËß£Á•ûÁªèÊú∫Âà∂‰∏éËßÇÂØüÂà∞ÁöÑËÑëÊ¥ªÂä®‰πãÈó¥ËÅîÁ≥ªÁöÑÂÖ≥ÈîÆÊ≠•È™§„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÂèØ‰ª•‰ªéËÑëÁîµÂõæ‰∏≠È¢ÑÊµãÂ±ÄÈÉ® JR-NMM ÂèÇÊï∞Ôºå‰ªéËÄåÊîØÊåÅÊàë‰ª¨Âü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÊé®ÁêÜÊñπÊ≥ïÁöÑÂèØË°åÊÄß„ÄÇÂú®Êú™Êù•ÁöÑÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ËÆ°ÂàíÂ∞ÜÊ≠§Ê°ÜÊû∂Êâ©Â±ïÂà∞‰ªé‰∏¥Â∫äÁõ∏ÂÖ≥Â∫îÁî®‰∏≠ÁöÑÁúüÂÆûËÑëÁîµÂõæ‰º∞ËÆ°Â±ÄÈÉ®ÂíåÂÖ®Â±ÄÂèÇÊï∞„ÄÇ

##### **DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation**
2406.06620v1 by Weiqi Zhang, Jiexia Ye, Ziyue Li, Jia Li, Fugee Tsung

The recent rapid development of language models (LMs) has attracted attention
in the field of time series, including multimodal time series modeling.
However, we note that current time series multimodal methods are biased, often
assigning a primary role to one modality while the other assumes a secondary
role. They overlook the mutual benefits and complementary of different
modalities. For example, in seizure diagnosis, relying solely on textual
clinical reports makes it difficult to pinpoint the area and type of the
disease, while electroencephalograms (EEGs) alone cannot provide an accurate
diagnosis without considering the symptoms. In this study, based on the
complementary information mining of time series multimodal data, we propose
DualTime, a Dual-adapter multimodal language model for Time series
representation implementing temporal-primary and textual-primary modeling
simultaneously. By injecting lightweight adaption tokens, the LM pipeline
shared by dual adapters encourages embedding alignment and achieves efficient
fine-tuning. Empirically, our method outperforms state-of-the-art models in
both supervised and unsupervised settings, highlighting the complementary
benefits of different modalities. In addition, we conduct few-shot label
transfer experiments, which further verifies the transferability and
expressiveness of our proposed DualTime.

ÊëòË¶ÅÔºöËøëÊúüË™ûË®ÄÊ®°Âûã (LM) ÁöÑÂø´ÈÄüÁôºÂ±ïÔºåÂê∏Âºï‰∫ÜÊôÇÈñìÂ∫èÂàóÈ†òÂüüÁöÑÈóúÊ≥®ÔºåÂåÖÊã¨Â§öÊ®°ÊÖãÊôÇÈñìÂ∫èÂàóÂª∫Ê®°„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÊ≥®ÊÑèÂà∞ÁõÆÂâçÁöÑÊôÇÈñìÂ∫èÂàóÂ§öÊ®°ÊÖãÊñπÊ≥ïÊúâÂÅèË¶ãÔºåÈÄöÂ∏∏Â∞á‰∏ªË¶ÅËßíËâ≤ÂàÜÈÖçÁµ¶‰∏ÄÁ®ÆÊ®°ÊÖãÔºåËÄåÂè¶‰∏ÄÁ®ÆÂâáÊâÆÊºîÊ¨°Ë¶ÅËßíËâ≤„ÄÇÂÆÉÂÄëÂøΩË¶ñ‰∫Ü‰∏çÂêåÊ®°ÊÖãÁöÑ‰∫íÊÉ†Âà©ÁõäÂíå‰∫íË£úÊÄß„ÄÇ‰æãÂ¶ÇÔºåÂú®Áô≤ÁôáË®∫Êñ∑‰∏≠ÔºåÂÉÖ‰æùË≥¥ÊñáÂ≠óËá®Â∫äÂ†±ÂëäÂæàÈõ£Á≤æÁ¢∫ÊåáÂá∫ÁñæÁóÖÁöÑÂçÄÂüüÂíåÈ°ûÂûãÔºåËÄåÂñÆÁç®ÁöÑËÖ¶ÈõªÂúñ (EEG) Âú®‰∏çËÄÉÊÖÆÁóáÁãÄÁöÑÊÉÖÊ≥Å‰∏ãÁÑ°Ê≥ïÊèê‰æõÊ∫ñÁ¢∫ÁöÑË®∫Êñ∑„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÂü∫ÊñºÊôÇÈñìÂ∫èÂàóÂ§öÊ®°ÊÖãË≥áÊñôÁöÑ‰∫íË£úË≥áË®äÊé¢ÂãòÔºåÊàëÂÄëÊèêÂá∫‰∫Ü DualTimeÔºå‰∏ÄÁ®ÆÁî®ÊñºÊôÇÈñìÂ∫èÂàóË°®Á§∫ÁöÑÈõôÈÅ©ÈÖçÂô®Â§öÊ®°ÊÖãË™ûË®ÄÊ®°ÂûãÔºåÂêåÊôÇÂØ¶‰ΩúÊôÇÈñìÂÑ™ÂÖàÂíåÊñáÂ≠óÂÑ™ÂÖàÂª∫Ê®°„ÄÇÈÄèÈÅéÊ≥®ÂÖ•ËºïÈáèÁ¥öÈÅ©ÊáâÊ¨äÊùñÔºåÁî±ÈõôÈÅ©ÈÖçÂô®ÂÖ±Áî®ÁöÑ LM ÁÆ°Á∑öÈºìÂãµÂµåÂÖ•Â∞çÈΩäÔºå‰∏¶ÂØ¶ÁèæÊúâÊïàÁéáÁöÑÂæÆË™ø„ÄÇÊ†πÊìöÁ∂ìÈ©óÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®Áõ£Áù£ÂºèÂíåÈùûÁõ£Áù£ÂºèË®≠ÂÆö‰∏≠ÈÉΩÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåÁ™ÅÈ°Ø‰∫Ü‰∏çÂêåÊ®°ÊÖãÁöÑ‰∫íË£úÂÑ™Âã¢„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂ∞èÊ®£Êú¨Ê®ôÁ±§ËΩâÁßªÂØ¶È©óÔºåÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑ DualTime ÁöÑÂèØËΩâÁßªÊÄßÂíåË°®ÈÅîËÉΩÂäõ„ÄÇ

##### **CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling**
2406.04940v1 by Matthew Fortier, Mats L. Richter, Oliver Sonnentag, Chris Pal

Terrestrial carbon fluxes provide vital information about our biosphere's
health and its capacity to absorb anthropogenic CO$_2$ emissions. The
importance of predicting carbon fluxes has led to the emerging field of
data-driven carbon flux modelling (DDCFM), which uses statistical techniques to
predict carbon fluxes from biophysical data. However, the field lacks a
standardized dataset to promote comparisons between models. To address this
gap, we present CarbonSense, the first machine learning-ready dataset for
DDCFM. CarbonSense integrates measured carbon fluxes, meteorological
predictors, and satellite imagery from 385 locations across the globe, offering
comprehensive coverage and facilitating robust model training. Additionally, we
provide a baseline model using a current state-of-the-art DDCFM approach and a
novel transformer based model. Our experiments illustrate the potential gains
that multimodal deep learning techniques can bring to this domain. By providing
these resources, we aim to lower the barrier to entry for other deep learning
researchers to develop new models and drive new advances in carbon flux
modelling.

ÊëòË¶ÅÔºöÈô∏Âú∞Á¢≥ÈÄöÈáèÊèê‰æõÊàëÂÄëÁîüÁâ©ÂúàÂÅ•Â∫∑ÂíåÂê∏Êî∂‰∫∫ÁÇ∫ CO$_2$ ÊéíÊîæÁöÑËÉΩÂäõÁöÑÈáçË¶ÅË≥áË®ä„ÄÇÈ†êÊ∏¨Á¢≥ÈÄöÈáèÁöÑÈáçË¶ÅÊÄßÂ∞éËá¥Ë≥áÊñôÈ©ÖÂãïÁ¢≥ÈÄöÈáèÂª∫Ê®° (DDCFM) Êñ∞ËààÈ†òÂüüÁöÑÂá∫ÁèæÔºåÂÆÉ‰ΩøÁî®Áµ±Ë®àÊäÄË°ìÂæûÁîüÁâ©Áâ©ÁêÜË≥áÊñôÈ†êÊ∏¨Á¢≥ÈÄöÈáè„ÄÇÁÑ∂ËÄåÔºåË©≤È†òÂüüÁº∫‰πèÊ®ôÊ∫ñÂåñË≥áÊñôÈõÜ‰æÜ‰øÉÈÄ≤Ê®°Âûã‰πãÈñìÁöÑÊØîËºÉ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫ CarbonSenseÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÈÅ©Áî®Êñº DDCFM ÁöÑÊ©üÂô®Â≠∏ÁøíÊ∫ñÂÇôË≥áÊñôÈõÜ„ÄÇCarbonSense Êï¥Âêà‰∫Ü‰æÜËá™ÂÖ®ÁêÉ 385 ÂÄãÂú∞ÈªûÁöÑÊ∏¨ÈáèÁ¢≥ÈÄöÈáè„ÄÅÊ∞£Ë±°È†êÊ∏¨Âõ†Â≠êÂíåË°õÊòüÂΩ±ÂÉèÔºåÊèê‰æõÂÖ®Èù¢ÁöÑÊ∂µËìãÁØÑÂúç‰∏¶‰øÉÈÄ≤Á©©ÂÅ•ÁöÑÊ®°ÂûãË®ìÁ∑¥„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ΩøÁî®Áï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑ DDCFM ÊñπÊ≥ïÂíåÂü∫ÊñºÊñ∞Á©éTransformerÁöÑÊ®°ÂûãÊèê‰æõÂü∫Ê∫ñÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË™™Êòé‰∫ÜÂ§öÊ®°ÊÖãÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÂèØ‰ª•ÁÇ∫ÈÄôÂÄãÈ†òÂüüÂ∏∂‰æÜÁöÑÊΩõÂú®Êî∂Áõä„ÄÇÈÄèÈÅéÊèê‰æõÈÄô‰∫õË≥áÊ∫êÔºåÊàëÂÄëÊó®Âú®Èôç‰ΩéÂÖ∂‰ªñÊ∑±Â∫¶Â≠∏ÁøíÁ†îÁ©∂‰∫∫Âì°ÈÄ≤ÂÖ•ÈñÄÊ™ªÔºå‰ª•ÈñãÁôºÊñ∞Ê®°Âûã‰∏¶Êé®ÂãïÁ¢≥ÈÄöÈáèÂª∫Ê®°ÁöÑÊñ∞ÈÄ≤Â±ï„ÄÇ

##### **PANDORA: Deep graph learning based COVID-19 infection risk level forecasting**
2406.06618v1 by Shuo Yu, Feng Xia, Yueru Wang, Shihao Li, Falih Febrinanto, Madhu Chetty

COVID-19 as a global pandemic causes a massive disruption to social stability
that threatens human life and the economy. Policymakers and all elements of
society must deliver measurable actions based on the pandemic's severity to
minimize the detrimental impact of COVID-19. A proper forecasting system is
arguably important to provide an early signal of the risk of COVID-19 infection
so that the authorities are ready to protect the people from the worst.
However, making a good forecasting model for infection risks in different
cities or regions is not an easy task, because it has a lot of influential
factors that are difficult to be identified manually. To address the current
limitations, we propose a deep graph learning model, called PANDORA, to predict
the infection risks of COVID-19, by considering all essential factors and
integrating them into a geographical network. The framework uses geographical
position relations and transportation frequency as higher-order structural
properties formulated by higher-order network structures (i.e., network
motifs). Moreover, four significant node attributes (i.e., multiple features of
a particular area, including climate, medical condition, economy, and human
mobility) are also considered. We propose three different aggregators to better
aggregate node attributes and structural features, namely, Hadamard, Summation,
and Connection. Experimental results over real data show that PANDORA
outperforms the baseline method with higher accuracy and faster convergence
speed, no matter which aggregator is chosen. We believe that PANDORA using deep
graph learning provides a promising approach to get superior performance in
infection risk level forecasting and help humans battle the COVID-19 crisis.

ÊëòË¶ÅÔºöCOVID-19 ‰ΩúÁÇ∫ÂÖ®ÁêÉÂ§ßÊµÅË°åÁóÖÂ∞çÁ§æÊúÉÁ©©ÂÆöÈÄ†ÊàêÂ§ßË¶èÊ®°ÁöÑÁ†¥Â£ûÔºåÂ®ÅËÑÖÂà∞‰∫∫È°ûÁîüÂëΩÂíåÁ∂ìÊøü„ÄÇÊîøÁ≠ñÂà∂ÂÆöËÄÖÂíåÁ§æÊúÉÂêÑÈöéÂ±§ÂøÖÈ†àÊ†πÊìöÁñ´ÊÉÖÁöÑÂö¥ÈáçÁ®ãÂ∫¶Êé°ÂèñÂèØË°°ÈáèÁöÑË°åÂãïÔºå‰ª•Â∞á COVID-19 ÁöÑ‰∏çÂà©ÂΩ±ÈüøÈôçÂà∞ÊúÄ‰Ωé„ÄÇ‰∏ÄÂÄãÈÅ©Áï∂ÁöÑÈ†êÊ∏¨Á≥ªÁµ±ÁÑ°ÁñëÂ∞çÊñºÊèê‰æõ COVID-19 ÊÑüÊüìÈ¢®Èö™ÁöÑÊó©Êúü‰ø°ËôüÈùûÂ∏∏ÈáçË¶ÅÔºå‰ª•‰æøÁï∂Â±ÄÂÅöÂ•ΩÊ∫ñÂÇô‰øùË≠∑‰∫∫Ê∞ëÂÖçÊñºÊúÄÂ£ûÁöÑÁãÄÊ≥Å„ÄÇÁÑ∂ËÄåÔºåÁÇ∫‰∏çÂêåÂüéÂ∏ÇÊàñÂú∞ÂçÄÁöÑÊÑüÊüìÈ¢®Èö™Âª∫Á´ã‰∏ÄÂÄãËâØÂ•ΩÁöÑÈ†êÊ∏¨Ê®°Âûã‰∏¶ÈùûÊòì‰∫ãÔºåÂõ†ÁÇ∫ÂÆÉÊúâË®±Â§öÂΩ±ÈüøÂõ†Á¥†ÔºåÈõ£‰ª•‰∫∫Â∑•Ë≠òÂà•„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÁõÆÂâçÁöÑÂ±ÄÈôêÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ PANDORA ÁöÑÊ∑±Â∫¶ÂúñÂ≠∏ÁøíÊ®°ÂûãÔºåÈÄöÈÅéËÄÉÊÖÆÊâÄÊúâÂøÖË¶ÅÂõ†Á¥†‰∏¶Â∞áÂÆÉÂÄëÊï¥ÂêàÂà∞‰∏ÄÂÄãÂú∞ÁêÜÁ∂≤Ë∑Ø‰∏≠Ôºå‰æÜÈ†êÊ∏¨ COVID-19 ÁöÑÊÑüÊüìÈ¢®Èö™„ÄÇË©≤Ê°ÜÊû∂‰ΩøÁî®Âú∞ÁêÜ‰ΩçÁΩÆÈóú‰øÇÂíåÈÅãËº∏È†ªÁéá‰ΩúÁÇ∫Áî±È´òÈöéÁ∂≤Ë∑ØÁµêÊßãÔºàÂç≥Á∂≤Ë∑Ø‰∏ªÈ°åÔºâÂà∂ÂÆöÁöÑÈ´òÈöéÁµêÊßãÂ±¨ÊÄß„ÄÇÊ≠§Â§ñÔºåÈÇÑËÄÉÊÖÆ‰∫ÜÂõõÂÄãÈáçË¶ÅÁöÑÁØÄÈªûÂ±¨ÊÄßÔºàÂç≥ÁâπÂÆöÂçÄÂüüÁöÑÊ∞£ÂÄô„ÄÅÈÜ´ÁôÇÊ¢ù‰ª∂„ÄÅÁ∂ìÊøüÂíå‰∫∫È°ûÊµÅÂãïÊÄßÁ≠âÂ§öÁ®ÆÁâπÂæµÔºâ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏âÂÄã‰∏çÂêåÁöÑËÅöÂêàÂô®‰æÜÊõ¥Â•ΩÂú∞ËÅöÂêàÁØÄÈªûÂ±¨ÊÄßÂíåÁµêÊßãÁâπÂæµÔºåÂç≥ Hadamard„ÄÅSummation Âíå Connection„ÄÇÂú®ÁúüÂØ¶Ë≥áÊñô‰∏äÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÁÑ°Ë´ñÈÅ∏ÊìáÂì™ÂÄãËÅöÂêàÂô®ÔºåPANDORA ÈÉΩ‰ª•Êõ¥È´òÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊõ¥Âø´ÁöÑÊî∂ÊñÇÈÄüÂ∫¶ÂÑ™ÊñºÂü∫Á∑öÊñπÊ≥ï„ÄÇÊàëÂÄëÁõ∏‰ø°‰ΩøÁî®Ê∑±Â∫¶ÂúñÂ≠∏ÁøíÁöÑ PANDORA Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Âú®ÊÑüÊüìÈ¢®Èö™Á≠âÁ¥öÈ†êÊ∏¨‰∏≠Áç≤ÂæóÂçìË∂äÁöÑÊÄßËÉΩÔºå‰∏¶Âπ´Âä©‰∫∫È°ûÊà∞Âãù COVID-19 Âç±Ê©ü„ÄÇ

##### **Transforming Dental Diagnostics with Artificial Intelligence: Advanced Integration of ChatGPT and Large Language Models for Patient Care**
2406.06616v1 by Masoumeh Farhadi Nia, Mohsen Ahmadi, Elyas Irankhah

Artificial intelligence has dramatically reshaped our interaction with
digital technologies, ushering in an era where advancements in AI algorithms
and Large Language Models (LLMs) have natural language processing (NLP) systems
like ChatGPT. This study delves into the impact of cutting-edge LLMs, notably
OpenAI's ChatGPT, on medical diagnostics, with a keen focus on the dental
sector. Leveraging publicly accessible datasets, these models augment the
diagnostic capabilities of medical professionals, streamline communication
between patients and healthcare providers, and enhance the efficiency of
clinical procedures. The advent of ChatGPT-4 is poised to make substantial
inroads into dental practices, especially in the realm of oral surgery. This
paper sheds light on the current landscape and explores potential future
research directions in the burgeoning field of LLMs, offering valuable insights
for both practitioners and developers. Furthermore, it critically assesses the
broad implications and challenges within various sectors, including academia
and healthcare, thus mapping out an overview of AI's role in transforming
dental diagnostics for enhanced patient care.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÂæπÂ∫ïÊîπËÆä‰∫ÜÊàëÂÄëËàáÊï∏‰ΩçÁßëÊäÄÁöÑ‰∫íÂãïÔºåÂºïÈ†òÊàëÂÄëÈÄ≤ÂÖ•‰∏ÄÂÄã AI ÊºîÁÆóÊ≥ïÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëì¨ÂãÉÁôºÂ±ïÁöÑÊôÇ‰ª£ÔºåÊìÅÊúâËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Á≥ªÁµ±Ôºå‰æãÂ¶Ç ChatGPT„ÄÇÊú¨Á†îÁ©∂Ê∑±ÂÖ•Êé¢Ë®éÂ∞ñÁ´Ø LLMÔºåÁâπÂà•ÊòØ OpenAI ÁöÑ ChatGPTÔºåÂ∞çÈÜ´ÁôÇË®∫Êñ∑ÁöÑÂΩ±ÈüøÔºå‰∏¶ÁâπÂà•ÈóúÊ≥®ÁâôÁßëÈ†òÂüü„ÄÇÈÄèÈÅéÈÅãÁî®ÂÖ¨ÈñãÂ≠òÂèñÁöÑË≥áÊñôÈõÜÔºåÈÄô‰∫õÊ®°ÂûãÂ¢ûÂº∑‰∫ÜÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÁöÑË®∫Êñ∑ËÉΩÂäõÔºåÁ∞°Âåñ‰∫ÜÊÇ£ËÄÖËàáÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖ‰πãÈñìÁöÑÊ∫ùÈÄöÔºå‰∏¶ÊèêÈ´ò‰∫ÜËá®Â∫äÁ®ãÂ∫èÁöÑÊïàÁéá„ÄÇChatGPT-4 ÁöÑÂá∫ÁèæÊ∫ñÂÇôÂú®ÁâôÁßëÂØ¶Âãô‰∏≠ÂèñÂæóÈáçÂ§ßÈÄ≤Â±ïÔºåÂ∞§ÂÖ∂ÊòØÂú®Âè£ËÖîÂ§ñÁßëÈ†òÂüü„ÄÇÊú¨ÊñáÈó°Êòé‰∫ÜÁõÆÂâçÁöÑÁèæÊ≥ÅÔºå‰∏¶Êé¢Ë®é‰∫ÜËì¨ÂãÉÁôºÂ±ïÁöÑ LLM È†òÂüü‰∏≠ÊΩõÂú®ÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêëÔºåÁÇ∫ÂØ¶ÂãôÂ∑•‰ΩúËÄÖÂíåÈñãÁôº‰∫∫Âì°Êèê‰æõÂØ∂Ë≤¥ÁöÑË¶ãËß£„ÄÇÊ≠§Â§ñÔºåÂÆÉÊâπÂà§ÊÄßÂú∞Ë©ï‰º∞‰∫ÜÂêÑÂÄãÈ†òÂüüÔºàÂåÖÊã¨Â≠∏Ë°ìÁïåÂíåÈÜ´ÁôÇ‰øùÂÅ•Ôºâ‰∏≠ÁöÑÂª£Ê≥õÂΩ±ÈüøÂíåÊåëÊà∞ÔºåÂæûËÄåÊ¶ÇËø∞‰∫Ü AI Âú®ËΩâËÆäÁâôÁßëË®∫Êñ∑‰ª•Â¢ûÂº∑ÊÇ£ËÄÖÁÖßË≠∑‰∏≠ÁöÑËßíËâ≤„ÄÇ

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

ÊëòË¶ÅÔºöËá™Ê≥®ÊÑèÂäõÊ©üÂà∂Â∑≤Ë¢´Êé°Áî®ÊñºÂ§öÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑË®äÊÅØÂÇ≥ÈÅûÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MPNN)Ôºà‰æãÂ¶Ç GATÔºâÔºåÂÆÉÂèØ‰ª•Ëá™ÈÅ©ÊáâÂú∞ÊéßÂà∂Ê≤øËëóÂ∫ïÂ±§ÂúñÂΩ¢ÈÇäÁ∑£ÊµÅÂãïÁöÑË≥áË®äÈáè„ÄÇÈÄôÁ®ÆÊ≥®ÊÑèÂäõÁöÑ‰ΩøÁî®‰ΩøÂæóÊ≠§È°ûÊ®°ÂûãÊàêÁÇ∫ÂèØËß£Èáã AI (XAI) Á†îÁ©∂ÁöÑÂü∫Á∑öÔºåÂõ†ÁÇ∫ÈÄèÈÅéÊ≥®ÊÑèÂäõÁöÑË©ÆÈáãÂ∑≤Âú®ÂêÑÁ®ÆÈ†òÂüüÔºà‰æãÂ¶ÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂíåÈõªËÖ¶Ë¶ñË¶∫Ôºâ‰∏≠ÊôÆÂèä„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂ÈÄöÂ∏∏‰ΩøÁî®Â§©ÁúüÁöÑË®àÁÆóÊñπÊ≥ïÂæûÊ≥®ÊÑèÂäõ‰∏≠Êé®Â∞éÂá∫Ê≠∏Âõ†ÂàÜÊï∏Ôºå‰∏¶‰∏îÊ≤íÊúâËÄÉÊÖÆÂà∞ÈÇäÁ∑£Ê≠∏Âõ†ÁöÑÁ≤æÁ¢∫‰∏î‰ªîÁ¥∞ÁöÑË®àÁÆó„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊó®Âú®Â°´Ë£úÊ≥®ÊÑèÂäõÂïüÁî® MPNN ÁöÑÂª£Ê≥õ‰ΩøÁî®ËàáÂÆÉÂÄëÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÁöÑÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÈÄôÂÄã‰∏ªÈ°åÂ∑≤Âú®ÂÖ∂‰ªñÈ†òÂüüÁ©çÊ•µÁ†îÁ©∂„ÄÇÁÇ∫Ê≠§Ôºå‰ΩúÁÇ∫Á¨¨‰∏ÄÊ¨°ÂòóË©¶ÔºåÊàëÂÄëÂ∞á GNN ‰∏≠Ê≥®ÊÑèÂäõÊ¨äÈáçÁöÑÈÇäÁ∑£Ê≠∏Âõ†ÂïèÈ°åÂΩ¢ÂºèÂåñ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫ GATTÔºå‰∏ÄÁ®ÆÂª∫Á´ãÂú®Ë®àÁÆóÊ®π‰∏äÁöÑÈÇäÁ∑£Ê≠∏Âõ†Ë®àÁÆóÊñπÊ≥ï„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Ë©ï‰º∞ GAT ÁöÑÊ≠∏Âõ†ÊôÇÊâÄÂÖ∑ÊúâÁöÑÊïàÊûú„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄëÊÜëÁ∂ìÈ©óÈ©óË≠â‰∫ÜÂÉÖÂ∞çÂúñÊ≥®ÊÑèÂäõÂ±§‰∏äÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÂèñÂπ≥ÂùáÂÄº‰∏çË∂≥‰ª•Ë©ÆÈáã GAT Ê®°ÂûãÁöÑË°åÁÇ∫„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº https://github.com/jordan7186/GAtt/tree/main„ÄÇ

##### **Rare Class Prediction Model for Smart Industry in Semiconductor Manufacturing**
2406.04533v1 by Abdelrahman Farrag, Mohammed-Khalil Ghali, Yu Jin

The evolution of industry has enabled the integration of physical and digital
systems, facilitating the collection of extensive data on manufacturing
processes. This integration provides a reliable solution for improving process
quality and managing equipment health. However, data collected from real
manufacturing processes often exhibit challenging properties, such as severe
class imbalance, high rates of missing values, and noisy features, which hinder
effective machine learning implementation. In this study, a rare class
prediction approach is developed for in situ data collected from a smart
semiconductor manufacturing process. The primary objective is to build a model
that addresses issues of noise and class imbalance, enhancing class separation.
The developed approach demonstrated promising results compared to existing
literature, which would allow the prediction of new observations that could
give insights into future maintenance plans and production quality. The model
was evaluated using various performance metrics, with ROC curves showing an AUC
of 0.95, a precision of 0.66, and a recall of 0.96

ÊëòË¶ÅÔºöÁî¢Ê•≠ÁöÑÊºîÈÄ≤‰ΩøÂæóÂØ¶È´îËàáÊï∏‰ΩçÁ≥ªÁµ±Âæó‰ª•Êï¥ÂêàÔºå‰øÉ‰ΩøË£ΩÈÄ†ÊµÅÁ®ã‰∏≠ËÉΩÊî∂ÈõÜÂà∞Âª£Ê≥õÁöÑË≥áÊñô„ÄÇÊ≠§Êï¥ÂêàÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÈù†ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºÊîπÂñÑÊµÅÁ®ãÂìÅË≥™‰∏¶ÁÆ°ÁêÜË®≠ÂÇôÂÅ•Â∫∑„ÄÇÁÑ∂ËÄåÔºåÂæûÁúüÂØ¶Ë£ΩÈÄ†ÊµÅÁ®ãÊî∂ÈõÜÂà∞ÁöÑË≥áÊñôÈÄöÂ∏∏ÊúÉË°®ÁèæÂá∫ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁâπÊÄßÔºå‰æãÂ¶ÇÂö¥ÈáçÁöÑÈ°ûÂà•‰∏çÂπ≥Ë°°„ÄÅÈ´òÊØîÁéáÁöÑÈÅ∫Â§±ÂÄºÂíåÊúâÈõúË®äÁöÑÁâπÂæµÔºåÈÄô‰∫õÈÉΩÊúÉÈòªÁ§ôÊúâÊïàÁöÑÊ©üÂô®Â≠∏ÁøíÂØ¶‰Ωú„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÁ®ÄÊúâÈ°ûÂà•È†êÊ∏¨ÊñπÊ≥ïÔºåÁî®ÊñºÂæûÊô∫ÊÖßÂçäÂ∞éÈ´îË£ΩÈÄ†ÊµÅÁ®ãÊî∂ÈõÜÁöÑÁèæÂ†¥Ë≥áÊñô„ÄÇ‰∏ªË¶ÅÁõÆÊ®ôÊòØÂª∫Á´ã‰∏ÄÂÄãÊ®°ÂûãÔºåÁî®ÊñºËß£Ê±∫ÈõúË®äÂíåÈ°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÂïèÈ°åÔºå‰∏¶Â¢ûÂº∑È°ûÂà•ÂàÜÈõ¢„ÄÇËàáÁèæÊúâÁöÑÊñáÁçªÁõ∏ÊØîÔºåÊâÄÈñãÁôºÁöÑÊñπÊ≥ïÂ±ïÁèæÂá∫ÊúâÂâçÊôØÁöÑÁµêÊûúÔºåÈÄôÂ∞áÂÖÅË®±È†êÊ∏¨Êñ∞ÁöÑËßÄÂØüÁµêÊûúÔºåÈÄô‰∫õËßÄÂØüÁµêÊûúÂèØ‰ª•Êèê‰æõÂ∞çÊú™‰æÜÁ∂≠Ë≠∑Ë®àÁï´ÂíåÁîüÁî¢ÂìÅË≥™ÁöÑË¶ãËß£„ÄÇ‰ΩøÁî®ÂêÑÁ®ÆÊïàËÉΩÊåáÊ®ôË©ï‰º∞Ê≠§Ê®°ÂûãÔºåROC Êõ≤Á∑öÈ°ØÁ§∫ AUC ÁÇ∫ 0.95„ÄÅÁ≤æÁ¢∫Â∫¶ÁÇ∫ 0.66„ÄÅÂè¨ÂõûÁéáÁÇ∫ 0.96

##### **Single Exposure Quantitative Phase Imaging with a Conventional Microscope using Diffusion Models**
2406.04388v1 by Gabriel della Maggiora, Luis Alberto Croquevielle, Harry Horsley, Thomas Heinis, Artur Yakimovich

Phase imaging is gaining importance due to its applications in fields like
biomedical imaging and material characterization. In biomedical applications,
it can provide quantitative information missing in label-free microscopy
modalities. One of the most prominent methods in phase quantification is the
Transport-of-Intensity Equation (TIE). TIE often requires multiple acquisitions
at different defocus distances, which is not always feasible in a clinical
setting. To address this issue, we propose to use chromatic aberrations to
induce the required through-focus images with a single exposure, effectively
generating a through-focus stack. Since the defocus distance induced by the
aberrations is small, conventional TIE solvers are insufficient to address the
resulting artifacts. We propose Zero-Mean Diffusion, a modified version of
diffusion models designed for quantitative image prediction, and train it with
synthetic data to ensure robust phase retrieval. Our contributions offer an
alternative TIE approach that leverages chromatic aberrations, achieving
accurate single-exposure phase measurement with white light and thus improving
the efficiency of phase imaging. Moreover, we present a new class of diffusion
models that are well-suited for quantitative data and have a sound theoretical
basis. To validate our approach, we employ a widespread brightfield microscope
equipped with a commercially available color camera. We apply our model to
clinical microscopy of patients' urine, obtaining accurate phase measurements.

ÊëòË¶ÅÔºöÁõ∏‰ΩçÂΩ±ÂÉèÁî±ÊñºÂú®ÁîüÁâ©ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊùêÊñôË°®ÂæµÁ≠âÈ†òÂüüÁöÑÊáâÁî®ËÄåÊó•ÁõäÈáçË¶Å„ÄÇÂú®ÁîüÁâ©ÈÜ´Â≠∏ÊáâÁî®‰∏≠ÔºåÂÆÉÂèØ‰ª•Êèê‰æõÊ®ôÁ±§È°ØÂæÆÈè°Ê®°Âºè‰∏≠Áº∫Â∞ëÁöÑÈáèÂåñË≥áË®ä„ÄÇÁõ∏‰ΩçÈáèÂåñÁöÑÊúÄÈ°ØËëóÊñπÊ≥ï‰πã‰∏ÄÊòØÂº∑Â∫¶ÂÇ≥Ëº∏ÊñπÁ®ãÂºè (TIE)„ÄÇTIE ÈÄöÂ∏∏ÈúÄË¶ÅÂú®‰∏çÂêåÁöÑÊï£ÁÑ¶Ë∑ùÈõ¢‰∏ãÈÄ≤Ë°åÂ§öÊ¨°Êì∑ÂèñÔºåÈÄôÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠‰∏¶‰∏çÁ∏ΩÊòØÂèØË°åÁöÑ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®Ëâ≤Â∑Æ‰æÜË™òÂ∞éÊâÄÈúÄÁöÑÈÄèÈÅéÁÑ¶ÈªûÂΩ±ÂÉèÔºå‰∏¶ÈÄèÈÅéÂñÆÊ¨°ÊõùÂÖâÊúâÊïàÂú∞Áî¢ÁîüÈÄèÈÅéÁÑ¶ÈªûÂ†ÜÁñä„ÄÇÁî±ÊñºËâ≤Â∑ÆÊâÄÁî¢ÁîüÁöÑÊï£ÁÑ¶Ë∑ùÈõ¢ÂæàÂ∞èÔºåÂõ†Ê≠§ÂÇ≥Áµ±ÁöÑ TIE Ëß£Ê±∫Âô®‰∏çË∂≥‰ª•Ëß£Ê±∫Áî¢ÁîüÁöÑÂÅΩÂÉè„ÄÇÊàëÂÄëÊèêÂá∫Èõ∂ÂùáÂÄºÊì¥Êï£Ôºå‰∏ÄÁ®ÆÈáùÂ∞çÈáèÂåñÂΩ±ÂÉèÈ†êÊ∏¨ËÄåË®≠Ë®àÁöÑÊì¥Êï£Ê®°ÂûãÁöÑ‰øÆÊîπÁâàÊú¨Ôºå‰∏¶‰ΩøÁî®ÂêàÊàêË≥áÊñôË®ìÁ∑¥ÂÆÉ‰ª•Á¢∫‰øùÁ©©ÂÅ•ÁöÑÁõ∏‰ΩçÊì∑Âèñ„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂà©Áî®Ëâ≤Â∑ÆÁöÑÊõø‰ª£ TIE ÊñπÊ≥ïÔºåÂØ¶Áèæ‰∫ÜÊ∫ñÁ¢∫ÁöÑÂñÆÊ¨°ÊõùÂÖâÁõ∏‰ΩçÊ∏¨ÈáèÔºåÂæûËÄåÊèêÈ´ò‰∫ÜÁõ∏‰ΩçÂΩ±ÂÉèÁöÑÊïàÁéá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÈ°ûÊñ∞ÁöÑÊì¥Êï£Ê®°ÂûãÔºåÂÆÉÂÄëÈùûÂ∏∏ÈÅ©ÂêàÈáèÂåñË≥áÊñôÔºå‰∏¶ÂÖ∑ÊúâËâØÂ•ΩÁöÑÁêÜË´ñÂü∫Á§é„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄëÊé°Áî®ÈÖçÂÇôÂ∏ÇÂîÆÂΩ©Ëâ≤Áõ∏Ê©üÁöÑÂª£Ê≥õ‰ΩøÁî®ÊòéÂ†¥È°ØÂæÆÈè°„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÊ®°ÂûãÊáâÁî®ÊñºÊÇ£ËÄÖÂ∞øÊ∂≤ÁöÑËá®Â∫äÈ°ØÂæÆÈè°Ê™¢Êü•ÔºåÁç≤ÂæóÊ∫ñÁ¢∫ÁöÑÁõ∏‰ΩçÊ∏¨Èáè„ÄÇ

##### **Promoting Fairness and Diversity in Speech Datasets for Mental Health and Neurological Disorders Research**
2406.04116v1 by Eleonora Mancini, Ana Tanevska, Andrea Galassi, Alessio Galatolo, Federico Ruggeri, Paolo Torroni

Current research in machine learning and artificial intelligence is largely
centered on modeling and performance evaluation, less so on data collection.
However, recent research demonstrated that limitations and biases in data may
negatively impact trustworthiness and reliability. These aspects are
particularly impactful on sensitive domains such as mental health and
neurological disorders, where speech data are used to develop AI applications
aimed at improving the health of patients and supporting healthcare providers.
In this paper, we chart the landscape of available speech datasets for this
domain, to highlight possible pitfalls and opportunities for improvement and
promote fairness and diversity. We present a comprehensive list of desiderata
for building speech datasets for mental health and neurological disorders and
distill it into a checklist focused on ethical concerns to foster more
responsible research.

ÊëòË¶ÅÔºöÁõÆÂâçÁöÑÊ©üÂô®Â≠∏ÁøíÂíå‰∫∫Â∑•Êô∫ÊÖßÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Âú®Âª∫Ê®°ÂíåÊïàËÉΩË©ï‰º∞‰∏äÔºåËºÉÂ∞ëËëóÈáçÊñºË≥áÊñôÊî∂ÈõÜ„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåË≥áÊñô‰∏≠ÁöÑÈôêÂà∂ÂíåÂÅèË¶ãÂèØËÉΩÊúÉÂ∞çÂèØ‰ø°Â∫¶ÂíåÂèØÈù†ÊÄßÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÈÄô‰∫õÈù¢ÂêëÂú®ÂøÉÁêÜÂÅ•Â∫∑ÂíåÁ•ûÁ∂ìÁñæÁóÖÁ≠âÊïèÊÑüÈ†òÂüü‰∏≠ÁâπÂà•ÂÖ∑ÊúâÂΩ±ÈüøÂäõÔºåÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠ÔºåË™ûÈü≥Ë≥áÊñôÁî®ÊñºÈñãÁôº‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºèÔºåÊó®Âú®ÊîπÂñÑÊÇ£ËÄÖÂÅ•Â∫∑‰∏¶ÊîØÊè¥ÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁπ™Ë£Ω‰∫ÜÊ≠§È†òÂüüÂèØÁî®ÁöÑË™ûÈü≥Ë≥áÊñôÈõÜÊ¶ÇÊ≥ÅÔºå‰ª•Âº∑Ë™øÂèØËÉΩÁöÑÈô∑Èò±ÂíåÊîπÈÄ≤Ê©üÊúÉÔºå‰∏¶‰øÉÈÄ≤ÂÖ¨Âπ≥ÊÄßÂíåÂ§öÊ®£ÊÄß„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÊ∏ÖÂñÆÔºåË™™Êòé‰∫ÜÂª∫Á´ãÂøÉÁêÜÂÅ•Â∫∑ÂíåÁ•ûÁ∂ìÁñæÁóÖË™ûÈü≥Ë≥áÊñôÈõÜÁöÑÁêÜÊÉ≥Ê¢ù‰ª∂Ôºå‰∏¶Â∞áÂÖ∂ÊøÉÁ∏ÆÊàê‰∏ÄÂÄãÂ∞àÊ≥®ÊñºÈÅìÂæ∑ËÄÉÈáèÁöÑÊ™¢Êü•Ê∏ÖÂñÆÔºå‰ª•‰øÉÈÄ≤Êõ¥Ë≤†Ë≤¨‰ªªÁöÑÁ†îÁ©∂„ÄÇ

##### **Leveraging SPD Matrices on Riemannian Manifolds in Quantum Classical Hybrid Models for Structural Health Monitoring**
2406.04055v1 by Azadeh Alavi, Sanduni Jayasinghe

Realtime finite element modeling of bridges assists modern structural health
monitoring systems by providing comprehensive insights into structural
integrity. This capability is essential for ensuring the safe operation of
bridges and preventing sudden catastrophic failures. However, FEM computational
cost and the need for realtime analysis pose significant challenges.
Additionally, the input data is a 7 dimensional vector, while the output is a
1017 dimensional vector, making accurate and efficient analysis particularly
difficult. In this study, we propose a novel hybrid quantum classical
Multilayer Perceptron pipeline leveraging Symmetric Positive Definite matrices
and Riemannian manifolds for effective data representation. To maintain the
integrity of the qubit structure, we utilize SPD matrices, ensuring data
representation is well aligned with the quantum computational framework.
Additionally, the method leverages polynomial feature expansion to capture
nonlinear relationships within the data. The proposed pipeline combines
classical fully connected neural network layers with quantum circuit layers to
enhance model performance and efficiency. Our experiments focused on various
configurations of such hybrid models to identify the optimal structure for
accurate and efficient realtime analysis. The best performing model achieved a
Mean Squared Error of 0.00031, significantly outperforming traditional methods.

ÊëòË¶ÅÔºöÊ©ãÊ®ëÁöÑÂç≥ÊôÇÊúâÈôêÂÖÉÁ¥†Âª∫Ê®°ÈÄèÈÅéÊèê‰æõÁµêÊßãÂÆåÊï¥ÊÄßÁöÑÂÖ®Èù¢Ë¶ãËß£ÔºåÂçîÂä©Áèæ‰ª£ÁµêÊßãÂÅ•Â∫∑Áõ£ÊéßÁ≥ªÁµ±„ÄÇÊ≠§ÂäüËÉΩÂ∞çÊñºÁ¢∫‰øùÊ©ãÊ®ëÂÆâÂÖ®Êìç‰ΩúÂíåÈò≤Ê≠¢Á™ÅÁÑ∂ÁÅΩÈõ£ÊÄßÊïÖÈöúËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÊúâÈôêÂÖÉÁ¥†ÊñπÊ≥ïÁöÑÈÅãÁÆóÊàêÊú¨ÂíåÂç≥ÊôÇÂàÜÊûêÁöÑÈúÄÊ±ÇÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåËº∏ÂÖ•Ë≥áÊñôÊòØ 7 Á∂≠ÂêëÈáèÔºåËÄåËº∏Âá∫ÊòØ 1017 Á∂≠ÂêëÈáèÔºåÈÄô‰ΩøÂæóÊ∫ñÁ¢∫ËÄåÊúâÊïàÁöÑÂàÜÊûêÁâπÂà•Âõ∞Èõ£„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ∑∑ÂêàÈáèÂ≠êÁ∂ìÂÖ∏Â§öÂ±§ÊÑüÁü•Âô®ÁÆ°ÈÅìÔºåÂà©Áî®Â∞çÁ®±Ê≠£ÂÆöÁü©Èô£ÂíåÈªéÊõºÊµÅÂΩ¢ÈÄ≤Ë°åÊúâÊïàÁöÑË≥áÊñôË°®Á§∫„ÄÇÁÇ∫‰∫ÜÁ∂≠Ë≠∑ÈáèÂ≠ê‰ΩçÂÖÉÁµêÊßãÁöÑÂÆåÊï¥ÊÄßÔºåÊàëÂÄëÂà©Áî®Â∞çÁ®±Ê≠£ÂÆöÁü©Èô£ÔºåÁ¢∫‰øùË≥áÊñôË°®Á§∫ËàáÈáèÂ≠êÈÅãÁÆóÊ°ÜÊû∂ÂÆåÂÖ®‰∏ÄËá¥„ÄÇÊ≠§Â§ñÔºåÊ≠§ÊñπÊ≥ïÂà©Áî®Â§öÈ†ÖÂºèÁâπÂæµÂ±ïÈñã‰æÜÊì∑ÂèñË≥áÊñô‰∏≠ÁöÑÈùûÁ∑öÊÄßÈóú‰øÇ„ÄÇÊâÄÊèêÂá∫ÁöÑÁÆ°ÈÅìÁµêÂêà‰∫ÜÁ∂ìÂÖ∏ÂÖ®ÈÄ£Êé•Á•ûÁ∂ìÁ∂≤Ë∑ØÂ±§ÂíåÈáèÂ≠êÈõªË∑ØÂ±§Ôºå‰ª•Â¢ûÂº∑Ê®°ÂûãÊïàËÉΩÂíåÊïàÁéá„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂ∞àÊ≥®ÊñºÊ≠§È°ûÊ∑∑ÂêàÊ®°ÂûãÁöÑÂêÑÁ®ÆÈÖçÁΩÆÔºå‰ª•Ë≠òÂà•Ê∫ñÁ¢∫‰∏îÊúâÊïàÁöÑÂç≥ÊôÇÂàÜÊûêÁöÑÊúÄ‰Ω≥ÁµêÊßã„ÄÇÊïàËÉΩÊúÄ‰Ω≥ÁöÑÊ®°ÂûãÈÅîÂà∞‰∫Ü 0.00031 ÁöÑÂπ≥ÂùáÂπ≥ÊñπË™§Â∑ÆÔºåÈ°ØËëóÂÑ™ÊñºÂÇ≥Áµ±ÊñπÊ≥ï„ÄÇ

##### **Speech-based Clinical Depression Screening: An Empirical Study**
2406.03510v2 by Yangbin Chen, Chenyang Xu, Chunfeng Liang, Yanbao Tao, Chuan Shi

This study investigates the utility of speech signals for AI-based depression
screening across varied interaction scenarios, including psychiatric
interviews, chatbot conversations, and text readings. Participants include
depressed patients recruited from the outpatient clinics of Peking University
Sixth Hospital and control group members from the community, all diagnosed by
psychiatrists following standardized diagnostic protocols. We extracted
acoustic and deep speech features from each participant's segmented recordings.
Classifications were made using neural networks or SVMs, with aggregated clip
outcomes determining final assessments. Our analysis across interaction
scenarios, speech processing techniques, and feature types confirms speech as a
crucial marker for depression screening. Specifically, human-computer
interaction matches clinical interview efficacy, surpassing reading tasks.
Segment duration and quantity significantly affect model performance, with deep
speech features substantially outperforming traditional acoustic features.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë™øÊü•‰∫ÜË™ûÈü≥Ë®äËôüÂú®Âü∫Êñº‰∫∫Â∑•Êô∫ÊÖßÁöÑÊÜÇÈ¨±ÁóáÁØ©Ê™¢‰∏≠ÁöÑÊïàÁî®ÔºåÊ∂µËìãÂêÑÁ®Æ‰∫íÂãïÊÉÖÂ¢ÉÔºåÂåÖÊã¨Á≤æÁ•ûÁßëË®™Ë´á„ÄÅËÅäÂ§©Ê©üÂô®‰∫∫Â∞çË©±ÂíåÊñáÊú¨ÊúóËÆÄ„ÄÇÂèÉËàáËÄÖÂåÖÊã¨ÂæûÂåó‰∫¨Â§ßÂ≠∏Á¨¨ÂÖ≠ÈÜ´Èô¢ÈñÄË®∫ÈÉ®ÊãõÂãüÁöÑÊÜÇÈ¨±ÁóáÊÇ£ËÄÖÂíå‰æÜËá™Á§æÂçÄÁöÑÂ∞çÁÖßÁµÑÊàêÂì°ÔºåÊâÄÊúâÂèÉËàáËÄÖÂùáÁî±Á≤æÁ•ûÁßëÈÜ´Â∏´Ê†πÊìöÊ®ôÊ∫ñÂåñË®∫Êñ∑ÂçîÂÆöÈÄ≤Ë°åË®∫Êñ∑„ÄÇÊàëÂÄëÂæûÊØèÂÄãÂèÉËàáËÄÖÁöÑÂàÜÊÆµÈåÑÈü≥‰∏≠ÊèêÂèñ‰∫ÜËÅ≤Â≠∏ÂíåÊ∑±Â∫¶Ë™ûÈü≥ÁâπÂæµ„ÄÇÂàÜÈ°ûÊòØ‰ΩøÁî®Á•ûÁ∂ìÁ∂≤Ë∑ØÊàñÊîØÊè¥ÂêëÈáèÊ©üÈÄ≤Ë°åÁöÑÔºå‰∏¶‰ª•ÂåØÁ∏ΩÁöÑÁâáÊÆµÁµêÊûúÁ¢∫ÂÆöÊúÄÁµÇË©ï‰º∞„ÄÇÊàëÂÄëÂ∞ç‰∫íÂãïÊÉÖÂ¢É„ÄÅË™ûÈü≥ËôïÁêÜÊäÄË°ìÂíåÁâπÂæµÈ°ûÂûãÁöÑÂàÜÊûêË≠âÂØ¶‰∫ÜË™ûÈü≥ÊòØÊÜÇÈ¨±ÁóáÁØ©Ê™¢ÁöÑÈóúÈçµÊ®ôË®ò„ÄÇÂÖ∑È´î‰æÜË™™Ôºå‰∫∫Ê©ü‰∫íÂãïËàáËá®Â∫äË®™Ë´áÊïàËÉΩÁõ∏Á¨¶ÔºåÂÑ™ÊñºÈñ±ËÆÄ‰ªªÂãô„ÄÇÂàÜÊÆµÊåÅÁ∫åÊôÇÈñìÂíåÊï∏ÈáèÊúÉÈ°ØËëóÂΩ±ÈüøÊ®°ÂûãÊïàËÉΩÔºåÊ∑±Â∫¶Ë™ûÈü≥ÁâπÂæµÊòéÈ°ØÂÑ™ÊñºÂÇ≥Áµ±ËÅ≤Â≠∏ÁâπÂæµ„ÄÇ

##### **Robust Prediction Model for Multidimensional and Unbalanced Datasets**
2406.03507v1 by Pooja Thakar, Anil Mehta, Manisha

Data Mining is a promising field and is applied in multiple domains for its
predictive capabilities. Data in the real world cannot be readily used for data
mining as it suffers from the problems of multidimensionality, unbalance and
missing values. It is difficult to use its predictive capabilities by novice
users. It is difficult for a beginner to find the relevant set of attributes
from a large pool of data available. The paper presents a Robust Prediction
Model that finds a relevant set of attributes; resolves the problems of
unbalanced and multidimensional real-life datasets and helps in finding
patterns for informed decision making. Model is tested upon five different
datasets in the domain of Health Sector, Education, Business and Fraud
Detection. The results showcase the robust behaviour of the model and its
applicability in various domains.

ÊëòË¶ÅÔºöË≥áÊñôÊé¢ÂãòÊòØ‰∏ÄÂÄãÂæàÊúâÂâçÊôØÁöÑÈ†òÂüüÔºå‰∏¶Âõ†ÂÖ∂È†êÊ∏¨ËÉΩÂäõËÄåÊáâÁî®ÊñºÂ§öÂÄãÈ†òÂüü„ÄÇÁèæÂØ¶‰∏ñÁïå‰∏≠ÁöÑË≥áÊñô‰∏¶‰∏çËÉΩÁõ¥Êé•Áî®ÊñºË≥áÊñôÊé¢ÂãòÔºåÂõ†ÁÇ∫ÂÆÉÊúÉÂèóÂà∞Â§öÁ∂≠ÊÄß„ÄÅ‰∏çÂπ≥Ë°°ÂíåÈÅ∫Â§±ÂÄºÁöÑÂïèÈ°åÂΩ±Èüø„ÄÇÊñ∞ÊâãÁî®Êà∂ÂæàÈõ£‰ΩøÁî®ÂÖ∂È†êÊ∏¨ËÉΩÂäõ„ÄÇÂ∞çÊñºÂàùÂ≠∏ËÄÖ‰æÜË™™ÔºåÂæûÂ§ßÈáèÂèØÁî®ÁöÑË≥áÊñô‰∏≠ÊâæÂá∫Áõ∏ÈóúÁöÑÂ±¨ÊÄßÈõÜÊòØ‰∏Ä‰ª∂Âõ∞Èõ£ÁöÑ‰∫ã„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ©©ÂÅ•ÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåË©≤Ê®°ÂûãÂèØ‰ª•ÊâæÂà∞Áõ∏ÈóúÁöÑÂ±¨ÊÄßÈõÜÔºõËß£Ê±∫‰∏çÂπ≥Ë°°ÂíåÂ§öÁ∂≠ÁöÑÁèæÂØ¶ÁîüÊ¥ª‰∏≠Ë≥áÊñôÈõÜÁöÑÂïèÈ°åÔºå‰∏¶Âπ´Âä©ÊâæÂá∫Ê®°Âºè‰ª•ÈÄ≤Ë°åÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇË©≤Ê®°ÂûãÂú®ÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÊïôËÇ≤„ÄÅÂïÜÊ•≠ÂíåË©êÊ¨∫ÂÅµÊ∏¨È†òÂüüÁöÑ‰∫îÂÄã‰∏çÂêåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÊ∏¨Ë©¶„ÄÇÁµêÊûúÂ±ïÁ§∫‰∫ÜË©≤Ê®°ÂûãÁöÑÁ©©ÂÅ•Ë°åÁÇ∫ÂèäÂÖ∂Âú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇ

##### **Stochastic Diffusion: A Diffusion Probabilistic Model for Stochastic Time Series Forecasting**
2406.02827v1 by Yuansan Liu, Sudanthi Wijewickrema, Dongting Hu, Christofer Bester, Stephen O'Leary, James Bailey

Recent innovations in diffusion probabilistic models have paved the way for
significant progress in image, text and audio generation, leading to their
applications in generative time series forecasting. However, leveraging such
abilities to model highly stochastic time series data remains a challenge. In
this paper, we propose a novel Stochastic Diffusion (StochDiff) model which
learns data-driven prior knowledge at each time step by utilizing the
representational power of the stochastic latent spaces to model the variability
of the multivariate time series data. The learnt prior knowledge helps the
model to capture complex temporal dynamics and the inherent uncertainty of the
data. This improves its ability to model highly stochastic time series data.
Through extensive experiments on real-world datasets, we demonstrate the
effectiveness of our proposed model on stochastic time series forecasting.
Additionally, we showcase an application of our model for real-world surgical
guidance, highlighting its potential to benefit the medical community.

ÊëòË¶ÅÔºöÊúÄËøëÂú®Êì¥Êï£Ê©üÁéáÊ®°ÂûãÁöÑÂâµÊñ∞ÁÇ∫ÂΩ±ÂÉè„ÄÅÊñáÂ≠óÂíåÈü≥Ë®äÁîüÊàêÈ†òÂüüÁöÑÈ°ØËëóÈÄ≤Â±ïÈã™Ë∑ØÔºå‰∏¶ÊáâÁî®ÊñºÁîüÊàêÂºèÊôÇÂ∫èÈ†êÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÂà©Áî®ÈÄô‰∫õËÉΩÂäõ‰æÜÂª∫Ê®°È´òÂ∫¶Èö®Ê©üÁöÑÊôÇÂ∫èË≥áÊñô‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÈö®Ê©üÊì¥Êï£ (StochDiff) Ê®°ÂûãÔºåÂÆÉÂà©Áî®Èö®Ê©üÊΩõÂú®Á©∫ÈñìÁöÑË°®Á§∫ËÉΩÂäõÂú®ÊØèÂÄãÊôÇÈñìÊ≠•Èï∑Â≠∏ÁøíË≥áÊñôÈ©ÖÂãïÁöÑÂÖàÈ©óÁü•Ë≠òÔºå‰ª•Âª∫Ê®°Â§öËÆäÈáèÊôÇÂ∫èË≥áÊñôÁöÑËÆäÁï∞ÊÄß„ÄÇÂ≠∏ÁøíÂà∞ÁöÑÂÖàÈ©óÁü•Ë≠òÊúâÂä©ÊñºÊ®°ÂûãÊçïÊçâË§áÈõúÁöÑÊôÇÈñìÂãïÊÖãÂíåË≥áÊñôÁöÑÂÖßÂú®‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÈÄôÊîπÂñÑ‰∫ÜÂÆÉÂª∫Ê®°È´òÂ∫¶Èö®Ê©üÊôÇÂ∫èË≥áÊñôÁöÑËÉΩÂäõ„ÄÇÈÄèÈÅéÂ∞çÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÁöÑÂª£Ê≥õÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Èö®Ê©üÊôÇÂ∫èÈ†êÊ∏¨‰∏äÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊ®°ÂûãÂú®ÁúüÂØ¶‰∏ñÁïåÊâãË°ìÊåáÂ∞é‰∏≠ÁöÑÊáâÁî®ÔºåÁ™ÅÈ°Ø‰∫ÜÂÆÉÂ∞çÈÜ´Â≠∏ÁïåÊΩõÂú®ÁöÑÁõäËôï„ÄÇ

##### **Pancreatic Tumor Segmentation as Anomaly Detection in CT Images Using Denoising Diffusion Models**
2406.02653v1 by Reza Babaei, Samuel Cheng, Theresa Thai, Shangqing Zhao

Despite the advances in medicine, cancer has remained a formidable challenge.
Particularly in the case of pancreatic tumors, characterized by their diversity
and late diagnosis, early detection poses a significant challenge crucial for
effective treatment. The advancement of deep learning techniques, particularly
supervised algorithms, has significantly propelled pancreatic tumor detection
in the medical field. However, supervised deep learning approaches necessitate
extensive labeled medical images for training, yet acquiring such annotations
is both limited and costly. Conversely, weakly supervised anomaly detection
methods, requiring only image-level annotations, have garnered interest.
Existing methodologies predominantly hinge on generative adversarial networks
(GANs) or autoencoder models, which can pose complexity in training and, these
models may face difficulties in accurately preserving fine image details. This
research presents a novel approach to pancreatic tumor detection, employing
weak supervision anomaly detection through denoising diffusion algorithms. By
incorporating a deterministic iterative process of adding and removing noise
along with classifier guidance, the method enables seamless translation of
images between diseased and healthy subjects, resulting in detailed anomaly
maps without requiring complex training protocols and segmentation masks. This
study explores denoising diffusion models as a recent advancement over
traditional generative models like GANs, contributing to the field of
pancreatic tumor detection. Recognizing the low survival rates of pancreatic
cancer, this study emphasizes the need for continued research to leverage
diffusion models' efficiency in medical segmentation tasks.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÈÜ´Â≠∏ÈÄ≤Ê≠•ÔºåÁôåÁóá‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÂ∑®Â§ßÁöÑÊåëÊà∞„ÄÇ
ÁâπÂà•ÊòØÂú®ËÉ∞ËáüËÖ´Áò§ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂÖ∂ÁâπÂæµÊòØÂ§öÊ®£ÊÄßÂíåÊôöÊúüË®∫Êñ∑ÔºåÊó©ÊúüÊ™¢Ê∏¨Â∞çÊúâÊïàÊ≤ªÁôÇËá≥ÈóúÈáçË¶ÅÔºåÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÁöÑÈÄ≤Ê≠•ÔºåÁâπÂà•ÊòØÁõ£Áù£ÂºèÊºîÁÆóÊ≥ïÔºåÂ∑≤È°ØËëóÊé®Âãï‰∫ÜÈÜ´Â≠∏È†òÂüüÁöÑËÉ∞ËáüËÖ´Áò§Ê™¢Ê∏¨„ÄÇÁÑ∂ËÄåÔºåÁõ£Áù£ÂºèÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®ôÁ±§ÈÜ´Â≠∏ÂΩ±ÂÉèÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ΩÜÂèñÂæóÊ≠§È°ûË®ªËß£Êó¢ÊúâÈôêÂèàÊòÇË≤¥„ÄÇÁõ∏ÂèçÂú∞ÔºåÂÉÖÈúÄË¶ÅÂΩ±ÂÉèÂ±§Á¥öË®ªËß£ÁöÑÂº±Áõ£Áù£Áï∞Â∏∏Ê™¢Ê∏¨ÊñπÊ≥ïÂºïËµ∑‰∫ÜËààË∂£„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïË´ñ‰∏ªË¶Å‰æùË≥¥ÊñºÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN) ÊàñËá™ÂãïÁ∑®Á¢ºÂô®Ê®°ÂûãÔºåÈÄôÂèØËÉΩÊúÉÂú®Ë®ìÁ∑¥‰∏≠ÈÄ†ÊàêË§áÈõúÊÄßÔºåËÄå‰∏îÈÄô‰∫õÊ®°ÂûãÂèØËÉΩÈõ£‰ª•Ê∫ñÁ¢∫Âú∞‰øùÁïôÁ≤æÁ¥∞ÁöÑÂΩ±ÂÉèÁ¥∞ÁØÄ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑËÉ∞ËáüËÖ´Áò§Ê™¢Ê∏¨ÊñπÊ≥ïÔºåÊé°Áî®ÂéªÂô™Êì¥Êï£ÊºîÁÆóÊ≥ïÈÄ≤Ë°åÂº±Áõ£Áù£Áï∞Â∏∏Ê™¢Ê∏¨„ÄÇÈÄöÈÅéÁµêÂêàÊ∑ªÂä†ÂíåÁßªÈô§ÈõúË®äÁöÑÁ¢∫ÂÆöÊÄßËø≠‰ª£ÈÅéÁ®ã‰ª•ÂèäÂàÜÈ°ûÂô®ÊåáÂ∞éÔºåË©≤ÊñπÊ≥ïËÉΩÂ§†Âú®ÊÇ£ÁóÖÂíåÂÅ•Â∫∑ÂèóË©¶ËÄÖ‰πãÈñìÁÑ°Á∏´Âú∞ËΩâÊèõÂΩ±ÂÉèÔºåÂæûËÄåÁî¢ÁîüË©≥Á¥∞ÁöÑÁï∞Â∏∏ÂúñÔºåËÄå‰∏çÈúÄË¶ÅË§áÈõúÁöÑË®ìÁ∑¥ÂçîÂÆöÂíåÂàÜÂâ≤ÈÅÆÁΩ©„ÄÇÊú¨Á†îÁ©∂Â∞áÂéªÂô™Êì¥Êï£Ê®°ÂûãÊé¢Á¥¢ÁÇ∫ÂÇ≥Áµ±ÁîüÊàêÊ®°ÂûãÔºàÂ¶Ç GANÔºâÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÁÇ∫ËÉ∞ËáüËÖ´Áò§Ê™¢Ê∏¨È†òÂüüÂÅöÂá∫Ë≤¢Áçª„ÄÇÈëëÊñºËÉ∞ËáüÁôåÁöÑÂ≠òÊ¥ªÁéá‰ΩéÔºåÊú¨Á†îÁ©∂Âº∑Ë™øÈúÄË¶ÅÊåÅÁ∫åÁ†îÁ©∂‰ª•Âà©Áî®Êì¥Êï£Ê®°ÂûãÂú®ÈÜ´Â≠∏ÂàÜÂâ≤‰ªªÂãô‰∏≠ÁöÑÊïàÁéá„ÄÇ

##### **Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems**
2406.02462v1 by Jason Hu, Bowen Song, Xiaojian Xu, Liyue Shen, Jeffrey A. Fessler

Diffusion models can learn strong image priors from underlying data
distribution and use them to solve inverse problems, but the training process
is computationally expensive and requires lots of data. Such bottlenecks
prevent most existing works from being feasible for high-dimensional and
high-resolution data such as 3D images. This paper proposes a method to learn
an efficient data prior for the entire image by training diffusion models only
on patches of images. Specifically, we propose a patch-based position-aware
diffusion inverse solver, called PaDIS, where we obtain the score function of
the whole image through scores of patches and their positional encoding and
utilize this as the prior for solving inverse problems. First of all, we show
that this diffusion model achieves an improved memory efficiency and data
efficiency while still maintaining the capability to generate entire images via
positional encoding. Additionally, the proposed PaDIS model is highly flexible
and can be plugged in with different diffusion inverse solvers (DIS). We
demonstrate that the proposed PaDIS approach enables solving various inverse
problems in both natural and medical image domains, including CT
reconstruction, deblurring, and superresolution, given only patch-based priors.
Notably, PaDIS outperforms previous DIS methods trained on entire image priors
in the case of limited training data, demonstrating the data efficiency of our
proposed approach by learning patch-based prior.

ÊëòË¶ÅÔºöÊâ©Êï£Ê®°ÂûãÂèØ‰ª•‰ªéÂ∫ïÂ±ÇÊï∞ÊçÆÂàÜÂ∏É‰∏≠Â≠¶‰π†Âº∫ÂõæÂÉèÂÖàÈ™åÔºåÂπ∂Âà©Áî®ÂÆÉ‰ª¨Êù•Ëß£ÂÜ≥ÈÄÜÈóÆÈ¢òÔºå‰ΩÜËÆ≠ÁªÉËøáÁ®ãÂú®ËÆ°ÁÆó‰∏äÂæàÊòÇË¥µÔºåÈúÄË¶ÅÂ§ßÈáèÊï∞ÊçÆ„ÄÇÊ≠§Á±ªÁì∂È¢àÈòªÁ¢ç‰∫ÜÂ§ßÂ§öÊï∞Áé∞ÊúâÂ∑•‰ΩúÂØπÈ´òÁª¥ÂíåÈ´òÂàÜËæ®ÁéáÊï∞ÊçÆÔºà‰æãÂ¶Ç 3D ÂõæÂÉèÔºâÁöÑÂèØË°åÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñπÊ≥ïÔºå‰ªÖÈÄöËøáËÆ≠ÁªÉÂõæÂÉèÁöÑÂùóÊù•Â≠¶‰π†Êï¥‰∏™ÂõæÂÉèÁöÑÊúâÊïàÊï∞ÊçÆÂÖàÈ™åÔºå‰ª•Êâ©Êï£Ê®°Âûã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÂùóÁöÑ‰ΩçÁΩÆÊÑüÁü•Êâ©Êï£ÈÄÜÊ±ÇËß£Âô®ÔºåÁß∞‰∏∫ PaDISÔºåÂÖ∂‰∏≠Êàë‰ª¨ÈÄöËøáÂùóÂèäÂÖ∂‰ΩçÁΩÆÁºñÁ†ÅËé∑ÂæóÊï¥‰∏™ÂõæÂÉèÁöÑÂàÜÊï∞ÂáΩÊï∞ÔºåÂπ∂Â∞ÜÂÖ∂Áî®‰ΩúËß£ÂÜ≥ÈÄÜÈóÆÈ¢òÁöÑÂÖàÈ™å„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨Ë°®ÊòéËØ•Êâ©Êï£Ê®°ÂûãÂÆûÁé∞‰∫ÜÊîπËøõÁöÑÂÜÖÂ≠òÊïàÁéáÂíåÊï∞ÊçÆÊïàÁéáÔºåÂêåÊó∂‰ªç‰øùÊåÅÈÄöËøá‰ΩçÁΩÆÁºñÁ†ÅÁîüÊàêÊï¥‰∏™ÂõæÂÉèÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫ÁöÑ PaDIS Ê®°ÂûãÈùûÂ∏∏ÁÅµÊ¥ªÔºåÂèØ‰ª•ÊèíÂÖ•‰∏çÂêåÁöÑÊâ©Êï£ÈÄÜÊ±ÇËß£Âô® (DIS)„ÄÇÊàë‰ª¨ËØÅÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑ PaDIS ÊñπÊ≥ïËÉΩÂ§üËß£ÂÜ≥Ëá™ÁÑ∂ÂíåÂåªÂ≠¶ÂõæÂÉèÂüü‰∏≠ÁöÑÂêÑÁßçÈÄÜÈóÆÈ¢òÔºåÂåÖÊã¨ CT ÈáçÂª∫„ÄÅÂéªÊ®°Á≥äÂíåË∂ÖÂàÜËæ®ÁéáÔºå‰ªÖÁªôÂá∫Âü∫‰∫éÂùóÁöÑÂÖàÈ™å„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú®ËÆ≠ÁªÉÊï∞ÊçÆÊúâÈôêÁöÑÊÉÖÂÜµ‰∏ãÔºåPaDIS ‰ºò‰∫é‰ª•ÂâçÂú®Êï¥‰∏™ÂõæÂÉèÂÖàÈ™å‰∏äËÆ≠ÁªÉÁöÑ DIS ÊñπÊ≥ïÔºåËØÅÊòé‰∫ÜÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ïÈÄöËøáÂ≠¶‰π†Âü∫‰∫éÂùóÁöÑÂÖàÈ™åÁöÑÊï∞ÊçÆÊïàÁéá„ÄÇ

##### **Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data**
2406.02394v1 by Maxime Griot, Jean Vanderdonckt, Demet Yuksel, Coralie Hemptinne

Large Language Models (LLMs) like ChatGPT demonstrate significant potential
in the medical field, often evaluated using multiple-choice questions (MCQs)
similar to those found on the USMLE. Despite their prevalence in medical
education, MCQs have limitations that might be exacerbated when assessing LLMs.
To evaluate the effectiveness of MCQs in assessing the performance of LLMs, we
developed a fictional medical benchmark focused on a non-existent gland, the
Glianorex. This approach allowed us to isolate the knowledge of the LLM from
its test-taking abilities. We used GPT-4 to generate a comprehensive textbook
on the Glianorex in both English and French and developed corresponding
multiple-choice questions in both languages. We evaluated various open-source,
proprietary, and domain-specific LLMs using these questions in a zero-shot
setting. The models achieved average scores around 67%, with minor performance
differences between larger and smaller models. Performance was slightly higher
in English than in French. Fine-tuned medical models showed some improvement
over their base versions in English but not in French. The uniformly high
performance across models suggests that traditional MCQ-based benchmarks may
not accurately measure LLMs' clinical knowledge and reasoning abilities,
instead highlighting their pattern recognition skills. This study underscores
the need for more robust evaluation methods to better assess the true
capabilities of LLMs in medical contexts.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºå‰æãÂ¶Ç ChatGPTÔºåÂú®ÈÜ´ÁôÇÈ†òÂüüÂ±ïÁèæÂá∫È°ØËëóÁöÑÊΩõÂäõÔºåÈÄöÂ∏∏‰ΩøÁî®ËàáÁæéÂúãÂü∑Ê•≠ÈÜ´Â∏´Ë≥áÊ†ºËÄÉË©¶ (USMLE) ‰∏≠È°û‰ººÁöÑÂ§öÈÅ∏È°å (MCQ) ÈÄ≤Ë°åË©ï‰º∞„ÄÇÂÑòÁÆ° MCQ Âú®ÈÜ´Â≠∏ÊïôËÇ≤‰∏≠ÂæàÊôÆÈÅçÔºå‰ΩÜÂú®Ë©ï‰º∞ LLM ÊôÇÔºåÂÖ∂ÈôêÂà∂ÂèØËÉΩÊúÉË¢´ÊîæÂ§ß„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ MCQ Âú®Ë©ï‰º∞ LLM ÊïàËÉΩÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãËôõÊßãÁöÑÈÜ´ÁôÇÂü∫Ê∫ñÔºåÈáçÈªûÈóúÊ≥®‰∏ÄÂÄã‰∏çÂ≠òÂú®ÁöÑËÖ∫È´îÔºöGlianorex„ÄÇÈÄôÁ®ÆÊñπÊ≥ïËÆìÊàëÂÄëËÉΩÂ§†Â∞á LLM ÁöÑÁü•Ë≠òËàáÂÖ∂ÊáâË©¶ËÉΩÂäõÈöîÈõ¢Èñã‰æÜ„ÄÇÊàëÂÄë‰ΩøÁî® GPT-4 ‰ª•Ëã±ÊñáÂíåÊ≥ïÊñáÁîüÊàê‰∫ÜÈóúÊñº Glianorex ÁöÑ‰∏ÄÊú¨Á∂úÂêàÊïôÁßëÊõ∏Ôºå‰∏¶ÈñãÁôº‰∫ÜÁõ∏ÊáâÁöÑÂ§öÈÅ∏È°å„ÄÇÊàëÂÄëÂú®Èõ∂Ê¨°Â≠∏ÁøíË®≠ÂÆö‰∏≠‰ΩøÁî®ÈÄô‰∫õÂïèÈ°åË©ï‰º∞‰∫ÜÂêÑÁ®ÆÈñãÊ∫ê„ÄÅÂ∞àÊúâÂíåÁâπÂÆöÈ†òÂüüÁöÑ LLM„ÄÇÈÄô‰∫õÊ®°ÂûãÈÅîÂà∞‰∫ÜÂπ≥ÂùáÁ¥Ñ 67% ÁöÑÂàÜÊï∏ÔºåËºÉÂ§ßÂíåËºÉÂ∞èÊ®°Âûã‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆÁï∞ÂæàÂ∞è„ÄÇËã±ÊñáÁöÑÊïàËÉΩÁï•È´òÊñºÊ≥ïÊñá„ÄÇÂæÆË™øÂæåÁöÑÈÜ´ÁôÇÊ®°ÂûãÂú®Ëã±ÊñáÊñπÈù¢Ë°®ÁèæÂá∫ÊØîÂÖ∂Âü∫Á§éÁâàÊú¨Áï•ÊúâÈÄ≤Ê≠•Ôºå‰ΩÜÂú®Ê≥ïÊñáÊñπÈù¢ÂâáÊ≤íÊúâ„ÄÇÊâÄÊúâÊ®°ÂûãÁöÑÊïàËÉΩÂùá‰∏ÄËá¥Âú∞È´òÔºåÈÄôË°®ÊòéÂÇ≥Áµ±Âü∫Êñº MCQ ÁöÑÂü∫Ê∫ñÂèØËÉΩÁÑ°Ê≥ïÊ∫ñÁ¢∫Ë°°Èáè LLM ÁöÑËá®Â∫äÁü•Ë≠òÂíåÊé®ÁêÜËÉΩÂäõÔºåËÄåÂÉÖÁ™ÅÈ°Ø‰∫ÜÂÆÉÂÄëÁöÑÊ®°ÂºèË≠òÂà•ÊäÄËÉΩ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÈúÄË¶ÅÊõ¥Âº∑Â§ßÁöÑË©ï‰º∞ÊñπÊ≥ïÔºå‰ª•Êõ¥Â•ΩÂú∞Ë©ï‰º∞ LLM Âú®ÈÜ´ÁôÇÁí∞Â¢É‰∏≠ÁöÑÁúüÂØ¶ËÉΩÂäõ„ÄÇ

##### **LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing**
2406.02350v2 by Maojun Sun

Large language models (LLMs) have shown amazing capabilities in knowledge
memorization and the present. However, when it comes to domain-specific
knowledge and downstream tasks like medical, general LLMs are often unable to
give precise answers. In addition, when people want LLMs to answer
classification questions, they usually go through instruction tuning first.
However, LLMs do not always give a direct index of the categorization after
instruction tuning. In this paper, we proposed LlamaCare, a fine-tuned medical
language model, and Extended Classification Integration(ECI), a module to
handle classification problems of LLMs. Our contributions are : (i) We
fine-tuned a large language model of medical knowledge with very low carbon
emissions and achieved similar performance with ChatGPT by a 24G GPU. (ii) We
solved the problem of redundant categorical answers and improved the
performance of LLMs by proposing a new module called Extended Classification
Integration. (iii) We released our processed data for one-shot and few-shot
training for some benchmarks such as PubMedQA and USMLE 1-3 step. Our method
achieves a close performance comparable to some state-of-the-art models with
the same quantity of parameters on benchmarks, while being more environmentally
friendly by using less GPU computation time. Our models, codes, and datasets
can be found at \url{https://github.com/Stephen-SMJ/LLamaCare}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Áü•Ë≠òË®òÊÜ∂ÂíåÁèæÂú®Â±ïÁèæÂá∫È©ö‰∫∫ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁï∂Ê∂âÂèäÂà∞ÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÂíå‰∏ãÊ∏∏‰ªªÂãôÔºàÂ¶ÇÈÜ´ÁôÇÔºâÔºå‰∏ÄËà¨ÁöÑ LLM ÈÄöÂ∏∏ÁÑ°Ê≥ïÁµ¶Âá∫Á≤æÁ¢∫ÁöÑÁ≠îÊ°à„ÄÇÊ≠§Â§ñÔºåÁï∂‰∫∫ÂÄëÂ∏åÊúõ LLM ÂõûÁ≠îÂàÜÈ°ûÂïèÈ°åÊôÇÔºå‰ªñÂÄëÈÄöÂ∏∏ÊúÉÂÖàÈÄ≤Ë°åÊåá‰ª§Ë™øÊï¥„ÄÇÁÑ∂ËÄåÔºåLLM Âú®Êåá‰ª§Ë™øÊï¥Âæå‰∏¶ÈùûÁ∏ΩÊòØÁµ¶Âá∫ÂàÜÈ°ûÁöÑÁõ¥Êé•ÊåáÊ®ô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LlamaCareÔºå‰∏ÄÁ®ÆÁ∂ìÈÅéÂæÆË™øÁöÑÈÜ´Â≠∏Ë™ûË®ÄÊ®°ÂûãÔºå‰ª•ÂèäÊì¥Â±ïÂàÜÈ°ûÊï¥Âêà (ECI)Ôºå‰∏ÄÂÄãÁî®ÊñºËôïÁêÜ LLM ÂàÜÈ°ûÂïèÈ°åÁöÑÊ®°ÁµÑ„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÊòØÔºö(i) ÊàëÂÄëÂæÆË™ø‰∫Ü‰∏ÄÂÄãÈÜ´ÁôÇÁü•Ë≠òÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºåÁ¢≥ÊéíÊîæÈùûÂ∏∏‰ΩéÔºå‰∏¶ÈÄöÈÅé 24G GPU ÈÅîÂà∞‰∫ÜËàá ChatGPT Áõ∏‰ººÁöÑÊïàËÉΩ„ÄÇ(ii) ÊàëÂÄëËß£Ê±∫‰∫ÜÂÜóÈ§òÈ°ûÂà•Á≠îÊ°àÁöÑÂïèÈ°åÔºå‰∏¶ÈÄöÈÅéÊèêÂá∫‰∏ÄÂÄãÁ®±ÁÇ∫Êì¥Â±ïÂàÜÈ°ûÊï¥ÂêàÁöÑÊñ∞Ê®°ÁµÑ‰æÜÊèêÂçá LLM ÁöÑÊïàËÉΩ„ÄÇ(iii) ÊàëÂÄëÈáãÂá∫‰∫ÜÊàëÂÄëËôïÁêÜÈÅéÁöÑË≥áÊñôÔºåÁî®Êñº PubMedQA Âíå USMLE 1-3 Ê≠•È©üÁ≠â‰∏Ä‰∫õÂü∫Ê∫ñÁöÑÂñÆÊ¨°ÂíåÂ∞ëÊ¨°Ë®ìÁ∑¥„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Âü∫Ê∫ñ‰∏äÈÅîÂà∞‰∫ÜËàá‰∏Ä‰∫õÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÁõ∏Áï∂ÁöÑÊïàËÉΩÔºåÂêåÊôÇÈÄèÈÅéÊ∏õÂ∞ë GPU Ë®àÁÆóÊôÇÈñìÔºåÂ∞çÁí∞Â¢ÉÊõ¥ÂèãÂñÑ„ÄÇÊàëÂÄëÁöÑÊ®°Âûã„ÄÅÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂèØ‰ª•Âú® \url{https://github.com/Stephen-SMJ/LLamaCare} ÊâæÂà∞„ÄÇ

##### **A Comparative Study of Sampling Methods with Cross-Validation in the FedHome Framework**
2406.01950v1 by Arash Ahmadi, Sarah S. Sharif, Yaser M. Banad

This paper presents a comparative study of sampling methods within the
FedHome framework, designed for personalized in-home health monitoring. FedHome
leverages federated learning (FL) and generative convolutional autoencoders
(GCAE) to train models on decentralized edge devices while prioritizing data
privacy. A notable challenge in this domain is the class imbalance in health
data, where critical events such as falls are underrepresented, adversely
affecting model performance. To address this, the research evaluates six
oversampling techniques using Stratified K-fold cross-validation: SMOTE,
Borderline-SMOTE, Random OverSampler, SMOTE-Tomek, SVM-SMOTE, and SMOTE-ENN.
These methods are tested on FedHome's public implementation over 200 training
rounds with and without stratified K-fold cross-validation. The findings
indicate that SMOTE-ENN achieves the most consistent test accuracy, with a
standard deviation range of 0.0167-0.0176, demonstrating stable performance
compared to other samplers. In contrast, SMOTE and SVM-SMOTE exhibit higher
variability in performance, as reflected by their wider standard deviation
ranges of 0.0157-0.0180 and 0.0155-0.0180, respectively. Similarly, the Random
OverSampler method shows a significant deviation range of 0.0155-0.0176.
SMOTE-Tomek, with a deviation range of 0.0160-0.0175, also shows greater
stability but not as much as SMOTE-ENN. This finding highlights the potential
of SMOTE-ENN to enhance the reliability and accuracy of personalized health
monitoring systems within the FedHome framework.

ÊëòË¶ÅÔºö<paragraph>Êú¨ÊñáÈáùÂ∞ç FedHome Êû∂ÊßãÂÖßÁöÑÊäΩÊ®£ÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉÁ†îÁ©∂ÔºåË©≤Êû∂ÊßãÊó®Âú®ÈÄ≤Ë°åÂÄã‰∫∫ÂåñÁöÑÂ±ÖÂÆ∂ÂÅ•Â∫∑Áõ£Êéß„ÄÇFedHome Êé°Áî®ËÅØÈÇ¶Â≠∏Áøí (FL) ÂíåÁîüÊàêÂºèÂç∑Á©çËá™ÂãïÁ∑®Á¢ºÂô® (GCAE) ‰æÜË®ìÁ∑¥ÂàÜÊï£ÂºèÈÇäÁ∑£Ë£ùÁΩÆ‰∏äÁöÑÊ®°ÂûãÔºåÂêåÊôÇÂÑ™ÂÖàËÄÉÊÖÆË≥áÊñôÈö±ÁßÅ„ÄÇÊ≠§È†òÂüüÁöÑ‰∏ÄÈ†ÖÈ°ØËëóÊåëÊà∞ÊòØÂÅ•Â∫∑Ë≥áÊñô‰∏≠ÁöÑÈ°ûÂà•‰∏çÂπ≥Ë°°ÔºåÂÖ∂‰∏≠Ë∑åÂÄíÁ≠âÈóúÈçµ‰∫ã‰ª∂ÁöÑ‰ª£Ë°®ÊÄß‰∏çË∂≥ÔºåÂ∞çÊ®°ÂûãÊïàËÉΩÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊú¨Á†îÁ©∂‰ΩøÁî®ÂàÜÂ±§ K ÂÄç‰∫§ÂèâÈ©óË≠âË©ï‰º∞ÂÖ≠Á®ÆÈÅéÊé°Ê®£ÊäÄË°ìÔºöSMOTE„ÄÅBorderline-SMOTE„ÄÅÈö®Ê©üÈÅéÊé°Ê®£Âô®„ÄÅSMOTE-Tomek„ÄÅSVM-SMOTE Âíå SMOTE-ENN„ÄÇÈÄô‰∫õÊñπÊ≥ïÂú® FedHome ÁöÑÂÖ¨ÈñãÂØ¶‰Ωú‰∏≠Á∂ìÈÅé 200 Ëº™Ë®ìÁ∑¥Ôºå‰ΩøÁî®Âíå‰∏ç‰ΩøÁî®ÂàÜÂ±§ K ÂÄç‰∫§ÂèâÈ©óË≠âÈÄ≤Ë°åÊ∏¨Ë©¶„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåSMOTE-ENN ÈÅîÂà∞ÊúÄÁ©©ÂÆöÁöÑÊ∏¨Ë©¶Ê∫ñÁ¢∫Â∫¶ÔºåÊ®ôÊ∫ñÂ∑ÆÁØÑÂúçÁÇ∫ 0.0167-0.0176ÔºåËàáÂÖ∂‰ªñÊé°Ê®£Âô®Áõ∏ÊØîÔºåË°®ÁèæÂá∫Á©©ÂÆöÁöÑÊïàËÉΩ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåSMOTE Âíå SVM-SMOTE ÁöÑÊïàËÉΩËÆäÁï∞ÊÄßËºÉÈ´òÔºåÊ®ôÊ∫ñÂ∑ÆÁØÑÂúçÂàÜÂà•ÁÇ∫ 0.0157-0.0180 Âíå 0.0155-0.0180„ÄÇÂêåÊ®£Âú∞ÔºåÈö®Ê©üÈÅéÊé°Ê®£Âô®ÊñπÊ≥ïÈ°ØÁ§∫Âá∫È°ØËëóÁöÑÂÅèÂ∑ÆÁØÑÂúç 0.0155-0.0176„ÄÇÂÅèÂ∑ÆÁØÑÂúçÁÇ∫ 0.0160-0.0175 ÁöÑ SMOTE-Tomek ‰πüÈ°ØÁ§∫Âá∫ËºÉÈ´òÁöÑÁ©©ÂÆöÊÄßÔºå‰ΩÜ‰∏çÂ¶Ç SMOTE-ENN„ÄÇÊ≠§ÁôºÁèæÁ™ÅÈ°Ø‰∫Ü SMOTE-ENN Âú® FedHome Êû∂Êßã‰∏≠Â¢ûÂº∑ÂÄã‰∫∫ÂåñÂÅ•Â∫∑Áõ£ÊéßÁ≥ªÁµ±ÁöÑÂèØÈù†ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Enhancing Clinical Documentation with Synthetic Data: Leveraging Generative Models for Improved Accuracy**
2406.06569v1 by Anjanava Biswas, Wrick Talukdar

Accurate and comprehensive clinical documentation is crucial for delivering
high-quality healthcare, facilitating effective communication among providers,
and ensuring compliance with regulatory requirements. However, manual
transcription and data entry processes can be time-consuming, error-prone, and
susceptible to inconsistencies, leading to incomplete or inaccurate medical
records. This paper proposes a novel approach to augment clinical documentation
by leveraging synthetic data generation techniques to generate realistic and
diverse clinical transcripts. We present a methodology that combines
state-of-the-art generative models, such as Generative Adversarial Networks
(GANs) and Variational Autoencoders (VAEs), with real-world clinical transcript
and other forms of clinical data to generate synthetic transcripts. These
synthetic transcripts can then be used to supplement existing documentation
workflows, providing additional training data for natural language processing
models and enabling more accurate and efficient transcription processes.
Through extensive experiments on a large dataset of anonymized clinical
transcripts, we demonstrate the effectiveness of our approach in generating
high-quality synthetic transcripts that closely resemble real-world data.
Quantitative evaluation metrics, including perplexity scores and BLEU scores,
as well as qualitative assessments by domain experts, validate the fidelity and
utility of the generated synthetic transcripts. Our findings highlight
synthetic data generation's potential to address clinical documentation
challenges, improving patient care, reducing administrative burdens, and
enhancing healthcare system efficiency.

ÊëòË¶ÅÔºöÁ≤æÁ¢∫‰∏îÂÖ®Èù¢ÁöÑËá®Â∫äÊñá‰ª∂Â∞çÊñºÊèê‰æõÈ´òÂìÅË≥™ÁöÑÈÜ´ÁôÇ‰øùÂÅ•„ÄÅ‰øÉÈÄ≤Êèê‰æõËÄÖ‰πãÈñìÁöÑÊúâÊïàÊ∫ùÈÄöÔºå‰ª•ÂèäÁ¢∫‰øùÁ¨¶ÂêàÊ≥ïË¶èË¶ÅÊ±ÇËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÊâãÂãïËΩâÈåÑÂíåË≥áÊñôËº∏ÂÖ•Á®ãÂ∫èÂèØËÉΩËÄóÊôÇ„ÄÅÂÆπÊòìÂá∫ÈåØÔºå‰∏îÂÆπÊòìÁî¢Áîü‰∏ç‰∏ÄËá¥ÔºåÂ∞éËá¥ÁóÖÊ≠∑‰∏çÂÆåÊï¥Êàñ‰∏çÊ∫ñÁ¢∫„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ï‰æÜÊì¥ÂÖÖËá®Â∫äÊñá‰ª∂ÔºåÊñπÊ≥ïÊòØÂà©Áî®ÂêàÊàêË≥áÊñôÁîüÊàêÊäÄË°ì‰æÜÁî¢ÁîüÈÄºÁúü‰∏îÂ§öÊ®£ÁöÑËá®Â∫äËΩâÈåÑ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁµêÂêà‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁîüÊàêÊ®°ÂûãÔºà‰æãÂ¶ÇÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN) ÂíåËÆäÂàÜËá™ÂãïÁ∑®Á¢ºÂô® (VAE)ÔºâÁöÑÊñπÊ≥ïÔºå‰∏¶ÁµêÂêà‰∫ÜÁúüÂØ¶‰∏ñÁïåÁöÑËá®Â∫äËΩâÈåÑÂíåÂÖ∂‰ªñÂΩ¢ÂºèÁöÑËá®Â∫äË≥áÊñô‰æÜÁî¢ÁîüÂêàÊàêËΩâÈåÑ„ÄÇÈÄô‰∫õÂêàÊàêËΩâÈåÑÁÑ∂ÂæåÂèØ‰ª•Áî®ÊñºË£úÂÖÖÁèæÊúâÁöÑÊñá‰ª∂Â∑•‰ΩúÊµÅÁ®ãÔºåÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊ®°ÂûãÊèê‰æõÈ°çÂ§ñÁöÑË®ìÁ∑¥Ë≥áÊñôÔºå‰∏¶ÂØ¶ÁèæÊõ¥Ê∫ñÁ¢∫„ÄÅÊõ¥ÊúâÊïàÁöÑËΩâÈåÑÊµÅÁ®ã„ÄÇÈÄèÈÅéÂ∞çÂ§ßÈáèÁöÑÂåøÂêçÂåñËá®Â∫äËΩâÈåÑÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Áî¢ÁîüËàáÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈùûÂ∏∏Áõ∏‰ººÁöÑÂÑ™Ë≥™ÂêàÊàêËΩâÈåÑÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÂÆöÈáèË©ï‰º∞ÊåáÊ®ôÔºåÂåÖÊã¨Âõ∞ÊÉëÂ∫¶ÂàÜÊï∏Âíå BLEU ÂàÜÊï∏Ôºå‰ª•ÂèäÈ†òÂüüÂ∞àÂÆ∂ÁöÑÂÆöÊÄßË©ï‰º∞ÔºåÈ©óË≠â‰∫ÜÁîüÊàêÁöÑÂêàÊàêËΩâÈåÑÁöÑ‰øùÁúüÂ∫¶ÂíåÊïàÁî®„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÂêàÊàêË≥áÊñôÁîüÊàêÂú®Ëß£Ê±∫Ëá®Â∫äÊñá‰ª∂ÊåëÊà∞„ÄÅÊîπÂñÑÊÇ£ËÄÖÁÖßË≠∑„ÄÅÊ∏õËºïË°åÊîøË≤†ÊìîÂíåÊèêÈ´òÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÊïàÁéáÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization**
2406.01314v1 by Firas Khader, Omar S. M. El Nahhas, Tianyu Han, Gustav M√ºller-Franzes, Sven Nebelung, Jakob Nikolas Kather, Daniel Truhn

The Transformer model has been pivotal in advancing fields such as natural
language processing, speech recognition, and computer vision. However, a
critical limitation of this model is its quadratic computational and memory
complexity relative to the sequence length, which constrains its application to
longer sequences. This is especially crucial in medical imaging where
high-resolution images can reach gigapixel scale. Efforts to address this issue
have predominantely focused on complex techniques, such as decomposing the
softmax operation integral to the Transformer's architecture. This paper
addresses this quadratic computational complexity of Transformer models and
introduces a remarkably simple and effective method that circumvents this issue
by eliminating the softmax function from the attention mechanism and adopting a
sequence normalization technique for the key, query, and value tokens. Coupled
with a reordering of matrix multiplications this approach reduces the memory-
and compute complexity to a linear scale. We evaluate this approach across
various medical imaging datasets comprising fundoscopic, dermascopic,
radiologic and histologic imaging data. Our findings highlight that these
models exhibit a comparable performance to traditional transformer models,
while efficiently handling longer sequences.

ÊëòË¶ÅÔºöTransformer Ê®°ÂûãÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÅË™ûÈü≥Ëæ®Ë≠òÂíåÈõªËÖ¶Ë¶ñË¶∫Á≠âÈ†òÂüüÁöÑÈÄ≤Â±ï‰∏≠ÁôºÊèÆ‰∫ÜÈóúÈçµ‰ΩúÁî®„ÄÇÁÑ∂ËÄåÔºåÊ≠§Ê®°ÂûãÁöÑ‰∏ÄÂÄãÈáçÂ§ßÈôêÂà∂ÊòØÂÖ∂‰∫åÊ¨°Ë®àÁÆóÂíåË®òÊÜ∂È´îË§áÈõúÂ∫¶Áõ∏Â∞çÊñºÂ∫èÂàóÈï∑Â∫¶ÔºåÈÄôÈôêÂà∂‰∫ÜÂÖ∂Âú®ËºÉÈï∑Â∫èÂàó‰∏≠ÁöÑÊáâÁî®„ÄÇÈÄôÂú®ÈÜ´ÁôÇÂΩ±ÂÉè‰∏≠Â∞§ÂÖ∂ÈáçË¶ÅÔºåÂÖ∂‰∏≠È´òËß£ÊûêÂ∫¶ÂΩ±ÂÉèÂèØ‰ª•ÈÅîÂà∞ÂêâÂÉèÁ¥†Á≠âÁ¥ö„ÄÇËß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÂä™Âäõ‰∏ªË¶ÅÈõÜ‰∏≠Âú®Ë§áÈõúÊäÄË°ì‰∏äÔºå‰æãÂ¶ÇÂàÜËß£ Transformer Êû∂Êßã‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑ softmax ÈÅãÁÆó„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫Ü Transformer Ê®°ÂûãÁöÑ‰∫åÊ¨°Ë®àÁÆóË§áÈõúÂ∫¶Ôºå‰∏¶‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÈùûÂ∏∏Á∞°ÂñÆ‰∏îÊúâÊïàÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÂæûÊ≥®ÊÑèÂäõÊ©üÂà∂‰∏≠ÁßªÈô§ softmax ÂáΩÊï∏‰∏¶Êé°Áî®ÈóúÈçµ„ÄÅÊü•Ë©¢ÂíåÂÄºÁ¨¶ËôüÁöÑÂ∫èÂàóÊ≠£Ë¶èÂåñÊäÄË°ì‰æÜËß£Ê±∫Ê≠§ÂïèÈ°å„ÄÇÁµêÂêàÁü©Èô£‰πòÊ≥ïÁöÑÈáçÊñ∞ÊéíÂ∫èÔºåÊ≠§ÊñπÊ≥ïÂ∞áË®òÊÜ∂È´îÂíåÈÅãÁÆóË§áÈõúÂ∫¶Èôç‰ΩéÂà∞Á∑öÊÄßÁ≠âÁ¥ö„ÄÇÊàëÂÄëÂú®ÂåÖÂê´ÁúºÂ∫ïÈè°„ÄÅÁöÆËÜöÈè°„ÄÅÊîæÂ∞ÑÂ≠∏ÂíåÁµÑÁπîÂ≠∏ÂΩ±ÂÉèË≥áÊñôÁöÑÂêÑÁ®ÆÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äË©ï‰º∞Ê≠§ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂº∑Ë™øÔºåÈÄô‰∫õÊ®°ÂûãË°®ÁèæÂá∫ËàáÂÇ≥Áµ± Transformer Ê®°ÂûãÁõ∏Áï∂ÁöÑÊïàËÉΩÔºåÂêåÊôÇÊúâÊïàÂú∞ËôïÁêÜËºÉÈï∑ÁöÑÂ∫èÂàó„ÄÇ

##### **TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models in Traditional Chinese Medicine**
2406.01126v1 by Wenjing Yue, Xiaoling Wang, Wei Zhu, Ming Guan, Huanran Zheng, Pengfei Wang, Changzhi Sun, Xin Ma

Large language models (LLMs) have performed remarkably well in various
natural language processing tasks by benchmarking, including in the Western
medical domain. However, the professional evaluation benchmarks for LLMs have
yet to be covered in the traditional Chinese medicine(TCM) domain, which has a
profound history and vast influence. To address this research gap, we introduce
TCM-Bench, an comprehensive benchmark for evaluating LLM performance in TCM. It
comprises the TCM-ED dataset, consisting of 5,473 questions sourced from the
TCM Licensing Exam (TCMLE), including 1,300 questions with authoritative
analysis. It covers the core components of TCMLE, including TCM basis and
clinical practice. To evaluate LLMs beyond accuracy of question answering, we
propose TCMScore, a metric tailored for evaluating the quality of answers
generated by LLMs for TCM related questions. It comprehensively considers the
consistency of TCM semantics and knowledge. After conducting comprehensive
experimental analyses from diverse perspectives, we can obtain the following
findings: (1) The unsatisfactory performance of LLMs on this benchmark
underscores their significant room for improvement in TCM. (2) Introducing
domain knowledge can enhance LLMs' performance. However, for in-domain models
like ZhongJing-TCM, the quality of generated analysis text has decreased, and
we hypothesize that their fine-tuning process affects the basic LLM
capabilities. (3) Traditional metrics for text generation quality like Rouge
and BertScore are susceptible to text length and surface semantic ambiguity,
while domain-specific metrics such as TCMScore can further supplement and
explain their evaluation results. These findings highlight the capabilities and
limitations of LLMs in the TCM and aim to provide a more profound assistance to
medical research.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤ÔºåÂåÖÊã¨Âú®Ë•øÊñπÈÜ´Â≠∏È†òÂüü„ÄÇÁÑ∂ËÄåÔºåLLM ÁöÑÂ∞àÊ•≠Ë©ï‰º∞Âü∫Ê∫ñÂ∞öÊú™Ê∂µËìã‰∏≠ÈÜ´È†òÂüüÔºåËÄå‰∏≠ÈÜ´È†òÂüüÊìÅÊúâÊ∑±ÂéöÁöÑÊ≠∑Âè≤ÂíåÂª£Ê≥õÁöÑÂΩ±ÈüøÂäõ„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄô‰∏ÄÁ†îÁ©∂Á©∫ÁôΩÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü TCM-BenchÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºË©ï‰º∞ LLM Âú®‰∏≠ÈÜ´È†òÂüüË°®ÁèæÁöÑÁ∂úÂêàÂü∫Ê∫ñ„ÄÇÂÆÉÂåÖÂê´ TCM-ED Êï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 5,473 ÂÄã‰æÜËá™‰∏≠ÈÜ´Âü∑ÁÖßËÄÉË©¶ (TCMLE) ÁöÑÂïèÈ°åÔºåÂåÖÊã¨ 1,300 ÂÄãÂÖ∑ÊúâÊ¨äÂ®ÅÂàÜÊûêÁöÑÂïèÈ°å„ÄÇÂÆÉÊ∂µËìã‰∫Ü TCMLE ÁöÑÊ†∏ÂøÉÁµÑÊàêÈÉ®ÂàÜÔºåÂåÖÊã¨‰∏≠ÈÜ´Âü∫Á§éÂíåËá®Â∫äÂØ¶Ë∏ê„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ LLM Ë∂ÖË∂äÂïèÈ°åÂõûÁ≠îÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫Ü TCMScoreÔºåÈÄôÊòØ‰∏ÄÂÄãÂ∞àÈñÄÁî®ÊñºË©ï‰º∞ LLM ÁÇ∫‰∏≠ÈÜ´Áõ∏ÈóúÂïèÈ°åÁîüÊàêÁöÑÁ≠îÊ°àË≥™ÈáèÁöÑÊåáÊ®ô„ÄÇÂÆÉÂÖ®Èù¢ËÄÉÊÖÆ‰∫Ü‰∏≠ÈÜ´Ë™ûÁæ©ÂíåÁü•Ë≠òÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂú®Âæû‰∏çÂêåËßíÂ∫¶ÈÄ≤Ë°åÁ∂úÂêàÂØ¶È©óÂàÜÊûêÂæåÔºåÊàëÂÄëÂèØ‰ª•ÂæóÂá∫‰ª•‰∏ãÁôºÁèæÔºö(1) LLM Âú®Ê≠§Âü∫Ê∫ñ‰∏äÁöÑË°®Áèæ‰∏çÁõ°‰∫∫ÊÑèÔºåÈÄôÂá∏È°Ø‰∫ÜÂÆÉÂÄëÂú®‰∏≠ÈÜ´È†òÂüüÊúâÂæàÂ§ßÁöÑÊîπÈÄ≤Á©∫Èñì„ÄÇ(2) ÂºïÂÖ•È†òÂüüÁü•Ë≠òÂèØ‰ª•ÊèêÂçá LLM ÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÂÉè ZhongJing-TCM ÈÄôÊ®£ÁöÑÈ†òÂüüÊ®°ÂûãÔºåÁîüÊàêÁöÑÂàÜÊûêÊñáÊú¨ÁöÑË≥™ÈáèÊúâÊâÄ‰∏ãÈôçÔºåÊàëÂÄëÂÅáË®≠ÂÆÉÂÄëÁöÑÂæÆË™øÈÅéÁ®ãÂΩ±Èüø‰∫ÜÂü∫Êú¨ÁöÑ LLM ËÉΩÂäõ„ÄÇ(3) ÂÇ≥Áµ±ÁöÑÊñáÊú¨ÁîüÊàêË≥™ÈáèÊåáÊ®ôÔºå‰æãÂ¶Ç Rouge Âíå BertScoreÔºåÂÆπÊòìÂèóÂà∞ÊñáÊú¨Èï∑Â∫¶ÂíåË°®Èù¢Ë™ûÁæ©Ê®°Á≥äÊÄßÁöÑÂΩ±ÈüøÔºåËÄåÂÉè TCMScore ÈÄôÊ®£ÁöÑÁâπÂÆöÈ†òÂüüÊåáÊ®ôÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•Ë£úÂÖÖÂíåËß£ÈáãÂÆÉÂÄëÁöÑË©ï‰º∞ÁµêÊûú„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÂá∫‰∫Ü LLM Âú®‰∏≠ÈÜ´È†òÂüüÁöÑËÉΩÂäõÂíåÂ±ÄÈôêÊÄßÔºå‰∏¶Êó®Âú®ÁÇ∫ÈÜ´Â≠∏Á†îÁ©∂Êèê‰æõÊõ¥Ê∑±ÂÖ•ÁöÑÂπ´Âä©„ÄÇ</paragraph>

##### **Effective Subset Selection Through The Lens of Neural Network Pruning**
2406.01086v1 by Noga Bar, Raja Giryes

Having large amounts of annotated data significantly impacts the
effectiveness of deep neural networks. However, the annotation task can be very
expensive in some domains, such as medical data. Thus, it is important to
select the data to be annotated wisely, which is known as the subset selection
problem. We investigate the relationship between subset selection and neural
network pruning, which is more widely studied, and establish a correspondence
between them. Leveraging insights from network pruning, we propose utilizing
the norm criterion of neural network features to improve subset selection
methods. We empirically validate our proposed strategy on various networks and
datasets, demonstrating enhanced accuracy. This shows the potential of
employing pruning tools for subset selection.

ÊëòË¶ÅÔºöÊìÅÊúâÂ§ßÈáèÁöÑË®ªÈáãË≥áÊñôÊúÉÈ°ØËëóÂΩ±ÈüøÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊïàÁõä„ÄÇÁÑ∂ËÄåÔºåÂú®Êüê‰∫õÈ†òÂüüÔºà‰æãÂ¶ÇÈÜ´Â≠∏Ë≥áÊñôÔºâÔºåË®ªÈáã‰ªªÂãôÂèØËÉΩÊúÉÈùûÂ∏∏ÊòÇË≤¥„ÄÇÂõ†Ê≠§ÔºåÊòéÊô∫Âú∞ÈÅ∏ÊìáË¶ÅË®ªÈáãÁöÑË≥áÊñôÈùûÂ∏∏ÈáçË¶ÅÔºåÈÄôÁ®±ÁÇ∫Â≠êÈõÜÈÅ∏ÊìáÂïèÈ°å„ÄÇÊàëÂÄëÊé¢Ë®éÂ≠êÈõÜÈÅ∏ÊìáËàáÁ•ûÁ∂ìÁ∂≤Ë∑ØÂâ™Êûù‰πãÈñìÁöÑÈóú‰øÇÔºåÂæåËÄÖÁ†îÁ©∂ÂæóÊõ¥Âª£Ê≥õÔºå‰∏¶Âú®ÂÆÉÂÄë‰πãÈñìÂª∫Á´ãÂ∞çÊáâÈóú‰øÇ„ÄÇÂà©Áî®Á∂≤Ë∑ØÂâ™ÊûùÁöÑË¶ãËß£ÔºåÊàëÂÄëÂª∫Ë≠∞Âà©Áî®Á•ûÁ∂ìÁ∂≤Ë∑ØÁâπÂæµÁöÑÁØÑÊï∏Ê∫ñÂâá‰æÜÊîπÂñÑÂ≠êÈõÜÈÅ∏ÊìáÊñπÊ≥ï„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆÁ∂≤Ë∑ØÂíåË≥áÊñôÈõÜ‰∏äÊ†πÊìöÁ∂ìÈ©óÈ©óË≠âÊàëÂÄëÊèêÂá∫ÁöÑÁ≠ñÁï•ÔºåË≠âÊòé‰∫ÜÂ¢ûÂº∑ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÈÄôÈ°ØÁ§∫‰∫Ü‰ΩøÁî®Ââ™ÊûùÂ∑•ÂÖ∑ÈÄ≤Ë°åÂ≠êÈõÜÈÅ∏ÊìáÁöÑÊΩõÂäõ„ÄÇ

##### **Causal prompting model-based offline reinforcement learning**
2406.01065v1 by Xuehui Yu, Yi Guan, Rujia Shen, Xin Li, Chen Tang, Jingchi Jiang

Model-based offline Reinforcement Learning (RL) allows agents to fully
utilise pre-collected datasets without requiring additional or unethical
explorations. However, applying model-based offline RL to online systems
presents challenges, primarily due to the highly suboptimal (noise-filled) and
diverse nature of datasets generated by online systems. To tackle these issues,
we introduce the Causal Prompting Reinforcement Learning (CPRL) framework,
designed for highly suboptimal and resource-constrained online scenarios. The
initial phase of CPRL involves the introduction of the Hidden-Parameter Block
Causal Prompting Dynamic (Hip-BCPD) to model environmental dynamics. This
approach utilises invariant causal prompts and aligns hidden parameters to
generalise to new and diverse online users. In the subsequent phase, a single
policy is trained to address multiple tasks through the amalgamation of
reusable skills, circumventing the need for training from scratch. Experiments
conducted across datasets with varying levels of noise, including
simulation-based and real-world offline datasets from the Dnurse APP,
demonstrate that our proposed method can make robust decisions in
out-of-distribution and noisy environments, outperforming contemporary
algorithms. Additionally, we separately verify the contributions of Hip-BCPDs
and the skill-reuse strategy to the robustness of performance. We further
analyse the visualised structure of Hip-BCPD and the interpretability of
sub-skills. We released our source code and the first ever real-world medical
dataset for precise medical decision-making tasks.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÊ®°ÂûãÁöÑÈõ¢Á∑öÂº∑ÂåñÂ≠∏Áøí (RL) ËÆì‰ª£ÁêÜ‰∫∫ËÉΩÂ§†ÂÖÖÂàÜÂà©Áî®È†êÂÖàÊî∂ÈõÜÁöÑË≥áÊñôÈõÜÔºåËÄå‰∏çÈúÄË¶ÅÈ°çÂ§ñÁöÑÊàñ‰∏çÈÅìÂæ∑ÁöÑÊé¢Á¥¢„ÄÇÁÑ∂ËÄåÔºåÂ∞áÂü∫ÊñºÊ®°ÂûãÁöÑÈõ¢Á∑ö RL ÊáâÁî®ÊñºÁ∑ö‰∏äÁ≥ªÁµ±ÊúÉÂ∏∂‰æÜÊåëÊà∞Ôºå‰∏ªË¶ÅÊòØÁî±ÊñºÁ∑ö‰∏äÁ≥ªÁµ±ÊâÄÁî¢ÁîüÁöÑË≥áÊñôÈõÜÂÖ∑ÊúâÈ´òÂ∫¶Ê¨°‰Ω≥ÔºàÂÖÖÊªøÈõúË®äÔºâÂíåÂ§öÊ®£ÂåñÁöÑÁâπÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂõ†ÊûúÊèêÁ§∫Âº∑ÂåñÂ≠∏Áøí (CPRL) Ê°ÜÊû∂ÔºåÂ∞àÁÇ∫È´òÂ∫¶Ê¨°‰Ω≥ÂíåË≥áÊ∫êÂèóÈôêÁöÑÁ∑ö‰∏äÂ†¥ÊôØËÄåË®≠Ë®à„ÄÇCPRL ÁöÑÂàùÂßãÈöéÊÆµÊ∂âÂèäÂºïÂÖ•Èö±ËóèÂèÉÊï∏ÂçÄÂ°äÂõ†ÊûúÊèêÁ§∫ÂãïÊÖã (Hip-BCPD) ‰æÜÂª∫Ê®°Áí∞Â¢ÉÂãïÊÖã„ÄÇÊ≠§ÊñπÊ≥ïÂà©Áî®‰∏çËÆäÁöÑÂõ†ÊûúÊèêÁ§∫‰∏¶Ë™øÊï¥Èö±ËóèÂèÉÊï∏‰ª•Ê¶ÇÊã¨Âà∞Êñ∞ÁöÑÂíåÂ§öÊ®£ÂåñÁöÑÁ∑ö‰∏ä‰ΩøÁî®ËÄÖ„ÄÇÂú®ÂæåÁ∫åÈöéÊÆµÔºåË®ìÁ∑¥ÂñÆ‰∏ÄÊîøÁ≠ñ‰ª•ÈÄèÈÅéÂêà‰ΩµÂèØÈáçË§á‰ΩøÁî®ÁöÑÊäÄËÉΩ‰æÜËôïÁêÜÂ§öÈ†Ö‰ªªÂãôÔºåË¶èÈÅøÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥ÁöÑÈúÄË¶Å„ÄÇÂú®ÂÖ∑Êúâ‰∏çÂêåÈõúË®äÂ±§Á¥öÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÔºåÂåÖÊã¨‰æÜËá™ Dnurse APP ÁöÑÂü∫ÊñºÊ®°Êì¨ÂíåÁúüÂØ¶‰∏ñÁïåÁöÑÈõ¢Á∑öË≥áÊñôÈõÜÔºåË≠âÊòéÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂèØ‰ª•Âú®Ë∂ÖÂá∫ÂàÜ‰ΩàÂíåÈõúË®äÁí∞Â¢É‰∏≠ÂÅöÂá∫Á©©ÂÅ•ÁöÑÊ±∫Á≠ñÔºåÂÑ™ÊñºÁï∂‰ª£ÊºîÁÆóÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂàÜÂà•È©óË≠â‰∫Ü Hip-BCPD ÂíåÊäÄËÉΩÈáçÁî®Á≠ñÁï•Â∞çÊïàËÉΩÁ©©ÂÅ•ÊÄßÁöÑË≤¢Áçª„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂàÜÊûê‰∫Ü Hip-BCPD ÁöÑÂèØË¶ñÂåñÁµêÊßãÂíåÂ≠êÊäÄËÉΩÁöÑÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÁôºÂ∏É‰∫ÜÊàëÂÄëÁöÑÂéüÂßãÁ¢ºÂíåÁ¨¨‰∏ÄÂÄãÁî®ÊñºÁ≤æÁ¢∫ÈÜ´ÁôÇÊ±∫Á≠ñ‰ªªÂãôÁöÑÁúüÂØ¶‰∏ñÁïåÈÜ´ÁôÇË≥áÊñôÈõÜ„ÄÇ</paragraph>

##### **Synthetic Data Generation for 3D Myocardium Deformation Analysis**
2406.01040v1 by Shahar Zuler, Dan Raviv

Accurate analysis of 3D myocardium deformation using high-resolution
computerized tomography (CT) datasets with ground truth (GT) annotations is
crucial for advancing cardiovascular imaging research. However, the scarcity of
such datasets poses a significant challenge for developing robust myocardium
deformation analysis models. To address this, we propose a novel approach to
synthetic data generation for enriching cardiovascular imaging datasets.
  We introduce a synthetic data generation method, enriched with crucial GT 3D
optical flow annotations. We outline the data preparation from a cardiac
four-dimensional (4D) CT scan, selection of parameters, and the subsequent
creation of synthetic data from the same or other sources of 3D cardiac CT data
for training.
  Our work contributes to overcoming the limitations imposed by the scarcity of
high-resolution CT datasets with precise annotations, thereby facilitating the
development of accurate and reliable myocardium deformation analysis algorithms
for clinical applications and diagnostics.
  Our code is available at:
http://www.github.com/shaharzuler/cardio_volume_skewer

ÊëòË¶ÅÔºö‰ΩøÁî®Â∏∂ÊúâÁúüÂØ¶ (GT) Ê®ôË®ªÁöÑÈ´òËß£ÊûêÂ∫¶ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) Ë≥áÊñôÈõÜÊ∫ñÁ¢∫ÂàÜÊûê 3D ÂøÉËÇåËÆäÂΩ¢Â∞çÊñºÊé®ÈÄ≤ÂøÉË°ÄÁÆ°ÂΩ±ÂÉèÁ†îÁ©∂Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûË≥áÊñôÈõÜÁöÑÁ®ÄÂ∞ëÂ∞çÈñãÁôºÂº∑ÂÅ•ÁöÑÂøÉËÇåËÆäÂΩ¢ÂàÜÊûêÊ®°ÂûãÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂêàÊàêË≥áÊñôÁîüÊàêÊñπÊ≥ïÔºåÁî®ÊñºË±êÂØåÂøÉË°ÄÁÆ°ÂΩ±ÂÉèË≥áÊñôÈõÜ„ÄÇ
  ÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂêàÊàêË≥áÊñôÁîüÊàêÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫ÜÈáçË¶ÅÁöÑ GT 3D ÂÖâÊµÅÊ®ôË®ª„ÄÇÊàëÂÄëÊ¶ÇËø∞‰∫ÜÂæûÂøÉËáüÂõõÁ∂≠ (4D) CT ÊéÉÊèè‰∏≠Ê∫ñÂÇôË≥áÊñô„ÄÅÈÅ∏ÊìáÂèÉÊï∏Ôºå‰ª•ÂèäÈö®ÂæåÂæûÁõ∏ÂêåÊàñÂÖ∂‰ªñ‰æÜÊ∫êÁöÑ 3D ÂøÉËáü CT Ë≥áÊñô‰∏≠Âª∫Á´ãÂêàÊàêË≥áÊñô‰ª•ÈÄ≤Ë°åË®ìÁ∑¥ÁöÑÈÅéÁ®ã„ÄÇ
  ÊàëÂÄëÁöÑÁ†îÁ©∂ÊúâÂä©ÊñºÂÖãÊúçÈ´òËß£ÊûêÂ∫¶ CT Ë≥áÊñôÈõÜÊ®ôË®ª‰∏çÁ≤æÁ¢∫ÁöÑÈôêÂà∂ÔºåÂæûËÄå‰øÉÈÄ≤ÈñãÁôºÈÅ©Áî®ÊñºËá®Â∫äÊáâÁî®ÂíåË®∫Êñ∑ÁöÑÊ∫ñÁ¢∫‰∏îÂèØÈù†ÁöÑÂøÉËÇåËÆäÂΩ¢ÂàÜÊûêÊºîÁÆóÊ≥ï„ÄÇ
  ÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºö
http://www.github.com/shaharzuler/cardio_volume_skewer

##### **MEDIQ: Question-Asking LLMs for Adaptive and Reliable Clinical Reasoning**
2406.00922v2 by Shuyue Stella Li, Vidhisha Balachandran, Shangbin Feng, Jonathan Ilgen, Emma Pierson, Pang Wei Koh, Yulia Tsvetkov

In high-stakes domains like clinical reasoning, AI assistants powered by
large language models (LLMs) are yet to be reliable and safe. We identify a key
obstacle towards reliability: existing LLMs are trained to answer any question,
even with incomplete context in the prompt or insufficient parametric
knowledge. We propose to change this paradigm to develop more careful LLMs that
ask follow-up questions to gather necessary and sufficient information and
respond reliably. We introduce MEDIQ, a framework to simulate realistic
clinical interactions, which incorporates a Patient System and an adaptive
Expert System. The Patient may provide incomplete information in the beginning;
the Expert refrains from making diagnostic decisions when unconfident, and
instead elicits missing details from the Patient via follow-up questions. To
evaluate MEDIQ, we convert MEDQA and CRAFT-MD -- medical benchmarks for
diagnostic question answering -- into an interactive setup. We develop a
reliable Patient system and prototype several Expert systems, first showing
that directly prompting state-of-the-art LLMs to ask questions degrades the
quality of clinical reasoning, indicating that adapting LLMs to interactive
information-seeking settings is nontrivial. We then augment the Expert with a
novel abstention module to better estimate model confidence and decide whether
to ask more questions, thereby improving diagnostic accuracy by 20.3%; however,
performance still lags compared to an (unrealistic in practice) upper bound
when full information is given upfront. Further analyses reveal that
interactive performance can be improved by filtering irrelevant contexts and
reformatting conversations. Overall, our paper introduces a novel problem
towards LLM reliability, a novel MEDIQ framework, and highlights important
future directions to extend the information-seeking abilities of LLM assistants
in critical domains.

ÊëòË¶ÅÔºö<paragraph>Âú®Ëá®Â∫äÊé®ÁêÜÁ≠âÈ´òÈ¢®Èö™È†òÂüüÔºåÁî±Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êèê‰æõÊîØÊè¥ÁöÑ AI Âä©ÁêÜ‰ªçÊú™ÈÅîÂà∞ÂèØÈù†ÂíåÂÆâÂÖ®ÁöÑÁ®ãÂ∫¶„ÄÇÊàëÂÄëÊâæÂá∫ÂèØÈù†ÊÄßÁöÑ‰∏ÄÂÄã‰∏ªË¶ÅÈöúÁ§ôÔºöÁèæÊúâÁöÑ LLM Á∂ìÈÅéË®ìÁ∑¥ÂèØ‰ª•ÂõûÁ≠î‰ªª‰ΩïÂïèÈ°åÔºåÂç≥‰ΩøÊèêÁ§∫‰∏≠ÁöÑÂÖßÂÆπ‰∏çÂÆåÊï¥ÊàñÂèÉÊï∏Áü•Ë≠ò‰∏çË∂≥„ÄÇÊàëÂÄëÂª∫Ë≠∞ÊîπËÆäÈÄôÁ®ÆÊ®°ÂºèÔºåÈñãÁôºÂá∫Êõ¥Ë¨πÊÖéÁöÑ LLMÔºåÂÆÉÂÄëÊúÉÊèêÂá∫ÂæåÁ∫åÂïèÈ°å‰æÜÊî∂ÈõÜÂøÖË¶Å‰∏îÂÖÖÂàÜÁöÑË≥áË®äÔºå‰∏¶ÂÅöÂá∫ÂèØÈù†ÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÊé®Âá∫ MEDIQÔºå‰∏ÄÂÄãÊ®°Êì¨ÁèæÂØ¶Ëá®Â∫ä‰∫íÂãïÁöÑÊû∂ÊßãÔºåÂÆÉÂåÖÂê´‰∏ÄÂÄãÁóÖ‰∫∫Á≥ªÁµ±Âíå‰∏ÄÂÄãÈÅ©ÊáâÊÄßÂ∞àÂÆ∂Á≥ªÁµ±„ÄÇÁóÖ‰∫∫‰∏ÄÈñãÂßãÂèØËÉΩÊúÉÊèê‰æõ‰∏çÂÆåÊï¥ÁöÑË≥áË®äÔºõÂ∞àÂÆ∂Âú®‰∏çÁ¢∫ÂÆöÁöÑÊôÇÂÄôÊúÉÈÅøÂÖçÂÅöÂá∫Ë®∫Êñ∑Ê±∫Á≠ñÔºåËÄåÊòØÈÄèÈÅéÂæåÁ∫åÂïèÈ°åÂæûÁóÖ‰∫∫ÈÇ£Ë£°ÂºïÂá∫ÈÅ∫ÊºèÁöÑÁ¥∞ÁØÄ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ MEDIQÔºåÊàëÂÄëÂ∞á MEDQA Âíå CRAFT-MDÔºàÁî®ÊñºË®∫Êñ∑ÊÄßÂïèÁ≠îÁöÑÈÜ´ÁôÇÂü∫Ê∫ñÔºâËΩâÊèõÁÇ∫‰∫íÂãïÂºèË®≠ÂÆö„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂèØÈù†ÁöÑÁóÖ‰∫∫Á≥ªÁµ±ÂíåÂπæÂÄãÂ∞àÂÆ∂Á≥ªÁµ±ÂéüÂûãÔºåÈ¶ñÂÖàË°®ÊòéÁõ¥Êé•ÊèêÁ§∫ÊúÄÂÖàÈÄ≤ÁöÑ LLM ÊèêÂá∫ÂïèÈ°åÊúÉÈôç‰ΩéËá®Â∫äÊé®ÁêÜÁöÑÂìÅË≥™ÔºåÈÄôË°®Á§∫Â∞á LLM ÈÅ©ÊáâÂà∞‰∫íÂãïÂºèË≥áË®äÂ∞ãÊ±ÇË®≠ÂÆö‰∏¶ÈùûÊòì‰∫ã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ£ÑÊ¨äÊ®°ÁµÑÊì¥ÂÖÖÂ∞àÂÆ∂Ôºå‰ª•Êõ¥Â•ΩÂú∞‰º∞Ë®àÊ®°ÂûãÁöÑ‰ø°ÂøÉ‰∏¶Ê±∫ÂÆöÊòØÂê¶Ë¶ÅÊèêÂá∫Êõ¥Â§öÂïèÈ°åÔºåÂæûËÄåÂ∞áË®∫Êñ∑Ê∫ñÁ¢∫ÁéáÊèêÈ´ò 20.3%ÔºõÁÑ∂ËÄåÔºåËàáÂú®ÊúÄÈñãÂßãÂ∞±Áµ¶‰∫àÂÆåÊï¥Ë≥áË®äÁöÑÔºàÂú®ÂØ¶Âãô‰∏ä‰∏çÂàáÂØ¶ÈöõÁöÑÔºâ‰∏äÈôêÁõ∏ÊØîÔºåÊïàËÉΩ‰ªçÁÑ∂ËêΩÂæå„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêÈ°ØÁ§∫Ôºå‰∫íÂãïÊïàËÉΩÂèØ‰ª•ÈÄèÈÅéÈÅéÊøæ‰∏çÁõ∏ÈóúÁöÑÂÖßÂÆπÂíåÈáçÊñ∞Ê†ºÂºèÂåñÂ∞çË©±‰æÜÊîπÂñÑ„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁöÑË´ñÊñáÈáùÂ∞ç LLM ÂèØÈù†ÊÄßÊèêÂá∫‰∏ÄÂÄãÊñ∞ÂïèÈ°å„ÄÅ‰∏ÄÂÄãÊñ∞Á©éÁöÑ MEDIQ Êû∂ÊßãÔºå‰∏¶Âº∑Ë™øÂú®ÈóúÈçµÈ†òÂüüÊì¥Â±ï LLM Âä©ÁêÜË≥áË®äÂ∞ãÊ±ÇËÉΩÂäõÁöÑÈáçË¶ÅÊú™‰æÜÊñπÂêë„ÄÇ</paragraph>

##### **Bayesian Joint Additive Factor Models for Multiview Learning**
2406.00778v1 by Niccolo Anceschi, Federico Ferrari, David B. Dunson, Himel Mallick

It is increasingly common in a wide variety of applied settings to collect
data of multiple different types on the same set of samples. Our particular
focus in this article is on studying relationships between such multiview
features and responses. A motivating application arises in the context of
precision medicine where multi-omics data are collected to correlate with
clinical outcomes. It is of interest to infer dependence within and across
views while combining multimodal information to improve the prediction of
outcomes. The signal-to-noise ratio can vary substantially across views,
motivating more nuanced statistical tools beyond standard late and early
fusion. This challenge comes with the need to preserve interpretability, select
features, and obtain accurate uncertainty quantification. We propose a joint
additive factor regression model (JAFAR) with a structured additive design,
accounting for shared and view-specific components. We ensure identifiability
via a novel dependent cumulative shrinkage process (D-CUSP) prior. We provide
an efficient implementation via a partially collapsed Gibbs sampler and extend
our approach to allow flexible feature and outcome distributions. Prediction of
time-to-labor onset from immunome, metabolome, and proteome data illustrates
performance gains against state-of-the-art competitors. Our open-source
software (R package) is available at https://github.com/niccoloanceschi/jafar.

ÊëòË¶ÅÔºöÂú®ÂêÑÁßçÂ∫îÁî®ËÆæÁΩÆ‰∏≠ÔºåÈíàÂØπÂêå‰∏ÄÁªÑÊ†∑Êú¨Êî∂ÈõÜÂ§öÁßç‰∏çÂêåÁ±ªÂûãÁöÑÊï∞ÊçÆÂèòÂæóË∂äÊù•Ë∂äÊôÆÈÅç„ÄÇÊú¨ÊñáÁöÑÈáçÁÇπÊòØÁ†îÁ©∂Ê≠§Á±ªÂ§öËßÜÂõæÁâπÂæÅÂíåÂìçÂ∫î‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇ‰∏Ä‰∏™ÊøÄÂä±ÊÄßÁöÑÂ∫îÁî®Âá∫Áé∞Âú®Á≤æÂáÜÂåªÂ≠¶ÁöÑËÉåÊôØ‰∏≠ÔºåÂÖ∂‰∏≠Êî∂ÈõÜÂ§öÁªÑÂ≠¶Êï∞ÊçÆ‰ª•‰∏é‰∏¥Â∫äÁªìÊûúÁõ∏ÂÖ≥ËÅî„ÄÇÂú®ÁªìÂêàÂ§öÊ®°Âºè‰ø°ÊÅØ‰ª•ÊîπÂñÑÁªìÊûúÈ¢ÑÊµãÊó∂ÔºåÊé®Êñ≠ËßÜÂõæÂÜÖÂíåËßÜÂõæ‰πãÈó¥ÁöÑ‰æùËµñÊÄßÈùûÂ∏∏ÈáçË¶Å„ÄÇ‰ø°Âô™ÊØîÂú®‰∏çÂêåËßÜÂõæ‰πãÈó¥ÂèØËÉΩ‰ºöÊúâÂæàÂ§ßÂ∑ÆÂºÇÔºåËøô‰øÉ‰Ωø‰∫∫‰ª¨Âú®Ê†áÂáÜÁöÑÂêéÊúüÂíåÊó©ÊúüËûçÂêà‰πãÂ§ñÈááÁî®Êõ¥ÁªÜËá¥ÁöÑÁªüËÆ°Â∑•ÂÖ∑„ÄÇËøô‰∏ÄÊåëÊàò‰º¥ÈöèÁùÄÈúÄË¶Å‰øùÊåÅÂèØËß£ÈáäÊÄß„ÄÅÈÄâÊã©ÁâπÂæÅÂíåËé∑ÂæóÂáÜÁ°ÆÁöÑ‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñ„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂÖ∑ÊúâÁªìÊûÑÂåñÂä†Ê≥ïËÆæËÆ°ÁöÑËÅîÂêàÂä†Ê≥ïÂõ†Â≠êÂõûÂΩíÊ®°Âûã (JAFAR)ÔºåÂÆÉËÄÉËôë‰∫ÜÂÖ±‰∫´ÂíåÁâπÂÆö‰∫éËßÜÂõæÁöÑÁªÑ‰ª∂„ÄÇÊàë‰ª¨ÈÄöËøá‰∏Ä‰∏™Êñ∞È¢ñÁöÑ‰æùËµñÁ¥ØÁßØÊî∂Áº©ËøáÁ®ã (D-CUSP) ÂÖàÈ™åÁ°Æ‰øùÂèØËØÜÂà´ÊÄß„ÄÇÊàë‰ª¨ÈÄöËøáÈÉ®ÂàÜÊäòÂè†ÁöÑ Gibbs ÈááÊ†∑Âô®Êèê‰æõÈ´òÊïàÁöÑÂÆûÁé∞ÔºåÂπ∂Êâ©Â±ïÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ª•ÂÖÅËÆ∏ÁÅµÊ¥ªÁöÑÁâπÂæÅÂíåÁªìÊûúÂàÜÂ∏É„ÄÇ‰ªéÂÖçÁñ´ÁªÑ„ÄÅ‰ª£Ë∞¢ÁªÑÂíåËõãÁôΩË¥®ÁªÑÊï∞ÊçÆÈ¢ÑÊµãÂàÜÂ®©ÂºÄÂßãÊó∂Èó¥ËØ¥Êòé‰∫ÜÈíàÂØπÊúÄÂÖàËøõÁ´û‰∫âÂØπÊâãÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÊàë‰ª¨ÁöÑÂºÄÊ∫êËΩØ‰ª∂ÔºàR ÂåÖÔºâÂèØÂú® https://github.com/niccoloanceschi/jafar Ëé∑Âæó„ÄÇ

##### **An Early Investigation into the Utility of Multimodal Large Language Models in Medical Imaging**
2406.00667v1 by Sulaiman Khan, Md. Rafiul Biswas, Alina Murad, Hazrat Ali, Zubair Shah

Recent developments in multimodal large language models (MLLMs) have spurred
significant interest in their potential applications across various medical
imaging domains. On the one hand, there is a temptation to use these generative
models to synthesize realistic-looking medical image data, while on the other
hand, the ability to identify synthetic image data in a pool of data is also
significantly important. In this study, we explore the potential of the Gemini
(\textit{gemini-1.0-pro-vision-latest}) and GPT-4V (gpt-4-vision-preview)
models for medical image analysis using two modalities of medical image data.
Utilizing synthetic and real imaging data, both Gemini AI and GPT-4V are first
used to classify real versus synthetic images, followed by an interpretation
and analysis of the input images. Experimental results demonstrate that both
Gemini and GPT-4 could perform some interpretation of the input images. In this
specific experiment, Gemini was able to perform slightly better than the GPT-4V
on the classification task. In contrast, responses associated with GPT-4V were
mostly generic in nature. Our early investigation presented in this work
provides insights into the potential of MLLMs to assist with the classification
and interpretation of retinal fundoscopy and lung X-ray images. We also
identify key limitations associated with the early investigation study on MLLMs
for specialized tasks in medical image analysis.

ÊëòË¶ÅÔºöÊúÄËøëÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (MLLM) ÁöÑÂèëÂ±ïÊøÄÂèë‰∫Ü‰∫∫‰ª¨ÂØπÂÖ∂Âú®ÂêÑÁßçÂåªÂ≠¶ÂΩ±ÂÉèÈ¢ÜÂüüÁöÑÊΩúÂú®Â∫îÁî®ÁöÑÊµìÂéöÂÖ¥Ë∂£„ÄÇ‰∏ÄÊñπÈù¢Ôºå‰∫∫‰ª¨ÂæàÊÉ≥‰ΩøÁî®Ëøô‰∫õÁîüÊàêÊ®°ÂûãÊù•ÂêàÊàêÈÄºÁúüÁöÑÂåªÂ≠¶ÂΩ±ÂÉèÊï∞ÊçÆÔºåËÄåÂè¶‰∏ÄÊñπÈù¢ÔºåÂú®Êï∞ÊçÆÊ±†‰∏≠ËØÜÂà´ÂêàÊàêÂΩ±ÂÉèÊï∞ÊçÆÁöÑËÉΩÂäõ‰πüÊûÅÂÖ∂ÈáçË¶Å„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàë‰ª¨Êé¢ËÆ®‰∫Ü Gemini (\textit{gemini-1.0-pro-vision-latest}) Âíå GPT-4V (gpt-4-vision-preview) Ê®°ÂûãÂú®‰ΩøÁî®‰∏§ÁßçÂåªÂ≠¶ÂΩ±ÂÉèÊï∞ÊçÆÊ®°ÊÄÅËøõË°åÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûêÊñπÈù¢ÁöÑÊΩúÂäõ„ÄÇÂà©Áî®ÂêàÊàêÂíåÁúüÂÆûÊàêÂÉèÊï∞ÊçÆÔºåGemini AI Âíå GPT-4V È¶ñÂÖàÁî®‰∫éÂØπÁúüÂÆûÂõæÂÉèÂíåÂêàÊàêÂõæÂÉèËøõË°åÂàÜÁ±ªÔºåÁÑ∂ÂêéÂØπËæìÂÖ•ÂõæÂÉèËøõË°åËß£ÈáäÂíåÂàÜÊûê„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGemini Âíå GPT-4 ÈÉΩÂèØ‰ª•ÂØπËæìÂÖ•ÂõæÂÉèËøõË°å‰∏Ä‰∫õËß£Èáä„ÄÇÂú®Ëøô‰∏™ÂÖ∑‰ΩìÂÆûÈ™å‰∏≠ÔºåGemini Âú®ÂàÜÁ±ª‰ªªÂä°‰∏äÁöÑË°®Áé∞Áï•Â•Ω‰∫é GPT-4V„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰∏é GPT-4V Áõ∏ÂÖ≥ÁöÑÂìçÂ∫îÂ§ßÂ§öÊòØÈÄöÁî®ÁöÑ„ÄÇÊàë‰ª¨Âú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÊèêÂá∫ÁöÑÊó©ÊúüË∞ÉÊü•Êèê‰æõ‰∫ÜÂÖ≥‰∫é MLLM ÂçèÂä©ÂàÜÁ±ªÂíåËß£ÈáäËßÜÁΩëËÜúÁúºÂ∫ïÈïúÂíåËÇ∫ÈÉ® X Â∞ÑÁ∫øÂõæÂÉèÁöÑÊΩúÂäõÁöÑËßÅËß£„ÄÇÊàë‰ª¨ËøòÁ°ÆÂÆö‰∫Ü‰∏éÈíàÂØπÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûê‰∏≠ÁöÑ‰∏ìÈó®‰ªªÂä°ÁöÑ MLLM Êó©ÊúüË∞ÉÊü•Á†îÁ©∂Áõ∏ÂÖ≥ÁöÑÂÖ≥ÈîÆÈôêÂà∂„ÄÇ

##### **SimSAM: Zero-shot Medical Image Segmentation via Simulated Interaction**
2406.00663v1 by Benjamin Towle, Xin Chen, Ke Zhou

The recently released Segment Anything Model (SAM) has shown powerful
zero-shot segmentation capabilities through a semi-automatic annotation setup
in which the user can provide a prompt in the form of clicks or bounding boxes.
There is growing interest around applying this to medical imaging, where the
cost of obtaining expert annotations is high, privacy restrictions may limit
sharing of patient data, and model generalisation is often poor. However, there
are large amounts of inherent uncertainty in medical images, due to unclear
object boundaries, low-contrast media, and differences in expert labelling
style. Currently, SAM is known to struggle in a zero-shot setting to adequately
annotate the contours of the structure of interest in medical images, where the
uncertainty is often greatest, thus requiring significant manual correction. To
mitigate this, we introduce \textbf{Sim}ulated Interaction for \textbf{S}egment
\textbf{A}nything \textbf{M}odel (\textsc{\textbf{SimSAM}}), an approach that
leverages simulated user interaction to generate an arbitrary number of
candidate masks, and uses a novel aggregation approach to output the most
compatible mask. Crucially, our method can be used during inference directly on
top of SAM, without any additional training requirement. Quantitatively, we
evaluate our method across three publicly available medical imaging datasets,
and find that our approach leads to up to a 15.5\% improvement in contour
segmentation accuracy compared to zero-shot SAM. Our code is available at
\url{https://github.com/BenjaminTowle/SimSAM}.

ÊëòË¶ÅÔºöÊúÄËøëÂèëÂ∏ÉÁöÑ Segment Anything Model (SAM) Â∑≤ÈÄöËøáÂçäËá™Âä®Ê≥®ÈáäËÆæÁΩÆÂ±ïÁ§∫‰∫ÜÂº∫Â§ßÁöÑÈõ∂Ê¨°ÂàÜÊÆµËÉΩÂäõÔºåÂÖ∂‰∏≠Áî®Êà∑ÂèØ‰ª•ÈÄöËøáÂçïÂáªÊàñËæπÁïåÊ°ÜÁöÑÂΩ¢ÂºèÊèê‰æõÊèêÁ§∫„ÄÇ‰∫∫‰ª¨Ë∂äÊù•Ë∂äÊúâÂÖ¥Ë∂£Â∞ÜÊ≠§Â∫îÁî®‰∫éÂåªÂ≠¶ÂΩ±ÂÉèÔºåÂÖ∂‰∏≠Ëé∑Âæó‰∏ìÂÆ∂Ê≥®ÈáäÁöÑÊàêÊú¨ÂæàÈ´òÔºåÈöêÁßÅÈôêÂà∂ÂèØËÉΩ‰ºöÈôêÂà∂ÊÇ£ËÄÖÊï∞ÊçÆÁöÑÂÖ±‰∫´ÔºåÂπ∂‰∏îÊ®°ÂûãÊ≥õÂåñÈÄöÂ∏∏ÂæàÂ∑Æ„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÂØπË±°ÁöÑËæπÁïå‰∏çÊ∏Ö„ÄÅ‰ªãË¥®ÂØπÊØîÂ∫¶‰Ωé‰ª•Âèä‰∏ìÂÆ∂Ê†áËÆ∞È£éÊ†ºÁöÑÂ∑ÆÂºÇÔºåÂåªÂ≠¶ÂΩ±ÂÉè‰∏≠Â≠òÂú®Â§ßÈáèÂõ∫ÊúâÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÁõÆÂâçÔºåÂ∑≤Áü• SAM Âú®Èõ∂Ê¨°ËÆæÁΩÆ‰∏≠Èöæ‰ª•ÂÖÖÂàÜÊ≥®ÈáäÂåªÂ≠¶ÂΩ±ÂÉè‰∏≠ÊÑüÂÖ¥Ë∂£ÁªìÊûÑÁöÑËΩÆÂªìÔºåÂÖ∂‰∏≠‰∏çÁ°ÆÂÆöÊÄßÈÄöÂ∏∏ÊúÄÂ§ßÔºåÂõ†Ê≠§ÈúÄË¶ÅÂ§ßÈáèÁöÑÊâãÂä®Ê†°Ê≠£„ÄÇ‰∏∫‰∫ÜÁºìËß£ËøôÁßçÊÉÖÂÜµÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü \textbf{S}imulated \textbf{I}nteraction for \textbf{S}egment \textbf{A}nything \textbf{M}odel (\textsc{\textbf{SimSAM}}ÔºâÔºåËøôÊòØ‰∏ÄÁßçÂà©Áî®Ê®°ÊãüÁî®Êà∑‰∫§‰∫íÊù•ÁîüÊàê‰ªªÊÑèÊï∞ÈáèÁöÑÂÄôÈÄâÊé©Á†ÅÁöÑÊñπÊ≥ïÔºåÂπ∂‰ΩøÁî®Êñ∞È¢ñÁöÑËÅöÂêàÊñπÊ≥ïÊù•ËæìÂá∫ÊúÄÂÖºÂÆπÁöÑÊé©Á†Å„ÄÇËá≥ÂÖ≥ÈáçË¶ÅÁöÑÊòØÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂèØ‰ª•Áõ¥Êé•Âú® SAM ‰πã‰∏ä‰ΩøÁî®ÔºåËÄåÊó†ÈúÄ‰ªª‰ΩïÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉË¶ÅÊ±Ç„ÄÇÂú®Êï∞ÈáèÊñπÈù¢ÔºåÊàë‰ª¨ÂØπ‰∏âÁßçÂÖ¨ÂºÄÁöÑÂåªÂ≠¶ÂΩ±ÂÉèÊï∞ÊçÆÈõÜËØÑ‰º∞‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÔºåÂπ∂ÂèëÁé∞‰∏éÈõ∂Ê¨° SAM Áõ∏ÊØîÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ËΩÆÂªìÂàÜÊÆµÂáÜÁ°ÆÊÄßÊñπÈù¢ÊèêÈ´ò‰∫Ü 15.5%„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú® \url{https://github.com/BenjaminTowle/SimSAM} Ëé∑Âæó„ÄÇ

##### **Multimodal Deep Learning for Low-Resource Settings: A Vector Embedding Alignment Approach for Healthcare Applications**
2406.02601v1 by David Restrepo, Chenwei Wu, Sebasti√°n Andr√©s Cajas, Luis Filipe Nakayama, Leo Anthony Celi, Diego M L√≥pez

Large-scale multi-modal deep learning models have revolutionized domains such
as healthcare, highlighting the importance of computational power. However, in
resource-constrained regions like Low and Middle-Income Countries (LMICs),
limited access to GPUs and data poses significant challenges, often leaving
CPUs as the sole resource. To address this, we advocate for leveraging vector
embeddings to enable flexible and efficient computational methodologies,
democratizing multimodal deep learning across diverse contexts.
  Our paper investigates the efficiency and effectiveness of using vector
embeddings from single-modal foundation models and multi-modal Vision-Language
Models (VLMs) for multimodal deep learning in low-resource environments,
particularly in healthcare. Additionally, we propose a simple yet effective
inference-time method to enhance performance by aligning image-text embeddings.
Comparing these approaches with traditional methods, we assess their impact on
computational efficiency and model performance using metrics like accuracy,
F1-score, inference time, training time, and memory usage across three medical
modalities: BRSET (ophthalmology), HAM10000 (dermatology), and SatelliteBench
(public health).
  Our findings show that embeddings reduce computational demands without
compromising model performance. Furthermore, our alignment method improves
performance in medical tasks. This research promotes sustainable AI practices
by optimizing resources in constrained environments, highlighting the potential
of embedding-based approaches for efficient multimodal learning. Vector
embeddings democratize multimodal deep learning in LMICs, particularly in
healthcare, enhancing AI adaptability in varied use cases.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãÂ§öÊ®°ÊÄÅÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÂ∑≤ÁªèÂΩªÂ∫ïÊîπÂèò‰∫ÜÂåªÁñó‰øùÂÅ•Á≠âÈ¢ÜÂüüÔºåÁ™ÅÂá∫‰∫ÜËÆ°ÁÆóËÉΩÂäõÁöÑÈáçË¶ÅÊÄß„ÄÇÁÑ∂ËÄåÔºåÂú®ËµÑÊ∫êÂèóÈôêÁöÑÂú∞Âå∫ÔºåÂ¶Ç‰ΩéÊî∂ÂÖ•Âíå‰∏≠Á≠âÊî∂ÂÖ•ÂõΩÂÆ∂ (LMIC)ÔºåÂèóÈôêÁöÑ GPU ÂíåÊï∞ÊçÆËÆøÈóÆÂ∏¶Êù•‰∫ÜÈáçÂ§ßÊåëÊàòÔºåÈÄöÂ∏∏Âè™Ââ©‰∏ã CPU ‰Ωú‰∏∫ÂîØ‰∏ÄËµÑÊ∫ê„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂÄ°Âà©Áî®ÂêëÈáèÂµåÂÖ•Êù•ÂÆûÁé∞ÁÅµÊ¥ªÈ´òÊïàÁöÑËÆ°ÁÆóÊñπÊ≥ïÔºåËÆ©Â§öÊ®°ÊÄÅÊ∑±Â∫¶Â≠¶‰π†Âú®‰∏çÂêåÁöÑÁéØÂ¢É‰∏≠ÂÆûÁé∞Ê∞ë‰∏ªÂåñ„ÄÇ
Êàë‰ª¨ÁöÑËÆ∫ÊñáÁ†îÁ©∂‰∫ÜÂú®ËµÑÊ∫êÂèóÈôêÁöÑÁéØÂ¢É‰∏≠Ôºå‰ΩøÁî®Êù•Ëá™ÂçïÊ®°ÊÄÅÂü∫Á°ÄÊ®°ÂûãÂíåÂ§öÊ®°ÊÄÅËßÜËßâËØ≠Ë®ÄÊ®°Âûã (VLM) ÁöÑÂêëÈáèÂµåÂÖ•ËøõË°åÂ§öÊ®°ÊÄÅÊ∑±Â∫¶Â≠¶‰π†ÁöÑÊïàÁéáÂíåÊúâÊïàÊÄßÔºåÁâπÂà´ÊòØÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüü„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçïËÄåÊúâÊïàÊé®ÁêÜÊó∂Èó¥ÊñπÊ≥ïÔºåÈÄöËøáÂØπÈΩêÂõæÂÉèÊñáÊú¨ÂµåÂÖ•Êù•Â¢ûÂº∫ÊÄßËÉΩ„ÄÇÂ∞ÜËøô‰∫õÊñπÊ≥ï‰∏é‰º†ÁªüÊñπÊ≥ïËøõË°åÊØîËæÉÔºåÊàë‰ª¨ËØÑ‰º∞‰∫ÜÂÆÉ‰ª¨ÂØπËÆ°ÁÆóÊïàÁéáÂíåÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±ÂìçÔºå‰ΩøÁî®ÂáÜÁ°ÆÂ∫¶„ÄÅF1 ÂàÜÊï∞„ÄÅÊé®ÁêÜÊó∂Èó¥„ÄÅËÆ≠ÁªÉÊó∂Èó¥ÂíåÂÜÖÂ≠ò‰ΩøÁî®Á≠âÊåáÊ†áÔºåË∑®Ë∂ä‰∏â‰∏™ÂåªÂ≠¶Ê®°ÊÄÅÔºöBRSETÔºàÁúºÁßëÔºâ„ÄÅHAM10000ÔºàÁöÆËÇ§ÁóÖÂ≠¶ÔºâÂíå SatelliteBenchÔºàÂÖ¨ÂÖ±Âç´ÁîüÔºâ„ÄÇ
Êàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÂµåÂÖ•ÂèØ‰ª•Èôç‰ΩéËÆ°ÁÆóÈúÄÊ±ÇÔºåÂêåÊó∂‰∏çÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÂØπÈΩêÊñπÊ≥ïÊèêÈ´ò‰∫ÜÂåªÂ≠¶‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇËøôÈ°πÁ†îÁ©∂ÈÄöËøá‰ºòÂåñÂèóÈôêÁéØÂ¢É‰∏≠ÁöÑËµÑÊ∫êÔºå‰øÉËøõ‰∫ÜÂèØÊåÅÁª≠ÁöÑ AI ÂÆûË∑µÔºåÁ™ÅÂá∫‰∫ÜÂü∫‰∫éÂµåÂÖ•ÁöÑÊñπÊ≥ïÂú®È´òÊïàÂ§öÊ®°ÊÄÅÂ≠¶‰π†‰∏≠ÁöÑÊΩúÂäõ„ÄÇÂêëÈáèÂµåÂÖ•ËÆ© LMIC ‰∏≠ÁöÑÂ§öÊ®°ÊÄÅÊ∑±Â∫¶Â≠¶‰π†ÂÆûÁé∞Ê∞ë‰∏ªÂåñÔºåÁâπÂà´ÊòØÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÔºåÂ¢ûÂº∫‰∫Ü AI Âú®ÂêÑÁßçÁî®‰æã‰∏≠ÁöÑÈÄÇÂ∫îÊÄß„ÄÇ</paragraph>

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

ÊëòË¶ÅÔºö‰π≥Áôå (BC) ÊòØÂΩ±ÈüøÂÖ®ÁêÉÂ•≥ÊÄßÊúÄÂ∏∏Ë¶ãÁöÑÊÉ°ÊÄßËÖ´Áò§‰πã‰∏ÄÔºåÂõ†Ê≠§ÈúÄË¶ÅÈÄ≤Ê≠•ÁöÑË®∫Êñ∑ÊñπÊ≥ïÔºå‰ª•ÊîπÂñÑËá®Â∫äÁµêÊûú„ÄÇÊú¨ÊñáÂÖ®Èù¢Êé¢Ë®é‰∫ÜÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ìÂú®‰π≥ÁôåÂÅµÊ∏¨ÂíåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÊåÅÁ∫åÊª≤ÈÄèÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÁâπÂà•ÊòØÂú®ËÖ´Áò§Â≠∏‰∏≠ÔºåÈÄèÊòé‰∏îÂèØËß£ÈáãÁöÑÊ®°ÂûãÈúÄÊ±ÇËÆäÂæóÂã¢Âú®ÂøÖË°åÔºå‰ª•Â¢ûÂº∑Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂíåÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§ÁØáË©ïË´ñÊé¢Ë®é‰∫ÜÂêÑÁ®Æ XAI ÊñπÊ≥ïÁöÑÊï¥ÂêàÔºå‰æãÂ¶Ç SHAP„ÄÅLIME„ÄÅGrad-CAM Á≠âÔºå‰ª•ÂèäÁî®Êñº‰π≥ÁôåÂÅµÊ∏¨ÂíåÂàÜÈ°ûÁöÑÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄèÈÅéÊé¢Ë®é‰π≥ÁôåË≥áÊñôÈõÜÁöÑÊ®°ÂºèÔºåÂåÖÊã¨‰π≥ÊàøÊîùÂΩ±„ÄÅË∂ÖÈü≥Ê≥¢ÂèäÂÖ∂Âú® AI ‰∏≠ÁöÑËôïÁêÜÔºåÊú¨ÊñáÈáçÈªûË™™Êòé XAI Â¶Ç‰ΩïËÉΩÂ∞éËá¥Êõ¥Ê∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇË®àÁï´„ÄÇÂÆÉ‰πüÊé¢Ë®é‰∫ÜÂØ¶ÊñΩÈÄô‰∫õÊäÄË°ìÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂà∂ÂÆöÊ®ôÊ∫ñÂåñË©ïÈáèÊåáÊ®ô‰ª•Ë©ï‰º∞ XAI Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑÂàÜÊûêÂíåË®éË´ñÔºåÊú¨ÊñáÊó®Âú®Âº∑Ë™ø XAI Âú®Á∏ÆÂ∞èË§áÈõú AI Ê®°ÂûãËàáÂØ¶ÂãôÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰πãÈñìÂ∑ÆË∑ùÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°‰πãÈñìÁöÑ‰ø°‰ªªËàáÁêÜËß£Ôºå‰∏¶ÊîπÂñÑÊÇ£ËÄÖÁöÑÁµêÊûú„ÄÇ

##### **CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models**
2406.00314v2 by Sarthak Harne, Monjoy Narayan Choudhury, Madhav Rao, TK Srikanth, Seema Mehrotra, Apoorva Vashisht, Aarushi Basu, Manjit Sodhi

The limited availability of psychologists necessitates efficient
identification of individuals requiring urgent mental healthcare. This study
explores the use of Natural Language Processing (NLP) pipelines to analyze text
data from online mental health forums used for consultations. By analyzing
forum posts, these pipelines can flag users who may require immediate
professional attention. A crucial challenge in this domain is data privacy and
scarcity. To address this, we propose utilizing readily available curricular
texts used in institutes specializing in mental health for pre-training the NLP
pipelines. This helps us mimic the training process of a psychologist. Our work
presents CASE-BERT that flags potential mental health disorders based on forum
text. CASE-BERT demonstrates superior performance compared to existing methods,
achieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the
most commonly reported mental health disorders. Our code is publicly available.

ÊëòË¶ÅÔºöÁî±ÊñºÂøÉÁêÜÂ≠∏ÂÆ∂Êï∏ÈáèÊúâÈôêÔºåÂõ†Ê≠§ÊúâÂøÖË¶ÅÊúâÊïàÁéáÂú∞ÊâæÂá∫ÈúÄË¶ÅÁ∑äÊÄ•ÂøÉÁêÜ‰øùÂÅ•ÁöÑÂÄã‰∫∫„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÁÆ°Á∑öÂàÜÊûêÁ∑ö‰∏äÂøÉÁêÜÂÅ•Â∫∑Ë´ñÂ£áÁî®ÊñºË´ÆË©¢ÁöÑÊñáÂ≠óË≥áÊñô„ÄÇÈÄô‰∫õÁÆ°Á∑öÂèØÈÄèÈÅéÂàÜÊûêË´ñÂ£áË≤ºÊñáÔºåÊ®ôË®òÂèØËÉΩÈúÄË¶ÅÁ´ãÂç≥Â∞àÊ•≠ÂçîÂä©ÁöÑ‰ΩøÁî®ËÄÖ„ÄÇÂú®ÈÄôÂÄãÈ†òÂüü‰∏≠ÔºåË≥áÊñôÈö±ÁßÅÂíåÁ®ÄÂ∞ëÊÄßÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂª∫Ë≠∞Âà©Áî®ÂøÉÁêÜÂÅ•Â∫∑Â∞àÊ•≠Ê©üÊßã‰∏≠ÁèæÊàêÁöÑË™≤Á®ãÊïôÊùêÔºåÂ∞ç NLP ÁÆ°Á∑öÈÄ≤Ë°åÈ†êË®ìÁ∑¥„ÄÇÈÄôÊúâÂä©ÊñºÊàëÂÄëÊ®°Êì¨ÂøÉÁêÜÂ≠∏ÂÆ∂ÁöÑË®ìÁ∑¥ÈÅéÁ®ã„ÄÇÊàëÂÄëÁöÑ‰ΩúÂìÅÂ±ïÁ§∫‰∫Ü CASE-BERTÔºåÂÆÉÊ†πÊìöË´ñÂ£áÊñáÂ≠óÊ®ôË®òÊΩõÂú®ÁöÑÂøÉÁêÜÂÅ•Â∫∑ÈöúÁ§ô„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåCASE-BERT Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÂú®ÊÜÇÈ¨±ÁóáÊñπÈù¢ÈÅîÂà∞ 0.91 ÁöÑ f1 ÂàÜÊï∏ÔºåÂú®ÁÑ¶ÊÖÆÁóáÊñπÈù¢ÂâáÈÅîÂà∞ 0.88ÔºåÈÄôÂÖ©Á®ÆÊòØÊúÄÂ∏∏Ë¢´ÂõûÂ†±ÁöÑÂøÉÁêÜÂÅ•Â∫∑ÈöúÁ§ô„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨Èñã„ÄÇ

##### **Lightening Anything in Medical Images**
2406.10236v1 by Ben Fei, Yixuan Li, Weidong Yang, Hengjun Gao, Jingyi Xu, Lipeng Ma, Yatian Yang, Pinghong Zhou

The development of medical imaging techniques has made a significant
contribution to clinical decision-making. However, the existence of suboptimal
imaging quality, as indicated by irregular illumination or imbalanced
intensity, presents significant obstacles in automating disease screening,
analysis, and diagnosis. Existing approaches for natural image enhancement are
mostly trained with numerous paired images, presenting challenges in data
collection and training costs, all while lacking the ability to generalize
effectively. Here, we introduce a pioneering training-free Diffusion Model for
Universal Medical Image Enhancement, named UniMIE. UniMIE demonstrates its
unsupervised enhancement capabilities across various medical image modalities
without the need for any fine-tuning. It accomplishes this by relying solely on
a single pre-trained model from ImageNet. We conduct a comprehensive evaluation
on 13 imaging modalities and over 15 medical types, demonstrating better
qualities, robustness, and accuracy than other modality-specific and
data-inefficient models. By delivering high-quality enhancement and
corresponding accuracy downstream tasks across a wide range of tasks, UniMIE
exhibits considerable potential to accelerate the advancement of diagnostic
tools and customized treatment plans.

ÊëòË¶ÅÔºöÈÜ´Â≠∏ÂΩ±ÂÉèÊäÄË°ìÁöÑÁôºÂ±ïÁÇ∫Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂÅöÂá∫‰∫ÜÈáçÂ§ßË≤¢Áçª„ÄÇÁÑ∂ËÄåÔºåÊ¨°ÂÑ™ÂΩ±ÂÉèÂìÅË≥™ÁöÑÂ≠òÂú®Ôºå‰æãÂ¶Ç‰∏çË¶èÂâáÁÖßÊòéÊàñ‰∏çÂπ≥Ë°°Âº∑Â∫¶ÔºåÂú®Ëá™ÂãïÂåñÁñæÁóÖÁØ©Ê™¢„ÄÅÂàÜÊûêÂíåË®∫Êñ∑ÊñπÈù¢ÈÄ†Êàê‰∫ÜÈáçÂ§ßÈöúÁ§ô„ÄÇÁèæÊúâÁöÑËá™ÁÑ∂ÂΩ±ÂÉèÂ¢ûÂº∑ÊñπÊ≥ïÂ§ßÂ§ö‰ΩøÁî®Â§ßÈáèÈÖçÂ∞çÂΩ±ÂÉèÈÄ≤Ë°åË®ìÁ∑¥ÔºåÂú®Ë≥áÊñôÊî∂ÈõÜÂíåË®ìÁ∑¥ÊàêÊú¨ÊñπÈù¢Èù¢Ëá®ÊåëÊà∞ÔºåÂêåÊôÇÁº∫‰πèÊúâÊïàÊ≥õÂåñÁöÑËÉΩÂäõ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÈñãÂâµÊÄßÁöÑ„ÄÅÁÑ°ÈúÄË®ìÁ∑¥ÁöÑÊì¥Êï£Ê®°ÂûãÔºåÁî®ÊñºÈÄöÁî®ÈÜ´Â≠∏ÂΩ±ÂÉèÂ¢ûÂº∑ÔºåÂêçÁÇ∫ UniMIE„ÄÇUniMIE Â±ïÁ§∫‰∫ÜÂÆÉÂú®ÂêÑÁ®ÆÈÜ´Â≠∏ÂΩ±ÂÉèÊ®°Âºè‰∏ãÁÑ°Áõ£Áù£Â¢ûÂº∑ÁöÑËÉΩÂäõÔºåËÄåÁÑ°ÈúÄ‰ªª‰ΩïÂæÆË™ø„ÄÇÂÆÉÂÉÖ‰æùË≥¥Êñº ImageNet ‰∏≠È†êÂÖàË®ìÁ∑¥ÁöÑÂñÆ‰∏ÄÊ®°Âûã‰æÜÂØ¶ÁèæÈÄô‰∏ÄÈªû„ÄÇÊàëÂÄëÂ∞ç 13 Á®ÆÂΩ±ÂÉèÊ®°ÂºèÂíå 15 Á®Æ‰ª•‰∏äÁöÑÈÜ´Â≠∏È°ûÂûãÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢Ë©ï‰º∞ÔºåË≠âÊòé‰∫ÜÂÖ∂ÊØîÂÖ∂‰ªñÁâπÂÆöÊñºÊ®°ÂºèÂíåË≥áÊñôÊïàÁéá‰Ωé‰∏ãÁöÑÊ®°ÂûãÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÂìÅË≥™„ÄÅÁ©©ÂÅ•ÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÈÄèÈÅéÂú®Âª£Ê≥õÁöÑ‰ªªÂãô‰∏≠Êèê‰æõÈ´òÂìÅË≥™ÁöÑÂ¢ûÂº∑ÂíåÁõ∏ÊáâÁöÑÊ∫ñÁ¢∫ÊÄß‰∏ãÊ∏∏‰ªªÂãôÔºåUniMIE Â±ïÁ§∫‰∫ÜÂä†ÈÄüË®∫Êñ∑Â∑•ÂÖ∑ÂíåÂÆ¢Ë£ΩÂåñÊ≤ªÁôÇË®àÁï´ÈÄ≤Â±ïÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇ

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

ÊëòË¶ÅÔºöË™ûÈü≥ÊÉÖÁ∑íËæ®Ë≠ò (SER) Áî±ÊñºÂÖ∂Âú®ÂøÉÁêÜÂÅ•Â∫∑„ÄÅÊïôËÇ≤Âíå‰∫∫Ê©ü‰∫íÂãïÁ≠âÂ§öÂÄãÊáâÁî®È†òÂüüËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåSER Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄßÂèóÂà∞È´òÁ∂≠ÁâπÂæµÈõÜÁöÑÈòªÁ§ôÔºåÈÄô‰∫õÁâπÂæµÈõÜÂèØËÉΩÂåÖÂê´‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑË≥áË®ä„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî®Êñº SER ÁöÑËø≠‰ª£ÁâπÂæµÊèêÂçáÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂº∑Ë™øÁâπÂæµÁõ∏ÈóúÊÄßÂíåÂèØËß£ÈáãÊÄßÔºå‰ª•Â¢ûÂº∑Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèä‰ªîÁ¥∞ÁöÑÁâπÂæµÈÅ∏ÊìáÂíåÂàÜÊûêÔºå‰ª•Âª∫Á´ãÈ´òÊïàÁöÑ SER Á≥ªÁµ±„ÄÇÁÇ∫‰∫ÜÈÄèÈÅéÊ®°ÂûãÂèØËß£ÈáãÊÄßËß£Ê±∫ÊàëÂÄëÁöÑÊ†∏ÂøÉÂïèÈ°åÔºåÊàëÂÄëÊé°Áî®‰∫ÜÂÖ∑Êúâ Shapley ÂÄºÁöÑÁâπÂæµË©ï‰º∞Ëø¥ÂúàÔºå‰ª•ÂèçË¶ÜÊîπÂñÑÁâπÂæµÈõÜ„ÄÇÈÄôÂÄãÈÅéÁ®ãÂú®Ê®°ÂûãÊïàËÉΩÂíåÈÄèÊòéÂ∫¶‰πãÈñìÂèñÂæóÂπ≥Ë°°ÔºåÈÄô‰ΩøÂæóÊàëÂÄëËÉΩÂ§†ÂÖ®Èù¢‰∫ÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ§öÈ†ÖÂÑ™ÈªûÔºåÂåÖÊã¨Ë≠òÂà•ÂíåÁßªÈô§‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑÁâπÂæµÔºåÂæûËÄåÂª∫Á´ãÊõ¥ÊúâÊïàÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰øÉÈÄ≤‰∫ÜÂèØËß£ÈáãÊÄßÔºåÊúâÂä©ÊñºÁêÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨‰ª•ÂèäË≠òÂà•ÊÉÖÁ∑íÊ±∫ÂÆöÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂ∑≤Âú®Â§öÂÄ´Â§öÊÉÖÁ∑íË™ûÈü≥ÈõÜ (TESS)„ÄÅÊüèÊûóÊÉÖÁ∑íË™ûÈü≥Ë≥áÊñôÂ∫´ (EMO-DB)„ÄÅË≥¥ÁàæÊ£ÆÈü≥Ë®äË¶ñË¶∫ÊÉÖÁ∑íË™ûÈü≥ÂíåÊ≠åÊõ≤Ë≥áÊñôÂ∫´ (RAVDESS) ÂíåËñ©ÈáåÈü≥Ë®äË¶ñË¶∫Ë°®ÈÅîÊÉÖÁ∑í (SAVEE) Ë≥áÊñôÈõÜÁöÑ SER Âü∫Ê∫ñ‰∏äÂæóÂà∞È©óË≠âÔºåÂÖ∂ÊïàËÉΩÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áÊ®°ÂûãÂèØËß£ÈáãÊÄßÁ¥çÂÖ• SER Êû∂ÊßãÁöÑÁ†îÁ©∂„ÄÇÊú¨ÊñáÁöÑÂéüÂßãÁ¢ºÂèØÈÄèÈÅéÊ≠§ÈÄ£ÁµêÂÖ¨ÈñãÂèñÂæóÔºöhttps://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition„ÄÇ

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, H√©lo√Øse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

ÊëòË¶ÅÔºöÂèØËß£ÈáäÊÄßÈÄöÂ∏∏ÂØπ‰∫é‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÂèØÊé•ÂèóÂÆûÊñΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÔºåËøô‰∏ÄÁÇπÂ∞§‰∏∫ÈáçË¶ÅÔºåÂõ†‰∏∫ÂÜ≥Á≠ñÁõ¥Êé•ÂΩ±ÂìçÊÇ£ËÄÖÔºåÂπ∂‰∏îÂØπ AI Á≥ªÁªüÁöÑ‰ø°‰ªªËá≥ÂÖ≥ÈáçË¶Å„ÄÇËøôÁßç‰ø°‰ªªÈÄöÂ∏∏Âª∫Á´ãÂú® AI Êèê‰æõÁöÑËß£ÈáäÂíåËØ†Èáä‰πã‰∏ä„ÄÇÂ∞ΩÁÆ° AI ÂèØËß£ÈáäÊÄßÂèñÂæó‰∫ÜÈáçÂ§ßËøõÂ±ïÔºå‰ΩÜ‰ªçÁÑ∂ÈúÄË¶ÅÊòéÁ°ÆÁöÑÊåáÂØºÊñπÈíàÔºåËØ¥ÊòéÂú®ÂåªÁñóÁéØÂ¢É‰∏≠‰ΩïÊó∂‰ª•ÂèäÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÈúÄË¶ÅËß£Èáä„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂàÜÁ±ªÁ≥ªÁªüÔºåËØ•Á≥ªÁªüÂÖ∑ÊúâÂõõÁßç‰∏çÂêåÁöÑËß£ÈáäÂøÖË¶ÅÊÄßÁ±ªÂà´ÔºåÊåáÂØºÊâÄÈúÄÁöÑËß£ÈáäÁ∫ßÂà´ÔºöÊÇ£ËÄÖÊàñÊ†∑Êú¨ÔºàÂ±ÄÈÉ®ÔºâÁ∫ßÂà´„ÄÅÈòüÂàóÊàñÊï∞ÊçÆÈõÜÔºàÂÖ®Â±ÄÔºâÁ∫ßÂà´ÔºåÊàñ‰∏§‰∏™Á∫ßÂà´„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êï∞Â≠¶ÂÖ¨ÂºèÔºåËØ•ÂÖ¨ÂºèÂå∫ÂàÜ‰∫ÜËøô‰∫õÁ±ªÂà´ÔºåÂπ∂‰∏∫Á†îÁ©∂‰∫∫ÂëòÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÆûÁî®Ê°ÜÊû∂Ôºå‰ª•Á°ÆÂÆöÂåªÁñó AI Â∫îÁî®‰∏≠ÊâÄÈúÄÁöÑËß£ÈáäÁöÑÂøÖË¶ÅÊÄßÂíåÊ∑±Â∫¶„ÄÇËÄÉËôë‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÂõ†Á¥†ÔºöËØÑ‰º∞ÂçèËÆÆÁöÑÁ®≥ÂÅ•ÊÄß„ÄÅ‰∏ìÂÆ∂ËßÇÂØüÁöÑÂèØÂèòÊÄß‰ª•ÂèäÂ∫îÁî®Á®ãÂ∫èÁöÑË°®Á§∫Áª¥Êï∞„ÄÇ‰ªéËøô‰∏™ËßíÂ∫¶Êù•ÁúãÔºåÊàë‰ª¨Ëß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºöAI ÂåªÁñóÂ∫îÁî®‰ΩïÊó∂ÈúÄË¶ÅËß£ÈáäÔºå‰ª•ÂèäÈúÄË¶ÅËß£ÈáäÂà∞‰ΩïÁßçÁ®ãÂ∫¶Ôºü

##### **DYNA: Disease-Specific Language Model for Variant Pathogenicity**
2406.00164v1 by Huixin Zhan, Zijun Zhang

Clinical variant classification of pathogenic versus benign genetic variants
remains a challenge in clinical genetics. Recently, the proposition of genomic
foundation models has improved the generic variant effect prediction (VEP)
accuracy via weakly-supervised or unsupervised training. However, these VEPs
are not disease-specific, limiting their adaptation at the point of care. To
address this problem, we propose DYNA: Disease-specificity fine-tuning via a
Siamese neural network broadly applicable to all genomic foundation models for
more effective variant effect predictions in disease-specific contexts. We
evaluate DYNA in two distinct disease-relevant tasks. For coding VEPs, we focus
on various cardiovascular diseases, where gene-disease relationships of
loss-of-function vs. gain-of-function dictate disease-specific VEP. For
non-coding VEPs, we apply DYNA to an essential post-transcriptional regulatory
axis of RNA splicing, the most common non-coding pathogenic mechanism in
established clinical VEP guidelines. In both cases, DYNA fine-tunes various
pre-trained genomic foundation models on small, rare variant sets. The DYNA
fine-tuned models show superior performance in the held-out rare variant
testing set and are further replicated in large, clinically-relevant variant
annotations in ClinVAR. Thus, DYNA offers a potent disease-specific variant
effect prediction method, excelling in intra-gene generalization and
generalization to unseen genetic variants, making it particularly valuable for
disease associations and clinical applicability.

ÊëòË¶ÅÔºöËá®Â∫äÈÅ∫ÂÇ≥Â≠∏‰∏≠ÔºåËá¥ÁóÖÊÄßÈÅ∫ÂÇ≥ËÆäÁï∞ËàáËâØÊÄßÈÅ∫ÂÇ≥ËÆäÁï∞ÁöÑËá®Â∫äËÆäÁï∞ÂàÜÈ°û‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÊúÄËøëÔºåÂü∫Âõ†È´îÂü∫Á§éÊ®°ÂûãÁöÑÊèêË≠∞ÈÄèÈÅéÂº±Áõ£Áù£ÊàñÁÑ°Áõ£Áù£Ë®ìÁ∑¥ÊîπÂñÑ‰∫ÜÈÄöÁî®ËÆäÁï∞ÊïàÊáâÈ†êÊ∏¨ (VEP) ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ VEP Ê≤íÊúâÁñæÁóÖÁâπÁï∞ÊÄßÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®ÁÖßË≠∑ÈªûÁöÑÈÅ©ÊáâÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü DYNAÔºöÈÄèÈÅé Siamese Á•ûÁ∂ìÁ∂≤Ë∑ØÈÄ≤Ë°åÁñæÁóÖÁâπÁï∞ÊÄßÂæÆË™øÔºåÂª£Ê≥õÈÅ©Áî®ÊñºÊâÄÊúâÂü∫Âõ†È´îÂü∫Á§éÊ®°ÂûãÔºå‰ª•Âú®ÁñæÁóÖÁâπÁï∞ÊÄßËÉåÊôØ‰∏≠ÈÄ≤Ë°åÊõ¥ÊúâÊïàÁöÑËÆäÁï∞ÊïàÊáâÈ†êÊ∏¨„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄã‰∏çÂêåÁöÑÁñæÁóÖÁõ∏Èóú‰ªªÂãô‰∏≠Ë©ï‰º∞ DYNA„ÄÇÂ∞çÊñºÁ∑®Á¢º VEPÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂêÑÁ®ÆÂøÉË°ÄÁÆ°ÁñæÁóÖÔºåÂÖ∂‰∏≠Ëá¥ÁóÖÊÄßËàáÂäüËÉΩÁç≤Âæó‰πãÈñìÁöÑÂü∫Âõ†ÁñæÁóÖÈóú‰øÇÊ±∫ÂÆö‰∫ÜÁñæÁóÖÁâπÁï∞ÊÄß VEP„ÄÇÂ∞çÊñºÈùûÁ∑®Á¢º VEPÔºåÊàëÂÄëÂ∞á DYNA ÊáâÁî®Êñº RNA Ââ™Êé•ÁöÑÂü∫Êú¨ËΩâÈåÑÂæåË™øÊéßËª∏ÔºåÈÄôÊòØÂ∑≤Âª∫Á´ãÁöÑËá®Â∫ä VEP ÊåáÂçó‰∏≠ÊúÄÂ∏∏Ë¶ãÁöÑÈùûÁ∑®Á¢ºËá¥ÁóÖÊ©üÂà∂„ÄÇÂú®ÂÖ©Á®ÆÊÉÖÊ≥Å‰∏ãÔºåDYNA ÈÉΩÂæÆË™ø‰∫ÜÂêÑÁ®ÆÈ†êË®ìÁ∑¥ÁöÑÂü∫Âõ†È´îÂü∫Á§éÊ®°ÂûãÔºåÈáùÂ∞çÂ∞èÂûã„ÄÅÁΩïË¶ãÁöÑËÆäÁï∞ÁµÑ„ÄÇDYNA ÂæÆË™øÊ®°ÂûãÂú®‰øùÁïôÁöÑÁΩïË¶ãËÆäÁï∞Ê∏¨Ë©¶ÁµÑ‰∏≠Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Ë§áË£ΩÊñº ClinVAR ‰∏≠Â§ßÂûã„ÄÅËá®Â∫ä‰∏äÁõ∏ÈóúÁöÑËÆäÁï∞Ë®ªËß£„ÄÇÂõ†Ê≠§ÔºåDYNA Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÊïàÁöÑÁñæÁóÖÁâπÁï∞ÊÄßËÆäÁï∞ÊïàÊáâÈ†êÊ∏¨ÊñπÊ≥ïÔºåÂú®Âü∫Âõ†ÂÖßÊ¶ÇÂåñÂíåÂ∞çÊú™Ë¶ãÈÅ∫ÂÇ≥ËÆäÁï∞ÁöÑÊ¶ÇÂåñÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩøÂÖ∂Â∞çÊñºÁñæÁóÖÈóúËÅØÂíåËá®Â∫äÊáâÁî®ÁâπÂà•ÊúâÂÉπÂÄº„ÄÇ

##### **Recurrent neural networks: vanishing and exploding gradients are not the end of the story**
2405.21064v1 by Nicolas Zucchet, Antonio Orvieto

Recurrent neural networks (RNNs) notoriously struggle to learn long-term
memories, primarily due to vanishing and exploding gradients. The recent
success of state-space models (SSMs), a subclass of RNNs, to overcome such
difficulties challenges our theoretical understanding. In this paper, we delve
into the optimization challenges of RNNs and discover that, as the memory of a
network increases, changes in its parameters result in increasingly large
output variations, making gradient-based learning highly sensitive, even
without exploding gradients. Our analysis further reveals the importance of the
element-wise recurrence design pattern combined with careful parametrizations
in mitigating this effect. This feature is present in SSMs, as well as in other
architectures, such as LSTMs. Overall, our insights provide a new explanation
for some of the difficulties in gradient-based learning of RNNs and why some
architectures perform better than others.

ÊëòË¶ÅÔºöÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑Ø (RNN) ÊÉ°ÂêçÊò≠ÂΩ∞Âú∞Èõ£‰ª•Â≠∏ÁøíÈï∑ÊúüË®òÊÜ∂Ôºå‰∏ªË¶ÅÊòØÁî±ÊñºÊ∂àÂ§±ÂíåÁàÜÁÇ∏Ê¢ØÂ∫¶„ÄÇÊúÄËøëÔºå‰ΩúÁÇ∫ RNN Â≠êÈ°ûÁöÑÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (SSM) Âú®ÂÖãÊúçÊ≠§È°ûÂõ∞Èõ£ÊñπÈù¢Áç≤ÂæóÊàêÂäüÔºåÈÄôÊåëÊà∞‰∫ÜÊàëÂÄëÁöÑÁêÜË´ñÁêÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®é RNN ÁöÑÊúÄ‰Ω≥ÂåñÊåëÊà∞Ôºå‰∏¶ÁôºÁèæÈö®ËëóÁ∂≤Ë∑ØË®òÊÜ∂ÁöÑÂ¢ûÂä†ÔºåÂÖ∂ÂèÉÊï∏ÁöÑËÆäÂåñÊúÉÂ∞éËá¥Ë∂ä‰æÜË∂äÂ§ßÁöÑËº∏Âá∫ËÆäÂåñÔºå‰ΩøÂæóÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÂ≠∏ÁøíÈ´òÂ∫¶ÊïèÊÑüÔºåÂç≥‰ΩøÊ≤íÊúâÁàÜÁÇ∏Ê¢ØÂ∫¶„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈÄ≤‰∏ÄÊ≠•Êè≠Á§∫‰∫ÜÈÄêÂÖÉÁ¥†ÈÅûËø¥Ë®≠Ë®àÊ®°ÂºèËàá‰ªîÁ¥∞ÂèÉÊï∏ÂåñÁõ∏ÁµêÂêàÂú®Ê∏õËºïÊ≠§ÊïàÊáâÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§ÂäüËÉΩÂ≠òÂú®Êñº SSM ‰ª•ÂèäÂÖ∂‰ªñÊû∂Êßã‰∏≠Ôºå‰æãÂ¶Ç LSTM„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁöÑË¶ãËß£ÁÇ∫ RNN Âü∫ÊñºÊ¢ØÂ∫¶ÁöÑÂ≠∏Áøí‰∏≠ÁöÑ‰∏Ä‰∫õÂõ∞Èõ£Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑËß£ÈáãÔºå‰∏¶Ë™™Êòé‰∫ÜÁÇ∫‰ªÄÈ∫ºÊüê‰∫õÊû∂ÊßãÁöÑË°®ÁèæÂÑ™ÊñºÂÖ∂‰ªñÊû∂Êßã„ÄÇ

##### **Generative Adversarial Networks in Ultrasound Imaging: Extending Field of View Beyond Conventional Limits**
2405.20981v1 by Matej Gazda, Samuel Kadoury, Jakub Gazda, Peter Drotar

Transthoracic Echocardiography (TTE) is a fundamental, non-invasive
diagnostic tool in cardiovascular medicine, enabling detailed visualization of
cardiac structures crucial for diagnosing various heart conditions. Despite its
widespread use, TTE ultrasound imaging faces inherent limitations, notably the
trade-off between field of view (FoV) and resolution. This paper introduces a
novel application of conditional Generative Adversarial Networks (cGANs),
specifically designed to extend the FoV in TTE ultrasound imaging while
maintaining high resolution. Our proposed cGAN architecture, termed echoGAN,
demonstrates the capability to generate realistic anatomical structures through
outpainting, effectively broadening the viewable area in medical imaging. This
advancement has the potential to enhance both automatic and manual ultrasound
navigation, offering a more comprehensive view that could significantly reduce
the learning curve associated with ultrasound imaging and aid in more accurate
diagnoses. The results confirm that echoGAN reliably reproduce detailed cardiac
features, thereby promising a significant step forward in the field of
non-invasive cardiac naviagation and diagnostics.

ÊëòË¶ÅÔºöÁ∂ìËÉ∏Ë∂ÖÈü≥Ê≥¢ÂøÉËáüÂúñ (TTE) ÊòØÂøÉË°ÄÁÆ°ÈÜ´Â≠∏‰∏≠ÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨Èùû‰æµÂÖ•ÊÄßË®∫Êñ∑Â∑•ÂÖ∑ÔºåËÉΩË©≥Á¥∞Ë¶ñË¶∫ÂåñÂøÉËáüÁµêÊßãÔºåÂ∞çÊñºË®∫Êñ∑ÂêÑÁ®ÆÂøÉËáüÁñæÁóÖËá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ° TTE Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂª£Ê≥õ‰ΩøÁî®Ôºå‰ΩÜÂÆÉÈù¢Ëá®ËëóÂõ∫ÊúâÁöÑÈôêÂà∂ÔºåÁâπÂà•ÊòØÂú®Ë¶ñÈáé (FoV) ÂíåËß£ÊûêÂ∫¶‰πãÈñìÁöÑÊ¨äË°°„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊ¢ù‰ª∂ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (cGANs) ÁöÑÊñ∞ÊáâÁî®ÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÊì¥Â±ï TTE Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑË¶ñÈáéÔºåÂêåÊôÇ‰øùÊåÅÈ´òËß£ÊûêÂ∫¶„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑ cGAN Êû∂ÊßãÁ®±ÁÇ∫ echoGANÔºåÂÆÉÂ±ïÁ§∫‰∫ÜÈÄèÈÅéÂ§ñÁπ™‰æÜÁîüÊàêÈÄºÁúüÁöÑËß£ÂâñÁµêÊßãÁöÑËÉΩÂäõÔºåÊúâÊïàÂú∞Êì¥Â±ï‰∫ÜÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÂèØË¶ñÂçÄÂüü„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïÊúâÂèØËÉΩÂ¢ûÂº∑Ëá™ÂãïÂíåÊâãÂãïË∂ÖÈü≥Ê≥¢Â∞éËà™ÔºåÊèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑË¶ñÈáéÔºåÈÄôÂèØ‰ª•Â§ßÂπÖÁ∏ÆÁü≠ËàáË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁõ∏ÈóúÁöÑÂ≠∏ÁøíÊõ≤Á∑öÔºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∫ñÁ¢∫ÁöÑË®∫Êñ∑„ÄÇÁµêÊûúË≠âÂØ¶ÔºåechoGAN ÂèØÈù†Âú∞ÈáçÁèæË©≥Á¥∞ÁöÑÂøÉËáüÁâπÂæµÔºåÂæûËÄåÊúâÊúõÂú®Èùû‰æµÂÖ•ÊÄßÂøÉËáüÂ∞éËà™ÂíåË®∫Êñ∑È†òÂüüÈÇÅÂá∫ÈáçË¶Å‰∏ÄÊ≠•„ÄÇ

##### **OR-Bench: An Over-Refusal Benchmark for Large Language Models**
2405.20947v1 by Justin Cui, Wei-Lin Chiang, Ion Stoica, Cho-Jui Hsieh

Large Language Models (LLMs) require careful safety alignment to prevent
malicious outputs. While significant research focuses on mitigating harmful
content generation, the enhanced safety often come with the side effect of
over-refusal, where the LLMs may reject innocuous prompts and become less
helpful. Although the issue of over-refusal has been empirically observed, a
systematic measurement is challenging due to the difficulty of crafting prompts
that appear harmful but are benign. This study proposes a novel method for
automatically generating large-scale sets of ``seemingly toxic prompts''
(benign prompts likely rejected by LLMs). Leveraging this technique, we
introduce OR-Bench, the first large-scale over-refusal benchmark. OR-Bench
comprises 80,000 seemingly toxic prompts across 10 common rejection categories,
a subset of around 1,000 hard prompts that are challenging even for
state-of-the-art LLMs, and an additional 600 toxic prompts to prevent
indiscriminate responses. We then conduct a comprehensive study to measure the
over-refusal of 25 popular LLMs across 8 model families. Our datasets are
available at https://huggingface.co/datasets/bench-llm/OR-Bench and the
corresponding demo can be found at
https://huggingface.co/spaces/bench-llm/or-bench. We hope this benchmark can
help the community develop better safety aligned models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈúÄË¶ÅË¨πÊÖéÁöÑÂÆâÂÖ®Ë™øÊï¥Ôºå‰ª•Èò≤Ê≠¢ÊÉ°ÊÑèËº∏Âá∫„ÄÇÈõñÁÑ∂ÈáçË¶ÅÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÊ∏õËºïÊúâÂÆ≥ÂÖßÂÆπÁöÑÁî¢ÁîüÔºå‰ΩÜÂ¢ûÂº∑ÁöÑÂÆâÂÖ®ÈÄöÂ∏∏ÊúÉÁî¢ÁîüÈÅéÂ∫¶ÊãíÁµïÁöÑÂâØ‰ΩúÁî®ÔºåLLM ÂèØËÉΩÊãíÁµïÁÑ°ÂÆ≥ÁöÑÊèêÁ§∫‰∏¶ËÆäÂæó‰∏çÈÇ£È∫ºÊúâÂπ´Âä©„ÄÇÂÑòÁÆ°Â∑≤Á∂ìÁ∂ìÈ©óÊÄßÂú∞ËßÄÂØüÂà∞ÈÅéÂ∫¶ÊãíÁµïÁöÑÂïèÈ°åÔºå‰ΩÜÁî±ÊñºÈõ£‰ª•Êí∞ÂØ´Áúã‰ººÊúâÂÆ≥‰ΩÜËâØÊÄßÁöÑÊèêÁ§∫ÔºåÂõ†Ê≠§Á≥ªÁµ±ÊÄßÁöÑÊ∏¨ÈáèÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËá™ÂãïÁî¢ÁîüÂ§ßÈáè„ÄåÁúã‰ººÊúâÊØíÁöÑÊèêÁ§∫„ÄçÈõÜÂêàÔºàÂèØËÉΩË¢´ LLM ÊãíÁµïÁöÑËâØÊÄßÊèêÁ§∫ÔºâÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂà©Áî®Ê≠§ÊäÄË°ìÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü OR-BenchÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÈÅéÂ∫¶ÊãíÁµïÂü∫Ê∫ñ„ÄÇOR-Bench ÂåÖÂê´ 10 ÂÄãÂ∏∏Ë¶ãÊãíÁµïÈ°ûÂà•‰∏≠ÁöÑ 80,000 ÂÄãÁúã‰ººÊúâÊØíÁöÑÊèêÁ§∫Ôºå‰∏ÄÂÄãÁî±Á¥Ñ 1,000 ÂÄãÂç≥‰ΩøÂ∞çÊñºÊúÄÂÖàÈÄ≤ÁöÑ LLM ‰æÜË™™‰πüÂæàÊúâÊåëÊà∞ÊÄßÁöÑÂõ∞Èõ£ÊèêÁ§∫Â≠êÈõÜÔºå‰ª•ÂèäÈ°çÂ§ñÁöÑ 600 ÂÄãÊúâÊØíÊèêÁ§∫Ôºå‰ª•Èò≤Ê≠¢‰∏çÂä†ÂçÄÂà•ÁöÑÂõûÊáâ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢Á†îÁ©∂Ôºå‰ª•Ê∏¨Èáè 8 ÂÄãÊ®°ÂûãÁ≥ªÂàó‰∏≠ÁöÑ 25 ÂÄãÊµÅË°å LLM ÁöÑÈÅéÂ∫¶ÊãíÁµï„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÂèØÂú® https://huggingface.co/datasets/bench-llm/OR-Bench Áç≤ÂæóÔºåÂèØ‰ª•Âú® https://huggingface.co/spaces/bench-llm/or-bench ÊâæÂà∞Â∞çÊáâÁöÑÁ§∫ÁØÑ„ÄÇÊàëÂÄëÂ∏åÊúõÊ≠§Âü∫Ê∫ñÂèØ‰ª•Âπ´Âä©Á§æÁæ§ÈñãÁôºÊõ¥Â•ΩÁöÑÂÆâÂÖ®Ë™øÊï¥Ê®°Âûã„ÄÇ

##### **ABodyBuilder3: Improved and scalable antibody structure predictions**
2405.20863v1 by Henry Kenlay, Fr√©d√©ric A. Dreyer, Daniel Cutting, Daniel Nissley, Charlotte M. Deane

Accurate prediction of antibody structure is a central task in the design and
development of monoclonal antibodies, notably to understand both their
developability and their binding properties. In this article, we introduce
ABodyBuilder3, an improved and scalable antibody structure prediction model
based on ImmuneBuilder. We achieve a new state-of-the-art accuracy in the
modelling of CDR loops by leveraging language model embeddings, and show how
predicted structures can be further improved through careful relaxation
strategies. Finally, we incorporate a predicted Local Distance Difference Test
into the model output to allow for a more accurate estimation of uncertainties.

ÊëòË¶ÅÔºöÁ≤æÊ∫ñÈ†êÊ∏¨ÊäóÈ´îÁµêÊßãÊòØÂñÆÊ†™ÊäóÈ´îË®≠Ë®àÂíåÈñãÁôº‰∏≠ÁöÑÊ†∏ÂøÉ‰ªªÂãôÔºåÁâπÂà•ÊòØÁÇ∫‰∫Ü‰∫ÜËß£ÂÆÉÂÄëÁöÑÂèØÈñãÁôºÊÄßÂíåÁµêÂêàÁâπÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü ABodyBuilder3ÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Êñº ImmuneBuilder ÁöÑÊîπËâØ‰∏îÂèØÊì¥ÂÖÖÁöÑÊäóÈ´îÁµêÊßãÈ†êÊ∏¨Ê®°Âûã„ÄÇÊàëÂÄëÈÄèÈÅéÂà©Áî®Ë™ûË®ÄÊ®°ÂûãÂµåÂÖ•ÔºåÂú® CDR Ëø¥ÂúàÂª∫Ê®°‰∏≠ÈÅîÂà∞‰∫ÜÊñ∞ÁöÑÊúÄÂÖàÈÄ≤Ê∫ñÁ¢∫Â∫¶Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄèÈÅéË¨πÊÖéÁöÑÊîæÈ¨ÜÁ≠ñÁï•ÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑÈ†êÊ∏¨ÁµêÊßã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞áÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ë∑ùÈõ¢Â∑ÆÁï∞Ê∏¨Ë©¶Á¥çÂÖ•Ê®°ÂûãËº∏Âá∫Ôºå‰ª•Êõ¥Ê∫ñÁ¢∫Âú∞‰º∞Ë®à‰∏çÁ¢∫ÂÆöÊÄß„ÄÇ

##### **Maximum Temperature Prediction Using Remote Sensing Data Via Convolutional Neural Network**
2405.20731v1 by Lorenzo Innocenti, Giacomo Blanco, Luca Barco, Claudio Rossi

Urban heat islands, defined as specific zones exhibiting substantially higher
temperatures than their immediate environs, pose significant threats to
environmental sustainability and public health. This study introduces a novel
machine-learning model that amalgamates data from the Sentinel-3 satellite,
meteorological predictions, and additional remote sensing inputs. The primary
aim is to generate detailed spatiotemporal maps that forecast the peak
temperatures within a 24-hour period in Turin. Experimental results validate
the model's proficiency in predicting temperature patterns, achieving a Mean
Absolute Error (MAE) of 2.09 degrees Celsius for the year 2023 at a resolution
of 20 meters per pixel, thereby enriching our knowledge of urban climatic
behavior. This investigation enhances the understanding of urban microclimates,
emphasizing the importance of cross-disciplinary data integration, and laying
the groundwork for informed policy-making aimed at alleviating the negative
impacts of extreme urban temperatures.

ÊëòË¶ÅÔºöÈÉΩÂ∏ÇÁÜ±Â≥∂ÊïàÊáâÊòØÊåáÁâπÂÆöÂçÄÂüüÁöÑÊ∫´Â∫¶ÊòéÈ°ØÈ´òÊñºÂë®ÂúçÁí∞Â¢ÉÔºåÂ∞çÁí∞Â¢ÉÊ∞∏Á∫åÊÄßËàáÂÖ¨ÂÖ±ÂÅ•Â∫∑ÈÄ†ÊàêÈáçÂ§ßÂ®ÅËÑÖ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÁµêÂêà Sentinel-3 Ë°õÊòü„ÄÅÊ∞£Ë±°È†êÊ∏¨ÂíåÈ°çÂ§ñÈÅôÊ∏¨Ëº∏ÂÖ•ÁöÑË≥áÊñô„ÄÇ‰∏ªË¶ÅÁõÆÁöÑÊòØÁî¢ÁîüË©≥Á¥∞ÁöÑÊôÇÁ©∫Âú∞ÂúñÔºåÈ†êÊ∏¨ÈÉΩÈùà 24 Â∞èÊôÇÂÖßÁöÑÊúÄÈ´òÊ∫´Â∫¶„ÄÇÂØ¶È©óÁµêÊûúÈ©óË≠â‰∫ÜÊ®°ÂûãÂú®È†êÊ∏¨Ê∫´Â∫¶Ê®°ÂºèÊñπÈù¢ÁöÑÁÜüÁ∑¥Â∫¶ÔºåÂú® 2023 Âπ¥‰ª•ÊØèÂÉèÁ¥† 20 ÂÖ¨Â∞∫Ëß£ÊûêÂ∫¶ÈÅîÂà∞ 2.09 Â∫¶ÊîùÊ∞èÁöÑÂπ≥ÂùáÁµïÂ∞çË™§Â∑Æ (MAE)ÔºåÂæûËÄåË±êÂØå‰∫ÜÊàëÂÄëÂ∞çÈÉΩÂ∏ÇÊ∞£ÂÄôË°åÁÇ∫ÁöÑË™çË≠ò„ÄÇÊ≠§Á†îÁ©∂Â¢ûÂº∑‰∫ÜÂ∞çÈÉΩÂ∏ÇÂæÆÊ∞£ÂÄôÁöÑ‰∫ÜËß£ÔºåÂº∑Ë™øË∑®È†òÂüüË≥áÊñôÊï¥ÂêàÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶ÁÇ∫Êó®Âú®Ê∏õËºïÊ•µÁ´ØÈÉΩÂ∏ÇÊ∫´Â∫¶Ë≤†Èù¢ÂΩ±ÈüøÁöÑÊòéÊô∫ÊîøÁ≠ñÂà∂ÂÆöÂ•†ÂÆöÂü∫Á§é„ÄÇ

##### **GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models**
2405.20585v1 by Mohammed-Khalil Ghali, Abdelrahman Farrag, Hajar Sakai, Hicham El Baz, Yu Jin, Sarah Lam

In the rapidly evolving field of healthcare and beyond, the integration of
generative AI in Electronic Health Records (EHRs) represents a pivotal
advancement, addressing a critical gap in current information extraction
techniques. This paper introduces GAMedX, a Named Entity Recognition (NER)
approach utilizing Large Language Models (LLMs) to efficiently extract entities
from medical narratives and unstructured text generated throughout various
phases of the patient hospital visit. By addressing the significant challenge
of processing unstructured medical text, GAMedX leverages the capabilities of
generative AI and LLMs for improved data extraction. Employing a unified
approach, the methodology integrates open-source LLMs for NER, utilizing
chained prompts and Pydantic schemas for structured output to navigate the
complexities of specialized medical jargon. The findings reveal significant
ROUGE F1 score on one of the evaluation datasets with an accuracy of 98\%. This
innovation enhances entity extraction, offering a scalable, cost-effective
solution for automated forms filling from unstructured data. As a result,
GAMedX streamlines the processing of unstructured narratives, and sets a new
standard in NER applications, contributing significantly to theoretical and
practical advancements beyond the medical technology sphere.

ÊëòË¶ÅÔºöÂú®Âø´ÈÄüÂèëÂ±ïÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÂèäÂÖ∂‰ªñÈ†òÂüü‰∏≠ÔºåÁîüÊàêÂºè AI Êï¥ÂêàÂà∞ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰∏≠‰ª£Ë°®ËëóÈóúÈçµÈÄ≤Â±ïÔºåËß£Ê±∫‰∫ÜÁï∂ÂâçË≥áË®äÊì∑ÂèñÊäÄË°ì‰∏≠ÁöÑÈáçÂ§ßÂ∑ÆË∑ù„ÄÇÊú¨Êñá‰ªãÁ¥π GAMedXÔºå‰∏ÄÁ®ÆÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (NER) ÊñπÊ≥ïÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæûÈÜ´ÁôÇÊïòËø∞ÂíåÊÇ£ËÄÖÈÜ´Èô¢Â∞±Ë®∫ÂêÑÂÄãÈöéÊÆµÁî¢ÁîüÁöÑÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠ÊúâÊïàÁéáÂú∞Êì∑ÂèñÂØ¶È´î„ÄÇÈÄèÈÅéËß£Ê±∫ËôïÁêÜÈùûÁµêÊßãÂåñÈÜ´ÁôÇÊñáÂ≠óÁöÑÈáçÂ§ßÊåëÊà∞ÔºåGAMedX ÂÖÖÂàÜÂà©Áî®ÁîüÊàêÂºè AI Âíå LLM ÁöÑËÉΩÂäõÔºå‰ª•ÊîπÂñÑË≥áÊñôÊì∑Âèñ„ÄÇÊé°Áî®Áµ±‰∏ÄÊñπÊ≥ïÔºåÊ≠§ÊñπÊ≥ïÊï¥ÂêàÈñãÊîæÂéüÂßãÁ¢º LLM ‰ª•ÈÄ≤Ë°å NERÔºåÂà©Áî®‰∏≤ÈÄ£ÊèêÁ§∫Âíå Pydantic Êû∂ÊßãÈÄ≤Ë°åÁµêÊßãÂåñËº∏Âá∫Ôºå‰ª•ÊáâÂ∞çÂ∞àÊ•≠ÈÜ´ÁôÇË°ìË™ûÁöÑË§áÈõúÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÂú®ÂÖ∂‰∏≠‰∏ÄÂÄãË©ïÈáèË≥áÊñôÈõÜ‰∏äÔºåROUGE F1 ÂæóÂàÜÈ°ØËëóÔºåÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 98%„ÄÇÈÄôÈ†ÖÂâµÊñ∞Â¢ûÂº∑‰∫ÜÂØ¶È´îÊì∑ÂèñÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ„ÄÅÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºÂæûÈùûÁµêÊßãÂåñË≥áÊñô‰∏≠Ëá™ÂãïÂ°´ÂØ´Ë°®Ê†º„ÄÇÂõ†Ê≠§ÔºåGAMedX Á∞°Âåñ‰∫ÜÈùûÁµêÊßãÂåñÊïòËø∞ÁöÑËôïÁêÜÔºå‰∏¶Âú® NER ÊáâÁî®Á®ãÂºè‰∏≠Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÊ®ôÊ∫ñÔºåÁÇ∫ÈÜ´ÁôÇÊäÄË°ìÈ†òÂüü‰πãÂ§ñÁöÑÁêÜË´ñÂíåÂØ¶ÂãôÈÄ≤Â±ïÂÅöÂá∫‰∫ÜÈáçÂ§ßË≤¢Áçª„ÄÇ

##### **The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes**
2405.20582v1 by Alissa A. Valentine, Lauren A. Lepow, Alexander W. Charney, Isotta Landi

In psychiatry, negative patient descriptions and stigmatizing language can
contribute to healthcare disparities in two ways: (1) read by patients they can
harm their trust and engagement with the medical center; (2) read by future
providers they may negatively influence the future perspective of a patient. By
leveraging large language models, this work aims to identify the sentiment
expressed in psychiatric clinical notes based on the reader's point of view.
Extracting sentences from the Mount Sinai Health System's large and diverse
clinical notes, we used prompts and in-context learning to adapt three large
language models (GPT-3.5, Llama 2, Mistral) to classify the sentiment conveyed
by the sentences according to the provider or non-provider point of view.
Results showed that GPT-3.5 aligns best to provider point of view, whereas
Mistral aligns best to non-provider point of view.

ÊëòË¶ÅÔºöÂú®Á≤æÁ•ûÁóÖÂ≠∏‰∏≠ÔºåË≤†Èù¢ÁöÑÁóÖ‰∫∫ÊèèËø∞ÂíåÊ±°ÂêçÂåñÁöÑË™ûË®ÄÂèØËÉΩÈÄèÈÅéÂÖ©Á®ÆÊñπÂºèÈÄ†ÊàêÈÜ´ÁôÇ‰øùÂÅ•Â∑ÆÁï∞Ôºö(1) ÁóÖ‰∫∫ËÆÄÂà∞ÂæåÊúÉÊêçÂÆ≥‰ªñÂÄëÂ∞çÈÜ´ÁôÇ‰∏≠ÂøÉÁöÑ‰ø°‰ªªÂíåÂèÉËàáÔºõ(2) Êú™‰æÜÁöÑÊèê‰æõËÄÖËÆÄÂà∞ÂæåÔºåÂèØËÉΩÊúÉÂ∞çÁóÖ‰∫∫ÁöÑÊú™‰æÜËßÄÈªûÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÈÄèÈÅéÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®Ê†πÊìöËÆÄËÄÖÁöÑËßÄÈªûÔºåÊâæÂá∫Á≤æÁ•ûÁóÖËá®Â∫äÁ≠ÜË®ò‰∏≠Ë°®ÈÅîÁöÑÊÉÖÁ∑í„ÄÇÂæûË•øÂ•àÂ±±ÂÅ•Â∫∑Á≥ªÁµ±ÁöÑÂ§ßÈáè‰∏îÂ§öÊ®£ÂåñÁöÑËá®Â∫äÁ≠ÜË®ò‰∏≠ÊëòÈåÑÂè•Â≠êÔºåÊàëÂÄë‰ΩøÁî®ÊèêÁ§∫ÂíåÊÉÖÂ¢ÉÂ≠∏Áøí‰æÜË™øÊï¥‰∏âÂÄãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (GPT-3.5„ÄÅLlama 2„ÄÅMistral)Ôºå‰ª•Ê†πÊìöÊèê‰æõËÄÖÊàñÈùûÊèê‰æõËÄÖËßÄÈªûÂ∞çÂè•Â≠êÂÇ≥ÈÅîÁöÑÊÉÖÁ∑íÈÄ≤Ë°åÂàÜÈ°û„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåGPT-3.5 ÊúÄÁ¨¶ÂêàÊèê‰æõËÄÖËßÄÈªûÔºåËÄå Mistral ÊúÄÁ¨¶ÂêàÈùûÊèê‰æõËÄÖËßÄÈªû„ÄÇ

##### **Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study**
2405.20562v1 by Haroon Miah, Dimitrios Kollias, Giacinto Luca Pedone, Drew Provan, Frederick Chen

Primary Immune thrombocytopenia (ITP) is a rare autoimmune disease
characterised by immune-mediated destruction of peripheral blood platelets in
patients leading to low platelet counts and bleeding. The diagnosis and
effective management of ITP is challenging because there is no established test
to confirm the disease and no biomarker with which one can predict the response
to treatment and outcome. In this work we conduct a feasibility study to check
if machine learning can be applied effectively for diagnosis of ITP using
routine blood tests and demographic data in a non-acute outpatient setting.
Various ML models, including Logistic Regression, Support Vector Machine,
k-Nearest Neighbor, Decision Tree and Random Forest, were applied to data from
the UK Adult ITP Registry and a general hematology clinic. Two different
approaches were investigated: a demographic-unaware and a demographic-aware
one. We conduct extensive experiments to evaluate the predictive performance of
these models and approaches, as well as their bias. The results revealed that
Decision Tree and Random Forest models were both superior and fair, achieving
nearly perfect predictive and fairness scores, with platelet count identified
as the most significant variable. Models not provided with demographic
information performed better in terms of predictive accuracy but showed lower
fairness score, illustrating a trade-off between predictive performance and
fairness.

ÊëòË¶ÅÔºöÂéüÁôºÊÄßÂÖçÁñ´ÊÄßË°ÄÂ∞èÊùøÊ∏õÂ∞ëÁóáÔºàITPÔºâÊòØ‰∏ÄÁ®ÆÁΩïË¶ãÁöÑËá™È´îÂÖçÁñ´ÁñæÁóÖ
ÂÖ∂ÁâπÂæµÂú®ÊñºÂÖçÁñ´‰ªãÂ∞éÁöÑÂ§ñÂë®Ë°ÄÂ∞èÊùøÁ†¥Â£ûÂ∞éËá¥ÊÇ£ËÄÖË°ÄÂ∞èÊùøÊï∏ÈáèÊ∏õÂ∞ëÂíåÂá∫Ë°Ä„ÄÇITP ÁöÑË®∫Êñ∑ÂíåÊúâÊïàÁÆ°ÁêÜÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫Ê≤íÊúâÊó¢ÂÆöÁöÑÊ™¢Ê∏¨ÊñπÊ≥ï‰æÜÁ¢∫Ë™çÁñæÁóÖÔºå‰πüÊ≤íÊúâÁîüÁâ©Ê®ôË™åÁâ©ÂèØ‰ª•È†êÊ∏¨Â∞çÊ≤ªÁôÇÂíåÁµêÊûúÁöÑÂèçÊáâ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂèØË°åÊÄßÁ†îÁ©∂Ôºå‰ª•Ê™¢Êü•Ê©üÂô®Â≠∏ÁøíÊòØÂê¶ÂèØ‰ª•ÊúâÊïàÊáâÁî®Êñº‰ΩøÁî®ÈùûÊÄ•ÊÄßÈñÄË®∫Áí∞Â¢É‰∏≠ÁöÑÂ∏∏Ë¶èË°ÄÊ∂≤Ê™¢Êü•Âíå‰∫∫Âè£Áµ±Ë®àÊï∏ÊìöË®∫Êñ∑ ITP„ÄÇÂêÑÁ®Æ ML Ê®°ÂûãÔºåÂåÖÊã¨ÈÇèËºØËø¥Ê≠∏„ÄÅÊîØÊåÅÂêëÈáèÊ©ü„ÄÅk ÊúÄËøëÈÑ∞„ÄÅÊ±∫Á≠ñÊ®πÂíåÈö®Ê©üÊ£ÆÊûóÔºåË¢´ÊáâÁî®Êñº‰æÜËá™Ëã±ÂúãÊàê‰∫∫ ITP ÁôªË®òËôïÂíåÊôÆÈÄöË°ÄÊ∂≤Â≠∏Ë®∫ÊâÄÁöÑÊï∏Êìö„ÄÇÁ†îÁ©∂‰∫ÜÂÖ©Á®Æ‰∏çÂêåÁöÑÊñπÊ≥ïÔºö‰∏ÄÁ®ÆÊòØ‰∏çÁü•ÈÅì‰∫∫Âè£Áµ±Ë®àÊï∏ÊìöÁöÑÊñπÊ≥ïÔºåÂè¶‰∏ÄÁ®ÆÊòØÁü•ÈÅì‰∫∫Âè£Áµ±Ë®àÊï∏ÊìöÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó‰æÜË©ï‰º∞ÈÄô‰∫õÊ®°ÂûãÂíåÊñπÊ≥ïÁöÑÈ†êÊ∏¨ÊÄßËÉΩ‰ª•ÂèäÂÆÉÂÄëÁöÑÂÅèÂ∑Æ„ÄÇÁµêÊûúË°®ÊòéÔºåÊ±∫Á≠ñÊ®πÂíåÈö®Ê©üÊ£ÆÊûóÊ®°ÂûãÈÉΩÂÑ™Ë∂ä‰∏îÂÖ¨Âπ≥ÔºåÂØ¶Áèæ‰∫ÜÊé•ËøëÂÆåÁæéÁöÑÈ†êÊ∏¨ÂíåÂÖ¨Âπ≥ÂàÜÊï∏ÔºåË°ÄÂ∞èÊùøË®àÊï∏Ë¢´Á¢∫ÂÆöÁÇ∫ÊúÄÈáçË¶ÅÁöÑËÆäÈáè„ÄÇÊú™Êèê‰æõ‰∫∫Âè£Áµ±Ë®à‰ø°ÊÅØÁöÑÊ®°ÂûãÂú®È†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÊñπÈù¢Ë°®ÁèæÂæóÊõ¥Â•ΩÔºå‰ΩÜÂÖ¨Âπ≥ÂàÜÊï∏ËºÉ‰ΩéÔºåË™™Êòé‰∫ÜÈ†êÊ∏¨ÊÄßËÉΩÂíåÂÖ¨Âπ≥ÊÄß‰πãÈñìÁöÑÊ¨äË°°„ÄÇ


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Mir√≥-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-27**|**Advancing Healthcare Automation: Multi-Agent Systems for Medical Necessity Justification**|Himanshu Pandey et.al.|[2404.17977v1](http://arxiv.org/abs/2404.17977v1)|null|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v1](http://arxiv.org/abs/2404.12832v1)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|S√©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timoth√©e Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in medical imaging AI**|Emma A. M. Stanley et.al.|[2311.02115v1](http://arxiv.org/abs/2311.02115v1)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. Garc√≠a-G√≥mez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v1](http://arxiv.org/abs/2309.12325v1)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|
|**2023-05-05**|**Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**|Goda Klumbyte et.al.|[2305.03376v1](http://arxiv.org/abs/2305.03376v1)|null|
|**2023-04-25**|**Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**|Surjodeep Sarkar et.al.|[2304.13191v1](http://arxiv.org/abs/2304.13191v1)|null|
|**2023-04-04**|**A Brief Review of Explainable Artificial Intelligence in Healthcare**|Zahra Sadeghi et.al.|[2304.01543v1](http://arxiv.org/abs/2304.01543v1)|null|
|**2023-03-22**|**Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**|Frederik Pahde et.al.|[2303.12641v2](http://arxiv.org/abs/2303.12641v2)|[link](https://github.com/maxdreyer/reveal2revise)|
|**2023-03-11**|**Explainable AI for Time Series via Virtual Inspection Layers**|Johanna Vielhaben et.al.|[2303.06365v1](http://arxiv.org/abs/2303.06365v1)|null|
|**2023-03-08**|**Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**|Truong Thanh Hung Nguyen et.al.|[2303.04731v1](http://arxiv.org/abs/2303.04731v1)|[link](https://github.com/hungntt/xai_thyroid)|
|**2023-03-06**|**Cybersecurity of AI medical devices: risks, legislation, and challenges**|Elisabetta Biasin et.al.|[2303.03140v1](http://arxiv.org/abs/2303.03140v1)|null|
|**2023-02-06**|**LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**|Nooshin Yousefzadeh et.al.|[2302.03008v2](http://arxiv.org/abs/2302.03008v2)|null|
|**2023-02-02**|**Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**|Brian Y. Lim et.al.|[2302.01241v2](http://arxiv.org/abs/2302.01241v2)|null|
|**2023-02-02**|**LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**|Ghanta Sai Krishna et.al.|[2302.01104v1](http://arxiv.org/abs/2302.01104v1)|null|
|**2023-02-01**|**SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**|Roxana Daneshjou et.al.|[2302.00785v1](http://arxiv.org/abs/2302.00785v1)|null|
|**2023-01-19**|**Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**|Paritosh Verma et.al.|[2301.07835v1](http://arxiv.org/abs/2301.07835v1)|null|
|**2023-01-18**|**Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**|Carlo Metta et.al.|[2302.03033v1](http://arxiv.org/abs/2302.03033v1)|null|
|**2023-01-17**|**Monotonicity for AI ethics and society: An empirical study of the monotonic neural additive model in criminology, education, health care, and finance**|Dangxing Chen et.al.|[2301.07060v1](http://arxiv.org/abs/2301.07060v1)|null|
|**2023-01-15**|**Rationalizing Predictions by Adversarial Information Calibration**|Lei Sha et.al.|[2301.06009v1](http://arxiv.org/abs/2301.06009v1)|null|
|**2023-01-05**|**Semantic match: Debugging feature attribution methods in XAI for healthcare**|Giovanni Cin√† et.al.|[2301.02080v3](http://arxiv.org/abs/2301.02080v3)|null|
|**2022-12-17**|**Context-dependent Explainability and Contestability for Trustworthy Medical Artificial Intelligence: Misclassification Identification of Morbidity Recognition Models in Preterm Infants**|Isil Guzey et.al.|[2212.08821v1](http://arxiv.org/abs/2212.08821v1)|null|
|**2022-12-16**|**It is not "accuracy vs. explainability" -- we need both for trustworthy AI systems**|D. Petkovic et.al.|[2212.11136v2](http://arxiv.org/abs/2212.11136v2)|null|
|**2022-12-02**|**SimpleMind adds thinking to deep neural networks**|Youngwon Choi et.al.|[2212.00951v1](http://arxiv.org/abs/2212.00951v1)|[link](https://gitlab.com/sm-ai-team/simplemind)|
|**2022-11-27**|**Attribution-based XAI Methods in Computer Vision: A Review**|Kumar Abhishek et.al.|[2211.14736v1](http://arxiv.org/abs/2211.14736v1)|null|
|**2022-11-08**|**Privacy Meets Explainability: A Comprehensive Impact Benchmark**|Saifullah Saifullah et.al.|[2211.04110v1](http://arxiv.org/abs/2211.04110v1)|null|
|**2022-11-05**|**Predicting Treatment Adherence of Tuberculosis Patients at Scale**|Mihir Kulkarni et.al.|[2211.02943v2](http://arxiv.org/abs/2211.02943v2)|null|
|**2022-11-02**|**Explainable AI over the Internet of Things (IoT): Overview, State-of-the-Art and Future Directions**|Senthil Kumar Jagatheesaperumal et.al.|[2211.01036v2](http://arxiv.org/abs/2211.01036v2)|null|
|**2022-10-24**|**Human-centered XAI for Burn Depth Characterization**|Maxwell J. Jacobson et.al.|[2210.13535v2](http://arxiv.org/abs/2210.13535v2)|null|

#### Abstracts
##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

ÊëòË¶ÅÔºöÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁöÑÊÖ¢ÊÄßÁñæÁóÖÔºåÊ≤íÊúâÂ∑≤Áü•ÁöÑÊúÄÁµÇÁôÇÊ≥ï‰∏îÁôºÁóÖÁéáÂæàÈ´ò„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÈÄ≤Ë°åÊÄßÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÁï∞Ë≥™ÊÄßÁñæÁóÖÔºåÊúÉÈ°ØËëóÂΩ±ÈüøËÖéËáüÁµêÊßãÂíåÂäüËÉΩÔºåÊúÄÁµÇÂ∞éËá¥ËÖéË°∞Á´≠„ÄÇÈö®ËëóÊôÇÈñìÁöÑÊé®ÁßªÔºåÊÖ¢ÊÄßËÖéËáüÁóÖÂ∑≤ÂæûÂΩ±ÈüøÂ∞ëÊï∏‰∫∫ÁöÑËá¥ÂëΩÁñæÁóÖËΩâËÆäÁÇ∫‰∏ÄÁ®ÆÂö¥ÈáçÁ®ãÂ∫¶‰∏çÂêåÁöÑÂ∏∏Ë¶ãÁñæÁóÖ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÊ®ôÊòØ‰ΩøÁî®ÈõÜÊàêÂ≠∏ÁøíÂíåÂèØËß£ÈáãÁöÑ AI ÈÄ≤Ë°åÊó©ÊúüÈ†êÂæåÂíå CKD Ê™¢Ê∏¨Ôºå‰∏¶Ë¶ñË¶∫Âåñ‰∏ªÂ∞éÁâπÂæµ„ÄÅÁâπÂæµÂàÜÊï∏ÂíåË°®ÁèæÂá∫ÁöÑÂÄº„ÄÇÁÇ∫Ê≠§ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ AI È©ÖÂãïÁöÑÈ†êÊ∏¨ÂàÜÊûêÊñπÊ≥ïÔºå‰ª•Âπ´Âä©Ëá®Â∫äÈÜ´ÁîüÁÇ∫ÂÄãÂà•ÊÇ£ËÄÖÈñãÂÖ∑ÁîüÊ¥ªÊñπÂºè‰øÆÊîπÂª∫Ë≠∞Ôºå‰ª•Èôç‰ΩéÈÄôÁ®ÆÁñæÁóÖÁöÑÈÄ≤Â±ïÈÄüÂ∫¶„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÊòØÂæû CKD ÊÇ£ËÄÖÂíåÂÅ•Â∫∑ÂèóË©¶ËÄÖÁöÑË∫´È´îÁîüÂëΩÈ´îÂæµ‰∏≠Êî∂ÈõÜÁöÑÔºå‰ª•Ê∫ñÁ¢∫ÈñãÁôºÊàëÂÄëÊèêÂá∫ÁöÑ AI È©ÖÂãïÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®ÈÄôÊñπÈù¢ÔºåÊèê‰æõ‰∫ÜË°ÄÊ∂≤ÂíåÂ∞øÊ∂≤Ê™¢Ê∏¨ÁµêÊûúÔºå‰∏¶ÊáâÁî®Âü∫ÊñºÈõÜÊàêÊ®πÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨Êú™ÁôºÁèæÁöÑ CKD ÁóÖ‰æã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ∂ìÈÅéËàáËÖéËáüÁßëÈÜ´ÁîüÁöÑÈï∑ÊúüË´ÆË©¢ÂæåÂæóÂà∞È©óË≠â„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂíåËß£ÈáãÁµêÊûúËàáÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ÁèæÊúâÁöÑÂèØËß£Èáã AI ÊáâÁî®ÈÄ≤Ë°å‰∫ÜÊØîËºÉÔºåÂåÖÊã¨ CKD„ÄÇÊØîËºÉË°®ÊòéÔºåÊàëÂÄëÈñãÁôºÁöÑ AI Ê®°ÂûãÔºåÁâπÂà•ÊòØÈö®Ê©üÊ£ÆÊûóÊ®°ÂûãÔºåÂ∑≤Á∂ìÁ¢∫ÂÆö‰∫ÜÊØî XgBoost Êõ¥Â§ö‰ΩúÁÇ∫ÈáçË¶ÅË≤¢ÁçªËÄÖÁöÑÁâπÂæµ„ÄÇÂèØËß£ÈáãÊÄß (I) Ë°°ÈáèÈáçË¶ÅÁâπÂæµËàáÊé©ËìãÁâπÂæµÁöÑÊØîÁéáÔºåË°®ÊòéÊàëÂÄëÁöÑ XgBoost Ê®°ÂûãÂú®ÈÄôÂÄãÊåáÊ®ô‰∏≠Áç≤Âæó‰∫ÜÊõ¥È´òÁöÑÂàÜÊï∏ÔºåÁâπÂà•ÊòØ 98% ÁöÑ‰øùÁúüÂ∫¶Ôºå‰∏¶‰∏îÂú® FII ÊåáÊï∏‰∏≠Ëá™ÁÑ∂È´òÊñºÁ´∂Áà≠Ê®°Âûã„ÄÇ

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

ÊëòË¶ÅÔºöÂøÉÁêÜÂÅ•Â∫∑ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖË§áÈõú‰∏îÊôÆÈÅçÁöÑÂÖ®ÁêÉÊåëÊà∞ÔºåÂΩ±Èüø‰∫ÜÊï∏ÁôæËê¨‰∫∫ÁöÑÁîüÊ¥ªÔºå‰∏¶Á∂ìÂ∏∏Â∞éËá¥Âö¥ÈáçÁöÑÂæåÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂæπÂ∫ïÁöÑË™øÊü•Ôºå‰ª•Êé¢Á¥¢Êï∏ÊìöÁßëÂ≠∏„ÄÅ‰∫∫Â∑•Êô∫ÊÖßÂíåÂøÉÁêÜ‰øùÂÅ•ÁöÑ‰∫§ÈõÜÔºåÈáçÈªûÈóúÊ≥®ÈÄöÈÅéÁ∑ö‰∏äÁ§æ‰∫§Â™íÈ´î (OSM) ÈÄ≤Ë°åÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨ÁöÑÊúÄÊñ∞ÁôºÂ±ï„ÄÇÂæàÂ§ß‰∏ÄÈÉ®ÂàÜ‰∫∫Âè£Á©çÊ•µÂèÉËàá OSM Âπ≥Âè∞ÔºåÂâµÈÄ†‰∫Ü‰∏ÄÂÄãÈæêÂ§ßÁöÑ‰∫∫Âì°Ë≥áÊñôÂ∫´ÔºåÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÂàÜÊûêÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÇ≥Áµ±ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÅÊúÄÂÖàÈÄ≤ÁöÑË≥áÊñôÂíå AI È©ÖÂãïÁöÑÁ†îÁ©∂Ôºå‰ª•ÂèäÂøÉÁêÜ‰øùÂÅ•‰∏≠ÂèØËß£Èáã AI (XAI) Ê®°ÂûãÁöÑÂá∫Áèæ„ÄÇÊàëÂÄëÂõûÈ°ß‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºåÁâπÂà•ÊòØÈÇ£‰∫õÂü∫ÊñºÁèæ‰ª£Ê∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÂêåÊôÇÂº∑Ë™ø‰∫ÜÈÜ´ÁôÇ‰øùÂÅ• AI Ê®°Âûã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÂØ¶È©óË®≠Ë®àÈÉ®ÂàÜÊèê‰æõ‰∫ÜÂ∞çÊôÆÈÅçÂÅöÊ≥ïÁöÑË¶ãËß£ÔºåÂåÖÊã¨ÂèØÁî®ÁöÑË≥áÊñôÈõÜÂíåË©ï‰º∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÈÇÑÊâæÂá∫Ë©≤È†òÂüüÁöÑ‰∏ªË¶ÅÂïèÈ°åÂíåÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊúâÂ∏åÊúõÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêë„ÄÇÁî±ÊñºÂøÉÁêÜÂÅ•Â∫∑Ê±∫Á≠ñÈúÄË¶ÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈÅìÂæ∑ËÄÉÈáèÔºåÊú¨ÊñáÊúâÂä©ÊñºÊé®ÈÄ≤ÂøÉÁêÜ‰øùÂÅ•‰∏≠ÈÄèÈÅéÁ§æ‰∫§Â™íÈ´îÊé®ÈÄ≤ XAI ÁöÑÊåÅÁ∫åË®éË´ñ„ÄÇÈÄôË£°ÊèêÂá∫ÁöÑÂÖ®Èù¢Ê¶ÇËø∞Êó®Âú®ÂºïÂ∞éÁ†îÁ©∂‰∫∫Âì°„ÄÅÂæûÊ•≠‰∫∫Âì°ÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖÁôºÂ±ïÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨È†òÂüü„ÄÇ

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁôÇÁÖßË≠∑‰∏≠ÈúÄË¶Å AI ËºîÂä©ÁöÑËá®Â∫äË®∫Êñ∑„ÄÇÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏î‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂΩ±ÂÉèÂàÜÊûê„ÄÇÊúÄËøëÈñãÁôºÁöÑÂãïÊÖã‰∏çÁ¢∫ÂÆöÂõ†ÊûúÈóú‰øÇÂúñ (DUCG) ÊñπÊ≥ïÊòØÂõ†ÊûúÈ©ÖÂãïÁöÑ„ÄÅÂèØËß£ÈáãÁöÑÔºå‰∏¶‰∏îÂú®‰∏çÂêåÁöÑÊáâÁî®Â†¥ÊôØ‰∏≠ÊòØ‰∏çËÆäÁöÑÔºåÊ≤íÊúâË≥áÊñôÊî∂ÈõÜ„ÄÅÊ®ôË®ò„ÄÅÊì¨Âêà„ÄÅÈö±ÁßÅ„ÄÅÂÅèË¶ã„ÄÅÊ¶ÇÂåñ„ÄÅÈ´òÊàêÊú¨ÂíåÈ´òËÉΩËÄóÁöÑÂïèÈ°å„ÄÇÈÄöÈÅéËá®Â∫äÂ∞àÂÆ∂Âíå DUCG ÊäÄË°ì‰∫∫Âì°‰πãÈñìÁöÑÂØÜÂàáÂêà‰ΩúÔºåÊßãÂª∫‰∫ÜÊ∂µËìã 54 ÂÄã‰∏ªË®¥ÁöÑ 46 ÂÄã DUCG Ê®°Âûã„ÄÇÂèØ‰ª•Âú®Ê≤íÊúâÂàÜÊµÅÁöÑÊÉÖÊ≥Å‰∏ãË®∫Êñ∑Âá∫ 1,000 Â§öÁ®ÆÁñæÁóÖ„ÄÇÂú®ÊáâÁî®ÊñºÂØ¶Èöõ‰∏ñÁïå‰πãÂâçÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Áî±Á¨¨‰∏âÊñπÈÜ´Èô¢ÂõûÊ∫ØÊÄßÈ©óË≠â„ÄÇÈ©óË≠âÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 95%ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÁΩïË¶ãÁñæÁóÖÂú®ÂÖßÁöÑÊØèÁ®ÆÁñæÁóÖÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 80%„ÄÇÈ©óË≠âÂæåÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Âú®‰∏≠ÂúãÂØ¶ÈöõÊáâÁî®„ÄÇÂ∑≤Á∂ìÂü∑Ë°å‰∫ÜË∂ÖÈÅé‰∏ÄÁôæËê¨ÂÄãÁúüÂØ¶Ë®∫Êñ∑Ê°à‰æãÔºåÂÉÖÁôºÁèæ 17 ÂÄã‰∏çÊ≠£Á¢∫ÁöÑË®∫Êñ∑„ÄÇÁî±Êñº DUCG ÁöÑÈÄèÊòéÊÄßÔºåÁôºÁèæ‰∏¶Á≥æÊ≠£‰∫ÜÂ∞éËá¥‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÁöÑÈåØË™§„ÄÇÈ†ªÁπÅÊáâÁî® DUCG ÁöÑËá®Â∫äÈÜ´ÁîüÁöÑË®∫Êñ∑ËÉΩÂäõÂæóÂà∞‰∫ÜÈ°ØËëóÊèêÈ´ò„ÄÇÂú®‰ªãÁ¥π‰∫ÜÂâçÈù¢ÊèêÂá∫ÁöÑ DUCG ÊñπÊ≥ïË´ñ‰πãÂæåÔºåÊèêÂá∫‰∫ÜÊΩõÂú®ÂÅ•Â∫∑Ê™¢Êü•ÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÔºå‰∏¶ÊèêÂèñ‰∫Ü DUCG ÁöÑÈóúÈçµÊÄùÊÉ≥„ÄÇ</paragraph>

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

ÊëòË¶ÅÔºöËá™Ê≥®ÊÑèÂäõÊ©üÂà∂Â∑≤Ë¢´Êé°Áî®ÊñºÂ§öÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑË®äÊÅØÂÇ≥ÈÅûÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MPNN)Ôºà‰æãÂ¶Ç GATÔºâÔºåÂÆÉÂèØ‰ª•Ëá™ÈÅ©ÊáâÂú∞ÊéßÂà∂Ê≤øËëóÂ∫ïÂ±§ÂúñÂΩ¢ÈÇäÁ∑£ÊµÅÂãïÁöÑË≥áË®äÈáè„ÄÇÈÄôÁ®ÆÊ≥®ÊÑèÂäõÁöÑ‰ΩøÁî®‰ΩøÂæóÊ≠§È°ûÊ®°ÂûãÊàêÁÇ∫ÂèØËß£Èáã AI (XAI) Á†îÁ©∂ÁöÑÂü∫Á∑öÔºåÂõ†ÁÇ∫ÈÄèÈÅéÊ≥®ÊÑèÂäõÁöÑË©ÆÈáãÂ∑≤Âú®ÂêÑÁ®ÆÈ†òÂüüÔºà‰æãÂ¶ÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂíåÈõªËÖ¶Ë¶ñË¶∫Ôºâ‰∏≠ÊôÆÂèä„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂ÈÄöÂ∏∏‰ΩøÁî®Â§©ÁúüÁöÑË®àÁÆóÊñπÊ≥ïÂæûÊ≥®ÊÑèÂäõ‰∏≠Êé®Â∞éÂá∫Ê≠∏Âõ†ÂàÜÊï∏Ôºå‰∏¶‰∏îÊ≤íÊúâËÄÉÊÖÆÂà∞ÈÇäÁ∑£Ê≠∏Âõ†ÁöÑÁ≤æÁ¢∫‰∏î‰ªîÁ¥∞ÁöÑË®àÁÆó„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊó®Âú®Â°´Ë£úÊ≥®ÊÑèÂäõÂïüÁî® MPNN ÁöÑÂª£Ê≥õ‰ΩøÁî®ËàáÂÆÉÂÄëÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÁöÑÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÈÄôÂÄã‰∏ªÈ°åÂ∑≤Âú®ÂÖ∂‰ªñÈ†òÂüüÁ©çÊ•µÁ†îÁ©∂„ÄÇÁÇ∫Ê≠§Ôºå‰ΩúÁÇ∫Á¨¨‰∏ÄÊ¨°ÂòóË©¶ÔºåÊàëÂÄëÂ∞á GNN ‰∏≠Ê≥®ÊÑèÂäõÊ¨äÈáçÁöÑÈÇäÁ∑£Ê≠∏Âõ†ÂïèÈ°åÂΩ¢ÂºèÂåñ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫ GATTÔºå‰∏ÄÁ®ÆÂª∫Á´ãÂú®Ë®àÁÆóÊ®π‰∏äÁöÑÈÇäÁ∑£Ê≠∏Âõ†Ë®àÁÆóÊñπÊ≥ï„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Ë©ï‰º∞ GAT ÁöÑÊ≠∏Âõ†ÊôÇÊâÄÂÖ∑ÊúâÁöÑÊïàÊûú„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄëÊÜëÁ∂ìÈ©óÈ©óË≠â‰∫ÜÂÉÖÂ∞çÂúñÊ≥®ÊÑèÂäõÂ±§‰∏äÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÂèñÂπ≥ÂùáÂÄº‰∏çË∂≥‰ª•Ë©ÆÈáã GAT Ê®°ÂûãÁöÑË°åÁÇ∫„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº https://github.com/jordan7186/GAtt/tree/main„ÄÇ

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

ÊëòË¶ÅÔºö‰π≥Áôå (BC) ÊòØÂΩ±ÈüøÂÖ®ÁêÉÂ•≥ÊÄßÊúÄÂ∏∏Ë¶ãÁöÑÊÉ°ÊÄßËÖ´Áò§‰πã‰∏ÄÔºåÂõ†Ê≠§ÈúÄË¶ÅÈÄ≤Ê≠•ÁöÑË®∫Êñ∑ÊñπÊ≥ïÔºå‰ª•ÊîπÂñÑËá®Â∫äÁµêÊûú„ÄÇÊú¨ÊñáÂÖ®Èù¢Êé¢Ë®é‰∫ÜÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ìÂú®‰π≥ÁôåÂÅµÊ∏¨ÂíåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÊåÅÁ∫åÊª≤ÈÄèÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÁâπÂà•ÊòØÂú®ËÖ´Áò§Â≠∏‰∏≠ÔºåÈÄèÊòé‰∏îÂèØËß£ÈáãÁöÑÊ®°ÂûãÈúÄÊ±ÇËÆäÂæóÂã¢Âú®ÂøÖË°åÔºå‰ª•Â¢ûÂº∑Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂíåÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§ÁØáË©ïË´ñÊé¢Ë®é‰∫ÜÂêÑÁ®Æ XAI ÊñπÊ≥ïÁöÑÊï¥ÂêàÔºå‰æãÂ¶Ç SHAP„ÄÅLIME„ÄÅGrad-CAM Á≠âÔºå‰ª•ÂèäÁî®Êñº‰π≥ÁôåÂÅµÊ∏¨ÂíåÂàÜÈ°ûÁöÑÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄèÈÅéÊé¢Ë®é‰π≥ÁôåË≥áÊñôÈõÜÁöÑÊ®°ÂºèÔºåÂåÖÊã¨‰π≥ÊàøÊîùÂΩ±„ÄÅË∂ÖÈü≥Ê≥¢ÂèäÂÖ∂Âú® AI ‰∏≠ÁöÑËôïÁêÜÔºåÊú¨ÊñáÈáçÈªûË™™Êòé XAI Â¶Ç‰ΩïËÉΩÂ∞éËá¥Êõ¥Ê∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇË®àÁï´„ÄÇÂÆÉ‰πüÊé¢Ë®é‰∫ÜÂØ¶ÊñΩÈÄô‰∫õÊäÄË°ìÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂà∂ÂÆöÊ®ôÊ∫ñÂåñË©ïÈáèÊåáÊ®ô‰ª•Ë©ï‰º∞ XAI Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑÂàÜÊûêÂíåË®éË´ñÔºåÊú¨ÊñáÊó®Âú®Âº∑Ë™ø XAI Âú®Á∏ÆÂ∞èË§áÈõú AI Ê®°ÂûãËàáÂØ¶ÂãôÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰πãÈñìÂ∑ÆË∑ùÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°‰πãÈñìÁöÑ‰ø°‰ªªËàáÁêÜËß£Ôºå‰∏¶ÊîπÂñÑÊÇ£ËÄÖÁöÑÁµêÊûú„ÄÇ

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

ÊëòË¶ÅÔºöË™ûÈü≥ÊÉÖÁ∑íËæ®Ë≠ò (SER) Áî±ÊñºÂÖ∂Âú®ÂøÉÁêÜÂÅ•Â∫∑„ÄÅÊïôËÇ≤Âíå‰∫∫Ê©ü‰∫íÂãïÁ≠âÂ§öÂÄãÊáâÁî®È†òÂüüËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåSER Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄßÂèóÂà∞È´òÁ∂≠ÁâπÂæµÈõÜÁöÑÈòªÁ§ôÔºåÈÄô‰∫õÁâπÂæµÈõÜÂèØËÉΩÂåÖÂê´‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑË≥áË®ä„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî®Êñº SER ÁöÑËø≠‰ª£ÁâπÂæµÊèêÂçáÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂº∑Ë™øÁâπÂæµÁõ∏ÈóúÊÄßÂíåÂèØËß£ÈáãÊÄßÔºå‰ª•Â¢ûÂº∑Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèä‰ªîÁ¥∞ÁöÑÁâπÂæµÈÅ∏ÊìáÂíåÂàÜÊûêÔºå‰ª•Âª∫Á´ãÈ´òÊïàÁöÑ SER Á≥ªÁµ±„ÄÇÁÇ∫‰∫ÜÈÄèÈÅéÊ®°ÂûãÂèØËß£ÈáãÊÄßËß£Ê±∫ÊàëÂÄëÁöÑÊ†∏ÂøÉÂïèÈ°åÔºåÊàëÂÄëÊé°Áî®‰∫ÜÂÖ∑Êúâ Shapley ÂÄºÁöÑÁâπÂæµË©ï‰º∞Ëø¥ÂúàÔºå‰ª•ÂèçË¶ÜÊîπÂñÑÁâπÂæµÈõÜ„ÄÇÈÄôÂÄãÈÅéÁ®ãÂú®Ê®°ÂûãÊïàËÉΩÂíåÈÄèÊòéÂ∫¶‰πãÈñìÂèñÂæóÂπ≥Ë°°ÔºåÈÄô‰ΩøÂæóÊàëÂÄëËÉΩÂ§†ÂÖ®Èù¢‰∫ÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ§öÈ†ÖÂÑ™ÈªûÔºåÂåÖÊã¨Ë≠òÂà•ÂíåÁßªÈô§‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑÁâπÂæµÔºåÂæûËÄåÂª∫Á´ãÊõ¥ÊúâÊïàÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰øÉÈÄ≤‰∫ÜÂèØËß£ÈáãÊÄßÔºåÊúâÂä©ÊñºÁêÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨‰ª•ÂèäË≠òÂà•ÊÉÖÁ∑íÊ±∫ÂÆöÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂ∑≤Âú®Â§öÂÄ´Â§öÊÉÖÁ∑íË™ûÈü≥ÈõÜ (TESS)„ÄÅÊüèÊûóÊÉÖÁ∑íË™ûÈü≥Ë≥áÊñôÂ∫´ (EMO-DB)„ÄÅË≥¥ÁàæÊ£ÆÈü≥Ë®äË¶ñË¶∫ÊÉÖÁ∑íË™ûÈü≥ÂíåÊ≠åÊõ≤Ë≥áÊñôÂ∫´ (RAVDESS) ÂíåËñ©ÈáåÈü≥Ë®äË¶ñË¶∫Ë°®ÈÅîÊÉÖÁ∑í (SAVEE) Ë≥áÊñôÈõÜÁöÑ SER Âü∫Ê∫ñ‰∏äÂæóÂà∞È©óË≠âÔºåÂÖ∂ÊïàËÉΩÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áÊ®°ÂûãÂèØËß£ÈáãÊÄßÁ¥çÂÖ• SER Êû∂ÊßãÁöÑÁ†îÁ©∂„ÄÇÊú¨ÊñáÁöÑÂéüÂßãÁ¢ºÂèØÈÄèÈÅéÊ≠§ÈÄ£ÁµêÂÖ¨ÈñãÂèñÂæóÔºöhttps://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition„ÄÇ

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, H√©lo√Øse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

ÊëòË¶ÅÔºöÂèØËß£ÈáäÊÄßÈÄöÂ∏∏ÂØπ‰∫é‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÂèØÊé•ÂèóÂÆûÊñΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÔºåËøô‰∏ÄÁÇπÂ∞§‰∏∫ÈáçË¶ÅÔºåÂõ†‰∏∫ÂÜ≥Á≠ñÁõ¥Êé•ÂΩ±ÂìçÊÇ£ËÄÖÔºåÂπ∂‰∏îÂØπ AI Á≥ªÁªüÁöÑ‰ø°‰ªªËá≥ÂÖ≥ÈáçË¶Å„ÄÇËøôÁßç‰ø°‰ªªÈÄöÂ∏∏Âª∫Á´ãÂú® AI Êèê‰æõÁöÑËß£ÈáäÂíåËØ†Èáä‰πã‰∏ä„ÄÇÂ∞ΩÁÆ° AI ÂèØËß£ÈáäÊÄßÂèñÂæó‰∫ÜÈáçÂ§ßËøõÂ±ïÔºå‰ΩÜ‰ªçÁÑ∂ÈúÄË¶ÅÊòéÁ°ÆÁöÑÊåáÂØºÊñπÈíàÔºåËØ¥ÊòéÂú®ÂåªÁñóÁéØÂ¢É‰∏≠‰ΩïÊó∂‰ª•ÂèäÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÈúÄË¶ÅËß£Èáä„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂàÜÁ±ªÁ≥ªÁªüÔºåËØ•Á≥ªÁªüÂÖ∑ÊúâÂõõÁßç‰∏çÂêåÁöÑËß£ÈáäÂøÖË¶ÅÊÄßÁ±ªÂà´ÔºåÊåáÂØºÊâÄÈúÄÁöÑËß£ÈáäÁ∫ßÂà´ÔºöÊÇ£ËÄÖÊàñÊ†∑Êú¨ÔºàÂ±ÄÈÉ®ÔºâÁ∫ßÂà´„ÄÅÈòüÂàóÊàñÊï∞ÊçÆÈõÜÔºàÂÖ®Â±ÄÔºâÁ∫ßÂà´ÔºåÊàñ‰∏§‰∏™Á∫ßÂà´„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êï∞Â≠¶ÂÖ¨ÂºèÔºåËØ•ÂÖ¨ÂºèÂå∫ÂàÜ‰∫ÜËøô‰∫õÁ±ªÂà´ÔºåÂπ∂‰∏∫Á†îÁ©∂‰∫∫ÂëòÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÆûÁî®Ê°ÜÊû∂Ôºå‰ª•Á°ÆÂÆöÂåªÁñó AI Â∫îÁî®‰∏≠ÊâÄÈúÄÁöÑËß£ÈáäÁöÑÂøÖË¶ÅÊÄßÂíåÊ∑±Â∫¶„ÄÇËÄÉËôë‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÂõ†Á¥†ÔºöËØÑ‰º∞ÂçèËÆÆÁöÑÁ®≥ÂÅ•ÊÄß„ÄÅ‰∏ìÂÆ∂ËßÇÂØüÁöÑÂèØÂèòÊÄß‰ª•ÂèäÂ∫îÁî®Á®ãÂ∫èÁöÑË°®Á§∫Áª¥Êï∞„ÄÇ‰ªéËøô‰∏™ËßíÂ∫¶Êù•ÁúãÔºåÊàë‰ª¨Ëß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºöAI ÂåªÁñóÂ∫îÁî®‰ΩïÊó∂ÈúÄË¶ÅËß£ÈáäÔºå‰ª•ÂèäÈúÄË¶ÅËß£ÈáäÂà∞‰ΩïÁßçÁ®ãÂ∫¶Ôºü

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

ÊëòË¶ÅÔºöÈö®ËëóÂÖàÈÄ≤ÁöÑ AI/MLÔºåÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂‰∏çÊñ∑Â¢ûÂä†Ôºå‰ª•ÂèäÈóúÊñº‰∫∫È°ûÂ¶Ç‰ΩïËàá AI Âíå XAI ‰∫íÂãï‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄë‰ªçÁÑ∂Áº∫‰πèÂ∞ç AI Á≥ªÁµ±Âíå XAI ÊáâÂ¶Ç‰ΩïÈ¶ñÂÖàÂëàÁèæÁµ¶Ê≤íÊúâÊäÄË°ìËÉåÊôØÁöÑÁî®Êà∂ÁöÑ‰∫ÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì° (n=12) Âíå‰∏ª‰øÆÈÜ´Â≠∏ÂíåÂÅ•Â∫∑ÁöÑÂ≠∏Áîü (n=4) ÈÄ≤Ë°åÂçäÁµêÊßãÂåñË®™Ë´áÁöÑÁµêÊûúÔºå‰ª•Á†îÁ©∂Â¶Ç‰ΩïÊîπÂñÑ AI Âíå XAI ÁöÑÂÖ•ÈñÄ„ÄÇÂ∞çÊñºË®™Ë´áÔºåÊàëÂÄëÂª∫Á´ãÂú®‰∫∫Ê©ü‰∫íÂãïÊ∫ñÂâá‰πã‰∏äÔºåÁÇ∫‰∏≠È¢®Â∫∑Âæ©Ë©ï‰º∞Âíå AI Ëß£ÈáãÁöÑ AI Á≥ªÁµ±ÂâµÂª∫ÂÖ•ÈñÄÊùêÊñôÔºå‰∏¶Â∞áÂÆÉÂÄë‰ªãÁ¥πÁµ¶ÂèÉËàáËÄÖ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈô§‰∫ÜÂëàÁèæÂÇ≥Áµ±ÁöÑ AI ÊÄßËÉΩÊåáÊ®ôÂ§ñÔºåÂèÉËàáËÄÖÈÇÑÂ∏åÊúõÂü∫ÂáÜ‰ø°ÊÅØ„ÄÅAI ÁöÑÂØ¶ÈöõÂ•ΩËôï‰ª•Âèä‰∫§‰∫íË©¶È©óÔºå‰ª•Êõ¥Â•ΩÂú∞Â∞á AI ÊÄßËÉΩÊÉÖÂ¢ÉÂåñÔºå‰∏¶ÂÆåÂñÑ AI ÁöÑÁõÆÊ®ôÂíåÊÄßËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊîπÈÄ≤ AI Âíå XAI ‰ª•Âèä‰∫∫Ê©üÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂÖ•ÈñÄÊñπÂêë„ÄÇ

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

ÊëòË¶ÅÔºöÊú¨Êñá‰ΩøÁî®Ê©üÂô®Â≠∏Áøí (ML) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ì‰æÜÊé¢Ë®éÁáüÈ§äÁãÄÊ≥ÅËàáÈòøËå≤Êµ∑ÈªòÁóá (AD) Áõ∏ÈóúÁöÑÊ≠ª‰∫°Áéá‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊé°Áî®Á¨¨‰∏âÊ¨°ÂÖ®ÂúãÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES III) Ë≥áÊñôÂ∫´ÈÄ≤Ë°åÂàÜÊûê„ÄÇÈÅ∏ÊìáÈö®Ê©üÊ£ÆÊûóÊ®°Âûã‰ΩúÁÇ∫ XAI ÂàÜÊûêÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ΩøÁî® Shapley Additive Explanations (SHAP) ÊñπÊ≥ï‰æÜË©ï‰º∞ÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈáçË¶ÅÁöÑÁáüÈ§äÂõ†Á¥†Ôºå‰æãÂ¶ÇË°ÄÊ∏ÖÁ∂≠ÁîüÁ¥† B12 ÂíåÁ≥ñÂåñË°ÄÁ¥ÖËõãÁôΩ„ÄÇË©≤Á†îÁ©∂Ë≠âÊòé‰∫ÜÈö®Ê©üÊ£ÆÊûóÂú®È†êÊ∏¨ AD Ê≠ª‰∫°ÁéáÊñπÈù¢Áõ∏ËºÉÊñºÂÖ∂‰ªñÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÁáüÈ§äÂ∞ç AD ÁöÑÂΩ±ÈüøÁöÑË¶ãËß£Ôºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇ

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÁ∑ö‰∏äÂÅ•Â∫∑Á§æÁæ§‰∏≠Â∞ãÊ±ÇË≥áË®äÊîØÊåÅÁöÑÂïèÈ°å„ÄÅÂõûÊáâÔºå‰ª•ÂèäÊúâÂπ´Âä©ÁöÑË©ïÂàÜ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁµÑÊ®ôË®òÁöÑÂïèÁ≠îÈÖçÂ∞çË≥áÊñôÈõÜÔºå‰∏¶ÈñãÁôº‰∫ÜÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÂèØÈù†Âú∞È†êÊ∏¨Ë≥áË®äÊîØÊåÅÂïèÈ°åÂíåÂõûÊáâ„ÄÇÊàëÂÄëÊé°Áî®ÂèØËß£ÈáãÁöÑ AI ‰æÜÊè≠Á§∫Ë≥áË®äÊîØÊåÅ‰∫§ÊµÅ‰∏≠ËòäÂê´ÁöÑÊÉÖÁ∑íÔºåË≠âÊòéÊÉÖÁ∑íÂú®Êèê‰æõË≥áË®äÊîØÊåÅ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊÉÖÁ∑íÊîØÊåÅÂíåË≥áË®äÊîØÊåÅ‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®‰ª•Ââç‰∏¶Êú™Ë¢´Á†îÁ©∂ÈÅé„ÄÇÊú¨Á†îÁ©∂ÊîπÈÄ≤‰∫ÜÁ§æÊúÉÊîØÊåÅÁêÜË´ñÔºå‰∏¶ÁÇ∫‰ΩøÁî®ËÄÖÊ±∫Á≠ñËºîÂä©Â∑•ÂÖ∑ÁöÑÈñãÁôºÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇË®éË´ñ‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂΩ±Èüø„ÄÇ

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

ÊëòË¶ÅÔºöÂú®ÁßëÊäÄÈ£õÈÄüÁôºÂ±ïÁöÑÊôÇ‰ª£Ôºå‰∏Ä‰ΩçÊÑèÂ§ñÁöÑË®™ÂÆ¢Â∑≤Âú®ÂÖ®ÁêÉÊïôÂÆ§‰∏≠‰ΩîÊúâ‰∏ÄÂ∏≠‰πãÂú∞ÔºåÈÇ£Â∞±ÊòØ‰∫∫Â∑•Êô∫ÊÖß„ÄÇÁîüÊàêÂºè AIÔºå‰æãÂ¶Ç ChatGPTÔºåÊâøË´æÂú®ÊïôËÇ≤È†òÂüüÊéÄËµ∑‰∏ÄÂ†¥Èù©ÂëΩÔºå‰ΩÜÂÆÉÂçªÊòØ‰∏ÄÊääÈõôÈù¢ÂàÉ„ÄÇÂÆÉÂú®ÂÄã‰∫∫ÂåñÂ≠∏ÁøíÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂçªÂõ†‰ΩúÂºä„ÄÅ‰∏çÊ∫ñÁ¢∫‰ª•ÂèäÊïôËÇ≤Â∑•‰ΩúËÄÖÈõ£‰ª•Â∞áÂÖ∂ÊúâÊïàËûçÂÖ•ÊïôÂ≠∏Ë®≠Ë®àÁ≠âÂïèÈ°åËÄåÊäµÈä∑„ÄÇÊàëÂÄëÊ≠£Á´ôÂú®ÈÄôÊïôËÇ≤ÂâçÊ≤øÁöÑÈÇäÁ∑£ÔºåÈ°ØÁÑ∂ÊàëÂÄëÈúÄË¶ÅÈùûÂ∏∏Â∞èÂøÉÂú∞Êé¢Á¥¢ÈÄôÁâáÈ†òÂüü„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂèØËÉΩÊúÉÊêçÂÆ≥ÊàëÂÄëÊïôËÇ≤ÈÅéÁ®ãÁöÑÂÆåÊï¥ÊÄßÂíåÂÉπÂÄº„ÄÇÈÇ£È∫ºÔºåÊàëÂÄëÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊåëÊà∞ËΩâÂåñÁÇ∫Ê©üÈÅáÔºüÁï∂‰∏çÈÅ©Áï∂Âú∞‰ΩøÁî®ÊôÇÔºåAI Â∑•ÂÖ∑ÂèØËÉΩÊúÉÊàêÁÇ∫Ë§áË£ΩË≤º‰∏äÂøÉÊÖãÁöÑÂÆåÁæéÂ∑•ÂÖ∑Ôºå‰∏¶ËøÖÈÄüËÖêËùïÊâπÂà§ÊÄßÊÄùÁ∂≠„ÄÅÂâµÈÄ†ÂäõÂíåÊ∑±ÂÖ•ÁêÜËß£ÔºåÈÄô‰∫õÈÉΩÊòØÊàëÂÄëÂø´ÈÄüËÆäÂåñÁöÑ‰∏ñÁïå‰∏≠ÊúÄÈáçË¶ÅÁöÑÊäÄËÉΩ„ÄÇÊïôÂ∏´ÂÄëË¶∫Âæó‰ªñÂÄëÊ≤íÊúâËÉΩÂäõÂà©Áî®ÈÄôÈ†ÖÊäÄË°ìÔºåÈÄôÊì¥Â§ß‰∫ÜÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÊ©üÊßã‰πãÈñìÁöÑÊï∏‰ΩçÈ¥ªÊ∫ù„ÄÇËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÁ†îÁ©∂ÊñπÊ≥ï„ÄÇÊàëÂÄëÂ∞áÊé°Áî®ÂØ¶Ë≠âÁ†îÁ©∂ÔºåÂÄüÈëëÊäÄË°ìÊé•ÂèóÊ®°ÂûãÔºå‰æÜË©ï‰º∞ÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÂ≠∏ÁîüÂ∞çÁîüÊàêÂºè AI ÁöÑÊÖãÂ∫¶„ÄÇ‰∫ÜËß£‰ªñÂÄëÁöÑÁúãÊ≥ï„ÄÅ‰ΩøÁî®Ê®°ÂºèÂíåÈöúÁ§ôÊòØÂâµÈÄ†ÊúâÊïàËß£Ê±∫ÊñπÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÈóúÈçµÊ≠•È©ü„ÄÇÊú¨Á†îÁ©∂Â∞á‰ΩúÁÇ∫Êú™‰æÜÁ†îÁ©∂‰∫∫Âì°ÊáâÁî®ÁöÑÊµÅÁ®ãÊâãÂÜäÔºåÊ†πÊìöÊ≠§ËôïË™™ÊòéÁöÑÊ≠•È©üÈÅãË°å‰ªñÂÄëËá™Â∑±ÁöÑÊï∏Êìö

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Gr√ºne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, Andr√© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

ÊëòË¶ÅÔºöÈö®ËëóÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊï∏‰ΩçÂåñÔºå‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´Â≠∏È†òÂüü‰∏≠ËÆäÂæóÊõ¥Âä†ÊôÆÂèä„ÄÇÁâπÂà•ÊòØÊ©üÂô®Â≠∏ÁøíÂú®ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÁ≠âË§áÈõú‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Ê•µÂ§ßÁöÑÊΩõÂäõÔºå‰ΩÜÈÄöÂ∏∏ÊòØ‰ª•ÈÄèÊòéÂ∫¶ÂíåÂèØÁêÜËß£ÊÄßÁÇ∫‰ª£ÂÉπ„ÄÇÈÄôÂ∞éËá¥‰∫∫È°ûÁº∫‰πè‰ø°‰ªªÔºåÂæûËÄåÈòªÁ§ô‰∫ÜÂÖ∂Á©çÊ•µ‰ΩøÁî®„ÄÇÂèØËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖßË©¶ÂúñÈÄöÈÅéÊèê‰æõÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÁöÑÊ¥ûÂØü‰æÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºå‰ΩÜÂÖ∂‰∏çÂêåÊñπÊ≥ïÁöÑÂØ¶ÈöõÊïàÁî®Â∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº‰ΩøÁî®ËÄÖÁ†îÁ©∂ÁöÑË©ï‰º∞ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫Ü Grad-CAM Ëß£ÈáãÊñπÊ≥ïÔºå‰∏¶Â∞áÂÖ∂ÊáâÁî®ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰ª•ÂàÜÈ°ûÊôÇÈñìÂ∫èÂàóÊñ∞ÁîüÂÖíÂëºÂê∏Êï∏Êìö‰∏≠ÁöÑÂëºÂê∏„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏çÂêåÂà©ÁõäÁõ∏ÈóúËÄÖÂ∞çÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÊÑüÁü•ÊïàÁî®ÔºåÊè≠Á§∫‰∫ÜÂØ¶ÁèæÂØ¶ÈöõÈÄèÊòéÂ∫¶ÁöÑÈõ£Â∫¶Ôºå‰ª•ÂèäË®±Â§öÂèÉËàáËÄÖÂ∏åÊúõÁç≤ÂæóÊõ¥Ê∑±ÂÖ•ÁöÑËß£Èáã„ÄÇ

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÈÜ´ÁôÇË®∫Êñ∑Êï¥Âêà
ÁÇ∫Ëá®Â∫äÊ±∫Á≠ñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂Ê¶ÇËø∞‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÊñπÊ≥ïÁöÑÈñãÁôºÔºåÁî®ÊñºÈõ∂Ê¨°Â≠∏Áøí/Â∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢ÉÂ≠∏Áøí (ICL)ÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®Â§öÂ±§ÁµêÊßãÂåñÊèêÁ§∫Êï¥ÂêàÈÜ´ÁôÇÈ†òÂüüÁü•Ë≠ò„ÄÇÊàëÂÄëÈÇÑÊé¢Ë®é‰∫Ü‰ΩøÁî®ËÄÖËàá LLM ‰πãÈñìÂÖ©Á®ÆÊ∫ùÈÄöÊñπÂºèÁöÑÂäüÊïàÔºöÊï∏ÂÄºÂ∞çË©± (NC) ÊñπÂºèÔºåÂÆÉÊúÉÈÄêÊ≠•ËôïÁêÜË≥áÊñôÔºå‰ª•ÂèäËá™ÁÑ∂Ë™ûË®ÄÂñÆÂõûÂêà (NL-ST) ÊñπÂºèÔºåÂÆÉÊúÉ‰ΩøÁî®Èï∑ÁØáÊïò‰∫ãÊèêÁ§∫„ÄÇ
ÊàëÂÄëÁöÑÁ†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞‰∫ÜË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÈ¢®Èö™Âõ†Â≠êÔºåÂåÖÊã¨ÊÄßÂà•ÂÅèË¶ãÂíåÂÅáÈô∞ÊÄßÁéáÔºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 920 ÂÄãÊÇ£ËÄÖË®òÈåÑÁöÑË≥áÊñôÈõÜÔºåÊé°Áî®ÂêÑÁ®ÆÂ∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢É„ÄÇÁµêÊûúË°®ÊòéÔºåÂÇ≥Áµ±ÁöÑËá®Â∫äÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÈÄöÂ∏∏Âú®Èõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÈáèÂ≠∏ÁøíË®≠ÂÆö‰∏≠Ë°®ÁèæÂÑ™Êñº LLM„ÄÇÁÑ∂ËÄåÔºåÁï∂‰ΩøÁî®Â∞ëÈáèÂ≠∏ÁøíÁØÑ‰æã‰ª•ÂèäÊúâÊïàÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï‰ΩúÁÇ∫È†òÂüüÁü•Ë≠ò‰æÜÊ∫êÊôÇÔºåÊïàËÉΩÂ∑ÆË∑ùÊúÉÈ°ØËëóÁ∏ÆÂ∞è„ÄÇÊ≠§Â§ñÔºåÈö®ËëóÊôÇÈñìÂÖÖË∂≥ÂíåÁØÑ‰æãÊï∏ÈáèÂ¢ûÂä†ÔºåÂ∞çË©±ÊñπÂºè (NC) Âπæ‰πéÂèØ‰ª•Â™≤Áæé ML Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊúÄÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåLLM Áõ∏Â∞çÊñº ML Ê®°ÂûãÂ±ïÁèæÂá∫Áõ∏Áï∂ÊàñÊõ¥‰Ω≥ÁöÑÊàêÊú¨ÊïèÊÑüÊ∫ñÁ¢∫Â∫¶„ÄÇ
Êú¨Á†îÁ©∂Ë≠âÂØ¶ÔºåÈÄèÈÅéÈÅ©Áï∂ÁöÑÈ†òÂüüÁü•Ë≠òÂíåÈáèË∫´ÊâìÈÄ†ÁöÑÊ∫ùÈÄöÁ≠ñÁï•ÔºåLLM ÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ë®∫Êñ∑Á®ãÂ∫è„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÊúÄ‰Ω≥ÂåñË®ìÁ∑¥ÁØÑ‰æãÊï∏ÈáèÂíåÊ∫ùÈÄöÊñπÂºèÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÊèêÈ´òÊ∫ñÁ¢∫Â∫¶‰∏¶Ê∏õÂ∞ë LLM ÊáâÁî®‰∏≠ÁöÑÂÅèÂ∑Æ„ÄÇ

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Mir√≥-Nicolau, Gabriel Moy√†-Alcover, Antoni Jaume-i-Cap√≥, Manuel Gonz√°lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

ÊëòË¶ÅÔºöÈö®ËëóÂ∞çÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æùË≥¥ÊÄßÁöÑÂ¢ûÂä†ÔºåÂä†‰∏äÂÖ∂Âõ∫ÊúâÁöÑÈÄèÊòéÂ∫¶‰∏çË∂≥Ôºå‰øÉ‰Ωø‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂È†òÂüüÁôºÂ±ïÔºåÁ®±ÁÇ∫ÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï„ÄÇÈÄô‰∫õÊñπÊ≥ïÊó®Âú®ÈÄèÈÅéÊ∑±ÂÖ•‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÂéüÁêÜÔºå‰æÜÊèêÂçáÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞çËá™ÂãïÂåñÁ≥ªÁµ±ÁöÑ‰ø°Ë≥¥„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË°°Èáè‰ΩøÁî®ËÄÖÂ∞ç XAI Á≥ªÁµ±‰ø°Ë≥¥Â∫¶ÁöÑÊñ∞Á©éÊñπÊ≥ïÔºåÂÖÅË®±Â∞çÂÖ∂ÈÄ≤Ë°åÊîπÈÄ≤„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊåáÊ®ôÁµêÂêà‰∫ÜÂÆ¢ËßÄËßÄÈªû‰∏ãÁöÑÊïàËÉΩÊåáÊ®ôÂíå‰ø°Ë≥¥ÊåáÊ®ô„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÈÄôÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÁúüÂØ¶ÁöÑÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÈÄ≤Ë°å‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂Ôºö‰ΩøÁî® XAI Á≥ªÁµ±Âæû X ÂÖâÂΩ±ÂÉè‰∏≠ÂÅµÊ∏¨ËÇ∫ÁÇé„ÄÇ

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

ÊëòË¶ÅÔºöCOVID-19 Áñ´ÊÉÖÂ∞çÂÖ®ÁêÉÂÖ¨ÂÖ±Ë°õÁîüÈÄ†ÊàêÂ£ìÂäõÔºåÂøÖÈ†àÈÄ≤Ë°åÊ∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂπ≤È†êÔºå‰ª•ÊéßÂà∂ÁñæÁóÖÂÇ≥Êí≠‰∏¶Èôç‰ΩéÊ≠ª‰∫°Áéá„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÈÄèÈÅéËÉ∏ÈÉ® X ÂÖâ (CXR) ÂΩ±ÂÉèÊîπÂñÑÂ∞ç COVID-19 È†êÂæåÁöÑÁêÜËß£Âíå‰ø°Ë≥¥„ÄÇÈÄèÈÅéÊï¥ÂêàÂ§ßË¶èÊ®°È†êË®ìÁ∑¥ÂΩ±ÂÉèÁ∑®Á¢ºÂô®„ÄÅÈ¢®Èö™ÁâπÂÆö Grad-CAM ÂíåËß£ÂâñÂçÄÂüüÂÅµÊ∏¨ÊäÄË°ìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁî¢ÁîüÂçÄÂüüÂèØËß£ÈáãÁöÑÁµêÊûúÔºåÊúâÊïàÊçïÊçâÂøÖË¶ÅÁöÑÁñæÁóÖÁâπÂæµÔºåÂêåÊôÇÂ∞àÊ≥®ÊñºÁΩïË¶ã‰ΩÜÈóúÈçµÁöÑÁï∞Â∏∏ÂçÄÂüü„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈ†êÊ∏¨ÁµêÊûúÈÄèÈÅéÈ¢®Èö™ÂçÄÂüüÂÆö‰ΩçÊèê‰æõÂ¢ûÂº∑ÁöÑÊ∏ÖÊô∞Â∫¶ÂíåÈÄèÊòéÂ∫¶ÔºåËÆìËá®Â∫äÈÜ´ÁîüËÉΩÂ§†Âú®Êõ¥‰∫ÜËß£È†êÂæåË¶ãËß£ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞± COVID-19 Ë®∫Êñ∑ÂÅöÂá∫ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÂú®Â§ö‰∏≠ÂøÉÁîüÂ≠òË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºå‰∏¶ÈÄèÈÅéÈáèÂåñÂíåË≥™ÂåñË©ï‰º∞Ë≠âÊòéÂÖ∂ÊúâÊïàÊÄßÔºåÈÅîÂà∞ÂÑ™Áï∞ÁöÑ C ÊåáÊï∏Ôºà0.764 Âíå 0.727ÔºâÂíåÊôÇÈñìÁõ∏Èóú AUCÔºà0.799 Âíå 0.691Ôºâ„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÂú®È¢®Èö™È†êÊ∏¨ÊñπÈù¢Ë∂ÖË∂äÂÇ≥Áµ±ÁöÑÁîüÂ≠òÂàÜÊûêÊñπÊ≥ïÔºåÊèêÂçáËá®Â∫äÊ±∫Á≠ñÁöÑËß£ÈáãÊÄßÔºå‰∏¶Â¢ûÂº∑ AI Á≥ªÁµ±ÁöÑ‰ø°Ë≥¥Â∫¶„ÄÇ

##### **Advancing Healthcare Automation: Multi-Agent Systems for Medical Necessity Justification**
2404.17977v1 by Himanshu Pandey, Akhil Amod, Shivang

This paper explores the application of Swarm-Structured Multi-Agent Systems
(MAS) to establish medical necessity, a process that involves a systematic
review of patient-specific medical structured and unstructured data against
clinical guidelines. We addressed this complex task by decomposing it into
smaller, more manageable sub-tasks. Each sub-task is handled by a specialized
AI agent. We conduct a systematic study of the impact of various prompting
strategies on these agents and benchmark different Large Language Models (LLMs)
to determine their accuracy in completing these tasks. Additionally, we
investigate how these agents can provide explainability, thereby enhancing
trust and transparency within the system.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫ÜÊáâÁî®Áæ§È´îÁµêÊßãÂ§ö‰∏ªÈ´îÁ≥ªÁµ± (MAS) ‰æÜÂª∫Á´ãÈÜ´ÁôÇÂøÖË¶ÅÊÄßÔºåÈÄôÊòØ‰∏ÄÂÄãÊ∂âÂèäÁ≥ªÁµ±ÊÄßÂØ©Êü•ÊÇ£ËÄÖÁâπÂÆöÈÜ´ÁôÇÁµêÊßãÂåñÂíåÈùûÁµêÊßãÂåñË≥áÊñôÂ∞çÁÖßËá®Â∫äÊåáÂºïÁöÑÈÅéÁ®ã„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áÊ≠§Ë§áÈõú‰ªªÂãôÂàÜËß£ÊàêËºÉÂ∞è‰∏îÊõ¥ÊòìÊñºÁÆ°ÁêÜÁöÑÂ≠ê‰ªªÂãô‰æÜËôïÁêÜ„ÄÇÊØèÂÄãÂ≠ê‰ªªÂãôÈÉΩÁî±‰∏ÄÂÄãÂ∞àÈñÄÁöÑ AI ‰∏ªÈ´îËôïÁêÜ„ÄÇÊàëÂÄëÂ∞çÂêÑÁ®ÆÊèêÁ§∫Á≠ñÁï•Â∞çÈÄô‰∫õ‰∏ªÈ´îÁöÑÂΩ±ÈüøÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁ†îÁ©∂Ôºå‰∏¶Â∞ç‰∏çÂêåÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰ª•Á¢∫ÂÆöÂÆÉÂÄëÂú®ÂÆåÊàêÈÄô‰∫õ‰ªªÂãôÊôÇÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂ÈÄô‰∫õ‰∏ªÈ´îÂ¶Ç‰ΩïÊèê‰æõÂèØËß£ÈáãÊÄßÔºåÂæûËÄåÂ¢ûÂº∑Á≥ªÁµ±ÂÖßÁöÑ‰ø°‰ªªÂíåÈÄèÊòéÂ∫¶„ÄÇ

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÅéÂéªÂπæÂπ¥ÔºåËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS) ‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®Âà©Áî®Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÊñπÈù¢ÁôºÊèÆ‰∫ÜÈóúÈçµ‰ΩúÁî®„ÄÇÂÑòÁÆ° AI Ê®°ÂûãÂÖ∑Êúâ‰ª§‰∫∫ÊªøÊÑèÁöÑËÉΩÂäõÔºå‰ΩÜÁº∫‰πèÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÔºåÁâπÂà•ÊòØÂú®ÂèØÈù†ÊÄßÁÇ∫ÂøÖË¶ÅËÄÉÈáèÁöÑÈÜ´ÁôÇËÉåÊôØ‰∏ãÔºåÈÄôÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®‰∏çÂΩ±ÈüøÈ†êÊ∏¨Á≤æÊ∫ñÂ∫¶ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÈÄèÊòéÂ∫¶‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥ Rad4XCNNÔºå‰ª•Â¢ûÂº∑ CNN Ë°çÁîüÁâπÂæµÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÂêåÊôÇÂÖ∑ÂÇôÊîæÂ∞ÑÁâπÂæµÂõ∫ÊúâÁöÑÂèØËß£ÈáãÊÄß„ÄÇRad4XCNN ‰∏çÂêåÊñºÂü∫ÊñºÈ°ØËëóÊÄßÂúñÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÔºåÂÆÉÈÄöÈÅéÊîæÂ∞ÑÁµÑÂ≠∏Â∞áÂèØÁêÜËß£ÁöÑÂê´Áæ©Ëàá CNN Ë°çÁîüÁâπÂæµÈóúËÅØËµ∑‰æÜÔºåÁÇ∫Ë∂ÖË∂äË¶ñË¶∫ÂåñÂúñË°®ÁöÑËß£ÈáãÊñπÊ≥ïÊèê‰æõ‰∫ÜÊñ∞ÁöÑËßÄÈªû„ÄÇÊàëÂÄë‰ª•‰π≥ÁôåÂàÜÈ°û‰ªªÂãô‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÂú®Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äË©ï‰º∞ Rad4XCNNÔºåÂåÖÊã¨‰∏ÄÂÄãÁ∑ö‰∏äË≥áÊñôÈõÜÂíåÂÖ©ÂÄãÁî®ÊñºÂÖßÈÉ®ÂíåÂ§ñÈÉ®È©óË≠âÁöÑÂÖßÈÉ®Ë≥áÊñôÈõÜ„ÄÇ‰∏Ä‰∫õÈóúÈçµÁµêÊûúÂ¶Ç‰∏ãÔºöi) Ëàá ViT Ë°çÁîüÁâπÂæµÂíåÊîæÂ∞ÑÁâπÂæµÁõ∏ÊØîÔºåCNN Ë°çÁîüÁâπÂæµ‰øùË≠â‰∫ÜÊõ¥Á©©ÂÅ•ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºõii) ÂÇ≥Áµ±ÁöÑË¶ñË¶∫ÂåñÂúñËß£ÈáãÊñπÊ≥ïÂ≠òÂú®‰∏Ä‰∫õÁº∫Èô∑Ôºõiii) Rad4XCNN Ê≤íÊúâÁäßÁâ≤Ê®°ÂûãÊ∫ñÁ¢∫Â∫¶‰æÜÊèõÂèñÂÖ∂ÂèØËß£ÈáãÊÄßÔºõiv) Rad4XCNN Êèê‰æõ‰∫ÜÂÖ®Â±ÄËß£ÈáãË¶ãËß£Ôºå‰ΩøÈÜ´Â∏´ËÉΩÂ§†ÂàÜÊûêÊ®°ÂûãËº∏Âá∫ÂíåÁôºÁèæ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™øÂ∞áÂèØËß£ÈáãÊÄßÊï¥ÂêàÂà∞ AI Ê®°Âûã‰∏≠Â∞çÊñºÂ¢ûÂº∑Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑ‰ø°‰ªªÂíåÊé°Áî®Ëá≥ÈóúÈáçË¶ÅÔºå‰∏¶Âº∑Ë™ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïËÉΩÁ∑©Ëß£ËàáÂèØËß£Èáã AI ÊñπÊ≥ïÁõ∏ÈóúÁöÑ‰∏Ä‰∫õÁñëÊÖÆ„ÄÇ</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊôÆÂèäÊï¥ÂêàÔºåÂú®Ê∂âÂèä AI È©ÖÂãïÁ≥ªÁµ±ÁöÑ‰∫ãÊïÖ‰∏≠ÔºåË≤¨‰ªªÂíåÁæ©ÂãôÊ≠∏Â±¨Áî¢Áîü‰∫ÜË§áÈõúÁöÑÊåëÊà∞„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÁöÑ‰∫íÈÄ£ÊÄß„ÄÅAI ÂºïÁôº‰∫ãÊïÖÁöÑÂÄ´ÁêÜÂïèÈ°åÔºåÂä†‰∏ä AI ÊäÄË°ìÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåÁº∫‰πèÁõ∏ÊáâÊ≥ïË¶èÔºå‰ΩøÂæóÂÇ≥Áµ±Ë≤¨‰ªªÊ≠∏Â±¨Èù¢Ëá®ÊåëÊà∞„ÄÇÁÇ∫Ê≠§ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË®àÁÆóÂèçÊÄùÂùáË°° (CRE) ÊñπÊ≥ïÔºå‰ª•Âª∫Á´ã‰∏ÄÂÄãÈÄ£Ë≤´‰∏îÂú®ÂÄ´ÁêÜ‰∏äÂèØÊé•ÂèóÁöÑË≤¨‰ªªÊ≠∏Â±¨Êû∂ÊßãÔºåÈÅ©Áî®ÊñºÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫„ÄÇË®àÁÆóÊñπÊ≥ïÊèê‰æõ‰∫ÜÁµêÊßãÂåñÁöÑÂàÜÊûêÔºåÂÖãÊúç‰∫ÜÊ¶ÇÂøµÊñπÊ≥ïÂú®ËôïÁêÜÂãïÊÖã‰∏îÂ§öÈù¢ÂêëÊÉÖÂ¢ÉÊôÇÁöÑÈôêÂà∂ÔºåÂ±ïÁ§∫‰∫ÜË©≤Êû∂ÊßãÂú®Ë≤¨‰ªªÊ≠∏Â±¨ÈÅéÁ®ã‰∏≠ÂÖ∑ÂÇôÁöÑÂèØËß£ÈáãÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜËàáÂùáË°°Ë®àÁÆó‰∏≠Á¥¢Ë≥†Áõ∏ÈóúÁöÑÂàùÂßãÂïüÂãïÂ±§Á¥öÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÊàëÂÄë‰ª• AI ËºîÂä©ÈÜ´ÁôÇÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåË™™Êòé‰∏çÂêåÁöÑÂàùÂßãÂåñÂ¶Ç‰ΩïÂ∞éËá¥‰∏çÂêåÁöÑË≤¨‰ªªÂàÜÈÖç„ÄÇË©≤Êû∂ÊßãÊèê‰æõ‰∫ÜÂ∞ç AI ÂºïÁôº‰∫ãÊïÖ‰∏≠ÂïèË≤¨Âà∂ÁöÑÂØ∂Ë≤¥Ë¶ãËß£ÔºåÈÄèÈÅéÊåÅÁ∫åÁõ£Êéß„ÄÅ‰øÆË®ÇÂíåÂèçÊÄùÔºå‰øÉÈÄ≤‰∫ÜÊ∞∏Á∫å‰∏îÊúâÈüåÊÄßÁöÑÁ≥ªÁµ±ÁôºÂ±ï„ÄÇ

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÈÄèÈÅéÈ†êÊ∏¨Ê®°ÂûãÂçîÂä©ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÔºåÂ§ßÂπÖËΩâËÆä‰∫ÜËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºèÊôÇÂÖ¨Âπ≥ÊÄßÂíåÂèØËß£ÈáãÊÄßÁöÑÈóúÈçµÈúÄÊ±ÇÔºå‰ª•Á¢∫‰øùÂú®‰∏çÂêåÁöÑÊÇ£ËÄÖ‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰∏≠Áç≤ÂæóÂÖ¨Âπ≥ÁöÑÁµêÊûú„ÄÇÈÄèÈÅéÂ∞àÊ≥®ÊñºÊïóË°ÄÁóáÁõ∏ÈóúÊ≠ª‰∫°ÁéáÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊúÉÂ≠∏Áøí‰∏ÄÂÄãÊïàËÉΩÊúÄ‰Ω≥ÂåñÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÁÑ∂ÂæåÊé°Áî®ËΩâÁßªÂ≠∏ÁøíÈÅéÁ®ã‰æÜÁî¢Áîü‰∏ÄÂÄãÂÖ∑ÊúâÊõ¥Â•ΩÂÖ¨Âπ≥ÊÄßÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂü∫ÊñºÊéíÂàóÁöÑÁâπÂæµÈáçË¶ÅÊÄßÊºîÁÆóÊ≥ïÔºåÊó®Âú®Èó°ÊòéÊØèÂÄãÁâπÂæµÂú®Â¢ûÂº∑È†êÊ∏¨ÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÁöÑË≤¢Áçª„ÄÇËàáÁèæÊúâÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞àÊ≥®ÊñºËß£ÈáãÁâπÂæµÂ∞çÈ†êÊ∏¨ÊïàËÉΩÁöÑË≤¢Áçª‰∏çÂêåÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁç®ÁâπÂú∞ÂΩåË£ú‰∫ÜÁêÜËß£ÊØèÂÄãÁâπÂæµÂ¶Ç‰ΩïÊúâÂä©ÊñºÂÖ¨Âπ≥ÊÄßÁöÑÂ∑ÆË∑ù„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÊïóË°ÄÁóáÁöÑÊ≠ª‰∫°ÁéáÂæàÈ´òÔºå‰∏îÂú®‰∏âÂàÜ‰πã‰∏ÄÁöÑÈÜ´Èô¢Ê≠ª‰∫°‰∏≠ÊâÆÊºîËëóËßíËâ≤„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰∏çÂÉÖÊúâÂä©ÊñºË≠òÂà•ÂíåÊ∏õËºïÈ†êÊ∏¨Ê®°Âûã‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÈÇÑËÉΩÈÄèÈÅéÊèêÈ´òÊ®°ÂûãÈ†êÊ∏¨ÁöÑÈÄèÊòéÂ∫¶ÂíåÂÖ¨Âπ≥ÊÄß‰æÜÂüπÈ§äÈÜ´ÁôÇ‰øùÂÅ•Âà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÁöÑ‰ø°‰ªªÔºåÈÄ≤ËÄåÊúâÂä©ÊñºÊèê‰æõÊõ¥ÂÖ¨Âπ≥‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

ÊëòË¶ÅÔºöÁèæ‰ªäÔºåÊÜÇÈ¨±ÁóáÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑË≠∞È°å„ÄÇÊ†πÊìö‰∏ñÁïåË°õÁîüÁµÑÁπî (WHO) ÁöÑË≥áÊñôÔºåÂú® 2023 Âπ¥ÔºåË∂ÖÈÅé 2.8 ÂÑÑ‰∫∫Ê≠£Âú®ËàáÊÜÇÈ¨±ÁóáÊêèÈ¨•„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈæêÂ§ßÁöÑÊï∏Â≠óÔºõÂ¶ÇÊûú‰∏çË™çÁúüÁúãÂæÖÔºåÈÄô‰∫õÊï∏Â≠óÂ∞áÊúÉÂø´ÈÄüÂ¢ûÂä†„ÄÇÂ§ßÁ¥ÑÊúâ 48.9 ÂÑÑ‰∫∫ÊòØÁ§æÁæ§Â™íÈ´î‰ΩøÁî®ËÄÖ„ÄÇ‰∫∫ÂÄëÂú® Twitter„ÄÅFacebook„ÄÅReddit„ÄÅInstagram Á≠âÂπ≥Âè∞‰∏äË°®ÈÅîËá™Â∑±ÁöÑÊÑüÂèóÂíåÊÉÖÁ∑í„ÄÇÈÄô‰∫õÂπ≥Âè∞ÂåÖÂê´ÊúâÂÉπÂÄºÁöÑË≥áË®äÔºåÂèØÁî®ÊñºÁ†îÁ©∂ÁõÆÁöÑ„ÄÇÂ∑≤Á∂ìÂú®ÂêÑÁ®ÆÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏äÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂä™Âäõ‰ªçÂ≠òÂú®Êüê‰∫õÈôêÂà∂„ÄÇÁâπÂà•ÊòØÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂÉÖÂ∞àÊ≥®ÊñºÂÅµÊ∏¨Êé®Êñá‰∏≠ÁöÑÊÜÇÈ¨±ÁóáÂíåÊÜÇÈ¨±ÁóáÁöÑÂº∑Â∫¶„ÄÇÊ≠§Â§ñÔºåË≥áÊñôÈõÜÊ®ôÁ±§‰∏≠Â≠òÂú®‰∏çÊ∫ñÁ¢∫ÁöÑÊÉÖÊ≥Å„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂Â∑•‰Ωú‰∏≠Ôºå‰ΩøÁî®Âü∫ÊñºË©ûÂΩôÊ®ôÁ±§ÁöÑ Twitter Ë≥áÊñôÂ∫´‰∏≠ÁöÑÊé®ÊñáÈ†êÊ∏¨‰∫Ü‰∫îÁ®ÆÈ°ûÂûãÁöÑÊÜÇÈ¨±ÁóáÔºàÈõôÊ•µÂûã„ÄÅÈáçÂ∫¶„ÄÅÁ≤æÁ•ûÁóÖÂûã„ÄÅÈùûÂÖ∏ÂûãÂíåÁî¢ÂæåÔºâ„ÄÇÂèØËß£ÈáãÁöÑ AI Áî®ÊñºÈÄèÈÅéÂº∑Ë™ø‰ª£Ë°®ÊÜÇÈ¨±ÁóáÈ°ûÂûãÁöÑÊé®ÊñáÈÉ®ÂàÜ‰æÜÊèê‰æõÊé®ÁêÜ„ÄÇÂæû TransformersÔºàBERTÔºâ‰∏≠ÊèêÂèñÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®Á§∫Áî®ÊñºÁâπÂæµÊèêÂèñÂíåË®ìÁ∑¥„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁî®ÊñºË®ìÁ∑¥Ê®°Âûã„ÄÇBERT Ê®°ÂûãÂëàÁèæÂá∫ÊúÄÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÈÅîÂà∞ 0.96 ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v1 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÊ≠£ÂäáÁÉàÂú∞ËΩâËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊîæÂ∞ÑÂ≠∏È†òÂüüÔºåËÉΩË≠òÂà•ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÁóÖÁêÜÔºåÂåÖÊã¨ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) Âíå X ÂÖâÊéÉÊèè„ÄÇÁÑ∂ËÄåÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®ÂàÜÂâ≤‰ªªÂãô‰∏≠ÔºåÂ∏∏Â∏∏ÂèóÂà∞Âª£Ê≥õË®ªËß£Ë≥áÊñôÈõÜÈúÄÊ±ÇÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÈÄèÈÅéÂèØËß£Èáã AI ÂíåÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÁî¢ÁîüÔºåÊé¢Ë®é‰∫ÜÂº±Áõ£Áù£Ë™ûÊÑèÂàÜÂâ≤ÁöÑËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁØÑÂúçÊòØÈñãÁôº‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂèç‰∫ãÂØ¶ÂÖßÁπ™ÊñπÊ≥ï (COIN)ÔºåÂÆÉÈÄèÈÅé‰ΩøÁî®ÁîüÊàêÊ®°ÂûãÔºåÂ∞áÈ†êÊ∏¨ÂàÜÈ°ûÊ®ôÁ±§ÂæûÁï∞Â∏∏ÁøªËΩâÁÇ∫Ê≠£Â∏∏„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÂàÜÈ°ûÂô®Â∞áËº∏ÂÖ•ÈÜ´Â≠∏ÂΩ±ÂÉè X Ë¶ñÁÇ∫Áï∞Â∏∏ÔºåË°®Á§∫Â≠òÂú®ÁóÖÁêÜÔºåÁîüÊàêÊ®°ÂûãÊó®Âú®ÂÖßÁπ™Áï∞Â∏∏ÂçÄÂüüÔºåÂæûËÄåÈÄÜËΩâÂàÜÈ°ûÂô®ÁöÑÂéüÂßãÈ†êÊ∏¨Ê®ôÁ±§„ÄÇÊ≠§ÊñπÊ≥ï‰ΩøÊàëÂÄëËÉΩÂ§†Áî¢ÁîüÁóÖÁêÜÁöÑÁ≤æÁ¢∫ÂàÜÂâ≤ÔºåËÄå‰∏ç‰æùË≥¥ÊñºÈ†êÂÖàÂ≠òÂú®ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÂà©Áî®ÂΩ±ÂÉèÂ±§Á¥öÊ®ôÁ±§ÔºåÈÄôÊØîÂª∫Á´ãË©≥Á¥∞ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©ÂÆπÊòìÂèñÂæóÂæóÂ§ö„ÄÇË©≤ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈÄèÈÅéÂàÜÂâ≤ÂêàÊàêÁõÆÊ®ôÂíåÂæûÊÑõÊ≤ôÂ∞º‰∫ûÂ°îÁàæÂúñÂ§ßÂ≠∏ÈÜ´Èô¢ÂèñÂæóÁöÑ CT ÂΩ±ÂÉè‰∏≠ÁöÑÂØ¶ÈöõËÖéËáüËÖ´Áò§‰æÜË≠âÊòé„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåCOIN ÈÅ†ÈÅ†Ë∂ÖË∂ä‰∫ÜÊó¢ÂÆöÁöÑÊ≠∏Âõ†ÊñπÊ≥ïÔºå‰æãÂ¶Ç RISE„ÄÅScoreCAM Âíå LayerCAMÔºå‰ª•Âèä Singla Á≠â‰∫∫ÊèêÂá∫ÁöÑÂè¶‰∏ÄÁ®ÆÂèç‰∫ãÂØ¶Ëß£ÈáãÊñπÊ≥ï„ÄÇÊ≠§Ë≠âÊìöË°®ÊòéÔºåCOIN ÊòØ‰∏ÄÁ®ÆÂæàÊúâÂâçÊôØÁöÑ CT ÂΩ±ÂÉè‰∏≠ËÖ´Áò§Ë™ûÊÑèÂàÜÂâ≤ÊñπÊ≥ïÔºå‰∏¶Âú®‰ΩøÊ∑±Â∫¶Â≠∏ÁøíÊáâÁî®Âú®Ë®ªËß£Ë≥áÊñôÁ®ÄÁº∫ÁöÑÈÜ´ÁôÇ‰øùÂÅ•‰∏≠Êõ¥ÊòìÊñºÂèñÂæóÂíåÊõ¥ÊúâÊïàÊñπÈù¢ÈÇÅÈÄ≤‰∫Ü‰∏ÄÊ≠•„ÄÇ

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

ÊëòË¶ÅÔºöÁî≤ÁãÄËÖ∫ÁôåÊòØ‰∏ÄÁ®ÆÊó•ÁõäÂö¥ÈáçÁöÑÂÖ®ÁêÉÂÅ•Â∫∑ÂïèÈ°åÔºåÈúÄË¶ÅÂÖàÈÄ≤ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÇÊú¨ÁØáË©ïË´ñÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩËàáÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂú®Áî≤ÁãÄËÖ∫ÁôåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÂú®Á¨¶Âêà PRISMA ÊåáÂçóÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞çÂ§öÂÄãË≥áÊñôÂ∫´ÈÄ≤Ë°å‰∫ÜÂõûÈ°ßÔºåÁõ¥Âà∞ 2023 Âπ¥ 10 Êúà„ÄÇÈÄöÈÅéÁµêÂêàÈóúÈçµÂ≠óÔºåÁôºÁèæ‰∫Ü‰∏ÄÁØáÈóúÊñºÁî≤ÁãÄËÖ∫ÁôåÂíåÁõ∏Èóú‰∏ªÈ°åÁöÑËã±ÊñáÂ≠∏Ë°ìÂá∫ÁâàÁâ©„ÄÇÂú®ÁßªÈô§ 109 ÁØáÈáçË§áÊñáÁçªÂæåÔºåÂéüÂßãÊêúÂ∞ãÂÖ±ÂõûÂÇ≥ 267 ÁØáË´ñÊñá„ÄÇÂú®Ê†πÊìöÈ†êÂÖàÁ¢∫ÂÆöÁöÑÊ®ôÊ∫ñÔºåÊ∑òÊ±∞‰∫Ü 124 ÁØáÊñáÁ´†ÁöÑÊëòË¶ÅÂíåÊ®ôÈ°åÂæåÔºåÈÅ∏Âá∫‰∫ÜÁõ∏ÈóúÁ†îÁ©∂„ÄÇÂú®ÈÄ≤Ë°åÂÖ®Èù¢ÂàÜÊûêÂæåÔºåÈ°çÂ§ñÊéíÈô§‰∫ÜÂÖ≠È†ÖÁ†îÁ©∂„ÄÇÂú®Á¥çÂÖ•ÁöÑ 28 È†ÖÁ†îÁ©∂‰∏≠ÔºåÁµêÂêàË∂ÖÈü≥Ê≥¢ (US) ÂΩ±ÂÉèÁöÑÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Ë®∫Êñ∑Áî≤ÁãÄËÖ∫ÁôåÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûú‰∏ç‰∏ÄÔºåÊúâ‰∫õÁ†îÁ©∂ÊèêÂá∫‰∫ÜÂÑ™ÊñºÁèæÁãÄÁöÑÊñ∞Á≠ñÁï•„ÄÇÊñáÁçªÂº∑Ë™ø‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÈù¢Ëá®ÁöÑÂêÑÁ®ÆÊåëÊà∞ÔºåÂåÖÊã¨ÂèØËß£ÈáãÊÄßÂïèÈ°å„ÄÅË≥áÊñôÈõÜÈôêÂà∂ÂíåÊìç‰ΩúÂì°‰æùË≥¥ÊÄß„ÄÇ28 È†ÖÁ¥çÂÖ•Á†îÁ©∂ÁöÑÁ∂úÂêàÁôºÁèæÊèêÂà∞ÔºåÈúÄË¶ÅÊ®ôÊ∫ñÂåñÂ∑•‰ΩúÂíåÂâçÁûªÊÄßÂ§ö‰∏≠ÂøÉÁ†îÁ©∂‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÈÇÑÁ¢∫ÂÆö‰∫ÜÂÖãÊúçÈÄô‰∫õÈöúÁ§ôÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÂèØËß£Èáã‰∫∫Â∑•Êô∫ËÉΩÊäÄË°ìÂíåÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊäÄË°ìÁöÑÈÄ≤Ê≠•„ÄÇÊú¨ÁØáË©ïË´ñÈáçÈªûÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÂíåÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂ¶Ç‰ΩïËΩâËÆäÁî≤ÁãÄËÖ∫ÁôåÁöÑË®∫Êñ∑ÂíåÊ≤ªÁôÇ„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÊú™‰æÜÂ∞çÂ§öÂ≠∏ÁßëÂêà‰Ωú„ÄÅËá®Â∫äÈÅ©Áî®ÊÄßÈ©óË≠âÂíåÊºîÁÆóÊ≥ïÊîπÈÄ≤ÁöÑÁ†îÁ©∂Ôºå‰ªçÊúâÊΩõÂäõÊîπÂñÑÁî≤ÁãÄËÖ∫ÁôåÊ≤ªÁôÇ‰∏≠ÁöÑÊÇ£ËÄÖÈ†êÂæåÂíåË®∫Êñ∑Á≤æÊ∫ñÂ∫¶„ÄÇ

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºå‰π≥ÁôåÁöÑÁõõË°åÁéáËøÖÈÄüÂ¢ûÂä†Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÊ≠ª‰∫°ÂéüÂõ†‰πã‰∏Ä„ÄÇÂú®ÊâÄÊúâÁôåÁóá‰∏≠Ôºå‰π≥ÁôåËøÑ‰ªäÁÇ∫Ê≠¢ÊòØÊúÄÂ∏∏Ë¶ãÁöÑ„ÄÇÊâãÂãïË®∫Êñ∑Ê≠§ÁñæÁóÖÈúÄË¶ÅÂ§ßÈáèÁöÑÊôÇÈñìÂíåÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÁî±Êñº‰π≥ÁôåÁöÑÊ™¢Ê∏¨ÈÅéÁ®ãËÄóÊôÇÔºåÂõ†Ê≠§ÈÄèÈÅéÂª∫Á´ãÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨ÔºåÊúâÂä©ÊñºÈò≤Ê≠¢ÂÖ∂ÈÄ≤‰∏ÄÊ≠•Êì¥Êï£„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÂèØËß£Èáã AI Âú®ÂàÜÈ°û‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰∏çÂÉÖÂèØ‰ª•Êèê‰æõÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨ÔºåÈÇÑÂèØ‰ª•Ê∑±ÂÖ•‰∫ÜËß£Ê®°ÂûãÂ¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñÔºåÊúâÂä©ÊñºÁêÜËß£Âíå‰ø°Ë≥¥ÂàÜÈ°ûÁµêÊûú„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∏¶ÊØîËºÉ‰∫Ü‰∫îÁ®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄã‰∏ªË¶ÅÁöÑË≥áÊñôÈõÜÔºàÈÅîÂç°ÈÜ´Â≠∏Èô¢ÈÜ´Èô¢ÁöÑ 500 ÂêçÊÇ£ËÄÖÔºâ„ÄÇ‰∫îÁ®Æ‰∏çÂêåÁöÑÁõ£Áù£ÂºèÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÂåÖÊã¨Ê±∫Á≠ñÊ®π„ÄÅÈö®Ê©üÊ£ÆÊûó„ÄÅÈÇèËºØËø¥Ê≠∏„ÄÅÊú¥Á¥†Ë≤ùÊ∞èÂíå XGBoostÔºåÂ∑≤Áî®ÊñºÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÂèñÂæóÊúÄ‰Ω≥ÁµêÊûú„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂Â∞á SHAP ÂàÜÊûêÊáâÁî®Êñº XGBoost Ê®°ÂûãÔºå‰ª•Ëß£ÈáãÊ®°ÂûãÁöÑÈ†êÊ∏¨‰∏¶‰∫ÜËß£ÊØèÂÄãÁâπÂæµÂ∞çÊ®°ÂûãËº∏Âá∫ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÂπæÁ®ÆÊºîÁÆóÊ≥ïÂ∞çË≥áÊñôÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶ËàáË©≤È†òÂüüÁöÑÂÖ∂‰ªñÊñáÁçªÈÄ≤Ë°åÂ∞çÊØî„ÄÇÂú®ÊúÄÂæåË©ï‰º∞ÂæåÔºåÊú¨Á†îÁ©∂ÁôºÁèæ XGBoost ÈÅîÂà∞‰∫ÜÊúÄ‰Ω≥ÁöÑÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÔºåÁÇ∫ 97%„ÄÇ</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Áî®ÊñºÂæû‰π≥ÊàøÊîùÂΩ±Ë°ìÂΩ±ÂÉèË®∫Êñ∑‰π≥ÁôåÁöÑÊ®°ÂûãÈÄöÂ∏∏‰ª•„ÄåÈªëÁõíÂ≠ê„ÄçÊñπÂºèÈÅã‰ΩúÔºåÈÄô‰ΩøÂæóÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°Èõ£‰ª•‰ø°‰ªªÂíåÁêÜËß£ÂÖ∂Ê±∫Á≠ñÈÅéÁ®ã„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊï¥ÂêàÊû∂ÊßãÔºåÁµêÂêàÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)Ôºå‰ª•‰ΩøÁî® CBIS-DDSM Ë≥áÊñôÈõÜÂ¢ûÂº∑‰π≥ÁôåÁöÑË®∫Êñ∑„ÄÇÊñπÊ≥ïÂåÖÂê´‰∏ÄÂÄãÁ≤æÁ¥∞ÁöÑË≥áÊñôÂâçËôïÁêÜÁÆ°Á∑öÂíåÈÄ≤ÈöéË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÔºå‰ª•Â∞çÊäóË≥áÊñôÈõÜÈôêÂà∂Ôºå‰∏¶Êé°Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÁ∂≤Ë∑ØÔºà‰æãÂ¶Ç VGG-16„ÄÅInception-V3 Âíå ResNetÔºâÈÄ≤Ë°åÈÅ∑ÁßªÂ≠∏Áøí„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÈáçÈªûÊòØË©ï‰º∞ XAI Âú®Ëß£ÈáãÊ®°ÂûãÈ†êÊ∏¨‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÈáçÈªûÂà©Áî®Ë±™ÊñØÂ§öÂ§´Ê∏¨Â∫¶ÈáèÂåñË©ï‰º∞ AI ÁîüÊàêÁöÑËß£ÈáãÂíåÂ∞àÂÆ∂Ë®ªËß£‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñº XAI Âú®‰øÉÈÄ≤ AI ËºîÂä©Ë®∫Êñ∑‰∏≠ÁöÑÂèØ‰ø°Â∫¶ÂíåÂÄ´ÁêÜÂÖ¨Âπ≥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÁôºÁèæË™™Êòé‰∫Ü CNN Âíå XAI Âú®Êé®ÈÄ≤‰π≥ÁôåË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊúâÊïàÂçî‰ΩúÔºåÂæûËÄå‰øÉÈÄ≤‰∫ÜÂÖàÈÄ≤ AI ÊäÄË°ìÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊõ¥È†ÜÊö¢Êï¥Âêà„ÄÇÈÄèÈÅéÂ¢ûÂº∑ AI È©ÖÂãïÊ±∫Á≠ñÁöÑÂèØËß£ÈáãÊÄßÔºåÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ AI Á≥ªÁµ±ÂíåÈÜ´ÁôÇÂæûÊ•≠‰∫∫Âì°‰πãÈñìÁöÑÊîπÂñÑÂçî‰ΩúÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåÊúÄÁµÇË±êÂØå‰∫ÜÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂ÁöÑÂΩ±ÈüøÈÅ†ÈÅ†Ë∂ÖÂá∫‰∫ÜÁõÆÂâçÁöÑÊäÄË°ì„ÄÇÂÆÉÈºìÂãµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂Â¶Ç‰ΩïÁµêÂêàÂ§öÊ®°ÂºèË≥áÊñô‰∏¶ÊîπÂñÑ AI Ëß£ÈáãÔºå‰ª•ÊªøË∂≥Ëá®Â∫äÂØ¶ÂãôÁöÑÈúÄÊ±Ç„ÄÇ

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

ÊëòË¶ÅÔºö‰ª•‰∫∫‰∏∫Êú¨ÁöÑÂèØËß£Èáä AI (HCXAI) ÂÄ°ÂØºÂ∞ÜÁ§æ‰ºöÂ±ÇÈù¢Êï¥ÂêàÂà∞ AI Ëß£Èáä‰∏≠„ÄÇHCXAI ËØùËØ≠ÁöÑÊ†∏ÂøÉÊòØÁ§æ‰ºöÈÄèÊòéÂ∫¶ (ST) Ê°ÜÊû∂ÔºåÂÖ∂ÁõÆÊ†áÊòØËÆ© AI Á≥ªÁªüÁöÑÁ§æ‰ºöÁªÑÁªáËÉåÊôØÂØπÁî®Êà∑Êù•ËØ¥ÊòØÂèØÁêÜËß£ÁöÑ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Âª∫ËÆÆÊâ©Â±ï ST Ê°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏≠Á§æ‰ºöÈîôËØØÂΩíÂõ†ÁöÑÈ£éÈô©ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂøÉÁêÜÂÅ•Â∫∑Á≠âÊïèÊÑüÈ¢ÜÂüü„ÄÇ‰∫ãÂÆû‰∏äÔºåLLM ËÉΩÂ§üÂá∫Ëâ≤Âú∞Ê®°ÊãüËßíËâ≤Âíå‰∫∫Ê†ºÔºåËøôÂèØËÉΩÂØºËá¥ËÆæËÆ°ËÄÖÁöÑÊÑèÂõæÂíåÁî®Êà∑ÂØπÁ§æ‰ºöÂ±ûÊÄßÁöÑËÆ§Áü•‰πãÈó¥Âá∫Áé∞ÈîôÈÖçÔºå‰ªéËÄåÊúâÈ£éÈô©‰øÉËøõÊÉÖÁª™ÊìçÁ∫µÂíåÂç±Èô©Ë°å‰∏∫„ÄÅËÆ§Áü•‰∏çÂÖ¨Ê≠£Âíå‰∏çÂêàÁêÜÁöÑ‰ø°‰ªª„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨Âª∫ËÆÆÁî®Á¨¨‰∫î‰∏™‚ÄúW ÈóÆÈ¢ò‚ÄùÊù•Â¢ûÂº∫ ST Ê°ÜÊû∂Ôºå‰ª•ÊòéÁ°ÆËÆæËÆ°ËÄÖÂíåÁî®Êà∑Ëµã‰∫à LLM ÁöÑÂÖ∑‰ΩìÁ§æ‰ºöÂ±ûÊÄß„ÄÇÊ≠§Ë°•ÂÖÖÊó®Âú®Âº•Âêà LLM ËÉΩÂäõÂíåÁî®Êà∑ËÆ§Áü•‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰øÉËøõÂü∫‰∫é LLM ÁöÑÊäÄÊúØÂú®ÈÅìÂæ∑‰∏äË¥üË¥£‰ªªÂú∞ÂºÄÂèëÂíå‰ΩøÁî®„ÄÇ

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöÊ∞£ËÉ∏ÊòØ‰∏ÄÁ®ÆÂõ†ËÇ∫ÈÉ®ËàáËÉ∏Â£Å‰πãÈñìÁï∞Â∏∏ÈõÜÊ∞£ÊâÄÂºïËµ∑ÁöÑÊÄ•ÊÄßËÉ∏ËÖîÁñæÁóÖ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê∑±Â∫¶Â≠∏ÁøíÔºàDLÔºâÊ®°ÂûãÁ∂ìÂ∏∏‰º¥Èö®ÁöÑ‰∏çÈÄèÊòéÊÄßÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÊñπÊ≥ïÂ∑≤Ë¢´ÂºïÂÖ•ÔºåÁî®ÊñºÊ¶ÇËø∞Ëàá DL Ê®°ÂûãÂÅöÂá∫ÁöÑÊ∞£ËÉ∏Ë®∫Êñ∑Áõ∏ÈóúÁöÑÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËß£ÈáãÊúâÊôÇÊúÉËàáÂØ¶ÈöõÁóÖÁÅ∂ÂçÄÂüüÊúâÊâÄÂá∫ÂÖ•ÔºåÁ™ÅÈ°ØÂá∫ÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊñπÊ≥ïÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÂ∞áÊ∞£ËÉ∏ÁöÑËá®Â∫äÁü•Ë≠òÁ¥çÂÖ• XAI ÊñπÊ≥ïÁî¢ÁîüÁöÑÊ®°ÂûãËß£Èáã‰∏≠ÔºåÂæûËÄåÊèêÂçáÈÄô‰∫õËß£ÈáãÁöÑÂìÅË≥™„ÄÇÂà©Áî®ÊîæÂ∞ÑÁßëÈÜ´Â∏´Âª∫Á´ãÁöÑÁóÖÁÅ∂ÊèèÁπ™ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÁî¢Áîü‰∏ÄÂÄãÊ®°ÊùøÔºåÁî®ÊñºË°®Á§∫Ê∞£ËÉ∏ÂèØËÉΩÁôºÁîüÁöÑÂçÄÂüü„ÄÇÁÑ∂ÂæåÂ∞áÊ≠§Ê®°ÊùøÁñäÂä†Âú®Ê®°ÂûãËß£Èáã‰∏äÔºå‰ª•ÁØ©ÈÅ∏Âá∫Ë∂ÖÂá∫Ê®°ÊùøÈÇäÁïåÁöÑÁÑ°ÈóúËß£Èáã„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÂÖ∂ÊïàÂäõÔºåÊàëÂÄëÂ∞ç‰∏âÁ®Æ XAI ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÊØîËºÉÂàÜÊûêÔºåÂú®ÂÖ©ÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏≠Ëß£ÈáãÂÖ©ÂÄã DL Ê®°ÂûãÊôÇÔºåÂàÜÂà•Êé°Áî®Âíå‰∏çÊé°Áî®ÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞é„ÄÇÁµêÊûúÔºöÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Âª∫Á´ãÊñº‰∏âÁ®Æ XAI ÊñπÊ≥ï„ÄÅÂÖ©ÂÄã DL Ê®°ÂûãÂíåÂÖ©ÂÄãË≥áÊñôÈõÜÁöÑÂçÅ‰∫åÁ®ÆÂü∫Ê∫ñÊÉÖÂ¢É‰∏≠ÔºåÂßãÁµÇÊîπÂñÑ‰∫ÜÂü∫Ê∫ñ XAI ÊñπÊ≥ï„ÄÇÂú®ÊØîËºÉÊ®°ÂûãËß£ÈáãÂíåÁúüÂØ¶ÁóÖÁÅ∂ÂçÄÂüüÊôÇÔºåÈÄèÈÅéÂü∫Ê∫ñÊïàËÉΩÁöÑÊïàËÉΩÊîπÈÄ≤Ë®àÁÆóÂá∫ÁöÑÂπ≥ÂùáÂ¢ûÈáèÁôæÂàÜÊØîÁÇ∫‰∫§ÈõÜÊØîÔºàIoUÔºâÁöÑ 97.8% ÂíåÈ™∞Â≠êÁõ∏‰ººÊÄß‰øÇÊï∏ÔºàDSCÔºâÁöÑ 94.1%„ÄÇÁµêË´ñÔºöÂú®Ê∞£ËÉ∏Ë®∫Êñ∑ÁöÑËÉåÊôØ‰∏ãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÁî®ÊñºÊîπÂñÑ AI Ëß£Èáã„ÄÇÊàëÂÄëÈ†êÊúüÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞éÂ∞áÈÄèÈÅéÊï¥ÂêàËá®Â∫äÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÔºåÁÇ∫Èó°Êòé AI Ê®°ÂûãÂª∫Á´ã‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï„ÄÇ</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by S√©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂ÂâçÊ©üÂô®ÁøªË≠Ø (MT) È†òÂüü‰∏≠ÔºåTransformer Êû∂ÊßãËÑ´Á©éËÄåÂá∫ÔºåÊàêÁÇ∫ÈªÉÈáëÊ®ôÊ∫ñÔºåÁâπÂà•ÊòØÂ∞çÊñºÈ´òË≥áÊ∫êË™ûË®ÄÂ∞ç„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®éÂÖ∂Â∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÊïàËÉΩÔºåÂåÖÊã¨Ëã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûË™ûË®ÄÂ∞ç„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊú¨Á†îÁ©∂Ë≠òÂà•Âá∫ÊúÄ‰Ω≥Ë∂ÖÂèÉÊï∏ÂíåÂ≠êË©ûÊ®°ÂûãÈ°ûÂûãÔºå‰ª•È°ØËëóÊèêÈ´ò Transformer Ê®°ÂûãÂ∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÂìÅË≥™„ÄÇ
‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÂπ≥Ë°åË≥áÊñôÈõÜÁöÑÁ®ÄÁº∫ÊúÉÈòªÁ§ô MT ÁöÑÁôºÂ±ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈñãÁôº‰∫Ü gaHealthÔºåÈÄôÊòØÊÑõÁàæËò≠Ë™ûÁöÑÁ¨¨‰∏ÄÂÄãÈõôË™ûÂÅ•Â∫∑Ë≥áÊñôË™ûÊñôÂ∫´„ÄÇÂ∞àÊ≥®ÊñºÂÅ•Â∫∑È†òÂüüÔºå‰ΩøÁî®Ê≠§ÂüüÂÖßË≥áÊñôÈõÜÈñãÁôºÁöÑÊ®°ÂûãÂú® BLEU ÂæóÂàÜÊñπÈù¢Ë°®ÁèæÂá∫ÈùûÂ∏∏È°ØËëóÁöÑÈÄ≤Ê≠•ÔºåËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÊ®°ÂûãÁõ∏ÊØî„ÄÇÈö®Âæå‰ΩøÁî®Â§öÁ∂≠ÂìÅË≥™ÊåáÊ®ôÈåØË™§ÂàÜÈ°ûÊ≥ïÈÄ≤Ë°åÁöÑ‰∫∫Â∑•Ë©ï‰º∞È°ØÁ§∫ÔºåËàáÂü∫Êñº RNN ÁöÑÂ∞çÊáâÊ®°ÂûãÁõ∏ÊØîÔºåTransformer Á≥ªÁµ±Âú®Ê∏õÂ∞ëÊ∫ñÁ¢∫ÊÄßÂíåÊµÅÊö¢ÊÄßÈåØË™§ÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩ„ÄÇ
Ê≠§Â§ñÔºåÊú¨Ë´ñÊñá‰ªãÁ¥π‰∫Ü adaptNMT Âíå adaptMLLMÔºåÈÄôÂÖ©ÂÄãÈñãÊ∫êÊáâÁî®Á®ãÂºèÁ∞°Âåñ‰∫ÜÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÊ®°ÂûãÁöÑÈñãÁôº„ÄÅÂæÆË™øÂíåÈÉ®ÁΩ≤„ÄÇÈÄô‰∫õÂ∑•ÂÖ∑Â§ßÂπÖÁ∞°Âåñ‰∫ÜË®≠ÂÆöÂíåË©ï‰º∞ÊµÅÁ®ãÔºåËÆì MT Êõ¥ÂÆπÊòìËÆìÈñãÁôº‰∫∫Âì°ÂíåÁøªË≠Ø‰∫∫Âì°‰ΩøÁî®„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåadaptNMT ‰ª• OpenNMT ÁîüÊÖãÁ≥ªÁµ±ÁÇ∫Âü∫Á§éÔºåÈÄöÈÅéÂº∑Ë™øÊ®°ÂûãÈñãÁôºÁöÑÁí∞Â¢ÉË∂≥Ë∑°‰æÜ‰øÉÈÄ≤ÁîüÊÖãÂèãÂ•ΩÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ†îÁ©∂„ÄÇËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåadaptMLLM Â∞ç MLLM ÁöÑÂæÆË™øË≠âÊòé‰∫ÜËã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûÈÄôÂÖ©ÂÄã‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÊÄßËÉΩÈÄ≤Ê≠•„ÄÇ</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖÔºàDMÔºâ‰ΩøÊÇ£ËÄÖÂÆπÊòìÂá∫ÁèæË°ÄÁÆ°‰ΩµÁôºÁóá„ÄÇ
Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂíåË°ÄÁÆ°ÂèçÊò†Ë∫´È´îÁöÑÂæÆË°ÄÁÆ°ÂíåÂ∑®Ë°ÄÁÆ°ÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇÂÆÉÂÄëÂèØÁî®ÊñºË®∫Êñ∑Á≥ñÂ∞øÁóÖ‰ΩµÁôºÁóáÔºåÂåÖÊã¨Á≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÔºàDRÔºâ„ÄÅÁ•ûÁ∂ìÁóÖËÆä„ÄÅËÖéÁóÖÂíåÂãïËÑàÁ≤•Ê®£Á°¨ÂåñÊÄßÂøÉË°ÄÁÆ°ÁñæÁóÖÔºå‰ª•ÂèäÈ†êÊ∏¨ÂøÉË°ÄÁÆ°‰∫ã‰ª∂ÁöÑÈ¢®Èö™„ÄÇÁÇ∫‰ΩøÁî®Êï∏‰ΩçÂåñË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÈÄ≤Ë°åÈ´òÈÄöÈáè DR Ê™¢Ê∏¨ËÄåÈñãÁôºÁöÑ‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂïüÁî®Á≥ªÁµ±Â∑≤Âú®Ëá®Â∫äÊé°Áî®„ÄÇÈô§‰∫Ü DR ÁØ©Ê™¢Â§ñÔºåAI Êï¥Âêà‰πüÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ‰æÜÊáâÂ∞çËàáÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖÊï¥È´îÁÖßË≠∑Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÂÖ®Èù¢ÂõûÈ°ßÂü∫ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÁöÑ AI ÊáâÁî®Áõ∏ÈóúÁ†îÁ©∂ÁöÑÊñáÁçªÔºåÈÄô‰∫õÁ†îÁ©∂ËàáÁ≥ñÂ∞øÁóÖÁöÑË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊúâÈóú„ÄÇÊàëÂÄëÂ∞áÊèèËø∞Êï¥È´î AI ËºîÂä©Á≥ñÂ∞øÁóÖÁÖßË≠∑ÁöÑÁôºÁèæÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôêÊñº DR ÁØ©Ê™¢Ôºå‰∏¶Ë®éË´ñÂØ¶ÊñΩÊ≠§È°ûÁ≥ªÁµ±ÁöÑÈöúÁ§ôÔºåÂåÖÊã¨ËàáÂÄ´ÁêÜ„ÄÅË≥áÊñôÈö±ÁßÅ„ÄÅÂÖ¨Âπ≥Â≠òÂèñÂíåÂèØËß£ÈáãÊÄßÊúâÈóúÁöÑÂïèÈ°å„ÄÇÈÄèÈÅéË©ï‰º∞ÊÇ£ËÄÖÁöÑÂÅ•Â∫∑ÁãÄÊ≥ÅÔºåÂêåÊôÇËÄÉÈáèÁ≥ñÂ∞øÁóÖ‰ΩµÁôºÁóá‰ª•ÂèäÊú™‰æÜÂøÉË°ÄÁÆ°‰ΩµÁôºÁóáÁöÑÈ¢®Èö™È†êÂæåÔºåAI ËºîÂä©Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂàÜÊûêÊúâÊΩõÂäõÊàêÁÇ∫Á≥ñÂ∞øÁóÖÊÇ£ËÄÖÁèæ‰ª£ÂåñÂÄã‰∫∫ÂåñÈÜ´ÁôÇÁöÑ‰∏≠ÂøÉÂ∑•ÂÖ∑„ÄÇ

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÁ†îÁ©∂ÂæûÂ§öÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑËßíÂ∫¶Êé¢Ë®é‰∏çÂêåÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊáâÁî®Âú®ÊïôËÇ≤‰∏äÁöÑÂèØÊé•ÂèóÊÄßÔºåÂåÖÊã¨Â≠∏Áîü„ÄÅËÄÅÂ∏´ÂíåÂÆ∂Èï∑„ÄÇÊâøË™ç AI Âú®ÊïôËÇ≤‰∏äÁöÑËΩâÂûãÊΩõÂäõÔºåÂÆÉËß£Ê±∫‰∫ÜËàáË≥áÊñôÈö±ÁßÅ„ÄÅAI ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíå AI ÁöÑÈÅìÂæ∑ÈÉ®ÁΩ≤Áõ∏ÈóúÁöÑÁñëÊÖÆ„ÄÇÈÄèÈÅéÂ∞èÊèíÊõ≤ÊñπÊ≥ïÔºåÂèÉËàáËÄÖË¢´ÂëàÁèæ‰∫ÜÂõõÁ®ÆÊÉÖÂ¢ÉÔºåÂÖ∂‰∏≠ AI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈö±ÁßÅÂèóÂà∞ÊìçÁ∏±„ÄÇÂú®ÊØèÂÄãÊÉÖÂ¢ÉÂæåÔºåÂèÉËàáËÄÖÂÆåÊàê‰∫Ü‰∏ÄÈ†ÖË™øÊü•ÔºåË©≤Ë™øÊü•ÊçïÊçâ‰∫Ü‰ªñÂÄëÂ∞ç AI ÁöÑÊï¥È´îÊïàÁî®„ÄÅÂÄã‰∫∫ÊïàÁî®„ÄÅÊ≠£Áæ©„ÄÅ‰ø°ÂøÉ„ÄÅÈ¢®Èö™ÂíåÂ¶ÇÊûúÂèØÁî®Ôºå‰ΩøÁî®ÊØèÂÄãÊÉÖÂ¢ÉÁöÑ AI ÁöÑÊÑèÂúñÁöÑÁúãÊ≥ï„ÄÇË≥áÊñôËíêÈõÜÂåÖÂê´‰æÜËá™Âêà‰ΩúÊ©üÊßãÂíåÁ§æÁæ§Â™íÈ´îÊ¥ªÂãïÁöÑ 1198 ‰ΩçÂ§öÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèÉËàáËÄÖÁöÑÊúÄÁµÇÊ®£Êú¨Ôºå‰∏¶Â∞àÊ≥®ÊñºÂ∞çÂõõÂÄã AI ‰ΩøÁî®Ê°à‰æãÁöÑÂÄãÂà•ÂõûÊáâ„ÄÇÂ∞çË≥áÊñôÁöÑË™øËß£ÂàÜÊûêË°®ÊòéÔºåÂ∞ç AI ÁöÑÊé•ÂèóÂ∫¶Âíå‰ø°‰ªªÂú®Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÂúòÈ´î‰πãÈñìÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁôºÁèæÔºåAI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÈ´ò‰ΩéÁ®ãÂ∫¶‰πãÈñìÁöÑÈóúÈçµË™øËß£ËÄÖÔºå‰ª•Âèä‰ΩøÁî®‰∏çÂêåÊïôËÇ≤ AI ÁöÑÊÑèÂúñÔºåÂåÖÊã¨ÊÑüÁü•Âà∞ÁöÑÊï¥È´îÊïàÁî®„ÄÅÊ≠£Áæ©Âíå‰ø°ÂøÉ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™øÔºåÊé•Âèó AI Âú®ÊïôËÇ≤‰∏äÁöÑÊáâÁî®ÊòØ‰∏ÄÂÄãÂæÆÂ¶ô‰∏îÂ§öÈù¢ÂêëÁöÑÂïèÈ°åÔºåÈô§‰∫Ü‰∏çÂêåÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÁúãÊ≥ïÂ§ñÔºåÈÇÑÈúÄË¶Å‰ªîÁ¥∞ËÄÉÊÖÆÂÖ∑È´îÁöÑ AI ÊáâÁî®ÂèäÂÖ∂ÁâπÂæµ„ÄÇ

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÂèØÁ©øÊà¥ÂºèÂñÆÂ∞éÁ®ãÂøÉÈõªÂúñ (ECG) Ë£ùÁΩÆÁöÑÈÅ†Á´ØÁóÖÊÇ£Áõ£Ê∏¨Âú®Êó©ÊúüÂÅµÊ∏¨ÂøÉËáüÁñæÁóÖÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØËàáÁî®ÊñºËá™ÂãïÂåñÂøÉËáüÁñæÁóÖÂÅµÊ∏¨ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÁµêÂêà‰ΩøÁî®ÊôÇ„ÄÇÂÖàÂâçÂ∑≤ÊúâÁ†îÁ©∂ÊáâÁî®Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑ AI ÊñπÊ≥ïÈÄ≤Ë°åÂøÉËáüÁñæÁóÖÂÅµÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂ∞öÊú™Ë¢´Âª£Ê≥õÊé•ÂèóÁÇ∫Ëá®Â∫äË®∫Êñ∑ÁöÑÂèØÈù†ËºîÂä©Â∑•ÂÖ∑ÔºåÈÉ®ÂàÜÂéüÂõ†Âú®ÊñºÂúçÁπûË®±Â§ö AI ÊºîÁÆóÊ≥ïÁöÑÁï∂ÂâçÈªëÁÆ±ÊÑüÁü•„ÄÇÁâπÂà•ÊòØÔºåÊúâÂøÖË¶ÅÊâæÂá∫ÊúâÂä©ÊñºÂÅöÂá∫Ê∫ñÁ¢∫Ë®∫Êñ∑ÁöÑ ECG Ë®äËôüÈóúÈçµÁâπÂæµÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÔºå‰ª•Ê†πÊìöÂñÆÂ∞éÁ®ã ECG Ë≥áÊñôÊâæÂá∫ÂøÉÊàøÈ°´Âãï„ÄÇÊÆòÂ∑ÆÁ∂≤Ë∑Ø (ResNet) ÊñπÊ≥ï‰πüÂ∑≤ÈñãÁôºÂá∫‰æÜÔºå‰ª•‰æøËàáË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÈÄô‰∫õÊ®°ÂûãÊáâÁî®Êñº Chapman-Shaoxing Ë≥áÊñôÈõÜÔºå‰ª•ÂàÜÈ°ûÂøÉÊàøÈ°´ÂãïÔºå‰ª•ÂèäÂè¶‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÂøÉÂæã‰∏çÊï¥ÔºåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÔºåÂíåÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãÁöÑÂøÉË∑≥„ÄÇÈÄô‰∫õÊ®°ÂûãËÉΩÂ§†ÊâæÂá∫Ê±∫ÂÆöÊúÄÁµÇÂàÜÈ°ûÁöÑÂøÉË∑≥ÈóúÈçµÂçÄÂüüÔºå‰∏¶Âº∑Ë™ø P Ê≥¢Âíå T Ê≥¢Ôºå‰ª•ÂèäÂøÉË∑≥ÊåÅÁ∫åÊôÇÈñìÂíåË®äËôüÊåØÂπÖÂú®ÂçÄÂàÜÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãËàáÂøÉÊàøÈ°´ÂãïÂíåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®ÂÖàÈÄ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÂíåÊ≤ªÁôÇÁöÑÊñ∞Ê®°ÂºèÔºöÁîüÊàêÂºèÈ†êË®ìÁ∑¥Transformer 4 (GPT-4)„ÄÅLlama 2 ËÅäÂ§©Ê©üÂô®‰∫∫Âíå Gemini„ÄÇÈÄô‰∫õ LLM Á∂ìÈÅéÂæÆË™øÔºåÂÖ∑ÂÇôÂ∞àÊ•≠ÊèêÁ§∫ÔºåÂèØË®∫Êñ∑„ÄÅËß£Èáã‰∏¶Âª∫Ë≠∞ÊÜÇÈ¨±ÁóáÁöÑÊ≤ªÁôÇ‰ªãÂÖ•ÊñπÊ≥ï„ÄÇ‰∏ÄÁ®ÆÁç®ÁâπÁöÑÂ∞ëÊ¨°ÊèêÁ§∫ÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÊ†πÊìö DSM-5 Ê®ôÊ∫ñÂàÜÊûêÂíåËß£ÈáãÊÜÇÈ¨±ÁóáÁãÄÁöÑËÉΩÂäõ„ÄÇÂú®‰∫íÂãïÈöéÊÆµÔºåÈÄô‰∫õÊ®°ÂûãÊúÉÂèÉËàáÂêåÁêÜÂøÉÂ∞çË©±ÁÆ°ÁêÜÔºåÂæû PsychDB ÂíåË™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÊåáÂçóÁ≠âË≥áÊ∫ê‰∏≠Ê±≤ÂèñÔºå‰øÉÈÄ≤ËàáÁ∂ìÊ≠∑ÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÁöÑ‰∫∫ÂÄëÁöÑÊîØÊåÅÊÄß‰∫íÂãï„ÄÇÊ≠§Â§ñÔºåÈÄôÈ†ÖÁ†îÁ©∂ÈÇÑ‰ªãÁ¥π‰∫Ü Illuminate Ë≥áÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂêÑÁ®Æ CBT Ê®°ÁµÑÔºåÊúâÂä©ÊñºÂÄãÊÄßÂåñÊ≤ªÁôÇÂª∫Ë≠∞„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰ΩøÁî® F1 ÂàÜÊï∏„ÄÅÊ∫ñÁ¢∫Áéá„ÄÅÂè¨ÂõûÁéá„ÄÅÈ§òÂº¶Áõ∏‰ººÂ∫¶ÂíåÈù¢ÂêëÂè¨ÂõûÁéáÁöÑ Gisting Ë©ï‰º∞ÊõøË∫´ (ROUGE) Á≠âÊåáÊ®ôÔºåÂú®‰∏çÂêåÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠Ë©ï‰º∞ LLM ÁöÑË°®ÁèæÔºåË≠âÊòé‰∫ÜÂÆÉÂÄëÁöÑÊúâÊïàÊÄß„ÄÇÈÄôÁ®ÆÁ∂úÂêàÊñπÊ≥ïÁµêÂêà‰∫ÜÂ∞ñÁ´ØÁöÑ AI ËàáÊó¢ÂÆöÁöÑÂøÉÁêÜÊñπÊ≥ïÔºåÁÇ∫ÂøÉÁêÜ‰øùÂÅ•Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫Ü LLM Âú®Èù©Êñ∞ÊÜÇÈ¨±ÁóáË®∫Êñ∑ÂíåÊ≤ªÁôÇÁ≠ñÁï•ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by Timoth√©e Schmude, Laura Koesten, Torsten M√∂ller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑË™™ÊòéÂæàÂ∞ëËÉΩÊªøË∂≥ÂèóÊºîÁÆóÊ≥ïÊ±∫Á≠ñ (ADM) ÂΩ±ÈüøÁöÑ‰∫∫ÂÄëÁöÑË≥áË®äÈúÄÊ±Ç„ÄÇÂÇ≥ÈÅîÁöÑË≥áË®äËàáÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÈáçË¶ÅÁöÑË≥áË®ä‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÂèØËÉΩÊúÉÈòªÁ§ô‰∫ÜËß£ÂíåÈÅµÂÆàÊ≥ïË¶èÊû∂ÊßãÔºå‰æãÂ¶Ç‰∫∫Â∑•Êô∫ÊÖßÊ≥ïÊ°à„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü„ÄåXAI ÂàùÂ≠∏ËÄÖÂïèÈ°åÂ∫´„ÄçÔºöÂèóÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫Ë≥áË®äÈúÄÊ±ÇÁöÑÁõÆÈåÑÔºåÊ∂µËìãÂÖ©ÂÄã ADM ‰ΩøÁî®Ê°à‰æãÔºàÂ∞±Ê•≠È†êÊ∏¨ÂíåÂÅ•Â∫∑Áõ£Ê∏¨ÔºâÔºåÊ∂µËìãË≥áÊñô„ÄÅÁ≥ªÁµ±ËÑàÁµ°„ÄÅÁ≥ªÁµ±‰ΩøÁî®ÂíåÁ≥ªÁµ±Ë¶èÊ†ºÈ°ûÂà•„ÄÇË≥áË®äÈúÄÊ±ÇÊòØÈÄèÈÅéË®™Ë´áÁ†îÁ©∂Êî∂ÈõÜÁöÑÔºåÂèÉËàáËÄÖÂú®Ë©¢ÂïèÂæåÊî∂Âà∞Ë™™Êòé„ÄÇÂèÉËàáËÄÖÈÄ≤‰∏ÄÊ≠•ÂõûÂ†±‰ªñÂÄëÁöÑÁêÜËß£ÂíåÊ±∫Á≠ñ‰ø°ÂøÉÔºåÈ°ØÁ§∫ÈõñÁÑ∂Âú®Êî∂Âà∞Ë™™ÊòéÂæå‰ø°ÂøÉÂÇæÂêëÊñºÂ¢ûÂä†Ôºå‰ΩÜÂèÉËàáËÄÖ‰πüÈÅáÂà∞‰∫ÜÁêÜËß£ÊåëÊà∞Ôºå‰æãÂ¶ÇÁÑ°Ê≥ïË™™ÊòéÁÇ∫‰ªÄÈ∫º‰ªñÂÄëÁöÑÁêÜËß£ÊÑüË¶∫‰∏çÂÆåÊï¥„ÄÇË™™ÊòéÈÄ≤‰∏ÄÊ≠•ÂΩ±ÈüøÂèÉËàáËÄÖÂ∞çÁ≥ªÁµ±È¢®Èö™ÂíåÂ•ΩËôïÁöÑÁúãÊ≥ïÔºå‰ªñÂÄëÊúÉÊ†πÊìö‰ΩøÁî®Ê°à‰æãÁ¢∫Ë™çÊàñÊîπËÆäÈÄô‰∫õÁúãÊ≥ï„ÄÇÁï∂È¢®Èö™Ë¢´Ë™çÁÇ∫ÂæàÈ´òÊôÇÔºåÂèÉËàáËÄÖË°®Á§∫ÁâπÂà•ÊúâËààË∂£‰∫ÜËß£ÊÑèÂúñÁöÑË™™ÊòéÔºå‰æãÂ¶ÇÁÇ∫‰ªÄÈ∫º‰ª•ÂèäÁÇ∫‰∫Ü‰ªÄÈ∫ºÁõÆÁöÑËÄåÂª∫Á´ãÁ≥ªÁµ±„ÄÇÈÄèÈÅéÈÄôÈ†ÖÂ∑•‰ΩúÔºåÊàëÂÄëÊó®Âú®ÈÄèÈÅéÂú®Ê±∫Á≠ñÊé°Áî® ADM Á≥ªÁµ±ÊôÇÊèê‰æõÁõ∏ÈóúË≥áË®äÂíåÊåëÊà∞ÁöÑÊ¶ÇË¶ΩÔºå‰æÜÊîØÊè¥Â∞áÂèóÂΩ±ÈüøÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫Á¥çÂÖ•ÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÊúÄÂæåÁ∏ΩÁµêÊàëÂÄëÁöÑÁôºÁèæÔºåÂàóÂá∫ÂÖ≠È†ÖÈóúÈçµÂΩ±ÈüøÔºåÈÄô‰∫õÂΩ±ÈüøÊúÉÂëäÁü•Êú™‰æÜÈáùÂ∞çÂèóÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèóÁúæË™™ÊòéÁöÑË®≠Ë®à„ÄÇ</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet G√ºrkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÊºîÈÄ≤ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁîüÊàêÂºè AI ÁöÑÈ†òÂüüÔºåÁÇ∫ÂêÑÂÄãÈ†òÂüüÁöÑÊáâÁî®ÈñãÂïü‰∫ÜÊñ∞ÈÄîÂæëÔºå‰ΩÜÂÖ∂Âú®ÂïÜÊ•≠ÊïôËÇ≤‰∏≠ÁöÑËßíËâ≤‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨Á†îÁ©∂È¶ñÊ¨°ÂºïÂÖ•‰∫ÜÂü∫Ê∫ñÔºåÁî®‰ª•Ë©ï‰º∞‰∏ÉÂÄã‰∏ªË¶Å LLM ÁöÑÊïàËÉΩÔºåÂåÖÊã¨ OpenAI ÁöÑÊ®°Âûã (GPT-3.5 Turbo„ÄÅGPT-4 Âíå GPT-4 Turbo)„ÄÅGoogle ÁöÑÊ®°Âûã (PaLM 2„ÄÅGemini 1.0 Pro) Âíå Anthropic ÁöÑÊ®°Âûã (Claude 2 Âíå Claude 2.1)ÔºåÈÄô‰∫õÊ®°ÂûãÂ∞áÁî®ÊñºÁ†îÁ©∂ÁîüÂïÜÊ•≠Ë™≤Á®ãÂÖ•Â≠∏Á®ãÂ∫è‰∏≠ÁöÑÈóúÈçµËÄÉË©¶ GMAT„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂ§ßÂ§öÊï∏ LLM ÁöÑË°®ÁèæÈÉΩÂÑ™Êñº‰∫∫È°ûËÄÉÁîüÔºåÂÖ∂‰∏≠ GPT-4 Turbo ‰∏çÂÉÖÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåÊõ¥Ë∂ÖË∂ä‰∫ÜÈ†ÇÂ∞ñÂïÜÂ≠∏Èô¢ÁöÑÁ†îÁ©∂ÁîüÂπ≥ÂùáÂàÜÊï∏„ÄÇÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü GPT-4 Turbo Âú®Ëß£ÈáãÁ≠îÊ°à„ÄÅË©ï‰º∞ÂõûÊáâ„ÄÅËæ®Ë≠òÈåØË™§„ÄÅË™øÊï¥Ë™™ÊòéÂíåÁî¢ÁîüÊõø‰ª£ÊÉÖÂ¢ÉÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇËàáÂâç‰∏Ä‰ª£ÁâàÊú¨Áõ∏ÊØîÔºåÊúÄÊñ∞ÁöÑ LLM ÁâàÊú¨ GPT-4 Turbo„ÄÅClaude 2.1 Âíå Gemini 1.0 Pro Âú®Êé®ÁêÜ‰ªªÂãôÊñπÈù¢ÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂá∏È°Ø‰∫ÜÂÖ∂Âú®Ëß£Ê±∫Ë§áÈõúÂïèÈ°åÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ° AI Âú®ÊïôËÇ≤„ÄÅË©ïÈáèÂíåËºîÂ∞éÊñπÈù¢ÁöÑÊâøË´æÂæàÊòéÁ¢∫Ôºå‰ΩÜ‰ªçÊúâÊåëÊà∞Â≠òÂú®„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÈó°Êòé‰∫Ü LLM ÁöÑÂ≠∏Ë°ìÊΩõÂäõÔºå‰πüÂº∑Ë™ø‰∫ÜÂú®ÊïôËÇ≤‰∏≠ÂØ©ÊÖéÈñãÁôºÂíåÊáâÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇÈö®Ëëó AI ÊäÄË°ìÁöÑÈÄ≤Ê≠•ÔºåÂª∫Á´ã AI ‰∫íÂãïÁöÑÊû∂ÊßãÂíåÂçîÂÆö„ÄÅÈ©óË≠â AI ÁîüÊàêÁöÑÂÖßÂÆπÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÁ¢∫‰øùÂÖ®ÁêÉÂêÑÂú∞Â§öÂÖÉÂ≠∏ÁøíËÄÖÁöÑÂ≠òÂèñÊ¨äÔºå‰ª•ÂèäÂâµÈÄ†‰∏ÄÂÄã AI ÊîØÊåÅ‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÁöÑÊïôËÇ≤Áí∞Â¢ÉËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÁÇ∫ÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî® AI ‰æÜË±êÂØåÊïôËÇ≤È´îÈ©ó‰∏¶ÊîπÂñÑËÄÉË©¶Ê∫ñÂÇôÂíåË©ïÈáèÊñπÊ≥ïÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

ÊëòË¶ÅÔºöÈ†êÊ∏¨Âä†Ë≠∑ÁóÖÊàø (ICU) ÁóÖÊÇ£ÁöÑÈô¢ÂÖßÊ≠ª‰∫°ÁéáÊòØÊúÄÁµÇËá®Â∫äÁµêÊûúÁöÑÈóúÈçµ„ÄÇAI Â∑≤Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂçªÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÂ§öÊ®°ÂºèÊ≠ª‰∫°ÁéáÈ†êÊ∏¨Âô® (X-MMP)ÔºåÊé°Áî®ÊúâÊïà‰∏îÂèØËß£ÈáãÁöÑ AI ÊñπÂºèÔºåËóâÁî±Â§öÊ®°Âºè ICU Ë≥áÊñô‰æÜÈ†êÊ∏¨Èô¢ÂÖßÊ≠ª‰∫°Áéá„ÄÇÊàëÂÄëÂú®Êû∂Êßã‰∏≠Êé°Áî®Â§öÊ®°ÂºèÂ≠∏ÁøíÔºåÂèØ‰ª•Êé•Êî∂‰æÜËá™Ëá®Â∫äË≥áÊñôÁöÑÁï∞Ë≥™Ëº∏ÂÖ•‰∏¶ÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂàÜÂ±§ÂÇ≥Êí≠Ëá≥ TransformerÔºå‰ΩúÁÇ∫ LRP ÊñπÊ≥ïÈÅ©Áï∂Âú∞Âª∂‰º∏Ëá≥ TransformerÔºåÂ∞çÂ§öÊ®°ÂºèËº∏ÂÖ•Áî¢ÁîüËß£ÈáãÔºå‰∏¶Êè≠Èú≤Ê≠∏Âõ†ÊñºÈ†êÊ∏¨ÁöÑÈ°ØËëóÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊØèÂÄãÊ®°ÂºèÂ∞çËá®Â∫äÁµêÊûúÁöÑË≤¢ÁçªÂèØ‰ª•Ë¶ñË¶∫ÂåñÔºåÂçîÂä©Ëá®Â∫äÈÜ´Â∏´‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÁêÜÁî±„ÄÇÊàëÂÄëÊ†πÊìö MIMIC-III Âíå MIMIC-III Ê≥¢ÂΩ¢Ë≥áÊñôÂ∫´ÊØîÂ∞çÂ≠êÈõÜÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÂºèË≥áÊñôÈõÜ„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÂèØ‰ª•ÈÅîÊàêÂêàÁêÜÁöÑË©ÆÈáãÔºå‰∏¶ÂÖ∑ÂÇôÁ´∂Áà≠ÂäõÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•ËºïÈ¨ÜÂú∞ËΩâÁßªÂà∞ÂÖ∂‰ªñËá®Â∫ä‰ªªÂãôÔºåÈÄôÊúâÂä©ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂‰∏≠ÁôºÁèæÈóúÈçµÂõ†Á¥†„ÄÇ

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Gei√üler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Bj√∂rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias K√ºster, Andr√© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÁöÑÂçÅÂπ¥‰∏≠ÔºåÁóÖÁêÜÂ≠∏‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÂ∑≤Â§ßÂπÖÈÄ≤Ê≠•„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË®±Â§öÊåëÊà∞ÔºåÂåÖÊã¨Â∞áÁ†îÁ©∂ÁµêÊûúËΩâÂåñÁÇ∫Ëá®Â∫äË®∫Êñ∑Áî¢ÂìÅÂú®ÊäÄË°ìÂíåÊ≥ïË¶èÊñπÈù¢ÁöÑÈöúÁ§ôÔºå‰ª•ÂèäÁº∫‰πèÊ®ôÊ∫ñÂåñ‰ªãÈù¢ÔºåÂ∞éËá¥Êï¥ÂêàÂà∞Â∏∏Ë¶èËá®Â∫äÂØ¶Âãô‰∏≠ÈÄ≤Â±ïÁ∑©ÊÖ¢„ÄÇÈñãÊîæ‰∏îËàá‰æõÊáâÂïÜÁÑ°ÈóúÁöÑ EMPAIA Ë®àÁï´ÊáâÂ∞ç‰∫ÜÈÄô‰∫õÊåëÊà∞„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèê‰æõ EMPAIA ÁöÑÊàêÂ∞±ÂíåÁ∂ìÈ©óÊïôË®ìÁöÑÊ¶ÇËø∞„ÄÇEMPAIA Êï¥Âêà‰∫ÜÁóÖÁêÜÂ≠∏ AI ÁîüÊÖãÁ≥ªÁµ±ÁöÑÂêÑÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÔºåÂç≥ÁóÖÁêÜÂ≠∏ÂÆ∂„ÄÅÈõªËÖ¶ÁßëÂ≠∏ÂÆ∂ÂíåÁî¢Ê•≠„ÄÇÂú®ÂØÜÂàáÂêà‰Ωú‰∏ãÔºåÊàëÂÄëÂà∂ÂÆö‰∫ÜÊäÄË°ì‰∫íÈÄöÊÄßÊ®ôÊ∫ñ„ÄÅAI Ê∏¨Ë©¶ÂíåÁî¢ÂìÅÈñãÁôºÂª∫Ë≠∞Ôºå‰ª•ÂèäÂèØËß£ÈáãÊÄßÊñπÊ≥ï„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫ÜÊ®°ÁµÑÂåñ‰∏îÈñãÊîæÂéüÂßãÁ¢ºÁöÑ EMPAIA Âπ≥Ëá∫Ôºå‰∏¶ÊàêÂäüÊï¥Âêà‰∫Ü‰æÜËá™ 8 ÂÄã‰∏çÂêå‰æõÊáâÂïÜÁöÑ 14 ÂÄãÂü∫Êñº AI ÁöÑÂΩ±ÂÉèÂàÜÊûêÊáâÁî®Á®ãÂºèÔºåÂ±ïÁ§∫‰∫Ü‰∏çÂêåÁöÑÊáâÁî®Á®ãÂºèÂ¶Ç‰Ωï‰ΩøÁî®ÂñÆ‰∏ÄÁöÑÊ®ôÊ∫ñÂåñ‰ªãÈù¢„ÄÇÊàëÂÄëÂÑ™ÂÖàËÄÉÊÖÆÈúÄÊ±ÇÔºå‰∏¶Ë©ï‰º∞‰∫Ü AI Âú®Ê≠êÊ¥≤Âíå‰∫ûÊ¥≤ÁöÑ 14 ÂÄã‰∏çÂêåÁóÖÁêÜÂØ¶È©óÂÆ§‰∏≠ÁöÑÂØ¶ÈöõËá®Â∫äÊáâÁî®„ÄÇÈô§‰∫ÜÊäÄË°ìÈñãÁôºÂ§ñÔºåÊàëÂÄëÈÇÑÁÇ∫ÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫Âª∫Á´ã‰∫Ü‰∏ÄÂÄãË´ñÂ£áÔºå‰ª•ÂàÜ‰∫´Êï∏‰ΩçÁóÖÁêÜÂ≠∏Âíå AI ÁöÑË≥áË®äÂíåÁ∂ìÈ©ó„ÄÇÂïÜÊ•≠„ÄÅËá®Â∫äÂíåÂ≠∏Ë°ìÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁèæÂú®ÂèØ‰ª•Êé°Áî® EMPAIA ÁöÑÂ∏∏Ë¶ãÈñãÊîæÂéüÂßãÁ¢º‰ªãÈù¢ÔºåÈÄôÁÇ∫Â§ßË¶èÊ®°Ê®ôÊ∫ñÂåñÂíåÁ∞°ÂåñÊµÅÁ®ãÊèê‰æõ‰∫ÜÁç®ÁâπÁöÑÊ©üÊúÉ„ÄÇÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÂä™ÂäõÊâçËÉΩÊúâÊïà‰∏îÂª£Ê≥õÂú∞Âª∫Á´ã‰æãË°åÂØ¶È©óÂÆ§‰ΩøÁî®‰∏≠ÁöÑ AI ËºîÂä©„ÄÇÁÇ∫Ê≠§ÔºåÂ∑≤ÊàêÁ´ãÈùûÁáüÂà©ÂçîÊúÉ EMPAIA InternationalÔºå‰ª•‰ΩúÁÇ∫Ê∞∏Á∫åÂü∫Á§éÊû∂ÊßãÔºåÁπºÁ∫åÈÄ≤Ë°åÊ®ôÊ∫ñÂåñÔºå‰∏¶ÊîØÊè¥Âª£Ê≥õÂØ¶‰ΩúÂíåÂÄ°Â∞é AI ËºîÂä©Êï∏‰ΩçÁóÖÁêÜÂ≠∏ÁöÑÊú™‰æÜ„ÄÇ

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

ÊëòË¶ÅÔºöÂèç‰∫ãÂØ¶Ëß£Èáã (CE) ÊäÄË°ìÂ∑≤ÂºïËµ∑ÈóúÊ≥®Ôºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÁÇ∫Ëàá AI Á≥ªÁµ±‰∫íÂãïÁöÑ‰ΩøÁî®ËÄÖÊèê‰æõË¶ãËß£ÁöÑÊñπÊ≥ï„ÄÇÈõñÁÑ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåËá™ÂãïÈßïÈßõÊ±ΩËªäÁ≠âÈ†òÂüüÂª£Ê≥õÁ†îÁ©∂ÔºåÂúñÂΩ¢Âèç‰∫ãÂØ¶Ëß£Èáã (GCE) ÊñπÊ≥ïÁõ∏Â∞çËºÉÂ∞ëË¢´Êé¢Á¥¢„ÄÇGCE ÊúÉÁî¢Áîü‰∏ÄÂÄãÈ°û‰ººÊñºÂéüÂßãÂúñÂΩ¢ÁöÑÊñ∞ÂúñÂΩ¢Ôºå‰∏¶Ê†πÊìöÂü∫Á§éÈ†êÊ∏¨Ê®°ÂûãÁî¢Áîü‰∏çÂêåÁöÑÁµêÊûú„ÄÇÂú®ÈÄô‰∫õ GCE ÊäÄË°ì‰∏≠ÔºåÂÑòÁÆ°Âú®ÂÖ∂‰ªñÈ†òÂüüÔºà‰æãÂ¶ÇËóùË°ìÈ¢®Ê†ºÂíåËá™ÁÑ∂Ë™ûË®ÄÂª∫Ê®°Ôºâ‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÂ∞±Ôºå‰ΩÜÊ§çÂü∫ÊñºÁîüÊàêÊ©üÂà∂ÁöÑÊäÄË°ìÁç≤ÂæóÁöÑÈóúÊ≥®Áõ∏Â∞çÊúâÈôê„ÄÇÂ∞çÁîüÊàêÂºèËß£ÈáãÂô®ÁöÑÂÅèÂ•ΩÊ∫êÊñºÂÆÉÂÄëÂú®Êé®ÁêÜÊúüÈñìÁî¢ÁîüÂèç‰∫ãÂØ¶ÂØ¶‰æãÁöÑËÉΩÂäõÔºåÂà©Áî®Ëº∏ÂÖ•ÂúñÂΩ¢ÁöÑËá™‰∏ªÁç≤ÂèñÊìæÂãï„ÄÇÂü∫Êñº‰∏äËø∞ÁêÜÁî±ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü RSGG-CEÔºå‰∏ÄÁ®ÆÁî®ÊñºÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÊñ∞ÂûãÁ©©ÂÅ•Èö®Ê©üÂúñÂΩ¢ÁîüÊàêÂô®ÔºåËÉΩÂ§†ÂæûÂ≠∏ÁøíÂà∞ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠Áî¢ÁîüÂèç‰∫ãÂØ¶ÁØÑ‰æãÔºåËÄÉÊÖÆÈÉ®ÂàÜÊúâÂ∫èÁöÑÁîüÊàêÂ∫èÂàó„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°åÂÆöÈáèÂíåÂÆöÊÄßÂàÜÊûêÔºå‰ª•ÊØîËºÉ RSGG-CE ÁöÑÊïàËÉΩËàá SoA ÁîüÊàêÂºèËß£ÈáãÂô®ÔºåÂº∑Ë™øÂÖ∂Â¢ûÂº∑‰∫ÜÁî¢ÁîüÂêàÁêÜËß£ÈáãÂÄôÈÅ∏ÁöÑËÉΩÂäõ„ÄÇ

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI ÁöÑÂãïÊ©ü‰πã‰∏ÄÊòØËÆì‰∫∫ÂÄëÂú®‰ΩøÁî®ÂíåÈÉ®ÁΩ≤ AI Ê®°ÂûãÊôÇÂÅöÂá∫Êõ¥Â•Ω„ÄÅÊõ¥ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇ‰ΩÜÈúÄË¶Å‰ªîÁ¥∞Ë©ï‰º∞‰ª•Ë©ï‰º∞ÊòØÂê¶Â∑≤ÈÅîÂà∞Ê≠§È†êÊúü„ÄÇÁõÆÂâçÁöÑË©ï‰º∞‰∏ªË¶ÅÈõÜ‰∏≠Âú®Ëß£ÈáãÁöÑÊºîÁÆóÊ≥ïÁâπÊÄßÔºåËÄåÊ∂âÂèä‰∫∫È°ûÂèóË©¶ËÄÖÁöÑË©ï‰º∞ÈÄöÂ∏∏Êé°Áî®‰∏ªËßÄÂïèÈ°å‰æÜÊ∏¨Ë©¶‰∫∫È°ûÂ∞çËß£ÈáãÊúâÁî®ÊÄßÁöÑÁúãÊ≥ïÔºåËÄåÊ≤íÊúâÂü∫ÊñºÂÆ¢ËßÄÊåáÊ®ôÂíåÊ∏¨Èáè„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞Ëß£ÈáãÊòØÂê¶ÂèØ‰ª•Âú®Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÈñãÁôºÁöÑÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÊîπÂñÑ‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÊ∂âÂèäÂΩ±ÂÉèË≥áÊñôÁöÑÊ∑∑ÂêàÊñπÊ≥ï‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ SmoothGrad„ÄÅGradCAM ÂíåÈ†êË®ÄËß£ÈáãÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏≠Áî¢ÁîüÁöÑÈ°ØËëóÊÄßÂúñÔºöÊ®°ÂûãÈÅ∏ÊìáÂíåÂèç‰∫ãÂØ¶Ê®°Êì¨„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÊ≤íÊúâÁôºÁèæ‰ªª‰ΩïÈ°ØËëóÊÄßÂúñÔºàÂç≥‰ΩøÊòØË®≠Ë®àÁÇ∫ÊòìÊñºÁêÜËß£‰∏îÈ´òÂ∫¶ÊåáÁ§∫Á≠îÊ°àÁöÑÂêàÊàêÈ†êË®ÄËß£ÈáãÔºâËÉΩËÆì‰ΩøÁî®ËÄÖÂú®ÈÄô‰∫õ‰ªªÂãô‰∏äÈ°ØËëóÊîπÂñÑÁöÑË≠âÊìö„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåËß£ÈáãÁ¢∫ÂØ¶ÊúâÂä©Êñº‰ΩøÁî®ËÄÖÊõ¥Ê∫ñÁ¢∫Âú∞ÊèèËø∞Ê®°Âûã„ÄÇÈÄô‰∫õÁôºÁèæÊèêÁ§∫ÊàëÂÄëË¶ÅÂ∞çÂü∫ÊñºÈ°ØËëóÊÄßÁöÑËß£Èáã‰∏≠ÂèØËÉΩÂ≠òÂú®Ë™§Ëß£ÁöÑÊúâÁî®ÊÄß‰øùÊåÅË¨πÊÖé„ÄÇ

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

ÊëòË¶ÅÔºöÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÂª∫Á´ã‰ø°‰ªª„ÄÇÈÄô‰∫õÈúÄË¶Å‰∏ÄÂÄãÊ®°Âûã‰æÜÂ±ïÁ§∫‰∏ÄËá¥ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÈÄô‰∫õÔºåÊúâÂøÖË¶Å‰ΩøÁî®ÂíåÂàÜÊûêÊï∏ÊìöÂíåÁü•Ë≠òÔºå‰∏¶‰ΩøÁî®Ëàá AI ÊáâÁî®Áõ∏ÈóúÁöÑÁµ±Ë®àÂíåÁ¨¶Ëôü AI ÊñπÊ≥ï - ÂñÆÁç®‰ΩøÁî®‰ªª‰Ωï‰∏ÄÁ®ÆÊñπÊ≥ïÈÉΩ‰∏çÊúÉÂ•èÊïà„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰∏ªÂºµ‰∏¶Ë©¶ÂúñË≠âÊòé NeuroSymbolic AI ÊñπÊ≥ïÊõ¥ÈÅ©ÂêàÊñº‰Ωø AI ÊàêÁÇ∫Âèó‰ø°‰ªªÁöÑ AI Á≥ªÁµ±„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü CREST Ê°ÜÊû∂ÔºåÂ±ïÁ§∫‰∫Ü‰∏ÄËá¥ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅ‰ΩøÁî®ËÄÖÂ±§Á¥öÁöÑÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÊòØÂ¶Ç‰ΩïÂª∫Á´ãÂú® NeuroSymbolic ÊñπÊ≥ï‰∏äÁöÑÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Êï∏ÊìöÂíåÁü•Ë≠ò‰æÜÊîØÊåÅÈóúÈçµÊáâÁî®Ôºà‰æãÂ¶ÇÂÅ•Â∫∑ÂíåÁ¶èÁ•âÔºâÁöÑË¶ÅÊ±Ç„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂõ†ÁÇ∫ÂÆÉÊòØ CREST Ê°ÜÊû∂‰∏≠ÈÅ∏ÊìáÁöÑ AI Á≥ªÁµ±„ÄÇLLM Âõ†ÂÖ∂Âú®ËôïÁêÜÂª£Ê≥õÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Â†¥ÊôØÊñπÈù¢ÁöÑÂ§öÂäüËÉΩÊÄßËÄåÂÇôÂèóÁ†îÁ©∂‰∫∫Âì°ÁöÑÈóúÊ≥®„ÄÇ‰æãÂ¶ÇÔºåChatGPT Âíå Google ÁöÑ MedPaLM Â∑≤ÊàêÁÇ∫Êèê‰æõ‰∏ÄËà¨ÂíåÂÅ•Â∫∑Áõ∏ÈóúÊü•Ë©¢‰ø°ÊÅØÁöÑÊ•µÊúâÂ∏åÊúõÁöÑÂπ≥Âè∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÊ®°Âûã‰ªçÁÑ∂ÊòØÈªëÁõíÂ≠êÔºåÂÑòÁÆ°Á¥çÂÖ•‰∫Ü‰∫∫È°ûÂèçÈ•ãÂíåÊåá‰ª§ÂºïÂ∞éÁöÑË™øÊï¥„ÄÇ‰æãÂ¶ÇÔºåÂÑòÁÆ°Âà∂ÂÆö‰∫ÜÂÆâÂÖ®Èò≤Ë≠∑Êé™ÊñΩÔºåChatGPT ‰ªçÂèØËÉΩÁî¢Áîü‰∏çÂÆâÂÖ®ÁöÑÂõûÊáâ„ÄÇCREST ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêàÁêÜÁöÑÊñπÊ≥ïÔºåÂú® NeuroSymbolic Ê°ÜÊû∂‰∏≠Âà©Áî®Á®ãÂ∫èÂíåÂü∫ÊñºÂúñË°®ÁöÑÁü•Ë≠òÔºå‰ª•Èó°ÊòéËàá LLM Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇ

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë∞ÉÊü•‰∫ÜÂú® COVID-19 Áñ´ÊÉÖÊúüÈó¥Âèä‰ª•ÂêéÈ¢ÑÊµãÊ≠ª‰∫°ÁéáÊó∂ÔºåÂ∑≤ÈÉ®ÁΩ≤‰∫∫Â∑•Êô∫ËÉΩ (AI) Ê®°ÂûãÁöÑÊÄßËÉΩ„ÄÅÂèØËß£ÈáäÊÄßÂíåÁ®≥ÂÅ•ÊÄß„ÄÇ‰Ωú‰∏∫ÂêåÁ±ªÁ†îÁ©∂‰∏≠ÁöÑÈ¶ñ‰æãÔºåÊàë‰ª¨ÂèëÁé∞Ë¥ùÂè∂ÊñØÁ•ûÁªèÁΩëÁªú (BNN) ÂíåÊô∫ËÉΩËÆ≠ÁªÉÊäÄÊúØËÆ©Êàë‰ª¨ÁöÑÊ®°ÂûãÂú®Êï∞ÊçÆÂèëÁîüÈáçÂ§ßÂèòÂåñÊó∂‰ªçËÉΩ‰øùÊåÅÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúÂº∫Ë∞É‰∫ÜÂºÄÂèëÁ®≥ÂÅ•ÁöÑ AI Ê®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºåÂç≥‰ΩøÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊù°‰ª∂‰∏ãÔºåËøô‰∫õÊ®°Âûã‰πüËÉΩÂåπÈÖçÊàñË∂ÖË∂ä‰∏¥Â∫äÂåªÁîüÁöÑÈ¢ÑÊµã„ÄÇÊàë‰ª¨ÂØπÊ®°ÂûãÂèØËß£ÈáäÊÄßÁöÑÊé¢Á¥¢Ë°®ÊòéÔºåÈöèÊú∫Ê®°Âûã‰ºö‰∫ßÁîüÊõ¥Â§öÊ†∑Âåñ‰∏î‰∏™ÊÄßÂåñÁöÑËß£ÈáäÔºå‰ªéËÄåÁ™ÅÂá∫‰∫ÜÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠Êèê‰æõËØ¶ÁªÜ‰∏î‰∏™ÊÄßÂåñËßÅËß£ÁöÑ AI Ê®°ÂûãÁöÑÂøÖË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âº∫Ë∞É‰∫ÜÈáèÂåñ AI Ê®°Âûã‰∏≠‰∏çÁ°ÆÂÆöÊÄßÁöÑÈáçË¶ÅÊÄßÔºåËøô‰Ωø‰∏¥Â∫äÂåªÁîüËÉΩÂ§üÊ†πÊçÆÂèØÈù†ÁöÑÈ¢ÑÊµãÂÅöÂá∫Êõ¥ÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÊèêÂÄ°Âú®ÂåªÁñó‰øùÂÅ•ÁöÑ AI Á†îÁ©∂‰∏≠‰ºòÂÖàËÄÉËôëÂÆûÊñΩÁßëÂ≠¶ÔºåÂπ∂Á°Æ‰øù AI Ëß£ÂÜ≥ÊñπÊ°àÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠ÂÆûÁî®„ÄÅÊúâÁõä‰∏îÂèØÊåÅÁª≠„ÄÇÈÄöËøáËß£ÂÜ≥ÂåªÁñó‰øùÂÅ•ÁéØÂ¢É‰∏≠ÁöÑÁã¨ÁâπÊåëÊàòÂíåÂ§çÊùÇÊÄßÔºåÁ†îÁ©∂‰∫∫ÂëòÂèØ‰ª•ÂºÄÂèëÂá∫ÊúâÊïàÊîπÂñÑ‰∏¥Â∫äÂÆûË∑µÂíåÊÇ£ËÄÖÈ¢ÑÂêéÁöÑ AI Ê®°Âûã„ÄÇ

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

ÊëòË¶ÅÔºöËÇ∫ÁôåÂç†Ëã±ÂúãÁôåÁóáÊ≠ª‰∫°‰∫∫Êï∏ÁöÑ 21%Ôºå‰∫îÂπ¥Â≠òÊ¥ªÁéáÂæàÂ§ßÁ®ãÂ∫¶ÂèñÊ±∫ÊñºÁôåÁóáË¢´ÁôºÁèæÁöÑÈöéÊÆµ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Ë≠âÊòé‰∫∫Â∑•Êô∫ËÉΩÊñπÊ≥ïÂÖ∑ÊúâÂæû‰æãË°åÊéÉÊèè‰∏≠Ê∫ñÁ¢∫ÂèäÊó©Ë®∫Êñ∑ËÇ∫ÁôåÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊ≠§Ë≠âÊìöÂ∞öÊú™ËΩâÂåñÁÇ∫Ëá®Â∫äÂØ¶ÂãôÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÈöúÁ§ôÊòØÁº∫‰πèÂèØËß£ÈáãÁöÑÊ®°Âûã„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÊáâÁî®ËÆäÂàÜËá™ÂãïÁ∑®Á¢ºÂô® (VAE)Ôºå‰∏ÄÁ®ÆÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÔºåÊñºËÇ∫ÁôåÁóÖÁÅ∂„ÄÇÂ∞áÊèêÂá∫ÁöÑÊ®°ÂûãË®ìÁ∑¥ÊñºÂæû LIDC-IDRI ÂÖ¨ÂÖ±Êï∏ÊìöÈõÜ‰∏≠ÊèêÂèñÁöÑ 3D ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁóÖÁÅ∂„ÄÇÈÄöÈÅéËÅöÈ°ûÊé¢Á¥¢‰∫Ü VAE ÁîüÊàêÁöÑ 2D ÂàáÁâáÁöÑÊΩõÂú®ÂêëÈáèË°®Á§∫Ôºå‰ª•Ë≠âÊòéÂÖ∂ÂìÅË≥™Ôºå‰∏¶Áî®ÊñºËÇ∫ÁôåË®∫Êñ∑ÁöÑ MLP ÂàÜÈ°ûÂô®Ê®°ÂûãÔºåÊúÄ‰Ω≥Ê®°ÂûãÈÅîÂà∞‰∫Ü AUC 0.98 Âíå 93.1% Ê∫ñÁ¢∫Â∫¶ÁöÑÊúÄÂÖàÈÄ≤ÊåáÊ®ô„ÄÇËÅöÈ°ûÂàÜÊûêÈ°ØÁ§∫ÔºåVAE ÊΩõÂú®Á©∫ÈñìÊ†πÊìöÊúâÊÑèÁæ©ÁöÑÁâπÂæµÁµÑÊàêÔºàÂåÖÊã¨ËÖ´Áò§Â§ßÂ∞è„ÄÅÂΩ¢ÁãÄ„ÄÅÊÇ£ËÄÖÂíåÊÉ°ÊÄßÈ°ûÂà•ÔºâÂ∞áÊÉ°ÊÄßÂíåËâØÊÄßÁóÖÁÅ∂ÁöÑÊï∏ÊìöÈõÜÂàÜÈñã„ÄÇÊàëÂÄëÈÇÑÂåÖÊã¨Ê®ôÊ∫ñÈ´òÊñØ VAE (GVAE) ÂíåÊõ¥Êñ∞ÁöÑÁãÑÂà©ÂÖãÈõ∑ VAE (DirVAE) ÁöÑÊØîËºÉÂàÜÊûêÔºåÂæåËÄÖÁî®ÁãÑÂà©ÂÖãÈõ∑ÂàÜ‰ΩàÂèñ‰ª£ÂÖàÈ©óÔºå‰ª•‰øÉÈÄ≤ÂÖ∑ÊúâËß£ÈñãÁâπÂæµË°®Á§∫ÁöÑÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÁöÑÊΩõÂú®Á©∫Èñì„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáËá®Â∫äÊúâÊÑèÁæ©ÁöÑÁâπÂæµËÆäÂåñÁõ∏ÊáâÁöÑÊΩõÂú®Á©∫ÈñìÊ©´Ë∂äÁöÑÊΩõÂäõ„ÄÇ

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂúñÂÉèÂàÜÈ°ûÂô®Ëº∏Âá∫Ëß£ÈáãÂ∑•ÂÖ∑ÂèØÂàÜÁÇ∫‰æùË≥¥ÊñºÊ®°ÂûãÂÖßÈÉ®Â≠òÂèñÊ¨äÈôêÁöÑÁôΩÁõíÔºå‰ª•ÂèäËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÈªëÁõí„ÄÇÈö®Ëëó AI Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑ‰ΩøÁî®Â¢ûÂä†ÔºåÂèØËß£ÈáãÊÄßÂ∑•ÂÖ∑ÁöÑ‰ΩøÁî®‰πüÈö®‰πãÂ¢ûÂä†„ÄÇÁèæÊúâÈÜ´Â≠∏ÂΩ±ÂÉèËß£ÈáãÁöÑÂ∑•‰ΩúÈáçÈªûÂú®ÊñºÁôΩÁõíÂ∑•ÂÖ∑Ôºå‰æãÂ¶Ç gradcam„ÄÇÁÑ∂ËÄåÔºåÂàáÊèõÂà∞ÈªëÁõíÂ∑•ÂÖ∑ÊúâÊòéÈ°ØÁöÑÂÑ™ÈªûÔºåÂåÖÊã¨ËÉΩÂ§†Ëàá‰ªª‰ΩïÂàÜÈ°ûÂô®‰∏ÄËµ∑‰ΩøÁî®Ôºå‰ª•ÂèäÂª£Ê≥õÁöÑÈªëÁõíÂ∑•ÂÖ∑ÂèØ‰æõÈÅ∏Êìá„ÄÇÂú®Ê®ôÊ∫ñÂΩ±ÂÉè‰∏äÔºåÈªëÁõíÂ∑•ÂÖ∑ËàáÁôΩÁõí‰∏ÄÊ®£Á≤æÁ¢∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∫ÜÂ§öÁ®ÆÈªëÁõíÊñπÊ≥ïÂú®ËÖ¶Áôå MRI Ë≥áÊñôÈõÜ‰∏äËàá gradcam ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëË≠âÊòéÂ§ßÂ§öÊï∏ÈªëÁõíÂ∑•ÂÖ∑‰∏çÈÅ©ÂêàËß£ÈáãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°ûÔºå‰∏¶Ë©≥Á¥∞ÂàÜÊûêÂÖ∂Áº∫ÈªûÁöÑÂéüÂõ†„ÄÇÊàëÂÄëÈÇÑË°®Êòé‰∏ÄÁ®ÆÈªëÁõíÂ∑•ÂÖ∑ÔºåÂü∫ÊñºÂõ†ÊûúÂèØËß£ÈáãÊÄßÁöÑ rexÔºåË°®ÁèæËàá \gradcam ‰∏ÄÊ®£Â•Ω„ÄÇ

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

ÊëòË¶ÅÔºöAI ÁôºÂ±ïÁ§æÁæ§Êó•ÁõäÂà©Áî® Hugging Face Á≠âË®óÁÆ°‰∏≠‰ªãÔºåÊèê‰æõ‰ΩøÁî®ËÄÖ‰∏äÂÇ≥‰πãÊ®°ÂûãËàáË®ìÁ∑¥Ë≥áÊñôÁöÑÁ∞°ÊòìÂèñÂæóÁÆ°ÈÅì„ÄÇÈÄô‰∫õÊ®°ÂûãÂ∏ÇÈõÜÈôç‰Ωé‰∫ÜÊï∏ÂçÅËê¨Âêç‰ΩøÁî®ËÄÖÁöÑÊäÄË°ìÈÉ®ÁΩ≤ÈñÄÊ™ªÔºå‰ΩÜÂçªÂèØËÉΩË¢´Áî®ÊñºË®±Â§öÊΩõÂú®ÊúâÂÆ≥‰∏îÈùûÊ≥ïÁöÑÁî®ÈÄî„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË™™Êòé‰∫Ü AI Á≥ªÁµ±Êó¢ÂèØ‰ª•„ÄåÂåÖÂê´„ÄçÂÖßÂÆπÔºå‰πüÂèØ‰ª•‰ΩúÁÇ∫ÈñãÊîæÂºèÂ∑•ÂÖ∑ÔºåÈÄôÊèêÂá∫‰∫ÜËøÑ‰ªäÁÇ∫Ê≠¢ÊúÄÊ£òÊâãÁöÑÂπ≥Âè∞Ê≤ªÁêÜÊåëÊà∞‰πã‰∏Ä„ÄÇÊàëÂÄëÊèê‰æõ Hugging Face„ÄÅGitHub Âíå Civitai Á≠â‰∏âÂÄãË™™ÊòéÊÄßÂπ≥Âè∞‰∏äÊï∏Ëµ∑‰∫ã‰ª∂ÁöÑÊ°à‰æãÁ†îÁ©∂Ôºå‰ª•Êé¢Ë®éÊ®°ÂûãÂ∏ÇÈõÜÂ¶Ç‰ΩïÊéßÁÆ°Ê®°Âûã„ÄÇÊ†πÊìöÊ≠§ÂàÜÊûêÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÁî¢Ê•≠ÁÇ∫ÂõûÊáâÊéßÁÆ°ÈúÄÊ±ÇËÄåÁôºÂ±ïÁöÑÈáçË¶ÅÔºà‰ΩÜ‰ªçÊúâÈôêÔºâÂØ¶ÂãôÔºöÊéàÊ¨ä„ÄÅÂ≠òÂèñÂíå‰ΩøÁî®ÈôêÂà∂„ÄÅËá™ÂãïÂÖßÂÆπÊéßÁÆ°ÂíåÈñãÊîæÂºèÊîøÁ≠ñÁôºÂ±ï„ÄÇÂÑòÁÆ°ÁõÆÂâçÈù¢Ëá®ÁöÑÊîøÁ≠ñÊåëÊà∞Áõ∏Áï∂Âö¥Â≥ªÔºåÊàëÂÄë‰ªçÊèêÂá∫‰∫Ü‰∏Ä‰∫õÊÉ≥Ê≥ïÔºåË™™ÊòéÂπ≥Âè∞Â¶Ç‰ΩïËÉΩÊõ¥Â•ΩÂú∞ÂãïÂì°Ë≥áÊ∫êÔºå‰ΩúÁÇ∫Ë¨πÊÖé„ÄÅÂÖ¨Âπ≥ÂíåÈÅ©Â∫¶ÁöÑÊ≥ïË¶èÂ≠òÂèñÈªû„ÄÇ

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÂíåÁõÆÊ®ôÔºöÈÄöÈÅéÊèêÂèñÈÄô‰∫õË≥áË®äÔºåÊ©üÂô®ÊàñÊ∑±Â∫¶Â≠∏Áøí (ML/DL) Âü∫ÊñºËá™‰∏ªÊï∏ÊìöÂàÜÊûêÂ∑•ÂÖ∑ÂèØ‰ª•ÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÂíåÁôåÁóáÁ†îÁ©∂‰∫∫Âì°ÂæûË§áÈõúÁöÑÊï∏ÊìöÈõÜ‰∏≠ÁôºÁèæÊ®°ÂºèÂíåÈóú‰øÇ„ÄÇÊúÄËøëÂ∑≤ÁôºË°®Ë®±Â§öÂü∫Êñº DL ÁöÑÂçµÂ∑¢Áôå (OC) Êï∏ÊìöÂàÜÊûê„ÄÇÈÄô‰∫õÂàÜÊûêÂú®ÁôåÁóáÁöÑÂêÑÂÄãÊñπÈù¢Ôºà‰æãÂ¶ÇÔºåÂÆÉÂÄëÊ∂âÂèäÁöÑÂ≠êÈ†òÂüüÂíåÁôåÁóáÈ°ûÂûãÔºâÂíåÊï∏ÊìöÂàÜÊûêÂäüËÉΩÊñπÈù¢È´òÂ∫¶Â§öÊ®£Âåñ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁº∫‰πèÂ∞çÈÄô‰∫õÂàÜÊûêÂú®ÈÄô‰∫õÁâπÂæµÂíå AI ‰øùË≠â (AIA) ÊñπÈù¢ÁöÑÂÖ®Èù¢ÁêÜËß£„ÄÇÈÄôÁØáÁ≥ªÁµ±ÊÄßÂõûÈ°ßÊó®Âú®ÈÄöÈÅéÊ™¢Ë¶ñÁèæÊúâÊñáÁçª‰∏¶ÊòéÁ¢∫ÈóúÊ≥®ÈóúÈçµÁâπÂæµÂíå AI ‰øùË≠âËßÄÈªûÔºå‰æÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩ„ÄÇÊñπÊ≥ïÔºö‰ΩøÁî® PRISMA Êû∂ÊßãÂú®‰∏âÂÄãÊúüÂàäË≥áÊñôÂ∫´‰∏≠ÈÄ≤Ë°åÂÖ®Èù¢ÊêúÂ∞ã„ÄÇÂàÜÊûêÂÉÖÂåÖÊã¨ 2015 Âπ¥Ëá≥ 2023 Âπ¥ÈñìÁôºË°®ÊñºÂêåË°åË©ïÂØ©ÊúüÂàäÁöÑÁ†îÁ©∂„ÄÇÁµêÊûúÔºöÂú®ÂõûÈ°ß‰∏≠ÔºåÁ∏ΩÂÖ±Ê™¢Ë¶ñ‰∫Ü 96 È†ÖÁî± DL È©ÖÂãïÁöÑÂàÜÊûê„ÄÇÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫ÜÂπæÂÄãÈóúÊñºÁî± DL È©ÖÂãïÁöÑÂçµÂ∑¢ÁôåÊï∏ÊìöÂàÜÊûêÁöÑÈáçË¶ÅË¶ãËß£Ôºö- Â§ßÂ§öÊï∏Á†îÁ©∂ 71%Ôºà96 È†Ö‰∏≠Êúâ 68 È†ÖÔºâÂ∞àÊ≥®ÊñºÊ™¢Ê∏¨ÂíåË®∫Êñ∑ÔºåËÄåÊ≤íÊúâÁ†îÁ©∂Êé¢Ë®é OC ÁöÑÈ†êÊ∏¨ÂíåÈ†êÈò≤„ÄÇ- ÈÄô‰∫õÂàÜÊûê‰∏ªË¶ÅÂü∫Êñº‰æÜËá™ÈùûÂ§öÂÖÉÊóèÁæ§ÁöÑÊ®£Êú¨Ôºà75%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 72 È†ÖÔºâÔºâÔºåÂÉÖÈôêÊñºÊüêÂÄãÂú∞ÁêÜ‰ΩçÁΩÆÊàñÂúãÂÆ∂„ÄÇ- Âè™ÊúâÂ∞ëÈÉ®ÂàÜÁ†îÁ©∂ÔºàÂÉÖ 33%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 32 È†ÖÔºâÂü∑Ë°åÊï¥ÂêàÂàÜÊûêÔºåÂÖ∂‰∏≠Â§ßÂ§öÊï∏‰ΩøÁî®ÂêåË≥™Êï∏ÊìöÔºàËá®Â∫äÊàñÁµÑÂ≠∏Ôºâ„ÄÇ- ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂè™Êúâ 8.3%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 8 È†ÖÔºâ‰ΩøÁî®Â§ñÈÉ®ÂíåÂ§öÂÖÉÊï∏ÊìöÈõÜÈ©óË≠â‰∫ÜÂÖ∂Ê®°ÂûãÔºåÂº∑Ë™ø‰∫ÜÂä†Âº∑Ê®°ÂûãÈ©óË≠âÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Âèä- Â∞á AIA Á¥çÂÖ•ÁôåÁóáÊï∏ÊìöÂàÜÊûê‰ªçËôïÊñºÈùûÂ∏∏Êó©ÊúüÁöÑÈöéÊÆµÔºõÂè™Êúâ 2.1%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 2 È†ÖÔºâÈÄèÈÅéÂèØËß£ÈáãÊÄßÊòéÁ¢∫Êé¢Ë®é‰∫Ü AIA„ÄÇ</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

ÊëòË¶ÅÔºö<paragraph>Ëß£ÈáãÊÄßÊòØÊ∑±Â∫¶Â≠∏Áøí‰∏≠Èï∑ÊúüÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≠âÈ´òÈ¢®Èö™È†òÂüü„ÄÇÂ∏∏Ë¶ãÁöÑËß£ÈáãÊÄßÊñπÊ≥ïÊúÉÂº∑Ë™øÈ©ÖÂãï AI Ê®°ÂûãÊ±∫Á≠ñÁöÑÂΩ±ÂÉèÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÂæàÂ§ßÁ®ãÂ∫¶‰æùË≥¥Ë™ûË®Ä‰æÜÂÇ≥ÈÅî‰∏çÂÉÖÊòØ„ÄåÂú®Âì™Ë£°„ÄçÔºåÈÇÑÊúâ„ÄåÊòØ‰ªÄÈ∫º„ÄçÁöÑËß£Èáã„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏Ëß£ÈáãÊÄßÊñπÊ≥ïÈÉΩÂ∞àÊ≥®ÊñºËß£ÈáãÂÄãÂà• AI È†êÊ∏¨ÔºåËÄå‰∏çÊòØÊèèËø∞ AI Ê®°Âûã‰∏ÄËà¨‰ΩøÁî®ÁöÑÁâπÂæµ„ÄÇÂæåËÄÖÂ∞çÊñºÊ®°ÂûãÂíåË≥áÊñôÈõÜÁ®ΩÊ†∏ÁâπÂà•ÊúâÁî®ÔºåÁîöËá≥ÂèØËÉΩÂú® AI ÊÑà‰æÜÊÑàÁî®ÊñºÊñ∞Á©é‰ªªÂãôÊôÇÁî¢ÁîüÁü•Ë≠ò„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã‰æÜËæ®Ë≠òË¶ñË¶∫ÂàÜÈ°û‰ªªÂãôÁöÑË™ûË®ÄÊèèËø∞Á¨¶ÁöÑËß£ÈáãÊÄßÁ≠ñÁï•„ÄÇÈÄèÈÅéÂà©Áî®ÂΩ±ÂÉèÂíåÊñáÂ≠ó‰πãÈñìÈ†êÂÖàË®ìÁ∑¥ÁöÑËÅØÂêàÂµåÂÖ•Á©∫ÈñìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÊñ∞ÁöÑÂàÜÈ°û‰ªªÂãô‰º∞Ë®àÁÇ∫‰∏ÄÂÄãÁ∑öÊÄßÊñáÂ≠óÁµÑÂêàÔºåÂ∞éËá¥ÊØèÂÄãÊñáÂ≠óÈÉΩÊúâÊ¨äÈáçÔºåË°®Á§∫ÂÆÉËàáÂü∫ÊñºË¶ñË¶∫ÁöÑÂàÜÈ°ûÂô®Â∞çÈΩä„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ©ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãô‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄëÁôºÁèæÁî¢ÁîüÁöÑÊèèËø∞Á¨¶Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äËàáËá®Â∫äÁü•Ë≠ò‰∏ÄËá¥ÔºåÂÑòÁÆ°Áº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑË™ûË®ÄË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰πüÁôºÁèæ‰∫ÜÊâÄÁî®ÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑ„ÄåÊç∑ÂæëÈÄ£Á∑ö„ÄçÁöÑÂèØËÉΩÊÄß„ÄÇÁÇ∫‰∫ÜÈÅîÂà∞Ëß£ÈáãÊÄßÁöÑÂäüËÉΩÊÄßË°°ÈáèÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖË©¶È©óËÆÄËÄÖÁ†îÁ©∂ÔºåÁôºÁèæ AI Ë≠òÂà•ÁöÑÊñáÂ≠óËÉΩËÆìÈùûÂ∞àÂÆ∂‰∫∫È°ûÂú®ÈùûÂπ≥Âá°ÁöÑÂ±§Á¥öÂü∑Ë°åÂ∞àÊ•≠ÁöÑÈÜ´ÁôÇ‰ªªÂãô„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫Ü‰ΩøÁî®Â§öÊ®°ÂºèÂü∫Á§éÊ®°Âûã‰æÜÊèê‰æõÁõ¥ËßÄÁöÑ„ÄÅÂü∫ÊñºË™ûË®ÄÁöÑË¶ñË¶∫‰ªªÂãôËß£ÈáãÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Towards objective and systematic evaluation of bias in medical imaging AI**
2311.02115v1 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

ÊëòË¶ÅÔºö<paragraph>‰ΩøÁî®ÈÜ´Â≠∏ÂΩ±ÂÉèË®ìÁ∑¥Áî®ÊñºËá®Â∫ä‰ªªÂãôÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÔºåÂ∏∏ÊúÉÂ±ïÁèæÂá∫ÊïàËÉΩÂ∑ÆÁï∞ÁöÑÂΩ¢ÂºèÂÅèË™§ÔºåÈÄô‰∫õÂ∑ÆÁï∞Â≠òÂú®ÊñºÊ¨°Áæ§ÁµÑ‰πãÈñì„ÄÇÁî±Êñº‰∏¶ÈùûÊâÄÊúâÁúüÂØ¶‰∏ñÁïåÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñô‰∏≠ÁöÑÂÅèË™§‰æÜÊ∫êÈÉΩÂÆπÊòìËæ®Ë≠òÔºåÂõ†Ê≠§ÂÖ®Èù¢Ë©ï‰º∞ÈÄô‰∫õÂÅèË™§Â¶Ç‰ΩïÁ∑®Á¢ºÂú®Ê®°Âûã‰∏≠Ôºå‰ª•ÂèäÂÅèË™§Á∑©Ëß£ÊñπÊ≥ïÂú®ÊîπÂñÑÊïàËÉΩÂ∑ÆÁï∞ÊñπÈù¢ÁöÑËÉΩÂäõÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÂÄãÊñ∞Á©éÁöÑÂàÜÊûêÊû∂ÊßãÔºåÁî®ÊñºÁ≥ªÁµ±ÊÄß‰∏îÂÆ¢ËßÄÂú∞Ë™øÊü•ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÂÅèË™§Â∞ç AI Ê®°ÂûãÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈñãÁôº‰∏¶Ê∏¨Ë©¶‰∫ÜÈÄôÂÄãÊû∂ÊßãÔºåÁî®ÊñºÂü∑Ë°åÂèóÊéßÁöÑÈõªËÖ¶Ê®°Êì¨Ë©¶È©óÔºå‰ª•Ë©ï‰º∞ÈÜ´Â≠∏ÂΩ±ÂÉè AI ‰∏≠ÁöÑÂÅèË™§Ôºå‰∏¶‰ΩøÁî®‰∏ÄÂÄãÂ∑•ÂÖ∑‰æÜÁî¢ÁîüÂ∑≤Áü•ÁñæÁóÖÂΩ±ÈüøÂíåÂÅèË™§‰æÜÊ∫êÁöÑÂêàÊàêÁ£ÅÂÖ±ÊåØÂΩ±ÂÉè„ÄÇÂèØË°åÊÄßÈÄèÈÅé‰ΩøÁî®‰∏âÂÄãÂèç‰∫ãÂØ¶ÂÅèË™§ÊÉÖÂ¢É‰æÜË°°ÈáèÊ®°Êì¨ÂÅèË™§ÂΩ±ÈüøÂ∞çÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂàÜÈ°ûÂô®Âíå‰∏âÂÄãÂÅèË™§Á∑©Ëß£Á≠ñÁï•ÁöÑÊïàËÉΩ„ÄÇÂàÜÊûêÈ°ØÁ§∫ÔºåÁï∂ CNN Âú®ÂêàÊàêË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÊôÇÔºåÊ®°Êì¨ÂÅèË™§ÊúÉÂ∞éËá¥È†êÊúüÁöÑÊ¨°Áæ§ÁµÑÊïàËÉΩÂ∑ÆÁï∞„ÄÇÊ≠§Â§ñÔºåÈáçÊñ∞Âä†Ê¨äË¢´Ë¶ñÁÇ∫Ê≠§Ë®≠ÂÆö‰∏≠ÊúÄÊàêÂäüÁöÑÂÅèË™§Á∑©Ëß£Á≠ñÁï•ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËß£ÈáãÊÄß AI ÊñπÊ≥ïÂ¶Ç‰ΩïÂçîÂä©Ë™øÊü•Ê®°Âûã‰∏≠ÂÅèË™§ÁöÑË°®ÁèæÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®ÈÄôÂÄãÊû∂Êßã„ÄÇÈñãÁôºÂÖ¨Âπ≥ÁöÑ AI Ê®°ÂûãÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂõ†ÁÇ∫Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏≠ÊúâË®±Â§ö‰∏îÈÄöÂ∏∏Êú™Áü•ÁöÑÂÅèË™§‰æÜÊ∫ê„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂÆ¢ËßÄÂú∞Á†îÁ©∂ÂÅèË™§ÂíåÁ∑©Ëß£Á≠ñÁï•Â∞çÊ∑±Â∫¶Â≠∏ÁøíÁÆ°Á∑öÁöÑÂΩ±ÈüøÔºåÈÄôÂèØ‰ª•ÊîØÊè¥ÂÅ•ÂÖ®‰∏îË≤†Ë≤¨‰ªªÁöÑËá®Â∫ä AI ÁöÑÈñãÁôº„ÄÇ</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÁÇ∫Ëá™ÂãïÈ†êÊ∏¨‰∏≠È¢®ÂæåÁóáÁãÄÂèäÂÖ∂Â∞çÂæ©ÂÅ•ÁöÑÂèçÊáâÊèê‰æõ‰∫ÜÊ•µÂ§ßÁöÑÊΩõÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÈáçÂ§ßÊåëÊà∞ÂåÖÊã¨Á•ûÁ∂ìÂΩ±ÂÉèË≥áÊñôÁöÑÁ∂≠Â∫¶ÈùûÂ∏∏È´ò„ÄÅÂèØÁî®ÊñºÂ≠∏ÁøíÁöÑË≥áÊñôÈõÜË¶èÊ®°Áõ∏Â∞çËºÉÂ∞èÔºå‰ª•ÂèäÂ¶Ç‰ΩïÊúâÊïàÁµêÂêàÁ•ûÁ∂ìÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÔºà‰æãÂ¶Ç‰∫∫Âè£Áµ±Ë®àË≥áË®äÂíåËá®Â∫äÁâπÂæµÔºâ„ÄÇÊú¨ÊñáÊ†πÊìöÂÖ©Á®ÆÁ≠ñÁï•Ë©ï‰º∞‰∫ÜÂ§öÁ®ÆËß£Ê±∫ÊñπÊ°à„ÄÇÁ¨¨‰∏ÄÁ®ÆÊòØ‰ΩøÁî®Á∏ΩÁµê MRI ÊéÉÊèèÁöÑ 2D ÂΩ±ÂÉè„ÄÇÁ¨¨‰∫åÁ®ÆÊòØÈÅ∏ÊìáÊúâÂä©ÊñºÊèêÈ´òÂàÜÈ°ûÁ≤æÁ¢∫Â∫¶ÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂú®ÁµêÂêàÂæû MRI ‰∏≠ÊèêÂèñÁöÑÊÑüËààË∂£ÂçÄÂüüËàáË°®Ê†ºË≥áÊñôÁöÑÁ¨¶ËôüË°®Á§∫ÁöÑÂΩ±ÂÉè‰∏äË®ìÁ∑¥Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÁöÑÊñ∞Á©éÊñπÊ≥ï„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü‰∏ÄÁ≥ªÂàó CNN Êû∂ÊßãÔºà2D Âíå 3DÔºâÔºåÈÄô‰∫õÊû∂ÊßãÂú® MRI ÂíåË°®Ê†ºË≥áÊñôÁöÑ‰∏çÂêåË°®Á§∫‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ª•È†êÊ∏¨‰∏≠È¢®ÂæåÂè£Ëø∞ÂúñÁâáÊèèËø∞ËÉΩÂäõÁöÑÁ∂úÂêàÊ∏¨ÈáèÊòØÂê¶Âú®Â§±Ë™ûÁóáÊàñÈùûÂ§±Ë™ûÁóáÁØÑÂúçÂÖß„ÄÇMRI ÂíåË°®Ê†ºË≥áÊñô‰æÜËá™ 758 ÂêçÂèÉËàá PLORAS Á†îÁ©∂ÁöÑËã±Ë™û‰∏≠È¢®ÂÄñÂ≠òËÄÖ„ÄÇÂÉÖÈáùÂ∞çÁóÖÁÅ∂Â§ßÂ∞èÁöÑÂü∫Á∑öÈÇèËºØËø¥Ê≠∏ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 0.678ÔºåÁï∂‰æùÂ∫èÂä†ÂÖ•ÂàùÂßãÁóáÁãÄÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÊôÇÔºå‰∏äÂçáËá≥ 0.757 Âíå 0.813„ÄÇÂú®ÂæûÊØèÂÄã MRI ÊéÉÊèè‰∏≠ÊèêÂèñ 8 ÂÄãÊÑüËààË∂£ÂçÄÂüü‰∏¶Âú® 2D ÊÆòÂ∑ÆÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ËàáÁóÖÁÅ∂Â§ßÂ∞è„ÄÅÂàùÂßãÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÁµêÂêàÊôÇÔºåËßÄÂØüÂà∞ÊúÄÈ´òÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ 0.854„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞áÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÁµêÂêàËµ∑‰æÜ‰ª•Áç≤ÂæóÈ´òÊñº‰∏≠È¢®ÂæåÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÔºåÂç≥‰ΩøÂú®Ê©üÂô®Â≠∏ÁøíË°ìË™û‰∏≠Ë≥áÊñôÈõÜÂæàÂ∞èÁöÑÊÉÖÊ≥Å‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫Â¶Ç‰ΩïÊîπÈÄ≤ÁõÆÂâçÁöÑÊ®°ÂûãÔºå‰ª•‰ΩøÁî®‰æÜËá™ÈÜ´Èô¢ÊéÉÊèèÂÑÄÁöÑÂΩ±ÂÉè‰æÜÂØ¶ÁèæÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫ËôïÁêÜ‰ªªÂãôÈóúÈçµÊáâÁî®Á®ãÂºèÊôÇÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨ÈúÄÊ±ÇÔºåÁ¢∫‰øùÊé°Áî®ÈªëÁõí AI Ê®°ÂûãÁöÑÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄß„ÄÇXAI ÁöÑÈáçË¶ÅÊÄßÊ∂µËìãÂæûÈÜ´ÁôÇ‰øùÂÅ•Âà∞ÈáëËûçÁöÑÂêÑÁ®ÆÈ†òÂüüÔºåÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠Ôºå‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãËá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂ§öÊï∏Âü∫Êñº AI ÁöÑÈõªËÖ¶Ë¶ñË¶∫Ê®°ÂûãÈÄöÂ∏∏ÊòØÈªëÁõíÂ≠êÔºõÂõ†Ê≠§ÔºåÂú®ÂΩ±ÂÉèËôïÁêÜ‰∏≠Êèê‰æõÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂèØËß£ÈáãÊÄßÂ∞çÊñºÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê„ÄÅËá™ÂãïÈßïÈßõÂíåÈÅôÊ∏¨ÊáâÁî®‰∏≠ÁöÑÂª£Ê≥õÊé°Áî®ÂíåÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÔºåÂ∑≤ÈáùÂ∞çÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÂºïÂÖ•‰∫ÜÂ§öÁ®Æ XAI ÊñπÊ≥ï„ÄÇÁõ∏ÂèçÂú∞ÔºåÂΩ±ÂÉèÂàÜÂâ≤Âú®ÂèØËß£ÈáãÊÄßÁöÑËÉåÊôØ‰∏ãÂèóÂà∞ÁöÑÈóúÊ≥®Áõ∏Â∞çËºÉÂ∞ëÔºåÂÑòÁÆ°ÂÆÉÊòØÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨‰ªªÂãôÔºåÁâπÂà•ÊòØÂú®ÈÅôÊ∏¨‰∏≠„ÄÇÂè™ÊúâÈÉ®ÂàÜÁ†îÁ©∂ÊèêÂá∫Áî®ÊñºÂΩ±ÂÉèÂàÜÂâ≤ÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑ XAI ÊºîÁÆóÊ≥ï„ÄÇÊú¨ÊñáÊîπÁ∑®‰∫ÜÊúÄËøëÁöÑÁÑ°Ê¢ØÂ∫¶ Sobol XAI ÊñπÊ≥ï‰ª•ÈÄ≤Ë°åË™ûÊÑèÂàÜÂâ≤„ÄÇÁÇ∫‰∫ÜË°°Èáè Sobol ÊñπÊ≥ïÂú®ÂàÜÂâ≤‰∏≠ÁöÑÊïàËÉΩÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂèØÂ≠∏ÁøíÈõúË®äÊ®°ÂûãÁöÑÂÆöÈáè XAI Ë©ï‰º∞ÊñπÊ≥ï„ÄÇÊ≠§Ê®°ÂûãÁöÑ‰∏ªË¶ÅÁõÆÁöÑÊòØÂú®Ëß£ÈáãÂúñ‰∏äË™òÁôºÈõúË®äÔºåÂÖ∂‰∏≠ËºÉÈ´òÁöÑË™òÁôºÈõúË®äË°®Á§∫ËºÉ‰ΩéÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂèç‰πã‰∫¶ÁÑ∂„ÄÇÈÄ≤Ë°åÂü∫Ê∫ñÂàÜÊûê‰ª•Ë©ï‰º∞ÂíåÊØîËºÉ‰∏âÁ®Æ XAI ÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÂåÖÊã¨ Seg-Grad-CAM„ÄÅSeg-Grad-CAM++ Âíå Seg-SobolÔºå‰∏¶‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÂü∫ÊñºÈõúË®äÁöÑË©ï‰º∞ÊäÄË°ì„ÄÇÈÄôÊßãÊàê‰∫Ü‰ΩøÁî®È´òËß£ÊûêÂ∫¶Ë°õÊòüÂΩ±ÂÉèÂü∑Ë°åÂíåË©ï‰º∞ XAI ÊñπÊ≥ïÁöÑÈ¶ñÊ¨°ÂòóË©¶„ÄÇ

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Áü≠ÊôÇÈñìÂÖßÂ∑≤Âú®Â§öÂÄãÈ†òÂüü‰∏≠Â§ßÈáèÊøÄÂ¢û„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº‰∫ãÂØ¶ÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÂπªË¶∫Á≠âÂïèÈ°åÔºåÈÜ´ÁôÇÂíå‰øùÂÅ•È†òÂüüÂ∞çÂÖ∂Êé°Áî®Áå∂Ë±´‰∏çÊ±∫„ÄÇÈëëÊñºÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÈ´òÈ¢®Èö™ÊÄßË≥™ÔºåË®±Â§öÁ†îÁ©∂‰∫∫Âì°ÁîöËá≥Ë≠¶Âëä‰∏çË¶Å‰ΩøÁî®ÂÆÉÔºåÁõ¥Âà∞ÈÄô‰∫õÂïèÈ°åÂæóÂà∞Ëß£Ê±∫„ÄÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂØ¶ÊñΩÂíåÈÉ®ÁΩ≤ LLM ÁöÑÈóúÈçµÊòØ‰ΩøÈÄô‰∫õÊ®°ÂûãÂÄºÂæó‰ø°Ë≥¥„ÄÅÈÄèÊòéÔºàÁõ°ÂèØËÉΩÂ§öÔºâ‰∏îÂèØËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèèËø∞‰∫ÜÂª∫Á´ãÂèØÈù†„ÄÅÂÄºÂæó‰ø°Ë≥¥ÂíåÁÑ°ÂÅèË¶ãÊ®°ÂûãÁöÑÈóúÈçµË¶ÅÁ¥†Ôºå‰ΩúÁÇ∫ÂÆÉÂÄëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂæóÂà∞Êé°Áî®ÁöÑÂøÖË¶ÅÊ¢ù‰ª∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•ËÉåÊôØ‰∏ãÂ∞çÂπªË¶∫ÈÄ≤Ë°åÈáèÂåñ„ÄÅÈ©óË≠âÂíåÁ∑©Ëß£„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊú™‰æÜÂèØËÉΩÊòØ‰ªÄÈ∫ºÊ®£Â≠ê„ÄÇ

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂ∑≤Âø´ÈÄüÈÄ≤Ê≠•ÔºåÁèæÂ∑≤Ê∫ñÂÇôÈÉ®ÁΩ≤ÊñºÂª£Ê≥õÁöÑÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰æãÂ¶ÇËá™‰∏ªÁ≥ªÁµ±„ÄÅÈÜ´ÁôÇË®∫Êñ∑ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÇÂèäÊó©Êé°Áî® AI ÊäÄË°ìÊñºÂØ¶ÈöõÊáâÁî®Á®ãÂºè‰∏¶ÈùûÊ≤íÊúâÂïèÈ°åÔºåÁâπÂà•ÊòØÂ∞çÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂÆÉÂèØËÉΩ‰∏çÁ©©ÂÆö‰∏îÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÁØÑ‰æãÁöÑÂΩ±Èüø„ÄÇÂæûÈï∑ÈÅ†‰æÜÁúãÔºåÈúÄË¶ÅÈñãÁôºÈÅ©Áï∂ÁöÑÂÆâÂÖ®‰øùË≠âÊäÄË°ìÔºå‰ª•Ê∏õÂ∞ëÂõ†ÂèØÈÅøÂÖçÁöÑÁ≥ªÁµ±ÊïÖÈöúËÄåÈÄ†ÊàêÁöÑÊΩõÂú®ÂÇ∑ÂÆ≥Ôºå‰∏¶Á¢∫‰øùÂèØ‰ø°Ë≥¥ÊÄß„ÄÇÊú¨ÊñáËëóÈáçÊñºË™çË≠âÂíåÂèØËß£ÈáãÊÄßÔºåÊ¶ÇËø∞‰∫ÜÂ∑≤ÈñãÁôºÁî®ÊñºÁ¢∫‰øù AI Ê±∫Á≠ñÂÆâÂÖ®ÁöÑÊäÄË°ìÔºå‰∏¶Ë®éË´ñÊú™‰æÜÁöÑÊåëÊà∞„ÄÇ

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. Garc√≠a-G√≥mez, Vicent Blanes-Selva, Jos√© Carlos de Bartolom√© Cenzano, Jaime Cebolla-Cornejo, Ascensi√≥n Do√±ate-Mart√≠nez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

ÊëòË¶ÅÔºöÊ≠êÊ¥≤Ë≠∞ÊúÉË≠∞ÊúÉÁ†îÁ©∂ÊúçÂãôÁ∏ΩÂ±ÄÂ∑≤ÁÇ∫Ê≠êÊ¥≤Ë≠∞ÊúÉË≠∞Âì°Ê∫ñÂÇô‰∫Ü‰∏Ä‰ªΩÂ†±ÂëäÔºåÂÖ∂‰∏≠ÂàóËàâ‰∫Ü‰∫∫Â∑•Êô∫ËÉΩ (AI) Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑ‰∏ÉÈ†Ö‰∏ªË¶ÅÈ¢®Èö™ÔºöAI ÈåØË™§Â∞éËá¥ÊÇ£ËÄÖÂèóÂà∞ÂÇ∑ÂÆ≥„ÄÅÈÜ´ÁôÇ AI Â∑•ÂÖ∑Ë¢´Êø´Áî®„ÄÅAI Â≠òÂú®ÂÅèË¶ã‰∏¶Â∞éËá¥ÁèæÊúâ inequities ÊåÅÁ∫åÂ≠òÂú®„ÄÅÁº∫‰πèÈÄèÊòéÂ∫¶„ÄÅÈö±ÁßÅÂíåÂÆâÂÖ®ÂïèÈ°å„ÄÅÂïèË≤¨Â∑ÆË∑ù‰ª•ÂèäÂØ¶ÊñΩÈöúÁ§ô„ÄÇ
  Âú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂçÅÂõõÈ†ÖÂäüËÉΩÊÄßË¶ÅÊ±ÇÔºåAI Á≥ªÁµ±ÂèØ‰ª•ÂØ¶ÊñΩÈÄô‰∫õË¶ÅÊ±Ç‰æÜÈôç‰ΩéËàáÂÖ∂ÈÜ´ÁôÇÁõÆÁöÑÁõ∏ÈóúÁöÑÈ¢®Èö™ÔºöAI Ë≠∑ÁÖß„ÄÅ‰ΩøÁî®ËÄÖÁÆ°ÁêÜ„ÄÅÊ≥ïË¶èÊ™¢Êü•„ÄÅÂÉÖÈôêÂ≠∏Ë°ìÁî®ÈÄîÂÖçË≤¨ËÅ≤Êòé„ÄÅË≥áÊñôÂìÅË≥™Ë©ï‰º∞„ÄÅËá®Â∫äÈÜ´ÁîüÈõôÈáçÊ™¢Êü•„ÄÅÊåÅÁ∫åÊïàËÉΩË©ï‰º∞„ÄÅÁ®ΩÊ†∏ËøΩËπ§„ÄÅÊåÅÁ∫åÂèØÁî®ÊÄßÊ∏¨Ë©¶„ÄÅÂõûÈ°ßÂõûÊ∫Ø/Ê®°Êì¨Ê°à‰æã„ÄÅÂÅèË¶ãÊ™¢Êü•„ÄÅÂèØËß£Èáã AI„ÄÅÂä†ÂØÜÂíå‰ΩøÁî®Á∂ìÈÅéÂØ¶Âú∞Ê∏¨Ë©¶ÁöÑÁ®ãÂºèÂ∫´Ôºå‰ª•ÂèäË™ûÊÑè‰∫íÈÄöÊÄß„ÄÇ
  ÊàëÂÄëÂú®Ê≠§ÁöÑÁõÆÁöÑÊòØÊèê‰æõÊäÄË°ìËß£Ê±∫ÊñπÊ°àÁöÑÁâπÂÆöÈ´òÈöéË¶èÊ†ºÔºå‰ª•Á¢∫‰øùÊåÅÁ∫åËâØÂ•ΩÁöÑÊïàËÉΩÔºå‰∏¶‰ΩøÁî® AI Á≥ªÁµ±Ôºå‰ª•Á¨¶ÂêàÊú™‰æÜÁöÑÊ≠êÁõüÊ≥ïË¶èÊû∂ÊßãÔºåÂæûËÄå‰ΩøÊÇ£ËÄÖÂèóÁõä„ÄÇ

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÂèØÁî®ÊñºÂàÜÈ°ûÁóÖÊÇ£ÁöÑË∫´È´îÊ¥ªÂãï‰∏¶È†êÊ∏¨ÈÅ†Ë∑ùÁóÖÊÇ£Áõ£ÊéßÁöÑÈáçË¶ÅÁîüÂëΩÂæµË±°„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁ≠âÈùûÁ∑öÊÄßÊ®°ÂûãÁöÑÂõûÊ≠∏ÂàÜÊûêÁî±ÊñºÂÖ∂ÈªëÁõíÂ≠êÁöÑÊÄßË≥™ËÄåÂÖ∑ÊúâÊúâÈôêÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈÄôÂèØËÉΩÈúÄË¶ÅÊ±∫Á≠ñËÄÖÊ†πÊìöÈùûÁ∑öÊÄßÊ®°ÂûãÁµêÊûúÂÅöÂá∫Áõ≤ÁõÆÁöÑ‰ø°‰ª∞È£õË∫çÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠„ÄÇÂú®Èùû‰æµÂÖ•ÊÄßÁõ£Êéß‰∏≠Ôºå‰æÜËá™ËøΩËπ§ÊÑüÊ∏¨Âô®ÂíåÂÖ∂ÊòìÊÑüËá®Â∫äÂ±¨ÊÄßÁöÑÁóÖÊÇ£Ë≥áÊñôÂÖÖÁï∂È†êÊ∏¨Êú™‰æÜÁîüÂëΩÂæµË±°ÁöÑËº∏ÂÖ•ÁâπÂæµ„ÄÇËß£ÈáãÂêÑÁ®ÆÁâπÂæµÂ∞çÁõ£ÊéßÊáâÁî®Á®ãÂºèÊï¥È´îËº∏Âá∫ÁöÑË≤¢ÁçªÂ∞çÊñºËá®Â∫äÈÜ´ÁîüÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî®ÊñºÈáèÂåñÂàÜÊûêÁöÑÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (QXAI) Êû∂ÊßãÔºåË©≤Êû∂ÊßãÂÖ∑ÊúâÁõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ï‰∏≠ÂõûÊ≠∏ÂíåÂàÜÈ°û‰ªªÂãôÁöÑ‰∫ãÂæåÊ®°ÂûãÂèØËß£ÈáãÊÄßÂíåÂÖßÂú®ÂèØËß£ÈáãÊÄß„ÄÇÈÄôÈÄèÈÅéÂà©Áî® Shapley ÂÄºÊ¶ÇÂøµ‰∏¶Â∞áÊ≥®ÊÑèÂäõÊ©üÂà∂Á¥çÂÖ•Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æÜÂØ¶Áèæ„ÄÇÊàëÂÄëÊé°Áî®‰∫∫Â∑•Á•ûÁ∂ìÁ∂≤Ë∑Ø (ANN) ÂíåÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÈõôÂêë LSTM (BiLSTM) Ê®°ÂûãÔºåÊ†πÊìöÊÑüÊ∏¨Âô®Ë≥áÊñôÈ†êÊ∏¨ÂøÉÁéáÂíåÂàÜÈ°ûË∫´È´îÊ¥ªÂãï„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®È†êÊ∏¨ÂíåÂàÜÈ°û‰ªªÂãô‰∏≠ÈÉΩÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊàêÊûú„ÄÇÂ∞çËº∏ÂÖ•Ë≥áÊñôÈÄ≤Ë°åÂÖ®Â±ÄËß£ÈáãÂíåÂ±ÄÈÉ®Ëß£ÈáãÔºå‰ª•‰∫ÜËß£ÂêÑÁ®ÆÁóÖÊÇ£Ë≥áÊñôÁöÑÁâπÂæµË≤¢Áçª„ÄÇÊâÄÊèêÂá∫ÁöÑ QXAI Êû∂Êßã‰ΩøÁî® PPG-DaLiA Ë≥áÊñôË©ï‰º∞Ôºå‰ª•È†êÊ∏¨ÂøÉÁéáÔºå‰∏¶‰ΩøÁî®Ë°åÂãïÂÅ•Â∫∑ (MHEALTH) Ë≥áÊñôÊ†πÊìöÊÑüÊ∏¨Âô®Ë≥áÊñôÂ∞çË∫´È´îÊ¥ªÂãïÈÄ≤Ë°åÂàÜÈ°û„ÄÇËíôÂú∞Âç°ÁæÖËøë‰ººÊ≥ïÊáâÁî®ÊñºË©≤Êû∂ÊßãÔºå‰ª•ÂÖãÊúç Shapley ÂÄºË®àÁÆóÊâÄÈúÄÁöÑÊôÇÈñìË§áÈõúÂ∫¶ÂíåÈ´òÈÅãÁÆóËÉΩÂäõÈúÄÊ±Ç„ÄÇ

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

ÊëòË¶ÅÔºöÂú®ÂèØËß£Èáä‰∫∫Â∑•Êô∫ËÉΩ (XAI) Á†îÁ©∂‰∏≠Ôºå‰∏ªË¶ÅÈáçÁÇπÂú®‰∫é‰∏∫‰∏ìÂÆ∂Âíå‰ªé‰∏öËÄÖËß£ÈáäÊ®°Âûã„ÄÇÊ®°Âûã‰∏çÂèØÁü•ÂíåÂ±ÄÈÉ®Ëß£ÈáäÊñπÊ≥ïÂú®ËÆ∏Â§öÂ∫îÁî®‰∏≠Ë¢´ËÆ§‰∏∫ÊòØÂèØËß£Èáä‰∏îË∂≥Â§üÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂú®ÂåªÁñó‰øùÂÅ•Á≠âÈ¢ÜÂüüÔºåÊúÄÁªàÁî®Êà∑ÊòØÁº∫‰πè‰∫∫Â∑•Êô∫ËÉΩÊàñÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÁöÑÊÇ£ËÄÖÔºåÂõ†Ê≠§Ëø´ÂàáÈúÄË¶ÅÊõ¥Êòì‰∫éÁêÜËß£‰∏îËÉΩÊøÄÂèëÂØπÊ®°ÂûãÊìç‰ΩúÁöÑ‰ø°‰ªªÁöÑÊ®°ÂûãËß£Èáä„ÄÇÊàë‰ª¨ÂÅáËÆæÁîüÊàêÂèôËø∞ÊÄß„ÄÅÊÇ£ËÄÖÁâπÂÆö‰∏îÂÖ®Â±ÄÔºàÊ®°ÂûãÊï¥‰ΩìÔºâÁöÑÊ®°ÂûãËß£ÈáäÂ∞ÜËÉΩÂ§üÊèêÈ´òÂèØÁêÜËß£ÊÄßÂπ∂ÊîØÊåÅÂÜ≥Á≠ñÂà∂ÂÆö„ÄÇÊàë‰ª¨‰ΩøÁî®ÂÜ≥Á≠ñÊ†ëÊ®°ÂûãÂØπÊ≠§ËøõË°åÊµãËØïÔºå‰∏∫Ë¢´ËØÜÂà´‰∏∫ÊÇ£ÊúâÂÜ†ÂøÉÁóÖÈ´òÈ£éÈô©ÁöÑÊÇ£ËÄÖÁîüÊàêÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄËß£Èáä„ÄÇËøô‰∫õËß£Èáä‰ºöÂëàÁé∞ÁªôÈùû‰∏ìÂÆ∂Áî®Êà∑„ÄÇÊàë‰ª¨ÂèëÁé∞Áî®Êà∑Âº∫ÁÉàÂÅèÂ•ΩÁâπÂÆöÁ±ªÂûãÁöÑËß£Èáä„ÄÇÂ§ßÂ§öÊï∞ÂèÇ‰∏éËÄÖÂÅèÂ•ΩÂÖ®Â±ÄËß£ÈáäÔºåËÄåËæÉÂ∞èÁöÑ‰∏ÄÁªÑÂèÇ‰∏éËÄÖÂÅèÂ•ΩÂ±ÄÈÉ®Ëß£Èáä„ÄÇÂü∫‰∫é‰ªªÂä°ÁöÑÂøÉÁêÜÊ®°ÂûãËØÑ‰º∞‰∏∫Ëøô‰∫õÂèÇ‰∏éËÄÖÊèê‰æõ‰∫ÜÊúâ‰ª∑ÂÄºÁöÑÂèçÈ¶àÔºå‰ª•Â¢ûÂº∫ÂèôËø∞ÊÄßÂÖ®Â±ÄËß£Èáä„ÄÇËøôÂèçËøáÊù•ÂèàÊåáÂØº‰∫ÜÊó¢ÂÄºÂæó‰ø°ËµñÂèàÂèØÊìç‰ΩúÁöÑÂÅ•Â∫∑‰ø°ÊÅØÂ≠¶Á≥ªÁªüÁöÑËÆæËÆ°„ÄÇ

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Âíå‰æãË°åÊñá‰ª∂Ë®òÈåÑÂØ¶ÂãôÂú®ÁóÖÊÇ£ÁöÑÊó•Â∏∏ÁÖßË≠∑‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÊèê‰æõÂÅ•Â∫∑„ÄÅË®∫Êñ∑ÂíåÊ≤ªÁôÇÁöÑÊï¥È´îÁ¥ÄÈåÑ„ÄÇÁÑ∂ËÄåÔºåË§áÈõú‰∏îÂÜóÈï∑ÁöÑ EHR ÊïòËø∞ÊúÉËÆìÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖË∂ÖËºâÔºåÊúâË®∫Êñ∑‰∏çÊ∫ñÁ¢∫ÁöÑÈ¢®Èö™„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂÖ∂Âú®ÂêÑÁ®ÆË™ûË®Ä‰ªªÂãô‰∏äÁöÑÊΩõÂäõÔºå‰ΩÜÂÖ∂Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊáâÁî®ÈúÄË¶ÅÁ¢∫‰øùÂ∞áË®∫Êñ∑ÈåØË™§ÈôçÂà∞ÊúÄ‰ΩéÔºå‰∏¶Èò≤Ê≠¢ÁóÖÊÇ£ÂèóÂà∞ÂÇ∑ÂÆ≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ¶ÇËø∞‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÊï¥ÂêàÈÜ´Â≠∏Áü•Ë≠òÂúñË≠ú (KG) Âíå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂúñË≠úÊ®°ÂûãÔºöDr.KnowsÔºàÈùàÊÑü‰æÜËá™Ëá®Â∫äË®∫Êñ∑Êé®ÁêÜÈÅéÁ®ãÔºâÔºå‰æÜÂ¢ûÂº∑ LLM Âú®Ëá™ÂãïÂåñË®∫Êñ∑Áî¢ÁîüÈ†òÂüüÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂæûÁæéÂúãÂúãÂÆ∂ÈÜ´Â≠∏ÂúñÊõ∏È§®ÁöÑÁµ±‰∏ÄÈÜ´Â≠∏Ë™ûË®ÄÁ≥ªÁµ± (UMLS) ‰∏≠Ë°çÁîüÂá∫ KGÔºåÈÄôÊòØ‰∏ÄÂÄãÂº∑Â§ßÁöÑÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂÑ≤Â≠òÂ∫´„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂê¶ÂÆö‰∫ÜÈ†êÂÖàË®ìÁ∑¥ÁöÑÈúÄË¶ÅÔºåËÄåÊòØÂ∞á KG ‰ΩúÁÇ∫ËºîÂä©Â∑•ÂÖ∑ÔºåÂçîÂä©Ëß£ÈáãÂíåÁ∏ΩÁµêË§áÈõúÁöÑÈÜ´Â≠∏Ê¶ÇÂøµ„ÄÇ‰ΩøÁî®ÁúüÂØ¶‰∏ñÁïåÁöÑÈÜ´Èô¢Ë≥áÊñôÈõÜÔºåÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÂ∞á LLM Ëàá KG ÁµêÂêàÁöÑÂª∫Ë≠∞ÊñπÊ≥ïÊúâÊΩõÂäõÊèêÈ´òËá™ÂãïÂåñË®∫Êñ∑Áî¢ÁîüÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÊ¢ùÂèØËß£ÈáãÁöÑË®∫Êñ∑ÈÄîÂæëÔºåËÆìÊàëÂÄëÊõ¥Êé•ËøëÂØ¶Áèæ AI Â¢ûÂº∑ÁöÑË®∫Êñ∑Ê±∫Á≠ñÊîØÊè¥Á≥ªÁµ±„ÄÇ

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÁî®ÊñºË®∫Êñ∑ËÜùÈ™®ÈóúÁØÄÁÇé (OA) ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÂõ†ÂÖ∂Áº∫‰πèÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßËÄåÂèóÂà∞ÊâπË©ïÔºåÂÑòÁÆ°ÂÆÉÂÄëÈÅîÂà∞‰∫ÜÈ°û‰ººÈÜ´Â≠∏Â∞àÂÆ∂ÁöÑË°®Áèæ„ÄÇÈÄôÁ®Æ‰∏çÈÄèÊòéÊÄß‰ΩøÂæóÂÆÉÂÄëÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠Èõ£‰ª•Ë¢´‰ø°‰ªª„ÄÇÊúÄËøëÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂ∞àÈñÄÊäÄË°ìÔºåÂÆÉËÉΩÈÄèÈÅéÊè≠Á§∫È†êÊ∏¨ÁöÑÊé®Â∞éÊñπÂºè‰æÜÊèê‰æõÂ∞çÊ®°ÂûãÈ†êÊ∏¨ÁöÑ‰ø°ÂøÉÔºåÂæûËÄå‰øÉÈÄ≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî® AI Á≥ªÁµ±„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÈáùÂ∞çËÜùÈ™®ÈóúÁØÄÁÇéË®∫Êñ∑ÊâÄ‰ΩøÁî®ÁöÑ XAI ÊäÄË°ìÁöÑÁ¨¨‰∏Ä‰ªΩË™øÊü•„ÄÇXAI ÊäÄË°ìÂæûÂÖ©ÂÄãËßíÂ∫¶ÈÄ≤Ë°åË®éË´ñÔºöË≥áÊñôÂèØËß£ÈáãÊÄßÂíåÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÇÊú¨ÊñáÁöÑÁõÆÁöÑÊòØÊèê‰æõÂ∞ç XAI Âú®Êõ¥ÂèØÈù†ÁöÑËÜùÈ™®ÈóúÁØÄÁÇéË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊΩõÂäõÁöÑÂØ∂Ë≤¥Ë¶ãËß£Ôºå‰∏¶ÈºìÂãµÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠Êé°Áî®ÂÆÉ„ÄÇ

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

ÊëòË¶ÅÔºöÊúÄËøëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®ÈÄ≤Â±ïÈ°ØÁ§∫Âá∫‰ª§‰∫∫Èõ£‰ª•ÁΩÆ‰ø°ÁöÑÊâøË´æÔºåÂú®Ë®∫Êñ∑ÂíåÁñæÁóÖÈ†êÂæåÊñπÈù¢Ë∂ÖË∂ä‰∫∫È°ûË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÈö®Ëëó‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÁöÑÊó•ÁõäË§áÈõúÔºå‰∫∫ÂÄëÂ∞çÂÖ∂‰∏çÈÄèÊòéÊÄß„ÄÅÊΩõÂú®ÂÅèÂ∑ÆÂíåÂ∞çÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÊÑüÂà∞ÊìîÊÜÇ„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øù‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±ÁöÑ‰ø°‰ªªÂíåÂèØÈù†ÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨Ê®°Âûã‰∏≠ÔºåÂèØËß£ÈáãÊÄßËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÂèØËß£ÈáãÊÄßÈÄöÂ∏∏Ë¢´Á®±ÁÇ∫‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±Êèê‰æõÂÖ∂Ê±∫Á≠ñÈÇèËºØÊàñÊ±∫Á≠ñÊú¨Ë∫´Â∞ç‰∫∫È°ûÂà©ÁõäÁõ∏ÈóúËÄÖÁöÑÂº∑ÊúâÂäõËß£ÈáãÁöÑËÉΩÂäõ„ÄÇÂú®Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨‰∏≠ÔºåÂèØËß£ÈáãÊÄßÁöÑÂÖ∂‰ªñÊñπÈù¢ÔºåÂ¶ÇÂÖ¨Âπ≥ÊÄß„ÄÅÂÅèË¶ã„ÄÅ‰ø°‰ªªÂíåÈÄèÊòéÂ∫¶Ôºå‰πü‰ª£Ë°®‰∫ÜË∂ÖË∂äÂèØËß£ÈáãÊÄßÁöÑÈáçË¶ÅÊ¶ÇÂøµ„ÄÇÂú®Êú¨Ê¨°ÂØ©Êü•‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊ¶ÇÂøµ‰πãÈñìÁöÑÈóú‰øÇÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁ∂ìÂ∏∏‰∏ÄËµ∑Êàñ‰∫íÊèõ‰ΩøÁî®„ÄÇÊú¨ÂØ©Êü•ÈÇÑË®éË´ñ‰∫ÜÁÇ∫Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨ÈñãÁôºÂèØËß£ÈáãÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫äÂØ¶Ë∏ê‰∏≠Â∞çÂ§öÁ®ÆÂ∏∏Ë¶ãÊ®°ÂºèÈÄ≤Ë°åÂÆöÈáèÂíåËá®Â∫äË©ï‰º∞ÂíåÈ©óË≠âÁöÑÈáçË¶ÅÊÄß„ÄÇÂÆÉÂº∑Ë™ø‰∫ÜÂ§ñÈÉ®È©óË≠âÂíåÂ§öÊ®£ÂåñÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁõ∏ÁµêÂêàÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Â¢ûÂº∑‰ø°‰ªªÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÊé°Áî®Âö¥Ê†ºÁöÑÊ∏¨Ë©¶Ôºå‰æãÂ¶Ç‰ΩøÁî®ÂÖ∑ÊúâÂ∑≤Áü•ÁîüÊàêÂõ†Á¥†ÁöÑÂêàÊàêÊï∏ÊìöÈõÜÔºåÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÂèØÈù†ÊÄß„ÄÇÈñãÊîæÁç≤ÂèñÂíå‰ª£Á¢ºÂÖ±‰∫´Ë≥áÊ∫êÂ∞çÊñºÈÄèÊòéÂ∫¶ÂíåÂèØÈáçË§áÊÄßËá≥ÈóúÈáçË¶ÅÔºåÂæûËÄå‰øÉÈÄ≤ÂèØËß£ÈáãÁ†îÁ©∂ÁöÑÂ¢ûÈï∑ÂíåÂèØ‰ø°Â∫¶„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÂæûËá®Â∫äÈÜ´ÁîüÂà∞ÈñãÁôº‰∫∫Âì°ÔºåÊé°Áî®Á´ØÂà∞Á´ØÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞çÊñºËá®Â∫äÈ¢®Èö™È†êÊ∏¨ÁöÑÊàêÂäüËá≥ÈóúÈáçË¶Å„ÄÇ

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v1 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A Gonz√°lez, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Ir√®ne Buvat, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerd√° Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Llu√≠s Donoso-Bach, Luis Mart√≠-Bonmat√≠, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, Mohammed Ammar, M√≥nica Cano Abad√≠a, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver D√≠az, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Auss√≥, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, X√®nia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

ÊëòË¶ÅÔºöÂÑòÁÆ°Âú®ÈÜ´Â≠∏ÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊúâÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜ AI ÊäÄË°ìÁöÑÈÉ®ÁΩ≤ÂíåÊé°Áî®Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÂØ¶Âãô‰∏≠‰ªçÁÑ∂ÊúâÈôê„ÄÇËøëÂπ¥‰æÜÔºå‰∫∫ÂÄëÂ∞çËàáÈÜ´ÁôÇ AI Áõ∏ÈóúÁöÑÊäÄË°ì„ÄÅËá®Â∫ä„ÄÅÂÄ´ÁêÜÂíåÊ≥ïÂæãÈ¢®Èö™ÊèêÂá∫‰∫ÜÁñëÊÖÆ„ÄÇÁÇ∫‰∫ÜÂ¢ûÂä†ÂØ¶Èöõ‰∏ñÁïåÁöÑÊé°Áî®ÁéáÔºåÈÜ´ÁôÇ AI Â∑•ÂÖ∑ÂøÖÈ†àÁç≤ÂæóÊÇ£ËÄÖ„ÄÅËá®Â∫äÈÜ´Áîü„ÄÅÈÜ´ÁôÇÊ©üÊßãÂíåÁï∂Â±ÄÁöÑ‰ø°‰ªªÂíåÊé•Âèó„ÄÇÊú¨Á†îÁ©∂Â∞á FUTURE-AI ÊåáÂçóÊèèËø∞ÁÇ∫ÊåáÂ∞éÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂèØ‰ø°Ë≥¥ AI Â∑•ÂÖ∑ÈñãÁôºÂíåÈÉ®ÁΩ≤ÁöÑÁ¨¨‰∏ÄÂÄãÂúãÈöõÂÖ±Ë≠òÊ°ÜÊû∂„ÄÇFUTURE-AI ËÅØÁõüÊàêÁ´ãÊñº 2021 Âπ¥ÔºåÁõÆÂâçÁî±‰æÜËá™ 51 ÂÄãÂúãÂÆ∂/Âú∞ÂçÄÁöÑ 118 ‰ΩçË∑®È†òÂüüÂ∞àÂÆ∂ÁµÑÊàêÔºå‰ª£Ë°®ÊâÄÊúâÊ¥≤ÔºåÂåÖÊã¨ AI ÁßëÂ≠∏ÂÆ∂„ÄÅËá®Â∫äÈÜ´Áîü„ÄÅÂÄ´ÁêÜÂ≠∏ÂÆ∂ÂíåÁ§æÊúÉÁßëÂ≠∏ÂÆ∂„ÄÇÂú®ÂÖ©Âπ¥ÁöÑÊôÇÈñìË£°ÔºåË©≤ËÅØÁõüÈÄöÈÅé‰∏ÄÂÄãÂèçË¶ÜÈÅãÁÆóÁöÑÈÅéÁ®ãÂÆöÁæ©‰∫ÜÂèØ‰ø°Ë≥¥ AI ÁöÑÊåáÂ∞éÂéüÂâáÂíåÊúÄ‰Ω≥ÂØ¶ÂãôÔºåÂåÖÊã¨Ê∑±ÂÖ•ÁöÑÊñáÁçªÂõûÈ°ß„ÄÅ‰øÆÊîπÂæåÁöÑÂæ∑ÁàæËè≤Ë™øÊü•ÂíåÁ∑ö‰∏äÂÖ±Ë≠òÊúÉË≠∞„ÄÇFUTURE-AI Ê°ÜÊû∂ÊòØÂü∫ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂèØ‰ø°Ë≥¥ AI ÁöÑ 6 È†ÖÊåáÂ∞éÂéüÂâáÂª∫Á´ãÁöÑÔºåÂç≥ÂÖ¨Âπ≥ÊÄß„ÄÅÊôÆÈÅçÊÄß„ÄÅÂèØËøΩÊ∫ØÊÄß„ÄÅÂèØÁî®ÊÄß„ÄÅÂÅ•Â£ØÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÈÄöÈÅéÂÖ±Ë≠òÔºåÂÆöÁæ©‰∫Ü‰∏ÄÁµÑ 28 È†ÖÊúÄ‰Ω≥ÂØ¶ÂãôÔºåÊ∂µËìãÊäÄË°ì„ÄÅËá®Â∫ä„ÄÅÊ≥ïÂæãÂíåÁ§æÊúÉÂÄ´ÁêÜÂ±§Èù¢„ÄÇÂª∫Ë≠∞Ê∂µËìã‰∫ÜÈÜ´ÁôÇ AI ÁöÑÊï¥ÂÄãÁîüÂëΩÈÄ±ÊúüÔºåÂæûË®≠Ë®à„ÄÅÈñãÁôºÂíåÈ©óË≠âÂà∞Ê≥ïË¶è„ÄÅÈÉ®ÁΩ≤ÂíåÁõ£Êéß„ÄÇFUTURE-AI ÊòØ‰∏ÄÂÄãÂü∫ÊñºÈ¢®Èö™„ÄÅÁÑ°ÂÅáË®≠ÁöÑÊåáÂçóÔºåÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁµêÊßãÂåñÁöÑÊñπÊ≥ï‰æÜÊßãÂª∫ÂèØ‰ø°Ë≥¥„ÄÅÈÉ®ÁΩ≤ÂíåÊé°Áî®ÊñºÁèæÂØ¶‰∏ñÁïåÂØ¶Âãô‰∏≠ÁöÑÈÜ´ÁôÇ AI Â∑•ÂÖ∑„ÄÇÈºìÂãµÁ†îÁ©∂‰∫∫Âì°Âú®Ê¶ÇÂøµÈ©óË≠âÈöéÊÆµËÄÉÊÖÆÂª∫Ë≠∞Ôºå‰ª•‰øÉÈÄ≤Êú™‰æÜÂ∞áÈÜ´ÁôÇ AI ËΩâÂåñÁÇ∫Ëá®Â∫äÂØ¶Âãô„ÄÇ

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´ÁôÇÈ†òÂüü‰∏≠Â∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºåÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè„ÄÅÁóÖ‰∫∫ÁÖßË≠∑ÂíåÂÖ∂‰ªñÈ†òÂüü‰∏≠Âá∫Áèæ‰∫ÜÊñ∞ËààÊáâÁî®„ÄÇÈõñÁÑ∂ÈÄô‰∫õÊáâÁî®Â∑≤Âú®ÂõûÈ°ßÊÄßÁ†îÁ©∂‰∏≠Ë¢´Ë≠âÂØ¶ÊòØÊàêÂäüÁöÑÔºå‰ΩÜÂØ¶Èöõ‰∏äÂè™ÊúâÊ•µÂ∞ëÊï∏ÊáâÁî®ÊñºÂØ¶Âãô„ÄÇÈÜ´ÁôÇ AI È†òÂüüÈù¢Ëá®ËëóÂêÑÁ®ÆÊåëÊà∞ÔºåÂåÖÊã¨Âª∫Á´ã‰ΩøÁî®ËÄÖ‰ø°‰ªª„ÄÅÈÅµÂÆàÊ≥ïË¶è„ÄÅ‰ΩøÁî®Ë≥áÊñôÁ¨¶ÂêàÂÄ´ÁêÜ„ÄÇÂèØËß£Èáã AI (XAI) ÁöÑÁõÆÊ®ôÊòØËÆì‰∫∫È°û‰∫ÜËß£ AI ‰∏¶Áõ∏‰ø°ÂÖ∂ÁµêÊûú„ÄÇÊú¨ÊñáÈáùÂ∞çÊúÄËøëÂπæÂπ¥ÁôºË°®ÁöÑ 198 ÁØáÊñáÁ´†ÁöÑÂÖ∑‰ª£Ë°®ÊÄßÊ®£Êú¨ÔºåÊèêÂá∫ÊúâÈóúÈÜ´ÁôÇÊ±∫Á≠ñÊîØÊè¥ÁöÑ XAI Ëß£Ê±∫ÊñπÊ°àÁöÑÊúÄÊñ∞ÁôºÂ±ïÁöÑÊñáÁçªÂõûÈ°ß„ÄÇÁõ∏ÈóúÊñáÁ´†ÁöÑÁ≥ªÁµ±ÊÄßÁ∂úÂêàÊï¥ÁêÜÁî¢Áîü‰∫ÜÂ§öÈ†ÖÁôºÁèæÔºö(1) ÈÄô‰∫õËß£Ê±∫ÊñπÊ°àÂ§ßÂ§öÊé°Áî®ËàáÊ®°ÂûãÁÑ°ÈóúÁöÑ XAI ÊäÄË°ìÔºå(2) Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑ‰ΩøÁî®ÁéáÈ´òÊñºÂÖ∂‰ªñÈ°ûÂûãÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºå(3) ÂèØËß£ÈáãÊÄßË¢´Áî®Êñº‰øÉÈÄ≤‰ø°‰ªªÔºå‰ΩÜÂæàÂ∞ëÊúâÁ†îÁ©∂Â†±ÂëäÈÜ´Â∏´ÂèÉËàáËø¥ÂúàÔºå(4) Ë¶ñË¶∫Âíå‰∫íÂãïÂºè‰ΩøÁî®ËÄÖ‰ªãÈù¢Â∞çÊñºÁêÜËß£Á≥ªÁµ±ÁöÑËß£ÈáãÂíåÂª∫Ë≠∞Êõ¥ÊúâÁî®„ÄÇÈúÄË¶ÅÊõ¥Â§öÈÜ´ÁôÇÂíå AI Â∞àÂÆ∂Âêà‰ΩúÈÄ≤Ë°åÁ†îÁ©∂ÔºåÈÄôÊúâÂä©ÊñºÁÇ∫ÈÜ´ÁôÇÈ†òÂüüÁöÑ XAI Ëß£Ê±∫ÊñπÊ°àÁöÑË®≠Ë®à„ÄÅÂØ¶‰ΩúÂíåË©ï‰º∞Êèê‰æõÈÅ©Áï∂Êû∂Êßã„ÄÇ

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva C√≠vico, Sergio √Ålvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

ÊëòË¶ÅÔºöÈ´îÂ§ñÂèóÁ≤æÊòØÊ≤ªÁôÇ‰∏çÂ≠ïÁóáÊúÄÂª£Ê≥õÁöÑÊñπÊ≥ï‰πã‰∏Ä„ÄÇÂÖ∂‰∏ªË¶ÅÊåëÊà∞‰πã‰∏ÄÊòØË©ï‰º∞ÂíåÈÅ∏ÊìáËÉöËÉéÈÄ≤Ë°åÊ§çÂÖ•ÔºåÊ≠§ÈÅéÁ®ãÂÖ∑ÊúâÂæàÂ§ßÁöÑËá®Â∫äÈñìÂíåËá®Â∫äÂÖßËÆäÁï∞ÊÄß„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÊ≠£ÂèóÂà∞ÈóúÊ≥®Ôºå‰ΩÜÂÖ∂‰∏çÈÄèÊòéÁöÑÊÄßË≥™ÊúÉÂΩ±ÈüøÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊé•ÂèóÂ∫¶ÔºåËÄåÈÄèÊòéÂ∫¶Âú®Ê±∫Á≠ñÂà∂ÂÆö‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫Ü AI ËºîÂä©ËÉöËÉéÂàÜÊûêÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÊñπÈù¢ÁöÑÁèæÊúâÂ∑•‰ΩúÔºå‰∏¶ÊâæÂá∫ÂÖ∂Â±ÄÈôêÊÄß„ÄÇÊàëÂÄëÈÇÑË®éË´ñ‰∫ÜÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊ®°Âûã‰ΩúÁÇ∫Ê±∫Á≠ñÊîØÊåÅÁ≥ªÁµ±Êï¥ÂêàÂà∞Ëá®Â∫äÁí∞Â¢É‰∏≠ÔºåÂêåÊôÇËÄÉÊÖÆËá®Â∫äÈÜ´ÁîüÂíåÊÇ£ËÄÖÁöÑÈúÄÊ±Ç„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊèêÈ´òÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÁöÑÊ∫ñÂâáÔºåÊé®ÈÄ≤ÈÄôÈ†ÖÊäÄË°ìÊúùËëóÊó¢ÂÆöÁöÑËá®Â∫äÂØ¶ÂãôÈÇÅÈÄ≤„ÄÇ

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

ÊëòË¶ÅÔºöÂú®ÈúÄÊ±ÇÂ∑•Á®ã (RE) È†òÂüü‰∏≠ÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Âú®Â∞á AI ÊîØÊåÅÁöÑÁ≥ªÁµ±Ëàá‰ΩøÁî®ËÄÖÈúÄÊ±Ç„ÄÅÁ§æÊúÉÊúüÊúõÂíåÊ≥ïË¶èÊ®ôÊ∫ñÁõ∏Á¨¶ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄßÊó•ÁõäÈ°ØËëóÔºåÂ∑≤Áç≤ÂæóË™çÂèØ„ÄÇ‰∏ÄËà¨‰æÜË™™ÔºåÂèØËß£ÈáãÊÄßÂ∑≤ÊàêÁÇ∫ÂΩ±ÈüøÁ≥ªÁµ±ÂìÅË≥™ÁöÑÈáçË¶ÅÈùûÂäüËÉΩÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÂèØËß£ÈáãÊÄßËàáÊïàËÉΩ‰πãÈñìÁöÑÂÅáÂÆöÊ¨äË°°ÊåëÊà∞‰∫ÜÂèØËß£ÈáãÊÄßÁöÑÂÅáÂÆöÊ≠£Èù¢ÂΩ±Èüø„ÄÇÂ¶ÇÊûúÊªøË∂≥ÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÈúÄË¶ÅÈôç‰ΩéÁ≥ªÁµ±ÊïàËÉΩÔºåÈÇ£È∫ºÂøÖÈ†à‰ªîÁ¥∞ËÄÉÊÖÆÈÄô‰∫õÂìÅË≥™Èù¢Âêë‰∏≠Âì™‰∏ÄÂÄãÂÑ™ÂÖàÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂú®ÂÆÉÂÄë‰πãÈñìÈÄ≤Ë°åÊäòË°∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊâπÂà§ÊÄßÂú∞Êé¢Ë®é‰∫ÜÈÄôÁ®ÆÂÅáÂÆöÁöÑÊ¨äË°°„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÊúÄÂ•ΩÁöÑÊñπÊ≥ïÊòØ‰ª•‰∏ÄÁ®ÆÁ¥∞Á∑ªÁöÑÊñπÂºè‰æÜËôïÁêÜÔºåÈÄôÁ®ÆÊñπÂºèÂåÖÂê´Ë≥áÊ∫êÂèØÁî®ÊÄß„ÄÅÈ†òÂüüÁâπÊÄßÂíåÈ¢®Èö™ËÄÉÈáè„ÄÇÈÄèÈÅéÊèê‰æõÊú™‰æÜÁ†îÁ©∂ÂíåÊúÄ‰Ω≥ÂØ¶ÂãôÁöÑÂü∫Á§éÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®ÊèêÂçá AI ÁöÑ RE È†òÂüü„ÄÇ

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian Schl√ºter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

ÊëòË¶ÅÔºöÂú®ÈúÄÊ±ÇÂ∑•Á®ãÔºàREÔºâÈ¢ÜÂüüÔºåÂèØËß£Èáä‰∫∫Â∑•Êô∫ËÉΩÔºàXAIÔºâÂú®Â∞Ü‰∫∫Â∑•Êô∫ËÉΩÊîØÊåÅÁöÑÁ≥ªÁªü‰∏éÁî®Êà∑ÈúÄÊ±Ç„ÄÅÁ§æ‰ºöÊúüÊúõÂíåÁõëÁÆ°Ê†áÂáÜÁõ∏‰∏ÄËá¥ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄßÊó•ÁõäÂá∏ÊòæÔºåÂπ∂Ëé∑Âæó‰∫ÜËÆ§ÂèØ„ÄÇ‰∏ÄËà¨Êù•ËØ¥ÔºåÂèØËß£ÈáäÊÄßÂ∑≤Êàê‰∏∫ÂΩ±ÂìçÁ≥ªÁªüË¥®ÈáèÁöÑÈáçË¶ÅÈùûÂäüËÉΩÊÄßÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÂèØËß£ÈáäÊÄßÂíåÊÄßËÉΩ‰πãÈó¥ÁöÑÊùÉË°°ÊåëÊàò‰∫ÜÂèØËß£ÈáäÊÄßÁöÑÊ≠£Èù¢ÂΩ±Âìç„ÄÇÂ¶ÇÊûúÊª°Ë∂≥ÂèØËß£ÈáäÊÄßÁöÑË¶ÅÊ±ÇÈúÄË¶ÅÈôç‰ΩéÁ≥ªÁªüÊÄßËÉΩÔºåÈÇ£‰πàÂøÖÈ°ª‰ªîÁªÜËÄÉËôëËøô‰∫õË¥®ÈáèÊñπÈù¢‰∏≠ÁöÑÂì™‰∏Ä‰∏™‰ºòÂÖàÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂú®ÂÆÉ‰ª¨‰πãÈó¥ËøõË°åÊùÉË°°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊâπÂà§ÊÄßÂú∞ËÄÉÂØü‰∫ÜÊâÄË∞ìÁöÑÊùÉË°°„ÄÇÊàë‰ª¨ËÆ§‰∏∫ÔºåÊúÄÂ•Ω‰ª•‰∏ÄÁßçÁªÜËá¥ÂÖ•ÂæÆÁöÑÊñπÂºèÊù•Â§ÑÁêÜÂÆÉÔºåËøôÁßçÊñπÂºèÁªìÂêà‰∫ÜËµÑÊ∫êÂèØÁî®ÊÄß„ÄÅÈ¢ÜÂüüÁâπÂæÅÂíåÈ£éÈô©ËÄÉËôë„ÄÇÈÄöËøá‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂ÂíåÊúÄ‰Ω≥ÂÆûË∑µÊèê‰æõÂü∫Á°ÄÔºåËøôÈ°πÂ∑•‰ΩúÊó®Âú®Êé®Ëøõ‰∫∫Â∑•Êô∫ËÉΩÁöÑ RE È¢ÜÂüü„ÄÇ

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

ÊëòË¶ÅÔºöÊú¨ÊñáÂö¥Ê†ºË©ï‰º∞Ê≠êÊ¥≤ÂßîÂì°ÊúÉÊèêÂá∫ÁöÑ AI Ê≥ïÊ°àÂ∞çÈ¢®Èö™ÁÆ°ÁêÜÂíåÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂ∞çÂü∫Êú¨Ê¨äÂà©ÂíåÂÆâÂÖ®ÊßãÊàêÈ¢®Èö™ÁöÑÈ´òÈ¢®Èö™ AI Á≥ªÁµ±„ÄÇË©≤Ê≥ïÊ°àÊó®Âú®‰ª•Áõ∏Á®±ÁöÑÁõ£ÁÆ°Ë≤†Êìî‰øÉÈÄ≤„ÄåÂÄºÂæó‰ø°Ë≥¥„ÄçÁöÑ AI„ÄÇÂÖ∂ÈóúÊñºÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÁöÑÊ¢ùÊ¨æË¶ÅÊ±ÇÂ∞áÈ´òÈ¢®Èö™Á≥ªÁµ±ÁöÑÊÆòÈ§òÈ¢®Èö™Ê∏õ‰ΩéÊàñÊ∂àÈô§„ÄåÁõ°ÂèØËÉΩ„ÄçÔºå‰∏¶ËÄÉÊÖÆ„ÄåÊäÄË°ìÁãÄÊÖã„Äç„ÄÇÊ≠§Ê∫ñÂâáÔºåÁâπÂà•ÊòØÂ¶ÇÊûúÁãπÁæ©Ëß£ÈáãÔºåÁÑ°Ê≥ïÂü∑Ë°åÔºåÊó¢‰∏ç‰øÉÈÄ≤Áõ∏Á®±ÁöÑÁõ£ÁÆ°Ë≤†ÊìîÔºå‰πü‰∏ç‰øÉÈÄ≤ÂèØ‰ø°Ë≥¥ÊÄß„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåË≠∞ÊúÉÂ∞çÈ¢®Èö™ÁÆ°ÁêÜÊ¢ùÊ¨æÁöÑÊúÄÊñ∞‰øÆÊ≠£ËçâÊ°àÂºïÂÖ•‰∫Ü„ÄåÂêàÁêÜÊÄß„Äç„ÄÅÊàêÊú¨ÊïàÁõäÂàÜÊûêÔºå‰∏¶‰∏îÊõ¥ÈÄèÊòéÂú∞Ë™™Êòé‰∫ÜÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÂà§Êñ∑ÁöÑÂÉπÂÄºËßÄÂíåËÉåÊôØÊÄßË≥™„ÄÇÊú¨ÊñáË´ñË≠âË≠∞ÊúÉÁöÑÊñπÊ≥ïÊõ¥ÂèØË°åÔºå‰∏îËÉΩÊõ¥Â•ΩÂú∞Âπ≥Ë°°Áõ∏Á®±ÊÄßÂíåÂèØ‰ø°Ë≥¥ÊÄßÁöÑÁõÆÊ®ô„ÄÇÊú¨ÊñáË™™ÊòéÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÂà§Êñ∑‰∏≠ÁöÑÂêàÁêÜÊÄßÊúÉÂ∏∂‰æÜ‰ªÄÈ∫ºÔºå‰∏¶Ê†πÊìöÈÅéÂ§±Ê≥ïÂíåÊ≠êÊ¥≤ÈÜ´ÁôÇÂô®ÊùêÊ≥ïË¶è‰∏≠ÁöÑÂéüÂâáÈÄ≤Ë°åË™™Êòé„ÄÇÊú¨Êñá‰∏ªÂºµÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÂà§Êñ∑ÁöÑÊñπÊ≥ïÈúÄË¶ÅÁ©©Âõ∫ÁöÑÂÖ¨Ê∞ëÂêàÊ≥ïÊÄßÂü∫Á§éÔºöÂåÖÊã¨Áõ£ÁÆ°Ê©üÊßãÁöÑË©≥Á¥∞ÊåáÂ∞éÊàñÂèÉËàáÔºå‰ª•ÂèäÂèóÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÊúâÊÑèÁæ©ÊäïÂÖ•„ÄÇ

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊòØÊ©üÂô®Â≠∏Áøí‰∏≠Âø´ÈÄüÈÄ≤Â±ïÁöÑÈ†òÂüüÔºåÊó®Âú®Ëß£ÈñãË§áÈõúÊ®°ÂûãÁöÑÈ†êÊ∏¨„ÄÇXAI Âú®ÊïèÊÑüÊáâÁî®‰∏≠ÁâπÂà•ÈúÄË¶ÅÔºå‰æãÂ¶ÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåÁï∂Ë®∫Êñ∑„ÄÅÂª∫Ë≠∞ÂíåÊ≤ªÁôÇÈÅ∏ÊìáÂèØËÉΩ‰æùË≥¥Êñº‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÂÅöÂá∫ÁöÑÊ±∫Á≠ñÊôÇ„ÄÇ‰∫∫Â∑•Êô∫ÊÖßÊñπÊ≥ï‰πüÂ∑≤Âª£Ê≥õÁî®ÊñºËÄÅÂåñÁ†îÁ©∂ÔºåÁâπÂà•ÊòØÂú®ÈñãÁôºÁîüÁâ©ÊôÇÈêòÊ®°ÂûãÂíåË≠òÂà•ËÄÅÂåñÂíåËàáÂπ¥ÈΩ°Áõ∏ÈóúÁñæÁóÖÁöÑÁîüÁâ©Ê®ôË™åÁâ©ÊñπÈù¢„ÄÇÁÑ∂ËÄåÔºåÈÄôË£° XAI ÁöÑÊΩõÂäõÊúâÂæÖÂÖÖÂàÜË™çË≠ò„ÄÇÊàëÂÄëË®éË´ñ‰∫Ü XAI Âú®ÈñãÁôº„ÄåËÄÅÂåñÊôÇÈêò„ÄçÊñπÈù¢ÁöÑÊáâÁî®Ôºå‰∏¶Â∞çÊåâÁâπÂÆöÁîüÁêÜÁ≥ªÁµ±ÁöÑÈáçÈªûÂàÜÈ°ûÁöÑÊñáÁçªÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂàÜÊûê„ÄÇ

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, J√∂rg Schl√∂tterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

ÊëòË¶ÅÔºöÈÉ®ÂàÜÂéüÂûãÊ®°ÂûãÊòØÂèØËß£ÈáãË®≠Ë®àÁöÑÂΩ±ÂÉèÂàÜÈ°ûÂô®Ôºå‰πüÊòØÈªëÁÆ± AI ÁöÑ‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÈÄôÁØáË´ñÊñáÊé¢Ë®é‰∫ÜËß£ÈáãÊÄßÊ©üÂô®Â≠∏ÁøíÔºåÁâπÂà•ÊòØ PIP-NetÔºåÂú®ÁúüÂØ¶‰∏ñÁïåÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñô‰∏äËá™ÂãïÂåñË®∫Êñ∑ÊîØÊè¥ÁöÑÈÅ©Áî®ÊÄßÂíåÊΩõÂäõ„ÄÇPIP-Net Â≠∏Áøí‰∫∫È°ûÂèØÁêÜËß£ÁöÑÂéüÂûãÂΩ±ÂÉèÈÉ®ÂàÜÔºåÊàëÂÄëË©ï‰º∞ÂÖ∂Âú®È™®ÊäòÊ™¢Ê∏¨ÂíåÁöÆËÜöÁôåË®∫Êñ∑ÊñπÈù¢ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÁôºÁèæ PIP-Net ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãÁ¨¶ÂêàÈÜ´Â≠∏ÂàÜÈ°ûÊ®ôÊ∫ñÔºåÂêåÊôÇÂÉÖÊèê‰æõÂΩ±ÂÉèÂ±§Á¥öÈ°ûÂà•Ê®ôÁ±§„ÄÇÁî±Êñº PIP-Net Â∞çÂéüÂûãÁöÑÁÑ°Áõ£Áù£È†êË®ìÁ∑¥ÔºåÂõ†Ê≠§ÂèØ‰ª•ËºïÈ¨ÜË≠òÂà•Ë≥áÊñôÂìÅË≥™ÂïèÈ°åÔºå‰æãÂ¶Ç X ÂÖâ‰∏≠ÁöÑ‰∏çÈúÄË¶ÅÊñáÂ≠óÊàñÊ®ôÁ±§ÈåØË™§„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ¶ñÊ¨°Â±ïÁ§∫‰∫∫È°ûÂèØ‰ª•ÈÄèÈÅéÁõ¥Êé•ÂÅúÁî®‰∏çÈúÄË¶ÅÁöÑÂéüÂûã‰æÜÊâãÂãï‰øÆÊ≠£ PIP-Net ÁöÑÊé®ÁêÜ„ÄÇÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÈÉ®ÂàÜÂéüÂûãÊ®°ÂûãÁî±ÊñºÂÖ∂ÂèØËß£ÈáãÊÄßÂíåÈÄ≤ÈöéÊ®°ÂûãÈô§ÈåØÁöÑÊΩõÂäõÔºåÂõ†Ê≠§ÊúâÊúõÊáâÁî®ÊñºÈÜ´ÁôÇ„ÄÇ

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI (XAI) ÊòØÊ©üÂô®Â≠∏ÁøíÁ†îÁ©∂‰∏≠Êó•ÁõäÈáçË¶ÅÁöÑÈ†òÂüüÔºåÂÖ∂ÁõÆÊ®ôÊòØËÆìÈªëÁÆ±Ê®°ÂûãÈÄèÊòé‰∏îÂèØËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ XAI ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Áî±ÁâπÂæµÊ¢ù‰ª∂ÁΩÆÊèõÁî¢ÁîüÁöÑÊâÄË¨ÇÂèç‰∫ãÂØ¶Ë∑ØÂæë„ÄÇË©≤ÊºîÁÆóÊ≥ïÈÄèÈÅéË≠òÂà•ÁâπÂæµÁöÑÈ†ÜÂ∫èÁΩÆÊèõ‰æÜË°°ÈáèÁâπÂæµÈáçË¶ÅÊÄßÔºåÈÄô‰∫õÁΩÆÊèõÊúÄËÉΩÂΩ±ÈüøÊ®°ÂûãÈ†êÊ∏¨ÁöÑËÆäÂåñ„ÄÇÂÆÉÁâπÂà•ÈÅ©ÂêàÊ†πÊìöÂåÖÂê´È†òÂüüÁü•Ë≠òÁöÑÁü•Ë≠òÂúñË≠ú‰∏≠ÁöÑÂèç‰∫ãÂØ¶Ë∑ØÂæë‰æÜÁî¢ÁîüËß£Èáã„ÄÇÂèç‰∫ãÂØ¶Ë∑ØÂæëÂú®Ëß£ÈáãÂíåË¶ñË¶∫ÂåñÈªëÁÆ±Ê®°ÂûãÊôÇÔºåÁÇ∫ÁõÆÂâçÁöÑ XAI ÊñπÊ≥ïÂºïÂÖ•‰∫ÜÈ°çÂ§ñÁöÑÂúñÂΩ¢Á∂≠Â∫¶„ÄÇ‰ΩøÁî®ÂêàÊàêÂíåÈÜ´ÁôÇË≥áÊñôÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂØ¶Áî®ÈÅ©Áî®ÊÄß„ÄÇ

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

ÊëòË¶ÅÔºöÂú®‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÂèØËß£ÈáãÊÄßÈ†òÂüü‰∏≠ÔºåÂ∑≤Á∂ìÁúãÂà∞Ë∂ä‰æÜË∂äÂ§öÁöÑÁ†îÁ©∂ÂíåÂ≠∏Ë°ìËààË∂£„ÄÇÁÑ∂ËÄåÔºåÂú®Ëß£ÈáãÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÁµêÊûúÊôÇÁº∫‰πè‰∫∫ÊÄßÂåñÂíåÂÄã‰∫∫ÂåñÁöÑË©ÆÈáãÔºåÈÄôÈ°ØËëóÈòªÁ§ô‰∫ÜËá®Â∫äÈÜ´ÁîüÂú®Á†îÁ©∂ÂíåËá®Â∫äÂØ¶Âãô‰∏≠Êé•ÂèóÈÄô‰∫õÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÁöÑÁ†îÁ©∂‰ΩøÁî®Âèç‰∫ãÂØ¶Ëß£Èáã‰æÜÊé¢Ë®é„ÄåÂ¶ÇÊûúÔºü„ÄçÊÉÖÂ¢ÉÂú®ÈÜ´Â≠∏Á†îÁ©∂‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÊì¥Â±ïÊàëÂÄëÂ∞çÁî®ÊñºË®∫Êñ∑Â∞èÂÖíÂæåÈ°±Á™©ËÖ¶ËÖ´Áò§ÁöÑÁ£ÅÂÖ±ÊåØÊàêÂÉè (MRI) ÁâπÂæµÁöÑÁêÜËß£ÔºåË∂ÖË∂äÁèæÊúâÁöÑÁïåÁ∑ö„ÄÇÂú®ÊàëÂÄëÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÔºåÊâÄÊèêÂá∫ÁöÑÊ¶ÇÂøµÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ï‰æÜÊ™¢Ë¶ñÊõø‰ª£Ê±∫Á≠ñÊÉÖÂ¢ÉÔºåÊèê‰æõÂÄã‰∫∫ÂåñÂíåÁâπÂÆöÊñºÊÉÖÂ¢ÉÁöÑË¶ãËß£ÔºåÂæûËÄåËÉΩÂ§†È©óË≠âÈ†êÊ∏¨‰∏¶ÈáêÊ∏ÖÂú®‰∏çÂêåÊÉÖÊ≥Å‰∏ãÁöÑÂ∑ÆÁï∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂèç‰∫ãÂØ¶Áî®ÊñºË≥áÊñôÊì¥ÂÖÖÁöÑÊΩõÂú®Áî®ÈÄîÔºå‰∏¶Ë©ï‰º∞ÂÖ∂‰ΩúÁÇ∫ÊàëÂÄëÈÜ´Â≠∏Á†îÁ©∂Ê°à‰æã‰∏≠Êõø‰ª£ÊñπÊ≥ïÁöÑÂèØË°åÊÄß„ÄÇÁµêÊûúË≠âÊòé‰∫Ü‰ΩøÁî®Âèç‰∫ãÂØ¶Ëß£Èáã‰æÜÂ¢ûÂº∑Ëá®Â∫äÁ†îÁ©∂‰∏≠ AI È©ÖÂãïÊñπÊ≥ïÁöÑÊé•ÂèóÂ∫¶ÁöÑÊΩõÂäõ„ÄÇ

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

ÊëòË¶ÅÔºöÁõÆÂâç‰∫∫Â∑•Êô∫ËÉΩÈ†òÂüüÁöÑÈÄ≤Â±ïÂ∞éËá¥‰∫ÜÂêÑÁ®ÆÈ°ûÂûãÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÁöÑÂ§±Êô∫ÁóáË©ï‰º∞ÁöÑÁôºÂ±ïÔºåÂèØÁî®ÊñºË≠òÂà•ËôïÊñºÂ§±Êô∫ÁóáÊó©ÊúüÈöéÊÆµÁöÑÊÇ£ËÄÖ„ÄÇÂÆÉÂèØ‰ª•ÂæπÂ∫ïÊîπËÆäÂ§±Êô∫ÁóáË≠∑ÁêÜË®≠ÁΩÆ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÈÜ´ÁôÇÁïåË¶Å‰∫ÜËß£ÂêÑÁ®Æ‰∫∫Â∑•Êô∫ËÉΩË©ï‰º∞Ôºå‰∏¶Ê†πÊìöÂÖ∂ÊúâÊïàÊÄß„ÄÅÊïàÁéá„ÄÅÂØ¶Áî®ÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÁ®ãÂ∫¶ÔºåËÄÉÊÖÆÈÅ∏ÊìáÂÆÉÂÄë‰æÜÊó©ÊúüË≠òÂà•Â§±Êô∫ÁóáÊÇ£ËÄÖ (PwD)„ÄÇÂè¶‰∏ÄÊñπÈù¢Ôºå‰∫∫Â∑•Êô∫ËÉΩÈñãÁôº‰∫∫Âì°‰πüÊáâË©≤‰∫ÜËß£ÂêÑÁ®ÆÈùû‰∫∫Â∑•Êô∫ËÉΩË©ï‰º∞‰ª•ÂèäÊúÄËøëÈñãÁôºÁöÑ‰∫∫Â∑•Êô∫ËÉΩË©ï‰º∞„ÄÇÂõ†Ê≠§ÔºåÈÄôÁØáËá®Â∫äÈÜ´ÁîüÂíå‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÂ∏´ÈÉΩÂèØ‰ª•Èñ±ËÆÄÁöÑË´ñÊñáÂ°´Ë£ú‰∫ÜÊñáÁçª‰∏≠ÈóúÊñºÂêëËá®Â∫äÈÜ´ÁîüËß£ÈáãÁèæÊúâÂ§±Êô∫ÁóáË≠òÂà•Ëß£Ê±∫ÊñπÊ°à‰ª•ÂèäÂêë‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÂ∏´Ëß£ÈáãÊâÄÁî®ÊäÄË°ìÂíåÊúÄÂª£Ê≥õÁöÑÂ§±Êô∫ÁóáÊï∏ÊìöÈõÜÁöÑÁ©∫ÁôΩ„ÄÇÂÆÉÈÅµÂæ™Â∞ç‰∫∫Â∑•Êô∫ËÉΩÂíåÈùû‰∫∫Â∑•Êô∫ËÉΩÂ§±Êô∫ÁóáË©ï‰º∞Ë´ñÊñáÁöÑÂõûÈ°ßÔºåÁÇ∫‰∫∫Â∑•Êô∫ËÉΩÂíåÈÜ´ÁôÇÁïåÊèê‰æõÊúâÈóúÂêÑÁ®ÆÂ§±Êô∫ÁóáË©ï‰º∞ÁöÑÂØ∂Ë≤¥‰ø°ÊÅØ„ÄÇË®éË´ñÂíåÁµêË´ñÈáçÈªû‰ªãÁ¥π‰∫ÜÊúÄÁ™ÅÂá∫ÁöÑÁ†îÁ©∂ÊñπÂêëÂíåÁèæÊúâËß£Ê±∫ÊñπÊ°àÁöÑÊàêÁÜüÂ∫¶„ÄÇ

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

ÊëòË¶ÅÔºö<paragraph>ÂèØËß£ÈáãÊÄßÂ∞ç‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÊßãÊàê‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÁï∂ÂâçÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂Áº∫‰πèÊèêÂèñÂ≠∏Áøí‰ªªÂãôÊï¥È´îÁü•Ë≠òÁöÑÊïàÁéáÔºåÂõ†Ê≠§Â≠òÂú®‰∏çÁ≤æÁ¢∫ÁöÑÈ°ØËëóÊÄß„ÄÅËàáÊÉÖÂ¢ÉÁÑ°ÈóúÁöÑÁº∫Â§±ÂíåÂê´Á≥äÊÑèÁæ©Á≠âÁº∫Èô∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫È°ûÂà•ÈóúËÅØÂµåÂÖ• (CAE) ÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊàëÂÄëÊé°Áî®Á∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Êû∂Êßã‰æÜÂµåÂÖ•Ê®£Êú¨ÁâπÂæµÔºå‰∏¶ÂêåÊôÇÂ∞áÂÆÉÂÄëÂàÜÁÇ∫È°ûÂà•Áõ∏ÈóúÂíåÂÄãÈ´îÁõ∏ÈóúÁöÑÊ®£ÂºèÂêëÈáè„ÄÇÂ∞áÁµ¶ÂÆöÊ®£Êú¨ÁöÑÂÄãÈ´îÊ®£Âºè‰ª£Á¢ºËàáÂè¶‰∏ÄÂÄãÊ®£Êú¨ÁöÑÈ°ûÂà•Ê®£Âºè‰ª£Á¢ºÈáçÊñ∞ÁµÑÂêàÔºåÊúÉÁî¢Áîü‰∏ÄÂÄãÂÖ∑Êúâ‰øùÁïôÂÄãÈ´îÁâπÂæµ‰ΩÜÊîπËÆäÈ°ûÂà•ÂàÜÈÖçÁöÑÂêàÊàêÊ®£Êú¨ÔºåÈÅµÂæ™Âæ™Áí∞Â∞çÊäóÂ≠∏ÁøíÁ≠ñÁï•„ÄÇÈ°ûÂà•ÈóúËÅØÂµåÂÖ•Â∞áÊâÄÊúâÂØ¶‰æãÁöÑÂÖ®Â±ÄÈ°ûÂà•Áõ∏ÈóúÁâπÂæµÊèêÁÖâÂà∞‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÈ†òÂüü‰∏≠Ôºå‰∏¶Âú®È°ûÂà•‰πãÈñìÊúâËâØÂ•ΩÁöÑÂçÄÂàÜ„ÄÇÁÑ∂ÂæåÂèØ‰ª•ÊèêÂèñ‰∏çÂêåÈ°ûÂà•‰πãÈñìÁöÑËΩâÊèõË¶èÂâáÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÊáâÁî®ÊñºÂÄãÂà•ÂØ¶‰æã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰∏ªÂãï XAI Ê°ÜÊû∂ÔºåÂÆÉÊ≤øËëóÂºïÂ∞éË∑ØÂæëÊìç‰ΩúÁâπÂÆöÊ®£Êú¨ÁöÑÈ°ûÂà•Ê®£ÂºèÂêëÈáèÔºåÊúùËëóÂèçÈ°ûÂà•ÁßªÂãïÔºåÂæûËÄåÁî¢Áîü‰∏ÄÁ≥ªÂàóÂÖ∑ÊúâÁõ∏ÂêåÂÄãÈ´îÁâπÂæµÁöÑÂèç‰æãÂêàÊàêÊ®£Êú¨„ÄÇÂ∞áÈÄô‰∫õÂèç‰∫ãÂØ¶Ê®£Êú¨ËàáÂéüÂßãÊ®£Êú¨ÈÄ≤Ë°åÊØîËºÉÔºåÂèØ‰ª•Â∞çÂàÜÈ°û‰ªªÂãôÁöÑÊÄßË≥™Êèê‰æõÂÖ®Â±Ä„ÄÅÁõ¥ËßÄÁöÑË™™Êòé„ÄÇÊàëÂÄëÊé°Áî®Ë©≤Ê°ÜÊû∂ÈÄ≤Ë°åÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÔºåÁµêÊûúË°®ÊòéÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÂèØ‰ª•Áç≤ÂæóÊõ¥Á≤æÁ¢∫ÁöÑÈ°ØËëóÊÄßÂúñÔºå‰∏¶ÂÖ∑ÊúâÂº∑Â§ßÁöÑËàáÊÉÖÂ¢ÉÁÑ°ÈóúÁöÑË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÁñæÁóÖÁóÖÁêÜÂ≠∏ÂèØ‰ª•Áõ¥Êé•ÈÄöÈÅéÂú®È°ûÂà•Ê®£ÂºèÁ©∫Èñì‰∏≠ÈÅçÊ≠∑Ë∑ØÂæë‰æÜÈÄ≤Ë°åÂèØË¶ñÂåñ„ÄÇ</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, I√±igo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

ÊëòË¶ÅÔºöÊèê‰æõÂü∫ÊñºÊ©üÂô®Â≠∏ÁøíÁöÑ AI È†êÊ∏¨ÁöÑÈ´òÂìÅË≥™Ë™™ÊòéÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÂíåË§áÈõúÊÄßÁöÑ‰ªªÂãô„ÄÇË¶ÅÈ†ÜÂà©ÈÄ≤Ë°åÔºåÂÆÉÈúÄË¶ÅÂÖ∑ÂÇô‰∏ãÂàóÂõ†Á¥†ÔºöÈÅ∏ÊìáÈÅ©Áï∂ÁöÑË™™ÊòéÊôÆÈÅçÊÄß/ÁâπÊÆäÊÄßÂ±§Á¥öÔºõËÄÉÈáèË™™ÊòéÂèóÁõä‰∫∫Â∞çÊâÄËÄÉÊÖÆÁöÑ AI ‰ªªÂãôÁöÑÁÜüÊÇâÁ®ãÂ∫¶ÂÅáË®≠ÔºõÂèÉÁÖß‰øÉÊàêÊ±∫Á≠ñÁöÑÁâπÂÆöÂÖÉÁ¥†ÔºõÂà©Áî®ÂèØËÉΩ‰∏çÂ±¨ÊñºÈ†êÊ∏¨Á®ãÂ∫èÁöÑ‰∏ÄÈÉ®ÂàÜÁöÑÈ°çÂ§ñÁü•Ë≠òÔºà‰æãÂ¶ÇÂ∞àÂÆ∂Ë≠âÊìöÔºâÔºõ‰∏¶Êèê‰æõÊîØÊåÅÂê¶ÂÆöÂÅáË®≠ÁöÑË≠âÊìö„ÄÇÊúÄÂæåÔºåÁ≥ªÁµ±ÈúÄË¶Å‰ª•Ê∏ÖÊô∞ÂèØËß£Èáã‰∏îÂèØËÉΩ‰ª§‰∫∫‰ø°ÊúçÁöÑÊñπÂºèÂà∂ÂÆöË™™Êòé„ÄÇÂü∫ÊñºÈÄô‰∫õËÄÉÈáèÔºåANTIDOTE ‰øÉÊàê‰∫ÜÂèØËß£Èáã AI ÁöÑÊï¥ÂêàÈ°òÊôØÔºåÂÖ∂‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÁ®ãÂ∫èÁöÑ‰ΩéÈöéÁâπÂæµËàá‰∫∫È°ûË´ñË≠âËÉΩÂäõÁöÑÈ´òÈöéÊû∂ÊßãÁõ∏ÁµêÂêà„ÄÇANTIDOTE Â∞áÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíËàáË´ñË≠âÁöÑË∑®È†òÂüüËÉΩÂäõÔºå‰æÜÊîØÊåÅÂèØËß£Èáã AI Êõ¥Âª£Ê≥õ‰∏îÂâµÊñ∞ÁöÑËßÄÈªûÔºåÂÖ∂‰∏≠Â∞çËá®Â∫äÊ°à‰æãÂØ©Ë≠∞ÁöÑÈ´òÂìÅË≥™Ë™™ÊòéÈúÄÊ±ÇËá≥ÈóúÈáçË¶Å„ÄÇ‰ΩúÁÇ∫Ë©≤Â∞àÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÊàêÊûúÔºåÊàëÂÄëÁôºÂ∏É‰∫Ü Antidote CasiMedicos Ë≥áÊñôÈõÜÔºå‰ª•Âà©Êñº‰∏ÄËà¨ÂèØËß£Èáã AI ÁöÑÁ†îÁ©∂ÔºåÁâπÂà•ÊòØÈÜ´ÁôÇÈ†òÂüüÁöÑË´ñË≠â„ÄÇ

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈÄ≤Â±ïËøÖÈÄüÔºåÂú®Ëó•Áâ©ÁôºÁèæ„ÄÅÈÜ´ÁôÇË®∫Êñ∑ÂíåÊé®Ëñ¶Á≥ªÁµ±ÊñπÈù¢ÈÉΩÊúâË®±Â§öÊñ∞ÁôºÂ±ï„ÄÇÈõñÁÑ∂ÈÄô‰∫õÈÄ≤Â±ïÂæàÈáçË¶ÅÔºå‰ΩÜË®±Â§öÁ∂≤Ë∑ØÈÉΩÊòØ„ÄåÈªëÁõíÂ≠ê„ÄçÔºåÂ∞çÊñºÁ∂≤Ë∑ØÂà∞Â∫ïÂú®Â≠∏Áøí„Äå‰ªÄÈ∫º„Äç‰∫ÜËß£ÁîöÂ∞ë„ÄÇË®±Â§öÈ´òÈ¢®Èö™ÊáâÁî®Ôºå‰æãÂ¶ÇËó•Áâ©ÁôºÁèæÔºåÈúÄË¶ÅÊ®°ÂûãÊèê‰æõ‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑËß£ÈáãÔºå‰ª•‰æø‰ΩøÁî®ËÄÖÂèØ‰ª•Ëæ®Ë≠òÈåØË™§‰∏¶ÁôºÁèæÊñ∞Áü•Ë≠ò„ÄÇÂõ†Ê≠§ÔºåÂèØËß£Èáã AI ÊºîÁÆóÊ≥ïÁöÑÈñãÁôºÂ∞çÊñºÊàëÂÄëÁç≤Âèñ AI ÁöÑÂ•ΩËôïËá≥ÈóúÈáçË¶Å„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ eXplainable Insight (XInsight) ÁöÑ GNN ÂèØËß£ÈáãÊÄßÊºîÁÆóÊ≥ïÔºåÂÆÉ‰ΩøÁî® GFlowNets Áî¢ÁîüÊ®°ÂûãËß£ÈáãÂàÜ‰Ωà„ÄÇÁî±Êñº GFlowNets ÊúÉÁî¢ÁîüÊ©üÁéáËàáÁçéÂãµÊàêÊ≠£ÊØîÁöÑÁâ©‰ª∂ÔºåÂõ†Ê≠§ËàáÂÖàÂâçÂÉÖÂ≠∏ÁøíÊúÄÂ§ßÁçéÂãµÁØÑ‰æãÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåXInsight ÂèØ‰ª•Áî¢ÁîüÂ§öÊ®£ÂåñÁöÑËß£ÈáãÈõÜÂêà„ÄÇÊàëÂÄëÈÄèÈÅéÁÇ∫Âú®ÂÖ©ÂÄãÂúñÂΩ¢ÂàÜÈ°û‰ªªÂãô‰∏≠Ë®ìÁ∑¥ÁöÑ GNN Áî¢ÁîüËß£Èáã‰æÜÂ±ïÁ§∫ XInsightÔºö‰ΩøÁî® MUTAG Ë≥áÊñôÈõÜÂ∞çËá¥Á™ÅËÆäÂåñÂêàÁâ©ÈÄ≤Ë°åÂàÜÈ°ûÔºå‰∏¶‰ΩøÁî®ÊàëÂÄëÂ∑≤ÈñãÊîæÂéüÂßãÁ¢ºÁöÑÂêàÊàêË≥áÊñôÈõÜÂ∞çÈùûÁí∞ÁãÄÂúñÂΩ¢ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî® QSAR Âª∫Ê®°ÂàÜÊûêÁî¢ÁîüÁöÑÂåñÂêàÁâ©‰æÜÂ±ïÁ§∫ XInsight Ëß£ÈáãÁöÑÊïàÁî®ÔºåÊàëÂÄëÁôºÁèæ XInsight ÊúÉÁî¢ÁîüÊåâË¶™ËÑÇÊÄßÔºàÂ∑≤Áü•ÁöÑËá¥Á™ÅËÆäÁõ∏ÈóúÊÄßÔºâÂàÜÁæ§ÁöÑÂåñÂêàÁâ©„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ XInsight ÊúÉÁî¢Áîü‰∏ÄÂÄãËß£ÈáãÂàÜ‰ΩàÔºåÊè≠Á§∫Ê®°ÂûãÊâÄÂ±ïÁ§∫ÁöÑÂ∫ïÂ±§Èóú‰øÇ„ÄÇÂÆÉÂÄë‰πüÂº∑Ë™øÁî¢ÁîüÂ§öÊ®£ÂåñËß£ÈáãÈõÜÂêàÁöÑÈáçË¶ÅÊÄßÔºåÂõ†ÁÇ∫ÂÆÉ‰ΩøÊàëÂÄëËÉΩÂ§†ÁôºÁèæÊ®°Âûã‰∏≠ÁöÑÈö±ËóèÈóú‰øÇÔºå‰∏¶ÁÇ∫ÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêÊèê‰æõÊúâÂÉπÂÄºÁöÑÊåáÂ∞é„ÄÇ</paragraph>

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton, Zhihuai Zhu, Elton Yechao Zhu, Serdar Kadƒ±oƒülu, Sima E. Borujeni, Helmut G. Katzgraber

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∏¶ÂØ¶‰Ωú‰∏ÄÂÄãÂèØËß£ÈáãÊ©üÂô®Â≠∏ÁøíÂàÜÈ°ûÊ®°ÂûãÔºåÁî®ÊñºÂü∫ÊñºË°®ÈÅîÂºèÂ∏ÉÊûóÂÖ¨ÂºèÁöÑÂèØËß£Èáã AI (XAI)„ÄÇÊΩõÂú®ÊáâÁî®ÂåÖÊã¨‰ø°Áî®Ë©ïÂàÜÂíåÈÜ´ÁôÇÁãÄÊ≥ÅË®∫Êñ∑„ÄÇÂ∏ÉÊûóÂÖ¨ÂºèÂÆöÁæ©‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÂèØË™øÊï¥Ë§áÈõúÊÄßÔºàÊàñÂèØËß£ÈáãÊÄßÔºâÁöÑË¶èÂâáÔºåÊ†πÊìöË©≤Ë¶èÂâáÂ∞çËº∏ÂÖ•Êï∏ÊìöÈÄ≤Ë°åÂàÜÈ°û„ÄÇÈÄôÊ®£ÁöÑÂÖ¨ÂºèÂèØ‰ª•ÂåÖÂê´‰ªª‰ΩïÂèØÊáâÁî®Êñº‰∏ÄÂÄãÊàñÂ§öÂÄãÂ∏ÉÊûóËÆäÊï∏ÁöÑÈÅãÁÆóÂ≠êÔºåÂæûËÄåËàáÊõ¥Âö¥Ê†ºÁöÑÂü∫ÊñºË¶èÂâáÂíåÂü∫ÊñºÊ®πÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÊèê‰æõÊõ¥È´òÁöÑË°®ÈÅîËÉΩÂäõ„ÄÇÂàÜÈ°ûÂô®‰ΩøÁî®ÂéüÁîüÂ±ÄÈÉ®ÊúÄ‰Ω≥ÂåñÊäÄË°ìÈÄ≤Ë°åË®ìÁ∑¥ÔºåÊúâÊïàÂú∞ÊêúÁ¥¢ÂèØË°åÂÖ¨ÂºèÁöÑÁ©∫Èñì„ÄÇÊ∑∫Â±§Ë¶èÂâáÂèØ‰ª•Áî®Âø´ÈÄüÁöÑÊï¥Êï∏Á∑öÊÄßË¶èÂäÉ (ILP) Êàñ‰∫åÊ¨°ÁÑ°Á¥ÑÊùü‰∫åÂÖÉÊúÄ‰Ω≥Âåñ (QUBO) Ê±ÇËß£Âô®‰æÜÁ¢∫ÂÆöÔºåÈÄô‰∫õÊ±ÇËß£Âô®ÂèØËÉΩÁî±ÁâπÊÆäÁî®ÈÄîÁöÑÁ°¨È´îÊàñÈáèÂ≠êË£ùÁΩÆÊèê‰æõÊîØÊè¥„ÄÇÊàëÂÄëÂ∞áÂéüÁîüÂ±ÄÈÉ®ÊúÄ‰Ω≥ÂåñÂô®ÁöÑË°®ÈÅîËÉΩÂäõÂíåÊïàÁéáËàáÈÄô‰∫õË£ùÁΩÆÁöÑÂø´ÈÄüÈÅãÁÆóÁõ∏ÁµêÂêàÔºåÈÄèÈÅéÂü∑Ë°åÈùûÂ±ÄÈÉ®ÁßªÂãï‰æÜÊúÄ‰Ω≥ÂåñÂÆåÊï¥Â∏ÉÊûóÂÖ¨ÂºèÁöÑÂ≠êÊ®π„ÄÇÊàëÂÄëÊèê‰æõÂª£Ê≥õÁöÑÊï∏ÂÄºÂü∫Ê∫ñÊ∏¨Ë©¶ÁµêÊûúÔºåÂÖ∂‰∏≠ÂåÖÂê´Âú®ÁúæÊâÄÂë®Áü•ÁöÑÂÖ¨ÂÖ±Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî®Â§öÂÄãÂü∫Á∑ö„ÄÇÊ†πÊìöÁµêÊûúÔºåÊàëÂÄëÁôºÁèæÂéüÁîüÂ±ÄÈÉ®Ë¶èÂâáÂàÜÈ°ûÂô®ÈÄöÂ∏∏ËàáÂÖ∂‰ªñÂàÜÈ°ûÂô®ÂÖ∑ÊúâÁ´∂Áà≠Âäõ„ÄÇÂä†ÂÖ•ÈùûÂ±ÄÈÉ®ÁßªÂãï‰ª•ËºÉÂ∞ëÁöÑÂèçË¶ÜÈÅãÁÆóÊ¨°Êï∏ÈÅîÊàêÈ°û‰ººÁöÑÁµêÊûúÔºåÂõ†Ê≠§‰ΩøÁî®Â∞àÁî®ÊàñÈáèÂ≠êÁ°¨È´îÂèØËÉΩÊúÉÈÄèÈÅéÂø´ÈÄüÊèêÂá∫ÈùûÂ±ÄÈÉ®ÁßªÂãï‰æÜÂä†ÈÄü„ÄÇ

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜËß£Ê±∫ÂøÉÁêÜÂÅ•Â∫∑ÂïèÈ°åÁöÑÂÖ®ÁêÉÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÈÇèËºØÁ•ûÁ∂ìÁ∂≤Ë∑Ø (LNN) ÁöÑÁ•ûÁ∂ìÁ¨¶Ëôü AI ÊñπÊ≥ï‰æÜË®∫Êñ∑ÂøÉÁêÜÁñæÁóÖ„ÄÇÁî±ÊñºÁº∫‰πèÊúâÊïàÁöÑÂøÉÁêÜÁñæÁóÖÊ≤ªÁôÇÊ∂µËìãÁØÑÂúçÔºåÂõ†Ê≠§ÈúÄË¶Å‰∏ÄÁ®Æ AI Ëß£Ê±∫ÊñπÊ°à‰æÜÂçîÂä©Ê≤ªÁôÇÂ∏´ÈÄ≤Ë°åË®∫Êñ∑„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÔºåÊ≤ªÁôÇÂ∏´ÂèØËÉΩÁÑ°Ê≥ï‰ø°‰ªªÂÆÉÂÄë„ÄÇLNN ÊòØ‰∏ÄÁ®ÆÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫ÜÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂ≠∏ÁøíËÉΩÂäõÂíåÂü∫ÊñºÁ∂ìÂÖ∏ÈÇèËºØÁöÑ AI ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±‰ΩøÁî®‰æÜËá™Ëá®Â∫äË®™Ë´áÁöÑËº∏ÂÖ•Ë¨ÇË©û‰æÜËº∏Âá∫ÂøÉÁêÜÁñæÁóÖÈ°ûÂà•Ôºå‰∏¶‰ΩøÁî®‰∏çÂêåÁöÑË¨ÇË©ûÂâ™ÊûùÊäÄË°ì‰æÜÂØ¶ÁèæÂèØÊì¥ÂÖÖÊÄßÂíåÊõ¥È´òÁöÑÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãË¶ãËß£ÊèêÂèñÊñπÊ≥ï‰æÜÂçîÂä©Ê≤ªÁôÇÂ∏´ÈÄ≤Ë°åË®∫Êñ∑„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±Ëß£Ê±∫‰∫ÜÁï∂ÂâçÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÂïèÈ°åÔºå‰∏¶ÁÇ∫ÂøÉÁêÜÁñæÁóÖË®∫Êñ∑Êèê‰æõ‰∫ÜÊõ¥ÂÄºÂæó‰ø°Ë≥¥ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

ÊëòË¶ÅÔºöÈö®ËëóÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´ÁôÇË®∫Êñ∑‰∏≠Ë∂ä‰æÜË∂äÊôÆÈÅçÔºåÂèØËß£ÈáãÊÄßÂíåÈÄèÊòéÂ∫¶ÁöÑÈúÄÊ±ÇËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇXAI Âæ©ËààÊ®ôË™åËëóË©≤È†òÂüüÁöÑÈáçÂ§ßËΩâËÆäÔºåÊó®Âú®ÈáçÊñ∞ÂÆöÁæ©ÈÜ´ÁôÇË®∫Êñ∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂèØËß£Èáã AI (XAI) È†òÂüüÂÖßÁöÑÂâµÊñ∞ÊñπÊ≥ïÂíåÊñπÊ≥ïË´ñÔºåÈÄô‰∫õÊñπÊ≥ïÂíåÊñπÊ≥ïË´ñÊ≠£Âú®Èù©Êñ∞ÈÜ´ÁôÇË®∫Êñ∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈÄöÈÅéÈó°ÊòéÂü∫Á§éÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãÔºåXAI ÊäÄË°ì‰ΩøÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ËÉΩÂ§†ÁêÜËß£„ÄÅ‰ø°‰ªª‰∏¶ÊúâÊïàÂú∞Âà©Áî®ÈÄô‰∫õÊ®°ÂûãÈÄ≤Ë°åÊ∫ñÁ¢∫‰∏îÂèØÈù†ÁöÑÈÜ´ÁôÇË®∫Êñ∑„ÄÇÊú¨Á∂úËø∞ÈáçÈªû‰ªãÁ¥π‰∫Ü XAI Âú®ÈÜ´ÁôÇË®∫Êñ∑ÊñπÈù¢ÁöÑÈóúÈçµÈÄ≤Â±ïÂèäÂÖ∂ËΩâËÆäÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊïàÊûú‰∏¶ÂüπÈ§äÂ∞ç AI È©ÖÂãïÁöÑË®∫Êñ∑Á≥ªÁµ±ÁöÑ‰ø°‰ªª„ÄÇ

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang, Aritejh Kr Goil, Henryk Chan, Jieyi Jeric Lew, Xin Chun Lee, Raihan Bin Ahmad Mustaffa, Timotius Jason, Ze Ting Woon, Bingquan Shen

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

ÊëòË¶ÅÔºö<paragraph>Âú®‰ª•È´òÂ∫¶ÈÄ£Êé•ÊÄßÂíåÊµÅÂãïÊÄßÁÇ∫ÁâπÂæµÁöÑÁí∞Â¢É‰∏≠ÔºåÂä†‰∏äÂøÉË°ÄÁÆ°ÁñæÁóÖÁöÑÊøÄÂ¢ûÔºåÈÄöÈÅéÈÅ†Á®ãÁõ£ÊéßÂøÉË°ÄÁÆ°ÂÅ•Â∫∑‰æÜÂâäÊ∏õÈÜ´ÁôÇ‰øùÂÅ•ÊîØÂá∫ÁöÑÂøÖË¶ÅÊÄßËÆäÂæóÊõ¥Âä†ÊòéÈ°Ø„ÄÇÊ∫ñÁ¢∫Ê™¢Ê∏¨ÂíåÂàÜÈ°ûÂøÉÂæã‰∏çÊï¥Â∞çÊñºË®∫Êñ∑ÊÇ£ÊúâÂøÉËáü‰∏çË¶èÂâáÁöÑ‰∫∫Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÂú®ÂÆ∂‰∏≠‰ΩøÁî®ÂøÉÈõªÂúñ (ECG) Ê∏¨ÈáèÈÄ≤Ë°åÂØ¶ÊôÇÂøÉÂæã‰∏çÊï¥Ê™¢Ê∏¨ÁöÑÂèØË°åÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂøÉÂæã‰∏çÊï¥Ê™¢Ê∏¨ÊáâÁî®ÔºåÂà©Áî®Â∞ñÁ´ØÁöÑ You-Only-Look-Once (YOLO)v8 ÊºîÁÆóÊ≥ïÂ∞çÂñÆÂ∞éËÅØ ECG Ë®äËôüÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊêçÂ§±‰øÆÊîπ YOLOv8 Ê®°ÂûãÔºå‰∏¶ÈáùÂ∞ç MIT-BIH ÂøÉÂæã‰∏çÊï¥Ë≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂæÆË™øÔºåÂæûËÄåÂØ¶Áèæ‰∫ÜÂØ¶ÊôÇÁöÑÊåÅÁ∫åÁõ£Êéß„ÄÇÁç≤ÂæóÁöÑÁµêÊûúË≠âÂØ¶‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåË©≤Ê®°ÂûãÂú® NVIDIA Tesla V100 ‰∏äÈÅîÂà∞‰∫Ü 99.5% ÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶Âíå 0.992 mAP@50Ôºå‰ª•Âèä 0.002 ÁßíÁöÑÂø´ÈÄüÊ™¢Ê∏¨ÊôÇÈñì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë™™Êòé‰∫ÜÂØ¶ÊôÇÂøÉÂæã‰∏çÊï¥Ê™¢Ê∏¨ÁöÑÊΩõÂäõÔºå‰ΩøÁî®Êà∂ËÉΩÂ§†Âú®ÂÆ∂‰∏≠ËàíÈÅ©Âú∞Ë¶ñË¶∫ÂåñËß£ËÆÄÊ®°ÂûãËº∏Âá∫„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂ÁÇ∫Êì¥Â±ïÂà∞ÂØ¶ÊôÇÂèØËß£Èáã AI (XAI) Ê®°ÂûãÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåË©≤Ê®°ÂûãËÉΩÂ§†ÈÉ®ÁΩ≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÂæûËÄåÈ°ØËëóÊé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°àÁöÑÈ†òÂüü„ÄÇ</paragraph>

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan, Taraka Satya Krishna Teja Malisetti

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

ÊëòË¶ÅÔºö‰π≥ÁôåÔºàBCÔºâ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÂÅ•Â∫∑Â®ÅËÑÖÔºåÁõÆÂâçÂ∞öÁÑ°Èï∑ÊúüÊ≤ªÁôíÁöÑÊñπÊ≥ï„ÄÇÊó©ÊúüÁôºÁèæËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰π≥ÊàøÊîùÂΩ±ÁöÑÂà§ËÆÄÂçªÂèóÂà∞È´òÂÅáÈôΩÊÄßÂíåÂÅáÈô∞ÊÄßÁöÑÈòªÁ§ô„ÄÇÁî±Êñº‰π≥ÁôåÁöÑÁôºÁîüÁéáÈ†êË®àÂ∞áË∂ÖÈÅéËÇ∫ÁôåÔºåÂõ†Ê≠§ÊîπÂñÑÊó©ÊúüÊ™¢Ê∏¨ÊñπÊ≥ïËá≥ÈóúÈáçË¶Å„ÄÇÁÜ±ÂÉèÊîùÂΩ±‰ΩøÁî®È´òËß£ÊûêÂ∫¶Á¥ÖÂ§ñÁ∑öÁõ∏Ê©üÔºåÁâπÂà•ÊòØÂú®Ëàá‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁµêÂêà‰ΩøÁî®ÊôÇÔºåÊèê‰æõ‰∫ÜÂ∏åÊúõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÁî®ÊñºÂàÜÂâ≤ÔºåÂú®‰π≥ÁôåÊ™¢Ê∏¨ÂíåÂàÜÈ°û‰∏≠Êèê‰æõ‰∫ÜÊõ¥È´òÁöÑÈÄüÂ∫¶ÂíåÁ≤æÂ∫¶„ÄÇË©≤Á≥ªÁµ±Â¢ûÂº∑ÂΩ±ÂÉè‰∏¶Âü∑Ë°åÂèØËß£ÈáãÁöÑ AI ÁôåÁóáÂàÜÂâ≤„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºTransformerÊ≥®ÊÑèÂäõÁöÑÂç∑Á©çÊû∂ÊßãÔºàUNetÔºâÁî®ÊñºÊïÖÈöúË≠òÂà•Ôºå‰∏¶‰ΩøÁî®Ê¢ØÂ∫¶Âä†Ê¨äÈ°ûÊøÄÊ¥ªÊò†Â∞ÑÔºàGrad-CAMÔºâ‰æÜÂàÜÊûê UNet Êû∂Êßã‰∏≠ÂÅèË¶ãÂíåÂº±ÈªûÁöÑÂçÄÂüüÔºå‰ΩøÁî® IRT ÂΩ±ÂÉè„ÄÇËàáÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ°ÜÊû∂Áõ∏ÊØîÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂ÁöÑÂÑ™Ë∂äÊÄßÂæóÂà∞Ë≠âÂØ¶„ÄÇ

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang, Jiaheng Xie, Zhijun Yan

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

ÊëòË¶ÅÔºöÊÜÇÈ¨±ÁóáÊòØÊúÄÊôÆÈÅç‰∏îÂö¥ÈáçÁöÑÁ≤æÁ•ûÁñæÁóÖÔºåÊúÉÈÄ†ÊàêÂö¥ÈáçÁöÑË≤°ÂãôÂíåÁ§æÊúÉÂæåÊûú„ÄÇÊÜÇÈ¨±ÁóáÁöÑÂÅµÊ∏¨Â∞çÊñºÊó©Êúü‰ªãÂÖ•‰ª•Ê∏õËºïÈÄô‰∫õÂæåÊûúËá≥ÈóúÈáçË¶Å„ÄÇÂ¶ÇÊ≠§ÈáçÂ§ßÁöÑÊ±∫ÂÆöÊú¨Ë≥™‰∏äÈúÄË¶ÅÂèØËß£ÈáãÊÄß„ÄÇÂÑòÁÆ°‰∏Ä‰∫õÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Á†îÁ©∂ÂòóË©¶Ê†πÊìöÈáçË¶ÅÊÄßÂàÜÊï∏ÊàñÊ≥®ÊÑèÂäõÊ¨äÈáç‰æÜËß£ÈáãÈÄôÂÄãÊ±∫ÂÆöÔºå‰ΩÜÈÄô‰∫õËß£ÈáãËàáÂü∫ÊñºÊÜÇÈ¨±ÁóáÁãÄÁöÑËá®Â∫äÊÜÇÈ¨±ÁóáË®∫Êñ∑Ê®ôÊ∫ñ‰∏ç‰∏ÄËá¥„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁº∫Âè£ÔºåÊàëÂÄëÈÅµÂæ™Ë®àÁÆóË®≠Ë®àÁßëÂ≠∏ÁØÑ‰æã‰æÜÈñãÁôº‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÂ∞∫Â∫¶ÊôÇÈñìÂéüÂûãÁ∂≤Ë∑Ø (MSTPNet)„ÄÇMSTPNet ÂâµÊñ∞Âú∞ÂÅµÊ∏¨‰∏¶Ëß£ÈáãÊÜÇÈ¨±ÁóáÁãÄ‰ª•ÂèäÂÆÉÂÄëÊåÅÁ∫åÂ§ö‰πÖ„ÄÇ‰ΩøÁî®Â§ßË¶èÊ®°Ë≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶Ë≠âÂàÜÊûêÈ°ØÁ§∫ÔºåMSTPNet ‰ª• 0.851 ÁöÑ F1 ÂàÜÊï∏ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÊñπÊ≥ï„ÄÇÊ≠§ÁµêÊûúÈÇÑÊè≠Á§∫‰∫ÜË™øÊü•ÊñπÊ≥ï‰∏≠Êú™Ê≥®ÊÑèÂà∞ÁöÑÊñ∞ÁóáÁãÄÔºå‰æãÂ¶ÇÂàÜ‰∫´Â∞ç‰∏çÂêåÁîüÊ¥ªÁöÑÊ¨Ω‰Ω©„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄ≤Ë°å‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•Ë≠âÊòéÂÖ∂Âú®ÂèØËß£ÈáãÊÄßÊñπÈù¢ÂÑ™ÊñºÂü∫Ê∫ñ„ÄÇÊú¨Á†îÁ©∂‰ª•‰∏ÄÂÄãÊñ∞Á©éÁöÑÂèØËß£ÈáãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁÇ∫ÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Âú®Á§æÁæ§Â™íÈ´î‰∏≠ÁöÑ IS ÊñáÁçªÂÅöÂá∫Ë≤¢Áçª„ÄÇÂú®ÂØ¶Âãô‰∏äÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂèØ‰ª•ÂØ¶‰ΩúÂú®Á§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏≠Ôºå‰ª•Êèê‰æõÂÄã‰∫∫ÂåñÁöÑÁ∑ö‰∏äË≥áÊ∫êÁµ¶Ë¢´ÂÅµÊ∏¨Âá∫ÊÜÇÈ¨±ÁóáÁöÑÊÇ£ËÄÖ„ÄÇ

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰ΩúÁÇ∫È†êÊÉ≥‰∏≠Áî±‰∫∫Â∑•Êô∫ÊÖß (AI) Êé®ÂãïÁöÑÈÜ´ÁôÇ‰øùÂÅ•ËΩâÂûãÁöÑÈáçË¶ÅË≥áÊñô‰æÜÊ∫ê„ÄÇÁÑ∂ËÄåÔºåÂèçÊò†Âú® EHR ÂÇôË®ª‰∏≠ÁöÑËá®Â∫äÂÅèË¶ãÂèØËÉΩÂ∞éËá¥ AI Ê®°ÂûãÁπºÊâø‰∏¶Êì¥Â§ßÈÄô‰∫õÂÅèË¶ãÔºåÈÄ≤ËÄåÈÄ†ÊàêÂÅ•Â∫∑Â∑ÆÁï∞„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é EHR ÂÇôË®ª‰∏≠Ê±ôÂêçÂåñË™ûË®Ä (SL) Â∞ç‰ΩøÁî®Âü∫Êñº Transformer ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂíåÂèØËß£Èáã AI (XAI) ÊäÄË°ìÈ†êÊ∏¨Ê≠ª‰∫°ÁéáÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÁî±Ëá®Â∫äÈÜ´ÁîüÊí∞ÂØ´ÁöÑ SL ÊúÉÂ∞ç AI ÊïàËÉΩÁî¢Áîü‰∏çÂà©ÂΩ±ÈüøÔºåÁâπÂà•ÊòØÂ∞çÈªë‰∫∫ÊÇ£ËÄÖËÄåË®ÄÔºåÁ™ÅÈ°Ø SL ÊòØ AI Ê®°ÂûãÈñãÁôº‰∏≠Á®ÆÊóèÂ∑ÆÁï∞ÁöÑ‰æÜÊ∫ê„ÄÇÁÇ∫‰∫ÜÊé¢Á¥¢‰∏ÄÁ®ÆÈÅã‰Ωú‰∏äÊúâÊïàÁéáÁöÑÊñπÊ≥ï‰æÜÊ∏õËºï SL ÁöÑÂΩ±ÈüøÔºåÊàëÂÄëÈÄèÈÅéËá®Â∫äÈÜ´ÁîüÁöÑÂçî‰ΩúÁ∂≤Ë∑ØÊé¢Ë®é SL Áî¢ÁîüÁöÑÊ®°ÂºèÔºå‰∏¶ÊâæÂá∫Ê†∏ÂøÉËá®Â∫äÈÜ´ÁîüÂ∞ç AI Ê®°Âûã‰∏≠ÁöÑÁ®ÆÊóèÂ∑ÆÁï∞ÊúâËºÉÂ§ßÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁôºÁèæÔºåÁßªÈô§Áî±Ê†∏ÂøÉËá®Â∫äÈÜ´ÁîüÊí∞ÂØ´ÁöÑ SL ÊòØÊØîÊ∂àÈô§Ë≥áÊñôÈõÜ‰∏≠ÊâÄÊúâ SL Êõ¥ÊúâÊïàÁéáÁöÑÂÅèË¶ãÊ∏õÂ∞ëÁ≠ñÁï•„ÄÇÊú¨Á†îÁ©∂Êèê‰æõÂèØË°åÁöÑË¶ãËß£ÔºåÁî®ÊñºË≤†Ë≤¨‰ªªÁöÑ AI ÈñãÁôºÔºå‰∏¶ÊúâÂä©Êñº‰∫ÜËß£Ëá®Â∫äÈÜ´ÁîüË°åÁÇ∫ÂíåÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ EHR ÂÇôË®ªÊí∞ÂØ´„ÄÇ

##### **Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**
2305.03376v1 by Goda Klumbyte, Hannah Piehl, Claude Draude

Contemporary automation through AI entails a substantial amount of
behind-the-scenes human labour, which is often both invisibilised and
underpaid. Since invisible labour, including labelling and maintenance work, is
an integral part of contemporary AI systems, it remains important to sensitise
users to its role. We suggest that this could be done through explainable AI
(XAI) design, particularly feminist intersectional XAI. We propose the method
of cartography, which stems from feminist intersectional research, to draw out
a systemic perspective of AI and include dimensions of AI that pertain to
invisible labour.

ÊëòË¶ÅÔºöÁï∂‰ª£ÈÄöÈÅé AI ÁöÑËá™ÂãïÂåñÈúÄË¶ÅÂ§ßÈáèÁöÑÂπïÂæå‰∫∫ÂäõÔºåÈÄôÈÄöÂ∏∏Êó¢‰∏çÂèØË¶ã‰∏îËñ™Ë≥áÈÅé‰Ωé„ÄÇÁî±Êñº‰∏çÂèØË¶ãÁöÑÂãûÂãïÔºåÂåÖÊã¨Ê®ôÁ±§ÂíåÁ∂≠Ë≠∑Â∑•‰ΩúÔºåÊòØÁï∂‰ª£ AI Á≥ªÁµ±ÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÂõ†Ê≠§ËÆì‰ΩøÁî®ËÄÖ‰∫ÜËß£ÂÖ∂ËßíËâ≤‰ªçÁÑ∂ÂæàÈáçË¶Å„ÄÇÊàëÂÄëÂª∫Ë≠∞ÈÄôÂèØ‰ª•ÈÄèÈÅéÂèØËß£ÈáãÁöÑ AIÔºàXAIÔºâË®≠Ë®à‰æÜÂÆåÊàêÔºåÁâπÂà•ÊòØÂ•≥ÊÄß‰∏ªÁæ©‰∫§ÂèâÁöÑ XAI„ÄÇÊàëÂÄëÊèêÂá∫Ê∫êËá™Â•≥ÊÄß‰∏ªÁæ©‰∫§ÂèâÁ†îÁ©∂ÁöÑË£ΩÂúñÊñπÊ≥ïÔºå‰ª•ÊèêÂá∫ AI ÁöÑÁ≥ªÁµ±ËßÄÈªûÔºå‰∏¶Á¥çÂÖ•Ëàá‰∏çÂèØË¶ãÂãûÂãïÁõ∏ÈóúÁöÑ AI Á∂≠Â∫¶„ÄÇ

##### **Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**
2304.13191v1 by Surjodeep Sarkar, Manas Gaur, L. Chen, Muskan Garg, Biplav Srivastava, Bhaktee Dongaonkar

Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.

ÊëòË¶ÅÔºöËôõÊì¨ÂøÉÁêÜÂÅ•Â∫∑Âä©ÁêÜ (VMHA) ÊåÅÁ∫åÈÄ≤Ê≠•Ôºå‰ª•ÊîØÊè¥ÊØèÂπ¥Êúâ 6000 Ëê¨‰∫∫Ê¨°ÂàùÁ¥ö‰øùÂÅ•Â∞±Ë®∫Âíå 600 Ëê¨‰∫∫Ê¨°ÊÄ•Ë®∫ÂÆ§ (ER) Â∞±Ë®∫ÁöÑË∂ÖË≤†Ëç∑ÂÖ®ÁêÉÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÊòØÁî±Ëá®Â∫äÂøÉÁêÜÂ≠∏ÂÆ∂„ÄÅÁ≤æÁ•ûÁßëÈÜ´Â∏´Âíå‰∫∫Â∑•Êô∫ÊÖß (AI) Á†îÁ©∂‰∫∫Âì°ÁÇ∫Ë™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÊâÄÂª∫Êßã„ÄÇÁõÆÂâçÔºåVMHA ÁöÑËßíËâ≤ÊòØÈÄèÈÅéË≥áË®äÊèê‰æõÊÉÖÁ∑íÊîØÊåÅÔºåËºÉÂ∞ëËëóÈáçÊñºËàáÊÇ£ËÄÖÁôºÂ±ïÂèçÊÄùÊÄßÁöÑÂ∞çË©±„ÄÇÈúÄË¶ÅÊõ¥ÂÖ®Èù¢„ÄÅÂÆâÂÖ®‰∏îÂèØËß£ÈáãÁöÑÊñπÊ≥ï‰æÜÂª∫ÊßãË≤†Ë≤¨‰ªªÁöÑ VMHAÔºå‰ª•ÊèêÂá∫ÂæåÁ∫åÂïèÈ°åÊàñÊèê‰æõÂÖÖÂàÜÁöÑÂõûÊáâ„ÄÇÈÄôÈ†ÖË™øÊü•Êèê‰æõ‰∫ÜÂ∞çÂøÉÁêÜÂÅ•Â∫∑‰∏≠ÁèæÊúâÂ∞çË©±‰ª£ÁêÜÁöÑÁ≥ªÁµ±ÊÄßÊâπÂà§ÊÄßÂõûÈ°ßÔºåÊé•ËëóÊ∑±ÂÖ•Êé¢Ë®é‰∫Ü VMHA Âú®ËÑàÁµ°Áü•Ë≠ò„ÄÅË≥áÊñôÈõÜÂíåÂÖ∂Âú®Ëá®Â∫äÊ±∫Á≠ñÊîØÊè¥‰∏≠Êñ∞ËààËßíËâ≤ÁöÑÊîπÈÄ≤„ÄÇÊàëÂÄë‰πüÊèê‰æõ‰∫ÜÊñ∞ÁöÑÊñπÂêëÔºå‰ª•ÈÄèÈÅéÂèØËß£ÈáãÊÄß„ÄÅÂÆâÂÖ®ÊÄßËàáÊï¥È´îÂèØ‰ø°Â∫¶‰æÜË±êÂØå VMHA ÁöÑ‰ΩøÁî®ËÄÖÈ´îÈ©ó„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∫ÜË©ïÈáèÊåáÊ®ôÂíå VMHA ÁöÑÂØ¶ÂãôËÄÉÈáèÔºåË∂ÖË∂äÁõÆÂâçÁöÑÊñáÁçªÔºåÂú® VMHA ËàáÊÇ£ËÄÖÁöÑÁ©çÊ•µÊ∫ùÈÄö‰∏≠Âª∫Á´ã‰ø°‰ªª„ÄÇ

##### **A Brief Review of Explainable Artificial Intelligence in Healthcare**
2304.01543v1 by Zahra Sadeghi, Roohallah Alizadehsani, Mehmet Akif Cifci, Samina Kausar, Rizwan Rehman, Priyakshi Mahanta, Pranjal Kumar Bora, Ammar Almasri, Rami S. Alkhawaldeh, Sadiq Hussain, Bilal Alatas, Afshin Shoeibi, Hossein Moosaei, Milan Hladik, Saeid Nahavandi, Panos M. Pardalos

XAI refers to the techniques and methods for building AI applications which
assist end users to interpret output and predictions of AI models. Black box AI
applications in high-stakes decision-making situations, such as medical domain
have increased the demand for transparency and explainability since wrong
predictions may have severe consequences. Model explainability and
interpretability are vital successful deployment of AI models in healthcare
practices. AI applications' underlying reasoning needs to be transparent to
clinicians in order to gain their trust. This paper presents a systematic
review of XAI aspects and challenges in the healthcare domain. The primary
goals of this study are to review various XAI methods, their challenges, and
related machine learning models in healthcare. The methods are discussed under
six categories: Features-oriented methods, global methods, concept models,
surrogate models, local pixel-based methods, and human-centric methods. Most
importantly, the paper explores XAI role in healthcare problems to clarify its
necessity in safety-critical applications. The paper intends to establish a
comprehensive understanding of XAI-related applications in the healthcare field
by reviewing the related experimental results. To facilitate future research
for filling research gaps, the importance of XAI models from different
viewpoints and their limitations are investigated.

ÊëòË¶ÅÔºöXAI ÊåáÁöÑÊòØÁî®ÊñºÂª∫Êßã AI ÊáâÁî®Á®ãÂºèÁöÑÊäÄË°ìÂíåÊñπÊ≥ïÔºåÈÄô‰∫õÊáâÁî®Á®ãÂºèÂèØÂçîÂä©ÊúÄÁµÇ‰ΩøÁî®ËÄÖË©ÆÈáã AI Ê®°ÂûãÁöÑËº∏Âá∫ÂíåÈ†êÊ∏¨„ÄÇÂú®È´òÈ¢®Èö™Ê±∫Á≠ñÊÉÖÂ¢É‰∏≠Ôºå‰æãÂ¶ÇÈÜ´ÁôÇÈ†òÂüüÔºåÈªëÁÆ± AI ÊáâÁî®Á®ãÂºèÂ¢ûÂä†‰∫ÜÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÔºåÂõ†ÁÇ∫ÈåØË™§ÁöÑÈ†êÊ∏¨ÂèØËÉΩÊúÉÈÄ†ÊàêÂö¥ÈáçÁöÑÂæåÊûú„ÄÇÊ®°ÂûãÂèØËß£ÈáãÊÄßÂíåÂèØË©ÆÈáãÊÄßÂ∞çÊñºÂú®ÈÜ´ÁôÇÂØ¶Âãô‰∏≠ÊàêÂäüÈÉ®ÁΩ≤ AI Ê®°ÂûãËá≥ÈóúÈáçË¶Å„ÄÇAI ÊáâÁî®Á®ãÂºèÁöÑÂü∫Êú¨Êé®ÁêÜÈúÄË¶ÅÂ∞çËá®Â∫äÈÜ´ÁîüÈÄèÊòéÔºåÊâçËÉΩÁç≤Âæó‰ªñÂÄëÁöÑ‰ø°‰ªª„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÈÜ´ÁôÇÈ†òÂüü‰∏≠ XAI Èù¢ÂêëÂíåÊåëÊà∞ÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ß„ÄÇÊú¨Á†îÁ©∂ÁöÑ‰∏ªË¶ÅÁõÆÊ®ôÊòØÂõûÈ°ßÂêÑÁ®Æ XAI ÊñπÊ≥ï„ÄÅÂÖ∂ÊåëÊà∞Ôºå‰ª•ÂèäÁõ∏ÈóúÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ê©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄô‰∫õÊñπÊ≥ïÂàÜÁÇ∫ÂÖ≠È°ûË®éË´ñÔºöÈù¢ÂêëÁâπÂæµÁöÑÊñπÊ≥ï„ÄÅÊï¥È´îÊñπÊ≥ï„ÄÅÊ¶ÇÂøµÊ®°Âûã„ÄÅ‰ª£ÁêÜÊ®°Âûã„ÄÅÂ±ÄÈÉ®Âü∫ÊñºÂÉèÁ¥†ÁöÑÊñπÊ≥ïÔºå‰ª•Âèä‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑÊñπÊ≥ï„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåÊú¨ÊñáÊé¢Ë®é‰∫Ü XAI Âú®ÈÜ´ÁôÇ‰øùÂÅ•ÂïèÈ°å‰∏≠ÁöÑËßíËâ≤Ôºå‰ª•ÈáêÊ∏ÖÂÖ∂Âú®ÂÆâÂÖ®ÈóúÈçµÊáâÁî®‰∏≠ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊú¨ÊñáÊó®Âú®ÈÄèÈÅéÂõûÈ°ßÁõ∏ÈóúÁöÑÂØ¶È©óÁµêÊûúÔºåÂª∫Á´ãÂ∞çÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ XAI Áõ∏ÈóúÊáâÁî®Á®ãÂºèÁöÑÂÖ®Èù¢‰∫ÜËß£„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Êú™‰æÜÁ†îÁ©∂Â°´Ë£úÁ†îÁ©∂Â∑ÆË∑ùÔºåÊú¨ÊñáÊé¢Ë®é‰∫Ü XAI Ê®°ÂûãÂæû‰∏çÂêåËßÄÈªû‰æÜÁúãÁöÑÈáçË¶ÅÊÄßÂèäÂÖ∂ÈôêÂà∂„ÄÇ

##### **Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**
2303.12641v2 by Frederik Pahde, Maximilian Dreyer, Wojciech Samek, Sebastian Lapuschkin

State-of-the-art machine learning models often learn spurious correlations
embedded in the training data. This poses risks when deploying these models for
high-stake decision-making, such as in medical applications like skin cancer
detection. To tackle this problem, we propose Reveal to Revise (R2R), a
framework entailing the entire eXplainable Artificial Intelligence (XAI) life
cycle, enabling practitioners to iteratively identify, mitigate, and
(re-)evaluate spurious model behavior with a minimal amount of human
interaction. In the first step (1), R2R reveals model weaknesses by finding
outliers in attributions or through inspection of latent concepts learned by
the model. Secondly (2), the responsible artifacts are detected and spatially
localized in the input data, which is then leveraged to (3) revise the model
behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model
correction, and (4) (re-)evaluate the model's performance and remaining
sensitivity towards the artifact. Using two medical benchmark datasets for
Melanoma detection and bone age estimation, we apply our R2R framework to VGG,
ResNet and EfficientNet architectures and thereby reveal and correct real
dataset-intrinsic artifacts, as well as synthetic variants in a controlled
setting. Completing the XAI life cycle, we demonstrate multiple R2R iterations
to mitigate different biases. Code is available on
https://github.com/maxdreyer/Reveal2Revise.

ÊëòË¶ÅÔºöÊúÄÂÖàËøõÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÈÄöÂ∏∏‰ºöÂ≠¶‰π†ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÂµåÂÖ•ÁöÑËôöÂÅáÂÖ≥ËÅî„ÄÇËøôÂú®Â∞ÜËøô‰∫õÊ®°ÂûãÈÉ®ÁΩ≤‰∫éÈ´òÈ£éÈô©ÂÜ≥Á≠ñÊó∂‰ºöÂ∏¶Êù•È£éÈô©Ôºå‰æãÂ¶ÇÂú®ÁöÆËÇ§ÁôåÊ£ÄÊµãÁ≠âÂåªÂ≠¶Â∫îÁî®‰∏≠„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü Reveal to Revise (R2R)Ôºå‰∏Ä‰∏™Ê∂µÁõñÊï¥‰∏™ÂèØËß£Èáä‰∫∫Â∑•Êô∫ËÉΩ (XAI) ÁîüÂëΩÂë®ÊúüÁöÑÊ°ÜÊû∂Ôºå‰Ωø‰ªé‰∏öËÄÖËÉΩÂ§ü‰ª•ÊúÄÂ∞ëÁöÑ‰∫∫Â∑•‰∫§‰∫íËø≠‰ª£ËØÜÂà´„ÄÅÁºìËß£ÂíåÔºàÈáçÊñ∞ÔºâËØÑ‰º∞ËôöÂÅáÊ®°ÂûãË°å‰∏∫„ÄÇÂú®Á¨¨‰∏ÄÊ≠• (1) ‰∏≠ÔºåR2R ÈÄöËøáÊâæÂá∫ÂΩíÂõ†‰∏≠ÁöÑÂºÇÂ∏∏ÂÄºÊàñÈÄöËøáÊ£ÄÊü•Ê®°ÂûãÂ≠¶‰π†ÁöÑÊΩúÂú®Ê¶ÇÂøµÊù•Êè≠Á§∫Ê®°ÂûãÁöÑÂº±ÁÇπ„ÄÇÂÖ∂Ê¨° (2)ÔºåÊ£ÄÊµãË¥üË¥£ÁöÑ‰º™ÂÉèÂπ∂Âú®ËæìÂÖ•Êï∞ÊçÆ‰∏≠ËøõË°åÁ©∫Èó¥ÂÆö‰ΩçÔºåÁÑ∂ÂêéÂà©Áî®ÂÆÉÊù• (3) ‰øÆÊîπÊ®°ÂûãË°å‰∏∫„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Â∫îÁî® RRR„ÄÅCDEP Âíå ClArC ÁöÑÊñπÊ≥ïÊù•ËøõË°åÊ®°ÂûãÊ†°Ê≠£ÔºåÂπ∂ (4)ÔºàÈáçÊñ∞ÔºâËØÑ‰º∞Ê®°ÂûãÁöÑÊÄßËÉΩÂíåÂØπ‰º™ÂÉèÁöÑÂâ©‰ΩôÊïèÊÑüÊÄß„ÄÇ‰ΩøÁî®‰∏§‰∏™Áî®‰∫éÈªëËâ≤Á¥†Áò§Ê£ÄÊµãÂíåÈ™®ÈæÑ‰º∞ËÆ°ÁöÑÂåªÂ≠¶Âü∫ÂáÜÊï∞ÊçÆÈõÜÔºåÊàë‰ª¨Â∞ÜÊàë‰ª¨ÁöÑ R2R Ê°ÜÊû∂Â∫îÁî®‰∫é VGG„ÄÅResNet Âíå EfficientNet Êû∂ÊûÑÔºå‰ªéËÄåÊè≠Á§∫ÂíåÁ∫†Ê≠£‰∫ÜÁúüÂÆûÊï∞ÊçÆÈõÜÂõ∫ÊúâÁöÑ‰º™ÂÉèÔºå‰ª•ÂèäÂèóÊéßËÆæÁΩÆ‰∏≠ÁöÑÂêàÊàêÂèò‰Ωì„ÄÇÂÆåÊàê XAI ÁîüÂëΩÂë®ÊúüÔºåÊàë‰ª¨ÊºîÁ§∫‰∫ÜÂ§ö‰∏™ R2R Ëø≠‰ª£‰ª•ÂáèËΩª‰∏çÂêåÁöÑÂÅèÂ∑Æ„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/maxdreyer/Reveal2Revise ‰∏äÊâæÂà∞„ÄÇ

##### **Explainable AI for Time Series via Virtual Inspection Layers**
2303.06365v1 by Johanna Vielhaben, Sebastian Lapuschkin, Gr√©goire Montavon, Wojciech Samek

The field of eXplainable Artificial Intelligence (XAI) has greatly advanced
in recent years, but progress has mainly been made in computer vision and
natural language processing. For time series, where the input is often not
interpretable, only limited research on XAI is available. In this work, we put
forward a virtual inspection layer, that transforms the time series to an
interpretable representation and allows to propagate relevance attributions to
this representation via local XAI methods like layer-wise relevance propagation
(LRP). In this way, we extend the applicability of a family of XAI methods to
domains (e.g. speech) where the input is only interpretable after a
transformation. Here, we focus on the Fourier transformation which is
prominently applied in the interpretation of time series and LRP and refer to
our method as DFT-LRP. We demonstrate the usefulness of DFT-LRP in various time
series classification settings like audio and electronic health records. We
showcase how DFT-LRP reveals differences in the classification strategies of
models trained in different domains (e.g., time vs. frequency domain) or helps
to discover how models act on spurious correlations in the data.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) È†òÂüüÂú®ËøëÂπ¥‰æÜÂèñÂæóÈï∑Ë∂≥ÈÄ≤Ê≠•Ôºå‰ΩÜÈÄ≤Â±ï‰∏ªË¶ÅÊòØÂú®ÈõªËÖ¶Ë¶ñË¶∫ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊñπÈù¢„ÄÇÂ∞çÊñºËº∏ÂÖ•ÈÄöÂ∏∏ÁÑ°Ê≥ïËß£ÈáãÁöÑÊôÇÈñìÂ∫èÂàóÔºåÂè™ÊúâÊúâÈôêÁöÑÁ†îÁ©∂ÂèØ‰æõ‰ΩøÁî® XAI„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËôõÊì¨Ê™¢Êü•Â±§ÔºåÂÆÉÂ∞áÊôÇÈñìÂ∫èÂàóËΩâÊèõÁÇ∫ÂèØËß£ÈáãÁöÑË°®Á§∫Ôºå‰∏¶ÂÖÅË®±ÈÄöÈÅéÂ±§Á¥öÁõ∏ÈóúÊÄßÂÇ≥Êí≠ (LRP) Á≠âÂ±ÄÈÉ® XAI ÊñπÊ≥ïÂ∞áÁõ∏ÈóúÊÄßÊ≠∏Âõ†ÂÇ≥Êí≠Âà∞Ê≠§Ë°®Á§∫„ÄÇËóâÊ≠§ÔºåÊàëÂÄëÂ∞á‰∏ÄÁ≥ªÂàó XAI ÊñπÊ≥ïÁöÑÈÅ©Áî®ÊÄßÊì¥Â±ïÂà∞Ëº∏ÂÖ•ÂÉÖÂú®ËΩâÊèõÂæåÊâçËÉΩËß£ÈáãÁöÑÈ†òÂüüÔºà‰æãÂ¶ÇË™ûÈü≥Ôºâ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂÇÖÁ´ãËëâËΩâÊèõÔºåÂÆÉ‰∏ªË¶ÅÊáâÁî®ÊñºÊôÇÈñìÂ∫èÂàóÂíå LRP ÁöÑËß£ÈáãÔºå‰∏¶Â∞áÊàëÂÄëÁöÑÁ®±‰πãÁÇ∫ DFT-LRP„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü DFT-LRP Âú®ÂêÑÁ®ÆÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûË®≠ÂÆöÔºà‰æãÂ¶ÇÈü≥Ë®äÂíåÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑÔºâ‰∏≠ÁöÑÊïàÁî®„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü DFT-LRP Â¶Ç‰ΩïÊè≠Á§∫Âú®‰∏çÂêåÈ†òÂüüÔºà‰æãÂ¶ÇÊôÇÈñìËàáÈ†ªÁéáÂüüÔºâË®ìÁ∑¥ÁöÑÊ®°ÂûãÁöÑÂàÜÈ°ûÁ≠ñÁï•Â∑ÆÁï∞ÔºåÊàñÊúâÂä©ÊñºÁôºÁèæÊ®°ÂûãÂ¶Ç‰ΩïËôïÁêÜË≥áÊñô‰∏≠ÁöÑËôõÂÅáÈóúËÅØ„ÄÇ

##### **Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**
2303.04731v1 by Truong Thanh Hung Nguyen, Van Binh Truong, Vo Thanh Khang Nguyen, Quoc Hung Cao, Quoc Khanh Nguyen

The ability to explain the prediction of deep learning models to end-users is
an important feature to leverage the power of artificial intelligence (AI) for
the medical decision-making process, which is usually considered
non-transparent and challenging to comprehend. In this paper, we apply
state-of-the-art eXplainable artificial intelligence (XAI) methods to explain
the prediction of the black-box AI models in the thyroid nodule diagnosis
application. We propose new statistic-based XAI methods, namely Kernel Density
Estimation and Density map, to explain the case of no nodule detected. XAI
methods' performances are considered under a qualitative and quantitative
comparison as feedback to improve the data quality and the model performance.
Finally, we survey to assess doctors' and patients' trust in XAI explanations
of the model's decisions on thyroid nodule images.

ÊëòË¶ÅÔºöËß£ÈáãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈ†êÊ∏¨ÁµêÊûúÁöÑËÉΩÂäõÂ∞çÊúÄÁµÇ‰ΩøÁî®ËÄÖËÄåË®ÄÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÂäüËÉΩÔºåÂèØÂà©Áî®‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂäõÈáèÈÄ≤Ë°åÈÜ´ÁôÇÊ±∫Á≠ñÊµÅÁ®ãÔºåÈÄôÈÄöÂ∏∏Ë¢´Ë™çÁÇ∫ÊòØ‰∏çÈÄèÊòé‰∏îÈõ£‰ª•ÁêÜËß£ÁöÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÅãÁî®ÊúÄÂÖàÈÄ≤ÁöÑÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊñπÊ≥ï‰æÜËß£ÈáãÈªëÁõí AI Ê®°ÂûãÂú®Áî≤ÁãÄËÖ∫ÁµêÁØÄË®∫Êñ∑ÊáâÁî®‰∏≠ÁöÑÈ†êÊ∏¨ÁµêÊûú„ÄÇÊàëÂÄëÊèêÂá∫Êñ∞ÁöÑÂü∫ÊñºÁµ±Ë®àÁöÑ XAI ÊñπÊ≥ïÔºåÂç≥Ê†∏ÂØÜÂ∫¶‰º∞Ë®àÂíåÂØÜÂ∫¶ÂúñÔºå‰æÜËß£ÈáãÊú™Ê™¢Ê∏¨Âà∞ÁµêÁØÄÁöÑÊÉÖÊ≥Å„ÄÇXAI ÊñπÊ≥ïÁöÑÊïàËÉΩÊúÉÂú®ÂÆöÊÄßÂíåÂÆöÈáèÊØîËºÉ‰∏ãË¢´Ë¶ñÁÇ∫ÊîπÂñÑË≥áÊñôÂìÅË≥™ÂíåÊ®°ÂûãÊïàËÉΩÁöÑÂõûÈ•ã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄ≤Ë°åË™øÊü•‰ª•Ë©ï‰º∞ÈÜ´Â∏´ÂíåÊÇ£ËÄÖÂ∞ç XAI Â∞çÊ®°ÂûãÂú®Áî≤ÁãÄËÖ∫ÁµêÁØÄÂΩ±ÂÉè‰∏≠Ê±∫Á≠ñÁöÑËß£ÈáãÁöÑ‰ø°‰ªªÂ∫¶„ÄÇ

##### **Cybersecurity of AI medical devices: risks, legislation, and challenges**
2303.03140v1 by Elisabetta Biasin, Erik Kamenjasevic, Kaspar Rosager Ludvigsen

Medical devices and artificial intelligence systems rapidly transform
healthcare provisions. At the same time, due to their nature, AI in or as
medical devices might get exposed to cyberattacks, leading to patient safety
and security risks. This book chapter is divided into three parts. The first
part starts by setting the scene where we explain the role of cybersecurity in
healthcare. Then, we briefly define what we refer to when we talk about AI that
is considered a medical device by itself or supports one. To illustrate the
risks such medical devices pose, we provide three examples: the poisoning of
datasets, social engineering, and data or source code extraction. In the second
part, the paper provides an overview of the European Union's regulatory
framework relevant for ensuring the cybersecurity of AI as or in medical
devices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and
the NIS 2 Directive proposal). Finally, the third part of the paper examines
possible challenges stemming from the EU regulatory framework. In particular,
we look toward the challenges deriving from the two legislative proposals and
their interaction with the existing legislation concerning AI medical devices'
cybersecurity. They are structured as answers to the following questions: (1)
how will the AI Act interact with the MDR regarding the cybersecurity and
safety requirements?; (2) how should we interpret incident notification
requirements from the NIS 2 Directive proposal and MDR?; and (3) what are the
consequences of the evolving term of critical infrastructures?
  [This is a draft chapter. The final version will be available in Research
Handbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,
forthcoming 2023, Edward Elgar Publishing Ltd]

ÊëòË¶ÅÔºöÈÜ´ÁôÇË®≠ÂÇôÂíå‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±Âø´ÈÄüËΩâÂåñÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÊèê‰æõÊñπÂºè„ÄÇÂêåÊôÇÔºåÁî±ÊñºÂÖ∂Êú¨Ë≥™ÔºåÈÜ´ÁôÇË®≠ÂÇô‰∏≠Êàñ‰ΩúÁÇ∫ÈÜ´ÁôÇË®≠ÂÇôÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂèØËÉΩÊúÉÈÅ≠ÂèóÁ∂≤Ë∑ØÊîªÊìäÔºåÈÄ≤ËÄåÂ∞éËá¥ÊÇ£ËÄÖÂÆâÂÖ®ÂíåÂÆâÂÖ®È¢®Èö™„ÄÇÊú¨Á´†ÁØÄÂàÜÁÇ∫‰∏âÈÉ®ÂàÜ„ÄÇÁ¨¨‰∏ÄÈÉ®ÂàÜÂæûË®≠ÂÆöÂ†¥ÊôØÈñãÂßãÔºåË™™ÊòéÁ∂≤Ë∑ØÂÆâÂÖ®Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑËßíËâ≤„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÁ∞°Ë¶ÅÂÆöÁæ©ÊàëÂÄëÂú®Ë´áË´ñË¢´Ë¶ñÁÇ∫ÈÜ´ÁôÇË®≠ÂÇôÊú¨Ë∫´ÊàñÊîØÊè¥ÈÜ´ÁôÇË®≠ÂÇôÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊôÇÊâÄÊåáÊ∂âÁöÑÂÖßÂÆπ„ÄÇÁÇ∫‰∫ÜË™™ÊòéÊ≠§È°ûÈÜ´ÁôÇË®≠ÂÇôÂ∏∂‰æÜÁöÑÈ¢®Èö™ÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏âÂÄãÁØÑ‰æãÔºöË≥áÊñôÈõÜ‰∏≠ÊØí„ÄÅÁ§æÊúÉÂ∑•Á®ãÂíåË≥áÊñôÊàñÂéüÂßãÁ¢ºËêÉÂèñ„ÄÇÂú®Á¨¨‰∫åÈÉ®ÂàÜÔºåÊú¨ÊñáÊ¶ÇËø∞‰∫ÜÊ≠êÁõüÁöÑÁõ£ÁÆ°Êû∂ÊßãÔºåËàáÁ¢∫‰øùÈÜ´ÁôÇË®≠ÂÇô‰∏≠Êàñ‰ΩúÁÇ∫ÈÜ´ÁôÇË®≠ÂÇôÁöÑ‰∫∫Â∑•Êô∫ÊÖßÁöÑÁ∂≤Ë∑ØÂÆâÂÖ®Áõ∏ÈóúÔºàÈÜ´ÁôÇÂô®ÊùêÊ≥ïË¶è„ÄÅÁ∂≤Ë∑ØËàáË≥áË®äÂÆâÂÖ®Êåá‰ª§„ÄÅÁ∂≤Ë∑ØÂÆâÂÖ®Ê≥ï„ÄÅ‰∏ÄËà¨Ë≥áÊñô‰øùË≠∑Ë¶èÁØÑ„ÄÅ‰∫∫Â∑•Êô∫ÊÖßÊ≥ïÊèêÊ°àÂíåÁ∂≤Ë∑ØËàáË≥áË®äÂÆâÂÖ® 2 Êåá‰ª§ÊèêÊ°àÔºâ„ÄÇÊúÄÂæåÔºåÊú¨ÊñáÁöÑÁ¨¨‰∏âÈÉ®ÂàÜÊé¢Ë®éÊ∫êËá™Ê≠êÁõüÁõ£ÁÆ°Êû∂ÊßãÁöÑÊΩõÂú®ÊåëÊà∞„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂ±ïÊúõÊ∫êËá™ÈÄôÂÖ©È†ÖÁ´ãÊ≥ïÊèêÊ°àÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂÆÉÂÄëËàáÁèæÊúâÈóúÊñº‰∫∫Â∑•Êô∫ÊÖßÈÜ´ÁôÇË®≠ÂÇôÁ∂≤Ë∑ØÂÆâÂÖ®ÁöÑÁ´ãÊ≥ï‰πãÈñìÁöÑ‰∫íÂãï„ÄÇÂÆÉÂÄëË¢´Êû∂ÊßãÁÇ∫‰ª•‰∏ãÂïèÈ°åÁöÑËß£Á≠îÔºö(1) ‰∫∫Â∑•Êô∫ÊÖßÊ≥ïÂ∞áÂ¶Ç‰ΩïËàáÈÜ´ÁôÇÂô®ÊùêÊ≥ïË¶è‰∫íÂãïÔºåÂ∞±Á∂≤Ë∑ØÂÆâÂÖ®ÂíåÂÆâÂÖ®Ë¶ÅÊ±ÇËÄåË®ÄÔºü(2) ÊàëÂÄëÊáâÂ¶Ç‰ΩïËß£ËÆÄÁ∂≤Ë∑ØËàáË≥áË®äÂÆâÂÖ® 2 Êåá‰ª§ÊèêÊ°àÂíåÈÜ´ÁôÇÂô®ÊùêÊ≥ïË¶èÁöÑ‰∫ã‰ª∂ÈÄöÁü•Ë¶ÅÊ±ÇÔºü(3) ÈóúÈçµÂü∫Á§éË®≠ÊñΩÊºîÈÄ≤ÁöÑË°ìË™ûÊúÉÂ∏∂‰æÜ‰ªÄÈ∫ºÂæåÊûúÔºü
[ÈÄôÊòØËçâÁ®øÁ´†ÁØÄ„ÄÇÊúÄÁµÇÁâàÊú¨Â∞áÂàäËºâÊñº Barry Solaiman Âíå I. Glenn Cohen Á∑®ËºØÁöÑ„ÄäÂÅ•Â∫∑„ÄÅ‰∫∫Â∑•Êô∫ÊÖßËàáÊ≥ïÂæãÁ†îÁ©∂ÊâãÂÜä„Äã‰∏≠Ôºå2023 Âπ¥Âá∫ÁâàÔºåEdward Elgar Publishing Ltd]

##### **LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**
2302.03008v2 by Nooshin Yousefzadeh, Charlie Tran, Adolfo Ramirez-Zamora, Jinghua Chen, Ruogu Fang, My T. Thai

Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the
leading cause of dementia. Early diagnosis is critical for patients to benefit
from potential intervention and treatment. The retina has been hypothesized as
a diagnostic site for AD detection owing to its anatomical connection with the
brain. Developed AI models for this purpose have yet to provide a rational
explanation about the decision and neither infer the stage of disease's
progression. Along this direction, we propose a novel model-agnostic
explainable-AI framework, called Granular Neuron-level Explainer (LAVA), an
interpretation prototype that probes into intermediate layers of the
Convolutional Neural Network (CNN) models to assess the AD continuum directly
from the retinal imaging without longitudinal or clinical evaluation. This
method is applied to validate the retinal vasculature as a biomarker and
diagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank
cognitive tests and vascular morphological features suggest LAVA shows strong
promise and effectiveness in identifying AD stages across the progression
continuum.

ÊëòË¶ÅÔºöÈòøËå≤Êµ∑ÈªòÁóá (AD) ÊòØ‰∏ÄÁ®ÆÈÄ≤Ë°åÊÄßÁöÑÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖÔºå‰πüÊòØÂ∞éËá¥Â§±Êô∫ÁóáÁöÑ‰∏ªÂõ†„ÄÇÊó©ÊúüË®∫Êñ∑Â∞çÊñºÊÇ£ËÄÖÊé•ÂèóÊΩõÂú®Âπ≤È†êÂíåÊ≤ªÁôÇËá≥ÈóúÈáçË¶Å„ÄÇÁî±ÊñºË¶ñÁ∂≤ËÜúËàáÂ§ßËÖ¶ÊúâËß£ÂâñÂ≠∏‰∏äÁöÑÈÄ£ÁµêÔºåÂõ†Ê≠§ÂÅáË®≠Ë¶ñÁ∂≤ËÜúÂèØ‰ª•‰ΩúÁÇ∫ AD Ê™¢Ê∏¨ÁöÑË®∫Êñ∑ÈÉ®‰Ωç„ÄÇÁÇ∫Ê≠§ÁõÆÁöÑËÄåÈñãÁôºÁöÑ AI Ê®°ÂûãÔºåÂ∞öÊú™Â∞çÊ±∫Á≠ñÊèê‰æõÂêàÁêÜÁöÑËß£ÈáãÔºå‰πüÁÑ°Ê≥ïÊé®Ë´ñÁñæÁóÖÈÄ≤Â±ïÁöÑÈöéÊÆµ„ÄÇÊ≤øËëóÈÄôÂÄãÊñπÂêëÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ®°Âûã‰∏çÂèØÁü•Ë´ñÂèØËß£Èáã AI Êû∂ÊßãÔºåÁ®±ÁÇ∫È°ÜÁ≤íÁ•ûÁ∂ìÂÖÉÁ¥öÂà•Ëß£ÈáãÂô® (LAVA)ÔºåÈÄôÊòØ‰∏ÄÂÄãËß£ÈáãÂéüÂûãÔºåÂèØ‰ª•Êé¢Ê∏¨Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Ê®°ÂûãÁöÑ‰∏≠ÈñìÂ±§Ôºå‰ª•Áõ¥Êé•ÂæûË¶ñÁ∂≤ËÜúÂΩ±ÂÉèË©ï‰º∞ AD ÈÄ£Á∫åÈ´îÔºåËÄåÁÑ°ÈúÄÁ∏±ÂêëÊàñËá®Â∫äË©ï‰º∞„ÄÇÊ≠§ÊñπÊ≥ïÁî®ÊñºÈ©óË≠âË¶ñÁ∂≤ËÜúË°ÄÁÆ°‰ΩúÁÇ∫ÁîüÁâ©Ê®ôË®òÂíåÈòøËå≤Êµ∑ÈªòÁóá (AD) Ë©ï‰º∞ÁöÑË®∫Êñ∑ÊñπÂºè„ÄÇËã±ÂúãÁîüÁâ©Ë≥áÊñôÂ∫´ÁöÑË™çÁü•Ê∏¨Ë©¶ÂíåË°ÄÁÆ°ÂΩ¢ÊÖãÁâπÂæµË°®ÊòéÔºåLAVA Âú®Ë≠òÂà•ÈÄ≤Â±ïÈÄ£Á∫åÈ´î‰∏≠ÁöÑ AD ÈöéÊÆµÊñπÈù¢È°ØÁ§∫Âá∫Âº∑Â§ßÁöÑÂâçÊôØÂíåÊúâÊïàÊÄß„ÄÇ

##### **Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**
2302.01241v2 by Brian Y. Lim, Joseph P. Cahaly, Chester Y. F. Sng, Adam Chew

Many visualizations have been developed for explainable AI (XAI), but they
often require further reasoning by users to interpret. We argue that XAI should
support diagrammatic and abductive reasoning for the AI to perform hypothesis
generation and evaluation to reduce the interpretability gap. We propose
Diagrammatization to i) perform Peircean abductive-deductive reasoning, ii)
follow domain conventions, and iii) explain with diagrams visually or verbally.
We implemented DiagramNet for a clinical application to predict cardiac
diagnoses from heart auscultation, and explain with shape-based murmur
diagrams. In modeling studies, we found that DiagramNet not only provides
faithful murmur shape explanations, but also has better prediction performance
than baseline models. We further demonstrate the interpretability and
trustworthiness of diagrammatic explanations in a qualitative user study with
medical students, showing that clinically-relevant, diagrammatic explanations
are preferred over technical saliency map explanations. This work contributes
insights into providing domain-conventional abductive explanations for
user-centric XAI.

ÊëòË¶ÅÔºöË®±Â§öË¶ñË¶∫ÂåñÂ∑≤Ë¢´ÈñãÁôºÁî®ÊñºÂèØËß£ÈáãÁöÑ AI (XAI)Ôºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏ÈúÄË¶Å‰ΩøÁî®ËÄÖÈÄ≤‰∏ÄÊ≠•Êé®ÁêÜÊâçËÉΩËß£ËÆÄ„ÄÇÊàëÂÄë‰∏ªÂºµ XAI ÊáâÊîØÊè¥ÂúñËß£ÂíåÊºîÁππÊé®ÁêÜÔºåËÆì AI Âü∑Ë°åÂÅáË®≠Áî¢ÁîüÂíåË©ï‰º∞‰ª•Á∏ÆÂ∞èÂèØËß£ÈáãÊÄßÂ∑ÆË∑ù„ÄÇÊàëÂÄëÊèêÂá∫ÂúñËß£Âåñ‰ª• i) Âü∑Ë°åÁöÆÁàæÂ£´ÊºîÁππ-ÊºîÁππÊé®ÁêÜÔºåii) ÈÅµÂæ™È†òÂüüÊÖ£‰æãÔºå‰ª•Âèä iii) ‰ª•Ë¶ñË¶∫ÊàñÂè£Ë™ûÊñπÂºèË™™ÊòéÂúñË°®„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫Ü DiagramNet ÈÄ≤Ë°åËá®Â∫äÊáâÁî®Ôºå‰ª•ÂæûÂøÉËáüËÅΩË®∫È†êÊ∏¨ÂøÉËáüË®∫Êñ∑Ôºå‰∏¶‰ª•ÂΩ¢ÁãÄÁÇ∫Âü∫Á§éÁöÑÈõúÈü≥ÂúñË™™Êòé„ÄÇÂú®Âª∫Ê®°Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁôºÁèæ DiagramNet ‰∏çÂÉÖÊèê‰æõ‰∫ÜÂø†ÂØ¶ÁöÑÈõúÈü≥ÂΩ¢ÁãÄË™™ÊòéÔºåËÄå‰∏îÊØîÂü∫Ê∫ñÊ®°ÂûãÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÈ†êÊ∏¨ÊïàËÉΩ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Âú®ËàáÈÜ´Â≠∏ÁîüÁöÑË≥™ÊÄß‰ΩøÁî®ËÄÖÁ†îÁ©∂‰∏≠Â±ïÁ§∫‰∫ÜÂúñËß£Ë™™ÊòéÁöÑÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÔºåÈ°ØÁ§∫Âá∫‰ª•Ëá®Â∫äÁõ∏ÈóúÁöÑÂúñËß£Ë™™ÊòéÂÑ™ÊñºÊäÄË°ìÈ°ØËëóÊÄßÂúñË™™Êòé„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊúâÂä©ÊñºÊèê‰æõ‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑ XAI ÁöÑÈ†òÂüüÊÖ£‰æãÊºîÁππË™™Êòé„ÄÇ

##### **LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**
2302.01104v1 by Ghanta Sai Krishna, Kundrapu Supriya, Mallikharjuna Rao K, Meetiksha Sorgile

Skin cancer is one of the most prevalent forms of human cancer. It is
recognized mainly visually, beginning with clinical screening and continuing
with the dermoscopic examination, histological assessment, and specimen
collection. Deep convolutional neural networks (CNNs) perform highly segregated
and potentially universal tasks against a classified finegrained object. This
research proposes a novel multi-class prediction framework that classifies skin
lesions based on ViT and ViTGAN. Vision transformers-based GANs (Generative
Adversarial Networks) are utilized to tackle the class imbalance. The framework
consists of four main phases: ViTGANs, Image processing, and explainable AI.
Phase 1 consists of generating synthetic images to balance all the classes in
the dataset. Phase 2 consists of applying different data augmentation
techniques and morphological operations to increase the size of the data.
Phases 3 & 4 involve developing a ViT model for edge computing systems that can
identify patterns and categorize skin lesions from the user's skin visible in
the image. In phase 3, after classifying the lesions into the desired class
with ViT, we will use explainable AI (XAI) that leads to more explainable
results (using activation maps, etc.) while ensuring high predictive accuracy.
Real-time images of skin diseases can capture by a doctor or a patient using
the camera of a mobile application to perform an early examination and
determine the cause of the skin lesion. The whole framework is compared with
the existing frameworks for skin lesion detection.

ÊëòË¶ÅÔºöÁöÆËÜöÁôåÊòØ‰∫∫È°ûÊúÄÊôÆÈÅçÁöÑÁôåÁóáÈ°ûÂûã‰πã‰∏Ä„ÄÇÂÆÉÁöÑË≠òÂà•‰∏ªË¶Å‰æùË≥¥Ë¶ñË¶∫ÔºåÂæûËá®Â∫äÁØ©Ê™¢ÈñãÂßãÔºåÊé•ËëóÊòØÁöÆËÜöÈè°Ê™¢Êü•„ÄÅÁµÑÁπîÂ≠∏Ë©ï‰º∞Ôºå‰ª•ÂèäÊ™¢È´îÊî∂ÈõÜ„ÄÇÊ∑±Â∫¶Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂèØÈáùÂ∞çÂàÜÈ°ûÁöÑÁ¥∞Á≤íÂ∫¶Áâ©‰ª∂Âü∑Ë°åÈ´òÂ∫¶ÂçÄÈöî‰∏îÊΩõÂú®ÈÄöÁî®ÁöÑ‰ªªÂãô„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÈ°ûÂà•È†êÊ∏¨Êû∂ÊßãÔºåÂÆÉ‰ª• ViT Âíå ViTGAN ÁÇ∫Âü∫Á§éÂ∞çÁöÆËÜöÁóÖÁÅ∂ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂü∫ÊñºË¶ñË¶∫ËΩâÊèõÂô®ÁöÑ GANÔºàÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑ØÔºâÁî®ÊñºËß£Ê±∫È°ûÂà•‰∏çÂπ≥Ë°°ÂïèÈ°å„ÄÇÊ≠§Êû∂ÊßãÂåÖÂê´ÂõõÂÄã‰∏ªË¶ÅÈöéÊÆµÔºöViTGAN„ÄÅÂΩ±ÂÉèËôïÁêÜÂíåÂèØËß£Èáã AI„ÄÇÁ¨¨‰∏ÄÈöéÊÆµÂåÖÊã¨Áî¢ÁîüÂêàÊàêÂΩ±ÂÉèÔºå‰ª•Âπ≥Ë°°Ë≥áÊñôÈõÜ‰∏≠ÁöÑÊâÄÊúâÈ°ûÂà•„ÄÇÁ¨¨‰∫åÈöéÊÆµÂåÖÊã¨ÊáâÁî®‰∏çÂêåÁöÑË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÂíåÂΩ¢ÊÖãÈÅãÁÆóÔºå‰ª•Â¢ûÂä†Ë≥áÊñôÂ§ßÂ∞è„ÄÇÁ¨¨‰∏âÂíåÁ¨¨ÂõõÈöéÊÆµÊ∂âÂèäÈñãÁôºÈÅ©Áî®ÊñºÈÇäÁ∑£ÈÅãÁÆóÁ≥ªÁµ±ÁöÑ ViT Ê®°ÂûãÔºåË©≤Ê®°ÂûãÂèØ‰ª•Ë≠òÂà•ÂúñÊ°àÔºå‰∏¶Â∞çÂΩ±ÂÉè‰∏≠Áî®Êà∂ÁöÆËÜöÂèØË¶ãÁöÑÁöÆËÜöÁóÖÁÅ∂ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂú®Á¨¨‰∏âÈöéÊÆµÔºåÂú®‰ΩøÁî® ViT Â∞áÁóÖÁÅ∂ÂàÜÈ°ûÂà∞ÊâÄÈúÄÁöÑÈ°ûÂà•ÂæåÔºåÊàëÂÄëÂ∞á‰ΩøÁî®ÂèØËß£Èáã AI (XAI)ÔºåÂÆÉÊúÉÁî¢ÁîüÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÁöÑÁµêÊûúÔºà‰ΩøÁî®ÂïüÁî®ÂúñÁ≠âÔºâÔºåÂêåÊôÇÁ¢∫‰øùÈ´òÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁöÆËÜöÁñæÁóÖÁöÑÂç≥ÊôÇÂΩ±ÂÉèÂèØ‰ª•Áî®Ë°åÂãïÊáâÁî®Á®ãÂºèÁöÑÁõ∏Ê©üÁî±ÈÜ´ÁîüÊàñÊÇ£ËÄÖÊì∑ÂèñÔºå‰ª•Âü∑Ë°åÊó©ÊúüÊ™¢Êü•‰∏¶Á¢∫ÂÆöÁöÆËÜöÁóÖÁÅ∂ÁöÑÂéüÂõ†„ÄÇÊï¥ÂÄãÊû∂ÊßãËàáÁèæÊúâÁöÑÁöÆËÜöÁóÖÁÅ∂ÂÅµÊ∏¨Êû∂ÊßãÈÄ≤Ë°åÊØîËºÉ„ÄÇ

##### **SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**
2302.00785v1 by Roxana Daneshjou, Mert Yuksekgonul, Zhuo Ran Cai, Roberto Novoa, James Zou

For the deployment of artificial intelligence (AI) in high-risk settings,
such as healthcare, methods that provide interpretability/explainability or
allow fine-grained error analysis are critical. Many recent methods for
interpretability/explainability and fine-grained error analysis use concepts,
which are meta-labels that are semantically meaningful to humans. However,
there are only a few datasets that include concept-level meta-labels and most
of these meta-labels are relevant for natural images that do not require domain
expertise. Densely annotated datasets in medicine focused on meta-labels that
are relevant to a single disease such as melanoma. In dermatology, skin disease
is described using an established clinical lexicon that allows clinicians to
describe physical exam findings to one another. To provide a medical dataset
densely annotated by domain experts with annotations useful across multiple
disease processes, we developed SkinCon: a skin disease dataset densely
annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick
17k dataset densely annotated with 48 clinical concepts, 22 of which have at
least 50 images representing the concept. The concepts used were chosen by two
dermatologists considering the clinical descriptor terms used to describe skin
lesions. Examples include "plaque", "scale", and "erosion". The same concepts
were also used to label 656 skin disease images from the Diverse Dermatology
Images dataset, providing an additional external dataset with diverse skin tone
representations. We review the potential applications for the SkinCon dataset,
such as probing models, concept-based explanations, and concept bottlenecks.
Furthermore, we use SkinCon to demonstrate two of these use cases: debugging
mistakes of an existing dermatology AI model with concepts and developing
interpretable models with post-hoc concept bottleneck models.

ÊëòË¶ÅÔºö<paragraph>Âú®È´òÈ¢®Èö™Áí∞Â¢É‰∏≠ÈÉ®ÁΩ≤‰∫∫Â∑•Êô∫ÊÖß (AI)Ôºà‰æãÂ¶ÇÈÜ´ÁôÇ‰øùÂÅ•ÔºâÔºåÊèê‰æõÂèØËß£ÈáãÊÄß/ÂèØË™™ÊòéÊÄßÁöÑÊñπÊ≥ïÊàñÂÖÅË®±Á≤æÁ¥∞ÈåØË™§ÂàÜÊûêÈùûÂ∏∏ÈáçË¶Å„ÄÇË®±Â§öËøëÊúüÁî®ÊñºÂèØËß£ÈáãÊÄß/ÂèØË™™ÊòéÊÄßÂíåÁ≤æÁ¥∞ÈåØË™§ÂàÜÊûêÁöÑÊñπÊ≥ïÈÉΩ‰ΩøÁî®Ê¶ÇÂøµÔºåÈÄô‰∫õÊ¶ÇÂøµÊòØÂ∞ç‰∫∫È°ûÂÖ∑ÊúâË™ûÁæ©ÊÑèÁæ©ÁöÑÂÖÉÊ®ôÁ±§„ÄÇÁÑ∂ËÄåÔºåÂè™ÊúâÂ∞ëÊï∏Ë≥áÊñôÈõÜÂåÖÂê´Ê¶ÇÂøµÂ±§Á¥öÁöÑÂÖÉÊ®ôÁ±§ÔºåËÄå‰∏îÈÄô‰∫õÂÖÉÊ®ôÁ±§Â§ßÂ§öËàá‰∏çÈúÄË¶ÅÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÁöÑËá™ÁÑ∂ÂΩ±ÂÉèÁõ∏Èóú„ÄÇÂ∞àÊ≥®ÊñºÂñÆ‰∏ÄÁñæÁóÖÔºà‰æãÂ¶ÇÈªëËâ≤Á¥†Áò§ÔºâÁöÑÂÖÉÊ®ôÁ±§ÁöÑÈÜ´Â≠∏ÂØÜÈõÜÊ®ôË®òË≥áÊñôÈõÜ„ÄÇÂú®ÁöÆËÜöÁßë‰∏≠ÔºåÁöÆËÜöÁñæÁóÖÁöÑÊèèËø∞‰ΩøÁî®Êó¢ÂÆöÁöÑËá®Â∫äË©ûÂΩôÔºåËÆìËá®Â∫äÈÜ´ÁîüÂèØ‰ª•ÂΩºÊ≠§ÊèèËø∞Ë∫´È´îÊ™¢Êü•ÁµêÊûú„ÄÇÁÇ∫‰∫ÜÊèê‰æõÁî±È†òÂüüÂ∞àÂÆ∂ÂØÜÈõÜÊ®ôË®òÁöÑÈÜ´Â≠∏Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂèØË∑®Â§öÁ®ÆÁñæÁóÖÈÅéÁ®ã‰ΩøÁî®ÁöÑÊ®ôË®òÔºåÊàëÂÄëÈñãÁôº‰∫Ü SkinConÔºöÁî±ÁöÆËÜöÁßëÈÜ´Â∏´ÂØÜÈõÜÊ®ôË®òÁöÑÁöÆËÜöÁñæÁóÖË≥áÊñôÈõÜ„ÄÇSkinCon ÂåÖÂê´‰æÜËá™ Fitzpatrick 17k Ë≥áÊñôÈõÜÁöÑ 3230 ÂºµÂΩ±ÂÉèÔºåÂØÜÈõÜÊ®ôË®ò‰∫Ü 48 ÂÄãËá®Â∫äÊ¶ÇÂøµÔºåÂÖ∂‰∏≠ 22 ÂÄãÊ¶ÇÂøµËá≥Â∞ëÊúâ 50 ÂºµÂΩ±ÂÉè‰ª£Ë°®Ë©≤Ê¶ÇÂøµ„ÄÇÊâÄ‰ΩøÁî®ÁöÑÊ¶ÇÂøµÊòØÁî±ÂÖ©‰ΩçÁöÆËÜöÁßëÈÜ´Â∏´Âú®ËÄÉÈáèÁî®ÊñºÊèèËø∞ÁöÆËÜöÁóÖËÆäÁöÑËá®Â∫äÊèèËø∞Ë©ûÂΩôÂæåÈÅ∏Âá∫ÁöÑ„ÄÇÁØÑ‰æãÂåÖÊã¨„ÄåÊñëÂ°ä„Äç„ÄÅ„ÄåÈ±óÂ±ë„ÄçÂíå„ÄåÁ≥úÁàõ„Äç„ÄÇÁõ∏ÂêåÁöÑÊ¶ÇÂøµ‰πüÁî®ÊñºÊ®ôË®ò‰æÜËá™ Diverse Dermatology Images Ë≥áÊñôÈõÜÁöÑ 656 ÂºµÁöÆËÜöÁñæÁóÖÂΩ±ÂÉèÔºåÊèê‰æõÂÖ∑ÊúâÂ§öÊ®£ËÜöËâ≤Ë°®Á§∫ÁöÑÈ°çÂ§ñÂ§ñÈÉ®Ë≥áÊñôÈõÜ„ÄÇÊàëÂÄëÊ™¢Ë¶ñ SkinCon Ë≥áÊñôÈõÜÁöÑÊΩõÂú®ÊáâÁî®Ôºå‰æãÂ¶ÇÊé¢Ê∏¨Ê®°Âûã„ÄÅÂü∫ÊñºÊ¶ÇÂøµÁöÑË™™ÊòéÂíåÊ¶ÇÂøµÁì∂È†∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ΩøÁî® SkinCon ‰æÜÂ±ïÁ§∫ÈÄôÂÖ©ÂÄã‰ΩøÁî®Ê°à‰æãÔºö‰ΩøÁî®Ê¶ÇÂøµÈô§ÈåØÁèæÊúâÁöÆËÜöÁßë AI Ê®°ÂûãÁöÑÈåØË™§Ôºå‰ª•Âèä‰ΩøÁî®‰∫ãÂæåÊ¶ÇÂøµÁì∂È†∏Ê®°ÂûãÈñãÁôºÂèØËß£ÈáãÁöÑÊ®°Âûã„ÄÇ</paragraph>

##### **Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**
2301.07835v1 by Paritosh Verma, Shresth Verma, Aditya Mate, Aparna Taneja, Milind Tambe

Restless multi-arm bandits (RMABs) is a popular decision-theoretic framework
that has been used to model real-world sequential decision making problems in
public health, wildlife conservation, communication systems, and beyond.
Deployed RMAB systems typically operate in two stages: the first predicts the
unknown parameters defining the RMAB instance, and the second employs an
optimization algorithm to solve the constructed RMAB instance.
  In this work we provide and analyze the results from a first-of-its-kind
deployment of an RMAB system in public health domain, aimed at improving
maternal and child health. Our analysis is focused towards understanding the
relationship between prediction accuracy and overall performance of deployed
RMAB systems. This is crucial for determining the value of investing in
improving predictive accuracy towards improving the final system performance,
and is useful for diagnosing, monitoring deployed RMAB systems.
  Using real-world data from our deployed RMAB system, we demonstrate that an
improvement in overall prediction accuracy may even be accompanied by a
degradation in the performance of RMAB system -- a broad investment of
resources to improve overall prediction accuracy may not yield expected
results. Following this, we develop decision-focused evaluation metrics to
evaluate the predictive component and show that it is better at explaining
(both empirically and theoretically) the overall performance of a deployed RMAB
system.

ÊëòË¶ÅÔºö‰∏çÂÆâÂàÜÁöÑÂ§öËáÇÂº∑Áõú (RMAB) ÊòØ‰∏ÄÂÄãÊµÅË°åÁöÑÊ±∫Á≠ñÁêÜË´ñÊû∂ÊßãÔºåÂ∑≤Ë¢´Áî®ÊñºÊ®°Êì¨ÂÖ¨ÂÖ±Ë°õÁîü„ÄÅÈáéÁîüÂãïÁâ©‰øùËÇ≤„ÄÅÈÄöË®äÁ≥ªÁµ±Á≠âÈ†òÂüüÁöÑÁúüÂØ¶‰∏ñÁïåÈ†ÜÂ∫èÊ±∫Á≠ñÂïèÈ°å„ÄÇÂ∑≤ÈÉ®ÁΩ≤ÁöÑ RMAB Á≥ªÁµ±ÈÄöÂ∏∏ÂàÜÂÖ©ÂÄãÈöéÊÆµÈÅã‰ΩúÔºöÁ¨¨‰∏ÄÂÄãÈöéÊÆµÈ†êÊ∏¨ÂÆöÁæ© RMAB Âü∑Ë°åÂÄãÈ´îÁöÑÊú™Áü•ÂèÉÊï∏ÔºåÁ¨¨‰∫åÂÄãÈöéÊÆµÊé°Áî®ÊúÄ‰Ω≥ÂåñÊºîÁÆóÊ≥ï‰æÜËß£Ê±∫Â∑≤Âª∫ÊßãÁöÑ RMAB Âü∑Ë°åÂÄãÈ´î„ÄÇ
Âú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∏¶ÂàÜÊûê‰∫ÜÂú®ÂÖ¨ÂÖ±Ë°õÁîüÈ†òÂüü‰∏≠È¶ñÊ¨°ÈÉ®ÁΩ≤ RMAB Á≥ªÁµ±ÁöÑÁµêÊûúÔºåÁõÆÊ®ôÊòØÊîπÂñÑÂ≠ïÁî¢Â©¶ÂíåÂÖíÁ´•ÂÅ•Â∫∑„ÄÇÊàëÂÄëÁöÑÂàÜÊûêËëóÈáçÊñº‰∫ÜËß£È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ËàáÂ∑≤ÈÉ®ÁΩ≤ RMAB Á≥ªÁµ±ÁöÑÊï¥È´îÊïàËÉΩ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÈÄôÂ∞çÊñºÊ±∫ÂÆöÊäïË≥áÊñºÊîπÂñÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶‰ª•ÊèêÂçáÊúÄÁµÇÁ≥ªÁµ±ÊïàËÉΩÁöÑÂÉπÂÄºËá≥ÈóúÈáçË¶ÅÔºå‰∏¶‰∏îÊúâÂä©ÊñºË®∫Êñ∑„ÄÅÁõ£ÊéßÂ∑≤ÈÉ®ÁΩ≤ÁöÑ RMAB Á≥ªÁµ±„ÄÇ
‰ΩøÁî®ÊàëÂÄëÂ∑≤ÈÉ®ÁΩ≤ RMAB Á≥ªÁµ±‰∏≠ÁöÑÁúüÂØ¶‰∏ñÁïåË≥áÊñôÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊï¥È´îÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÁöÑÊèêÂçáÁîöËá≥ÂèØËÉΩ‰º¥Èö®Ëëó RMAB Á≥ªÁµ±ÊïàËÉΩÁöÑ‰∏ãÈôç‚Äî‚ÄîÂª£Ê≥õÊäïÂÖ•Ë≥áÊ∫ê‰ª•ÊîπÂñÑÊï¥È´îÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÂèØËÉΩÁÑ°Ê≥ïÁî¢ÁîüÈ†êÊúüÁöÑÁµêÊûú„ÄÇÂú®Ê≠§‰πãÂæåÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰ª•Ê±∫Á≠ñÁÇ∫ÈáçÈªûÁöÑË©ï‰º∞ÊåáÊ®ô‰æÜË©ï‰º∞È†êÊ∏¨ÂÖÉ‰ª∂Ôºå‰∏¶Ë≠âÊòéÂÆÉÊõ¥ËÉΩËß£ÈáãÂ∑≤ÈÉ®ÁΩ≤ RMAB Á≥ªÁµ±ÁöÑÊï¥È´îÊïàËÉΩÔºàÁÑ°Ë´ñÊòØÁ∂ìÈ©ó‰∏äÊàñÁêÜË´ñ‰∏äÔºâ„ÄÇ

##### **Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**
2302.03033v1 by Carlo Metta, Riccardo Guidotti, Yuan Yin, Patrick Gallinari, Salvatore Rinzivillo

Explainable AI consists in developing mechanisms allowing for an interaction
between decision systems and humans by making the decisions of the formers
understandable. This is particularly important in sensitive contexts like in
the medical domain. We propose a use case study, for skin lesion diagnosis,
illustrating how it is possible to provide the practitioner with explanations
on the decisions of a state of the art deep neural network classifier trained
to characterize skin lesions from examples. Our framework consists of a trained
classifier onto which an explanation module operates. The latter is able to
offer the practitioner exemplars and counterexemplars for the classification
diagnosis thus allowing the physician to interact with the automatic diagnosis
system. The exemplars are generated via an adversarial autoencoder. We
illustrate the behavior of the system on representative examples.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI ÊòØÂú®ÈñãÁôºÊ©üÂà∂ÔºåËÆìÊ±∫Á≠ñÁ≥ªÁµ±Ëàá‰∫∫È°û‰πãÈñìËÉΩ‰∫íÂãïÔºå‰∏¶ËÆìÂâçËÄÖÁöÑÊ±∫Á≠ñËÆäÂæóÂèØ‰ª•ÁêÜËß£„ÄÇÈÄôÂú®ÊïèÊÑüÁöÑËÑàÁµ°‰∏≠ÁâπÂà•ÈáçË¶ÅÔºå‰æãÂ¶ÇÂú®ÈÜ´ÁôÇÈ†òÂüü„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Ê°à‰æãÁ†îÁ©∂ÔºåÁî®ÊñºÁöÆËÜöÁóÖËÆäË®∫Êñ∑ÔºåË™™ÊòéÂ¶Ç‰ΩïËÆìÂü∑Ê•≠ÈÜ´Â∏´‰∫ÜËß£ÊúÄÂÖàÈÄ≤ÁöÑÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÂàÜÈ°ûÂô®Âú®Ê±∫Á≠ñ‰∏äÁöÑËß£ÈáãÔºåË©≤ÂàÜÈ°ûÂô®Á∂ìÈÅéË®ìÁ∑¥ÔºåÂèØ‰ª•ÂæûÁØÑ‰æã‰∏≠ÊèèËø∞ÁöÆËÜöÁóÖËÆä„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂåÖÂê´‰∏ÄÂÄãË®ìÁ∑¥ÈÅéÁöÑÂàÜÈ°ûÂô®ÔºåËß£ÈáãÊ®°ÁµÑÊúÉÂú®Ë©≤ÂàÜÈ°ûÂô®‰∏äÈÅã‰Ωú„ÄÇÂæåËÄÖËÉΩÂ§†ÁÇ∫ÂàÜÈ°ûË®∫Êñ∑Êèê‰æõÂü∑Ê•≠ÈÜ´Â∏´ÁØÑ‰æãÂíåÂèç‰æãÔºåÂõ†Ê≠§ËÆìÈÜ´Â∏´ÂèØ‰ª•ËàáËá™ÂãïË®∫Êñ∑Á≥ªÁµ±‰∫íÂãï„ÄÇÁØÑ‰æãÊòØÈÄèÈÅéÂ∞çÊäóÂºèËá™ÂãïÁ∑®Á¢ºÂô®Áî¢ÁîüÁöÑ„ÄÇÊàëÂÄëË™™ÊòéÁ≥ªÁµ±Âú®‰ª£Ë°®ÊÄßÁØÑ‰æã‰∏äÁöÑË°åÁÇ∫„ÄÇ

##### **Monotonicity for AI ethics and society: An empirical study of the monotonic neural additive model in criminology, education, health care, and finance**
2301.07060v1 by Dangxing Chen, Luyao Zhang

Algorithm fairness in the application of artificial intelligence (AI) is
essential for a better society. As the foundational axiom of social mechanisms,
fairness consists of multiple facets. Although the machine learning (ML)
community has focused on intersectionality as a matter of statistical parity,
especially in discrimination issues, an emerging body of literature addresses
another facet -- monotonicity. Based on domain expertise, monotonicity plays a
vital role in numerous fairness-related areas, where violations could misguide
human decisions and lead to disastrous consequences. In this paper, we first
systematically evaluate the significance of applying monotonic neural additive
models (MNAMs), which use a fairness-aware ML algorithm to enforce both
individual and pairwise monotonicity principles, for the fairness of AI ethics
and society. We have found, through a hybrid method of theoretical reasoning,
simulation, and extensive empirical analysis, that considering monotonicity
axioms is essential in all areas of fairness, including criminology, education,
health care, and finance. Our research contributes to the interdisciplinary
research at the interface of AI ethics, explainable AI (XAI), and
human-computer interactions (HCIs). By evidencing the catastrophic consequences
if monotonicity is not met, we address the significance of monotonicity
requirements in AI applications. Furthermore, we demonstrate that MNAMs are an
effective fairness-aware ML approach by imposing monotonicity restrictions
integrating human intelligence.

ÊëòË¶ÅÔºöÂú®‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÊáâÁî®‰∏≠ÔºåÊºîÁÆóÊ≥ïÂÖ¨Âπ≥ÊÄßÂ∞çÊñºÂª∫Á´ã‰∏ÄÂÄãÊõ¥ÁæéÂ•ΩÁöÑÁ§æÊúÉËá≥ÈóúÈáçË¶Å„ÄÇÂÖ¨Âπ≥ÊÄß‰ΩúÁÇ∫Á§æÊúÉÊ©üÂà∂ÁöÑÂü∫Á§éÂÖ¨ÁêÜÔºåÂåÖÂê´Â§öÂÄãÈù¢Âêë„ÄÇÂÑòÁÆ°Ê©üÂô®Â≠∏Áøí (ML) Á§æÁæ§Â∑≤Â∞áÁÑ¶ÈªûÊîæÂú®‰∫§ÂèâÊÄß‰ΩúÁÇ∫Áµ±Ë®àÂêåË≥™ÊÄßÁöÑÂïèÈ°å‰∏äÔºåÁâπÂà•ÊòØÂú®Ê≠ßË¶ñÂïèÈ°å‰∏≠Ôºå‰ΩÜÊñ∞ËààÁöÑÊñáÁçªÊé¢Ë®é‰∫ÜÂè¶‰∏ÄÂÄãÈù¢Âêë‚Äî‚ÄîÂñÆË™øÊÄß„ÄÇÊ†πÊìöÈ†òÂüüÂ∞àÂÆ∂ÔºåÂñÆË™øÊÄßÂú®Ë®±Â§öËàáÂÖ¨Âπ≥ÊÄßÁõ∏ÈóúÁöÑÈ†òÂüü‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÈÅïÂèçÂñÆË™øÊÄßÂèØËÉΩÊúÉË™§Â∞é‰∫∫È°ûÊ±∫Á≠ñÔºå‰∏¶Â∞éËá¥ÁÅΩÈõ£ÊÄßÁöÑÂæåÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÁ≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞ÊáâÁî®ÂñÆË™øÁ•ûÁ∂ìÂä†Ê≥ïÊ®°Âûã (MNAM) ÁöÑÈáçË¶ÅÊÄßÔºåÈÄô‰∫õÊ®°Âûã‰ΩøÁî®ÂÖ¨Âπ≥ÊÑüÁü• ML ÊºîÁÆóÊ≥ï‰æÜÂº∑Âà∂Âü∑Ë°åÂÄãÂà•ÂíåÊàêÂ∞çÂñÆË™øÊÄßÂéüÂâáÔºå‰ª•Á¢∫‰øù AI ÂÄ´ÁêÜÂíåÁ§æÊúÉÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÁêÜË´ñÊé®ÁêÜ„ÄÅÊ®°Êì¨ÂíåÂª£Ê≥õÁöÑÂØ¶Ë≠âÂàÜÊûêÁöÑÊ∑∑ÂêàÊñπÊ≥ïÁôºÁèæÔºåÂú®ÊâÄÊúâÂÖ¨Âπ≥È†òÂüüÔºàÂåÖÊã¨ÁäØÁΩ™Â≠∏„ÄÅÊïôËÇ≤„ÄÅÈÜ´ÁôÇ‰øùÂÅ•ÂíåÈáëËûçÔºâ‰∏≠ÔºåËÄÉÈáèÂñÆË™øÊÄßÂÖ¨ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÊúâÂä©Êñº AI ÂÄ´ÁêÜ„ÄÅÂèØËß£Èáã AI (XAI) Âíå‰∫∫Ê©ü‰∫íÂãï (HCI) ‰ªãÈù¢‰∏≠ÁöÑË∑®È†òÂüüÁ†îÁ©∂„ÄÇÈÄèÈÅéË≠âÊòé‰∏çÁ¨¶ÂêàÂñÆË™øÊÄßÁöÑÁÅΩÈõ£ÊÄßÂæåÊûúÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂñÆË™øÊÄßÈúÄÊ±ÇÂú® AI ÊáâÁî®‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòé MNAM ÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑÂÖ¨Âπ≥ÊÑüÁü• ML ÊñπÊ≥ïÔºåÈÄèÈÅéÊñΩÂä†ÂñÆË™øÊÄßÈôêÂà∂‰æÜÊï¥Âêà‰∫∫È°ûÊô∫ÊÖß„ÄÇ

##### **Rationalizing Predictions by Adversarial Information Calibration**
2301.06009v1 by Lei Sha, Oana-Maria Camburu, Thomas Lukasiewicz

Explaining the predictions of AI models is paramount in safety-critical
applications, such as in legal or medical domains. One form of explanation for
a prediction is an extractive rationale, i.e., a subset of features of an
instance that lead the model to give its prediction on that instance. For
example, the subphrase ``he stole the mobile phone'' can be an extractive
rationale for the prediction of ``Theft''. Previous works on generating
extractive rationales usually employ a two-phase model: a selector that selects
the most important features (i.e., the rationale) followed by a predictor that
makes the prediction based exclusively on the selected features. One
disadvantage of these works is that the main signal for learning to select
features comes from the comparison of the answers given by the predictor to the
ground-truth answers. In this work, we propose to squeeze more information from
the predictor via an information calibration method. More precisely, we train
two models jointly: one is a typical neural model that solves the task at hand
in an accurate but black-box manner, and the other is a selector-predictor
model that additionally produces a rationale for its prediction. The first
model is used as a guide for the second model. We use an adversarial technique
to calibrate the information extracted by the two models such that the
difference between them is an indicator of the missed or over-selected
features. In addition, for natural language tasks, we propose a
language-model-based regularizer to encourage the extraction of fluent
rationales. Experimental results on a sentiment analysis task, a hate speech
recognition task as well as on three tasks from the legal domain show the
effectiveness of our approach to rationale extraction.

ÊëòË¶ÅÔºö<paragraph>Âú®ÂÆâÂÖ®ÈóúÈçµÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰æãÂ¶ÇÊ≥ïÂæãÊàñÈÜ´ÁôÇÈ†òÂüüÔºåËß£Èáã AI Ê®°ÂûãÁöÑÈ†êÊ∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇ‰∏ÄÁ®ÆÈ†êÊ∏¨ÁöÑËß£ÈáãÂΩ¢ÂºèÊòØËêÉÂèñ‰æùÊìöÔºå‰∫¶Âç≥ÊüêÂÄãÂØ¶‰æã‰∏≠Â∞éËá¥Ê®°ÂûãÂ∞çË©≤ÂØ¶‰æãÂÅöÂá∫È†êÊ∏¨ÁöÑÂ≠êÈõÜÂêàÁâπÂæµ„ÄÇ‰æãÂ¶ÇÔºåÂ≠êË©ûÁµÑ„Äå‰ªñÂÅ∑‰∫ÜÊâãÊ©ü„ÄçÂèØËÉΩÊòØ„ÄåÂÅ∑Á´ä„ÄçÈ†êÊ∏¨ÁöÑËêÉÂèñ‰æùÊìö„ÄÇÂÖàÂâçÈóúÊñºÁî¢ÁîüËêÉÂèñ‰æùÊìöÁöÑÁ†îÁ©∂ÈÄöÂ∏∏Êé°Áî®‰∫åÈöéÊÆµÊ®°ÂûãÔºö‰∏ÄÂÄãÈÅ∏ÊìáÂô®ÈÅ∏ÊìáÊúÄÈáçË¶ÅÁöÑÁâπÂæµÔºàÂç≥‰æùÊìöÔºâÔºåÊé•ËëóÊòØ‰∏ÄÂÄãÈ†êÊ∏¨Âô®ÔºåÂÆÉÊ†πÊìöÊâÄÈÅ∏ÁöÑÁâπÂæµÁç®ÂÆ∂ÂÅöÂá∫È†êÊ∏¨„ÄÇÈÄô‰∫õÁ†îÁ©∂ÁöÑ‰∏ÄÂÄãÁº∫ÈªûÊòØÔºåÂ≠∏ÁøíÈÅ∏ÊìáÁâπÂæµÁöÑ‰∏ªË¶ÅË®äËôü‰æÜËá™Â∞áÈ†êÊ∏¨Âô®Áµ¶Âá∫ÁöÑÁ≠îÊ°àËàáÁúüÂØ¶Á≠îÊ°àÈÄ≤Ë°åÊØîËºÉ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞ÈÄèÈÅéË≥áË®äÊ†°Ê≠£ÊñπÊ≥ïÂæûÈ†êÊ∏¨Âô®‰∏≠Êì∑ÂèñÊõ¥Â§öË≥áË®ä„ÄÇÊõ¥Á≤æÁ¢∫Âú∞Ë™™ÔºåÊàëÂÄëËÅØÂêàË®ìÁ∑¥ÂÖ©ÂÄãÊ®°ÂûãÔºö‰∏ÄÂÄãÊòØÂÖ∏ÂûãÁöÑÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºåÂÆÉ‰ª•Ê∫ñÁ¢∫‰ΩÜÈªëÁÆ±ÁöÑÊñπÂºèËß£Ê±∫ÊâãÈÇäÁöÑ‰ªªÂãôÔºåÂè¶‰∏ÄÂÄãÊòØÈÅ∏ÊìáÂô®È†êÊ∏¨Âô®Ê®°ÂûãÔºåÂÆÉÂè¶Â§ñÁÇ∫ÂÖ∂È†êÊ∏¨Áî¢Áîü‰æùÊìö„ÄÇÁ¨¨‰∏ÄÂÄãÊ®°ÂûãÁî®‰ΩúÁ¨¨‰∫åÂÄãÊ®°ÂûãÁöÑÊåáÂçó„ÄÇÊàëÂÄë‰ΩøÁî®Â∞çÊäóÊäÄË°ìÊ†°Ê≠£ÂÖ©ÂÄãÊ®°ÂûãËêÉÂèñÁöÑË≥áË®äÔºå‰ΩøÂÆÉÂÄë‰πãÈñìÁöÑÂ∑ÆÁï∞ÊàêÁÇ∫ÈÅ∫ÊºèÊàñÈÅéÂ∫¶ÈÅ∏ÊìáÁöÑÁâπÂæµÁöÑÊåáÊ®ô„ÄÇÊ≠§Â§ñÔºåÂ∞çÊñºËá™ÁÑ∂Ë™ûË®Ä‰ªªÂãôÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºË™ûË®ÄÊ®°ÂûãÁöÑÊ≠£Ë¶èÂåñÂô®Ôºå‰ª•ÈºìÂãµËêÉÂèñÊµÅÊö¢ÁöÑ‰æùÊìö„ÄÇÊÉÖÁ∑íÂàÜÊûê‰ªªÂãô„ÄÅ‰ªáÊÅ®Ë®ÄË´ñËæ®Ë≠ò‰ªªÂãô‰ª•ÂèäÊ≥ïÂæãÈ†òÂüü‰∏âÂÄã‰ªªÂãôÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÂú®‰æùÊìöËêÉÂèñÊñπÈù¢ÁöÑÂÅöÊ≥ïÂçÅÂàÜÊúâÊïà„ÄÇ</paragraph>

##### **Semantic match: Debugging feature attribution methods in XAI for healthcare**
2301.02080v3 by Giovanni Cin√†, Tabea E. R√∂ber, Rob Goedhart, ≈û. ƒ∞lker Birbil

The recent spike in certified Artificial Intelligence (AI) tools for
healthcare has renewed the debate around adoption of this technology. One
thread of such debate concerns Explainable AI (XAI) and its promise to render
AI devices more transparent and trustworthy. A few voices active in the medical
AI space have expressed concerns on the reliability of Explainable AI
techniques and especially feature attribution methods, questioning their use
and inclusion in guidelines and standards. Despite valid concerns, we argue
that existing criticism on the viability of post-hoc local explainability
methods throws away the baby with the bathwater by generalizing a problem that
is specific to image data. We begin by characterizing the problem as a lack of
semantic match between explanations and human understanding. To understand when
feature importance can be used reliably, we introduce a distinction between
feature importance of low- and high-level features. We argue that for data
types where low-level features come endowed with a clear semantics, such as
tabular data like Electronic Health Records (EHRs), semantic match can be
obtained, and thus feature attribution methods can still be employed in a
meaningful and useful way. Finally, we sketch a procedure to test whether
semantic match has been achieved.

ÊëòË¶ÅÔºöÊúÄËøëÈÄöÈÅéË™çË≠âÁöÑ‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÈÜ´ÁôÇ‰øùÂÅ•Â∑•ÂÖ∑Êï∏ÈáèÊøÄÂ¢ûÔºåËÆìÊé°Áî®Ê≠§ÊäÄË°ìÁöÑËæØË´ñÂÜçÂ∫¶ÊµÆ‰∏äÊ™ØÈù¢„ÄÇÂÖ∂‰∏≠‰∏ÄÂÄãËæØË´ñ‰∏ªÈ°åÊòØÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÂèäÂÖ∂ËÆì AI Ë£ùÁΩÆÊõ¥ÈÄèÊòé‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÊâøË´æ„ÄÇÈÜ´ÁôÇ AI È†òÂüü‰∏≠ÁöÑ‰∏Ä‰∫õÁ©çÊ•µÁôºË®ÄËÄÖË°®ÈÅî‰∫ÜÂ∞çÂèØËß£Èáã AI ÊäÄË°ìÔºåÂ∞§ÂÖ∂ÊòØÁâπÂæµÊ≠∏Âõ†ÊñπÊ≥ïÁöÑÂèØÈù†ÊÄßÁñëÊÖÆÔºåË≥™ÁñëÂÖ∂Âú®Ê∫ñÂâáÂíåÊ®ôÊ∫ñ‰∏≠ÁöÑ‰ΩøÁî®ÂíåÁ¥çÂÖ•„ÄÇÂÑòÁÆ°ÊúâÂêàÁêÜÁöÑÁñëÊÖÆÔºåÊàëÂÄë‰∏ªÂºµÂ∞ç‰∫ãÂæåÂ±ÄÈÉ®ÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÂèØË°åÊÄßÊèêÂá∫ÊâπË©ïÔºåÁ≠âÊñºÈÄ£ÂêåÊ¥óÊæ°Ê∞¥‰∏ÄËµ∑ÊääÂ¨∞ÂÖíÂÄíÊéâÔºåÂõ†ÁÇ∫ÈÄôÊòØÂú®Â∞çÂΩ±ÂÉèË≥áÊñôÁâπÊúâÁöÑÂïèÈ°åÈÄ≤Ë°åÊ¶ÇÂåñ„ÄÇÊàëÂÄëÂæûÂ∞áÂïèÈ°åÊèèËø∞ÁÇ∫Ëß£ÈáãËàá‰∫∫È°ûÁêÜËß£‰πãÈñìÁº∫‰πèË™ûÊÑèÂåπÈÖçÈñãÂßã„ÄÇÁÇ∫‰∫ÜÁû≠Ëß£‰ΩïÊôÇÂèØ‰ª•ÂèØÈù†Âú∞‰ΩøÁî®ÁâπÂæµÈáçË¶ÅÊÄßÔºåÊàëÂÄëÂçÄÂàÜ‰∫Ü‰ΩéÈöéÂíåÈ´òÈöéÁâπÂæµÁöÑÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÊàëÂÄë‰∏ªÂºµÔºåÂ∞çÊñº‰ΩéÈöéÁâπÂæµÂÖ∑ÊúâÊòéÁ¢∫Ë™ûÊÑèÁöÑË≥áÊñôÈ°ûÂûãÔºå‰æãÂ¶ÇÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑÔºàEHRÔºâÁ≠âË°®Ê†ºË≥áÊñôÔºåÂèØ‰ª•Áç≤ÂæóË™ûÊÑèÂåπÈÖçÔºåÂõ†Ê≠§‰ªçÁÑ∂ÂèØ‰ª•Âú®ÊúâÊÑèÁæ©‰∏îÊúâÁî®ÁöÑÊñπÂºè‰∏≠Êé°Áî®ÁâπÂæµÊ≠∏Âõ†ÊñπÊ≥ï„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ¶ÇËø∞‰∫Ü‰∏ÄÂÄãÁ®ãÂ∫èÔºå‰ª•Ê∏¨Ë©¶ÊòØÂê¶Â∑≤ÈÅîÊàêË™ûÊÑèÂåπÈÖç„ÄÇ

##### **Context-dependent Explainability and Contestability for Trustworthy Medical Artificial Intelligence: Misclassification Identification of Morbidity Recognition Models in Preterm Infants**
2212.08821v1 by Isil Guzey, Ozlem Ucar, Nukhet Aladag Ciftdemir, Betul Acunas

Although machine learning (ML) models of AI achieve high performances in
medicine, they are not free of errors. Empowering clinicians to identify
incorrect model recommendations is crucial for engendering trust in medical AI.
Explainable AI (XAI) aims to address this requirement by clarifying AI
reasoning to support the end users. Several studies on biomedical imaging
achieved promising results recently. Nevertheless, solutions for models using
tabular data are not sufficient to meet the requirements of clinicians yet.
This paper proposes a methodology to support clinicians in identifying failures
of ML models trained with tabular data. We built our methodology on three main
pillars: decomposing the feature set by leveraging clinical context latent
space, assessing the clinical association of global explanations, and Latent
Space Similarity (LSS) based local explanations. We demonstrated our
methodology on ML-based recognition of preterm infant morbidities caused by
infection. The risk of mortality, lifelong disability, and antibiotic
resistance due to model failures was an open research question in this domain.
We achieved to identify misclassification cases of two models with our
approach. By contextualizing local explanations, our solution provides
clinicians with actionable insights to support their autonomy for informed
final decisions.

ÊëòË¶ÅÔºöÂÑòÁÆ°‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÂú®ÈÜ´Â≠∏È†òÂüü‰∏≠Ë°®ÁèæÂÑ™Áï∞Ôºå‰ΩÜÂÆÉÂÄë‰∏¶ÈùûÊ≤íÊúâÈåØË™§„ÄÇËÆìËá®Â∫äÈÜ´ÁîüËÉΩÂ§†Ëæ®Ë≠ò‰∏çÊ≠£Á¢∫ÁöÑÊ®°ÂûãÂª∫Ë≠∞ÔºåÂ∞çÊñºÂª∫Á´ãÂ∞çÈÜ´ÁôÇ AI ÁöÑ‰ø°‰ªªËá≥ÈóúÈáçË¶Å„ÄÇÂèØËß£Èáã AI (XAI) Êó®Âú®ÈÄèÈÅéÈáêÊ∏Ö AI Êé®ÁêÜ‰æÜÊªøË∂≥Ê≠§È†ÖÈúÄÊ±ÇÔºå‰ª•ÊîØÊè¥ÊúÄÁµÇ‰ΩøÁî®ËÄÖ„ÄÇÊúÄËøëÈáùÂ∞çÁîüÁâ©ÈÜ´Â≠∏ÂΩ±ÂÉèÈÄ≤Ë°åÁöÑÂπæÈ†ÖÁ†îÁ©∂Áç≤Âæó‰∫Ü‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®Ë°®Ê†ºË≥áÊñôÁöÑÊ®°ÂûãËß£Ê±∫ÊñπÊ°àÈÇÑ‰∏çË∂≥‰ª•ÊªøË∂≥Ëá®Â∫äÈÜ´ÁîüÁöÑÈúÄÊ±Ç„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂçîÂä©Ëá®Â∫äÈÜ´ÁîüËæ®Ë≠ò‰ΩøÁî®Ë°®Ê†ºË≥áÊñôË®ìÁ∑¥ÁöÑ ML Ê®°ÂûãÁöÑÂ§±Êïó„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂª∫Á´ãÂú®‰∏âÂÄã‰∏ªË¶ÅÊîØÊü±‰∏äÔºöÂà©Áî®Ëá®Â∫äËÉåÊôØÊΩõÂú®Á©∫ÈñìÂàÜËß£ÁâπÂæµÈõÜ„ÄÅË©ï‰º∞Êï¥È´îËß£ÈáãÁöÑËá®Â∫äÈóúËÅØÊÄßÔºå‰ª•ÂèäÂü∫ÊñºÊΩõÂú®Á©∫ÈñìÁõ∏‰ººÊÄß (LSS) ÁöÑÂ±ÄÈÉ®Ëß£Èáã„ÄÇÊàëÂÄëÂú® ML Âü∫ÊñºÊÑüÊüìÊâÄÂ∞éËá¥ÁöÑÊó©Áî¢ÂÖíÁôºÁóÖÁéáË≠òÂà•‰∏äÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÈÄôÈ†ÖÊñπÊ≥ï„ÄÇÁî±ÊñºÊ®°ÂûãÂ§±ÊïóËÄåÁî¢ÁîüÁöÑÊ≠ª‰∫°È¢®Èö™„ÄÅÁµÇË∫´ÊÆòÁñæÂíåÊäóÁîüÁ¥†ÊäóËó•ÊÄßÔºåÊòØÊ≠§È†òÂüü‰∏≠‰∏ÄÂÄãÂÖ¨ÈñãÁöÑÁ†îÁ©∂ÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÊàêÂäüËæ®Ë≠òÂá∫ÂÖ©ÂÄãÊ®°ÂûãÁöÑÈåØË™§ÂàÜÈ°ûÊ°à‰æã„ÄÇÊàëÂÄëÁöÑËß£Ê±∫ÊñπÊ°àÈÄèÈÅéÂ∞áÂ±ÄÈÉ®Ëß£ÈáãËÑàÁµ°ÂåñÔºåÁÇ∫Ëá®Â∫äÈÜ´ÁîüÊèê‰æõÂèØË°åÁöÑË¶ãËß£Ôºå‰ª•ÊîØÊè¥‰ªñÂÄëËá™‰∏ªÂÅöÂá∫ÊòéÊô∫ÁöÑÊúÄÁµÇÊ±∫ÂÆö„ÄÇ

##### **It is not "accuracy vs. explainability" -- we need both for trustworthy AI systems**
2212.11136v2 by D. Petkovic

We are witnessing the emergence of an AI economy and society where AI
technologies are increasingly impacting health care, business, transportation
and many aspects of everyday life. Many successes have been reported where AI
systems even surpassed the accuracy of human experts. However, AI systems may
produce errors, can exhibit bias, may be sensitive to noise in the data, and
often lack technical and judicial transparency resulting in reduction in trust
and challenges in their adoption. These recent shortcomings and concerns have
been documented in scientific but also in general press such as accidents with
self driving cars, biases in healthcare, hiring and face recognition systems
for people of color, seemingly correct medical decisions later found to be made
due to wrong reasons etc. This resulted in emergence of many government and
regulatory initiatives requiring trustworthy and ethical AI to provide accuracy
and robustness, some form of explainability, human control and oversight,
elimination of bias, judicial transparency and safety. The challenges in
delivery of trustworthy AI systems motivated intense research on explainable AI
systems (XAI). Aim of XAI is to provide human understandable information of how
AI systems make their decisions. In this paper we first briefly summarize
current XAI work and then challenge the recent arguments of accuracy vs.
explainability for being mutually exclusive and being focused only on deep
learning. We then present our recommendations for the use of XAI in full
lifecycle of high stakes trustworthy AI systems delivery, e.g. development,
validation and certification, and trustworthy production and maintenance.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊ≠£Ë¶ãË≠âËëó AI Á∂ìÊøüËàáÁ§æÊúÉÁöÑÂ¥õËµ∑ÔºåÂÖ∂‰∏≠ AI ÊäÄË°ìÊ≠£Êó•ÁõäÂΩ±ÈüøËëóÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÂïÜÊ•≠„ÄÅÈÅãËº∏‰ª•ÂèäÊó•Â∏∏ÁîüÊ¥ª‰∏≠ÁöÑË®±Â§öÊñπÈù¢„ÄÇË®±Â§öÊàêÂäüÊ°à‰æã‰∏≠ÔºåAI Á≥ªÁµ±ÁîöËá≥Ë∂ÖË∂ä‰∫Ü‰∫∫È°ûÂ∞àÂÆ∂ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÁÑ∂ËÄåÔºåAI Á≥ªÁµ±ÂèØËÉΩÊúÉÁî¢ÁîüÈåØË™§ÔºåÂèØËÉΩË°®ÁèæÂá∫ÂÅèË¶ãÔºåÂèØËÉΩÂ∞çË≥áÊñô‰∏≠ÁöÑÈõúË®äÊïèÊÑüÔºåËÄå‰∏îÂ∏∏Â∏∏Áº∫‰πèÊäÄË°ìÂíåÂè∏Ê≥ïÈÄèÊòéÂ∫¶ÔºåÂ∞éËá¥‰ø°‰ªªÂ∫¶‰∏ãÈôç‰ª•ÂèäÊé°Áî®‰∏äÁöÑÊåëÊà∞„ÄÇÈÄô‰∫õÊúÄËøëÁöÑÁº∫ÈªûÂíåÁñëÊÖÆÂ∑≤Âú®ÁßëÂ≠∏ÊúüÂàäÂíå‰∏ÄËà¨Â™íÈ´î‰∏≠ÂæóÂà∞Ë®òÈåÑÔºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõÊ±ΩËªä‰∫ãÊïÖ„ÄÅÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÅèË¶ã„ÄÅÊúâËâ≤‰∫∫Á®ÆÁöÑÊãõËÅòÂíå‰∫∫ËáâË≠òÂà•Á≥ªÁµ±„ÄÅÁúã‰ººÊ≠£Á¢∫ÁöÑÈÜ´ÁôÇÊ±∫Á≠ñÂæå‰æÜÁôºÁèæÊòØÂá∫ÊñºÈåØË™§ÁöÑÂéüÂõ†Á≠âÁ≠â„ÄÇÈÄôÂ∞éËá¥Ë®±Â§öÊîøÂ∫úÂíåÁõ£ÁÆ°ÂÄ°Ë≠∞ÁöÑÂá∫ÁèæÔºåË¶ÅÊ±ÇÂèØ‰ø°Ë≥¥‰∏îÂêà‰πéÈÅìÂæ∑ÁöÑ AI Êèê‰æõÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÅÊüêÁ®ÆÂΩ¢ÂºèÁöÑÂèØËß£ÈáãÊÄß„ÄÅ‰∫∫È°ûÊéßÂà∂ÂíåÁõ£Áù£„ÄÅÊ∂àÈô§ÂÅèË¶ã„ÄÅÂè∏Ê≥ïÈÄèÊòéÂ∫¶ÂíåÂÆâÂÖ®ÊÄß„ÄÇÊèê‰æõÂèØ‰ø°Ë≥¥ AI Á≥ªÁµ±ÁöÑÊåëÊà∞ÊøÄÂãµ‰∫ÜÂ∞çÂèØËß£Èáã AI Á≥ªÁµ± (XAI) ÁöÑÊ∑±ÂÖ•Á†îÁ©∂„ÄÇXAI ÁöÑÁõÆÊ®ôÊòØÊèê‰æõ‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË≥áË®äÔºåË™™Êòé AI Á≥ªÁµ±Â¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÁ∞°Ë¶ÅÁ∏ΩÁµêÁõÆÂâçÁöÑ XAI Â∑•‰ΩúÔºåÁÑ∂ÂæåÊåëÊà∞Ê∫ñÁ¢∫ÊÄßËàáÂèØËß£ÈáãÊÄßÁõ∏‰∫íÊéíÊñ•‰∏îÂÉÖÂ∞àÊ≥®ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑËøëÊúüË´ñÈªû„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫ÊàëÂÄëÁöÑÂª∫Ë≠∞ÔºåÂú®È´òÈ¢®Èö™ÂèØ‰ø°Ë≥¥ AI Á≥ªÁµ±‰∫§‰ªòÁöÑÂÆåÊï¥ÁîüÂëΩÈÄ±Êúü‰∏≠‰ΩøÁî® XAIÔºå‰æãÂ¶ÇÈñãÁôº„ÄÅÈ©óË≠âÂíåË™çË≠âÔºå‰ª•ÂèäÂèØ‰ø°Ë≥¥ÁöÑÁîüÁî¢ÂíåÁ∂≠Ë≠∑„ÄÇ</paragraph>

##### **SimpleMind adds thinking to deep neural networks**
2212.00951v1 by Youngwon Choi, M. Wasil Wahi-Anwar, Matthew S. Brown

Deep neural networks (DNNs) detect patterns in data and have shown
versatility and strong performance in many computer vision applications.
However, DNNs alone are susceptible to obvious mistakes that violate simple,
common sense concepts and are limited in their ability to use explicit
knowledge to guide their search and decision making. While overall DNN
performance metrics may be good, these obvious errors, coupled with a lack of
explainability, have prevented widespread adoption for crucial tasks such as
medical image analysis. The purpose of this paper is to introduce SimpleMind,
an open-source software framework for Cognitive AI focused on medical image
understanding. It allows creation of a knowledge base that describes expected
characteristics and relationships between image objects in an intuitive
human-readable form. The SimpleMind framework brings thinking to DNNs by: (1)
providing methods for reasoning with the knowledge base about image content,
such as spatial inferencing and conditional reasoning to check DNN outputs; (2)
applying process knowledge, in the form of general-purpose software agents,
that are chained together to accomplish image preprocessing, DNN prediction,
and result post-processing, and (3) performing automatic co-optimization of all
knowledge base parameters to adapt agents to specific problems. SimpleMind
enables reasoning on multiple detected objects to ensure consistency, providing
cross checking between DNN outputs. This machine reasoning improves the
reliability and trustworthiness of DNNs through an interpretable model and
explainable decisions. Example applications are provided that demonstrate how
SimpleMind supports and improves deep neural networks by embedding them within
a Cognitive AI framework.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Á•ûÁªèÁ∂≤Ë∑Ø (DNN) ÂèØÂÅµÊ∏¨Ë≥áÊñô‰∏≠ÁöÑÊ®°ÂºèÔºå‰∏¶Âú®Ë®±Â§öÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®‰∏≠Â±ïÁèæÂá∫Â§öÂäüËÉΩÊÄßËàáÂº∑Â§ßÊïàËÉΩ„ÄÇ
ÁÑ∂ËÄåÔºåDNN Êú¨Ë∫´ÂÆπÊòìÁäØ‰∏ãÈÅïÂèçÁ∞°ÂñÆÂ∏∏Ë≠òÊ¶ÇÂøµÁöÑÊòéÈ°ØÈåØË™§Ôºå‰∏îÂú®‰ΩøÁî®ÊòéÁ¢∫Áü•Ë≠ò‰æÜÂºïÂ∞éÂÖ∂ÊêúÂ∞ãËàáÊ±∫Á≠ñÂà∂ÂÆöÊôÇÊúâÂÖ∂ÈôêÂà∂„ÄÇÂÑòÁÆ°Êï¥È´î DNN ÊïàËÉΩÊåáÊ®ôÂèØËÉΩËâØÂ•ΩÔºå‰ΩÜÈÄô‰∫õÊòéÈ°ØÁöÑÈåØË™§ÔºåÂä†‰∏äÁº∫‰πèÂèØËß£ÈáãÊÄßÔºåÂ∑≤ÈòªÁ§ôÂÖ∂Âª£Ê≥õÊé°Áî®ÊñºË´∏Â¶ÇÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÁ≠âÈóúÈçµ‰ªªÂãô„ÄÇÊú¨ÊñáÁöÑÁõÆÁöÑÊòØ‰ªãÁ¥π SimpleMindÔºå‰∏ÄÂÄãÂ∞àÊ≥®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÁêÜËß£ÁöÑË™çÁü• AI ÈñãÊ∫êËªüÈ´îÊ°ÜÊû∂„ÄÇÂÆÉÂÖÅË®±Âª∫Á´ã‰∏ÄÂÄãÁü•Ë≠òÂ∫´Ôºå‰ª•Áõ¥ËßÄÁöÑ‰∫∫È°ûÂèØËÆÄÂΩ¢ÂºèÊèèËø∞ÂΩ±ÂÉèÁâ©‰ª∂‰πãÈñìÈ†êÊúüÁöÑÁâπÂæµÂíåÈóú‰øÇ„ÄÇSimpleMind Ê°ÜÊû∂ÈÄèÈÅé‰ª•‰∏ãÊñπÂºèÁÇ∫ DNN Â∏∂‰æÜÊÄùËÄÉËÉΩÂäõÔºö(1) Êèê‰æõÂü∫ÊñºÁü•Ë≠òÂ∫´Â∞çÂΩ±ÂÉèÂÖßÂÆπÈÄ≤Ë°åÊé®ÁêÜÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÁ©∫ÈñìÊé®Ë´ñÂíåÊ¢ù‰ª∂Êé®ÁêÜÔºå‰ª•Ê™¢Êü• DNN Ëº∏Âá∫Ôºõ(2) ‰ª•ÈÄöÁî®ËªüÈ´î‰ª£ÁêÜÁöÑÂΩ¢ÂºèÂ•óÁî®Á®ãÂ∫èÁü•Ë≠òÔºåÂ∞áÂÖ∂‰∏≤ÈÄ£Âú®‰∏ÄËµ∑‰ª•ÂÆåÊàêÂΩ±ÂÉèÂâçËôïÁêÜ„ÄÅDNN È†êÊ∏¨ÂíåÁµêÊûúÂæåËôïÁêÜÔºõ‰ª•Âèä (3) Â∞çÊâÄÊúâÁü•Ë≠òÂ∫´ÂèÉÊï∏Âü∑Ë°åËá™ÂãïÂÖ±ÂêåÊúÄ‰Ω≥ÂåñÔºå‰ª•ÈÅ©Êáâ‰ª£ÁêÜÂà∞ÁâπÂÆöÂïèÈ°å„ÄÇSimpleMind ËÉΩÂ∞çÂ§öÂÄãÂÅµÊ∏¨Âà∞ÁöÑÁâ©‰ª∂ÈÄ≤Ë°åÊé®ÁêÜ‰ª•Á¢∫‰øù‰∏ÄËá¥ÊÄßÔºå‰∏¶Êèê‰æõ DNN Ëº∏Âá∫‰πãÈñìÁöÑ‰∫§ÂèâÊ™¢Êü•„ÄÇÈÄôÁ®ÆÊ©üÂô®Êé®ÁêÜÈÄèÈÅé‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ®°ÂûãÂíåÂèØËß£ÈáãÁöÑÊ±∫Á≠ñÔºå‰æÜÊèêÂçá DNN ÁöÑÂèØÈù†ÊÄßÂíåÂèØ‰ø°Â∫¶„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÁØÑ‰æãÊáâÁî®ÔºåÂ±ïÁ§∫ SimpleMind Â¶Ç‰ΩïÈÄèÈÅéÂ∞áÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÂµåÂÖ•Ë™çÁü• AI Ê°ÜÊû∂‰∏≠Ôºå‰æÜÊîØÊè¥ÂíåÊîπÂñÑÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇ

##### **Attribution-based XAI Methods in Computer Vision: A Review**
2211.14736v1 by Kumar Abhishek, Deeksha Kamath

The advancements in deep learning-based methods for visual perception tasks
have seen astounding growth in the last decade, with widespread adoption in a
plethora of application areas from autonomous driving to clinical decision
support systems. Despite their impressive performance, these deep
learning-based models remain fairly opaque in their decision-making process,
making their deployment in human-critical tasks a risky endeavor. This in turn
makes understanding the decisions made by these models crucial for their
reliable deployment. Explainable AI (XAI) methods attempt to address this by
offering explanations for such black-box deep learning methods. In this paper,
we provide a comprehensive survey of attribution-based XAI methods in computer
vision and review the existing literature for gradient-based,
perturbation-based, and contrastive methods for XAI, and provide insights on
the key challenges in developing and evaluating robust XAI methods.

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÂçÅÂπ¥‰∏≠ÔºåÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁöÑË¶ñË¶∫ÊÑüÁü•‰ªªÂãôÂèñÂæó‰∫ÜÈ©ö‰∫∫ÁöÑÈÄ≤Â±ïÔºå‰∏¶Âª£Ê≥õÊáâÁî®ÊñºÂæûËá™ÂãïÈßïÈßõÂà∞Ëá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁöÑÁúæÂ§öÊáâÁî®È†òÂüü„ÄÇÂÑòÁÆ°ÈÄô‰∫õÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊ®°ÂûãÊïàËÉΩ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÔºå‰ΩÜÂÆÉÂÄëÂú®Ê±∫Á≠ñÈÅéÁ®ã‰∏≠‰ªçÁÑ∂Áõ∏Áï∂‰∏çÈÄèÊòéÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂú®‰∫∫È°ûÈóúÈçµ‰ªªÂãô‰∏≠ÁöÑÈÉ®ÁΩ≤ÊàêÁÇ∫‰∏ÄÈ†ÖÂÜíÈö™ÁöÑ‰∫ãÊ•≠„ÄÇÈÄôÂèçÈÅé‰æÜÂèà‰ΩøÂæóÁêÜËß£ÈÄô‰∫õÊ®°ÂûãÂÅöÂá∫ÁöÑÊ±∫Á≠ñÂ∞çÊñºÂÆÉÂÄëÁöÑÂèØÈù†ÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïË©¶ÂúñÈÄöÈÅéÁÇ∫ÈÄôÁ®ÆÈªëÁõíÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊèê‰æõËß£Èáã‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞çÈõªËÖ¶Ë¶ñË¶∫‰∏≠ÁöÑÂü∫ÊñºÊ≠∏Âõ†ÁöÑ XAI ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË™øÊü•Ôºå‰∏¶ÂõûÈ°ß‰∫ÜÁèæÊúâÈóúÊñºÂü∫ÊñºÊ¢ØÂ∫¶„ÄÅÂü∫ÊñºÊìæÂãïÂíåÂü∫ÊñºÂ∞çÊØîÁöÑ XAI ÊñπÊ≥ïÁöÑÊñáÁçªÔºå‰∏¶Â∞çÈñãÁôºÂíåË©ï‰º∞Á©©ÂÅ•ÁöÑ XAI ÊñπÊ≥ïÁöÑÈóúÈçµÊåëÊà∞Êèê‰æõ‰∫ÜË¶ãËß£„ÄÇ

##### **Privacy Meets Explainability: A Comprehensive Impact Benchmark**
2211.04110v1 by Saifullah Saifullah, Dominique Mercier, Adriano Lucieri, Andreas Dengel, Sheraz Ahmed

Since the mid-10s, the era of Deep Learning (DL) has continued to this day,
bringing forth new superlatives and innovations each year. Nevertheless, the
speed with which these innovations translate into real applications lags behind
this fast pace. Safety-critical applications, in particular, underlie strict
regulatory and ethical requirements which need to be taken care of and are
still active areas of debate. eXplainable AI (XAI) and privacy-preserving
machine learning (PPML) are both crucial research fields, aiming at mitigating
some of the drawbacks of prevailing data-hungry black-box models in DL. Despite
brisk research activity in the respective fields, no attention has yet been
paid to their interaction. This work is the first to investigate the impact of
private learning techniques on generated explanations for DL-based models. In
an extensive experimental analysis covering various image and time series
datasets from multiple domains, as well as varying privacy techniques, XAI
methods, and model architectures, the effects of private training on generated
explanations are studied. The findings suggest non-negligible changes in
explanations through the introduction of privacy. Apart from reporting
individual effects of PPML on XAI, the paper gives clear recommendations for
the choice of techniques in real applications. By unveiling the
interdependencies of these pivotal technologies, this work is a first step
towards overcoming the remaining hurdles for practically applicable AI in
safety-critical domains.

ÊëòË¶ÅÔºöËá™ 10 Âπ¥‰ª£‰∏≠Êúü‰ª•‰æÜÔºåÊ∑±Â∫¶Â≠∏Áøí (DL) ÁöÑÊôÇ‰ª£ÊåÅÁ∫åËá≥‰ªäÔºåÊØèÂπ¥ÈÉΩÊúÉÂ∏∂‰æÜÊñ∞ÁöÑÊúÄÂÑ™ÂÄºÂíåÂâµÊñ∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÂâµÊñ∞ËΩâÂåñÁÇ∫ÂØ¶ÈöõÊáâÁî®Á®ãÂºèÁöÑÈÄüÂ∫¶‰ªçËêΩÂæåÊñºÈÄôÁ®ÆÂø´ÈÄüÊ≠•‰ºê„ÄÇÁâπÂà•ÊòØÂÆâÂÖ®ÈóúÈçµÊáâÁî®Á®ãÂºèÔºåÂÖ∂Âü∫Á§éÊòØÂö¥Ê†ºÁöÑÊ≥ïË¶èÂíåÈÅìÂæ∑Ë¶ÅÊ±ÇÔºåÈúÄË¶ÅÂ¶•ÂñÑËôïÁêÜÔºå‰∏¶‰∏î‰ªçÁÑ∂ÊòØÁà≠Ë´ñÁöÑÈ†òÂüü„ÄÇÂèØËß£Èáã AI (XAI) ÂíåÈö±ÁßÅ‰øùË≠∑Ê©üÂô®Â≠∏Áøí (PPML) ÈÉΩÊòØËá≥ÈóúÈáçË¶ÅÁöÑÁ†îÁ©∂È†òÂüüÔºåÊó®Âú®Ê∏õËºï DL ‰∏≠ÊµÅË°åÁöÑË≥áÊñôÂØÜÈõÜÂûãÈªëÁõíÊ®°ÂûãÁöÑ‰∏Ä‰∫õÁº∫Èªû„ÄÇÂÑòÁÆ°Âú®ÂêÑËá™È†òÂüü‰∏≠ÈÄ≤Ë°å‰∫ÜÁÜ±ÁÉàÁöÑÁ†îÁ©∂Ê¥ªÂãïÔºå‰ΩÜÂ∞öÊú™ÈóúÊ≥®ÂÆÉÂÄëÁöÑ‰∫íÂãï„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊòØÁ¨¨‰∏ÄÂÄãÊé¢Ë®éÁßÅÊúâÂ≠∏ÁøíÊäÄË°ìÂ∞çÂü∫Êñº DL ÁöÑÊ®°ÂûãÁî¢ÁîüÁöÑËß£ÈáãÁöÑÂΩ±Èüø„ÄÇÂú®Ê∂µËìãÂ§öÂÄãÈ†òÂüüÁöÑÂêÑÁ®ÆÂΩ±ÂÉèÂíåÊôÇÈñìÂ∫èÂàóË≥áÊñôÈõÜ‰ª•Âèä‰∏çÂêåÁöÑÈö±ÁßÅÊäÄË°ì„ÄÅXAI ÊñπÊ≥ïÂíåÊ®°ÂûãÊû∂ÊßãÁöÑÂª£Ê≥õÂØ¶È©óÂàÜÊûê‰∏≠ÔºåÁ†îÁ©∂‰∫ÜÁßÅÊúâË®ìÁ∑¥Â∞çÁî¢ÁîüÁöÑËß£ÈáãÁöÑÂΩ±Èüø„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈÄèÈÅéÂºïÂÖ•Èö±ÁßÅÔºåËß£ÈáãÊúÉÁî¢Áîü‰∏çÂèØÂøΩË¶ñÁöÑËÆäÂåñ„ÄÇÈô§‰∫ÜÂ†±Âëä PPML Â∞ç XAI ÁöÑÂÄãÂà•ÂΩ±ÈüøÂ§ñÔºåÊú¨ÊñáÈÇÑÂ∞çÂØ¶ÈöõÊáâÁî®‰∏≠ÊäÄË°ìÁöÑÈÅ∏ÊìáÊèê‰æõ‰∫ÜÊòéÁ¢∫ÁöÑÂª∫Ë≠∞„ÄÇÈÄèÈÅéÊè≠Á§∫ÈÄô‰∫õÈóúÈçµÊäÄË°ìÁöÑÁõ∏‰∫í‰æùË≥¥ÊÄßÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊòØÂÖãÊúçÂÆâÂÖ®ÈóúÈçµÈ†òÂüü‰∏≠ÂØ¶ÈöõÂèØÊáâÁî® AI ÁöÑÂâ©È§òÈöúÁ§ôÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇ

##### **Predicting Treatment Adherence of Tuberculosis Patients at Scale**
2211.02943v2 by Mihir Kulkarni, Satvik Golechha, Rishi Raj, Jithin Sreedharan, Ankit Bhardwaj, Santanu Rathod, Bhavin Vadera, Jayakrishna Kurada, Sanjay Mattoo, Rajendra Joshi, Kirankumar Rade, Alpan Raval

Tuberculosis (TB), an infectious bacterial disease, is a significant cause of
death, especially in low-income countries, with an estimated ten million new
cases reported globally in $2020$. While TB is treatable, non-adherence to the
medication regimen is a significant cause of morbidity and mortality. Thus,
proactively identifying patients at risk of dropping off their medication
regimen enables corrective measures to mitigate adverse outcomes. Using a proxy
measure of extreme non-adherence and a dataset of nearly $700,000$ patients
from four states in India, we formulate and solve the machine learning (ML)
problem of early prediction of non-adherence based on a custom rank-based
metric. We train ML models and evaluate against baselines, achieving a $\sim
100\%$ lift over rule-based baselines and $\sim 214\%$ over a random
classifier, taking into account country-wide large-scale future deployment. We
deal with various issues in the process, including data quality,
high-cardinality categorical data, low target prevalence, distribution shift,
variation across cohorts, algorithmic fairness, and the need for robustness and
explainability. Our findings indicate that risk stratification of non-adherent
patients is a viable, deployable-at-scale ML solution. As the official AI
partner of India's Central TB Division, we are working on multiple city and
state-level pilots with the goal of pan-India deployment.

ÊëòË¶ÅÔºöËÇ∫ÁµêÊ†∏ÔºàTBÔºâÔºå‰∏ÄÁ®ÆÂÇ≥ÊüìÊÄßÁ¥∞ËèåÁñæÁóÖÔºåÊòØÈÄ†ÊàêÊ≠ª‰∫°ÁöÑÈáçË¶ÅÂéüÂõ†ÔºåÁâπÂà•ÊòØÂú®‰ΩéÊî∂ÂÖ•ÂúãÂÆ∂ÔºåÊìö‰º∞Ë®àÂú® 2020 Âπ¥ÂÖ®ÁêÉÈÄöÂ†±‰∫Ü‰∏ÄÂçÉËê¨‰æãÊñ∞ÁóÖ‰æã„ÄÇÈõñÁÑ∂ËÇ∫ÁµêÊ†∏ÊòØÂèØ‰ª•Ê≤ªÁôÇÁöÑÔºå‰ΩÜÊú™ÈÅµÂæ™Ëó•Áâ©Ê≤ªÁôÇË®àÁï´ÊòØÈÄ†ÊàêÁôºÁóÖÁéáÂíåÊ≠ª‰∫°ÁéáÁöÑÈáçË¶ÅÂéüÂõ†„ÄÇÂõ†Ê≠§Ôºå‰∏ªÂãïÊâæÂá∫Êúâ‰∏≠Êñ∑Ëó•Áâ©Ê≤ªÁôÇË®àÁï´È¢®Èö™ÁöÑÊÇ£ËÄÖÔºåËÉΩÊé°ÂèñÁüØÊ≠£Êé™ÊñΩ‰æÜÊ∏õËºï‰∏çËâØÂæåÊûú„ÄÇÂà©Áî®Ê•µÁ´ØÊú™ÈÅµÂæ™Ê≤ªÁôÇË®àÁï´ÁöÑ‰ª£ÁêÜË°°ÈáèÊåáÊ®ôÔºå‰ª•Âèä‰æÜËá™Âç∞Â∫¶ÂõõÂÄãÈÇ¶Ëøë 700,000 ÂêçÊÇ£ËÄÖÁöÑË≥áÊñôÈõÜÔºåÊàëÂÄëÂà∂ÂÆö‰∏¶Ëß£Ê±∫‰∫ÜÊ©üÂô®Â≠∏Áøí (ML) ÂïèÈ°åÔºåÊ†πÊìöËá™Ë®ÇÁöÑÂü∫ÊñºÊéíÂêçÊåáÊ®ôÔºåÊèêÊó©È†êÊ∏¨Êú™ÈÅµÂæ™Ê≤ªÁôÇË®àÁï´ÁöÑÊÉÖÊ≥Å„ÄÇÊàëÂÄëË®ìÁ∑¥Ê©üÂô®Â≠∏ÁøíÊ®°Âûã‰∏¶ÈáùÂ∞çÂü∫Ê∫ñÈÄ≤Ë°åË©ï‰º∞ÔºåÂú®ËÄÉÈáèÂÖ®ÂúãË¶èÊ®°ÁöÑÊú™‰æÜÈÉ®ÁΩ≤ÂæåÔºåÈÅîÂà∞‰∫ÜÊØîÂü∫ÊñºË¶èÂâáÁöÑÂü∫Ê∫ñÈ´òÂá∫Á¥Ñ 100%ÔºåÊØîÈö®Ê©üÂàÜÈ°ûÂô®È´òÂá∫Á¥Ñ 214% ÁöÑÊèêÂçá„ÄÇÊàëÂÄëÂú®ÈÅéÁ®ã‰∏≠ËôïÁêÜ‰∫ÜÂêÑÁ®ÆÂïèÈ°åÔºåÂåÖÊã¨Ë≥áÊñôÂìÅË≥™„ÄÅÈ´òÂü∫Êï∏ÂàÜÈ°ûË≥áÊñô„ÄÅ‰ΩéÁõÆÊ®ôÊµÅË°åÁéá„ÄÅÂàÜ‰ΩàËΩâÁßª„ÄÅ‰∏çÂêåÁæ§ÁµÑÈñìÁöÑÂ∑ÆÁï∞„ÄÅÊºîÁÆóÊ≥ïÂÖ¨Âπ≥ÊÄßÔºå‰ª•ÂèäÂ∞çÁ©©ÂÅ•ÊÄßÂíåÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈùûÈÅµÂæ™Ê≤ªÁôÇË®àÁï´ÊÇ£ËÄÖÁöÑÈ¢®Èö™ÂàÜÂ±§ÊòØ‰∏ÄÁ®ÆÂèØË°åÁöÑ„ÄÅÂèØÂ§ßË¶èÊ®°ÈÉ®ÁΩ≤ÁöÑÊ©üÂô®Â≠∏ÁøíËß£Ê±∫ÊñπÊ°à„ÄÇ‰ΩúÁÇ∫Âç∞Â∫¶‰∏≠Â§ÆËÇ∫ÁµêÊ†∏ÈÉ®ÈñÄÁöÑÂÆòÊñπ‰∫∫Â∑•Êô∫ÊÖßÂêà‰ΩúÂ§•‰º¥ÔºåÊàëÂÄëÊ≠£Âú®ËàáÂ§öÂÄãÂüéÂ∏ÇÂíåÈÇ¶Á¥öË©¶ÈªûÂêà‰ΩúÔºåÁõÆÊ®ôÊòØÂÖ®Âç∞Â∫¶ÈÉ®ÁΩ≤„ÄÇ

##### **Explainable AI over the Internet of Things (IoT): Overview, State-of-the-Art and Future Directions**
2211.01036v2 by Senthil Kumar Jagatheesaperumal, Quoc-Viet Pham, Rukhsana Ruby, Zhaohui Yang, Chunmei Xu, Zhaoyang Zhang

Explainable Artificial Intelligence (XAI) is transforming the field of
Artificial Intelligence (AI) by enhancing the trust of end-users in machines.
As the number of connected devices keeps on growing, the Internet of Things
(IoT) market needs to be trustworthy for the end-users. However, existing
literature still lacks a systematic and comprehensive survey work on the use of
XAI for IoT. To bridge this lacking, in this paper, we address the XAI
frameworks with a focus on their characteristics and support for IoT. We
illustrate the widely-used XAI services for IoT applications, such as security
enhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and
Internet of City Things (IoCT). We also suggest the implementation choice of
XAI models over IoT systems in these applications with appropriate examples and
summarize the key inferences for future works. Moreover, we present the
cutting-edge development in edge XAI structures and the support of
sixth-generation (6G) communication services for IoT applications, along with
key inferences. In a nutshell, this paper constitutes the first holistic
compilation on the development of XAI-based frameworks tailored for the demands
of future IoT use cases.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÈÄèÈÅéÊèêÂçáÁµÇÁ´Ø‰ΩøÁî®ËÄÖÂ∞çÊ©üÂô®‰ø°‰ªªÂ∫¶ÔºåËΩâËÆä‰∫Ü‰∫∫Â∑•Êô∫ÊÖß (AI) È†òÂüü„ÄÇÈö®ËëóÈÄ£Á∂≤Ë£ùÁΩÆÊï∏ÈáèÊåÅÁ∫åÂ¢ûÂä†ÔºåÁâ©ËÅØÁ∂≤ (IoT) Â∏ÇÂ†¥ÈúÄË¶ÅËÆìÁµÇÁ´Ø‰ΩøÁî®ËÄÖ‰ø°Ë≥¥„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñáÁçª‰ªçÁº∫‰πèÂ∞çÊñº XAI Áî®ÊñºÁâ©ËÅØÁ∂≤ÁöÑÁ≥ªÁµ±ÊÄß‰∏îÂÖ®Èù¢ÁöÑË™øÊü•Â∑•‰Ωú„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄã‰∏çË∂≥‰πãËôïÔºåÊàëÂÄëÂú®ÈÄôÁØáË´ñÊñá‰∏≠Êé¢Ë®é XAI Êû∂ÊßãÔºåÈáçÈªûÂú®ÊñºÂÖ∂ÁâπÊÄßÂíåÂ∞çÁâ©ËÅØÁ∂≤ÁöÑÊîØÊè¥„ÄÇÊàëÂÄëË™™ÊòéÂª£Ê≥õ‰ΩøÁî®ÁöÑ XAI ÊúçÂãôÔºåÁî®ÊñºÁâ©ËÅØÁ∂≤ÊáâÁî®Ôºå‰æãÂ¶ÇÂÆâÂÖ®ÊÄßÂº∑Âåñ„ÄÅÈÜ´ÁôÇÁâ©ËÅØÁ∂≤ (IoMT)„ÄÅÂ∑•Ê•≠Áâ©ËÅØÁ∂≤ (IIoT) ÂíåÂüéÂ∏ÇÁâ©ËÅØÁ∂≤ (IoCT)„ÄÇÊàëÂÄë‰πüÂª∫Ë≠∞Âú®ÈÄô‰∫õÊáâÁî®‰∏≠ÔºåÈÄèÈÅéÈÅ©Áï∂ÁöÑÁØÑ‰æãÂú®Áâ©ËÅØÁ∂≤Á≥ªÁµ±‰∏äÂØ¶‰Ωú XAI Ê®°ÂûãÁöÑÈÅ∏ÊìáÔºå‰∏¶Á∏ΩÁµêÊú™‰æÜÂ∑•‰ΩúÁöÑÈóúÈçµÊé®Ë´ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ÈÇäÁ∑£ XAI Êû∂ÊßãÁöÑÂ∞ñÁ´ØÁôºÂ±ïÔºå‰ª•ÂèäÂ∞çÁâ©ËÅØÁ∂≤ÊáâÁî®Á¨¨ÂÖ≠‰ª£ (6G) ÈÄöË®äÊúçÂãôÁöÑÊîØÊè¥ÔºåÈÄ£ÂêåÈóúÈçµÊé®Ë´ñ„ÄÇÁ∞°ËÄåË®Ä‰πãÔºåÈÄôÁØáË´ñÊñáÊßãÊàêÁ¨¨‰∏ÄÂÄãÈáùÂ∞ç XAI Âü∫Á§éÊû∂ÊßãÁôºÂ±ïÁöÑÊï¥È´îÂΩôÁ∑®ÔºåÂ∞àÈñÄÈáùÂ∞çÊú™‰æÜÁâ©ËÅØÁ∂≤‰ΩøÁî®Ê°à‰æãÁöÑÈúÄÊ±Ç„ÄÇ

##### **Human-centered XAI for Burn Depth Characterization**
2210.13535v2 by Maxwell J. Jacobson, Daniela Chanci Arrubla, Maria Romeo Tricas, Gayle Gordillo, Yexiang Xue, Chandan Sen, Juan Wachs

Approximately 1.25 million people in the United States are treated each year
for burn injuries. Precise burn injury classification is an important aspect of
the medical AI field. In this work, we propose an explainable human-in-the-loop
framework for improving burn ultrasound classification models. Our framework
leverages an explanation system based on the LIME classification explainer to
corroborate and integrate a burn expert's knowledge -- suggesting new features
and ensuring the validity of the model. Using this framework, we discover that
B-mode ultrasound classifiers can be enhanced by supplying textural features.
More specifically, we confirm that texture features based on the Gray Level
Co-occurance Matrix (GLCM) of ultrasound frames can increase the accuracy of
transfer learned burn depth classifiers. We test our hypothesis on real data
from porcine subjects. We show improvements in the accuracy of burn depth
classification -- from ~88% to ~94% -- once modified according to our
framework.

ÊëòË¶ÅÔºöÁæéÂúãÊØèÂπ¥Á¥ÑÊúâ 125 Ëê¨‰∫∫Êé•ÂèóÁáíÂÇ∑Ê≤ªÁôÇ„ÄÇÊ∫ñÁ¢∫ÁöÑÁáíÂÇ∑ÂàÜÈ°ûÊòØÈÜ´ÁôÇ AI È†òÂüüÁöÑÈáçË¶ÅÈù¢Âêë„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂèØËß£ÈáãÁöÑËø¥Âúà‰∏≠ÁöÑ‰∫∫È°ûÊ°ÜÊû∂ÔºåÁî®ÊñºÊîπÂñÑÁáíÂÇ∑Ë∂ÖÈü≥Ê≥¢ÂàÜÈ°ûÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Âà©Áî®Âü∫Êñº LIME ÂàÜÈ°ûËß£ÈáãÂô®ÁöÑËß£ÈáãÁ≥ªÁµ±Ôºå‰æÜÈ©óË≠âÂíåÊï¥ÂêàÁáíÂÇ∑Â∞àÂÆ∂ÁöÑÁü•Ë≠òÔºåÂª∫Ë≠∞Êñ∞ÁöÑÁâπÂæµ‰∏¶Á¢∫‰øùÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇ‰ΩøÁî®Ê≠§Ê°ÜÊû∂ÔºåÊàëÂÄëÁôºÁèæ B ÂûãË∂ÖÈü≥Ê≥¢ÂàÜÈ°ûÂô®ÂèØÈÄèÈÅéÊèê‰æõÁ¥ãÁêÜÁâπÂæµ‰æÜÂ¢ûÂº∑„ÄÇÊõ¥ÂÖ∑È´îÂú∞Ë™™ÔºåÊàëÂÄëÁ¢∫Ë™çÂü∫ÊñºË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑÁÅ∞ÈöéÂÖ±ÁîüÁü©Èô£ (GLCM) ÁöÑÁ¥ãÁêÜÁâπÂæµÔºåÂèØ‰ª•ÊèêÈ´òËΩâÁßªÂ≠∏ÁøíÁöÑÁáíÂÇ∑Ê∑±Â∫¶ÂàÜÈ°ûÂô®ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÂú®Ë±¨ÈöªÂèóË©¶ËÄÖÁöÑÁúüÂØ¶Ë≥áÊñô‰∏äÊ∏¨Ë©¶ÊàëÂÄëÁöÑÂÅáË®≠„ÄÇÊàëÂÄëÈ°ØÁ§∫Âá∫Âú®Ê†πÊìöÊàëÂÄëÁöÑÊ°ÜÊû∂‰øÆÊîπÂæåÔºåÁáíÂÇ∑Ê∑±Â∫¶ÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫ÊÄßÊúâÊâÄÊèêÂçáÔºåÂæûÁ¥Ñ 88% ÊèêÂçáËá≥Á¥Ñ 94%„ÄÇ

