{"2502.10385": {"publish_time": "2025-02-14", "title": "Simplifying DINO via Coding Rate Regularization", "paper_summary": "DINO and DINOv2 are two model families being widely used to learn\nrepresentations from unlabeled imagery data at large scales. Their learned\nrepresentations often enable state-of-the-art performance for downstream tasks,\nsuch as image classification and segmentation. However, they employ many\nempirically motivated design choices and their training pipelines are highly\ncomplex and unstable -- many hyperparameters need to be carefully tuned to\nensure that the representations do not collapse -- which poses considerable\ndifficulty to improving them or adapting them to new domains. In this work, we\nposit that we can remove most such-motivated idiosyncrasies in the pre-training\npipelines, and only need to add an explicit coding rate term in the loss\nfunction to avoid collapse of the representations. As a result, we obtain\nhighly simplified variants of the DINO and DINOv2 which we call SimDINO and\nSimDINOv2, respectively. Remarkably, these simplified models are more robust to\ndifferent design choices, such as network architecture and hyperparameters, and\nthey learn even higher-quality representations, measured by performance on\ndownstream tasks, offering a Pareto improvement over the corresponding DINO and\nDINOv2 models. This work highlights the potential of using simplifying design\nprinciples to improve the empirical practice of deep learning.", "paper_summary_zh": "DINO \u548c DINOv2 \u662f\u5169\u500b\u6a21\u578b\u7cfb\u5217\uff0c\u5b83\u5011\u88ab\u5ee3\u6cdb\u7528\u65bc\u5f9e\u5927\u578b\u672a\u6a19\u8a18\u5f71\u50cf\u8cc7\u6599\u4e2d\u5b78\u7fd2\u8868\u5fb5\u3002\u5b83\u5011\u5b78\u7fd2\u5230\u7684\u8868\u5fb5\u901a\u5e38\u80fd\u8b93\u4e0b\u6e38\u4efb\u52d9\uff08\u4f8b\u5982\u5f71\u50cf\u5206\u985e\u548c\u5206\u5272\uff09\u9054\u5230\u6700\u5148\u9032\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u5b83\u5011\u63a1\u7528\u8a31\u591a\u4ee5\u7d93\u9a57\u70ba\u4f9d\u64da\u7684\u8a2d\u8a08\u9078\u64c7\uff0c\u800c\u4e14\u5b83\u5011\u7684\u8a13\u7df4\u7ba1\u9053\u975e\u5e38\u8907\u96dc\u4e14\u4e0d\u7a69\u5b9a\uff0c\u9700\u8981\u4ed4\u7d30\u8abf\u6574\u8a31\u591a\u8d85\u53c3\u6578\uff0c\u4ee5\u78ba\u4fdd\u8868\u5fb5\u4e0d\u6703\u5d29\u6f70\uff0c\u9019\u5c0d\u6539\u5584\u5b83\u5011\u6216\u5c07\u5b83\u5011\u9069\u61c9\u5230\u65b0\u9818\u57df\u9020\u6210\u4e86\u76f8\u7576\u5927\u7684\u56f0\u96e3\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5047\u8a2d\u6211\u5011\u53ef\u4ee5\u5728\u9810\u8a13\u7df4\u7ba1\u9053\u4e2d\u79fb\u9664\u5927\u591a\u6578\u6b64\u985e\u52d5\u6a5f\u7279\u8cea\uff0c\u800c\u4e14\u53ea\u9700\u8981\u5728\u640d\u5931\u51fd\u6578\u4e2d\u52a0\u5165\u660e\u78ba\u7684\u7de8\u78bc\u7387\u9805\uff0c\u5c31\u80fd\u907f\u514d\u8868\u5fb5\u5d29\u6f70\u3002\u56e0\u6b64\uff0c\u6211\u5011\u7372\u5f97\u4e86 DINO \u548c DINOv2 \u7684\u9ad8\u5ea6\u7c21\u5316\u8b8a\u9ad4\uff0c\u6211\u5011\u5206\u5225\u7a31\u4e4b\u70ba SimDINO \u548c SimDINOv2\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u9019\u4e9b\u7c21\u5316\u7684\u6a21\u578b\u5c0d\u4e0d\u540c\u7684\u8a2d\u8a08\u9078\u64c7\uff08\u4f8b\u5982\u7db2\u8def\u67b6\u69cb\u548c\u8d85\u53c3\u6578\uff09\u66f4\u70ba\u7a69\u5065\uff0c\u800c\u4e14\u5b83\u5011\u5b78\u7fd2\u5230\u54c1\u8cea\u66f4\u9ad8\u7684\u8868\u5fb5\uff0c\u9019\u4ee5\u5728\u4e0b\u6e38\u4efb\u52d9\u4e2d\u7684\u6548\u80fd\u4f86\u8861\u91cf\uff0c\u5c0d\u61c9\u61c9\u7684 DINO \u548c DINOv2 \u6a21\u578b\u63d0\u4f9b\u4e86\u5e15\u96f7\u6258\u6539\u5584\u3002\u9019\u9805\u5de5\u4f5c\u7a81\u986f\u4e86\u4f7f\u7528\u7c21\u5316\u8a2d\u8a08\u539f\u5247\u4f86\u6539\u5584\u6df1\u5ea6\u5b78\u7fd2\u7684\u5be6\u52d9\u6f5b\u529b\u3002", "author": "Ziyang Wu et.al.", "authors": "Ziyang Wu, Jingyuan Zhang, Druv Pai, XuDong Wang, Chandan Singh, Jianwei Yang, Jianfeng Gao, Yi Ma", "id": "2502.10385v1", "paper_url": "http://arxiv.org/abs/2502.10385v1", "repo": "null"}}