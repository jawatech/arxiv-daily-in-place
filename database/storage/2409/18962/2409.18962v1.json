{"2409.18962": {"publish_time": "2024-09-27", "title": "Exploring Token Pruning in Vision State Space Models", "paper_summary": "State Space Models (SSMs) have the advantage of keeping linear computational\ncomplexity compared to attention modules in transformers, and have been applied\nto vision tasks as a new type of powerful vision foundation model. Inspired by\nthe observations that the final prediction in vision transformers (ViTs) is\nonly based on a subset of most informative tokens, we take the novel step of\nenhancing the efficiency of SSM-based vision models through token-based\npruning. However, direct applications of existing token pruning techniques\ndesigned for ViTs fail to deliver good performance, even with extensive\nfine-tuning. To address this issue, we revisit the unique computational\ncharacteristics of SSMs and discover that naive application disrupts the\nsequential token positions. This insight motivates us to design a novel and\ngeneral token pruning method specifically for SSM-based vision models. We first\nintroduce a pruning-aware hidden state alignment method to stabilize the\nneighborhood of remaining tokens for performance enhancement. Besides, based on\nour detailed analysis, we propose a token importance evaluation method adapted\nfor SSM models, to guide the token pruning. With efficient implementation and\npractical acceleration methods, our method brings actual speedup. Extensive\nexperiments demonstrate that our approach can achieve significant computation\nreduction with minimal impact on performance across different tasks. Notably,\nwe achieve 81.7\\% accuracy on ImageNet with a 41.6\\% reduction in the FLOPs for\npruned PlainMamba-L3. Furthermore, our work provides deeper insights into\nunderstanding the behavior of SSM-based vision models for future research.", "paper_summary_zh": "\u72c0\u614b\u7a7a\u9593\u6a21\u578b (SSM) \u7684\u512a\u9ede\u5728\u65bc\u8207Transformer\u4e2d\u7684\u6ce8\u610f\u529b\u6a21\u7d44\u76f8\u6bd4\uff0c\u5b83\u80fd\u4fdd\u6301\u7dda\u6027\u904b\u7b97\u8907\u96dc\u5ea6\uff0c\u4e14\u5df2\u61c9\u7528\u65bc\u8996\u89ba\u4efb\u52d9\u4f5c\u70ba\u4e00\u7a2e\u65b0\u578b\u5f37\u5927\u7684\u8996\u89ba\u57fa\u790e\u6a21\u578b\u3002\u53d7\u5230\u8996\u89baTransformer (ViT) \u4e2d\u7684\u6700\u7d42\u9810\u6e2c\u50c5\u57fa\u65bc\u6700\u6709\u8cc7\u8a0a\u7684\u4ee3\u5e63\u5b50\u96c6\u7684\u89c0\u5bdf\u555f\u767c\uff0c\u6211\u5011\u63a1\u53d6\u5275\u65b0\u7684\u6b65\u9a5f\uff0c\u900f\u904e\u57fa\u65bc\u4ee3\u5e63\u7684\u526a\u679d\u4f86\u63d0\u5347\u57fa\u65bc SSM \u7684\u8996\u89ba\u6a21\u578b\u7684\u6548\u7387\u3002\u7136\u800c\uff0c\u5373\u4f7f\u7d93\u904e\u5ee3\u6cdb\u7684\u5fae\u8abf\uff0c\u76f4\u63a5\u61c9\u7528\u70ba ViT \u8a2d\u8a08\u7684\u73fe\u6709\u4ee3\u5e63\u526a\u679d\u6280\u8853\u4e5f\u7121\u6cd5\u63d0\u4f9b\u826f\u597d\u7684\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u91cd\u65b0\u6aa2\u8996 SSM \u7684\u7368\u7279\u904b\u7b97\u7279\u6027\uff0c\u4e26\u767c\u73fe\u5929\u771f\u7684\u61c9\u7528\u6703\u4e2d\u65b7\u9806\u5e8f\u4ee3\u5e63\u4f4d\u7f6e\u3002\u9019\u500b\u898b\u89e3\u6fc0\u52f5\u6211\u5011\u5c08\u9580\u70ba\u57fa\u65bc SSM \u7684\u8996\u89ba\u6a21\u578b\u8a2d\u8a08\u4e00\u7a2e\u65b0\u7a4e\u4e14\u901a\u7528\u7684\u4ee3\u5e63\u526a\u679d\u65b9\u6cd5\u3002\u6211\u5011\u9996\u5148\u5f15\u5165\u4e00\u7a2e\u4fee\u526a\u611f\u77e5\u7684\u96b1\u85cf\u72c0\u614b\u5c0d\u9f4a\u65b9\u6cd5\uff0c\u4ee5\u7a69\u5b9a\u5269\u9918\u4ee3\u5e63\u7684\u9130\u57df\uff0c\u9032\u800c\u63d0\u5347\u6548\u80fd\u3002\u6b64\u5916\uff0c\u6839\u64da\u6211\u5011\u7684\u8a73\u7d30\u5206\u6790\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u9069\u7528\u65bc SSM \u6a21\u578b\u7684\u4ee3\u5e63\u91cd\u8981\u6027\u8a55\u4f30\u65b9\u6cd5\uff0c\u4ee5\u6307\u5c0e\u4ee3\u5e63\u526a\u679d\u3002\u900f\u904e\u6709\u6548\u7387\u7684\u5be6\u4f5c\u548c\u5be6\u7528\u7684\u52a0\u901f\u65b9\u6cd5\uff0c\u6211\u5011\u7684\u6280\u8853\u5e36\u4f86\u4e86\u5be6\u969b\u7684\u52a0\u901f\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u6211\u5011\u7684\u4f5c\u6cd5\u53ef\u4ee5\u5728\u4e0d\u540c\u7684\u4efb\u52d9\u4e2d\u5be6\u73fe\u986f\u8457\u7684\u904b\u7b97\u6e1b\u5c11\uff0c\u540c\u6642\u5c0d\u6548\u80fd\u7684\u5f71\u97ff\u5f88\u5c0f\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u5728 ImageNet \u4e0a\u5be6\u73fe\u4e86 81.7% \u7684\u6e96\u78ba\u5ea6\uff0c\u4fee\u526a\u5f8c\u7684 PlainMamba-L3 \u7684 FLOP \u6e1b\u5c11\u4e86 41.6%\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u898b\u89e3\uff0c\u4ee5\u4e86\u89e3\u57fa\u65bc SSM \u7684\u8996\u89ba\u6a21\u578b\u7684\u884c\u70ba\uff0c\u4f9b\u672a\u4f86\u7684\u7814\u7a76\u53c3\u8003\u3002", "author": "Zheng Zhan et.al.", "authors": "Zheng Zhan, Zhenglun Kong, Yifan Gong, Yushu Wu, Zichong Meng, Hangyu Zheng, Xuan Shen, Stratis Ioannidis, Wei Niu, Pu Zhao, Yanzhi Wang", "id": "2409.18962v1", "paper_url": "http://arxiv.org/abs/2409.18962v1", "repo": "null"}}