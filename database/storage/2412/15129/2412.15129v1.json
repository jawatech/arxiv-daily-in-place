{"2412.15129": {"publish_time": "2024-12-19", "title": "Jet: A Modern Transformer-Based Normalizing Flow", "paper_summary": "In the past, normalizing generative flows have emerged as a promising class\nof generative models for natural images. This type of model has many modeling\nadvantages: the ability to efficiently compute log-likelihood of the input\ndata, fast generation and simple overall structure. Normalizing flows remained\na topic of active research but later fell out of favor, as visual quality of\nthe samples was not competitive with other model classes, such as GANs,\nVQ-VAE-based approaches or diffusion models. In this paper we revisit the\ndesign of the coupling-based normalizing flow models by carefully ablating\nprior design choices and using computational blocks based on the Vision\nTransformer architecture, not convolutional neural networks. As a result, we\nachieve state-of-the-art quantitative and qualitative performance with a much\nsimpler architecture. While the overall visual quality is still behind the\ncurrent state-of-the-art models, we argue that strong normalizing flow models\ncan help advancing research frontier by serving as building components of more\npowerful generative models.", "paper_summary_zh": "\u5728\u904e\u53bb\uff0c\u6b63\u898f\u5316\u751f\u6210\u6d41\u5df2\u6210\u70ba\u81ea\u7136\u5716\u50cf\u751f\u6210\u6a21\u578b\u4e2d\u4e00\u500b\u5f88\u6709\u524d\u666f\u7684\u985e\u5225\u3002\u9019\u7a2e\u985e\u578b\u7684\u6a21\u578b\u6709\u8a31\u591a\u5efa\u6a21\u512a\u52e2\uff1a\u6709\u6548\u8a08\u7b97\u8f38\u5165\u8cc7\u6599\u7684\u5c0d\u6578\u4f3c\u7136\u3001\u5feb\u901f\u751f\u6210\u548c\u7c21\u55ae\u7684\u6574\u9ad4\u7d50\u69cb\u3002\u6b63\u898f\u5316\u6d41\u4ecd\u7136\u662f\u7a4d\u6975\u7814\u7a76\u7684\u4e3b\u984c\uff0c\u4f46\u5f8c\u4f86\u4e0d\u53d7\u9752\u775e\uff0c\u56e0\u70ba\u6a23\u672c\u7684\u8996\u89ba\u54c1\u8cea\u7121\u6cd5\u8207\u5176\u4ed6\u6a21\u578b\u985e\u5225\u7af6\u722d\uff0c\u4f8b\u5982 GAN\u3001\u57fa\u65bc VQ-VAE \u7684\u65b9\u6cd5\u6216\u64f4\u6563\u6a21\u578b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u91cd\u65b0\u6aa2\u8996\u57fa\u65bc\u8026\u5408\u7684\u6b63\u898f\u5316\u6d41\u6a21\u578b\u7684\u8a2d\u8a08\uff0c\u900f\u904e\u4ed4\u7d30\u6d88\u878d\u5148\u524d\u7684\u8a2d\u8a08\u9078\u64c7\uff0c\u4e26\u4f7f\u7528\u57fa\u65bc Vision Transformer \u67b6\u69cb\uff08\u800c\u975e\u5377\u7a4d\u795e\u7d93\u7db2\u8def\uff09\u7684\u8a08\u7b97\u5340\u584a\u3002\u56e0\u6b64\uff0c\u6211\u5011\u4ee5\u66f4\u7c21\u55ae\u7684\u67b6\u69cb\u5be6\u73fe\u4e86\u6700\u5148\u9032\u7684\u91cf\u5316\u548c\u8cea\u5316\u6548\u80fd\u3002\u96d6\u7136\u6574\u9ad4\u8996\u89ba\u54c1\u8cea\u4ecd\u843d\u5f8c\u65bc\u76ee\u524d\u7684\u6700\u65b0\u6a21\u578b\uff0c\u4f46\u6211\u5011\u8a8d\u70ba\u5f37\u5927\u7684\u6b63\u898f\u5316\u6d41\u6a21\u578b\u53ef\u4ee5\u900f\u904e\u4f5c\u70ba\u66f4\u5f37\u5927\u751f\u6210\u6a21\u578b\u7684\u5efa\u69cb\u5143\u4ef6\uff0c\u4f86\u5e6b\u52a9\u63a8\u9032\u7814\u7a76\u524d\u6cbf\u3002", "author": "Alexander Kolesnikov et.al.", "authors": "Alexander Kolesnikov, Andr\u00e9 Susano Pinto, Michael Tschannen", "id": "2412.15129v1", "paper_url": "http://arxiv.org/abs/2412.15129v1", "repo": "null"}}