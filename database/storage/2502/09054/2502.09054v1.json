{"2502.09054": {"publish_time": "2025-02-13", "title": "Cost-Saving LLM Cascades with Early Abstention", "paper_summary": "LLM cascades are based on the idea that processing all queries with the\nlargest and most expensive LLMs is inefficient. Instead, cascades deploy small\nLLMs to answer the majority of queries, limiting the use of large and expensive\nLLMs to only the most difficult queries. This approach can significantly reduce\ncosts without impacting performance. However, risk-sensitive domains such as\nfinance or medicine place an additional premium on avoiding model errors.\nRecognizing that even the most expensive models may make mistakes, applications\nin these domains benefit from allowing LLM systems to completely abstain from\nanswering a query when the chance of making a mistake is significant. However,\ngiving a cascade the ability to abstain poses an immediate design question for\nLLM cascades: should abstention only be allowed at the final model or also at\nearlier models? Since the error patterns of small and large models are\ncorrelated, the latter strategy may further reduce inference costs by letting\ninexpensive models anticipate abstention decisions by expensive models, thereby\nobviating the need to run the expensive models. We investigate the benefits of\n\"early abstention\" in LLM cascades and find that it reduces the overall test\nloss by 2.2% on average across six benchmarks (GSM8K, MedMCQA, MMLU, TriviaQA,\nTruthfulQA, and XSum). These gains result from a more effective use of\nabstention, which trades a 4.1% average increase in the overall abstention rate\nfor a 13.0% reduction in cost and a 5.0% reduction in error rate. Our findings\ndemonstrate that it is possible to leverage correlations between the error\npatterns of different language models to drive performance improvements for LLM\nsystems with abstention.", "paper_summary_zh": "<paragraph>LLM \u7d1a\u806f\u57fa\u65bc\u4ee5\u4e0b\u6982\u5ff5\uff1a\u4f7f\u7528\u6700\u5927\u4e14\u6700\u6602\u8cb4\u7684 LLM \u8655\u7406\u6240\u6709\u67e5\u8a62\u6548\u7387\u4f4e\u4e0b\u3002\u76f8\u53cd\uff0c\u7d1a\u806f\u6703\u90e8\u7f72\u5c0f\u578b LLM \u4f86\u56de\u7b54\u5927\u90e8\u5206\u67e5\u8a62\uff0c\u5c07\u5927\u578b\u4e14\u6602\u8cb4\u7684 LLM \u7684\u4f7f\u7528\u9650\u5236\u5728\u6700\u56f0\u96e3\u7684\u67e5\u8a62\u4e0a\u3002\u9019\u7a2e\u65b9\u6cd5\u53ef\u4ee5\u5927\u5e45\u964d\u4f4e\u6210\u672c\uff0c\u800c\u4e0d\u6703\u5f71\u97ff\u6548\u80fd\u3002\u7136\u800c\uff0c\u50cf\u91d1\u878d\u6216\u91ab\u5b78\u7b49\u5c0d\u98a8\u96aa\u654f\u611f\u7684\u9818\u57df\u6703\u984d\u5916\u91cd\u8996\u907f\u514d\u6a21\u578b\u932f\u8aa4\u3002\u8a8d\u8b58\u5230\u5373\u4f7f\u662f\u6700\u6602\u8cb4\u7684\u6a21\u578b\u4e5f\u53ef\u80fd\u6703\u51fa\u932f\uff0c\u5728\u9019\u4e9b\u9818\u57df\u4e2d\u7684\u61c9\u7528\u7a0b\u5f0f\u53ef\u53d7\u76ca\u65bc\u5141\u8a31 LLM \u7cfb\u7d71\u5728\u51fa\u932f\u6a5f\u7387\u5f88\u5927\u7684\u60c5\u6cc1\u4e0b\u5b8c\u5168\u4e0d\u56de\u7b54\u67e5\u8a62\u3002\u7136\u800c\uff0c\u8ce6\u4e88\u7d1a\u806f\u4e0d\u56de\u7b54\u7684\u80fd\u529b\u6703\u5c0d LLM \u7d1a\u806f\u63d0\u51fa\u7acb\u5373\u7684\u8a2d\u8a08\u554f\u984c\uff1a\u662f\u5426\u53ea\u5141\u8a31\u5728\u6700\u7d42\u6a21\u578b\u4e2d\u4e0d\u56de\u7b54\uff0c\u9084\u662f\u4e5f\u5728\u8f03\u65e9\u7684\u6a21\u578b\u4e2d\u4e0d\u56de\u7b54\uff1f\u7531\u65bc\u5c0f\u578b\u548c\u5927\u578b\u6a21\u578b\u7684\u932f\u8aa4\u6a21\u5f0f\u76f8\u95dc\uff0c\u5f8c\u4e00\u7a2e\u7b56\u7565\u53ef\u4ee5\u8b93\u4fbf\u5b9c\u7684\u6a21\u578b\u9810\u6e2c\u6602\u8cb4\u6a21\u578b\u7684\u4e0d\u56de\u7b54\u6c7a\u7b56\uff0c\u9032\u800c\u964d\u4f4e\u63a8\u8ad6\u6210\u672c\uff0c\u5f9e\u800c\u907f\u514d\u57f7\u884c\u6602\u8cb4\u7684\u6a21\u578b\u3002\u6211\u5011\u8abf\u67e5\u4e86 LLM \u7d1a\u806f\u4e2d\u300c\u65e9\u671f\u4e0d\u56de\u7b54\u300d\u7684\u597d\u8655\uff0c\u4e26\u767c\u73fe\u5b83\u5e73\u5747\u964d\u4f4e\u4e86\u516d\u500b\u57fa\u6e96\u6e2c\u8a66\uff08GSM8K\u3001MedMCQA\u3001MMLU\u3001TriviaQA\u3001TruthfulQA \u548c XSum\uff09\u7684\u6574\u9ad4\u6e2c\u8a66\u640d\u5931 2.2%\u3002\u9019\u4e9b\u6536\u76ca\u4f86\u81ea\u65bc\u66f4\u6709\u6548\u5730\u4f7f\u7528\u4e0d\u56de\u7b54\uff0c\u4ee5\u6574\u9ad4\u4e0d\u56de\u7b54\u7387\u5e73\u5747\u589e\u52a0 4.1% \u7684\u4ee3\u50f9\u63db\u53d6\u6210\u672c\u964d\u4f4e 13.0% \u548c\u932f\u8aa4\u7387\u964d\u4f4e 5.0%\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8b49\u660e\uff0c\u53ef\u4ee5\u5229\u7528\u4e0d\u540c\u8a9e\u8a00\u6a21\u578b\u7684\u932f\u8aa4\u6a21\u5f0f\u4e4b\u9593\u7684\u95dc\u806f\u6027\uff0c\u4f86\u63a8\u52d5\u5177\u6709\u4e0d\u56de\u7b54\u529f\u80fd\u7684 LLM \u7cfb\u7d71\u7684\u6548\u80fd\u6539\u9032\u3002</paragraph>", "author": "Michael J. Zellinger et.al.", "authors": "Michael J. Zellinger, Rex Liu, Matt Thomson", "id": "2502.09054v1", "paper_url": "http://arxiv.org/abs/2502.09054v1", "repo": "null"}}