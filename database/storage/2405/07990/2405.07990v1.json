{"2405.07990": {"publish_time": "2024-05-13", "title": "Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots", "paper_summary": "The remarkable progress of Multi-modal Large Language Models (MLLMs) has\nattracted significant attention due to their superior performance in visual\ncontexts. However, their capabilities in turning visual figure to executable\ncode, have not been evaluated thoroughly. To address this, we introduce\nPlot2Code, a comprehensive visual coding benchmark designed for a fair and\nin-depth assessment of MLLMs. We carefully collect 132 manually selected\nhigh-quality matplotlib plots across six plot types from publicly available\nmatplotlib galleries. For each plot, we carefully offer its source code, and an\ndescriptive instruction summarized by GPT-4. This approach enables Plot2Code to\nextensively evaluate MLLMs' code capabilities across various input modalities.\nFurthermore, we propose three automatic evaluation metrics, including code pass\nrate, text-match ratio, and GPT-4V overall rating, for a fine-grained\nassessment of the output code and rendered images. Instead of simply judging\npass or fail, we employ GPT-4V to make an overall judgement between the\ngenerated and reference images, which has been shown to be consistent with\nhuman evaluation. The evaluation results, which include analyses of 14 MLLMs\nsuch as the proprietary GPT-4V, Gemini-Pro, and the open-sourced Mini-Gemini,\nhighlight the substantial challenges presented by Plot2Code. With Plot2Code, we\nreveal that most existing MLLMs struggle with visual coding for text-dense\nplots, heavily relying on textual instruction. We hope that the evaluation\nresults from Plot2Code on visual coding will guide the future development of\nMLLMs. All data involved with Plot2Code are available at\nhttps://huggingface.co/datasets/TencentARC/Plot2Code.", "paper_summary_zh": "\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u986f\u8457\u9032\u6b65\uff0c\u7531\u65bc\u5176\u5728\u8996\u89ba\u8a9e\u5883\u4e2d\u7684\u5353\u8d8a\u8868\u73fe\uff0c\u5f15\u8d77\u4e86\u5ee3\u6cdb\u95dc\u6ce8\u3002\u7136\u800c\uff0c\u5b83\u5011\u5c07\u8996\u89ba\u5716\u5f62\u8f49\u63db\u70ba\u53ef\u57f7\u884c\u7a0b\u5f0f\u78bc\u7684\u80fd\u529b\uff0c\u5c1a\u672a\u5f97\u5230\u5fb9\u5e95\u8a55\u4f30\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 Plot2Code\uff0c\u4e00\u500b\u5168\u9762\u7684\u8996\u89ba\u7de8\u78bc\u57fa\u6e96\uff0c\u65e8\u5728\u5c0d MLLM \u9032\u884c\u516c\u5e73\u548c\u6df1\u5165\u7684\u8a55\u4f30\u3002\u6211\u5011\u4ed4\u7d30\u6536\u96c6\u4e86 132 \u500b\u624b\u52d5\u6311\u9078\u7684\u9ad8\u54c1\u8cea matplotlib \u5716\u5f62\uff0c\u6db5\u84cb\u4f86\u81ea\u516c\u958b matplotlib \u5eab\u7684\u516d\u7a2e\u5716\u5f62\u985e\u578b\u3002\u5c0d\u65bc\u6bcf\u500b\u5716\u5f62\uff0c\u6211\u5011\u4ed4\u7d30\u63d0\u4f9b\u4e86\u5176\u539f\u59cb\u7a0b\u5f0f\u78bc\uff0c\u4ee5\u53ca\u7531 GPT-4 \u7e3d\u7d50\u7684\u63cf\u8ff0\u6027\u8aaa\u660e\u3002\u9019\u7a2e\u65b9\u6cd5\u4f7f Plot2Code \u80fd\u5920\u5ee3\u6cdb\u8a55\u4f30 MLLM \u7684\u7a0b\u5f0f\u78bc\u80fd\u529b\uff0c\u6db5\u84cb\u5404\u7a2e\u8f38\u5165\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e09\u7a2e\u81ea\u52d5\u8a55\u4f30\u6307\u6a19\uff0c\u5305\u62ec\u7a0b\u5f0f\u78bc\u901a\u904e\u7387\u3001\u6587\u5b57\u5339\u914d\u7387\u548c GPT-4V \u6574\u9ad4\u8a55\u5206\uff0c\u7528\u65bc\u5c0d\u8f38\u51fa\u7a0b\u5f0f\u78bc\u548c\u6e32\u67d3\u5716\u50cf\u9032\u884c\u7d30\u7c92\u5ea6\u7684\u8a55\u4f30\u3002\u6211\u5011\u6c92\u6709\u7c21\u55ae\u5730\u5224\u65b7\u901a\u904e\u6216\u5931\u6557\uff0c\u800c\u662f\u63a1\u7528 GPT-4V \u5c0d\u751f\u6210\u7684\u5716\u50cf\u548c\u53c3\u8003\u5716\u50cf\u9032\u884c\u6574\u9ad4\u5224\u65b7\uff0c\u9019\u5df2\u88ab\u8b49\u660e\u8207\u4eba\u985e\u8a55\u4f30\u4e00\u81f4\u3002\u8a55\u4f30\u7d50\u679c\u5305\u62ec\u5c0d 14 \u500b MLLM\uff08\u4f8b\u5982\u5c08\u6709\u7684 GPT-4V\u3001Gemini-Pro \u548c\u958b\u6e90\u7684 Mini-Gemini\uff09\u7684\u5206\u6790\uff0c\u7a81\u51fa\u4e86 Plot2Code \u5e36\u4f86\u7684\u91cd\u5927\u6311\u6230\u3002\u901a\u904e Plot2Code\uff0c\u6211\u5011\u767c\u73fe\u5927\u591a\u6578\u73fe\u6709\u7684 MLLM \u5728\u8655\u7406\u6587\u5b57\u5bc6\u96c6\u578b\u5716\u5f62\u7684\u8996\u89ba\u7de8\u78bc\u6642\u90fd\u5b58\u5728\u56f0\u96e3\uff0c\u56b4\u91cd\u4f9d\u8cf4\u65bc\u6587\u5b57\u8aaa\u660e\u3002\u6211\u5011\u5e0c\u671b Plot2Code \u5728\u8996\u89ba\u7de8\u78bc\u4e0a\u7684\u8a55\u4f30\u7d50\u679c\uff0c\u5c07\u6307\u5c0e MLLM \u672a\u4f86\u7684\u767c\u5c55\u3002Plot2Code \u6d89\u53ca\u7684\u6240\u6709\u8cc7\u6599\u90fd\u53ef\u4ee5\u5728 https://huggingface.co/datasets/TencentARC/Plot2Code \u53d6\u5f97\u3002", "author": "Chengyue Wu et.al.", "authors": "Chengyue Wu, Yixiao Ge, Qiushan Guo, Jiahao Wang, Zhixuan Liang, Zeyu Lu, Ying Shan, Ping Luo", "id": "2405.07990v1", "paper_url": "http://arxiv.org/abs/2405.07990v1", "repo": "null"}}