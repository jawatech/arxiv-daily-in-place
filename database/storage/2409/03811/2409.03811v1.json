{"2409.03811": {"publish_time": "2024-09-05", "title": "PARCO: Learning Parallel Autoregressive Policies for Efficient Multi-Agent Combinatorial Optimization", "paper_summary": "Multi-agent combinatorial optimization problems such as routing and\nscheduling have great practical relevance but present challenges due to their\nNP-hard combinatorial nature, hard constraints on the number of possible\nagents, and hard-to-optimize objective functions. This paper introduces PARCO\n(Parallel AutoRegressive Combinatorial Optimization), a novel approach that\nlearns fast surrogate solvers for multi-agent combinatorial problems with\nreinforcement learning by employing parallel autoregressive decoding. We\npropose a model with a Multiple Pointer Mechanism to efficiently decode\nmultiple decisions simultaneously by different agents, enhanced by a\nPriority-based Conflict Handling scheme. Moreover, we design specialized\nCommunication Layers that enable effective agent collaboration, thus enriching\ndecision-making. We evaluate PARCO in representative multi-agent combinatorial\nproblems in routing and scheduling and demonstrate that our learned solvers\noffer competitive results against both classical and neural baselines in terms\nof both solution quality and speed. We make our code openly available at\nhttps://github.com/ai4co/parco.", "paper_summary_zh": "\u591a\u4ee3\u7406\u7d44\u5408\u512a\u5316\u554f\u984c\uff0c\u5982\u8def\u7531\u548c\u6392\u7a0b\uff0c\u5177\u6709\u6975\u5927\u7684\u5be6\u7528\u6027\uff0c\u4f46\u7531\u65bc\u5176 NP \u96e3\u7d44\u5408\u6027\u8cea\u3001\u4ee3\u7406\u6578\u91cf\u4e0a\u7684\u786c\u7d04\u675f\u548c\u96e3\u4ee5\u6700\u4f73\u5316\u7684\u76ee\u6a19\u51fd\u6578\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u6311\u6230\u3002\u672c\u6587\u4ecb\u7d39\u4e86 PARCO\uff08\u4e26\u884c\u81ea\u56de\u6b78\u7d44\u5408\u512a\u5316\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u5b83\u901a\u904e\u63a1\u7528\u4e26\u884c\u81ea\u56de\u6b78\u89e3\u78bc\uff0c\u5b78\u7fd2\u591a\u4ee3\u7406\u7d44\u5408\u554f\u984c\u7684\u5feb\u901f\u4ee3\u7406\u6c42\u89e3\u5668\uff0c\u4e26\u9032\u884c\u5f37\u5316\u5b78\u7fd2\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5177\u6709\u591a\u6307\u6a19\u6a5f\u5236\u7684\u6a21\u578b\uff0c\u4ee5\u901a\u904e\u4e0d\u540c\u7684\u4ee3\u7406\u540c\u6642\u6709\u6548\u5730\u89e3\u78bc\u591a\u500b\u6c7a\u7b56\uff0c\u4e26\u901a\u904e\u57fa\u65bc\u512a\u5148\u7d1a\u7684\u885d\u7a81\u8655\u7406\u65b9\u6848\u9032\u884c\u589e\u5f37\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u5c08\u9580\u7684\u901a\u4fe1\u5c64\uff0c\u4ee5\u5be6\u73fe\u6709\u6548\u7684\u4ee3\u7406\u5354\u4f5c\uff0c\u5f9e\u800c\u8c50\u5bcc\u6c7a\u7b56\u5236\u5b9a\u3002\u6211\u5011\u5728\u8def\u7531\u548c\u6392\u7a0b\u4e2d\u7684\u4ee3\u8868\u6027\u591a\u4ee3\u7406\u7d44\u5408\u554f\u984c\u4e2d\u8a55\u4f30\u4e86 PARCO\uff0c\u4e26\u8b49\u660e\u6211\u5011\u7684\u5b78\u7fd2\u6c42\u89e3\u5668\u5728\u89e3\u6c7a\u65b9\u6848\u8cea\u91cf\u548c\u901f\u5ea6\u65b9\u9762\u90fd\u63d0\u4f9b\u4e86\u8207\u7d93\u5178\u548c\u795e\u7d93\u57fa\u7dda\u76f8\u6bd4\u5177\u6709\u7af6\u722d\u529b\u7684\u7d50\u679c\u3002\u6211\u5011\u5728 https://github.com/ai4co/parco \u4e0a\u516c\u958b\u4e86\u6211\u5011\u7684\u4ee3\u78bc\u3002", "author": "Federico Berto et.al.", "authors": "Federico Berto, Chuanbo Hua, Laurin Luttmann, Jiwoo Son, Junyoung Park, Kyuree Ahn, Changhyun Kwon, Lin Xie, Jinkyoo Park", "id": "2409.03811v1", "paper_url": "http://arxiv.org/abs/2409.03811v1", "repo": "null"}}