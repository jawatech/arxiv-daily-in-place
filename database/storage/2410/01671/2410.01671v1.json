{"2410.01671": {"publish_time": "2024-10-02", "title": "Bridging Context Gaps: Leveraging Coreference Resolution for Long Contextual Understanding", "paper_summary": "Large language models (LLMs) have shown remarkable capabilities in natural\nlanguage processing; however, they still face difficulties when tasked with\nunderstanding lengthy contexts and executing effective question answering.\nThese challenges often arise due to the complexity and ambiguity present in\nlonger texts. To enhance the performance of LLMs in such scenarios, we\nintroduce the Long Question Coreference Adaptation (LQCA) method. This\ninnovative framework focuses on coreference resolution tailored to long\ncontexts, allowing the model to identify and manage references effectively. The\nLQCA method encompasses four key steps: resolving coreferences within\nsub-documents, computing the distances between mentions, defining a\nrepresentative mention for coreference, and answering questions through mention\nreplacement. By processing information systematically, the framework provides\neasier-to-handle partitions for LLMs, promoting better understanding.\nExperimental evaluations on a range of LLMs and datasets have yielded positive\nresults, with a notable improvements on OpenAI-o1-mini and GPT-4o models,\nhighlighting the effectiveness of leveraging coreference resolution to bridge\ncontext gaps in question answering.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4e2d\u5c55\u73fe\u4e86\u975e\u51e1\u7684\u80fd\u529b\uff1b\u7136\u800c\uff0c\u7576\u5b83\u5011\u9762\u81e8\u7406\u89e3\u5197\u9577\u7684\u8a9e\u5883\u548c\u57f7\u884c\u6709\u6548\u7684\u554f\u7b54\u4efb\u52d9\u6642\uff0c\u4ecd\u7136\u6703\u9047\u5230\u56f0\u96e3\u3002\u9019\u4e9b\u6311\u6230\u901a\u5e38\u662f\u56e0\u70ba\u8f03\u9577\u7684\u6587\u672c\u4e2d\u5b58\u5728\u8907\u96dc\u6027\u548c\u6b67\u7fa9\u3002\u70ba\u4e86\u589e\u5f37 LLM \u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\u7684\u6548\u80fd\uff0c\u6211\u5011\u5f15\u5165\u4e86\u9577\u5f0f\u554f\u984c\u6307\u4ee3\u9069\u61c9 (LQCA) \u65b9\u6cd5\u3002\u9019\u500b\u5275\u65b0\u7684\u67b6\u69cb\u5c08\u6ce8\u65bc\u91dd\u5c0d\u9577\u8a9e\u5883\u7684\u6307\u4ee3\u6d88\u89e3\uff0c\u8b93\u6a21\u578b\u80fd\u5920\u6709\u6548\u5730\u8b58\u5225\u548c\u7ba1\u7406\u6307\u4ee3\u3002LQCA \u65b9\u6cd5\u5305\u542b\u56db\u500b\u95dc\u9375\u6b65\u9a5f\uff1a\u5728\u5b50\u6587\u4ef6\u4e2d\u89e3\u6790\u6307\u4ee3\u3001\u8a08\u7b97\u63d0\u53ca\u4e4b\u9593\u7684\u8ddd\u96e2\u3001\u5b9a\u7fa9\u6307\u4ee3\u7684\u4ee3\u8868\u6027\u63d0\u53ca\uff0c\u4ee5\u53ca\u900f\u904e\u63d0\u53ca\u66ff\u63db\u4f86\u56de\u7b54\u554f\u984c\u3002\u900f\u904e\u7cfb\u7d71\u6027\u5730\u8655\u7406\u8cc7\u8a0a\uff0c\u9019\u500b\u67b6\u69cb\u70ba LLM \u63d0\u4f9b\u4e86\u66f4\u5bb9\u6613\u8655\u7406\u7684\u5206\u5340\uff0c\u4fc3\u9032\u66f4\u597d\u7684\u7406\u89e3\u3002\u5728\u5404\u7a2e LLM \u548c\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u8a55\u4f30\u7522\u751f\u4e86\u6b63\u9762\u7684\u7d50\u679c\uff0c\u5728 OpenAI-o1-mini \u548c GPT-4o \u6a21\u578b\u4e0a\u90fd\u6709\u986f\u8457\u7684\u6539\u9032\uff0c\u7a81\u986f\u4e86\u5229\u7528\u6307\u4ee3\u6d88\u89e3\u4f86\u5f4c\u88dc\u554f\u7b54\u4e2d\u8a9e\u5883\u5dee\u8ddd\u7684\u6709\u6548\u6027\u3002", "author": "Yanming Liu et.al.", "authors": "Yanming Liu, Xinyue Peng, Jiannan Cao, Shi Bo, Yanxin Shen, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du", "id": "2410.01671v1", "paper_url": "http://arxiv.org/abs/2410.01671v1", "repo": "null"}}