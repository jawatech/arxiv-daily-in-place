{"2409.18364": {"publish_time": "2024-09-27", "title": "Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images", "paper_summary": "3D human shape reconstruction under severe occlusion due to human-object or\nhuman-human interaction is a challenging problem. Parametric models i.e.,\nSMPL(-X), which are based on the statistics across human shapes, can represent\nwhole human body shapes but are limited to minimally-clothed human shapes.\nImplicit-function-based methods extract features from the parametric models to\nemploy prior knowledge of human bodies and can capture geometric details such\nas clothing and hair. However, they often struggle to handle misaligned\nparametric models and inpaint occluded regions given a single RGB image. In\nthis work, we propose a novel pipeline, MHCDIFF, Multi-hypotheses Conditioned\nPoint Cloud Diffusion, composed of point cloud diffusion conditioned on\nprobabilistic distributions for pixel-aligned detailed 3D human reconstruction\nunder occlusion. Compared to previous implicit-function-based methods, the\npoint cloud diffusion model can capture the global consistent features to\ngenerate the occluded regions, and the denoising process corrects the\nmisaligned SMPL meshes. The core of MHCDIFF is extracting local features from\nmultiple hypothesized SMPL(-X) meshes and aggregating the set of features to\ncondition the diffusion model. In the experiments on CAPE and MultiHuman\ndatasets, the proposed method outperforms various SOTA methods based on SMPL,\nimplicit functions, point cloud diffusion, and their combined, under synthetic\nand real occlusions.", "paper_summary_zh": "\u7531\u65bc\u4eba\u9ad4\u8207\u7269\u9ad4\u6216\u4eba\u9ad4\u8207\u4eba\u9ad4\u7684\u4ea4\u4e92\u4f5c\u7528\u5c0e\u81f4\u56b4\u91cd\u7684\u906e\u64cb\uff0c3D \u4eba\u9ad4\u5f62\u72c0\u91cd\u5efa\u662f\u4e00\u500b\u5177\u6709\u6311\u6230\u6027\u7684\u554f\u984c\u3002\u57fa\u65bc\u4eba\u9ad4\u5f62\u72c0\u7d71\u8a08\u8cc7\u6599\u7684\u53c3\u6578\u6a21\u578b\uff0c\u4f8b\u5982 SMPL(-X)\uff0c\u53ef\u4ee5\u8868\u793a\u5b8c\u6574\u7684\u4eba\u9ad4\u5f62\u72c0\uff0c\u4f46\u50c5\u9650\u65bc\u7a7f\u8457\u6700\u5c11\u8863\u7269\u7684\u7684\u4eba\u9ad4\u5f62\u72c0\u3002\u57fa\u65bc\u96b1\u5f0f\u51fd\u6578\u7684\u65b9\u6cd5\u5f9e\u53c3\u6578\u6a21\u578b\u4e2d\u63d0\u53d6\u7279\u5fb5\uff0c\u4ee5\u904b\u7528\u4eba\u9ad4\u7684\u5148\u9a57\u77e5\u8b58\uff0c\u4e26\u53ef\u4ee5\u6355\u6349\u5e7e\u4f55\u7d30\u7bc0\uff0c\u4f8b\u5982\u8863\u7269\u548c\u982d\u9aee\u3002\u7136\u800c\uff0c\u5b83\u5011\u901a\u5e38\u96e3\u4ee5\u8655\u7406\u672a\u5c0d\u9f4a\u7684\u53c3\u6578\u6a21\u578b\uff0c\u4e26\u5728\u7d66\u5b9a\u55ae\u4e00 RGB \u5f71\u50cf\u7684\u60c5\u6cc1\u4e0b\u586b\u88dc\u88ab\u906e\u64cb\u7684\u5340\u57df\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u7ba1\u9053\uff0c\u5373 MHCDIFF\uff0c\u591a\u5047\u8a2d\u689d\u4ef6\u9ede\u96f2\u64f4\u6563\uff0c\u5b83\u7531\u689d\u4ef6\u5316\u65bc\u50cf\u7d20\u5c0d\u9f4a\u7684\u8a73\u7d30 3D \u4eba\u9ad4\u91cd\u5efa\u7684\u6a5f\u7387\u5206\u4f48\u7684\u9ede\u96f2\u64f4\u6563\u7d44\u6210\u3002\u8207\u5148\u524d\u7684\u57fa\u65bc\u96b1\u5f0f\u51fd\u6578\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u9ede\u96f2\u64f4\u6563\u6a21\u578b\u53ef\u4ee5\u6355\u6349\u5168\u5c40\u4e00\u81f4\u7684\u7279\u5fb5\u4ee5\u751f\u6210\u88ab\u906e\u64cb\u7684\u5340\u57df\uff0c\u800c\u53bb\u96dc\u8a0a\u7a0b\u5e8f\u6703\u4fee\u6b63\u672a\u5c0d\u9f4a\u7684 SMPL \u7db2\u683c\u3002MHCDIFF \u7684\u6838\u5fc3\u662f\u5f9e\u591a\u500b\u5047\u8a2d\u7684 SMPL(-X) \u7db2\u683c\u4e2d\u63d0\u53d6\u5c40\u90e8\u7279\u5fb5\uff0c\u4e26\u805a\u5408\u7279\u5fb5\u96c6\u5408\u4ee5\u8abf\u6574\u64f4\u6563\u6a21\u578b\u3002\u5728 CAPE \u548c MultiHuman \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u512a\u65bc\u5404\u7a2e\u57fa\u65bc SMPL\u3001\u96b1\u5f0f\u51fd\u6578\u3001\u9ede\u96f2\u64f4\u6563\u53ca\u5176\u7d44\u5408\u7684 SOTA \u65b9\u6cd5\uff0c\u5728\u5408\u6210\u548c\u771f\u5be6\u906e\u64cb\u4e0b\u7686\u662f\u5982\u6b64\u3002", "author": "Donghwan Kim et.al.", "authors": "Donghwan Kim, Tae-Kyun Kim", "id": "2409.18364v1", "paper_url": "http://arxiv.org/abs/2409.18364v1", "repo": "null"}}