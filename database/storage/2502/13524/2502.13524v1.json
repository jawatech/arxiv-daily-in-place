{"2502.13524": {"publish_time": "2025-02-19", "title": "MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis", "paper_summary": "Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.", "paper_summary_zh": "<paragraph>\u6709\u6548\u8a55\u4f30\u4e09\u7dad (3D) \u91ab\u5b78\u5f71\u50cf\u5c0d\u65bc\u91ab\u7642\u4fdd\u5065\u4e2d\u7684\u8a3a\u65b7\u548c\u6cbb\u7642\u5be6\u52d9\u81f3\u95dc\u91cd\u8981\u3002\u8fd1\u5e74\u4f86\uff0c\u5c07\u6df1\u5ea6\u5b78\u7fd2\u548c\u96fb\u8166\u8996\u89ba\u61c9\u7528\u65bc\u5206\u6790\u548c\u8a6e\u91cb\u91ab\u5b78\u5f71\u50cf\u7684\u61c9\u7528\u5927\u5e45\u589e\u52a0\u3002\u50b3\u7d71\u65b9\u6cd5\uff0c\u4f8b\u5982\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u548c\u8996\u89baTransformer (ViT)\uff0c\u9762\u81e8\u91cd\u5927\u7684\u904b\u7b97\u6311\u6230\uff0c\u4fc3\u4f7f\u9700\u8981\u67b6\u69cb\u4e0a\u7684\u9032\u6b65\u3002\u6700\u8fd1\u7684\u52aa\u529b\u5df2\u5c0e\u81f4\u5f15\u9032\u5275\u65b0\u7684\u67b6\u69cb\uff0c\u4f8b\u5982\u300cMamba\u300d\u6a21\u578b\uff0c\u4f5c\u70ba\u50b3\u7d71 CNN \u6216 ViT \u7684\u66ff\u4ee3\u89e3\u6c7a\u65b9\u6848\u3002Mamba \u6a21\u578b\u64c5\u9577\u4ee5\u4f4e\u904b\u7b97\u9700\u6c42\u9032\u884c\u4e00\u7dad\u8cc7\u6599\u7684\u7dda\u6027\u8655\u7406\u3002\u7136\u800c\uff0cMamba \u5728 3D \u91ab\u5b78\u5f71\u50cf\u5206\u6790\u65b9\u9762\u7684\u6f5b\u529b\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u4e26\u4e14\u96a8\u8457\u7dad\u5ea6\u7684\u589e\u52a0\u53ef\u80fd\u6703\u9762\u81e8\u91cd\u5927\u7684\u904b\u7b97\u6311\u6230\u3002\u672c\u624b\u7a3f\u63d0\u51fa MobileViM\uff0c\u9019\u662f\u4e00\u7a2e\u7c21\u5316\u7684\u67b6\u69cb\uff0c\u53ef\u6709\u6548\u5206\u5272 3D \u91ab\u5b78\u5f71\u50cf\u3002\u5728 MobileViM \u7db2\u8def\u4e2d\uff0c\u6211\u5011\u767c\u660e\u4e86\u4e00\u7a2e\u65b0\u7684\u8207\u7dad\u5ea6\u7121\u95dc\u7684\u6a5f\u5236\u548c\u96d9\u5411\u904d\u6b77\u65b9\u6cd5\uff0c\u4ee5\u8207\u57fa\u65bc\u8996\u89ba Mamba \u7684\u67b6\u69cb\u7d50\u5408\u3002MobileViM \u9084\u5177\u5099\u8de8\u5c3a\u5ea6\u6a4b\u63a5\u6280\u8853\uff0c\u4ee5\u63d0\u9ad8\u5404\u7a2e\u91ab\u5b78\u5f71\u50cf\u6a21\u5f0f\u7684\u6548\u7387\u548c\u6e96\u78ba\u6027\u3002\u900f\u904e\u9019\u4e9b\u589e\u5f37\u529f\u80fd\uff0cMobileViM \u5728\u55ae\u4e00\u986f\u793a\u5361 (\u5373 NVIDIA RTX 4090) \u4e0a\u9054\u5230\u4e86\u6bcf\u79d2\u8d85\u904e 90 \u5e40 (FPS) \u7684\u5206\u5272\u901f\u5ea6\u3002\u6b64\u6548\u80fd\u6bd4\u73fe\u6709\u6700\u5148\u9032\u7684\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u5feb\u4e86\u8d85\u904e 24 FPS\uff0c\u9019\u4e9b\u6a21\u578b\u4f7f\u7528\u76f8\u540c\u7684\u904b\u7b97\u8cc7\u6e90\u8655\u7406 3D \u5f71\u50cf\u3002\u6b64\u5916\uff0c\u5be6\u9a57\u8a55\u4f30\u8b49\u660e MobileViM \u63d0\u4f9b\u4e86\u5353\u8d8a\u7684\u6548\u80fd\uff0cDice \u76f8\u4f3c\u6027\u8a55\u5206\u5c0d\u65bc PENGWIN\u3001BraTS2024\u3001ATLAS \u548c Toothfairy2 \u8cc7\u6599\u96c6\u5206\u5225\u9054\u5230 92.72%\u300186.69%\u300180.46% \u548c 77.43%\uff0c\u986f\u8457\u8d85\u8d8a\u73fe\u6709\u6a21\u578b\u3002</paragraph>", "author": "Wei Dai et.al.", "authors": "Wei Dai, Steven Wang, Jun Liu", "id": "2502.13524v1", "paper_url": "http://arxiv.org/abs/2502.13524v1", "repo": "https://github.com/anthonyweidai/MobileViM_3D"}}