{"2407.21687": {"publish_time": "2024-07-31", "title": "Dynamic Object Queries for Transformer-based Incremental Object Detection", "paper_summary": "Incremental object detection (IOD) aims to sequentially learn new classes,\nwhile maintaining the capability to locate and identify old ones. As the\ntraining data arrives with annotations only with new classes, IOD suffers from\ncatastrophic forgetting. Prior methodologies mainly tackle the forgetting issue\nthrough knowledge distillation and exemplar replay, ignoring the conflict\nbetween limited model capacity and increasing knowledge. In this paper, we\nexplore \\textit{dynamic object queries} for incremental object detection built\non Transformer architecture. We propose the \\textbf{Dy}namic object\n\\textbf{Q}uery-based \\textbf{DE}tection \\textbf{TR}ansformer (DyQ-DETR), which\nincrementally expands the model representation ability to achieve\nstability-plasticity tradeoff. First, a new set of learnable object queries are\nfed into the decoder to represent new classes. These new object queries are\naggregated with those from previous phases to adapt both old and new knowledge\nwell. Second, we propose the isolated bipartite matching for object queries in\ndifferent phases, based on disentangled self-attention. The interaction among\nthe object queries at different phases is eliminated to reduce inter-class\nconfusion. Thanks to the separate supervision and computation over object\nqueries, we further present the risk-balanced partial calibration for effective\nexemplar replay. Extensive experiments demonstrate that DyQ-DETR significantly\nsurpasses the state-of-the-art methods, with limited parameter overhead. Code\nwill be made publicly available.", "paper_summary_zh": "\u589e\u91cf\u5f0f\u7269\u4ef6\u5075\u6e2c (IOD) \u65e8\u5728\u5faa\u5e8f\u6f38\u9032\u5730\u5b78\u7fd2\u65b0\u985e\u5225\uff0c\u540c\u6642\u7dad\u6301\u5b9a\u4f4d\u548c\u8fa8\u8b58\u820a\u985e\u5225\u7684\u80fd\u529b\u3002\u7531\u65bc\u8a13\u7df4\u8cc7\u6599\u50c5\u9644\u6709\u65b0\u985e\u5225\u7684\u8a3b\u89e3\uff0cIOD \u6703\u767c\u751f\u707d\u96e3\u6027\u907a\u5fd8\u3002\u5148\u524d\u7684\u7814\u7a76\u65b9\u6cd5\u4e3b\u8981\u900f\u904e\u77e5\u8b58\u8403\u53d6\u548c\u7bc4\u4f8b\u91cd\u64ad\u4f86\u89e3\u6c7a\u907a\u5fd8\u554f\u984c\uff0c\u537b\u5ffd\u7565\u4e86\u6a21\u578b\u5bb9\u91cf\u6709\u9650\u548c\u77e5\u8b58\u589e\u52a0\u4e4b\u9593\u7684\u885d\u7a81\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u7d22\u5efa\u7acb\u5728 Transformer \u67b6\u69cb\u4e0a\u7684\u589e\u91cf\u5f0f\u7269\u4ef6\u5075\u6e2c\u7684\u300c\u52d5\u614b\u7269\u4ef6\u67e5\u8a62\u300d\u3002\u6211\u5011\u63d0\u51fa\u4ee5\u52d5\u614b\u7269\u4ef6\u67e5\u8a62\u70ba\u57fa\u790e\u7684\u5075\u6e2c\u8b8a\u5f62\u91d1\u525b (DyQ-DETR)\uff0c\u5b83\u6703\u9010\u6b65\u64f4\u5c55\u6a21\u578b\u8868\u793a\u80fd\u529b\uff0c\u4ee5\u9054\u6210\u7a69\u5b9a\u6027\u548c\u53ef\u5851\u6027\u7684\u6298\u8877\u3002\u9996\u5148\uff0c\u5c07\u4e00\u7d44\u65b0\u7684\u53ef\u5b78\u7fd2\u7269\u4ef6\u67e5\u8a62\u8f38\u5165\u89e3\u78bc\u5668\uff0c\u4ee5\u8868\u793a\u65b0\u985e\u5225\u3002\u9019\u4e9b\u65b0\u7684\u7269\u4ef6\u67e5\u8a62\u6703\u8207\u524d\u4e00\u968e\u6bb5\u7684\u67e5\u8a62\u5408\u4f75\uff0c\u4ee5\u9069\u7576\u5730\u8abf\u6574\u820a\u6709\u548c\u65b0\u7684\u77e5\u8b58\u3002\u5176\u6b21\uff0c\u6211\u5011\u63d0\u51fa\u57fa\u65bc\u89e3\u958b\u81ea\u6211\u6ce8\u610f\u529b\u7684\u3001\u7528\u65bc\u4e0d\u540c\u968e\u6bb5\u7269\u4ef6\u67e5\u8a62\u7684\u5b64\u7acb\u4e8c\u90e8\u5339\u914d\u3002\u6d88\u9664\u4e0d\u540c\u968e\u6bb5\u7269\u4ef6\u67e5\u8a62\u4e4b\u9593\u7684\u4e92\u52d5\uff0c\u4ee5\u6e1b\u5c11\u985e\u5225\u9593\u7684\u6df7\u6dc6\u3002\u7531\u65bc\u7269\u4ef6\u67e5\u8a62\u6709\u7368\u7acb\u7684\u76e3\u7763\u548c\u904b\u7b97\uff0c\u6211\u5011\u9032\u4e00\u6b65\u63d0\u51fa\u98a8\u96aa\u5e73\u8861\u7684\u90e8\u5206\u6821\u6b63\uff0c\u4ee5\u6709\u6548\u5730\u91cd\u64ad\u7bc4\u4f8b\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8b49\u660e\uff0cDyQ-DETR \u5927\u5e45\u8d85\u8d8a\u6700\u5148\u9032\u7684\u65b9\u6cd5\uff0c\u4e14\u53c3\u6578\u958b\u92b7\u6709\u9650\u3002\u7a0b\u5f0f\u78bc\u5c07\u516c\u958b\u63d0\u4f9b\u3002", "author": "Jichuan Zhang et.al.", "authors": "Jichuan Zhang, Wei Li, Shuang Cheng, Ya-Li Li, Shengjin Wang", "id": "2407.21687v1", "paper_url": "http://arxiv.org/abs/2407.21687v1", "repo": "null"}}