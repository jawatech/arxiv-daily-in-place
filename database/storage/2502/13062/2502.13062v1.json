{"2502.13062": {"publish_time": "2025-02-18", "title": "AI-Assisted Decision Making with Human Learning", "paper_summary": "AI systems increasingly support human decision-making. In many cases, despite\nthe algorithm's superior performance, the final decision remains in human\nhands. For example, an AI may assist doctors in determining which diagnostic\ntests to run, but the doctor ultimately makes the diagnosis. This paper studies\nsuch AI-assisted decision-making settings, where the human learns through\nrepeated interactions with the algorithm. In our framework, the algorithm --\ndesigned to maximize decision accuracy according to its own model -- determines\nwhich features the human can consider. The human then makes a prediction based\non their own less accurate model. We observe that the discrepancy between the\nalgorithm's model and the human's model creates a fundamental tradeoff. Should\nthe algorithm prioritize recommending more informative features, encouraging\nthe human to recognize their importance, even if it results in less accurate\npredictions in the short term until learning occurs? Or is it preferable to\nforgo educating the human and instead select features that align more closely\nwith their existing understanding, minimizing the immediate cost of learning?\nThis tradeoff is shaped by the algorithm's time-discounted objective and the\nhuman's learning ability. Our results show that optimal feature selection has a\nsurprisingly clean combinatorial characterization, reducible to a stationary\nsequence of feature subsets that is tractable to compute. As the algorithm\nbecomes more \"patient\" or the human's learning improves, the algorithm\nincreasingly selects more informative features, enhancing both prediction\naccuracy and the human's understanding. Notably, early investment in learning\nleads to the selection of more informative features than a later investment. We\ncomplement our analysis by showing that the impact of errors in the algorithm's\nknowledge is limited as it does not make the prediction directly.", "paper_summary_zh": "\u4eba\u5de5\u667a\u6167\u7cfb\u7d71\u65e5\u76ca\u652f\u63f4\u4eba\u985e\u6c7a\u7b56\u3002\u5728\u8a31\u591a\u60c5\u6cc1\u4e0b\uff0c\u5118\u7ba1\u6f14\u7b97\u6cd5\u7684\u6548\u80fd\u512a\u7570\uff0c\u6700\u7d42\u6c7a\u7b56\u4ecd\u638c\u63e1\u5728\u4eba\u985e\u624b\u4e2d\u3002\u4f8b\u5982\uff0c\u4eba\u5de5\u667a\u6167\u53ef\u80fd\u6703\u5354\u52a9\u91ab\u751f\u6c7a\u5b9a\u8981\u57f7\u884c\u54ea\u4e9b\u8a3a\u65b7\u6e2c\u8a66\uff0c\u4f46\u6700\u7d42\u4e0b\u8a3a\u65b7\u7684\u662f\u91ab\u751f\u3002\u672c\u6587\u63a2\u8a0e\u6b64\u985e\u4eba\u5de5\u667a\u6167\u8f14\u52a9\u6c7a\u7b56\u8a2d\u5b9a\uff0c\u5176\u4e2d\u4eba\u985e\u900f\u904e\u8207\u6f14\u7b97\u6cd5\u91cd\u8907\u4e92\u52d5\u800c\u5b78\u7fd2\u3002\u5728\u6211\u5011\u7684\u67b6\u69cb\u4e2d\uff0c\u6f14\u7b97\u6cd5\uff08\u65e8\u5728\u6839\u64da\u5176\u81ea\u8eab\u6a21\u578b\u6700\u5927\u5316\u6c7a\u7b56\u6e96\u78ba\u5ea6\uff09\u6703\u6c7a\u5b9a\u4eba\u985e\u53ef\u4ee5\u8003\u91cf\u7684\u7279\u5fb5\u3002\u7136\u5f8c\uff0c\u4eba\u985e\u6839\u64da\u5176\u81ea\u8eab\u8f03\u4e0d\u6e96\u78ba\u7684\u6a21\u578b\u505a\u51fa\u9810\u6e2c\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u6f14\u7b97\u6cd5\u6a21\u578b\u8207\u4eba\u985e\u6a21\u578b\u4e4b\u9593\u7684\u5dee\u7570\u6703\u7522\u751f\u57fa\u672c\u7684\u6b0a\u8861\u3002\u6f14\u7b97\u6cd5\u662f\u5426\u61c9\u512a\u5148\u63a8\u85a6\u66f4\u591a\u8cc7\u8a0a\u6027\u7279\u5fb5\uff0c\u9f13\u52f5\u4eba\u985e\u8a8d\u8b58\u5176\u91cd\u8981\u6027\uff0c\u5373\u4f7f\u77ed\u671f\u5167\u6703\u5c0e\u81f4\u6e96\u78ba\u5ea6\u8f03\u4f4e\u7684\u9810\u6e2c\uff0c\u76f4\u5230\u5b78\u7fd2\u767c\u751f\uff1f\u6216\u8005\uff0c\u662f\u5426\u8f03\u597d\u653e\u68c4\u6559\u80b2\u4eba\u985e\uff0c\u800c\u9078\u64c7\u8207\u5176\u73fe\u6709\u7406\u89e3\u66f4\u7dca\u5bc6\u5c0d\u9f4a\u7684\u7279\u5fb5\uff0c\u5c07\u5b78\u7fd2\u7684\u7acb\u5373\u6210\u672c\u964d\u81f3\u6700\u4f4e\uff1f\u9019\u7a2e\u6b0a\u8861\u53d6\u6c7a\u65bc\u6f14\u7b97\u6cd5\u7684\u6642\u9593\u6298\u73fe\u76ee\u6a19\u548c\u4eba\u985e\u7684\u5b78\u7fd2\u80fd\u529b\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u6700\u4f73\u7279\u5fb5\u9078\u64c7\u5177\u6709\u4ee4\u4eba\u9a5a\u8a1d\u7684\u4e7e\u6de8\u7d44\u5408\u7279\u5fb5\uff0c\u53ef\u7c21\u5316\u70ba\u53ef\u8a08\u7b97\u7684\u56fa\u5b9a\u7279\u5fb5\u5b50\u96c6\u5e8f\u5217\u3002\u96a8\u8457\u6f14\u7b97\u6cd5\u8b8a\u5f97\u66f4\u300c\u6709\u8010\u5fc3\u300d\u6216\u4eba\u985e\u7684\u5b78\u7fd2\u9032\u6b65\uff0c\u6f14\u7b97\u6cd5\u6703\u8d8a\u4f86\u8d8a\u591a\u5730\u9078\u64c7\u66f4\u591a\u8cc7\u8a0a\u6027\u7279\u5fb5\uff0c\u589e\u5f37\u9810\u6e2c\u6e96\u78ba\u5ea6\u548c\u4eba\u985e\u7684\u7406\u89e3\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u65e9\u671f\u6295\u8cc7\u65bc\u5b78\u7fd2\u6703\u5c0e\u81f4\u9078\u64c7\u6bd4\u5f8c\u671f\u6295\u8cc7\u66f4\u591a\u8cc7\u8a0a\u6027\u7279\u5fb5\u3002\u6211\u5011\u900f\u904e\u986f\u793a\u6f14\u7b97\u6cd5\u77e5\u8b58\u4e2d\u932f\u8aa4\u7684\u5f71\u97ff\u662f\u6709\u9650\u7684\uff0c\u56e0\u70ba\u5b83\u4e0d\u6703\u76f4\u63a5\u505a\u51fa\u9810\u6e2c\uff0c\u4f86\u88dc\u5145\u6211\u5011\u7684\u5206\u6790\u3002", "author": "Gali Noti et.al.", "authors": "Gali Noti, Kate Donahue, Jon Kleinberg, Sigal Oren", "id": "2502.13062v1", "paper_url": "http://arxiv.org/abs/2502.13062v1", "repo": "null"}}