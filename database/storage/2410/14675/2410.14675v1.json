{"2410.14675": {"publish_time": "2024-10-18", "title": "Enhancing Large Language Models' Situated Faithfulness to External Contexts", "paper_summary": "Large Language Models (LLMs) are often augmented with external information as\ncontexts, but this external information can sometimes be inaccurate or even\nintentionally misleading. We argue that robust LLMs should demonstrate situated\nfaithfulness, dynamically calibrating their trust in external information based\non their confidence in the internal knowledge and the external context. To\nbenchmark this capability, we evaluate LLMs across several QA datasets,\nincluding a newly created dataset called RedditQA featuring in-the-wild\nincorrect contexts sourced from Reddit posts. We show that when provided with\nboth correct and incorrect contexts, both open-source and proprietary models\ntend to overly rely on external information, regardless of its factual\naccuracy. To enhance situated faithfulness, we propose two approaches:\nSelf-Guided Confidence Reasoning (SCR) and Rule-Based Confidence Reasoning\n(RCR). SCR enables models to self-access the confidence of external information\nrelative to their own internal knowledge to produce the most accurate answer.\nRCR, in contrast, extracts explicit confidence signals from the LLM and\ndetermines the final answer using predefined rules. Our results show that for\nLLMs with strong reasoning capabilities, such as GPT-4o and GPT-4o mini, SCR\noutperforms RCR, achieving improvements of up to 24.2% over a direct input\naugmentation baseline. Conversely, for a smaller model like Llama-3-8B, RCR\noutperforms SCR. Fine-tuning SCR with our proposed Confidence Reasoning Direct\nPreference Optimization (CR-DPO) method improves performance on both seen and\nunseen datasets, yielding an average improvement of 8.9% on Llama-3-8B. In\naddition to quantitative results, we offer insights into the relative strengths\nof SCR and RCR. Our findings highlight promising avenues for improving situated\nfaithfulness in LLMs. The data and code are released.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u901a\u5e38\u6703\u4ee5\u5916\u90e8\u8cc7\u8a0a\u4f5c\u70ba\u60c5\u5883\u9032\u884c\u64f4\u5145\uff0c\u4f46\u9019\u4e9b\u5916\u90e8\u8cc7\u8a0a\u6709\u6642\u53ef\u80fd\u4e0d\u6b63\u78ba\uff0c\u751a\u81f3\u6545\u610f\u5177\u6709\u8aa4\u5c0e\u6027\u3002\u6211\u5011\u8a8d\u70ba\uff0c\u5f37\u5065\u7684 LLM \u61c9\u5c55\u73fe\u60c5\u5883\u5fe0\u5be6\u5ea6\uff0c\u6839\u64da\u5176\u5c0d\u5167\u90e8\u77e5\u8b58\u548c\u5916\u90e8\u60c5\u5883\u7684\u4fe1\u5fc3\uff0c\u52d5\u614b\u6821\u6e96\u5176\u5c0d\u5916\u90e8\u8cc7\u8a0a\u7684\u4fe1\u4efb\u3002\u70ba\u4e86\u8a55\u91cf\u6b64\u9805\u80fd\u529b\uff0c\u6211\u5011\u91dd\u5c0d\u591a\u500b\u554f\u7b54\u8cc7\u6599\u96c6\u8a55\u4f30 LLM\uff0c\u5305\u62ec\u4e00\u500b\u65b0\u5efa\u7acb\u7684\u8cc7\u6599\u96c6 RedditQA\uff0c\u5176\u7279\u9ede\u662f\u5f9e Reddit \u8cbc\u6587\u4e2d\u64f7\u53d6\u7684\u771f\u5be6\u4e0d\u6b63\u78ba\u60c5\u5883\u3002\u6211\u5011\u767c\u73fe\uff0c\u7576\u63d0\u4f9b\u6b63\u78ba\u548c\u4e0d\u6b63\u78ba\u7684\u60c5\u5883\u6642\uff0c\u4e0d\u8ad6\u662f\u958b\u653e\u539f\u59cb\u78bc\u6216\u5c08\u6709\u6a21\u578b\uff0c\u90fd\u50be\u5411\u904e\u5ea6\u4f9d\u8cf4\u5916\u90e8\u8cc7\u8a0a\uff0c\u800c\u4e0d\u7ba1\u5176\u4e8b\u5be6\u6b63\u78ba\u6027\u3002\u70ba\u4e86\u589e\u5f37\u60c5\u5883\u5fe0\u5be6\u5ea6\uff0c\u6211\u5011\u63d0\u51fa\u5169\u7a2e\u65b9\u6cd5\uff1a\u81ea\u5c0e\u4fe1\u5fc3\u63a8\u7406 (SCR) \u548c\u57fa\u65bc\u898f\u5247\u7684\u4fe1\u5fc3\u63a8\u7406 (RCR)\u3002SCR \u4f7f\u6a21\u578b\u80fd\u5920\u81ea\u884c\u5b58\u53d6\u5916\u90e8\u8cc7\u8a0a\u7684\u4fe1\u5fc3\uff0c\u76f8\u5c0d\u65bc\u5176\u81ea\u8eab\u7684\u5167\u90e8\u77e5\u8b58\uff0c\u4ee5\u7522\u751f\u6700\u6e96\u78ba\u7684\u7b54\u6848\u3002\u76f8\u53cd\u5730\uff0cRCR \u5f9e LLM \u4e2d\u64f7\u53d6\u660e\u78ba\u7684\u4fe1\u5fc3\u8a0a\u865f\uff0c\u4e26\u4f7f\u7528\u9810\u5b9a\u7fa9\u7684\u898f\u5247\u4f86\u6c7a\u5b9a\u6700\u7d42\u7b54\u6848\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u5c0d\u65bc\u5177\u6709\u5f37\u5927\u63a8\u7406\u80fd\u529b\u7684 LLM\uff0c\u4f8b\u5982 GPT-4o \u548c GPT-4o mini\uff0cSCR \u512a\u65bc RCR\uff0c\u8207\u76f4\u63a5\u8f38\u5165\u64f4\u5145\u57fa\u6e96\u76f8\u6bd4\uff0c\u6539\u9032\u5e45\u5ea6\u9ad8\u9054 24.2%\u3002\u76f8\u53cd\u5730\uff0c\u5c0d\u65bc\u8f03\u5c0f\u7684\u6a21\u578b\uff0c\u4f8b\u5982 Llama-3-8B\uff0cRCR \u512a\u65bc SCR\u3002\u4f7f\u7528\u6211\u5011\u63d0\u51fa\u7684\u4fe1\u5fc3\u63a8\u7406\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (CR-DPO) \u65b9\u6cd5\u5fae\u8abf SCR\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5df2\u898b\u548c\u672a\u898b\u8cc7\u6599\u96c6\u7684\u6548\u80fd\uff0c\u5728 Llama-3-8B \u4e0a\u7522\u751f\u5e73\u5747 8.9% \u7684\u6539\u9032\u3002\u9664\u4e86\u91cf\u5316\u7d50\u679c\u5916\uff0c\u6211\u5011\u9084\u63d0\u4f9b\u4e86\u5c0d SCR \u548c RCR \u76f8\u5c0d\u512a\u52e2\u7684\u898b\u89e3\u3002\u6211\u5011\u7684\u767c\u73fe\u7a81\u986f\u4e86\u6539\u5584 LLM \u4e2d\u60c5\u5883\u5fe0\u5be6\u5ea6\u7684\u6709\u524d\u666f\u9014\u5f91\u3002\u8cc7\u6599\u548c\u7a0b\u5f0f\u78bc\u5df2\u767c\u5e03\u3002", "author": "Yukun Huang et.al.", "authors": "Yukun Huang, Sanxing Chen, Hongyi Cai, Bhuwan Dhingra", "id": "2410.14675v1", "paper_url": "http://arxiv.org/abs/2410.14675v1", "repo": "https://github.com/kkkevinkkkkk/situated_faithfulness"}}