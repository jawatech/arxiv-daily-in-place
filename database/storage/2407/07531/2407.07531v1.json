{"2407.07531": {"publish_time": "2024-07-10", "title": "Beyond Benchmarking: A New Paradigm for Evaluation and Assessment of Large Language Models", "paper_summary": "In current benchmarks for evaluating large language models (LLMs), there are\nissues such as evaluation content restriction, untimely updates, and lack of\noptimization guidance. In this paper, we propose a new paradigm for the\nmeasurement of LLMs: Benchmarking-Evaluation-Assessment. Our paradigm shifts\nthe \"location\" of LLM evaluation from the \"examination room\" to the \"hospital\".\nThrough conducting a \"physical examination\" on LLMs, it utilizes specific\ntask-solving as the evaluation content, performs deep attribution of existing\nproblems within LLMs, and provides recommendation for optimization.", "paper_summary_zh": "\u5728\u7576\u524d\u7528\u65bc\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u57fa\u6e96\u4e2d\uff0c\u5b58\u5728\u8a55\u4f30\u5167\u5bb9\u9650\u5236\u3001\u66f4\u65b0\u4e0d\u5373\u6642\u4ee5\u53ca\u7f3a\u4e4f\u6700\u4f73\u5316\u6307\u5c0e\u7b49\u554f\u984c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7684\u7bc4\u4f8b\u4f86\u6e2c\u91cf LLM\uff1a\u57fa\u6e96\u8a55\u4f30\u3002\u6211\u5011\u7684\u7bc4\u4f8b\u5c07 LLM \u8a55\u4f30\u7684\u300c\u4f4d\u7f6e\u300d\u5f9e\u300c\u8003\u5834\u300d\u8f49\u79fb\u5230\u300c\u91ab\u9662\u300d\u3002\u900f\u904e\u5c0d LLM \u9032\u884c\u300c\u8eab\u9ad4\u6aa2\u67e5\u300d\uff0c\u5b83\u5229\u7528\u5177\u9ad4\u7684\u4efb\u52d9\u89e3\u6c7a\u4f5c\u70ba\u8a55\u4f30\u5167\u5bb9\uff0c\u5c0d LLM \u5167\u90e8\u73fe\u6709\u554f\u984c\u9032\u884c\u6df1\u5165\u6b78\u56e0\uff0c\u4e26\u63d0\u4f9b\u6700\u4f73\u5316\u5efa\u8b70\u3002", "author": "Jin Liu et.al.", "authors": "Jin Liu, Qingquan Li, Wenlong Du", "id": "2407.07531v1", "paper_url": "http://arxiv.org/abs/2407.07531v1", "repo": "null"}}