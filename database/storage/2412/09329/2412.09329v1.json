{"2412.09329": {"publish_time": "2024-12-12", "title": "Towards Open-Vocabulary Video Semantic Segmentation", "paper_summary": "Semantic segmentation in videos has been a focal point of recent research.\nHowever, existing models encounter challenges when faced with unfamiliar\ncategories. To address this, we introduce the Open Vocabulary Video Semantic\nSegmentation (OV-VSS) task, designed to accurately segment every pixel across a\nwide range of open-vocabulary categories, including those that are novel or\npreviously unexplored. To enhance OV-VSS performance, we propose a robust\nbaseline, OV2VSS, which integrates a spatial-temporal fusion module, allowing\nthe model to utilize temporal relationships across consecutive frames.\nAdditionally, we incorporate a random frame enhancement module, broadening the\nmodel's understanding of semantic context throughout the entire video sequence.\nOur approach also includes video text encoding, which strengthens the model's\ncapability to interpret textual information within the video context.\nComprehensive evaluations on benchmark datasets such as VSPW and Cityscapes\nhighlight OV-VSS's zero-shot generalization capabilities, especially in\nhandling novel categories. The results validate OV2VSS's effectiveness,\ndemonstrating improved performance in semantic segmentation tasks across\ndiverse video datasets.", "paper_summary_zh": "\u5f71\u7247\u4e2d\u7684\u8bed\u610f\u5206\u5272\u4e00\u76f4\u662f\u8fd1\u671f\u7814\u7a76\u7684\u91cd\u70b9\u3002\n\u7136\u800c\uff0c\u73b0\u6709\u7684\u6a21\u578b\u5728\u9762\u5bf9\u4e0d\u719f\u6089\u7684\u7c7b\u522b\u65f6\u4f1a\u9047\u5230\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u5f00\u653e\u8bcd\u6c47\u89c6\u9891\u8bed\u4e49\u5206\u5272 (OV-VSS) \u4efb\u52a1\uff0c\u65e8\u5728\u51c6\u786e\u5206\u5272\u5e7f\u6cdb\u5f00\u653e\u8bcd\u6c47\u7c7b\u522b\u4e2d\u7684\u6bcf\u4e2a\u50cf\u7d20\uff0c\u5305\u62ec\u90a3\u4e9b\u65b0\u9896\u6216\u4ee5\u524d\u672a\u63a2\u7d22\u7684\u7c7b\u522b\u3002\u4e3a\u4e86\u589e\u5f3a OV-VSS \u7684\u6027\u80fd\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u7a33\u5065\u7684\u57fa\u51c6 OV2VSS\uff0c\u5b83\u96c6\u6210\u4e86\u4e00\u4e2a\u65f6\u7a7a\u878d\u5408\u6a21\u5757\uff0c\u5141\u8bb8\u6a21\u578b\u5229\u7528\u8fde\u7eed\u5e27\u4e2d\u7684\u65f6\u95f4\u5173\u7cfb\u3002\n\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u7eb3\u5165\u4e86\u968f\u673a\u5e27\u589e\u5f3a\u6a21\u5757\uff0c\u6269\u5927\u4e86\u6a21\u578b\u5bf9\u6574\u4e2a\u89c6\u9891\u5e8f\u5217\u4e2d\u8bed\u4e49\u4e0a\u4e0b\u6587\u7684\u7406\u89e3\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u8fd8\u5305\u62ec\u89c6\u9891\u6587\u672c\u7f16\u7801\uff0c\u8fd9\u52a0\u5f3a\u4e86\u6a21\u578b\u5728\u89c6\u9891\u4e0a\u4e0b\u6587\u4e2d\u89e3\u91ca\u6587\u672c\u4fe1\u606f\u7684\u80fd\u529b\u3002\n\u5728 VSPW \u548c Cityscapes \u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5168\u9762\u8bc4\u4f30\u7a81\u51fa\u4e86 OV-VSS \u7684\u96f6\u6b21\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u65b0\u9896\u7c7b\u522b\u65b9\u9762\u3002\u7ed3\u679c\u9a8c\u8bc1\u4e86 OV2VSS \u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5728\u5404\u79cd\u89c6\u9891\u6570\u636e\u96c6\u4e2d\u7684\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\u6027\u80fd\u5f97\u5230\u63d0\u5347\u3002", "author": "Xinhao Li et.al.", "authors": "Xinhao Li, Yun Liu, Guolei Sun, Min Wu, Le Zhang, Ce Zhu", "id": "2412.09329v1", "paper_url": "http://arxiv.org/abs/2412.09329v1", "repo": "null"}}