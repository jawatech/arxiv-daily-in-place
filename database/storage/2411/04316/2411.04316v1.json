{"2411.04316": {"publish_time": "2024-11-06", "title": "A Multilingual Sentiment Lexicon for Low-Resource Language Translation using Large Languages Models and Explainable AI", "paper_summary": "South Africa and the Democratic Republic of Congo (DRC) present a complex\nlinguistic landscape with languages such as Zulu, Sepedi, Afrikaans, French,\nEnglish, and Tshiluba (Ciluba), which creates unique challenges for AI-driven\ntranslation and sentiment analysis systems due to a lack of accurately labeled\ndata. This study seeks to address these challenges by developing a multilingual\nlexicon designed for French and Tshiluba, now expanded to include translations\nin English, Afrikaans, Sepedi, and Zulu. The lexicon enhances cultural\nrelevance in sentiment classification by integrating language-specific\nsentiment scores. A comprehensive testing corpus is created to support\ntranslation and sentiment analysis tasks, with machine learning models such as\nRandom Forest, Support Vector Machine (SVM), Decision Trees, and Gaussian Naive\nBayes (GNB) trained to predict sentiment across low resource languages (LRLs).\nAmong them, the Random Forest model performed particularly well, capturing\nsentiment polarity and handling language-specific nuances effectively.\nFurthermore, Bidirectional Encoder Representations from Transformers (BERT), a\nLarge Language Model (LLM), is applied to predict context-based sentiment with\nhigh accuracy, achieving 99% accuracy and 98% precision, outperforming other\nmodels. The BERT predictions were clarified using Explainable AI (XAI),\nimproving transparency and fostering confidence in sentiment classification.\nOverall, findings demonstrate that the proposed lexicon and machine learning\nmodels significantly enhance translation and sentiment analysis for LRLs in\nSouth Africa and the DRC, laying a foundation for future AI models that support\nunderrepresented languages, with applications across education, governance, and\nbusiness in multilingual contexts.", "paper_summary_zh": "\u5357\u975e\u548c\u525b\u679c\u6c11\u4e3b\u5171\u548c\u570b (DRC) \u5448\u73fe\u51fa\u8907\u96dc\u7684\u8a9e\u8a00\u74b0\u5883\uff0c\u5176\u4e2d\u5305\u542b\u7956\u9b6f\u8a9e\u3001\u5317\u7d22\u6258\u8a9e\u3001\u5357\u975e\u8377\u862d\u8a9e\u3001\u6cd5\u8a9e\u3001\u82f1\u8a9e\u548c\u5947\u76e7\u5df4\u8a9e (\u5947\u76e7\u5df4\u8a9e)\uff0c\u7531\u65bc\u7f3a\u4e4f\u6e96\u78ba\u6a19\u8a18\u7684\u8cc7\u6599\uff0c\u9019\u5c0d AI \u9a45\u52d5\u7684\u7ffb\u8b6f\u548c\u60c5\u7dd2\u5206\u6790\u7cfb\u7d71\u9020\u6210\u4e86\u7368\u7279\u7684\u6311\u6230\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u904e\u958b\u767c\u4e00\u7a2e\u5c08\u70ba\u6cd5\u8a9e\u548c\u5947\u76e7\u5df4\u8a9e\u8a2d\u8a08\u7684\u591a\u8a9e\u8a00\u8a5e\u5f59\u8868\u4f86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u73fe\u5728\u5df2\u64f4\u5c55\u5230\u5305\u62ec\u82f1\u8a9e\u3001\u5357\u975e\u8377\u862d\u8a9e\u3001\u5317\u7d22\u6258\u8a9e\u548c\u7956\u9b6f\u8a9e\u7684\u7ffb\u8b6f\u3002\u8a72\u8a5e\u5f59\u8868\u901a\u904e\u6574\u5408\u7279\u5b9a\u8a9e\u8a00\u7684\u60c5\u7dd2\u5206\u6578\u4f86\u589e\u5f37\u60c5\u7dd2\u5206\u985e\u4e2d\u7684\u6587\u5316\u76f8\u95dc\u6027\u3002\u5efa\u7acb\u4e86\u4e00\u500b\u5168\u9762\u7684\u6e2c\u8a66\u8a9e\u6599\u5eab\u4f86\u652f\u6301\u7ffb\u8b6f\u548c\u60c5\u7dd2\u5206\u6790\u4efb\u52d9\uff0c\u4e26\u8a13\u7df4\u4e86\u96a8\u6a5f\u68ee\u6797\u3001\u652f\u6301\u5411\u91cf\u6a5f (SVM)\u3001\u6c7a\u7b56\u6a39\u548c\u9ad8\u65af\u6a38\u7d20\u8c9d\u8449\u65af (GNB) \u7b49\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u4f86\u9810\u6e2c\u4f4e\u8cc7\u6e90\u8a9e\u8a00 (LRL) \u7684\u60c5\u7dd2\u3002\u5176\u4e2d\uff0c\u96a8\u6a5f\u68ee\u6797\u6a21\u578b\u8868\u73fe\u7279\u5225\u51fa\u8272\uff0c\u6709\u6548\u6355\u6349\u60c5\u7dd2\u6975\u6027\u548c\u8655\u7406\u7279\u5b9a\u8a9e\u8a00\u7684\u7d30\u5fae\u5dee\u5225\u3002\u6b64\u5916\uff0c\u4f86\u81ea Transformer \u7684\u96d9\u5411\u7de8\u78bc\u5668\u8868\u793a (BERT)\uff0c\u4e00\u7a2e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u88ab\u7528\u65bc\u9810\u6e2c\u57fa\u65bc\u4e0a\u4e0b\u6587\u7684\u8a9e\u610f\uff0c\u5177\u6709\u5f88\u9ad8\u7684\u6e96\u78ba\u5ea6\uff0c\u9054\u5230 99% \u7684\u6e96\u78ba\u5ea6\u548c 98% \u7684\u7cbe\u78ba\u5ea6\uff0c\u512a\u65bc\u5176\u4ed6\u6a21\u578b\u3002BERT \u9810\u6e2c\u4f7f\u7528\u53ef\u89e3\u91cb AI (XAI) \u9032\u884c\u6f84\u6e05\uff0c\u63d0\u9ad8\u900f\u660e\u5ea6\u4e26\u589e\u5f37\u5c0d\u60c5\u7dd2\u5206\u985e\u7684\u4fe1\u5fc3\u3002\u7e3d\u9ad4\u800c\u8a00\uff0c\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8a5e\u5f59\u8868\u548c\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u986f\u8457\u589e\u5f37\u4e86\u5357\u975e\u548c\u525b\u679c\u6c11\u4e3b\u5171\u548c\u570b\u7684 LRL \u7684\u7ffb\u8b6f\u548c\u60c5\u7dd2\u5206\u6790\uff0c\u70ba\u672a\u4f86\u652f\u6301\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u8a9e\u8a00\u7684 AI \u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u790e\uff0c\u4e26\u5728\u591a\u8a9e\u8a00\u74b0\u5883\u4e2d\u7684\u6559\u80b2\u3001\u6cbb\u7406\u548c\u5546\u696d\u4e2d\u61c9\u7528\u3002", "author": "Melusi Malinga et.al.", "authors": "Melusi Malinga, Isaac Lupanda, Mike Wa Nkongolo, Phil van Deventer", "id": "2411.04316v1", "paper_url": "http://arxiv.org/abs/2411.04316v1", "repo": "null"}}