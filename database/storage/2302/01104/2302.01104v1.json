{"2302.01104": {"publish_time": "2023-02-02", "title": "LesionAid: Vision Transformers-based Skin Lesion Generation and Classification", "paper_summary": "Skin cancer is one of the most prevalent forms of human cancer. It is\nrecognized mainly visually, beginning with clinical screening and continuing\nwith the dermoscopic examination, histological assessment, and specimen\ncollection. Deep convolutional neural networks (CNNs) perform highly segregated\nand potentially universal tasks against a classified finegrained object. This\nresearch proposes a novel multi-class prediction framework that classifies skin\nlesions based on ViT and ViTGAN. Vision transformers-based GANs (Generative\nAdversarial Networks) are utilized to tackle the class imbalance. The framework\nconsists of four main phases: ViTGANs, Image processing, and explainable AI.\nPhase 1 consists of generating synthetic images to balance all the classes in\nthe dataset. Phase 2 consists of applying different data augmentation\ntechniques and morphological operations to increase the size of the data.\nPhases 3 & 4 involve developing a ViT model for edge computing systems that can\nidentify patterns and categorize skin lesions from the user's skin visible in\nthe image. In phase 3, after classifying the lesions into the desired class\nwith ViT, we will use explainable AI (XAI) that leads to more explainable\nresults (using activation maps, etc.) while ensuring high predictive accuracy.\nReal-time images of skin diseases can capture by a doctor or a patient using\nthe camera of a mobile application to perform an early examination and\ndetermine the cause of the skin lesion. The whole framework is compared with\nthe existing frameworks for skin lesion detection.", "paper_summary_zh": "", "author": "Ghanta Sai Krishna et.al.", "authors": "Ghanta Sai Krishna,Kundrapu Supriya,Mallikharjuna Rao K,Meetiksha Sorgile", "id": "2302.01104v1", "paper_url": "http://arxiv.org/abs/2302.01104v1", "repo": "null"}}