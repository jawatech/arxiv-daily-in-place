{"2406.12673": {"publish_time": "2024-06-18", "title": "Estimating Knowledge in Large Language Models Without Generating a Single Token", "paper_summary": "To evaluate knowledge in large language models (LLMs), current methods query\nthe model and then evaluate its generated responses. In this work, we ask\nwhether evaluation can be done $\\textit{before}$ the model has generated any\ntext. Concretely, is it possible to estimate how knowledgeable a model is about\na certain entity, only from its internal computation? We study this question\nwith two tasks: given a subject entity, the goal is to predict (a) the ability\nof the model to answer common questions about the entity, and (b) the\nfactuality of responses generated by the model about the entity. Experiments\nwith a variety of LLMs show that KEEN, a simple probe trained over internal\nsubject representations, succeeds at both tasks - strongly correlating with\nboth the QA accuracy of the model per-subject and FActScore, a recent\nfactuality metric in open-ended generation. Moreover, KEEN naturally aligns\nwith the model's hedging behavior and faithfully reflects changes in the\nmodel's knowledge after fine-tuning. Lastly, we show a more interpretable yet\nequally performant variant of KEEN, which highlights a small set of tokens that\ncorrelates with the model's lack of knowledge. Being simple and lightweight,\nKEEN can be leveraged to identify gaps and clusters of entity knowledge in\nLLMs, and guide decisions such as augmenting queries with retrieval.", "paper_summary_zh": "<paragraph>\u70ba\u4e86\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u77e5\u8b58\uff0c\u76ee\u524d\u7684\u65b9\u6cd5\u6703\u67e5\u8a62\u6a21\u578b\uff0c\u7136\u5f8c\u8a55\u4f30\u5176\u7522\u751f\u7684\u56de\u61c9\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u8a62\u554f\u662f\u5426\u53ef\u4ee5\u5728\u6a21\u578b\u7522\u751f\u4efb\u4f55\u6587\u5b57$\\textit{\u4e4b\u524d}$\u9032\u884c\u8a55\u4f30\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u662f\u5426\u53ef\u4ee5\u50c5\u5f9e\u6a21\u578b\u7684\u5167\u90e8\u904b\u7b97\u4f86\u4f30\u8a08\u6a21\u578b\u5c0d\u67d0\u500b\u5be6\u9ad4\u7684\u4e86\u89e3\u7a0b\u5ea6\uff1f\u6211\u5011\u4f7f\u7528\u5169\u500b\u4efb\u52d9\u4f86\u7814\u7a76\u9019\u500b\u554f\u984c\uff1a\u7d66\u5b9a\u4e00\u500b\u4e3b\u984c\u5be6\u9ad4\uff0c\u76ee\u6a19\u662f\u9810\u6e2c (a) \u6a21\u578b\u56de\u7b54\u6709\u95dc\u5be6\u9ad4\u7684\u5e38\u898b\u554f\u984c\u7684\u80fd\u529b\uff0c\u4ee5\u53ca (b) \u6a21\u578b\u7522\u751f\u7684\u6709\u95dc\u5be6\u9ad4\u7684\u56de\u61c9\u7684\u4e8b\u5be6\u6027\u3002\u4f7f\u7528\u5404\u7a2e LLM \u7684\u5be6\u9a57\u8868\u660e\uff0cKEEN \u662f\u4e00\u500b\u8a13\u7df4\u5728\u5167\u90e8\u4e3b\u9ad4\u8868\u793a\u4e0a\u7684\u7c21\u55ae\u63a2\u91dd\uff0c\u5b83\u5728\u5169\u500b\u4efb\u52d9\u4e2d\u90fd\u6210\u529f\u4e86 - \u8207\u6a21\u578b\u7684\u6bcf\u500b\u4e3b\u9ad4\u7684\u554f\u7b54\u6e96\u78ba\u5ea6\u548c FActScore\uff08\u958b\u653e\u5f0f\u751f\u6210\u7684\u6700\u65b0\u4e8b\u5be6\u6027\u6307\u6a19\uff09\u5bc6\u5207\u76f8\u95dc\u3002\u6b64\u5916\uff0cKEEN \u81ea\u7136\u5730\u8207\u6a21\u578b\u7684\u907f\u96aa\u884c\u70ba\u4fdd\u6301\u4e00\u81f4\uff0c\u4e26\u5fe0\u5be6\u5730\u53cd\u6620\u4e86\u5fae\u8abf\u5f8c\u6a21\u578b\u77e5\u8b58\u7684\u8b8a\u5316\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c55\u793a\u4e86 KEEN \u4e00\u500b\u66f4\u5177\u53ef\u89e3\u91cb\u6027\u4f46\u6027\u80fd\u76f8\u540c\u7684\u8b8a\u9ad4\uff0c\u5b83\u5f37\u8abf\u4e86\u4e00\u7d44\u8207\u6a21\u578b\u7f3a\u4e4f\u77e5\u8b58\u76f8\u95dc\u7684\u5c0f\u578b\u4ee3\u5e63\u3002KEEN \u7c21\u55ae\u4e14\u8f15\u91cf\u7d1a\uff0c\u53ef\u7528\u65bc\u8b58\u5225 LLM \u4e2d\u5be6\u9ad4\u77e5\u8b58\u7684\u5dee\u8ddd\u548c\u7fa4\u96c6\uff0c\u4e26\u6307\u5c0e\u6c7a\u7b56\uff0c\u4f8b\u5982\u4f7f\u7528\u64f7\u53d6\u4f86\u64f4\u5145\u67e5\u8a62\u3002</paragraph>", "author": "Daniela Gottesman et.al.", "authors": "Daniela Gottesman, Mor Geva", "id": "2406.12673v1", "paper_url": "http://arxiv.org/abs/2406.12673v1", "repo": "null"}}