{"2411.15244": {"publish_time": "2024-11-22", "title": "Adversarial Prompt Distillation for Vision-Language Models", "paper_summary": "Large pre-trained Vision-Language Models (VLMs) such as Contrastive\nLanguage-Image Pre-Training (CLIP) have been shown to be susceptible to\nadversarial attacks, raising concerns about their deployment in safety-critical\nscenarios like autonomous driving and medical diagnosis. One promising approach\nfor improving the robustness of pre-trained VLMs is Adversarial Prompt Tuning\n(APT), which combines adversarial training with prompt tuning. However,\nexisting APT methods are mostly single-modal methods that design prompt(s) for\nonly the visual or textual modality, limiting their effectiveness in either\nrobustness or clean accuracy. In this work, we propose a novel method called\nAdversarial Prompt Distillation (APD) that combines APT with knowledge\ndistillation to boost the adversarial robustness of CLIP. Specifically, APD is\na bimodal method that adds prompts for both the visual and textual modalities\nwhile leveraging a cleanly pre-trained teacher CLIP model to distill and boost\nthe performance of the student CLIP model on downstream tasks. Extensive\nexperiments on multiple benchmark datasets demonstrate the superiority of our\nAPD over the current state-of-the-art APT methods in terms of both natural and\nadversarial performances. The effectiveness of our APD method validates the\npossibility of using a non-robust teacher to improve the generalization and\nrobustness of VLMs.", "paper_summary_zh": "\u5927\u578b\u9810\u8a13\u7df4\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM)\uff0c\u4f8b\u5982\u5c0d\u6bd4\u8a9e\u8a00\u5f71\u50cf\u9810\u8a13\u7df4 (CLIP)\uff0c\u5df2\u88ab\u8b49\u660e\u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u653b\u64ca\uff0c\u9019\u5f15\u8d77\u4e86\u4eba\u5011\u5c0d\u5176\u5728\u81ea\u52d5\u99d5\u99db\u548c\u91ab\u7642\u8a3a\u65b7\u7b49\u5b89\u5168\u95dc\u9375\u5834\u666f\u4e2d\u90e8\u7f72\u7684\u64d4\u6182\u3002\u4e00\u7a2e\u6709\u5e0c\u671b\u7684\u65b9\u6cd5\u662f\u5c0d\u6297\u63d0\u793a\u8abf\u6574 (APT)\uff0c\u5b83\u7d50\u5408\u4e86\u5c0d\u6297\u8a13\u7df4\u548c\u63d0\u793a\u8abf\u6574\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 APT \u65b9\u6cd5\u5927\u591a\u662f\u55ae\u6a21\u614b\u65b9\u6cd5\uff0c\u50c5\u70ba\u8996\u89ba\u6216\u6587\u672c\u6a21\u614b\u8a2d\u8a08\u63d0\u793a\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u9b6f\u68d2\u6027\u6216\u4e7e\u6de8\u6e96\u78ba\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u7a31\u70ba\u5c0d\u6297\u63d0\u793a\u84b8\u993e (APD) \u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u5c07 APT \u8207\u77e5\u8b58\u84b8\u993e\u76f8\u7d50\u5408\uff0c\u4ee5\u63d0\u9ad8 CLIP \u7684\u5c0d\u6297\u9b6f\u68d2\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cAPD \u662f\u4e00\u7a2e\u96d9\u6a21\u614b\u65b9\u6cd5\uff0c\u5b83\u70ba\u8996\u89ba\u548c\u6587\u672c\u6a21\u614b\u6dfb\u52a0\u63d0\u793a\uff0c\u540c\u6642\u5229\u7528\u9810\u5148\u8a13\u7df4\u597d\u7684\u4e7e\u6de8\u6559\u5e2b CLIP \u6a21\u578b\u4f86\u84b8\u993e\u548c\u63d0\u5347\u5b78\u751f CLIP \u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52d9\u4e0a\u7684\u6027\u80fd\u3002\u5728\u591a\u500b\u57fa\u6e96\u6578\u64da\u96c6\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u7684 APD \u5728\u81ea\u7136\u548c\u5c0d\u6297\u6027\u80fd\u65b9\u9762\u512a\u65bc\u7576\u524d\u6700\u5148\u9032\u7684 APT \u65b9\u6cd5\u3002\u6211\u5011\u7684 APD \u65b9\u6cd5\u7684\u6709\u6548\u6027\u9a57\u8b49\u4e86\u4f7f\u7528\u975e\u9b6f\u68d2\u6559\u5e2b\u4f86\u63d0\u9ad8 VLM \u7684\u6cdb\u5316\u6027\u548c\u9b6f\u68d2\u6027\u7684\u53ef\u80fd\u6027\u3002", "author": "Lin Luo et.al.", "authors": "Lin Luo, Xin Wang, Bojia Zi, Shihao Zhao, Xingjun Ma", "id": "2411.15244v1", "paper_url": "http://arxiv.org/abs/2411.15244v1", "repo": "null"}}