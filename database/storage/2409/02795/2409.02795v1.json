{"2409.02795": {"publish_time": "2024-09-04", "title": "Towards a Unified View of Preference Learning for Large Language Models: A Survey", "paper_summary": "Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of\nthe crucial factors to achieve success is aligning the LLM's output with human\npreferences. This alignment process often requires only a small amount of data\nto efficiently enhance the LLM's performance. While effective, research in this\narea spans multiple domains, and the methods involved are relatively complex to\nunderstand. The relationships between different methods have been\nunder-explored, limiting the development of the preference alignment. In light\nof this, we break down the existing popular alignment strategies into different\ncomponents and provide a unified framework to study the current alignment\nstrategies, thereby establishing connections among them. In this survey, we\ndecompose all the strategies in preference learning into four components:\nmodel, data, feedback, and algorithm. This unified view offers an in-depth\nunderstanding of existing alignment algorithms and also opens up possibilities\nto synergize the strengths of different strategies. Furthermore, we present\ndetailed working examples of prevalent existing algorithms to facilitate a\ncomprehensive understanding for the readers. Finally, based on our unified\nperspective, we explore the challenges and future research directions for\naligning large language models with human preferences.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u73fe\u4e86\u5f37\u5927\u7684\u529f\u80fd\u3002\u5176\u4e2d\u4e00\u500b\u6210\u529f\u7684\u95dc\u9375\u56e0\u7d20\u662f\u5c07 LLM \u7684\u8f38\u51fa\u8207\u4eba\u985e\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u6b64\u8abf\u6574\u904e\u7a0b\u901a\u5e38\u53ea\u9700\u8981\u5c11\u91cf\u8cc7\u6599\u5c31\u80fd\u6709\u6548\u63d0\u5347 LLM \u7684\u6548\u80fd\u3002\u96d6\u7136\u6709\u6548\uff0c\u4f46\u9019\u65b9\u9762\u7684\u7814\u7a76\u6a6b\u8de8\u591a\u500b\u9818\u57df\uff0c\u4e14\u6240\u6d89\u53ca\u7684\u65b9\u6cd5\u76f8\u5c0d\u8907\u96dc\u96e3\u61c2\u3002\u4e0d\u540c\u65b9\u6cd5\u4e4b\u9593\u7684\u95dc\u4fc2\u5c1a\u672a\u5145\u5206\u63a2\u8a0e\uff0c\u9019\u9650\u5236\u4e86\u504f\u597d\u8abf\u6574\u7684\u767c\u5c55\u3002\u6709\u9451\u65bc\u6b64\uff0c\u6211\u5011\u5c07\u73fe\u6709\u7684\u71b1\u9580\u8abf\u6574\u7b56\u7565\u5206\u89e3\u6210\u4e0d\u540c\u7684\u7d44\u6210\u90e8\u5206\uff0c\u4e26\u63d0\u4f9b\u4e00\u500b\u7d71\u4e00\u7684\u67b6\u69cb\u4f86\u7814\u7a76\u76ee\u524d\u7684\u8abf\u6574\u7b56\u7565\uff0c\u5f9e\u800c\u5efa\u7acb\u5b83\u5011\u4e4b\u9593\u7684\u806f\u7e6b\u3002\u5728\u6b64\u8abf\u67e5\u4e2d\uff0c\u6211\u5011\u5c07\u504f\u597d\u5b78\u7fd2\u4e2d\u7684\u6240\u6709\u7b56\u7565\u5206\u89e3\u6210\u56db\u500b\u7d44\u6210\u90e8\u5206\uff1a\u6a21\u578b\u3001\u8cc7\u6599\u3001\u56de\u994b\u548c\u6f14\u7b97\u6cd5\u3002\u6b64\u7d71\u4e00\u89c0\u9ede\u63d0\u4f9b\u4e86\u5c0d\u73fe\u6709\u8abf\u6574\u6f14\u7b97\u6cd5\u7684\u6df1\u5165\u4e86\u89e3\uff0c\u4e5f\u958b\u555f\u4e86\u5354\u8abf\u4e0d\u540c\u7b56\u7565\u512a\u52e2\u7684\u53ef\u80fd\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u73fe\u6709\u76db\u884c\u6f14\u7b97\u6cd5\u7684\u8a73\u7d30\u5de5\u4f5c\u7bc4\u4f8b\uff0c\u4ee5\u4fc3\u9032\u8b80\u8005\u5168\u9762\u4e86\u89e3\u3002\u6700\u5f8c\uff0c\u6839\u64da\u6211\u5011\u7684\u7d71\u4e00\u89c0\u9ede\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u8207\u4eba\u985e\u504f\u597d\u8abf\u6574\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u6311\u6230\u548c\u672a\u4f86\u7684\u7814\u7a76\u65b9\u5411\u3002", "author": "Bofei Gao et.al.", "authors": "Bofei Gao, Feifan Song, Yibo Miao, Zefan Cai, Zhe Yang, Liang Chen, Helan Hu, Runxin Xu, Qingxiu Dong, Ce Zheng, Wen Xiao, Ge Zhang, Daoguang Zan, Keming Lu, Bowen Yu, Dayiheng Liu, Zeyu Cui, Jian Yang, Lei Sha, Houfeng Wang, Zhifang Sui, Peiyi Wang, Tianyu Liu, Baobao Chang", "id": "2409.02795v1", "paper_url": "http://arxiv.org/abs/2409.02795v1", "repo": "null"}}