{"2407.19568": {"publish_time": "2024-07-28", "title": "Are LLMs Good Annotators for Discourse-level Event Relation Extraction?", "paper_summary": "Large Language Models (LLMs) have demonstrated proficiency in a wide array of\nnatural language processing tasks. However, its effectiveness over\ndiscourse-level event relation extraction (ERE) tasks remains unexplored. In\nthis paper, we assess the effectiveness of LLMs in addressing discourse-level\nERE tasks characterized by lengthy documents and intricate relations\nencompassing coreference, temporal, causal, and subevent types. Evaluation is\nconducted using an commercial model, GPT-3.5, and an open-source model,\nLLaMA-2. Our study reveals a notable underperformance of LLMs compared to the\nbaseline established through supervised learning. Although Supervised\nFine-Tuning (SFT) can improve LLMs performance, it does not scale well compared\nto the smaller supervised baseline model. Our quantitative and qualitative\nanalysis shows that LLMs have several weaknesses when applied for extracting\nevent relations, including a tendency to fabricate event mentions, and failures\nto capture transitivity rules among relations, detect long distance relations,\nor comprehend contexts with dense event mentions.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u793a\u51fa\u5728\u5e7f\u6cdb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u5177\u6709\u719f\u7ec3\u5ea6\u3002\u7136\u800c\uff0c\u5176\u5728\u8bdd\u8bed\u5c42\u9762\u4e8b\u4ef6\u5173\u7cfb\u62bd\u53d6 (ERE) \u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u4ecd\u672a\u5f97\u5230\u63a2\u7d22\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86 LLM \u5728\u89e3\u51b3\u8bdd\u8bed\u5c42\u9762 ERE \u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u8fd9\u4e9b\u4efb\u52a1\u7684\u7279\u70b9\u662f\u7bc7\u5e45\u8f83\u957f\u4e14\u5305\u542b\u4ee3\u8bcd\u3001\u65f6\u95f4\u3001\u56e0\u679c\u548c\u5b50\u4e8b\u4ef6\u7c7b\u578b\u7b49\u590d\u6742\u5173\u7cfb\u3002\u8bc4\u4f30\u4f7f\u7528\u5546\u4e1a\u6a21\u578b GPT-3.5 \u548c\u5f00\u6e90\u6a21\u578b LLaMA-2 \u8fdb\u884c\u3002\u6211\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u5efa\u7acb\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0cLLM \u7684\u8868\u73b0\u660e\u663e\u4e0d\u4f73\u3002\u5c3d\u7ba1\u76d1\u7763\u5fae\u8c03 (SFT) \u53ef\u4ee5\u63d0\u9ad8 LLM \u7684\u6027\u80fd\uff0c\u4f46\u4e0e\u8f83\u5c0f\u7684\u76d1\u7763\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0c\u5176\u6269\u5c55\u6027\u4e0d\u4f73\u3002\u6211\u4eec\u7684\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u8868\u660e\uff0cLLM \u5728\u7528\u4e8e\u63d0\u53d6\u4e8b\u4ef6\u5173\u7cfb\u65f6\u5b58\u5728\u82e5\u5e72\u5f31\u70b9\uff0c\u5305\u62ec\u7f16\u9020\u4e8b\u4ef6\u63d0\u53ca\u7684\u503e\u5411\uff0c\u4ee5\u53ca\u672a\u80fd\u6355\u83b7\u5173\u7cfb\u4e4b\u95f4\u7684\u4f20\u9012\u6027\u89c4\u5219\u3001\u68c0\u6d4b\u957f\u8ddd\u79bb\u5173\u7cfb\u6216\u7406\u89e3\u5305\u542b\u5bc6\u96c6\u4e8b\u4ef6\u63d0\u53ca\u7684\u4e0a\u4e0b\u6587\u3002", "author": "Kangda Wei et.al.", "authors": "Kangda Wei, Aayush Gautam, Ruihong Huang", "id": "2407.19568v1", "paper_url": "http://arxiv.org/abs/2407.19568v1", "repo": "null"}}