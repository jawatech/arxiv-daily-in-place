{"2502.09051": {"publish_time": "2025-02-13", "title": "AIDE: Agentically Improve Visual Language Model with Domain Experts", "paper_summary": "The enhancement of Visual Language Models (VLMs) has traditionally relied on\nknowledge distillation from larger, more capable models. This dependence\ncreates a fundamental bottleneck for improving state-of-the-art systems,\nparticularly when no superior models exist. We introduce AIDE (Agentic\nImprovement through Domain Experts), a novel framework that enables VLMs to\nautonomously enhance their capabilities by leveraging specialized domain expert\nmodels. AIDE operates through a four-stage process: (1) identifying instances\nfor refinement, (2) engaging domain experts for targeted analysis, (3)\nsynthesizing expert outputs with existing data, and (4) integrating enhanced\ninstances into the training pipeline. Experiments on multiple benchmarks,\nincluding MMMU, MME, MMBench, etc., demonstrate AIDE's ability to achieve\nnotable performance gains without relying on larger VLMs nor human supervision.\nOur framework provides a scalable, resource-efficient approach to continuous\nVLM improvement, addressing critical limitations in current methodologies,\nparticularly valuable when larger models are unavailable to access.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u7684\u589e\u5f37\u50b3\u7d71\u4e0a\u4f9d\u8cf4\u65bc\u5f9e\u66f4\u5927\u3001\u529f\u80fd\u66f4\u5f37\u5927\u7684\u6a21\u578b\u4e2d\u9032\u884c\u77e5\u8b58\u8403\u53d6\u3002\u9019\u7a2e\u4f9d\u8cf4\u6027\u6703\u9020\u6210\u6539\u5584\u6700\u5148\u9032\u7cfb\u7d71\u7684\u57fa\u672c\u74f6\u9838\uff0c\u5c24\u5176\u5728\u6c92\u6709\u66f4\u512a\u8d8a\u7684\u6a21\u578b\u6642\u3002\u6211\u5011\u5f15\u9032 AIDE\uff08\u900f\u904e\u9818\u57df\u5c08\u5bb6\u9032\u884c\u4ee3\u7406\u5f0f\u6539\u5584\uff09\uff0c\u4e00\u500b\u5275\u65b0\u7684\u67b6\u69cb\uff0c\u8b93 VLM \u80fd\u5920\u900f\u904e\u5229\u7528\u5c08\u696d\u7684\u9818\u57df\u5c08\u5bb6\u6a21\u578b\uff0c\u81ea\u4e3b\u589e\u5f37\u5176\u529f\u80fd\u3002AIDE \u900f\u904e\u56db\u968e\u6bb5\u6d41\u7a0b\u904b\u4f5c\uff1a(1) \u8b58\u5225\u9700\u8981\u6539\u5584\u7684\u5be6\u4f8b\uff0c(2) \u8058\u8acb\u9818\u57df\u5c08\u5bb6\u9032\u884c\u6709\u91dd\u5c0d\u6027\u7684\u5206\u6790\uff0c(3) \u5c07\u5c08\u5bb6\u8f38\u51fa\u8207\u73fe\u6709\u8cc7\u6599\u7d9c\u5408\uff0c\u4ee5\u53ca (4) \u5c07\u589e\u5f37\u7684\u5be6\u4f8b\u6574\u5408\u5230\u8a13\u7df4\u6d41\u7a0b\u4e2d\u3002\u5728\u591a\u500b\u57fa\u6e96\u6e2c\u8a66\u4e0a\u7684\u5be6\u9a57\uff0c\u5305\u62ec MMMU\u3001MME\u3001MMBench \u7b49\uff0c\u8b49\u660e\u4e86 AIDE \u80fd\u5920\u5728\u4e0d\u4f9d\u8cf4\u66f4\u5927\u578b\u7684 VLM \u6216\u4eba\u5de5\u76e3\u7763\u7684\u60c5\u6cc1\u4e0b\uff0c\u5be6\u73fe\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\u3002\u6211\u5011\u7684\u67b6\u69cb\u63d0\u4f9b\u4e86\u4e00\u500b\u53ef\u64f4\u5145\u3001\u8cc7\u6e90\u6548\u7387\u9ad8\u7684\u6301\u7e8c VLM \u6539\u9032\u65b9\u6cd5\uff0c\u89e3\u6c7a\u4e86\u7576\u524d\u65b9\u6cd5\u4e2d\u7684\u95dc\u9375\u9650\u5236\uff0c\u7279\u5225\u662f\u5728\u7121\u6cd5\u53d6\u5f97\u5927\u578b\u6a21\u578b\u6642\uff0c\u9019\u4e00\u9ede\u7279\u5225\u6709\u50f9\u503c\u3002", "author": "Ming-Chang Chiu et.al.", "authors": "Ming-Chang Chiu, Fuxiao Liu, Karan Sapra, Andrew Tao, Yaser Jacoob, Xuezhe Ma, Zhiding Yu, Guilin Liu", "id": "2502.09051v1", "paper_url": "http://arxiv.org/abs/2502.09051v1", "repo": "null"}}