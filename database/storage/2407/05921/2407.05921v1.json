{"2407.05921": {"publish_time": "2024-07-08", "title": "TAPVid-3D: A Benchmark for Tracking Any Point in 3D", "paper_summary": "We introduce a new benchmark, TAPVid-3D, for evaluating the task of\nlong-range Tracking Any Point in 3D (TAP-3D). While point tracking in two\ndimensions (TAP) has many benchmarks measuring performance on real-world\nvideos, such as TAPVid-DAVIS, three-dimensional point tracking has none. To\nthis end, leveraging existing footage, we build a new benchmark for 3D point\ntracking featuring 4,000+ real-world videos, composed of three different data\nsources spanning a variety of object types, motion patterns, and indoor and\noutdoor environments. To measure performance on the TAP-3D task, we formulate a\ncollection of metrics that extend the Jaccard-based metric used in TAP to\nhandle the complexities of ambiguous depth scales across models, occlusions,\nand multi-track spatio-temporal smoothness. We manually verify a large sample\nof trajectories to ensure correct video annotations, and assess the current\nstate of the TAP-3D task by constructing competitive baselines using existing\ntracking models. We anticipate this benchmark will serve as a guidepost to\nimprove our ability to understand precise 3D motion and surface deformation\nfrom monocular video. Code for dataset download, generation, and model\nevaluation is available at https://tapvid3d.github.io", "paper_summary_zh": "<paragraph>\u6211\u5011\u5f15\u5165\u4e00\u500b\u65b0\u7684\u57fa\u6e96\u6e2c\u8a66 TAPVid-3D\uff0c\u7528\u65bc\u8a55\u4f30\u5728 3D \u4e2d\u8ffd\u8e64\u4efb\u4f55\u9ede\u7684\u9060\u8ddd\u96e2\u4efb\u52d9 (TAP-3D)\u3002\u96d6\u7136\u5728\u5169\u500b\u7dad\u5ea6 (TAP) \u4e2d\u7684\u9ede\u8ffd\u8e64\u6709\u8a31\u591a\u57fa\u6e96\u6e2c\u8a66\u7528\u65bc\u8861\u91cf\u771f\u5be6\u4e16\u754c\u5f71\u7247\u7684\u6548\u80fd\uff0c\u4f8b\u5982 TAPVid-DAVIS\uff0c\u4f46\u4e09\u7dad\u9ede\u8ffd\u8e64\u537b\u6c92\u6709\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5229\u7528\u73fe\u6709\u7684\u7d20\u6750\uff0c\u5efa\u7acb\u4e86\u4e00\u500b\u65b0\u7684 3D \u9ede\u8ffd\u8e64\u57fa\u6e96\u6e2c\u8a66\uff0c\u5176\u4e2d\u5305\u542b 4,000 \u591a\u500b\u771f\u5be6\u4e16\u754c\u5f71\u7247\uff0c\u7531\u4e09\u500b\u4e0d\u540c\u7684\u8cc7\u6599\u4f86\u6e90\u7d44\u6210\uff0c\u6db5\u84cb\u5404\u7a2e\u7269\u4ef6\u985e\u578b\u3001\u52d5\u4f5c\u6a21\u5f0f\uff0c\u4ee5\u53ca\u5ba4\u5167\u548c\u5ba4\u5916\u74b0\u5883\u3002\u70ba\u4e86\u8861\u91cf TAP-3D \u4efb\u52d9\u7684\u6548\u80fd\uff0c\u6211\u5011\u5236\u5b9a\u4e86\u4e00\u7cfb\u5217\u6307\u6a19\uff0c\u5c07 TAP \u4e2d\u4f7f\u7528\u7684 Jaccard \u57fa\u65bc\u6307\u6a19\u5ef6\u4f38\uff0c\u4ee5\u8655\u7406\u8de8\u6a21\u578b\u7684\u6a21\u7cca\u6df1\u5ea6\u5c3a\u5ea6\u3001\u906e\u64cb\uff0c\u4ee5\u53ca\u591a\u8ecc\u6642\u7a7a\u5e73\u6ed1\u5ea6\u7684\u8907\u96dc\u6027\u3002\u6211\u5011\u624b\u52d5\u9a57\u8b49\u5927\u91cf\u8ecc\u8de1\uff0c\u4ee5\u78ba\u4fdd\u6b63\u78ba\u7684\u5f71\u7247\u8a3b\u89e3\uff0c\u4e26\u4f7f\u7528\u73fe\u6709\u7684\u8ffd\u8e64\u6a21\u578b\u5efa\u7acb\u7af6\u722d\u6027\u7684\u57fa\u6e96\u7dda\uff0c\u4ee5\u8a55\u4f30 TAP-3D \u4efb\u52d9\u7684\u7576\u524d\u72c0\u614b\u3002\u6211\u5011\u9810\u671f\u9019\u500b\u57fa\u6e96\u6e2c\u8a66\u5c07\u4f5c\u70ba\u4e00\u500b\u6307\u5f15\uff0c\u4ee5\u6539\u5584\u6211\u5011\u5f9e\u55ae\u773c\u5f71\u7247\u4e2d\u4e86\u89e3\u7cbe\u78ba 3D \u904b\u52d5\u548c\u8868\u9762\u8b8a\u5f62\u7684\u7684\u80fd\u529b\u3002\u8cc7\u6599\u96c6\u4e0b\u8f09\u3001\u7522\u751f\u548c\u6a21\u578b\u8a55\u4f30\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://tapvid3d.github.io \u53d6\u5f97</paragraph>", "author": "Skanda Koppula et.al.", "authors": "Skanda Koppula, Ignacio Rocco, Yi Yang, Joe Heyward, Jo\u00e3o Carreira, Andrew Zisserman, Gabriel Brostow, Carl Doersch", "id": "2407.05921v1", "paper_url": "http://arxiv.org/abs/2407.05921v1", "repo": "null"}}