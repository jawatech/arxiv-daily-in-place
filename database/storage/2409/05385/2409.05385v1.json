{"2409.05385": {"publish_time": "2024-09-09", "title": "Towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models", "paper_summary": "The development of LLMs has greatly enhanced the intelligence and fluency of\nquestion answering, while the emergence of retrieval enhancement has enabled\nmodels to better utilize external information. However, the presence of noise\nand errors in retrieved information poses challenges to the robustness of LLMs.\nIn this work, to evaluate the model's performance under multiple interferences,\nwe first construct a dataset based on machine reading comprehension datasets\nsimulating various scenarios, including critical information absence, noise,\nand conflicts. To address the issue of model accuracy decline caused by noisy\nexternal information, we propose a data augmentation-based fine-tuning method\nto enhance LLM's robustness against noise. Additionally, contrastive learning\napproach is utilized to preserve the model's discrimination capability of\nexternal information. We have conducted experiments on both existing LLMs and\nour approach, the results are evaluated by GPT-4, which indicates that our\nproposed methods improve model robustness while strengthening the model's\ndiscrimination capability.", "paper_summary_zh": "\u5927\u8a9e\u8a00\u6a21\u578b\u7684\u767c\u5c55\u5927\u5e45\u63d0\u5347\u4e86\u554f\u7b54\u7684\u667a\u80fd\u5316\u548c\u6d41\u66a2\u5ea6\uff0c\u800c\u6aa2\u7d22\u589e\u5f37\u7684\u51fa\u73fe\u8b93\u6a21\u578b\u80fd\u66f4\u597d\u5730\u5229\u7528\u5916\u90e8\u8cc7\u8a0a\u3002\u7136\u800c\uff0c\u6aa2\u7d22\u8cc7\u8a0a\u4e2d\u51fa\u73fe\u7684\u96dc\u8a0a\u548c\u932f\u8aa4\u5c0d\u5927\u8a9e\u8a00\u6a21\u578b\u7684\u7a69\u5065\u6027\u69cb\u6210\u6311\u6230\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u70ba\u4e86\u8a55\u4f30\u6a21\u578b\u5728\u591a\u7a2e\u5e72\u64fe\u4e0b\u7684\u8868\u73fe\uff0c\u6211\u5011\u9996\u5148\u6839\u64da\u6a5f\u5668\u95b1\u8b80\u7406\u89e3\u8cc7\u6599\u96c6\u5efa\u69cb\u4e00\u500b\u8cc7\u6599\u96c6\uff0c\u6a21\u64ec\u5404\u7a2e\u60c5\u5883\uff0c\u5305\u62ec\u95dc\u9375\u8cc7\u8a0a\u7f3a\u5931\u3001\u96dc\u8a0a\u548c\u885d\u7a81\u3002\u70ba\u4e86\u89e3\u6c7a\u96dc\u8a0a\u5916\u90e8\u8cc7\u8a0a\u5c0e\u81f4\u6a21\u578b\u6e96\u78ba\u5ea6\u4e0b\u964d\u7684\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u8cc7\u6599\u64f4\u5145\u7684\u5fae\u8abf\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f37\u5927\u8a9e\u8a00\u6a21\u578b\u5c0d\u96dc\u8a0a\u7684\u7a69\u5065\u6027\u3002\u6b64\u5916\uff0c\u5229\u7528\u5c0d\u6bd4\u5b78\u7fd2\u65b9\u6cd5\u4f86\u4fdd\u6301\u6a21\u578b\u5c0d\u5916\u90e8\u8cc7\u8a0a\u7684\u8fa8\u5225\u80fd\u529b\u3002\u6211\u5011\u5df2\u91dd\u5c0d\u73fe\u6709\u7684 LLM \u548c\u6211\u5011\u7684\u505a\u6cd5\u9032\u884c\u5be6\u9a57\uff0c\u7d50\u679c\u7531 GPT-4 \u8a55\u4f30\uff0c\u9019\u8868\u660e\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u589e\u5f37\u6a21\u578b\u7684\u8fa8\u5225\u80fd\u529b\u7684\u540c\u6642\uff0c\u4e5f\u6539\u5584\u4e86\u6a21\u578b\u7684\u7a69\u5065\u6027\u3002", "author": "Hong Xingyun Hong et.al.", "authors": "Hong Xingyun Hong, Shao Yan Shao, Wang Zhilin Wang, Duan Manni Duan, Jin Xiongnan", "id": "2409.05385v1", "paper_url": "http://arxiv.org/abs/2409.05385v1", "repo": "null"}}