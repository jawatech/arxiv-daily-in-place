{"2407.18423": {"publish_time": "2024-07-25", "title": "HDL-GPT: High-Quality HDL is All You Need", "paper_summary": "This paper presents Hardware Description Language Generative Pre-trained\nTransformers (HDL-GPT), a novel approach that leverages the vast repository of\nopen-source High Definition Language (HDL) codes to train superior quality\nlarge code models. The core premise of this paper is the hypothesis that\nhigh-quality HDL is all you need to create models with exceptional performance\nand broad zero-shot generalization abilities. The paper elucidates the methods\nemployed for the curation and augmentation of large corpora from open-source\nHDL code, transforming highly variable quality data into high-quality data\nthrough careful prompting and context maintenance. We demonstrate that the\ncareful selection, filtering, and augmentation of data across HDLs can yield\npowerful models that surpass current state-of-the-art models. We also explore\nthe impact of different fine-tuning methods on the quality of results. We\ndescribe experimental results across a range of fine-tuned SOTA LLMs,\nsubstantiating our claims. We demonstrate improvements of 50% to 200% over SOTA\nHDL models on current benchmarks in tasks ranging from HDL circuit\nexplanations, code generation, formal and simulation testbench creation,\ntriaging bugs, and fixing them. HDL-GPT opens new avenues for the development\nof advanced model training techniques for circuit design tasks.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u786c\u9ad4\u63cf\u8ff0\u8a9e\u8a00\u751f\u6210\u5f0f\u9810\u8a13\u7df4\u8f49\u63db\u5668 (HDL-GPT)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u91cf\u958b\u6e90\u9ad8\u5b9a\u7fa9\u8a9e\u8a00 (HDL) \u7a0b\u5f0f\u78bc\u4f86\u8a13\u7df4\u512a\u8cea\u7684\u5927\u578b\u7a0b\u5f0f\u78bc\u6a21\u578b\u3002\u672c\u6587\u7684\u6838\u5fc3\u524d\u63d0\u662f\u9ad8\u54c1\u8cea\u7684 HDL \u662f\u5efa\u7acb\u5177\u6709\u5353\u8d8a\u6548\u80fd\u548c\u5ee3\u6cdb\u96f6\u6b21\u5b78\u7fd2\u6982\u5316\u80fd\u529b\u6a21\u578b\u7684\u552f\u4e00\u8981\u7d20\u3002\u672c\u6587\u95e1\u660e\u4e86\u5f9e\u958b\u6e90 HDL \u7a0b\u5f0f\u78bc\u7b56\u5c55\u548c\u64f4\u5145\u5927\u578b\u8a9e\u6599\u5eab\u6240\u4f7f\u7528\u7684\u65b9\u6cd5\uff0c\u900f\u904e\u4ed4\u7d30\u63d0\u793a\u548c\u8108\u7d61\u7dad\u8b77\uff0c\u5c07\u54c1\u8cea\u9ad8\u5ea6\u8b8a\u7570\u7684\u8cc7\u6599\u8f49\u63db\u6210\u9ad8\u54c1\u8cea\u8cc7\u6599\u3002\u6211\u5011\u8b49\u660e\u4e86\u4ed4\u7d30\u9078\u64c7\u3001\u7be9\u9078\u548c\u64f4\u5145 HDL \u4e2d\u7684\u8cc7\u6599\u53ef\u4ee5\u7522\u751f\u5f37\u5927\u7684\u6a21\u578b\uff0c\u8d85\u8d8a\u73fe\u6709\u7684\u6700\u5148\u9032\u6a21\u578b\u3002\u6211\u5011\u4e5f\u63a2\u8a0e\u4e86\u4e0d\u540c\u5fae\u8abf\u65b9\u6cd5\u5c0d\u7d50\u679c\u54c1\u8cea\u7684\u5f71\u97ff\u3002\u6211\u5011\u63cf\u8ff0\u4e86\u91dd\u5c0d\u4e00\u7cfb\u5217\u5fae\u8abf\u904e\u7684 SOTA LLM \u7684\u5be6\u9a57\u7d50\u679c\uff0c\u4ee5\u8b49\u5be6\u6211\u5011\u7684\u8aaa\u6cd5\u3002\u6211\u5011\u8b49\u660e\u4e86\u5728\u5f9e HDL \u96fb\u8def\u8aaa\u660e\u3001\u7a0b\u5f0f\u78bc\u7522\u751f\u3001\u6b63\u5f0f\u548c\u6a21\u64ec\u6e2c\u8a66\u5e73\u53f0\u5efa\u7acb\u3001\u5206\u985e\u932f\u8aa4\u5230\u4fee\u6b63\u932f\u8aa4\u7b49\u4efb\u52d9\u7684\u73fe\u6709\u57fa\u6e96\u4e2d\uff0cHDL-GPT \u6bd4 SOTA HDL \u6a21\u578b\u9032\u6b65\u4e86 50% \u81f3 200%\u3002HDL-GPT \u70ba\u96fb\u8def\u8a2d\u8a08\u4efb\u52d9\u7684\u9032\u968e\u6a21\u578b\u8a13\u7df4\u6280\u8853\u958b\u767c\u958b\u555f\u4e86\u65b0\u9014\u5f91\u3002", "author": "Bhuvnesh Kumar et.al.", "authors": "Bhuvnesh Kumar, Saurav Nanda, Ganapathy Parthasarathy, Pawan Patil, Austin Tsai, Parivesh Choudhary", "id": "2407.18423v1", "paper_url": "http://arxiv.org/abs/2407.18423v1", "repo": "null"}}