{"2405.03852": {"publish_time": "2024-05-06", "title": "VSA4VQA: Scaling a Vector Symbolic Architecture to Visual Question Answering on Natural Images", "paper_summary": "While Vector Symbolic Architectures (VSAs) are promising for modelling\nspatial cognition, their application is currently limited to artificially\ngenerated images and simple spatial queries. We propose VSA4VQA - a novel 4D\nimplementation of VSAs that implements a mental representation of natural\nimages for the challenging task of Visual Question Answering (VQA). VSA4VQA is\nthe first model to scale a VSA to complex spatial queries. Our method is based\non the Semantic Pointer Architecture (SPA) to encode objects in a\nhyperdimensional vector space. To encode natural images, we extend the SPA to\ninclude dimensions for object's width and height in addition to their spatial\nlocation. To perform spatial queries we further introduce learned spatial query\nmasks and integrate a pre-trained vision-language model for answering\nattribute-related questions. We evaluate our method on the GQA benchmark\ndataset and show that it can effectively encode natural images, achieving\ncompetitive performance to state-of-the-art deep learning methods for zero-shot\nVQA.", "paper_summary_zh": "\u96d6\u7136\u5411\u91cf\u7b26\u865f\u67b6\u69cb (VSA) \u5c0d\u65bc\u5efa\u6a21\u7a7a\u9593\u8a8d\u77e5\u5f88\u6709\u524d\u666f\uff0c\u4f46\u5176\u61c9\u7528\u76ee\u524d\u50c5\u9650\u65bc\u4eba\u5de5\u7522\u751f\u7684\u5716\u50cf\u548c\u7c21\u55ae\u7684\u7a7a\u9593\u67e5\u8a62\u3002\u6211\u5011\u63d0\u51fa VSA4VQA - \u4e00\u7a2e VSA \u7684\u65b0\u578b 4D \u5be6\u4f5c\uff0c\u7528\u65bc\u5be6\u4f5c\u81ea\u7136\u5f71\u50cf\u7684\u5fc3\u667a\u8868\u5fb5\uff0c\u4ee5\u57f7\u884c\u5177\u6311\u6230\u6027\u7684\u8996\u89ba\u554f\u7b54 (VQA) \u4efb\u52d9\u3002VSA4VQA \u662f\u7b2c\u4e00\u500b\u5c07 VSA \u64f4\u5c55\u5230\u8907\u96dc\u7a7a\u9593\u67e5\u8a62\u7684\u6a21\u578b\u3002\u6211\u5011\u7684\u505a\u6cd5\u5efa\u69cb\u65bc\u8a9e\u610f\u6307\u6a19\u67b6\u69cb (SPA)\uff0c\u7528\u65bc\u5728\u8d85\u7dad\u5411\u91cf\u7a7a\u9593\u4e2d\u7de8\u78bc\u7269\u4ef6\u3002\u70ba\u4e86\u7de8\u78bc\u81ea\u7136\u5f71\u50cf\uff0c\u6211\u5011\u5c07 SPA \u5ef6\u4f38\uff0c\u9664\u4e86\u7a7a\u9593\u4f4d\u7f6e\u5916\uff0c\u9084\u5305\u62ec\u7269\u4ef6\u7684\u5bec\u5ea6\u548c\u9ad8\u5ea6\u7dad\u5ea6\u3002\u70ba\u4e86\u57f7\u884c\u7a7a\u9593\u67e5\u8a62\uff0c\u6211\u5011\u9032\u4e00\u6b65\u5f15\u5165\u5df2\u5b78\u7fd2\u7684\u7a7a\u9593\u67e5\u8a62\u906e\u7f69\uff0c\u4e26\u6574\u5408\u9810\u5148\u8a13\u7df4\u597d\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\uff0c\u4ee5\u56de\u7b54\u8207\u5c6c\u6027\u76f8\u95dc\u7684\u554f\u984c\u3002\u6211\u5011\u5728 GQA \u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u8a55\u4f30\u6211\u5011\u7684\u505a\u6cd5\uff0c\u4e26\u986f\u793a\u5b83\u53ef\u4ee5\u6709\u6548\u5730\u7de8\u78bc\u81ea\u7136\u5f71\u50cf\uff0c\u5728\u96f6\u6b21\u5b78\u7fd2 VQA \u4e2d\u9054\u6210\u8207\u6700\u5148\u9032\u7684\u6df1\u5ea6\u5b78\u7fd2\u65b9\u6cd5\u76f8\u8fd1\u7684\u6548\u80fd\u3002", "author": "Anna Penzkofer et.al.", "authors": "Anna Penzkofer, Lei Shi, Andreas Bulling", "id": "2405.03852v1", "paper_url": "http://arxiv.org/abs/2405.03852v1", "repo": "null"}}