
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-09**|**[MASK] is All You Need**|Vincent Tao Hu et.al.|[2412.06787v1](http://arxiv.org/abs/2412.06787v1)|null|
|**2024-12-09**|**P3-PO: Prescriptive Point Priors for Visuo-Spatial Generalization of Robot Policies**|Mara Levy et.al.|[2412.06784v1](http://arxiv.org/abs/2412.06784v1)|null|
|**2024-12-09**|**AnyBimanual: Transferring Unimanual Policy for General Bimanual Manipulation**|Guanxing Lu et.al.|[2412.06779v1](http://arxiv.org/abs/2412.06779v1)|null|
|**2024-12-09**|**Delve into Visual Contrastive Decoding for Hallucination Mitigation of Large Vision-Language Models**|Yi-Lun Lee et.al.|[2412.06775v1](http://arxiv.org/abs/2412.06775v1)|[link](https://github.com/yilunlee/vcd_analysis)|
|**2024-12-09**|**Visual Lexicon: Rich Image Features in Language Space**|XuDong Wang et.al.|[2412.06774v1](http://arxiv.org/abs/2412.06774v1)|null|
|**2024-12-09**|**Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty**|Meera Hahn et.al.|[2412.06771v1](http://arxiv.org/abs/2412.06771v1)|[link](https://github.com/google-deepmind/proactive_t2i_agents)|
|**2024-12-09**|**Training Large Language Models to Reason in a Continuous Latent Space**|Shibo Hao et.al.|[2412.06769v1](http://arxiv.org/abs/2412.06769v1)|null|
|**2024-12-09**|**Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models**|Neel Jain et.al.|[2412.06748v1](http://arxiv.org/abs/2412.06748v1)|null|
|**2024-12-09**|**ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended Capabilities**|Adhiraj Ghosh et.al.|[2412.06745v1](http://arxiv.org/abs/2412.06745v1)|null|
|**2024-12-09**|**ContRail: A Framework for Realistic Railway Image Synthesis using ControlNet**|Andrei-Robert Alexandrescu et.al.|[2412.06742v1](http://arxiv.org/abs/2412.06742v1)|null|
|**2024-12-09**|**JAPAGEN: Efficient Few/Zero-shot Learning via Japanese Training Dataset Generation with LLM**|Takuro Fujii et.al.|[2412.06738v1](http://arxiv.org/abs/2412.06738v1)|null|
|**2024-12-09**|**AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and Benchmark**|Lan Li et.al.|[2412.06724v1](http://arxiv.org/abs/2412.06724v1)|null|
|**2024-12-09**|**Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**|Sahil Sethi et.al.|[2412.06717v1](http://arxiv.org/abs/2412.06717v1)|null|
|**2024-12-09**|**How to Merge Your Multimodal Models Over Time?**|Sebastian Dziadzio et.al.|[2412.06712v1](http://arxiv.org/abs/2412.06712v1)|null|
|**2024-12-09**|**Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**|Aqib Nazir Mir et.al.|[2412.06709v1](http://arxiv.org/abs/2412.06709v1)|null|
|**2024-12-09**|**Digital Transformation in the Water Distribution System based on the Digital Twins Concept**|MohammadHossein Homaei et.al.|[2412.06694v1](http://arxiv.org/abs/2412.06694v1)|null|
|**2024-12-09**|**OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large Language Model and its Omni-Extensions**|Yi-Kai Zhang et.al.|[2412.06693v1](http://arxiv.org/abs/2412.06693v1)|null|
|**2024-12-09**|**Policy Agnostic RL: Offline RL and Online RL Fine-Tuning of Any Class and Backbone**|Max Sobol Mark et.al.|[2412.06685v1](http://arxiv.org/abs/2412.06685v1)|null|
|**2024-12-09**|**Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework**|Tianming Liu et.al.|[2412.06681v1](http://arxiv.org/abs/2412.06681v1)|null|
|**2024-12-09**|**I Don't Know: Explicit Modeling of Uncertainty with an [IDK] Token**|Roi Cohen et.al.|[2412.06676v1](http://arxiv.org/abs/2412.06676v1)|null|
|**2024-12-09**|**GEAR: A Simple GENERATE, EMBED, AVERAGE AND RANK Approach for Unsupervised Reverse Dictionary**|Fatemah Almeman et.al.|[2412.06654v1](http://arxiv.org/abs/2412.06654v1)|null|
|**2024-12-09**|**Detecting Facial Image Manipulations with Multi-Layer CNN Models**|Alejandro Marco Montejano et.al.|[2412.06643v1](http://arxiv.org/abs/2412.06643v1)|null|
|**2024-12-09**|**Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**|Sooyong Jang et.al.|[2412.06624v1](http://arxiv.org/abs/2412.06624v1)|null|
|**2024-12-09**|**Copyright-Protected Language Generation via Adaptive Model Fusion**|Javier Abad et.al.|[2412.06619v1](http://arxiv.org/abs/2412.06619v1)|[link](https://github.com/jaabmar/cp_fuse)|
|**2024-12-09**|**Towards Controllable Speech Synthesis in the Era of Large Language Models: A Survey**|Tianxin Xie et.al.|[2412.06602v1](http://arxiv.org/abs/2412.06602v1)|[link](https://github.com/imxtx/awesome-controllabe-speech-synthesis)|
|**2024-12-09**|**Anchoring Bias in Large Language Models: An Experimental Study**|Jiaxu Lou et.al.|[2412.06593v1](http://arxiv.org/abs/2412.06593v1)|null|
|**2024-12-09**|**EmoSpeech: A Corpus of Emotionally Rich and Contextually Detailed Speech Annotations**|Weizhen Bian et.al.|[2412.06581v1](http://arxiv.org/abs/2412.06581v1)|null|
|**2024-12-09**|**Data Quality Enhancement on the Basis of Diversity with Large Language Models for Text Classification: Uncovered, Difficult, and Noisy**|Min Zeng et.al.|[2412.06575v1](http://arxiv.org/abs/2412.06575v1)|null|
|**2024-12-09**|**ProcessBench: Identifying Process Errors in Mathematical Reasoning**|Chujie Zheng et.al.|[2412.06559v1](http://arxiv.org/abs/2412.06559v1)|null|
|**2024-12-09**|**Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families**|Felipe Maia Polo et.al.|[2412.06540v1](http://arxiv.org/abs/2412.06540v1)|null|
|**2024-12-09**|**Understanding Factual Recall in Transformers via Associative Memories**|Eshaan Nichani et.al.|[2412.06538v1](http://arxiv.org/abs/2412.06538v1)|null|
|**2024-12-09**|**HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**|Jiayan Chen et.al.|[2412.06530v1](http://arxiv.org/abs/2412.06530v1)|null|
|**2024-12-09**|**The Fusion of Large Language Models and Formal Methods for Trustworthy AI Agents: A Roadmap**|Yedi Zhang et.al.|[2412.06512v1](http://arxiv.org/abs/2412.06512v1)|null|
|**2024-12-09**|**AnomalyControl: Learning Cross-modal Semantic Features for Controllable Anomaly Synthesis**|Shidan He et.al.|[2412.06510v1](http://arxiv.org/abs/2412.06510v1)|null|
|**2024-12-09**|**SimuDICE: Offline Policy Optimization Through World Model Updates and DICE Estimation**|Catalin E. Brita et.al.|[2412.06486v1](http://arxiv.org/abs/2412.06486v1)|[link](https://github.com/catalin-2002/simudice)|
|**2024-12-09**|**Small Languages, Big Models: A Study of Continual Training on Languages of Norway**|David Samuel et.al.|[2412.06484v1](http://arxiv.org/abs/2412.06484v1)|null|
|**2024-12-09**|**SafeWorld: Geo-Diverse Safety Alignment**|Da Yin et.al.|[2412.06483v1](http://arxiv.org/abs/2412.06483v1)|null|
|**2024-12-09**|**From Uncertainty to Trust: Enhancing Reliability in Vision-Language Models with Uncertainty-Guided Dropout Decoding**|Yixiong Fang et.al.|[2412.06474v1](http://arxiv.org/abs/2412.06474v1)|[link](https://github.com/kigb/dropoutdecoding)|
|**2024-12-09**|**Gated Delta Networks: Improving Mamba2 with Delta Rule**|Songlin Yang et.al.|[2412.06464v1](http://arxiv.org/abs/2412.06464v1)|null|
|**2024-12-09**|**How Certain are Uncertainty Estimates? Three Novel Earth Observation Datasets for Benchmarking Uncertainty Quantification in Machine Learning**|Yuanyuan Wang et.al.|[2412.06451v1](http://arxiv.org/abs/2412.06451v1)|null|
|**2024-12-09**|**BoRA: Bi-dimensional Weight-Decomposed Low-Rank Adaptation**|Qiushi Wang et.al.|[2412.06441v1](http://arxiv.org/abs/2412.06441v1)|null|
|**2024-12-09**|**Simulating Human-like Daily Activities with Desire-driven Autonomy**|Yiding Wang et.al.|[2412.06435v1](http://arxiv.org/abs/2412.06435v1)|null|
|**2024-12-09**|**Integrating Expert Labels into LLM-based Emission Goal Detection: Example Selection vs Automatic Prompt Design**|Marco Wrzalik et.al.|[2412.06432v1](http://arxiv.org/abs/2412.06432v1)|null|
|**2024-12-09**|**LLM-BIP: Structured Pruning for Large Language Models with Block-Wise Forward Importance Propagation**|Haihang Wu et.al.|[2412.06419v1](http://arxiv.org/abs/2412.06419v1)|null|
|**2024-12-09**|**StarWhisper Telescope: Agent-Based Observation Assistant System to Approach AI Astrophysicist**|Cunshi Wang et.al.|[2412.06412v1](http://arxiv.org/abs/2412.06412v1)|null|
|**2024-12-09**|**BatchTopK Sparse Autoencoders**|Bart Bussmann et.al.|[2412.06410v1](http://arxiv.org/abs/2412.06410v1)|[link](https://github.com/bartbussmann/batchtopk)|
|**2024-12-09**|**GameArena: Evaluating LLM Reasoning through Live Computer Games**|Lanxiang Hu et.al.|[2412.06394v1](http://arxiv.org/abs/2412.06394v1)|null|
|**2024-12-09**|**Exploring Memorization and Copyright Violation in Frontier LLMs: A Study of the New York Times v. OpenAI 2023 Lawsuit**|Joshua Freeman et.al.|[2412.06370v1](http://arxiv.org/abs/2412.06370v1)|null|
|**2024-12-09**|**Measuring Pre-training Data Quality without Labels for Time Series Foundation Models**|Songkang Wen et.al.|[2412.06368v1](http://arxiv.org/abs/2412.06368v1)|null|
|**2024-12-09**|**Elastic-DETR: Making Image Resolution Learnable with Content-Specific Network Prediction**|Daeun Seo et.al.|[2412.06341v1](http://arxiv.org/abs/2412.06341v1)|null|
|**2024-12-09**|**Not All Errors Are Equal: Investigation of Speech Recognition Errors in Alzheimer's Disease Detection**|Jiawen Kang et.al.|[2412.06332v1](http://arxiv.org/abs/2412.06332v1)|null|
|**2024-12-09**|**CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**|Yijie Dang et.al.|[2412.06314v1](http://arxiv.org/abs/2412.06314v1)|null|
|**2024-12-09**|**Towards High-Level Modelling in Automated Planning**|Carla Davesa Sureda et.al.|[2412.06312v1](http://arxiv.org/abs/2412.06312v1)|null|
|**2024-12-09**|**PRECISE: Pre-training Sequential Recommenders with Collaborative and Semantic Information**|Chonggang Song et.al.|[2412.06308v1](http://arxiv.org/abs/2412.06308v1)|null|
|**2024-12-09**|**DSAI: Unbiased and Interpretable Latent Feature Extraction for Data-Centric AI**|Hyowon Cho et.al.|[2412.06303v1](http://arxiv.org/abs/2412.06303v1)|null|
|**2024-12-09**|**S$^{2}$FT: Efficient, Scalable and Generalizable LLM Fine-tuning by Structured Sparsity**|Xinyu Yang et.al.|[2412.06289v1](http://arxiv.org/abs/2412.06289v1)|null|
|**2024-12-09**|**PediaBench: A Comprehensive Chinese Pediatric Dataset for Benchmarking Large Language Models**|Qian Zhang et.al.|[2412.06287v1](http://arxiv.org/abs/2412.06287v1)|[link](https://github.com/acmislab/pediabench)|
|**2024-12-09**|**Methods for Legal Citation Prediction in the Age of LLMs: An Australian Law Case Study**|Ehsan Shareghi et.al.|[2412.06272v1](http://arxiv.org/abs/2412.06272v1)|null|
|**2024-12-09**|**Optimizing Multi-Task Learning for Enhanced Performance in Large Language Models**|Zhen Qi et.al.|[2412.06249v1](http://arxiv.org/abs/2412.06249v1)|null|
|**2024-12-09**|**A Comparative Study of Learning Paradigms in Large Language Models via Intrinsic Dimension**|Saahith Janapati et.al.|[2412.06245v1](http://arxiv.org/abs/2412.06245v1)|null|
|**2024-12-09**|**Unseen Attack Detection in Software-Defined Networking Using a BERT-Based Large Language Model**|Mohammed N. Swileh et.al.|[2412.06239v1](http://arxiv.org/abs/2412.06239v1)|null|
|**2024-12-09**|**LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments**|Prakash Aryan et.al.|[2412.06229v1](http://arxiv.org/abs/2412.06229v1)|null|
|**2024-12-09**|**Data Free Backdoor Attacks**|Bochuan Cao et.al.|[2412.06219v1](http://arxiv.org/abs/2412.06219v1)|[link](https://github.com/aaaaaasuka/datafree_backdoor_attacks)|
|**2024-12-09**|**A Real-Time Defense Against Object Vanishing Adversarial Patch Attacks for Object Detection in Autonomous Vehicles**|Jaden Mu et.al.|[2412.06215v1](http://arxiv.org/abs/2412.06215v1)|null|
|**2024-12-09**|**A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**|Zhepeng Wang et.al.|[2412.06212v1](http://arxiv.org/abs/2412.06212v1)|null|
|**2024-12-09**|**Skill-Enhanced Reinforcement Learning Acceleration from Demonstrations**|Hanping Zhang et.al.|[2412.06207v1](http://arxiv.org/abs/2412.06207v1)|null|
|**2024-12-09**|**SiReRAG: Indexing Similar and Related Information for Multihop Reasoning**|Nan Zhang et.al.|[2412.06206v1](http://arxiv.org/abs/2412.06206v1)|null|
|**2024-12-09**|**SparseAccelerate: Efficient Long-Context Inference for Mid-Range GPUs**|James Vo et.al.|[2412.06198v1](http://arxiv.org/abs/2412.06198v1)|null|
|**2024-12-09**|**Enhancing Adversarial Resistance in LLMs with Recursion**|Bryan Li et.al.|[2412.06181v1](http://arxiv.org/abs/2412.06181v1)|null|
|**2024-12-09**|**Annotations for Exploring Food Tweets From Multiple Aspects**|Matīss Rikters et.al.|[2412.06179v1](http://arxiv.org/abs/2412.06179v1)|[link](https://github.com/Usprogis/Latvian-Twitter-Eater-Corpus)|
|**2024-12-09**|**AlphaVerus: Bootstrapping Formally Verified Code Generation through Self-Improving Translation and Treefinement**|Pranjal Aggarwal et.al.|[2412.06176v1](http://arxiv.org/abs/2412.06176v1)|null|
|**2024-12-09**|**ACQ: A Unified Framework for Automated Programmatic Creativity in Online Advertising**|Ruizhi Wang et.al.|[2412.06167v1](http://arxiv.org/abs/2412.06167v1)|null|
|**2024-12-09**|**Query-Efficient Planning with Language Models**|Gonzalo Gonzalez-Pumariega et.al.|[2412.06162v1](http://arxiv.org/abs/2412.06162v1)|[link](https://github.com/portal-cornell/llms-for-planning)|
|**2024-12-09**|**MoSH: Modeling Multi-Objective Tradeoffs with Soft and Hard Bounds**|Edward Chen et.al.|[2412.06154v1](http://arxiv.org/abs/2412.06154v1)|null|
|**2024-12-09**|**The Computational Limits of State-Space Models and Mamba via the Lens of Circuit Complexity**|Yifang Chen et.al.|[2412.06148v1](http://arxiv.org/abs/2412.06148v1)|null|
|**2024-12-09**|**Hate Speech According to the Law: An Analysis for Effective Detection**|Katerina Korre et.al.|[2412.06144v1](http://arxiv.org/abs/2412.06144v1)|null|
|**2024-12-09**|**Precise, Fast, and Low-cost Concept Erasure in Value Space: Orthogonal Complement Matters**|Yuan Wang et.al.|[2412.06143v1](http://arxiv.org/abs/2412.06143v1)|null|
|**2024-12-09**|**MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**|Kangyu Zhu et.al.|[2412.06141v1](http://arxiv.org/abs/2412.06141v1)|[link](https://github.com/aiming-lab/mmedpo)|
|**2024-12-09**|**AIDE: Task-Specific Fine Tuning with Attribute Guided Multi-Hop Data Expansion**|Jiayu Li et.al.|[2412.06136v1](http://arxiv.org/abs/2412.06136v1)|null|
|**2024-12-09**|**Evaluating and Mitigating Social Bias for Large Language Models in Open-ended Settings**|Zhao Liu et.al.|[2412.06134v1](http://arxiv.org/abs/2412.06134v1)|null|
|**2024-12-09**|**Privacy-Preserving Large Language Models: Mechanisms, Applications, and Future Directions**|Guoshenghui Zhao et.al.|[2412.06113v1](http://arxiv.org/abs/2412.06113v1)|null|
|**2024-12-08**|**Infusing Prompts with Syntax and Semantics**|Anton Bulle Labate et.al.|[2412.06107v1](http://arxiv.org/abs/2412.06107v1)|null|
|**2024-12-08**|**Enhanced Computationally Efficient Long LoRA Inspired Perceiver Architectures for Auto-Regressive Language Modeling**|Kaleel Mahmood et.al.|[2412.06106v1](http://arxiv.org/abs/2412.06106v1)|null|
|**2024-12-08**|**Measuring Grammatical Diversity from Small Corpora: Derivational Entropy Rates, Mean Length of Utterances, and Annotation Invariance**|Fermin Moscoso del Prado Martin et.al.|[2412.06095v1](http://arxiv.org/abs/2412.06095v1)|null|
|**2024-12-08**|**Trust No AI: Prompt Injection Along The CIA Security Triad**|Johann Rehberger et.al.|[2412.06090v1](http://arxiv.org/abs/2412.06090v1)|null|
|**2024-12-08**|**A4-Unet: Deformable Multi-Scale Attention Network for Brain Tumor Segmentation**|Ruoxin Wang et.al.|[2412.06088v1](http://arxiv.org/abs/2412.06088v1)|null|
|**2024-12-08**|**Ethnography and Machine Learning: Synergies and New Directions**|Zhuofan Li et.al.|[2412.06087v1](http://arxiv.org/abs/2412.06087v1)|null|
|**2024-12-08**|**KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models**|Fan Wang et.al.|[2412.06071v1](http://arxiv.org/abs/2412.06071v1)|[link](https://github.com/juyongjiang/kasa)|
|**2024-12-08**|**Curse of Attention: A Kernel-Based Perspective for Why Transformers Fail to Generalize on Time Series Forecasting and Beyond**|Yekun Ke et.al.|[2412.06061v1](http://arxiv.org/abs/2412.06061v1)|null|
|**2024-12-08**|**Steering Large Language Models to Evaluate and Amplify Creativity**|Matthew Lyle Olson et.al.|[2412.06060v1](http://arxiv.org/abs/2412.06060v1)|null|
|**2024-12-08**|**Cloud Platforms for Developing Generative AI Solutions: A Scoping Review of Tools and Services**|Dhavalkumar Patel et.al.|[2412.06044v1](http://arxiv.org/abs/2412.06044v1)|null|
|**2024-12-08**|**Can Generative AI Solve Your In-Context Learning Problem? A Martingale Perspective**|Andrew Jesson et.al.|[2412.06033v1](http://arxiv.org/abs/2412.06033v1)|null|
|**2024-12-08**|**Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**|Akshat Choube et.al.|[2412.06018v1](http://arxiv.org/abs/2412.06018v1)|null|
|**2024-12-08**|**Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation**|Hyeonho Jeong et.al.|[2412.06016v1](http://arxiv.org/abs/2412.06016v1)|null|
|**2024-12-08**|**1-800-SHARED-TASKS at RegNLP: Lexical Reranking of Semantic Retrieval (LeSeR) for Regulatory Question Answering**|Jebish Purbey et.al.|[2412.06009v1](http://arxiv.org/abs/2412.06009v1)|null|
|**2024-12-08**|**Does RLHF Scale? Exploring the Impacts From Data, Model, and Method**|Zhenyu Hou et.al.|[2412.06000v1](http://arxiv.org/abs/2412.06000v1)|null|
|**2024-12-08**|**PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations**|Namgyu Kang et.al.|[2412.05994v1](http://arxiv.org/abs/2412.05994v1)|null|
|**2024-12-08**|**LVS-Net: A Lightweight Vessels Segmentation Network for Retinal Image Analysis**|Mehwish Mehmood et.al.|[2412.05968v1](http://arxiv.org/abs/2412.05968v1)|null|
|**2024-12-08**|**Language hooks: a modular framework for augmenting LLM reasoning that decouples tool usage from the model and its prompt**|Damien de Mijolla et.al.|[2412.05967v1](http://arxiv.org/abs/2412.05967v1)|null|
|**2024-12-08**|**A Cross-Validation Study of Turkish Sentiment Analysis Datasets and Tools**|Şevval Çakıcı et.al.|[2412.05964v1](http://arxiv.org/abs/2412.05964v1)|null|

#### Abstracts
##### **[MASK] is All You Need**
2412.06787v1 by Vincent Tao Hu, Björn Ommer

In generative models, two paradigms have gained attraction in various
applications: next-set prediction-based Masked Generative Models and next-noise
prediction-based Non-Autoregressive Models, e.g., Diffusion Models. In this
work, we propose using discrete-state models to connect them and explore their
scalability in the vision domain. First, we conduct a step-by-step analysis in
a unified design space across two types of models including
timestep-independence, noise schedule, temperature, guidance strength, etc in a
scalable manner. Second, we re-cast typical discriminative tasks, e.g., image
segmentation, as an unmasking process from [MASK]tokens on a discrete-state
model. This enables us to perform various sampling processes, including
flexible conditional sampling by only training once to model the joint
distribution. All aforementioned explorations lead to our framework named
Discrete Interpolants, which enables us to achieve state-of-the-art or
competitive performance compared to previous discrete-state based methods in
various benchmarks, like ImageNet256, MS COCO, and video dataset FaceForensics.
In summary, by leveraging [MASK] in discrete-state models, we can bridge Masked
Generative and Non-autoregressive Diffusion models, as well as generative and
discriminative tasks.

摘要：在生成模型中，有兩種範例在各種應用程式中獲得關注：基於下一個集合預測的遮罩生成模型和基於下一個雜訊預測的非自迴歸模型，例如擴散模型。在這項工作中，我們建議使用離散狀態模型將它們連接起來，並探索它們在視覺領域的可擴充性。首先，我們在一個統一的設計空間中對兩種模型類型進行逐步分析，包括時間步長獨立性、雜訊排程、溫度、引導強度等，並以可擴充的方式進行。其次，我們將典型的區分任務（例如影像分割）重新轉換為離散狀態模型上 [MASK] 令牌的取消遮罩程序。這使我們能夠執行各種抽樣程序，包括僅透過訓練一次來建模聯合分配的彈性條件抽樣。所有上述探討都導致我們架構稱為離散內插，它使我們能夠在各種基準中（例如 ImageNet256、MS COCO 和影片資料集 FaceForensics）實現與先前基於離散狀態的方法相比最先進或有競爭力的效能。總之，透過利用離散狀態模型中的 [MASK]，我們可以橋接遮罩生成和非自迴歸擴散模型，以及生成和區分任務。

##### **P3-PO: Prescriptive Point Priors for Visuo-Spatial Generalization of Robot Policies**
2412.06784v1 by Mara Levy, Siddhant Haldar, Lerrel Pinto, Abhinav Shirivastava

Developing generalizable robot policies that can robustly handle varied
environmental conditions and object instances remains a fundamental challenge
in robot learning. While considerable efforts have focused on collecting large
robot datasets and developing policy architectures to learn from such data,
naively learning from visual inputs often results in brittle policies that fail
to transfer beyond the training data. This work presents Prescriptive Point
Priors for Policies or P3-PO, a novel framework that constructs a unique state
representation of the environment leveraging recent advances in computer vision
and robot learning to achieve improved out-of-distribution generalization for
robot manipulation. This representation is obtained through two steps. First, a
human annotator prescribes a set of semantically meaningful points on a single
demonstration frame. These points are then propagated through the dataset using
off-the-shelf vision models. The derived points serve as an input to
state-of-the-art policy architectures for policy learning. Our experiments
across four real-world tasks demonstrate an overall 43% absolute improvement
over prior methods when evaluated in identical settings as training. Further,
P3-PO exhibits 58% and 80% gains across tasks for new object instances and more
cluttered environments respectively. Videos illustrating the robot's
performance are best viewed at point-priors.github.io.

摘要：開發可以穩健處理各種環境條件和物件實例的通用機器人策略，在機器人學習中仍然是一項基本挑戰。儘管已投入大量精力收集大型機器人資料集，並開發策略架構從此類資料中學習，但天真地從視覺輸入中學習通常會導致脆弱的策略，無法傳輸到訓練資料之外。這項工作提出了策略規範點先驗或 P3-PO，這是一個創新的框架，它建構了一個環境的獨特狀態表示，利用電腦視覺和機器人學習的最新進展，以實現機器人操作的改進的分布外概括。此表示是透過兩個步驟獲得的。首先，人類註解者在單一示範畫面中指定一組語義有意義的點。然後使用現成的視覺模型將這些點傳播到資料集中。衍生的點作為策略學習的最先進策略架構的輸入。我們在四項真實世界任務中的實驗表明，在與訓練相同的設定下評估時，與先前方法相比，整體絕對改進了 43%。此外，P3-PO 在新物件實例和更混亂的環境中分別展現了 58% 和 80% 的任務增益。說明機器人效能的影片最好在 point-priors.github.io 中觀看。

##### **AnyBimanual: Transferring Unimanual Policy for General Bimanual Manipulation**
2412.06779v1 by Guanxing Lu, Tengbo Yu, Haoyuan Deng, Season Si Chen, Yansong Tang, Ziwei Wang

Performing general language-conditioned bimanual manipulation tasks is of
great importance for many applications ranging from household service to
industrial assembly. However, collecting bimanual manipulation data is
expensive due to the high-dimensional action space, which poses challenges for
conventional methods to handle general bimanual manipulation tasks. In
contrast, unimanual policy has recently demonstrated impressive
generalizability across a wide range of tasks because of scaled model
parameters and training data, which can provide sharable manipulation knowledge
for bimanual systems. To this end, we propose a plug-and-play method named
AnyBimanual, which transfers pre-trained unimanual policy to general bimanual
manipulation policy with few bimanual demonstrations. Specifically, we first
introduce a skill manager to dynamically schedule the skill representations
discovered from pre-trained unimanual policy for bimanual manipulation tasks,
which linearly combines skill primitives with task-oriented compensation to
represent the bimanual manipulation instruction. To mitigate the observation
discrepancy between unimanual and bimanual systems, we present a visual aligner
to generate soft masks for visual embedding of the workspace, which aims to
align visual input of unimanual policy model for each arm with those during
pretraining stage. AnyBimanual shows superiority on 12 simulated tasks from
RLBench2 with a sizable 12.67% improvement in success rate over previous
methods. Experiments on 9 real-world tasks further verify its practicality with
an average success rate of 84.62%.

摘要：執行一般語言條件下的雙手操作任務對於許多應用程式來說非常重要，範圍從家庭服務到工業組裝。但是，由於高維度動作空間，收集雙手操作資料非常昂貴，這對傳統方法處理一般雙手操作任務構成挑戰。相反，由於縮放模型參數和訓練資料，單手策略最近展示了在各種任務中的令人印象深刻的概括能力，這可以為雙手系統提供可共享的操作知識。為此，我們提出了一種名為 AnyBimanual 的即插即用方法，它將預先訓練的單手策略轉移到一般雙手操作策略，並僅需少量的雙手示範。具體來說，我們首先引入一個技能管理員，以動態安排從預先訓練的單手策略中發現的技能表示，用於雙手操作任務，它將技能原語與面向任務的補償線性結合，以表示雙手操作指令。為了減輕單手和雙手系統之間的觀察差異，我們提出了一個視覺對齊器，為工作空間的視覺嵌入生成軟遮罩，其目的是將每個手臂的單手策略模型的視覺輸入與預訓練階段的視覺輸入對齊。AnyBimanual 在 RLBench2 的 12 個模擬任務中表現出優越性，成功率比以前的方法提高了 12.67%。在 9 個真實任務上的實驗進一步驗證了其實用性，平均成功率為 84.62%。

##### **Delve into Visual Contrastive Decoding for Hallucination Mitigation of Large Vision-Language Models**
2412.06775v1 by Yi-Lun Lee, Yi-Hsuan Tsai, Wei-Chen Chiu

While large vision-language models (LVLMs) have shown impressive capabilities
in generating plausible responses correlated with input visual contents, they
still suffer from hallucinations, where the generated text inaccurately
reflects visual contents. To address this, recent approaches apply contrastive
decoding to calibrate the model's response via contrasting output distributions
with original and visually distorted samples, demonstrating promising
hallucination mitigation in a training-free manner. However, the potential of
changing information in visual inputs is not well-explored, so a deeper
investigation into the behaviors of visual contrastive decoding is of great
interest. In this paper, we first explore various methods for contrastive
decoding to change visual contents, including image downsampling and editing.
Downsampling images reduces the detailed textual information while editing
yields new contents in images, providing new aspects as visual contrastive
samples. To further study benefits by using different contrastive samples, we
analyze probability-level metrics, including entropy and distribution distance.
Interestingly, the effect of these samples in mitigating hallucinations varies
a lot across LVLMs and benchmarks. Based on our analysis, we propose a simple
yet effective method to combine contrastive samples, offering a practical
solution for applying contrastive decoding across various scenarios. Extensive
experiments are conducted to validate the proposed fusion method among
different benchmarks.

摘要：雖然大型視覺語言模型 (LVLMs) 在產生與輸入視覺內容相關的合理回應方面展現了令人印象深刻的能力，但它們仍會出現幻覺，其中產生的文字不準確地反映視覺內容。為了解決這個問題，最近的方法採用對比解碼來校準模型的回應，方法是對比輸出分佈與原始和視覺失真的範例，以無訓練的方式展現有望減輕幻覺。然而，改變視覺輸入中資訊的可能性尚未得到充分探討，因此深入研究視覺對比解碼的行為非常重要。在本文中，我們首先探討各種對比解碼方法來改變視覺內容，包括影像降採樣和編輯。影像降採樣會減少詳細的文字資訊，而編輯會在影像中產生新的內容，提供新的面向作為視覺對比範例。為了進一步研究使用不同對比範例的好處，我們分析機率層級的指標，包括熵和分佈距離。有趣的是，這些範例在減輕幻覺方面的效果在 LVLMs 和基準測試中差異很大。根據我們的分析，我們提出一個簡單但有效的方法來結合對比範例，提供一個實用的解決方案，以便在各種場景中應用對比解碼。我們進行了廣泛的實驗，以驗證在不同基準測試中提出的融合方法。

##### **Visual Lexicon: Rich Image Features in Language Space**
2412.06774v1 by XuDong Wang, Xingyi Zhou, Alireza Fathi, Trevor Darrell, Cordelia Schmid

We present Visual Lexicon, a novel visual language that encodes rich image
information into the text space of vocabulary tokens while retaining intricate
visual details that are often challenging to convey in natural language. Unlike
traditional methods that prioritize either high-level semantics (e.g., CLIP) or
pixel-level reconstruction (e.g., VAE), ViLex simultaneously captures rich
semantic content and fine visual details, enabling high-quality image
generation and comprehensive visual scene understanding. Through a
self-supervised learning pipeline, ViLex generates tokens optimized for
reconstructing input images using a frozen text-to-image (T2I) diffusion model,
preserving the detailed information necessary for high-fidelity semantic-level
reconstruction. As an image embedding in the language space, ViLex tokens
leverage the compositionality of natural languages, allowing them to be used
independently as "text tokens" or combined with natural language tokens to
prompt pretrained T2I models with both visual and textual inputs, mirroring how
we interact with vision-language models (VLMs). Experiments demonstrate that
ViLex achieves higher fidelity in image reconstruction compared to text
embeddings--even with a single ViLex token. Moreover, ViLex successfully
performs various DreamBooth tasks in a zero-shot, unsupervised manner without
fine-tuning T2I models. Additionally, ViLex serves as a powerful vision
encoder, consistently improving vision-language model performance across 15
benchmarks relative to a strong SigLIP baseline.

摘要：我們提出 Visual Lexicon，這是一種新穎的視覺語言，它將豐富的圖像資訊編碼到詞彙符號的文字空間中，同時保留了自然語言中通常難以傳達的複雜視覺細節。與優先考慮高階語義（例如 CLIP）或像素級重建（例如 VAE）的傳統方法不同，ViLex 同時擷取豐富的語義內容和精細的視覺細節，實現高品質的圖像生成和全面的視覺場景理解。透過自監督學習管道，ViLex 產生最佳化符號，用於使用凍結的文字轉圖像 (T2I) 擴散模型重建輸入圖像，保留高保真語義級重建所需的詳細資訊。作為語言空間中的圖像嵌入，ViLex 符號利用自然語言的組合性，允許它們獨立用作「文字符號」，或與自然語言符號結合，以視覺和文字輸入提示預訓練的 T2I 模型，反映我們與視覺語言模型 (VLM) 的互動方式。實驗證明，與文字嵌入相比，ViLex 在圖像重建中實現了更高的保真度，即使只使用一個 ViLex 符號。此外，ViLex 以零次學習、無監督的方式成功執行各種 DreamBooth 任務，而無需微調 T2I 模型。此外，ViLex 是一個強大的視覺編碼器，在 15 個基準測試中，相對於強大的 SigLIP 基準，持續改善視覺語言模型的效能。

##### **Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty**
2412.06771v1 by Meera Hahn, Wenjun Zeng, Nithish Kannen, Rich Galt, Kartikeya Badola, Been Kim, Zi Wang

User prompts for generative AI models are often underspecified, leading to
sub-optimal responses. This problem is particularly evident in text-to-image
(T2I) generation, where users commonly struggle to articulate their precise
intent. This disconnect between the user's vision and the model's
interpretation often forces users to painstakingly and repeatedly refine their
prompts. To address this, we propose a design for proactive T2I agents equipped
with an interface to (1) actively ask clarification questions when uncertain,
and (2) present their understanding of user intent as an understandable belief
graph that a user can edit. We build simple prototypes for such agents and
verify their effectiveness through both human studies and automated evaluation.
We observed that at least 90% of human subjects found these agents and their
belief graphs helpful for their T2I workflow. Moreover, we develop a scalable
automated evaluation approach using two agents, one with a ground truth image
and the other tries to ask as few questions as possible to align with the
ground truth. On DesignBench, a benchmark we created for artists and designers,
the COCO dataset (Lin et al., 2014), and ImageInWords (Garg et al., 2024), we
observed that these T2I agents were able to ask informative questions and
elicit crucial information to achieve successful alignment with at least 2
times higher VQAScore (Lin et al., 2024) than the standard single-turn T2I
generation. Demo: https://github.com/google-deepmind/proactive_t2i_agents.

摘要：<paragraph>使用者提示給生成式 AI 模型的內容通常不具體，會導致次佳的回應。這個問題在文字轉圖片 (T2I) 生成中特別明顯，使用者通常難以清楚表達他們的精確意圖。使用者願景與模型詮釋之間的落差，通常會迫使用者費力反覆地修改他們的提示。為了解決這個問題，我們提出一個主動式 T2I 代理程式的設計，配備一個介面，可以在不確定的時候 (1) 主動詢問澄清問題，以及 (2) 將他們對使用者意圖的理解呈現為一個使用者可以編輯的可理解信念圖。我們為這些代理程式建立了簡單的原型，並透過人工研究和自動化評估驗證其有效性。我們觀察到，至少 90% 的受試者發現這些代理程式和他們的信念圖對他們的 T2I 工作流程有幫助。此外，我們開發了一種可擴充的自動化評估方法，使用兩個代理程式，一個具有真實影像，另一個嘗試詢問最少的問題以與真實影像對齊。在 DesignBench，一個我們為藝術家和設計師建立的基準測試，COCO 資料集 (Lin 等人，2014) 和 ImageInWords (Garg 等人，2024)，我們觀察到這些 T2I 代理程式能夠提出有見地的問題，並引出關鍵資訊，以與至少高出 2 倍的 VQAScore (Lin 等人，2024) 成功對齊，而不是標準的單回合 T2I 生成。展示：https://github.com/google-deepmind/proactive_t2i_agents。</paragraph>

##### **Training Large Language Models to Reason in a Continuous Latent Space**
2412.06769v1 by Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, Yuandong Tian

Large language models (LLMs) are restricted to reason in the "language
space", where they typically express the reasoning process with a
chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue
that language space may not always be optimal for reasoning. For example, most
word tokens are primarily for textual coherence and not essential for
reasoning, while some critical tokens require complex planning and pose huge
challenges to LLMs. To explore the potential of LLM reasoning in an
unrestricted latent space instead of using natural language, we introduce a new
paradigm Coconut (Chain of Continuous Thought). We utilize the last hidden
state of the LLM as a representation of the reasoning state (termed "continuous
thought"). Rather than decoding this into a word token, we feed it back to the
LLM as the subsequent input embedding directly in the continuous space.
Experiments show that Coconut can effectively augment the LLM on several
reasoning tasks. This novel latent reasoning paradigm leads to emergent
advanced reasoning patterns: the continuous thought can encode multiple
alternative next reasoning steps, allowing the model to perform a breadth-first
search (BFS) to solve the problem, rather than prematurely committing to a
single deterministic path like CoT. Coconut outperforms CoT in certain logical
reasoning tasks that require substantial backtracking during planning, with
fewer thinking tokens during inference. These findings demonstrate the promise
of latent reasoning and offer valuable insights for future research.

摘要：大型語言模型 (LLM) 被限制在「語言空間」中推理，在語言空間中，它們通常使用思想鏈 (CoT) 來表達推理過程，以解決複雜的推理問題。然而，我們認為語言空間可能並不總是推理的最佳選擇。例如，大多數字元標記主要用於文字連貫性，而非推理的必要條件，而某些關鍵標記則需要複雜的規劃，並對 LLM 構成巨大挑戰。為了探索 LLM 在非受限潛在空間中推理的可能性，而不是使用自然語言，我們引入了一個新的範例 Coconut（連續思想鏈）。我們利用 LLM 的最後隱藏狀態作為推理狀態的表示（稱為「連續思想」）。我們並未將其解碼成字元標記，而是將其直接在連續空間中作為後續輸入嵌入回饋給 LLM。實驗表明，Coconut 可以有效地增強 LLM 在多項推理任務上的能力。這種新穎的潛在推理範例會導致出現進階推理模式：連續思想可以編碼多個備選的後續推理步驟，使模型能夠執行廣度優先搜尋 (BFS) 來解決問題，而不是像 CoT 那樣過早地承諾單一的確定性路徑。在某些邏輯推理任務中，Coconut 優於 CoT，這些任務需要在規劃過程中進行大量的回溯，推理期間的思考標記較少。這些發現證明了潛在推理的前景，並為未來的研究提供了寶貴的見解。

##### **Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models**
2412.06748v1 by Neel Jain, Aditya Shrivastava, Chenyang Zhu, Daben Liu, Alfy Samuel, Ashwinee Panda, Anoop Kumar, Micah Goldblum, Tom Goldstein

A key component of building safe and reliable language models is enabling the
models to appropriately refuse to follow certain instructions or answer certain
questions. We may want models to output refusal messages for various categories
of user queries, for example, ill-posed questions, instructions for committing
illegal acts, or queries which require information past the model's knowledge
horizon. Engineering models that refuse to answer such questions is complicated
by the fact that an individual may want their model to exhibit varying levels
of sensitivity for refusing queries of various categories, and different users
may want different refusal rates. The current default approach involves
training multiple models with varying proportions of refusal messages from each
category to achieve the desired refusal rates, which is computationally
expensive and may require training a new model to accommodate each user's
desired preference over refusal rates. To address these challenges, we propose
refusal tokens, one such token for each refusal category or a single refusal
token, which are prepended to the model's responses during training. We then
show how to increase or decrease the probability of generating the refusal
token for each category during inference to steer the model's refusal behavior.
Refusal tokens enable controlling a single model's refusal rates without the
need of any further fine-tuning, but only by selectively intervening during
generation.

摘要：建構安全又可靠的語言模型的一個關鍵要素，在於讓模型適當地拒絕遵循某些指示或回答某些問題。我們可能希望模型針對各種類別的使用者查詢輸出拒絕訊息，例如，不當的問題、執行非法行為的指示，或查詢需要模型知識範圍以外的資訊。設計會拒絕回答此類問題的模型很複雜，因為個人可能希望他們的模型針對不同類別的查詢表現出不同程度的敏感性，而不同的使用者可能希望有不同的拒絕率。目前的預設方法包括訓練多個模型，其中每個類別的拒絕訊息比例不同，以達到所需的拒絕率，這在計算上很昂貴，而且可能需要訓練一個新模型來適應每個使用者對拒絕率的偏好。為了應對這些挑戰，我們提出拒絕權杖，每個拒絕類別一個這樣的權杖，或一個單一的拒絕權杖，在訓練期間將其置於模型回應之前。然後，我們展示如何在推論期間增加或降低產生每個類別的拒絕權杖的機率，以引導模型的拒絕行為。拒絕權杖能夠控制單一模型的拒絕率，而無需進一步微調，但僅在產生期間有選擇地介入。

##### **ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended Capabilities**
2412.06745v1 by Adhiraj Ghosh, Sebastian Dziadzio, Ameya Prabhu, Vishaal Udandarao, Samuel Albanie, Matthias Bethge

Traditional fixed test sets fall short in evaluating open-ended capabilities
of foundation models. To address this, we propose ONEBench(OpeN-Ended
Benchmarking), a new testing paradigm that consolidates individual evaluation
datasets into a unified, ever-expanding sample pool. ONEBench allows users to
generate custom, open-ended evaluation benchmarks from this pool, corresponding
to specific capabilities of interest. By aggregating samples across test sets,
ONEBench enables the assessment of diverse capabilities beyond those covered by
the original test sets, while mitigating overfitting and dataset bias. Most
importantly, it frames model evaluation as a collective process of selecting
and aggregating sample-level tests.
  The shift from task-specific benchmarks to ONEBench introduces two
challenges: (1)heterogeneity and (2)incompleteness. Heterogeneity refers to the
aggregation over diverse metrics, while incompleteness describes comparing
models evaluated on different data subsets. To address these challenges, we
explore algorithms to aggregate sparse measurements into reliable model scores.
Our aggregation algorithm ensures identifiability(asymptotically recovering
ground-truth scores) and rapid convergence, enabling accurate model ranking
with less data. On homogenous datasets, we show our aggregation algorithm
provides rankings that highly correlate with those produced by average scores.
We also demonstrate robustness to ~95% of measurements missing, reducing
evaluation cost by up to 20x with little-to-no change in model rankings. We
introduce ONEBench-LLM for language models and ONEBench-LMM for vision-language
models, unifying evaluations across these domains. Overall, we present a
technique for open-ended evaluation, which can aggregate over incomplete,
heterogeneous sample-level measurements to continually grow a benchmark
alongside the rapidly developing foundation models.

摘要：傳統固定測試組不足以評估基礎模型的開放式能力。為了解決此問題，我們提出 ONEBench（開放式基準測試），這是一種新的測試範例，它將個別評估資料集整合到一個統一且不斷擴展的樣本池中。ONEBench 讓使用者可以從此池產生自訂的開放式評估基準，以對應特定感興趣的能力。透過彙總測試組中的樣本，ONEBench 能夠評估原始測試組涵蓋範圍之外的多元能力，同時減輕過度擬合和資料集偏差。最重要的是，它將模型評估設定為選擇和彙總樣本層級測試的集體程序。
從特定任務基準測試轉換到 ONEBench 會產生兩個挑戰：(1) 異質性和 (2) 不完整性。異質性是指彙總多樣化指標，而未完成性是指比較在不同資料子集上評估的模型。為了應對這些挑戰，我們探討了將稀疏測量彙總為可靠模型評分的演算法。我們的彙總演算法確保可識別性（漸近恢復真實評分）和快速收斂，進而能以較少資料進行準確的模型排名。在同質資料集上，我們展示我們的彙總演算法提供的排名與平均評分產生的排名高度相關。我們也證明了對約 95% 遺失測量的穩健性，將評估成本降低了多達 20 倍，而模型排名幾乎沒有變化。我們針對語言模型推出 ONEBench-LLM，針對視覺語言模型推出 ONEBench-LMM，統一了這些領域的評估。總體而言，我們提出了一種開放式評估技術，它可以彙總不完整、異質的樣本層級測量，以隨著快速發展的基礎模型持續擴充基準。

##### **ContRail: A Framework for Realistic Railway Image Synthesis using ControlNet**
2412.06742v1 by Andrei-Robert Alexandrescu, Razvan-Gabriel Petec, Alexandru Manole, Laura-Silvia Diosan

Deep Learning became an ubiquitous paradigm due to its extraordinary
effectiveness and applicability in numerous domains. However, the approach
suffers from the high demand of data required to achieve the potential of this
type of model. An ever-increasing sub-field of Artificial Intelligence, Image
Synthesis, aims to address this limitation through the design of intelligent
models capable of creating original and realistic images, endeavour which could
drastically reduce the need for real data. The Stable Diffusion generation
paradigm recently propelled state-of-the-art approaches to exceed all previous
benchmarks. In this work, we propose the ContRail framework based on the novel
Stable Diffusion model ControlNet, which we empower through a multi-modal
conditioning method. We experiment with the task of synthetic railway image
generation, where we improve the performance in rail-specific tasks, such as
rail semantic segmentation by enriching the dataset with realistic synthetic
images.

摘要：深度學習由於其非凡的效能和在眾多領域的適用性，成為了無所不在的範例。然而，這種方法需要大量資料才能達到這種類型的模型的潛力，這一點讓它備受困擾。人工智慧的一個不斷增長的子領域——影像合成，旨在透過設計能夠創造出原創且逼真的影像的智慧模型來解決這個限制，這項努力可以大幅減少對真實資料的需求。Stable Diffusion 生成範例最近推動了最先進的方法，超越了所有先前的基準。在這項工作中，我們提出了基於新穎的 Stable Diffusion 模型 ControlNet 的 ContRail 框架，我們透過多模式條件化方法賦予它能力。我們實驗了合成鐵路影像生成的任務，在鐵路特定任務中改進了效能，例如透過使用逼真的合成影像豐富資料集，來進行鐵路語意分割。

##### **JAPAGEN: Efficient Few/Zero-shot Learning via Japanese Training Dataset Generation with LLM**
2412.06738v1 by Takuro Fujii, Satoru Katsumata

Recently some studies have highlighted the potential of Large Language Models
(LLMs) as effective generators of supervised training data, offering advantages
such as enhanced inference efficiency and reduced costs associated with data
collection. However, these studies have predominantly focused on English
language tasks. In this paper, we address the fundamental research question:
Can LLMs serve as proficient training data generators for other language tasks?
Specifically, we leverage LLMs to synthesize supervised training data under
few-shot and zero-shot learning scenarios across six diverse Japanese
downstream tasks. Subsequently, we utilize this synthesized data to train
compact models (e.g., BERT). This novel methodology is termed JAPAGEN. Our
experimental findings underscore that JAPAGEN achieves robust performance in
classification tasks that necessitate formal text inputs, demonstrating
competitive results compared to conventional LLM prompting strategies.

摘要：最近一些研究強調了大型語言模型 (LLM) 作為監督訓練資料的有效生成器的潛力，提供增強的推論效率和降低與資料收集相關的成本等優勢。然而，這些研究主要集中在英文任務上。在本文中，我們探討了基本的研究問題：LLM 能否作為其他語言任務的熟練訓練資料生成器？具體來說，我們利用 LLM 在六項不同的日文下游任務中綜合監督訓練資料，採用少量樣本和零樣本學習場景。隨後，我們利用這些綜合資料來訓練精簡模型 (例如 BERT)。這種新穎的方法稱為 JAPAGEN。我們的實驗結果強調，JAPAGEN 在需要正式文字輸入的分類任務中取得了穩健的表現，與傳統的 LLM 提示策略相比，展示了具有競爭力的結果。

##### **AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and Benchmark**
2412.06724v1 by Lan Li, Liri Fang, Vetle I. Torvik

We investigate the reasoning capabilities of large language models (LLMs) for
automatically generating data-cleaning workflows. To evaluate LLMs' ability to
complete data-cleaning tasks, we implemented a pipeline for LLM-based Auto Data
Cleaning Workflow (AutoDCWorkflow), prompting LLMs on data cleaning operations
to repair three types of data quality issues: duplicates, missing values, and
inconsistent data formats. Given a dirty table and a purpose (expressed as a
query), this pipeline generates a minimal, clean table sufficient to address
the purpose and the data cleaning workflow used to produce the table. The
planning process involves three main LLM-driven components: (1) Select Target
Columns: Identifies a set of target columns related to the purpose. (2) Inspect
Column Quality: Assesses the data quality for each target column and generates
a Data Quality Report as operation objectives. (3) Generate Operation &
Arguments: Predicts the next operation and arguments based on the data quality
report results. Additionally, we propose a data cleaning benchmark to evaluate
the capability of LLM agents to automatically generate workflows that address
data cleaning purposes of varying difficulty levels. The benchmark comprises
the annotated datasets as a collection of purpose, raw table, clean table, data
cleaning workflow, and answer set. In our experiments, we evaluated three LLMs
that auto-generate purpose-driven data cleaning workflows. The results indicate
that LLMs perform well in planning and generating data-cleaning workflows
without the need for fine-tuning.

摘要：<paragraph>我們調查大型語言模型 (LLM) 的推理能力，以自動產生資料清理工作流程。為評估 LLM 完成資料清理任務的能力，我們實作了一個基於 LLM 的自動資料清理工作流程 (AutoDCWorkflow) 管道，提示 LLM 進行資料清理操作，以修復三種類型的資料品質問題：重複、遺失值和不一致的資料格式。給定一個髒資料表和一個目的 (表示為查詢)，此管道會產生一個最小的乾淨資料表，足以解決目的和用於產生資料表的資料清理工作流程。規劃流程包含三個主要的 LLM 驅動元件：(1) 選擇目標欄位：識別一組與目的相關的目標欄位。(2) 檢查欄位品質：評估每個目標欄位的資料品質，並產生資料品質報告作為操作目標。(3) 產生操作和參數：根據資料品質報告結果預測下一個操作和參數。此外，我們提出一個資料清理基準，以評估 LLM 代理自動產生工作流程的能力，以解決不同難度層級的資料清理目的。基準包含註解資料集，作為目的、原始資料表、乾淨資料表、資料清理工作流程和答案集的集合。在我們的實驗中，我們評估了三個自動產生以目的為導向的資料清理工作流程的 LLM。結果表明，LLM 在規劃和產生資料清理工作流程方面表現良好，無需微調。</paragraph>

##### **Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**
2412.06717v1 by Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi

Bankart lesions, or anterior-inferior glenoid labral tears, are
diagnostically challenging on standard MRIs due to their subtle imaging
features-often necessitating invasive MRI arthrograms (MRAs). This study
develops deep learning (DL) models to detect Bankart lesions on both standard
MRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on
MRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from
558 patients who underwent arthroscopy. Ground truth labels were derived from
intraoperative findings, the gold standard for Bankart lesion diagnosis.
Separate DL models for MRAs and standard MRIs were trained using the Swin
Transformer architecture, pre-trained on a public knee MRI dataset. Predictions
from sagittal, axial, and coronal views were ensembled to optimize performance.
The models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71
standard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of
standard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,
86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on
standard MRIs and MRAs, respectively. These results match or surpass
radiologist performance on our dataset and reported literature metrics.
Notably, our model's performance on non-invasive standard MRIs matched or
surpassed the radiologists interpreting MRAs. This study demonstrates the
feasibility of using DL to address the diagnostic challenges posed by subtle
pathologies like Bankart lesions. Our models demonstrate potential to improve
diagnostic confidence, reduce reliance on invasive imaging, and enhance
accessibility to care.

摘要：Bankart 病灶，或前下盂唇撕裂，由於其影像特徵微妙，在標準核磁共振成像中診斷具有挑戰性，通常需要侵入性核磁共振血管造影 (MRA)。本研究開發深度學習 (DL) 模型，用於在標準核磁共振成像和核磁共振血管造影中檢測 Bankart 病灶，旨在提高診斷準確性並減少對核磁共振血管造影的依賴。我們從 558 名接受關節鏡檢查的患者中策劃了一組 586 例肩部核磁共振成像 (335 例標準，251 例核磁共振血管造影) 的數據集。基本事實標籤來自術中發現，這是 Bankart 病灶診斷的黃金標準。使用 Swin Transformer 架構訓練了核磁共振血管造影和標準核磁共振成像的單獨深度學習模型，並在公開的膝部核磁共振成像數據集上進行預訓練。矢狀面、軸面和冠狀面的預測結果被組合起來以優化性能。這些模型在 20% 的保留測試集（117 例核磁共振成像：46 例核磁共振血管造影，71 例標準核磁共振成像）上進行了評估。在 31.9% 的核磁共振血管造影和 8.6% 的標準核磁共振成像中發現了 Bankart 病灶。這些模型在標準核磁共振成像和核磁共振血管造影中的 AUC 分別達到 0.87（86% 準確度，83% 靈敏度，86% 特異度）和 0.90（85% 準確度，82% 靈敏度，86% 特異度）。這些結果與放射科醫生對我們數據集的表現相匹配或超過，並超過了報告的文獻指標。值得注意的是，我們的模型在非侵入性標準核磁共振成像中的表現與放射科醫生對核磁共振血管造影的解釋相匹配或超過。本研究證明了使用深度學習來解決 Bankart 病灶等微妙病理診斷挑戰的可行性。我們的模型展示了提高診斷信心、減少對侵入性影像檢查的依賴以及增強獲得照護的機會的潛力。

##### **How to Merge Your Multimodal Models Over Time?**
2412.06712v1 by Sebastian Dziadzio, Vishaal Udandarao, Karsten Roth, Ameya Prabhu, Zeynep Akata, Samuel Albanie, Matthias Bethge

Model merging combines multiple expert models - finetuned from a base
foundation model on diverse tasks and domains - into a single, more capable
model. However, most existing model merging approaches assume that all experts
are available simultaneously. In reality, new tasks and domains emerge
progressively over time, requiring strategies to integrate the knowledge of
expert models as they become available: a process we call temporal model
merging. The temporal dimension introduces unique challenges not addressed in
prior work, raising new questions such as: when training for a new task, should
the expert model start from the merged past experts or from the original base
model? Should we merge all models at each time step? Which merging techniques
are best suited for temporal merging? Should different strategies be used to
initialize the training and deploy the model? To answer these questions, we
propose a unified framework called TIME - Temporal Integration of Model
Expertise - which defines temporal model merging across three axes: (1)
Initialization Phase, (2) Deployment Phase, and (3) Merging Technique. Using
TIME, we study temporal model merging across model sizes, compute budgets, and
learning horizons on the FoMo-in-Flux benchmark. Our comprehensive suite of
experiments across TIME allows us to uncover key insights for temporal model
merging, offering a better understanding of current challenges and best
practices for effective temporal model merging.

摘要：模型合併結合多個專家模型，這些模型從基礎模型微調而來，用於不同的任務和領域，進而形成單一、功能更強大的模型。然而，現有的大多數模型合併方法都假設所有專家模型都能同時使用。實際上，新的任務和領域會隨著時間推移而逐漸出現，這需要策略來整合專家模型的知識，因為這些知識會隨著時間推移而可用：我們將此過程稱為時間模型合併。時間維度引入了先前工作中未解決的獨特挑戰，提出了新的問題，例如：在為新任務訓練時，專家模型應從合併的過往專家開始，還是從原始基礎模型開始？我們是否應在每個時間步驟合併所有模型？哪些合併技術最適合時間合併？應使用不同的策略來初始化訓練並部署模型嗎？為了回答這些問題，我們提出一個統一的框架，稱為 TIME（模型專業知識的時間整合），它定義了跨三個軸的時間模型合併：(1) 初始化階段，(2) 部署階段，和 (3) 合併技術。使用 TIME，我們研究了跨模型大小、計算預算和 FoMo-in-Flux 基準上的學習範圍的時間模型合併。我們在 TIME 中進行的全面實驗套件讓我們得以發現時間模型合併的重要見解，進而更深入了解當前挑戰和有效時間模型合併的最佳實務。

##### **Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**
2412.06709v1 by Aqib Nazir Mir, Iqra Nissar, Mumtaz Ahmed, Sarfaraz Masood, Danish Raza Rizvi

Deep learning holds tremendous potential in healthcare for uncovering hidden
patterns within extensive clinical datasets, aiding in the diagnosis of various
diseases. Parkinson's disease (PD) is a neurodegenerative condition
characterized by the deterioration of brain function. In the initial stages of
PD, automatic diagnosis poses a challenge due to the similarity in behavior
between individuals with PD and those who are healthy. Our objective is to
propose an effective model that can aid in the early detection of Parkinson's
disease. We employed the VGRF gait signal dataset sourced from Physionet for
distinguishing between healthy individuals and those diagnosed with Parkinson's
disease. This paper introduces a novel deep learning architecture based on the
LSTM network for automatically detecting freezing of gait episodes in
Parkinson's disease patients. In contrast to conventional machine learning
algorithms, this method eliminates manual feature engineering and proficiently
captures prolonged temporal dependencies in gait patterns, thereby improving
the diagnosis of Parkinson's disease. The LSTM network resolves the issue of
vanishing gradients by employing memory blocks in place of self-connected
hidden units, allowing for optimal information assimilation. To prevent
overfitting, dropout and L2 regularization techniques have been employed.
Additionally, the stochastic gradient-based optimizer Adam is used for the
optimization process. The results indicate that our proposed approach surpasses
current state-of-the-art models in FOG episode detection, achieving an accuracy
of 97.71%, sensitivity of 99%, precision of 98%, and specificity of 96%. This
demonstrates its potential as a superior classification method for Parkinson's
disease detection.

摘要：深度學習在醫療保健領域擁有巨大的潛力，可用於發掘廣泛臨床資料集中的隱藏模式，協助診斷各種疾病。帕金森氏症 (PD) 是一種神經退化性疾病，其特徵是大腦功能惡化。在 PD 的初期階段，由於 PD 患者與健康者的行為相似，因此自動診斷具有挑戰性。我們的目標是提出一個有效的模型，可以幫助早期檢測帕金森氏症。我們採用了來自 Physionet 的 VGRF 步態信號資料集，用於區分健康個體和被診斷出患有帕金森氏症的個體。本文介紹了一種基於 LSTM 網路的深度學習新架構，用於自動檢測帕金森氏症患者的步態凍結發作。與傳統機器學習演算法相比，此方法消除了手動特徵工程，並熟練地捕捉步態模式中的長時間依賴性，從而改進了帕金森氏症的診斷。LSTM 網路通過使用記憶區塊代替自連接隱藏單元來解決梯度消失問題，從而實現最佳資訊同化。為了防止過度擬合，已採用中斷和 L2 正則化技術。此外，隨機梯度優化器 Adam 用於優化過程。結果表明，我們提出的方法在 FOG 發作檢測方面超越了當前最先進的模型，達到了 97.71% 的準確率、99% 的靈敏度、98% 的精確度和 96% 的特異性。這證明了其作為帕金森氏症檢測的優越分類方法的潛力。

##### **Digital Transformation in the Water Distribution System based on the Digital Twins Concept**
2412.06694v1 by MohammadHossein Homaei, Agustín Javier Di Bartolo, Mar Ávila, Óscar Mogollón-Gutiérrez, Andrés Caro

Digital Twins have emerged as a disruptive technology with great potential;
they can enhance WDS by offering real-time monitoring, predictive maintenance,
and optimization capabilities. This paper describes the development of a
state-of-the-art DT platform for WDS, introducing advanced technologies such as
the Internet of Things, Artificial Intelligence, and Machine Learning models.
This paper provides insight into the architecture of the proposed
platform-CAUCCES-that, informed by both historical and meteorological data,
effectively deploys AI/ML models like LSTM networks, Prophet, LightGBM, and
XGBoost in trying to predict water consumption patterns. Furthermore, we delve
into how optimization in the maintenance of WDS can be achieved by formulating
a Constraint Programming problem for scheduling, hence minimizing the
operational cost efficiently with reduced environmental impacts. It also
focuses on cybersecurity and protection to ensure the integrity and reliability
of the DT platform. In this view, the system will contribute to improvements in
decision-making capabilities, operational efficiency, and system reliability,
with reassurance being drawn from the important role it can play toward
sustainable management of water resources.

摘要：數位孿生已成為一種潛力巨大的顛覆性技術；
它們可透過提供即時監控、預測性維護和最佳化功能來強化 WDS。本文說明了 WDS 最先進 DT 平台的開發，引進了物聯網、人工智慧和機器學習模型等先進技術。
本文深入探討了所建議平台 CAUCCES 的架構，該平台根據歷史和氣象資料，有效地部署 AI/ML 模型，例如 LSTM 網路、Prophet、LightGBM 和 XGBoost，嘗試預測用水模式。此外，我們深入探討如何透過制定排程的約束式規劃問題來達成 WDS 維護的最佳化，從而有效地降低營運成本並減少環境影響。它也注重於網路安全和防護，以確保 DT 平台的完整性和可靠性。從這個觀點來看，此系統將有助於改善決策制定能力、營運效率和系統可靠性，並從其在永續管理水資源方面所能扮演的重要角色中獲得保證。

##### **OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large Language Model and its Omni-Extensions**
2412.06693v1 by Yi-Kai Zhang, Xu-Xiang Zhong, Shiyin Lu, Qing-Guo Chen, De-Chuan Zhan, Han-Jia Ye

The rapid advancements in Large Language Models (LLMs) have significantly
expanded their applications, ranging from multilingual support to
domain-specific tasks and multimodal integration. In this paper, we present
OmniEvalKit, a novel benchmarking toolbox designed to evaluate LLMs and their
omni-extensions across multilingual, multidomain, and multimodal capabilities.
Unlike existing benchmarks that often focus on a single aspect, OmniEvalKit
provides a modular, lightweight, and automated evaluation system. It is
structured with a modular architecture comprising a Static Builder and Dynamic
Data Flow, promoting the seamless integration of new models and datasets.
OmniEvalKit supports over 100 LLMs and 50 evaluation datasets, covering
comprehensive evaluations across thousands of model-dataset combinations.
OmniEvalKit is dedicated to creating an ultra-lightweight and fast-deployable
evaluation framework, making downstream applications more convenient and
versatile for the AI community.

摘要：大型語言模型 (LLM) 的快速進步大幅擴展了它們的應用，從多語言支援到特定領域任務和多模態整合。在本文中，我們提出 OmniEvalKit，這是一個新穎的基準測試工具箱，旨在評估 LLM 及其在多語言、多領域和多模態能力上的全方位擴展。與通常只關注單一方面的現有基準測試不同，OmniEvalKit 提供了一個模組化、輕量化且自動化的評估系統。它採用模組化架構，包含靜態建構器和動態資料流程，促進新模型和資料集的無縫整合。OmniEvalKit 支援超過 100 個 LLM 和 50 個評估資料集，涵蓋數千個模型資料集組合的全面評估。OmniEvalKit 致力於建立一個超輕量級且快速部署的評估架構，讓下游應用程式對 AI 社群來說更加便利且多功能。

##### **Policy Agnostic RL: Offline RL and Online RL Fine-Tuning of Any Class and Backbone**
2412.06685v1 by Max Sobol Mark, Tian Gao, Georgia Gabriela Sampaio, Mohan Kumar Srirama, Archit Sharma, Chelsea Finn, Aviral Kumar

Recent advances in learning decision-making policies can largely be
attributed to training expressive policy models, largely via imitation
learning. While imitation learning discards non-expert data, reinforcement
learning (RL) can still learn from suboptimal data. However, instantiating RL
training of a new policy class often presents a different challenge: most deep
RL machinery is co-developed with assumptions on the policy class and backbone,
resulting in poor performance when the policy class changes. For instance, SAC
utilizes a low-variance reparameterization policy gradient for Gaussian
policies, but this is unstable for diffusion policies and intractable for
autoregressive categorical policies. To address this issue, we develop an
offline RL and online fine-tuning approach called policy-agnostic RL (PA-RL)
that can effectively train multiple policy classes, with varying architectures
and sizes. We build off the basic idea that a universal supervised learning
loss can replace the policy improvement step in RL, as long as it is applied on
"optimized" actions. To obtain these optimized actions, we first sample
multiple actions from a base policy, and run global optimization (i.e.,
re-ranking multiple action samples using the Q-function) and local optimization
(i.e., running gradient steps on an action sample) to maximize the critic on
these candidates. PA-RL enables fine-tuning diffusion and transformer policies
with either autoregressive tokens or continuous action outputs, at different
sizes, entirely via actor-critic RL. Moreover, PA-RL improves the performance
and sample-efficiency by up to 2 times compared to existing offline RL and
online fine-tuning methods. We show the first result that successfully
fine-tunes OpenVLA, a 7B generalist robot policy, autonomously with Cal-QL, an
online RL fine-tuning algorithm, improving from 40% to 70% in the real world in
40 minutes.

摘要：近来在学习决策制定政策方面取得的进展，在很大程度上可归因于训练表现力政策模型，主要是通过模仿学习。虽然模仿学习会丢弃非专家数据，但强化学习 (RL) 仍可从次优数据中学习。然而，实例化新政策类的 RL 训练通常会带来不同的挑战：大多数深度 RL 机制都与对政策类和主干的假设共同开发，导致在政策类发生变化时性能不佳。例如，SAC 对高斯政策使用低方差重新参数化策略梯度，但这对扩散策略不稳定，对自回归分类策略来说难以处理。为了解决这个问题，我们开发了一种称为策略不可知 RL (PA-RL) 的离线 RL 和在线微调方法，该方法可以有效地训练具有不同架构和大小的多个策略类。我们建立在这样一个基本思想之上：只要应用于“优化”操作，通用监督学习损失就可以替代 RL 中的策略改进步骤。为了获得这些优化的操作，我们首先从基本策略中采样多个操作，并运行全局优化（即，使用 Q 函数对多个操作样本进行重新排序）和局部优化（即，对操作样本运行梯度步骤）以最大化这些候选者的批评者。PA-RL 启用微调扩散和转换器策略，具有自回归标记或连续操作输出，在不同大小下，完全通过 actor-critic RL。此外，与现有的离线 RL 和在线微调方法相比，PA-RL 将性能和样本效率提高了 2 倍。我们展示了第一个成功微调 OpenVLA 的结果，OpenVLA 是一种 7B 通才机器人策略，使用 Cal-QL（一种在线 RL 微调算法）自主运行，在 40 分钟内从现实世界的 40% 提高到 70%。

##### **Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework**
2412.06681v1 by Tianming Liu, Jirong Yang, Yafeng Yin

In transportation system demand modeling and simulation, agent-based models
and microsimulations are current state-of-the-art approaches. However, existing
agent-based models still have some limitations on behavioral realism and
resource demand that limit their applicability. In this study, leveraging the
emerging technology of large language models (LLMs) and LLM-based agents, we
propose a general LLM-agent-based modeling framework for transportation
systems. We argue that LLM agents not only possess the essential capabilities
to function as agents but also offer promising solutions to overcome some
limitations of existing agent-based models. Our conceptual framework design
closely replicates the decision-making and interaction processes and traits of
human travelers within transportation networks, and we demonstrate that the
proposed systems can meet critical behavioral criteria for decision-making and
learning behaviors using related studies and a demonstrative example of LLM
agents' learning and adjustment in the bottleneck setting. Although further
refinement of the LLM-agent-based modeling framework is necessary, we believe
that this approach has the potential to improve transportation system modeling
and simulation.

摘要：在交通系統需求建模和模擬中，基於代理的模型和微觀模擬是當前最先進的方法。然而，現有的基於代理的模型在行為真實性和資源需求方面仍然存在一些限制，這限制了它們的適用性。在本研究中，我們利用大型語言模型 (LLM) 和基於 LLM 的代理的新興技術，提出了一個用於交通系統的通用 LLM 代理建模框架。我們認為 LLM 代理不僅具備作為代理運作的基本能力，而且還提供了有希望的解決方案來克服現有基於代理的模型的一些限制。我們的概念框架設計緊密複製了交通網路中人類旅行者的決策制定和互動過程和特徵，我們證明了所提出的系統可以使用相關研究和 LLM 代理在瓶頸設置中的學習和調整的示範性範例來滿足決策制定和學習行為的重要行為標準。儘管進一步完善基於 LLM 的代理建模框架是必要的，但我們相信這種方法有可能改善交通系統建模和模擬。

##### **I Don't Know: Explicit Modeling of Uncertainty with an [IDK] Token**
2412.06676v1 by Roi Cohen, Konstantin Dobler, Eden Biran, Gerard de Melo

Large Language Models are known to capture real-world knowledge, allowing
them to excel in many downstream tasks. Despite recent advances, these models
are still prone to what are commonly known as hallucinations, causing them to
emit unwanted and factually incorrect text. In this work, we propose a novel
calibration method that can be used to combat hallucinations. We add a special
[IDK] ("I don't know") token to the model's vocabulary and introduce an
objective function that shifts probability mass to the [IDK] token for
incorrect predictions. This approach allows the model to express uncertainty in
its output explicitly. We evaluate our proposed method across multiple model
architectures and factual downstream tasks. We find that models trained with
our method are able to express uncertainty in places where they would
previously make mistakes while suffering only a small loss of encoded
knowledge. We further perform extensive ablation studies of multiple variations
of our approach and provide a detailed analysis of the precision-recall
tradeoff of our method.

摘要：大型語言模型已知會擷取真實世界的知識，讓它們在許多下游任務中表現出色。儘管有近期的進展，這些模型仍容易出現一般稱為幻覺的問題，導致它們發出不必要的且事實上不正確的文字。在這項工作中，我們提出了一種新穎的校準方法，可用於對抗幻覺。我們在模型的詞彙中新增一個特殊的 [IDK]（「我不知道」）標記，並引入一個目標函數，將機率質量轉移到 [IDK] 標記，以進行不正確的預測。這種方法允許模型明確表達其輸出中的不確定性。我們在多個模型架構和事實下游任務中評估我們提出的方法。我們發現使用我們的方法訓練的模型能夠在以前會出錯的地方表達不確定性，同時僅損失少量的編碼知識。我們進一步對我們方法的各種變化進行廣泛的消融研究，並提供我們方法的精確度召回權衡的詳細分析。

##### **GEAR: A Simple GENERATE, EMBED, AVERAGE AND RANK Approach for Unsupervised Reverse Dictionary**
2412.06654v1 by Fatemah Almeman, Luis Espinosa-Anke

Reverse Dictionary (RD) is the task of obtaining the most relevant word or
set of words given a textual description or dictionary definition. Effective RD
methods have applications in accessibility, translation or writing support
systems. Moreover, in NLP research we find RD to be used to benchmark text
encoders at various granularities, as it often requires word, definition and
sentence embeddings. In this paper, we propose a simple approach to RD that
leverages LLMs in combination with embedding models. Despite its simplicity,
this approach outperforms supervised baselines in well studied RD datasets,
while also showing less over-fitting. We also conduct a number of experiments
on different dictionaries and analyze how different styles, registers and
target audiences impact the quality of RD systems. We conclude that, on
average, untuned embeddings alone fare way below an LLM-only baseline (although
they are competitive in highly technical dictionaries), but are crucial for
boosting performance in combined methods.

摘要：逆向詞典 (RD) 是一項任務，即根據文字說明或字典定義取得最相關的字詞或字詞組。有效的 RD 方法在無障礙、翻譯或寫作支援系統中都有應用。此外，在 NLP 研究中，我們發現 RD 被用於對不同粒度的文字編碼器進行基準測試，因為它通常需要字詞、定義和句子嵌入。在本文中，我們提出了一個 RD 的簡單方法，它結合了 LLM 和嵌入模型。儘管很簡單，但這種方法在研究良好的 RD 資料集中優於監督式基準，同時也顯示出較少的過度擬合。我們還對不同的字典進行了多項實驗，並分析了不同的風格、註冊和目標受眾如何影響 RD 系統的品質。我們得出結論，平均而言，未調整的嵌入本身遠低於僅 LLM 的基準（儘管它們在高度技術性的字典中具有競爭力），但對於提升組合方法的效能至關重要。

##### **Detecting Facial Image Manipulations with Multi-Layer CNN Models**
2412.06643v1 by Alejandro Marco Montejano, Angela Sanchez Perez, Javier Barrachina, David Ortiz-Perez, Manuel Benavent-Lledo, Jose Garcia-Rodriguez

The rapid evolution of digital image manipulation techniques poses
significant challenges for content verification, with models such as stable
diffusion and mid-journey producing highly realistic, yet synthetic, images
that can deceive human perception. This research develops and evaluates
convolutional neural networks (CNNs) specifically tailored for the detection of
these manipulated images. The study implements a comparative analysis of three
progressively complex CNN architectures, assessing their ability to classify
and localize manipulations across various facial image modifications.
Regularization and optimization techniques were systematically incorporated to
improve feature extraction and performance. The results indicate that the
proposed models achieve an accuracy of up to 76\% in distinguishing manipulated
images from genuine ones, surpassing traditional approaches. This research not
only highlights the potential of CNNs in enhancing the robustness of digital
media verification tools, but also provides insights into effective
architectural adaptations and training strategies for low-computation
environments. Future work will build on these findings by extending the
architectures to handle more diverse manipulation techniques and integrating
multi-modal data for improved detection capabilities.

摘要：數位影像處理技術的快速演進，對內容驗證帶來重大的挑戰，例如 stable diffusion 和 mid-journey 等模型產生高度逼真但合成的影像，足以欺騙人類的感知。本研究開發並評估專門針對這些處理影像的偵測而設計的卷積神經網路 (CNN)。本研究實作了對三種逐漸複雜的 CNN 架構進行比較分析，評估它們對各種臉部影像修改進行分類和定位的能力。系統性地整合正則化和最佳化技術，以改善特徵萃取和效能。結果顯示，所提出的模型在區分處理影像和真實影像方面達到高達 76% 的準確度，超越傳統方法。本研究不僅強調 CNN 在增強數位媒體驗證工具的穩健性方面的潛力，也提供對低運算環境下有效架構調整和訓練策略的見解。未來的研究將建立在這些發現的基礎上，透過擴充架構來處理更多樣化的處理技術，並整合多模式資料以提升偵測能力。

##### **Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**
2412.06624v1 by Sooyong Jang, Kuk Jin Jang, Hyonyoung Choi, Yong-Seop Han, Seongjin Lee, Jin-hyun Kim, Insup Lee

Timely detection and treatment are essential for maintaining eye health.
Visual acuity (VA), which measures the clarity of vision at a distance, is a
crucial metric for managing eye health. Machine learning (ML) techniques have
been introduced to assist in VA measurement, potentially alleviating
clinicians' workloads. However, the inherent uncertainties in ML models make
relying solely on them for VA prediction less than ideal. The VA prediction
task involves multiple sources of uncertainty, requiring more robust
approaches. A promising method is to build prediction sets or intervals rather
than point estimates, offering coverage guarantees through techniques like
conformal prediction and Probably Approximately Correct (PAC) prediction sets.
Despite the potential, to date, these approaches have not been applied to the
VA prediction task.To address this, we propose a method for deriving prediction
intervals for estimating visual acuity from fundus images with a PAC guarantee.
Our experimental results demonstrate that the PAC guarantees are upheld, with
performance comparable to or better than that of two prior works that do not
provide such guarantees.

摘要：及時地偵測和治療對於維持眼睛健康至關重要。
視力（VA），用於測量遠距離視覺的清晰度，是維持眼睛健康的關鍵指標。機器學習（ML）技術已被引入以協助 VA 測量，潛在地減輕臨床醫師的工作負擔。然而，ML 模型中固有的不確定性使得僅依賴它們進行 VA 預測並非理想。VA 預測任務涉及多種不確定性來源，需要更強大的方法。一種有前途的方法是建立預測集合或區間，而不是點估計，通過像共形預測和大概正確（PAC）預測集合這樣的技術提供覆蓋率保證。儘管有潛力，但迄今為止，這些方法尚未應用於 VA 預測任務。為了解決這個問題，我們提出了一種從眼底圖像估計視力的預測區間的方法，並提供 PAC 保證。我們的實驗結果表明，PAC 保證得到維持，其性能與不提供此類保證的兩項先前工作的性能相當或更好。

##### **Copyright-Protected Language Generation via Adaptive Model Fusion**
2412.06619v1 by Javier Abad, Konstantin Donhauser, Francesco Pinto, Fanny Yang

The risk of language models reproducing copyrighted material from their
training data has led to the development of various protective measures. Among
these, inference-time strategies that impose constraints via post-processing
have shown promise in addressing the complexities of copyright regulation.
However, they often incur prohibitive computational costs or suffer from
performance trade-offs. To overcome these limitations, we introduce
Copyright-Protecting Model Fusion (CP-Fuse), a novel approach that combines
models trained on disjoint sets of copyrighted material during inference. In
particular, CP-Fuse adaptively aggregates the model outputs to minimize the
reproduction of copyrighted content, adhering to a crucial balancing property
that prevents the regurgitation of memorized data. Through extensive
experiments, we show that CP-Fuse significantly reduces the reproduction of
protected material without compromising the quality of text and code
generation. Moreover, its post-hoc nature allows seamless integration with
other protective measures, further enhancing copyright safeguards. Lastly, we
show that CP-Fuse is robust against common techniques for extracting training
data.

摘要：語言模型重製訓練資料中的受版權保護材料的風險已導致開發出各種保護措施。其中，透過後處理施加約束的推論時間策略已展現出解決版權法規複雜性的希望。然而，它們經常會產生高昂的運算成本或因效能權衡而受苦。為了解決這些限制，我們引進受版權保護的模型融合 (CP-Fuse)，這是一種新穎的方法，結合推論期間在不相交的受版權保護材料集合上訓練的模型。特別是，CP-Fuse 自適應地彙總模型輸出以最小化受版權保護內容的重製，遵守防止背誦記憶資料的重要平衡屬性。透過廣泛的實驗，我們展示 CP-Fuse 大幅減少受保護材料的重製，同時不損害文字和程式碼產生的品質。此外，其事後性質允許與其他保護措施無縫整合，進一步增強版權保障。最後，我們展示 CP-Fuse 對於用於擷取訓練資料的常見技術具有穩健性。

##### **Towards Controllable Speech Synthesis in the Era of Large Language Models: A Survey**
2412.06602v1 by Tianxin Xie, Yan Rong, Pengfei Zhang, Li Liu

Text-to-speech (TTS), also known as speech synthesis, is a prominent research
area that aims to generate natural-sounding human speech from text. Recently,
with the increasing industrial demand, TTS technologies have evolved beyond
synthesizing human-like speech to enabling controllable speech generation. This
includes fine-grained control over various attributes of synthesized speech
such as emotion, prosody, timbre, and duration. Besides, advancements in deep
learning, such as diffusion and large language models, have significantly
enhanced controllable TTS over the past several years. In this paper, we
conduct a comprehensive survey of controllable TTS, covering approaches ranging
from basic control techniques to methods utilizing natural language prompts,
aiming to provide a clear understanding of the current state of research. We
examine the general controllable TTS pipeline, challenges, model architectures,
and control strategies, offering a comprehensive and clear taxonomy of existing
methods. Additionally, we provide a detailed summary of datasets and evaluation
metrics and shed some light on the applications and future directions of
controllable TTS. To the best of our knowledge, this survey paper provides the
first comprehensive review of emerging controllable TTS methods, which can
serve as a beneficial resource for both academic researchers and industry
practitioners.

摘要：文本轉語音 (TTS)，也稱為語音合成，是一個重要的研究領域，旨在從文字產生聽起來自然的語音。最近，隨著產業需求的增加，TTS 技術已從合成類人語音演進到支援可控語音產生。這包括精細地控制合成語音的各種屬性，例如情緒、語調、音色和持續時間。此外，深度學習的進步，例如擴散和大型語言模型，在過去幾年顯著增強了可控 TTS。在本文中，我們對可控 TTS 進行全面調查，涵蓋從基本控制技術到利用自然語言提示的方法，旨在提供對當前研究狀態的清晰理解。我們探討了通用的可控 TTS 管線、挑戰、模型架構和控制策略，提供現有方法的全面且清晰的分類。此外，我們詳細總結了資料集和評估指標，並說明了可控 TTS 的應用和未來方向。據我們所知，這篇調查報告提供了對新興可控 TTS 方法的第一個全面回顧，這可以作為學術研究人員和產業從業人員的寶貴資源。

##### **Anchoring Bias in Large Language Models: An Experimental Study**
2412.06593v1 by Jiaxu Lou

Large Language Models (LLMs) like GPT-4 and Gemini have significantly
advanced artificial intelligence by enabling machines to generate and
comprehend human-like text. Despite their impressive capabilities, LLMs are not
immune to limitations, including various biases. While much research has
explored demographic biases, the cognitive biases in LLMs have not been equally
scrutinized. This study delves into anchoring bias, a cognitive bias where
initial information disproportionately influences judgment. Utilizing an
experimental dataset, we examine how anchoring bias manifests in LLMs and
verify the effectiveness of various mitigation strategies. Our findings
highlight the sensitivity of LLM responses to biased hints. At the same time,
our experiments show that, to mitigate anchoring bias, one needs to collect
hints from comprehensive angles to prevent the LLMs from being anchored to
individual pieces of information, while simple algorithms such as
Chain-of-Thought, Thoughts of Principles, Ignoring Anchor Hints, and Reflection
are not sufficient.

摘要：大型語言模型 (LLM) 如 GPT-4 和 Gemini 已大幅提升人工智慧，讓機器能夠產生和理解類似人類的文字。儘管具備令人印象深刻的能力，LLM 仍無法避免限制，包括各種偏見。雖然許多研究已探討人口統計偏見，但 LLM 中的認知偏見尚未受到同等程度的審查。本研究深入探討錨定偏誤，這是一種認知偏誤，其中初始資訊會對判斷造成不成比例的影響。利用實驗資料集，我們檢視錨定偏誤如何在 LLM 中表現，並驗證各種緩解策略的有效性。我們的研究結果突顯了 LLM 回應對偏差提示的敏感性。同時，我們的實驗顯示，為了減輕錨定偏誤，需要從全面的角度收集提示，以防止 LLM 被錨定在個別資訊上，而鏈式思考、原則思考、忽略錨定提示和反思等簡單演算法並不足夠。

##### **EmoSpeech: A Corpus of Emotionally Rich and Contextually Detailed Speech Annotations**
2412.06581v1 by Weizhen Bian, Yubo Zhou, Kaitai Zhang, Xiaohan Gu

Advances in text-to-speech (TTS) technology have significantly improved the
quality of generated speech, closely matching the timbre and intonation of the
target speaker. However, due to the inherent complexity of human emotional
expression, the development of TTS systems capable of controlling subtle
emotional differences remains a formidable challenge. Existing emotional speech
databases often suffer from overly simplistic labelling schemes that fail to
capture a wide range of emotional states, thus limiting the effectiveness of
emotion synthesis in TTS applications. To this end, recent efforts have
focussed on building databases that use natural language annotations to
describe speech emotions. However, these approaches are costly and require more
emotional depth to train robust systems. In this paper, we propose a novel
process aimed at building databases by systematically extracting emotion-rich
speech segments and annotating them with detailed natural language descriptions
through a generative model. This approach enhances the emotional granularity of
the database and significantly reduces the reliance on costly manual
annotations by automatically augmenting the data with high-level language
models. The resulting rich database provides a scalable and economically viable
solution for developing a more nuanced and dynamic basis for developing
emotionally controlled TTS systems.

摘要：文字轉語音 (TTS) 技術的進展顯著提升了合成語音的品質，能緊密貼合目標說話者的音色和語調。然而，由於人類情緒表達的複雜性，開發出能控制細微情緒差異的 TTS 系統仍然是一項艱鉅的挑戰。現有的情緒化語音資料庫常常採用過於簡化的標記方案，無法捕捉廣泛的情緒狀態，因此限制了 TTS 應用中情緒合成的有效性。為了解決這個問題，最近的研究專注於建立使用自然語言註解來描述語音情緒的資料庫。然而，這些方法成本高昂，而且需要更多的情緒深度來訓練強健的系統。在本文中，我們提出一個新的流程，旨在透過系統性地萃取情緒豐富的語音片段，並透過生成模型為其加上詳細的自然語言描述，來建立資料庫。這種方法增強了資料庫的情緒粒度，並透過自動使用高階語言模型來擴充資料，大幅降低了對昂貴的人工註解的依賴。產生的豐富資料庫提供了一個可擴充且經濟可行的解決方案，用於建立一個更細緻且動態的基礎，來開發受情緒控制的 TTS 系統。

##### **Data Quality Enhancement on the Basis of Diversity with Large Language Models for Text Classification: Uncovered, Difficult, and Noisy**
2412.06575v1 by Min Zeng, Caiquan Liu, Shiqi Zhang, Li Xie, Chen Sang, Xiaoxin Chen, Xiaoxin Chen

In recent years, the use of large language models (LLMs) for text
classification has attracted widespread attention. Despite this, the
classification accuracy of LLMs has not yet universally surpassed that of
smaller models. LLMs can enhance their performance in text classification
through fine-tuning. However, existing data quality research based on LLMs is
challenging to apply directly to solve text classification problems. To further
improve the performance of LLMs in classification tasks, this paper proposes a
data quality enhancement (DQE) method for text classification based on LLMs.
This method starts by using a greedy algorithm to select data, dividing the
dataset into sampled and unsampled subsets, and then performing fine-tuning of
the LLMs using the sampled data. Subsequently, this model is used to predict
the outcomes for the unsampled data, categorizing incorrectly predicted data
into uncovered, difficult, and noisy data. Experimental results demonstrate
that our method effectively enhances the performance of LLMs in text
classification tasks and significantly improves training efficiency, saving
nearly half of the training time. Our method has achieved state-of-the-art
performance in several open-source classification tasks.

摘要：近年來，使用大型語言模型（LLM）進行文本分類已廣受關注。儘管如此，LLM 的分類準確度尚未普遍超越較小的模型。LLM 可以透過微調來提升其在文本分類中的效能。然而，現有的基於 LLM 的資料品質研究難以直接應用於解決文本分類問題。為了進一步提升 LLM 在分類任務中的效能，本文提出了一種基於 LLM 的文本分類資料品質提升（DQE）方法。此方法首先使用貪婪演算法來選擇資料，將資料集分為取樣和未取樣子集，然後使用取樣資料對 LLM 進行微調。接著，使用此模型來預測未取樣資料的結果，將預測錯誤的資料分類為未涵蓋、困難和雜訊資料。實驗結果證明，我們的模型有效提升了 LLM 在文本分類任務中的效能，並顯著提升訓練效率，節省了將近一半的訓練時間。我們的模型在多項開放原始碼分類任務中達到了最先進的效能。

##### **ProcessBench: Identifying Process Errors in Mathematical Reasoning**
2412.06559v1 by Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin

As language models regularly make mistakes when solving math problems,
automated identification of errors in the reasoning process becomes
increasingly significant for their scalable oversight. In this paper, we
introduce ProcessBench for measuring the ability to identify erroneous steps in
mathematical reasoning. It consists of 3,400 test cases, primarily focused on
competition- and Olympiad-level math problems. Each test case contains a
step-by-step solution with error location annotated by human experts. Models
are required to identify the earliest step that contains an error, or conclude
that all steps are correct. We conduct extensive evaluation on ProcessBench,
involving two types of models: process reward models (PRMs) and critic models,
where for the latter we prompt general language models to critique each
solution step by step. We draw two main observations: (1) Existing PRMs
typically fail to generalize to more challenging math problems beyond GSM8K and
MATH. They underperform both critic models (i.e., prompted general language
models) and our own trained PRM that is straightforwardly fine-tuned on the
PRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has
demonstrated the critique capability competitive with the proprietary model
GPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We
hope ProcessBench can foster future research in reasoning process assessment,
paving the way toward scalable oversight of language models.

摘要：由於語言模型在解決數學問題時經常犯錯，自動化識別推理過程中的錯誤對於其可擴充的監督變得越來越重要。在本文中，我們介紹了 ProcessBench，用於衡量識別數學推理中錯誤步驟的能力。它包含 3,400 個測試案例，主要集中於競賽和奧林匹克級別的數學問題。每個測試案例都包含一個分步解決方案，其中錯誤位置由人類專家註解。模型需要識別包含錯誤的最早步驟，或得出所有步驟都正確的結論。我們對 ProcessBench 進行了廣泛的評估，涉及兩種類型的模型：過程獎勵模型 (PRM) 和批評者模型，後者我們提示通用語言模型逐步驟批評每個解決步驟。我們得出兩個主要觀察結果：(1) 現有的 PRM 通常無法概括到 GSM8K 和 MATH 之外更具挑戰性的數學問題。它們的表現不如批評者模型（即提示的通用語言模型）和我們自己訓練的 PRM，該 PRM 在 PRM800K 數據集上進行了直接微調。(2) 最好的開源模型 QwQ-32B-Preview 已展示出與專有模型 GPT-4o 相當的批評能力，儘管它仍然落後於推理專用的 o1-mini。我們希望 ProcessBench 能夠促進未來在推理過程評估方面的研究，為語言模型的可擴充監督鋪平道路。

##### **Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families**
2412.06540v1 by Felipe Maia Polo, Seamus Somerstep, Leshem Choshen, Yuekai Sun, Mikhail Yurochkin

Scaling laws for large language models (LLMs) predict model performance based
on parameters like size and training data. However, differences in training
configurations and data processing across model families lead to significant
variations in benchmark performance, making it difficult for a single scaling
law to generalize across all LLMs. On the other hand, training family-specific
scaling laws requires training models of varying sizes for every family. In
this work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a
novel scaling law that leverages publicly available benchmark data and assumes
LLM performance is driven by low-dimensional latent skills, such as reasoning
and instruction following. These latent skills are influenced by computational
resources like model size and training tokens but with varying efficiencies
across model families. Sloth exploits correlations across benchmarks to provide
more accurate and interpretable predictions while alleviating the need to train
multiple LLMs per family. We present both theoretical results on parameter
identification and empirical evaluations on 12 prominent benchmarks, from Open
LLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance
efficiently and offers insights into scaling behaviors for downstream tasks
such as coding and emotional intelligence applications.

摘要：大型語言模型 (LLM) 的規模定律預測模型效能基於大小和訓練資料等參數。然而，在模型家族中訓練組態和資料處理的差異導致基準效能有顯著的變化，使得單一規模定律難以概括所有 LLM。另一方面，訓練特定於家族的規模定律需要為每個家族訓練不同規模的模型。在這項工作中，我們提出技能規模定律 (SSLaws，發音為 Sloth)，一種創新的規模定律，利用公開可用的基準資料，並假設 LLM 效能是由低維度潛在技能驅動的，例如推理和指令遵循。這些潛在技能受到模型大小和訓練標記等計算資源的影響，但在不同模型家族中效率不同。Sloth 利用基準之間的關聯性提供更準確且可解釋的預測，同時減輕訓練每個家族多個 LLM 的需求。我們在參數辨識上提出理論結果，並在 12 個 Open LLM Leaderboard v1/v2 中進行實證評估，證明 Sloth 有效預測 LLM 效能，並提供對下游任務（例如編碼和情緒智力應用）的規模行為見解。

##### **Understanding Factual Recall in Transformers via Associative Memories**
2412.06538v1 by Eshaan Nichani, Jason D. Lee, Alberto Bietti

Large language models have demonstrated an impressive ability to perform
factual recall. Prior work has found that transformers trained on factual
recall tasks can store information at a rate proportional to their parameter
count. In our work, we show that shallow transformers can use a combination of
associative memories to obtain such near optimal storage capacity. We begin by
proving that the storage capacities of both linear and MLP associative memories
scale linearly with parameter count. We next introduce a synthetic factual
recall task, and prove that a transformer with a single layer of self-attention
followed by an MLP can obtain 100% accuracy on the task whenever either the
total number of self-attention parameters or MLP parameters scales (up to log
factors) linearly with the number of facts. In particular, the transformer can
trade off between using the value matrices or the MLP as an associative memory
to store the dataset of facts. We complement these expressivity results with an
analysis of the gradient flow trajectory of a simplified linear attention model
trained on our factual recall task, where we show that the model exhibits
sequential learning behavior.

摘要：大型語言模型已證明其具備令人印象深刻的執行事實回憶的能力。先前的研究發現，針對事實回憶任務訓練的Transformer可以以與其參數計數成正比的速度儲存資訊。在我們的研究中，我們展示了淺層Transformer可以使用聯想記憶體的組合來獲得這種接近最佳的儲存容量。我們首先證明了線性聯想記憶體和 MLP 聯想記憶體的儲存容量與參數計數成正比。接下來，我們引入了一個合成事實回憶任務，並證明了一個具有單層自注意力，後接 MLP 的Transformer可以在任務中獲得 100% 的準確度，只要自注意力參數或 MLP 參數的總數（最多為 log 因子）與事實數量成線性比例。特別是，Transformer可以在使用值矩陣或 MLP 作為聯想記憶體來儲存事實資料集之間進行權衡。我們用對在我們的現實回憶任務中訓練的簡化線性注意力模型的梯度流軌跡的分析來補充這些表現力結果，其中我們展示了該模型表現出順序學習行為。

##### **HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**
2412.06530v1 by Jiayan Chen, Kai Li, Zhanjin Wang, Zhan Wang, Jianqiang Huang

Hepatic echinococcosis (HE) is a prevalent disease in economically
underdeveloped pastoral areas, where adequate medical resources are usually
lacking. Existing methods often ignore multi-scale feature fusion or focus only
on feature fusion between adjacent levels, which may lead to insufficient
feature fusion. To address these issues, we propose HES-UNet, an efficient and
accurate model for HE lesion segmentation. This model combines convolutional
layers and attention modules to capture local and global features. During
downsampling, the multi-directional downsampling block (MDB) is employed to
integrate high-frequency and low-frequency features, effectively extracting
image details. The multi-scale aggregation block (MAB) aggregates multi-scale
feature information. In contrast, the multi-scale upsampling Block (MUB) learns
highly abstract features and supplies this information to the skip connection
module to fuse multi-scale features. Due to the distinct regional
characteristics of HE, there is currently no publicly available high-quality
dataset for training our model. We collected CT slice data from 268 patients at
a certain hospital to train and evaluate the model. The experimental results
show that HES-UNet achieves state-of-the-art performance on our dataset,
achieving an overall Dice Similarity Coefficient (DSC) of 89.21%, which is
1.09% higher than that of TransUNet. The project page is available at
https://chenjiayan-qhu.github.io/HES-UNet-page.

摘要：肝包蟲病（HE）在經濟落後的畜牧地區盛行，那裡通常缺乏足夠的醫療資源。現有方法通常忽略多尺度特徵融合，或僅關注相鄰層之間的特徵融合，這可能導致特徵融合不足。為了解決這些問題，我們提出了 HES-UNet，這是一種用於 HE 病灶分割的高效且準確的模型。此模型結合了卷積層和注意力模組，以擷取局部和全局特徵。在降採樣過程中，採用多向降採樣區塊 (MDB) 來整合高頻和低頻特徵，有效提取影像細節。多尺度聚合區塊 (MAB) 聚合多尺度特徵資訊。相反，多尺度上採樣區塊 (MUB) 會學習高度抽象的特徵，並將此資訊提供給跳躍連接模組，以融合多尺度特徵。由於 HE 的區域特徵不同，目前沒有公開可用的高品質資料集可供訓練我們的模型。我們從某家醫院收集了 268 位患者的 CT 切片資料，以訓練和評估模型。實驗結果表明，HES-UNet 在我們的資料集上達到了最先進的效能，整體 Dice 相似性係數 (DSC) 達到 89.21%，比 TransUNet 高 1.09%。專案頁面可於 https://chenjiayan-qhu.github.io/HES-UNet-page 取得。

##### **The Fusion of Large Language Models and Formal Methods for Trustworthy AI Agents: A Roadmap**
2412.06512v1 by Yedi Zhang, Yufan Cai, Xinyue Zuo, Xiaokun Luan, Kailong Wang, Zhe Hou, Yifan Zhang, Zhiyuan Wei, Meng Sun, Jun Sun, Jing Sun, Jin Song Dong

Large Language Models (LLMs) have emerged as a transformative AI paradigm,
profoundly influencing daily life through their exceptional language
understanding and contextual generation capabilities. Despite their remarkable
performance, LLMs face a critical challenge: the propensity to produce
unreliable outputs due to the inherent limitations of their learning-based
nature. Formal methods (FMs), on the other hand, are a well-established
computation paradigm that provides mathematically rigorous techniques for
modeling, specifying, and verifying the correctness of systems. FMs have been
extensively applied in mission-critical software engineering, embedded systems,
and cybersecurity. However, the primary challenge impeding the deployment of
FMs in real-world settings lies in their steep learning curves, the absence of
user-friendly interfaces, and issues with efficiency and adaptability.
  This position paper outlines a roadmap for advancing the next generation of
trustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs.
First, we illustrate how FMs, including reasoning and certification techniques,
can help LLMs generate more reliable and formally certified outputs.
Subsequently, we highlight how the advanced learning capabilities and
adaptability of LLMs can significantly enhance the usability, efficiency, and
scalability of existing FM tools. Finally, we show that unifying these two
computation paradigms -- integrating the flexibility and intelligence of LLMs
with the rigorous reasoning abilities of FMs -- has transformative potential
for the development of trustworthy AI software systems. We acknowledge that
this integration has the potential to enhance both the trustworthiness and
efficiency of software engineering practices while fostering the development of
intelligent FM tools capable of addressing complex yet real-world challenges.

摘要：大型語言模型 (LLM) 已成為一種變革性的 AI 典範，
透過其卓越的語言理解和情境生成能力，對日常生活產生深遠的影響。儘管表現非凡，
LLM 面臨一項嚴峻的挑戰：由於其基於學習的本質所固有的限制，
容易產生不可靠的輸出。另一方面，形式化方法 (FM) 是一種完善的
計算範例，它提供嚴謹的數學技術，用於建模、指定和驗證系統的正確性。FM 已廣泛應用於任務關鍵型軟體工程、嵌入式系統，
與網路安全。然而，阻礙 FM 在實際環境中部署的主要挑戰在於其陡峭的學習曲線、缺乏
使用者友善的介面，以及效率和適應性問題。
這篇立場文件概述了一個藍圖，用於透過利用 LLM 和 FM 的相互強化來推進下一代值得信賴的 AI 系統。
首先，我們說明 FM，包括推理和認證技術，如何能協助 LLM 產生更可靠且經過正式認證的輸出。
隨後，我們強調 LLM 的先進學習能力和適應性如何能顯著增強現有 FM 工具的可用性、效率和
可擴充性。最後，我們表明統一這兩個計算範例——整合 LLM 的靈活性與智慧，
以及 FM 的嚴謹推理能力——對於開發值得信賴的 AI 軟體系統具有變革潛力。我們承認，
這種整合有可能同時增強軟體工程實務的信賴度和效率，同時促進能夠解決複雜但真實世界挑戰的智慧 FM 工具的開發。

##### **AnomalyControl: Learning Cross-modal Semantic Features for Controllable Anomaly Synthesis**
2412.06510v1 by Shidan He, Lei Liu, Shen Zhao

Anomaly synthesis is a crucial approach to augment abnormal data for
advancing anomaly inspection. Based on the knowledge from the large-scale
pre-training, existing text-to-image anomaly synthesis methods predominantly
focus on textual information or coarse-aligned visual features to guide the
entire generation process. However, these methods often lack sufficient
descriptors to capture the complicated characteristics of realistic anomalies
(e.g., the fine-grained visual pattern of anomalies), limiting the realism and
generalization of the generation process. To this end, we propose a novel
anomaly synthesis framework called AnomalyControl to learn cross-modal semantic
features as guidance signals, which could encode the generalized anomaly cues
from text-image reference prompts and improve the realism of synthesized
abnormal samples. Specifically, AnomalyControl adopts a flexible and
non-matching prompt pair (i.e., a text-image reference prompt and a targeted
text prompt), where a Cross-modal Semantic Modeling (CSM) module is designed to
extract cross-modal semantic features from the textual and visual descriptors.
Then, an Anomaly-Semantic Enhanced Attention (ASEA) mechanism is formulated to
allow CSM to focus on the specific visual patterns of the anomaly, thus
enhancing the realism and contextual relevance of the generated anomaly
features. Treating cross-modal semantic features as the prior, a Semantic
Guided Adapter (SGA) is designed to encode effective guidance signals for the
adequate and controllable synthesis process. Extensive experiments indicate
that AnomalyControl can achieve state-of-the-art results in anomaly synthesis
compared with existing methods while exhibiting superior performance for
downstream tasks.

摘要：異常合成是擴充異常資料以推動異常檢查的一種關鍵方法。根據大規模預訓練的知識，現有的文字轉圖像異常合成方法主要關注文字資訊或粗略對齊的視覺特徵，以引導整個生成過程。然而，這些方法通常缺乏足夠的描述符來捕捉逼真異常的複雜特徵（例如，異常的細粒度視覺模式），限制了生成過程的真實性和概括性。為此，我們提出了一個名為 AnomalyControl 的新型異常合成架構，以學習跨模態語義特徵作為指導信號，這可以編碼來自文字圖像參考提示的廣義異常線索，並提高合成異常樣本的真實性。具體而言，AnomalyControl 採用了一個靈活且不匹配的提示對（即文字圖像參考提示和目標文字提示），其中跨模態語義建模 (CSM) 模組被設計為從文字和視覺描述符中提取跨模態語義特徵。然後，制定一個異常語義增強注意力 (ASEA) 機制，以允許 CSM 專注於異常的特定視覺模式，從而增強生成異常特徵的真實性和上下文相關性。將跨模態語義特徵視為先驗，設計了一個語義引導適配器 (SGA) 來編碼足夠且可控的合成過程的有效指導信號。大量的實驗表明，與現有方法相比，AnomalyControl 可以實現異常合成中的最新結果，同時在後續任務中表現出優異的效能。

##### **SimuDICE: Offline Policy Optimization Through World Model Updates and DICE Estimation**
2412.06486v1 by Catalin E. Brita, Stephan Bongers, Frans A. Oliehoek

In offline reinforcement learning, deriving an effective policy from a
pre-collected set of experiences is challenging due to the distribution
mismatch between the target policy and the behavioral policy used to collect
the data, as well as the limited sample size. Model-based reinforcement
learning improves sample efficiency by generating simulated experiences using a
learned dynamic model of the environment. However, these synthetic experiences
often suffer from the same distribution mismatch. To address these challenges,
we introduce SimuDICE, a framework that iteratively refines the initial policy
derived from offline data using synthetically generated experiences from the
world model. SimuDICE enhances the quality of these simulated experiences by
adjusting the sampling probabilities of state-action pairs based on stationary
DIstribution Correction Estimation (DICE) and the estimated confidence in the
model's predictions. This approach guides policy improvement by balancing
experiences similar to those frequently encountered with ones that have a
distribution mismatch. Our experiments show that SimuDICE achieves performance
comparable to existing algorithms while requiring fewer pre-collected
experiences and planning steps, and it remains robust across varying data
collection policies.

摘要：在離線強化學習中，由於目標策略與用於收集資料的行為策略之間的分配不匹配，以及有限的樣本大小，因此從預先收集的一組經驗中推导出有效的策略具有挑戰性。基於模型的強化學習通過使用環境的學習動態模型來生成模擬經驗，從而提高樣本效率。然而，這些合成經驗通常會遭受相同的分配不匹配。為了應對這些挑戰，我們引入了 SimuDICE，這是一個框架，它使用來自世界模型的合成生成經驗，反覆優化從離線資料中得出的初始策略。SimuDICE 通過根據穩態 DIstribution Correction Estimation (DICE) 和對模型預測的估計置信度調整狀態動作對的抽樣機率，來提高這些模擬經驗的品質。這種方法通過平衡經常遇到的經驗與分佈不匹配的經驗，來指導策略改進。我們的實驗表明，SimuDICE 達到了與現有演算法相當的效能，同時需要較少的預先收集的經驗和規劃步驟，並且在不同的資料收集策略中保持穩健。

##### **Small Languages, Big Models: A Study of Continual Training on Languages of Norway**
2412.06484v1 by David Samuel, Vladislav Mikhailov, Erik Velldal, Lilja Øvrelid, Lucas Georges Gabriel Charpentier, Andrey Kutuzov

Training large language models requires vast amounts of data, posing a
challenge for less widely spoken languages like Norwegian and even more so for
truly low-resource languages like S\'ami. To address this issue, we present a
novel three-stage continual training approach. We also experiment with
combining causal and masked language modeling to get more flexible models.
Based on our findings, we train, evaluate, and openly release a new large
generative language model for Norwegian Bokm\r{a}l, Nynorsk, and Northern
S\'ami with 11.4 billion parameters: NorMistral-11B.

摘要：訓練大型語言模型需要大量的資料，對較少人使用的語言（例如挪威語）構成挑戰，更何況是像薩米語這種資源極度匱乏的語言。為了解決這個問題，我們提出了一種新穎的三階段持續訓練方法。我們也嘗試結合因果關係和遮蔽語言模型，以獲得更靈活的模型。根據我們的發現，我們訓練、評估並公開發布了一個新的挪威語博克馬爾語、新挪威語和北薩米語的大型生成語言模型，參數達 114 億：NorMistral-11B。

##### **SafeWorld: Geo-Diverse Safety Alignment**
2412.06483v1 by Da Yin, Haoyi Qiu, Kung-Hsiang Huang, Kai-Wei Chang, Nanyun Peng

In the rapidly evolving field of Large Language Models (LLMs), ensuring
safety is a crucial and widely discussed topic. However, existing works often
overlook the geo-diversity of cultural and legal standards across the world. To
demonstrate the challenges posed by geo-diverse safety standards, we introduce
SafeWorld, a novel benchmark specifically designed to evaluate LLMs' ability to
generate responses that are not only helpful but also culturally sensitive and
legally compliant across diverse global contexts. SafeWorld encompasses 2,342
test user queries, each grounded in high-quality, human-verified cultural norms
and legal policies from 50 countries and 493 regions/races. On top of it, we
propose a multi-dimensional automatic safety evaluation framework that assesses
the contextual appropriateness, accuracy, and comprehensiveness of responses.
Our evaluations reveal that current LLMs struggle to meet these criteria. To
enhance LLMs' alignment with geo-diverse safety standards, we synthesize
helpful preference pairs for Direct Preference Optimization (DPO) alignment
training. The preference pair construction aims to encourage LLMs to behave
appropriately and provide precise references to relevant cultural norms and
policies when necessary. Our trained SafeWorldLM outperforms all competing
models, including GPT-4o on all three evaluation dimensions by a large margin.
Global human evaluators also note a nearly 20% higher winning rate in
helpfulness and harmfulness evaluation. Our code and data can be found here:
https://github.com/PlusLabNLP/SafeWorld.

摘要：在快速演進的大語言模型 (LLM) 領域中，確保安全是一個至關重要且廣泛討論的主題。然而，現有研究經常忽略全球文化和法律標準的地理多樣性。為了展示地理多樣性安全標準帶來的挑戰，我們引入了 SafeWorld，一個專門設計來評估 LLM 產生回應的能力的新基準，這些回應不僅有幫助，而且在不同的全球背景下具有文化敏感性和法律合規性。SafeWorld 涵蓋了 2,342 個測試使用者查詢，每個查詢都基於來自 50 個國家和 493 個地區/種族的優質、人工驗證的文化規範和法律政策。最重要的是，我們提出了一個多維度的自動安全評估框架，用於評估回應的上下文適當性、準確性和全面性。我們的評估表明，目前的 LLM 難以滿足這些標準。為了增強 LLM 與地理多樣性安全標準的一致性，我們綜合了有用的偏好對，用於直接偏好最佳化 (DPO) 對齊訓練。偏好對的建構旨在鼓勵 LLM 適當地表現，並在必要時提供與相關文化規範和政策的精確參考。我們訓練的 SafeWorldLM 在所有三個評估維度上都大幅優於所有競爭模型，包括 GPT-4o。全球人類評估員還注意到在有幫助性和有害性評估中獲勝率提高了近 20%。我們的程式碼和資料可以在這裡找到：https://github.com/PlusLabNLP/SafeWorld。

##### **From Uncertainty to Trust: Enhancing Reliability in Vision-Language Models with Uncertainty-Guided Dropout Decoding**
2412.06474v1 by Yixiong Fang, Ziran Yang, Zhaorun Chen, Zhuokai Zhao, Jiawei Zhou

Large vision-language models (LVLMs) demonstrate remarkable capabilities in
multimodal tasks but are prone to misinterpreting visual inputs, often
resulting in hallucinations and unreliable outputs. To address these
challenges, we propose Dropout Decoding, a novel inference-time approach that
quantifies the uncertainty of visual tokens and selectively masks uncertain
tokens to improve decoding. Our method measures the uncertainty of each visual
token by projecting it onto the text space and decomposing it into aleatoric
and epistemic components. Specifically, we focus on epistemic uncertainty,
which captures perception-related errors more effectively. Inspired by dropout
regularization, we introduce uncertainty-guided token dropout, which applies
the dropout principle to input visual tokens instead of model parameters, and
during inference rather than training. By aggregating predictions from an
ensemble of masked decoding contexts, Dropout Decoding robustly mitigates
errors arising from visual token misinterpretations. Evaluations on benchmarks
including CHAIR, THRONE, and MMBench demonstrate that Dropout Decoding
significantly reduces object hallucinations (OH) and enhances both reliability
and quality of LVLM outputs across diverse visual contexts.

摘要：大型視覺語言模型 (LVLMs) 在多模態任務中展現出非凡的能力，但容易誤解視覺輸入，經常導致幻覺和不可靠的輸出。為了應對這些挑戰，我們提出 Dropout Decoding，這是一種新穎的推論時間方法，它量化視覺符號的不確定性，並選擇性地遮罩不確定的符號以改善解碼。我們的模型通過將每個視覺符號投射到文本空間並將其分解為隨機和認識論組成部分，來衡量每個視覺符號的不確定性。具體來說，我們專注於認識論不確定性，它更有效地捕捉與感知相關的錯誤。在 Dropout 正則化的啟發下，我們引入了不確定性引導符號 Dropout，它將 Dropout 原理應用於輸入視覺符號，而不是模型參數，並且在推論期間而不是訓練期間。通過匯總來自遮罩解碼上下文的預測，Dropout Decoding 強有力地減輕了源自視覺符號誤解的錯誤。在包括 CHAIR、THRONE 和 MMBench 在內的基準上的評估表明，Dropout Decoding 大幅減少了物件幻覺 (OH)，並增強了 LVLM 輸出在各種視覺環境中的可靠性和品質。

##### **Gated Delta Networks: Improving Mamba2 with Delta Rule**
2412.06464v1 by Songlin Yang, Jan Kautz, Ali Hatamizadeh

Linear Transformers have gained attention as efficient alternatives to
standard Transformers, but their performance in retrieval and long-context
tasks has been limited. To address these limitations, recent work has explored
two distinct mechanisms: gating for adaptive memory control and the delta
update rule for precise memory modifications. We observe that these mechanisms
are complementary: gating enables rapid memory erasure while the delta rule
facilitates targeted updates. Building on this insight, we introduce the gated
delta rule and develop a parallel training algorithm optimized for modern
hardware. Our proposed architecture, Gated DeltaNet, consistently surpasses
existing models like Mamba2 and DeltaNet across multiple benchmarks, including
language modeling, common-sense reasoning, in-context retrieval, length
extrapolation, and long-context understanding. We further enhance performance
by developing hybrid architectures that combine Gated DeltaNet layers with
sliding window attention or Mamba2 layers, achieving both improved training
efficiency and superior task performance.

摘要：線性Transformer作為標準Transformer的有效替代方案而受到關注，但它們在檢索和長語境任務中的表現受到限制。為了解決這些限制，最近的研究探索了兩種不同的機制：用於自適應記憶體控制的閘控和用於精確記憶體修改的 delta 更新規則。我們觀察到這些機制是互補的：閘控允許快速記憶體擦除，而 delta 規則則促進有針對性的更新。基於此見解，我們引入了閘控 delta 規則，並開發了一種針對現代硬體最佳化的並行訓練演算法。我們提出的架構 Gated DeltaNet 在多個基準測試中始終超越現有模型，例如 Mamba2 和 DeltaNet，包括語言建模、常識推理、語境檢索、長度外推和長語境理解。我們進一步透過開發結合 Gated DeltaNet 層與滑動視窗注意力或 Mamba2 層的混合架構來增強效能，同時提高訓練效率和優異的任務效能。

##### **How Certain are Uncertainty Estimates? Three Novel Earth Observation Datasets for Benchmarking Uncertainty Quantification in Machine Learning**
2412.06451v1 by Yuanyuan Wang, Qian Song, Dawood Wasif, Muhammad Shahzad, Christoph Koller, Jonathan Bamber, Xiao Xiang Zhu

Uncertainty quantification (UQ) is essential for assessing the reliability of
Earth observation (EO) products. However, the extensive use of machine learning
models in EO introduces an additional layer of complexity, as those models
themselves are inherently uncertain. While various UQ methods do exist for
machine learning models, their performance on EO datasets remains largely
unevaluated. A key challenge in the community is the absence of the ground
truth for uncertainty, i.e. how certain the uncertainty estimates are, apart
from the labels for the image/signal. This article fills this gap by
introducing three benchmark datasets specifically designed for UQ in EO machine
learning models. These datasets address three common problem types in EO:
regression, image segmentation, and scene classification. They enable a
transparent comparison of different UQ methods for EO machine learning models.
We describe the creation and characteristics of each dataset, including data
sources, preprocessing steps, and label generation, with a particular focus on
calculating the reference uncertainty. We also showcase baseline performance of
several machine learning models on each dataset, highlighting the utility of
these benchmarks for model development and comparison. Overall, this article
offers a valuable resource for researchers and practitioners working in
artificial intelligence for EO, promoting a more accurate and reliable quality
measure of the outputs of machine learning models. The dataset and code are
accessible via https://gitlab.lrz.de/ai4eo/WG_Uncertainty.

摘要：不確定量化 (UQ) 對於評估地球觀測 (EO) 產品的可靠性至關重要。然而，機器學習模型在 EO 中的廣泛使用引入了額外的複雜性，因為這些模型本身就具有不確定性。儘管存在各種針對機器學習模型的 UQ 方法，但它們在 EO 資料集上的效能仍未得到充分評估。社群中的主要挑戰是缺乏不確定性的基本事實，即不確定性估計的確定程度，除了影像/訊號的標籤之外。本文透過導入專門針對 EO 機器學習模型中的 UQ 設計的三個基準資料集來填補此空白。這些資料集解決了 EO 中的三個常見問題類型：迴歸、影像分割和場景分類。它們能針對 EO 機器學習模型的不同 UQ 方法進行透明的比較。我們描述了每個資料集的建立和特徵，包括資料來源、前處理步驟和標籤產生，特別關注參考不確定性的計算。我們還展示了多個機器學習模型在每個資料集上的基準效能，強調了這些基準對模型開發和比較的有用性。總體而言，本文為在 EO 中從事人工智慧的研究人員和從業人員提供了寶貴的資源，推廣了更準確且可靠的機器學習模型輸出品質衡量標準。資料集和程式碼可透過 https://gitlab.lrz.de/ai4eo/WG_Uncertainty 取得。

##### **BoRA: Bi-dimensional Weight-Decomposed Low-Rank Adaptation**
2412.06441v1 by Qiushi Wang, Yuchen Fan, Junwei Bao, Hongfei Jiang, Yang Song

In recent years, Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank
Adaptation (LoRA) have significantly enhanced the adaptability of large-scale
pre-trained models. Weight-Decomposed Low-Rank Adaptation (DoRA) improves upon
LoRA by separating the magnitude and direction components of the weight matrix,
leading to superior performance. However, DoRA's improvements are limited to
the vertical dimension, resulting in an asymmetrical pattern between horizontal
and vertical dimensions. This paper introduces BoRA, an innovative extension of
LoRA and DoRA, characterized by symmetrical properties across horizontal and
vertical dimensions. Our approach optimizes the weight matrix symmetrically by
adjusting both column-wise and row-wise magnitudes. Extensive experiments
demonstrate that BoRA surpasses state-of-the-art PEFT methods, including LoRA
and DoRA, achieving superior results across various benchmarks.

摘要：近年來，參數高效微調 (PEFT) 方法（例如低秩適應 (LoRA)）顯著提升了大規模預訓練模型的適應性。權重分解低秩適應 (DoRA) 透過將權重矩陣的幅度和方向組成分離，進而改善 LoRA，進而提升效能。然而，DoRA 的改善僅限於垂直維度，導致水平維度和垂直維度之間出現不對稱模式。本文介紹 BoRA，這是 LoRA 和 DoRA 的創新延伸，其特徵在於橫向和縱向維度之間具有對稱特性。我們的做法透過調整逐列和逐列幅度，對稱地最佳化權重矩陣。廣泛的實驗證明，BoRA 超越了最先進的 PEFT 方法，包括 LoRA 和 DoRA，在各種基準測試中取得了優異的結果。

##### **Simulating Human-like Daily Activities with Desire-driven Autonomy**
2412.06435v1 by Yiding Wang, Yuxuan Chen, Fangwei Zhong, Long Ma, Yizhou Wang

Existing task-oriented AI agents often depend on explicit instructions or
external rewards, limiting their ability to be driven by intrinsic motivations
like humans. In this paper, we present a desire-driven autonomy framework to
guide a Large Language Model-based (LLM-based) agent to simulate human-like
daily activities. In contrast to previous agents, our Desire-driven Autonomous
Agent (D2A) operates on the principle of intrinsic desire, allowing it to
propose and select tasks that fulfill its motivational framework autonomously.
Inspired by the Theory of Needs, the motivational framework incorporates an
understanding of human-like desires, such as the need for social interaction,
personal fulfillment, and self-care. Utilizing a desire-driven task generation
mechanism, the agent evaluates its current state and takes a sequence of
activities aligned with its intrinsic motivations. Through simulations, we
demonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,
contextually relevant daily activities while exhibiting variability and
adaptability similar to human behavior. A comparative analysis with other
LLM-based frameworks demonstrates that our approach significantly enhances the
rationality of the simulated activities.

摘要：現有的任務導向 AI 代理通常依賴明確的指示或外部獎勵，這限制了它們像人類一樣由內在動機驅動的能力。在本文中，我們提出了一個慾望驅動的自主框架，以指導基於大型語言模型 (LLM) 的代理模擬類人的日常活動。與之前的代理不同，我們的慾望驅動自主代理 (D2A) 遵循內在慾望的原則，允許它自主提出和選擇符合其動機框架的任務。受需求理論的啟發，動機框架包含對類人慾望的理解，例如社會互動、個人滿足和自我保健的需要。利用慾望驅動任務生成機制，代理評估其當前狀態並採取一系列與其內在動機一致的活動。通過模擬，我們證明了我們的慾望驅動自主代理 (D2A) 產生了連貫、與上下文相關的日常活動，同時表現出與人類行為相似的可變性和適應性。與其他基於 LLM 的框架進行比較分析表明，我們的做法顯著提高了模擬活動的合理性。

##### **Integrating Expert Labels into LLM-based Emission Goal Detection: Example Selection vs Automatic Prompt Design**
2412.06432v1 by Marco Wrzalik, Adrian Ulges, Anne Uersfeld, Florian Faust

We address the detection of emission reduction goals in corporate reports, an
important task for monitoring companies' progress in addressing climate change.
Specifically, we focus on the issue of integrating expert feedback in the form
of labeled example passages into LLM-based pipelines, and compare the two
strategies of (1) a dynamic selection of few-shot examples and (2) the
automatic optimization of the prompt by the LLM itself. Our findings on a
public dataset of 769 climate-related passages from real-world business reports
indicate that automatic prompt optimization is the superior approach, while
combining both methods provides only limited benefit. Qualitative results
indicate that optimized prompts do indeed capture many intricacies of the
targeted emission goal extraction task.

摘要：我們探討企業報告中排放減量目標的偵測，這是監控公司在因應氣候變遷進度方面的一項重要任務。具體來說，我們專注於以標籤範例段落形式整合專家回饋到基於 LLM 的管道，並比較兩種策略：(1) 少數範例的動態選擇，以及 (2) LLM 本身對提示的自動最佳化。我們在來自真實商業報告的 769 篇與氣候相關段落的公開資料集上的研究結果指出，自動提示最佳化是較好的方法，而結合兩種方法僅能提供有限的益處。定性結果指出，最佳化的提示確實捕捉到目標排放目標萃取任務的許多複雜性。

##### **LLM-BIP: Structured Pruning for Large Language Models with Block-Wise Forward Importance Propagation**
2412.06419v1 by Haihang Wu

Large language models (LLMs) have demonstrated remarkable performance across
various language tasks, but their widespread deployment is impeded by their
large size and high computational costs. Structural pruning is a prevailing
technique used to introduce sparsity into pre-trained models and facilitate
direct hardware acceleration during inference by removing redundant connections
(structurally-grouped parameters), such as channels and attention heads.
Existing structural pruning approaches often employ either global or layer-wise
pruning criteria; however, they are hindered by ineffectiveness stemming from
inaccurate evaluation of connection importance. Global pruning methods
typically assess component importance using near-zero and unreliable gradients,
while layer-wise pruning approaches encounter significant pruning error
accumulation issues. To this end, we propose a more accurate pruning metric
based on the block-wise importance score propagation, termed LLM-BIP.
Specifically, LLM-BIP precisely evaluates connection importance by gauging its
influence on the respective transformer block output, which can be efficiently
approximated in a single forward pass through an upper bound derived from the
assumption of Lipschitz continuity. We evaluate the proposed method using
LLaMA-7B, Vicuna-7B, and LLaMA-13B across common zero-shot tasks. The results
demonstrate that our approach achieves an average of 3.26% increase in accuracy
for common reasoning tasks compared to previous best baselines. It also reduces
perplexity by 14.09 and 68.76 on average for the WikiText2 dataset and PTB
dataset, respectively.

摘要：大型語言模型 (LLM) 已在各種語言任務中展現出卓越的效能，但其廣泛部署受到其龐大規模和高運算成本的阻礙。結構化剪枝是一種普遍用於在預訓練模型中引入稀疏性，並透過移除多餘連接（結構化群組參數），例如通道和注意力頭部，以利於在推論期間直接硬體加速的技術。現有的結構化剪枝方法通常採用全域或逐層剪枝準則；然而，它們受到源自於連接重要性評估不準確所造成的無效性阻礙。全域剪枝方法通常使用接近於零且不可靠的梯度來評估組成部分的重要性，而逐層剪枝方法則會遭遇顯著的剪枝誤差累積問題。為此，我們提出一個更精確的剪枝指標，其基於區塊式重要性分數傳播，稱為 LLM-BIP。具體來說，LLM-BIP 精確地評估連接的重要性，方法是評估其對應Transformer區塊輸出的影響，而這可以用一個前向傳遞中的單一上限來有效近似，該上限源自於 Lipschitz 連續性的假設。我們使用 LLaMA-7B、Vicuna-7B 和 LLaMA-13B 在常見的零次任務中評估所提出的方法。結果表明，與先前的最佳基準線相比，我們的做法在常見推理任務中平均提高了 3.26% 的準確度。它還分別將 WikiText2 資料集和 PTB 資料集的困惑度平均降低了 14.09 和 68.76。

##### **StarWhisper Telescope: Agent-Based Observation Assistant System to Approach AI Astrophysicist**
2412.06412v1 by Cunshi Wang, Xinjie Hu, Yu Zhang, Xunhao Chen, Pengliang Du, Yiming Mao, Rui Wang, Yuyang Li, Ying Wu, Hang Yang, Yansong Li, Beichuan Wang, Haiyang Mu, Zheng Wang, Jianfeng Tian, Liang Ge, Yongna Mao, Shengming Li, Xiaomeng Lu, Jinhang Zou, Yang Huang, Ningchen Sun, Jie Zheng, Min He, Yu Bai, Junjie Jin, Hong Wu, Chaohui Shang, Jifeng Liu

With the rapid advancements in Large Language Models (LLMs), LLM-based agents
have introduced convenient and user-friendly methods for leveraging tools
across various domains. In the field of astronomical observation, the
construction of new telescopes has significantly increased astronomers'
workload. Deploying LLM-powered agents can effectively alleviate this burden
and reduce the costs associated with training personnel. Within the Nearby
Galaxy Supernovae Survey (NGSS) project, which encompasses eight telescopes
across three observation sites, aiming to find the transients from the galaxies
in 50 mpc, we have developed the \textbf{StarWhisper Telescope System} to
manage the entire observation process. This system automates tasks such as
generating observation lists, conducting observations, analyzing data, and
providing feedback to the observer. Observation lists are customized for
different sites and strategies to ensure comprehensive coverage of celestial
objects. After manual verification, these lists are uploaded to the telescopes
via the agents in the system, which initiates observations upon neutral
language. The observed images are analyzed in real-time, and the transients are
promptly communicated to the observer. The agent modifies them into a real-time
follow-up observation proposal and send to the Xinglong observatory group chat,
then add them to the next-day observation lists. Additionally, the integration
of AI agents within the system provides online accessibility, saving
astronomers' time and encouraging greater participation from amateur
astronomers in the NGSS project.

摘要：隨著大型語言模型 (LLM) 的快速進展，基於 LLM 的代理引入了便利且使用者友善的方法，用於在各種領域中運用工具。在天文觀測領域中，建造新的望遠鏡大幅增加了天文學家的工作負擔。部署由 LLM 驅動的代理可以有效減輕這種負擔，並降低與人員訓練相關的成本。在鄰近星系超新星巡天 (NGSS) 計畫中，該計畫包含橫跨三個觀測站的八架望遠鏡，旨在尋找距離 50 mpc 內星系中的瞬變現象，我們開發了 **StarWhisper 望遠鏡系統** 來管理整個觀測過程。此系統自動執行產生觀測清單、執行觀測、分析資料和提供回饋給觀測者的任務。觀測清單會針對不同的地點和策略進行自訂，以確保對天體的全面覆蓋。在手動驗證後，這些清單會透過系統中的代理上傳至望遠鏡，該代理會在收到自然語言後啟動觀測。觀測到的影像會即時分析，並會立即將瞬變現象傳達給觀測者。代理會將其修改為即時的後續觀測提案，並傳送至興隆觀測站群組聊天室，然後將其加入隔天的觀測清單中。此外，系統中整合 AI 代理提供了線上存取功能，節省了天文學家的時間，並鼓勵業餘天文學家更積極參與 NGSS 計畫。

##### **BatchTopK Sparse Autoencoders**
2412.06410v1 by Bart Bussmann, Patrick Leask, Neel Nanda

Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting
language model activations by decomposing them into sparse, interpretable
features. A popular approach is the TopK SAE, that uses a fixed number of the
most active latents per sample to reconstruct the model activations. We
introduce BatchTopK SAEs, a training method that improves upon TopK SAEs by
relaxing the top-k constraint to the batch-level, allowing for a variable
number of latents to be active per sample. As a result, BatchTopK adaptively
allocates more or fewer latents depending on the sample, improving
reconstruction without sacrificing average sparsity. We show that BatchTopK
SAEs consistently outperform TopK SAEs in reconstructing activations from GPT-2
Small and Gemma 2 2B, and achieve comparable performance to state-of-the-art
JumpReLU SAEs. However, an advantage of BatchTopK is that the average number of
latents can be directly specified, rather than approximately tuned through a
costly hyperparameter sweep. We provide code for training and evaluating
BatchTopK SAEs at https://github.com/bartbussmann/BatchTopK

摘要：稀疏自動編碼器 (SAE) 已成為一種強大的工具，可用於透過將語言模型激活分解為稀疏、可解釋的功能來進行解釋。一種流行的方法是 TopK SAE，它使用每個樣本中最活躍潛在變數的固定數量來重建模型激活。我們引進 BatchTopK SAE，這是一種訓練方法，透過放寬頂部 k 約束至批次層級來改善 TopK SAE，允許每個樣本有可變數量的潛在變數處於活躍狀態。因此，BatchTopK 會根據樣本適應性地分配更多或更少的潛在變數，改善重建而不犧牲平均稀疏性。我們展示 BatchTopK SAE 在重建 GPT-2 Small 和 Gemma 2 2B 的激活方面始終優於 TopK SAE，並達到與最先進的 JumpReLU SAE 相當的效能。然而，BatchTopK 的優點在於可以直接指定潛在變數的平均數量，而不是透過代價高昂的超參數掃描來近似調整。我們在 https://github.com/bartbussmann/BatchTopK 提供訓練和評估 BatchTopK SAE 的程式碼

##### **GameArena: Evaluating LLM Reasoning through Live Computer Games**
2412.06394v1 by Lanxiang Hu, Qiyu Li, Anze Xie, Nan Jiang, Ion Stoica, Haojian Jin, Hao Zhang

Evaluating the reasoning abilities of large language models (LLMs) is
challenging. Existing benchmarks often depend on static datasets, which are
vulnerable to data contamination and may get saturated over time, or on binary
live human feedback that conflates reasoning with other abilities. As the most
prominent dynamic benchmark, Chatbot Arena evaluates open-ended questions in
real-world settings, but lacks the granularity in assessing specific reasoning
capabilities. We introduce GameArena, a dynamic benchmark designed to evaluate
LLM reasoning capabilities through interactive gameplay with humans. GameArena
consists of three games designed to test specific reasoning capabilities (e.g.,
deductive and inductive reasoning), while keeping participants entertained and
engaged. We analyze the gaming data retrospectively to uncover the underlying
reasoning processes of LLMs and measure their fine-grained reasoning
capabilities. We collect over 2000 game sessions and provide detailed
assessments of various reasoning capabilities for five state-of-the-art LLMs.
Our user study with 100 participants suggests that GameArena improves user
engagement compared to Chatbot Arena. For the first time, GameArena enables the
collection of step-by-step LLM reasoning data in the wild.

摘要：評估大型語言模型 (LLM) 的推理能力具有挑戰性。現有的基準通常依賴於靜態數據集，而這些數據集容易受到數據污染，並且可能會隨著時間而飽和，或者依賴於將推理與其他能力混為一談的二進制人類實時回饋。作為最知名的動態基準，Chatbot Arena 評估現實世界中的開放式問題，但缺乏評估特定推理能力的詳細程度。我們引入了 GameArena，這是一個動態基準，旨在通過與人類的互動遊戲來評估 LLM 推理能力。GameArena 包含三個遊戲，旨在測試具體的推理能力（例如，演繹推理和歸納推理），同時讓參與者保持娛樂和參與。我們回顧性地分析遊戲數據，以揭示 LLM 的底層推理過程，並衡量其細緻的推理能力。我們收集了 2000 多場遊戲，並對五種最先進的 LLM 的各種推理能力進行了詳細評估。我們與 100 名參與者進行的用戶研究表明，與 Chatbot Arena 相比，GameArena 提高了用戶參與度。GameArena 首次實現了收集野外 LLM 的逐步推理數據。

##### **Exploring Memorization and Copyright Violation in Frontier LLMs: A Study of the New York Times v. OpenAI 2023 Lawsuit**
2412.06370v1 by Joshua Freeman, Chloe Rippe, Edoardo Debenedetti, Maksym Andriushchenko

Copyright infringement in frontier LLMs has received much attention recently
due to the New York Times v. OpenAI lawsuit, filed in December 2023. The New
York Times claims that GPT-4 has infringed its copyrights by reproducing
articles for use in LLM training and by memorizing the inputs, thereby publicly
displaying them in LLM outputs. Our work aims to measure the propensity of
OpenAI's LLMs to exhibit verbatim memorization in its outputs relative to other
LLMs, specifically focusing on news articles. We discover that both GPT and
Claude models use refusal training and output filters to prevent verbatim
output of the memorized articles. We apply a basic prompt template to bypass
the refusal training and show that OpenAI models are currently less prone to
memorization elicitation than models from Meta, Mistral, and Anthropic. We find
that as models increase in size, especially beyond 100 billion parameters, they
demonstrate significantly greater capacity for memorization. Our findings have
practical implications for training: more attention must be placed on
preventing verbatim memorization in very large models. Our findings also have
legal significance: in assessing the relative memorization capacity of OpenAI's
LLMs, we probe the strength of The New York Times's copyright infringement
claims and OpenAI's legal defenses, while underscoring issues at the
intersection of generative AI, law, and policy.

摘要：最近，邊界 LLM 的著作權侵權問題備受關注，原因是紐約時報於 2023 年 12 月提起的紐約時報訴 OpenAI 訴訟。紐約時報聲稱，GPT-4 複製文章以供 LLM 訓練使用，並記住輸入，從而公開展示它們在 LLM 輸出中，侵犯了其著作權。我們的研究旨在衡量 OpenAI 的 LLM 相對於其他 LLM 在其輸出中表現出逐字記憶的傾向，特別關注新聞文章。我們發現，GPT 和 Claude 模型都使用拒絕訓練和輸出過濾器來防止記憶文章的逐字輸出。我們應用了一個基本的提示範本來繞過拒絕訓練，並表明 OpenAI 模型目前比 Meta、Mistral 和 Anthropic 的模型更不容易引發記憶。我們發現，隨著模型規模的增加，特別是超過 1000 億個參數時，它們表現出顯著更大的記憶容量。我們的研究結果對訓練有實際意義：必須更加註重防止在非常大的模型中逐字記憶。我們的研究結果也具有法律意義：在評估 OpenAI 的 LLM 的相對記憶容量時，我們探討了紐約時報著作權侵權主張和 OpenAI 的法律抗辯的強度，同時強調了生成式 AI、法律和政策交叉點上的問題。

##### **Measuring Pre-training Data Quality without Labels for Time Series Foundation Models**
2412.06368v1 by Songkang Wen, Vasilii Feofanov, Jianfeng Zhang

Recently, there has been a growing interest in time series foundation models
that generalize across different downstream tasks. A key to strong foundation
models is a diverse pre-training dataset, which is particularly challenging to
collect for time series classification. In this work, we explore the
performance of a contrastive-learning-based foundation model as a function of
the data used for pre-training. We introduce contrastive accuracy, a new
measure to evaluate the quality of the representation space learned by the
foundation model. Our experiments reveal the positive correlation between the
proposed measure and the accuracy of the model on a collection of downstream
tasks. This suggests that the contrastive accuracy can serve as a criterion to
search for time series datasets that can enhance the pre-training and improve
thereby the foundation model's generalization.

摘要：最近，人们对能够在不同下游任务中进行泛化的时序基础模型越来越感兴趣。强大的基础模型的关键在于多样化的预训练数据集，而这对于时序分类来说尤其具有挑战性。在这项工作中，我们探索了基于对比学习的基础模型的性能，作为用于预训练的数据的函数。我们引入了对比准确性，一种评估基础模型学习的表示空间质量的新方法。我们的实验揭示了所提出的度量与模型在收集的下游任务上的准确性之间的正相关关系。这表明对比准确性可以作为寻找能够增强预训练并因此提高基础模型泛化的时序数据集的标准。

##### **Elastic-DETR: Making Image Resolution Learnable with Content-Specific Network Prediction**
2412.06341v1 by Daeun Seo, Hoeseok Yang, Sihyeong Park, Hyungshin Kim

Multi-scale image resolution is a de facto standard approach in modern object
detectors, such as DETR. This technique allows for the acquisition of various
scale information from multiple image resolutions. However, manual
hyperparameter selection of the resolution can restrict its flexibility, which
is informed by prior knowledge, necessitating human intervention. This work
introduces a novel strategy for learnable resolution, called Elastic-DETR,
enabling elastic utilization of multiple image resolutions. Our network
provides an adaptive scale factor based on the content of the image with a
compact scale prediction module (< 2 GFLOPs). The key aspect of our method lies
in how to determine the resolution without prior knowledge. We present two loss
functions derived from identified key components for resolution optimization:
scale loss, which increases adaptiveness according to the image, and
distribution loss, which determines the overall degree of scaling based on
network performance. By leveraging the resolution's flexibility, we can
demonstrate various models that exhibit varying trade-offs between accuracy and
computational complexity. We empirically show that our scheme can unleash the
potential of a wide spectrum of image resolutions without constraining
flexibility. Our models on MS COCO establish a maximum accuracy gain of 3.5%p
or 26% decrease in computation than MS-trained DN-DETR.

摘要：多尺度影像解析度是現代物體偵測器的事實標準方法，例如 DETR。此技術允許從多個影像解析度取得各種尺度資訊。然而，解析度的超參數手動選擇會限制其彈性，這由先驗知識告知，需要人工介入。這項工作引入了一個可學習解析度的創新策略，稱為 Elastic-DETR，實現了多個影像解析度的彈性使用。我們的網路提供了一個基於影像內容的自適應縮放因子，並具備一個緊湊的縮放預測模組（< 2 GFLOPs）。我們方法的關鍵方面在於如何在沒有先驗知識的情況下確定解析度。我們提出了兩個從解析度最佳化的已識別關鍵組成部分衍生的損失函數：尺度損失，它會根據影像增加自適應性，以及分佈損失，它會根據網路效能確定整體縮放程度。透過利用解析度的彈性，我們可以展示各種模型，這些模型在準確度和計算複雜度之間展現出不同的權衡。我們經驗性地表明，我們的方案可以釋放各種影像解析度的潛力，而不會限制彈性。我們在 MS COCO 上的模型建立了 3.5%p 的最大準確度提升，或比 MS 訓練的 DN-DETR 減少 26% 的計算。

##### **Not All Errors Are Equal: Investigation of Speech Recognition Errors in Alzheimer's Disease Detection**
2412.06332v1 by Jiawen Kang, Junan Li, Jinchao Li, Xixin Wu, Helen Meng

Automatic Speech Recognition (ASR) plays an important role in speech-based
automatic detection of Alzheimer's disease (AD). However, recognition errors
could propagate downstream, potentially impacting the detection decisions.
Recent studies have revealed a non-linear relationship between word error rates
(WER) and AD detection performance, where ASR transcriptions with notable
errors could still yield AD detection accuracy equivalent to that based on
manual transcriptions. This work presents a series of analyses to explore the
effect of ASR transcription errors in BERT-based AD detection systems. Our
investigation reveals that not all ASR errors contribute equally to detection
performance. Certain words, such as stopwords, despite constituting a large
proportion of errors, are shown to play a limited role in distinguishing AD. In
contrast, the keywords related to diagnosis tasks exhibit significantly greater
importance relative to other words. These findings provide insights into the
interplay between ASR errors and the downstream detection model.

摘要：自動語音辨識 (ASR) 在基於語音的阿茲海默症 (AD) 自動檢測中扮演著重要的角色。然而，辨識錯誤可能會向下傳播，並潛在地影響檢測決策。最近的研究揭示了字元錯誤率 (WER) 與 AD 檢測效能之間的非線性關係，其中包含顯著錯誤的 ASR 轉錄仍能產生等同於基於手動轉錄的 AD 檢測準確度。這項工作提出了一系列分析，以探討 ASR 轉錄錯誤對 BERT 基礎 AD 檢測系統的影響。我們的調查顯示，並非所有 ASR 錯誤都會對檢測效能造成相同的影響。某些詞彙，例如停止詞，儘管構成錯誤的很大一部分，但顯示在區分 AD 中所扮演的角色有限。相反地，與診斷任務相關的關鍵字相較於其他詞彙，顯著地展現出更重要的地位。這些發現提供了 ASR 錯誤與下游檢測模型之間交互作用的見解。

##### **CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**
2412.06314v1 by Yijie Dang, Weijun Ma, Xiaohu Luo

Since the outbreak of the COVID-19 pandemic in 2019, medical imaging has
emerged as a primary modality for diagnosing COVID-19 pneumonia. In clinical
settings, the segmentation of lung infections from computed tomography images
enables rapid and accurate quantification and diagnosis of COVID-19.
Segmentation of COVID-19 infections in the lungs poses a formidable challenge,
primarily due to the indistinct boundaries and limited contrast presented by
ground glass opacity manifestations. Moreover, the confounding similarity
between infiltrates, lung tissues, and lung walls further complicates this
segmentation task. To address these challenges, this paper introduces a novel
deep network architecture, called CAD-Unet, for segmenting COVID-19 lung
infections. In this architecture, capsule networks are incorporated into the
existing Unet framework. Capsule networks represent a novel network
architecture that differs from traditional convolutional neural networks. They
utilize vectors for information transfer among capsules, facilitating the
extraction of intricate lesion spatial information. Additionally, we design a
capsule encoder path and establish a coupling path between the unet encoder and
the capsule encoder. This design maximizes the complementary advantages of both
network structures while achieving efficient information fusion. \noindent
Finally, extensive experiments are conducted on four publicly available
datasets, encompassing binary segmentation tasks and multi-class segmentation
tasks. The experimental results demonstrate the superior segmentation
performance of the proposed model. The code has been released at:
https://github.com/AmanoTooko-jie/CAD-Unet.

摘要：自 2019 年 COVID-19 大流行爆发以来，医学影像已成为诊断 COVID-19 肺炎的主要方式。在临床环境中，从计算机断层扫描图像中分割肺部感染，可以快速、准确地量化和诊断 COVID-19。分割肺部中的 COVID-19 感染是一个艰巨的挑战，这主要是由于毛玻璃样变现出的边界不清晰且对比度有限。此外，浸润、肺组织和肺壁之间的混淆相似性进一步复杂化了这项分割任务。为了应对这些挑战，本文介绍了一种新颖的深度网络架构，称为 CAD-Unet，用于分割 COVID-19 肺部感染。在此架构中，胶囊网络被纳入现有的 Unet 框架中。胶囊网络代表了一种新颖的网络架构，它不同于传统的卷积神经网络。它们利用向量在胶囊之间进行信息传输，促进了复杂病变空间信息的提取。此外，我们设计了一个胶囊编码器路径，并在 unet 编码器和胶囊编码器之间建立了一个耦合路径。这种设计最大限度地发挥了两种网络结构的互补优势，同时实现了高效的信息融合。\noindent
最后，在四个公开可用的数据集上进行了广泛的实验，包括二进制分割任务和多类分割任务。实验结果证明了所提出模型的卓越分割性能。该代码已发布在：
https://github.com/AmanoTooko-jie/CAD-Unet。

##### **Towards High-Level Modelling in Automated Planning**
2412.06312v1 by Carla Davesa Sureda, Joan Espasa Arxer, Ian Miguel, Mateu Villaret Auselle

Planning is a fundamental activity, arising frequently in many contexts, from
daily tasks to industrial processes. The planning task consists of selecting a
sequence of actions to achieve a specified goal from specified initial
conditions. The Planning Domain Definition Language (PDDL) is the leading
language used in the field of automated planning to model planning problems.
Previous work has highlighted the limitations of PDDL, particularly in terms of
its expressivity. Our interest lies in facilitating the handling of complex
problems and enhancing the overall capability of automated planning systems.
Unified-Planning is a Python library offering high-level API to specify
planning problems and to invoke automated planners. In this paper, we present
an extension of the UP library aimed at enhancing its expressivity for
high-level problem modelling. In particular, we have added an array type, an
expression to count booleans, and the allowance for integer parameters in
actions. We show how these facilities enable natural high-level models of three
classical planning problems.

摘要：規劃是一項基本活動，經常出現在許多情境中，從日常工作到工業流程。規劃任務包括從指定的初始條件中選擇一系列動作來達成指定目標。規劃領域定義語言 (PDDL) 是自動化規劃領域中用於建模規劃問題的主要語言。先前的研究重點說明了 PDDL 的限制，特別是在其表達能力方面。我們的興趣在於促進處理複雜問題，並增強自動化規劃系統的整體能力。Unified-Planning 是 Python 函式庫，提供高階 API 來指定規劃問題並呼叫自動化規劃器。在本文中，我們提出 UP 函式庫的延伸，旨在增強其對高階問題建模的表達能力。特別是，我們新增了一個陣列類型、一個用於計算布林值的表達式，以及在動作中允許整數參數。我們展示了這些功能如何能讓三個經典規劃問題自然地建構高階模型。

##### **PRECISE: Pre-training Sequential Recommenders with Collaborative and Semantic Information**
2412.06308v1 by Chonggang Song, Chunxu Shen, Hao Gu, Yaoming Wu, Lingling Yi, Jie Wen, Chuan Chen

Real-world recommendation systems commonly offer diverse content scenarios
for users to interact with. Considering the enormous number of users in
industrial platforms, it is infeasible to utilize a single unified
recommendation model to meet the requirements of all scenarios. Usually,
separate recommendation pipelines are established for each distinct scenario.
This practice leads to challenges in comprehensively grasping users' interests.
Recent research endeavors have been made to tackle this problem by pre-training
models to encapsulate the overall interests of users. Traditional pre-trained
recommendation models mainly capture user interests by leveraging collaborative
signals. Nevertheless, a prevalent drawback of these systems is their
incapacity to handle long-tail items and cold-start scenarios. With the recent
advent of large language models, there has been a significant increase in
research efforts focused on exploiting LLMs to extract semantic information for
users and items. However, text-based recommendations highly rely on elaborate
feature engineering and frequently fail to capture collaborative similarities.
To overcome these limitations, we propose a novel pre-training framework for
sequential recommendation, termed PRECISE. This framework combines
collaborative signals with semantic information. Moreover, PRECISE employs a
learning framework that initially models users' comprehensive interests across
all recommendation scenarios and subsequently concentrates on the specific
interests of target-scene behaviors. We demonstrate that PRECISE precisely
captures the entire range of user interests and effectively transfers them to
the target interests. Empirical findings reveal that the PRECISE framework
attains outstanding performance on both public and industrial datasets.

摘要：現實世界的推薦系統通常提供多樣化的內容情境，供使用者互動。考量到產業平台中龐大的使用者數量，要使用單一的統一推薦模型來滿足所有情境的需要並不可行。通常，會為每個不同的情境建立獨立的推薦管道。這種做法帶來全面掌握使用者興趣的挑戰。最近的研究努力嘗試透過預訓練模型來解決這個問題，以概括使用者的整體興趣。傳統的預訓練推薦模型主要透過利用協同訊號來擷取使用者興趣。儘管如此，這些系統普遍存在的缺點是無法處理長尾項目和冷啟動情境。隨著大型語言模型的近期出現，研究工作大幅增加，專注於利用 LLM 來擷取使用者的語意資訊和項目。然而，基於文字的推薦高度仰賴精密的特徵工程，而且經常無法擷取協同相似性。為了克服這些限制，我們提出一個序列推薦的新穎預訓練架構，稱為 PRECISE。這個架構結合了協同訊號與語意資訊。此外，PRECISE 採用一個學習架構，最初會對所有推薦情境建模使用者的綜合興趣，然後專注於目標場景行為的特定興趣。我們展示 PRECISE 精確擷取使用者興趣的完整範圍，並有效地將它們轉移到目標興趣。經驗發現顯示，PRECISE 架構在公開和產業資料集上皆獲得傑出的效能。

##### **DSAI: Unbiased and Interpretable Latent Feature Extraction for Data-Centric AI**
2412.06303v1 by Hyowon Cho, Soonwon Ka, Daechul Park, Jaewook Kang, Minjoon Seo, Bokyung Son

Large language models (LLMs) often struggle to objectively identify latent
characteristics in large datasets due to their reliance on pre-trained
knowledge rather than actual data patterns. To address this data grounding
issue, we propose Data Scientist AI (DSAI), a framework that enables unbiased
and interpretable feature extraction through a multi-stage pipeline with
quantifiable prominence metrics for evaluating extracted features. On synthetic
datasets with known ground-truth features, DSAI demonstrates high recall in
identifying expert-defined features while faithfully reflecting the underlying
data. Applications on real-world datasets illustrate the framework's practical
utility in uncovering meaningful patterns with minimal expert oversight,
supporting use cases such as interpretable classification.
  The title of our paper is chosen from multiple candidates based on
DSAI-generated criteria.

摘要：大型語言模型 (LLM) 經常難以客觀地識別大型資料集中的潛在特徵，因為它們依賴預先訓練的知識，而非實際資料模式。為了解決這個資料基礎問題，我們提出資料科學家 AI (DSAI)，一個透過多階段管線進行無偏且可解釋特徵萃取的架構，並具備可量化重要性指標來評估萃取的特徵。在具有已知實際特徵的合成資料集上，DSAI 展示出在識別專家定義特徵時的高召回率，同時忠實反映底層資料。在真實世界資料集上的應用說明了該架構在以最少專家監督揭露有意義模式方面的實際效用，支援可解釋分類等使用案例。我們論文的標題是根據 DSAI 生成的準則從多個候選標題中選出的。

##### **S$^{2}$FT: Efficient, Scalable and Generalizable LLM Fine-tuning by Structured Sparsity**
2412.06289v1 by Xinyu Yang, Jixuan Leng, Geyang Guo, Jiawei Zhao, Ryumei Nakada, Linjun Zhang, Huaxiu Yao, Beidi Chen

Current PEFT methods for LLMs can achieve either high quality, efficient
training, or scalable serving, but not all three simultaneously. To address
this limitation, we investigate sparse fine-tuning and observe a remarkable
improvement in generalization ability. Utilizing this key insight, we propose a
family of Structured Sparse Fine-Tuning (S$^{2}$FT) methods for LLMs, which
concurrently achieve state-of-the-art fine-tuning performance, training
efficiency, and inference scalability. S$^{2}$FT accomplishes this by
"selecting sparsely and computing densely". It selects a few heads and channels
in the MHA and FFN modules for each Transformer block, respectively. Next, it
co-permutes weight matrices on both sides of the coupled structures in LLMs to
connect the selected components in each layer into a dense submatrix. Finally,
S$^{2}$FT performs in-place gradient updates on all submatrices. Through
theoretical analysis and empirical results, our method prevents overfitting and
forgetting, delivers SOTA performance on both commonsense and arithmetic
reasoning with 4.6% and 1.3% average improvements compared to LoRA, and
surpasses full FT by 11.5% when generalizing to various domains after
instruction tuning. Using our partial backpropagation algorithm, S$^{2}$FT
saves training memory up to 3$\times$ and improves latency by 1.5-2.7$\times$
compared to full FT, while delivering an average 10% improvement over LoRA on
both metrics. We further demonstrate that the weight updates in S$^{2}$FT can
be decoupled into adapters, enabling effective fusion, fast switch, and
efficient parallelism for serving multiple fine-tuned models.

摘要：目前用於 LLM 的 PEFT 方法可實現高品質、高效訓練或可擴充服務，但無法同時實現這三項。為了解決這個限制，我們探討稀疏微調，並觀察到泛化能力顯著提升。利用這個關鍵見解，我們提出了一系列 LLM 的結構化稀疏微調 (S$^{2}$FT) 方法，同時實現了最先進的微調效能、訓練效率和推論可擴充性。S$^{2}$FT 透過「稀疏選擇和密集運算」來達成此目標。它分別為每個 Transformer 區塊的 MHA 和 FFN 模組選擇一些頭部和通道。接著，它在 LLM 中耦合結構的兩側對權重矩陣進行共置換，將每一層中選定的組件連接到一個密集子矩陣中。最後，S$^{2}$FT 對所有子矩陣執行就地梯度更新。透過理論分析和實證結果，我們的模型可以防止過度擬合和遺忘，在常識和算術推理上提供 SOTA 效能，與 LoRA 相比，平均改善了 4.6% 和 1.3%，並且在經過指令微調後，對各種領域的泛化能力提升了 11.5%，超越了完整的 FT。使用我們的部分反向傳播演算法，與完整的 FT 相比，S$^{2}$FT 可節省高達 3 倍的訓練記憶體，並將延遲改善 1.5-2.7 倍，同時在兩個指標上比 LoRA 平均改善 10%。我們進一步證明，S$^{2}$FT 中的權重更新可以解耦成適配器，從而實現有效的融合、快速切換和高效並行運算，以服務多個微調模型。

##### **PediaBench: A Comprehensive Chinese Pediatric Dataset for Benchmarking Large Language Models**
2412.06287v1 by Qian Zhang, Panfeng Chen, Jiali Li, Linkun Feng, Shuyu Liu, Mei Chen, Hui Li, Yanhao Wang

The emergence of Large Language Models (LLMs) in the medical domain has
stressed a compelling need for standard datasets to evaluate their
question-answering (QA) performance. Although there have been several benchmark
datasets for medical QA, they either cover common knowledge across different
departments or are specific to another department rather than pediatrics.
Moreover, some of them are limited to objective questions and do not measure
the generation capacity of LLMs. Therefore, they cannot comprehensively assess
the QA ability of LLMs in pediatrics. To fill this gap, we construct
PediaBench, the first Chinese pediatric dataset for LLM evaluation.
Specifically, it contains 4,565 objective questions and 1,632 subjective
questions spanning 12 pediatric disease groups. It adopts an integrated scoring
criterion based on different difficulty levels to thoroughly assess the
proficiency of an LLM in instruction following, knowledge understanding,
clinical case analysis, etc. Finally, we validate the effectiveness of
PediaBench with extensive experiments on 20 open-source and commercial LLMs.
Through an in-depth analysis of experimental results, we offer insights into
the ability of LLMs to answer pediatric questions in the Chinese context,
highlighting their limitations for further improvements. Our code and data are
published at https://github.com/ACMISLab/PediaBench.

摘要：大型語言模型 (LLM) 在醫療領域的出現
強調了對標準資料集的迫切需求，以評估其
問答 (QA) 效能。儘管有幾個醫療 QA 的基準
資料集，但它們涵蓋不同科別的常識，或特定於兒科以外的科別。
此外，其中一些僅限於客觀問題，且無法衡量 LLM 的生成能力。因此，它們無法全面評估
LLM 在兒科中的 QA 能力。為了填補這個空白，我們建構
PediaBench，這是第一個用於 LLM 評估的中文兒科資料集。
具體來說，它包含 4,565 個客觀問題和 1,632 個主觀
問題，涵蓋 12 個兒科疾病組。它採用基於不同難度等級的綜合評分
標準，以徹底評估 LLM 在遵循說明、知識理解、
臨床案例分析等方面的能力。最後，我們驗證了
PediaBench 的有效性，對 20 個開源和商業 LLM 進行了廣泛的實驗。
透過深入分析實驗結果，我們深入了解了 LLM 在中文背景下回答兒科問題的能力，
強調了它們的限制以進一步改進。我們的程式碼和資料已發布在 https://github.com/ACMISLab/PediaBench。

##### **Methods for Legal Citation Prediction in the Age of LLMs: An Australian Law Case Study**
2412.06272v1 by Ehsan Shareghi, Jiuzhou Han, Paul Burgess

In recent years, Large Language Models (LLMs) have shown great potential
across a wide range of legal tasks. Despite these advances, mitigating
hallucination remains a significant challenge, with state-of-the-art LLMs still
frequently generating incorrect legal references. In this paper, we focus on
the problem of legal citation prediction within the Australian law context,
where correctly identifying and citing relevant legislations or precedents is
critical. We compare several approaches: prompting general purpose and
law-specialised LLMs, retrieval-only pipelines with both generic and
domain-specific embeddings, task-specific instruction-tuning of LLMs, and
hybrid strategies that combine LLMs with retrieval augmentation, query
expansion, or voting ensembles. Our findings indicate that domain-specific
pre-training alone is insufficient for achieving satisfactory citation accuracy
even after law-specialised pre-training. In contrast, instruction tuning on our
task-specific dataset dramatically boosts performance reaching the best results
across all settings. We also highlight that database granularity along with the
type of embeddings play a critical role in the performance of retrieval
systems. Among retrieval-based approaches, hybrid methods consistently
outperform retrieval-only setups, and among these, ensemble voting delivers the
best result by combining the predictive quality of instruction-tuned LLMs with
the retrieval system.

摘要：近年來，大型語言模型（LLM）在各種法律事務上展現出巨大的潛力。儘管有這些進展，減輕幻覺仍然是一項重大挑戰，最先進的 LLM 仍然經常產生不正確的法律參考。在本文中，我們專注於澳大利亞法律背景下的法律引用預測問題，其中正確識別和引用相關立法或先例至關重要。我們比較了幾種方法：提示通用和法律專業的 LLM、具有通用和特定領域嵌入的僅檢索管道、LLM 的特定任務指令調整，以及將 LLM 與檢索擴充、查詢擴充或投票集成相結合的混合策略。我們的研究結果表明，即使經過法律專業的預訓練，僅特定領域的預訓練不足以實現令人滿意的引用準確度。相比之下，針對我們特定任務數據集的指令調整顯著提升了效能，在所有設定中達到最佳結果。我們還強調，資料庫粒度以及嵌入類型在檢索系統的效能中扮演著至關重要的角色。在基於檢索的方法中，混合方法始終優於僅檢索的設定，其中，集成投票通過結合指令調整的 LLM 的預測品質和檢索系統，提供最佳結果。

##### **Optimizing Multi-Task Learning for Enhanced Performance in Large Language Models**
2412.06249v1 by Zhen Qi, Jiajing Chen, Shuo Wang, Bingying Liu, Hongye Zheng, Chihang Wang

This study aims to explore the performance improvement method of large
language models based on GPT-4 under the multi-task learning framework and
conducts experiments on two tasks: text classification and automatic summary
generation. Through the combined design of shared feature extractors and
task-specific modules, we achieve knowledge-sharing and optimization of
multiple tasks in the same model. The experiment uses multiple subtasks of the
GLUE dataset to compare the performance of the multi-task model with the
single-task GPT-4, the multi-task version of GPT-3, the BERT basic model, and
the classic Bi-LSTM with Attention model. The results show that the proposed
multi-task learning model outperforms other comparison models in terms of text
classification accuracy and ROUGE value of summary generation, demonstrating
the advantages of multi-task learning in improving model generalization ability
and collaborative learning between tasks. The model maintains a stable loss
convergence rate during training, showing good learning efficiency and
adaptability to the test set. This study verifies the applicability of the
multi-task learning framework in large language models, especially in improving
the model's ability to balance different tasks. In the future, with the
combination of large language models and multimodal data and the application of
dynamic task adjustment technology, the framework based on multi-task learning
is expected to play a greater role in practical applications across fields and
provide new ideas for the development of general artificial intelligence.

摘要：本研究旨在探索基於 GPT-4 的大型語言模型在多任務學習架構下的效能提升方法，並針對兩個任務進行實驗：文字分類和自動摘要生成。透過共享特徵萃取器和特定任務模組的結合設計，我們在同一個模型中實現了知識共享與多任務的最佳化。實驗使用 GLUE 資料集的子任務，來比較多任務模型與單任務 GPT-4、多任務版本的 GPT-3、BERT 基本模型、以及經典的注意力機制雙向 LSTM 模型的效能。結果顯示，提出的多任務學習模型在文字分類準確度和摘要生成的 ROUGE 值方面，優於其他比較模型，證明了多任務學習在提升模型泛化能力和任務間協同學習的優勢。該模型在訓練過程中維持穩定的損失收斂速度，展現良好的學習效率和對測試集的適應性。本研究驗證了多任務學習架構在大語言模型中的適用性，特別是在提升模型平衡不同任務的能力方面。未來，隨著大語言模型與多模態資料的結合，以及動態任務調整技術的應用，基於多任務學習的框架預期將在跨領域的實際應用中發揮更大的作用，並為通用人工智慧的發展提供新的思路。

##### **A Comparative Study of Learning Paradigms in Large Language Models via Intrinsic Dimension**
2412.06245v1 by Saahith Janapati, Yangfeng Ji

The performance of Large Language Models (LLMs) on natural language tasks can
be improved through both supervised fine-tuning (SFT) and in-context learning
(ICL), which operate via distinct mechanisms. Supervised fine-tuning updates
the model's weights by minimizing loss on training data, whereas in-context
learning leverages task demonstrations embedded in the prompt, without changing
the model's parameters. This study investigates the effects of these learning
paradigms on the hidden representations of LLMs using Intrinsic Dimension (ID).
We use ID to estimate the number of degrees of freedom between representations
extracted from LLMs as they perform specific natural language tasks. We first
explore how the ID of LLM representations evolves during SFT and how it varies
due to the number of demonstrations in ICL. We then compare the IDs induced by
SFT and ICL and find that ICL consistently induces a higher ID compared to SFT,
suggesting that representations generated during ICL reside in higher
dimensional manifolds in the embedding space.

摘要：大型語言模型 (LLM) 在自然語言任務上的表現，可透過監督式微調 (SFT) 和語境學習 (ICL) 來提升，這兩種方法是透過不同的機制運作。監督式微調會透過最小化訓練資料的損失來更新模型的權重，而語境學習則會利用嵌入在提示中的任務示範，而不會改變模型的參數。此研究使用內在維度 (ID) 探討這些學習範例對 LLM 隱藏式表徵的影響。我們使用 ID 來估計從 LLM 中萃取的表徵之間的自由度，因為它們執行特定自然語言任務。我們首先探討 LLM 表徵的 ID 在 SFT 期間如何演變，以及它如何因為 ICL 中的示範數量而有所不同。然後，我們比較 SFT 和 ICL 所引發的 ID，發現 ICL 持續誘發比 SFT 更高的 ID，這表示在 ICL 期間產生的表徵存在於嵌入空間中更高的維度流形中。

##### **Unseen Attack Detection in Software-Defined Networking Using a BERT-Based Large Language Model**
2412.06239v1 by Mohammed N. Swileh, Shengli Zhang

Software defined networking (SDN) represents a transformative shift in
network architecture by decoupling the control plane from the data plane,
enabling centralized and flexible management of network resources. However,
this architectural shift introduces significant security challenges, as SDN's
centralized control becomes an attractive target for various types of attacks.
While current research has yielded valuable insights into attack detection in
SDN, critical gaps remain. Addressing challenges in feature selection,
broadening the scope beyond DDoS attacks, strengthening attack decisions based
on multi flow analysis, and building models capable of detecting unseen attacks
that they have not been explicitly trained on are essential steps toward
advancing security in SDN. In this paper, we introduce a novel approach that
leverages Natural Language Processing (NLP) and the pre trained BERT base model
to enhance attack detection in SDN. Our approach transforms network flow data
into a format interpretable by language models, allowing BERT to capture
intricate patterns and relationships within network traffic. By using Random
Forest for feature selection, we optimize model performance and reduce
computational overhead, ensuring accurate detection. Attack decisions are made
based on several flows, providing stronger and more reliable detection of
malicious traffic. Furthermore, our approach is specifically designed to detect
previously unseen attacks, offering a solution for identifying threats that the
model was not explicitly trained on. To rigorously evaluate our approach, we
conducted experiments in two scenarios: one focused on detecting known attacks,
achieving 99.96% accuracy, and another on detecting unseen attacks, where our
model achieved 99.96% accuracy, demonstrating the robustness of our approach in
detecting evolving threats to improve the security of SDN networks.

摘要：軟體定義網路 (SDN) 藉由將控制平面與資料平面分離，代表網路架構的轉型變革，讓網路資源能以集中且彈性的方式進行管理。不過，這種架構轉變引入了顯著的安全挑戰，因為 SDN 的集中式控制機制對於各種類型的攻擊而言，是一個有吸引力的目標。雖然目前的研究已對 SDN 中的攻擊偵測產生了寶貴的見解，但仍存在關鍵的差距。解決特徵選取中的挑戰、擴大 DDoS 攻擊以外的範圍、根據多流程分析強化攻擊決策，以及建立能夠偵測未見過且未明確訓練過的攻擊的模型，是提升 SDN 安全性的必要步驟。在本文中，我們介紹一種新穎的方法，它利用自然語言處理 (NLP) 和預先訓練的 BERT 基礎模型來增強 SDN 中的攻擊偵測。我們的做法將網路流程資料轉換成語言模型可以解譯的格式，讓 BERT 能夠擷取網路流量中的複雜模式和關係。藉由使用隨機森林進行特徵選取，我們最佳化模型效能並減少運算負擔，確保精確的偵測。攻擊決策是根據多個流程做出的，提供更強大且更可靠的惡意流量偵測。此外，我們的方法特別設計用來偵測先前未見過的攻擊，提供一個解決方案來識別模型未明確訓練過的威脅。為了嚴謹評估我們的方法，我們在兩個情境中進行了實驗：一個專注於偵測已知的攻擊，達到了 99.96% 的準確度；另一個專注於偵測未見過的攻擊，我們的模型達到了 99.96% 的準確度，證明了我們的方法在偵測不斷演化的威脅以提升 SDN 網路安全性方面的強健性。

##### **LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments**
2412.06229v1 by Prakash Aryan

This paper introduces DebateBrawl, an innovative AI-powered debate platform
that integrates Large Language Models (LLMs), Genetic Algorithms (GA), and
Adversarial Search (AS) to create an adaptive and engaging debating experience.
DebateBrawl addresses the limitations of traditional LLMs in strategic planning
by incorporating evolutionary optimization and game-theoretic techniques. The
system demonstrates remarkable performance in generating coherent, contextually
relevant arguments while adapting its strategy in real-time. Experimental
results involving 23 debates show balanced outcomes between AI and human
participants, with the AI system achieving an average score of 2.72 compared to
the human average of 2.67 out of 10. User feedback indicates significant
improvements in debating skills and a highly satisfactory learning experience,
with 85% of users reporting improved debating abilities and 78% finding the AI
opponent appropriately challenging. The system's ability to maintain high
factual accuracy (92% compared to 78% in human-only debates) while generating
diverse arguments addresses critical concerns in AI-assisted discourse.
DebateBrawl not only serves as an effective educational tool but also
contributes to the broader goal of improving public discourse through
AI-assisted argumentation. The paper discusses the ethical implications of AI
in persuasive contexts and outlines the measures implemented to ensure
responsible development and deployment of the system, including robust
fact-checking mechanisms and transparency in decision-making processes.

摘要：<paragraph>本文介紹了 DebateBrawl，一個創新的 AI 辯論平台，它整合了大型語言模型 (LLM)、遺傳演算法 (GA) 和對抗搜尋 (AS)，以創造適應性和吸引力的辯論體驗。DebateBrawl 透過整合演化最佳化和博弈論技巧，來解決傳統 LLM 在策略規劃上的限制。該系統在產生連貫、與脈絡相關的論點方面表現出色，同時還能即時調整其策略。涉及 23 場辯論的實驗結果顯示，AI 和人類參與者之間的結果平衡，AI 系統的平均得分為 2.72，而人類的平均得分為 2.67（滿分 10 分）。使用者回饋顯示，辯論技巧有顯著進步，學習體驗非常滿意，85% 的使用者表示辯論能力有所提升，78% 的使用者認為 AI 對手具有適當的挑戰性。該系統在產生多元論點的同時，還能維持高事實準確度（92%，而僅限人類的辯論為 78%），解決了 AI 輔助論述中的關鍵問題。DebateBrawl 不僅是一個有效的教育工具，也透過 AI 輔助論證，為改善公共論述的更廣泛目標做出貢獻。本文探討了 AI 在說服性脈絡中的倫理影響，並概述了為確保系統負責任的開發和部署而實施的措施，包括強大的事實查核機制和決策過程的透明度。</paragraph>

##### **Data Free Backdoor Attacks**
2412.06219v1 by Bochuan Cao, Jinyuan Jia, Chuxuan Hu, Wenbo Guo, Zhen Xiang, Jinghui Chen, Bo Li, Dawn Song

Backdoor attacks aim to inject a backdoor into a classifier such that it
predicts any input with an attacker-chosen backdoor trigger as an
attacker-chosen target class. Existing backdoor attacks require either
retraining the classifier with some clean data or modifying the model's
architecture. As a result, they are 1) not applicable when clean data is
unavailable, 2) less efficient when the model is large, and 3) less stealthy
due to architecture changes. In this work, we propose DFBA, a novel
retraining-free and data-free backdoor attack without changing the model
architecture. Technically, our proposed method modifies a few parameters of a
classifier to inject a backdoor. Through theoretical analysis, we verify that
our injected backdoor is provably undetectable and unremovable by various
state-of-the-art defenses under mild assumptions. Our evaluation on multiple
datasets further demonstrates that our injected backdoor: 1) incurs negligible
classification loss, 2) achieves 100% attack success rates, and 3) bypasses six
existing state-of-the-art defenses. Moreover, our comparison with a
state-of-the-art non-data-free backdoor attack shows our attack is more
stealthy and effective against various defenses while achieving less
classification accuracy loss.

摘要：後門攻擊旨在將一個後門注入分類器中，使其將任何輸入與攻擊者選擇的後門觸發器預測為攻擊者選擇的目標類別。現有的後門攻擊需要重新訓練分類器，使用一些乾淨的資料或修改模型架構。因此，它們 1) 在沒有乾淨資料時不適用，2) 在模型較大的時候效率較低，3) 由於架構的變更而較不隱蔽。在這項工作中，我們提出 DFBA，一種新穎的無需重新訓練且無需資料的後門攻擊，而不會改變模型架構。技術上，我們提出的方法修改分類器的幾個參數，以注入後門。透過理論分析，我們驗證我們注入的後門在輕微的假設下，被證明無法被各種最先進的防禦措施偵測和移除。我們在多個資料集上的評估進一步證明了我們注入的後門：1) 造成微不足道的分類損失，2) 達到 100% 的攻擊成功率，3) 繞過六種現有的最先進防禦措施。此外，我們與最先進的非無資料後門攻擊的比較顯示，我們的攻擊在對抗各種防禦措施時更隱蔽且有效，同時達到較低的分類準確度損失。

##### **A Real-Time Defense Against Object Vanishing Adversarial Patch Attacks for Object Detection in Autonomous Vehicles**
2412.06215v1 by Jaden Mu

Autonomous vehicles (AVs) increasingly use DNN-based object detection models
in vision-based perception. Correct detection and classification of obstacles
is critical to ensure safe, trustworthy driving decisions. Adversarial patches
aim to fool a DNN with intentionally generated patterns concentrated in a
localized region of an image. In particular, object vanishing patch attacks can
cause object detection models to fail to detect most or all objects in a scene,
posing a significant practical threat to AVs.
  This work proposes ADAV (Adversarial Defense for Autonomous Vehicles), a
novel defense methodology against object vanishing patch attacks specifically
designed for autonomous vehicles. Unlike existing defense methods which have
high latency or are designed for static images, ADAV runs in real-time and
leverages contextual information from prior frames in an AV's video feed. ADAV
checks if the object detector's output for the target frame is temporally
consistent with the output from a previous reference frame to detect the
presence of a patch. If the presence of a patch is detected, ADAV uses
gradient-based attribution to localize adversarial pixels that break temporal
consistency. This two stage procedure allows ADAV to efficiently process clean
inputs, and both stages are optimized to be low latency. ADAV is evaluated
using real-world driving data from the Berkeley Deep Drive BDD100K dataset, and
demonstrates high adversarial and clean performance.

摘要：自動駕駛車輛 (AV) 日益使用基於 DNN 的物件偵測模型，用於基於視覺的感知。正確偵測和分類障礙物對於確保安全、值得信賴的駕駛決策至關重要。對抗性貼片旨在透過集中在影像局部區域的故意產生圖案來欺騙 DNN。特別是，物件消失貼片攻擊可能導致物件偵測模型無法偵測場景中的大多數或所有物件，對 AV 構成重大的實際威脅。本研究提出 ADAV（針對自動駕駛車輛的對抗性防禦），一種針對自動駕駛車輛特別設計的對抗性消失貼片攻擊的新型防禦方法。與現有防禦方法不同，這些方法具有高延遲或專為靜態影像設計，ADAV 以即時方式執行，並利用 AV 視訊饋送中先前畫格的上下文資訊。ADAV 檢查目標畫格的物件偵測器輸出是否與先前參考畫格的輸出在時間上一致，以偵測貼片的出現。如果偵測到貼片的出現，ADAV 使用基於梯度的歸因來定位破壞時間一致性的對抗性像素。此兩階段程序允許 ADAV 有效處理乾淨的輸入，且兩個階段都經過最佳化以降低延遲。ADAV 使用來自 Berkeley Deep Drive BDD100K 資料集的真實世界駕駛資料進行評估，並展示出高度的對抗性和乾淨效能。

##### **A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**
2412.06212v1 by Zhepeng Wang, Runxue Bao, Yawen Wu, Guodong Liu, Lei Yang, Liang Zhan, Feng Zheng, Weiwen Jiang, Yanfu Zhang

Graph neural networks (GNNs) are powerful machine learning models designed to
handle irregularly structured data. However, their generic design often proves
inadequate for analyzing brain connectomes in Alzheimer's Disease (AD),
highlighting the need to incorporate domain knowledge for optimal performance.
Infusing AD-related knowledge into GNNs is a complicated task. Existing methods
typically rely on collaboration between computer scientists and domain experts,
which can be both time-intensive and resource-demanding. To address these
limitations, this paper presents a novel self-guided, knowledge-infused
multimodal GNN that autonomously incorporates domain knowledge into the model
development process. Our approach conceptualizes domain knowledge as natural
language and introduces a specialized multimodal GNN capable of leveraging this
uncurated knowledge to guide the learning process of the GNN, such that it can
improve the model performance and strengthen the interpretability of the
predictions. To evaluate our framework, we curated a comprehensive dataset of
recent peer-reviewed papers on AD and integrated it with multiple real-world AD
datasets. Experimental results demonstrate the ability of our method to extract
relevant domain knowledge, provide graph-based explanations for AD diagnosis,
and improve the overall performance of the GNN. This approach provides a more
scalable and efficient alternative to inject domain knowledge for AD compared
with the manual design from the domain expert, advancing both prediction
accuracy and interpretability in AD diagnosis.

摘要：圖形神經網路 (GNN) 是一款強大的機器學習模型，專門用於處理結構不規則的資料。然而，它們的通用設計通常無法充分分析阿茲海默症 (AD) 中的腦連接體，突顯了加入領域知識以優化效能的需求。將 AD 相關知識融入 GNN 是一項複雜的任務。現有方法通常仰賴電腦科學家和領域專家之間的合作，這可能會耗費大量時間和資源。為了解決這些限制，本文提出了一種新穎的自導式、知識注入多模式 GNN，它能自主地將領域知識納入模型開發過程中。我們的做法將領域知識概念化為自然語言，並引入一個專門的多模式 GNN，它能利用這種未經整理的知識來指導 GNN 的學習過程，以便它能改善模型效能並加強預測的可解釋性。為了評估我們的架構，我們整理了一份關於 AD 的近期同行評審論文的全面資料集，並將其與多個真實世界的 AD 資料集整合。實驗結果證明了我們的方法能夠萃取相關的領域知識、提供 AD 診斷的圖形化說明，並改善 GNN 的整體效能。與領域專家的手動設計相比，這種方法提供了一個更具可擴充性和效率性的替代方案，用於注入 AD 的領域知識，進而提升 AD 診斷中的預測準確性和可解釋性。

##### **Skill-Enhanced Reinforcement Learning Acceleration from Demonstrations**
2412.06207v1 by Hanping Zhang, Yuhong Guo

Learning from Demonstration (LfD) aims to facilitate rapid Reinforcement
Learning (RL) by leveraging expert demonstrations to pre-train the RL agent.
However, the limited availability of expert demonstration data often hinders
its ability to effectively aid downstream RL learning. To address this problem,
we propose a novel two-stage method dubbed as Skill-enhanced Reinforcement
Learning Acceleration (SeRLA). SeRLA introduces a skill-level adversarial
Positive-Unlabeled (PU) learning model to extract useful skill prior knowledge
by enabling learning from both limited expert data and general low-cost
demonstration data in the offline prior learning stage. Subsequently, it
deploys a skill-based soft actor-critic algorithm to leverage this acquired
prior knowledge in the downstream online RL stage for efficient training of a
skill policy network. Moreover, we develop a simple skill-level data
enhancement technique to further alleviate data sparsity and improve both skill
prior learning and downstream skill policy training. Our experimental results
on multiple standard RL environments show the proposed SeRLA method achieves
state-of-the-art performance on accelerating reinforcement learning on
downstream tasks, especially in the early learning phase.

摘要：示範學習 (LfD) 旨在透過利用專家示範來預先訓練 RL 代理，以促進快速強化學習 (RL)。然而，專家示範資料的取得有限，往往會阻礙其有效協助下游 RL 學習的能力。為了解決這個問題，我們提出了一種名為「技能增強強化學習加速 (SeRLA)」的創新兩階段方法。SeRLA 引入了技能等級對抗式正負未標籤 (PU) 學習模型，藉由在離線先驗學習階段從有限的專家資料和一般低成本示範資料中學習，來萃取出有用的技能先驗知識。隨後，它部署了一個基於技能的軟性動作-評論演算法，以在後續的線上 RL 階段中利用這個獲得的先驗知識，有效率地訓練技能政策網路。此外，我們開發了一種簡單的技能等級資料增強技術，以進一步減輕資料稀疏性，並改善技能先驗學習和後續的技能政策訓練。我們在多個標準 RL 環境中進行的實驗結果顯示，所提出的 SeRLA 方法在加速下游任務的強化學習方面達到了最先進的效能，特別是在早期學習階段。

##### **SiReRAG: Indexing Similar and Related Information for Multihop Reasoning**
2412.06206v1 by Nan Zhang, Prafulla Kumar Choubey, Alexander Fabbri, Gabriel Bernadett-Shapiro, Rui Zhang, Prasenjit Mitra, Caiming Xiong, Chien-Sheng Wu

Indexing is an important step towards strong performance in
retrieval-augmented generation (RAG) systems. However, existing methods
organize data based on either semantic similarity (similarity) or related
information (relatedness), but do not cover both perspectives comprehensively.
Our analysis reveals that modeling only one perspective results in insufficient
knowledge synthesis, leading to suboptimal performance on complex tasks
requiring multihop reasoning. In this paper, we propose SiReRAG, a novel RAG
indexing approach that explicitly considers both similar and related
information. On the similarity side, we follow existing work and explore some
variances to construct a similarity tree based on recursive summarization. On
the relatedness side, SiReRAG extracts propositions and entities from texts,
groups propositions via shared entities, and generates recursive summaries to
construct a relatedness tree. We index and flatten both similarity and
relatedness trees into a unified retrieval pool. Our experiments demonstrate
that SiReRAG consistently outperforms state-of-the-art indexing methods on
three multihop datasets (MuSiQue, 2WikiMultiHopQA, and HotpotQA), with an
average 1.9% improvement in F1 scores. As a reasonably efficient solution,
SiReRAG enhances existing reranking methods significantly, with up to 7.8%
improvement in average F1 scores.

摘要：索引是增強檢索生成 (RAG) 系統中邁向強大效能的重要步驟。然而，現有方法依據語意相似性 (相似性) 或相關資訊 (相關性) 來組織資料，但並未全面涵蓋這兩個觀點。我們的分析顯示，僅建模單一觀點會導致知識綜合不足，進而導致在需要多重跳躍推理的複雜任務上產生次佳效能。在本文中，我們提出 SiReRAG，一種新穎的 RAG 索引方法，它明確考慮相似和相關資訊。在相似性方面，我們遵循現有工作並探索一些變異，以基於遞迴摘要來建構相似性樹。在相關性方面，SiReRAG 從文本中萃取命題和實體，透過共享實體來群組命題，並產生遞迴摘要以建構相關性樹。我們將相似性和相關性樹索引並壓平到統一的檢索池中。我們的實驗證明，SiReRAG 在三個多重跳躍資料集 (MuSiQue、2WikiMultiHopQA 和 HotpotQA) 上始終優於最先進的索引方法，F1 分數平均提升 1.9%。作為一個相當有效率的解決方案，SiReRAG 大幅增強現有的重新排序方法，F1 分數平均提升達 7.8%。

##### **SparseAccelerate: Efficient Long-Context Inference for Mid-Range GPUs**
2412.06198v1 by James Vo

As Large Language Models (LLMs) scale to longer context windows, the
computational cost of attention mechanisms, which traditionally grows
quadratically with input length, presents a critical challenge for real-time
and memory-constrained deployments. Existing sparse attention techniques have
sought to reduce this complexity, but they often incur significant overhead or
compromise accuracy, making them less practical for large contexts on mid-range
hardware. In this paper, we introduce SparseAccelerate, a dynamic sparse
attention method that adapts its sparsity patterns based on input
characteristics, effectively flattening the attention complexity curve. Our
approach is effective for input lengths starting at 16K tokens and scales
efficiently up to 128K tokens on dual NVIDIA A5000 GPUs (24GB each).
Experimental results show that SparseAccelerate achieves up to a 1.04x
reduction in Time-To-First-Token (TTFT) latency at 32K tokens, while also
providing substantial memory savings. These improvements yield practical gains
for memory-intensive applications and long-context tasks that were previously
infeasible with standard attention. Beyond latency reductions, SparseAccelerate
fundamentally shifts the scaling trend, demonstrating the smallest TTFT growth
gradient relative to context length among competing methods. Ongoing
evaluations on diverse benchmarks confirm its scalability, positioning
SparseAccelerate as a critical advancement toward efficient, real-time, and
large-context LLM inference on accessible hardware.

摘要：隨著大型語言模型 (LLM) 擴展到更長的內容視窗，傳統上隨著輸入長度呈二次方增長的注意力機制計算成本，對即時和記憶體受限的部署構成了一項重大挑戰。現有的稀疏注意力技術已尋求降低此複雜性，但它們通常會產生顯著的開銷或損害準確性，這使得它們對於中階硬體上的大型內容不太實用。在本文中，我們介紹了 SparseAccelerate，這是一種動態稀疏注意力方法，它根據輸入特徵調整其稀疏模式，有效地展平了注意力複雜性曲線。我們的做法對於從 16K 個代幣開始的輸入長度有效，並且可以在兩個 NVIDIA A5000 GPU（每個 24GB）上有效地擴展到 128K 個代幣。實驗結果表明，SparseAccelerate 在 32K 個代幣時將首次代幣時間 (TTFT) 延遲減少了 1.04 倍，同時也提供了大量的記憶體節省。這些改進為記憶體密集型應用程式和長內容任務帶來了實際收益，而這些任務以前使用標準注意力是不可行的。除了減少延遲之外，SparseAccelerate 從根本上改變了擴展趨勢，展示了相對於內容長度而言，在競爭方法中 TTFT 增長梯度最小。對各種基準的持續評估確認了其可擴展性，將 SparseAccelerate 定位為朝著在可存取硬體上進行高效、即時且大內容 LLM 推論的關鍵進展。

##### **Enhancing Adversarial Resistance in LLMs with Recursion**
2412.06181v1 by Bryan Li, Sounak Bagchi, Zizhan Wang

The increasing integration of Large Language Models (LLMs) into society
necessitates robust defenses against vulnerabilities from jailbreaking and
adversarial prompts. This project proposes a recursive framework for enhancing
the resistance of LLMs to manipulation through the use of prompt simplification
techniques. By increasing the transparency of complex and confusing adversarial
prompts, the proposed method enables more reliable detection and prevention of
malicious inputs. Our findings attempt to address a critical problem in AI
safety and security, providing a foundation for the development of systems able
to distinguish harmless inputs from prompts containing malicious intent. As
LLMs continue to be used in diverse applications, the importance of such
safeguards will only grow.

摘要：大型語言模型 (LLM) 與社會的整合日益增加，因此需要健全的防禦措施來應對越獄和對抗性提示所帶來的漏洞。此專案提出一個遞迴架構，透過使用提示簡化技術來增強 LLM 對操縱的抵抗力。透過增加複雜且令人困惑的對抗性提示的透明度，所提出的方法能夠更可靠地偵測和預防惡意輸入。我們的研究結果試圖解決人工智慧安全性和安全性中的關鍵問題，為開發能夠區分無害輸入和包含惡意意圖的提示的系統奠定基礎。隨著 LLM 持續用於各種應用程式，此類防護措施的重要性只會與日俱增。

##### **Annotations for Exploring Food Tweets From Multiple Aspects**
2412.06179v1 by Matīss Rikters, Edison Marrese-Taylor, Rinalds Vīksna

This research builds upon the Latvian Twitter Eater Corpus (LTEC), which is
focused on the narrow domain of tweets related to food, drinks, eating and
drinking. LTEC has been collected for more than 12 years and reaching almost 3
million tweets with the basic information as well as extended automatically and
manually annotated metadata. In this paper we supplement the LTEC with manually
annotated subsets of evaluation data for machine translation, named entity
recognition, timeline-balanced sentiment analysis, and text-image relation
classification. We experiment with each of the data sets using baseline models
and highlight future challenges for various modelling approaches.

摘要：本研究建立在拉脫維亞 Twitter Eater 語料庫 (LTEC) 的基礎上，該語料庫專注於與食物、飲料、飲食相關的推文狹窄領域。LTEC 已收集超過 12 年，並收集了近 300 萬條推文，其中包含基本資訊以及自動和手動標註的擴充元資料。在本文中，我們使用手動標註的機器翻譯評估資料子集、命名實體辨識、時間軸平衡情緒分析和文字影像關係分類來補充 LTEC。我們使用基準模型對每個資料集進行實驗，並重點說明各種建模方法的未來挑戰。

##### **AlphaVerus: Bootstrapping Formally Verified Code Generation through Self-Improving Translation and Treefinement**
2412.06176v1 by Pranjal Aggarwal, Bryan Parno, Sean Welleck

Automated code generation with large language models has gained significant
traction, but there remains no guarantee on the correctness of generated code.
We aim to use formal verification to provide mathematical guarantees that the
generated code is correct. However, generating formally verified code with LLMs
is hindered by the scarcity of training data and the complexity of formal
proofs. To tackle this challenge, we introduce AlphaVerus, a self-improving
framework that bootstraps formally verified code generation by iteratively
translating programs from a higher-resource language and leveraging feedback
from a verifier. AlphaVerus operates in three phases: exploration of candidate
translations, Treefinement -- a novel tree search algorithm for program
refinement using verifier feedback, and filtering misaligned specifications and
programs to prevent reward hacking. Through this iterative process, AlphaVerus
enables a LLaMA-3.1-70B model to generate verified code without human
intervention or model finetuning. AlphaVerus shows an ability to generate
formally verified solutions for HumanEval and MBPP, laying the groundwork for
truly trustworthy code-generation agents.

摘要：大型語言模型的自動程式碼生成獲得顯著進展，但產生的程式碼正確性仍無法保證。我們旨在使用形式化驗證，提供產生的程式碼正確性的數學保證。然而，使用 LLM 產生形式化驗證的程式碼，受到訓練資料稀少和形式化證明複雜性的阻礙。為了應對這個挑戰，我們引入了 AlphaVerus，一個自我提升的架構，透過反覆翻譯來自較高資源語言的程式，並利用驗證器的回饋，來引導形式化驗證的程式碼產生。AlphaVerus 以三個階段運作：候選翻譯的探索、Treefinement——一種新穎的樹狀搜尋演算法，用於使用驗證器回饋來改善程式，以及過濾錯誤比對的規格和程式，以防止獎勵駭客攻擊。透過這個反覆的過程，AlphaVerus 能讓 LLaMA-3.1-70B 模型在沒有人工介入或模型微調的情況下，產生驗證的程式碼。AlphaVerus 展示了產生 HumanEval 和 MBPP 的形式化驗證解決方案的能力，為真正值得信賴的程式碼產生代理奠定了基礎。

##### **ACQ: A Unified Framework for Automated Programmatic Creativity in Online Advertising**
2412.06167v1 by Ruizhi Wang, Kai Liu, Bingjie Li, Yu Rong, Qingpeng Cai, Fei Pan, Peng Jiang

In online advertising, the demand-side platform (a.k.a. DSP) enables
advertisers to create different ad creatives for real-time bidding.
Intuitively, advertisers tend to create more ad creatives for a single photo to
increase the probability of participating in bidding, further enhancing their
ad cost. From the perspective of DSP, the following are two overlooked issues.
On the one hand, the number of ad creatives cannot grow indefinitely. On the
other hand, the marginal effects of ad cost diminish as the number of ad
creatives increases. To this end, this paper proposes a two-stage framework
named Automated Creatives Quota (ACQ) to achieve the automatic creation and
deactivation of ad creatives. ACQ dynamically allocates the creative quota
across multiple advertisers to maximize the revenue of the ad platform. ACQ
comprises two components: a prediction module to estimate the cost of a photo
under different numbers of ad creatives, and an allocation module to decide the
quota for photos considering their estimated costs in the prediction module.
Specifically, in the prediction module, we develop a multi-task learning model
based on an unbalanced binary tree to effectively mitigate the target variable
imbalance problem. In the allocation module, we formulate the quota allocation
problem as a multiple-choice knapsack problem (MCKP) and develop an efficient
solver to solve such large-scale problems involving tens of millions of ads. We
performed extensive offline and online experiments to validate the superiority
of our proposed framework, which increased cost by 9.34%.

摘要：在網路廣告中，需求方平台（又稱 DSP）讓廣告主得以針對即時競價建立不同的廣告素材。直覺上，廣告主傾向於針對單一圖片建立更多廣告素材，以提高參與競標的機率，進一步提升廣告成本。從 DSP 的角度來看，以下有兩個被忽略的問題。一方面，廣告素材的數量無法無限增加。另一方面，隨著廣告素材數量增加，廣告成本的邊際效益會遞減。為此，本文提出一個名為自動化素材配額 (ACQ) 的兩階段架構，以達成廣告素材的自動建立與停用。ACQ 動態分配多個廣告主的素材配額，以最大化廣告平台的收益。ACQ 包含兩個組成部分：一個預測模組，用於估計在不同廣告素材數量下的圖片成本；一個分配模組，用於決定圖片的配額，並考慮其在預測模組中估計的成本。具體來說，在預測模組中，我們開發一個基於不平衡二元樹的多任務學習模型，以有效減輕目標變數不平衡的問題。在分配模組中，我們將配額分配問題制定為多選背包問題（MCKP），並開發一個高效的求解器，用於解決涉及數千萬個廣告的大規模問題。我們執行廣泛的離線和線上實驗，以驗證我們提出的架構的優越性，該架構將成本提高了 9.34%。

##### **Query-Efficient Planning with Language Models**
2412.06162v1 by Gonzalo Gonzalez-Pumariega, Wayne Chen, Kushal Kedia, Sanjiban Choudhury

Planning in complex environments requires an agent to efficiently query a
world model to find a feasible sequence of actions from start to goal. Recent
work has shown that Large Language Models (LLMs), with their rich prior
knowledge and reasoning capabilities, can potentially help with planning by
searching over promising states and adapting to feedback from the world. In
this paper, we propose and study two fundamentally competing frameworks that
leverage LLMs for query-efficient planning. The first uses LLMs as a heuristic
within a search-based planner to select promising nodes to expand and propose
promising actions. The second uses LLMs as a generative planner to propose an
entire sequence of actions from start to goal, query a world model, and adapt
based on feedback. We show that while both approaches improve upon comparable
baselines, using an LLM as a generative planner results in significantly fewer
interactions. Our key finding is that the LLM as a planner can more rapidly
adapt its planning strategies based on immediate feedback than LLM as a
heuristic. We present evaluations and ablations on Robotouille and PDDL
planning benchmarks and discuss connections to existing theory on
query-efficient planning algorithms. Code is available at
https://github.com/portal-cornell/llms-for-planning

摘要：在複雜的環境中規劃需要一個代理程式有效地查詢世界模型，以找出從開始到目標的可行動作序列。最近的研究表明，大型語言模型 (LLM) 具有豐富的先驗知識和推理能力，可以通過搜尋有希望的狀態並適應來自世界的回饋來幫助規劃。在本文中，我們提出並研究了兩個從根本上相互競爭的框架，它們利用 LLM 進行查詢高效的規劃。第一個使用 LLM 作為基於搜尋的規劃器中的啟發式，以選擇有希望的節點進行擴充並提出有希望的動作。第二個使用 LLM 作為生成式規劃器，從開始到目標提出整個動作序列，查詢世界模型並根據回饋進行調整。我們表明，儘管兩種方法都改進了可比較的基準，但使用 LLM 作為生成式規劃器會導致交互次數顯著減少。我們的關鍵發現是，作為規劃器的 LLM 可以比作為啟發式的 LLM 更快地根據即時回饋調整其規劃策略。我們在 Robotouille 和 PDDL 規劃基準上提出了評估和消融，並討論了與現有查詢高效規劃演算法理論的聯繫。程式碼可在 https://github.com/portal-cornell/llms-for-planning 獲得

##### **MoSH: Modeling Multi-Objective Tradeoffs with Soft and Hard Bounds**
2412.06154v1 by Edward Chen, Natalie Dullerud, Thomas Niedermayr, Elizabeth Kidd, Ransalu Senanayake, Pang Wei Koh, Sanmi Koyejo, Carlos Guestrin

Countless science and engineering applications in multi-objective
optimization (MOO) necessitate that decision-makers (DMs) select a
Pareto-optimal solution which aligns with their preferences. Evaluating
individual solutions is often expensive, necessitating cost-sensitive
optimization techniques. Due to competing objectives, the space of trade-offs
is also expansive -- thus, examining the full Pareto frontier may prove
overwhelming to a DM. Such real-world settings generally have loosely-defined
and context-specific desirable regions for each objective function that can aid
in constraining the search over the Pareto frontier. We introduce a novel
conceptual framework that operationalizes these priors using soft-hard
functions, SHFs, which allow for the DM to intuitively impose soft and hard
bounds on each objective -- which has been lacking in previous MOO frameworks.
Leveraging a novel minimax formulation for Pareto frontier sampling, we propose
a two-step process for obtaining a compact set of Pareto-optimal points which
respect the user-defined soft and hard bounds: (1) densely sample the Pareto
frontier using Bayesian optimization, and (2) sparsify the selected set to
surface to the user, using robust submodular function optimization. We prove
that (2) obtains the optimal compact Pareto-optimal set of points from (1). We
further show that many practical problems fit within the SHF framework and
provide extensive empirical validation on diverse domains, including
brachytherapy, engineering design, and large language model personalization.
Specifically, for brachytherapy, our approach returns a compact set of points
with over 3% greater SHF-defined utility than the next best approach. Among the
other diverse experiments, our approach consistently leads in utility, allowing
the DM to reach >99% of their maximum possible desired utility within
validation of 5 points.

摘要：<paragraph>無數的多目標優化 (MOO) 中的科學和工程應用都需要決策者 (DM) 選擇符合其偏好的帕雷托最優解。評估個別解法通常很昂貴，因此需要具備成本效益的最佳化技術。由於目標相互競爭，取捨空間也十分廣闊，因此，檢查完整的帕雷托前緣可能會讓 DM 感到不知所措。此類實際設定通常對於每個目標函數都有定義鬆散且特定於情境的理想區域，有助於限制在帕雷托前緣上的搜尋。我們引入了一個新穎的概念框架，使用軟硬函數 (SHF) 來操作這些先驗，讓 DM 能夠直觀地對每個目標施加軟約束和硬約束，而這是先前的 MOO 框架所缺乏的。利用帕雷托前緣取樣的創新 minimax 公式，我們提出了一個兩步驟流程來取得一組精簡的帕雷托最優點，這些點符合使用者定義的軟約束和硬約束：(1) 使用貝氏最佳化密集取樣帕雷托前緣，以及 (2) 使用穩健次模函數最佳化稀疏化所選集合，以顯示給使用者。我們證明 (2) 從 (1) 中取得最佳的精簡帕雷托最優點集合。我們進一步說明許多實際問題符合 SHF 框架，並在各種領域提供廣泛的實證驗證，包括近距離放射治療、工程設計和大型語言模型個人化。具體來說，對於近距離放射治療，我們的做法回傳一組精簡的點，其 SHF 定義的效用比次佳做法高出 3% 以上。在其他各種實驗中，我們的做法始終領先於效用，讓 DM 能在驗證 5 個點時達到其最大可能期望效用的 >99%。</paragraph>

##### **The Computational Limits of State-Space Models and Mamba via the Lens of Circuit Complexity**
2412.06148v1 by Yifang Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song

In this paper, we analyze the computational limitations of Mamba and
State-space Models (SSMs) by using the circuit complexity framework. Despite
Mamba's stateful design and recent attention as a strong candidate to
outperform Transformers, we have demonstrated that both Mamba and SSMs with
$\mathrm{poly}(n)$-precision and constant-depth layers reside within the
$\mathsf{DLOGTIME}$-uniform $\mathsf{TC}^0$ complexity class. This result
indicates Mamba has the same computational capabilities as Transformer
theoretically, and it cannot solve problems like arithmetic formula problems,
boolean formula value problems, and permutation composition problems if
$\mathsf{TC}^0 \neq \mathsf{NC}^1$. Therefore, it challenges the assumption
Mamba is more computationally expressive than Transformers. Our contributions
include rigorous proofs showing that Selective SSM and Mamba architectures can
be simulated by $\mathsf{DLOGTIME}$-uniform $\mathsf{TC}^0$ circuits, and they
cannot solve problems outside $\mathsf{TC}^0$.

摘要：在本文中，我们使用電路複雜度框架分析了 Mamba 和狀態空間模型 (SSM) 的計算限制。儘管 Mamba 具有狀態設計，並且最近作為超越 Transformer 的強有力候選者受到關注，但我們已經證明了具有 $\mathrm{poly}(n)$ 精度和恆定深度層的 Mamba 和 SSM 都存在於 $\mathsf{DLOGTIME}$-uniform $\mathsf{TC}^0$ 複雜度類中。這個結果表明 Mamba 在理論上具有與 Transformer 相同的計算能力，並且如果 $\mathsf{TC}^0 \neq \mathsf{NC}^1$，它無法解決算術公式問題、布林公式值問題和排列組合問題等問題。因此，它挑戰了 Mamba 比 Transformer 具有更多計算表達能力的假設。我們的貢獻包括嚴格的證明，表明選擇性 SSM 和 Mamba 架構可以由 $\mathsf{DLOGTIME}$-uniform $\mathsf{TC}^0$ 電路模擬，並且它們無法解決 $\mathsf{TC}^0$ 之外的問題。

##### **Hate Speech According to the Law: An Analysis for Effective Detection**
2412.06144v1 by Katerina Korre, John Pavlopoulos, Paolo Gajo, Alberto Barrón-Cedeño

The issue of hate speech extends beyond the confines of the online realm. It
is a problem with real-life repercussions, prompting most nations to formulate
legal frameworks that classify hate speech as a punishable offence. These legal
frameworks differ from one country to another, contributing to the big chaos
that online platforms have to face when addressing reported instances of hate
speech. With the definitions of hate speech falling short in introducing a
robust framework, we turn our gaze onto hate speech laws. We consult the
opinion of legal experts on a hate speech dataset and we experiment by
employing various approaches such as pretrained models both on hate speech and
legal data, as well as exploiting two large language models (Qwen2-7B-Instruct
and Meta-Llama-3-70B). Due to the time-consuming nature of data acquisition for
prosecutable hate speech, we use pseudo-labeling to improve our pretrained
models. This study highlights the importance of amplifying research on
prosecutable hate speech and provides insights into effective strategies for
combating hate speech within the parameters of legal frameworks. Our findings
show that legal knowledge in the form of annotations can be useful when
classifying prosecutable hate speech, yet more focus should be paid on the
differences between the laws.

摘要：仇恨言論的問題已超出網路領域的範疇。它是一個具有現實後果的問題，促使大多數國家制定將仇恨言論歸類為可處罰罪行的法律架構。這些法律架構因國家而異，導致線上平台在處理仇恨言論的通報個案時面臨巨大的混亂。由於仇恨言論的定義未能提出一個強而有力的架構，我們將目光轉向仇恨言論法。我們諮詢法律專家對仇恨言論資料集的意見，並透過採用各種方法進行實驗，例如在仇恨言論和法律資料上預先訓練的模型，以及利用兩個大型語言模型（Qwen2-7B-Instruct 和 Meta-Llama-3-70B）。由於可起訴仇恨言論的資料取得本質上耗時，我們使用偽標籤來改善我們的預訓練模型。這項研究強調了擴大對可起訴仇恨言論的研究的重要性，並提供了在法律架構參數內打擊仇恨言論的有效策略見解。我們的研究結果顯示，註解形式的法律知識在對可起訴仇恨言論進行分類時可能很有用，但應更多關注法律之間的差異。

##### **Precise, Fast, and Low-cost Concept Erasure in Value Space: Orthogonal Complement Matters**
2412.06143v1 by Yuan Wang, Ouxiang Li, Tingting Mu, Yanbin Hao, Kuien Liu, Xiang Wang, Xiangnan He

The success of text-to-image generation enabled by diffuion models has
imposed an urgent need to erase unwanted concepts, e.g., copyrighted,
offensive, and unsafe ones, from the pre-trained models in a precise, timely,
and low-cost manner. The twofold demand of concept erasure requires a precise
removal of the target concept during generation (i.e., erasure efficacy), while
a minimal impact on non-target content generation (i.e., prior preservation).
Existing methods are either computationally costly or face challenges in
maintaining an effective balance between erasure efficacy and prior
preservation. To improve, we propose a precise, fast, and low-cost concept
erasure method, called Adaptive Vaule Decomposer (AdaVD), which is
training-free. This method is grounded in a classical linear algebraic
orthogonal complement operation, implemented in the value space of each
cross-attention layer within the UNet of diffusion models. An effective shift
factor is designed to adaptively navigate the erasure strength, enhancing prior
preservation without sacrificing erasure efficacy. Extensive experimental
results show that the proposed AdaVD is effective at both single and multiple
concept erasure, showing a 2- to 10-fold improvement in prior preservation as
compared to the second best, meanwhile achieving the best or near best erasure
efficacy, when comparing with both training-based and training-free state of
the arts. AdaVD supports a series of diffusion models and downstream image
generation tasks, the code is available on the project page:
https://github.com/WYuan1001/AdaVD

摘要：<paragraph>扩散模型所实现的文本到图像生成技术成功后，迫切需要以精确、及时且低成本的方式从预先训练的模型中消除不需要的概念，例如受版权保护、冒犯性和不安全的概念。概念消除的双重需求需要在生成过程中精确移除目标概念（即消除功效），同时对非目标内容生成（即先验保留）的影响最小。现有的方法要么计算成本高，要么在保持消除功效和先验保留之间的有效平衡方面面临挑战。为了改进，我们提出了一种精确、快速且低成本的概念消除方法，称为自适应值分解器 (AdaVD)，它无需训练。此方法基于经典线性代数正交补操作，在扩散模型的 UNet 中每个交叉注意层的值空间中实现。设计了一个有效的偏移因子来自适应地控制消除强度，在不牺牲消除功效的情况下增强先验保留。广泛的实验结果表明，所提出的 AdaVD 在单概念和多概念消除方面都非常有效，与第二好的方法相比，先验保留提高了 2 到 10 倍，同时在与基于训练和无训练的最新技术进行比较时，实现了最佳或接近最佳的消除效果。AdaVD 支持一系列扩散模型和下游图像生成任务，代码可在项目页面上获取：https://github.com/WYuan1001/AdaVD</paragraph>

##### **MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**
2412.06141v1 by Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.

摘要：大型視覺語言模型 (LVLMs) 的進步推動了它們在醫療領域的應用。然而，醫學 LVLMs (Med-LVLMs) 由於模態錯位而遇到事實挑戰，其中模型優先考慮文字知識而非視覺輸入，導致幻覺與醫學影像中的資訊相矛盾。先前嘗試透過偏好最佳化來增強 Med-LVLMs 中的模態對齊，在偏好資料中不足以減輕臨床相關性，使得這些範例容易區分，並降低對齊效果。為了應對這項挑戰，我們提出 MMedPO，一種新的多模態醫學偏好最佳化方法，它考慮偏好範例的臨床相關性，以增強 Med-LVLM 對齊。MMedPO 透過引入兩種類型的反偏好來管理多模態偏好資料：(1) 合理的幻覺透過目標 Med-LVLMs 或 GPT-4o 注入，以產生醫學上不準確的回應，以及 (2) 透過局部病灶雜訊實現病灶區域忽略，破壞對關鍵區域的視覺理解。然後，我們根據來自多個 Med-LLMs 和視覺工具的分數計算每個範例的臨床相關性，並將這些分數作為權重整合到偏好最佳化過程中，以實現有效對齊。我們的實驗證明，MMedPO 明顯增強了 Med-LVLMs 中的事實準確性，在 Med-VQA 和報告生成任務中，平均分別比現有的偏好最佳化方法提高了 14.2% 和 51.7%。我們的程式碼可以在 https://github.com/aiming-lab/MMedPO 中取得。

##### **AIDE: Task-Specific Fine Tuning with Attribute Guided Multi-Hop Data Expansion**
2412.06136v1 by Jiayu Li, Xuan Zhu, Fang Liu, Yanjun Qi

Fine-tuning large language models (LLMs) for specific tasks requires
high-quality, diverse training data relevant to the task. Recent research has
leveraged LLMs to synthesize training data, but existing approaches either
depend on large seed datasets or struggle to ensure both task relevance and
data diversity in the generated outputs. To address these challenges, we
propose AIDE, a novel data synthesis framework that uses a multi-hop process to
expand 10 seed data points while ensuring diversity and task relevance. AIDE
extracts the main topic and key knowledge attributes from the seed data to
guide the synthesis process. In each subsequent hop, it extracts the topic and
attributes from the newly generated data and continues guided synthesis. This
process repeats for a total of K hops. To prevent irrelevant data generation as
the hop depth increases, AIDE incorporates a residual connection mechanism and
uses self-reflection to improve data quality. Our empirical results demonstrate
that fine-tuning Mistral-7B, Llama-3.1-8B and Llama-3.2-3B with AIDE achieves
more than 10% accuracy improvements over the base models across 13 tasks from 5
different benchmarks, while outperforming the models fine-tuned with
state-of-the-art data synthesis methods like Evol-Instruct, DataTune and
Prompt2Model.

摘要：微調大型語言模型 (LLM) 以執行特定任務需要與任務相關的高品質、多樣化訓練資料。最近的研究已利用 LLM 來綜合訓練資料，但現有方法依賴於大型種子資料集，或難以確保生成輸出中的任務相關性和資料多樣性。為了應對這些挑戰，我們提出 AIDE，這是一個新穎的資料綜合架構，它使用多重跳躍程序來擴充 10 個種子資料點，同時確保多樣性和任務相關性。AIDE 從種子資料中提取主要主題和關鍵知識屬性，以指導綜合程序。在每個後續跳躍中，它從新生成的資料中提取主題和屬性，並繼續進行引導式綜合。這個程序總共重複 K 次跳躍。為了防止隨著跳躍深度增加而產生不相關的資料，AIDE 結合了殘差連接機制，並使用自我反思來改善資料品質。我們的實證結果表明，使用 AIDE 微調 Mistral-7B、Llama-3.1-8B 和 Llama-3.2-3B，在來自 5 個不同基準的 13 個任務中，其準確度提升幅度超過 10%，同時優於使用 Evol-Instruct、DataTune 和 Prompt2Model 等最先進資料綜合方法微調的模型。

##### **Evaluating and Mitigating Social Bias for Large Language Models in Open-ended Settings**
2412.06134v1 by Zhao Liu

Current social bias benchmarks for Large Language Models (LLMs) primarily
rely on pre-defined question formats like multiple-choice, limiting their
ability to reflect the complexity and open-ended nature of real-world
interactions. To address this gap, we extend an existing BBQ dataset introduced
by incorporating fill-in-the-blank and short-answer question types, designed to
evaluate biases in an open-ended setting. Our finding reveals that LLMs tend to
produce responses that are more biased against certain protected attributes,
like age and socio-economic status. On the other hand, these biased outputs
produced by LLMs can serve as valuable contexts and chains of thought for
debiasing. Our debiasing approach combined zero-shot, few-shot, and
chain-of-thought could significantly reduce the level of bias to almost 0. We
open-source our evaluation and debiasing code hoping to encourage further
measurements and mitigation of bias and stereotype in LLMs.

摘要：目前大型語言模型 (LLM) 的社會偏見基準主要依賴於預先定義的問題格式，例如多重選擇，限制了它們反映現實世界互動的複雜性和開放式性質的能力。為了解決這個差距，我們擴展了一個現有的 BBQ 資料集，引入了填空和簡答題類型，旨在評估開放式環境中的偏見。我們的發現表明，LLM 傾向於產生對某些受保護屬性（例如年齡和社會經濟地位）更偏見的回應。另一方面，這些由 LLM 產生的有偏見的輸出可以作為有價值的上下文和去偏見的思考鏈。我們的去偏見方法結合了零次學習、少次學習和思考鏈，可以顯著將偏見程度降低到接近於 0。我們開放原始碼評估和去偏見代碼，希望鼓勵進一步測量和減輕 LLM 中的偏見和刻板印象。

##### **Privacy-Preserving Large Language Models: Mechanisms, Applications, and Future Directions**
2412.06113v1 by Guoshenghui Zhao, Eric Song

The rapid advancement of large language models (LLMs) has revolutionized
natural language processing, enabling applications in diverse domains such as
healthcare, finance and education. However, the growing reliance on extensive
data for training and inference has raised significant privacy concerns,
ranging from data leakage to adversarial attacks. This survey comprehensively
explores the landscape of privacy-preserving mechanisms tailored for LLMs,
including differential privacy, federated learning, cryptographic protocols,
and trusted execution environments. We examine their efficacy in addressing key
privacy challenges, such as membership inference and model inversion attacks,
while balancing trade-offs between privacy and model utility. Furthermore, we
analyze privacy-preserving applications of LLMs in privacy-sensitive domains,
highlighting successful implementations and inherent limitations. Finally, this
survey identifies emerging research directions, emphasizing the need for novel
frameworks that integrate privacy by design into the lifecycle of LLMs. By
synthesizing state-of-the-art approaches and future trends, this paper provides
a foundation for developing robust, privacy-preserving large language models
that safeguard sensitive information without compromising performance.

摘要：大型語言模型 (LLM) 的快速進步徹底改變了自然語言處理，讓醫療保健、金融和教育等不同領域的應用成為可能。然而，對大量資料的依賴不斷增長，無論是訓練或推論都引發了嚴重的隱私問題，從資料外洩到對抗攻擊等都有。這項調查全面探討了專為 LLM 量身打造的隱私保護機制的概況，包括差分隱私、聯合學習、加密協定和受信任執行環境。我們檢視了它們在解決關鍵隱私挑戰（例如成員推論和模型反演攻擊）方面的效力，同時平衡隱私和模型效用之間的取捨。此外，我們分析了 LLM 在隱私敏感領域的隱私保護應用，重點說明成功的實作和固有的限制。最後，這項調查找出新興的研究方向，強調將隱私設計整合到 LLM 生命週期中，以建立創新的架構。透過綜合最先進的方法和未來趨勢，本文提供了一個基礎，用於開發強健的隱私保護大型語言模型，在不影響效能的情況下保護敏感資訊。

##### **Infusing Prompts with Syntax and Semantics**
2412.06107v1 by Anton Bulle Labate, Fabio Gagliardi Cozman

Despite impressive success, language models often generate outputs with
flawed linguistic structure. We analyze the effect of directly infusing various
kinds of syntactic and semantic information into large language models. To
demonstrate the value of our proposals, we focus on the translation of natural
language queries to SQL, in particular dealing with languages with less
resources than English, to better investigate how much help we can get from low
cost syntactic and semantic information. We show that linguistic analysis can
significantly boost language models, to the point that we have surpassed
previous best systems.

摘要：儘管語言模型獲得了令人印象深刻的成功，但它們經常會生成語言結構有瑕疵的輸出。我們分析了將各種句法和語義資訊直接注入大型語言模型的效果。為了證明我們建議的價值，我們專注於將自然語言查詢轉換為 SQL，特別是處理資源少於英語的語言，以更好地探討我們能從低成本句法和語義資訊中獲得多少幫助。我們表明，語言分析可以顯著提升語言模型，甚至超越了之前的最佳系統。

##### **Enhanced Computationally Efficient Long LoRA Inspired Perceiver Architectures for Auto-Regressive Language Modeling**
2412.06106v1 by Kaleel Mahmood, Shaoyi Huang

The Transformer architecture has revolutionized the Natural Language
Processing field and is the backbone of Large Language Models (LLMs). The
Transformer uses the attention mechanism that computes the pair-wise similarity
between its input tokens to produce latent vectors that are able to understand
the semantic meaning of the input text. One of the challenges in the
Transformer architecture is the quadratic complexity of the attention mechanism
that prohibits the efficient processing of long sequence lengths. While many
recent research works have attempted to provide a reduction from $O(n^2)$ time
complexity of attention to semi-linear complexity, it remains an unsolved
problem in the sense of maintaining a high performance when such complexity is
reduced. One of the important works in this respect is the Perceiver class of
architectures that have demonstrated excellent performance while reducing the
computation complexity. In this paper, we use the PerceiverAR that was proposed
for Auto-Regressive modeling as a baseline, and provide three different
architectural enhancements to it with varying computation overhead tradeoffs.
Inspired by the recently proposed efficient attention computation approach of
Long-LoRA, we then present an equally efficient Perceiver-based architecture
(termed as Long LoRA Pereceiver - LLP) that can be used as the base
architecture in LLMs instead of just a fine-tuning add-on. Our results on
different benchmarks indicate impressive improvements compared to recent
Transformer based models.

摘要：Transformer 架構徹底改變了自然語言處理領域，並且是大語言模型 (LLM) 的支柱。Transformer 使用注意力機制，計算其輸入代幣之間成對的相似性，以產生能夠理解輸入文本語義含義的潛在向量。Transformer 架構面臨的挑戰之一是注意力機制的二次複雜度，這會阻礙對長序列長度的有效處理。雖然許多最近的研究工作都嘗試將注意力從 O(n^2) 時間複雜度降低到半線性複雜度，但它在降低這種複雜度時仍無法保持高性能，這仍然是一個未解決的問題。這方面的重要工作之一是感知器類架構，它在降低計算複雜度的同時展示了卓越的性能。在本文中，我們使用為自迴歸建模提出的感知器 AR 作為基線，並針對它提供了三種不同的架構增強，這些增強具有不同的計算開銷權衡。受最近提出的 Long-LoRA 高效注意力計算方法的啟發，我們隨後提出了一個同樣高效的基於感知器的架構（稱為 Long LoRA 感知器 - LLP），它可以用作 LLM 中的基本架構，而不仅仅是一個微調附加元件。我們在不同基準測試上的結果表明，與最近基於 Transformer 的模型相比，我們的模型有了顯著的改進。

##### **Measuring Grammatical Diversity from Small Corpora: Derivational Entropy Rates, Mean Length of Utterances, and Annotation Invariance**
2412.06095v1 by Fermin Moscoso del Prado Martin

In many fields, such as language acquisition, neuropsychology of language,
the study of aging, and historical linguistics, corpora are used for estimating
the diversity of grammatical structures that are produced during a period by an
individual, community, or type of speakers. In these cases, treebanks are taken
as representative samples of the syntactic structures that might be
encountered. Generalizing the potential syntactic diversity from the structures
documented in a small corpus requires careful extrapolation whose accuracy is
constrained by the limited size of representative sub-corpora. In this article,
I demonstrate -- theoretically, and empirically -- that a grammar's
derivational entropy and the mean length of the utterances (MLU) it generates
are fundamentally linked, giving rise to a new measure, the derivational
entropy rate. The mean length of utterances becomes the most practical index of
syntactic complexity; I demonstrate that MLU is not a mere proxy, but a
fundamental measure of syntactic diversity. In combination with the new
derivational entropy rate measure, it provides a theory-free assessment of
grammatical complexity. The derivational entropy rate indexes the rate at which
different grammatical annotation frameworks determine the grammatical
complexity of treebanks. I introduce the Smoothed Induced Treebank Entropy
(SITE) as a tool for estimating these measures accurately, even from very small
treebanks. I conclude by discussing important implications of these results for
both NLP and human language processing.

摘要：在許多領域中，例如語言習得、語言神經心理學、老化研究和歷史語言學，語料庫用於估計個人、社群或說話者類型在某個時段內產生的語法結構的多樣性。在這些案例中，樹庫被視為可能遭遇的句法結構的代表性樣本。從小型語料庫中記錄的結構概化潛在的句法多樣性需要仔細推論，其準確性受到代表性子語料庫的有限大小所限制。在本文中，我證明——在理論上和經驗上——語法的派生熵和它產生的發話平均長度 (MLU) 在根本上是相關聯的，產生了一個新的測量值，即派生熵率。發話的平均長度成為句法複雜性的最實用指標；我證明 MLU 不僅僅是一個代理，而且是句法多樣性的基本測量值。結合新的派生熵率測量值，它提供了一個無理論的語法複雜性評估。派生熵率對應於不同語法註解框架確定樹庫的語法複雜性的速率。我介紹了平滑誘導樹庫熵 (SITE) 作為準確估計這些測量值的工具，即使是來自非常小的樹庫。我最後討論了這些結果對自然語言處理和人類語言處理的重要影響。

##### **Trust No AI: Prompt Injection Along The CIA Security Triad**
2412.06090v1 by Johann Rehberger

The CIA security triad - Confidentiality, Integrity, and Availability - is a
cornerstone of data and cybersecurity. With the emergence of large language
model (LLM) applications, a new class of threat, known as prompt injection, was
first identified in 2022. Since then, numerous real-world vulnerabilities and
exploits have been documented in production LLM systems, including those from
leading vendors like OpenAI, Microsoft, Anthropic and Google. This paper
compiles real-world exploits and proof-of concept examples, based on the
research conducted and publicly documented by the author, demonstrating how
prompt injection undermines the CIA triad and poses ongoing risks to
cybersecurity and AI systems at large.

摘要：中情局安全三要素 - 保密性、完整性和可用性 - 是数据和网络安全的基础。随着大型语言模型 (LLM) 应用程序的出现，一类新的威胁——称为提示注入——于 2022 年首次被发现。从那时起，在生产 LLM 系统中记录了许多现实世界的漏洞和攻击，包括来自 OpenAI、Microsoft、Anthropic 和 Google 等领先供应商的漏洞。本文根据作者进行的研究和公开记录的真实世界攻击和概念验证示例，展示了提示注入如何破坏 CIA 三要素，并对网络安全和人工智能系统构成持续的风险。

##### **A4-Unet: Deformable Multi-Scale Attention Network for Brain Tumor Segmentation**
2412.06088v1 by Ruoxin Wang, Tianyi Tang, Haiming Du, Yuxuan Cheng, Yu Wang, Lingjie Yang, Xiaohui Duan, Yunfang Yu, Yu Zhou, Donglong Chen

Brain tumor segmentation models have aided diagnosis in recent years.
However, they face MRI complexity and variability challenges, including
irregular shapes and unclear boundaries, leading to noise, misclassification,
and incomplete segmentation, thereby limiting accuracy. To address these
issues, we adhere to an outstanding Convolutional Neural Networks (CNNs) design
paradigm and propose a novel network named A4-Unet. In A4-Unet, Deformable
Large Kernel Attention (DLKA) is incorporated in the encoder, allowing for
improved capture of multi-scale tumors. Swin Spatial Pyramid Pooling (SSPP)
with cross-channel attention is employed in a bottleneck further to study
long-distance dependencies within images and channel relationships. To enhance
accuracy, a Combined Attention Module (CAM) with Discrete Cosine Transform
(DCT) orthogonality for channel weighting and convolutional element-wise
multiplication is introduced for spatial weighting in the decoder. Attention
gates (AG) are added in the skip connection to highlight the foreground while
suppressing irrelevant background information. The proposed network is
evaluated on three authoritative MRI brain tumor benchmarks and a proprietary
dataset, and it achieves a 94.4% Dice score on the BraTS 2020 dataset, thereby
establishing multiple new state-of-the-art benchmarks. The code is available
here: https://github.com/WendyWAAAAANG/A4-Unet.

摘要：近幾年，腦腫瘤分割模型已協助診斷。
然而，它們面臨 MRI 複雜性和可變性挑戰，包括不規則形狀和不清晰的邊界，導致雜訊、錯誤分類和不完整分割，因而限制了準確性。為了解決這些問題，我們遵循傑出的卷積神經網路 (CNN) 設計範例，並提出一個名為 A4-Unet 的新網路。在 A4-Unet 中，可變形大核注意力 (DLKA) 被納入編碼器，允許改進多尺度腫瘤的擷取。具有跨通道注意力的 Swin 空間金字塔池化 (SSPP) 被用於瓶頸中，以進一步研究影像中的長距離依賴性和通道關係。為了提高準確性，引入了具有離散餘弦轉換 (DCT) 正交性的組合注意力模組 (CAM) 以進行通道加權，並在解碼器中進行卷積元素級乘法以進行空間加權。注意力閘門 (AG) 被加入跳躍連接中，以在抑制不相關背景資訊的同時，重點關注前景。所提出的網路在三個權威的 MRI 腦腫瘤基準和一個專有資料集上進行評估，並在 BraTS 2020 資料集上取得 94.4% 的 Dice 分數，從而建立了多個新的最先進基準。程式碼可在此處取得：https://github.com/WendyWAAAAANG/A4-Unet。

##### **Ethnography and Machine Learning: Synergies and New Directions**
2412.06087v1 by Zhuofan Li, Corey M. Abramson

Ethnography (social scientific methods that illuminate how people understand,
navigate and shape the real world contexts in which they live their lives) and
machine learning (computational techniques that use big data and statistical
learning models to perform quantifiable tasks) are each core to contemporary
social science. Yet these tools have remained largely separate in practice.
This chapter draws on a growing body of scholarship that argues that
ethnography and machine learning can be usefully combined, particularly for
large comparative studies. Specifically, this paper (a) explains the value (and
challenges) of using machine learning alongside qualitative field research for
certain types of projects, (b) discusses recent methodological trends to this
effect, (c) provides examples that illustrate workflow drawn from several large
projects, and (d) concludes with a roadmap for enabling productive coevolution
of field methods and machine learning.

摘要：民族誌（闡明人們如何理解、探索和塑造他們生活於其中的真實世界脈絡的社會科學方法）和機器學習（使用大數據和統計學習模型來執行可量化任務的計算技術）都是當代社會科學的核心。然而，這些工具在實務上仍然很大程度上是分開的。本章借鑑了越來越多的學術著作，這些著作主張民族誌和機器學習可以有益地結合起來，特別是對於大型比較研究。具體而言，本文（a）說明了在某些類型的專案中將機器學習與定性實地研究結合使用的價值（和挑戰），（b）討論了最近的這方面的研究方法趨勢，（c）提供了說明從幾個大型專案中提取的工作流程的範例，以及（d）最後總結了實現實地方法和機器學習的生產性共同演化的路線圖。

##### **KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models**
2412.06071v1 by Fan Wang, Juyong Jiang, Chansung Park, Sunghun Kim, Jing Tang

The increasing sizes of large language models (LLMs) result in significant
computational overhead and memory usage when adapting these models to specific
tasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have
been devised to mitigate these challenges by training a small set of parameters
for the task-specific updates of the model weights. Among PEFT methods, LoRA
stands out for its simplicity and efficiency, inspiring the development of a
series of variants. However, LoRA and its successors disregard the knowledge
that is noisy or irrelevant to the targeted task, detrimentally impacting model
performance and leading to suboptimality. To address this limitation, we
introduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that
leverages singular value decomposition (SVD) with knowledge-aware singular
values to dynamically activate knowledge based on its relevance to the task at
hand. We conduct extensive experiments across a range of LLMs on tasks spanning
natural language understanding (NLU), generation (NLG), instruction following,
and commonsense reasoning. The experimental results demonstrate that KaSA
consistently outperforms FFT and 14 popular PEFT baselines across 16 benchmarks
and 4 synthetic datasets, underscoring our method's efficacy and adaptability.
The source code of our method is available at
https://github.com/juyongjiang/KaSA.

摘要：大型語言模型（LLM）規模不斷擴大，在將這些模型調整至特定任務或領域時，會造成顯著的運算負擔和記憶體使用量。各種參數高效微調（PEFT）方法已被設計出來，透過訓練一組小參數來針對模型權重的任務特定更新，以減輕這些挑戰。在 PEFT 方法中，LoRA 以其簡潔和效率脫穎而出，激發了一系列變體的開發。然而，LoRA 及其後繼者忽視了對目標任務有雜訊或無關的知識，對模型效能造成不利影響，並導致次最佳化。為了解決這個限制，我們引入了知識感知奇異值適應（KaSA），這是一種 PEFT 方法，它利用奇異值分解（SVD）和知識感知奇異值，根據其與手邊任務相關性動態啟用知識。我們針對一系列 LLM 進行廣泛的實驗，涵蓋自然語言理解（NLU）、生成（NLG）、指令遵循和常識推理。實驗結果表明，在 16 個基準和 4 個合成資料集上，KaSA 持續優於 FFT 和 14 個流行的 PEFT 基準，突顯了我們方法的有效性和適應性。我們方法的原始碼可在 https://github.com/juyongjiang/KaSA 取得。

##### **Curse of Attention: A Kernel-Based Perspective for Why Transformers Fail to Generalize on Time Series Forecasting and Beyond**
2412.06061v1 by Yekun Ke, Yingyu Liang, Zhenmei Shi, Zhao Song, Chiwun Yang

The application of transformer-based models on time series forecasting (TSF)
tasks has long been popular to study. However, many of these works fail to beat
the simple linear residual model, and the theoretical understanding of this
issue is still limited. In this work, we propose the first theoretical
explanation of the inefficiency of transformers on TSF tasks. We attribute the
mechanism behind it to {\bf Asymmetric Learning} in training attention
networks. When the sign of the previous step is inconsistent with the sign of
the current step in the next-step-prediction time series, attention fails to
learn the residual features. This makes it difficult to generalize on
out-of-distribution (OOD) data, especially on the sign-inconsistent
next-step-prediction data, with the same representation pattern, whereas a
linear residual network could easily accomplish it. We hope our theoretical
insights provide important necessary conditions for designing the expressive
and efficient transformer-based architecture for practitioners.

摘要：Transformer基礎模型在時間序列預測 (TSF) 任務上的應用一直是熱門的研究主題。然而，許多這類研究都無法超越簡單的線性殘差模型，且對此問題的理論理解仍十分有限。在這項研究中，我們提出了Transformer在 TSF 任務中效率不彰的第一個理論解釋。我們將其背後的機制歸因於訓練注意力網路中的「不對稱學習」。當前一步的符號與時間序列中下一步預測的符號不一致時，注意力便無法學習殘差特徵。這使得在分佈外 (OOD) 資料中進行概化變得困難，特別是在符號不一致的下一步預測資料中，具有相同的表示模式，而線性殘差網路則可以輕鬆達成。我們希望我們的理論見解能為實務工作者設計表現力強且高效的Transformer基礎架構提供重要的必要條件。

##### **Steering Large Language Models to Evaluate and Amplify Creativity**
2412.06060v1 by Matthew Lyle Olson, Neale Ratzlaff, Musashi Hinck, Shao-yen Tseng, Vasudev Lal

Although capable of generating creative text, Large Language Models (LLMs)
are poor judges of what constitutes "creativity". In this work, we show that we
can leverage this knowledge of how to write creatively in order to better judge
what is creative. We take a mechanistic approach that extracts differences in
the internal states of an LLM when prompted to respond "boringly" or
"creatively" to provide a robust measure of creativity that corresponds
strongly with human judgment. We also show these internal state differences can
be applied to enhance the creativity of generated text at inference time.

摘要：儘管大型語言模型 (LLM) 有能力產生有創意的文字，
但對於構成「創意」的要素卻判斷得很差。在本文中，我們展示了我們
可以利用這種如何以有創意的方式寫作的知識，以便更好地判斷什麼是有創意的。我們採取一種機械化的方法，提取 LLM 在收到「無聊」或
「有創意」的提示時，其內部狀態的差異，以提供與人類判斷高度相符的穩健創意衡量標準。我們也展示這些內部狀態差異可以在推論時應用於增強所產生文字的創意。

##### **Cloud Platforms for Developing Generative AI Solutions: A Scoping Review of Tools and Services**
2412.06044v1 by Dhavalkumar Patel, Ganesh Raut, Satya Narayan Cheetirala, Girish N Nadkarni, Robert Freeman, Benjamin S. Glicksberg, Eyal Klang, Prem Timsina

Generative AI is transforming enterprise application development by enabling
machines to create content, code, and designs. These models, however, demand
substantial computational power and data management. Cloud computing addresses
these needs by offering infrastructure to train, deploy, and scale generative
AI models. This review examines cloud services for generative AI, focusing on
key providers like Amazon Web Services (AWS), Microsoft Azure, Google Cloud,
IBM Cloud, Oracle Cloud, and Alibaba Cloud. It compares their strengths,
weaknesses, and impact on enterprise growth. We explore the role of
high-performance computing (HPC), serverless architectures, edge computing, and
storage in supporting generative AI. We also highlight the significance of data
management, networking, and AI-specific tools in building and deploying these
models. Additionally, the review addresses security concerns, including data
privacy, compliance, and AI model protection. It assesses the performance and
cost efficiency of various cloud providers and presents case studies from
healthcare, finance, and entertainment. We conclude by discussing challenges
and future directions, such as technical hurdles, vendor lock-in,
sustainability, and regulatory issues. Put together, this work can serve as a
guide for practitioners and researchers looking to adopt cloud-based generative
AI solutions, serving as a valuable guide to navigating the intricacies of this
evolving field.

摘要：生成式 AI 透過讓機器建立內容、程式碼和設計而轉變了企業應用程式開發。然而，這些模型需要大量的運算能力和資料管理。雲端運算透過提供訓練、部署和擴充生成式 AI 模型的基礎架構來滿足這些需求。此評論探討了生成式 AI 的雲端服務，重點關注 Amazon Web Services (AWS)、Microsoft Azure、Google Cloud、IBM Cloud、Oracle Cloud 和 Alibaba Cloud 等主要供應商。它比較了他們的優勢、劣勢和對企業成長的影響。我們探討了高性能運算 (HPC)、無伺服器架構、邊緣運算和儲存在支援生成式 AI 中的角色。我們也強調了資料管理、網路和 AI 專用工具在建立和部署這些模型中的重要性。此外，此評論也探討了安全問題，包括資料隱私、合規性和 AI 模型保護。它評估了各種雲端供應商的效能和成本效益，並提供來自醫療保健、金融和娛樂產業的案例研究。我們最後討論了挑戰和未來方向，例如技術難題、供應商鎖定、永續性和法規問題。總之，這項工作可以作為一個指南，供實務工作者和研究人員在採用基於雲端的生成式 AI 解决方案時參考，並作為了解這個不斷演進的領域錯綜複雜之處的寶貴指南。

##### **Can Generative AI Solve Your In-Context Learning Problem? A Martingale Perspective**
2412.06033v1 by Andrew Jesson, Nicolas Beltran-Velez, David Blei

This work is about estimating when a conditional generative model (CGM) can
solve an in-context learning (ICL) problem. An in-context learning (ICL)
problem comprises a CGM, a dataset, and a prediction task. The CGM could be a
multi-modal foundation model; the dataset, a collection of patient histories,
test results, and recorded diagnoses; and the prediction task to communicate a
diagnosis to a new patient. A Bayesian interpretation of ICL assumes that the
CGM computes a posterior predictive distribution over an unknown Bayesian model
defining a joint distribution over latent explanations and observable data.
From this perspective, Bayesian model criticism is a reasonable approach to
assess the suitability of a given CGM for an ICL problem. However, such
approaches -- like posterior predictive checks (PPCs) -- often assume that we
can sample from the likelihood and posterior defined by the Bayesian model,
which are not explicitly given for contemporary CGMs. To address this, we show
when ancestral sampling from the predictive distribution of a CGM is equivalent
to sampling datasets from the posterior predictive of the assumed Bayesian
model. Then we develop the generative predictive $p$-value, which enables PPCs
and their cousins for contemporary CGMs. The generative predictive $p$-value
can then be used in a statistical decision procedure to determine when the
model is appropriate for an ICL problem. Our method only requires generating
queries and responses from a CGM and evaluating its response log probability.
We empirically evaluate our method on synthetic tabular, imaging, and natural
language ICL tasks using large language models.

摘要：這項工作旨在估計條件生成模型 (CGM) 何時能
解決情境學習 (ICL) 問題。情境學習 (ICL)
問題包含 CGM、資料集和預測任務。CGM 可能是一個
多模態基礎模型；資料集，收集病歷、
檢驗結果和記錄診斷；以及預測任務，以傳達
診斷給新患者。ICL 的貝氏詮釋假設 CGM 計算
一個後驗預測分佈，在一個未知的貝氏模型上
定義一個潛在解釋和可觀察資料的聯合分佈。
從這個角度來看，貝氏模型批評是一種合理的途徑
評估給定的 CGM 是否適合 ICL 問題。然而，這樣的
方法（如後驗預測檢查 (PPC)) 通常假設我們
可以從貝氏模型定義的可能性和後驗中取樣，
這對於當代 CGM 來說並未明確給出。為了解決這個問題，我們展示
當 CGM 預測分佈的祖先取樣等於從假設的貝氏模型的後驗預測中取樣資料集時。然後我們開發生成預測 $p$-值，這使得 PPC 和它們在當代 CGM 中的表親成為可能。生成預測 $p$-值
然後可以在統計決策程序中使用，以確定模型何時
適合 ICL 問題。我們的模型只需要從 CGM 生成
查詢和回應，並評估其回應日誌機率。
我們使用大型語言模型對合成表格、影像和自然
語言 ICL 任務實證評估我們的模型。

##### **Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**
2412.06018v1 by Akshat Choube, Rahul Majethia, Sohini Bhattacharya, Vedant Das Swain, Jiachen Li, Varun Mishra

Longitudinal passive sensing studies for health and behavior outcomes often
have missing and incomplete data. Handling missing data effectively is thus a
critical data processing and modeling step. Our formative interviews with
researchers working in longitudinal health and behavior passive sensing
revealed a recurring theme: most researchers consider imputation a low-priority
step in their analysis and inference pipeline, opting to use simple and
off-the-shelf imputation strategies without comprehensively evaluating its
impact on study outcomes. Through this paper, we call attention to the
importance of imputation. Using publicly available passive sensing datasets for
depression, we show that prioritizing imputation can significantly impact the
study outcomes -- with our proposed imputation strategies resulting in up to
31% improvement in AUROC to predict depression over the original imputation
strategy. We conclude by discussing the challenges and opportunities with
effective imputation in longitudinal sensing studies.

摘要：縱向被動感測研究對於健康和行為結果常常有缺失和不完整的資料。有效處理缺失資料因此是資料處理和建模的重要步驟。我們與從事縱向健康和行為被動感測的研究人員進行的形成性訪談揭露了一個反覆出現的主題：大多數研究人員認為內插是其分析和推論流程中優先順序較低的一個步驟，選擇使用簡單且現成的內插策略，而沒有全面評估其對研究結果的影響。透過這篇論文，我們呼籲重視內插。使用公開的被動感測資料集進行憂鬱症研究，我們證明優先考慮內插會對研究結果產生重大影響——我們提出的內插策略使 AUROC 預測憂鬱症的能力比原始內插策略提高了 31%。最後，我們討論了在縱向感測研究中有效內插的挑戰和機會。

##### **Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation**
2412.06016v1 by Hyeonho Jeong, Chun-Hao Paul Huang, Jong Chul Ye, Niloy Mitra, Duygu Ceylan

While recent foundational video generators produce visually rich output, they
still struggle with appearance drift, where objects gradually degrade or change
inconsistently across frames, breaking visual coherence. We hypothesize that
this is because there is no explicit supervision in terms of spatial tracking
at the feature level. We propose Track4Gen, a spatially aware video generator
that combines video diffusion loss with point tracking across frames, providing
enhanced spatial supervision on the diffusion features. Track4Gen merges the
video generation and point tracking tasks into a single network by making
minimal changes to existing video generation architectures. Using Stable Video
Diffusion as a backbone, Track4Gen demonstrates that it is possible to unify
video generation and point tracking, which are typically handled as separate
tasks. Our extensive evaluations show that Track4Gen effectively reduces
appearance drift, resulting in temporally stable and visually coherent video
generation. Project page: hyeonho99.github.io/Track4Gen

摘要：儘管最近基礎影片產生器可產生視覺豐富的輸出，但它們仍受外觀漂移所苦，其中物件會逐漸劣化或在各個畫格中不一致地改變，破壞視覺一致性。我們假設這是因為在特徵層級沒有明確的空間追蹤監督。我們提出 Track4Gen，一種具有空間感知的影片產生器，它結合影片擴散損失與各個畫格的點追蹤，在擴散特徵上提供增強的空間監督。Track4Gen 將影片產生與點追蹤任務合併成單一網路，對現有的影片產生架構進行極小的變更。Track4Gen 使用 Stable Video Diffusion 作為主幹，證明了統一影片產生與點追蹤是可行的，而這兩個任務通常被視為獨立的任務。我們廣泛的評估顯示，Track4Gen 有效地減少外觀漂移，產生時間穩定且視覺一致的影片。專案頁面：hyeonho99.github.io/Track4Gen

##### **1-800-SHARED-TASKS at RegNLP: Lexical Reranking of Semantic Retrieval (LeSeR) for Regulatory Question Answering**
2412.06009v1 by Jebish Purbey, Drishti Sharma, Siddhant Gupta, Khawaja Murad, Siddartha Pullakhandam, Ram Mohan Rao Kadiyala

This paper presents the system description of our entry for the COLING 2025
RegNLP RIRAG (Regulatory Information Retrieval and Answer Generation)
challenge, focusing on leveraging advanced information retrieval and answer
generation techniques in regulatory domains. We experimented with a combination
of embedding models, including Stella, BGE, CDE, and Mpnet, and leveraged
fine-tuning and reranking for retrieving relevant documents in top ranks. We
utilized a novel approach, LeSeR, which achieved competitive results with a
recall@10 of 0.8201 and map@10 of 0.6655 for retrievals. This work highlights
the transformative potential of natural language processing techniques in
regulatory applications, offering insights into their capabilities for
implementing a retrieval augmented generation system while identifying areas
for future improvement in robustness and domain adaptation.

摘要：這篇論文提出我們在 COLING 2025 RegNLP RIRAG（法規資訊檢索與答案生成）挑戰中的系統描述，重點在於在法規領域中利用進階的資訊檢索與答案生成技術。我們實驗了嵌入模型的組合，包括 Stella、BGE、CDE 和 Mpnet，並利用微調和重新排序來檢索頂級排名中的相關文件。我們利用了一種新穎的方法 LeSeR，在檢索中取得了具有競爭力的結果，recall@10 為 0.8201，map@10 為 0.6655。這項工作突顯了自然語言處理技術在法規應用中的轉型潛力，提供了對其在實作檢索增強生成系統時的能力的見解，同時也找出在穩健性和領域適應性方面未來改進的領域。

##### **Does RLHF Scale? Exploring the Impacts From Data, Model, and Method**
2412.06000v1 by Zhenyu Hou, Pengfan Du, Yilin Niu, Zhengxiao Du, Aohan Zeng, Xiao Liu, Minlie Huang, Hongning Wang, Jie Tang, Yuxiao Dong

This study explores the scaling properties of Reinforcement Learning from
Human Feedback (RLHF) in Large Language Models (LLMs). Although RLHF is
considered an important step in post-training of LLMs, its scaling potential is
still largely unknown. We systematically analyze key components in the RLHF
framework--model size, data composition, and inference budget--and their
impacts on performance. Our findings show that increasing data diversity and
volume improves reward model performance, helping process-supervision models
scale better. For policy training, more response samples per prompt boost
performance initially but quickly plateau. And larger reward models offer
modest gains in policy training. In addition, larger policy models benefit less
from RLHF with a fixed reward model. Overall, RLHF scales less efficiently than
pretraining, with diminishing returns from additional computational resources.
Based on these observations, we propose strategies to optimize RLHF performance
within computational limits.

摘要：本研究探討了大型語言模型 (LLM) 中強化學習來自人類回饋 (RLHF) 的擴充屬性。雖然 RLHF 被認為是 LLM 後訓練的重要步驟，但其擴充潛力仍然很大程度上未知。我們系統性地分析 RLHF 框架中的關鍵組成部分——模型大小、資料組成和推論預算——及其對效能的影響。我們的研究結果顯示，增加資料的多樣性和數量可以提升獎勵模型效能，有助於流程監督模型更好地擴充。對於策略訓練，每個提示的更多回應範例會在初期提升效能，但很快就會達到平穩期。而較大的獎勵模型在策略訓練中提供了適度的增益。此外，較大的策略模型從具有固定獎勵模型的 RLHF 獲益較少。總的來說，RLHF 的擴充效率低於預訓練，額外的運算資源會帶來遞減的回報。根據這些觀察，我們提出了在運算限制內最佳化 RLHF 效能的策略。

##### **PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations**
2412.05994v1 by Namgyu Kang, Jaemin Oh, Youngjoon Hong, Eunbyung Park

The approximation of Partial Differential Equations (PDEs) using neural
networks has seen significant advancements through Physics-Informed Neural
Networks (PINNs). Despite their straightforward optimization framework and
flexibility in implementing various PDEs, PINNs often suffer from limited
accuracy due to the spectral bias of Multi-Layer Perceptrons (MLPs), which
struggle to effectively learn high-frequency and non-linear components.
Recently, parametric mesh representations in combination with neural networks
have been investigated as a promising approach to eliminate the inductive
biases of neural networks. However, they usually require very high-resolution
grids and a large number of collocation points to achieve high accuracy while
avoiding overfitting issues. In addition, the fixed positions of the mesh
parameters restrict their flexibility, making it challenging to accurately
approximate complex PDEs. To overcome these limitations, we propose
Physics-Informed Gaussians (PIGs), which combine feature embeddings using
Gaussian functions with a lightweight neural network. Our approach uses
trainable parameters for the mean and variance of each Gaussian, allowing for
dynamic adjustment of their positions and shapes during training. This
adaptability enables our model to optimally approximate PDE solutions, unlike
models with fixed parameter positions. Furthermore, the proposed approach
maintains the same optimization framework used in PINNs, allowing us to benefit
from their excellent properties. Experimental results show the competitive
performance of our model across various PDEs, demonstrating its potential as a
robust tool for solving complex PDEs. Our project page is available at
https://namgyukang.github.io/Physics-Informed-Gaussians/

摘要：利用神经網路近似偏微分方程式 (PDE) 已透過物理資訊神經網路 (PINN) 看見顯著進步。儘管其最佳化架構簡單明瞭，且在實作各種 PDE 上具有彈性，但 PINN 卻常因多層感知器 (MLP) 的光譜偏差而導致精確度受限，難以有效學習高頻率與非線性元件。近期，已研究將參數網格表示法結合神經網路作為一種消除神經網路歸納偏差的策略。然而，它們通常需要極高解析度的網格和大量的配置點才能達成高精確度，同時避免過度擬合問題。此外，網格參數的固定位置限制了其彈性，使得精確近似複雜 PDE 充滿挑戰。為了解決這些限制，我們提出物理資訊高斯函數 (PIG)，它結合使用高斯函數與輕量級神經網路進行特徵嵌入。我們的策略使用可訓練參數作為每個高斯函數的平均值和變異數，允許在訓練期間動態調整其位置和形狀。這種適應性使我們的模型能夠最佳化近似 PDE 解，這與具有固定參數位置的模型不同。此外，建議的方法維持與 PINN 相同的最佳化架構，讓我們能夠受益於其優異的特性。實驗結果顯示了我們模型在各種 PDE 上的競爭力，證明其作為解決複雜 PDE 的強大工具的潛力。我們的專案頁面可於 https://namgyukang.github.io/Physics-Informed-Gaussians/ 取得。

##### **LVS-Net: A Lightweight Vessels Segmentation Network for Retinal Image Analysis**
2412.05968v1 by Mehwish Mehmood, Shahzaib Iqbal, Tariq Mahmood Khan, Ivor Spence, Muhammad Fahim

The analysis of retinal images for the diagnosis of various diseases is one
of the emerging areas of research. Recently, the research direction has been
inclined towards investigating several changes in retinal blood vessels in
subjects with many neurological disorders, including dementia. This research
focuses on detecting diseases early by improving the performance of models for
segmentation of retinal vessels with fewer parameters, which reduces
computational costs and supports faster processing. This paper presents a novel
lightweight encoder-decoder model that segments retinal vessels to improve the
efficiency of disease detection. It incorporates multi-scale convolutional
blocks in the encoder to accurately identify vessels of various sizes and
thicknesses. The bottleneck of the model integrates the Focal Modulation
Attention and Spatial Feature Refinement Blocks to refine and enhance essential
features for efficient segmentation. The decoder upsamples features and
integrates them with the corresponding feature in the encoder using skip
connections and the spatial feature refinement block at every upsampling stage
to enhance feature representation at various scales. The estimated computation
complexity of our proposed model is around 29.60 GFLOP with 0.71 million
parameters and 2.74 MB of memory size, and it is evaluated using public
datasets, that is, DRIVE, CHASE\_DB, and STARE. It outperforms existing models
with dice scores of 86.44\%, 84.22\%, and 87.88\%, respectively.

摘要：視網膜影像分析用於診斷各種疾病是新興的研究領域之一。最近，研究方向傾向於探討許多神經疾病（包括失智症）患者視網膜血管的各種變化。這項研究專注於透過改善視網膜血管分割模型的效能來及早偵測疾病，同時減少參數，以降低運算成本並支援更快速的處理。本文提出了一個新穎的輕量級編碼器-解碼器模型，用於分割視網膜血管以提高疾病偵測的效率。它在編碼器中結合了多尺度卷積區塊，以準確識別各種大小和厚度的血管。該模型的瓶頸整合了焦點調製注意力和空間特徵精化區塊，以精化和增強特徵，以進行有效的分割。解碼器對特徵進行上採樣，並在每個上採樣階段使用跳躍連接和空間特徵精化區塊將它們與編碼器中的對應特徵整合，以增強各種尺度的特徵表示。我們提出的模型的估計運算複雜度約為 29.60 GFLOP，參數為 0.71 百萬，記憶體大小為 2.74 MB，並使用公開的資料集（即 DRIVE、CHASE_DB 和 STARE）進行評估。它的骰子分數分別為 86.44%、84.22% 和 87.88%，優於現有模型。

##### **Language hooks: a modular framework for augmenting LLM reasoning that decouples tool usage from the model and its prompt**
2412.05967v1 by Damien de Mijolla, Wen Yang, Philippa Duckett, Christopher Frye, Mark Worrall

Prompting and fine-tuning have emerged as two competing paradigms for
augmenting language models with new capabilities, such as the use of tools.
Prompting approaches are quick to set up but rely on providing explicit
demonstrations of each tool's usage in the model's prompt, thus coupling tool
use to the task at hand and limiting generalisation. Fine-tuning removes the
need for task-specific demonstrations of tool usage at runtime; however, this
ties new capabilities to a single model, thus making already-heavier setup
costs a recurring expense. In this paper, we introduce language hooks, a novel
framework for augmenting language models with new capabilities that is
decoupled both from the model's task-specific prompt and from the model itself.
The language hook algorithm interleaves text generation by the base model with
the execution of modular programs that trigger conditionally based on the
existing text and the available capabilities. Upon triggering, programs may
call external tools, auxiliary language models (e.g. using tool specific
prompts), and modify the existing context. We benchmark our method against
state-of-the-art baselines, find that it outperforms task-aware approaches, and
demonstrate its ability to generalise to novel tasks.

摘要：提示和微调已成为两种竞争性的范例，用于增强语言模型的新功能，例如使用工具。提示方法设置起来很快，但依赖于在模型提示中明确演示每个工具的使用，从而将工具的使用与手头的任务相结合并限制概括。微调消除了在运行时对特定任务的工具使用演示的需要；然而，这将新功能与单个模型联系起来，从而使已经很重的设置成本成为经常性的开支。在本文中，我们介绍了语言钩子，这是一个新的框架，用于增强语言模型的新功能，它既与模型的任务特定提示又与模型本身分离。语言钩子算法将基本模型的文本生成与模块化程序的执行交织在一起，这些程序根据现有文本和可用功能有条件地触发。触发后，程序可以调用外部工具、辅助语言模型（例如，使用特定于工具的提示）并修改现有上下文。我们根据最先进的基准测试我们的方法，发现它优于任务感知方法，并展示了它推广到新任务的能力。

##### **A Cross-Validation Study of Turkish Sentiment Analysis Datasets and Tools**
2412.05964v1 by Şevval Çakıcı, Dilara Karaduman, Mehmet Akif Çırlan, Ali Hürriyetoğlu

In recent years, sentiment analysis has gained increasing significance,
prompting researchers to explore datasets in various languages, including
Turkish. However, the limited availability of Turkish datasets has led to their
multifaceted usage in different studies, yielding diverse outcomes. To overcome
this challenge, a rigorous review was conducted of research articles published
between 2012 and 2022. 31 studies were listed, and 23 Turkish datasets obtained
from publicly available sources and email requests used in these studies were
collected. We labeled these 31 studies using a taxonomy. We provide a map of
sentiment analysis datasets according to this taxonomy in Turkish over 10
years. Moreover, we run state-of-the-art sentiment analysis tools on these
datasets and analyzed performance across popular Turkish sentiment datasets. We
observed that the performance of the sentiment analysis tools significantly
depends on the characteristics of the target text. Our study fosters a more
nuanced understanding of sentiment analysis in the Turkish language.

摘要：近年來，情緒分析的重要性與日俱增，促使研究人員探索各種語言的資料集，包括土耳其語。然而，土耳其語資料集的可用性有限，導致它們在不同的研究中被多方面使用，產生了不同的結果。為了克服這個挑戰，對 2012 年至 2022 年間發表的期刊文章進行了嚴謹的回顧。列出了 31 項研究，並收集了這些研究中從公開來源和電子郵件請求中獲得的 23 個土耳其語資料集。我們使用分類法標記了這 31 項研究。我們提供了 10 年來根據此分類法在土耳其語中情緒分析資料集的對應表。此外，我們在這些資料集上執行最先進的情緒分析工具，並分析了在熱門土耳其語情緒資料集上的效能。我們觀察到，情緒分析工具的效能很大程度上取決於目標文字的特性。我們的研究促進了對土耳其語中情緒分析的更細緻理解。

