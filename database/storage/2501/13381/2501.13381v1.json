{"2501.13381": {"publish_time": "2025-01-23", "title": "Do as We Do, Not as You Think: the Conformity of Large Language Models", "paper_summary": "Recent advancements in large language models (LLMs) revolutionize the field\nof intelligent agents, enabling collaborative multi-agent systems capable of\ntackling complex problems across various domains. However, the potential of\nconformity within these systems, analogous to phenomena like conformity bias\nand groupthink in human group dynamics, remains largely unexplored, raising\nconcerns about their collective problem-solving capabilities and possible\nethical implications. This paper presents a comprehensive study on conformity\nin LLM-driven multi-agent systems, focusing on three aspects: the existence of\nconformity, the factors influencing conformity, and potential mitigation\nstrategies. In particular, we introduce BenchForm, a new conformity-oriented\nbenchmark, featuring reasoning-intensive tasks and five distinct interaction\nprotocols designed to probe LLMs' behavior in collaborative scenarios. Several\nrepresentative LLMs are evaluated on BenchForm, using metrics such as\nconformity rate and independence rate to quantify conformity's impact. Our\nanalysis delves into factors influencing conformity, including interaction time\nand majority size, and examines how the subject agent rationalizes its\nconforming behavior. Furthermore, we explore two strategies to mitigate\nconformity effects, i.e., developing enhanced personas and implementing a\nreflection mechanism. Several interesting findings regarding LLMs' conformity\nare derived from empirical results and case studies. We hope that these\ninsights can pave the way for more robust and ethically-aligned collaborative\nAI systems. Our benchmark and code are available at BenchForm.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u5fb9\u5e95\u9769\u65b0\u4e86\u667a\u6167\u4ee3\u7406\u9818\u57df\uff0c\u4fc3\u6210\u4e86\u5354\u4f5c\u5f0f\u591a\u91cd\u4ee3\u7406\u7cfb\u7d71\uff0c\u80fd\u5920\u89e3\u6c7a\u8de8\u8d8a\u5404\u500b\u9818\u57df\u7684\u8907\u96dc\u554f\u984c\u3002\u7136\u800c\uff0c\u9019\u4e9b\u7cfb\u7d71\u5167\u90e8\u4e00\u81f4\u6027\u7684\u6f5b\u529b\uff0c\u985e\u4f3c\u65bc\u4eba\u985e\u7fa4\u9ad4\u52d5\u614b\u4e2d\u7684\u4e00\u81f4\u6027\u504f\u8aa4\u548c\u5718\u9ad4\u8ff7\u601d\u7b49\u73fe\u8c61\uff0c\u4ecd\u672a\u88ab\u5ee3\u6cdb\u63a2\u8a0e\uff0c\u5f15\u767c\u4e86\u5c0d\u5176\u96c6\u9ad4\u554f\u984c\u89e3\u6c7a\u80fd\u529b\u548c\u6f5b\u5728\u9053\u5fb7\u5f71\u97ff\u7684\u64d4\u6182\u3002\u672c\u6587\u91dd\u5c0d LLM \u9a45\u52d5\u7684\u591a\u91cd\u4ee3\u7406\u7cfb\u7d71\u4e2d\u7684\u4e00\u81f4\u6027\u9032\u884c\u5168\u9762\u7814\u7a76\uff0c\u91cd\u9ede\u95dc\u6ce8\u4e09\u500b\u9762\u5411\uff1a\u4e00\u81f4\u6027\u7684\u5b58\u5728\u3001\u5f71\u97ff\u4e00\u81f4\u6027\u7684\u56e0\u7d20\u4ee5\u53ca\u6f5b\u5728\u7684\u7de9\u89e3\u7b56\u7565\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u5f15\u5165\u4e86 BenchForm\uff0c\u4e00\u500b\u65b0\u7684\u4ee5\u4e00\u81f4\u6027\u70ba\u5c0e\u5411\u7684\u57fa\u6e96\uff0c\u5177\u5099\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52d9\u548c\u4e94\u7a2e\u4e0d\u540c\u7684\u4e92\u52d5\u5354\u5b9a\uff0c\u65e8\u5728\u63a2\u8a0e LLM \u5728\u5354\u4f5c\u5834\u666f\u4e2d\u7684\u884c\u70ba\u3002\u4f7f\u7528\u4e00\u81f4\u6027\u6bd4\u7387\u548c\u7368\u7acb\u6027\u6bd4\u7387\u7b49\u6307\u6a19\u5c0d BenchForm \u4e0a\u7684\u5e7e\u500b\u5177\u4ee3\u8868\u6027\u7684 LLM \u9032\u884c\u8a55\u4f30\uff0c\u4ee5\u91cf\u5316\u4e00\u81f4\u6027\u7684\u5f71\u97ff\u3002\u6211\u5011\u7684\u5206\u6790\u6df1\u5165\u63a2\u8a0e\u4e86\u5f71\u97ff\u4e00\u81f4\u6027\u7684\u56e0\u7d20\uff0c\u5305\u62ec\u4e92\u52d5\u6642\u9593\u548c\u591a\u6578\u898f\u6a21\uff0c\u4e26\u63a2\u8a0e\u4e86\u4e3b\u9ad4\u4ee3\u7406\u5982\u4f55\u5408\u7406\u5316\u5176\u4e00\u81f4\u6027\u884c\u70ba\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u6e1b\u8f15\u4e00\u81f4\u6027\u5f71\u97ff\u7684\u5169\u7a2e\u7b56\u7565\uff0c\u5373\u958b\u767c\u589e\u5f37\u7684\u89d2\u8272\u548c\u5be6\u65bd\u53cd\u601d\u6a5f\u5236\u3002\u5f9e\u5be6\u8b49\u7d50\u679c\u548c\u6848\u4f8b\u7814\u7a76\u4e2d\u5f97\u51fa\u4e86\u5e7e\u500b\u95dc\u65bc LLM \u4e00\u81f4\u6027\u7684\u6709\u8da3\u767c\u73fe\u3002\u6211\u5011\u5e0c\u671b\u9019\u4e9b\u898b\u89e3\u80fd\u70ba\u66f4\u5f37\u5927\u4e14\u7b26\u5408\u9053\u5fb7\u7684\u5354\u4f5c\u5f0f AI \u7cfb\u7d71\u92ea\u8def\u3002\u6211\u5011\u7684\u57fa\u6e96\u548c\u7a0b\u5f0f\u78bc\u53ef\u5728 BenchForm \u53d6\u5f97\u3002", "author": "Zhiyuan Weng et.al.", "authors": "Zhiyuan Weng, Guikun Chen, Wenguan Wang", "id": "2501.13381v1", "paper_url": "http://arxiv.org/abs/2501.13381v1", "repo": "https://github.com/zhiyuan-weng/benchform"}}