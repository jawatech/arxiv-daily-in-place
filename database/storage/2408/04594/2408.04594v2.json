{"2408.04594": {"publish_time": "2024-08-08", "title": "Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models", "paper_summary": "High-performance Multimodal Large Language Models (MLLMs) rely heavily on\ndata quality. This study introduces a novel dataset named Img-Diff, designed to\nenhance fine-grained image recognition in MLLMs by leveraging insights from\ncontrastive learning and image difference captioning. By analyzing object\ndifferences between similar images, we challenge models to identify both\nmatching and distinct components. We utilize the Stable-Diffusion-XL model and\nadvanced image editing techniques to create pairs of similar images that\nhighlight object replacements. Our methodology includes a Difference Area\nGenerator for object differences identifying, followed by a Difference Captions\nGenerator for detailed difference descriptions. The result is a relatively\nsmall but high-quality dataset of \"object replacement\" samples. We use the the\nproposed dataset to finetune state-of-the-art (SOTA) MLLMs such as MGM-7B,\nyielding comprehensive improvements of performance scores over SOTA models that\ntrained with larger-scale datasets, in numerous image difference and Visual\nQuestion Answering tasks. For instance, our trained models notably surpass the\nSOTA models GPT-4V and Gemini on the MMVP benchmark. Besides, we investigate\nalternative methods for generating image difference data through \"object\nremoval\" and conduct a thorough evaluation to confirm the dataset's diversity,\nquality, and robustness, presenting several insights on the synthesis of such a\ncontrastive dataset. To encourage further research and advance the field of\nmultimodal data synthesis and enhancement of MLLMs' fundamental capabilities\nfor image understanding, we release our codes and dataset at\nhttps://github.com/modelscope/data-juicer/tree/ImgDiff.", "paper_summary_zh": "\u9ad8\u6027\u80fd\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b (MLLM) \u4e25\u91cd\u4f9d\u8d56\u6570\u636e\u8d28\u91cf\u3002\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3a Img-Diff \u7684\u65b0\u6570\u636e\u96c6\uff0c\u65e8\u5728\u901a\u8fc7\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u548c\u56fe\u50cf\u5dee\u5f02\u63cf\u8ff0\u4e2d\u7684\u89c1\u89e3\u6765\u589e\u5f3a MLLM \u4e2d\u7684\u7ec6\u7c92\u5ea6\u56fe\u50cf\u8bc6\u522b\u3002\u901a\u8fc7\u5206\u6790\u7c7b\u4f3c\u56fe\u50cf\u4e4b\u95f4\u7684\u5bf9\u8c61\u5dee\u5f02\uff0c\u6211\u4eec\u6311\u6218\u6a21\u578b\u8bc6\u522b\u5339\u914d\u548c\u4e0d\u540c\u7684\u7ec4\u4ef6\u3002\u6211\u4eec\u5229\u7528 Stable-Diffusion-XL \u6a21\u578b\u548c\u9ad8\u7ea7\u56fe\u50cf\u7f16\u8f91\u6280\u672f\u6765\u521b\u5efa\u6210\u5bf9\u7684\u76f8\u4f3c\u56fe\u50cf\uff0c\u4ee5\u7a81\u51fa\u5bf9\u8c61\u66ff\u6362\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5305\u62ec\u4e00\u4e2a\u7528\u4e8e\u8bc6\u522b\u5bf9\u8c61\u5dee\u5f02\u7684\u5dee\u5f02\u533a\u57df\u751f\u6210\u5668\uff0c\u7136\u540e\u662f\u4e00\u4e2a\u7528\u4e8e\u8be6\u7ec6\u5dee\u5f02\u63cf\u8ff0\u7684\u5dee\u5f02\u63cf\u8ff0\u751f\u6210\u5668\u3002\u7ed3\u679c\u662f\u4e00\u4e2a\u76f8\u5bf9\u8f83\u5c0f\u4f46\u9ad8\u8d28\u91cf\u7684\u201c\u5bf9\u8c61\u66ff\u6362\u201d\u6837\u672c\u6570\u636e\u96c6\u3002\u6211\u4eec\u4f7f\u7528\u6240\u63d0\u51fa\u7684\u6570\u636e\u96c6\u5bf9\u6700\u5148\u8fdb (SOTA) MLLM\uff08\u4f8b\u5982 MGM-7B\uff09\u8fdb\u884c\u5fae\u8c03\uff0c\u5728\u4f17\u591a\u56fe\u50cf\u5dee\u5f02\u548c\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u4ea7\u751f\u6bd4\u4f7f\u7528\u66f4\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u7684 SOTA \u6a21\u578b\u66f4\u5168\u9762\u7684\u6027\u80fd\u5f97\u5206\u6539\u8fdb\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u8bad\u7ec3\u7684\u6a21\u578b\u5728 MMVP \u57fa\u51c6\u4e0a\u660e\u663e\u8d85\u8fc7\u4e86 SOTA \u6a21\u578b GPT-4V \u548c Gemini\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u901a\u8fc7\u201c\u5bf9\u8c61\u79fb\u9664\u201d\u751f\u6210\u56fe\u50cf\u5dee\u5f02\u6570\u636e\u7684\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u5f7b\u5e95\u7684\u8bc4\u4f30\u4ee5\u786e\u8ba4\u6570\u636e\u96c6\u7684\u591a\u6837\u6027\u3001\u8d28\u91cf\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5bf9\u8fd9\u79cd\u5bf9\u6bd4\u6570\u636e\u96c6\u5408\u6210\u7684\u82e5\u5e72\u89c1\u89e3\u3002\u4e3a\u4e86\u9f13\u52b1\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u548c\u63a8\u8fdb\u591a\u6a21\u6001\u6570\u636e\u5408\u6210\u548c\u589e\u5f3a MLLM \u7684\u56fe\u50cf\u7406\u89e3\u57fa\u672c\u80fd\u529b\u7684\u9886\u57df\uff0c\u6211\u4eec\u5728 https://github.com/modelscope/data-juicer/tree/ImgDiff \u4e0a\u53d1\u5e03\u4e86\u6211\u4eec\u7684\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002", "author": "Qirui Jiao et.al.", "authors": "Qirui Jiao, Daoyuan Chen, Yilun Huang, Yaliang Li, Ying Shen", "id": "2408.04594v2", "paper_url": "http://arxiv.org/abs/2408.04594v2", "repo": "https://github.com/modelscope/data-juicer"}}