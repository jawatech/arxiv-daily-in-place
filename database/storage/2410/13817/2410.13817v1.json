{"2410.13817": {"publish_time": "2024-10-17", "title": "Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation", "paper_summary": "Reinforcement learning (RL) often necessitates a meticulous Markov Decision\nProcess (MDP) design tailored to each task. This work aims to address this\nchallenge by proposing a systematic approach to behavior synthesis and control\nfor multi-contact loco-manipulation tasks, such as navigating spring-loaded\ndoors and manipulating heavy dishwashers. We define a task-independent MDP to\ntrain RL policies using only a single demonstration per task generated from a\nmodel-based trajectory optimizer. Our approach incorporates an adaptive phase\ndynamics formulation to robustly track the demonstrations while accommodating\ndynamic uncertainties and external disturbances. We compare our method against\nprior motion imitation RL works and show that the learned policies achieve\nhigher success rates across all considered tasks. These policies learn recovery\nmaneuvers that are not present in the demonstration, such as re-grasping\nobjects during execution or dealing with slippages. Finally, we successfully\ntransfer the policies to a real robot, demonstrating the practical viability of\nour approach.", "paper_summary_zh": "\u5f37\u5316\u5b78\u7fd2 (RL) \u901a\u5e38\u9700\u8981\u91dd\u5c0d\u6bcf\u9805\u4efb\u52d9\u91cf\u8eab\u6253\u9020\u7cbe\u5bc6\u7684\u99ac\u53ef\u592b\u6c7a\u7b56\u904e\u7a0b (MDP) \u8a2d\u8a08\u3002\u9019\u9805\u5de5\u4f5c\u65e8\u5728\u900f\u904e\u63d0\u51fa\u884c\u70ba\u5408\u6210\u548c\u63a7\u5236\u7684\u591a\u63a5\u89f8\u5f0f\u79fb\u52d5\u64cd\u4f5c\u4efb\u52d9\u7cfb\u7d71\u5316\u65b9\u6cd5\u4f86\u89e3\u6c7a\u9019\u500b\u6311\u6230\uff0c\u4f8b\u5982\u5c0e\u822a\u5f48\u7c27\u5f0f\u9580\u548c\u64cd\u4f5c\u91cd\u578b\u6d17\u7897\u6a5f\u3002\u6211\u5011\u5b9a\u7fa9\u4e86\u4e00\u500b\u8207\u4efb\u52d9\u7121\u95dc\u7684 MDP\uff0c\u4ee5\u50c5\u4f7f\u7528\u5f9e\u57fa\u65bc\u6a21\u578b\u7684\u8ecc\u8de1\u512a\u5316\u5668\u7522\u751f\u7684\u6bcf\u500b\u4efb\u52d9\u7684\u55ae\u4e00\u793a\u7bc4\u4f86\u8a13\u7df4 RL \u653f\u7b56\u3002\u6211\u5011\u7684\u505a\u6cd5\u7d50\u5408\u4e86\u4e00\u500b\u81ea\u9069\u61c9\u76f8\u4f4d\u52d5\u614b\u516c\u5f0f\uff0c\u4ee5\u5728\u9069\u61c9\u52d5\u614b\u4e0d\u78ba\u5b9a\u6027\u548c\u5916\u90e8\u5e72\u64fe\u7684\u540c\u6642\uff0c\u7a69\u5065\u5730\u8ffd\u8e64\u793a\u7bc4\u3002\u6211\u5011\u5c07\u6211\u5011\u7684\u65b9\u6cd5\u8207\u5148\u524d\u7684\u52d5\u4f5c\u6a21\u4eff RL \u5de5\u4f5c\u9032\u884c\u6bd4\u8f03\uff0c\u4e26\u8b49\u660e\u6240\u5b78\u7fd2\u7684\u653f\u7b56\u5728\u6240\u6709\u8003\u616e\u7684\u4efb\u52d9\u4e2d\u90fd\u9054\u5230\u4e86\u66f4\u9ad8\u7684\u6210\u529f\u7387\u3002\u9019\u4e9b\u653f\u7b56\u5b78\u7fd2\u4e86\u793a\u7bc4\u4e2d\u4e0d\u5b58\u5728\u7684\u6062\u5fa9\u52d5\u4f5c\uff0c\u4f8b\u5982\u5728\u57f7\u884c\u904e\u7a0b\u4e2d\u91cd\u65b0\u6293\u53d6\u7269\u9ad4\u6216\u8655\u7406\u6ed1\u52d5\u3002\u6700\u5f8c\uff0c\u6211\u5011\u6210\u529f\u5730\u5c07\u9019\u4e9b\u653f\u7b56\u8f49\u79fb\u5230\u771f\u5be6\u6a5f\u5668\u4eba\u4e0a\uff0c\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u5be6\u7528\u53ef\u884c\u6027\u3002", "author": "Jean-Pierre Sleiman et.al.", "authors": "Jean-Pierre Sleiman, Mayank Mittal, Marco Hutter", "id": "2410.13817v1", "paper_url": "http://arxiv.org/abs/2410.13817v1", "repo": "null"}}