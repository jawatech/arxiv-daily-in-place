{"2408.09621": {"publish_time": "2024-08-19", "title": "Refining Packing and Shuffling Strategies for Enhanced Performance in Generative Language Models", "paper_summary": "Packing and shuffling tokens is a common practice in training auto-regressive\nlanguage models (LMs) to prevent overfitting and improve efficiency. Typically\ndocuments are concatenated to chunks of maximum sequence length (MSL) and then\nshuffled. However setting the atom size, the length for each data chunk\naccompanied by random shuffling, to MSL may lead to contextual incoherence due\nto tokens from different documents being packed into the same chunk. An\nalternative approach is to utilize padding, another common data packing\nstrategy, to avoid contextual incoherence by only including one document in\neach shuffled chunk. To optimize both packing strategies (concatenation vs\npadding), we investigated the optimal atom size for shuffling and compared\ntheir performance and efficiency. We found that matching atom size to MSL\noptimizes performance for both packing methods (concatenation and padding), and\npadding yields lower final perplexity (higher performance) than concatenation\nat the cost of more training steps and lower compute efficiency. This trade-off\ninforms the choice of packing methods in training language models.", "paper_summary_zh": "\u6253\u5305\u548c\u6d17\u724c\u6807\u8bb0\u662f\u8bad\u7ec3\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b (LM) \u4ee5\u9632\u6b62\u8fc7\u5ea6\u62df\u5408\u5e76\u63d0\u9ad8\u6548\u7387\u7684\u5e38\u89c1\u505a\u6cd5\u3002\u901a\u5e38\uff0c\u6587\u4ef6\u4f1a\u8fde\u63a5\u6210\u6700\u5927\u5e8f\u5217\u957f\u5ea6 (MSL) \u7684\u5757\uff0c\u7136\u540e\u6d17\u724c\u3002\u7136\u800c\uff0c\u5c06\u539f\u5b50\u5927\u5c0f\uff08\u6bcf\u4e2a\u6570\u636e\u5757\u7684\u957f\u5ea6\uff09\u4f34\u968f\u7740\u968f\u673a\u6d17\u724c\u8bbe\u7f6e\u4e3a MSL \u53ef\u80fd\u4f1a\u5bfc\u81f4\u4e0a\u4e0b\u6587\u4e0d\u8fde\u8d2f\uff0c\u56e0\u4e3a\u6765\u81ea\u4e0d\u540c\u6587\u4ef6\u7684\u6807\u8bb0\u88ab\u6253\u5305\u5230\u540c\u4e00\u4e2a\u5757\u4e2d\u3002\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u5229\u7528\u586b\u5145\uff08\u53e6\u4e00\u79cd\u5e38\u89c1\u7684\u6570\u636e\u6253\u5305\u7b56\u7565\uff09\u6765\u907f\u514d\u4e0a\u4e0b\u6587\u4e0d\u8fde\u8d2f\uff0c\u65b9\u6cd5\u662f\u5728\u6bcf\u4e2a\u6d17\u724c\u5757\u4e2d\u53ea\u5305\u542b\u4e00\u4e2a\u6587\u4ef6\u3002\u4e3a\u4e86\u4f18\u5316\u8fd9\u4e24\u79cd\u6253\u5305\u7b56\u7565\uff08\u8fde\u63a5\u4e0e\u586b\u5145\uff09\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u6d17\u724c\u7684\u6700\u4f73\u539f\u5b50\u5927\u5c0f\uff0c\u5e76\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u6027\u80fd\u548c\u6548\u7387\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u5c06\u539f\u5b50\u5927\u5c0f\u4e0e MSL \u5339\u914d\u53ef\u4ee5\u4f18\u5316\u4e24\u79cd\u6253\u5305\u65b9\u6cd5\uff08\u8fde\u63a5\u548c\u586b\u5145\uff09\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u586b\u5145\u6bd4\u8fde\u63a5\u4ea7\u751f\u66f4\u4f4e\u7684\u6700\u7ec8\u56f0\u60d1\u5ea6\uff08\u66f4\u9ad8\u7684\u6027\u80fd\uff09\uff0c\u4f46\u4ee3\u4ef7\u662f\u66f4\u591a\u7684\u8bad\u7ec3\u6b65\u9aa4\u548c\u66f4\u4f4e\u7684\u8ba1\u7b97\u6548\u7387\u3002\u8fd9\u79cd\u6743\u8861\u4e3a\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6253\u5305\u65b9\u6cd5\u9009\u62e9\u63d0\u4f9b\u4e86\u4fe1\u606f\u3002", "author": "Yanbing Chen et.al.", "authors": "Yanbing Chen, Ruilin Wang, Zihao Yang, Lavender Yao Jiang, Eric Karl Oermann", "id": "2408.09621v1", "paper_url": "http://arxiv.org/abs/2408.09621v1", "repo": "null"}}