{"2410.22114": {"publish_time": "2024-10-29", "title": "Policy Gradient for Robust Markov Decision Processes", "paper_summary": "We develop a generic policy gradient method with the global optimality\nguarantee for robust Markov Decision Processes (MDPs). While policy gradient\nmethods are widely used for solving dynamic decision problems due to their\nscalable and efficient nature, adapting these methods to account for model\nambiguity has been challenging, often making it impractical to learn robust\npolicies. This paper introduces a novel policy gradient method, Double-Loop\nRobust Policy Mirror Descent (DRPMD), for solving robust MDPs. DRPMD employs a\ngeneral mirror descent update rule for the policy optimization with adaptive\ntolerance per iteration, guaranteeing convergence to a globally optimal policy.\nWe provide a comprehensive analysis of DRPMD, including new convergence results\nunder both direct and softmax parameterizations, and provide novel insights\ninto the inner problem solution through Transition Mirror Ascent (TMA).\nAdditionally, we propose innovative parametric transition kernels for both\ndiscrete and continuous state-action spaces, broadening the applicability of\nour approach. Empirical results validate the robustness and global convergence\nof DRPMD across various challenging robust MDP settings.", "paper_summary_zh": "\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u5177\u6709\u5168\u5c40\u6700\u512a\u6027\n\u4fdd\u8b49\u7684\u901a\u7528\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff0c\u7528\u65bc\u7a69\u5065\u99ac\u53ef\u592b\u6c7a\u7b56\u904e\u7a0b (MDP)\u3002\u96d6\u7136\u7b56\u7565\u68af\u5ea6\n\u65b9\u6cd5\u7531\u65bc\u5176\u53ef\u64f4\u5c55\u4e14\u9ad8\u6548\u7684\u7279\u6027\u800c\u5ee3\u6cdb\u7528\u65bc\u89e3\u6c7a\u52d5\u614b\u6c7a\u7b56\u554f\u984c\uff0c\u4f46\u8abf\u6574\u9019\u4e9b\u65b9\u6cd5\u4ee5\u8003\u616e\u6a21\u578b\n\u6a21\u7cca\u6027\u4e00\u76f4\u5f88\u6709\u6311\u6230\u6027\uff0c\u901a\u5e38\u4f7f\u5f97\u5b78\u7fd2\u7a69\u5065\u7b56\u7565\u8b8a\u5f97\u4e0d\u5207\u5be6\u969b\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff0c\u96d9\u8ff4\u8def\n\u7a69\u5065\u7b56\u7565\u93e1\u50cf\u4e0b\u964d (DRPMD)\uff0c\u7528\u65bc\u89e3\u6c7a\u7a69\u5065 MDP\u3002DRPMD \u63a1\u7528\n\u901a\u7528\u93e1\u50cf\u4e0b\u964d\u66f4\u65b0\u898f\u5247\u9032\u884c\u7b56\u7565\u512a\u5316\uff0c\u6bcf\u500b\u8fed\u4ee3\u5177\u6709\u81ea\u9069\u61c9\u5bb9\u5dee\uff0c\u4fdd\u8b49\u6536\u6582\u5230\u5168\u5c40\u6700\u512a\u7b56\u7565\u3002\n\u6211\u5011\u63d0\u4f9b\u4e86\u5c0d DRPMD \u7684\u5168\u9762\u5206\u6790\uff0c\u5305\u62ec\u76f4\u63a5\u548c softmax \u53c3\u6578\u5316\u4e0b\u7684\u65b0\u6536\u6582\u7d50\u679c\uff0c\u4e26\u901a\u904e\u8f49\u79fb\u93e1\u50cf\u4e0a\u5347 (TMA) \u63d0\u4f9b\u4e86\u5c0d\u5167\u90e8\u554f\u984c\u89e3\u6c7a\u65b9\u6848\u7684\u65b0\u898b\u89e3\u3002\n\u6b64\u5916\uff0c\u6211\u5011\u91dd\u5c0d\u96e2\u6563\u548c\u9023\u7e8c\u72c0\u614b\u52d5\u4f5c\u7a7a\u9593\u63d0\u51fa\u4e86\u5275\u65b0\u7684\u53c3\u6578\u5316\u8f49\u79fb\u6838\uff0c\u64f4\u5927\u4e86\n\u6211\u5011\u65b9\u6cd5\u7684\u9069\u7528\u6027\u3002\u7d93\u9a57\u7d50\u679c\u9a57\u8b49\u4e86 DRPMD \u5728\u5404\u7a2e\u5177\u6709\u6311\u6230\u6027\u7684\u7a69\u5065 MDP \u8a2d\u7f6e\u4e2d\u7684\u7a69\u5065\u6027\u548c\u5168\u5c40\u6536\u6582\u6027\u3002", "author": "Qiuhao Wang et.al.", "authors": "Qiuhao Wang, Shaohang Xu, Chin Pang Ho, Marek Petrick", "id": "2410.22114v1", "paper_url": "http://arxiv.org/abs/2410.22114v1", "repo": "https://github.com/JerrisonWang/JMLR-DRPMD"}}