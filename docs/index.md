# arxiv-daily
 Automated deployment @ 2024-10-02 09:05:38 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-30**|**The Perfect Blend: Redefining RLHF with Mixture of Judges**|Tengyu Xu et.al.|[2409.20370v1](http://arxiv.org/abs/2409.20370v1)|null|
|**2024-09-30**|**Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**|Arunava Chakravarty et.al.|[2409.20195v1](http://arxiv.org/abs/2409.20195v1)|null|
|**2024-09-30**|**Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**|Vincent Beliveau et.al.|[2409.20147v1](http://arxiv.org/abs/2409.20147v1)|null|
|**2024-09-30**|**Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**|Samia Belhadj et.al.|[2409.19940v1](http://arxiv.org/abs/2409.19940v1)|null|
|**2024-09-29**|**InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries**|Mengze Hong et.al.|[2409.19689v1](http://arxiv.org/abs/2409.19689v1)|null|
|**2024-09-29**|**See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning**|Chengxin Zheng et.al.|[2409.19676v2](http://arxiv.org/abs/2409.19676v2)|[link](https://github.com/chauncey-jheng/pcrl-mrg)|
|**2024-09-29**|**Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales**|Maor Reuben et.al.|[2409.19655v1](http://arxiv.org/abs/2409.19655v1)|null|
|**2024-09-29**|**A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends**|Yucheng Wang et.al.|[2409.19629v1](http://arxiv.org/abs/2409.19629v1)|null|
|**2024-09-29**|**MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI**|Vivek Kumar Trivedi et.al.|[2409.19623v1](http://arxiv.org/abs/2409.19623v1)|[link](https://github.com/vivekkumartri/mcddpm)|
|**2024-09-29**|**Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation**|Hyojin Bae et.al.|[2409.19531v1](http://arxiv.org/abs/2409.19531v1)|null|
|**2024-09-29**|**MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models**|Vibhor Agarwal et.al.|[2409.19492v1](http://arxiv.org/abs/2409.19492v1)|null|
|**2024-09-28**|**INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning**|Pablo Romero et.al.|[2409.19467v1](http://arxiv.org/abs/2409.19467v1)|null|
|**2024-09-28**|**Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment**|Tianyi Liu et.al.|[2409.19366v1](http://arxiv.org/abs/2409.19366v1)|null|
|**2024-09-28**|**3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models**|Hao Chen et.al.|[2409.19330v1](http://arxiv.org/abs/2409.19330v1)|null|
|**2024-09-27**|**Secure Multiparty Generative AI**|Manil Shrestha et.al.|[2409.19120v1](http://arxiv.org/abs/2409.19120v1)|null|
|**2024-09-27**|**Differential privacy for protecting patient data in speech disorder detection using deep learning**|Soroosh Tayebi Arasteh et.al.|[2409.19078v1](http://arxiv.org/abs/2409.19078v1)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|Huizi Yu et.al.|[2409.18924v1](http://arxiv.org/abs/2409.18924v1)|null|
|**2024-09-27**|**Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**|Zehan Li et.al.|[2409.18878v1](http://arxiv.org/abs/2409.18878v1)|null|
|**2024-09-27**|**Early diagnosis of Alzheimer's disease from MRI images with deep learning model**|Sajjad Aghasi Javid et.al.|[2409.18814v1](http://arxiv.org/abs/2409.18814v1)|null|
|**2024-09-27**|**State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**|George R. Nahass et.al.|[2409.18769v1](http://arxiv.org/abs/2409.18769v1)|null|
|**2024-09-27**|**Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**|Salma Hassan et.al.|[2409.18715v1](http://arxiv.org/abs/2409.18715v1)|null|
|**2024-09-27**|**Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow**|Marvin Tom Teichmann et.al.|[2409.18628v1](http://arxiv.org/abs/2409.18628v1)|null|
|**2024-09-27**|**Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications**|Aditi Godbole et.al.|[2409.18454v1](http://arxiv.org/abs/2409.18454v1)|null|
|**2024-09-27**|**Physics Augmented Tuple Transformer for Autism Severity Level Detection**|Chinthaka Ranasingha et.al.|[2409.18438v1](http://arxiv.org/abs/2409.18438v1)|null|
|**2024-09-26**|**DRL-STNet: Unsupervised Domain Adaptation for Cross-modality Medical Image Segmentation via Disentangled Representation Learning**|Hui Lin et.al.|[2409.18340v1](http://arxiv.org/abs/2409.18340v1)|null|
|**2024-09-26**|**Cross-Institutional Structured Radiology Reporting for Lung Cancer Screening Using a Dynamic Template-Constrained Large Language Model**|Chuang Niu et.al.|[2409.18319v1](http://arxiv.org/abs/2409.18319v1)|null|
|**2024-09-26**|**Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams**|Yuexing Hao et.al.|[2409.18290v1](http://arxiv.org/abs/2409.18290v1)|null|
|**2024-09-26**|**Evaluation of Large Language Models for Summarization Tasks in the Medical Domain: A Narrative Review**|Emma Croxford et.al.|[2409.18170v1](http://arxiv.org/abs/2409.18170v1)|null|
|**2024-09-26**|**Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography**|Yuexi Du et.al.|[2409.18119v1](http://arxiv.org/abs/2409.18119v1)|null|
|**2024-09-26**|**CRoP: Context-wise Robust Static Human-Sensing Personalization**|Sawinder Kaur et.al.|[2409.17994v2](http://arxiv.org/abs/2409.17994v2)|null|
|**2024-09-26**|**Supervised Learning Model for Key Frame Identification from Cow Teat Videos**|Minghao Wang et.al.|[2409.18797v1](http://arxiv.org/abs/2409.18797v1)|null|
|**2024-09-26**|**Implementing a Nordic-Baltic Federated Health Data Network: a case report**|Taridzo Chomutare et.al.|[2409.17865v1](http://arxiv.org/abs/2409.17865v1)|null|
|**2024-09-26**|**DREAMS: A python framework to train deep learning models with model card reporting for medical and health applications**|Rabindra Khadka et.al.|[2409.17815v1](http://arxiv.org/abs/2409.17815v1)|null|
|**2024-09-26**|**Ophthalmic Biomarker Detection with Parallel Prediction of Transformer and Convolutional Architecture**|Md. Touhidul Islam et.al.|[2409.17788v1](http://arxiv.org/abs/2409.17788v1)|null|
|**2024-09-26**|**Confidence intervals uncovered: Are we ready for real-world medical imaging AI?**|Evangelia Christodoulou et.al.|[2409.17763v2](http://arxiv.org/abs/2409.17763v2)|null|
|**2024-09-26**|**Artificial Data Point Generation in Clustered Latent Space for Small Medical Datasets**|Yasaman Haghbin et.al.|[2409.17685v1](http://arxiv.org/abs/2409.17685v1)|null|
|**2024-09-26**|**Zero- and Few-shot Named Entity Recognition and Text Expansion in Medication Prescriptions using ChatGPT**|Natthanaphop Isaradech et.al.|[2409.17683v1](http://arxiv.org/abs/2409.17683v1)|null|
|**2024-09-26**|**Digital Twin Ecosystem for Oncology Clinical Operations**|Himanshu Pandey et.al.|[2409.17650v1](http://arxiv.org/abs/2409.17650v1)|null|
|**2024-09-26**|**A Scalable Data-Driven Framework for Systematic Analysis of SEC 10-K Filings Using Large Language Models**|Syed Affan Daimi et.al.|[2409.17581v1](http://arxiv.org/abs/2409.17581v1)|null|
|**2024-09-26**|**Dr. GPT in Campus Counseling: Understanding Higher Education Students' Opinions on LLM-assisted Mental Health Services**|Owen Xingjian Zhang et.al.|[2409.17572v1](http://arxiv.org/abs/2409.17572v1)|null|
|**2024-09-26**|**Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE**|Xun Zhu et.al.|[2409.17508v1](http://arxiv.org/abs/2409.17508v1)|null|
|**2024-09-26**|**Global-Local Medical SAM Adaptor Based on Full Adaption**|Meng Wang et.al.|[2409.17486v1](http://arxiv.org/abs/2409.17486v1)|null|
|**2024-09-25**|**Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting**|Jay Zoellin et.al.|[2409.17332v1](http://arxiv.org/abs/2409.17332v1)|null|
|**2024-09-25**|**Data-Centric AI Governance: Addressing the Limitations of Model-Focused Policies**|Ritwik Gupta et.al.|[2409.17216v1](http://arxiv.org/abs/2409.17216v1)|null|
|**2024-09-25**|**Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**|Xinrui Zhou et.al.|[2409.17091v1](http://arxiv.org/abs/2409.17091v1)|null|
|**2024-09-25**|**DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**|Lucas Robinet et.al.|[2409.17055v2](http://arxiv.org/abs/2409.17055v2)|[link](https://github.com/lucas-rbnt/drim)|
|**2024-09-25**|**Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**|Azmul Asmar Irfan et.al.|[2409.17054v1](http://arxiv.org/abs/2409.17054v1)|null|
|**2024-09-25**|**GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**|Phillip Mueller et.al.|[2409.17045v1](http://arxiv.org/abs/2409.17045v1)|null|
|**2024-09-25**|**AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**|Jaeyoung Huh et.al.|[2409.16898v2](http://arxiv.org/abs/2409.16898v2)|null|
|**2024-09-25**|**The Role of Language Models in Modern Healthcare: A Comprehensive Review**|Amna Khalid et.al.|[2409.16860v1](http://arxiv.org/abs/2409.16860v1)|null|
|**2024-09-25**|**A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**|Syed Mohd Faisal Malik et.al.|[2409.16721v1](http://arxiv.org/abs/2409.16721v1)|null|
|**2024-09-25**|**Enhancing Guardrails for Safe and Secure Healthcare AI**|Ananya Gangavarapu et.al.|[2409.17190v1](http://arxiv.org/abs/2409.17190v1)|null|
|**2024-09-25**|**Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels**|Yishu Wei et.al.|[2409.16563v1](http://arxiv.org/abs/2409.16563v1)|null|
|**2024-09-24**|**To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study**|Imra Aqeel et.al.|[2409.16486v1](http://arxiv.org/abs/2409.16486v1)|null|
|**2024-09-24**|**Design and Evaluation of a CDSS for Drug Allergy Management Using LLMs and Pharmaceutical Data Integration**|Gabriele De Vito et.al.|[2409.16395v1](http://arxiv.org/abs/2409.16395v1)|null|
|**2024-09-24**|**Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review**|Nikolas Koutsoubis et.al.|[2409.16340v1](http://arxiv.org/abs/2409.16340v1)|null|
|**2024-09-24**|**Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**|Henry Musto et.al.|[2409.16231v1](http://arxiv.org/abs/2409.16231v1)|null|
|**2024-09-24**|**Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**|Mehtab Ur Rahman et.al.|[2409.16106v2](http://arxiv.org/abs/2409.16106v2)|null|
|**2024-09-24**|**The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems**|África Periáñez et.al.|[2409.16098v1](http://arxiv.org/abs/2409.16098v1)|null|
|**2024-09-24**|**Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**|Kriti Agarwal et.al.|[2409.15910v1](http://arxiv.org/abs/2409.15910v1)|null|
|**2024-09-24**|**AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**|Adil Bahaj et.al.|[2409.15815v1](http://arxiv.org/abs/2409.15815v1)|null|
|**2024-09-24**|**Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2409.15814v1](http://arxiv.org/abs/2409.15814v1)|null|
|**2024-09-24**|**Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm**|Yooseok Lim et.al.|[2409.15753v1](http://arxiv.org/abs/2409.15753v1)|null|
|**2024-09-24**|**dnaGrinder: a lightweight and high-capacity genomic foundation model**|Qihang Zhao et.al.|[2409.15697v1](http://arxiv.org/abs/2409.15697v1)|null|
|**2024-09-24**|**Safe Navigation for Robotic Digestive Endoscopy via Human Intervention-based Reinforcement Learning**|Min Tan et.al.|[2409.15688v1](http://arxiv.org/abs/2409.15688v1)|null|
|**2024-09-24**|**A Comprehensive Evaluation of Large Language Models on Mental Illnesses**|Abdelrahman Hanafi et.al.|[2409.15687v1](http://arxiv.org/abs/2409.15687v1)|null|
|**2024-09-23**|**TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU**|Rosemary Y. He et.al.|[2409.15586v2](http://arxiv.org/abs/2409.15586v2)|null|
|**2024-09-23**|**MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis**|Stanislav Kozák et.al.|[2409.16329v1](http://arxiv.org/abs/2409.16329v1)|null|
|**2024-09-23**|**Computational Pathology for Accurate Prediction of Breast Cancer Recurrence: Development and Validation of a Deep Learning-based Tool**|Ziyu Su et.al.|[2409.15491v1](http://arxiv.org/abs/2409.15491v1)|null|
|**2024-09-23**|**A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?**|Yunfei Xie et.al.|[2409.15277v1](http://arxiv.org/abs/2409.15277v1)|null|
|**2024-09-23**|**Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation**|Yi-Fei Zhao et.al.|[2409.15260v1](http://arxiv.org/abs/2409.15260v1)|null|
|**2024-09-23**|**Boosting Healthcare LLMs Through Retrieved Context**|Jordi Bayarri-Planas et.al.|[2409.15127v1](http://arxiv.org/abs/2409.15127v1)|null|
|**2024-09-23**|**Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network**|Sijia Du et.al.|[2409.15006v1](http://arxiv.org/abs/2409.15006v1)|null|
|**2024-09-23**|**DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models**|Sangyeon Cho et.al.|[2409.14904v1](http://arxiv.org/abs/2409.14904v1)|[link](https://github.com/josangyeon/dsg-kd)|
|**2024-09-23**|**Mammo-Clustering:A Weakly Supervised Multi-view Global-Local Context Clustering Network for Detection and Classification in Mammography**|Shilong Yang et.al.|[2409.14876v1](http://arxiv.org/abs/2409.14876v1)|null|
|**2024-09-23**|**Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images**|Ahjol Senbi et.al.|[2409.14874v2](http://arxiv.org/abs/2409.14874v2)|null|
|**2024-09-23**|**A-VL: Adaptive Attention for Large Vision-Language Models**|Junyang Zhang et.al.|[2409.14846v1](http://arxiv.org/abs/2409.14846v1)|null|
|**2024-09-22**|**Can Large Language Models Logically Predict Myocardial Infarction? Evaluation based on UK Biobank Cohort**|Yuxing Zhi et.al.|[2409.14478v1](http://arxiv.org/abs/2409.14478v1)|null|
|**2024-09-22**|**Detection of pulmonary pathologies using convolutional neural networks, Data Augmentation, ResNet50 and Vision Transformers**|Pablo Ramirez Amador et.al.|[2409.14446v1](http://arxiv.org/abs/2409.14446v1)|null|
|**2024-09-22**|**Data-Driven Spatiotemporal Feature Representation and Mining in Multidimensional Time Series**|Xu Yan et.al.|[2409.14327v1](http://arxiv.org/abs/2409.14327v1)|null|
|**2024-09-22**|**PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation**|Yuxuan Zhou et.al.|[2409.14302v1](http://arxiv.org/abs/2409.14302v1)|null|
|**2024-09-21**|**Data-Driven Approach to assess and identify gaps in healthcare set up in South Asia**|Rusham Elahi et.al.|[2409.14194v1](http://arxiv.org/abs/2409.14194v1)|null|
|**2024-09-21**|**Democratising Artificial Intelligence for Pandemic Preparedness and Global Governance in Latin American and Caribbean Countries**|Andre de Carvalho et.al.|[2409.14181v1](http://arxiv.org/abs/2409.14181v1)|null|
|**2024-09-20**|**CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data**|Zhao Cheng et.al.|[2409.13903v1](http://arxiv.org/abs/2409.13903v1)|null|
|**2024-09-20**|**Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in Ophthalmology**|Aidan Gilson et.al.|[2409.13902v1](http://arxiv.org/abs/2409.13902v1)|null|
|**2024-09-20**|**A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics**|Mengyun Qiao et.al.|[2409.13825v1](http://arxiv.org/abs/2409.13825v1)|null|
|**2024-09-20**|**Morphological Detection and Classification of Microplastics and Nanoplastics Emerged from Consumer Products by Deep Learning**|Hadi Rezvani et.al.|[2409.13688v1](http://arxiv.org/abs/2409.13688v1)|null|
|**2024-09-20**|**Depression Diagnosis Dialogue Simulation: Self-improving Psychiatrist with Tertiary Memory**|Kunyao Lan et.al.|[2409.15084v1](http://arxiv.org/abs/2409.15084v1)|null|
|**2024-09-20**|**Toward Automated Clinical Transcriptions**|Mitchell A. Klusty et.al.|[2409.15378v1](http://arxiv.org/abs/2409.15378v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-20**|**Differentially Private Multimodal Laplacian Dropout (DP-MLD) for EEG Representative Learning**|Xiaowen Fu et.al.|[2409.13440v1](http://arxiv.org/abs/2409.13440v1)|null|
|**2024-09-20**|**FPBoost: Fully Parametric Gradient Boosting for Survival Analysis**|Alberto Archetti et.al.|[2409.13363v1](http://arxiv.org/abs/2409.13363v1)|null|
|**2024-09-20**|**Multi-omics data integration for early diagnosis of hepatocellular carcinoma (HCC) using machine learning**|Annette Spooner et.al.|[2409.13791v1](http://arxiv.org/abs/2409.13791v1)|null|
|**2024-09-20**|**Recent Advancement of Emotion Cognition in Large Language Models**|Yuyan Chen et.al.|[2409.13354v1](http://arxiv.org/abs/2409.13354v1)|null|
|**2024-09-20**|**SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation**|Jinge Wu et.al.|[2409.13321v1](http://arxiv.org/abs/2409.13321v1)|null|
|**2024-09-20**|**OMG-RL:Offline Model-based Guided Reward Learning for Heparin Treatment**|Yooseok Lim et.al.|[2409.13299v1](http://arxiv.org/abs/2409.13299v1)|null|
|**2024-09-20**|**Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia**|Elisa Castagnari et.al.|[2409.15377v1](http://arxiv.org/abs/2409.15377v1)|null|
|**2024-09-20**|**An adapted large language model facilitates multiple medical tasks in diabetes care**|Lai Wei et.al.|[2409.13191v1](http://arxiv.org/abs/2409.13191v1)|[link](https://github.com/waltonfuture/Diabetica)|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Personalized 2D Binary Patient Codes of Tissue Images and Immunogenomic Data Through Multimodal Self-Supervised Fusion**|Areej Alsaafin et.al.|[2409.13115v1](http://arxiv.org/abs/2409.13115v1)|null|

#### Abstracts
##### **The Perfect Blend: Redefining RLHF with Mixture of Judges**
2409.20370v1 by Tengyu Xu, Eryk Helenowski, Karthik Abinav Sankararaman, Di Jin, Kaiyan Peng, Eric Han, Shaoliang Nie, Chen Zhu, Hejia Zhang, Wenxuan Zhou, Zhouhao Zeng, Yun He, Karishma Mandyam, Arya Talabzadeh, Madian Khabsa, Gabriel Cohen, Yuandong Tian, Hao Ma, Sinong Wang, Han Fang

Reinforcement learning from human feedback (RLHF) has become the leading
approach for fine-tuning large language models (LLM). However, RLHF has
limitations in multi-task learning (MTL) due to challenges of reward hacking
and extreme multi-objective optimization (i.e., trade-off of multiple and/or
sometimes conflicting objectives). Applying RLHF for MTL currently requires
careful tuning of the weights for reward model and data combinations. This is
often done via human intuition and does not generalize. In this work, we
introduce a novel post-training paradigm which we called Constrained Generative
Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with
cost-efficient constrained policy optimization with stratification, which can
identify the perfect blend in RLHF in a principled manner. It shows strong
empirical results with theoretical guarantees, does not require extensive
hyper-parameter tuning, and is plug-and-play in common post-training pipelines.
Together, this can detect and mitigate reward hacking behaviors while reaching
a pareto-optimal point across an extremely large number of objectives.
  Our empirical evaluations demonstrate that CGPO significantly outperforms
standard RLHF algorithms like PPO and DPO across various tasks including
general chat, STEM questions, instruction following, and coding. Specifically,
CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in
Arena-Hard (STEM & reasoning), and consistent gains in other domains like math
and coding. Notably, PPO, while commonly used, is prone to severe reward
hacking in popular coding benchmarks, which CGPO successfully addresses. This
breakthrough in RLHF not only tackles reward hacking and extreme
multi-objective optimization challenges but also advances the state-of-the-art
in aligning general-purpose LLMs for diverse applications.

摘要：人類回饋強化學習 (RLHF) 已成為微調大型語言模型 (LLM) 的領先方法。然而，RLHF 在多任務學習 (MTL) 中受到獎勵破解和極端多目標最佳化（例如，多重和/或有時相互衝突的目標之間的取捨）的挑戰而有所限制。目前，將 RLHF 應用於 MTL 需要仔細調整獎勵模型和資料組合的權重。這通常是透過人類直覺來完成，而且無法概括。在這項工作中，我們引入了一種新穎的訓練後範例，我們稱之為受約束生成策略最佳化 (CGPO)。CGPO 的核心是法官混合 (MoJ)，透過分層進行具有成本效益的受約束策略最佳化，它可以以原則性的方式找出 RLHF 中的完美融合。它在理論保證下展現強大的實證結果，不需要廣泛的超參數調整，並且可以即插即用於常見的訓練後管道。總之，它可以在極大量的目標中偵測和減輕獎勵破解行為，同時達到帕雷托最優點。我們的實證評估證明，CGPO 在各種任務中顯著優於標準 RLHF 演算法，例如一般聊天、STEM 問題、指令遵循和編碼。具體來說，CGPO 在 AlpacaEval-2（一般聊天）中提升了 7.4%，在 Arena-Hard（STEM 和推理）中提升了 12.5%，並且在數學和編碼等其他領域中持續獲得收益。值得注意的是，PPO 雖然普遍使用，但在流行的編碼基準中容易受到嚴重的獎勵破解，而 CGPO 成功地解決了這個問題。RLHF 的這項突破不僅解決了獎勵破解和極端多目標最佳化的挑戰，而且還推動了將通用 LLM 與各種應用程式相結合的最新技術。

##### **Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**
2409.20195v1 by Arunava Chakravarty, Taha Emre, Dmitrii Lachinov, Antoine Rivail, Hendrik Scholl, Lars Fritsche, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Ursula Schmidt-Erfurth, Hrvoje Bogunović

Predicting future disease progression risk from medical images is challenging
due to patient heterogeneity, and subtle or unknown imaging biomarkers.
Moreover, deep learning (DL) methods for survival analysis are susceptible to
image domain shifts across scanners. We tackle these issues in the task of
predicting late dry Age-related Macular Degeneration (dAMD) onset from retinal
OCT scans. We propose a novel DL method for survival prediction to jointly
predict from the current scan a risk score, inversely related to
time-to-conversion, and the probability of conversion within a time interval
$t$. It uses a family of parallel hyperplanes generated by parameterizing the
bias term as a function of $t$. In addition, we develop unsupervised losses
based on intra-subject image pairs to ensure that risk scores increase over
time and that future conversion predictions are consistent with AMD stage
prediction using actual scans of future visits. Such losses enable
data-efficient fine-tuning of the trained model on new unlabeled datasets
acquired with a different scanner. Extensive evaluation on two large datasets
acquired with different scanners resulted in a mean AUROCs of 0.82 for
Dataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24
months.

摘要：由於患者異質性以及不明顯或未知的影像生物標記，從醫學影像預測未來疾病進程風險具有挑戰性。
此外，用於存活分析的深度學習 (DL) 方法容易受到跨掃描儀的影像域轉移影響。我們在預測晚期乾性年齡相關性黃斑部病變 (dAMD) 從視網膜 OCT 掃描中發生的任務中解決這些問題。我們提出了一種新的 DL 方法，用於存活預測，以從當前掃描中共同預測風險評分，與轉換時間成反比，以及在時間間隔 $t$ 內轉換的機率。它使用一組平行超平面，這些超平面是透過將偏差項參數化為 $t$ 的函數而產生的。此外，我們根據受試者內影像對開發無監督損失，以確保風險評分隨著時間增加，並且未來的轉換預測與使用未來就診實際掃描的 AMD 階段預測一致。此類損失能夠對使用不同掃描儀取得的新未標籤資料集進行資料有效微調訓練模型。對使用不同掃描儀取得的兩個大型資料集進行廣泛評估，在 6、12 和 24 個月的預測區間內，資料集 1 的平均 AUROC 為 0.82，資料集 2 的平均 AUROC 為 0.83。

##### **Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**
2409.20147v1 by Vincent Beliveau, Helene Kaas, Martin Prener, Claes N. Ladefoged, Desmond Elliott, Gitte M. Knudsen, Lars H. Pinborg, Melanie Ganz

Natural language processing (NLP) in the medical domain can underperform in
real-world applications involving small datasets in a non-English language with
few labeled samples and imbalanced classes. There is yet no consensus on how to
approach this problem. We evaluated a set of NLP models including BERT-like
transformers, few-shot learning with sentence transformers (SetFit), and
prompted large language models (LLM), using three datasets of radiology reports
on magnetic resonance images of epilepsy patients in Danish, a low-resource
language. Our results indicate that BERT-like models pretrained in the target
domain of radiology reports currently offer the optimal performances for this
scenario. Notably, the SetFit and LLM models underperformed compared to
BERT-like models, with LLM performing the worst. Importantly, none of the
models investigated was sufficiently accurate to allow for text classification
without any supervision. However, they show potential for data filtering, which
could reduce the amount of manual labeling required.

摘要：自然語言處理 (NLP) 在醫療領域中，在涉及非英語語言中小型資料集、標記樣本少和類別不平衡的實際應用中表現不佳。對於如何解決這個問題，目前尚未達成共識。我們使用三組丹麥語癲癇患者磁共振影像的放射報告資料集，評估了一組 NLP 模型，包括類 BERT 轉換器、使用句子轉換器 (SetFit) 的少樣本學習，以及提示的大型語言模型 (LLM)。我們的結果表明，目前在放射報告目標領域中預訓練的類 BERT 模型為此情境提供最佳效能。值得注意的是，與類 BERT 模型相比，SetFit 和 LLM 模型表現不佳，而 LLM 表現最差。重要的是，所研究的模型中沒有一個足夠準確，可以在沒有任何監督的情況下進行文字分類。然而，它們顯示出資料過濾的潛力，這可以減少所需的手動標記量。

##### **Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**
2409.19940v1 by Samia Belhadj, Sanguk Park, Ambika Seth, Hesham Dar, Thijs Kooi

Fairness in medical AI is increasingly recognized as a crucial aspect of
healthcare delivery. While most of the prior work done on fairness emphasizes
the importance of equal performance, we argue that decreases in fairness can be
either harmful or non-harmful, depending on the type of change and how
sensitive attributes are used. To this end, we introduce the notion of
positive-sum fairness, which states that an increase in performance that
results in a larger group disparity is acceptable as long as it does not come
at the cost of individual subgroup performance. This allows sensitive
attributes correlated with the disease to be used to increase performance
without compromising on fairness.
  We illustrate this idea by comparing four CNN models that make different use
of the race attribute in the training phase. The results show that removing all
demographic encodings from the images helps close the gap in performance
between the different subgroups, whereas leveraging the race attribute as a
model's input increases the overall performance while widening the disparities
between subgroups. These larger gaps are then put in perspective of the
collective benefit through our notion of positive-sum fairness to distinguish
harmful from non harmful disparities.

摘要：醫療 AI 中的公平性日益被視為醫療保健提供中至關重要的一環。雖然大多數先前關於公平性的研究都強調同等表現的重要性，我們認為公平性的下降可能是有害的或無害的，具體取決於變化的類型和敏感屬性的使用方式。為此，我們引入了正和公平性的概念，它指出，只要不以犧牲個別子群體表現為代價，那麼導致群體差異更大的表現提升是可以接受的。這允許將與疾病相關的敏感屬性用於提高表現，而不會損害公平性。
我們通過比較四個在訓練階段對種族屬性使用不同的 CNN 模型來說明這個想法。結果顯示，從圖像中移除所有人口編碼有助於縮小不同子群體之間的表現差距，而將種族屬性用作模型的輸入會提高整體表現，同時擴大子群體之間的差異。然後，通過我們正和公平性的概念將這些更大的差距置於整體效益的角度，以區分有害和無害的差異。

##### **InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries**
2409.19689v1 by Mengze Hong, Chen Jason Zhang, Lingxiao Yang, Yuanfeng Song, Di Jiang

Understanding the meaning of infant cries is a significant challenge for
young parents in caring for their newborns. The presence of background noise
and the lack of labeled data present practical challenges in developing systems
that can detect crying and analyze its underlying reasons. In this paper, we
present a novel data-driven framework, "InfantCryNet," for accomplishing these
tasks. To address the issue of data scarcity, we employ pre-trained audio
models to incorporate prior knowledge into our model. We propose the use of
statistical pooling and multi-head attention pooling techniques to extract
features more effectively. Additionally, knowledge distillation and model
quantization are applied to enhance model efficiency and reduce the model size,
better supporting industrial deployment in mobile devices. Experiments on
real-life datasets demonstrate the superior performance of the proposed
framework, outperforming state-of-the-art baselines by 4.4% in classification
accuracy. The model compression effectively reduces the model size by 7%
without compromising performance and by up to 28% with only an 8% decrease in
accuracy, offering practical insights for model selection and system design.

摘要：了解嬰兒哭聲的含義對於年輕父母照顧新生兒來說是一項重大挑戰。背景噪音的存在和標籤資料的缺乏在開發可以偵測哭聲並分析其背後原因的系統時提出了實際挑戰。在本文中，我們提出了一個新穎的資料驅動框架「InfantCryNet」來完成這些任務。為了解決資料稀缺的問題，我們採用預先訓練的音訊模型，將先驗知識納入我們的模型中。我們提出使用統計池化和多頭注意力池化技術來更有效地提取特徵。此外，知識蒸餾和模型量化被應用於增強模型效率並縮小模型大小，更好地支援行動裝置中的產業部署。對真實資料集的實驗證明了所提出的框架的優異效能，在分類準確度上比最先進的基準高出 4.4%。模型壓縮有效地將模型大小減少了 7%，而不會損害效能，並在準確度僅下降 8% 的情況下將模型大小減少了 28%，為模型選擇和系統設計提供了實用的見解。

##### **See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning**
2409.19676v2 by Chengxin Zheng, Junzhong Ji, Yanzhao Shi, Xiaodan Zhang, Liangqiong Qu

Brain CT report generation is significant to aid physicians in diagnosing
cranial diseases. Recent studies concentrate on handling the consistency
between visual and textual pathological features to improve the coherence of
report. However, there exist some challenges: 1) Redundant visual representing:
Massive irrelevant areas in 3D scans distract models from representing salient
visual contexts. 2) Shifted semantic representing: Limited medical corpus
causes difficulties for models to transfer the learned textual representations
to generative layers. This study introduces a Pathological Clue-driven
Representation Learning (PCRL) model to build cross-modal representations based
on pathological clues and naturally adapt them for accurate report generation.
Specifically, we construct pathological clues from perspectives of segmented
regions, pathological entities, and report themes, to fully grasp visual
pathological patterns and learn cross-modal feature representations. To adapt
the representations for the text generation task, we bridge the gap between
representation learning and report generation by using a unified large language
model (LLM) with task-tailored instructions. These crafted instructions enable
the LLM to be flexibly fine-tuned across tasks and smoothly transfer the
semantic representation for report generation. Experiments demonstrate that our
method outperforms previous methods and achieves SoTA performance. Our code is
available at "https://github.com/Chauncey-Jheng/PCRL-MRG".

摘要：腦部電腦斷層掃描報告生成有助於醫生診斷顱骨疾病。最近的研究專注於處理視覺和文字病理特徵之間的一致性，以提高報告的一致性。然而，存在一些挑戰：1) 多餘的視覺表示：3D 掃描中的大量無關區域會分散模型對顯著視覺背景的表示。2) 轉移的語義表示：有限的醫學語料庫導致模型難以將學習到的文字表示轉移到生成層。本研究引入了病理線索驅動表示學習 (PCRL) 模型，基於病理線索構建跨模態表示，並自然地調整它們以進行準確的報告生成。具體來說，我們從分割區域、病理實體和報告主題的角度構建病理線索，以充分掌握視覺病理模式並學習跨模態特徵表示。為了調整表示以適應文本生成任務，我們通過使用具有任務定制指令的統一大型語言模型 (LLM) 來彌合表示學習和報告生成之間的差距。這些精心製作的指令使 LLM 能夠靈活地跨任務進行微調，並順利地將語義表示轉移到報告生成中。實驗表明，我們的模型優於先前的模型，並達到了最先進的性能。我們的程式碼可在「https://github.com/Chauncey-Jheng/PCRL-MRG」取得。

##### **Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales**
2409.19655v1 by Maor Reuben, Ortal Slobodin, Aviad Elyshar, Idan-Chaim Cohen, Orna Braun-Lewensohn, Odeya Cohen, Rami Puzis

Human-like personality traits have recently been discovered in large language
models, raising the hypothesis that their (known and as yet undiscovered)
biases conform with human latent psychological constructs. While large
conversational models may be tricked into answering psychometric
questionnaires, the latent psychological constructs of thousands of simpler
transformers, trained for other tasks, cannot be assessed because appropriate
psychometric methods are currently lacking. Here, we show how standard
psychological questionnaires can be reformulated into natural language
inference prompts, and we provide a code library to support the psychometric
assessment of arbitrary models. We demonstrate, using a sample of 88 publicly
available models, the existence of human-like mental health-related constructs
(including anxiety, depression, and Sense of Coherence) which conform with
standard theories in human psychology and show similar correlations and
mitigation strategies. The ability to interpret and rectify the performance of
language models by using psychological tools can boost the development of more
explainable, controllable, and trustworthy models.

摘要：大型語言模型最近發現了類人的人格特質，提出了一個假設，即它們（已知和尚未發現的）偏見符合人類潛在的心理結構。雖然大型對話模型可能會被誘騙回答心理測驗問卷，但數千個經過訓練以執行其他任務的較簡單轉換器的潛在心理結構無法評估，因為目前缺乏適當的心理測量方法。在這裡，我們展示了如何將標準心理問卷重新表述為自然語言推理提示，並提供一個代碼庫來支持任意模型的心理測量評估。我們使用 88 個公開可用的模型的樣本，證明了類人心理健康相關結構（包括焦慮、抑鬱和一致感）的存在，這些結構符合人類心理學的標準理論，並顯示出類似的相關性和緩解策略。使用心理工具解釋和糾正語言模型的性能的能力可以促進更具可解釋性、可控性和可信度的模型的開發。

##### **A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends**
2409.19629v1 by Yucheng Wang, Min Wu, Xiaoli Li, Lihua Xie, Zhenghua Chen

Remaining Useful Life (RUL) prediction is a critical aspect of Prognostics
and Health Management (PHM), aimed at predicting the future state of a system
to enable timely maintenance and prevent unexpected failures. While existing
deep learning methods have shown promise, they often struggle to fully leverage
the spatial information inherent in complex systems, limiting their
effectiveness in RUL prediction. To address this challenge, recent research has
explored the use of Graph Neural Networks (GNNs) to model spatial information
for more accurate RUL prediction. This paper presents a comprehensive review of
GNN techniques applied to RUL prediction, summarizing existing methods and
offering guidance for future research. We first propose a novel taxonomy based
on the stages of adapting GNNs to RUL prediction, systematically categorizing
approaches into four key stages: graph construction, graph modeling, graph
information processing, and graph readout. By organizing the field in this way,
we highlight the unique challenges and considerations at each stage of the GNN
pipeline. Additionally, we conduct a thorough evaluation of various
state-of-the-art (SOTA) GNN methods, ensuring consistent experimental settings
for fair comparisons. This rigorous analysis yields valuable insights into the
strengths and weaknesses of different approaches, serving as an experimental
guide for researchers and practitioners working in this area. Finally, we
identify and discuss several promising research directions that could further
advance the field, emphasizing the potential for GNNs to revolutionize RUL
prediction and enhance the effectiveness of PHM strategies. The benchmarking
codes are available in GitHub:
https://github.com/Frank-Wang-oss/GNN\_RUL\_Benchmarking.

摘要：剩餘使用壽命 (RUL) 預測是預測與健康管理 (PHM) 的一個關鍵面向，旨在預測系統的未來狀態，以利於適時維護並預防意外故障。雖然現有的深度學習方法已展現前景，但它們往往難以充分利用複雜系統中固有的空間資訊，限制了它們在 RUL 預測中的效能。為了解決此挑戰，最近的研究已探討使用圖神經網路 (GNN) 來建模空間資訊，以進行更準確的 RUL 預測。本文提供了應用於 RUL 預測的 GNN 技術的全面回顧，總結了現有方法，並為未來的研究提供指導。我們首先根據適應 GNN 至 RUL 預測的階段提出一個新穎的分類法，系統性地將方法分類為四個關鍵階段：圖形建構、圖形建模、圖形資訊處理和圖形讀取。透過這種方式組織領域，我們強調了 GNN 管線中每個階段的獨特挑戰和考量。此外，我們對各種最先進 (SOTA) GNN 方法進行了徹底的評估，確保了一致的實驗設定以進行公平的比較。這種嚴謹的分析對不同方法的優缺點產生了寶貴的見解，作為在這個領域工作的研究人員和實務者的實驗指南。最後，我們找出並討論了幾個有前景的研究方向，這些方向可以進一步推進此領域，強調 GNN 具有革新 RUL 預測和提升 PHM 策略效能的潛力。基準代碼可在 GitHub 中取得：https://github.com/Frank-Wang-oss/GNN\_RUL\_Benchmarking。

##### **MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI**
2409.19623v1 by Vivek Kumar Trivedi, Bheeshm Sharma, P. Balamurugan

Detecting anomalies in brain MRI scans using supervised deep learning methods
presents challenges due to anatomical diversity and labor-intensive requirement
of pixel-level annotations. Generative models like Denoising Diffusion
Probabilistic Model (DDPM) and their variants like pDDPM, mDDPM, cDDPM have
recently emerged to be powerful alternatives to perform unsupervised anomaly
detection in brain MRI scans. These methods leverage frame-level labels of
healthy brains to generate healthy tissues in brain MRI scans. During
inference, when an anomalous (or unhealthy) scan image is presented as an
input, these models generate a healthy scan image corresponding to the input
anomalous scan, and the difference map between the generated healthy scan image
and the original anomalous scan image provide the necessary pixel level
identification of abnormal tissues. The generated healthy images from the DDPM,
pDDPM and mDDPM models however suffer from fidelity issues and contain
artifacts that do not have medical significance. While cDDPM achieves slightly
better fidelity and artifact suppression, it requires huge memory footprint and
is computationally expensive than the other DDPM based models. In this work, we
propose an improved version of DDPM called Multichannel Conditional Denoising
Diffusion Probabilistic Model (MCDDPM) for unsupervised anomaly detection in
brain MRI scans. Our proposed model achieves high fidelity by making use of
additional information from the healthy images during the training process,
enriching the representation power of DDPM models, with a computational cost
and memory requirements on par with DDPM, pDDPM and mDDPM models. Experimental
results on multiple datasets (e.g. BraTS20, BraTS21) demonstrate promising
performance of the proposed method. The code is available at
https://github.com/vivekkumartri/MCDDPM.

摘要：使用监督式深度学习方法检测脑部 MRI 扫描中的异常现象会面临解剖学多样性以及像素级注释的劳动密集型需求的挑战。去噪扩散概率模型 (DDPM) 及其变体如 pDDPM、mDDPM、cDDPM 等生成模型最近浮出水面，成为在脑部 MRI 扫描中执行无监督异常检测的强大替代方案。这些方法利用健康脑部的帧级标签在脑部 MRI 扫描中生成健康组织。在推理过程中，当异常（或不健康）扫描图像作为输入呈现时，这些模型会生成与输入异常扫描对应的健康扫描图像，而生成的健康扫描图像与原始异常扫描图像之间的差异图提供了异常组织的必要像素级识别。然而，DDPM、pDDPM 和 mDDPM 模型生成的健康图像存在保真度问题，并且包含没有医学意义的伪像。虽然 cDDPM 实现了稍微更好的保真度和伪像抑制，但它需要巨大的内存占用，并且比其他基于 DDPM 的模型在计算上更昂贵。在这项工作中，我们提出了一个称为多通道条件去噪扩散概率模型 (MCDDPM) 的 DDPM 改进版本，用于在脑部 MRI 扫描中进行无监督异常检测。我们提出的模型通过在训练过程中利用健康图像中的附加信息来实现高保真度，从而丰富了 DDPM 模型的表示能力，并且计算成本和内存需求与 DDPM、pDDPM 和 mDDPM 模型相当。在多个数据集（例如 BraTS20、BraTS21）上的实验结果证明了所提出方法的良好性能。代码可在 https://github.com/vivekkumartri/MCDDPM 获得。

##### **Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation**
2409.19531v1 by Hyojin Bae, Bongsu Kang, Chang-Eop Kim

This study examines the clinical decision-making processes in Traditional
East Asian Medicine (TEAM) by reinterpreting pattern identification (PI)
through the lens of dimensionality reduction. Focusing on the Eight Principle
Pattern Identification (EPPI) system and utilizing empirical data from the
Shang-Han-Lun, we explore the necessity and significance of prioritizing the
Exterior-Interior pattern in diagnosis and treatment selection. We test three
hypotheses: whether the Ext-Int pattern contains the most information about
patient symptoms, represents the most abstract and generalizable symptom
information, and facilitates the selection of appropriate herbal prescriptions.
Employing quantitative measures such as the abstraction index,
cross-conditional generalization performance, and decision tree regression, our
results demonstrate that the Exterior-Interior pattern represents the most
abstract and generalizable symptom information, contributing to the efficient
mapping between symptom and herbal prescription spaces. This research provides
an objective framework for understanding the cognitive processes underlying
TEAM, bridging traditional medical practices with modern computational
approaches. The findings offer insights into the development of AI-driven
diagnostic tools in TEAM and conventional medicine, with the potential to
advance clinical practice, education, and research.

摘要：本研究透過降維透視重新詮釋證候辨識（PI），探討傳統東亞醫學（TEAM）的臨床決策制定過程。我們專注於八綱證候辨識（EPPI）系統，並利用傷寒論的經驗資料，探討在診斷和治療選擇中優先考慮表裡證的必要性和重要性。我們檢驗了三個假設：表裡證是否包含最多關於患者症狀的資訊、是否代表最抽象且可概括的症狀資訊，以及是否能促進適當草藥處方的選擇。我們的結果採用了抽象指數、交叉條件概化效能和決策樹回歸等量化測量，證明表裡證代表最抽象且可概括的症狀資訊，有助於症狀與草藥處方空間之間的有效對應。本研究為理解 TEAM 背後的認知過程提供了客觀架構，結合傳統醫學實務與現代運算方法。研究結果提供了見解，有助於開發 TEAM 和傳統醫學中由 AI 驅動的診斷工具，並有潛力促進臨床實務、教育和研究。

##### **MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models**
2409.19492v1 by Vibhor Agarwal, Yiqiao Jin, Mohit Chandra, Munmun De Choudhury, Srijan Kumar, Nishanth Sastry

The remarkable capabilities of large language models (LLMs) in language
understanding and generation have not rendered them immune to hallucinations.
LLMs can still generate plausible-sounding but factually incorrect or
fabricated information. As LLM-empowered chatbots become popular, laypeople may
frequently ask health-related queries and risk falling victim to these LLM
hallucinations, resulting in various societal and healthcare implications. In
this work, we conduct a pioneering study of hallucinations in LLM-generated
responses to real-world healthcare queries from patients. We propose MedHalu, a
carefully crafted first-of-its-kind medical hallucination dataset with a
diverse range of health-related topics and the corresponding hallucinated
responses from LLMs with labeled hallucination types and hallucinated text
spans. We also introduce MedHaluDetect framework to evaluate capabilities of
various LLMs in detecting hallucinations. We also employ three groups of
evaluators -- medical experts, LLMs, and laypeople -- to study who are more
vulnerable to these medical hallucinations. We find that LLMs are much worse
than the experts. They also perform no better than laypeople and even worse in
few cases in detecting hallucinations. To fill this gap, we propose
expert-in-the-loop approach to improve hallucination detection through LLMs by
infusing expert reasoning. We observe significant performance gains for all the
LLMs with an average macro-F1 improvement of 6.3 percentage points for GPT-4.

摘要：大型語言模型 (LLM) 在語言理解和生成方面的卓越能力並未讓它們免於出現幻覺。LLM 仍然可以生成聽起來合理但事實上不正確或捏造的信息。隨著由 LLM 驅動的聊天機器人變得流行，外行人可能會頻繁詢問與健康相關的問題，並冒著成為這些 LLM 幻覺受害者的風險，從而產生各種社會和醫療保健影響。在這項工作中，我們對患者現實世界的醫療保健查詢中由 LLM 生成的回應中的幻覺進行了開創性的研究。我們提出了 MedHalu，這是一個精心製作的同類首創的醫學幻覺數據集，其中包含各種與健康相關的主題以及來自 LLM 的對應幻覺回應，並標記了幻覺類型和幻覺文本跨度。我們還引入了 MedHaluDetect 框架來評估各種 LLM 在檢測幻覺方面的能力。我們還聘請了三組評估人員——醫學專家、LLM 和外行人——來研究誰更容易受到這些醫療幻覺的影響。我們發現 LLM 遠不如專家。在檢測幻覺方面，它們的表現也不比外行人好，甚至在某些情況下表現得更糟。為了填補這一空白，我們提出了專家循環方法，通過注入專家推理來改進 LLM 的幻覺檢測。我們觀察到所有 LLM 的性能都有顯著提升，GPT-4 的平均宏觀 F1 提升了 6.3 個百分點。

##### **INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning**
2409.19467v1 by Pablo Romero, Lifeng Han, Goran Nenadic

Medication Extraction and Mining play an important role in healthcare NLP
research due to its practical applications in hospital settings, such as their
mapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this
work, we investigate state-of-the-art LLMs in text mining tasks on medications
and their related attributes such as dosage, route, strength, and adverse
effects. In addition, we explore different ensemble learning methods
(\textsc{Stack-Ensemble} and \textsc{Voting-Ensemble}) to augment the model
performances from individual LLMs. Our ensemble learning result demonstrated
better performances than individually fine-tuned base models BERT, RoBERTa,
RoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and
PubMedBERT across general and specific domains. Finally, we build up an entity
linking function to map extracted medical terminologies into the SNOMED-CT
codes and the British National Formulary (BNF) codes, which are further mapped
to the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit
and desktop applications are publicly available at
\url{https://github.com/HECTA-UoM/ensemble-NER}.

摘要：藥物萃取和探勘在醫療保健自然語言處理研究中扮演重要的角色，因為它在醫院環境中有實際應用，例如將它們對應到標準臨床知識庫（SNOMED-CT、BNF 等）。在這項工作中，我們探討了最先進的 LLM 在藥物及其相關屬性（例如劑量、途徑、強度和不良反應）的文字探勘任務。此外，我們探索了不同的整合學習方法（\textsc{Stack-Ensemble} 和 \textsc{Voting-Ensemble}）以增強個別 LLM 的模型效能。我們的整合學習結果證明了比個別微調基礎模型 BERT、RoBERTa、RoBERTa-L、BioBERT、BioClinicalBERT、BioMedRoBERTa、ClinicalBERT 和 PubMedBERT 在一般和特定領域中表現得更好。最後，我們建立了一個實體連結函數，將萃取的醫學術語對應到 SNOMED-CT 代碼和英國國家處方集 (BNF) 代碼，進一步對應到藥品和器材字典 (dm+d) 和 ICD。我們的模型工具組和桌面應用程式公開於\url{https://github.com/HECTA-UoM/ensemble-NER}。

##### **Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment**
2409.19366v1 by Tianyi Liu, Zhaorui Tan, Haochuan Jiang, Xi Yang, Kaizhu Huang

Brain tumor segmentation is often based on multiple magnetic resonance
imaging (MRI). However, in clinical practice, certain modalities of MRI may be
missing, which presents an even more difficult scenario. To cope with this
challenge, knowledge distillation has emerged as one promising strategy.
However, recent efforts typically overlook the modality gaps and thus fail to
learn invariant feature representations across different modalities. Such
drawback consequently leads to limited performance for both teachers and
students. To ameliorate these problems, in this paper, we propose a novel
paradigm that aligns latent features of involved modalities to a well-defined
distribution anchor. As a major contribution, we prove that our novel training
paradigm ensures a tight evidence lower bound, thus theoretically certifying
its effectiveness. Extensive experiments on different backbones validate that
the proposed paradigm can enable invariant feature representations and produce
a teacher with narrowed modality gaps. This further offers superior guidance
for missing modality students, achieving an average improvement of 1.75 on dice
score.

摘要：腦腫瘤分割通常基於多種磁共振影像 (MRI)。然而，在臨床實務中，某些 MRI 的方式可能缺失，這會構成更困難的情境。為了應對此一挑戰，知識蒸餾已成為一項有前途的策略。然而，最近的努力通常忽略方式的差距，因此無法學習跨不同方式的不變特徵表示。這樣的缺點導致教師和學生兩者的表現有限。為了改善這些問題，我們在本文中提出一個新的範例，將相關方式的潛在特徵與明確定義的分布錨點對齊。作為一項重大貢獻，我們證明我們新的訓練範例確保嚴謹的證據下界，從而理論上證明其有效性。在不同骨幹上的廣泛實驗驗證了所提出的範例能夠啟用不變特徵表示，並產生方式差距縮小的教師。這進一步為遺失方式的學生提供優異的指導，在骰子分數上平均提升 1.75。

##### **3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models**
2409.19330v1 by Hao Chen, Wei Zhao, Yingli Li, Tianyang Zhong, Yisong Wang, Youlan Shang, Lei Guo, Junwei Han, Tianming Liu, Jun Liu, Tuo Zhang

Medical image analysis is crucial in modern radiological diagnostics,
especially given the exponential growth in medical imaging data. The demand for
automated report generation systems has become increasingly urgent. While prior
research has mainly focused on using machine learning and multimodal language
models for 2D medical images, the generation of reports for 3D medical images
has been less explored due to data scarcity and computational complexities.
This paper introduces 3D-CT-GPT, a Visual Question Answering (VQA)-based
medical visual language model specifically designed for generating radiology
reports from 3D CT scans, particularly chest CTs. Extensive experiments on both
public and private datasets demonstrate that 3D-CT-GPT significantly
outperforms existing methods in terms of report accuracy and quality. Although
current methods are few, including the partially open-source CT2Rep and the
open-source M3D, we ensured fair comparison through appropriate data conversion
and evaluation methodologies. Experimental results indicate that 3D-CT-GPT
enhances diagnostic accuracy and report coherence, establishing itself as a
robust solution for clinical radiology report generation. Future work will
focus on expanding the dataset and further optimizing the model to enhance its
performance and applicability.

摘要：醫療影像分析在現代放射診斷中至關重要，特別是考慮到醫學影像資料的指數成長。對自動化報告產生系統的需求已變得越來越迫切。雖然先前的研究主要集中於使用機器學習和多模態語言模型進行 2D 醫療影像，但由於資料稀少和計算複雜度，3D 醫療影像的報告產生較少被探討。本文介紹 3D-CT-GPT，一種專門設計用於從 3D CT 掃描（特別是胸部 CT）產生放射科報告的基於視覺問答 (VQA) 的醫學視覺語言模型。在公共和私人資料集上的廣泛實驗表明，3D-CT-GPT 在報告準確性和品質方面顯著優於現有方法。雖然目前的方法很少，包括部分開源的 CT2Rep 和開源的 M3D，但我們透過適當的資料轉換和評估方法確保了公平的比較。實驗結果表明，3D-CT-GPT 增強了診斷準確性和報告一致性，確立了其作為臨床放射科報告產生的強大解決方案。未來的研究將專注於擴充資料集和進一步最佳化模型，以增強其效能和適用性。

##### **Secure Multiparty Generative AI**
2409.19120v1 by Manil Shrestha, Yashodha Ravichandran, Edward Kim

As usage of generative AI tools skyrockets, the amount of sensitive
information being exposed to these models and centralized model providers is
alarming. For example, confidential source code from Samsung suffered a data
leak as the text prompt to ChatGPT encountered data leakage. An increasing
number of companies are restricting the use of LLMs (Apple, Verizon, JPMorgan
Chase, etc.) due to data leakage or confidentiality issues. Also, an increasing
number of centralized generative model providers are restricting, filtering,
aligning, or censoring what can be used. Midjourney and RunwayML, two of the
major image generation platforms, restrict the prompts to their system via
prompt filtering. Certain political figures are restricted from image
generation, as well as words associated with women's health care, rights, and
abortion.
  In our research, we present a secure and private methodology for generative
artificial intelligence that does not expose sensitive data or models to
third-party AI providers. Our work modifies the key building block of modern
generative AI algorithms, e.g. the transformer, and introduces confidential and
verifiable multiparty computations in a decentralized network to maintain the
1) privacy of the user input and obfuscation to the output of the model, and 2)
introduce privacy to the model itself. Additionally, the sharding process
reduces the computational burden on any one node, enabling the distribution of
resources of large generative AI processes across multiple, smaller nodes. We
show that as long as there exists one honest node in the decentralized
computation, security is maintained. We also show that the inference process
will still succeed if only a majority of the nodes in the computation are
successful. Thus, our method offers both secure and verifiable computation in a
decentralized network.

摘要：<paragraph>隨著生成式 AI 工具的使用量激增，暴露給這些模型和集中式模型提供者的敏感資訊數量令人擔憂。例如，來自三星的機密原始碼發生資料外洩，因為 ChatGPT 的文字提示遇到了資料外洩。由於資料外洩或機密性問題，越來越多的公司正在限制使用 LLM（Apple、Verizon、JPMorgan Chase 等）。此外，越來越多的集中式生成模型提供者正在限制、過濾、調整或審查可以使用什麼。Midjourney 和 RunwayML 是兩個主要的影像生成平台，它們透過提示過濾限制系統的提示。某些政治人物被禁止生成影像，以及與婦女保健、權利和墮胎相關的字詞。
在我們的研究中，我們提出了一種安全且私密的生成式人工智慧方法，不會將敏感資料或模型暴露給第三方 AI 提供者。我們的研究修改了現代生成式 AI 演算法的主要建構區塊，例如Transformer，並在分散式網路中引入了機密且可驗證的多方運算，以維護 1) 使用者輸入的隱私和模型輸出的混淆，以及 2) 為模型本身引入隱私。此外，分片處理會降低任何一個節點的運算負擔，讓大型生成式 AI 處理的資源可以分布在多個較小的節點上。我們表明，只要在分散式運算中存在一個誠實的節點，就能維持安全性。我們也表明，如果運算中只有多數節點成功，推理程序仍然會成功。因此，我們的模型在分散式網路中提供了安全且可驗證的運算。</paragraph>

##### **Differential privacy for protecting patient data in speech disorder detection using deep learning**
2409.19078v1 by Soroosh Tayebi Arasteh, Mahshad Lotfinia, Paula Andrea Perez-Toro, Tomas Arias-Vergara, Juan Rafael Orozco-Arroyave, Maria Schuster, Andreas Maier, Seung Hee Yang

Speech pathology has impacts on communication abilities and quality of life.
While deep learning-based models have shown potential in diagnosing these
disorders, the use of sensitive data raises critical privacy concerns. Although
differential privacy (DP) has been explored in the medical imaging domain, its
application in pathological speech analysis remains largely unexplored despite
the equally critical privacy concerns. This study is the first to investigate
DP's impact on pathological speech data, focusing on the trade-offs between
privacy, diagnostic accuracy, and fairness. Using a large, real-world dataset
of 200 hours of recordings from 2,839 German-speaking participants, we observed
a maximum accuracy reduction of 3.85% when training with DP with a privacy
budget, denoted by {\epsilon}, of 7.51. To generalize our findings, we
validated our approach on a smaller dataset of Spanish-speaking Parkinson's
disease patients, demonstrating that careful pretraining on large-scale
task-specific datasets can maintain or even improve model accuracy under DP
constraints. We also conducted a comprehensive fairness analysis, revealing
that reasonable privacy levels (2<{\epsilon}<10) do not introduce significant
gender bias, though age-related disparities may require further attention. Our
results suggest that DP can effectively balance privacy and utility in speech
disorder detection, but also highlight the unique challenges in the speech
domain, particularly regarding the privacy-fairness trade-off. This provides a
foundation for future work to refine DP methodologies and address fairness
across diverse patient groups in real-world deployments.

摘要：<paragraph>言語病理學對溝通能力和生活品質有影響。
儘管基於深度學習的模型在診斷這些疾病方面已展現潛力，但敏感資料的使用引發了嚴重的隱私問題。儘管差分隱私 (DP) 已在醫學影像領域中得到探討，但其在病理語言分析中的應用仍未得到充分探討，儘管其隱私問題同樣嚴重。本研究首次探討了 DP 對病理語言資料的影響，重點關注隱私、診斷準確性和公平性之間的權衡。我們使用了一個大型的真實世界資料集，其中包含來自 2,839 名德語參與者的 200 小時錄音，我們觀察到在使用 DP 進行訓練時，隱私預算（以 {\epsilon} 表示）為 7.51 時，準確度最高降低了 3.85%。為了推廣我們的發現，我們在一個規模較小的西班牙語帕金森病患者資料集上驗證了我們的做法，證明了在大規模特定任務資料集上進行仔細的預訓練可以在 DP 約束下維持甚至提高模型準確度。我們還進行了全面的公平性分析，結果顯示合理的隱私等級（2<{\epsilon}<10）不會引入顯著的性別偏見，儘管與年齡相關的差異可能需要進一步關注。我們的結果表明，DP 可以有效地在語言障礙檢測中平衡隱私和效用，但也突出了語言領域中獨特的挑戰，特別是關於隱私公平性的權衡。這為未來的研究提供了基礎，以完善 DP 方法並在實際部署中解決不同患者群體中的公平性問題。</paragraph>

##### **AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**
2409.18924v1 by Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan

Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p<0.1), and stability (ANOVA F-value
0.782, p<0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.

摘要：<paragraph>模擬病人系統在現代醫學教育和研究中扮演著至關重要的角色，提供安全、整合的學習環境，並支援臨床決策模擬。大型語言模型 (LLM) 能夠複製醫療狀況和醫病互動，進而以高保真度和低成本提升模擬病人系統。然而，確保這些系統的有效性和可信度仍然是一項挑戰，因為它們需要一個龐大、多元且精確的病人知識庫，以及一種強健且穩定的知識傳播方式。在此，我們開發了 AIPatient，一個進階的模擬病人系統，其以 AIPatient 知識圖譜 (AIPatient KG) 作為輸入，並以推理檢索增強生成 (Reasoning RAG) 代理工作流程作為生成主幹。AIPatient KG 從密集照護醫學資訊市集 (MIMIC)-III 資料庫中的電子健康紀錄 (EHR) 中抽取資料，產生一個臨床多元且相關的 1,495 位病患群組，且具有高度的知識庫有效性 (F1 0.89)。Reasoning RAG 運用六個 LLM 驅動的代理，涵蓋檢索、KG 查詢生成、抽象化、檢查器、重寫和摘要等任務。此代理架構在基於 EHR 的醫療問答 (QA) 中達到 94.15% 的整體準確度，優於未使用代理或僅部分整合代理的基準。我們的系統還具備高度可讀性 (中位數 Flesch 閱讀簡易度 77.23；中位數 Flesch Kincaid 等級 5.6)、強健性 (ANOVA F 值 0.6126，p<0.1) 和穩定性 (ANOVA F 值 0.782，p<0.1)。AIPatient 系統令人滿意的效能突顯了其支援廣泛應用程式的潛力，包括醫學教育、模型評估和系統整合。</paragraph>

##### **Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**
2409.18878v1 by Zehan Li, Yan Hu, Scott Lane, Salih Selek, Lokesh Shahani, Rodrigo Machado-Vieira, Jair Soares, Hua Xu, Hongfang Liu, Ming Huang

Accurate identification and categorization of suicidal events can yield
better suicide precautions, reducing operational burden, and improving care
quality in high-acuity psychiatric settings. Pre-trained language models offer
promise for identifying suicidality from unstructured clinical narratives. We
evaluated the performance of four BERT-based models using two fine-tuning
strategies (multiple single-label and single multi-label) for detecting
coexisting suicidal events from 500 annotated psychiatric evaluation notes. The
notes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure
to suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed
other models using binary relevance (acc=0.86, F1=0.78). MentalBERT (F1=0.74)
also exceeded BioClinicalBERT (F1=0.72). RoBERTa fine-tuned with a single
multi-label classifier further improved performance (acc=0.88, F1=0.81),
highlighting that models pre-trained on domain-relevant data and the single
multi-label classification strategy enhance efficiency and performance.
  Keywords: EHR-based Phynotyping; Natural Language Processing; Secondary Use
of EHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental
Health

摘要：準確識別和分類自殺事件可以產生更好的自殺預防措施，減少運作負擔，並提高高敏銳度精神科環境中的照護品質。預先訓練的語言模型提供從非結構化臨床敘述中辨識自殺傾向的承諾。我們評估了四個基於 BERT 的模型的效能，使用兩種微調策略（多個單標籤和單個多標籤）來從 500 個註解的精神科評估備忘錄中偵測共存的自殺事件。這些備忘錄標記為自殺意念 (SI)、自殺企圖 (SA)、暴露於自殺 (ES) 和非自殺性自傷 (NSSI)。RoBERTa 使用二元關聯性表現優於其他模型（acc=0.86，F1=0.78）。MentalBERT (F1=0.74) 也超過 BioClinicalBERT (F1=0.72)。使用單一多標籤分類器微調的 RoBERTa 進一步改善了效能（acc=0.88，F1=0.81），強調預先在與領域相關的資料上訓練的模型和單一多標籤分類策略可提升效率和效能。關鍵字：基於電子病歷的表型分析；自然語言處理；電子病歷資料的二次使用；自殺分類；基於 BERT 的模型；精神病學；心理健康

##### **Early diagnosis of Alzheimer's disease from MRI images with deep learning model**
2409.18814v1 by Sajjad Aghasi Javid, Mahmood Mohassel Feghhi

It is acknowledged that the most common cause of dementia worldwide is
Alzheimer's disease (AD). This condition progresses in severity from mild to
severe and interferes with people's everyday routines. Early diagnosis plays a
critical role in patient care and clinical trials. Convolutional neural
networks (CNN) are used to create a framework for identifying specific disease
features from MRI scans Classification of dementia involves approaches such as
medical history review, neuropsychological tests, and magnetic resonance
imaging (MRI). However, the image dataset obtained from Kaggle faces a
significant issue of class imbalance, which requires equal distribution of
samples from each class to address. In this article, to address this imbalance,
the Synthetic Minority Oversampling Technique (SMOTE) is utilized. Furthermore,
a pre-trained convolutional neural network has been applied to the DEMNET
dementia network to extract key features from AD images. The proposed model
achieved an impressive accuracy of 98.67%.

摘要：全球公認最常見的失智症成因是
阿茲海默症（AD）。這種疾病的嚴重程度從輕度到重度，並會干擾人們的日常作息。早期診斷在患者照護和臨床試驗中扮演至關重要的角色。卷積神經網路（CNN）用於建立一個架構，以從 MRI 掃描中辨識特定的疾病特徵。失智症的分類涉及病歷回顧、神經心理測驗和磁振造影（MRI）等方法。然而，從 Kaggle 取得的影像資料集面臨類別不平衡的重大問題，這需要每個類別的樣本數量相等才能解決。在本文中，為了解決這種不平衡，使用了合成少數過採樣技術（SMOTE）。此外，已將預先訓練好的卷積神經網路應用於 DEMNET 失智症網路，以從 AD 影像中萃取關鍵特徵。所提出的模型達到了令人印象深刻的 98.67% 準確率。

##### **State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**
2409.18769v1 by George R. Nahass, Ghasem Yazdanpanah, Madison Cheung, Alex Palacios, Jeffery Peterson, Kevin Heinze, Sasha Hubschman, Chad A. Purnell, Pete Setabutr, Ann Q. Tran, Darvin Yi

Periorbital distances and features around the eyes and lids hold valuable
information for disease quantification and monitoring of surgical and medical
intervention. These distances are commonly measured manually, a process that is
both subjective and highly time-consuming. Here, we set out to developed three
deep-learning methods for segmentation and periorbital distance prediction, and
also evaluate the utility of periorbital distances for disease classification.
The MAE of our deep learning predicted distances was less than or very close to
the error observed between trained human annotators. We compared our models to
the current state-of-the-art (SOTA) method for periorbital distance prediction
and found that our methods outperformed SOTA on all of our datasets on all but
one periorbital measurement. We also show that robust segmentation can be
achieved on diseased eyes using models trained on open-source, healthy eyes,
and that periorbital distances have can be used as high-quality features in
downstream classification models. Leveraging segmentation networks as
intermediary steps in classification has broad implications for increasing the
generalizability of classification models in ophthalmic plastic and
craniofacial surgery by avoiding the out-of-distribution problem observed in
traditional convolutional neural networks.

摘要：眼眶周圍的距離和眼睛及眼瞼周圍的特徵對於疾病量化以及外科和醫療介入的監控具有重要的資訊。這些距離通常是手動測量，這是一個主觀且非常耗時的過程。在此，我們著手開發三種深度學習方法，用於分割和眼眶周圍距離預測，並評估眼眶周圍距離對於疾病分類的效用。我們的深度學習預測距離的 MAE 小於或非常接近訓練的人類註解者之間觀察到的誤差。我們將我們的模型與眼眶周圍距離預測的當前最先進 (SOTA) 方法進行比較，發現我們的模型在除了一種眼眶周圍測量外，在我們所有資料集上都優於 SOTA。我們還表明，可以使用在開放原始碼健康眼睛上訓練的模型在患病的眼睛上實現穩健的分割，並且眼眶周圍距離可用作下游分類模型中的高品質特徵。利用分割網路作為分類中的中間步驟對於提高眼科整形和顱面外科中分類模型的概括性具有廣泛的意義，因為避免了在傳統卷積神經網路中觀察到的分布外問題。

##### **Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**
2409.18715v1 by Salma Hassan, Hamad Al Hammadi, Ibrahim Mohammed, Muhammad Haris Khan

The early detection and nuanced subtype classification of non-small cell lung
cancer (NSCLC), a predominant cause of cancer mortality worldwide, is a
critical and complex issue. In this paper, we introduce an innovative
integration of multi-modal data, synthesizing fused medical imaging (CT and PET
scans) with clinical health records and genomic data. This unique fusion
methodology leverages advanced machine learning models, notably MedClip and
BEiT, for sophisticated image feature extraction, setting a new standard in
computational oncology. Our research surpasses existing approaches, as
evidenced by a substantial enhancement in NSCLC detection and classification
precision. The results showcase notable improvements across key performance
metrics, including accuracy, precision, recall, and F1-score. Specifically, our
leading multi-modal classifier model records an impressive accuracy of 94.04%.
We believe that our approach has the potential to transform NSCLC diagnostics,
facilitating earlier detection and more effective treatment planning and,
ultimately, leading to superior patient outcomes in lung cancer care.

摘要：早期檢測和細緻的非小細胞肺癌 (NSCLC) 亞型分類，是全球癌症死亡率的主要原因，是一個關鍵且複雜的問題。在本文中，我們介紹了一個創新的多模式數據整合，將融合的醫學影像 (CT 和 PET 掃描) 與臨床健康記錄和基因組數據合成。這種獨特的融合方法利用了先進的機器學習模型，特別是 MedClip 和 BEiT，進行複雜的影像特徵提取，為計算腫瘤學設定了新的標準。我們的研究超越了現有方法，這從 NSCLC 檢測和分類精度的顯著提高中得到證明。結果展示了在關鍵效能指標（包括準確度、精確度、召回率和 F1 分數）上的顯著改進。具體來說，我們領先的多模式分類器模型記錄了令人印象深刻的 94.04% 準確度。我們相信我們的做法有潛力轉變 NSCLC 診斷，促進早期檢測和更有效的治療計畫，並最終改善肺癌照護中的患者預後。

##### **Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow**
2409.18628v1 by Marvin Tom Teichmann, Manasi Datar, Lisa Kratzke, Fernando Vega, Florin C. Ghesu

The precision of contouring target structures and organs-at-risk (OAR) in
radiotherapy planning is crucial for ensuring treatment efficacy and patient
safety. Recent advancements in deep learning (DL) have significantly improved
OAR contouring performance, yet the reliability of these models, especially in
the presence of out-of-distribution (OOD) scenarios, remains a concern in
clinical settings. This application study explores the integration of epistemic
uncertainty estimation within the OAR contouring workflow to enable OOD
detection in clinically relevant scenarios, using specifically compiled data.
Furthermore, we introduce an advanced statistical method for OOD detection to
enhance the methodological framework of uncertainty estimation. Our empirical
evaluation demonstrates that epistemic uncertainty estimation is effective in
identifying instances where model predictions are unreliable and may require an
expert review. Notably, our approach achieves an AUC-ROC of 0.95 for OOD
detection, with a specificity of 0.95 and a sensitivity of 0.92 for implant
cases, underscoring its efficacy. This study addresses significant gaps in the
current research landscape, such as the lack of ground truth for uncertainty
estimation and limited empirical evaluations. Additionally, it provides a
clinically relevant application of epistemic uncertainty estimation in an
FDA-approved and widely used clinical solution for OAR segmentation from
Varian, a Siemens Healthineers company, highlighting its practical benefits.

摘要：<paragraph>在放射治療規劃中，輪廓化標靶結構和器官風險（OAR）的精確度對於確保治療效果和患者安全至關重要。深度學習（DL）的最新進展顯著改善了 OAR 輪廓化效能，但這些模型的可靠性，特別是在出現分布外（OOD）場景時，在臨床環境中仍然令人擔憂。本應用研究探討了將認識不確定性估計整合到 OAR 輪廓化工作流程中，以使用特別編譯的資料在臨床上相關的場景中啟用 OOD 偵測。此外，我們引入了一種先進的統計方法進行 OOD 偵測，以增強不確定性估計的方法論架構。我們的實證評估證明，認識不確定性估計在識別模型預測不可靠且可能需要專家審查的情況方面是有效的。值得注意的是，我們的做法對於植入物案例達到了 0.95 的 OOD 偵測 AUC-ROC，特異性為 0.95，靈敏度為 0.92，突顯了其功效。這項研究解決了當前研究領域中的重大差距，例如缺乏不確定性估計的基本原理和有限的實證評估。此外，它提供了一個在 FDA 批准且廣泛使用的臨床解決方案中認識不確定性估計在 OAR 分割方面的臨床相關應用，該解決方案來自西門子醫療公司旗下的 Varian，突顯了其實際效益。</paragraph>

##### **Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications**
2409.18454v1 by Aditi Godbole, Jabin Geevarghese George, Smita Shandilya

The rapid increase in unstructured data across various fields has made
multi-document comprehension and summarization a critical task. Traditional
approaches often fail to capture relevant context, maintain logical
consistency, and extract essential information from lengthy documents. This
paper explores the use of Long-context Large Language Models (LLMs) for
multi-document summarization, demonstrating their exceptional capacity to grasp
extensive connections, provide cohesive summaries, and adapt to various
industry domains and integration with enterprise applications/systems. The
paper discusses the workflow of multi-document summarization for effectively
deploying long-context LLMs, supported by case studies in legal applications,
enterprise functions such as HR, finance, and sourcing, as well as in the
medical and news domains. These case studies show notable enhancements in both
efficiency and accuracy. Technical obstacles, such as dataset diversity, model
scalability, and ethical considerations like bias mitigation and factual
accuracy, are carefully analyzed. Prospective research avenues are suggested to
augment the functionalities and applications of long-context LLMs, establishing
them as pivotal tools for transforming information processing across diverse
sectors and enterprise applications.

摘要：隨著非結構化資料在各個領域快速增加，多文件理解和摘要已成為一項重要的任務。傳統方法通常無法擷取相關脈絡、維持邏輯一致性，以及從冗長的文件中萃取必要資訊。本文探討使用長脈絡大型語言模型 (LLM) 進行多文件摘要，展示其掌握廣泛關聯、提供有凝聚力的摘要，以及適應各種產業領域和整合企業應用程式/系統的非凡能力。本文探討多文件摘要的工作流程，以有效部署長脈絡 LLM，並以法律應用、企業功能（例如人力資源、財務和採購），以及醫療和新聞領域的案例研究作為佐證。這些案例研究顯示出效率和準確性都有顯著的提升。技術障礙，例如資料集多樣性、模型可擴充性，以及道德考量（例如減輕偏差和事實準確性）都經過仔細分析。本文建議未來的研究方向，以擴充長脈絡 LLM 的功能和應用，使其成為轉變不同產業和企業應用程式資訊處理方式的關鍵工具。

##### **Physics Augmented Tuple Transformer for Autism Severity Level Detection**
2409.18438v1 by Chinthaka Ranasingha, Harshala Gammulle, Tharindu Fernando, Sridha Sridharan, Clinton Fookes

Early diagnosis of Autism Spectrum Disorder (ASD) is an effective and
favorable step towards enhancing the health and well-being of children with
ASD. Manual ASD diagnosis testing is labor-intensive, complex, and prone to
human error due to several factors contaminating the results. This paper
proposes a novel framework that exploits the laws of physics for ASD severity
recognition. The proposed physics-informed neural network architecture encodes
the behaviour of the subject extracted by observing a part of the
skeleton-based motion trajectory in a higher dimensional latent space. Two
decoders, namely physics-based and non-physics-based decoder, use this latent
embedding and predict the future motion patterns. The physics branch leverages
the laws of physics that apply to a skeleton sequence in the prediction process
while the non-physics-based branch is optimised to minimise the difference
between the predicted and actual motion of the subject. A classifier also
leverages the same latent space embeddings to recognise the ASD severity. This
dual generative objective explicitly forces the network to compare the actual
behaviour of the subject with the general normal behaviour of children that are
governed by the laws of physics, aiding the ASD recognition task. The proposed
method attains state-of-the-art performance on multiple ASD diagnosis
benchmarks. To illustrate the utility of the proposed framework beyond the task
ASD diagnosis, we conduct a third experiment using a publicly available
benchmark for the task of fall prediction and demonstrate the superiority of
our model.

摘要：自閉症譜系障礙 (ASD) 的早期診斷是改善 ASD 兒童健康和福祉的有效且有利的一步。手動 ASD 診斷測試勞動密集、複雜，且容易因多種污染結果的因素而產生人為錯誤。本文提出了一個新穎的框架，利用物理定律來識別 ASD 的嚴重程度。所提出的物理訊息神經網路架構編碼了通過觀察基於骨架的運動軌跡的一部分在高維潛在空間中提取的主體行為。兩個解碼器，即基於物理和非基於物理的解碼器，使用此潛在嵌入並預測未來的運動模式。物理分支在預測過程中利用適用於骨架序列的物理定律，而非基於物理的分支則經過最佳化以最小化受試者預測和實際運動之間的差異。分類器也利用相同的潛在空間嵌入來識別 ASD 的嚴重程度。這種雙重生成目標明確地迫使網路將受試者的實際行為與受物理定律支配的兒童一般正常行為進行比較，從而有助於 ASD 識別任務。所提出的方法在多個 ASD 診斷基準上達到了最先進的效能。為了說明所提出的框架在 ASD 診斷任務之外的效用，我們使用公開可用的跌倒預測任務基準進行了第三個實驗，並展示了我們模型的優越性。

##### **DRL-STNet: Unsupervised Domain Adaptation for Cross-modality Medical Image Segmentation via Disentangled Representation Learning**
2409.18340v1 by Hui Lin, Florian Schiffers, Santiago López-Tapia, Neda Tavakoli, Daniel Kim, Aggelos K. Katsaggelos

Unsupervised domain adaptation (UDA) is essential for medical image
segmentation, especially in cross-modality data scenarios. UDA aims to transfer
knowledge from a labeled source domain to an unlabeled target domain, thereby
reducing the dependency on extensive manual annotations. This paper presents
DRL-STNet, a novel framework for cross-modality medical image segmentation that
leverages generative adversarial networks (GANs), disentangled representation
learning (DRL), and self-training (ST). Our method leverages DRL within a GAN
to translate images from the source to the target modality. Then, the
segmentation model is initially trained with these translated images and
corresponding source labels and then fine-tuned iteratively using a combination
of synthetic and real images with pseudo-labels and real labels. The proposed
framework exhibits superior performance in abdominal organ segmentation on the
FLARE challenge dataset, surpassing state-of-the-art methods by 11.4% in the
Dice similarity coefficient and by 13.1% in the Normalized Surface Dice metric,
achieving scores of 74.21% and 80.69%, respectively. The average running time
is 41 seconds, and the area under the GPU memory-time curve is 11,292 MB. These
results indicate the potential of DRL-STNet for enhancing cross-modality
medical image segmentation tasks.

摘要：無監督域適應 (UDA) 對醫學影像分割至關重要，特別是在跨模態數據場景中。UDA 旨在將標記來源域的知識轉移到未標記目標域，從而減少對大量人工標註的依賴。本文提出 DRL-STNet，這是一個用於跨模態醫學影像分割的新穎架構，它利用生成對抗網路 (GAN)、解糾纏表示學習 (DRL) 和自我訓練 (ST)。我們的模型在 GAN 中利用 DRL 將影像從來源轉換到目標模態。然後，分割模型最初使用這些轉換後的影像和對應的來源標籤進行訓練，然後使用合成影像和帶有偽標籤和真實標籤的真實影像的組合進行反覆微調。所提出的架構在 FLARE 挑戰資料集上的腹部器官分割中表現出優異的效能，在 Dice 相似係數上超越現有技術 11.4%，在標準化表面 Dice 指標上超越 13.1%，分別達到 74.21% 和 80.69% 的分數。平均執行時間為 41 秒，GPU 記憶體時間曲線下的面積為 11,292 MB。這些結果表明 DRL-STNet 在增強跨模態醫學影像分割任務方面具有潛力。

##### **Cross-Institutional Structured Radiology Reporting for Lung Cancer Screening Using a Dynamic Template-Constrained Large Language Model**
2409.18319v1 by Chuang Niu, Parisa Kaviani, Qing Lyu, Mannudeep K. Kalra, Christopher T. Whitlow, Ge Wang

Structured radiology reporting is advantageous for optimizing clinical
workflows and patient outcomes. Current LLMs in creating structured reports
face the challenges of formatting errors, content hallucinations, and privacy
leakage concerns when uploaded to external servers. We aim to develop an
enhanced open-source LLM for creating structured and standardized LCS reports
from free-text descriptions. After institutional IRB approvals, 5,442
de-identified LCS reports from two institutions were retrospectively analyzed.
500 reports were randomly selected from the two institutions evenly and then
manually labeled for evaluation. Two radiologists from the two institutions
developed a standardized template including 29 features for lung nodule
reporting. We proposed template-constrained decoding to enhance
state-of-the-art open-source LLMs, including LLAMA, Qwen, and Mistral. The LLM
performance was extensively evaluated in terms of F1 score, confidence
interval, McNemar test, and z-test. Based on the structured reports created
from the large-scale dataset, a nodule-level retrieval system was prototyped
and an automatic statistical analysis was performed. Our software,
vLLM-structure, is publicly available for local deployment with enhanced LLMs.
Our template-constrained decoding approach consistently enhanced the LLM
performance on multi-institutional datasets, with neither formatting errors nor
content hallucinations. Our method improved the best open-source LLAMA-3.1 405B
by up to 10.42%, and outperformed GPT-4o by 17.19%. A novel nodule retrieval
system was successfully prototyped and demonstrated on a large-scale multimodal
database using our enhanced LLM technologies. The automatically derived
statistical distributions were closely consistent with the prior findings in
terms of nodule type, location, size, status, and Lung-RADS.

摘要：結構化放射報告有利於優化臨床工作流程和患者結果。當前 LLM 在建立結構化報告時，在格式錯誤、內容幻覺和隱私洩露問題上，面臨上傳至外部伺服器的挑戰。我們的目標是開發一個增強的開源 LLM，用於根據自由文字說明建立結構化且標準化的 LCS 報告。在獲得機構 IRB 批准後，回顧性分析了來自兩個機構的 5,442 份去識別化 LCS 報告。從兩個機構中隨機選取 500 份報告，然後手動標記以進行評估。來自兩個機構的兩名放射科醫師開發了一個標準化範本，其中包含 29 個肺結節報告功能。我們提出了範本約束解碼，以增強最先進的開源 LLM，包括 LLAMA、Qwen 和 Mistral。LLM 效能根據 F1 分數、信心區間、McNemar 檢定和 z 檢定進行廣泛評估。根據從大型資料集建立的結構化報告，建立了結節層級檢索系統並執行自動統計分析。我們的軟體 vLLM-structure 可公開使用，並可與增強的 LLM 搭配進行本地部署。我們的範本約束解碼方法持續增強 LLM 在多機構資料集上的效能，既沒有格式錯誤，也沒有內容幻覺。我們的技術將最佳開源 LLAMA-3.1 405B 提升了 10.42%，並超越了 GPT-4o 17.19%。使用我們增強的 LLM 技術，成功建立了一個新穎的結節檢索系統，並在大型多模式資料庫上進行了展示。自動衍生的統計分佈與先前的發現非常一致，包括結節類型、位置、大小、狀態和 Lung-RADS。

##### **Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams**
2409.18290v1 by Yuexing Hao, Jason M. Holmes, Jared Hobson, Alexandra Bennett, Daniel K. Ebner, David M. Routman, Satomi Shiraishi, Samir H. Patel, Nathan Y. Yu, Chris L. Hallemeier, Brooke E. Ball, Mark R. Waddle, Wei Liu

In-basket message interactions play a crucial role in physician-patient
communication, occurring during all phases (pre-, during, and post) of a
patient's care journey. However, responding to these patients' inquiries has
become a significant burden on healthcare workflows, consuming considerable
time for clinical care teams. To address this, we introduce RadOnc-GPT, a
specialized Large Language Model (LLM) powered by GPT-4 that has been designed
with a focus on radiotherapeutic treatment of prostate cancer with advanced
prompt engineering, and specifically designed to assist in generating
responses. We integrated RadOnc-GPT with patient electronic health records
(EHR) from both the hospital-wide EHR database and an internal,
radiation-oncology-specific database. RadOnc-GPT was evaluated on 158
previously recorded in-basket message interactions. Quantitative natural
language processing (NLP) analysis and two grading studies with clinicians and
nurses were used to assess RadOnc-GPT's responses. Our findings indicate that
RadOnc-GPT slightly outperformed the clinical care team in "Clarity" and
"Empathy," while achieving comparable scores in "Completeness" and
"Correctness." RadOnc-GPT is estimated to save 5.2 minutes per message for
nurses and 2.4 minutes for clinicians, from reading the inquiry to sending the
response. Employing RadOnc-GPT for in-basket message draft generation has the
potential to alleviate the workload of clinical care teams and reduce
healthcare costs by producing high-quality, timely responses.

摘要：收件匣訊息互動在醫師與病患溝通中扮演著至關重要的角色，發生在病患照護旅程的各個階段（事前、事中和事後）。然而，回應這些病患的詢問已成為醫療工作流程的重大負擔，耗費臨床照護團隊大量時間。為了解決這個問題，我們引進 RadOnc-GPT，這是一個由 GPT-4 提供技術支援的專業大型語言模型 (LLM)，其設計重點在於透過進階提示工程技術對攝護腺癌進行放射治療，並特別設計用於協助產生回應。我們將 RadOnc-GPT 整合到病患電子健康紀錄 (EHR) 中，這些紀錄來自於全院的 EHR 資料庫和一個內部的放射腫瘤專用資料庫。RadOnc-GPT 針對 158 則先前記錄的收件匣訊息互動進行評估。我們使用量化自然語言處理 (NLP) 分析和兩項評分研究（由臨床醫師和護理師進行）來評估 RadOnc-GPT 的回應。我們的研究結果顯示，RadOnc-GPT 在「清晰度」和「同理心」方面表現略優於臨床照護團隊，同時在「完整性」和「正確性」方面達到相當的分數。估計 RadOnc-GPT 可為護理師節省每則訊息 5.2 分鐘，為臨床醫師節省 2.4 分鐘，從閱讀詢問到發送回應。採用 RadOnc-GPT 來產生收件匣訊息草稿有潛力減輕臨床照護團隊的工作負擔，並透過產生高品質、及時的回應來降低醫療保健成本。

##### **Evaluation of Large Language Models for Summarization Tasks in the Medical Domain: A Narrative Review**
2409.18170v1 by Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First, Frank J. Liao, Cherodeep Goswami, Brian Patterson, Majid Afshar

Large Language Models have advanced clinical Natural Language Generation,
creating opportunities to manage the volume of medical text. However, the
high-stakes nature of medicine requires reliable evaluation, which remains a
challenge. In this narrative review, we assess the current evaluation state for
clinical summarization tasks and propose future directions to address the
resource constraints of expert human evaluation.

摘要：大型語言模型促進了臨床自然語言生成，
創造了管理大量醫療文本的機會。然而，
醫學的高風險性質需要可靠的評估，這仍然是一個
挑戰。在這個敘述性回顧中，我們評估了
臨床摘要任務的當前評估狀態，並提出未來的方向，以解決
專家人類評估的資源限制。

##### **Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography**
2409.18119v1 by Yuexi Du, John Onofrey, Nicha C. Dvornek

Contrastive Language-Image Pre-training (CLIP) shows promise in medical image
analysis but requires substantial data and computational resources. Due to
these restrictions, existing CLIP applications in medical imaging focus mainly
on modalities like chest X-rays that have abundant image-report data available,
leaving many other important modalities under-explored. Here, we propose the
first adaptation of the full CLIP model to mammography, which presents
significant challenges due to labeled data scarcity, high-resolution images
with small regions of interest, and data imbalance. We first develop a
specialized supervision framework for mammography that leverages its multi-view
nature. Furthermore, we design a symmetric local alignment module to better
focus on detailed features in high-resolution images. Lastly, we incorporate a
parameter-efficient fine-tuning approach for large language models pre-trained
with medical knowledge to address data limitations. Our multi-view and
multi-scale alignment (MaMA) method outperforms state-of-the-art baselines for
three different tasks on two large real-world mammography datasets, EMBED and
RSNA-Mammo, with only 52% model size compared with the largest baseline.

摘要：對比語言影像預訓練 (CLIP) 在醫學影像分析中展現潛力，但需要大量的資料和運算資源。由於這些限制，現有的 CLIP 在醫學影像中的應用主要集中在胸部 X 光等有豐富影像報告資料的模式，導致許多其他重要的模式未被充分探索。在此，我們提出將完整的 CLIP 模型首次適應於乳房攝影，由於標籤資料稀少、高解析度影像中感興趣區域較小，以及資料不平衡，這提出了重大的挑戰。我們首先開發了一個專門的監督架構用於乳房攝影，利用其多視圖的特性。此外，我們設計了一個對稱局部對齊模組，以更好地聚焦於高解析度影像中的詳細特徵。最後，我們結合了一個參數高效的微調方法，用於預先訓練具有醫學知識的大型語言模型，以解決資料限制。我們的多視圖和多尺度對齊 (MaMA) 方法在兩個大型真實世界乳房攝影資料集 EMBED 和 RSNA-Mammo 的三個不同任務中優於現有技術基線，而模型大小僅為最大基線的 52%。

##### **CRoP: Context-wise Robust Static Human-Sensing Personalization**
2409.17994v2 by Sawinder Kaur, Avery Gump, Jingyu Xin, Yi Xiao, Harshit Sharma, Nina R Benway, Jonathan L Preston, Asif Salekin

The advancement in deep learning and internet-of-things have led to diverse
human sensing applications. However, distinct patterns in human sensing,
influenced by various factors or contexts, challenge generic neural network
model's performance due to natural distribution shifts. To address this,
personalization tailors models to individual users. Yet most personalization
studies overlook intra-user heterogeneity across contexts in sensory data,
limiting intra-user generalizability. This limitation is especially critical in
clinical applications, where limited data availability hampers both
generalizability and personalization. Notably, intra-user sensing attributes
are expected to change due to external factors such as treatment progression,
further complicating the challenges. This work introduces CRoP, a novel static
personalization approach using an off-the-shelf pre-trained model and pruning
to optimize personalization and generalization. CRoP shows superior
personalization effectiveness and intra-user robustness across four
human-sensing datasets, including two from real-world health domains,
highlighting its practical and social impact. Additionally, to support CRoP's
generalization ability and design choices, we provide empirical justification
through gradient inner product analysis, ablation studies, and comparisons
against state-of-the-art baselines.

摘要：深度學習和物聯網的進步已導致各種人類感測應用。然而，受各種因素或情境影響的人類感測中的不同模式，由於自然分佈轉移，對通用神經網路模型的效能構成挑戰。為了解決此問題，個人化會根據個別使用者調整模型。然而，大多數個人化研究忽略了感測資料中跨情境內的使用者內部異質性，這限制了使用者內部的一般化能力。此限制在臨床應用中特別關鍵，因為資料可用性有限會阻礙一般化能力和個人化。值得注意的是，由於治療進展等外部因素，預計使用者內部感測屬性會發生變化，進一步使挑戰複雜化。本研究引入了 CRoP，一種使用現成的預訓練模型和剪枝來最佳化個人化和一般化的創新靜態個人化方法。CRoP 在四個人類感測資料集（包括兩個來自真實世界健康領域的資料集）中展現出優異的個人化效能和使用者內部穩健性，突顯其實用性和社會影響。此外，為了支援 CRoP 的一般化能力和設計選擇，我們透過梯度內積分析、消融研究和與最新基準的比較提供經驗依據。

##### **Supervised Learning Model for Key Frame Identification from Cow Teat Videos**
2409.18797v1 by Minghao Wang, Pinxue Lin

This paper proposes a method for improving the accuracy of mastitis risk
assessment in cows using neural networks and video analysis. Mastitis, an
infection of the udder tissue, is a critical health problem for cows and can be
detected by examining the cow's teat. Traditionally, veterinarians assess the
health of a cow's teat during the milking process, but this process is limited
in time and can weaken the accuracy of the assessment. In commercial farms,
cows are recorded by cameras when they are milked in the milking parlor. This
paper uses a neural network to identify key frames in the recorded video where
the cow's udder appears intact. These key frames allow veterinarians to have
more flexible time to perform health assessments on the teat, increasing their
efficiency and accuracy. However, there are challenges in using cow teat video
for mastitis risk assessment, such as complex environments, changing cow
positions and postures, and difficulty in identifying the udder from the video.
To address these challenges, a fusion distance and an ensemble model are
proposed to improve the performance (F-score) of identifying key frames from
cow teat videos. The results show that these two approaches improve performance
compared to using a single distance measure or model.

摘要：本文提出了一种利用神经网络和视频分析来提高乳房炎风险评估准确率的方法。乳房炎是奶牛的乳房组织感染，是一种对奶牛健康造成严重威胁的疾病，可以通过检查奶牛的乳头来检测。传统上，兽医在挤奶过程中评估奶牛乳头的健康状况，但这种方法受时间限制，并且会降低评估的准确性。在商业化农场中，奶牛在挤奶时会被摄像头记录下来。本文使用神经网络来识别记录的视频中奶牛乳房完好无损的关键帧。这些关键帧允许兽医有更灵活的时间对乳头进行健康评估，从而提高效率和准确性。然而，利用奶牛乳头视频进行乳房炎风险评估存在一些挑战，例如复杂的环境、不断变化的奶牛位置和姿势，以及从视频中识别乳房的困难。为了应对这些挑战，本文提出了一种融合距离和集成模型来提高从奶牛乳头视频中识别关键帧的性能（F 值）。结果表明，与使用单一距离度量或模型相比，这两种方法都能提高性能。

##### **Implementing a Nordic-Baltic Federated Health Data Network: a case report**
2409.17865v1 by Taridzo Chomutare, Aleksandar Babic, Laura-Maria Peltonen, Silja Elunurm, Peter Lundberg, Arne Jönsson, Emma Eneling, Ciprian-Virgil Gerstenberger, Troels Siggaard, Raivo Kolde, Oskar Jerdhaf, Martin Hansson, Alexandra Makhlysheva, Miroslav Muzny, Erik Ylipää, Søren Brunak, Hercules Dalianis

Background: Centralized collection and processing of healthcare data across
national borders pose significant challenges, including privacy concerns, data
heterogeneity and legal barriers. To address some of these challenges, we
formed an interdisciplinary consortium to develop a feder-ated health data
network, comprised of six institutions across five countries, to facilitate
Nordic-Baltic cooperation on secondary use of health data. The objective of
this report is to offer early insights into our experiences developing this
network. Methods: We used a mixed-method ap-proach, combining both experimental
design and implementation science to evaluate the factors affecting the
implementation of our network. Results: Technically, our experiments indicate
that the network functions without significant performance degradation compared
to centralized simu-lation. Conclusion: While use of interdisciplinary
approaches holds a potential to solve challeng-es associated with establishing
such collaborative networks, our findings turn the spotlight on the uncertain
regulatory landscape playing catch up and the significant operational costs.

摘要：背景：跨國界集中收集和處理醫療保健數據會帶來重大挑戰，包括隱私問題、數據異質性和法律障礙。為了應對其中一些挑戰，我們組成了一個跨學科聯盟，開發一個聯邦式健康數據網路，由五個國家的六個機構組成，以促進北歐和波羅的海國家在健康數據二次利用方面的合作。本報告的目的是提供我們在開發此網路方面的早期見解。方法：我們使用混合方法，結合實驗設計和實施科學來評估影響我們網路實施的因素。結果：在技術上，我們的實驗表明，與集中式模擬相比，該網路在沒有顯著效能下降的情況下運作。結論：雖然使用跨學科方法有可能解決與建立此類合作網路相關的挑戰，但我們的發現將焦點轉移到不確定的監管環境中，以迎頭趕上並降低顯著的營運成本。

##### **DREAMS: A python framework to train deep learning models with model card reporting for medical and health applications**
2409.17815v1 by Rabindra Khadka, Pedro G Lind, Anis Yazidi, Asma Belhadi

Electroencephalography (EEG) data provides a non-invasive method for
researchers and clinicians to observe brain activity in real time. The
integration of deep learning techniques with EEG data has significantly
improved the ability to identify meaningful patterns, leading to valuable
insights for both clinical and research purposes. However, most of the
frameworks so far, designed for EEG data analysis, are either too focused on
pre-processing or in deep learning methods per, making their use for both
clinician and developer communities problematic. Moreover, critical issues such
as ethical considerations, biases, uncertainties, and the limitations inherent
in AI models for EEG data analysis are frequently overlooked, posing challenges
to the responsible implementation of these technologies. In this paper, we
introduce a comprehensive deep learning framework tailored for EEG data
processing, model training and report generation. While constructed in way to
be adapted and developed further by AI developers, it enables to report,
through model cards, the outcome and specific information of use for both
developers and clinicians. In this way, we discuss how this framework can, in
the future, provide clinical researchers and developers with the tools needed
to create transparent and accountable AI models for EEG data analysis and
diagnosis.

摘要：腦電圖 (EEG) 數據提供了一種非侵入式方法，讓研究人員和臨床醫生可以即時觀察大腦活動。深度學習技術與腦電圖數據的整合，顯著提升了識別有意義模式的能力，進而產生了有價值的見解，可用於臨床和研究目的。然而，到目前為止，大多數專門設計用於腦電圖數據分析的架構，都過於專注於預處理或深度學習方法，導致臨床醫生和開發人員社群難以使用。此外，腦電圖數據分析中的人工智慧模型固有的倫理考量、偏見、不確定性和限制等關鍵問題，經常被忽略，對這些技術的負責任實作構成了挑戰。在本文中，我們介紹了一個專為腦電圖數據處理、模型訓練和報告產生的綜合性深度學習架構。這個架構的建構方式，讓人工智慧開發人員可以進一步調整和開發，並能透過模型卡報告結果和特定資訊，供開發人員和臨床醫生使用。透過這種方式，我們探討這個架構在未來如何能為臨床研究人員和開發人員提供必要的工具，以建立透明且負責任的人工智慧模型，用於腦電圖數據分析和診斷。

##### **Ophthalmic Biomarker Detection with Parallel Prediction of Transformer and Convolutional Architecture**
2409.17788v1 by Md. Touhidul Islam, Md. Abtahi Majeed Chowdhury, Mahmudul Hasan, Asif Quadir, Lutfa Aktar

Ophthalmic diseases represent a significant global health issue,
necessitating the use of advanced precise diagnostic tools. Optical Coherence
Tomography (OCT) imagery which offers high-resolution cross-sectional images of
the retina has become a pivotal imaging modality in ophthalmology.
Traditionally physicians have manually detected various diseases and biomarkers
from such diagnostic imagery. In recent times, deep learning techniques have
been extensively used for medical diagnostic tasks enabling fast and precise
diagnosis. This paper presents a novel approach for ophthalmic biomarker
detection using an ensemble of Convolutional Neural Network (CNN) and Vision
Transformer. While CNNs are good for feature extraction within the local
context of the image, transformers are known for their ability to extract
features from the global context of the image. Using an ensemble of both
techniques allows us to harness the best of both worlds. Our method has been
implemented on the OLIVES dataset to detect 6 major biomarkers from the OCT
images and shows significant improvement of the macro averaged F1 score on the
dataset.

摘要：眼科疾病是全球重要的健康問題，因此需要使用先進且精確的診斷工具。光學相干斷層掃描 (OCT) 影像可提供視網膜的高解析度橫斷面影像，已成為眼科中至關重要的影像模式。傳統上，醫生會手動從此類診斷影像中偵測各種疾病和生物標記。最近，深度學習技術已廣泛用於醫療診斷任務，可進行快速且精確的診斷。本文提出使用卷積神經網路 (CNN) 和視覺Transformer組合的一種新方法來進行眼科生物標記偵測。雖然 CNN 擅長從影像的局部脈絡中萃取特徵，但Transformer則以能從影像的全局脈絡中萃取特徵而聞名。結合這兩種技術，讓我們能夠同時利用兩者的優點。我們的技術已在 OLIVES 資料集上實作，用於從 OCT 影像中偵測六個主要的生物標記，並顯示資料集上的巨平均 F1 分數有顯著的提升。

##### **Confidence intervals uncovered: Are we ready for real-world medical imaging AI?**
2409.17763v2 by Evangelia Christodoulou, Annika Reinke, Rola Houhou, Piotr Kalinowski, Selen Erkan, Carole H. Sudre, Ninon Burgos, Sofiène Boutaj, Sophie Loizillon, Maëlys Solal, Nicola Rieke, Veronika Cheplygina, Michela Antonelli, Leon D. Mayer, Minu D. Tizabi, M. Jorge Cardoso, Amber Simpson, Paul F. Jäger, Annette Kopp-Schneider, Gaël Varoquaux, Olivier Colliot, Lena Maier-Hein

Medical imaging is spearheading the AI transformation of healthcare.
Performance reporting is key to determine which methods should be translated
into clinical practice. Frequently, broad conclusions are simply derived from
mean performance values. In this paper, we argue that this common practice is
often a misleading simplification as it ignores performance variability. Our
contribution is threefold. (1) Analyzing all MICCAI segmentation papers (n =
221) published in 2023, we first observe that more than 50% of papers do not
assess performance variability at all. Moreover, only one (0.5%) paper reported
confidence intervals (CIs) for model performance. (2) To address the reporting
bottleneck, we show that the unreported standard deviation (SD) in segmentation
papers can be approximated by a second-order polynomial function of the mean
Dice similarity coefficient (DSC). Based on external validation data from 56
previous MICCAI challenges, we demonstrate that this approximation can
accurately reconstruct the CI of a method using information provided in
publications. (3) Finally, we reconstructed 95% CIs around the mean DSC of
MICCAI 2023 segmentation papers. The median CI width was 0.03 which is three
times larger than the median performance gap between the first and second
ranked method. For more than 60% of papers, the mean performance of the
second-ranked method was within the CI of the first-ranked method. We conclude
that current publications typically do not provide sufficient evidence to
support which models could potentially be translated into clinical practice.

摘要：醫療影像正帶領著醫療保健的人工智慧轉型。
效能報告對於決定哪些方法應轉換為臨床實務至關重要。通常，廣泛的結論僅來自於平均效能值。在本文中，我們主張這種常見做法通常是一種誤導性的簡化，因為它忽略了效能變異性。我們的貢獻有三方面：(1) 分析 2023 年發表的 221 篇 MICCAI 分割論文，我們首先觀察到超過 50% 的論文根本沒有評估效能變異性。此外，只有一篇 (0.5%) 論文報告了模型效能的信心區間 (CI)。(2) 為了解決報告瓶頸，我們表明分割論文中未報告的標準差 (SD) 可以近似為平均 Dice 相似性係數 (DSC) 的二階多項式函數。根據來自 56 項先前 MICCAI 挑戰的外部驗證資料，我們證明此近似值可以使用論文中提供的資訊準確重建方法的 CI。(3) 最後，我們重建了 MICCAI 2023 分割論文平均 DSC 周圍的 95% CI。中位數 CI 寬度為 0.03，是第一名和第二名方法之間的中位數效能差距的三倍。對於超過 60% 的論文，排名第二的方法的平均效能都在排名第一的方法的 CI 內。我們得出結論，目前的論文通常無法提供足夠的證據來支持哪些模型有可能轉換為臨床實務。

##### **Artificial Data Point Generation in Clustered Latent Space for Small Medical Datasets**
2409.17685v1 by Yasaman Haghbin, Hadi Moradi, Reshad Hosseini

One of the growing trends in machine learning is the use of data generation
techniques, since the performance of machine learning models is dependent on
the quantity of the training dataset. However, in many medical applications,
collecting large datasets is challenging due to resource constraints, which
leads to overfitting and poor generalization. This paper introduces a novel
method, Artificial Data Point Generation in Clustered Latent Space (AGCL),
designed to enhance classification performance on small medical datasets
through synthetic data generation. The AGCL framework involves feature
extraction, K-means clustering, cluster evaluation based on a class separation
metric, and the generation of synthetic data points from clusters with distinct
class representations. This method was applied to Parkinson's disease
screening, utilizing facial expression data, and evaluated across multiple
machine learning classifiers. Experimental results demonstrate that AGCL
significantly improves classification accuracy compared to baseline, GN and
kNNMTD. AGCL achieved the highest overall test accuracy of 83.33% and
cross-validation accuracy of 90.90% in majority voting over different emotions,
confirming its effectiveness in augmenting small datasets.

摘要：機器學習中日益增長的趨勢之一是使用資料產生技術，因為機器學習模型的效能取決於訓練資料集的數量。然而，在許多醫學應用中，由於資源限制，收集大型資料集具有挑戰性，這會導致過度擬合和不良的泛化。本文介紹了一種新方法，即叢集潛在空間中的人工資料點產生（AGCL），旨在透過合成資料產生來增強小型醫學資料集上的分類效能。AGCL 框架涉及特徵萃取、K 平均叢集、基於類別分離度量標準的叢集評估，以及從具有不同類別表示的叢集中產生合成資料點。此方法應用於帕金森氏症篩檢，利用面部表情資料，並在多個機器學習分類器中進行評估。實驗結果表明，與基線、GN 和 kNNMTD 相比，AGCL 大幅提升了分類準確度。在對不同情緒進行多數決投票時，AGCL 達到了最高的整體測試準確度 83.33% 和交叉驗證準確度 90.90%，證實了其在擴充小型資料集方面的有效性。

##### **Zero- and Few-shot Named Entity Recognition and Text Expansion in Medication Prescriptions using ChatGPT**
2409.17683v1 by Natthanaphop Isaradech, Andrea Riedel, Wachiranun Sirikul, Markus Kreuzthaler, Stefan Schulz

Introduction: Medication prescriptions are often in free text and include a
mix of two languages, local brand names, and a wide range of idiosyncratic
formats and abbreviations. Large language models (LLMs) have shown promising
ability to generate text in response to input prompts. We use ChatGPT 3.5 to
automatically structure and expand medication statements in discharge summaries
and thus make them easier to interpret for people and machines. Methods:
Named-entity Recognition (NER) and Text Expansion (EX) are used in a zero- and
few-shot setting with different prompt strategies. 100 medication statements
were manually annotated and curated. NER performance was measured by using
strict and partial matching. For the task EX, two experts interpreted the
results by assessing semantic equivalence between original and expanded
statements. The model performance was measured by precision, recall, and F1
score. Results: For NER, the best-performing prompt reached an average F1 score
of 0.94 in the test set. For EX, the few-shot prompt showed superior
performance among other prompts, with an average F1 score of 0.87. Conclusion:
Our study demonstrates good performance for NER and EX tasks in free-text
medication statements using ChatGPT. Compared to a zero-shot baseline, a
few-shot approach prevented the system from hallucinating, which would be
unacceptable when processing safety-relevant medication data.

摘要：**引言：**藥物處方通常以自由文本形式呈現，並包含兩種語言、當地品牌名稱，以及各種慣用格式和縮寫。大型語言模型 (LLM) 已展現出極佳的文本生成能力，能回應輸入提示。我們使用 ChatGPT 3.5 自動建構和擴充出院摘要中的藥物陳述，讓人類和機器更容易解讀。**方法：**命名實體辨識 (NER) 和文字擴充 (EX) 用於零次和少量提示策略的設定。100 個藥物陳述經過人工註解和整理。NER 的效能透過嚴格和部分比對進行衡量。對於 EX 任務，兩位專家透過評估原始陳述和擴充陳述之間的語義等效性來解讀結果。模型效能透過精確度、召回率和 F1 分數進行衡量。**結果：**對於 NER，效能最佳的提示在測試集中達到平均 F1 分數 0.94。對於 EX，少量提示在其他提示中展現出優異效能，平均 F1 分數為 0.87。**結論：**我們的研究證明，使用 ChatGPT 處理自由文本藥物陳述中的 NER 和 EX 任務具有良好的效能。與零次基準相比，少量提示方法可防止系統產生幻覺，這在處理與安全性相關的藥物資料時是不可接受的。

##### **Digital Twin Ecosystem for Oncology Clinical Operations**
2409.17650v1 by Himanshu Pandey, Akhil Amod, Shivang, Kshitij Jaggi, Ruchi Garg, Abheet Jain, Vinayak Tantia

Artificial Intelligence (AI) and Large Language Models (LLMs) hold
significant promise in revolutionizing healthcare, especially in clinical
applications. Simultaneously, Digital Twin technology, which models and
simulates complex systems, has gained traction in enhancing patient care.
However, despite the advances in experimental clinical settings, the potential
of AI and digital twins to streamline clinical operations remains largely
untapped. This paper introduces a novel digital twin framework specifically
designed to enhance oncology clinical operations. We propose the integration of
multiple specialized digital twins, such as the Medical Necessity Twin, Care
Navigator Twin, and Clinical History Twin, to enhance workflow efficiency and
personalize care for each patient based on their unique data. Furthermore, by
synthesizing multiple data sources and aligning them with the National
Comprehensive Cancer Network (NCCN) guidelines, we create a dynamic Cancer Care
Path, a continuously evolving knowledge base that enables these digital twins
to provide precise, tailored clinical recommendations.

摘要：人工智慧 (AI) 和大型語言模型 (LLM) 在醫療保健領域中，特別是在臨床應用中，具有顯著的變革前景。同時，用於模擬和建模複雜系統的數位孿生技術，在增強患者照護方面也獲得了關注。然而，儘管在實驗性臨床環境中取得進展，AI 和數位孿生在簡化臨床運作方面的潛力仍未得到充分發揮。本文介紹了一個專門設計用於增強腫瘤學臨床運作的新型數位孿生架構。我們建議整合多個專業數位孿生，例如醫療必要性孿生、照護領航員孿生和臨床病史孿生，以提高工作流程效率，並根據每個患者的獨特資料為其提供個人化照護。此外，透過綜合多個資料來源並將其與國家綜合癌症網路 (NCCN) 指南相符，我們建立了一個動態癌症照護路徑，一個持續發展的知識庫，使這些數位孿生能夠提供精確且客製化的臨床建議。

##### **A Scalable Data-Driven Framework for Systematic Analysis of SEC 10-K Filings Using Large Language Models**
2409.17581v1 by Syed Affan Daimi, Asma Iqbal

The number of companies listed on the NYSE has been growing exponentially,
creating a significant challenge for market analysts, traders, and stockholders
who must monitor and assess the performance and strategic shifts of a large
number of companies regularly. There is an increasing need for a fast,
cost-effective, and comprehensive method to evaluate the performance and detect
and compare many companies' strategy changes efficiently. We propose a novel
data-driven approach that leverages large language models (LLMs) to
systematically analyze and rate the performance of companies based on their SEC
10-K filings. These filings, which provide detailed annual reports on a
company's financial performance and strategic direction, serve as a rich source
of data for evaluating various aspects of corporate health, including
confidence, environmental sustainability, innovation, and workforce management.
We also introduce an automated system for extracting and preprocessing 10-K
filings. This system accurately identifies and segments the required sections
as outlined by the SEC, while also isolating key textual content that contains
critical information about the company. This curated data is then fed into
Cohere's Command-R+ LLM to generate quantitative ratings across various
performance metrics. These ratings are subsequently processed and visualized to
provide actionable insights. The proposed scheme is then implemented on an
interactive GUI as a no-code solution for running the data pipeline and
creating the visualizations. The application showcases the rating results and
provides year-on-year comparisons of company performance.

摘要：紐約證券交易所上市的公司數量呈指數成長，對必須定期監控和評估大量公司績效和策略轉變的市場分析師、交易員和股東來說，這是一個重大的挑戰。對於一種快速、具成本效益且全面的方法，有越來越高的需求，以評估績效並有效地偵測和比較許多公司的策略變化。我們提出一個新穎的資料驅動方法，利用大型語言模型 (LLM) 來系統性地分析和評比公司的績效，其基礎是公司的美國證券交易委員會 (SEC) 10-K 檔。這些申報提供公司財務績效和策略方向的詳細年度報告，作為評估公司健全程度各個面向的豐富資料來源，包括信心、環境永續性、創新和員工管理。我們也導入一個自動化系統，用於擷取和預處理 10-K 申報。此系統精確地識別和區隔美國證券交易委員會所概述的必要部分，同時也孤立包含公司關鍵資訊的文字內容。接著將這些整理過的資料輸入 Cohere 的 Command-R+ LLM，以產生各種績效指標的量化評分。接著處理和視覺化這些評分，以提供可行的見解。然後在互動式 GUI 上實作建議的架構，作為執行資料管線和建立視覺化的無程式碼解決方案。此應用程式展示評分結果，並提供公司績效的年對年比較。

##### **Dr. GPT in Campus Counseling: Understanding Higher Education Students' Opinions on LLM-assisted Mental Health Services**
2409.17572v1 by Owen Xingjian Zhang, Shuyao Zhou, Jiayi Geng, Yuhan Liu, Sunny Xun Liu

In response to the increasing mental health challenges faced by college
students, we sought to understand their perspectives on how AI applications,
particularly Large Language Models (LLMs), can be leveraged to enhance their
mental well-being. Through pilot interviews with ten diverse students, we
explored their opinions on the use of LLMs across five fictional scenarios:
General Information Inquiry, Initial Screening, Reshaping Patient-Expert
Dynamics, Long-term Care, and Follow-up Care. Our findings revealed that
students' acceptance of LLMs varied by scenario, with participants highlighting
both potential benefits, such as proactive engagement and personalized
follow-up care, and concerns, including limitations in training data and
emotional support. These insights inform how AI technology should be designed
and implemented to effectively support and enhance students' mental well-being,
particularly in scenarios where LLMs can complement traditional methods, while
maintaining empathy and respecting individual preferences.

摘要：為了回應大學生面臨日益增加的心理健康挑戰，我們試圖了解他們對 AI 應用程式的觀點，特別是大型語言模型 (LLM) 如何能提升他們的心理健康。透過對十位不同學生的試點訪談，我們探討了他們對 LLM 在五個虛構情境中的使用意見：一般資訊詢問、初步篩選、重塑患者與專家的互動模式、長期照護和後續照護。我們的研究結果顯示，學生對 LLM 的接受度因情境而異，參與者強調了潛在的好處，例如主動參與和個人化的後續照護，以及疑慮，包括訓練資料和情緒支持的限制。這些見解說明了 AI 技術應如何設計和實施，以有效支援和提升學生的心理健康，特別是在 LLM 能補充傳統方法的情境中，同時保持同理心並尊重個人偏好。

##### **Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE**
2409.17508v1 by Xun Zhu, Ying Hu, Fanbin Mo, Miao Li, Ji Wu

Multi-modal large language models (MLLMs) have shown impressive capabilities
as a general-purpose interface for various visual and linguistic tasks.
However, building a unified MLLM for multi-task learning in the medical field
remains a thorny challenge. To mitigate the tug-of-war problem of multi-modal
multi-task optimization, recent advances primarily focus on improving the LLM
components, while neglecting the connector that bridges the gap between
modalities. In this paper, we introduce Uni-Med, a novel medical generalist
foundation model which consists of a universal visual feature extraction
module, a connector mixture-of-experts (CMoE) module, and an LLM. Benefiting
from the proposed CMoE that leverages a well-designed router with a mixture of
projection experts at the connector, Uni-Med achieves efficient solution to the
tug-of-war problem and can perform six different medical tasks including
question answering, visual question answering, report generation, referring
expression comprehension, referring expression generation and image
classification. To the best of our knowledge, Uni-Med is the first effort to
tackle multi-task interference at the connector. Extensive ablation experiments
validate the effectiveness of introducing CMoE under any configuration, with up
to an average 8% performance gains. We further provide interpretation analysis
of the tug-of-war problem from the perspective of gradient optimization and
parameter statistics. Compared to previous state-of-the-art medical MLLMs,
Uni-Med achieves competitive or superior evaluation metrics on diverse tasks.
Code, data and model will be soon available at GitHub.

摘要：<paragraph>多模態大型語言模型 (MLLM) 已展現出令人印象深刻的能力，可作為各種視覺和語言任務的通用介面。然而，建立一個統一的 MLLM 來進行醫學領域的多任務學習仍然是一個棘手的挑戰。為了減輕多模態多任務最佳化的拉鋸戰問題，最近的進展主要集中在改進 LLM 組件，同時忽略了橋接不同模態之間差距的連接器。在本文中，我們介紹了 Uni-Med，這是一個新穎的醫學通才基礎模型，它包含一個通用視覺特徵提取模組、一個連接器混合專家 (CMoE) 模組和一個 LLM。受益於提議的 CMoE，它利用了一個經過精心設計的路由器，其中包含連接器上的混合投影專家，Uni-Med 對拉鋸戰問題實現了高效的解決方案，並且可以執行六項不同的醫療任務，包括問答、視覺問答、報告生成、指稱表達理解、指稱表達生成和影像分類。據我們所知，Uni-Med 是第一個在連接器上解決多任務干擾的嘗試。廣泛的消融實驗驗證了在任何組態下引入 CMoE 的有效性，效能提升幅度平均高達 8%。我們進一步提供了從梯度最佳化和參數統計的角度對拉鋸戰問題的解釋分析。與先前的醫學 MLLM 最先進技術相比，Uni-Med 在不同的任務上實現了具有競爭力或更佳的評估指標。程式碼、資料和模型將很快在 GitHub 上提供。</paragraph>

##### **Global-Local Medical SAM Adaptor Based on Full Adaption**
2409.17486v1 by Meng Wang, Yarong Feng, Yongwei Tang, Tian Zhang, Yuxin Liang, Chao Lv

Emerging of visual language models, such as the segment anything model (SAM),
have made great breakthroughs in the field of universal semantic segmentation
and significantly aid the improvements of medical image segmentation, in
particular with the help of Medical SAM adaptor (Med-SA). However, Med-SA still
can be improved, as it fine-tunes SAM in a partial adaption manner. To resolve
this problem, we present a novel global medical SAM adaptor (GMed-SA) with full
adaption, which can adapt SAM globally. We further combine GMed-SA and Med-SA
to propose a global-local medical SAM adaptor (GLMed-SA) to adapt SAM both
globally and locally. Extensive experiments have been performed on the
challenging public 2D melanoma segmentation dataset. The results show that
GLMed-SA outperforms several state-of-the-art semantic segmentation methods on
various evaluation metrics, demonstrating the superiority of our methods.

摘要：視覺語言模型的出現，例如任何區段模型 (SAM)，
在通用語意分割領域取得重大突破，
並顯著幫助改善醫學影像分割，
特別是在醫學 SAM 適配器 (Med-SA) 的幫助下。然而，Med-SA 仍有改進空間，因為它以部分適應的方式微調 SAM。為了解決這個問題，我們提出一個具有完全適應能力的新型全局醫學 SAM 適配器 (GMed-SA)，它可以全局適應 SAM。我們進一步結合 GMed-SA 和 Med-SA 來提出一個全局局部醫學 SAM 適配器 (GLMed-SA)，以全局和局部的方式適應 SAM。在具有挑戰性的公共 2D 黑色素瘤分割數據集上進行了廣泛的實驗。結果表明，GLMed-SA 在各種評估指標上優於多種最先進的語意分割方法，證明了我們方法的優越性。

##### **Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting**
2409.17332v1 by Jay Zoellin, Colin Merk, Mischa Buob, Amr Saad, Samuel Giesser, Tahm Spitznagel, Ferhat Turgut, Rui Santos, Yukun Zhou, Sigfried Wagner, Pearse A. Keane, Yih Chung Tham, Delia Cabrera DeBuc, Matthias D. Becker, Gabor M. Somfai

Integrating deep learning into medical imaging is poised to greatly advance
diagnostic methods but it faces challenges with generalizability. Foundation
models, based on self-supervised learning, address these issues and improve
data efficiency. Natural domain foundation models show promise for medical
imaging, but systematic research evaluating domain adaptation, especially using
self-supervised learning and parameter-efficient fine-tuning, remains
underexplored. Additionally, little research addresses the issue of
catastrophic forgetting during fine-tuning of foundation models. We adapted the
DINOv2 vision transformer for retinal imaging classification tasks using
self-supervised learning and generated two novel foundation models termed
DINORET and BE DINORET. Publicly available color fundus photographs were
employed for model development and subsequent fine-tuning for diabetic
retinopathy staging and glaucoma detection. We introduced block expansion as a
novel domain adaptation strategy and assessed the models for catastrophic
forgetting. Models were benchmarked to RETFound, a state-of-the-art foundation
model in ophthalmology. DINORET and BE DINORET demonstrated competitive
performance on retinal imaging tasks, with the block expanded model achieving
the highest scores on most datasets. Block expansion successfully mitigated
catastrophic forgetting. Our few-shot learning studies indicated that DINORET
and BE DINORET outperform RETFound in terms of data-efficiency. This study
highlights the potential of adapting natural domain vision models to retinal
imaging using self-supervised learning and block expansion. BE DINORET offers
robust performance without sacrificing previously acquired capabilities. Our
findings suggest that these methods could enable healthcare institutions to
develop tailored vision models for their patient populations, enhancing global
healthcare inclusivity.

摘要：<paragraph>將深度學習整合到醫學影像中，有望大幅提升診斷方法，但它在普遍性方面面臨挑戰。基於自我監督學習的基礎模型，解決了這些問題並提高了資料效率。自然領域基礎模型顯示出在醫學影像方面的潛力，但評估領域適應的系統性研究，特別是使用自我監督學習和參數有效微調，仍未被充分探討。此外，很少有研究探討基礎模型微調過程中災難性遺忘的問題。我們採用 DINOv2 視覺轉換器，使用自我監督學習進行視網膜影像分類任務，並生成了兩個新的基礎模型，稱為 DINORET 和 BE DINORET。公開可用的彩色眼底照片被用於模型開發和後續微調，以進行糖尿病視網膜病變分期和青光眼檢測。我們引入了區塊擴展作為一種新的領域適應策略，並評估了模型的災難性遺忘。這些模型與眼科領域最先進的基礎模型 RETFound 進行了基準測試。DINORET 和 BE DINORET 在視網膜影像任務中表現出競爭力，其中區塊擴展模型在大多數數據集上獲得了最高分。區塊擴展成功地減輕了災難性遺忘。我們的一發學習研究表明，DINORET 和 BE DINORET 在資料效率方面優於 RETFound。這項研究強調了使用自我監督學習和區塊擴展將自然領域視覺模型適應到視網膜影像的潛力。BE DINORET 在不犧牲先前獲得的能力的情況下提供了穩健的性能。我們的研究結果表明，這些方法可以使醫療機構為其患者群體開發量身定制的視覺模型，從而增強全球醫療保健的包容性。</paragraph>

##### **Data-Centric AI Governance: Addressing the Limitations of Model-Focused Policies**
2409.17216v1 by Ritwik Gupta, Leah Walker, Rodolfo Corona, Stephanie Fu, Suzanne Petryk, Janet Napolitano, Trevor Darrell, Andrew W. Reddie

Current regulations on powerful AI capabilities are narrowly focused on
"foundation" or "frontier" models. However, these terms are vague and
inconsistently defined, leading to an unstable foundation for governance
efforts. Critically, policy debates often fail to consider the data used with
these models, despite the clear link between data and model performance. Even
(relatively) "small" models that fall outside the typical definitions of
foundation and frontier models can achieve equivalent outcomes when exposed to
sufficiently specific datasets. In this work, we illustrate the importance of
considering dataset size and content as essential factors in assessing the
risks posed by models both today and in the future. More broadly, we emphasize
the risk posed by over-regulating reactively and provide a path towards
careful, quantitative evaluation of capabilities that can lead to a simplified
regulatory environment.

摘要：當前針對強大 AI 能力的法規，狹隘地聚焦在「基礎」或「前沿」模型上。然而，這些術語模糊且定義不一致，導致治理工作缺乏穩固的基礎。至關重要的是，政策辯論經常未能考慮與這些模型一起使用的資料，儘管資料與模型效能之間有明確的關聯。即使是落在基礎和前沿模型典型定義之外的（相對）「小型」模型，在接觸到足夠具體的資料集時，也能達成同等的結果。在這項工作中，我們說明了在評估模型當前和未來帶來的風險時，考量資料集大小和內容為必要因素的重要性。更廣泛地來說，我們強調了過度反應式監管所帶來的風險，並提供了一條通往審慎、量化評估能力的道路，這將有助於簡化監管環境。

##### **Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**
2409.17091v1 by Xinrui Zhou, Yuhao Huang, Haoran Dou, Shijing Chen, Ao Chang, Jia Liu, Weiran Long, Jian Zheng, Erjiao Xu, Jie Ren, Ruobing Huang, Jun Cheng, Wufeng Xue, Dong Ni

In the medical field, the limited availability of large-scale datasets and
labor-intensive annotation processes hinder the performance of deep models.
Diffusion-based generative augmentation approaches present a promising solution
to this issue, having been proven effective in advancing downstream medical
recognition tasks. Nevertheless, existing works lack sufficient semantic and
sequential steerability for challenging video/3D sequence generation, and
neglect quality control of noisy synthesized samples, resulting in unreliable
synthetic databases and severely limiting the performance of downstream tasks.
In this work, we present Ctrl-GenAug, a novel and general generative
augmentation framework that enables highly semantic- and sequential-customized
sequence synthesis and suppresses incorrectly synthesized samples, to aid
medical sequence classification. Specifically, we first design a multimodal
conditions-guided sequence generator for controllably synthesizing
diagnosis-promotive samples. A sequential augmentation module is integrated to
enhance the temporal/stereoscopic coherence of generated samples. Then, we
propose a noisy synthetic data filter to suppress unreliable cases at semantic
and sequential levels. Extensive experiments on 3 medical datasets, using 11
networks trained on 3 paradigms, comprehensively analyze the effectiveness and
generality of Ctrl-GenAug, particularly in underrepresented high-risk
populations and out-domain conditions.

摘要：在医学領域中，大規模數據集的可用性有限，且人工標註過程繁瑣，阻礙了深度模型的執行。基於擴散的生成式擴充方法為此問題提供了有前景的解決方案，已被證實能有效推進下游醫療識別任務。儘管如此，現有作品缺乏足夠的語義和序列可控性，難以進行具有挑戰性的視訊/3D 序列生成，且忽略了對有雜訊合成樣本的品質控制，導致合成式資料庫不可靠，並嚴重限制了下游任務的執行。在這項工作中，我們提出了 Ctrl-GenAug，一個新穎且通用的生成式擴充架構，能實現高度語義和序列自訂的序列合成，並抑制錯誤合成的樣本，以協助醫療序列分類。具體來說，我們首先設計了一個多模態條件引導序列生成器，用於可控地合成促進診斷的樣本。整合了一個序列擴充模組，以增強生成樣本的時間/立體一致性。然後，我們提出了一個有雜訊的合成資料濾波器，以抑制語義和序列層級中不可靠的案例。在 3 個醫療數據集上進行的廣泛實驗，使用在 3 個範例中訓練的 11 個網路，全面分析了 Ctrl-GenAug 的有效性和普遍性，特別是在代表性不足的高風險族群和領域外條件中。

##### **DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**
2409.17055v2 by Lucas Robinet, Ahmad Berjaoui, Ziad Kheil, Elizabeth Cohen-Jonathan Moyal

Real-life medical data is often multimodal and incomplete, fueling the
growing need for advanced deep learning models capable of integrating them
efficiently. The use of diverse modalities, including histopathology slides,
MRI, and genetic data, offers unprecedented opportunities to improve prognosis
prediction and to unveil new treatment pathways. Contrastive learning, widely
used for deriving representations from paired data in multimodal tasks, assumes
that different views contain the same task-relevant information and leverages
only shared information. This assumption becomes restrictive when handling
medical data since each modality also harbors specific knowledge relevant to
downstream tasks. We introduce DRIM, a new multimodal method for capturing
these shared and unique representations, despite data sparsity. More
specifically, given a set of modalities, we aim to encode a representation for
each one that can be divided into two components: one encapsulating
patient-related information common across modalities and the other,
encapsulating modality-specific details. This is achieved by increasing the
shared information among different patient modalities while minimizing the
overlap between shared and unique components within each modality. Our method
outperforms state-of-the-art algorithms on glioma patients survival prediction
tasks, while being robust to missing modalities. To promote reproducibility,
the code is made publicly available at https://github.com/Lucas-rbnt/DRIM

摘要：真實世界的醫療數據通常是多模態且不完整的，推動了對能夠有效整合它們的先進深度學習模型的需求。使用多種模式，包括組織病理學幻燈片、核磁共振和遺傳數據，提供了前所未有的機會來改進預後預測並揭示新的治療途徑。對比學習廣泛用於從多模態任務中的配對數據中推導表示，假設不同的視圖包含相同的與任務相關的信息，並且僅利用共享信息。在處理醫療數據時，這種假設變得具有限制性，因為每種模式也包含與下游任務相關的特定知識。我們介紹了 DRIM，這是一種新的多模態方法，用於捕獲這些共享和獨特的表示，儘管數據稀疏。更具體地說，給定一組模式，我們的目標是為每個模式編碼一個表示，該表示可以分為兩個組成部分：一個封裝跨模式共有的患者相關信息，另一個封裝特定於模式的細節。這是通過增加不同患者模式之間的共享信息，同時最小化每個模式內共享和唯一組件之間的重疊來實現的。我們的算法在神經膠質瘤患者生存預測任務中優於最先進的算法，同時對缺失模式具有魯棒性。為了促進可重複性，代碼已在 https://github.com/Lucas-rbnt/DRIM 上公開。

##### **Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**
2409.17054v1 by Azmul Asmar Irfan, Nur Ahmad Khatim, Mansur M. Arief

One of the key issues contributing to inefficiency in Puskesmas is the
time-consuming nature of doctor-patient interactions. Doctors need to conduct
thorough consultations, which include diagnosing the patient's condition,
providing treatment advice, and transcribing detailed notes into medical
records. In regions with diverse linguistic backgrounds, doctors often have to
ask clarifying questions, further prolonging the process. While diagnosing is
essential, transcription and summarization can often be automated using AI to
improve time efficiency and help doctors enhance care quality and enable early
diagnosis and intervention. This paper proposes a solution using a localized
large language model (LLM) to transcribe, translate, and summarize
doctor-patient conversations. We utilize the Whisper model for transcription
and GPT-3 to summarize them into the ePuskemas medical records format. This
system is implemented as an add-on to an existing web browser extension,
allowing doctors to fill out patient forms while talking. By leveraging this
solution for real-time transcription, translation, and summarization, doctors
can improve the turnaround time for patient care while enhancing the quality of
records, which become more detailed and insightful for future visits. This
innovation addresses challenges like overcrowded facilities and the
administrative burden on healthcare providers in Indonesia. We believe this
solution will help doctors save time, provide better care, and produce more
accurate medical records, representing a significant step toward modernizing
healthcare and ensuring patients receive timely, high-quality care, even in
resource-constrained settings.

摘要：<paragraph>導致 Puskesmas 效率低下的關鍵問題之一是，醫生和病人互動耗時。醫生需要進行徹底的諮詢，包括診斷病人的病情、提供治療建議，以及將詳細的筆記記錄在醫療記錄中。在語言背景多元的地區，醫生經常必須提出澄清問題，進一步延長流程。雖然診斷至關重要，但使用 AI 進行轉錄和摘要通常可以自動化，以提高時間效率，並幫助醫生提高護理品質，並實現早期診斷和干預。本文提出了一個使用本地化大型語言模型 (LLM) 來轉錄、翻譯和摘要醫生與病人對話的解決方案。我們利用 Whisper 模型進行轉錄，並使用 GPT-3 將其摘要成 ePuskemas 醫療記錄格式。此系統實作為現有網路瀏覽器擴充功能的附加元件，讓醫生可以在交談時填寫病患表單。透過利用此解決方案進行即時轉錄、翻譯和摘要，醫生可以改善病患照護的周轉時間，同時提升記錄品質，讓記錄變得更詳細且更有洞見，以利於後續就診。此創新解決了像醫療機構人滿為患和印尼醫療保健提供者的行政負擔等挑戰。我們相信此解決方案將幫助醫生節省時間、提供更好的照護，並產生更準確的醫療記錄，代表著現代化醫療保健並確保病人即使在資源受限的環境中也能獲得及時、高品質的照護的重要一步。</paragraph>

##### **GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**
2409.17045v1 by Phillip Mueller, Sebastian Mueller, Lars Mikelsons

We provide a dataset for enabling Deep Generative Models (DGMs) in
engineering design and propose methods to automate data labeling by utilizing
large-scale foundation models. GeoBiked is curated to contain 4 355 bicycle
images, annotated with structural and technical features and is used to
investigate two automated labeling techniques: The utilization of consolidated
latent features (Hyperfeatures) from image-generation models to detect
geometric correspondences (e.g. the position of the wheel center) in structural
images and the generation of diverse text descriptions for structural images.
GPT-4o, a vision-language-model (VLM), is instructed to analyze images and
produce diverse descriptions aligned with the system-prompt. By representing
technical images as Diffusion-Hyperfeatures, drawing geometric correspondences
between them is possible. The detection accuracy of geometric points in unseen
samples is improved by presenting multiple annotated source images. GPT-4o has
sufficient capabilities to generate accurate descriptions of technical images.
Grounding the generation only on images leads to diverse descriptions but
causes hallucinations, while grounding it on categorical labels restricts the
diversity. Using both as input balances creativity and accuracy. Successfully
using Hyperfeatures for geometric correspondence suggests that this approach
can be used for general point-detection and annotation tasks in technical
images. Labeling such images with text descriptions using VLMs is possible, but
dependent on the models detection capabilities, careful prompt-engineering and
the selection of input information. Applying foundation models in engineering
design is largely unexplored. We aim to bridge this gap with a dataset to
explore training, finetuning and conditioning DGMs in this field and suggesting
approaches to bootstrap foundation models to process technical images.

摘要：<paragraph>我們提供了一個資料集，用於在工程設計中啟用深度生成模型 (DGM)，並提出透過利用大規模基礎模型自動化資料標籤的方法。GeoBiked 經過策展，包含 4,355 張自行車影像，並附有結構和技術特徵註解，且用於調查兩種自動化標籤技術：利用影像生成模型的整合潛在特徵（超特徵）來偵測結構影像中的幾何對應（例如車輪中心的位子），以及為結構影像產生多樣化的文字描述。GPT-4o 是一個視覺語言模型 (VLM)，指示要分析影像並產生與系統提示一致的多樣化描述。透過將技術影像表示為擴散超特徵，就可以繪製它們之間的幾何對應。透過呈現多個帶註解的來源影像，可以改善在未見樣本中幾何點的偵測準確度。GPT-4o 具有足夠的能力來產生技術影像的準確描述。僅根據影像進行基礎會產生多樣化的描述，但會產生幻覺，而根據分類標籤進行基礎則會限制多樣性。將兩者都用作輸入，可以平衡創造力和準確性。成功地將超特徵用於幾何對應，表示這種方法可用於技術影像中的一般點偵測和註解任務。使用 VLM 標籤此類影像的文字描述是可行的，但取決於模型的偵測能力、仔細的提示工程和輸入資訊的選擇。在工程設計中應用基礎模型在很大程度上尚未探索。我們旨在透過一個資料集來填補這個空白，以探索在這個領域訓練、微調和調整 DGM，並建議引導基礎模型處理技術影像的方法。</paragraph>

##### **AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**
2409.16898v2 by Jaeyoung Huh, Paul Klein, Gareth Funka-Lea, Puneet Sharma, Ankur Kapoor, Young-Ho Kim

Intra-cardiac Echocardiography (ICE) is a crucial imaging modality used in
electrophysiology (EP) and structural heart disease (SHD) interventions,
providing real-time, high-resolution views from within the heart. Despite its
advantages, effective manipulation of the ICE catheter requires significant
expertise, which can lead to inconsistent outcomes, particularly among less
experienced operators. To address this challenge, we propose an AI-driven
closed-loop view guidance system with human-in-the-loop feedback, designed to
assist users in navigating ICE imaging without requiring specialized knowledge.
Our method models the relative position and orientation vectors between
arbitrary views and clinically defined ICE views in a spatial coordinate
system, guiding users on how to manipulate the ICE catheter to transition from
the current view to the desired view over time. Operating in a closed-loop
configuration, the system continuously predicts and updates the necessary
catheter manipulations, ensuring seamless integration into existing clinical
workflows. The effectiveness of the proposed system is demonstrated through a
simulation-based evaluation, achieving an 89% success rate with the 6532 test
dataset, highlighting its potential to improve the accuracy and efficiency of
ICE imaging procedures.

摘要：心內超音波 (ICE) 是一種重要的影像模式，用於電生理 (EP) 和結構性心臟疾病 (SHD) 的介入治療，提供來自心臟內部的高解析度即時影像。儘管有這些優點，但有效操作 ICE 導管需要大量的專業知識，這可能會導致不一致的結果，尤其是在經驗較少的操作者中。為了應對這個挑戰，我們提出了一種以 AI 為驅動的閉環視圖引導系統，並結合人為回饋，旨在協助使用者在不需要專業知識的情況下導航 ICE 影像。我們的模型方法在空間座標系統中建構任意視圖和臨床定義的 ICE 視圖之間的相對位置和方向向量，引導使用者如何操作 ICE 導管，以隨著時間推移從目前的視圖轉換到所需的視圖。系統在閉環配置中運作，持續預測和更新必要的導管操作，確保無縫整合到現有的臨床工作流程中。所提出的系統的有效性透過基於模擬的評估得到證明，在 6532 個測試數據集中實現了 89% 的成功率，突顯了其改善 ICE 影像程序準確性和效率的潛力。

##### **The Role of Language Models in Modern Healthcare: A Comprehensive Review**
2409.16860v1 by Amna Khalid, Ayma Khalid, Umar Khalid

The application of large language models (LLMs) in healthcare has gained
significant attention due to their ability to process complex medical data and
provide insights for clinical decision-making. These models have demonstrated
substantial capabilities in understanding and generating natural language,
which is crucial for medical documentation, diagnostics, and patient
interaction. This review examines the trajectory of language models from their
early stages to the current state-of-the-art LLMs, highlighting their strengths
in healthcare applications and discussing challenges such as data privacy,
bias, and ethical considerations. The potential of LLMs to enhance healthcare
delivery is explored, alongside the necessary steps to ensure their ethical and
effective integration into medical practice.

摘要：大型語言模型 (LLM) 在醫療保健中的應用已獲得顯著關注，因為它們能夠處理複雜的醫療數據並提供臨床決策的見解。這些模型已展示出在理解和產生自然語言方面的實質能力，這對於醫療文件、診斷和患者互動至關重要。本篇評論探討了語言模型從早期階段到當前最先進的 LLM 的軌跡，重點介紹了它們在醫療保健應用中的優勢，並討論了數據隱私、偏見和道德考量等挑戰。探討了 LLM 提升醫療保健服務的潛力，以及確保它們道德且有效整合到醫療實務中的必要步驟。

##### **A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**
2409.16721v1 by Syed Mohd Faisal Malik, Md Tabrez Nafis, Mohd Abdul Ahad, Safdar Tanweer

In contemporary healthcare, to protect patient data, electronic health
records have become invaluable repositories, creating vast opportunities to
leverage deep learning techniques for predictive analysis. Retinal fundus
images, cirrhosis stages, and heart disease diagnostic predictions have shown
promising results through the integration of deep learning techniques for
classifying diverse datasets. This study proposes a novel deep learning
predictive analysis framework for classifying multiple datasets by
pre-processing data from three distinct sources. A hybrid deep learning model
combining Residual Networks and Artificial Neural Networks is proposed to
detect acute and chronic diseases such as heart diseases, cirrhosis, and
retinal conditions, outperforming existing models. Dataset preparation involves
aspects such as categorical data transformation, dimensionality reduction, and
missing data synthesis. Feature extraction is effectively performed using
scaler transformation for categorical datasets and ResNet architecture for
image datasets. The resulting features are integrated into a unified
classification model. Rigorous experimentation and evaluation resulted in high
accuracies of 93%, 99%, and 95% for retinal fundus images, cirrhosis stages,
and heart disease diagnostic predictions, respectively. The efficacy of the
proposed method is demonstrated through a detailed analysis of F1-score,
precision, and recall metrics. This study offers a comprehensive exploration of
methodologies and experiments, providing in-depth knowledge of deep learning
predictive analysis in electronic health records.

摘要：<paragraph>在當代醫療保健中，為了保護患者數據，電子健康記錄已成為無價的儲存庫，創造了利用深度學習技術進行預測分析的廣闊機會。視網膜眼底圖像、肝硬化分期和心臟病診斷預測已透過整合深度學習技術來分類不同的數據集，顯示出有希望的結果。本研究提出一個新的深度學習預測分析架構，透過預處理來自三個不同來源的數據來分類多個數據集。提出了一個結合殘差網路和人工神經網路的混合深度學習模型，用於檢測急性病和慢性病，例如心臟病、肝硬化和視網膜疾病，其效能優於現有的模型。數據集準備涉及範疇資料轉換、降維和遺失資料合成等方面。特徵萃取使用範疇資料集的縮放器轉換和影像資料集的 ResNet 架構來有效執行。產生的特徵被整合到一個統一的分類模型中。嚴謹的實驗和評估導致視網膜眼底圖像、肝硬化分期和心臟病診斷預測的準確度分別高達 93%、99% 和 95%。所提出方法的有效性透過對 F1 分數、精確度和召回率指標的詳細分析來證明。本研究提供了方法論和實驗的全面探討，深入了解電子健康記錄中的深度學習預測分析。</paragraph>

##### **Enhancing Guardrails for Safe and Secure Healthcare AI**
2409.17190v1 by Ananya Gangavarapu

Generative AI holds immense promise in addressing global healthcare access
challenges, with numerous innovative applications now ready for use across
various healthcare domains. However, a significant barrier to the widespread
adoption of these domain-specific AI solutions is the lack of robust safety
mechanisms to effectively manage issues such as hallucination, misinformation,
and ensuring truthfulness. Left unchecked, these risks can compromise patient
safety and erode trust in healthcare AI systems. While general-purpose
frameworks like Llama Guard are useful for filtering toxicity and harmful
content, they do not fully address the stringent requirements for truthfulness
and safety in healthcare contexts. This paper examines the unique safety and
security challenges inherent to healthcare AI, particularly the risk of
hallucinations, the spread of misinformation, and the need for factual accuracy
in clinical settings. I propose enhancements to existing guardrails frameworks,
such as Nvidia NeMo Guardrails, to better suit healthcare-specific needs. By
strengthening these safeguards, I aim to ensure the secure, reliable, and
accurate use of AI in healthcare, mitigating misinformation risks and improving
patient safety.

摘要：生成式 AI 在解決全球醫療保健存取挑戰方面極具前景，許多創新應用現已準備好在各種醫療保健領域使用。然而，廣泛採用這些特定領域的 AI 解決方案面臨的一大障礙，是缺乏健全的安全機制來有效管理幻覺、錯誤資訊等問題，並確保真實性。如果不加以控制，這些風險可能會損害患者安全，並侵蝕對醫療保健 AI 系統的信任。雖然像 Llama Guard 這樣的通用框架有助於過濾有害和有害內容，但它們並未完全滿足醫療保健環境中對真實性和安全性的嚴格要求。本文探討了醫療保健 AI 固有的獨特安全性和安全性挑戰，特別是幻覺的風險、錯誤資訊的傳播，以及在臨床環境中對事實準確性的需求。我建議對現有的護欄框架（例如 Nvidia NeMo Guardrails）進行改進，以更好地滿足醫療保健的特定需求。通過加強這些保障措施，我旨在確保 AI 在醫療保健中的安全、可靠和準確使用，降低錯誤資訊風險並提高患者安全性。

##### **Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels**
2409.16563v1 by Yishu Wei, Xindi Wang, Hanley Ong, Yiliang Zhou, Adam Flanders, George Shih, Yifan Peng

Despite significant progress in applying large language models (LLMs) to the
medical domain, several limitations still prevent them from practical
applications. Among these are the constraints on model size and the lack of
cohort-specific labeled datasets. In this work, we investigated the potential
of improving a lightweight LLM, such as Llama 3.1-8B, through fine-tuning with
datasets using synthetic labels. Two tasks are jointly trained by combining
their respective instruction datasets. When the quality of the task-specific
synthetic labels is relatively high (e.g., generated by GPT4- o), Llama 3.1-8B
achieves satisfactory performance on the open-ended disease detection task,
with a micro F1 score of 0.91. Conversely, when the quality of the
task-relevant synthetic labels is relatively low (e.g., from the MIMIC-CXR
dataset), fine-tuned Llama 3.1-8B is able to surpass its noisy teacher labels
(micro F1 score of 0.67 v.s. 0.63) when calibrated against curated labels,
indicating the strong inherent underlying capability of the model. These
findings demonstrate the potential of fine-tuning LLMs with synthetic labels,
offering a promising direction for future research on LLM specialization in the
medical domain.

摘要：儘管將大型語言模型 (LLM) 應用於醫療領域已取得顯著進展，但仍有若干限制阻礙它們實際應用。其中包括模型大小的限制和缺乏特定於群體的標籤資料集。在這項工作中，我們探討了透過使用合成標籤微調資料集來改善輕量級 LLM（例如 Llama 3.1-8B）的潛力。透過結合各自的指令資料集，共同訓練兩個任務。當特定於任務的合成標籤品質相對較高時（例如，由 GPT4-o 產生），Llama 3.1-8B 在開放式疾病偵測任務中取得令人滿意的表現，微觀 F1 分數為 0.91。相反地，當與任務相關的合成標籤品質相對較低時（例如，來自 MIMIC-CXR 資料集），微調後的 Llama 3.1-8B 能夠超越其有雜訊的教師標籤（微觀 F1 分數為 0.67，相較於 0.63），並根據經過整理的標籤進行校準，這表示該模型具有強大的內在潛在能力。這些發現證明了使用合成標籤微調 LLM 的潛力，為未來針對 LLM 在醫療領域的專門化研究提供了有前景的方向。

##### **To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study**
2409.16486v1 by Imra Aqeel

The global pandemic due to emergence of COVID 19 has created the unrivaled
public health crisis. It has huge morbidity rate never comprehended in the
recent decades. Researchers have made many efforts to find the optimal solution
of this pandemic. Progressively, drug repurposing is an emergent and powerful
strategy with saving cost, time, and labor. Lacking of identified repurposed
drug candidates against COVID 19 demands more efforts to explore the potential
inhibitors for effective cure. In this study, we used the combination of
molecular docking and machine learning regression approaches to explore the
potential inhibitors for the treatment of COVID 19. We calculated the binding
affinities of these drugs to multitarget proteins using molecular docking
process. We perform the QSAR modeling by employing various machine learning
regression approaches to identify the potential inhibitors against COVID 19.
Our findings with best scores of R2 and RMSE demonstrated that our proposed
Decision Tree Regression (DTR) model is the most appropriate model to explore
the potential inhibitors. We proposed five novel promising inhibitors with
their respective Zinc IDs ZINC (3873365, 85432544, 8214470, 85536956, and
261494640) within the range of -19.7 kcal/mol to -12.6 kcal/mol. We further
analyzed the physiochemical and pharmacokinetic properties of these most potent
inhibitors to examine their behavior. The analysis of these properties is the
key factor to promote an effective cure for public health. Our work constructs
an efficient structure with which to probe the potential inhibitors against
COVID-19, creating the combination of molecular docking with machine learning
regression approaches.

摘要：由於 COVID-19 的出現，全球大流行造成了無與倫比的公共衛生危機。它在最近幾十年來從未見過如此高的發病率。研究人員已做出許多努力來尋找此一流行病的最佳解決方案。漸進式藥物再利用是一種新興且強大的策略，可節省成本、時間和勞力。缺乏針對 COVID-19 的已識別再利用藥物候選藥物，需要更多努力來探索潛在的抑制劑以進行有效治療。在本研究中，我們結合了分子對接和機器學習回歸方法來探索治療 COVID-19 的潛在抑制劑。我們使用分子對接程序計算這些藥物與多目標蛋白的結合親和力。我們透過採用各種機器學習回歸方法來執行 QSAR 建模，以識別針對 COVID-19 的潛在抑制劑。我們在 R2 和 RMSE 中獲得的最佳分數發現，我們提出的決策樹回歸 (DTR) 模型是最合適的模型，可探索潛在的抑制劑。我們提出了五種新穎且有希望的抑制劑，它們各自的 Zinc ID 為 ZINC (3873365、85432544、8214470、85536956 和 261494640)，範圍在 -19.7 kcal/mol 至 -12.6 kcal/mol 之間。我們進一步分析了這些最強效抑制劑的理化和藥代動力學特性，以檢驗它們的行為。這些特性的分析是促進公共衛生有效治療的關鍵因素。我們的研究建立了一個有效的結構，可用於探測針對 COVID-19 的潛在抑制劑，結合分子對接與機器學習回歸方法。

##### **Design and Evaluation of a CDSS for Drug Allergy Management Using LLMs and Pharmaceutical Data Integration**
2409.16395v1 by Gabriele De Vito, Filomena Ferrucci, Athanasios Angelakis

Medication errors significantly threaten patient safety, leading to adverse
drug events and substantial economic burdens on healthcare systems. Clinical
Decision Support Systems (CDSSs) aimed at mitigating these errors often face
limitations, including reliance on static databases and rule-based algorithms,
which can result in high false alert rates and alert fatigue among clinicians.
This paper introduces HELIOT, an innovative CDSS for drug allergy management,
integrating Large Language Models (LLMs) with a comprehensive pharmaceutical
data repository. HELIOT leverages advanced natural language processing
capabilities to interpret complex medical texts and synthesize unstructured
data, overcoming the limitations of traditional CDSSs. An empirical evaluation
using a synthetic patient dataset and expert-verified ground truth demonstrates
HELIOT's high accuracy, precision, recall, and F1 score, uniformly reaching
100\% across multiple experimental runs. The results underscore HELIOT's
potential to enhance decision support in clinical settings, offering a
scalable, efficient, and reliable solution for managing drug allergies.

摘要：藥物錯誤嚴重威脅患者安全，導致不良藥物事件和醫療系統的重大經濟負擔。旨在減輕這些錯誤的臨床決策支援系統 (CDSS) 經常面臨限制，包括依賴靜態資料庫和基於規則的演算法，這可能會導致臨床醫生之間的高誤報率和警報疲勞。本文介紹 HELIOT，一種創新的藥物過敏管理 CDSS，將大型語言模型 (LLM) 與全面的藥物資料庫整合在一起。HELIOT 利用先進的自然語言處理能力來解釋複雜的醫學文本並綜合非結構化資料，克服傳統 CDSS 的限制。使用合成患者資料集和專家驗證的地面實況進行的經驗評估證明了 HELIOT 的高準確度、精確度、召回率和 F1 分數，在多次實驗運行中均達到 100%。結果強調了 HELIOT 在臨床環境中增強決策支援的潛力，為管理藥物過敏提供可擴充、高效且可靠的解決方案。

##### **Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review**
2409.16340v1 by Nikolas Koutsoubis, Asim Waqas, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool

Artificial Intelligence (AI) has demonstrated significant potential in
automating various medical imaging tasks, which could soon become routine in
clinical practice for disease diagnosis, prognosis, treatment planning, and
post-treatment surveillance. However, the privacy concerns surrounding patient
data present a major barrier to the widespread adoption of AI in medical
imaging, as large, diverse training datasets are essential for developing
accurate, generalizable, and robust Artificial intelligence models. Federated
Learning (FL) offers a solution that enables organizations to train AI models
collaboratively without sharing sensitive data. federated learning exchanges
model training information, such as gradients, between the participating sites.
Despite its promise, federated learning is still in its developmental stages
and faces several challenges. Notably, sensitive information can still be
inferred from the gradients shared during model training. Quantifying AI
models' uncertainty is vital due to potential data distribution shifts
post-deployment, which can affect model performance. Uncertainty quantification
(UQ) in FL is particularly challenging due to data heterogeneity across
participating sites. This review provides a comprehensive examination of FL,
privacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL
methodologies and propose future research directions to enhance data privacy
and trustworthiness in medical imaging applications.

摘要：人工智慧 (AI) 已在自動化各種醫學影像任務中展現出顯著的潛力，這可能很快就會在疾病診斷、預後、治療規劃和治療後監測的臨床實務中成為例行公事。然而，圍繞著病患資料的隱私疑慮對 AI 在醫學影像中的廣泛採用構成了一項重大的障礙，因為龐大且多樣化的訓練資料集對於開發準確、可概括且強健的人工智慧模型至關重要。聯合學習 (FL) 提供了一項解決方案，讓組織能夠在不共享敏感資料的情況下協同訓練 AI 模型。聯合學習會在參與的各個站點之間交換模型訓練資訊，例如梯度。儘管聯合學習前景看好，但它仍處於開發階段，並面臨著若干挑戰。值得注意的是，即使在模型訓練期間共享，敏感資訊仍可能被推斷出來。由於模型部署後潛在的資料分佈轉移可能會影響模型效能，因此量化 AI 模型的不確定性至關重要。由於參與站點之間資料的異質性，聯合學習中的不確定性量化 (UQ) 特別具有挑戰性。此篇評論對聯合學習、隱私保護聯合學習 (PPFL) 和聯合學習中的不確定性量化進行了全面的探討。我們找出目前聯合學習方法中的關鍵差距，並提出未來的研究方向，以增強醫學影像應用中的資料隱私和可信度。

##### **Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**
2409.16231v1 by Henry Musto, Daniel Stamate, Doina Logofatu, Daniel Stahl

The paper proposes a novel approach of survival transformers and extreme
gradient boosting models in predicting cognitive deterioration in individuals
with mild cognitive impairment (MCI) using metabolomics data in the ADNI
cohort. By leveraging advanced machine learning and transformer-based
techniques applied in survival analysis, the proposed approach highlights the
potential of these techniques for more accurate early detection and
intervention in Alzheimer's dementia disease. This research also underscores
the importance of non-invasive biomarkers and innovative modelling tools in
enhancing the accuracy of dementia risk assessments, offering new avenues for
clinical practice and patient care. A comprehensive Monte Carlo simulation
procedure consisting of 100 repetitions of a nested cross-validation in which
models were trained and evaluated, indicates that the survival machine learning
models based on Transformer and XGBoost achieved the highest mean C-index
performances, namely 0.85 and 0.8, respectively, and that they are superior to
the conventional survival analysis Cox Proportional Hazards model which
achieved a mean C-Index of 0.77. Moreover, based on the standard deviations of
the C-Index performances obtained in the Monte Carlo simulation, we established
that both survival machine learning models above are more stable than the
conventional statistical model.

摘要：這篇論文提出了一種新的方法，使用 ADNI 隊伍中的代謝組學資料，在認知功能輕微受損 (MCI) 的個體中預測認知惡化，這種方法結合了生存轉換器和極端梯度提升模型。透過利用進階機器學習和基於轉換器的技術，應用於存活分析，提出的方法突顯了這些技術在阿茲海默症失智症中更準確的早期檢測和干預的潛力。這項研究也強調了非侵入性生物標記和創新建模工具在提升失智症風險評估準確度中的重要性，為臨床實務和病人照護提供了新途徑。一個包含 100 次巢狀交叉驗證重複的綜合蒙地卡羅模擬程序，其中模型經過訓練和評估，顯示基於轉換器和 XGBoost 的生存機器學習模型達到了最高的平均 C 指數表現，分別為 0.85 和 0.8，而且它們優於傳統的生存分析 Cox 比例風險模型，後者的平均 C 指數為 0.77。此外，根據蒙地卡羅模擬中獲得的 C 指數表現的標準差，我們確立了上述兩種生存機器學習模型都比傳統的統計模型更穩定。

##### **Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**
2409.16106v2 by Mehtab Ur Rahman, Martha Larson, Louis ten Bosch, Cristian Tejedor-García

Speech recordings are being more frequently used to detect and monitor
disease, leading to privacy concerns. Beyond cryptography, protection of speech
can be addressed by approaches, such as perturbation, disentanglement, and
re-synthesis, that eliminate sensitive information of the speaker, leaving the
information necessary for medical analysis purposes. In order for such privacy
protective approaches to be developed, clear and systematic specifications of
assumptions concerning medical settings and the needs of medical professionals
are necessary. In this paper, we propose a Scenario of Use Scheme that
incorporates an Attacker Model, which characterizes the adversary against whom
the speaker's privacy must be defended, and a Protector Model, which specifies
the defense. We discuss the connection of the scheme with previous work on
speech privacy. Finally, we present a concrete example of a specified Scenario
of Use and a set of experiments about protecting speaker data against gender
inference attacks while maintaining utility for Parkinson's detection.

摘要：語音錄音正越來越常被用於偵測和監測疾病，進而引發隱私疑慮。除了密碼學之外，語音保護還能透過擾動、解糾纏和重新合成等方法來達成，這些方法消除了說話者的敏感資訊，保留了醫療分析目的所需資訊。為了發展出此類保護隱私的方法，必須清楚且系統性地說明有關醫療環境的假設和醫療專業人員的需求。在本文中，我們提出了一個使用情境方案，其中包含攻擊者模型（用於描述必須保護說話者隱私的對手）和保護者模型（用於說明防禦措施）。我們探討了該方案與先前語音隱私研究的關聯。最後，我們提出了一個具體的使用情境範例，以及一組關於在維持帕金森氏症偵測效用的同時保護說話者資料免於性別推論攻擊的實驗。

##### **The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems**
2409.16098v1 by África Periáñez, Ana Fernández del Río, Ivan Nazarov, Enric Jané, Moiz Hassan, Aditya Rastogi, Dexian Tang

Mobile health has the potential to revolutionize health care delivery and
patient engagement. In this work, we discuss how integrating Artificial
Intelligence into digital health applications-focused on supply chain, patient
management, and capacity building, among other use cases-can improve the health
system and public health performance. We present an Artificial Intelligence and
Reinforcement Learning platform that allows the delivery of adaptive
interventions whose impact can be optimized through experimentation and
real-time monitoring. The system can integrate multiple data sources and
digital health applications. The flexibility of this platform to connect to
various mobile health applications and digital devices and send personalized
recommendations based on past data and predictions can significantly improve
the impact of digital tools on health system outcomes. The potential for
resource-poor settings, where the impact of this approach on health outcomes
could be more decisive, is discussed specifically. This framework is, however,
similarly applicable to improving efficiency in health systems where scarcity
is not an issue.

摘要：行動醫療具有革新醫療保健服務和患者參與的潛力。在這項工作中，我們討論如何將人工智慧整合到數位健康應用程式中，專注於供應鏈、患者管理和能力建構，以及其他使用案例，可以改善健康系統和公共衛生績效。我們提出一個人工智慧和強化學習平台，允許提供適應性介入措施，其影響可以透過實驗和即時監控進行最佳化。該系統可以整合多個資料來源和數位健康應用程式。此平台連接到各種行動醫療應用程式和數位裝置的靈活性，並根據過去的資料和預測發送個人化建議，可以顯著改善數位工具對健康系統成果的影響。特別討論了資源匱乏環境的潛力，在該環境中，這種方法對健康成果的影響可能更具決定性。然而，此架構同樣適用於改善健康系統的效率，其中稀缺性並非問題。

##### **Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**
2409.15910v1 by Kriti Agarwal, Samhruth Ananthanarayanan, Srinitish Srinivasan, Abirami S

This paper presents the development of a novel plant communication
application that allows plants to "talk" to humans using real-time sensor data
and AI-powered language models. Utilizing soil sensors that track moisture,
temperature, and nutrient levels, the system feeds this data into the Gemini
API, where it is processed and transformed into natural language insights about
the plant's health and "mood." Developed using Flutter, Firebase, and
ThingSpeak, the app offers a seamless user experience with real-time
interaction capabilities. By fostering human-plant connectivity, this system
enhances plant care practices, promotes sustainability, and introduces
innovative applications for AI and IoT technologies in both personal and
agricultural contexts. The paper explores the technical architecture, system
integration, and broader implications of AI-driven plant communication.

摘要：本文介紹了一款新穎的植物溝通應用程式的開發，它允許植物利用即時感測器資料和 AI 語言模型與人類「對話」。系統利用追蹤水分、溫度和養分含量的土壤感測器，將這些資料輸入 Gemini API，並在其中進行處理，轉換成關於植物健康和「情緒」的自然語言見解。此應用程式使用 Flutter、Firebase 和 ThingSpeak 開發，提供與即時互動功能無縫接軌的使用者體驗。透過促進人與植物的連結，此系統提升了植物照護方式，促進永續性，並在個人和農業情境中引進了 AI 和 IoT 技術的創新應用。本文探討了 AI 驅動的植物溝通技術架構、系統整合和更廣泛的意涵。

##### **AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**
2409.15815v1 by Adil Bahaj, Mounir Ghogho

Asthma rates have risen globally, driven by environmental and lifestyle
factors. Access to immediate medical care is limited, particularly in
developing countries, necessitating automated support systems. Large Language
Models like ChatGPT (Chat Generative Pre-trained Transformer) and Gemini have
advanced natural language processing in general and question answering in
particular, however, they are prone to producing factually incorrect responses
(i.e. hallucinations). Retrieval-augmented generation systems, integrating
curated documents, can improve large language models' performance and reduce
the incidence of hallucination. We introduce AsthmaBot, a multi-lingual,
multi-modal retrieval-augmented generation system for asthma support.
Evaluation of an asthma-related frequently asked questions dataset shows
AsthmaBot's efficacy. AsthmaBot has an added interactive and intuitive
interface that integrates different data modalities (text, images, videos) to
make it accessible to the larger public. AsthmaBot is available online via
\url{asthmabot.datanets.org}.

摘要：氣喘發生率在全球上升，原因在於環境和生活方式的因素。立即獲得醫療照護的管道有限，特別是在開發中國家，這使得自動化支援系統變得必要。大型語言模型，例如 ChatGPT（Chat Generative Pre-trained Transformer）和 Gemini，已提升一般自然語言處理和特別是問答的進展，然而，它們容易產生事實上不正確的回應（即幻覺）。擷取增強生成系統，整合策展文件，可以提升大型語言模型的效能並減少幻覺發生的機率。我們介紹 AsthmaBot，一個多語言、多模態擷取增強生成系統，用於氣喘支援。評估與氣喘相關的常見問題資料集顯示 AsthmaBot 的效能。AsthmaBot 有一個額外的互動且直覺的介面，它整合不同的資料模式（文字、圖片、影片），使其能讓更多大眾使用。AsthmaBot 可透過 \url{asthmabot.datanets.org} 線上取得。

##### **Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**
2409.15814v1 by Min Hun Lee, Renee Bao Xuan Ng, Silvana Xinyi Choo, Shamala Thilarajah

A growing research explores the usage of AI explanations on user's decision
phases for human-AI collaborative decision-making. However, previous studies
found the issues of overreliance on `wrong' AI outputs. In this paper, we
propose interactive example-based explanations to improve health professionals'
onboarding with AI for their better reliance on AI during AI-assisted
decision-making. We implemented an AI-based decision support system that
utilizes a neural network to assess the quality of post-stroke survivors'
exercises and interactive example-based explanations that systematically
surface the nearest neighborhoods of a test/task sample from the training set
of the AI model to assist users' onboarding with the AI model. To investigate
the effect of interactive example-based explanations, we conducted a study with
domain experts, health professionals to evaluate their performance and reliance
on AI. Our interactive example-based explanations during onboarding assisted
health professionals in having a better reliance on AI and making a higher
ratio of making `right' decisions and a lower ratio of `wrong' decisions than
providing only feature-based explanations during the decision-support phase.
Our study discusses new challenges of assisting user's onboarding with AI for
human-AI collaborative decision-making.

摘要：越來越多研究探討在人類與 AI 協作決策時，使用 AI 解釋對使用者決策階段的影響。然而，先前的研究發現過度依賴「錯誤」的 AI 輸出的問題。在本文中，我們提出互動式範例為基礎的解釋，以改善醫療專業人員與 AI 的整合，讓他們在 AI 輔助決策時能更依賴 AI。我們實作了一個基於 AI 的決策支援系統，它利用神經網路評估中風後倖存者運動的品質，並利用互動式範例為基礎的解釋，系統性地從 AI 模型的訓練集中找出測試/任務範例最近的鄰域，以協助使用者與 AI 模型整合。為了探討互動式範例為基礎的解釋的效果，我們進行了一項研究，找來領域專家和醫療專業人員評估他們的表現與對 AI 的依賴。我們在整合期間提供的互動式範例為基礎的解釋，協助醫療專業人員更依賴 AI，並且在決策支援階段中做出「正確」決策的比率較高，而做出「錯誤」決策的比率較低，優於只提供基於特徵的解釋。我們的研究探討了在人類與 AI 協作決策時，協助使用者與 AI 整合的新挑戰。

##### **Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm**
2409.15753v1 by Yooseok Lim, Inbeom Park, Sujee Lee

Appropriate medication dosages in the intensive care unit (ICU) are critical
for patient survival. Heparin, used to treat thrombosis and inhibit blood
clotting in the ICU, requires careful administration due to its complexity and
sensitivity to various factors, including patient clinical characteristics,
underlying medical conditions, and potential drug interactions. Incorrect
dosing can lead to severe complications such as strokes or excessive bleeding.
To address these challenges, this study proposes a reinforcement learning
(RL)-based personalized optimal heparin dosing policy that guides dosing
decisions reliably within the therapeutic range based on individual patient
conditions. A batch-constrained policy was implemented to minimize
out-of-distribution errors in an offline RL environment and effectively
integrate RL with existing clinician policies. The policy's effectiveness was
evaluated using weighted importance sampling, an off-policy evaluation method,
and the relationship between state representations and Q-values was explored
using t-SNE. Both quantitative and qualitative analyses were conducted using
the Medical Information Mart for Intensive Care III (MIMIC-III) database,
demonstrating the efficacy of the proposed RL-based medication policy.
Leveraging advanced machine learning techniques and extensive clinical data,
this research enhances heparin administration practices and establishes a
precedent for the development of sophisticated decision-support tools in
medicine.

摘要：在重症监护病房 (ICU) 中，适当的药物剂量对于患者的存活至关重要。肝素用于治疗血栓形成并抑制 ICU 中的血液凝结，由于其复杂性和对各种因素的敏感性，包括患者的临床特征、潜在的药物相互作用和基础疾病，因此需要谨慎给药。剂量不当会导致严重并发症，例如中风或过度出血。为了应对这些挑战，本研究提出了一种基于强化学习 (RL) 的个性化最佳肝素给药策略，该策略可以根据患者的个体情况在治疗范围内可靠地指导给药决策。实施了批约束策略以最大程度地减少离线 RL 环境中的分布外误差，并有效地将 RL 与现有的临床医生策略相结合。该策略的有效性使用加权重要性抽样（一种非策略评估方法）进行了评估，并使用 t-SNE 探索了状态表示和 Q 值之间的关系。使用重症监护 III（MIMIC-III）数据库进行了定量和定性分析，证明了所提出的基于 RL 的药物策略的有效性。利用先进的机器学习技术和广泛的临床数据，本研究增强了肝素给药实践，并为医学中复杂决策支持工具的开发树立了先例。

##### **dnaGrinder: a lightweight and high-capacity genomic foundation model**
2409.15697v1 by Qihang Zhao, Chi Zhang, Weixiong Zhang

The task of understanding and interpreting the complex information encoded
within genomic sequences remains a grand challenge in biological research and
clinical applications. In this context, recent advancements in large language
model research have led to the development of both encoder-only and
decoder-only foundation models designed to decode intricate information in DNA
sequences. However, several issues persist, particularly regarding the
efficient management of long-range dependencies inherent in genomic sequences,
the effective representation of nucleotide variations, and the considerable
computational costs associated with large model architectures and extensive
pretraining datasets. Current genomic foundation models often face a critical
tradeoff: smaller models with mediocre performance versus large models with
improved performance. To address these challenges, we introduce dnaGrinder, a
unique and efficient genomic foundation model. dnaGrinder excels at managing
long-range dependencies within genomic sequences while minimizing computational
costs without compromising performance. It achieves results that are not just
comparable but often superior to leading DNA models such as Nucleotide
Transformer and DNABERT-2. Furthermore, dnaGrinder is designed for easy
fine-tuning on workstation-grade GPUs, accommodating input lengths exceeding
17,000 tokens. On a single high-performance GPU, it supports sequences longer
than 140,000 tokens, making it a highly efficient and accessible tool for both
basic biological research and clinical applications.

摘要：理解和詮釋編碼在基因組序列中的複雜資訊，在生物研究和臨床應用中仍是一項重大挑戰。在此背景下，大型語言模型研究的最新進展已導致編碼器專用和解碼器專用基礎模型的開發，旨在解碼 DNA 序列中的複雜資訊。然而，仍存在一些問題，特別是在基因組序列中固有的長距離依賴性的有效管理、核苷酸變異的有效表示，以及與大型模型架構和廣泛預訓練資料集相關的龐大計算成本。目前的基因組基礎模型通常面臨一個關鍵的權衡：效能平庸的小型模型與效能提升的大型模型。為了解決這些挑戰，我們引入了 dnaGrinder，一個獨特且高效的基因組基礎模型。dnaGrinder 擅長管理基因組序列中的長距離依賴性，同時最小化計算成本，而不會損害效能。它所取得的成果不僅與領先的 DNA 模型（例如 Nucleotide Transformer 和 DNABERT-2）相當，而且往往更勝一籌。此外，dnaGrinder 設計為可輕鬆在工作站級 GPU 上進行微調，可容納長度超過 17,000 個符號的輸入。在單一高效能 GPU 上，它支援長度超過 140,000 個符號的序列，使其成為基礎生物研究和臨床應用中高效且易於存取的工具。

##### **Safe Navigation for Robotic Digestive Endoscopy via Human Intervention-based Reinforcement Learning**
2409.15688v1 by Min Tan, Yushun Tao, Boyun Zheng, GaoSheng Xie, Lijuan Feng, Zeyang Xia, Jing Xiong

With the increasing application of automated robotic digestive endoscopy
(RDE), ensuring safe and efficient navigation in the unstructured and narrow
digestive tract has become a critical challenge. Existing automated
reinforcement learning navigation algorithms, often result in potentially risky
collisions due to the absence of essential human intervention, which
significantly limits the safety and effectiveness of RDE in actual clinical
practice. To address this limitation, we proposed a Human Intervention
(HI)-based Proximal Policy Optimization (PPO) framework, dubbed HI-PPO, which
incorporates expert knowledge to enhance RDE's safety. Specifically, we
introduce an Enhanced Exploration Mechanism (EEM) to address the low
exploration efficiency of the standard PPO. Additionally, a reward-penalty
adjustment (RPA) is implemented to penalize unsafe actions during initial
interventions. Furthermore, Behavior Cloning Similarity (BCS) is included as an
auxiliary objective to ensure the agent emulates expert actions. Comparative
experiments conducted in a simulated platform across various anatomical colon
segments demonstrate that our model effectively and safely guides RDE.

摘要：隨著自動化機器人消化道內視鏡檢查 (RDE) 的應用日益廣泛，在結構化且狹窄的消化道中確保安全且有效率的導航已成為一項重大的挑戰。現有的自動化強化學習導航演算法，由於缺乏必要的介入，經常導致潛在的風險碰撞，這顯著限制了 RDE 在實際臨床實務中的安全性和有效性。為了解決此限制，我們提出了一個基於人類介入 (HI) 的近端策略最佳化 (PPO) 架構，稱為 HI-PPO，它結合了專家知識來增強 RDE 的安全性。具體來說，我們引入了一個增強探索機制 (EEM) 來解決標準 PPO 的低探索效率。此外，實施了獎勵懲罰調整 (RPA) 來懲罰在最初介入期間的不安全行為。此外，行為複製相似性 (BCS) 被納入作為輔助目標，以確保代理模擬專家行為。在模擬平台中進行的比較實驗，橫跨各種解剖結腸片段，證明我們的模型有效且安全地引導 RDE。

##### **A Comprehensive Evaluation of Large Language Models on Mental Illnesses**
2409.15687v1 by Abdelrahman Hanafi, Mohammed Saad, Noureldin Zahran, Radwa J. Hanafy, Mohammed E. Fouda

Large language models have shown promise in various domains, including
healthcare. In this study, we conduct a comprehensive evaluation of LLMs in the
context of mental health tasks using social media data. We explore the
zero-shot (ZS) and few-shot (FS) capabilities of various LLMs, including GPT-4,
Llama 3, Gemini, and others, on tasks such as binary disorder detection,
disorder severity evaluation, and psychiatric knowledge assessment. Our
evaluation involved 33 models testing 9 main prompt templates across the tasks.
Key findings revealed that models like GPT-4 and Llama 3 exhibited superior
performance in binary disorder detection, with accuracies reaching up to 85% on
certain datasets. Moreover, prompt engineering played a crucial role in
enhancing model performance. Notably, the Mixtral 8x22b model showed an
improvement of over 20%, while Gemma 7b experienced a similar boost in
performance. In the task of disorder severity evaluation, we observed that FS
learning significantly improved the model's accuracy, highlighting the
importance of contextual examples in complex assessments. Notably, the
Phi-3-mini model exhibited a substantial increase in performance, with balanced
accuracy improving by over 6.80% and mean average error dropping by nearly 1.3
when moving from ZS to FS learning. In the psychiatric knowledge task, recent
models generally outperformed older, larger counterparts, with the Llama 3.1
405b achieving an accuracy of 91.2%. Despite promising results, our analysis
identified several challenges, including variability in performance across
datasets and the need for careful prompt engineering. Furthermore, the ethical
guards imposed by many LLM providers hamper the ability to accurately evaluate
their performance, due to tendency to not respond to potentially sensitive
queries.

摘要：大型語言模型已在醫療保健等各個領域展現潛力。在本研究中，我們使用社群媒體資料對 LLM 在心理健康任務中的表現進行全面評估。我們探討各種 LLM，包括 GPT-4、Llama 3、Gemini 等，在二元障礙偵測、障礙嚴重性評估和精神疾病知識評估等任務上的零次學習 (ZS) 和少次學習 (FS) 能力。我們的評估涉及 33 個模型，在各項任務中測試 9 個主要提示範本。主要發現顯示，GPT-4 和 Llama 3 等模型在二元障礙偵測中表現出優異的效能，在特定資料集上的準確率高達 85%。此外，提示工程在提升模型效能方面扮演至關重要的角色。值得注意的是，Mixtral 8x22b 模型的進步幅度超過 20%，而 Gemma 7b 的效能也獲得類似的提升。在障礙嚴重性評估任務中，我們觀察到 FS 學習顯著提升模型的準確度，突顯出背景範例在複雜評估中的重要性。值得注意的是，Phi-3-mini 模型的效能大幅提升，從 ZS 學習轉換到 FS 學習後，平衡準確度提升超過 6.80%，平均平均誤差降低近 1.3。在精神疾病知識任務中，較新的模型通常優於較舊、較大的模型，其中 Llama 3.1 405b 達到 91.2% 的準確度。儘管有令人振奮的結果，我們的分析發現了幾個挑戰，包括跨資料集的效能變異性，以及仔細提示工程的需求。此外，許多 LLM 提供者施加的道德守則阻礙了準確評估其效能的能力，因為它們傾向於不回應潛在的敏感查詢。

##### **TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU**
2409.15586v2 by Rosemary Y. He, Jeffrey N. Chiang

Trajectory forecasting in healthcare data has been an important area of
research in precision care and clinical integration for computational methods.
In recent years, generative AI models have demonstrated promising results in
capturing short and long range dependencies in time series data. While these
models have also been applied in healthcare, most of them only predict one
value at a time, which is unrealistic in a clinical setting where multiple
measures are taken at once. In this work, we extend the framework temporal
fusion transformer (TFT), a multi-horizon time series prediction tool, and
propose TFT-multi, an end-to-end framework that can predict multiple vital
trajectories simultaneously. We apply TFT-multi to forecast 5 vital signs
recorded in the intensive care unit: blood pressure, pulse, SpO2, temperature
and respiratory rate. We hypothesize that by jointly predicting these measures,
which are often correlated with one another, we can make more accurate
predictions, especially in variables with large missingness. We validate our
model on the public MIMIC dataset and an independent institutional dataset, and
demonstrate that this approach outperforms state-of-the-art univariate
prediction tools including the original TFT and Prophet, as well as vector
regression modeling for multivariate prediction. Furthermore, we perform a
study case analysis by applying our pipeline to forecast blood pressure changes
in response to actual and hypothetical pressor administration.

摘要：醫療數據中的軌跡預測一直是精準照護和臨床整合中計算方法的重要研究領域。近年來，生成式 AI 模型在捕捉時間序列資料中的短程和長程依賴關係方面已展現出令人滿意的成果。儘管這些模型也已應用於醫療保健，但其中大多數一次只預測一個值，這在一次採取多項測量的臨床環境中是不切實際的。在這項工作中，我們擴充了時序融合Transformer (TFT) 這個多地平線時間序列預測工具，並提出 TFT-multi，這是一個可以同時預測多個重要軌跡的端對端框架。我們將 TFT-multi 應用於預測在加護病房中記錄的 5 個生命徵象：血壓、脈搏、SpO2、體溫和呼吸速率。我們假設透過共同預測這些通常彼此相關的測量值，我們可以做出更準確的預測，特別是在缺失值較多的變數中。我們在公開的 MIMIC 資料集和一個獨立的機構資料集上驗證我們的模型，並證明這種方法優於最先進的單變量預測工具，包括原始的 TFT 和 Prophet，以及用於多變量預測的向量回歸建模。此外，我們透過將我們的管道應用於預測對實際和假設的升壓劑給藥的反應，來執行案例分析研究血壓變化。

##### **MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis**
2409.16329v1 by Stanislav Kozák

Radiomics is a relatively new field which utilises automatically identified
features from radiological scans. It has found a widespread application,
particularly in oncology because many of the important oncological biomarkers
are not visible to the naked eye. The recent advent of big data, including in
medical imaging, and the development of new ML techniques brought the
possibility of faster and more accurate oncological diagnosis. Furthermore,
standardised mathematical feature extraction based on radiomics helps to
eliminate possible radiologist bias. This paper reviews the recent development
in the oncological use of MRI radiomic features. It focuses on the
identification of the isocitrate dehydrogenase (IDH) mutation status, which is
an important biomarker for the diagnosis of glioblastoma and grade IV
astrocytoma.

摘要：放射組學是一個相對較新的領域，它利用放射掃描自動識別的特徵。它已廣泛應用，特別是在腫瘤學中，因為許多重要的腫瘤生物標誌物肉眼不可見。包括醫學影像在內的大數據最近的出現以及新機器學習技術的發展帶來了更快、更準確的腫瘤學診斷的可能性。此外，基於放射組學的標準化數學特徵提取有助於消除可能的放射科醫師偏見。本文回顧了放射組學特徵在腫瘤學應用中的最新發展。它側重於異檸檬酸脫氫酶 (IDH) 突變狀態的識別，這是診斷膠質母細胞瘤和 IV 級星形細胞瘤的重要生物標誌物。

##### **Computational Pathology for Accurate Prediction of Breast Cancer Recurrence: Development and Validation of a Deep Learning-based Tool**
2409.15491v1 by Ziyu Su, Yongxin Guo, Robert Wesolowski, Gary Tozbikian, Nathaniel S. O'Connell, M. Khalid Khan Niazi, Metin N. Gurcan

Accurate recurrence risk stratification is crucial for optimizing treatment
plans for breast cancer patients. Current prognostic tools like Oncotype DX
(ODX) offer valuable genomic insights for HR+/HER2- patients but are limited by
cost and accessibility, particularly in underserved populations. In this study,
we present Deep-BCR-Auto, a deep learning-based computational pathology
approach that predicts breast cancer recurrence risk from routine H&E-stained
whole slide images (WSIs). Our methodology was validated on two independent
cohorts: the TCGA-BRCA dataset and an in-house dataset from The Ohio State
University (OSU). Deep-BCR-Auto demonstrated robust performance in stratifying
patients into low- and high-recurrence risk categories. On the TCGA-BRCA
dataset, the model achieved an area under the receiver operating characteristic
curve (AUROC) of 0.827, significantly outperforming existing weakly supervised
models (p=0.041). In the independent OSU dataset, Deep-BCR-Auto maintained
strong generalizability, achieving an AUROC of 0.832, along with 82.0%
accuracy, 85.0% specificity, and 67.7% sensitivity. These findings highlight
the potential of computational pathology as a cost-effective alternative for
recurrence risk assessment, broadening access to personalized treatment
strategies. This study underscores the clinical utility of integrating deep
learning-based computational pathology into routine pathological assessment for
breast cancer prognosis across diverse clinical settings.

摘要：精準的復發風險分層對於最佳化乳癌病患的治療計畫至關重要。目前的預後工具，例如 Oncotype DX (ODX)，為 HR+/HER2- 病患提供了有價值的基因體見解，但成本和可及性有限，特別是在服務不足的人群中。在本研究中，我們提出 Deep-BCR-Auto，一種基於深度學習的計算病理學方法，可從常規 H&E 染色的全玻片影像 (WSI) 預測乳癌復發風險。我們的技術在兩個獨立的群組中得到驗證：TCGA-BRCA 資料集和來自俄亥俄州立大學 (OSU) 的內部資料集。Deep-BCR-Auto 在將患者分層為低和高復發風險類別方面表現出強大的效能。在 TCGA-BRCA 資料集上，該模型在受試者作業特徵曲線 (AUROC) 下方達到了 0.827 的面積，顯著優於現有的弱監督模型 (p=0.041)。在獨立的 OSU 資料集中，Deep-BCR-Auto 保持了很強的泛化性，達到了 0.832 的 AUROC，以及 82.0% 的準確度、85.0% 的特異度和 67.7% 的敏感度。這些發現突顯了計算病理學作為復發風險評估的經濟有效替代方案的潛力，擴大了個人化治療策略的可及性。這項研究強調了將基於深度學習的計算病理學整合到乳癌預後的常規病理評估中，在不同的臨床環境中具有臨床效用。

##### **A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?**
2409.15277v1 by Yunfei Xie, Juncheng Wu, Haoqin Tu, Siwei Yang, Bingchen Zhao, Yongshuo Zong, Qiao Jin, Cihang Xie, Yuyin Zhou

Large language models (LLMs) have exhibited remarkable capabilities across
various domains and tasks, pushing the boundaries of our knowledge in learning
and cognition. The latest model, OpenAI's o1, stands out as the first LLM with
an internalized chain-of-thought technique using reinforcement learning
strategies. While it has demonstrated surprisingly strong capabilities on
various general language tasks, its performance in specialized fields such as
medicine remains unknown. To this end, this report provides a comprehensive
exploration of o1 on different medical scenarios, examining 3 key aspects:
understanding, reasoning, and multilinguality. Specifically, our evaluation
encompasses 6 tasks using data from 37 medical datasets, including two newly
constructed and more challenging question-answering (QA) tasks based on
professional medical quizzes from the New England Journal of Medicine (NEJM)
and The Lancet. These datasets offer greater clinical relevance compared to
standard medical QA benchmarks such as MedQA, translating more effectively into
real-world clinical utility. Our analysis of o1 suggests that the enhanced
reasoning ability of LLMs may (significantly) benefit their capability to
understand various medical instructions and reason through complex clinical
scenarios. Notably, o1 surpasses the previous GPT-4 in accuracy by an average
of 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios.
But meanwhile, we identify several weaknesses in both the model capability and
the existing evaluation protocols, including hallucination, inconsistent
multilingual ability, and discrepant metrics for evaluation. We release our raw
data and model outputs at https://ucsc-vlaa.github.io/o1_medicine/ for future
research.

摘要：大型語言模型 (LLM) 在各種領域和任務中展現出非凡的能力，推動了我們在學習和認知方面的知識界限。最新的模型，OpenAI 的 o1，脫穎而出，成為第一個使用強化學習策略內化思想鏈技術的 LLM。雖然它在各種一般語言任務中展現出驚人強大的能力，但它在醫學等專業領域的表現仍然未知。為此，本報告全面探討了 o1 在不同醫療情境中的表現，檢視了 3 個關鍵面向：理解、推理和多語言能力。具體來說，我們的評估涵蓋了使用來自 37 個醫療資料集的資料的 6 項任務，包括兩個新建構且更具挑戰性的問答 (QA) 任務，這些任務是根據新英格蘭醫學期刊 (NEJM) 和刺胳針雜誌的專業醫療測驗而來。與 MedQA 等標準醫療 QA 基準相比，這些資料集提供了更高的臨床相關性，更有效地轉化為實際的臨床效用。我們對 o1 的分析表明，LLM 增強的推理能力可能（顯著地）提升它們理解各種醫療指示和推理複雜臨床情境的能力。值得注意的是，o1 在 19 個資料集和兩個新建立的複雜 QA 情境中的準確度平均比先前的 GPT-4 高出 6.2% 和 6.6%。但同時，我們發現模型能力和現有評估協定中存在若干弱點，包括幻覺、不一致的多語言能力和評估的差異化指標。我們在 https://ucsc-vlaa.github.io/o1_medicine/ 發布我們的原始資料和模型輸出，以供未來研究。

##### **Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation**
2409.15260v1 by Yi-Fei Zhao, Allyn Bove, David Thompson, James Hill, Yi Xu, Yufan Ren, Andrea Hassman, Leming Zhou, Yanshan Wang

Low back pain (LBP) is a leading cause of disability globally. Following the
onset of LBP and subsequent treatment, adequate patient education is crucial
for improving functionality and long-term outcomes. Despite advancements in
patient education strategies, significant gaps persist in delivering
personalized, evidence-based information to patients with LBP. Recent
advancements in large language models (LLMs) and generative artificial
intelligence (GenAI) have demonstrated the potential to enhance patient
education. However, their application and efficacy in delivering educational
content to patients with LBP remain underexplored and warrant further
investigation. In this study, we introduce a novel approach utilizing LLMs with
Retrieval-Augmented Generation (RAG) and few-shot learning to generate tailored
educational materials for patients with LBP. Physical therapists manually
evaluated our model responses for redundancy, accuracy, and completeness using
a Likert scale. In addition, the readability of the generated education
materials is assessed using the Flesch Reading Ease score. The findings
demonstrate that RAG-based LLMs outperform traditional LLMs, providing more
accurate, complete, and readable patient education materials with less
redundancy. Having said that, our analysis reveals that the generated materials
are not yet ready for use in clinical practice. This study underscores the
potential of AI-driven models utilizing RAG to improve patient education for
LBP; however, significant challenges remain in ensuring the clinical relevance
and granularity of content generated by these models.

摘要：下背痛 (LBP) 是全球導致殘疾的主要原因。在 LBP 發作和後續治療後，充分的患者教育對於改善功能和長期結果至關重要。儘管患者教育策略取得進展，但向 LBP 患者提供個性化、循證信息的過程中仍存在顯著差距。大型語言模型 (LLM) 和生成式人工智能 (GenAI) 的最新進展已證明有增強患者教育的潛力。然而，它們在向 LBP 患者傳遞教育內容方面的應用和功效仍未得到充分探索，有待進一步調查。在本研究中，我們引入一種新方法，利用具有檢索增強生成 (RAG) 和少次學習的 LLM，為 LBP 患者生成量身定制的教育材料。物理治療師使用李克特量表手動評估我們的模型反應的冗餘性、準確性和完整性。此外，使用弗萊施閱讀簡易度評分評估生成的教育材料的可讀性。研究結果表明，基於 RAG 的 LLM 優於傳統 LLM，提供更準確、完整且可讀的患者教育材料，且冗餘性更低。話雖如此，我們的分析表明，生成的材料還不適合在臨床實務中使用。本研究強調了利用 RAG 的 AI 驅動模型在改善 LBP 患者教育方面的潛力；然而，確保這些模型生成的內容的臨床相關性和精細度仍存在重大挑戰。

##### **Boosting Healthcare LLMs Through Retrieved Context**
2409.15127v1 by Jordi Bayarri-Planas, Ashwin Kumar Gururajan, Dario Garcia-Gasulla

Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language processing, and yet, their factual inaccuracies and
hallucinations limits their application, particularly in critical domains like
healthcare. Context retrieval methods, by introducing relevant information as
input, have emerged as a crucial approach for enhancing LLM factuality and
reliability. This study explores the boundaries of context retrieval methods
within the healthcare domain, optimizing their components and benchmarking
their performance against open and closed alternatives. Our findings reveal how
open LLMs, when augmented with an optimized retrieval system, can achieve
performance comparable to the biggest private solutions on established
healthcare benchmarks (multiple-choice question answering). Recognizing the
lack of realism of including the possible answers within the question (a setup
only found in medical exams), and after assessing a strong LLM performance
degradation in the absence of those options, we extend the context retrieval
system in that direction. In particular, we propose OpenMedPrompt a pipeline
that improves the generation of more reliable open-ended answers, moving this
technology closer to practical application.

摘要：大型語言模型 (LLM) 在自然語言處理方面展現了卓越的能力，然而，它們的事實不準確和幻覺限制了它們的應用，特別是在醫療保健等關鍵領域。情境檢索方法透過引入相關資訊作為輸入，成為增強 LLM 事實性和可靠性的關鍵方法。本研究探討了情境檢索方法在醫療保健領域的界線，最佳化其元件，並根據開放和封閉的替代方案對其效能進行基準測試。我們的研究結果揭示了開放式 LLM 在結合最佳化檢索系統後，如何在既定的醫療保健基準（多選題答題）上達到與最大的私人解決方案相當的效能。認識到在問題中包含可能的答案（僅在醫學考試中發現的設定）缺乏現實性，並在評估在沒有這些選項的情況下 LLM 效能大幅下降後，我們將情境檢索系統擴展到該方向。特別是，我們提出 OpenMedPrompt，一個管道，用於改善更可靠的開放式答案的產生，讓這項技術更接近實際應用。

##### **Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network**
2409.15006v1 by Sijia Du, Chengfeng Zhou, Suncheng Xiang, Jianwei Xu, Dahong Qian

Objective: Depth estimation is crucial for endoscopic navigation and
manipulation, but obtaining ground-truth depth maps in real clinical scenarios,
such as the colon, is challenging. This study aims to develop a robust
framework that generalizes well to real colonoscopy images, overcoming
challenges like non-Lambertian surface reflection and diverse data
distributions. Methods: We propose a framework combining a convolutional neural
network (CNN) for capturing local features and a Transformer for capturing
global information. An uncertainty-based fusion block was designed to enhance
generalization by identifying complementary contributions from the CNN and
Transformer branches. The network can be trained with simulated datasets and
generalize directly to unseen clinical data without any fine-tuning. Results:
Our method is validated on multiple datasets and demonstrates an excellent
generalization ability across various datasets and anatomical structures.
Furthermore, qualitative analysis in real clinical scenarios confirmed the
robustness of the proposed method. Conclusion: The integration of local and
global features through the CNN-Transformer architecture, along with the
uncertainty-based fusion block, improves depth estimation performance and
generalization in both simulated and real-world endoscopic environments.
Significance: This study offers a novel approach to estimate depth maps for
endoscopy images despite the complex conditions in clinic, serving as a
foundation for endoscopic automatic navigation and other clinical tasks, such
as polyp detection and segmentation.

摘要：目標：深度估計對於內視鏡導航和操作至關重要，但在實際臨床場景中（例如結腸）取得真實深度圖非常具有挑戰性。本研究旨在開發一個強大的框架，可以很好地推廣到實際的結腸鏡檢查影像，克服非朗伯反射面和多樣化資料分佈等挑戰。方法：我們提出一個結合卷積神經網路（CNN）來擷取局部特徵和 Transformer 來擷取全局資訊的框架。設計了一個基於不確定性的融合區塊，透過識別 CNN 和 Transformer 分支的互補貢獻來增強泛化能力。網路可以用模擬資料集進行訓練，並直接推廣到未見過的臨床資料，而無需任何微調。結果：我們的模型在多個資料集上得到驗證，並展示出跨越各種資料集和解剖結構的出色泛化能力。此外，在實際臨床場景中的定性分析證實了所提出模型的穩健性。結論：透過 CNN-Transformer 架構整合局部和全局特徵，以及基於不確定性的融合區塊，改善了模擬和真實世界內視鏡環境中的深度估計效能和泛化能力。意義：本研究提供了一種新穎的方法來估計內視鏡影像的深度圖，儘管在臨床上有複雜的條件，但作為內視鏡自動導航和其他臨床任務（例如息肉檢測和分割）的基礎。

##### **DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models**
2409.14904v1 by Sangyeon Cho, Jangyeong Jeon, Dongjoon Lee, Changhee Lee, Junyeong Kim

The use of pre-trained language models fine-tuned to address specific
downstream tasks is a common approach in natural language processing (NLP).
However, acquiring domain-specific knowledge via fine-tuning is challenging.
Traditional methods involve pretraining language models using vast amounts of
domain-specific data before fine-tuning for particular tasks. This study
investigates emergency/non-emergency classification tasks based on electronic
medical record (EMR) data obtained from pediatric emergency departments (PEDs)
in Korea. Our findings reveal that existing domain-specific pre-trained
language models underperform compared to general language models in handling
N-lingual free-text data characteristics of non-English-speaking regions. To
address these limitations, we propose a domain knowledge transfer methodology
that leverages knowledge distillation to infuse general language models with
domain-specific knowledge via fine-tuning. This study demonstrates the
effective transfer of specialized knowledge between models by defining a
general language model as the student model and a domain-specific pre-trained
model as the teacher model. In particular, we address the complexities of EMR
data obtained from PEDs in non-English-speaking regions, such as Korea, and
demonstrate that the proposed method enhances classification performance in
such contexts. The proposed methodology not only outperforms baseline models on
Korean PED EMR data, but also promises broader applicability in various
professional and technical domains. In future works, we intend to extend this
methodology to include diverse non-English-speaking regions and address
additional downstream tasks, with the aim of developing advanced model
architectures using state-of-the-art KD techniques. The code is available in
https://github.com/JoSangYeon/DSG-KD.

摘要：<paragraph>使用針對特定下游任務進行微調的預先訓練語言模型是自然語言處理 (NLP) 中的常見方法。然而，透過微調來獲取特定領域的知識具有挑戰性。傳統方法涉及使用大量的特定領域資料來預訓練語言模型，然後針對特定任務進行微調。本研究調查了基於從韓國小兒急診科 (PED) 取得的電子醫療紀錄 (EMR) 資料的緊急/非緊急分類任務。我們的研究結果顯示，現有的特定領域預訓練語言模型在處理非英語系地區的 N 語言自由文字資料特性時，表現不如一般語言模型。為了解決這些限制，我們提出了一種領域知識轉移方法，該方法利用知識蒸餾，透過微調將一般語言模型注入特定領域的知識。本研究透過將一般語言模型定義為學生模型，將特定領域的預訓練模型定義為老師模型，展示了模型之間專業知識的有效轉移。特別是，我們解決了從非英語系地區（例如韓國）的 PED 取得的 EMR 資料的複雜性，並展示了所提出的方法增強了此類情境中的分類效能。所提出的方法不僅在韓文 PED EMR 資料上優於基準模型，還承諾在各種專業和技術領域中更廣泛的應用性。在未來的研究中，我們打算擴展此方法以納入不同的非英語系地區，並解決其他下游任務，目標是使用最先進的 KD 技術開發先進的模型架構。程式碼可在 https://github.com/JoSangYeon/DSG-KD 取得。</paragraph>

##### **Mammo-Clustering:A Weakly Supervised Multi-view Global-Local Context Clustering Network for Detection and Classification in Mammography**
2409.14876v1 by Shilong Yang, Chulong Zhang, Qi Zang, Juan Yu, Liang Zeng, Xiao Luo, Yexuan Xing, Xin Pan, Qi Li, Xiaokun Liang, Yaoqin Xie

Breast cancer has long posed a significant threat to women's health, making
early screening crucial for mitigating its impact. However, mammography, the
preferred method for early screening, faces limitations such as the burden of
double reading by radiologists, challenges in widespread adoption in remote and
underdeveloped areas, and obstacles in intelligent early screening development
due to data constraints. To address these challenges, we propose a weakly
supervised multi-view mammography early screening model for breast cancer based
on context clustering. Context clustering, a feature extraction structure that
is neither CNN nor transformer, combined with multi-view learning for
information complementation, presents a promising approach. The weak
supervision design specifically addresses data limitations. Our model achieves
state-of-the-art performance with fewer parameters on two public datasets, with
an AUC of 0.828 on the Vindr-Mammo dataset and 0.805 on the CBIS-DDSM dataset.
Our model shows potential in reducing the burden on doctors and increasing the
feasibility of breast cancer screening for women in underdeveloped regions.

摘要：乳癌長期以來對女性健康構成重大威脅，及早篩檢對於減輕其影響至關重要。然而，乳房攝影術作為早期篩檢的首選方式，卻面臨放射科醫師雙重判讀的負擔、在偏遠和未開發地區廣泛採用所面臨的挑戰，以及由於資料限制而導致的智慧型早期篩檢開發障礙等限制。為了應對這些挑戰，我們提出一個基於脈絡聚類的乳癌弱監督多視角乳房攝影早期篩檢模型。脈絡聚類是一種既非 CNN 也非轉換器的特徵提取結構，結合多視角學習進行資訊互補，提供了一個有前景的方法。弱監督設計特別解決了資料限制的問題。我們的模型在兩個公開資料集上以較少的參數達到了最先進的效能，在 Vindr-Mammo 資料集上的 AUC 為 0.828，在 CBIS-DDSM 資料集上的 AUC 為 0.805。我們的模型顯示出減輕醫生負擔和增加未開發地區女性乳癌篩檢可行性的潛力。

##### **Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images**
2409.14874v2 by Ahjol Senbi, Tianyu Huang, Fei Lyu, Qing Li, Yuhui Tao, Wei Shao, Qiang Chen, Chengyan Wang, Shuo Wang, Tao Zhou, Yizhe Zhang

We explore the feasibility and potential of building a ground-truth-free
evaluation model to assess the quality of segmentations generated by the
Segment Anything Model (SAM) and its variants in medical imaging. This
evaluation model estimates segmentation quality scores by analyzing the
coherence and consistency between the input images and their corresponding
segmentation predictions. Based on prior research, we frame the task of
training this model as a regression problem within a supervised learning
framework, using Dice scores (and optionally other metrics) along with mean
squared error to compute the training loss. The model is trained utilizing a
large collection of public datasets of medical images with segmentation
predictions from SAM and its variants. We name this model EvanySeg (Evaluation
of Any Segmentation in Medical Images). Our exploration of convolution-based
models (e.g., ResNet) and transformer-based models (e.g., ViT) suggested that
ViT yields better performance for this task. EvanySeg can be employed for
various tasks, including: (1) identifying poorly segmented samples by detecting
low-percentile segmentation quality scores; (2) benchmarking segmentation
models without ground truth by averaging quality scores across test samples;
(3) alerting human experts to poor-quality segmentation predictions during
human-AI collaboration by applying a threshold within the score space; and (4)
selecting the best segmentation prediction for each test sample at test time
when multiple segmentation models are available, by choosing the prediction
with the highest quality score. Models and code will be made available at
https://github.com/ahjolsenbics/EvanySeg.

摘要：<paragraph>我們探討建立一個無地面實相的評估模型，以評估由 Segment Anything Model (SAM) 及其在醫學影像中的變體所產生的分割品質的可行性和潛力。此評估模型透過分析輸入影像與其對應分割預測之間的相干性和一致性來估計分割品質分數。根據先前的研究，我們將訓練此模型的任務設定為監督式學習架構中的回歸問題，使用 Dice 分數（以及其他指標，可選擇）與平均平方誤差一起計算訓練損失。此模型使用來自 SAM 及其變體的分割預測的大型公共醫學影像資料集進行訓練。我們將此模型命名為 EvanySeg（醫學影像中任何分割的評估）。我們對基於卷積的模型（例如 ResNet）和基於Transformer的模型（例如 ViT）的探討表明，ViT 在此任務中表現得更好。EvanySeg 可用於各種任務，包括：(1) 透過偵測低百分位數分割品質分數來識別分割不良的樣本；(2) 透過平均測試樣本的品質分數來對沒有地面實相的分割模型進行基準測試；(3) 在人機協作期間，透過在分數空間中應用閾值來提醒人類專家注意品質不佳的分割預測；(4) 在測試時間為每個測試樣本選擇最佳分割預測（當有多個分割模型可用時），透過選擇具有最高品質分數的預測。模型和程式碼將在 https://github.com/ahjolsenbics/EvanySeg 提供。</paragraph>

##### **A-VL: Adaptive Attention for Large Vision-Language Models**
2409.14846v1 by Junyang Zhang, Mu Yuan, Ruiguang Zhong, Puhan Luo, Huiyou Zhan, Ningkang Zhang, Chengchen Hu, Xiangyang Li

The Large Vision-Language Model (LVLM) integrates computer vision and natural
language processing techniques, offering substantial application potential.
However, these models demand extensive resources during inference. Adaptive
attention techniques can dynamically reduce computational redundancy and thus
improve efficiency. Although current adaptive attention methods significantly
reduce the memory requirements of Transformer-based language models, they are
not tailored for LVLMs. We observe that LVLMs generate responses from both
remote image tokens and local text tokens, and different modalities have
different attention patterns. This observation inspires us to manage the
attention for each modality separately. Specifically, for visual input, we
store the cache of potentially useful information but only compute the most
critical parts. For language input, we care more about local information. Based
on our observation and analysis of vision-language attention patterns, we
develop A-VL, a plug-and-play adaptive attention tailored for LVLM inference.
Extensive evaluations on three vision-language tasks and five datasets show the
effectiveness of our designs. Our approach A-VL outperforms existing adaptive
attention methods in reducing memory usage and computational load without
compromising performance.

摘要：大型视觉语言模型 (LVLM) 整合了计算机视觉和自然语言处理技术，提供了大量的应用潜力。然而，这些模型在推理过程中需要大量的资源。自适应注意力技术可以动态减少计算冗余，从而提高效率。虽然当前的自适应注意力方法显著减少了基于 Transformer 的语言模型的内存需求，但它们并不适合 LVLM。我们观察到，LVLM 从远程图像标记和局部文本标记生成响应，并且不同的模态具有不同的注意力模式。这一观察启发了我们分别管理每个模态的注意力。具体来说，对于视觉输入，我们存储潜在有用信息的缓存，但只计算最关键的部分。对于语言输入，我们更关心局部信息。基于我们对视觉语言注意力模式的观察和分析，我们开发了 A-VL，这是一种针对 LVLM 推理量身定制的即插即用自适应注意力。在三个视觉语言任务和五个数据集上的广泛评估表明了我们设计的有效性。我们的方法 A-VL 在减少内存使用和计算负载方面优于现有的自适应注意力方法，同时不影响性能。

##### **Can Large Language Models Logically Predict Myocardial Infarction? Evaluation based on UK Biobank Cohort**
2409.14478v1 by Yuxing Zhi, Yuan Guo, Kai Yuan, Hesong Wang, Heng Xu, Haina Yao, Albert C Yang, Guangrui Huang, Yuping Duan

Background: Large language models (LLMs) have seen extraordinary advances
with applications in clinical decision support. However, high-quality evidence
is urgently needed on the potential and limitation of LLMs in providing
accurate clinical decisions based on real-world medical data. Objective: To
evaluate quantitatively whether universal state-of-the-art LLMs (ChatGPT and
GPT-4) can predict the incidence risk of myocardial infarction (MI) with
logical inference, and to further make comparison between various models to
assess the performance of LLMs comprehensively. Methods: In this retrospective
cohort study, 482,310 participants recruited from 2006 to 2010 were initially
included in UK Biobank database and later on resampled into a final cohort of
690 participants. For each participant, tabular data of the risk factors of MI
were transformed into standardized textual descriptions for ChatGPT
recognition. Responses were generated by asking ChatGPT to select a score
ranging from 0 to 10 representing the risk. Chain of Thought (CoT) questioning
was used to evaluate whether LLMs make prediction logically. The predictive
performance of ChatGPT was compared with published medical indices, traditional
machine learning models and other large language models. Conclusions: Current
LLMs are not ready to be applied in clinical medicine fields. Future medical
LLMs are suggested to be expert in medical domain knowledge to understand both
natural languages and quantified medical data, and further make logical
inferences.

摘要：<paragraph>背景：大型語言模型 (LLM) 已在臨床決策支持應用中取得非凡進展。然而，迫切需要高品質的證據來證明 LLM 在根據現實世界醫療數據提供準確臨床決策方面的潛力和限制。目標：定量評估通用最先進的 LLM（ChatGPT 和 GPT-4）是否能通過邏輯推理預測心肌梗塞 (MI) 的發生風險，並進一步在各種模型之間進行比較，以全面評估 LLM 的效能。方法：在這項回顧性隊列研究中，最初將 2006 年至 2010 年招募的 482,310 名參與者納入英國生物銀行資料庫，並隨後重新抽樣成 690 名參與者的最終隊列。對於每位參與者，MI 風險因子的表格資料都轉換成 ChatGPT 辨識的標準文字描述。回應是透過要求 ChatGPT 選擇一個介於 0 到 10 之間的評分來代表風險。思想鏈 (CoT) 提問用於評估 LLM 是否以邏輯方式進行預測。將 ChatGPT 的預測效能與已發表的醫療指數、傳統機器學習模型和其他大型語言模型進行比較。結論：目前的 LLM 尚未準備好應用於臨床醫學領域。建議未來的醫療 LLM 專精於醫療領域知識，以了解自然語言和量化的醫療數據，並進一步進行邏輯推理。</paragraph>

##### **Detection of pulmonary pathologies using convolutional neural networks, Data Augmentation, ResNet50 and Vision Transformers**
2409.14446v1 by Pablo Ramirez Amador, Dinarle Milagro Ortega, Arnold Cesarano

Pulmonary diseases are a public health problem that requires accurate and
fast diagnostic techniques. In this paper, a method based on convolutional
neural networks (CNN), Data Augmentation, ResNet50 and Vision Transformers
(ViT) is proposed to detect lung pathologies from medical images. A dataset of
X-ray images and CT scans of patients with different lung diseases, such as
cancer, pneumonia, tuberculosis and fibrosis, is used. The results obtained by
the proposed method are compared with those of other existing methods, using
performance metrics such as accuracy, sensitivity, specificity and area under
the ROC curve. The results show that the proposed method outperforms the other
methods in all metrics, achieving an accuracy of 98% and an area under the ROC
curve of 99%. It is concluded that the proposed method is an effective and
promising tool for the diagnosis of pulmonary pathologies by medical imaging.

摘要：肺部疾病是一種公共衛生問題，需要準確且快速的診斷技術。在本文中，提出了一種基於卷積神經網路 (CNN)、資料擴充、ResNet50 和視覺Transformer (ViT) 的方法，以從醫學影像中偵測肺部病理。我們使用了一組 X 光影像和不同肺部疾病患者的電腦斷層掃描，例如癌症、肺炎、肺結核和纖維化。將所提出的方法獲得的結果與其他現有方法的結果進行比較，使用準確度、敏感度、特異度和 ROC 曲線下的面積等效能指標。結果顯示，所提出的方法在所有指標上都優於其他方法，準確度達到 98%，ROC 曲線下的面積為 99%。結論是，所提出的方法是一種有效且有前途的工具，可透過醫學影像診斷肺部病理。

##### **Data-Driven Spatiotemporal Feature Representation and Mining in Multidimensional Time Series**
2409.14327v1 by Xu Yan, Yaoting Jiang, Wenyi Liu, Didi Yi, Haoyang Sang, Jianjun Wei

This paper explores a new method for time series data analysis, aiming to
overcome the limitations of traditional mining techniques when dealing with
multidimensional time series data. Time series data are extensively utilized in
diverse fields, including backend services for monitoring and optimizing IT
infrastructure, medical diagnosis through continuous patient monitoring and
health trend analysis, and internet business for tracking user behavior and
forecasting sales. However, since the effective information in time series data
is often hidden in sequence fragments, the uncertainty of their length,
quantity, and morphological variables brings challenges to mining. To this end,
this paper proposes a new spatiotemporal feature representation method, which
converts multidimensional time series (MTS) into one-dimensional event
sequences by transforming spatially varying events, and uses a series of event
symbols to represent the spatial structural information of multidimensional
coupling in the sequence, which has good interpretability. Then, this paper
introduces a variable-length tuple mining method to extract non-redundant key
event subsequences in event sequences as spatiotemporal structural features of
motion sequences. This method is an unsupervised method that does not rely on
large-scale training samples and defines a new model for representing the
spatiotemporal structural features of multidimensional time series. The
superior performance of the STEM model is verified by pattern classification
experiments on a variety of motion sequences. The research results of this
paper provide an important theoretical basis and technical support for
understanding and predicting human behavior patterns, and have far-reaching
practical application value.

摘要：<paragraph>本文探討了一種新的時間序列資料分析方法，旨在克服傳統挖掘技術在處理多維時間序列資料時的限制。時間序列資料廣泛用於各種領域，包括用於監控和最佳化 IT 基礎架構的後端服務、透過持續監控患者和健康趨勢分析進行的醫療診斷，以及用於追蹤使用者行為和預測銷售的網路業務。然而，由於時間序列資料中的有效資訊通常隱藏在序列片段中，因此其長度、數量和形態變數的不確定性為挖掘帶來了挑戰。為此，本文提出了一種新的時空特徵表示方法，該方法透過轉換空間上變化的事件將多維時間序列 (MTS) 轉換為一維事件序列，並使用一系列事件符號來表示序列中多維耦合的空間結構資訊，具有良好的可解釋性。然後，本文引入一種變長元組挖掘方法，以提取事件序列中非冗餘的關鍵事件子序列，作為動作序列的時空結構特徵。此方法是一種無監督方法，不依賴於大規模訓練樣本，並定義了一個新的模型來表示多維時間序列的時空結構特徵。STEM 模型的優異效能已通過各種動作序列上的模式分類實驗得到驗證。本文的研究成果為理解和預測人類行為模式提供了重要的理論基礎和技術支援，並具有深遠的實用應用價值。</paragraph>

##### **PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation**
2409.14302v1 by Yuxuan Zhou, Xien Liu, Chen Ning, Ji Wu

In the study, we aim to investigate current LLMs' mastery of medical factual
knowledge with a dynamic evaluation schema, which can automatically generate
multiple test samples for each medical factual knowledge point. Test samples
produced directly by LLMs always introduce factual errors and lack diversity in
the manner of knowledge expression. To overcome the drawbacks, here we propose
a novel evaluation method, Predicate-text Dual Transformation (PretextTrans),
by introducing predicate transformations into the dynamic evaluation schema.
Specifically, each medical knowledge point is firstly transformed into a
predicate expression; then, the predicate expression derives a series of
variants through predicate transformations; lastly, the produced predicate
variants are transformed back into textual expressions, resulting in a series
of test samples with both factual reliability and expression diversity. Using
the proposed PretextTrans method, we systematically investigate 12 well-known
LLMs' mastery of medical factual knowledge based on two medical datasets. The
comparison results show that current LLMs still have significant deficiencies
in fully mastering medical knowledge, which may illustrate why current LLMs
still perform unsatisfactorily in real-world medical scenarios despite having
achieved considerable performance on public benchmarks. Our proposed method
serves as an effective solution for evaluation of LLMs in medical domain and
offers valuable insights for developing medical-specific LLMs.

摘要：<paragraph>在研究中，我們旨在使用動態評估架構來調查當前 LLM 對醫學事實知識的掌握情況，該架構可以自動為每個醫學事實知識點生成多個測試樣本。由 LLM 直接產生的測試樣本總是會引入事實錯誤，並且在知識表達方式上缺乏多樣性。為了克服這些缺點，我們在此提出了一種新的評估方法，即謂詞-文本雙重轉換 (PretextTrans)，通過將謂詞轉換引入動態評估架構中。具體來說，每個醫學知識點首先被轉換為謂詞表達式；然後，謂詞表達式通過謂詞轉換得到一系列變體；最後，產生的謂詞變體被轉換回文本表達式，從而產生一系列既具有事實可靠性又具有表達多樣性的測試樣本。使用所提出的 PretextTrans 方法，我們系統地調查了 12 個著名的 LLM 對基於兩個醫學數據集的醫學事實知識的掌握情況。比較結果表明，當前 LLM 在完全掌握醫學知識方面仍然存在顯著的缺陷，這可能說明了為什麼當前 LLM 在現實世界的醫學場景中表現仍然不令人滿意，儘管在公共基準上取得了顯著的表現。我們提出的方法作為一種有效的解決方案，用於評估醫學領域的 LLM，並為開發特定於醫學的 LLM 提供了寶貴的見解。</paragraph>

##### **Data-Driven Approach to assess and identify gaps in healthcare set up in South Asia**
2409.14194v1 by Rusham Elahi, Zia Tahseen, Tehreem Fatima, Syed Wafa Zahra, Hafiz Muhammad Abubakar, Tehreem Zafar, Aqs Younas, Muhammad Talha Quddoos, Usman Nazir

Primary healthcare is a crucial strategy for achieving universal health
coverage. South Asian countries are working to improve their primary healthcare
system through their country specific policies designed in line with WHO health
system framework using the six thematic pillars: Health Financing, Health
Service delivery, Human Resource for Health, Health Information Systems,
Governance, Essential Medicines and Technology, and an addition area of
Cross-Sectoral Linkages. Measuring the current accessibility of healthcare
facilities and workforce availability is essential for improving healthcare
standards and achieving universal health coverage in developing countries.
Data-driven surveillance approaches are required that can provide rapid,
reliable, and geographically scalable solutions to understand a) which
communities and areas are most at risk of inequitable access and when, b) what
barriers to health access exist, and c) how they can be overcome in ways
tailored to the specific challenges faced by individual communities. We propose
to harness current breakthroughs in Earth-observation (EO) technology, which
provide the ability to generate accurate, up-to-date, publicly accessible, and
reliable data, which is necessary for equitable access planning and resource
allocation to ensure that vaccines, and other interventions reach everyone,
particularly those in greatest need, during normal and crisis times. This
requires collaboration among countries to identify evidence based solutions to
shape health policy and interventions, and drive innovations and research in
the region.

摘要：初級保健是實現全民健保的關鍵策略。南亞國家透過制定符合 WHO 健保系統架構的國家特定政策，使用六大主題支柱來改善其初級保健系統：健保融資、健保服務提供、健保人力資源、健保資訊系統、治理、基本藥物與技術，以及跨部門連結的附加領域。衡量當前健保設施的可及性和人力可得性，對於提升健保標準和在開發中國家實現全民健保至關重要。需要以資料為基礎的監控方法，才能提供快速、可靠且在地域上可擴充的解決方案，以了解 a) 哪些社區和地區最容易遭受不公平的醫療服務，以及何時會發生、b) 醫療服務存有哪方面的障礙，以及 c) 如何以針對各個社區所面臨特定挑戰的方式克服這些障礙。我們提議利用地球觀測 (EO) 技術的最新突破，這些技術能產生準確、最新、公開且可靠的資料，這對於公平的醫療服務規劃和資源分配至關重要，以確保疫苗和其他干預措施能惠及所有人，特別是在正常和危機時期最需要的人。這需要各國合作，找出證據為基礎的解決方案，以制定健保政策和干預措施，並推動該地區的創新和研究。

##### **Democratising Artificial Intelligence for Pandemic Preparedness and Global Governance in Latin American and Caribbean Countries**
2409.14181v1 by Andre de Carvalho, Robson Bonidia, Jude Dzevela Kong, Mariana Dauhajre, Claudio Struchiner, Guilherme Goedert, Peter F. Stadler, Maria Emilia Walter, Danilo Sanches, Troy Day, Marcia Castro, John Edmunds, Manuel Colome-Hidalgo, Demian Arturo Herrera Morban, Edian F. Franco, Cesar Ugarte-Gil, Patricia Espinoza-Lopez, Gabriel Carrasco-Escobar, Ulisses Rocha

Infectious diseases, transmitted directly or indirectly, are among the
leading causes of epidemics and pandemics. Consequently, several open
challenges exist in predicting epidemic outbreaks, detecting variants, tracing
contacts, discovering new drugs, and fighting misinformation. Artificial
Intelligence (AI) can provide tools to deal with these scenarios, demonstrating
promising results in the fight against the COVID-19 pandemic. AI is becoming
increasingly integrated into various aspects of society. However, ensuring that
AI benefits are distributed equitably and that they are used responsibly is
crucial. Multiple countries are creating regulations to address these concerns,
but the borderless nature of AI requires global cooperation to define
regulatory and guideline consensus. Considering this, The Global South AI for
Pandemic & Epidemic Preparedness & Response Network (AI4PEP) has developed an
initiative comprising 16 projects across 16 countries in the Global South,
seeking to strengthen equitable and responsive public health systems that
leverage Southern-led responsible AI solutions to improve prevention,
preparedness, and response to emerging and re-emerging infectious disease
outbreaks. This opinion introduces our branches in Latin American and Caribbean
(LAC) countries and discusses AI governance in LAC in the light of
biotechnology. Our network in LAC has high potential to help fight infectious
diseases, particularly in low- and middle-income countries, generating
opportunities for the widespread use of AI techniques to improve the health and
well-being of their communities.

摘要：傳染病的直接或間接傳播是造成流行病和全球大流行的主要原因之一。因此，在預測流行病爆發、檢測變異株、追蹤接觸者、發現新藥物和對抗錯誤訊息方面存在許多未解決的挑戰。人工智慧 (AI) 可提供應對這些情境的工具，在對抗 COVID-19 大流行方面展現出令人振奮的成果。AI 正日益融入社會的各個層面。然而，確保 AI 的好處能公平分配且負責任地使用至關重要。許多國家正制定法規來解決這些問題，但 AI 的無國界性質需要全球合作才能定義法規和指導方針的共識。有鑑於此，全球南方 AI 防疫和流行病防範及應變網路 (AI4PEP) 已開發一項計畫，包含全球南方 16 個國家/地區的 16 個專案，旨在強化公平且具應變能力的公共衛生系統，並利用南方主導的負責任 AI 解決方案來改善對新興和再興傳染病爆發的預防、防範和應變。本意見書介紹我們在拉丁美洲和加勒比海 (LAC) 國家的分支機構，並根據生物技術探討 LAC 中的 AI 治理。我們在 LAC 的網路極具潛力，有助於對抗傳染病，特別是在低收入和中等收入國家，並為廣泛使用 AI 技術創造機會，以改善其社區的健康和福祉。

##### **CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data**
2409.13903v1 by Zhao Cheng, Diane Wan, Matthew Abueg, Sahra Ghalebikesabi, Ren Yi, Eugene Bagdasarian, Borja Balle, Stefan Mellem, Shawn O'Banion

Advances in generative AI point towards a new era of personalized
applications that perform diverse tasks on behalf of users. While general AI
assistants have yet to fully emerge, their potential to share personal data
raises significant privacy challenges. This paper introduces CI-Bench, a
comprehensive synthetic benchmark for evaluating the ability of AI assistants
to protect personal information during model inference. Leveraging the
Contextual Integrity framework, our benchmark enables systematic assessment of
information flow across important context dimensions, including roles,
information types, and transmission principles. We present a novel, scalable,
multi-step synthetic data pipeline for generating natural communications,
including dialogues and emails. Unlike previous work with smaller, narrowly
focused evaluations, we present a novel, scalable, multi-step data pipeline
that synthetically generates natural communications, including dialogues and
emails, which we use to generate 44 thousand test samples across eight domains.
Additionally, we formulate and evaluate a naive AI assistant to demonstrate the
need for further study and careful training towards personal assistant tasks.
We envision CI-Bench as a valuable tool for guiding future language model
development, deployment, system design, and dataset construction, ultimately
contributing to the development of AI assistants that align with users' privacy
expectations.

摘要：生成式 AI 的進展指向一個新的個人化應用程式時代，這些應用程式可以代表使用者執行各種任務。儘管通用 AI 助理尚未完全出現，但它們共享個人資料的潛力引發了重大的隱私挑戰。本文介紹 CI-Bench，一個全面的合成基準，用於評估 AI 助理在模型推論期間保護個人資訊的能力。利用情境完整性架構，我們的基準可以系統性地評估跨越重要情境維度的資訊流，包括角色、資訊類型和傳輸原則。我們提出了一個新穎、可擴充、多步驟的合成資料管道，用於產生自然溝通，包括對話和電子郵件。與先前針對較小、重點較窄的評估所做的工作不同，我們提出了一個新穎、可擴充、多步驟的資料管道，可以合成產生自然溝通，包括對話和電子郵件，我們使用這些資料在八個網域中產生了 44,000 個測試範例。此外，我們制定並評估了一個天真的 AI 助理，以證明需要進一步研究和仔細培訓，才能執行個人助理任務。我們將 CI-Bench 視為指導未來語言模型開發、部署、系統設計和資料集建構的寶貴工具，最終有助於開發符合使用者隱私預期的 AI 助理。

##### **Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in Ophthalmology**
2409.13902v1 by Aidan Gilson, Xuguang Ai, Thilaka Arunachalam, Ziyou Chen, Ki Xiong Cheong, Amisha Dave, Cameron Duic, Mercy Kibe, Annette Kaminaka, Minali Prasad, Fares Siddig, Maxwell Singer, Wendy Wong, Qiao Jin, Tiarnan D. L. Keenan, Xia Hu, Emily Y. Chew, Zhiyong Lu, Hua Xu, Ron A. Adelman, Yih-Chung Tham, Qingyu Chen

Despite the potential of Large Language Models (LLMs) in medicine, they may
generate responses lacking supporting evidence or based on hallucinated
evidence. While Retrieval Augment Generation (RAG) is popular to address this
issue, few studies implemented and evaluated RAG in downstream domain-specific
applications. We developed a RAG pipeline with 70,000 ophthalmology-specific
documents that retrieve relevant documents to augment LLMs during inference
time. In a case study on long-form consumer health questions, we systematically
evaluated the responses including over 500 references of LLMs with and without
RAG on 100 questions with 10 healthcare professionals. The evaluation focuses
on factuality of evidence, selection and ranking of evidence, attribution of
evidence, and answer accuracy and completeness. LLMs without RAG provided 252
references in total. Of which, 45.3% hallucinated, 34.1% consisted of minor
errors, and 20.6% were correct. In contrast, LLMs with RAG significantly
improved accuracy (54.5% being correct) and reduced error rates (18.8% with
minor hallucinations and 26.7% with errors). 62.5% of the top 10 documents
retrieved by RAG were selected as the top references in the LLM response, with
an average ranking of 4.9. The use of RAG also improved evidence attribution
(increasing from 1.85 to 2.49 on a 5-point scale, P<0.001), albeit with slight
decreases in accuracy (from 3.52 to 3.23, P=0.03) and completeness (from 3.47
to 3.27, P=0.17). The results demonstrate that LLMs frequently exhibited
hallucinated and erroneous evidence in the responses, raising concerns for
downstream applications in the medical domain. RAG substantially reduced the
proportion of such evidence but encountered challenges.

摘要：儘管大型語言模型（LLM）在醫學領域具有潛力，但它們可能會產生缺乏支持證據或基於虛構證據的回應。雖然檢索擴充生成（RAG）很受歡迎，用於解決此問題，但很少有研究在下游特定領域的應用中實施和評估 RAG。我們開發了一個 RAG 管線，其中包含 70,000 份特定於眼科的文件，這些文件會在推理時間檢索相關文件以擴充 LLM。在針對長篇消費者健康問題的案例研究中，我們系統性地評估了 LLM 的回應，包括 100 個問題中 500 多個引用，其中 10 個問題由 10 位醫療保健專業人員提出。評估重點在於證據的真實性、證據的選擇和排名、證據的歸因，以及答案的準確性和完整性。沒有 RAG 的 LLM 總共提供了 252 個參考。其中，45.3% 是虛構的，34.1% 包含輕微錯誤，20.6% 是正確的。相比之下，帶有 RAG 的 LLM 大幅提高了準確度（54.5% 是正確的）並降低了錯誤率（18.8% 有輕微虛構，26.7% 有錯誤）。RAG 檢索的前 10 份文件中有 62.5% 被選為 LLM 回應中的首要參考，平均排名為 4.9。RAG 的使用也改進了證據歸因（在 5 分量表上從 1.85 增加到 2.49，P<0.001），儘管準確度（從 3.52 降低到 3.23，P=0.03）和完整性（從 3.47 降低到 3.27，P=0.17）略有下降。結果表明，LLM 在回應中經常表現出虛構和錯誤的證據，這引起了對醫療領域下游應用程序的擔憂。RAG 大幅減少了此類證據的比例，但遇到了挑戰。

##### **A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics**
2409.13825v1 by Mengyun Qiao, Kathryn A McGurk, Shuo Wang, Paul M. Matthews, Declan P O Regan, Wenjia Bai

Understanding the structure and motion of the heart is crucial for diagnosing
and managing cardiovascular diseases, the leading cause of global death. There
is wide variation in cardiac shape and motion patterns, that are influenced by
demographic, anthropometric and disease factors. Unravelling the normal
patterns of shape and motion, as well as understanding how each individual
deviates from the norm, would facilitate accurate diagnosis and personalised
treatment strategies. To this end, we developed a novel conditional generative
model, MeshHeart, to learn the distribution of cardiac shape and motion
patterns. MeshHeart is capable of generating 3D+t cardiac mesh sequences,
taking into account clinical factors such as age, sex, weight and height. To
model the high-dimensional and complex spatio-temporal mesh data, MeshHeart
employs a geometric encoder to represent cardiac meshes in a latent space,
followed by a temporal Transformer to model the motion dynamics of latent
representations. Based on MeshHeart, we investigate the latent space of 3D+t
cardiac mesh sequences and propose a novel distance metric termed latent delta,
which quantifies the deviation of a real heart from its personalised normative
pattern in the latent space. In experiments using a large dataset of 38,309
subjects, MeshHeart demonstrates a high performance in cardiac mesh sequence
reconstruction and generation. Features defined in the latent space are highly
discriminative for cardiac disease classification, whereas the latent delta
exhibits strong correlation with clinical phenotypes in phenome-wide
association studies. The codes and models of this study will be released to
benefit further research on digital heart modelling.

摘要：<paragraph>了解心脏的结构和运动对于诊断和管理心血管疾病至关重要，而心血管疾病是全球主要的死亡原因。心脏的形状和运动模式有很大的差异，这些差异受人口统计学、人体测量学和疾病因素的影响。解开形状和运动的正常模式，以及了解每个人如何偏离常态，将有助于准确诊断和个性化治疗策略。为此，我们开发了一种新颖的条件生成模型 MeshHeart，以学习心脏形状和运动模式的分布。MeshHeart 能够生成 3D+t 心脏网格序列，同时考虑年龄、性别、体重和身高等临床因素。为了对高维和复杂的时空网格数据建模，MeshHeart 采用几何编码器在潜在空间中表示心脏网格，然后采用时间转换器对潜在表示的运动动态进行建模。基于 MeshHeart，我们研究了 3D+t 心脏网格序列的潜在空间，并提出了一个新颖的距离度量，称为潜在增量，该度量量化了真实心脏在其潜在空间中与其个性化规范模式的偏差。在使用包含 38,309 名受试者的庞大数据集进行的实验中，MeshHeart 在心脏网格序列重建和生成方面表现出很高的性能。在潜在空间中定义的特征对于心脏疾病分类具有很高的判别力，而潜在增量在全表型关联研究中与临床表型表现出很强的相关性。本研究的代码和模型将发布，以造福对数字心脏建模的进一步研究。</paragraph>

##### **Morphological Detection and Classification of Microplastics and Nanoplastics Emerged from Consumer Products by Deep Learning**
2409.13688v1 by Hadi Rezvani, Navid Zarrabi, Ishaan Mehta, Christopher Kolios, Hussein Ali Jaafar, Cheng-Hao Kao, Sajad Saeedi, Nariman Yousefi

Plastic pollution presents an escalating global issue, impacting health and
environmental systems, with micro- and nanoplastics found across mediums from
potable water to air. Traditional methods for studying these contaminants are
labor-intensive and time-consuming, necessitating a shift towards more
efficient technologies. In response, this paper introduces micro- and
nanoplastics (MiNa), a novel and open-source dataset engineered for the
automatic detection and classification of micro and nanoplastics using object
detection algorithms. The dataset, comprising scanning electron microscopy
images simulated under realistic aquatic conditions, categorizes plastics by
polymer type across a broad size spectrum. We demonstrate the application of
state-of-the-art detection algorithms on MiNa, assessing their effectiveness
and identifying the unique challenges and potential of each method. The dataset
not only fills a critical gap in available resources for microplastic research
but also provides a robust foundation for future advancements in the field.

摘要：塑膠污染是一個日益嚴重的全球議題，影響健康和環境系統，從飲用水到空氣中都發現了微塑膠和奈米塑膠。傳統研究這些污染物的技術費時費力，因此有必要轉向更有效率的技術。為了解決這個問題，本文介紹微塑膠和奈米塑膠 (MiNa)，這是一個新穎的開源資料集，專門用於使用物件偵測演算法自動偵測和分類微塑膠和奈米塑膠。該資料集包含在逼真的水生環境下模擬的掃描電子顯微鏡影像，並根據聚合物類型對塑膠進行分類，涵蓋廣泛的尺寸範圍。我們展示了在 MiNa 上應用最先進的偵測演算法，評估其有效性，並找出每種方法的獨特挑戰和潛力。該資料集不僅填補了微塑膠研究可用資源的關鍵缺口，也為該領域未來的進展奠定了穩固的基礎。

##### **Depression Diagnosis Dialogue Simulation: Self-improving Psychiatrist with Tertiary Memory**
2409.15084v1 by Kunyao Lan, Bingui Jin, Zichen Zhu, Siyuan Chen, Shu Zhang, Kenny Q. Zhu, Mengyue Wu

Mental health issues, particularly depressive disorders, present significant
challenges in contemporary society, necessitating the development of effective
automated diagnostic methods. This paper introduces the Agent Mental Clinic
(AMC), a self-improving conversational agent system designed to enhance
depression diagnosis through simulated dialogues between patient and
psychiatrist agents. To enhance the dialogue quality and diagnosis accuracy, we
design a psychiatrist agent consisting of a tertiary memory structure, a
dialogue control and reflect plugin that acts as ``supervisor'' and a memory
sampling module, fully leveraging the skills reflected by the psychiatrist
agent, achieving great accuracy on depression risk and suicide risk diagnosis
via conversation. Experiment results on datasets collected in real-life
scenarios demonstrate that the system, simulating the procedure of training
psychiatrists, can be a promising optimization method for aligning LLMs with
real-life distribution in specific domains without modifying the weights of
LLMs, even when only a few representative labeled cases are available.

摘要：心理健康問題，尤其是憂鬱症，對現代社會構成重大挑戰，因此有必要開發有效的自動診斷方法。本文介紹了 Agent Mental Clinic (AMC)，這是一個自我提升的對話代理系統，旨在透過患者和精神科醫師代理之間的模擬對話來加強憂鬱症的診斷。為了提升對話品質和診斷準確度，我們設計了一個精神科醫師代理，它包含一個三級記憶結構、一個對話控制和反映插件（作為「監督者」）和一個記憶體抽樣模組，充分利用精神科醫師代理反映的技能，透過對話在憂鬱症風險和自殺風險診斷上取得極高的準確度。在現實生活中收集的資料集上的實驗結果表明，這個系統模擬了精神科醫師的訓練程序，可以成為一種有前途的最佳化方法，用於在不修改 LLM 權重的條件下，將 LLM 與特定領域的真實生活分佈對齊，即使只有少數具有代表性的標記案例可用。

##### **Toward Automated Clinical Transcriptions**
2409.15378v1 by Mitchell A. Klusty, W. Vaiden Logan, Samuel E. Armstrong, Aaron D. Mullen, Caroline N. Leach, Jeff Talbert, V. K. Cody Bumgardner

Administrative documentation is a major driver of rising healthcare costs and
is linked to adverse outcomes, including physician burnout and diminished
quality of care. This paper introduces a secure system that applies recent
advancements in speech-to-text transcription and speaker-labeling (diarization)
to patient-provider conversations. This system is optimized to produce accurate
transcriptions and highlight potential errors to promote rapid human
verification, further reducing the necessary manual effort. Applied to over 40
hours of simulated conversations, this system offers a promising foundation for
automating clinical transcriptions.

摘要：行政文件是醫療保健成本上升的主要驅動力，並與不良結果有關，包括醫師倦怠和醫療品質下降。本文介紹了一個安全的系統，該系統將語音轉文字轉錄和說話者標籤（日記）的最新進展應用於患者與提供者的對話。此系統經過最佳化，可產生準確的轉錄並強調潛在錯誤，以促進快速的人工驗證，進一步減少必要的作業。應用於超過 40 小時的模擬對話，此系統為自動化臨床轉錄提供了有希望的基礎。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Differentially Private Multimodal Laplacian Dropout (DP-MLD) for EEG Representative Learning**
2409.13440v1 by Xiaowen Fu, Bingxin Wang, Xinzhou Guo, Guoqing Liu, Yang Xiang

Recently, multimodal electroencephalogram (EEG) learning has shown great
promise in disease detection. At the same time, ensuring privacy in clinical
studies has become increasingly crucial due to legal and ethical concerns. One
widely adopted scheme for privacy protection is differential privacy (DP)
because of its clear interpretation and ease of implementation. Although
numerous methods have been proposed under DP, it has not been extensively
studied for multimodal EEG data due to the complexities of models and signal
data considered there. In this paper, we propose a novel Differentially Private
Multimodal Laplacian Dropout (DP-MLD) scheme for multimodal EEG learning. Our
approach proposes a novel multimodal representative learning model that
processes EEG data by language models as text and other modal data by vision
transformers as images, incorporating well-designed cross-attention mechanisms
to effectively extract and integrate cross-modal features. To achieve DP, we
design a novel adaptive feature-level Laplacian dropout scheme, where
randomness allocation and performance are dynamically optimized within given
privacy budgets. In the experiment on an open-source multimodal dataset of
Freezing of Gait (FoG) in Parkinson's Disease (PD), our proposed method
demonstrates an approximate 4\% improvement in classification accuracy, and
achieves state-of-the-art performance in multimodal EEG learning under DP.

摘要：<paragraph>最近，多模态脑电图 (EEG) 学习在疾病检测方面显示出了巨大的前景。与此同时，由于法律和道德方面的考虑，在临床研究中确保隐私变得越来越重要。差分隐私 (DP) 是一种被广泛采用的隐私保护方案，因为它具有清晰的解释和易于实现的特点。尽管在 DP 下已经提出了许多方法，但由于所考虑的模型和信号数据的复杂性，尚未对其在多模态 EEG 数据中进行广泛的研究。在本文中，我们提出了一种新颖的差分隐私多模态拉普拉斯 Dropout（DP-MLD）方案，用于多模态 EEG 学习。我们的方法提出了一种新颖的多模态表示学习模型，该模型通过语言模型将 EEG 数据处理为文本，并将其他模态数据通过视觉转换器处理为图像，并结合精心设计的交叉注意力机制来有效提取和整合跨模态特征。为了实现 DP，我们设计了一种新颖的自适应特征级拉普拉斯 Dropout 方案，其中在给定的隐私预算内动态优化随机性分配和性能。在帕金森病 (PD) 中步态冻结 (FoG) 的开源多模态数据集上的实验中，我们提出的方法在分类准确性方面显示出约 4% 的提升，并在 DP 下的多模态 EEG 学习中实现了最先进的性能。</paragraph>

##### **FPBoost: Fully Parametric Gradient Boosting for Survival Analysis**
2409.13363v1 by Alberto Archetti, Eugenio Lomurno, Diego Piccinotti, Matteo Matteucci

Survival analysis is a critical tool for analyzing time-to-event data and
extracting valuable clinical insights. Recently, numerous machine learning
techniques leveraging neural networks and decision trees have been developed
for this task. Among these, the most successful approaches often rely on
specific assumptions about the shape of the modeled hazard function. These
assumptions include proportional hazard, accelerated failure time, or discrete
estimation at a predefined set of time points. In this study, we propose a
novel paradigm for survival model design based on the weighted sum of
individual fully parametric hazard contributions. We build upon well-known
ensemble techniques to deliver a novel contribution to the field by applying
additive hazard functions, improving over approaches based on survival or
cumulative hazard functions. Furthermore, the proposed model, which we call
FPBoost, is the first algorithm to directly optimize the survival likelihood
via gradient boosting. We evaluated our approach across a diverse set of
datasets, comparing it against a variety of state-of-the-art models. The
results demonstrate that FPBoost improves risk estimation, according to both
concordance and calibration metrics.

摘要：生存分析是分析事件发生时间数据和提取有价值的临床见解的关键工具。最近，已经开发出许多利用神经网络和决策树的机器学习技术来完成此任务。其中，最成功的做法通常依赖于对建模风险函数形状的特定假设。这些假设包括比例风险、加速失效时间或在预定义时间点进行离散估计。在这项研究中，我们提出了一种基于加权和的个体全参数风险贡献的新型生存模型设计范例。我们建立在众所周知的集成技术之上，通过应用加性风险函数，对该领域做出新的贡献，改进基于生存或累积风险函数的方法。此外，我们称之为 FPBoost 的提议模型是第一个直接通过梯度提升优化生存可能性的算法。我们对各种数据集评估了我们的方法，并将其与各种最先进的模型进行了比较。结果表明，根据一致性和校准指标，FPBoost 改进了风险估计。

##### **Multi-omics data integration for early diagnosis of hepatocellular carcinoma (HCC) using machine learning**
2409.13791v1 by Annette Spooner, Mohammad Karimi Moridani, Azadeh Safarchi, Salim Maher, Fatemeh Vafaee, Amany Zekry, Arcot Sowmya

The complementary information found in different modalities of patient data
can aid in more accurate modelling of a patient's disease state and a better
understanding of the underlying biological processes of a disease. However, the
analysis of multi-modal, multi-omics data presents many challenges, including
high dimensionality and varying size, statistical distribution, scale and
signal strength between modalities. In this work we compare the performance of
a variety of ensemble machine learning algorithms that are capable of late
integration of multi-class data from different modalities. The ensemble methods
and their variations tested were i) a voting ensemble, with hard and soft vote,
ii) a meta learner, iii) a multi-modal Adaboost model using a hard vote, a soft
vote and a meta learner to integrate the modalities on each boosting round, the
PB-MVBoost model and a novel application of a mixture of experts model. These
were compared to simple concatenation as a baseline. We examine these methods
using data from an in-house study on hepatocellular carcinoma (HCC), along with
four validation datasets on studies from breast cancer and irritable bowel
disease (IBD). Using the area under the receiver operating curve as a measure
of performance we develop models that achieve a performance value of up to 0.85
and find that two boosted methods, PB-MVBoost and Adaboost with a soft vote
were the overall best performing models. We also examine the stability of
features selected, and the size of the clinical signature determined. Finally,
we provide recommendations for the integration of multi-modal multi-class data.

摘要：<paragraph>在不同模式的患者數據中發現的互補信息，有助於更準確地建立患者疾病狀態的模型，並更深入了解疾病的基礎生物過程。然而，多模態、多組學數據的分析提出了許多挑戰，包括高維度和不同的數據規模、統計分佈、比例和模態之間的信號強度。在這項工作中，我們比較了各種集成機器學習演算法的效能，這些演算法能夠對來自不同模態的多類別數據進行後整合。測試的集成方法及其變體為：i) 投票集成，採用硬投票和軟投票，ii) 元學習器，iii) 多模態 Adaboost 模型，使用硬投票、軟投票和元學習器在每次提升回合中整合模態，PB-MVBoost 模型和專家混合模型的新應用。這些方法與作為基準的簡單串接進行了比較。我們使用來自肝細胞癌 (HCC) 內部研究的數據，以及來自乳癌和腸躁症 (IBD) 研究的四個驗證數據集，來檢驗這些方法。使用受試者操作曲線下的面積作為效能衡量標準，我們開發了效能值高達 0.85 的模型，並發現兩種提升方法，PB-MVBoost 和採用軟投票的 Adaboost 是整體效能最佳的模型。我們還檢驗了所選特徵的穩定性，以及所確定的臨床特徵的大小。最後，我們針對多模態多類別數據的整合提供了建議。</paragraph>

##### **Recent Advancement of Emotion Cognition in Large Language Models**
2409.13354v1 by Yuyan Chen, Yanghua Xiao

Emotion cognition in large language models (LLMs) is crucial for enhancing
performance across various applications, such as social media, human-computer
interaction, and mental health assessment. We explore the current landscape of
research, which primarily revolves around emotion classification, emotionally
rich response generation, and Theory of Mind assessments, while acknowledge the
challenges like dependency on annotated data and complexity in emotion
processing. In this paper, we present a detailed survey of recent progress in
LLMs for emotion cognition. We explore key research studies, methodologies,
outcomes, and resources, aligning them with Ulric Neisser's cognitive stages.
Additionally, we outline potential future directions for research in this
evolving field, including unsupervised learning approaches and the development
of more complex and interpretable emotion cognition LLMs. We also discuss
advanced methods such as contrastive learning used to improve LLMs' emotion
cognition capabilities.

摘要：大型語言模型（LLM）的情緒認知對於增強各種應用程式的效能至關重要，例如社群媒體、人機互動和心理健康評估。我們探討了當前研究領域，其主要圍繞著情緒分類、情緒豐富的回應產生和心智理論評估，同時承認依賴註解資料和情緒處理的複雜性等挑戰。在本文中，我們對 LLM 在情緒認知方面的近期進展進行了詳細的調查。我們探討了關鍵的研究、方法、成果和資源，並將它們與烏爾里希·奈瑟的認知階段相結合。此外，我們概述了這個不斷演進的領域中未來研究的潛在方向，包括無監督學習方法和更複雜且可解釋的情緒認知 LLM 的開發。我們還討論了對比學習等先進方法，用於提升 LLM 的情緒認知能力。

##### **SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation**
2409.13321v1 by Jinge Wu, Yunsoo Kim, Daqian Shi, David Cliffton, Fenglin Liu, Honghan Wu

Inspired by the success of large language models (LLMs), there is growing
research interest in developing LLMs in the medical domain to assist
clinicians. However, for hospitals, using closed-source commercial LLMs
involves privacy issues, and developing open-source public LLMs requires
large-scale computational resources, which are usually limited, especially in
resource-efficient regions and low-income countries. We propose an open-source
Small Language and Vision Assistant (SLaVA-CXR) that can be used for Chest
X-Ray report automation. To efficiently train a small assistant, we first
propose the Re$^3$Training method, which simulates the cognitive development of
radiologists and optimizes the model in the Recognition, Reasoning, and
Reporting training manner. Then, we introduce a data synthesis method, RADEX,
which can generate a high-quality and diverse training corpus with privacy
regulation compliance. The extensive experiments show that our SLaVA-CXR built
on a 2.7B backbone not only outperforms but also achieves 6 times faster
inference efficiency than previous state-of-the-art larger models.

摘要：受到大型語言模型 (LLM) 成功啟發，在醫療領域開發 LLM 以協助臨床醫生引起了越來越多的研究興趣。然而，對於醫院而言，使用封閉原始碼的商業 LLM 涉及隱私問題，而開發開放原始碼的公共 LLM 需要大規模的計算資源，這些資源通常有限，特別是在資源效率高的地區和低收入國家。我們提出了一個開放原始碼的小語言和視覺助理 (SLaVA-CXR)，可用於胸部 X 光報告自動化。為了有效訓練一個小型助理，我們首先提出了 Re$^3$Training 方法，它模擬了放射科醫生的認知發展，並以識別、推理和報告訓練方式優化模型。然後，我們引入了一種數據合成方法 RADEX，它可以在符合隱私法規的情況下生成一個高品質且多樣化的訓練語料庫。大量的實驗表明，我們建立在 2.7B 主幹上的 SLaVA-CXR 不僅表現出色，而且推理效率比以前最先進的較大模型快 6 倍。

##### **OMG-RL:Offline Model-based Guided Reward Learning for Heparin Treatment**
2409.13299v1 by Yooseok Lim, Sujee Lee

Accurate diagnosis of individual patient conditions and appropriate
medication dosing strategies are core elements of personalized medical
decision-making processes. This therapeutic procedure, which entails
recursively assessing the patient's condition and administering suitable
medications, can effectively be modeled as a reinforcement learning (RL)
problem. Crucially, the success of RL in this context depends on the
establishment of a well-defined reward function that accurately represents the
optimal treatment strategy. However, defining the learning direction in RL with
only a limited set of explicit indicators complicates the task due to the
inherent complexity of the required domain knowledge. This approach may also
increase the likelihood that the RL policy does not adequately reflect the
clinician's treatment intentions, which are determined by considering various
situations and indicators. In this study, we focus on developing a reward
function that reflects the clinician's intentions and introduce Offline
Model-based Guided Reward Learning (OMG-RL), which performs offline inverse
reinforcement learning (IRL) aligned with the offline RL environment. Through
OMG-RL, we learn a parameterized reward function that includes the expert's
intentions from limited data, thereby enhancing the agent's policy. We validate
the proposed approach on the heparin dosing task. The results demonstrate that
policy learning through OMG-RL is meaningful and confirm that the learned
policy is positively reinforced in terms of activated partial thromboplastin
time (aPTT), a key indicator for monitoring the effects of heparin. This
approach can be broadly utilized not only for the heparin dosing problem but
also for RL-based medication dosing tasks in general.

摘要：準確診斷個別病患狀況和適當的藥物給藥策略是個人化醫療決策過程中核心元素。這個治療程序包含反覆評估病患狀況和給予適當藥物，可以有效地建模為強化學習 (RL) 問題。至關重要的是，RL 在此脈絡中的成功取決於建立一個定義良好的回饋函數，能準確代表最佳治療策略。然而，僅使用有限的明確指標來定義 RL 中的學習方向會使任務複雜化，因為需要領域知識的複雜性。這種方法也可能增加 RL 政策無法充分反映臨床醫師治療意圖的可能性，而臨床醫師的治療意圖是由考量各種情況和指標來決定的。在本研究中，我們專注於開發一個反映臨床醫師意圖的回饋函數，並引入離線模型引導回饋學習 (OMG-RL)，它執行與離線 RL 環境一致的離線逆向強化學習 (IRL)。透過 OMG-RL，我們從有限的資料中學習一個參數化的回饋函數，其中包含專家的意圖，從而增強代理的政策。我們在肝素給藥任務中驗證了所提出的方法。結果表明，透過 OMG-RL 進行政策學習是有意義的，並確認所學習的政策在活化部分凝血活酶時間 (aPTT) 方面得到正向加強，而 aPTT 是監測肝素效果的關鍵指標。這種方法不僅可以廣泛用於肝素給藥問題，還可以用於一般的基於 RL 的藥物給藥任務。

##### **Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia**
2409.15377v1 by Elisa Castagnari, Lillian Muyama, Adrien Coulet

In practice, clinicians achieve a diagnosis by following a sequence of steps,
such as laboratory exams, observations, or imaging. The pathways to reach
diagnosis decisions are documented by guidelines authored by expert
organizations, which guide clinicians to reach a correct diagnosis through
these sequences of steps. While these guidelines are beneficial for following
medical reasoning and consolidating medical knowledge, they have some
drawbacks. They often fail to address patients with uncommon conditions due to
their focus on the majority population, and are slow and costly to update,
making them unsuitable for rapidly emerging diseases or new practices. Inspired
by clinical guidelines, our study aimed to develop pathways similar to those
that can be obtained in clinical guidelines. We tested three Large Language
Models (LLMs) -Generative Pretrained Transformer 4 (GPT-4), Large Language
Model Meta AI (LLaMA), and Mistral -on a synthetic yet realistic dataset to
differentially diagnose anemia and its subtypes. By using advanced prompting
techniques to enhance the decision-making process, we generated diagnostic
pathways using these models. Experimental results indicate that LLMs hold huge
potential in clinical pathway discovery from patient data, with GPT-4
exhibiting the best performance in all conducted experiments.

摘要：<paragraph>在實務上，臨床醫生會遵循一系列步驟來診斷，
例如實驗室檢查、觀察或影像。診斷決策的途徑由專家組織編寫的指南記錄下來，這些指南引導臨床醫生透過這些步驟序列得出正確的診斷。雖然這些指南有助於遵循醫療推理並彙整醫療知識，但它們有一些缺點。由於專注於大多數族群，它們常常無法針對罕見疾病的患者提供建議，而且更新既緩慢又昂貴，這使得它們不適合用於快速出現的疾病或新療法。受到臨床指南的啟發，我們的研究旨在開發出類似於臨床指南中可以獲得的途徑。我們在一個合成但逼真的資料集上測試了三個大型語言模型 (LLM) - 生成式預訓練Transformer 4 (GPT-4)、大型語言模型 Meta AI (LLaMA) 和 Mistral - 以區分診斷貧血及其亞型。透過使用進階提示技術來增強決策制定過程，我們使用這些模型生成了診斷途徑。實驗結果表明，LLM 在從患者資料中發現臨床途徑方面具有巨大的潛力，其中 GPT-4 在所有進行的實驗中表現最佳。</paragraph>

##### **An adapted large language model facilitates multiple medical tasks in diabetes care**
2409.13191v1 by Lai Wei, Zhen Ying, Muyang He, Yutong Chen, Qian Yang, Yanzhe Hong, Jiaping Lu, Xiaoying Li, Weiran Huang, Ying Chen

Diabetes is a chronic disease that poses a significant global health burden,
and optimizing diabetes management requires multi-stakeholder collaboration.
Large language models (LLMs) have shown promise in various healthcare
scenarios, but their effectiveness across a diverse range of diabetes tasks
remains unproven. In this study, we introduced a framework to train and
validate diabetes-specific LLMs. We first developed a comprehensive data
processing pipeline that includes data collection, filtering, augmentation and
refinement. This approach contributes to creating a high-quality,
diabetes-specific dataset, and several evaluation benchmarks entirely from
scratch. Utilizing the collected training dataset, we fine-tuned a
diabetes-specific LLM family that demonstrated state-of-the-art proficiency in
understanding and processing various diabetes tasks compared to other LLMs.
Furthermore, clinical studies showed the potential applications of our models
in diabetes care, including providing personalized healthcare, assisting
medical education, and streamlining clinical tasks. In conclusion, our study
introduced a framework to develop and evaluate a diabetes-specific LLM family,
and highlighted its potential to enhance clinical practice and provide
personalized, data-driven support for diabetes support when facing different
end users. The code is provided via GitHub at
https://github.com/waltonfuture/Diabetica.

摘要：糖尿病是一種慢性疾病，對全球健康造成重大負擔，而優化糖尿病管理需要多方利益相關者的合作。大型語言模型 (LLM) 已在各種醫療保健場景中展現出潛力，但它們在各種糖尿病任務中的有效性仍未得到證實。在這個研究中，我們引入了一個訓練和驗證糖尿病特定 LLM 的框架。我們首先開發了一個全面的數據處理管道，其中包括數據收集、過濾、擴充和優化。這種方法有助於創建一個高品質、特定於糖尿病的數據集，以及從頭開始的幾個評估基準。利用收集的訓練數據集，我們微調了一個特定於糖尿病的 LLM 家族，與其他 LLM 相比，在理解和處理各種糖尿病任務方面展示了最先進的熟練度。此外，臨床研究表明我們的模型在糖尿病護理中具有潛在應用，包括提供個性化醫療保健、協助醫學教育和簡化臨床任務。總之，我們的研究引入了一個開發和評估特定於糖尿病的 LLM 家族的框架，並強調了其增強臨床實務和在面對不同最終用戶時提供個性化、數據驅動的糖尿病支持的潛力。該程式碼透過 GitHub 提供，網址為 https://github.com/waltonfuture/Diabetica。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Personalized 2D Binary Patient Codes of Tissue Images and Immunogenomic Data Through Multimodal Self-Supervised Fusion**
2409.13115v1 by Areej Alsaafin, Abubakr Shafique, Saghir Alfasly, H. R. Tizhoosh

The field of medical diagnostics has witnessed a transformative convergence
of artificial intelligence (AI) and healthcare data, offering promising avenues
for enhancing patient care and disease comprehension. However, this integration
of multimodal data, specifically histopathology whole slide images (WSIs) and
genetic sequencing data, presents unique challenges due to modality disparities
and the need for scalable computational solutions. This paper addresses the
scarcity of multimodal solutions, primarily centered around unimodal data
solutions, thus limiting the realization of the rich insights that can be
derived from integrating images and genomic data. Here, we introduce MarbliX
``Multimodal Association and Retrieval with Binary Latent Indexed matriX,'' an
innovative multimodal framework that integrates histopathology images with
immunogenomic sequencing data, encapsulating them into a concise binary patient
code, referred to as ``monogram.'' This binary representation facilitates the
establishment of a comprehensive archive, enabling clinicians to match similar
cases. The experimental results demonstrate the potential of MarbliX to empower
healthcare professionals with in-depth insights, leading to more precise
diagnoses, reduced variability, and expanded personalized treatment options,
particularly in the context of cancer.

摘要：醫療診斷領域見證了人工智慧 (AI) 與醫療保健資料的變革性融合，為提升病患照護和疾病理解提供了有希望的途徑。然而，這種整合多模式資料，特別是組織病理學全切片影像 (WSI) 和基因定序資料，由於模式差異和對可擴充計算解決方案的需求，因此提出了獨特的挑戰。本文探討了多模式解決方案的稀缺性，主要集中在單模式資料解決方案，因此限制了從整合影像和基因體資料中獲得豐富見解的實現。在此，我們介紹 MarbliX ``使用二進制潛在索引矩陣的多模式關聯和擷取''，一個創新的多模式架構，它將組織病理學影像與免疫基因組定序資料整合，將它們封裝成一個簡潔的二進制病患代碼，稱為 ``單字''。這種二進制表示有助於建立一個全面的檔案，讓臨床醫生能夠比對類似的案例。實驗結果證明了 MarbliX 能夠讓醫療保健專業人員獲得深入見解的潛力，從而導致更精確的診斷、減少變異性，並擴展個人化治療選項，特別是在癌症的背景下。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-30**|**MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning**|Haotian Zhang et.al.|[2409.20566v1](http://arxiv.org/abs/2409.20566v1)|null|
|**2024-09-30**|**Ranking Over Scoring: Towards Reliable and Robust Automated Evaluation of LLM-Generated Medical Explanatory Arguments**|Iker De la Iglesia et.al.|[2409.20565v1](http://arxiv.org/abs/2409.20565v1)|null|
|**2024-09-30**|**LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner**|Xiaopan Zhang et.al.|[2409.20560v1](http://arxiv.org/abs/2409.20560v1)|null|
|**2024-09-30**|**Maia-2: A Unified Model for Human-AI Alignment in Chess**|Zhenwei Tang et.al.|[2409.20553v1](http://arxiv.org/abs/2409.20553v1)|null|
|**2024-09-30**|**LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation**|Ziyao Zhang et.al.|[2409.20550v1](http://arxiv.org/abs/2409.20550v1)|null|
|**2024-09-30**|**Robi Butler: Remote Multimodal Interactions with Household Robot Assistant**|Anxing Xiao et.al.|[2409.20548v1](http://arxiv.org/abs/2409.20548v1)|null|
|**2024-09-30**|**Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical Evaluation Resource**|Pablo Ortega et.al.|[2409.20524v1](http://arxiv.org/abs/2409.20524v1)|null|
|**2024-09-30**|**SMLE: Safe Machine Learning via Embedded Overapproximation**|Matteo Francobaldi et.al.|[2409.20517v1](http://arxiv.org/abs/2409.20517v1)|null|
|**2024-09-30**|**What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach**|Xingfang Wu et.al.|[2409.20503v1](http://arxiv.org/abs/2409.20503v1)|null|
|**2024-09-30**|**COLLAGE: Collaborative Human-Agent Interaction Generation using Hierarchical Latent Diffusion and Language Models**|Divyanshu Daiya et.al.|[2409.20502v1](http://arxiv.org/abs/2409.20502v1)|null|
|**2024-09-30**|**Enhancing Romanian Offensive Language Detection through Knowledge Distillation, Multi-Task Learning, and Data Augmentation**|Vlad-Cristian Matei et.al.|[2409.20498v1](http://arxiv.org/abs/2409.20498v1)|null|
|**2024-09-30**|**RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations**|Johannes Kruse et.al.|[2409.20483v1](http://arxiv.org/abs/2409.20483v1)|null|
|**2024-09-30**|**A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media**|Dung Ha Nguyen et.al.|[2409.20467v1](http://arxiv.org/abs/2409.20467v1)|null|
|**2024-09-30**|**Language Resources in Spanish for Automatic Text Simplification across Domains**|Antonio Moreno-Sandoval et.al.|[2409.20466v1](http://arxiv.org/abs/2409.20466v1)|null|
|**2024-09-30**|**POMONAG: Pareto-Optimal Many-Objective Neural Architecture Generator**|Eugenio Lomurno et.al.|[2409.20447v1](http://arxiv.org/abs/2409.20447v1)|null|
|**2024-09-30**|**Instance-adaptive Zero-shot Chain-of-Thought Prompting**|Xiaosong Yuan et.al.|[2409.20441v2](http://arxiv.org/abs/2409.20441v2)|null|
|**2024-09-30**|**QAEncoder: Towards Aligned Representation Learning in Question Answering System**|Zhengren Wang et.al.|[2409.20434v1](http://arxiv.org/abs/2409.20434v1)|null|
|**2024-09-30**|**HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding**|Fan Yuan et.al.|[2409.20429v1](http://arxiv.org/abs/2409.20429v1)|null|
|**2024-09-30**|**Sufficient and Necessary Explanations (and What Lies in Between)**|Beepul Bharti et.al.|[2409.20427v1](http://arxiv.org/abs/2409.20427v1)|null|
|**2024-09-30**|**World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering**|Jiacong Wang et.al.|[2409.20424v1](http://arxiv.org/abs/2409.20424v1)|null|
|**2024-09-30**|**Stream-level flow matching from a Bayesian decision theoretic perspective**|Ganchao Wei et.al.|[2409.20423v1](http://arxiv.org/abs/2409.20423v1)|null|
|**2024-09-30**|**Conformal Prediction for Dose-Response Models with Continuous Treatments**|Jarne Verhaeghe et.al.|[2409.20412v1](http://arxiv.org/abs/2409.20412v1)|null|
|**2024-09-30**|**Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield Anti-stereotypical Writing**|Connor Baumler et.al.|[2409.20390v1](http://arxiv.org/abs/2409.20390v1)|null|
|**2024-09-30**|**Wait, but Tylenol is Acetaminophen... Investigating and Improving Language Models' Ability to Resist Requests for Misinformation**|Shan Chen et.al.|[2409.20385v1](http://arxiv.org/abs/2409.20385v1)|null|
|**2024-09-30**|**Word-wise intonation model for cross-language TTS systems**|Tomilov A. A. et.al.|[2409.20374v1](http://arxiv.org/abs/2409.20374v1)|null|
|**2024-09-30**|**Frequency Adaptive Normalization For Non-stationary Time Series Forecasting**|Weiwei Ye et.al.|[2409.20371v1](http://arxiv.org/abs/2409.20371v1)|null|
|**2024-09-30**|**The Perfect Blend: Redefining RLHF with Mixture of Judges**|Tengyu Xu et.al.|[2409.20370v1](http://arxiv.org/abs/2409.20370v1)|null|
|**2024-09-30**|**Disentangling Singlish Discourse Particles with Task-Driven Representation**|Linus Tze En Foo et.al.|[2409.20366v1](http://arxiv.org/abs/2409.20366v1)|null|
|**2024-09-30**|**Efficient Driving Behavior Narration and Reasoning on Edge Device Using Large Language Models**|Yizhou Huang et.al.|[2409.20364v1](http://arxiv.org/abs/2409.20364v1)|null|
|**2024-09-30**|**Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference**|Ke Yi et.al.|[2409.20361v1](http://arxiv.org/abs/2409.20361v1)|null|
|**2024-09-30**|**Enhancing GANs with Contrastive Learning-Based Multistage Progressive Finetuning SNN and RL-Based External Optimization**|Osama Mustafa et.al.|[2409.20340v2](http://arxiv.org/abs/2409.20340v2)|null|
|**2024-09-30**|**Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding**|Takafumi Moriya et.al.|[2409.20313v1](http://arxiv.org/abs/2409.20313v1)|null|
|**2024-09-30**|**A Looming Replication Crisis in Evaluating Behavior in Language Models? Evidence and Solutions**|Laurène Vaugrante et.al.|[2409.20303v1](http://arxiv.org/abs/2409.20303v1)|null|
|**2024-09-30**|**PersonalLLM: Tailoring LLMs to Individual Preferences**|Thomas P. Zollo et.al.|[2409.20296v1](http://arxiv.org/abs/2409.20296v1)|null|
|**2024-09-30**|**LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models**|Haitao Li et.al.|[2409.20288v1](http://arxiv.org/abs/2409.20288v1)|[link](https://github.com/cshaitao/lexeval)|
|**2024-09-30**|**Computer-mediated therapies for stroke rehabilitation: a systematic review and meta-Analysis**|Stanley Mugisha. Mirko Job. Matteo Zoppi et.al.|[2409.20260v1](http://arxiv.org/abs/2409.20260v1)|null|
|**2024-09-30**|**What is the Role of Large Language Models in the Evolution of Astronomy Research?**|Morgan Fouesneau et.al.|[2409.20252v1](http://arxiv.org/abs/2409.20252v1)|null|
|**2024-09-30**|**Resource Allocation for Stable LLM Training in Mobile Edge Computing**|Chang Liu et.al.|[2409.20247v1](http://arxiv.org/abs/2409.20247v1)|null|
|**2024-09-30**|**Analysing Zero-Shot Readability-Controlled Sentence Simplification**|Abdullah Barayan et.al.|[2409.20246v1](http://arxiv.org/abs/2409.20246v1)|null|
|**2024-09-30**|**PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling**|Huachuan Qiu et.al.|[2409.20243v1](http://arxiv.org/abs/2409.20243v1)|[link](https://github.com/qiuhuachuan/psyguard)|
|**2024-09-30**|**Beyond Prompts: Dynamic Conversational Benchmarking of Large Language Models**|David Castillo-Bolado et.al.|[2409.20222v1](http://arxiv.org/abs/2409.20222v1)|null|
|**2024-09-30**|**Divided by discipline? A systematic literature review on the quantification of online sexism and misogyny using a semi-automated approach**|Aditi Dutta et.al.|[2409.20204v1](http://arxiv.org/abs/2409.20204v1)|null|
|**2024-09-30**|**AfriHuBERT: A self-supervised speech representation model for African languages**|Jesujoba O. Alabi et.al.|[2409.20201v1](http://arxiv.org/abs/2409.20201v1)|null|
|**2024-09-30**|**Melody Is All You Need For Music Generation**|Shaopeng Wei et.al.|[2409.20196v1](http://arxiv.org/abs/2409.20196v1)|[link](https://github.com/shaopengw/Awesome-Music-Generation)|
|**2024-09-30**|**Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**|Arunava Chakravarty et.al.|[2409.20195v1](http://arxiv.org/abs/2409.20195v1)|null|
|**2024-09-30**|**Factory Operators' Perspectives on Cognitive Assistants for Knowledge Sharing: Challenges, Risks, and Impact on Work**|Samuel Kernan Freire et.al.|[2409.20192v1](http://arxiv.org/abs/2409.20192v1)|null|
|**2024-09-30**|**TaskComplexity: A Dataset for Task Complexity Classification with In-Context Learning, FLAN-T5 and GPT-4o Benchmarks**|Areeg Fahad Rasheed et.al.|[2409.20189v1](http://arxiv.org/abs/2409.20189v1)|[link](https://github.com/AREEG94FAHAD/TaskComplexityEval-24)|
|**2024-09-30**|**Choosing DAG Models Using Markov and Minimal Edge Count in the Absence of Ground Truth**|Joseph D. Ramsey et.al.|[2409.20187v1](http://arxiv.org/abs/2409.20187v1)|null|
|**2024-09-30**|**Reference Trustable Decoding: A Training-Free Augmentation Paradigm for Large Language Models**|Luohe Shi et.al.|[2409.20181v1](http://arxiv.org/abs/2409.20181v1)|null|
|**2024-09-30**|**Modelando procesos cognitivos de la lectura natural con GPT-2**|Bruno Bianchi et.al.|[2409.20174v1](http://arxiv.org/abs/2409.20174v1)|null|
|**2024-09-30**|**Using Large Multimodal Models to Extract Knowledge Components for Knowledge Tracing from Multimedia Question Information**|Hyeongdon Moon et.al.|[2409.20167v1](http://arxiv.org/abs/2409.20167v1)|null|
|**2024-09-30**|**How Entangled is Factuality and Deception in German?**|Aswathy Velutharambath et.al.|[2409.20165v1](http://arxiv.org/abs/2409.20165v1)|null|
|**2024-09-30**|**MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants**|Zeyu Zhang et.al.|[2409.20163v1](http://arxiv.org/abs/2409.20163v1)|[link](https://github.com/nuster1128/memsim)|
|**2024-09-30**|**1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data Sharing and Compensation in Large Language Models**|Chanjun Park et.al.|[2409.20149v1](http://arxiv.org/abs/2409.20149v1)|null|
|**2024-09-30**|**Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**|Vincent Beliveau et.al.|[2409.20147v1](http://arxiv.org/abs/2409.20147v1)|null|
|**2024-09-30**|**Federated Instruction Tuning of LLMs with Domain Coverage Augmentation**|Zezhou Wang et.al.|[2409.20135v2](http://arxiv.org/abs/2409.20135v2)|null|
|**2024-09-30**|**ACE: Abstractions for Communicating Efficiently**|Jonathan D. Thomas et.al.|[2409.20120v1](http://arxiv.org/abs/2409.20120v1)|null|
|**2024-09-30**|**Aggressive Post-Training Compression on Extremely Large Language Models**|Zining Zhang et.al.|[2409.20094v1](http://arxiv.org/abs/2409.20094v1)|null|
|**2024-09-30**|**Robust LLM safeguarding via refusal feature adversarial training**|Lei Yu et.al.|[2409.20089v1](http://arxiv.org/abs/2409.20089v1)|null|
|**2024-09-30**|**BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain**|Kaisi Guan et.al.|[2409.20075v1](http://arxiv.org/abs/2409.20075v1)|null|
|**2024-09-30**|**Knowledge Discovery using Unsupervised Cognition**|Alfredo Ibias et.al.|[2409.20064v1](http://arxiv.org/abs/2409.20064v1)|null|
|**2024-09-30**|**Is Preference Alignment Always the Best Option to Enhance LLM-Based Translation? An Empirical Analysis**|Hippolyte Gisserot-Boukhlef et.al.|[2409.20059v1](http://arxiv.org/abs/2409.20059v1)|null|
|**2024-09-30**|**Evaluating and explaining training strategies for zero-shot cross-lingual news sentiment analysis**|Luka Andrenšek et.al.|[2409.20054v1](http://arxiv.org/abs/2409.20054v1)|null|
|**2024-09-30**|**GUNDAM: Aligning Large Language Models with Graph Understanding**|Sheng Ouyang et.al.|[2409.20053v1](http://arxiv.org/abs/2409.20053v1)|null|
|**2024-09-30**|**Mitigating Propensity Bias of Large Language Models for Recommender Systems**|Guixian Zhang et.al.|[2409.20052v1](http://arxiv.org/abs/2409.20052v1)|null|
|**2024-09-30**|**Depression detection in social media posts using transformer-based models and auxiliary features**|Marios Kerasiotis et.al.|[2409.20048v1](http://arxiv.org/abs/2409.20048v1)|null|
|**2024-09-30**|**Beyond Scores: A Modular RAG-Based System for Automatic Short Answer Scoring with Feedback**|Menna Fateen et.al.|[2409.20042v1](http://arxiv.org/abs/2409.20042v1)|null|
|**2024-09-30**|**Towards Robust Multimodal Sentiment Analysis with Incomplete Data**|Haoyu Zhang et.al.|[2409.20012v1](http://arxiv.org/abs/2409.20012v1)|null|
|**2024-09-30**|**Customized Information and Domain-centric Knowledge Graph Construction with Large Language Models**|Frank Wawrzik et.al.|[2409.20010v1](http://arxiv.org/abs/2409.20010v1)|null|
|**2024-09-30**|**Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data**|Ke-Han Lu et.al.|[2409.20007v1](http://arxiv.org/abs/2409.20007v1)|null|
|**2024-09-30**|**Model Selection with a Shapelet-based Distance Measure for Multi-source Transfer Learning in Time Series Classification**|Jiseok Lee et.al.|[2409.20005v1](http://arxiv.org/abs/2409.20005v1)|null|
|**2024-09-30**|**Do Influence Functions Work on Large Language Models?**|Zhe Li et.al.|[2409.19998v1](http://arxiv.org/abs/2409.19998v1)|null|
|**2024-09-30**|**Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges**|Qin Liu et.al.|[2409.19993v1](http://arxiv.org/abs/2409.19993v1)|null|
|**2024-09-30**|**Predictive Speech Recognition and End-of-Utterance Detection Towards Spoken Dialog Systems**|Oswald Zink et.al.|[2409.19990v1](http://arxiv.org/abs/2409.19990v1)|null|
|**2024-09-30**|**CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models**|Eitan Wagner et.al.|[2409.19984v1](http://arxiv.org/abs/2409.19984v1)|null|
|**2024-09-30**|**Enhancing High-order Interaction Awareness in LLM-based Recommender Model**|Xinfeng Wang et.al.|[2409.19979v2](http://arxiv.org/abs/2409.19979v2)|[link](https://github.com/WangXFng/ELMRec)|
|**2024-09-30**|**Knowledge Graph Embedding by Normalizing Flows**|Changyi Xiao et.al.|[2409.19977v1](http://arxiv.org/abs/2409.19977v1)|[link](https://github.com/changyi7231/nfe)|
|**2024-09-30**|**Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval**|Yabing Wang et.al.|[2409.19961v1](http://arxiv.org/abs/2409.19961v1)|null|
|**2024-09-30**|**TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning**|Joshua Feinglass et.al.|[2409.19960v1](http://arxiv.org/abs/2409.19960v1)|null|
|**2024-09-30**|**Attribute-Text Guided Forgetting Compensation for Lifelong Person Re-Identification**|Shiben Liu et.al.|[2409.19954v1](http://arxiv.org/abs/2409.19954v1)|null|
|**2024-09-30**|**Law of the Weakest Link: Cross Capabilities of Large Language Models**|Ming Zhong et.al.|[2409.19951v1](http://arxiv.org/abs/2409.19951v1)|[link](https://github.com/facebookresearch/llm-cross-capabilities)|
|**2024-09-30**|**Task-agnostic Pre-training and Task-guided Fine-tuning for Versatile Diffusion Planner**|Chenyou Fan et.al.|[2409.19949v1](http://arxiv.org/abs/2409.19949v1)|null|
|**2024-09-30**|**JaPOC: Japanese Post-OCR Correction Benchmark using Vouchers**|Masato Fujitake et.al.|[2409.19948v1](http://arxiv.org/abs/2409.19948v1)|null|
|**2024-09-30**|**Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**|Samia Belhadj et.al.|[2409.19940v1](http://arxiv.org/abs/2409.19940v1)|null|
|**2024-09-30**|**Large Language Model Empowered Embedding Generator for Sequential Recommendation**|Qidong Liu et.al.|[2409.19925v1](http://arxiv.org/abs/2409.19925v1)|null|
|**2024-09-30**|**On The Planning Abilities of OpenAI's o1 Models: Feasibility, Optimality, and Generalizability**|Kevin Wang et.al.|[2409.19924v2](http://arxiv.org/abs/2409.19924v2)|[link](https://github.com/vita-group/o1-planning)|
|**2024-09-30**|**Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming**|Ming Li et.al.|[2409.19916v1](http://arxiv.org/abs/2409.19916v1)|null|
|**2024-09-30**|**Scaling Optimal LR Across Token Horizon**|Johan Bjorck et.al.|[2409.19913v1](http://arxiv.org/abs/2409.19913v1)|null|
|**2024-09-30**|**UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs**|Yuho Lee et.al.|[2409.19898v2](http://arxiv.org/abs/2409.19898v2)|[link](https://github.com/disl-lab/unisumeval-v1.0)|
|**2024-09-30**|**TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation**|Zhiqiang Yuan et.al.|[2409.19894v2](http://arxiv.org/abs/2409.19894v2)|null|
|**2024-09-30**|**RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models**|Shuhao Chen et.al.|[2409.19886v1](http://arxiv.org/abs/2409.19886v1)|[link](https://github.com/shuhao02/routerdc)|
|**2024-09-30**|**SWIM: Short-Window CNN Integrated with Mamba for EEG-Based Auditory Spatial Attention Decoding**|Ziyang Zhang et.al.|[2409.19884v1](http://arxiv.org/abs/2409.19884v1)|[link](https://github.com/windowso/swim-asad)|
|**2024-09-30**|**Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation**|Huangyu Dai et.al.|[2409.19877v1](http://arxiv.org/abs/2409.19877v1)|null|
|**2024-09-30**|**TSI: A Multi-View Representation Learning Approach for Time Series Forecasting**|Wentao Gao et.al.|[2409.19871v1](http://arxiv.org/abs/2409.19871v1)|null|
|**2024-09-30**|**The Construction of Instruction-tuned LLMs for Finance without Instruction Data Using Continual Pretraining and Model Merging**|Masanori Hirano et.al.|[2409.19854v1](http://arxiv.org/abs/2409.19854v1)|null|
|**2024-09-30**|**ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities**|Ezra Karger et.al.|[2409.19839v1](http://arxiv.org/abs/2409.19839v1)|null|
|**2024-09-29**|**Counterfactual Evaluation of Ads Ranking Models through Domain Adaptation**|Mohamed A. Radwan et.al.|[2409.19824v1](http://arxiv.org/abs/2409.19824v1)|null|
|**2024-09-29**|**Calibrating Language Models with Adaptive Temperature Scaling**|Johnathan Xie et.al.|[2409.19817v1](http://arxiv.org/abs/2409.19817v1)|null|
|**2024-09-29**|**Grounded Curriculum Learning**|Linji Wang et.al.|[2409.19816v1](http://arxiv.org/abs/2409.19816v1)|null|
|**2024-09-29**|**Transforming Hidden States into Binary Semantic Features**|Tomáš Musil et.al.|[2409.19813v1](http://arxiv.org/abs/2409.19813v1)|null|

#### Abstracts
##### **MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning**
2409.20566v1 by Haotian Zhang, Mingfei Gao, Zhe Gan, Philipp Dufter, Nina Wenzel, Forrest Huang, Dhruti Shah, Xianzhi Du, Bowen Zhang, Yanghao Li, Sam Dodge, Keen You, Zhen Yang, Aleksei Timofeev, Mingze Xu, Hong-You Chen, Jean-Philippe Fauconnier, Zhengfeng Lai, Haoxuan You, Zirui Wang, Afshin Dehghan, Peter Grasch, Yinfei Yang

We present MM1.5, a new family of multimodal large language models (MLLMs)
designed to enhance capabilities in text-rich image understanding, visual
referring and grounding, and multi-image reasoning. Building upon the MM1
architecture, MM1.5 adopts a data-centric approach to model training,
systematically exploring the impact of diverse data mixtures across the entire
model training lifecycle. This includes high-quality OCR data and synthetic
captions for continual pre-training, as well as an optimized visual
instruction-tuning data mixture for supervised fine-tuning. Our models range
from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE)
variants, and demonstrate that careful data curation and training strategies
can yield strong performance even at small scales (1B and 3B). Additionally, we
introduce two specialized variants: MM1.5-Video, designed for video
understanding, and MM1.5-UI, tailored for mobile UI understanding. Through
extensive empirical studies and ablations, we provide detailed insights into
the training processes and decisions that inform our final designs, offering
valuable guidance for future research in MLLM development.

摘要：我們提出 MM1.5，一種新的多模態大型語言模型 (MLLM) 家族，旨在增強文本豐富影像理解、視覺指涉和基礎，以及多影像推理的能力。在 MM1 架構的基礎上，MM1.5 採用以資料為中心的模型訓練方法，系統性地探討各種資料混合對整個模型訓練生命週期的影響。這包括用於持續預訓練的高品質 OCR 資料和合成式字幕，以及用於監督微調的最佳化視覺指令調校資料混合。我們的模型範圍從 1B 到 30B 參數，包含密集和專家混合 (MoE) 變體，並證明仔細的資料策展和訓練策略即使在小規模 (1B 和 3B) 下也能產生強大的效能。此外，我們還引入了兩個專門的變體：MM1.5-Video，專為影片理解而設計，以及 MM1.5-UI，專為行動裝置 UI 理解而設計。透過廣泛的實證研究和消融，我們提供了對訓練流程和決策的詳細見解，這些見解說明了我們的最終設計，為 MLLM 開發的未來研究提供了寶貴的指導。

##### **Ranking Over Scoring: Towards Reliable and Robust Automated Evaluation of LLM-Generated Medical Explanatory Arguments**
2409.20565v1 by Iker De la Iglesia, Iakes Goenaga, Johanna Ramirez-Romero, Jose Maria Villa-Gonzalez, Josu Goikoetxea, Ander Barrena

Evaluating LLM-generated text has become a key challenge, especially in
domain-specific contexts like the medical field. This work introduces a novel
evaluation methodology for LLM-generated medical explanatory arguments, relying
on Proxy Tasks and rankings to closely align results with human evaluation
criteria, overcoming the biases typically seen in LLMs used as judges. We
demonstrate that the proposed evaluators are robust against adversarial
attacks, including the assessment of non-argumentative text. Additionally, the
human-crafted arguments needed to train the evaluators are minimized to just
one example per Proxy Task. By examining multiple LLM-generated arguments, we
establish a methodology for determining whether a Proxy Task is suitable for
evaluating LLM-generated medical explanatory arguments, requiring only five
examples and two human experts.

摘要：評估 LLM 生成的文字已成為一項關鍵挑戰，特別是在醫療領域等特定領域中。這項工作介紹了一種針對 LLM 生成的醫學解釋性論點的新穎評估方法，依賴代理任務和排名，以將結果與人類評估標準緊密對齊，克服了通常在用作評判的 LLM 中看到的偏差。我們證明了所提出的評估員對對抗性攻擊具有魯棒性，包括對非論證性文字的評估。此外，訓練評估員所需的人工論證已最小化，每個代理任務僅一個範例。通過檢查多個 LLM 生成的論點，我們建立了一種方法來確定代理任務是否適合評估 LLM 生成的醫學解釋性論點，只需要五個範例和兩位人類專家。

##### **LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner**
2409.20560v1 by Xiaopan Zhang, Hao Qin, Fuquan Wang, Yue Dong, Jiachen Li

Language models (LMs) possess a strong capability to comprehend natural
language, making them effective in translating human instructions into detailed
plans for simple robot tasks. Nevertheless, it remains a significant challenge
to handle long-horizon tasks, especially in subtask identification and
allocation for cooperative heterogeneous robot teams. To address this issue, we
propose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel
multi-agent task planning framework that achieves state-of-the-art performance
on long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning
capability and the traditional heuristic search planner to achieve a high
success rate and efficiency while demonstrating strong generalization across
tasks. Additionally, we create MAT-THOR, a comprehensive benchmark that
features household tasks with two different levels of complexity based on the
AI2-THOR environment. The experimental results demonstrate that LaMMA-P
achieves a 105% higher success rate and 36% higher efficiency than existing
LM-based multi-agent planners. The experimental videos, code, and datasets of
this work as well as the detailed prompts used in each module are available at
https://lamma-p.github.io.

摘要：語言模型 (LM) 擁有強大的理解自然語言的能力，這使得它們能夠有效地將人類指令轉換為簡單機器人任務的詳細計畫。儘管如此，處理長期任務仍然是一個重大的挑戰，特別是在合作異質機器人團隊的子任務識別和分配方面。為了解決這個問題，我們提出了一個語言模型驅動的多代理 PDDL 計畫器 (LaMMA-P)，這是一個新穎的多代理任務計畫框架，在長期任務上實現了最先進的效能。LaMMA-P 整合了 LM 推理能力和傳統啟發式搜尋計畫器的優勢，以實現高成功率和效率，同時在各項任務中展現出強大的泛化能力。此外，我們建立了 MAT-THOR，一個全面的基準測試，它具有基於 AI2-THOR 環境的兩個不同複雜程度的家務任務。實驗結果表明，與現有的基於 LM 的多代理計畫器相比，LaMMA-P 的成功率提高了 105%，效率提高了 36%。這項工作的實驗影片、程式碼和資料集以及每個模組中使用的詳細提示都可以在 https://lamma-p.github.io/ 獲得。

##### **Maia-2: A Unified Model for Human-AI Alignment in Chess**
2409.20553v1 by Zhenwei Tang, Difan Jiao, Reid McIlroy-Young, Jon Kleinberg, Siddhartha Sen, Ashton Anderson

There are an increasing number of domains in which artificial intelligence
(AI) systems both surpass human ability and accurately model human behavior.
This introduces the possibility of algorithmically-informed teaching in these
domains through more relatable AI partners and deeper insights into human
decision-making. Critical to achieving this goal, however, is coherently
modeling human behavior at various skill levels. Chess is an ideal model system
for conducting research into this kind of human-AI alignment, with its rich
history as a pivotal testbed for AI research, mature superhuman AI systems like
AlphaZero, and precise measurements of skill via chess rating systems. Previous
work in modeling human decision-making in chess uses completely independent
models to capture human style at different skill levels, meaning they lack
coherence in their ability to adapt to the full spectrum of human improvement
and are ultimately limited in their effectiveness as AI partners and teaching
tools. In this work, we propose a unified modeling approach for human-AI
alignment in chess that coherently captures human style across different skill
levels and directly captures how people improve. Recognizing the complex,
non-linear nature of human learning, we introduce a skill-aware attention
mechanism to dynamically integrate players' strengths with encoded chess
positions, enabling our model to be sensitive to evolving player skill. Our
experimental results demonstrate that this unified framework significantly
enhances the alignment between AI and human players across a diverse range of
expertise levels, paving the way for deeper insights into human decision-making
and AI-guided teaching tools.

摘要：<paragraph>在人工智能（AI）系統既超越人類能力，又能準確模擬人類行為的領域中，數量正不斷增加。這引入了在這些領域中通過更具關聯性的 AI 合作夥伴和更深入的人類決策制定見解，進行演算法知情教學的可能性。然而，實現此目標的關鍵在於以連貫的方式模擬不同技能級別的人類行為。西洋棋是一個理想的模型系統，可用於對此類人機對齊進行研究，它作為 AI 研究的關鍵測試平台，擁有豐富的歷史，成熟的超人類 AI 系統，例如 AlphaZero，以及通過西洋棋評分系統進行的精確技能測量。先前在西洋棋中模擬人類決策制定的工作使用完全獨立的模型來捕捉不同技能級別的人類風格，這表示它們在適應人類進步全光譜的能力上缺乏連貫性，並且最終在作為 AI 合作夥伴和教學工具方面的效能受到限制。在這項工作中，我們提出了一種統一的建模方法，用於西洋棋中的人機對齊，它以連貫的方式捕捉不同技能級別的人類風格，並直接捕捉人們如何進步。認識到人類學習的複雜、非線性本質，我們引入了一種技能感知注意力機制，以動態整合玩家的優勢與編碼西洋棋位置，使我們的模型能夠對不斷變化的玩家技能做出反應。我們的實驗結果表明，這個統一的框架顯著增強了 AI 和人類玩家在各種專業級別之間的對齊，為更深入了解人類決策制定和 AI 指導的教學工具鋪平了道路。</paragraph>

##### **LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation**
2409.20550v1 by Ziyao Zhang, Yanlin Wang, Chong Wang, Jiachi Chen, Zibin Zheng

Code generation aims to automatically generate code from input requirements,
significantly enhancing development efficiency. Recent large language models
(LLMs) based approaches have shown promising results and revolutionized code
generation task. Despite the promising performance, LLMs often generate
contents with hallucinations, especially for the code generation scenario
requiring the handling of complex contextual dependencies in practical
development process. Although previous study has analyzed hallucinations in
LLM-powered code generation, the study is limited to standalone function
generation. In this paper, we conduct an empirical study to study the
phenomena, mechanism, and mitigation of LLM hallucinations within more
practical and complex development contexts in repository-level generation
scenario. First, we manually examine the code generation results from six
mainstream LLMs to establish a hallucination taxonomy of LLM-generated code.
Next, we elaborate on the phenomenon of hallucinations, analyze their
distribution across different models. We then analyze causes of hallucinations
and identify four potential factors contributing to hallucinations. Finally, we
propose an RAG-based mitigation method, which demonstrates consistent
effectiveness in all studied LLMs. The replication package including code,
data, and experimental results is available at
https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination

摘要：程式碼生成旨在根據輸入需求自動產生程式碼，大幅提升開發效率。最近基於大型語言模型 (LLM) 的方法已展現出有希望的成果，並徹底改變了程式碼生成任務。儘管有令人期待的效能，LLM 經常會產生包含幻覺的內容，特別是在程式碼生成場景，需要處理實際開發過程中複雜的內容相關性。儘管先前的研究已分析 LLM 驅動的程式碼生成中的幻覺，但研究僅限於獨立函式生成。在本文中，我們進行一項實證研究來研究 LLM 幻覺在儲存庫層級生成場景中更實際且複雜的開發背景下的現象、機制和緩解。首先，我們手動檢查來自六個主流 LLM 的程式碼生成結果，以建立 LLM 生成的程式碼的幻覺分類法。接下來，我們詳細說明幻覺的現象，分析它們在不同模型中的分佈。然後，我們分析幻覺的原因，並找出導致幻覺的四個潛在因素。最後，我們提出一個基於 RAG 的緩解方法，在所有研究的 LLM 中都展現出一致的有效性。包含程式碼、資料和實驗結果的複製套件可在 https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination 取得

##### **Robi Butler: Remote Multimodal Interactions with Household Robot Assistant**
2409.20548v1 by Anxing Xiao, Nuwan Janaka, Tianrun Hu, Anshul Gupta, Kaixin Li, Cunjun Yu, David Hsu

In this paper, we introduce Robi Butler, a novel household robotic system
that enables multimodal interactions with remote users. Building on the
advanced communication interfaces, Robi Butler allows users to monitor the
robot's status, send text or voice instructions, and select target objects by
hand pointing. At the core of our system is a high-level behavior module,
powered by Large Language Models (LLMs), that interprets multimodal
instructions to generate action plans. These plans are composed of a set of
open vocabulary primitives supported by Vision Language Models (VLMs) that
handle both text and pointing queries. The integration of the above components
allows Robi Butler to ground remote multimodal instructions in the real-world
home environment in a zero-shot manner. We demonstrate the effectiveness and
efficiency of this system using a variety of daily household tasks that involve
remote users giving multimodal instructions. Additionally, we conducted a user
study to analyze how multimodal interactions affect efficiency and user
experience during remote human-robot interaction and discuss the potential
improvements.

摘要：在本文中，我們介紹了 Robi Butler，這是一個新穎的家用機器人系統，它能與遠端使用者進行多模式互動。Robi Butler 建立在先進的通訊介面上，讓使用者可以監控機器人的狀態、傳送文字或語音指令，以及用手指點選目標物件。我們系統的核心是一個高階行為模組，由大型語言模型 (LLM) 提供支援，它會解譯多模式指令以產生行動計畫。這些計畫由一組開放式詞彙基本元素組成，並由同時處理文字和指向查詢的視覺語言模型 (VLM) 提供支援。上述元件的整合讓 Robi Butler 能在零次學習的情況下，將遠端多模式指令應用於真實世界的居家環境中。我們使用各種涉及遠端使用者提供多模式指令的日常家務任務，來展示此系統的有效性和效率。此外，我們進行了一項使用者研究，以分析多模式互動如何影響遠端人機互動的效率和使用者體驗，並討論潛在的改進方式。

##### **Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical Evaluation Resource**
2409.20524v1 by Pablo Ortega, Jordi Luque, Luis Lamiable, Rodrigo López, Richard Benjamins

Human language, while aimed at conveying meaning, inherently carries
ambiguity. It poses challenges for speech and language processing, but also
serves crucial communicative functions. Efficiently solve ambiguity is both a
desired and a necessary characteristic. The lexical meaning of a word in
context can be determined automatically by Word Sense Disambiguation (WSD)
algorithms that rely on external knowledge often limited and biased toward
English. When adapting content to other languages, automated translations are
frequently inaccurate and a high degree of expert human validation is necessary
to ensure both accuracy and understanding. The current study addresses previous
limitations by introducing a new resource for Spanish WSD. It includes a sense
inventory and a lexical dataset sourced from the Diccionario de la Lengua
Espa\~nola which is maintained by the Real Academia Espa\~nola. We also review
current resources for Spanish and report metrics on them by a state-of-the-art
system.

摘要：人類語言雖然旨在傳達意義，但本質上卻充滿了歧義。它對語言和語言處理提出了挑戰，但也發揮了至關重要的溝通功能。有效解決歧義既是一種理想，也是一種必要的特質。語境中單詞的詞彙意義可以用詞義消歧 (WSD) 演算法自動確定，這些演算法依賴於外部知識，而這些知識通常有限且偏向於英語。在將內容改編為其他語言時，自動翻譯通常不準確，需要大量專家的人工驗證，以確保準確性和理解度。本研究通過引入西班牙語 WSD 的新資源來解決先前的限制。它包括一個語義庫和一個詞彙資料集，其來源是 Real Academia Espa\~nola 維護的 Diccionario de la Lengua Espa\~nola。我們還回顧了西班牙語的現有資源，並通過最先進的系統對它們進行了指標報告。

##### **SMLE: Safe Machine Learning via Embedded Overapproximation**
2409.20517v1 by Matteo Francobaldi, Michele Lombardi

Despite the extent of recent advances in Machine Learning (ML) and Neural
Networks, providing formal guarantees on the behavior of these systems is still
an open problem, and a crucial requirement for their adoption in regulated or
safety-critical scenarios. We consider the task of training differentiable ML
models guaranteed to satisfy designer-chosen properties, stated as input-output
implications. This is very challenging, due to the computational complexity of
rigorously verifying and enforcing compliance in modern neural models. We
provide an innovative approach based on three components: 1) a general, simple
architecture enabling efficient verification with a conservative semantic; 2) a
rigorous training algorithm based on the Projected Gradient Method; 3) a
formulation of the problem of searching for strong counterexamples. The
proposed framework, being only marginally affected by model complexity, scales
well to practical applications, and produces models that provide full property
satisfaction guarantees. We evaluate our approach on properties defined by
linear inequalities in regression, and on mutually exclusive classes in
multilabel classification. Our approach is competitive with a baseline that
includes property enforcement during preprocessing, i.e. on the training data,
as well as during postprocessing, i.e. on the model predictions. Finally, our
contributions establish a framework that opens up multiple research directions
and potential improvements.

摘要：儘管機器學習 (ML) 和神經網路最近有很大的進展，但要對這些系統的行為提供正式保證仍然是一個開放的問題，也是在受規範或安全關鍵情境中採用它們的關鍵要求。我們考慮訓練可微分 ML 模型的任務，保證滿足設計師選擇的屬性，並表示為輸入輸出蘊涵。由於嚴格驗證和強制現代神經模型的相容性在計算上很複雜，因此這是一個非常具有挑戰性的任務。我們提供了一種基於三個組成的創新方法：1) 一種通用、簡單的架構，能夠使用保守語義進行有效的驗證；2) 一種基於投影梯度法的嚴格訓練演算法；3) 一種尋找強反例的問題表述。所提出的架構僅受模型複雜性邊際影響，可以很好地擴展到實際應用，並且產生的模型提供了完全的屬性滿足保證。我們根據回歸中的線性不等式和多標籤分類中的互斥類別來評估我們的做法。我們的做法與基線具有競爭力，該基線在預處理（即在訓練資料上）和後處理（即在模型預測上）期間都包括屬性強制。最後，我們的貢獻建立了一個框架，為多個研究方向和潛在改進開闢了道路。

##### **What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach**
2409.20503v1 by Xingfang Wu, Heng Li, Foutse Khomh

Log data are generated from logging statements in the source code, providing
insights into the execution processes of software applications and systems.
State-of-the-art log-based anomaly detection approaches typically leverage deep
learning models to capture the semantic or sequential information in the log
data and detect anomalous runtime behaviors. However, the impacts of these
different types of information are not clear. In addition, existing approaches
have not captured the timestamps in the log data, which can potentially provide
more fine-grained temporal information than sequential information. In this
work, we propose a configurable transformer-based anomaly detection model that
can capture the semantic, sequential, and temporal information in the log data
and allows us to configure the different types of information as the model's
features. Additionally, we train and evaluate the proposed model using log
sequences of different lengths, thus overcoming the constraint of existing
methods that rely on fixed-length or time-windowed log sequences as inputs.
With the proposed model, we conduct a series of experiments with different
combinations of input features to evaluate the roles of different types of
information in anomaly detection. When presented with log sequences of varying
lengths, the model can attain competitive and consistently stable performance
compared to the baselines. The results indicate that the event occurrence
information plays a key role in identifying anomalies, while the impact of the
sequential and temporal information is not significant for anomaly detection in
the studied public datasets. On the other hand, the findings also reveal the
simplicity of the studied public datasets and highlight the importance of
constructing new datasets that contain different types of anomalies to better
evaluate the performance of anomaly detection models.

摘要：<paragraph>記錄資料是由原始程式碼中的記錄陳述所產生，提供軟體應用程式和系統執行程式的見解。
最先進的基於記錄的異常偵測方法通常利用深度學習模型來擷取記錄資料中的語義或順序資訊，並偵測異常的執行時間行為。然而，這些不同類型資訊的影響並不清楚。此外，現有的方法並未擷取記錄資料中的時間戳記，這可能會提供比順序資訊更精細的暫時資訊。在這項工作中，我們提出一個可組態的基於轉換器的異常偵測模型，它可以擷取記錄資料中的語義、順序和暫時資訊，並允許我們將不同類型的資訊組態為模型的特徵。此外，我們使用不同長度的記錄序列訓練和評估所提出的模型，從而克服現有方法的限制，這些方法依賴於固定長度或時間視窗的記錄序列作為輸入。使用所提出的模型，我們進行了一系列具有不同輸入特徵組合的實驗，以評估不同類型資訊在異常偵測中的角色。當提供長度不同的記錄序列時，與基線相比，該模型可以達到競爭且始終穩定的效能。結果表明，事件發生資訊在識別異常中扮演關鍵角色，而順序和暫時資訊的影響對於所研究的公開資料集中的異常偵測並不顯著。另一方面，這些發現也揭示了所研究的公開資料集的簡單性，並強調建構包含不同類型異常的新資料集以更好地評估異常偵測模型效能的重要性。</paragraph>

##### **COLLAGE: Collaborative Human-Agent Interaction Generation using Hierarchical Latent Diffusion and Language Models**
2409.20502v1 by Divyanshu Daiya, Damon Conover, Aniket Bera

We propose a novel framework COLLAGE for generating collaborative
agent-object-agent interactions by leveraging large language models (LLMs) and
hierarchical motion-specific vector-quantized variational autoencoders
(VQ-VAEs). Our model addresses the lack of rich datasets in this domain by
incorporating the knowledge and reasoning abilities of LLMs to guide a
generative diffusion model. The hierarchical VQ-VAE architecture captures
different motion-specific characteristics at multiple levels of abstraction,
avoiding redundant concepts and enabling efficient multi-resolution
representation. We introduce a diffusion model that operates in the latent
space and incorporates LLM-generated motion planning cues to guide the
denoising process, resulting in prompt-specific motion generation with greater
control and diversity. Experimental results on the CORE-4D, and InterHuman
datasets demonstrate the effectiveness of our approach in generating realistic
and diverse collaborative human-object-human interactions, outperforming
state-of-the-art methods. Our work opens up new possibilities for modeling
complex interactions in various domains, such as robotics, graphics and
computer vision.

摘要：我們提出一個名為 COLLAGE 的新框架，透過利用大型語言模型 (LLM) 和分層動作特定向量量化變異自動編碼器 (VQ-VAE) 來產生協作主體-物件-主體互動。我們的模型透過整合 LLM 的知識和推理能力來引導生成擴散模型，來解決此領域中缺乏豐富資料集的問題。分層 VQ-VAE 架構在多個抽象層級中擷取不同的動作特定特徵，避免冗餘概念並啟用有效率的多解析度表示。我們引入一個在潛在空間中運作的擴散模型，並整合 LLM 生成的動作規劃提示來引導去噪程序，產生具有更高控制和多樣性的提示特定動作。在 CORE-4D 和 InterHuman 資料集上的實驗結果證明了我們的方法在產生真實且多樣化的協作人體-物件-人體互動方面的有效性，優於最先進的方法。我們的研究為在各種領域（例如機器人技術、圖形和電腦視覺）中建模複雜互動開啟了新的可能性。

##### **Enhancing Romanian Offensive Language Detection through Knowledge Distillation, Multi-Task Learning, and Data Augmentation**
2409.20498v1 by Vlad-Cristian Matei, Iulian-Marius Tăiatu, Răzvan-Alexandru Smădu, Dumitru-Clementin Cercel

This paper highlights the significance of natural language processing (NLP)
within artificial intelligence, underscoring its pivotal role in comprehending
and modeling human language. Recent advancements in NLP, particularly in
conversational bots, have garnered substantial attention and adoption among
developers. This paper explores advanced methodologies for attaining smaller
and more efficient NLP models. Specifically, we employ three key approaches:
(1) training a Transformer-based neural network to detect offensive language,
(2) employing data augmentation and knowledge distillation techniques to
increase performance, and (3) incorporating multi-task learning with knowledge
distillation and teacher annealing using diverse datasets to enhance
efficiency. The culmination of these methods has yielded demonstrably improved
outcomes.

摘要：本文重点阐述自然语言处理 (NLP) 在人工智能中的重要性，强调其在理解和建模人类语言中至关重要的作用。NLP 的最新进展，尤其是在会话机器人方面，已引起开发人员的极大关注和采用。本文探讨了实现更小、更高效的 NLP 模型的高级方法。具体来说，我们采用了三种关键方法：(1) 训练基于 Transformer 的神经网络来检测攻击性语言，(2) 采用数据增强和知识蒸馏技术来提高性能，以及 (3) 结合多任务学习与知识蒸馏和教师退火，使用不同的数据集来提高效率。这些方法的结合产生了明显改善的结果。

##### **RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations**
2409.20483v1 by Johannes Kruse, Kasper Lindskow, Saikishore Kalloori, Marco Polignano, Claudio Pomo, Abhishek Srivastava, Anshuk Uppal, Michael Riis Andersen, Jes Frellsen

The RecSys Challenge 2024 aims to advance news recommendation by addressing
both the technical and normative challenges inherent in designing effective and
responsible recommender systems for news publishing. This paper describes the
challenge, including its objectives, problem setting, and the dataset provided
by the Danish news publishers Ekstra Bladet and JP/Politikens Media Group
("Ekstra Bladet"). The challenge explores the unique aspects of news
recommendation, such as modeling user preferences based on behavior, accounting
for the influence of the news agenda on user interests, and managing the rapid
decay of news items. Additionally, the challenge embraces normative
complexities, investigating the effects of recommender systems on news flow and
their alignment with editorial values. We summarize the challenge setup,
dataset characteristics, and evaluation metrics. Finally, we announce the
winners and highlight their contributions. The dataset is available at:
https://recsys.eb.dk.

摘要：RecSys Challenge 2024 旨在透過解決設計有效且負責任的新聞發布推薦系統時固有的技術和規範挑戰，來提升新聞推薦。本文說明了挑戰，包括其目標、問題設定，以及丹麥新聞出版商 Ekstra Bladet 和 JP/Politikens Media Group（「Ekstra Bladet」）提供的資料集。挑戰探討新聞推薦的獨特面向，例如根據行為建模使用者偏好、考量新聞議程對使用者興趣的影響，以及管理新聞項目快速衰退。此外，挑戰涵蓋規範的複雜性，調查推薦系統對新聞流程的影響，以及它們與編輯價值觀的一致性。我們總結挑戰設定、資料集特徵和評量指標。最後，我們宣布獲獎者並強調他們的貢獻。資料集可在以下網址取得：https://recsys.eb.dk。

##### **A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media**
2409.20467v1 by Dung Ha Nguyen, Anh Thi Hoang Nguyen, Kiet Van Nguyen

This study introduces an innovative automatic labeling framework to address
the challenges of lexical normalization in social media texts for low-resource
languages like Vietnamese. Social media data is rich and diverse, but the
evolving and varied language used in these contexts makes manual labeling
labor-intensive and expensive. To tackle these issues, we propose a framework
that integrates semi-supervised learning with weak supervision techniques. This
approach enhances the quality of training dataset and expands its size while
minimizing manual labeling efforts. Our framework automatically labels raw
data, converting non-standard vocabulary into standardized forms, thereby
improving the accuracy and consistency of the training data. Experimental
results demonstrate the effectiveness of our weak supervision framework in
normalizing Vietnamese text, especially when utilizing Pre-trained Language
Models. The proposed framework achieves an impressive F1-score of 82.72% and
maintains vocabulary integrity with an accuracy of up to 99.22%. Additionally,
it effectively handles undiacritized text under various conditions. This
framework significantly enhances natural language normalization quality and
improves the accuracy of various NLP tasks, leading to an average accuracy
increase of 1-3%.

摘要：本研究提出一個創新的自動標籤框架，以解決越南語等低資源語言在社群媒體文字中詞彙標準化的挑戰。社群媒體資料豐富且多元，但這些情境中使用不斷演進且多變的語言，使得手動標籤費時且昂貴。為了應對這些問題，我們提出一個將半監督式學習與弱監督式技術整合的框架。此方法提升訓練資料集的品質並擴充其規模，同時將手動標籤工作降至最低。我們的框架自動標籤原始資料，將非標準詞彙轉換為標準化形式，進而提升訓練資料的準確度和一致性。實驗結果證明我們的弱監督式框架在標準化越南語文字上具有成效，特別是在使用預訓練語言模型時。提出的框架達到令人印象深刻的 82.72% F1 分數，並以高達 99.22% 的準確度維持詞彙完整性。此外，它在各種條件下有效處理未加附加符號的文字。這個框架顯著提升自然語言標準化的品質，並提升各種自然語言處理任務的準確度，導致平均準確度提升 1-3%。

##### **Language Resources in Spanish for Automatic Text Simplification across Domains**
2409.20466v1 by Antonio Moreno-Sandoval, Leonardo Campillos-Llanos, Ana García-Serrano

This work describes the language resources and models developed for automatic
simplification of Spanish texts in three domains: Finance, Medicine and History
studies. We created several corpora in each domain, annotation and
simplification guidelines, a lexicon of technical and simplified medical terms,
datasets used in shared tasks for the financial domain, and two simplification
tools. The methodology, resources and companion publications are shared
publicly on the web-site: https://clara-nlp.uned.es/.

摘要：本研究描述了为三个领域的西班牙语文本自动简化而开发的语言资源和模型：金融、医学和历史研究。我们在每个领域创建了多个语料库、注释和简化指南、技术和简化医学术语词典、用于金融领域共享任务的数据集以及两个简化工具。方法、资源和配套出版物在网站上公开共享：https://clara-nlp.uned.es/。

##### **POMONAG: Pareto-Optimal Many-Objective Neural Architecture Generator**
2409.20447v1 by Eugenio Lomurno, Samuele Mariani, Matteo Monti, Matteo Matteucci

Neural Architecture Search (NAS) automates neural network design, reducing
dependence on human expertise. While NAS methods are computationally intensive
and dataset-specific, auxiliary predictors reduce the models needing training,
decreasing search time. This strategy is used to generate architectures
satisfying multiple computational constraints. Recently, Transferable NAS has
emerged, generalizing the search process from dataset-dependent to
task-dependent. In this field, DiffusionNAG is a state-of-the-art method. This
diffusion-based approach streamlines computation, generating architectures
optimized for accuracy on unseen datasets without further adaptation. However,
by focusing solely on accuracy, DiffusionNAG overlooks other crucial objectives
like model complexity, computational efficiency, and inference latency --
factors essential for deploying models in resource-constrained environments.
This paper introduces the Pareto-Optimal Many-Objective Neural Architecture
Generator (POMONAG), extending DiffusionNAG via a many-objective diffusion
process. POMONAG simultaneously considers accuracy, number of parameters,
multiply-accumulate operations (MACs), and inference latency. It integrates
Performance Predictor models to estimate these metrics and guide diffusion
gradients. POMONAG's optimization is enhanced by expanding its training
Meta-Dataset, applying Pareto Front Filtering, and refining embeddings for
conditional generation. These enhancements enable POMONAG to generate
Pareto-optimal architectures that outperform the previous state-of-the-art in
performance and efficiency. Results were validated on two search spaces --
NASBench201 and MobileNetV3 -- and evaluated across 15 image classification
datasets.

摘要：<paragraph>神經架構搜尋 (NAS) 自動化神經網路設計，減少對人類專業知識的依賴。儘管 NAS 方法在計算上很密集且特定於資料集，但輔助預測器可減少需要訓練的模型，縮短搜尋時間。此策略用於產生滿足多項運算限制的架構。近期，可轉移 NAS 已浮現，將搜尋程序從特定於資料集概括為特定於任務。在這個領域，DiffusionNAG 是一種最先進的方法。這種基於擴散的方法簡化了運算，產生了針對未見資料集最佳化準確度的架構，而無需進一步調整。然而，DiffusionNAG 僅專注於準確度，而忽略了其他關鍵目標，例如模型複雜度、運算效率和推論延遲，這些因素對於在資源受限的環境中部署模型至關重要。本文介紹了 Pareto 最佳多目標神經架構產生器 (POMONAG)，透過多目標擴散過程擴充 DiffusionNAG。POMONAG 同時考慮準確度、參數數量、乘累加運算 (MAC) 和推論延遲。它整合了效能預測器模型來估計這些指標並引導擴散梯度。POMONAG 的最佳化透過擴充其訓練元資料集、應用 Pareto 前緣過濾和精煉用於條件式產生的嵌入式元件而增強。這些增強功能讓 POMONAG 能夠產生 Pareto 最佳架構，其效能和效率優於先前的最先進技術。結果在兩個搜尋空間（NASBench201 和 MobileNetV3）上得到驗證，並在 15 個影像分類資料集上進行評估。</paragraph>

##### **Instance-adaptive Zero-shot Chain-of-Thought Prompting**
2409.20441v2 by Xiaosong Yuan, Chen Shen, Shaotian Yan, Xiaofeng Zhang, Liang Xie, Wenxiao Wang, Renchu Guan, Ying Wang, Jieping Ye

Zero-shot Chain-of-Thought (CoT) prompting emerges as a simple and effective
strategy for enhancing the performance of large language models (LLMs) in
real-world reasoning tasks. Nonetheless, the efficacy of a singular, task-level
prompt uniformly applied across the whole of instances is inherently limited
since one prompt cannot be a good partner for all, a more appropriate approach
should consider the interaction between the prompt and each instance
meticulously. This work introduces an instance-adaptive prompting algorithm as
an alternative zero-shot CoT reasoning scheme by adaptively differentiating
good and bad prompts. Concretely, we first employ analysis on LLMs through the
lens of information flow to detect the mechanism under zero-shot CoT reasoning,
in which we discover that information flows from question to prompt and
question to rationale jointly influence the reasoning results most. We notice
that a better zero-shot CoT reasoning needs the prompt to obtain semantic
information from the question then the rationale aggregates sufficient
information from the question directly and via the prompt indirectly. On the
contrary, lacking any of those would probably lead to a bad one. Stem from
that, we further propose an instance-adaptive prompting strategy (IAP) for
zero-shot CoT reasoning. Experiments conducted with LLaMA-2, LLaMA-3, and Qwen
on math, logic, and commonsense reasoning tasks (e.g., GSM8K, MMLU, Causal
Judgement) obtain consistent improvement, demonstrating that the
instance-adaptive zero-shot CoT prompting performs better than other task-level
methods with some curated prompts or sophisticated procedures, showing the
significance of our findings in the zero-shot CoT reasoning mechanism.

摘要：零次發想鏈（CoT）提示作為一種簡單且有效的策略，用於增強大型語言模型（LLM）在現實世界推理任務中的表現。儘管如此，單一任務級別提示在所有實例中統一應用的效力本質上是有限的，因為一個提示無法成為所有提示的好夥伴，一個更適當的方法應該仔細考慮提示與每個實例之間的交互。這項工作引入了一個實例自適應提示演算法，作為一種替代的零次發想鏈推理方案，通過自適應地區分好提示和壞提示。具體來說，我們首先通過資訊流的視角對 LLM 進行分析，以檢測零次發想鏈推理下的機制，我們發現從問題到提示和從問題到理由的資訊流共同對推理結果影響最大。我們注意到，一個更好的零次發想鏈推理需要提示從問題中獲取語義資訊，然後理由直接從問題中聚合足夠的資訊，並通過提示間接聚合。相反，缺少任何一個都可能導致一個壞的推理。由此，我們進一步提出了一個實例自適應提示策略（IAP），用於零次發想鏈推理。使用 LLaMA-2、LLaMA-3 和 Qwen 在數學、邏輯和常識推理任務（例如 GSM8K、MMLU、因果判斷）上進行的實驗獲得了一致的改進，證明了實例自適應零次發想鏈提示比其他具有某些策展提示或複雜程序的任務級別方法表現得更好，顯示了我們的發現對於零次發想鏈推理機制的意義。

##### **QAEncoder: Towards Aligned Representation Learning in Question Answering System**
2409.20434v1 by Zhengren Wang, Qinhan Yu, Shida Wei, Zhiyu Li, Feiyu Xiong, Xiaoxing Wang, Simin Niu, Hao Liang, Wentao Zhang

Modern QA systems entail retrieval-augmented generation (RAG) for accurate
and trustworthy responses. However, the inherent gap between user queries and
relevant documents hinders precise matching. Motivated by our conical
distribution hypothesis, which posits that potential queries and documents form
a cone-like structure in the embedding space, we introduce QAEncoder, a
training-free approach to bridge this gap. Specifically, QAEncoder estimates
the expectation of potential queries in the embedding space as a robust
surrogate for the document embedding, and attaches document fingerprints to
effectively distinguish these embeddings. Extensive experiments on fourteen
embedding models across six languages and eight datasets validate QAEncoder's
alignment capability, which offers a plug-and-play solution that seamlessly
integrates with existing RAG architectures and training-based methods.

摘要：現代 QA 系統需要檢索增強生成 (RAG) 才能提供準確且值得信賴的回應。然而，使用者查詢與相關文件之間的固有差距阻礙了精確的配對。在我們的錐形分佈假設的激勵下，該假設認為潛在查詢和文件在嵌入空間中形成類錐形結構，我們引入了 QAEncoder，一種無需訓練的方法來彌合這一差距。具體來說，QAEncoder 將嵌入空間中潛在查詢的期望值估計為文件嵌入的強健替代，並附加文件指紋以有效區分這些嵌入。在六種語言和八個資料集上的十四個嵌入模型上的廣泛實驗驗證了 QAEncoder 的對齊能力，這提供了一個即插即用的解決方案，可以與現有的 RAG 架構和基於訓練的方法無縫整合。

##### **HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding**
2409.20429v1 by Fan Yuan, Chi Qin, Xiaogang Xu, Piji Li

Large Vision-Language Models (LVLMs) have shown remarkable performance on
many visual-language tasks. However, these models still suffer from multimodal
hallucination, which means the generation of objects or content that violates
the images. Many existing work detects hallucination by directly judging
whether an object exists in an image, overlooking the association between the
object and semantics. To address this issue, we propose Hierarchical Feedback
Learning with Vision-enhanced Penalty Decoding (HELPD). This framework
incorporates hallucination feedback at both object and sentence semantic
levels. Remarkably, even with a marginal degree of training, this approach can
alleviate over 15% of hallucination. Simultaneously, HELPD penalizes the output
logits according to the image attention window to avoid being overly affected
by generated text. HELPD can be seamlessly integrated with any LVLMs. Our
experiments demonstrate that the proposed framework yields favorable results
across multiple hallucination benchmarks. It effectively mitigates
hallucination for different LVLMs and concurrently improves their text
generation quality.

摘要：大型視覺語言模型 (LVLMs) 在許多視覺語言任務中表現出色。然而，這些模型仍然存在多模態幻覺，這表示產生的物件或內容違反了影像。許多現有工作透過直接判斷物件是否存在於影像中來偵測幻覺，忽略了物件與語義之間的關聯。為了解決這個問題，我們提出了具有視覺增強懲罰解碼的階層式回饋學習 (HELPD)。此架構在物件和句子語義層級中都納入了幻覺回饋。值得注意的是，即使訓練程度很低，這種方法也能減輕超過 15% 的幻覺。同時，HELPD 會根據影像注意力視窗懲罰輸出 logit，以避免受到生成文字過度影響。HELPD 可以與任何 LVLMs 無縫整合。我們的實驗證明，所提出的架構在多個幻覺基準中產生了良好的結果。它有效地減輕了不同 LVLMs 的幻覺，並同時提升其文字生成品質。

##### **Sufficient and Necessary Explanations (and What Lies in Between)**
2409.20427v1 by Beepul Bharti, Paul Yi, Jeremias Sulam

As complex machine learning models continue to find applications in
high-stakes decision-making scenarios, it is crucial that we can explain and
understand their predictions. Post-hoc explanation methods provide useful
insights by identifying important features in an input $\mathbf{x}$ with
respect to the model output $f(\mathbf{x})$. In this work, we formalize and
study two precise notions of feature importance for general machine learning
models: sufficiency and necessity. We demonstrate how these two types of
explanations, albeit intuitive and simple, can fall short in providing a
complete picture of which features a model finds important. To this end, we
propose a unified notion of importance that circumvents these limitations by
exploring a continuum along a necessity-sufficiency axis. Our unified notion,
we show, has strong ties to other popular definitions of feature importance,
like those based on conditional independence and game-theoretic quantities like
Shapley values. Crucially, we demonstrate how a unified perspective allows us
to detect important features that could be missed by either of the previous
approaches alone.

摘要：隨著複雜機器學習模型持續在高風險決策情境中找到應用，我們能夠解釋並了解其預測至關重要。事後解釋方法透過辨識輸入 $\mathbf{x}$ 中相對於模型輸出 $f(\mathbf{x})$ 的重要特徵，提供了有用的見解。在這項工作中，我們形式化並研究了兩種精確的機器學習模型特徵重要性概念：充分性和必要性。我們展示了這兩種類型的解釋，儘管直觀且簡單，但在提供模型認為重要的特徵的完整圖像方面可能會有所不足。為此，我們提出了統一的重要性概念，透過探索必要性-充分性軸上的連續統整體來規避這些限制。我們展示了統一概念與其他流行的特徵重要性定義有密切關聯，例如基於條件獨立性和博弈論量（如 Shapley 值）的定義。至關重要的是，我們展示了統一的觀點如何讓我們能夠偵測到以前任何一種方法都可能錯失的重要特徵。

##### **World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering**
2409.20424v1 by Jiacong Wang, Bohong Wu, Haiyong Jiang, Xun Zhou, Xin Xiao, Haoyuan Guo, Jun Xiao

Recent advances in Vision-Language Models (VLMs) and the scarcity of
high-quality multi-modal alignment data have inspired numerous researches on
synthetic VLM data generation. The conventional norm in VLM data construction
uses a mixture of specialists in caption and OCR, or stronger VLM APIs and
expensive human annotation. In this paper, we present World to Code (W2C), a
meticulously curated multi-modal data construction pipeline that organizes the
final generation output into a Python code format. The pipeline leverages the
VLM itself to extract cross-modal information via different prompts and filter
the generated outputs again via a consistency filtering strategy. Experiments
have demonstrated the high quality of W2C by improving various existing visual
question answering and visual grounding benchmarks across different VLMs.
Further analysis also demonstrates that the new code parsing ability of VLMs
presents better cross-modal equivalence than the commonly used detail caption
ability. Our code is available at
https://github.com/foundation-multimodal-models/World2Code.

摘要：近期在視覺語言模型 (VLM) 的進展以及高品質多模態對齊資料的稀缺，激發了許多關於合成 VLM 資料產生的研究。VLM 資料建構中的傳統規範使用標題和 OCR 專家，或更強大的 VLM API 和昂貴的人工標註的混合。在本文中，我們提出世界到程式碼 (W2C)，一個精心策劃的多模態資料建構管道，它將最終產生的輸出組織成 Python 程式碼格式。該管道利用 VLM 本身透過不同的提示來萃取跨模態資訊，並透過一致性過濾策略再次過濾產生的輸出。實驗已透過改善不同 VLM 中的各種現有視覺問答和視覺基礎基準來證明 W2C 的高品質。進一步的分析也證明 VLM 的新程式碼解析能力呈現出比一般使用的詳細標題能力更好的跨模態等價性。我們的程式碼可在 https://github.com/foundation-multimodal-models/World2Code 取得。

##### **Stream-level flow matching from a Bayesian decision theoretic perspective**
2409.20423v1 by Ganchao Wei, Li Ma

Flow matching (FM) is a family of training algorithms for fitting continuous
normalizing flows (CNFs). A standard approach to FM, called conditional flow
matching (CFM), exploits the fact that the marginal vector field of a CNF can
be learned by fitting least-square regression to the so-called conditional
vector field specified given one or both ends of the flow path. We show that
viewing CFM training from a Bayesian decision theoretic perspective on
parameter estimation opens the door to generalizations of CFM algorithms. We
propose one such extension by introducing a CFM algorithm based on defining
conditional probability paths given what we refer to as ``streams'', instances
of latent stochastic paths that connect pairs of noise and observed data.
Further, we advocates the modeling of these latent streams using Gaussian
processes (GPs). The unique distributional properties of GPs, and in particular
the fact that the velocities of a GP is still a GP, allows drawing samples from
the resulting stream-augmented conditional probability path without simulating
the actual streams, and hence the ``simulation-free" nature of CFM training is
preserved. We show that this generalization of the CFM can substantially reduce
the variance in the estimated marginal vector field at a moderate computational
cost, thereby improving the quality of the generated samples under common
metrics. Additionally, we show that adopting the GP on the streams allows for
flexibly linking multiple related training data points (e.g., time series) and
incorporating additional prior information. We empirically validate our claim
through both simulations and applications to two hand-written image datasets.

摘要：流匹配 (FM) 是用於擬合連續正規化流 (CNF) 的一組訓練演算法。一種稱為條件流匹配 (CFM) 的標準 FM 方法利用了 CNF 的邊際向量場可以透過擬合最小平方迴歸來學習，以指定給定流路徑一端或兩端的條件向量場。我們展示了從貝氏決策理論觀點檢視 CFM 訓練，在參數估計上開啟了 CFM 演算法的概括。我們提出一個這樣的延伸，透過引入基於定義條件機率路徑的 CFM 演算法，給定我們稱為「串流」的潛在隨機路徑，連接雜訊和觀察資料對。此外，我們主張使用高斯過程 (GP) 對這些潛在串流進行建模。GP 的獨特分佈特性，特別是 GP 的速度仍為 GP 的事實，允許從串流增強的條件機率路徑中抽取樣本，而無需模擬實際串流，因此 CFM 訓練的「無模擬」性質得以保留。我們展示了 CFM 的這種概括可以在適度的運算成本下大幅減少估計邊際向量場的變異，從而改善常見指標下產生樣本的品質。此外，我們展示了在串流上採用 GP 可以靈活地連結多個相關的訓練資料點（例如時間序列），並納入其他先驗資訊。我們透過模擬和應用於兩個手寫影像資料集，實證驗證了我們的說法。

##### **Conformal Prediction for Dose-Response Models with Continuous Treatments**
2409.20412v1 by Jarne Verhaeghe, Jef Jonkers, Sofie Van Hoecke

Understanding the dose-response relation between a continuous treatment and
the outcome for an individual can greatly drive decision-making, particularly
in areas like personalized drug dosing and personalized healthcare
interventions. Point estimates are often insufficient in these high-risk
environments, highlighting the need for uncertainty quantification to support
informed decisions. Conformal prediction, a distribution-free and
model-agnostic method for uncertainty quantification, has seen limited
application in continuous treatments or dose-response models. To address this
gap, we propose a novel methodology that frames the causal dose-response
problem as a covariate shift, leveraging weighted conformal prediction. By
incorporating propensity estimation, conformal predictive systems, and
likelihood ratios, we present a practical solution for generating prediction
intervals for dose-response models. Additionally, our method approximates local
coverage for every treatment value by applying kernel functions as weights in
weighted conformal prediction. Finally, we use a new synthetic benchmark
dataset to demonstrate the significance of covariate shift assumptions in
achieving robust prediction intervals for dose-response models.

摘要：了解连续治疗与个人结果之间的剂量反应关系可以极大地推动决策制定，尤其是在个性化药物给药和个性化医疗保健干预等领域。在这些高风险环境中，点估计通常是不够的，这突出了对不确定性量化的需求，以支持明智的决策。一致性预测是一种不依赖分布且与模型无关的不确定性量化方法，在连续治疗或剂量反应模型中的应用受到限制。为了解决这一差距，我们提出了一种新方法，将因果剂量反应问题构建为协变量转移，利用加权一致性预测。通过纳入倾向估计、一致性预测系统和似然比，我们提出了一个实用的解决方案，用于生成剂量反应模型的预测区间。此外，我们的方法通过在加权一致性预测中应用核函数作为权重，为每个治疗值近似局部覆盖。最后，我们使用一个新的合成基准数据集来证明协变量转移假设在实现剂量反应模型的稳健预测区间中的重要性。

##### **Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield Anti-stereotypical Writing**
2409.20390v1 by Connor Baumler, Hal Daumé III

AI-based systems such as language models can replicate and amplify social
biases reflected in their training data. Among other questionable behavior,
this can lead to LM-generated text--and text suggestions--that contain
normatively inappropriate stereotypical associations. In this paper, we
consider the question of how "debiasing" a language model impacts stories that
people write using that language model in a predictive text scenario. We find
that (n=414), in certain scenarios, language model suggestions that align with
common social stereotypes are more likely to be accepted by human authors.
Conversely, although anti-stereotypical language model suggestions sometimes
lead to an increased rate of anti-stereotypical stories, this influence is far
from sufficient to lead to "fully debiased" stories.

摘要：基於 AI 的系統，例如語言模型，可以複製和放大訓練資料中反映的社會偏見。在其他可疑行為中，這可能導致 LM 生成的文字和文字建議包含規範上不適當的刻板印象聯想。在本文中，我們考慮了「去偏見」語言模型如何影響人們在預測文字場景中使用該語言模型撰寫的故事的問題。我們發現 (n=414)，在某些情況下，與常見社會刻板印象一致的語言模型建議更有可能被人類作者接受。相反，儘管反刻板印象語言模型建議有時會導致反刻板印象故事的比率增加，但這種影響遠不足以導致「完全去偏見」的故事。

##### **Wait, but Tylenol is Acetaminophen... Investigating and Improving Language Models' Ability to Resist Requests for Misinformation**
2409.20385v1 by Shan Chen, Mingye Gao, Kuleen Sasse, Thomas Hartvigsen, Brian Anthony, Lizhou Fan, Hugo Aerts, Jack Gallifant, Danielle Bitterman

Background: Large language models (LLMs) are trained to follow directions,
but this introduces a vulnerability to blindly comply with user requests even
if they generate wrong information. In medicine, this could accelerate the
generation of misinformation that impacts human well-being.
  Objectives/Methods: We analyzed compliance to requests to generate misleading
content about medications in settings where models know the request is
illogical. We investigated whether in-context directions and instruction-tuning
of LLMs to prioritize logical reasoning over compliance reduced misinformation
risk.
  Results: While all frontier LLMs complied with misinformation requests, both
prompt-based and parameter-based approaches can improve the detection of logic
flaws in requests and prevent the dissemination of medical misinformation.
  Conclusion: Shifting LLMs to prioritize logic over compliance could reduce
risks of exploitation for medical misinformation.

摘要：背景：大型語言模型 (LLM) 接受訓練以遵循指示，但這導致了一個漏洞，即使它們會產生錯誤資訊，也會盲目地遵守使用者的要求。在醫學領域，這可能會加速產生錯誤資訊，進而影響人類的健康。
目標/方法：我們分析了在模型知道請求不合理的情況下，對產生有關藥物的誤導內容請求的遵守情況。我們調查了情境指示和 LLM 的指令調整是否可以優先考慮邏輯推理，高於遵循指示，進而降低錯誤資訊的風險。
結果：雖然所有前沿 LLM 都遵守錯誤資訊請求，但基於提示和基於參數的方法都可以改善對請求中邏輯缺陷的偵測，並防止醫學錯誤資訊的傳播。
結論：將 LLM 轉移到優先考慮邏輯高於遵循指示，可以降低錯誤資訊被用於醫療目的的風險。

##### **Word-wise intonation model for cross-language TTS systems**
2409.20374v1 by Tomilov A. A., Gromova A. Y., Svischev A. N

In this paper we propose a word-wise intonation model for Russian language
and show how it can be generalized for other languages. The proposed model is
suitable for automatic data markup and its extended application to
text-to-speech systems. It can also be implemented for an intonation contour
modeling by using rule-based algorithms or by predicting contours with language
models. The key idea is a partial elimination of the variability connected with
different placements of a stressed syllable in a word. It is achieved with
simultaneous applying of pitch simplification with a dynamic time warping
clustering. The proposed model could be used as a tool for intonation research
or as a backbone for prosody description in text-to-speech systems. As the
advantage of the model, we show its relations with the existing intonation
systems as well as the possibility of using language models for prosody
prediction. Finally, we demonstrate some practical evidence of the system
robustness to parameter variations.

摘要：在本文中，我们提出了俄语单词级的语调模型，并展示了如何将其推广到其他语言。所提出的模型适用于自动数据标记及其在文本到语音系统的扩展应用。它还可以通过使用基于规则的算法或通过使用语言模型预测轮廓来实现语调轮廓建模。关键思想是部分消除与单词中重读音节不同位置相关的可变性。这是通过同时应用音高简化和动态时间扭曲聚类来实现的。所提出的模型可以用作语调研究的工具，或作为文本到语音系统中韵律描述的骨干。作为该模型的优点，我们展示了它与现有语调系统的关系，以及使用语言模型进行韵律预测的可能性。最后，我们展示了系统对参数变化的鲁棒性的实际证据。

##### **Frequency Adaptive Normalization For Non-stationary Time Series Forecasting**
2409.20371v1 by Weiwei Ye, Songgaojun Deng, Qiaosha Zou, Ning Gui

Time series forecasting typically needs to address non-stationary data with
evolving trend and seasonal patterns. To address the non-stationarity,
reversible instance normalization has been recently proposed to alleviate
impacts from the trend with certain statistical measures, e.g., mean and
variance. Although they demonstrate improved predictive accuracy, they are
limited to expressing basic trends and are incapable of handling seasonal
patterns. To address this limitation, this paper proposes a new instance
normalization solution, called frequency adaptive normalization (FAN), which
extends instance normalization in handling both dynamic trend and seasonal
patterns. Specifically, we employ the Fourier transform to identify
instance-wise predominant frequent components that cover most non-stationary
factors. Furthermore, the discrepancy of those frequency components between
inputs and outputs is explicitly modeled as a prediction task with a simple MLP
model. FAN is a model-agnostic method that can be applied to arbitrary
predictive backbones. We instantiate FAN on four widely used forecasting models
as the backbone and evaluate their prediction performance improvements on eight
benchmark datasets. FAN demonstrates significant performance advancement,
achieving 7.76% ~ 37.90% average improvements in MSE.

摘要：時間序列預測通常需要處理具有演化趨勢和季節性模式的非平穩數據。為了解決非平穩性，最近提出了可逆實例正規化，以使用某些統計量（例如平均值和變異數）減輕趨勢的影響。儘管它們展示了改進的預測準確性，但它們僅限於表達基本趨勢，並且無法處理季節性模式。為了解決這個限制，本文提出了一個新的實例正規化解決方案，稱為頻率自適應正規化 (FAN)，它擴展了實例正規化，以處理動態趨勢和季節性模式。具體來說，我們使用傅立葉轉換來識別覆蓋大多數非平穩因素的實例級主要頻率分量。此外，輸入和輸出之間這些頻率分量的差異被明確建模為具有簡單 MLP 模型的預測任務。FAN 是一個與模型無關的方法，可以應用於任意預測主幹。我們在四個廣泛使用的預測模型上實例化 FAN 作為主幹，並在八個基準數據集上評估它們的預測性能改進。FAN 展示了顯著的性能提升，在 MSE 中實現了 7.76% ~ 37.90% 的平均改進。

##### **The Perfect Blend: Redefining RLHF with Mixture of Judges**
2409.20370v1 by Tengyu Xu, Eryk Helenowski, Karthik Abinav Sankararaman, Di Jin, Kaiyan Peng, Eric Han, Shaoliang Nie, Chen Zhu, Hejia Zhang, Wenxuan Zhou, Zhouhao Zeng, Yun He, Karishma Mandyam, Arya Talabzadeh, Madian Khabsa, Gabriel Cohen, Yuandong Tian, Hao Ma, Sinong Wang, Han Fang

Reinforcement learning from human feedback (RLHF) has become the leading
approach for fine-tuning large language models (LLM). However, RLHF has
limitations in multi-task learning (MTL) due to challenges of reward hacking
and extreme multi-objective optimization (i.e., trade-off of multiple and/or
sometimes conflicting objectives). Applying RLHF for MTL currently requires
careful tuning of the weights for reward model and data combinations. This is
often done via human intuition and does not generalize. In this work, we
introduce a novel post-training paradigm which we called Constrained Generative
Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with
cost-efficient constrained policy optimization with stratification, which can
identify the perfect blend in RLHF in a principled manner. It shows strong
empirical results with theoretical guarantees, does not require extensive
hyper-parameter tuning, and is plug-and-play in common post-training pipelines.
Together, this can detect and mitigate reward hacking behaviors while reaching
a pareto-optimal point across an extremely large number of objectives.
  Our empirical evaluations demonstrate that CGPO significantly outperforms
standard RLHF algorithms like PPO and DPO across various tasks including
general chat, STEM questions, instruction following, and coding. Specifically,
CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in
Arena-Hard (STEM & reasoning), and consistent gains in other domains like math
and coding. Notably, PPO, while commonly used, is prone to severe reward
hacking in popular coding benchmarks, which CGPO successfully addresses. This
breakthrough in RLHF not only tackles reward hacking and extreme
multi-objective optimization challenges but also advances the state-of-the-art
in aligning general-purpose LLMs for diverse applications.

摘要：人類回饋強化學習 (RLHF) 已成為微調大型語言模型 (LLM) 的領先方法。然而，RLHF 在多任務學習 (MTL) 中受到獎勵破解和極端多目標最佳化（例如，多重和/或有時相互衝突的目標之間的取捨）的挑戰而有所限制。目前，將 RLHF 應用於 MTL 需要仔細調整獎勵模型和資料組合的權重。這通常是透過人類直覺來完成，而且無法概括。在這項工作中，我們引入了一種新穎的訓練後範例，我們稱之為受約束生成策略最佳化 (CGPO)。CGPO 的核心是法官混合 (MoJ)，透過分層進行具有成本效益的受約束策略最佳化，它可以以原則性的方式找出 RLHF 中的完美融合。它在理論保證下展現強大的實證結果，不需要廣泛的超參數調整，並且可以即插即用於常見的訓練後管道。總之，它可以在極大量的目標中偵測和減輕獎勵破解行為，同時達到帕雷托最優點。我們的實證評估證明，CGPO 在各種任務中顯著優於標準 RLHF 演算法，例如一般聊天、STEM 問題、指令遵循和編碼。具體來說，CGPO 在 AlpacaEval-2（一般聊天）中提升了 7.4%，在 Arena-Hard（STEM 和推理）中提升了 12.5%，並且在數學和編碼等其他領域中持續獲得收益。值得注意的是，PPO 雖然普遍使用，但在流行的編碼基準中容易受到嚴重的獎勵破解，而 CGPO 成功地解決了這個問題。RLHF 的這項突破不僅解決了獎勵破解和極端多目標最佳化的挑戰，而且還推動了將通用 LLM 與各種應用程式相結合的最新技術。

##### **Disentangling Singlish Discourse Particles with Task-Driven Representation**
2409.20366v1 by Linus Tze En Foo, Lynnette Hui Xian Ng

Singlish, or formally Colloquial Singapore English, is an English-based
creole language originating from the SouthEast Asian country Singapore. The
language contains influences from Sinitic languages such as Chinese dialects,
Malay, Tamil and so forth. A fundamental task to understanding Singlish is to
first understand the pragmatic functions of its discourse particles, upon which
Singlish relies heavily to convey meaning. This work offers a preliminary
effort to disentangle the Singlish discourse particles (lah, meh and hor) with
task-driven representation learning. After disentanglement, we cluster these
discourse particles to differentiate their pragmatic functions, and perform
Singlish-to-English machine translation. Our work provides a computational
method to understanding Singlish discourse particles, and opens avenues towards
a deeper comprehension of the language and its usage.

摘要：星式英语，或正式名称为新加坡口语英语，是一种以英语为基础的克里奥尔语，起源于东南亚国家新加坡。该语言包含汉语方言、马来语、泰米尔语等汉语语言的影响。理解星式英语的一项基本任务是首先理解其话语粒子的语用功能，星式英语在很大程度上依赖于此来传达意义。这项工作提供了一项初步尝试，即利用任务驱动的表征学习来解开星式英语话语粒子（lah、meh 和 hor）。在解开纠缠后，我们将这些话语粒子进行聚类以区分它们的语用功能，并执行星式英语到英语的机器翻译。我们的工作提供了一种计算方法来理解星式英语话语粒子，并为更深入地理解该语言及其用法开辟了途径。

##### **Efficient Driving Behavior Narration and Reasoning on Edge Device Using Large Language Models**
2409.20364v1 by Yizhou Huang, Yihua Cheng, Kezhi Wang

Deep learning architectures with powerful reasoning capabilities have driven
significant advancements in autonomous driving technology. Large language
models (LLMs) applied in this field can describe driving scenes and behaviors
with a level of accuracy similar to human perception, particularly in visual
tasks. Meanwhile, the rapid development of edge computing, with its advantage
of proximity to data sources, has made edge devices increasingly important in
autonomous driving. Edge devices process data locally, reducing transmission
delays and bandwidth usage, and achieving faster response times. In this work,
we propose a driving behavior narration and reasoning framework that applies
LLMs to edge devices. The framework consists of multiple roadside units, with
LLMs deployed on each unit. These roadside units collect road data and
communicate via 5G NSR/NR networks. Our experiments show that LLMs deployed on
edge devices can achieve satisfactory response speeds. Additionally, we propose
a prompt strategy to enhance the narration and reasoning performance of the
system. This strategy integrates multi-modal information, including
environmental, agent, and motion data. Experiments conducted on the
OpenDV-Youtube dataset demonstrate that our approach significantly improves
performance across both tasks.

摘要：深度學習架構具備強大的推理能力，推動了自動駕駛技術的重大進展。應用於此領域的大型語言模型 (LLM) 可以描述駕駛場景和行為，其準確度與人類感知類似，特別是在視覺任務中。同時，邊緣運算的快速發展，因其靠近數據源的優勢，使得邊緣設備在自動駕駛中變得越來越重要。邊緣設備在本地處理數據，減少傳輸延遲和頻寬使用，並實現更快的響應時間。在這項工作中，我們提出了一個駕駛行為敘述和推理框架，將 LLM 應用於邊緣設備。該框架由多個路邊單元組成，每個單元上都部署了 LLM。這些路邊單元收集道路數據並通過 5G NSR/NR 網路進行通信。我們的實驗表明，部署在邊緣設備上的 LLM 可以實現令人滿意的響應速度。此外，我們提出了一種提示策略來增強系統的敘述和推理性能。此策略整合了多模態信息，包括環境、代理和運動數據。在 OpenDV-Youtube 數據集上進行的實驗表明，我們的方案顯著提高了這兩項任務的性能。

##### **Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference**
2409.20361v1 by Ke Yi, Zengke Liu, Jianwei Zhang, Chengyuan Li, Tong Zhang, Junyang Lin, Jingren Zhou

Large language models have demonstrated promising capabilities upon scaling
up parameters. However, serving large language models incurs substantial
computation and memory movement costs due to their large scale. Quantization
methods have been employed to reduce service costs and latency. Nevertheless,
outliers in activations hinder the development of INT4 weight-activation
quantization. Existing approaches separate outliers and normal values into two
matrices or migrate outliers from activations to weights, suffering from high
latency or accuracy degradation. Based on observing activations from large
language models, outliers can be classified into channel-wise and spike
outliers. In this work, we propose Rotated Runtime Smooth (RRS), a
plug-and-play activation smoother for quantization, consisting of Runtime
Smooth and the Rotation operation. Runtime Smooth (RS) is introduced to
eliminate channel-wise outliers by smoothing activations with channel-wise
maximums during runtime. The rotation operation can narrow the gap between
spike outliers and normal values, alleviating the effect of victims caused by
channel-wise smoothing. The proposed method outperforms the state-of-the-art
method in the LLaMA and Qwen families and improves WikiText-2 perplexity from
57.33 to 6.66 for INT4 inference.

摘要：大型语言模型在扩大参数时已展示出有希望的能力。然而，由于大规模，提供大型语言模型会产生大量的计算和内存移动成本。量化方法已被用来降低服务成本和延迟。尽管如此，激活中的异常值阻碍了 INT4 权重激活量化的发展。现有的方法将异常值和正常值分成两个矩阵，或将异常值从激活迁移到权重，从而导致高延迟或精度下降。基于对大型语言模型的激活观察，异常值可以分类为通道内异常值和尖峰异常值。在这项工作中，我们提出了旋转运行时平滑 (RRS)，这是一种即插即用的激活平滑器，用于量化，由运行时平滑和旋转操作组成。引入运行时平滑 (RS) 以通过在运行时使用通道内最大值平滑激活来消除通道内异常值。旋转操作可以缩小尖峰异常值和正常值之间的差距，减轻通道内平滑造成的受害影响。所提出的方法优于 LLaMA 和 Qwen 系列中的最先进方法，并将 WikiText-2 的困惑度从 57.33 提高到 6.66，用于 INT4 推断。

##### **Enhancing GANs with Contrastive Learning-Based Multistage Progressive Finetuning SNN and RL-Based External Optimization**
2409.20340v2 by Osama Mustafa

The application of deep learning in cancer research, particularly in early
diagnosis, case understanding, and treatment strategy design, emphasizes the
need for high-quality data. Generative AI, especially Generative Adversarial
Networks (GANs), has emerged as a leading solution to challenges like class
imbalance, robust learning, and model training, while addressing issues
stemming from patient privacy and the scarcity of real data. Despite their
promise, GANs face several challenges, both inherent and specific to
histopathology data. Inherent issues include training imbalance, mode collapse,
linear learning from insufficient discriminator feedback, and hard boundary
convergence due to stringent feedback. Histopathology data presents a unique
challenge with its complex representation, high spatial resolution, and
multiscale features. To address these challenges, we propose a framework
consisting of two components. First, we introduce a contrastive learning-based
Multistage Progressive Finetuning Siamese Neural Network (MFT-SNN) for
assessing the similarity between histopathology patches. Second, we implement a
Reinforcement Learning-based External Optimizer (RL-EO) within the GAN training
loop, serving as a reward signal generator. The modified discriminator loss
function incorporates a weighted reward, guiding the GAN to maximize this
reward while minimizing loss. This approach offers an external optimization
guide to the discriminator, preventing generator overfitting and ensuring
smooth convergence. Our proposed solution has been benchmarked against
state-of-the-art (SOTA) GANs and a Denoising Diffusion Probabilistic model,
outperforming previous SOTA across various metrics, including FID score, KID
score, Perceptual Path Length, and downstream classification tasks.

摘要：深度學習在癌症研究中的應用，特別是在早期診斷、案例理解和治療策略設計中，強調了對高品質數據的需求。生成式 AI，特別是生成式對抗網路 (GAN)，已成為解決類別不平衡、穩健學習和模型訓練等挑戰的領先解決方案，同時解決了患者隱私和真實數據稀缺的問題。儘管有其優點，但 GAN 面臨著多項挑戰，既有固有的，也有特定於組織病理學數據的。固有問題包括訓練不平衡、模式崩潰、判別器回饋不足導致的線性學習，以及由於嚴格回饋導致的硬邊界收斂。組織病理學數據以其複雜的表示、高空間解析度和多尺度特徵呈現出獨特的挑戰。為了應對這些挑戰，我們提出了一個由兩個組成部分組成的框架。首先，我們引入了一個基於對比學習的多階段漸進微調連體神經網路 (MFT-SNN)，用於評估組織病理學貼片之間的相似性。其次，我們在 GAN 訓練迴圈中實作了一個基於強化學習的外部優化器 (RL-EO)，作為獎勵訊號產生器。修改後的判別器損失函數包含一個加權獎勵，指導 GAN 在最小化損失的同時最大化這個獎勵。這種方法為判別器提供了外部優化指南，防止生成器過度擬合並確保平穩收斂。我們提出的解決方案已針對最先進 (SOTA) GAN 和去噪擴散概率模型進行了基準測試，在 FID 分數、KID 分數、感知路徑長度和下游分類任務等各種指標上優於先前的 SOTA。

##### **Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding**
2409.20313v1 by Takafumi Moriya, Takanori Ashihara, Masato Mimura, Hiroshi Sato, Kohei Matsuura, Ryo Masumura, Taichi Asami

A hybrid autoregressive transducer (HAT) is a variant of neural transducer
that models blank and non-blank posterior distributions separately. In this
paper, we propose a novel internal acoustic model (IAM) training strategy to
enhance HAT-based speech recognition. IAM consists of encoder and joint
networks, which are fully shared and jointly trained with HAT. This joint
training not only enhances the HAT training efficiency but also encourages IAM
and HAT to emit blanks synchronously which skips the more expensive non-blank
computation, resulting in more effective blank thresholding for faster
decoding. Experiments demonstrate that the relative error reductions of the HAT
with IAM compared to the vanilla HAT are statistically significant. Moreover,
we introduce dual blank thresholding, which combines both HAT- and IAM-blank
thresholding and a compatible decoding algorithm. This results in a 42-75%
decoding speed-up with no major performance degradation.

摘要：混合自迴歸轉換器 (HAT) 是神經轉換器的一種變體，它分別對空白和非空白後驗分佈進行建模。在本文中，我們提出了一種新穎的內部聲學模型 (IAM) 訓練策略，以增強基於 HAT 的語音識別。IAM 由編碼器和聯合網路組成，它們完全共享並與 HAT 聯合訓練。這種聯合訓練不僅提高了 HAT 訓練效率，還鼓勵 IAM 和 HAT 同步發出空白，從而跳過更昂貴的非空白計算，從而對更有效的空白閾值進行更快解碼。實驗表明，與香草 HAT 相比，帶有 IAM 的 HAT 的相對誤差減少具有統計學意義。此外，我們引入了雙空白閾值，它結合了 HAT 和 IAM 空白閾值和一個相容的解碼演算法。這導致解碼速度提高了 42-75%，而效能沒有明顯下降。

##### **A Looming Replication Crisis in Evaluating Behavior in Language Models? Evidence and Solutions**
2409.20303v1 by Laurène Vaugrante, Mathias Niepert, Thilo Hagendorff

In an era where large language models (LLMs) are increasingly integrated into
a wide range of everyday applications, research into these models' behavior has
surged. However, due to the novelty of the field, clear methodological
guidelines are lacking. This raises concerns about the replicability and
generalizability of insights gained from research on LLM behavior. In this
study, we discuss the potential risk of a replication crisis and support our
concerns with a series of replication experiments focused on prompt engineering
techniques purported to influence reasoning abilities in LLMs. We tested
GPT-3.5, GPT-4o, Gemini 1.5 Pro, Claude 3 Opus, Llama 3-8B, and Llama 3-70B, on
the chain-of-thought, EmotionPrompting, ExpertPrompting, Sandbagging, as well
as Re-Reading prompt engineering techniques, using manually double-checked
subsets of reasoning benchmarks including CommonsenseQA, CRT, NumGLUE,
ScienceQA, and StrategyQA. Our findings reveal a general lack of statistically
significant differences across nearly all techniques tested, highlighting,
among others, several methodological weaknesses in previous research. We
propose a forward-looking approach that includes developing robust
methodologies for evaluating LLMs, establishing sound benchmarks, and designing
rigorous experimental frameworks to ensure accurate and reliable assessments of
model outputs.

摘要：在大型語言模型（LLM）日益整合到各種日常應用程式的時代，對這些模型行為的研究激增。然而，由於該領域的新穎性，缺乏明確的方法論指南。這引起了對從 LLM 行為研究中獲得的見解的可複製性和概括性的擔憂。在本研究中，我們討論了複製危機的潛在風險，並通過一系列複製實驗支持我們的擔憂，這些實驗專注於據稱影響 LLM 推理能力的提示工程技術。我們在思想鏈、EmotionPrompting、ExpertPrompting、Sandbagging 以及 Re-Reading 提示工程技術上測試了 GPT-3.5、GPT-4o、Gemini 1.5 Pro、Claude 3 Opus、Llama 3-8B 和 Llama 3-70B，使用手動雙重檢查的推理基準子集，包括 CommonsenseQA、CRT、NumGLUE、ScienceQA 和 StrategyQA。我們的研究結果揭示了在幾乎所有測試技術中普遍缺乏統計學上的顯著差異，其中包括強調以前研究中存在的若干方法論弱點。我們提出了一種前瞻性的方法，包括開發用於評估 LLM 的健壯方法論、建立健全的基準以及設計嚴謹的實驗框架，以確保對模型輸出的準確且可靠的評估。

##### **PersonalLLM: Tailoring LLMs to Individual Preferences**
2409.20296v1 by Thomas P. Zollo, Andrew Wei Tung Siah, Naimeng Ye, Ang Li, Hongseok Namkoong

As LLMs become capable of complex tasks, there is growing potential for
personalized interactions tailored to the subtle and idiosyncratic preferences
of the user. We present a public benchmark, PersonalLLM, focusing on adapting
LLMs to provide maximal benefits for a particular user. Departing from existing
alignment benchmarks that implicitly assume uniform preferences, we curate
open-ended prompts paired with many high-quality answers over which users would
be expected to display heterogeneous latent preferences. Instead of
persona-prompting LLMs based on high-level attributes (e.g., user's race or
response length), which yields homogeneous preferences relative to humans, we
develop a method that can simulate a large user base with diverse preferences
from a set of pre-trained reward models. Our dataset and generated
personalities offer an innovative testbed for developing personalization
algorithms that grapple with continual data sparsity--few relevant feedback
from the particular user--by leveraging historical data from other (similar)
users. We explore basic in-context learning and meta-learning baselines to
illustrate the utility of PersonalLLM and highlight the need for future
methodological development. Our dataset is available at
https://huggingface.co/datasets/namkoong-lab/PersonalLLM

摘要：随着 LLM 能够执行复杂的任务，针对用户的微妙且独特的偏好量身定制个性化互动具有越来越大的潜力。我们提出了一个公共基准 PersonalLLM，重点是调整 LLM 以为特定用户提供最大的好处。与隐式假设统一偏好的现有对齐基准不同，我们策划了开放式提示，并配有许多高质量的答案，用户可能会对这些答案表现出异质的潜在偏好。我们没有根据高级属性（例如，用户的种族或响应长度）对 LLM 进行角色提示，这会产生相对于人类的同质偏好，而是开发了一种方法，该方法可以使用一组预先训练的奖励模型来模拟具有不同偏好的大量用户群。我们的数据集和生成的人格为开发个性化算法提供了一个创新的测试平台，该算法通过利用其他（相似）用户的历史数据来解决持续的数据稀疏性问题——来自特定用户的相关反馈很少。我们探索了基本的上下文学习和元学习基线，以说明 PersonalLLM 的效用，并强调未来方法论发展的必要性。我们的数据集可在 https://huggingface.co/datasets/namkoong-lab/PersonalLLM 获得

##### **LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models**
2409.20288v1 by Haitao Li, You Chen, Qingyao Ai, Yueyue Wu, Ruizhe Zhang, Yiqun Liu

Large language models (LLMs) have made significant progress in natural
language processing tasks and demonstrate considerable potential in the legal
domain. However, legal applications demand high standards of accuracy,
reliability, and fairness. Applying existing LLMs to legal systems without
careful evaluation of their potential and limitations could pose significant
risks in legal practice. To this end, we introduce a standardized comprehensive
Chinese legal benchmark LexEval. This benchmark is notable in the following
three aspects: (1) Ability Modeling: We propose a new taxonomy of legal
cognitive abilities to organize different tasks. (2) Scale: To our knowledge,
LexEval is currently the largest Chinese legal evaluation dataset, comprising
23 tasks and 14,150 questions. (3) Data: we utilize formatted existing
datasets, exam datasets and newly annotated datasets by legal experts to
comprehensively evaluate the various capabilities of LLMs. LexEval not only
focuses on the ability of LLMs to apply fundamental legal knowledge but also
dedicates efforts to examining the ethical issues involved in their
application. We evaluated 38 open-source and commercial LLMs and obtained some
interesting findings. The experiments and findings offer valuable insights into
the challenges and potential solutions for developing Chinese legal systems and
LLM evaluation pipelines. The LexEval dataset and leaderboard are publicly
available at \url{https://github.com/CSHaitao/LexEval} and will be continuously
updated.

摘要：大型語言模型 (LLM) 在自然語言處理任務方面取得了重大進展，並在法律領域展現了巨大的潛力。然而，法律應用要求極高的準確性、可靠性和公平性。在未仔細評估其潛力和限制的情況下將現有的 LLM 應用於法律系統，可能會在法律實務中造成重大風險。為此，我們引入了標準化的綜合中文法律基準 LexEval。此基準在以下三個方面值得注意：(1) 能力建模：我們提出了一種新的法律認知能力分類法，以組織不同的任務。(2) 規模：據我們所知，LexEval 目前是最大的中文法律評估資料集，包含 23 項任務和 14,150 個問題。(3) 資料：我們利用法律專家格式化的現有資料集、考試資料集和新註解資料集，以全面評估 LLM 的各種能力。LexEval 不僅專注於 LLM 應用基本法律知識的能力，還致力於審查其應用中涉及的倫理問題。我們評估了 38 個開源和商業 LLM，並獲得了一些有趣的發現。這些實驗和發現為開發中文法律系統和 LLM 評估管道提供了寶貴的見解。LexEval 資料集和排行榜公開於 \url{https://github.com/CSHaitao/LexEval}，並將持續更新。

##### **Computer-mediated therapies for stroke rehabilitation: a systematic review and meta-Analysis**
2409.20260v1 by Stanley Mugisha. Mirko Job. Matteo Zoppi, Marco Testa, Rezia Molfino

OBJECTIVE: To evaluate the efficacy of different forms of virtual reality
(VR) treatments as either immersive virtual reality (IVR) or non-immersive
virtual reality (NIVR) in comparison to conventional therapy (CT) in improving
physical and psychological status among stroke patients. METHODS: The
literature search was conducted on seven databases. ACM Digital Library,
Medline (via PubMed), Cochrane, IEEE Xplore, Web of Science, and Scopus. The
effect sizes of the main outcomes were calculated using Cohen's d. Pooled
results were used to present an overall estimate of the treatment effect using
a random-effects model. RESULTS: A total of 22 randomized controlled trials
were evaluated. 3 trials demonstrated that immersive virtual reality improved
upper limb activity, function and activity of daily life in a way comparable to
CT. 18 trials showed that NIVR had similar benefits to CT for upper limb
activity and function, balance and mobility, activities of daily living and
participation. A comparison between the different forms of VR showed that IVR
may be more beneficial than NIVR for upper limb training and activities of
daily life. CONCLUSIONS: This study found out that IVR therapies may be more
effective than NIVR but not CT to improve upper limb activity, function, and
daily life activities. However, there is no evidence of the durability of IVR
treatment. More research involving studies with larger samples is needed to
assess the long-term effects and promising benefits of immersive virtual
reality technology.

摘要：目標：評估不同形式的虛擬實境 (VR) 治療，例如沉浸式虛擬實境 (IVR) 或非沉浸式虛擬實境 (NIVR)，與傳統療法 (CT) 相比，在改善中風患者的身體和心理狀態方面的功效。方法：在七個資料庫中進行文獻搜尋。ACM 數位圖書館、Medline（透過 PubMed）、Cochrane、IEEE Xplore、Web of Science 和 Scopus。使用 Cohen's d 計算主要結果的效應值。匯總結果用於使用隨機效應模型呈現治療效果的整體估計。結果：總共評估了 22 項隨機對照試驗。3 項試驗表明，沉浸式虛擬實境改善了上肢活動、功能和日常生活活動，與 CT 相當。18 項試驗表明，NIVR 對上肢活動和功能、平衡和活動能力、日常生活活動和參與度具有與 CT 相似的益處。不同形式的 VR 之間的比較表明，IVR 可能比 NIVR 對上肢訓練和日常生活活動更有益。結論：本研究發現 IVR 治療可能比 NIVR 更有效，但不如 CT 能改善上肢活動、功能和日常生活活動。然而，沒有證據表明 IVR 治療的持久性。需要更多涉及更大樣本的研究來評估沉浸式虛擬實境技術的長期效果和有希望的益處。

##### **What is the Role of Large Language Models in the Evolution of Astronomy Research?**
2409.20252v1 by Morgan Fouesneau, Ivelina G. Momcheva, Urmila Chadayammuri, Mariia Demianenko, Antoine Dumont, Raphael E. Hviding, K. Angelique Kahle, Nadiia Pulatova, Bhavesh Rajpoot, Marten B. Scheuck, Rhys Seeburger, Dmitry Semenov, Jaime I. Villaseñor

ChatGPT and other state-of-the-art large language models (LLMs) are rapidly
transforming multiple fields, offering powerful tools for a wide range of
applications. These models, commonly trained on vast datasets, exhibit
human-like text generation capabilities, making them useful for research tasks
such as ideation, literature review, coding, drafting, and outreach. We
conducted a study involving 13 astronomers at different career stages and
research fields to explore LLM applications across diverse tasks over several
months and to evaluate their performance in research-related activities. This
work was accompanied by an anonymous survey assessing participants' experiences
and attitudes towards LLMs. We provide a detailed analysis of the tasks
attempted and the survey answers, along with specific output examples. Our
findings highlight both the potential and limitations of LLMs in supporting
research while also addressing general and research-specific ethical
considerations. We conclude with a series of recommendations, emphasizing the
need for researchers to complement LLMs with critical thinking and domain
expertise, ensuring these tools serve as aids rather than substitutes for
rigorous scientific inquiry.

摘要：ChatGPT 和其他最先進的大語言模型 (LLM) 正快速轉變多重領域，為廣泛的應用程式提供強大的工具。這些模型通常在龐大的資料集上訓練，展現出類似人類的文字生成能力，讓它們可用於研究任務，例如構思、文獻回顧、編碼、起草和外展。我們進行了一項研究，讓 13 位不同事業階段和研究領域的天文學家參與，在幾個月內探索 LLM 在不同任務中的應用，並評估它們在研究相關活動中的表現。這項工作附有一份匿名調查，評估參與者對 LLM 的經驗和態度。我們提供任務嘗試和調查答案的詳細分析，以及具體的輸出範例。我們的發現強調了 LLM 在支持研究方面的潛力和限制，同時也處理了一般性和研究特定的倫理考量。我們最後提出了一系列建議，強調研究人員需要以批判性思考和領域專業知識來補充 LLM，確保這些工具作為輔助工具，而不是嚴謹科學探究的替代品。

##### **Resource Allocation for Stable LLM Training in Mobile Edge Computing**
2409.20247v1 by Chang Liu, Jun Zhao

As mobile devices increasingly become focal points for advanced applications,
edge computing presents a viable solution to their inherent computational
limitations, particularly in deploying large language models (LLMs). However,
despite the advancements in edge computing, significant challenges remain in
efficient training and deploying LLMs due to the computational demands and data
privacy concerns associated with these models. This paper explores a
collaborative training framework that integrates mobile users with edge servers
to optimize resource allocation, thereby enhancing both performance and
efficiency. Our approach leverages parameter-efficient fine-tuning (PEFT)
methods, allowing mobile users to adjust the initial layers of the LLM while
edge servers handle the more demanding latter layers. Specifically, we
formulate a multi-objective optimization problem to minimize the total energy
consumption and delay during training. We also address the common issue of
instability in model performance by incorporating stability enhancements into
our objective function. Through novel fractional programming technique, we
achieve a stationary point for the formulated problem. Simulations demonstrate
that our method reduces the energy consumption as well as the latency, and
increases the reliability of LLMs across various mobile settings.

摘要：隨著行動裝置日益成為進階應用程式的重點，
邊緣運算為其固有的運算限制提供了可行的解決方案，特別是在部署大型語言模型 (LLM) 時。然而，儘管邊緣運算有進展，由於這些模型相關的運算需求和資料隱私問題，在訓練和部署 LLM 時仍有重大的挑戰。本文探討了一個協作訓練架構，將行動裝置使用者與邊緣伺服器整合，以最佳化資源配置，進而提升效能和效率。我們的做法利用了參數有效微調 (PEFT) 方法，讓行動裝置使用者調整 LLM 的初始層，而邊緣伺服器則處理要求較高的後續層。具體來說，我們制定了一個多目標最佳化問題，以最小化訓練期間的總能耗和延遲。我們也透過將穩定性強化納入我們的目標函數，來解決模型效能不穩定的常見問題。透過創新的分數規劃技術，我們為制定的問題達到了平穩點。模擬結果顯示，我們的做法減少了能耗和延遲，並提高了 LLM 在各種行動裝置設定中的可靠性。

##### **Analysing Zero-Shot Readability-Controlled Sentence Simplification**
2409.20246v1 by Abdullah Barayan, Jose Camacho-Collados, Fernando Alva-Manchego

Readability-controlled text simplification (RCTS) rewrites texts to lower
readability levels while preserving their meaning. RCTS models often depend on
parallel corpora with readability annotations on both source and target sides.
Such datasets are scarce and difficult to curate, especially at the sentence
level. To reduce reliance on parallel data, we explore using instruction-tuned
large language models for zero-shot RCTS. Through automatic and manual
evaluations, we examine: (1) how different types of contextual information
affect a model's ability to generate sentences with the desired readability,
and (2) the trade-off between achieving target readability and preserving
meaning. Results show that all tested models struggle to simplify sentences
(especially to the lowest levels) due to models' limitations and
characteristics of the source sentences that impede adequate rewriting. Our
experiments also highlight the need for better automatic evaluation metrics
tailored to RCTS, as standard ones often misinterpret common simplification
operations, and inaccurately assess readability and meaning preservation.

摘要：可讀性控制文本簡化 (RCTS) 會改寫文字，降低可讀性等級，同時保留其意義。RCTS 模型通常依賴於來源和目標兩側都有可讀性註解的平行語料庫。此類資料集稀少且難以整理，特別是在句子層級。為了減少對平行資料的依賴，我們探索使用指令調整的大型語言模型進行零次學習 RCTS。透過自動和手動評估，我們探討：(1) 不同類型的上下文資訊如何影響模型產生具有所需可讀性句子的能力，以及 (2) 達到目標可讀性與保留意義之間的取捨。結果顯示，所有測試模型都難以簡化句子（特別是到最低等級），原因在於模型的限制和阻礙充分改寫的來源句子特性。我們的實驗也強調需要針對 RCTS 量身打造更好的自動評估指標，因為標準指標通常會誤解常見的簡化操作，並錯誤評估可讀性和意義保留。

##### **PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling**
2409.20243v1 by Huachuan Qiu, Lizhi Ma, Zhenzhong Lan

As awareness of mental health issues grows, online counseling support
services are becoming increasingly prevalent worldwide. Detecting whether users
express suicidal ideation in text-based counseling services is crucial for
identifying and prioritizing at-risk individuals. However, the lack of
domain-specific systems to facilitate fine-grained suicide detection and
corresponding risk assessment in online counseling poses a significant
challenge for automated crisis intervention aimed at suicide prevention. In
this paper, we propose PsyGUARD, an automated system for detecting suicide
ideation and assessing risk in psychological counseling. To achieve this, we
first develop a detailed taxonomy for detecting suicide ideation based on
foundational theories. We then curate a large-scale, high-quality dataset
called PsySUICIDE for suicide detection. To evaluate the capabilities of
automated systems in fine-grained suicide detection, we establish a range of
baselines. Subsequently, to assist automated services in providing safe,
helpful, and tailored responses for further assessment, we propose to build a
suite of risk assessment frameworks. Our study not only provides an insightful
analysis of the effectiveness of automated risk assessment systems based on
fine-grained suicide detection but also highlights their potential to improve
mental health services on online counseling platforms. Code, data, and models
are available at https://github.com/qiuhuachuan/PsyGUARD.

摘要：隨著心理健康問題意識的提升，線上諮詢服務正於全球各地日益普及。在基於文字的諮詢服務中，偵測使用者是否表達出自殺意念對於辨識並優先處理有風險的個人至關重要。然而，缺乏特定領域的系統來促進精細化的自殺偵測與相應的風險評估，對旨在預防自殺的自動化危機介入構成了重大的挑戰。在本文中，我們提出 PsyGUARD，一個用於偵測自殺意念與評估心理諮詢風險的自動化系統。為達成此目標，我們首先根據基礎理論，開發出一套詳細的自殺意念偵測分類法。接著，我們策劃了一個名為 PsySUICIDE 的大規模、高品質自殺偵測資料集。為了評估自動化系統在精細化自殺偵測中的能力，我們建立了一系列的基準。隨後，為了協助自動化服務提供安全、有幫助且客製化的回應以進行進一步的評估，我們提議建構一套風險評估架構。我們的研究不僅提供了基於精細化自殺偵測的自動化風險評估系統的有效性分析，也強調了它們改善線上諮詢平台的心理健康服務的潛力。程式碼、資料和模型可於 https://github.com/qiuhuachuan/PsyGUARD 取得。

##### **Beyond Prompts: Dynamic Conversational Benchmarking of Large Language Models**
2409.20222v1 by David Castillo-Bolado, Joseph Davidson, Finlay Gray, Marek Rosa

We introduce a dynamic benchmarking system for conversational agents that
evaluates their performance through a single, simulated, and lengthy
user$\leftrightarrow$agent interaction. The interaction is a conversation
between the user and agent, where multiple tasks are introduced and then
undertaken concurrently. We context switch regularly to interleave the tasks,
which constructs a realistic testing scenario in which we assess the Long-Term
Memory, Continual Learning, and Information Integration capabilities of the
agents. Results from both proprietary and open-source Large-Language Models
show that LLMs in general perform well on single-task interactions, but they
struggle on the same tasks when they are interleaved. Notably, short-context
LLMs supplemented with an LTM system perform as well as or better than those
with larger contexts. Our benchmark suggests that there are other challenges
for LLMs responding to more natural interactions that contemporary benchmarks
have heretofore not been able to capture.

摘要：我們引進了一套動態基準系統，用於對話代理，透過單一、模擬且冗長的使用者$\leftrightarrow$代理互動，評估其效能。互動是使用者與代理之間的對話，其中會導入多項任務，然後同時進行。我們會定期切換內容，以交錯任務，建構一個實際的測試情境，在其中評估代理的長期記憶、持續學習和資訊整合能力。來自專有和開放原始碼大型語言模型的結果顯示，LLM 在單一任務互動中通常表現良好，但當任務交錯時，它們在相同任務上會遇到困難。值得注意的是，補充 LTM 系統的短內容 LLM 的表現與較大內容的 LLM 一樣好，甚至更好。我們的基準表明，LLM 在回應更自然的互動時還有其他挑戰，而當代基準迄今無法掌握這些挑戰。

##### **Divided by discipline? A systematic literature review on the quantification of online sexism and misogyny using a semi-automated approach**
2409.20204v1 by Aditi Dutta, Susan Banducci, Chico Q. Camargo

In recent years, several computational tools have been developed to detect
and identify sexism, misogyny, and gender-based hate speech, especially on
online platforms. Though these tools intend to draw on knowledge from both
social science and computer science, little is known about the current state of
research in quantifying online sexism or misogyny. Given the growing concern
over the discrimination of women in online spaces and the rise in
interdisciplinary research on capturing the online manifestation of sexism and
misogyny, a systematic literature review on the research practices and their
measures is the need of the hour. We make three main contributions: (i) we
present a semi-automated way to narrow down the search results in the different
phases of selection stage in the PRISMA flowchart; (ii) we perform a systematic
literature review of research papers that focus on the quantification and
measurement of online gender-based hate speech, examining literature from
computer science and the social sciences from 2012 to 2022; and (iii) we
identify the opportunities and challenges for measuring gender-based online
hate speech. Our findings from topic analysis suggest a disciplinary divide
between the themes of research on sexism/misogyny. With evidence-based review,
we summarise the different approaches used by the studies who have explored
interdisciplinary approaches to bridge the knowledge gap. Coupled with both the
existing literature on social science theories and computational modeling, we
provide an analysis of the benefits and shortcomings of the methodologies used.
Lastly, we discuss the challenges and opportunities for future research
dedicated to measuring online sexism and misogyny.

摘要：<paragraph>近年來，已經開發出多種計算工具來偵測和辨識性別歧視、厭女症和基於性別的仇恨言論，特別是在線上平台上。儘管這些工具旨在利用社會科學和電腦科學的知識，但對於量化網路性別歧視或厭女症的研究現況所知甚少。鑑於對網路空間中女性遭受歧視的關注日益增加，以及捕捉性別歧視和厭女症網路表現的跨領域研究興起，對於研究實務及其衡量標準進行系統性的文獻回顧是當務之急。我們提出了三個主要的貢獻：(i) 提出一個半自動化的方式，縮小 PRISMA 流程圖中選擇階段不同階段的搜尋結果；(ii) 針對網路性別仇恨言論的量化和衡量進行系統性的文獻回顧，探討 2012 年至 2022 年間電腦科學和社會科學的文獻；(iii) 找出衡量網路性別仇恨言論的機會和挑戰。我們從主題分析中發現的結果顯示，性別歧視/厭女症研究主題之間存在學科鴻溝。透過循證回顧，我們總結了研究中用於彌合知識差距的跨領域方法。結合社會科學理論和計算模型的既有文獻，我們分析了所使用方法的優點和缺點。最後，我們討論了致力於衡量網路性別歧視和厭女症的未來研究的挑戰和機會。</paragraph>

##### **AfriHuBERT: A self-supervised speech representation model for African languages**
2409.20201v1 by Jesujoba O. Alabi, Xuechen Liu, Dietrich Klakow, Junichi Yamagishi

In this work, we present AfriHuBERT, an extension of mHuBERT-147, a
state-of-the-art (SOTA) and compact self-supervised learning (SSL) model,
originally pretrained on 147 languages. While mHuBERT-147 was pretrained on 16
African languages, we expand this to cover 39 African languages through
continued pretraining on 6,500+ hours of speech data aggregated from diverse
sources, including 23 newly added languages. We evaluate AfriHuBERT on two key
speech tasks: Language Identification (LID) and Automatic Speech Recognition
(ASR) using FLEURS dataset. Our results show a +4% F1 score improvement on
average for LID and a -1.2% average Word Error Rate (WER) reduction for ASR.
Further analysis shows that ASR models trained on AfriHuBERT exhibit improved
cross-corpus generalization. Additionally, the analysis indicates that the
FLEURS have data quality limitations that may affect their suitability for
evaluating low-resource African languages, suggesting the need for better
evaluation benchmarks for these languages.

摘要：在這項工作中，我們提出了 AfriHuBERT，這是 mHuBERT-147 的延伸，一種最先進 (SOTA) 且緊湊的自監督學習 (SSL) 模型，最初在 147 種語言上進行預訓練。雖然 mHuBERT-147 在 16 種非洲語言上進行了預訓練，但我們通過在從不同來源彙集的 6,500 多小時語音數據（包括 23 種新增加的語言）上持續預訓練，將其擴展到涵蓋 39 種非洲語言。我們在兩個主要的語音任務上評估了 AfriHuBERT：語言識別 (LID) 和自動語音識別 (ASR)，使用 FLEURS 數據集。我們的結果顯示，LID 的 F1 分數平均提高了 +4%，而 ASR 的平均字元錯誤率 (WER) 降低了 -1.2%。進一步的分析表明，在 AfriHuBERT 上訓練的 ASR 模型表現出更好的跨語料庫概括性。此外，分析表明 FLEURS 存在數據品質限制，這可能會影響它們評估低資源非洲語言的適用性，這表明需要針對這些語言制定更好的評估基準。

##### **Melody Is All You Need For Music Generation**
2409.20196v1 by Shaopeng Wei, Manzhen Wei, Haoyu Wang, Yu Zhao, Gang Kou

We present the Melody Guided Music Generation (MMGen) model, the first novel
approach using melody to guide the music generation that, despite a pretty
simple method and extremely limited resources, achieves excellent performance.
Specifically, we first align the melody with audio waveforms and their
associated descriptions using the multimodal alignment module. Subsequently, we
condition the diffusion module on the learned melody representations. This
allows MMGen to generate music that matches the style of the provided audio
while also producing music that reflects the content of the given text
description. To address the scarcity of high-quality data, we construct a
multi-modal dataset, MusicSet, which includes melody, text, and audio, and will
be made publicly available. We conduct extensive experiments which demonstrate
the superiority of the proposed model both in terms of experimental metrics and
actual performance quality.

摘要：我們提出旋律引導音樂生成（MMGen）模型，這是第一個使用旋律來引導音樂生成的新穎方法，儘管方法相當簡單且資源極為有限，但仍能達到極佳的表現。具體來說，我們首先使用多模態對齊模組將旋律與音訊波形及其相關描述對齊。隨後，我們對擴散模組進行條件處理，以學習旋律表示。這讓 MMGen 能夠生成符合所提供音訊風格的音樂，同時也能產生反映給定文字描述內容的音樂。為了解決高品質資料的稀缺問題，我們建構了一個包含旋律、文字和音訊的多模態資料集 MusicSet，並將公開提供。我們進行了廣泛的實驗，證明了所提出的模型在實驗指標和實際效能品質方面都具有優越性。

##### **Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**
2409.20195v1 by Arunava Chakravarty, Taha Emre, Dmitrii Lachinov, Antoine Rivail, Hendrik Scholl, Lars Fritsche, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Ursula Schmidt-Erfurth, Hrvoje Bogunović

Predicting future disease progression risk from medical images is challenging
due to patient heterogeneity, and subtle or unknown imaging biomarkers.
Moreover, deep learning (DL) methods for survival analysis are susceptible to
image domain shifts across scanners. We tackle these issues in the task of
predicting late dry Age-related Macular Degeneration (dAMD) onset from retinal
OCT scans. We propose a novel DL method for survival prediction to jointly
predict from the current scan a risk score, inversely related to
time-to-conversion, and the probability of conversion within a time interval
$t$. It uses a family of parallel hyperplanes generated by parameterizing the
bias term as a function of $t$. In addition, we develop unsupervised losses
based on intra-subject image pairs to ensure that risk scores increase over
time and that future conversion predictions are consistent with AMD stage
prediction using actual scans of future visits. Such losses enable
data-efficient fine-tuning of the trained model on new unlabeled datasets
acquired with a different scanner. Extensive evaluation on two large datasets
acquired with different scanners resulted in a mean AUROCs of 0.82 for
Dataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24
months.

摘要：由於患者異質性以及不明顯或未知的影像生物標記，從醫學影像預測未來疾病進程風險具有挑戰性。
此外，用於存活分析的深度學習 (DL) 方法容易受到跨掃描儀的影像域轉移影響。我們在預測晚期乾性年齡相關性黃斑部病變 (dAMD) 從視網膜 OCT 掃描中發生的任務中解決這些問題。我們提出了一種新的 DL 方法，用於存活預測，以從當前掃描中共同預測風險評分，與轉換時間成反比，以及在時間間隔 $t$ 內轉換的機率。它使用一組平行超平面，這些超平面是透過將偏差項參數化為 $t$ 的函數而產生的。此外，我們根據受試者內影像對開發無監督損失，以確保風險評分隨著時間增加，並且未來的轉換預測與使用未來就診實際掃描的 AMD 階段預測一致。此類損失能夠對使用不同掃描儀取得的新未標籤資料集進行資料有效微調訓練模型。對使用不同掃描儀取得的兩個大型資料集進行廣泛評估，在 6、12 和 24 個月的預測區間內，資料集 1 的平均 AUROC 為 0.82，資料集 2 的平均 AUROC 為 0.83。

##### **Factory Operators' Perspectives on Cognitive Assistants for Knowledge Sharing: Challenges, Risks, and Impact on Work**
2409.20192v1 by Samuel Kernan Freire, Tianhao He, Chaofan Wang, Evangelos Niforatos, Alessandro Bozzon

In the shift towards human-centered manufacturing, our two-year longitudinal
study investigates the real-world impact of deploying Cognitive Assistants
(CAs) in factories. The CAs were designed to facilitate knowledge sharing among
factory operators. Our investigation focused on smartphone-based voice
assistants and LLM-powered chatbots, examining their usability and utility in a
real-world factory setting. Based on the qualitative feedback we collected
during the deployments of CAs at the factories, we conducted a thematic
analysis to investigate the perceptions, challenges, and overall impact on
workflow and knowledge sharing.
  Our results indicate that while CAs have the potential to significantly
improve efficiency through knowledge sharing and quicker resolution of
production issues, they also introduce concerns around workplace surveillance,
the types of knowledge that can be shared, and shortcomings compared to
human-to-human knowledge sharing. Additionally, our findings stress the
importance of addressing privacy, knowledge contribution burdens, and tensions
between factory operators and their managers.

摘要：在以人为本的制造业转型中，我们的两年纵向研究调查了在工厂部署认知助理 (CA) 的实际影响。CA 被设计为促进工厂操作员之间的知识共享。我们的调查重点关注基于智能手机的语音助手和 LLM 驱动的聊天机器人，考察了它们在真实工厂环境中的可用性和实用性。基于我们在工厂部署 CA 期间收集的定性反馈，我们进行了主题分析来调查对工作流程和知识共享的看法、挑战和总体影响。
我们的结果表明，虽然 CA 有可能通过知识共享和更快速地解决生产问题来显着提高效率，但它们也引发了对工作场所监控、可共享的知识类型以及与人际知识共享相比的不足的担忧。此外，我们的研究结果强调了解决隐私、知识贡献负担以及工厂操作员与其经理之间的紧张关系的重要性。

##### **TaskComplexity: A Dataset for Task Complexity Classification with In-Context Learning, FLAN-T5 and GPT-4o Benchmarks**
2409.20189v1 by Areeg Fahad Rasheed, M. Zarkoosh, Safa F. Abbas, Sana Sabah Al-Azzawi

This paper addresses the challenge of classifying and assigning programming
tasks to experts, a process that typically requires significant effort, time,
and cost. To tackle this issue, a novel dataset containing a total of 4,112
programming tasks was created by extracting tasks from various websites. Web
scraping techniques were employed to collect this dataset of programming
problems systematically. Specific HTML tags were tracked to extract key
elements of each issue, including the title, problem description, input-output,
examples, problem class, and complexity score. Examples from the dataset are
provided in the appendix to illustrate the variety and complexity of tasks
included. The dataset's effectiveness has been evaluated and benchmarked using
two approaches; the first approach involved fine-tuning the FLAN-T5 small model
on the dataset, while the second approach used in-context learning (ICL) with
the GPT-4o mini. The performance was assessed using standard metrics: accuracy,
recall, precision, and F1-score. The results indicated that in-context learning
with GPT-4o-mini outperformed the FLAN-T5 model.

摘要：本論文探討了對程式設計任務進行分類和指派給專家的挑戰，這是一個通常需要大量精力、時間和成本的過程。為了解決這個問題，建立了一個包含總共 4,112 個程式設計任務的新穎資料集，方法是從各種網站中擷取任務。使用網頁擷取技術系統地收集這個程式設計問題資料集。追蹤特定的 HTML 標籤，以擷取每個問題的關鍵元素，包括標題、問題說明、輸入輸出、範例、問題類別和複雜度分數。資料集中的範例在附錄中提供，以說明所包含任務的多樣性和複雜性。資料集的有效性已使用兩種方法進行評估和基準測試；第一種方法涉及在資料集上微調 FLAN-T5 小型模型，而第二種方法使用 GPT-4o mini 的情境內學習 (ICL)。使用標準指標評估效能：準確度、召回率、精確度和 F1 分數。結果表明，使用 GPT-4o-mini 的情境內學習優於 FLAN-T5 模型。

##### **Choosing DAG Models Using Markov and Minimal Edge Count in the Absence of Ground Truth**
2409.20187v1 by Joseph D. Ramsey, Bryan Andrews, Peter Spirtes

We give a novel nonparametric pointwise consistent statistical test (the
Markov Checker) of the Markov condition for directed acyclic graph (DAG) or
completed partially directed acyclic graph (CPDAG) models given a dataset. We
also introduce the Cross-Algorithm Frugality Search (CAFS) for rejecting DAG
models that either do not pass the Markov Checker test or that are not edge
minimal. Edge minimality has been used previously by Raskutti and Uhler as a
nonparametric simplicity criterion, though CAFS readily generalizes to other
simplicity conditions. Reference to the ground truth is not necessary for CAFS,
so it is useful for finding causal structure learning algorithms and tuning
parameter settings that output causal models that are approximately true from a
given data set. We provide a software tool for this analysis that is suitable
for even quite large or dense models, provided a suitably fast pointwise
consistent test of conditional independence is available. In addition, we show
in simulation that the CAFS procedure can pick approximately correct models
without knowing the ground truth.

摘要：我們提供了一個新穎的非參數點態一致性統計檢定（馬可夫檢驗器），用於有向非循環圖（DAG）或已完成的部分有向非循環圖（CPDAG）模型的馬可夫條件，給定一個資料集。我們還引入了交叉演算法節儉搜尋（CAFS），用於拒絕未通過馬可夫檢驗器檢定或邊緣非最小的 DAG 模型。邊緣最少性先前已被 Raskutti 和 Uhler 用作非參數簡潔性準則，儘管 CAFS 很容易概括到其他簡潔性條件。CAFS 不需要參考真實情況，因此對於尋找因果結構學習演算法和調整參數設定很有用，這些參數設定會從給定的資料集輸出近似真實的因果模型。我們提供了一個適用於相當大或密集模型的軟體工具，只要有適當的條件獨立點態一致性檢定可用即可。此外，我們在模擬中顯示，CAFS 程序可以在不知道真實情況下挑選近似正確的模型。

##### **Reference Trustable Decoding: A Training-Free Augmentation Paradigm for Large Language Models**
2409.20181v1 by Luohe Shi, Yao Yao, Zuchao Li, Lefei Zhang, Hai Zhao

Large language models (LLMs) have rapidly advanced and demonstrated
impressive capabilities. In-Context Learning (ICL) and Parameter-Efficient
Fine-Tuning (PEFT) are currently two mainstream methods for augmenting LLMs to
downstream tasks. ICL typically constructs a few-shot learning scenario, either
manually or by setting up a Retrieval-Augmented Generation (RAG) system,
helping models quickly grasp domain knowledge or question-answering patterns
without changing model parameters. However, this approach involves trade-offs,
such as slower inference speed and increased space occupancy. PEFT assists the
model in adapting to tasks through minimal parameter modifications, but the
training process still demands high hardware requirements, even with a small
number of parameters involved. To address these challenges, we propose
Reference Trustable Decoding (RTD), a paradigm that allows models to quickly
adapt to new tasks without fine-tuning, maintaining low inference costs. RTD
constructs a reference datastore from the provided training examples and
optimizes the LLM's final vocabulary distribution by flexibly selecting
suitable references based on the input, resulting in more trustable responses
and enabling the model to adapt to downstream tasks at a low cost. Experimental
evaluations on various LLMs using different benchmarks demonstrate that RTD
establishes a new paradigm for augmenting models to downstream tasks.
Furthermore, our method exhibits strong orthogonality with traditional methods,
allowing for concurrent usage.

摘要：大型語言模型 (LLM) 已快速進步並展現出令人印象深刻的能力。情境學習 (ICL) 和參數高效微調 (PEFT) 目前是擴充 LLM 以執行下游任務的兩種主流方法。ICL 通常會建構一個小樣本學習情境，可以手動或透過設定檢索擴充生成 (RAG) 系統來執行，協助模型快速掌握領域知識或問答模式，而無需變更模型參數。然而，這種方法會涉及取捨，例如推論速度變慢和空間佔用量增加。PEFT 協助模型透過最少的參數修改來適應任務，但訓練過程仍需要很高的硬體需求，即使涉及的參數數量很少。為了應對這些挑戰，我們提出參考可信解碼 (RTD)，這是一種典範，讓模型能夠快速適應新任務，而無需微調，並維持低推論成本。RTD 從提供的訓練範例建構參考資料儲存庫，並透過根據輸入靈活地選擇合適的參考來最佳化 LLM 的最終詞彙分佈，進而產生更可信的回應，並讓模型能夠以低成本適應下游任務。使用不同基準對各種 LLM 進行的實驗評估顯示，RTD 為擴充模型以執行下游任務建立了一個新的典範。此外，我們的方法展現出與傳統方法的強大正交性，允許同時使用。

##### **Modelando procesos cognitivos de la lectura natural con GPT-2**
2409.20174v1 by Bruno Bianchi, Alfredo Umfurer, Juan Esteban Kamienkowski

The advancement of the Natural Language Processing field has enabled the
development of language models with a great capacity for generating text. In
recent years, Neuroscience has been using these models to better understand
cognitive processes. In previous studies, we found that models like Ngrams and
LSTM networks can partially model Predictability when used as a co-variable to
explain readers' eye movements. In the present work, we further this line of
research by using GPT-2 based models. The results show that this architecture
achieves better outcomes than its predecessors.

摘要：自然語言處理領域的進步使得開發出具有巨大文本生成能力的語言模型成為可能。近年來，神經科學一直在使用這些模型來更好地理解認知過程。在先前的研究中，我們發現 Ngrams 和 LSTM 網路等模型可用作協變數來解釋讀者的眼球運動時，可以部分地模擬可預測性。在目前的工作中，我們通過使用基於 GPT-2 的模型進一步推進了這條研究路線。結果表明，這種架構比其前身取得了更好的成果。

##### **Using Large Multimodal Models to Extract Knowledge Components for Knowledge Tracing from Multimedia Question Information**
2409.20167v1 by Hyeongdon Moon, Richard Davis, Seyed Parsa Neshaei, Pierre Dillenbourg

Knowledge tracing models have enabled a range of intelligent tutoring systems
to provide feedback to students. However, existing methods for knowledge
tracing in learning sciences are predominantly reliant on statistical data and
instructor-defined knowledge components, making it challenging to integrate
AI-generated educational content with traditional established methods. We
propose a method for automatically extracting knowledge components from
educational content using instruction-tuned large multimodal models. We
validate this approach by comprehensively evaluating it against knowledge
tracing benchmarks in five domains. Our results indicate that the automatically
extracted knowledge components can effectively replace human-tagged labels,
offering a promising direction for enhancing intelligent tutoring systems in
limited-data scenarios, achieving more explainable assessments in educational
settings, and laying the groundwork for automated assessment.

摘要：知識追蹤模型讓一系列智慧教學系統能為學生提供回饋。然而，現有的知識追蹤方法在學習科學中主要依賴統計資料和由教師定義的知識成分，這使得將 AI 生成的教育內容與傳統既定方法整合起來具有挑戰性。我們提出了一種方法，使用針對教學調整過的大多模態模型從教育內容中自動提取知識成分。我們透過在五個領域的知識追蹤基準對其進行全面評估，驗證了這種方法。我們的結果表明，自動提取的知識成分可以有效取代人工標記的標籤，為在資料有限的情況下增強智慧教學系統、在教育環境中實現更具說明性的評量，以及為自動化評量奠定基礎提供了有希望的方向。

##### **How Entangled is Factuality and Deception in German?**
2409.20165v1 by Aswathy Velutharambath, Amelie Wührl, Roman Klinger

The statement "The earth is flat" is factually inaccurate, but if someone
truly believes and argues in its favor, it is not deceptive. Research on
deception detection and fact checking often conflates factual accuracy with the
truthfulness of statements. This assumption makes it difficult to (a) study
subtle distinctions and interactions between the two and (b) gauge their
effects on downstream tasks. The belief-based deception framework disentangles
these properties by defining texts as deceptive when there is a mismatch
between what people say and what they truly believe. In this study, we assess
if presumed patterns of deception generalize to German language texts. We test
the effectiveness of computational models in detecting deception using an
established corpus of belief-based argumentation. Finally, we gauge the impact
of deception on the downstream task of fact checking and explore if this
property confounds verification models. Surprisingly, our analysis finds no
correlation with established cues of deception. Previous work claimed that
computational models can outperform humans in deception detection accuracy,
however, our experiments show that both traditional and state-of-the-art models
struggle with the task, performing no better than random guessing. For fact
checking, we find that Natural Language Inference-based verification performs
worse on non-factual and deceptive content, while prompting Large Language
Models for the same task is less sensitive to these properties.

摘要：「地球是平的」這句話在事實上是不正確的，但如果有人真的相信並主張它的正確性，這並非欺騙。關於欺騙偵測和事實查核的研究，經常將事實正確性與陳述的真實性混為一談。這個假設使得（a）難以研究兩者之間的細微差異和交互作用，以及（b）衡量它們對下游任務的影響。基於信念的欺騙框架，透過定義在人們所說的話與他們真正相信的事情之間存在不匹配時，將這些屬性區分開來。在這項研究中，我們評估了欺騙的假定模式是否能推廣到德語文本。我們使用既定的基於信念的論證語料庫，測試了計算模型在偵測欺騙方面的有效性。最後，我們衡量了欺騙對事實查核下游任務的影響，並探討這個屬性是否會混淆驗證模型。令人驚訝的是，我們的分析沒有發現與既定的欺騙線索相關。先前的研究聲稱計算模型在欺騙偵測的準確性上可以優於人類，然而，我們的實驗顯示傳統和最先進的模型在這個任務上都表現不佳，表現不比隨機猜測好。對於事實查核，我們發現基於自然語言推論的驗證在非事實和欺騙性內容上表現較差，而提示大型語言模型執行相同的任務，對這些屬性較不敏感。

##### **MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants**
2409.20163v1 by Zeyu Zhang, Quanyu Dai, Luyu Chen, Zeren Jiang, Rui Li, Jieming Zhu, Xu Chen, Yi Xie, Zhenhua Dong, Ji-Rong Wen

LLM-based agents have been widely applied as personal assistants, capable of
memorizing information from user messages and responding to personal queries.
However, there still lacks an objective and automatic evaluation on their
memory capability, largely due to the challenges in constructing reliable
questions and answers (QAs) according to user messages. In this paper, we
propose MemSim, a Bayesian simulator designed to automatically construct
reliable QAs from generated user messages, simultaneously keeping their
diversity and scalability. Specifically, we introduce the Bayesian Relation
Network (BRNet) and a causal generation mechanism to mitigate the impact of LLM
hallucinations on factual information, facilitating the automatic creation of
an evaluation dataset. Based on MemSim, we generate a dataset in the daily-life
scenario, named MemDaily, and conduct extensive experiments to assess the
effectiveness of our approach. We also provide a benchmark for evaluating
different memory mechanisms in LLM-based agents with the MemDaily dataset. To
benefit the research community, we have released our project at
https://github.com/nuster1128/MemSim.

摘要：基於 LLM 的代理已廣泛用作個人助理，能夠記住使用者訊息中的資訊並回應個人查詢。然而，由於在根據使用者訊息建構可靠的問題和解答 (QA) 時面臨挑戰，因此仍缺乏對其記憶能力的客觀且自動化的評估。在本文中，我們提出 MemSim，這是一個貝氏模擬器，旨在從產生的使用者訊息中自動建構可靠的 QA，同時保持其多樣性和可擴充性。具體來說，我們引入了貝氏關係網路 (BRNet) 和因果生成機制，以減輕 LLM 幻覺對事實資訊的影響，促進自動建立評估資料集。基於 MemSim，我們在日常生活場景中產生了一個名為 MemDaily 的資料集，並進行廣泛的實驗以評估我們方法的有效性。我們還提供了使用 MemDaily 資料集評估 LLM 基礎代理中不同記憶機制的基準。為了造福研究社群，我們已在 https://github.com/nuster1128/MemSim 上發布了我們的專案。

##### **1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data Sharing and Compensation in Large Language Models**
2409.20149v1 by Chanjun Park, Hyunsoo Ha, Jihoo Kim, Yungi Kim, Dahyun Kim, Sukyung Lee, Seonghoon Yang

In this paper, we propose the 1 Trillion Token Platform (1TT Platform), a
novel framework designed to facilitate efficient data sharing with a
transparent and equitable profit-sharing mechanism. The platform fosters
collaboration between data contributors, who provide otherwise non-disclosed
datasets, and a data consumer, who utilizes these datasets to enhance their own
services. Data contributors are compensated in monetary terms, receiving a
share of the revenue generated by the services of the data consumer. The data
consumer is committed to sharing a portion of the revenue with contributors,
according to predefined profit-sharing arrangements. By incorporating a
transparent profit-sharing paradigm to incentivize large-scale data sharing,
the 1TT Platform creates a collaborative environment to drive the advancement
of NLP and LLM technologies.

摘要：在本文中，我們提出了 1 兆個代幣平台 (1TT 平台)，這是一個新穎的框架，旨在透過透明且公平的利潤分享機制促進資料共享效率。該平台促進資料貢獻者（提供原本不會公開的資料集）與資料使用者（利用這些資料集來提升其自身服務）之間的合作。資料貢獻者會獲得金錢補償，並從資料使用者服務產生的收益中獲得一部分利潤。資料使用者承諾根據預先定義的利潤分享安排，與貢獻者分享部分收益。透過納入透明的利潤分享模式以激勵大規模資料共享，1TT 平台創造了一個協作環境，以推動 NLP 和 LLM 技術的進步。

##### **Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**
2409.20147v1 by Vincent Beliveau, Helene Kaas, Martin Prener, Claes N. Ladefoged, Desmond Elliott, Gitte M. Knudsen, Lars H. Pinborg, Melanie Ganz

Natural language processing (NLP) in the medical domain can underperform in
real-world applications involving small datasets in a non-English language with
few labeled samples and imbalanced classes. There is yet no consensus on how to
approach this problem. We evaluated a set of NLP models including BERT-like
transformers, few-shot learning with sentence transformers (SetFit), and
prompted large language models (LLM), using three datasets of radiology reports
on magnetic resonance images of epilepsy patients in Danish, a low-resource
language. Our results indicate that BERT-like models pretrained in the target
domain of radiology reports currently offer the optimal performances for this
scenario. Notably, the SetFit and LLM models underperformed compared to
BERT-like models, with LLM performing the worst. Importantly, none of the
models investigated was sufficiently accurate to allow for text classification
without any supervision. However, they show potential for data filtering, which
could reduce the amount of manual labeling required.

摘要：自然語言處理 (NLP) 在醫療領域中，在涉及非英語語言中小型資料集、標記樣本少和類別不平衡的實際應用中表現不佳。對於如何解決這個問題，目前尚未達成共識。我們使用三組丹麥語癲癇患者磁共振影像的放射報告資料集，評估了一組 NLP 模型，包括類 BERT 轉換器、使用句子轉換器 (SetFit) 的少樣本學習，以及提示的大型語言模型 (LLM)。我們的結果表明，目前在放射報告目標領域中預訓練的類 BERT 模型為此情境提供最佳效能。值得注意的是，與類 BERT 模型相比，SetFit 和 LLM 模型表現不佳，而 LLM 表現最差。重要的是，所研究的模型中沒有一個足夠準確，可以在沒有任何監督的情況下進行文字分類。然而，它們顯示出資料過濾的潛力，這可以減少所需的手動標記量。

##### **Federated Instruction Tuning of LLMs with Domain Coverage Augmentation**
2409.20135v2 by Zezhou Wang, Yaxin Du, Zhuzhong Qian, Siheng Chen

Federated Domain-specific Instruction Tuning (FedDIT) utilizes limited
cross-client private data alongside server-side public data for instruction
augmentation, ultimately enhancing model performance within specific domains.
While the factors affecting FedDIT remain unclear and existing instruction
augmentation methods mainly focus on the centralized setting without
considering the distributed environment. Our experiments reveal that the
cross-client domain coverage, rather than data heterogeneity, drives model
performance in FedDIT. In response, we propose FedDCA, which optimizes domain
coverage through greedy client center selection and retrieval-based
augmentation. To alleviate client-side computational burdens, FedDCA$^*$ uses
heterogeneous encoders with server-side feature alignment. Extensive
experiments across four distinct domains (code, medical, financial, and
mathematical) substantiate the effectiveness of both methods. Additionally, we
investigate privacy preservation against memory extraction attacks utilizing
varying amounts of public data. Results show no significant correlation between
the volume of public data and the privacy-preserving capability. However, as
the fine-tuning round increases, the risk of privacy leakage reduces or
converges.

摘要：聯邦領域特定指令調整 (FedDIT) 利用有限的跨用戶端私人數據以及伺服器端的公開數據進行指令擴充，最終增強特定領域內的模型效能。雖然影響 FedDIT 的因素仍不明確，現有的指令擴充方法主要著重於集中式設定，而未考慮分散式環境。我們的實驗顯示，跨用戶端領域涵蓋範圍，而非數據異質性，驅動了 FedDIT 中的模型效能。為此，我們提出 FedDCA，它透過貪婪用戶端中心選擇和基於檢索的擴充，最佳化領域涵蓋範圍。為了減輕用戶端端的運算負擔，FedDCA$^*$ 使用具有伺服器端特徵比對的異質編碼器。跨越四個不同領域（程式碼、醫療、金融和數學）的廣泛實驗證實了這兩種方法的有效性。此外，我們針對利用不同量公開數據的記憶體提取攻擊調查隱私保護。結果顯示公開數據量與隱私保護能力之間沒有顯著相關性。然而，隨著微調回合數增加，隱私洩漏的風險會降低或收斂。

##### **ACE: Abstractions for Communicating Efficiently**
2409.20120v1 by Jonathan D. Thomas, Andrea Silvi, Devdatt Dubhashi, Vikas Garg, Moa Johansson

A central but unresolved aspect of problem-solving in AI is the capability to
introduce and use abstractions, something humans excel at. Work in cognitive
science has demonstrated that humans tend towards higher levels of abstraction
when engaged in collaborative task-oriented communication, enabling gradually
shorter and more information-efficient utterances. Several computational
methods have attempted to replicate this phenomenon, but all make unrealistic
simplifying assumptions about how abstractions are introduced and learned. Our
method, Abstractions for Communicating Efficiently (ACE), overcomes these
limitations through a neuro-symbolic approach. On the symbolic side, we draw on
work from library learning for proposing abstractions. We combine this with
neural methods for communication and reinforcement learning, via a novel use of
bandit algorithms for controlling the exploration and exploitation trade-off in
introducing new abstractions. ACE exhibits similar tendencies to humans on a
collaborative construction task from the cognitive science literature, where
one agent (the architect) instructs the other (the builder) to reconstruct a
scene of block-buildings. ACE results in the emergence of an efficient language
as a by-product of collaborative communication. Beyond providing mechanistic
insights into human communication, our work serves as a first step to providing
conversational agents with the ability for human-like communicative
abstractions.

摘要：問題解決在 AI 中一個核心但尚未解決的面向是抽象化的引入和使用能力，這是人類擅長的事情。認知科學中的研究已證明，當人類從事協作任務導向溝通時，會傾向於較高層級的抽象化，這使得話語逐漸簡短且更具資訊效率。有幾種運算方法已嘗試複製此現象，但全部都對抽象化是如何引入和學習的做出不切實際的簡化假設。我們的抽象化有效溝通 (ACE) 方法透過神經符號方法克服了這些限制。在符號方面，我們利用來自程式庫學習的成果來提出抽象化。我們將此與神經方法結合起來，用於溝通和強化學習，透過一種新穎的強盜演算法使用方式來控制在引入新抽象化時探索和利用的權衡。ACE 在認知科學文獻中的一項協作建構任務中展現出與人類相似的傾向，在該任務中，一個代理人（建築師）指示另一個代理人（建造者）重建一個積木建築場景。ACE 導致一種有效語言的出現，作為協作溝通的副產品。除了提供人類溝通的機制見解外，我們的研究還作為提供對話代理人具有人類式溝通抽象化能力的第一步。

##### **Aggressive Post-Training Compression on Extremely Large Language Models**
2409.20094v1 by Zining Zhang, Yao Chen, Bingsheng He, Zhenjie Zhang

The increasing size and complexity of Large Language Models (LLMs) pose
challenges for their deployment on personal computers and mobile devices.
Aggressive post-training model compression is necessary to reduce the models'
size, but it often results in significant accuracy loss. To address this
challenge, we propose a novel network pruning technology that utilizes over 0.7
sparsity and less than 8 bits of quantization. Our approach enables the
compression of prevailing LLMs within a couple of hours while maintaining a
relatively small accuracy loss. In experimental evaluations, our method
demonstrates effectiveness and potential for practical deployment. By making
LLMs available on domestic devices, our work can facilitate a new era of
natural language processing applications with wide-ranging impacts.

摘要：大型語言模型 (LLM) 的規模和複雜性日益增加，對其在個人電腦和行動裝置上的部署構成挑戰。積極的訓練後模型壓縮對於縮小模型的規模是必要的，但它通常會導致顯著的準確性損失。為了應對這一挑戰，我們提出了一種新穎的網路修剪技術，它利用超過 0.7 的稀疏性和不到 8 位元的量化。我們的做法可以在幾個小時內壓縮主流的 LLM，同時保持相對較小的準確性損失。在實驗評估中，我們的模型證明了其在實際部署中的有效性和潛力。透過讓 LLM 可用於家用裝置，我們的研究可以促進自然語言處理應用程式的新時代，並產生廣泛的影響。

##### **Robust LLM safeguarding via refusal feature adversarial training**
2409.20089v1 by Lei Yu, Virginie Do, Karen Hambardzumyan, Nicola Cancedda

Large language models (LLMs) are vulnerable to adversarial attacks that can
elicit harmful responses. Defending against such attacks remains challenging
due to the opacity of jailbreaking mechanisms and the high computational cost
of training LLMs robustly. We demonstrate that adversarial attacks share a
universal mechanism for circumventing LLM safeguards that works by ablating a
dimension in the residual stream embedding space called the refusal feature. We
further show that the operation of refusal feature ablation (RFA) approximates
the worst-case perturbation of offsetting model safety. Based on these
findings, we propose Refusal Feature Adversarial Training (ReFAT), a novel
algorithm that efficiently performs LLM adversarial training by simulating the
effect of input-level attacks via RFA. Experiment results show that ReFAT
significantly improves the robustness of three popular LLMs against a wide
range of adversarial attacks, with considerably less computational overhead
compared to existing adversarial training methods.

摘要：大型語言模型 (LLM) 容易受到對抗性攻擊，這些攻擊會引發有害的回應。由於越獄機制的不透明性以及訓練穩健的 LLM 的高運算成本，防禦此類攻擊仍然具有挑戰性。我們證明對抗性攻擊共用一種通用機制來規避 LLM 保障措施，這種機制通過消融殘差串流嵌入空間中稱為拒絕特徵的維度來運作。我們進一步表明，拒絕特徵消融 (RFA) 的操作近似於抵消模型安全性的最壞情況擾動。基於這些發現，我們提出了拒絕特徵對抗性訓練 (ReFAT)，這是一種新穎的演算法，通過 RFA 模擬輸入級別攻擊的影響，有效地執行 LLM 對抗性訓練。實驗結果表明，與現有的對抗性訓練方法相比，ReFAT 大幅提高了三種流行的 LLM 對各種對抗性攻擊的穩健性，且運算負擔顯著降低。

##### **BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain**
2409.20075v1 by Kaisi Guan, Qian Cao, Yuchong Sun, Xiting Wang, Ruihua Song

Retrieval Augmented Generation (RAG) system is important in domains such as
e-commerce, which has many long-tail entities and frequently updated
information. Most existing works adopt separate modules for retrieval and
generation, which may be suboptimal since the retrieval task and the generation
task cannot benefit from each other to improve performance. We propose a novel
Backbone Shared RAG framework (BSharedRAG). It first uses a domain-specific
corpus to continually pre-train a base model as a domain-specific backbone
model and then trains two plug-and-play Low-Rank Adaptation (LoRA) modules
based on the shared backbone to minimize retrieval and generation losses
respectively. Experimental results indicate that our proposed BSharedRAG
outperforms baseline models by 5% and 13% in Hit@3 upon two datasets in
retrieval evaluation and by 23% in terms of BLEU-3 in generation evaluation.
Our codes, models, and dataset are available at https://bsharedrag.github.io.

摘要：擷取增強生成（RAG）系統在電子商務等領域中非常重要，電子商務有許多長尾實體和經常更新的資訊。大多數現有作品採用獨立模組進行擷取和生成，這可能是次佳方案，因為擷取任務和生成任務無法互相受益以改善效能。我們提出了一種新穎的 Backbone 共享 RAG 架構（BSharedRAG）。它首先使用特定領域的語料庫持續預訓練基礎模型作為特定領域的 Backbone 模型，然後根據共享 Backbone 訓練兩個即插即用的低階適應（LoRA）模組，以分別最小化擷取和生成損失。實驗結果表明，我們提出的 BSharedRAG 在擷取評估中，於兩個資料集的 Hit@3 中優於基準模型 5% 和 13%，在生成評估中，以 BLEU-3 而言優於基準模型 23%。我們的程式碼、模型和資料集可在 https://bsharedrag.github.io/ 取得。

##### **Knowledge Discovery using Unsupervised Cognition**
2409.20064v1 by Alfredo Ibias, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart

Knowledge discovery is key to understand and interpret a dataset, as well as
to find the underlying relationships between its components. Unsupervised
Cognition is a novel unsupervised learning algorithm that focus on modelling
the learned data. This paper presents three techniques to perform knowledge
discovery over an already trained Unsupervised Cognition model. Specifically,
we present a technique for pattern mining, a technique for feature selection
based on the previous pattern mining technique, and a technique for
dimensionality reduction based on the previous feature selection technique. The
final goal is to distinguish between relevant and irrelevant features and use
them to build a model from which to extract meaningful patterns. We evaluated
our proposals with empirical experiments and found that they overcome the
state-of-the-art in knowledge discovery.

摘要：知識發現是了解和詮釋資料集的關鍵，以及找出其組成部分之間的基礎關係。無監督認知是一種新穎的無監督學習演算法，專注於對學習到的資料進行建模。本文提出了三種技術，以對已訓練好的無監督認知模型執行知識發現。具體來說，我們提出了一種模式探勘技術、一種基於先前模式探勘技術的特徵選取技術，以及一種基於先前特徵選取技術的降維技術。最終目標是區分相關和無關特徵，並使用它們來建立一個模型，從中提取有意義的模式。我們使用經驗實驗評估了我們的提案，發現它們克服了知識發現的最新技術。

##### **Is Preference Alignment Always the Best Option to Enhance LLM-Based Translation? An Empirical Analysis**
2409.20059v1 by Hippolyte Gisserot-Boukhlef, Ricardo Rei, Emmanuel Malherbe, Céline Hudelot, Pierre Colombo, Nuno M. Guerreiro

Neural metrics for machine translation (MT) evaluation have become
increasingly prominent due to their superior correlation with human judgments
compared to traditional lexical metrics. Researchers have therefore utilized
neural metrics through quality-informed decoding strategies, achieving better
results than likelihood-based methods. With the rise of Large Language Models
(LLMs), preference-based alignment techniques have gained attention for their
potential to enhance translation quality by optimizing model weights directly
on preferences induced by quality estimators. This study focuses on Contrastive
Preference Optimization (CPO) and conducts extensive experiments to evaluate
the impact of preference-based alignment on translation quality. Our findings
indicate that while CPO consistently outperforms Supervised Fine-Tuning (SFT)
on high-quality data with regard to the alignment metric, it may lead to
instability across downstream evaluation metrics, particularly between neural
and lexical ones. Additionally, we demonstrate that relying solely on the base
model for generating candidate translations achieves performance comparable to
using multiple external systems, while ensuring better consistency across
downstream metrics.

摘要：神經機器翻譯 (MT) 評估指標由於與人類評分相比具有更高的相關性，因此越來越重要，而傳統的詞彙指標則不然。因此，研究人員透過品質導向的解碼策略來利用神經指標，達成比基於似然性的方法更好的結果。隨著大型語言模型 (LLM) 的興起，基於偏好的對齊技術因其透過品質估計器直接最佳化模型權重來提升翻譯品質的潛力而受到關注。本研究專注於對比偏好最佳化 (CPO)，並進行廣泛的實驗來評估基於偏好的對齊對翻譯品質的影響。我們的發現顯示，雖然 CPO 在對齊指標方面始終優於監督微調 (SFT) 的高品質資料，但它可能會導致下游評估指標的不穩定性，特別是在神經指標和詞彙指標之間。此外，我們證明僅依賴基礎模型來產生候選翻譯可達成與使用多個外部系統相當的效能，同時確保下游指標之間的一致性。

##### **Evaluating and explaining training strategies for zero-shot cross-lingual news sentiment analysis**
2409.20054v1 by Luka Andrenšek, Boshko Koloski, Andraž Pelicon, Nada Lavrač, Senja Pollak, Matthew Purver

We investigate zero-shot cross-lingual news sentiment detection, aiming to
develop robust sentiment classifiers that can be deployed across multiple
languages without target-language training data. We introduce novel evaluation
datasets in several less-resourced languages, and experiment with a range of
approaches including the use of machine translation; in-context learning with
large language models; and various intermediate training regimes including a
novel task objective, POA, that leverages paragraph-level information. Our
results demonstrate significant improvements over the state of the art, with
in-context learning generally giving the best performance, but with the novel
POA approach giving a competitive alternative with much lower computational
overhead. We also show that language similarity is not in itself sufficient for
predicting the success of cross-lingual transfer, but that similarity in
semantic content and structure can be equally important.

摘要：我們研究零次學習跨語言新聞情緒偵測，目標是開發強健的情緒分類器，可以在沒有目標語言訓練資料的情況下部署到多種語言中。我們在幾種資源較少的語言中引入了新穎的評估資料集，並嘗試了一系列的方法，包括使用機器翻譯；使用大型語言模型進行情境學習；以及各種中間訓練制度，包括利用段落層級資訊的新穎任務目標 POA。我們的結果證明了與現有技術相比有顯著的改進，其中情境學習通常能提供最佳效能，但新穎的 POA 方法提供了具有較低運算成本的競爭替代方案。我們還表明，語言相似性本身不足以預測跨語言轉移的成功，但語義內容和結構的相似性可能同樣重要。

##### **GUNDAM: Aligning Large Language Models with Graph Understanding**
2409.20053v1 by Sheng Ouyang, Yulan Hu, Ge Chen, Yong Liu

Large Language Models (LLMs) have achieved impressive results in processing
text data, which has sparked interest in applying these models beyond textual
data, such as graphs. In the field of graph learning, there is a growing
interest in harnessing LLMs to comprehend and manipulate graph-structured data.
Existing research predominantly focuses on graphs with rich textual features,
such as knowledge graphs or text attribute graphs, leveraging LLMs' ability to
process text but inadequately addressing graph structure. This work
specifically aims to assess and enhance LLMs' abilities to comprehend and
utilize the structural knowledge inherent in graph data itself, rather than
focusing solely on graphs rich in textual content. To achieve this, we
introduce the \textbf{G}raph \textbf{U}nderstanding for \textbf{N}atural
Language \textbf{D}riven \textbf{A}nalytical \textbf{M}odel (\model). This
model adapts LLMs to better understand and engage with the structure of graph
data, enabling them to perform complex reasoning tasks by leveraging the
graph's structure itself. Our experimental evaluations on graph reasoning
benchmarks not only substantiate that \model~ outperforms the SOTA baselines
for comparisons. But also reveals key factors affecting the graph reasoning
capabilities of LLMs. Moreover, we provide a theoretical analysis illustrating
how reasoning paths can enhance LLMs' reasoning capabilities.

摘要：大型語言模型 (LLM) 在處理文本數據方面取得了令人印象深刻的成果，這激發了將這些模型應用於文本數據之外領域（例如圖表）的興趣。在圖表學習領域，利用 LLM 來理解和操作圖表結構數據的興趣與日俱增。現有的研究主要集中於具有豐富文本特徵的圖表，例如知識圖表或文本屬性圖表，利用 LLM 處理文本的能力，但未能充分解決圖表結構。這項工作特別旨在評估和增強 LLM 理解和利用圖表數據本身固有的結構知識的能力，而不是僅關注富含文本內容的圖表。為此，我們引入了自然語言驅動分析模型的圖表理解 (\model)。此模型改進了 LLM 以便更好地理解和參與圖表數據的結構，使其能夠通過利用圖表的結構本身來執行複雜的推理任務。我們對圖表推理基準的實驗評估不僅證實了 \model~ 優於用於比較的 SOTA 基準，還揭示了影響 LLM 圖表推理能力的主要因素。此外，我們提供了理論分析，說明推理路徑如何增強 LLM 的推理能力。

##### **Mitigating Propensity Bias of Large Language Models for Recommender Systems**
2409.20052v1 by Guixian Zhang, Guan Yuan, Debo Cheng, Lin Liu, Jiuyong Li, Shichao Zhang

The rapid development of Large Language Models (LLMs) creates new
opportunities for recommender systems, especially by exploiting the side
information (e.g., descriptions and analyses of items) generated by these
models. However, aligning this side information with collaborative information
from historical interactions poses significant challenges. The inherent biases
within LLMs can skew recommendations, resulting in distorted and potentially
unfair user experiences. On the other hand, propensity bias causes side
information to be aligned in such a way that it often tends to represent all
inputs in a low-dimensional subspace, leading to a phenomenon known as
dimensional collapse, which severely restricts the recommender system's ability
to capture user preferences and behaviours. To address these issues, we
introduce a novel framework named Counterfactual LLM Recommendation (CLLMR).
Specifically, we propose a spectrum-based side information encoder that
implicitly embeds structural information from historical interactions into the
side information representation, thereby circumventing the risk of dimension
collapse. Furthermore, our CLLMR approach explores the causal relationships
inherent in LLM-based recommender systems. By leveraging counterfactual
inference, we counteract the biases introduced by LLMs. Extensive experiments
demonstrate that our CLLMR approach consistently enhances the performance of
various recommender models.

摘要：大型語言模型 (LLM) 的快速發展為推薦系統創造了新的機會，特別是透過利用這些模型產生的附帶資訊 (例如，物品的描述和分析)。然而，將此附帶資訊與來自歷史互動的協作資訊相結合，會造成重大的挑戰。LLM 內部固有的偏見會扭曲推薦，導致失真且可能不公平的使用者體驗。另一方面，傾向偏見會導致附帶資訊以某種方式對齊，而這種方式通常傾向於在低維子空間中表示所有輸入，進而導致稱為維度崩潰的現象，這嚴重限制了推薦系統擷取使用者偏好和行為的能力。為了解決這些問題，我們引進一個名為反事實 LLM 推薦 (CLLMR) 的新穎架構。具體來說，我們提出一個基於頻譜的附帶資訊編碼器，它將來自歷史互動的結構資訊隱含地嵌入附帶資訊表示中，從而迴避維度崩潰的風險。此外，我們的 CLLMR 方法探討了基於 LLM 的推薦系統中固有的因果關係。透過利用反事實推論，我們抵銷 LLM 引入的偏見。廣泛的實驗證明，我們的 CLLMR 方法持續提升各種推薦模型的效能。

##### **Depression detection in social media posts using transformer-based models and auxiliary features**
2409.20048v1 by Marios Kerasiotis, Loukas Ilias, Dimitris Askounis

The detection of depression in social media posts is crucial due to the
increasing prevalence of mental health issues. Traditional machine learning
algorithms often fail to capture intricate textual patterns, limiting their
effectiveness in identifying depression. Existing studies have explored various
approaches to this problem but often fall short in terms of accuracy and
robustness. To address these limitations, this research proposes a neural
network architecture leveraging transformer-based models combined with metadata
and linguistic markers. The study employs DistilBERT, extracting information
from the last four layers of the transformer, applying learned weights, and
averaging them to create a rich representation of the input text. This
representation, augmented by metadata and linguistic markers, enhances the
model's comprehension of each post. Dropout layers prevent overfitting, and a
Multilayer Perceptron (MLP) is used for final classification. Data augmentation
techniques, inspired by the Easy Data Augmentation (EDA) methods, are also
employed to improve model performance. Using BERT, random insertion and
substitution of phrases generate additional training data, focusing on
balancing the dataset by augmenting underrepresented classes. The proposed
model achieves weighted Precision, Recall, and F1-scores of 84.26%, 84.18%, and
84.15%, respectively. The augmentation techniques significantly enhance model
performance, increasing the weighted F1-score from 72.59% to 84.15%.

摘要：由於心理健康問題的盛行，在社群媒體貼文中偵測憂鬱症至關重要。傳統機器學習演算法經常無法捕捉複雜的文字模式，限制了它們在辨識憂鬱症上的效能。現有的研究探索了各種解決此問題的方法，但往往在準確度和穩健性方面有所不足。為了解決這些限制，本研究提出了一種神經網路架構，它利用了基於轉換器的模型，並結合了元資料和語言標記。本研究採用 DistilBERT，從轉換器的最後四層提取資訊，套用學習到的權重，並將它們平均以建立輸入文字的豐富表徵。此表徵由元資料和語言標記增強，增強了模型對每則貼文的理解。中斷層防止過度擬合，並使用多層感知器 (MLP) 進行最終分類。資料擴充技術（受簡易資料擴充 (EDA) 方法啟發）也用於改善模型效能。使用 BERT，隨機插入和替換片語會產生額外的訓練資料，重點在透過擴充代表性不足的類別來平衡資料集。所提出的模型分別達到了加權準確率、召回率和 F1 分數 84.26%、84.18% 和 84.15%。擴充技術顯著提升了模型效能，將加權 F1 分數從 72.59% 提升至 84.15%。

##### **Beyond Scores: A Modular RAG-Based System for Automatic Short Answer Scoring with Feedback**
2409.20042v1 by Menna Fateen, Bo Wang, Tsunenori Mine

Automatic short answer scoring (ASAS) helps reduce the grading burden on
educators but often lacks detailed, explainable feedback. Existing methods in
ASAS with feedback (ASAS-F) rely on fine-tuning language models with limited
datasets, which is resource-intensive and struggles to generalize across
contexts. Recent approaches using large language models (LLMs) have focused on
scoring without extensive fine-tuning. However, they often rely heavily on
prompt engineering and either fail to generate elaborated feedback or do not
adequately evaluate it. In this paper, we propose a modular retrieval augmented
generation based ASAS-F system that scores answers and generates feedback in
strict zero-shot and few-shot learning scenarios. We design our system to be
adaptable to various educational tasks without extensive prompt engineering
using an automatic prompt generation framework. Results show an improvement in
scoring accuracy by 9\% on unseen questions compared to fine-tuning, offering a
scalable and cost-effective solution.

摘要：自動簡答評分 (ASAS) 有助於減輕教育者的評分負擔，但通常缺乏詳細且可說明的回饋。現有的 ASAS 附回饋 (ASAS-F) 方法仰賴微調語言模型，但資料集有限，這耗費資源且難以概括所有情境。近期使用大型語言模型 (LLM) 的方法專注於評分，而無需廣泛的微調。然而，它們通常過於依賴提示工程，而且無法產生精緻的回饋，或無法充分評估回饋。在本文中，我們提出一個模組化的檢索增強生成式 ASAS-F 系統，它能在嚴格的零次學習和少次學習情境中評分答案並產生回饋。我們設計系統以適應各種教育任務，而無需使用自動提示產生架構進行廣泛的提示工程。結果顯示，與微調相比，在未見過的問題上，評分準確度提升了 9%，提供了一個可擴充且具有成本效益的解決方案。

##### **Towards Robust Multimodal Sentiment Analysis with Incomplete Data**
2409.20012v1 by Haoyu Zhang, Wenbin Wang, Tianshu Yu

The field of Multimodal Sentiment Analysis (MSA) has recently witnessed an
emerging direction seeking to tackle the issue of data incompleteness.
Recognizing that the language modality typically contains dense sentiment
information, we consider it as the dominant modality and present an innovative
Language-dominated Noise-resistant Learning Network (LNLN) to achieve robust
MSA. The proposed LNLN features a dominant modality correction (DMC) module and
dominant modality based multimodal learning (DMML) module, which enhances the
model's robustness across various noise scenarios by ensuring the quality of
dominant modality representations. Aside from the methodical design, we perform
comprehensive experiments under random data missing scenarios, utilizing
diverse and meaningful settings on several popular datasets (\textit{e.g.,}
MOSI, MOSEI, and SIMS), providing additional uniformity, transparency, and
fairness compared to existing evaluations in the literature. Empirically, LNLN
consistently outperforms existing baselines, demonstrating superior performance
across these challenging and extensive evaluation metrics.

摘要：多模态情感分析 (MSA) 领域最近见证了一个新兴的方向，旨在解决数据不完整的问题。认识到语言模态通常包含密集的情感信息，我们将其视为主要模态，并提出了一种创新的语言主导抗噪学习网络 (LNLN) 来实现稳健的 MSA。所提出的 LNLN 具有主导模态校正 (DMC) 模块和基于主导模态的多模态学习 (DMML) 模块，通过确保主导模态表示的质量，增强了模型在各种噪声场景下的稳健性。除了方法设计之外，我们还在随机数据缺失场景下执行了综合实验，在几个流行的数据集（例如 MOSI、MOSEI 和 SIMS）上利用多样且有意义的设置，与文献中现有的评估相比，提供了额外的统一性、透明性和公平性。凭经验，LNLN 始终优于现有的基线，在这些具有挑战性和广泛的评估指标中展示了卓越的性能。

##### **Customized Information and Domain-centric Knowledge Graph Construction with Large Language Models**
2409.20010v1 by Frank Wawrzik, Matthias Plaue, Savan Vekariya, Christoph Grimm

In this paper we propose a novel approach based on knowledge graphs to
provide timely access to structured information, to enable actionable
technology intelligence, and improve cyber-physical systems planning. Our
framework encompasses a text mining process, which includes information
retrieval, keyphrase extraction, semantic network creation, and topic map
visualization. Following this data exploration process, we employ a selective
knowledge graph construction (KGC) approach supported by an electronics and
innovation ontology-backed pipeline for multi-objective decision-making with a
focus on cyber-physical systems. We apply our methodology to the domain of
automotive electrical systems to demonstrate the approach, which is scalable.
Our results demonstrate that our construction process outperforms GraphGPT as
well as our bi-LSTM and transformer REBEL with a pre-defined dataset by several
times in terms of class recognition, relationship construction and correct
"sublass of" categorization. Additionally, we outline reasoning applications
and provide a comparison with Wikidata to show the differences and advantages
of the approach.

摘要：在本文中，我們提出一個基於知識圖譜的新方法，以提供對結構化資訊的即時存取，以啟用可操作的技術情報，並改善網路實體系統規劃。我們的架構包含一個文字探勘程序，其中包括資訊檢索、關鍵字詞萃取、語意網路建立和主題地圖視覺化。在這個資料探勘程序之後，我們採用一個選擇性的知識圖譜建構 (KGC) 方法，由電子和創新本體支援的管道支援，用於以網路實體系統為重點的多目標決策制定。我們將我們的技術應用於汽車電氣系統領域，以展示這種可擴充的方法。我們的結果表明，我們的建構程序在類別辨識、關係建構和正確的「子類別」分類方面，比 GraphGPT 以及我們使用預定義資料集的雙向 LSTM 和 Transformer REBEL 快好幾倍。此外，我們概述推理應用，並提供與 Wikidata 的比較，以顯示這種方法的差異和優點。

##### **Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data**
2409.20007v1 by Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, Chao-Han Huck Yang, Jagadeesh Balam, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee

Recent end-to-end speech language models (SLMs) have expanded upon the
capabilities of large language models (LLMs) by incorporating pre-trained
speech models. However, these SLMs often undergo extensive speech
instruction-tuning to bridge the gap between speech and text modalities. This
requires significant annotation efforts and risks catastrophic forgetting of
the original language capabilities. In this work, we present a simple yet
effective automatic process for creating speech-text pair data that carefully
injects speech paralinguistic understanding abilities into SLMs while
preserving the inherent language capabilities of the text-based LLM. Our model
demonstrates general capabilities for speech-related tasks without the need for
speech instruction-tuning data, achieving impressive performance on
Dynamic-SUPERB and AIR-Bench-Chat benchmarks. Furthermore, our model exhibits
the ability to follow complex instructions derived from LLMs, such as specific
output formatting and chain-of-thought reasoning. Our approach not only
enhances the versatility and effectiveness of SLMs but also reduces reliance on
extensive annotated datasets, paving the way for more efficient and capable
speech understanding systems.

摘要：近期的端到端语音语言模型 (SLM) 已通过整合预先训练的语音模型，扩大了大型语言模型 (LLM) 的能力。然而，这些 SLM 经常进行广泛的语音指令微调，以弥合语音和文本模态之间的差距。这需要大量的标注工作，并且有灾难性遗忘原始语言能力的风险。在这项工作中，我们提出一个简单但有效的自动流程来创建语音文本对数据，该数据将语音副语言理解能力小心注入 SLM，同时保留基于文本的 LLM 的固有语言能力。我们的模型展示了对与语音相关的任务的一般能力，而不需要语音指令微调数据，在 Dynamic-SUPERB 和 AIR-Bench-Chat 基准测试中取得了令人印象深刻的性能。此外，我们的模型展示了遵循从 LLM 衍生的复杂指令的能力，例如特定的输出格式和思想链推理。我们的方法不仅增强了 SLM 的多功能性和有效性，而且减少了对大量标注数据集的依赖，为更高效、更强大的语音理解系统铺平了道路。

##### **Model Selection with a Shapelet-based Distance Measure for Multi-source Transfer Learning in Time Series Classification**
2409.20005v1 by Jiseok Lee, Brian Kenji Iwana

Transfer learning is a common practice that alleviates the need for extensive
data to train neural networks. It is performed by pre-training a model using a
source dataset and fine-tuning it for a target task. However, not every source
dataset is appropriate for each target dataset, especially for time series. In
this paper, we propose a novel method of selecting and using multiple datasets
for transfer learning for time series classification. Specifically, our method
combines multiple datasets as one source dataset for pre-training neural
networks. Furthermore, for selecting multiple sources, our method measures the
transferability of datasets based on shapelet discovery for effective source
selection. While traditional transferability measures require considerable time
for pre-training all the possible sources for source selection of each possible
architecture, our method can be repeatedly used for every possible architecture
with a single simple computation. Using the proposed method, we demonstrate
that it is possible to increase the performance of temporal convolutional
neural networks (CNN) on time series datasets.

摘要：遷移學習是一種常見的實務，可以減輕訓練神經網路時對大量資料的需求。它會使用來源資料集預訓練模型，並針對目標任務微調模型。然而，並非每個來源資料集都適用於每個目標資料集，特別是對於時間序列。在本文中，我們提出了一種新穎的方法，用於選擇和使用多個資料集，以進行時間序列分類的遷移學習。具體來說，我們的方法將多個資料集合併為一個來源資料集，以預訓練神經網路。此外，對於選擇多個來源，我們的方法會根據形狀特徵發現來衡量資料集的可轉移性，以進行有效的來源選擇。雖然傳統的可轉移性測量需要大量時間來預訓練所有可能的來源，以進行每個可能架構的來源選擇，但我們的方法可以重複用於每個可能的架構，只需進行一次簡單的運算。使用所提出的方法，我們證明了提高時間序列資料集上時序卷積神經網路 (CNN) 效能是可行的。

##### **Do Influence Functions Work on Large Language Models?**
2409.19998v1 by Zhe Li, Wei Zhao, Yige Li, Jun Sun

Influence functions aim to quantify the impact of individual training data
points on a model's predictions. While extensive research has been conducted on
influence functions in traditional machine learning models, their application
to large language models (LLMs) has been limited. In this work, we conduct a
systematic study to address a key question: do influence functions work on
LLMs? Specifically, we evaluate influence functions across multiple tasks and
find that they consistently perform poorly in most settings. Our further
investigation reveals that their poor performance can be attributed to: (1)
inevitable approximation errors when estimating the iHVP component due to the
scale of LLMs, (2) uncertain convergence during fine-tuning, and, more
fundamentally, (3) the definition itself, as changes in model parameters do not
necessarily correlate with changes in LLM behavior. Our study thus suggests the
need for alternative approaches for identifying influential samples. To support
future work, our code is made available at
https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs.

摘要：影響函數旨在量化個別訓練資料點對模型預測的影響。雖然針對傳統機器學習模型已進行廣泛的研究，但其在大型語言模型 (LLM) 中的應用受到限制。在這項工作中，我們進行一項系統性研究以解決一個關鍵問題：影響函數是否適用於 LLM？具體而言，我們跨多個任務評估影響函數，並發現它們在大多數設定中表現持續不佳。我們的進一步調查顯示，其表現不佳可歸因於：(1) 由於 LLM 的規模，在估計 iHVP 組成部分時出現不可避免的近似誤差，(2) 微調期間的不確定收斂，以及更根本地，(3) 定義本身，因為模型參數的變化並不一定與 LLM 行為的變化相關。因此，我們的研究表明需要採用替代方法來識別有影響力的樣本。為了支持未來的研究，我們的程式碼已於 https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs 公開。

##### **Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges**
2409.19993v1 by Qin Liu, Wenjie Mo, Terry Tong, Jiashu Xu, Fei Wang, Chaowei Xiao, Muhao Chen

The advancement of Large Language Models (LLMs) has significantly impacted
various domains, including Web search, healthcare, and software development.
However, as these models scale, they become more vulnerable to cybersecurity
risks, particularly backdoor attacks. By exploiting the potent memorization
capacity of LLMs, adversaries can easily inject backdoors into LLMs by
manipulating a small portion of training data, leading to malicious behaviors
in downstream applications whenever the hidden backdoor is activated by the
pre-defined triggers. Moreover, emerging learning paradigms like instruction
tuning and reinforcement learning from human feedback (RLHF) exacerbate these
risks as they rely heavily on crowdsourced data and human feedback, which are
not fully controlled. In this paper, we present a comprehensive survey of
emerging backdoor threats to LLMs that appear during LLM development or
inference, and cover recent advancement in both defense and detection
strategies for mitigating backdoor threats to LLMs. We also outline key
challenges in addressing these threats, highlighting areas for future research.

摘要：大型語言模型 (LLM) 的進步顯著影響了各種領域，包括網路搜尋、醫療保健和軟體開發。然而，隨著這些模型的擴展，它們更容易受到網路安全風險的影響，特別是後門攻擊。透過利用 LLM 強大的記憶能力，對手可以透過操作一小部分訓練資料，輕鬆地將後門注入 LLM，導致惡意行為出現在下游應用程式中，只要預先定義的觸發器啟動了隱藏的後門。此外，新興的學習範例，例如指令微調和來自人類回饋的強化學習 (RLHF)，會加劇這些風險，因為它們嚴重依賴群眾外包資料和人類回饋，而這些資料和回饋並未受到完全控制。在本文中，我們針對 LLM 開發或推論期間出現的新興後門威脅提出全面的調查，並涵蓋了緩解後門威脅的防禦和偵測策略的最新進展。我們也概述了因應這些威脅的主要挑戰，並重點說明未來研究領域。

##### **Predictive Speech Recognition and End-of-Utterance Detection Towards Spoken Dialog Systems**
2409.19990v1 by Oswald Zink, Yosuke Higuchi, Carlos Mullov, Alexander Waibel, Tetsunori Kobayashi

Effective spoken dialog systems should facilitate natural interactions with
quick and rhythmic timing, mirroring human communication patterns. To reduce
response times, previous efforts have focused on minimizing the latency in
automatic speech recognition (ASR) to optimize system efficiency. However, this
approach requires waiting for ASR to complete processing until a speaker has
finished speaking, which limits the time available for natural language
processing (NLP) to formulate accurate responses. As humans, we continuously
anticipate and prepare responses even while the other party is still speaking.
This allows us to respond appropriately without missing the optimal time to
speak. In this work, as a pioneering study toward a conversational system that
simulates such human anticipatory behavior, we aim to realize a function that
can predict the forthcoming words and estimate the time remaining until the end
of an utterance (EOU), using the middle portion of an utterance. To achieve
this, we propose a training strategy for an encoder-decoder-based ASR system,
which involves masking future segments of an utterance and prompting the
decoder to predict the words in the masked audio. Additionally, we develop a
cross-attention-based algorithm that incorporates both acoustic and linguistic
information to accurately detect the EOU. The experimental results demonstrate
the proposed model's ability to predict upcoming words and estimate future EOU
events up to 300ms prior to the actual EOU. Moreover, the proposed training
strategy exhibits general improvements in ASR performance.

摘要：有效的口語對話系統應促進自然互動，節奏明快，反映人類溝通模式。為了縮短回應時間，先前的努力集中在最小化自動語音辨識 (ASR) 中的延遲，以最佳化系統效率。然而，這種方法需要等到 ASR 完成處理，直到說話者說完話為止，這限制了自然語言處理 (NLP) 可用於制定準確回應的時間。作為人類，我們會持續預期和準備回應，即使對方仍在說話。這讓我們能夠在不錯過最適說話時間的情況下適當地回應。在這項工作中，作為模擬這種人類預期行為的對話系統的開創性研究，我們旨在實現一項功能，該功能可以使用一段話的中間部分來預測接下來的字詞，並估計到話語結束 (EOU) 所剩的時間。為達成此目的，我們提出編碼器解碼器式 ASR 系統的訓練策略，其中涉及遮蔽一段話的未來片段，並提示解碼器預測遮蔽音訊中的字詞。此外，我們開發了一種基於交叉注意力的演算法，該演算法結合了聲學和語言資訊，以準確偵測 EOU。實驗結果證明了所提出的模型預測後續字詞和估計未來 EOU 事件的能力，在實際 EOU 之前最多可達 300 毫秒。此外，所提出的訓練策略在 ASR 效能方面展現了一般性的改進。

##### **CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models**
2409.19984v1 by Eitan Wagner, Yuli Slavutsky, Omri Abend

Although language model scores are often treated as probabilities, their
reliability as probability estimators has mainly been studied through
calibration, overlooking other aspects. In particular, it is unclear whether
language models produce the same value for different ways of assigning joint
probabilities to word spans. Our work introduces a novel framework, ConTestS
(Consistency Testing over Spans), involving statistical tests to assess score
consistency across interchangeable completion and conditioning orders. We
conduct experiments on post-release real and synthetic data to eliminate
training effects. Our findings reveal that both Masked Language Models (MLMs)
and autoregressive models exhibit inconsistent predictions, with autoregressive
models showing larger discrepancies. Larger MLMs tend to produce more
consistent predictions, while autoregressive models show the opposite trend.
Moreover, for both model types, prediction entropies offer insights into the
true word span likelihood and therefore can aid in selecting optimal decoding
strategies. The inconsistencies revealed by our analysis, as well their
connection to prediction entropies and differences between model types, can
serve as useful guides for future research on addressing these limitations.

摘要：儘管語言模型分數通常被視為機率，但其作為機率估計器的可靠性主要透過校準來研究，忽視了其他面向。特別是不清楚語言模型是否對指定詞彙範圍的聯合機率的不同方式產生相同的值。我們的研究引入了一個新穎的架構，ConTestS（跨範圍的一致性測試），涉及統計測試以評估可互換完成和條件順序之間的分數一致性。我們對發布後的真實和合成資料進行實驗，以消除訓練效果。我們的研究結果顯示，遮蔽語言模型 (MLM) 和自迴歸模型都會產生不一致的預測，而自迴歸模型顯示出更大的差異。較大的 MLM 傾向於產生更一致的預測，而自迴歸模型則顯示相反的趨勢。此外，對於這兩種模型類型，預測熵提供了對真實詞彙範圍機率的見解，因此有助於選擇最佳解碼策略。我們的分析揭示的不一致性，以及它們與預測熵和模型類型之間的差異，可以作為未來研究解決這些限制的有用指南。

##### **Enhancing High-order Interaction Awareness in LLM-based Recommender Model**
2409.19979v2 by Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki

Large language models (LLMs) have demonstrated prominent reasoning
capabilities in recommendation tasks by transforming them into text-generation
tasks. However, existing approaches either disregard or ineffectively model the
user-item high-order interactions. To this end, this paper presents an enhanced
LLM-based recommender (ELMRec). We enhance whole-word embeddings to
substantially enhance LLMs' interpretation of graph-constructed interactions
for recommendations, without requiring graph pre-training. This finding may
inspire endeavors to incorporate rich knowledge graphs into LLM-based
recommenders via whole-word embedding. We also found that LLMs often recommend
items based on users' earlier interactions rather than recent ones, and present
a reranking solution. Our ELMRec outperforms state-of-the-art (SOTA) methods in
both direct and sequential recommendations.

摘要：大型語言模型 (LLM) 已證明在推薦任務中具有顯著的推理能力，方法是將其轉換為文本生成任務。然而，現有方法不是忽略用戶項目高階互動，就是對其建模效果不佳。為此，本文提出了一種增強的基於 LLM 的推薦器 (ELMRec)。我們增強了全詞嵌入，以大幅增強 LLM 對圖形構建互動的解讀，用於推薦，而不需要圖形預訓練。這一發現可能會激勵將豐富的知識圖譜通過全詞嵌入整合到基於 LLM 的推薦器中的努力。我們還發現，LLM 通常根據用戶早期的互動而非最近的互動來推薦項目，並提出了一種重新排序的解決方案。我們的 ELMRec 在直接和順序推薦中都優於最先進 (SOTA) 方法。

##### **Knowledge Graph Embedding by Normalizing Flows**
2409.19977v1 by Changyi Xiao, Xiangnan He, Yixin Cao

A key to knowledge graph embedding (KGE) is to choose a proper representation
space, e.g., point-wise Euclidean space and complex vector space. In this
paper, we propose a unified perspective of embedding and introduce uncertainty
into KGE from the view of group theory. Our model can incorporate existing
models (i.e., generality), ensure the computation is tractable (i.e.,
efficiency) and enjoy the expressive power of complex random variables (i.e.,
expressiveness). The core idea is that we embed entities/relations as elements
of a symmetric group, i.e., permutations of a set. Permutations of different
sets can reflect different properties of embedding. And the group operation of
symmetric groups is easy to compute. In specific, we show that the embedding of
many existing models, point vectors, can be seen as elements of a symmetric
group. To reflect uncertainty, we first embed entities/relations as
permutations of a set of random variables. A permutation can transform a simple
random variable into a complex random variable for greater expressiveness,
called a normalizing flow. We then define scoring functions by measuring the
similarity of two normalizing flows, namely NFE. We construct several
instantiating models and prove that they are able to learn logical rules.
Experimental results demonstrate the effectiveness of introducing uncertainty
and our model. The code is available at https://github.com/changyi7231/NFE.

摘要：知識圖譜嵌入 (KGE) 的關鍵在於選擇適當的表示空間，例如點狀歐幾里得空間和複數向量空間。在本文中，我們提出了嵌入的統一觀點，並從群論的角度將不確定性引入 KGE。我們的模型可以整合現有模型（即一般性），確保計算是可行的（即效率），並享有複數隨機變數的表達能力（即表達性）。核心思想是我們將實體/關係嵌入為對稱群的元素，即集合的排列。不同集合的排列可以反映嵌入的不同屬性。而對稱群的群運算很容易計算。具體來說，我們表明許多現有模型的嵌入，點向量，可以看作是對稱群的元素。為了反映不確定性，我們首先將實體/關係嵌入為一組隨機變數的排列。一個排列可以將一個簡單的隨機變數轉換為一個複雜的隨機變數以獲得更大的表達能力，稱為正規化流。然後，我們通過測量兩個正規化流的相似性來定義評分函數，即 NFE。我們構建了幾個實例化模型，並證明它們能夠學習邏輯規則。實驗結果證明了引入不確定性和我們模型的有效性。程式碼可在 https://github.com/changyi7231/NFE 取得。

##### **Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval**
2409.19961v1 by Yabing Wang, Le Wang, Qiang Zhou, Zhibin Wang, Hao Li, Gang Hua, Wei Tang

Cross-lingual cross-modal retrieval (CCR) aims to retrieve visually relevant
content based on non-English queries, without relying on human-labeled
cross-modal data pairs during training. One popular approach involves utilizing
machine translation (MT) to create pseudo-parallel data pairs, establishing
correspondence between visual and non-English textual data. However, aligning
their representations poses challenges due to the significant semantic gap
between vision and text, as well as the lower quality of non-English
representations caused by pre-trained encoders and data noise. To overcome
these challenges, we propose LECCR, a novel solution that incorporates the
multi-modal large language model (MLLM) to improve the alignment between visual
and non-English representations. Specifically, we first employ MLLM to generate
detailed visual content descriptions and aggregate them into multi-view
semantic slots that encapsulate different semantics. Then, we take these
semantic slots as internal features and leverage them to interact with the
visual features. By doing so, we enhance the semantic information within the
visual features, narrowing the semantic gap between modalities and generating
local visual semantics for subsequent multi-level matching. Additionally, to
further enhance the alignment between visual and non-English features, we
introduce softened matching under English guidance. This approach provides more
comprehensive and reliable inter-modal correspondences between visual and
non-English features. Extensive experiments on four CCR benchmarks, \ie
Multi30K, MSCOCO, VATEX, and MSR-VTT-CN, demonstrate the effectiveness of our
proposed method. Code: \url{https://github.com/LiJiaBei-7/leccr}.

摘要：跨語言跨模態檢索 (CCR) 旨在根據非英語查詢檢索視覺相關內容，而無需在訓練過程中依賴人工標記的跨模態資料對。一種流行的方法涉及利用機器翻譯 (MT) 來建立偽平行資料對，建立視覺與非英語文本資料之間的對應關係。然而，由於視覺與文本之間存在顯著的語義差距，以及預訓練編碼器和資料雜訊造成的非英語表示品質較低，因此對齊其表示會帶來挑戰。為了克服這些挑戰，我們提出了 LECCR，這是一種結合多模態大型語言模型 (MLLM) 來改善視覺與非英語表示之間對齊的新穎解決方案。具體來說，我們首先使用 MLLM 來產生詳細的視覺內容描述，並將它們匯總到包含不同語義的多視角語義槽中。然後，我們將這些語義槽作為內部特徵，並利用它們與視覺特徵進行互動。透過這樣做，我們增強了視覺特徵中的語義資訊，縮小了模態之間的語義差距，並為後續的多層次匹配產生了局部視覺語義。此外，為了進一步增強視覺與非英語特徵之間的對齊，我們引入了在英語指導下的軟化匹配。這種方法提供了視覺與非英語特徵之間更全面且可靠的跨模態對應關係。在四個 CCR 基準上的廣泛實驗，即 Multi30K、MSCOCO、VATEX 和 MSR-VTT-CN，證明了我們提出的方法的有效性。程式碼：\url{https://github.com/LiJiaBei-7/leccr}。

##### **TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning**
2409.19960v1 by Joshua Feinglass, Yezhou Yang

Zero-shot inference, where pre-trained models perform tasks without specific
training data, is an exciting emergent ability of large models like CLIP.
Although there has been considerable exploration into enhancing zero-shot
abilities in image captioning (IC) for popular datasets such as MSCOCO and
Flickr8k, these approaches fall short with fine-grained datasets like CUB, FLO,
UCM-Captions, and Sydney-Captions. These datasets require captions to discern
between visually and semantically similar classes, focusing on detailed object
parts and their attributes. To overcome this challenge, we introduce
TRaining-Free Object-Part Enhancement (TROPE). TROPE enriches a base caption
with additional object-part details using object detector proposals and Natural
Language Processing techniques. It complements rather than alters the base
caption, allowing seamless integration with other captioning methods and
offering users enhanced flexibility. Our evaluations show that TROPE
consistently boosts performance across all tested zero-shot IC approaches and
achieves state-of-the-art results on fine-grained IC datasets.

摘要：零次學習推理，其中預訓練模型在沒有特定訓練資料的情況下執行任務，是 CLIP 等大型模型令人興奮的新興能力。儘管已經對增強流行資料集（例如 MSCOCO 和 Flickr8k）中影像標題（IC）的零次學習能力進行了大量的探索，但這些方法在 CUB、FLO、UCM-Captions 和 Sydney-Captions 等細粒度資料集上仍有不足。這些資料集需要標題來區分視覺上和語義上相似的類別，重點關注詳細的物件部分及其屬性。為了克服這個挑戰，我們引入了無訓練物件部分增強（TROPE）。TROPE 使用物件偵測建議和自然語言處理技術，使用額外的物件部分細節來豐富基本標題。它補充而不是改變基本標題，允許與其他標題方法無縫整合，並為使用者提供增強的靈活性。我們的評估表明，TROPE 在所有測試的零次學習 IC 方法中持續提升效能，並在細粒度 IC 資料集上取得最先進的結果。

##### **Attribute-Text Guided Forgetting Compensation for Lifelong Person Re-Identification**
2409.19954v1 by Shiben Liu, Huijie Fan, Qiang Wang, Weihong Ren, Yandong Tang

Lifelong person re-identification (LReID) aims to continuously learn from
non-stationary data to match individuals in different environments. Each task
is affected by variations in illumination and person-related information (such
as pose and clothing), leading to task-wise domain gaps. Current LReID methods
focus on task-specific knowledge and ignore intrinsic task-shared
representations within domain gaps, limiting model performance. Bridging
task-wise domain gaps is crucial for improving anti-forgetting and
generalization capabilities, especially when accessing limited old classes
during training. To address these issues, we propose a novel attribute-text
guided forgetting compensation (ATFC) model, which explores text-driven global
representations of identity-related information and attribute-related local
representations of identity-free information for LReID. Due to the lack of
paired text-image data, we design an attribute-text generator (ATG) to
dynamically generate a text descriptor for each instance. We then introduce a
text-guided aggregation network (TGA) to explore robust text-driven global
representations for each identity and knowledge transfer. Furthermore, we
propose an attribute compensation network (ACN) to investigate
attribute-related local representations, which distinguish similar identities
and bridge domain gaps. Finally, we develop an attribute anti-forgetting (AF)
loss and knowledge transfer (KT) loss to minimize domain gaps and achieve
knowledge transfer, improving model performance. Extensive experiments
demonstrate that our ATFC method achieves superior performance, outperforming
existing LReID methods by over 9.0$\%$/7.4$\%$ in average mAP/R-1 on the seen
dataset.

摘要：終身人物再識別 (LReID) 旨在持續從非平穩資料中學習，以在不同環境中比對個人。每個任務都會受到光照和個人相關資訊（例如姿勢和服裝）的變化影響，導致任務間的領域差距。目前的 LReID 方法專注於任務特定知識，而忽略領域差距內的內在任務共享表徵，限制了模型效能。彌合任務間的領域差距對於提升抗遺忘和概化能力至關重要，尤其是在訓練期間存取受限的舊類別時。為了解決這些問題，我們提出一個新穎的屬性文字引導遺忘補償 (ATFC) 模型，探索與身分相關資訊的文字驅動全局表徵，以及 LReID 身分無關資訊的屬性相關局部表徵。由於缺乏成對文字影像資料，我們設計了一個屬性文字產生器 (ATG) 來動態產生每個實例的文字描述符。然後，我們引入一個文字引導聚合網路 (TGA) 來探索每個身分的強健文字驅動全局表徵和知識傳遞。此外，我們提出一個屬性補償網路 (ACN) 來探討屬性相關的局部表徵，區分相似的身分並彌合領域差距。最後，我們開發了一個屬性抗遺忘 (AF) 損失和知識傳遞 (KT) 損失，以最小化領域差距並實現知識傳遞，提升模型效能。廣泛的實驗證明，我們的 ATFC 方法實現了卓越的效能，在已見資料集上以平均 mAP/R-1 超過 9.0% / 7.4% 的幅度優於現有的 LReID 方法。

##### **Law of the Weakest Link: Cross Capabilities of Large Language Models**
2409.19951v1 by Ming Zhong, Aston Zhang, Xuewei Wang, Rui Hou, Wenhan Xiong, Chenguang Zhu, Zhengxing Chen, Liang Tan, Chloe Bi, Mike Lewis, Sravya Popuri, Sharan Narang, Melanie Kambadur, Dhruv Mahajan, Sergey Edunov, Jiawei Han, Laurens van der Maaten

The development and evaluation of Large Language Models (LLMs) have largely
focused on individual capabilities. However, this overlooks the intersection of
multiple abilities across different types of expertise that are often required
for real-world tasks, which we term cross capabilities. To systematically
explore this concept, we first define seven core individual capabilities and
then pair them to form seven common cross capabilities, each supported by a
manually constructed taxonomy. Building on these definitions, we introduce
CrossEval, a benchmark comprising 1,400 human-annotated prompts, with 100
prompts for each individual and cross capability. To ensure reliable
evaluation, we involve expert annotators to assess 4,200 model responses,
gathering 8,400 human ratings with detailed explanations to serve as reference
examples. Our findings reveal that, in both static evaluations and attempts to
enhance specific abilities, current LLMs consistently exhibit the "Law of the
Weakest Link," where cross-capability performance is significantly constrained
by the weakest component. Specifically, across 58 cross-capability scores from
17 models, 38 scores are lower than all individual capabilities, while 20 fall
between strong and weak, but closer to the weaker ability. These results
highlight the under-performance of LLMs in cross-capability tasks, making the
identification and improvement of the weakest capabilities a critical priority
for future research to optimize performance in complex, multi-dimensional
scenarios.

摘要：大型語言模型 (LLM) 的開發和評估主要集中在個別能力上。然而，這忽略了在現實世界任務中通常需要的不同類型專業知識間多種能力的交集，我們稱之為交叉能力。為了系統性地探討這個概念，我們首先定義了七項核心個別能力，然後將它們配對形成七項常見的交叉能力，每項都由人工構建的分類法支持。建立在這些定義之上，我們引入了 CrossEval，一個包含 1,400 個人類註解提示的基準，每個個別和交叉能力有 100 個提示。為了確保可靠的評估，我們讓專家註解者評估 4,200 個模型回應，收集 8,400 個帶有詳細說明的人類評分作為參考範例。我們的研究結果顯示，在靜態評估和嘗試增強特定能力時，目前的 LLM 持續展現「最弱環節法則」，其中交叉能力的表現顯著地受到最弱組成的限制。具體來說，在 17 個模型的 58 個交叉能力分數中，有 38 個分數低於所有個別能力，而 20 個介於強和弱之間，但更接近較弱的能力。這些結果突顯了 LLM 在交叉能力任務中的表現不佳，使得識別和改善最弱的能力成為未來研究優化複雜、多維度場景中表現的關鍵優先事項。

##### **Task-agnostic Pre-training and Task-guided Fine-tuning for Versatile Diffusion Planner**
2409.19949v1 by Chenyou Fan, Chenjia Bai, Zhao Shan, Haoran He, Yang Zhang, Zhen Wang

Diffusion models have demonstrated their capabilities in modeling
trajectories of multi-tasks. However, existing multi-task planners or policies
typically rely on task-specific demonstrations via multi-task imitation, or
require task-specific reward labels to facilitate policy optimization via
Reinforcement Learning (RL). To address these challenges, we aim to develop a
versatile diffusion planner that can leverage large-scale inferior data that
contains task-agnostic sub-optimal trajectories, with the ability to fast adapt
to specific tasks. In this paper, we propose \textbf{SODP}, a two-stage
framework that leverages \textbf{S}ub-\textbf{O}ptimal data to learn a
\textbf{D}iffusion \textbf{P}lanner, which is generalizable for various
downstream tasks. Specifically, in the pre-training stage, we train a
foundation diffusion planner that extracts general planning capabilities by
modeling the versatile distribution of multi-task trajectories, which can be
sub-optimal and has wide data coverage. Then for downstream tasks, we adopt
RL-based fine-tuning with task-specific rewards to fast refine the diffusion
planner, which aims to generate action sequences with higher task-specific
returns. Experimental results from multi-task domains including Meta-World and
Adroit demonstrate that SODP outperforms state-of-the-art methods with only a
small amount of data for reward-guided fine-tuning.

摘要：擴散模型已展現其在模擬多任務軌跡上的能力。然而，現有的多任務規劃器或策略通常依賴於透過多任務模仿進行特定任務的示範，或需要特定任務的獎勵標籤以透過強化學習 (RL) 促進策略最佳化。為了解決這些挑戰，我們旨在開發一個多功能擴散規劃器，該規劃器可以利用包含與任務無關的次佳軌跡的大規模劣質資料，並具備快速適應特定任務的能力。在本文中，我們提出了一個兩階段架構 **SODP**，它利用 **S**ub-**O**ptimal 資料來學習一個 **D**iffusion **P**lanner，該規劃器可以泛化到各種下游任務。具體來說，在預訓練階段，我們訓練一個基礎擴散規劃器，它透過模擬多任務軌跡的多功能分佈來提取一般規劃能力，該分佈可以是次佳的，並且具有廣泛的資料涵蓋範圍。然後，對於下游任務，我們採用基於 RL 的微調，並使用特定任務的獎勵來快速微調擴散規劃器，其目的是生成具有較高任務特定回報的動作序列。來自多任務領域（包括 Meta-World 和 Adroit）的實驗結果表明，SODP 在僅使用少量資料進行獎勵引導微調的情況下，優於最先進的方法。

##### **JaPOC: Japanese Post-OCR Correction Benchmark using Vouchers**
2409.19948v1 by Masato Fujitake

In this paper, we create benchmarks and assess the effectiveness of error
correction methods for Japanese vouchers in OCR (Optical Character Recognition)
systems. It is essential for automation processing to correctly recognize
scanned voucher text, such as the company name on invoices. However, perfect
recognition is complex due to the noise, such as stamps. Therefore, it is
crucial to correctly rectify erroneous OCR results. However, no publicly
available OCR error correction benchmarks for Japanese exist, and methods have
not been adequately researched. In this study, we measured text recognition
accuracy by existing services on Japanese vouchers and developed a post-OCR
correction benchmark. Then, we proposed simple baselines for error correction
using language models and verified whether the proposed method could
effectively correct these errors. In the experiments, the proposed error
correction algorithm significantly improved overall recognition accuracy.

摘要：在本文中，我們建立基準並評估光學字元辨識 (OCR) 系統中日文憑證錯誤校正方法的有效性。正確辨識掃描的憑證文字（例如發票上的公司名稱）對於自動化處理至關重要。然而，由於印章等雜訊，完美的辨識很複雜。因此，正確修正錯誤的 OCR 結果至關重要。然而，目前沒有公開可用的日文 OCR 錯誤校正基準，且方法尚未得到充分研究。在本研究中，我們測量了現有服務對日文憑證的文字辨識準確度，並開發了一個 OCR 後校正基準。然後，我們提出了使用語言模型進行錯誤校正的簡單基線，並驗證所提出的方法是否可以有效校正這些錯誤。在實驗中，所提出的錯誤校正演算法顯著提高了整體辨識準確度。

##### **Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**
2409.19940v1 by Samia Belhadj, Sanguk Park, Ambika Seth, Hesham Dar, Thijs Kooi

Fairness in medical AI is increasingly recognized as a crucial aspect of
healthcare delivery. While most of the prior work done on fairness emphasizes
the importance of equal performance, we argue that decreases in fairness can be
either harmful or non-harmful, depending on the type of change and how
sensitive attributes are used. To this end, we introduce the notion of
positive-sum fairness, which states that an increase in performance that
results in a larger group disparity is acceptable as long as it does not come
at the cost of individual subgroup performance. This allows sensitive
attributes correlated with the disease to be used to increase performance
without compromising on fairness.
  We illustrate this idea by comparing four CNN models that make different use
of the race attribute in the training phase. The results show that removing all
demographic encodings from the images helps close the gap in performance
between the different subgroups, whereas leveraging the race attribute as a
model's input increases the overall performance while widening the disparities
between subgroups. These larger gaps are then put in perspective of the
collective benefit through our notion of positive-sum fairness to distinguish
harmful from non harmful disparities.

摘要：醫療 AI 中的公平性日益被視為醫療保健提供中至關重要的一環。雖然大多數先前關於公平性的研究都強調同等表現的重要性，我們認為公平性的下降可能是有害的或無害的，具體取決於變化的類型和敏感屬性的使用方式。為此，我們引入了正和公平性的概念，它指出，只要不以犧牲個別子群體表現為代價，那麼導致群體差異更大的表現提升是可以接受的。這允許將與疾病相關的敏感屬性用於提高表現，而不會損害公平性。
我們通過比較四個在訓練階段對種族屬性使用不同的 CNN 模型來說明這個想法。結果顯示，從圖像中移除所有人口編碼有助於縮小不同子群體之間的表現差距，而將種族屬性用作模型的輸入會提高整體表現，同時擴大子群體之間的差異。然後，通過我們正和公平性的概念將這些更大的差距置於整體效益的角度，以區分有害和無害的差異。

##### **Large Language Model Empowered Embedding Generator for Sequential Recommendation**
2409.19925v1 by Qidong Liu, Xian Wu, Wanyu Wang, Yejing Wang, Yuanshao Zhu, Xiangyu Zhao, Feng Tian, Yefeng Zheng

Sequential Recommender Systems (SRS) are extensively applied across various
domains to predict users' next interaction by modeling their interaction
sequences. However, these systems typically grapple with the long-tail problem,
where they struggle to recommend items that are less popular. This challenge
results in a decline in user discovery and reduced earnings for vendors,
negatively impacting the system as a whole. Large Language Model (LLM) has the
potential to understand the semantic connections between items, regardless of
their popularity, positioning them as a viable solution to this dilemma. In our
paper, we present LLMEmb, an innovative technique that harnesses LLM to create
item embeddings that bolster the performance of SRS. To align the capabilities
of general-purpose LLM with the needs of the recommendation domain, we
introduce a method called Supervised Contrastive Fine-Tuning (SCFT). This
method involves attribute-level data augmentation and a custom contrastive loss
designed to tailor LLM for enhanced recommendation performance. Moreover, we
highlight the necessity of incorporating collaborative filtering signals into
LLM-generated embeddings and propose Recommendation Adaptation Training (RAT)
for this purpose. RAT refines the embeddings to be optimally suited for SRS.
The embeddings derived from LLMEmb can be easily integrated with any SRS model,
showcasing its practical utility. Extensive experimentation on three real-world
datasets has shown that LLMEmb significantly improves upon current methods when
applied across different SRS models.

摘要：序列推薦系統 (SRS) 廣泛應用於各種領域，透過建模使用者的互動序列來預測他們的下一個互動。然而，這些系統通常會遇到長尾問題，也就是難以推薦較不受歡迎的項目。此挑戰導致使用者探索減少，以及供應商收益降低，對系統整體造成負面影響。大型語言模型 (LLM) 有潛力了解項目之間的語義關聯，而不管其受歡迎程度如何，使其成為解決此困境的可行方案。在我們的論文中，我們提出 LLMEmb，這是一種創新的技術，利用 LLM 來建立項目嵌入，以提升 SRS 的效能。為了將通用 LLM 的功能與推薦領域的需求結合，我們引入一種稱為監督對比微調 (SCFT) 的方法。此方法涉及屬性層級資料擴充和自訂對比損失，旨在調整 LLM 以增強推薦效能。此外，我們強調將協同過濾訊號納入 LLM 生成的嵌入的必要性，並提出推薦適應訓練 (RAT) 以達到此目的。RAT 會調整嵌入，使其最適合 SRS。從 LLMEmb 衍生的嵌入可以輕鬆與任何 SRS 模型整合，展示其實用性。在三個真實世界資料集上進行的廣泛實驗顯示，LLMEmb 在應用於不同 SRS 模型時，顯著優於目前的方法。

##### **On The Planning Abilities of OpenAI's o1 Models: Feasibility, Optimality, and Generalizability**
2409.19924v2 by Kevin Wang, Junbo Li, Neel P. Bhatt, Yihan Xi, Qiang Liu, Ufuk Topcu, Zhangyang Wang

Recent advancements in Large Language Models (LLMs) have showcased their
ability to perform complex reasoning tasks, but their effectiveness in planning
remains underexplored. In this study, we evaluate the planning capabilities of
OpenAI's o1 models across a variety of benchmark tasks, focusing on three key
aspects: feasibility, optimality, and generalizability. Through empirical
evaluations on constraint-heavy tasks (e.g., $\textit{Barman}$,
$\textit{Tyreworld}$) and spatially complex environments (e.g.,
$\textit{Termes}$, $\textit{Floortile}$), we highlight o1-preview's strengths
in self-evaluation and constraint-following, while also identifying bottlenecks
in decision-making and memory management, particularly in tasks requiring
robust spatial reasoning. Our results reveal that o1-preview outperforms GPT-4
in adhering to task constraints and managing state transitions in structured
environments. However, the model often generates suboptimal solutions with
redundant actions and struggles to generalize effectively in spatially complex
tasks. This pilot study provides foundational insights into the planning
limitations of LLMs, offering key directions for future research on improving
memory management, decision-making, and generalization in LLM-based planning.

摘要：大型語言模型 (LLM) 的最新進展展示了它們執行複雜推理任務的能力，但它們在規劃中的有效性仍未得到充分探討。在本研究中，我們評估了 OpenAI 的 o1 模型在各種基準任務中的規劃能力，重點關注三個關鍵方面：可行性、最優性和可概括性。通過對約束繁重的任務（例如，$\textit{Barman}$、$\textit{Tyreworld}$）和空間複雜環境（例如，$\textit{Termes}$、$\textit{Floortile}$）的經驗評估，我們強調了 o1-preview 在自我評估和約束遵循方面的優勢，同時也發現了決策制定和記憶體管理中的瓶頸，特別是在需要強大的空間推理能力的任務中。我們的結果表明，o1-preview 在遵守任務約束和管理結構化環境中的狀態轉換方面優於 GPT-4。然而，該模型通常會生成具有冗餘動作的次優解，並且難以在空間複雜的任務中有效概括。這項試點研究提供了對 LLM 規劃限制的基本見解，為改進基於 LLM 的規劃中的記憶體管理、決策制定和概括提供了未來研究的主要方向。

##### **Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming**
2409.19916v1 by Ming Li, Ziqian Bi, Tianyang Wang, Keyu Chen, Jiawei Xu, Qian Niu, Junyu Liu, Benji Peng, Sen Zhang, Xuanhe Pan, Jinlang Wang, Pohsun Feng, Caitlyn Heqi Yin, Yizhu Wen, Ming Liu

Object-Oriented Programming (OOP) has become a crucial paradigm for managing
the growing complexity of modern software systems, particularly in fields like
machine learning, deep learning, large language models (LLM), and data
analytics. This work provides a comprehensive introduction to the integration
of OOP techniques within these domains, with a focus on improving code
modularity, maintainability, and scalability. We begin by outlining the
evolution of computing and the rise of OOP, followed by an in-depth discussion
of key OOP principles such as encapsulation, inheritance, polymorphism, and
abstraction. The practical application of these principles is demonstrated
using Python, a widely adopted language in AI and data science. Furthermore, we
examine how design patterns and modular programming can be employed to enhance
the structure and efficiency of machine learning systems. In subsequent
sections, we apply these OOP concepts to real-world AI tasks, including the
encapsulation of preprocessing workflows, machine learning model training, and
evaluation. Detailed examples illustrate how OOP can be used to build reusable,
scalable machine learning systems while maintaining code clarity and reducing
redundancy.This work is intended to serve as a bridge for both beginners and
experienced developers, equipping them with the necessary knowledge to apply
OOP methodologies in AI-driven projects, ultimately fostering the development
of more robust and maintainable systems.

摘要：<paragraph>物件導向程式設計（OOP）已成為管理現代軟體系統日益增加的複雜性的關鍵範例，特別是在機器學習、深度學習、大型語言模型（LLM）和資料分析等領域。這項工作提供了將 OOP 技術整合到這些領域的全面性介紹，重點在於改善程式碼的模組化、可維護性和可擴充性。我們從概述運算的演進和 OOP 的興起開始，接著深入探討封裝、繼承、多型和抽象化等 OOP 原則。這些原則的實際應用是使用 Python 來展示，Python 是 AI 和資料科學中廣泛採用的語言。此外，我們探討設計模式和模組化程式設計如何用於增強機器學習系統的結構和效率。在後續的章節中，我們將這些 OOP 概念應用於真實世界的 AI 任務，包括預處理工作流程的封裝、機器學習模型訓練和評估。詳細範例說明如何使用 OOP 來建構可重複使用、可擴充的機器學習系統，同時保持程式碼清晰度並減少重複性。這項工作旨在作為初學者和經驗豐富的開發人員的橋樑，讓他們具備在 AI 驅動專案中應用 OOP 方法論的必要知識，最終促進更強大且可維護的系統開發。</paragraph>

##### **Scaling Optimal LR Across Token Horizon**
2409.19913v1 by Johan Bjorck, Alon Benhaim, Vishrav Chaudhary, Furu Wei, Xia Song

State-of-the-art LLMs are powered by scaling -- scaling model size, dataset
size and cluster size. It is economically infeasible to extensively tune
hyperparameter for the largest runs. Instead, approximately optimal
hyperparameters must be inferred or \textit{transferred} from smaller
experiments. Hyperparameter transfer across model sizes has been studied in
Yang et al. However, hyperparameter transfer across dataset size -- or token
horizon -- has not been studied yet. To remedy this we conduct a large scale
empirical study on how optimal learning rate (LR) depends on token horizon in
LLM training. We first demonstrate that the optimal LR changes significantly
with token horizon -- longer training necessitates smaller LR. Secondly we
demonstrate the the optimal LR follows a scaling law, and that the optimal LR
for longer horizons can be accurately estimated from shorter horizons via our
scaling laws. We also provide a rule-of-thumb for transferring LR across token
horizons with zero overhead over current practices. Lastly we provide evidence
that LLama-1 used too high LR, and estimate the performance hit from this. We
thus argue that hyperparameter transfer across data size is an important and
overlooked component of LLM training.

摘要：最先进的 LLM 由以下方式提供支持：扩展模型大小、数据集大小和集群大小。广泛调整超参数以进行最大运行在经济上不可行。相反，必须从较小的实验中推断或“传输”近似最优超参数。Yang 等人研究了跨模型大小的超参数传输。然而，尚未研究跨数据集大小（或令牌范围）的超参数传输。为了解决这个问题，我们对最优学习率 (LR) 如何依赖 LLM 训练中的令牌范围进行了大规模实证研究。我们首先证明最优 LR 随令牌范围而显着变化——更长的训练需要更小的 LR。其次，我们证明最优 LR 遵循缩放定律，并且可以通过我们的缩放定律从较短的范围准确估计较长范围的最优 LR。我们还提供了一个经验法则，用于在令牌范围之间传输 LR，而无需对当前实践进行任何开销。最后，我们提供了证据表明 LLama-1 使用了过高的 LR，并估计了由此造成的性能损失。因此，我们认为跨数据大小的超参数传输是 LLM 训练的一个重要且被忽视的组成部分。

##### **UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs**
2409.19898v2 by Yuho Lee, Taewon Yun, Jason Cai, Hang Su, Hwanjun Song

Existing benchmarks for summarization quality evaluation often lack diverse
input scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and
struggle with subjective and coarse-grained annotation schemes. To address
these shortcomings, we create UniSumEval benchmark, which extends the range of
input context (e.g., domain, length) and provides fine-grained,
multi-dimensional annotations. We use AI assistance in data creation,
identifying potentially hallucinogenic input texts, and also helping human
annotators reduce the difficulty of fine-grained annotation tasks. With
UniSumEval, we benchmark nine latest language models as summarizers, offering
insights into their performance across varying input contexts and evaluation
dimensions. Furthermore, we conduct a thorough comparison of SOTA automated
summary evaluators. Our benchmark data will be available at
https://github.com/DISL-Lab/UniSumEval-v1.0.

摘要：現有的摘要品質評估基準通常缺乏多樣化的輸入情境，專注於狹義的維度（例如忠實度），並與主觀且粗略的註解方案奮戰。為了解決這些缺點，我們建立了 UniSumEval 基準，它擴展了輸入內容的範圍（例如，領域、長度），並提供了細緻、多維度的註解。我們在資料建立中使用 AI 協助，識別潛在的幻覺輸入文字，並協助人工註解者降低細緻註解任務的難度。有了 UniSumEval，我們將九個最新的語言模型作為摘要者進行基準測試，提供對它們在不同輸入內容和評估維度中表現的見解。此外，我們對 SOTA 自動摘要評估器進行了徹底的比較。我們的基準資料將於 https://github.com/DISL-Lab/UniSumEval-v1.0 提供。

##### **TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation**
2409.19894v2 by Zhiqiang Yuan, Weitong Chen, Hanlin Wang, Kai Yu, Xin Peng, Yiling Lou

Code translation converts code from one programming language to another while
maintaining its original functionality, which is crucial for software
migration, system refactoring, and cross-platform development. Traditional
rule-based methods rely on manually-written rules, which can be time-consuming
and often result in less readable code. To overcome this, learning-based
methods have been developed, leveraging parallel data to train models for
automated code translation. More recently, the advance of Large Language Models
(LLMs) further boosts learning-based code translation. Although promising,
LLM-translated program still suffers from diverse quality issues (e.g., syntax
errors and semantic errors). In particular, it can be challenging for LLMs to
self-debug these errors when simply provided with the corresponding error
messages.
  In this work, we propose a novel LLM-based multi-agent system TRANSAGENT,
which enhances LLM-based code translation by fixing the syntax errors and
semantic errors with the synergy between four LLM-based agents, including
Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error
Fixer. The main insight of TRANSAGENT is to first localize the error code block
in the target program based on the execution alignment between the target and
source program, which can narrow down the fixing space and thus lower down the
fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark
from recent programming tasks to mitigate the potential data leakage issue. On
our benchmark, TRANSAGENT outperforms the latest LLM-based code translation
technique UniTrans in both translation effectiveness and efficiency;
additionally, our evaluation on different LLMs show the generalization of
TRANSAGENT and our ablation study shows the contribution of each agent.

摘要：<paragraph>程式碼翻譯將程式碼從一種程式語言轉換成另一種程式語言，同時維持其原始功能，這對軟體遷移、系統重構和跨平台開發至關重要。傳統的基於規則的方法依賴於手寫規則，這可能會耗時，且經常導致可讀性較差的程式碼。為了克服這個問題，已經開發出基於學習的方法，利用平行資料來訓練自動化程式碼翻譯的模型。最近，大型語言模型 (LLM) 的進步進一步提升了基於學習的程式碼翻譯。儘管有希望，但 LLM 翻譯的程式仍然存在各種品質問題（例如，語法錯誤和語義錯誤）。特別是，當僅提供對應的錯誤訊息時，LLM 可能難以自行除錯這些錯誤。
在這項工作中，我們提出了一個新穎的基於 LLM 的多代理系統 TRANSAGENT，它透過修正語法錯誤和語義錯誤來增強基於 LLM 的程式碼翻譯，並結合了四個基於 LLM 的代理，包括初始程式碼翻譯器、語法錯誤修正器、程式碼對齊器和語義錯誤修正器。TRANSAGENT 的主要見解是首先根據目標程式與原始程式碼之間的執行對齊來定位目標程式中的錯誤程式碼區塊，這可以縮小修正空間，從而降低修正難度。為了評估 TRANSAGENT，我們首先從最近的程式設計任務中建構一個新的基準，以減輕潛在的資料外洩問題。在我們的基準上，TRANSAGENT 在翻譯效果和效率方面都優於最新的基於 LLM 的程式碼翻譯技術 UniTrans；此外，我們對不同 LLM 的評估顯示了 TRANSAGENT 的泛化性，而我們的消融研究顯示了每個代理的貢獻。</paragraph>

##### **RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models**
2409.19886v1 by Shuhao Chen, Weisen Jiang, Baijiong Lin, James T. Kwok, Yu Zhang

Recent works show that assembling multiple off-the-shelf large language
models (LLMs) can harness their complementary abilities. To achieve this,
routing is a promising method, which learns a router to select the most
suitable LLM for each query. However, existing routing models are ineffective
when multiple LLMs perform well for a query. To address this problem, in this
paper, we propose a method called query-based Router by Dual Contrastive
learning (RouterDC). The RouterDC model consists of an encoder and LLM
embeddings, and we propose two contrastive learning losses to train the
RouterDC model. Experimental results show that RouterDC is effective in
assembling LLMs and largely outperforms individual top-performing LLMs as well
as existing routing methods on both in-distribution (+2.76\%) and
out-of-distribution (+1.90\%) tasks. Source code is available at
https://github.com/shuhao02/RouterDC.

摘要：最近的研究表明，组装多个现成的、大型语言模型 (LLM) 可以利用它们的互补能力。为了实现这一目标，路由是一种很有前景的方法，它学习路由器为每个查询选择最合适的 LLM。然而，当多个 LLM 对查询执行良好时，现有的路由模型无效。为了解决这个问题，在本文中，我们提出了一种基于查询的路由器方法，即双对比学习 (RouterDC)。RouterDC 模型由编码器和 LLM 嵌入组成，我们提出了两种对比学习损失来训练 RouterDC 模型。实验结果表明，RouterDC 在组装 LLM 方面是有效的，并且在分布内 (+2.76%) 和分布外 (+1.90%) 任务中都大大优于单独的顶级 LLM 以及现有的路由方法。源代码可在 https://github.com/shuhao02/RouterDC 获得。

##### **SWIM: Short-Window CNN Integrated with Mamba for EEG-Based Auditory Spatial Attention Decoding**
2409.19884v1 by Ziyang Zhang, Andrew Thwaites, Alexandra Woolgar, Brian Moore, Chao Zhang

In complex auditory environments, the human auditory system possesses the
remarkable ability to focus on a specific speaker while disregarding others. In
this study, a new model named SWIM, a short-window convolution neural network
(CNN) integrated with Mamba, is proposed for identifying the locus of auditory
attention (left or right) from electroencephalography (EEG) signals without
relying on speech envelopes. SWIM consists of two parts. The first is a
short-window CNN (SW$_\text{CNN}$), which acts as a short-term EEG feature
extractor and achieves a final accuracy of 84.9% in the leave-one-speaker-out
setup on the widely used KUL dataset. This improvement is due to the use of an
improved CNN structure, data augmentation, multitask training, and model
combination. The second part, Mamba, is a sequence model first applied to
auditory spatial attention decoding to leverage the long-term dependency from
previous SW$_\text{CNN}$ time steps. By joint training SW$_\text{CNN}$ and
Mamba, the proposed SWIM structure uses both short-term and long-term
information and achieves an accuracy of 86.2%, which reduces the classification
errors by a relative 31.0% compared to the previous state-of-the-art result.
The source code is available at https://github.com/windowso/SWIM-ASAD.

摘要：在複雜的聽覺環境中，人類聽覺系統擁有專注於特定說話者，同時忽視其他說話者的非凡能力。在這項研究中，提出了一個名為 SWIM 的新模型，一個與 Mamba 整合的短時窗卷積神經網路 (CNN)，用於從腦電圖 (EEG) 信號中識別聽覺注意力的位置 (左或右)，而不依賴語音包絡。SWIM 由兩部分組成。第一個是短時窗 CNN (SW$_\text{CNN}$)，它充當短期 EEG 特徵提取器，並在廣泛使用的 KUL 資料集上在留一說話者法設定中達到 84.9% 的最終準確度。這種改進是歸功於使用改進的 CNN 結構、資料擴充、多任務訓練和模型組合。第二部分 Mamba 是一個序列模型，首先應用於聽覺空間注意力解碼，以利用來自先前 SW$_\text{CNN}$ 時間步長的長期依賴性。透過聯合訓練 SW$_\text{CNN}$ 和 Mamba，提出的 SWIM 結構使用短期和長期資訊，並達到 86.2% 的準確度，與先前的最先進結果相比，將分類錯誤減少了相對的 31.0%。原始碼可在 https://github.com/windowso/SWIM-ASAD 取得。

##### **Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation**
2409.19877v1 by Huangyu Dai, Ben Chen, Kaidi Chen, Ying Han, Zihan Liang, Wen Jiang

For crosslingual conversation and trade, Neural Machine Translation (NMT) is
pivotal yet faces persistent challenges with monotony and repetition in
generated content. Traditional solutions that rely on penalizing text
redundancy or token reoccurrence have shown limited efficacy, particularly for
lengthy article and e-commerce descriptions with inherent redundancy, even with
the advent of Large Language Models (LLMs). This paper investigates the
underlying causes of textual repetition through the lens of information
entropy, attributing the phenomenon to the elevated uncertainty within the
input text. To address this, a novel algorithm named Contrastive Token Learning
with Similarity Decay (CTSD) is introduced, which modulates the suppression of
tokens dynamically, informed by varying attention weights and inter-token
distances. Furthermore, an e-commerce dataset comprised of title texts of
online real items is compiled and released susceptible to hallucination
translations to benchmark the algorithm. Extensive evaluations demonstrate that
CTSD significantly outperforms existing approaches in precision and
generalizability. Additional online A/B testing underscores its practical
value, showing marked improvements in user engagement and conversion. Notably,
this method has been implemented with full traffic on eight multilingual sites
of alibaba.com, the largest B2B e-commerce platform in the world.

摘要：對於跨語言對話和貿易而言，神經機器翻譯 (NMT) 至關重要，但仍面臨著生成內容中單調和重複的持續挑戰。傳統的解決方案依賴於懲罰文字冗餘或標記重現，已顯示出有限的功效，特別是對於具有內在冗餘的冗長文章和電子商務描述，即使出現了大型語言模型 (LLM)。本文通過資訊熵的視角探討了文字重複的根本原因，將這種現象歸因於輸入文字中較高的不確定性。為了解決這個問題，提出了一種名為對比標記學習與相似性衰減 (CTSD) 的新演算法，它根據不同的注意力權重和標記間距離，動態地調節標記的抑制。此外，編制並發布了一個由線上真實商品標題文字組成的電子商務資料集，容易產生幻覺翻譯，以作為演算法的基準。廣泛的評估表明，CTSD 在精準度和概括性方面明顯優於現有方法。額外的線上 A/B 測試強調了它的實用價值，顯示出使用者參與度和轉換率的顯著提升。值得注意的是，此方法已在全球最大的 B2B 電子商務平台 alibaba.com 的八個多語言網站上全面實施。

##### **TSI: A Multi-View Representation Learning Approach for Time Series Forecasting**
2409.19871v1 by Wentao Gao, Ziqi Xu, Jiuyong Li, Lin Liu, Jixue Liu, Thuc Duy Le, Debo Cheng, Yanchang Zhao, Yun Chen

As the growing demand for long sequence time-series forecasting in real-world
applications, such as electricity consumption planning, the significance of
time series forecasting becomes increasingly crucial across various domains.
This is highlighted by recent advancements in representation learning within
the field. This study introduces a novel multi-view approach for time series
forecasting that innovatively integrates trend and seasonal representations
with an Independent Component Analysis (ICA)-based representation. Recognizing
the limitations of existing methods in representing complex and
high-dimensional time series data, this research addresses the challenge by
combining TS (trend and seasonality) and ICA (independent components)
perspectives. This approach offers a holistic understanding of time series
data, going beyond traditional models that often miss nuanced, nonlinear
relationships. The efficacy of TSI model is demonstrated through comprehensive
testing on various benchmark datasets, where it shows superior performance over
current state-of-the-art models, particularly in multivariate forecasting. This
method not only enhances the accuracy of forecasting but also contributes
significantly to the field by providing a more in-depth understanding of time
series data. The research which uses ICA for a view lays the groundwork for
further exploration and methodological advancements in time series forecasting,
opening new avenues for research and practical applications.

摘要：隨著在實際應用中對長序列時間序列預測的需求日益增長，例如電力消耗規劃，時間序列預測的重要性在各個領域變得越來越關鍵。這一點從最近在該領域內表示學習的進展中得到了強調。本研究引入了一種新的時間序列預測多視角方法，該方法創新地將趨勢和季節表示與基於獨立成分分析 (ICA) 的表示相結合。認識到現有方法在表示複雜和高維時間序列數據方面的局限性，本研究通過結合 TS（趨勢和季節性）和 ICA（獨立成分）觀點來應對這一挑戰。這種方法提供了對時間序列數據的整體理解，超越了傳統模型，後者經常會遺漏細微的非線性關係。TSI 模型的功效通過在各種基準數據集上的全面測試得到證明，在其中它展示了優於當前最先進模型的性能，特別是在多變量預測中。這種方法不僅提高了預測的準確性，而且通過提供對時間序列數據的更深入理解，還為該領域做出了重大貢獻。使用 ICA 作為視角的研究為時間序列預測中的進一步探索和方法學進步奠定了基礎，為研究和實際應用開闢了新的途徑。

##### **The Construction of Instruction-tuned LLMs for Finance without Instruction Data Using Continual Pretraining and Model Merging**
2409.19854v1 by Masanori Hirano, Kentaro Imajo

This paper proposes a novel method for constructing instruction-tuned large
language models (LLMs) for finance without instruction data. Traditionally,
developing such domain-specific LLMs has been resource-intensive, requiring a
large dataset and significant computational power for continual pretraining and
instruction tuning. Our study proposes a simpler approach that combines
domain-specific continual pretraining with model merging. Given that
general-purpose pretrained LLMs and their instruction-tuned LLMs are often
publicly available, they can be leveraged to obtain the necessary instruction
task vector. By merging this with a domain-specific pretrained vector, we can
effectively create instruction-tuned LLMs for finance without additional
instruction data. Our process involves two steps: first, we perform continual
pretraining on financial data; second, we merge the instruction-tuned vector
with the domain-specific pretrained vector. Our experiments demonstrate the
successful construction of instruction-tuned LLMs for finance. One major
advantage of our method is that the instruction-tuned and domain-specific
pretrained vectors are nearly independent. This independence makes our approach
highly effective. The Japanese financial instruction-tuned LLMs we developed in
this study are available at
https://huggingface.co/pfnet/nekomata-14b-pfn-qfin-inst-merge.

摘要：本文提出了一种新方法，用于在没有指令数据的情况下构建针对金融领域的指令调整大型语言模型 (LLM)。传统上，开发此类特定领域的 LLM 需要大量资源，需要一个大型数据集和大量的计算能力来进行持续预训练和指令调整。我们的研究提出了一种更简单的方法，该方法将特定领域的持续预训练与模型合并相结合。鉴于通用预训练 LLM 及其指令调整的 LLM 通常是公开可用的，因此可以利用它们来获取必要的指令任务向量。通过将其与特定领域的预训练向量合并，我们可以有效地为金融领域创建指令调整的 LLM，而无需额外的指令数据。我们的流程包括两个步骤：首先，我们对金融数据执行持续预训练；其次，我们将指令调整向量与特定领域的预训练向量合并。我们的实验表明，成功构建了针对金融领域的指令调整 LLM。我们方法的一个主要优点是，指令调整的向量和特定领域的预训练向量几乎是独立的。这种独立性使我们的方法非常有效。我们在本研究中开发的日语金融指令调整 LLM 可在 https://huggingface.co/pfnet/nekomata-14b-pfn-qfin-inst-merge 获得。

##### **ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities**
2409.19839v1 by Ezra Karger, Houtan Bastani, Chen Yueh-Han, Zachary Jacobs, Danny Halawi, Fred Zhang, Philip E. Tetlock

Forecasts of future events are essential inputs into informed
decision-making. Machine learning (ML) systems have the potential to deliver
forecasts at scale, but there is no framework for evaluating the accuracy of ML
systems on a standardized set of forecasting questions. To address this gap, we
introduce ForecastBench: a dynamic benchmark that evaluates the accuracy of ML
systems on an automatically generated and regularly updated set of 1,000
forecasting questions. To avoid any possibility of data leakage, ForecastBench
is comprised solely of questions about future events that have no known answer
at the time of submission. We quantify the ability of current ML systems by
collecting forecasts from expert (human) forecasters, the general public, and
LLMs on a random subset of questions from the benchmark (N = 200). While LLMs
have achieved super-human performance on many benchmarks, they perform less
well here: expert forecasters outperform the top-performing LLM (p-values <=
0.01). We display system and human scores in a public leaderboard at
www.forecastbench.org.

摘要：未來事件預測是明智決策制定中的重要輸入。機器學習 (ML) 系統有潛力大規模提供預測，但沒有框架可以在標準化的預測問題集上評估 ML 系統的準確性。為了解決這個差距，我們引入了 ForecastBench：一個動態基準，它在自動生成並定期更新的 1,000 個預測問題集上評估 ML 系統的準確性。為了避免任何資料外洩的可能性，ForecastBench 僅包含關於未來事件的問題，這些問題在提交時沒有已知的答案。我們透過從專家（人類）預測員、一般大眾和 LLM 中收集預測，在基準中的隨機問題子集中（N = 200）量化當前 ML 系統的能力。雖然 LLM 在許多基準上都達到了超人類的表現，但它們在此表現不佳：專家預測員優於表現最佳的 LLM（p 值 <= 0.01）。我們在 www.forecastbench.org 上的公開排行榜中顯示系統和人類分數。

##### **Counterfactual Evaluation of Ads Ranking Models through Domain Adaptation**
2409.19824v1 by Mohamed A. Radwan, Himaghna Bhattacharjee, Quinn Lanners, Jiasheng Zhang, Serkan Karakulak, Houssam Nassif, Murat Ali Bayir

We propose a domain-adapted reward model that works alongside an Offline A/B
testing system for evaluating ranking models. This approach effectively
measures reward for ranking model changes in large-scale Ads recommender
systems, where model-free methods like IPS are not feasible. Our experiments
demonstrate that the proposed technique outperforms both the vanilla IPS method
and approaches using non-generalized reward models.

摘要：我們提出一個領域適應獎勵模型，與離線 A/B 測試系統一起使用，用於評估排名模型。此方法有效地衡量了在大型廣告推薦系統中排名模型變更的獎勵，其中像 IPS 等無模型方法不可行。我們的實驗表明，所提出的技術優於香草 IPS 方法和使用非廣義獎勵模型的方法。

##### **Calibrating Language Models with Adaptive Temperature Scaling**
2409.19817v1 by Johnathan Xie, Annie S. Chen, Yoonho Lee, Eric Mitchell, Chelsea Finn

The effectiveness of large language models (LLMs) is not only measured by
their ability to generate accurate outputs but also by their calibration-how
well their confidence scores reflect the probability of their outputs being
correct. While unsupervised pre-training has been shown to yield LLMs with
well-calibrated conditional probabilities, recent studies have shown that after
fine-tuning with reinforcement learning from human feedback (RLHF), the
calibration of these models degrades significantly. In this work, we introduce
Adaptive Temperature Scaling (ATS), a post-hoc calibration method that predicts
a temperature scaling parameter for each token prediction. The predicted
temperature values adapt based on token-level features and are fit over a
standard supervised fine-tuning (SFT) dataset. The adaptive nature of ATS
addresses the varying degrees of calibration shift that can occur after RLHF
fine-tuning. ATS improves calibration by over 10-50% across three downstream
natural language evaluation benchmarks compared to prior calibration methods
and does not impede performance improvements from RLHF.

摘要：大型語言模型 (LLM) 的效能不僅取決於它們產生準確輸出的能力，還取決於它們的校準能力，也就是它們的信心分數能多準確地反映其輸出的正確性。雖然已證實無監督預訓練可產生具有良好校準條件機率的 LLM，但最近的研究顯示，在經過人類回饋強化學習 (RLHF) 微調後，這些模型的校準會顯著下降。在這項研究中，我們引入了自適應溫度縮放 (ATS)，這是一種事後校準方法，可預測每個權杖預測的溫度縮放參數。預測的溫度值會根據權杖層級特徵進行調整，並針對標準監督式微調 (SFT) 資料集進行擬合。ATS 的自適應特性可處理 RLHF 微調後可能發生的校準轉移的程度差異。與先前的校準方法相比，ATS 可將三個下游自然語言評估基準的校準改善超過 10-50%，且不會阻礙 RLHF 的效能提升。

##### **Grounded Curriculum Learning**
2409.19816v1 by Linji Wang, Zifan Xu, Peter Stone, Xuesu Xiao

The high cost of real-world data for robotics Reinforcement Learning (RL)
leads to the wide usage of simulators. Despite extensive work on building
better dynamics models for simulators to match with the real world, there is
another, often-overlooked mismatch between simulations and the real world,
namely the distribution of available training tasks. Such a mismatch is further
exacerbated by existing curriculum learning techniques, which automatically
vary the simulation task distribution without considering its relevance to the
real world. Considering these challenges, we posit that curriculum learning for
robotics RL needs to be grounded in real-world task distributions. To this end,
we propose Grounded Curriculum Learning (GCL), which aligns the simulated task
distribution in the curriculum with the real world, as well as explicitly
considers what tasks have been given to the robot and how the robot has
performed in the past. We validate GCL using the BARN dataset on complex
navigation tasks, achieving a 6.8% and 6.5% higher success rate compared to a
state-of-the-art CL method and a curriculum designed by human experts,
respectively. These results show that GCL can enhance learning efficiency and
navigation performance by grounding the simulation task distribution in the
real world within an adaptive curriculum.

摘要：機器人強化學習 (RL) 中真實世界數據的高昂成本導致廣泛使用模擬器。儘管在建立更好的動態模型以使模擬器與真實世界相匹配方面做了大量工作，但模擬與真實世界之間還存在另一個經常被忽視的不匹配，即可用訓練任務的分布。現有的課程學習技術進一步加劇了這種不匹配，這些技術會自動改變模擬任務分佈，而不會考慮其與真實世界的相關性。考慮到這些挑戰，我們假設機器人 RL 的課程學習需要以真實世界的任務分佈為基礎。為此，我們提出了基於真實世界的課程學習 (GCL)，它將課程中的模擬任務分佈與真實世界保持一致，並明確考慮了機器人已獲得哪些任務以及機器人在過去的表現。我們使用 BARN 資料集驗證了 GCL 在複雜導航任務中，與最先進的 CL 方法和由人類專家設計的課程相比，分別實現了 6.8% 和 6.5% 的更高成功率。這些結果表明，GCL 能夠通過在自適應課程中將模擬任務分佈建立在真實世界中來提高學習效率和導航性能。

##### **Transforming Hidden States into Binary Semantic Features**
2409.19813v1 by Tomáš Musil, David Mareček

Large language models follow a lineage of many NLP applications that were
directly inspired by distributional semantics, but do not seem to be closely
related to it anymore. In this paper, we propose to employ the distributional
theory of meaning once again. Using Independent Component Analysis to overcome
some of its challenging aspects, we show that large language models represent
semantic features in their hidden states.

摘要：大型語言模型遵循許多 NLP 應用程式的譜系，這些應用程式直接受到分佈語義的啟發，但似乎不再與其密切相關。在本文中，我們建議再次採用分佈式的意義理論。我們使用獨立成分分析來克服其一些具有挑戰性的方面，我們表明大型語言模型在其隱藏狀態中表示語義特徵。


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-30**|**GUNDAM: Aligning Large Language Models with Graph Understanding**|Sheng Ouyang et.al.|[2409.20053v1](http://arxiv.org/abs/2409.20053v1)|null|
|**2024-09-30**|**Enhancing High-order Interaction Awareness in LLM-based Recommender Model**|Xinfeng Wang et.al.|[2409.19979v2](http://arxiv.org/abs/2409.19979v2)|[link](https://github.com/WangXFng/ELMRec)|
|**2024-09-29**|**CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering**|Yike Wu et.al.|[2409.19753v1](http://arxiv.org/abs/2409.19753v1)|null|
|**2024-09-29**|**Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models**|Xin Li et.al.|[2409.19667v1](http://arxiv.org/abs/2409.19667v1)|[link](https://github.com/bupt-gamma/prograph)|
|**2024-09-28**|**Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs**|Zheng Wang et.al.|[2409.19401v1](http://arxiv.org/abs/2409.19401v1)|null|
|**2024-09-27**|**CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting**|Haobo Li et.al.|[2409.19058v1](http://arxiv.org/abs/2409.19058v1)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|Huizi Yu et.al.|[2409.18924v1](http://arxiv.org/abs/2409.18924v1)|null|
|**2024-09-27**|**Soft Measures for Extracting Causal Collective Intelligence**|Maryam Berijanian et.al.|[2409.18911v1](http://arxiv.org/abs/2409.18911v1)|[link](https://github.com/kuldeep7688/soft-measures-causal-intelligence)|
|**2024-09-27**|**OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph**|Yujie Tang et.al.|[2409.18743v1](http://arxiv.org/abs/2409.18743v1)|null|
|**2024-09-27**|**Rehearsing Answers to Probable Questions with Perspective-Taking**|Yung-Yu Shih et.al.|[2409.18678v1](http://arxiv.org/abs/2409.18678v1)|null|
|**2024-09-26**|**LowREm: A Repository of Word Embeddings for 87 Low-Resource Languages Enhanced with Multilingual Graph Knowledge**|Daniil Gurgurov et.al.|[2409.18193v1](http://arxiv.org/abs/2409.18193v1)|null|
|**2024-09-26**|**Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study**|Zahra Sepasdar et.al.|[2409.17580v1](http://arxiv.org/abs/2409.17580v1)|null|
|**2024-09-25**|**Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**|Juliette Faille et.al.|[2409.16707v1](http://arxiv.org/abs/2409.16707v1)|null|
|**2024-09-25**|**GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**|Zhe-Rui Yang et.al.|[2409.16670v1](http://arxiv.org/abs/2409.16670v1)|null|
|**2024-09-24**|**Cyber Knowledge Completion Using Large Language Models**|Braden K Webb et.al.|[2409.16176v1](http://arxiv.org/abs/2409.16176v1)|null|
|**2024-09-24**|**Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**|Maria Lysyuk et.al.|[2409.15902v1](http://arxiv.org/abs/2409.15902v1)|[link](https://github.com/s-nlp/konstruktor)|
|**2024-09-24**|**Symmetries and Expressive Requirements for Learning General Policies**|Dominik Drexler et.al.|[2409.15892v1](http://arxiv.org/abs/2409.15892v1)|null|
|**2024-09-23**|**GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**|Brendan Hogan Rappazzo et.al.|[2409.15566v1](http://arxiv.org/abs/2409.15566v1)|null|
|**2024-09-23**|**KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems**|Zixuan Wang et.al.|[2409.14908v1](http://arxiv.org/abs/2409.14908v1)|null|
|**2024-09-23**|**End-to-End Graph Flattening Method for Large Language Models**|Bin Hong et.al.|[2409.14880v1](http://arxiv.org/abs/2409.14880v1)|null|
|**2024-09-22**|**RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph**|Linxi Wei et.al.|[2409.14556v1](http://arxiv.org/abs/2409.14556v1)|null|
|**2024-09-21**|**Graph Neural Network Framework for Sentiment Analysis Using Syntactic Feature**|Linxiao Wu et.al.|[2409.14000v1](http://arxiv.org/abs/2409.14000v1)|null|
|**2024-09-20**|**ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources**|Shuting Yang et.al.|[2409.13537v1](http://arxiv.org/abs/2409.13537v1)|[link](https://github.com/zaiwen/cropgpt)|
|**2024-09-20**|**LM-assisted keyword biasing with Aho-Corasick algorithm for Transducer-based ASR**|Iuliia Thorbecke et.al.|[2409.13514v1](http://arxiv.org/abs/2409.13514v1)|null|
|**2024-09-20**|**AQA: Adaptive Question Answering in a Society of LLMs via Contextual Multi-Armed Bandit**|Mohanna Hoveyda et.al.|[2409.13447v2](http://arxiv.org/abs/2409.13447v2)|null|
|**2024-09-20**|**GAProtoNet: A Multi-head Graph Attention-based Prototypical Network for Interpretable Text Classification**|Ximing Wen et.al.|[2409.13312v1](http://arxiv.org/abs/2409.13312v1)|null|
|**2024-09-20**|**Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems**|Andrea Colombo et.al.|[2409.13252v1](http://arxiv.org/abs/2409.13252v1)|null|
|**2024-09-19**|**Knowledge-Based Domain-Oriented Data Augmentation for Enhancing Unsupervised Sentence Embedding**|Peichao Lai et.al.|[2409.12887v1](http://arxiv.org/abs/2409.12887v1)|null|
|**2024-09-19**|**KnowFormer: Revisiting Transformers for Knowledge Graph Reasoning**|Junnan Liu et.al.|[2409.12865v1](http://arxiv.org/abs/2409.12865v1)|null|
|**2024-09-19**|**A New Perspective on ADHD Research: Knowledge Graph Construction with LLMs and Network Based Insights**|Hakan T. Otal et.al.|[2409.12853v1](http://arxiv.org/abs/2409.12853v1)|null|
|**2024-09-19**|**Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data**|Jiaming Zhou et.al.|[2409.12437v1](http://arxiv.org/abs/2409.12437v1)|[link](https://github.com/riddickzhou/llm-graph-synthetic-reasoning)|
|**2024-09-19**|**Textualized Agent-Style Reasoning for Complex Tasks by Multiple Round LLM Generation**|Chen Liang et.al.|[2409.12411v1](http://arxiv.org/abs/2409.12411v1)|null|
|**2024-09-18**|**GUNet: A Graph Convolutional Network United Diffusion Model for Stable and Diversity Pose Generation**|Shuowen Liang et.al.|[2409.11689v1](http://arxiv.org/abs/2409.11689v1)|[link](https://github.com/liangshuowen/posediffusion)|
|**2024-09-17**|**FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction**|Ziwei Li et.al.|[2409.11509v1](http://arxiv.org/abs/2409.11509v1)|null|
|**2024-09-17**|**Reasoning Graph Enhanced Exemplars Retrieval for In-Context Learning**|Yukang Lin et.al.|[2409.11147v1](http://arxiv.org/abs/2409.11147v1)|[link](https://github.com/yukang-lin/rger)|
|**2024-09-17**|**Semformer: Transformer Language Models with Semantic Planning**|Yongjing Yin et.al.|[2409.11143v1](http://arxiv.org/abs/2409.11143v1)|null|
|**2024-09-17**|**KALE: An Artwork Image Captioning System Augmented with Heterogeneous Graph**|Yanbei Jiang et.al.|[2409.10921v1](http://arxiv.org/abs/2409.10921v1)|[link](https://github.com/yanbei-jiang/artwork-interpretation)|
|**2024-09-16**|**A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**|Zhang Zheng et.al.|[2409.10403v1](http://arxiv.org/abs/2409.10403v1)|null|
|**2024-09-16**|**MGSA: Multi-Granularity Graph Structure Attention for Knowledge Graph-to-Text Generation**|Shanshan Wang et.al.|[2409.10294v2](http://arxiv.org/abs/2409.10294v2)|null|
|**2024-09-16**|**LLM-DER:A Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain**|Le Xiao et.al.|[2409.10077v1](http://arxiv.org/abs/2409.10077v1)|null|
|**2024-09-16**|**On the Diagram of Thought**|Yifan Zhang et.al.|[2409.10038v1](http://arxiv.org/abs/2409.10038v1)|[link](https://github.com/diagram-of-thought/diagram-of-thought)|
|**2024-09-15**|**Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation Extraction in Long Sentences**|Xin Wang et.al.|[2409.13755v1](http://arxiv.org/abs/2409.13755v1)|null|
|**2024-09-14**|**Generating Event-oriented Attribution for Movies via Two-Stage Prefix-Enhanced Multimodal LLM**|Yuanjie Lyu et.al.|[2409.09362v1](http://arxiv.org/abs/2409.09362v1)|null|
|**2024-09-14**|**ODE: Open-Set Evaluation of Hallucinations in Multimodal Large Language Models**|Yahan Tu et.al.|[2409.09318v1](http://arxiv.org/abs/2409.09318v1)|null|
|**2024-09-13**|**Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks**|Florian Grötschla et.al.|[2409.09026v1](http://arxiv.org/abs/2409.09026v1)|null|
|**2024-09-13**|**Contri(e)ve: Context + Retrieve for Scholarly Question Answering**|Kanchan Shivashankar et.al.|[2409.09010v1](http://arxiv.org/abs/2409.09010v1)|null|
|**2024-09-13**|**SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity**|Qitian Wu et.al.|[2409.09007v1](http://arxiv.org/abs/2409.09007v1)|[link](https://github.com/qitianwu/sgformer)|
|**2024-09-13**|**Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies**|Zhiqiang Zhong et.al.|[2409.08864v1](http://arxiv.org/abs/2409.08864v1)|null|
|**2024-09-13**|**A RAG Approach for Generating Competency Questions in Ontology Engineering**|Xueli Pan et.al.|[2409.08820v1](http://arxiv.org/abs/2409.08820v1)|null|
|**2024-09-13**|**ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model**|Zezheng Qin et.al.|[2409.08543v1](http://arxiv.org/abs/2409.08543v1)|null|
|**2024-09-12**|**What Makes a Maze Look Like a Maze?**|Joy Hsu et.al.|[2409.08202v1](http://arxiv.org/abs/2409.08202v1)|null|
|**2024-09-12**|**Towards a graph-based foundation model for network traffic analysis**|Louis Van Langendonck et.al.|[2409.08111v1](http://arxiv.org/abs/2409.08111v1)|null|
|**2024-09-12**|**Learning Rules from KGs Guided by Language Models**|Zihang Peng et.al.|[2409.07869v1](http://arxiv.org/abs/2409.07869v1)|[link](https://github.com/pzh97/learning-rules-from-kgs-guided-by-language-models)|
|**2024-09-12**|**Multi-object event graph representation learning for Video Question Answering**|Yanan Wang et.al.|[2409.07747v1](http://arxiv.org/abs/2409.07747v1)|null|
|**2024-09-11**|**Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**|Khiem Ton et.al.|[2409.07368v3](http://arxiv.org/abs/2409.07368v3)|null|
|**2024-09-11**|**Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs**|William Van Woensel et.al.|[2409.12171v1](http://arxiv.org/abs/2409.12171v1)|null|
|**2024-09-11**|**Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model**|Daehee Kim et.al.|[2409.07088v1](http://arxiv.org/abs/2409.07088v1)|[link](https://github.com/daehuikim/WikiOFGraph)|
|**2024-09-11**|**Automated Speaking Assessment of Conversation Tests with Novel Graph-based Modeling on Spoken Response Coherence**|Jiun-Ting Li et.al.|[2409.07064v1](http://arxiv.org/abs/2409.07064v1)|null|
|**2024-09-11**|**FreeRide: Harvesting Bubbles in Pipeline Parallelism**|Jiashu Zhang et.al.|[2409.06941v1](http://arxiv.org/abs/2409.06941v1)|null|
|**2024-09-10**|**Generative Hierarchical Materials Search**|Sherry Yang et.al.|[2409.06762v1](http://arxiv.org/abs/2409.06762v1)|null|
|**2024-09-10**|**Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization**|Gollam Rabby et.al.|[2409.06433v1](http://arxiv.org/abs/2409.06433v1)|null|
|**2024-09-10**|**TopoChat: Enhancing Topological Materials Retrieval With Large Language Model and Multi-Source Knowledge**|HuangChao Xu et.al.|[2409.13732v1](http://arxiv.org/abs/2409.13732v1)|null|
|**2024-09-10**|**KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation**|Lei Liang et.al.|[2409.13731v3](http://arxiv.org/abs/2409.13731v3)|null|
|**2024-09-09**|**Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**|Dongyue Li et.al.|[2409.06091v1](http://arxiv.org/abs/2409.06091v1)|[link](https://github.com/virtuosoresearch/scalablemtl)|
|**2024-09-09**|**OneEdit: A Neural-Symbolic Collaboratively Knowledge Editing System**|Ningyu Zhang et.al.|[2409.07497v1](http://arxiv.org/abs/2409.07497v1)|[link](https://github.com/zjunlp/oneedit)|
|**2024-09-09**|**SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning**|Alireza Ghafarollahi et.al.|[2409.05556v1](http://arxiv.org/abs/2409.05556v1)|[link](https://github.com/lamm-mit/SciAgentsDiscovery)|
|**2024-09-09**|**Assessing SPARQL capabilities of Large Language Models**|Lars-Peter Meyer et.al.|[2409.05925v1](http://arxiv.org/abs/2409.05925v1)|[link](https://github.com/aksw/llm-kg-bench)|
|**2024-09-09**|**KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**|Yingshu Li et.al.|[2409.05370v1](http://arxiv.org/abs/2409.05370v1)|null|
|**2024-09-07**|**Action is the primary key: a categorical framework for episode description and logical reasoning**|Yoshiki Fukada et.al.|[2409.04793v1](http://arxiv.org/abs/2409.04793v1)|null|
|**2024-09-06**|**Accelerating Training with Neuron Interaction and Nowcasting Networks**|Boris Knyazev et.al.|[2409.04434v1](http://arxiv.org/abs/2409.04434v1)|[link](https://github.com/samsungsailmontreal/nino)|
|**2024-09-06**|**Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets**|Desiree Heim et.al.|[2409.04286v1](http://arxiv.org/abs/2409.04286v1)|null|
|**2024-09-06**|**GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding**|Ziyin Zhang et.al.|[2409.04183v1](http://arxiv.org/abs/2409.04183v1)|null|
|**2024-09-06**|**Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering**|Larissa Pusch et.al.|[2409.04181v1](http://arxiv.org/abs/2409.04181v1)|null|
|**2024-09-06**|**Refining Wikidata Taxonomy using Large Language Models**|Yiwen Peng et.al.|[2409.04056v1](http://arxiv.org/abs/2409.04056v1)|[link](https://github.com/peng-yiwen/WiKC)|
|**2024-09-06**|**Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features**|Miao Fan et.al.|[2409.04009v1](http://arxiv.org/abs/2409.04009v1)|null|
|**2024-09-05**|**Rx Strategist: Prescription Verification using LLM Agents System**|Phuc Phan Van et.al.|[2409.03440v1](http://arxiv.org/abs/2409.03440v1)|null|
|**2024-09-05**|**iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models**|Yassir Lairgi et.al.|[2409.03284v1](http://arxiv.org/abs/2409.03284v1)|[link](https://github.com/AuvaLab/itext2kg)|
|**2024-09-05**|**GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding**|Yukun Cao et.al.|[2409.03258v1](http://arxiv.org/abs/2409.03258v1)|null|
|**2024-09-05**|**Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models**|Jie Ma et.al.|[2409.03155v1](http://arxiv.org/abs/2409.03155v1)|[link](https://github.com/reml-group/dog)|
|**2024-09-04**|**Word and Phrase Features in Graph Convolutional Network for Automatic Question Classification**|Junyoung Lee et.al.|[2409.02481v1](http://arxiv.org/abs/2409.02481v1)|null|
|**2024-09-04**|**Multi-modal Situated Reasoning in 3D Scenes**|Xiongkun Linghu et.al.|[2409.02389v1](http://arxiv.org/abs/2409.02389v1)|null|
|**2024-09-02**|**Grounding Language Models in Autonomous Loco-manipulation Tasks**|Jin Wang et.al.|[2409.01326v1](http://arxiv.org/abs/2409.01326v1)|null|
|**2024-09-02**|**LATEX-GCL: Large Language Models (LLMs)-Based Data Augmentation for Text-Attributed Graph Contrastive Learning**|Haoran Yang et.al.|[2409.01145v1](http://arxiv.org/abs/2409.01145v1)|null|
|**2024-09-01**|**Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering**|Derian Boer et.al.|[2409.00861v1](http://arxiv.org/abs/2409.00861v1)|[link](https://github.com/kramerlab/4StepFocus)|
|**2024-09-01**|**Building FKG.in: a Knowledge Graph for Indian Food**|Saransh Kumar Gupta et.al.|[2409.00830v1](http://arxiv.org/abs/2409.00830v1)|null|
|**2024-09-01**|**Hound: Hunting Supervision Signals for Few and Zero Shot Node Classification on Text-attributed Graph**|Yuxiang Wang et.al.|[2409.00727v1](http://arxiv.org/abs/2409.00727v1)|null|
|**2024-08-31**|**WikiCausal: Corpus and Evaluation Framework for Causal Knowledge Graph Construction**|Oktie Hassanzadeh et.al.|[2409.00331v1](http://arxiv.org/abs/2409.00331v1)|[link](https://github.com/IBM/wikicausal)|
|**2024-08-29**|**HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation System for AI Legal and Policy Applications**|Rishi Kalra et.al.|[2409.09046v1](http://arxiv.org/abs/2409.09046v1)|null|
|**2024-08-29**|**LLaVA-SG: Leveraging Scene Graphs as Visual Semantic Expression in Vision-Language Models**|Jingyi Wang et.al.|[2408.16224v2](http://arxiv.org/abs/2408.16224v2)|null|
|**2024-08-28**|**LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments**|Ruirui Chen et.al.|[2408.15903v1](http://arxiv.org/abs/2408.15903v1)|null|
|**2024-08-27**|**VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities**|Shusaku Egami et.al.|[2408.14895v2](http://arxiv.org/abs/2408.14895v2)|[link](https://github.com/aistairc/virtualhome_aist)|
|**2024-08-27**|**XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model**|Yasir Ali Farrukh et.al.|[2408.16021v1](http://arxiv.org/abs/2408.16021v1)|[link](https://github.com/yasir-ali-farrukh/gnn4id)|
|**2024-08-26**|**Process Trace Querying using Knowledge Graphs and Notation3**|William Van Woensel et.al.|[2409.04452v1](http://arxiv.org/abs/2409.04452v1)|null|
|**2024-08-26**|**PatentGPT: A Large Language Model for Patent Drafting Using Knowledge-based Fine-tuning Method**|Runtao Ren et.al.|[2409.00092v1](http://arxiv.org/abs/2409.00092v1)|null|
|**2024-08-26**|**DynamicRouteGPT: A Real-Time Multi-Vehicle Dynamic Navigation Framework Based on Large Language Models**|Ziai Zhou et.al.|[2408.14185v1](http://arxiv.org/abs/2408.14185v1)|null|
|**2024-08-26**|**Exploring the Potential of Large Language Models for Heterophilic Graphs**|Yuxia Wu et.al.|[2408.14134v1](http://arxiv.org/abs/2408.14134v1)|null|
|**2024-08-26**|**Towards Graph Prompt Learning: A Survey and Beyond**|Qingqing Long et.al.|[2408.14520v3](http://arxiv.org/abs/2408.14520v3)|null|
|**2024-08-25**|**CodeGraph: Enhancing Graph Reasoning of LLMs with Code**|Qiaolong Cai et.al.|[2408.13863v1](http://arxiv.org/abs/2408.13863v1)|null|
|**2024-08-25**|**LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings**|Duo Wang et.al.|[2408.14512v1](http://arxiv.org/abs/2408.14512v1)|null|
|**2024-08-24**|**Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models**|Sakhinana Sagar Srinivas et.al.|[2408.13661v1](http://arxiv.org/abs/2408.13661v1)|null|

#### Abstracts
##### **GUNDAM: Aligning Large Language Models with Graph Understanding**
2409.20053v1 by Sheng Ouyang, Yulan Hu, Ge Chen, Yong Liu

Large Language Models (LLMs) have achieved impressive results in processing
text data, which has sparked interest in applying these models beyond textual
data, such as graphs. In the field of graph learning, there is a growing
interest in harnessing LLMs to comprehend and manipulate graph-structured data.
Existing research predominantly focuses on graphs with rich textual features,
such as knowledge graphs or text attribute graphs, leveraging LLMs' ability to
process text but inadequately addressing graph structure. This work
specifically aims to assess and enhance LLMs' abilities to comprehend and
utilize the structural knowledge inherent in graph data itself, rather than
focusing solely on graphs rich in textual content. To achieve this, we
introduce the \textbf{G}raph \textbf{U}nderstanding for \textbf{N}atural
Language \textbf{D}riven \textbf{A}nalytical \textbf{M}odel (\model). This
model adapts LLMs to better understand and engage with the structure of graph
data, enabling them to perform complex reasoning tasks by leveraging the
graph's structure itself. Our experimental evaluations on graph reasoning
benchmarks not only substantiate that \model~ outperforms the SOTA baselines
for comparisons. But also reveals key factors affecting the graph reasoning
capabilities of LLMs. Moreover, we provide a theoretical analysis illustrating
how reasoning paths can enhance LLMs' reasoning capabilities.

摘要：大型語言模型 (LLM) 在處理文本數據方面取得了令人印象深刻的成果，這激發了將這些模型應用於文本數據之外領域（例如圖表）的興趣。在圖表學習領域，利用 LLM 來理解和操作圖表結構數據的興趣與日俱增。現有的研究主要集中於具有豐富文本特徵的圖表，例如知識圖表或文本屬性圖表，利用 LLM 處理文本的能力，但未能充分解決圖表結構。這項工作特別旨在評估和增強 LLM 理解和利用圖表數據本身固有的結構知識的能力，而不是僅關注富含文本內容的圖表。為此，我們引入了自然語言驅動分析模型的圖表理解 (\model)。此模型改進了 LLM 以便更好地理解和參與圖表數據的結構，使其能夠通過利用圖表的結構本身來執行複雜的推理任務。我們對圖表推理基準的實驗評估不僅證實了 \model~ 優於用於比較的 SOTA 基準，還揭示了影響 LLM 圖表推理能力的主要因素。此外，我們提供了理論分析，說明推理路徑如何增強 LLM 的推理能力。

##### **Enhancing High-order Interaction Awareness in LLM-based Recommender Model**
2409.19979v2 by Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki

Large language models (LLMs) have demonstrated prominent reasoning
capabilities in recommendation tasks by transforming them into text-generation
tasks. However, existing approaches either disregard or ineffectively model the
user-item high-order interactions. To this end, this paper presents an enhanced
LLM-based recommender (ELMRec). We enhance whole-word embeddings to
substantially enhance LLMs' interpretation of graph-constructed interactions
for recommendations, without requiring graph pre-training. This finding may
inspire endeavors to incorporate rich knowledge graphs into LLM-based
recommenders via whole-word embedding. We also found that LLMs often recommend
items based on users' earlier interactions rather than recent ones, and present
a reranking solution. Our ELMRec outperforms state-of-the-art (SOTA) methods in
both direct and sequential recommendations.

摘要：大型語言模型 (LLM) 已證明在推薦任務中具有顯著的推理能力，方法是將其轉換為文本生成任務。然而，現有方法不是忽略用戶項目高階互動，就是對其建模效果不佳。為此，本文提出了一種增強的基於 LLM 的推薦器 (ELMRec)。我們增強了全詞嵌入，以大幅增強 LLM 對圖形構建互動的解讀，用於推薦，而不需要圖形預訓練。這一發現可能會激勵將豐富的知識圖譜通過全詞嵌入整合到基於 LLM 的推薦器中的努力。我們還發現，LLM 通常根據用戶早期的互動而非最近的互動來推薦項目，並提出了一種重新排序的解決方案。我們的 ELMRec 在直接和順序推薦中都優於最先進 (SOTA) 方法。

##### **CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering**
2409.19753v1 by Yike Wu, Yi Huang, Nan Hu, Yuncheng Hua, Guilin Qi, Jiaoyan Chen, Jeff Z. Pan

Recent studies have explored the use of Large Language Models (LLMs) with
Retrieval Augmented Generation (RAG) for Knowledge Graph Question Answering
(KGQA). They typically require rewriting retrieved subgraphs into natural
language formats comprehensible to LLMs. However, when tackling complex
questions, the knowledge rewritten by existing methods may include irrelevant
information, omit crucial details, or fail to align with the question's
semantics. To address them, we propose a novel rewriting method CoTKR,
Chain-of-Thought Enhanced Knowledge Rewriting, for generating reasoning traces
and corresponding knowledge in an interleaved manner, thereby mitigating the
limitations of single-step knowledge rewriting. Additionally, to bridge the
preference gap between the knowledge rewriter and the question answering (QA)
model, we propose a training strategy PAQAF, Preference Alignment from Question
Answering Feedback, for leveraging feedback from the QA model to further
optimize the knowledge rewriter. We conduct experiments using various LLMs
across several KGQA benchmarks. Experimental results demonstrate that, compared
with previous knowledge rewriting methods, CoTKR generates the most beneficial
knowledge representation for QA models, which significantly improves the
performance of LLMs in KGQA.

摘要：近期研究探索了使用大型語言模型 (LLM) 和檢索增強生成 (RAG) 來進行知識圖表問答 (KGQA)。它們通常需要將檢索到的子圖改寫為 LLM 可以理解的自然語言格式。然而，在處理複雜問題時，現有方法改寫的知識可能包含不相關的資訊、遺漏關鍵細節，或無法與問題的語義對齊。為了解決這些問題，我們提出了一種新的改寫方法 CoTKR，即基於思考鏈的知識增強改寫，以交錯的方式生成推理軌跡和對應的知識，從而減輕單步知識改寫的限制。此外，為了彌合知識改寫器和問答 (QA) 模型之間的偏好差距，我們提出了一種訓練策略 PAQAF，即基於問答回饋的偏好對齊，以利用 QA 模型的回饋進一步最佳化知識改寫器。我們使用各種 LLM 在多個 KGQA 基準上進行了實驗。實驗結果表明，與先前的知識改寫方法相比，CoTKR 為 QA 模型生成了最有益的知識表示，這顯著提高了 LLM 在 KGQA 中的效能。

##### **Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models**
2409.19667v1 by Xin Li, Weize Chen, Qizhi Chu, Haopeng Li, Zhaojun Sun, Ran Li, Chen Qian, Yiwei Wei, Zhiyuan Liu, Chuan Shi, Maosong Sun, Cheng Yang

The need to analyze graphs is ubiquitous across various fields, from social
networks to biological research and recommendation systems. Therefore, enabling
the ability of large language models (LLMs) to process graphs is an important
step toward more advanced general intelligence. However, current LLM benchmarks
on graph analysis require models to directly reason over the prompts describing
graph topology, and are thus limited to small graphs with only a few dozens of
nodes. In contrast, human experts typically write programs based on popular
libraries for task solving, and can thus handle graphs with different scales.
To this end, a question naturally arises: can LLMs analyze graphs like
professionals? In this paper, we introduce ProGraph, a manually crafted
benchmark containing 3 categories of graph tasks. The benchmark expects
solutions based on programming instead of directly reasoning over raw inputs.
Our findings reveal that the performance of current LLMs is unsatisfactory,
with the best model achieving only 36% accuracy. To bridge this gap, we propose
LLM4Graph datasets, which include crawled documents and auto-generated codes
based on 6 widely used graph libraries. By augmenting closed-source LLMs with
document retrieval and fine-tuning open-source ones on the codes, we show
11-32% absolute improvements in their accuracies. Our results underscore that
the capabilities of LLMs in handling structured data are still under-explored,
and show the effectiveness of LLM4Graph in enhancing LLMs' proficiency of graph
analysis. The benchmark, datasets and enhanced open-source models are available
at https://github.com/BUPT-GAMMA/ProGraph.

摘要：<paragraph>在從社交網路到生物研究和推薦系統的各種領域中，分析圖形的需求無處不在。因此，賦予大型語言模型 (LLM) 處理圖形的能力，是邁向更先進的通用智慧的重要一步。然而，目前圖形分析上的 LLM 基準要求模型直接對描述圖形拓撲結構的提示進行推理，因此僅限於只有數十個節點的小型圖形。相比之下，人類專家通常會根據流行的函式庫撰寫程式來解決任務，因此可以處理不同規模的圖形。為此，自然會產生一個問題：LLM 能像專業人士一樣分析圖形嗎？在本文中，我們介紹 ProGraph，一個包含 3 類圖形任務的手工製作基準。該基準預期解決方案是基於程式設計，而不是直接對原始輸入進行推理。我們的發現顯示，目前 LLM 的效能並不令人滿意，最佳模型僅達到 36% 的準確度。為了彌補這個差距，我們提出了 LLM4Graph 資料集，其中包含根據 6 個廣泛使用的圖形函式庫爬取的的文件和自動生成的程式碼。透過使用文件檢索來擴充閉源 LLM，並針對程式碼微調開源 LLM，我們展示了準確度提升了 11-32%。我們的結果強調，LLM 在處理結構化資料方面的能力仍未被充分探索，並顯示了 LLM4Graph 在提升 LLM 圖形分析能力方面的有效性。基準、資料集和增強的開源模型可在 https://github.com/BUPT-GAMMA/ProGraph 取得。</paragraph>

##### **Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs**
2409.19401v1 by Zheng Wang, Zhongyang Li, Zeren Jiang, Dandan Tu, Wei Shi

In the age of mobile internet, user data, often referred to as memories, is
continuously generated on personal devices. Effectively managing and utilizing
this data to deliver services to users is a compelling research topic. In this
paper, we introduce a novel task of crafting personalized agents powered by
large language models (LLMs), which utilize a user's smartphone memories to
enhance downstream applications with advanced LLM capabilities. To achieve this
goal, we introduce EMG-RAG, a solution that combines Retrieval-Augmented
Generation (RAG) techniques with an Editable Memory Graph (EMG). This approach
is further optimized using Reinforcement Learning to address three distinct
challenges: data collection, editability, and selectability. Extensive
experiments on a real-world dataset validate the effectiveness of EMG-RAG,
achieving an improvement of approximately 10% over the best existing approach.
Additionally, the personalized agents have been transferred into a real
smartphone AI assistant, which leads to enhanced usability.

摘要：在行動網路時代，使用者資料（常稱為記憶）會持續在個人裝置上產生。有效管理並利用這些資料，為使用者提供服務，是一個引人入勝的研究主題。在本文中，我們介紹了一項創新的任務，即利用大型語言模型（LLM）打造個人化代理，利用使用者的智慧型手機記憶體，以進階 LLM 功能強化下游應用程式。為了達成這個目標，我們介紹了 EMG-RAG，一種結合檢索擴充生成（RAG）技術與可編輯記憶圖（EMG）的解決方案。這種方法進一步透過強化學習進行最佳化，以解決三個不同的挑戰：資料收集、可編輯性與可選擇性。在真實世界資料集上的廣泛實驗驗證了 EMG-RAG 的有效性，比現有最佳方法提升了約 10%。此外，個人化代理已轉移到真正的智慧型手機 AI 助理中，這提升了可用性。

##### **CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting**
2409.19058v1 by Haobo Li, Zhaowei Wang, Jiachen Wang, Alexis Kai Hon Lau, Huamin Qu

Forecasting weather and climate events is crucial for making appropriate
measures to mitigate environmental hazards and minimize associated losses.
Previous research on environmental forecasting focuses on predicting numerical
meteorological variables related to closed-set events rather than forecasting
open-set events directly, which limits the comprehensiveness of event
forecasting. We propose Weather and Climate Event Forecasting (WCEF), a new
task that leverages meteorological raster data and textual event data to
predict potential weather and climate events. However, due to difficulties in
aligning multimodal data and the lack of sufficient supervised datasets, this
task is challenging to accomplish. Therefore, we first propose a framework to
align historical meteorological data with past weather and climate events using
the large language model (LLM). In this framework, we construct a knowledge
graph by using LLM to extract information about weather and climate events from
a corpus of over 41k highly environment-focused news articles. Subsequently, we
mapped these events with meteorological raster data, creating a supervised
dataset, which is the largest and most novel for LLM tuning on the WCEF task.
Finally, we introduced our aligned models, CLLMate (LLM for climate), a
multimodal LLM to forecast weather and climate events using meteorological
raster data. In evaluating CLLMate, we conducted extensive experiments. The
results indicate that CLLMate surpasses both the baselines and other multimodal
LLMs, showcasing the potential of utilizing LLM to align weather and climate
events with meteorological data and highlighting the promising future for
research on the WCEF task.

摘要：預測天氣和氣候事件對於採取適當措施減輕環境危害和將相關損失降至最低至關重要。
先前有關環境預測的研究著重於預測與封閉集事件相關的數值氣象變數，而非直接預測開放集事件，這限制了事件預測的全面性。
我們提出天氣和氣候事件預測 (WCEF)，這是一項利用氣象柵格資料和文字事件資料來預測潛在天氣和氣候事件的新任務。
然而，由於多模態資料對齊的困難以及缺乏足夠的監督式資料集，因此此任務難以達成。
因此，我們首先提出一個架構，使用大型語言模型 (LLM) 將歷史氣象資料與過去的天氣和氣候事件對齊。
在此架構中，我們透過使用 LLM 從超過 41,000 篇高度關注環境的新聞文章中擷取有關天氣和氣候事件的資訊來建構知識圖譜。
隨後，我們將這些事件對應到氣象柵格資料，建立一個監督式資料集，這是 LLM 在 WCEF 任務上調整中最大且最新穎的資料集。
最後，我們引入了我們的對齊模型，CLLMate（氣候的 LLM），這是一個多模態 LLM，使用氣象柵格資料來預測天氣和氣候事件。
在評估 CLLMate 時，我們進行了大量的實驗。
結果表明，CLLMate 超越了基準和其他的多模態 LLM，展示了利用 LLM 將天氣和氣候事件與氣象資料對齊的潛力，並強調了 WCEF 任務研究的未來前景。

##### **AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**
2409.18924v1 by Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan

Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p<0.1), and stability (ANOVA F-value
0.782, p<0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.

摘要：<paragraph>模擬病人系統在現代醫學教育和研究中扮演著至關重要的角色，提供安全、整合的學習環境，並支援臨床決策模擬。大型語言模型 (LLM) 能夠複製醫療狀況和醫病互動，進而以高保真度和低成本提升模擬病人系統。然而，確保這些系統的有效性和可信度仍然是一項挑戰，因為它們需要一個龐大、多元且精確的病人知識庫，以及一種強健且穩定的知識傳播方式。在此，我們開發了 AIPatient，一個進階的模擬病人系統，其以 AIPatient 知識圖譜 (AIPatient KG) 作為輸入，並以推理檢索增強生成 (Reasoning RAG) 代理工作流程作為生成主幹。AIPatient KG 從密集照護醫學資訊市集 (MIMIC)-III 資料庫中的電子健康紀錄 (EHR) 中抽取資料，產生一個臨床多元且相關的 1,495 位病患群組，且具有高度的知識庫有效性 (F1 0.89)。Reasoning RAG 運用六個 LLM 驅動的代理，涵蓋檢索、KG 查詢生成、抽象化、檢查器、重寫和摘要等任務。此代理架構在基於 EHR 的醫療問答 (QA) 中達到 94.15% 的整體準確度，優於未使用代理或僅部分整合代理的基準。我們的系統還具備高度可讀性 (中位數 Flesch 閱讀簡易度 77.23；中位數 Flesch Kincaid 等級 5.6)、強健性 (ANOVA F 值 0.6126，p<0.1) 和穩定性 (ANOVA F 值 0.782，p<0.1)。AIPatient 系統令人滿意的效能突顯了其支援廣泛應用程式的潛力，包括醫學教育、模型評估和系統整合。</paragraph>

##### **Soft Measures for Extracting Causal Collective Intelligence**
2409.18911v1 by Maryam Berijanian, Spencer Dork, Kuldeep Singh, Michael Riley Millikan, Ashlin Riggs, Aadarsh Swaminathan, Sarah L. Gibbs, Scott E. Friedman, Nathan Brugnone

Understanding and modeling collective intelligence is essential for
addressing complex social systems. Directed graphs called fuzzy cognitive maps
(FCMs) offer a powerful tool for encoding causal mental models, but extracting
high-integrity FCMs from text is challenging. This study presents an approach
using large language models (LLMs) to automate FCM extraction. We introduce
novel graph-based similarity measures and evaluate them by correlating their
outputs with human judgments through the Elo rating system. Results show
positive correlations with human evaluations, but even the best-performing
measure exhibits limitations in capturing FCM nuances. Fine-tuning LLMs
improves performance, but existing measures still fall short. This study
highlights the need for soft similarity measures tailored to FCM extraction,
advancing collective intelligence modeling with NLP.

摘要：了解和建模集体智慧对于解决复杂的社会系统至关重要。称为模糊认知图（FCM）的有向图提供了一种强大的工具来编码因果心智模型，但从文本中提取高完整性的 FCM 具有挑战性。本研究提出了一种使用大型语言模型（LLM）来自动化 FCM 提取的方法。我们引入了新颖的基于图的相似性度量，并通过通过 Elo 评级系统将其输出与人类判断相关联来评估它们。结果表明与人类评估呈正相关，但即使是表现最好的度量在捕捉 FCM 细微差别方面也表现出局限性。微调 LLM 可以提高性能，但现有措施仍然不足。本研究强调了针对 FCM 提取量身定制的软相似性度量的必要性，通过 NLP 推进了集体智能建模。

##### **OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph**
2409.18743v1 by Yujie Tang, Meiling Wang, Yinan Deng, Zibo Zheng, Jiagui Zhong, Yufeng Yue

In everyday life, frequently used objects like cups often have unfixed
positions and multiple instances within the same category, and their carriers
frequently change as well. As a result, it becomes challenging for a robot to
efficiently navigate to a specific instance. To tackle this challenge, the
robot must capture and update scene changes and plans continuously. However,
current object navigation approaches primarily focus on semantic-level and lack
the ability to dynamically update scene representation. This paper captures the
relationships between frequently used objects and their static carriers. It
constructs an open-vocabulary Carrier-Relationship Scene Graph (CRSG) and
updates the carrying status during robot navigation to reflect the dynamic
changes of the scene. Based on the CRSG, we further propose an instance
navigation strategy that models the navigation process as a Markov Decision
Process. At each step, decisions are informed by Large Language Model's
commonsense knowledge and visual-language feature similarity. We designed a
series of long-sequence navigation tasks for frequently used everyday items in
the Habitat simulator. The results demonstrate that by updating the CRSG, the
robot can efficiently navigate to moved targets. Additionally, we deployed our
algorithm on a real robot and validated its practical effectiveness.

摘要：日常生活中，經常使用的物品（例如杯子）通常沒有固定的位置，而且同一類別中有多個實例，其承載者也經常變更。因此，機器人要有效地導航到特定實例變得具有挑戰性。為了應對這一挑戰，機器人必須不斷捕捉和更新場景變更和計畫。然而，目前的物件導航方法主要集中在語義層級，並且缺乏動態更新場景表示的能力。本文捕捉了經常使用的物件及其靜態承載者之間的關係。它構建了一個開放詞彙的承載者關係場景圖 (CRSG)，並在機器人導航期間更新承載狀態以反映場景的動態變化。基於 CRSG，我們進一步提出了一種將導航過程建模為馬可夫決策過程的實例導航策略。在每一步中，決策都由大型語言模型的常識知識和視覺語言特徵相似性來告知。我們為 Habitat 模擬器中的日常常用物品設計了一系列長序列導航任務。結果表明，通過更新 CRSG，機器人可以有效地導航到移動的目標。此外，我們在真實機器人上部署了我們的演算法，並驗證了其實際效能。

##### **Rehearsing Answers to Probable Questions with Perspective-Taking**
2409.18678v1 by Yung-Yu Shih, Ziwei Xu, Hiroya Takamura, Yun-Nung Chen, Chung-Chi Chen

Question answering (QA) has been a long-standing focus in the NLP field,
predominantly addressing reading comprehension and common sense QA. However,
scenarios involving the preparation of answers to probable questions during
professional oral presentations remain underexplored. In this paper, we pioneer
the examination of this crucial yet overlooked topic by utilizing real-world QA
conversation transcripts between company managers and professional analysts. We
explore the proposed task using three causal knowledge graphs (KGs) and three
large language models (LLMs). This work provides foundational insights into the
application of LLMs in professional QA scenarios, highlighting the importance
of causal KGs and perspective-taking in generating effective responses.

摘要：問題解答 (QA) 一直是自然語言處理 (NLP) 領域的長期關注重點，
主要解決閱讀理解和常識問題解答。然而，
在專業口頭簡報中準備回答可能問題的場景仍未得到充分探討。在本文中，我們率先
利用公司經理和專業分析師之間的真實世界問答對話記錄，探討這個至關重要但被忽視的主題。我們
使用三個因果知識圖譜 (KG) 和三個大型語言模型 (LLM) 來探討提出的任務。這項工作為 LLM 在專業問答場景中的應用提供了基礎見解，強調了因果 KG 和觀點採取在產生有效回應中的重要性。

##### **LowREm: A Repository of Word Embeddings for 87 Low-Resource Languages Enhanced with Multilingual Graph Knowledge**
2409.18193v1 by Daniil Gurgurov, Rishu Kumar, Simon Ostermann

Contextualized embeddings based on large language models (LLMs) are available
for various languages, but their coverage is often limited for lower resourced
languages. Training LLMs for such languages is often difficult due to
insufficient data and high computational cost. Especially for very low resource
languages, static word embeddings thus still offer a viable alternative. There
is, however, a notable lack of comprehensive repositories with such embeddings
for diverse languages. To address this, we present LowREm, a centralized
repository of static embeddings for 87 low-resource languages. We also propose
a novel method to enhance GloVe-based embeddings by integrating multilingual
graph knowledge, utilizing another source of knowledge. We demonstrate the
superior performance of our enhanced embeddings as compared to contextualized
embeddings extracted from XLM-R on sentiment analysis. Our code and data are
publicly available under https://huggingface.co/DFKI.

摘要：基於大型語言模型 (LLM) 的語境化嵌入可供各種語言使用，但其涵蓋範圍通常僅限於資源較少的語言。由於資料不足和高運算成本，為此類語言訓練 LLM 通常很困難。特別是對於資源非常少的語言，因此靜態字詞嵌入仍提供可行的替代方案。然而，對於各種語言來說，此類嵌入缺乏全面的儲存庫。為了解決這個問題，我們提出了 LowREm，一個針對 87 種低資源語言的靜態嵌入集中式儲存庫。我們還提出了一種新方法，透過整合多語言圖形知識來增強基於 GloVe 的嵌入，利用另一個知識來源。我們展示了我們增強的嵌入在情緒分析上優於從 XLM-R 提取的語境化嵌入。我們的程式碼和資料已公開在 https://huggingface.co/DFKI 下。

##### **Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study**
2409.17580v1 by Zahra Sepasdar, Sushant Gautam, Cise Midoglu, Michael A. Riegler, Pål Halvorsen

Extracting meaningful insights from large and complex datasets poses
significant challenges, particularly in ensuring the accuracy and relevance of
retrieved information. Traditional data retrieval methods such as sequential
search and index-based retrieval often fail when handling intricate and
interconnected data structures, resulting in incomplete or misleading outputs.
To overcome these limitations, we introduce Structured-GraphRAG, a versatile
framework designed to enhance information retrieval across structured datasets
in natural language queries. Structured-GraphRAG utilizes multiple knowledge
graphs, which represent data in a structured format and capture complex
relationships between entities, enabling a more nuanced and comprehensive
retrieval of information. This graph-based approach reduces the risk of errors
in language model outputs by grounding responses in a structured format,
thereby enhancing the reliability of results. We demonstrate the effectiveness
of Structured-GraphRAG by comparing its performance with that of a recently
published method using traditional retrieval-augmented generation. Our findings
show that Structured-GraphRAG significantly improves query processing
efficiency and reduces response times. While our case study focuses on soccer
data, the framework's design is broadly applicable, offering a powerful tool
for data analysis and enhancing language model applications across various
structured domains.

摘要：從龐大且複雜的資料集中萃取出有意義的見解會帶來顯著的挑戰，特別是在確保擷取資訊的準確性和相關性方面。傳統的資料擷取方法，例如順序搜尋和基於索引的擷取，在處理複雜且相互連結的資料結構時，常常會失敗，導致不完整或誤導性的輸出。為了克服這些限制，我們引入了結構化圖形 RAG，這是一個通用框架，旨在增強自然語言查詢中結構化資料集的資訊擷取。結構化圖形 RAG 利用多個知識圖形，它們以結構化格式表示資料，並擷取實體之間的複雜關係，從而實現更細緻且全面的資訊擷取。這種基於圖形的做法透過以結構化格式為基礎回應，降低語言模型輸出中出現錯誤的風險，從而提高結果的可靠性。我們透過將結構化圖形 RAG 的效能與最近發表的傳統擷取增強生成方法進行比較，來證明其有效性。我們的研究結果顯示，結構化圖形 RAG 大幅提升了查詢處理效率，並縮短了回應時間。雖然我們的案例研究專注於足球資料，但這個架構的設計具有廣泛的適用性，提供了一個強大的資料分析工具，並增強了各種結構化領域的語言模型應用。

##### **Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**
2409.16707v1 by Juliette Faille, Albert Gatt, Claire Gardent

In Natural Language Generation (NLG), important information is sometimes
omitted in the output text. To better understand and analyse how this type of
mistake arises, we focus on RDF-to-Text generation and explore two methods of
probing omissions in the encoder output of BART (Lewis et al, 2020) and of T5
(Raffel et al, 2019): (i) a novel parameter-free probing method based on the
computation of cosine similarity between embeddings of RDF graphs and of RDF
graphs in which we removed some entities and (ii) a parametric probe which
performs binary classification on the encoder embeddings to detect omitted
entities. We also extend our analysis to distorted entities, i.e. entities that
are not fully correctly mentioned in the generated text (e.g. misspelling of
entity, wrong units of measurement). We found that both omitted and distorted
entities can be probed in the encoder's output embeddings. This suggests that
the encoder emits a weaker signal for these entities and therefore is
responsible for some loss of information. This also shows that probing methods
can be used to detect mistakes in the output of NLG models.

摘要：在自然語言生成 (NLG) 中，重要資訊有時會在輸出文字中被省略。為了更了解並分析這類錯誤是如何產生的，我們專注於 RDF 轉文字的生成，並探討兩種探測 BART (Lewis 等人，2020) 和 T5 (Raffel 等人，2019) 的編碼器輸出中遺漏的方法：(i) 一種基於 RDF 圖形嵌入和我們移除一些實體的 RDF 圖形之間的餘弦相似度計算的新型無參數探測方法，以及 (ii) 一種在編碼器嵌入中執行二元分類以偵測遺漏實體的參數化探測。我們也將我們的分析延伸到扭曲的實體，也就是在產生的文字中沒有被完全正確提及的實體 (例如實體拼寫錯誤、測量單位錯誤)。我們發現遺漏和扭曲的實體都可以被探測到在編碼器的輸出嵌入中。這表示編碼器針對這些實體發射較弱的訊號，因此導致一些資訊遺失。這也顯示探測方法可以用於偵測 NLG 模型輸出中的錯誤。

##### **GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**
2409.16670v1 by Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu

Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in
handling a range of graph analytical tasks across various domains, such as
e-commerce and social networks. Despite their versatility, GNNs face
significant challenges in transferability, limiting their utility in real-world
applications. Existing research in GNN transfer learning overlooks
discrepancies in distribution among various graph datasets, facing challenges
when transferring across different distributions. How to effectively adopt a
well-trained GNN to new graphs with varying feature and structural
distributions remains an under-explored problem. Taking inspiration from the
success of Low-Rank Adaptation (LoRA) in adapting large language models to
various domains, we propose GraphLoRA, an effective and parameter-efficient
method for transferring well-trained GNNs to diverse graph domains.
Specifically, we first propose a Structure-aware Maximum Mean Discrepancy
(SMMD) to align divergent node feature distributions across source and target
graphs. Moreover, we introduce low-rank adaptation by injecting a small
trainable GNN alongside the pre-trained one, effectively bridging structural
distribution gaps while mitigating the catastrophic forgetting. Additionally, a
structure-aware regularization objective is proposed to enhance the
adaptability of the pre-trained GNN to target graph with scarce supervision
labels. Extensive experiments on six real-world datasets demonstrate the
effectiveness of GraphLoRA against eleven baselines by tuning only 20% of
parameters, even across disparate graph domains. The code is available at
https://anonymous.4open.science/r/GraphLoRA.

摘要：圖形神經網路 (GNN) 已展現出在各種領域處理一系列圖形分析任務的卓越能力，例如電子商務和社群網路。儘管 GNN 具有多功能性，但在可轉移性方面仍面臨重大挑戰，限制了它們在現實世界應用中的效用。現有的 GNN 轉移學習研究忽視了各種圖形資料集之間的分布差異，在跨不同分布轉移時面臨挑戰。如何有效地將訓練良好的 GNN 應用於具有不同特徵和結構分布的新圖形，仍然是一個尚未充分探討的問題。從低秩適應 (LoRA) 在將大型語言模型適應到各種領域方面獲得的成功中汲取靈感，我們提出了 GraphLoRA，這是一種有效且參數效率高的方法，可用於將訓練良好的 GNN 轉移到不同的圖形領域。具體來說，我們首先提出一個結構感知最大平均差異 (SMMD) 來調整來源和目標圖形中的不同節點特徵分布。此外，我們通過在預先訓練的 GNN 旁邊注入一個小的可訓練 GNN 來引入低秩適應，從而有效地彌合結構分布差距，同時減輕災難性遺忘。此外，還提出了結構感知正則化目標，以增強預先訓練的 GNN 對具有稀疏監督標籤的目標圖形的適應性。在六個真實世界資料集上的大量實驗證明了 GraphLoRA 的有效性，它僅調整了 20% 的參數，即使在不同的圖形領域中也能夠勝過十一種基準。程式碼可在 https://anonymous.4open.science/r/GraphLoRA 取得。

##### **Cyber Knowledge Completion Using Large Language Models**
2409.16176v1 by Braden K Webb, Sumit Purohit, Rounak Meyur

The integration of the Internet of Things (IoT) into Cyber-Physical Systems
(CPSs) has expanded their cyber-attack surface, introducing new and
sophisticated threats with potential to exploit emerging vulnerabilities.
Assessing the risks of CPSs is increasingly difficult due to incomplete and
outdated cybersecurity knowledge. This highlights the urgent need for
better-informed risk assessments and mitigation strategies. While previous
efforts have relied on rule-based natural language processing (NLP) tools to
map vulnerabilities, weaknesses, and attack patterns, recent advancements in
Large Language Models (LLMs) present a unique opportunity to enhance
cyber-attack knowledge completion through improved reasoning, inference, and
summarization capabilities. We apply embedding models to encapsulate
information on attack patterns and adversarial techniques, generating mappings
between them using vector embeddings. Additionally, we propose a
Retrieval-Augmented Generation (RAG)-based approach that leverages pre-trained
models to create structured mappings between different taxonomies of threat
patterns. Further, we use a small hand-labeled dataset to compare the proposed
RAG-based approach to a baseline standard binary classification model. Thus,
the proposed approach provides a comprehensive framework to address the
challenge of cyber-attack knowledge graph completion.

摘要：物聯網 (IoT) 與網路實體系統 (CPS) 的整合擴大了其網路攻擊面，引入了新的和複雜的威脅，具有利用新興漏洞的潛力。由於網路安全知識不完整且過時，評估 CPS 的風險變得越來越困難。這突顯了迫切需要更完善的風險評估和緩解策略。雖然先前的努力依賴於基於規則的自然語言處理 (NLP) 工具來繪製漏洞、弱點和攻擊模式，但大型語言模型 (LLM) 的最新進展提供了一個獨特的機會，可以透過改進的推理、推論和摘要能力來增強網路攻擊知識的完成度。我們應用嵌入模型來封裝有關攻擊模式和對抗技術的資訊，使用向量嵌入在它們之間產生對應關係。此外，我們提出了一個基於檢索增強生成 (RAG) 的方法，該方法利用預先訓練的模型在威脅模式的不同分類法之間建立結構化的對應關係。此外，我們使用一個小型的手動標記資料集來比較所提出的基於 RAG 的方法與基線標準二元分類模型。因此，所提出的方法提供了一個全面的架構來解決網路攻擊知識圖完成的挑戰。

##### **Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**
2409.15902v1 by Maria Lysyuk, Mikhail Salnikov, Pavel Braslavski, Alexander Panchenko

While being one of the most popular question types, simple questions such as
"Who is the author of Cinderella?", are still not completely solved.
Surprisingly, even the most powerful modern Large Language Models are prone to
errors when dealing with such questions, especially when dealing with rare
entities. At the same time, as an answer may be one hop away from the question
entity, one can try to develop a method that uses structured knowledge graphs
(KGs) to answer such questions. In this paper, we introduce Konstruktor - an
efficient and robust approach that breaks down the problem into three steps:
(i) entity extraction and entity linking, (ii) relation prediction, and (iii)
querying the knowledge graph. Our approach integrates language models and
knowledge graphs, exploiting the power of the former and the interpretability
of the latter. We experiment with two named entity recognition and entity
linking methods and several relation detection techniques. We show that for
relation detection, the most challenging step of the workflow, a combination of
relation classification/generation and ranking outperforms other methods. We
report Konstruktor's strong results on four datasets.

摘要：儘管是最常見的問題類型之一，但諸如「灰姑娘的作者是誰？」這類簡單的問題仍未完全獲得解答。令人驚訝的是，即使是最強大的現代大型語言模型在處理此類問題時也容易出錯，特別是在處理罕見實體時。與此同時，由於答案可能距離問題實體僅一步之遙，因此可以嘗試開發一種使用結構化知識圖譜 (KG) 來回答此類問題的方法。在本文中，我們介紹 Konstruktor - 一種高效且強大的方法，它將問題分解為三個步驟：(i) 實體萃取和實體連結、(ii) 關係預測以及 (iii) 查詢知識圖譜。我們的做法整合了語言模型和知識圖譜，發揮了前者的能力和後者的可解釋性。我們實驗了兩種命名實體識別和實體連結方法以及多種關係偵測技術。我們表明，對於關係偵測，也就是工作流程中最具挑戰性的步驟，關係分類/生成和排名相結合的組合優於其他方法。我們報告了 Konstruktor 在四個資料集上的強勁成果。

##### **Symmetries and Expressive Requirements for Learning General Policies**
2409.15892v1 by Dominik Drexler, Simon Ståhlberg, Blai Bonet, Hector Geffner

State symmetries play an important role in planning and generalized planning.
In the first case, state symmetries can be used to reduce the size of the
search; in the second, to reduce the size of the training set. In the case of
general planning, however, it is also critical to distinguish non-symmetric
states, i.e., states that represent non-isomorphic relational structures.
However, while the language of first-order logic distinguishes non-symmetric
states, the languages and architectures used to represent and learn general
policies do not. In particular, recent approaches for learning general policies
use state features derived from description logics or learned via graph neural
networks (GNNs) that are known to be limited by the expressive power of C_2,
first-order logic with two variables and counting. In this work, we address the
problem of detecting symmetries in planning and generalized planning and use
the results to assess the expressive requirements for learning general policies
over various planning domains. For this, we map planning states to plain
graphs, run off-the-shelf algorithms to determine whether two states are
isomorphic with respect to the goal, and run coloring algorithms to determine
if C_2 features computed logically or via GNNs distinguish non-isomorphic
states. Symmetry detection results in more effective learning, while the
failure to detect non-symmetries prevents general policies from being learned
at all in certain domains.

摘要：狀態對稱性在規劃和廣義規劃中扮演著重要的角色。
在第一種情況中，狀態對稱性可用於縮小搜尋的規模；在第二種情況中，可用於縮小訓練集的規模。然而，在廣義規劃的情況中，區分非對稱狀態（即表示非同構關係結構的狀態）也很重要。然而，雖然一階邏輯的語言區分了非對稱狀態，但用於表示和學習一般策略的語言和架構卻沒有。特別是，最近用於學習一般策略的方法使用從描述邏輯中衍生的狀態特徵，或通過圖神經網路 (GNN) 學習，已知這些特徵受到具有兩個變數和計數的一階邏輯 C_2 的表達能力限制。在這項工作中，我們解決了在規劃和廣義規劃中檢測對稱性的問題，並使用結果評估在各種規劃領域中學習一般策略的表達需求。為此，我們將規劃狀態映射到平面圖形，執行現成的演算法來確定兩個狀態是否相對於目標同構，並執行著色演算法來確定透過邏輯或 GNN 計算的 C_2 特徵是否區分非同構狀態。對稱性檢測會帶來更有效的學習，而無法檢測非對稱性則會完全阻止在某些領域中學習一般策略。

##### **GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**
2409.15566v1 by Brendan Hogan Rappazzo, Yingheng Wang, Aaron Ferber, Carla Gomes

The ability to form, retrieve, and reason about memories in response to
stimuli serves as the cornerstone for general intelligence - shaping entities
capable of learning, adaptation, and intuitive insight. Large Language Models
(LLMs) have proven their ability, given the proper memories or context, to
reason and respond meaningfully to stimuli. However, they are still unable to
optimally encode, store, and retrieve memories - the ability to do this would
unlock their full ability to operate as AI agents, and to specialize to niche
domains. To remedy this, one promising area of research is Retrieval Augmented
Generation (RAG), which aims to augment LLMs by providing them with rich
in-context examples and information. In question-answering (QA) applications,
RAG methods embed the text of interest in chunks, and retrieve the most
relevant chunks for a prompt using text embeddings. Motivated by human memory
encoding and retrieval, we aim to improve over standard RAG methods by
generating and encoding higher-level information and tagging the chunks by
their utility to answer questions. We introduce Graphical Eigen Memories For
Retrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk
of text in a given text corpus with LLM generated ``utility'' questions,
connecting chunks in a graph based on the similarity of both their text and
utility questions, and then using the eigendecomposition of the memory graph to
build higher level summary nodes that capture the main themes of the text. We
evaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with
SBERT, and OpenAI's text encoders on two standard QA tasks, showing that
GEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also
discuss the implications of having a robust RAG system and future directions.

摘要：<paragraph>根據刺激形成、檢索和推理記憶的能力是通用智慧的基石，塑造了具備學習、適應和直覺洞察力的實體。大型語言模型 (LLM) 已證明其能力，在適當的記憶或背景下，對刺激進行推理和有意義地回應。然而，它們仍然無法最佳地編碼、儲存和檢索記憶，執行此操作的能力將解鎖它們作為 AI 代理運作並專門化為利基領域的全部能力。為了補救此問題，一個有前景的研究領域是檢索增強生成 (RAG)，其目標是透過提供豐富的上下文範例和資訊來擴充 LLM。在問答 (QA) 應用程式中，RAG 方法將感興趣的文字分塊嵌入，並使用文字嵌入為提示檢索最相關的區塊。受人類記憶編碼和檢索的啟發，我們旨在透過產生和編碼更高級別的資訊並根據區塊回答問題的效用標記區塊，從而改進標準 RAG 方法。我們引入了用於檢索增強生成的圖形特徵記憶 (GEM-RAG)。GEM-RAG 的工作原理是使用 LLM 生成的「效用」問題標記給定文字語料庫中每個文字區塊，根據文字和效用問題的相似性將區塊連接在圖形中，然後使用記憶圖形的特徵分解來建立擷取文字主題的高階摘要節點。我們使用 UnifiedQA 和 GPT-3.5 Turbo 作為 LLM，以及 SBERT 和 OpenAI 的文字編碼器，在兩個標準 QA 任務中評估 GEM-RAG，顯示 GEM-RAG 在這些任務中優於其他最先進的 RAG 方法。我們還討論了擁有強大的 RAG 系統的含意和未來的方向。</paragraph>

##### **KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems**
2409.14908v1 by Zixuan Wang, Bo Yu, Junzhe Zhao, Wenhao Sun, Sai Hou, Shuai Liang, Xing Hu, Yinhe Han, Yiming Gan

Embodied AI agents responsible for executing interconnected, long-sequence
household tasks often face difficulties with in-context memory, leading to
inefficiencies and errors in task execution. To address this issue, we
introduce KARMA, an innovative memory system that integrates long-term and
short-term memory modules, enhancing large language models (LLMs) for planning
in embodied agents through memory-augmented prompting. KARMA distinguishes
between long-term and short-term memory, with long-term memory capturing
comprehensive 3D scene graphs as representations of the environment, while
short-term memory dynamically records changes in objects' positions and states.
This dual-memory structure allows agents to retrieve relevant past scene
experiences, thereby improving the accuracy and efficiency of task planning.
Short-term memory employs strategies for effective and adaptive memory
replacement, ensuring the retention of critical information while discarding
less pertinent data. Compared to state-of-the-art embodied agents enhanced with
memory, our memory-augmented embodied AI agent improves success rates by 1.3x
and 2.3x in Composite Tasks and Complex Tasks within the AI2-THOR simulator,
respectively, and enhances task execution efficiency by 3.4x and 62.7x.
Furthermore, we demonstrate that KARMA's plug-and-play capability allows for
seamless deployment on real-world robotic systems, such as mobile manipulation
platforms.Through this plug-and-play memory system, KARMA significantly
enhances the ability of embodied agents to generate coherent and contextually
appropriate plans, making the execution of complex household tasks more
efficient. The experimental videos from the work can be found at
https://youtu.be/4BT7fnw9ehs.

摘要：負責執行相互連接的長序列家庭任務的具身化 AI 代理經常面臨情境記憶的困難，導致任務執行效率低下和錯誤。為了解決這個問題，我們引入了 KARMA，這是一個創新的記憶系統，它整合了長期和短期記憶模組，透過記憶增強提示，增強具身化代理中用於規劃的大語言模型 (LLM)。KARMA 區分長期和短期記憶，長期記憶擷取全面的 3D 場景圖形作為環境的表示，而短期記憶則動態記錄物件位置和狀態的變化。這種雙重記憶結構允許代理擷取相關的過去場景經驗，從而提高任務規劃的準確性和效率。短期記憶採用策略來進行有效和適應性的記憶替換，確保保留關鍵資訊，同時捨棄較不相關的資料。與具備增強記憶功能的最新具身化代理相比，我們的記憶增強具身化 AI 代理在 AI2-THOR 模擬器中的複合任務和複雜任務中，分別將成功率提高了 1.3 倍和 2.3 倍，並將任務執行效率提高了 3.4 倍和 62.7 倍。此外，我們證明了 KARMA 的即插即用功能允許在真實世界的機器人系統上進行無縫部署，例如行動操作平台。透過這個即插即用記憶系統，KARMA 大幅增強了具身化代理產生一致且符合情境的計畫的能力，使複雜家庭任務的執行更有效率。這項工作的實驗影片可以在 https://youtu.be/4BT7fnw9ehs 找到。

##### **End-to-End Graph Flattening Method for Large Language Models**
2409.14880v1 by Bin Hong, Jinze Wu, Jiayu Liu, Liang Ding, Jing Sha, Kai Zhang, Shijin Wang, Zhenya Huang

In recent years, the breakthrough of Large Language Models (LLMs) offers new
ideas for achieving universal methods on graph data. The common practice of
converting graphs into natural language for LLMs, which refers to graph
flattening, exhibits good generalizability and interpretability. However, the
poor organization of the textual format results in poor performance in
long-distance scenario understanding. Inspired by human cognitive reasoning
habits, we propose a novel method for graph flattening to fit LLMs, termed as
End-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show
that EEDP enhances the reasoning performance of LLMs in long-distance scenarios
while maintaining excellent performance in short-distance scenarios,
demonstrating good robustness in the face of distance variations.

摘要：近年來，大型語言模型 (LLM) 的突破為在圖形資料中達成通用方法提供了新想法。將圖形轉換為自然語言以供 LLM 使用的常見做法，即圖形扁平化，展現出良好的通用性和可解釋性。然而，文本格式組織不佳導致在長距離場景理解中表現不佳。受到人類認知推理習慣的啟發，我們提出了一種新穎的方法來進行圖形扁平化以配合 LLM，稱為端到端 DAG 路徑提示 (EEDP)。在真實世界資料集上的實驗表明，EEDP 增強了 LLM 在長距離場景中的推理性能，同時在短距離場景中保持了出色的性能，在面對距離變化時表現出良好的魯棒性。

##### **RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph**
2409.14556v1 by Linxi Wei, Guorui Xiao, Magdalena Balazinska

As an important component of data exploration and integration, Column Type
Annotation (CTA) aims to label columns of a table with one or more semantic
types. With the recent development of Large Language Models (LLMs), researchers
have started to explore the possibility of using LLMs for CTA, leveraging their
strong zero-shot capabilities. In this paper, we build on this promising work
and improve on LLM-based methods for CTA by showing how to use a Knowledge
Graph (KG) to augment the context information provided to the LLM. Our
approach, called RACOON, combines both pre-trained parametric and
non-parametric knowledge during generation to improve LLMs' performance on CTA.
Our experiments show that RACOON achieves up to a 0.21 micro F-1 improvement
compared against vanilla LLM inference.

摘要：作為資料探勘與整合的重要組成部分，欄位類型註解 (CTA) 的目標是使用一個或多個語意類型標記表格欄位。隨著大型語言模型 (LLM) 的近期發展，研究人員已開始探討使用 LLM 來進行 CTA 的可能性，並利用其強大的零次學習能力。在本文中，我們建立在這個有前景的研究上，並透過展示如何使用知識圖譜 (KG) 來擴充提供給 LLM 的脈絡資訊，進而改善基於 LLM 的 CTA 方法。我們的方法稱為 RACOON，它在生成過程中結合預先訓練的參數式和非參數式知識，以改善 LLM 在 CTA 上的效能。我們的實驗顯示，與純粹的 LLM 推論相比，RACOON 在微型 F-1 上的進步高達 0.21。

##### **Graph Neural Network Framework for Sentiment Analysis Using Syntactic Feature**
2409.14000v1 by Linxiao Wu, Yuanshuai Luo, Binrong Zhu, Guiran Liu, Rui Wang, Qian Yu

Amidst the swift evolution of social media platforms and e-commerce
ecosystems, the domain of opinion mining has surged as a pivotal area of
exploration within natural language processing. A specialized segment within
this field focuses on extracting nuanced evaluations tied to particular
elements within textual contexts. This research advances a composite framework
that amalgamates the positional cues of topical descriptors. The proposed
system converts syntactic structures into a matrix format, leveraging
convolutions and attention mechanisms within a graph to distill salient
characteristics. Incorporating the positional relevance of descriptors relative
to lexical items enhances the sequential integrity of the input. Trials have
substantiated that this integrated graph-centric scheme markedly elevates the
efficacy of evaluative categorization, showcasing preeminence.

摘要：隨著社群媒體平台和電子商務生態系統的快速演進，意見探勘領域已成為自然語言處理中一項關鍵的探索領域。此領域中的專門區塊著重於從文字脈絡中的特定元素中萃取出細微的評價。本研究提出一個複合架構，將主題描述詞的位置線索合併在一起。所提出的系統將句法結構轉換成矩陣格式，並在圖形中運用卷積和注意力機制來萃取出顯著特徵。納入描述詞相對於詞彙項目的位置相關性，可強化輸入的順序完整性。試驗證實，這種整合圖形為中心的架構顯著提升了評估分類的效能，展現出卓越性。

##### **ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources**
2409.13537v1 by Shuting Yang, Zehui Liu, Wolfgang Mayer

Recent developments in large language models (LLMs) have led to significant
improvements in intelligent dialogue systems'ability to handle complex
inquiries. However, current LLMs still exhibit limitations in specialized
domain knowledge, particularly in technical fields such as agriculture. To
address this problem, we propose ShizishanGPT, an intelligent question
answering system for agriculture based on the Retrieval Augmented Generation
(RAG) framework and agent architecture. ShizishanGPT consists of five key
modules: including a generic GPT-4 based module for answering general
questions; a search engine module that compensates for the problem that the
large language model's own knowledge cannot be updated in a timely manner; an
agricultural knowledge graph module for providing domain facts; a retrieval
module which uses RAG to supplement domain knowledge; and an agricultural agent
module, which invokes specialized models for crop phenotype prediction, gene
expression analysis, and so on. We evaluated the ShizishanGPT using a dataset
containing 100 agricultural questions specially designed for this study. The
experimental results show that the tool significantly outperforms general LLMs
as it provides more accurate and detailed answers due to its modular design and
integration of different domain knowledge sources. Our source code, dataset,
and model weights are publicly available at https://github.com/Zaiwen/CropGPT.

摘要：近來大型語言模型（LLM）的發展，大幅提升了智慧對話系統處理複雜詢問的能力。然而，現有的 LLM 仍展現出在專業領域知識的限制，特別是在農業等技術領域。為了解決這個問題，我們提出 ShizishanGPT，一個基於檢索擴充生成（RAG）架構和代理架構的農業智慧問答系統。ShizishanGPT 包含五個關鍵模組：包含一個用於回答一般問題的通用 GPT-4 基礎模組；一個搜尋引擎模組，用於彌補大型語言模型本身的知識無法及時更新的問題；一個農業知識圖譜模組，用於提供領域事實；一個使用 RAG 來補充領域知識的檢索模組；以及一個農業代理模組，用於呼叫用於作物表型預測、基因表現分析等的專業模型。我們使用一個特別為這項研究設計的，包含 100 個農業問題的資料集來評估 ShizishanGPT。實驗結果顯示，由於其模組化設計和整合了不同的領域知識來源，此工具顯著優於一般的 LLM，因為它提供了更準確且詳細的答案。我們的原始碼、資料集和模型權重已公開於 https://github.com/Zaiwen/CropGPT。

##### **LM-assisted keyword biasing with Aho-Corasick algorithm for Transducer-based ASR**
2409.13514v1 by Iuliia Thorbecke, Juan Zuluaga-Gomez, Esaú Villatoro-Tello, Andres Carofilis, Shashi Kumar, Petr Motlicek, Karthik Pandia, Aravind Ganapathiraju

Despite the recent success of end-to-end models for automatic speech
recognition, recognizing special rare and out-of-vocabulary words, as well as
fast domain adaptation with text, are still challenging. It often happens that
biasing to the special entities leads to a degradation in the overall
performance. We propose a light on-the-fly method to improve automatic speech
recognition performance by combining a bias list of named entities with a
word-level n-gram language model with the shallow fusion approach based on the
Aho-Corasick string matching algorithm. The Aho-Corasick algorithm has proved
to be more efficient than other methods and allows fast context adaptation. An
n-gram language model is introduced as a graph with fail and output arcs, where
the arc weights are adapted from the n-gram probabilities. The language model
is used as an additional support to keyword biasing when the language model is
combined with bias entities in a single context graph to take care of the
overall performance. We demonstrate our findings on 4 languages, 2 public and 1
private datasets including performance on named entities and out-of-vocabulary
entities. We achieve up to 21.6% relative improvement in the general word error
rate with no practical difference in the inverse real-time factor.

摘要：儘管端對端模型在自動語音辨識上獲得近期成功，辨識特殊罕見且不在詞彙表中的字詞，以及透過文字進行快速領域適應，仍具有挑戰性。偏向特殊實體經常導致整體效能降低。我們提出一個即時輕量方法，透過將命名實體的偏差清單，與基於 Aho-Corasick 字串配對演算法的淺層融合方法，結合字元等級 n-gram 語言模型，來改善自動語音辨識效能。Aho-Corasick 演算法已被證明比其他方法更有效率，並允許快速脈絡適應。n-gram 語言模型被引入為具有失敗與輸出弧線的圖形，其中弧線權重從 n-gram 機率改編而來。語言模型用作關鍵字偏差的額外支援，當語言模型與偏差實體結合在單一脈絡圖形中時，用於照顧整體效能。我們在 4 種語言、2 個公開和 1 個私人資料集上展示我們的發現，包括命名實體和不在詞彙表中的實體的效能。我們在一般字元錯誤率上獲得高達 21.6% 的相對改善，且在反向即時因子中沒有實際差異。

##### **AQA: Adaptive Question Answering in a Society of LLMs via Contextual Multi-Armed Bandit**
2409.13447v2 by Mohanna Hoveyda, Arjen P. de Vries, Maarten de Rijke, Harrie Oosterhuis, Faegheh Hasibi

In question answering (QA), different questions can be effectively addressed
with different answering strategies. Some require a simple lookup, while others
need complex, multi-step reasoning to be answered adequately. This observation
motivates the development of a dynamic method that adaptively selects the most
suitable QA strategy for each question, enabling more efficient and effective
systems capable of addressing a broader range of question types. To this aim,
we build on recent advances in the orchestration of multiple large language
models (LLMs) and formulate adaptive QA as a dynamic orchestration challenge.
We define this as a contextual multi-armed bandit problem, where the context is
defined by the characteristics of the incoming question and the action space
consists of potential communication graph configurations among the LLM agents.
We then train a linear upper confidence bound model to learn an optimal mapping
between different question types and their corresponding optimal multi-LLM
communication graph representation. Our experiments show that the proposed
solution is viable for adaptive orchestration of a QA system with multiple
modules, as it combines the superior performance of more complex strategies
while avoiding their costs when simpler strategies suffice.

摘要：在問答 (QA) 中，不同的問題可以用不同的回答策略有效地解決。有些問題只需要簡單的查詢，而另一些問題則需要複雜的多步驟推理才能得到充分的回答。這個觀察促使開發一種動態方法，能適應性地為每個問題選擇最合適的 QA 策略，從而實現更高效且有效的系統，能解決更廣泛的類型問題。為此，我們建立在多個大型語言模型 (LLM) 編排的最新進展之上，並將適應性 QA 制定為一個動態編排挑戰。我們將其定義為一個情境多重選擇問題，其中情境由輸入問題的特徵定義，而動作空間由 LLM 代理之間的潛在通信圖形配置組成。然後，我們訓練一個線性上限置信界模型，以學習不同問題類型及其對應的最佳多 LLM 通信圖形表示之間的最佳映射。我們的實驗表明，所提出的解決方案適用於具有多個模組的 QA 系統的適應性編排，因為它結合了更複雜策略的優越效能，同時在較簡單的策略足夠時避免了其成本。

##### **GAProtoNet: A Multi-head Graph Attention-based Prototypical Network for Interpretable Text Classification**
2409.13312v1 by Ximing Wen, Wenjuan Tan, Rosina O. Weber

Pretrained transformer-based Language Models (LMs) are well-known for their
ability to achieve significant improvement on text classification tasks with
their powerful word embeddings, but their black-box nature, which leads to a
lack of interpretability, has been a major concern. In this work, we introduce
GAProtoNet, a novel white-box Multi-head Graph Attention-based Prototypical
Network designed to explain the decisions of text classification models built
with LM encoders. In our approach, the input vector and prototypes are regarded
as nodes within a graph, and we utilize multi-head graph attention to
selectively construct edges between the input node and prototype nodes to learn
an interpretable prototypical representation. During inference, the model makes
decisions based on a linear combination of activated prototypes weighted by the
attention score assigned for each prototype, allowing its choices to be
transparently explained by the attention weights and the prototypes projected
into the closest matching training examples. Experiments on multiple public
datasets show our approach achieves superior results without sacrificing the
accuracy of the original black-box LMs. We also compare with four alternative
prototypical network variations and our approach achieves the best accuracy and
F1 among all. Our case study and visualization of prototype clusters also
demonstrate the efficiency in explaining the decisions of black-box models
built with LMs.

摘要：預訓練的 Transformer 基於語言模型 (LM) 以其強大的詞嵌入功能而聞名，能夠在文本分類任務中獲得顯著的改進，但其黑盒性質導致缺乏可解釋性，一直是一個主要問題。在這項工作中，我們引入了 GAProtoNet，這是一個新穎的白盒多頭圖注意力原型網路，旨在解釋使用 LM 編碼器建立的文本分類模型的決策。在我們的做法中，輸入向量和原型被視為圖形中的節點，我們利用多頭圖注意力在輸入節點和原型節點之間有選擇地構造邊緣，以學習可解釋的原型表示。在推理過程中，模型根據激活原型的線性組合做出決策，該組合由分配給每個原型的注意力分數加權，從而允許通過注意力權重和投影到最接近匹配訓練範例的原型來透明地解釋其選擇。在多個公共資料集上的實驗表明，我們的做法在不犧牲原始黑盒 LM 的準確性的情況下，取得了優異的結果。我們還與四種替代原型網路變體進行了比較，我們的做法在所有變體中取得了最佳的準確性和 F1。我們的案例研究和原型群集的可視化也證明了使用 LM 建立的黑盒模型決策的解釋效率。

##### **Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems**
2409.13252v1 by Andrea Colombo

Knowledge Graphs (KGs) have been used to organize large datasets into
structured, interconnected information, enhancing data analytics across various
fields. In the legislative context, one potential natural application of KGs is
modeling the intricate set of interconnections that link laws and their
articles with each other and the broader legislative context.
  At the same time, the rise of large language models (LLMs) such as GPT has
opened new opportunities in legal applications, such as text generation and
document drafting. Despite their potential, the use of LLMs in legislative
contexts is critical since it requires the absence of hallucinations and
reliance on up-to-date information, as new laws are published on a daily basis.
  This work investigates how Legislative Knowledge Graphs and LLMs can
synergize and support legislative processes. We address three key questions:
the benefits of using KGs for legislative systems, how LLM can support
legislative activities by ensuring an accurate output, and how we can allow
non-technical users to use such technologies in their activities. To this aim,
we develop Legis AI Platform, an interactive platform focused on Italian
legislation that enhances the possibility of conducting legislative analysis
and that aims to support lawmaking activities.

摘要：知識圖譜 (KG) 已被用於將大型資料集整理成結構化、相互關聯的資訊，以增強各種領域的資料分析。在立法背景下，KG 的一個潛在自然應用是建模連結法律及其條文彼此之間以及更廣泛立法背景的複雜相互連結集。
與此同時，大型語言模型 (LLM)（例如 GPT）的興起為法律應用開闢了新的機會，例如文字產生和文件起草。儘管有其潛力，在立法背景下使用 LLM 至關重要，因為它需要沒有幻覺並且依賴於最新的資訊，因為每天都會公佈新的法律。
這項工作探討了立法知識圖譜和 LLM 如何產生協同效應並支援立法程序。我們探討了三個關鍵問題：使用 KG 對立法系統的好處、LLM 如何透過確保準確的輸出支援立法活動，以及我們如何讓非技術使用者在他們的活動中使用這些技術。為此，我們開發了 Legis AI Platform，這是一個專注於義大利立法的互動式平台，可增強進行立法分析的可能性，並旨在支援立法活動。

##### **Knowledge-Based Domain-Oriented Data Augmentation for Enhancing Unsupervised Sentence Embedding**
2409.12887v1 by Peichao Lai, Zhengfeng Zhang, Bin Cui

Recently, unsupervised sentence embedding models have received significant
attention in downstream natural language processing tasks. Using large language
models (LLMs) for data augmentation has led to considerable improvements in
previous studies. Nevertheless, these strategies emphasize data augmentation
with extensive generic corpora, neglecting the consideration of few-shot domain
data. The synthesized data lacks fine-grained information and may introduce
negative sample noise. This study introduces a novel pipeline-based data
augmentation method that leverages LLM to synthesize the domain-specific
dataset. It produces both positive and negative samples through entity- and
quantity-aware augmentation, utilizing an entity knowledge graph to synthesize
samples with fine-grained semantic distinctions, increasing training sample
diversity and relevance. We then present a Gaussian-decayed gradient-assisted
Contrastive Sentence Embedding (GCSE) model to reduce synthetic data noise and
improve model discrimination to reduce negative sample noise. Experimental
results demonstrate that our approach achieves state-of-the-art semantic
textual similarity performance with fewer synthetic data samples and lesser LLM
parameters, demonstrating its efficiency and robustness in varied backbones.

摘要：近来，无监督句子嵌入模型在自然语言处理的下游任务中受到广泛关注。在先前研究中，使用大型语言模型（LLM）进行数据扩充已带来显著的改进。然而，这些策略强调使用广泛的通用语料库进行数据扩充，忽略了对少量领域数据的考量。合成的资料缺乏细粒度信息，并可能引入负面样本噪声。本研究提出了一种新颖的基于管道的数据扩充方法，该方法利用 LLM 来合成特定于领域的资料集。它通过实体和数量感知扩充产生正面和负面样本，利用实体知识图谱来合成具有细粒度语义区别的样本，增加训练样本的多样性和相关性。然后，我们提出了一个高斯衰减梯度辅助对比句子嵌入（GCSE）模型，以减少合成数据噪声，并提高模型判别能力，以减少负面样本噪声。实验结果表明，我们的方法以更少的合成数据样本和更少的 LLM 参数实现了最先进的语义文本相似性性能，证明了其在各种骨干网中的效率和鲁棒性。

##### **KnowFormer: Revisiting Transformers for Knowledge Graph Reasoning**
2409.12865v1 by Junnan Liu, Qianren Mao, Weifeng Jiang, Jianxin Li

Knowledge graph reasoning plays a vital role in various applications and has
garnered considerable attention. Recently, path-based methods have achieved
impressive performance. However, they may face limitations stemming from
constraints in message-passing neural networks, such as missing paths and
information over-squashing. In this paper, we revisit the application of
transformers for knowledge graph reasoning to address the constraints faced by
path-based methods and propose a novel method KnowFormer.KnowFormer utilizes a
transformer architecture to perform reasoning on knowledge graphs from the
message-passing perspective, rather than reasoning by textual information like
previous pretrained language model based methods. Specifically, we define the
attention computation based on the query prototype of knowledge graph
reasoning, facilitating convenient construction and efficient optimization. To
incorporate structural information into the self-attention mechanism, we
introduce structure-aware modules to calculate query, key, and value
respectively. Additionally, we present an efficient attention computation
method for better scalability. Experimental results demonstrate the superior
performance of KnowFormer compared to prominent baseline methods on both
transductive and inductive benchmarks.

摘要：知識圖譜推理在各種應用中扮演著至關重要的角色，並已獲得相當大的關注。最近，基於路徑的方法已取得令人印象深刻的表現。然而，它們可能會面臨源自訊息傳遞神經網路中的限制，例如路徑遺失和資訊過度壓縮。在本文中，我們重新探討Transformer在知識圖譜推理中的應用，以解決基於路徑的方法所面臨的限制，並提出一個新穎的方法 KnowFormer。KnowFormer 利用Transformer架構從訊息傳遞的角度對知識圖譜執行推理，而不是像之前的預訓練語言模型所依賴的文本資訊那樣進行推理。具體來說，我們根據知識圖譜推理的查詢原型定義注意力的運算，促進便利的建構和有效的最佳化。為了將結構資訊納入自注意力機制，我們引入結構感知模組來分別計算查詢、鍵和值。此外，我們提出一個有效率的注意力運算方法以獲得更好的可擴充性。實驗結果證明，KnowFormer 在轉導和歸納基準上都優於傑出的基線方法。

##### **A New Perspective on ADHD Research: Knowledge Graph Construction with LLMs and Network Based Insights**
2409.12853v1 by Hakan T. Otal, Stephen V. Faraone, M. Abdullah Canbaz

Attention-Deficit/Hyperactivity Disorder (ADHD) is a challenging disorder to
study due to its complex symptomatology and diverse contributing factors. To
explore how we can gain deeper insights on this topic, we performed a network
analysis on a comprehensive knowledge graph (KG) of ADHD, constructed by
integrating scientific literature and clinical data with the help of
cutting-edge large language models. The analysis, including k-core techniques,
identified critical nodes and relationships that are central to understanding
the disorder. Building on these findings, we developed a context-aware chatbot
using Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG),
enabling accurate and informed interactions. Our knowledge graph not only
advances the understanding of ADHD but also provides a powerful tool for
research and clinical applications.

摘要：注意力缺陷過動症 (ADHD) 是一種具有挑戰性的疾病，由於其複雜的症狀和多樣化的成因。為了探討如何深入了解這個主題，我們對一個由科學文獻和臨床數據整合而成的 ADHD 全面知識圖譜 (KG) 進行了網路分析，並借助尖端的語言模型。分析，包括 k-core 技術，識別出對於理解此疾病至關重要的關鍵節點和關係。根據這些發現，我們使用大型語言模型 (LLM) 和檢索增強生成 (RAG) 開發了一個具備情境感知能力的聊天機器人，以實現準確且有根據的互動。我們的知識圖譜不僅促進了對 ADHD 的理解，還為研究和臨床應用提供了強大的工具。

##### **Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data**
2409.12437v1 by Jiaming Zhou, Abbas Ghaddar, Ge Zhang, Liheng Ma, Yaochen Hu, Soumyasundar Pal, Mark Coates, Bin Wang, Yingxue Zhang, Jianye Hao

Despite recent advances in training and prompting strategies for Large
Language Models (LLMs), these models continue to face challenges with complex
logical reasoning tasks that involve long reasoning chains. In this work, we
explore the potential and limitations of using graph-based synthetic reasoning
data as training signals to enhance LLMs' reasoning capabilities. Our extensive
experiments, conducted on two established natural language reasoning tasks --
inductive reasoning and spatial reasoning -- demonstrate that supervised
fine-tuning (SFT) with synthetic graph-based reasoning data effectively
enhances LLMs' reasoning performance without compromising their effectiveness
on other standard evaluation benchmarks.

摘要：儘管在大型語言模型 (LLM) 的訓練和提示策略方面有近期的進展，這些模型在涉及長推理鏈的複雜邏輯推理任務中仍面臨挑戰。在這項工作中，我們探討了使用基於圖形的合成推理數據作為訓練訊號以增強 LLM 推理能力的潛力和限制。我們在兩個既定的自然語言推理任務（歸納推理和空間推理）上進行了廣泛的實驗，證明了使用基於圖形的合成推理數據進行監督微調 (SFT) 有效地增強了 LLM 的推理性能，而不會損害其在其他標準評估基準上的效能。

##### **Textualized Agent-Style Reasoning for Complex Tasks by Multiple Round LLM Generation**
2409.12411v1 by Chen Liang, Zhifan Feng, Zihe Liu, Wenbin Jiang, Jinan Xu, Yufeng Chen, Yong Wang

Chain-of-thought prompting significantly boosts the reasoning ability of
large language models but still faces three issues: hallucination problem,
restricted interpretability, and uncontrollable generation. To address these
challenges, we present AgentCOT, a llm-based autonomous agent framework, which
can solve complex problems in an agent-style manner by multiple round LLM
generation. At each step, AgentCOT selects an action and executes it to yield
an intermediate result with supporting evidence. In addition, we integrate the
step's index into the reasoning process to form a graph structure for complex
inference logic. We introduce two new strategies to enhance the performance of
AgentCOT.We conduct extensive experiments to verify the effectiveness of our
method on six common benchmarks. Results exhibit that our method brings in
substantial improvements over current competitive approaches.

摘要：鏈條思考提示顯著提升大型語言模型的推理能力，但仍面臨三個問題：幻覺問題、受限的可解釋性，以及無法控制的生成。為了應對這些挑戰，我們提出了 AgentCOT，一個基於 llm 的自主代理架構，它可以通過多輪 LLM 生成以代理樣式解決複雜問題。在每一步中，AgentCOT 選擇一個動作並執行它，以產生一個具有支持證據的中間結果。此外，我們將步驟索引整合到推理過程中，以形成一個圖形結構，用於複雜的推理邏輯。我們引入了兩種新策略來增強 AgentCOT 的性能。我們進行了廣泛的實驗，以驗證我們的方法在六個常見基準上的有效性。結果表明，我們的的方法比當前的競爭方法有了顯著的改進。

##### **GUNet: A Graph Convolutional Network United Diffusion Model for Stable and Diversity Pose Generation**
2409.11689v1 by Shuowen Liang, Sisi Li, Qingyun Wang, Cen Zhang, Kaiquan Zhu, Tian Yang

Pose skeleton images are an important reference in pose-controllable image
generation. In order to enrich the source of skeleton images, recent works have
investigated the generation of pose skeletons based on natural language. These
methods are based on GANs. However, it remains challenging to perform diverse,
structurally correct and aesthetically pleasing human pose skeleton generation
with various textual inputs. To address this problem, we propose a framework
with GUNet as the main model, PoseDiffusion. It is the first generative
framework based on a diffusion model and also contains a series of variants
fine-tuned based on a stable diffusion model. PoseDiffusion demonstrates
several desired properties that outperform existing methods. 1) Correct
Skeletons. GUNet, a denoising model of PoseDiffusion, is designed to
incorporate graphical convolutional neural networks. It is able to learn the
spatial relationships of the human skeleton by introducing skeletal information
during the training process. 2) Diversity. We decouple the key points of the
skeleton and characterise them separately, and use cross-attention to introduce
textual conditions. Experimental results show that PoseDiffusion outperforms
existing SoTA algorithms in terms of stability and diversity of text-driven
pose skeleton generation. Qualitative analyses further demonstrate its
superiority for controllable generation in Stable Diffusion.

摘要：姿勢骨架圖像是姿勢可控圖像生成中重要的參考。為了豐富骨架圖像的來源，最近的研究調查了基於自然語言的姿勢骨架生成。這些方法基於 GAN。然而，要執行多樣化、結構正確且美觀的人體姿勢骨架生成，並具有各種文本輸入，仍然具有挑戰性。為了解決這個問題，我們提出了以 GUNet 為主要模型的框架，PoseDiffusion。它是基於擴散模型的第一個生成框架，還包含一系列基於穩定擴散模型進行微調的變體。PoseDiffusion 展示了多項優於現有方法的理想屬性。1) 正確的骨架。PoseDiffusion 的去噪模型 GUNet 被設計為結合圖形卷積神經網路。它能夠透過在訓練過程中引入骨架資訊來學習人體骨架的空間關係。2) 多樣性。我們解耦骨架的關鍵點並分別對其進行表徵，並使用交叉注意力來引入文本條件。實驗結果表明，PoseDiffusion 在文本驅動姿勢骨架生成的穩定性和多樣性方面優於現有的 SoTA 演算法。定性分析進一步證明了它在 Stable Diffusion 中可控生成的優越性。

##### **FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction**
2409.11509v1 by Ziwei Li, Xiaoqi Wang, Hong-You Chen, Han-Wei Shen, Wei-Lun Chao

Federated learning (FL) has rapidly evolved as a promising paradigm that
enables collaborative model training across distributed participants without
exchanging their local data. Despite its broad applications in fields such as
computer vision, graph learning, and natural language processing, the
development of a data projection model that can be effectively used to
visualize data in the context of FL is crucial yet remains heavily
under-explored. Neighbor embedding (NE) is an essential technique for
visualizing complex high-dimensional data, but collaboratively learning a joint
NE model is difficult. The key challenge lies in the objective function, as
effective visualization algorithms like NE require computing loss functions
among pairs of data. In this paper, we introduce \textsc{FedNE}, a novel
approach that integrates the \textsc{FedAvg} framework with the contrastive NE
technique, without any requirements of shareable data. To address the lack of
inter-client repulsion which is crucial for the alignment in the global
embedding space, we develop a surrogate loss function that each client learns
and shares with each other. Additionally, we propose a data-mixing strategy to
augment the local data, aiming to relax the problems of invisible neighbors and
false neighbors constructed by the local $k$NN graphs. We conduct comprehensive
experiments on both synthetic and real-world datasets. The results demonstrate
that our \textsc{FedNE} can effectively preserve the neighborhood data
structures and enhance the alignment in the global embedding space compared to
several baseline methods.

摘要：聯合式學習 (FL) 已迅速演變為一種有前途的範例，它可以在分布式參與者之間進行協作模型訓練，而無需交換他們的本地數據。儘管它在電腦視覺、圖形學習和自然語言處理等領域有廣泛的應用，但開發一個數據投影模型，可有效用於在 FL 的背景下視覺化數據，這一點至關重要，但仍未得到充分的探索。鄰域嵌入 (NE) 是用於視覺化複雜高維數據的一項基本技術，但協作學習一個聯合 NE 模型很困難。主要的挑戰在於目標函數，因為像 NE 這樣的有效視覺化演算法需要計算數據對之間的損失函數。在本文中，我們介紹了 \textsc{FedNE}，這是一種新穎的方法，它將 \textsc{FedAvg} 框架與對比 NE 技術相整合，而無需任何可共享數據的要求。為了解決對於在全局嵌入空間中對齊至關重要的客戶端間排斥力不足的問題，我們開發了一個代理損失函數，每個客戶端學習此函數並與彼此共享。此外，我們提出了一種數據混合策略來擴充本地數據，旨在緩解由本地 $k$NN 圖形構造的不可見鄰域和錯誤鄰域的問題。我們在合成和真實世界數據集上進行了全面的實驗。結果表明，與幾種基線方法相比，我們的 \textsc{FedNE} 可以有效地保留鄰域數據結構並增強在全局嵌入空間中的對齊。

##### **Reasoning Graph Enhanced Exemplars Retrieval for In-Context Learning**
2409.11147v1 by Yukang Lin, Bingchen Zhong, Shuoran Jiang, Joanna Siebert, Qingcai Chen

Large language models(LLMs) have exhibited remarkable few-shot learning
capabilities and unified the paradigm of NLP tasks through the in-context
learning(ICL) technique. Despite the success of ICL, the quality of the
exemplar demonstrations can significantly influence the LLM's performance.
Existing exemplar selection methods mainly focus on the semantic similarity
between queries and candidate exemplars. On the other hand, the logical
connections between reasoning steps can be beneficial to depict the
problem-solving process as well. In this paper, we proposes a novel method
named Reasoning Graph-enhanced Exemplar Retrieval(RGER). RGER first quires LLM
to generate an initial response, then expresses intermediate problem-solving
steps to a graph structure. After that, it employs graph kernel to select
exemplars with semantic and structural similarity. Extensive experiments
demonstrate the structural relationship is helpful to the alignment of queries
and candidate exemplars. The efficacy of RGER on math and logit reasoning tasks
showcases its superiority over state-of-the-art retrieval-based approaches. Our
code is released at https://github.com/Yukang-Lin/RGER.

摘要：大型語言模型 (LLM) 已展現出卓越的少量學習能力，並透過情境學習 (ICL) 技術統一了 NLP 任務的範例。儘管 ICL 已成功，範例示範的品質會顯著影響 LLM 的效能。現有的範例選擇方法主要著重於查詢與候選範例之間的語意相似性。另一方面，推理步驟之間的邏輯連結有助於描繪問題解決流程。在本文中，我們提出了一種稱為推理圖增強範例檢索 (RGER) 的新方法。RGER 首先要求 LLM 產生一個初始回應，然後將中間問題解決步驟表示為圖形結構。之後，它採用圖形核選取具有語意和結構相似性的範例。廣泛的實驗證明，結構關係有助於查詢和候選範例的對齊。RGER 在數學和邏輯推理任務上的功效展示了它優於最先進的基於檢索的方法。我們的程式碼已發布於 https://github.com/Yukang-Lin/RGER。

##### **Semformer: Transformer Language Models with Semantic Planning**
2409.11143v1 by Yongjing Yin, Junran Ding, Kai Song, Yue Zhang

Next-token prediction serves as the dominant component in current neural
language models. During the training phase, the model employs teacher forcing,
which predicts tokens based on all preceding ground truth tokens. However, this
approach has been found to create shortcuts, utilizing the revealed prefix to
spuriously fit future tokens, potentially compromising the accuracy of the
next-token predictor. In this paper, we introduce Semformer, a novel method of
training a Transformer language model that explicitly models the semantic
planning of response. Specifically, we incorporate a sequence of planning
tokens into the prefix, guiding the planning token representations to predict
the latent semantic representations of the response, which are induced by an
autoencoder. In a minimal planning task (i.e., graph path-finding), our model
exhibits near-perfect performance and effectively mitigates shortcut learning,
a feat that standard training methods and baseline models have been unable to
accomplish. Furthermore, we pretrain Semformer from scratch with 125M
parameters, demonstrating its efficacy through measures of perplexity,
in-context learning, and fine-tuning on summarization tasks.

摘要：在當前的語言模型中，下一個詞彙預測是主導組成部分。在訓練階段，模型採用教師強制法，根據所有前一個的真實詞彙來預測詞彙。然而，發現這種方法會產生捷徑，利用已揭露的前綴來虛假地符合後續的詞彙，潛在會危害下一個詞彙預測器的準確度。在本文中，我們介紹 Semformer，一種訓練 Transformer 語言模型的新方法，明確地建構回應的語意規劃。具體來說，我們將一系列規劃詞彙納入前綴，引導規劃詞彙的表徵去預測回應的潛在語意表徵，這些表徵是由自動編碼器誘導的。在一個最小的規劃任務（即圖形路徑尋找）中，我們的模型表現出接近完美的效能，並有效地減輕捷徑學習，這是標準訓練方法和基線模型無法達成的壯舉。此外，我們從頭開始使用 1.25 億個參數預訓練 Semformer，透過困惑度、語境學習和在摘要任務上的微調來證明其功效。

##### **KALE: An Artwork Image Captioning System Augmented with Heterogeneous Graph**
2409.10921v1 by Yanbei Jiang, Krista A. Ehinger, Jey Han Lau

Exploring the narratives conveyed by fine-art paintings is a challenge in
image captioning, where the goal is to generate descriptions that not only
precisely represent the visual content but also offer a in-depth interpretation
of the artwork's meaning. The task is particularly complex for artwork images
due to their diverse interpretations and varied aesthetic principles across
different artistic schools and styles. In response to this, we present KALE
Knowledge-Augmented vision-Language model for artwork Elaborations), a novel
approach that enhances existing vision-language models by integrating artwork
metadata as additional knowledge. KALE incorporates the metadata in two ways:
firstly as direct textual input, and secondly through a multimodal
heterogeneous knowledge graph. To optimize the learning of graph
representations, we introduce a new cross-modal alignment loss that maximizes
the similarity between the image and its corresponding metadata. Experimental
results demonstrate that KALE achieves strong performance (when evaluated with
CIDEr, in particular) over existing state-of-the-art work across several
artwork datasets. Source code of the project is available at
https://github.com/Yanbei-Jiang/Artwork-Interpretation.

摘要：探索由美术绘画传达的叙事是图像字幕中的挑战，其目标是生成不仅准确地表示视觉内容而且还提供对艺术品含义的深入解释的描述。由于其不同的解释和跨不同艺术流派和风格的不同美学原则，这项任务对于艺术品图像来说尤其复杂。为了应对这种情况，我们提出了 KALE 知识增强视觉语言模型用于艺术品阐释，一种通过将艺术品元数据作为附加知识来增强现有视觉语言模型的新方法。KALE 以两种方式合并元数据：首先作为直接文本输入，其次通过多模态异构知识图。为了优化图表的学习表示，我们引入了一种新的跨模态对齐损失，它最大化图像与其对应元数据之间的相似性。实验结果表明，KALE 在使用 CIDEr 评估时，在几个艺术品数据集上取得了优异的性能（特别是与现有的最先进的工作相比）。该项目的源代码可在 https://github.com/Yanbei-Jiang/Artwork-Interpretation 获得。

##### **A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**
2409.10403v1 by Zhang Zheng

This paper proposes a knowledge-enhanced disease diagnosis method based on a
prompt learning framework. The method retrieves structured knowledge from
external knowledge graphs related to clinical cases, encodes it, and injects it
into the prompt templates to enhance the language model's understanding and
reasoning capabilities for the task.We conducted experiments on three public
datasets: CHIP-CTC, IMCS-V2-NER, and KUAKE-QTR. The results show that the
proposed method significantly outperforms existing models across multiple
evaluation metrics, with an F1 score improvement of 2.4% on the CHIP-CTC
dataset, 3.1% on the IMCS-V2-NER dataset,and 4.2% on the KUAKE-QTR dataset.
Additionally,ablation studies confirmed the critical role of the knowledge
injection module,as the removal of this module resulted in a significant drop
in F1 score. The experimental results demonstrate that the proposed method not
only effectively improves the accuracy of disease diagnosis but also enhances
the interpretability of the predictions, providing more reliable support and
evidence for clinical diagnosis.

摘要：本文提出了一种基于提示学习框架的知识增强疾病诊断方法。该方法从与临床病例相关的外部知识图谱中检索结构化知识，对其进行编码，并将其注入到提示模板中，以增强语言模型对任务的理解和推理能力。我们在三个公共数据集上进行了实验：CHIP-CTC、IMCS-V2-NER 和 KUAKE-QTR。结果表明，所提出的方法在多个评估指标上明显优于现有模型，在 CHIP-CTC 数据集上的 F1 得分提高了 2.4%，在 IMCS-V2-NER 数据集上提高了 3.1%，在 KUAKE-QTR 数据集上提高了 4.2%。此外，消融研究证实了知识注入模块的关键作用，因为移除此模块会导致 F1 得分显着下降。实验结果表明，所提出的方法不仅有效提高了疾病诊断的准确性，而且增强了预测的可解释性，为临床诊断提供了更可靠的支持和证据。

##### **MGSA: Multi-Granularity Graph Structure Attention for Knowledge Graph-to-Text Generation**
2409.10294v2 by Shanshan Wang, Chun Zhang, Ning Zhang

The Knowledge Graph-to-Text Generation task aims to convert structured
knowledge graphs into coherent and human-readable natural language text. Recent
efforts in this field have focused on enhancing pre-trained language models
(PLMs) by incorporating graph structure information to capture the intricate
structure details of knowledge graphs. However, most of these approaches tend
to capture only single-granularity structure information, concentrating either
on the relationships between entities within the original graph or on the
relationships between words within the same entity or across different
entities. This narrow focus results in a significant limitation: models that
concentrate solely on entity-level structure fail to capture the nuanced
semantic relationships between words, while those that focus only on word-level
structure overlook the broader relationships between original entire entities.
To overcome these limitations, this paper introduces the Multi-granularity
Graph Structure Attention (MGSA), which is based on PLMs. The encoder of the
model architecture features an entity-level structure encoding module, a
word-level structure encoding module, and an aggregation module that
synthesizes information from both structure. This multi-granularity structure
encoding approach allows the model to simultaneously capture both entity-level
and word-level structure information, providing a more comprehensive
understanding of the knowledge graph's structure information, thereby
significantly improving the quality of the generated text. We conducted
extensive evaluations of the MGSA model using two widely recognized KG-to-Text
Generation benchmark datasets, WebNLG and EventNarrative, where it consistently
outperformed models that rely solely on single-granularity structure
information, demonstrating the effectiveness of our approach.

摘要：知識圖譜轉文字生成任務旨在將結構化的知識圖譜轉換為連貫且人類可讀的自然語言文字。最近在這個領域的努力集中在透過納入圖形結構資訊來增強預先訓練的語言模型 (PLM)，以擷取知識圖譜的複雜結構細節。然而，這些方法中的大多數傾向於僅擷取單一粒度的結構資訊，專注於原始圖形中實體之間的關係或同一個實體或不同實體之間的詞彙關係。這種狹隘的焦點導致了一個重大的限制：僅專注於實體層級結構的模型無法擷取詞彙之間的細微語義關係，而僅專注於詞彙層級結構的模型則忽略了原始整個實體之間的更廣泛關係。為了克服這些限制，本文引入了基於 PLM 的多粒度圖形結構注意力 (MGSA)。模型架構的編碼器具有一個實體層級結構編碼模組、一個詞彙層級結構編碼模組，以及一個從兩個結構中綜合資訊的聚合模組。這種多粒度結構編碼方法允許模型同時擷取實體層級和詞彙層級的結構資訊，提供對知識圖譜結構資訊更全面的理解，從而顯著提升所生成文字的品質。我們使用兩個廣泛認可的 KG 轉文字生成基準資料集 WebNLG 和 EventNarrative 對 MGSA 模型進行了廣泛的評估，它始終優於僅依賴單一粒度結構資訊的模型，證明了我們方法的有效性。

##### **LLM-DER:A Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain**
2409.10077v1 by Le Xiao, Yunfei Xu, Jing Zhao

Domain-specific Named Entity Recognition (NER), whose goal is to recognize
domain-specific entities and their categories, provides an important support
for constructing domain knowledge graphs. Currently, deep learning-based
methods are widely used and effective in NER tasks, but due to the reliance on
large-scale labeled data. As a result, the scarcity of labeled data in a
specific domain will limit its application.Therefore, many researches started
to introduce few-shot methods and achieved some results. However, the entity
structures in specific domains are often complex, and the current few-shot
methods are difficult to adapt to NER tasks with complex features.Taking the
Chinese coal chemical industry domain as an example,there exists a complex
structure of multiple entities sharing a single entity, as well as multiple
relationships for the same pair of entities, which affects the NER task under
the sample less condition.In this paper, we propose a Large Language Models
(LLMs)-based entity recognition framework LLM-DER for the domain-specific
entity recognition problem in Chinese, which enriches the entity information by
generating a list of relationships containing entity types through LLMs, and
designing a plausibility and consistency evaluation method to remove
misrecognized entities, which can effectively solve the complex structural
entity recognition problem in a specific domain.The experimental results of
this paper on the Resume dataset and the self-constructed coal chemical dataset
Coal show that LLM-DER performs outstandingly in domain-specific entity
recognition, not only outperforming the existing GPT-3.5-turbo baseline, but
also exceeding the fully-supervised baseline, verifying its effectiveness in
entity recognition.

摘要：<paragraph>領域特定命名實體辨識（NER），其目標是辨識領域特定實體及其類別，為建構領域知識圖譜提供重要的支援。目前，基於深度學習的方法廣泛用於 NER 任務且十分有效，但由於依賴於大規模標記資料。因此，特定領域中標記資料的稀少會限制其應用。因此，許多研究開始引入少量樣本方法並獲得一些成果。然而，特定領域中的實體結構通常很複雜，而目前的少量樣本方法難以適應具有複雜特徵的 NER 任務。以中國煤化工產業領域為例，存在多個實體共用單一實體的複雜結構，以及同一對實體有多重關係，這會影響樣本較少條件下的 NER 任務。在本文中，我們提出了一個基於大型語言模型（LLM）的實體辨識架構 LLM-DER，用於中文領域特定實體辨識問題，通過 LLM 生成包含實體類型的關係清單，並設計一個合理性和一致性評估方法來移除辨識錯誤的實體，從而可以有效解決特定領域中複雜結構實體辨識問題。本文在 Resume 資料集和自建煤化工資料集 Coal 上的實驗結果表明，LLM-DER 在領域特定實體辨識中表現出色，不僅優於現有的 GPT-3.5-turbo 基準，還超過了完全監督的基線，驗證了其在實體辨識中的有效性。</paragraph>

##### **On the Diagram of Thought**
2409.10038v1 by Yifan Zhang, Yang Yuan, Andrew Chi-Chih Yao

We introduce Diagram of Thought (DoT), a framework that models iterative
reasoning in large language models (LLMs) as the construction of a directed
acyclic graph (DAG) within a single model. Unlike traditional approaches that
represent reasoning as linear chains or trees, DoT organizes propositions,
critiques, refinements, and verifications into a cohesive DAG structure,
allowing the model to explore complex reasoning pathways while maintaining
logical consistency. Each node in the diagram corresponds to a proposition that
has been proposed, critiqued, refined, or verified, enabling the LLM to
iteratively improve its reasoning through natural language feedback. By
leveraging auto-regressive next-token prediction with role-specific tokens, DoT
facilitates seamless transitions between proposing ideas and critically
evaluating them, providing richer feedback than binary signals. Furthermore, we
formalize the DoT framework using Topos Theory, providing a mathematical
foundation that ensures logical consistency and soundness in the reasoning
process. This approach enhances both the training and inference processes
within a single LLM, eliminating the need for multiple models or external
control mechanisms. DoT offers a conceptual framework for designing
next-generation reasoning-specialized models, emphasizing training efficiency,
robust reasoning capabilities, and theoretical grounding. The code is available
at https://github.com/diagram-of-thought/diagram-of-thought.

摘要：我們介紹了思想圖（DoT），這是一個框架，它將大型語言模型（LLM）中的迭代推理建模為在單一模型內建構一個有向無環圖（DAG）。與將推理表示為線性鏈或樹的傳統方法不同，DoT 將命題、批判、修正和驗證組織成一個有凝聚力的 DAG 結構，允許模型探索複雜的推理路徑，同時保持邏輯一致性。圖表中的每個節點對應於一個已被提出、批判、修正或驗證的命題，使 LLM 能夠通過自然語言回饋迭代地改進其推理。通過利用具有角色特定標記的自動回歸下一個標記預測，DoT 促進了提出想法和批判性評估它們之間的無縫過渡，提供了比二元信號更豐富的回饋。此外，我們使用拓撲理論形式化了 DoT 框架，提供了一個數學基礎，以確保推理過程中的邏輯一致性和健全性。這種方法增強了單一 LLM 內的訓練和推理過程，消除了對多個模型或外部控制機制的需要。DoT 為設計下一代推理專用模型提供了一個概念框架，強調訓練效率、強大的推理能力和理論基礎。代碼可在 https://github.com/diagram-of-thought/diagram-of-thought 獲得。

##### **Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation Extraction in Long Sentences**
2409.13755v1 by Xin Wang, Xinyi Bai

Relation extraction as an important natural Language processing (NLP) task is
to identify relations between named entities in text. Recently, graph
convolutional networks over dependency trees have been widely used to capture
syntactic features and achieved attractive performance. However, most existing
dependency-based approaches ignore the positive influence of the words outside
the dependency trees, sometimes conveying rich and useful information on
relation extraction. In this paper, we propose a novel model, Entity-aware
Self-attention Contextualized GCN (ESC-GCN), which efficiently incorporates
syntactic structure of input sentences and semantic context of sequences. To be
specific, relative position self-attention obtains the overall semantic
pairwise correlation related to word position, and contextualized graph
convolutional networks capture rich intra-sentence dependencies between words
by adequately pruning operations. Furthermore, entity-aware attention layer
dynamically selects which token is more decisive to make final relation
prediction. In this way, our proposed model not only reduces the noisy impact
from dependency trees, but also obtains easily-ignored entity-related semantic
representation. Extensive experiments on various tasks demonstrate that our
model achieves encouraging performance as compared to existing dependency-based
and sequence-based models. Specially, our model excels in extracting relations
between entities of long sentences.

摘要：關係萃取作為一項重要的自然語言處理 (NLP) 任務，是為了辨識文本中命名實體之間的關係。最近，依存樹上的圖形卷積網路已廣泛用於擷取句法特徵，並獲得令人滿意的效能。然而，現有的基於依存的演算法大多忽略依存樹外單字的正面影響，這些單字有時會傳達豐富且有用的關係萃取資訊。在本文中，我們提出一個新穎的模型，實體感知自我注意脈絡化 GCN (ESC-GCN)，它有效地整合輸入句子的句法結構和序列的語意脈絡。具體來說，相對位置自我注意會取得與單字位置相關的整體語意成對關聯性，而脈絡化圖形卷積網路則透過適當的修剪運算，擷取單字之間豐富的句子內依存關係。此外，實體感知注意層會動態地選擇哪個記號對於做出最終關係預測較為決定性。藉由這種方式，我們提出的模型不僅減少了依存樹帶來的雜訊影響，還能取得容易被忽略的實體相關語意表徵。在各種任務上的廣泛實驗證明，與現有的基於依存和基於序列的模型相比，我們的模型達到了令人鼓舞的效能。特別是，我們的模型在萃取長句中實體之間的關係方面表現出色。

##### **Generating Event-oriented Attribution for Movies via Two-Stage Prefix-Enhanced Multimodal LLM**
2409.09362v1 by Yuanjie Lyu, Tong Xu, Zihan Niu, Bo Peng, Jing Ke, Enhong Chen

The prosperity of social media platforms has raised the urgent demand for
semantic-rich services, e.g., event and storyline attribution. However, most
existing research focuses on clip-level event understanding, primarily through
basic captioning tasks, without analyzing the causes of events across an entire
movie. This is a significant challenge, as even advanced multimodal large
language models (MLLMs) struggle with extensive multimodal information due to
limited context length. To address this issue, we propose a Two-Stage
Prefix-Enhanced MLLM (TSPE) approach for event attribution, i.e., connecting
associated events with their causal semantics, in movie videos. In the local
stage, we introduce an interaction-aware prefix that guides the model to focus
on the relevant multimodal information within a single clip, briefly
summarizing the single event. Correspondingly, in the global stage, we
strengthen the connections between associated events using an inferential
knowledge graph, and design an event-aware prefix that directs the model to
focus on associated events rather than all preceding clips, resulting in
accurate event attribution. Comprehensive evaluations of two real-world
datasets demonstrate that our framework outperforms state-of-the-art methods.

摘要：社群媒體平台的蓬勃發展，提升了對語意豐富服務（例如事件和故事線歸因）的迫切需求。然而，現有的研究大多著重於片段層級的事件理解，主要是透過基礎的字幕任務，而未分析整部電影中事件發生的原因。這是一個重大的挑戰，因為即使是進階的多模態大型語言模型 (MLLM) 也會因為受限的脈絡長度而難以處理廣泛的多模態資訊。為了解決這個問題，我們提出了一個兩階段前置詞增強 MLLM (TSPE) 方法，用於電影影片中的事件歸因，也就是將相關事件與其因果語意連結起來。在局部階段，我們引入了一個互動感知前置詞，引導模型專注於單一片段中的相關多模態資訊，簡要地總結單一事件。相應地，在整體階段，我們使用推理知識圖譜強化相關事件之間的連結，並設計了一個事件感知前置詞，引導模型專注於相關事件，而非所有前置片段，進而產生準確的事件歸因。對兩個真實世界資料集的全面評估顯示，我們的架構優於現有的最先進方法。

##### **ODE: Open-Set Evaluation of Hallucinations in Multimodal Large Language Models**
2409.09318v1 by Yahan Tu, Rui Hu, Jitao Sang

Hallucination poses a significant challenge for multimodal large language
models (MLLMs). However, existing benchmarks for evaluating hallucinations are
static, which can lead to potential data contamination. This paper introduces
ODE, an open-set, dynamic protocol for evaluating object existence
hallucinations in MLLMs. Our framework employs graph structures to model
associations between real-word concepts and generates novel samples for both
general and domain-specific scenarios. The dynamic combination of concepts,
along with various combination principles, ensures a broad sample distribution.
Experimental results show that MLLMs exhibit higher hallucination rates with
ODE-generated samples, effectively avoiding data contamination. Moreover, these
samples can also be used for fine-tuning to improve MLLM performance on
existing benchmarks.

摘要：幻覺對多模態大型語言模型 (MLLM) 構成重大挑戰。然而，現有的評估幻覺基準是靜態的，這可能導致潛在的資料污染。本文介紹了 ODE，一種開放式、動態的協定，用於評估 MLLM 中的物件存在幻覺。我們的架構採用圖形結構來建模真實世界概念之間的關聯，並為一般和特定領域情境產生新的範例。概念的動態組合，以及各種組合原則，確保了廣泛的範例分佈。實驗結果顯示，MLLM 在 ODE 生成的範例中表現出較高的幻覺率，有效避免了資料污染。此外，這些範例也可被用於微調，以改善 MLLM 在現有基準上的效能。

##### **Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks**
2409.09026v1 by Florian Grötschla, Luca Strässle, Luca A. Lanzendörfer, Roger Wattenhofer

Music recommender systems frequently utilize network-based models to capture
relationships between music pieces, artists, and users. Although these
relationships provide valuable insights for predictions, new music pieces or
artists often face the cold-start problem due to insufficient initial
information. To address this, one can extract content-based information
directly from the music to enhance collaborative-filtering-based methods. While
previous approaches have relied on hand-crafted audio features for this
purpose, we explore the use of contrastively pretrained neural audio embedding
models, which offer a richer and more nuanced representation of music. Our
experiments demonstrate that neural embeddings, particularly those generated
with the Contrastive Language-Audio Pretraining (CLAP) model, present a
promising approach to enhancing music recommendation tasks within graph-based
frameworks.

摘要：音樂推薦系統經常使用基於網路的模型來擷取音樂作品、藝術家和使用者之間的關係。儘管這些關係為預測提供了有價值的見解，但由於初始資訊不足，新的音樂作品或藝術家經常面臨冷啟動問題。為了解決這個問題，可以從音樂中直接擷取基於內容的資訊，以增強基於協同過濾的方法。雖然先前的做法已依賴手工製作的音訊特徵來達成此目的，但我們探索使用對比預訓練神經音訊嵌入模型，這提供了更豐富且更細緻的音樂表示。我們的實驗證明了神經嵌入，特別是使用對比語言音訊預訓練 (CLAP) 模型產生的嵌入，展示了一種有前景的方法，可以用於增強圖形化框架中的音樂推薦任務。

##### **Contri(e)ve: Context + Retrieve for Scholarly Question Answering**
2409.09010v1 by Kanchan Shivashankar, Nadine Steinmetz

Scholarly communication is a rapid growing field containing a wealth of
knowledge. However, due to its unstructured and document format, it is
challenging to extract useful information from them through conventional
document retrieval methods. Scholarly knowledge graphs solve this problem, by
representing the documents in a semantic network, providing, hidden insights,
summaries and ease of accessibility through queries. Naturally, question
answering for scholarly graphs expands the accessibility to a wider audience.
But some of the knowledge in this domain is still presented as unstructured
text, thus requiring a hybrid solution for question answering systems. In this
paper, we present a two step solution using open source Large Language
Model(LLM): Llama3.1 for Scholarly-QALD dataset. Firstly, we extract the
context pertaining to the question from different structured and unstructured
data sources: DBLP, SemOpenAlex knowledge graphs and Wikipedia text. Secondly,
we implement prompt engineering to improve the information retrieval
performance of the LLM. Our approach achieved an F1 score of 40% and also
observed some anomalous responses from the LLM, that are discussed in the final
part of the paper.

摘要：學術交流是一個快速成長的領域，包含了豐富的知識。然而，由於其非結構化和文件格式，透過傳統的文件檢索方法很難從中萃取出有用的資訊。學術知識圖譜解決了這個問題，它以語義網路呈現文件，提供隱藏的見解、摘要和透過查詢輕鬆存取。自然地，學術圖譜的問答擴展了對更廣泛受眾的存取性。但這個領域中的一些知識仍然以非結構化文字呈現，因此需要一個混合解決方案來進行問答系統。在本文中，我們提出了一個使用開放原始碼大型語言模型 (LLM) 的兩步驟解決方案：Llama3.1 for Scholarly-QALD 資料集。首先，我們從不同的結構化和非結構化資料來源中萃取與問題相關的脈絡：DBLP、SemOpenAlex 知識圖譜和維基百科文字。其次，我們實作提示工程以改善 LLM 的資訊檢索效能。我們的做法達到了 40% 的 F1 分數，並且也觀察到 LLM 的一些異常回應，這些回應在本文的最後一部分中進行了討論。

##### **SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity**
2409.09007v1 by Qitian Wu, Kai Yang, Hengrui Zhang, David Wipf, Junchi Yan

Learning representations on large graphs is a long-standing challenge due to
the inter-dependence nature. Transformers recently have shown promising
performance on small graphs thanks to its global attention for capturing
all-pair interactions beyond observed structures. Existing approaches tend to
inherit the spirit of Transformers in language and vision tasks, and embrace
complicated architectures by stacking deep attention-based propagation layers.
In this paper, we attempt to evaluate the necessity of adopting multi-layer
attentions in Transformers on graphs, which considerably restricts the
efficiency. Specifically, we analyze a generic hybrid propagation layer,
comprised of all-pair attention and graph-based propagation, and show that
multi-layer propagation can be reduced to one-layer propagation, with the same
capability for representation learning. It suggests a new technical path for
building powerful and efficient Transformers on graphs, particularly through
simplifying model architectures without sacrificing expressiveness. As
exemplified by this work, we propose a Simplified Single-layer Graph
Transformers (SGFormer), whose main component is a single-layer global
attention that scales linearly w.r.t. graph sizes and requires none of any
approximation for accommodating all-pair interactions. Empirically, SGFormer
successfully scales to the web-scale graph ogbn-papers100M, yielding
orders-of-magnitude inference acceleration over peer Transformers on
medium-sized graphs, and demonstrates competitiveness with limited labeled
data.

摘要：在大型圖表上學習表徵由於相互依賴的性質而成為一項長期的挑戰。由於 Transfomer 能夠針對所有成對互動進行全局關注，超越觀測結構，因此最近在小型圖表上展現出令人滿意的效能。現有的方法傾向於繼承 Transformer 在語言和視覺任務中的精神，並通過堆疊基於深度關注的傳播層來採用複雜的架構。在本文中，我們嘗試評估在圖表上採用多層注意力 Transformer 的必要性，這極大地限制了效率。具體來說，我們分析了一個通用的混合傳播層，它包含所有成對注意力和基於圖表的傳播，並表明多層傳播可以簡化為單層傳播，具有相同的表徵學習能力。這為在圖表上構建強大而高效的 Transformer 提供了一條新的技術路徑，特別是通過簡化模型架構，而無需犧牲表達能力。正如這項工作所例證的，我們提出了一個簡化的單層圖形 Transformer (SGFormer)，其主要組成部分是一個單層全局注意力，它與圖形大小成線性比例，並且不需要任何近似來適應所有成對互動。根據經驗，SGFormer 成功地擴展到網路規模的圖表 ogbn-papers100M，在中等大小的圖表上產生了比同儕 Transformer 快幾個數量級的推論加速，並證明了在標籤資料有限的情況下具有競爭力。

##### **Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies**
2409.08864v1 by Zhiqiang Zhong, Davide Mottin

Large Language Models (LLMs) have shown remarkable capabilities in processing
various data structures, including graphs. While previous research has focused
on developing textual encoding methods for graph representation, the emergence
of multimodal LLMs presents a new frontier for graph comprehension. These
advanced models, capable of processing both text and images, offer potential
improvements in graph understanding by incorporating visual representations
alongside traditional textual data. This study investigates the impact of graph
visualisations on LLM performance across a range of benchmark tasks at node,
edge, and graph levels. Our experiments compare the effectiveness of multimodal
approaches against purely textual graph representations. The results provide
valuable insights into both the potential and limitations of leveraging visual
graph modalities to enhance LLMs' graph structure comprehension abilities.

摘要：大型語言模型 (LLM) 在處理各種數據結構（包括圖形）方面表現出非凡的能力。儘管先前的研究著重於開發圖形表示的文本編碼方法，但多模態 LLM 的出現為圖形理解提供了新的領域。這些先進的模型能夠處理文本和圖像，透過結合視覺表示與傳統文本資料，提供圖形理解的潛在改進。本研究探討圖形視覺化對 LLM 在節點、邊緣和圖形層級一系列基準任務的效能影響。我們的實驗比較了多模態方法與純文本圖形表示的有效性。結果提供了有價值的見解，了解利用視覺圖形模態來增強 LLM 圖形結構理解能力的潛力與限制。

##### **A RAG Approach for Generating Competency Questions in Ontology Engineering**
2409.08820v1 by Xueli Pan, Jacco van Ossenbruggen, Victor de Boer, Zhisheng Huang

Competency question (CQ) formulation is central to several ontology
development and evaluation methodologies. Traditionally, the task of crafting
these competency questions heavily relies on the effort of domain experts and
knowledge engineers which is often time-consuming and labor-intensive. With the
emergence of Large Language Models (LLMs), there arises the possibility to
automate and enhance this process. Unlike other similar works which use
existing ontologies or knowledge graphs as input to LLMs, we present a
retrieval-augmented generation (RAG) approach that uses LLMs for the automatic
generation of CQs given a set of scientific papers considered to be a domain
knowledge base. We investigate its performance and specifically, we study the
impact of different number of papers to the RAG and different temperature
setting of the LLM. We conduct experiments using GPT-4 on two domain ontology
engineering tasks and compare results against ground-truth CQs constructed by
domain experts. Empirical assessments on the results, utilizing evaluation
metrics (precision and consistency), reveal that compared to zero-shot
prompting, adding relevant domain knowledge to the RAG improves the performance
of LLMs on generating CQs for concrete ontology engineering tasks.

摘要：能力問題 (CQ) 的制定是幾個本体論發展和評估方法的中心。傳統上，制定這些能力問題的任務很大程度上依賴於領域專家和知識工程師的努力，這通常是耗時且勞力密集的。隨著大型語言模型 (LLM) 的出現，自動化和增強此過程的可能性出現了。與其他使用現有本体論或知識圖譜作為 LLM 輸入的類似工作不同，我們提出了一種檢索增強生成 (RAG) 方法，該方法使用 LLM 自動生成被認為是領域知識庫的一組科學論文的 CQ。我們研究其性能，特別是我們研究不同數量的論文對 RAG 的影響和 LLM 的不同溫度設置。我們使用 GPT-4 對兩個領域本体論工程任務進行實驗，並將結果與由領域專家構造的真實 CQ 進行比較。利用評估指標（精確度和一致性）對結果進行的實證評估表明，與零次提示相比，將相關領域知識添加到 RAG 可以提高 LLM 在為具體本体論工程任務生成 CQ 方面的性能。

##### **ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model**
2409.08543v1 by Zezheng Qin

Recommender Systems (RS) play a pivotal role in boosting user satisfaction by
providing personalized product suggestions in domains such as e-commerce and
entertainment. This study examines the integration of multimodal data text and
audio into large language models (LLMs) with the aim of enhancing
recommendation performance. Traditional text and audio recommenders encounter
limitations such as the cold-start problem, and recent advancements in LLMs,
while promising, are computationally expensive. To address these issues,
Low-Rank Adaptation (LoRA) is introduced, which enhances efficiency without
compromising performance. The ATFLRec framework is proposed to integrate audio
and text modalities into a multimodal recommendation system, utilizing various
LoRA configurations and modality fusion techniques. Results indicate that
ATFLRec outperforms baseline models, including traditional and graph neural
network-based approaches, achieving higher AUC scores. Furthermore, separate
fine-tuning of audio and text data with distinct LoRA modules yields optimal
performance, with different pooling methods and Mel filter bank numbers
significantly impacting performance. This research offers valuable insights
into optimizing multimodal recommender systems and advancing the integration of
diverse data modalities in LLMs.

摘要：推薦系統 (RS) 在提升使用者滿意度中扮演著舉足輕重的角色，它在電子商務和娛樂等領域提供個人化的產品建議。本研究探討將多模態資料文字和音訊整合到大型語言模型 (LLM) 中，以增強推薦效能。傳統的文字和音訊推薦器會遇到冷啟動問題等限制，而 LLM 的最新進展雖然很有前景，但計算成本很高。為了解決這些問題，引入了低秩適應 (LoRA)，它在不影響效能的情況下提升了效率。ATFLRec 框架被提出來將音訊和文字模態整合到多模態推薦系統中，利用各種 LoRA 配置和模態融合技術。結果表明，ATFLRec 優於基線模型，包括傳統和基於圖神經網路的方法，達到了更高的 AUC 分數。此外，使用不同的 LoRA 模組對音訊和文字資料進行單獨微調會產生最佳效能，不同的池化方法和 Mel 濾波器組數會對效能產生顯著影響。本研究提供了寶貴的見解，用於最佳化多模態推薦系統，並推動將不同的資料模態整合到 LLM 中。

##### **What Makes a Maze Look Like a Maze?**
2409.08202v1 by Joy Hsu, Jiayuan Mao, Joshua B. Tenenbaum, Noah D. Goodman, Jiajun Wu

A unique aspect of human visual understanding is the ability to flexibly
interpret abstract concepts: acquiring lifted rules explaining what they
symbolize, grounding them across familiar and unfamiliar contexts, and making
predictions or reasoning about them. While off-the-shelf vision-language models
excel at making literal interpretations of images (e.g., recognizing object
categories such as tree branches), they still struggle to make sense of such
visual abstractions (e.g., how an arrangement of tree branches may form the
walls of a maze). To address this challenge, we introduce Deep Schema Grounding
(DSG), a framework that leverages explicit structured representations of visual
abstractions for grounding and reasoning. At the core of DSG are
schemas--dependency graph descriptions of abstract concepts that decompose them
into more primitive-level symbols. DSG uses large language models to extract
schemas, then hierarchically grounds concrete to abstract components of the
schema onto images with vision-language models. The grounded schema is used to
augment visual abstraction understanding. We systematically evaluate DSG and
different methods in reasoning on our new Visual Abstractions Dataset, which
consists of diverse, real-world images of abstract concepts and corresponding
question-answer pairs labeled by humans. We show that DSG significantly
improves the abstract visual reasoning performance of vision-language models,
and is a step toward human-aligned understanding of visual abstractions.

摘要：人類視覺理解的獨特面向在於靈活詮釋抽象概念的能力：獲取解釋其象徵意義的提升規則，在熟悉和不熟悉的背景下奠定其基礎，並對其進行預測或推理。雖然現成的視覺語言模型擅長對影像進行字面詮釋（例如辨識樹枝等物體類別），但它們在理解此類視覺抽象概念時仍有困難（例如樹枝的排列如何形成迷宮的牆壁）。為了應對此挑戰，我們引入了深度模式基礎（DSG），這是一個框架，利用視覺抽象概念的明確結構化表示來進行基礎和推理。DSG 的核心是模式——抽象概念的依賴圖描述，將其分解為更原始層級的符號。DSG 使用大型語言模型來提取模式，然後將模式的具體組成部分分層基礎到影像上，並使用視覺語言模型。基礎模式用於擴充視覺抽象理解。我們系統性地評估了 DSG 和我們的新視覺抽象資料集上的不同推理方法，該資料集包含各種真實世界的抽象概念影像，以及由人類標記的對應問題解答對。我們證明 DSG 大幅提升了視覺語言模型的抽象視覺推理效能，並且朝著與人類一致的視覺抽象理解邁進一步。

##### **Towards a graph-based foundation model for network traffic analysis**
2409.08111v1 by Louis Van Langendonck, Ismael Castell-Uroz, Pere Barlet-Ros

Foundation models have shown great promise in various fields of study. A
potential application of such models is in computer network traffic analysis,
where these models can grasp the complexities of network traffic dynamics and
adapt to any specific task or network environment with minimal fine-tuning.
Previous approaches have used tokenized hex-level packet data and the model
architecture of large language transformer models. We propose a new, efficient
graph-based alternative at the flow-level. Our approach represents network
traffic as a dynamic spatio-temporal graph, employing a self-supervised link
prediction pretraining task to capture the spatial and temporal dynamics in
this network graph framework. To evaluate the effectiveness of our approach, we
conduct a few-shot learning experiment for three distinct downstream network
tasks: intrusion detection, traffic classification, and botnet classification.
Models finetuned from our pretrained base achieve an average performance
increase of 6.87\% over training from scratch, demonstrating their ability to
effectively learn general network traffic dynamics during pretraining. This
success suggests the potential for a large-scale version to serve as an
operational foundational model.

摘要：基礎模型已在各個研究領域中展現出極大的前景。此類模型的潛在應用之一在於電腦網路流量分析，其中這些模型可以掌握網路流量動態的複雜性，並以最小的微調適應任何特定任務或網路環境。先前的做法已使用標記化十六進位層級封包資料和大型語言轉換器模型的模型架構。我們提出一個新的、有效的流程層級圖形化替代方案。我們的做法將網路流量表示為動態時空圖形，採用自我監督連結預測預訓練任務來捕捉此網路圖形架構中的空間和時間動態。為了評估我們做法的有效性，我們對三個不同的下游網路任務（入侵偵測、流量分類和殭屍網路分類）進行少量學習實驗。從我們的預訓練基礎微調的模型，其平均效能提升 6.87%，高於從頭訓練，這證明了它們在預訓練期間有效學習一般網路流量動態的能力。這項成功顯示出大規模版本有潛力作為運作基礎模型。

##### **Learning Rules from KGs Guided by Language Models**
2409.07869v1 by Zihang Peng, Daria Stepanova, Vinh Thinh Ho, Heike Adel, Alessandra Russo, Simon Ott

Advances in information extraction have enabled the automatic construction of
large knowledge graphs (e.g., Yago, Wikidata or Google KG), which are widely
used in many applications like semantic search or data analytics. However, due
to their semi-automatic construction, KGs are often incomplete. Rule learning
methods, concerned with the extraction of frequent patterns from KGs and
casting them into rules, can be applied to predict potentially missing facts. A
crucial step in this process is rule ranking. Ranking of rules is especially
challenging over highly incomplete or biased KGs (e.g., KGs predominantly
storing facts about famous people), as in this case biased rules might fit the
data best and be ranked at the top based on standard statistical metrics like
rule confidence. To address this issue, prior works proposed to rank rules not
only relying on the original KG but also facts predicted by a KG embedding
model. At the same time, with the recent rise of Language Models (LMs), several
works have claimed that LMs can be used as alternative means for KG completion.
In this work, our goal is to verify to which extent the exploitation of LMs is
helpful for improving the quality of rule learning systems.

摘要：資訊萃取的進展已能自動建構大型知識圖譜（例如 Yago、Wikidata 或 Google KG），這些知識圖譜廣泛用於許多應用程式，例如語意搜尋或資料分析。然而，由於這些知識圖譜是半自動建構的，因此通常並不完整。規則學習方法著重於從知識圖譜中萃取頻繁模式，並將它們轉換為規則，可應用於預測潛在遺失的事實。此過程中的一個關鍵步驟是規則排序。規則排序在高度不完整或有偏差的知識圖譜（例如，主要儲存名人事實的知識圖譜）中特別具有挑戰性，因為在這種情況下，有偏差的規則可能最符合資料，並根據標準統計量度（例如規則信心）排在最前面。為了解決這個問題，先前的研究提出不只依賴原始知識圖譜，還要依賴知識圖譜嵌入模型預測的事實來對規則進行排序。同時，隨著語言模型 (LM) 的興起，一些研究聲稱 LM 可用作知識圖譜完成的替代方法。在這項研究中，我們的目標是驗證利用 LM 在多大程度上有助於提升規則學習系統的品質。

##### **Multi-object event graph representation learning for Video Question Answering**
2409.07747v1 by Yanan Wang, Shuichiro Haruta, Donghuo Zeng, Julio Vizcarra, Mori Kurokawa

Video question answering (VideoQA) is a task to predict the correct answer to
questions posed about a given video. The system must comprehend spatial and
temporal relationships among objects extracted from videos to perform causal
and temporal reasoning. While prior works have focused on modeling individual
object movements using transformer-based methods, they falter when capturing
complex scenarios involving multiple objects (e.g., "a boy is throwing a ball
in a hoop"). We propose a contrastive language event graph representation
learning method called CLanG to address this limitation. Aiming to capture
event representations associated with multiple objects, our method employs a
multi-layer GNN-cluster module for adversarial graph representation learning,
enabling contrastive learning between the question text and its relevant
multi-object event graph. Our method outperforms a strong baseline, achieving
up to 2.2% higher accuracy on two challenging VideoQA datasets, NExT-QA and
TGIF-QA-R. In particular, it is 2.8% better than baselines in handling causal
and temporal questions, highlighting its strength in reasoning multiple
object-based events.

摘要：影片問答 (VideoQA) 是一項任務，用於預測針對給定影片提出的問題的正確答案。系統必須了解從影片中提取的物件之間的空間和時間關係，才能執行因果關係和時間推理。雖然先前的研究集中於使用基於Transformer的模型來建模個別物件的動作，但在捕捉涉及多個物件的複雜場景（例如「一個男孩正在將球投進籃框」）時，它們會出現問題。我們提出了一個對比式語言事件圖表表示學習方法，稱為 CLanG，以解決此限制。為了捕捉與多個物件相關的事件表示，我們的模型採用多層 GNN 集群模組進行對抗式圖表表示學習，使問題文字及其相關的多物件事件圖表之間能夠進行對比式學習。我們的模型優於強大的基準，在兩個具有挑戰性的 VideoQA 資料集 NExT-QA 和 TGIF-QA-R 上達到了高達 2.2% 的更高準確度。特別是，在處理因果關係和時間問題方面比基準高出 2.8%，突顯了它在推理多個基於物件的事件方面的優勢。

##### **Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**
2409.07368v3 by Khiem Ton, Nhi Nguyen, Mahmoud Nazzal, Abdallah Khreishah, Cristian Borcea, NhatHai Phan, Ruoming Jin, Issa Khalil, Yelong Shen

This paper introduces SGCode, a flexible prompt-optimizing system to generate
secure code with large language models (LLMs). SGCode integrates recent
prompt-optimization approaches with LLMs in a unified system accessible through
front-end and back-end APIs, enabling users to 1) generate secure code, which
is free of vulnerabilities, 2) review and share security analysis, and 3)
easily switch from one prompt optimization approach to another, while providing
insights on model and system performance. We populated SGCode on an AWS server
with PromSec, an approach that optimizes prompts by combining an LLM and
security tools with a lightweight generative adversarial graph neural network
to detect and fix security vulnerabilities in the generated code. Extensive
experiments show that SGCode is practical as a public tool to gain insights
into the trade-offs between model utility, secure code generation, and system
cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is
available at: https://sgcode.codes/.

摘要：本文介紹 SGCode，一個彈性的提示最佳化系統，用於生成大型語言模型 (LLM) 的安全程式碼。SGCode 將最近的提示最佳化方法與 LLM 整合在一個統一的系統中，可透過前端和後端 API 存取，使用戶能夠 1) 產生安全的程式碼，沒有漏洞，2) 檢閱和分享安全性分析，以及 3) 從一種提示最佳化方法輕鬆切換到另一種，同時提供模型和系統效能的見解。我們在 AWS 伺服器上使用 PromSec 填充 SGCode，這是一種透過結合 LLM 和安全性工具，以及輕量級生成對抗圖形神經網路來最佳化提示，以偵測和修復產生程式碼中的安全性漏洞的方法。廣泛的實驗顯示，SGCode 作為一個公用工具，在模型效用、安全程式碼產生和系統成本之間的權衡中獲得見解，是實用的。與提示 LLM 相比，SGCode 只有邊際成本。SGCode 可在 https://sgcode.codes/ 取得。

##### **Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs**
2409.12171v1 by William Van Woensel, Oshani Seneviratne

Background: Health 3.0 allows decision making to be based on longitudinal
data from multiple institutions, from across the patient's healthcare journey.
In such a distributed setting, blockchain smart contracts can act as neutral
intermediaries to implement trustworthy decision making.
  Objective: In a distributed setting, transmitted data will be structured
using standards (such as HL7 FHIR) for semantic interoperability. In turn, the
smart contract will require interoperability with this standard, implement a
complex communication setup (e.g., using oracles), and be developed using
blockchain languages (e.g., Solidity). We propose the encoding of smart
contract logic using a high-level semantic Knowledge Graph, using concepts from
the domain standard. We then deploy this semantic KG on blockchain.
  Methods: Off-chain, a code generation pipeline compiles the KG into a
concrete smart contract, which is then deployed on-chain. Our pipeline targets
an intermediary bridge representation, which can be transpiled into a specific
blockchain language. Our choice avoids on-chain rule engines, with
unpredictable and likely higher computational cost; it is thus in line with the
economic rules of blockchain.
  Results: We applied our code generation approach to generate smart contracts
for 3 health insurance cases from Medicare. We discuss the suitability of our
approach - the need for a neutral intermediary - for a number of healthcare use
cases. Our evaluation finds that the generated contracts perform well in terms
of correctness and execution cost ("gas") on blockchain.
  Conclusions: We showed that it is feasible to automatically generate smart
contract code based on a semantic KG, in a way that respects the economic rules
of blockchain. Future work includes studying the use of Large Language Models
(LLM) in our approach, and evaluations on other blockchains.

摘要：<paragraph>背景：Health 3.0 允許決策制定基於來自多個機構的縱向數據，來自患者的醫療保健歷程。在這種分布式設置中，區塊鏈智能合約可以作為中立的仲介來實施值得信賴的決策制定。目標：在分布式設置中，傳輸的數據將使用標準（例如 HL7 FHIR）進行結構化，以實現語義互操作性。反過來，智能合約將需要與此標準互操作，實施複雜的通信設置（例如，使用預言機），並使用區塊鏈語言（例如，Solidity）開發。我們提議使用來自領域標準的概念，使用高級語義知識圖對智能合約邏輯進行編碼。然後我們將這個語義知識圖部署在區塊鏈上。方法：鏈下，一個代碼生成管道將知識圖編譯成具體的智能合約，然後將其部署到鏈上。我們的管道針對中間橋接表示，可以轉譯成特定的區塊鏈語言。我們的選擇避免了鏈上規則引擎，其不可預測且可能計算成本更高；因此，它符合區塊鏈的經濟規則。結果：我們應用我們的代碼生成方法來生成來自 Medicare 的 3 個健康保險案例的智能合約。我們討論了我們的方法的適用性——對中立仲介的需求——對於許多醫療保健用例。我們的評估發現，生成的合約在區塊鏈上的正確性和執行成本（“gas”）方面表現良好。結論：我們表明，以符合區塊鏈經濟規則的方式自動生成基於語義知識圖的智能合約代碼是可行的。未來的研究包括研究我們的方法中使用大型語言模型 (LLM)，以及對其他區塊鏈的評估。</paragraph>

##### **Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model**
2409.07088v1 by Daehee Kim, Deokhyung Kang, Sangwon Ryu, Gary Geunbae Lee

Knowledge Graph-to-Text (G2T) generation involves verbalizing structured
knowledge graphs into natural language text. Recent advancements in Pretrained
Language Models (PLMs) have improved G2T performance, but their effectiveness
depends on datasets with precise graph-text alignment. However, the scarcity of
high-quality, general-domain G2T generation datasets restricts progress in the
general-domain G2T generation research. To address this issue, we introduce
Wikipedia Ontology-Free Graph-text dataset (WikiOFGraph), a new large-scale G2T
dataset generated using a novel method that leverages Large Language Model
(LLM) and Data-QuestEval. Our new dataset, which contains 5.85M general-domain
graph-text pairs, offers high graph-text consistency without relying on
external ontologies. Experimental results demonstrate that PLM fine-tuned on
WikiOFGraph outperforms those trained on other datasets across various
evaluation metrics. Our method proves to be a scalable and effective solution
for generating high-quality G2T data, significantly advancing the field of G2T
generation.

摘要：知識圖譜到文字 (G2T) 生成涉及將結構化知識圖譜表達為自然語言文字。預訓練語言模型 (PLM) 的最新進展改善了 G2T 的效能，但其有效性取決於具有精確圖形文字對齊的資料集。然而，高品質、一般領域 G2T 生成資料集的稀少性限制了一般領域 G2T 生成研究的進展。為了解決這個問題，我們引入了維基百科本体免費圖形文字資料集 (WikiOFGraph)，這是一個使用利用大型語言模型 (LLM) 和 Data-QuestEval 的新方法生成的新大型 G2T 資料集。我們的這個新資料集包含 585 萬個一般領域的圖形文字對，提供高圖形文字一致性，而不依賴於外部本体。實驗結果表明，在 WikiOFGraph 上微調的 PLM 在各種評估指標上優於在其他資料集上訓練的 PLM。我們的這個方法被證明是一個可擴充且有效的解決方案，用於生成高品質的 G2T 資料，顯著推動了 G2T 生成領域的發展。

##### **Automated Speaking Assessment of Conversation Tests with Novel Graph-based Modeling on Spoken Response Coherence**
2409.07064v1 by Jiun-Ting Li, Bi-Cheng Yan, Tien-Hong Lo, Yi-Cheng Wang, Yung-Chang Hsu, Berlin Chen

Automated speaking assessment in conversation tests (ASAC) aims to evaluate
the overall speaking proficiency of an L2 (second-language) speaker in a
setting where an interlocutor interacts with one or more candidates. Although
prior ASAC approaches have shown promising performance on their respective
datasets, there is still a dearth of research specifically focused on
incorporating the coherence of the logical flow within a conversation into the
grading model. To address this critical challenge, we propose a hierarchical
graph model that aptly incorporates both broad inter-response interactions
(e.g., discourse relations) and nuanced semantic information (e.g., semantic
words and speaker intents), which is subsequently fused with contextual
information for the final prediction. Extensive experimental results on the
NICT-JLE benchmark dataset suggest that our proposed modeling approach can
yield considerable improvements in prediction accuracy with respect to various
assessment metrics, as compared to some strong baselines. This also sheds light
on the importance of investigating coherence-related facets of spoken responses
in ASAC.

摘要：自動對話評量中的自動化口說評量（ASAC）旨在評估 L2（第二語言）話者在與一位或多位應試者互動的環境中，整體的口說能力。儘管先前的 ASAC 方法在其各自的資料集上展現出有前途的表現，但仍缺乏專注於將對話中邏輯流程的連貫性納入評分模型的研究。為了應對這項關鍵挑戰，我們提出了一個階層式圖形模型，它適當地結合了廣泛的回應間互動（例如：語篇關係）和細微的語義資訊（例如：語義字詞和說話者意圖），隨後與脈絡資訊融合，以進行最終預測。在 NICT-JLE 基準資料集上進行的廣泛實驗結果表明，與一些強大的基準線相比，我們提出的建模方法可以顯著提升預測準確度，特別是在各種評量指標方面。這也闡明了在 ASAC 中探討口語回應的連貫性相關面向的重要性。

##### **FreeRide: Harvesting Bubbles in Pipeline Parallelism**
2409.06941v1 by Jiashu Zhang, Zihan Pan, Molly, Xu, Khuzaima Daudjee, Sihang Liu

The occurrence of bubbles in pipeline parallelism is an inherent limitation
that can account for more than 40% of the large language model (LLM) training
time and is one of the main reasons for the underutilization of GPU resources
in LLM training. Harvesting these bubbles for GPU side tasks can increase
resource utilization and reduce training costs but comes with challenges.
First, because bubbles are discontinuous with various shapes, programming side
tasks becomes difficult while requiring excessive engineering effort. Second, a
side task can compete with pipeline training for GPU resources and incur
significant overhead. To address these challenges, we propose FreeRide, a
system designed to harvest bubbles in pipeline parallelism for side tasks.
FreeRide provides programmers with interfaces to implement side tasks easily,
manages bubbles and side tasks during pipeline training, and controls access to
GPU resources by side tasks to reduce overhead. We demonstrate that FreeRide
achieves 7.8% average cost savings with a negligible overhead of about 1% in
training LLMs while serving model training, graph analytics, and image
processing side tasks.

摘要：管線平行處理中發生氣泡是一個固有限制，可能佔大型語言模型 (LLM) 訓練時間的 40% 以上，並且是 LLM 訓練中 GPU 資源利用不足的主要原因之一。收集這些氣泡以進行 GPU 側面任務可以提高資源利用率並降低訓練成本，但會帶來挑戰。首先，由於氣泡是不連續的且形狀各異，因此編寫程式側面任務變得困難，同時需要過多的工程工作。其次，側面任務可能會與管線訓練競爭 GPU 資源，並造成顯著的開銷。為了應對這些挑戰，我們提出了 FreeRide，這是一個旨在收集管線平行處理中的氣泡以進行側面任務的系統。FreeRide 為程式設計師提供了輕鬆實作側面任務的介面，在管線訓練期間管理氣泡和側面任務，並控制側面任務對 GPU 資源的存取以減少開銷。我們證明 FreeRide 在訓練 LLM 時可節省 7.8% 的平均成本，同時在執行模型訓練、圖形分析和影像處理側面任務時，開銷可忽略不計，約為 1%。

##### **Generative Hierarchical Materials Search**
2409.06762v1 by Sherry Yang, Simon Batzner, Ruiqi Gao, Muratahan Aykol, Alexander L. Gaunt, Brendan McMorrow, Danilo J. Rezende, Dale Schuurmans, Igor Mordatch, Ekin D. Cubuk

Generative models trained at scale can now produce text, video, and more
recently, scientific data such as crystal structures. In applications of
generative approaches to materials science, and in particular to crystal
structures, the guidance from the domain expert in the form of high-level
instructions can be essential for an automated system to output candidate
crystals that are viable for downstream research. In this work, we formulate
end-to-end language-to-structure generation as a multi-objective optimization
problem, and propose Generative Hierarchical Materials Search (GenMS) for
controllable generation of crystal structures. GenMS consists of (1) a language
model that takes high-level natural language as input and generates
intermediate textual information about a crystal (e.g., chemical formulae), and
(2) a diffusion model that takes intermediate information as input and
generates low-level continuous value crystal structures. GenMS additionally
uses a graph neural network to predict properties (e.g., formation energy) from
the generated crystal structures. During inference, GenMS leverages all three
components to conduct a forward tree search over the space of possible
structures. Experiments show that GenMS outperforms other alternatives of
directly using language models to generate structures both in satisfying user
request and in generating low-energy structures. We confirm that GenMS is able
to generate common crystal structures such as double perovskites, or spinels,
solely from natural language input, and hence can form the foundation for more
complex structure generation in near future.

摘要：<paragraph>大規模訓練的生成模型現在可以產生文字、影片，以及最近的科學資料，例如晶體結構。在生成方法應用於材料科學，尤其是晶體結構時，領域專家的指導，以高階指令的形式，對於自動化系統輸出可行於下游研究的候選晶體至關重要。在這項工作中，我們將端對端語言到結構生成制定為多目標最佳化問題，並提出生成分層材料搜尋 (GenMS) 以控制晶體結構的生成。GenMS 包含 (1) 一個語言模型，它將高階自然語言作為輸入，並生成有關晶體的中間文字資訊（例如化學公式），以及 (2) 一個擴散模型，它將中間資訊作為輸入，並生成低階連續值晶體結構。GenMS 此外使用圖形神經網路從生成的晶體結構預測屬性（例如形成能）。在推理期間，GenMS 利用所有三個組件對可能的結構空間進行前向樹狀搜尋。實驗顯示，GenMS 優於直接使用語言模型來生成結構的其他替代方案，無論是在滿足使用者要求或生成低能結構方面。我們確認 GenMS 能夠僅從自然語言輸入生成常見的晶體結構，例如雙鈣鈦礦或尖晶石，因此可以在不久的將來形成更複雜結構生成的基礎。</paragraph>

##### **Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization**
2409.06433v1 by Gollam Rabby, Sören Auer, Jennifer D'Souza, Allard Oelen

The increasing amount of published scholarly articles, exceeding 2.5 million
yearly, raises the challenge for researchers in following scientific progress.
Integrating the contributions from scholarly articles into a novel type of
cognitive knowledge graph (CKG) will be a crucial element for accessing and
organizing scholarly knowledge, surpassing the insights provided by titles and
abstracts. This research focuses on effectively conveying structured scholarly
knowledge by utilizing large language models (LLMs) to categorize scholarly
articles and describe their contributions in a structured and comparable
manner. While previous studies explored language models within specific
research domains, the extensive domain-independent knowledge captured by LLMs
offers a substantial opportunity for generating structured contribution
descriptions as CKGs. Additionally, LLMs offer customizable pathways through
prompt engineering or fine-tuning, thus facilitating to leveraging of smaller
LLMs known for their efficiency, cost-effectiveness, and environmental
considerations. Our methodology involves harnessing LLM knowledge, and
complementing it with domain expert-verified scholarly data sourced from a CKG.
This strategic fusion significantly enhances LLM performance, especially in
tasks like scholarly article categorization and predicate recommendation. Our
method involves fine-tuning LLMs with CKG knowledge and additionally injecting
knowledge from a CKG with a novel prompting technique significantly increasing
the accuracy of scholarly knowledge extraction. We integrated our approach in
the Open Research Knowledge Graph (ORKG), thus enabling precise access to
organized scholarly knowledge, crucially benefiting domain-independent
scholarly knowledge exchange and dissemination among policymakers, industrial
practitioners, and the general public.

摘要：<paragraph>每年超過 250 萬篇的學術文章發表數量持續增加，對研究人員追蹤科學進展帶來挑戰。將學術文章的貢獻整合到新型態的認知知識圖譜 (CKG) 中，將成為存取和組織學術知識的關鍵要素，超越標題和摘要提供的見解。本研究專注於有效傳達結構化的學術知識，利用大型語言模型 (LLM) 來分類學術文章，並以結構化且可比較的形式描述其貢獻。雖然先前的研究在特定研究領域中探索語言模型，但 LLM 捕捉到的廣泛領域無關知識，為產生結構化的貢獻描述提供了實質機會，例如 CKG。此外，LLM 透過提示工程或微調提供可自訂路徑，從而促進利用以效率、成本效益和環境考量聞名的較小型 LLM。我們的做法包括利用 LLM 知識，並透過 CKG 來源的領域專家驗證學術資料來補充。這種策略融合顯著提升 LLM 的效能，特別是在學術文章分類和謂詞推薦等任務中。我們的方法包括以 CKG 知識微調 LLM，並透過新的提示技術注入 CKG 的知識，顯著提升學術知識萃取的準確度。我們將我們的做法整合到開放研究知識圖譜 (ORKG) 中，從而能精準存取已組織的學術知識，這對政策制定者、產業從業人員和一般大眾之間的領域無關學術知識交流和傳播至關重要。</paragraph>

##### **TopoChat: Enhancing Topological Materials Retrieval With Large Language Model and Multi-Source Knowledge**
2409.13732v1 by HuangChao Xu, Baohua Zhang, Zhong Jin, Tiannian Zhu, Quansheng Wu, Hongming Weng

Large language models (LLMs), such as ChatGPT, have demonstrated impressive
performance in the text generation task, showing the ability to understand and
respond to complex instructions. However, the performance of naive LLMs in
speciffc domains is limited due to the scarcity of domain-speciffc corpora and
specialized training. Moreover, training a specialized large-scale model
necessitates signiffcant hardware resources, which restricts researchers from
leveraging such models to drive advances. Hence, it is crucial to further
improve and optimize LLMs to meet speciffc domain demands and enhance their
scalability. Based on the condensed matter data center, we establish a material
knowledge graph (MaterialsKG) and integrate it with literature. Using large
language models and prompt learning, we develop a specialized dialogue system
for topological materials called TopoChat. Compared to naive LLMs, TopoChat
exhibits superior performance in structural and property querying, material
recommendation, and complex relational reasoning. This system enables efffcient
and precise retrieval of information and facilitates knowledge interaction,
thereby encouraging the advancement on the ffeld of condensed matter materials.

摘要：大型語言模型（LLM），例如 ChatGPT，在文本生成任務中展現了令人印象深刻的表現，展現了理解和回應複雜指令的能力。然而，由於缺乏特定領域的語料庫和專業訓練，天真的 LLM 在特定領域的表現受到限制。此外，訓練一個專業的大規模模型需要大量的硬體資源，這限制了研究人員利用這些模型來推動進展。因此，進一步改進和優化 LLM 以滿足特定領域的需求並增強其可擴充性至關重要。基於凝聚態資料中心，我們建立了一個材料知識圖譜（MaterialsKG），並將其與文獻整合。使用大型語言模型和提示學習，我們開發了一個名為 TopoChat 的拓撲材料專用對話系統。與天真的 LLM 相比，TopoChat 在結構和屬性查詢、材料推薦和複雜關係推理方面表現出優異的性能。該系統能夠有效且準確地檢索資訊，並促進知識互動，從而促進凝聚態材料領域的進步。

##### **KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation**
2409.13731v3 by Lei Liang, Mengshu Sun, Zhengke Gui, Zhongshu Zhu, Zhouyu Jiang, Ling Zhong, Yuan Qu, Peilong Zhao, Zhongpu Bo, Jin Yang, Huaidong Xiong, Lin Yuan, Jun Xu, Zaoyang Wang, Zhiqiang Zhang, Wen Zhang, Huajun Chen, Wenguang Chen, Jun Zhou

The recently developed retrieval-augmented generation (RAG) technology has
enabled the efficient construction of domain-specific applications. However, it
also has limitations, including the gap between vector similarity and the
relevance of knowledge reasoning, as well as insensitivity to knowledge logic,
such as numerical values, temporal relations, expert rules, and others, which
hinder the effectiveness of professional knowledge services. In this work, we
introduce a professional domain knowledge service framework called Knowledge
Augmented Generation (KAG). KAG is designed to address the aforementioned
challenges with the motivation of making full use of the advantages of
knowledge graph(KG) and vector retrieval, and to improve generation and
reasoning performance by bidirectionally enhancing large language models (LLMs)
and KGs through five key aspects: (1) LLM-friendly knowledge representation,
(2) mutual-indexing between knowledge graphs and original chunks, (3)
logical-form-guided hybrid reasoning engine, (4) knowledge alignment with
semantic reasoning, and (5) model capability enhancement for KAG. We compared
KAG with existing RAG methods in multihop question answering and found that it
significantly outperforms state-of-theart methods, achieving a relative
improvement of 19.6% on 2wiki and 33.5% on hotpotQA in terms of F1 score. We
have successfully applied KAG to two professional knowledge Q&A tasks of Ant
Group, including E-Government Q&A and E-Health Q&A, achieving significant
improvement in professionalism compared to RAG methods.

摘要：最近開發的檢索增強生成 (RAG) 技術已能有效建構特定領域的應用程式。然而，它也有一些限制，包括向量相似度與知識推理相關性之間的差距，以及對知識邏輯的不敏感性，例如數字值、時間關係、專家規則等，這些限制阻礙了專業知識服務的有效性。在這項工作中，我們引入了稱為知識增強生成 (KAG) 的專業領域知識服務架構。KAG 旨在解決上述挑戰，目的是充分利用知識圖 (KG) 和向量檢索的優勢，並通過以下五個關鍵方面雙向增強大型語言模型 (LLM) 和 KG 來改善生成和推理效能：(1) LLM 友善的知識表示，(2) 知識圖與原始區塊之間的相互索引，(3) 邏輯形式引導的混合推理引擎，(4) 與語義推理的知識對齊，以及 (5) KAG 的模型功能增強。我們在多跳問題解答中比較了 KAG 與現有的 RAG 方法，發現它顯著優於現有技術，在 F1 分數方面，在 2wiki 上提高了 19.6%，在 hotpotQA 上提高了 33.5%。我們已成功將 KAG 應用於螞蟻集團的兩個專業知識問答任務，包括電子政務問答和電子健康問答，與 RAG 方法相比，專業性有顯著提升。

##### **Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**
2409.06091v1 by Dongyue Li, Aneesh Sharma, Hongyang R. Zhang

Multitask learning is a widely used paradigm for training models on diverse
tasks, with applications ranging from graph neural networks to language model
fine-tuning. Since tasks may interfere with each other, a key notion for
modeling their relationships is task affinity. This includes pairwise task
affinity, computed among pairs of tasks, and higher-order affinity, computed
among subsets of tasks. Naively computing either of them requires repeatedly
training on data from various task combinations, which is computationally
intensive. We present a new algorithm Grad-TAG that can estimate task
affinities without this repeated training.
  The key idea of Grad-TAG is to train a "base" model for all tasks and then
use a linearization technique to estimate the loss of the model for a specific
task combination. The linearization works by computing a gradient-based
approximation of the loss, using low-dimensional projections of gradients as
features in a logistic regression to predict labels for the task combination.
We show that the linearized model can provably approximate the loss when the
gradient-based approximation is accurate, and also empirically verify that on
several large models. Then, given the estimated task affinity, we design a
semi-definite program for clustering similar tasks by maximizing the average
density of clusters.
  We evaluate Grad-TAG's performance across seven datasets, including
multi-label classification on graphs, and instruction fine-tuning of language
models. Our task affinity estimates are within 2.7% distance to the true
affinities while needing only 3% of FLOPs in full training. On our largest
graph with 21M edges and 500 labeling tasks, our algorithm delivers estimates
within 5% distance to the true affinities, using only 112 GPU hours. Our
results show that Grad-TAG achieves excellent performance and runtime tradeoffs
compared to existing approaches.

摘要：多任務學習是一種廣泛使用的範例，用於在不同的任務上訓練模型，其應用範圍從圖神經網路到語言模型微調。由於任務可能會相互干擾，因此建模它們關係的一個關鍵概念是任務親和性。這包括成對任務親和性，在成對任務之間計算，以及高階親和性，在任務子集之間計算。天真地計算其中任何一個都需要重複訓練來自各種任務組合的資料，這在計算上很密集。我們提出了一種新的演算法 Grad-TAG，它可以在沒有重複訓練的情況下估計任務親和性。
Grad-TAG 的關鍵思想是為所有任務訓練一個「基礎」模型，然後使用線性化技術來估計模型對特定任務組合的損失。線性化通過計算損失的基於梯度的近似值來工作，使用梯度的低維投影作為特徵，在邏輯迴歸中預測任務組合的標籤。我們證明了當基於梯度的近似值準確時，線性化模型可以證明地近似損失，並且在幾個大型模型上經驗驗證了這一點。然後，給定估計的任務親和性，我們設計了一個半定程式，通過最大化叢集的平均密度來對類似的任務進行叢集。
我們評估了 Grad-TAG 在七個資料集上的效能，包括圖形上的多標籤分類，以及語言模型的指令微調。我們的任務親和性估計與真實親和性距離在 2.7% 以內，同時只需要 3% 的 FLOP 進行完整訓練。在我們最大的圖形（有 2100 萬條邊和 500 個標籤任務）上，我們的演算法提供的估計與真實親和性距離在 5% 以內，只使用 112 個 GPU 小時。我們的結果表明，與現有方法相比，Grad-TAG 在效能和執行時間權衡方面取得了優異的表現。

##### **OneEdit: A Neural-Symbolic Collaboratively Knowledge Editing System**
2409.07497v1 by Ningyu Zhang, Zekun Xi, Yujie Luo, Peng Wang, Bozhong Tian, Yunzhi Yao, Jintian Zhang, Shumin Deng, Mengshu Sun, Lei Liang, Zhiqiang Zhang, Xiaowei Zhu, Jun Zhou, Huajun Chen

Knowledge representation has been a central aim of AI since its inception.
Symbolic Knowledge Graphs (KGs) and neural Large Language Models (LLMs) can
both represent knowledge. KGs provide highly accurate and explicit knowledge
representation, but face scalability issue; while LLMs offer expansive coverage
of knowledge, but incur significant training costs and struggle with precise
and reliable knowledge manipulation. To this end, we introduce OneEdit, a
neural-symbolic prototype system for collaborative knowledge editing using
natural language, which facilitates easy-to-use knowledge management with KG
and LLM. OneEdit consists of three modules: 1) The Interpreter serves for user
interaction with natural language; 2) The Controller manages editing requests
from various users, leveraging the KG with rollbacks to handle knowledge
conflicts and prevent toxic knowledge attacks; 3) The Editor utilizes the
knowledge from the Controller to edit KG and LLM. We conduct experiments on two
new datasets with KGs which demonstrate that OneEdit can achieve superior
performance.

摘要：知識表徵自人工智慧誕生以來一直是其核心目標。
符號知識圖譜 (KG) 和神經語言大模型 (LLM) 都可以表徵知識。KG 提供高度準確且明確的知識表徵，但面臨可擴充性的問題；而 LLM 提供廣泛的知識涵蓋範圍，但會產生大量的訓練成本，並且在精確且可靠的知識操作方面遇到困難。為了解決這個問題，我們引入了 OneEdit，這是一個使用自然語言進行協作知識編輯的神經符號原型系統，它促進了使用 KG 和 LLM 進行易於使用的知識管理。OneEdit 包含三個模組：1) 解譯器用於使用者透過自然語言進行互動；2) 控制器管理來自不同使用者的編輯請求，利用 KG 和回滾來處理知識衝突並防止有毒的知識攻擊；3) 編輯器利用來自控制器的知識來編輯 KG 和 LLM。我們對兩個具有 KG 的新資料集進行了實驗，證明 OneEdit 可以實現優異的效能。

##### **SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning**
2409.05556v1 by Alireza Ghafarollahi, Markus J. Buehler

A key challenge in artificial intelligence is the creation of systems capable
of autonomously advancing scientific understanding by exploring novel domains,
identifying complex patterns, and uncovering previously unseen connections in
vast scientific data. In this work, we present SciAgents, an approach that
leverages three core concepts: (1) the use of large-scale ontological knowledge
graphs to organize and interconnect diverse scientific concepts, (2) a suite of
large language models (LLMs) and data retrieval tools, and (3) multi-agent
systems with in-situ learning capabilities. Applied to biologically inspired
materials, SciAgents reveals hidden interdisciplinary relationships that were
previously considered unrelated, achieving a scale, precision, and exploratory
power that surpasses traditional human-driven research methods. The framework
autonomously generates and refines research hypotheses, elucidating underlying
mechanisms, design principles, and unexpected material properties. By
integrating these capabilities in a modular fashion, the intelligent system
yields material discoveries, critique and improve existing hypotheses, retrieve
up-to-date data about existing research, and highlights their strengths and
limitations. Our case studies demonstrate scalable capabilities to combine
generative AI, ontological representations, and multi-agent modeling,
harnessing a `swarm of intelligence' similar to biological systems. This
provides new avenues for materials discovery and accelerates the development of
advanced materials by unlocking Nature's design principles.

摘要：在人工智能中，一個關鍵的挑戰是創造出有能力透過探索新領域、識別複雜模式，以及在大量的科學數據中發現前所未見的關聯，來自主推進科學理解的系統。在這項工作中，我們提出了 SciAgents，一種利用三個核心概念的方法：(1) 使用大規模的本体知識圖譜來整理和連結不同的科學概念，(2) 一套大型語言模型 (LLM) 和數據檢索工具，以及 (3) 具有原位學習能力的多代理系統。應用於生物啟發材料，SciAgents 揭示了以前被認為無關的隱藏跨學科關係，達到了超越傳統人為研究方法的規模、精確度和探索能力。該框架自主生成和優化研究假設，闡明基礎機制、設計原理和意外的材料特性。透過以模組化方式整合這些能力，智能系統產生材料發現、批判和改進現有假設、檢索關於現有研究的最新數據，並強調它們的優點和限制。我們的案例研究展示了結合生成式 AI、本体表示和多代理建模的可擴充能力，利用類似於生物系統的「智慧群體」。這為材料發現提供了新途徑，並透過解鎖大自然的設計原理來加速先進材料的開發。

##### **Assessing SPARQL capabilities of Large Language Models**
2409.05925v1 by Lars-Peter Meyer, Johannes Frey, Felix Brei, Natanael Arndt

The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)
offers significant synergistic potential for knowledge-driven applications. One
possible integration is the interpretation and generation of formal languages,
such as those used in the Semantic Web, with SPARQL being a core technology for
accessing KGs. In this paper, we focus on measuring out-of-the box capabilities
of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries
applying a quantitative approach.
  We implemented various benchmarking tasks in the LLM-KG-Bench framework for
automated execution and evaluation with several LLMs. The tasks assess
capabilities along the dimensions of syntax, semantic read, semantic create,
and the role of knowledge graph prompt inclusion.
  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,
and Claude models. Our findings indicate that working with SPARQL SELECT
queries is still challenging for LLMs and heavily depends on the specific LLM
as well as the complexity of the task. While fixing basic syntax errors seems
to pose no problems for the best of the current LLMs evaluated, creating
semantically correct SPARQL SELECT queries is difficult in several cases.

摘要：大型語言模型 (LLM) 與知識圖譜 (KG) 的整合為知識驅動應用程式提供了顯著的綜效潛力。一種可能的整合是解釋和產生形式化語言，例如語義網路中使用的語言，而 SPARQL 是存取 KG 的核心技術。在本文中，我們專注於衡量 LLM 開箱即用的能力，以使用 SPARQL，更具體地說，使用 SPARQL SELECT 查詢應用量化方法。
  我們在 LLM-KG-Bench 架構中實作了各種基準測試任務，以自動執行和評估多個 LLM。這些任務評估了語法、語義讀取、語義建立和知識圖譜提示包含的角色等面向的能力。
  有了這些新的基準測試任務，我們評估了 GPT、Gemini 和 Claude 模型的選項。我們的研究結果表明，使用 SPARQL SELECT 查詢對於 LLM 來說仍然具有挑戰性，並且在很大程度上取決於具體的 LLM 以及任務的複雜性。儘管修復基本的語法錯誤似乎對目前評估的最佳 LLM 來說不成問題，但在某些情況下建立語義正確的 SPARQL SELECT 查詢很困難。

##### **KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**
2409.05370v1 by Yingshu Li, Zhanyu Wang, Yunyi Liu, Lei Wang, Lingqiao Liu, Luping Zhou

Harnessing the robust capabilities of Large Language Models (LLMs) for
narrative generation, logical reasoning, and common-sense knowledge
integration, this study delves into utilizing LLMs to enhance automated
radiology report generation (R2Gen). Despite the wealth of knowledge within
LLMs, efficiently triggering relevant knowledge within these large models for
specific tasks like R2Gen poses a critical research challenge. This paper
presents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration
framework based on LLMs. Utilizing a frozen LLM to generate reports, the
framework integrates a knowledge graph to unlock chest disease-related
knowledge within the LLM to enhance the clinical utility of generated reports.
This is achieved by leveraging the knowledge graph to distill disease-related
features in a designed way. Since a radiology report encompasses both normal
and disease-related findings, the extracted graph-enhanced disease-related
features are integrated with regional image features, attending to both
aspects. We explore two fusion methods to automatically prioritize and select
the most relevant features. The fused features are employed by LLM to generate
reports that are more sensitive to diseases and of improved quality. Our
approach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets.

摘要：<paragraph>利用大型語言模型 (LLM) 強大的功能，進行敘事生成、邏輯推理和常識知識整合，本研究深入探討利用 LLM 來增強自動化放射報告生成 (R2Gen)。儘管 LLM 擁有豐富的知識，但要有效觸發這些大型模型中與特定任務（如 R2Gen）相關的知識，是一個重要的研究挑戰。本文提出了 KARGEN，一個基於 LLM 的知識增強自動化放射報告生成框架。利用凍結的 LLM 來生成報告，該框架整合了一個知識圖譜，以解鎖 LLM 中與胸部疾病相關的知識，以增強生成報告的臨床效用。這是透過利用知識圖譜以設計的方式提取與疾病相關的特徵來實現的。由於放射報告包含正常和疾病相關的發現，因此提取的圖形增強疾病相關特徵與區域影像特徵整合，兼顧兩個方面。我們探索了兩種融合方法，以自動優先排序和選擇最相關的特徵。融合的特徵由 LLM 使用，以生成對疾病更敏感且品質更高的報告。我們的做法在 MIMIC-CXR 和 IU-Xray 資料集上展示了有希望的結果。</paragraph>

##### **Action is the primary key: a categorical framework for episode description and logical reasoning**
2409.04793v1 by Yoshiki Fukada

This research presents a computational framework for describing and
recognizing episodes and for logical reasoning. This framework, named
cognitive-logs, consists of a set of relational and graph databases.
Cognitive-logs record knowledge, particularly in episodes that consist of
"actions" represented by verbs in natural languages and "participants" who
perform the actions. These objects are connected by arrows (morphisms) that
link each action to its participant and link cause to effect. Operations based
on category theory enable comparisons between episodes and deductive
inferences, including abstractions of stories. One of the goals of this study
is to develop a database-driven artificial intelligence. This artificial
intelligence thinks like a human but possesses the accuracy and rigour of a
machine. The vast capacities of databases (up to petabyte scales in current
technologies) enable the artificial intelligence to store a greater volume of
knowledge than neural-network based artificial intelligences. Cognitive-logs
serve as a model of human cognition and designed with references to cognitive
linguistics. Cognitive-logs also have the potential to model various human mind
activities.

摘要：本研究提出一個計算框架，用來描述和辨識事件以及進行邏輯推理。這個框架名為認知日誌，包含一組關聯式和圖形資料庫。認知日誌記錄知識，特別是包含由自然語言中的動詞表示的「動作」和執行動作的「參與者」的事件。這些物件由箭頭（態射）連接，將每個動作連結到其參與者，並將原因連結到結果。基於範疇論的運算可比較事件和演繹推論，包括故事的抽象化。本研究的目標之一是開發一個資料庫驅動的人工智慧。這個人工智慧思考方式像人類，但擁有機器般的準確性和嚴謹性。資料庫的龐大容量（在目前的技術中可達皮位元組等級）使人工智慧能夠儲存比基於神經網路的人工智慧更大的知識量。認知日誌作為人類認知的模型，並參考認知語言學進行設計。認知日誌也有潛力模擬各種人類心智活動。

##### **Accelerating Training with Neuron Interaction and Nowcasting Networks**
2409.04434v1 by Boris Knyazev, Abhinav Moudgil, Guillaume Lajoie, Eugene Belilovsky, Simon Lacoste-Julien

Neural network training can be accelerated when a learnable update rule is
used in lieu of classic adaptive optimizers (e.g. Adam). However, learnable
update rules can be costly and unstable to train and use. A simpler recently
proposed approach to accelerate training is to use Adam for most of the
optimization steps and periodically, only every few steps, nowcast (predict
future) parameters. We improve this approach by Neuron interaction and
Nowcasting (NiNo) networks. NiNo leverages neuron connectivity and graph neural
networks to more accurately nowcast parameters by learning in a supervised way
from a set of training trajectories over multiple tasks. We show that in some
networks, such as Transformers, neuron connectivity is non-trivial. By
accurately modeling neuron connectivity, we allow NiNo to accelerate Adam
training by up to 50\% in vision and language tasks.

摘要：神经网络训练可以加速，当一个可学习的更新规则被用来代替经典的自适应优化器（例如 Adam）。然而，可学习的更新规则可能是昂贵且不稳定的，需要训练和使用。一种最近提出的更简单的加速训练的方法是，对于大多数的优化步骤使用 Adam，并且定期地，仅每隔几步，预测（预测未来）参数。我们通过神经元交互和预测（NiNo）网络来改进这种方法。NiNo 利用神经元连接和图神经网络，通过从多个任务中的一组训练轨迹中以监督方式学习，更准确地预测参数。我们表明，在一些网络中，例如 Transformer，神经元连接是非平凡的。通过准确地建模神经元连接，我们允许 NiNo 将 Adam 训练加速高达 50%，用于视觉和语言任务。

##### **Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets**
2409.04286v1 by Desiree Heim, Christian Jilek, Adrian Ulges, Andreas Dengel

Current publicly available knowledge work data collections lack diversity,
extensive annotations, and contextual information about the users and their
documents. These issues hinder objective and comparable data-driven evaluations
and optimizations of knowledge work assistance systems. Due to the considerable
resources needed to collect such data in real-life settings and the necessity
of data censorship, collecting such a dataset appears nearly impossible. For
this reason, we propose a configurable, multi-agent knowledge work dataset
generator. This system simulates collaborative knowledge work among agents
producing Large Language Model-generated documents and accompanying data
traces. Additionally, the generator captures all background information, given
in its configuration or created during the simulation process, in a knowledge
graph. Finally, the resulting dataset can be utilized and shared without
privacy or confidentiality concerns.
  This paper introduces our approach's design and vision and focuses on
generating authentic knowledge work documents using Large Language Models. Our
study involving human raters who assessed 53% of the generated and 74% of the
real documents as realistic demonstrates the potential of our approach.
Furthermore, we analyze the authenticity criteria mentioned in the
participants' comments and elaborate on potential improvements for identified
common issues.

摘要：<paragraph>目前公開可用的知識工作資料蒐集缺乏多元性、廣泛註解和使用者及其文件背景資訊。這些問題阻礙了客觀且可比較的資料驅動評估，以及知識工作協助系統的最佳化。由於在現實生活中蒐集此類資料需要大量資源，而且必須審查資料，蒐集此類資料組顯然幾乎不可能。因此，我們提出一個可設定的多重代理知識工作資料組產生器。此系統模擬代理之間的協作知識工作，產生大型語言模型產生的文件和隨附的資料追蹤。此外，產生器會擷取所有背景資訊，在組態中提供或在模擬過程中建立，並將其儲存在知識圖譜中。最後，產生的資料組可以使用和分享，無須擔心隱私或機密性。
本文介紹我們方法的設計和願景，並專注於使用大型語言模型產生真實的知識工作文件。我們的研究涉及人類評分員，他們評估了 53% 的產生文件和 74% 的真實文件為真實，這證明了我們方法的潛力。此外，我們分析參與者評論中提到的真實性標準，並詳細說明已識別常見問題的潛在改善方法。</paragraph>

##### **GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding**
2409.04183v1 by Ziyin Zhang, Hang Yu, Shijie Li, Peng Di, Jianguo Li, Rui Wang

Programming languages possess rich semantic information such as data flow
that is represented by graphs and not available from the surface form of source
code. Recent code language models have scaled to billions of parameters, but
model source code solely as text tokens while ignoring any other structural
information. Conversely, models that do encode structural information of code
make modifications to the Transformer architecture, limiting their scale and
compatibility with pretrained LLMs. In this work, we take the best of both
worlds with GALLa - Graph Aligned Large Language Model. GALLa utilizes graph
neural networks and cross-modal alignment technologies to inject the structural
information of code into LLMs as an auxiliary task during finetuning. This
framework is both model-agnostic and task-agnostic, as it can be applied to any
code LLM for any code downstream task, and requires the structural graph data
only at training time from a corpus unrelated to the finetuning data, while
incurring no cost at inference time over the baseline LLM. Experiments on five
code tasks with four different baseline LLMs ranging in size from 350M to 8B
validate the effectiveness of GALLa, demonstrating consistent improvement over
the baseline, even for powerful models such as LLaMA3.

摘要：程式語言擁有豐富的語意資訊，例如由圖形表示且無法從原始碼表面形式取得的資料流程。最近的程式碼語言模型已擴充至數十億個參數，但模型原始碼僅作為文字符號，而忽略任何其他結構資訊。反之，編碼程式碼結構資訊的模型會修改 Transformer 架構，限制其規模和與預先訓練的 LLM 的相容性。在這項工作中，我們採用 GALLa（圖形對齊大型語言模型）擷取兩全其美的優點。GALLa 利用圖形神經網路和跨模態對齊技術，在微調期間將程式碼的結構資訊注入 LLM 作為輔助任務。此架構同時不依賴模型和任務，因為它可以應用於任何程式碼 LLM 的任何程式碼下游任務，並且僅在訓練期間從與微調資料無關的語料庫取得結構圖形資料，同時在推論期間不產生比基準 LLM 更高的成本。在五個程式碼任務中進行實驗，使用四個不同的基準 LLM，規模從 350M 到 8B，驗證 GALLa 的有效性，證明即使對於 LLaMA3 等強大模型，也能持續優於基準。

##### **Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering**
2409.04181v1 by Larissa Pusch, Tim O. F. Conrad

Advancements in natural language processing have revolutionized the way we
can interact with digital information systems, such as databases, making them
more accessible. However, challenges persist, especially when accuracy is
critical, as in the biomedical domain. A key issue is the hallucination
problem, where models generate information unsupported by the underlying data,
potentially leading to dangerous misinformation. This paper presents a novel
approach designed to bridge this gap by combining Large Language Models (LLM)
and Knowledge Graphs (KG) to improve the accuracy and reliability of
question-answering systems, on the example of a biomedical KG. Built on the
LangChain framework, our method incorporates a query checker that ensures the
syntactical and semantic validity of LLM-generated queries, which are then used
to extract information from a Knowledge Graph, substantially reducing errors
like hallucinations. We evaluated the overall performance using a new benchmark
dataset of 50 biomedical questions, testing several LLMs, including GPT-4 Turbo
and llama3:70b. Our results indicate that while GPT-4 Turbo outperforms other
models in generating accurate queries, open-source models like llama3:70b show
promise with appropriate prompt engineering. To make this approach accessible,
a user-friendly web-based interface has been developed, allowing users to input
natural language queries, view generated and corrected Cypher queries, and
verify the resulting paths for accuracy. Overall, this hybrid approach
effectively addresses common issues such as data gaps and hallucinations,
offering a reliable and intuitive solution for question answering systems. The
source code for generating the results of this paper and for the user-interface
can be found in our Git repository: https://git.zib.de/lpusch/cyphergenkg-gui

摘要：自然語言處理的進展徹底改變了我們與數位資訊系統（例如資料庫）互動的方式，讓這些系統變得更易於存取。然而，挑戰仍然存在，尤其是在準確性至關重要的情況下，例如在生物醫學領域。一個關鍵問題是幻覺問題，其中模型會產生未經基礎資料驗證的資訊，可能導致危險的錯誤資訊。本文提出了一種新穎的方法，旨在透過結合大型語言模型 (LLM) 和知識圖譜 (KG) 來彌補這個差距，以提高生物醫學 KG 中問答系統的準確性和可靠性。我們的技術建立在 LangChain 框架上，結合了一個查詢檢查器，可確保 LLM 生成的查詢在語法和語意上有效，然後用於從知識圖譜中萃取資訊，大幅減少幻覺等錯誤。我們使用一個新的 50 個生物醫學問題基準資料集評估了整體效能，測試了包括 GPT-4 Turbo 和 llama3:70b 在內的幾個 LLM。我們的結果顯示，雖然 GPT-4 Turbo 在產生準確查詢方面優於其他模型，但像 llama3:70b 這樣的開源模型在適當的提示工程下顯示出前景。為了讓這種方法易於使用，我們開發了一個使用者友善的網路介面，讓使用者可以輸入自然語言查詢、檢視產生和更正的 Cypher 查詢，並驗證結果路徑的準確性。總體而言，這種混合方法有效地解決了資料差距和幻覺等常見問題，為問答系統提供了一個可靠且直觀的解決方案。本文結果產生的原始碼和使用者介面的原始碼可以在我們的 Git 儲存庫中找到：https://git.zib.de/lpusch/cyphergenkg-gui

##### **Refining Wikidata Taxonomy using Large Language Models**
2409.04056v1 by Yiwen Peng, Thomas Bonald, Mehwish Alam

Due to its collaborative nature, Wikidata is known to have a complex
taxonomy, with recurrent issues like the ambiguity between instances and
classes, the inaccuracy of some taxonomic paths, the presence of cycles, and
the high level of redundancy across classes. Manual efforts to clean up this
taxonomy are time-consuming and prone to errors or subjective decisions. We
present WiKC, a new version of Wikidata taxonomy cleaned automatically using a
combination of Large Language Models (LLMs) and graph mining techniques.
Operations on the taxonomy, such as cutting links or merging classes, are
performed with the help of zero-shot prompting on an open-source LLM. The
quality of the refined taxonomy is evaluated from both intrinsic and extrinsic
perspectives, on a task of entity typing for the latter, showing the practical
interest of WiKC.

摘要：由於其協作性質，Wikidata 已知具有複雜的分類法，並有重複發生的問題，例如實例和類別之間的歧義、某些分類路徑的不準確性、循環的存在，以及類別之間的高冗餘。手動清理此分類法的工作既耗時又容易出現錯誤或主觀判斷。我們提出 WiKC，這是 Wikidata 分類法的新版本，使用大型語言模型 (LLM) 和圖形挖掘技術自動清理。分類法上的操作，例如剪切鏈接或合併類別，是在開源 LLM 上借助零次提示的幫助下執行的。精煉分類法的品質從內在和外在的觀點進行評估，在後者的實體分型任務上，顯示了 WiKC 的實際興趣。

##### **Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features**
2409.04009v1 by Miao Fan, Yeqi Bai, Mingming Sun, Ping Li

Relation classification (RC) plays a pivotal role in both natural language
understanding and knowledge graph completion. It is generally formulated as a
task to recognize the relationship between two entities of interest appearing
in a free-text sentence. Conventional approaches on RC, regardless of feature
engineering or deep learning based, can obtain promising performance on
categorizing common types of relation leaving a large proportion of
unrecognizable long-tail relations due to insufficient labeled instances for
training. In this paper, we consider few-shot learning is of great practical
significance to RC and thus improve a modern framework of metric learning for
few-shot RC. Specifically, we adopt the large-margin ProtoNet with fine-grained
features, expecting they can generalize well on long-tail relations. Extensive
experiments were conducted by FewRel, a large-scale supervised few-shot RC
dataset, to evaluate our framework: LM-ProtoNet (FGF). The results demonstrate
that it can achieve substantial improvements over many baseline approaches.

摘要：關係分類 (RC) 在自然語言理解和知識圖譜完成中扮演著關鍵角色。它通常被表述為一個任務，用於辨識出現在自由文字句子中的兩個感興趣實體之間的關係。無論是基於特徵工程還是深度學習的傳統 RC 方法，都可以對常見的關係類型進行分類，從而獲得有希望的效能，但由於訓練標籤實例不足，因此無法辨識出大量的長尾關係。在本文中，我們認為少樣本學習對 RC 具有重要的實用意義，因此改進了度量學習的現代框架，以進行少樣本 RC。具體來說，我們採用具有細粒度特徵的大邊距 ProtoNet，期望它們能在長尾關係上很好地概括。我們使用大型監督少樣本 RC 資料集 FewRel 進行了廣泛的實驗，以評估我們的框架：LM-ProtoNet (FGF)。結果表明，它可以比許多基線方法獲得顯著改進。

##### **Rx Strategist: Prescription Verification using LLM Agents System**
2409.03440v1 by Phuc Phan Van, Dat Nguyen Minh, An Dinh Ngoc, Huy Phan Thanh

To protect patient safety, modern pharmaceutical complexity demands strict
prescription verification. We offer a new approach - Rx Strategist - that makes
use of knowledge graphs and different search strategies to enhance the power of
Large Language Models (LLMs) inside an agentic framework. This multifaceted
technique allows for a multi-stage LLM pipeline and reliable information
retrieval from a custom-built active ingredient database. Different facets of
prescription verification, such as indication, dose, and possible drug
interactions, are covered in each stage of the pipeline. We alleviate the
drawbacks of monolithic LLM techniques by spreading reasoning over these
stages, improving correctness and reliability while reducing memory demands.
Our findings demonstrate that Rx Strategist surpasses many current LLMs,
achieving performance comparable to that of a highly experienced clinical
pharmacist. In the complicated world of modern medications, this combination of
LLMs with organized knowledge and sophisticated search methods presents a
viable avenue for reducing prescription errors and enhancing patient outcomes.

摘要：為了保護患者安全，現代藥品複雜性要求嚴格的處方驗證。我們提供一種新方法 - Rx Strategist - 它利用知識圖譜和不同的搜尋策略來增強代理架構內大型語言模型 (LLM) 的功能。這種多方面的技術允許多階段的 LLM 管線和從自訂主動成分資料庫中可靠地擷取資訊。處方驗證的不同面向，例如適應症、劑量和可能的藥物交互作用，都在管線的每個階段中涵蓋。我們透過將推理分散在這些階段來減輕單一 LLM 技術的缺點，同時提高正確性和可靠性，並減少記憶體需求。我們的研究結果表明，Rx Strategist 超越許多現有的 LLM，達到與經驗豐富的臨床藥劑師相當的表現。在現代藥物複雜的世界中，這種將 LLM 與有組織的知識和先進搜尋方法相結合，為減少處方錯誤和改善患者預後提供了可行的途徑。

##### **iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models**
2409.03284v1 by Yassir Lairgi, Ludovic Moncla, Rémy Cazabet, Khalid Benabdeslem, Pierre Cléau

Most available data is unstructured, making it challenging to access valuable
information. Automatically building Knowledge Graphs (KGs) is crucial for
structuring data and making it accessible, allowing users to search for
information effectively. KGs also facilitate insights, inference, and
reasoning. Traditional NLP methods, such as named entity recognition and
relation extraction, are key in information retrieval but face limitations,
including the use of predefined entity types and the need for supervised
learning. Current research leverages large language models' capabilities, such
as zero- or few-shot learning. However, unresolved and semantically duplicated
entities and relations still pose challenges, leading to inconsistent graphs
and requiring extensive post-processing. Additionally, most approaches are
topic-dependent. In this paper, we propose iText2KG, a method for incremental,
topic-independent KG construction without post-processing. This plug-and-play,
zero-shot method is applicable across a wide range of KG construction scenarios
and comprises four modules: Document Distiller, Incremental Entity Extractor,
Incremental Relation Extractor, and Graph Integrator and Visualization. Our
method demonstrates superior performance compared to baseline methods across
three scenarios: converting scientific papers to graphs, websites to graphs,
and CVs to graphs.

摘要：大部分可用資料為非結構化，這使得存取有價值的資訊變得具有挑戰性。自動建立知識圖譜 (KG) 對於結構化資料和讓資料易於存取至關重要，讓使用者能夠有效地搜尋資訊。KG 也促進見解、推論和推理。傳統的 NLP 方法，例如命名實體辨識和關係萃取，在資訊檢索中是關鍵，但面臨限制，包括使用預定義的實體類型和需要監督式學習。目前的研究所利用大型語言模型的能力，例如零次或少次學習。然而，未解決和語義重複的實體和關係仍然構成挑戰，導致圖形不一致，需要廣泛的後處理。此外，大多數方法都依賴於主題。在本文中，我們提出 iText2KG，一種用於漸進式、與主題無關的 KG 建構方法，無需後處理。這種即插即用、零次的方法適用於廣泛的 KG 建構場景，並包含四個模組：文件精餾器、漸進式實體萃取器、漸進式關係萃取器，以及圖形整合器和視覺化器。與基線方法相比，我們的模型在三種場景中展現出卓越的效能：將科學論文轉換為圖形、網站轉換為圖形，以及履歷轉換為圖形。

##### **GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding**
2409.03258v1 by Yukun Cao, Shuo Han, Zengyi Gao, Zezhong Ding, Xike Xie, S. Kevin Zhou

Although Large Language Models (LLMs) have demonstrated potential in
processing graphs, they struggle with comprehending graphical structure
information through prompts of graph description sequences, especially as the
graph size increases. We attribute this challenge to the uneven memory
performance of LLMs across different positions in graph description sequences,
known as ''positional biases''. To address this, we propose GraphInsight, a
novel framework aimed at improving LLMs' comprehension of both macro- and
micro-level graphical information. GraphInsight is grounded in two key
strategies: 1) placing critical graphical information in positions where LLMs
exhibit stronger memory performance, and 2) investigating a lightweight
external knowledge base for regions with weaker memory performance, inspired by
retrieval-augmented generation (RAG). Moreover, GraphInsight explores
integrating these two strategies into LLM agent processes for composite graph
tasks that require multi-step reasoning. Extensive empirical studies on
benchmarks with a wide range of evaluation tasks show that GraphInsight
significantly outperforms all other graph description methods (e.g., prompting
techniques and reordering strategies) in understanding graph structures of
varying sizes.

摘要：儘管大型語言模型 (LLM) 已展現出處理圖形的能力，但它們在透過圖形描述序列提示理解圖形結構資訊時會遇到困難，特別是在圖形大小增加時。我們將此挑戰歸因於 LLM 在圖形描述序列中不同位置的記憶力表現不均，稱為「位置偏誤」。為了解決這個問題，我們提出了 GraphInsight，一個旨在改善 LLM 對巨觀和微觀層級圖形資訊理解的新框架。GraphInsight 以兩個關鍵策略為基礎：1) 將關鍵圖形資訊放置在 LLM 展現較強記憶力表現的位置，以及 2) 調查一個受到檢索增強生成 (RAG) 啟發的、針對記憶力表現較弱區域的輕量級外部知識庫。此外，GraphInsight 探索將這兩個策略整合到 LLM 代理程序中，以處理需要多步驟推理的複合圖形任務。在具有廣泛評量任務的基準上進行的廣泛實證研究顯示，GraphInsight 在理解各種大小的圖形結構方面，明顯優於所有其他圖形描述方法（例如提示技巧和重新排序策略）。

##### **Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models**
2409.03155v1 by Jie Ma, Zhitao Gao, Qi Chai, Wangchun Sun, Pinghui Wang, Hongbin Pei, Jing Tao, Lingyun Song, Jun Liu, Chen Zhang, Lizhen Cui

Large Language Models (LLMs) may suffer from hallucinations in real-world
applications due to the lack of relevant knowledge. In contrast, knowledge
graphs encompass extensive, multi-relational structures that store a vast array
of symbolic facts. Consequently, integrating LLMs with knowledge graphs has
been extensively explored, with Knowledge Graph Question Answering (KGQA)
serving as a critical touchstone for the integration. This task requires LLMs
to answer natural language questions by retrieving relevant triples from
knowledge graphs. However, existing methods face two significant challenges:
\textit{excessively long reasoning paths distracting from the answer
generation}, and \textit{false-positive relations hindering the path
refinement}. In this paper, we propose an iterative interactive KGQA framework
that leverages the interactive learning capabilities of LLMs to perform
reasoning and Debating over Graphs (DoG). Specifically, DoG employs a
subgraph-focusing mechanism, allowing LLMs to perform answer trying after each
reasoning step, thereby mitigating the impact of lengthy reasoning paths. On
the other hand, DoG utilizes a multi-role debate team to gradually simplify
complex questions, reducing the influence of false-positive relations. This
debate mechanism ensures the reliability of the reasoning process. Experimental
results on five public datasets demonstrate the effectiveness and superiority
of our architecture. Notably, DoG outperforms the state-of-the-art method ToG
by 23.7\% and 9.1\% in accuracy on WebQuestions and GrailQA, respectively.
Furthermore, the integration experiments with various LLMs on the mentioned
datasets highlight the flexibility of DoG. Code is available at
\url{https://github.com/reml-group/DoG}.

摘要：<paragraph>大型語言模型 (LLM) 由於缺乏相關知識，在實際應用中可能會產生幻覺。相較之下，知識圖譜包含廣泛的多重關係結構，儲存大量符號事實。因此，將 LLM 與知識圖譜整合已廣泛探討，其中知識圖譜問題解答 (KGQA) 成為整合的重要試金石。此任務要求 LLM 透過從知識圖譜中擷取相關三元組來回答自然語言問題。然而，現有方法面臨兩項重大挑戰：\textit{過長的推理路徑會分散回答產生}，以及\textit{錯誤正向關係阻礙路徑精煉}。在本文中，我們提出一個反覆互動的 KGQA 框架，它利用 LLM 的互動學習能力來執行推理和圖形辯論 (DoG)。具體來說，DoG 採用子圖聚焦機制，允許 LLM 在每個推理步驟後執行答案嘗試，從而減輕冗長推理路徑的影響。另一方面，DoG 利用多角色辯論小組逐漸簡化複雜問題，減少錯誤正向關係的影響。這種辯論機制確保了推理過程的可靠性。在五個公共數據集上的實驗結果證明了我們架構的有效性和優越性。值得注意的是，DoG 在 WebQuestions 和 GrailQA 上的準確度分別比最先進的方法 ToG 高出 23.7% 和 9.1%。此外，在上述數據集上與各種 LLM 的整合實驗突顯了 DoG 的靈活性。程式碼可在\url{https://github.com/reml-group/DoG}取得。</paragraph>

##### **Word and Phrase Features in Graph Convolutional Network for Automatic Question Classification**
2409.02481v1 by Junyoung Lee, Ninad Dixit, Kaustav Chakrabarti, S. Supraja

Effective question classification is crucial for AI-driven educational tools,
enabling adaptive learning systems to categorize questions by skill area,
difficulty level, and competence. This classification not only supports
educational diagnostics and analytics but also enhances complex tasks like
information retrieval and question answering by associating questions with
relevant categories. Traditional methods, often based on word embeddings and
conventional classifiers, struggle to capture the nuanced relationships in
natural language, leading to suboptimal performance. To address this, we
propose a novel approach leveraging graph convolutional networks (GCNs), named
Phrase Question-Graph Convolutional Network (PQ-GCN) to better model the
inherent structure of questions. By representing questions as graphs -- where
nodes signify words or phrases and edges denote syntactic or semantic
relationships -- our method allows GCNs to learn from the interconnected nature
of language more effectively. Additionally, we explore the incorporation of
phrase-based features to enhance classification accuracy, especially in
low-resource settings. Our findings demonstrate that GCNs, augmented with these
features, offer a promising solution for more accurate and context-aware
question classification, bridging the gap between graph neural network research
and practical educational applications.

摘要：有效的問題分類對於 AI 驅動的教育工具至關重要，
讓適應性學習系統能依據技能領域、
難度等級和能力對問題進行分類。這種分類不僅支援
教育診斷和分析，還能透過將問題與
相關類別關聯起來，增強資訊檢索和問題解答等複雜任務。傳統方法通常建立在詞嵌入和
傳統分類器上，難以捕捉自然語言中的細微關係，導致次佳效能。為了解決這個問題，我們
提出了一種創新的方法，利用圖形卷積網路 (GCN)，稱為
Phrase Question-Graph Convolutional Network (PQ-GCN) 來更好地建模問題的內在結構。透過將問題表示為圖形——其中
節點表示詞或詞組，邊緣表示語法或語義關係——我們的模型允許 GCN 更有效地從語言的相互連結性質中學習。此外，我們探索了整合
基於詞組的特徵以增強分類準確度，特別是在
低資源設定中。我們的研究結果表明，GCN 在這些
特徵的增強下，為更準確且具備情境感知能力的問題分類提供了一個有前途的解決方案，縮小了圖形神經網路研究
與實際教育應用之間的差距。

##### **Multi-modal Situated Reasoning in 3D Scenes**
2409.02389v1 by Xiongkun Linghu, Jiangyong Huang, Xuesong Niu, Xiaojian Ma, Baoxiong Jia, Siyuan Huang

Situation awareness is essential for understanding and reasoning about 3D
scenes in embodied AI agents. However, existing datasets and benchmarks for
situated understanding are limited in data modality, diversity, scale, and task
scope. To address these limitations, we propose Multi-modal Situated Question
Answering (MSQA), a large-scale multi-modal situated reasoning dataset,
scalably collected leveraging 3D scene graphs and vision-language models (VLMs)
across a diverse range of real-world 3D scenes. MSQA includes 251K situated
question-answering pairs across 9 distinct question categories, covering
complex scenarios within 3D scenes. We introduce a novel interleaved
multi-modal input setting in our benchmark to provide text, image, and point
cloud for situation and question description, resolving ambiguity in previous
single-modality convention (e.g., text). Additionally, we devise the
Multi-modal Situated Next-step Navigation (MSNN) benchmark to evaluate models'
situated reasoning for navigation. Comprehensive evaluations on MSQA and MSNN
highlight the limitations of existing vision-language models and underscore the
importance of handling multi-modal interleaved inputs and situation modeling.
Experiments on data scaling and cross-domain transfer further demonstrate the
efficacy of leveraging MSQA as a pre-training dataset for developing more
powerful situated reasoning models.

摘要：情境感知對於理解和推理具身 AI 代理中的 3D 場景至關重要。然而，現有的資料集和基準在資料模態、多樣性、規模和任務範圍方面對於情境理解來說是有限的。為了解決這些限制，我們提出了多模態情境問答 (MSQA)，這是一個大型多模態情境推理資料集，可透過利用 3D 場景圖和視覺語言模型 (VLM) 在各種真實世界 3D 場景中進行可擴充收集。MSQA 包含 251K 個情境問答對，涵蓋 9 個不同的問題類別，涵蓋 3D 場景中的複雜場景。我們在基準中引入了一種新穎的交錯多模態輸入設定，以提供文字、影像和點雲，用於情境和問題描述，解決以前單一模態慣例（例如文字）中的歧義。此外，我們設計了多模態情境下一步導航 (MSNN) 基準，以評估模型的導航情境推理。MSQA 和 MSNN 的綜合評估突顯了現有視覺語言模型的限制，並強調了處理多模態交錯輸入和情境建模的重要性。資料擴充和跨領域轉移的實驗進一步證明了利用 MSQA 作為預訓練資料集來開發更強大的情境推理模型的有效性。

##### **Grounding Language Models in Autonomous Loco-manipulation Tasks**
2409.01326v1 by Jin Wang, Nikos Tsagarakis

Humanoid robots with behavioral autonomy have consistently been regarded as
ideal collaborators in our daily lives and promising representations of
embodied intelligence. Compared to fixed-based robotic arms, humanoid robots
offer a larger operational space while significantly increasing the difficulty
of control and planning. Despite the rapid progress towards general-purpose
humanoid robots, most studies remain focused on locomotion ability with few
investigations into whole-body coordination and tasks planning, thus limiting
the potential to demonstrate long-horizon tasks involving both mobility and
manipulation under open-ended verbal instructions. In this work, we propose a
novel framework that learns, selects, and plans behaviors based on tasks in
different scenarios. We combine reinforcement learning (RL) with whole-body
optimization to generate robot motions and store them into a motion library. We
further leverage the planning and reasoning features of the large language
model (LLM), constructing a hierarchical task graph that comprises a series of
motion primitives to bridge lower-level execution with higher-level planning.
Experiments in simulation and real-world using the CENTAURO robot show that the
language model based planner can efficiently adapt to new loco-manipulation
tasks, demonstrating high autonomy from free-text commands in unstructured
scenes.

摘要：具有行為自主權的人形機器人一直被視為我們日常生活中理想的合作者，也是具體智能的有希望的代表。與固定式機器手臂相比，人形機器人提供了更大的操作空間，同時顯著增加了控制和規劃的難度。儘管朝著通用人形機器人快速發展，但大多數研究仍然集中在運動能力上，很少研究全身協調和任務規劃，從而限制了展示涉及移動和操作的長期任務的潛力，同時還能接受開放式口頭指令。在這項工作中，我們提出了一個新的框架，該框架可以根據不同場景中的任務學習、選擇和規劃行為。我們將強化學習 (RL) 與全身優化相結合，以生成機器人動作並將其存儲到動作庫中。我們進一步利用大型語言模型 (LLM) 的規劃和推理功能，構建了一個分層任務圖，其中包含一系列運動原語，以橋接低級執行和高級規劃。在模擬和使用 CENTAURO 機器人的現實世界中的實驗表明，基於語言模型的規劃器可以有效適應新的運動操作任務，證明了在非結構化場景中從自由文本命令中獲得的高度自主性。

##### **LATEX-GCL: Large Language Models (LLMs)-Based Data Augmentation for Text-Attributed Graph Contrastive Learning**
2409.01145v1 by Haoran Yang, Xiangyu Zhao, Sirui Huang, Qing Li, Guandong Xu

Graph Contrastive Learning (GCL) is a potent paradigm for self-supervised
graph learning that has attracted attention across various application
scenarios. However, GCL for learning on Text-Attributed Graphs (TAGs) has yet
to be explored. Because conventional augmentation techniques like feature
embedding masking cannot directly process textual attributes on TAGs. A naive
strategy for applying GCL to TAGs is to encode the textual attributes into
feature embeddings via a language model and then feed the embeddings into the
following GCL module for processing. Such a strategy faces three key
challenges: I) failure to avoid information loss, II) semantic loss during the
text encoding phase, and III) implicit augmentation constraints that lead to
uncontrollable and incomprehensible results. In this paper, we propose a novel
GCL framework named LATEX-GCL to utilize Large Language Models (LLMs) to
produce textual augmentations and LLMs' powerful natural language processing
(NLP) abilities to address the three limitations aforementioned to pave the way
for applying GCL to TAG tasks. Extensive experiments on four high-quality TAG
datasets illustrate the superiority of the proposed LATEX-GCL method. The
source codes and datasets are released to ease the reproducibility, which can
be accessed via this link: https://anonymous.4open.science/r/LATEX-GCL-0712.

摘要：圖形對比學習 (GCL) 是自監督圖形學習的強大範例，已在各種應用場景中引起關注。然而，GCL 對於在文本註解圖形 (TAG) 上學習尚未被探討。因為特徵嵌入遮罩等傳統擴充技術無法直接處理 TAG 上的文本屬性。將 GCL 應用於 TAG 的一種天真策略是通過語言模型將文本屬性編碼到特徵嵌入中，然後將嵌入輸入後續的 GCL 模組進行處理。這種策略面臨三個關鍵挑戰：I) 無法避免資訊遺失，II) 在文本編碼階段發生語義遺失，以及 III) 導致無法控制且難以理解結果的隱式擴充約束。在本文中，我們提出一個名為 LATEX-GCL 的新穎 GCL 框架，利用大型語言模型 (LLM) 來產生文本擴充，以及 LLM 強大的自然語言處理 (NLP) 能力來解決上述三個限制，為將 GCL 應用於 TAG 任務鋪平道路。在四個高品質 TAG 資料集上的大量實驗說明了所提出的 LATEX-GCL 方法的優越性。原始碼和資料集已發布以簡化可重製性，可透過此連結存取：https://anonymous.4open.science/r/LATEX-GCL-0712。

##### **Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering**
2409.00861v1 by Derian Boer, Fabian Koch, Stefan Kramer

Large Language Models (LLMs) frequently lack domain-specific knowledge and
even fine-tuned models tend to hallucinate. Hence, more reliable models that
can include external knowledge are needed. We present a pipeline, 4StepFocus,
and specifically a preprocessing step, that can substantially improve the
answers of LLMs. This is achieved by providing guided access to external
knowledge making use of the model's ability to capture relational context and
conduct rudimentary reasoning by themselves. The method narrows down
potentially correct answers by triplets-based searches in a semi-structured
knowledge base in a direct, traceable fashion, before switching to latent
representations for ranking those candidates based on unstructured data. This
distinguishes it from related methods that are purely based on latent
representations. 4StepFocus consists of the steps: 1) Triplet generation for
extraction of relational data by an LLM, 2) substitution of variables in those
triplets to narrow down answer candidates employing a knowledge graph, 3)
sorting remaining candidates with a vector similarity search involving
associated non-structured data, 4) reranking the best candidates by the LLM
with background data provided. Experiments on a medical, a product
recommendation, and an academic paper search test set demonstrate that this
approach is indeed a powerful augmentation. It not only adds relevant traceable
background information from information retrieval, but also improves
performance considerably in comparison to state-of-the-art methods. This paper
presents a novel, largely unexplored direction and therefore provides a wide
range of future work opportunities. Used source code is available at
https://github.com/kramerlab/4StepFocus.

摘要：大型語言模型 (LLM) 經常缺乏特定領域的知識，即使經過微調的模型也容易產生幻覺。因此，需要更多可靠的模型來納入外部知識。我們提出了一個流程 4StepFocus，特別是預處理步驟，可以大幅改善 LLM 的答案。這是透過提供受引導的外部知識存取，利用模型自行擷取關聯性脈絡和進行基本推理的能力來實現的。此方法透過在半結構化知識庫中進行基於三元組的搜尋，以直接且可追蹤的方式縮小潛在正確答案的範圍，然後再切換到潛在表徵，根據非結構化資料對這些候選答案進行排名。這與純粹基於潛在表徵的相關方法有所區別。4StepFocus 包含以下步驟：1) 由 LLM 進行三元組產生以擷取關聯資料，2) 在這些三元組中替換變數，以採用知識圖表縮小答案候選範圍，3) 使用涉及關聯非結構化資料的向量相似性搜尋對剩餘候選答案進行排序，4) 由 LLM 重新對最佳候選答案進行排名，並提供背景資料。在醫療、產品推薦和學術論文搜尋測試集中進行的實驗證明，這種方法確實是一種強大的擴充。它不僅增加了來自資訊檢索的相关可追蹤背景資訊，而且與最先進的方法相比，也大幅提升了效能。本文提出了一個新穎且鮮少探索的方向，因此提供了廣泛的未來工作機會。使用的原始碼可在 https://github.com/kramerlab/4StepFocus 取得。

##### **Building FKG.in: a Knowledge Graph for Indian Food**
2409.00830v1 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Ramesh Jain

This paper presents an ontology design along with knowledge engineering, and
multilingual semantic reasoning techniques to build an automated system for
assimilating culinary information for Indian food in the form of a knowledge
graph. The main focus is on designing intelligent methods to derive ontology
designs and capture all-encompassing knowledge about food, recipes,
ingredients, cooking characteristics, and most importantly, nutrition, at
scale. We present our ongoing work in this workshop paper, describe in some
detail the relevant challenges in curating knowledge of Indian food, and
propose our high-level ontology design. We also present a novel workflow that
uses AI, LLM, and language technology to curate information from recipe blog
sites in the public domain to build knowledge graphs for Indian food. The
methods for knowledge curation proposed in this paper are generic and can be
replicated for any domain. The design is application-agnostic and can be used
for AI-driven smart analysis, building recommendation systems for Personalized
Digital Health, and complementing the knowledge graph for Indian food with
contextual information such as user information, food biochemistry, geographic
information, agricultural information, etc.

摘要：本文提出了一個知識工程和多語言語義推理技術的本体設計，用於建立一個自動化系統，以知識圖譜的形式吸收印度料理的烹飪資訊。重點在於設計智慧方法，以推導本体設計，並全面擷取關於食物、食譜、食材、烹飪特性，以及最重要的營養的知識，並擴大規模。我們在這個研討會論文中介紹了我們正在進行的工作，詳細描述了整理印度料理知識相關的挑戰，並提出了我們的高階本体設計。我們也提出了一種新的工作流程，它使用 AI、LLM 和語言技術，從公共領域的食譜部落格網站中整理資訊，以建立印度料理的知識圖譜。本文提出的知識整理方法是通用的，可以複製到任何領域。設計與應用無關，可用於 AI 驅動的智慧分析、建立個人化數位健康推薦系統，以及使用使用者資訊、食物生物化學、地理資訊、農業資訊等脈絡資訊，來補充印度料理的知識圖譜。

##### **Hound: Hunting Supervision Signals for Few and Zero Shot Node Classification on Text-attributed Graph**
2409.00727v1 by Yuxiang Wang, Xiao Yan, Shiyu Jin, Quanqing Xu, Chuanhui Yang, Yuanyuan Zhu, Chuang Hu, Bo Du, Jiawei Jiang

Text-attributed graph (TAG) is an important type of graph structured data
with text descriptions for each node. Few- and zero-shot node classification on
TAGs have many applications in fields such as academia and social networks.
However, the two tasks are challenging due to the lack of supervision signals,
and existing methods only use the contrastive loss to align graph-based node
embedding and language-based text embedding. In this paper, we propose Hound to
improve accuracy by introducing more supervision signals, and the core idea is
to go beyond the node-text pairs that come with data. Specifically, we design
three augmentation techniques, i.e., node perturbation, text matching, and
semantics negation to provide more reference nodes for each text and vice
versa. Node perturbation adds/drops edges to produce diversified node
embeddings that can be matched with a text. Text matching retrieves texts with
similar embeddings to match with a node. Semantics negation uses a negative
prompt to construct a negative text with the opposite semantics, which is
contrasted with the original node and text. We evaluate Hound on 5 datasets and
compare with 13 state-of-the-art baselines. The results show that Hound
consistently outperforms all baselines, and its accuracy improvements over the
best-performing baseline are usually over 5%.

摘要：文字属性圖 (TAG) 是一種重要的圖形結構化資料類型，其中每個節點都有文字描述。TAG 上的少樣本和零樣本節點分類在學術界和社交網路等領域有許多應用。然而，由於缺乏監督訊號，這兩個任務具有挑戰性，現有方法僅使用對比損失來對齊基於圖形節點的嵌入和基於語言的文字嵌入。在本文中，我們提出 Hound 來透過引入更多監督訊號來改善準確度，其核心思想是超越資料中附帶的節點文字對。具體來說，我們設計了三種擴充技術，即節點擾動、文字配對和語義否定，為每個文字提供更多參考節點，反之亦然。節點擾動新增/刪除邊緣以產生可以與文字配對的多樣化節點嵌入。文字配對擷取具有類似嵌入的文字以與節點配對。語義否定使用負面提示來建構具有相反語義的負面文字，與原始節點和文字形成對比。我們在 5 個資料集上評估 Hound，並與 13 個最先進的基線進行比較。結果表明，Hound 在所有基線上始終表現優異，其準確度通常比效能最佳的基線提高了 5% 以上。

##### **WikiCausal: Corpus and Evaluation Framework for Causal Knowledge Graph Construction**
2409.00331v1 by Oktie Hassanzadeh

Recently, there has been an increasing interest in the construction of
general-domain and domain-specific causal knowledge graphs. Such knowledge
graphs enable reasoning for causal analysis and event prediction, and so have a
range of applications across different domains. While great progress has been
made toward automated construction of causal knowledge graphs, the evaluation
of such solutions has either focused on low-level tasks (e.g., cause-effect
phrase extraction) or on ad hoc evaluation data and small manual evaluations.
In this paper, we present a corpus, task, and evaluation framework for causal
knowledge graph construction. Our corpus consists of Wikipedia articles for a
collection of event-related concepts in Wikidata. The task is to extract causal
relations between event concepts from the corpus. The evaluation is performed
in part using existing causal relations in Wikidata to measure recall, and in
part using Large Language Models to avoid the need for manual or crowd-sourced
evaluation. We evaluate a pipeline for causal knowledge graph construction that
relies on neural models for question answering and concept linking, and show
how the corpus and the evaluation framework allow us to effectively find the
right model for each task. The corpus and the evaluation framework are publicly
available.

摘要：<paragraph>最近，人們對通用領域和特定領域因果知識圖譜的建構越來越感興趣。此類知識圖譜能夠推理因果分析和事件預測，因此在不同領域中有廣泛的應用。雖然在因果知識圖譜的自動建構方面取得了重大進展，但此類解決方案的評估要嘛著重於低階任務（例如因果關係短語擷取），要嘛著重於臨時評估資料和小型手動評估。在本文中，我們提出了一個語料庫、任務和因果知識圖譜建構評估架構。我們的語料庫包含維基百科文章，其中包含 Wikidata 中一系列事件相關概念。任務是從語料庫中擷取事件概念之間的因果關係。評估部分使用 Wikidata 中現有的因果關係來衡量召回率，部分使用大型語言模型來避免手動或群眾外包評估的需要。我們評估了一個因果知識圖譜建構管道，該管道依賴於用於問答和概念連結的神經模型，並展示了語料庫和評估架構如何讓我們有效地為每個任務找到合適的模型。語料庫和評估架構公開提供。</paragraph>

##### **HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation System for AI Legal and Policy Applications**
2409.09046v1 by Rishi Kalra, Zekun Wu, Ayesha Gulley, Airlie Hilliard, Xin Guan, Adriano Koshiyama, Philip Treleaven

While Large Language Models (LLMs) excel in text generation and
question-answering, their effectiveness in AI legal and policy is limited by
outdated knowledge, hallucinations, and inadequate reasoning in complex
contexts. Retrieval-Augmented Generation (RAG) systems improve response
accuracy by integrating external knowledge but struggle with retrieval errors,
poor context integration, and high costs, particularly in interpreting
qualitative and quantitative AI legal texts. This paper introduces a Hybrid
Parameter-Adaptive RAG (HyPA-RAG) system tailored for AI legal and policy,
exemplified by NYC Local Law 144 (LL144). HyPA-RAG uses a query complexity
classifier for adaptive parameter tuning, a hybrid retrieval strategy combining
dense, sparse, and knowledge graph methods, and an evaluation framework with
specific question types and metrics. By dynamically adjusting parameters,
HyPA-RAG significantly improves retrieval accuracy and response fidelity.
Testing on LL144 shows enhanced correctness, faithfulness, and contextual
precision, addressing the need for adaptable NLP systems in complex,
high-stakes AI legal and policy applications.

摘要：大型語言模型 (LLM) 雖然在文字產生和問答方面表現優異，但其在 AI 法律和政策中的效能卻受到過時知識、幻覺以及在複雜脈絡中推理不足的限制。檢索增強生成 (RAG) 系統透過整合外部知識來改善回應準確性，但卻在檢索錯誤、脈絡整合不良以及成本高昂方面面臨挑戰，特別是在詮釋定性和定量的 AI 法律文本時。本文介紹了一種專為 AI 法律和政策量身打造的混合參數自適應 RAG (HyPA-RAG) 系統，以紐約市地方法律 144 (LL144) 為例。HyPA-RAG 使用查詢複雜度分類器進行自適應參數調整，結合稠密、稀疏和知識圖表方法的混合檢索策略，以及包含特定問題類型和指標的評估架構。透過動態調整參數，HyPA-RAG 大幅改善了檢索準確性和回應保真度。在 LL144 上的測試顯示出增強的正確性、忠實度和脈絡準確度，滿足了在複雜、高風險的 AI 法律和政策應用中對可適應 NLP 系統的需求。

##### **LLaVA-SG: Leveraging Scene Graphs as Visual Semantic Expression in Vision-Language Models**
2408.16224v2 by Jingyi Wang, Jianzhong Ju, Jian Luan, Zhidong Deng

Recent advances in large vision-language models (VLMs) typically employ
vision encoders based on the Vision Transformer (ViT) architecture. The
division of the images into patches by ViT results in a fragmented perception,
thereby hindering the visual understanding capabilities of VLMs. In this paper,
we propose an innovative enhancement to address this limitation by introducing
a Scene Graph Expression (SGE) module in VLMs. This module extracts and
structurally expresses the complex semantic information within images, thereby
improving the foundational perception and understanding abilities of VLMs.
Extensive experiments demonstrate that integrating our SGE module significantly
enhances the VLM's performance in vision-language tasks, indicating its
effectiveness in preserving intricate semantic details and facilitating better
visual understanding.

摘要：近來大型視覺語言模型 (VLM) 的進展通常採用基於視覺轉換器 (ViT) 架構的視覺編碼器。ViT 將影像分割成區塊會造成破碎的感知，從而阻礙 VLM 的視覺理解能力。在本文中，我們提出了一項創新的增強功能，透過在 VLM 中引入場景圖表達 (SGE) 模組來解決此限制。此模組會萃取影像中的複雜語意資訊並以結構化的方式表達，從而改善 VLM 的基礎感知和理解能力。廣泛的實驗證明，整合我們的 SGE 模組能顯著提升 VLM 在視覺語言任務中的效能，表示它在保留複雜的語意細節和促進更好的視覺理解方面很有效。

##### **LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments**
2408.15903v1 by Ruirui Chen, Weifeng Jiang, Chengwei Qin, Ishaan Singh Rawal, Cheston Tan, Dongkyu Choi, Bo Xiong, Bo Ai

The rapid obsolescence of information in Large Language Models (LLMs) has
driven the development of various techniques to incorporate new facts. However,
existing methods for knowledge editing still face difficulties with multi-hop
questions that require accurate fact identification and sequential logical
reasoning, particularly among numerous fact updates. To tackle these
challenges, this paper introduces Graph Memory-based Editing for Large Language
Models (GMeLLo), a straitforward and effective method that merges the explicit
knowledge representation of Knowledge Graphs (KGs) with the linguistic
flexibility of LLMs. Beyond merely leveraging LLMs for question answering,
GMeLLo employs these models to convert free-form language into structured
queries and fact triples, facilitating seamless interaction with KGs for rapid
updates and precise multi-hop reasoning. Our results show that GMeLLo
significantly surpasses current state-of-the-art knowledge editing methods in
the multi-hop question answering benchmark, MQuAKE, especially in scenarios
with extensive knowledge edits.

摘要：大型語言模型 (LLM) 中資訊快速過時，促使各種技術發展以納入新事實。然而，現有的知識編輯方法在需要準確事實辨識和順序邏輯推理的多跳問題上仍面臨困難，特別是在眾多事實更新中。為了應對這些挑戰，本文介紹了大型語言模型的圖記憶編輯 (GMeLLo)，這是一種直接且有效的方法，結合了知識圖譜 (KG) 的明確知識表示與 LLM 的語言靈活性。GMeLLo 不僅利用 LLM 來回答問題，還使用這些模型將自由形式的語言轉換為結構化查詢和事實三元組，促進與 KG 的無縫互動，以便快速更新和精確的多跳推理。我們的結果表明，在多跳問題回答基準 MQuAKE 中，GMeLLo 明顯超越了當前最先進的知識編輯方法，特別是在廣泛知識編輯的場景中。

##### **VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities**
2408.14895v2 by Shusaku Egami, Takahiro Ugai, Swe Nwe Nwe Htun, Ken Fukuda

Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data
(e.g., images and videos) into symbols, have attracted attention as resources
enabling knowledge processing and machine learning across modalities. However,
the construction of MMKGs for videos consisting of multiple events, such as
daily activities, is still in the early stages. In this paper, we construct an
MMKG based on synchronized multi-view simulated videos of daily activities.
Besides representing the content of daily life videos as event-centric
knowledge, our MMKG also includes frame-by-frame fine-grained changes, such as
bounding boxes within video frames. In addition, we provide support tools for
querying our MMKG. As an application example, we demonstrate that our MMKG
facilitates benchmarking vision-language models by providing the necessary
vision-language datasets for a tailored task.

摘要：多模態知識圖（MMKG）將各種非符號數據（例如，影像和影片）轉換為符號，成為一種資源，能讓跨模態的知識處理和機器學習成為可能。然而，對於包含多個事件（例如日常生活活動）的影片，其 MMKG 的建構仍處於早期階段。在本文中，我們基於每日活動的同步多視角模擬影片，建構了一個 MMKG。除了將日常生活影片的內容表示為以事件為中心的知識外，我們的 MMKG 也包含逐幀的細微變化，例如影片幀中的邊界框。此外，我們還提供了用於查詢 MMKG 的支援工具。作為應用範例，我們展示了我們的 MMKG 如何透過提供特定任務所需的視覺語言資料集，來促進視覺語言模型的基準測試。

##### **XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model**
2408.16021v1 by Yasir Ali Farrukh, Syed Wali, Irfan Khan, Nathaniel D. Bastian

In the rapidly evolving field of cybersecurity, the integration of flow-level
and packet-level information for real-time intrusion detection remains a
largely untapped area of research. This paper introduces "XG-NID," a novel
framework that, to the best of our knowledge, is the first to fuse flow-level
and packet-level data within a heterogeneous graph structure, offering a
comprehensive analysis of network traffic. Leveraging a heterogeneous graph
neural network (GNN) with graph-level classification, XG-NID uniquely enables
real-time inference while effectively capturing the intricate relationships
between flow and packet payload data. Unlike traditional GNN-based
methodologies that predominantly analyze historical data, XG-NID is designed to
accommodate the heterogeneous nature of network traffic, providing a robust and
real-time defense mechanism. Our framework extends beyond mere classification;
it integrates Large Language Models (LLMs) to generate detailed, human-readable
explanations and suggest potential remedial actions, ensuring that the insights
produced are both actionable and comprehensible. Additionally, we introduce a
new set of flow features based on temporal information, further enhancing the
contextual and explainable inferences provided by our model. To facilitate
practical application and accessibility, we developed "GNN4ID," an open-source
tool that enables the extraction and transformation of raw network traffic into
the proposed heterogeneous graph structure, seamlessly integrating flow and
packet-level data. Our comprehensive quantitative comparative analysis
demonstrates that XG-NID achieves an F1 score of 97\% in multi-class
classification, outperforming existing baseline and state-of-the-art methods.
This sets a new standard in Network Intrusion Detection Systems by combining
innovative data fusion with enhanced interpretability and real-time
capabilities.

摘要：<paragraph>在快速發展的網路安全領域中，整合流層級和封包層級資訊以進行即時入侵偵測，仍然是一個尚未開發的研究領域。本文介紹「XG-NID」，一個創新的架構，據我們所知，這是第一個在異質圖形結構中融合流層級和封包層級資料的架構，提供對網路流量的全面分析。透過利用異質圖形神經網路 (GNN) 和圖形層級分類，XG-NID 獨特地實現即時推論，同時有效擷取流和封包酬載資料之間的複雜關係。與傳統基於 GNN 的方法（主要分析歷史資料）不同，XG-NID 被設計成適應網路流量的異質性，提供強大且即時的防禦機制。我們的架構不僅限於分類；它整合大型語言模型 (LLM) 以產生詳細、人類可讀的解釋並建議潛在的補救措施，確保產生的見解既可操作又易於理解。此外，我們根據時間資訊引入一組新的流特徵，進一步增強模型提供的脈絡和可解釋推論。為了促進實際應用和可及性，我們開發了「GNN4ID」，一個開放原始碼工具，可以將原始網路流量提取並轉換為建議的異質圖形結構，無縫整合流和封包層級資料。我們全面的定量比較分析表明，XG-NID 在多類別分類中達到 97% 的 F1 分數，優於現有的基準和最先進的方法。這透過結合創新的資料融合、增強的可解釋性和即時功能，在網路入侵偵測系統中樹立了新的標準。</paragraph>

##### **Process Trace Querying using Knowledge Graphs and Notation3**
2409.04452v1 by William Van Woensel

In process mining, a log exploration step allows making sense of the event
traces; e.g., identifying event patterns and illogical traces, and gaining
insight into their variability. To support expressive log exploration, the
event log can be converted into a Knowledge Graph (KG), which can then be
queried using general-purpose languages. We explore the creation of semantic KG
using the Resource Description Framework (RDF) as a data model, combined with
the general-purpose Notation3 (N3) rule language for querying. We show how
typical trace querying constraints, inspired by the state of the art, can be
implemented in N3. We convert case- and object-centric event logs into a
trace-based semantic KG; OCEL2 logs are hereby "flattened" into traces based on
object paths through the KG. This solution offers (a) expressivity, as queries
can instantiate constraints in multiple ways and arbitrarily constrain
attributes and relations (e.g., actors, resources); (b) flexibility, as OCEL2
event logs can be serialized as traces in arbitrary ways based on the KG; and
(c) extensibility, as others can extend our library by leveraging the same
implementation patterns.

摘要：在流程挖掘中，日志探索步骤可以理解事件轨迹；例如，识别事件模式和非逻辑轨迹，并深入了解其可变性。为了支持表达性日志探索，事件日志可以转换为知识图 (KG)，然后可以使用通用语言对其进行查询。我们探索使用资源描述框架 (RDF) 作为数据模型创建语义 KG，并结合通用 Notation3 (N3) 规则语言进行查询。我们展示了如何使用 N3 实现受现有技术启发的典型轨迹查询约束。我们将案例和对象中心事件日志转换为基于轨迹的语义 KG；OCEL2 日志在此被“扁平化”为基于通过 KG 的对象路径的轨迹。此解决方案提供 (a) 表达力，因为查询可以以多种方式实例化约束并任意约束属性和关系（例如，参与者、资源）；(b) 灵活，因为 OCEL2 事件日志可以基于 KG 以任意方式序列化为轨迹；以及 (c) 可扩展性，因为其他人可以通过利用相同的实现模式来扩展我们的库。

##### **PatentGPT: A Large Language Model for Patent Drafting Using Knowledge-based Fine-tuning Method**
2409.00092v1 by Runtao Ren, Jian Ma

As humanity stands on the brink of a new era of technological innovation, the
ability to rapidly transform creative ideas into protected intellectual
property (IP) is more crucial than ever. However, the conventional processes
for patent drafting are fraught with challenges, demanding a nuanced
understanding of advanced field knowledge and technical concepts. Existing
large language models (LLMs), while powerful, often fall short in this IP
creation domain due to their lack of specialized knowledge and
context-awareness necessary for generating technically accurate patent
documents. To bridge this critical gap, we propose a groundbreaking framework
for Knowledge Fine-Tuning (KFT) of LLMs, designed to endow AI with the ability
to autonomously mine, understand, and apply domain-specific knowledge. Our
model, PatentGPT leverages a unique combination of knowledge graph-based
pre-training, domain-specific supervised fine-tuning (SFT), and reinforcement
learning from human feedback (RLHF). Through extensive evaluation, PatentGPT
has demonstrated outstanding performance, scoring up to approximately 400%
higher in patent related benchmark tests compared to state-of-the-art models.
By KFT method the model's capability to not only assist but also augment human
creativity and innovation, our approach sets a new standard for AI-driven
intellectual property generation, paving the way for more efficient and
effective invention processes.

摘要：<paragraph>隨著人類邁入科技創新的新紀元，迅速將創意點子轉化為受保護的智慧財產（IP）的能力比以往任何時候都更加重要。然而，傳統的專利起草程序充滿挑戰，需要對先進領域知識和技術概念有細緻入微的了解。現有的大型語言模型（LLM）雖然強大，但由於缺乏產生技術上準確的專利文件的專業知識和情境意識，因此常常無法滿足此 IP 創作領域的需求。為了彌補這個關鍵差距，我們提出了一個創新的 LLM 知識微調 (KFT) 架構，旨在賦予 AI 自主挖掘、理解和應用特定領域知識的能力。我們的模型 PatentGPT 充分利用了基於知識圖表的預訓練、特定領域的監督式微調 (SFT) 和人類回饋的強化學習 (RLHF) 的獨特組合。透過廣泛的評估，PatentGPT 已展現出傑出的表現，在與最先進模型相比的專利相關基準測試中，得分高出約 400%。透過 KFT 方法，此模型不僅能夠協助，還能擴增人類的創造力和創新力，我們的做法為 AI 驅動的智慧財產生成樹立了新標準，為更有效率且更有效的發明流程鋪路。</paragraph>

##### **DynamicRouteGPT: A Real-Time Multi-Vehicle Dynamic Navigation Framework Based on Large Language Models**
2408.14185v1 by Ziai Zhou, Bin Zhou, Hao Liu

Real-time dynamic path planning in complex traffic environments presents
challenges, such as varying traffic volumes and signal wait times. Traditional
static routing algorithms like Dijkstra and A* compute shortest paths but often
fail under dynamic conditions. Recent Reinforcement Learning (RL) approaches
offer improvements but tend to focus on local optima, risking dead-ends or
boundary issues. This paper proposes a novel approach based on causal inference
for real-time dynamic path planning, balancing global and local optimality. We
first use the static Dijkstra algorithm to compute a globally optimal baseline
path. A distributed control strategy then guides vehicles along this path. At
intersections, DynamicRouteGPT performs real-time decision-making for local
path selection, considering real-time traffic, driving preferences, and
unexpected events. DynamicRouteGPT integrates Markov chains, Bayesian
inference, and large-scale pretrained language models like Llama3 8B to provide
an efficient path planning solution. It dynamically adjusts to traffic
scenarios and driver preferences and requires no pre-training, offering broad
applicability across road networks. A key innovation is the construction of
causal graphs for counterfactual reasoning, optimizing path decisions.
Experimental results show that our method achieves state-of-the-art performance
in real-time dynamic path planning for multiple vehicles while providing
explainable path selections, offering a novel and efficient solution for
complex traffic environments.

摘要：在複雜交通環境中進行實時動態路徑規劃會面臨挑戰，例如交通流量變化和信號等待時間。傳統的靜態路由演算法，例如 Dijkstra 和 A*，會計算最短路徑，但通常在動態條件下會失敗。最近的強化學習 (RL) 方法提供了改進，但傾向於關注局部最優，冒著陷入死胡同或邊界問題的風險。本文提出了一種基於因果推論的新穎方法，用於實時動態路徑規劃，平衡全局和局部最優性。我們首先使用靜態 Dijkstra 演算法計算全局最優基線路徑。然後，一個分布式控制策略沿著這條路徑引導車輛。在交叉路口，DynamicRouteGPT 針對局部路徑選擇執行實時決策，考量實時交通、駕駛偏好和意外事件。DynamicRouteGPT 整合了馬可夫鏈、貝氏推論和 Llama3 8B 等大規模預先訓練的語言模型，以提供有效的路徑規劃解決方案。它會動態調整到交通狀況和駕駛偏好，並且不需要預先訓練，在道路網路上提供廣泛的適用性。一個關鍵創新是建立反事實推理的因果圖，以最佳化路徑決策。實驗結果顯示，我們的模型在多輛車輛的實時動態路徑規劃中達到最先進的效能，同時提供可解釋的路徑選擇，為複雜的交通環境提供一種新穎且有效的解決方案。

##### **Exploring the Potential of Large Language Models for Heterophilic Graphs**
2408.14134v1 by Yuxia Wu, Shujie Li, Yuan Fang, Chuan Shi

Graph Neural Networks (GNNs) are essential for various graph-based learning
tasks. Notably, classical GNN architectures operate under the assumption of
homophily, which posits that connected nodes are likely to share similar
features. However, this assumption limits the effectiveness of GNNs in handling
heterophilic graphs where connected nodes often exhibit dissimilar
characteristics. Existing approaches for homophily graphs such as non-local
neighbor extension and architectural refinement overlook the rich textual data
associated with nodes, which could unlock deeper insights into these
heterophilic contexts. With advancements in Large Language Models (LLMs), there
is significant promise to enhance GNNs by leveraging the extensive open-world
knowledge within LLMs to more effectively interpret and utilize textual data
for characterizing heterophilic graphs. In this work, we explore the potential
of LLMs for modeling heterophilic graphs and propose a novel two-stage
framework: LLM-enhanced edge discriminator and LLM-guided edge reweighting.
Specifically, in the first stage, we fine-tune the LLM to better identify
homophilic and heterophilic edges based on the textual information of their
nodes. In the second stage, we adaptively manage message propagation in GNNs
for different edge types based on node features, structures, and heterophilic
or homophilic characteristics. To cope with the computational demands when
deploying LLMs in practical scenarios, we further explore model distillation
techniques to fine-tune smaller, more efficient models that maintain
competitive performance. Extensive experiments validate the effectiveness of
our framework, demonstrating the feasibility of using LLMs to enhance GNNs for
node classification on heterophilic graphs.

摘要：圖神經網路 (GNN) 對於各種基於圖形的學習任務至關重要。值得注意的是，傳統的 GNN 架構在同質性的假設下運作，該假設認為連接的節點可能共享類似的特徵。然而，此假設限制了 GNN 在處理異質性圖形中的效能，其中連接的節點通常表現出不同的特徵。現有的同質性圖形方法（例如非局部鄰域延伸和架構改進）忽略了與節點相關的豐富文本資料，這可以深入了解這些異質性脈絡。隨著大型語言模型 (LLM) 的進步，透過利用 LLM 中廣泛的開放世界知識來增強 GNN，對於更有效地詮釋和利用文本資料來表徵異質性圖形有很大的希望。在這項工作中，我們探討了 LLM 在異質性圖形建模中的潛力，並提出了一個新穎的兩階段架構：LLM 增強邊緣判別器和 LLM 引導邊緣重新加權。具體來說，在第一階段，我們微調 LLM 以根據其節點的文本資訊，更好地識別同質性和異質性邊緣。在第二階段，我們根據節點特徵、結構和異質性或同質性特徵，自適應地管理 GNN 中不同邊緣類型的訊息傳遞。為了應對在實際場景中部署 LLM 時的計算需求，我們進一步探討模型萃取技術，以微調較小、更有效率的模型，以維持競爭力。廣泛的實驗驗證了我們架構的有效性，證明了使用 LLM 來增強 GNN 以進行異質性圖形上的節點分類的可行性。

##### **Towards Graph Prompt Learning: A Survey and Beyond**
2408.14520v3 by Qingqing Long, Yuchen Yan, Peiyan Zhang, Chen Fang, Wentao Cui, Zhiyuan Ning, Meng Xiao, Ning Cao, Xiao Luo, Lingjun Xu, Shiyue Jiang, Zheng Fang, Chong Chen, Xian-Sheng Hua, Yuanchun Zhou

Large-scale "pre-train and prompt learning" paradigms have demonstrated
remarkable adaptability, enabling broad applications across diverse domains
such as question answering, image recognition, and multimodal retrieval. This
approach fully leverages the potential of large-scale pre-trained models,
reducing downstream data requirements and computational costs while enhancing
model applicability across various tasks. Graphs, as versatile data structures
that capture relationships between entities, play pivotal roles in fields such
as social network analysis, recommender systems, and biological graphs. Despite
the success of pre-train and prompt learning paradigms in Natural Language
Processing (NLP) and Computer Vision (CV), their application in graph domains
remains nascent. In graph-structured data, not only do the node and edge
features often have disparate distributions, but the topological structures
also differ significantly. This diversity in graph data can lead to
incompatible patterns or gaps between pre-training and fine-tuning on
downstream graphs. We aim to bridge this gap by summarizing methods for
alleviating these disparities. This includes exploring prompt design
methodologies, comparing related techniques, assessing application scenarios
and datasets, and identifying unresolved problems and challenges. This survey
categorizes over 100 relevant works in this field, summarizing general design
principles and the latest applications, including text-attributed graphs,
molecules, proteins, and recommendation systems. Through this extensive review,
we provide a foundational understanding of graph prompt learning, aiming to
impact not only the graph mining community but also the broader Artificial
General Intelligence (AGI) community.

摘要：<paragraph>大規模「預訓練與提示學習」範例已展現出卓越的適應性，能廣泛應用於各種領域，例如問答、影像辨識和多模態檢索。此方法充分利用了大型預訓練模型的潛力，降低了下游資料需求和運算成本，同時提升了模型在各種任務中的適用性。圖形作為能捕捉實體之間關係的多功能資料結構，在社群網路分析、推薦系統和生物圖形等領域扮演著關鍵角色。儘管預訓練與提示學習範例在自然語言處理 (NLP) 和電腦視覺 (CV) 中獲得成功，它們在圖形領域的應用仍屬起步階段。在圖形結構資料中，節點和邊緣特徵不僅經常有不同的分佈，其拓撲結構也大不相同。圖形資料的這種多樣性可能導致預訓練和微調之間出現不相容的模式或差距。我們旨在透過總結減輕這些差異的方法來彌補此差距。這包括探索提示設計方法、比較相關技術、評估應用場景和資料集，以及找出未解決的問題和挑戰。本調查分類了此領域中 100 多項相關著作，總結了一般設計原則和最新應用，包括文字屬性圖形、分子、蛋白質和推薦系統。透過這項廣泛的回顧，我們提供了圖形提示學習的基本理解，旨在不僅影響圖形挖掘社群，也影響更廣泛的人工通用智慧 (AGI) 社群。</paragraph>

##### **CodeGraph: Enhancing Graph Reasoning of LLMs with Code**
2408.13863v1 by Qiaolong Cai, Zhaowei Wang, Shizhe Diao, James Kwok, Yangqiu Song

With the increasing popularity of large language models (LLMs), reasoning on
basic graph algorithm problems is an essential intermediate step in assessing
their abilities to process and infer complex graph reasoning tasks. Existing
methods usually convert graph-structured data to textual descriptions and then
use LLMs for reasoning and computation. However, LLMs often produce computation
errors on arithmetic parts in basic graph algorithm problems, such as counting
number of edges. In addition, they struggle to control or understand the output
of the reasoning process, raising concerns about whether LLMs are simply
guessing. In this paper, we introduce CodeGraph, a method that encodes graph
problem solutions as code. The methods solve new graph problems by learning
from exemplars, generating programs, and executing them via a program
interpreter. Using the few-shot setting, we evaluate CodeGraph with the base
LLM being GPT-3.5 Turbo, Llama3-70B Instruct, Mixtral-8x22B Instruct, and
Mixtral-8x7B Instruct. Experimental results on six tasks with six graph
encoding methods in the GraphQA dataset demonstrate that CodeGraph can boost
performance on graph reasoning tasks inside LLMs by 1.3% to 58.6%, depending on
the task. Compared to the existing methods, CodeGraph demonstrates strong
performance on arithmetic problems in graph tasks and offers a more
controllable and interpretable approach to the reasoning process.

摘要：隨著大型語言模型 (LLM) 的日漸普及，對基本圖形演算法問題進行推理是評估它們處理和推論複雜圖形推理任務的能力中一個重要的中間步驟。現有的方法通常會將圖形結構化的資料轉換成文字描述，然後使用 LLM 進行推理和運算。然而，LLM 通常會在基本圖形演算法問題中，例如計算邊緣數量，對算術部分產生運算錯誤。此外，它們難以控制或理解推理過程的輸出，這引發了 LLM 是否只是在猜測的疑慮。在本文中，我們介紹了 CodeGraph，這是一種將圖形問題解決方案編碼為程式碼的方法。這些方法透過學習範例、產生程式，並透過程式碼直譯器執行它們來解決新的圖形問題。使用少次嘗試設定，我們使用基礎 LLM 為 GPT-3.5 Turbo、Llama3-70B Instruct、Mixtral-8x22B Instruct 和 Mixtral-8x7B Instruct 來評估 CodeGraph。在 GraphQA 資料集中使用六種圖形編碼方法對六項任務進行的實驗結果表明，CodeGraph 可以將 LLM 中的圖形推理任務的效能提升 1.3% 到 58.6%，具體取決於任務。與現有方法相比，CodeGraph 在圖形任務中的算術問題上表現出強勁的效能，並為推理過程提供更具可控性和可解釋性的方法。

##### **LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings**
2408.14512v1 by Duo Wang, Yuan Zuo, Fengzhi Li, Junjie Wu

Zero-shot graph machine learning, especially with graph neural networks
(GNNs), has garnered significant interest due to the challenge of scarce
labeled data. While methods like self-supervised learning and graph prompt
learning have been extensively explored, they often rely on fine-tuning with
task-specific labels, limiting their effectiveness in zero-shot scenarios.
Inspired by the zero-shot capabilities of instruction-fine-tuned large language
models (LLMs), we introduce a novel framework named Token Embedding-Aligned
Graph Language Model (TEA-GLM) that leverages LLMs as cross-dataset and
cross-task zero-shot learners for graph machine learning. Concretely, we
pretrain a GNN, aligning its representations with token embeddings of an LLM.
We then train a linear projector that transforms the GNN's representations into
a fixed number of graph token embeddings without tuning the LLM. A unified
instruction is designed for various graph tasks at different levels, such as
node classification (node-level) and link prediction (edge-level). These design
choices collectively enhance our method's effectiveness in zero-shot learning,
setting it apart from existing methods. Experiments show that our graph token
embeddings help the LLM predictor achieve state-of-the-art performance on
unseen datasets and tasks compared to other methods using LLMs as predictors.

摘要：零範例圖形機器學習，特別是圖形神經網路 (GNN)，由於稀有標籤資料的挑戰而備受關注。雖然自監督式學習和圖形提示學習等方法已被廣泛探索，但它們通常依賴於任務特定標籤的微調，這限制了它們在零範例場景中的有效性。受到指令微調大型語言模型 (LLM) 的零範例功能的啟發，我們引入了一個名為 Token Embedding-Aligned Graph Language Model (TEA-GLM) 的新框架，它利用 LLM 作為跨資料集和跨任務的零範例學習器，用於圖形機器學習。具體來說，我們預訓練一個 GNN，將其表示與 LLM 的 token embedding 對齊。然後，我們訓練一個線性投影機，將 GNN 的表示轉換為固定數量的圖形 token embedding，而無需調整 LLM。統一的指令是為不同層級的各種圖形任務設計的，例如節點分類（節點層級）和連結預測（邊緣層級）。這些設計選擇共同增強了我們的方法在零範例學習中的有效性，使其有別於現有方法。實驗表明，與使用 LLM 作為預測器的其他方法相比，我們的圖形 token embedding 幫助 LLM 預測器在未見過的資料集和任務上實現了最先進的效能。

##### **Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models**
2408.13661v1 by Sakhinana Sagar Srinivas, Geethan Sannidhi, Venkataramana Runkana

Characterizing materials with electron micrographs is a crucial task in
fields such as semiconductors and quantum materials. The complex hierarchical
structure of micrographs often poses challenges for traditional classification
methods. In this study, we propose an innovative backbone architecture for
analyzing electron micrographs. We create multi-modal representations of the
micrographs by tokenizing them into patch sequences and, additionally,
representing them as vision graphs, commonly referred to as patch attributed
graphs. We introduce the Hierarchical Network Fusion (HNF), a multi-layered
network structure architecture that facilitates information exchange between
the multi-modal representations and knowledge integration across different
patch resolutions. Furthermore, we leverage large language models (LLMs) to
generate detailed technical descriptions of nanomaterials as auxiliary
information to assist in the downstream task. We utilize a cross-modal
attention mechanism for knowledge fusion across cross-domain
representations(both image-based and linguistic insights) to predict the
nanomaterial category. This multi-faceted approach promises a more
comprehensive and accurate representation and classification of micrographs for
nanomaterial identification. Our framework outperforms traditional methods,
overcoming challenges posed by distributional shifts, and facilitating
high-throughput screening.

摘要：利用電子顯微照片來表徵材料，在半導體和量子材料等領域中是一項至關重要的任務。顯微照片複雜的分層結構通常會對傳統分類方法帶來挑戰。在這項研究中，我們提出了一種創新的主幹架構，用於分析電子顯微照片。我們透過將顯微照片代換成區塊序列來建立其多模態表示，此外，我們還將其表示為視覺圖形，通常稱為區塊屬性圖形。我們引入了分層網路融合 (HNF)，這是一種多層網路結構架構，有助於多模態表示之間的資訊交換，以及不同區塊解析度之間的知識整合。此外，我們利用大型語言模型 (LLM) 來產生奈米材料的詳細技術說明，作為輔助資訊，以協助下游任務。我們利用跨模態注意力機制，在跨領域表示（基於影像和語言洞察力）中進行知識融合，以預測奈米材料類別。這種多方面的做法有望為奈米材料識別提供更全面且準確的表示和分類。我們的架構優於傳統方法，克服了分佈轉移帶來的挑戰，並促進了高通量篩選。


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v1](http://arxiv.org/abs/2409.12087v1)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v1](http://arxiv.org/abs/2407.15851v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v5](http://arxiv.org/abs/2401.13324v5)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. García-Gómez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|

#### Abstracts
##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v1 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政索賠資料的潛力，結合進階機器學習和深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD)。我們分析由一家大型健康保險組織提供的十年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長短期記憶 (LSTM) 網路）開發多個觀察時段的預測模型。我們的研究結果表明，LSTM 模型，特別是具有 24 個月的觀察時段，在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 加法解釋 (SHAP) 分析來增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政索賠資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

摘要：隨著越來越複雜且準確的預測模型，基於人工智慧 (AI) 解決方案的提案在許多領域中變得無處不在。隨著這些模型複雜性的增加，透明度和使用者的理解力往往會降低。這表示僅有準確的預測並不足以讓 AI 解決方案真正有用。在醫療保健系統的開發中，這引入了與問責制和安全性相關的新問題。瞭解 AI 系統如何以及為何提出建議可能需要對其內部運作和推理過程進行複雜的說明。儘管近年來對可解釋 AI (XAI) 的研究已大幅增加，且醫學領域對 XAI 有很高的需求，但定義什麼構成一個好的解釋仍是臨時性的，而提供適當的解釋仍然具有挑戰性。為了充分發揮 AI 的潛力，對於安全關鍵型 AI 應用（例如健康 AI）的解釋，探討兩個基本問題至關重要：(1) 什麼是健康 AI 中的解釋？以及 (2) 健康 AI 中一個好的解釋有哪些屬性？在本研究中，我們檢視了已發表的文獻，並透過兩輪德爾菲研究收集了專家意見。研究成果包括：(1) 健康 AI 中什麼構成解釋的定義，以及 (2) 健康 AI 中一個好解釋的屬性清單。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v1 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
extant surveys on the trustworthiness of foundation models fail to address
their specific variations and applications within the medical imaging domain.
This survey paper reviews the current research on foundation models in the
major medical imaging applications, with a focus on segmentation, medical
report generation, medical question and answering (Q&A), and disease diagnosis,
which includes trustworthiness discussion in their manuscripts. We explore the
complex challenges of making foundation models for medical image analysis
trustworthy, associated with each application, and summarize the current
concerns and strategies to enhance trustworthiness. Furthermore, we explore the
future promises of these models in revolutionizing patient care. Our analysis
underscores the imperative for advancing towards trustworthy AI in medical
image analysis, advocating for a balanced approach that fosters innovation
while ensuring ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像上的快速進展代表著在增強診斷準確度和個人化治療方面邁出了一大步。然而，基礎模型在醫療保健中的部署需要嚴格檢查其可信度，包括隱私、穩健性、可靠性、可解釋性和公平性。當前關於醫學影像中基礎模型的調查文獻顯示出相當大的差距，特別是在可信度方面。此外，現有的關於基礎模型可信度的調查未能解決其在醫學影像領域內的具體變化和應用。這篇調查論文回顧了當前關於基礎模型在主要醫學影像應用中的研究，重點關注分割、醫療報告生成、醫療問題和解答 (Q&A) 以及疾病診斷，其中包括手稿中的可信度討論。我們探討了讓用於醫學影像分析的基礎模型值得信賴的複雜挑戰，與每個應用相關，並總結了當前提高可信度的問題和策略。此外，我們探討了這些模型在革新患者照護方面的未來前景。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，提倡一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

摘要：隨著大型語言模型 (LLM) 的興起，了解它們在解碼和解釋語言所蘊含的複雜因果關係網路中的能力和限制變得至關重要。目前的技術使用明確或隱含的因果推理，但強烈需要一種統一的方法，結合兩者以更有效地處理廣泛的因果關係。本研究提出了一種稱為情境感知推理增強與反事實分析 (CARE CA) 框架的新架構，以增強因果推理和可解釋性。提出的框架結合了使用 ConceptNet 和反事實陳述的明確因果檢測模組，以及透過 LLM 進行的隱含因果檢測。我們的框架更進一步，加入一層反事實解釋，以強調 LLM 對因果關係的理解。來自 ConceptNet 的知識增強了多項因果推理任務的執行，例如因果發現、因果識別和反事實推理。反事實句加入了未由情境造成的明確知識。透過結合這些強大的模組，我們的模型旨在提供對因果關係更深入的理解，實現增強的可解釋性。基準資料集的評估顯示在所有指標（例如準確度、精確度、召回率和 F1 分數）上都有所提升。我們還引入了 CausalNet，一個新的資料集，並附上了我們的程式碼，以促進在這個領域的進一步研究。

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v5 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

摘要：<paragraph>每個對人進行決策的 AI 系統都有一群個人受到這些決策影響的利益關係人。然而，AI 系統的說明很少針對這群利益關係人的資訊需求，他們通常是 AI 新手。這在傳達的資訊和對受系統決策影響的人來說重要的資訊之間，造成了一道鴻溝，例如領域專家和決策主體。為了解決這個問題，我們提出了「XAI 新手問題庫」，這是 XAI 問題庫的延伸，包含來自兩個使用案例中 AI 新手的資訊需求目錄：就業預測和健康監控。目錄涵蓋了資料、系統背景、系統使用和系統規格等類別。我們透過任務型訪談收集資訊需求，參與者在其中詢問了兩個 AI 系統的問題，以決定採用與否，並收到口頭說明作為回應。我們的分析顯示，參與者在收到說明後，信心有所提升，但他們的理解面臨挑戰。這些挑戰包括難以找到資訊和評估自己的理解，以及試圖外包理解。此外，參與者對系統風險和好處的先前認知影響了他們的資訊需求。認為風險高的人尋求有關系統部署背後意圖的說明，而認為風險低的人則詢問系統的運作。我們的研究旨在透過強調他們的資訊需求、目標和挑戰，來支持將 AI 新手納入可解釋性工作。我們將我們的研究結果總結為五個關鍵影響，這些影響可以為未來針對非專業利益相關者受眾的說明設計提供參考。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 開發社群日益利用 Hugging Face 等託管中介機構提供用戶上傳的模型和訓練資料的簡易存取權限。這些模型市集降低了數十萬名用戶的技術部署障礙，但可能會被用於許多潛在有害和非法的方式。在本文中，我們說明 AI 系統既可以「包含」內容，又可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以檢視模型市集如何審核模型。根據此分析，我們概述產業為回應審核需求而開發的重要（但仍有限）實務：授權、存取和使用限制、自動化內容審核和開放政策制定。雖然當前政策挑戰相當可觀，我們最後提出一些構想，說明平台如何能更好地動員資源，作為謹慎、公平且適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

摘要：<paragraph>使用醫療影像訓練的人工智慧 (AI) 模型，用於臨床任務時，常會在效能上展現出次群體之間的差異，形成偏見。由於並非所有真實世界醫療影像資料中的偏見來源都容易辨識，因此全面評估這些偏見是如何編碼到模型中，以及偏見緩解方法在改善效能差異方面的能力，是一項挑戰。在本文中，我們介紹了一個新穎的分析架構，用於系統化且客觀地調查醫療影像中的偏見對 AI 模型的影響。我們開發並測試了這個架構，以進行受控的電腦模擬試驗，使用一個工具來評估醫療影像 AI 中的偏見，該工具用於產生具有已知疾病影響和偏見來源的合成磁共振影像。可行性透過使用三個反事實偏見情境來衡量模擬偏見效應對卷積神經網路 (CNN) 分類器和三個偏見緩解策略的影響，並展示出來。分析顯示，當 CNN 在合成資料集上受訓時，模擬偏見會導致預期的次群體效能差異。此外，重新加權被認為是此設定中最成功的偏見緩解策略，我們展示了解釋性 AI 方法如何協助使用這個架構調查模型中偏見的表現。開發公平的 AI 模型是一項重大的挑戰，因為醫療影像資料集中可能存在許多且經常未知的偏見來源。在這項工作中，我們提出了一種新穎的方法，用於客觀地研究偏見和緩解策略對深度學習管線的影響，這可以支援健全且負責任的臨床 AI 的開發。</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

摘要：機器學習為自動預測中風後症狀及其對復健的反應提供了極大的潛力。這項工作的重大挑戰包括神經影像資料的維度非常高、可用於學習的資料集規模相對較小，以及如何有效結合神經影像和表格資料（例如人口統計資訊和臨床特徵）。本文根據兩種策略評估了多種解決方案。第一種是使用總結 MRI 掃描的 2D 影像。第二種是選擇有助於提高分類精確度的關鍵特徵。此外，我們引入了在結合從 MRI 中提取的感興趣區域與表格資料的符號表示的影像上訓練卷積神經網路 (CNN) 的新穎方法。我們評估了一系列 CNN 架構（2D 和 3D），這些架構在 MRI 和表格資料的不同表示上進行訓練，以預測中風後口述圖片描述能力的綜合測量是否在失語症或非失語症範圍內。MRI 和表格資料來自 758 名參與 PLORAS 研究的英語中風倖存者。僅針對病灶大小的基線邏輯迴歸分類準確度為 0.678，當依序加入初始症狀嚴重程度和恢復時間時，上升至 0.757 和 0.813。在從每個 MRI 掃描中提取 8 個感興趣區域並在 2D 殘差神經網路中與病灶大小、初始嚴重程度和恢復時間結合時，觀察到最高的分類準確度 0.854。我們的研究結果展示了如何將影像和表格資料結合起來以獲得高於中風後分類準確度，即使在機器學習術語中資料集很小的情況下也是如此。最後，我們提出如何改進目前的模型，以使用來自醫院掃描儀的影像來實現更高的準確度。

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

摘要：可解釋人工智慧 (XAI) 已成為處理任務關鍵應用程式時的一項基本需求，確保採用黑盒 AI 模型的透明度和可解釋性。XAI 的重要性涵蓋從醫療保健到金融的各種領域，在這些領域中，了解深度學習演算法的決策制定過程至關重要。大多數基於 AI 的電腦視覺模型通常是黑盒子；因此，在影像處理中提供深度神經網路的可解釋性對於其在醫學影像分析、自動駕駛和遙測應用中的廣泛採用和部署至關重要。最近，已針對影像分類任務引入了多種 XAI 方法。相反地，影像分割在可解釋性的背景下受到的關注相對較少，儘管它是電腦視覺應用中的一項基本任務，特別是在遙測中。只有部分研究提出用於影像分割的基於梯度的 XAI 演算法。本文改編了最近的無梯度 Sobol XAI 方法以進行語意分割。為了衡量 Sobol 方法在分割中的效能，我們提出了一種基於可學習雜訊模型的定量 XAI 評估方法。此模型的主要目的是在解釋圖上誘發雜訊，其中較高的誘發雜訊表示較低的準確度，反之亦然。進行基準分析以評估和比較三種 XAI 方法的效能，包括 Seg-Grad-CAM、Seg-Grad-CAM++ 和 Seg-Sobol，並使用所提出的基於雜訊的評估技術。這構成了使用高解析度衛星影像執行和評估 XAI 方法的首次嘗試。

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

摘要：大型語言模型在短時間內已在多個領域中大量激增。然而，由於事實性、連貫性和幻覺等問題，醫療和保健領域對其採用猶豫不決。鑑於醫療保健的高風險性質，許多研究人員甚至警告不要使用它，直到這些問題得到解決。在醫療保健中實施和部署 LLM 的關鍵是使這些模型值得信賴、透明（盡可能多）且可解釋。在本文中，我們描述了建立可靠、值得信賴和無偏見模型的關鍵要素，作為它們在醫療保健中得到採用的必要條件。具體來說，我們專注於在醫療保健背景下對幻覺進行量化、驗證和緩解。最後，我們討論了 LLM 在醫療保健中的未來可能是什麼樣子。

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

摘要：人工智慧（AI）已快速進步，現已準備部署於廣泛的應用程式中，例如自主系統、醫療診斷和自然語言處理。及早採用 AI 技術於實際應用程式並非沒有問題，特別是對於神經網路，它可能不穩定且容易受到對抗性範例的影響。從長遠來看，需要開發適當的安全保證技術，以減少因可避免的系統故障而造成的潛在傷害，並確保可信賴性。本文著重於認證和可解釋性，概述了已開發用於確保 AI 決策安全的技術，並討論未來的挑戰。

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. García-Gómez, Vicent Blanes-Selva, José Carlos de Bartolomé Cenzano, Jaime Cebolla-Cornejo, Ascensión Doñate-Martínez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

摘要：歐洲議會議會研究服務總局已為歐洲議會議員準備了一份報告，其中列舉了人工智能 (AI) 在醫療保健領域的七項主要風險：AI 錯誤導致患者受到傷害、醫療 AI 工具被濫用、AI 存在偏見並導致現有 inequities 持續存在、缺乏透明度、隱私和安全問題、問責差距以及實施障礙。
  在這項研究中，我們提出了十四項功能性要求，AI 系統可以實施這些要求來降低與其醫療目的相關的風險：AI 護照、使用者管理、法規檢查、僅限學術用途免責聲明、資料品質評估、臨床醫生雙重檢查、持續效能評估、稽核追蹤、持續可用性測試、回顧回溯/模擬案例、偏見檢查、可解釋 AI、加密和使用經過實地測試的程式庫，以及語意互通性。
  我們在此的目的是提供技術解決方案的特定高階規格，以確保持續良好的效能，並使用 AI 系統，以符合未來的歐盟法規架構，從而使患者受益。

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

摘要：人工智慧技術可用於分類病患的身體活動並預測遠距病患監控的重要生命徵象。基於深度學習模型等非線性模型的回歸分析由於其黑盒子的性質而具有有限的可解釋性。這可能需要決策者根據非線性模型結果做出盲目的信仰飛躍，特別是在醫療保健應用中。在非侵入性監控中，來自追蹤感測器和其易感臨床屬性的病患資料充當預測未來生命徵象的輸入特徵。解釋各種特徵對監控應用程式整體輸出的貢獻對於臨床醫生的決策至關重要。在本研究中，提出了一個用於量化分析的可解釋人工智慧 (QXAI) 架構，該架構具有監督式學習方法中回歸和分類任務的事後模型可解釋性和內在可解釋性。這透過利用 Shapley 值概念並將注意力機制納入深度學習模型來實現。我們採用人工神經網路 (ANN) 和基於注意力的雙向 LSTM (BiLSTM) 模型，根據感測器資料預測心率和分類身體活動。深度學習模型在預測和分類任務中都取得了最先進的成果。對輸入資料進行全局解釋和局部解釋，以了解各種病患資料的特徵貢獻。所提出的 QXAI 架構使用 PPG-DaLiA 資料評估，以預測心率，並使用行動健康 (MHEALTH) 資料根據感測器資料對身體活動進行分類。蒙地卡羅近似法應用於該架構，以克服 Shapley 值計算所需的時間複雜度和高運算能力需求。

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

摘要：在可解释人工智能 (XAI) 研究中，主要重点在于为专家和从业者解释模型。模型不可知和局部解释方法在许多应用中被认为是可解释且足够的。然而，在医疗保健等领域，最终用户是缺乏人工智能或领域专业知识的患者，因此迫切需要更易于理解且能激发对模型操作的信任的模型解释。我们假设生成叙述性、患者特定且全局（模型整体）的模型解释将能够提高可理解性并支持决策制定。我们使用决策树模型对此进行测试，为被识别为患有冠心病高风险的患者生成局部和全局解释。这些解释会呈现给非专家用户。我们发现用户强烈偏好特定类型的解释。大多数参与者偏好全局解释，而较小的一组参与者偏好局部解释。基于任务的心理模型评估为这些参与者提供了有价值的反馈，以增强叙述性全局解释。这反过来又指导了既值得信赖又可操作的健康信息学系统的设计。

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

摘要：電子健康紀錄 (EHR) 和例行文件記錄實務在病患的日常照護中扮演著至關重要的角色，提供健康、診斷和治療的整體紀錄。然而，複雜且冗長的 EHR 敘述會讓醫療保健提供者超載，有診斷不準確的風險。大型語言模型 (LLM) 已展現其在各種語言任務上的潛力，但其在醫療保健領域的應用需要確保將診斷錯誤降到最低，並防止病患受到傷害。在本文中，我們概述一種創新的方法，透過整合醫學知識圖譜 (KG) 和一種新穎的圖譜模型：Dr.Knows（靈感來自臨床診斷推理過程），來增強 LLM 在自動化診斷產生領域的能力。我們從美國國家醫學圖書館的統一醫學語言系統 (UMLS) 中衍生出 KG，這是一個強大的生物醫學知識儲存庫。我們的做法否定了預先訓練的需要，而是將 KG 作為輔助工具，協助解釋和總結複雜的醫學概念。使用真實世界的醫院資料集，我們的實驗結果證明，將 LLM 與 KG 結合的建議方法有潛力提高自動化診斷產生的準確性。更重要的是，我們的做法提供了一條可解釋的診斷途徑，讓我們更接近實現 AI 增強的診斷決策支援系統。

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

摘要：現有的用於診斷膝骨關節炎 (OA) 的人工智慧 (AI) 模型因其缺乏透明度和可解釋性而受到批評，儘管它們達到了類似醫學專家的表現。這種不透明性使得它們在臨床實務中難以被信任。最近，可解釋人工智慧 (XAI) 已成為一種專門技術，它能透過揭示預測的推導方式來提供對模型預測的信心，從而促進在醫療保健中使用 AI 系統。本文提供了針對膝骨關節炎診斷所使用的 XAI 技術的第一份調查。XAI 技術從兩個角度進行討論：資料可解釋性和模型可解釋性。本文的目的是提供對 XAI 在更可靠的膝骨關節炎診斷方法中的潛力的寶貴見解，並鼓勵在臨床實務中採用它。

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

摘要：最近在醫療保健中的人工智慧應用進展顯示出令人難以置信的承諾，在診斷和疾病預後方面超越人類表現。然而，隨著人工智能模型的日益複雜，人們對其不透明性、潛在偏差和對可解釋性的需求感到擔憂。為了確保人工智能系統的信任和可靠性，尤其是在臨床風險預測模型中，可解釋性變得至關重要。可解釋性通常被稱為人工智能系統提供其決策邏輯或決策本身對人類利益相關者的強有力解釋的能力。在臨床風險預測中，可解釋性的其他方面，如公平性、偏見、信任和透明度，也代表了超越可解釋性的重要概念。在本次審查中，我們探討了這些概念之間的關係，因為它們經常一起或互換使用。本審查還討論了為臨床風險預測開發可解釋模型的最新進展，強調了在臨床實踐中對多種常見模式進行定量和臨床評估和驗證的重要性。它強調了外部驗證和多樣化可解釋性方法相結合的必要性，以增強信任和公平性。採用嚴格的測試，例如使用具有已知生成因素的合成數據集，可以進一步提高可解釋性方法的可靠性。開放獲取和代碼共享資源對於透明度和可重複性至關重要，從而促進可解釋研究的增長和可信度。儘管存在挑戰，但從臨床醫生到開發人員，採用端到端的可解釋性方法對於臨床風險預測的成功至關重要。

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A González, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Irène Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerdá Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Lluís Donoso-Bach, Luis Martí-Bonmatí, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, Mónica Cano Abadía, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver Díaz, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Aussó, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, Xènia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

摘要：儘管在醫學和醫療保健方面的人工智慧 (AI) 有重大的進展，但 AI 技術的部署和採用在現實世界的臨床實務中仍然有限。近年來，人們對於與醫療 AI 相關的技術、臨床、倫理和法律風險提出了疑慮。為了增加現實世界的採用率，醫療 AI 工具必須獲得患者、臨床醫生、醫療機構和當局的信任和接受。這項工作將 FUTURE-AI 指南描述為指導醫療保健中可信賴 AI 工具開發和部署的第一個國際共識架構。FUTURE-AI 聯盟成立於 2021 年，目前由來自 51 個國家的 118 位跨領域專家組成，代表所有洲，包括 AI 科學家、臨床醫生、倫理學家和社會科學家。在兩年的時間裡，該聯盟通過一個反覆運算的過程定義了可信賴 AI 的指導原則和最佳實務，包括深入的文獻回顧、修改後的德爾菲調查和線上共識會議。FUTURE-AI 架構是基於醫療保健中可信賴 AI 的 6 項指導原則建立的，即公平性、普遍性、可追溯性、可用性、穩健性和可解釋性。通過共識，定義了一組 28 項最佳實務，涵蓋技術、臨床、法律和社會倫理層面。建議涵蓋了醫療 AI 的整個生命週期，從設計、開發和驗證到法規、部署和監控。FUTURE-AI 是一個基於風險、無假設的指南，提供了一個結構化的方法，用於建構將在現實世界實務中受到信任、部署和採用的醫療 AI 工具。鼓勵研究人員在概念驗證階段考慮這些建議，以促進未來將醫療 AI 轉化為臨床實務。

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

摘要：人工智慧在醫療領域中已取得顯著進展，在醫學影像、病人照護和其他領域中出現了新興應用。雖然這些應用已在回顧性研究中被證實是成功的，但實際上只有極少數應用於實務。醫療 AI 領域面臨著各種挑戰，包括建立使用者信任、遵守法規、使用資料符合倫理。可解釋 AI (XAI) 的目標是讓人類了解 AI 並相信其結果。本文針對最近幾年發表的 198 篇文章的具代表性樣本，提出有關醫療決策支援的 XAI 解決方案的最新發展的文獻回顧。相關文章的系統性綜合整理產生了多項發現：(1) 這些解決方案大多採用與模型無關的 XAI 技術，(2) 深度學習模型的使用率高於其他類型的機器學習模型，(3) 可解釋性被用於促進信任，但很少有研究報告醫師參與迴圈，(4) 視覺和互動式使用者介面對於理解系統的解釋和建議更有用。需要更多醫療和 AI 專家合作進行研究，這有助於為醫療領域的 XAI 解決方案的設計、實作和評估提供適當架構。

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva Cívico, Sergio Álvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

摘要：體外受精是治療不孕症最廣泛的方法之一。其主要挑戰之一是評估和選擇胚胎進行植入，此過程具有很大的臨床間和臨床內變異性。基於深度學習的方法正受到關注，但其不透明的性質會影響其在臨床環境中的接受度，而透明度在決策制定中至關重要。在本文中，我們分析了 AI 輔助胚胎分析模型的可解釋性方面的現有工作，並找出其局限性。我們還討論了如何將這些模型作為決策支持系統整合到臨床環境中，同時考慮臨床醫生和患者的需求。最後，我們提出了提高可解釋性和可信度的準則，推進這項技術朝著既定的臨床實務邁進。

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程 (RE) 領域中，可解釋人工智慧 (XAI) 在將 AI 支持的系統與使用者需求、社會期望和法規標準相符方面的重要性日益顯著，已獲得認可。一般來說，可解釋性已成為影響系統品質的重要非功能需求。然而，可解釋性與效能之間的假定權衡挑戰了可解釋性的假定正面影響。如果滿足可解釋性的需求需要降低系統效能，那麼必須仔細考慮這些品質面向中哪一個優先，以及如何在它們之間進行折衷。在本文中，我們批判性地探討了這種假定的權衡。我們認為，最好的方法是以一種細緻的方式來處理，這種方式包含資源可用性、領域特性和風險考量。透過提供未來研究和最佳實務的基礎，這項工作旨在提升 AI 的 RE 領域。

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian Schlüter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程（RE）领域，可解释人工智能（XAI）在将人工智能支持的系统与用户需求、社会期望和监管标准相一致方面的重要性日益凸显，并获得了认可。一般来说，可解释性已成为影响系统质量的重要非功能性需求。然而，可解释性和性能之间的权衡挑战了可解释性的正面影响。如果满足可解释性的要求需要降低系统性能，那么必须仔细考虑这些质量方面中的哪一个优先，以及如何在它们之间进行权衡。在本文中，我们批判性地考察了所谓的权衡。我们认为，最好以一种细致入微的方式来处理它，这种方式结合了资源可用性、领域特征和风险考虑。通过为未来的研究和最佳实践提供基础，这项工作旨在推进人工智能的 RE 领域。

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

摘要：本文嚴格評估歐洲委員會提出的 AI 法案對風險管理和風險可接受性的方法，用於對基本權利和安全構成風險的高風險 AI 系統。該法案旨在以相稱的監管負擔促進「值得信賴」的 AI。其關於風險可接受性的條款要求將高風險系統的殘餘風險減低或消除「盡可能」，並考慮「技術狀態」。此準則，特別是如果狹義解釋，無法執行，既不促進相稱的監管負擔，也不促進可信賴性。相比之下，議會對風險管理條款的最新修正草案引入了「合理性」、成本效益分析，並且更透明地說明了風險可接受性判斷的價值觀和背景性質。本文論證議會的方法更可行，且能更好地平衡相稱性和可信賴性的目標。本文說明風險可接受性判斷中的合理性會帶來什麼，並根據過失法和歐洲醫療器材法規中的原則進行說明。本文主張風險可接受性判斷的方法需要穩固的公民合法性基礎：包括監管機構的詳細指導或參與，以及受影響利害關係人的有意義投入。

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

摘要：可解釋人工智慧 (XAI) 是機器學習中快速進展的領域，旨在解開複雜模型的預測。XAI 在敏感應用中特別需要，例如在醫療保健中，當診斷、建議和治療選擇可能依賴於人工智慧系統做出的決策時。人工智慧方法也已廣泛用於老化研究，特別是在開發生物時鐘模型和識別老化和與年齡相關疾病的生物標誌物方面。然而，這裡 XAI 的潛力有待充分認識。我們討論了 XAI 在開發「老化時鐘」方面的應用，並對按特定生理系統的重點分類的文獻進行了全面的分析。

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, Jörg Schlötterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

摘要：部分原型模型是可解釋設計的影像分類器，也是黑箱 AI 的一個有前途的替代方案。這篇論文探討了解釋性機器學習，特別是 PIP-Net，在真實世界醫學影像資料上自動化診斷支援的適用性和潛力。PIP-Net 學習人類可理解的原型影像部分，我們評估其在骨折檢測和皮膚癌診斷方面的準確性和可解釋性。我們發現 PIP-Net 的決策制定過程符合醫學分類標準，同時僅提供影像層級類別標籤。由於 PIP-Net 對原型的無監督預訓練，因此可以輕鬆識別資料品質問題，例如 X 光中的不需要文字或標籤錯誤。此外，我們首次展示人類可以透過直接停用不需要的原型來手動修正 PIP-Net 的推理。我們得出結論，部分原型模型由於其可解釋性和進階模型除錯的潛力，因此有望應用於醫療。

