{"2501.09957": {"publish_time": "2025-01-17", "title": "FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs", "paper_summary": "To mitigate the hallucination and knowledge deficiency in large language\nmodels (LLMs), Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG)\nhas shown promising potential by utilizing KGs as external resource to enhance\nLLMs reasoning. However, existing KG-RAG approaches struggle with a trade-off\nbetween flexibility and retrieval quality. Modular methods prioritize\nflexibility by avoiding the use of KG-fine-tuned models during retrieval,\nleading to fixed retrieval strategies and suboptimal retrieval quality.\nConversely, coupled methods embed KG information within models to improve\nretrieval quality, but at the expense of flexibility. In this paper, we propose\na novel flexible modular KG-RAG framework, termed FRAG, which synergizes the\nadvantages of both approaches. FRAG estimates the hop range of reasoning paths\nbased solely on the query and classify it as either simple or complex. To match\nthe complexity of the query, tailored pipelines are applied to ensure efficient\nand accurate reasoning path retrieval, thus fostering the final reasoning\nprocess. By using the query text instead of the KG to infer the structural\ninformation of reasoning paths and employing adaptable retrieval strategies,\nFRAG improves retrieval quality while maintaining flexibility. Moreover, FRAG\ndoes not require extra LLMs fine-tuning or calls, significantly boosting\nefficiency and conserving resources. Extensive experiments show that FRAG\nachieves state-of-the-art performance with high efficiency and low resource\nconsumption.", "paper_summary_zh": "<paragraph>\u70ba\u4e86\u6e1b\u8f15\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u5e7b\u89ba\u548c\u77e5\u8b58\u4e0d\u8db3\uff0c\u57fa\u65bc\u77e5\u8b58\u5716\u8b5c (KG) \u7684\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u5df2\u5c55\u73fe\u51fa\u5229\u7528 KG \u4f5c\u70ba\u5916\u90e8\u8cc7\u6e90\u4f86\u589e\u5f37 LLM \u63a8\u7406\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 KG-RAG \u65b9\u6cd5\u5728\u9748\u6d3b\u6027\u8207\u6aa2\u7d22\u54c1\u8cea\u4e4b\u9593\u9762\u81e8\u53d6\u6368\u3002\u6a21\u7d44\u5316\u65b9\u6cd5\u900f\u904e\u907f\u514d\u5728\u6aa2\u7d22\u671f\u9593\u4f7f\u7528 KG \u5fae\u8abf\u6a21\u578b\u4f86\u512a\u5148\u8003\u616e\u9748\u6d3b\u6027\uff0c\u5c0e\u81f4\u56fa\u5b9a\u7684\u6aa2\u7d22\u7b56\u7565\u548c\u6b21\u4f73\u7684\u6aa2\u7d22\u54c1\u8cea\u3002\u76f8\u53cd\u5730\uff0c\u8026\u5408\u65b9\u6cd5\u5c07 KG \u8cc7\u8a0a\u5d4c\u5165\u6a21\u578b\u4e2d\u4ee5\u6539\u5584\u6aa2\u7d22\u54c1\u8cea\uff0c\u4f46\u72a7\u7272\u4e86\u9748\u6d3b\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u9748\u6d3b\u6a21\u7d44\u5316 KG-RAG \u6846\u67b6\uff0c\u7a31\u70ba FRAG\uff0c\u5b83\u5354\u540c\u4e86\u5169\u7a2e\u65b9\u6cd5\u7684\u512a\u9ede\u3002FRAG \u50c5\u6839\u64da\u67e5\u8a62\u4f30\u8a08\u63a8\u7406\u8def\u5f91\u7684\u8df3\u8e8d\u7bc4\u570d\uff0c\u4e26\u5c07\u5176\u5206\u985e\u70ba\u7c21\u55ae\u6216\u8907\u96dc\u3002\u70ba\u4e86\u5339\u914d\u67e5\u8a62\u7684\u8907\u96dc\u6027\uff0c\u61c9\u7528\u5ba2\u88fd\u5316\u7ba1\u9053\u4ee5\u78ba\u4fdd\u6709\u6548\u4e14\u6e96\u78ba\u7684\u63a8\u7406\u8def\u5f91\u6aa2\u7d22\uff0c\u5f9e\u800c\u4fc3\u9032\u6700\u7d42\u7684\u63a8\u7406\u904e\u7a0b\u3002FRAG \u4f7f\u7528\u67e5\u8a62\u6587\u5b57\u800c\u975e KG \u4f86\u63a8\u65b7\u63a8\u7406\u8def\u5f91\u7684\u7d50\u69cb\u5316\u8cc7\u8a0a\uff0c\u4e26\u63a1\u7528\u53ef\u9069\u61c9\u7684\u6aa2\u7d22\u7b56\u7565\uff0c\u5f9e\u800c\u6539\u5584\u6aa2\u7d22\u54c1\u8cea\uff0c\u540c\u6642\u4fdd\u6301\u9748\u6d3b\u6027\u3002\u6b64\u5916\uff0cFRAG \u4e0d\u9700\u8981\u984d\u5916\u7684 LLM \u5fae\u8abf\u6216\u547c\u53eb\uff0c\u986f\u8457\u63d0\u5347\u6548\u7387\u4e26\u7bc0\u7701\u8cc7\u6e90\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8868\u660e\uff0cFRAG \u4ee5\u9ad8\u6548\u7387\u548c\u4f4e\u8cc7\u6e90\u6d88\u8017\u5be6\u73fe\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\u3002</paragraph>", "author": "Zengyi Gao et.al.", "authors": "Zengyi Gao, Yukun Cao, Hairu Wang, Ao Ke, Yuan Feng, Xike Xie, S Kevin Zhou", "id": "2501.09957v2", "paper_url": "http://arxiv.org/abs/2501.09957v2", "repo": "null"}}