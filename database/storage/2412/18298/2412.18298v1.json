{"2412.18298": {"publish_time": "2024-12-24", "title": "Quo Vadis, Anomaly Detection? LLMs and VLMs in the Spotlight", "paper_summary": "Video anomaly detection (VAD) has witnessed significant advancements through\nthe integration of large language models (LLMs) and vision-language models\n(VLMs), addressing critical challenges such as interpretability, temporal\nreasoning, and generalization in dynamic, open-world scenarios. This paper\npresents an in-depth review of cutting-edge LLM-/VLM-based methods in 2024,\nfocusing on four key aspects: (i) enhancing interpretability through semantic\ninsights and textual explanations, making visual anomalies more understandable;\n(ii) capturing intricate temporal relationships to detect and localize dynamic\nanomalies across video frames; (iii) enabling few-shot and zero-shot detection\nto minimize reliance on large, annotated datasets; and (iv) addressing\nopen-world and class-agnostic anomalies by using semantic understanding and\nmotion features for spatiotemporal coherence. We highlight their potential to\nredefine the landscape of VAD. Additionally, we explore the synergy between\nvisual and textual modalities offered by LLMs and VLMs, highlighting their\ncombined strengths and proposing future directions to fully exploit the\npotential in enhancing video anomaly detection.", "paper_summary_zh": "\u5f71\u7247\u7570\u5e38\u5075\u6e2c (VAD) \u900f\u904e\u6574\u5408\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM)\uff0c\u5728\u53ef\u89e3\u91cb\u6027\u3001\u6642\u5e8f\u63a8\u7406\u548c\u52d5\u614b\u958b\u653e\u4e16\u754c\u5834\u666f\u4e2d\u7684\u6982\u62ec\u7b49\u95dc\u9375\u6311\u6230\u4e0a\u53d6\u5f97\u986f\u8457\u9032\u5c55\u3002\u672c\u6587\u6df1\u5165\u63a2\u8a0e 2024 \u5e74\u5c16\u7aef\u7684 LLM-/VLM- \u57fa\u790e\u65b9\u6cd5\uff0c\u91cd\u9ede\u95dc\u6ce8\u56db\u500b\u9762\u5411\uff1a(i) \u900f\u904e\u8a9e\u610f\u898b\u89e3\u548c\u6587\u5b57\u8aaa\u660e\u589e\u5f37\u53ef\u89e3\u91cb\u6027\uff0c\u8b93\u8996\u89ba\u7570\u5e38\u66f4\u6613\u65bc\u7406\u89e3\uff1b(ii) \u6355\u6349\u8907\u96dc\u7684\u6642\u9593\u95dc\u4fc2\uff0c\u4ee5\u5075\u6e2c\u548c\u5b9a\u4f4d\u5f71\u7247\u683c\u4e2d\u7684\u52d5\u614b\u7570\u5e38\uff1b(iii) \u555f\u7528\u5c11\u6a23\u672c\u548c\u96f6\u6a23\u672c\u5075\u6e2c\uff0c\u4ee5\u6e1b\u5c11\u5c0d\u5927\u578b\u6a19\u8a3b\u8cc7\u6599\u96c6\u7684\u4f9d\u8cf4\uff1b(iv) \u900f\u904e\u8a9e\u610f\u7406\u89e3\u548c\u52d5\u4f5c\u7279\u5fb5\u89e3\u6c7a\u958b\u653e\u4e16\u754c\u548c\u8207\u985e\u5225\u7121\u95dc\u7684\u7570\u5e38\uff0c\u4ee5\u5be6\u73fe\u6642\u7a7a\u4e00\u81f4\u6027\u3002\u6211\u5011\u5f37\u8abf\u5b83\u5011\u91cd\u65b0\u5b9a\u7fa9 VAD \u9818\u57df\u7684\u6f5b\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e LLM \u548c VLM \u63d0\u4f9b\u7684\u8996\u89ba\u548c\u6587\u5b57\u6a21\u614b\u4e4b\u9593\u7684\u7d9c\u6548\uff0c\u91cd\u9ede\u8aaa\u660e\u5b83\u5011\u7d50\u5408\u7684\u512a\u52e2\uff0c\u4e26\u63d0\u51fa\u672a\u4f86\u65b9\u5411\uff0c\u4ee5\u5145\u5206\u767c\u63ee\u589e\u5f37\u5f71\u7247\u7570\u5e38\u5075\u6e2c\u7684\u6f5b\u529b\u3002", "author": "Xi Ding et.al.", "authors": "Xi Ding, Lei Wang", "id": "2412.18298v1", "paper_url": "http://arxiv.org/abs/2412.18298v1", "repo": "null"}}