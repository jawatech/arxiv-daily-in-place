{"2502.11779": {"publish_time": "2025-02-17", "title": "Efficient Response Generation Method Selection for Fine-Tuning Large Language Models", "paper_summary": "The training data for fine-tuning large language models (LLMs) is typically\nstructured as input-output pairs. However, for many tasks, there can be\nmultiple equally valid output variations for the same input. Recent studies\nhave observed that the choice of output variation used in training can affect\nthe model's performance. This raises an important question: how can we generate\nthe most effective output from the many possible response generation strategy\noptions? Rather than relying on the traditional but resource-intensive\ntrain-and-evaluate approach, this paper proposes a scalable, approximate method\nfor estimating the quality of a small subset of generated training data derived\nfrom the same input. We then evaluate how well this small subset of generated\noutput fits the target model we are trying to train. We present a large-scale\nbenchmark covering diverse reasoning-based datasets to support our study.\n  The central idea is that a good output should closely resemble the output\ngenerated by the target LLM. We formalize this 'closeness' as the expected\nalignment score between a candidate output and the output sampled from the\ntarget LLM. We connect this measurement to the perplexity metric used in\nprevious literature and demonstrate that leveraging an alignment-based metric\ncan provide better predictions of model performance. Using this strategy, we\ncan evaluate a small subset of the generated output from each response\ngeneration strategy option, then select the most effective strategy. We show\nthat an LLM trained on data generated by the selected strategy could lead to a\nsignificant performance gain in many cases.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5fae\u8abf\u8a13\u7df4\u8cc7\u6599\u901a\u5e38\n\u4ee5\u8f38\u5165\u8f38\u51fa\u914d\u5c0d\u7d50\u69cb\u5316\u3002\u7136\u800c\uff0c\u5c0d\u65bc\u8a31\u591a\u4efb\u52d9\u800c\u8a00\uff0c\u76f8\u540c\u7684\u8f38\u5165\u53ef\u80fd\u6709\u591a\u500b\u540c\u6a23\u6709\u6548\u7684\u8f38\u51fa\u8b8a\u5316\u3002\u6700\u8fd1\u7684\u7814\u7a76\n\u89c0\u5bdf\u5230\u8a13\u7df4\u4e2d\u4f7f\u7528\u7684\u8f38\u51fa\u8b8a\u5316\u9078\u64c7\u6703\u5f71\u97ff\u6a21\u578b\u7684\u6548\u80fd\u3002\u9019\u5f15\u767c\u4e86\u4e00\u500b\u91cd\u8981\u554f\u984c\uff1a\u6211\u5011\u5982\u4f55\u5f9e\u8a31\u591a\u53ef\u80fd\u7684\u56de\u61c9\u7522\u751f\u7b56\u7565\u9078\u9805\u4e2d\u7522\u751f\u6700\u6709\u6548\u7684\u8f38\u51fa\uff1f\u672c\u6587\u63d0\u51fa\u4e00\u500b\u53ef\u64f4\u5145\u3001\u8fd1\u4f3c\u7684\u65b9\u6cd5\uff0c\u7528\u65bc\u4f30\u8a08\u5f9e\u76f8\u540c\u8f38\u5165\u884d\u751f\u7684\u8a13\u7df4\u8cc7\u6599\u5c0f\u5b50\u96c6\u7684\u54c1\u8cea\uff0c\u800c\u975e\u4f9d\u8cf4\u50b3\u7d71\u4f46\u8cc7\u6e90\u5bc6\u96c6\u7684\u8a13\u7df4\u548c\u8a55\u4f30\u65b9\u6cd5\u3002\u7136\u5f8c\u6211\u5011\u8a55\u4f30\u9019\u500b\u7522\u751f\u8f38\u51fa\u7684\u5c0f\u5b50\u96c6\u8207\u6211\u5011\u5617\u8a66\u8a13\u7df4\u7684\u76ee\u6a19\u6a21\u578b\u7684\u5951\u5408\u7a0b\u5ea6\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u6db5\u84cb\u5404\u7a2e\u57fa\u65bc\u63a8\u7406\u7684\u8cc7\u6599\u96c6\u7684\u5927\u898f\u6a21\u57fa\u6e96\uff0c\u4ee5\u652f\u6301\u6211\u5011\u7684\u7814\u7a76\u3002\n\u6838\u5fc3\u6982\u5ff5\u662f\u826f\u597d\u7684\u8f38\u51fa\u61c9\u8207\u76ee\u6a19 LLM \u7522\u751f\u7684\u8f38\u51fa\u5bc6\u5207\u76f8\u4f3c\u3002\u6211\u5011\u5c07\u9019\u7a2e\u300c\u63a5\u8fd1\u5ea6\u300d\u5f62\u5f0f\u5316\u70ba\u5019\u9078\u8f38\u51fa\u8207\u5f9e\u76ee\u6a19 LLM \u53d6\u6a23\u7684\u8f38\u51fa\u4e4b\u9593\u7684\u9810\u671f\u5c0d\u9f4a\u5206\u6578\u3002\u6211\u5011\u5c07\u6b64\u6e2c\u91cf\u9023\u63a5\u5230\u5148\u524d\u6587\u737b\u4e2d\u4f7f\u7528\u7684\u56f0\u60d1\u5ea6\u6307\u6a19\uff0c\u4e26\u8b49\u660e\u5229\u7528\u57fa\u65bc\u5c0d\u9f4a\u7684\u6307\u6a19\u53ef\u4ee5\u63d0\u4f9b\u66f4\u597d\u7684\u6a21\u578b\u6548\u80fd\u9810\u6e2c\u3002\u4f7f\u7528\u6b64\u7b56\u7565\uff0c\u6211\u5011\u53ef\u4ee5\u8a55\u4f30\u6bcf\u500b\u56de\u61c9\u7522\u751f\u7b56\u7565\u9078\u9805\u6240\u7522\u751f\u8f38\u51fa\u7684\u5c0f\u5b50\u96c6\uff0c\u7136\u5f8c\u9078\u64c7\u6700\u6709\u6548\u7684\u7b56\u7565\u3002\u6211\u5011\u5c55\u793a\u5728\u7531\u6240\u9078\u7b56\u7565\u7522\u751f\u7684\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684 LLM\uff0c\u5728\u8a31\u591a\u60c5\u6cc1\u4e0b\u53ef\u80fd\u5c0e\u81f4\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\u3002", "author": "Xuan Ren et.al.", "authors": "Xuan Ren, Qi Chen, Lingqiao Liu", "id": "2502.11779v1", "paper_url": "http://arxiv.org/abs/2502.11779v1", "repo": "null"}}