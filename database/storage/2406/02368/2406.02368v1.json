{"2406.02368": {"publish_time": "2024-06-04", "title": "Large Language Models Make Sample-Efficient Recommender Systems", "paper_summary": "Large language models (LLMs) have achieved remarkable progress in the field\nof natural language processing (NLP), demonstrating remarkable abilities in\nproducing text that resembles human language for various tasks. This opens up\nnew opportunities for employing them in recommender systems (RSs). In this\npaper, we specifically examine the sample efficiency of LLM-enhanced\nrecommender systems, which pertains to the model's capacity to attain superior\nperformance with a limited quantity of training data. Conventional\nrecommendation models (CRMs) often need a large amount of training data because\nof the sparsity of features and interactions. Hence, we propose and verify our\ncore viewpoint: Large Language Models Make Sample-Efficient Recommender\nSystems. We propose a simple yet effective framework (i.e., Laser) to validate\nthe viewpoint from two aspects: (1) LLMs themselves are sample-efficient\nrecommenders; and (2) LLMs, as feature generators and encoders, make CRMs more\nsample-efficient. Extensive experiments on two public datasets show that Laser\nrequires only a small fraction of training samples to match or even surpass\nCRMs that are trained on the entire training set, demonstrating superior sample\nefficiency.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u9818\u57df\u53d6\u5f97\u4e86\u986f\u8457\u9032\u5c55\uff0c\u5728\u70ba\u5404\u7a2e\u4efb\u52d9\u7522\u751f\u985e\u4f3c\u4eba\u985e\u8a9e\u8a00\u7684\u6587\u5b57\u65b9\u9762\u5c55\u73fe\u4e86\u975e\u51e1\u7684\u80fd\u529b\u3002\u9019\u70ba\u5c07\u5b83\u5011\u61c9\u7528\u65bc\u63a8\u85a6\u7cfb\u7d71 (RS) \u958b\u95e2\u4e86\u65b0\u7684\u6a5f\u6703\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7279\u5225\u63a2\u8a0e\u4e86 LLM \u589e\u5f37\u63a8\u85a6\u7cfb\u7d71\u7684\u7bc4\u4f8b\u6548\u7387\uff0c\u9019\u8207\u6a21\u578b\u5728\u6709\u9650\u8a13\u7df4\u8cc7\u6599\u91cf\u4e0b\u7372\u5f97\u5353\u8d8a\u6548\u80fd\u7684\u80fd\u529b\u6709\u95dc\u3002\u50b3\u7d71\u63a8\u85a6\u6a21\u578b (CRM) \u901a\u5e38\u9700\u8981\u5927\u91cf\u7684\u8a13\u7df4\u8cc7\u6599\uff0c\u56e0\u70ba\u7279\u5fb5\u548c\u4e92\u52d5\u7684\u7a00\u758f\u6027\u3002\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e26\u9a57\u8b49\u4e86\u6211\u5011\u7684\u6838\u5fc3\u89c0\u9ede\uff1a\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u8b93\u7bc4\u4f8b\u9ad8\u6548\u7684\u63a8\u85a6\u7cfb\u7d71\u6210\u70ba\u53ef\u80fd\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u6709\u6548\u7684\u67b6\u69cb (\u5373 Laser)\uff0c\u5f9e\u5169\u500b\u65b9\u9762\u9a57\u8b49\u89c0\u9ede\uff1a(1) LLM \u672c\u8eab\u5c31\u662f\u7bc4\u4f8b\u9ad8\u6548\u7684\u63a8\u85a6\u7cfb\u7d71\uff1b(2) LLM \u4f5c\u70ba\u7279\u5fb5\u751f\u6210\u5668\u548c\u7de8\u78bc\u5668\uff0c\u8b93 CRM \u8b8a\u5f97\u66f4\u7bc4\u4f8b\u9ad8\u6548\u3002\u5728\u5169\u500b\u516c\u958b\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u986f\u793a\uff0cLaser \u53ea\u9700\u8981\u4e00\u5c0f\u90e8\u5206\u8a13\u7df4\u7bc4\u4f8b\u5c31\u80fd\u8207\u5728\u6574\u500b\u8a13\u7df4\u96c6\u4e0a\u8a13\u7df4\u7684 CRM \u76f8\u5339\u914d\uff0c\u751a\u81f3\u8d85\u8d8a\u5b83\u5011\uff0c\u5c55\u73fe\u51fa\u512a\u8d8a\u7684\u7bc4\u4f8b\u6548\u7387\u3002", "author": "Jianghao Lin et.al.", "authors": "Jianghao Lin, Xinyi Dai, Rong Shan, Bo Chen, Ruiming Tang, Yong Yu, Weinan Zhang", "id": "2406.02368v1", "paper_url": "http://arxiv.org/abs/2406.02368v1", "repo": "null"}}