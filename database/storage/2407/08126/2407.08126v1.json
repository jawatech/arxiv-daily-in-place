{"2407.08126": {"publish_time": "2024-07-11", "title": "Label-anticipated Event Disentanglement for Audio-Visual Video Parsing", "paper_summary": "Audio-Visual Video Parsing (AVVP) task aims to detect and temporally locate\nevents within audio and visual modalities. Multiple events can overlap in the\ntimeline, making identification challenging. While traditional methods usually\nfocus on improving the early audio-visual encoders to embed more effective\nfeatures, the decoding phase -- crucial for final event classification, often\nreceives less attention. We aim to advance the decoding phase and improve its\ninterpretability. Specifically, we introduce a new decoding paradigm,\n\\underline{l}abel s\\underline{e}m\\underline{a}ntic-based \\underline{p}rojection\n(LEAP), that employs labels texts of event categories, each bearing distinct\nand explicit semantics, for parsing potentially overlapping events.LEAP works\nby iteratively projecting encoded latent features of audio/visual segments onto\nsemantically independent label embeddings. This process, enriched by modeling\ncross-modal (audio/visual-label) interactions, gradually disentangles event\nsemantics within video segments to refine relevant label embeddings,\nguaranteeing a more discriminative and interpretable decoding process. To\nfacilitate the LEAP paradigm, we propose a semantic-aware optimization\nstrategy, which includes a novel audio-visual semantic similarity loss\nfunction. This function leverages the Intersection over Union of audio and\nvisual events (EIoU) as a novel metric to calibrate audio-visual similarities\nat the feature level, accommodating the varied event densities across\nmodalities. Extensive experiments demonstrate the superiority of our method,\nachieving new state-of-the-art performance for AVVP and also enhancing the\nrelevant audio-visual event localization task.", "paper_summary_zh": "\u8996\u807d\u5f71\u7247\u89e3\u6790 (AVVP) \u4efb\u52d9\u65e8\u5728\u5075\u6e2c\u548c\u66ab\u6642\u5b9a\u4f4d\u97f3\u8a0a\u548c\u8996\u89ba\u6a21\u5f0f\u4e2d\u7684\u4e8b\u4ef6\u3002\u591a\u91cd\u4e8b\u4ef6\u53ef\u80fd\u6703\u5728\u6642\u9593\u8ef8\u4e2d\u91cd\u758a\uff0c\u4f7f\u5f97\u8b58\u5225\u5177\u6709\u6311\u6230\u6027\u3002\u96d6\u7136\u50b3\u7d71\u65b9\u6cd5\u901a\u5e38\u5c08\u6ce8\u65bc\u6539\u9032\u65e9\u671f\u97f3\u8a0a\u8996\u89ba\u7de8\u78bc\u5668\u4ee5\u5d4c\u5165\u66f4\u6709\u6548\u7684\u7279\u5fb5\uff0c\u4f46\u5c0d\u65bc\u6700\u7d42\u4e8b\u4ef6\u5206\u985e\u81f3\u95dc\u91cd\u8981\u7684\u89e3\u78bc\u968e\u6bb5\uff0c\u901a\u5e38\u8f03\u5c11\u53d7\u5230\u95dc\u6ce8\u3002\u6211\u5011\u65e8\u5728\u63a8\u9032\u89e3\u78bc\u968e\u6bb5\u4e26\u6539\u5584\u5176\u53ef\u89e3\u91cb\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5f15\u5165\u4e00\u7a2e\u65b0\u7684\u89e3\u78bc\u7bc4\u4f8b\uff0c\\underline{l}abel s\\underline{e}m\\underline{a}ntic-based \\underline{p}rojection (LEAP)\uff0c\u5b83\u63a1\u7528\u4e8b\u4ef6\u985e\u5225\u7684\u6a19\u7c64\u6587\u5b57\uff0c\u6bcf\u500b\u6587\u5b57\u90fd\u5e36\u6709\u4e0d\u540c\u7684\u660e\u78ba\u8a9e\u7fa9\uff0c\u7528\u65bc\u89e3\u6790\u6f5b\u5728\u91cd\u758a\u4e8b\u4ef6\u3002LEAP \u7684\u904b\u4f5c\u65b9\u5f0f\u662f\u5c07\u97f3\u8a0a/\u8996\u89ba\u7247\u6bb5\u7684\u7de8\u78bc\u6f5b\u5728\u7279\u5fb5\u53cd\u8986\u6295\u5f71\u5230\u8a9e\u7fa9\u7368\u7acb\u7684\u6a19\u7c64\u5d4c\u5165\u4e2d\u3002\u9019\u500b\u904e\u7a0b\u900f\u904e\u5efa\u6a21\u8de8\u6a21\u614b\uff08\u97f3\u8a0a/\u8996\u89ba\u6a19\u7c64\uff09\u4e92\u52d5\u800c\u5f97\u5230\u8c50\u5bcc\uff0c\u9010\u6f38\u89e3\u958b\u5f71\u7247\u7247\u6bb5\u4e2d\u7684\u4e8b\u4ef6\u8a9e\u7fa9\uff0c\u4ee5\u6539\u5584\u76f8\u95dc\u6a19\u7c64\u5d4c\u5165\uff0c\u4fdd\u8b49\u66f4\u5177\u5340\u8fa8\u529b\u548c\u53ef\u89e3\u91cb\u6027\u7684\u89e3\u78bc\u904e\u7a0b\u3002\u70ba\u4e86\u4fc3\u9032 LEAP \u7bc4\u4f8b\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u8a9e\u7fa9\u611f\u77e5\u6700\u4f73\u5316\u7b56\u7565\uff0c\u5176\u4e2d\u5305\u62ec\u4e00\u500b\u65b0\u7a4e\u7684\u97f3\u8a0a\u8996\u89ba\u8a9e\u7fa9\u76f8\u4f3c\u6027\u640d\u5931\u51fd\u6578\u3002\u6b64\u51fd\u6578\u5229\u7528\u97f3\u8a0a\u548c\u8996\u89ba\u4e8b\u4ef6\u7684\u806f\u5408\u76f8\u5c0d\u65bc\u4ea4\u96c6 (EIoU) \u4f5c\u70ba\u4e00\u500b\u65b0\u7a4e\u7684\u6307\u6a19\uff0c\u7528\u65bc\u6821\u6e96\u7279\u5fb5\u5c64\u7d1a\u7684\u97f3\u8a0a\u8996\u89ba\u76f8\u4f3c\u6027\uff0c\u4ee5\u9069\u61c9\u5404\u7a2e\u8de8\u6a21\u614b\u7684\u4e8b\u4ef6\u5bc6\u5ea6\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u512a\u8d8a\u6027\uff0c\u5728 AVVP \u4e2d\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u5148\u9032\u6548\u80fd\uff0c\u4e26\u589e\u5f37\u4e86\u76f8\u95dc\u7684\u97f3\u8a0a\u8996\u89ba\u4e8b\u4ef6\u5b9a\u4f4d\u4efb\u52d9\u3002", "author": "Jinxing Zhou et.al.", "authors": "Jinxing Zhou, Dan Guo, Yuxin Mao, Yiran Zhong, Xiaojun Chang, Meng Wang", "id": "2407.08126v1", "paper_url": "http://arxiv.org/abs/2407.08126v1", "repo": "null"}}