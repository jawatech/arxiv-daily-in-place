{"2411.09947": {"publish_time": "2024-11-15", "title": "LoRA-LiteE: A Computationally Efficient Framework for Chatbot Preference-Tuning", "paper_summary": "Effective preference tuning is pivotal in aligning chatbot responses with\nhuman expectations, enhancing user satisfaction and engagement. Traditional\napproaches, notably Reinforcement Learning from Human Feedback (RLHF) as\nemployed in advanced models like GPT-4, have demonstrated considerable success\nin this domain. However, RLHF methods are often computationally intensive and\nresource-demanding, limiting their scalability and accessibility for broader\napplications. To address these challenges, this study introduces LoRA-Lite\nEnsemble (LoRA-LiteE), an innovative framework that combines Supervised\nFine-tuning (SFT) with Low-Rank Adaptation (LoRA) and Ensemble Learning\ntechniques to effectively aggregate predictions of lightweight models, which\naim to achieve a balance between the performance and computational cost.\nUtilizing the Chatbot Arena benchmark dataset, we conduct a comprehensive\ncomparative analysis among our LoRA-LiteE model, corresponding base models at\ndifferent scales, and GPT-4 trained with RLHF. Our empirical results\ndemonstrate that the proposed LoRA-LiteE model achieves comparable performance\nto un-finetuned GPT-4 and outperforms the single larger-scale models under\nlimited resource constraints. These findings highlight that our LoRA-LiteE\nprovides a feasible and efficient methodology for human preference prediction\nin chatbot systems, enhancing scalability and accessibility, and thereby\nbroadening the applicability of preference-tuned chatbots in\nresource-constrained environments.", "paper_summary_zh": "<paragraph>\u6709\u6548\u7684\u504f\u597d\u8abf\u6574\u5c0d\u65bc\u5c07\u804a\u5929\u6a5f\u5668\u4eba\u56de\u61c9\u8207\u4eba\u985e\u671f\u671b\u4fdd\u6301\u4e00\u81f4\u81f3\u95dc\u91cd\u8981\uff0c\u5f9e\u800c\u589e\u5f37\u7528\u6236\u6eff\u610f\u5ea6\u548c\u53c3\u8207\u5ea6\u3002\u50b3\u7d71\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u50cf GPT-4 \u7b49\u5148\u9032\u6a21\u578b\u4e2d\u63a1\u7528\u7684\u57fa\u65bc\u4eba\u985e\u53cd\u994b\u7684\u5f37\u5316\u5b78\u7fd2 (RLHF)\uff0c\u5df2\u8b49\u660e\u5728\u9019\u500b\u9818\u57df\u53d6\u5f97\u4e86\u986f\u8457\u6210\u529f\u3002\u7136\u800c\uff0cRLHF \u65b9\u6cd5\u901a\u5e38\u8a08\u7b97\u91cf\u5927\u4e14\u9700\u8981\u5927\u91cf\u8cc7\u6e90\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u66f4\u5ee3\u6cdb\u61c9\u7528\u4e2d\u7684\u53ef\u64f4\u5c55\u6027\u548c\u53ef\u8a2a\u554f\u6027\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u672c\u7814\u7a76\u5f15\u5165\u4e86 LoRA-Lite Ensemble (LoRA-LiteE)\uff0c\u9019\u662f\u4e00\u500b\u5275\u65b0\u7684\u6846\u67b6\uff0c\u5b83\u5c07\u76e3\u7763\u5fae\u8abf (SFT) \u8207\u4f4e\u79e9\u9069\u61c9 (LoRA) \u548c\u96c6\u6210\u5b78\u7fd2\u6280\u8853\u76f8\u7d50\u5408\uff0c\u4ee5\u6709\u6548\u5730\u532f\u7e3d\u8f15\u91cf\u7d1a\u6a21\u578b\u7684\u9810\u6e2c\uff0c\u65e8\u5728\u6027\u80fd\u8207\u8a08\u7b97\u6210\u672c\u4e4b\u9593\u53d6\u5f97\u5e73\u8861\u3002\u5229\u7528 Chatbot Arena \u57fa\u6e96\u6578\u64da\u96c6\uff0c\u6211\u5011\u5c0d\u6211\u5011\u7684 LoRA-LiteE \u6a21\u578b\u3001\u4e0d\u540c\u898f\u6a21\u7684\u5c0d\u61c9\u57fa\u790e\u6a21\u578b\u4ee5\u53ca\u4f7f\u7528 RLHF \u8a13\u7df4\u7684 GPT-4 \u9032\u884c\u4e86\u5168\u9762\u7684\u6bd4\u8f03\u5206\u6790\u3002\u6211\u5011\u7684\u5be6\u8b49\u7d50\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684 LoRA-LiteE \u6a21\u578b\u5be6\u73fe\u4e86\u8207\u672a\u5fae\u8abf\u7684 GPT-4 \u76f8\u7576\u7684\u6027\u80fd\uff0c\u4e26\u4e14\u5728\u6709\u9650\u7684\u8cc7\u6e90\u7d04\u675f\u4e0b\u512a\u65bc\u55ae\u500b\u66f4\u5927\u898f\u6a21\u7684\u6a21\u578b\u3002\u9019\u4e9b\u767c\u73fe\u5f37\u8abf\u4e86\u6211\u5011\u7684 LoRA-LiteE \u70ba\u804a\u5929\u6a5f\u5668\u4eba\u7cfb\u7d71\u4e2d\u7684\u4eba\u985e\u504f\u597d\u9810\u6e2c\u63d0\u4f9b\u4e86\u4e00\u7a2e\u53ef\u884c\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u589e\u5f37\u4e86\u53ef\u64f4\u5c55\u6027\u548c\u53ef\u8a2a\u554f\u6027\uff0c\u5f9e\u800c\u64f4\u5927\u4e86\u504f\u597d\u8abf\u6574\u804a\u5929\u6a5f\u5668\u4eba\u5728\u8cc7\u6e90\u53d7\u9650\u74b0\u5883\u4e2d\u7684\u9069\u7528\u6027\u3002</paragraph>", "author": "Yahe Yang et.al.", "authors": "Yahe Yang, Chunliang Tao, Xiaojing Fan", "id": "2411.09947v1", "paper_url": "http://arxiv.org/abs/2411.09947v1", "repo": "null"}}