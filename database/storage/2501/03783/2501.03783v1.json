{"2501.03783": {"publish_time": "2025-01-07", "title": "How to Select Pre-Trained Code Models for Reuse? A Learning Perspective", "paper_summary": "Pre-training a language model and then fine-tuning it has shown to be an\nefficient and effective technique for a wide range of code intelligence tasks,\nsuch as code generation, code summarization, and vulnerability detection.\nHowever, pretraining language models on a large-scale code corpus is\ncomputationally expensive. Fortunately, many off-the-shelf Pre-trained Code\nModels (PCMs), such as CodeBERT, CodeT5, CodeGen, and Code Llama, have been\nreleased publicly. These models acquire general code understanding and\ngeneration capability during pretraining, which enhances their performance on\ndownstream code intelligence tasks. With an increasing number of these public\npre-trained models, selecting the most suitable one to reuse for a specific\ntask is essential. In this paper, we systematically investigate the reusability\nof PCMs. We first explore three intuitive model selection methods that select\nby size, training data, or brute-force fine-tuning. Experimental results show\nthat these straightforward techniques either perform poorly or suffer high\ncosts. Motivated by these findings, we explore learning-based model selection\nstrategies that utilize pre-trained models without altering their parameters.\nSpecifically, we train proxy models to gauge the performance of pre-trained\nmodels, and measure the distribution deviation between a model's latent\nfeatures and the task's labels, using their closeness as an indicator of model\ntransferability. We conduct experiments on 100 widely-used opensource PCMs for\ncode intelligence tasks, with sizes ranging from 42.5 million to 3 billion\nparameters. The results demonstrate that learning-based selection methods\nreduce selection time to 100 seconds, compared to 2,700 hours with brute-force\nfine-tuning, with less than 6% performance degradation across related tasks.", "paper_summary_zh": "<paragraph>\u9810\u5148\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\uff0c\u7136\u5f8c\u5fae\u8abf\u5b83\uff0c\u5df2\u88ab\u8b49\u660e\u662f\u4e00\u7a2e\u9ad8\u6548\u4e14\u6709\u6548\u7684\u6280\u8853\uff0c\u53ef\u61c9\u7528\u4e8e\u5404\u7a2e\u7a0b\u5f0f\u78bc\u667a\u80fd\u4efb\u52d9\uff0c\u4f8b\u5982\u7a0b\u5f0f\u78bc\u751f\u6210\u3001\u7a0b\u5f0f\u78bc\u6458\u8981\u548c\u6f0f\u6d1e\u5075\u6e2c\u3002\n\u7136\u800c\uff0c\u5728\u5927\u578b\u7a0b\u5f0f\u78bc\u8a9e\u6599\u5eab\u4e0a\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u5728\u8a08\u7b97\u4e0a\u975e\u5e38\u6602\u8cb4\u3002\u5e78\u904b\u7684\u662f\uff0c\u8a31\u591a\u73fe\u6210\u7684\u9810\u8a13\u7df4\u7a0b\u5f0f\u78bc\u6a21\u578b (PCM)\uff0c\u4f8b\u5982 CodeBERT\u3001CodeT5\u3001CodeGen \u548c Code Llama\uff0c\u5df2\u7d93\u516c\u958b\u767c\u5e03\u3002\u9019\u4e9b\u6a21\u578b\u5728\u9810\u8a13\u7df4\u671f\u9593\u7372\u5f97\u4e86\u901a\u7528\u7684\u7a0b\u5f0f\u78bc\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u9019\u589e\u5f37\u4e86\u5b83\u5011\u5728\u4e0b\u6e38\u7a0b\u5f0f\u78bc\u667a\u80fd\u4efb\u52d9\u4e0a\u7684\u6548\u80fd\u3002\u96a8\u8457\u9019\u4e9b\u516c\u958b\u9810\u8a13\u7df4\u6a21\u578b\u6578\u91cf\u7684\u4e0d\u65b7\u589e\u52a0\uff0c\u9078\u64c7\u6700\u9069\u5408\u7279\u5b9a\u4efb\u52d9\u91cd\u8907\u4f7f\u7528\u7684\u6a21\u578b\u81f3\u95dc\u91cd\u8981\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7cfb\u7d71\u5730\u7814\u7a76\u4e86 PCM \u7684\u53ef\u91cd\u8907\u4f7f\u7528\u6027\u3002\u6211\u5011\u9996\u5148\u63a2\u8a0e\u4e86\u4e09\u7a2e\u76f4\u89c0\u7684\u6a21\u578b\u9078\u64c7\u65b9\u6cd5\uff0c\u5b83\u5011\u901a\u904e\u5927\u5c0f\u3001\u8a13\u7df4\u8cc7\u6599\u6216\u883b\u529b\u5fae\u8abf\u9032\u884c\u9078\u64c7\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u9019\u4e9b\u76f4\u63a5\u6280\u8853\u8981\u4e48\u57f7\u884c\u5f97\u5f88\u5dee\uff0c\u8981\u4e48\u6210\u672c\u5f88\u9ad8\u3002\u53d7\u9019\u4e9b\u767c\u73fe\u7684\u555f\u767c\uff0c\u6211\u5011\u63a2\u7d22\u4e86\u57fa\u65bc\u5b78\u7fd2\u7684\u6a21\u578b\u9078\u64c7\u7b56\u7565\uff0c\u5b83\u5011\u5229\u7528\u9810\u8a13\u7df4\u6a21\u578b\u800c\u4e0d\u6539\u8b8a\u5b83\u5011\u7684\u53c3\u6578\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u8a13\u7df4\u4ee3\u7406\u6a21\u578b\u4f86\u8a55\u4f30\u9810\u8a13\u7df4\u6a21\u578b\u7684\u6548\u80fd\uff0c\u4e26\u4f7f\u7528\u5b83\u5011\u7684\u63a5\u8fd1\u7a0b\u5ea6\u4f5c\u70ba\u6a21\u578b\u53ef\u50b3\u8f38\u6027\u7684\u6307\u6a19\uff0c\u4f86\u8861\u91cf\u6a21\u578b\u6f5b\u5728\u7279\u5fb5\u548c\u4efb\u52d9\u6a19\u7c64\u4e4b\u9593\u7684\u5206\u5e03\u504f\u5dee\u3002\u6211\u5011\u5c0d 100 \u500b\u5ee3\u6cdb\u4f7f\u7528\u7684\u958b\u6e90 PCM \u9032\u884c\u4e86\u7a0b\u5f0f\u78bc\u667a\u80fd\u4efb\u52d9\u7684\u5be6\u9a57\uff0c\u5176\u898f\u6a21\u5f9e 4250 \u842c\u5230 30 \u5104\u500b\u53c3\u6578\u4e0d\u7b49\u3002\u7d50\u679c\u8868\u660e\uff0c\u8207\u883b\u529b\u5fae\u8abf\u7684 2700 \u5c0f\u6642\u76f8\u6bd4\uff0c\u57fa\u65bc\u5b78\u7fd2\u7684\u9078\u64c7\u65b9\u6cd5\u5c07\u9078\u64c7\u6642\u9593\u6e1b\u5c11\u5230 100 \u79d2\uff0c\u800c\u76f8\u95dc\u4efb\u52d9\u7684\u6548\u80fd\u4e0b\u964d\u4e0d\u5230 6%\u3002</paragraph>", "author": "Zhangqian Bi et.al.", "authors": "Zhangqian Bi, Yao Wan, Zhaoyang Chu, Yufei Hu, Junyi Zhang, Hongyu Zhang, Guandong Xu, Hai Jin", "id": "2501.03783v1", "paper_url": "http://arxiv.org/abs/2501.03783v1", "repo": "null"}}