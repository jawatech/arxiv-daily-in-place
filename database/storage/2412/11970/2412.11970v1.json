{"2412.11970": {"publish_time": "2024-12-16", "title": "DARWIN 1.5: Large Language Models as Materials Science Adapted Learners", "paper_summary": "Materials discovery and design aim to find components and structures with\ndesirable properties over highly complex and diverse search spaces. Traditional\nsolutions, such as high-throughput simulations and machine learning (ML), often\nrely on complex descriptors, which hinder generalizability and transferability\nacross tasks. Moreover, these descriptors may deviate from experimental data\ndue to inevitable defects and purity issues in the real world, which may reduce\ntheir effectiveness in practical applications. To address these challenges, we\npropose Darwin 1.5, an open-source large language model (LLM) tailored for\nmaterials science. By leveraging natural language as input, Darwin eliminates\nthe need for task-specific descriptors and enables a flexible, unified approach\nto material property prediction and discovery. We employ a two-stage training\nstrategy combining question-answering (QA) fine-tuning with multi-task learning\n(MTL) to inject domain-specific knowledge in various modalities and facilitate\ncross-task knowledge transfer. Through our strategic approach, we achieved a\nsignificant enhancement in the prediction accuracy of LLMs, with a maximum\nimprovement of 60\\% compared to LLaMA-7B base models. It further outperforms\ntraditional machine learning models on various tasks in material science,\nshowcasing the potential of LLMs to provide a more versatile and scalable\nfoundation model for materials discovery and design.", "paper_summary_zh": "\u6750\u6599\u767c\u73fe\u548c\u8a2d\u8a08\u65e8\u5728\u5c0b\u627e\u5728\u9ad8\u5ea6\u8907\u96dc\u4e14\u591a\u6a23\u5316\u7684\u641c\u5c0b\u7a7a\u9593\u4e2d\u5177\u6709\u7406\u60f3\u7279\u6027\u7684\u7d44\u6210\u548c\u7d50\u69cb\u3002\u50b3\u7d71\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4f8b\u5982\u9ad8\u901a\u91cf\u6a21\u64ec\u548c\u6a5f\u5668\u5b78\u7fd2 (ML)\uff0c\u901a\u5e38\u4f9d\u8cf4\u65bc\u8907\u96dc\u7684\u63cf\u8ff0\u7b26\uff0c\u9019\u6703\u963b\u7919\u4efb\u52d9\u9593\u7684\u6982\u62ec\u6027\u548c\u53ef\u50b3\u905e\u6027\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u63cf\u8ff0\u7b26\u53ef\u80fd\u6703\u56e0\u73fe\u5be6\u4e16\u754c\u4e2d\u4e0d\u53ef\u907f\u514d\u7684\u7f3a\u9677\u548c\u7d14\u5ea6\u554f\u984c\u800c\u504f\u96e2\u5be6\u9a57\u6578\u64da\uff0c\u9019\u53ef\u80fd\u6703\u964d\u4f4e\u5b83\u5011\u5728\u5be6\u969b\u61c9\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86 Darwin 1.5\uff0c\u9019\u662f\u4e00\u500b\u91dd\u5c0d\u6750\u6599\u79d1\u5b78\u91cf\u8eab\u5b9a\u5236\u7684\u958b\u6e90\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\u3002\u901a\u904e\u5229\u7528\u81ea\u7136\u8a9e\u8a00\u4f5c\u70ba\u8f38\u5165\uff0cDarwin \u6d88\u9664\u4e86\u5c0d\u7279\u5b9a\u4efb\u52d9\u63cf\u8ff0\u7b26\u7684\u9700\u6c42\uff0c\u4e26\u5be6\u73fe\u4e86\u5c0d\u6750\u6599\u5c6c\u6027\u9810\u6e2c\u548c\u767c\u73fe\u7684\u9748\u6d3b\u3001\u7d71\u4e00\u7684\u65b9\u6cd5\u3002\u6211\u5011\u63a1\u7528\u7d50\u5408\u554f\u984c\u89e3\u7b54 (QA) \u5fae\u8abf\u548c\u591a\u4efb\u52d9\u5b78\u7fd2 (MTL) \u7684\u5169\u968e\u6bb5\u8a13\u7df4\u7b56\u7565\uff0c\u4ee5\u6ce8\u5165\u5404\u7a2e\u6a21\u5f0f\u7684\u9818\u57df\u7279\u5b9a\u77e5\u8b58\uff0c\u4e26\u4fc3\u9032\u8de8\u4efb\u52d9\u77e5\u8b58\u50b3\u905e\u3002\u901a\u904e\u6211\u5011\u7684\u7b56\u7565\u6027\u65b9\u6cd5\uff0c\u6211\u5011\u5728 LLM \u7684\u9810\u6e2c\u6e96\u78ba\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u986f\u8457\u63d0\u5347\uff0c\u8207 LLaMA-7B \u57fa\u790e\u6a21\u578b\u76f8\u6bd4\uff0c\u6700\u5927\u6539\u9032\u4e86 60%\u3002\u5b83\u5728\u6750\u6599\u79d1\u5b78\u7684\u5404\u7a2e\u4efb\u52d9\u4e2d\u9032\u4e00\u6b65\u512a\u65bc\u50b3\u7d71\u7684\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\uff0c\u5c55\u793a\u4e86 LLM \u70ba\u6750\u6599\u767c\u73fe\u548c\u8a2d\u8a08\u63d0\u4f9b\u66f4\u901a\u7528\u3001\u66f4\u53ef\u64f4\u5c55\u57fa\u790e\u6a21\u578b\u7684\u6f5b\u529b\u3002", "author": "Tong Xie et.al.", "authors": "Tong Xie, Yuwei Wan, Yixuan Liu, Yuchen Zeng, Wenjie Zhang, Chunyu Kit, Dongzhan Zhou, Bram Hoex", "id": "2412.11970v1", "paper_url": "http://arxiv.org/abs/2412.11970v1", "repo": "null"}}