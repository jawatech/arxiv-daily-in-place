{"2405.14604": {"publish_time": "2024-05-23", "title": "A Watermark for Low-entropy and Unbiased Generation in Large Language Models", "paper_summary": "Recent advancements in large language models (LLMs) have highlighted the risk\nof misuse, raising concerns about accurately detecting LLM-generated content. A\nviable solution for the detection problem is to inject imperceptible\nidentifiers into LLMs, known as watermarks. Previous work demonstrates that\nunbiased watermarks ensure unforgeability and preserve text quality by\nmaintaining the expectation of the LLM output probability distribution.\nHowever, previous unbiased watermarking methods are impractical for local\ndeployment because they rely on accesses to white-box LLMs and input prompts\nduring detection. Moreover, these methods fail to provide statistical\nguarantees for the type II error of watermark detection. This study proposes\nthe Sampling One Then Accepting (STA-1) method, an unbiased watermark that does\nnot require access to LLMs nor prompts during detection and has statistical\nguarantees for the type II error. Moreover, we propose a novel tradeoff between\nwatermark strength and text quality in unbiased watermarks. We show that in\nlow-entropy scenarios, unbiased watermarks face a tradeoff between watermark\nstrength and the risk of unsatisfactory outputs. Experimental results on\nlow-entropy and high-entropy datasets demonstrate that STA-1 achieves text\nquality and watermark strength comparable to existing unbiased watermarks, with\na low risk of unsatisfactory outputs. Implementation codes for this study are\navailable online.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u7a81\u986f\u4e86\u8aa4\u7528\u98a8\u96aa\uff0c\u5f15\u767c\u4e86\u6e96\u78ba\u6aa2\u6e2c LLM \u751f\u6210\u7684\u5167\u5bb9\u7684\u64d4\u6182\u3002\u6aa2\u6e2c\u554f\u984c\u7684\u53ef\u884c\u89e3\u6c7a\u65b9\u6848\u662f\u5c07\u96e3\u4ee5\u5bdf\u89ba\u7684\u8b58\u5225\u7b26\u6ce8\u5165 LLM\uff0c\u7a31\u70ba\u6d6e\u6c34\u5370\u3002\u5148\u524d\u7684\u7814\u7a76\u8868\u660e\uff0c\u7121\u504f\u6d6e\u6c34\u5370\u53ef\u78ba\u4fdd\u4e0d\u53ef\u507d\u9020\u6027\u4e26\u900f\u904e\u7dad\u6301 LLM \u8f38\u51fa\u6a5f\u7387\u5206\u4f48\u7684\u9810\u671f\u503c\u4f86\u4fdd\u7559\u6587\u5b57\u54c1\u8cea\u3002\u7136\u800c\uff0c\u5148\u524d\u7684\u7121\u504f\u6d6e\u6c34\u5370\u65b9\u6cd5\u5c0d\u65bc\u672c\u5730\u90e8\u7f72\u800c\u8a00\u4e0d\u5207\u5be6\u969b\uff0c\u56e0\u70ba\u5b83\u5011\u4f9d\u8cf4\u65bc\u5728\u6aa2\u6e2c\u671f\u9593\u5b58\u53d6\u767d\u76d2 LLM \u548c\u8f38\u5165\u63d0\u793a\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u65b9\u6cd5\u7121\u6cd5\u70ba\u6d6e\u6c34\u5370\u6aa2\u6e2c\u7684\u7b2c\u4e8c\u578b\u932f\u8aa4\u63d0\u4f9b\u7d71\u8a08\u4fdd\u8b49\u3002\u672c\u7814\u7a76\u63d0\u51fa\u63a1\u6a23\u4e00\u500b\u7136\u5f8c\u63a5\u53d7 (STA-1) \u65b9\u6cd5\uff0c\u9019\u662f\u4e00\u500b\u7121\u504f\u6d6e\u6c34\u5370\uff0c\u5728\u6aa2\u6e2c\u671f\u9593\u4e0d\u9700\u8981\u5b58\u53d6 LLM \u6216\u63d0\u793a\uff0c\u4e26\u4e14\u5c0d\u7b2c\u4e8c\u578b\u932f\u8aa4\u6709\u7d71\u8a08\u4fdd\u8b49\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u7121\u504f\u6d6e\u6c34\u5370\u4e2d\u6d6e\u6c34\u5370\u5f37\u5ea6\u548c\u6587\u5b57\u54c1\u8cea\u4e4b\u9593\u7684\u65b0\u6b0a\u8861\u3002\u6211\u5011\u8868\u660e\uff0c\u5728\u4f4e\u71b5\u5834\u666f\u4e2d\uff0c\u7121\u504f\u6d6e\u6c34\u5370\u9762\u81e8\u6d6e\u6c34\u5370\u5f37\u5ea6\u548c\u4e0d\u4ee4\u4eba\u6eff\u610f\u7684\u8f38\u51fa\u98a8\u96aa\u4e4b\u9593\u7684\u6b0a\u8861\u3002\u5728\u4f4e\u71b5\u548c\u9ad8\u71b5\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cSTA-1 \u9054\u5230\u4e86\u8207\u73fe\u6709\u7121\u504f\u6d6e\u6c34\u5370\u76f8\u7576\u7684\u6587\u5b57\u54c1\u8cea\u548c\u6d6e\u6c34\u5370\u5f37\u5ea6\uff0c\u4e14\u4e0d\u4ee4\u4eba\u6eff\u610f\u7684\u8f38\u51fa\u98a8\u96aa\u8f03\u4f4e\u3002\u672c\u7814\u7a76\u7684\u5be6\u4f5c\u7a0b\u5f0f\u78bc\u53ef\u5728\u7dda\u4e0a\u53d6\u5f97\u3002", "author": "Minjia Mao et.al.", "authors": "Minjia Mao, Dongjun Wei, Zeyu Chen, Xiao Fang, Michael Chau", "id": "2405.14604v1", "paper_url": "http://arxiv.org/abs/2405.14604v1", "repo": "https://github.com/djwei96/sta"}}