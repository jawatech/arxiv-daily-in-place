{"2412.16533": {"publish_time": "2024-12-21", "title": "Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models", "paper_summary": "We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that\nadvances the capabilities of large language models (LLMs) beyond existing\nparadigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of\nThoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT),\nwhich allows for an executable plan to be specified by LLMs for LLMs. LWT\nallows these plans to be arbitrary networks, where single-step LLM operations\nare nodes, and edges correspond to message passing between these steps.\nFurthermore, LWT supports selection of individual elements through indexing,\nfacilitating kNoT to produce intricate plans where each LLM operation can be\nlimited to elementary operations, greatly enhancing reliability over extended\ntask sequences. We demonstrate that kNoT significantly outperforms the state of\nthe art on six use cases, while reducing the need for extensive prompt\nengineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over\n12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less\ntask-specific prompts, respectively.", "paper_summary_zh": "\u6211\u5011\u5f15\u5165\u4e86\u601d\u60f3\u77e5\u8b58\u7db2\u8def (kNoT)\uff1a\u4e00\u7a2e\u63d0\u793a\u67b6\u69cb\uff0c\u5b83\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u80fd\u529b\u63d0\u5347\u5230\u4e86\u8d85\u8d8a\u73fe\u6709\u7bc4\u4f8b\u7684\u5883\u754c\uff0c\u4f8b\u5982\u601d\u60f3\u93c8 (CoT)\u3001\u601d\u60f3\u6a39 (ToT) \u548c\u601d\u60f3\u5716 (GoT)\u3002kNoT \u7684\u95dc\u9375\u5275\u65b0\u662f LLM \u5de5\u4f5c\u6d41\u7a0b\u7bc4\u672c (LWT)\uff0c\u5b83\u5141\u8a31 LLM \u70ba LLM \u6307\u5b9a\u4e00\u500b\u53ef\u57f7\u884c\u7684\u8a08\u756b\u3002LWT \u5141\u8a31\u9019\u4e9b\u8a08\u756b\u6210\u70ba\u4efb\u610f\u7db2\u8def\uff0c\u5176\u4e2d\u55ae\u6b65 LLM \u64cd\u4f5c\u70ba\u7bc0\u9ede\uff0c\u800c\u908a\u7de3\u5c0d\u61c9\u65bc\u9019\u4e9b\u6b65\u9a5f\u4e4b\u9593\u7684\u8a0a\u606f\u50b3\u905e\u3002\u6b64\u5916\uff0cLWT \u652f\u63f4\u900f\u904e\u7d22\u5f15\u9078\u53d6\u500b\u5225\u5143\u7d20\uff0c\u9032\u800c\u8b93 kNoT \u80fd\u5920\u5236\u5b9a\u8907\u96dc\u7684\u8a08\u756b\uff0c\u5176\u4e2d\u6bcf\u500b LLM \u64cd\u4f5c\u90fd\u53ef\u4ee5\u9650\u5236\u70ba\u57fa\u672c\u64cd\u4f5c\uff0c\u5927\u5e45\u63d0\u5347\u5ef6\u4f38\u4efb\u52d9\u5e8f\u5217\u7684\u53ef\u9760\u6027\u3002\u6211\u5011\u8b49\u660e kNoT \u5728\u516d\u500b\u7528\u4f8b\u4e0a\u986f\u8457\u512a\u65bc\u73fe\u6709\u6280\u8853\uff0c\u540c\u6642\u6e1b\u5c11\u4e86\u5c0d\u5ee3\u6cdb\u63d0\u793a\u5de5\u7a0b\u7684\u9700\u6c42\u3002\u4f8b\u5982\uff0ckNoT \u5728\u5c0d 32 \u500b\u6578\u5b57\u9032\u884c\u6392\u5e8f\u6642\u767c\u73fe 92% \u7684\u6e96\u78ba\u7387\uff0c\u800c ToT \u548c GoT \u70ba 12% \u548c 31%\uff0c\u540c\u6642\u5206\u5225\u5229\u7528\u4e86\u5c11\u9054 84.4% \u548c 87.3% \u7684\u7279\u5b9a\u4efb\u52d9\u63d0\u793a\u3002", "author": "Chao-Chi Chen et.al.", "authors": "Chao-Chi Chen, Chin-Yuan Yeh, Hsi-Wen Chen, De-Nian Yang, Ming-Syan Chen", "id": "2412.16533v1", "paper_url": "http://arxiv.org/abs/2412.16533v1", "repo": "null"}}