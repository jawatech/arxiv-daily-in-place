{"2412.20996": {"publish_time": "2024-12-30", "title": "Plug-and-Play Training Framework for Preference Optimization", "paper_summary": "Recently, preference optimization methods such as DPO have significantly\nenhanced large language models (LLMs) in wide tasks including dialogue and\nquestion-answering. However, current methods fail to account for the varying\ndifficulty levels of training samples during preference optimization, leading\nto mediocre performance in tasks with high accuracy requirements, particularly\nin mathematical reasoning. To address this limitation, we propose a novel\ntraining framework, which employs multiple sampling to analyze output\ndistributions, assign different weights to samples, and incorporate these\nweights into the preference optimization process. This plug-and-play approach\nenables LLMs to prioritize challenging examples during training, improving\nlearning efficiency. Experimental results demonstrate that our framework\nintegrates seamlessly with various preference optimization methods and achieves\nconsistent improvements in mathematical reasoning tasks.", "paper_summary_zh": "\u6700\u8fd1\uff0c\u8bf8\u5982 DPO \u7684\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u5df2\u663e\u8457\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM)\uff0c\u4f7f\u5176\u5728\u5305\u62ec\u5bf9\u8bdd\u548c\u95ee\u7b54\u5728\u5185\u7684\u5e7f\u6cdb\u4efb\u52a1\u4e2d\u5f97\u5230\u5e94\u7528\u3002\u7136\u800c\uff0c\u5f53\u524d\u65b9\u6cd5\u65e0\u6cd5\u5728\u504f\u597d\u4f18\u5316\u671f\u95f4\u8003\u8651\u8bad\u7ec3\u6837\u672c\u7684\u96be\u5ea6\u7ea7\u522b\uff0c\u5bfc\u81f4\u5728\u5bf9\u51c6\u786e\u6027\u8981\u6c42\u8f83\u9ad8\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u5e73\u5e73\uff0c\u5c24\u5176\u662f\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u591a\u91cd\u91c7\u6837\u6765\u5206\u6790\u8f93\u51fa\u5206\u5e03\uff0c\u4e3a\u6837\u672c\u5206\u914d\u4e0d\u540c\u7684\u6743\u91cd\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6743\u91cd\u7eb3\u5165\u504f\u597d\u4f18\u5316\u8fc7\u7a0b\u3002\u8fd9\u79cd\u5373\u63d2\u5373\u7528\u7684\u65b9\u6cd5\u4f7f LLM \u80fd\u591f\u5728\u8bad\u7ec3\u671f\u95f4\u4f18\u5148\u8003\u8651\u5177\u6709\u6311\u6218\u6027\u7684\u793a\u4f8b\uff0c\u4ece\u800c\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6846\u67b6\u4e0e\u5404\u79cd\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u65e0\u7f1d\u96c6\u6210\uff0c\u5e76\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4e00\u81f4\u7684\u6539\u8fdb\u3002", "author": "Jingyuan Ma et.al.", "authors": "Jingyuan Ma, Rui Li, Zheng Li, Lei Sha, Zhifang Sui", "id": "2412.20996v1", "paper_url": "http://arxiv.org/abs/2412.20996v1", "repo": "null"}}