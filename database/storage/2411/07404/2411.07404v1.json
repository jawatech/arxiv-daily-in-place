{"2411.07404": {"publish_time": "2024-11-11", "title": "Controllable Context Sensitivity and the Knob Behind It", "paper_summary": "When making predictions, a language model must trade off how much it relies\non its context vs. its prior knowledge. Choosing how sensitive the model is to\nits context is a fundamental functionality, as it enables the model to excel at\ntasks like retrieval-augmented generation and question-answering. In this\npaper, we search for a knob which controls this sensitivity, determining\nwhether language models answer from the context or their prior knowledge. To\nguide this search, we design a task for controllable context sensitivity. In\nthis task, we first feed the model a context (Paris is in England) and a\nquestion (Where is Paris?); we then instruct the model to either use its prior\nor contextual knowledge and evaluate whether it generates the correct answer\nfor both intents (either France or England). When fine-tuned on this task,\ninstruction-tuned versions of Llama-3.1, Mistral-v0.3, and Gemma-2 can solve it\nwith high accuracy (85-95%). Analyzing these high-performing models, we narrow\ndown which layers may be important to context sensitivity using a novel linear\ntime algorithm. Then, in each model, we identify a 1-D subspace in a single\nlayer that encodes whether the model follows context or prior knowledge.\nInterestingly, while we identify this subspace in a fine-tuned model, we find\nthat the exact same subspace serves as an effective knob in not only that model\nbut also non-fine-tuned instruct and base models of that model family. Finally,\nwe show a strong correlation between a model's performance and how distinctly\nit separates context-agreeing from context-ignoring answers in this subspace.\nThese results suggest a single subspace facilitates how the model chooses\nbetween context and prior knowledge, hinting at a simple fundamental mechanism\nthat controls this behavior.", "paper_summary_zh": "<paragraph>\u5728\u8fdb\u884c\u9884\u6d4b\u65f6\uff0c\u8bed\u8a00\u6a21\u578b\u5fc5\u987b\u6743\u8861\u5176\u5bf9\u4e0a\u4e0b\u6587\u4e0e\u5148\u9a8c\u77e5\u8bc6\u7684\u4f9d\u8d56\u7a0b\u5ea6\u3002\u9009\u62e9\u6a21\u578b\u5bf9\u4e0a\u4e0b\u6587\u7684\u654f\u611f\u7a0b\u5ea6\u662f\u4e00\u9879\u57fa\u672c\u529f\u80fd\uff0c\u56e0\u4e3a\u5b83\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u95ee\u7b54\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u5bfb\u627e\u4e00\u4e2a\u63a7\u5236\u8fd9\u79cd\u654f\u611f\u6027\u7684\u65cb\u94ae\uff0c\u786e\u5b9a\u8bed\u8a00\u6a21\u578b\u662f\u6839\u636e\u4e0a\u4e0b\u6587\u8fd8\u662f\u5148\u9a8c\u77e5\u8bc6\u6765\u56de\u7b54\u3002\u4e3a\u4e86\u6307\u5bfc\u8fd9\u9879\u641c\u7d22\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53ef\u63a7\u5236\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u7684\u4efb\u52a1\u3002\u5728\u8fd9\u4e2a\u4efb\u52a1\u4e2d\uff0c\u6211\u4eec\u9996\u5148\u5411\u6a21\u578b\u63d0\u4f9b\u4e00\u4e2a\u4e0a\u4e0b\u6587\uff08\u5df4\u9ece\u5728\u82f1\u56fd\uff09\u548c\u4e00\u4e2a\u95ee\u9898\uff08\u5df4\u9ece\u5728\u54ea\u91cc\uff1f\uff09\uff1b\u7136\u540e\u6211\u4eec\u6307\u793a\u6a21\u578b\u4f7f\u7528\u5176\u5148\u9a8c\u6216\u4e0a\u4e0b\u6587\u77e5\u8bc6\uff0c\u5e76\u8bc4\u4f30\u5b83\u662f\u5426\u4e3a\u4e24\u79cd\u610f\u56fe\uff08\u6cd5\u56fd\u6216\u82f1\u56fd\uff09\u751f\u6210\u4e86\u6b63\u786e\u7684\u7b54\u6848\u3002\u5728\u9488\u5bf9\u6b64\u4efb\u52a1\u8fdb\u884c\u5fae\u8c03\u540e\uff0cLlama-3.1\u3001Mistral-v0.3 \u548c Gemma-2 \u7684\u6307\u4ee4\u8c03\u6574\u7248\u672c\u53ef\u4ee5\u9ad8\u7cbe\u5ea6\uff0885-95%\uff09\u89e3\u51b3\u5b83\u3002\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u9ad8\u6027\u80fd\u6a21\u578b\uff0c\u6211\u4eec\u4f7f\u7528\u4e00\u79cd\u65b0\u9896\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u7f29\u5c0f\u4e86\u53ef\u80fd\u5bf9\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u5f88\u91cd\u8981\u7684\u5c42\u3002\u7136\u540e\uff0c\u5728\u6bcf\u4e2a\u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u5728\u5355\u4e2a\u5c42\u4e2d\u8bc6\u522b\u4e00\u4e2a\u4e00\u7ef4\u5b50\u7a7a\u95f4\uff0c\u8be5\u5b50\u7a7a\u95f4\u5bf9\u6a21\u578b\u662f\u9075\u5faa\u4e0a\u4e0b\u6587\u8fd8\u662f\u5148\u9a8c\u77e5\u8bc6\u8fdb\u884c\u7f16\u7801\u3002\u6709\u8da3\u7684\u662f\uff0c\u867d\u7136\u6211\u4eec\u5728\u5fae\u8c03\u6a21\u578b\u4e2d\u8bc6\u522b\u51fa\u8fd9\u4e2a\u5b50\u7a7a\u95f4\uff0c\u4f46\u6211\u4eec\u53d1\u73b0\u5b8c\u5168\u76f8\u540c\u7684\u5b50\u7a7a\u95f4\u4e0d\u4ec5\u5728\u8be5\u6a21\u578b\u4e2d\uff0c\u800c\u4e14\u5728\u8be5\u6a21\u578b\u7cfb\u5217\u7684\u975e\u5fae\u8c03\u6307\u4ee4\u548c\u57fa\u7840\u6a21\u578b\u4e2d\u90fd\u5145\u5f53\u6709\u6548\u65cb\u94ae\u3002\u6700\u540e\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u6a21\u578b\u7684\u6027\u80fd\u4e0e\u5176\u5728\u8fd9\u4e2a\u5b50\u7a7a\u95f4\u4e2d\u660e\u663e\u533a\u5206\u4e0a\u4e0b\u6587\u540c\u610f\u548c\u4e0a\u4e0b\u6587\u5ffd\u7565\u7b54\u6848\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u4e00\u4e2a\u5b50\u7a7a\u95f4\u4fc3\u8fdb\u4e86\u6a21\u578b\u5982\u4f55\u5728\u4e0a\u4e0b\u6587\u548c\u5148\u9a8c\u77e5\u8bc6\u4e4b\u95f4\u8fdb\u884c\u9009\u62e9\uff0c\u6697\u793a\u4e86\u4e00\u79cd\u63a7\u5236\u6b64\u884c\u4e3a\u7684\u7b80\u5355\u57fa\u672c\u673a\u5236\u3002</paragraph>", "author": "Julian Minder et.al.", "authors": "Julian Minder, Kevin Du, Niklas Stoehr, Giovanni Monea, Chris Wendler, Robert West, Ryan Cotterell", "id": "2411.07404v1", "paper_url": "http://arxiv.org/abs/2411.07404v1", "repo": "null"}}