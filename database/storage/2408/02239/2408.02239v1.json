{"2408.02239": {"publish_time": "2024-08-05", "title": "BOTS-LM: Training Large Language Models for Setswana", "paper_summary": "In this work we present BOTS-LM, a series of bilingual language models\nproficient in both Setswana and English. Leveraging recent advancements in data\navailability and efficient fine-tuning, BOTS-LM achieves performance similar to\nmodels significantly larger than itself while maintaining computational\nefficiency. Our initial release features an 8 billion parameter generative\nlarge language model, with upcoming 0.5 billion and 1 billion parameter large\nlanguage models and a 278 million parameter encoder-only model soon to be\nreleased. We find the 8 billion parameter model significantly outperforms\nLlama-3-70B and Aya 23 on English-Setswana translation tasks, approaching the\nperformance of dedicated machine translation models, while approaching 70B\nparameter performance on Setswana reasoning as measured by a machine translated\nsubset of the MMLU benchmark. To accompany the BOTS-LM series of language\nmodels, we release the largest Setswana web dataset, SetsText, totalling over\n267 million tokens. In addition, we release the largest machine translated\nSetswana dataset, the first and largest synthetic Setswana dataset, training\nand evaluation code, training logs, and MMLU-tsn, a machine translated subset\nof MMLU.", "paper_summary_zh": "\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u4e86 BOTS-LM\uff0c\u9019\u662f\u4e00\u7cfb\u5217\u7cbe\u901a\u585e\u8328\u74e6\u7d0d\u8a9e\u548c\u82f1\u8a9e\u7684\u96d9\u8a9e\u8a9e\u8a00\u6a21\u578b\u3002\u5229\u7528\u6578\u64da\u53ef\u7528\u6027\u548c\u9ad8\u6548\u5fae\u8abf\u7684\u6700\u65b0\u9032\u5c55\uff0cBOTS-LM \u9054\u5230\u4e86\u8207\u81ea\u8eab\u5927\u5f97\u591a\u7684\u6a21\u578b\u76f8\u4f3c\u7684\u6027\u80fd\uff0c\u540c\u6642\u4fdd\u6301\u4e86\u8a08\u7b97\u6548\u7387\u3002\u6211\u5011\u7684\u521d\u59cb\u7248\u672c\u5177\u6709 80 \u5104\u500b\u53c3\u6578\u7684\u751f\u6210\u5f0f\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u5373\u5c07\u63a8\u51fa\u7684 0.5 \u5104\u548c 10 \u5104\u500b\u53c3\u6578\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u4ee5\u53ca\u4e00\u500b 2.78 \u5104\u500b\u53c3\u6578\u7684\u50c5\u7de8\u78bc\u5668\u6a21\u578b\u3002\u6211\u5011\u767c\u73fe\uff0c80 \u5104\u500b\u53c3\u6578\u7684\u6a21\u578b\u5728\u82f1\u8a9e-\u585e\u8328\u74e6\u7d0d\u8a9e\u7ffb\u8b6f\u4efb\u52d9\u4e2d\u986f\u8457\u512a\u65bc Llama-3-70B \u548c Aya 23\uff0c\u63a5\u8fd1\u5c08\u7528\u6a5f\u5668\u7ffb\u8b6f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u6642\u5728\u901a\u904e\u6a5f\u5668\u7ffb\u8b6f\u7684 MMLU \u57fa\u6e96\u5b50\u96c6\u6e2c\u91cf\u7684\u585e\u8328\u74e6\u7d0d\u8a9e\u63a8\u7406\u65b9\u9762\u63a5\u8fd1 70B \u53c3\u6578\u6027\u80fd\u3002\u70ba\u4e86\u914d\u5408 BOTS-LM \u7cfb\u5217\u8a9e\u8a00\u6a21\u578b\uff0c\u6211\u5011\u767c\u5e03\u4e86\u6700\u5927\u7684\u585e\u8328\u74e6\u7d0d\u8a9e\u7db2\u8def\u6578\u64da\u96c6 SetsText\uff0c\u7e3d\u8a08\u8d85\u904e 2.67 \u5104\u500b\u4ee4\u724c\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u5e03\u4e86\u6700\u5927\u7684\u6a5f\u5668\u7ffb\u8b6f\u585e\u8328\u74e6\u7d0d\u8a9e\u6578\u64da\u96c6\u3001\u7b2c\u4e00\u500b\u4e5f\u662f\u6700\u5927\u7684\u5408\u6210\u585e\u8328\u74e6\u7d0d\u8a9e\u6578\u64da\u96c6\u3001\u8a13\u7df4\u548c\u8a55\u4f30\u4ee3\u78bc\u3001\u8a13\u7df4\u65e5\u8a8c\u548c MMLU-tsn\uff0c\u9019\u662f MMLU \u7684\u6a5f\u5668\u7ffb\u8b6f\u5b50\u96c6\u3002", "author": "Nathan Brown et.al.", "authors": "Nathan Brown, Vukosi Marivate", "id": "2408.02239v1", "paper_url": "http://arxiv.org/abs/2408.02239v1", "repo": "null"}}