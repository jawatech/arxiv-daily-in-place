{"2408.14438": {"publish_time": "2024-08-26", "title": "Evaluating Large Language Models on Spatial Tasks: A Multi-Task Benchmarking Study", "paper_summary": "The advent of large language models such as ChatGPT, Gemini, and others has\nunderscored the importance of evaluating their diverse capabilities, ranging\nfrom natural language understanding to code generation. However, their\nperformance on spatial tasks has not been comprehensively assessed. This study\naddresses this gap by introducing a novel multi-task spatial evaluation\ndataset, designed to systematically explore and compare the performance of\nseveral advanced models on spatial tasks. The dataset encompasses twelve\ndistinct task types, including spatial understanding and path planning, each\nwith verified, accurate answers. We evaluated multiple models, including\nOpenAI's gpt-3.5-turbo, gpt-4o, and ZhipuAI's glm-4, through a two-phase\ntesting approach. Initially, we conducted zero-shot testing, followed by\ncategorizing the dataset by difficulty and performing prompt tuning tests.\nResults indicate that gpt-4o achieved the highest overall accuracy in the first\nphase, with an average of 71.3%. Although moonshot-v1-8k slightly\nunderperformed overall, it surpassed gpt-4o in place name recognition tasks.\nThe study also highlights the impact of prompt strategies on model performance\nin specific tasks. For example, the Chain-of-Thought (COT) strategy increased\ngpt-4o's accuracy in path planning from 12.4% to 87.5%, while a one-shot\nstrategy enhanced moonshot-v1-8k's accuracy in mapping tasks from 10.1% to\n76.3%.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u4f8b\u5982 ChatGPT\u3001Gemini \u7b49\u7684\u51fa\u73fe\uff0c\n\u7a81\u986f\u4e86\u8a55\u4f30\u5176\u591a\u6a23\u5316\u529f\u80fd\u7684\u91cd\u8981\u6027\uff0c\u5f9e\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u5230\u7a0b\u5f0f\u78bc\u751f\u6210\u3002\n\u7136\u800c\uff0c\u5b83\u5011\u5728\u7a7a\u9593\u4efb\u52d9\u4e0a\u7684\u8868\u73fe\u5c1a\u672a\u5f97\u5230\u5168\u9762\u8a55\u4f30\u3002\n\u672c\u7814\u7a76\u901a\u904e\u5f15\u5165\u4e00\u500b\u65b0\u7a4e\u7684\u591a\u4efb\u52d9\u7a7a\u9593\u8a55\u4f30\u8cc7\u6599\u96c6\u4f86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\n\u65e8\u5728\u7cfb\u7d71\u5730\u63a2\u7d22\u548c\u6bd4\u8f03\u5e7e\u500b\u5148\u9032\u6a21\u578b\u5728\u7a7a\u9593\u4efb\u52d9\u4e0a\u7684\u8868\u73fe\u3002\n\u8a72\u8cc7\u6599\u96c6\u5305\u542b\u5341\u4e8c\u500b\u4e0d\u540c\u7684\u4efb\u52d9\u985e\u578b\uff0c\u5305\u62ec\u7a7a\u9593\u7406\u89e3\u548c\u8def\u5f91\u898f\u5283\uff0c\n\u6bcf\u500b\u4efb\u52d9\u90fd\u6709\u7d93\u904e\u9a57\u8b49\u7684\u6e96\u78ba\u7b54\u6848\u3002\n\u6211\u5011\u8a55\u4f30\u4e86\u591a\u500b\u6a21\u578b\uff0c\u5305\u62ec OpenAI \u7684 gpt-3.5-turbo\u3001gpt-4o \u548c ZhipuAI \u7684 glm-4\uff0c\n\u63a1\u7528\u5169\u968e\u6bb5\u6e2c\u8a66\u65b9\u6cd5\u3002\u6700\u521d\uff0c\u6211\u5011\u9032\u884c\u4e86\u96f6\u6b21\u5b78\u7fd2\u6e2c\u8a66\uff0c\n\u7136\u5f8c\u6309\u96e3\u5ea6\u5c0d\u8cc7\u6599\u96c6\u9032\u884c\u5206\u985e\u4e26\u57f7\u884c\u63d0\u793a\u8abf\u6574\u6e2c\u8a66\u3002\n\u7d50\u679c\u8868\u660e\uff0cgpt-4o \u5728\u7b2c\u4e00\u968e\u6bb5\u4e2d\u7372\u5f97\u4e86\u6700\u9ad8\u7684\u6574\u9ad4\u6e96\u78ba\u5ea6\uff0c\u5e73\u5747\u70ba 71.3%\u3002\n\u5118\u7ba1 moonshot-v1-8k \u7684\u6574\u9ad4\u8868\u73fe\u7565\u905c\u4e00\u7c4c\uff0c\u4f46\u5b83\u5728\u5730\u540d\u8b58\u5225\u4efb\u52d9\u4e2d\u8d85\u8d8a\u4e86 gpt-4o\u3002\n\u8a72\u7814\u7a76\u9084\u5f37\u8abf\u4e86\u63d0\u793a\u7b56\u7565\u5c0d\u7279\u5b9a\u4efb\u52d9\u4e2d\u6a21\u578b\u6548\u80fd\u7684\u5f71\u97ff\u3002\n\u4f8b\u5982\uff0c\u601d\u8003\u93c8 (COT) \u7b56\u7565\u5c07 gpt-4o \u5728\u8def\u5f91\u898f\u5283\u4e2d\u7684\u6e96\u78ba\u5ea6\u5f9e 12.4% \u63d0\u9ad8\u5230 87.5%\uff0c\n\u800c\u4e00\u6b21\u6027\u7b56\u7565\u5c07 moonshot-v1-8k \u5728\u6620\u5c04\u4efb\u52d9\u4e2d\u7684\u6e96\u78ba\u5ea6\u5f9e 10.1% \u63d0\u9ad8\u5230 76.3%\u3002", "author": "Liuchang Xu et.al.", "authors": "Liuchang Xu, Shuo Zhao, Qingming Lin, Luyao Chen, Qianqian Luo, Sensen Wu, Xinyue Ye, Hailin Feng, Zhenhong Du", "id": "2408.14438v2", "paper_url": "http://arxiv.org/abs/2408.14438v2", "repo": "null"}}