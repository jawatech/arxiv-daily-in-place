{"2412.02906": {"publish_time": "2024-12-03", "title": "Does Few-Shot Learning Help LLM Performance in Code Synthesis?", "paper_summary": "Large language models (LLMs) have made significant strides at code generation\nthrough improved model design, training, and chain-of-thought. However,\nprompt-level optimizations remain an important yet under-explored aspect of\nLLMs for coding. This work focuses on the few-shot examples present in most\ncode generation prompts, offering a systematic study on whether few-shot\nexamples improve LLM's coding capabilities, which few-shot examples have the\nlargest impact, and how to select impactful examples. Our work offers 2\napproaches for selecting few-shot examples, a model-free method,\nCODEEXEMPLAR-FREE, and a model-based method, CODEEXEMPLAR-BASED. The 2 methods\noffer a trade-off between improved performance and reliance on training data\nand interpretability. Both methods significantly improve CodeLlama's coding\nability across the popular HumanEval+ coding benchmark. In summary, our work\nprovides valuable insights into how to pick few-shot examples in code\ngeneration prompts to improve LLM code generation capabilities.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u900f\u904e\u6539\u5584\u6a21\u578b\u8a2d\u8a08\u3001\u8a13\u7df4\u548c\u601d\u8003\u93c8\uff0c\u5728\u7a0b\u5f0f\u78bc\u751f\u6210\u65b9\u9762\u53d6\u5f97\u91cd\u5927\u9032\u5c55\u3002\u7136\u800c\uff0c\u63d0\u793a\u5c64\u7d1a\u6700\u4f73\u5316\u4ecd\u7136\u662f LLM \u7de8\u78bc\u7684\u91cd\u8981\u4f46\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u65b9\u9762\u3002\u9019\u9805\u5de5\u4f5c\u91cd\u9ede\u5728\u65bc\u5927\u591a\u6578\u7a0b\u5f0f\u78bc\u751f\u6210\u63d0\u793a\u4e2d\u51fa\u73fe\u7684\u5c11\u6578\u7bc4\u4f8b\uff0c\u63d0\u4f9b\u4e00\u9805\u7cfb\u7d71\u6027\u7814\u7a76\uff0c\u63a2\u8a0e\u5c11\u6578\u7bc4\u4f8b\u662f\u5426\u80fd\u63d0\u5347 LLM \u7684\u7de8\u78bc\u80fd\u529b\uff0c\u54ea\u4e9b\u5c11\u6578\u7bc4\u4f8b\u5f71\u97ff\u6700\u5927\uff0c\u4ee5\u53ca\u5982\u4f55\u9078\u64c7\u6709\u5f71\u97ff\u529b\u7684\u7bc4\u4f8b\u3002\u6211\u5011\u7684\u7814\u7a76\u63d0\u4f9b 2 \u7a2e\u9078\u64c7\u5c11\u6578\u7bc4\u4f8b\u7684\u65b9\u6cd5\uff0c\u4e00\u7a2e\u662f\u7121\u6a21\u578b\u65b9\u6cd5\uff0cCODEEXEMPLAR-FREE\uff0c\u4e00\u7a2e\u662f\u57fa\u65bc\u6a21\u578b\u7684\u65b9\u6cd5\uff0cCODEEXEMPLAR-BASED\u3002\u9019 2 \u7a2e\u65b9\u6cd5\u5728\u6539\u5584\u6548\u80fd\u548c\u4f9d\u8cf4\u8a13\u7df4\u8cc7\u6599\u53ca\u53ef\u89e3\u91cb\u6027\u4e4b\u9593\u53d6\u5f97\u6b0a\u8861\u3002\u9019\u5169\u7a2e\u65b9\u6cd5\u90fd\u5927\u5e45\u63d0\u5347 CodeLlama \u5728\u71b1\u9580 HumanEval+ \u7de8\u78bc\u57fa\u6e96\u4e2d\u7684\u7de8\u78bc\u80fd\u529b\u3002\u7e3d\u4e4b\uff0c\u6211\u5011\u7684\u7814\u7a76\u63d0\u4f9b\u6709\u50f9\u503c\u7684\u898b\u89e3\uff0c\u8aaa\u660e\u5982\u4f55\u5728\u7a0b\u5f0f\u78bc\u751f\u6210\u63d0\u793a\u4e2d\u6311\u9078\u5c11\u6578\u7bc4\u4f8b\uff0c\u4ee5\u63d0\u5347 LLM \u7a0b\u5f0f\u78bc\u751f\u6210\u80fd\u529b\u3002", "author": "Derek Xu et.al.", "authors": "Derek Xu, Tong Xie, Botao Xia, Haoyu Li, Yunsheng Bai, Yizhou Sun, Wei Wang", "id": "2412.02906v1", "paper_url": "http://arxiv.org/abs/2412.02906v1", "repo": "null"}}