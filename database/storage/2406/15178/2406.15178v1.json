{"2406.15178": {"publish_time": "2024-06-21", "title": "Hybrid Alignment Training for Large Language Models", "paper_summary": "Alignment training is crucial for enabling large language models (LLMs) to\ncater to human intentions and preferences. It is typically performed based on\ntwo stages with different objectives: instruction-following alignment and\nhuman-preference alignment. However, aligning LLMs with these objectives in\nsequence suffers from an inherent problem: the objectives may conflict, and the\nLLMs cannot guarantee to simultaneously align with the instructions and human\npreferences well. To response to these, in this work, we propose a Hybrid\nAlignment Training (Hbat) approach, based on alternating alignment and modified\nelastic weight consolidation methods. The basic idea is to alternate between\ndifferent objectives during alignment training, so that better collaboration\ncan be achieved between the two alignment tasks.We experiment with Hbat on\nsummarization and dialogue tasks. Experimental results show that the proposed\n\\textsc{Hbat} can significantly outperform all baselines. Notably, Hbat yields\nconsistent performance gains over the traditional two-stage alignment training\nwhen using both proximal policy optimization and direct preference\noptimization.", "paper_summary_zh": "\u5c0d\u9f4a\u8a13\u7df4\u5c0d\u65bc\u8b93\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8fce\u5408\u4eba\u985e\u610f\u5716\u548c\u504f\u597d\u81f3\u95dc\u91cd\u8981\u3002\u5b83\u901a\u5e38\u57fa\u65bc\u5169\u500b\u5177\u6709\u4e0d\u540c\u76ee\u6a19\u7684\u968e\u6bb5\u57f7\u884c\uff1a\u9075\u5faa\u6307\u4ee4\u7684\u5c0d\u9f4a\u548c\u4eba\u985e\u504f\u597d\u7684\u5c0d\u9f4a\u3002\u7136\u800c\uff0c\u6309\u9806\u5e8f\u4f7f\u7528\u9019\u4e9b\u76ee\u6a19\u5c0d\u9f4a LLM \u6703\u7522\u751f\u4e00\u500b\u56fa\u6709\u7684\u554f\u984c\uff1a\u9019\u4e9b\u76ee\u6a19\u53ef\u80fd\u6703\u885d\u7a81\uff0c\u800c LLM \u7121\u6cd5\u4fdd\u8b49\u540c\u6642\u8207\u6307\u4ee4\u548c\u4eba\u985e\u504f\u597d\u5f88\u597d\u5730\u5c0d\u9f4a\u3002\u70ba\u4e86\u56de\u61c9\u9019\u4e9b\u554f\u984c\uff0c\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u6df7\u5408\u5c0d\u9f4a\u8a13\u7df4 (Hbat) \u65b9\u6cd5\uff0c\u5b83\u57fa\u65bc\u4ea4\u66ff\u5c0d\u9f4a\u548c\u4fee\u6539\u7684\u5f48\u6027\u6b0a\u91cd\u5408\u4f75\u65b9\u6cd5\u3002\u57fa\u672c\u60f3\u6cd5\u662f\u5728\u5c0d\u9f4a\u8a13\u7df4\u671f\u9593\u5728\u4e0d\u540c\u7684\u76ee\u6a19\u4e4b\u9593\u4ea4\u66ff\uff0c\u4ee5\u4fbf\u5728\u5169\u500b\u5c0d\u9f4a\u4efb\u52d9\u4e4b\u9593\u5be6\u73fe\u66f4\u597d\u7684\u5354\u4f5c\u3002\u6211\u5011\u5728\u6458\u8981\u548c\u5c0d\u8a71\u4efb\u52d9\u4e2d\u5c0d Hbat \u9032\u884c\u4e86\u5be6\u9a57\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\\textsc{Hbat} \u53ef\u4ee5\u986f\u8457\u512a\u65bc\u6240\u6709\u57fa\u6e96\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u512a\u5316\u548c\u76f4\u63a5\u504f\u597d\u512a\u5316\u6642\uff0cHbat \u5728\u50b3\u7d71\u5169\u968e\u6bb5\u5c0d\u9f4a\u8a13\u7df4\u4e2d\u7522\u751f\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "author": "Chenglong Wang et.al.", "authors": "Chenglong Wang, Hang Zhou, Kaiyan Chang, Bei Li, Yongyu Mu, Tong Xiao, Tongran Liu, Jingbo Zhu", "id": "2406.15178v1", "paper_url": "http://arxiv.org/abs/2406.15178v1", "repo": "null"}}