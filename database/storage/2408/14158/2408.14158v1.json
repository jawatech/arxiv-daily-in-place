{"2408.14158": {"publish_time": "2024-08-26", "title": "Fire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning", "paper_summary": "The rapid progress in Deep Learning (DL) and Large Language Models (LLMs) has\nexponentially increased demands of computational power and bandwidth. This,\ncombined with the high costs of faster computing chips and interconnects, has\nsignificantly inflated High Performance Computing (HPC) construction costs. To\naddress these challenges, we introduce the Fire-Flyer AI-HPC architecture, a\nsynergistic hardware-software co-design framework and its best practices. For\nDL training, we deployed the Fire-Flyer 2 with 10,000 PCIe A100 GPUs, achieved\nperformance approximating the DGX-A100 while reducing costs by half and energy\nconsumption by 40%. We specifically engineered HFReduce to accelerate allreduce\ncommunication and implemented numerous measures to keep our Computation-Storage\nIntegrated Network congestion-free. Through our software stack, including\nHaiScale, 3FS, and HAI-Platform, we achieved substantial scalability by\noverlapping computation and communication. Our system-oriented experience from\nDL training provides valuable insights to drive future advancements in AI-HPC.", "paper_summary_zh": "\u6df1\u5ea6\u5b78\u7fd2 (DL) \u548c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u9032\u5c55\uff0c\u5df2\u5448\u6307\u6578\u7d1a\u589e\u9577\u5730\u589e\u52a0\u4e86\u5c0d\u904b\u7b97\u80fd\u529b\u548c\u983b\u5bec\u7684\u9700\u6c42\u3002\u9019\u8207\u66f4\u5feb\u901f\u7684\u904b\u7b97\u6676\u7247\u548c\u4e92\u9023\u7684\u9ad8\u6210\u672c\u76f8\u7d50\u5408\uff0c\u5df2\u5927\u5e45\u63d0\u9ad8\u4e86\u9ad8\u6027\u80fd\u904b\u7b97 (HPC) \u7684\u5efa\u7f6e\u6210\u672c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 Fire-Flyer AI-HPC \u67b6\u69cb\uff0c\u9019\u662f\u4e00\u500b\u5354\u540c\u7684\u786c\u9ad4\u8edf\u9ad4\u5171\u540c\u8a2d\u8a08\u67b6\u69cb\u53ca\u5176\u6700\u4f73\u5be6\u52d9\u3002\u5c0d\u65bc DL \u8a13\u7df4\uff0c\u6211\u5011\u90e8\u7f72\u4e86\u914d\u5099 10,000 \u500b PCIe A100 GPU \u7684 Fire-Flyer 2\uff0c\u5728\u5c07\u6210\u672c\u964d\u4f4e\u4e00\u534a\u548c\u80fd\u8017\u964d\u4f4e 40% \u7684\u540c\u6642\uff0c\u9054\u5230\u4e86\u8fd1\u4f3c\u65bc DGX-A100 \u7684\u6548\u80fd\u3002\u6211\u5011\u7279\u5225\u8a2d\u8a08\u4e86 HFReduce \u4f86\u52a0\u901f allreduce \u901a\u8a0a\uff0c\u4e26\u5be6\u65bd\u4e86\u8a31\u591a\u63aa\u65bd\u4f86\u4fdd\u6301\u6211\u5011\u7684\u904b\u7b97\u5132\u5b58\u6574\u5408\u7db2\u8def\u66a2\u901a\u7121\u963b\u3002\u900f\u904e\u6211\u5011\u7684\u8edf\u9ad4\u5806\u758a\uff0c\u5305\u62ec HaiScale\u30013FS \u548c HAI-Platform\uff0c\u6211\u5011\u900f\u904e\u91cd\u758a\u904b\u7b97\u548c\u901a\u8a0a\uff0c\u9054\u6210\u4e86\u5927\u5e45\u5ea6\u7684\u53ef\u64f4\u5145\u6027\u3002\u6211\u5011\u5f9e DL \u8a13\u7df4\u4e2d\u7372\u5f97\u7684\u7cfb\u7d71\u5c0e\u5411\u7d93\u9a57\uff0c\u70ba\u63a8\u52d5 AI-HPC \u672a\u4f86\u7684\u9032\u5c55\u63d0\u4f9b\u4e86\u5bf6\u8cb4\u7684\u898b\u89e3\u3002", "author": "Wei An et.al.", "authors": "Wei An, Xiao Bi, Guanting Chen, Shanhuang Chen, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Wenjun Gao, Kang Guan, Jianzhong Guo, Yongqiang Guo, Zhe Fu, Ying He, Panpan Huang, Jiashi Li, Wenfeng Liang, Xiaodong Liu, Xin Liu, Yiyuan Liu, Yuxuan Liu, Shanghao Lu, Xuan Lu, Xiaotao Nie, Tian Pei, Junjie Qiu, Hui Qu, Zehui Ren, Zhangli Sha, Xuecheng Su, Xiaowen Sun, Yixuan Tan, Minghui Tang, Shiyu Wang, Yaohui Wang, Yongji Wang, Ziwei Xie, Yiliang Xiong, Yanhong Xu, Shengfeng Ye, Shuiping Yu, Yukun Zha, Liyue Zhang, Haowei Zhang, Mingchuan Zhang, Wentao Zhang, Yichao Zhang, Chenggang Zhao, Yao Zhao, Shangyan Zhou, Shunfeng Zhou, Yuheng Zou", "id": "2408.14158v1", "paper_url": "http://arxiv.org/abs/2408.14158v1", "repo": "null"}}