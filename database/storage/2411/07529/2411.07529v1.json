{"2411.07529": {"publish_time": "2024-11-12", "title": "Evaluating ChatGPT-3.5 Efficiency in Solving Coding Problems of Different Complexity Levels: An Empirical Analysis", "paper_summary": "ChatGPT and other large language models (LLMs) promise to revolutionize\nsoftware development by automatically generating code from program\nspecifications. We assess the performance of ChatGPT's GPT-3.5-turbo model on\nLeetCode, a popular platform with algorithmic coding challenges for technical\ninterview practice, across three difficulty levels: easy, medium, and hard. We\ntest three main hypotheses. First, ChatGPT solves fewer problems as difficulty\nrises (Hypothesis 1). Second, prompt engineering improves ChatGPT's\nperformance, with greater gains on easier problems and diminishing returns on\nharder ones (Hypothesis 2). Third, ChatGPT performs better in popular languages\nlike Python, Java, and C++ than in less common ones like Elixir, Erlang, and\nRacket (Hypothesis 3). To investigate these hypotheses, we conduct automated\nexperiments using Python scripts to generate prompts that instruct ChatGPT to\ncreate Python solutions. These solutions are stored and manually submitted on\nLeetCode to check their correctness. For Hypothesis 1, results show the\nGPT-3.5-turbo model successfully solves 92% of easy, 79% of medium, and 51% of\nhard problems. For Hypothesis 2, prompt engineering yields improvements: 14-29%\nfor Chain of Thought Prompting, 38-60% by providing failed test cases in a\nsecond feedback prompt, and 33-58% by switching to GPT-4. From a random subset\nof problems ChatGPT solved in Python, it also solved 78% in Java, 50% in C++,\nand none in Elixir, Erlang, or Racket. These findings generally validate all\nthree hypotheses.", "paper_summary_zh": "ChatGPT \u548c\u5176\u4ed6\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u627f\u8bfa\u901a\u8fc7\u6839\u636e\u7a0b\u5e8f\u89c4\u683c\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u6765\u9769\u65b0\u8f6f\u4ef6\u5f00\u53d1\u3002\u6211\u4eec\u8bc4\u4f30\u4e86 ChatGPT \u7684 GPT-3.5-turbo \u6a21\u578b\u5728 LeetCode \u4e0a\u7684\u8868\u73b0\uff0c\u8fd9\u662f\u4e00\u4e2a\u6d41\u884c\u7684\u5e73\u53f0\uff0c\u63d0\u4f9b\u7b97\u6cd5\u7f16\u7801\u6311\u6218\uff0c\u7528\u4e8e\u6280\u672f\u9762\u8bd5\u5b9e\u8df5\uff0c\u6db5\u76d6\u4e09\u4e2a\u96be\u5ea6\u7ea7\u522b\uff1a\u7b80\u5355\u3001\u4e2d\u7b49\u548c\u56f0\u96be\u3002\u6211\u4eec\u6d4b\u8bd5\u4e86\u4e09\u4e2a\u4e3b\u8981\u5047\u8bbe\u3002\u9996\u5148\uff0c\u968f\u7740\u96be\u5ea6\u7684\u589e\u52a0\uff0cChatGPT \u89e3\u51b3\u7684\u95ee\u9898\u66f4\u5c11\uff08\u5047\u8bbe 1\uff09\u3002\u5176\u6b21\uff0c\u63d0\u793a\u5de5\u7a0b\u63d0\u9ad8\u4e86 ChatGPT \u7684\u6027\u80fd\uff0c\u5728\u8f83\u7b80\u5355\u7684\u9898\u76ee\u4e0a\u83b7\u5f97\u4e86\u66f4\u5927\u7684\u6536\u76ca\uff0c\u800c\u5728\u8f83\u96be\u7684\u9898\u76ee\u4e0a\u6536\u76ca\u9012\u51cf\uff08\u5047\u8bbe 2\uff09\u3002\u7b2c\u4e09\uff0cChatGPT \u5728 Python\u3001Java \u548c C++ \u7b49\u6d41\u884c\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u5728 Elixir\u3001Erlang \u548c Racket \u7b49\u4e0d\u592a\u5e38\u89c1\u7684\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\uff08\u5047\u8bbe 3\uff09\u3002\u4e3a\u4e86\u8c03\u67e5\u8fd9\u4e9b\u5047\u8bbe\uff0c\u6211\u4eec\u4f7f\u7528 Python \u811a\u672c\u8fdb\u884c\u81ea\u52a8\u5316\u5b9e\u9a8c\uff0c\u751f\u6210\u63d0\u793a\uff0c\u6307\u793a ChatGPT \u521b\u5efa Python \u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\u88ab\u5b58\u50a8\u5e76\u624b\u52a8\u63d0\u4ea4\u5230 LeetCode \u4ee5\u68c0\u67e5\u5176\u6b63\u786e\u6027\u3002\u5bf9\u4e8e\u5047\u8bbe 1\uff0c\u7ed3\u679c\u663e\u793a GPT-3.5-turbo \u6a21\u578b\u6210\u529f\u89e3\u51b3\u4e86 92% \u7684\u7b80\u5355\u95ee\u9898\u300179% \u7684\u4e2d\u7b49\u95ee\u9898\u548c 51% \u7684\u56f0\u96be\u95ee\u9898\u3002\u5bf9\u4e8e\u5047\u8bbe 2\uff0c\u63d0\u793a\u5de5\u7a0b\u4ea7\u751f\u4e86\u6539\u8fdb\uff1a\u601d\u7ef4\u94fe\u63d0\u793a\u63d0\u9ad8\u4e86 14-29%\uff0c\u5728\u7b2c\u4e8c\u4e2a\u53cd\u9988\u63d0\u793a\u4e2d\u63d0\u4f9b\u4e86\u5931\u8d25\u7684\u6d4b\u8bd5\u7528\u4f8b\u63d0\u9ad8\u4e86 38-60%\uff0c\u5207\u6362\u5230 GPT-4 \u63d0\u9ad8\u4e86 33-58%\u3002\u4ece ChatGPT \u7528 Python \u89e3\u51b3\u7684\u95ee\u9898\u7684\u968f\u673a\u5b50\u96c6\u4e2d\uff0c\u5b83\u8fd8\u7528 Java \u89e3\u51b3 78% \u7684\u95ee\u9898\uff0c\u7528 C++ \u89e3\u51b3 50% \u7684\u95ee\u9898\uff0c\u7528 Elixir\u3001Erlang \u6216 Racket \u89e3\u51b3 0 \u4e2a\u95ee\u9898\u3002\u8fd9\u4e9b\u53d1\u73b0\u603b\u4f53\u4e0a\u9a8c\u8bc1\u4e86\u6240\u6709\u4e09\u4e2a\u5047\u8bbe\u3002", "author": "Minda Li et.al.", "authors": "Minda Li, Bhaskar Krishnamachari", "id": "2411.07529v1", "paper_url": "http://arxiv.org/abs/2411.07529v1", "repo": "null"}}