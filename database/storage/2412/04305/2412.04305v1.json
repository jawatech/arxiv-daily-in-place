{"2412.04305": {"publish_time": "2024-12-05", "title": "ALMA: Alignment with Minimal Annotation", "paper_summary": "Recent approaches to large language model (LLM) alignment typically require\nmillions of human annotations or rely on external aligned models for synthetic\ndata generation. This paper introduces ALMA: Alignment with Minimal Annotation,\ndemonstrating that effective alignment can be achieved using only 9,000 labeled\nexamples -- less than 1% of conventional approaches. ALMA generates large\namounts of high-quality synthetic alignment data through new techniques:\ndiverse prompt synthesis via few-shot learning, diverse response generation\nwith multiple model checkpoints, and judge (reward model) enhancement through\nscore aggregation and self-distillation. Using only a pretrained Llama3 base\nmodel, 5,000 SFT examples, and 4,000 judge annotations, ALMA achieves\nperformance close to Llama3-Instruct across diverse alignment benchmarks (e.g.,\n0.1% difference on AlpacaEval 2.0 score). These results are achieved with a\nmulti-round, self-bootstrapped data synthesis and training recipe that\ncontinues to improve for 10 rounds, surpassing the typical 3-round ceiling of\nprevious methods. These results suggest that base models already possess\nsufficient knowledge for effective alignment, and that synthetic data\ngeneration methods can expose it.", "paper_summary_zh": "\u8fd1\u671f\u91dd\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c0d\u9f4a\u7684\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u6578\u767e\u842c\u7b46\u4eba\u5de5\u8a3b\u89e3\uff0c\u6216\u4f9d\u8cf4\u5916\u90e8\u5c0d\u9f4a\u6a21\u578b\u4f86\u7522\u751f\u5408\u6210\u8cc7\u6599\u3002\u672c\u6587\u4ecb\u7d39 ALMA\uff1a\u4f7f\u7528\u6700\u5c11\u8a3b\u89e3\u5c0d\u9f4a\uff0c\u8b49\u660e\u50c5\u4f7f\u7528 9,000 \u500b\u6a19\u8a18\u7bc4\u4f8b\u5c31\u80fd\u9054\u6210\u6709\u6548\u5c0d\u9f4a\uff0c\u5c11\u65bc\u50b3\u7d71\u65b9\u6cd5\u7684 1%\u3002ALMA \u900f\u904e\u65b0\u6280\u8853\u7522\u751f\u5927\u91cf\u9ad8\u54c1\u8cea\u7684\u5408\u6210\u5c0d\u9f4a\u8cc7\u6599\uff1a\u900f\u904e\u5c11\u91cf\u5b78\u7fd2\u9032\u884c\u591a\u5143\u63d0\u793a\u5408\u6210\u3001\u4f7f\u7528\u591a\u500b\u6a21\u578b\u6aa2\u67e5\u9ede\u9032\u884c\u591a\u5143\u56de\u61c9\u7522\u751f\uff0c\u4ee5\u53ca\u900f\u904e\u5206\u6578\u5f59\u7e3d\u548c\u81ea\u6211\u84b8\u993e\u4f86\u63d0\u5347\u8a55\u5224 (\u734e\u52f5\u6a21\u578b)\u3002ALMA \u50c5\u4f7f\u7528\u9810\u5148\u8a13\u7df4\u7684 Llama3 \u57fa\u790e\u6a21\u578b\u30015,000 \u500b SFT \u7bc4\u4f8b\u548c 4,000 \u500b\u8a55\u5224\u8a3b\u89e3\uff0c\u5c31\u80fd\u5728\u4e0d\u540c\u7684\u5c0d\u9f4a\u57fa\u6e96\u4e0a\u9054\u6210\u63a5\u8fd1 Llama3-Instruct \u7684\u6548\u80fd (\u4f8b\u5982\uff0cAlpacaEval 2.0 \u5206\u6578\u76f8\u5dee 0.1%)\u3002\u9019\u4e9b\u7d50\u679c\u662f\u900f\u904e\u591a\u8f2a\u3001\u81ea\u6211\u5f15\u5c0e\u7684\u8cc7\u6599\u5408\u6210\u548c\u8a13\u7df4\u65b9\u6cd5\u9054\u6210\uff0c\u6301\u7e8c\u6539\u5584 10 \u8f2a\uff0c\u8d85\u8d8a\u5148\u524d\u65b9\u6cd5\u5178\u578b\u7684 3 \u8f2a\u4e0a\u9650\u3002\u9019\u4e9b\u7d50\u679c\u986f\u793a\uff0c\u57fa\u790e\u6a21\u578b\u5df2\u5177\u5099\u8db3\u5920\u77e5\u8b58\u4f86\u9032\u884c\u6709\u6548\u5c0d\u9f4a\uff0c\u800c\u5408\u6210\u8cc7\u6599\u7522\u751f\u65b9\u6cd5\u53ef\u4ee5\u63ed\u9732\u9019\u4e9b\u77e5\u8b58\u3002", "author": "Michihiro Yasunaga et.al.", "authors": "Michihiro Yasunaga, Leonid Shamis, Chunting Zhou, Andrew Cohen, Jason Weston, Luke Zettlemoyer, Marjan Ghazvininejad", "id": "2412.04305v1", "paper_url": "http://arxiv.org/abs/2412.04305v1", "repo": "null"}}