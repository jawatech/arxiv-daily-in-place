{"2410.13765": {"publish_time": "2024-10-17", "title": "Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval", "paper_summary": "Large language models (LLMs) have been used to generate query expansions\naugmenting original queries for improving information search. Recent studies\nalso explore providing LLMs with initial retrieval results to generate query\nexpansions more grounded to document corpus. However, these methods mostly\nfocus on enhancing textual similarities between search queries and target\ndocuments, overlooking document relations. For queries like \"Find me a highly\nrated camera for wildlife photography compatible with my Nikon F-Mount lenses\",\nexisting methods may generate expansions that are semantically similar but\nstructurally unrelated to user intents. To handle such semi-structured queries\nwith both textual and relational requirements, in this paper we propose a\nknowledge-aware query expansion framework, augmenting LLMs with structured\ndocument relations from knowledge graph (KG). To further address the limitation\nof entity-based scoring in existing KG-based methods, we leverage document\ntexts as rich KG node representations and use document-based relation filtering\nfor our Knowledge-Aware Retrieval (KAR). Extensive experiments on three\ndatasets of diverse domains show the advantages of our method compared against\nstate-of-the-art baselines on textual and relational semi-structured retrieval.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u7528\u65bc\u7522\u751f\u67e5\u8a62\u64f4\u5145\uff0c\u85c9\u4ee5\u64f4\u5145\u539f\u59cb\u67e5\u8a62\uff0c\u4ee5\u6539\u5584\u8cc7\u8a0a\u641c\u5c0b\u3002\u6700\u8fd1\u7684\u7814\u7a76\u4e5f\u63a2\u8a0e\u63d0\u4f9b LLM \u521d\u59cb\u6aa2\u7d22\u7d50\u679c\uff0c\u4ee5\u7522\u751f\u66f4\u8cbc\u8fd1\u6587\u4ef6\u8a9e\u6599\u5eab\u7684\u67e5\u8a62\u64f4\u5145\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u5927\u591a\u8457\u91cd\u65bc\u52a0\u5f37\u641c\u5c0b\u67e5\u8a62\u8207\u76ee\u6a19\u6587\u4ef6\u4e4b\u9593\u7684\u6587\u5b57\u76f8\u4f3c\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u6587\u4ef6\u95dc\u4fc2\u3002\u5c0d\u65bc\u300c\u5e6b\u6211\u627e\u4e00\u53f0\u8207\u6211\u7684 Nikon F-Mount \u93e1\u982d\u76f8\u5bb9\u3001\u8a55\u50f9\u5f88\u9ad8\u7684\u91ce\u751f\u52d5\u7269\u651d\u5f71\u76f8\u6a5f\u300d\u7b49\u67e5\u8a62\uff0c\u73fe\u6709\u65b9\u6cd5\u53ef\u80fd\u6703\u7522\u751f\u8a9e\u7fa9\u4e0a\u76f8\u4f3c\u4f46\u7d50\u69cb\u4e0a\u8207\u4f7f\u7528\u8005\u610f\u5716\u7121\u95dc\u7684\u64f4\u5145\u3002\u70ba\u4e86\u8655\u7406\u5177\u6709\u6587\u5b57\u548c\u95dc\u4fc2\u9700\u6c42\u7684\u6b64\u985e\u534a\u7d50\u69cb\u5316\u67e5\u8a62\uff0c\u6211\u5011\u5728\u672c\u6587\u4e2d\u63d0\u51fa\u4e00\u500b\u77e5\u8b58\u611f\u77e5\u67e5\u8a62\u64f4\u5145\u67b6\u69cb\uff0c\u5229\u7528\u77e5\u8b58\u5716\u8b5c (KG) \u4e2d\u7684\u7d50\u69cb\u5316\u6587\u4ef6\u95dc\u4fc2\u64f4\u5145 LLM\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u89e3\u6c7a\u73fe\u6709\u57fa\u65bc KG \u7684\u65b9\u6cd5\u4e2d\u57fa\u65bc\u5be6\u9ad4\u7684\u8a55\u5206\u9650\u5236\uff0c\u6211\u5011\u5229\u7528\u6587\u4ef6\u6587\u5b57\u4f5c\u70ba\u8c50\u5bcc\u7684 KG \u7bc0\u9ede\u8868\u5fb5\uff0c\u4e26\u4f7f\u7528\u57fa\u65bc\u6587\u4ef6\u7684\u95dc\u4fc2\u7be9\u9078\uff0c\u9032\u884c\u6211\u5011\u7684\u77e5\u8b58\u611f\u77e5\u6aa2\u7d22 (KAR)\u3002\u91dd\u5c0d\u4e09\u500b\u4e0d\u540c\u9818\u57df\u8cc7\u6599\u96c6\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u986f\u793a\uff0c\u6211\u5011\u7684\u6a21\u578b\u8207\u6587\u5b57\u548c\u95dc\u4fc2\u534a\u7d50\u69cb\u5316\u6aa2\u7d22\u7684\u6700\u65b0\u57fa\u6e96\u76f8\u6bd4\uff0c\u5177\u6709\u512a\u52e2\u3002", "author": "Yu Xia et.al.", "authors": "Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan A. Rossi, Haoliang Wang, Julian McAuley", "id": "2410.13765v1", "paper_url": "http://arxiv.org/abs/2410.13765v1", "repo": "null"}}