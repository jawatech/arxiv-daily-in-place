{"2406.10729": {"publish_time": "2024-06-15", "title": "A Comprehensive Survey of Foundation Models in Medicine", "paper_summary": "Foundation models (FMs) are large-scale deep-learning models trained on\nextensive datasets using self-supervised techniques. These models serve as a\nbase for various downstream tasks, including healthcare. FMs have been adopted\nwith great success across various domains within healthcare, including natural\nlanguage processing (NLP), computer vision, graph learning, biology, and omics.\nExisting healthcare-based surveys have not yet included all of these domains.\nTherefore, this survey provides a comprehensive overview of FMs in healthcare.\nWe focus on the history, learning strategies, flagship models, applications,\nand challenges of FMs. We explore how FMs such as the BERT and GPT families are\nreshaping various healthcare domains, including clinical large language models,\nmedical image analysis, and omics data. Furthermore, we provide a detailed\ntaxonomy of healthcare applications facilitated by FMs, such as clinical NLP,\nmedical computer vision, graph learning, and other biology-related tasks.\nDespite the promising opportunities FMs provide, they also have several\nassociated challenges, which are explained in detail. We also outline potential\nfuture directions to provide researchers and practitioners with insights into\nthe potential and limitations of FMs in healthcare to advance their deployment\nand mitigate associated risks.", "paper_summary_zh": "\u57fa\u790e\u6a21\u578b (FM) \u662f\u4f7f\u7528\u81ea\u6211\u76e3\u7763\u6280\u8853\u5728\u5ee3\u6cdb\u6578\u64da\u96c6\u4e0a\u8a13\u7df4\u7684\u5927\u898f\u6a21\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u3002\u9019\u4e9b\u6a21\u578b\u4f5c\u70ba\u5404\u7a2e\u4e0b\u6e38\u4efb\u52d9\u7684\u57fa\u790e\uff0c\u5305\u62ec\u91ab\u7642\u4fdd\u5065\u3002FM \u5df2\u5728\u91ab\u7642\u4fdd\u5065\u7684\u5404\u7a2e\u9818\u57df\u4e2d\u88ab\u5ee3\u6cdb\u63a1\u7528\uff0c\u5305\u62ec\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP)\u3001\u96fb\u8166\u8996\u89ba\u3001\u5716\u5f62\u5b78\u7fd2\u3001\u751f\u7269\u5b78\u548c\u7d44\u5b78\u3002\u73fe\u6709\u7684\u57fa\u65bc\u91ab\u7642\u4fdd\u5065\u7684\u8abf\u67e5\u5c1a\u672a\u6db5\u84cb\u6240\u6709\u9019\u4e9b\u9818\u57df\u3002\u56e0\u6b64\uff0c\u672c\u8abf\u67e5\u63d0\u4f9b\u4e86 FM \u5728\u91ab\u7642\u4fdd\u5065\u4e2d\u7684\u5168\u9762\u6982\u8ff0\u3002\u6211\u5011\u5c08\u6ce8\u65bc FM \u7684\u6b77\u53f2\u3001\u5b78\u7fd2\u7b56\u7565\u3001\u65d7\u8266\u6a21\u578b\u3001\u61c9\u7528\u548c\u6311\u6230\u3002\u6211\u5011\u63a2\u8a0e\u4e86 BERT \u548c GPT \u5bb6\u65cf\u7b49 FM \u5982\u4f55\u91cd\u5851\u5404\u7a2e\u91ab\u7642\u4fdd\u5065\u9818\u57df\uff0c\u5305\u62ec\u81e8\u5e8a\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u3001\u91ab\u5b78\u5f71\u50cf\u5206\u6790\u548c\u7d44\u5b78\u6578\u64da\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u7531 FM \u4fc3\u9032\u7684\u91ab\u7642\u4fdd\u5065\u61c9\u7528\u8a73\u7d30\u5206\u985e\u6cd5\uff0c\u4f8b\u5982\u81e8\u5e8a NLP\u3001\u91ab\u5b78\u96fb\u8166\u8996\u89ba\u3001\u5716\u5f62\u5b78\u7fd2\u548c\u5176\u4ed6\u8207\u751f\u7269\u76f8\u95dc\u7684\u4efb\u52d9\u3002\u5118\u7ba1 FM \u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u6a5f\u6703\uff0c\u4f46\u5b83\u5011\u4e5f\u9762\u81e8\u8457\u4e00\u4e9b\u76f8\u95dc\u7684\u6311\u6230\uff0c\u9019\u4e9b\u6311\u6230\u5728\u6587\u4e2d\u90fd\u6709\u8a73\u7d30\u8aaa\u660e\u3002\u6211\u5011\u9084\u6982\u8ff0\u4e86\u6f5b\u5728\u7684\u672a\u4f86\u65b9\u5411\uff0c\u70ba\u7814\u7a76\u4eba\u54e1\u548c\u5f9e\u696d\u8005\u63d0\u4f9b\u6709\u95dc FM \u5728\u91ab\u7642\u4fdd\u5065\u4e2d\u7684\u6f5b\u529b\u548c\u5c40\u9650\u6027\u7684\u898b\u89e3\uff0c\u4ee5\u63a8\u9032\u5176\u90e8\u7f72\u4e26\u6e1b\u8f15\u76f8\u95dc\u98a8\u96aa\u3002", "author": "Wasif Khan et.al.", "authors": "Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, Ruogu Fang", "id": "2406.10729v1", "paper_url": "http://arxiv.org/abs/2406.10729v1", "repo": "null"}}