{"2412.20821": {"publish_time": "2024-12-30", "title": "Enhancing Multimodal Emotion Recognition through Multi-Granularity Cross-Modal Alignment", "paper_summary": "Multimodal emotion recognition (MER), leveraging speech and text, has emerged\nas a pivotal domain within human-computer interaction, demanding sophisticated\nmethods for effective multimodal integration. The challenge of aligning\nfeatures across these modalities is significant, with most existing approaches\nadopting a singular alignment strategy. Such a narrow focus not only limits\nmodel performance but also fails to address the complexity and ambiguity\ninherent in emotional expressions. In response, this paper introduces a\nMulti-Granularity Cross-Modal Alignment (MGCMA) framework, distinguished by its\ncomprehensive approach encompassing distribution-based, instance-based, and\ntoken-based alignment modules. This framework enables a multi-level perception\nof emotional information across modalities. Our experiments on IEMOCAP\ndemonstrate that our proposed method outperforms current state-of-the-art\ntechniques.", "paper_summary_zh": "\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\uff08MER\uff09\u5229\u7528\u8bed\u97f3\u548c\u6587\u672c\uff0c\u5df2\u6210\u4e3a\u4eba\u673a\u4ea4\u4e92\u4e2d\u81f3\u5173\u91cd\u8981\u7684\u9886\u57df\uff0c\u9700\u8981\u590d\u6742\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u6709\u6548\u7684\u591a\u6a21\u6001\u96c6\u6210\u3002\u8de8\u8fd9\u4e9b\u6a21\u6001\u5bf9\u9f50\u7279\u5f81\u7684\u6311\u6218\u662f\u91cd\u5927\u7684\uff0c\u5927\u591a\u6570\u73b0\u6709\u65b9\u6cd5\u91c7\u7528\u5355\u4e00\u5bf9\u9f50\u7b56\u7565\u3002\u5982\u6b64\u72ed\u7a84\u7684\u7126\u70b9\u4e0d\u4ec5\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u800c\u4e14\u65e0\u6cd5\u89e3\u51b3\u60c5\u611f\u8868\u8fbe\u4e2d\u56fa\u6709\u7684\u590d\u6742\u6027\u548c\u6a21\u7cca\u6027\u3002\u5bf9\u6b64\uff0c\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u591a\u7c92\u5ea6\u8de8\u6a21\u6001\u5bf9\u9f50\uff08MGCMA\uff09\u6846\u67b6\uff0c\u5176\u7279\u70b9\u662f\u5176\u5168\u9762\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u5206\u5e03\u3001\u57fa\u4e8e\u5b9e\u4f8b\u548c\u57fa\u4e8e\u4ee4\u724c\u7684\u5bf9\u9f50\u6a21\u5757\u3002\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u8de8\u6a21\u6001\u60c5\u611f\u4fe1\u606f\u7684\u591a\u5206\u8fa8\u7387\u611f\u77e5\u3002\u6211\u4eec\u5728 IEMOCAP \u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6280\u672f\u3002", "author": "Xuechen Wang et.al.", "authors": "Xuechen Wang, Shiwan Zhao, Haoqin Sun, Hui Wang, Jiaming Zhou, Yong Qin", "id": "2412.20821v1", "paper_url": "http://arxiv.org/abs/2412.20821v1", "repo": "null"}}