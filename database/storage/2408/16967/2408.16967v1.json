{"2408.16967": {"publish_time": "2024-08-30", "title": "MemLong: Memory-Augmented Retrieval for Long Text Modeling", "paper_summary": "Recent advancements in Large Language Models (LLMs) have yielded remarkable\nsuccess across diverse fields. However, handling long contexts remains a\nsignificant challenge for LLMs due to the quadratic time and space complexity\nof attention mechanisms and the growing memory consumption of the key-value\ncache during generation. This work introduces MemLong: Memory-Augmented\nRetrieval for Long Text Generation, a method designed to enhance the\ncapabilities of long-context language modeling by utilizing an external\nretriever for historical information retrieval. MemLong combines a\nnon-differentiable ``ret-mem'' module with a partially trainable decoder-only\nlanguage model and introduces a fine-grained, controllable retrieval attention\nmechanism that leverages semantic-level relevant chunks. Comprehensive\nevaluations on multiple long-context language modeling benchmarks demonstrate\nthat MemLong consistently outperforms other state-of-the-art LLMs. More\nimportantly, MemLong can extend the context length on a single 3090 GPU from 4k\nup to 80k. Our code is available at https://github.com/Bui1dMySea/MemLong", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8fd1\u671f\u7684\u9032\u5c55\u5728\u5404\u500b\u9818\u57df\u90fd\u53d6\u5f97\u4e86\u986f\u8457\u7684\u6210\u529f\u3002\u7136\u800c\uff0c\u7531\u65bc\u6ce8\u610f\u529b\u6a5f\u5236\u7684\u4e8c\u6b21\u6642\u9593\u548c\u7a7a\u9593\u8907\u96dc\u5ea6\uff0c\u4ee5\u53ca\u751f\u6210\u904e\u7a0b\u4e2d\u9375\u503c\u5feb\u53d6\u4e0d\u65b7\u589e\u52a0\u7684\u8a18\u61b6\u9ad4\u6d88\u8017\uff0c\u8655\u7406\u9577\u8a9e\u5883\u5c0d\u65bc LLM \u4f86\u8aaa\u4ecd\u7136\u662f\u4e00\u500b\u91cd\u5927\u7684\u6311\u6230\u3002\u9019\u9805\u5de5\u4f5c\u4ecb\u7d39\u4e86 MemLong\uff1a\u9577\u6587\u672c\u751f\u6210\u8a18\u61b6\u9ad4\u64f4\u5145\u6aa2\u7d22\uff0c\u4e00\u7a2e\u900f\u904e\u5229\u7528\u5916\u90e8\u6aa2\u7d22\u5668\u9032\u884c\u6b77\u53f2\u8cc7\u8a0a\u6aa2\u7d22\u4f86\u589e\u5f37\u9577\u8a9e\u5883\u8a9e\u8a00\u5efa\u6a21\u80fd\u529b\u7684\u65b9\u6cd5\u3002MemLong \u5c07\u4e00\u500b\u4e0d\u53ef\u5fae\u5206\u7684 ``ret-mem'' \u6a21\u7d44\u8207\u4e00\u500b\u90e8\u5206\u53ef\u8a13\u7df4\u7684\u50c5\u89e3\u78bc\u5668\u8a9e\u8a00\u6a21\u578b\u7d50\u5408\u8d77\u4f86\uff0c\u4e26\u5f15\u5165\u4e86\u4e00\u7a2e\u7cbe\u7d30\u4e14\u53ef\u63a7\u7684\u6aa2\u7d22\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u8a72\u6a5f\u5236\u5229\u7528\u4e86\u8a9e\u7fa9\u5c64\u7d1a\u76f8\u95dc\u7684\u5340\u584a\u3002\u5728\u591a\u500b\u9577\u8a9e\u5883\u8a9e\u8a00\u5efa\u6a21\u57fa\u6e96\u4e0a\u7684\u5168\u9762\u8a55\u4f30\u8868\u660e\uff0cMemLong \u6301\u7e8c\u512a\u65bc\u5176\u4ed6\u6700\u5148\u9032\u7684 LLM\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0cMemLong \u53ef\u4ee5\u5c07\u55ae\u500b 3090 GPU \u4e0a\u7684\u8a9e\u5883\u9577\u5ea6\u5f9e 4k \u64f4\u5c55\u5230 80k\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/Bui1dMySea/MemLong \u53d6\u5f97", "author": "Weijie Liu et.al.", "authors": "Weijie Liu, Zecheng Tang, Juntao Li, Kehai Chen, Min Zhang", "id": "2408.16967v1", "paper_url": "http://arxiv.org/abs/2408.16967v1", "repo": "https://github.com/bui1dmysea/memlong"}}