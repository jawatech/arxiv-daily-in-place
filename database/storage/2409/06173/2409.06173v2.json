{"2409.06173": {"publish_time": "2024-09-10", "title": "Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks", "paper_summary": "In-Context Learning (ICL) in Large Language Models (LLM) has emerged as the\ndominant technique for performing natural language tasks, as it does not\nrequire updating the model parameters with gradient-based methods. ICL promises\nto \"adapt\" the LLM to perform the present task at a competitive or\nstate-of-the-art level at a fraction of the computational cost. ICL can be\naugmented by incorporating the reasoning process to arrive at the final label\nexplicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.\nHowever, recent work has found that ICL relies mostly on the retrieval of task\npriors and less so on \"learning\" to perform tasks, especially for complex\nsubjective domains like emotion and morality, where priors ossify posterior\npredictions. In this work, we examine whether \"enabling\" reasoning also creates\nthe same behavior in LLMs, wherein the format of CoT retrieves reasoning priors\nthat remain relatively unchanged despite the evidence in the prompt. We find\nthat, surprisingly, CoT indeed suffers from the same posterior collapse as ICL\nfor larger language models. Code is avalaible at\nhttps://github.com/gchochla/cot-priors.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u8108\u7d61\u5b78\u7fd2 (ICL) \u5df2\u6210\u70ba\u57f7\u884c\u81ea\u7136\u8a9e\u8a00\u4efb\u52d9\u7684\u4e3b\u6d41\u6280\u8853\uff0c\u56e0\u70ba\u5b83\u4e0d\u9700\u8981\u4f7f\u7528\u57fa\u65bc\u68af\u5ea6\u7684\u6a21\u578b\u4f86\u66f4\u65b0\u6a21\u578b\u53c3\u6578\u3002ICL \u627f\u8afe\u4ee5\u6975\u4f4e\u7684\u8a08\u7b97\u6210\u672c\u300c\u9069\u61c9\u300dLLM \u4ee5\u5728\u7af6\u722d\u6216\u6700\u5148\u9032\u7684\u5c64\u7d1a\u57f7\u884c\u7576\u524d\u4efb\u52d9\u3002ICL \u53ef\u4ee5\u900f\u904e\u5728\u63d0\u793a\u4e2d\u660e\u78ba\u5730\u7d0d\u5165\u63a8\u7406\u904e\u7a0b\u4f86\u64f4\u5145\uff0c\u4ee5\u5f97\u51fa\u6700\u7d42\u6a19\u7c64\uff0c\u9019\u9805\u6280\u8853\u7a31\u70ba\u601d\u8003\u93c8 (CoT) \u63d0\u793a\u3002\u7136\u800c\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u767c\u73fe\uff0cICL \u4e3b\u8981\u4f9d\u8cf4\u4efb\u52d9\u5148\u9a57\u7684\u6aa2\u7d22\uff0c\u8f03\u5c11\u4f9d\u8cf4\u300c\u5b78\u7fd2\u300d\u4f86\u57f7\u884c\u4efb\u52d9\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u60c5\u7dd2\u548c\u9053\u5fb7\u7b49\u8907\u96dc\u7684\u4e3b\u89c0\u9818\u57df\uff0c\u5176\u4e2d\u5148\u9a57\u6703\u50f5\u5316\u5f8c\u9a57\u9810\u6e2c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u300c\u555f\u7528\u300d\u63a8\u7406\u662f\u5426\u4e5f\u6703\u5728 LLM \u4e2d\u7522\u751f\u76f8\u540c\u7684\u884c\u70ba\uff0c\u5176\u4e2d CoT \u7684\u683c\u5f0f\u6703\u6aa2\u7d22\u63a8\u7406\u5148\u9a57\uff0c\u5118\u7ba1\u63d0\u793a\u4e2d\u7684\u8b49\u64da\u4e0d\u540c\uff0c\u4f46\u9019\u4e9b\u5148\u9a57\u4ecd\u7136\u76f8\u5c0d\u4e0d\u8b8a\u3002\u6211\u5011\u767c\u73fe\uff0c\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0c\u5c0d\u65bc\u8f03\u5927\u7684\u8a9e\u8a00\u6a21\u578b\uff0cCoT \u78ba\u5be6\u8207 ICL \u906d\u53d7\u76f8\u540c\u7684\u5f8c\u9a57\u5d29\u6f70\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/gchochla/cot-priors \u53d6\u5f97\u3002", "author": "Georgios Chochlakis et.al.", "authors": "Georgios Chochlakis, Niyantha Maruthu Pandiyan, Kristina Lerman, Shrikanth Narayanan", "id": "2409.06173v2", "paper_url": "http://arxiv.org/abs/2409.06173v2", "repo": "https://github.com/gchochla/cot-priors"}}