{"2409.11786": {"publish_time": "2024-09-18", "title": "Efficient Low-Resolution Face Recognition via Bridge Distillation", "paper_summary": "Face recognition in the wild is now advancing towards light-weight models,\nfast inference speed and resolution-adapted capability. In this paper, we\npropose a bridge distillation approach to turn a complex face model pretrained\non private high-resolution faces into a light-weight one for low-resolution\nface recognition. In our approach, such a cross-dataset resolution-adapted\nknowledge transfer problem is solved via two-step distillation. In the first\nstep, we conduct cross-dataset distillation to transfer the prior knowledge\nfrom private high-resolution faces to public high-resolution faces and generate\ncompact and discriminative features. In the second step, the resolution-adapted\ndistillation is conducted to further transfer the prior knowledge to synthetic\nlow-resolution faces via multi-task learning. By learning low-resolution face\nrepresentations and mimicking the adapted high-resolution knowledge, a\nlight-weight student model can be constructed with high efficiency and\npromising accuracy in recognizing low-resolution faces. Experimental results\nshow that the student model performs impressively in recognizing low-resolution\nfaces with only 0.21M parameters and 0.057MB memory. Meanwhile, its speed\nreaches up to 14,705, ~934 and 763 faces per second on GPU, CPU and mobile\nphone, respectively.", "paper_summary_zh": "\u4eba\u81c9\u8fa8\u8b58\u73fe\u5728\u671d\u5411\u8f15\u91cf\u7d1a\u6a21\u578b\u3001\u5feb\u901f\u7684\u63a8\u8ad6\u901f\u5ea6\u548c\u9069\u61c9\u89e3\u6790\u5ea6\u7684\u80fd\u529b\u9081\u9032\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u6a4b\u6a11\u84b8\u993e\u65b9\u6cd5\uff0c\u5c07\u4e00\u500b\u8907\u96dc\u7684\u4eba\u81c9\u6a21\u578b\u9810\u5148\u8a13\u7df4\u5728\u79c1\u4eba\u9ad8\u89e3\u6790\u5ea6\u4eba\u81c9\u4e0a\uff0c\u8f49\u63db\u6210\u4e00\u500b\u4f4e\u89e3\u6790\u5ea6\u4eba\u81c9\u8fa8\u8b58\u7684\u8f15\u91cf\u7d1a\u6a21\u578b\u3002\u5728\u6211\u5011\u7684\u505a\u6cd5\u4e2d\uff0c\u9019\u7a2e\u8de8\u8cc7\u6599\u96c6\u9069\u61c9\u89e3\u6790\u5ea6\u7684\u77e5\u8b58\u8f49\u79fb\u554f\u984c\u900f\u904e\u5169\u968e\u6bb5\u84b8\u993e\u4f86\u89e3\u6c7a\u3002\u5728\u7b2c\u4e00\u968e\u6bb5\uff0c\u6211\u5011\u9032\u884c\u8de8\u8cc7\u6599\u96c6\u84b8\u993e\uff0c\u5c07\u5148\u9a57\u77e5\u8b58\u5f9e\u79c1\u4eba\u9ad8\u89e3\u6790\u5ea6\u4eba\u81c9\u8f49\u79fb\u5230\u516c\u958b\u9ad8\u89e3\u6790\u5ea6\u4eba\u81c9\uff0c\u4e26\u7522\u751f\u7dca\u6e4a\u4e14\u5177\u5340\u5225\u6027\u7684\u7279\u5fb5\u3002\u5728\u7b2c\u4e8c\u968e\u6bb5\uff0c\u9032\u884c\u9069\u61c9\u89e3\u6790\u5ea6\u7684\u84b8\u993e\uff0c\u4ee5\u900f\u904e\u591a\u4efb\u52d9\u5b78\u7fd2\u9032\u4e00\u6b65\u5c07\u5148\u9a57\u77e5\u8b58\u8f49\u79fb\u5230\u5408\u6210\u4f4e\u89e3\u6790\u5ea6\u4eba\u81c9\u3002\u900f\u904e\u5b78\u7fd2\u4f4e\u89e3\u6790\u5ea6\u4eba\u81c9\u8868\u793a\u548c\u6a21\u64ec\u9069\u61c9\u7684\u9ad8\u89e3\u6790\u5ea6\u77e5\u8b58\uff0c\u53ef\u4ee5\u5efa\u69cb\u4e00\u500b\u8f15\u91cf\u7d1a\u7684\u5b78\u751f\u6a21\u578b\uff0c\u5728\u8fa8\u8b58\u4f4e\u89e3\u6790\u5ea6\u4eba\u81c9\u6642\u5177\u6709\u9ad8\u6548\u7387\u548c\u826f\u597d\u7684\u6e96\u78ba\u5ea6\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u5b78\u751f\u6a21\u578b\u5728\u8fa8\u8b58\u4f4e\u89e3\u6790\u5ea6\u4eba\u81c9\u6642\u8868\u73fe\u51fa\u8272\uff0c\u53ea\u6709 0.21M \u53c3\u6578\u548c 0.057MB \u8a18\u61b6\u9ad4\u3002\u540c\u6642\uff0c\u5b83\u7684\u901f\u5ea6\u5206\u5225\u5728 GPU\u3001CPU \u548c\u624b\u6a5f\u4e0a\u9054\u5230\u6bcf\u79d2 14,705\u3001~934 \u548c 763 \u5f35\u4eba\u81c9\u3002", "author": "Shiming Ge et.al.", "authors": "Shiming Ge, Shengwei Zhao, Chenyu Li, Yu Zhang, Jia Li", "id": "2409.11786v1", "paper_url": "http://arxiv.org/abs/2409.11786v1", "repo": "null"}}