{"2405.20962": {"publish_time": "2024-05-31", "title": "Large Language Models are Zero-Shot Next Location Predictors", "paper_summary": "Predicting the locations an individual will visit in the future is crucial\nfor solving many societal issues like disease diffusion and reduction of\npollution among many others. The models designed to tackle next-location\nprediction, however, require a significant amount of individual-level\ninformation to be trained effectively. Such data may be scarce or even\nunavailable in some geographic regions or peculiar scenarios (e.g., cold-start\nin recommendation systems). Moreover, the design of a next-location predictor\nable to generalize or geographically transfer knowledge is still an open\nresearch challenge. Recent advances in natural language processing have led to\na rapid diffusion of Large Language Models (LLMs) which have shown good\ngeneralization and reasoning capabilities. These insights, coupled with the\nrecent findings that LLMs are rich in geographical knowledge, allowed us to\nbelieve that these models can act as zero-shot next-location predictors. This\npaper evaluates the capabilities of many popular LLMs in this role,\nspecifically Llama, GPT-3.5 and Mistral 7B. After designing a proper prompt, we\ntested the models on three real-world mobility datasets. The results show that\nLLMs can obtain accuracies up to 32.4%, a significant relative improvement of\nover 600% when compared to sophisticated DL models specifically designed for\nhuman mobility. Moreover, we show that other LLMs are unable to perform the\ntask properly. To prevent positively biased results, we also propose a\nframework inspired by other studies to test data contamination. Finally, we\nexplored the possibility of using LLMs as text-based explainers for\nnext-location prediction showing that can effectively provide an explanation\nfor their decision. Notably, 7B models provide more generic, but still\nreliable, explanations compared to larger counterparts. Code:\ngithub.com/ssai-trento/LLM-zero-shot-NL", "paper_summary_zh": "<paragraph>\u9810\u6e2c\u500b\u4eba\u672a\u4f86\u6703\u9020\u8a2a\u7684\u5730\u9ede\u5c0d\u65bc\u89e3\u6c7a\u8a31\u591a\u793e\u6703\u554f\u984c\u81f3\u95dc\u91cd\u8981\uff0c\u4f8b\u5982\u75be\u75c5\u64f4\u6563\u548c\u6e1b\u5c11\u6c61\u67d3\u7b49\u3002\u4e0d\u904e\uff0c\u7528\u4f86\u8655\u7406\u4e0b\u500b\u5730\u9ede\u9810\u6e2c\u7684\u6a21\u578b\u9700\u8981\u5927\u91cf\u7684\u500b\u4eba\u5c64\u7d1a\u8cc7\u8a0a\u624d\u80fd\u6709\u6548\u8a13\u7df4\u3002\u6b64\u985e\u8cc7\u6599\u5728\u67d0\u4e9b\u5730\u7406\u5340\u57df\u6216\u7279\u6b8a\u60c5\u6cc1\u4e2d\u53ef\u80fd\u7a00\u5c11\u751a\u81f3\u7121\u6cd5\u53d6\u5f97\uff08\u4f8b\u5982\u63a8\u85a6\u7cfb\u7d71\u4e2d\u7684\u51b7\u555f\u52d5\uff09\u3002\u6b64\u5916\uff0c\u8a2d\u8a08\u4e00\u500b\u80fd\u5920\u6982\u5316\u6216\u5728\u5730\u7406\u4e0a\u50b3\u905e\u77e5\u8b58\u7684\u4e0b\u500b\u5730\u9ede\u9810\u6e2c\u5668\u4ecd\u7136\u662f\u4e00\u9805\u958b\u653e\u7684\u7814\u7a76\u6311\u6230\u3002\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u7684\u6700\u65b0\u9032\u5c55\u5df2\u5c0e\u81f4\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5feb\u901f\u64f4\u6563\uff0c\u9019\u4e9b\u6a21\u578b\u5df2\u5c55\u73fe\u826f\u597d\u7684\u6982\u5316\u548c\u63a8\u7406\u80fd\u529b\u3002\u9019\u4e9b\u898b\u89e3\u52a0\u4e0a LLM \u5bcc\u542b\u5730\u7406\u77e5\u8b58\u7684\u6700\u65b0\u767c\u73fe\uff0c\u8b93\u6211\u5011\u76f8\u4fe1\u9019\u4e9b\u6a21\u578b\u53ef\u4ee5\u4f5c\u70ba\u96f6\u6b21\u5b78\u7fd2\u7684\u4e0b\u500b\u5730\u9ede\u9810\u6e2c\u5668\u3002\u672c\u6587\u8a55\u4f30\u8a31\u591a\u71b1\u9580 LLM \u5728\u6b64\u89d2\u8272\u4e2d\u7684\u80fd\u529b\uff0c\u7279\u5225\u662f Llama\u3001GPT-3.5 \u548c Mistral 7B\u3002\u5728\u8a2d\u8a08\u9069\u7576\u7684\u63d0\u793a\u5f8c\uff0c\u6211\u5011\u5728\u4e09\u500b\u771f\u5be6\u4e16\u754c\u6d41\u52d5\u6027\u8cc7\u6599\u96c6\u4e0a\u6e2c\u8a66\u9019\u4e9b\u6a21\u578b\u3002\u7d50\u679c\u986f\u793a LLM \u53ef\u4ee5\u7372\u5f97\u9ad8\u9054 32.4% \u7684\u6e96\u78ba\u5ea6\uff0c\u8207\u5c08\u9580\u70ba\u4eba\u985e\u6d41\u52d5\u6027\u8a2d\u8a08\u7684\u7cbe\u5bc6 DL \u6a21\u578b\u76f8\u6bd4\uff0c\u76f8\u5c0d\u6539\u5584\u5e45\u5ea6\u8d85\u904e 600%\u3002\u6b64\u5916\uff0c\u6211\u5011\u986f\u793a\u5176\u4ed6 LLM \u7121\u6cd5\u9069\u7576\u57f7\u884c\u4efb\u52d9\u3002\u70ba\u9632\u6b62\u6b63\u5411\u504f\u5dee\u7684\u7d50\u679c\uff0c\u6211\u5011\u4e5f\u63d0\u51fa\u4e00\u500b\u53d7\u5176\u4ed6\u7814\u7a76\u555f\u767c\u7684\u67b6\u69cb\u4f86\u6e2c\u8a66\u8cc7\u6599\u6c61\u67d3\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63a2\u7d22\u4f7f\u7528 LLM \u4f5c\u70ba\u4e0b\u500b\u5730\u9ede\u9810\u6e2c\u7684\u57fa\u65bc\u6587\u5b57\u7684\u8aaa\u660e\u5de5\u5177\u7684\u53ef\u80fd\u6027\uff0c\u986f\u793a\u53ef\u4ee5\u6709\u6548\u63d0\u4f9b\u5176\u6c7a\u7b56\u7684\u8aaa\u660e\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8207\u8f03\u5927\u7684\u5c0d\u61c9\u6a21\u578b\u76f8\u6bd4\uff0c7B \u6a21\u578b\u63d0\u4f9b\u7684\u8aaa\u660e\u66f4\u901a\u7528\uff0c\u4f46\u4ecd\u7136\u53ef\u9760\u3002\u7a0b\u5f0f\u78bc\uff1agithub.com/ssai-trento/LLM-zero-shot-NL</paragraph>", "author": "Ciro Beneduce et.al.", "authors": "Ciro Beneduce, Bruno Lepri, Massimiliano Luca", "id": "2405.20962v2", "paper_url": "http://arxiv.org/abs/2405.20962v2", "repo": "https://github.com/ssai-trento/llm-zero-shot-nl"}}