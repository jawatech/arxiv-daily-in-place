{"2405.20701": {"publish_time": "2024-05-31", "title": "Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement", "paper_summary": "Large language models (LLMs) demonstrate exceptional instruct-following\nability to complete various downstream tasks. Although this impressive ability\nmakes LLMs flexible task solvers, their performance in solving tasks also\nheavily relies on instructions. In this paper, we reveal that LLMs are\nover-sensitive to lexical variations in task instructions, even when the\nvariations are imperceptible to humans. By providing models with neighborhood\ninstructions, which are closely situated in the latent representation space and\ndiffer by only one semantically similar word, the performance on downstream\ntasks can be vastly different. Following this property, we propose a black-box\nCombinatorial Optimization framework for Prompt Lexical Enhancement (COPLE).\nCOPLE performs iterative lexical optimization according to the feedback from a\nbatch of proxy tasks, using a search strategy related to word influence.\nExperiments show that even widely-used human-crafted prompts for current\nbenchmarks suffer from the lexical sensitivity of models, and COPLE recovers\nthe declined model ability in both instruct-following and solving downstream\ntasks.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u793a\u51fa\u5353\u8d8a\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u4ee5\u5b8c\u6210\u5404\u7a2e\u4e0b\u6e38\u4efb\u52d9\u3002\u5118\u7ba1\u9019\u7a2e\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\u4f7f LLM \u6210\u70ba\u9748\u6d3b\u7684\u4efb\u52d9\u89e3\u6c7a\u5668\uff0c\u4f46\u5b83\u5011\u5728\u89e3\u6c7a\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\u4e5f\u6975\u5ea6\u4f9d\u8cf4\u65bc\u6307\u4ee4\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63ed\u793a\u4e86 LLM \u5c0d\u4efb\u52d9\u6307\u4ee4\u4e2d\u7684\u8a5e\u5f59\u8b8a\u7570\u904e\u5ea6\u654f\u611f\uff0c\u5373\u4f7f\u9019\u4e9b\u8b8a\u7570\u5c0d\u4eba\u985e\u4f86\u8aaa\u662f\u7121\u6cd5\u5bdf\u89ba\u7684\u3002\u901a\u904e\u70ba\u6a21\u578b\u63d0\u4f9b\u9130\u57df\u6307\u4ee4\uff08\u9019\u4e9b\u6307\u4ee4\u5728\u6f5b\u5728\u8868\u793a\u7a7a\u9593\u4e2d\u7dca\u5bc6\u76f8\u9130\uff0c\u4e26\u4e14\u53ea\u6709\u4e00\u500b\u8a9e\u7fa9\u76f8\u4f3c\u7684\u8a5e\u4e0d\u540c\uff09\uff0c\u4e0b\u6e38\u4efb\u52d9\u7684\u8868\u73fe\u53ef\u80fd\u6703\u6709\u5f88\u5927\u4e0d\u540c\u3002\u9075\u5faa\u6b64\u5c6c\u6027\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u7528\u65bc\u63d0\u793a\u8a5e\u5f59\u589e\u5f37 (COPLE) \u7684\u9ed1\u76d2\u7d44\u5408\u512a\u5316\u6846\u67b6\u3002COPLE \u6839\u64da\u4e00\u6279\u4ee3\u7406\u4efb\u52d9\u7684\u56de\u994b\uff0c\u4f7f\u7528\u8207\u8a5e\u5f59\u5f71\u97ff\u76f8\u95dc\u7684\u641c\u5c0b\u7b56\u7565\uff0c\u57f7\u884c\u53cd\u8986\u7684\u8a5e\u5f59\u512a\u5316\u3002\u5be6\u9a57\u8868\u660e\uff0c\u5373\u4f7f\u662f\u7576\u524d\u57fa\u6e96\u5ee3\u6cdb\u4f7f\u7528\u7684\u7531\u4eba\u985e\u88fd\u4f5c\u7684\u63d0\u793a\u4e5f\u6703\u53d7\u5230\u6a21\u578b\u7684\u8a5e\u5f59\u654f\u611f\u6027\u5f71\u97ff\uff0c\u800c COPLE \u5728\u6307\u4ee4\u9075\u5faa\u548c\u89e3\u6c7a\u4e0b\u6e38\u4efb\u52d9\u4e2d\u6062\u5fa9\u4e86\u6a21\u578b\u4e0b\u964d\u7684\u80fd\u529b\u3002", "author": "Pengwei Zhan et.al.", "authors": "Pengwei Zhan, Zhen Xu, Qian Tan, Jie Song, Ru Xie", "id": "2405.20701v1", "paper_url": "http://arxiv.org/abs/2405.20701v1", "repo": "null"}}