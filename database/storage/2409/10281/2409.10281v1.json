{"2409.10281": {"publish_time": "2024-09-16", "title": "DreamHead: Learning Spatial-Temporal Correspondence via Hierarchical Diffusion for Audio-driven Talking Head Synthesis", "paper_summary": "Audio-driven talking head synthesis strives to generate lifelike video\nportraits from provided audio. The diffusion model, recognized for its superior\nquality and robust generalization, has been explored for this task. However,\nestablishing a robust correspondence between temporal audio cues and\ncorresponding spatial facial expressions with diffusion models remains a\nsignificant challenge in talking head generation. To bridge this gap, we\npresent DreamHead, a hierarchical diffusion framework that learns\nspatial-temporal correspondences in talking head synthesis without compromising\nthe model's intrinsic quality and adaptability.~DreamHead learns to predict\ndense facial landmarks from audios as intermediate signals to model the spatial\nand temporal correspondences.~Specifically, a first hierarchy of\naudio-to-landmark diffusion is first designed to predict temporally smooth and\naccurate landmark sequences given audio sequence signals. Then, a second\nhierarchy of landmark-to-image diffusion is further proposed to produce\nspatially consistent facial portrait videos, by modeling spatial\ncorrespondences between the dense facial landmark and appearance. Extensive\nexperiments show that proposed DreamHead can effectively learn spatial-temporal\nconsistency with the designed hierarchical diffusion and produce high-fidelity\naudio-driven talking head videos for multiple identities.", "paper_summary_zh": "\u97f3\u9891\u9a71\u52a8\u7684\u8bf4\u8bdd\u4eba\u5934\u90e8\u5408\u6210\u529b\u6c42\u6839\u636e\u63d0\u4f9b\u7684\u97f3\u9891\u751f\u6210\u903c\u771f\u7684\u89c6\u9891\n\u4eba\u50cf\u3002\u6269\u6563\u6a21\u578b\u4ee5\u5176\u5353\u8d8a\u7684\u54c1\u8d28\u548c\u7a33\u5065\u7684\u6cdb\u5316\u800c\u8457\u79f0\uff0c\u5df2\u88ab\u63a2\u7d22\u7528\u4e8e\u6b64\u4efb\u52a1\u3002\u7136\u800c\uff0c\n\u5728\u6269\u6563\u6a21\u578b\u4e2d\u5efa\u7acb\u65f6\u95f4\u97f3\u9891\u63d0\u793a\u4e0e\u76f8\u5e94\u7a7a\u95f4\u9762\u90e8\u8868\u60c5\u4e4b\u95f4\u7684\u7a33\u5065\u5bf9\u5e94\u5173\u7cfb\u4ecd\u7136\u662f\n\u8bf4\u8bdd\u4eba\u5934\u90e8\u751f\u6210\u4e2d\u7684\u91cd\u5927\u6311\u6218\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 DreamHead\uff0c\u8fd9\u662f\u4e00\u4e2a\u5206\u5c42\u6269\u6563\u6846\u67b6\uff0c\u5b83\u5b66\u4e60\n\u8bf4\u8bdd\u4eba\u5934\u90e8\u5408\u6210\u4e2d\u7684\u65f6\u7a7a\u5bf9\u5e94\u5173\u7cfb\uff0c\u540c\u65f6\u4e0d\u635f\u5bb3\u6a21\u578b\u7684\u5185\u5728\u54c1\u8d28\u548c\u9002\u5e94\u6027\u3002~DreamHead \u5b66\u4e60\u4ece\u97f3\u9891\u4e2d\u9884\u6d4b\u5bc6\u96c6\u7684\u9762\u90e8\u5730\u6807\u4f5c\u4e3a\u4e2d\u95f4\u4fe1\u53f7\uff0c\u4ee5\u6a21\u62df\u7a7a\u95f4\n\u548c\u65f6\u95f4\u5bf9\u5e94\u5173\u7cfb\u3002~\u5177\u4f53\u6765\u8bf4\uff0c\u9996\u5148\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u97f3\u9891\u5230\u5730\u6807\u6269\u6563\u7684\u7b2c\u4e00\u5c42\u7ea7\uff0c\u4ee5\u9884\u6d4b\u7ed9\u5b9a\u97f3\u9891\u5e8f\u5217\u4fe1\u53f7\u7684\u65f6\u95f4\u5e73\u6ed1\u4e14\u51c6\u786e\u7684\u5730\u6807\u5e8f\u5217\u3002\u7136\u540e\uff0c\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u5730\u6807\u5230\u56fe\u50cf\u6269\u6563\u7684\u7b2c\u4e8c\u5c42\u7ea7\uff0c\u4ee5\u901a\u8fc7\u5efa\u6a21\u5bc6\u96c6\u7684\u9762\u90e8\u5730\u6807\u548c\u5916\u89c2\u4e4b\u95f4\u7684\u7a7a\u95f4\u5bf9\u5e94\u5173\u7cfb\u6765\u751f\u6210\u7a7a\u95f4\u4e00\u81f4\u7684\u9762\u90e8\u8096\u50cf\u89c6\u9891\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684 DreamHead \u53ef\u4ee5\u901a\u8fc7\u8bbe\u8ba1\u7684\u5206\u5c42\u6269\u6563\u6709\u6548\u5730\u5b66\u4e60\u65f6\u7a7a\n\u4e00\u81f4\u6027\uff0c\u5e76\u4e3a\u591a\u4e2a\u8eab\u4efd\u751f\u6210\u9ad8\u4fdd\u771f\u97f3\u9891\u9a71\u52a8\u7684\u8bf4\u8bdd\u4eba\u5934\u90e8\u89c6\u9891\u3002", "author": "Fa-Ting Hong et.al.", "authors": "Fa-Ting Hong, Yunfei Liu, Yu Li, Changyin Zhou, Fei Yu, Dan Xu", "id": "2409.10281v1", "paper_url": "http://arxiv.org/abs/2409.10281v1", "repo": "null"}}