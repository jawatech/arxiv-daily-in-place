
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-30**|**Action-Agnostic Point-Level Supervision for Temporal Action Detection**|Shuhei M. Yoshida et.al.|[2412.21205v1](http://arxiv.org/abs/2412.21205v1)|null|
|**2024-12-30**|**Distributed Mixture-of-Agents for Edge Inference with Large Language Models**|Purbesh Mitra et.al.|[2412.21200v1](http://arxiv.org/abs/2412.21200v1)|[link](https://github.com/purbeshmitra/distributed_moa)|
|**2024-12-30**|**HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation**|Zhaojian Yu et.al.|[2412.21199v1](http://arxiv.org/abs/2412.21199v1)|null|
|**2024-12-30**|**Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs**|Xingyu Chen et.al.|[2412.21187v1](http://arxiv.org/abs/2412.21187v1)|null|
|**2024-12-30**|**Two-component spatiotemporal template for activation-inhibition of speech in ECoG**|Eric Easthope et.al.|[2412.21178v1](http://arxiv.org/abs/2412.21178v1)|null|
|**2024-12-30**|**Open RAN-Enabled Deep Learning-Assisted Mobility Management for Connected Vehicles**|Maria Barbosa et.al.|[2412.21161v1](http://arxiv.org/abs/2412.21161v1)|null|
|**2024-12-30**|**Aviary: training language agents on challenging scientific tasks**|Siddharth Narayanan et.al.|[2412.21154v1](http://arxiv.org/abs/2412.21154v1)|null|
|**2024-12-30**|**PyG-SSL: A Graph Self-Supervised Learning Toolkit**|Lecheng Zheng et.al.|[2412.21151v1](http://arxiv.org/abs/2412.21151v1)|[link](https://github.com/idea-isail-lab-uiuc/pyg-ssl)|
|**2024-12-30**|**Facilitating large language model Russian adaptation with Learned Embedding Propagation**|Mikhail Tikhomirov et.al.|[2412.21140v1](http://arxiv.org/abs/2412.21140v1)|null|
|**2024-12-30**|**Training Software Engineering Agents and Verifiers with SWE-Gym**|Jiayi Pan et.al.|[2412.21139v1](http://arxiv.org/abs/2412.21139v1)|[link](https://github.com/swe-gym/swe-gym)|
|**2024-12-30**|**Exploring and Controlling Diversity in LLM-Agent Conversation**|KuanChao Chu et.al.|[2412.21102v1](http://arxiv.org/abs/2412.21102v1)|null|
|**2024-12-30**|**Efficient Multi-Task Inferencing with a Shared Backbone and Lightweight Task-Specific Adapters for Automatic Scoring**|Ehsan Latif et.al.|[2412.21065v1](http://arxiv.org/abs/2412.21065v1)|null|
|**2024-12-30**|**Towards Effective Discrimination Testing for Generative AI**|Thomas P. Zollo et.al.|[2412.21052v1](http://arxiv.org/abs/2412.21052v1)|null|
|**2024-12-30**|**Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense**|Yuyang Zhou et.al.|[2412.21051v1](http://arxiv.org/abs/2412.21051v1)|[link](https://github.com/SEU-ProactiveSecurity-Group/LLM-PD)|
|**2024-12-30**|**TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization**|Chia-Yu Hung et.al.|[2412.21037v1](http://arxiv.org/abs/2412.21037v1)|[link](https://github.com/declare-lab/TangoFlux)|
|**2024-12-30**|**GePBench: Evaluating Fundamental Geometric Perception for Multimodal Large Language Models**|Shangyu Xing et.al.|[2412.21036v1](http://arxiv.org/abs/2412.21036v1)|null|
|**2024-12-30**|**Plancraft: an evaluation dataset for planning with LLM agents**|Gautier Dagan et.al.|[2412.21033v1](http://arxiv.org/abs/2412.21033v1)|[link](https://github.com/gautierdag/plancraft)|
|**2024-12-30**|**MapQaTor: A System for Efficient Annotation of Map Query Datasets**|Mahir Labib Dihan et.al.|[2412.21015v1](http://arxiv.org/abs/2412.21015v1)|[link](https://github.com/MapQaTor/.github/tree/main/profile)|
|**2024-12-30**|**Verbosity-Aware Rationale Reduction: Effective Reduction of Redundant Rationale via Principled Criteria**|Joonwon Jang et.al.|[2412.21006v1](http://arxiv.org/abs/2412.21006v1)|null|
|**2024-12-30**|**LEASE: Offline Preference-based Reinforcement Learning with High Sample Efficiency**|Xiao-Yin Liu et.al.|[2412.21001v1](http://arxiv.org/abs/2412.21001v1)|null|
|**2024-12-30**|**Plug-and-Play Training Framework for Preference Optimization**|Jingyuan Ma et.al.|[2412.20996v1](http://arxiv.org/abs/2412.20996v1)|null|
|**2024-12-30**|**KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**|Siyuan Fang et.al.|[2412.20995v1](http://arxiv.org/abs/2412.20995v1)|null|
|**2024-12-30**|**Efficiently Serving LLM Reasoning Programs with Certaindex**|Yichao Fu et.al.|[2412.20993v1](http://arxiv.org/abs/2412.20993v1)|null|
|**2024-12-30**|**UnrealZoo: Enriching Photo-realistic Virtual Worlds for Embodied AI**|Fangwei Zhong et.al.|[2412.20977v1](http://arxiv.org/abs/2412.20977v1)|null|
|**2024-12-30**|**Conservation-informed Graph Learning for Spatiotemporal Dynamics Prediction**|Yuan Mi et.al.|[2412.20962v1](http://arxiv.org/abs/2412.20962v1)|null|
|**2024-12-30**|**Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**|Xiaohan Feng et.al.|[2412.20942v1](http://arxiv.org/abs/2412.20942v1)|null|
|**2024-12-30**|**HisynSeg: Weakly-Supervised Histopathological Image Segmentation via Image-Mixing Synthesis and Consistency Regularization**|Zijie Fang et.al.|[2412.20924v1](http://arxiv.org/abs/2412.20924v1)|null|
|**2024-12-30**|**WalkVLM:Aid Visually Impaired People Walking by Vision Language Model**|Zhiqiang Yuan et.al.|[2412.20903v1](http://arxiv.org/abs/2412.20903v1)|null|
|**2024-12-30**|**ILDiff: Generate Transparent Animated Stickers by Implicit Layout Distillation**|Ting Zhang et.al.|[2412.20901v1](http://arxiv.org/abs/2412.20901v1)|null|
|**2024-12-30**|**DoTA: Weight-Decomposed Tensor Adaptation for Large Language Models**|Xiaolin Hu et.al.|[2412.20891v1](http://arxiv.org/abs/2412.20891v1)|null|
|**2024-12-30**|**Holistic Construction Automation with Modular Robots: From High-Level Task Specification to Execution**|Jonathan Külz et.al.|[2412.20867v1](http://arxiv.org/abs/2412.20867v1)|null|
|**2024-12-30**|**Enhancing Annotated Bibliography Generation with LLM Ensembles**|Sergio Bermejo et.al.|[2412.20864v1](http://arxiv.org/abs/2412.20864v1)|null|
|**2024-12-30**|**Are LLMs Really Not Knowledgable? Mining the Submerged Knowledge in LLMs' Memory**|Xingjian Tao et.al.|[2412.20846v1](http://arxiv.org/abs/2412.20846v1)|null|
|**2024-12-30**|**Dual-Space Augmented Intrinsic-LoRA for Wind Turbine Segmentation**|Shubh Singhal et.al.|[2412.20838v1](http://arxiv.org/abs/2412.20838v1)|null|
|**2024-12-30**|**Disentangling Preference Representation and Text Generation for Efficient Individual Preference Alignment**|Jianfei Zhang et.al.|[2412.20834v1](http://arxiv.org/abs/2412.20834v1)|null|
|**2024-12-30**|**Fine-Tuning TransMorph with Gradient Correlation for Anatomical Alignment**|Lukas Förner et.al.|[2412.20822v1](http://arxiv.org/abs/2412.20822v1)|null|
|**2024-12-30**|**Enhancing Multimodal Emotion Recognition through Multi-Granularity Cross-Modal Alignment**|Xuechen Wang et.al.|[2412.20821v1](http://arxiv.org/abs/2412.20821v1)|null|
|**2024-12-30**|**Length-Aware DETR for Robust Moment Retrieval**|Seojeong Park et.al.|[2412.20816v1](http://arxiv.org/abs/2412.20816v1)|null|
|**2024-12-30**|**A Tale of Two Imperatives: Privacy and Explainability**|Supriya Manna et.al.|[2412.20798v1](http://arxiv.org/abs/2412.20798v1)|[link](https://github.com/humblef-oo-l/DP)|
|**2024-12-30**|**Frequency-Masked Embedding Inference: A Non-Contrastive Approach for Time Series Representation Learning**|En Fu et.al.|[2412.20790v1](http://arxiv.org/abs/2412.20790v1)|[link](https://github.com/USTBInnovationPark/Frequency-masked-Embedding-Inference)|
|**2024-12-30**|**SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity**|Pengfei Jing et.al.|[2412.20787v1](http://arxiv.org/abs/2412.20787v1)|null|
|**2024-12-30**|**Sample Correlation for Fingerprinting Deep Face Recognition**|Jiyang Guan et.al.|[2412.20768v1](http://arxiv.org/abs/2412.20768v1)|[link](https://github.com/guanjiyang/sac_jc)|
|**2024-12-30**|**KeyGS: A Keyframe-Centric Gaussian Splatting Method for Monocular Image Sequences**|Keng-Wei Chang et.al.|[2412.20767v1](http://arxiv.org/abs/2412.20767v1)|null|
|**2024-12-30**|**Attributing Culture-Conditioned Generations to Pretraining Corpora**|Huihan Li et.al.|[2412.20760v1](http://arxiv.org/abs/2412.20760v1)|null|
|**2024-12-30**|**Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks**|Abhinav Roy et.al.|[2412.20744v1](http://arxiv.org/abs/2412.20744v1)|null|
|**2024-12-30**|**Depression and Anxiety Prediction Using Deep Language Models and Transfer Learning**|Tomasz Rutowski et.al.|[2412.20741v1](http://arxiv.org/abs/2412.20741v1)|null|
|**2024-12-30**|**HUNYUANPROVER: A Scalable Data Synthesis Framework and Guided Tree Search for Automated Theorem Proving**|Yang Li et.al.|[2412.20735v1](http://arxiv.org/abs/2412.20735v1)|null|
|**2024-12-30**|**M$^3$oralBench: A MultiModal Moral Benchmark for LVLMs**|Bei Yan et.al.|[2412.20718v1](http://arxiv.org/abs/2412.20718v1)|null|
|**2024-12-30**|**ChartAdapter: Large Vision-Language Model for Chart Summarization**|Peixin Xu et.al.|[2412.20715v1](http://arxiv.org/abs/2412.20715v1)|null|
|**2024-12-30**|**UBER: Uncertainty-Based Evolution with Large Language Models for Automatic Heuristic Design**|Zijie Chen et.al.|[2412.20694v1](http://arxiv.org/abs/2412.20694v1)|null|
|**2024-12-30**|**Align Attention Heads Before Merging Them: An Effective Way for Converting MHA to GQA**|Qingyun Jin et.al.|[2412.20677v1](http://arxiv.org/abs/2412.20677v1)|null|
|**2024-12-30**|**Enhancing Table Recognition with Vision LLMs: A Benchmark and Neighbor-Guided Toolchain Reasoner**|Yitong Zhou et.al.|[2412.20662v1](http://arxiv.org/abs/2412.20662v1)|null|
|**2024-12-30**|**Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis**|Yousef Yeganeh et.al.|[2412.20651v1](http://arxiv.org/abs/2412.20651v1)|null|
|**2024-12-30**|**Knowledge Editing for Large Language Model with Knowledge Neuronal Ensemble**|Yongchang Li et.al.|[2412.20637v1](http://arxiv.org/abs/2412.20637v1)|null|
|**2024-12-30**|**NetFlowGen: Leveraging Generative Pre-training for Network Traffic Dynamics**|Jiawei Zhou et.al.|[2412.20635v1](http://arxiv.org/abs/2412.20635v1)|null|
|**2024-12-29**|**HALLUCINOGEN: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models**|Ashish Seth et.al.|[2412.20622v1](http://arxiv.org/abs/2412.20622v1)|null|
|**2024-12-29**|**NLP-based Regulatory Compliance -- Using GPT 4.0 to Decode Regulatory Documents**|Bimal Kumar et.al.|[2412.20602v1](http://arxiv.org/abs/2412.20602v1)|null|
|**2024-12-29**|**MATEY: multiscale adaptive foundation models for spatiotemporal physical systems**|Pei Zhang et.al.|[2412.20601v1](http://arxiv.org/abs/2412.20601v1)|null|
|**2024-12-29**|**GliLem: Leveraging GliNER for Contextualized Lemmatization in Estonian**|Aleksei Dorkin et.al.|[2412.20597v1](http://arxiv.org/abs/2412.20597v1)|null|
|**2024-12-29**|**Controlling Out-of-Domain Gaps in LLMs for Genre Classification and Generated Text Detection**|Dmitri Roussinov et.al.|[2412.20595v1](http://arxiv.org/abs/2412.20595v1)|null|
|**2024-12-29**|**Towards Neural No-Resource Language Translation: A Comparative Evaluation of Approaches**|Madhavendra Thakur et.al.|[2412.20584v1](http://arxiv.org/abs/2412.20584v1)|null|
|**2024-12-29**|**A Survey on Time-Series Distance Measures**|John Paparrizos et.al.|[2412.20574v1](http://arxiv.org/abs/2412.20574v1)|null|
|**2024-12-29**|**The intrinsic motivation of reinforcement and imitation learning for sequential tasks**|Sao Mai Nguyen et.al.|[2412.20573v1](http://arxiv.org/abs/2412.20573v1)|null|
|**2024-12-29**|**Segmentation of Muscularis Propria in Colon Histopathology Images Using Vision Transformers for Hirschsprung's Disease**|Youssef Megahed et.al.|[2412.20571v1](http://arxiv.org/abs/2412.20571v1)|null|
|**2024-12-29**|**Enhancing autonomous vehicle safety in rain: a data-centric approach for clear vision**|Mark A. Seferian et.al.|[2412.20565v1](http://arxiv.org/abs/2412.20565v1)|null|
|**2024-12-29**|**Counterfactual Samples Constructing and Training for Commonsense Statements Estimation**|Chong Liu et.al.|[2412.20563v1](http://arxiv.org/abs/2412.20563v1)|null|
|**2024-12-29**|**The Impact of Prompt Programming on Function-Level Code Generation**|Ranim Khojah et.al.|[2412.20545v1](http://arxiv.org/abs/2412.20545v1)|[link](https://github.com/icetlab/codeprompteval)|
|**2024-12-29**|**SAFE-MEME: Structured Reasoning Framework for Robust Hate Speech Detection in Memes**|Palash Nandi et.al.|[2412.20541v1](http://arxiv.org/abs/2412.20541v1)|null|
|**2024-12-29**|**Goal-Conditioned Data Augmentation for Offline Reinforcement Learning**|Xingshuai Huang et.al.|[2412.20519v1](http://arxiv.org/abs/2412.20519v1)|null|
|**2024-12-29**|**Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning**|Hang Ni et.al.|[2412.20505v1](http://arxiv.org/abs/2412.20505v1)|null|
|**2024-12-29**|**ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video Understanding**|Xiao Wang et.al.|[2412.20504v1](http://arxiv.org/abs/2412.20504v1)|[link](https://github.com/sczwangxiao/video-retake)|
|**2024-12-29**|**A Multiparty Homomorphic Encryption Approach to Confidential Federated Kaplan Meier Survival Analysis**|Narasimha Raghavan Veeraragavan et.al.|[2412.20495v1](http://arxiv.org/abs/2412.20495v1)|null|
|**2024-12-29**|**Cut the Deadwood Out: Post-Training Model Purification with Selective Module Substitution**|Yao Tong et.al.|[2412.20476v1](http://arxiv.org/abs/2412.20476v1)|null|
|**2024-12-29**|**A Comprehensive Framework for Reliable Legal AI: Combining Specialized Expert Systems and Adaptive Refinement**|Sidra Nasir et.al.|[2412.20468v1](http://arxiv.org/abs/2412.20468v1)|null|
|**2024-12-29**|**Utilizing Multimodal Data for Edge Case Robust Call-sign Recognition and Understanding**|Alexander Blatt et.al.|[2412.20467v1](http://arxiv.org/abs/2412.20467v1)|null|
|**2024-12-29**|**Enhancing Entertainment Translation for Indian Languages using Adaptive Context, Style and LLMs**|Pratik Rakesh Singh et.al.|[2412.20440v1](http://arxiv.org/abs/2412.20440v1)|null|
|**2024-12-29**|**Integrating Natural Language Processing Techniques of Text Mining Into Financial System: Applications and Limitations**|Denisa Millo et.al.|[2412.20438v1](http://arxiv.org/abs/2412.20438v1)|null|
|**2024-12-29**|**Comparative Performance of Advanced NLP Models and LLMs in Multilingual Geo-Entity Detection**|Kalin Kopanov et.al.|[2412.20414v1](http://arxiv.org/abs/2412.20414v1)|null|
|**2024-12-29**|**Multi-Objective Large Language Model Unlearning**|Zibin Pan et.al.|[2412.20412v1](http://arxiv.org/abs/2412.20412v1)|null|
|**2024-12-29**|**Natural Language Fine-Tuning**|Jia Liu et.al.|[2412.20382v1](http://arxiv.org/abs/2412.20382v1)|[link](https://github.com/julia-liuj/nlft)|
|**2024-12-29**|**A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data**|Seungyeon Lee et.al.|[2412.20373v1](http://arxiv.org/abs/2412.20373v1)|null|
|**2024-12-29**|**LLM2: Let Large Language Models Harness System 2 Reasoning**|Cheng Yang et.al.|[2412.20372v1](http://arxiv.org/abs/2412.20372v1)|null|
|**2024-12-29**|**Enhancing Code LLMs with Reinforcement Learning in Code Generation**|Junqiao Wang et.al.|[2412.20367v1](http://arxiv.org/abs/2412.20367v1)|null|
|**2024-12-29**|**Safe Multiagent Coordination via Entropic Exploration**|Ayhan Alp Aydeniz et.al.|[2412.20361v1](http://arxiv.org/abs/2412.20361v1)|null|
|**2024-12-29**|**EmoReg: Directional Latent Vector Modeling for Emotional Intensity Regularization in Diffusion-based Voice Conversion**|Ashishkumar Gudmalwar et.al.|[2412.20359v1](http://arxiv.org/abs/2412.20359v1)|null|
|**2024-12-29**|**HindiLLM: Large Language Model for Hindi**|Sanjay Chouhan et.al.|[2412.20357v1](http://arxiv.org/abs/2412.20357v1)|null|
|**2024-12-29**|**Distilling Desired Comments for Enhanced Code Review with Large Language Models**|Yongda Yu et.al.|[2412.20340v1](http://arxiv.org/abs/2412.20340v1)|null|
|**2024-12-29**|**Mind the Data Gap: Bridging LLMs to Enterprise Data Integration**|Moe Kayali et.al.|[2412.20331v1](http://arxiv.org/abs/2412.20331v1)|null|
|**2024-12-29**|**Protein Structure Prediction in the 3D HP Model Using Deep Reinforcement Learning**|Giovanny Espitia et.al.|[2412.20329v1](http://arxiv.org/abs/2412.20329v1)|null|
|**2024-12-29**|**Hypergraph-Based Dynamic Graph Node Classification**|Xiaoxu Ma et.al.|[2412.20321v1](http://arxiv.org/abs/2412.20321v1)|null|
|**2024-12-29**|**Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain**|Shintaro Ozaki et.al.|[2412.20309v1](http://arxiv.org/abs/2412.20309v1)|null|
|**2024-12-28**|**No Preference Left Behind: Group Distributional Preference Optimization**|Binwei Yao et.al.|[2412.20299v1](http://arxiv.org/abs/2412.20299v1)|null|
|**2024-12-28**|**Transformer-Based Contrastive Meta-Learning For Low-Resource Generalizable Activity Recognition**|Junyao Wang et.al.|[2412.20290v1](http://arxiv.org/abs/2412.20290v1)|null|
|**2024-12-28**|**High-fidelity social learning via shared episodic memories enhances collaborative foraging through mnemonic convergence**|Ismael T. Freire et.al.|[2412.20271v1](http://arxiv.org/abs/2412.20271v1)|null|
|**2024-12-28**|**Scoring with Large Language Models: A Study on Measuring Empathy of Responses in Dialogues**|Henry J. Xie et.al.|[2412.20264v1](http://arxiv.org/abs/2412.20264v1)|null|
|**2024-12-28**|**ComparisonQA: Evaluating Factuality Robustness of LLMs Through Knowledge Frequency Control and Uncertainty**|Qing Zong et.al.|[2412.20251v1](http://arxiv.org/abs/2412.20251v1)|null|
|**2024-12-28**|**How To Think About End-To-End Encryption and AI: Training, Processing, Disclosure, and Consent**|Mallory Knodel et.al.|[2412.20231v1](http://arxiv.org/abs/2412.20231v1)|null|
|**2024-12-28**|**Leveraging Large Language Models for Enhancing Autonomous Vehicle Perception**|Athanasios Karagounis et.al.|[2412.20230v1](http://arxiv.org/abs/2412.20230v1)|null|
|**2024-12-28**|**LLM Reasoning Engine: Specialized Training for Enhanced Mathematical Reasoning**|Shuguang Chen et.al.|[2412.20227v1](http://arxiv.org/abs/2412.20227v1)|null|
|**2024-12-28**|**AfriHG: News headline generation for African Languages**|Toyib Ogunremi et.al.|[2412.20223v1](http://arxiv.org/abs/2412.20223v1)|null|

#### Abstracts
##### **Action-Agnostic Point-Level Supervision for Temporal Action Detection**
2412.21205v1 by Shuhei M. Yoshida, Takashi Shibata, Makoto Terao, Takayuki Okatani, Masashi Sugiyama

We propose action-agnostic point-level (AAPL) supervision for temporal action
detection to achieve accurate action instance detection with a lightly
annotated dataset. In the proposed scheme, a small portion of video frames is
sampled in an unsupervised manner and presented to human annotators, who then
label the frames with action categories. Unlike point-level supervision, which
requires annotators to search for every action instance in an untrimmed video,
frames to annotate are selected without human intervention in AAPL supervision.
We also propose a detection model and learning method to effectively utilize
the AAPL labels. Extensive experiments on the variety of datasets (THUMOS '14,
FineAction, GTEA, BEOID, and ActivityNet 1.3) demonstrate that the proposed
approach is competitive with or outperforms prior methods for video-level and
point-level supervision in terms of the trade-off between the annotation cost
and detection performance.

摘要：我們提出動作無關的點級 (AAPL) 監督，以進行時間動作偵測，使用輕度註解資料集來達成精確的動作實例偵測。在建議的方案中，以非監督方式取樣一小部分影片幀，並呈現給人工註解員，然後由他們使用動作類別標記幀。與點級監督不同，後者要求註解員在未修剪的影片中搜尋每個動作實例，在 AAPL 監督中，會在沒有人工介入的情況下選取要註解的幀。我們也提出一個偵測模型和學習方法，以有效利用 AAPL 標籤。在各種資料集 (THUMOS '14、FineAction、GTEA、BEOID 和 ActivityNet 1.3) 上進行的廣泛實驗證明，在註解成本和偵測效能之間的權衡方面，建議的方法具有競爭力或優於先前的影片級和點級監督方法。

##### **Distributed Mixture-of-Agents for Edge Inference with Large Language Models**
2412.21200v1 by Purbesh Mitra, Priyanka Kaswan, Sennur Ulukus

Mixture-of-Agents (MoA) has recently been proposed as a method to enhance
performance of large language models (LLMs), enabling multiple individual LLMs
to work together for collaborative inference. This collaborative approach
results in improved responses to user prompts compared to relying on a single
LLM. In this paper, we consider such an MoA architecture in a distributed
setting, where LLMs operate on individual edge devices, each uniquely
associated with a user and equipped with its own distributed computing power.
These devices exchange information using decentralized gossip algorithms,
allowing different device nodes to talk without the supervision of a
centralized server. In the considered setup, different users have their own LLM
models to address user prompts. Additionally, the devices gossip either their
own user-specific prompts or augmented prompts to generate more refined answers
to certain queries. User prompts are temporarily stored in the device queues
when their corresponding LLMs are busy. Given the memory limitations of edge
devices, it is crucial to ensure that the average queue sizes in the system
remain bounded. In this paper, we address this by theoretically calculating the
queuing stability conditions for the device queues under reasonable
assumptions, which we validate experimentally as well. Further, we demonstrate
through experiments, leveraging open-source LLMs for the implementation of
distributed MoA, that certain MoA configurations produce higher-quality
responses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The
implementation is available at:
https://github.com/purbeshmitra/distributed_moa.

摘要：<paragraph>混合代理 (MoA) 最近被提议作为一种增强大型语言模型 (LLM) 性能的方法，让多个独立的 LLM 能够协作进行推理。这种协作式方法能够改善对用户提示的响应，而无需依赖单个 LLM。在本文中，我们在分布式环境中考虑了这种 MoA 架构，其中 LLM 在各个边缘设备上运行，每个设备都与一个用户唯一关联，并配备了自己的分布式计算能力。这些设备使用分散式八卦算法交换信息，允许不同的设备节点在没有集中式服务器监督的情况下进行通信。在考虑的设置中，不同的用户有自己的 LLM 模型来处理用户提示。此外，设备会八卦它们自己的用户特定提示或增强提示，以生成对某些查询的更精细的答案。当相应的 LLM 繁忙时，用户提示会暂时存储在设备队列中。鉴于边缘设备的内存限制，确保系统中平均队列大小保持有界至关重要。在本文中，我们通过在合理假设下从理论上计算设备队列的排队稳定性条件来解决这个问题，我们也通过实验验证了这一点。此外，我们通过实验演示，利用开源 LLM 来实现分布式 MoA，某些 MoA 配置会产生比其他配置更高质量的响应，如在 AlpacaEval 2.0 基准上评估的那样。该实现可在以下位置获得：
https://github.com/purbeshmitra/distributed_moa。</paragraph>

##### **HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation**
2412.21199v1 by Zhaojian Yu, Yilun Zhao, Arman Cohan, Xiao-Ping Zhang

We introduce self-invoking code generation, a new task designed to evaluate
the progressive reasoning and problem-solving capabilities of LLMs. In this
task, models are presented with a base problem and a related, more complex
problem. They must solve the base problem and then utilize its solution to
address the more complex one. This work features three key contributions.
First, we propose a general recipe for generating more challenging versions of
existing benchmarks, resulting in three new benchmarks: HumanEval Pro, MBPP
Pro, and BigCodeBench-Lite Pro, specifically designed to assess LLMs on
self-invoking code generation. Second, from the analysis of experimental
results over twenty LLMs on our benchmarks, we have two important observations:
(i) Most LLMs excel in traditional code generation benchmarks like HumanEval
and MBPP, but their performance declines on self-invoking tasks. For example,
o1-mini achieves 96.2% pass@1 on HumanEval but only 76.2% on HumanEval Pro.
(ii) On self-invoking code generation task, the instruction-tuned models
demonstrate only marginal improvements compared to the base models. Third, we
disclose the types of failure modes that exist in our evaluation results. All
these results underscore the need for further advancements in self-invoking
code generation tasks and provide a new direction for future research on
enhancing LLMs' code reasoning capabilities.

摘要：<paragraph>我們引入了自調用程式碼生成，這項新任務旨在評估 LLM 的漸進式推理和問題解決能力。在這個任務中，模型會收到一個基本問題和一個相關的更複雜問題。它們必須解決基本問題，然後利用其解決方案來解決更複雜的問題。這項工作有三個關鍵貢獻。首先，我們提出了一個通用方法，用於生成現有基準的更具挑戰性的版本，產生了三個新的基準：HumanEval Pro、MBPP Pro 和 BigCodeBench-Lite Pro，專門設計用於評估 LLM 的自調用程式碼生成。其次，從我們基準上對二十個 LLM 的實驗結果分析中，我們有兩個重要的觀察：(i) 大多數 LLM 在傳統程式碼生成基準（例如 HumanEval 和 MBPP）中表現出色，但它們在自調用任務上的表現卻下降。例如，o1-mini 在 HumanEval 上達到 96.2% 的 pass@1，但在 HumanEval Pro 上只有 76.2%。(ii) 在自調用程式碼生成任務上，與基礎模型相比，經過指令調整的模型只表現出邊際改善。第三，我們公開了我們的評估結果中存在的失敗模式類型。所有這些結果都強調了進一步推進自調用程式碼生成任務的必要性，並為未來加強 LLM 程式碼推理能力的研究提供了新的方向。</paragraph>

##### **Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs**
2412.21187v1 by Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu

The remarkable performance of models like the OpenAI o1 can be attributed to
their ability to emulate human-like long-time thinking during inference. These
models employ extended chain-of-thought (CoT) processes, exploring multiple
strategies to enhance problem-solving capabilities. However, a critical
question remains: How to intelligently and efficiently scale computational
resources during testing. This paper presents the first comprehensive study on
the prevalent issue of overthinking in these models, where excessive
computational resources are allocated for simple problems with minimal benefit.
We introduce novel efficiency metrics from both outcome and process
perspectives to evaluate the rational use of computational resources by o1-like
models. Using a self-training paradigm, we propose strategies to mitigate
overthinking, streamlining reasoning processes without compromising accuracy.
Experimental results show that our approach successfully reduces computational
overhead while preserving model performance across a range of testsets with
varying difficulty levels, such as GSM8K, MATH500, GPQA, and AIME.

摘要：OpenAI o1 等模型的卓越性能可归因于
它们在推理期间模拟人类长期思考的能力。这些
模型采用扩展的思维链 (CoT) 过程，探索多种
策略来增强解决问题的能力。然而，一个关键
问题仍然存在：如何在测试期间智能且高效地扩展计算
资源。本文对这些模型中普遍存在的过度思考问题进行了首次全面研究，其中为具有极小收益的简单问题分配了过多的
计算资源。我们从结果和过程
角度引入新颖的效率指标，以评估 o1 类
模型对计算资源的合理使用。使用自训练范例，我们提出策略来减轻
过度思考，简化推理过程而不影响准确性。
实验结果表明，我们的方法成功地减少了计算
开销，同时在具有不同难度级别的各种测试集中保持了模型性能，例如 GSM8K、MATH500、GPQA 和 AIME。

##### **Two-component spatiotemporal template for activation-inhibition of speech in ECoG**
2412.21178v1 by Eric Easthope

I compute the average trial-by-trial power of band-limited speech activity
across epochs of multi-channel high-density electrocorticography (ECoG)
recorded from multiple subjects during a consonant-vowel speaking task. I show
that previously seen anti-correlations of average beta frequency activity
(12-35 Hz) to high-frequency gamma activity (70-140 Hz) during speech movement
are observable between individual ECoG channels in the sensorimotor cortex
(SMC). With this I fit a variance-based model using principal component
analysis to the band-powers of individual channels of session-averaged ECoG
data in the SMC and project SMC channels onto their lower-dimensional principal
components.
  Spatiotemporal relationships between speech-related activity and principal
components are identified by correlating the principal components of both
frequency bands to individual ECoG channels over time using windowed
correlation. Correlations of principal component areas to sensorimotor areas
reveal a distinct two-component activation-inhibition-like representation for
speech that resembles distinct local sensorimotor areas recently shown to have
complex interplay in whole-body motor control, inhibition, and posture. Notably
the third principal component shows insignificant correlations across all
subjects, suggesting two components of ECoG are sufficient to represent SMC
activity during speech movement.

摘要：我计算了多通道高密度脑皮层电图（ECoG）中各个时期的带限语音活动试验平均功率，该电图是在辅音元音说话任务期间从多个受试者身上记录下来的。我展示了之前观察到的平均β频活动（12-35 Hz）与高频γ活动（70-140 Hz）在言语运动期间的反相关性在感觉运动皮层（SMC）的各个 ECoG 通道之间是可以观察到的。利用此，我使用主成分分析对 SMC 中会话平均 ECoG 数据的各个通道的频带功率拟合了一个基于方差的模型，并将 SMC 通道投影到其低维主成分上。
言语相关活动与主成分之间的时空关系是通过使用窗选相关性将两个频带的主成分与各个 ECoG 通道随时间相关联来识别的。主成分区域与感觉运动区域的相关性揭示了言语的独特两分量激活抑制样表征，该表征类似于最近显示在全身运动控制、抑制和姿势中具有复杂相互作用的不同局部感觉运动区域。值得注意的是，第三主成分在所有受试者中显示出不显着的相关性，这表明 ECoG 的两个成分足以表示言语运动期间的 SMC 活动。

##### **Open RAN-Enabled Deep Learning-Assisted Mobility Management for Connected Vehicles**
2412.21161v1 by Maria Barbosa, Kelvin Dias

Connected Vehicles (CVs) can leverage the unique features of 5G and future
6G/NextG networks to enhance Intelligent Transportation System (ITS) services.
However, even with advancements in cellular network generations, CV
applications may experience communication interruptions in high-mobility
scenarios due to frequent changes of serving base station, also known as
handovers (HOs). This paper proposes the adoption of Open Radio Access Network
(Open RAN/O-RAN) and deep learning models for decision-making to prevent
Quality of Service (QoS) degradation due to HOs and to ensure the timely
connectivity needed for CV services. The solution utilizes the O-RAN Software
Community (OSC), an open-source O-RAN platform developed by the collaboration
between the O-RAN Alliance and Linux Foundation, to develop xApps that are
executed in the near-Real-Time RIC of OSC. To demonstrate the proposal's
effectiveness, an integrated framework combining the OMNeT++ simulator and OSC
was created. Evaluations used real-world datasets in urban application
scenarios, such as video streaming transmission and over-the-air (OTA) updates.
Results indicate that the proposal achieved superior performance and reduced
latency compared to the standard 3GPP HO procedure.

摘要：連網車輛 (CV) 能運用 5G 和未來 6G/NextG 網路的獨特功能來提升智慧運輸系統 (ITS) 服務。不過，即使在行動網路世代進步之下，CV 應用程式仍可能在高度流動的場景中因頻繁變更服務基地台（又稱交接，HO）而經歷通訊中斷。本文提出採用開放式無線存取網路 (Open RAN/O-RAN) 和深度學習模型來做決策，以防止因交接而造成的服務品質 (QoS) 降低，並確保 CV 服務所需的即時連線。此解決方案利用 O-RAN 軟體社群 (OSC)（一個由 O-RAN 聯盟和 Linux 基金會合作開發的開放原始碼 O-RAN 平台）來開發 xApp，並在 OSC 的近即時 RIC 中執行。為了證明此提案的有效性，建立了一個整合 OMNeT++ 模擬器和 OSC 的整合架構。評估使用都市應用場景中的真實世界資料集，例如串流影片傳輸與無線 (OTA) 更新。結果顯示，與標準 3GPP 交接程序相比，此提案達到了優異的效能並降低了延遲。

##### **Aviary: training language agents on challenging scientific tasks**
2412.21154v1 by Siddharth Narayanan, James D. Braza, Ryan-Rhys Griffiths, Manu Ponnapati, Albert Bou, Jon Laurent, Ori Kabeli, Geemi Wellawatte, Sam Cox, Samuel G. Rodriques, Andrew D. White

Solving complex real-world tasks requires cycles of actions and observations.
This is particularly true in science, where tasks require many cycles of
analysis, tool use, and experimentation. Language agents are promising for
automating intellectual tasks in science because they can interact with tools
via natural language or code. Yet their flexibility creates conceptual and
practical challenges for software implementations, since agents may comprise
non-standard components such as internal reasoning, planning, tool usage, as
well as the inherent stochasticity of temperature-sampled language models.
Here, we introduce Aviary, an extensible gymnasium for language agents. We
formalize agents as policies solving language-grounded partially observable
Markov decision processes, which we term language decision processes. We then
implement five environments, including three challenging scientific
environments: (1) manipulating DNA constructs for molecular cloning, (2)
answering research questions by accessing scientific literature, and (3)
engineering protein stability. These environments were selected for their focus
on multi-step reasoning and their relevance to contemporary biology research.
Finally, with online training and scaling inference-time compute, we show that
language agents backed by open-source, non-frontier LLMs can match and exceed
both frontier LLM agents and human experts on multiple tasks at up to 100x
lower inference cost.

摘要：解決複雜的真實世界任務需要一系列的動作和觀察。
這在科學領域尤其如此，因為任務需要許多分析、工具使用和實驗的循環。語言代理有望自動化科學中的智力任務，因為它們可以使用自然語言或代碼與工具互動。然而，它們的靈活性為軟體實作帶來了概念性和實際挑戰，因為代理可能包含非標準元件，例如內部推理、規劃、工具使用，以及溫度取樣語言模型固有的隨機性。
在此，我們介紹 Aviary，這是語言代理的可擴充體育館。我們將代理形式化為解決語言基礎部分可觀察馬可夫決策過程的政策，我們稱之為語言決策過程。然後，我們實作了五個環境，包括三個具有挑戰性的科學環境：(1) 操縱 DNA 結構以進行分子複製，(2) 透過存取科學文獻來回答研究問題，以及 (3) 工程蛋白質穩定性。選擇這些環境是因為它們專注於多步驟推理以及與當代生物學研究相關。
最後，透過線上訓練和擴充推論時間計算，我們展示了由開源、非前沿 LLM 支援的語言代理可以在多項任務上匹配並超越前沿 LLM 代理和人類專家，且推論成本低達 100 倍。

##### **PyG-SSL: A Graph Self-Supervised Learning Toolkit**
2412.21151v1 by Lecheng Zheng, Baoyu Jing, Zihao Li, Zhichen Zeng, Tianxin Wei, Mengting Ai, Xinrui He, Lihui Liu, Dongqi Fu, Jiaxuan You, Hanghang Tong, Jingrui He

Graph Self-Supervised Learning (SSL) has emerged as a pivotal area of
research in recent years. By engaging in pretext tasks to learn the intricate
topological structures and properties of graphs using unlabeled data, these
graph SSL models achieve enhanced performance, improved generalization, and
heightened robustness. Despite the remarkable achievements of these graph SSL
methods, their current implementation poses significant challenges for
beginners and practitioners due to the complex nature of graph structures,
inconsistent evaluation metrics, and concerns regarding reproducibility hinder
further progress in this field. Recognizing the growing interest within the
research community, there is an urgent need for a comprehensive,
beginner-friendly, and accessible toolkit consisting of the most representative
graph SSL algorithms. To address these challenges, we present a Graph SSL
toolkit named PyG-SSL, which is built upon PyTorch and is compatible with
various deep learning and scientific computing backends. Within the toolkit, we
offer a unified framework encompassing dataset loading, hyper-parameter
configuration, model training, and comprehensive performance evaluation for
diverse downstream tasks. Moreover, we provide beginner-friendly tutorials and
the best hyper-parameters of each graph SSL algorithm on different graph
datasets, facilitating the reproduction of results. The GitHub repository of
the library is https://github.com/iDEA-iSAIL-Lab-UIUC/pyg-ssl.

摘要：圖形自監督學習 (SSL) 已成為近年研究中的關鍵領域。透過參與預設任務，利用未標記資料學習圖形的複雜拓撲結構和屬性，這些圖形 SSL 模型可提升效能、改善概化，並增強穩健性。儘管這些圖形 SSL 方法已取得顯著成就，但由於圖形結構的複雜性、不一致的評估指標，以及對再現性的疑慮，使得目前實作對初學者和實務工作者而言具有重大挑戰，阻礙了此領域的進一步進展。鑑於研究社群中日益增長的需求，迫切需要一個全面、對初學者友善且容易取得的工具包，其中包含最具代表性的圖形 SSL 演算法。為了應對這些挑戰，我們提出一個名為 PyG-SSL 的圖形 SSL 工具包，它建立在 PyTorch 之上，並與各種深度學習和科學運算後端相容。在工具包中，我們提供一個統一的架構，涵蓋資料集載入、超參數設定、模型訓練，以及對各種下游任務進行全面的效能評估。此外，我們提供對初學者友善的教學課程，以及每種圖形 SSL 演算法在不同圖形資料集上的最佳超參數，以利於結果的重現。此程式庫的 GitHub 儲存庫為 https://github.com/iDEA-iSAIL-Lab-UIUC/pyg-ssl。

##### **Facilitating large language model Russian adaptation with Learned Embedding Propagation**
2412.21140v1 by Mikhail Tikhomirov, Daniil Chernyshev

Rapid advancements of large language model (LLM) technologies led to the
introduction of powerful open-source instruction-tuned LLMs that have the same
text generation quality as the state-of-the-art counterparts such as GPT-4.
While the emergence of such models accelerates the adoption of LLM technologies
in sensitive-information environments the authors of such models don not
disclose the training data necessary for replication of the results thus making
the achievements model-exclusive. Since those open-source models are also
multilingual this in turn reduces the benefits of training a language specific
LLMs as improved inference computation efficiency becomes the only guaranteed
advantage of such costly procedure. More cost-efficient options such as
vocabulary extension and subsequent continued pre-training are also inhibited
by the lack of access to high-quality instruction-tuning data since it is the
major factor behind the resulting LLM task-solving capabilities. To address the
limitations and cut the costs of the language adaptation pipeline we propose
Learned Embedding Propagation (LEP). Unlike existing approaches our method has
lower training data size requirements due to minimal impact on existing LLM
knowledge which we reinforce using novel ad-hoc embedding propagation procedure
that allows to skip the instruction-tuning step and instead implant the new
language knowledge directly into any existing instruct-tuned variant. We
evaluated four Russian vocabulary adaptations for LLaMa-3-8B and Mistral-7B,
showing that LEP is competitive with traditional instruction-tuning methods,
achieving performance comparable to OpenChat 3.5 and LLaMa-3-8B-Instruct, with
further improvements via self-calibration and continued tuning enhancing
task-solving capabilities.

摘要：大型語言模型 (LLM) 技術的快速進展導致了功能強大的開源指令調整 LLM 的引入，它們具有與 GPT-4 等最先進對應模型相同的文本生成品質。儘管此類模型的出現加速了在敏感訊息環境中採用 LLM 技術，但此類模型的作者並未公開複製結果所需的訓練資料，從而使成就成為模型獨有的。由於這些開源模型也是多語言的，這反過來又減少了訓練特定語言 LLM 的好處，因為改進的推論計算效率成為這種昂貴程序唯一有保證的優勢。更具成本效益的選項，例如詞彙擴充和後續持續預訓練，也受到無法獲得高品質指令調整資料的阻礙，因為它是導致 LLM 任務解決能力的主要因素。為了解決限制並降低語言適應管線的成本，我們提出了學習嵌入傳播 (LEP)。與現有方法不同，我們的方法對訓練資料大小的要求較低，因為它對現有 LLM 知識的影響很小，我們使用新穎的臨時嵌入傳播程序來加強這種影響，該程序允許跳過指令調整步驟，而是將新語言知識直接植入任何現有的指令調整變體中。我們評估了 LLaMa-3-8B 和 Mistral-7B 的四種俄語詞彙改編，表明 LEP 與傳統的指令調整方法具有競爭力，實現了與 OpenChat 3.5 和 LLaMa-3-8B-Instruct 相當的效能，並通過自校準和持續調整進一步改進了任務解決能力。

##### **Training Software Engineering Agents and Verifiers with SWE-Gym**
2412.21139v1 by Jiayi Pan, Xingyao Wang, Graham Neubig, Navdeep Jaitly, Heng Ji, Alane Suhr, Yizhe Zhang

We present SWE-Gym, the first environment for training real-world software
engineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task
instances, each comprising a codebase with an executable runtime environment,
unit tests, and a task specified in natural language. We use SWE-Gym to train
language model based SWE agents , achieving up to 19% absolute gains in resolve
rate on the popular SWE-Bench Verified and Lite test sets. We also experiment
with inference-time scaling through verifiers trained on agent trajectories
sampled from SWE-Gym. When combined with our fine-tuned SWE agents, we achieve
32.0% and 26.0% on SWE-Bench Verified and Lite, respectively, reflecting a new
state-of-the-art for open-weight SWE agents. To facilitate further research, we
publicly release SWE-Gym, models, and agent trajectories.

摘要：我們提出 SWE-Gym，這是第一個用於訓練真實世界軟體工程 (SWE) 代理的環境。SWE-Gym 包含 2,438 個真實世界的 Python 任務實例，每個實例都包含一個具有可執行執行時間環境、單元測試和以自然語言指定的任務的程式碼庫。我們使用 SWE-Gym 來訓練基於語言模型的 SWE 代理，在流行的 SWE-Bench Verified 和 Lite 測試集中實現了高達 19% 的絕對增益解決率。我們還通過訓練從 SWE-Gym 採樣的代理軌跡的驗證器來試驗推理時間縮放。當與我們微調的 SWE 代理結合使用時，我們分別在 SWE-Bench Verified 和 Lite 上實現了 32.0% 和 26.0%，這反映了開放權重 SWE 代理的新技術水準。為了促進進一步的研究，我們公開發布了 SWE-Gym、模型和代理軌跡。

##### **Exploring and Controlling Diversity in LLM-Agent Conversation**
2412.21102v1 by KuanChao Chu, Yi-Pei Chen, Hideki Nakayama

Diversity is a critical aspect of multi-agent communication. In this paper,
we focus on controlling and exploring diversity in the context of open-domain
multi-agent conversations, particularly for world simulation applications. We
propose Adaptive Prompt Pruning (APP), a novel method that dynamically adjusts
the content of the utterance generation prompt to control diversity using a
single parameter, lambda. Through extensive experiments, we show that APP
effectively controls the output diversity across models and datasets, with
pruning more information leading to more diverse output. We comprehensively
analyze the relationship between prompt content and conversational diversity.
Our findings reveal that information from all components of the prompt
generally constrains the diversity of the output, with the Memory block
exerting the most significant influence. APP is compatible with established
techniques like temperature sampling and top-p sampling, providing a versatile
tool for diversity management. To address the trade-offs of increased
diversity, such as inconsistencies with omitted information, we incorporate a
post-generation correction step, which effectively balances diversity
enhancement with output consistency. Additionally, we examine how prompt
structure, including component order and length, impacts diversity. This study
addresses key questions surrounding diversity in multi-agent world simulation,
offering insights into its control, influencing factors, and associated
trade-offs. Our contributions lay the foundation for systematically engineering
diversity in LLM-based multi-agent collaborations, advancing their
effectiveness in real-world applications.

摘要：多樣性是多主體溝通中的一個關鍵面向。在本文中，
我們專注於控制和探索開放領域多主體對話中的多樣性，特別是針對世界模擬應用程式。我們
提出自適應提示剪枝 (APP)，這是一種新方法，可以動態調整發話產生提示的內容，以使用單一參數 lambda 控制多樣性。透過廣泛的實驗，我們展示了 APP
有效地控制了跨模型和資料集的輸出多樣性，剪枝更多資訊會導致更多樣化的輸出。我們全面
分析提示內容與對話多樣性之間的關係。
我們的研究結果顯示，提示所有組件的資訊通常會限制輸出的多樣性，其中記憶體區塊
發揮了最顯著的影響。APP 與已建立的技術相容，例如溫度抽樣和 top-p 抽樣，提供了一個用於多樣性管理的多功能工具。為了解決增加
多樣性的權衡，例如與遺漏資訊的不一致，我們納入了後生成校正步驟，有效地平衡了多樣性
增強和輸出一致性。此外，我們探討了提示結構，包括組件順序和長度，如何影響多樣性。這項研究
探討了圍繞多主體世界模擬中多樣性的關鍵問題，提供了對其控制、影響因素和相關
權衡的見解。我們的貢獻奠定了在基於 LLM 的多主體協作中系統化工程多樣性的基礎，提升了它們
在實際應用中的效能。

##### **Efficient Multi-Task Inferencing with a Shared Backbone and Lightweight Task-Specific Adapters for Automatic Scoring**
2412.21065v1 by Ehsan Latif, Xiaoming Zhai

The integration of Artificial Intelligence (AI) in education requires
scalable and efficient frameworks that balance performance, adaptability, and
cost. This paper addresses these needs by proposing a shared backbone model
architecture enhanced with lightweight LoRA adapters for task-specific
fine-tuning, targeting the automated scoring of student responses across 27
mutually exclusive tasks. By achieving competitive performance (average QWK of
0.848 compared to 0.888 for fully fine-tuned models) while reducing GPU memory
consumption by 60% and inference latency by 40%, the framework demonstrates
significant efficiency gains. This approach aligns with the workshops' focus on
improving language models for educational tasks, creating responsible
innovations for cost-sensitive deployment, and supporting educators by
streamlining assessment workflows. The findings underscore the potential of
scalable AI to enhance learning outcomes while maintaining fairness and
transparency in automated scoring systems.

摘要：人工智慧（AI）在教育中的整合需要可擴充且有效率的架構，以平衡效能、適應性和成本。本文透過提出一個共同的骨幹模型架構來解決這些需求，並透過輕量化的 LoRA 適配器針對特定任務進行微調，目標是自動評分學生在 27 個相互排斥的任務中的回應。透過達成具競爭力的效能（與經過完全微調的模型相比，平均 QWK 為 0.848，而後者為 0.888），同時將 GPU 記憶體消耗減少 60%，並將推論延遲減少 40%，此架構展示了顯著的效率提升。這種方法符合工作坊的重點，即改善教育任務的語言模型、為成本敏感的部署創造負責任的創新，以及透過簡化評量工作流程來支援教育工作者。這些發現強調了可擴充 AI 在提升學習成果方面的潛力，同時在自動評分系統中維持公平性和透明度。

##### **Towards Effective Discrimination Testing for Generative AI**
2412.21052v1 by Thomas P. Zollo, Nikita Rajaneesh, Richard Zemel, Talia B. Gillis, Emily Black

Generative AI (GenAI) models present new challenges in regulating against
discriminatory behavior. In this paper, we argue that GenAI fairness research
still has not met these challenges; instead, a significant gap remains between
existing bias assessment methods and regulatory goals. This leads to
ineffective regulation that can allow deployment of reportedly fair, yet
actually discriminatory, GenAI systems. Towards remedying this problem, we
connect the legal and technical literature around GenAI bias evaluation and
identify areas of misalignment. Through four case studies, we demonstrate how
this misalignment between fairness testing techniques and regulatory goals can
result in discriminatory outcomes in real-world deployments, especially in
adaptive or complex environments. We offer practical recommendations for
improving discrimination testing to better align with regulatory goals and
enhance the reliability of fairness assessments in future deployments.

摘要：生成式 AI (GenAI) 模型在規範歧視行為方面提出了新的挑戰。在本文中，我們認為 GenAI 公平性研究仍未滿足這些挑戰；相反，現有的偏見評估方法與法規目標之間仍存在顯著差距。這導致無效的規範，允許部署據稱公平但實際上具有歧視性的 GenAI 系統。為了解決這個問題，我們將 GenAI 偏見評估相關的法律和技術文獻聯繫起來，並找出錯位領域。透過四個案例研究，我們展示了公平性測試技術與法規目標之間的錯位如何導致實際部署中的歧視性結果，特別是在適應性或複雜環境中。我們提供了改進歧視測試的實用建議，以更好地符合法規目標，並提高未來部署中公平性評估的可靠性。

##### **Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense**
2412.21051v1 by Yuyang Zhou, Guang Cheng, Kang Du, Zihan Chen

The rapid evolution of cloud computing technologies and the increasing number
of cloud applications have provided a large number of benefits in daily lives.
However, the diversity and complexity of different components pose a
significant challenge to cloud security, especially when dealing with
sophisticated and advanced cyberattacks. Recent advancements in generative
foundation models (GFMs), particularly in the large language models (LLMs),
offer promising solutions for security intelligence. By exploiting the powerful
abilities in language understanding, data analysis, task inference, action
planning, and code generation, we present LLM-PD, a novel proactive defense
architecture that defeats various threats in a proactive manner. LLM-PD can
efficiently make a decision through comprehensive data analysis and sequential
reasoning, as well as dynamically creating and deploying actionable defense
mechanisms on the target cloud. Furthermore, it can flexibly self-evolve based
on experience learned from previous interactions and adapt to new attack
scenarios without additional training. The experimental results demonstrate its
remarkable ability in terms of defense effectiveness and efficiency,
particularly highlighting an outstanding success rate when compared with other
existing methods.

摘要：雲端運算技術的快速演進和雲端應用程式數量的增加，為日常生活中提供了許多好處。
然而，不同組件的多樣性和複雜性對雲端安全性構成重大挑戰，特別是在處理複雜的進階網路攻擊時。生成基礎模型 (GFM) 的最新進展，特別是在大型語言模型 (LLM) 中，為安全情報提供了有前景的解決方案。透過利用語言理解、資料分析、任務推論、動作規劃和程式碼生成等強大能力，我們提出了 LLM-PD，這是一種創新的主動防禦架構，可以主動抵禦各種威脅。LLM-PD 可以透過全面的資料分析和順序推理有效地做出決策，並在目標雲端動態建立和部署可行的防禦機制。此外，它可以根據從先前互動中學到的經驗靈活地自我演化，並在沒有額外訓練的情況下適應新的攻擊場景。實驗結果證明了其在防禦效能和效率方面的顯著能力，特別是在與其他現有方法相比時突出的成功率。

##### **TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization**
2412.21037v1 by Chia-Yu Hung, Navonil Majumder, Zhifeng Kong, Ambuj Mehrish, Rafael Valle, Bryan Catanzaro, Soujanya Poria

We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model
with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio
in just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models
lies in the difficulty of creating preference pairs, as TTA lacks structured
mechanisms like verifiable rewards or gold-standard answers available for Large
Language Models (LLMs). To address this, we propose CLAP-Ranked Preference
Optimization (CRPO), a novel framework that iteratively generates and optimizes
preference data to enhance TTA alignment. We demonstrate that the audio
preference dataset generated using CRPO outperforms existing alternatives. With
this framework, TangoFlux achieves state-of-the-art performance across both
objective and subjective benchmarks. We open source all code and models to
support further research in TTA generation.

摘要：我們介紹 TangoFlux，一個高效的文字轉音訊 (TTA) 生成模型，具有 515M 參數，能夠在單個 A40 GPU 上僅需 3.7 秒就能產生長達 30 秒的 44.1kHz 音訊。TTA 模型對齊的一個主要挑戰在於難以建立偏好配對，因為 TTA 缺乏大型語言模型 (LLM) 可用的結構化機制，例如可驗證的獎勵或黃金標準答案。為了解決這個問題，我們提出 CLAP 排名偏好最佳化 (CRPO)，這是一個新穎的框架，可反覆生成和最佳化偏好資料以增強 TTA 對齊。我們展示使用 CRPO 生成的音訊偏好資料集優於現有的替代方案。有了這個框架，TangoFlux 在客觀和主觀基準上都達到了最先進的效能。我們開放所有程式碼和模型，以支援 TTA 生成進一步的研究。

##### **GePBench: Evaluating Fundamental Geometric Perception for Multimodal Large Language Models**
2412.21036v1 by Shangyu Xing, Changhao Xiang, Yuteng Han, Yifan Yue, Zhen Wu, Xinyu Liu, Zhangtai Wu, Fei Zhao, Xinyu Dai

Multimodal large language models (MLLMs) have achieved significant
advancements in integrating visual and linguistic understanding. While existing
benchmarks evaluate these models in context-rich, real-life scenarios, they
often overlook fundamental perceptual skills essential for environments
deviating from everyday realism. In particular, geometric perception, the
ability to interpret spatial relationships and abstract visual patterns,
remains underexplored. To address this limitation, we introduce GePBench, a
novel benchmark designed to assess the geometric perception capabilities of
MLLMs. Results from extensive evaluations reveal that current state-of-the-art
MLLMs exhibit significant deficiencies in such tasks. Additionally, we
demonstrate that models trained with data sourced from GePBench show notable
improvements on a wide range of downstream tasks, underscoring the importance
of geometric perception as a foundation for advanced multimodal applications.
Our code and datasets will be publicly available.

摘要：多模态大型语言模型 (MMLM) 在整合视觉和语言理解方面取得了重大进展。虽然现有的基准在内容丰富、真实的场景中评估这些模型，但它们常常忽略了对偏离日常现实的环境至关重要的基本感知技能。特别是，几何感知，即解释空间关系和抽象视觉模式的能力，仍然没有得到充分的探索。为了解决这一限制，我们引入了 GePBench，这是一个新颖的基准，旨在评估 MMLM 的几何感知能力。广泛评估的结果表明，当前最先进的 MMLM 在此类任务中表现出明显的缺陷。此外，我们证明了使用从 GePBench 获得的数据训练的模型在广泛的下游任务中显示出显着的改进，这强调了几何感知作为高级多模态应用程序基础的重要性。我们的代码和数据集将公开提供。

##### **Plancraft: an evaluation dataset for planning with LLM agents**
2412.21033v1 by Gautier Dagan, Frank Keller, Alex Lascarides

We present Plancraft, a multi-modal evaluation dataset for LLM agents.
Plancraft has both a text-only and multi-modal interface, based on the
Minecraft crafting GUI. We include the Minecraft Wiki to evaluate tool use and
Retrieval Augmented Generation (RAG), as well as an oracle planner and oracle
RAG information extractor, to ablate the different components of a modern agent
architecture. To evaluate decision-making, Plancraft also includes a subset of
examples that are intentionally unsolvable, providing a realistic challenge
that requires the agent not only to complete tasks but also to decide whether
they are solvable at all. We benchmark both open-source and closed-source LLMs
and strategies on our task and compare their performance to a handcrafted
planner. We find that LLMs and VLMs struggle with the planning problems that
Plancraft introduces, and we offer suggestions on how to improve their
capabilities.

摘要：我們提出 Plancraft，一個針對 LLM 代理的多模式評量資料集。
Plancraft 有一個純文字和多模式介面，基於 Minecraft 製作 GUI。我們包含 Minecraft Wiki 來評量工具使用和檢索擴充產生 (RAG)，以及一個神諭規劃器和神諭 RAG 資訊萃取器，以消融現代代理架構的不同元件。為了評量決策制定，Plancraft 也包含一個故意無法解決的範例子集，提供一個逼真的挑戰，要求代理不僅要完成任務，還要決定它們是否可以解決。我們在我們的任務上對開源和閉源 LLM 和策略進行基準測試，並將其效能與手工規劃器進行比較。我們發現 LLM 和 VLM 難以處理 Plancraft 引入的規劃問題，並提供如何改善其能力的建議。

##### **MapQaTor: A System for Efficient Annotation of Map Query Datasets**
2412.21015v1 by Mahir Labib Dihan, Mohammed Eunus Ali, Md Rizwan Parvez

Mapping and navigation services like Google Maps, Apple Maps, Openstreet
Maps, are essential for accessing various location-based data, yet they often
struggle to handle natural language geospatial queries. Recent advancements in
Large Language Models (LLMs) show promise in question answering (QA), but
creating reliable geospatial QA datasets from map services remains challenging.
We introduce MapQaTor, a web application that streamlines the creation of
reproducible, traceable map-based QA datasets. With its plug-and-play
architecture, MapQaTor enables seamless integration with any maps API, allowing
users to gather and visualize data from diverse sources with minimal setup. By
caching API responses, the platform ensures consistent ground truth, enhancing
the reliability of the data even as real-world information evolves. MapQaTor
centralizes data retrieval, annotation, and visualization within a single
platform, offering a unique opportunity to evaluate the current state of
LLM-based geospatial reasoning while advancing their capabilities for improved
geospatial understanding. Evaluation metrics show that, MapQaTor speeds up the
annotation process by at least 30 times compared to manual methods,
underscoring its potential for developing geospatial resources, such as complex
map reasoning datasets. The website is live at: https://mapqator.github.io/ and
a demo video is available at: https://youtu.be/7_aV9Wmhs6Q.

摘要：像 Google Maps、Apple Maps、Openstreet
Maps 等地圖和導航服務對於存取各種基於位置的資料至關重要，但他們經常難以處理自然語言的地理空間查詢。大型語言模型 (LLM) 在問答 (QA) 方面的最新進展顯示出前景，但從地圖服務建立可靠的地理空間 QA 資料集仍然具有挑戰性。
我們介紹 MapQaTor，這是一個簡化建立可複製、可追蹤的基於地圖的 QA 資料集的網路應用程式。透過其即插即用的架構，MapQaTor 能夠與任何地圖 API 無縫整合，讓使用者能夠從不同的來源收集和視覺化資料，且設定最少。透過快取 API 回應，該平台確保了一致的真實情況，即使現實世界中的資訊不斷演變，也能增強資料的可靠性。MapQaTor 在單一平台中集中化資料擷取、註解和視覺化，提供了一個獨特的機會來評估 LLM 基於地理空間推理的當前狀態，同時提升其功能以改善地理空間理解。評估指標顯示，與手動方法相比，MapQaTor 將註解程序加速至少 30 倍，凸顯其開發地理空間資源（例如複雜的地圖推理資料集）的潛力。網站已上線：https://mapqator.github.io/，示範影片可於：https://youtu.be/7_aV9Wmhs6Q 觀看。

##### **Verbosity-Aware Rationale Reduction: Effective Reduction of Redundant Rationale via Principled Criteria**
2412.21006v1 by Joonwon Jang, Jaehee Kim, Wonbin Kweon, Hwanjo Yu

Large Language Models (LLMs) rely on generating extensive intermediate
reasoning units (e.g., tokens, sentences) to enhance final answer quality
across a wide range of complex tasks. While generating multiple reasoning paths
or iteratively refining rationales proves effective for improving performance,
these approaches inevitably result in significantly higher inference costs. In
this work, we propose a novel sentence-level rationale reduction training
framework that leverages likelihood-based criteria, verbosity, to identify and
remove redundant reasoning sentences. Unlike previous approaches that utilize
token-level reduction, our sentence-level reduction framework maintains model
performance while reducing generation length. This preserves the original
reasoning abilities of LLMs and achieves an average 17.15% reduction in
generation costs across various models and tasks.

摘要：大型語言模型 (LLM) 仰賴產生廣泛的中間推理單元 (例如：符號、句子) 來提升在各種複雜任務中的最終答案品質。儘管產生多重推理路徑或反覆精進依據已證實能有效提升效能，但這些方法無可避免地會導致顯著更高的推論成本。在這項工作中，我們提出一個新穎的句子層級依據簡化訓練架構，該架構利用基於可能性的標準（冗長度）來識別並移除多餘的推理句子。與利用符號層級簡化的先前方法不同，我們的句子層級簡化架構在減少產生長度的同時，維持模型效能。這保留了 LLM 的原始推理能力，並在各種模型和任務中平均減少了 17.15% 的產生成本。

##### **LEASE: Offline Preference-based Reinforcement Learning with High Sample Efficiency**
2412.21001v1 by Xiao-Yin Liu, Guotao Li, Xiao-Hu Zhou, Zeng-Guang Hou

Offline preference-based reinforcement learning (PbRL) provides an effective
way to overcome the challenges of designing reward and the high costs of online
interaction. However, since labeling preference needs real-time human feedback,
acquiring sufficient preference labels is challenging. To solve this, this
paper proposes a offLine prEference-bAsed RL with high Sample Efficiency
(LEASE) algorithm, where a learned transition model is leveraged to generate
unlabeled preference data. Considering the pretrained reward model may generate
incorrect labels for unlabeled data, we design an uncertainty-aware mechanism
to ensure the performance of reward model, where only high confidence and low
variance data are selected. Moreover, we provide the generalization bound of
reward model to analyze the factors influencing reward accuracy, and
demonstrate that the policy learned by LEASE has theoretical improvement
guarantee. The developed theory is based on state-action pair, which can be
easily combined with other offline algorithms. The experimental results show
that LEASE can achieve comparable performance to baseline under fewer
preference data without online interaction.

摘要：離線偏好強化學習 (PbRL) 提供了一種有效的方式來克服設計獎勵和線上互動的高成本所帶來的挑戰。然而，由於標籤偏好需要即時的使用者回饋，因此取得足夠的偏好標籤是一項挑戰。為了解決這個問題，本文提出了一種具有高取樣效率的離線偏好強化學習演算法 (LEASE)，其中利用學習到的轉換模型來產生未標籤的偏好資料。考慮到預訓練的獎勵模型可能會為未標籤資料產生不正確的標籤，我們設計了一個不確定性感知機制來確保獎勵模型的效能，其中僅選擇高信心和低變異的資料。此外，我們提供了獎勵模型的泛化界限來分析影響獎勵準確度的因素，並證明了 LEASE 所學習到的策略具有理論上的改進保證。所開發的理論基於狀態動作對，可以輕鬆地與其他離線演算法結合。實驗結果表明，LEASE 可以在較少的偏好資料下，在沒有線上互動的情況下，達到與基線相當的效能。

##### **Plug-and-Play Training Framework for Preference Optimization**
2412.20996v1 by Jingyuan Ma, Rui Li, Zheng Li, Lei Sha, Zhifang Sui

Recently, preference optimization methods such as DPO have significantly
enhanced large language models (LLMs) in wide tasks including dialogue and
question-answering. However, current methods fail to account for the varying
difficulty levels of training samples during preference optimization, leading
to mediocre performance in tasks with high accuracy requirements, particularly
in mathematical reasoning. To address this limitation, we propose a novel
training framework, which employs multiple sampling to analyze output
distributions, assign different weights to samples, and incorporate these
weights into the preference optimization process. This plug-and-play approach
enables LLMs to prioritize challenging examples during training, improving
learning efficiency. Experimental results demonstrate that our framework
integrates seamlessly with various preference optimization methods and achieves
consistent improvements in mathematical reasoning tasks.

摘要：最近，诸如 DPO 的偏好优化方法已显著增强大型语言模型 (LLM)，使其在包括对话和问答在内的广泛任务中得到应用。然而，当前方法无法在偏好优化期间考虑训练样本的难度级别，导致在对准确性要求较高的任务中表现平平，尤其是在数学推理中。为了解决这一限制，我们提出了一种新颖的训练框架，该框架采用多重采样来分析输出分布，为样本分配不同的权重，并将这些权重纳入偏好优化过程。这种即插即用的方法使 LLM 能够在训练期间优先考虑具有挑战性的示例，从而提高学习效率。实验结果表明，我们的框架与各种偏好优化方法无缝集成，并在数学推理任务中取得了一致的改进。

##### **KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**
2412.20995v1 by Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xinrun Du, Ningxuan Lu, Ge Zhang, Qingkun Tang

Large language models (LLMs) demonstrate exceptional performance across a
variety of tasks, yet they are often affected by hallucinations and the
timeliness of knowledge. Leveraging knowledge graphs (KGs) as external
knowledge sources has emerged as a viable solution, but existing methods for
LLM-based knowledge graph question answering (KGQA) are often limited by
step-by-step decision-making on KGs, restricting the global planning and
reasoning capabilities of LLMs, or they require fine-tuning or pre-training on
specific KGs. To address these challenges, we propose Knowledge graph Assisted
Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global
planning abilities of LLMs for efficient and accurate KG reasoning. KARPA
operates in three steps: pre-planning relation paths using the LLM's global
planning capabilities, matching semantically relevant paths via an embedding
model, and reasoning over these paths to generate answers. Unlike existing KGQA
methods, KARPA avoids stepwise traversal, requires no additional training, and
is adaptable to various LLM architectures. Extensive experimental results show
that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both
high efficiency and accuracy. Our code will be available on Github.

摘要：大型語言模型 (LLM) 在各種任務中表現出色的表現，但它們經常受到幻覺和知識時效性的影響。利用知識圖譜 (KG) 作為外部知識來源已成為一個可行的解決方案，但現有的 LLM 基於知識圖譜問答 (KGQA) 的方法通常受到 KG 上逐步決策的限制，限制了 LLM 的全局規劃和推理能力，或者它們需要針對特定 KG 進行微調或預訓練。為了應對這些挑戰，我們提出了知識圖譜輔助推理路徑聚合 (KARPA)，這是一個新穎的框架，利用 LLM 的全局規劃能力進行高效且準確的 KG 推理。KARPA 分三步操作：使用 LLM 的全局規劃能力預先規劃關係路徑、通過嵌入模型匹配語義相關路徑，以及推理這些路徑以產生答案。與現有的 KGQA 方法不同，KARPA 避免逐步遍歷，不需要額外的訓練，並且可以適應各種 LLM 架構。大量的實驗結果表明，KARPA 在 KGQA 任務中實現了最先進的性能，既提供了高效率又提供了高準確度。我們的程式碼將在 Github 上提供。

##### **Efficiently Serving LLM Reasoning Programs with Certaindex**
2412.20993v1 by Yichao Fu, Junda Chen, Siqi Zhu, Zheyu Fu, Zhongdongming Dai, Aurick Qiao, Hao Zhang

The rapid evolution of large language models (LLMs) has unlocked their
capabilities in advanced reasoning tasks like mathematical problem-solving,
code generation, and legal analysis. Central to this progress are
inference-time reasoning algorithms, which refine outputs by exploring multiple
solution paths, at the cost of increasing compute demands and response
latencies. Existing serving systems fail to adapt to the scaling behaviors of
these algorithms or the varying difficulty of queries, leading to inefficient
resource use and unmet latency targets.
  We present Dynasor, a system that optimizes inference-time compute for LLM
reasoning queries. Unlike traditional engines, Dynasor tracks and schedules
requests within reasoning queries and uses Certaindex, a proxy that measures
statistical reasoning progress based on model certainty, to guide compute
allocation dynamically. Dynasor co-adapts scheduling with reasoning progress:
it allocates more compute to hard queries, reduces compute for simpler ones,
and terminates unpromising queries early, balancing accuracy, latency, and
cost. On diverse datasets and algorithms, Dynasor reduces compute by up to 50%
in batch processing and sustaining 3.3x higher query rates or 4.7x tighter
latency SLOs in online serving.

摘要：大型語言模型 (LLM) 的快速演進已解鎖其在進階推理任務中的能力，例如數學問題求解、程式碼生成和法律分析。這種進步的核心是推理時間推理演算法，它透過探索多種解題路徑來優化輸出，但代價是增加運算需求和回應延遲。現有的服務系統無法適應這些演算法的擴充行為或查詢的難度變化，導致資源使用效率低下和延遲目標未達成。
  我們提出 Dynasor，一個針對 LLM 推理查詢最佳化推理時間運算的系統。與傳統引擎不同，Dynasor 追蹤和排程推理查詢中的要求，並使用 Certaindex，一個基於模型確定性測量統計推理進度的代理，來動態引導運算配置。Dynasor 將排程與推理進度共同適應：它為困難的查詢分配更多運算，為較簡單的查詢減少運算，並提早終止沒有希望的查詢，平衡準確性、延遲和成本。在不同的資料集和演算法上，Dynasor 將批次處理中的運算減少了 50%，並在線上服務中維持高出 3.3 倍的查詢率或嚴格 4.7 倍的延遲 SLO。

##### **UnrealZoo: Enriching Photo-realistic Virtual Worlds for Embodied AI**
2412.20977v1 by Fangwei Zhong, Kui Wu, Churan Wang, Hao Chen, Hai Ci, Zhoujun Li, Yizhou Wang

We introduce UnrealZoo, a rich collection of photo-realistic 3D virtual
worlds built on Unreal Engine, designed to reflect the complexity and
variability of the open worlds. Additionally, we offer a variety of playable
entities for embodied AI agents. Based on UnrealCV, we provide a suite of
easy-to-use Python APIs and tools for various potential applications, such as
data collection, environment augmentation, distributed training, and
benchmarking. We optimize the rendering and communication efficiency of
UnrealCV to support advanced applications, such as multi-agent interaction. Our
experiments benchmark agents in various complex scenes, focusing on visual
navigation and tracking, which are fundamental capabilities for embodied visual
intelligence. The results yield valuable insights into the advantages of
diverse training environments for reinforcement learning (RL) agents and the
challenges faced by current embodied vision agents, including those based on RL
and large vision-language models (VLMs), in open worlds. These challenges
involve latency in closed-loop control in dynamic scenes and reasoning about 3D
spatial structures in unstructured terrain.

摘要：我們介紹 UnrealZoo，這是建立在 Unreal Engine 上的一系列豐富的寫實 3D 虛擬世界，旨在反映開放世界的複雜性和可變性。此外，我們還提供各種可玩實體，供具身 AI 代理使用。基於 UnrealCV，我們提供一系列易於使用的 Python API 和工具，適用於各種潛在應用，例如數據收集、環境擴充、分散式訓練和基準測試。我們最佳化 UnrealCV 的渲染和通訊效率，以支援進階應用，例如多重代理互動。我們的實驗在各種複雜場景中對代理進行基準測試，專注於視覺導航和追蹤，這是具身視覺智慧的基本能力。結果對強化學習 (RL) 代理的不同訓練環境的優勢以及當前具身視覺代理（包括基於 RL 和大型視覺語言模型 (VLM) 的代理）在開放世界中所面臨的挑戰，產生了有價值的見解。這些挑戰涉及動態場景中閉環控制的延遲，以及對非結構化地形中 3D 空間結構的推理。

##### **Conservation-informed Graph Learning for Spatiotemporal Dynamics Prediction**
2412.20962v1 by Yuan Mi, Pu Ren, Hongteng Xu, Hongsheng Liu, Zidong Wang, Yike Guo, Ji-Rong Wen, Hao Sun, Yang Liu

Data-centric methods have shown great potential in understanding and
predicting spatiotemporal dynamics, enabling better design and control of the
object system. However, pure deep learning models often lack interpretability,
fail to obey intrinsic physics, and struggle to cope with the various domains.
While geometry-based methods, e.g., graph neural networks (GNNs), have been
proposed to further tackle these challenges, they still need to find the
implicit physical laws from large datasets and rely excessively on rich labeled
data. In this paper, we herein introduce the conservation-informed GNN (CiGNN),
an end-to-end explainable learning framework, to learn spatiotemporal dynamics
based on limited training data. The network is designed to conform to the
general conservation law via symmetry, where conservative and non-conservative
information passes over a multiscale space enhanced by a latent temporal
marching strategy. The efficacy of our model has been verified in various
spatiotemporal systems based on synthetic and real-world datasets, showing
superiority over baseline models. Results demonstrate that CiGNN exhibits
remarkable accuracy and generalization ability, and is readily applicable to
learning for prediction of various spatiotemporal dynamics in a spatial domain
with complex geometry.

摘要：<paragraph>資料為中心的各種方法在理解和預測時空動力學方面展現極佳的潛力，能更有效地設計與控制物件系統。然而，純粹的深度學習模型往往缺乏可解釋性，無法遵循內在物理定律，且難以應對各種領域。雖然幾何基礎方法（例如圖形神經網路 (GNN)）已被提出進一步應對這些挑戰，但它們仍需要從大型資料集中找出隱含的物理定律，並過度依賴豐富的標籤資料。在本文中，我們在此介紹了受守恆定律啟發的 GNN (CiGNN)，這是一個端到端的可解釋學習架構，用於根據有限的訓練資料學習時空動力學。該網路被設計為透過對稱性符合一般守恆定律，其中保守和非保守資訊會透過一個由潛在時間行進策略增強的多尺度空間傳遞。我們模型的效力已在各種基於合成和真實世界資料集的時空系統中得到驗證，顯示出優於基線模型的優越性。結果證明，CiGNN 展現出卓越的準確性和泛化能力，且易於應用於學習，以預測具有複雜幾何形狀的空間域中的各種時空動力學。</paragraph>

##### **Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**
2412.20942v1 by Xiaohan Feng, Xixin Wu, Helen Meng

We propose an ontology-grounded approach to Knowledge Graph (KG) construction
using Large Language Models (LLMs) on a knowledge base. An ontology is authored
by generating Competency Questions (CQ) on knowledge base to discover knowledge
scope, extracting relations from CQs, and attempt to replace equivalent
relations by their counterpart in Wikidata. To ensure consistency and
interpretability in the resulting KG, we ground generation of KG with the
authored ontology based on extracted relations. Evaluation on benchmark
datasets demonstrates competitive performance in knowledge graph construction
task. Our work presents a promising direction for scalable KG construction
pipeline with minimal human intervention, that yields high quality and
human-interpretable KGs, which are interoperable with Wikidata semantics for
potential knowledge base expansion.

摘要：我們提出一個以本体為基礎的方法來建構知識圖譜（KG），方法是使用大型語言模型（LLM）在知識庫上。本体是由在知識庫上產生能力問題（CQ）來發現知識範圍，從 CQ 中提取關係，並嘗試用 Wikidata 中的對應關係替換等效關係而編寫的。為了確保結果 KG 的一致性和可解釋性，我們根據提取的關係，以編寫的本体為基礎來建立 KG 的產生。在基準資料集上的評估顯示在知識圖譜建構任務中有競爭力的效能。我們的研究提出了一個有希望的方向，可以透過極少的人工介入來建構可擴充的 KG 管線，產生高品質且人類可解釋的 KG，這些 KG 與 Wikidata 語義可以互通，以擴充潛在的知識庫。

##### **HisynSeg: Weakly-Supervised Histopathological Image Segmentation via Image-Mixing Synthesis and Consistency Regularization**
2412.20924v1 by Zijie Fang, Yifeng Wang, Peizhang Xie, Zhi Wang, Yongbing Zhang

Tissue semantic segmentation is one of the key tasks in computational
pathology. To avoid the expensive and laborious acquisition of pixel-level
annotations, a wide range of studies attempt to adopt the class activation map
(CAM), a weakly-supervised learning scheme, to achieve pixel-level tissue
segmentation. However, CAM-based methods are prone to suffer from
under-activation and over-activation issues, leading to poor segmentation
performance. To address this problem, we propose a novel weakly-supervised
semantic segmentation framework for histopathological images based on
image-mixing synthesis and consistency regularization, dubbed HisynSeg.
Specifically, synthesized histopathological images with pixel-level masks are
generated for fully-supervised model training, where two synthesis strategies
are proposed based on Mosaic transformation and B\'ezier mask generation.
Besides, an image filtering module is developed to guarantee the authenticity
of the synthesized images. In order to further avoid the model overfitting to
the occasional synthesis artifacts, we additionally propose a novel
self-supervised consistency regularization, which enables the real images
without segmentation masks to supervise the training of the segmentation model.
By integrating the proposed techniques, the HisynSeg framework successfully
transforms the weakly-supervised semantic segmentation problem into a
fully-supervised one, greatly improving the segmentation accuracy. Experimental
results on three datasets prove that the proposed method achieves a
state-of-the-art performance. Code is available at
https://github.com/Vison307/HisynSeg.

摘要：組織語意分割是計算病理學中的關鍵任務之一。為了避免昂貴且費力的像素層級註解取得，許多研究嘗試採用類別啟動映射（CAM），一種弱監督學習方案，以達成像素層級組織分割。然而，基於 CAM 的方法容易遭受欠啟動和過度啟動問題，導致分割效能不佳。為了解決這個問題，我們提出一個新的組織病理學影像弱監督語意分割架構，基於影像混合合成和一致性正則化，稱為 HisynSeg。具體來說，我們為全監督模型訓練生成了具有像素層級遮罩的合成組織病理學影像，其中基於馬賽克轉換和貝茲曲線遮罩生成提出了兩種合成策略。此外，我們開發了一個影像濾波模組來保證合成影像的真實性。為了進一步避免模型過度擬合到偶爾的合成偽影，我們另外提出了一個新的自我監督一致性正則化，它能讓沒有分割遮罩的真實影像監督分割模型的訓練。透過整合所提出的技術，HisynSeg 框架成功地將弱監督語意分割問題轉換成全監督問題，大幅提升分割準確度。在三個資料集上的實驗結果證明，所提出的方法達到了最先進的效能。程式碼可以在 https://github.com/Vison307/HisynSeg 取得。

##### **WalkVLM:Aid Visually Impaired People Walking by Vision Language Model**
2412.20903v1 by Zhiqiang Yuan, Ting Zhang, Jiapei Zhang, Jie Zhou, Jinchao Zhang

Approximately 200 million individuals around the world suffer from varying
degrees of visual impairment, making it crucial to leverage AI technology to
offer walking assistance for these people. With the recent progress of
vision-language models (VLMs), employing VLMs to improve this field has emerged
as a popular research topic. However, most existing methods are studied on
self-built question-answering datasets, lacking a unified training and testing
benchmark for walk guidance. Moreover, in blind walking task, it is necessary
to perform real-time streaming video parsing and generate concise yet
informative reminders, which poses a great challenge for VLMs that suffer from
redundant responses and low inference efficiency. In this paper, we firstly
release a diverse, extensive, and unbiased walking awareness dataset,
containing 12k video-manual annotation pairs from Europe and Asia to provide a
fair training and testing benchmark for blind walking task. Furthermore, a
WalkVLM model is proposed, which employs chain of thought for hierarchical
planning to generate concise but informative reminders and utilizes
temporal-aware adaptive prediction to reduce the temporal redundancy of
reminders. Finally, we have established a solid benchmark for blind walking
task and verified the advantages of WalkVLM in stream video processing for this
task compared to other VLMs. Our dataset and code will be released at anonymous
link https://walkvlm2024.github.io.

摘要：全球约有 2 亿人患有不同程度的视觉障碍，因此利用人工智能技术为这些人提供行走辅助至关重要。随着视觉语言模型 (VLM) 的最新进展，使用 VLM 来改进该领域已成为一个热门的研究课题。然而，大多数现有方法都是在自建的问答数据集上进行研究的，缺乏统一的步行指导训练和测试基准。此外，在盲人行走任务中，有必要执行实时流视频解析并生成简洁而有意义的提醒，这对遭受冗余响应和低推理效率的 VLM 构成了巨大挑战。在本文中，我们首先发布了一个多样化、广泛且无偏见的步行感知数据集，其中包含来自欧洲和亚洲的 12k 个视频手册注释对，以提供盲人步行任务的公平训练和测试基准。此外，提出了一种 WalkVLM 模型，该模型采用思想链进行分层规划以生成简洁但有意义的提醒，并利用时间感知自适应预测来减少提醒的时间冗余。最后，我们为盲人行走任务建立了一个坚实的基准，并验证了 WalkVLM 在流视频处理中与其他 VLM 相比的优势。我们的数据集和代码将在匿名链接 https://walkvlm2024.github.io 上发布。

##### **ILDiff: Generate Transparent Animated Stickers by Implicit Layout Distillation**
2412.20901v1 by Ting Zhang, Zhiqiang Yuan, Yeshuang Zhu, Jinchao Zhang

High-quality animated stickers usually contain transparent channels, which
are often ignored by current video generation models. To generate fine-grained
animated transparency channels, existing methods can be roughly divided into
video matting algorithms and diffusion-based algorithms. The methods based on
video matting have poor performance in dealing with semi-open areas in
stickers, while diffusion-based methods are often used to model a single image,
which will lead to local flicker when modeling animated stickers. In this
paper, we firstly propose an ILDiff method to generate animated transparent
channels through implicit layout distillation, which solves the problems of
semi-open area collapse and no consideration of temporal information in
existing methods. Secondly, we create the Transparent Animated Sticker Dataset
(TASD), which contains 0.32M high-quality samples with transparent channel, to
provide data support for related fields. Extensive experiments demonstrate that
ILDiff can produce finer and smoother transparent channels compared to other
methods such as Matting Anything and Layer Diffusion. Our code and dataset will
be released at link https://xiaoyuan1996.github.io.

摘要：高品質的動態貼圖通常包含透明通道，而這通常會被目前的影片生成模型所忽略。為了生成細緻的動態透明通道，現有的方法大致上可以分為影片去背演算法和基於擴散的演算法。基於影片去背的方法在處理貼圖中的半開放區域時效能不佳，而基於擴散的方法通常用於建模單一影像，這將會在建模動態貼圖時導致局部閃爍。在本文中，我們首先提出一個 ILDiff 方法，透過隱式佈局萃取來生成動態透明通道，這解決了現有方法中半開放區域崩潰和未考慮時間資訊的問題。其次，我們建立了透明動態貼圖資料集 (TASD)，其中包含 0.32M 個具有透明通道的高品質樣本，以提供相關領域的資料支援。廣泛的實驗證明，與 Matting Anything 和 Layer Diffusion 等其他方法相比，ILDiff 能夠產生更細緻、更平滑的透明通道。我們的程式碼和資料集將在 https://xiaoyuan1996.github.io/ 連結中釋出。

##### **DoTA: Weight-Decomposed Tensor Adaptation for Large Language Models**
2412.20891v1 by Xiaolin Hu, Xiang Cheng, Peiyu Liu, Wei Liu, Jian Luan, Bin Wang, Yong Liu

Low-rank adaptation (LoRA) reduces the computational and memory demands of
fine-tuning large language models (LLMs) by approximating updates with low-rank
matrices. However, low-rank approximation in two-dimensional space fails to
capture high-dimensional structures within the target matrix. Recently, tensor
decomposition methods have been explored for fine-tuning LLMs, leveraging their
ability to extract structured information. Yet, these approaches primarily rely
on random initialization, and the impact of initialization on tensor adaptation
remains underexplored. In this paper, we reveal that random initialization
significantly diverges from the validation loss achieved by full fine-tuning.
To address this, we propose Weight-Decomposed Tensor Adaptation (DoTA), which
leverages the Matrix Product Operator (MPO) decomposition of pre-trained
weights for effective initialization in fine-tuning LLMs. Additionally, we
introduce QDoTA, a quantized version of DoTA designed for 4-bit quantization.
Experiments on commonsense and arithmetic reasoning tasks show that DoTA
outperforms random initialization methods with fewer parameters. QDoTA further
reduces memory consumption and achieves comparable performance to DoTA on
commonsense reasoning tasks. We will release our code to support future
research.

摘要：低秩適應 (LoRA) 透過使用低秩矩陣近似更新，來降低微調大型語言模型 (LLM) 的運算和記憶體需求。然而，在二維空間中的低秩近似無法擷取目標矩陣中的高維結構。最近，已經探討使用張量分解方法來微調 LLM，利用其提取結構化資訊的能力。然而，這些方法主要依賴於隨機初始化，而初始化對張量適應的影響仍未充分探討。在本文中，我們揭示隨機初始化與完全微調所達成的驗證損失有顯著差異。為了解決這個問題，我們提出重量分解張量適應 (DoTA)，它利用預訓練權重的矩陣乘積算子 (MPO) 分解，在微調 LLM 中進行有效的初始化。此外，我們還引入了 QDoTA，這是一種針對 4 位元量化設計的 DoTA 量化版本。在常識和算術推理任務上的實驗表明，DoTA 以較少的參數優於隨機初始化方法。QDoTA 進一步降低了記憶體消耗，並在常識推理任務上達到了與 DoTA 相當的效能。我們將釋出我們的程式碼以支援未來的研究。

##### **Holistic Construction Automation with Modular Robots: From High-Level Task Specification to Execution**
2412.20867v1 by Jonathan Külz, Michael Terzer, Marco Magri, Andrea Giusti, Matthias Althoff

In situ robotic automation in construction is challenging due to constantly
changing environments, a shortage of robotic experts, and a lack of
standardized frameworks bridging robotics and construction practices. This work
proposes a holistic framework for construction task specification, optimization
of robot morphology, and mission execution using a mobile modular
reconfigurable robot. Users can specify and monitor the desired robot behavior
through a graphical interface. Our framework identifies an optimized robot
morphology and enables automatic real-world execution by integrating Building
Information Modelling (BIM). By leveraging modular robot components, we ensure
seamless and fast adaption to the specific demands of the construction task.
Experimental validation demonstrates that our approach robustly enables the
autonomous execution of robotic drilling.

摘要：由於環境不斷變化、機器人專家短缺，以及橋接機器人和施工實務的標準化框架不足，現場機器人自動化在施工中面臨挑戰。這項工作提出了一個整體框架，用於施工任務規格、機器人形態最佳化，以及使用行動模組化可重新組態機器人執行任務。使用者可以透過圖形介面指定和監控所需的機器人行為。我們的框架識別最佳化的機器人形態，並透過整合建築資訊模型 (BIM) 來實現自動的真實世界執行。藉由利用模組化機器人元件，我們確保能無縫且快速地適應施工任務的特定需求。實驗驗證證明，我們的做法能穩健地實現機器人鑽孔的自主執行。

##### **Enhancing Annotated Bibliography Generation with LLM Ensembles**
2412.20864v1 by Sergio Bermejo

This work proposes a novel approach to enhancing annotated bibliography
generation through Large Language Model (LLM) ensembles. In particular,
multiple LLMs in different roles -- controllable text generation, evaluation,
and summarization -- are introduced and validated using a systematic
methodology to enhance model performance in scholarly tasks. Output diversity
among the ensemble that generates text is obtained using different LLM
parameters, followed by an LLM acting as a judge to assess relevance, accuracy,
and coherence. Responses selected by several combining strategies are then
merged and refined through summarization and redundancy removal techniques. The
preliminary experimental validation demonstrates that the combined outputs from
the LLM ensemble improve coherence and relevance compared to individual
responses, leading to a 38% improvement in annotation quality and a 51%
reduction in content redundancy, thus highlighting the potential for automating
complex scholarly tasks while maintaining high-quality standards.

摘要：這項工作提出了一種新方法，透過大型語言模型 (LLM) 整合來增強註解書目生成。特別是，在不同角色中引入了多個 LLM -- 可控文字生成、評估和摘要 -- 並使用系統化方法驗證，以增強模型在學術任務中的效能。文字生成整合中的輸出多樣性是使用不同的 LLM 參數取得的，接著由 LLM 作為評審者來評估相關性、準確性和一致性。然後透過摘要和移除冗餘技術合併和精煉由多種組合策略選出的回應。初步實驗驗證顯示，與個別回應相比，LLM 整合的組合輸出改善了一致性和相關性，導致註解品質改善了 38%，內容冗餘減少了 51%，因此突出了在維持高品質標準的同時自動化複雜學術任務的潛力。

##### **Are LLMs Really Not Knowledgable? Mining the Submerged Knowledge in LLMs' Memory**
2412.20846v1 by Xingjian Tao, Yiwei Wang, Yujun Cai, Zhicheng Yang, Jing Tang

Large language models (LLMs) have shown promise as potential knowledge bases,
yet they often struggle with question-answering tasks and are prone to
hallucinations. While previous research attributes these issues to knowledge
gaps in the model's parameters, our investigation reveals a different
phenomenon: LLMs often retain correct knowledge even when generating incorrect
answers. Through analysis of model's internal representations, we find that
correct answers frequently appear among high-probability tokens despite not
being selected as final outputs. Based on this observation, we introduce
Hits@k, a new metric to assess knowledge retention independent of expression
accuracy. Our extensive experiments demonstrate that LLMs store significantly
more knowledge than their QA performance suggests. Building on these findings,
we develop SkipUnsure, a method to improve answer accuracy by leveraging
detected but unexpressed knowledge. Experiments on both open-domain and
specific-domain datasets show consistent improvements, with accuracy gains of
up to 11.8% on DBPedia and 6.3% on IMDB, without requiring model retraining.

摘要：大型語言模型 (LLM) 已展現作為潛在知識庫的潛力，
但它們經常難以應付問答任務，且容易出現幻覺。雖然先前的研究將這些問題歸因於模型參數中的知識差距，但我們的調查揭示了不同的現象：LLM 即使在產生不正確答案時，也經常保留正確的知識。透過分析模型的內部表示，我們發現正確答案經常出現在高機率權杖中，儘管未被選為最終輸出。基於此觀察，我們引入了 Hits@k，一種新的指標，用於評估與表達準確性無關的知識保留。我們廣泛的實驗表明，LLM 儲存的知識遠多於其問答效能所顯示的。根據這些發現，我們開發了 SkipUnsure，一種透過利用已偵測但未表達的知識來提高答案準確性的方法。在開放領域和特定領域資料集上的實驗顯示出持續的改進，在 DBPedia 上的準確度提高了 11.8%，在 IMDB 上提高了 6.3%，而無需重新訓練模型。

##### **Dual-Space Augmented Intrinsic-LoRA for Wind Turbine Segmentation**
2412.20838v1 by Shubh Singhal, Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo

Accurate segmentation of wind turbine blade (WTB) images is critical for
effective assessments, as it directly influences the performance of automated
damage detection systems. Despite advancements in large universal vision
models, these models often underperform in domain-specific tasks like WTB
segmentation. To address this, we extend Intrinsic LoRA for image segmentation,
and propose a novel dual-space augmentation strategy that integrates both
image-level and latent-space augmentations. The image-space augmentation is
achieved through linear interpolation between image pairs, while the
latent-space augmentation is accomplished by introducing a noise-based latent
probabilistic model. Our approach significantly boosts segmentation accuracy,
surpassing current state-of-the-art methods in WTB image segmentation.

摘要：風力渦輪機葉片 (WTB) 影像的準確分割對於有效的評估至關重要，因為它直接影響自動化損壞檢測系統的效能。儘管大型通用視覺模型有進展，但這些模型在領域特定的任務中，例如 WTB 分割，往往表現不佳。為了解決這個問題，我們擴展了用於影像分割的 Intrinsic LoRA，並提出了一種新穎的雙空間擴充策略，結合了影像層級和潛在空間擴充。影像空間擴充是透過影像對之間的線性插值來實現，而潛在空間擴充則是透過引入基於雜訊的潛在機率模型來達成。我們的做法大幅提升了分割的準確度，超越了 WTB 影像分割中現有的最先進方法。

##### **Disentangling Preference Representation and Text Generation for Efficient Individual Preference Alignment**
2412.20834v1 by Jianfei Zhang, Jun Bai, Bei Li, Yanmeng Wang, Rumei Li, Chenghua Lin, Wenge Rong

Aligning Large Language Models (LLMs) with general human preferences has been
proved crucial in improving the interaction quality between LLMs and human.
However, human values are inherently diverse among different individuals,
making it insufficient to align LLMs solely with general preferences. To
address this, personalizing LLMs according to individual feedback emerges as a
promising solution. Nonetheless, this approach presents challenges in terms of
the efficiency of alignment algorithms. In this work, we introduce a flexible
paradigm for individual preference alignment. Our method fundamentally improves
efficiency by disentangling preference representation from text generation in
LLMs. We validate our approach across multiple text generation tasks and
demonstrate that it can produce aligned quality as well as or better than
PEFT-based methods, while reducing additional training time for each new
individual preference by $80\%$ to $90\%$ in comparison with them.

摘要：對大型語言模型 (LLM) 與一般人類偏好進行比對，已被證實對於改善 LLM 與人類之間的互動品質至關重要。然而，人類價值觀在不同個體之間本質上是多樣化的，這使得僅對 LLM 與一般偏好進行比對是不夠的。為了解決這個問題，根據個人回饋意見對 LLM 進行個性化調整成為一個有前途的解決方案。儘管如此，這種方法在比對演算法的效率方面提出了挑戰。在這項工作中，我們引入了一個靈活的個人偏好比對範例。我們的模型透過將偏好表示與 LLM 中的文字生成區分開來，從根本上提高了效率。我們在多項文字生成任務中驗證了我們的模型，並證明它可以產生與 PEFT 為基礎的方法一樣好或更好的比對品質，同時將每個新個人偏好的額外訓練時間減少了 80% 到 90%。

##### **Fine-Tuning TransMorph with Gradient Correlation for Anatomical Alignment**
2412.20822v1 by Lukas Förner, Kartikay Tehlan, Thomas Wendler

Unsupervised deep learning is a promising method in brain MRI registration to
reduce the reliance on anatomical labels, while still achieving anatomically
accurate transformations. For the Learn2Reg2024 LUMIR challenge, we propose
fine-tuning of the pre-trained TransMorph model to improve the convergence
stability as well as the deformation smoothness. The former is achieved through
the FAdam optimizer, and consistency in structural changes is incorporated
through the addition of gradient correlation in the similarity measure,
improving anatomical alignment. The results show slight improvements in the
Dice and HdDist95 scores, and a notable reduction in the NDV compared to the
baseline TransMorph model. These are also confirmed by inspecting the
boundaries of the tissue. Our proposed method highlights the effectiveness of
including Gradient Correlation to achieve smoother and structurally consistent
deformations for interpatient brain MRI registration.

摘要：無監督深度學習是一種腦部 MRI 配準中很有前景的方法，它可以減少對解剖標籤的依賴，同時仍能實現解剖學上準確的轉換。對於 Learn2Reg2024 LUMIR 挑戰，我們建議微調預訓練的 TransMorph 模型，以改善收斂穩定性以及變形平滑度。前者是透過 FAdam 最佳化器實現的，而結構變化的一致性則透過在相似性測量中加入梯度相關性來納入，進而改善解剖對齊。結果顯示，與基準 TransMorph 模型相比，Dice 和 HdDist95 分數略有改善，而 NDV 則顯著降低。這些也透過檢查組織的邊界得到證實。我們提出的方法突顯了納入梯度相關性以實現更平滑且結構一致的變形，對於患者間腦部 MRI 配準的有效性。

##### **Enhancing Multimodal Emotion Recognition through Multi-Granularity Cross-Modal Alignment**
2412.20821v1 by Xuechen Wang, Shiwan Zhao, Haoqin Sun, Hui Wang, Jiaming Zhou, Yong Qin

Multimodal emotion recognition (MER), leveraging speech and text, has emerged
as a pivotal domain within human-computer interaction, demanding sophisticated
methods for effective multimodal integration. The challenge of aligning
features across these modalities is significant, with most existing approaches
adopting a singular alignment strategy. Such a narrow focus not only limits
model performance but also fails to address the complexity and ambiguity
inherent in emotional expressions. In response, this paper introduces a
Multi-Granularity Cross-Modal Alignment (MGCMA) framework, distinguished by its
comprehensive approach encompassing distribution-based, instance-based, and
token-based alignment modules. This framework enables a multi-level perception
of emotional information across modalities. Our experiments on IEMOCAP
demonstrate that our proposed method outperforms current state-of-the-art
techniques.

摘要：多模态情感识别（MER）利用语音和文本，已成为人机交互中至关重要的领域，需要复杂的方法来实现有效的多模态集成。跨这些模态对齐特征的挑战是重大的，大多数现有方法采用单一对齐策略。如此狭窄的焦点不仅限制了模型性能，而且无法解决情感表达中固有的复杂性和模糊性。对此，本文介绍了一个多粒度跨模态对齐（MGCMA）框架，其特点是其全面的方法，包括基于分布、基于实例和基于令牌的对齐模块。该框架实现了跨模态情感信息的多分辨率感知。我们在 IEMOCAP 上的实验表明，我们提出的方法优于当前最先进的技术。

##### **Length-Aware DETR for Robust Moment Retrieval**
2412.20816v1 by Seojeong Park, Jiho Choi, Kyungjune Baek, Hyunjung Shim

Video Moment Retrieval (MR) aims to localize moments within a video based on
a given natural language query. Given the prevalent use of platforms like
YouTube for information retrieval, the demand for MR techniques is
significantly growing. Recent DETR-based models have made notable advances in
performance but still struggle with accurately localizing short moments.
Through data analysis, we identified limited feature diversity in short
moments, which motivated the development of MomentMix. MomentMix employs two
augmentation strategies: ForegroundMix and BackgroundMix, each enhancing the
feature representations of the foreground and background, respectively.
Additionally, our analysis of prediction bias revealed that short moments
particularly struggle with accurately predicting their center positions of
moments. To address this, we propose a Length-Aware Decoder, which conditions
length through a novel bipartite matching process. Our extensive studies
demonstrate the efficacy of our length-aware approach, especially in localizing
short moments, leading to improved overall performance. Our method surpasses
state-of-the-art DETR-based methods on benchmark datasets, achieving the
highest R1 and mAP on QVHighlights and the highest R1@0.7 on TACoS and
Charades-STA (such as a 2.46% gain in R1@0.7 and a 2.57% gain in mAP average
for QVHighlights). The code is available at
https://github.com/sjpark5800/LA-DETR.

摘要：影片片段檢索 (MR) 旨在根據給定的自然語言查詢，在影片中找出片段。由於 YouTube 等平台普遍用於資訊檢索，對 MR 技術的需求大幅增加。最近基於 DETR 的模型在效能方面有顯著進步，但仍難以準確找出短片段。透過資料分析，我們發現短片段中的特徵多樣性有限，這促成了 MomentMix 的開發。MomentMix 採用兩種擴增策略：前景混合和背景混合，分別增強前景和背景的特徵表示。此外，我們對預測偏差的分析顯示，短片段特別難以準確預測其片段中心位置。為了解決這個問題，我們提出一個長度感知解碼器，透過新穎的二部匹配程序來設定長度。我們廣泛的研究證明了我們長度感知方法的效力，特別是在找出短片段時，進而改善整體效能。我們的模型在基準資料集上超越了最先進的基於 DETR 的方法，在 QVHighlights 上達到了最高的 R1 和 mAP，在 TACoS 和 Charades-STA 上達到了最高的 R1@0.7（例如在 QVHighlights 上 R1@0.7 提升了 2.46%，mAP 平均提升了 2.57%）。程式碼可於 https://github.com/sjpark5800/LA-DETR 取得。

##### **A Tale of Two Imperatives: Privacy and Explainability**
2412.20798v1 by Supriya Manna, Niladri Sett

Deep learning's preponderance across scientific domains has reshaped
high-stakes decision-making, making it essential to follow rigorous operational
frameworks that include both Right-to-Privacy (RTP) and Right-to-Explanation
(RTE). This paper examines the complexities of combining these two
requirements. For RTP, we focus on 'Differentially privacy' (DP), which is
considered the current gold standard for privacy-preserving machine learning
due to its strong quantitative guarantee of privacy. For RTE, we focus on
post-hoc explainers: they are the go-to option for model auditing as they
operate independently of model training. We formally investigate (DP) models
and various commonly-used post-hoc explainers: how to evaluate these explainers
subject to RTP, and analyze the intrinsic interactions between DP models and
these explainers. Furthermore, our work throws light on how RTP and RTE can be
effectively combined in high-stakes applications. Our study concludes by
outlining an industrial software pipeline, with the example of a wildly used
use-case, that respects both RTP and RTE requirements.

摘要：深度學習在科學領域的盛行已重塑了高風險決策制定，因此遵循嚴謹的操作框架至關重要，其中包括隱私權 (RTP) 和解釋權 (RTE)。本文探討了結合這兩個要求的複雜性。對於 RTP，我們專注於「差分隱私」(DP)，由於其對隱私的強有力的量化保證，因此被認為是隱私保護機器學習的當前黃金標準。對於 RTE，我們專注於事後解釋器：由於它們獨立於模型訓練，因此它們是模型稽核的首選。我們正式研究了 (DP) 模型和各種常用的事後解釋器：如何根據 RTP 評估這些解釋器，並分析 DP 模型和這些解釋器之間的內在交互作用。此外，我們的研究闡明了如何在高風險應用中有效結合 RTP 和 RTE。我們的研究最後概述了一個產業軟體管道，以一個廣泛使用的用例為例，它符合 RTP 和 RTE 要求。

##### **Frequency-Masked Embedding Inference: A Non-Contrastive Approach for Time Series Representation Learning**
2412.20790v1 by En Fu, Yanyan Hu

Contrastive learning underpins most current self-supervised time series
representation methods. The strategy for constructing positive and negative
sample pairs significantly affects the final representation quality. However,
due to the continuous nature of time series semantics, the modeling approach of
contrastive learning struggles to accommodate the characteristics of time
series data. This results in issues such as difficulties in constructing hard
negative samples and the potential introduction of inappropriate biases during
positive sample construction. Although some recent works have developed several
scientific strategies for constructing positive and negative sample pairs with
improved effectiveness, they remain constrained by the contrastive learning
framework. To fundamentally overcome the limitations of contrastive learning,
this paper introduces Frequency-masked Embedding Inference (FEI), a novel
non-contrastive method that completely eliminates the need for positive and
negative samples. The proposed FEI constructs 2 inference branches based on a
prompting strategy: 1) Using frequency masking as prompts to infer the
embedding representation of the target series with missing frequency bands in
the embedding space, and 2) Using the target series as prompts to infer its
frequency masking embedding. In this way, FEI enables continuous semantic
relationship modeling for time series. Experiments on 8 widely used time series
datasets for classification and regression tasks, using linear evaluation and
end-to-end fine-tuning, show that FEI significantly outperforms existing
contrastive-based methods in terms of generalization. This study provides new
insights into self-supervised representation learning for time series. The code
is available at
https://github.com/USTBInnovationPark/Frequency-masked-Embedding-Inference.

摘要：對比學習支撐了目前大多數的自監督時間序列表示方法。建構正負樣本對的策略會顯著影響最終的表示品質。然而，由於時間序列語意的連續性，對比學習的建模方法難以適應時間序列資料的特性。這會造成一些問題，例如建構困難負樣本的困難，以及在建構正樣本期間引入不適當偏差的可能性。儘管最近的一些研究已經開發出幾種科學策略來建構正負樣本對，並提高了有效性，但它們仍然受到對比學習架構的限制。為了從根本上克服對比學習的限制，本文介紹了頻率遮罩嵌入推論 (FEI)，這是一種新的非對比方法，完全消除了對正負樣本的需求。所提出的 FEI 基於提示策略建構了 2 個推論分支：1) 使用頻率遮罩作為提示，在嵌入空間中推論缺少頻率頻段的目標序列的嵌入表示，以及 2) 使用目標序列作為提示，推論其頻率遮罩嵌入。藉由這種方式，FEI 能夠為時間序列建構連續的語意關係模型。在 8 個廣泛使用於分類和回歸任務的時間序列資料集上進行的實驗，使用線性評估和端到端微調，顯示 FEI 在泛化方面顯著優於現有的基於對比的方法。這項研究為時間序列的自監督表示學習提供了新的見解。程式碼可在 https://github.com/USTBInnovationPark/Frequency-masked-Embedding-Inference 取得。

##### **SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity**
2412.20787v1 by Pengfei Jing, Mengyun Tang, Xiaorong Shi, Xing Zheng, Sen Nie, Shi Wu, Yong Yang, Xiapu Luo

Evaluating Large Language Models (LLMs) is crucial for understanding their
capabilities and limitations across various applications, including natural
language processing and code generation. Existing benchmarks like MMLU, C-Eval,
and HumanEval assess general LLM performance but lack focus on specific expert
domains such as cybersecurity. Previous attempts to create cybersecurity
datasets have faced limitations, including insufficient data volume and a
reliance on multiple-choice questions (MCQs). To address these gaps, we propose
SecBench, a multi-dimensional benchmarking dataset designed to evaluate LLMs in
the cybersecurity domain. SecBench includes questions in various formats (MCQs
and short-answer questions (SAQs)), at different capability levels (Knowledge
Retention and Logical Reasoning), in multiple languages (Chinese and English),
and across various sub-domains. The dataset was constructed by collecting
high-quality data from open sources and organizing a Cybersecurity Question
Design Contest, resulting in 44,823 MCQs and 3,087 SAQs. Particularly, we used
the powerful while cost-effective LLMs to (1). label the data and (2).
constructing a grading agent for automatic evaluation of SAQs.Benchmarking
results on 13 SOTA LLMs demonstrate the usability of SecBench, which is
arguably the largest and most comprehensive benchmark dataset for LLMs in
cybersecurity. More information about SecBench can be found at our website, and
the dataset can be accessed via the artifact link.

摘要：評估大型語言模型 (LLM) 對於了解其在各種應用中的能力和限制至關重要，包括自然語言處理和程式碼生成。現有的基準測試，例如 MMLU、C-Eval 和 HumanEval，可以評估 LLM 的一般效能，但缺乏對特定專家領域（例如網路安全）的關注。以前建立網路安全資料集的嘗試都面臨限制，包括資料量不足和依賴於多選題 (MCQ)。為了解決這些差距，我們提出 SecBench，這是一個多維度的基準測試資料集，旨在評估網路安全領域的 LLM。SecBench 包含各種格式（MCQ 和簡答題 (SAQ)）的問題，具有不同的能力層級（知識保留和邏輯推理），使用多種語言（中文和英文），並涵蓋各種子領域。該資料集是透過從開放來源收集高品質資料和組織網路安全問題設計競賽而建構的，產生了 44,823 個 MCQ 和 3,087 個 SAQ。特別是，我們使用功能強大且經濟實惠的 LLM 來 (1)。標記資料和 (2)。建構一個評分代理，用於自動評估 SAQ。13 個 SOTA LLM 的基準測試結果證明了 SecBench 的可用性，這可以說是網路安全領域 LLM 中最大且最全面的基準測試資料集。可以在我們的網站上找到有關 SecBench 的更多資訊，並且可以透過人工製品連結存取資料集。

##### **Sample Correlation for Fingerprinting Deep Face Recognition**
2412.20768v1 by Jiyang Guan, Jian Liang, Yanbo Wang, Ran He

Face recognition has witnessed remarkable advancements in recent years,
thanks to the development of deep learning techniques.However, an off-the-shelf
face recognition model as a commercial service could be stolen by model
stealing attacks, posing great threats to the rights of the model owner.Model
fingerprinting, as a model stealing detection method, aims to verify whether a
suspect model is stolen from the victim model, gaining more and more attention
nowadays.Previous methods always utilize transferable adversarial examples as
the model fingerprint, but this method is known to be sensitive to adversarial
defense and transfer learning techniques.To address this issue, we consider the
pairwise relationship between samples instead and propose a novel yet simple
model stealing detection method based on SAmple Correlation (SAC).Specifically,
we present SAC-JC that selects JPEG compressed samples as model inputs and
calculates the correlation matrix among their model outputs.Extensive results
validate that SAC successfully defends against various model stealing attacks
in deep face recognition, encompassing face verification and face emotion
recognition, exhibiting the highest performance in terms of AUC, p-value and F1
score.Furthermore, we extend our evaluation of SAC-JC to object recognition
datasets including Tiny-ImageNet and CIFAR10, which also demonstrates the
superior performance of SAC-JC to previous methods.The code will be available
at \url{https://github.com/guanjiyang/SAC_JC}.

摘要：<paragraph>人臉辨識在近年來見證了顯著的進展，
這要歸功於深度學習技術的發展。然而，現成的
人臉辨識模型作為商業服務可能會被模型
竊取攻擊竊取，對模型所有者的權利構成極大的威脅。模型
指紋作為一種模型竊取檢測方法，旨在驗證
可疑模型是否從受害者模型中竊取，現今獲得越來越多關注。先前的
方法總是利用可轉移對抗範例作為模型指紋，但已知這種方法對對抗
防禦和遷移學習技術很敏感。為了解決這個問題，我們考慮
樣本之間成對的關係，並提出一個基於 SAmple Correlation (SAC) 的新穎且簡單
的模型竊取檢測方法。具體來說，我們提出 SAC-JC，它選擇 JPEG 壓縮樣本作為模型輸入，
並計算其模型輸出之間的相關矩陣。廣泛的結果
驗證了 SAC 成功防禦了深度人臉辨識中的各種模型竊取攻擊，
包括人臉驗證和人臉情緒辨識，在 AUC、p 值和 F1
分數方面表現出最高的效能。此外，我們將 SAC-JC 的評估擴展到物件辨識
資料集，包括 Tiny-ImageNet 和 CIFAR10，這也證明了 SAC-JC 優於先前方法的
卓越效能。程式碼將在
\url{https://github.com/guanjiyang/SAC_JC} 提供。</paragraph>

##### **KeyGS: A Keyframe-Centric Gaussian Splatting Method for Monocular Image Sequences**
2412.20767v1 by Keng-Wei Chang, Zi-Ming Wang, Shang-Hong Lai

Reconstructing high-quality 3D models from sparse 2D images has garnered
significant attention in computer vision. Recently, 3D Gaussian Splatting
(3DGS) has gained prominence due to its explicit representation with efficient
training speed and real-time rendering capabilities. However, existing methods
still heavily depend on accurate camera poses for reconstruction. Although some
recent approaches attempt to train 3DGS models without the
Structure-from-Motion (SfM) preprocessing from monocular video datasets, these
methods suffer from prolonged training times, making them impractical for many
applications.
  In this paper, we present an efficient framework that operates without any
depth or matching model. Our approach initially uses SfM to quickly obtain
rough camera poses within seconds, and then refines these poses by leveraging
the dense representation in 3DGS. This framework effectively addresses the
issue of long training times. Additionally, we integrate the densification
process with joint refinement and propose a coarse-to-fine frequency-aware
densification to reconstruct different levels of details. This approach
prevents camera pose estimation from being trapped in local minima or drifting
due to high-frequency signals. Our method significantly reduces training time
from hours to minutes while achieving more accurate novel view synthesis and
camera pose estimation compared to previous methods.

摘要：<paragraph>從稀疏的 2D 影像重建高品質的 3D 模型在電腦視覺中備受關注。最近，3D 高斯潑灑 (3DGS) 因其明確的表示方式、高效的訓練速度和即時渲染能力而備受重視。然而，現有方法仍然高度依賴於準確的相機姿勢進行重建。儘管一些最近的方法嘗試在沒有單眼影片資料集的結構運動 (SfM) 預處理下訓練 3DGS 模型，但這些方法的訓練時間過長，這使得它們在許多應用中不切實際。
  在本文中，我們提出一個不使用任何深度或匹配模型的有效框架。我們的做法最初使用 SfM 在幾秒鐘內快速取得粗略的相機姿勢，然後利用 3DGS 中的密集表示來優化這些姿勢。此框架有效地解決了訓練時間過長的問題。此外，我們將致密化過程與聯合優化整合起來，並提出一個粗到細的頻率感知致密化來重建不同層級的細節。這種方法可以防止相機姿勢估計因高頻率訊號而受困於局部最小值或漂移。與以往的方法相比，我們的做法將訓練時間從數小時大幅縮短至數分鐘，同時實現更準確的新視圖合成和相機姿勢估計。</paragraph>

##### **Attributing Culture-Conditioned Generations to Pretraining Corpora**
2412.20760v1 by Huihan Li, Arnav Goel, Keyu He, Xiang Ren

In open-ended generative tasks like narrative writing or dialogue, large
language models often exhibit cultural biases, showing limited knowledge and
generating templated outputs for less prevalent cultures. Recent works show
that these biases may stem from uneven cultural representation in pretraining
corpora. This work investigates how pretraining leads to biased
culture-conditioned generations by analyzing how models associate entities with
cultures based on pretraining data patterns. We propose the MEMOed framework
(MEMOrization from pretraining document) to determine whether a generation for
a culture arises from memorization. Using MEMOed on culture-conditioned
generations about food and clothing for 110 cultures, we find that
high-frequency cultures in pretraining data yield more generations with
memorized symbols, while some low-frequency cultures produce none.
Additionally, the model favors generating entities with extraordinarily high
frequency regardless of the conditioned culture, reflecting biases toward
frequent pretraining terms irrespective of relevance. We hope that the MEMOed
framework and our insights will inspire more works on attributing model
performance on pretraining data.

摘要：在開放式生成任務（例如敘事寫作或對話）中，大型語言模型經常表現出文化偏見，顯示出有限的知識，並為較不流行的文化產生範本化的輸出。最近的研究顯示，這些偏見可能源自預訓練語料庫中不均衡的文化表徵。本研究探討預訓練如何導致有偏見的文化條件生成，方法是分析模型如何根據預訓練數據模式將實體與文化聯繫起來。我們提出 MEMOed 架構（從預訓練文件中記憶），以確定針對某種文化的生成是否源自記憶。我們對 110 種文化的飲食和服裝進行文化條件生成，並使用 MEMOed 發現，預訓練數據中高頻率的文化會產生更多具有記憶符號的生成，而某些低頻率的文化則不會產生任何生成。此外，該模型傾向於生成頻率極高的實體，而不管條件文化如何，這反映出對頻繁預訓練術語的偏見，而不管其相關性如何。我們希望 MEMOed 架構和我們的見解能激發更多關於將模型效能歸因於預訓練數據的研究。

##### **Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks**
2412.20744v1 by Abhinav Roy, Bhavesh Gyanchandani, Aditya Oza, Abhishek Sharma

Parkinson's Disease (PD) is a degenerative neurological disorder that impairs
motor and non-motor functions, significantly reducing quality of life and
increasing mortality risk. Early and accurate detection of PD progression is
vital for effective management and improved patient outcomes. Current
diagnostic methods, however, are often costly, time-consuming, and require
specialized equipment and expertise. This work proposes an innovative approach
to predicting PD progression using regression methods, Long Short-Term Memory
(LSTM) networks, and Kolmogorov Arnold Networks (KAN). KAN, utilizing
spline-parametrized univariate functions, allows for dynamic learning of
activation patterns, unlike traditional linear models.
  The Movement Disorder Society-Sponsored Revision of the Unified Parkinson's
Disease Rating Scale (MDS-UPDRS) is a comprehensive tool for evaluating PD
symptoms and is commonly used to measure disease progression. Additionally,
protein or peptide abnormalities are linked to PD onset and progression.
Identifying these associations can aid in predicting disease progression and
understanding molecular changes.
  Comparing multiple models, including LSTM and KAN, this study aims to
identify the method that delivers the highest metrics. The analysis reveals
that KAN, with its dynamic learning capabilities, outperforms other approaches
in predicting PD progression. This research highlights the potential of AI and
machine learning in healthcare, paving the way for advanced computational
models to enhance clinical predictions and improve patient care and treatment
strategies in PD management.

摘要：帕金森氏症 (PD) 是一種神經退化性疾病，會損害運動和非運動功能，嚴重降低生活品質並增加死亡風險。早期且準確檢測 PD 進程對於有效管理和改善患者預後至關重要。然而，目前的診斷方法通常成本高昂、耗時且需要專業設備和專業知識。這項研究提出了一種創新的方法，使用迴歸方法、長短期記憶 (LSTM) 網路和 Kolmogorov Arnold 網路 (KAN) 來預測 PD 進程。KAN 利用樣條參數化的單變量函數，可以動態學習激活模式，這與傳統線性模型不同。運動障礙協會贊助的統一帕金森氏症評分量表 (MDS-UPDRS) 是評估 PD 症狀的綜合工具，通常用於測量疾病進程。此外，蛋白質或胜肽異常與 PD 發作和進程有關。找出這些關聯可以幫助預測疾病進程並了解分子變化。這項研究比較了包括 LSTM 和 KAN 在內的多種模型，旨在找出提供最高指標的方法。分析顯示，具有動態學習能力的 KAN 在預測 PD 進程方面優於其他方法。這項研究突顯了 AI 和機器學習在醫療保健中的潛力，為先進的計算模型鋪路，以增強臨床預測並改善 PD 管理中的患者照護和治療策略。

##### **Depression and Anxiety Prediction Using Deep Language Models and Transfer Learning**
2412.20741v1 by Tomasz Rutowski, Elizabeth Shriberg, Amir Harati, Yang Lu, Piotr Chlebek, Ricardo Oliveira

Digital screening and monitoring applications can aid providers in the
management of behavioral health conditions. We explore deep language models for
detecting depression, anxiety, and their co-occurrence from conversational
speech collected during 16k user interactions with an application. Labels come
from PHQ-8 and GAD-7 results also collected by the application. We find that
results for binary classification range from 0.86 to 0.79 AUC, depending on
condition and co-occurrence. Best performance is achieved when a user has
either both or neither condition, and we show that this result is not
attributable to data skew. Finally, we find evidence suggesting that underlying
word sequence cues may be more salient for depression than for anxiety.

摘要：數位篩檢和監控應用程式能協助醫療保健提供者管理行為健康狀況。我們探索深度語言模型，以從 16k 使用者與應用程式的對話中偵測憂鬱症、焦慮症及其共病。標籤來自應用程式同時收集的 PHQ-8 和 GAD-7 結果。我們發現二元分類的結果範圍從 0.86 到 0.79 AUC，取決於狀況和共病。當使用者同時有或沒有這兩種狀況時，會達到最佳效能，而我們顯示這個結果並非歸因於資料偏差。最後，我們發現證據顯示，潛在的詞彙順序線索可能對憂鬱症比對焦慮症更顯著。

##### **HUNYUANPROVER: A Scalable Data Synthesis Framework and Guided Tree Search for Automated Theorem Proving**
2412.20735v1 by Yang Li, Dong Du, Linfeng Song, Chen Li, Weikang Wang, Tao Yang, Haitao Mi

We introduce HunyuanProver, an language model finetuned from the Hunyuan 7B
for interactive automatic theorem proving with LEAN4. To alleviate the data
sparsity issue, we design a scalable framework to iterative synthesize data
with low cost. Besides, guided tree search algorithms are designed to enable
effective ``system 2 thinking`` of the prover. HunyuanProver achieves
state-of-the-art (SOTA) performances on major benchmarks. Specifically, it
achieves a pass of 68.4% on the miniF2F-test compared to 65.9%, the current
SOTA results. It proves 4 IMO statements (imo_1960_p2, imo_1962_p2},
imo_1964_p2 and imo_1983_p6) in miniF2F-test. To benefit the community, we will
open-source a dataset of 30k synthesized instances, where each instance
contains the original question in natural language, the converted statement by
autoformalization, and the proof by HunyuanProver.

摘要：<paragraph>我們介紹 HunyuanProver，一種從 Hunyuan 7B 微調而來的語言模型，用於與 LEAN4 進行互動式自動定理證明。為了減輕數據稀疏性問題，我們設計了一個可擴充框架，以低成本反覆合成數據。此外，我們設計了引導樹搜尋演算法，以實現證明者的有效「系統 2 思考」。HunyuanProver 在主要基準測試中取得了最先進 (SOTA) 的表現。具體來說，它在 miniF2F 測試中獲得了 68.4% 的通過率，而目前 SOTA 的結果為 65.9%。它在 miniF2F 測試中證明了 4 個 IMO 陳述（imo_1960_p2、imo_1962_p2、imo_1964_p2 和 imo_1983_p6）。為了造福社群，我們將開放原始碼一個包含 30k 個合成實例的資料集，其中每個實例都包含自然語言中的原始問題、自動形式化的轉換陳述，以及 HunyuanProver 的證明。</paragraph>

##### **M$^3$oralBench: A MultiModal Moral Benchmark for LVLMs**
2412.20718v1 by Bei Yan, Jie Zhang, Zhiyuan Chen, Shiguang Shan, Xilin Chen

Recently, large foundation models, including large language models (LLMs) and
large vision-language models (LVLMs), have become essential tools in critical
fields such as law, finance, and healthcare. As these models increasingly
integrate into our daily life, it is necessary to conduct moral evaluation to
ensure that their outputs align with human values and remain within moral
boundaries. Previous works primarily focus on LLMs, proposing moral datasets
and benchmarks limited to text modality. However, given the rapid development
of LVLMs, there is still a lack of multimodal moral evaluation methods. To
bridge this gap, we introduce M$^3$oralBench, the first MultiModal Moral
Benchmark for LVLMs. M$^3$oralBench expands the everyday moral scenarios in
Moral Foundations Vignettes (MFVs) and employs the text-to-image diffusion
model, SD3.0, to create corresponding scenario images. It conducts moral
evaluation across six moral foundations of Moral Foundations Theory (MFT) and
encompasses tasks in moral judgement, moral classification, and moral response,
providing a comprehensive assessment of model performance in multimodal moral
understanding and reasoning. Extensive experiments on 10 popular open-source
and closed-source LVLMs demonstrate that M$^3$oralBench is a challenging
benchmark, exposing notable moral limitations in current models. Our benchmark
is publicly available.

摘要：最近，包括大型语言模型 (LLM) 和大型视觉语言模型 (LVLMs) 在内的大型基础模型已成为法律、金融和医疗保健等关键领域的必要工具。随着这些模型日益融入我们的日常生活，有必要进行道德评估，以确保其输出与人类价值观一致并保持在道德界限内。以前的工作主要集中在 LLM 上，提出了仅限于文本模式的道德数据集和基准。然而，鉴于 LVLMs 的快速发展，仍然缺乏多模态道德评估方法。为了弥补这一差距，我们引入了 M$^3$oralBench，这是第一个针对 LVLMs 的多模态道德基准。M$^3$oralBench 扩展了道德基础小插图 (MFV) 中的日常道德场景，并采用文本到图像扩散模型 SD3.0 来创建相应的场景图像。它根据道德基础理论 (MFT) 的六个道德基础进行道德评估，并包含道德判断、道德分类和道德反应的任务，对模型在多模态道德理解和推理方面的性能进行了全面评估。对 10 个流行的开源和闭源 LVLMs 的广泛实验表明，M$^3$oralBench 是一个具有挑战性的基准，揭示了当前模型中明显的道德限制。我们的基准是公开的。

##### **ChartAdapter: Large Vision-Language Model for Chart Summarization**
2412.20715v1 by Peixin Xu, Yujuan Ding, Wenqi Fan

Chart summarization, which focuses on extracting key information from charts
and interpreting it in natural language, is crucial for generating and
delivering insights through effective and accessible data analysis. Traditional
methods for chart understanding and summarization often rely on multi-stage
pipelines, which may produce suboptimal semantic alignment between visual and
textual information. In comparison, recently developed LLM-based methods are
more dependent on the capability of foundation images or languages, while
ignoring the characteristics of chart data and its relevant challenges. To
address these limitations, we propose ChartAdapter, a novel lightweight
transformer module designed to bridge the gap between charts and textual
summaries. ChartAdapter employs learnable query vectors to extract implicit
semantics from chart data and incorporates a cross-modal alignment projector to
enhance vision-to-language generative learning. By integrating ChartAdapter
with an LLM, we enable end-to-end training and efficient chart summarization.
To further enhance the training, we introduce a three-stage hierarchical
training procedure and develop a large-scale dataset specifically curated for
chart summarization, comprising 190,618 samples. Experimental results on the
standard Chart-to-Text testing set demonstrate that our approach significantly
outperforms existing methods, including state-of-the-art models, in generating
high-quality chart summaries. Ablation studies further validate the
effectiveness of key components in ChartAdapter. This work highlights the
potential of tailored LLM-based approaches to advance chart understanding and
sets a strong foundation for future research in this area.

摘要：圖表摘要著重於從圖表中萃取關鍵資訊，並以自然語言加以詮釋，對於透過有效且易於取得的資料分析來產生並傳遞見解至關重要。傳統的圖表理解與摘要方法通常仰賴多階段管線，這可能會在視覺與文字資訊之間產生次佳的語意對齊。相較之下，最近開發的 LLM 為基礎的方法更依賴於基礎影像或語言的能力，同時忽略圖表資料的特性及其相關挑戰。為了解決這些限制，我們提出 ChartAdapter，這是一個新穎的輕量級轉換器模組，旨在橋接圖表和文字摘要之間的差距。ChartAdapter 採用可學習的查詢向量從圖表資料中萃取隱含語意，並結合跨模態對齊投影機來增強視覺到語言的生成式學習。透過將 ChartAdapter 與 LLM 整合，我們能夠進行端到端的訓練和高效的圖表摘要。為了進一步增強訓練，我們引入了三階段階層式訓練程序，並開發了一個專門為圖表摘要整理的大規模資料集，包含 190,618 個樣本。在標準 Chart-to-Text 測試集上的實驗結果證明，我們的做法在產生高品質圖表摘要方面顯著優於現有方法，包括最先進的模型。消融研究進一步驗證了 ChartAdapter 中關鍵組件的有效性。這項工作突顯了客製化 LLM 為基礎的方法在促進圖表理解方面的潛力，並為此領域的未來研究奠定了堅實的基礎。

##### **UBER: Uncertainty-Based Evolution with Large Language Models for Automatic Heuristic Design**
2412.20694v1 by Zijie Chen, Zhanchao Zhou, Yu Lu, Renjun Xu, Lili Pan, Zhenzhong Lan

NP-hard problem-solving traditionally relies on heuristics, but manually
crafting effective heuristics for complex problems remains challenging. While
recent work like FunSearch has demonstrated that large language models (LLMs)
can be leveraged for heuristic design in evolutionary algorithm (EA)
frameworks, their potential is not fully realized due to its deficiency in
exploitation and exploration. We present UBER (Uncertainty-Based Evolution for
Refinement), a method that enhances LLM+EA methods for automatic heuristic
design by integrating uncertainty on top of the FunSearch framework. UBER
introduces two key innovations: an Uncertainty-Inclusive Evolution Process
(UIEP) for adaptive exploration-exploitation balance, and a principled
Uncertainty-Inclusive Island Reset (UIIS) strategy for maintaining population
diversity. Through extensive experiments on challenging NP-complete problems,
UBER demonstrates significant improvements over FunSearch. Our work provides a
new direction for the synergy of LLMs and EA, advancing the field of automatic
heuristic design.

摘要：NP 難度問題求解傳統上依賴啟發法，但人工製作複雜問題的有效啟發法仍然具有挑戰性。雖然像 FunSearch 這樣的近期工作已經證明，大型語言模型 (LLM) 可以用於演化演算法 (EA) 框架中的啟發式設計，但由於其在利用和探索方面的不足，它們的潛力並未得到充分發揮。我們提出了 UBER（基於不確定性的精煉演化），這是一種通過在 FunSearch 框架之上整合不確定性來增強 LLM+EA 方法以進行自動啟發式設計的方法。UBER 引入了兩項關鍵創新：用於自適應探索-利用平衡的不確定性包容演化過程 (UIEP)，以及用於維持種群多樣性的基於原則的不確定性包容島嶼重置 (UIIS) 策略。通過對具有挑戰性的 NP 完全問題進行廣泛的實驗，UBER 展示了比 FunSearch 更顯著的改進。我們的研究為 LLM 和 EA 的協同作用提供了新的方向，推動了自動啟發式設計領域的發展。

##### **Align Attention Heads Before Merging Them: An Effective Way for Converting MHA to GQA**
2412.20677v1 by Qingyun Jin, Xiaohui Song, Feng Zhou, Zengchang Qin

Large language models have been shown to perform well on a variety of natural
language processing problems. However, as the model size and the input
sequence's length increase, the rapid increase of KV Cache significantly slows
down inference speed. Therefore GQA model, as an alternative to MHA model, has
been widely introduced into LLMs. In this work, we propose a low-cost method
for pruning MHA models into GQA models with any compression ratio of key-value
heads. Our method is based on $\mathit{L_0}$ masks to gradually remove
redundant parameters. In addition, we apply orthogonal transformations to
attention heads without changing the model to increase similarity between
attention heads before pruning training, in order to further improve
performance of the model. Our method can be compatible with rotary position
embedding (RoPE), which means the model after training can be fully adapted to
the mainstream standard GQA framework. Experiments demonstrate that our
strategy can compress up to 87.5% of key-value heads of the LLaMA2-7B model
without too much performance degradation, just achieved through supervised
fine-tuning.

摘要：大型語言模型已顯示在各種自然語言處理問題中表現良好。然而，隨著模型大小和輸入序列長度的增加，KV 快取的快速增加顯著降低了推理速度。因此，GQA 模型作為 MHA 模型的替代品，已被廣泛引入 LLM。在這項工作中，我們提出了一種低成本的方法，將 MHA 模型剪枝成具有任何鍵值頭壓縮率的 GQA 模型。我們的模型基於 $\mathit{L_0}$ 掩碼，以逐漸移除多餘的參數。此外，我們在不改變模型的情況下將正交變換應用於注意力頭，以在剪枝訓練前增加注意力頭之間的相似度，以進一步提高模型的效能。我們的模型可以與旋轉位置嵌入 (RoPE) 相容，這表示訓練後的模型可以完全適應主流標準 GQA 框架。實驗證明，我們的策略可以壓縮 LLaMA2-7B 模型中高達 87.5% 的鍵值頭，而不會造成過多的效能下降，只需透過監督微調即可達成。

##### **Enhancing Table Recognition with Vision LLMs: A Benchmark and Neighbor-Guided Toolchain Reasoner**
2412.20662v1 by Yitong Zhou, Mingyue Cheng, Qingyang Mao, Qi Liu, Feiyang Xu, Xin Li, Enhong Chen

Pre-trained foundation models have recently significantly progressed in
structured table understanding and reasoning. However, despite advancements in
areas such as table semantic understanding and table question answering,
recognizing the structure and content of unstructured tables using Vision Large
Language Models (VLLMs) remains under-explored. In this work, we address this
research gap by employing VLLMs in a training-free reasoning paradigm. First,
we design a benchmark with various hierarchical dimensions relevant to table
recognition. Subsequently, we conduct in-depth evaluations using pre-trained
VLLMs, finding that low-quality image input is a significant bottleneck in the
recognition process. Drawing inspiration from these findings, we propose the
Neighbor-Guided Toolchain Reasoner (NGTR) framework, which is characterized by
integrating multiple lightweight models for low-level visual processing
operations aimed at mitigating issues with low-quality input images.
Specifically, we utilize a neighbor retrieval mechanism to guide the generation
of multiple tool invocation plans, transferring tool selection experiences from
similar neighbors to the given input, thereby facilitating suitable tool
selection. Additionally, we introduce a reflection module to supervise the tool
invocation process. Extensive experiments on public table recognition datasets
demonstrate that our approach significantly enhances the recognition
capabilities of the vanilla VLLMs. We believe that the designed benchmark and
the proposed NGTR framework could provide an alternative solution in table
recognition.

摘要：预训练基础模型最近在结构化表格理解和推理方面取得了显著进展。然而，尽管在表格语义理解和表格问题解答等领域取得了进步，但使用视觉大语言模型 (VLLM) 识别非结构化表格的结构和内容仍然是探索不足的领域。在这项工作中，我们通过在无训练推理范式中使用 VLLM 来解决这一研究空白。首先，我们设计了一个基准，其中包含与表格识别相关的各种层次维度。随后，我们使用预训练的 VLLM 进行了深入评估，发现低质量的图像输入是识别过程中的一个重大瓶颈。受这些发现的启发，我们提出了邻域引导工具链推理器 (NGTR) 框架，其特点是集成了多个轻量级模型，用于低级视觉处理操作，旨在减轻低质量输入图像的问题。具体来说，我们利用邻域检索机制来指导生成多个工具调用计划，将工具选择经验从相似的邻域转移到给定的输入，从而促进合适的工具选择。此外，我们引入了一个反射模块来监督工具调用过程。在公共表格识别数据集上的大量实验表明，我们的方法显著增强了香草 VLLM 的识别能力。我们相信，设计的基准和提出的 NGTR 框架可以在表格识别中提供一种替代解决方案。

##### **Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis**
2412.20651v1 by Yousef Yeganeh, Ioannis Charisiadis, Marta Hasny, Martin Hartenberger, Björn Ommer, Nassir Navab, Azade Farshad, Ehsan Adeli

Scaling by training on large datasets has been shown to enhance the quality
and fidelity of image generation and manipulation with diffusion models;
however, such large datasets are not always accessible in medical imaging due
to cost and privacy issues, which contradicts one of the main applications of
such models to produce synthetic samples where real data is scarce. Also,
finetuning on pre-trained general models has been a challenge due to the
distribution shift between the medical domain and the pre-trained models. Here,
we propose Latent Drift (LD) for diffusion models that can be adopted for any
fine-tuning method to mitigate the issues faced by the distribution shift or
employed in inference time as a condition. Latent Drifting enables diffusion
models to be conditioned for medical images fitted for the complex task of
counterfactual image generation, which is crucial to investigate how parameters
such as gender, age, and adding or removing diseases in a patient would alter
the medical images. We evaluate our method on three public longitudinal
benchmark datasets of brain MRI and chest X-rays for counterfactual image
generation. Our results demonstrate significant performance gains in various
scenarios when combined with different fine-tuning schemes. The source code of
this work will be publicly released upon its acceptance.

摘要：<paragraph>透過訓練大型資料集來調整比例，已被證明可以提升擴散模型影像產生與操作的品質和保真度；然而，由於成本和隱私問題，在醫學影像中並不總是能取得這麼大型的資料集，這與這些模型的主要應用之一相矛盾，也就是在真實資料稀少的情況下產生合成樣本。此外，由於醫學領域與預訓練模型之間的分布轉移，對預訓練的通用模型進行微調一直是一項挑戰。在此，我們提出擴散模型的潛在漂移 (LD)，可以採用任何微調方法來減輕分布轉移所面臨的問題，或在推理時間作為條件使用。潛在漂移使擴散模型能夠針對適合於反事實影像產生複雜任務的醫學影像進行調整，這對於探討諸如性別、年齡以及在患者中增加或移除疾病等參數將如何改變醫學影像至關重要。我們在三個大腦 MRI 和胸部 X 光的公開縱向基準資料集上評估了我們的方法，以進行反事實影像產生。我們的結果表明，與不同的微調方案結合使用時，在各種情況下都能顯著提升效能。這項工作的原始碼將在獲得接受後公開發布。</paragraph>

##### **Knowledge Editing for Large Language Model with Knowledge Neuronal Ensemble**
2412.20637v1 by Yongchang Li, Yujin Zhu, Tao Yan, Shijian Fan, Gang Wu, Liang Xu

As real-world knowledge is constantly evolving, ensuring the timeliness and
accuracy of a model's knowledge is crucial. This has made knowledge editing in
large language models increasingly important. However, existing knowledge
editing methods face several challenges, including parameter localization
coupling, imprecise localization, and a lack of dynamic interaction across
layers. In this paper, we propose a novel knowledge editing method called
Knowledge Neuronal Ensemble (KNE). A knowledge neuronal ensemble represents a
group of neurons encoding specific knowledge, thus mitigating the issue of
frequent parameter modification caused by coupling in parameter localization.
The KNE method enhances the precision and accuracy of parameter localization by
computing gradient attribution scores for each parameter at each layer. During
the editing process, only the gradients and losses associated with the
knowledge neuronal ensemble are computed, with error backpropagation performed
accordingly, ensuring dynamic interaction and collaborative updates among
parameters. Experimental results on three widely used knowledge editing
datasets show that the KNE method significantly improves the accuracy of
knowledge editing and achieves, or even exceeds, the performance of the best
baseline methods in portability and locality metrics.

摘要：隨著真實世界的知識不斷演變，確保模型知識的及時性和準確性至關重要。這使得大型語言模型中的知識編輯變得越來越重要。然而，現有的知識編輯方法面臨著多項挑戰，包括參數定位耦合、定位不精確以及跨層缺乏動態交互。在本文中，我們提出了一種名為知識神經元集合（KNE）的新型知識編輯方法。知識神經元集合表示一組編碼特定知識的神經元，從而減輕了參數定位中耦合引起的頻繁參數修改問題。KNE方法通過計算每一層的每個參數的梯度歸因分數來提高參數定位的精確度和準確性。在編輯過程中，只計算與知識神經元集合相關的梯度和損失，並相應地執行誤差反向傳播，確保參數之間的動態交互和協作更新。在三個廣泛使用的知識編輯數據集上的實驗結果表明，KNE方法顯著提高了知識編輯的準確性，並且在可移植性和局部性指標方面達到了或甚至超過了最佳基線方法的性能。

##### **NetFlowGen: Leveraging Generative Pre-training for Network Traffic Dynamics**
2412.20635v1 by Jiawei Zhou, Woojeong Kim, Zhiying Xu, Alexander M. Rush, Minlan Yu

Understanding the traffic dynamics in networks is a core capability for
automated systems to monitor and analyze networking behaviors, reducing
expensive human efforts and economic risks through tasks such as traffic
classification, congestion prediction, and attack detection. However, it is
still challenging to accurately model network traffic with machine learning
approaches in an efficient and broadly applicable manner. Task-specific models
trained from scratch are used for different networking applications, which
limits the efficiency of model development and generalization of model
deployment. Furthermore, while networking data is abundant, high-quality
task-specific labels are often insufficient for training individual models.
Large-scale self-supervised learning on unlabeled data provides a natural
pathway for tackling these challenges. We propose to pre-train a
general-purpose machine learning model to capture traffic dynamics with only
traffic data from NetFlow records, with the goal of fine-tuning for different
downstream tasks with small amount of labels. Our presented NetFlowGen
framework goes beyond a proof-of-concept for network traffic pre-training and
addresses specific challenges such as unifying network feature representations,
learning from large unlabeled traffic data volume, and testing on real
downstream tasks in DDoS attack detection. Experiments demonstrate promising
results of our pre-training framework on capturing traffic dynamics and
adapting to different networking tasks.

摘要：了解網路中的流量動態是自動化系統監控和分析網路行為的核心能力，透過流量分類、壅塞預測和攻擊偵測等任務，減少昂貴的人力成本和經濟風險。然而，以機器學習方法精準建模網路流量，在有效率且廣泛適用的情況下仍具有挑戰性。從頭訓練特定於任務的模型，用於不同的網路應用程式，這限制了模型開發和模型部署的概括性。此外，雖然網路資料豐富，但高品質的特定於任務的標籤通常不足以訓練個別的模型。大規模的無標籤資料自監督學習，提供了解決這些挑戰的自然途徑。我們提議預先訓練一個通用機器學習模型，僅使用 NetFlow 記錄中的流量資料來擷取流量動態，目標是微調不同下游任務，標籤量少。我們提出的 NetFlowGen 架構超越了網路流量預先訓練的概念驗證，並解決特定挑戰，例如統一網路特徵表徵、從大量的無標籤流量資料中學習，以及在 DDoS 攻擊偵測中測試真實的下游任務。實驗證明了我們的預先訓練架構在擷取流量動態和適應不同的網路任務方面，具有令人滿意的結果。

##### **HALLUCINOGEN: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models**
2412.20622v1 by Ashish Seth, Dinesh Manocha, Chirag Agarwal

Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
in performing complex multimodal tasks. However, they are still plagued by
object hallucination: the misidentification or misclassification of objects
present in images. To this end, we propose HALLUCINOGEN, a novel visual
question answering (VQA) object hallucination attack benchmark that utilizes
diverse contextual reasoning prompts to evaluate object hallucination in
state-of-the-art LVLMs. We design a series of contextual reasoning
hallucination prompts to evaluate LVLMs' ability to accurately identify objects
in a target image while asking them to perform diverse visual-language tasks
such as identifying, locating or performing visual reasoning around specific
objects. Further, we extend our benchmark to high-stakes medical applications
and introduce MED-HALLUCINOGEN, hallucination attacks tailored to the
biomedical domain, and evaluate the hallucination performance of LVLMs on
medical images, a critical area where precision is crucial. Finally, we conduct
extensive evaluations of eight LVLMs and two hallucination mitigation
strategies across multiple datasets to show that current generic and medical
LVLMs remain susceptible to hallucination attacks.

摘要：大型視覺語言模型 (LVLMs) 在執行複雜的多模態任務方面表現出色。然而，它們仍然受到物體幻覺的困擾：錯誤識別或錯誤分類圖像中存在的物體。為此，我們提出了 HALLUCINOGEN，這是一個新穎的視覺問答 (VQA) 物體幻覺攻擊基準，它利用多樣化的上下文推理提示來評估最先進的 LVLMs 中的物體幻覺。我們設計了一系列上下文推理幻覺提示，以評估 LVLMs 在要求它們執行多樣化的視覺語言任務（例如識別、定位或對特定物體進行視覺推理）的同時準確識別目標圖像中物體的能力。此外，我們將基準擴展到高風險的醫學應用，並引入了專門針對生物醫學領域的幻覺攻擊 MED-HALLUCINOGEN，並評估了 LVLMs 在醫學圖像（一個精確至關重要的關鍵領域）上的幻覺表現。最後，我們對八個 LVLMs 和兩個幻覺緩解策略進行了廣泛的評估，跨多個數據集，以表明當前的通用和醫學 LVLMs 仍然容易受到幻覺攻擊。

##### **NLP-based Regulatory Compliance -- Using GPT 4.0 to Decode Regulatory Documents**
2412.20602v1 by Bimal Kumar, Dmitri Roussinov

Large Language Models (LLMs) such as GPT-4.0 have shown significant promise
in addressing the semantic complexities of regulatory documents, particularly
in detecting inconsistencies and contradictions. This study evaluates GPT-4.0's
ability to identify conflicts within regulatory requirements by analyzing a
curated corpus with artificially injected ambiguities and contradictions,
designed in collaboration with architects and compliance engineers. Using
metrics such as precision, recall, and F1 score, the experiment demonstrates
GPT-4.0's effectiveness in detecting inconsistencies, with findings validated
by human experts. The results highlight the potential of LLMs to enhance
regulatory compliance processes, though further testing with larger datasets
and domain-specific fine-tuning is needed to maximize accuracy and practical
applicability. Future work will explore automated conflict resolution and
real-world implementation through pilot projects with industry partners.

摘要：大型語言模型 (LLM)，例如 GPT-4.0，在解決法規文件中的語義複雜性方面展現出巨大的前景，特別是在偵測不一致和矛盾方面。本研究評估了 GPT-4.0 在法規要求中識別衝突的能力，方法是分析一個精心策劃的語料庫，其中包含人工注入的歧義和矛盾，並與建築師和合規工程師合作設計。實驗使用精確度、召回率和 F1 分數等指標，證明了 GPT-4.0 在偵測不一致方面的有效性，其結果已由人類專家驗證。研究結果突顯了 LLM 增強法規遵循流程的潛力，儘管需要使用更大的資料集和特定領域的微調進行進一步測試，以最大化準確度和實用性。未來的研究將透過與產業合作夥伴的試點專案，探索自動衝突解決和實際世界的實作。

##### **MATEY: multiscale adaptive foundation models for spatiotemporal physical systems**
2412.20601v1 by Pei Zhang, M. Paul Laiu, Matthew Norman, Doug Stefanski, John Gounley

Accurate representation of the multiscale features in spatiotemporal physical
systems using vision transformer (ViT) architectures requires extremely long,
computationally prohibitive token sequences. To address this issue, we propose
two adaptive tokenization schemes that dynamically adjust patch sizes based on
local features: one ensures convergent behavior to uniform patch refinement,
while the other offers better computational efficiency. Moreover, we present a
set of spatiotemporal attention schemes, where the temporal or axial spatial
dimensions are decoupled, and evaluate their computational and data
efficiencies. We assess the performance of the proposed multiscale adaptive
model, MATEY, in a sequence of experiments. The results show that adaptive
tokenization schemes achieve improved accuracy without significantly increasing
the length of the token sequence. Compared to a full spatiotemporal attention
scheme or a scheme that decouples only the temporal dimension, we find that
fully decoupled axial attention is less efficient and expressive, requiring
more training time and model weights to achieve the same accuracy. Finally, we
demonstrate in two fine-tuning tasks featuring different physics that models
pretrained on PDEBench data outperform the ones trained from scratch,
especially in the low data regime with frozen attention.

摘要：使用視覺Transformer (ViT) 架構精確表示時空物理系統中的多尺度特徵需要極長且計算成本過高的標記序列。為了解決此問題，我們提出了兩種自適應標記化架構，可根據局部特徵動態調整區塊大小：一種確保收斂行為以進行均勻區塊細化，而另一種則提供更好的計算效率。此外，我們提出了一組時空注意力架構，其中時序或軸向空間維度是解耦的，並評估其計算和資料效率。我們在實驗序列中評估所提出的多尺度自適應模型 MATEY 的效能。結果顯示，自適應標記化架構在未顯著增加標記序列長度的情況下，可提高準確度。與完全時空注意力架構或僅解耦時序維度的架構相比，我們發現完全解耦的軸向注意力效率較低且表達力較差，需要更多訓練時間和模型權重才能達到相同的準確度。最後，我們在兩個具有不同物理特性的微調任務中證明，在 PDEBench 資料上預先訓練的模型優於從頭開始訓練的模型，特別是在凍結注意力的低資料範圍內。

##### **GliLem: Leveraging GliNER for Contextualized Lemmatization in Estonian**
2412.20597v1 by Aleksei Dorkin, Kairit Sirts

We present GliLem -- a novel hybrid lemmatization system for Estonian that
enhances the highly accurate rule-based morphological analyzer Vabamorf with an
external disambiguation module based on GliNER -- an open vocabulary NER model
that is able to match text spans with text labels in natural language. We
leverage the flexibility of a pre-trained GliNER model to improve the
lemmatization accuracy of Vabamorf by 10\% compared to its original
disambiguation module and achieve an improvement over the token
classification-based baseline. To measure the impact of improvements in
lemmatization accuracy on the information retrieval downstream task, we first
created an information retrieval dataset for Estonian by automatically
translating the DBpedia-Entity dataset from English. We benchmark several token
normalization approaches, including lemmatization, on the created dataset using
the BM25 algorithm. We observe a substantial improvement in IR metrics when
using lemmatization over simplistic stemming. The benefits of improving lemma
disambiguation accuracy manifest in small but consistent improvement in the IR
recall measure, especially in the setting of high k.

摘要：我們提出 GliLem -- 一個愛沙尼亞語的新型混合詞形還原系統，它通過基於 GliNER 的外部消歧義模組增強了高度準確的基於規則的形態分析器 Vabamorf -- 一個開放詞彙 NER 模型，能夠將文本跨度與自然語言中的文本標籤相匹配。我們利用預訓練的 GliNER 模型的靈活性，將 Vabamorf 的詞形還原準確度提高了 10%，與其原始消歧義模組相比，並實現了對基於標記分類的基線的改進。為了衡量詞形還原準確度改進對下游任務中資訊檢索的影響，我們首先通過自動翻譯英文的 DBpedia-Entity 資料集來建立一個愛沙尼亞語的資訊檢索資料集。我們使用 BM25 演算法在建立的資料集上對包括詞形還原在內的幾種標記正規化方法進行基準測試。我們觀察到，當使用詞形還原而不是簡化的詞幹提取時，IR 指標有顯著改善。改進詞形消歧義準確性的好處在 IR 召回率指標中表現為微小但一致的改進，特別是在 k 值較高的情況下。

##### **Controlling Out-of-Domain Gaps in LLMs for Genre Classification and Generated Text Detection**
2412.20595v1 by Dmitri Roussinov, Serge Sharoff, Nadezhda Puchnina

This study demonstrates that the modern generation of Large Language Models
(LLMs, such as GPT-4) suffers from the same out-of-domain (OOD) performance gap
observed in prior research on pre-trained Language Models (PLMs, such as BERT).
We demonstrate this across two non-topical classification tasks: 1) genre
classification and 2) generated text detection. Our results show that when
demonstration examples for In-Context Learning (ICL) come from one domain
(e.g., travel) and the system is tested on another domain (e.g., history),
classification performance declines significantly.
  To address this, we introduce a method that controls which predictive
indicators are used and which are excluded during classification. For the two
tasks studied here, this ensures that topical features are omitted, while the
model is guided to focus on stylistic rather than content-based attributes.
This approach reduces the OOD gap by up to 20 percentage points in a few-shot
setup. Straightforward Chain-of-Thought (CoT) methods, used as the baseline,
prove insufficient, while our approach consistently enhances domain transfer
performance.

摘要：本研究表明，現代的大語言模型 (LLM，例如 GPT-4) 存在與先前針對預訓練語言模型 (PLM，例如 BERT) 的研究中觀察到的相同領域外 (OOD) 效能差距。我們透過兩個非主題分類任務來證明這一點：1) 類型分類和 2) 生成文字偵測。我們的結果顯示，當情境學習 (ICL) 的示範範例來自一個領域（例如旅遊），而系統在另一個領域（例如歷史）中受測時，分類效能會顯著下降。
為了解決這個問題，我們提出了一個方法來控制哪些預測指標在分類期間使用，哪些被排除。對於這裡研究的兩個任務，這確保了主題特徵被省略，而模型則被引導專注於風格而非基於內容的屬性。這種方法在少次嘗試設定中將 OOD 差距減少了多達 20 個百分點。作為基準使用的直接思考鏈 (CoT) 方法被證明是不足的，而我們的做法則持續增強了領域轉移效能。

##### **Towards Neural No-Resource Language Translation: A Comparative Evaluation of Approaches**
2412.20584v1 by Madhavendra Thakur

No-resource languages - those with minimal or no digital representation -
pose unique challenges for machine translation (MT). Unlike low-resource
languages, which rely on limited but existent corpora, no-resource languages
often have fewer than 100 sentences available for training. This work explores
the problem of no-resource translation through three distinct workflows:
fine-tuning of translation-specific models, in-context learning with large
language models (LLMs) using chain-of-reasoning prompting, and direct prompting
without reasoning. Using Owens Valley Paiute as a case study, we demonstrate
that no-resource translation demands fundamentally different approaches from
low-resource scenarios, as traditional approaches to machine translation, such
as those that work for low-resource languages, fail. Empirical results reveal
that, although traditional approaches fail, the in-context learning
capabilities of general-purpose large language models enable no-resource
language translation that outperforms low-resource translation approaches and
rivals human translations (BLEU 0.45-0.6); specifically, chain-of-reasoning
prompting outperforms other methods for larger corpora, while direct prompting
exhibits advantages in smaller datasets. As these approaches are
language-agnostic, they have potential to be generalized to translation tasks
from a wide variety of no-resource languages without expert input. These
findings establish no-resource translation as a distinct paradigm requiring
innovative solutions, providing practical and theoretical insights for language
preservation.

摘要：<paragraph>沒有資源的語言（即數位呈現極少或沒有的語言）對機器翻譯 (MT) 構成獨特的挑戰。與依賴有限但存在的語料庫的低資源語言不同，沒有資源的語言通常只有不到 100 個可供訓練的句子。這項工作透過三個不同的工作流程探討沒有資源的翻譯問題：微調翻譯特定模型、使用推理鏈提示的大型語言模型 (LLM) 進行情境學習，以及沒有推理的直接提示。我們以歐文斯谷派尤特語為案例研究，證明沒有資源的翻譯需要與低資源場景截然不同的方法，因為傳統的機器翻譯方法（例如適用於低資源語言的方法）會失敗。實證結果顯示，儘管傳統方法會失敗，但通用大型語言模型的情境學習能力讓沒有資源的語言翻譯能夠超越低資源翻譯方法，並與人工翻譯相媲美（BLEU 0.45-0.6）；特別是，推理鏈提示在較大的語料庫中優於其他方法，而直接提示在較小的資料集中展現優勢。由於這些方法與語言無關，因此它們有可能推廣到各種沒有資源的語言的翻譯任務，而無需專家輸入。這些發現將沒有資源的翻譯確立為一個需要創新解決方案的不同範例，為語言保存提供實用和理論見解。</paragraph>

##### **A Survey on Time-Series Distance Measures**
2412.20574v1 by John Paparrizos, Haojun Li, Fan Yang, Kaize Wu, Jens E. d'Hondt, Odysseas Papapetrou

Distance measures have been recognized as one of the fundamental building
blocks in time-series analysis tasks, e.g., querying, indexing, classification,
clustering, anomaly detection, and similarity search. The vast proliferation of
time-series data across a wide range of fields has increased the relevance of
evaluating the effectiveness and efficiency of these distance measures. To
provide a comprehensive view of this field, this work considers over 100
state-of-the-art distance measures, classified into 7 categories: lock-step
measures, sliding measures, elastic measures, kernel measures, feature-based
measures, model-based measures, and embedding measures. Beyond providing
comprehensive mathematical frameworks, this work also delves into the
distinctions and applications across these categories for both univariate and
multivariate cases. By providing comprehensive collections and insights, this
study paves the way for the future development of innovative time-series
distance measures.

摘要：距離測量已被視為時序分析任務中的一項基本建構模組，例如查詢、索引、分類、分群、異常偵測和相似性搜尋。時序資料在各個領域中大量激增，這提升了評估這些距離測量的有效性和效率的重要性。為了提供此領域的全面觀點，本研究考量了 100 多種最先進的距離測量，並將其分類為 7 個類別：鎖步測量、滑動測量、彈性測量、核測量、基於特徵的測量、基於模型的測量和嵌入式測量。除了提供全面的數學架構之外，本研究也深入探討了這些類別在單變量和多變量案例中的區別和應用。透過提供全面的彙編和見解，本研究為創新時序距離測量的未來發展鋪路。

##### **The intrinsic motivation of reinforcement and imitation learning for sequential tasks**
2412.20573v1 by Sao Mai Nguyen

This work in the field of developmental cognitive robotics aims to devise a
new domain bridging between reinforcement learning and imitation learning, with
a model of the intrinsic motivation for learning agents to learn with guidance
from tutors multiple tasks, including sequential tasks. The main contribution
has been to propose a common formulation of intrinsic motivation based on
empirical progress for a learning agent to choose automatically its learning
curriculum by actively choosing its learning strategy for simple or sequential
tasks: which task to learn, between autonomous exploration or imitation
learning, between low-level actions or task decomposition, between several
tutors. The originality is to design a learner that benefits not only passively
from data provided by tutors, but to actively choose when to request tutoring
and what and whom to ask. The learner is thus more robust to the quality of the
tutoring and learns faster with fewer demonstrations. We developed the
framework of socially guided intrinsic motivation with machine learning
algorithms to learn multiple tasks by taking advantage of the generalisability
properties of human demonstrations in a passive manner or in an active manner
through requests of demonstrations from the best tutor for simple and composing
subtasks. The latter relies on a representation of subtask composition proposed
for a construction process, which should be refined by representations used for
observational processes of analysing human movements and activities of daily
living. With the outlook of a language-like communication with the tutor, we
investigated the emergence of a symbolic representation of the continuous
sensorimotor space and of tasks using intrinsic motivation. We proposed within
the reinforcement learning framework, a reward function for interacting with
tutors for automatic curriculum learning in multi-task learning.

摘要：<paragraph>這項在發展認知機器人學領域中的研究旨在設計一個新的領域，在強化學習和模仿學習之間架起橋樑，並使用一個內在動機模型，讓學習代理人從多位導師的指導中學習多項任務，包括順序任務。主要貢獻在於提出一個基於經驗進展的內在動機共通用式，讓學習代理人能夠自動選擇其學習課程，並積極選擇其在簡單或順序任務中的學習策略：在自主探索或模仿學習、在低層級動作或任務分解、在多位導師之間選擇要學習的任務。其獨創性在於設計一個學習者，不僅能被動地從導師提供的資料中受益，還能主動選擇何時請求指導，以及向誰詢問什麼。因此，學習者對指導品質的耐受性更高，並能以更少的示範更快地學習。我們開發了社會引導內在動機架構，使用機器學習演算法學習多項任務，並利用人類示範在被動或主動方式中的概括性，透過向最適合的導師請求示範來學習簡單和組成子任務。後者依賴於為建構過程提出的子任務組成表示，該表示應透過用於分析人類動作和日常生活活動的觀察過程的表示進行精煉。我們以與導師進行語言式溝通的觀點，探討了連續感官運動空間和任務的符號表示在內在動機中的出現。我們在強化學習架構中提出了一個獎勵函數，用於與導師互動，以在多任務學習中進行自動課程學習。</paragraph>

##### **Segmentation of Muscularis Propria in Colon Histopathology Images Using Vision Transformers for Hirschsprung's Disease**
2412.20571v1 by Youssef Megahed, Anthony Fuller, Saleh Abou-Alwan, Dina El Demellawy, Adrian D. C. Chan

Hirschsprung's disease (HD) is a congenital birth defect diagnosed by
identifying the lack of ganglion cells within the colon's muscularis propria,
specifically within the myenteric plexus regions. There may be advantages for
quantitative assessments of histopathology images of the colon, such as
counting the ganglion and assessing their spatial distribution; however, this
would be time-intensive for pathologists, costly, and subject to inter- and
intra-rater variability. Previous research has demonstrated the potential for
deep learning approaches to automate histopathology image analysis, including
segmentation of the muscularis propria using convolutional neural networks
(CNNs). Recently, Vision Transformers (ViTs) have emerged as a powerful deep
learning approach due to their self-attention. This study explores the
application of ViTs for muscularis propria segmentation in calretinin-stained
histopathology images and compares their performance to CNNs and shallow
learning methods. The ViT model achieved a DICE score of 89.9% and Plexus
Inclusion Rate (PIR) of 100%, surpassing the CNN (DICE score of 89.2%; PIR of
96.0%) and k-means clustering method (DICE score of 80.7%; PIR 77.4%). Results
assert that ViTs are a promising tool for advancing HD-related image analysis.

摘要：先天性巨結腸症 (HD) 是一種先天性出生缺陷，透過確認結腸肌層內缺乏神經節細胞，特別是在神經肌叢區域內，來診斷。對結腸組織病理學影像進行定量評估可能有一些優點，例如計算神經節並評估其空間分佈；然而，這對病理學家來說會很耗時、成本高昂，而且容易受到評分者之間和評分者內變異的影響。先前的研究已證明深度學習方法有潛力自動化組織病理學影像分析，包括使用卷積神經網路 (CNN) 對肌層進行分割。最近，視覺Transformer (ViT) 由於其自我注意，已成為一種強大的深度學習方法。本研究探討了 ViT 在鈣雷蛋白染色組織病理學影像中對肌層分割的應用，並將其效能與 CNN 和淺層學習方法進行比較。ViT 模型達到了 89.9% 的 DICE 分數和 100% 的神經叢包覆率 (PIR)，優於 CNN（DICE 分數為 89.2%；PIR 為 96.0%）和 k 均值聚類方法（DICE 分數為 80.7%；PIR 為 77.4%）。結果表明，ViT 是推動 HD 相關影像分析的一種有前途的工具。

##### **Enhancing autonomous vehicle safety in rain: a data-centric approach for clear vision**
2412.20565v1 by Mark A. Seferian, Jidong J. Yang

Autonomous vehicles face significant challenges in navigating adverse
weather, particularly rain, due to the visual impairment of camera-based
systems. In this study, we leveraged contemporary deep learning techniques to
mitigate these challenges, aiming to develop a vision model that processes live
vehicle camera feeds to eliminate rain-induced visual hindrances, yielding
visuals closely resembling clear, rain-free scenes. Using the Car Learning to
Act (CARLA) simulation environment, we generated a comprehensive dataset of
clear and rainy images for model training and testing. In our model, we
employed a classic encoder-decoder architecture with skip connections and
concatenation operations. It was trained using novel batching schemes designed
to effectively distinguish high-frequency rain patterns from low-frequency
scene features across successive image frames. To evaluate the model
performance, we integrated it with a steering module that processes front-view
images as input. The results demonstrated notable improvements in steering
accuracy, underscoring the model's potential to enhance navigation safety and
reliability in rainy weather conditions.

摘要：自動駕駛車輛在惡劣天氣中，特別是雨天，面臨著重大的挑戰，這是因為基於相機的系統會受到視覺損害。在這個研究中，我們利用了當代的深度學習技術來減輕這些挑戰，目標是開發一個視覺模型，它可以處理車輛相機的實時影像，以消除雨水引起的視覺障礙，產生出與清晰、無雨場景非常相似的視覺效果。使用 Car Learning to Act (CARLA) 模擬環境，我們生成了包含清晰和雨天影像的綜合資料集，用於模型訓練和測試。在我們的模型中，我們採用了經典的編碼器-解碼器架構，並具有跳躍連接和串接操作。它使用新穎的批次處理方案進行訓練，這些方案旨在有效區分連續影像幀中的高頻率雨水模式和低頻率場景特徵。為了評估模型效能，我們將其與一個轉向模組整合，該模組將前視影像作為輸入進行處理。結果顯示轉向準確度有顯著的提升，這突顯了該模型在雨天條件下增強導航安全性和可靠性的潛力。

##### **Counterfactual Samples Constructing and Training for Commonsense Statements Estimation**
2412.20563v1 by Chong Liu, Zaiwen Feng, Lin Liu, Zhenyun Deng, Jiuyong Li, Ruifang Zhai, Debo Cheng, Li Qin

Plausibility Estimation (PE) plays a crucial role for enabling language
models to objectively comprehend the real world. While large language models
(LLMs) demonstrate remarkable capabilities in PE tasks but sometimes produce
trivial commonsense errors due to the complexity of commonsense knowledge. They
lack two key traits of an ideal PE model: a) Language-explainable: relying on
critical word segments for decisions, and b) Commonsense-sensitive: detecting
subtle linguistic variations in commonsense. To address these issues, we
propose a novel model-agnostic method, referred to as Commonsense
Counterfactual Samples Generating (CCSG). By training PE models with CCSG, we
encourage them to focus on critical words, thereby enhancing both their
language-explainable and commonsense-sensitive capabilities. Specifically, CCSG
generates counterfactual samples by strategically replacing key words and
introducing low-level dropout within sentences. These counterfactual samples
are then incorporated into a sentence-level contrastive training framework to
further enhance the model's learning process. Experimental results across nine
diverse datasets demonstrate the effectiveness of CCSG in addressing
commonsense reasoning challenges, with our CCSG method showing 3.07%
improvement against the SOTA methods.

摘要：似真性評估 (PE) 在讓語言模型客觀理解真實世界中扮演著至關重要的角色。儘管大型語言模型 (LLM) 在 PE 任務中展現出非凡的能力，但有時會因為常識知識的複雜性而產生微不足道的常識錯誤。它們缺少理想 PE 模型的兩個關鍵特徵：a) 語言可解釋性：依賴關鍵字片段來做出決策，以及 b) 常識敏感性：偵測常識中的細微語言變化。為了解決這些問題，我們提出了一種新穎的模型不可知方法，稱為常識反事實範例生成 (CCSG)。透過使用 CCSG 來訓練 PE 模型，我們鼓勵它們專注於關鍵字，進而增強它們的語言可解釋性和常識敏感性能力。具體來說，CCSG 透過策略性地替換關鍵字並在句子中引入低層級輟學，來產生反事實範例。接著將這些反事實範例納入句子層級對比訓練架構中，以進一步增強模型的學習過程。橫跨九個不同資料集的實驗結果證明了 CCSG 在解決常識推理挑戰上的有效性，我們的 CCSG 方法顯示出比 SOTA 方法進步了 3.07%。

##### **The Impact of Prompt Programming on Function-Level Code Generation**
2412.20545v1 by Ranim Khojah, Francisco Gomes de Oliveira Neto, Mazen Mohamad, Philipp Leitner

Large Language Models (LLMs) are increasingly used by software engineers for
code generation. However, limitations of LLMs such as irrelevant or incorrect
code have highlighted the need for prompt programming (or prompt engineering)
where engineers apply specific prompt techniques (e.g., chain-of-thought or
input-output examples) to improve the generated code. Despite this, the impact
of different prompt techniques -- and their combinations -- on code generation
remains underexplored. In this study, we introduce CodePromptEval, a dataset of
7072 prompts designed to evaluate five prompt techniques (few-shot, persona,
chain-of-thought, function signature, list of packages) and their effect on the
correctness, similarity, and quality of complete functions generated by three
LLMs (GPT-4o, Llama3, and Mistral). Our findings show that while certain prompt
techniques significantly influence the generated code, combining multiple
techniques does not necessarily improve the outcome. Additionally, we observed
a trade-off between correctness and quality when using prompt techniques. Our
dataset and replication package enable future research on improving
LLM-generated code and evaluating new prompt techniques.

摘要：大型語言模型 (LLM)  zunehmend von Software-Ingenieuren für die Code-Generierung verwendet. Einschränkungen von LLMs wie irrelevanter oder inkorrekter Code haben jedoch die Notwendigkeit einer prompten Programmierung (oder Prompt-Engineering) verdeutlicht, bei der Ingenieure spezifische Prompt-Techniken (z. B. Gedankenkette oder Eingabe-Ausgabe-Beispiele) anwenden, um den generierten Code zu verbessern. Trotzdem bleibt der Einfluss verschiedener Prompt-Techniken – und ihrer Kombinationen – auf die Codegenerierung unerforscht. In dieser Studie stellen wir CodePromptEval vor, einen Datensatz mit 7072 Prompts, die entwickelt wurden, um fünf Prompt-Techniken (Few-Shot, Persona, Gedankenkette, Funktionssignatur, Liste von Paketen) und ihre Auswirkungen auf die Korrektheit, Ähnlichkeit und Qualität vollständiger Funktionen zu bewerten, die von drei LLMs (GPT-4o, Llama3 und Mistral) generiert wurden. Unsere Ergebnisse zeigen, dass bestimmte Prompt-Techniken den generierten Code zwar erheblich beeinflussen, die Kombination mehrerer Techniken jedoch nicht unbedingt das Ergebnis verbessert. Darüber hinaus haben wir einen Kompromiss zwischen Korrektheit und Qualität bei der Verwendung von Prompt-Techniken beobachtet. Unser Datensatz und Replikationspaket ermöglichen zukünftige Forschungen zur Verbesserung von LLM-generiertem Code und zur Bewertung neuer Prompt-Techniken.

##### **SAFE-MEME: Structured Reasoning Framework for Robust Hate Speech Detection in Memes**
2412.20541v1 by Palash Nandi, Shivam Sharma, Tanmoy Chakraborty

Memes act as cryptic tools for sharing sensitive ideas, often requiring
contextual knowledge to interpret. This makes moderating multimodal memes
challenging, as existing works either lack high-quality datasets on nuanced
hate categories or rely on low-quality social media visuals. Here, we curate
two novel multimodal hate speech datasets, MHS and MHS-Con, that capture
fine-grained hateful abstractions in regular and confounding scenarios,
respectively. We benchmark these datasets against several competing baselines.
Furthermore, we introduce SAFE-MEME (Structured reAsoning FramEwork), a novel
multimodal Chain-of-Thought-based framework employing Q&A-style reasoning
(SAFE-MEME-QA) and hierarchical categorization (SAFE-MEME-H) to enable robust
hate speech detection in memes. SAFE-MEME-QA outperforms existing baselines,
achieving an average improvement of approximately 5% and 4% on MHS and MHS-Con,
respectively. In comparison, SAFE-MEME-H achieves an average improvement of 6%
in MHS while outperforming only multimodal baselines in MHS-Con. We show that
fine-tuning a single-layer adapter within SAFE-MEME-H outperforms fully
fine-tuned models in regular fine-grained hateful meme detection. However, the
fully fine-tuning approach with a Q&A setup is more effective for handling
confounding cases. We also systematically examine the error cases, offering
valuable insights into the robustness and limitations of the proposed
structured reasoning framework for analyzing hateful memes.

摘要：迷因作為分享敏感想法的神秘工具，通常需要背景知識才能解讀。這使得節制多模態迷因變得具有挑戰性，因為現有作品要么缺乏關於細微仇恨類別的高品質數據集，要么依賴於低品質的社交媒體視覺效果。在此，我們策劃了兩個新穎的多模態仇恨言論數據集，分別是 MHS 和 MHS-Con，它們分別捕捉了常規和令人困惑場景中的細粒度仇恨抽象。我們根據幾個競爭基線對這些數據集進行基準測試。此外，我們還引入了 SAFE-MEME（結構化推理框架），這是一個新穎的多模態基於思想鏈的框架，採用問答式推理（SAFE-MEME-QA）和分層分類（SAFE-MEME-H）來實現對迷因中仇恨言論的強大檢測。SAFE-MEME-QA 優於現有的基線，分別在 MHS 和 MHS-Con 上實現了大約 5% 和 4% 的平均改進。相比之下，SAFE-MEME-H 在 MHS 中實現了 6% 的平均改進，而僅在 MHS-Con 中優於多模態基線。我們表明，在 SAFE-MEME-H 中微調單層適配器優於常規細粒度仇恨迷因檢測中的完全微調模型。然而，具有問答設置的完全微調方法對於處理令人困惑的情況更有效。我們還系統地檢查了錯誤案例，為分析仇恨迷因的提議結構化推理框架的魯棒性和局限性提供了寶貴的見解。

##### **Goal-Conditioned Data Augmentation for Offline Reinforcement Learning**
2412.20519v1 by Xingshuai Huang, Di Wu Member, Benoit Boulet

Offline reinforcement learning (RL) enables policy learning from
pre-collected offline datasets, relaxing the need to interact directly with the
environment. However, limited by the quality of offline datasets, it generally
fails to learn well-qualified policies in suboptimal datasets. To address
datasets with insufficient optimal demonstrations, we introduce
Goal-cOnditioned Data Augmentation (GODA), a novel goal-conditioned
diffusion-based method for augmenting samples with higher quality. Leveraging
recent advancements in generative modeling, GODA incorporates a novel
return-oriented goal condition with various selection mechanisms. Specifically,
we introduce a controllable scaling technique to provide enhanced return-based
guidance during data sampling. GODA learns a comprehensive distribution
representation of the original offline datasets while generating new data with
selectively higher-return goals, thereby maximizing the utility of limited
optimal demonstrations. Furthermore, we propose a novel adaptive gated
conditioning method for processing noised inputs and conditions, enhancing the
capture of goal-oriented guidance. We conduct experiments on the D4RL benchmark
and real-world challenges, specifically traffic signal control (TSC) tasks, to
demonstrate GODA's effectiveness in enhancing data quality and superior
performance compared to state-of-the-art data augmentation methods across
various offline RL algorithms.

摘要：<paragraph>離線強化學習 (RL) 能夠從預先收集的離線數據集學習政策，放寬了與環境直接互動的需求。然而，受到離線數據集品質的限制，它通常無法在次佳數據集中學習到品質良好的政策。為了處理具有不充分最佳示範的數據集，我們引入了目標條件數據擴充 (GODA)，一種新穎的目標條件擴散方法，用於擴充品質更高的範例。利用生成式建模的最新進展，GODA 結合了新穎的回報導向目標條件與各種選擇機制。具體來說，我們引入了一種可控的縮放技術，以便在數據抽樣期間提供增強的回報導向指引。GODA 學習原始離線數據集的全面分佈表示，同時生成具有選擇性更高回報目標的新數據，從而最大化有限最佳示範的效用。此外，我們提出了一種新穎的自適應閘控條件方法，用於處理雜訊輸入和條件，增強目標導向指引的捕捉。我們在 D4RL 基準和真實世界的挑戰，特別是交通號誌控制 (TSC) 任務上進行了實驗，以證明 GODA 在提升數據品質和優異效能方面的有效性，優於各種離線 RL 演算法中的最新數據擴充方法。</paragraph>

##### **Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning**
2412.20505v1 by Hang Ni, Yuzhi Wang, Hao Liu

Urban regeneration presents significant challenges within the context of
urbanization, requiring adaptive approaches to tackle evolving needs.
Leveraging advancements in large language models (LLMs), we propose Cyclical
Urban Planning (CUP), a new paradigm that continuously generates, evaluates,
and refines urban plans in a closed-loop. Specifically, our multi-agent
LLM-based framework consists of three key components: (1) Planning, where LLM
agents generate and refine urban plans based on contextual data; (2) Living,
where agents simulate the behaviors and interactions of residents, modeling
life in the urban environment; and (3) Judging, which involves evaluating plan
effectiveness and providing iterative feedback for improvement. The cyclical
process enables a dynamic and responsive planning approach. Experiments on the
real-world dataset demonstrate the effectiveness of our framework as a
continuous and adaptive planning process.

摘要：城市更新在都市化的背景下提出了重大挑戰，需要採用適應性方法來因應不斷變化的需求。
利用大型語言模型 (LLM) 的進展，我們提出循環城市規劃 (CUP)，這是一個新的範例，可以持續在閉環中產生、評估和改善城市計畫。具體來說，我們基於多代理 LLM 的架構包含三個關鍵組成部分：(1) 規劃，其中 LLM 代理根據脈絡數據產生和改善城市規劃；(2) 生活，其中代理模擬居民的行為和互動，模擬城市環境中的生活；(3) 評斷，其中包括評估計畫的有效性並提供反覆的回饋以進行改善。循環過程能實現動態且靈敏的規劃方法。在真實世界資料集上的實驗證明了我們架構作為持續且適應性規劃過程的有效性。

##### **ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video Understanding**
2412.20504v1 by Xiao Wang, Qingyi Si, Jianlong Wu, Shiyu Zhu, Li Cao, Liqiang Nie

Video Large Language Models (VideoLLMs) have achieved remarkable progress in
video understanding. However, existing VideoLLMs often inherit the limitations
of their backbone LLMs in handling long sequences, leading to challenges for
long video understanding. Common solutions either simply uniformly sample
videos' frames or compress visual tokens, which focus primarily on low-level
temporal visual redundancy, overlooking high-level knowledge redundancy. This
limits the achievable compression rate with minimal loss. To this end. we
introduce a training-free method, $\textbf{ReTaKe}$, containing two novel
modules DPSelect and PivotKV, to jointly model and reduce both temporal visual
redundancy and knowledge redundancy for long video understanding. Specifically,
DPSelect identifies keyframes with local maximum peak distance based on their
visual features, which are closely aligned with human video perception. PivotKV
employs the obtained keyframes as pivots and conducts KV-Cache compression for
the non-pivot tokens with low attention scores, which are derived from the
learned prior knowledge of LLMs. Experiments on benchmarks VideoMME, MLVU, and
LVBench, show that ReTaKe can support 4x longer video sequences with minimal
performance loss (<1%) and outperform all similar-size VideoLLMs with 3%-5%,
even surpassing or on par with much larger ones. Our code is available at
https://github.com/SCZwangxiao/video-ReTaKe

摘要：視訊大型語言模型 (VideoLLM) 已在視訊理解方面取得顯著進展。然而，現有的 VideoLLM 經常會繼承其骨幹 LLM 在處理長序列時的限制，導致難以理解長視訊。常見的解決方案，要不就是均勻取樣視訊的影格，要不就是壓縮視覺代碼，這些方法主要著重於低階時間視覺冗餘，忽略了高階知識冗餘。這會限制可達到的壓縮率，同時損失降到最低。有鑑於此，我們推出了一個免訓練方法「ReTaKe」，包含兩個新穎的模組 DPSelect 和 PivotKV，以共同建模並減少時間視覺冗餘和知識冗餘，以利於理解長視訊。具體來說，DPSelect 會根據視覺特徵，找出具有局部最大峰值距離的關鍵影格，這些特徵與人類的視訊感知緊密相關。PivotKV 將取得的關鍵影格用作樞紐，並對注意力評分低的非樞紐代碼執行 KV 快取壓縮，這些代碼來自於 LLM 所學習的先驗知識。在基準 VideoMME、MLVU 和 LVBench 上的實驗顯示，ReTaKe 可以支援長度為原本 4 倍的視訊序列，且效能損失降到最低 (<1%)，並以 3%-5% 的幅度優於所有類似大小的 VideoLLM，甚至超越或與大得多的 VideoLLM 相當。我們的程式碼可在 https://github.com/SCZwangxiao/video-ReTaKe 取得

##### **A Multiparty Homomorphic Encryption Approach to Confidential Federated Kaplan Meier Survival Analysis**
2412.20495v1 by Narasimha Raghavan Veeraragavan, Svetlana Boudko, Jan Franz Nygård

The proliferation of healthcare data has expanded opportunities for
collaborative research, yet stringent privacy regulations hinder pooling
sensitive patient records. We propose a \emph{multiparty homomorphic
encryption-based} framework for \emph{privacy-preserving federated
Kaplan--Meier survival analysis}, offering native floating-point support, a
theoretical model, and explicit reconstruction-attack mitigation. Compared to
prior work, our framework ensures encrypted federated survival estimates
closely match centralized outcomes, supported by formal utility-loss bounds
that demonstrate convergence as aggregation and decryption noise diminish.
Extensive experiments on the NCCTG Lung Cancer and synthetic Breast Cancer
datasets confirm low \emph{mean absolute error (MAE)} and \emph{root mean
squared error (RMSE)}, indicating negligible deviations between encrypted and
non-encrypted survival curves. Log-rank and numerical accuracy tests reveal
\emph{no significant difference} between federated encrypted and non-encrypted
analyses, preserving statistical validity. A reconstruction-attack evaluation
shows smaller federations (2--3 providers) with overlapping data between the
institutions are vulnerable, a challenge mitigated by multiparty encryption.
Larger federations (5--50 sites) degrade reconstruction accuracy further, with
encryption improving confidentiality. Despite an 8--19$\times$ computational
overhead, threshold-based homomorphic encryption is \emph{feasible for
moderate-scale deployments}, balancing security and runtime. By providing
robust privacy guarantees alongside high-fidelity survival estimates, our
framework advances the state-of-the art in secure multi-institutional survival
analysis.

摘要：醫療數據的激增擴大了協作研究的機會，但嚴格的隱私法規阻礙了敏感患者記錄的匯集。我們提出了一個基於多方同態加密的框架，用於隱私保護的聯邦 Kaplan-Meier 生存分析，提供原生浮點支持、理論模型和明確的重建攻擊緩解。與先前的研究相比，我們的框架確保加密的聯邦生存估計值與集中結果密切匹配，並得到正式的效用損失邊界的支持，證明了隨著聚合和解密噪聲的減少而收斂。在 NCCTG 肺癌和合成乳腺癌數據集上的大量實驗證實了較低的平均絕對誤差 (MAE) 和均方根誤差 (RMSE)，表明加密和非加密生存曲線之間的偏差可以忽略不計。對數秩和數值準確度測試表明，聯邦加密和非加密分析之間沒有顯著差異，從而保持了統計效度。重建攻擊評估表明，數據在機構之間重疊的較小聯盟（2-3 個提供者）容易受到攻擊，而多方加密可以緩解這一挑戰。較大的聯盟（5-50 個站點）進一步降低了重建準確度，而加密則提高了機密性。儘管計算開銷增加了 8-19 倍，但基於閾值的同態加密對於中等規模的部署是可行的，它平衡了安全性與運行時。通過提供強大的隱私保證以及高保真生存估計，我們的框架推動了安全的多機構生存分析的最新技術。

##### **Cut the Deadwood Out: Post-Training Model Purification with Selective Module Substitution**
2412.20476v1 by Yao Tong, Weijun Li, Xuanli He, Haolan Zhan, Qiongkai Xu

The success of DNNs often depends on training with large-scale datasets, but
building such datasets is both expensive and challenging. Consequently, public
datasets from open-source platforms like HuggingFace have become popular,
posing significant risks of data poisoning attacks. Existing backdoor defenses
in NLP primarily focus on identifying and removing poisoned samples; however,
purifying a backdoored model with these sample-cleaning approaches typically
requires expensive retraining. Therefore, we propose Greedy Module Substitution
(GMS), which identifies and substitutes ''deadwood'' modules (i.e., components
critical to backdoor pathways) in a backdoored model to purify it. Our method
relaxes the common dependency of prior model purification methods on clean
datasets or clean auxiliary models. When applied to RoBERTa-large under
backdoor attacks, GMS demonstrates strong effectiveness across various
settings, particularly against widely recognized challenging attacks like LWS,
achieving a post-purification attack success rate (ASR) of 9.7% on SST-2
compared to 58.8% for the best baseline approach.

摘要：DNN 的成功通常取决于使用大规模数据集进行训练，但构建此类数据集既昂贵又具有挑战性。因此，来自 HuggingFace 等开源平台的公共数据集已变得流行，对数据中毒攻击构成了重大风险。现有的 NLP 后门防御主要集中于识别和移除中毒样本；然而，使用这些样本清理方法净化后门模型通常需要昂贵的重新训练。因此，我们提出了贪婪模块替换 (GMS)，它识别并替换后门模型中的“废弃”模块（即对后门路径至关重要的组件）以对其进行净化。我们的方法消除了先前模型净化方法对干净数据集或干净辅助模型的常见依赖性。当应用于 RoBERTa-large 受到后门攻击时，GMS 在各种设置中展示了很强的有效性，特别是针对 LWS 等公认的具有挑战性的攻击，在 SST-2 上实现了 9.7% 的净化后攻击成功率 (ASR)，而最佳基线方法为 58.8%。

##### **A Comprehensive Framework for Reliable Legal AI: Combining Specialized Expert Systems and Adaptive Refinement**
2412.20468v1 by Sidra Nasir, Qamar Abbas, Samita Bai, Rizwan Ahmed Khan

This article discusses the evolving role of artificial intelligence (AI) in
the legal profession, focusing on its potential to streamline tasks such as
document review, research, and contract drafting. However, challenges persist,
particularly the occurrence of "hallucinations" in AI models, where they
generate inaccurate or misleading information, undermining their reliability in
legal contexts. To address this, the article proposes a novel framework
combining a mixture of expert systems with a knowledge-based architecture to
improve the precision and contextual relevance of AI-driven legal services.
This framework utilizes specialized modules, each focusing on specific legal
areas, and incorporates structured operational guidelines to enhance
decision-making. Additionally, it leverages advanced AI techniques like
Retrieval-Augmented Generation (RAG), Knowledge Graphs (KG), and Reinforcement
Learning from Human Feedback (RLHF) to improve the system's accuracy. The
proposed approach demonstrates significant improvements over existing AI
models, showcasing enhanced performance in legal tasks and offering a scalable
solution to provide more accessible and affordable legal services. The article
also outlines the methodology, system architecture, and promising directions
for future research in AI applications for the legal sector.

摘要：本文探討人工智慧 (AI) 在法律專業中不斷演變的角色，重點在於其簡化文件審查、研究和合約起草等任務的潛力。然而，挑戰依然存在，特別是 AI 模型中出現「幻覺」，它們會產生不準確或誤導性資訊，損害其在法律脈絡中的可靠性。為了解決這個問題，本文提出一個創新的架構，結合專家系統與基於知識的架構，以提高 AI 驅動法律服務的精確度和情境相關性。此架構使用專門的模組，每個模組都專注於特定法律領域，並納入結構化的操作指南以增強決策制定。此外，它利用先進的 AI 技術，例如檢索增強生成 (RAG)、知識圖 (KG) 和透過人類回饋進行強化學習 (RLHF)，以提高系統的準確性。所提出的方法展示出比現有 AI 模型有顯著的進步，展示了在法律任務中增強的效能，並提供可擴充的解決方案，以提供更平易近人且負擔得起的法律服務。本文也概述了方法論、系統架構和法律部門 AI 應用未來研究的有希望的方向。

##### **Utilizing Multimodal Data for Edge Case Robust Call-sign Recognition and Understanding**
2412.20467v1 by Alexander Blatt, Dietrich Klakow

Operational machine-learning based assistant systems must be robust in a wide
range of scenarios. This hold especially true for the air-traffic control (ATC)
domain. The robustness of an architecture is particularly evident in edge
cases, such as high word error rate (WER) transcripts resulting from noisy ATC
recordings or partial transcripts due to clipped recordings. To increase the
edge-case robustness of call-sign recognition and understanding (CRU), a core
tasks in ATC speech processing, we propose the multimodal call-sign-command
recovery model (CCR). The CCR architecture leads to an increase in the edge
case performance of up to 15%. We demonstrate this on our second proposed
architecture, CallSBERT. A CRU model that has less parameters, can be
fine-tuned noticeably faster and is more robust during fine-tuning than the
state of the art for CRU. Furthermore, we demonstrate that optimizing for edge
cases leads to a significantly higher accuracy across a wide operational range.

摘要：以机器学习为基础的操作助理系统必须在各种场景中保持稳健。这对于空中交通管制 (ATC) 领域尤其如此。架构的稳健性在边缘案例中尤为明显，例如由于嘈杂的 ATC 录音或由于录音被剪切而导致的高词错误率 (WER) 转录。为了提高呼号识别和理解 (CRU) 的边缘案例稳健性，这是 ATC 语音处理中的核心任务，我们提出了多模态呼号命令恢复模型 (CCR)。CCR 架构使边缘案例性能提高了 15%。我们在我们提出的第二个架构 CallSBERT 上演示了这一点。CRU 模型的参数较少，可以明显更快地进行微调，并且在微调过程中比 CRU 的最新技术更稳健。此外，我们证明了针对边缘案例进行优化会导致在广泛的操作范围内显着提高准确性。

##### **Enhancing Entertainment Translation for Indian Languages using Adaptive Context, Style and LLMs**
2412.20440v1 by Pratik Rakesh Singh, Mohammadi Zaki, Pankaj Wasnik

We address the challenging task of neural machine translation (NMT) in the
entertainment domain, where the objective is to automatically translate a given
dialogue from a source language content to a target language. This task has
various applications, particularly in automatic dubbing, subtitling, and other
content localization tasks, enabling source content to reach a wider audience.
Traditional NMT systems typically translate individual sentences in isolation,
without facilitating knowledge transfer of crucial elements such as the context
and style from previously encountered sentences. In this work, we emphasize the
significance of these fundamental aspects in producing pertinent and
captivating translations. We demonstrate their significance through several
examples and propose a novel framework for entertainment translation, which, to
our knowledge, is the first of its kind. Furthermore, we introduce an algorithm
to estimate the context and style of the current session and use these
estimations to generate a prompt that guides a Large Language Model (LLM) to
generate high-quality translations. Our method is both language and
LLM-agnostic, making it a general-purpose tool. We demonstrate the
effectiveness of our algorithm through various numerical studies and observe
significant improvement in the COMET scores over various state-of-the-art LLMs.
Moreover, our proposed method consistently outperforms baseline LLMs in terms
of win-ratio.

摘要：我們解決了娛樂領域中神經機器翻譯 (NMT) 的挑戰性任務，目標是自動將給定的對話從原始語言內容翻譯成目標語言。此任務有各種應用，特別是在自動配音、字幕和其他內容在地化任務中，讓原始內容能接觸到更廣泛的受眾。傳統的 NMT 系統通常孤立地翻譯個別句子，而沒有促進先前遇到的句子中關鍵元素（例如上下文和風格）的知識轉移。在這項工作中，我們強調這些基本方面在產生相關且引人入勝的翻譯中的重要性。我們透過幾個範例展示它們的重要性，並提出一個娛樂翻譯的新架構，據我們所知，這是同類架構中的第一個。此外，我們引入一個演算法來估計當前對話的上下文和風格，並使用這些估計值來產生一個提示，引導大型語言模型 (LLM) 產生高品質的翻譯。我們的模型既與語言無關，也與 LLM 無關，使其成為一個通用工具。我們透過各種數值研究證明了我們演算法的有效性，並觀察到 COMET 分數在各種最先進的 LLM 上有顯著的提升。此外，我們提出的模型在勝率方面始終優於基準 LLM。

##### **Integrating Natural Language Processing Techniques of Text Mining Into Financial System: Applications and Limitations**
2412.20438v1 by Denisa Millo, Blerina Vika, Nevila Baci

The financial sector, a pivotal force in economic development, increasingly
uses the intelligent technologies such as natural language processing to
enhance data processing and insight extraction. This research paper through a
review process of the time span of 2018-2023 explores the use of text mining as
natural language processing techniques in various components of the financial
system including asset pricing, corporate finance, derivatives, risk
management, and public finance and highlights the need to address the specific
problems in the discussion section. We notice that most of the research
materials combined probabilistic with vector-space models, and text-data with
numerical ones. The most used technique regarding information processing is the
information classification technique and the most used algorithms include the
long-short term memory and bidirectional encoder models. The research noticed
that new specific algorithms are developed and the focus of the financial
system is mainly on asset pricing component. The research also proposes a path
from engineering perspective for researchers who need to analyze financial
text. The challenges regarding text mining perspective such as data quality,
context-adaption and model interpretability need to be solved so to integrate
advanced natural language processing models and techniques in enhancing
financial analysis and prediction. Keywords: Financial System (FS), Natural
Language Processing (NLP), Software and Text Engineering, Probabilistic,
Vector-Space, Models, Techniques, TextData, Financial Analysis.

摘要：金融部門是經濟發展的關鍵力量，越來越多地使用自然語言處理等智慧技術來增強數據處理和洞察力萃取。本研究論文透過 2018-2023 年的時間跨度審查過程，探討了文本探勘作為自然語言處理技術在金融系統的各種組成部分中的應用，包括資產定價、公司財務、衍生性商品、風險管理和公共財務，並強調了在討論部分中解決具體問題的必要性。我們注意到，大多數研究材料將機率模型與向量空間模型以及文本資料與數值資料結合在一起。關於資訊處理的最常用技術是資訊分類技術，最常用的演算法包括長短期記憶和雙向編碼器模型。研究注意到新的特定演算法被開發出來，而金融系統的重點主要在於資產定價組成部分。本研究還提出了研究人員分析財務文本所需的工程觀點路徑。關於文本探勘觀點的挑戰，例如資料品質、情境適應和模型可解釋性，需要解決，才能整合先進的自然語言處理模型和技術，以增強財務分析和預測。關鍵字：金融系統 (FS)、自然語言處理 (NLP)、軟體和文字工程、機率、向量空間、模型、技術、文本資料、財務分析。

##### **Comparative Performance of Advanced NLP Models and LLMs in Multilingual Geo-Entity Detection**
2412.20414v1 by Kalin Kopanov

The integration of advanced Natural Language Processing (NLP) methodologies
and Large Language Models (LLMs) has significantly enhanced the extraction and
analysis of geospatial data from multilingual texts, impacting sectors such as
national and international security. This paper presents a comprehensive
evaluation of leading NLP models -- SpaCy, XLM-RoBERTa, mLUKE, GeoLM -- and
LLMs, specifically OpenAI's GPT 3.5 and GPT 4, within the context of
multilingual geo-entity detection. Utilizing datasets from Telegram channels in
English, Russian, and Arabic, we examine the performance of these models
through metrics such as accuracy, precision, recall, and F1 scores, to assess
their effectiveness in accurately identifying geospatial references. The
analysis exposes each model's distinct advantages and challenges, underscoring
the complexities involved in achieving precise geo-entity identification across
varied linguistic landscapes. The conclusions drawn from this experiment aim to
direct the enhancement and creation of more advanced and inclusive NLP tools,
thus advancing the field of geospatial analysis and its application to global
security.

摘要：自然語言處理 (NLP) 先進方法和大型語言模型 (LLM) 的整合，大幅提升了從多語言文本中擷取和分析地理空間資料的能力，對國家和國際安全等領域產生了重大影響。本文提供了領先的 NLP 模型（SpaCy、XLM-RoBERTa、mLUKE、GeoLM）和 LLM（特別是 OpenAI 的 GPT 3.5 和 GPT 4）在多語言地理實體偵測方面的全面評估。我們使用來自 Telegram 頻道的英文、俄文和阿拉伯文資料集，透過準確度、精確度、召回率和 F1 分數等指標來檢驗這些模型的效能，評估它們在準確識別地理空間參考方面的有效性。分析揭露了每個模型獨特的優點和挑戰，強調了在不同的語言環境中實現精確地理實體識別所涉及的複雜性。從這個實驗中得出的結論旨在引導更先進和更具包容性的 NLP 工具的開發和創建，從而促進地理空間分析領域的進步及其在全球安全中的應用。

##### **Multi-Objective Large Language Model Unlearning**
2412.20412v1 by Zibin Pan, Shuwen Zhang, Yuesheng Zheng, Chi Li, Yuheng Cheng, Junhua Zhao

Machine unlearning in the domain of large language models (LLMs) has
attracted great attention recently, which aims to effectively eliminate
undesirable behaviors from LLMs without full retraining from scratch. In this
paper, we explore the Gradient Ascent (GA) approach in LLM unlearning, which is
a proactive way to decrease the prediction probability of the model on the
target data in order to remove their influence. We analyze two challenges that
render the process impractical: gradient explosion and catastrophic forgetting.
To address these issues, we propose Multi-Objective Large Language Model
Unlearning (MOLLM) algorithm. We first formulate LLM unlearning as a
multi-objective optimization problem, in which the cross-entropy loss is
modified to the unlearning version to overcome the gradient explosion issue. A
common descent update direction is then calculated, which enables the model to
forget the target data while preserving the utility of the LLM. Our empirical
results verify that MoLLM outperforms the SOTA GA-based LLM unlearning methods
in terms of unlearning effect and model utility preservation.

摘要：機器在大型語言模型（LLM）領域的去學習最近備受關注，其目標是有效消除 LLM 中的不良行為，而無需從頭開始進行完全重新訓練。在本文中，我們探討了 LLM 去學習中的梯度上升（GA）方法，這是一種主動方式，可以降低模型對目標數據的預測機率，以消除其影響。我們分析了兩個使這個過程不切實際的挑戰：梯度爆炸和災難性遺忘。為了解決這些問題，我們提出了多目標大型語言模型去學習（MOLLM）演算法。我們首先將 LLM 去學習制定為多目標最佳化問題，其中交叉熵損失被修改為去學習版本，以克服梯度爆炸問題。然後計算出一個常見的下降更新方向，這使模型能夠忘記目標數據，同時保留 LLM 的效用。我們的實證結果驗證了 MoLLM 在去學習效果和模型效用保留方面優於基於 SOTA GA 的 LLM 去學習方法。

##### **Natural Language Fine-Tuning**
2412.20382v1 by Jia Liu, Yue Wang, Zhiqi Lin, Min Chen, Yixue Hao, Long Hu

Large language model fine-tuning techniques typically depend on extensive
labeled data, external guidance, and feedback, such as human alignment, scalar
rewards, and demonstration. However, in practical application, the scarcity of
specific knowledge poses unprecedented challenges to existing fine-tuning
techniques. In this paper, focusing on fine-tuning tasks in specific domains
with limited data, we introduce Natural Language Fine-Tuning (NLFT), which
utilizes natural language for fine-tuning for the first time. By leveraging the
strong language comprehension capability of the target LM, NLFT attaches the
guidance of natural language to the token-level outputs. Then, saliency tokens
are identified with calculated probabilities. Since linguistic information is
effectively utilized in NLFT, our proposed method significantly reduces
training costs. It markedly enhances training efficiency, comprehensively
outperforming reinforcement fine-tuning algorithms in accuracy, time-saving,
and resource conservation. Additionally, on the macro level, NLFT can be viewed
as a token-level fine-grained optimization of SFT, thereby efficiently
replacing the SFT process without the need for warm-up (as opposed to ReFT
requiring multiple rounds of warm-up with SFT). Compared to SFT, NLFT does not
increase the algorithmic complexity, maintaining O(n). Extensive experiments on
the GSM8K dataset demonstrate that NLFT, with only 50 data instances, achieves
an accuracy increase that exceeds SFT by 219%. Compared to ReFT, the time
complexity and space complexity of NLFT are reduced by 78.27% and 92.24%,
respectively. The superior technique of NLFT is paving the way for the
deployment of various innovative LLM fine-tuning applications when resources
are limited at network edges.
  Our code has been released at https://github.com/Julia-LiuJ/NLFT.

摘要：大型语言模型微调技术通常依赖于广泛的标记数据、外部指导和反馈，例如人工对齐、标量奖励和演示。然而，在实际应用中，特定知识的稀缺性给现有的微调技术带来了前所未有的挑战。在本文中，我们专注于利用自然语言进行微调，针对数据有限的特定领域的微调任务，我们引入了自然语言微调 (NLFT)，这是首次利用自然语言进行微调。通过利用目标 LM 强大的语言理解能力，NLFT 将自然语言的指导附加到令牌级别的输出中。然后，使用计算出的概率识别显着令牌。由于语言信息在 NLFT 中得到了有效利用，我们提出的方法大大降低了训练成本。它显著提高了训练效率，在准确性、节省时间和资源节约方面全面优于强化微调算法。此外，在宏观层面上，NLFT 可以被视为 SFT 的令牌级细粒度优化，从而有效地取代 SFT 过程，而无需预热（与 ReFT 需要多轮 SFT 预热相反）。与 SFT 相比，NLFT 不会增加算法复杂度，保持 O(n)。在 GSM8K 数据集上的广泛实验表明，NLFT 仅使用 50 个数据实例，其准确性提升超过 SFT 219%。与 ReFT 相比，NLFT 的时间复杂度和空间复杂度分别降低了 78.27% 和 92.24%。当网络边缘的资源有限时，NLFT 的卓越技术为各种创新 LLM 微调应用程序的部署铺平了道路。我们的代码已在 https://github.com/Julia-LiuJ/NLFT 发布。

##### **A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data**
2412.20373v1 by Seungyeon Lee, Ruoqi Liu, Feixiong Cheng, Ping Zhang

Drug repurposing identifies new therapeutic uses for existing drugs, reducing
the time and costs compared to traditional de novo drug discovery. Most
existing drug repurposing studies using real-world patient data often treat the
entire population as homogeneous, ignoring the heterogeneity of treatment
responses across patient subgroups. This approach may overlook promising drugs
that benefit specific subgroups but lack notable treatment effects across the
entire population, potentially limiting the number of repurposable candidates
identified. To address this, we introduce STEDR, a novel drug repurposing
framework that integrates subgroup analysis with treatment effect estimation.
Our approach first identifies repurposing candidates by emulating multiple
clinical trials on real-world patient data and then characterizes patient
subgroups by learning subgroup-specific treatment effects. We deploy \model to
Alzheimer's Disease (AD), a condition with few approved drugs and known
heterogeneity in treatment responses. We emulate trials for over one thousand
medications on a large-scale real-world database covering over 8 million
patients, identifying 14 drug candidates with beneficial effects to AD in
characterized subgroups. Experiments demonstrate STEDR's superior capability in
identifying repurposing candidates compared to existing approaches.
Additionally, our method can characterize clinically relevant patient subgroups
associated with important AD-related risk factors, paving the way for precision
drug repurposing.

摘要：药物再利用为现有药物找出新的治疗用途，与传统的从头药物发现相比，减少了时间和成本。大多数使用真实世界患者数据的现有药物再利用研究通常将整个人群视为同质的，而忽略了不同患者亚组治疗反应的异质性。这种方法可能会忽视对特定亚组有益但整个群体缺乏显着治疗效果的有希望的药物，从而可能限制已识别的可再利用候选药物的数量。为了解决这个问题，我们引入了 STEDR，这是一个新颖的药物再利用框架，它将亚组分析与治疗效果估计相结合。我们的方法首先通过模拟真实世界患者数据的多个临床试验来识别再利用候选药物，然后通过学习亚组特异性治疗效果来表征患者亚组。我们部署\model到阿尔茨海默病 (AD)，这是一种已获批药物较少且治疗反应已知异质性的疾病。我们在一个覆盖超过 800 万患者的大规模真实世界数据库上模拟了超过一千种药物的试验，确定了 14 种在表征的亚组中对 AD 有益的候选药物。实验表明，与现有方法相比，STEDR 在识别再利用候选药物方面具有更强的能力。此外，我们的方法可以表征与重要的 AD 相关危险因素相关的临床相关患者亚组，为精准药物再利用铺平道路。

##### **LLM2: Let Large Language Models Harness System 2 Reasoning**
2412.20372v1 by Cheng Yang, Chufan Shi, Siheng Li, Bo Shui, Yujiu Yang, Wai Lam

Large language models (LLMs) have exhibited impressive capabilities across a
myriad of tasks, yet they occasionally yield undesirable outputs. We posit that
these limitations are rooted in the foundational autoregressive architecture of
LLMs, which inherently lacks mechanisms for differentiating between desirable
and undesirable results. Drawing inspiration from the dual-process theory of
human cognition, we introduce LLM2, a novel framework that combines an LLM
(System 1) with a process-based verifier (System 2). Within LLM2, the LLM is
responsible for generating plausible candidates, while the verifier provides
timely process-based feedback to distinguish desirable and undesirable outputs.
The verifier is trained with a pairwise comparison loss on synthetic
process-supervision data generated through our token quality exploration
strategy. Empirical results on mathematical reasoning benchmarks substantiate
the efficacy of LLM2, exemplified by an accuracy enhancement from 50.3 to 57.8
(+7.5) for Llama3-1B on GSM8K. Furthermore, when combined with
self-consistency, LLM2 achieves additional improvements, boosting major@20
accuracy from 56.2 to 70.2 (+14.0).

摘要：大型語言模型 (LLM) 在各種任務中表現出令人印象深刻的能力，但它們偶爾會產生不良的輸出。我們假設這些限制根植於 LLM 的基礎自回歸架構，它本質上缺乏區分期望結果和不良結果的機制。從人類認知的雙重過程理論中汲取靈感，我們引入了 LLM2，這是一個新穎的框架，它將 LLM（系統 1）與基於流程的驗證器（系統 2）相結合。在 LLM2 中，LLM 負責產生合理的候選項，而驗證器則提供及時的基於流程的回饋，以區分期望輸出和不良輸出。驗證器使用成對比較損失在通過我們的代幣品質探索策略生成的合成流程監督數據上進行訓練。數學推理基準上的經驗結果證實了 LLM2 的有效性，Llama3-1B 在 GSM8K 上的準確率從 50.3 提升到 57.8（+7.5）就是一個例子。此外，當與自洽性相結合時，LLM2 可以實現進一步的改進，將 major@20 準確率從 56.2 提升到 70.2（+14.0）。

##### **Enhancing Code LLMs with Reinforcement Learning in Code Generation**
2412.20367v1 by Junqiao Wang, Zeng Zhang, Yangfan He, Yuyang Song, Tianyu Shi, Yuchen Li, Hengyuan Xu, Kunyu Wu, Guangwu Qian, Qiuwu Chen, Lewei He

With the rapid evolution of large language models (LLM), reinforcement
learning (RL) has emerged as a pivotal technique for code generation and
optimization in various domains. This paper presents a systematic survey of the
application of RL in code optimization and generation, highlighting its role in
enhancing compiler optimization, resource allocation, and the development of
frameworks and tools. Subsequent sections first delve into the intricate
processes of compiler optimization, where RL algorithms are leveraged to
improve efficiency and resource utilization. The discussion then progresses to
the function of RL in resource allocation, emphasizing register allocation and
system optimization. We also explore the burgeoning role of frameworks and
tools in code generation, examining how RL can be integrated to bolster their
capabilities. This survey aims to serve as a comprehensive resource for
researchers and practitioners interested in harnessing the power of RL to
advance code generation and optimization techniques.

摘要：隨著大型語言模型 (LLM) 的快速發展，強化學習 (RL) 已成為各種領域中用於程式碼生成和最佳化的關鍵技術。本文系統性地綜述了 RL 在程式碼最佳化和生成中的應用，重點說明其在增強編譯器最佳化、資源配置以及框架和工具開發中的作用。後續章節首先深入探討編譯器最佳化的複雜過程，其中利用 RL 演算法來提高效率和資源利用率。接著討論 RL 在資源配置中的功能，強調暫存器配置和系統最佳化。我們還探討了框架和工具在程式碼生成中日益重要的作用，探討如何整合 RL 來提升其功能。本綜述旨在為有興趣利用 RL 的力量來推進程式碼生成和最佳化技術的研究人員和從業人員提供全面的資源。

##### **Safe Multiagent Coordination via Entropic Exploration**
2412.20361v1 by Ayhan Alp Aydeniz, Enrico Marchesini, Robert Loftin, Christopher Amato, Kagan Tumer

Many real-world multiagent learning problems involve safety concerns. In
these setups, typical safe reinforcement learning algorithms constrain agents'
behavior, limiting exploration -- a crucial component for discovering effective
cooperative multiagent behaviors. Moreover, the multiagent literature typically
models individual constraints for each agent and has yet to investigate the
benefits of using joint team constraints. In this work, we analyze these team
constraints from a theoretical and practical perspective and propose entropic
exploration for constrained multiagent reinforcement learning (E2C) to address
the exploration issue. E2C leverages observation entropy maximization to
incentivize exploration and facilitate learning safe and effective cooperative
behaviors. Experiments across increasingly complex domains show that E2C agents
match or surpass common unconstrained and constrained baselines in task
performance while reducing unsafe behaviors by up to $50\%$.

摘要：在許多真實世界的多智能體學習問題中，都涉及到安全問題。在這些設定中，典型的安全強化學習演算法會限制智能體的行為，限制探索——探索是發現有效合作多智能體行為的關鍵組成部分。此外，多智能體文獻通常為每個智能體建模個別約束，但尚未探討使用聯合團隊約束的好處。在這項工作中，我們從理論和實務角度分析這些團隊約束，並提出用於受約束多智能體強化學習（E2C）的熵探索，以解決探索問題。E2C 利用觀測熵最大化來激勵探索，並促進學習安全且有效的合作行為。在越來越複雜的領域中進行的實驗表明，E2C 智能體在任務執行中匹配或超越常見的無約束和受約束基線，同時將不安全行為減少了 50%。

##### **EmoReg: Directional Latent Vector Modeling for Emotional Intensity Regularization in Diffusion-based Voice Conversion**
2412.20359v1 by Ashishkumar Gudmalwar, Ishan D. Biyani, Nirmesh Shah, Pankaj Wasnik, Rajiv Ratn Shah

The Emotional Voice Conversion (EVC) aims to convert the discrete emotional
state from the source emotion to the target for a given speech utterance while
preserving linguistic content. In this paper, we propose regularizing emotion
intensity in the diffusion-based EVC framework to generate precise speech of
the target emotion. Traditional approaches control the intensity of an
emotional state in the utterance via emotion class probabilities or intensity
labels that often lead to inept style manipulations and degradations in
quality. On the contrary, we aim to regulate emotion intensity using
self-supervised learning-based feature representations and unsupervised
directional latent vector modeling (DVM) in the emotional embedding space
within a diffusion-based framework. These emotion embeddings can be modified
based on the given target emotion intensity and the corresponding direction
vector. Furthermore, the updated embeddings can be fused in the reverse
diffusion process to generate the speech with the desired emotion and
intensity. In summary, this paper aims to achieve high-quality emotional
intensity regularization in the diffusion-based EVC framework, which is the
first of its kind work. The effectiveness of the proposed method has been shown
across state-of-the-art (SOTA) baselines in terms of subjective and objective
evaluations for the English and Hindi languages \footnote{Demo samples are
available at the following URL: \url{https://nirmesh-sony.github.io/EmoReg/}}.

摘要：情緒化語音轉換 (EVC) 旨在將離散情緒狀態從來源情緒轉換到目標，以針對特定語音發話，同時保留語言內容。在本文中，我們提議在基於擴散的 EVC 架構中調整情緒強度，以產生目標情緒的精確語音。傳統方法透過情緒類別機率或強度標籤來控制發話中情緒狀態的強度，這通常會導致不恰當的風格操作和品質下降。相反地，我們旨在使用基於自監督學習的特徵表示和在基於擴散的架構中的情緒嵌入空間中無監督方向潛在向量建模 (DVM) 來調整情緒強度。這些情緒嵌入可以根據給定的目標情緒強度和對應的方向向量進行修改。此外，更新的嵌入可以融合在反向擴散過程中，以產生具有所需情緒和強度的語音。總之，本文旨在在基於擴散的 EVC 架構中實現高品質的情緒強度調整，這是同類工作中的第一個。所提出的方法的有效性已在主觀和客觀評估方面展現於最先進 (SOTA) 基準，針對英語和印地語語言\footnote{示範範例可在以下網址取得：\url{https://nirmesh-sony.github.io/EmoReg/}}。

##### **HindiLLM: Large Language Model for Hindi**
2412.20357v1 by Sanjay Chouhan, Shubha Brata Nath, Aparajita Dutta

The advancements in the Large Language Model (LLM) have helped in solving
several problems related to language processing. Most of the researches have
focused on the English language only, because of its popularity and abundance
on the internet. However, a high-performance language model for Hindi and other
Indic languages is lacking in the literature. In this work, we have pre-trained
two autoregressive LLM models for the Hindi language, namely HindiLLM-Small and
HindiLLM-Medium. We use a two-step process comprising unsupervised pre-training
and supervised fine-tuning. First, we create a large and high-quality text
corpus for unsupervised pre-training. Next, we train a Byte-Pair Encoding,
named HindiLLM tokenizer, using the pre-training text data. We then perform
training on the unlabeled data, known as the pre-training step, to get the
HindiLLM base models. Furthermore, we perform fine-tuning of the HindiLLM base
models for different tasks like sentiment analysis, text classification,
natural language inference, and multiple choice question-answer on popular
labeled datasets to measure the real-world performance. The evaluation shows
that the HindiLLM-based fine-tuned models outperform several models in most of
the language related tasks.

摘要：大型語言模型 (LLM) 的進步有助於解決與語言處理相關的幾個問題。由於其普及性和網路上的豐富性，大多數研究僅專注於英語。然而，文獻中缺乏針對印地語和其他印度語言的高效能語言模型。在這項工作中，我們預訓練了兩個針對印地語的自動迴歸 LLM 模型，分別為 HindiLLM-Small 和 HindiLLM-Medium。我們使用包含無監督預訓練和監督微調的兩步驟流程。首先，我們建立一個大型且高品質的文字語料庫，用於無監督預訓練。接下來，我們使用預訓練文字資料訓練名為 HindiLLM 分詞器的位元組對編碼。然後，我們對未標記資料執行訓練，稱為預訓練步驟，以取得 HindiLLM 基礎模型。此外，我們對 HindiLLM 基礎模型執行微調，以執行不同的任務，例如情緒分析、文字分類、自然語言推論和熱門標籤資料集上的多重選擇問答，以衡量實際效能。評估顯示，基於 HindiLLM 的微調模型在大部分與語言相關的任務中優於其他模型。

##### **Distilling Desired Comments for Enhanced Code Review with Large Language Models**
2412.20340v1 by Yongda Yu, Lei Zhang, Guoping Rong, Haifeng Shen, Jiahao Zhang, Haoxiang Yan, Guohao Shi, Dong Shao, Ruiqi Pan, Yuan Li, Qiushi Wang, Zhao Tian

There has been a growing interest in using Large Language Models (LLMs) for
code review thanks to their proven proficiency in code comprehension. The
primary objective of most review scenarios is to generate desired review
comments (DRCs) that explicitly identify issues to trigger code fixes. However,
existing LLM-based solutions are not so effective in generating DRCs for
various reasons such as hallucination. To enhance their code review ability,
they need to be fine-tuned with a customized dataset that is ideally full of
DRCs. Nevertheless, such a dataset is not yet available, while manual
annotation of DRCs is too laborious to be practical. In this paper, we propose
a dataset distillation method, Desiview, which can automatically construct a
distilled dataset by identifying DRCs from a code review dataset. Experiments
on the CodeReviewer dataset comprising more than 150K review entries show that
Desiview achieves an impressive performance of 88.93%, 80.37%, 86.67%, and
84.44% in terms of Precision, Recall, Accuracy, and F1, respectively,
surpassing state-of-the-art methods. To validate the effect of such a distilled
dataset on enhancing LLMs' code review ability, we first fine-tune the latest
LLaMA series (i.e., LLaMA 3 and LLaMA 3.1) to build model Desiview4FT. We then
enhance the model training effect through KTO alignment by feeding those review
comments identified as non-DRCs to the LLMs, resulting in model Desiview4FA.
Verification results indicate that Desiview4FA slightly outperforms
Desiview4FT, while both models have significantly improved against the base
models in terms of generating DRCs. Human evaluation confirms that both models
identify issues more accurately and tend to generate review comments that
better describe the issues contained in the code than the base LLMs do.

摘要：<paragraph>由於大型語言模型 (LLM) 在程式碼理解方面已證明其能力，因此使用 LLM 進行程式碼檢閱的興趣日益增加。大多數檢閱情境的初階目標是產生明確指出問題以觸發程式碼修正的預期檢閱評論 (DRC)。然而，現有的基於 LLM 的解決方案由於幻覺等各種原因，在產生 DRC 方面並非如此有效。為了增強其程式碼檢閱能力，需要使用理想情況下充滿 DRC 的自訂資料集對其進行微調。儘管如此，此類資料集尚未推出，而 DRC 的手動註解又太過費力，不切實際。在本文中，我們提出了一種資料集萃取方法 Desiview，它可以透過從程式碼檢閱資料集中識別 DRC 來自動建構萃取的資料集。在包含超過 15 萬個檢閱條目的 CodeReviewer 資料集上進行的實驗表明，Desiview 在準確度、召回率、準確性和 F1 方面分別達到了令人印象深刻的 88.93%、80.37%、86.67% 和 84.44%，超越了最先進的方法。為了驗證此類萃取資料集對增強 LLM 程式碼檢閱能力的影響，我們首先微調了最新的 LLaMA 系列（即 LLaMA 3 和 LLaMA 3.1）來建構模型 Desiview4FT。然後，我們透過 KTO 對齊來增強模型訓練效果，方法是將那些被識別為非 DRC 的檢閱評論提供給 LLM，從而產生模型 Desiview4FA。驗證結果表明，Desiview4FA 略勝於 Desiview4FT，而這兩個模型在產生 DRC 方面都顯著優於基礎模型。人工評估證實，這兩個模型都能更準確地識別問題，並且傾向於產生比基礎 LLM 更能描述程式碼中所含問題的檢閱評論。</paragraph>

##### **Mind the Data Gap: Bridging LLMs to Enterprise Data Integration**
2412.20331v1 by Moe Kayali, Fabian Wenz, Nesime Tatbul, Çağatay Demiralp

Leading large language models (LLMs) are trained on public data. However,
most of the world's data is dark data that is not publicly accessible, mainly
in the form of private organizational or enterprise data. We show that the
performance of methods based on LLMs seriously degrades when tested on
real-world enterprise datasets. Current benchmarks, based on public data,
overestimate the performance of LLMs. We release a new benchmark dataset, the
GOBY Benchmark, to advance discovery in enterprise data integration. Based on
our experience with this enterprise benchmark, we propose techniques to uplift
the performance of LLMs on enterprise data, including (1) hierarchical
annotation, (2) runtime class-learning, and (3) ontology synthesis. We show
that, once these techniques are deployed, the performance on enterprise data
becomes on par with that of public data. The Goby benchmark can be obtained at
https://goby-benchmark.github.io/.

摘要：領先的大語言模型 (LLM) 是根據公開資料訓練的。然而，世界上大部分的資料都是難以公開取得的暗資料，主要以私人組織或企業資料的形式存在。我們展示了在實際企業資料集上進行測試時，基於 LLM 的方法的效能嚴重下降。基於公開資料的當前基準過度高估了 LLM 的效能。我們發布了一個新的基準資料集，即 Goby 基準，以推動企業資料整合的發現。根據我們使用此企業基準的經驗，我們提出了提升 LLM 在企業資料上效能的技術，包括 (1) 層級註解、(2) 執行時期類別學習，以及 (3) 本体合成。我們展示了在部署這些技術後，企業資料上的效能已與公開資料相當。Goby 基準可以在 https://goby-benchmark.github.io/ 取得。

##### **Protein Structure Prediction in the 3D HP Model Using Deep Reinforcement Learning**
2412.20329v1 by Giovanny Espitia, Yui Tik Pang, James C. Gumbart

We address protein structure prediction in the 3D Hydrophobic-Polar lattice
model through two novel deep learning architectures. For proteins under 36
residues, our hybrid reservoir-based model combines fixed random projections
with trainable deep layers, achieving optimal conformations with 25% fewer
training episodes. For longer sequences, we employ a long short-term memory
network with multi-headed attention, matching best-known energy values. Both
architectures leverage a stabilized Deep Q-Learning framework with experience
replay and target networks, demonstrating consistent achievement of optimal
conformations while significantly improving training efficiency compared to
existing methods.

摘要：我們透過兩種新穎的深度學習架構在 3D 疏水-親水格點模型中處理蛋白質結構預測。對於 36 個殘基以下的蛋白質，我們的混合儲存器模型結合固定隨機投影與可訓練深度層，以 25% 較少的訓練週期達成最佳構形。對於較長的序列，我們採用具有多頭注意力的長短期記憶網路，匹配最著名的能量值。兩種架構都利用穩定的深度 Q 學習框架，具備經驗重播和目標網路，展示出與現有方法相比，在顯著改善訓練效率的同時，始終如一地達成最佳構形。

##### **Hypergraph-Based Dynamic Graph Node Classification**
2412.20321v1 by Xiaoxu Ma, Chen Zhao, Minglai Shao, Yujie Lin

Node classification on static graphs has achieved significant success, but
achieving accurate node classification on dynamic graphs where node topology,
attributes, and labels change over time has not been well addressed. Existing
methods based on RNNs and self-attention only aggregate features of the same
node across different time slices, which cannot adequately address and capture
the diverse dynamic changes in dynamic graphs. Therefore, we propose a novel
model named Hypergraph-Based Multi-granularity Dynamic Graph Node
Classification (HYDG). After obtaining basic node representations for each
slice through a GNN backbone, HYDG models the representations of each node in
the dynamic graph through two modules. The individual-level hypergraph captures
the spatio-temporal node representations between individual nodes, while the
group-level hypergraph captures the multi-granularity group temporal
representations among nodes of the same class. Each hyperedge captures
different temporal dependencies of varying lengths by connecting multiple nodes
within specific time ranges. More accurate representations are obtained through
weighted information propagation and aggregation by the hypergraph neural
network. Extensive experiments on five real dynamic graph datasets using two
GNN backbones demonstrate the superiority of our proposed framework.

摘要：節點分類在靜態圖形上已取得顯著的成功，但對於節點拓撲、屬性和標籤會隨時間變化的動態圖形，要達成精確的節點分類仍未獲得妥善的解決。現有的方法基於 RNN 和自注意力，只會彙總不同時間切片中同一個節點的特徵，無法充分地處理和擷取動態圖形中多樣化的動態變化。因此，我們提出一個名為超圖形基於多粒度動態圖形節點分類 (HYDG) 的新模型。在透過 GNN 主幹為每個切片取得基本節點表示後，HYDG 會透過兩個模組來建模動態圖形中每個節點的表示。個別層級的超圖形擷取個別節點間的時空節點表示，而群組層級的超圖形則擷取同類別節點間的多粒度群組時間表示。每個超邊緣透過連接特定時間範圍內的多個節點，擷取不同長度的不同時間依賴性。更精確的表示是透過超圖形神經網路的加權資訊傳播和彙總所取得。在兩個 GNN 主幹上使用五個真實動態圖形資料集進行的廣泛實驗，證明了我們提出的架構的優越性。

##### **Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain**
2412.20309v1 by Shintaro Ozaki, Yuta Kato, Siyuan Feng, Masayo Tomita, Kazuki Hayashi, Ryoma Obara, Masafumi Oyamada, Katsuhiko Hayashi, Hidetaka Kamigaito, Taro Watanabe

Retrieval Augmented Generation (RAG) complements the knowledge of Large
Language Models (LLMs) by leveraging external information to enhance response
accuracy for queries. This approach is widely applied in several fields by
taking its advantage of injecting the most up-to-date information, and
researchers are focusing on understanding and improving this aspect to unlock
the full potential of RAG in such high-stakes applications. However, despite
the potential of RAG to address these needs, the mechanisms behind the
confidence levels of its outputs remain underexplored, although the confidence
of information is very critical in some domains, such as finance, healthcare,
and medicine. Our study focuses the impact of RAG on confidence within the
medical domain under various configurations and models. We evaluate confidence
by treating the model's predicted probability as its output and calculating
Expected Calibration Error (ECE) and Adaptive Calibration Error (ACE) scores
based on the probabilities and accuracy. In addition, we analyze whether the
order of retrieved documents within prompts calibrates the confidence. Our
findings reveal large variation in confidence and accuracy depending on the
model, settings, and the format of input prompts. These results underscore the
necessity of optimizing configurations based on the specific model and
conditions.

摘要：檢索增強生成 (RAG) 透過利用外部資訊來提升回應精準度，以補充大型語言模型 (LLM) 的知識。此方法廣泛應用於多個領域，透過注入最新資訊來發揮優勢，而研究人員正專注於了解並改善此面向，以發揮 RAG 在此類高風險應用中的全部潛力。然而，儘管 RAG 有潛力滿足這些需求，但其輸出信心等級背後的機制仍未充分探討，儘管在某些領域（例如金融、醫療保健和醫學）中，資訊的信心至關重要。我們的研究著重於在各種組態和模型下，RAG 對醫療領域信心的影響。我們透過將模型預測的機率視為其輸出，並根據機率和準確度計算預期校準誤差 (ECE) 和適應性校準誤差 (ACE) 分數，來評估信心。此外，我們分析提示中檢索文件順序是否校準信心。我們的研究結果顯示，信心和準確度會因模型、設定和輸入提示格式而有很大的差異。這些結果強調了根據特定模型和條件最佳化組態的必要性。

##### **No Preference Left Behind: Group Distributional Preference Optimization**
2412.20299v1 by Binwei Yao, Zefan Cai, Yun-Shiuan Chuang, Shanglin Yang, Ming Jiang, Diyi Yang, Junjie Hu

Preferences within a group of people are not uniform but follow a
distribution. While existing alignment methods like Direct Preference
Optimization (DPO) attempt to steer models to reflect human preferences, they
struggle to capture the distributional pluralistic preferences within a group.
These methods often skew toward dominant preferences, overlooking the diversity
of opinions, especially when conflicting preferences arise. To address this
issue, we propose Group Distribution Preference Optimization (GDPO), a novel
framework that aligns language models with the distribution of preferences
within a group by incorporating the concept of beliefs that shape individual
preferences. GDPO calibrates a language model using statistical estimation of
the group's belief distribution and aligns the model with belief-conditioned
preferences, offering a more inclusive alignment framework than traditional
methods. In experiments using both synthetic controllable opinion generation
and real-world movie review datasets, we show that DPO fails to align with the
targeted belief distributions, while GDPO consistently reduces this alignment
gap during training. Moreover, our evaluation metrics demonstrate that GDPO
outperforms existing approaches in aligning with group distributional
preferences, marking a significant advance in pluralistic alignment.

摘要：群組中個人的偏好並非一致，而是遵循某種分配。現有的對齊方法（如直接偏好最佳化 (DPO)）試圖引導模型以反映人類偏好，但它們難以捕捉群組內部分配式的多元偏好。這些方法通常會偏向於主導偏好，忽略意見的多樣性，特別是在出現相互衝突的偏好時。為了解決這個問題，我們提出群組分配偏好最佳化 (GDPO)，這是一個新的架構，透過納入塑造個人偏好的信念概念，將語言模型與群組內偏好的分配對齊。GDPO 使用群組信念分配的統計估計值校準語言模型，並將模型與信念條件偏好對齊，提供比傳統方法更具包容性的對齊架構。在使用合成可控意見產生和真實電影評論資料集的實驗中，我們發現 DPO 無法與目標信念分配對齊，而 GDPO 在訓練期間持續縮小這個對齊差距。此外，我們的評估指標證明，GDPO 在與群組分配偏好對齊方面優於現有方法，標誌著多元對齊的重大進步。

##### **Transformer-Based Contrastive Meta-Learning For Low-Resource Generalizable Activity Recognition**
2412.20290v1 by Junyao Wang, Mohammad Abdullah Al Faruque

Deep learning has been widely adopted for human activity recognition (HAR)
while generalizing a trained model across diverse users and scenarios remains
challenging due to distribution shifts. The inherent low-resource challenge in
HAR, i.e., collecting and labeling adequate human-involved data can be
prohibitively costly, further raising the difficulty of tackling DS. We propose
TACO, a novel transformer-based contrastive meta-learning approach for
generalizable HAR. TACO addresses DS by synthesizing virtual target domains in
training with explicit consideration of model generalizability. Additionally,
we extract expressive feature with the attention mechanism of Transformer and
incorporate the supervised contrastive loss function within our
meta-optimization to enhance representation learning. Our evaluation
demonstrates that TACO achieves notably better performance across various
low-resource DS scenarios.

摘要：深度學習已被廣泛採用於人類活動辨識 (HAR)，然而，由於分佈轉移，在不同使用者和場景中推廣已訓練模型仍然具有挑戰性。HAR 中固有的低資源挑戰，即收集和標記足夠的人類參與資料可能成本高昂，進一步增加了應對 DS 的難度。我們提出 TACO，一種新穎的基於 Transformer 的對比元學習方法，用於可推廣的 HAR。TACO 通過在訓練中合成虛擬目標域來解決 DS，並明確考慮模型的可推廣性。此外，我們利用 Transformer 的注意力機制提取表達性特徵，並在我們的元優化中納入監督對比損失函數，以增強表示學習。我們的評估表明，TACO 在各種低資源 DS 場景中取得了顯著更好的效能。

##### **High-fidelity social learning via shared episodic memories enhances collaborative foraging through mnemonic convergence**
2412.20271v1 by Ismael T. Freire, Paul Verschure

Social learning, a cornerstone of cultural evolution, enables individuals to
acquire knowledge by observing and imitating others. At the heart of its
efficacy lies episodic memory, which encodes specific behavioral sequences to
facilitate learning and decision-making. This study explores the interrelation
between episodic memory and social learning in collective foraging. Using
Sequential Episodic Control (SEC) agents capable of sharing complete behavioral
sequences stored in episodic memory, we investigate how variations in the
frequency and fidelity of social learning influence collaborative foraging
performance. Furthermore, we analyze the effects of social learning on the
content and distribution of episodic memories across the group. High-fidelity
social learning is shown to consistently enhance resource collection efficiency
and distribution, with benefits sustained across memory lengths. In contrast,
low-fidelity learning fails to outperform nonsocial learning, spreading diverse
but ineffective mnemonic patterns. Novel analyses using mnemonic metrics reveal
that high-fidelity social learning also fosters mnemonic group alignment and
equitable resource distribution, while low-fidelity conditions increase
mnemonic diversity without translating to performance gains. Additionally, we
identify an optimal range for episodic memory length in this task, beyond which
performance plateaus. These findings underscore the critical effects of social
learning on mnemonic group alignment and distribution and highlight the
potential of neurocomputational models to probe the cognitive mechanisms
driving cultural evolution.

摘要：社會學習是文化演化的基石，它使個人能夠透過觀察和模仿他人來獲取知識。其效能的核心在於情節記憶，它編碼特定的行為序列以促進學習和決策制定。本研究探討了情節記憶和集體覓食中的社會學習之間的相互關係。我們使用能夠分享儲存在情節記憶中的完整行為序列的序列情節控制 (SEC) 代理，來調查社會學習的頻率和保真度變化如何影響協作覓食的表現。此外，我們分析了社會學習對群體中情節記憶的內容和分佈的影響。高保真度社會學習被證明能持續提升資源收集的效率和分配，且好處會隨著記憶長度而持續。相反，低保真度學習無法優於非社會學習，它會散佈多樣但無效的記憶模式。使用記憶度量的新穎分析顯示，高保真度社會學習也能促進記憶群體對齊和公平的資源分配，而低保真度條件會增加記憶多樣性，但不會轉化為效能提升。此外，我們在此任務中找出情節記憶長度的最佳範圍，超過此範圍後效能會達到平穩期。這些發現強調了社會學習對記憶群體對齊和分配的關鍵影響，並突顯了神經計算模型在探討驅動文化演化的認知機制的潛力。

##### **Scoring with Large Language Models: A Study on Measuring Empathy of Responses in Dialogues**
2412.20264v1 by Henry J. Xie, Jinghan Zhang, Xinhao Zhang, Kunpeng Liu

In recent years, Large Language Models (LLMs) have become increasingly more
powerful in their ability to complete complex tasks. One such task in which
LLMs are often employed is scoring, i.e., assigning a numerical value from a
certain scale to a subject. In this paper, we strive to understand how LLMs
score, specifically in the context of empathy scoring. We develop a novel and
comprehensive framework for investigating how effective LLMs are at measuring
and scoring empathy of responses in dialogues, and what methods can be employed
to deepen our understanding of LLM scoring. Our strategy is to approximate the
performance of state-of-the-art and fine-tuned LLMs with explicit and
explainable features. We train classifiers using various features of dialogues
including embeddings, the Motivational Interviewing Treatment Integrity (MITI)
Code, a set of explicit subfactors of empathy as proposed by LLMs, and a
combination of the MITI Code and the explicit subfactors. Our results show that
when only using embeddings, it is possible to achieve performance close to that
of generic LLMs, and when utilizing the MITI Code and explicit subfactors
scored by an LLM, the trained classifiers can closely match the performance of
fine-tuned LLMs. We employ feature selection methods to derive the most crucial
features in the process of empathy scoring. Our work provides a new perspective
toward understanding LLM empathy scoring and helps the LLM community explore
the potential of LLM scoring in social science studies.

摘要：近年來，大型語言模型 (LLM) 在完成複雜任務的能力上變得越來越強大。其中一項 LLM 常被用於執行的工作便是評分，也就是將某個標的從特定範圍中賦予一個數值。在本文中，我們致力於了解 LLM 如何評分，特別是在同理心評分的情境中。我們開發了一個新穎且全面的架構，用於探討 LLM 在對話中衡量和評分同理心的反應有多有效，以及可以採用哪些方法來加深我們對 LLM 評分的理解。我們的策略是利用明確且可解釋的功能來近似最先進且經過微調的 LLM 的效能。我們使用對話的各種功能來訓練分類器，包括嵌入、動機性訪談治療完整性 (MITI) 準則、LLM 提出的同理心明確子因子組，以及 MITI 準則和明確子因子的組合。我們的結果顯示，僅使用嵌入時，就有可能達到接近一般 LLM 的效能，而當使用 LLM 評分的 MITI 準則和明確子因子時，訓練出的分類器可以緊密匹配經過微調的 LLM 的效能。我們採用特徵選擇方法來推導同理心評分過程中最重要的特徵。我們的研究為理解 LLM 同理心評分提供了新的觀點，並幫助 LLM 社群探索 LLM 評分在社會科學研究中的潛力。

##### **ComparisonQA: Evaluating Factuality Robustness of LLMs Through Knowledge Frequency Control and Uncertainty**
2412.20251v1 by Qing Zong, Zhaowei Wang, Tianshi Zheng, Xiyu Ren, Yangqiu Song

The rapid development of LLMs has sparked extensive research into their
factual knowledge. Current works claim that LLMs fall short on questions
requiring less frequent knowledge. However, their proof is incomplete since
they only study the influence of entity frequency, which can not fully
represent knowledge frequency. So we introduce ComparisonQA benchmark,
containing 283K abstract questions, each instantiated by a pair of
high-frequency and low-frequency entities. It ensures a controllable comparison
because the difference of knowledge frequency between such a pair is only
related to entity frequency. In addition, to avoid possible semantic shortcuts,
which is a severe problem of current LLMs study, we design a two-round method
for knowledge robustness measurement utilizing both correctness and
uncertainty. Experiments reveal that LLMs exhibit particularly low robustness
regarding low-frequency knowledge, and GPT-4o is even the worst under this
measurement. Besides, we introduce an automatic method to filter out questions
with low-quality and shortcuts to form ComparisonQA-Hard. We find that
uncertainty effectively identifies such questions while maintaining the data
size.

摘要：大型語言模型的快速發展引發了對其事實知識的廣泛研究。目前的研究表明，大型語言模型在需要較不頻繁知識的問題上表現不佳。然而，他們的證明並不完整，因為他們只研究實體頻率的影響，而這無法完全代表知識頻率。因此，我們引入了 ComparisonQA 基準，其中包含 283K 個抽象問題，每個問題都由一對高頻率和低頻率實體實例化。它確保了可控的比較，因為這樣一對實體之間的知識頻率差異僅與實體頻率相關。此外，為了避免可能的語義捷徑（這是當前大型語言模型研究的嚴重問題），我們設計了一種兩輪方法來測量知識穩健性，同時利用正確性和不確定性。實驗表明，大型語言模型在低頻率知識方面表現出特別低的穩健性，而 GPT-4o 在這種測量下甚至是最差的。此外，我們引入了一種自動方法來過濾掉質量低且有捷徑的問題，以形成 ComparisonQA-Hard。我們發現不確定性可以有效地識別出這些問題，同時保持數據大小。

##### **How To Think About End-To-End Encryption and AI: Training, Processing, Disclosure, and Consent**
2412.20231v1 by Mallory Knodel, Andrés Fábrega, Daniella Ferrari, Jacob Leiken, Betty Li Hou, Derek Yen, Sam de Alfaro, Kyunghyun Cho, Sunoo Park

End-to-end encryption (E2EE) has become the gold standard for securing
communications, bringing strong confidentiality and privacy guarantees to
billions of users worldwide. However, the current push towards widespread
integration of artificial intelligence (AI) models, including in E2EE systems,
raises some serious security concerns. This work performs a critical
examination of the (in)compatibility of AI models and E2EE applications. We
explore this on two fronts: (1) the integration of AI "assistants" within E2EE
applications, and (2) the use of E2EE data for training AI models. We analyze
the potential security implications of each, and identify conflicts with the
security guarantees of E2EE. Then, we analyze legal implications of integrating
AI models in E2EE applications, given how AI integration can undermine the
confidentiality that E2EE promises. Finally, we offer a list of detailed
recommendations based on our technical and legal analyses, including: technical
design choices that must be prioritized to uphold E2EE security; how service
providers must accurately represent E2EE security; and best practices for the
default behavior of AI features and for requesting user consent. We hope this
paper catalyzes an informed conversation on the tensions that arise between the
brisk deployment of AI and the security offered by E2EE, and guides the
responsible development of new AI features.

摘要：端對端加密 (E2EE) 已成為確保通訊的金牌標準，為全球數十億用戶帶來強大的機密性和隱私保證。然而，目前朝著廣泛整合人工智慧 (AI) 模型（包括在 E2EE 系統中）的方向邁進，引發了一些嚴重的安全疑慮。這項工作對 AI 模型和 E2EE 應用程式的（不）相容性進行了嚴格的審查。我們從兩個方面探討這一點：(1) 在 E2EE 應用程式中整合 AI「助理」，以及 (2) 將 E2EE 資料用於訓練 AI 模型。我們分析了每種潛在的安全影響，並找出與 E2EE 的安全保證相衝突的地方。然後，我們分析在 E2EE 應用程式中整合 AI 模型的法律影響，考量到 AI 整合如何可能破壞 E2EE 所承諾的機密性。最後，我們根據我們的技術和法律分析提供了一份詳細建議清單，包括：必須優先考慮以維護 E2EE 安全性的技術設計選擇；服務供應商必須準確地表示 E2EE 安全性；以及 AI 功能的預設行為和請求使用者同意的最佳實務。我們希望這篇論文能促成一場關於在 AI 快速部署和 E2EE 提供的安全之間產生的緊張關係的明智對話，並指導負責任地開發新的 AI 功能。

##### **Leveraging Large Language Models for Enhancing Autonomous Vehicle Perception**
2412.20230v1 by Athanasios Karagounis

Autonomous vehicles (AVs) rely on sophisticated perception systems to
interpret their surroundings, a cornerstone for safe navigation and
decision-making. The integration of Large Language Models (LLMs) into AV
perception frameworks offers an innovative approach to address challenges in
dynamic environments, sensor fusion, and contextual reasoning. This paper
presents a novel framework for incorporating LLMs into AV perception, enabling
advanced contextual understanding, seamless sensor integration, and enhanced
decision support. Experimental results demonstrate that LLMs significantly
improve the accuracy and reliability of AV perception systems, paving the way
for safer and more intelligent autonomous driving technologies. By expanding
the scope of perception beyond traditional methods, LLMs contribute to creating
a more adaptive and human-centric driving ecosystem, making autonomous vehicles
more reliable and transparent in their operations. These advancements redefine
the relationship between human drivers and autonomous systems, fostering trust
through enhanced understanding and personalized decision-making. Furthermore,
by integrating memory modules and adaptive learning mechanisms, LLMs introduce
continuous improvement in AV perception, enabling vehicles to evolve with time
and adapt to changing environments and user preferences.

摘要：自動駕駛車輛 (AV) 依賴精密的感知系統來解讀周遭環境，這是安全導航和決策制定的基石。將大型語言模型 (LLM) 整合到 AV 感知架構中，提供了一個創新的方法來解決動態環境、感測器融合和情境推理中的挑戰。本文提出了一個新的架構，用於將 LLM 整合到 AV 感知中，實現進階情境理解、無縫感測器整合和增強決策支援。實驗結果證明，LLM 大幅提升了 AV 感知系統的準確度和可靠度，為更安全、更智慧的自動駕駛技術鋪路。透過將感知範圍擴展到傳統方法之外，LLM 有助於創造一個更具適應性和以人為中心的駕駛生態系統，讓自動駕駛車輛在運作上更可靠、更透明。這些進展重新定義了人類駕駛和自動系統之間的關係，透過增強理解和個人化決策制定來培養信任。此外，透過整合記憶模組和適應性學習機制，LLM 引入了 AV 感知中的持續改進，使車輛能夠隨著時間演進和適應不斷變化的環境和使用者偏好。

##### **LLM Reasoning Engine: Specialized Training for Enhanced Mathematical Reasoning**
2412.20227v1 by Shuguang Chen, Guang Lin

Large Language Models (LLMs) have shown remarkable performance in various
natural language processing tasks but face challenges in mathematical
reasoning, where complex problem-solving requires both linguistic understanding
and mathematical reasoning skills. Existing approaches to address this
challenge often rely on ensemble methods and suffer from the problem of data
scarcity in target domains. In this work, we present a novel method to enhance
LLMs' capabilities in mathematical reasoning tasks. Motivated by the need to
bridge this gap, our approach incorporates a question paraphrase strategy,
which aims at diversifying the linguistic forms of mathematical questions to
improve generalization. Additionally, specialized training objectives are
employed to guide the model's learning process, focusing on enhancing its
understanding of mathematical concepts and reasoning processes. We conduct
experiments on four datasets using different LLMs, and demonstrate the
effectiveness of our approach in improving LLMs' performance on mathematical
reasoning tasks. Our findings underscore the significance of our methodology in
the advancement of large language models and its potential implications for
real-world applications that require mathematical reasoning abilities.

摘要：大型語言模型（LLM）在各種自然語言處理任務中展現出卓越的效能，但在數學推理方面卻面臨挑戰，因為複雜的問題解決需要語言理解和數學推理技能。現有的方法經常依賴於整體方法，並且在目標領域中會遇到資料稀疏的問題。在本文中，我們提出了一種新方法來增強 LLM 在數學推理任務中的能力。我們的做法基於彌合此差距的需求，包含了一個問題改寫策略，其目的是使數學問題的語言形式多樣化，以改善概括性。此外，我們採用了專門的訓練目標來引導模型的學習過程，重點在於增強其對數學概念和推理過程的理解。我們使用不同的 LLM 對四個資料集進行實驗，並證明了我們的方法在改善 LLM 在數學推理任務中的效能方面是有效的。我們的研究結果強調了我們的方法對大型語言模型進步的重要性，以及其對需要數學推理能力的實際應用之潛在影響。

##### **AfriHG: News headline generation for African Languages**
2412.20223v1 by Toyib Ogunremi, Serah Akojenu, Anthony Soronnadi, Olubayo Adekanmbi, David Ifeoluwa Adelani

This paper introduces AfriHG -- a news headline generation dataset created by
combining from XLSum and MasakhaNEWS datasets focusing on 16 languages widely
spoken by Africa. We experimented with two seq2eq models (mT5-base and AfriTeVa
V2), and Aya-101 LLM. Our results show that Africa-centric seq2seq models such
as AfriTeVa V2 outperform the massively multilingual mT5-base model. Finally,
we show that the performance of fine-tuning AfriTeVa V2 with 313M parameters is
competitive to prompting Aya-101 LLM with more than 13B parameters.

摘要：本文介紹 AfriHG，這是一個新聞標題生成資料集，透過結合 XLSum 和 MasakhaNEWS 資料集，專注於 16 種在非洲廣泛使用的語言。我們使用兩個 seq2eq 模型 (mT5-base 和 AfriTeVa V2) 以及 Aya-101 LLM 進行實驗。我們的結果顯示，以非洲為中心的 seq2seq 模型，例如 AfriTeVa V2，優於大量的多語言 mT5-base 模型。最後，我們展示了以 3.13 億個參數微調 AfriTeVa V2 的效能，可以與提示使用超過 130 億個參數的 Aya-101 LLM 相媲美。

