{"2407.08583": {"publish_time": "2024-07-11", "title": "The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective", "paper_summary": "The rapid development of large language models (LLMs) has been witnessed in\nrecent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the\nmodality from text to a broader spectrum of domains, attracting widespread\nattention due to the broader range of application scenarios. As LLMs and MLLMs\nrely on vast amounts of model parameters and data to achieve emergent\ncapabilities, the importance of data is receiving increasingly widespread\nattention and recognition. Tracing and analyzing recent data-oriented works for\nMLLMs, we find that the development of models and data is not two separate\npaths but rather interconnected. On the one hand, vaster and higher-quality\ndata contribute to better performance of MLLMs, on the other hand, MLLMs can\nfacilitate the development of data. The co-development of multi-modal data and\nMLLMs requires a clear view of 1) at which development stage of MLLMs can\nspecific data-centric approaches be employed to enhance which capabilities, and\n2) by utilizing which capabilities and acting as which roles can models\ncontribute to multi-modal data. To promote the data-model co-development for\nMLLM community, we systematically review existing works related to MLLMs from\nthe data-model co-development perspective. A regularly maintained project\nassociated with this survey is accessible at\nhttps://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.", "paper_summary_zh": "<paragraph>\u8fd1\u5e74\u4f86\u898b\u8b49\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u767c\u5c55\u3002\u57fa\u65bc\u5f37\u5927\u7684 LLM\uff0c\u591a\u6a21\u614b LLM (MLLM) \u5c07\u6a21\u614b\u5f9e\u6587\u672c\u64f4\u5c55\u5230\u66f4\u5ee3\u6cdb\u7684\u9818\u57df\uff0c\u7531\u65bc\u61c9\u7528\u5834\u666f\u66f4\u5ee3\u6cdb\uff0c\u56e0\u6b64\u5099\u53d7\u95dc\u6ce8\u3002\u7531\u65bc LLM \u548c MLLM \u4f9d\u8cf4\u5927\u91cf\u7684\u6a21\u578b\u53c3\u6578\u548c\u8cc7\u6599\u624d\u80fd\u5be6\u73fe\u65b0\u8208\u80fd\u529b\uff0c\u56e0\u6b64\u8cc7\u6599\u7684\u91cd\u8981\u6027\u8d8a\u4f86\u8d8a\u53d7\u5230\u5ee3\u6cdb\u95dc\u6ce8\u548c\u8a8d\u53ef\u3002\u8ffd\u8e64\u548c\u5206\u6790\u91dd\u5c0d MLLM \u7684\u6700\u65b0\u8cc7\u6599\u5c0e\u5411\u5de5\u4f5c\uff0c\u6211\u5011\u767c\u73fe\u6a21\u578b\u548c\u8cc7\u6599\u7684\u767c\u5c55\u4e26\u975e\u5169\u689d\u7368\u7acb\u7684\u9053\u8def\uff0c\u800c\u662f\u76f8\u4e92\u95dc\u806f\u7684\u3002\u4e00\u65b9\u9762\uff0c\u66f4\u5927\u4e14\u54c1\u8cea\u66f4\u9ad8\u7684\u8cc7\u6599\u6709\u52a9\u65bc\u63d0\u5347 MLLM \u7684\u6548\u80fd\uff0c\u53e6\u4e00\u65b9\u9762\uff0cMLLM \u53ef\u4ee5\u4fc3\u9032\u8cc7\u6599\u7684\u767c\u5c55\u3002\u591a\u6a21\u614b\u8cc7\u6599\u548c MLLM \u7684\u5171\u540c\u958b\u767c\u9700\u8981\u660e\u78ba\u4e86\u89e3 1) \u5728 MLLM \u7684\u54ea\u500b\u958b\u767c\u968e\u6bb5\u53ef\u4ee5\u63a1\u7528\u7279\u5b9a\u7684\u8cc7\u6599\u4e2d\u5fc3\u65b9\u6cd5\u4f86\u589e\u5f37\u54ea\u4e9b\u80fd\u529b\uff0c\u4ee5\u53ca 2) \u6a21\u578b\u53ef\u4ee5\u5229\u7528\u54ea\u4e9b\u80fd\u529b\u4e26\u626e\u6f14\u54ea\u4e9b\u89d2\u8272\u4f86\u8ca2\u737b\u591a\u6a21\u614b\u8cc7\u6599\u3002\u70ba\u4e86\u4fc3\u9032 MLLM \u793e\u7fa4\u7684\u8cc7\u6599\u6a21\u578b\u5171\u540c\u958b\u767c\uff0c\u6211\u5011\u5f9e\u8cc7\u6599\u6a21\u578b\u5171\u540c\u958b\u767c\u7684\u89d2\u5ea6\u7cfb\u7d71\u6027\u5730\u56de\u9867\u8207 MLLM \u76f8\u95dc\u7684\u73fe\u6709\u5de5\u4f5c\u3002\u8207\u9019\u9805\u8abf\u67e5\u76f8\u95dc\u7684\u5b9a\u671f\u7dad\u8b77\u5c08\u6848\u53ef\u65bc https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md \u53d6\u5f97\u3002</paragraph>", "author": "Zhen Qin et.al.", "authors": "Zhen Qin, Daoyuan Chen, Wenhao Zhang, Liuyi Yao, Yilun Huang, Bolin Ding, Yaliang Li, Shuiguang Deng", "id": "2407.08583v1", "paper_url": "http://arxiv.org/abs/2407.08583v1", "repo": "https://github.com/modelscope/data-juicer"}}