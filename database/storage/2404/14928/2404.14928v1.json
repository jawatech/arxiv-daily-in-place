{"2404.14928": {"publish_time": "2024-04-23", "title": "Graph Machine Learning in the Era of Large Language Models (LLMs)", "paper_summary": "Graphs play an important role in representing complex relationships in\nvarious domains like social networks, knowledge graphs, and molecular\ndiscovery. With the advent of deep learning, Graph Neural Networks (GNNs) have\nemerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the\nrepresentation and processing of graph structures. Recently, LLMs have\ndemonstrated unprecedented capabilities in language tasks and are widely\nadopted in a variety of applications such as computer vision and recommender\nsystems. This remarkable success has also attracted interest in applying LLMs\nto the graph domain. Increasing efforts have been made to explore the potential\nof LLMs in advancing Graph ML's generalization, transferability, and few-shot\nlearning ability. Meanwhile, graphs, especially knowledge graphs, are rich in\nreliable factual knowledge, which can be utilized to enhance the reasoning\ncapabilities of LLMs and potentially alleviate their limitations such as\nhallucinations and the lack of explainability. Given the rapid progress of this\nresearch direction, a systematic review summarizing the latest advancements for\nGraph ML in the era of LLMs is necessary to provide an in-depth understanding\nto researchers and practitioners. Therefore, in this survey, we first review\nthe recent developments in Graph ML. We then explore how LLMs can be utilized\nto enhance the quality of graph features, alleviate the reliance on labeled\ndata, and address challenges such as graph heterogeneity and\nout-of-distribution (OOD) generalization. Afterward, we delve into how graphs\ncan enhance LLMs, highlighting their abilities to enhance LLM pre-training and\ninference. Furthermore, we investigate various applications and discuss the\npotential future directions in this promising field.", "paper_summary_zh": "\u5716\u5f62\u5728\u8868\u793a\u5404\u7a2e\u9818\u57df\u4e2d\u8907\u96dc\u7684\u95dc\u4fc2\u4e2d\u626e\u6f14\u8457\u91cd\u8981\u7684\u89d2\u8272\uff0c\u4f8b\u5982\u793e\u4ea4\u7db2\u8def\u3001\u77e5\u8b58\u5716\u8b5c\u548c\u5206\u5b50\u767c\u73fe\u3002\u96a8\u8457\u6df1\u5ea6\u5b78\u7fd2\u7684\u51fa\u73fe\uff0c\u5716\u795e\u7d93\u7db2\u8def (GNN) \u5df2\u6210\u70ba\u5716\u5f62\u6a5f\u5668\u5b78\u7fd2 (Graph ML) \u7684\u57fa\u77f3\uff0c\u4fc3\u9032\u5716\u5f62\u7d50\u69cb\u7684\u8868\u793a\u548c\u8655\u7406\u3002\u6700\u8fd1\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u8a9e\u8a00\u4efb\u52d9\u4e2d\u5c55\u73fe\u4e86\u524d\u6240\u672a\u6709\u7684\u80fd\u529b\uff0c\u4e26\u5ee3\u6cdb\u61c9\u7528\u65bc\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\u4e2d\uff0c\u4f8b\u5982\u96fb\u8166\u8996\u89ba\u548c\u63a8\u85a6\u7cfb\u7d71\u3002\u9019\u9805\u975e\u51e1\u7684\u6210\u529f\u4e5f\u5f15\u8d77\u4e86\u5c07 LLM \u61c9\u7528\u65bc\u5716\u5f62\u9818\u57df\u7684\u8208\u8da3\u3002\u4eba\u5011\u6b63\u6295\u5165\u8d8a\u4f86\u8d8a\u591a\u7684\u7cbe\u529b\u4f86\u63a2\u7d22 LLM \u5728\u63d0\u5347\u5716\u5f62 ML \u7684\u6982\u62ec\u5316\u3001\u53ef\u8f49\u79fb\u6027\u548c\u5c11\u91cf\u5b78\u7fd2\u80fd\u529b\u65b9\u9762\u7684\u6f5b\u529b\u3002\u540c\u6642\uff0c\u5716\u5f62\uff08\u5c24\u5176\u662f\u77e5\u8b58\u5716\u8b5c\uff09\u5bcc\u542b\u53ef\u9760\u7684\u4e8b\u5be6\u77e5\u8b58\uff0c\u53ef\u7528\u65bc\u589e\u5f37 LLM \u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e26\u6709\u53ef\u80fd\u6e1b\u8f15\u5176\u5e7b\u89ba\u548c\u7f3a\u4e4f\u53ef\u89e3\u91cb\u6027\u7b49\u9650\u5236\u3002\u9451\u65bc\u6b64\u7814\u7a76\u65b9\u5411\u7684\u5feb\u901f\u9032\u5c55\uff0c\u6709\u5fc5\u8981\u5c0d LLM \u6642\u4ee3\u5716\u5f62 ML \u7684\u6700\u65b0\u9032\u5c55\u9032\u884c\u7cfb\u7d71\u6027\u56de\u9867\uff0c\u4ee5\u5411\u7814\u7a76\u4eba\u54e1\u548c\u5f9e\u696d\u8005\u63d0\u4f9b\u6df1\u5165\u7684\u7406\u89e3\u3002\u56e0\u6b64\uff0c\u5728\u672c\u8abf\u67e5\u4e2d\uff0c\u6211\u5011\u9996\u5148\u56de\u9867\u5716\u5f62 ML \u7684\u6700\u65b0\u767c\u5c55\u3002\u7136\u5f8c\uff0c\u6211\u5011\u63a2\u8a0e\u5982\u4f55\u5229\u7528 LLM \u4f86\u63d0\u5347\u5716\u5f62\u7279\u5fb5\u7684\u54c1\u8cea\u3001\u6e1b\u8f15\u5c0d\u6a19\u7c64\u8cc7\u6599\u7684\u4f9d\u8cf4\uff0c\u4e26\u89e3\u6c7a\u5716\u5f62\u7570\u8cea\u6027\u548c\u5206\u5e03\u5916 (OOD) \u6982\u62ec\u5316\u7b49\u6311\u6230\u3002\u4e4b\u5f8c\uff0c\u6211\u5011\u6df1\u5165\u63a2\u8a0e\u5716\u5f62\u5982\u4f55\u589e\u5f37 LLM\uff0c\u5f37\u8abf\u5b83\u5011\u589e\u5f37 LLM \u9810\u8a13\u7df4\u548c\u63a8\u7406\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\uff0c\u4e26\u8a0e\u8ad6\u9019\u500b\u6709\u524d\u9014\u9818\u57df\u7684\u6f5b\u5728\u672a\u4f86\u65b9\u5411\u3002", "author": "Wenqi Fan et.al.", "authors": "Wenqi Fan, Shijie Wang, Jiani Huang, Zhikai Chen, Yu Song, Wenzhuo Tang, Haitao Mao, Hui Liu, Xiaorui Liu, Dawei Yin, Qing Li", "id": "2404.14928v1", "paper_url": "http://arxiv.org/abs/2404.14928v1", "repo": "null"}}