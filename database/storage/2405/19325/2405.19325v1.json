{"2405.19325": {"publish_time": "2024-05-29", "title": "Nearest Neighbor Speculative Decoding for LLM Generation and Attribution", "paper_summary": "Large language models (LLMs) often hallucinate and lack the ability to\nprovide attribution for their generations. Semi-parametric LMs, such as kNN-LM,\napproach these limitations by refining the output of an LM for a given prompt\nusing its nearest neighbor matches in a non-parametric data store. However,\nthese models often exhibit slow inference speeds and produce non-fluent texts.\nIn this paper, we introduce Nearest Neighbor Speculative Decoding (NEST), a\nnovel semi-parametric language modeling approach that is capable of\nincorporating real-world text spans of arbitrary length into the LM generations\nand providing attribution to their sources. NEST performs token-level retrieval\nat each inference step to compute a semi-parametric mixture distribution and\nidentify promising span continuations in a corpus. It then uses an approximate\nspeculative decoding procedure that accepts a prefix of the retrieved span or\ngenerates a new token. NEST significantly enhances the generation quality and\nattribution rate of the base LM across a variety of knowledge-intensive tasks,\nsurpassing the conventional kNN-LM method and performing competitively with\nin-context retrieval augmentation. In addition, NEST substantially improves the\ngeneration speed, achieving a 1.8x speedup in inference time when applied to\nLlama-2-Chat 70B.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ecf\u5e38\u51fa\u73b0\u5e7b\u89c9\uff0c\u5e76\u4e14\u7f3a\u4e4f\u4e3a\u5176\u751f\u6210\u5185\u5bb9\u63d0\u4f9b\u5f52\u56e0\u7684\u80fd\u529b\u3002\u534a\u53c2\u6570\u8bed\u8a00\u6a21\u578b\uff08\u4f8b\u5982 kNN-LM\uff09\u901a\u8fc7\u4f7f\u7528\u975e\u53c2\u6570\u6570\u636e\u5b58\u50a8\u4e2d\u4e0e\u5176\u6700\u90bb\u8fd1\u7684\u5339\u914d\u9879\u6765\u4f18\u5316\u7ed9\u5b9a\u63d0\u793a\u7684 LM \u8f93\u51fa\uff0c\u4ece\u800c\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6a21\u578b\u901a\u5e38\u8868\u73b0\u51fa\u8f83\u6162\u7684\u63a8\u7406\u901f\u5ea6\u5e76\u4ea7\u751f\u4e0d\u6d41\u5229\u7684\u6587\u672c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u6700\u8fd1\u90bb\u63a8\u6d4b\u89e3\u7801\uff08NEST\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u534a\u53c2\u6570\u8bed\u8a00\u5efa\u6a21\u65b9\u6cd5\uff0c\u80fd\u591f\u5c06\u4efb\u610f\u957f\u5ea6\u7684\u771f\u5b9e\u6587\u672c\u8de8\u5ea6\u5408\u5e76\u5230 LM \u751f\u6210\u4e2d\uff0c\u5e76\u4e3a\u5176\u6765\u6e90\u63d0\u4f9b\u5f52\u56e0\u3002NEST \u5728\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u6267\u884c\u4ee4\u724c\u7ea7\u68c0\u7d22\u4ee5\u8ba1\u7b97\u534a\u53c2\u6570\u6df7\u5408\u5206\u5e03\uff0c\u5e76\u5728\u8bed\u6599\u5e93\u4e2d\u8bc6\u522b\u6709\u5e0c\u671b\u7684\u8de8\u5ea6\u5ef6\u7eed\u3002\u7136\u540e\uff0c\u5b83\u4f7f\u7528\u8fd1\u4f3c\u63a8\u6d4b\u89e3\u7801\u7a0b\u5e8f\uff0c\u8be5\u7a0b\u5e8f\u63a5\u53d7\u68c0\u7d22\u8de8\u5ea6\u7684\u524d\u7f00\u6216\u751f\u6210\u65b0\u4ee4\u724c\u3002NEST \u663e\u7740\u63d0\u9ad8\u4e86\u57fa\u7840 LM \u5728\u5404\u79cd\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u751f\u6210\u8d28\u91cf\u548c\u5f52\u56e0\u7387\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684 kNN-LM \u65b9\u6cd5\uff0c\u5e76\u4e14\u4e0e\u4e0a\u4e0b\u6587\u68c0\u7d22\u589e\u5f3a\u5177\u6709\u7ade\u4e89\u529b\u3002\u6b64\u5916\uff0cNEST \u5927\u5927\u63d0\u9ad8\u4e86\u751f\u6210\u901f\u5ea6\uff0c\u5728\u5e94\u7528\u4e8e Llama-2-Chat 70B \u65f6\uff0c\u63a8\u7406\u65f6\u95f4\u52a0\u5feb\u4e86 1.8 \u500d\u3002", "author": "Minghan Li et.al.", "authors": "Minghan Li, Xilun Chen, Ari Holtzman, Beidi Chen, Jimmy Lin, Wen-tau Yih, Xi Victoria Lin", "id": "2405.19325v1", "paper_url": "http://arxiv.org/abs/2405.19325v1", "repo": "null"}}