{"2412.03784": {"publish_time": "2024-12-05", "title": "Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech", "paper_summary": "Due to the subjective nature of current clinical evaluation, the need for\nautomatic severity evaluation in dysarthric speech has emerged. DNN models\noutperform ML models but lack user-friendly explainability. ML models offer\nexplainable results at a feature level, but their performance is comparatively\nlower. Current ML models extract various features from raw waveforms to predict\nseverity. However, existing methods do not encompass all dysarthric features\nused in clinical evaluation. To address this gap, we propose a feature\nextraction method that minimizes information loss. We introduce an ASR\ntranscription as a novel feature extraction source. We finetune the ASR model\nfor dysarthric speech, then use this model to transcribe dysarthric speech and\nextract word segment boundary information. It enables capturing finer\npronunciation and broader prosodic features. These features demonstrated an\nimproved severity prediction performance to existing features: balanced\naccuracy of 83.72%.", "paper_summary_zh": "\u7531\u65bc\u7576\u524d\u81e8\u5e8a\u8a55\u4f30\u7684\u4e3b\u89c0\u6027\uff0c\u56e0\u6b64\u51fa\u73fe\u4e86\u5c0d\u69cb\u97f3\u969c\u7919\u8a00\u8a9e\u4e2d\u81ea\u52d5\u56b4\u91cd\u7a0b\u5ea6\u8a55\u4f30\u7684\u9700\u6c42\u3002DNN \u6a21\u578b\u512a\u65bc ML \u6a21\u578b\uff0c\u4f46\u7f3a\u4e4f\u4f7f\u7528\u8005\u53cb\u5584\u7684\u53ef\u89e3\u91cb\u6027\u3002ML \u6a21\u578b\u5728\u7279\u5fb5\u5c64\u7d1a\u63d0\u4f9b\u53ef\u89e3\u91cb\u7684\u7d50\u679c\uff0c\u4f46\u5176\u6548\u80fd\u76f8\u5c0d\u8f03\u4f4e\u3002\u7576\u524d\u7684 ML \u6a21\u578b\u5f9e\u539f\u59cb\u6ce2\u5f62\u4e2d\u64f7\u53d6\u5404\u7a2e\u7279\u5fb5\u4ee5\u9810\u6e2c\u56b4\u91cd\u7a0b\u5ea6\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u4e26\u672a\u6db5\u84cb\u81e8\u5e8a\u8a55\u4f30\u4e2d\u4f7f\u7528\u7684\u6240\u6709\u69cb\u97f3\u969c\u7919\u7279\u5fb5\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u53ef\u5c07\u8cc7\u8a0a\u640d\u5931\u964d\u81f3\u6700\u4f4e\u7684\u7279\u5fb5\u64f7\u53d6\u65b9\u6cd5\u3002\u6211\u5011\u5f15\u5165\u4e86 ASR \u8f49\u9304\u4f5c\u70ba\u4e00\u7a2e\u65b0\u7a4e\u7684\u7279\u5fb5\u64f7\u53d6\u4f86\u6e90\u3002\u6211\u5011\u70ba\u69cb\u97f3\u969c\u7919\u8a00\u8a9e\u5fae\u8abf ASR \u6a21\u578b\uff0c\u7136\u5f8c\u4f7f\u7528\u6b64\u6a21\u578b\u8f49\u9304\u69cb\u97f3\u969c\u7919\u8a00\u8a9e\u4e26\u64f7\u53d6\u5b57\u5143\u5340\u6bb5\u908a\u754c\u8cc7\u8a0a\u3002\u5b83\u53ef\u4ee5\u64f7\u53d6\u66f4\u7cbe\u7d30\u7684\u767c\u97f3\u548c\u66f4\u5ee3\u6cdb\u7684\u97fb\u5f8b\u7279\u5fb5\u3002\u9019\u4e9b\u7279\u5fb5\u986f\u793a\u51fa\u6bd4\u73fe\u6709\u7279\u5fb5\u66f4\u597d\u7684\u56b4\u91cd\u7a0b\u5ea6\u9810\u6e2c\u6548\u80fd\uff1a\u5e73\u8861\u6e96\u78ba\u5ea6\u70ba 83.72%\u3002", "author": "Yerin Choi et.al.", "authors": "Yerin Choi, Jeehyun Lee, Myoung-Wan Koo", "id": "2412.03784v1", "paper_url": "http://arxiv.org/abs/2412.03784v1", "repo": "null"}}