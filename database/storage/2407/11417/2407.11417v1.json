{"2407.11417": {"publish_time": "2024-07-16", "title": "SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions", "paper_summary": "Recent work integrating Large Language Models (LLMs) has led to significant\nimprovements in the Knowledge Base Question Answering (KBQA) task. However, we\nposit that existing KBQA datasets that either have simple questions, use\nsynthetically generated logical forms, or are based on small knowledge base\n(KB) schemas, do not capture the true complexity of KBQA tasks.\n  To address this, we introduce the SPINACH dataset, an expert-annotated KBQA\ndataset collected from forum discussions on Wikidata's \"Request a Query\" forum\nwith 320 decontextualized question-SPARQL pairs. Much more complex than\nexisting datasets, SPINACH calls for strong KBQA systems that do not rely on\ntraining data to learn the KB schema, but can dynamically explore large and\noften incomplete schemas and reason about them.\n  Along with the dataset, we introduce the SPINACH agent, a new KBQA approach\nthat mimics how a human expert would write SPARQLs for such challenging\nquestions. Experiments on existing datasets show SPINACH's capability in KBQA,\nachieving a new state of the art on the QALD-7, QALD-9 Plus and QALD-10\ndatasets by 30.1%, 27.0%, and 10.0% in F1, respectively, and coming within 1.6%\nof the fine-tuned LLaMA SOTA model on WikiWebQuestions. On our new SPINACH\ndataset, SPINACH agent outperforms all baselines, including the best\nGPT-4-based KBQA agent, by 38.1% in F1.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u6574\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u5de5\u4f5c\u5df2\u5927\u5e45\u6539\u5584\u77e5\u8bc6\u5e93\u95ee\u7b54 (KBQA) \u4efb\u52a1\u3002\u7136\u800c\uff0c\u6211\u4eec\u8ba4\u4e3a\u73b0\u6709\u7684 KBQA \u6570\u636e\u96c6\u8981\u4e48\u6709\u7b80\u5355\u7684\u95ee\u9898\uff0c\u8981\u4e48\u4f7f\u7528\u5408\u6210\u751f\u6210\u7684\u903b\u8f91\u5f62\u5f0f\uff0c\u6216\u8005\u57fa\u4e8e\u5c0f\u578b\u77e5\u8bc6\u5e93 (KB) \u67b6\u6784\uff0c\u5e76\u672a\u6355\u6349\u5230 KBQA \u4efb\u52a1\u7684\u771f\u6b63\u590d\u6742\u6027\u3002\n\u4e3a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86 SPINACH \u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u4ece Wikidata \u7684\u300c\u8bf7\u6c42\u67e5\u8be2\u300d\u8bba\u575b\u4e0a\u7684\u8bba\u575b\u8ba8\u8bba\u4e2d\u6536\u96c6\u7684\u4e13\u5bb6\u6ce8\u91ca KBQA \u6570\u636e\u96c6\uff0c\u5176\u4e2d\u6709 320 \u4e2a\u53bb\u8bed\u5883\u5316\u7684 question-SPARQL \u5bf9\u3002SPINACH \u6bd4\u73b0\u6709\u6570\u636e\u96c6\u590d\u6742\u5f97\u591a\uff0c\u9700\u8981\u5f3a\u5927\u7684 KBQA \u7cfb\u7edf\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u4e0d\u4f9d\u8d56\u8bad\u7ec3\u6570\u636e\u6765\u5b66\u4e60 KB \u67b6\u6784\uff0c\u4f46\u53ef\u4ee5\u52a8\u6001\u63a2\u7d22\u5927\u578b\u4e14\u901a\u5e38\u4e0d\u5b8c\u6574\u7684\u67b6\u6784\u5e76\u5bf9\u5176\u8fdb\u884c\u63a8\u7406\u3002\n\u9664\u4e86\u6570\u636e\u96c6\u4e4b\u5916\uff0c\u6211\u4eec\u8fd8\u5f15\u5165\u4e86 SPINACH agent\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684 KBQA \u65b9\u6cd5\uff0c\u5b83\u6a21\u4eff\u4eba\u7c7b\u4e13\u5bb6\u5982\u4f55\u4e3a\u5982\u6b64\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u7f16\u5199 SPARQL\u3002\u73b0\u6709\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\u4e86 SPINACH \u5728 KBQA \u4e2d\u7684\u80fd\u529b\uff0c\u5728 QALD-7\u3001QALD-9 Plus \u548c QALD-10 \u6570\u636e\u96c6\u4e0a\u5206\u522b\u4ee5 F1 \u5206\u522b\u63d0\u9ad8\u4e86 30.1%\u300127.0% \u548c 10.0%\uff0c\u5e76\u4e14\u5728 WikiWebQuestions \u4e0a\u8fbe\u5230\u5fae\u8c03\u7684 LLaMA SOTA \u6a21\u578b\u7684 1.6%\u3002\u5728\u6211\u4eec\u7684\u65b0 SPINACH \u6570\u636e\u96c6\u4e0a\uff0cSPINACH agent \u5728 F1 \u4e0a\u4f18\u4e8e\u6240\u6709\u57fa\u51c6\uff0c\u5305\u62ec\u57fa\u4e8e GPT-4 \u7684\u6700\u4f73 KBQA agent\uff0c\u63d0\u9ad8\u4e86 38.1%\u3002</paragraph>", "author": "Shicheng Liu et.al.", "authors": "Shicheng Liu, Sina J. Semnani, Harold Triedman, Jialiang Xu, Isaac Dan Zhao, Monica S. Lam", "id": "2407.11417v1", "paper_url": "http://arxiv.org/abs/2407.11417v1", "repo": "null"}}