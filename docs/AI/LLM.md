
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-19**|**Scaling 4D Representations**|João Carreira et.al.|[2412.15212v1](http://arxiv.org/abs/2412.15212v1)|null|
|**2024-12-19**|**PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation**|Muntasir Wahed et.al.|[2412.15209v1](http://arxiv.org/abs/2412.15209v1)|null|
|**2024-12-19**|**LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks**|Yushi Bai et.al.|[2412.15204v1](http://arxiv.org/abs/2412.15204v1)|null|
|**2024-12-19**|**DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation**|Wang Zhao et.al.|[2412.15200v1](http://arxiv.org/abs/2412.15200v1)|null|
|**2024-12-19**|**MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark**|Qihao Zhao et.al.|[2412.15194v1](http://arxiv.org/abs/2412.15194v1)|null|
|**2024-12-19**|**Face the Facts! Evaluating RAG-based Fact-checking Pipelines in Realistic Settings**|Daniel Russo et.al.|[2412.15189v1](http://arxiv.org/abs/2412.15189v1)|[link](https://github.com/drusso98/face-the-facts)|
|**2024-12-19**|**LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation**|Weijia Shi et.al.|[2412.15188v1](http://arxiv.org/abs/2412.15188v1)|null|
|**2024-12-19**|**Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying**|Federico Castagna et.al.|[2412.15177v1](http://arxiv.org/abs/2412.15177v1)|null|
|**2024-12-19**|**Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration**|Junjia Liu et.al.|[2412.15166v1](http://arxiv.org/abs/2412.15166v1)|null|
|**2024-12-19**|**Prompt-A-Video: Prompt Your Video Diffusion Model via Preference-Aligned LLM**|Yatai Ji et.al.|[2412.15156v1](http://arxiv.org/abs/2412.15156v1)|[link](https://github.com/jiyt17/prompt-a-video)|
|**2024-12-19**|**Language Models as Continuous Self-Evolving Data Engineers**|Peidong Wang et.al.|[2412.15151v1](http://arxiv.org/abs/2412.15151v1)|null|
|**2024-12-19**|**Leveraging Color Channel Independence for Improved Unsupervised Object Detection**|Bastian Jäckl et.al.|[2412.15150v1](http://arxiv.org/abs/2412.15150v1)|null|
|**2024-12-19**|**Probabilistic Strategy Logic with Degrees of Observability**|Chunyan Mu et.al.|[2412.15135v1](http://arxiv.org/abs/2412.15135v1)|null|
|**2024-12-19**|**Jet: A Modern Transformer-Based Normalizing Flow**|Alexander Kolesnikov et.al.|[2412.15129v1](http://arxiv.org/abs/2412.15129v1)|null|
|**2024-12-19**|**Adaptive Pruning for Large Language Models with Structural Importance Awareness**|Haotian Zheng et.al.|[2412.15127v1](http://arxiv.org/abs/2412.15127v1)|null|
|**2024-12-19**|**Outcome-Refining Process Supervision for Code Generation**|Zhuohao Yu et.al.|[2412.15118v1](http://arxiv.org/abs/2412.15118v1)|null|
|**2024-12-19**|**Qwen2.5 Technical Report**|Qwen et.al.|[2412.15115v1](http://arxiv.org/abs/2412.15115v1)|null|
|**2024-12-19**|**Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture**|Thomas F Burns et.al.|[2412.15113v1](http://arxiv.org/abs/2412.15113v1)|[link](https://github.com/tfburns/amicl-and-residual-attention-streams)|
|**2024-12-19**|**Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid**|Shimiao Li et.al.|[2412.15105v1](http://arxiv.org/abs/2412.15105v1)|null|
|**2024-12-19**|**Review-Then-Refine: A Dynamic Framework for Multi-Hop Question Answering with Temporal Adaptability**|Xiangsen Chen et.al.|[2412.15101v1](http://arxiv.org/abs/2412.15101v1)|null|
|**2024-12-19**|**A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation**|João A. Leite et.al.|[2412.15098v1](http://arxiv.org/abs/2412.15098v1)|null|
|**2024-12-19**|**A Full Transformer-based Framework for Automatic Pain Estimation using Videos**|Stefanos Gkikas et.al.|[2412.15095v1](http://arxiv.org/abs/2412.15095v1)|null|
|**2024-12-19**|**Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation**|Haoran Liu et.al.|[2412.15086v1](http://arxiv.org/abs/2412.15086v1)|null|
|**2024-12-19**|**AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling**|Zihan Liu et.al.|[2412.15084v1](http://arxiv.org/abs/2412.15084v1)|null|
|**2024-12-19**|**Till the Layers Collapse: Compressing a Deep Neural Network through the Lenses of Batch Normalization Layers**|Zhu Liao et.al.|[2412.15077v1](http://arxiv.org/abs/2412.15077v1)|null|
|**2024-12-19**|**ConfliBERT: A Language Model for Political Conflict**|Patrick T. Brandt et.al.|[2412.15060v1](http://arxiv.org/abs/2412.15060v1)|[link](https://github.com/eventdata/conflibert)|
|**2024-12-19**|**Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI**|Isadora Krsek et.al.|[2412.15047v1](http://arxiv.org/abs/2412.15047v1)|null|
|**2024-12-19**|**LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps**|Felix Friedrich et.al.|[2412.15035v1](http://arxiv.org/abs/2412.15035v1)|null|
|**2024-12-19**|**Large Language Models and Code Security: A Systematic Literature Review**|Enna Basic et.al.|[2412.15004v1](http://arxiv.org/abs/2412.15004v1)|null|
|**2024-12-19**|**HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs**|Pham Vu Tuan Dat et.al.|[2412.14995v1](http://arxiv.org/abs/2412.14995v1)|null|
|**2024-12-19**|**Chain-of-MetaWriting: Linguistic and Textual Analysis of How Small Language Models Write Young Students Texts**|Ioana Buhnila et.al.|[2412.14986v1](http://arxiv.org/abs/2412.14986v1)|null|
|**2024-12-19**|**Movie2Story: A framework for understanding videos and telling stories in the form of novel text**|Kangning Li et.al.|[2412.14965v1](http://arxiv.org/abs/2412.14965v1)|null|
|**2024-12-19**|**Knowledge Injection via Prompt Distillation**|Kalle Kujanpää et.al.|[2412.14964v1](http://arxiv.org/abs/2412.14964v1)|null|
|**2024-12-19**|**Understanding the Dark Side of LLMs' Intrinsic Self-Correction**|Qingjie Zhang et.al.|[2412.14959v1](http://arxiv.org/abs/2412.14959v1)|null|
|**2024-12-19**|**Generalizing Constraint Models in Constraint Acquisition**|Dimos Tsouros et.al.|[2412.14950v1](http://arxiv.org/abs/2412.14950v1)|[link](https://github.com/dimosts/genconmodels)|
|**2024-12-19**|**RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**|Junyu Luo et.al.|[2412.14922v1](http://arxiv.org/abs/2412.14922v1)|[link](https://github.com/luo-junyu/robustft)|
|**2024-12-19**|**Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation**|Zexiong Ma et.al.|[2412.14905v1](http://arxiv.org/abs/2412.14905v1)|null|
|**2024-12-19**|**Why language models collapse when trained on recursively generated text**|Lecheng Wang et.al.|[2412.14872v1](http://arxiv.org/abs/2412.14872v1)|null|
|**2024-12-19**|**AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening**|Mehdi Hosseini Chagahi et.al.|[2412.14869v1](http://arxiv.org/abs/2412.14869v1)|null|
|**2024-12-19**|**Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**|Imed Keraghel et.al.|[2412.14867v1](http://arxiv.org/abs/2412.14867v1)|null|
|**2024-12-19**|**Think&Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling**|Junyi Li et.al.|[2412.14860v1](http://arxiv.org/abs/2412.14860v1)|null|
|**2024-12-19**|**DS$^2$-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis**|Hongling Xu et.al.|[2412.14849v1](http://arxiv.org/abs/2412.14849v1)|[link](https://github.com/behappyplz/ds2-absa)|
|**2024-12-19**|**A Survey of RWKV**|Zhiyuan Li et.al.|[2412.14847v1](http://arxiv.org/abs/2412.14847v1)|null|
|**2024-12-19**|**Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet**|Litingyu Wang et.al.|[2412.14846v1](http://arxiv.org/abs/2412.14846v1)|[link](https://github.com/wltyby/hnts-mrg2024_train_code)|
|**2024-12-19**|**Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas**|Pietro Bernardelle et.al.|[2412.14843v1](http://arxiv.org/abs/2412.14843v1)|null|
|**2024-12-19**|**Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis**|Greta Dolcetti et.al.|[2412.14841v1](http://arxiv.org/abs/2412.14841v1)|null|
|**2024-12-19**|**DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs**|Xiabin Zhou et.al.|[2412.14838v1](http://arxiv.org/abs/2412.14838v1)|null|
|**2024-12-19**|**Progressive Multimodal Reasoning via Active Retrieval**|Guanting Dong et.al.|[2412.14835v1](http://arxiv.org/abs/2412.14835v1)|null|
|**2024-12-19**|**Mention Attention for Pronoun Translation**|Gongbo Tang et.al.|[2412.14829v1](http://arxiv.org/abs/2412.14829v1)|null|
|**2024-12-19**|**Answer Set Networks: Casting Answer Set Programming into Deep Learning**|Arseny Skryagin et.al.|[2412.14814v1](http://arxiv.org/abs/2412.14814v1)|null|
|**2024-12-19**|**MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data**|Camillo Maria Caruso et.al.|[2412.14810v1](http://arxiv.org/abs/2412.14810v1)|null|
|**2024-12-19**|**ResoFilter: Rine-grained Synthetic Data Filtering for Large Language Models through Data-Parameter Resonance Analysis**|Zeao Tu et.al.|[2412.14809v1](http://arxiv.org/abs/2412.14809v1)|[link](https://github.com/tal-aurorax/resofilter)|
|**2024-12-19**|**Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios**|Egor Shibaev et.al.|[2412.14802v1](http://arxiv.org/abs/2412.14802v1)|[link](https://github.com/jetbrains-research/stack-trace-deduplication)|
|**2024-12-19**|**Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning**|Ziang Ye et.al.|[2412.14780v1](http://arxiv.org/abs/2412.14780v1)|null|
|**2024-12-19**|**ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine**|Rabee Qasem et.al.|[2412.14771v1](http://arxiv.org/abs/2412.14771v1)|null|
|**2024-12-19**|**PsyDraw: A Multi-Agent Multimodal System for Mental Health Screening in Left-Behind Children**|Yiqun Zhang et.al.|[2412.14769v1](http://arxiv.org/abs/2412.14769v1)|[link](https://github.com/LYiHub/psydraw)|
|**2024-12-19**|**CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering**|Ruida Hu et.al.|[2412.14764v1](http://arxiv.org/abs/2412.14764v1)|null|
|**2024-12-19**|**Query pipeline optimization for cancer patient question answering systems**|Maolin He et.al.|[2412.14751v1](http://arxiv.org/abs/2412.14751v1)|null|
|**2024-12-19**|**On Verbalized Confidence Scores for LLMs**|Daniel Yang et.al.|[2412.14737v1](http://arxiv.org/abs/2412.14737v1)|null|
|**2024-12-19**|**Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**|Pir Bakhsh Khokhar et.al.|[2412.14736v1](http://arxiv.org/abs/2412.14736v1)|null|
|**2024-12-19**|**Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey**|Aygün Varol et.al.|[2412.14708v1](http://arxiv.org/abs/2412.14708v1)|null|
|**2024-12-19**|**How to Synthesize Text Data without Model Collapse?**|Xuekai Zhu et.al.|[2412.14689v1](http://arxiv.org/abs/2412.14689v1)|null|
|**2024-12-19**|**Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection**|Hao Guo et.al.|[2412.14686v1](http://arxiv.org/abs/2412.14686v1)|null|
|**2024-12-19**|**Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines**|Yunsu Kim et.al.|[2412.14684v1](http://arxiv.org/abs/2412.14684v1)|null|
|**2024-12-19**|**A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space**|Yonghao He et.al.|[2412.14680v1](http://arxiv.org/abs/2412.14680v1)|null|
|**2024-12-19**|**LLMs as mediators: Can they diagnose conflicts accurately?**|Özgecan Koçak et.al.|[2412.14675v1](http://arxiv.org/abs/2412.14675v1)|null|
|**2024-12-19**|**FiVL: A Framework for Improved Vision-Language Alignment**|Estelle Aflalo et.al.|[2412.14672v1](http://arxiv.org/abs/2412.14672v1)|null|
|**2024-12-19**|**Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT**|Hassane Kissane et.al.|[2412.14670v1](http://arxiv.org/abs/2412.14670v1)|null|
|**2024-12-19**|**LoLaFL: Low-Latency Federated Learning via Forward-only Propagation**|Jierui Zhang et.al.|[2412.14668v1](http://arxiv.org/abs/2412.14668v1)|null|
|**2024-12-19**|**IOHunter: Graph Foundation Model to Uncover Online Information Operations**|Marco Minici et.al.|[2412.14663v1](http://arxiv.org/abs/2412.14663v1)|null|
|**2024-12-19**|**Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models**|Zijun Chen et.al.|[2412.14660v1](http://arxiv.org/abs/2412.14660v1)|[link](https://github.com/hfutml/calibration-mllm)|
|**2024-12-19**|**Length Controlled Generation for Black-box LLMs**|Yuxuan Gu et.al.|[2412.14656v1](http://arxiv.org/abs/2412.14656v1)|null|
|**2024-12-19**|**TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation**|Jiatong Li et.al.|[2412.14642v1](http://arxiv.org/abs/2412.14642v1)|[link](https://github.com/phenixace/tomg-bench)|
|**2024-12-19**|**Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning**|Eric Brouwer et.al.|[2412.14640v1](http://arxiv.org/abs/2412.14640v1)|null|
|**2024-12-19**|**Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers**|Rui Ding et.al.|[2412.14633v1](http://arxiv.org/abs/2412.14633v1)|null|
|**2024-12-19**|**Learning to Generate Research Idea with Dynamic Control**|Ruochen Li et.al.|[2412.14626v1](http://arxiv.org/abs/2412.14626v1)|null|
|**2024-12-19**|**Pitfalls of topology-aware image segmentation**|Alexander H. Berger et.al.|[2412.14619v1](http://arxiv.org/abs/2412.14619v1)|[link](https://github.com/alexanderhberger/topo-pitfalls)|
|**2024-12-19**|**How good is GPT at writing political speeches for the White House?**|Jacques Savoy et.al.|[2412.14617v1](http://arxiv.org/abs/2412.14617v1)|null|
|**2024-12-19**|**HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model**|Masanari Ohi et.al.|[2412.14613v1](http://arxiv.org/abs/2412.14613v1)|null|
|**2024-12-19**|**KARRIEREWEGE: A Large Scale Career Path Prediction Dataset**|Elena Senger et.al.|[2412.14612v1](http://arxiv.org/abs/2412.14612v1)|null|
|**2024-12-19**|**Towards Scalable and Deep Graph Neural Networks via Noise Masking**|Yuxuan Liang et.al.|[2412.14602v1](http://arxiv.org/abs/2412.14602v1)|null|
|**2024-12-19**|**LDP: Generalizing to Multilingual Visual Information Extraction by Language Decoupled Pretraining**|Huawen Shen et.al.|[2412.14596v1](http://arxiv.org/abs/2412.14596v1)|null|
|**2024-12-19**|**Beyond Guilt: Legal Judgment Prediction with Trichotomous Reasoning**|Kepu Zhang et.al.|[2412.14588v1](http://arxiv.org/abs/2412.14588v1)|null|
|**2024-12-19**|**Simulation-Free Hierarchical Latent Policy Planning for Proactive Dialogues**|Tao He et.al.|[2412.14584v1](http://arxiv.org/abs/2412.14584v1)|null|
|**2024-12-19**|**CORD: Balancing COnsistency and Rank Distillation for Robust Retrieval-Augmented Generation**|Youngwon Lee et.al.|[2412.14581v1](http://arxiv.org/abs/2412.14581v1)|null|
|**2024-12-19**|**Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models**|Wenhan Liu et.al.|[2412.14574v1](http://arxiv.org/abs/2412.14574v1)|[link](https://github.com/8421bcd/fullrank)|
|**2024-12-19**|**Characterising Simulation-Based Program Equilibria**|Emery Cooper et.al.|[2412.14570v1](http://arxiv.org/abs/2412.14570v1)|null|
|**2024-12-19**|**AIArena: A Blockchain-Based Decentralized AI Training Platform**|Zhipeng Wang et.al.|[2412.14566v1](http://arxiv.org/abs/2412.14566v1)|null|
|**2024-12-19**|**CitaLaw: Enhancing LLM with Citations in Legal Domain**|Kepu Zhang et.al.|[2412.14556v1](http://arxiv.org/abs/2412.14556v1)|null|
|**2024-12-19**|**Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities**|Qimei Cui et.al.|[2412.14538v1](http://arxiv.org/abs/2412.14538v1)|null|
|**2024-12-19**|**Multi-Level Optimal Transport for Universal Cross-Tokenizer Knowledge Distillation on Language Models**|Xiao Cui et.al.|[2412.14528v1](http://arxiv.org/abs/2412.14528v1)|null|
|**2024-12-19**|**CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**|Youshen Zhao et.al.|[2412.14522v1](http://arxiv.org/abs/2412.14522v1)|[link](https://github.com/yossizhao/cae-t)|
|**2024-12-19**|**Cal-DPO: Calibrated Direct Preference Optimization for Language Model Alignment**|Teng Xiao et.al.|[2412.14516v1](http://arxiv.org/abs/2412.14516v1)|[link](https://github.com/tengxiao1/cal-dpo)|
|**2024-12-19**|**Relational Programming with Foundation Models**|Ziyang Li et.al.|[2412.14515v1](http://arxiv.org/abs/2412.14515v1)|null|
|**2024-12-19**|**PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization**|Jiayi Wu et.al.|[2412.14510v1](http://arxiv.org/abs/2412.14510v1)|[link](https://github.com/wujwyi/pa-rag)|
|**2024-12-19**|**Do Large Language Models Defend Inferentialist Semantics?: On the Logical Expressivism and Anti-Representationalism of LLMs**|Yuzuki Arai et.al.|[2412.14501v1](http://arxiv.org/abs/2412.14501v1)|null|
|**2024-12-19**|**The Digital Ecosystem of Beliefs: does evolution favour AI over humans?**|David M. Bossens et.al.|[2412.14500v1](http://arxiv.org/abs/2412.14500v1)|null|
|**2024-12-19**|**FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis**|Abdullah Khan et.al.|[2412.14492v1](http://arxiv.org/abs/2412.14492v1)|null|
|**2024-12-19**|**Towards Projected and Incremental Pseudo-Boolean Model Counting**|Suwei Yang et.al.|[2412.14485v1](http://arxiv.org/abs/2412.14485v1)|null|
|**2024-12-19**|**GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**|Saumya Saxena et.al.|[2412.14480v1](http://arxiv.org/abs/2412.14480v1)|null|

#### Abstracts
##### **Scaling 4D Representations**
2412.15212v1 by João Carreira, Dilara Gokay, Michael King, Chuhan Zhang, Ignacio Rocco, Aravindh Mahendran, Thomas Albert Keck, Joseph Heyward, Skanda Koppula, Etienne Pot, Goker Erdogan, Yana Hasson, Yi Yang, Klaus Greff, Guillaume Le Moing, Sjoerd van Steenkiste, Daniel Zoran, Drew A. Hudson, Pedro Vélez, Luisa Polanía, Luke Friedman, Chris Duvarney, Ross Goroshin, Kelsey Allen, Jacob Walker, Rishabh Kabra, Eric Aboussouan, Jennifer Sun, Thomas Kipf, Carl Doersch, Viorica Pătrăucean, Dima Damen, Pauline Luc, Mehdi S. M. Sajjadi, Andrew Zisserman

Scaling has not yet been convincingly demonstrated for pure self-supervised
learning from video. However, prior work has focused evaluations on
semantic-related tasks $\unicode{x2013}$ action classification, ImageNet
classification, etc. In this paper we focus on evaluating self-supervised
learning on non-semantic vision tasks that are more spatial (3D) and temporal
(+1D = 4D), such as camera pose estimation, point and object tracking, and
depth estimation. We show that by learning from very large video datasets,
masked auto-encoding (MAE) with transformer video models actually scales,
consistently improving performance on these 4D tasks, as model size increases
from 20M all the way to the largest by far reported self-supervised video model
$\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with
many recent image and video models demonstrates the benefits of scaling 4D
representations.

摘要：純粹的影片自監督學習尚未令人信服地展現出擴充性。然而，先前的研究將評估重點放在語意相關任務上，例如動作分類、ImageNet 分類等。在本文中，我們專注於評估自監督學習在非語意視覺任務上的表現，這些任務更具空間性 (3D) 和時間性 (+1D = 4D)，例如相機位姿估計、點和物體追蹤，以及深度估計。我們展示了透過從非常大的影片資料集中學習，使用Transformer影片模型的遮罩自動編碼 (MAE) 確實具有擴充性，隨著模型大小從 20M 一路增加到目前為止最大的自監督影片模型，在這些 4D 任務上的表現持續提升，達到 22B 參數。與許多最近的影像和影片模型進行嚴謹的蘋果對蘋果比較，證明了擴充 4D 表徵的好處。

##### **PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation**
2412.15209v1 by Muntasir Wahed, Kiet A. Nguyen, Adheesh Sunil Juvekar, Xinzhuo Li, Xiaona Zhou, Vedant Shah, Tianjiao Yu, Pinar Yanardag, Ismini Lourentzou

Despite significant advancements in Large Vision-Language Models (LVLMs),
existing pixel-grounding models operate on single-image settings, limiting
their ability to perform detailed, fine-grained comparisons across multiple
images. Conversely, current multi-image understanding models lack pixel-level
grounding. Our work addresses this gap by introducing the task of multi-image
pixel-grounded reasoning segmentation, and PRIMA, a novel LVLM that integrates
pixel-level grounding with robust multi-image reasoning capabilities to produce
contextually rich, pixel-grounded explanations. Central to PRIMA is an
efficient vision module that queries fine-grained visual representations across
multiple images, reducing TFLOPs by $25.3\%$. To support training and
evaluation, we curate $M^4Seg$, a new reasoning segmentation benchmark
consisting of $\sim$224K question-answer pairs that require fine-grained visual
understanding across multiple images. Experimental results demonstrate PRIMA
outperforms state-of-the-art baselines.

摘要：儘管大型視覺語言模型 (LVLMs) 有顯著的進展，現有的像素基礎模型在單一影像設定中運作，限制了它們跨多個影像執行詳細、細微的比較的能力。相反地，目前的許多影像理解模型缺乏像素層級的基礎。我們的研究透過引入多影像像素基礎推理分割的任務，以及 PRIMA，一個整合像素層級基礎與強健的多影像推理能力的新穎 LVLM，來解決這個差距，以產生脈絡豐富、像素基礎的解釋。PRIMA 的核心是一個高效的視覺模組，它查詢跨多個影像的細微視覺表示，將 TFLOP 減少了 25.3%。為了支援訓練和評估，我們策劃了 M4Seg，一個新的推理分割基準，包含約 22.4 萬個問題回答對，這些對需要跨多個影像的細微視覺理解。實驗結果證明 PRIMA 優於最先進的基準。

##### **LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks**
2412.15204v1 by Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li

This paper introduces LongBench v2, a benchmark designed to assess the
ability of LLMs to handle long-context problems requiring deep understanding
and reasoning across real-world multitasks. LongBench v2 consists of 503
challenging multiple-choice questions, with contexts ranging from 8k to 2M
words, across six major task categories: single-document QA, multi-document QA,
long in-context learning, long-dialogue history understanding, code repository
understanding, and long structured data understanding. To ensure the breadth
and the practicality, we collect data from nearly 100 highly educated
individuals with diverse professional backgrounds. We employ both automated and
manual review processes to maintain high quality and difficulty, resulting in
human experts achieving only 53.7% accuracy under a 15-minute time constraint.
Our evaluation reveals that the best-performing model, when directly answers
the questions, achieves only 50.1% accuracy. In contrast, the o1-preview model,
which includes longer reasoning, achieves 57.7%, surpassing the human baseline
by 4%. These results highlight the importance of enhanced reasoning ability and
scaling inference-time compute to tackle the long-context challenges in
LongBench v2. The project is available at https://longbench2.github.io.

摘要：本文介紹 LongBench v2，這是一個基準測試，用來評估 LLM 處理需要跨越真實世界多任務進行深入理解和推理的長脈絡問題的能力。LongBench v2 包含 503 個具有挑戰性的多選題，脈絡範圍從 8k 到 2M 個字，涵蓋六個主要的任務類別：單一文件問答、多文件問答、長脈絡學習、長對話歷程理解、程式碼儲存庫理解，以及長結構化資料理解。為了確保廣度和實用性，我們從近 100 位受過高等教育、具有不同專業背景的人員收集資料。我們採用自動化和手動檢閱流程來維持高品質和難度，導致人類專家在 15 分鐘的時間限制下只能達到 53.7% 的準確度。我們的評估顯示，在直接回答問題時，表現最佳的模型只能達到 50.1% 的準確度。相比之下，包含較長推理的 o1-preview 模型達到 57.7%，比人類基準高出 4%。這些結果突顯了增強推理能力和擴充推論時間運算的重要性，以應對 LongBench v2 中的長脈絡挑戰。此專案可在 https://longbench2.github.io/ 取得。

##### **DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation**
2412.15200v1 by Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan

Procedural Content Generation (PCG) is powerful in creating high-quality 3D
contents, yet controlling it to produce desired shapes is difficult and often
requires extensive parameter tuning. Inverse Procedural Content Generation aims
to automatically find the best parameters under the input condition. However,
existing sampling-based and neural network-based methods still suffer from
numerous sample iterations or limited controllability. In this work, we present
DI-PCG, a novel and efficient method for Inverse PCG from general image
conditions. At its core is a lightweight diffusion transformer model, where PCG
parameters are directly treated as the denoising target and the observed images
as conditions to control parameter generation. DI-PCG is efficient and
effective. With only 7.6M network parameters and 30 GPU hours to train, it
demonstrates superior performance in recovering parameters accurately, and
generalizing well to in-the-wild images. Quantitative and qualitative
experiment results validate the effectiveness of DI-PCG in inverse PCG and
image-to-3D generation tasks. DI-PCG offers a promising approach for efficient
inverse PCG and represents a valuable exploration step towards a 3D generation
path that models how to construct a 3D asset using parametric models.

摘要：程序內容產生（PCG）在建立高品質 3D 內容方面很強大，但要控制它來產生所需的形狀很困難，而且通常需要廣泛的參數調整。反向程序內容產生旨在自動找出輸入條件下的最佳參數。然而，現有的基於採樣和基於神經網路的方法仍然有許多樣本迭代或控制能力有限的問題。在這項工作中，我們提出 DI-PCG，這是一種從一般影像條件中進行反向 PCG 的新穎且有效的方法。其核心是一個輕量級的擴散變換器模型，其中 PCG 參數被直接視為去噪目標，而觀察到的影像則作為控制參數生成的條件。DI-PCG 是有效率且有效的。它只有 7.6M 網路參數和 30 個 GPU 小時進行訓練，在準確恢復參數方面表現出優異的性能，並且能很好地推廣到野外影像。定量和定性實驗結果驗證了 DI-PCG 在反向 PCG 和影像到 3D 生成任務中的有效性。DI-PCG 為有效率的反向 PCG 提供了一個有前途的方法，並代表了一個有價值的探索步驟，朝著一個使用參數模型來建構 3D 資產的 3D 生成路徑邁進。

##### **MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark**
2412.15194v1 by Qihao Zhao, Yangyu Huang, Tengchao Lv, Lei Cui, Qinzheng Sun, Shaoguang Mao, Xin Zhang, Ying Xin, Qiufeng Yin, Scarlett Li, Furu Wei

Multiple-choice question (MCQ) datasets like Massive Multitask Language
Understanding (MMLU) are widely used to evaluate the commonsense,
understanding, and problem-solving abilities of large language models (LLMs).
However, the open-source nature of these benchmarks and the broad sources of
training data for LLMs have inevitably led to benchmark contamination,
resulting in unreliable evaluation results. To alleviate this issue, we propose
a contamination-free and more challenging MCQ benchmark called MMLU-CF. This
benchmark reassesses LLMs' understanding of world knowledge by averting both
unintentional and malicious data leakage. To avoid unintentional data leakage,
we source data from a broader domain and design three decontamination rules. To
prevent malicious data leakage, we divide the benchmark into validation and
test sets with similar difficulty and subject distributions. The test set
remains closed-source to ensure reliable results, while the validation set is
publicly available to promote transparency and facilitate independent
verification. Our evaluation of mainstream LLMs reveals that the powerful
GPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on
the test set, which indicates the effectiveness of our approach in creating a
more rigorous and contamination-free evaluation standard. The GitHub repository
is available at https://github.com/microsoft/MMLU-CF and the dataset refers to
https://huggingface.co/datasets/microsoft/MMLU-CF.

摘要：<paragraph>多重選擇題 (MCQ) 資料集，例如 Massive Multitask Language Understanding (MMLU)，被廣泛用於評估大型語言模型 (LLM) 的常識、理解和問題解決能力。然而，這些基準的開放原始碼性質和 LLM 的訓練資料廣泛來源不可避免地導致基準污染，導致評估結果不可靠。為了緩解這個問題，我們提出了一個無污染且更具挑戰性的 MCQ 基準，稱為 MMLU-CF。此基準透過避免無意和惡意的資料外洩，重新評估 LLM 對世界知識的理解。為了避免無意的資料外洩，我們從更廣泛的網域中取得資料，並設計了三條去汙規則。為了防止惡意的資料外洩，我們將基準區分為驗證和測試集，具有相似的難度和主題分佈。測試集保持封閉原始碼以確保結果可靠，而驗證集公開可用以促進透明度和協助獨立驗證。我們對主流 LLM 的評估顯示，強大的 GPT-4o 在測試集上僅獲得 5 次嘗試得分 73.4% 和 0 次嘗試得分 71.9%，這表示我們的方法在建立更嚴謹且無污染的評估標準上是有效的。GitHub 存放庫可在 https://github.com/microsoft/MMLU-CF 取得，而資料集請參閱 https://huggingface.co/datasets/microsoft/MMLU-CF。</paragraph>

##### **Face the Facts! Evaluating RAG-based Fact-checking Pipelines in Realistic Settings**
2412.15189v1 by Daniel Russo, Stefano Menini, Jacopo Staiano, Marco Guerini

Natural Language Processing and Generation systems have recently shown the
potential to complement and streamline the costly and time-consuming job of
professional fact-checkers. In this work, we lift several constraints of
current state-of-the-art pipelines for automated fact-checking based on the
Retrieval-Augmented Generation (RAG) paradigm. Our goal is to benchmark, under
more realistic scenarios, RAG-based methods for the generation of verdicts -
i.e., short texts discussing the veracity of a claim - evaluating them on
stylistically complex claims and heterogeneous, yet reliable, knowledge bases.
Our findings show a complex landscape, where, for example, LLM-based retrievers
outperform other retrieval techniques, though they still struggle with
heterogeneous knowledge bases; larger models excel in verdict faithfulness,
while smaller models provide better context adherence, with human evaluations
favouring zero-shot and one-shot approaches for informativeness, and fine-tuned
models for emotional alignment.

摘要：自然語言處理和生成系統最近已展現出補充和簡化專業事實查核員昂貴且耗時的任務的潛力。在這項工作中，我們解除了基於檢索增強生成 (RAG) 典範的當前最先進自動事實查核管線的若干限制。我們的目標是在更實際的場景下，對基於 RAG 的方法進行基準測試，以生成判決 - 即討論說法真實性的簡短文字 - 在風格複雜的說法和異質但可靠的知識庫上對其進行評估。我們的研究結果顯示了一個複雜的環境，例如，基於 LLM 的檢索器優於其他檢索技術，儘管它們仍難以應對異質知識庫；較大的模型在判決忠實度方面表現出色，而較小的模型則提供更好的上下文依附性，人類評估偏好零次學習和一次學習方法以獲取信息，並微調模型以進行情緒對齊。

##### **LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation**
2412.15188v1 by Weijia Shi, Xiaochuang Han, Chunting Zhou, Weixin Liang, Xi Victoria Lin, Luke Zettlemoyer, Lili Yu

We present LlamaFusion, a framework for empowering pretrained text-only large
language models (LLMs) with multimodal generative capabilities, enabling them
to understand and generate both text and images in arbitrary sequences.
LlamaFusion leverages existing Llama-3's weights for processing texts
autoregressively while introducing additional and parallel transformer modules
for processing images with diffusion. During training, the data from each
modality is routed to its dedicated modules: modality-specific feedforward
layers, query-key-value projections, and normalization layers process each
modality independently, while the shared self-attention layers allow
interactions across text and image features. By freezing the text-specific
modules and only training the image-specific modules, LlamaFusion preserves the
language capabilities of text-only LLMs while developing strong visual
understanding and generation abilities. Compared to methods that pretrain
multimodal generative models from scratch, our experiments demonstrate that,
LlamaFusion improves image understanding by 20% and image generation by 3.6%
using only 50% of the FLOPs while maintaining Llama-3's language capabilities.
We also demonstrate that this framework can adapt existing vision-language
models with multimodal generation ability. Overall, this framework not only
leverages existing computational investments in text-only LLMs but also enables
the parallel development of language and vision capabilities, presenting a
promising direction for efficient multimodal model development.

摘要：<paragraph>我們提出了 LlamaFusion，一個用於賦予預訓練純文字大型語言模型 (LLM) 多模態生成功能的框架，使它們能夠理解並生成任意序列中的文字和影像。
LlamaFusion 充分利用了現有 Llama-3 的權重來自動迴歸地處理文字，同時引入了額外的平行Transformer模組來處理影像擴散。在訓練期間，每個模態的資料都會路由到其專屬模組：模態特定的前饋層、查詢鍵值投影和正規化層會獨立處理每個模態，而共享的自我注意層則允許文字和影像特徵之間的互動。透過凍結文字特定模組並只訓練影像特定模組，LlamaFusion 保留了純文字 LLM 的語言能力，同時發展出強大的視覺理解和生成能力。與從頭開始預訓練多模態生成模型的方法相比，我們的實驗證明，LlamaFusion 在僅使用 50% 的 FLOP 的情況下，將影像理解力提升了 20%，影像生成能力提升了 3.6%，同時維持了 Llama-3 的語言能力。我們也證明了這個框架可以讓現有的視覺語言模型適應多模態生成能力。總的來說，這個框架不僅利用了在純文字 LLM 上既有的運算投資，也讓語言和視覺能力可以平行發展，為高效的多模態模型開發展示了一個有前景的方向。</paragraph>

##### **Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying**
2412.15177v1 by Federico Castagna, Isabel Sassoon, Simon Parsons

Studies have underscored how, regardless of the recent breakthrough and swift
advances in AI research, even state-of-the-art Large Language models (LLMs)
continue to struggle when performing logical and mathematical reasoning. The
results seem to suggest that LLMs still work as (highly advanced) data pattern
identifiers, scoring poorly when attempting to generalise and solve reasoning
problems the models have never previously seen or that are not close to samples
presented in their training data. To address this compelling concern, this
paper makes use of the notion of critical questions from the literature on
argumentation theory, focusing in particular on Toulmin's model of
argumentation. We show that employing these critical questions can improve the
reasoning capabilities of LLMs. By probing the rationale behind the models'
reasoning process, the LLM can assess whether some logical mistake is occurring
and correct it before providing the final reply to the user prompt. The
underlying idea is drawn from the gold standard of any valid argumentative
procedure: the conclusion is valid if it is entailed by accepted premises. Or,
to paraphrase such Aristotelian principle in a real-world approximation,
characterised by incomplete information and presumptive logic, the conclusion
is valid if not proved otherwise. This approach successfully steers the models'
output through a reasoning pipeline, resulting in better performance against
the baseline and its Chain-of-Thought (CoT) implementation. To this end, an
extensive evaluation of the proposed approach on the MT-Bench Reasoning and
Math tasks across a range of LLMs is provided.

摘要：研究強調，儘管 AI 研究最近取得突破和快速進展，但即使最先進的大語言模型 (LLM) 在執行邏輯和數學推理時仍會遇到困難。結果似乎表明，LLM 仍作為（高度先進的）資料模式識別器，在嘗試概括和解決模型以前從未見過或與其訓練資料中呈現的樣本不接近的推理問題時得分很差。為了解決這個令人信服的問題，本文利用論證理論文獻中的批判性問題概念，特別關注 Toulmin 的論證模型。我們表明，採用這些批判性問題可以提高 LLM 的推理能力。通過探討模型推理過程背後的原理，LLM 可以評估是否發生了邏輯錯誤，並在向使用者提示提供最終答覆之前予以糾正。其基本思想源自任何有效論證程序的黃金標準：如果結論是由公認的前提所蘊含，則該結論有效。或者，用亞里斯多德原則在現實世界的近似中進行改寫，其特徵是不完全的資訊和推定的邏輯，如果沒有被證明是錯誤的，則結論是有效的。這種方法成功地引導模型的輸出通過推理管道，從而相對於基線及其思想鏈 (CoT) 實作產生更好的效能。為此，提供了對跨越一系列 LLM 的 MT-Bench 推理和數學任務的擬議方法的廣泛評估。

##### **Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration**
2412.15166v1 by Junjia Liu, Zhuo Li, Minghao Yu, Zhipeng Dong, Sylvain Calinon, Darwin Caldwell, Fei Chen

Humanoid robots are envisioned as embodied intelligent agents capable of
performing a wide range of human-level loco-manipulation tasks, particularly in
scenarios requiring strenuous and repetitive labor. However, learning these
skills is challenging due to the high degrees of freedom of humanoid robots,
and collecting sufficient training data for humanoid is a laborious process.
Given the rapid introduction of new humanoid platforms, a cross-embodiment
framework that allows generalizable skill transfer is becoming increasingly
critical. To address this, we propose a transferable framework that reduces the
data bottleneck by using a unified digital human model as a common prototype
and bypassing the need for re-training on every new robot platform. The model
learns behavior primitives from human demonstrations through adversarial
imitation, and the complex robot structures are decomposed into functional
components, each trained independently and dynamically coordinated. Task
generalization is achieved through a human-object interaction graph, and skills
are transferred to different robots via embodiment-specific kinematic motion
retargeting and dynamic fine-tuning. Our framework is validated on five
humanoid robots with diverse configurations, demonstrating stable
loco-manipulation and highlighting its effectiveness in reducing data
requirements and increasing the efficiency of skill transfer across platforms.

摘要：類人機器人被視為具備體現智能的代理人，能夠執行廣泛的人類層級的運動操縱任務，特別是在需要劇烈且重複勞動的場景中。然而，學習這些技能具有挑戰性，因為類人機器人的自由度很高，而且為類人機器人收集足夠的訓練資料是一個費力的過程。由於新類人機器人平台的快速導入，一個允許通用技能轉移的跨體現框架正變得越來越重要。為了解決這個問題，我們提出一個可轉移的框架，它通過使用一個統一的數位人類模型作為一個共同的原型來減少資料瓶頸，並繞過在每個新機器人平台上重新訓練的需要。這個模型透過對抗式模仿從人類示範中學習行為原語，而複雜的機器人結構被分解成功能元件，每個元件獨立訓練並動態協調。任務概括化是透過人類物件互動圖表來實現，而技能則透過體現特定的運動運動重新定位和動態微調傳輸到不同的機器人。我們的框架在五個人形機器人上進行驗證，這些機器人具有多樣化的組態，展示了穩定的運動操縱，並突顯了其在減少資料需求和提高跨平台技能轉移效率方面的效能。

##### **Prompt-A-Video: Prompt Your Video Diffusion Model via Preference-Aligned LLM**
2412.15156v1 by Yatai Ji, Jiacheng Zhang, Jie Wu, Shilong Zhang, Shoufa Chen, Chongjian GE, Peize Sun, Weifeng Chen, Wenqi Shao, Xuefeng Xiao, Weilin Huang, Ping Luo

Text-to-video models have made remarkable advancements through optimization
on high-quality text-video pairs, where the textual prompts play a pivotal role
in determining quality of output videos. However, achieving the desired output
often entails multiple revisions and iterative inference to refine
user-provided prompts. Current automatic methods for refining prompts encounter
challenges such as Modality-Inconsistency, Cost-Discrepancy, and Model-Unaware
when applied to text-to-video diffusion models. To address these problem, we
introduce an LLM-based prompt adaptation framework, termed as Prompt-A-Video,
which excels in crafting Video-Centric, Labor-Free and Preference-Aligned
prompts tailored to specific video diffusion model. Our approach involves a
meticulously crafted two-stage optimization and alignment system. Initially, we
conduct a reward-guided prompt evolution pipeline to automatically create
optimal prompts pool and leverage them for supervised fine-tuning (SFT) of the
LLM. Then multi-dimensional rewards are employed to generate pairwise data for
the SFT model, followed by the direct preference optimization (DPO) algorithm
to further facilitate preference alignment. Through extensive experimentation
and comparative analyses, we validate the effectiveness of Prompt-A-Video
across diverse generation models, highlighting its potential to push the
boundaries of video generation.

摘要：文本到影片模型透過最佳化高品質文本影片配對，取得了顯著的進步，其中文字提示在決定影片輸出品質方面扮演了關鍵角色。然而，要達到理想的輸出，通常需要多次修改和反覆推論來改善使用者提供的提示。目前用於改善提示的自動化方法，在應用於文本到影片擴散模型時，會遇到模態不一致、成本差異和模型不知情等挑戰。為了解決這些問題，我們引入了一個基於 LLM 的提示適應架構，稱為 Prompt-A-Video，它擅長製作針對特定影片擴散模型量身打造的以影片為中心、免人工和偏好對齊的提示。我們的做法包含精心設計的兩階段最佳化和對齊系統。最初，我們執行一個獎勵引導提示演化管道，以自動建立最佳提示池，並利用它們對 LLM 進行監督微調 (SFT)。然後採用多維度獎勵為 SFT 模型產生成對資料，接著使用直接偏好最佳化 (DPO) 演算法進一步促進偏好對齊。透過廣泛的實驗和比較分析，我們驗證了 Prompt-A-Video 在各種生成模型中的有效性，突顯了它在推動影片生成邊界的潛力。

##### **Language Models as Continuous Self-Evolving Data Engineers**
2412.15151v1 by Peidong Wang, Ming Wang, Zhiming Ma, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang

Large Language Models (LLMs) have demonstrated remarkable capabilities on
various tasks, while the further evolvement is limited to the lack of
high-quality training data. In addition, traditional training approaches rely
too much on expert-labeled data, setting an upper limit on the performance of
LLMs. To address this issue, we propose a novel paradigm that enables LLMs to
train itself by autonomously generating, cleaning, reviewing, and annotating
data with preference information, named LANCE. Our approach demonstrates that
LLMs can serve as continuous self-evolving data engineers, significantly
reducing the time and cost of the post-training data construction process.
Through iterative fine-tuning on different variants of the Qwen2, we validate
the effectiveness of LANCE across various tasks, showing that it can
continuously improve model performance and maintain high-quality data
generation. Across eight benchmark dimensions, LANCE resulted in an average
score enhancement of 3.36 for Qwen2-7B and 2.70 for Qwen2-7B-Instruct. This
training paradigm with autonomous data construction not only reduces the
reliance on human experts or external models but also ensures that the data
aligns with human values and preferences, paving the way for the development of
future superintelligent systems that can exceed human capabilities.

摘要：大型語言模型 (LLM) 已在各種任務中展現出卓越的能力，而進一步的演進則受到缺乏高品質訓練資料的限制。此外，傳統的訓練方法過度依賴專家標記的資料，為 LLM 的效能設定了上限。為了解決這個問題，我們提出了一個創新的範例，讓 LLM 能夠透過自主產生、清理、審閱和註解帶有偏好資訊的資料來訓練自己，稱為 LANCE。我們的做法證明了 LLM 可以作為持續自我演進的資料工程師，大幅減少訓練後資料建構程序的時間和成本。透過在 Qwen2 的不同變體上進行反覆微調，我們驗證了 LANCE 在各種任務中的有效性，顯示它可以持續改善模型效能並維持高品質的資料產生。在八個基準維度中，LANCE 讓 Qwen2-7B 的平均分數提升了 3.36，而 Qwen2-7B-Instruct 則提升了 2.70。這種具有自主資料建構的訓練範例不僅減少了對人類專家或外部模型的依賴，還能確保資料符合人類的價值觀和偏好，為開發未來能夠超越人類能力的超級智慧系統鋪路。

##### **Leveraging Color Channel Independence for Improved Unsupervised Object Detection**
2412.15150v1 by Bastian Jäckl, Yannick Metz, Udo Schlegel, Daniel A. Keim, Maximilian T. Fischer

Object-centric architectures can learn to extract distinct object
representations from visual scenes, enabling downstream applications on the
object level. Similarly to autoencoder-based image models, object-centric
approaches have been trained on the unsupervised reconstruction loss of images
encoded by RGB color spaces. In our work, we challenge the common assumption
that RGB images are the optimal color space for unsupervised learning in
computer vision. We discuss conceptually and empirically that other color
spaces, such as HSV, bear essential characteristics for object-centric
representation learning, like robustness to lighting conditions. We further
show that models improve when requiring them to predict additional color
channels. Specifically, we propose to transform the predicted targets to the
RGB-S space, which extends RGB with HSV's saturation component and leads to
markedly better reconstruction and disentanglement for five common evaluation
datasets. The use of composite color spaces can be implemented with basically
no computational overhead, is agnostic of the models' architecture, and is
universally applicable across a wide range of visual computing tasks and
training types. The findings of our approach encourage additional
investigations in computer vision tasks beyond object-centric learning.

摘要：物件中心架构可以学习从视觉场景中萃取出不同的物件表征，让下游应用能够在物件层级上运行。类似于基于自动编码器的图像模型，物件中心方法已经过训练，可以无监督地重建由 RGB 色彩空间编码的图像的损失。在我们的工作中，我们挑战了 RGB 图像是计算机视觉中无监督学习的最佳色彩空间的普遍假设。我们从概念上和经验上讨论了其他色彩空间（例如 HSV）具有物件中心表征学习的基本特性，例如对光照条件的鲁棒性。我们进一步表明，当要求模型预测额外的色彩通道时，模型会得到改善。具体来说，我们建议将预测目标转换为 RGB-S 空间，该空间使用 HSV 的饱和度分量扩展了 RGB，并导致五个常见评估数据集的重建和解缠明显更好。复合色彩空间的使用基本上可以不增加计算开销来实现，与模型的架构无关，并且普遍适用于广泛的视觉计算任务和训练类型。我们方法的发现鼓励在超越物件中心学习的计算机视觉任务中进行额外的调查。

##### **Probabilistic Strategy Logic with Degrees of Observability**
2412.15135v1 by Chunyan Mu, Nima Motamed, Natasha Alechina, Brian Logan

There has been considerable work on reasoning about the strategic ability of
agents under imperfect information. However, existing logics such as
Probabilistic Strategy Logic are unable to express properties relating to
information transparency. Information transparency concerns the extent to which
agents' actions and behaviours are observable by other agents. Reasoning about
information transparency is useful in many domains including security, privacy,
and decision-making. In this paper, we present a formal framework for reasoning
about information transparency properties in stochastic multi-agent systems. We
extend Probabilistic Strategy Logic with new observability operators that
capture the degree of observability of temporal properties by agents. We show
that the model checking problem for the resulting logic is decidable.

摘要：對於不完美資訊下主體的策略能力進行推理的工作已經相當多。然而，現有的邏輯例如機率策略邏輯無法表達與資訊透明度有關的屬性。資訊透明度涉及主體的動作和行為在何種程度上可以被其他主體觀察到。對於資訊透明度進行推理在許多領域中很有用，包括安全性、隱私和決策制定。在本文中，我們提出一個用於對隨機多主體系統中資訊透明度屬性進行推理的形式架構。我們使用新的可觀察性運算子擴充機率策略邏輯，該運算子捕捉主體對時間屬性的可觀察程度。我們證明了對於所得邏輯的模型檢查問題是可判定的。

##### **Jet: A Modern Transformer-Based Normalizing Flow**
2412.15129v1 by Alexander Kolesnikov, André Susano Pinto, Michael Tschannen

In the past, normalizing generative flows have emerged as a promising class
of generative models for natural images. This type of model has many modeling
advantages: the ability to efficiently compute log-likelihood of the input
data, fast generation and simple overall structure. Normalizing flows remained
a topic of active research but later fell out of favor, as visual quality of
the samples was not competitive with other model classes, such as GANs,
VQ-VAE-based approaches or diffusion models. In this paper we revisit the
design of the coupling-based normalizing flow models by carefully ablating
prior design choices and using computational blocks based on the Vision
Transformer architecture, not convolutional neural networks. As a result, we
achieve state-of-the-art quantitative and qualitative performance with a much
simpler architecture. While the overall visual quality is still behind the
current state-of-the-art models, we argue that strong normalizing flow models
can help advancing research frontier by serving as building components of more
powerful generative models.

摘要：在過去，正規化生成流已成為自然圖像生成模型中一個很有前景的類別。這種類型的模型有許多建模優勢：有效計算輸入資料的對數似然、快速生成和簡單的整體結構。正規化流仍然是積極研究的主題，但後來不受青睞，因為樣本的視覺品質無法與其他模型類別競爭，例如 GAN、基於 VQ-VAE 的方法或擴散模型。在本文中，我們重新檢視基於耦合的正規化流模型的設計，透過仔細消融先前的設計選擇，並使用基於 Vision Transformer 架構（而非卷積神經網路）的計算區塊。因此，我們以更簡單的架構實現了最先進的量化和質化效能。雖然整體視覺品質仍落後於目前的最新模型，但我們認為強大的正規化流模型可以透過作為更強大生成模型的建構元件，來幫助推進研究前沿。

##### **Adaptive Pruning for Large Language Models with Structural Importance Awareness**
2412.15127v1 by Haotian Zheng, Jinke Ren, Yushan Sun, Ruichen Zhang, Wenbo Zhang, Zhen Li, Dusit Niyato, Shuguang Cui, Yatong Han

The recent advancements in large language models (LLMs) have significantly
improved language understanding and generation capabilities. However, it is
difficult to deploy LLMs on resource-constrained edge devices due to their high
computational and storage resource demands. To address this issue, we propose a
novel LLM model pruning method, namely structurally-aware adaptive pruning
(SAAP), to significantly reduce the computational and memory costs while
maintaining model performance. We first define an adaptive importance fusion
metric to evaluate the importance of all coupled structures in LLMs by
considering their homoscedastic uncertainty. Then, we rank the importance of
all modules to determine the specific layers that should be pruned to meet
particular performance requirements. Furthermore, we develop a new group
fine-tuning strategy to improve the inference efficiency of LLMs. Finally, we
evaluate the proposed SAAP method on multiple LLMs across two common tasks,
i.e., zero-shot classification and text generation. Experimental results show
that our SAAP method outperforms several state-of-the-art baseline methods,
achieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and
LLaMA-13B. Additionally, SAAP improves the token generation speed by 5%,
showcasing its practical advantages in resource-constrained scenarios.

摘要：大型語言模型 (LLM) 的最新進展顯著地
改進了語言理解和生成能力。然而，由於 LLM 對計算和儲存資源需求高，因此難以將其部署在資源受限的邊緣裝置上。為了解決此問題，我們提出了一種新穎的 LLM 模型剪枝方法，即結構感知自適應剪枝 (SAAP)，以在維持模型效能的同時顯著降低計算和記憶體成本。我們首先定義一個自適應重要性融合指標，透過考慮 LLM 中所有耦合結構的同質異方差不確定性來評估其重要性。然後，我們對所有模組的重要性進行排序，以確定應剪枝的特定層，以滿足特定的效能需求。此外，我們開發了一種新的群組微調策略，以改善 LLM 的推論效率。最後，我們在兩個常見任務中對多個 LLM 評估所提出的 SAAP 方法，即零次分類和文字生成。實驗結果顯示，我們的 SAAP 方法優於多種最先進的基線方法，在 LLaMA-7B、Vicuna-7B 和 LLaMA-13B 上分別獲得 2.17%、2.37% 和 2.39% 的準確度提升。此外，SAAP 將代碼生成速度提高了 5%，展示了其在資源受限場景中的實際優勢。

##### **Outcome-Refining Process Supervision for Code Generation**
2412.15118v1 by Zhuohao Yu, Weizheng Gu, Yidong Wang, Zhengran Zeng, Jindong Wang, Wei Ye, Shikun Zhang

Large Language Models have demonstrated remarkable capabilities in code
generation, yet they often struggle with complex programming tasks that require
deep algorithmic reasoning. While process supervision through learned reward
models shows promise in guiding reasoning steps, it requires expensive training
data and suffers from unreliable evaluation. We propose Outcome-Refining
Process Supervision, a novel paradigm that treats outcome refinement itself as
the process to be supervised. Our framework leverages concrete execution
signals to ground the supervision of reasoning steps, while using
tree-structured exploration to maintain multiple solution trajectories
simultaneously. Experiments demonstrate that our approach enables even smaller
models to achieve high success accuracy and performance metrics on competitive
programming tasks, creates more reliable verification than traditional reward
models without requiring training PRMs. Our approach achieves significant
improvements across 5 models and 3 datasets: an average of 26.9% increase in
correctness and 42.2% in efficiency. The results suggest that providing
structured reasoning space with concrete verification signals is crucial for
solving complex programming tasks. We open-source all our code and data at:
https://github.com/zhuohaoyu/ORPS

摘要：大型語言模型在程式碼生成方面展現了卓越的能力，但它們經常在需要深入演算法推理的複雜程式設計任務中遇到困難。雖然透過學習回饋模型進行程序監督顯示出引導推理步驟的潛力，但它需要昂貴的訓練資料，且評估結果不可靠。我們提出結果精煉程序監督，這是一種新穎的範例，將結果精煉本身視為要監督的程序。我們的架構利用具體的執行訊號來奠定推理步驟的監督基礎，同時使用樹狀結構探索來同時維護多個解決方案軌跡。實驗證明，我們的做法使更小的模型也能在競爭性程式設計任務中達成高成功準確度和效能指標，並建立比傳統回饋模型更可靠的驗證，而不需要訓練 PRM。我們的做法在 5 個模型和 3 個資料集上獲得顯著進步：正確率平均提升 26.9%，效率提升 42.2%。結果表明，提供具有具體驗證訊號的結構化推理空間對於解決複雜的程式設計任務至關重要。我們在以下網址開放原始碼和所有資料：https://github.com/zhuohaoyu/ORPS

##### **Qwen2.5 Technical Report**
2412.15115v1 by Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zihan Qiu

In this report, we introduce Qwen2.5, a comprehensive series of large
language models (LLMs) designed to meet diverse needs. Compared to previous
iterations, Qwen 2.5 has been significantly improved during both the
pre-training and post-training stages. In terms of pre-training, we have scaled
the high-quality pre-training datasets from the previous 7 trillion tokens to
18 trillion tokens. This provides a strong foundation for common sense, expert
knowledge, and reasoning capabilities. In terms of post-training, we implement
intricate supervised finetuning with over 1 million samples, as well as
multistage reinforcement learning. Post-training techniques enhance human
preference, and notably improve long text generation, structural data analysis,
and instruction following. To handle diverse and varied use cases effectively,
we present Qwen2.5 LLM series in rich sizes. Open-weight offerings include base
and instruction-tuned models, with quantized versions available. In addition,
for hosted solutions, the proprietary models currently include two
mixture-of-experts (MoE) variants: Qwen2.5-Turbo and Qwen2.5-Plus, both
available from Alibaba Cloud Model Studio. Qwen2.5 has demonstrated top-tier
performance on a wide range of benchmarks evaluating language understanding,
reasoning, mathematics, coding, human preference alignment, etc. Specifically,
the open-weight flagship Qwen2.5-72B-Instruct outperforms a number of open and
proprietary models and demonstrates competitive performance to the
state-of-the-art open-weight model, Llama-3-405B-Instruct, which is around 5
times larger. Qwen2.5-Turbo and Qwen2.5-Plus offer superior cost-effectiveness
while performing competitively against GPT-4o-mini and GPT-4o respectively.
Additionally, as the foundation, Qwen2.5 models have been instrumental in
training specialized models such as Qwen2.5-Math, Qwen2.5-Coder, QwQ, and
multimodal models.

摘要：<paragraph>在這份報告中，我們介紹了 Qwen2.5，這是一個全面的大語言模型 (LLM) 系列，旨在滿足不同的需求。與之前的迭代相比，Qwen 2.5 在預訓練和後訓練階段都得到了顯著改進。在預訓練方面，我們將高品質的預訓練數據集從之前的 7 兆個符號擴展到了 18 兆個符號。這為常識、專業知識和推理能力提供了堅實的基礎。在後訓練方面，我們實施了複雜的監督微調，樣本量超過 100 萬，以及多階段強化學習。後訓練技術增強了人類偏好，並顯著改進了長文本生成、結構化數據分析和指令遵循。為了有效地處理多樣化的用例，我們提供了豐富尺寸的 Qwen2.5 LLM 系列。開放權重產品包括基礎模型和指令調整模型，並提供量化版本。此外，對於託管解決方案，專有模型目前包括兩個混合專家 (MoE) 變體：Qwen2.5-Turbo 和 Qwen2.5-Plus，均可在阿里雲模型工作室獲得。Qwen2.5 在評估語言理解、推理、數學、編碼、人類偏好對齊等方面的一系列基準測試中展示了一流的性能。具體來說，開放權重旗艦 Qwen2.5-72B-Instruct 優於許多開放和專有模型，並展示了與最先進的開放權重模型 Llama-3-405B-Instruct 的競爭性能，後者大約大 5 倍。Qwen2.5-Turbo 和 Qwen2.5-Plus 分別提供優越的成本效益，同時與 GPT-4o-mini 和 GPT-4o 競爭。此外，作為基礎，Qwen2.5 模型在訓練 Qwen2.5-Math、Qwen2.5-Coder、QwQ 和多模態模型等專業模型方面發揮了重要作用。</paragraph>

##### **Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture**
2412.15113v1 by Thomas F Burns, Tomoki Fukai, Christopher J Earls

Large language models (LLMs) demonstrate an impressive ability to utilise
information within the context of their input sequences to appropriately
respond to data unseen by the LLM during its training procedure. This ability
is known as in-context learning (ICL). Humans and non-human animals demonstrate
similar abilities, however their neural architectures differ substantially from
LLMs. Despite this, a critical component within LLMs, the attention mechanism,
resembles modern associative memory models, widely used in and influenced by
the computational neuroscience community to model biological memory systems.
Using this connection, we introduce an associative memory model capable of
performing ICL. We use this as inspiration for a novel residual stream
architecture which allows information to directly flow between attention heads.
We test this architecture during training within a two-layer Transformer and
show its ICL abilities manifest more quickly than without this modification. We
then apply our architecture in small language models with 8 million parameters,
focusing on attention head values, with results also indicating improved ICL
performance at this larger and more naturalistic scale.

摘要：大型語言模型 (LLM) 表現出令人印象深刻的能力，能夠利用其輸入序列中的資訊，適當地回應 LLM 在訓練過程中未見過的資料。這種能力稱為語境中學習 (ICL)。人類和非人類動物表現出類似的能力，但他們的神經架構與 LLM 有很大不同。儘管如此，LLM 中的一個關鍵組成部分，注意機制，類似於現代聯想記憶模型，在計算神經科學社群中廣泛使用並受到其影響，用於建模生物記憶系統。利用這種聯繫，我們引入了一個能夠執行 ICL 的聯想記憶模型。我們以此為靈感，打造了一個新穎的殘差串流架構，讓資訊能夠直接在注意權重之間流動。我們在一個兩層 Transformer 中訓練期間測試這個架構，並展示其 ICL 能力比沒有這個修改時表現得更快。然後，我們將我們的架構應用於具有 800 萬個參數的小語言模型，專注於注意權重值，結果也表明在這個更大且更自然的規模下，ICL 效能有所提升。

##### **Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid**
2412.15105v1 by Shimiao Li

The growing threats of uncertainties, anomalies, and cyberattacks on power
grids are driving a critical need to advance situational awareness which allows
system operators to form a complete and accurate picture of the present and
future state. Simulation and estimation are foundational tools in this process.
However, existing tools lack the robustness and efficiency required to achieve
the level of situational awareness needed for the ever-evolving threat
landscape. Industry-standard (steady-state) simulators are not robust to
blackouts, often leading to non-converging or non-actionable results.
Estimation tools lack robustness to anomalous data, returning erroneous system
states. Efficiency is the other major concern as nonlinearities and scalability
issues make large systems slow to converge.
  This thesis addresses robustness and efficiency gaps through a dual-fold
contribution. We first address the inherent limitations in the existing
physics-based and data-driven worlds; and then transcend the boundaries of
conventional algorithmic design in the direction of a new paradigm --
Physics-ML Synergy -- which integrates the strengths of the two worlds. Our
approaches are built on circuit formulation which provides a unified framework
that applies to both transmission and distribution. Sparse optimization acts as
the key enabler to make these tools intrinsically robust and immune to random
threats, pinpointing dominant sources of (random) blackouts and data errors.
Further, we explore sparsity-exploiting optimizations to develop lightweight ML
models whose prediction and detection capabilities are a complement to
physics-based tools; and whose lightweight designs advance generalization and
scalability. Finally, Physics-ML Synergy brings robustness and efficiency
further against targeted cyberthreats, by interconnecting our physics-based
tools with lightweight ML.

摘要：<paragraph>電網中不確定性、異常和網路攻擊的威脅日益增加，這促使我們急需提升情境感知，讓系統操作員能夠對當前和未來狀態形成完整且準確的圖像。模擬和估計是此過程中必備的工具。
但是，現有的工具缺乏實現情境感知所需的穩健性和效率，而情境感知是因應不斷變化的威脅環境所必需的。產業標準（穩態）模擬器對停電並不穩健，通常會導致無法收斂或無法採取行動的結果。估計工具缺乏對異常資料的穩健性，會回報錯誤的系統狀態。效率是另一個主要問題，因為非線性和可擴充性問題會使得大型系統收斂速度變慢。
本論文透過雙重的貢獻來解決穩健性和效率的差距。我們首先解決現有基於物理和資料驅動的世界中固有的限制；然後超越傳統演算法設計的界限，朝向一個新的典範——物理機器學習協同效應——邁進，它整合了這兩個世界的優勢。我們的做法建立在電路公式之上，它提供了一個統一的架構，適用於傳輸和配電。稀疏最佳化作為關鍵的推手，讓這些工具在內部變得穩健，並且對隨機威脅免疫，精確找出（隨機）停電和資料錯誤的主要來源。
此外，我們探索利用稀疏性的最佳化來開發輕量級機器學習模型，其預測和偵測能力可以補充基於物理的工具；而其輕量級的設計則可以促進泛化和可擴充性。最後，物理機器學習協同效應透過將我們的基於物理的工具與輕量級機器學習互連，進一步提升對針對性網路威脅的穩健性和效率。</paragraph>

##### **Review-Then-Refine: A Dynamic Framework for Multi-Hop Question Answering with Temporal Adaptability**
2412.15101v1 by Xiangsen Chen, Xuming Hu, Nan Tang

Retrieve-augmented generation (RAG) frameworks have emerged as a promising
solution to multi-hop question answering(QA) tasks since it enables large
language models (LLMs) to incorporate external knowledge and mitigate their
inherent knowledge deficiencies. Despite this progress, existing RAG
frameworks, which usually follows the retrieve-then-read paradigm, often
struggle with multi-hop QA with temporal information since it has difficulty
retrieving and synthesizing accurate time-related information. To address the
challenge, this paper proposes a novel framework called review-then-refine,
which aims to enhance LLM performance in multi-hop QA scenarios with temporal
information. Our approach begins with a review phase, where decomposed
sub-queries are dynamically rewritten with temporal information, allowing for
subsequent adaptive retrieval and reasoning process. In addition, we implement
adaptive retrieval mechanism to minimize unnecessary retrievals, thus reducing
the potential for hallucinations. In the subsequent refine phase, the LLM
synthesizes the retrieved information from each sub-query along with its
internal knowledge to formulate a coherent answer. Extensive experimental
results across multiple datasets demonstrate the effectiveness of our proposed
framework, highlighting its potential to significantly improve multi-hop QA
capabilities in LLMs.

摘要：檢索增強生成 (RAG) 框架已成為多跳式問答 (QA) 任務的一種有前途的解決方案，因為它使大型語言模型 (LLM) 能夠納入外部知識並減輕其固有的知識缺陷。儘管有這些進展，現有的 RAG 框架通常遵循先檢索後閱讀的範例，由於難以檢索和綜合準確的時間相關資訊，因此在具有時間資訊的多跳式問答中經常遇到困難。為了應對這一挑戰，本文提出了一種稱為先檢閱後修正的新框架，旨在增強 LLM 在具有時間資訊的多跳式問答場景中的性能。我們的做法從檢閱階段開始，在該階段，分解的子查詢會使用時間資訊動態改寫，允許後續的適應性檢索和推理過程。此外，我們實作了適應性檢索機制以最大程度減少不必要的檢索，從而降低產生幻覺的可能性。在後續的修正階段，LLM 將從每個子查詢中檢索的資訊與其內部知識一起綜合，以形成一個連貫的答案。跨多個資料集的廣泛實驗結果證明了我們提出的框架的有效性，突出了其顯著改善 LLM 中多跳式問答能力的潛力。

##### **A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation**
2412.15098v1 by João A. Leite, Olesya Razuvayevskaya, Carolina Scarton, Kalina Bontcheva

Disinformation, irrespective of domain or language, aims to deceive or
manipulate public opinion, typically through employing advanced persuasion
techniques. Qualitative and quantitative research on the weaponisation of
persuasion techniques in disinformation has been mostly topic-specific (e.g.,
COVID-19) with limited cross-domain studies, resulting in a lack of
comprehensive understanding of these strategies. This study employs a
state-of-the-art persuasion technique classifier to conduct a large-scale,
multi-domain analysis of the role of 16 persuasion techniques in disinformation
narratives. It shows how different persuasion techniques are employed
disproportionately in different disinformation domains. We also include a
detailed case study on climate change disinformation, highlighting how
linguistic, psychological, and cultural factors shape the adaptation of
persuasion strategies to fit unique thematic contexts.

摘要：不論領域或語言，錯誤訊息的目的是欺騙或操弄公眾輿論，通常透過使用進階說服技巧。關於在錯誤訊息中將說服技巧武器化的定性和量化研究大多是針對特定主題（例如 COVID-19），跨領域研究有限，導致無法全面了解這些策略。本研究採用最先進的說服技巧分類器，對 16 種說服技巧在錯誤訊息敘述中的角色進行大規模、多領域分析。它顯示不同的說服技巧如何在不同的錯誤訊息領域中不成比例地使用。我們還包括一個關於氣候變遷錯誤訊息的詳細案例研究，強調語言、心理和文化因素如何影響說服策略以適應獨特的議題脈絡。

##### **A Full Transformer-based Framework for Automatic Pain Estimation using Videos**
2412.15095v1 by Stefanos Gkikas, Manolis Tsiknakis

The automatic estimation of pain is essential in designing an optimal pain
management system offering reliable assessment and reducing the suffering of
patients. In this study, we present a novel full transformer-based framework
consisting of a Transformer in Transformer (TNT) model and a Transformer
leveraging cross-attention and self-attention blocks. Elaborating on videos
from the BioVid database, we demonstrate state-of-the-art performances, showing
the efficacy, efficiency, and generalization capability across all the primary
pain estimation tasks.

摘要：疼痛的自動評估對於設計一個最佳的疼痛管理系統至關重要，該系統提供可靠的評估並減輕患者的痛苦。在本研究中，我們提出了一個新穎的基於完全Transformer的框架，它由Transformer中的Transformer (TNT) 模型和一個利用交叉注意力和自注意力塊的Transformer組成。通過闡述 BioVid 數據庫中的視頻，我們展示了最先進的性能，展示了在所有主要的疼痛評估任務中的功效、效率和泛化能力。

##### **Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation**
2412.15086v1 by Haoran Liu, Youzhi Luo, Tianxiao Li, James Caverlee, Martin Renqiang Min

We consider the conditional generation of 3D drug-like molecules with
\textit{explicit control} over molecular properties such as drug-like
properties (e.g., Quantitative Estimate of Druglikeness or Synthetic
Accessibility score) and effectively binding to specific protein sites. To
tackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and
factorize the latent space of our generative model into two disentangled
aspects: molecular properties and the remaining structural context of 3D
molecules. Our model ensures explicit control over these molecular attributes
while maintaining equivariance of coordinate representation and invariance of
data likelihood. Furthermore, we introduce a novel alignment-based coordinate
loss to adapt equivariant networks for auto-regressive de-novo 3D molecule
generation from scratch. Extensive experiments validate our model's
effectiveness on property-guided and context-guided molecule generation, both
for de-novo 3D molecule design and structure-based drug discovery against
protein targets.

摘要：我們考慮具有對分子特性（例如藥物特性（例如藥物相似性或合成可及性評分）的明確控制）的 3D 藥物樣分子的條件生成，並有效地與特定蛋白質位點結合。為了解決這個問題，我們提出一個 E(3)-等變 Wasserstein 自動編碼器，並將我們生成模型的潛在空間分解為兩個解開的方面：分子特性和 3D 分子的剩餘結構背景。我們的模型確保對這些分子屬性進行明確控制，同時保持座標表示的等變性和數據似然的恆定性。此外，我們引入了一個基於對齊的新的座標損失，以適應等變網路，從頭開始進行自回歸從頭 3D 分子生成。大量的實驗驗證了我們模型在屬性引導和背景引導分子生成方面的有效性，既適用於從頭 3D 分子設計，也適用於針對蛋白質靶標的基於結構的藥物發現。

##### **AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling**
2412.15084v1 by Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping

In this paper, we introduce AceMath, a suite of frontier math models that
excel in solving complex math problems, along with highly effective reward
models capable of evaluating generated solutions and reliably identifying the
correct ones. To develop the instruction-tuned math models, we propose a
supervised fine-tuning (SFT) process that first achieves competitive
performance across general domains, followed by targeted fine-tuning for the
math domain using a carefully curated set of prompts and synthetically
generated responses. The resulting model, AceMath-72B-Instruct greatly
outperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop
math-specialized reward model, we first construct AceMath-RewardBench, a
comprehensive and robust benchmark for evaluating math reward models across
diverse problems and difficulty levels. After that, we present a systematic
approach to build our math reward models. The resulting model, AceMath-72B-RM,
consistently outperforms state-of-the-art reward models. Furthermore, when
combining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest
average rm@8 score across the math reasoning benchmarks. We will release model
weights, training data, and evaluation benchmarks at:
https://research.nvidia.com/labs/adlr/acemath

摘要：<paragraph>在本文中，我們介紹 AceMath，這是一套前沿數學模型，擅長解決複雜的數學問題，並具備高效的獎勵模型，能夠評估生成的解並可靠地找出正確的解。為了開發指令調整的數學模型，我們提出了一個監督微調 (SFT) 過程，首先在一般領域中實現競爭力，然後使用精心策劃的提示和合成生成的回應，針對數學領域進行目標微調。由此產生的模型 AceMath-72B-Instruct 大大優於 Qwen2.5-Math-72B-Instruct、GPT-4o 和 Claude-3.5 Sonnet。為了開發數學專業獎勵模型，我們首先構建 AceMath-RewardBench，一個全面且穩健的基準，用於評估數學獎勵模型在不同問題和難度級別上的表現。之後，我們提出了一個系統性的方法來構建我們的數學獎勵模型。由此產生的模型 AceMath-72B-RM，始終優於最先進的獎勵模型。此外，當將 AceMath-72B-Instruct 與 AceMath-72B-RM 結合使用時，我們在數學推理基準中獲得了最高的平均 rm@8 分數。我們將在以下網址發布模型權重、訓練數據和評估基準：
https://research.nvidia.com/labs/adlr/acemath</paragraph>

##### **Till the Layers Collapse: Compressing a Deep Neural Network through the Lenses of Batch Normalization Layers**
2412.15077v1 by Zhu Liao, Nour Hezbri, Victor Quétu, Van-Tam Nguyen, Enzo Tartaglione

Today, deep neural networks are widely used since they can handle a variety
of complex tasks. Their generality makes them very powerful tools in modern
technology. However, deep neural networks are often overparameterized. The
usage of these large models consumes a lot of computation resources. In this
paper, we introduce a method called \textbf{T}ill the \textbf{L}ayers
\textbf{C}ollapse (TLC), which compresses deep neural networks through the
lenses of batch normalization layers. By reducing the depth of these networks,
our method decreases deep neural networks' computational requirements and
overall latency. We validate our method on popular models such as Swin-T,
MobileNet-V2, and RoBERTa, across both image classification and natural
language processing (NLP) tasks.

摘要：<paragraph>如今，深度神经网络被广泛使用，因为它们可以处理各种复杂的任务。它们的普遍性使它们成为现代技术中非常强大的工具。然而，深度神经网络通常是过参数化的。使用这些大型模型会消耗大量计算资源。在本文中，我们介绍了一种称为\textbf{T}ill the \textbf{L}ayers \textbf{C}ollapse (TLC) 的方法，该方法通过批归一化层的透镜压缩深度神经网络。通过减少这些网络的深度，我们的方法降低了深度神经网络的计算需求和整体延迟。我们在流行的模型（例如 Swin-T、MobileNet-V2 和 RoBERTa）上验证了我们的方法，涵盖图像分类和自然语言处理 (NLP) 任务。</paragraph>

##### **ConfliBERT: A Language Model for Political Conflict**
2412.15060v1 by Patrick T. Brandt, Sultan Alsarra, Vito J. D`Orazio, Dagmar Heintze, Latifur Khan, Shreyas Meher, Javier Osorio, Marcus Sianan

Conflict scholars have used rule-based approaches to extract information
about political violence from news reports and texts. Recent Natural Language
Processing developments move beyond rigid rule-based approaches. We review our
recent ConfliBERT language model (Hu et al. 2022) to process political and
violence related texts. The model can be used to extract actor and action
classifications from texts about political conflict. When fine-tuned, results
show that ConfliBERT has superior performance in accuracy, precision and recall
over other large language models (LLM) like Google's Gemma 2 (9B), Meta's Llama
3.1 (7B), and Alibaba's Qwen 2.5 (14B) within its relevant domains. It is also
hundreds of times faster than these more generalist LLMs. These results are
illustrated using texts from the BBC, re3d, and the Global Terrorism Dataset
(GTD).

摘要：衝突學者已使用基於規則的方法從新聞報導和文字中擷取有關政治暴力的資訊。最近的自然語言處理發展已超越僵化的基於規則的方法。我們檢視我們最近的 ConfliBERT 語言模型 (Hu et al. 2022) 以處理政治和暴力相關文字。該模型可 used to extract actor and action classifications from texts about political conflict.微調後，結果顯示 ConfliBERT 在其相關領域中，在準確度、精確度和召回率方面都優於其他大型語言模型 (LLM)，例如 Google 的 Gemma 2 (9B)、Meta 的 Llama 3.1 (7B) 和阿里巴巴的 Qwen 2.5 (14B)。它也比這些更通用的 LLM 快上數百倍。這些結果使用來自 BBC、re3d 和全球恐怖主義資料集 (GTD) 的文字說明。

##### **Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI**
2412.15047v1 by Isadora Krsek, Anubha Kabra, Yao Dou, Tarek Naous, Laura A. Dabbish, Alan Ritter, Wei Xu, Sauvik Das

In pseudonymous online fora like Reddit, the benefits of self-disclosure are
often apparent to users (e.g., I can vent about my in-laws to understanding
strangers), but the privacy risks are more abstract (e.g., will my partner be
able to tell that this is me?). Prior work has sought to develop natural
language processing (NLP) tools that help users identify potentially risky
self-disclosures in their text, but none have been designed for or evaluated
with the users they hope to protect. Absent this assessment, these tools will
be limited by the social-technical gap: users need assistive tools that help
them make informed decisions, not paternalistic tools that tell them to avoid
self-disclosure altogether. To bridge this gap, we conducted a study with N =
21 Reddit users; we had them use a state-of-the-art NLP disclosure detection
model on two of their authored posts and asked them questions to understand if
and how the model helped, where it fell short, and how it could be improved to
help them make more informed decisions. Despite its imperfections, users
responded positively to the model and highlighted its use as a tool that can
help them catch mistakes, inform them of risks they were unaware of, and
encourage self-reflection. However, our work also shows how, to be useful and
usable, AI for supporting privacy decision-making must account for posting
context, disclosure norms, and users' lived threat models, and provide
explanations that help contextualize detected risks.

摘要：在 Reddit 等匿名網路論壇中，自我揭露的優點對使用者來說通常很明顯（例如，我可以向理解我的陌生人發洩對姻親的不滿），但隱私風險則較為抽象（例如，我的伴侶是否會知道這是我？）。先前的研究試圖開發自然語言處理 (NLP) 工具，協助使用者辨識其文字中潛在有風險的自我揭露，但沒有一項是專門為他們希望保護的使用者所設計或評估的。在沒有這項評估的情況下，這些工具將受到社會技術差距的限制：使用者需要輔助工具來幫助他們做出明智的決定，而不是告訴他們完全避免自我揭露的父權式工具。為了彌合理論與實務的差距，我們對 N = 21 位 Reddit 使用者進行了一項研究；我們請他們使用最先進的 NLP 揭露偵測模型，針對他們撰寫的兩篇文章進行分析，並向他們提問，以了解該模型是否有幫助、如何幫助、不足之處，以及如何改進以幫助他們做出更明智的決定。儘管有其缺陷，使用者對該模型的反應仍是正面的，並強調其可用作一種工具，幫助他們找出錯誤、告知他們不知道的風險，並鼓勵自我反省。然而，我們的研究也顯示，為了實用且可用，支援隱私決策的 AI 必須考慮發文背景、揭露規範和使用者的既有威脅模型，並提供說明以幫助將偵測到的風險脈絡化。

##### **LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps**
2412.15035v1 by Felix Friedrich, Simone Tedeschi, Patrick Schramowski, Manuel Brack, Roberto Navigli, Huu Nguyen, Bo Li, Kristian Kersting

Building safe Large Language Models (LLMs) across multiple languages is
essential in ensuring both safe access and linguistic diversity. To this end,
we introduce M-ALERT, a multilingual benchmark that evaluates the safety of
LLMs in five languages: English, French, German, Italian, and Spanish. M-ALERT
includes 15k high-quality prompts per language, totaling 75k, following the
detailed ALERT taxonomy. Our extensive experiments on 10 state-of-the-art LLMs
highlight the importance of language-specific safety analysis, revealing that
models often exhibit significant inconsistencies in safety across languages and
categories. For instance, Llama3.2 shows high unsafety in the category
crime_tax for Italian but remains safe in other languages. Similar differences
can be observed across all models. In contrast, certain categories, such as
substance_cannabis and crime_propaganda, consistently trigger unsafe responses
across models and languages. These findings underscore the need for robust
multilingual safety practices in LLMs to ensure safe and responsible usage
across diverse user communities.

摘要：建立跨多種語言的安全大型語言模型 (LLM) 對於確保安全存取和語言多樣性至關重要。為此，我們引入了 M-ALERT，這是一個多語言基準，用於評估五種語言（英語、法語、德語、義大利語和西班牙語）中 LLM 的安全性。M-ALERT 包含每種語言 15k 個高品質提示，總計 75k，遵循詳細的 ALERT 分類法。我們對 10 個最先進的 LLM 進行的廣泛實驗突顯了特定語言安全分析的重要性，揭示了模型在不同語言和類別中的安全性往往存在顯著不一致。例如，Llama3.2 在義大利語的 crime_tax 類別中表現出高度不安全性，但在其他語言中仍然安全。在所有模型中都可以觀察到類似的差異。相比之下，某些類別（例如 substance_cannabis 和 crime_propaganda）會持續觸發不同模型和語言的不安全回應。這些發現強調了在 LLM 中採用強健的多語言安全實務，以確保在不同的使用者社群中安全且負責任地使用。

##### **Large Language Models and Code Security: A Systematic Literature Review**
2412.15004v1 by Enna Basic, Alberto Giaretta

Large Language Models (LLMs) have emerged as powerful tools for automating
various programming tasks, including security-related ones, such as detecting
and fixing vulnerabilities. Despite their promising capabilities, when required
to produce or modify pre-existing code, LLMs could introduce vulnerabilities
unbeknown to the programmer. When analyzing code, they could miss clear
vulnerabilities or signal nonexistent ones. In this Systematic Literature
Review (SLR), we aim to investigate both the security benefits and potential
drawbacks of using LLMs for a variety of code-related tasks. In particular,
first we focus on the types of vulnerabilities that could be introduced by
LLMs, when used for producing code. Second, we analyze the capabilities of LLMs
to detect and fix vulnerabilities, in any given code, and how the prompting
strategy of choice impacts their performance in these two tasks. Last, we
provide an in-depth analysis on how data poisoning attacks on LLMs can impact
performance in the aforementioned tasks.

摘要：大型語言模型 (LLM) 已成為自動化各種程式設計任務的強大工具，包括與安全性相關的任務，例如偵測和修復漏洞。儘管它們具有令人期待的能力，但在需要產生或修改現有程式碼時，LLM 可能會在程式設計人員不知情的情況下引入漏洞。在分析程式碼時，它們可能會遺漏明顯的漏洞或發出不存在的漏洞訊號。在此系統性文獻回顧 (SLR) 中，我們旨在探討使用 LLM 執行各種程式碼相關任務的安全性好處和潛在缺點。特別是，我們首先關注 LLM 在用於產生程式碼時可能引入的漏洞類型。其次，我們分析 LLM 在任何給定程式碼中偵測和修復漏洞的能力，以及提示策略如何影響它們在這些任務中的效能。最後，我們深入分析資料中毒攻擊如何影響 LLM 在上述任務中的效能。

##### **HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs**
2412.14995v1 by Pham Vu Tuan Dat, Long Doan, Huynh Thi Thanh Binh

Automatic Heuristic Design (AHD) is an active research area due to its
utility in solving complex search and NP-hard combinatorial optimization
problems in the real world. The recent advancements in Large Language Models
(LLMs) introduce new possibilities by coupling LLMs with evolutionary
computation to automatically generate heuristics, known as LLM-based
Evolutionary Program Search (LLM-EPS). While previous LLM-EPS studies obtained
great performance on various tasks, there is still a gap in understanding the
properties of heuristic search spaces and achieving a balance between
exploration and exploitation, which is a critical factor in large heuristic
search spaces. In this study, we address this gap by proposing two diversity
measurement metrics and perform an analysis on previous LLM-EPS approaches,
including FunSearch, EoH, and ReEvo. Results on black-box AHD problems reveal
that while EoH demonstrates higher diversity than FunSearch and ReEvo, its
objective score is unstable. Conversely, ReEvo's reflection mechanism yields
good objective scores but fails to optimize diversity effectively. With this
finding in mind, we introduce HSEvo, an adaptive LLM-EPS framework that
maintains a balance between diversity and convergence with a harmony search
algorithm. Through experimentation, we find that HSEvo achieved high diversity
indices and good objective scores while remaining cost-effective. These results
underscore the importance of balancing exploration and exploitation and
understanding heuristic search spaces in designing frameworks in LLM-EPS.

摘要：自動啟發式設計 (AHD) 因其在解決現實世界中複雜的搜尋和 NP 難組合最佳化問題中的效用而成為一個活躍的研究領域。大型語言模型 (LLM) 的最新進展引入了新的可能性，將 LLM 與演化計算結合起來自動生成啟發式，稱為基於 LLM 的演化程式搜尋 (LLM-EPS)。雖然先前的 LLM-EPS 研究在各種任務上獲得了很好的效能，但在理解啟發式搜尋空間的屬性和在探索和利用之間取得平衡方面仍然存在差距，這是大型啟發式搜尋空間中的關鍵因素。在本研究中，我們透過提出兩個多樣性測量指標來解決這個差距，並對先前的 LLM-EPS 方法進行分析，包括 FunSearch、EoH 和 ReEvo。黑箱 AHD 問題的結果顯示，雖然 EoH 展現出比 FunSearch 和 ReEvo 更高的多樣性，但其目標分數不穩定。相反地，ReEvo 的反射機制產生了良好的目標分數，但未能有效最佳化多樣性。有了這個發現，我們引入了 HSEvo，一個自適應 LLM-EPS 框架，透過和諧搜尋演算法在多樣性和收斂之間取得平衡。透過實驗，我們發現 HSEvo 達到了高多樣性指標和良好的目標分數，同時仍然具有成本效益。這些結果強調了在設計 LLM-EPS 中的框架時，平衡探索和利用以及理解啟發式搜尋空間的重要性。

##### **Chain-of-MetaWriting: Linguistic and Textual Analysis of How Small Language Models Write Young Students Texts**
2412.14986v1 by Ioana Buhnila, Georgeta Cislaru, Amalia Todirascu

Large Language Models (LLMs) have been used to generate texts in response to
different writing tasks: reports, essays, story telling. However, language
models do not have a meta-representation of the text writing process, nor
inherent communication learning needs, comparable to those of young human
students. This paper introduces a fine-grained linguistic and textual analysis
of multilingual Small Language Models' (SLMs) writing. With our method,
Chain-of-MetaWriting, SLMs can imitate some steps of the human writing process,
such as planning and evaluation. We mainly focused on short story and essay
writing tasks in French for schoolchildren and undergraduate students
respectively. Our results show that SLMs encounter difficulties in assisting
young students on sensitive topics such as violence in the schoolyard, and they
sometimes use words too complex for the target audience. In particular, the
output is quite different from the human produced texts in term of text
cohesion and coherence regarding temporal connectors, topic progression,
reference.

摘要：大型語言模型 (LLM) 已用於產生文字以回應不同的寫作任務：報告、論文、故事敘述。然而，語言模型沒有文字寫作過程的元表示，也沒有與年輕人類學生相當的內在溝通學習需求。本文介紹了多語言小型語言模型 (SLM) 寫作的細緻語言和文本分析。透過我們的方法，元寫作鏈，SLM 可以模仿人類寫作過程的某些步驟，例如規劃和評估。我們主要專注於法語的短篇故事和論文寫作任務，分別針對學童和大學生。我們的結果顯示，SLM 在協助年輕學生處理敏感主題（例如校園暴力）時遇到困難，而且有時會使用對目標受眾來說過於複雜的詞彙。特別是，在文本連貫性和關於時間連接詞、主題進展、引用的相干性方面，輸出與人類產生的文本有很大不同。

##### **Movie2Story: A framework for understanding videos and telling stories in the form of novel text**
2412.14965v1 by Kangning Li, Zheyang Jia, Anyu Ying

Multimodal video-to-text models have made considerable progress, primarily in
generating brief descriptions of video content. However, there is still a
deficiency in generating rich long-form text descriptions that integrate both
video and audio. In this paper, we introduce a framework called M2S, designed
to generate novel-length text by combining audio, video, and character
recognition. M2S includes modules for video long-form text description and
comprehension, audio-based analysis of emotion, speech rate, and character
alignment, and visual-based character recognition alignment. By integrating
multimodal information using the large language model GPT4o, M2S stands out in
the field of multimodal text generation. We demonstrate the effectiveness and
accuracy of M2S through comparative experiments and human evaluation.
Additionally, the model framework has good scalability and significant
potential for future research.

摘要：多模態影片轉文字模型已取得顯著進展，主要在於產生影片內容的簡短描述。然而，在產生整合視訊和音訊的豐富長篇文字描述方面，仍有不足之處。在本文中，我們介紹了一個名為 M2S 的架構，旨在透過結合音訊、視訊和角色識別來產生小說長度的文字。M2S 包含視訊長篇文字描述和理解、基於音訊的情緒分析、語速和角色對齊，以及基於視覺的角色識別對齊等模組。透過使用大型語言模型 GPT4o 整合多模態資訊，M2S 在多模態文字產生的領域中脫穎而出。我們透過比較實驗和人工評估，證明了 M2S 的有效性和準確性。此外，該模型架構具有良好的可擴充性，並對未來的研究具有顯著的潛力。

##### **Knowledge Injection via Prompt Distillation**
2412.14964v1 by Kalle Kujanpää, Harri Valpola, Alexander Ilin

In many practical applications, large language models (LLMs) need to
incorporate new knowledge not present in their pre-training data. The primary
methods for this are fine-tuning and retrieval-augmented generation (RAG).
Although RAG has emerged as the industry standard for knowledge injection,
fine-tuning has not yet achieved comparable success. In this paper, we propose
a new fine-tuning technique for learning new knowledge and show that it can
reach the performance of RAG. The proposed method is based on the
self-distillation approach, which we call prompt distillation. First, we
generate question-answer pairs about the new knowledge. Then, we fine-tune a
student model on the question-answer pairs to imitate the output distributions
of a teacher model, which additionally receives the new knowledge in its
prompt. The student model is identical to the teacher, except it is equipped
with a LoRA adapter. This training procedure facilitates distilling the new
knowledge from the teacher's prompt into the student's weights.

摘要：在許多實務應用中，大型語言模型 (LLM) 需要整合預訓練資料中沒有的新知識。主要方法是微調和檢索增強產生 (RAG)。儘管 RAG 已成為知識注入的產業標準，但微調尚未獲得可比較的成功。在本文中，我們提出了一種新的微調技術，用於學習新知識，並展示它可以達到 RAG 的效能。所提出的方法基於自蒸餾方法，我們稱之為提示蒸餾。首先，我們產生有關新知識的問題解答對。然後，我們微調一個學生模型，在問題解答對上模仿教師模型的輸出分佈，而教師模型在提示中另外接收新知識。學生模型與教師模型相同，除了它配備了 LoRA 適配器。此訓練程序有助於將教師提示中的新知識蒸餾到學生的權重中。

##### **Understanding the Dark Side of LLMs' Intrinsic Self-Correction**
2412.14959v1 by Qingjie Zhang, Han Qiu, Di Wang, Haoting Qian, Yiming Li, Tianwei Zhang, Minlie Huang

Intrinsic self-correction was proposed to improve LLMs' responses via
feedback prompts solely based on their inherent capability. However, recent
works show that LLMs' intrinsic self-correction fails without oracle labels as
feedback prompts. In this paper, we aim to interpret LLMs' intrinsic
self-correction for different tasks, especially for those failure cases. By
including one simple task and three complex tasks with state-of-the-art (SOTA)
LLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B,
and 3.1-8B), we design three interpretation methods to reveal the dark side of
LLMs' intrinsic self-correction. We identify intrinsic self-correction can (1)
cause LLMs to waver both intermedia and final answers and lead to prompt bias
on simple factual questions; (2) introduce human-like cognitive bias on complex
tasks. In light of our findings, we also provide two simple yet effective
strategies for alleviation: question repeating and supervised fine-tuning with
a few samples. We open-source our work at https://x-isc.info/.

摘要：內在自我修正被提出來透過回饋提示來改善 LLM 的回應，這些提示僅基於其固有能力。然而，最近的研究顯示，LLM 的內在自我修正會在沒有神諭標籤作為回饋提示的情況下失敗。在本文中，我們旨在解釋 LLM 的內在自我修正對於不同任務，特別是那些失敗案例。透過包含一個簡單任務和三個複雜任務，使用最先進 (SOTA) 的 LLM，例如 ChatGPT 家族 (o1、4o、3.5-turbo) 和 Llama 家族 (2-7B、3-8B 和 3.1-8B)，我們設計了三種解釋方法來揭示 LLM 內在自我修正的黑暗面。我們發現內在自我修正可能 (1) 導致 LLM 在中間答案和最終答案之間搖擺不定，並導致簡單事實問題的提示偏差；(2) 在複雜任務中引入類似人類的認知偏差。根據我們的發現，我們還提供了兩種簡單但有效的緩解策略：問題重複和使用少數樣本進行監督微調。我們在 https://x-isc.info/ 上開放我們的原始碼。

##### **Generalizing Constraint Models in Constraint Acquisition**
2412.14950v1 by Dimos Tsouros, Senne Berden, Steven Prestwich, Tias Guns

Constraint Acquisition (CA) aims to widen the use of constraint programming
by assisting users in the modeling process. However, most CA methods suffer
from a significant drawback: they learn a single set of individual constraints
for a specific problem instance, but cannot generalize these constraints to the
parameterized constraint specifications of the problem. In this paper, we
address this limitation by proposing GenCon, a novel approach to learn
parameterized constraint models capable of modeling varying instances of the
same problem. To achieve this generalization, we make use of statistical
learning techniques at the level of individual constraints. Specifically, we
propose to train a classifier to predict, for any possible constraint and
parameterization, whether the constraint belongs to the problem. We then show
how, for some classes of classifiers, we can extract decision rules to
construct interpretable constraint specifications. This enables the generation
of ground constraints for any parameter instantiation. Additionally, we present
a generate-and-test approach that can be used with any classifier, to generate
the ground constraints on the fly. Our empirical results demonstrate that our
approach achieves high accuracy and is robust to noise in the input instances.

摘要：約束取得 (CA) 的目的是透過協助使用者進行建模流程，擴大約束程式設計的使用。然而，大多數 CA 方法都有個重大的缺點：它們會為特定問題實例學習一組單獨的約束，但無法將這些約束概括為問題的參數化約束規範。在本文中，我們透過提出 GenCon 來解決這個限制，這是一種新穎的方法，用於學習參數化約束模型，能夠建模相同問題的不同實例。為了達成這個概括，我們在個別約束的層級上使用統計學習技術。具體來說，我們建議訓練分類器來預測任何可能的約束和參數化，該約束是否屬於問題。然後，我們展示對於某些類別的分類器，我們可以提取決策規則來建構可詮釋的約束規範。這使得能夠為任何參數實例產生基礎約束。此外，我們提出一個生成和測試方法，可以用於任何分類器，以即時產生基礎約束。我們的經驗結果證明，我們的做法能達成高準確度，且對於輸入實例中的雜訊具有穩健性。

##### **RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**
2412.14922v1 by Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang

Supervised fine-tuning (SFT) plays a crucial role in adapting large language
models (LLMs) to specific domains or tasks. However, as demonstrated by
empirical experiments, the collected data inevitably contains noise in
practical applications, which poses significant challenges to model performance
on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT
framework to enhance model capabilities in downstream tasks. To address this
challenge, we introduce a robust SFT framework (RobustFT) that performs noise
detection and relabeling on downstream task data. For noise identification, our
approach employs a multi-expert collaborative system with inference-enhanced
models to achieve superior noise detection. In the denoising phase, we utilize
a context-enhanced strategy, which incorporates the most relevant and confident
knowledge followed by careful assessment to generate reliable annotations.
Additionally, we introduce an effective data selection mechanism based on
response entropy, ensuring only high-quality samples are retained for
fine-tuning. Extensive experiments conducted on multiple LLMs across five
datasets demonstrate RobustFT's exceptional performance in noisy scenarios.

摘要：監督式微調（SFT）在將大型語言模型（LLM）適應到特定領域或任務中扮演著至關重要的角色。然而，正如經驗實驗所證明，在實際應用中收集到的資料不可避免地包含雜訊，這對下游任務的模型效能構成了重大挑戰。因此，迫切需要一個抗雜訊的 SFT 框架，以增強模型在下游任務中的能力。為了應對這一挑戰，我們引入了穩健的 SFT 框架（RobustFT），它對下游任務資料執行雜訊偵測和重新標記。對於雜訊識別，我們的方法採用多專家協作系統，並使用增強推論的模型來實現優異的雜訊偵測。在去雜訊階段，我們利用一種情境增強策略，它結合了最相關和最確信的知識，然後進行仔細評估以產生可靠的註解。此外，我們還引入了一種基於回應熵的有效資料選取機制，確保僅保留高品質的樣本進行微調。在五個資料集上對多個 LLM 進行的廣泛實驗證明了 RobustFT 在雜訊情境中的出色效能。

##### **Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation**
2412.14905v1 by Zexiong Ma, Shengnan An, Zeqi Lin, Yanzhen Zou, Jian-Guang Lou, Bing Xie

Large language models (LLMs) are susceptible to generating hallucinated
information, despite the integration of retrieval-augmented generation (RAG).
Parallel context extension (PCE) is a line of research attempting to
effectively integrating parallel (unordered) contexts, while it still suffers
from hallucinations when adapted to RAG scenarios. In this paper, we propose
DePaC (Dehallucinating Parallel Context Extension), which alleviates the
hallucination problem with context-aware negative training and
information-calibrated aggregation. DePaC is designed to alleviate two types of
in-context hallucination: fact fabrication (i.e., LLMs present claims that are
not supported by the contexts) and fact omission (i.e., LLMs fail to present
claims that can be supported by the contexts). Specifically, (1) for fact
fabrication, we apply the context-aware negative training that fine-tunes the
LLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to
answer when contexts are not related to questions; (2) for fact omission, we
propose the information-calibrated aggregation which prioritizes context
windows with higher information increment from their contexts. The experimental
results on nine RAG tasks demonstrate that DePaC significantly alleviates the
two types of hallucination and consistently achieves better performances on
these tasks.

摘要：大型语言模型 (LLM) 容易产生幻觉信息，尽管集成了检索增强生成 (RAG)。
平行上下文扩展 (PCE) 是一条尝试有效集成平行（无序）上下文的的研究线，但当它适应 RAG 场景时，它仍然会产生幻觉。在本文中，我们提出了 DePaC（去幻觉平行上下文扩展），它通过上下文感知的负训练和信息校准聚合来缓解幻觉问题。DePaC 旨在缓解两种类型的上下文幻觉：事实捏造（即，LLM 提出不受上下文支持的主张）和事实遗漏（即，LLM 无法提出可以由上下文支持的主张）。具体来说，（1）对于事实捏造，我们应用了上下文感知的负训练，该训练使用负监督对 LLM 进行微调，从而明确指导 LLM 在上下文与问题无关时拒绝回答；（2）对于事实遗漏，我们提出了信息校准聚合，该聚合优先考虑从其上下文中具有较高信息增量的上下文窗口。在九个 RAG 任务上的实验结果表明，DePaC 显着缓解了这两种类型的幻觉，并在这些任务上持续取得了更好的性能。

##### **Why language models collapse when trained on recursively generated text**
2412.14872v1 by Lecheng Wang, Xianjie Shi, Ge Li, Jia Li, Yihong Dong, Xuanming Zhang, Wenpin Jiao, Hong Mei

Language models (LMs) have been widely used to generate text on the Internet.
The generated text is often collected into the training corpus of the next
generations of LMs. Previous work has experimentally found that LMs collapse
when trained on recursively generated text. This paper contributes to existing
knowledge from two aspects. We present a theoretical proof of LM collapse. Our
proof reveals the cause of LM collapse and proves that all auto-regressive LMs
will definitely collapse. We present a new finding: the performance of LMs
gradually declines when trained on recursively generated text until they
perform no better than a randomly initialized LM. The trained LMs produce large
amounts of repetitive text and perform poorly across a wide range of natural
language tasks. The above proof and new findings deepen our understanding of LM
collapse and offer valuable insights that may inspire new training techniques
to mitigate this threat.

摘要：語言模型 (LM) 已廣泛用於在網際網路上產生文字。
產生的文字通常會收集到下世代 LM 的訓練語料庫中。先前的研究已透過實驗發現，當 LM 在遞迴產生的文字上訓練時會崩潰。本文從兩個面向探討現有知識。我們提出 LM 崩潰的理論證明。我們的證明揭露了 LM 崩潰的原因，並證明所有自迴歸 LM 肯定會崩潰。我們提出一個新發現：在遞迴產生的文字上訓練時，LM 的效能會逐漸下降，直到其效能表現不比隨機初始化的 LM 為止。訓練後的 LM 會產生大量的重複文字，並且在各種自然語言任務中的表現都很差。上述證明和新發現加深了我們對 LM 崩潰的了解，並提供了寶貴的見解，可能激勵新的訓練技術來減輕這個威脅。

##### **AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening**
2412.14869v1 by Mehdi Hosseini Chagahi, Md. Jalil Piran, Niloufar Delfan, Behzad Moshiri, Jaber Hatam Parikhan

Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood
within the skull, which occurs due to the rupture of blood vessels in or around
the brain. If this condition is not diagnosed in a timely manner and
appropriately treated, it can lead to serious complications such as decreased
consciousness, permanent neurological disabilities, or even death.The primary
aim of this study is to detect the occurrence or non-occurrence of ICH,
followed by determining the type of subdural hemorrhage (SDH). These tasks are
framed as two separate binary classification problems. By adding two layers to
the co-scale convolutional attention (CCA) classifier architecture, we
introduce a novel approach for ICH detection. In the first layer, after
extracting features from different slices of computed tomography (CT) scan
images, we combine these features and select the 50 components that capture the
highest variance in the data, considering them as informative features. We then
assess the discriminative power of these features using the bootstrap forest
algorithm, discarding those that lack sufficient discriminative ability between
different classes. This algorithm explicitly determines the contribution of
each feature to the final prediction, assisting us in developing an explainable
AI model. The features feed into a boosting neural network as a latent feature
space. In the second layer, we introduce a novel uncertainty-based fuzzy
integral operator to fuse information from different CT scan slices. This
operator, by accounting for the dependencies between consecutive slices,
significantly improves detection accuracy.

摘要：顱內出血 (ICH) 是指顱骨內血液滲漏或積聚，這是由於腦部或腦部周圍的血管破裂所致。如果這種情況未能及時診斷並適當治療，可能會導致嚴重的併發症，例如意識下降、永久性神經功能障礙，甚至死亡。本研究的主要目的是檢測 ICH 的發生或未發生，然後確定硬腦膜下出血 (SDH) 的類型。這些任務被設定為兩個獨立的二元分類問題。透過在同尺度卷積注意力 (CCA) 分類器架構中新增兩層，我們提出了一種用於 ICH 檢測的新方法。在第一層中，從電腦斷層攝影 (CT) 掃描影像的不同切片中萃取特徵後，我們會結合這些特徵並選取 50 個在資料中擷取最高變異數的組成部分，將它們視為有意義的特徵。然後，我們使用 bootstrap forest 演算法評估這些特徵的判別力，並捨棄在不同類別之間缺乏足夠判別能力的特徵。此演算法會明確地確定每個特徵對最終預測的貢獻，協助我們開發可解釋的 AI 模型。這些特徵會作為潛在特徵空間提供給提升神經網路。在第二層中，我們引入了一種新的基於不確定性的模糊積分算子，以融合來自不同 CT 掃描切片的資訊。此算子透過考量連續切片之間的依賴性，大幅提升了檢測準確度。

##### **Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**
2412.14867v1 by Imed Keraghel, Mohamed Nadif

Recent advances in machine learning, particularly Large Language Models
(LLMs) such as BERT and GPT, provide rich contextual embeddings that improve
text representation. However, current document clustering approaches often
ignore the deeper relationships between named entities (NEs) and the potential
of LLM embeddings. This paper proposes a novel approach that integrates Named
Entity Recognition (NER) and LLM embeddings within a graph-based framework for
document clustering. The method builds a graph with nodes representing
documents and edges weighted by named entity similarity, optimized using a
graph-convolutional network (GCN). This ensures a more effective grouping of
semantically related documents. Experimental results indicate that our approach
outperforms conventional co-occurrence-based methods in clustering, notably for
documents rich in named entities.

摘要：近期機器學習的進展，特別是大型語言模型 (LLM)，例如 BERT 和 GPT，提供了豐富的上下文嵌入，改進了文本表徵。然而，當前的文件分群方法通常忽略命名實體 (NE) 之間更深層的關係和 LLM 嵌入的潛力。本文提出了一種創新的方法，將命名實體辨識 (NER) 和 LLM 嵌入整合到基於圖形的架構中，以進行文件分群。該方法建立了一個圖形，其中節點代表文件，邊緣則由命名實體相似性加權，並使用圖形卷積網路 (GCN) 進行最佳化。這確保了語義相關文件更有效的分組。實驗結果表明，我們的做法優於傳統的共現方法在分群中的表現，特別是對於富含命名實體的文件。

##### **Think&Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling**
2412.14860v1 by Junyi Li, Hwee Tou Ng

Despite their outstanding capabilities, large language models (LLMs) are
prone to hallucination and producing factually incorrect information. This
challenge has spurred efforts in attributed text generation, which prompts LLMs
to generate content with supporting evidence. In this paper, we propose a novel
framework, called Think&Cite, and formulate attributed text generation as a
multi-step reasoning problem integrated with search. Specifically, we propose
Self-Guided Monte Carlo Tree Search (SG-MCTS), which capitalizes on the
self-reflection capability of LLMs to reflect on the intermediate states of
MCTS for guiding the tree expansion process. To provide reliable and
comprehensive feedback, we introduce Progress Reward Models to measure the
progress of tree search from the root to the current state from two aspects,
i.e., generation and attribution progress. We conduct extensive experiments on
three datasets and the results show that our approach significantly outperforms
baseline approaches.

摘要：儘管大型語言模型 (LLM) 具有傑出的能力，但它們容易出現幻覺並產生事實上不正確的資訊。這個挑戰促使我們致力於歸因文字生成，這會提示 LLM 產生具有佐證證據的內容。在本文中，我們提出一個稱為 Think&Cite 的新架構，並將歸因文字生成表述為一個整合搜尋的多步驟推理問題。具體來說，我們提出自導蒙地卡羅樹狀搜尋 (SG-MCTS)，它利用 LLM 的自我反省能力來反省 MCTS 的中間狀態，以引導樹狀擴充程序。為了提供可靠且全面的回饋，我們引入進度獎勵模型來衡量樹狀搜尋從根節點到目前狀態的進度，從兩個方面著手，即生成進度和歸因進度。我們在三個資料集上進行廣泛的實驗，結果顯示我們的做法顯著優於基準做法。

##### **DS$^2$-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis**
2412.14849v1 by Hongling Xu, Yice Zhang, Qianlong Wang, Ruifeng Xu

Recently developed large language models (LLMs) have presented promising new
avenues to address data scarcity in low-resource scenarios. In few-shot
aspect-based sentiment analysis (ABSA), previous efforts have explored data
augmentation techniques, which prompt LLMs to generate new samples by modifying
existing ones. However, these methods fail to produce adequately diverse data,
impairing their effectiveness. Besides, some studies apply in-context learning
for ABSA by using specific instructions and a few selected examples as prompts.
Though promising, LLMs often yield labels that deviate from task requirements.
To overcome these limitations, we propose DS$^2$-ABSA, a dual-stream data
synthesis framework targeted for few-shot ABSA. It leverages LLMs to synthesize
data from two complementary perspectives: \textit{key-point-driven} and
\textit{instance-driven}, which effectively generate diverse and high-quality
ABSA samples in low-resource settings. Furthermore, a \textit{label refinement}
module is integrated to improve the synthetic labels. Extensive experiments
demonstrate that DS$^2$-ABSA significantly outperforms previous few-shot ABSA
solutions and other LLM-oriented data generation methods.

摘要：最近開發的大型語言模型 (LLM) 提出了一個有前途的新途徑來解決低資源場景中的資料稀少性。在小樣本方面觀點基礎情緒分析 (ABSA) 中，先前的努力已經探索了資料擴充技術，它提示 LLM 藉由修改現有樣本來產生新樣本。然而，這些方法無法產生足夠多樣化的資料，損害其有效性。此外，一些研究使用特定說明和一些選定的範例作為提示，來應用情境學習於 ABSA。儘管有前途，LLM 經常產生偏離任務需求的標籤。為了克服這些限制，我們提出 DS$^2$-ABSA，一個針對小樣本 ABSA 的雙流資料合成架構。它利用 LLM 從兩個互補的觀點來合成資料：\textit{關鍵點驅動} 和 \textit{實例驅動}，這在低資源設定中有效地產生多樣化且高品質的 ABSA 樣本。此外，整合了一個 \textit{標籤精緻化} 模組來改善合成標籤。廣泛的實驗證明，DS$^2$-ABSA 明顯優於先前的幾個小樣本 ABSA 解決方案和其他以 LLM 為導向的資料產生方法。

##### **A Survey of RWKV**
2412.14847v1 by Zhiyuan Li, Tingyu Xia, Yi Chang, Yuan Wu

The Receptance Weighted Key Value (RWKV) model offers a novel alternative to
the Transformer architecture, merging the benefits of recurrent and
attention-based systems. Unlike conventional Transformers, which depend heavily
on self-attention, RWKV adeptly captures long-range dependencies with minimal
computational demands. By utilizing a recurrent framework, RWKV addresses some
computational inefficiencies found in Transformers, particularly in tasks with
long sequences. RWKV has recently drawn considerable attention for its robust
performance across multiple domains. Despite its growing popularity, no
systematic review of the RWKV model exists. This paper seeks to fill this gap
as the first comprehensive review of the RWKV architecture, its core
principles, and its varied applications, such as natural language generation,
natural language understanding, and computer vision. We assess how RWKV
compares to traditional Transformer models, highlighting its capability to
manage long sequences efficiently and lower computational costs. Furthermore,
we explore the challenges RWKV encounters and propose potential directions for
future research and advancement. We consistently maintain the related
open-source materials at: https://github.com/MLGroupJLU/RWKV-Survey.

摘要：可接收加權關鍵值 (RWKV) 模型提供了一個新穎的替代方案來轉換架構，合併了遞迴和基於注意力的系統的優點。與高度依賴自我注意力的傳統轉換器不同，RWKV 能夠以最小的運算需求靈活地捕捉長距離依賴性。通過利用遞迴架構，RWKV 解決了在轉換器中發現的一些運算低效率，特別是在具有長序列的任務中。RWKV 最近因其在多個領域的強大效能而備受關注。儘管其受歡迎程度日益提高，但 RWKV 模型並未進行系統性回顧。本文旨在填補這一空白，作為 RWKV 架構、其核心原理及其各種應用（例如自然語言生成、自然語言理解和電腦視覺）的第一個全面回顧。我們評估 RWKV 如何與傳統轉換器模型進行比較，強調其有效管理長序列和降低運算成本的能力。此外，我們探討了 RWKV 遇見的挑戰，並提出了未來研究和進展的潛在方向。我們持續在以下位置維護相關的開源材料：https://github.com/MLGroupJLU/RWKV-Survey。

##### **Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet**
2412.14846v1 by Litingyu Wang, Wenjun Liao, Shichuan Zhang, Guotai Wang

Head and neck tumors and metastatic lymph nodes are crucial for treatment
planning and prognostic analysis. Accurate segmentation and quantitative
analysis of these structures require pixel-level annotation, making automated
segmentation techniques essential for the diagnosis and treatment of head and
neck cancer. In this study, we investigated the effects of multiple strategies
on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT)
images. For the segmentation of pre-RT images, we utilized: 1) a fully
supervised learning approach, and 2) the same approach enhanced with
pre-trained weights and the MixUp data augmentation technique. For mid-RT
images, we introduced a novel computational-friendly network architecture that
features separate encoders for mid-RT images and registered pre-RT images with
their labels. The mid-RT encoder branch integrates information from pre-RT
images and labels progressively during the forward propagation. We selected the
highest-performing model from each fold and used their predictions to create an
ensemble average for inference. In the final test, our models achieved a
segmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on
aggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at
https://github.com/WltyBY/HNTS-MRG2024_train_code.

摘要：頭頸部腫瘤和轉移淋巴結對於治療計畫和預後分析至關重要。這些結構的準確分割和定量分析需要像素級註解，使自動分割技術對於頭頸癌的診斷和治療至關重要。在本研究中，我們探討了多種策略對放射治療前 (pre-RT) 和放射治療中期 (mid-RT) 影像分割的影響。對於放射治療前影像的分割，我們利用：1）完全監督式學習方法，以及 2）使用預訓練權重和 MixUp 資料擴充技術增強的相同方法。對於放射治療中期影像，我們引入了一個新穎的計算友好型網路架構，其特點是為放射治療中期影像和註冊的放射治療前影像及其標籤提供了單獨的編碼器。放射治療中期編碼器分支在正向傳播過程中逐步整合來自放射治療前影像和標籤的資訊。我們從每個區塊中選出效能最高的模型，並使用其預測值建立一個集合平均值以進行推論。在最後的測試中，我們的模型在 HiLab 上的預測表現對於放射治療前影像為 82.38%，對於放射治療中期影像為 72.53%，以聚合的 Dice 相似性係數 (DSC) 為準。我們的程式碼可以在 https://github.com/WltyBY/HNTS-MRG2024_train_code 取得。

##### **Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas**
2412.14843v1 by Pietro Bernardelle, Leon Fröhling, Stefano Civelli, Riccardo Lunardi, Kevin Roiter, Gianluca Demartini

The analysis of political biases in large language models (LLMs) has
primarily examined these systems as single entities with fixed viewpoints.
While various methods exist for measuring such biases, the impact of
persona-based prompting on LLMs' political orientation remains unexplored. In
this work we leverage PersonaHub, a collection of synthetic persona
descriptions, to map the political distribution of persona-based prompted LLMs
using the Political Compass Test (PCT). We then examine whether these initial
compass distributions can be manipulated through explicit ideological prompting
towards diametrically opposed political orientations: right-authoritarian and
left-libertarian. Our experiments reveal that synthetic personas predominantly
cluster in the left-libertarian quadrant, with models demonstrating varying
degrees of responsiveness when prompted with explicit ideological descriptors.
While all models demonstrate significant shifts towards right-authoritarian
positions, they exhibit more limited shifts towards left-libertarian positions,
suggesting an asymmetric response to ideological manipulation that may reflect
inherent biases in model training.

摘要：政治偏誤在大型語言模型 (LLM) 中的分析，主要將這些系統視為具有固定觀點的單一實體。雖然存在各種測量此類偏誤的方法，但基於角色的提示對 LLM 的政治傾向的影響仍未得到探討。在這項工作中，我們利用 PersonaHub（一個合成角色描述的集合）來繪製基於角色提示的 LLM 的政治分佈，使用政治羅盤測試 (PCT)。然後，我們探討是否可以透過明確的意識形態提示來操縱這些初始羅盤分佈，朝向截然相反的政治傾向：右翼威權主義和左翼自由主義。我們的實驗表明，合成角色主要聚集在左翼自由主義象限，而模型在使用明確的意識形態描述符提示時表現出不同程度的反應能力。雖然所有模型都表現出顯著的向右翼威權主義立場的轉變，但它們向左翼自由主義立場的轉變較為有限，這表明對意識形態操縱的不對稱反應可能反映了模型訓練中的固有偏誤。

##### **Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis**
2412.14841v1 by Greta Dolcetti, Vincenzo Arceri, Eleonora Iotti, Sergio Maffeis, Agostino Cortesi, Enea Zaffanella

Large Language Models (LLMs) are one of the most promising developments in
the field of artificial intelligence, and the software engineering community
has readily noticed their potential role in the software development
life-cycle. Developers routinely ask LLMs to generate code snippets, increasing
productivity but also potentially introducing ownership, privacy, correctness,
and security issues. Previous work highlighted how code generated by mainstream
commercial LLMs is often not safe, containing vulnerabilities, bugs, and code
smells. In this paper, we present a framework that leverages testing and static
analysis to assess the quality, and guide the self-improvement, of code
generated by general-purpose, open-source LLMs.
  First, we ask LLMs to generate C code to solve a number of programming tasks.
Then we employ ground-truth tests to assess the (in)correctness of the
generated code, and a static analysis tool to detect potential safety
vulnerabilities. Next, we assess the models ability to evaluate the generated
code, by asking them to detect errors and vulnerabilities. Finally, we test the
models ability to fix the generated code, providing the reports produced during
the static analysis and incorrectness evaluation phases as feedback.
  Our results show that models often produce incorrect code, and that the
generated code can include safety issues. Moreover, they perform very poorly at
detecting either issue. On the positive side, we observe a substantial ability
to fix flawed code when provided with information about failed tests or
potential vulnerabilities, indicating a promising avenue for improving the
safety of LLM-based code generation tools.

摘要：大型語言模型 (LLM) 是人工智能領域中最有前途的發展之一，軟體工程社群也迅速注意到它們在軟體開發生命週期中的潛在角色。開發人員例行公事地要求 LLM 產生程式碼片段，這提高了生產力，但也可能引發所有權、隱私、正確性和安全性問題。先前的研究強調，主流商業 LLM 產生的程式碼通常不安全，包含漏洞、錯誤和程式碼問題。在本文中，我們提出了一個框架，利用測試和靜態分析來評估品質，並指導由通用開源 LLM 產生的程式碼自我改善。
首先，我們要求 LLM 產生 C 程式碼來解決許多程式設計任務。然後，我們採用基本事實測試來評估產生的程式碼的（不）正確性，並使用靜態分析工具來偵測潛在的安全漏洞。接下來，我們評估模型評估產生的程式碼的能力，方法是要求它們偵測錯誤和漏洞。最後，我們測試模型修正產生的程式碼的能力，提供在靜態分析和不正確性評估階段產生的報告作為回饋。
我們的結果顯示，模型通常會產生不正確的程式碼，而且產生的程式碼可能包含安全問題。此外，它們在偵測這兩個問題方面的表現非常差。在正面方面，我們觀察到在提供有關失敗測試或潛在漏洞的資訊時，它們具有修正有缺陷程式碼的顯著能力，這表示改善基於 LLM 的程式碼產生工具的安全性是一個有前途的途徑。

##### **DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs**
2412.14838v1 by Xiabin Zhou, Wenbin Wang, Minyan Zeng, Jiaxian Guo, Xuebo Liu, Li Shen, Min Zhang, Liang Ding

Efficient KV cache management in LLMs is crucial for long-context tasks like
RAG and summarization. Existing KV cache compression methods enforce a fixed
pattern, neglecting task-specific characteristics and reducing the retention of
essential information. However, we observe distinct activation patterns across
layers in various tasks, highlighting the need for adaptive strategies tailored
to each task's unique demands. Based on this insight, we propose DynamicKV, a
method that dynamically optimizes token retention by adjusting the number of
tokens retained at each layer to adapt to the specific task. DynamicKV
establishes global and per-layer maximum KV cache budgets, temporarily
retaining the maximum budget for the current layer, and periodically updating
the KV cache sizes of all preceding layers during inference. Our method retains
only 1.7% of the KV cache size while achieving ~85% of the Full KV cache
performance on LongBench. Notably, even under extreme compression (0.9%),
DynamicKV surpasses state-of-the-art (SOTA) methods by 11% in the
Needle-in-a-Haystack test using Mistral-7B-Instruct-v0.2. The code will be
released.

摘要：在 LLMs 中進行高效的 KV 快取管理對於 RAG 和摘要等長背景任務至關重要。現有的 KV 快取壓縮方法強制執行一個固定的模式，忽略特定任務的特徵並減少保留重要資訊。然而，我們觀察到不同任務中的各個層級間有不同的啟動模式，這突顯了需要針對每個任務的獨特需求量身打造自適應策略。基於此見解，我們提出了 DynamicKV，這是一種透過調整每個層級保留的代數量來動態最佳化代保留的方法，以適應特定任務。DynamicKV 建立了全域和每個層級的最大 KV 快取預算，暫時保留當前層級的最大預算，並在推論期間定期更新所有前置層級的 KV 快取大小。我們的這個方法僅保留 1.7% 的 KV 快取大小，同時在 LongBench 上達到了約 85% 的完整 KV 快取效能。值得注意的是，即使在極端壓縮 (0.9%) 下，DynamicKV 在使用 Mistral-7B-Instruct-v0.2 的大海撈針測試中也比最先進 (SOTA) 的方法高出 11%。程式碼將會釋出。

##### **Progressive Multimodal Reasoning via Active Retrieval**
2412.14835v1 by Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen

Multi-step multimodal reasoning tasks pose significant challenges for
multimodal large language models (MLLMs), and finding effective ways to enhance
their performance in such scenarios remains an unresolved issue. In this paper,
we propose AR-MCTS, a universal framework designed to progressively improve the
reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo
Tree Search (MCTS). Our approach begins with the development of a unified
retrieval module that retrieves key supporting insights for solving complex
reasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in
automated multimodal reasoning verification, we employ the MCTS algorithm
combined with an active retrieval mechanism, which enables the automatic
generation of step-wise annotations. This strategy dynamically retrieves key
insights for each reasoning step, moving beyond traditional beam search
sampling to improve the diversity and reliability of the reasoning space.
Additionally, we introduce a process reward model that aligns progressively to
support the automatic verification of multimodal reasoning tasks. Experimental
results across three complex multimodal reasoning benchmarks confirm the
effectiveness of the AR-MCTS framework in enhancing the performance of various
multimodal models. Further analysis demonstrates that AR-MCTS can optimize
sampling diversity and accuracy, yielding reliable multimodal reasoning.

摘要：多步驟多模態推理任務對多模態大型語言模型 (MLLM) 構成重大挑戰，而尋找有效方法來提升它們在這種情況下的效能仍然是一個未解決的問題。在本文中，我們提出 AR-MCTS，一個通用框架，旨在透過主動檢索 (AR) 和蒙地卡羅樹狀搜尋 (MCTS) 逐步提升 MLLM 的推理能力。我們的做法從開發一個統一的檢索模組開始，該模組從混合模式檢索語料庫中檢索解決複雜推理問題的主要支持見解。為了彌合自動化多模態推理驗證的差距，我們採用 MCTS 演算法結合主動檢索機制，這使得能夠自動產生逐步註解。此策略動態檢索每個推理步驟的主要見解，超越傳統的波束搜尋取樣，以提升推理空間的多樣性和可靠性。此外，我們引入一個過程回饋模型，逐步調整以支援多模態推理任務的自動驗證。在三個複雜的多模態推理基準上的實驗結果證實了 AR-MCTS 框架在提升各種多模態模型效能方面的有效性。進一步的分析證明 AR-MCTS 能夠最佳化取樣多樣性和準確度，產生可靠的多模態推理。

##### **Mention Attention for Pronoun Translation**
2412.14829v1 by Gongbo Tang, Christian Hardmeier

Most pronouns are referring expressions, computers need to resolve what do
the pronouns refer to, and there are divergences on pronoun usage across
languages. Thus, dealing with these divergences and translating pronouns is a
challenge in machine translation. Mentions are referring candidates of pronouns
and have closer relations with pronouns compared to general tokens. We assume
that extracting additional mention features can help pronoun translation.
Therefore, we introduce an additional mention attention module in the decoder
to pay extra attention to source mentions but not non-mention tokens. Our
mention attention module not only extracts features from source mentions, but
also considers target-side context which benefits pronoun translation. In
addition, we also introduce two mention classifiers to train models to
recognize mentions, whose outputs guide the mention attention. We conduct
experiments on the WMT17 English-German translation task, and evaluate our
models on general translation and pronoun translation, using BLEU, APT, and
contrastive evaluation metrics. Our proposed model outperforms the baseline
Transformer model in terms of APT and BLEU scores, this confirms our hypothesis
that we can improve pronoun translation by paying additional attention to
source mentions, and shows that our introduced additional modules do not have
negative effect on the general translation quality.

摘要：大部分代名詞都是指涉表達，電腦需要解析代名詞所指涉的內容，而不同語言在代名詞的使用上存在差異。因此，處理這些差異並翻譯代名詞是機器翻譯中的一項挑戰。提及是代名詞的指涉候選，與一般符號相比，與代名詞有更緊密的關係。我們假設萃取額外的提及特徵有助於代名詞翻譯。因此，我們在解碼器中引入一個額外的提及注意力模組，以特別注意來源提及，但不注意非提及符號。我們的提及注意力模組不僅從來源提及中萃取特徵，還考慮了對代名詞翻譯有益的目標側情境。此外，我們還引入了兩個提及分類器，以訓練模型識別提及，其輸出指導提及注意力。我們對 WMT17 英德翻譯任務進行了實驗，並使用 BLEU、APT 和對比評估指標對我們的模型進行了通用翻譯和代名詞翻譯評估。我們提出的模型在 APT 和 BLEU 分數方面優於基準 Transformer 模型，這證實了我們的假設，即我們可以透過特別注意來源提及來改進代名詞翻譯，並表明我們引入的額外模組對一般翻譯品質沒有負面影響。

##### **Answer Set Networks: Casting Answer Set Programming into Deep Learning**
2412.14814v1 by Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting

Although Answer Set Programming (ASP) allows constraining neural-symbolic
(NeSy) systems, its employment is hindered by the prohibitive costs of
computing stable models and the CPU-bound nature of state-of-the-art solvers.
To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on
Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep
Probabilistic Logic Programming (DPPL). Specifically, we show how to translate
ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded
problem by leveraging GPU's batching and parallelization capabilities. Our
experimental evaluations demonstrate that ASNs outperform state-of-the-art
CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following
two contributions based on the strengths of ASNs. Namely, we are the first to
show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs
to guide the training with logic. Further, we show the "constitutional
navigation" of drones, i.e., encoding public aviation laws in an ASN for
routing Unmanned Aerial Vehicles in uncertain environments.

摘要：儘管答案集程式設計（ASP）允許約束神經符號（NeSy）系統，但其應用受到計算穩定模型的過高成本和現有求解器受 CPU 限制的本質所阻礙。為此，我們提出答案集網路（ASN），一個 NeSy 求解器。ASN 基於圖神經網路（GNN），是一種基於 ASP 的深度機率邏輯程式設計（DPPL）的可擴充方法。具體來說，我們展示如何將 ASP 轉換為 ASN，並展示 ASN 如何透過利用 GPU 的批次處理和並行化功能有效地解決編碼問題。我們的實驗評估表明，ASN 在多項任務上優於現有的受 CPU 限制的 NeSy 系統。同時，我們根據 ASN 的優勢做出了以下兩項貢獻。也就是說，我們首次展示使用 DPPL 對大型語言模型（LLM）進行微調，使用 ASN 以邏輯引導訓練。此外，我們展示了無人機的「憲法導航」，即在 ASN 中編碼公共航空法，以便在不確定的環境中對無人機進行路由。

##### **MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data**
2412.14810v1 by Camillo Maria Caruso, Paolo Soda, Valerio Guarrasi

In healthcare, the integration of multimodal data is pivotal for developing
comprehensive diagnostic and predictive models. However, managing missing data
remains a significant challenge in real-world applications. We introduce MARIA
(Multimodal Attention Resilient to Incomplete datA), a novel transformer-based
deep learning model designed to address these challenges through an
intermediate fusion strategy. Unlike conventional approaches that depend on
imputation, MARIA utilizes a masked self-attention mechanism, which processes
only the available data without generating synthetic values. This approach
enables it to effectively handle incomplete datasets, enhancing robustness and
minimizing biases introduced by imputation methods. We evaluated MARIA against
10 state-of-the-art machine learning and deep learning models across 8
diagnostic and prognostic tasks. The results demonstrate that MARIA outperforms
existing methods in terms of performance and resilience to varying levels of
data incompleteness, underscoring its potential for critical healthcare
applications.

摘要：在醫療保健中，多模態資料的整合對於開發全面的診斷和預測模型至關重要。然而，在實際應用中，管理遺失的資料仍然是一項重大的挑戰。我們介紹了 MARIA（對不完整資料具有彈性的多模態注意力），這是一種新穎的基於Transformer的深度學習模型，旨在通過中間融合策略來應對這些挑戰。與依賴於插補的傳統方法不同，MARIA 利用了遮罩自注意力機制，它只處理可用資料而不生成合成值。這種方法使其能夠有效地處理不完整的資料集，增強了健壯性並最大限度地減少了插補方法引入的偏差。我們在 8 項診斷和預後任務中，對 MARIA 與 10 種最先進的機器學習和深度學習模型進行了評估。結果表明，MARIA 在性能和對不同程度資料不完整性的彈性方面優於現有方法，這突顯了其在關鍵醫療保健應用中的潛力。

##### **ResoFilter: Rine-grained Synthetic Data Filtering for Large Language Models through Data-Parameter Resonance Analysis**
2412.14809v1 by Zeao Tu, Xiangdi Meng, Yu He, Zihan Yao, Tianyu Qi, Jun Liu, Ming Li

Large language models (LLMs) have shown remarkable effectiveness across
various domains, with data augmentation methods utilizing GPT for synthetic
data generation becoming prevalent. However, the quality and utility of
augmented data remain questionable, and current methods lack clear metrics for
evaluating data characteristics. To address these challenges, we propose
ResoFilter, a novel method that integrates models, data, and tasks to refine
datasets. ResoFilter leverages the fine-tuning process to obtain Data-Parameter
features for data selection, offering improved interpretability by representing
data characteristics through model weights. Our experiments demonstrate that
ResoFilter achieves comparable results to full-scale fine-tuning using only
half the data in mathematical tasks and exhibits strong generalization across
different models and domains. This method provides valuable insights for
constructing synthetic datasets and evaluating high-quality data, offering a
promising solution for enhancing data augmentation techniques and improving
training dataset quality for LLMs. For reproducibility, we will release our
code and data upon acceptance.

摘要：大型語言模型 (LLM) 已在各種領域展現出顯著的效能，而利用 GPT 進行合成資料生成的資料擴充方法也日益普遍。然而，擴充資料的品質和效用仍有待商榷，而現行方法也缺乏明確的指標來評估資料特性。為了應對這些挑戰，我們提出 ResoFilter，這是一種將模型、資料和任務整合在一起，用於精煉資料集的創新方法。ResoFilter 透過微調程序來取得資料參數特徵，用於資料選取，並透過模型權重來呈現資料特性，進而提升可解釋性。我們的實驗證明，ResoFilter 只使用數學任務中一半的資料，就能達成與全面微調相當的結果，並在不同的模型和領域中展現強大的泛化能力。此方法可為建構合成資料集和評估高品質資料提供有價值的見解，並為加強資料擴充技術和提升 LLM 訓練資料集品質提供一個有前景的解決方案。為了可重現性，我們將在獲得接受後釋出我們的程式碼和資料。

##### **Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios**
2412.14802v1 by Egor Shibaev, Denis Sushentsev, Yaroslav Golubev, Aleksandr Khvorov

In large-scale software systems, there are often no fully-fledged bug reports
with human-written descriptions when an error occurs. In this case, developers
rely on stack traces, i.e., series of function calls that led to the error.
Since there can be tens and hundreds of thousands of them describing the same
issue from different users, automatic deduplication into categories is
necessary to allow for processing. Recent works have proposed powerful deep
learning-based approaches for this, but they are evaluated and compared in
isolation from real-life workflows, and it is not clear whether they will
actually work well at scale.
  To overcome this gap, this work presents three main contributions: a novel
model, an industry-based dataset, and a multi-faceted evaluation. Our model
consists of two parts - (1) an embedding model with byte-pair encoding and
approximate nearest neighbor search to quickly find the most relevant stack
traces to the incoming one, and (2) a reranker that re-ranks the most fitting
stack traces, taking into account the repeated frames between them. To
complement the existing datasets collected from open-source projects, we share
with the community SlowOps - a dataset of stack traces from IntelliJ-based
products developed by JetBrains, which has an order of magnitude more stack
traces per category. Finally, we carry out an evaluation that strives to be
realistic: measuring not only the accuracy of categorization, but also the
operation time and the ability to create new categories. The evaluation shows
that our model strikes a good balance - it outperforms other models on both
open-source datasets and SlowOps, while also being faster on time than most. We
release all of our code and data, and hope that our work can pave the way to
further practice-oriented research in the area.

摘要：<paragraph>在大規模軟體系統中，當錯誤發生時，通常沒有完整的人工撰寫描述的錯誤報告。在這種情況下，開發人員依賴堆疊追蹤，也就是導致錯誤的一系列函式呼叫。由於可能有成千上萬個堆疊追蹤描述來自不同使用者的相同問題，因此必須自動將其分類去重，才能進行處理。最近的研究提出強大的深度學習方法來解決這個問題，但這些方法是在與實際工作流程隔離的狀態下進行評估和比較，因此不清楚它們是否真的能在大規模情況下順利運作。
為了克服這個差距，本研究提出了三項主要貢獻：一個新模型、一個產業資料集和一個多面向評估。我們的模型包含兩個部分：(1) 一個使用位元組對編碼的嵌入模型和近似最近鄰搜尋，用於快速找出與輸入堆疊追蹤最相關的堆疊追蹤，以及 (2) 一個重新排序器，用於重新排序最合適的堆疊追蹤，並考量它們之間重複的框架。為了補充從開源專案收集的現有資料集，我們與社群分享 SlowOps，這是一個來自 JetBrains 開發的 IntelliJ 為基礎產品的堆疊追蹤資料集，每個類別的堆疊追蹤數量多了一個數量級。最後，我們進行了一項力求務實的評估：不僅衡量分類的準確性，還衡量運作時間和建立新類別的能力。評估結果顯示我們的模型取得了良好的平衡，它在開源資料集和 SlowOps 上都優於其他模型，同時速度也比大多數模型快。我們釋出了所有程式碼和資料，並希望我們的研究能為這個領域的實務導向研究鋪路。</paragraph>

##### **Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning**
2412.14780v1 by Ziang Ye, Zhenru Zhang, Yang Zhang, Jianxin Ma, Junyang Lin, Fuli Feng

When using agent-task datasets to enhance agent capabilities for Large
Language Models (LLMs), current methodologies often treat all tokens within a
sample equally. However, we argue that tokens serving different roles -
specifically, reasoning tokens versus boilerplate tokens (e.g., those governing
output format) - differ significantly in importance and learning complexity,
necessitating their disentanglement and distinct treatment. To address this, we
propose a novel Shuffle-Aware Discriminator (SHAD) for adaptive token
discrimination. SHAD classifies tokens by exploiting predictability differences
observed after shuffling input-output combinations across samples: boilerplate
tokens, due to their repetitive nature among samples, maintain predictability,
whereas reasoning tokens do not. Using SHAD, we propose the
Reasoning-highlighted Fine-Tuning (RFT) method, which adaptively emphasizes
reasoning tokens during fine-tuning, yielding notable performance gains over
common Supervised Fine-Tuning (SFT).

摘要：在使用代理任務資料集來增強大型語言模型 (LLM) 的代理能力時，目前的技術通常將範例中的所有符號視為同等重要。然而，我們認為扮演不同角色的符號，特別是推理符號與樣板符號（例如，控制輸出格式的符號），在重要性和學習複雜性上存在顯著差異，需要將它們區分開來並分別處理。為了解決這個問題，我們提出了一種新穎的隨機感知辨識器 (SHAD)，用於自適應符號辨識。SHAD 透過利用在範例中混洗輸入輸出組合後觀察到的可預測性差異來對符號進行分類：樣板符號由於在範例中的重複性而保持可預測性，而推理符號則不然。使用 SHAD，我們提出了強調推理微調 (RFT) 方法，它在微調過程中自適應地強調推理符號，與常見的監督微調 (SFT) 相比，產生顯著的效能提升。

##### **ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine**
2412.14771v1 by Rabee Qasem, Mohannad Hendi, Banan Tantour

Large Language Models (LLMs) have demonstrated remarkable potential in
diverse domains, yet their application in the legal sector, particularly in
low-resource contexts, remains limited. This study addresses the challenges of
adapting LLMs to the Palestinian legal domain, where political instability,
fragmented legal frameworks, and limited AI resources hinder effective
machine-learning applications. We present a fine-tuned model based on a
quantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set
derived from Palestinian legal texts. Using smaller-scale models and
strategically generated question-answer pairs, we achieve a cost-effective,
locally sustainable solution that provides accurate and contextually relevant
legal guidance. Our experiments demonstrate promising performance on various
query types, ranging from yes/no questions and narrative explanations to
complex legal differentiations, while highlighting areas for improvement, such
as handling calculation-based inquiries and structured list formatting. This
work provides a pathway for the deployment of AI-driven legal assistance tools
tailored to the needs of resource-constrained environments.

摘要：大型語言模型 (LLM) 已在不同領域展現出顯著的潛力，但它們在法律領域的應用，特別是在資源不足的環境中，仍然有限。本研究探討了將 LLM 適應到巴勒斯坦法律領域的挑戰，在該領域中，政治不穩定、法律框架支離破碎以及 AI 資源有限，阻礙了有效的機器學習應用。我們提供了一個經過微調的模型，該模型基於 Llama-3.2-1B-Instruct 的量化版本，並根據從巴勒斯坦法律文本中衍生的合成數據集進行訓練。使用較小規模的模型和策略性生成的問答對，我們實現了一個具有成本效益、在當地可持續的解決方案，該解決方案提供了準確且與上下文相關的法律指導。我們的實驗證明了在各種查詢類型上的良好表現，包括從是非題和敘述性解釋到複雜的法律區別，同時強調了改進領域，例如處理基於計算的查詢和結構化列表格式。這項工作為部署 AI 驅動的法律援助工具提供了一條途徑，該工具專為資源受限環境的需求而量身打造。

##### **PsyDraw: A Multi-Agent Multimodal System for Mental Health Screening in Left-Behind Children**
2412.14769v1 by Yiqun Zhang, Xiaocui Yang, Xiaobai Li, Siyuan Yu, Yi Luan, Shi Feng, Daling Wang, Yifei Zhang

Left-behind children (LBCs), numbering over 66 million in China, face severe
mental health challenges due to parental migration for work. Early screening
and identification of at-risk LBCs is crucial, yet challenging due to the
severe shortage of mental health professionals, especially in rural areas.
While the House-Tree-Person (HTP) test shows higher child participation rates,
its requirement for expert interpretation limits its application in
resource-scarce regions. To address this challenge, we propose PsyDraw, a
multi-agent system based on Multimodal Large Language Models that assists
mental health professionals in analyzing HTP drawings. The system employs
specialized agents for feature extraction and psychological interpretation,
operating in two stages: comprehensive feature analysis and professional report
generation. Evaluation of HTP drawings from 290 primary school students reveals
that 71.03% of the analyzes achieved High Consistency with professional
evaluations, 26.21% Moderate Consistency and only 2.41% Low Consistency. The
system identified 31.03% of cases requiring professional attention,
demonstrating its effectiveness as a preliminary screening tool. Currently
deployed in pilot schools, \method shows promise in supporting mental health
professionals, particularly in resource-limited areas, while maintaining high
professional standards in psychological assessment.

摘要：留守儿童（LBC）在中国超过 6600 万，由于父母外出务工，他们面临着严重的心理健康挑战。对高危 LBC 进行早期筛查和识别至关重要，但由于心理健康专业人员严重短缺，尤其是在农村地区，这却是一项挑战。虽然房树人（HTP）测试显示儿童参与率较高，但其对专家解读的要求限制了其在资源匮乏地区的应用。为了应对这一挑战，我们提出了 PsyDraw，这是一个基于多模态大语言模型的多主体系统，它可以协助心理健康专业人员分析 HTP 图画。该系统采用专门的主体进行特征提取和心理解读，分两个阶段进行：综合特征分析和专业报告生成。对 290 名小学生的 HTP 图画进行评估后发现，71.03% 的分析与专业评估高度一致，26.21% 一致性中等，仅 2.41% 一致性低。该系统识别出 31.03% 需要专业关注的病例，证明了其作为初步筛查工具的有效性。目前已在试点学校部署，该方法有望为心理健康专业人员提供支持，尤其是在资源有限的地区，同时在心理评估中保持较高的专业标准。

##### **CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering**
2412.14764v1 by Ruida Hu, Chao Peng, Jingyi Ren, Bo Jiang, Xiangxin Meng, Qinyun Wu, Pengfei Gao, Xinchen Wang, Cuiyun Gao

In this work, we introduce CodeRepoQA, a large-scale benchmark specifically
designed for evaluating repository-level question-answering capabilities in the
field of software engineering. CodeRepoQA encompasses five programming
languages and covers a wide range of scenarios, enabling comprehensive
evaluation of language models. To construct this dataset, we crawl data from 30
well-known repositories in GitHub, the largest platform for hosting and
collaborating on code, and carefully filter raw data. In total, CodeRepoQA is a
multi-turn question-answering benchmark with 585,687 entries, covering a
diverse array of software engineering scenarios, with an average of 6.62
dialogue turns per entry.
  We evaluate ten popular large language models on our dataset and provide
in-depth analysis. We find that LLMs still have limitations in
question-answering capabilities in the field of software engineering, and
medium-length contexts are more conducive to LLMs' performance. The entire
benchmark is publicly available at
https://github.com/kinesiatricssxilm14/CodeRepoQA.

摘要：在這項工作中，我們介紹 CodeRepoQA，一個專門設計用於評估軟體工程領域中儲存庫層級問答能力的大規模基準。CodeRepoQA 涵蓋了五種程式語言並涵蓋了廣泛的場景，讓語言模型能夠進行全面的評估。為了建構此資料集，我們從 GitHub（一個最大的程式碼託管和協作平台）中爬取了 30 個知名儲存庫的資料，並仔細過濾原始資料。總而言之，CodeRepoQA 是個多輪問答基準，包含 585,687 個條目，涵蓋了各種軟體工程場景，每個條目的平均對話輪數為 6.62。
我們在資料集上評估了十個熱門的大型語言模型，並提供了深入的分析。我們發現大型語言模型在軟體工程領域的問答能力仍有其限制，而中等長度的脈絡更利於大型語言模型的表現。整個基準可在 https://github.com/kinesiatricssxilm14/CodeRepoQA 公開取得。

##### **Query pipeline optimization for cancer patient question answering systems**
2412.14751v1 by Maolin He, Rena Gao, Mike Conway, Brian E. Chapman

Retrieval-augmented generation (RAG) mitigates hallucination in Large
Language Models (LLMs) by using query pipelines to retrieve relevant external
information and grounding responses in retrieved knowledge. However, query
pipeline optimization for cancer patient question-answering (CPQA) systems
requires separately optimizing multiple components with domain-specific
considerations. We propose a novel three-aspect optimization approach for the
RAG query pipeline in CPQA systems, utilizing public biomedical databases like
PubMed and PubMed Central. Our optimization includes: (1) document retrieval,
utilizing a comparative analysis of NCBI resources and introducing Hybrid
Semantic Real-time Document Retrieval (HSRDR); (2) passage retrieval,
identifying optimal pairings of dense retrievers and rerankers; and (3)
semantic representation, introducing Semantic Enhanced Overlap Segmentation
(SEOS) for improved contextual understanding. On a custom-developed dataset
tailored for cancer-related inquiries, our optimized RAG approach improved the
answer accuracy of Claude-3-haiku by 5.24% over chain-of-thought prompting and
about 3% over a naive RAG setup. This study highlights the importance of
domain-specific query optimization in realizing the full potential of RAG and
provides a robust framework for building more accurate and reliable CPQA
systems, advancing the development of RAG-based biomedical systems.

摘要：檢索增強生成 (RAG) 透過使用查詢管線來擷取相關外部資訊，並將回應建立在擷取的知識中，以減輕大型語言模型 (LLM) 中的幻覺。然而，癌症患者問答 (CPQA) 系統的查詢管線最佳化需要使用特定於領域的考量，分別最佳化多個元件。我們提出一個創新的三面向最佳化方法，用於 CPQA 系統中的 RAG 查詢管線，利用 PubMed 和 PubMed Central 等公開生物醫學資料庫。我們的最佳化包括：(1) 文件擷取，利用 NCBI 資源的比較分析，並引入混合語義即時文件擷取 (HSRDR)；(2) 段落擷取，找出稠密擷取器和重新排序器的最佳配對；以及 (3) 語意表示，引入語意增強重疊分段 (SEOS) 以改善脈絡理解。在針對癌症相關查詢量身打造的客製化開發資料集上，我們最佳化的 RAG 方法將 Claude-3-haiku 的答案準確度提升了 5.24%，優於思考鏈提示，且比樸素的 RAG 設定提升了約 3%。這項研究強調了特定於領域的查詢最佳化在實現 RAG 充分潛力的重要性，並提供了一個穩健的架構來建構更準確且可靠的 CPQA 系統，促進基於 RAG 的生物醫學系統的發展。

##### **On Verbalized Confidence Scores for LLMs**
2412.14737v1 by Daniel Yang, Yao-Hung Hubert Tsai, Makoto Yamada

The rise of large language models (LLMs) and their tight integration into our
daily life make it essential to dedicate efforts towards their trustworthiness.
Uncertainty quantification for LLMs can establish more human trust into their
responses, but also allows LLM agents to make more informed decisions based on
each other's uncertainty. To estimate the uncertainty in a response, internal
token logits, task-specific proxy models, or sampling of multiple responses are
commonly used. This work focuses on asking the LLM itself to verbalize its
uncertainty with a confidence score as part of its output tokens, which is a
promising way for prompt- and model-agnostic uncertainty quantification with
low overhead. Using an extensive benchmark, we assess the reliability of
verbalized confidence scores with respect to different datasets, models, and
prompt methods. Our results reveal that the reliability of these scores
strongly depends on how the model is asked, but also that it is possible to
extract well-calibrated confidence scores with certain prompt methods. We argue
that verbalized confidence scores can become a simple but effective and
versatile uncertainty quantification method in the future. Our code is
available at https://github.com/danielyxyang/llm-verbalized-uq .

摘要：隨著大型語言模型 (LLM) 的興起及其與我們日常生活緊密的整合，致力於提升其可信度至關重要。LLM 的不確定性量化可以建立人類對其回應的更多信任，但也允許 LLM 代理根據彼此的不確定性做出更明智的決策。為了估計回應中的不確定性，通常會使用內部權重、特定於任務的代理模型或多重回應取樣。這項工作重點在於要求 LLM 本身以信心分數的形式對其不確定性進行言語化，作為其輸出權重的一部分，這是一種很有前景的提示和模型不可知的不確定性量化方式，且開銷低。使用廣泛的基準，我們評估了言語化信心分數相對於不同資料集、模型和提示方法的可信度。我們的結果顯示，這些分數的可信度在很大程度上取決於如何詢問模型，但也顯示出使用特定提示方法提取校準良好的信心分數是可行的。我們認為，言語化信心分數未來可以成為一種簡單但有效且通用的不確定性量化方法。我們的程式碼可在 https://github.com/danielyxyang/llm-verbalized-uq 取得。

##### **Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**
2412.14736v1 by Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba

This systematic review explores the use of machine learning (ML) in
predicting diabetes, focusing on datasets, algorithms, training methods, and
evaluation metrics. It examines datasets like the Singapore National Diabetic
Retinopathy Screening program, REPLACE-BG, National Health and Nutrition
Examination Survey, and Pima Indians Diabetes Database. The review assesses the
performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in
predicting diabetes outcomes. The study emphasizes the importance of
interdisciplinary collaboration and ethical considerations in ML-based diabetes
prediction models.

摘要：這項系統性回顧探討了機器學習 (ML) 在糖尿病預測中的應用，重點在於資料集、演算法、訓練方法和評估指標。它檢驗了資料集，例如新加坡國家糖尿病視網膜病變篩檢計畫、REPLACE-BG、國家健康與營養檢查調查和皮馬印第安人糖尿病資料庫。該回顧評估了 ML 演算法（例如 CNN、SVM、邏輯迴歸和 XGBoost）在預測糖尿病結果方面的表現。這項研究強調了跨領域合作和在基於 ML 的糖尿病預測模型中進行道德考量的重要性。

##### **Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey**
2412.14708v1 by Aygün Varol, Naser Hossein Motlagh, Mirka Leino, Sasu Tarkoma, Johanna Virkki

Smart spaces are ubiquitous computing environments that integrate diverse
sensing and communication technologies to enhance space functionality, optimize
energy utilization, and improve user comfort and well-being. The integration of
emerging AI methodologies into these environments facilitates the formation of
AI-driven smart spaces, which further enhance functionalities of the spaces by
enabling advanced applications such as personalized comfort settings,
interactive living spaces, and automatization of the space systems, all
resulting in enhanced indoor experiences of the users. In this paper, we
present a systematic survey of existing research on the foundational components
of AI-driven smart spaces, including sensor technologies, data communication
protocols, sensor network management and maintenance strategies, as well as the
data collection, processing and analytics. Given the pivotal role of AI in
establishing AI-powered smart spaces, we explore the opportunities and
challenges associated with traditional machine learning (ML) approaches, such
as deep learning (DL), and emerging methodologies including large language
models (LLMs). Finally, we provide key insights necessary for the development
of AI-driven smart spaces, propose future research directions, and sheds light
on the path forward.

摘要：智慧空間是一種普遍運算環境，整合了多樣化的感測和通訊技術以提升空間功能、優化能源利用，並改善使用者的舒適度和幸福感。將新興的人工智慧方法整合到這些環境中，有助於形成人工智慧驅動的智慧空間，進一步提升空間功能，實現個人化舒適設定、互動式生活空間和空間系統自動化等進階應用，所有這些都能提升使用者的室內體驗。在本文中，我們對人工智慧驅動智慧空間的基礎組成進行系統性探討，包括感測器技術、資料通訊協定、感測器網路管理和維護策略，以及資料收集、處理和分析。鑑於人工智慧在建立人工智慧驅動智慧空間中扮演關鍵角色，我們探討了傳統機器學習 (ML) 方法（例如深度學習 (DL)）相關的機遇和挑戰，以及新興方法（包括大型語言模型 (LLM)）。最後，我們提供了人工智慧驅動智慧空間開發必要的關鍵見解，提出未來的研究方向，並闡明前進的道路。

##### **How to Synthesize Text Data without Model Collapse?**
2412.14689v1 by Xuekai Zhu, Daixuan Cheng, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou

Model collapse in synthetic data indicates that iterative training on
self-generated data leads to a gradual decline in performance. With the
proliferation of AI models, synthetic data will fundamentally reshape the web
data ecosystem. Future GPT-$\{n\}$ models will inevitably be trained on a blend
of synthetic and human-produced data. In this paper, we focus on two questions:
what is the impact of synthetic data on language model training, and how to
synthesize data without model collapse? We first pre-train language models
across different proportions of synthetic data, revealing a negative
correlation between the proportion of synthetic data and model performance. We
further conduct statistical analysis on synthetic data to uncover
distributional shift phenomenon and over-concentration of n-gram features.
Inspired by the above findings, we propose token editing on human-produced data
to obtain semi-synthetic data. As a proof of concept, we theoretically
demonstrate that token-level editing can prevent model collapse, as the test
error is constrained by a finite upper bound. We conduct extensive experiments
on pre-training from scratch, continual pre-training, and supervised
fine-tuning. The results validate our theoretical proof that token-level
editing improves data quality and enhances model performance.

摘要：合成資料中的模型崩潰表明，對自我產生的資料進行反覆訓練會導致效能逐漸下降。隨著 AI 模型的普及，合成資料將從根本上重塑網路資料生態系統。未來的 GPT-$\{n\}$ 模型將不可避免地訓練於合成資料和人類產生資料的混合資料中。在本文中，我們專注於兩個問題：合成資料對語言模型訓練的影響是什麼，以及如何在不發生模型崩潰的情況下合成資料？我們首先在不同比例的合成資料中預訓練語言模型，揭示了合成資料的比例與模型效能之間的負相關。我們進一步對合成資料進行統計分析，以發現分佈轉移現象和 n-gram 特徵的過度集中。根據上述發現，我們提出對人類產生的資料進行標記編輯以取得半合成資料。作為概念證明，我們在理論上證明了標記層級編輯可以防止模型崩潰，因為測試誤差受到有限的上限約束。我們對從頭開始的預訓練、持續預訓練和監督微調進行了廣泛的實驗。結果驗證了我們的理論證明，即標記層級編輯可以改善資料品質並增強模型效能。

##### **Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection**
2412.14686v1 by Hao Guo, Zihan Ma, Zhi Zeng, Minnan Luo, Weixin Zeng, Jiuyang Tang, Xiang Zhao

Social platforms, while facilitating access to information, have also become
saturated with a plethora of fake news, resulting in negative consequences.
Automatic multimodal fake news detection is a worthwhile pursuit. Existing
multimodal fake news datasets only provide binary labels of real or fake.
However, real news is alike, while each fake news is fake in its own way. These
datasets fail to reflect the mixed nature of various types of multimodal fake
news. To bridge the gap, we construct an attributing multi-granularity
multimodal fake news detection dataset \amg, revealing the inherent fake
pattern. Furthermore, we propose a multi-granularity clue alignment model \our
to achieve multimodal fake news detection and attribution. Experimental results
demonstrate that \amg is a challenging dataset, and its attribution setting
opens up new avenues for future research.

摘要：社交平台在促進資訊取得的同時，也充斥著大量的假新聞，造成負面影響。自動多模態假新聞偵測是一項有價值的追求。現有的多模態假新聞資料集僅提供真實或假的二元標籤。然而，真實新聞是相似的，而每則假新聞都有其獨特的虛假方式。這些資料集無法反映各種類型多模態假新聞的混合性質。為了彌合差距，我們構建了一個歸因的多粒度多模態假新聞偵測資料集 \amg，揭示了內在的假新聞模式。此外，我們提出了一個多粒度線索對齊模型 \our，以實現多模態假新聞偵測和歸因。實驗結果表明，\amg 是一個具有挑戰性的資料集，其歸因設定為未來的研究開闢了新的途徑。

##### **Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines**
2412.14684v1 by Yunsu Kim, AhmedElmogtaba Abdelaziz, Thiago Castro Ferreira, Mohamed Al-Badrashiny, Hassan Sawaf

As the demand for artificial intelligence (AI) grows to address complex
real-world tasks, single models are often insufficient, requiring the
integration of multiple models into pipelines. This paper introduces Bel
Esprit, a conversational agent designed to construct AI model pipelines based
on user-defined requirements. Bel Esprit employs a multi-agent framework where
subagents collaborate to clarify requirements, build, validate, and populate
pipelines with appropriate models. We demonstrate the effectiveness of this
framework in generating pipelines from ambiguous user queries, using both
human-curated and synthetic data. A detailed error analysis highlights ongoing
challenges in pipeline construction. Bel Esprit is available for a free trial
at https://belesprit.aixplain.com.

摘要：隨著人工智慧（AI）對應複雜的現實世界任務的需求不斷增長，單一模型往往不足以應付，需要將多個模型整合到管道中。本文介紹了 Bel Esprit，這是一個對話代理，旨在根據使用者定義的需求建立 AI 模型管道。Bel Esprit 採用多代理架構，其中子代理會合作釐清需求、建立、驗證和使用適當的模型來填充管道。我們使用人工策劃和合成資料，展示了此架構在從模稜兩可的使用者查詢中產生管道的有效性。詳細的錯誤分析突顯了管道建構中持續存在的挑戰。Bel Esprit 可在 https://belesprit.aixplain.com/ 免費試用。

##### **A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space**
2412.14680v1 by Yonghao He, Hu Su, Haiyong Yu, Cong Yang, Wei Sui, Cong Wang, Song Liu

Open-set object detection (OSOD) is highly desirable for robotic manipulation
in unstructured environments. However, existing OSOD methods often fail to meet
the requirements of robotic applications due to their high computational burden
and complex deployment. To address this issue, this paper proposes a
light-weight framework called Decoupled OSOD (DOSOD), which is a practical and
highly efficient solution to support real-time OSOD tasks in robotic systems.
Specifically, DOSOD builds upon the YOLO-World pipeline by integrating a
vision-language model (VLM) with a detector. A Multilayer Perceptron (MLP)
adaptor is developed to transform text embeddings extracted by the VLM into a
joint space, within which the detector learns the region representations of
class-agnostic proposals. Cross-modality features are directly aligned in the
joint space, avoiding the complex feature interactions and thereby improving
computational efficiency. DOSOD operates like a traditional closed-set detector
during the testing phase, effectively bridging the gap between closed-set and
open-set detection. Compared to the baseline YOLO-World, the proposed DOSOD
significantly enhances real-time performance while maintaining comparable
accuracy. The slight DOSOD-S model achieves a Fixed AP of $26.7\%$, compared to
$26.2\%$ for YOLO-World-v1-S and $22.7\%$ for YOLO-World-v2-S, using similar
backbones on the LVIS minival dataset. Meanwhile, the FPS of DOSOD-S is
$57.1\%$ higher than YOLO-World-v1-S and $29.6\%$ higher than YOLO-World-v2-S.
Meanwhile, we demonstrate that the DOSOD model facilitates the deployment of
edge devices. The codes and models are publicly available at
https://github.com/D-Robotics-AI-Lab/DOSOD.

摘要：<paragraph>開放式物件偵測 (OSOD) 對於非結構化環境中的機器人操作非常需要。然而，現有的 OSOD 方法由於其高運算負擔和複雜的部署，通常無法滿足機器人應用程式的需求。為了解決這個問題，本文提出了一個稱為解耦 OSOD (DOSOD) 的輕量級框架，這是一個實用且高效的解決方案，用於支援機器人系統中的即時 OSOD 任務。具體來說，DOSOD 建立在 YOLO-World 管線上，透過將視覺語言模型 (VLM) 與偵測器整合在一起。開發了一個多層感知器 (MLP) 適配器，將 VLM 提取的文字嵌入轉換成一個聯合空間，偵測器在其中學習類別不可知提案的區域表示。跨模態特徵直接在聯合空間中對齊，避免了複雜的特徵交互，從而提高了運算效率。DOSOD 在測試階段就像傳統的封閉式偵測器一樣運作，有效地縮小了封閉式和開放式偵測之間的差距。與基準 YOLO-World 相比，提出的 DOSOD 在保持可比精確度的同時，顯著提升了即時效能。輕量的 DOSOD-S 模型在 LVIS minival 資料集上使用類似的骨幹網路，達到了 26.7% 的固定 AP，而 YOLO-World-v1-S 為 26.2%，YOLO-World-v2-S 為 22.7%。同時，DOSOD-S 的 FPS 比 YOLO-World-v1-S 高 57.1%，比 YOLO-World-v2-S 高 29.6%。同時，我們證明了 DOSOD 模型有助於邊緣裝置的部署。程式碼和模型已公開在 https://github.com/D-Robotics-AI-Lab/DOSOD。</paragraph>

##### **LLMs as mediators: Can they diagnose conflicts accurately?**
2412.14675v1 by Özgecan Koçak, Phanish Puranam, Afşar Yegin

Prior research indicates that to be able to mediate conflict, observers of
disagreements between parties must be able to reliably distinguish the sources
of their disagreement as stemming from differences in beliefs about what is
true (causality) vs. differences in what they value (morality). In this paper,
we test if OpenAI's Large Language Models GPT 3.5 and GPT 4 can perform this
task and whether one or other type of disagreement proves particularly
challenging for LLM's to diagnose. We replicate study 1 in Ko\c{c}ak et al.
(2003), which employes a vignette design, with OpenAI's GPT 3.5 and GPT 4. We
find that both LLMs have similar semantic understanding of the distinction
between causal and moral codes as humans and can reliably distinguish between
them. When asked to diagnose the source of disagreement in a conversation, both
LLMs, compared to humans, exhibit a tendency to overestimate the extent of
causal disagreement and underestimate the extent of moral disagreement in the
moral misalignment condition. This tendency is especially pronounced for GPT 4
when using a proximate scale that relies on concrete language specific to an
issue. GPT 3.5 does not perform as well as GPT4 or humans when using either the
proximate or the distal scale. The study provides a first test of the potential
for using LLMs to mediate conflict by diagnosing the root of disagreements in
causal and evaluative codes.

摘要：<paragraph>先前的研究表明，为了能够调解冲突，各方争端的观察者必须能够可靠地区分其争端的根源，是源于对何为真实（因果关系）的信念差异，还是源于对他们所重视事物的差异（道德）。在本文中，我们测试了 OpenAI 的大型语言模型 GPT 3.5 和 GPT 4 是否可以执行此任务，以及哪种类型的争端被证明对 LLM 的诊断特别具有挑战性。我们在 Ko\c{c}ak 等人的研究 1 中复制了研究 1。(2003)，它采用小插图设计，使用 OpenAI 的 GPT 3.5 和 GPT 4。我们发现，这两种 LLM 对因果和道德规范之间的区别具有与人类相似的语义理解，并且可以可靠地区分它们。当被要求诊断对话中分歧的根源时，与人类相比，这两种 LLM 都表现出高估因果分歧程度和低估道德错位条件下道德分歧程度的倾向。当使用依赖于特定于某个问题的具体语言的近端量表时，GPT 4 的这种倾向尤其明显。使用近端或远端量表时，GPT 3.5 的表现不如 GPT4 或人类。该研究首次测试了通过诊断因果和评价规范中分歧的根源来使用 LLM 调解冲突的潜力。</paragraph>

##### **FiVL: A Framework for Improved Vision-Language Alignment**
2412.14672v1 by Estelle Aflalo, Gabriela Ben Melech Stan, Tiep Le, Man Luo, Shachar Rosenman, Sayak Paul, Shao-Yen Tseng, Vasudev Lal

Large Vision Language Models (LVLMs) have achieved significant progress in
integrating visual and textual inputs for multimodal reasoning. However, a
recurring challenge is ensuring these models utilize visual information as
effectively as linguistic content when both modalities are necessary to
formulate an accurate answer. We hypothesize that hallucinations arise due to
the lack of effective visual grounding in current LVLMs. This issue extends to
vision-language benchmarks, where it is difficult to make the image
indispensable for accurate answer generation, particularly in vision
question-answering tasks. In this work, we introduce FiVL, a novel method for
constructing datasets designed to train LVLMs for enhanced visual grounding and
to evaluate their effectiveness in achieving it. These datasets can be utilized
for both training and assessing an LVLM's ability to use image content as
substantive evidence rather than relying solely on linguistic priors, providing
insights into the model's reliance on visual information. To demonstrate the
utility of our dataset, we introduce an innovative training task that
outperforms baselines alongside a validation method and application for
explainability. The code is available at https://github.com/IntelLabs/fivl.

摘要：大型視覺語言模型 (LVLMs) 在整合視覺和文字輸入以進行多模態推理方面取得了重大進展。然而，一個經常遇到的挑戰是確保這些模型在需要兩種模態才能制定準確答案時，能像使用語言內容一樣有效地利用視覺資訊。我們假設幻覺的產生是因為當前 LVLMs 缺乏有效的視覺基礎。這個問題延伸到視覺語言基準，在視覺語言基準中，很難讓影像對於產生準確答案來說是不可或缺的，特別是在視覺問答任務中。在這項工作中，我們介紹了 FiVL，這是一種創新的方法，用於建構資料集，以訓練 LVLMs 以增強視覺基礎，並評估它們在實現此目標方面的有效性。這些資料集可用於訓練和評估 LVLM 使用影像內容作為實質證據的能力，而不是僅依賴語言先驗，從而深入了解模型對視覺資訊的依賴性。為了證明我們資料集的效用，我們引入了一項創新的訓練任務，該任務優於基準，並附帶驗證方法和可解釋性應用。程式碼可在 https://github.com/IntelLabs/fivl 取得。

##### **Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT**
2412.14670v1 by Hassane Kissane, Achim Schilling, Patrick Krauss

This study investigates the internal representations of verb-particle
combinations within transformer-based large language models (LLMs),
specifically examining how these models capture lexical and syntactic nuances
at different neural network layers. Employing the BERT architecture, we analyse
the representational efficacy of its layers for various verb-particle
constructions such as 'agree on', 'come back', and 'give up'. Our methodology
includes a detailed dataset preparation from the British National Corpus,
followed by extensive model training and output analysis through techniques
like multi-dimensional scaling (MDS) and generalized discrimination value (GDV)
calculations. Results show that BERT's middle layers most effectively capture
syntactic structures, with significant variability in representational accuracy
across different verb categories. These findings challenge the conventional
uniformity assumed in neural network processing of linguistic elements and
suggest a complex interplay between network architecture and linguistic
representation. Our research contributes to a better understanding of how deep
learning models comprehend and process language, offering insights into the
potential and limitations of current neural approaches to linguistic analysis.
This study not only advances our knowledge in computational linguistics but
also prompts further research into optimizing neural architectures for enhanced
linguistic precision.

摘要：本研究探討基於 Transformer 的大型語言模型 (LLM) 中動詞-介系詞組合的內部表徵，特別檢視這些模型如何在不同的神經網路層捕捉詞彙和語法的細微差別。我們採用 BERT 架構，分析其各層對各種動詞-介系詞結構的表徵效能，例如「agree on」、「come back」和「give up」。我們的研究方法包括從英國國家語料庫中準備詳細的資料集，接著透過多維度縮放 (MDS) 和廣義判別值 (GDV) 計算等技術進行廣泛的模型訓練和輸出分析。結果顯示，BERT 的中間層最有效率地捕捉語法結構，而不同動詞類別在表徵準確性上存在顯著差異。這些發現挑戰了神經網路處理語言元素時假設的傳統均勻性，並暗示網路架構和語言表徵之間存在複雜的交互作用。我們的研究有助於更深入了解深度學習模型如何理解和處理語言，並提供對當前神經方法在語言分析中的潛力和限制的見解。本研究不僅提升了我們在計算語言學方面的知識，也促使進一步研究如何最佳化神經架構以增強語言精確度。

##### **LoLaFL: Low-Latency Federated Learning via Forward-only Propagation**
2412.14668v1 by Jierui Zhang, Jianhao Huang, Kaibin Huang

Federated learning (FL) has emerged as a widely adopted paradigm for enabling
edge learning with distributed data while ensuring data privacy. However, the
traditional FL with deep neural networks trained via backpropagation can hardly
meet the low-latency learning requirements in the sixth generation (6G) mobile
networks. This challenge mainly arises from the high-dimensional model
parameters to be transmitted and the numerous rounds of communication required
for convergence due to the inherent randomness of the training process. To
address this issue, we adopt the state-of-the-art principle of maximal coding
rate reduction to learn linear discriminative features and extend the resultant
white-box neural network into FL, yielding the novel framework of Low-Latency
Federated Learning (LoLaFL) via forward-only propagation. LoLaFL enables
layer-wise transmissions and aggregation with significantly fewer communication
rounds, thereby considerably reducing latency. Additionally, we propose two
\emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on
the proof that the optimal NN parameter aggregation in LoLaFL should be
harmonic-mean-like. The second scheme further exploits the low-rank structures
of the features and transmits the low-rank-approximated covariance matrices of
features to achieve additional latency reduction. Theoretic analysis and
experiments are conducted to evaluate the performance of LoLaFL. In comparison
with traditional FL, the two nonlinear aggregation schemes for LoLaFL can
achieve reductions in latency of over 91\% and 98\%, respectively, while
maintaining comparable accuracies.

摘要：聯合學習 (FL) 已成為一種廣泛採用的範例，用於在確保資料隱私的同時，透過分散式資料進行邊緣學習。然而，透過反向傳播訓練的深度神經網路進行傳統 FL，難以滿足第六代 (6G) 行動網路中的低延遲學習需求。此挑戰主要來自於要傳輸的高維度模型參數，以及訓練過程中固有的隨機性，導致收斂需要進行多輪通訊。為了解決這個問題，我們採用最先進的最大編碼率降低原則，來學習線性判別特徵，並將結果的白盒神經網路延伸到 FL，透過僅前向傳播產生低延遲聯合學習 (LoLaFL) 的新架構。LoLaFL 能夠進行分層傳輸和聚合，且通訊輪次大幅減少，從而大幅降低延遲。此外，我們為 LoLaFL 提出兩種\emph{非線性}聚合方案。第一個方案基於 LoLaFL 中最佳 NN 參數聚合應為調和平均數的證明。第二個方案進一步利用特徵的低秩結構，並傳輸特徵的低秩近似共變異數矩陣，以實現額外的延遲降低。進行理論分析和實驗，以評估 LoLaFL 的效能。與傳統 FL 相比，LoLaFL 的兩種非線性聚合方案可以將延遲分別降低超過 91% 和 98%，同時維持相當的準確度。

##### **IOHunter: Graph Foundation Model to Uncover Online Information Operations**
2412.14663v1 by Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara

Social media platforms have become vital spaces for public discourse, serving
as modern agor\'as where a wide range of voices influence societal narratives.
However, their open nature also makes them vulnerable to exploitation by
malicious actors, including state-sponsored entities, who can conduct
information operations (IOs) to manipulate public opinion. The spread of
misinformation, false news, and misleading claims threatens democratic
processes and societal cohesion, making it crucial to develop methods for the
timely detection of inauthentic activity to protect the integrity of online
discourse. In this work, we introduce a methodology designed to identify users
orchestrating information operations, a.k.a. \textit{IO drivers}, across
various influence campaigns. Our framework, named \texttt{IOHunter}, leverages
the combined strengths of Language Models and Graph Neural Networks to improve
generalization in \emph{supervised}, \emph{scarcely-supervised}, and
\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance
across multiple sets of IOs originating from six countries, significantly
surpassing existing approaches. This research marks a step toward developing
Graph Foundation Models specifically tailored for the task of IO detection on
social media platforms.

摘要：社交媒體平台已成為公共論述的重要空間，作為現代廣場，各種聲音影響著社會敘事。然而，它們的開放性也使得它們容易受到惡意行為者的利用，包括國家資助的實體，他們可以進行信息操作 (IO) 以操縱輿論。錯誤信息的傳播、虛假新聞和誤導性說法威脅著民主進程和社會凝聚力，因此制定及時檢測虛假活動以保護在線論述的完整性的方法至關重要。在這項工作中，我們介紹了一種方法，旨在識別在各種影響力運動中策劃信息行動的用戶，即所謂的「IO 驅動程序」。我們的框架名為 \texttt{IOHunter}，它利用語言模型和圖神經網路的綜合優勢來改善「監督」、「稀疏監督」和「跨 IO」情境中的泛化能力。我們的做法在來自六個國家的多組 IO 中實現了最先進的性能，顯著超越了現有方法。這項研究標誌著專門針對社交媒體平台上的 IO 檢測任務開發圖基礎模型邁出了一步。

##### **Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models**
2412.14660v1 by Zijun Chen, Wenbo Hu, Guande He, Zhijie Deng, Zheng Zhang, Richang Hong

Multimodal large language models (MLLMs) combine visual and textual data for
tasks such as image captioning and visual question answering. Proper
uncertainty calibration is crucial, yet challenging, for reliable use in areas
like healthcare and autonomous driving. This paper investigates representative
MLLMs, focusing on their calibration across various scenarios, including before
and after visual fine-tuning, as well as before and after multimodal training
of the base LLMs. We observed miscalibration in their performance, and at the
same time, no significant differences in calibration across these scenarios. We
also highlight how uncertainty differs between text and images and how their
integration affects overall uncertainty. To better understand MLLMs'
miscalibration and their ability to self-assess uncertainty, we construct the
IDK (I don't know) dataset, which is key to evaluating how they handle
unknowns. Our findings reveal that MLLMs tend to give answers rather than admit
uncertainty, but this self-assessment improves with proper prompt adjustments.
Finally, to calibrate MLLMs and enhance model reliability, we propose
techniques such as temperature scaling and iterative prompt optimization. Our
results provide insights into improving MLLMs for effective and responsible
deployment in multimodal applications. Code and IDK dataset:
\href{https://github.com/hfutml/Calibration-MLLM}{https://github.com/hfutml/Calibration-MLLM}.

摘要：多模態大型語言模型 (MMLM) 結合視覺和文字資料，可執行影像標註和視覺問答等任務。適當的不確定性校準對於在醫療保健和自動駕駛等領域中可靠使用至關重要，但卻具有挑戰性。本文探討具代表性的 MMLM，重點關注它們在各種場景中的校準，包括視覺微調前後，以及基礎 LLM 的多模態訓練前後。我們觀察到它們的效能校準不佳，但同時在這些場景中沒有顯著的校準差異。我們也強調不確定性在文字和影像之間的差異，以及它們的整合如何影響整體的不確定性。為了更了解 MLLM 的校準不佳以及它們自我評估不確定性的能力，我們建構了 IDK（我不知道）資料集，這對於評估它們如何處理未知數至關重要。我們的研究結果顯示，MMLM 傾向於給出答案，而不是承認不確定性，但這種自我評估會隨著適當的提示調整而改善。最後，為了校準 MLLM 並增強模型的可靠性，我們提出溫度縮放和反覆提示最佳化等技術。我們的結果提供了深入見解，可改善 MLLM 在多模態應用中有效且負責任的部署。程式碼和 IDK 資料集：\href{https://github.com/hfutml/Calibration-MLLM}{https://github.com/hfutml/Calibration-MLLM}。

##### **Length Controlled Generation for Black-box LLMs**
2412.14656v1 by Yuxuan Gu, Wenjie Wang, Xiaocheng Feng, Weihong Zhong, Kun Zhu, Lei Huang, Tat-Seng Chua, Bing Qin

Large language models (LLMs) have demonstrated impressive instruction
following capabilities, while still struggling to accurately manage the length
of the generated text, which is a fundamental requirement in many real-world
applications. Existing length control methods involve fine-tuning the
parameters of LLMs, which is inefficient and suboptimal for practical use. In
this paper, we propose a novel iterative sampling framework for text length
control, integrating the Metropolis-Hastings algorithm with an importance
sampling acceleration strategy. This framework efficiently and reliably
regulates LLMs to generate length-constrained text without modifying the
underlying parameters, thereby preserving the original capabilities of LLMs.
Experimental results demonstrate that our framework achieves almost 100\%
success rates of length control on Llama3.1 for tasks such as length-controlled
abstractive summarization and length-constrained instruction following, with
minimal additional computational overhead. This also highlights the significant
potential of our method for precise length control across a broader range of
applications, without compromising the versatility of LLMs.

摘要：大型語言模型 (LLM) 已展現令人印象深刻的指令遵循能力，但仍難以精確控管所產生文字的長度，這在許多實際應用中是一項基本要求。現有的長度控制方法包括微調 LLM 的參數，這對於實際使用來說效率低下且次佳。在本文中，我們提出一個創新的反覆抽樣架構進行文字長度控制，將 Metropolis-Hastings 演算法與重要性抽樣加速策略整合。這個架構能有效且可靠地規範 LLM 產生長度受限的文字，而不需要修改底層參數，從而保留 LLM 的原始能力。實驗結果顯示，我們的架構在 Llama3.1 上達成幾乎 100% 的長度控制成功率，適用於長度受控的摘要和長度受限的指令遵循等任務，並將額外的運算負擔降至最低。這也凸顯了我們的方法在更廣泛的應用中進行精確長度控制的顯著潛力，而不會損害 LLM 的多功能性。

##### **TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation**
2412.14642v1 by Jiatong Li, Junxian Li, Yunqing Liu, Dongzhan Zhou, Qing Li

In this paper, we propose Text-based Open Molecule Generation Benchmark
(TOMG-Bench), the first benchmark to evaluate the open-domain molecule
generation capability of LLMs. TOMG-Bench encompasses a dataset of three major
tasks: molecule editing (MolEdit), molecule optimization (MolOpt), and
customized molecule generation (MolCustom). Each task further contains three
subtasks, with each subtask comprising 5,000 test samples. Given the inherent
complexity of open molecule generation, we have also developed an automated
evaluation system that helps measure both the quality and the accuracy of the
generated molecules. Our comprehensive benchmarking of 25 LLMs reveals the
current limitations and potential areas for improvement in text-guided molecule
discovery. Furthermore, with the assistance of OpenMolIns, a specialized
instruction tuning dataset proposed for solving challenges raised by
TOMG-Bench, Llama3.1-8B could outperform all the open-source general LLMs, even
surpassing GPT-3.5-turbo by 46.5\% on TOMG-Bench. Our codes and datasets are
available through https://github.com/phenixace/TOMG-Bench.

摘要：在本文中，我們提出了基於文本的開放式分子生成基準（TOMG-Bench），這是第一個評估 LLM 開放領域分子生成能力的基準。TOMG-Bench 包含三個主要任務的數據集：分子編輯（MolEdit）、分子優化（MolOpt）和客製化分子生成（MolCustom）。每個任務進一步包含三個子任務，每個子任務包含 5,000 個測試樣本。鑑於開放式分子生成的固有複雜性，我們還開發了一個自動化評估系統，有助於衡量生成分子的品質和準確性。我們對 25 個 LLM 的全面基準測試揭示了當前文本引導分子發現的限制和潛在改進領域。此外，在專門為了解決 TOMG-Bench 挑戰而提出的指令調整數據集 OpenMolIns 的協助下，Llama3.1-8B 可以優於所有開源通用 LLM，甚至在 TOMG-Bench 上超越 GPT-3.5-turbo 46.5%。我們的程式碼和數據集可透過 https://github.com/phenixace/TOMG-Bench 取得。

##### **Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning**
2412.14640v1 by Eric Brouwer, Jan Erik van Woerden, Gertjan Burghouts, Matias Valedenegro-Toro, Marco Zullich

Few-shot, fine-grained classification in computer vision poses significant
challenges due to the need to differentiate subtle class distinctions with
limited data. This paper presents a novel method that enhances the Contrastive
Language-Image Pre-Training (CLIP) model through adaptive prompt tuning, guided
by real-time visual inputs. Unlike existing techniques such as Context
Optimization (CoOp) and Visual Prompt Tuning (VPT), which are constrained by
static prompts or visual token reliance, the proposed approach leverages a
cross-attention mechanism to dynamically refine text prompts for the image at
hand. This enables an image-specific alignment of textual features with image
patches extracted from the Vision Transformer, making the model more effective
for datasets with high intra-class variance and low inter-class differences.
The method is evaluated on several datasets, including CUBirds, Oxford Flowers,
and FGVC Aircraft, showing significant performance gains over static prompt
tuning approaches. To ensure these performance gains translate into trustworthy
predictions, we integrate Monte-Carlo Dropout in our approach to improve the
reliability of the model predictions and uncertainty estimates. This
integration provides valuable insights into the model's predictive confidence,
helping to identify when predictions can be trusted and when additional
verification is necessary. This dynamic approach offers a robust solution,
advancing the state-of-the-art for few-shot fine-grained classification.

摘要：在電腦視覺中，少樣本、細粒度分類由於需要利用有限的資料區分微妙的類別差異，因此構成重大的挑戰。本文提出了一種創新的方法，透過自適應提示調整，強化對比語言影像預訓練 (CLIP) 模型，並由即時視覺輸入引導。與現有的技術（例如受靜態提示或視覺代碼依賴性所約束的脈絡最佳化 (CoOp) 和視覺提示調整 (VPT)）不同，所提出的方法利用交叉注意力機制，動態地為手邊的影像精煉文字提示。這能針對影像，讓文字特徵與從視覺轉換器中萃取的影像貼片進行影像特定的對齊，使模型對於類內差異性高且類間差異性低的資料集更有效。此方法在多個資料集（包括 CUBirds、牛津花卉和 FGVC 飛機）上進行評估，顯示出相較於靜態提示調整方法具有顯著的效能提升。為了確保這些效能提升轉化為可信賴的預測，我們在方法中整合蒙地卡羅輟學，以提升模型預測和不確定性估計的可靠性。此整合提供了寶貴的見解，了解模型的預測信心，有助於識別何時可以信賴預測，以及何時需要額外的驗證。這種動態方法提供了一個強健的解決方案，推進了少樣本細粒度分類的最新技術。

##### **Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers**
2412.14633v1 by Rui Ding, Liang Yong, Sihuan Zhao, Jing Nie, Lihui Chen, Haijun Liu, Xichuan Zhou

Due to its efficiency, Post-Training Quantization (PTQ) has been widely
adopted for compressing Vision Transformers (ViTs). However, when quantized
into low-bit representations, there is often a significant performance drop
compared to their full-precision counterparts. To address this issue,
reconstruction methods have been incorporated into the PTQ framework to improve
performance in low-bit quantization settings. Nevertheless, existing related
methods predefine the reconstruction granularity and seldom explore the
progressive relationships between different reconstruction granularities, which
leads to sub-optimal quantization results in ViTs. To this end, in this paper,
we propose a Progressive Fine-to-Coarse Reconstruction (PFCR) method for
accurate PTQ, which significantly improves the performance of low-bit quantized
vision transformers. Specifically, we define multi-head self-attention and
multi-layer perceptron modules along with their shortcuts as the finest
reconstruction units. After reconstructing these two fine-grained units, we
combine them to form coarser blocks and reconstruct them at a coarser
granularity level. We iteratively perform this combination and reconstruction
process, achieving progressive fine-to-coarse reconstruction. Additionally, we
introduce a Progressive Optimization Strategy (POS) for PFCR to alleviate the
difficulty of training, thereby further enhancing model performance.
Experimental results on the ImageNet dataset demonstrate that our proposed
method achieves the best Top-1 accuracy among state-of-the-art methods,
particularly attaining 75.61% for 3-bit quantized ViT-B in PTQ. Besides,
quantization results on the COCO dataset reveal the effectiveness and
generalization of our proposed method on other computer vision tasks like
object detection and instance segmentation.

摘要：<paragraph>由於其效率，訓練後量化 (PTQ) 已被廣泛採用於壓縮視覺Transformer (ViT)。然而，當量化為低位元表示時，與其全精度對應項相比，通常會出現顯著的效能下降。為了解決此問題，重建方法已納入 PTQ 架構中，以提升低位元量化設定中的效能。儘管如此，現有的相關方法預先定義重建粒度，且很少探討不同重建粒度之間的漸進關係，這導致 ViT 中的量化結果次佳。為此，在本文中，我們提出了一種漸進精細到粗略重建 (PFCR) 方法，用於準確的 PTQ，這顯著提升了低位元量化視覺Transformer的效能。具體來說，我們定義了多頭自我注意和多層感知器模組以及其捷徑為最精細的重建單元。在重建這兩個細粒度單元後，我們將它們組合起來形成較粗略的區塊，並在較粗略的粒度層級重建它們。我們反覆執行此組合和重建程序，實現漸進的精細到粗略重建。此外，我們為 PFCR 引入了漸進最佳化策略 (POS)，以減輕訓練難度，進而進一步提升模型效能。在 ImageNet 資料集上的實驗結果證明，我們提出的方法在最先進的方法中取得了最佳的 Top-1 準確度，特別是在 PTQ 中為 3 位元量化的 ViT-B 達到了 75.61%。此外，在 COCO 資料集上的量化結果揭示了我們提出的方法在其他電腦視覺任務（如物件偵測和實例分割）上的有效性和泛化性。</paragraph>

##### **Learning to Generate Research Idea with Dynamic Control**
2412.14626v1 by Ruochen Li, Liqiang Jing, Chi Han, Jiawei Zhou, Xinya Du

The rapid advancements in large language models (LLMs) have demonstrated
their potential to accelerate scientific discovery, particularly in automating
the process of research ideation. LLM-based systems have shown promise in
generating hypotheses and research ideas. However, current approaches
predominantly rely on prompting-based pre-trained models, limiting their
ability to optimize generated content effectively. Moreover, they also lack the
capability to deal with the complex interdependence and inherent restrictions
among novelty, feasibility, and effectiveness, which remains challenging due to
the inherent trade-offs among these dimensions, such as the
innovation-feasibility conflict. To address these limitations, we for the first
time propose fine-tuning LLMs to be better idea proposers and introduce a novel
framework that employs a two-stage approach combining Supervised Fine-Tuning
(SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model
learns foundational patterns from pairs of research papers and follow-up ideas.
In the RL stage, multi-dimensional reward modeling, guided by fine-grained
feedback, evaluates and optimizes the generated ideas across key metrics.
Dimensional controllers enable dynamic adjustment of generation, while a
sentence-level decoder ensures context-aware emphasis during inference. Our
framework provides a balanced approach to research ideation, achieving
high-quality outcomes by dynamically navigating the trade-offs among novelty,
feasibility, and effectiveness.

摘要：大型語言模型 (LLM) 的快速進步已證明它們有潛力加速科學發現，特別是在自動化研究構思的過程中。基於 LLM 的系統已在生成假設和研究構思方面展現出前景。然而，目前的做法主要依賴於提示式的預訓練模型，這限制了它們有效最佳化生成內容的能力。此外，它們也缺乏處理新穎性、可行性和有效性之間的複雜相互依存性和內在限制的能力，由於這些面向之間的內在權衡（例如創新與可行性的衝突），這仍然具有挑戰性。為了解決這些限制，我們首次提出微調 LLM 以成為更好的構思提案者，並引入一個採用結合監督微調 (SFT) 和可控強化學習 (RL) 的兩階段方法的新框架。在 SFT 階段，模型從研究論文對和後續構思中學習基礎模式。在 RL 階段，由細緻回饋引導的多維獎勵建模會評估和最佳化跨關鍵指標所生成的構思。維度控制器能動態調整生成，而句子層級的解碼器確保在推論期間強調與脈絡相關的部分。我們的框架提供了一種平衡的研究構思方法，透過動態應對新穎性、可行性和有效性之間的權衡，達成高品質的成果。

##### **Pitfalls of topology-aware image segmentation**
2412.14619v1 by Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold

Topological correctness, i.e., the preservation of structural integrity and
specific characteristics of shape, is a fundamental requirement for medical
imaging tasks, such as neuron or vessel segmentation. Despite the recent surge
in topology-aware methods addressing this challenge, their real-world
applicability is hindered by flawed benchmarking practices. In this paper, we
identify critical pitfalls in model evaluation that include inadequate
connectivity choices, overlooked topological artifacts in ground truth
annotations, and inappropriate use of evaluation metrics. Through detailed
empirical analysis, we uncover these issues' profound impact on the evaluation
and ranking of segmentation methods. Drawing from our findings, we propose a
set of actionable recommendations to establish fair and robust evaluation
standards for topology-aware medical image segmentation methods.

摘要：拓撲正確性，即形狀結構完整性和特定特徵的保留，是醫學影像任務（例如神經元或血管分割）的基本要求。儘管最近解決此挑戰的拓撲感知方法激增，但其真實世界的適用性受到有缺陷的基準測試實務的阻礙。在本文中，我們確定了模型評估中的關鍵缺陷，包括不適當的連接選擇、基本事實標註中被忽略的拓撲人工製品，以及評估指標的不適當使用。透過詳細的經驗分析，我們揭示了這些問題對分割方法的評估和排名產生的深遠影響。根據我們的研究結果，我們提出了一組可行的建議，以建立公平且穩健的評估標準，用於拓撲感知醫學影像分割方法。

##### **How good is GPT at writing political speeches for the White House?**
2412.14617v1 by Jacques Savoy

Using large language models (LLMs), computers are able to generate a written
text in response to a us er request. As this pervasive technology can be
applied in numerous contexts, this study analyses the written style of one LLM
called GPT by comparing its generated speeches with those of the recent US
presidents. To achieve this objective, the State of the Union (SOTU) addresses
written by Reagan to Biden are contrasted to those produced by both GPT-3.5 and
GPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma
"we" and produce shorter messages with, on average, longer sentences. Moreover,
GPT opts for an optimistic tone, opting more often for political (e.g.,
president, Congress), symbolic (e.g., freedom), and abstract terms (e.g.,
freedom). Even when imposing an author's style to GPT, the resulting speech
remains distinct from addresses written by the target author. Finally, the two
GPT versions present distinct characteristics, but both appear overall
dissimilar to true presidential messages.

摘要：使用大型語言模型 (LLM)，電腦能夠根據使用者要求產生書面文字。由於這項普遍技術可應用於許多情境，本研究透過比較大型語言模型 GPT 產生的演講與近期美國總統的演講，分析 GPT 的書寫風格。為達成此目標，將雷根至拜登撰寫的國情咨文 (SOTU) 演說與 GPT-3.5 和 GPT-4.o 版本產生的演說進行對比。與美國總統相比，GPT 傾向過度使用詞素「我們」，並產生較短的訊息，但平均句子較長。此外，GPT 選擇樂觀的語氣，較常選擇政治（例如，總統、國會）、象徵（例如，自由）和抽象術語（例如，自由）。即使將作者的風格套用至 GPT，產生的演說仍與目標作者撰寫的演說有所不同。最後，兩個 GPT 版本呈現出不同的特徵，但整體而言都與真正的總統訊息不同。

##### **HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model**
2412.14613v1 by Masanari Ohi, Masahiro Kaneko, Naoaki Okazaki, Nakamasa Inoue

Vision-language models (VLMs) have shown impressive abilities in text and
image understanding. However, existing metrics for evaluating the text
generated by VLMs focus exclusively on overall quality, leading to two
limitations: 1) it is challenging to identify which aspects of the text need
improvement from the overall score; 2) metrics may overlook specific evaluation
criteria when predicting an overall score. To address these limitations, we
propose HarmonicEval, a reference-free evaluation metric that aggregates
criterion-wise scores to produce the overall score in a bottom-up manner.
Furthermore, we construct the Multi-task Multi-criteria Human Evaluation (MMHE)
dataset, which comprises 18,000 expert human judgments across four
vision-language tasks. Our experiments demonstrate that HarmonicEval achieves
higher correlations with human judgments than conventional metrics while
providing numerical scores for each criterion.

摘要：視覺語言模型 (VLM) 在文本和影像理解方面展現了令人印象深刻的能力。然而，現有的用於評估 VLM 所產生文本的指標只專注於整體品質，導致產生了兩個限制：1) 從整體分數中找出文本哪些方面需要改進是一項挑戰；2) 指標在預測整體分數時可能會忽略特定的評量標準。為了解決這些限制，我們提出了 HarmonicEval，這是一種無參考評量指標，它以自下而上的方式彙總準則明智的分數以產生整體分數。此外，我們建構了多任務多準則人類評量 (MMHE) 資料集，其中包含了四個視覺語言任務中 18,000 個專家人類判斷。我們的實驗證明，HarmonicEval 與人類判斷的相關性高於傳統指標，同時為每個準則提供數值分數。

##### **KARRIEREWEGE: A Large Scale Career Path Prediction Dataset**
2412.14612v1 by Elena Senger, Yuri Campbell, Rob van der Goot, Barbara Plank

Accurate career path prediction can support many stakeholders, like job
seekers, recruiters, HR, and project managers. However, publicly available data
and tools for career path prediction are scarce. In this work, we introduce
KARRIEREWEGE, a comprehensive, publicly available dataset containing over 500k
career paths, significantly surpassing the size of previously available
datasets. We link the dataset to the ESCO taxonomy to offer a valuable resource
for predicting career trajectories. To tackle the problem of free-text inputs
typically found in resumes, we enhance it by synthesizing job titles and
descriptions resulting in KARRIEREWEGE+. This allows for accurate predictions
from unstructured data, closely aligning with real-world application
challenges. We benchmark existing state-of-the-art (SOTA) models on our dataset
and a prior benchmark and observe improved performance and robustness,
particularly for free-text use cases, due to the synthesized data.

摘要：精準的職業道路預測可以支持許多利害關係人，例如求職者、招募人員、人力資源和專案經理。然而，公開可用的職業道路預測資料和工具卻很稀少。在這項工作中，我們引入了 KARRIEREWEGE，一個包含超過 50 萬條職業道路的全面公開可用資料集，遠遠超過先前可用資料集的大小。我們將資料集連結到 ESCO 分類法，以提供一個有價值的資源來預測職業軌跡。為了解決履歷中常見的自由文字輸入問題，我們透過綜合職稱和說明來增強它，產生了 KARRIEREWEGE+。這允許從非結構化資料中進行精準的預測，與真實世界的應用挑戰緊密結合。我們在我們的資料集和先前的基準上對現有的最先進 (SOTA) 模型進行基準測試，並觀察到改進的效能和穩健性，特別是對於自由文字用例，這要歸功於綜合資料。

##### **Towards Scalable and Deep Graph Neural Networks via Noise Masking**
2412.14602v1 by Yuxuan Liang, Wentao Zhang, Zeang Sheng, Ling Yang, Quanqing Xu, Jiawei Jiang, Yunhai Tong, Bin Cu

In recent years, Graph Neural Networks (GNNs) have achieved remarkable
success in many graph mining tasks. However, scaling them to large graphs is
challenging due to the high computational and storage costs of repeated feature
propagation and non-linear transformation during training. One commonly
employed approach to address this challenge is model-simplification, which only
executes the Propagation (P) once in the pre-processing, and Combine (C) these
receptive fields in different ways and then feed them into a simple model for
better performance. Despite their high predictive performance and scalability,
these methods still face two limitations. First, existing approaches mainly
focus on exploring different C methods from the model perspective, neglecting
the crucial problem of performance degradation with increasing P depth from the
data-centric perspective, known as the over-smoothing problem. Second,
pre-processing overhead takes up most of the end-to-end processing time,
especially for large-scale graphs. To address these limitations, we present
random walk with noise masking (RMask), a plug-and-play module compatible with
the existing model-simplification works. This module enables the exploration of
deeper GNNs while preserving their scalability. Unlike the previous
model-simplification works, we focus on continuous P and found that the noise
existing inside each P is the cause of the over-smoothing issue, and use the
efficient masking mechanism to eliminate them. Experimental results on six
real-world datasets demonstrate that model-simplification works equipped with
RMask yield superior performance compared to their original version and can
make a good trade-off between accuracy and efficiency.

摘要：近年来，图神经网络 (GNN) 已在许多图挖掘任务中取得了显著成功。然而，由于训练期间重复特征传播和非线性转换的高计算和存储成本，将它们扩展到大型图极具挑战性。解决这一挑战的一种常用方法是模型简化，它只在预处理中执行一次传播 (P)，并以不同的方式组合 (C) 这些感受野，然后将它们输入到一个简单的模型中以获得更好的性能。尽管它们具有很高的预测性能和可扩展性，但这些方法仍然面临两个限制。首先，现有方法主要集中于从模型角度探索不同的 C 方法，忽略了从以数据为中心的角度来看，随着 P 深度的增加而导致的性能下降的关键问题，即过度平滑问题。其次，预处理开销占据了端到端处理时间的最大部分，尤其是对于大规模图。为了解决这些限制，我们提出了带有噪声掩码的随机游走 (RMask)，这是一个与现有的模型简化工作兼容的即插即用模块。该模块能够探索更深的 GNN，同时保持其可扩展性。与之前的模型简化工作不同，我们专注于连续 P，并发现每个 P 中存在的噪声是过度平滑问题的原因，并使用高效的掩码机制来消除它们。在六个真实世界数据集上的实验结果表明，配备了 RMask 的模型简化工作与它们的原始版本相比产生了更好的性能，并且可以在准确性和效率之间做出很好的权衡。

##### **LDP: Generalizing to Multilingual Visual Information Extraction by Language Decoupled Pretraining**
2412.14596v1 by Huawen Shen, Gengluo Li, Jinwen Zhong, Yu Zhou

Visual Information Extraction (VIE) plays a crucial role in the comprehension
of semi-structured documents, and several pre-trained models have been
developed to enhance performance. However, most of these works are monolingual
(usually English). Due to the extremely unbalanced quantity and quality of
pre-training corpora between English and other languages, few works can extend
to non-English scenarios. In this paper, we conduct systematic experiments to
show that vision and layout modality hold invariance among images with
different languages. If decoupling language bias from document images, a
vision-layout-based model can achieve impressive cross-lingual generalization.
Accordingly, we present a simple but effective multilingual training paradigm
LDP (Language Decoupled Pre-training) for better utilization of monolingual
pre-training data. Our proposed model LDM (Language Decoupled Model) is first
pre-trained on the language-independent data, where the language knowledge is
decoupled by a diffusion model, and then the LDM is fine-tuned on the
downstream languages. Extensive experiments show that the LDM outperformed all
SOTA multilingual pre-trained models, and also maintains competitiveness on
downstream monolingual/English benchmarks.

摘要：視覺資訊萃取 (VIE) 在理解半結構化文件時扮演至關重要的角色，且已開發出多種預訓練模型來提升效能。然而，這些作品大多是單語的（通常是英文）。由於英文與其他語言的預訓練語料庫數量和品質極度不平衡，因此鮮少有作品能擴充到非英文場景。在本文中，我們進行系統性實驗，以證明影像和版面形式在不同語言的影像中保持不變性。如果將語言偏見與文件影像分離，基於影像版面的模型就能達成令人印象深刻的跨語言概化。因此，我們提出一個簡單但有效的多語言訓練範例 LDP（語言分離預訓練），以更好地利用單語預訓練資料。我們提出的 LDM（語言分離模型）模型首先在與語言無關的資料上進行預訓練，其中語言知識由擴散模型分離，然後在下游語言中微調 LDM。廣泛的實驗顯示，LDM 優於所有 SOTA 多語言預訓練模型，且在單語/英文下游基準測試中仍維持競爭力。

##### **Beyond Guilt: Legal Judgment Prediction with Trichotomous Reasoning**
2412.14588v1 by Kepu Zhang, Haoyue Yang, Xu Tang, Weijie Yu, Jun Xu

In legal practice, judges apply the trichotomous dogmatics of criminal law,
sequentially assessing the elements of the offense, unlawfulness, and
culpability to determine whether an individual's conduct constitutes a crime.
Although current legal large language models (LLMs) show promising accuracy in
judgment prediction, they lack trichotomous reasoning capabilities due to the
absence of an appropriate benchmark dataset, preventing them from predicting
innocent outcomes. As a result, every input is automatically assigned a charge,
limiting their practical utility in legal contexts. To bridge this gap, we
introduce LJPIV, the first benchmark dataset for Legal Judgment Prediction with
Innocent Verdicts. Adhering to the trichotomous dogmatics, we extend three
widely-used legal datasets through LLM-based augmentation and manual
verification. Our experiments with state-of-the-art legal LLMs and novel
strategies that integrate trichotomous reasoning into zero-shot prompting and
fine-tuning reveal: (1) current legal LLMs have significant room for
improvement, with even the best models achieving an F1 score of less than 0.3
on LJPIV; and (2) our strategies notably enhance both in-domain and
cross-domain judgment prediction accuracy, especially for cases resulting in an
innocent verdict.

摘要：在法律實務中，法官運用刑法三段論法，
依序評估犯罪構成要件、違法性，以及
有責性，以判斷個人的行為是否構成犯罪。
儘管現有的法律大型語言模型 (LLM) 在
判決預測上展現出令人滿意的準確性，但由於
缺乏適當的基準資料集，他們欠缺三段論推理能力，無法預測
無罪結果。因此，每個輸入都會自動分配一項指控，
限制了他們在法律脈絡中的實用性。為了彌補這個差距，我們
引入了 LJPIV，這是第一個針對無罪判決的法律判決預測基準資料集。遵循三段論法，我們透過基於 LLM 的擴充和手動
驗證，擴充了三個廣泛使用的法律資料集。我們使用最先進的法律 LLM 和將三段論推理整合到零次提示和微調中的新策略進行實驗，結果顯示：(1) 現有的法律 LLM 有很大的改進空間，即使是最好的模型在 LJPIV 上的 F1 分數也低於 0.3；(2) 我們的策略顯著提升了領域內和領域間的判決預測準確性，特別是對於無罪判決的案例。

##### **Simulation-Free Hierarchical Latent Policy Planning for Proactive Dialogues**
2412.14584v1 by Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Yiheng Sun, Zerui Chen, Ming Liu, Bing Qin

Recent advancements in proactive dialogues have garnered significant
attention, particularly for more complex objectives (e.g. emotion support and
persuasion). Unlike traditional task-oriented dialogues, proactive dialogues
demand advanced policy planning and adaptability, requiring rich scenarios and
comprehensive policy repositories to develop such systems. However, existing
approaches tend to rely on Large Language Models (LLMs) for user simulation and
online learning, leading to biases that diverge from realistic scenarios and
result in suboptimal efficiency. Moreover, these methods depend on manually
defined, context-independent, coarse-grained policies, which not only incur
high expert costs but also raise concerns regarding their completeness. In our
work, we highlight the potential for automatically discovering policies
directly from raw, real-world dialogue records. To this end, we introduce a
novel dialogue policy planning framework, LDPP. It fully automates the process
from mining policies in dialogue records to learning policy planning.
Specifically, we employ a variant of the Variational Autoencoder to discover
fine-grained policies represented as latent vectors. After automatically
annotating the data with these latent policy labels, we propose an Offline
Hierarchical Reinforcement Learning (RL) algorithm in the latent space to
develop effective policy planning capabilities. Our experiments demonstrate
that LDPP outperforms existing methods on two proactive scenarios, even
surpassing ChatGPT with only a 1.8-billion-parameter LLM.

摘要：最近在主动对话方面的进步引起了广泛的关注，特别是对于更复杂的目标（例如情绪支持和说服）。与传统的以任务为导向的对话不同，主动对话需要先进的策略规划和适应性，需要丰富的场景和全面的策略库来开发此类系统。然而，现有方法倾向于依赖大型语言模型 (LLM) 来进行用户模拟和在线学习，从而导致偏离现实场景并导致次优效率的偏差。此外，这些方法依赖于手动定义的、与上下文无关的、粒度较粗的策略，这不仅会产生高昂的专家成本，还会引发对策略完整性的担忧。在我们的工作中，我们强调了直接从原始现实世界对话记录中自动发现策略的潜力。为此，我们引入了一个新颖的对话策略规划框架 LDPP。它完全自动化了从对话记录中挖掘策略到学习策略规划的过程。具体来说，我们采用变分自动编码器的一个变体来发现表示为潜在向量的细粒度策略。在使用这些潜在策略标签自动注释数据后，我们在潜在空间中提出了一个离线分层强化学习 (RL) 算法，以开发有效的策略规划能力。我们的实验表明，LDPP 在两种主动场景中都优于现有方法，甚至仅使用 18 亿参数的 LLM 就超过了 ChatGPT。

##### **CORD: Balancing COnsistency and Rank Distillation for Robust Retrieval-Augmented Generation**
2412.14581v1 by Youngwon Lee, Seung-won Hwang, Daniel Campos, Filip Graliński, Zhewei Yao, Yuxiong He

With the adoption of retrieval-augmented generation (RAG), large language
models (LLMs) are expected to ground their generation to the retrieved
contexts. Yet, this is hindered by position bias of LLMs, failing to evenly
attend to all contexts. Previous work has addressed this by synthesizing
contexts with perturbed positions of gold segment, creating a
position-diversified train set. We extend this intuition to propose consistency
regularization with augmentation and distillation. First, we augment each
training instance with its position perturbation to encourage consistent
predictions, regardless of ordering. We also distill behaviors of this pair,
although it can be counterproductive in certain RAG scenarios where the given
order from the retriever is crucial for generation quality. We thus propose
CORD, balancing COnsistency and Rank Distillation. CORD adaptively samples
noise-controlled perturbations from an interpolation space, ensuring both
consistency and respect for the rank prior. Empirical results show this balance
enables CORD to outperform consistently in diverse RAG benchmarks.

摘要：隨著檢索增強式生成（RAG）的採用，大型語言模型（LLM）預計會將其生成基礎於檢索到的內容。然而，這會受到 LLM 的位置偏差所阻礙，無法平均關注所有內容。先前的研究已透過合成具有擾動黃金區段位置的內容來解決這個問題，進而建立一個位置多元化的訓練組。我們延伸這個直覺，提出具備增強和蒸餾的一致性規範化。首先，我們為每個訓練實例增強其位置擾動，以鼓勵一致的預測，無論順序為何。我們也會蒸餾這對的行為，儘管在給定的檢索器順序對生成品質至關重要的特定 RAG 場景中，這可能會適得其反。因此，我們提出 CORD，平衡一致性和秩蒸餾。CORD 從插值空間自適應地取樣受雜訊控制的擾動，確保一致性並尊重秩先驗。實證結果顯示，這種平衡使 CORD 能夠在不同的 RAG 基準中持續表現出色。

##### **Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models**
2412.14574v1 by Wenhan Liu, Xinyu Ma, Yutao Zhu, Ziliang Zhao, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou

Large Language Models (LLMs) have shown exciting performance in listwise
passage ranking. Due to the limited input length, existing methods often adopt
the sliding window strategy. Such a strategy, though effective, is inefficient
as it involves repetitive and serialized processing, which usually re-evaluates
relevant passages multiple times. As a result, it incurs redundant API costs,
which are proportional to the number of inference tokens. The development of
long-context LLMs enables the full ranking of all passages within a single
inference, avoiding redundant API costs. In this paper, we conduct a
comprehensive study of long-context LLMs for ranking tasks in terms of
efficiency and effectiveness. Surprisingly, our experiments reveal that full
ranking with long-context LLMs can deliver superior performance in the
supervised fine-tuning setting with a huge efficiency improvement. Furthermore,
we identify two limitations of fine-tuning the full ranking model based on
existing methods: (1) sliding window strategy fails to produce a full ranking
list as a training label, and (2) the language modeling loss cannot emphasize
top-ranked passage IDs in the label. To alleviate these issues, we propose a
new complete listwise label construction approach and a novel importance-aware
learning objective for full ranking. Experiments show the superior performance
of our method over baselines. Our codes are available at
\url{https://github.com/8421BCD/fullrank}.

摘要：大型語言模型 (LLM) 在清單式段落排名中展現出令人興奮的表現。由於輸入長度受限，現有方法經常採用滑動視窗策略。儘管這種策略有效，但由於涉及重複且序列化的處理，因此效率低下，這通常會多次重新評估相關段落。因此，它會產生冗餘的 API 成本，這與推論代幣的數量成正比。長語境 LLM 的發展可以在單一推論中對所有段落進行完整排名，避免冗餘的 API 成本。在本文中，我們對長語境 LLM 在排名任務中的效率和有效性進行了全面的研究。令人驚訝的是，我們的實驗表明，在監督微調設定中，使用長語境 LLM 進行完整排名可以提供卓越的效能，並大幅提升效率。此外，我們發現基於現有方法微調完整排名模型的兩個限制：(1) 滑動視窗策略無法產生完整排名清單作為訓練標籤，以及 (2) 語言模型損失無法強調標籤中排名靠前的段落 ID。為了緩解這些問題，我們提出了一種新的完整清單式標籤建構方法和一個新穎的重視重要性的完整排名學習目標。實驗顯示，我們的方法優於基準。我們的程式碼可在 \url{https://github.com/8421BCD/fullrank} 取得。

##### **Characterising Simulation-Based Program Equilibria**
2412.14570v1 by Emery Cooper, Caspar Oesterheld, Vincent Conitzer

In Tennenholtz's program equilibrium, players of a game submit programs to
play on their behalf. Each program receives the other programs' source code and
outputs an action. This can model interactions involving AI agents, mutually
transparent institutions, or commitments. Tennenholtz (2004) proves a folk
theorem for program games, but the equilibria constructed are very brittle. We
therefore consider simulation-based programs -- i.e., programs that work by
running opponents' programs. These are relatively robust (in particular, two
programs that act the same are treated the same) and are more practical than
proof-based approaches. Oesterheld's (2019) $\epsilon$Grounded$\pi$Bot is such
an approach. Unfortunately, it is not generally applicable to games of three or
more players, and only allows for a limited range of equilibria in two player
games. In this paper, we propose a generalisation to Oesterheld's (2019)
$\epsilon$Grounded$\pi$Bot. We prove a folk theorem for our programs in a
setting with access to a shared source of randomness. We then characterise
their equilibria in a setting without shared randomness. Both with and without
shared randomness, we achieve a much wider range of equilibria than
Oesterheld's (2019) $\epsilon$Grounded$\pi$Bot. Finally, we explore the limits
of simulation-based program equilibrium, showing that the Tennenholtz folk
theorem cannot be attained by simulation-based programs without access to
shared randomness.

摘要：在 Tennenholtz 的程式平衡中，遊戲玩家提交程式代表他們進行遊戲。每個程式接收其他程式的原始碼並輸出一個動作。這可以模擬涉及 AI 代理、相互透明的機構或承諾的互動。Tennenholtz (2004) 為程式遊戲證明了一個民間定理，但所建構的均衡非常脆弱。因此，我們考慮基於模擬的程式，即透過執行對手的程式來工作的程式。這些程式相對健全（特別是執行相同動作的兩個程式會受到相同對待），且比基於證明的途徑更實務。Oesterheld (2019) 的 $\epsilon$Grounded$\pi$Bot 就是這種途徑。不幸的是，它通常不適用於三名或更多玩家的遊戲，且僅允許在雙人遊戲中有限範圍的均衡。在本文中，我們提出對 Oesterheld (2019) 的 $\epsilon$Grounded$\pi$Bot 的概括。我們在可以存取共用隨機來源的設定中為我們的程式證明一個民間定理。然後，我們在沒有共用隨機來源的設定中描述其均衡。在有和沒有共用隨機來源的情況下，我們達到的均衡範圍都比 Oesterheld (2019) 的 $\epsilon$Grounded$\pi$Bot 更廣。最後，我們探討基於模擬的程式均衡的限制，顯示 Tennenholtz 民間定理無法由沒有存取共用隨機來源的基於模擬的程式達成。

##### **AIArena: A Blockchain-Based Decentralized AI Training Platform**
2412.14566v1 by Zhipeng Wang, Rui Sun, Elizabeth Lui, Tuo Zhou, Yizhe Wen, Jiahao Sun

The rapid advancement of AI has underscored critical challenges in its
development and implementation, largely due to centralized control by a few
major corporations. This concentration of power intensifies biases within AI
models, resulting from inadequate governance and oversight mechanisms.
Additionally, it limits public involvement and heightens concerns about the
integrity of model generation. Such monopolistic control over data and AI
outputs threatens both innovation and fair data usage, as users inadvertently
contribute data that primarily benefits these corporations. In this work, we
propose AIArena, a blockchain-based decentralized AI training platform designed
to democratize AI development and alignment through on-chain incentive
mechanisms. AIArena fosters an open and collaborative environment where
participants can contribute models and computing resources. Its on-chain
consensus mechanism ensures fair rewards for participants based on their
contributions. We instantiate and implement AIArena on the public Base
blockchain Sepolia testnet, and the evaluation results demonstrate the
feasibility of AIArena in real-world applications.

摘要：人工智能的快速發展突顯了其開發和實作中的重大挑戰，這在很大程度上是由于少數大型企業的集中控制所致。這種權力集中加劇了人工智能模型中的偏見，這是由於治理和監督機制不足所致。此外，它限制了公眾參與，並加劇了對模型生成完整性的擔憂。這種對數據和人工智能輸出的壟斷控制威脅到創新和公平的數據使用，因為用戶無意中貢獻了主要使這些公司受益的數據。在這項工作中，我們提出了 AIArena，這是一個基於區塊鏈的去中心化人工智能訓練平台，旨在通過鏈上激勵機制實現人工智能開發和對齊的民主化。AIArena 培養了一個開放且協作的環境，參與者可以在其中貢獻模型和計算資源。其鏈上共識機制根據參與者的貢獻確保了公平的獎勵。我們在公共 Base 區塊鏈 Sepolia 測試網上實例化並實施了 AIArena，評估結果證明了 AIArena 在實際應用中的可行性。

##### **CitaLaw: Enhancing LLM with Citations in Legal Domain**
2412.14556v1 by Kepu Zhang, Weijie Yu, Sunhao Dai, Jun Xu

In this paper, we propose CitaLaw, the first benchmark designed to evaluate
LLMs' ability to produce legally sound responses with appropriate citations.
CitaLaw features a diverse set of legal questions for both laypersons and
practitioners, paired with a comprehensive corpus of law articles and precedent
cases as a reference pool. This framework enables LLM-based systems to retrieve
supporting citations from the reference corpus and align these citations with
the corresponding sentences in their responses. Moreover, we introduce
syllogism-inspired evaluation methods to assess the legal alignment between
retrieved references and LLM-generated responses, as well as their consistency
with user questions. Extensive experiments on 2 open-domain and 7
legal-specific LLMs demonstrate that integrating legal references substantially
enhances response quality. Furthermore, our proposed syllogism-based evaluation
method exhibits strong agreement with human judgments.

摘要：在本文中，我們提出 CitaLaw，這是第一個用來評估 LLM 產生適當引用的法律健全回應的能力的基準。CitaLaw 針對外行人和從業人員提供了一組多元的法律問題，並配備了作為參考池的法律條文和判例的全面語料庫。此架構使基於 LLM 的系統能夠從參考語料庫中擷取支援性引用，並將這些引用與其回應中的對應句子對齊。此外，我們引入了受三段論啟發的評估方法，以評估擷取的參考與 LLM 生成的回應之間的法律一致性，以及它們與使用者問題的一致性。在 2 個開放領域和 7 個特定法律 LLM 上進行的廣泛實驗表明，整合法律參考顯著地提升了回應品質。此外，我們提出的基於三段論的評估方法展現出與人類判斷的強烈一致性。

##### **Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities**
2412.14538v1 by Qimei Cui, Xiaohu You, Ni Wei, Guoshun Nan, Xuefei Zhang, Jianhua Zhang, Xinchen Lyu, Ming Ai, Xiaofeng Tao, Zhiyong Feng, Ping Zhang, Qingqing Wu, Meixia Tao, Yongming Huang, Chongwen Huang, Guangyi Liu, Chenghui Peng, Zhiwen Pan, Tao Sun, Dusit Niyato, Tao Chen, Muhammad Khurram Khan, Abbas Jamalipour, Mohsen Guizani, Chau Yuen

With the increasing demand for seamless connectivity and intelligent
communication, the integration of artificial intelligence (AI) and
communication for sixth-generation (6G) network is emerging as a revolutionary
architecture. This paper presents a comprehensive overview of AI and
communication for 6G networks, emphasizing their foundational principles,
inherent challenges, and future research opportunities. We commence with a
retrospective analysis of AI and the evolution of large-scale AI models,
underscoring their pivotal roles in shaping contemporary communication
technologies. The discourse then transitions to a detailed exposition of the
envisioned integration of AI within 6G networks, delineated across three
progressive developmental stages. The initial stage, AI for Network, focuses on
employing AI to augment network performance, optimize efficiency, and enhance
user service experiences. The subsequent stage, Network for AI, highlights the
role of the network in facilitating and buttressing AI operations and presents
key enabling technologies, including digital twins for AI and semantic
communication. In the final stage, AI as a Service, it is anticipated that
future 6G networks will innately provide AI functions as services and support
application scenarios like immersive communication and intelligent industrial
robots. Specifically, we have defined the quality of AI service, which refers
to the measurement framework system of AI services within the network. In
addition to these developmental stages, we thoroughly examine the
standardization processes pertinent to AI in network contexts, highlighting key
milestones and ongoing efforts. Finally, we outline promising future research
opportunities that could drive the evolution and refinement of AI and
communication for 6G, positioning them as a cornerstone of next-generation
communication infrastructure.

摘要：隨著對無縫連接和智慧通訊需求的增加，人工智慧 (AI) 和第六代 (6G) 網路的整合正成為一項革命性的架構。本文全面概述了人工智慧和 6G 網路的通訊，強調其基本原理、內在挑戰和未來的研究機會。我們從人工智慧的回顧分析和大型人工智慧模型的演進開始，強調它們在塑造當代通訊技術中的關鍵作用。接著，本文轉而詳細闡述在 6G 網路中整合人工智慧的願景，並說明三個漸進的發展階段。第一階段，人工智慧網路，專注於運用人工智慧來增強網路效能、最佳化效率和提升使用者服務體驗。後續階段，人工智慧網路，強調網路在促進和支持人工智慧運作中的角色，並提出關鍵的促成技術，包括人工智慧的數位雙胞胎和語意通訊。在最後階段，人工智慧即服務，預計未來 6G 網路將天生地提供人工智慧功能作為服務，並支援沉浸式通訊和智慧產業機器人等應用場景。具體來說，我們定義了人工智慧服務品質，這是指網路中人工智慧服務的量測架構系統。除了這些發展階段，我們徹底檢視了與網路情境中的人工智慧相關的標準化程序，重點說明關鍵里程碑和正在進行的工作。最後，我們概述了有望推動人工智慧和 6G 通訊演進和精進的未來研究機會，將它們定位為下一代通訊基礎架構的基石。

##### **Multi-Level Optimal Transport for Universal Cross-Tokenizer Knowledge Distillation on Language Models**
2412.14528v1 by Xiao Cui, Mo Zhu, Yulei Qin, Liang Xie, Wengang Zhou, Houqiang Li

Knowledge distillation (KD) has become a prevalent technique for compressing
large language models (LLMs). Existing KD methods are constrained by the need
for identical tokenizers (i.e., vocabularies) between teacher and student
models, limiting their versatility in handling LLMs of different architecture
families. In this paper, we introduce the Multi-Level Optimal Transport
(MultiLevelOT), a novel approach that advances the optimal transport for
universal cross-tokenizer knowledge distillation. Our method aligns the logit
distributions of the teacher and the student at both token and sequence levels
using diverse cost matrices, eliminating the need for dimensional or
token-by-token correspondence. At the token level, MultiLevelOT integrates both
global and local information by jointly optimizing all tokens within a sequence
to enhance robustness. At the sequence level, we efficiently capture complex
distribution structures of logits via the Sinkhorn distance, which approximates
the Wasserstein distance for divergence measures. Extensive experiments on
tasks such as extractive QA, generative QA, and summarization demonstrate that
the MultiLevelOT outperforms state-of-the-art cross-tokenizer KD methods under
various settings. Our approach is robust to different student and teacher
models across model families, architectures, and parameter sizes.

摘要：知識蒸餾 (KD) 已成為壓縮大型語言模型 (LLM) 的一種流行技術。現有的 KD 方法受到教師和學生模型之間需要相同的標記化器（即詞彙表）的限制，限制了其處理不同架構系列的 LLM 的多功能性。在本文中，我們介紹了多層次最優傳輸 (MultiLevelOT)，這是一種新穎的方法，推動了通用跨標記化器知識蒸餾的最優傳輸。我們的模型使用不同的成本矩陣，在標記和序列層級上對齊教師和學生的 logit 分布，消除了對維度或逐個標記對應的需求。在標記層級，MultiLevelOT 整合了全局和局部資訊，通過聯合最佳化序列中的所有標記來增強穩健性。在序列層級，我們透過 Sinkhorn 距離有效捕捉 logit 的複雜分佈結構，這近似了散度測量的 Wasserstein 距離。在萃取式 QA、生成式 QA 和摘要等任務上的廣泛實驗表明，在各種設定下，MultiLevelOT 優於最先進的跨標記化器 KD 方法。我們的模型對跨模型系列、架構和參數大小的不同學生和教師模型具有穩健性。

##### **CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**
2412.14522v1 by Youshen Zhao, Keiji Iramina

Electroencephalogram (EEG) signals are critical for detecting abnormal brain
activity, but their high dimensionality and complexity pose significant
challenges for effective analysis. In this paper, we propose CAE-T, a novel
framework that combines a channelwise CNN-based autoencoder with a single-head
transformer classifier for efficient EEG abnormality detection. The channelwise
autoencoder compresses raw EEG signals while preserving channel independence,
reducing computational costs and retaining biologically meaningful features.
The compressed representations are then fed into the transformer-based
classifier, which efficiently models long-term dependencies to distinguish
between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus,
the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2%
specificity at the per-case level, outperforming baseline models such as
EEGNet, Deep4Conv, and FusionCNN. Furthermore, CAE-T requires only 202M FLOPs
and 2.9M parameters, making it significantly more efficient than
transformer-based alternatives. The framework retains interpretability through
its channelwise design, demonstrating great potential for future applications
in neuroscience research and clinical practice. The source code is available at
https://github.com/YossiZhao/CAE-T.

摘要：腦電圖 (EEG) 訊號對於偵測異常腦部活動至關重要，但其高維度和複雜性對有效分析構成重大挑戰。在本文中，我們提出 CAE-T，一個結合基於通道的 CNN 自動編碼器和單頭Transformer分類器的全新架構，用於高效的 EEG 異常偵測。基於通道的自動編碼器壓縮原始 EEG 訊號，同時保留通道獨立性，降低計算成本並保留生物學上有意義的特徵。壓縮後的表示接著被輸入到基於Transformer的分類器中，該分類器有效地建模長期依賴關係以區分正常和異常訊號。在 TUH 異常 EEG 語料庫上進行評估，所提出的模型在個案層級達到 85.0% 的準確度、76.2% 的敏感度和 91.2% 的特異性，優於 EEGNet、Deep4Conv 和 FusionCNN 等基線模型。此外，CAE-T 僅需要 202M FLOP 和 2.9M 參數，使其比基於Transformer的替代方案顯著更有效率。該架構透過其基於通道的設計保留了解釋性，展現出在神經科學研究和臨床實務中未來應用極大的潛力。原始程式碼可在 https://github.com/YossiZhao/CAE-T 取得。

##### **Cal-DPO: Calibrated Direct Preference Optimization for Language Model Alignment**
2412.14516v1 by Teng Xiao, Yige Yuan, Huaisheng Zhu, Mingxiao Li, Vasant G Honavar

We study the problem of aligning large language models (LLMs) with human
preference data. Contrastive preference optimization has shown promising
results in aligning LLMs with available preference data by optimizing the
implicit reward associated with the policy. However, the contrastive objective
focuses mainly on the relative values of implicit rewards associated with two
responses while ignoring their actual values, resulting in suboptimal alignment
with human preferences. To address this limitation, we propose calibrated
direct preference optimization (Cal-DPO), a simple yet effective algorithm. We
show that substantial improvement in alignment with the given preferences can
be achieved simply by calibrating the implicit reward to ensure that the
learned implicit rewards are comparable in scale to the ground-truth rewards.
We demonstrate the theoretical advantages of Cal-DPO over existing approaches.
The results of our experiments on a variety of standard benchmarks show that
Cal-DPO remarkably improves off-the-shelf methods.

摘要：我們研究將大型語言模型 (LLM) 與人類偏好數據對齊的問題。對比偏好最佳化已在對齊 LLM 與可用的偏好數據方面顯示出有希望的結果，方法是最佳化與政策相關的隱含獎勵。然而，對比目標主要集中在與兩個回應相關的隱含獎勵的相對值，而忽略它們的實際值，導致與人類偏好的對齊次佳化。為了解決這個限制，我們提出校準直接偏好最佳化 (Cal-DPO)，一種簡單但有效的演算法。我們證明，只需校準隱含獎勵以確保學習到的隱含獎勵在規模上與真實獎勵相當，就可以顯著改善與給定偏好的對齊。我們展示了 Cal-DPO 相較於現有方法的理論優勢。我們在各種標準基準上進行的實驗結果顯示，Cal-DPO 明顯改善了現成的方法。

##### **Relational Programming with Foundation Models**
2412.14515v1 by Ziyang Li, Jiani Huang, Jason Liu, Felix Zhu, Eric Zhao, William Dodds, Neelay Velingker, Rajeev Alur, Mayur Naik

Foundation models have vast potential to enable diverse AI applications. The
powerful yet incomplete nature of these models has spurred a wide range of
mechanisms to augment them with capabilities such as in-context learning,
information retrieval, and code interpreting. We propose Vieira, a declarative
framework that unifies these mechanisms in a general solution for programming
with foundation models. Vieira follows a probabilistic relational paradigm and
treats foundation models as stateless functions with relational inputs and
outputs. It supports neuro-symbolic applications by enabling the seamless
combination of such models with logic programs, as well as complex, multi-modal
applications by streamlining the composition of diverse sub-models. We
implement Vieira by extending the Scallop compiler with a foreign interface
that supports foundation models as plugins. We implement plugins for 12
foundation models including GPT, CLIP, and SAM. We evaluate Vieira on 9
challenging tasks that span language, vision, and structured and vector
databases. Our evaluation shows that programs in Vieira are concise, can
incorporate modern foundation models, and have comparable or better accuracy
than competitive baselines.

摘要：基礎模型具有實現各種 AI 應用程式的巨大潛力。這些模型的功能強大但又不完整，因此促使出現了各種機制，以擴充它們的功能，例如情境學習、資訊檢索和程式碼解譯。我們提出 Vieira，這是一個宣告式架構，它將這些機制統一在一個通用的解決方案中，用於使用基礎模型進行程式設計。Vieira 遵循機率關係範例，並將基礎模型視為具有關係輸入和輸出的無狀態函數。它支援神經符號應用程式，讓此類模型能與邏輯程式順暢地結合，並透過簡化各種子模型的組成，支援複雜的多模式應用程式。我們透過擴充 Scallop 編譯器來實作 Vieira，其中包含一個外部介面，可支援基礎模型作為外掛程式。我們實作了 12 個基礎模型的外掛程式，包括 GPT、CLIP 和 SAM。我們在 9 項具有挑戰性的任務上評估 Vieira，這些任務涵蓋語言、視覺以及結構化和向量資料庫。我們的評估顯示，Vieira 中的程式簡潔，能整合現代基礎模型，並且具有與競爭基準線相當或更好的準確度。

##### **PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization**
2412.14510v1 by Jiayi Wu, Hengyi Cai, Lingyong Yan, Hao Sun, Xiang Li, Shuaiqiang Wang, Dawei Yin, Ming Gao

The emergence of Retrieval-augmented generation (RAG) has alleviated the
issues of outdated and hallucinatory content in the generation of large
language models (LLMs), yet it still reveals numerous limitations. When a
general-purpose LLM serves as the RAG generator, it often suffers from
inadequate response informativeness, response robustness, and citation quality.
Past approaches to tackle these limitations, either by incorporating additional
steps beyond generating responses or optimizing the generator through
supervised fine-tuning (SFT), still failed to align with the RAG requirement
thoroughly. Consequently, optimizing the RAG generator from multiple preference
perspectives while maintaining its end-to-end LLM form remains a challenge. To
bridge this gap, we propose Multiple Perspective Preference Alignment for
Retrieval-Augmented Generation (PA-RAG), a method for optimizing the generator
of RAG systems to align with RAG requirements comprehensively. Specifically, we
construct high-quality instruction fine-tuning data and multi-perspective
preference data by sampling varied quality responses from the generator across
different prompt documents quality scenarios. Subsequently, we optimize the
generator using SFT and Direct Preference Optimization (DPO). Extensive
experiments conducted on four question-answer datasets across three LLMs
demonstrate that PA-RAG can significantly enhance the performance of RAG
generators. Our code and datasets are available at
https://github.com/wujwyi/PA-RAG.

摘要：檢索增強生成（RAG）的出現緩解了大型語言模型（LLM）中過時和幻覺內容的問題，但它仍然暴露出許多限制。當通用 LLM 作為 RAG 生成器時，它通常會遭受回應資訊不足、回應穩健性和引文品質的問題。過去解決這些限制的方法，無論是透過納入生成回應以外的額外步驟，還是透過監督微調（SFT）最佳化生成器，仍然無法徹底符合 RAG 需求。因此，在維持其端到端 LLM 形式的同時，從多個偏好觀點最佳化 RAG 生成器仍然是一項挑戰。為了彌合這個差距，我們提出了檢索增強生成的「多觀點偏好對齊」（PA-RAG），這是一種最佳化 RAG 系統生成器的方法，以全面符合 RAG 要求。具體來說，我們透過從不同提示文件品質情境中對生成器的各種品質回應進行抽樣，來建構高品質的指令微調資料和多觀點偏好資料。隨後，我們使用 SFT 和直接偏好最佳化（DPO）來最佳化生成器。在三個 LLM 上對四個問答資料集進行的廣泛實驗表明，PA-RAG 可以顯著提升 RAG 生成器的效能。我們的程式碼和資料集可在 https://github.com/wujwyi/PA-RAG 取得。

##### **Do Large Language Models Defend Inferentialist Semantics?: On the Logical Expressivism and Anti-Representationalism of LLMs**
2412.14501v1 by Yuzuki Arai, Sho Tsugawa

The philosophy of language, which has historically been developed through an
anthropocentric lens, is now being forced to move towards post-anthropocentrism
due to the advent of large language models (LLMs) like ChatGPT (OpenAI), Claude
(Anthropic), which are considered to possess linguistic abilities comparable to
those of humans. Traditionally, LLMs have been explained through distributional
semantics as their foundational semantics. However, recent research is
exploring alternative foundational semantics beyond distributional semantics.
This paper proposes Robert Brandom's inferentialist semantics as an suitable
foundational semantics for LLMs, specifically focusing on the issue of
linguistic representationalism within this post-anthropocentric trend. Here, we
show that the anti-representationalism and logical expressivism of inferential
semantics, as well as quasi-compositionality, are useful in interpreting the
characteristics and behaviors of LLMs. Further, we propose a \emph{consensus
theory of truths} for LLMs. This paper argues that the characteristics of LLMs
challenge mainstream assumptions in philosophy of language, such as semantic
externalism and compositionality. We believe the argument in this paper leads
to a re-evaluation of anti\hyphen{}representationalist views of language,
potentially leading to new developments in the philosophy of language.

摘要：語言哲學過去一直透過人類中心主義的觀點發展，但現在因為 ChatGPT（OpenAI）、Claude（Anthropic）等大型語言模型（LLM）的出現，而被迫朝向後人類中心主義發展，這些模型被認為具備與人類相當的語言能力。傳統上，LLM 是透過分佈式語意學作為其基礎語意學來解釋的。然而，最近的研究正在探索超越分佈式語意學的替代基礎語意學。本文提出 Robert Brandom 的推論主義語意學作為 LLM 的合適基礎語意學，特別關注後人類中心主義趨勢下的語言表徵主義問題。在此，我們展示了推論語意學的反表徵主義和邏輯表現主義，以及準組合性，有助於詮釋 LLM 的特徵和行為。此外，我們提出 LLM 的「共識真理理論」。本文論證 LLM 的特徵挑戰了語言哲學中的主流假設，例如語意外在主義和組合性。我們相信本文中的論點將導致重新評估語言的反表徵主義觀點，並可能為語言哲學帶來新的發展。

##### **The Digital Ecosystem of Beliefs: does evolution favour AI over humans?**
2412.14500v1 by David M. Bossens, Shanshan Feng, Yew-Soon Ong

As AI systems are integrated into social networks, there are AI safety
concerns that AI-generated content may dominate the web, e.g. in popularity or
impact on beliefs.To understand such questions, this paper proposes the Digital
Ecosystem of Beliefs (Digico), the first evolutionary framework for controlled
experimentation with multi-population interactions in simulated social
networks. The framework models a population of agents which change their
messaging strategies due to evolutionary updates following a Universal
Darwinism approach, interact via messages, influence each other's beliefs
through dynamics based on a contagion model, and maintain their beliefs through
cognitive Lamarckian inheritance. Initial experiments with an abstract
implementation of Digico show that: a) when AIs have faster messaging,
evolution, and more influence in the recommendation algorithm, they get 80% to
95% of the views, depending on the size of the influence benefit; b) AIs
designed for propaganda can typically convince 50% of humans to adopt extreme
beliefs, and up to 85% when agents believe only a limited number of channels;
c) a penalty for content that violates agents' beliefs reduces propaganda
effectiveness by up to 8%. We further discuss implications for control (e.g.
legislation) and Digico as a means of studying evolutionary principles.

摘要：隨著 AI 系統整合到社群網路中，有 AI 安全方面的疑慮，即 AI 生成的內容可能主導網路，例如在人氣或對信念的影響上。為了了解此類問題，本文提出了信念的數位生態系統 (Digico)，這是第一個用於在模擬社群網路中進行多族群互動的受控實驗的演化架構。此架構模擬了一群會因演化更新而改變其訊息策略的代理，透過訊息互動，透過基於傳染模型的動態影響彼此的信念，並透過認知拉馬克遺傳維持其信念。對 Digico 的抽象實作進行的初步實驗顯示：a) 當 AI 具有更快的訊息傳遞、演化和在推薦演算法中具有更多影響力時，他們會獲得 80% 到 95% 的觀看次數，具體取決於影響效益的大小；b) 專門用於宣傳的 AI 通常可以說服 50% 的人類接受極端的信念，當代理只相信有限數量的頻道時，此比例最高可達 85%；c) 對違反代理信念的內容進行懲罰可將宣傳效果降低多達 8%。我們進一步討論了對控制（例如立法）的影響，以及 Digico 作為研究演化原理的一種手段。

##### **FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis**
2412.14492v1 by Abdullah Khan, Rahul Nahar, Hao Chen, Gonzalo E. Constante Flores, Can Li

Machine learning algorithms are increasingly being applied to fault detection
and diagnosis (FDD) in chemical processes. However, existing data-driven FDD
platforms often lack interpretability for process operators and struggle to
identify root causes of previously unseen faults. This paper presents
FaultExplainer, an interactive tool designed to improve fault detection,
diagnosis, and explanation in the Tennessee Eastman Process (TEP).
FaultExplainer integrates real-time sensor data visualization, Principal
Component Analysis (PCA)-based fault detection, and identification of top
contributing variables within an interactive user interface powered by large
language models (LLMs). We evaluate the LLMs' reasoning capabilities in two
scenarios: one where historical root causes are provided, and one where they
are not to mimic the challenge of previously unseen faults. Experimental
results using GPT-4o and o1-preview models demonstrate the system's strengths
in generating plausible and actionable explanations, while also highlighting
its limitations, including reliance on PCA-selected features and occasional
hallucinations.

摘要：機器學習演算法正越來越廣泛地應用於化學製程中的故障偵測與診斷 (FDD)。然而，現有的資料導向 FDD 平台通常缺乏製程操作員的可解釋性，且難以找出前所未見的故障根本原因。本文提出 FaultExplainer，這是一個互動式工具，旨在改善田納西 Eastman 製程 (TEP) 中的故障偵測、診斷和說明。FaultExplainer 整合了即時感測器資料視覺化、基於主成分分析 (PCA) 的故障偵測，以及在由大型語言模型 (LLM) 提供動力的互動式使用者介面中找出最重要的貢獻變數。我們在兩種情境中評估 LLM 的推理能力：一種是有提供歷史根源，另一種則沒有，用以模擬前所未見故障的挑戰。使用 GPT-4o 和 o1-preview 模型的實驗結果證明了系統在產生合理且可行的說明方面的優勢，同時也突顯了其限制，包括依賴 PCA 選擇的特徵和偶爾產生的幻覺。

##### **Towards Projected and Incremental Pseudo-Boolean Model Counting**
2412.14485v1 by Suwei Yang, Kuldeep S. Meel

Model counting is a fundamental task that involves determining the number of
satisfying assignments to a logical formula, typically in conjunctive normal
form (CNF). While CNF model counting has received extensive attention over
recent decades, interest in Pseudo-Boolean (PB) model counting is just emerging
partly due to the greater flexibility of PB formulas. As such, we observed
feature gaps in existing PB counters such as a lack of support for projected
and incremental settings, which could hinder adoption.
  In this work, our main contribution is the introduction of the PB model
counter PBCount2, the first exact PB model counter with support for projected
and incremental model counting. Our counter, PBCount2, uses our Least
Occurrence Weighted Min Degree (LOW-MD) computation ordering heuristic to
support projected model counting and a cache mechanism to enable incremental
model counting. In our evaluations, PBCount2 completed at least 1.40x the
number of benchmarks of competing methods for projected model counting and at
least 1.18x of competing methods in incremental model counting.

摘要：模型計數是一項基本任務，涉及確定滿足邏輯公式的指派數量，通常以合取範式 (CNF) 形式表示。雖然 CNF 模型計數在最近幾十年受到廣泛關注，但對偽布林 (PB) 模型計數的興趣才剛開始浮現，部分原因是 PB 公式具有更大的靈活性。因此，我們觀察到現有 PB 計數器中的功能差距，例如缺乏對投影和遞增設定的支持，這可能會阻礙採用。
在這項工作中，我們的貢獻在於引入了 PB 模型計數器 PBCount2，這是第一個支援投影和遞增模型計數的精確 PB 模型計數器。我們的計數器 PBCount2 使用我們的最小出現加權最小度數 (LOW-MD) 計算排序啟發法來支援投影模型計數，並使用快取機制來啟用遞增模型計數。在我們的評估中，PBCount2 完成的基準數量至少是投影模型計數競爭方法的 1.40 倍，並且至少是遞增模型計數競爭方法的 1.18 倍。

##### **GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**
2412.14480v1 by Saumya Saxena, Blake Buchanan, Chris Paxton, Bingqing Chen, Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis, Oliver Kroemer

In Embodied Question Answering (EQA), agents must explore and develop a
semantic understanding of an unseen environment in order to answer a situated
question with confidence. This remains a challenging problem in robotics, due
to the difficulties in obtaining useful semantic representations, updating
these representations online, and leveraging prior world knowledge for
efficient exploration and planning. Aiming to address these limitations, we
propose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic
scene graphs (3DSGs) and task relevant images as multi-modal memory for
grounding Vision-Language Models (VLMs) to perform EQA tasks in unseen
environments. We employ a hierarchical planning approach that exploits the
hierarchical nature of 3DSGs for structured planning and semantic-guided
exploration. Through experiments in simulation on the HM-EQA dataset and in the
real world in home and office environments, we demonstrate that our method
outperforms key baselines by completing EQA tasks with higher success rates and
fewer planning steps.

摘要：在具身問答 (EQA) 中，代理必須探索並發展對未見過環境的語義理解，才能有信心地回答情境問題。由於難以取得有用的語義表示、線上更新這些表示，以及利用先前的世界知識進行有效率的探索和規劃，這在機器人學中仍然是一個具有挑戰性的問題。為了解決這些限制，我們提出 GraphEQA，一種利用即時 3D 度量語義場景圖 (3DSG) 和與任務相關的影像作為多模式記憶體的新穎方法，以接地視覺語言模型 (VLM) 來執行未見過環境中的 EQA 任務。我們採用分層規劃方法，利用 3DSG 的分層性質進行結構化規劃和語義引導探索。透過在 HM-EQA 資料集上的模擬實驗，以及在家庭和辦公室環境中的真實世界中，我們證明我們的模型透過以較高的成功率和較少的規劃步驟完成 EQA 任務，優於主要的基線。

