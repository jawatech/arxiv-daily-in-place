{"2407.16171": {"publish_time": "2024-07-23", "title": "Learning Trimodal Relation for AVQA with Missing Modality", "paper_summary": "Recent Audio-Visual Question Answering (AVQA) methods rely on complete visual\nand audio input to answer questions accurately. However, in real-world\nscenarios, issues such as device malfunctions and data transmission errors\nfrequently result in missing audio or visual modality. In such cases, existing\nAVQA methods suffer significant performance degradation. In this paper, we\npropose a framework that ensures robust AVQA performance even when a modality\nis missing. First, we propose a Relation-aware Missing Modal (RMM) generator\nwith Relation-aware Missing Modal Recalling (RMMR) loss to enhance the ability\nof the generator to recall missing modal information by understanding the\nrelationships and context among the available modalities. Second, we design an\nAudio-Visual Relation-aware (AVR) diffusion model with Audio-Visual Enhancing\n(AVE) loss to further enhance audio-visual features by leveraging the\nrelationships and shared cues between the audio-visual modalities. As a result,\nour method can provide accurate answers by effectively utilizing available\ninformation even when input modalities are missing. We believe our method holds\npotential applications not only in AVQA research but also in various\nmulti-modal scenarios.", "paper_summary_zh": "\u6700\u8fd1\u7684\u97f3\u8996\u89ba\u554f\u7b54\uff08AVQA\uff09\u65b9\u6cd5\u4f9d\u8cf4\u65bc\u5b8c\u6574\u7684\u8996\u89ba\u548c\u97f3\u8a0a\u8f38\u5165\uff0c\u624d\u80fd\u6e96\u78ba\u56de\u7b54\u554f\u984c\u3002\u7136\u800c\uff0c\u5728\u73fe\u5be6\u4e16\u754c\u7684\u5834\u666f\u4e2d\uff0c\u8af8\u5982\u88dd\u7f6e\u6545\u969c\u548c\u8cc7\u6599\u50b3\u8f38\u932f\u8aa4\u7b49\u554f\u984c\u7d93\u5e38\u5c0e\u81f4\u97f3\u8a0a\u6216\u8996\u89ba\u6a21\u5f0f\u907a\u5931\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u73fe\u6709\u7684 AVQA \u65b9\u6cd5\u6703\u906d\u53d7\u986f\u8457\u7684\u6548\u80fd\u4e0b\u964d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u6846\u67b6\uff0c\u5373\u4f7f\u5728\u6a21\u5f0f\u907a\u5931\u7684\u60c5\u6cc1\u4e0b\u4e5f\u80fd\u78ba\u4fdd\u7a69\u5065\u7684 AVQA \u6548\u80fd\u3002\u9996\u5148\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5177\u6709\u95dc\u4fc2\u611f\u77e5\u907a\u5931\u6a21\u5f0f\u56de\u61b6\uff08RMMR\uff09\u640d\u5931\u7684\u95dc\u4fc2\u611f\u77e5\u907a\u5931\u6a21\u5f0f\uff08RMM\uff09\u751f\u6210\u5668\uff0c\u4ee5\u589e\u5f37\u751f\u6210\u5668\u900f\u904e\u7406\u89e3\u53ef\u7528\u6a21\u5f0f\u4e4b\u9593\u7684\u95dc\u4fc2\u548c\u80cc\u666f\u4f86\u56de\u61b6\u907a\u5931\u6a21\u5f0f\u8cc7\u8a0a\u7684\u80fd\u529b\u3002\u5176\u6b21\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u5177\u6709\u97f3\u8996\u89ba\u589e\u5f37\uff08AVE\uff09\u640d\u5931\u7684\u97f3\u8996\u89ba\u95dc\u4fc2\u611f\u77e5\uff08AVR\uff09\u64f4\u6563\u6a21\u578b\uff0c\u4ee5\u9032\u4e00\u6b65\u589e\u5f37\u97f3\u8996\u89ba\u7279\u5fb5\uff0c\u65b9\u6cd5\u662f\u5229\u7528\u97f3\u8996\u89ba\u6a21\u5f0f\u4e4b\u9593\u7684\u95dc\u4fc2\u548c\u5171\u4eab\u63d0\u793a\u3002\u56e0\u6b64\uff0c\u5373\u4f7f\u8f38\u5165\u6a21\u5f0f\u907a\u5931\uff0c\u6211\u5011\u7684\u6a21\u578b\u4e5f\u80fd\u900f\u904e\u6709\u6548\u5229\u7528\u53ef\u7528\u8cc7\u8a0a\u63d0\u4f9b\u6e96\u78ba\u7684\u7b54\u6848\u3002\u6211\u5011\u76f8\u4fe1\u6211\u5011\u7684\u6a21\u578b\u4e0d\u50c5\u5728 AVQA \u7814\u7a76\u4e2d\u5177\u6709\u6f5b\u5728\u61c9\u7528\uff0c\u5728\u5404\u7a2e\u591a\u6a21\u5f0f\u5834\u666f\u4e2d\u4e5f\u5177\u6709\u6f5b\u5728\u61c9\u7528\u3002", "author": "Kyu Ri Park et.al.", "authors": "Kyu Ri Park, Hong Joo Lee, Jung Uk Kim", "id": "2407.16171v1", "paper_url": "http://arxiv.org/abs/2407.16171v1", "repo": "https://github.com/visualaikhu/missing-avqa"}}