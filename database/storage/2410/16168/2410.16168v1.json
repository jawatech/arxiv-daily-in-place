{"2410.16168": {"publish_time": "2024-10-21", "title": "Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models", "paper_summary": "Large Language Models (LLMs) demonstrate exceptional capabilities in a\nmultitude of NLP tasks. However, the efficacy of such models to languages other\nthan English is often limited. Prior works have shown that encoder-only models\nsuch as BERT or XLM-RoBERTa show impressive cross lingual transfer of their\ncapabilities from English to other languages. In this work, we propose a\npretraining strategy that uses active forgetting to achieve similar cross\nlingual transfer in decoder-only LLMs. We show that LLMs pretrained with active\nforgetting are highly effective when adapting to new and unseen languages.\nThrough extensive experimentation, we find that LLMs pretrained with active\nforgetting are able to learn better multilingual representations which\ntranslates to better performance in many downstream tasks.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5927\u91cf\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u6b64\u985e\u6a21\u578b\u5728\u82f1\u8a9e\u4ee5\u5916\u7684\u8a9e\u8a00\u4e2d\uff0c\u5176\u6548\u80fd\u5f80\u5f80\u53d7\u5230\u9650\u5236\u3002\u5148\u524d\u7684\u7814\u7a76\u986f\u793a\uff0c\u50c5\u7de8\u78bc\u5668\u6a21\u578b\uff08\u4f8b\u5982 BERT \u6216 XLM-RoBERTa\uff09\u5c55\u73fe\u51fa\u5176\u80fd\u529b\u5f9e\u82f1\u8a9e\u8f49\u79fb\u81f3\u5176\u4ed6\u8a9e\u8a00\u7684\u9a5a\u4eba\u8de8\u8a9e\u8a00\u8f49\u79fb\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u9810\u8a13\u7df4\u7b56\u7565\uff0c\u8a72\u7b56\u7565\u4f7f\u7528\u4e3b\u52d5\u907a\u5fd8\u4f86\u9054\u6210\u50c5\u89e3\u78bc\u5668 LLM \u4e2d\u985e\u4f3c\u7684\u8de8\u8a9e\u8a00\u8f49\u79fb\u3002\u6211\u5011\u8b49\u660e\u4e86\u4f7f\u7528\u4e3b\u52d5\u907a\u5fd8\u9032\u884c\u9810\u8a13\u7df4\u7684 LLM \u5728\u9069\u61c9\u65b0\u7684\u548c\u672a\u898b\u904e\u7684\u8a9e\u8a00\u6642\u975e\u5e38\u6709\u6548\u3002\u900f\u904e\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6211\u5011\u767c\u73fe\u4f7f\u7528\u4e3b\u52d5\u907a\u5fd8\u9032\u884c\u9810\u8a13\u7df4\u7684 LLM \u80fd\u5920\u5b78\u7fd2\u5230\u66f4\u597d\u7684\u591a\u8a9e\u8a00\u8868\u5fb5\uff0c\u9019\u8f49\u5316\u70ba\u5728\u8a31\u591a\u4e0b\u6e38\u4efb\u52d9\u4e2d\u7372\u5f97\u66f4\u597d\u7684\u6548\u80fd\u3002", "author": "Divyanshu Aggarwal et.al.", "authors": "Divyanshu Aggarwal, Ashutosh Sathe, Sunayana Sitaram", "id": "2410.16168v1", "paper_url": "http://arxiv.org/abs/2410.16168v1", "repo": "null"}}