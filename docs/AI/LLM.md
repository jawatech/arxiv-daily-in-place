
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-21**|**Learning segmentation from point trajectories**|Laurynas Karazija et.al.|[2501.12392v1](http://arxiv.org/abs/2501.12392v1)|null|
|**2025-01-21**|**Physics of Skill Learning**|Ziming Liu et.al.|[2501.12391v1](http://arxiv.org/abs/2501.12391v1)|[link](https://github.com/kindxiaoming/physics_of_skill_learning)|
|**2025-01-21**|**MMVU: Measuring Expert-Level Multi-Discipline Video Understanding**|Yilun Zhao et.al.|[2501.12380v1](http://arxiv.org/abs/2501.12380v1)|[link](https://github.com/yale-nlp/mmvu)|
|**2025-01-21**|**Video Depth Anything: Consistent Depth Estimation for Super-Long Videos**|Sili Chen et.al.|[2501.12375v1](http://arxiv.org/abs/2501.12375v1)|null|
|**2025-01-21**|**Expertise elevates AI usage: experimental evidence comparing laypeople and professional artists**|Thomas F. Eisenmann et.al.|[2501.12374v1](http://arxiv.org/abs/2501.12374v1)|[link](https://github.com/andreskarjus/genaiexperiment)|
|**2025-01-21**|**Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL**|Yeounoh Chung et.al.|[2501.12372v1](http://arxiv.org/abs/2501.12372v1)|null|
|**2025-01-21**|**Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models**|Samira Abnar et.al.|[2501.12370v1](http://arxiv.org/abs/2501.12370v1)|null|
|**2025-01-21**|**InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model**|Yuhang Zang et.al.|[2501.12368v1](http://arxiv.org/abs/2501.12368v1)|[link](https://github.com/internlm/internlm-xcomposer)|
|**2025-01-21**|**Test-time regression: a unifying framework for designing sequence models with associative memory**|Ke Alexander Wang et.al.|[2501.12352v1](http://arxiv.org/abs/2501.12352v1)|null|
|**2025-01-21**|**Treefix: Enabling Execution with a Tree of Prefixes**|Beatriz Souza et.al.|[2501.12339v1](http://arxiv.org/abs/2501.12339v1)|null|
|**2025-01-21**|**FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**|Phuoc Duong Huy Chu et.al.|[2501.12336v1](http://arxiv.org/abs/2501.12336v1)|null|
|**2025-01-21**|**Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration**|Thomas Walshe et.al.|[2501.12332v1](http://arxiv.org/abs/2501.12332v1)|null|
|**2025-01-21**|**UI-TARS: Pioneering Automated GUI Interaction with Native Agents**|Yujia Qin et.al.|[2501.12326v1](http://arxiv.org/abs/2501.12326v1)|[link](https://github.com/bytedance/ui-tars)|
|**2025-01-21**|**LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**|Hasan Abu-Rasheed et.al.|[2501.12300v1](http://arxiv.org/abs/2501.12300v1)|null|
|**2025-01-21**|**RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning**|Jiacheng Zuo et.al.|[2501.12296v1](http://arxiv.org/abs/2501.12296v1)|[link](https://github.com/jiachengzuo/ralad)|
|**2025-01-21**|**With Great Backbones Comes Great Adversarial Transferability**|Erik Arakelyan et.al.|[2501.12275v1](http://arxiv.org/abs/2501.12275v1)|null|
|**2025-01-21**|**Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement**|Maosong Cao et.al.|[2501.12273v1](http://arxiv.org/abs/2501.12273v1)|null|
|**2025-01-21**|**CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**|Cristiano Patr√≠cio et.al.|[2501.12266v1](http://arxiv.org/abs/2501.12266v1)|null|
|**2025-01-21**|**FOCUS: First Order Concentrated Updating Scheme**|Yizhou Liu et.al.|[2501.12243v1](http://arxiv.org/abs/2501.12243v1)|null|
|**2025-01-21**|**InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**|Pha Nguyen et.al.|[2501.12231v1](http://arxiv.org/abs/2501.12231v1)|null|
|**2025-01-21**|**Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model**|Kazi Hasan Ibn Arif et.al.|[2501.12206v1](http://arxiv.org/abs/2501.12206v1)|null|
|**2025-01-21**|**An End-to-End Approach for Korean Wakeword Systems with Speaker Authentication**|Geonwoo Seo et.al.|[2501.12194v1](http://arxiv.org/abs/2501.12194v1)|[link](https://github.com/gws8820/securewakeword-model)|
|**2025-01-21**|**AdaServe: SLO-Customized LLM Serving with Fine-Grained Speculative Decoding**|Zikun Li et.al.|[2501.12162v1](http://arxiv.org/abs/2501.12162v1)|null|
|**2025-01-21**|**On the practical applicability of modern DFT functionals for chemical computations. Case study of DM21 applicability for geometry optimization**|Kirill Kulaev et.al.|[2501.12149v1](http://arxiv.org/abs/2501.12149v1)|null|
|**2025-01-21**|**Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities**|Qirun Dai et.al.|[2501.12147v1](http://arxiv.org/abs/2501.12147v1)|null|
|**2025-01-21**|**FedCLEAN: byzantine defense by CLustering Errors of Activation maps in Non-IID federated learning environments**|Mehdi Ben Ghali et.al.|[2501.12123v1](http://arxiv.org/abs/2501.12123v1)|null|
|**2025-01-21**|**Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**|Stefan Lenz et.al.|[2501.12106v1](http://arxiv.org/abs/2501.12106v1)|[link](https://github.com/stefan-m-lenz/urollmeval)|
|**2025-01-21**|**Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection**|ShiXuan Song et.al.|[2501.12104v1](http://arxiv.org/abs/2501.12104v1)|null|
|**2025-01-21**|**Proxies for Distortion and Consistency with Applications for Real-World Image Restoration**|Sean Man et.al.|[2501.12102v1](http://arxiv.org/abs/2501.12102v1)|null|
|**2025-01-21**|**Scalable Whole Slide Image Representation Using K-Mean Clustering and Fisher Vector Aggregation**|Ravi Kant Gupta et.al.|[2501.12085v1](http://arxiv.org/abs/2501.12085v1)|null|
|**2025-01-21**|**EDoRA: Efficient Weight-Decomposed Low-Rank Adaptation via Singular Value Decomposition**|Hamid Nasiri et.al.|[2501.12067v1](http://arxiv.org/abs/2501.12067v1)|[link](https://github.com/hamid-nasiri/edora)|
|**2025-01-21**|**MedS$^3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking**|Shuyang Jiang et.al.|[2501.12051v1](http://arxiv.org/abs/2501.12051v1)|[link](https://github.com/pixas/medsss)|
|**2025-01-21**|**Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**|Shramana Dey et.al.|[2501.12048v1](http://arxiv.org/abs/2501.12048v1)|null|
|**2025-01-21**|**Harnessing Generative Pre-Trained Transformer for Datacenter Packet Trace Generation**|Chen Griner et.al.|[2501.12033v1](http://arxiv.org/abs/2501.12033v1)|null|
|**2025-01-21**|**Reference-free Evaluation Metrics for Text Generation: A Survey**|Takumi Ito et.al.|[2501.12011v1](http://arxiv.org/abs/2501.12011v1)|null|
|**2025-01-21**|**Survey on Hand Gesture Recognition from Visual Input**|Manousos Linardakis et.al.|[2501.11992v1](http://arxiv.org/abs/2501.11992v1)|null|
|**2025-01-21**|**Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**|Maya Medjad et.al.|[2501.11977v1](http://arxiv.org/abs/2501.11977v1)|null|
|**2025-01-21**|**Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**|Jie Zhao et.al.|[2501.11968v1](http://arxiv.org/abs/2501.11968v1)|null|
|**2025-01-21**|**A Hybrid Attention Framework for Fake News Detection with Large Language Models**|Xiaochuan Xu et.al.|[2501.11967v1](http://arxiv.org/abs/2501.11967v1)|null|
|**2025-01-21**|**TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection**|Yang Cao et.al.|[2501.11960v1](http://arxiv.org/abs/2501.11960v1)|null|
|**2025-01-21**|**Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model**|Minghan Wang et.al.|[2501.11953v1](http://arxiv.org/abs/2501.11953v1)|null|
|**2025-01-21**|**HERITAGE: An End-to-End Web Platform for Processing Korean Historical Documents in Hanja**|Seyoung Song et.al.|[2501.11951v1](http://arxiv.org/abs/2501.11951v1)|[link](https://github.com/seyoungsong/hanja-platform)|
|**2025-01-21**|**Webvs. LLMs: An Empirical Study of Learning Behaviors of CS2 Students**|Aayush Kumar et.al.|[2501.11935v1](http://arxiv.org/abs/2501.11935v1)|null|
|**2025-01-21**|**A Lightweight and Interpretable Deepfakes Detection Framework**|Muhammad Umar Farooq et.al.|[2501.11927v1](http://arxiv.org/abs/2501.11927v1)|null|
|**2025-01-21**|**LuxVeri at GenAI Detection Task 3: Cross-Domain Detection of AI-Generated Text Using Inverse Perplexity-Weighted Ensemble of Fine-Tuned Transformer Models**|Md Kamrujjaman Mobin et.al.|[2501.11918v1](http://arxiv.org/abs/2501.11918v1)|null|
|**2025-01-21**|**LuxVeri at GenAI Detection Task 1: Inverse Perplexity Weighted Ensemble for Robust Detection of AI-Generated Text across English and Multilingual Contexts**|Md Kamrujjaman Mobin et.al.|[2501.11914v1](http://arxiv.org/abs/2501.11914v1)|null|
|**2025-01-21**|**Bridging the Communication Gap: Evaluating AI Labeling Practices for Trustworthy AI Development**|Raphael Fischer et.al.|[2501.11909v1](http://arxiv.org/abs/2501.11909v1)|[link](https://github.com/raphischer/labeling-evaluation)|
|**2025-01-21**|**Panoramic Interests: Stylistic-Content Aware Personalized Headline Generation**|Junhong Lian et.al.|[2501.11900v1](http://arxiv.org/abs/2501.11900v1)|[link](https://github.com/ictmldm/SCAPE)|
|**2025-01-21**|**Systematic Abductive Reasoning via Diverse Relation Representations in Vector-symbolic Architecture**|Zhong-Hua Sun et.al.|[2501.11896v1](http://arxiv.org/abs/2501.11896v1)|null|
|**2025-01-21**|**Med-R$^2$: Crafting Trustworthy LLM Physicians through Retrieval and Reasoning of Evidence-Based Medicine**|Keer Lu et.al.|[2501.11885v1](http://arxiv.org/abs/2501.11885v1)|null|
|**2025-01-21**|**Community-Aware Temporal Walks: Parameter-Free Representation Learning on Continuous-Time Dynamic Graphs**|He Yu et.al.|[2501.11880v1](http://arxiv.org/abs/2501.11880v1)|[link](https://github.com/leonyuhe/ctwalks)|
|**2025-01-21**|**From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning**|Yafu Li et.al.|[2501.11877v1](http://arxiv.org/abs/2501.11877v1)|[link](https://github.com/linzwcs/aft)|
|**2025-01-21**|**Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models**|Zihan Qiu et.al.|[2501.11873v1](http://arxiv.org/abs/2501.11873v1)|null|
|**2025-01-21**|**EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents**|Zhili Cheng et.al.|[2501.11858v1](http://arxiv.org/abs/2501.11858v1)|[link](https://github.com/thunlp/embodiedeval)|
|**2025-01-21**|**Cross-Entropy Attacks to Language Models via Rare Event Simulation**|Mingze Ni et.al.|[2501.11852v1](http://arxiv.org/abs/2501.11852v1)|null|
|**2025-01-21**|**Challenges in Expanding Portuguese Resources: A View from Open Information Extraction**|Marlo Souza et.al.|[2501.11851v1](http://arxiv.org/abs/2501.11851v1)|null|
|**2025-01-21**|**Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**|Nikos Kanakaris et.al.|[2501.11849v1](http://arxiv.org/abs/2501.11849v1)|[link](https://github.com/nkanak/brag-fake-news-campaigns)|
|**2025-01-21**|**A Survey on Memory-Efficient Large-Scale Model Training in AI for Science**|Kaiyuan Tian et.al.|[2501.11847v1](http://arxiv.org/abs/2501.11847v1)|null|
|**2025-01-21**|**Supervised Learning for Analog and RF Circuit Design: Benchmarks and Comparative Insights**|Asal Mehradfar et.al.|[2501.11839v1](http://arxiv.org/abs/2501.11839v1)|null|
|**2025-01-21**|**Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**|Saeid Ataei et.al.|[2501.11836v1](http://arxiv.org/abs/2501.11836v1)|null|
|**2025-01-21**|**Is your LLM trapped in a Mental Set? Investigative study on how mental sets affect the reasoning capabilities of LLMs**|Saiful Haq et.al.|[2501.11833v1](http://arxiv.org/abs/2501.11833v1)|null|
|**2025-01-21**|**PXGen: A Post-hoc Explainable Method for Generative Models**|Yen-Lung Huang et.al.|[2501.11827v1](http://arxiv.org/abs/2501.11827v1)|null|
|**2025-01-21**|**Toward Scalable Graph Unlearning: A Node Influence Maximization based Approach**|Xunkai Li et.al.|[2501.11823v1](http://arxiv.org/abs/2501.11823v1)|null|
|**2025-01-21**|**Toward Effective Digraph Representation Learning: A Magnetic Adaptive Propagation based Approach**|Xunkai Li et.al.|[2501.11817v1](http://arxiv.org/abs/2501.11817v1)|null|
|**2025-01-21**|**Policy-Adaptable Methods For Resolving Normative Conflicts Through Argumentation and Graph Colouring**|Johnny Joyce et.al.|[2501.11799v1](http://arxiv.org/abs/2501.11799v1)|null|
|**2025-01-20**|**Benchmarking Large Language Models via Random Variables**|Zijin Hong et.al.|[2501.11790v1](http://arxiv.org/abs/2501.11790v1)|null|
|**2025-01-20**|**Synthetic Data Can Mislead Evaluations: Membership Inference as Machine Text Detection**|Ali Naseh et.al.|[2501.11786v1](http://arxiv.org/abs/2501.11786v1)|null|
|**2025-01-20**|**Human-AI Collaborative Game Testing with Vision Language Models**|Boran Zhang et.al.|[2501.11782v1](http://arxiv.org/abs/2501.11782v1)|null|
|**2025-01-20**|**The Value of Nothing: Multimodal Extraction of Human Values Expressed by TikTok Influencers**|Alina Starovolsky-Shitrit et.al.|[2501.11770v1](http://arxiv.org/abs/2501.11770v1)|null|
|**2025-01-20**|**Is logical analysis performed by transformers taking place in self-attention or in the fully connected part?**|Evgeniy Shin et.al.|[2501.11765v1](http://arxiv.org/abs/2501.11765v1)|null|
|**2025-01-20**|**Optimizing Pretraining Data Mixtures with LLM-Estimated Utility**|William Held et.al.|[2501.11747v1](http://arxiv.org/abs/2501.11747v1)|null|
|**2025-01-20**|**SILO: Solving Inverse Problems with Latent Operators**|Ron Raphaeli et.al.|[2501.11746v1](http://arxiv.org/abs/2501.11746v1)|null|
|**2025-01-20**|**Episodic memory in AI agents poses risks that should be studied and mitigated**|Chad DeChant et.al.|[2501.11739v1](http://arxiv.org/abs/2501.11739v1)|null|
|**2025-01-20**|**Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks**|Zhenhailong Wang et.al.|[2501.11733v1](http://arxiv.org/abs/2501.11733v1)|null|
|**2025-01-20**|**Transformer Vibration Forecasting for Advancing Rail Safety and Maintenance 4.0**|Dar√≠o C. Larese et.al.|[2501.11730v1](http://arxiv.org/abs/2501.11730v1)|null|
|**2025-01-20**|**Explain-Query-Test: Self-Evaluating LLMs Via Explanation and Comprehension Discrepancy**|Saeid Asgari Taghanaki et.al.|[2501.11721v1](http://arxiv.org/abs/2501.11721v1)|[link](https://github.com/asgsaeid/eqt)|
|**2025-01-20**|**GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**|Wenjie Kang et.al.|[2501.11715v1](http://arxiv.org/abs/2501.11715v1)|null|
|**2025-01-20**|**YouLeQD: Decoding the Cognitive Complexity of Questions and Engagement in Online Educational Videos from Learners' Perspectives**|Nong Ming et.al.|[2501.11712v1](http://arxiv.org/abs/2501.11712v1)|[link](https://github.com/jiho-yesnlp/qytl)|
|**2025-01-20**|**Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**|Brian E. Perron et.al.|[2501.11705v1](http://arxiv.org/abs/2501.11705v1)|null|
|**2025-01-20**|**Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling**|Zhenyu Hou et.al.|[2501.11651v1](http://arxiv.org/abs/2501.11651v1)|[link](https://github.com/thudm/t1)|
|**2025-01-20**|**StAyaL | Multilingual Style Transfer**|Karishma Thakrar et.al.|[2501.11639v1](http://arxiv.org/abs/2501.11639v1)|null|
|**2025-01-20**|**Noise-Agnostic Multitask Whisper Training for Reducing False Alarm Errors in Call-for-Help Detection**|Myeonghoon Ryu et.al.|[2501.11631v1](http://arxiv.org/abs/2501.11631v1)|null|
|**2025-01-20**|**Early evidence of how LLMs outperform traditional systems on OCR/HTR tasks for historical records**|Seorin Kim et.al.|[2501.11623v1](http://arxiv.org/abs/2501.11623v1)|null|
|**2025-01-20**|**Trojan Detection Through Pattern Recognition for Large Language Models**|Vedant Bhasin et.al.|[2501.11621v1](http://arxiv.org/abs/2501.11621v1)|null|
|**2025-01-20**|**Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems**|Giorgio Robino et.al.|[2501.11613v1](http://arxiv.org/abs/2501.11613v1)|null|
|**2025-01-20**|**SR-FoT: A Syllogistic-Reasoning Framework of Thought for Large Language Models Tackling Knowledge-based Reasoning Tasks**|Wentao Wan et.al.|[2501.11599v1](http://arxiv.org/abs/2501.11599v1)|null|
|**2025-01-20**|**Fairness Testing through Extreme Value Theory**|Verya Monjezi et.al.|[2501.11597v1](http://arxiv.org/abs/2501.11597v1)|null|
|**2025-01-20**|**Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**|Chaoqing Tang et.al.|[2501.11592v1](http://arxiv.org/abs/2501.11592v1)|null|
|**2025-01-20**|**Recurrent Diffusion for Large-Scale Parameter Generation**|Kai Wang et.al.|[2501.11587v1](http://arxiv.org/abs/2501.11587v1)|[link](https://github.com/nus-hpc-ai-lab/recurrent-parameter-generation)|
|**2025-01-20**|**Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**|M. Manzour et.al.|[2501.11560v1](http://arxiv.org/abs/2501.11560v1)|null|
|**2025-01-20**|**PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation**|Jinyu Wang et.al.|[2501.11551v1](http://arxiv.org/abs/2501.11551v1)|null|
|**2025-01-20**|**Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas**|Nishant Balepur et.al.|[2501.11549v1](http://arxiv.org/abs/2501.11549v1)|[link](https://github.com/pinafore/alignment-personalization)|
|**2025-01-20**|**Technical Report for the Forgotten-by-Design Project: Targeted Obfuscation for Machine Learning**|Rickard Br√§nnvall et.al.|[2501.11525v1](http://arxiv.org/abs/2501.11525v1)|null|
|**2025-01-20**|**Dialect2SQL: A Novel Text-to-SQL Dataset for Arabic Dialects with a Focus on Moroccan Darija**|Salmane Chafik et.al.|[2501.11498v1](http://arxiv.org/abs/2501.11498v1)|null|
|**2025-01-20**|**Generative AI and Large Language Models in Language Preservation: Opportunities and Challenges**|Vincent Koc et.al.|[2501.11496v1](http://arxiv.org/abs/2501.11496v1)|null|
|**2025-01-20**|**Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification**|Jonas Klotz et.al.|[2501.11493v1](http://arxiv.org/abs/2501.11493v1)|null|
|**2025-01-20**|**Graph-defined Language Learning with LLMs**|Huachi Zhou et.al.|[2501.11478v1](http://arxiv.org/abs/2501.11478v1)|null|
|**2025-01-20**|**Curiosity-Driven Reinforcement Learning from Human Feedback**|Haoran Sun et.al.|[2501.11463v1](http://arxiv.org/abs/2501.11463v1)|null|
|**2025-01-20**|**Improving thermal state preparation of Sachdev-Ye-Kitaev model with reinforcement learning on quantum hardware**|Akash Kundu et.al.|[2501.11454v1](http://arxiv.org/abs/2501.11454v1)|null|
|**2025-01-20**|**Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components**|Abel Jansma et.al.|[2501.11447v1](http://arxiv.org/abs/2501.11447v1)|null|

#### Abstracts
##### **Learning segmentation from point trajectories**
2501.12392v1 by Laurynas Karazija, Iro Laina, Christian Rupprecht, Andrea Vedaldi

We consider the problem of segmenting objects in videos based on their motion
and no other forms of supervision. Prior work has often approached this problem
by using the principle of common fate, namely the fact that the motion of
points that belong to the same object is strongly correlated. However, most
authors have only considered instantaneous motion from optical flow. In this
work, we present a way to train a segmentation network using long-term point
trajectories as a supervisory signal to complement optical flow. The key
difficulty is that long-term motion, unlike instantaneous motion, is difficult
to model -- any parametric approximation is unlikely to capture complex motion
patterns over long periods of time. We instead draw inspiration from subspace
clustering approaches, proposing a loss function that seeks to group the
trajectories into low-rank matrices where the motion of object points can be
approximately explained as a linear combination of other point tracks. Our
method outperforms the prior art on motion-based segmentation, which shows the
utility of long-term motion and the effectiveness of our formulation.

ÊëòË¶ÅÔºöÊàëÂÄëËÄÉÊÖÆÂü∫ÊñºÈÅãÂãïÂíåÊ≤íÊúâÂÖ∂‰ªñÂΩ¢ÂºèÁöÑÁõ£Áù£‰æÜÂàÜÂâ≤ÂΩ±Áâá‰∏≠ÁöÑÁâ©È´îÁöÑÂïèÈ°å„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÈÄöÂ∏∏ÈÄèÈÅé‰ΩøÁî®ÂÖ±ÂêåÂëΩÈÅãÁöÑÂéüÁêÜ‰æÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°åÔºå‰πüÂ∞±ÊòØÂ±¨ÊñºÂêå‰∏ÄÂÄãÁâ©È´îÁöÑÈªûÁöÑÈÅãÂãïÂÖ∑ÊúâÂº∑ÈóúËÅØÊÄß„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏‰ΩúËÄÖÂè™ËÄÉÊÖÆ‰∫ÜÂÖâÊµÅÁöÑÁû¨ÊôÇÈÅãÂãï„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Èï∑ÊúüÈªûËªåË∑°‰ΩúÁÇ∫Áõ£Áù£Ë®äËôü‰æÜË®ìÁ∑¥ÂàÜÂâ≤Á∂≤Ë∑ØÁöÑÊñπÊ≥ïÔºå‰ª•Ë£úÂÖÖÂÖâÊµÅ„ÄÇÈóúÈçµÁöÑÈõ£ËôïÂú®ÊñºÔºåÈï∑ÊúüÈÅãÂãï‰∏çÂÉèÁû¨ÊôÇÈÅãÂãïÔºåÈõ£‰ª•Âª∫Ê®°‚Äî‚Äî‰ªª‰ΩïÂèÉÊï∏Ëøë‰ººÈÉΩ‰∏çÂ§™ÂèØËÉΩÊçïÊçâÂà∞Èï∑ÊôÇÊúüÁöÑË§áÈõúÈÅãÂãïÊ®°Âºè„ÄÇÊàëÂÄëÊîπÁÇ∫ÂæûÂ≠êÁ©∫ÈñìËÅöÈ°ûÊñπÊ≥ï‰∏≠Ê±≤ÂèñÈùàÊÑüÔºåÊèêÂá∫‰∏ÄÂÄãÊêçÂ§±ÂáΩÊï∏ÔºåÁî®ÊñºÂ∞áËªåË∑°ÂàÜÁµÑÊàê‰ΩéÁß©Áü©Èô£ÔºåÂÖ∂‰∏≠Áâ©È´îÈªûÁöÑÈÅãÂãïÂèØ‰ª•Ëøë‰ººËß£ÈáãÁÇ∫ÂÖ∂‰ªñÈªûËªåË∑°ÁöÑÁ∑öÊÄßÁµÑÂêà„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Âü∫ÊñºÈÅãÂãïÁöÑÂàÜÂâ≤ÊñπÈù¢ÂÑ™ÊñºÂÖàÂâçÁöÑÊäÄË°ìÔºåÈÄôÈ°ØÁ§∫‰∫ÜÈï∑ÊúüÈÅãÂãïÁöÑÊïàÁî®ÂíåÊàëÂÄëÂÖ¨ÂºèÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Physics of Skill Learning**
2501.12391v1 by Ziming Liu, Yizhou Liu, Eric J. Michaud, Jeff Gore, Max Tegmark

We aim to understand physics of skill learning, i.e., how skills are learned
in neural networks during training. We start by observing the Domino effect,
i.e., skills are learned sequentially, and notably, some skills kick off
learning right after others complete learning, similar to the sequential fall
of domino cards. To understand the Domino effect and relevant behaviors of
skill learning, we take physicists' approach of abstraction and simplification.
We propose three models with varying complexities -- the Geometry model, the
Resource model, and the Domino model, trading between reality and simplicity.
The Domino effect can be reproduced in the Geometry model, whose resource
interpretation inspires the Resource model, which can be further simplified to
the Domino model. These models present different levels of abstraction and
simplification; each is useful to study some aspects of skill learning. The
Geometry model provides interesting insights into neural scaling laws and
optimizers; the Resource model sheds light on the learning dynamics of
compositional tasks; the Domino model reveals the benefits of modularity. These
models are not only conceptually interesting -- e.g., we show how Chinchilla
scaling laws can emerge from the Geometry model, but also are useful in
practice by inspiring algorithmic development -- e.g., we show how simple
algorithmic changes, motivated by these toy models, can speed up the training
of deep learning models.

ÊëòË¶ÅÔºöÊàëÂÄëÊó®Âú®‰∫ÜËß£ÊäÄËÉΩÂ≠∏ÁøíÁöÑÁâ©ÁêÜÂ≠∏ÔºåÂç≥Âú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠Â¶Ç‰ΩïÂ≠∏ÁøíÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ÁöÑÊäÄËÉΩ„ÄÇÊàëÂÄëÂæûËßÄÂØüÂ§öÁ±≥Ë´æÈ™®ÁâåÊïàÊáâÈñãÂßãÔºåÂç≥ÊäÄËÉΩÊòØÊåâÈ†ÜÂ∫èÂ≠∏ÁøíÁöÑÔºåÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊüê‰∫õÊäÄËÉΩÊúÉÂú®ÂÖ∂‰ªñÊäÄËÉΩÂÆåÊàêÂ≠∏ÁøíÂæåÁ´ãÂç≥ÈñãÂßãÂ≠∏ÁøíÔºåÈ°û‰ººÊñºÂ§öÁ±≥Ë´æÈ™®ÁâåÊåâÈ†ÜÂ∫èÂÄí‰∏ãÁöÑÊÉÖÊ≥Å„ÄÇÁÇ∫‰∫Ü‰∫ÜËß£Â§öÁ±≥Ë´æÈ™®ÁâåÊïàÊáâÂíåÊäÄËÉΩÂ≠∏ÁøíÁõ∏ÈóúË°åÁÇ∫ÔºåÊàëÂÄëÊé°Áî®Áâ©ÁêÜÂ≠∏ÂÆ∂ÁöÑÊäΩË±°ÂåñÂíåÁ∞°ÂåñÊñπÊ≥ï„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏âÁ®ÆÂÖ∑Êúâ‰∏çÂêåË§áÈõúÊÄßÁöÑÊ®°Âûã‚Äî‚ÄîÂπæ‰ΩïÊ®°Âûã„ÄÅË≥áÊ∫êÊ®°ÂûãÂíåÂ§öÁ±≥Ë´æÊ®°ÂûãÔºåÂú®ÁèæÂØ¶ÂíåÁ∞°ÊΩîÊÄß‰πãÈñìÈÄ≤Ë°åÊ¨äË°°„ÄÇÂ§öÁ±≥Ë´æÈ™®ÁâåÊïàÊáâÂèØ‰ª•Âú®Âπæ‰ΩïÊ®°Âûã‰∏≠ÈáçÁèæÔºåÂÖ∂Ë≥áÊ∫êËß£ÈáãÊøÄÁôº‰∫ÜË≥áÊ∫êÊ®°ÂûãÔºåËÄåË≥áÊ∫êÊ®°ÂûãÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•Á∞°ÂåñÁÇ∫Â§öÁ±≥Ë´æÊ®°Âûã„ÄÇÈÄô‰∫õÊ®°ÂûãÂëàÁèæÂá∫‰∏çÂêåÁöÑÊäΩË±°ÂåñÂíåÁ∞°ÂåñÂ±§Á¥öÔºõÊØè‰∏ÄÂÄãÈÉΩÂèØÁî®ÊñºÁ†îÁ©∂ÊäÄËÉΩÂ≠∏ÁøíÁöÑÊüê‰∫õÊñπÈù¢„ÄÇÂπæ‰ΩïÊ®°ÂûãÊèê‰æõ‰∫ÜÂ∞çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊì¥ÂÖÖÊ≥ïÂâáÂíåÊúÄ‰Ω≥ÂåñÂô®ÁöÑÊúâË∂£Ë¶ãËß£ÔºõË≥áÊ∫êÊ®°ÂûãÈó°Êòé‰∫ÜÁµÑÂêà‰ªªÂãôÁöÑÂ≠∏ÁøíÂãïÊÖãÔºõÂ§öÁ±≥Ë´æÊ®°ÂûãÊè≠Á§∫‰∫ÜÊ®°ÁµÑÂåñÁöÑÂÑ™Èªû„ÄÇÈÄô‰∫õÊ®°Âûã‰∏çÂÉÖÂú®Ê¶ÇÂøµ‰∏äÂæàÊúâË∂£‚Äî‚Äî‰æãÂ¶ÇÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊ¨ΩÂ•áÊãâÊì¥ÂÖÖÊ≥ïÂâáÂ¶Ç‰ΩïÂæûÂπæ‰ΩïÊ®°Âûã‰∏≠Âá∫ÁèæÔºåËÄå‰∏îÂú®ÂØ¶Âãô‰∏ä‰πüÂæàÊúâÁî®ÔºåÂõ†ÁÇ∫ÂÆÉÊøÄÁôº‰∫ÜÊºîÁÆóÊ≥ïÁöÑÈñãÁôº‚Äî‚Äî‰æãÂ¶ÇÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂèóÈÄô‰∫õÁé©ÂÖ∑Ê®°ÂûãÂïüÁôºÁöÑÁ∞°ÂñÆÊºîÁÆóÊ≥ïËÆäÊõ¥Â¶Ç‰ΩïËÉΩÂä†ÈÄüÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑË®ìÁ∑¥„ÄÇ

##### **MMVU: Measuring Expert-Level Multi-Discipline Video Understanding**
2501.12380v1 by Yilun Zhao, Lujing Xie, Haowei Zhang, Guo Gan, Yitao Long, Zhiyuan Hu, Tongyan Hu, Weiyuan Chen, Chuhan Li, Junyang Song, Zhijian Xu, Chengye Wang, Weifeng Pan, Ziyao Shangguan, Xiangru Tang, Zhenwen Liang, Yixin Liu, Chen Zhao, Arman Cohan

We introduce MMVU, a comprehensive expert-level, multi-discipline benchmark
for evaluating foundation models in video understanding. MMVU includes 3,000
expert-annotated questions spanning 27 subjects across four core disciplines:
Science, Healthcare, Humanities & Social Sciences, and Engineering. Compared to
prior benchmarks, MMVU features three key advancements. First, it challenges
models to apply domain-specific knowledge and perform expert-level reasoning to
analyze specialized-domain videos, moving beyond the basic visual perception
typically assessed in current video benchmarks. Second, each example is
annotated by human experts from scratch. We implement strict data quality
controls to ensure the high quality of the dataset. Finally, each example is
enriched with expert-annotated reasoning rationals and relevant domain
knowledge, facilitating in-depth analysis. We conduct an extensive evaluation
of 32 frontier multimodal foundation models on MMVU. The latest
System-2-capable models, o1 and Gemini 2.0 Flash Thinking, achieve the highest
performance among the tested models. However, they still fall short of matching
human expertise. Through in-depth error analyses and case studies, we offer
actionable insights for future advancements in expert-level,
knowledge-intensive video understanding for specialized domains.

ÊëòË¶ÅÔºöÊàëÂÄë‰ªãÁ¥π MMVUÔºå‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂ∞àÂÆ∂Á¥ö„ÄÅÂ§öÈ†òÂüüÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ÂΩ±ÁâáÁêÜËß£‰∏≠ÁöÑÂü∫Á§éÊ®°Âûã„ÄÇMMVU ÂåÖÂê´ 3,000 ÂÄãÂ∞àÂÆ∂Ë®ªËß£ÂïèÈ°åÔºåÊ∂µËìãÂõõÂÄãÊ†∏ÂøÉÈ†òÂüüÁöÑ 27 ÂÄãÁßëÁõÆÔºöÁßëÂ≠∏„ÄÅÈÜ´ÁôÇ‰øùÂÅ•„ÄÅ‰∫∫ÊñáËàáÁ§æÊúÉÁßëÂ≠∏‰ª•ÂèäÂ∑•Á®ã„ÄÇËàáÂÖàÂâçÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåMMVU ÂÖ∑ÂÇô‰∏âÂ§ßÈÄ≤Â±ï„ÄÇÈ¶ñÂÖàÔºåÂÆÉÊåëÊà∞Ê®°ÂûãÊáâÁî®ÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÔºå‰∏¶Âü∑Ë°åÂ∞àÂÆ∂Á¥öÊé®ÁêÜÔºå‰ª•ÂàÜÊûêÁâπÂÆöÈ†òÂüüÁöÑÂΩ±ÁâáÔºåË∂ÖË∂äÁï∂ÂâçÂΩ±ÁâáÂü∫Ê∫ñ‰∏≠ÈÄöÂ∏∏Ë©ï‰º∞ÁöÑÂü∫Êú¨Ë¶ñË¶∫ÊÑüÁü•„ÄÇÂÖ∂Ê¨°ÔºåÊØèÂÄãÁØÑ‰æãÈÉΩÊòØÁî±‰∫∫È°ûÂ∞àÂÆ∂ÂæûÈ†≠ÈñãÂßãË®ªËß£„ÄÇÊàëÂÄëÂØ¶ÊñΩÂö¥Ê†ºÁöÑË≥áÊñôÂìÅË≥™ÊéßÁÆ°Ôºå‰ª•Á¢∫‰øùË≥áÊñôÈõÜÁöÑÈ´òÂìÅË≥™„ÄÇÊúÄÂæåÔºåÊØèÂÄãÁØÑ‰æãÈÉΩË±êÂØå‰∫ÜÂ∞àÂÆ∂Ë®ªËß£ÁöÑÊé®ÁêÜÂéüÁêÜÂíåÁõ∏ÈóúÈ†òÂüüÁü•Ë≠òÔºå‰øÉÈÄ≤Ê∑±ÂÖ•ÂàÜÊûê„ÄÇÊàëÂÄëÂ∞ç 32 ÂÄãÂâçÊ≤øÂ§öÊ®°ÊÖãÂü∫Á§éÊ®°ÂûãÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑ MMVU Ë©ï‰º∞„ÄÇÊúÄÊñ∞ÁöÑ System-2 ËÉΩÂäõÊ®°Âûã o1 Âíå Gemini 2.0 Flash Thinking Âú®Ê∏¨Ë©¶Ê®°Âûã‰∏≠Áç≤ÂæóÊúÄÈ´òÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄë‰ªçÁÑ∂ÁÑ°Ê≥ïËàá‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÁõ∏ÂåπÈÖç„ÄÇÈÄèÈÅéÊ∑±ÂÖ•ÁöÑÈåØË™§ÂàÜÊûêÂíåÊ°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëÁÇ∫ÁâπÂÆöÈ†òÂüüÁöÑÂ∞àÂÆ∂Á¥ö„ÄÅÁü•Ë≠òÂØÜÈõÜÂûãÂΩ±ÁâáÁêÜËß£ÁöÑÊú™‰æÜÈÄ≤Â±ïÊèê‰æõ‰∫ÜÂèØË°åÁöÑË¶ãËß£„ÄÇ

##### **Video Depth Anything: Consistent Depth Estimation for Super-Long Videos**
2501.12375v1 by Sili Chen, Hengkai Guo, Shengnan Zhu, Feihu Zhang, Zilong Huang, Jiashi Feng, Bingyi Kang

Depth Anything has achieved remarkable success in monocular depth estimation
with strong generalization ability. However, it suffers from temporal
inconsistency in videos, hindering its practical applications. Various methods
have been proposed to alleviate this issue by leveraging video generation
models or introducing priors from optical flow and camera poses. Nonetheless,
these methods are only applicable to short videos (< 10 seconds) and require a
trade-off between quality and computational efficiency. We propose Video Depth
Anything for high-quality, consistent depth estimation in super-long videos
(over several minutes) without sacrificing efficiency. We base our model on
Depth Anything V2 and replace its head with an efficient spatial-temporal head.
We design a straightforward yet effective temporal consistency loss by
constraining the temporal depth gradient, eliminating the need for additional
geometric priors. The model is trained on a joint dataset of video depth and
unlabeled images, similar to Depth Anything V2. Moreover, a novel
key-frame-based strategy is developed for long video inference. Experiments
show that our model can be applied to arbitrarily long videos without
compromising quality, consistency, or generalization ability. Comprehensive
evaluations on multiple video benchmarks demonstrate that our approach sets a
new state-of-the-art in zero-shot video depth estimation. We offer models of
different scales to support a range of scenarios, with our smallest model
capable of real-time performance at 30 FPS.

ÊëòË¶ÅÔºöDepth Anything Âú®ÂñÆÁúºÊ∑±Â∫¶‰º∞Ë®àÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºå‰∏¶ÂÖ∑ÊúâÂº∑Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂú®ÂΩ±Áâá‰∏≠Â≠òÂú®ÊôÇÈñì‰∏ç‰∏ÄËá¥ÊÄßÁöÑÂïèÈ°åÔºåÈòªÁ§ô‰∫ÜÂÖ∂ÂØ¶ÈöõÊáâÁî®„ÄÇÂ∑≤Á∂ìÊèêÂá∫‰∫ÜÂêÑÁ®ÆÊñπÊ≥ï‰æÜÂà©Áî®ÂΩ±ÁâáÁîüÊàêÊ®°ÂûãÊàñÂºïÂÖ•ÂÖâÊµÅÂíåÁõ∏Ê©üÂßøÂã¢ÁöÑÂÖàÈ©ó‰æÜÁ∑©Ëß£ÈÄôÂÄãÂïèÈ°å„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÊñπÊ≥ïÂÉÖÈÅ©Áî®ÊñºÁü≠ÂΩ±ÁâáÔºà< 10 ÁßíÔºâÔºå‰∏¶‰∏îÈúÄË¶ÅÂú®ÂìÅË≥™ÂíåÈÅãÁÆóÊïàÁéá‰πãÈñìÈÄ≤Ë°åÊ¨äË°°„ÄÇÊàëÂÄëÊèêÂá∫ÂΩ±ÁâáÊ∑±Â∫¶ AnythingÔºåÁî®ÊñºÂú®Ë∂ÖÈï∑ÂΩ±ÁâáÔºàÊï∏ÂàÜÈêò‰ª•‰∏äÔºâ‰∏≠ÈÄ≤Ë°åÈ´òÂìÅË≥™„ÄÅ‰∏ÄËá¥ÁöÑÊ∑±Â∫¶‰º∞Ë®àÔºåËÄå‰∏çÊúÉÁäßÁâ≤ÊïàÁéá„ÄÇÊàëÂÄëÂ∞áÊ®°ÂûãÂª∫Á´ãÂú® Depth Anything V2 ‰∏äÔºå‰∏¶Áî®‰∏ÄÂÄãÈ´òÊïàÁöÑÊôÇÁ©∫È†≠ÊõøÊèõÂÖ∂È†≠ÈÉ®„ÄÇÊàëÂÄëÈÄöÈÅéÁ¥ÑÊùüÊôÇÈñìÊ∑±Â∫¶Ê¢ØÂ∫¶Ë®≠Ë®à‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊôÇÈñì‰∏ÄËá¥ÊÄßÊêçÂ§±ÔºåÊ∂àÈô§‰∫ÜÂ∞çÈ°çÂ§ñÂπæ‰ΩïÂÖàÈ©óÁöÑÈúÄÊ±Ç„ÄÇË©≤Ê®°ÂûãÂú®ÂΩ±ÁâáÊ∑±Â∫¶ÂíåÊú™Ê®ôË®òÂΩ±ÂÉèÁöÑËÅØÂêàË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÔºåÈ°û‰ººÊñº Depth Anything V2„ÄÇÊ≠§Â§ñÔºåÈÇÑÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂü∫ÊñºÈóúÈçµÂΩ±Ê†ºÁöÑÁ≠ñÁï•ÔºåÁî®ÊñºÈï∑ÂΩ±ÁâáÊé®Ë´ñ„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•ÊáâÁî®Êñº‰ªªÊÑèÈï∑ÁöÑÂΩ±ÁâáÔºåËÄå‰∏çÊúÉÊêçÂÆ≥ÂìÅË≥™„ÄÅ‰∏ÄËá¥ÊÄßÊàñÊ≥õÂåñËÉΩÂäõ„ÄÇÂ∞çÂ§öÂÄãÂΩ±ÁâáÂü∫Ê∫ñÁöÑÁ∂úÂêàË©ï‰º∞Ë°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Èõ∂Ê¨°Â≠∏ÁøíÂΩ±ÁâáÊ∑±Â∫¶‰º∞Ë®à‰∏≠Ê®πÁ´ã‰∫ÜÊñ∞ÁöÑÊäÄË°ìÊ∞¥Ê∫ñ„ÄÇÊàëÂÄëÊèê‰æõ‰∏çÂêåË¶èÊ®°ÁöÑÊ®°Âûã‰æÜÊîØÊè¥ÂêÑÁ®ÆÂ†¥ÊôØÔºåÊàëÂÄëÊúÄÂ∞èÁöÑÊ®°ÂûãËÉΩÂ§†‰ª• 30 FPS ÁöÑÈÄüÂ∫¶Âü∑Ë°åÂç≥ÊôÇÊïàËÉΩ„ÄÇ

##### **Expertise elevates AI usage: experimental evidence comparing laypeople and professional artists**
2501.12374v1 by Thomas F. Eisenmann, Andres Karjus, Mar Canet Sola, Levin Brinkmann, Bramantyo Ibrahim Supriyatno, Iyad Rahwan

Novel capacities of generative AI to analyze and generate cultural artifacts
raise inevitable questions about the nature and value of artistic education and
human expertise. Has AI already leveled the playing field between professional
artists and laypeople, or do trained artistic expressive capacity, curation
skills and experience instead enhance the ability to use these new tools? In
this pre-registered study, we conduct experimental comparisons between 50
active artists and a demographically matched sample of laypeople. We designed
two tasks to approximate artistic practice for testing their capabilities in
both faithful and creative image creation: replicating a reference image, and
moving as far away as possible from it. We developed a bespoke platform where
participants used a modern text-to-image model to complete both tasks. We also
collected and compared participants' sentiments towards AI. On average, artists
produced more faithful and creative outputs than their lay counterparts,
although only by a small margin. While AI may ease content creation,
professional expertise is still valuable - even within the confined space of
generative AI itself. Finally, we also explored how well an exemplary
vision-capable large language model (GPT-4o) would complete the same tasks, if
given the role of an image generation agent, and found it performed on par in
copying but outperformed even artists in the creative task. The very best
results were still produced by humans in both tasks. These outcomes highlight
the importance of integrating artistic skills with AI training to prepare
artists and other visual professionals for a technologically evolving
landscape. We see a potential in collaborative synergy with generative AI,
which could reshape creative industries and education in the arts.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI ÂàÜÊûêÂíåÁîüÊàêÊñáÂåñË£ΩÂìÅÁöÑÊñ∞Á©éËÉΩÂäõ
ÂºïÁôº‰∫ÜÈóúÊñºËóùË°ìÊïôËÇ≤ÁöÑÊÄßË≥™ÂíåÂÉπÂÄº‰ª•Âèä
‰∫∫È°ûÂ∞àÂÆ∂Áü•Ë≠òÁöÑ‰∏çÂèØÈÅøÂÖçÂïèÈ°å„ÄÇAI ÊòØÂê¶Â∑≤Á∂ìÊãâÂπ≥‰∫ÜÂ∞àÊ•≠
ËóùË°ìÂÆ∂ÂíåÂ§ñË°å‰πãÈñìÁöÑÁ´∂Áà≠Áí∞Â¢ÉÔºåÊàñËÄÖË®ìÁ∑¥ÊúâÁ¥†ÁöÑËóùË°ìË°®ÁèæËÉΩÂäõ„ÄÅÁ≠ñÂ±ï
ÊäÄÂ∑ßÂíåÁ∂ìÈ©óÂèçËÄåÂ¢ûÂº∑‰∫Ü‰ΩøÁî®ÈÄô‰∫õÊñ∞Â∑•ÂÖ∑ÁöÑËÉΩÂäõÔºüÂú®
ÈÄôÈ†ÖÈ†êÂÖàË®ªÂÜäÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞ç 50
‰ΩçÊ¥ªË∫çËóùË°ìÂÆ∂Âíå‰∫∫Âè£Áµ±Ë®àÂåπÈÖçÁöÑÂ§ñË°åÊ®£Êú¨ÈÄ≤Ë°å‰∫ÜÂØ¶È©óÊØîËºÉ„ÄÇÊàëÂÄëË®≠Ë®à
‰∫ÜÂÖ©ÂÄã‰ªªÂãô‰æÜËøë‰ººËóùË°ìÂØ¶Ë∏êÔºå‰ª•Ê∏¨Ë©¶ÂÆÉÂÄëÂú®
Âø†ÂØ¶ÂíåÂâµÈÄ†ÊÄßÂúñÂÉèÂâµ‰Ωú‰∏≠ÁöÑËÉΩÂäõÔºöË§áË£ΩÂèÉËÄÉÂúñÂÉèÔºå‰∏¶
Áõ°ÂèØËÉΩÈÅ†Èõ¢ÂÆÉ„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãË®ÇË£ΩÂπ≥Âè∞ÔºåËÆì
ÂèÉËàáËÄÖ‰ΩøÁî®Áèæ‰ª£ÊñáÂ≠óËΩâÂúñÂÉèÊ®°Âûã‰æÜÂÆåÊàêÈÄôÂÖ©ÂÄã‰ªªÂãô„ÄÇÊàëÂÄëÈÇÑ
Êî∂ÈõÜ‰∏¶ÊØîËºÉ‰∫ÜÂèÉËàáËÄÖÂ∞ç AI ÁöÑÊÉÖÁ∑í„ÄÇÂπ≥ÂùáËÄåË®ÄÔºåËóùË°ìÂÆ∂
Áî¢ÁîüÁöÑÂø†ÂØ¶‰∏îÊúâÂâµÊÑèÁöÑÁî¢Âá∫Â§öÊñº‰ªñÂÄëÁöÑÈùûÂ∞àÊ•≠Â∞çÊâãÔºå
ÂÑòÁÆ°Âè™ÊòØ‰∏ÄÂÄãÂæàÂ∞èÁöÑÂ∑ÆË∑ù„ÄÇÈõñÁÑ∂ AI ÂèØËÉΩÁ∞°Âåñ‰∫ÜÂÖßÂÆπÂâµ‰ΩúÔºå
Â∞àÊ•≠Áü•Ë≠ò‰ªçÁÑ∂ÊúâÂÉπÂÄº - Âç≥‰ΩøÂú®ÁîüÊàêÂºè AI Êú¨Ë∫´ÁöÑÂèóÈôêÁ©∫ÈñìÂÖß‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÇÑÊé¢Ë®é‰∫Ü‰∏ÄÂÄãÁØÑ‰æã
ÂÖ∑ÊúâË¶ñË¶∫ËÉΩÂäõÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (GPT-4o) Âú®
ÂÖÖÁï∂ÂúñÂÉèÁîüÊàê‰ª£ÁêÜÁöÑÊÉÖÊ≥Å‰∏ãÂÆåÊàêÁõ∏Âêå‰ªªÂãôÁöÑÊïàÊûúÂ¶Ç‰ΩïÔºå‰∏¶ÁôºÁèæÂÆÉÂú®
Ë§áË£Ω‰∏≠Ë°®ÁèæÂæóÁõ∏Áï∂Âá∫Ëâ≤Ôºå‰ΩÜÂú®ÂâµÈÄ†ÊÄß‰ªªÂãô‰∏≠ÁîöËá≥ÂÑ™ÊñºËóùË°ìÂÆ∂„ÄÇÊúÄÊ£íÁöÑ
ÁµêÊûú‰ªçÁÑ∂ÊòØÁî±‰∫∫È°ûÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏≠Áî¢ÁîüÁöÑ„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫ÜÂ∞áËóùË°ìÊäÄËÉΩËàá AI Ë®ìÁ∑¥Áõ∏ÁµêÂêà‰ª•Ê∫ñÂÇô
ËóùË°ìÂÆ∂ÂíåÂÖ∂‰ªñË¶ñË¶∫Â∞àÊ•≠‰∫∫Â£´ÊáâÂ∞çÊäÄË°ìÁôºÂ±ï
ÊÉÖÂã¢ÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÁúãÂà∞ËàáÁîüÊàêÂºè AI Âêà‰ΩúÂçîÂêåÁöÑÊΩõÂäõÔºå
ÈÄôÂèØËÉΩÊúÉÈáçÂ°ëÂâµÊÑèÁî¢Ê•≠ÂíåËóùË°ìÊïôËÇ≤„ÄÇ

##### **Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL**
2501.12372v1 by Yeounoh Chung, Gaurav T. Kakkar, Yu Gan, Brenton Milne, Fatma Ozcan

Large Language Models (LLMs) have demonstrated impressive capabilities across
a range of natural language processing tasks. In particular, improvements in
reasoning abilities and the expansion of context windows have opened new
avenues for leveraging these powerful models. NL2SQL is challenging in that the
natural language question is inherently ambiguous, while the SQL generation
requires a precise understanding of complex data schema and semantics. One
approach to this semantic ambiguous problem is to provide more and sufficient
contextual information.
  In this work, we explore the performance and the latency trade-offs of the
extended context window (a.k.a., long context) offered by Google's
state-of-the-art LLM (\textit{gemini-1.5-pro}). We study the impact of various
contextual information, including column example values, question and SQL query
pairs, user-provided hints, SQL documentation, and schema. To the best of our
knowledge, this is the first work to study how the extended context window and
extra contextual information can help NL2SQL generation with respect to both
accuracy and latency cost. We show that long context LLMs are robust and do not
get lost in the extended contextual information. Additionally, our long-context
NL2SQL pipeline based on Google's \textit{gemini-pro-1.5} achieve a strong
performance with 67.41\% on BIRD benchmark (dev) without finetuning and
expensive self-consistency based techniques.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Â±ïÁ§∫Âá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõ„ÄÇÁâπÂà•ÊòØÔºåÊé®ÁêÜËÉΩÂäõÁöÑÊèêÂçáÂíå‰∏ä‰∏ãÊñáË¶ñÁ™óÁöÑÊì¥Â±ïÁÇ∫Âà©Áî®ÈÄô‰∫õÂº∑Â§ßÁöÑÊ®°ÂûãÈñãÈó¢‰∫ÜÊñ∞ÈÄîÂæë„ÄÇNL2SQL ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄÂïèÈ°åÊú¨Ë≥™‰∏äÊòØÊ®°Á®úÂÖ©ÂèØÁöÑÔºåËÄå SQL ÁîüÊàêÈúÄË¶ÅÁ≤æÁ¢∫ÁêÜËß£Ë§áÈõúÁöÑÊï∏ÊìöÊ®°ÂºèÂíåË™ûÁæ©„ÄÇËß£Ê±∫ÈÄôÂÄãË™ûÁæ©Ê®°Á≥äÂïèÈ°åÁöÑ‰∏ÄÁ®ÆÊñπÊ≥ïÊòØÊèê‰æõÊõ¥Â§ö‰∏îÂÖÖÂàÜÁöÑ‰∏ä‰∏ãÊñáË≥áË®ä„ÄÇ
Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü Google ÊúÄÂÖàÈÄ≤ÁöÑ LLM (\textit{gemini-1.5-pro}) Êèê‰æõÁöÑÊì¥Â±ï‰∏ä‰∏ãÊñáË¶ñÁ™óÔºàÂèàÁ®±Èï∑‰∏ä‰∏ãÊñáÔºâÁöÑÊïàËÉΩÂíåÂª∂ÈÅ≤Ê¨äË°°„ÄÇÊàëÂÄëÁ†îÁ©∂‰∫ÜÂêÑÁ®Æ‰∏ä‰∏ãÊñáË≥áË®äÁöÑÂΩ±ÈüøÔºåÂåÖÊã¨Ê¨Ñ‰ΩçÁØÑ‰æãÂÄº„ÄÅÂïèÈ°åÂíå SQL Êü•Ë©¢ÈÖçÂ∞ç„ÄÅ‰ΩøÁî®ËÄÖÊèê‰æõÁöÑÊèêÁ§∫„ÄÅSQL Êñá‰ª∂ÂíåÊ®°Âºè„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÁ†îÁ©∂Êì¥Â±ï‰∏ä‰∏ãÊñáË¶ñÁ™óÂíåÈ°çÂ§ñ‰∏ä‰∏ãÊñáË≥áË®äÂ¶Ç‰ΩïËÉΩÂú®Ê∫ñÁ¢∫ÊÄßÂíåÂª∂ÈÅ≤ÊàêÊú¨ÊñπÈù¢ÂçîÂä© NL2SQL ÁîüÊàêÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈï∑‰∏ä‰∏ãÊñá LLM ÊòØÂº∑ÂÅ•ÁöÑÔºå‰∏çÊúÉËø∑Â§±Âú®Êì¥Â±ïÁöÑ‰∏ä‰∏ãÊñáË≥áË®ä‰∏≠„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂü∫Êñº Google ÁöÑ \textit{gemini-pro-1.5} ÁöÑÈï∑‰∏ä‰∏ãÊñá NL2SQL ÁÆ°Á∑öÂú® BIRD Âü∫Ê∫ñÊ∏¨Ë©¶ (dev) ‰∏äÈÅîÂà∞‰∫Ü 67.41% ÁöÑÂº∑ÂãÅÊïàËÉΩÔºåËÄåÁÑ°ÈúÄÂæÆË™øÂíåÊòÇË≤¥ÁöÑÂü∫ÊñºËá™Êàë‰∏ÄËá¥ÊÄßÁöÑÊäÄË°ì„ÄÇ

##### **Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models**
2501.12370v1 by Samira Abnar, Harshay Shah, Dan Busbridge, Alaaeldin Mohamed Elnouby Ali, Josh Susskind, Vimal Thilak

Scaling the capacity of language models has consistently proven to be a
reliable approach for improving performance and unlocking new capabilities.
Capacity can be primarily defined by two dimensions: the number of model
parameters and the compute per example. While scaling typically involves
increasing both, the precise interplay between these factors and their combined
contribution to overall capacity remains not fully understood. We explore this
relationship in the context of sparse Mixture-of-Expert models (MoEs), which
allow scaling the number of parameters without proportionally increasing the
FLOPs per example. We investigate how varying the sparsity level, i.e., the
ratio of non-active to total parameters, affects model performance in terms of
both pretraining and downstream performance. We find that under different
constraints (e.g. parameter size and total training compute), there is an
optimal level of sparsity that improves both training efficiency and model
performance. These results provide a better understanding of the impact of
sparsity in scaling laws for MoEs and complement existing works in this area,
offering insights for designing more efficient architectures.

ÊëòË¶ÅÔºöÊì¥Â±ïË™ûË®ÄÊ®°ÂûãÁöÑÂÆπÈáè‰∏ÄÁõ¥Ë¢´Ë≠âÊòéÊòØÊîπÂñÑÊïàËÉΩ‰∏¶Ëß£ÈéñÊñ∞ÂäüËÉΩÁöÑÂèØÈù†ÊñπÊ≥ï„ÄÇÂÆπÈáè‰∏ªË¶ÅÂèØ‰ª•Áî±ÂÖ©ÂÄãÈù¢ÂêëÂÆöÁæ©ÔºöÊ®°ÂûãÂèÉÊï∏Êï∏ÈáèÂíåÊØèÂÄãÁØÑ‰æãÁöÑÈÅãÁÆó„ÄÇÈõñÁÑ∂Êì¥Â±ïÈÄöÂ∏∏ÂåÖÂê´Â¢ûÂä†ÂÖ©ËÄÖÔºå‰ΩÜÈÄô‰∫õÂõ†Á¥†‰πãÈñìÁöÑÁ≤æÁ¢∫‰∫§‰∫í‰ΩúÁî®ÂèäÂÖ∂Â∞çÊï¥È´îÂÆπÈáèÁöÑÂÖ±ÂêåË≤¢Áçª‰ªçÊú™ÂÆåÂÖ®‰∫ÜËß£„ÄÇÊàëÂÄëÂú®Á®ÄÁñèÊ∑∑ÂêàÂ∞àÂÆ∂Ê®°Âûã (MoE) ÁöÑËÉåÊôØ‰∏ãÊé¢Ë®éÈÄôÁ®ÆÈóú‰øÇÔºåÂÆÉÂÖÅË®±Êì¥Â±ïÂèÉÊï∏Êï∏ÈáèÔºåËÄå‰∏çÊúÉÊàêÊØî‰æãÂú∞Â¢ûÂä†ÊØèÂÄãÁØÑ‰æãÁöÑ FLOP„ÄÇÊàëÂÄëÁ†îÁ©∂ÊîπËÆäÁ®ÄÁñèÁ®ãÂ∫¶ÔºàÂç≥ÈùûÊ¥ªÂãïÂèÉÊï∏ËàáÁ∏ΩÂèÉÊï∏ÁöÑÊØîÁéáÔºâÂ¶Ç‰ΩïÂΩ±ÈüøÊ®°ÂûãÂú®È†êË®ìÁ∑¥Âíå‰∏ãÊ∏∏ÊïàËÉΩÊñπÈù¢ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁôºÁèæÔºåÂú®‰∏çÂêåÁöÑÈôêÂà∂Ê¢ù‰ª∂Ôºà‰æãÂ¶ÇÂèÉÊï∏Â§ßÂ∞èÂíåÁ∏ΩË®ìÁ∑¥ÈÅãÁÆóÔºâ‰∏ãÔºåÂ≠òÂú®ÊúÄ‰Ω≥Á®ÄÁñèÁ®ãÂ∫¶ÔºåÂèØÂêåÊôÇÊîπÂñÑË®ìÁ∑¥ÊïàÁéáÂíåÊ®°ÂûãÊïàËÉΩ„ÄÇÈÄô‰∫õÁµêÊûúËÆìÊàëÂÄëÂ∞çÁ®ÄÁñèÊÄßÂú® MoE ÁöÑÊì¥Â±ïÂÆöÂæã‰∏≠ÁöÑÂΩ±ÈüøÊúâÊõ¥Â•ΩÁöÑ‰∫ÜËß£Ôºå‰∏¶Ë£úÂÖÖ‰∫ÜÈÄôÊñπÈù¢ÁöÑÁèæÊúâÂ∑•‰ΩúÔºåÊèê‰æõ‰∫ÜË®≠Ë®àÊõ¥ÊúâÊïàÁéáÁöÑÊû∂ÊßãÁöÑË¶ãËß£„ÄÇ

##### **InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model**
2501.12368v1 by Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Ziyu Liu, Shengyuan Ding, Shenxi Wu, Yubo Ma, Haodong Duan, Wenwei Zhang, Kai Chen, Dahua Lin, Jiaqi Wang

Despite the promising performance of Large Vision Language Models (LVLMs) in
visual understanding, they occasionally generate incorrect outputs. While
reward models (RMs) with reinforcement learning or test-time scaling offer the
potential for improving generation quality, a critical gap remains: publicly
available multi-modal RMs for LVLMs are scarce, and the implementation details
of proprietary models are often unclear. We bridge this gap with
InternLM-XComposer2.5-Reward (IXC-2.5-Reward), a simple yet effective
multi-modal reward model that aligns LVLMs with human preferences. To ensure
the robustness and versatility of IXC-2.5-Reward, we set up a high-quality
multi-modal preference corpus spanning text, image, and video inputs across
diverse domains, such as instruction following, general understanding,
text-rich documents, mathematical reasoning, and video understanding.
IXC-2.5-Reward achieves excellent results on the latest multi-modal reward
model benchmark and shows competitive performance on text-only reward model
benchmarks. We further demonstrate three key applications of IXC-2.5-Reward:
(1) Providing a supervisory signal for RL training. We integrate IXC-2.5-Reward
with Proximal Policy Optimization (PPO) yields IXC-2.5-Chat, which shows
consistent improvements in instruction following and multi-modal open-ended
dialogue; (2) Selecting the best response from candidate responses for
test-time scaling; and (3) Filtering outlier or noisy samples from existing
image and video instruction tuning training data. To ensure reproducibility and
facilitate further research, we have open-sourced all model weights and
training recipes at https://github.com/InternLM/InternLM-XComposer

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) Âú®Ë¶ñË¶∫ÁêÜËß£ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂÆÉÂÄëÂÅ∂ÁàæÊúÉÁî¢Áîü‰∏çÊ≠£Á¢∫ÁöÑËº∏Âá∫„ÄÇÈõñÁÑ∂ÂÖ∑ÊúâÂº∑ÂåñÂ≠∏ÁøíÊàñÊ∏¨Ë©¶ÊôÇÁ∏ÆÊîæÁöÑÂõûÈ•ãÊ®°Âûã (RMs) Êèê‰æõ‰∫ÜÊèêÈ´òÁîüÊàêÂìÅË≥™ÁöÑÂèØËÉΩÊÄßÔºå‰ΩÜ‰ªçÂ≠òÂú®‰∏ÄÂÄãÈóúÈçµÂ∑ÆË∑ùÔºöÂÖ¨ÈñãÁöÑÂ§öÊ®°ÊÖã LVLMs RMs ÂæàÂ∞ëÔºåËÄå‰∏îÂ∞àÊúâÊ®°ÂûãÁöÑÂØ¶‰ΩúÁ¥∞ÁØÄÂæÄÂæÄ‰∏çÊ∏ÖÊ•ö„ÄÇÊàëÂÄë‰ª• InternLM-XComposer2.5-Reward (IXC-2.5-Reward) ‰æÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÈÄôÊòØ‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÂ§öÊ®°ÊÖãÂõûÈ•ãÊ®°ÂûãÔºåÂÆÉÂ∞á LVLMs Ëàá‰∫∫È°ûÂÅèÂ•Ω‰øùÊåÅ‰∏ÄËá¥„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øù IXC-2.5-Reward ÁöÑÁ©©ÂÅ•ÊÄßÂíåÂ§öÂäüËÉΩÊÄßÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãË∑®Ë∂ä‰∏çÂêåÈ†òÂüüÔºà‰æãÂ¶ÇÊåá‰ª§ÈÅµÂæ™„ÄÅ‰∏ÄËà¨ÁêÜËß£„ÄÅÊñáÂ≠óË±êÂØåÁöÑÊñá‰ª∂„ÄÅÊï∏Â≠∏Êé®ÁêÜÂíåÂΩ±ÁâáÁêÜËß£ÔºâÁöÑÈ´òÂìÅË≥™Â§öÊ®°ÊÖãÂÅèÂ•ΩË™ûÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊñáÂ≠ó„ÄÅÂΩ±ÂÉèÂíåÂΩ±ÁâáËº∏ÂÖ•„ÄÇIXC-2.5-Reward Âú®ÊúÄÊñ∞ÁöÑÂ§öÊ®°ÊÖãÂõûÈ•ãÊ®°ÂûãÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÂèñÂæó‰∫ÜÂÑ™Áï∞ÁöÑÊàêÊûúÔºå‰∏¶Âú®Á¥îÊñáÂ≠óÂõûÈ•ãÊ®°ÂûãÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Â±ïÁèæ‰∫ÜÁ´∂Áà≠Âäõ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â±ïÁ§∫‰∫Ü IXC-2.5-Reward ÁöÑ‰∏âÂÄãÈóúÈçµÊáâÁî®Ôºö(1) Êèê‰æõ RL Ë®ìÁ∑¥ÁöÑÁõ£Áù£Ë®äËôü„ÄÇÊàëÂÄëÂ∞á IXC-2.5-Reward ËàáËøëÁ´ØÁ≠ñÁï•ÊúÄ‰Ω≥Âåñ (PPO) Êï¥ÂêàÔºåÁî¢Áîü IXC-2.5-ChatÔºåÂú®Êåá‰ª§ÈÅµÂæ™ÂíåÂ§öÊ®°ÊÖãÈñãÊîæÂºèÂ∞çË©±ÊñπÈù¢ÊåÅÁ∫åÊîπÂñÑÔºõ(2) ÂæûÂÄôÈÅ∏ÂõûÊáâ‰∏≠ÈÅ∏Âá∫ÊúÄ‰Ω≥ÂõûÊáâÔºå‰ª•ÈÄ≤Ë°åÊ∏¨Ë©¶ÊôÇÁ∏ÆÊîæÔºõ(3) ÂæûÁèæÊúâÁöÑÂΩ±ÂÉèÂíåÂΩ±ÁâáÊïôÂ≠∏Ë™øÊï¥Ë®ìÁ∑¥Ë≥áÊñô‰∏≠ÈÅéÊøæÁï∞Â∏∏ÂÄºÊàñÈõúË®äÊ®£Êú¨„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÂèØË§áË£ΩÊÄß‰∏¶‰øÉÈÄ≤ÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÔºåÊàëÂÄëÂ∑≤Âú® https://github.com/InternLM/InternLM-XComposer ÈñãÊîæÂéüÂßãÁ¢ºÁöÑÊâÄÊúâÊ®°ÂûãÊ¨äÈáçÂíåË®ìÁ∑¥ÈÖçÊñπ

##### **Test-time regression: a unifying framework for designing sequence models with associative memory**
2501.12352v1 by Ke Alexander Wang, Jiaxin Shi, Emily B. Fox

Sequences provide a remarkably general way to represent and process
information. This powerful abstraction has placed sequence modeling at the
center of modern deep learning applications, inspiring numerous architectures
from transformers to recurrent networks. While this fragmented development has
yielded powerful models, it has left us without a unified framework to
understand their fundamental similarities and explain their effectiveness. We
present a unifying framework motivated by an empirical observation: effective
sequence models must be able to perform associative recall. Our key insight is
that memorizing input tokens through an associative memory is equivalent to
performing regression at test-time. This regression-memory correspondence
provides a framework for deriving sequence models that can perform associative
recall, offering a systematic lens to understand seemingly ad-hoc architectural
choices. We show numerous recent architectures -- including linear attention
models, their gated variants, state-space models, online learners, and softmax
attention -- emerge naturally as specific approaches to test-time regression.
Each architecture corresponds to three design choices: the relative importance
of each association, the regressor function class, and the optimization
algorithm. This connection leads to new understanding: we provide theoretical
justification for QKNorm in softmax attention, and we motivate higher-order
generalizations of softmax attention. Beyond unification, our work unlocks
decades of rich statistical tools that can guide future development of more
powerful yet principled sequence models.

ÊëòË¶ÅÔºöÂ∫èÂàóÊèê‰æõ‰∫Ü‰∏ÄÂÄãÈùûÂ∏∏ÈÄöÁî®ÁöÑÊñπÂºè‰æÜË°®Á§∫ÂíåËôïÁêÜË≥áË®ä„ÄÇÈÄôÁ®ÆÂº∑Â§ßÁöÑÊäΩË±°ÂåñÂ∑≤Â∞áÂ∫èÂàóÊ®°ÂûãÁΩÆÊñºÁèæ‰ª£Ê∑±Â∫¶Â≠∏ÁøíÊáâÁî®Á®ãÂºèÁöÑÊ†∏ÂøÉÔºåÂæûTransformerÂà∞ÈÅûËø¥Á∂≤Ë∑ØÊøÄÁôº‰∫ÜË®±Â§öÊû∂Êßã„ÄÇÈõñÁÑ∂ÈÄôÁ®ÆÂàÜÊï£ÁöÑÁôºÂ±ïÁî¢Áîü‰∫ÜÂº∑Â§ßÁöÑÊ®°ÂûãÔºå‰ΩÜÂÆÉËÆìÊàëÂÄëÊ≤íÊúâÁµ±‰∏ÄÁöÑÊû∂Êßã‰æÜÁêÜËß£ÂÆÉÂÄëÁöÑÂü∫Êú¨Áõ∏‰ººÊÄß‰∏¶Ëß£ÈáãÂÆÉÂÄëÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî±Á∂ìÈ©óËßÄÂØüÊøÄÂãµÁöÑÁµ±‰∏ÄÊû∂ÊßãÔºöÊúâÊïàÁöÑÂ∫èÂàóÊ®°ÂûãÂøÖÈ†àËÉΩÂ§†Âü∑Ë°åÈóúËÅØÂºèÂõûÊÜ∂„ÄÇÊàëÂÄëÁöÑÈóúÈçµË¶ãËß£ÊòØÔºåÈÄèÈÅéËÅØÊÉ≥Ë®òÊÜ∂È´îË®òÊÜ∂Ëº∏ÂÖ•‰ª£Âπ£Á≠âÂêåÊñºÂú®Ê∏¨Ë©¶ÊôÇÂü∑Ë°åËø¥Ê≠∏„ÄÇÈÄôÁ®ÆËø¥Ê≠∏Ë®òÊÜ∂Â∞çÊáâÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊ°ÜÊû∂ÔºåÁî®ÊñºÊé®Â∞éÂèØ‰ª•Âü∑Ë°åÈóúËÅØÂºèÂõûÊÜ∂ÁöÑÂ∫èÂàóÊ®°ÂûãÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±ÁöÑÈÄèÈè°‰æÜÁêÜËß£Áúã‰ººËá®ÊôÇÁöÑÊû∂ÊßãÈÅ∏Êìá„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜË®±Â§öÊúÄËøëÁöÑÊû∂Êßã‚Äî‚ÄîÂåÖÊã¨Á∑öÊÄßÊ≥®ÊÑèÂäõÊ®°Âûã„ÄÅÂÆÉÂÄëÁöÑÈñÄÊéßËÆäÈ´î„ÄÅÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã„ÄÅÁ∑ö‰∏äÂ≠∏ÁøíÂô®Âíå softmax Ê≥®ÊÑèÂäõ‚Äî‚ÄîËá™ÁÑ∂ËÄåÁÑ∂Âú∞Âá∫Áèæ‰ΩúÁÇ∫Ê∏¨Ë©¶ÊôÇÈñìËø¥Ê≠∏ÁöÑÂÖ∑È´îÊñπÊ≥ï„ÄÇÊØèÂÄãÊû∂ÊßãÈÉΩÂ∞çÊáâÊñº‰∏âÂÄãË®≠Ë®àÈÅ∏ÊìáÔºöÊØèÂÄãÈóúËÅØÁöÑÁõ∏Â∞çÈáçË¶ÅÊÄß„ÄÅÂõûÊ≠∏ÂáΩÊï∏È°ûÂíåÊúÄ‰Ω≥ÂåñÊºîÁÆóÊ≥ï„ÄÇÈÄôÁ®ÆËÅØÁπ´Â∞éËá¥‰∫ÜÊñ∞ÁöÑÁêÜËß£ÔºöÊàëÂÄëÁÇ∫ softmax Ê≥®ÊÑèÂäõ‰∏≠ÁöÑ QKNorm Êèê‰æõ‰∫ÜÁêÜË´ñ‰æùÊìöÔºå‰∏¶‰∏îÊàëÂÄëÊøÄÂãµ‰∫Ü softmax Ê≥®ÊÑèÂäõÁöÑÈ´òÈöéÊ¶ÇÊã¨„ÄÇÈô§‰∫ÜÁµ±‰∏Ä‰πãÂ§ñÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÈÇÑËß£Èéñ‰∫ÜÊï∏ÂçÅÂπ¥ÁöÑË±êÂØåÁµ±Ë®àÂ∑•ÂÖ∑ÔºåÈÄô‰∫õÂ∑•ÂÖ∑ÂèØ‰ª•ÊåáÂ∞éÊõ¥Âº∑Â§ß‰ΩÜÊúâÂéüÂâáÁöÑÂ∫èÂàóÊ®°ÂûãÁöÑÊú™‰æÜÁôºÂ±ï„ÄÇ

##### **Treefix: Enabling Execution with a Tree of Prefixes**
2501.12339v1 by Beatriz Souza, Michael Pradel

The ability to execute code is a prerequisite for various dynamic program
analyses. Learning-guided execution has been proposed as an approach to enable
the execution of arbitrary code snippets by letting a neural model predict
likely values for any missing variables. Although state-of-the-art
learning-guided execution approaches, such as LExecutor, can enable the
execution of a relative high amount of code, they are limited to predicting a
restricted set of possible values and do not use any feedback from previous
executions to execute even more code. This paper presents Treefix, a novel
learning-guided execution approach that leverages LLMs to iteratively create
code prefixes that enable the execution of a given code snippet. The approach
addresses the problem in a multi-step fashion, where each step uses feedback
about the code snippet and its execution to instruct an LLM to improve a
previously generated prefix. This process iteratively creates a tree of
prefixes, a subset of which is returned to the user as prefixes that maximize
the number of executed lines in the code snippet. In our experiments with two
datasets of Python code snippets, Treefix achieves 25% and 7% more coverage
relative to the current state of the art in learning-guided execution, covering
a total of 84% and 82% of all lines in the code snippets.

ÊëòË¶ÅÔºöÂü∑Ë°åÁ®ãÂºèÁ¢ºÁöÑËÉΩÂäõÊòØÂêÑÁ®ÆÂãïÊÖãÁ®ãÂºèÂàÜÊûêÁöÑÂâçÊèê„ÄÇÂ≠∏ÁøíÂ∞éÂêëÂü∑Ë°åÂ∑≤Ë¢´ÊèêË≠∞ÁÇ∫‰∏ÄÁ®ÆÊñπÊ≥ïÔºåËÆìÁ•ûÁ∂ìÊ®°ÂûãÈ†êÊ∏¨‰ªª‰ΩïÈÅ∫Â§±ËÆäÊï∏ÁöÑÂèØËÉΩÂÄºÔºåÂæûËÄåËÉΩÂ§†Âü∑Ë°å‰ªªÊÑèÁ®ãÂºèÁ¢ºÁâáÊÆµ„ÄÇÂÑòÁÆ°ÊúÄÂÖàÈÄ≤ÁöÑÂ≠∏ÁøíÂ∞éÂêëÂü∑Ë°åÊñπÊ≥ïÔºà‰æãÂ¶Ç LExecutorÔºâÂèØ‰ª•Âü∑Ë°åÁõ∏Â∞çÂ§ßÈáèÁöÑÁ®ãÂºèÁ¢ºÔºå‰ΩÜÂÆÉÂÄëÂÉÖÈôêÊñºÈ†êÊ∏¨‰∏ÄÁµÑÂèØËÉΩÁöÑÂèóÈôêÂÄºÔºå‰∏¶‰∏î‰∏ç‰ΩøÁî®ÂÖàÂâçÂü∑Ë°åÁöÑ‰ªª‰ΩïÂõûÈ•ã‰æÜÂü∑Ë°åÊõ¥Â§öÁ®ãÂºèÁ¢º„ÄÇÊú¨ÊñáÊèêÂá∫ TreefixÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ≠∏ÁøíÂ∞éÂêëÂü∑Ë°åÊñπÊ≥ïÔºåÂÆÉÂà©Áî® LLM Ëø≠‰ª£Âª∫Á´ãÁ®ãÂºèÁ¢ºÂâçÁ∂¥Ôºå‰ª•Âü∑Ë°åÁµ¶ÂÆöÁöÑÁ®ãÂºèÁ¢ºÁâáÊÆµ„ÄÇË©≤ÊñπÊ≥ï‰ª•Â§öÊ≠•È©üÊñπÂºèËß£Ê±∫ÂïèÈ°åÔºåÂÖ∂‰∏≠ÊØè‰∏ÄÊ≠•ÈÉΩ‰ΩøÁî®ÈóúÊñºÁ®ãÂºèÁ¢ºÁâáÊÆµÂèäÂÖ∂Âü∑Ë°åÁöÑÂõûÈ•ãÔºå‰æÜÊåáÂ∞é LLM ÊîπÈÄ≤ÂÖàÂâçÁîüÊàêÁöÑÂ≠óÈ¶ñ„ÄÇÊ≠§ÈÅéÁ®ãÂèçË¶ÜÂª∫Á´ã‰∏ÄÂÄãÂâçÁ∂¥Ê®πÔºåÂÖ∂‰∏≠ÁöÑ‰∏ÄÈÉ®ÂàÜ‰ΩúÁÇ∫ÂâçÁ∂¥ÂõûÂÇ≥Áµ¶‰ΩøÁî®ËÄÖÔºå‰ª•ÊúÄÂ§ßÂåñÁ®ãÂºèÁ¢ºÁâáÊÆµ‰∏≠Âü∑Ë°åË°åÁöÑÊï∏Èáè„ÄÇÂú®ÊàëÂÄë‰ΩøÁî®ÂÖ©ÂÄã Python Á®ãÂºèÁ¢ºÁâáÊÆµË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂØ¶È©ó‰∏≠ÔºåTreefix Âú®Â≠∏ÁøíÂ∞éÂêëÂü∑Ë°å‰∏≠ÂèñÂæó‰∫ÜÊØîÁõÆÂâçÊúÄÂÖàÈÄ≤ÁöÑÊäÄË°ìÈ´òÂá∫ 25% Âíå 7% ÁöÑË¶ÜËìãÁéáÔºåÁ∏ΩÂÖ±Ê∂µËìã‰∫ÜÁ®ãÂºèÁ¢ºÁâáÊÆµ‰∏≠ÊâÄÊúâË°åÁöÑ 84% Âíå 82%„ÄÇ

##### **FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**
2501.12336v1 by Phuoc Duong Huy Chu

This paper presents results of our system for CoMeDi Shared Task, focusing on
Subtask 2: Disagreement Ranking. Our system leverages sentence embeddings
generated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep
neural regression model incorporating batch normalization and dropout for
improved generalization. By predicting the mean of pairwise judgment
differences between annotators, our method explicitly targets disagreement
ranking, diverging from traditional "gold label" aggregation approaches. We
optimized our system with a customized architecture and training procedure,
achieving competitive performance in Spearman correlation against mean
disagreement labels. Our results highlight the importance of robust embeddings,
effective model architecture, and careful handling of judgment differences for
ranking disagreement in multilingual contexts. These findings provide insights
into the use of contextualized representations for ordinal judgment tasks and
open avenues for further refinement of disagreement prediction models.

ÊëòË¶ÅÔºöÊú¨ÊñáÂ±ïÁ§∫‰∫ÜÊàëÂÄëÂú® CoMeDi ÂÖ±‰∫´‰ªªÂãôÁ≥ªÁµ±‰∏≠ÁöÑÁµêÊûúÔºåÈáçÈªûÂú®
Â≠ê‰ªªÂãô 2ÔºöÂàÜÊ≠ßÊéíÂêç„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Âà©Áî® paraphrase-xlm-r-multilingual-v1 Ê®°ÂûãÁî¢ÁîüÁöÑÂè•Â≠êÂµåÂÖ•ÔºåÁµêÂêàÊ∑±Â∫¶
Á•ûÁ∂ìËø¥Ê≠∏Ê®°ÂûãÔºå‰∏¶Âä†ÂÖ•ÊâπÊ¨°Ê≠£Ë¶èÂåñÂíå‰∏≠Êñ∑‰ª•ÊîπÂñÑÊ¶ÇÂåñ„ÄÇÈÄèÈÅéÈ†êÊ∏¨Ë®ªËß£ËÄÖ‰πãÈñìÊàêÂ∞çÂà§Êñ∑Â∑ÆÁï∞ÁöÑÂπ≥ÂùáÂÄºÔºåÊàëÂÄëÁöÑ
ÊñπÊ≥ïÊòéÁ¢∫ÈáùÂ∞çÂàÜÊ≠ßÊéíÂêçÔºåÂÅèÈõ¢ÂÇ≥Áµ±ÁöÑ„ÄåÈªÉÈáëÊ®ôÁ±§„ÄçËÅöÂêàÊñπÊ≥ï„ÄÇÊàëÂÄë‰ΩøÁî®Ëá™Ë®ÇÊû∂ÊßãÂíåË®ìÁ∑¥Á®ãÂ∫èÂÑ™ÂåñÁ≥ªÁµ±Ôºå
Âú®ËàáÂπ≥ÂùáÂàÜÊ≠ßÊ®ôÁ±§ÁöÑ Spearman Áõ∏ÈóúÊÄß‰∏≠Áç≤ÂæóÁ´∂Áà≠ÂäõË°®Áèæ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫ÜÁ©©ÂÅ•ÂµåÂÖ•„ÄÅÊúâÊïàÊ®°ÂûãÊû∂ÊßãÂíå
Ë¨πÊÖéËôïÁêÜÂà§Êñ∑Â∑ÆÁï∞Â∞çÊñºÂú®Â§öË™ûË®ÄÁí∞Â¢É‰∏≠Â∞çÂàÜÊ≠ßÈÄ≤Ë°åÊéíÂêçÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄô‰∫õÁôºÁèæÊèê‰æõ‰∫Ü‰ΩøÁî®ÊÉÖÂ¢ÉÂåñË°®ÂæµÈÄ≤Ë°åÂ∫èÊï∏Âà§Êñ∑‰ªªÂãôÁöÑË¶ãËß£Ôºå‰∏¶ÁÇ∫ÈÄ≤‰∏ÄÊ≠•ÂÑ™ÂåñÂàÜÊ≠ßÈ†êÊ∏¨Ê®°ÂûãÈñãÈó¢‰∫ÜÈÅìË∑Ø„ÄÇ

##### **Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration**
2501.12332v1 by Thomas Walshe, Sae Young Moon, Chunyang Xiao, Yawwani Gunawardana, Fran Silavong

Acquiring labelled training data remains a costly task in real world machine
learning projects to meet quantity and quality requirements. Recently Large
Language Models (LLMs), notably GPT-4, have shown great promises in labelling
data with high accuracy. However, privacy and cost concerns prevent the
ubiquitous use of GPT-4. In this work, we explore effectively leveraging
open-source models for automatic labelling. We identify integrating label
schema as a promising technology but found that naively using the label
description for classification leads to poor performance on high cardinality
tasks. To address this, we propose Retrieval Augmented Classification (RAC) for
which LLM performs inferences for one label at a time using corresponding label
schema; we start with the most related label and iterates until a label is
chosen by the LLM. We show that our method, which dynamically integrates label
description, leads to performance improvements in labelling tasks. We further
show that by focusing only on the most promising labels, RAC can trade off
between label quality and coverage - a property we leverage to automatically
label our internal datasets.

ÊëòË¶ÅÔºöÂú®ÂØ¶ÈöõÊ©üÂô®Â≠∏ÁøíÂ∞àÊ°à‰∏≠ÔºåÂèñÂæóÊ®ôÁ±§Ë®ìÁ∑¥Ë≥áÊñô‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÊàêÊú¨È´òÊòÇÁöÑ‰ªªÂãôÔºå‰ª•ÊªøË∂≥Êï∏ÈáèÂíåÂìÅË≥™ÈúÄÊ±Ç„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂ∞§ÂÖ∂ÊòØ GPT-4ÔºåÂú®Ê®ôÁ±§Ë≥áÊñô‰∏äÂ±ïÁèæÂá∫È´òÁ≤æÊ∫ñÂ∫¶ÁöÑÂÑ™Áï∞Ë°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÈö±ÁßÅÂíåÊàêÊú¨ËÄÉÈáèÈòªÁ§ô‰∫Ü GPT-4 ÁöÑÂª£Ê≥õ‰ΩøÁî®„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ¶Ç‰ΩïÊúâÊïàÂà©Áî®ÈñãÊ∫êÊ®°ÂûãÈÄ≤Ë°åËá™ÂãïÊ®ôÁ±§„ÄÇÊàëÂÄëÁôºÁèæÊï¥ÂêàÊ®ôÁ±§Êû∂ÊßãÊòØ‰∏ÄÈ†ÖÊúâÂâçÈÄîÁöÑÊäÄË°ìÔºå‰ΩÜÁôºÁèæÂ§©ÁúüÂú∞‰ΩøÁî®Ê®ôÁ±§Ë™™ÊòéÈÄ≤Ë°åÂàÜÈ°ûÊúÉÂ∞éËá¥È´òÂü∫Êï∏‰ªªÂãôÁöÑÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊ™¢Á¥¢Â¢ûÂº∑ÂàÜÈ°û (RAC)ÔºåÂÖ∂‰∏≠ LLM ‰ΩøÁî®Â∞çÊáâÁöÑÊ®ôÁ±§Êû∂Êßã‰∏ÄÊ¨°Â∞ç‰∏ÄÂÄãÊ®ôÁ±§Âü∑Ë°åÊé®Ë´ñÔºõÊàëÂÄëÂæûÊúÄÁõ∏ÈóúÁöÑÊ®ôÁ±§ÈñãÂßãÔºå‰∏¶ÂèçË¶ÜÈÅãÁÆóÔºåÁõ¥Âà∞ LLM ÈÅ∏Êìá‰∏ÄÂÄãÊ®ôÁ±§„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºàÂãïÊÖãÊï¥ÂêàÊ®ôÁ±§Ë™™ÊòéÔºâÊúÉÊèêÂçáÊ®ôÁ±§‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â±ïÁ§∫ÔºåÈÄèÈÅéÂÉÖÂ∞àÊ≥®ÊñºÊúÄÊúâÂ∏åÊúõÁöÑÊ®ôÁ±§ÔºåRAC ÂèØ‰ª•Ê¨äË°°Ê®ôÁ±§ÂìÅË≥™ÂíåÊ∂µËìãÁØÑÂúçÔºåÊàëÂÄëÂà©Áî®ÈÄôÈ†ÖÁâπÊÄßËá™ÂãïÊ®ôÁ±§ÊàëÂÄëÁöÑÂÖßÈÉ®Ë≥áÊñôÈõÜ„ÄÇ

##### **UI-TARS: Pioneering Automated GUI Interaction with Native Agents**
2501.12326v1 by Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin Li, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli Ma, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao Wang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, Guang Shi

This paper introduces UI-TARS, a native GUI agent model that solely perceives
the screenshots as input and performs human-like interactions (e.g., keyboard
and mouse operations). Unlike prevailing agent frameworks that depend on
heavily wrapped commercial models (e.g., GPT-4o) with expert-crafted prompts
and workflows, UI-TARS is an end-to-end model that outperforms these
sophisticated frameworks. Experiments demonstrate its superior performance:
UI-TARS achieves SOTA performance in 10+ GUI agent benchmarks evaluating
perception, grounding, and GUI task execution. Notably, in the OSWorld
benchmark, UI-TARS achieves scores of 24.6 with 50 steps and 22.7 with 15
steps, outperforming Claude (22.0 and 14.9 respectively). In AndroidWorld,
UI-TARS achieves 46.6, surpassing GPT-4o (34.5). UI-TARS incorporates several
key innovations: (1) Enhanced Perception: leveraging a large-scale dataset of
GUI screenshots for context-aware understanding of UI elements and precise
captioning; (2) Unified Action Modeling, which standardizes actions into a
unified space across platforms and achieves precise grounding and interaction
through large-scale action traces; (3) System-2 Reasoning, which incorporates
deliberate reasoning into multi-step decision making, involving multiple
reasoning patterns such as task decomposition, reflection thinking, milestone
recognition, etc. (4) Iterative Training with Reflective Online Traces, which
addresses the data bottleneck by automatically collecting, filtering, and
reflectively refining new interaction traces on hundreds of virtual machines.
Through iterative training and reflection tuning, UI-TARS continuously learns
from its mistakes and adapts to unforeseen situations with minimal human
intervention. We also analyze the evolution path of GUI agents to guide the
further development of this domain.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü UI-TARSÔºå‰∏ÄÁ®ÆÂéüÁîü GUI ‰ª£ÁêÜÊ®°ÂûãÔºåÂÆÉÂÉÖÂ∞áËû¢ÂπïÊà™ÂúñË¶ñÁÇ∫Ëº∏ÂÖ•Ôºå‰∏¶Âü∑Ë°åÈ°û‰ºº‰∫∫È°ûÁöÑ‰∫íÂãïÔºà‰æãÂ¶ÇÔºåÈçµÁõ§ÂíåÊªëÈº†Êìç‰ΩúÔºâ„ÄÇËàá‰æùË≥¥ÊñºÂ∞àÂÆ∂Á≤æÂøÉË£Ω‰ΩúÁöÑÊèêÁ§∫ÂíåÂ∑•‰ΩúÊµÅÁ®ãÁöÑÁõõË°å‰ª£ÁêÜÊû∂Êßã‰∏çÂêåÔºåUI-TARS ÊòØ‰∏ÄÂÄãÁ´ØÂà∞Á´ØÊ®°ÂûãÔºåÂÖ∂ÊïàËÉΩÂÑ™ÊñºÈÄô‰∫õË§áÈõúÁöÑÊû∂Êßã„ÄÇÂØ¶È©óË≠âÊòé‰∫ÜÂÖ∂ÂçìË∂äÁöÑÊïàËÉΩÔºöUI-TARS Âú® 10 Â§öÂÄã GUI ‰ª£ÁêÜÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÂèñÂæó SOTA ÊïàËÉΩÔºåË©ï‰º∞ÊÑüÁü•„ÄÅÂü∫Á§éÂíå GUI ‰ªªÂãôÂü∑Ë°å„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú® OSWorld Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÔºåUI-TARS Âú® 50 ÂÄãÊ≠•È©ü‰∏≠ÂèñÂæó 24.6 ÂàÜÔºåÂú® 15 ÂÄãÊ≠•È©ü‰∏≠ÂèñÂæó 22.7 ÂàÜÔºåÂÑ™Êñº ClaudeÔºàÂàÜÂà•ÁÇ∫ 22.0 Âíå 14.9Ôºâ„ÄÇÂú® AndroidWorld ‰∏≠ÔºåUI-TARS ÂèñÂæó 46.6 ÂàÜÔºåË∂ÖË∂ä GPT-4oÔºà34.5Ôºâ„ÄÇUI-TARS ËûçÂêà‰∫ÜÂ§öÈ†ÖÈóúÈçµÂâµÊñ∞Ôºö(1) Â¢ûÂº∑ÊÑüÁü•ÔºöÂà©Áî®Â§ßË¶èÊ®° GUI Ëû¢ÂπïÊà™ÂúñË≥áÊñôÈõÜÔºå‰ª•ÊÉÖÂ¢ÉÊÑüÁü•ÁöÑÊñπÂºèÁêÜËß£ UI ÂÖÉÁ¥†‰∏¶ÈÄ≤Ë°åÁ≤æÁ¢∫Ê®ôÈ°åË™™ÊòéÔºõ(2) Áµ±‰∏ÄÂãï‰ΩúÂª∫Ê®°ÔºåÂ∞áÂãï‰ΩúÊ®ôÊ∫ñÂåñÂà∞Ë∑®Âπ≥Âè∞ÁöÑÁµ±‰∏ÄÁ©∫ÈñìÔºå‰∏¶ÈÄèÈÅéÂ§ßË¶èÊ®°Âãï‰ΩúËøΩËπ§ÔºåÂØ¶ÁèæÁ≤æÁ¢∫ÁöÑÂü∫Á§éÂíå‰∫íÂãïÔºõ(3) Á≥ªÁµ± 2 Êé®ÁêÜÔºåÂ∞áÊ∑±ÊÄùÁÜüÊÖÆÁöÑÊé®ÁêÜÁ¥çÂÖ•Â§öÊ≠•È©üÊ±∫Á≠ñÂà∂ÂÆö‰∏≠ÔºåÊ∂âÂèäÂ§öÁ®ÆÊé®ÁêÜÊ®°ÂºèÔºå‰æãÂ¶Ç‰ªªÂãôÂàÜËß£„ÄÅÂèçÊÄùÊÄùËÄÉ„ÄÅÈáåÁ®ãÁ¢ëË≠òÂà•Á≠âÔºõ(4) ÈÄèÈÅéÂèçÊÄùÊÄßÁ∑ö‰∏äËøΩËπ§ÈÄ≤Ë°åÂèçË¶ÜË®ìÁ∑¥ÔºåÈÄèÈÅéÂú®Êï∏ÁôæÂè∞ËôõÊì¨Ê©üÂô®‰∏äËá™ÂãïÊî∂ÈõÜ„ÄÅÈÅéÊøæÂíåÂèçÊÄùÊÄßÂú∞Á≤æÁÖâÊñ∞ÁöÑ‰∫íÂãïËøΩËπ§Ôºå‰æÜËß£Ê±∫Ë≥áÊñôÁì∂È†∏ÂïèÈ°å„ÄÇÈÄèÈÅéÂèçË¶ÜË®ìÁ∑¥ÂíåÂèçÊÄùË™øÊï¥ÔºåUI-TARS ‰∏çÊñ∑ÂæûÂÖ∂ÈåØË™§‰∏≠Â≠∏ÁøíÔºå‰∏¶Âú®ÊúÄÂ∞ëÁöÑ‰∫∫ÁÇ∫Âπ≤È†ê‰∏ãÈÅ©ÊáâÁÑ°Ê≥ïÈ†êË¶ãÁöÑÊÉÖÊ≥Å„ÄÇÊàëÂÄë‰πüÂàÜÊûê‰∫Ü GUI ‰ª£ÁêÜÁöÑÊºîÈÄ≤Ë∑ØÂæëÔºå‰ª•ÂºïÂ∞éÊ≠§È†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ï„ÄÇ

##### **LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**
2501.12300v1 by Hasan Abu-Rasheed, Constance Jumbo, Rashed Al Amin, Christian Weber, Veit Wiese, Roman Obermaisser, Madjid Fathi

While learning personalization offers great potential for learners, modern
practices in higher education require a deeper consideration of domain models
and learning contexts, to develop effective personalization algorithms. This
paper introduces an innovative approach to higher education curriculum
modelling that utilizes large language models (LLMs) for knowledge graph (KG)
completion, with the goal of creating personalized learning-path
recommendations. Our research focuses on modelling university subjects and
linking their topics to corresponding domain models, enabling the integration
of learning modules from different faculties and institutions in the student's
learning path. Central to our approach is a collaborative process, where LLMs
assist human experts in extracting high-quality, fine-grained topics from
lecture materials. We develop a domain, curriculum, and user models for
university modules and stakeholders. We implement this model to create the KG
from two study modules: Embedded Systems and Development of Embedded Systems
Using FPGA. The resulting KG structures the curriculum and links it to the
domain models. We evaluate our approach through qualitative expert feedback and
quantitative graph quality metrics. Domain experts validated the relevance and
accuracy of the model, while the graph quality metrics measured the structural
properties of our KG. Our results show that the LLM-assisted graph completion
approach enhances the ability to connect related courses across disciplines to
personalize the learning experience. Expert feedback also showed high
acceptance of the proposed collaborative approach for concept extraction and
classification.

ÊëòË¶ÅÔºö<paragraph>Âú®Â≠∏ÁøíÂÄã‰∫∫ÂåñÊèê‰æõÂ≠∏ÁøíËÄÖÂ∑®Â§ßÊΩõÂäõÁöÑÂêåÊôÇÔºåÈ´òÁ≠âÊïôËÇ≤‰∏≠ÁöÑÁèæ‰ª£ÂØ¶ÂãôÈúÄË¶ÅÊõ¥Ê∑±ÂÖ•Âú∞ËÄÉÊÖÆÈ†òÂüüÊ®°ÂûãÂíåÂ≠∏ÁøíÊÉÖÂ¢ÉÔºå‰ª•ÈñãÁôºÊúâÊïàÁöÑÂÄã‰∫∫ÂåñÊºîÁÆóÊ≥ï„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÈ´òÁ≠âÊïôËÇ≤Ë™≤Á®ãÂª∫Ê®°ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÂÆåÊàêÁü•Ë≠òÂúñË≠ú (KG)ÔºåÁõÆÁöÑÊòØÂª∫Á´ãÂÄã‰∫∫ÂåñÁöÑÂ≠∏ÁøíË∑ØÂæëÂª∫Ë≠∞„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈáçÈªûÂú®ÊñºÂª∫Ê®°Â§ßÂ≠∏ÁßëÁõÆÔºå‰∏¶Â∞áÂÆÉÂÄëÁöÑ‰∏ªÈ°åÈÄ£ÁµêÂà∞Â∞çÊáâÁöÑÈ†òÂüüÊ®°ÂûãÔºåÂæûËÄåËÉΩÂ§†Â∞á‰æÜËá™‰∏çÂêåÈô¢Á≥ªÂíåÊ©üÊßãÁöÑÂ≠∏ÁøíÊ®°ÁµÑÊï¥ÂêàÂà∞Â≠∏ÁîüÁöÑÂ≠∏ÁøíË∑ØÂæë‰∏≠„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ†∏ÂøÉÊòØ‰∏ÄÂÄãÂçî‰ΩúÊµÅÁ®ãÔºåÂÖ∂‰∏≠ LLM ÂçîÂä©‰∫∫È°ûÂ∞àÂÆ∂ÂæûË¨õÁæ©ÊùêÊñô‰∏≠ËêÉÂèñÈ´òÂìÅË≥™„ÄÅÁ¥∞Á∑ªÁöÑ‰∏ªÈ°å„ÄÇÊàëÂÄëÁÇ∫Â§ßÂ≠∏Ê®°ÁµÑÂíåÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÈñãÁôº‰∫ÜÈ†òÂüü„ÄÅË™≤Á®ãÂíå‰ΩøÁî®ËÄÖÊ®°Âûã„ÄÇÊàëÂÄëÂØ¶‰ΩúÈÄôÂÄãÊ®°ÂûãÔºåÂæûÂÖ©ÂÄãÁ†îÁ©∂Ê®°ÁµÑÂª∫Á´ã KGÔºöÂµåÂÖ•ÂºèÁ≥ªÁµ±Âíå‰ΩøÁî® FPGA ÁöÑÂµåÂÖ•ÂºèÁ≥ªÁµ±ÈñãÁôº„ÄÇÁî¢ÁîüÁöÑ KG Âª∫Êßã‰∫ÜË™≤Á®ã‰∏¶Â∞áÂÖ∂ÈÄ£ÁµêÂà∞È†òÂüüÊ®°Âûã„ÄÇÊàëÂÄëÈÄèÈÅéÂÆöÊÄßÂ∞àÂÆ∂ÂõûÈ•ãÂíåÂÆöÈáèÂúñÂΩ¢ÂìÅË≥™ÊåáÊ®ô‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ï„ÄÇÈ†òÂüüÂ∞àÂÆ∂È©óË≠â‰∫ÜÊ®°ÂûãÁöÑÁõ∏ÈóúÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÔºåËÄåÂúñÂΩ¢ÂìÅË≥™ÊåáÊ®ôÂâáÊ∏¨Èáè‰∫ÜÊàëÂÄë KG ÁöÑÁµêÊßãÁâπÊÄß„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåLLM ËºîÂä©ÁöÑÂúñÂΩ¢ÂÆåÊàêÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜË∑®Â≠∏ÁßëÈÄ£ÁµêÁõ∏ÈóúË™≤Á®ãÁöÑËÉΩÂäõÔºå‰ª•ÂÄã‰∫∫ÂåñÂ≠∏ÁøíÈ´îÈ©ó„ÄÇÂ∞àÂÆ∂ÂõûÈ•ã‰πüÈ°ØÁ§∫È´òÂ∫¶Êé•ÂèóÊâÄÊèêÂá∫ÁöÑÂçî‰ΩúÊñπÊ≥ïÔºåÁî®ÊñºÊ¶ÇÂøµËêÉÂèñÂíåÂàÜÈ°û„ÄÇ</paragraph>

##### **RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning**
2501.12296v1 by Jiacheng Zuo, Haibo Hu, Zikang Zhou, Yufei Cui, Ziquan Liu, Jianping Wang, Nan Guan, Jin Wang, Chun Jason Xue

In the pursuit of robust autonomous driving systems, models trained on
real-world datasets often struggle to adapt to new environments, particularly
when confronted with corner cases such as extreme weather conditions.
Collecting these corner cases in the real world is non-trivial, which
necessitates the use of simulators for validation. However,the high
computational cost and the domain gap in data distribution have hindered the
seamless transition between real and simulated driving scenarios. To tackle
this challenge, we propose Retrieval-Augmented Learning for Autonomous Driving
(RALAD), a novel framework designed to bridge the real-to-sim gap at a low
cost. RALAD features three primary designs, including (1) domain adaptation via
an enhanced Optimal Transport (OT) method that accounts for both individual and
grouped image distances, (2) a simple and unified framework that can be applied
to various models, and (3) efficient fine-tuning techniques that freeze the
computationally expensive layers while maintaining robustness. Experimental
results demonstrate that RALAD compensates for the performance degradation in
simulated environments while maintaining accuracy in real-world scenarios
across three different models. Taking Cross View as an example, the mIOU and
mAP metrics in real-world scenarios remain stable before and after RALAD
fine-tuning, while in simulated environments,the mIOU and mAP metrics are
improved by 10.30% and 12.29%, respectively. Moreover, the re-training cost of
our approach is reduced by approximately 88.1%. Our code is available at
https://github.com/JiachengZuo/RALAD.git.

ÊëòË¶ÅÔºö<paragraph>Âú®ËøΩÊ±ÇÁ©©ÂÅ•ÁöÑËá™ÂãïÈßïÈßõÁ≥ªÁµ±ÊôÇÔºå‰ΩøÁî®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜË®ìÁ∑¥ÁöÑÊ®°ÂûãÈÄöÂ∏∏Èõ£‰ª•ÈÅ©ÊáâÊñ∞Áí∞Â¢ÉÔºåÁâπÂà•ÊòØÂú®ÈÅáÂà∞Ê•µÁ´ØÂ§©Ê∞£Ê¢ù‰ª∂Á≠âÊ•µÁ´ØÊÉÖÊ≥ÅÊôÇ„ÄÇÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠Êî∂ÈõÜÈÄô‰∫õÊ•µÁ´ØÊÉÖÊ≥Å‰∏¶ÈùûÊòì‰∫ãÔºåÈÄôÈúÄË¶Å‰ΩøÁî®Ê®°Êì¨Âô®ÈÄ≤Ë°åÈ©óË≠â„ÄÇÁÑ∂ËÄåÔºåÈ´òË®àÁÆóÊàêÊú¨ÂíåË≥áÊñôÂàÜ‰Ωà‰∏≠ÁöÑÈ†òÂüüÂ∑ÆË∑ùÈòªÁ§ô‰∫ÜÁúüÂØ¶ÂíåÊ®°Êì¨ÈßïÈßõÂ†¥ÊôØ‰πãÈñìÁöÑÁÑ°Á∏´ÈÅéÊ∏°„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁî®ÊñºËá™ÂãïÈßïÈßõÁöÑÊ™¢Á¥¢Â¢ûÂº∑Â≠∏Áøí (RALAD)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®‰ª•‰ΩéÊàêÊú¨ÂΩåÂêàÁúüÂØ¶ËàáÊ®°Êì¨ÁöÑÂ∑ÆË∑ù„ÄÇRALAD ÂÖ∑Êúâ‰∏âÈ†Ö‰∏ªË¶ÅË®≠Ë®àÔºåÂåÖÊã¨ (1) ÈÄèÈÅé‰∏ÄÁ®ÆÂ¢ûÂº∑ÁöÑÊúÄ‰Ω≥ÂÇ≥Ëº∏ (OT) ÊñπÊ≥ïÈÄ≤Ë°åÈ†òÂüüÈÅ©ÊáâÔºåË©≤ÊñπÊ≥ïËÄÉÊÖÆ‰∫ÜÂÄãÂà•ÂíåÁæ§ÁµÑÂΩ±ÂÉèË∑ùÈõ¢Ôºå(2) ‰∏ÄÂÄãÁ∞°ÂñÆ‰∏îÁµ±‰∏ÄÁöÑÊ°ÜÊû∂ÔºåÂèØÊáâÁî®ÊñºÂêÑÁ®ÆÊ®°ÂûãÔºå‰ª•Âèä (3) ÊúâÊïàÁöÑÂæÆË™øÊäÄË°ìÔºåÂèØÂú®Á∂≠ÊåÅÁ©©ÂÅ•ÊÄßÁöÑÂêåÊôÇÂáçÁµêË®àÁÆóÊàêÊú¨È´òÁöÑÂ±§„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåRALAD Ë£úÂÑü‰∫ÜÊ®°Êì¨Áí∞Â¢É‰∏≠ÁöÑÊïàËÉΩ‰∏ãÈôçÔºåÂêåÊôÇÂú®‰∏âÂÄã‰∏çÂêåÁöÑÊ®°Âûã‰∏≠Á∂≠ÊåÅ‰∫ÜÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇ‰ª• Cross View ÁÇ∫‰æãÔºåRALAD ÂæÆË™øÂâçÂæåÔºåÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑ mIOU Âíå mAP ÊåáÊ®ô‰øùÊåÅÁ©©ÂÆöÔºåËÄåÂú®Ê®°Êì¨Áí∞Â¢É‰∏≠ÔºåmIOU Âíå mAP ÊåáÊ®ôÂàÜÂà•ÊèêÈ´ò‰∫Ü 10.30% Âíå 12.29%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÁöÑÈáçÊñ∞Ë®ìÁ∑¥ÊàêÊú¨Èôç‰Ωé‰∫ÜÂ§ßÁ¥Ñ 88.1%„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/JiachengZuo/RALAD.git ‰∏≠ÂèñÂæó„ÄÇ</paragraph>

##### **With Great Backbones Comes Great Adversarial Transferability**
2501.12275v1 by Erik Arakelyan, Karen Hambardzumyan, Davit Papikyan, Pasquale Minervini, Albert Gordo, Isabelle Augenstein, Aram H. Markosyan

Advances in self-supervised learning (SSL) for machine vision have improved
representation robustness and model performance, giving rise to pre-trained
backbones like \emph{ResNet} and \emph{ViT} models tuned with SSL methods such
as \emph{SimCLR}. Due to the computational and data demands of pre-training,
the utilization of such backbones becomes a strenuous necessity. However,
employing these backbones may inherit vulnerabilities to adversarial attacks.
While adversarial robustness has been studied under \emph{white-box} and
\emph{black-box} settings, the robustness of models tuned on pre-trained
backbones remains largely unexplored. Additionally, the role of tuning
meta-information in mitigating exploitation risks is unclear. This work
systematically evaluates the adversarial robustness of such models across
$20,000$ combinations of tuning meta-information, including fine-tuning
techniques, backbone families, datasets, and attack types. We propose using
proxy models to transfer attacks, simulating varying levels of target knowledge
by fine-tuning these proxies with diverse configurations. Our findings reveal
that proxy-based attacks approach the effectiveness of \emph{white-box}
methods, even with minimal tuning knowledge. We also introduce a naive
"backbone attack," leveraging only the backbone to generate adversarial
samples, which outperforms \emph{black-box} attacks and rivals \emph{white-box}
methods, highlighting critical risks in model-sharing practices. Finally, our
ablations reveal how increasing tuning meta-information impacts attack
transferability, measuring each meta-information combination.

ÊëòË¶ÅÔºö<paragraph>Ê©üÂô®Ë¶ñË¶∫ÁöÑËá™Áõ£Áù£Â≠∏Áøí (SSL) ÈÄ≤Ê≠•ÊèêÂçá‰∫ÜË°®Á§∫Á©©ÂÅ•ÊÄßÂíåÊ®°ÂûãÊïàËÉΩÔºåÁî¢ÁîüÈ†êÂÖàË®ìÁ∑¥ÁöÑÈ™®ÂππÔºå‰æãÂ¶Ç‰ΩøÁî® SSL ÊñπÊ≥ïÔºà‰æãÂ¶Ç SimCLRÔºâË™øÊï¥ÁöÑ ResNet Âíå ViT Ê®°Âûã„ÄÇÁî±ÊñºÈ†êÂÖàË®ìÁ∑¥ÁöÑÈÅãÁÆóÂíåË≥áÊñôÈúÄÊ±ÇÔºå‰ΩøÁî®Ê≠§È°ûÈ™®ÂππËÆäÂæóÊ•µÁÇ∫ÂøÖË¶Å„ÄÇÁÑ∂ËÄåÔºåÊé°Áî®ÈÄô‰∫õÈ™®ÂππÂèØËÉΩÊúÉÁπºÊâøÂ∞çÊäóÊîªÊìäÁöÑÊºèÊ¥û„ÄÇÂÑòÁÆ°Âú®ÁôΩÁõíÂíåÈªëÁõíË®≠ÂÆö‰∏ãÂ∑≤Á†îÁ©∂Â∞çÊäóÁ©©ÂÅ•ÊÄßÔºå‰ΩÜÈ†êÂÖàË®ìÁ∑¥È™®Âππ‰∏äË™øÊï¥ÁöÑÊ®°ÂûãÁöÑÁ©©ÂÅ•ÊÄß‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊ≠§Â§ñÔºåË™øÊï¥ÂÖÉË≥áË®äÂú®Ê∏õËºïÂà©Áî®È¢®Èö™‰∏≠ÁöÑ‰ΩúÁî®Â∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÊú¨Á†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞Ê≠§È°ûÊ®°ÂûãÂú® 20,000 Á®ÆË™øÊï¥ÂÖÉË≥áË®äÁµÑÂêà‰∏≠ÁöÑÂ∞çÊäóÁ©©ÂÅ•ÊÄßÔºåÂåÖÊã¨ÂæÆË™øÊäÄË°ì„ÄÅÈ™®ÂππÁ≥ªÂàó„ÄÅË≥áÊñôÈõÜÂíåÊîªÊìäÈ°ûÂûã„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®‰ª£ÁêÜÊ®°Âûã‰æÜÂÇ≥Ëº∏ÊîªÊìäÔºåÈÄèÈÅé‰ΩøÁî®‰∏çÂêåÁöÑÁµÑÊÖãÂæÆË™øÈÄô‰∫õ‰ª£ÁêÜÊ®°Âûã‰æÜÊ®°Êì¨‰∏çÂêåÂ±§Á¥öÁöÑÁõÆÊ®ôÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÂç≥‰ΩøË™øÊï¥Áü•Ë≠òÊúÄÂ∞ëÔºåÂü∫Êñº‰ª£ÁêÜÁöÑÊîªÊìä‰πüÊé•ËøëÁôΩÁõíÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂ§©ÁúüÁöÑ„ÄåÈ™®ÂππÊîªÊìä„ÄçÔºåÂÉÖÂà©Áî®È™®ÂππÁî¢ÁîüÂ∞çÊäóÊ®£Êú¨ÔºåÂÖ∂Ë°®ÁèæÂÑ™ÊñºÈªëÁõíÊîªÊìäÔºå‰∏¶ËàáÁôΩÁõíÊñπÊ≥ïÁõ∏ÊäóË°°ÔºåÁ™ÅÈ°ØÊ®°ÂûãÂàÜ‰∫´ÂØ¶Âãô‰∏≠ÁöÑÈóúÈçµÈ¢®Èö™„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁöÑÊ∂àËûçÂØ¶È©óÊè≠Á§∫‰∫ÜÂ¢ûÂä†Ë™øÊï¥ÂÖÉË≥áË®äÂ¶Ç‰ΩïÂΩ±ÈüøÊîªÊìäÂèØÂÇ≥ÈÅûÊÄßÔºå‰∏¶Ë°°ÈáèÊØèÂÄãÂÖÉË≥áË®äÁµÑÂêà„ÄÇ</paragraph>

##### **Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement**
2501.12273v1 by Maosong Cao, Taolin Zhang, Mo Li, Chuyu Zhang, Yunxin Liu, Haodong Duan, Songyang Zhang, Kai Chen

The quality of Supervised Fine-Tuning (SFT) data plays a critical role in
enhancing the conversational capabilities of Large Language Models (LLMs).
However, as LLMs become more advanced, the availability of high-quality
human-annotated SFT data has become a significant bottleneck, necessitating a
greater reliance on synthetic training data. In this work, we introduce Condor,
a novel two-stage synthetic data generation framework that incorporates World
Knowledge Tree and Self-Reflection Refinement to produce high-quality SFT data
at scale. Our experimental results demonstrate that a base model fine-tuned on
only 20K Condor-generated samples achieves superior performance compared to
counterparts. The additional refinement stage in Condor further enables
iterative self-improvement for LLMs at various scales (up to 72B), validating
the effectiveness of our approach. Furthermore, our investigation into the
scaling for synthetic data in post-training reveals substantial unexplored
potential for performance improvements, opening promising avenues for future
research.

ÊëòË¶ÅÔºöÁõ£Áù£ÂºèÂæÆË™ø (SFT) Ë≥áÊñôÁöÑÂìÅË≥™Â∞çÊñºÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂ∞çË©±ËÉΩÂäõÁôºÊèÆÈóúÈçµ‰ΩúÁî®„ÄÇÁÑ∂ËÄåÔºåÈö®Ëëó LLM ËÆäÂæóË∂ä‰æÜË∂äÂÖàÈÄ≤ÔºåÈ´òÂìÅË≥™‰∫∫Â∑•Ê®ôË®ª SFT Ë≥áÊñôÁöÑÂèØÁî®ÊÄßÂ∑≤ÊàêÁÇ∫‰∏ÄÂÄãÈáçÂ§ßÁöÑÁì∂È†∏ÔºåÈÄô‰ΩøÂæóÂ∞çÂêàÊàêË®ìÁ∑¥Ë≥áÊñôÁöÑ‰æùË≥¥ÊÄßË∂ä‰æÜË∂äÈ´ò„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü CondorÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÂÖ©ÈöéÊÆµÂêàÊàêË≥áÊñôÁîüÊàêÊû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫Ü‰∏ñÁïåÁü•Ë≠òÊ®πÂíåËá™ÊàëÂèçÁúÅÁ≤æÁÖâÔºå‰ª•Â§ßË¶èÊ®°Áî¢ÁîüÈ´òÂìÅË≥™ÁöÑ SFT Ë≥áÊñô„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂÉÖÈáùÂ∞ç 20K ÂÄã Condor ÁîüÊàêÁöÑÁØÑ‰æãÈÄ≤Ë°åÂæÆË™øÁöÑÂü∫Êú¨Ê®°ÂûãÔºåËàáÂêåÈ°ûÂûãÊ®°ÂûãÁõ∏ÊØîÔºåÂèØÁç≤ÂæóÂÑ™Ë∂äÁöÑÊïàËÉΩ„ÄÇCondor ‰∏≠ÁöÑÈ°çÂ§ñÁ≤æÁÖâÈöéÊÆµÈÄ≤‰∏ÄÊ≠•ËÆì LLM ËÉΩÂ§†Âú®ÂêÑÁ®ÆË¶èÊ®°ÔºàÊúÄÈ´ò 72BÔºâ‰∏ãÈÄ≤Ë°åÂèçË¶ÜËá™ÊàëÊîπÂñÑÔºåÈ©óË≠â‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞çË®ìÁ∑¥ÂæåÂêàÊàêË≥áÊñôÁöÑÊì¥Â±ïÊÄßÈÄ≤Ë°åË™øÊü•ÔºåÊè≠Á§∫‰∫ÜÊïàËÉΩÊîπÂñÑÁöÑÂ∑®Â§ßÊú™ÈñãÁôºÊΩõÂäõÔºåÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂ÈñãÈó¢‰∫ÜÊúâÂâçÊôØÁöÑÈÄîÂæë„ÄÇ

##### **CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**
2501.12266v1 by Cristiano Patr√≠cio, Isabel Rio-Torto, Jaime S. Cardoso, Lu√≠s F. Teixeira, Jo√£o C. Neves

The main challenges limiting the adoption of deep learning-based solutions in
medical workflows are the availability of annotated data and the lack of
interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the
latter by constraining the final disease prediction on a set of predefined and
human-interpretable concepts. However, the increased interpretability achieved
through these concept-based explanations implies a higher annotation burden.
Moreover, if a new concept needs to be added, the whole system needs to be
retrained. Inspired by the remarkable performance shown by Large
Vision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet
effective, methodology, CBVLM, which tackles both of the aforementioned
challenges. First, for each concept, we prompt the LVLM to answer if the
concept is present in the input image. Then, we ask the LVLM to classify the
image based on the previous concept predictions. Moreover, in both stages, we
incorporate a retrieval module responsible for selecting the best examples for
in-context learning. By grounding the final diagnosis on the predicted
concepts, we ensure explainability, and by leveraging the few-shot capabilities
of LVLMs, we drastically lower the annotation cost. We validate our approach
with extensive experiments across four medical datasets and twelve LVLMs (both
generic and medical) and show that CBVLM consistently outperforms CBMs and
task-specific supervised methods without requiring any training and using just
a few annotated examples. More information on our project page:
https://cristianopatricio.github.io/CBVLM/.

ÊëòË¶ÅÔºöÈôêÂà∂Âú®ÈÜ´ÁôÇÂ∑•‰ΩúÊµÅÁ®ã‰∏≠Êé°Áî®Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑËß£Ê±∫ÊñπÊ°àÁöÑ‰∏ªË¶ÅÊåëÊà∞ÊòØÊ®ôË®òË≥áÊñôÁöÑÂèØÁî®ÊÄß‰ª•ÂèäÊ≠§È°ûÁ≥ªÁµ±ÁöÑÂèØËß£ÈáãÊÄß‰∏çË∂≥„ÄÇÊ¶ÇÂøµÁì∂È†∏Ê®°Âûã (CBM) ÈÄèÈÅéÈôêÂà∂‰∏ÄÁµÑÈ†êÂÆöÁæ©‰∏î‰∫∫È°ûÂèØËß£ÈáãÁöÑÊ¶ÇÂøµÂ∞çÊúÄÁµÇÁñæÁóÖÈ†êÊ∏¨Ôºå‰æÜËß£Ê±∫ÂæåËÄÖ„ÄÇÁÑ∂ËÄåÔºåÈÄèÈÅéÈÄô‰∫õÂü∫ÊñºÊ¶ÇÂøµÁöÑËß£ÈáãÊâÄÂØ¶ÁèæÁöÑÂèØËß£ÈáãÊÄßÊèêÂçáÔºåÊÑèÂë≥ËëóÊõ¥È´òÁöÑÊ®ôË®òË≤†Êìî„ÄÇÊ≠§Â§ñÔºåÂ¶ÇÊûúÈúÄË¶ÅÊñ∞Â¢û‰∏ÄÂÄãÊñ∞Ê¶ÇÂøµÔºåÂâáÈúÄË¶ÅÈáçÊñ∞Ë®ìÁ∑¥Êï¥ÂÄãÁ≥ªÁµ±„ÄÇÂèóÂà∞Â§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) Âú®Â∞èÊ®£Êú¨Ë®≠ÂÆö‰∏≠Â±ïÁèæÁöÑÂçìË∂äÊïàËÉΩÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑ CBVLM ÊñπÊ≥ïÔºå‰æÜËß£Ê±∫‰∏äËø∞ÂÖ©ÂÄãÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÂ∞çÊñºÊØèÂÄãÊ¶ÇÂøµÔºåÊàëÂÄëÊèêÁ§∫ LVLM ÂõûÁ≠îËº∏ÂÖ•ÂΩ±ÂÉè‰∏≠ÊòØÂê¶ÂåÖÂê´Ë©≤Ê¶ÇÂøµ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË¶ÅÊ±Ç LVLM Ê†πÊìöÂÖàÂâçÁöÑÊ¶ÇÂøµÈ†êÊ∏¨Â∞çÂΩ±ÂÉèÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊ≠§Â§ñÔºåÂú®ÂÖ©ÂÄãÈöéÊÆµ‰∏≠ÔºåÊàëÂÄëÈÉΩÁ¥çÂÖ•‰∏ÄÂÄãÊ™¢Á¥¢Ê®°ÁµÑÔºåË≤†Ë≤¨ÈÅ∏Âá∫ÊúÄÈÅ©ÂêàÊñºÊÉÖÂ¢ÉÂ≠∏ÁøíÁöÑÁØÑ‰æã„ÄÇÈÄèÈÅéÂ∞áÊúÄÁµÇË®∫Êñ∑Âª∫Á´ãÂú®È†êÊ∏¨Ê¶ÇÂøµ‰πã‰∏äÔºåÊàëÂÄëÁ¢∫‰øù‰∫ÜÂèØËß£ÈáãÊÄßÔºå‰∏¶ÈÄèÈÅéÂà©Áî® LVLMs ÁöÑÂ∞èÊ®£Êú¨ËÉΩÂäõÔºåÊàëÂÄëÂ§ßÂπÖÈôç‰Ωé‰∫ÜÊ®ôË®òÊàêÊú¨„ÄÇÊàëÂÄëÈÄèÈÅéÂõõÂÄãÈÜ´ÁôÇË≥áÊñôÈõÜÂíåÂçÅ‰∫åÂÄã LVLMÔºàÈÄöÁî®ÂíåÈÜ´ÁôÇÔºâÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑ‰ΩúÊ≥ïÔºå‰∏¶È°ØÁ§∫ CBVLM Âú®ÁÑ°ÈúÄ‰ªª‰ΩïË®ìÁ∑¥‰∏îÂÉÖ‰ΩøÁî®Â∞ëÊï∏Ê®ôË®òÁØÑ‰æãÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂßãÁµÇÂÑ™Êñº CBM ÂíåÁâπÂÆöÊñº‰ªªÂãôÁöÑÁõ£Áù£ÂºèÊñπÊ≥ï„ÄÇÊõ¥Â§öË≥áË®äË´ãË¶ãÊàëÂÄëÁöÑÂ∞àÊ°àÈ†ÅÈù¢Ôºöhttps://cristianopatricio.github.io/CBVLM/„ÄÇ

##### **FOCUS: First Order Concentrated Updating Scheme**
2501.12243v1 by Yizhou Liu, Ziming Liu, Jeff Gore

Large language models (LLMs) demonstrate remarkable performance, and
improving their pre-training process appears to be key to enhancing their
capabilities further. Based on the documented success of Adam, learning rate
decay, and weight decay, we hypothesize that the pre-training loss landscape
features a narrowing valley structure. Through experiments with synthetic loss
functions, we discover that when gradient query noise is high relative to the
valley's sharpness, Adam's performance falls behind that of Signum because Adam
reduces the effective step size too drastically. This observation led us to
develop FOCUS, an optimizer that enhances Signum by incorporating attraction
toward moving averaged parameters, allowing it to handle noise better while
maintaining larger step sizes. In training GPT-2, FOCUS proves to be more
stable than Signum and faster than Adam. These results suggest that gradient
noise may be an underappreciated limiting factor in LLM training, and FOCUS
offers promising solutions.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â±ïÁèæÂá∫ÂçìË∂äÁöÑÊïàËÉΩÔºåËÄåÊîπÂñÑÂÖ∂È†êË®ìÁ∑¥Á®ãÂ∫è‰ºº‰πéÊòØÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÂÖ∂ÂäüËÉΩÁöÑÈóúÈçµ„ÄÇÊ†πÊìö Adam„ÄÅÂ≠∏ÁøíÁéáË°∞Ê∏õÂíåÊ¨äÈáçË°∞Ê∏õÁöÑÂ∑≤Ë®òÈåÑÊàêÂäüÔºåÊàëÂÄëÂÅáË®≠È†êË®ìÁ∑¥ÊêçÂ§±ÊôØËßÄÂÖ∑ÊúâÁ∏ÆÂ∞èÁöÑË∞∑Âú∞ÁµêÊßã„ÄÇÈÄèÈÅéÂ∞çÂêàÊàêÊêçÂ§±ÂáΩÊï∏ÁöÑÂØ¶È©óÔºåÊàëÂÄëÁôºÁèæÁï∂Ê¢ØÂ∫¶Êü•Ë©¢ÈõúË®äÁõ∏Â∞çÊñºË∞∑Âú∞ÁöÑÈä≥Âà©Â∫¶ËºÉÈ´òÊôÇÔºåAdam ÁöÑÊïàËÉΩÊúÉËêΩÂæåÊñº SignumÔºåÂõ†ÁÇ∫ Adam ÊúÉÈÅéÂ∫¶Â§ßÂπÖÂ∫¶Âú∞Ê∏õÂ∞ëÊúâÊïàÊ≠•È©üÂ§ßÂ∞è„ÄÇÈÄôÂÄãËßÄÂØüËÆìÊàëÂÄëÈñãÁôºÂá∫ FOCUSÔºå‰∏ÄÁ®ÆÈÄèÈÅéÁ¥çÂÖ•Â∞çÁßªÂãïÂπ≥ÂùáÂèÉÊï∏ÁöÑÂê∏ÂºïÂäõ‰æÜÂ¢ûÂº∑ Signum ÁöÑÊúÄ‰Ω≥ÂåñÂô®ÔºåËÆìÂÆÉÂèØ‰ª•Âú®Á∂≠ÊåÅËºÉÂ§ßÊ≠•È©üÂ§ßÂ∞èÁöÑÂêåÊôÇÊõ¥Â•ΩÂú∞ËôïÁêÜÈõúË®ä„ÄÇÂú®Ë®ìÁ∑¥ GPT-2 ÊôÇÔºåFOCUS Ë≠âÊòéÊØî Signum Êõ¥Á©©ÂÆöÔºåËÄå‰∏îÊØî Adam Êõ¥Âø´„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÊ¢ØÂ∫¶ÈõúË®äÂèØËÉΩÊòØ LLM Ë®ìÁ∑¥‰∏≠‰∏ÄÂÄãÊú™Ë¢´ÂÖÖÂàÜÈáçË¶ñÁöÑÈôêÂà∂Âõ†Á¥†ÔºåËÄå FOCUS Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**
2501.12231v1 by Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min

The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.

ÊëòË¶ÅÔºöÁîüÊàêÊ®°ÂûãËÉΩÂäõÁöÑÊèêÂçáÊúâÂä©‰∫éÊûÑÂª∫Âà©Áî®ËØ≠Ë®Ä‰πãÂ§ñÁöÑÂ§öÊ®°ÊÄÅËôöÊãüÂä©Êâã„ÄÇÈÄöËøáËßÇÂØü‰∫∫Á±ªÊâßË°åÂ§öÊ≠•È™§‰ªªÂä°ÔºåÂèØ‰ª•ÊûÑÂª∫ÂØπÊ≠£Âú®ÊâßË°åÁöÑÂä®‰ΩúÂíå‰ªªÂä°ÊúâÊÉÖÂ¢ÉÊÑüÁü•ÁöÑÂä©ÊâãÔºå‰Ωø‰ªñ‰ª¨ËÉΩÂ§üÊ†πÊçÆËøôÁßçÁêÜËß£Êèê‰æõÂ∏ÆÂä©„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™ÂÖ∑ÊúâÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∏ä‰∏ãÊñáÊÑüÁü•Êåá‰ª§‰ªªÂä°Âä©Êâã (InsTALL)ÔºåËØ•Âä©ÊâãÂà©Áî®Âú®Á∫øËßÜËßâÊµÅÔºà‰æãÂ¶ÇÁî®Êà∑ÁöÑÂ±èÂπïÂÖ±‰∫´ÊàñËßÜÈ¢ëÂΩïÂà∂ÔºâÔºåÂπ∂ÂÆûÊó∂ÂìçÂ∫î‰∏éÊâãÂ§¥‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÁî®Êà∑Êü•ËØ¢„ÄÇ‰∏∫‰∫ÜÊèê‰æõÊúâÁî®ÁöÑÂ∏ÆÂä©ÔºåInsTALL 1) Âú®‰ªªÂä°ËßÜÈ¢ëÂíåÈÖçÂØπÊñáÊú¨Êï∞ÊçÆ‰∏äËÆ≠ÁªÉÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºå‰ª•Âèä 2) ‰ªéËßÜÈ¢ëÊï∞ÊçÆ‰∏≠Ëá™Âä®ÊèêÂèñ‰ªªÂä°ÂõæÔºåÂπ∂Âú®ËÆ≠ÁªÉÂíåÊé®ÁêÜÊó∂Èó¥Âà©Áî®ÂÆÉ„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫Ü InsTALL Âú®ËÄÉËôëÁî®‰∫éÂ§öÊ®°ÊÄÅÊ¥ªÂä®ÁêÜËß£ÁöÑÊèêËÆÆÂ≠ê‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ‚Äî‚Äî‰ªªÂä°ËØÜÂà´ (TR)„ÄÅÂä®‰ΩúËØÜÂà´ (AR)„ÄÅ‰∏ã‰∏Ä‰∏™Âä®‰ΩúÈ¢ÑÊµã (AP) ÂíåËÆ°ÂàíÈ¢ÑÊµã (PP)‚Äî‚ÄîÂπ∂‰∏îÂú®‰∏éËá™Âä®ÈîôËØØËØÜÂà´Áõ∏ÂÖ≥ÁöÑ‰∏§‰∏™Êñ∞Â≠ê‰ªªÂä°‰∏ä‰ºò‰∫éÁé∞ÊúâÁöÑÂü∫ÂáÜ„ÄÇ

##### **Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model**
2501.12206v1 by Kazi Hasan Ibn Arif, Sajib Acharjee Dip, Khizar Hussain, Lang Zhang, Chris Thomas

Large Vision Language Models (LVLMs) have demonstrated remarkable
capabilities in understanding and describing visual content, achieving
state-of-the-art performance across various vision-language tasks. However,
these models frequently exhibit hallucination behavior, where they generate
descriptions containing objects or details absent in the input image. Our work
investigates this phenomenon by analyzing attention patterns across transformer
layers and heads, revealing that hallucinations often stem from progressive
degradation of visual grounding in deeper layers. We propose a novel attention
modification approach that combines selective token emphasis and head-specific
modulation to maintain visual grounding throughout the generation process. Our
method introduces two key components: (1) a dual-stream token selection
mechanism that identifies and prioritizes both locally informative and
spatially significant visual tokens, and (2) an attention head-specific
modulation strategy that differentially amplifies visual information processing
based on measured visual sensitivity of individual attention heads. Through
extensive experimentation on the MSCOCO dataset, we demonstrate that our
approach reduces hallucination rates by up to 62.3\% compared to baseline
models while maintaining comparable task performance. Our analysis reveals that
selectively modulating tokens across attention heads with varying levels of
visual sensitivity can significantly improve visual grounding without requiring
model retraining.

ÊëòË¶ÅÔºöÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) Â∑≤Â±ïÁèæÂá∫Âú®ÁêÜËß£ÂíåÊèèËø∞Ë¶ñË¶∫ÂÖßÂÆπÊñπÈù¢ÁöÑÂçìË∂äËÉΩÂäõÔºåÂú®ÂêÑÁ®ÆË¶ñË¶∫Ë™ûË®Ä‰ªªÂãô‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÁ∂ìÂ∏∏Ë°®ÁèæÂá∫ÂπªË¶∫Ë°åÁÇ∫ÔºåÂÆÉÂÄëÊúÉÁî¢ÁîüÂåÖÂê´Ëº∏ÂÖ•ÂΩ±ÂÉè‰∏≠‰∏çÂ≠òÂú®ÁöÑÁâ©‰ª∂ÊàñÁ¥∞ÁØÄÁöÑÊèèËø∞„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéÂàÜÊûêTransformerÂ±§ÂíåÈ†≠ÈÉ®ÁöÑÊ≥®ÊÑèÂäõÊ®°Âºè‰æÜÊé¢Ë®éÈÄôÁ®ÆÁèæË±°ÔºåÊè≠Á§∫ÂπªË¶∫ÈÄöÂ∏∏Ê∫êÊñºËºÉÊ∑±Â±§ÁöÑË¶ñË¶∫Âü∫Á§éÈÄêÊº∏ÈÄÄÂåñ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ≥®ÊÑèÂäõ‰øÆÊîπÊñπÊ≥ïÔºåÁµêÂêàÈÅ∏ÊìáÊÄßÁöÑÊ¨äÊ®ôÂº∑Ë™øÂíåÁâπÂÆöÊñºÈ†≠ÈÉ®ÁöÑË™øËÆäÔºå‰ª•Âú®Êï¥ÂÄãÁîüÊàêÈÅéÁ®ã‰∏≠Á∂≠ÊåÅË¶ñË¶∫Âü∫Á§é„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÂºïÂÖ•‰∫ÜÂÖ©ÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºö(1) ‰∏ÄÁ®ÆÈõô‰∏≤ÊµÅÊ¨äÊ®ôÈÅ∏ÊìáÊ©üÂà∂ÔºåÁî®ÊñºË≠òÂà•ÂíåÂÑ™ÂÖàËôïÁêÜÂ±ÄÈÉ®Ë≥áË®äÊÄßÂíåÁ©∫ÈñìÈ°ØËëóÊÄßÁöÑË¶ñË¶∫Ê¨äÊ®ôÔºå‰ª•Âèä (2) ‰∏ÄÁ®ÆÊ≥®ÊÑèÂäõÈ†≠ÈÉ®ÁâπÂÆöË™øËÆäÁ≠ñÁï•ÔºåÊ†πÊìöÂÄãÂà•Ê≥®ÊÑèÂäõÈ†≠ÈÉ®ÁöÑÊ∏¨ÈáèË¶ñË¶∫ÊïèÊÑüÂ∫¶ÔºåÂ∞çË¶ñË¶∫Ë≥áË®äËôïÁêÜÈÄ≤Ë°å‰∏çÂêåÁöÑÊîæÂ§ß„ÄÇÈÄèÈÅéÂú® MSCOCO Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé‰∫ÜËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊäÄË°ìÂ∞áÂπªË¶∫ÁéáÈôç‰Ωé‰∫ÜÂ§öÈÅî 62.3%ÔºåÂêåÊôÇÁ∂≠ÊåÅ‰∫ÜÁõ∏Áï∂ÁöÑ‰ªªÂãôË°®Áèæ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÈÅ∏ÊìáÊÄßÂú∞Ë™øËÆäÂÖ∑Êúâ‰∏çÂêåË¶ñË¶∫ÊïèÊÑüÂ∫¶Â±§Á¥öÁöÑÊ≥®ÊÑèÂäõÈ†≠ÈÉ®ÁöÑÊ¨äÊ®ôÔºåÂèØ‰ª•Âú®‰∏çÈúÄÈáçÊñ∞Ë®ìÁ∑¥Ê®°ÂûãÁöÑÊÉÖÊ≥Å‰∏ãÔºåÈ°ØËëóÊîπÂñÑË¶ñË¶∫Âü∫Á§é„ÄÇ

##### **An End-to-End Approach for Korean Wakeword Systems with Speaker Authentication**
2501.12194v1 by Geonwoo Seo

Wakeword detection plays a critical role in enabling AI assistants to listen
to user voices and interact effectively. However, for languages other than
English, there is a significant lack of pre-trained wakeword models.
Additionally, systems that merely determine the presence of a wakeword can pose
serious privacy concerns. In this paper, we propose an end-to-end approach that
trains wakewords for Non-English languages, particulary Korean, and uses this
to develop a Voice Authentication model to protect user privacy. Our
implementation employs an open-source platform OpenWakeWord, which performs
wakeword detection using an FCN (Fully-Connected Network) architecture. Once a
wakeword is detected, our custom-developed code calculates cosine similarity
for robust user authentication. Experimental results demonstrate the
effectiveness of our approach, achieving a 16.79% and a 6.6% Equal Error Rate
(EER) each in the Wakeword Detection and the Voice Authentication. These
findings highlight the model's potential in providing secure and accurate
wakeword detection and authentication for Korean users.

ÊëòË¶ÅÔºöÂñöÈÜíÂ≠óÂÅµÊ∏¨Âú®ËÆì AI Âä©ÁêÜËÅÜËÅΩ‰ΩøÁî®ËÄÖËÅ≤Èü≥‰∏¶ÊúâÊïà‰∫íÂãï‰∏≠ÊâÆÊºîÈóúÈçµËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÈùûËã±Ë™ûË™ûË®Ä‰æÜË™™ÔºåÈ†êÂÖàË®ìÁ∑¥ÁöÑÂñöÈÜíÂ≠óÊ®°ÂûãÂ≠òÂú®ËëóÈ°ØËëóÁöÑÁº∫‰πè„ÄÇÊ≠§Â§ñÔºåÂÉÖÂÉÖÂà§ÂÆöÂñöÈÜíÂ≠óÂ≠òÂú®ÁöÑÁ≥ªÁµ±ÂèØËÉΩÊúÉÈÄ†ÊàêÂö¥ÈáçÁöÑÈö±ÁßÅÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ´ØÂ∞çÁ´ØÁöÑÊñπÊ≥ïÔºåÁî®ÊñºË®ìÁ∑¥ÈùûËã±Ë™ûË™ûË®ÄÔºàÁâπÂà•ÊòØÈüìË™ûÔºâÁöÑÂñöÈÜíÂ≠óÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜÈñãÁôº‰∏ÄÂÄãË™ûÈü≥È©óË≠âÊ®°Âûã‰ª•‰øùË≠∑‰ΩøÁî®ËÄÖÈö±ÁßÅ„ÄÇÊàëÂÄëÁöÑÂØ¶‰ΩúÊé°Áî®‰∏ÄÂÄãÈñãÊ∫êÂπ≥Âè∞ OpenWakeWordÔºåÂÆÉ‰ΩøÁî® FCNÔºàÂÖ®ÈÄ£Êé•Á∂≤Ë∑ØÔºâÊû∂Êßã‰æÜÂü∑Ë°åÂñöÈÜíÂ≠óÂÅµÊ∏¨„ÄÇ‰∏ÄÊó¶ÂÅµÊ∏¨Âà∞ÂñöÈÜíÂ≠óÔºåÊàëÂÄëËá™Ë®ÇÈñãÁôºÁöÑÁ®ãÂºèÁ¢ºÊúÉË®àÁÆóÈ§òÂº¶Áõ∏‰ººÂ∫¶‰ª•ÈÄ≤Ë°åÁ©©ÂÅ•ÁöÑ‰ΩøÁî®ËÄÖÈ©óË≠â„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÂú®ÂñöÈÜíÂ≠óÂÅµÊ∏¨ÂíåË™ûÈü≥È©óË≠â‰∏≠ÂàÜÂà•ÈÅîÂà∞ 16.79% Âíå 6.6% ÁöÑÁ≠âÈåØÁéáÔºàEERÔºâ„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜË©≤Ê®°ÂûãÂú®ÁÇ∫ÈüìË™û‰ΩøÁî®ËÄÖÊèê‰æõÂÆâÂÖ®‰∏îÊ∫ñÁ¢∫ÁöÑÂñöÈÜíÂ≠óÂÅµÊ∏¨ÂíåÈ©óË≠âÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **AdaServe: SLO-Customized LLM Serving with Fine-Grained Speculative Decoding**
2501.12162v1 by Zikun Li, Zhuofu Chen, Remi Delacourt, Gabriele Oliaro, Zeyu Wang, Qinghan Chen, Shuhuai Lin, April Yang, Zhihao Zhang, Zhuoming Chen, Sean Lai, Xupeng Miao, Zhihao Jia

This paper introduces AdaServe, the first LLM serving system to support SLO
customization through fine-grained speculative decoding. AdaServe leverages the
logits of a draft model to predict the speculative accuracy of tokens and
employs a theoretically optimal algorithm to construct token trees for
verification. To accommodate diverse SLO requirements without compromising
throughput, AdaServe employs a speculation-and-selection scheme that first
constructs candidate token trees for each request and then dynamically selects
tokens to meet individual SLO constraints while optimizing throughput.
Comprehensive evaluations demonstrate that AdaServe achieves up to 73% higher
SLO attainment and 74% higher goodput compared to state-of-the-art systems.
These results underscore AdaServe's potential to enhance the efficiency and
adaptability of LLM deployments across varied application scenarios.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñá‰ªãÁ¥π‰∫Ü AdaServeÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊîØÊè¥ÈÄèÈÅéÁ¥∞Á≤íÂ∫¶Êé®Ê∏¨Ëß£Á¢º‰æÜËá™Ë®ÇÊúçÂãôÁ≠âÁ¥öÁõÆÊ®ô (SLO) ÁöÑ LLM ÊúçÂãôÁ≥ªÁµ±„ÄÇAdaServe Âà©Áî®ËçâÁ®øÊ®°ÂûãÁöÑÈÇèËºØ‰æÜÈ†êÊ∏¨‰ª£Á¢ºÁöÑÊé®Ê∏¨Ê∫ñÁ¢∫Â∫¶Ôºå‰∏¶Êé°Áî®ÁêÜË´ñ‰∏äÊúÄ‰Ω≥ÁöÑÊºîÁÆóÊ≥ï‰æÜÂª∫Êßã‰ª£Á¢ºÊ®π‰ª•ÈÄ≤Ë°åÈ©óË≠â„ÄÇÁÇ∫‰∫ÜÊªøË∂≥‰∏çÂêåÁöÑ SLO ÈúÄÊ±ÇÔºåÂêåÊôÇ‰∏çÂΩ±ÈüøËôïÁêÜÈáèÔºåAdaServe Êé°Áî®‰∏ÄÁ®ÆÊé®Ê∏¨ËàáÈÅ∏ÊìáÁöÑÊñπÊ°àÔºåË©≤ÊñπÊ°àÊúÉÂÖàÁÇ∫ÊØèÂÄãË¶ÅÊ±ÇÂª∫ÊßãÂÄôÈÅ∏‰ª£Á¢ºÊ®πÔºåÁÑ∂ÂæåÂãïÊÖãÈÅ∏Êìá‰ª£Á¢º‰ª•ÊªøË∂≥ÂÄãÂà• SLO Á¥ÑÊùüÔºåÂêåÊôÇÊúÄ‰Ω≥ÂåñËôïÁêÜÈáè„ÄÇÂÖ®Èù¢ÁöÑË©ï‰º∞È°ØÁ§∫ÔºåËàáÁèæÊúâÁ≥ªÁµ±Áõ∏ÊØîÔºåAdaServe ÁöÑ SLO ÈÅîÊàêÁéáÊúÄÈ´òÂèØÊèêÂçá 73%ÔºåËÄåÂ•ΩËôïÁéáÂâáÊúÄÈ´òÂèØÊèêÂçá 74%„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫Ü AdaServe Âú®ÊèêÂçá LLM ÈÉ®ÁΩ≤ÊïàÁéáÂíåÈÅ©ÊáâÂäõÊñπÈù¢ÁöÑÊΩõÂäõÔºåÈÅ©Áî®ÊñºÂêÑÁ®ÆÊáâÁî®Â†¥ÊôØ„ÄÇ

##### **On the practical applicability of modern DFT functionals for chemical computations. Case study of DM21 applicability for geometry optimization**
2501.12149v1 by Kirill Kulaev, Alexander Ryabov, Michael Medvedev, Evgeny Burnaev, Vladimir Vanovskiy

Density functional theory (DFT) is probably the most promising approach for
quantum chemistry calculations considering its good balance between
calculations precision and speed. In recent years, several neural network-based
functionals have been developed for exchange-correlation energy approximation
in DFT, DM21 developed by Google Deepmind being the most notable between them.
This study focuses on evaluating the efficiency of DM21 functional in
predicting molecular geometries, with a focus on the influence of oscillatory
behavior in neural network exchange-correlation functionals. We implemented
geometry optimization in PySCF for the DM21 functional in geometry optimization
problem, compared its performance with traditional functionals, and tested it
on various benchmarks. Our findings reveal both the potential and the current
challenges of using neural network functionals for geometry optimization in
DFT. We propose a solution extending the practical applicability of such
functionals and allowing to model new substances with their help.

ÊëòË¶ÅÔºöÂØÜÂ∫¶Ê≥õÂáΩÁêÜË´ñ (DFT) ÂèØËÉΩÊòØÂú®ÈáèÂ≠êÂåñÂ≠∏Ë®àÁÆó‰∏≠ÔºåÂú®Ë®àÁÆóÁ≤æÂ∫¶ÂíåÈÄüÂ∫¶‰πãÈñìÂèñÂæóËâØÂ•ΩÂπ≥Ë°°ÁöÑÊúÄÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇËøëÂπ¥‰æÜÔºåÂ∑≤Á∂ìÁÇ∫ DFT ‰∏≠ÁöÑ‰∫§ÊèõÁõ∏ÈóúËÉΩËøë‰ººÈñãÁôº‰∫ÜÂπæÁ®ÆÂü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊ≥õÂáΩÔºåÁî± Google Deepmind ÈñãÁôºÁöÑ DM21 ÊòØÂÖ∂‰∏≠ÊúÄËëóÂêçÁöÑ„ÄÇÊú¨Á†îÁ©∂ÈáçÈªûÂú®ÊñºË©ï‰º∞ DM21 Ê≥õÂáΩÂú®È†êÊ∏¨ÂàÜÂ≠êÂπæ‰ΩïÂΩ¢ÁãÄÊñπÈù¢ÁöÑÊïàÁéáÔºåÈáçÈªûÂú®ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∫§ÊèõÁõ∏ÈóúÊ≥õÂáΩ‰∏≠ÊåØÁõ™Ë°åÁÇ∫ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂú®Âπæ‰ΩïÊúÄ‰Ω≥ÂåñÂïèÈ°å‰∏≠ÁÇ∫ DM21 Ê≥õÂáΩÂØ¶‰Ωú‰∫Ü PySCF ‰∏≠ÁöÑÂπæ‰ΩïÊúÄ‰Ω≥ÂåñÔºåÂ∞áÂÖ∂ÊïàËÉΩËàáÂÇ≥Áµ±Ê≥õÂáΩÈÄ≤Ë°åÊØîËºÉÔºå‰∏¶Âú®ÂêÑÁ®ÆÂü∫Ê∫ñ‰∏äÂ∞çÂÖ∂ÈÄ≤Ë°åÊ∏¨Ë©¶„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊè≠Á§∫‰∫Ü‰ΩøÁî®Á•ûÁ∂ìÁ∂≤Ë∑ØÊ≥õÂáΩÈÄ≤Ë°å DFT ‰∏≠Âπæ‰ΩïÊúÄ‰Ω≥ÂåñÁöÑÊΩõÂäõÂíåÁï∂ÂâçÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËß£Ê±∫ÊñπÊ°àÔºåÊì¥Â±ï‰∫ÜÊ≠§È°ûÊ≥õÂáΩÁöÑÂØ¶Áî®ÈÅ©Áî®ÊÄßÔºå‰∏¶ÂÖÅË®±ËóâÂä©ÂÆÉÂÄë‰æÜÂª∫Ê®°Êñ∞Áâ©Ë≥™„ÄÇ

##### **Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities**
2501.12147v1 by Qirun Dai, Dylan Zhang, Jiaqi W. Ma, Hao Peng

Selecting appropriate training data is crucial for effective instruction
fine-tuning of large language models (LLMs), which aims to (1) elicit strong
capabilities, and (2) achieve balanced performance across a diverse range of
tasks. Influence-based methods show promise in achieving (1) by estimating the
contribution of each training example to the model's predictions, but often
struggle with (2). Our systematic investigation reveals that this
underperformance can be attributed to an inherent bias where certain tasks
intrinsically have greater influence than others. As a result, data selection
is often biased towards these tasks, not only hurting the model's performance
on others but also, counterintuitively, harms performance on these
high-influence tasks themselves.
  As a remedy, we propose BIDS, a Balanced and Influential Data Selection
algorithm. BIDS first normalizes influence scores of the training data, and
then iteratively balances data selection by choosing the training example with
the highest influence on the most underrepresented task. Experiments with both
Llama-3 and Mistral-v0.3 on seven benchmarks spanning five diverse capabilities
show that BIDS consistently outperforms both state-of-the-art influence-based
algorithms and other non-influence-based selection frameworks. Surprisingly,
training on a 15% subset selected by BIDS can even outperform full-dataset
training with a much more balanced performance. Our analysis further highlights
the importance of both instance-level normalization and iterative optimization
of selected data for balanced learning of diverse capabilities.

ÊëòË¶ÅÔºö<paragraph>ÈÅ∏ÊìáÈÅ©Áï∂ÁöÑË®ìÁ∑¥Ë≥áÊñôÂ∞çÊñºÊúâÊïàÊåáÁ§∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂæÆË™øËá≥ÈóúÈáçË¶ÅÔºåÂÖ∂ÁõÆÊ®ôÁÇ∫Ôºö(1) ÂºïÁôºÂº∑Â§ßÁöÑËÉΩÂäõÔºå‰ª•Âèä (2) Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÈÅîÊàêÂπ≥Ë°°ÁöÑË°®Áèæ„ÄÇÂü∫ÊñºÂΩ±ÈüøÂäõÁöÑÊñπÊ≥ïÈ°ØÁ§∫Âá∫Âú®ÈÅîÊàê (1) ÊñπÈù¢ÂæàÊúâÂ∏åÊúõÔºåÈÄèÈÅé‰º∞Ë®àÊØèÂÄãË®ìÁ∑¥ÁØÑ‰æãÂ∞çÊ®°ÂûãÈ†êÊ∏¨ÁöÑË≤¢ÁçªÔºå‰ΩÜÈÄöÂ∏∏Âú® (2) ÊñπÈù¢ÊúÉÈÅ≠ÈÅáÂõ∞Èõ£„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±ÊÄßË™øÊü•È°ØÁ§∫ÔºåÈÄôÁ®ÆË°®Áèæ‰∏ç‰Ω≥ÂèØÊ≠∏Âõ†ÊñºÂÖßÂú®ÂÅèÂ∑ÆÔºåÂÖ∂‰∏≠Êüê‰∫õ‰ªªÂãôÊú¨Ë≥™‰∏äÊØîÂÖ∂‰ªñ‰ªªÂãôÂÖ∑ÊúâÊõ¥Â§ßÁöÑÂΩ±ÈüøÂäõ„ÄÇÂõ†Ê≠§ÔºåË≥áÊñôÈÅ∏ÊìáÈÄöÂ∏∏ÊúÉÂÅèÂêëÈÄô‰∫õ‰ªªÂãôÔºåÈÄô‰∏çÂÉÖÊúÉÊêçÂÆ≥Ê®°ÂûãÂú®ÂÖ∂‰ªñ‰ªªÂãô‰∏äÁöÑË°®ÁèæÔºåËÄå‰∏îÂèçÁõ¥Ë¶∫Âú∞ÊúÉÊêçÂÆ≥ÈÄô‰∫õÈ´òÂΩ±ÈüøÂäõ‰ªªÂãôÊú¨Ë∫´ÁöÑË°®Áèæ„ÄÇ
‰ΩúÁÇ∫Ë£úÊïëÊé™ÊñΩÔºåÊàëÂÄëÊèêÂá∫ BIDSÔºå‰∏ÄÁ®ÆÂπ≥Ë°°‰∏îÊúâÂΩ±ÈüøÂäõÁöÑË≥áÊñôÈÅ∏ÊìáÊºîÁÆóÊ≥ï„ÄÇBIDS È¶ñÂÖàÂ∞áË®ìÁ∑¥Ë≥áÊñôÁöÑÂΩ±ÈüøÂäõÂàÜÊï∏Ê®ôÊ∫ñÂåñÔºåÁÑ∂ÂæåÈÄèÈÅéÈÅ∏ÊìáÂ∞ç‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑ‰ªªÂãôÂΩ±ÈüøÊúÄÂ§ßÁöÑË®ìÁ∑¥ÁØÑ‰æãÔºåÂèçË¶ÜÂπ≥Ë°°Ë≥áÊñôÈÅ∏Êìá„ÄÇÂú® Llama-3 Âíå Mistral-v0.3 ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÔºåÊ∂µËìã‰∫îÁ®Æ‰∏çÂêåËÉΩÂäõÁöÑ‰∏ÉÂÄãÂü∫Ê∫ñÔºåÈ°ØÁ§∫ BIDS ÊåÅÁ∫åÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºÂΩ±ÈüøÂäõÁöÑÊºîÁÆóÊ≥ïÂíåÂÖ∂‰ªñÈùûÂü∫ÊñºÂΩ±ÈüøÂäõÁöÑÈÅ∏ÊìáÊû∂Êßã„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÂú® BIDS ÈÅ∏ÊìáÁöÑ 15% Â≠êÈõÜ‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÔºåÁîöËá≥ÂèØ‰ª•ÂÑ™Êñº‰ΩøÁî®Âπ≥Ë°°Â∫¶Êõ¥È´òÁöÑÂÆåÊï¥Ë≥áÊñôÈõÜË®ìÁ∑¥„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈÄ≤‰∏ÄÊ≠•Á™ÅÈ°Ø‰∫ÜÂú®Âπ≥Ë°°Â≠∏ÁøíÂêÑÁ®ÆËÉΩÂäõÊôÇÔºåÂü∑Ë°åÂÄãÈ´îÂ±§Á¥öÊ®ôÊ∫ñÂåñÂíåÂèçË¶ÜÊúÄ‰Ω≥ÂåñÊâÄÈÅ∏Ë≥áÊñôÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **FedCLEAN: byzantine defense by CLustering Errors of Activation maps in Non-IID federated learning environments**
2501.12123v1 by Mehdi Ben Ghali, Reda Bellafqira, Gouenou Coatrieux

Federated Learning (FL) enables clients to collaboratively train a global
model using their local datasets while reinforcing data privacy. However, FL is
susceptible to poisoning attacks. Existing defense mechanisms assume that
clients' data are independent and identically distributed (IID), making them
ineffective in real-world applications where data are non-IID. This paper
presents FedCLEAN, the first defense capable of filtering attackers' model
updates in a non-IID FL environment. The originality of FedCLEAN is twofold.
First, it relies on a client confidence score derived from the reconstruction
errors of each client's model activation maps for a given trigger set, with
reconstruction errors obtained by means of a Conditional Variational
Autoencoder trained according to a novel server-side strategy. Second, we
propose an ad-hoc trust propagation algorithm based on client scores, which
allows building a cluster of benign clients while flagging potential attackers.
Experimental results on the datasets MNIST and FashionMNIST demonstrate the
robustness of FedCLEAN against Byzantine attackers in non-IID scenarios and a
close-to-zero benign client misclassification rate, even in the absence of an
attack.

ÊëòË¶ÅÔºöËÅØÁõüÂºèÂ≠∏Áøí (FL) ËÆìÂÆ¢Êà∂Á´ØËÉΩÂ§†Âà©Áî®ÂÖ∂Êú¨Ê©üË≥áÊñôÈõÜÈÄ≤Ë°åÂçî‰ΩúË®ìÁ∑¥ÔºåÂêåÊôÇÂº∑ÂåñË≥áÊñôÈö±ÁßÅ„ÄÇÁÑ∂ËÄåÔºåFL ÂÆπÊòìÂèóÂà∞‰∏≠ÊØíÊîªÊìä„ÄÇÁèæÊúâÁöÑÈò≤Á¶¶Ê©üÂà∂ÂÅáË®≠ÂÆ¢Êà∂Á´ØË≥áÊñôÊòØÁç®Á´ã‰∏îÂêåË≥™ÂàÜ‰Ωà (IID)ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂú®Ë≥áÊñôÈùû IID ÁöÑÂØ¶ÈöõÊáâÁî®‰∏≠ÁÑ°Êïà„ÄÇÊú¨ÊñáÊèêÂá∫ FedCLEANÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãËÉΩÂ§†Âú®Èùû IID FL Áí∞Â¢É‰∏≠ÈÅéÊøæÊîªÊìäËÄÖÊ®°ÂûãÊõ¥Êñ∞ÁöÑÈò≤Á¶¶Ê©üÂà∂„ÄÇFedCLEAN ÁöÑÂéüÂâµÊÄßÊúâÂÖ©ÊñπÈù¢„ÄÇÈ¶ñÂÖàÔºåÂÆÉ‰æùË≥¥ÊñºÂÆ¢Êà∂Á´Ø‰ø°ÂøÉË©ïÂàÜÔºåË©≤Ë©ïÂàÜ‰æÜËá™ÊñºÁâπÂÆöËß∏ÁôºÂô®ÈõÜÁöÑÊØèÂÄãÂÆ¢Êà∂Á´ØÊ®°ÂûãÂïüÁî®Êò†Â∞ÑÁöÑÈáçÂª∫Ë™§Â∑ÆÔºåÈáçÂª∫Ë™§Â∑ÆÊòØÈÄèÈÅéÊ†πÊìöÊñ∞Á©é‰º∫ÊúçÂô®Á´ØÁ≠ñÁï•Ë®ìÁ∑¥ÁöÑÊ¢ù‰ª∂ËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô®Áç≤ÂæóÁöÑ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂÆ¢Êà∂Á´ØË©ïÂàÜÁöÑËá®ÊôÇ‰ø°‰ªªÂÇ≥Êí≠ÊºîÁÆóÊ≥ïÔºåË©≤ÊºîÁÆóÊ≥ïÂÖÅË®±Âª∫Á´ãËâØÊÄßÂÆ¢Êà∂Á´ØÂè¢ÈõÜÔºåÂêåÊôÇÊ®ôË®òÊΩõÂú®ÁöÑÊîªÊìäËÄÖ„ÄÇÂú® MNIST Âíå FashionMNIST Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü FedCLEAN Âú®Èùû IID ÊÉÖÂ¢É‰∏≠Â∞çÊãúÂç†Â∫≠ÊîªÊìäËÄÖÁöÑÁ©©ÂÅ•ÊÄßÔºå‰ª•ÂèäÊé•ËøëÊñºÈõ∂ÁöÑËâØÊÄßÂÆ¢Êà∂Á´ØË™§ÂàÜÈ°ûÁéáÔºåÂç≥‰ΩøÂú®Ê≤íÊúâÊîªÊìäÁöÑÊÉÖÊ≥Å‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇ

##### **Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**
2501.12106v1 by Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Torsten Panholzer

Tumor documentation in Germany is largely done manually, requiring reading
patient records and entering data into structured databases. Large language
models (LLMs) could potentially enhance this process by improving efficiency
and reliability. This evaluation tests eleven different open source LLMs with
sizes ranging from 1-70 billion model parameters on three basic tasks of the
tumor documentation process: identifying tumor diagnoses, assigning ICD-10
codes, and extracting the date of first diagnosis. For evaluating the LLMs on
these tasks, a dataset of annotated text snippets based on anonymized doctors'
notes from urology was prepared. Different prompting strategies were used to
investigate the effect of the number of examples in few-shot prompting and to
explore the capabilities of the LLMs in general. The models Llama 3.1 8B,
Mistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.
Models with less extensive training data or having fewer than 7 billion
parameters showed notably lower performance, while larger models did not
display performance gains. Examples from a different medical domain than
urology could also improve the outcome in few-shot prompting, which
demonstrates the ability of LLMs to handle tasks needed for tumor
documentation. Open source LLMs show a strong potential for automating tumor
documentation. Models from 7-12 billion parameters could offer an optimal
balance between performance and resource efficiency. With tailored fine-tuning
and well-designed prompting, these models might become important tools for
clinical documentation in the future. The code for the evaluation is available
from https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset
as a new valuable resource that addresses the shortage of authentic and easily
accessible benchmarks in German-language medical NLP.

ÊëòË¶ÅÔºöÂæ∑ÂúãÁöÑËÖ´Áò§Êñá‰ª∂Ë®òÈåÑÂ§ßÈÉ®ÂàÜÊòØÊâãÂãïÂÆåÊàêÔºåÈúÄË¶ÅÈñ±ËÆÄÁóÖÊ≠∑‰∏¶Â∞áË≥áÊñôËº∏ÂÖ•ÁµêÊßãÂåñÁöÑË≥áÊñôÂ∫´‰∏≠„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØËÉΩÈÄèÈÅéÊèêÂçáÊïàÁéáÂíåÂèØÈù†ÊÄß‰æÜÂ¢ûÂº∑Ê≠§Á®ãÂ∫è„ÄÇÊ≠§Ë©ïÈáèÊ∏¨Ë©¶‰∫Ü 11 ÂÄã‰∏çÂêåÁöÑÈñãÊ∫ê LLMÔºåÊ®°ÂûãÂèÉÊï∏Â§ßÂ∞èÂæû 10 ÂÑÑÂà∞ 700 ÂÑÑ‰∏çÁ≠âÔºåÈáùÂ∞çËÖ´Áò§Êñá‰ª∂Ë®òÈåÑÁ®ãÂ∫èÁöÑ‰∏âÈ†ÖÂü∫Êú¨‰ªªÂãôÔºöË≠òÂà•ËÖ´Áò§Ë®∫Êñ∑„ÄÅÊåáÂÆö ICD-10 ‰ª£Á¢ºÔºå‰ª•ÂèäÊì∑ÂèñÈ¶ñÊ¨°Ë®∫Êñ∑Êó•Êúü„ÄÇÁÇ∫‰∫ÜÈáùÂ∞çÈÄô‰∫õ‰ªªÂãôË©ï‰º∞ LLMÔºåÊ∫ñÂÇô‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊ≥åÂ∞øÁßëÈÜ´ÁîüÂåøÂêçÁ≠ÜË®òÁöÑË®ªËß£ÊñáÂ≠óÁâáÊÆµË≥áÊñôÈõÜ„ÄÇ‰ΩøÁî®‰∏çÂêåÁöÑÊèêÁ§∫Á≠ñÁï•‰æÜË™øÊü•Â∞ëÈáèÊèêÁ§∫‰∏≠ÁØÑ‰æãÊï∏ÈáèÁöÑÂΩ±ÈüøÔºå‰∏¶Êé¢Á¥¢ LLM ÁöÑ‰∏ÄËà¨ËÉΩÂäõ„ÄÇLlama 3.1 8B„ÄÅMistral 7B Âíå Mistral NeMo 12 B Á≠âÊ®°ÂûãÂú®ÈÄô‰∫õ‰ªªÂãô‰∏≠Ë°®ÁèæÁõ∏Áï∂Â•Ω„ÄÇË®ìÁ∑¥Ë≥áÊñôËºÉÂ∞ëÊàñÂèÉÊï∏Â∞ëÊñº 70 ÂÑÑÁöÑÊ®°ÂûãË°®ÁèæÊòéÈ°ØËºÉÂ∑ÆÔºåËÄåËºÉÂ§ßÁöÑÊ®°Âûã‰∏¶Êú™Â±ïÁèæÊïàËÉΩÊèêÂçá„ÄÇËàáÊ≥åÂ∞øÁßë‰∏çÂêåÁöÑÈÜ´ÁôÇÈ†òÂüüÁöÑÁØÑ‰æã‰πüÂèØ‰ª•ÊîπÂñÑÂ∞ëÈáèÊèêÁ§∫ÁöÑÁµêÊûúÔºåÈÄôË≠âÊòé‰∫Ü LLM ËôïÁêÜËÖ´Áò§Êñá‰ª∂Ë®òÈåÑÊâÄÈúÄ‰ªªÂãôÁöÑËÉΩÂäõ„ÄÇÈñãÊ∫ê LLM Âú®Ëá™ÂãïÂåñËÖ´Áò§Êñá‰ª∂Ë®òÈåÑÊñπÈù¢È°ØÁ§∫Âá∫Âº∑Â§ßÁöÑÊΩõÂäõ„ÄÇÂèÉÊï∏‰ªãÊñº 70 ÂÑÑÂà∞ 120 ÂÑÑÁöÑÊ®°ÂûãÂèØ‰ª•Âú®ÊïàËÉΩÂíåË≥áÊ∫êÊïàÁéá‰πãÈñìÊèê‰æõÊúÄ‰Ω≥Âπ≥Ë°°„ÄÇÈÄèÈÅéÈáèË∫´ÊâìÈÄ†ÂæÆË™øÂíåÁ≤æÂøÉË®≠Ë®àÁöÑÊèêÁ§∫ÔºåÈÄô‰∫õÊ®°ÂûãÊú™‰æÜÂèØËÉΩÊúÉÊàêÁÇ∫Ëá®Â∫äÊñá‰ª∂Ë®òÈåÑÁöÑÈáçË¶ÅÂ∑•ÂÖ∑„ÄÇË©ï‰º∞Á®ãÂºèÁ¢ºÂèØÂæû https://github.com/stefan-m-lenz/UroLlmEval ÂèñÂæó„ÄÇÊàëÂÄë‰πüÈáãÂá∫Ë≥áÊñôÈõÜ‰ΩúÁÇ∫‰∏ÄÂÄãÊñ∞ÁöÑÊúâÂÉπÂÄºË≥áÊ∫êÔºåÁî®ÊñºËß£Ê±∫Âæ∑Ë™ûÈÜ´ÁôÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÁúüÂØ¶‰∏îÊòìÊñºÂèñÂæóÁöÑÂü∫Ê∫ñÁü≠Áº∫ÂïèÈ°å„ÄÇ

##### **Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection**
2501.12104v1 by ShiXuan Song, Hao Chen, Shu Hu, Xin Wang, Jinrong Hu, Xi Wu

Visual anomaly detection is a highly challenging task, often categorized as a
one-class classification and segmentation problem. Recent studies have
demonstrated that the student-teacher (S-T) framework effectively addresses
this challenge. However, most S-T frameworks rely solely on pre-trained teacher
networks to guide student networks in learning multi-scale similar features,
overlooking the potential of the student networks to enhance learning through
multi-scale feature fusion. In this study, we propose a novel model named
PFADSeg, which integrates a pre-trained teacher network, a denoising student
network with multi-scale feature fusion, and a guided anomaly segmentation
network into a unified framework. By adopting a unique teacher-encoder and
student-decoder denoising mode, the model improves the student network's
ability to learn from teacher network features. Furthermore, an adaptive
feature fusion mechanism is introduced to train a self-supervised segmentation
network that synthesizes anomaly masks autonomously, significantly increasing
detection performance. Evaluated on the MVTec AD dataset, PFADSeg achieves
state-of-the-art results with an image-level AUC of 98.9%, a pixel-level mean
precision of 76.4%, and an instance-level mean precision of 78.7%.

ÊëòË¶ÅÔºöË¶ñË¶∫Áï∞Â∏∏ÂÅµÊ∏¨ÊòØ‰∏ÄÈ†ÖÊ•µÂÖ∑ÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÈÄöÂ∏∏Ë¢´Ê≠∏È°ûÁÇ∫‰∏ÄÈ°ûÂàÜÈ°ûÂíåÂàÜÂâ≤ÂïèÈ°å„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂ≠∏Áîü-ÊïôÂ∏´ (S-T) Ê°ÜÊû∂ÊúâÊïàÂú∞ÊáâÂ∞ç‰∫ÜÈÄô‰∏ÄÊåëÊà∞„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ S-T Ê°ÜÊû∂ÂÉÖ‰æùË≥¥È†êÂÖàË®ìÁ∑¥ÁöÑÊïôÂ∏´Á∂≤Ë∑Ø‰æÜÊåáÂ∞éÂ≠∏ÁîüÁ∂≤Ë∑ØÂ≠∏ÁøíÂ§öÂ∞∫Â∫¶Áõ∏‰ººÁâπÂæµÔºåÂøΩË¶ñ‰∫ÜÂ≠∏ÁîüÁ∂≤Ë∑ØÈÄöÈÅéÂ§öÂ∞∫Â∫¶ÁâπÂæµËûçÂêàÂ¢ûÂº∑Â≠∏ÁøíÁöÑÂèØËÉΩÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ PFADSeg ÁöÑÊñ∞Ê®°ÂûãÔºåÂÆÉÂ∞áÈ†êË®ìÁ∑¥ÁöÑÊïôÂ∏´Á∂≤Ë∑Ø„ÄÅÂÖ∑ÊúâÂ§öÂ∞∫Â∫¶ÁâπÂæµËûçÂêàÁöÑÂéªÂô™Â≠∏ÁîüÁ∂≤Ë∑ØÂíåÂºïÂ∞éÁï∞Â∏∏ÂàÜÂâ≤Á∂≤Ë∑ØÊï¥ÂêàÂà∞‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊ°ÜÊû∂‰∏≠„ÄÇÈÄöÈÅéÊé°Áî®Áç®ÁâπÁöÑÊïôÂ∏´Á∑®Á¢ºÂô®ÂíåÂ≠∏ÁîüËß£Á¢ºÂô®ÂéªÂô™Ê®°ÂºèÔºåË©≤Ê®°ÂûãÊèêÈ´ò‰∫ÜÂ≠∏ÁîüÁ∂≤Ë∑ØÂæûÊïôÂ∏´Á∂≤Ë∑ØÁâπÂæµ‰∏≠Â≠∏ÁøíÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãËá™ÈÅ©ÊáâÁâπÂæµËûçÂêàÊ©üÂà∂‰æÜË®ìÁ∑¥‰∏ÄÂÄãËá™Áõ£Áù£ÂàÜÂâ≤Á∂≤Ë∑ØÔºåË©≤Á∂≤Ë∑ØÂèØ‰ª•Ëá™ÂãïÂêàÊàêÁï∞Â∏∏ÈÅÆÁΩ©ÔºåÂæûËÄåÈ°ØËëóÊèêÈ´òÊ™¢Ê∏¨ÊÄßËÉΩ„ÄÇÂú® MVTec AD Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞ÔºåPFADSeg ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºåÂúñÂÉèÁ¥öÂà• AUC ÁÇ∫ 98.9%ÔºåÂÉèÁ¥†Á¥öÂà•Âπ≥ÂùáÁ≤æÂ∫¶ÁÇ∫ 76.4%ÔºåÂØ¶‰æãÁ¥öÂà•Âπ≥ÂùáÁ≤æÂ∫¶ÁÇ∫ 78.7%„ÄÇ

##### **Proxies for Distortion and Consistency with Applications for Real-World Image Restoration**
2501.12102v1 by Sean Man, Guy Ohayon, Ron Raphaeli, Michael Elad

Real-world image restoration deals with the recovery of images suffering from
an unknown degradation. This task is typically addressed while being given only
degraded images, without their corresponding ground-truth versions. In this
hard setting, designing and evaluating restoration algorithms becomes highly
challenging. This paper offers a suite of tools that can serve both the design
and assessment of real-world image restoration algorithms. Our work starts by
proposing a trained model that predicts the chain of degradations a given
real-world measured input has gone through. We show how this estimator can be
used to approximate the consistency -- the match between the measurements and
any proposed recovered image. We also use this estimator as a guiding force for
the design of a simple and highly-effective plug-and-play real-world image
restoration algorithm, leveraging a pre-trained diffusion-based image prior.
Furthermore, this work proposes no-reference proxy measures of MSE and LPIPS,
which, without access to the ground-truth images, allow ranking of real-world
image restoration algorithms according to their (approximate) MSE and LPIPS.
The proposed suite provides a versatile, first of its kind framework for
evaluating and comparing blind image restoration algorithms in real-world
scenarios.

ÊëòË¶ÅÔºöÁúüÂØ¶‰∏ñÁïåÁöÑÂΩ±ÂÉè‰øÆÂæ©ËôïÁêÜÂèóÊêçÂΩ±ÂÉèÁöÑÂæ©ÂéüÔºåÂÖ∂ÊêçÂ£ûÊÉÖÊ≥Å‰∏çÊòé„ÄÇÊ≠§‰ªªÂãôÈÄöÂ∏∏Âú®ÂÉÖÊèê‰æõÂèóÊêçÂΩ±ÂÉèÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÔºåËÄåÊ≤íÊúâÂ∞çÊáâÁöÑÁúüÂØ¶ÁâàÊú¨„ÄÇÂú®Ê≠§Ëâ±Èõ£ÁöÑË®≠ÂÆö‰∏≠ÔºåË®≠Ë®àÂíåË©ï‰º∞‰øÆÂæ©ÊºîÁÆóÊ≥ïËÆäÂæóÊ•µÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÊú¨ÊñáÊèê‰æõ‰∫Ü‰∏ÄÂ•óÂ∑•ÂÖ∑ÔºåÂèØÂêåÊôÇÊúçÂãôÊñºÁúüÂØ¶‰∏ñÁïåÂΩ±ÂÉè‰øÆÂæ©ÊºîÁÆóÊ≥ïÁöÑË®≠Ë®àÂíåË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂæûÊèêÂá∫‰∏ÄÂÄãË®ìÁ∑¥Â•ΩÁöÑÊ®°ÂûãÈñãÂßãÔºåË©≤Ê®°ÂûãÈ†êÊ∏¨Áµ¶ÂÆöÁöÑÁúüÂØ¶‰∏ñÁïåÊ∏¨ÈáèËº∏ÂÖ•ÊâÄÁ∂ìÊ≠∑ÁöÑ‰∏ÄÈÄ£‰∏≤Âä£Âåñ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Ê≠§‰º∞Ë®àÂô®‰æÜÈÄºËøë‰∏ÄËá¥ÊÄßÔºåÂç≥Ê∏¨ÈáèÂÄºËàá‰ªª‰ΩïÊèêË≠∞ÁöÑÂæ©ÂéüÂΩ±ÂÉè‰πãÈñìÁöÑÂåπÈÖç„ÄÇÊàëÂÄëÈÇÑ‰ΩøÁî®Ê≠§‰º∞Ë®àÂô®‰ΩúÁÇ∫Ë®≠Ë®à‰∏ÄÂÄãÁ∞°ÂñÆ‰∏îÈ´òÊïàÁöÑÂç≥ÊèíÂç≥Áî®ÁúüÂØ¶‰∏ñÁïåÂΩ±ÂÉè‰øÆÂæ©ÊºîÁÆóÊ≥ïÁöÑÊåáÂ∞éÂäõÈáèÔºåÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÂü∫ÊñºÊì¥Êï£ÁöÑÂΩ±ÂÉèÂÖàÈ©ó„ÄÇÊ≠§Â§ñÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü MSE Âíå LPIPS ÁöÑÁÑ°ÂèÉËÄÉ‰ª£ÁêÜÊ∏¨ÈáèÔºåÂú®ÁÑ°Ê≥ïÂèñÂæóÁúüÂØ¶ÂΩ±ÂÉèÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂèØ‰ª•Ê†πÊìöÂÖ∂ÔºàËøë‰ººÁöÑÔºâMSE Âíå LPIPS Â∞çÁúüÂØ¶‰∏ñÁïåÂΩ±ÂÉè‰øÆÂæ©ÊºîÁÆóÊ≥ïÈÄ≤Ë°åÊéíÂêç„ÄÇÊâÄÊèêÂá∫ÁöÑÂ•ó‰ª∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãÈÄöÁî®‰∏îÈ¶ñÂâµÁöÑÊû∂ÊßãÔºåÁî®ÊñºË©ï‰º∞ÂíåÊØîËºÉÂú®ÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠Áõ≤ÁõÆÂΩ±ÂÉè‰øÆÂæ©ÊºîÁÆóÊ≥ï„ÄÇ

##### **Scalable Whole Slide Image Representation Using K-Mean Clustering and Fisher Vector Aggregation**
2501.12085v1 by Ravi Kant Gupta, Shounak Das, Ardhendu Sekhar, Amit Sethi

Whole slide images (WSIs) are high-resolution, gigapixel sized images that
pose significant computational challenges for traditional machine learning
models due to their size and heterogeneity.In this paper, we present a scalable
and efficient methodology for WSI classification by leveraging patch-based
feature extraction, clustering, and Fisher vector encoding. Initially, WSIs are
divided into fixed size patches, and deep feature embeddings are extracted from
each patch using a pre-trained convolutional neural network (CNN). These
patch-level embeddings are subsequently clustered using K-means clustering,
where each cluster aggregates semantically similar regions of the WSI. To
effectively summarize each cluster, Fisher vector representations are computed
by modeling the distribution of patch embeddings in each cluster as a
parametric Gaussian mixture model (GMM). The Fisher vectors from each cluster
are concatenated into a high-dimensional feature vector, creating a compact and
informative representation of the entire WSI. This feature vector is then used
by a classifier to predict the WSI's diagnostic label. Our method captures
local and global tissue structures and yields robust performance for
large-scale WSI classification, demonstrating superior accuracy and scalability
compared to other approaches.

ÊëòË¶ÅÔºöÂÖ®ÁéªÁâáÂΩ±ÂÉèÔºàWSIÔºâÊòØÈ´òËß£ÊûêÂ∫¶„ÄÅÂçÉÂÖÜÂÉèÁ¥†Â§ßÂ∞èÁöÑÂΩ±ÂÉèÔºåÁî±‰∫éÂÖ∂Â§ßÂ∞èÂíåÂºÇË¥®ÊÄßÔºåÂØπ‰º†ÁªüÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÈÄ†ÊàêÈáçÂ§ßÁöÑËÆ°ÁÆóÊåëÊàò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∏ÄÁßçÂèØÊâ©Â±ï‰∏îÊúâÊïàÁöÑÊñπÊ≥ïÔºåÈÄöËøáÂà©Áî®Âü∫‰∫éË¥¥ÁâáÁöÑÁâπÂæÅÊèêÂèñ„ÄÅËÅöÁ±ªÂíå Fisher ÂêëÈáèÁºñÁ†ÅÊù•ËøõË°å WSI ÂàÜÁ±ª„ÄÇÊúÄÂàùÔºåWSI Ë¢´ÂàÜÊàêÂõ∫ÂÆöÂ§ßÂ∞èÁöÑË¥¥ÁâáÔºåÂπ∂‰ΩøÁî®È¢ÑÂÖàËÆ≠ÁªÉËøáÁöÑÂç∑ÁßØÁ•ûÁªèÁΩëÁªú (CNN) ‰ªéÊØè‰∏™Ë¥¥Áâá‰∏≠ÊèêÂèñÊ∑±Â∫¶ÁâπÂæÅÂµåÂÖ•„ÄÇËøô‰∫õË¥¥ÁâáÁ∫ßÂà´ÁöÑÂµåÂÖ•ÈöèÂêé‰ΩøÁî® K ÂùáÂÄºËÅöÁ±ªËøõË°åËÅöÁ±ªÔºåÂÖ∂‰∏≠ÊØè‰∏™ËÅöÁ±ªÈÉΩËÅöÂêà‰∫Ü WSI ‰∏≠ËØ≠‰πâÁõ∏‰ººÁöÑÂå∫Âüü„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂú∞ÊÄªÁªìÊØè‰∏™ËÅöÁ±ªÔºåÈÄöËøáÂ∞ÜÊØè‰∏™ËÅöÁ±ª‰∏≠Ë¥¥ÁâáÂµåÂÖ•ÁöÑÂàÜÂ∏ÉÂª∫Ê®°‰∏∫ÂèÇÊï∞ÂåñÈ´òÊñØÊ∑∑ÂêàÊ®°Âûã (GMM) Êù•ËÆ°ÁÆó Fisher ÂêëÈáèË°®Á§∫„ÄÇÊù•Ëá™ÊØè‰∏™ËÅöÁ±ªÁöÑ Fisher ÂêëÈáèË¢´ËøûÊé•Êàê‰∏Ä‰∏™È´òÁª¥ÁâπÂæÅÂêëÈáèÔºåÂàõÂª∫Êï¥‰∏™ WSI ÁöÑÁ¥ßÂáë‰∏î‰ø°ÊÅØ‰∏∞ÂØåÁöÑË°®Á§∫„ÄÇÁÑ∂ÂêéÔºåÂàÜÁ±ªÂô®‰ΩøÁî®Ê≠§ÁâπÂæÅÂêëÈáèÊù•È¢ÑÊµã WSI ÁöÑËØäÊñ≠Ê†áÁ≠æ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÊçïÊçâÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÁªÑÁªáÁªìÊûÑÔºåÂπ∂‰∫ßÁîüÂ§ßËßÑÊ®° WSI ÂàÜÁ±ªÁöÑÈ´òÈ≤ÅÊ£íÊÄßÊÄßËÉΩÔºå‰∏éÂÖ∂‰ªñÊñπÊ≥ïÁõ∏ÊØîÔºåÂ±ïÁ§∫Âá∫ÂçìË∂äÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÊâ©Â±ïÊÄß„ÄÇ

##### **EDoRA: Efficient Weight-Decomposed Low-Rank Adaptation via Singular Value Decomposition**
2501.12067v1 by Hamid Nasiri, Peter Garraghan

Parameter-efficient fine-tuning methods, such as LoRA, reduces the number of
trainable parameters. However, they often suffer from scalability issues and
differences between their learning pattern and full fine-tuning. To overcome
these limitations, we propose Efficient Weight-Decomposed Low-Rank Adaptation
(EDoRA): a novel PEFT method that decomposes pre-trained weights into magnitude
and directional components. By freezing low-rank matrices, initializing them by
singular value decomposition, and introducing a small trainable matrix between
them, EDoRA achieves substantial reduction in trainable parameters while
maintaining learning capacity. Experimental results on the GLUE benchmark
demonstrate that EDoRA achieves competitive or superior performance compared to
state-of-the-art methods, such as LoRA and DoRA, with up to 30x fewer trainable
parameters. This makes EDoRA a highly efficient solution for adapting LLMs to
diverse tasks under memory-constrained settings. Code is available at
https://github.com/Hamid-Nasiri/EDoRA .

ÊëòË¶ÅÔºöÂèÉÊï∏È´òÊïàÂæÆË™øÊñπÊ≥ïÔºà‰æãÂ¶Ç LoRAÔºâÊ∏õÂ∞ë‰∫ÜÂèØË®ìÁ∑¥ÂèÉÊï∏ÁöÑÊï∏Èáè„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁ∂ìÂ∏∏ÊúÉÈÅáÂà∞ÂèØÊì¥ÂÖÖÊÄßÂïèÈ°åÔºåËÄå‰∏îÂÆÉÂÄëÁöÑÂ≠∏ÁøíÊ®°ÂºèËàáÂÆåÂÖ®ÂæÆË™ø‰πãÈñìÂ≠òÂú®Â∑ÆÁï∞„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈ´òÊïàÊ¨äÈáçÂàÜËß£‰ΩéÁß©ÈÅ©Êáâ (EDoRA)Ôºö‰∏ÄÁ®ÆÂ∞áÈ†êË®ìÁ∑¥Ê¨äÈáçÂàÜËß£ÁÇ∫ÂπÖÂ∫¶ÂíåÊñπÂêëÂàÜÈáèÁöÑÂÖ®Êñ∞ PEFT ÊñπÊ≥ï„ÄÇÈÄèÈÅéÂáçÁµê‰ΩéÁß©Áü©Èô£„ÄÅ‰ΩøÁî®Â•áÁï∞ÂÄºÂàÜËß£Â∞çÂÆÉÂÄëÈÄ≤Ë°åÂàùÂßãÂåñÔºå‰∏¶Âú®ÂÆÉÂÄë‰πãÈñìÂºïÂÖ•‰∏ÄÂÄãÂ∞èÁöÑÂèØË®ìÁ∑¥Áü©Èô£ÔºåEDoRA ÂØ¶Áèæ‰∫ÜÂèØË®ìÁ∑¥ÂèÉÊï∏ÁöÑÂ§ßÂπÖÊ∏õÂ∞ëÔºåÂêåÊôÇÁ∂≠ÊåÅ‰∫ÜÂ≠∏ÁøíËÉΩÂäõ„ÄÇGLUE Âü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåËàá LoRA Âíå DoRA Á≠âÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåEDoRA ÈÅîÂà∞‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÊàñÊõ¥ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÂèØË®ìÁ∑¥ÂèÉÊï∏Ê∏õÂ∞ë‰∫ÜÂ§öÈÅî 30 ÂÄç„ÄÇÈÄô‰ΩøÂæó EDoRA ÊàêÁÇ∫Âú®Ë®òÊÜ∂È´îÂèóÈôêË®≠ÂÆö‰∏ãÂ∞á LLM ÈÅ©ÊáâÂà∞ÂêÑÁ®Æ‰ªªÂãôÁöÑÈ´òÊïàËß£Ê±∫ÊñπÊ°à„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Hamid-Nasiri/EDoRA ÂèñÂæó„ÄÇ

##### **MedS$^3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking**
2501.12051v1 by Shuyang Jiang, Yusheng Liao, Zhe Chen, Ya Zhang, Yanfeng Wang, Yu Wang

Medical language models (MLMs) have become pivotal in advancing medical
natural language processing. However, prior models that rely on pre-training or
supervised fine-tuning often exhibit low data efficiency and limited
practicality in real-world clinical applications. While OpenAIs O1 highlights
test-time scaling in mathematics, attempts to replicate this approach in
medicine typically distill responses from GPT-series models to open-source
models, focusing primarily on multiple-choice tasks. This strategy, though
straightforward, neglects critical concerns like data privacy and realistic
deployment in clinical settings. In this work, we present a deployable,
small-scale medical language model, \mone, designed for long-chain reasoning in
clinical tasks using a self-evolution paradigm. Starting with a seed dataset of
around 8,000 instances spanning five domains and 16 datasets, we prompt a base
policy model to perform Monte Carlo Tree Search (MCTS) to construct verifiable
reasoning chains. Each reasoning step is assigned an evolution rollout value,
allowing verified trajectories to train the policy model and the reward model.
During inference, the policy model generates multiple responses, and the reward
model selects the one with the highest reward score. Experiments on eleven
evaluation datasets demonstrate that \mone outperforms prior open-source models
by 2 points, with the addition of the reward model further boosting performance
($\sim$13 points), surpassing GPT-4o-mini. Code and data are available at
\url{https://github.com/pixas/MedSSS}.

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁôÇË™ûË®ÄÊ®°Âûã (MLM) Â∑≤ÊàêÁÇ∫Êé®ÈÄ≤ÈÜ´ÁôÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÈóúÈçµ„ÄÇÁÑ∂ËÄåÔºå‰æùË≥¥ÊñºÈ†êË®ìÁ∑¥ÊàñÁõ£Áù£ÂæÆË™øÁöÑÂÖàÂâçÊ®°ÂûãÈÄöÂ∏∏Ë°®ÁèæÂá∫‰ΩéË≥áÊñôÊïàÁéáÔºå‰∏îÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÊáâÁî®‰∏≠ÂØ¶Áî®ÊÄßÊúâÈôê„ÄÇÂÑòÁÆ° OpenAI ÁöÑ O1 Âº∑Ë™øÊï∏Â≠∏‰∏≠ÁöÑÊ∏¨Ë©¶ÊôÇÈñìÁ∏ÆÊîæÔºå‰ΩÜÂòóË©¶Âú®ÈÜ´Â≠∏‰∏≠Ë§áË£ΩÊ≠§ÊñπÊ≥ïÈÄöÂ∏∏ÊúÉÂ∞á GPT Á≥ªÂàóÊ®°ÂûãÁöÑÂõûÊáâÊèêÁÖâÂà∞ÈñãÊ∫êÊ®°ÂûãÔºå‰∏ªË¶ÅÈóúÊ≥®ÊñºÂ§öÈÅ∏È°å‰ªªÂãô„ÄÇÈÄôÁ®ÆÁ≠ñÁï•ÈõñÁÑ∂Á∞°ÂñÆÔºå‰ΩÜÂøΩÁï•‰∫ÜË≥áÊñôÈö±ÁßÅÂíåËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÂØ¶ÈöõÈÉ®ÁΩ≤Á≠âÈóúÈçµÂïèÈ°å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØÈÉ®ÁΩ≤ÁöÑÂ∞èË¶èÊ®°ÈÜ´ÁôÇË™ûË®ÄÊ®°Âûã \moneÔºåÂÆÉ‰ΩøÁî®Ëá™ÊºîÂåñÁØÑ‰æãÈáùÂ∞çËá®Â∫ä‰ªªÂãô‰∏≠ÁöÑÈï∑ÈèàÊé®ÁêÜËÄåË®≠Ë®à„ÄÇÂæûË∑®Ë∂ä‰∫îÂÄãÈ†òÂüüÂíå 16 ÂÄãË≥áÊñôÈõÜÁöÑÂ§ßÁ¥Ñ 8,000 ÂÄãÂØ¶‰æãÁöÑÁ®ÆÂ≠êË≥áÊñôÈõÜÈñãÂßãÔºåÊàëÂÄëÊèêÁ§∫‰∏ÄÂÄãÂü∫Êú¨Á≠ñÁï•Ê®°ÂûãÂü∑Ë°åËíôÂú∞Âç°ÁæÖÊ®πÁãÄÊêúÂ∞ã (MCTS) ‰ª•Âª∫ÊßãÂèØÈ©óË≠âÁöÑÊé®ÁêÜÈèà„ÄÇÊØèÂÄãÊé®ÁêÜÊ≠•È©üÈÉΩÊåáÂÆö‰∫Ü‰∏ÄÂÄãÊºîÂåñÂ±ïÈñãÂÄºÔºåÂÖÅË®±È©óË≠âÁöÑËªåË∑°Ë®ìÁ∑¥Á≠ñÁï•Ê®°ÂûãÂíåÁçéÂãµÊ®°Âûã„ÄÇÂú®Êé®ÁêÜÊúüÈñìÔºåÁ≠ñÁï•Ê®°ÂûãÊúÉÁî¢ÁîüÂ§öÂÄãÂõûÊáâÔºåËÄåÁçéÂãµÊ®°ÂûãÊúÉÈÅ∏ÊìáÁçéÂãµÂàÜÊï∏ÊúÄÈ´òÁöÑÂõûÊáâ„ÄÇÂ∞ç 11 ÂÄãË©ï‰º∞Ë≥áÊñôÈõÜÁöÑÂØ¶È©óË°®ÊòéÔºå\mone ÁöÑË°®ÁèæÂÑ™ÊñºÂÖàÂâçÁöÑÈñãÊ∫êÊ®°Âûã 2 ÂàÜÔºåËÄåÁçéÂãµÊ®°ÂûãÁöÑÂä†ÂÖ•ÈÄ≤‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊïàËÉΩÔºà$\sim$13 ÂàÜÔºâÔºåË∂ÖË∂ä‰∫Ü GPT-4o-mini„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØ‰ª•Âú® \url{https://github.com/pixas/MedSSS} ÂèñÂæó„ÄÇ</paragraph>

##### **Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**
2501.12048v1 by Shramana Dey, Pallabi Dutta, Riddhasree Bhattacharyya, Surochita Pal, Sushmita Mitra, Rajiv Raman

The prevalence of ocular illnesses is growing globally, presenting a
substantial public health challenge. Early detection and timely intervention
are crucial for averting visual impairment and enhancing patient prognosis.
This research introduces a new framework called Class Extension with Limited
Data (CELD) to train a classifier to categorize retinal fundus images. The
classifier is initially trained to identify relevant features concerning
Healthy and Diabetic Retinopathy (DR) classes and later fine-tuned to adapt to
the task of classifying the input images into three classes: Healthy, DR, and
Glaucoma. This strategy allows the model to gradually enhance its
classification capabilities, which is beneficial in situations where there are
only a limited number of labeled datasets available. Perturbation methods are
also used to identify the input image characteristics responsible for
influencing the models decision-making process. We achieve an overall accuracy
of 91% on publicly available datasets.

ÊëòË¶ÅÔºöÂÖ®ÁêÉÁúºÁñæÊÇ£ÁóÖÁéáÊåÅÁ∫å‰∏äÂçáÔºåÂ∞çÂÖ¨ÂÖ±Ë°õÁîüÈÄ†ÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÊó©ÊúüÁôºÁèæÂíåÂèäÊôÇÂπ≤È†êÂ∞çÊñºÈ†êÈò≤Ë¶ñÂäõÈöúÁ§ôÂíåÊîπÂñÑÊÇ£ËÄÖÈ†êÂæåËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ÊúâÈôêÊï∏ÊìöÈ°ûÂà•Êì¥Â±ï (CELD) ÁöÑÊñ∞Ê°ÜÊû∂ÔºåÁî®ÊñºË®ìÁ∑¥ÂàÜÈ°ûÂô®Â∞çË¶ñÁ∂≤ËÜúÁúºÂ∫ïÂúñÂÉèÈÄ≤Ë°åÂàÜÈ°û„ÄÇË©≤ÂàÜÈ°ûÂô®ÊúÄÂàùÊé•ÂèóË®ìÁ∑¥‰ª•Ë≠òÂà•ËàáÂÅ•Â∫∑ÂíåÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆä (DR) È°ûÂà•Áõ∏ÈóúÁöÑÁâπÂæµÔºåÁÑ∂ÂæåÈÄ≤Ë°åÂæÆË™ø‰ª•ÈÅ©ÊáâÂ∞áËº∏ÂÖ•ÂúñÂÉèÂàÜÈ°ûÁÇ∫‰∏âÈ°ûÁöÑ‰ªªÂãôÔºöÂÅ•Â∫∑„ÄÅDR ÂíåÈùíÂÖâÁúº„ÄÇÊ≠§Á≠ñÁï•ÂÖÅË®±Ê®°ÂûãÈÄêÊ≠•Â¢ûÂº∑ÂÖ∂ÂàÜÈ°ûËÉΩÂäõÔºåÈÄôÂú®Ê®ôË®òÊï∏ÊìöÈõÜÊï∏ÈáèÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ãÊòØÊúâÁõäÁöÑ„ÄÇÊìæÂãïÊñπÊ≥ï‰πüÁî®ÊñºË≠òÂà•Ë≤†Ë≤¨ÂΩ±ÈüøÊ®°ÂûãÊ±∫Á≠ñÈÅéÁ®ãÁöÑËº∏ÂÖ•ÂúñÂÉèÁâπÂæµ„ÄÇÊàëÂÄëÂú®ÂÖ¨ÈñãÊï∏ÊìöÈõÜ‰∏äÂØ¶Áèæ‰∫Ü 91% ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Harnessing Generative Pre-Trained Transformer for Datacenter Packet Trace Generation**
2501.12033v1 by Chen Griner

Today, the rapid growth of applications reliant on datacenters calls for new
advancements to meet the increasing traffic and computational demands. Traffic
traces from datacenters are essential for further development and optimization
of future datacenters. However, traces are rarely released to the public.
Researchers often use simplified mathematical models that lack the depth needed
to recreate intricate traffic patterns and, thus, miss optimization
opportunities found in realistic traffic. In this preliminary work, we
introduce DTG-GPT, a packet-level Datacenter Traffic Generator (DTG), based on
the generative pre-trained transformer (GPT) architecture used by many
state-of-the-art large language models. We train our model on a small set of
available traffic traces from different domains and offer a simple methodology
to evaluate the fidelity of the generated traces to their original
counterparts. We show that DTG-GPT can synthesize novel traces that mimic the
spatiotemporal patterns found in real traffic traces. We further demonstrate
that DTG-GPT can generate traces for networks of different scales while
maintaining fidelity. Our findings indicate the potential that, in the future,
similar models to DTG-GPT will allow datacenter operators to release traffic
information to the research community via trained GPT models.

ÊëòË¶ÅÔºö<paragraph>Â¶Ç‰ªäÔºå‰ª∞Ë≥¥Ë≥áÊñô‰∏≠ÂøÉÁöÑÊáâÁî®Á®ãÂºèÂø´ÈÄüÊàêÈï∑ÔºåÂëºÁ±≤Êñ∞ÁöÑÈÄ≤Â±ï‰ª•ÊªøË∂≥Êó•ÁõäÂ¢ûÂä†ÁöÑÊµÅÈáèÂíåË®àÁÆóÈúÄÊ±Ç„ÄÇË≥áÊñô‰∏≠ÂøÉÁöÑÊµÅÈáèËøΩËπ§Â∞çÊñºÊú™‰æÜË≥áÊñô‰∏≠ÂøÉÁöÑÈÄ≤‰∏ÄÊ≠•ÈñãÁôºÂíåÊúÄ‰Ω≥ÂåñËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåËøΩËπ§ÂæàÂ∞ëÂÖ¨ÈñãÁôºÂ∏É„ÄÇÁ†îÁ©∂‰∫∫Âì°Á∂ìÂ∏∏‰ΩøÁî®Á∞°ÂåñÁöÑÊï∏Â≠∏Ê®°ÂûãÔºåËÄåÈÄô‰∫õÊ®°ÂûãÁº∫‰πèÈáçÊñ∞Âª∫Á´ãË§áÈõúÊµÅÈáèÊ®°ÂºèÊâÄÈúÄÁöÑÊ∑±Â∫¶ÔºåÂõ†Ê≠§ÈåØÂ§±‰∫ÜÂú®ÂØ¶ÈöõÊµÅÈáè‰∏≠ÁôºÁèæÁöÑÊúÄ‰Ω≥ÂåñÊ©üÊúÉ„ÄÇÂú®ÈÄôÈ†ÖÂàùÊ≠•Â∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π DTG-GPTÔºå‰∏ÄÁ®ÆÂü∫ÊñºË®±Â§öÊúÄÂÖàÈÄ≤ÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÊâÄ‰ΩøÁî®ÁöÑÁîüÊàêÂºèÈ†êÂÖàË®ìÁ∑¥Transformer (GPT) Êû∂ÊßãÁöÑÂ∞ÅÂåÖÁ≠âÁ¥öË≥áÊñô‰∏≠ÂøÉÊµÅÈáèÁî¢ÁîüÂô® (DTG)„ÄÇÊàëÂÄëÂú®‰æÜËá™‰∏çÂêåÁ∂≤ÂüüÁöÑ‰∏ÄÂ∞èÁµÑÂèØÁî®ÊµÅÈáèËøΩËπ§‰∏äË®ìÁ∑¥ÊàëÂÄëÁöÑÊ®°ÂûãÔºå‰∏¶Êèê‰æõ‰∏ÄÂÄãÁ∞°ÂñÆÁöÑÊñπÊ≥ï‰æÜË©ï‰º∞ÊâÄÁî¢ÁîüËøΩËπ§ËàáÂÖ∂ÂéüÂßãÂ∞çÊáâÈ†ÖÁöÑ‰øùÁúüÂ∫¶„ÄÇÊàëÂÄëÂ±ïÁ§∫ DTG-GPT ÂèØ‰ª•ÂêàÊàêÊñ∞ÁöÑËøΩËπ§ÔºåÊ®°Êì¨Âú®ÂØ¶ÈöõÊµÅÈáèËøΩËπ§‰∏≠ÁôºÁèæÁöÑÊôÇÁ©∫Ê®°Âºè„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â±ïÁ§∫ DTG-GPT ÂèØ‰ª•ÁÇ∫‰∏çÂêåË¶èÊ®°ÁöÑÁ∂≤Ë∑ØÁî¢ÁîüËøΩËπ§ÔºåÂêåÊôÇÁ∂≠ÊåÅ‰øùÁúüÂ∫¶„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊåáÂá∫ÔºåÂú®Êú™‰æÜÔºåÈ°û‰ººÊñº DTG-GPT ÁöÑÊ®°ÂûãÂ∞áÂÖÅË®±Ë≥áÊñô‰∏≠ÂøÉÁáüÈÅãÂïÜÈÄèÈÅéË®ìÁ∑¥ÈÅéÁöÑ GPT Ê®°ÂûãÂêëÁ†îÁ©∂Á§æÁæ§ÁôºÂ∏ÉÊµÅÈáèË≥áË®ä„ÄÇ</paragraph>

##### **Reference-free Evaluation Metrics for Text Generation: A Survey**
2501.12011v1 by Takumi Ito, Kees van Deemter, Jun Suzuki

A number of automatic evaluation metrics have been proposed for natural
language generation systems. The most common approach to automatic evaluation
is the use of a reference-based metric that compares the model's output with
gold-standard references written by humans. However, it is expensive to create
such references, and for some tasks, such as response generation in dialogue,
creating references is not a simple matter. Therefore, various reference-free
metrics have been developed in recent years. In this survey, which intends to
cover the full breadth of all NLG tasks, we investigate the most commonly used
approaches, their application, and their other uses beyond evaluating models.
The survey concludes by highlighting some promising directions for future
research.

ÊëòË¶ÅÔºöÈáùÂ∞çËá™ÁÑ∂Ë™ûË®ÄÁîüÊàêÁ≥ªÁµ±ÔºåÂ∑≤Á∂ìÊèêÂá∫Ë®±Â§öËá™ÂãïË©ïÈáèÊåáÊ®ô„ÄÇÊúÄÂ∏∏Ë¶ãÁöÑËá™ÂãïË©ïÈáèÊñπÊ≥ïÔºåÊòØ‰ΩøÁî®ÂèÉËÄÉÂü∫Á§éÊåáÊ®ôÔºåÂ∞áÊ®°ÂûãÁöÑËº∏Âá∫Ëàá‰∫∫È°ûÊí∞ÂØ´ÁöÑÈªÉÈáëÊ®ôÊ∫ñÂèÉËÄÉÈÄ≤Ë°åÊØîËºÉ„ÄÇÁÑ∂ËÄåÔºåÂª∫Á´ãÈÄô‰∫õÂèÉËÄÉÁöÑÊàêÊú¨ÂæàÈ´òÔºåËÄå‰∏îÂ∞çÊñºÊüê‰∫õ‰ªªÂãôÔºà‰æãÂ¶ÇÂ∞çË©±‰∏≠ÁöÑÂõûÊáâÁî¢ÁîüÔºâÔºåÂª∫Á´ãÂèÉËÄÉ‰∏¶ÈùûÊòì‰∫ã„ÄÇÂõ†Ê≠§ÔºåËøëÂπ¥‰æÜÂ∑≤Á∂ìÈñãÁôºÂá∫ÂêÑÁ®ÆÁÑ°ÂèÉËÄÉÊåáÊ®ô„ÄÇÂú®Êú¨Ë™øÊü•‰∏≠ÔºåÊàëÂÄëÊó®Âú®Ê∂µËìãÊâÄÊúâ NLG ‰ªªÂãôÁöÑÂÆåÊï¥Âª£Â∫¶ÔºåÊé¢Ë®éÊúÄÂ∏∏Áî®ÁöÑÊñπÊ≥ï„ÄÅÂÖ∂ÊáâÁî®‰ª•ÂèäÈô§‰∫ÜË©ï‰º∞Ê®°Âûã‰πãÂ§ñÁöÑÂÖ∂‰ªñÁî®ÈÄî„ÄÇÊú¨Ë™øÊü•ÊúÄÂæåÈáçÈªûË™™ÊòéÊú™‰æÜÁ†îÁ©∂ÁöÑ‰∏Ä‰∫õÊúâÂ∏åÊúõÁöÑÊñπÂêë„ÄÇ

##### **Survey on Hand Gesture Recognition from Visual Input**
2501.11992v1 by Manousos Linardakis, Iraklis Varlamis, Georgios Th. Papadopoulos

Hand gesture recognition has become an important research area, driven by the
growing demand for human-computer interaction in fields such as sign language
recognition, virtual and augmented reality, and robotics. Despite the rapid
growth of the field, there are few surveys that comprehensively cover recent
research developments, available solutions, and benchmark datasets. This survey
addresses this gap by examining the latest advancements in hand gesture and 3D
hand pose recognition from various types of camera input data including RGB
images, depth images, and videos from monocular or multiview cameras, examining
the differing methodological requirements of each approach. Furthermore, an
overview of widely used datasets is provided, detailing their main
characteristics and application domains. Finally, open challenges such as
achieving robust recognition in real-world environments, handling occlusions,
ensuring generalization across diverse users, and addressing computational
efficiency for real-time applications are highlighted to guide future research
directions. By synthesizing the objectives, methodologies, and applications of
recent studies, this survey offers valuable insights into current trends,
challenges, and opportunities for future research in human hand gesture
recognition.

ÊëòË¶ÅÔºöÊâãÂã¢Ëæ®Ë≠òÂ∑≤ÊàêÁÇ∫‰∏ÄÈ†ÖÈáçË¶ÅÁöÑÁ†îÁ©∂È†òÂüüÔºåÂÖ∂È©ÖÂãïÂäõÊòØÂêÑÈ†òÂüüÂ∞ç‰∫∫Ê©ü‰∫íÂãïÁöÑÈúÄÊ±ÇÊó•ÁõäÂ¢ûÈï∑Ôºå‰æãÂ¶ÇÊâãË™ûËæ®Ë≠ò„ÄÅËôõÊì¨ÂØ¶Â¢ÉÂíåÊì¥Â¢ûÂØ¶Â¢ÉÔºå‰ª•ÂèäÊ©üÂô®‰∫∫ÊäÄË°ì„ÄÇÂÑòÁÆ°Ë©≤È†òÂüüÂø´ÈÄüÁôºÂ±ïÔºå‰ΩÜÂÖ®Èù¢Ê∂µËìãËøëÊúüÁ†îÁ©∂ÁôºÂ±ï„ÄÅÂèØÁî®Ëß£Ê±∫ÊñπÊ°àÂíåÂü∫Ê∫ñË≥áÊñôÈõÜÁöÑË™øÊü•ÂçªÂæàÂ∞ë„ÄÇÊú¨Ë™øÊü•ÈÄèÈÅéÊ™¢Ë¶ñÊâãÂã¢Âíå 3D ÊâãÈÉ®ÂßøÂã¢Ëæ®Ë≠òÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂæûÂêÑÁ®ÆÈ°ûÂûãÁöÑÁõ∏Ê©üËº∏ÂÖ•Ë≥áÊñô‰∏≠ÈÄ≤Ë°åÊé¢Ë®éÔºåÂåÖÊã¨ RGB ÂΩ±ÂÉè„ÄÅÊ∑±Â∫¶ÂΩ±ÂÉèÔºå‰ª•ÂèäÂñÆÁúºÊàñÂ§öË¶ñËßíÁõ∏Ê©üÁöÑÂΩ±ÁâáÔºåÊé¢Ë®éÊØèÁ®ÆÊñπÊ≥ï‰∏çÂêåÁöÑÊñπÊ≥ïË´ñÈúÄÊ±Ç„ÄÇÊ≠§Â§ñÔºåÈÇÑÊèê‰æõ‰∫ÜÂª£Ê≥õ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜÊ¶ÇËßÄÔºåË©≥Á¥∞Ë™™ÊòéÂÖ∂‰∏ªË¶ÅÁâπÂæµÂíåÊáâÁî®È†òÂüü„ÄÇÊúÄÂæåÔºåÁ™ÅÈ°Ø‰∫ÜÂú®ÁèæÂØ¶‰∏ñÁïåÁí∞Â¢É‰∏≠ÂØ¶ÁèæÁ©©ÂÅ•Ëæ®Ë≠ò„ÄÅËôïÁêÜÈÅÆÊìã„ÄÅÁ¢∫‰øù‰∏çÂêå‰ΩøÁî®ËÄÖ‰πãÈñìÁöÑÊ≥õÂåñÔºå‰ª•ÂèäËß£Ê±∫Âç≥ÊôÇÊáâÁî®Á®ãÂºèÈÅãÁÆóÊïàÁéáÁ≠âÈñãÊîæÊÄßÊåëÊà∞Ôºå‰ª•ÂºïÂ∞éÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÈÄèÈÅéÁ∂úÂêàËøëÊúüÁ†îÁ©∂ÁöÑÁõÆÊ®ô„ÄÅÊñπÊ≥ïÂíåÊáâÁî®ÔºåÊú¨Ë™øÊü•Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£Ôºå‰∫ÜËß£Áï∂ÂâçË∂®Âã¢„ÄÅÊåëÊà∞ÂíåÊú™‰æÜÊâãÂã¢Ëæ®Ë≠òÁ†îÁ©∂ÁöÑÊ©üÊúÉ„ÄÇ

##### **Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**
2501.11977v1 by Maya Medjad, Hugo Imbert, Bruno Yun, Rapha√´l Szymocha, Fr√©d√©ric Armetta

Training task-oriented dialogue systems is both costly and time-consuming,
due to the need for high-quality datasets encompassing diverse intents.
Traditional methods depend on extensive human annotation, while recent
advancements leverage large language models (LLMs) to generate synthetic data.
However, these approaches often require custom prompts or code, limiting
accessibility for non-technical users. We introduce GraphTOD, an end-to-end
framework that simplifies the generation of task-oriented dialogues. Users can
create dialogues by specifying transition graphs in JSON format. Our evaluation
demonstrates that GraphTOD generates high-quality dialogues across various
domains, significantly lowering the cost and complexity of dataset creation.

ÊëòË¶ÅÔºöË®ìÁ∑¥‰ªªÂãôÂ∞éÂêëÂ∞çË©±Á≥ªÁµ±Êó¢ÊòÇË≤¥ÂèàËÄóÊôÇÔºå
Âõ†ÁÇ∫ÈúÄË¶ÅÂåÖÂê´ÂêÑÁ®ÆÊÑèÂúñÁöÑÈ´òÂìÅË≥™Ë≥áÊñôÈõÜ„ÄÇ
ÂÇ≥Áµ±ÊñπÊ≥ï‰æùË≥¥ÊñºÂª£Ê≥õÁöÑ‰∫∫Â∑•Ê®ôË®ªÔºåËÄåÊúÄËøë
ÁöÑÈÄ≤Â±ïÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÁî¢ÁîüÂêàÊàêË≥áÊñô„ÄÇ
ÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅËá™Ë®ÇÊèêÁ§∫ÊàñÁ®ãÂºèÁ¢ºÔºåÈôêÂà∂
ÈùûÊäÄË°ì‰ΩøÁî®ËÄÖÁöÑÂèØÂèäÊÄß„ÄÇÊàëÂÄë‰ªãÁ¥π GraphTODÔºå‰∏ÄÂÄãÁ´ØÂ∞çÁ´ØÁöÑ
Êû∂ÊßãÔºåÁ∞°Âåñ‰∫Ü‰ªªÂãôÂ∞éÂêëÂ∞çË©±ÁöÑÁî¢Áîü„ÄÇ‰ΩøÁî®ËÄÖÂèØ‰ª•
ÈÄèÈÅéÊåáÂÆö JSON Ê†ºÂºèÁöÑËΩâÊèõÂúñË°®‰æÜÂª∫Á´ãÂ∞çË©±„ÄÇÊàëÂÄëÁöÑË©ï‰º∞
Ë≠âÊòé GraphTOD Âú®ÂêÑÁ®ÆÈ†òÂüüÁî¢ÁîüÈ´òÂìÅË≥™Â∞çË©±ÔºåÈ°ØËëóÈôç‰ΩéË≥áÊñôÈõÜÂª∫Á´ãÁöÑÊàêÊú¨ÂíåË§áÈõúÊÄß„ÄÇ

##### **Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**
2501.11968v1 by Jie Zhao, Kang Hao Cheong, Witold Pedrycz

Graph-structured combinatorial challenges are inherently difficult due to
their nonlinear and intricate nature, often rendering traditional computational
methods ineffective or expensive. However, these challenges can be more
naturally tackled by humans through visual representations that harness our
innate ability for spatial reasoning. In this study, we propose transforming
graphs into images to preserve their higher-order structural features
accurately, revolutionizing the representation used in solving graph-structured
combinatorial tasks. This approach allows machines to emulate human-like
processing in addressing complex combinatorial challenges. By combining the
innovative paradigm powered by multimodal large language models (MLLMs) with
simple search techniques, we aim to develop a novel and effective framework for
tackling such problems. Our investigation into MLLMs spanned a variety of
graph-based tasks, from combinatorial problems like influence maximization to
sequential decision-making in network dismantling, as well as addressing six
fundamental graph-related issues. Our findings demonstrate that MLLMs exhibit
exceptional spatial intelligence and a distinctive capability for handling
these problems, significantly advancing the potential for machines to
comprehend and analyze graph-structured data with a depth and intuition akin to
human cognition. These results also imply that integrating MLLMs with simple
optimization strategies could form a novel and efficient approach for
navigating graph-structured combinatorial challenges without complex
derivations, computationally demanding training and fine-tuning.

ÊëòË¶ÅÔºöÂúñÂΩ¢ÁµêÊßãÁöÑÁµÑÂêàÊåëÊà∞Êú¨Ë≥™‰∏äÂæàÂõ∞Èõ£ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁöÑÈùûÁ∑öÊÄßÂíåË§áÈõúÊÄßÔºåÈÄöÂ∏∏ÊúÉ‰ΩøÂÇ≥Áµ±ÁöÑË®àÁÆóÊñπÊ≥ïÁÑ°ÊïàÊàñÊòÇË≤¥„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÂèØ‰ª•ÈÄèÈÅéÂà©Áî®ÊàëÂÄëÂ§©ÁîüÁöÑÁ©∫ÈñìÊé®ÁêÜËÉΩÂäõÁöÑË¶ñË¶∫Ë°®ÂæµÔºåÊõ¥Ëá™ÁÑ∂Âú∞ÊáâÂ∞çÈÄô‰∫õÊåëÊà∞„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞Â∞áÂúñÂΩ¢ËΩâÊèõÁÇ∫ÂΩ±ÂÉèÔºå‰ª•Ê∫ñÁ¢∫‰øùÁïôÂÆÉÂÄëÁöÑÈ´òÈöéÁµêÊßãÁâπÂæµÔºåÂæûËÄåÈù©Êñ∞Áî®ÊñºËß£Ê±∫ÂúñÂΩ¢ÁµêÊßãÁµÑÂêà‰ªªÂãôÁöÑË°®Âæµ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂÖÅË®±Ê©üÂô®Âú®Ëß£Ê±∫Ë§áÈõúÁöÑÁµÑÂêàÊåëÊà∞ÊôÇÊ®°Êì¨È°û‰∫∫ÁöÑËôïÁêÜ„ÄÇÈÄèÈÅéÁµêÂêàÁî±Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Êèê‰æõÂãïÂäõÁöÑÂâµÊñ∞ÁØÑ‰æãËàáÁ∞°ÂñÆÁöÑÊêúÂ∞ãÊäÄË°ìÔºåÊàëÂÄëÊó®Âú®ÁÇ∫Ëß£Ê±∫Ê≠§È°ûÂïèÈ°åÈñãÁôº‰∏ÄÂÄãÊñ∞Á©é‰∏îÊúâÊïàÁöÑÊû∂Êßã„ÄÇÊàëÂÄëÂ∞ç MLLM ÁöÑÁ†îÁ©∂Ê∂µËìã‰∫ÜÂêÑÁ®ÆÂü∫ÊñºÂúñÂΩ¢ÁöÑ‰ªªÂãôÔºåÂæûÁµÑÂêàÂïèÈ°åÔºàÂ¶ÇÂΩ±ÈüøÂäõÊúÄÂ§ßÂåñÔºâÂà∞Á∂≤Ë∑ØÊãÜÈô§‰∏≠ÁöÑÈ†ÜÂ∫èÊ±∫Á≠ñÂà∂ÂÆöÔºå‰ª•ÂèäËß£Ê±∫ÂÖ≠ÂÄãÂü∫Êú¨ÁöÑÂúñÂΩ¢Áõ∏ÈóúÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåMLLM Ë°®ÁèæÂá∫ÈùûÂá°ÁöÑÁ©∫ÈñìÊô∫ËÉΩÂíåËôïÁêÜÈÄô‰∫õÂïèÈ°åÁöÑÁç®ÁâπËÉΩÂäõÔºåÈ°ØËëóÊèêÂçá‰∫ÜÊ©üÂô®‰ª•È°û‰ºº‰∫∫È°ûË™çÁü•ÁöÑÊ∑±Â∫¶ÂíåÁõ¥Ë¶∫‰æÜÁêÜËß£ÂíåÂàÜÊûêÂúñÂΩ¢ÁµêÊßãË≥áÊñôÁöÑÊΩõÂäõ„ÄÇÈÄô‰∫õÁµêÊûúÈÇÑÊöóÁ§∫ÔºåÂ∞á MLLM ËàáÁ∞°ÂñÆÁöÑÊúÄ‰Ω≥ÂåñÁ≠ñÁï•Êï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÂèØ‰ª•ÂΩ¢Êàê‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÊúâÊïàÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂú®Ê≤íÊúâË§áÈõúÊé®Â∞é„ÄÅË®àÁÆóÈúÄÊ±ÇÈáèÂ§ßÁöÑË®ìÁ∑¥ÂíåÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÊáâÂ∞çÂúñÂΩ¢ÁµêÊßãÁöÑÁµÑÂêàÊåëÊà∞„ÄÇ

##### **A Hybrid Attention Framework for Fake News Detection with Large Language Models**
2501.11967v1 by Xiaochuan Xu, Peiyang Yu, Zeqiu Xu, Jiani Wang

With the rapid growth of online information, the spread of fake news has
become a serious social challenge. In this study, we propose a novel detection
framework based on Large Language Models (LLMs) to identify and classify fake
news by integrating textual statistical features and deep semantic features.
Our approach utilizes the contextual understanding capability of the large
language model for text analysis and introduces a hybrid attention mechanism to
focus on feature combinations that are particularly important for fake news
identification. Extensive experiments on the WELFake news dataset show that our
model significantly outperforms existing methods, with a 1.5\% improvement in
F1 score. In addition, we assess the interpretability of the model through
attention heat maps and SHAP values, providing actionable insights for content
review strategies. Our framework provides a scalable and efficient solution to
deal with the spread of fake news and helps build a more reliable online
information ecosystem.

ÊëòË¶ÅÔºöÈö®ËëóÁ∂≤Ë∑ØË≥áË®äÁöÑÂø´ÈÄüÊàêÈï∑ÔºåÂÅáÊñ∞ËÅûÁöÑÊï£Êí≠Â∑≤ÊàêÁÇ∫Âö¥ÈáçÁöÑÁ§æÊúÉÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñ∞Á©éÂÅµÊ∏¨Êû∂ÊßãÔºåÈÄèÈÅéÊï¥ÂêàÊñáÂ≠óÁµ±Ë®àÁâπÂæµÂíåÊ∑±Â±§Ë™ûÊÑèÁâπÂæµ‰æÜËæ®Ë≠òÂíåÂàÜÈ°ûÂÅáÊñ∞ËÅû„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÊñáÂ≠óÂàÜÊûê‰∏äÁöÑËÑàÁµ°ÁêÜËß£ËÉΩÂäõÔºå‰∏¶ÂºïÂÖ•Ê∑∑ÂêàÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÂ∞àÊ≥®ÊñºÂ∞çÂÅáÊñ∞ËÅûËæ®Ë≠òÁâπÂà•ÈáçË¶ÅÁöÑÁâπÂæµÁµÑÂêà„ÄÇÂú® WELFake Êñ∞ËÅûË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåF1 ÂàÜÊï∏ÊèêÂçá‰∫Ü 1.5%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÊ≥®ÊÑèÂäõÁÜ±ÂúñÂíå SHAP ÂÄºË©ï‰º∞Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºåÊèê‰æõÂèØË°åÁöÑÊ¥ûÂØüÂäõ‰ª•‰ΩúÁÇ∫ÂÖßÂÆπÂØ©Êü•Á≠ñÁï•„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ‰∏îÊúâÊïàÁöÑËß£Ê±∫ÊñπÊ°à‰æÜËôïÁêÜÂÅáÊñ∞ËÅûÁöÑÊï£Êí≠Ôºå‰∏¶ÊúâÂä©ÊñºÂª∫Á´ãÊõ¥ÂèØÈù†ÁöÑÁ∂≤Ë∑ØË≥áË®äÁîüÊÖãÁ≥ªÁµ±„ÄÇ

##### **TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection**
2501.11960v1 by Yang Cao, Sikun Yang, Chen Li, Haolong Xiang, Lianyong Qi, Bo Liu, Rongsheng Li, Ming Liu

Text anomaly detection is crucial for identifying spam, misinformation, and
offensive language in natural language processing tasks. Despite the growing
adoption of embedding-based methods, their effectiveness and generalizability
across diverse application scenarios remain under-explored. To address this, we
present TAD-Bench, a comprehensive benchmark designed to systematically
evaluate embedding-based approaches for text anomaly detection. TAD-Bench
integrates multiple datasets spanning different domains, combining
state-of-the-art embeddings from large language models with a variety of
anomaly detection algorithms. Through extensive experiments, we analyze the
interplay between embeddings and detection methods, uncovering their strengths,
weaknesses, and applicability to different tasks. These findings offer new
perspectives on building more robust, efficient, and generalizable anomaly
detection systems for real-world applications.

ÊëòË¶ÅÔºöÊñáÊú¨Áï∞Â∏∏ÂÅµÊ∏¨Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Â∞çÊñºËæ®Ë≠òÂûÉÂúæÈÉµ‰ª∂„ÄÅÈåØË™§Ë®äÊÅØÂíåÂÜíÁäØÊÄßË™ûË®ÄËá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°Âü∫ÊñºÂµåÂÖ•ÂºèÁöÑÊñπÊ≥ïÊé°Áî®ÁéáÊó•ÁõäÊèêÈ´òÔºå‰ΩÜÂÖ∂Âú®‰∏çÂêåÊáâÁî®Â†¥ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÊôÆÈÅçÊÄß‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü TAD-BenchÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÔºåÊó®Âú®Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞Âü∫ÊñºÂµåÂÖ•ÂºèÁöÑÊñπÊ≥ï‰ª•ÈÄ≤Ë°åÊñáÊú¨Áï∞Â∏∏ÂÅµÊ∏¨„ÄÇTAD-Bench Êï¥Âêà‰∫ÜË∑®Ë∂ä‰∏çÂêåÈ†òÂüüÁöÑÂ§öÂÄãË≥áÊñôÈõÜÔºåÁµêÂêà‰∫Ü‰æÜËá™Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊúÄÊñ∞ÂµåÂÖ•ÂºèÊäÄË°ìÂíåÂêÑÁ®ÆÁï∞Â∏∏ÂÅµÊ∏¨ÊºîÁÆóÊ≥ï„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂµåÂÖ•ÂºèÊäÄË°ìÂíåÂÅµÊ∏¨ÊñπÊ≥ï‰πãÈñìÁöÑ‰∫§‰∫í‰ΩúÁî®ÔºåÊè≠Á§∫‰∫ÜÂÆÉÂÄëÁöÑÂÑ™Èªû„ÄÅÁº∫ÈªûÂíåÂ∞ç‰∏çÂêå‰ªªÂãôÁöÑÈÅ©Áî®ÊÄß„ÄÇÈÄô‰∫õÁôºÁèæÁÇ∫Âª∫ÊßãÊõ¥Âº∑Â§ß„ÄÅÊõ¥ÊúâÊïàÁéáÂíåÊõ¥ÂÖ∑ÊôÆÈÅçÊÄßÁöÑÁï∞Â∏∏ÂÅµÊ∏¨Á≥ªÁµ±‰ª•ÊáâÂ∞çÁúüÂØ¶‰∏ñÁïåÁöÑÊáâÁî®Êèê‰æõ‰∫ÜÊñ∞ÁöÑËßÄÈªû„ÄÇ

##### **Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model**
2501.11953v1 by Minghan Wang, Viet-Thanh Pham, Farhad Moghimifar, Thuy-Trang Vu

Despite achieving remarkable performance, machine translation (MT) research
remains underexplored in terms of translating cultural elements in languages,
such as idioms, proverbs, and colloquial expressions. This paper investigates
the capability of state-of-the-art neural machine translation (NMT) and large
language models (LLMs) in translating proverbs, which are deeply rooted in
cultural contexts. We construct a translation dataset of standalone proverbs
and proverbs in conversation for four language pairs. Our experiments show that
the studied models can achieve good translation between languages with similar
cultural backgrounds, and LLMs generally outperform NMT models in proverb
translation. Furthermore, we find that current automatic evaluation metrics
such as BLEU, CHRF++ and COMET are inadequate for reliably assessing the
quality of proverb translation, highlighting the need for more culturally aware
evaluation metrics.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê©üÂô®ÁøªË≠Ø (MT) Á†îÁ©∂Â∑≤ÂèñÂæóÈ°ØËëóÁöÑÊàêÊïàÔºå‰ΩÜÂú®ÁøªË≠ØË™ûË®Ä‰∏≠ÁöÑÊñáÂåñÂÖÉÁ¥†Ôºå‰æãÂ¶ÇÊàêË™û„ÄÅË´∫Ë™ûÂíåÂè£Ë™ûË°®ÈÅîÊñπÈù¢‰ªçÊú™ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠Ø (NMT) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÁøªË≠ØË´∫Ë™ûÊñπÈù¢ÁöÑËÉΩÂäõÔºåËÄåË´∫Ë™ûÊ∑±Ê∑±Ê§çÊ†πÊñºÊñáÂåñËÉåÊôØ‰∏≠„ÄÇÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂåÖÂê´ÂõõÁ®ÆË™ûË®ÄÂ∞çÁöÑÁç®Á´ãË´∫Ë™ûÂíåÂ∞çË©±‰∏≠Ë´∫Ë™ûÁöÑÁøªË≠ØË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÊâÄÁ†îÁ©∂ÁöÑÊ®°ÂûãÂèØ‰ª•Âú®ÊñáÂåñËÉåÊôØÁõ∏‰ººÁöÑË™ûË®Ä‰πãÈñìÂØ¶ÁèæËâØÂ•ΩÁöÑÁøªË≠ØÔºåËÄå LLM ÈÄöÂ∏∏Âú®Ë´∫Ë™ûÁøªË≠Ø‰∏≠ÂÑ™Êñº NMT Ê®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæÁõÆÂâçÁöÑËá™ÂãïË©ï‰º∞ÊåáÊ®ôÔºå‰æãÂ¶Ç BLEU„ÄÅCHRF++ Âíå COMETÔºå‰∏çË∂≥‰ª•ÂèØÈù†Âú∞Ë©ï‰º∞Ë´∫Ë™ûÁøªË≠ØÁöÑÂìÅË≥™ÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜÂ∞çÊõ¥ÂÖ∑ÊñáÂåñÊÑèË≠òÁöÑË©ï‰º∞ÊåáÊ®ôÁöÑÈúÄÊ±Ç„ÄÇ

##### **HERITAGE: An End-to-End Web Platform for Processing Korean Historical Documents in Hanja**
2501.11951v1 by Seyoung Song, Haneul Yoo, Jiho Jin, Kyunghyun Cho, Alice Oh

While Korean historical documents are invaluable cultural heritage,
understanding those documents requires in-depth Hanja expertise. Hanja is an
ancient language used in Korea before the 20th century, whose characters were
borrowed from old Chinese but had evolved in Korea for centuries. Modern
Koreans and Chinese cannot understand Korean historical documents without
substantial additional help, and while previous efforts have produced some
Korean and English translations, this requires in-depth expertise, and so most
of the documents are not translated into any modern language. To address this
gap, we present HERITAGE, the first open-source Hanja NLP toolkit to assist in
understanding and translating the unexplored Korean historical documents
written in Hanja. HERITAGE is a web-based platform providing model predictions
of three critical tasks in historical document understanding via Hanja language
models: punctuation restoration, named entity recognition, and machine
translation (MT). HERITAGE also provides an interactive glossary, which
provides the character-level reading of the Hanja characters in modern Korean,
as well as character-level English definition. HERITAGE serves two purposes.
First, anyone interested in these documents can get a general understanding
from the model predictions and the interactive glossary, especially MT outputs
in Korean and English. Second, since the model outputs are not perfect, Hanja
experts can revise them to produce better annotations and translations. This
would boost the translation efficiency and potentially lead to most of the
historical documents being translated into modern languages, lowering the
barrier on unexplored Korean historical documents.

ÊëòË¶ÅÔºö<paragraph>ÂÑòÁÆ°ÈüìÂúãÊ≠∑Âè≤Êñá‰ª∂ÊòØÁÑ°ÂÉπÁöÑÊñáÂåñÈÅ∫Áî¢Ôºå‰ΩÜË¶ÅÁêÜËß£ÈÄô‰∫õÊñá‰ª∂ÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÊº¢Â≠óÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÊº¢Â≠óÊòØ‰∏ÄÁ®ÆÂú® 20 ‰∏ñÁ¥ÄÂâçÊñºÈüìÂúã‰ΩøÁî®ÁöÑÂè§‰ª£Ë™ûË®ÄÔºåÂÖ∂Â≠óÂÖÉÂèñËá™Âè§Êº¢Ë™ûÔºå‰ΩÜÂú®ÈüìÂúãÊºîËÆä‰∫ÜÊï∏ÁôæÂπ¥„ÄÇÁèæ‰ª£ÈüìÂúã‰∫∫Âíå‰∏≠Âúã‰∫∫ÁÑ°Ê≥ïÂú®Ê≤íÊúâÂ§ßÈáèÈ°çÂ§ñÂπ´Âä©ÁöÑÊÉÖÊ≥Å‰∏ãÁêÜËß£ÈüìÂúãÊ≠∑Âè≤Êñá‰ª∂ÔºåÂÑòÁÆ°ÂÖàÂâçÁöÑÂä™ÂäõÁî¢Áîü‰∫Ü‰∏Ä‰∫õÈüìË™ûÂíåËã±Ë™ûÁøªË≠ØÔºå‰ΩÜÈÄôÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÂ∞àÊ•≠Áü•Ë≠òÔºåÂõ†Ê≠§Â§ßÂ§öÊï∏Êñá‰ª∂‰∏¶Êú™ÁøªË≠ØÊàê‰ªª‰ΩïÁèæ‰ª£Ë™ûË®Ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü HERITAGEÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÈñãÊ∫êÊº¢Â≠ó NLP Â∑•ÂÖ∑ÂåÖÔºåÁî®ÊñºÂçîÂä©ÁêÜËß£ÂíåÁøªË≠ØÊú™Êé¢Á¥¢ÁöÑ‰ª•Êº¢Â≠óÊõ∏ÂØ´ÁöÑÈüìÂúãÊ≠∑Âè≤Êñá‰ª∂„ÄÇHERITAGE ÊòØÂü∫ÊñºÁ∂≤Ë∑ØÁöÑÂπ≥Âè∞ÔºåÈÄèÈÅéÊº¢Â≠óË™ûË®ÄÊ®°ÂûãÊèê‰æõÊ≠∑Âè≤Êñá‰ª∂ÁêÜËß£‰∏≠‰∏âÂÄãÈóúÈçµ‰ªªÂãôÁöÑÊ®°ÂûãÈ†êÊ∏¨ÔºöÊ®ôÈªûÁ¨¶ËôüÈÇÑÂéü„ÄÅÂëΩÂêçÂØ¶È´îËæ®Ë≠òÂíåÊ©üÂô®ÁøªË≠Ø (MT)„ÄÇHERITAGE ÈÇÑÊèê‰æõ‰∫íÂãïÂºèË©ûÂΩôË°®ÔºåÊèê‰æõÊº¢Â≠óÂ≠óÂÖÉÂú®Áèæ‰ª£ÈüìË™û‰∏≠ÁöÑÂ≠óÂÖÉÁ¥öËÆÄÈü≥Ôºå‰ª•ÂèäÂ≠óÂÖÉÁ¥öËã±Ë™ûÂÆöÁæ©„ÄÇHERITAGE ÊúâÂÖ©ÂÄãÁõÆÁöÑ„ÄÇÈ¶ñÂÖàÔºå‰ªª‰ΩïÂ∞çÈÄô‰∫õÊñá‰ª∂ÊÑüËààË∂£ÁöÑ‰∫∫ÈÉΩÂèØ‰ª•ÂæûÊ®°ÂûãÈ†êÊ∏¨Âíå‰∫íÂãïÂºèË©ûÂΩôË°®‰∏≠Áç≤Âæó‰∏ÄËà¨ÊÄßÁöÑÁêÜËß£ÔºåÁâπÂà•ÊòØÈüìË™ûÂíåËã±Ë™û‰∏≠ÁöÑ MT Ëº∏Âá∫„ÄÇÂÖ∂Ê¨°ÔºåÁî±ÊñºÊ®°ÂûãËº∏Âá∫‰∏¶ÈùûÂÆåÁæéÔºåÊº¢Â≠óÂ∞àÂÆ∂ÂèØ‰ª•‰øÆÊîπÂÆÉÂÄë‰ª•Áî¢ÁîüÊõ¥Â•ΩÁöÑË®ªÈáãÂíåÁøªË≠Ø„ÄÇÈÄôÂ∞áÊèêÈ´òÁøªË≠ØÊïàÁéáÔºå‰∏¶ÂèØËÉΩÂ∞éËá¥Â§ßÂ§öÊï∏Ê≠∑Âè≤Êñá‰ª∂Ë¢´ÁøªË≠ØÊàêÁèæ‰ª£Ë™ûË®ÄÔºåÈôç‰ΩéÊú™Êé¢Á¥¢ÁöÑÈüìÂúãÊ≠∑Âè≤Êñá‰ª∂ÁöÑÈñÄÊ™ª„ÄÇ</paragraph>

##### **Webvs. LLMs: An Empirical Study of Learning Behaviors of CS2 Students**
2501.11935v1 by Aayush Kumar, Daniel Prol, Amin Alipour, Sruti Srinivasa Ragavan

LLMs such as ChatGPT have been widely adopted by students in higher education
as tools for learning programming and related concepts. However, it remains
unclear how effective students are and what strategies students use while
learning with LLMs. Since the majority of students' experiences in online
self-learning have come through using search engines such as Google, evaluating
AI tools in this context can help us address these gaps. In this mixed methods
research, we conducted an exploratory within-subjects study to understand how
CS2 students learn programming concepts using both LLMs as well as traditional
online methods such as educational websites and videos to examine how students
approach learning within and across both scenarios. We discovered that students
found it easier to learn a more difficult concept using traditional methods
than using ChatGPT. We also found that students ask fewer follow-ups and use
more keyword-based queries for search engines while their prompts to LLMs tend
to explicitly ask for information.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰æãÂ¶Ç ChatGPT Â∑≤Ë¢´È´òÁ≠âÊïôËÇ≤‰∏≠ÁöÑÂ≠∏ÁîüÂª£Ê≥õÊé°Áî®Ôºå‰ΩúÁÇ∫Â≠∏ÁøíÁ®ãÂºèË®≠Ë®àÂíåÁõ∏ÈóúÊ¶ÇÂøµÁöÑÂ∑•ÂÖ∑„ÄÇÁÑ∂ËÄåÔºåÂ≠∏Áîü‰ΩøÁî® LLM ÁöÑÊàêÊïàÂ¶Ç‰Ωï‰ª•Âèä‰ΩøÁî®ÁöÑÁ≠ñÁï•ÁÇ∫‰Ωï‰ªç‰∏çÊ∏ÖÊ•ö„ÄÇÁî±ÊñºÂ§ßÂ§öÊï∏Â≠∏ÁîüÂú®Á∑ö‰∏äËá™Â≠∏ÁöÑÁ∂ìÈ©óÈÉΩ‰æÜËá™‰ΩøÁî® Google Á≠âÊêúÂ∞ãÂºïÊìéÔºåÂõ†Ê≠§Âú®Ê≠§ËÑàÁµ°‰∏≠Ë©ï‰º∞ AI Â∑•ÂÖ∑ÊúâÂä©ÊñºÊàëÂÄëËß£Ê±∫ÈÄô‰∫õÂ∑ÆË∑ù„ÄÇÂú®Ê≠§Ê∑∑ÂêàÊñπÊ≥ïÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÊé¢Á¥¢ÊÄßÁöÑÂèóË©¶ËÄÖÂÖßÁ†îÁ©∂Ôºå‰ª•‰∫ÜËß£ CS2 Â≠∏ÁîüÂ¶Ç‰Ωï‰ΩøÁî® LLM ÂíåÂÇ≥Áµ±Á∑ö‰∏äÊñπÊ≥ïÔºà‰æãÂ¶ÇÊïôËÇ≤Á∂≤Á´ôÂíåÂΩ±ÁâáÔºâÂ≠∏ÁøíÁ®ãÂºèË®≠Ë®àÊ¶ÇÂøµÔºå‰ª•Êé¢Ë®éÂ≠∏ÁîüÂ¶Ç‰ΩïÂú®ÂÖ©Á®ÆÊÉÖÂ¢É‰∏≠ÂíåË∑®ÊÉÖÂ¢ÉÂ≠∏Áøí„ÄÇÊàëÂÄëÁôºÁèæÂ≠∏Áîü‰ΩøÁî®ÂÇ≥Áµ±ÊñπÊ≥ïÂ≠∏ÁøíËºÉÂõ∞Èõ£ÁöÑÊ¶ÇÂøµÊØî‰ΩøÁî® ChatGPT ÂÆπÊòì„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÂ≠∏ÁîüÂú®‰ΩøÁî®ÊêúÂ∞ãÂºïÊìéÊôÇÊúÉÊèêÂá∫ËºÉÂ∞ëÁöÑËøΩËπ§ÂïèÈ°åÔºå‰∏¶‰ΩøÁî®Êõ¥Â§öÂü∫ÊñºÈóúÈçµÂ≠óÁöÑÊü•Ë©¢ÔºåËÄå‰ªñÂÄëÂ∞ç LLM ÁöÑÊèêÁ§∫ÂâáÂÇæÂêëÊñºÊòéÁ¢∫Ë¶ÅÊ±ÇÊèê‰æõË≥áË®ä„ÄÇ

##### **A Lightweight and Interpretable Deepfakes Detection Framework**
2501.11927v1 by Muhammad Umar Farooq, Ali Javed, Khalid Mahmood Malik, Muhammad Anas Raza

The recent realistic creation and dissemination of so-called deepfakes poses
a serious threat to social life, civil rest, and law. Celebrity defaming,
election manipulation, and deepfakes as evidence in court of law are few
potential consequences of deepfakes. The availability of open source trained
models based on modern frameworks such as PyTorch or TensorFlow, video
manipulations Apps such as FaceApp and REFACE, and economical computing
infrastructure has easen the creation of deepfakes. Most of the existing
detectors focus on detecting either face-swap, lip-sync, or puppet master
deepfakes, but a unified framework to detect all three types of deepfakes is
hardly explored. This paper presents a unified framework that exploits the
power of proposed feature fusion of hybrid facial landmarks and our novel heart
rate features for detection of all types of deepfakes. We propose novel heart
rate features and fused them with the facial landmark features to better
extract the facial artifacts of fake videos and natural variations available in
the original videos. We used these features to train a light-weight XGBoost to
classify between the deepfake and bonafide videos. We evaluated the performance
of our framework on the world leaders dataset (WLDR) that contains all types of
deepfakes. Experimental results illustrate that the proposed framework offers
superior detection performance over the comparative deepfakes detection
methods. Performance comparison of our framework against the LSTM-FCN, a
candidate of deep learning model, shows that proposed model achieves similar
results, however, it is more interpretable.

ÊëòË¶ÅÔºöÊúÄËøëÊâÄË∞ìÁöÑÊ∑±Â∫¶‰º™ÈÄ†ÁöÑÈÄºÁúüÂàõ‰ΩúÂíå‰º†Êí≠ÂØπÁ§æ‰ºöÁîüÊ¥ª„ÄÅÂÖ¨Ê∞ëÂÆâÂÆÅÂíåÊ≥ïÂæãÊûÑÊàê‰∫Ü‰∏•ÈáçÂ®ÅËÉÅ„ÄÇÂêç‰∫∫ËØΩË∞§„ÄÅÈÄâ‰∏æÊìçÁ∫µÂíåÂú®Ê≥ïÂ∫≠‰∏äÂ∞ÜÊ∑±Â∫¶‰º™ÈÄ†‰Ωú‰∏∫ËØÅÊçÆÂè™ÊòØÊ∑±Â∫¶‰º™ÈÄ†ÁöÑÂ∞ëÊï∞ÊΩúÂú®ÂêéÊûú„ÄÇÂü∫‰∫é PyTorch Êàñ TensorFlow Á≠âÁé∞‰ª£Ê°ÜÊû∂ÁöÑÂºÄÊ∫êËÆ≠ÁªÉÊ®°Âûã„ÄÅFaceApp Âíå REFACE Á≠âËßÜÈ¢ëÂ§ÑÁêÜÂ∫îÁî®Á®ãÂ∫è‰ª•ÂèäÁªèÊµéÁöÑËÆ°ÁÆóÂü∫Á°ÄËÆæÊñΩÂ∑≤ÁªèÁÆÄÂåñ‰∫ÜÊ∑±Â∫¶‰º™ÈÄ†ÁöÑÂàõÂª∫„ÄÇÂ§ßÂ§öÊï∞Áé∞ÊúâÁöÑÊ£ÄÊµãÂô®‰∏ìÊ≥®‰∫éÊ£ÄÊµãÊç¢ËÑ∏„ÄÅÂîáÂΩ¢ÂêåÊ≠•ÊàñÂÇÄÂÑ°Â§ßÂ∏àÊ∑±Â∫¶‰º™ÈÄ†Ôºå‰ΩÜÂá†‰πéÊ≤°ÊúâÊé¢Á¥¢Âà∞‰∏Ä‰∏™Áî®‰∫éÊ£ÄÊµãÊâÄÊúâËøô‰∏âÁßçÁ±ªÂûãÊ∑±Â∫¶‰º™ÈÄ†ÁöÑÁªü‰∏ÄÊ°ÜÊû∂„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Âà©Áî®‰∫ÜÊ∑∑ÂêàÈù¢ÈÉ®ÁâπÂæÅÂíåÊàë‰ª¨Êñ∞È¢ñÁöÑÂøÉÁéáÁâπÂæÅÁöÑÁâπÂæÅËûçÂêàÂäüËÉΩÊù•Ê£ÄÊµãÊâÄÊúâÁ±ªÂûãÁöÑÊ∑±Â∫¶‰º™ÈÄ†„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜÊñ∞È¢ñÁöÑÂøÉÁéáÁâπÂæÅÔºåÂπ∂Â∞ÜÂÆÉ‰ª¨‰∏éÈù¢ÈÉ®ÁâπÂæÅËûçÂêàÔºå‰ª•Êõ¥Â•ΩÂú∞ÊèêÂèñÂÅáËßÜÈ¢ëÁöÑÈù¢ÈÉ®‰º™ÂÉèÂíåÂéüÂßãËßÜÈ¢ë‰∏≠Â≠òÂú®ÁöÑËá™ÁÑ∂ÂèòÂåñ„ÄÇÊàë‰ª¨‰ΩøÁî®Ëøô‰∫õÁâπÂæÅÊù•ËÆ≠ÁªÉËΩªÈáèÁ∫ßÁöÑ XGBoostÔºå‰ª•ÂØπÊ∑±Â∫¶‰º™ÈÄ†ËßÜÈ¢ëÂíåÁúüÂÆûËßÜÈ¢ëËøõË°åÂàÜÁ±ª„ÄÇÊàë‰ª¨Âú®ÂåÖÂê´ÊâÄÊúâÁ±ªÂûãÊ∑±Â∫¶‰º™ÈÄ†ÁöÑ‰∏ñÁïåÈ¢ÜÂØº‰∫∫Êï∞ÊçÆÈõÜ (WLDR) ‰∏äËØÑ‰º∞‰∫ÜÊàë‰ª¨Ê°ÜÊû∂ÁöÑÊÄßËÉΩ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏éÊØîËæÉÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµãÊñπÊ≥ïÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Êèê‰æõ‰∫ÜÂçìË∂äÁöÑÊ£ÄÊµãÊÄßËÉΩ„ÄÇÊàë‰ª¨Ê°ÜÊû∂‰∏é LSTM-FCNÔºàÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÁöÑÂÄôÈÄâËÄÖÔºâÁöÑÊÄßËÉΩÊØîËæÉË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂèñÂæó‰∫ÜÁ±ª‰ººÁöÑÁªìÊûúÔºåÁÑ∂ËÄåÔºåÂÆÉÊõ¥ÂÖ∑ÂèØËß£ÈáäÊÄß„ÄÇ

##### **LuxVeri at GenAI Detection Task 3: Cross-Domain Detection of AI-Generated Text Using Inverse Perplexity-Weighted Ensemble of Fine-Tuned Transformer Models**
2501.11918v1 by Md Kamrujjaman Mobin, Md Saiful Islam

This paper presents our approach for Task 3 of the GenAI content detection
workshop at COLING-2025, focusing on Cross-Domain Machine-Generated Text (MGT)
Detection. We propose an ensemble of fine-tuned transformer models, enhanced by
inverse perplexity weighting, to improve classification accuracy across diverse
text domains. For Subtask A (Non-Adversarial MGT Detection), we combined a
fine-tuned RoBERTa-base model with an OpenAI detector-integrated RoBERTa-base
model, achieving an aggregate TPR score of 0.826, ranking 10th out of 23
detectors. In Subtask B (Adversarial MGT Detection), our fine-tuned
RoBERTa-base model achieved a TPR score of 0.801, securing 8th out of 22
detectors. Our results demonstrate the effectiveness of inverse
perplexity-based weighting for enhancing generalization and performance in both
non-adversarial and adversarial MGT detection, highlighting the potential for
transformer models in cross-domain AI-generated content detection.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥πÊàëÂÄëÂ∞ç COLING-2025 GenAI ÂÖßÂÆπÂÅµÊ∏¨Â∑•‰ΩúÂùä‰ªªÂãô 3 ÁöÑÊñπÊ≥ïÔºåÈáçÈªûÂú®ÊñºË∑®È†òÂüüÊ©üÂô®Áî¢ÁîüÁöÑÊñáÂ≠ó (MGT) ÂÅµÊ∏¨„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ∂ìÈÅéÂæÆË™øÁöÑËΩâÊèõÂô®Ê®°ÂûãÈõÜÂêàÔºå‰∏¶ÈÄèÈÅéÂèçÂ∞çÊï∏Âõ∞ÊÉëÂ∫¶Âä†Ê¨ä‰æÜÂº∑ÂåñÔºå‰ª•ÊèêÂçá‰∏çÂêåÊñáÂ≠óÈ†òÂüüÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÇÂ∞çÊñºÂ≠ê‰ªªÂãô AÔºàÈùûÂ∞çÊäóÊÄß MGT ÂÅµÊ∏¨ÔºâÔºåÊàëÂÄëÂ∞áÁ∂ìÈÅéÂæÆË™øÁöÑ RoBERTa-base Ê®°ÂûãËàáÊï¥Âêà OpenAI ÂÅµÊ∏¨Âô®ÁöÑ RoBERTa-base Ê®°ÂûãÁµêÂêàÔºåÈÅîÂà∞ 0.826 ÁöÑÁ∏ΩÈ´î TPR ÂàÜÊï∏ÔºåÂú® 23 ÂÄãÂÅµÊ∏¨Âô®‰∏≠ÊéíÂêçÁ¨¨ 10„ÄÇÂú®Â≠ê‰ªªÂãô BÔºàÂ∞çÊäóÊÄß MGT ÂÅµÊ∏¨Ôºâ‰∏≠ÔºåÊàëÂÄëÁ∂ìÈÅéÂæÆË™øÁöÑ RoBERTa-base Ê®°ÂûãÈÅîÂà∞ 0.801 ÁöÑ TPR ÂàÜÊï∏ÔºåÂú® 22 ÂÄãÂÅµÊ∏¨Âô®‰∏≠ÊéíÂêçÁ¨¨ 8„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÊòé‰∫ÜÂü∫ÊñºÂèçÂ∞çÊï∏Âõ∞ÊÉëÂ∫¶ÁöÑÂä†Ê¨äÂú®ÈùûÂ∞çÊäóÊÄßÂíåÂ∞çÊäóÊÄß MGT ÂÅµÊ∏¨‰∏≠ÔºåÂ∞çÊñºÂº∑ÂåñÊ¶ÇÂåñÂíåÊïàËÉΩÊòØÊúâÂπ´Âä©ÁöÑÔºåÁ™ÅÈ°Ø‰∫ÜËΩâÊèõÂô®Ê®°ÂûãÂú®Ë∑®È†òÂüü AI ÁîüÊàêÁöÑÂÖßÂÆπÂÅµÊ∏¨‰∏≠ÁöÑÊΩõÂäõ„ÄÇ

##### **LuxVeri at GenAI Detection Task 1: Inverse Perplexity Weighted Ensemble for Robust Detection of AI-Generated Text across English and Multilingual Contexts**
2501.11914v1 by Md Kamrujjaman Mobin, Md Saiful Islam

This paper presents a system developed for Task 1 of the COLING 2025 Workshop
on Detecting AI-Generated Content, focusing on the binary classification of
machine-generated versus human-written text. Our approach utilizes an ensemble
of models, with weights assigned according to each model's inverse perplexity,
to enhance classification accuracy. For the English text detection task, we
combined RoBERTa-base, RoBERTa-base with the OpenAI detector, and
BERT-base-cased, achieving a Macro F1-score of 0.7458, which ranked us 12th out
of 35 teams. We ensembled RemBERT, XLM-RoBERTa-base, and
BERT-base-multilingual-case for the multilingual text detection task, employing
the same inverse perplexity weighting technique. This resulted in a Macro
F1-score of 0.7513, positioning us 4th out of 25 teams. Our results demonstrate
the effectiveness of inverse perplexity weighting in improving the robustness
of machine-generated text detection across both monolingual and multilingual
settings, highlighting the potential of ensemble methods for this challenging
task.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±ÔºåË©≤Á≥ªÁµ±ÊòØÁÇ∫ COLING 2025 Â∑•‰ΩúÂùäÁöÑ‰ªªÂãô 1 ÈñãÁôºÁöÑÔºåÈáçÈªûÂú®ÊñºÊ©üÂô®Áî¢ÁîüÁöÑÂÖßÂÆπËàá‰∫∫È°ûÊí∞ÂØ´ÁöÑÊñáÂ≠ó‰πãÈñìÁöÑ‰∫åÂÖÉÂàÜÈ°û„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®Ê®°ÂûãÈõÜÂêàÔºå‰∏¶Ê†πÊìöÊØèÂÄãÊ®°ÂûãÁöÑÂèçÂ∞çÊï∏ÂàÜÈÖçÊ¨äÈáçÔºå‰ª•ÊèêÈ´òÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÇÂ∞çÊñºËã±ÊñáÊñáÊú¨ÂÅµÊ∏¨‰ªªÂãôÔºåÊàëÂÄëÁµêÂêà‰∫Ü RoBERTa-base„ÄÅÊê≠Ëºâ OpenAI ÂÅµÊ∏¨Âô®ÁöÑ RoBERTa-baseÔºå‰ª•Âèä BERT-base-casedÔºåÈÅîÂà∞‰∫Ü 0.7458 ÁöÑÂ∑®ËßÄ F1 ÂàÜÊï∏ÔºåÂú® 35 ÂÄãÂúòÈöä‰∏≠ÊéíÂêçÁ¨¨ 12„ÄÇÊàëÂÄëÂ∞á RemBERT„ÄÅXLM-RoBERTa-baseÔºå‰ª•Âèä BERT-base-multilingual-case ÁµÑÂêàËµ∑‰æÜÔºåÁî®ÊñºÂ§öË™ûË®ÄÊñáÊú¨ÂÅµÊ∏¨‰ªªÂãôÔºå‰∏¶Êé°Áî®Áõ∏ÂêåÁöÑÂèçÂ∞çÊï∏Ê¨äÈáçÊäÄË°ì„ÄÇÈÄôÁî¢Áîü‰∫Ü 0.7513 ÁöÑÂ∑®ËßÄ F1 ÂàÜÊï∏Ôºå‰ΩøÊàëÂÄëÂú® 25 ÂÄãÂúòÈöä‰∏≠ÊéíÂêçÁ¨¨ 4„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÊòé‰∫ÜÂèçÂ∞çÊï∏Ê¨äÈáçÂú®ÊèêÈ´òÊ©üÂô®Áî¢ÁîüÁöÑÊñáÊú¨ÂÅµÊ∏¨ÁöÑÁ©©ÂÅ•ÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÁÑ°Ë´ñÊòØÂú®ÂñÆË™ûÁ≥ªÈÇÑÊòØÂ§öË™ûÁ≥ªÁöÑË®≠ÂÆö‰∏≠ÔºåÈÉΩÁ™ÅÈ°Ø‰∫ÜÈõÜÂêàÊñπÊ≥ïÂú®ÈÄôÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõ„ÄÇ

##### **Bridging the Communication Gap: Evaluating AI Labeling Practices for Trustworthy AI Development**
2501.11909v1 by Raphael Fischer, Magdalena Wischnewski, Alexander van der Staay, Katharina Poitz, Christian Janiesch, Thomas Liebig

As artificial intelligence (AI) becomes integral to economy and society,
communication gaps between developers, users, and stakeholders hinder trust and
informed decision-making. High-level AI labels, inspired by frameworks like EU
energy labels, have been proposed to make the properties of AI models more
transparent. Without requiring deep technical expertise, they can inform on the
trade-off between predictive performance and resource efficiency. However, the
practical benefits and limitations of AI labeling remain underexplored. This
study evaluates AI labeling through qualitative interviews along four key
research questions. Based on thematic analysis and inductive coding, we found a
broad range of practitioners to be interested in AI labeling (RQ1). They see
benefits for alleviating communication gaps and aiding non-expert
decision-makers, however limitations, misunderstandings, and suggestions for
improvement were also discussed (RQ2). Compared to other reporting formats,
interviewees positively evaluated the reduced complexity of labels, increasing
overall comprehensibility (RQ3). Trust was influenced most by usability and the
credibility of the responsible labeling authority, with mixed preferences for
self-certification versus third-party certification (RQ4). Our Insights
highlight that AI labels pose a trade-off between simplicity and complexity,
which could be resolved by developing customizable and interactive labeling
frameworks to address diverse user needs. Transparent labeling of resource
efficiency also nudged interviewee priorities towards paying more attention to
sustainability aspects during AI development. This study validates AI labels as
a valuable tool for enhancing trust and communication in AI, offering
actionable guidelines for their refinement and standardization.

ÊëòË¶ÅÔºö<paragraph>ÈöèÁùÄ‰∫∫Â∑•Êô∫ËÉΩ (AI) ÈÄêÊ∏êÊàê‰∏∫ÁªèÊµé‰∏éÁ§æ‰ºö‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂºÄÂèë‰∫∫Âëò„ÄÅ‰ΩøÁî®ËÄÖÂíåÂà©ÁõäÁõ∏ÂÖ≥ËÄÖ‰πãÈó¥ÁöÑÊ≤üÈÄöÈ∏øÊ≤üÈòªÁ¢ç‰∫Ü‰ø°‰ªªÂíåÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇÂèóÊ¨ßÁõüËÉΩÊ∫êÊ†áÁ≠æÁ≠âÊ°ÜÊû∂ÂêØÂèëÁöÑ AI È´òÁ∫ßÊ†áÁ≠æÂ∑≤Ë¢´ÊèêÂá∫Ôºå‰ª•‰Ωø AI Ê®°ÂûãÁöÑÂ±ûÊÄßÊõ¥Âä†ÈÄèÊòé„ÄÇÂú®Êó†ÈúÄÊ∑±ÂÖ•ÊäÄÊúØ‰∏ì‰∏öÁü•ËØÜÁöÑÊÉÖÂÜµ‰∏ãÔºåÂÆÉ‰ª¨ÂèØ‰ª•ÂëäÁü•È¢ÑÊµãÊÄßËÉΩÂíåËµÑÊ∫êÊïàÁéá‰πãÈó¥ÁöÑÊùÉË°°ÂèñËàç„ÄÇÁÑ∂ËÄåÔºåAI Ê†áÁ≠æÁöÑÂÆûÈôÖÂ•ΩÂ§ÑÂíåÂ±ÄÈôêÊÄß‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÊú¨Á†îÁ©∂ÈÄöËøáÂÆöÊÄßËÆøË∞àËØÑ‰º∞‰∫Ü AI Ê†áÁ≠æÔºåÊ∂âÂèäÂõõ‰∏™ÂÖ≥ÈîÆÁöÑÁ†îÁ©∂ÈóÆÈ¢ò„ÄÇÂü∫‰∫é‰∏ªÈ¢òÂàÜÊûêÂíåÂΩíÁ∫≥ÁºñÁ†ÅÔºåÊàë‰ª¨ÂèëÁé∞ÂπøÊ≥õÁöÑ‰ªé‰∏öËÄÖÂØπ AI Ê†áÁ≠æÊÑüÂÖ¥Ë∂£ (RQ1)„ÄÇ‰ªñ‰ª¨ÁúãÂà∞‰∫ÜÁºìËß£Ê≤üÈÄöÈ∏øÊ≤üÂíåÂ∏ÆÂä©Èùû‰∏ìÂÆ∂ÂÜ≥Á≠ñËÄÖÁöÑÂ•ΩÂ§ÑÔºå‰ΩÜÂ±ÄÈôêÊÄß„ÄÅËØØËß£ÂíåÊîπËøõÂª∫ËÆÆ‰πüËøõË°å‰∫ÜËÆ®ËÆ∫ (RQ2)„ÄÇ‰∏éÂÖ∂‰ªñÊä•ÂëäÊ†ºÂºèÁõ∏ÊØîÔºåÂèóËÆøËÄÖÂØπÊ†áÁ≠æÂ§çÊùÇÊÄßÁöÑÈôç‰ΩéÂíåÊï¥‰ΩìÂèØÁêÜËß£ÊÄßÁöÑÊèêÈ´òÁªô‰∫à‰∫ÜÁßØÊûÅËØÑ‰ª∑ (RQ3)„ÄÇ‰ø°‰ªªÊúÄÂèóÂèØÁî®ÊÄßÂíåË¥üË¥£Ê†áÁ≠æÊú∫ÊûÑÁöÑÂèØ‰ø°Â∫¶ÁöÑÂΩ±ÂìçÔºåÂØπ‰∫éËá™ÊàëËÆ§ËØÅ‰∏éÁ¨¨‰∏âÊñπËÆ§ËØÅÊúâ‰∏çÂêåÁöÑÂÅèÂ•Ω (RQ4)„ÄÇÊàë‰ª¨ÁöÑËßÅËß£Âº∫Ë∞ÉÔºåAI Ê†áÁ≠æÂú®ÁÆÄÂçïÊÄßÂíåÂ§çÊùÇÊÄß‰πãÈó¥Â≠òÂú®ÊùÉË°°ÔºåÂèØ‰ª•ÈÄöËøáÂºÄÂèëÂèØÂÆöÂà∂Âíå‰∫§‰∫íÂºèÁöÑÊ†áÁ≠æÊ°ÜÊû∂Êù•Ëß£ÂÜ≥‰∏çÂêåÁöÑÁî®Êà∑ÈúÄÊ±Ç„ÄÇËµÑÊ∫êÊïàÁéáÁöÑÈÄèÊòéÊ†áÁ≠æ‰πü‰øÉ‰ΩøÂèóËÆøËÄÖÁöÑ‰ºòÂÖà‰∫ãÈ°πÂú® AI ÂºÄÂèëËøáÁ®ã‰∏≠Êõ¥Âä†ÂÖ≥Ê≥®ÂèØÊåÅÁª≠ÊÄßÊñπÈù¢„ÄÇÊú¨Á†îÁ©∂È™åËØÅ‰∫Ü AI Ê†áÁ≠æ‰Ωú‰∏∫Â¢ûÂº∫ AI ‰∏≠‰ø°‰ªªÂíåÊ≤üÈÄöÁöÑÂÆùË¥µÂ∑•ÂÖ∑Ôºå‰∏∫ÂÖ∂ÂÆåÂñÑÂíåÊ†áÂáÜÂåñÊèê‰æõ‰∫ÜÂèØË°åÁöÑÊåáÂØºÊñπÈíà„ÄÇ</paragraph>

##### **Panoramic Interests: Stylistic-Content Aware Personalized Headline Generation**
2501.11900v1 by Junhong Lian, Xiang Ao, Xinyu Liu, Yang Liu, Qing He

Personalized news headline generation aims to provide users with
attention-grabbing headlines that are tailored to their preferences. Prevailing
methods focus on user-oriented content preferences, but most of them overlook
the fact that diverse stylistic preferences are integral to users' panoramic
interests, leading to suboptimal personalization. In view of this, we propose a
novel Stylistic-Content Aware Personalized Headline Generation (SCAPE)
framework. SCAPE extracts both content and stylistic features from headlines
with the aid of large language model (LLM) collaboration. It further adaptively
integrates users' long- and short-term interests through a contrastive
learning-based hierarchical fusion network. By incorporating the panoramic
interests into the headline generator, SCAPE reflects users' stylistic-content
preferences during the generation process. Extensive experiments on the
real-world dataset PENS demonstrate the superiority of SCAPE over baselines.

ÊëòË¶ÅÔºöÂÄã‰∫∫ÂåñÊñ∞ËÅûÊ®ôÈ°åÁîüÊàêÊó®Âú®ÁÇ∫‰ΩøÁî®ËÄÖÊèê‰æõÂê∏ÂºïÁúºÁêÉ„ÄÅ‰∏îÁ¨¶ÂêàÂÖ∂ÂÅèÂ•ΩÁöÑÊ®ôÈ°å„ÄÇÁèæË°åÁöÑÂÅöÊ≥ïËëóÈáçÊñº‰ª•‰ΩøÁî®ËÄÖÁÇ∫Â∞éÂêëÁöÑÂÖßÂÆπÂÅèÂ•ΩÔºå‰ΩÜÂ§ßÂ§öÊï∏ÁöÑÂÅöÊ≥ïÂøΩÁï•‰∫ÜÂ§öÊ®£ÂåñÁöÑÈ¢®Ê†ºÂÅèÂ•ΩËàá‰ΩøÁî®ËÄÖÂÖ®ÊôØÂºèËààË∂£ÂØÜ‰∏çÂèØÂàÜÁöÑÈÄôÂÄã‰∫ãÂØ¶ÔºåÂ∞éËá¥Ê¨°‰Ω≥ÁöÑÂÄã‰∫∫ÂåñÁµêÊûú„ÄÇÊúâÈëëÊñºÊ≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÈ¢®Ê†ºÂÖßÂÆπÊÑüÁü•ÂÄã‰∫∫ÂåñÊ®ôÈ°åÁîüÊàê (SCAPE) Êû∂Êßã„ÄÇSCAPE Âú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âçî‰ΩúÁöÑÂçîÂä©‰∏ãÔºåÂæûÊ®ôÈ°å‰∏≠ÊèêÂèñÂÖßÂÆπÂíåÈ¢®Ê†ºÁâπÂæµ„ÄÇÂÆÉÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÂ∞çÊØîÂ≠∏ÁøíÂü∫Á§éÁöÑÂàÜÂ±§ËûçÂêàÁ∂≤Ë∑ØÔºåËá™ÈÅ©ÊáâÂú∞Êï¥Âêà‰ΩøÁî®ËÄÖÁöÑÈï∑ÊúüÂíåÁü≠ÊúüËààË∂£„ÄÇSCAPE ÈÄèÈÅéÂ∞áÂÖ®ÊôØÂºèËààË∂£Á¥çÂÖ•Ê®ôÈ°åÁî¢ÁîüÂô®ÔºåÂú®ÁîüÊàêÈÅéÁ®ã‰∏≠ÂèçÊò†‰ΩøÁî®ËÄÖÁöÑÈ¢®Ê†ºÂÖßÂÆπÂÅèÂ•Ω„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ PENS ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü SCAPE ÂÑ™ÊñºÂü∫Á∑ö„ÄÇ

##### **Systematic Abductive Reasoning via Diverse Relation Representations in Vector-symbolic Architecture**
2501.11896v1 by Zhong-Hua Sun, Ru-Yuan Zhang, Zonglei Zhen, Da-Hui Wang, Yong-Jie Li, Xiaohong Wan, Hongzhi You

In abstract visual reasoning, monolithic deep learning models suffer from
limited interpretability and generalization, while existing neuro-symbolic
approaches fall short in capturing the diversity and systematicity of
attributes and relation representations. To address these challenges, we
propose a Systematic Abductive Reasoning model with diverse relation
representations (Rel-SAR) in Vector-symbolic Architecture (VSA) to solve
Raven's Progressive Matrices (RPM). To derive attribute representations with
symbolic reasoning potential, we introduce not only various types of atomic
vectors that represent numeric, periodic and logical semantics, but also the
structured high-dimentional representation (SHDR) for the overall Grid
component. For systematic reasoning, we propose novel numerical and logical
relation functions and perform rule abduction and execution in a unified
framework that integrates these relation representations. Experimental results
demonstrate that Rel-SAR achieves significant improvement on RPM tasks and
exhibits robust out-of-distribution generalization. Rel-SAR leverages the
synergy between HD attribute representations and symbolic reasoning to achieve
systematic abductive reasoning with both interpretable and computable
semantics.

ÊëòË¶ÅÔºöÂú®ÊäΩË±°ËßÜËßâÊé®ÁêÜ‰∏≠ÔºåÂçï‰∏ÄÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÂú®ÂèØËß£ÈáäÊÄßÂíåÊ≥õÂåñËÉΩÂäõÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåËÄåÁé∞ÊúâÁöÑÁ•ûÁªèÁ¨¶Âè∑ÊñπÊ≥ïÂú®ÊçïÊçâÂ±ûÊÄßÂíåÂÖ≥Á≥ªË°®Á§∫ÁöÑÂ§öÊ†∑ÊÄßÂíåÁ≥ªÁªüÊÄßÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∫õÊåëÊàòÔºåÊàë‰ª¨Âú®Áü¢ÈáèÁ¨¶Âè∑Êû∂ÊûÑ (VSA) ‰∏≠ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂÖ∑Êúâ‰∏çÂêåÂÖ≥Á≥ªË°®Á§∫ÁöÑÁ≥ªÁªüÊºîÁªéÊé®ÁêÜÊ®°Âûã (Rel-SAR)Ôºå‰ª•Ëß£ÂÜ≥Èõ∑ÊñáÊ∏êËøõÁü©Èòµ (RPM)„ÄÇ‰∏∫‰∫ÜÊé®ÂØºÂá∫ÂÖ∑ÊúâÁ¨¶Âè∑Êé®ÁêÜÊΩúÂäõÁöÑÂ±ûÊÄßË°®Á§∫ÔºåÊàë‰ª¨‰∏ç‰ªÖÂºïÂÖ•‰∫ÜË°®Á§∫Êï∞Â≠ó„ÄÅÂë®ÊúüÊÄßÂíåÈÄªËæëËØ≠‰πâÁöÑÂêÑÁßçÁ±ªÂûãÁöÑÂéüÂ≠êÂêëÈáèÔºåËøòÂºïÂÖ•‰∫ÜÊï¥‰ΩìÁΩëÊ†ºÁªÑ‰ª∂ÁöÑÁªìÊûÑÂåñÈ´òÁª¥Ë°®Á§∫ (SHDR)„ÄÇÂØπ‰∫éÁ≥ªÁªüÊé®ÁêÜÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊñ∞ÁöÑÊï∞ÂÄºÂíåÈÄªËæëÂÖ≥Á≥ªÂáΩÊï∞ÔºåÂπ∂Âú®Áªü‰∏ÄÁöÑÊ°ÜÊû∂‰∏≠ÊâßË°åËßÑÂàôÂΩíÁ∫≥ÂíåÊâßË°åÔºåËØ•Ê°ÜÊû∂ÈõÜÊàê‰∫ÜËøô‰∫õÂÖ≥Á≥ªË°®Á§∫„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRel-SAR Âú® RPM ‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæÁùÄÊîπËøõÔºåÂπ∂Ë°®Áé∞Âá∫Á®≥ÂÅ•ÁöÑÂàÜÂ∏ÉÂ§ñÊ≥õÂåñËÉΩÂäõ„ÄÇRel-SAR Âà©Áî®È´òÊ∏ÖÂ±ûÊÄßË°®Á§∫ÂíåÁ¨¶Âè∑Êé®ÁêÜ‰πãÈó¥ÁöÑÂçèÂêå‰ΩúÁî®ÔºåÂÆûÁé∞‰∫ÜÂèØËß£ÈáäÂíåÂèØËÆ°ÁÆóËØ≠‰πâÁöÑÁ≥ªÁªüÊºîÁªéÊé®ÁêÜ„ÄÇ

##### **Med-R$^2$: Crafting Trustworthy LLM Physicians through Retrieval and Reasoning of Evidence-Based Medicine**
2501.11885v1 by Keer Lu, Zheng Liang, Da Pan, Shusen Zhang, Xin Wu, Weipeng Chen, Zenan Zhou, Guosheng Dong, Bin Cui, Wentao Zhang

In recent years, Large Language Models (LLMs) have exhibited remarkable
capabilities in clinical scenarios. However, despite their potential, existing
works face challenges when applying LLMs to medical settings. Strategies
relying on training with medical datasets are highly cost-intensive and may
suffer from outdated training data. Leveraging external knowledge bases is a
suitable alternative, yet it faces obstacles such as limited retrieval
precision and poor effectiveness in answer extraction. These issues
collectively prevent LLMs from demonstrating the expected level of proficiency
in mastering medical expertise. To address these challenges, we introduce
Med-R^2, a novel LLM physician framework that adheres to the Evidence-Based
Medicine (EBM) process, efficiently integrating retrieval mechanisms as well as
the selection and reasoning processes of evidence, thereby enhancing the
problem-solving capabilities of LLMs in healthcare scenarios and fostering a
trustworthy LLM physician. Our comprehensive experiments indicate that Med-R^2
achieves a 14.87\% improvement over vanilla RAG methods and even a 3.59\%
enhancement compared to fine-tuning strategies, without incurring additional
training costs.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•ÔºåÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®‰∏¥Â∫äÂú∫ÊôØ‰∏≠Â±ïÁé∞Âá∫‰∫ÜÈùûÂá°ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂ∞ΩÁÆ°ÂÆÉ‰ª¨ÂÖ∑ÊúâÊΩúÂäõÔºå‰ΩÜÁé∞ÊúâÂ∑•‰ΩúÂú®Â∞Ü LLM Â∫îÁî®‰∫éÂåªÁñóÁéØÂ¢ÉÊó∂Èù¢‰∏¥ÊåëÊàò„ÄÇ‰æùËµñ‰∫éÂåªÂ≠¶Êï∞ÊçÆÈõÜËøõË°åËÆ≠ÁªÉÁöÑÁ≠ñÁï•ÊàêÊú¨ÈùûÂ∏∏È´òÔºåÂπ∂‰∏îÂèØËÉΩ‰ºöÂõ†ËÆ≠ÁªÉÊï∞ÊçÆËøáÊó∂ËÄåÂèóÂà∞ÂΩ±Âìç„ÄÇÂà©Áî®Â§ñÈÉ®Áü•ËØÜÂ∫ìÊòØ‰∏Ä‰∏™ÂêàÈÄÇÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰ΩÜÂÆÉÈù¢‰∏¥ÁùÄËØ∏Â¶ÇÊ£ÄÁ¥¢Á≤æÂ∫¶ÊúâÈôêÂíåÁ≠îÊ°àÊèêÂèñÊïàÊûúÂ∑ÆÁ≠âÈöúÁ¢ç„ÄÇËøô‰∫õÈóÆÈ¢òÂÖ±ÂêåÈòªÊ≠¢‰∫Ü LLM Âú®ÊéåÊè°ÂåªÂ≠¶‰∏ì‰∏öÁü•ËØÜÊñπÈù¢Ë°®Áé∞Âá∫È¢ÑÊúüÁöÑÁÜüÁªÉÁ®ãÂ∫¶„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü Med-R^2ÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑ LLM ÂåªÁîüÊ°ÜÊû∂ÔºåÂÆÉÈÅµÂæ™Âæ™ËØÅÂåªÂ≠¶ (EBM) ÊµÅÁ®ãÔºåÊúâÊïàÂú∞ÈõÜÊàê‰∫ÜÊ£ÄÁ¥¢Êú∫Âà∂‰ª•ÂèäËØÅÊçÆÁöÑÈÄâÊã©ÂíåÊé®ÁêÜËøáÁ®ãÔºå‰ªéËÄåÂ¢ûÂº∫‰∫Ü LLM Âú®ÂåªÁñó‰øùÂÅ•Âú∫ÊôØ‰∏≠ÁöÑÈóÆÈ¢òËß£ÂÜ≥ËÉΩÂäõÂπ∂ÂüπÂÖª‰∫Ü‰∏Ä‰∏™ÂÄºÂæó‰ø°ËµñÁöÑ LLM ÂåªÁîü„ÄÇÊàë‰ª¨ÁöÑÁªºÂêàÂÆûÈ™åË°®ÊòéÔºåMed-R^2 ÊØîÈ¶ôËçâ RAG ÊñπÊ≥ïÊèêÈ´ò‰∫Ü 14.87%ÔºåÁîöËá≥ÊØîÂæÆË∞ÉÁ≠ñÁï•ÊèêÈ´ò‰∫Ü 3.59%ÔºåËÄåÊ≤°Êúâ‰∫ßÁîüÈ¢ùÂ§ñÁöÑÂüπËÆ≠ÊàêÊú¨„ÄÇ

##### **Community-Aware Temporal Walks: Parameter-Free Representation Learning on Continuous-Time Dynamic Graphs**
2501.11880v1 by He Yu, Jing Liu

Dynamic graph representation learning plays a crucial role in understanding
evolving behaviors. However, existing methods often struggle with flexibility,
adaptability, and the preservation of temporal and structural dynamics. To
address these issues, we propose Community-aware Temporal Walks (CTWalks), a
novel framework for representation learning on continuous-time dynamic graphs.
CTWalks integrates three key components: a community-based parameter-free
temporal walk sampling mechanism, an anonymization strategy enriched with
community labels, and an encoding process that leverages continuous temporal
dynamics modeled via ordinary differential equations (ODEs). This design
enables precise modeling of both intra- and inter-community interactions,
offering a fine-grained representation of evolving temporal patterns in
continuous-time dynamic graphs. CTWalks theoretically overcomes locality bias
in walks and establishes its connection to matrix factorization. Experiments on
benchmark datasets demonstrate that CTWalks outperforms established methods in
temporal link prediction tasks, achieving higher accuracy while maintaining
robustness.

ÊëòË¶ÅÔºöÂãïÊÖãÂúñÂΩ¢Ë°®ÂæµÂ≠∏ÁøíÂú®ÁêÜËß£ÊºîÂåñË°åÁÇ∫ÊâÆÊºîËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏Âú®ÈùàÊ¥ªÊÄß„ÄÅÈÅ©ÊáâÊÄßÂíåÊôÇÈñìÂíåÁµêÊßãÂãïÊÖãÁöÑ‰øùÂ≠ò‰∏äÈÅáÂà∞Âõ∞Èõ£„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫Á§æÁæ§ÊÑüÁü•ÊôÇÈñìÊº´Ê≠• (CTWalks)Ôºå‰∏ÄÁ®ÆÈáùÂ∞çÈÄ£Á∫åÊôÇÈñìÂãïÊÖãÂúñÂΩ¢ÈÄ≤Ë°åË°®ÂæµÂ≠∏ÁøíÁöÑÊñ∞Á©éÊû∂Êßã„ÄÇCTWalks Êï¥Âêà‰∫Ü‰∏âÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºöÂü∫ÊñºÁ§æÁæ§ÁöÑÁÑ°ÂèÉÊï∏ÊôÇÈñìÊº´Ê≠•ÂèñÊ®£Ê©üÂà∂„ÄÅË±êÂØåÁ§æÁæ§Ê®ôÁ±§ÁöÑÂåøÂêçÂåñÁ≠ñÁï•Ôºå‰ª•ÂèäÂà©Áî®ÈÄèÈÅéÂ∏∏ÂæÆÂàÜÊñπÁ®ãÂºè (ODE) Âª∫Ê®°ÁöÑÈÄ£Á∫åÊôÇÈñìÂãïÊÖãÁöÑÁ∑®Á¢ºÊµÅÁ®ã„ÄÇÊ≠§Ë®≠Ë®àËÉΩÁ≤æÁ¢∫Âª∫Ê®°Á§æÁæ§ÂÖßÈÉ®ÂíåÁ§æÁæ§‰πãÈñìÁöÑ‰∫íÂãïÔºåÊèê‰æõÈÄ£Á∫åÊôÇÈñìÂãïÊÖãÂúñÂΩ¢‰∏≠ÊºîÂåñÊôÇÈñìÊ®°ÂºèÁöÑÁ¥∞Á∑ªË°®Âæµ„ÄÇCTWalks Âú®ÁêÜË´ñ‰∏äÂÖãÊúç‰∫ÜÊº´Ê≠•‰∏≠ÁöÑÂ±ÄÈÉ®ÂÅèË™§Ôºå‰∏¶Âª∫Á´ãËàáÁü©Èô£ÂàÜËß£ÁöÑÈóúËÅØ„ÄÇÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË≠âÊòéÔºåCTWalks Âú®ÊôÇÈñìÈÄ£ÁµêÈ†êÊ∏¨‰ªªÂãô‰∏≠ÂÑ™ÊñºÊó¢ÊúâÊñπÊ≥ïÔºåÂú®Á∂≠ÊåÅÁ©©ÂÅ•ÊÄßÁöÑÂêåÊôÇÈÅîÊàêÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning**
2501.11877v1 by Yafu Li, Zhilin Wang, Tingchen Fu, Ganqu Cui, Sen Yang, Yu Cheng

Scaling data and model size has been proven effective for boosting the
performance of large language models. In addition to training-time scaling,
recent studies have revealed that increasing test-time computational resources
can further improve performance. In this work, we introduce Aggregation
Fine-Tuning (AFT), a supervised finetuning paradigm where the model learns to
synthesize multiple draft responses, referred to as proposals, into a single,
refined answer, termed aggregation. At inference time, a propose-and-aggregate
strategy further boosts performance by iteratively generating proposals and
aggregating them. Empirical evaluations on benchmark datasets show that
AFT-trained models substantially outperform standard SFT. Notably, an AFT
model, fine-tuned from Llama3.1-8B-Base with only 64k data, achieves a 41.3% LC
win rate on AlpacaEval 2, surpassing significantly larger LLMs such as
Llama3.1-405B-Instruct and GPT4. By combining sequential refinement and
parallel sampling, the propose-and-aggregate framework scales inference-time
computation in a flexible manner. Overall, These findings position AFT as a
promising approach to unlocking additional capabilities of LLMs without
resorting to increasing data volume or model size.

ÊëòË¶ÅÔºöÊì¥Â±ïË≥áÊñôÂíåÊ®°ÂûãÂ§ßÂ∞èÂ∑≤Ë¢´Ë≠âÊòéËÉΩÊúâÊïàÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÈô§‰∫ÜË®ìÁ∑¥ÊôÇÈñìÁöÑÊì¥Â±ïÔºåÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÂ¢ûÂä†Ê∏¨Ë©¶ÊôÇÈñìÁöÑÈÅãÁÆóË≥áÊ∫êËÉΩÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÊïàËÉΩ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËÅöÂêàÂæÆË™ø (AFT)Ôºå‰∏ÄÁ®ÆÁõ£Áù£ÂºèÂæÆË™øÁØÑ‰æãÔºåÂÖ∂‰∏≠Ê®°ÂûãÂ≠∏ÁøíÂ∞áÂ§öÂÄãËçâÁ®øÂõûÊáâÔºàÁ®±ÁÇ∫ÊèêÊ°àÔºâÂêàÊàêÁÇ∫‰∏ÄÂÄãÂñÆ‰∏ÄÁöÑÁ≤æÁ∑ªÁ≠îÊ°àÔºåÁ®±ÁÇ∫ËÅöÂêà„ÄÇÂú®Êé®Ë´ñÊôÇÈñìÔºå‰∏ÄÁ®ÆÊèêÂá∫ÂíåËÅöÂêàÁ≠ñÁï•ÈÄöÈÅéÂèçË¶ÜÁîüÊàêÊèêÊ°à‰∏¶Â∞áÂÆÉÂÄëËÅöÂêàËµ∑‰æÜÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÊïàËÉΩ„ÄÇÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÁ∂ìÈ©óË©ï‰º∞È°ØÁ§∫ÔºåAFT Ë®ìÁ∑¥ÁöÑÊ®°ÂûãÊòéÈ°ØÂÑ™ÊñºÊ®ôÊ∫ñ SFT„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºå‰∏ÄÂÄã AFT Ê®°ÂûãÔºåÂÉÖ‰ΩøÁî® 64k Ë≥áÊñôÂæû Llama3.1-8B-Base ÂæÆË™øÔºåÂú® AlpacaEval 2 ‰∏äÂØ¶Áèæ‰∫Ü 41.3% ÁöÑ LC ÂãùÁéáÔºåË∂ÖÈÅé‰∫ÜÈ°ØËëóÊõ¥Â§ßÁöÑ LLMÔºå‰æãÂ¶Ç Llama3.1-405B-Instruct Âíå GPT4„ÄÇÈÄöÈÅéÁµêÂêàÈ†ÜÂ∫èÁ≤æÁÖâÂíå‰∏¶Ë°åÊé°Ê®£ÔºåÊèêÂá∫ÂíåËÅöÂêàÊ°ÜÊû∂‰ª•ÈùàÊ¥ªÁöÑÊñπÂºèÊì¥Â±ï‰∫ÜÊé®Ë´ñÊôÇÈñìÁöÑÈÅãÁÆó„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÈÄô‰∫õÁôºÁèæÂ∞á AFT ÂÆö‰ΩçÁÇ∫‰∏ÄÁ®ÆÊúâÂ∏åÊúõÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Âú®‰∏çÂ¢ûÂä†Ë≥áÊñôÈáèÊàñÊ®°ÂûãÂ§ßÂ∞èÁöÑÊÉÖÊ≥Å‰∏ãÈáãÊîæ LLM ÁöÑÈ°çÂ§ñÂäüËÉΩ„ÄÇ

##### **Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models**
2501.11873v1 by Zihan Qiu, Zeyu Huang, Bo Zheng, Kaiyue Wen, Zekun Wang, Rui Men, Ivan Titov, Dayiheng Liu, Jingren Zhou, Junyang Lin

This paper revisits the implementation of
$\textbf{L}$oad-$\textbf{b}$alancing $\textbf{L}$oss (LBL) when training
Mixture-of-Experts (MoEs) models. Specifically, LBL for MoEs is defined as $N_E
\sum_{i=1}^{N_E} f_i p_i$, where $N_E$ is the total number of experts, $f_i$
represents the frequency of expert $i$ being selected, and $p_i$ denotes the
average gating score of the expert $i$. Existing MoE training frameworks
usually employ the parallel training strategy so that $f_i$ and the LBL are
calculated within a $\textbf{micro-batch}$ and then averaged across parallel
groups. In essence, a micro-batch for training billion-scale LLMs normally
contains very few sequences. So, the micro-batch LBL is almost at the sequence
level, and the router is pushed to distribute the token evenly within each
sequence. Under this strict constraint, even tokens from a domain-specific
sequence ($\textit{e.g.}$, code) are uniformly routed to all experts, thereby
inhibiting expert specialization. In this work, we propose calculating LBL
using a $\textbf{global-batch}$ to loose this constraint. Because a
global-batch contains much more diverse sequences than a micro-batch, which
will encourage load balance at the corpus level. Specifically, we introduce an
extra communication step to synchronize $f_i$ across micro-batches and then use
it to calculate the LBL. Through experiments on training MoEs-based LLMs (up to
$\textbf{42.8B}$ total parameters and $\textbf{400B}$ tokens), we surprisingly
find that the global-batch LBL strategy yields excellent performance gains in
both pre-training perplexity and downstream tasks. Our analysis reveals that
the global-batch LBL also greatly improves the domain specialization of MoE
experts.

ÊëòË¶ÅÔºö<paragraph>Êú¨ÊñáÈáçÊñ∞Êé¢Ë®é‰∫ÜÂú®Ë®ìÁ∑¥ Mixture-of-Experts (MoEs) Ê®°ÂûãÊôÇÔºå$\textbf{L}$oad-$\textbf{b}$alancing $\textbf{L}$oss (LBL) ÁöÑÂØ¶‰Ωú„ÄÇÂÖ∑È´î‰æÜË™™ÔºåMoEs ÁöÑ LBL Ë¢´ÂÆöÁæ©ÁÇ∫ $N_E \sum_{i=1}^{N_E} f_i p_i$ÔºåÂÖ∂‰∏≠ $N_E$ ÊòØÂ∞àÂÆ∂ÁöÑÁ∏ΩÊï∏Ôºå$f_i$ Ë°®Á§∫ÈÅ∏ÊìáÂ∞àÂÆ∂ $i$ ÁöÑÈ†ªÁéáÔºåËÄå $p_i$ Ë°®Á§∫Â∞àÂÆ∂ $i$ ÁöÑÂπ≥ÂùáÈñòÊéßÂàÜÊï∏„ÄÇÁèæÊúâÁöÑ MoE Ë®ìÁ∑¥Êû∂ÊßãÈÄöÂ∏∏Êé°Áî®‰∏¶Ë°åË®ìÁ∑¥Á≠ñÁï•Ôºå‰ª•‰æøÂú® $\textbf{ÂæÆÊâπÊ¨°}$ ‰∏≠Ë®àÁÆó $f_i$ Âíå LBLÔºåÁÑ∂ÂæåÂú®‰∏¶Ë°åÁæ§ÁµÑ‰∏≠ÂèñÂπ≥ÂùáÂÄº„ÄÇÂØ¶Ë≥™‰∏äÔºåË®ìÁ∑¥ÂçÅÂÑÑË¶èÊ®° LLM ÁöÑÂæÆÊâπÊ¨°ÈÄöÂ∏∏Âè™ÂåÖÂê´ÂæàÂ∞ëÁöÑÂ∫èÂàó„ÄÇÂõ†Ê≠§ÔºåÂæÆÊâπÊ¨° LBL Âπæ‰πéËôïÊñºÂ∫èÂàóÂ±§Á¥öÔºåËÄåË∑ØÁî±Âô®Ë¢´Ëø´Âú®ÊØèÂÄãÂ∫èÂàó‰∏≠ÂùáÂãªÂàÜÈÖç‰ª§Áâå„ÄÇÂú®ÈÄôÂÄãÂö¥Ê†ºÁöÑÁ¥ÑÊùü‰∏ãÔºåÂç≥‰Ωø‰æÜËá™ÁâπÂÆöÈ†òÂüüÂ∫èÂàóÔºà$\textit{e.g.}$ÔºåÁ®ãÂºèÁ¢ºÔºâÁöÑ‰ª§Áâå‰πüÊúÉÂùáÂãªË∑ØÁî±Âà∞ÊâÄÊúâÂ∞àÂÆ∂ÔºåÂæûËÄåÊäëÂà∂Â∞àÂÆ∂Â∞àÊ•≠Âåñ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰ΩøÁî® $\textbf{ÂÖ®ÂüüÊâπÊ¨°}$ Ë®àÁÆó LBL ‰ª•Ëß£Èô§ÈÄôÂÄãÁ¥ÑÊùü„ÄÇÁî±ÊñºÂÖ®ÂüüÊâπÊ¨°ÂåÖÂê´ÊØîÂæÆÊâπÊ¨°Êõ¥Â§öÊ®£ÂåñÁöÑÂ∫èÂàóÔºåÈÄôÂ∞á‰øÉÈÄ≤Ë™ûÊñôÂ±§Á¥öÁöÑË≤†ËºâÂπ≥Ë°°„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÈ°çÂ§ñÁöÑÈÄöË®äÊ≠•È©üÔºå‰ª•Âú®ÂæÆÊâπÊ¨°‰πãÈñìÂêåÊ≠• $f_i$ÔºåÁÑ∂Âæå‰ΩøÁî®ÂÆÉ‰æÜË®àÁÆó LBL„ÄÇÈÄèÈÅéÂ∞çÂü∫Êñº MoE ÁöÑ LLMÔºàÁ∏ΩÂèÉÊï∏ÈáèÈ´òÈÅî $\textbf{42.8B}$Ôºå‰ª§ÁâåÈÅî $\textbf{400B}$ÔºâÁöÑË®ìÁ∑¥ÈÄ≤Ë°åÂØ¶È©óÔºåÊàëÂÄëÈ©öË®ùÂú∞ÁôºÁèæÔºåÂÖ®ÂüüÊâπÊ¨° LBL Á≠ñÁï•Âú®È†êË®ìÁ∑¥Âõ∞ÊÉëÂ∫¶Âíå‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÈÉΩÁî¢Áîü‰∫ÜÊ•µ‰Ω≥ÁöÑÊïàËÉΩÊèêÂçá„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË°®ÊòéÔºåÂÖ®ÂüüÊâπÊ¨° LBL ‰πüÂ§ßÂπÖÊèêÂçá‰∫Ü MoE Â∞àÂÆ∂ÁöÑÈ†òÂüüÂ∞àÊ•≠Âåñ„ÄÇ</paragraph>

##### **EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents**
2501.11858v1 by Zhili Cheng, Yuge Tu, Ran Li, Shiqi Dai, Jinyi Hu, Shengding Hu, Jiahao Li, Yang Shi, Tianyu Yu, Weize Chen, Lei Shi, Maosong Sun

Multimodal Large Language Models (MLLMs) have shown significant advancements,
providing a promising future for embodied agents. Existing benchmarks for
evaluating MLLMs primarily utilize static images or videos, limiting
assessments to non-interactive scenarios. Meanwhile, existing embodied AI
benchmarks are task-specific and not diverse enough, which do not adequately
evaluate the embodied capabilities of MLLMs. To address this, we propose
EmbodiedEval, a comprehensive and interactive evaluation benchmark for MLLMs
with embodied tasks. EmbodiedEval features 328 distinct tasks within 125 varied
3D scenes, each of which is rigorously selected and annotated. It covers a
broad spectrum of existing embodied AI tasks with significantly enhanced
diversity, all within a unified simulation and evaluation framework tailored
for MLLMs. The tasks are organized into five categories: navigation, object
interaction, social interaction, attribute question answering, and spatial
question answering to assess different capabilities of the agents. We evaluated
the state-of-the-art MLLMs on EmbodiedEval and found that they have a
significant shortfall compared to human level on embodied tasks. Our analysis
demonstrates the limitations of existing MLLMs in embodied capabilities,
providing insights for their future development. We open-source all evaluation
data and simulation framework at https://github.com/thunlp/EmbodiedEval.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (MMLM) Â∑≤Â±ïÁ§∫Âá∫ÊòæËëóÁöÑËøõÊ≠•Ôºå‰∏∫ÂÖ∑Ë∫´‰ª£ÁêÜÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÊúâÂ∏åÊúõÁöÑÊú™Êù•„ÄÇÁî®‰∫éËØÑ‰º∞ MMLM ÁöÑÁé∞ÊúâÂü∫ÂáÜ‰∏ªË¶ÅÂà©Áî®ÈùôÊÄÅÂõæÂÉèÊàñËßÜÈ¢ëÔºåÂ∞ÜËØÑ‰º∞ÈôêÂà∂Âú®Èùû‰∫§‰∫íÂºèÂú∫ÊôØ‰∏≠„ÄÇÂêåÊó∂ÔºåÁé∞ÊúâÁöÑÂÖ∑Ë∫´ AI Âü∫ÂáÜÊòØÁâπÂÆö‰∫é‰ªªÂä°ÁöÑÔºåÂπ∂‰∏î‰∏çÂ§üÂ§öÊ†∑ÂåñÔºåÊó†Ê≥ïÂÖÖÂàÜËØÑ‰º∞ MLLM ÁöÑÂÖ∑Ë∫´ËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü EmbodiedEvalÔºå‰∏Ä‰∏™ÈíàÂØπÂÖ∑ÊúâÂÖ∑Ë∫´‰ªªÂä°ÁöÑ MLLM ÁöÑÂÖ®Èù¢‰∏î‰∫§‰∫íÂºèÁöÑËØÑ‰º∞Âü∫ÂáÜ„ÄÇEmbodiedEval Âú® 125 ‰∏™‰∏çÂêåÁöÑ 3D Âú∫ÊôØ‰∏≠Êèê‰æõ‰∫Ü 328 ‰∏™‰∏çÂêåÁöÑ‰ªªÂä°ÔºåÊØè‰∏™‰ªªÂä°ÈÉΩÁªèËøá‰∏•Ê†ºÁöÑÊåëÈÄâÂíåÊ≥®Èáä„ÄÇÂÆÉÊ∂µÁõñ‰∫ÜÁé∞ÊúâÁöÑÂÖ∑Ë∫´ AI ‰ªªÂä°ÁöÑÂπøÊ≥õËåÉÂõ¥ÔºåÂπ∂ÊòæËëóÊèêÈ´ò‰∫ÜÂ§öÊ†∑ÊÄßÔºåÊâÄÊúâËøô‰∫õÈÉΩÂú®‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ®°ÊãüÂíåËØÑ‰º∞Ê°ÜÊû∂‰∏≠ÔºåËØ•Ê°ÜÊû∂‰∏ì‰∏∫ MLLM ÈáèË∫´ÂÆöÂà∂„ÄÇËøô‰∫õ‰ªªÂä°Ë¢´ÁªÑÁªáÊàê‰∫î‰∏™Á±ªÂà´ÔºöÂØºËà™„ÄÅÂØπË±°‰∫§‰∫í„ÄÅÁ§æ‰∫§‰∫§‰∫í„ÄÅÂ±ûÊÄßÈóÆÈ¢òËß£Á≠îÂíåÁ©∫Èó¥ÈóÆÈ¢òËß£Á≠îÔºå‰ª•ËØÑ‰º∞‰ª£ÁêÜÁöÑ‰∏çÂêåËÉΩÂäõ„ÄÇÊàë‰ª¨ËØÑ‰º∞‰∫Ü EmbodiedEval ‰∏äÊúÄÂÖàËøõÁöÑ MLLMÔºåÂèëÁé∞‰∏é‰∫∫Á±ªÂú®ÂÖ∑Ë∫´‰ªªÂä°‰∏äÁöÑÊ∞¥Âπ≥Áõ∏ÊØîÔºåÂÆÉ‰ª¨ÊúâÂæàÂ§ßÁöÑ‰∏çË∂≥„ÄÇÊàë‰ª¨ÁöÑÂàÜÊûêÂ±ïÁ§∫‰∫ÜÁé∞Êúâ MLLM Âú®ÂÖ∑Ë∫´ËÉΩÂäõÊñπÈù¢ÁöÑÂ±ÄÈôêÊÄßÔºå‰∏∫ÂÖ∂Êú™Êù•ÁöÑÂèëÂ±ïÊèê‰æõ‰∫ÜËßÅËß£„ÄÇÊàë‰ª¨Âú® https://github.com/thunlp/EmbodiedEval ‰∏äÂºÄÊ∫ê‰∫ÜÊâÄÊúâËØÑ‰º∞Êï∞ÊçÆÂíåÊ®°ÊãüÊ°ÜÊû∂„ÄÇ

##### **Cross-Entropy Attacks to Language Models via Rare Event Simulation**
2501.11852v1 by Mingze Ni, Yongshun Gong, Wei Liu

Black-box textual adversarial attacks are challenging due to the lack of
model information and the discrete, non-differentiable nature of text. Existing
methods often lack versatility for attacking different models, suffer from
limited attacking performance due to the inefficient optimization with word
saliency ranking, and frequently sacrifice semantic integrity to achieve better
attack outcomes. This paper introduces a novel approach to textual adversarial
attacks, which we call Cross-Entropy Attacks (CEA), that uses Cross-Entropy
optimization to address the above issues. Our CEA approach defines adversarial
objectives for both soft-label and hard-label settings and employs CE
optimization to identify optimal replacements. Through extensive experiments on
document classification and language translation problems, we demonstrate that
our attack method excels in terms of attacking performance, imperceptibility,
and sentence quality.

ÊëòË¶ÅÔºöÈªëÁõíÊñáÊú¨ÂØπÊäóÊîªÊìäÁî±ÊñºÁº∫‰πèÊ®°ÂûãË≥áË®ä‰ª•ÂèäÊñáÂ≠óÁöÑÈõ¢Êï£„ÄÅ‰∏çÂèØÂæÆÂàÜÁöÑÁâπÊÄßÔºåÂõ†Ê≠§ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏Áº∫‰πèÊîªÊìä‰∏çÂêåÊ®°ÂûãÁöÑÂ§öÂäüËÉΩÊÄßÔºåÁî±Êñº‰ΩøÁî®Â≠óË©ûÈ°ØËëóÊÄßÊéíÂêçËÄåÂ∞éËá¥ÊîªÊìäÊïàËÉΩÊúâÈôêÔºå‰∏îÁ∂ìÂ∏∏ÁäßÁâ≤Ë™ûÊÑèÂÆåÊï¥ÊÄß‰ª•ÈÅîÊàêÊõ¥Â•ΩÁöÑÊîªÊìäÁµêÊûú„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñáÊú¨Â∞çÊäóÊîªÊìäÊñπÊ≥ïÔºåÊàëÂÄëÁ®±‰πãÁÇ∫‰∫§ÂèâÁÜµÊîªÊìä (CEA)ÔºåÂÆÉ‰ΩøÁî®‰∫§ÂèâÁÜµÊúÄ‰Ω≥Âåñ‰æÜËß£Ê±∫‰∏äËø∞ÂïèÈ°å„ÄÇÊàëÂÄëÁöÑ CEA ÊñπÊ≥ïÂÆöÁæ©‰∫ÜËªüÊ®ôÁ±§ÂíåÁ°¨Ê®ôÁ±§Ë®≠ÂÆöÁöÑÂ∞çÊäóÁõÆÊ®ôÔºå‰∏¶Êé°Áî® CE ÊúÄ‰Ω≥Âåñ‰æÜË≠òÂà•ÊúÄ‰Ω≥ÊõøÊèõ„ÄÇÈÄèÈÅéÊñá‰ª∂ÂàÜÈ°ûÂíåË™ûË®ÄÁøªË≠ØÂïèÈ°åÁöÑÂª£Ê≥õÂØ¶È©óÔºåÊàëÂÄëË≠âÊòéÊàëÂÄëÁöÑÊîªÊìäÊñπÊ≥ïÂú®ÊîªÊìäÊïàËÉΩ„ÄÅÈõ£‰ª•ÂØüË¶∫ÊÄßÂíåÂè•Â≠êÂìÅË≥™ÊñπÈù¢Ë°®ÁèæÂÑ™Áï∞„ÄÇ

##### **Challenges in Expanding Portuguese Resources: A View from Open Information Extraction**
2501.11851v1 by Marlo Souza, Bruno Cabral, Daniela Claro, Lais Salvador

Open Information Extraction (Open IE) is the task of extracting structured
information from textual documents, independent of domain. While traditional
Open IE methods were based on unsupervised approaches, recently, with the
emergence of robust annotated datasets, new data-based approaches have been
developed to achieve better results. These innovations, however, have focused
mainly on the English language due to a lack of datasets and the difficulty of
constructing such resources for other languages. In this work, we present a
high-quality manually annotated corpus for Open Information Extraction in the
Portuguese language, based on a rigorous methodology grounded in established
semantic theories. We discuss the challenges encountered in the annotation
process, propose a set of structural and contextual annotation rules, and
validate our corpus by evaluating the performance of state-of-the-art Open IE
systems. Our resource addresses the lack of datasets for Open IE in Portuguese
and can support the development and evaluation of new methods and systems in
this area.

ÊëòË¶ÅÔºöÈñãÊîæÂºèË≥áË®äËêÉÂèñÔºàOpen IEÔºâÊòØ‰∏ÄÈ†ÖÂæûÊñáÊú¨Êñá‰ª∂‰∏≠ËêÉÂèñÂá∫ÁµêÊßãÂåñË≥áË®äÁöÑ‰ªªÂãôÔºåËàáÈ†òÂüüÁÑ°Èóú„ÄÇÈõñÁÑ∂ÂÇ≥Áµ±ÁöÑÈñãÊîæÂºèË≥áË®äËêÉÂèñÊñπÊ≥ïÊòØÂü∫ÊñºÈùûÁõ£Áù£ÂºèÊñπÊ≥ïÔºå‰ΩÜÊúÄËøëÔºåÈö®ËëóÂº∑ÂÅ•Ê®ôË®ªË≥áÊñôÈõÜÁöÑÂá∫ÁèæÔºåÊñ∞ÁöÑË≥áÊñôÈ©ÖÂãïÊñπÊ≥ïÂ∑≤Ë¢´ÈñãÁôºÂá∫‰æÜ‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂâµÊñ∞‰∏ªË¶ÅÈõÜ‰∏≠Âú®Ëã±Ë™û‰∏äÔºåÂõ†ÁÇ∫Áº∫‰πèË≥áÊñôÈõÜÂíåÂª∫ÊßãÊ≠§È°ûË≥áÊ∫êÁöÑÂõ∞Èõ£ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂö¥Ë¨πÊñπÊ≥ïÂ≠∏ÔºàÊ†πÊ§çÊñºÂ∑≤Âª∫Á´ãÁöÑË™ûÁæ©ÁêÜË´ñÔºâÁöÑÈ´òÂìÅË≥™ÊâãÂãïÊ®ôË®ªË™ûÊñôÂ∫´ÔºåÁî®ÊñºËë°ËêÑÁâôË™ûÁöÑÈñãÊîæÂºèË≥áË®äËêÉÂèñ„ÄÇÊàëÂÄëË®éË´ñÊ®ôË®ªÈÅéÁ®ã‰∏≠ÈÅáÂà∞ÁöÑÊåëÊà∞ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁµÑÁµêÊßãÂåñÂíåËÑàÁµ°Ê®ôË®ªË¶èÂâáÔºå‰∏¶ÈÄèÈÅéË©ï‰º∞ÊúÄÂÖàÈÄ≤ÁöÑÈñãÊîæÂºèË≥áË®äËêÉÂèñÁ≥ªÁµ±ÁöÑÊïàËÉΩ‰æÜÈ©óË≠âÊàëÂÄëÁöÑË™ûÊñôÂ∫´„ÄÇÊàëÂÄëÁöÑË≥áÊ∫êËß£Ê±∫‰∫ÜËë°ËêÑÁâôË™ûÈñãÊîæÂºèË≥áË®äËêÉÂèñÁº∫‰πèË≥áÊñôÈõÜÁöÑÂïèÈ°åÔºå‰∏¶ÂèØ‰ª•ÊîØÊè¥Ê≠§È†òÂüü‰∏≠Êñ∞ÊñπÊ≥ïÂíåÁ≥ªÁµ±ÁöÑÈñãÁôºÂíåË©ï‰º∞„ÄÇ

##### **Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**
2501.11849v1 by Nikos Kanakaris, Heng Ping, Xiongye Xiao, Nesreen K. Ahmed, Luca Luceri, Emilio Ferrara, Paul Bogdan

Detecting organized political campaigns is of paramount importance in
fighting against disinformation on social media. Existing approaches for the
identification of such organized actions employ techniques mostly from network
science, graph machine learning and natural language processing. Their ultimate
goal is to analyze the relationships and interactions (e.g. re-posting) among
users and the textual similarities of their posts. Despite their effectiveness
in recognizing astroturf campaigns, these methods face significant challenges,
notably the class imbalance in available training datasets. To mitigate this
issue, recent methods usually resort to data augmentation or increasing the
number of positive samples, which may not always be feasible or sufficient in
real-world settings. Following a different path, in this paper, we propose a
novel framework for identifying astroturf campaigns based solely on large
language models (LLMs), introducing a Balanced Retrieval-Augmented Generation
(Balanced RAG) component. Our approach first gives both textual information
concerning the posts (in our case tweets) and the user interactions of the
social network as input to a language model. Then, through prompt engineering
and the proposed Balanced RAG method, it effectively detects coordinated
disinformation campaigns on X (Twitter). The proposed framework does not
require any training or fine-tuning of the language model. Instead, by
strategically harnessing the strengths of prompt engineering and Balanced RAG,
it facilitates LLMs to overcome the effects of class imbalance and effectively
identify coordinated political campaigns. The experimental results demonstrate
that by incorporating the proposed prompt engineering and Balanced RAG methods,
our framework outperforms the traditional graph-based baselines, achieving
2x-3x improvements in terms of precision, recall and F1 scores.

ÊëòË¶ÅÔºö<paragraph>Âú®Á§æ‰∫§Â™íÈ´î‰∏äÊâìÊìäÈåØË™§Ë≥áË®äÔºåÂÅµÊ∏¨ÊúâÁµÑÁπîÁöÑÊîøÊ≤ªÂÆ£ÂÇ≥Ëá≥ÈóúÈáçË¶Å„ÄÇÁèæÊúâÁöÑÊ≠§È°ûÊúâÁµÑÁπîË°åÂãïË≠òÂà•ÊñπÊ≥ïÔºå‰∏ªË¶ÅÊé°Áî®Á∂≤Ë∑ØÁßëÂ≠∏„ÄÅÂúñÂΩ¢Ê©üÂô®Â≠∏ÁøíÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÊäÄË°ì„ÄÇÂÖ∂ÊúÄÁµÇÁõÆÊ®ôÊòØÂàÜÊûê‰ΩøÁî®ËÄÖ‰πãÈñìÁöÑÈóú‰øÇÂíå‰∫íÂãïÔºà‰æãÂ¶ÇËΩâÁôºÔºâÔºå‰ª•ÂèäÂÖ∂Ë≤ºÊñáÁöÑÊñáÂ≠óÁõ∏‰ººÂ∫¶„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊñπÊ≥ïÂú®Ëæ®Ë≠òÂÅáËçâÊ†πÈÅãÂãïÂÆ£ÂÇ≥‰∏äÂæàÊúâÊïàÔºå‰ΩÜ‰ªçÈù¢Ëá®ÈáçÂ§ßÊåëÊà∞ÔºåÁâπÂà•ÊòØÂèØÁî®Ë®ìÁ∑¥Ë≥áÊñôÈõÜ‰∏≠ÁöÑÈ°ûÂà•‰∏çÂπ≥Ë°°„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄôÂÄãÂïèÈ°åÔºåÊúÄËøëÁöÑÊñπÊ≥ïÈÄöÂ∏∏Ë®¥Ë´∏ÊñºË≥áÊñôÊì¥ÂÖÖÊàñÂ¢ûÂä†Ê≠£ÂêëÊ®£Êú¨Êï∏ÈáèÔºå‰ΩÜÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÔºåÈÄô‰∏¶‰∏çÁ∏ΩÊòØÂèØË°åÊàñË∂≥Â§†ÁöÑ„ÄÇÊú¨ÊñáÊé°Ë°å‰∏çÂêåÁöÑÈÄîÂæëÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñ∞ÂûãÊ°ÜÊû∂ÔºåÁî®ÊñºË≠òÂà•ÂÅáËçâÊ†πÈÅãÂãïÂÆ£ÂÇ≥Ôºå‰∏¶ÂºïÂÖ•Âπ≥Ë°°Ê™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (Balanced RAG) ÂÖÉ‰ª∂„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÂ∞áÊúâÈóúË≤ºÊñáÔºàÂú®Êú¨‰æã‰∏≠ÁÇ∫Êé®ÊñáÔºâÁöÑÊñáÂ≠óË≥áË®äÂíåÁ§æ‰∫§Á∂≤Ë∑ØÁöÑ‰ΩøÁî®ËÄÖ‰∫íÂãï‰ΩúÁÇ∫Ëº∏ÂÖ•ÔºåÊèê‰æõÁµ¶Ë™ûË®ÄÊ®°Âûã„ÄÇÁÑ∂ÂæåÔºåÈÄèÈÅéÊèêÁ§∫Â∑•Á®ãÂíåÊèêÂá∫ÁöÑÂπ≥Ë°°Ê™¢Á¥¢Êì¥ÂÖÖÁîüÊàêÊñπÊ≥ïÔºåÂÆÉÊúâÊïàÂú∞ÂÅµÊ∏¨ X (Twitter) ‰∏äÂçîË™øÁöÑÈåØË™§Ë≥áË®äÂÆ£ÂÇ≥„ÄÇÊèêÂá∫ÁöÑÊ°ÜÊû∂‰∏çÈúÄË¶Å‰ªª‰ΩïË™ûË®ÄÊ®°ÂûãÁöÑË®ìÁ∑¥ÊàñÂæÆË™ø„ÄÇÁõ∏ÂèçÂú∞ÔºåÈÄèÈÅéÁ≠ñÁï•ÊÄßÂú∞Âà©Áî®ÊèêÁ§∫Â∑•Á®ãÂíåÂπ≥Ë°°Ê™¢Á¥¢Êì¥ÂÖÖÁîüÊàêÁöÑÂÑ™Âã¢ÔºåÂÆÉËÉΩËÆìÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂÖãÊúçÈ°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÂΩ±ÈüøÔºå‰∏¶ÊúâÊïàË≠òÂà•ÂçîË™øÁöÑÊîøÊ≤ªÂÆ£ÂÇ≥„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÈÄèÈÅéÊï¥ÂêàÊèêÂá∫ÁöÑÊèêÁ§∫Â∑•Á®ãÂíåÂπ≥Ë°°Ê™¢Á¥¢Êì¥ÂÖÖÁîüÊàêÊñπÊ≥ïÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂ÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÂü∫ÊñºÂúñÂΩ¢ÁöÑÂü∫Ê∫ñÔºåÂú®Á≤æÊ∫ñÂ∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏ÊñπÈù¢Áç≤Âæó 2x-3x ÁöÑÊèêÂçá„ÄÇ</paragraph>

##### **A Survey on Memory-Efficient Large-Scale Model Training in AI for Science**
2501.11847v1 by Kaiyuan Tian, Linbo Qiao, Baihui Liu, Gongqingjian Jiang, Dongsheng Li

Scientific research faces high costs and inefficiencies with traditional
methods, but the rise of deep learning and large language models (LLMs) offers
innovative solutions. This survey reviews LLM applications across scientific
fields such as biology, medicine, chemistry, and meteorology, underscoring
their role in advancing research. However, the continuous expansion of model
size has led to significant memory demands, hindering further development and
application of LLMs for science. To address this, we review memory-efficient
training techniques for LLMs based on the transformer architecture, including
distributed training, mixed precision training, and gradient checkpointing.
Using AlphaFold 2 as an example, we demonstrate how tailored memory
optimization methods can reduce storage needs while preserving prediction
accuracy. We also discuss the challenges of memory optimization in practice and
potential future directions, hoping to provide valuable insights for
researchers and engineers.

ÊëòË¶ÅÔºöÁßëÂ≠∏Á†îÁ©∂Èù¢Ëá®ÂÇ≥Áµ±ÊñπÊ≥ïÁöÑÈ´òÊàêÊú¨Âíå‰ΩéÊïàÁéáÔºå‰ΩÜÊ∑±Â∫¶Â≠∏ÁøíÂíåÂ§ßË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËààËµ∑Êèê‰æõ‰∫ÜÂâµÊñ∞ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊ≠§Ë™øÊü•ÂõûÈ°ß‰∫Ü LLM Âú®ÁîüÁâ©Â≠∏„ÄÅÈÜ´Â≠∏„ÄÅÂåñÂ≠∏ÂíåÊ∞£Ë±°Â≠∏Á≠âÁßëÂ≠∏È†òÂüüÁöÑÊáâÁî®ÔºåÂº∑Ë™øÂÆÉÂÄëÂú®Êé®ÈÄ≤Á†îÁ©∂‰∏≠ÁöÑ‰ΩúÁî®„ÄÇÁÑ∂ËÄåÔºåÊ®°ÂûãË¶èÊ®°ÁöÑÊåÅÁ∫åÊì¥Â±ïÂ∞éËá¥‰∫ÜÈ°ØËëóÁöÑË®òÊÜ∂È´îÈúÄÊ±ÇÔºåÈòªÁ§ô‰∫Ü LLM Âú®ÁßëÂ≠∏È†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•ÈñãÁôºÂíåÊáâÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂõûÈ°ß‰∫ÜÂü∫ÊñºTransformerÊû∂ÊßãÁöÑ LLM ÁöÑË®òÊÜ∂È´îÈ´òÊïàË®ìÁ∑¥ÊäÄË°ìÔºåÂåÖÊã¨ÂàÜ‰ΩàÂºèË®ìÁ∑¥„ÄÅÊ∑∑ÂêàÁ≤æÂ∫¶Ë®ìÁ∑¥ÂíåÊ¢ØÂ∫¶Ê™¢Êü•Èªû„ÄÇ‰ª• AlphaFold 2 ÁÇ∫‰æãÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈáèË∫´ÂÆöÂà∂ÁöÑË®òÊÜ∂È´îÂÑ™ÂåñÊñπÊ≥ïÂ¶Ç‰ΩïÂú®‰øùÊåÅÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÁöÑÂêåÊôÇÊ∏õÂ∞ëÂÑ≤Â≠òÈúÄÊ±Ç„ÄÇÊàëÂÄëÈÇÑË®éË´ñ‰∫ÜË®òÊÜ∂È´îÂÑ™ÂåñÂú®ÂØ¶Âãô‰∏≠ÁöÑÊåëÊà∞ÂíåÊΩõÂú®ÁöÑÊú™‰æÜÊñπÂêëÔºåÂ∏åÊúõËÉΩÁÇ∫Á†îÁ©∂‰∫∫Âì°ÂíåÂ∑•Á®ãÂ∏´Êèê‰æõÊúâÂÉπÂÄºÁöÑË¶ãËß£„ÄÇ

##### **Supervised Learning for Analog and RF Circuit Design: Benchmarks and Comparative Insights**
2501.11839v1 by Asal Mehradfar, Xuzhe Zhao, Yue Niu, Sara Babakniya, Mahdi Alesheikh, Hamidreza Aghasi, Salman Avestimehr

Automating analog and radio-frequency (RF) circuit design using machine
learning (ML) significantly reduces the time and effort required for parameter
optimization. This study explores supervised ML-based approaches for designing
circuit parameters from performance specifications across various circuit
types, including homogeneous and heterogeneous designs. By evaluating diverse
ML models, from neural networks like transformers to traditional methods like
random forests, we identify the best-performing models for each circuit. Our
results show that simpler circuits, such as low-noise amplifiers, achieve
exceptional accuracy with mean relative errors as low as 0.3% due to their
linear parameter-performance relationships. In contrast, complex circuits, like
power amplifiers and voltage-controlled oscillators, present challenges due to
their non-linear interactions and larger design spaces. For heterogeneous
circuits, our approach achieves an 88% reduction in errors with increased
training data, with the receiver achieving a mean relative error as low as
0.23%, showcasing the scalability and accuracy of the proposed methodology.
Additionally, we provide insights into model strengths, with transformers
excelling in capturing non-linear mappings and k-nearest neighbors performing
robustly in moderately linear parameter spaces, especially in heterogeneous
circuits with larger datasets. This work establishes a foundation for extending
ML-driven design automation, enabling more efficient and scalable circuit
design workflows.

ÊëòË¶ÅÔºöÂà©Áî®Ê©üÂô®Â≠∏Áøí (ML) Ëá™ÂãïÂåñÈ°ûÊØîÂíåÂ∞ÑÈ†ª (RF) ÈõªË∑ØË®≠Ë®àÔºåÂèØÂ§ßÂπÖÊ∏õÂ∞ëÂèÉÊï∏ÊúÄ‰Ω≥ÂåñÊâÄÈúÄÁöÑÊôÇÈñìÂíåÁ≤æÂäõ„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂü∫ÊñºÁõ£Áù£Âºè ML ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÊ†πÊìöÂêÑÁ®ÆÈõªË∑ØÈ°ûÂûãÔºàÂåÖÊã¨ÂêåË≥™ÂíåÁï∞Ë≥™Ë®≠Ë®àÔºâÁöÑÊïàËÉΩË¶èÊ†ºË®≠Ë®àÈõªË∑ØÂèÉÊï∏„ÄÇÈÄèÈÅéË©ï‰º∞ÂêÑÁ®Æ ML Ê®°ÂûãÔºàÂæûTransformerÁ≠âÁ•ûÁ∂ìÁ∂≤Ë∑ØÂà∞Èö®Ê©üÊ£ÆÊûóÁ≠âÂÇ≥Áµ±ÊñπÊ≥ïÔºâÔºåÊàëÂÄëÊâæÂá∫ÊØèÁ®ÆÈõªË∑ØÁöÑÊúÄ‰Ω≥ÊïàËÉΩÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåËºÉÁ∞°ÂñÆÁöÑÈõªË∑ØÔºà‰æãÂ¶Ç‰ΩéÈõúË®äÊîæÂ§ßÂô®ÔºâÁî±ÊñºÂÖ∂Á∑öÊÄßÂèÉÊï∏ÊïàËÉΩÈóú‰øÇÔºåÂèØÈÅîÂà∞Ê•µÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂπ≥ÂùáÁõ∏Â∞çË™§Â∑Æ‰ΩéËá≥ 0.3%„ÄÇÁõ∏ÂèçÂú∞ÔºåË§áÈõúÈõªË∑ØÔºà‰æãÂ¶ÇÂäüÁéáÊîæÂ§ßÂô®ÂíåÈõªÂ£ìÊéßÂà∂ÊåØÁõ™Âô®ÔºâÁî±ÊñºÂÖ∂ÈùûÁ∑öÊÄß‰∫§‰∫í‰ΩúÁî®ÂíåËºÉÂ§ßÁöÑË®≠Ë®àÁ©∫ÈñìÔºåÂõ†Ê≠§ÊúÉÂ∏∂‰æÜÊåëÊà∞„ÄÇÂ∞çÊñºÁï∞Ë≥™ÈõªË∑ØÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØÊ∏õÂ∞ë 88% ÁöÑË™§Â∑ÆÔºå‰∏¶Â¢ûÂä†Ë®ìÁ∑¥Ë≥áÊñôÔºåÊé•Êî∂Âô®ÂèØÈÅîÂà∞‰ΩéËá≥ 0.23% ÁöÑÂπ≥ÂùáÁõ∏Â∞çË™§Â∑ÆÔºåÂ±ïÁ§∫‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÂèØÊì¥ÂÖÖÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõÊ®°ÂûãÂÑ™Âã¢ÁöÑË¶ãËß£ÔºåÂÖ∂‰∏≠TransformerÂú®ÊçïÊçâÈùûÁ∑öÊÄßÂ∞çÊáâÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºåËÄå k ÊúÄËøëÈÑ∞Âú®ÈÅ©Â∫¶Á∑öÊÄßÂèÉÊï∏Á©∫Èñì‰∏≠Ë°®ÁèæÂº∑ÂÅ•ÔºåÁâπÂà•ÊòØÂú®ÂÖ∑ÊúâËºÉÂ§ßË≥áÊñôÈõÜÁöÑÁï∞Ë≥™ÈõªË∑Ø‰∏≠„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂª∫Á´ã‰∫ÜÊì¥Â±ï ML È©ÖÂãïÁöÑË®≠Ë®àËá™ÂãïÂåñÁöÑÂü∫Á§éÔºåÈÄ≤ËÄåÂØ¶ÁèæÊõ¥ÊúâÊïàÁéá‰∏îÂèØÊì¥ÂÖÖÁöÑÈõªË∑ØË®≠Ë®àÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ

##### **Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**
2501.11836v1 by Saeid Ataei, Saeed Adibnazari, Seyyed Taghi Ataei

Structural integrity is vital for maintaining the safety and longevity of
concrete infrastructures such as bridges, tunnels, and walls. Traditional
methods for detecting damages like cracks and spalls are labor-intensive,
time-consuming, and prone to human error. To address these challenges, this
study explores advanced data-driven techniques using deep learning for
automated damage detection and analysis. Two state-of-the-art instance
segmentation models, YOLO-v7 instance segmentation and Mask R-CNN, were
evaluated using a dataset comprising 400 images, augmented to 10,995 images
through geometric and color-based transformations to enhance robustness. The
models were trained and validated using a dataset split into 90% training set,
validation and test set 10%. Performance metrics such as precision, recall,
mean average precision (mAP@0.5), and frames per second (FPS) were used for
evaluation. YOLO-v7 achieved a superior mAP@0.5 of 96.1% and processed 40 FPS,
outperforming Mask R-CNN, which achieved a mAP@0.5 of 92.1% with a slower
processing speed of 18 FPS. The findings recommend YOLO-v7 instance
segmentation model for real-time, high-speed structural health monitoring,
while Mask R-CNN is better suited for detailed offline assessments. This study
demonstrates the potential of deep learning to revolutionize infrastructure
maintenance, offering a scalable and efficient solution for automated damage
detection.

ÊëòË¶ÅÔºöÁµêÊßãÂÆåÊï¥ÊÄßÂ∞çÊñºÁ∂≠Ë≠∑Ê©ãÊ®ë„ÄÅÈößÈÅìÂíåÁâÜÂ£ÅÁ≠âÊ∑∑ÂáùÂúüÂü∫Á§éË®≠ÊñΩÁöÑÂÆâÂÖ®ÊÄßÂíå‰ΩøÁî®Â£ΩÂëΩËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑÊêçÂ£ûÊ™¢Ê∏¨ÊñπÊ≥ïÔºå‰æãÂ¶ÇË£ÇÁ∏´ÂíåÂâùËêΩÔºåÈúÄË¶ÅÂ§ßÈáè‰∫∫Â∑•ÔºåËÄóÊôÇ‰∏îÂÆπÊòìÂá∫Áèæ‰∫∫ÁÇ∫ÈåØË™§„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÁöÑÂÖàÈÄ≤Êï∏ÊìöÈ©ÖÂãïÊäÄË°ìÔºåÁî®ÊñºËá™ÂãïÊêçÂ£ûÊ™¢Ê∏¨ÂíåÂàÜÊûê„ÄÇ‰ΩøÁî®ÂåÖÂê´ 400 ÂºµÂúñÂÉèÁöÑÊï∏ÊìöÈõÜË©ï‰º∞‰∫ÜÂÖ©ÂÄãÊúÄÂÖàÈÄ≤ÁöÑÂØ¶‰æãÂàÜÂâ≤Ê®°ÂûãÔºåYOLO-v7 ÂØ¶‰æãÂàÜÂâ≤Âíå Mask R-CNNÔºåÈÄöÈÅéÂπæ‰ΩïÂíåÂü∫ÊñºÈ°èËâ≤ÁöÑËΩâÊèõÊì¥Â±ïÂà∞ 10,995 ÂºµÂúñÂÉèÔºå‰ª•Â¢ûÂº∑È≠ØÊ£íÊÄß„ÄÇ‰ΩøÁî®ÂàÜÁÇ∫ 90% Ë®ìÁ∑¥ÈõÜ„ÄÅÈ©óË≠âÂíåÊ∏¨Ë©¶ÈõÜ 10% ÁöÑÊï∏ÊìöÈõÜË®ìÁ∑¥ÂíåÈ©óË≠âÊ®°Âûã„ÄÇ‰ΩøÁî®Á≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéá„ÄÅÂπ≥ÂùáÂπ≥ÂùáÁ≤æÁ¢∫Â∫¶ (mAP@0.5) ÂíåÊØèÁßíÂπÄÊï∏ (FPS) Á≠âÊÄßËÉΩÊåáÊ®ôÈÄ≤Ë°åË©ï‰º∞„ÄÇYOLO-v7 ÈÅîÂà∞‰∫Ü 96.1% ÁöÑÂÑ™Áï∞ mAP@0.5Ôºå‰∏¶ËôïÁêÜ‰∫Ü 40 FPSÔºåÂÑ™Êñº Mask R-CNNÔºåÂæåËÄÖ‰ª• 18 FPS ÁöÑËºÉÊÖ¢ËôïÁêÜÈÄüÂ∫¶ÈÅîÂà∞‰∫Ü 92.1% ÁöÑ mAP@0.5„ÄÇÁ†îÁ©∂ÁµêÊûúÊé®Ëñ¶‰ΩøÁî® YOLO-v7 ÂØ¶‰æãÂàÜÂâ≤Ê®°ÂûãÈÄ≤Ë°åÂØ¶ÊôÇ„ÄÅÈ´òÈÄüÁµêÊßãÂÅ•Â∫∑Áõ£Ê∏¨ÔºåËÄå Mask R-CNN Êõ¥ÈÅ©ÂêàË©≥Á¥∞ÁöÑÈõ¢Á∑öË©ï‰º∞„ÄÇÊú¨Á†îÁ©∂Â±ïÁ§∫‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÂú®Âü∫Á§éË®≠ÊñΩÁ∂≠Ë≠∑ÊñπÈù¢ÂÖ∑ÊúâÈù©ÂëΩÊÄßÁöÑÊΩõÂäõÔºåÁÇ∫Ëá™ÂãïÊêçÂ£ûÊ™¢Ê∏¨Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥Â±ï‰∏îÈ´òÊïàÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Is your LLM trapped in a Mental Set? Investigative study on how mental sets affect the reasoning capabilities of LLMs**
2501.11833v1 by Saiful Haq, Niyati Chhaya, Piyush Pandey, Pushpak Bhattacharya

In this paper, we present an investigative study on how Mental Sets influence
the reasoning capabilities of LLMs. LLMs have excelled in diverse natural
language processing (NLP) tasks, driven by advancements in parameter-efficient
fine-tuning (PEFT) and emergent capabilities like in-context learning (ICL).
For complex reasoning tasks, selecting the right model for PEFT or ICL is
critical, often relying on scores on benchmarks such as MMLU, MATH, and GSM8K.
However, current evaluation methods, based on metrics like F1 Score or
reasoning chain assessments by larger models, overlook a key dimension:
adaptability to unfamiliar situations and overcoming entrenched thinking
patterns. In cognitive psychology, Mental Set refers to the tendency to persist
with previously successful strategies, even when they become inefficient - a
challenge for problem solving and reasoning. We compare the performance of LLM
models like Llama-3.1-8B-Instruct, Llama-3.1-70B-Instruct and GPT-4o in the
presence of mental sets. To the best of our knowledge, this is the first study
to integrate cognitive psychology concepts into the evaluation of LLMs for
complex reasoning tasks, providing deeper insights into their adaptability and
problem-solving efficacy.

ÊëòË¶ÅÔºö<paragraph>Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖË™øÊü•Á†îÁ©∂ÔºåÊé¢Ë®éÂøÉÊô∫ÂÆöÂã¢Â¶Ç‰ΩïÂΩ±Èüø LLM ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇLLM Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤ÔºåÈÄôÊ≠∏ÂäüÊñºÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) ÂíåÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) Á≠âÊñ∞ËààËÉΩÂäõÁöÑÈÄ≤Ê≠•„ÄÇÂ∞çÊñºË§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãôÔºåÈÅ∏ÊìáÈÅ©Áï∂ÁöÑ PEFT Êàñ ICL Ê®°ÂûãËá≥ÈóúÈáçË¶ÅÔºåÈÄôÈÄöÂ∏∏‰æùË≥¥Êñº MMLU„ÄÅMATH Âíå GSM8K Á≠âÂü∫Ê∫ñ‰∏äÁöÑÂàÜÊï∏„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂâçÁöÑË©ï‰º∞ÊñπÊ≥ïÂü∫Êñº F1 ÂàÜÊï∏ÊàñÂ§ßÂûãÊ®°ÂûãÁöÑÊé®ÁêÜÈèàË©ï‰º∞Á≠âÊåáÊ®ôÔºåÂçªÂøΩÁï•‰∫Ü‰∏ÄÂÄãÈóúÈçµÈù¢ÂêëÔºöÈÅ©Êáâ‰∏çÁÜüÊÇâÁöÑÊÉÖÊ≥ÅÂíåÂÖãÊúçÊ†πÊ∑±ËíÇÂõ∫ÁöÑÊÄùÁ∂≠Ê®°Âºè„ÄÇÂú®Ë™çÁü•ÂøÉÁêÜÂ≠∏‰∏≠ÔºåÂøÉÊô∫ÂÆöÂã¢ÊòØÊåáÂç≥‰ΩøÂú®Á≠ñÁï•ËÆäÂæó‰ΩéÊïàÊôÇÔºå‰ªçÊåÅÁ∫åÊé°Áî®ÂÖàÂâçÊàêÂäüÁ≠ñÁï•ÁöÑÂÇæÂêë - ÈÄôÊòØÂïèÈ°åËß£Ê±∫ÂíåÊé®ÁêÜÁöÑ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÊàëÂÄëÊØîËºÉ‰∫Ü Llama-3.1-8B-Instruct„ÄÅLlama-3.1-70B-Instruct Âíå GPT-4o Á≠â LLM Ê®°ÂûãÂú®ÂøÉÊô∫ÂÆöÂã¢Â≠òÂú®‰∏ãÁöÑË°®Áèæ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áË™çÁü•ÂøÉÁêÜÂ≠∏Ê¶ÇÂøµÊï¥ÂêàÂà∞ LLM Ë§áÈõúÊé®ÁêÜ‰ªªÂãôË©ï‰º∞‰∏≠ÁöÑÁ†îÁ©∂ÔºåÊèê‰æõ‰∫ÜÂ∞çÂÖ∂ÈÅ©ÊáâÊÄßÂíåÂïèÈ°åËß£Ê±∫ÊïàËÉΩÁöÑÊõ¥Ê∑±ÂÖ•Ë¶ãËß£„ÄÇ</paragraph>

##### **PXGen: A Post-hoc Explainable Method for Generative Models**
2501.11827v1 by Yen-Lung Huang, Ming-Hsi Weng, Hao-Tsung Yang

With the rapid growth of generative AI in numerous applications, explainable
AI (XAI) plays a crucial role in ensuring the responsible development and
deployment of generative AI technologies. XAI has undergone notable
advancements and widespread adoption in recent years, reflecting a concerted
push to enhance the transparency, interpretability, and credibility of AI
systems. Recent research emphasizes that a proficient XAI method should adhere
to a set of criteria, primarily focusing on two key areas. Firstly, it should
ensure the quality and fluidity of explanations, encompassing aspects like
faithfulness, plausibility, completeness, and tailoring to individual needs.
Secondly, the design principle of the XAI system or mechanism should cover the
following factors such as reliability, resilience, the verifiability of its
outputs, and the transparency of its algorithm. However, research in XAI for
generative models remains relatively scarce, with little exploration into how
such methods can effectively meet these criteria in that domain. In this work,
we propose PXGen, a post-hoc explainable method for generative models. Given a
model that needs to be explained, PXGen prepares two materials for the
explanation, the Anchor set and intrinsic & extrinsic criteria. Those materials
are customizable by users according to their purpose and requirements. Via the
calculation of each criterion, each anchor has a set of feature values and
PXGen provides examplebased explanation methods according to the feature values
among all the anchors and illustrated and visualized to the users via tractable
algorithms such as k-dispersion or k-center.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÁîüÊàêÂºè AI Âú®Ë®±Â§öÊáâÁî®Á®ãÂºè‰∏≠ÁöÑÂø´ÈÄüÊàêÈï∑ÔºåÂèØËß£Èáã AI (XAI) Âú®Á¢∫‰øùÁîüÊàêÂºè AI ÊäÄË°ìË≤†Ë≤¨‰ªªÂú∞ÈñãÁôºÂíåÈÉ®ÁΩ≤ÊñπÈù¢ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇXAI Âú®ËøëÂπ¥‰æÜÁ∂ìÊ≠∑‰∫ÜÈ°ØËëóÁöÑÈÄ≤Â±ïÂíåÂª£Ê≥õÁöÑÊé°Áî®ÔºåÂèçÊò†Âá∫ÂçîË™ø‰∏ÄËá¥Âú∞Êé®ÂãïÂ¢ûÂº∑ AI Á≥ªÁµ±ÁöÑÈÄèÊòéÊÄß„ÄÅÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Âº∑Ë™øÔºå‰∏ÄÁ®ÆÁÜüÁ∑¥ÁöÑ XAI ÊñπÊ≥ïÊáâÈÅµÂæ™‰∏ÄÁµÑÊ®ôÊ∫ñÔºå‰∏ªË¶ÅÈóúÊ≥®ÊñºÂÖ©ÂÄãÈóúÈçµÈ†òÂüü„ÄÇÈ¶ñÂÖàÔºåÂÆÉÊáâÁ¢∫‰øùËß£ÈáãÁöÑÂìÅË≥™ÂíåÊµÅÊö¢Â∫¶ÔºåÂåÖÂê´Âø†ÂØ¶Â∫¶„ÄÅÂêàÁêÜÊÄß„ÄÅÂÆåÊï¥ÊÄßÂíåÈáùÂ∞çÂÄãÂà•ÈúÄÊ±ÇÈÄ≤Ë°åË™øÊï¥Á≠âÈù¢Âêë„ÄÇÂÖ∂Ê¨°ÔºåXAI Á≥ªÁµ±ÊàñÊ©üÂà∂ÁöÑË®≠Ë®àÂéüÂâáÊáâÊ∂µËìã‰ª•‰∏ãÂõ†Á¥†Ôºå‰æãÂ¶ÇÂÖ∂Ëº∏Âá∫ÁöÑÂèØÈù†ÊÄß„ÄÅÂæ©ÂéüÂäõ„ÄÅÂèØÈ©óË≠âÊÄßÔºå‰ª•ÂèäÂÖ∂ÊºîÁÆóÊ≥ïÁöÑÈÄèÊòéÊÄß„ÄÇÁÑ∂ËÄåÔºåÈáùÂ∞çÁîüÊàêÂºèÊ®°ÂûãÁöÑ XAI Á†îÁ©∂‰ªçÁÑ∂Áõ∏Â∞çÁ®ÄÂ∞ëÔºåÂ∞çÊñºÊ≠§È°ûÊñπÊ≥ïÂ¶Ç‰ΩïÊúâÊïàÊªøË∂≥Ë©≤È†òÂüü‰∏≠ÁöÑÈÄô‰∫õÊ®ôÊ∫ñÔºåÈÆÆÂ∞ëÊé¢Á¥¢„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ PXGenÔºå‰∏ÄÁ®ÆÈáùÂ∞çÁîüÊàêÂºèÊ®°ÂûãÁöÑÂæåË®≠ÂèØËß£ÈáãÊñπÊ≥ï„ÄÇÈáùÂ∞çÈúÄË¶ÅËß£ÈáãÁöÑÊ®°ÂûãÔºåPXGen Ê∫ñÂÇô‰∫ÜÈå®ÈªûÈõÜÂíåÂÖßÂú®ËàáÂ§ñÂú®Ê®ôÊ∫ñÈÄôÂÖ©Á®ÆÊùêÊñô‰æõËß£Èáã„ÄÇ‰ΩøÁî®ËÄÖÂèØ‰ª•Ê†πÊìöÂÖ∂ÁõÆÁöÑÂíåÈúÄÊ±ÇËá™Ë®ÇÈÄô‰∫õÊùêÊñô„ÄÇÈÄèÈÅéË®àÁÆóÊØèÂÄãÊ®ôÊ∫ñÔºåÊØèÂÄãÈå®ÈªûÈÉΩÊúâ‰∏ÄÁµÑÁâπÂæµÂÄºÔºåPXGen Êèê‰æõÂü∫ÊñºÁØÑ‰æãÁöÑËß£ÈáãÊñπÊ≥ïÔºåÊ†πÊìöÊâÄÊúâÈå®Èªû‰∏≠ÁöÑÁâπÂæµÂÄºÔºå‰∏¶ÈÄèÈÅéÊòìÊñºËôïÁêÜÁöÑÊºîÁÆóÊ≥ïÔºà‰æãÂ¶Ç k ÂàÜÊï£Êàñ k ‰∏≠ÂøÉÔºâÂêë‰ΩøÁî®ËÄÖË™™ÊòéÂíåË¶ñË¶∫Âåñ„ÄÇ</paragraph>

##### **Toward Scalable Graph Unlearning: A Node Influence Maximization based Approach**
2501.11823v1 by Xunkai Li, Bowen Fan, Zhengyu Wu, Zhiyu Li, Rong-Hua Li, Guoren Wang

Machine unlearning, as a pivotal technology for enhancing model robustness
and data privacy, has garnered significant attention in prevalent web mining
applications, especially in thriving graph-based scenarios. However, most
existing graph unlearning (GU) approaches face significant challenges due to
the intricate interactions among web-scale graph elements during the model
training: (1) The gradient-driven node entanglement hinders the complete
knowledge removal in response to unlearning requests; (2) The billion-level
graph elements in the web scenarios present inevitable scalability issues. To
break the above limitations, we open up a new perspective by drawing a
connection between GU and conventional social influence maximization. To this
end, we propose Node Influence Maximization (NIM) through the decoupled
influence propagation model and fine-grained influence function in a scalable
manner, which is crafted to be a plug-and-play strategy to identify potential
nodes affected by unlearning entities. This approach enables offline execution
independent of GU, allowing it to be seamlessly integrated into most GU methods
to improve their unlearning performance. Based on this, we introduce Scalable
Graph Unlearning (SGU) as a new fine-tuned framework, which balances the
forgetting and reasoning capability of the unlearned model by entity-specific
optimizations. Extensive experiments on 14 datasets, including large-scale
ogbn-papers100M, have demonstrated the effectiveness of our approach.
Specifically, NIM enhances the forgetting capability of most GU methods, while
SGU achieves comprehensive SOTA performance and maintains scalability.

ÊëòË¶ÅÔºöÊ©üÂô®ÂéªÂ≠∏ÁøíÔºå‰ΩúÁÇ∫Â¢ûÂº∑Ê®°ÂûãÁ©©ÂÅ•ÊÄßÂíåË≥áÊñôÈö±ÁßÅÁöÑÈóúÈçµÊäÄË°ìÔºåÂú®ÊôÆÈÅçÁöÑÁ∂≤Ë∑ØÊåñÊéòÊáâÁî®‰∏≠Áç≤ÂæóÈ°ØËëóÁöÑÈóúÊ≥®ÔºåÁâπÂà•ÊòØÂú®Ëì¨ÂãÉÁôºÂ±ïÁöÑÂü∫ÊñºÂúñË°®ÁöÑÂ†¥ÊôØ‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ÁèæÊúâÁöÑÂúñË°®ÂéªÂ≠∏Áøí (GU) ÊñπÊ≥ïÂú®Ê®°ÂûãË®ìÁ∑¥ÊúüÈñìÁî±ÊñºÁ∂≤Ë∑ØË¶èÊ®°ÂúñË°®ÂÖÉÁ¥†‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®ËÄåÈù¢Ëá®ÈáçÂ§ßÊåëÊà∞Ôºö(1) Ê¢ØÂ∫¶È©ÖÂãïÁöÑÁØÄÈªûÁ≥æÁ∫èÈòªÁ§ô‰∫ÜÂ∞çÂéªÂ≠∏ÁøíË´ãÊ±ÇÁöÑÂÆåÊï¥Áü•Ë≠òÂà™Èô§Ôºõ(2) Á∂≤Ë∑ØÂ†¥ÊôØ‰∏≠ÁöÑÂçÅÂÑÑÁ¥öÂúñË°®ÂÖÉÁ¥†ÊèêÂá∫‰∫Ü‰∏çÂèØÈÅøÂÖçÁöÑÂèØÊì¥ÂÖÖÊÄßÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÁ™ÅÁ†¥‰∏äËø∞ÈôêÂà∂ÔºåÊàëÂÄëÈÄöÈÅéÂú® GU ÂíåÂÇ≥Áµ±ÁöÑÁ§æÊúÉÂΩ±ÈüøÊúÄÂ§ßÂåñ‰πãÈñìÂª∫Á´ãËÅØÁπ´ÔºåÈñãÈó¢‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑË¶ñËßí„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÈÄöÈÅéËß£ËÄ¶ÁöÑÂΩ±ÈüøÂÇ≥Êí≠Ê®°ÂûãÂíåÂèØÊì¥ÂÖÖÊÄßÊñπÂºè‰∏≠ÁöÑÁ¥∞Á≤íÂ∫¶ÂΩ±ÈüøÂáΩÊï∏ÔºåÊèêÂá∫‰∫ÜÁØÄÈªûÂΩ±ÈüøÊúÄÂ§ßÂåñ (NIM)ÔºåÂÆÉË¢´Ë®≠Ë®àÁÇ∫‰∏ÄÂÄãÂç≥ÊèíÂç≥Áî®ÁöÑÁ≠ñÁï•ÔºåÁî®ÊñºË≠òÂà•ÂèóÂéªÂ≠∏ÁøíÂØ¶È´îÂΩ±ÈüøÁöÑÊΩõÂú®ÁØÄÈªû„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂÖÅË®±Èõ¢Á∑öÂü∑Ë°åÁç®Á´ãÊñº GUÔºå‰ΩøÂÖ∂ÂèØ‰ª•ÁÑ°Á∏´Êï¥ÂêàÂà∞Â§ßÂ§öÊï∏ GU ÊñπÊ≥ï‰∏≠Ôºå‰ª•ÊîπÂñÑÂÖ∂ÂéªÂ≠∏ÁøíÊïàËÉΩ„ÄÇÂü∫ÊñºÊ≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂèØÊì¥ÂÖÖÂúñË°®ÂéªÂ≠∏Áøí (SGU) ‰ΩúÁÇ∫‰∏ÄÂÄãÊñ∞ÁöÑÂæÆË™øÊ°ÜÊû∂ÔºåÂÆÉÈÄöÈÅéÂØ¶È´îÁâπÂÆöÁöÑÊúÄ‰Ω≥ÂåñÂπ≥Ë°°‰∫ÜÂéªÂ≠∏ÁøíÊ®°ÂûãÁöÑÈÅ∫ÂøòÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÂú® 14 ÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÔºåÂåÖÊã¨Â§ßË¶èÊ®°ÁöÑ ogbn-papers100MÔºåË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåNIM Â¢ûÂº∑‰∫ÜÂ§ßÂ§öÊï∏ GU ÊñπÊ≥ïÁöÑÈÅ∫ÂøòËÉΩÂäõÔºåËÄå SGU ÂâáÂØ¶Áèæ‰∫ÜÂÖ®Èù¢ÁöÑ SOTA ÊïàËÉΩ‰∏¶‰øùÊåÅÂèØÊì¥ÂÖÖÊÄß„ÄÇ

##### **Toward Effective Digraph Representation Learning: A Magnetic Adaptive Propagation based Approach**
2501.11817v1 by Xunkai Li, Daohan Su, Zhengyu Wu, Guang Zeng, Hongchao Qin, Rong-Hua Li, Guoren Wang

The $q$-parameterized magnetic Laplacian serves as the foundation of directed
graph (digraph) convolution, enabling this kind of digraph neural network
(MagDG) to encode node features and structural insights by complex-domain
message passing. As a generalization of undirected methods, MagDG shows
superior capability in modeling intricate web-scale topology. Despite the great
success achieved by existing MagDGs, limitations still exist: (1) Hand-crafted
$q$: The performance of MagDGs depends on selecting an appropriate
$q$-parameter to construct suitable graph propagation equations in the complex
domain. This parameter tuning, driven by downstream tasks, limits model
flexibility and significantly increases manual effort. (2) Coarse Message
Passing: Most approaches treat all nodes with the same complex-domain
propagation and aggregation rules, neglecting their unique digraph contexts.
This oversight results in sub-optimal performance. To address the above issues,
we propose two key techniques: (1) MAP is crafted to be a plug-and-play
complex-domain propagation optimization strategy in the context of digraph
learning, enabling seamless integration into any MagDG to improve predictions
while enjoying high running efficiency. (2) MAP++ is a new digraph learning
framework, further incorporating a learnable mechanism to achieve adaptively
edge-wise propagation and node-wise aggregation in the complex domain for
better performance. Extensive experiments on 12 datasets demonstrate that MAP
enjoys flexibility for it can be incorporated with any MagDG, and scalability
as it can deal with web-scale digraphs. MAP++ achieves SOTA predictive
performance on 4 different downstream tasks.

ÊëòË¶ÅÔºö<paragraph>Â∏∂Êúâ $q$ ÂèÉÊï∏ÂåñÁöÑÁ£ÅÊÄßÊãâÊôÆÊãâÊñØÁÆóÂ≠êÂèØ‰ΩúÁÇ∫ÊúâÂêëÂúñ (digraph) Êë∫Á©çÁöÑÂü∫Á§éÔºå‰ΩøÈÄôÁ®ÆÈ°ûÂûãÁöÑÊúâÂêëÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MagDG) ËÉΩÈÄèÈÅéË§áÊï∏ÂüüË®äÊÅØÂÇ≥ÈÅûÂ∞çÁØÄÈªûÁâπÂæµÂíåÁµêÊßãË¶ãËß£ÈÄ≤Ë°åÁ∑®Á¢º„ÄÇ‰ΩúÁÇ∫ÁÑ°ÂêëÊñπÊ≥ïÁöÑÊ¶ÇÊã¨ÔºåMagDG Âú®Âª∫Ê®°Ë§áÈõúÁöÑÁ∂≤Ë∑ØË¶èÊ®°ÊãìÊí≤ÊñπÈù¢Â±ïÁèæÂá∫ÂÑ™Ë∂äÁöÑËÉΩÂäõ„ÄÇÂÑòÁÆ°ÁèæÊúâÁöÑ MagDG ÂèñÂæó‰∫ÜÂ∑®Â§ßÁöÑÊàêÂäüÔºå‰ΩÜ‰ªçÂ≠òÂú®‰ª•‰∏ãÈôêÂà∂Ôºö(1) ÊâãÂ∑•Ë£Ω‰ΩúÁöÑ $q$ÔºöMagDG ÁöÑÊïàËÉΩÂèñÊ±∫ÊñºÈÅ∏ÊìáÈÅ©Áï∂ÁöÑ $q$ ÂèÉÊï∏Ôºå‰ª•Âú®Ë§áÊï∏Âüü‰∏≠Âª∫ÊßãÂêàÈÅ©ÁöÑÂúñÂΩ¢ÂÇ≥Êí≠ÊñπÁ®ãÂºè„ÄÇÊ≠§ÂèÉÊï∏Ë™øÊï¥Âèó‰∏ãÊ∏∏‰ªªÂãôÈ©ÖÂãïÔºåÊúÉÈôêÂà∂Ê®°ÂûãÂΩàÊÄßÔºå‰∏¶Â§ßÂπÖÂ¢ûÂä†ÊâãÂãïÂ∑•‰Ωú„ÄÇ(2) Á≤óÁï•Ë®äÊÅØÂÇ≥ÈÅûÔºöÂ§ßÂ§öÊï∏ÊñπÊ≥ï‰ΩøÁî®Áõ∏ÂêåÁöÑË§áÊï∏ÂüüÂÇ≥Êí≠ÂíåËÅöÂêàË¶èÂâá‰æÜËôïÁêÜÊâÄÊúâÁØÄÈªûÔºåÂøΩÁï•‰∫ÜÂÆÉÂÄëÁç®ÁâπÁöÑÊúâÂêëÂúñËÑàÁµ°„ÄÇÈÄôÁ®ÆÁñèÂøΩÂ∞éËá¥Ê¨°‰Ω≥ÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫‰∏äËø∞ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ©È†ÖÈóúÈçµÊäÄË°ìÔºö(1) MAP Ë¢´Ë®≠Ë®àÁÇ∫Âç≥ÊèíÂç≥Áî®ÁöÑË§áÊï∏ÂüüÂÇ≥Êí≠ÊúÄ‰Ω≥ÂåñÁ≠ñÁï•ÔºåÁî®ÊñºÊúâÂêëÂúñÂ≠∏ÁøíÁöÑËÑàÁµ°‰∏≠ÔºåËÉΩÁÑ°Á∏´Êï¥ÂêàËá≥‰ªª‰Ωï MagDG ‰ª•ÊîπÂñÑÈ†êÊ∏¨ÔºåÂêåÊôÇ‰∫´ÊúâÈ´òÂü∑Ë°åÊïàÁéá„ÄÇ(2) MAP++ ÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑÊúâÂêëÂúñÂ≠∏ÁøíÊû∂ÊßãÔºåÈÄ≤‰∏ÄÊ≠•ÁµêÂêàÂèØÂ≠∏ÁøíÊ©üÂà∂ÔºåÂú®Ë§áÊï∏Âüü‰∏≠ÈÅîÊàêÈÅ©ÊáâÊÄßÁöÑÈÇäÁ∑£ÂÇ≥Êí≠ÂíåÁØÄÈªûËÅöÂêàÔºå‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇÂú® 12 ÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåMAP ‰∫´ÊúâÂΩàÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•Ëàá‰ªª‰Ωï MagDG Êï¥ÂêàÔºåËÄå‰∏îÂÖ∑ÊúâÂèØÊì¥ÂÖÖÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•ËôïÁêÜÁ∂≤Ë∑ØË¶èÊ®°ÁöÑÊúâÂêëÂúñ„ÄÇMAP++ Âú® 4 ÂÄã‰∏çÂêåÁöÑ‰∏ãÊ∏∏‰ªªÂãô‰∏äÈÅîÂà∞‰∫Ü SOTA È†êÊ∏¨ÊïàËÉΩ„ÄÇ</paragraph>

##### **Policy-Adaptable Methods For Resolving Normative Conflicts Through Argumentation and Graph Colouring**
2501.11799v1 by Johnny Joyce

In a multi-agent system, one may choose to govern the behaviour of an agent
by imposing norms, which act as guidelines for how agents should act either all
of the time or in given situations. However, imposing multiple norms on one or
more agents may result in situations where these norms conflict over how the
agent should behave. In any system with normative conflicts (such as safe
reinforcement models or systems which monitor safety protocols), one must
decide which norms should be followed such that the most important and most
relevant norms are maintained. We introduce a new method for resolving
normative conflicts through argumentation and graph colouring which is
compatible with a variety of normative conflict resolution policies. We prove
that this method always creates an admissible set of arguments under
argumentation semantics, meaning that it produces coherent outputs. We also
introduce more robust variants of this method, each building upon their
predecessor to create a superior output, and we include further mathematical
proof of their coherence. Our most advanced variant uses the existing concept
of curtailment, where one norm may supersede another without fully eliminating
it. The methods we introduce are all compatible with various pre-existing
policies for resolving normative conflicts. Empirical evaluations are also
performed to compare our algorithms to each other and to others in existing
literature.

ÊëòË¶ÅÔºöÂú®Â§ö‰ª£ÁêÜÁ≥ªÁµ±‰∏≠Ôºå‰∫∫ÂÄëÂèØËÉΩÊúÉÈÅ∏ÊìáÈÄèÈÅéÂØ¶ÊñΩË¶èÁØÑ‰æÜÁÆ°ÁêÜ‰ª£ÁêÜÁöÑË°åÁÇ∫ÔºåÈÄô‰∫õË¶èÁØÑ‰ΩúÁÇ∫‰ª£ÁêÜÂú®‰ªª‰ΩïÊôÇÂÄôÊàñÁâπÂÆöÊÉÖÊ≥Å‰∏ãÊáâÂ¶Ç‰ΩïÊé°ÂèñË°åÂãïÁöÑÊ∫ñÂâá„ÄÇÁÑ∂ËÄåÔºåÂ∞ç‰∏ÄÂÄãÊàñÂ§öÂÄã‰ª£ÁêÜÂØ¶ÊñΩÂ§öÈ†ÖË¶èÁØÑÂèØËÉΩÊúÉÂ∞éËá¥ÈÄô‰∫õË¶èÁØÑÂú®‰ª£ÁêÜÊáâÂ¶Ç‰ΩïÊé°ÂèñË°åÂãïÊñπÈù¢ÁôºÁîüË°ùÁ™ÅÁöÑÊÉÖÊ≥Å„ÄÇÂú®‰ªª‰ΩïÂÖ∑ÊúâË¶èÁØÑË°ùÁ™ÅÁöÑÁ≥ªÁµ±‰∏≠Ôºà‰æãÂ¶ÇÂÆâÂÖ®Âº∑ÂåñÊ®°ÂûãÊàñÁõ£ÊéßÂÆâÂÖ®ÂçîÂÆöÁöÑÁ≥ªÁµ±ÔºâÔºå‰∫∫ÂÄëÂøÖÈ†àÊ±∫ÂÆöÊáâÈÅµÂæ™Âì™‰∫õË¶èÁØÑÔºå‰ª•‰æøÁ∂≠Ë≠∑ÊúÄÈáçË¶Å‰∏îÊúÄÁõ∏ÈóúÁöÑË¶èÁØÑ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéË´ñË≠âÂíåÂúñÂΩ¢ËëóËâ≤‰æÜËß£Ê±∫Ë¶èÁØÑË°ùÁ™ÅÔºåÈÄôÁ®ÆÊñπÊ≥ïËàáÂêÑÁ®ÆË¶èÁØÑË°ùÁ™ÅËß£Ê±∫ÊîøÁ≠ñÁõ∏ÂÆπ„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÂßãÁµÇÊúÉÂú®Ë´ñË≠âË™ûÁæ©‰∏ãÂª∫Á´ã‰∏ÄÁµÑÂèØÊé•ÂèóÁöÑË´ñË≠âÔºåÈÄôË°®Á§∫ÂÆÉÊúÉÁî¢ÁîüÈÄ£Ë≤´ÁöÑËº∏Âá∫„ÄÇÊàëÂÄë‰πüÂºïÂÖ•‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑÊõ¥Âº∑ÂÅ•ËÆäÈ´îÔºåÊØèÂÄãËÆäÈ´îÈÉΩÂª∫Á´ãÂú®ÂÆÉÂÄëÁöÑÂâçË∫´‰πã‰∏äÔºå‰ª•Âª∫Á´ãÂÑ™Áï∞ÁöÑËº∏Âá∫Ôºå‰∏¶‰∏îÊàëÂÄëÂåÖÊã¨‰∫ÜÂÆÉÂÄëÁöÑÈÄ£Ë≤´ÊÄßÁöÑÈÄ≤‰∏ÄÊ≠•Êï∏Â≠∏Ë≠âÊòé„ÄÇÊàëÂÄëÊúÄÂÖàÈÄ≤ÁöÑËÆäÈ´î‰ΩøÁî®‰∫ÜÁèæÊúâÁöÑÈôêÂà∂Ê¶ÇÂøµÔºåÂÖ∂‰∏≠‰∏ÄÂÄãË¶èÁØÑÂèØ‰ª•Âú®‰∏çÂÆåÂÖ®Ê∂àÈô§Âè¶‰∏ÄÂÄãË¶èÁØÑÁöÑÊÉÖÊ≥Å‰∏ãÂèñ‰ª£Âè¶‰∏ÄÂÄãË¶èÁØÑ„ÄÇÊàëÂÄëÂºïÂÖ•ÁöÑÊñπÊ≥ïÈÉΩËàáÂêÑÁ®ÆÈ†êÂÖàÂ≠òÂú®ÁöÑË¶èÁØÑË°ùÁ™ÅËß£Ê±∫ÊîøÁ≠ñÁõ∏ÂÆπ„ÄÇÊàëÂÄë‰πüÈÄ≤Ë°å‰∫ÜÁ∂ìÈ©óË©ï‰º∞Ôºå‰ª•Â∞áÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂΩºÊ≠§ÊØîËºÉÔºå‰∏¶ËàáÁèæÊúâÊñáÁçª‰∏≠ÁöÑÂÖ∂‰ªñÊºîÁÆóÊ≥ïÊØîËºÉ„ÄÇ

##### **Benchmarking Large Language Models via Random Variables**
2501.11790v1 by Zijin Hong, Hao Wu, Su Dong, Junnan Dong, Yilin Xiao, Yujing Zhang, Zhu Wang, Feiran Huang, Linyi Li, Hongxia Yang, Xiao Huang

With the continuous advancement of large language models (LLMs) in
mathematical reasoning, evaluating their performance in this domain has become
a prominent research focus. Recent studies have raised concerns about the
reliability of current mathematical benchmarks, highlighting issues such as
simplistic design and potential data leakage. Therefore, creating a reliable
benchmark that effectively evaluates the genuine capabilities of LLMs in
mathematical reasoning remains a significant challenge. To address this, we
propose RV-Bench, a framework for Benchmarking LLMs via Random Variables in
mathematical reasoning. Specifically, the background content of a random
variable question (RV question) mirrors the original problem in existing
standard benchmarks, but the variable combinations are randomized into
different values. LLMs must fully understand the problem-solving process for
the original problem to correctly answer RV questions with various combinations
of variable values. As a result, the LLM's genuine capability in mathematical
reasoning is reflected by its accuracy on RV-Bench. Extensive experiments are
conducted with 29 representative LLMs across 900+ RV questions. A leaderboard
for RV-Bench ranks the genuine capability of these LLMs. Further analysis of
accuracy dropping indicates that current LLMs still struggle with complex
mathematical reasoning problems.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êï∏Â≠∏Êé®ÁêÜÊñπÈù¢ÁöÑÊåÅÁ∫åÈÄ≤Ê≠•ÔºåË©ï‰º∞ÂÆÉÂÄëÂú®ÈÄôÂÄãÈ†òÂüüÁöÑË°®ÁèæÂ∑≤ÊàêÁÇ∫‰∏ÄÂÄãÈáçË¶ÅÁöÑÁ†îÁ©∂ÈáçÈªû„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∞çÁï∂ÂâçÊï∏Â≠∏Âü∫Ê∫ñÁöÑÂèØÈù†ÊÄßÊèêÂá∫‰∫ÜÁñëÊÖÆÔºå‰∏¶Âº∑Ë™ø‰∫ÜË´∏Â¶ÇË®≠Ë®àÈÅéÊñºÁ∞°ÂåñÂíåÊΩõÂú®Êï∏ÊìöÊ¥©ÊºèÁ≠âÂïèÈ°å„ÄÇÂõ†Ê≠§ÔºåÂª∫Á´ã‰∏ÄÂÄãÂèØÈù†ÁöÑÂü∫Ê∫ñÔºå‰ª•ÊúâÊïàË©ï‰º∞ LLM Âú®Êï∏Â≠∏Êé®ÁêÜ‰∏≠ÁöÑÁúüÂØ¶ËÉΩÂäõÔºå‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü RV-BenchÔºå‰∏ÄÂÄãÈÄèÈÅéÈö®Ê©üËÆäÊï∏Â∞ç LLM ÈÄ≤Ë°åÂü∫ÂáÜÊ∏¨Ë©¶ÁöÑÊï∏Â≠∏Êé®ÁêÜÊ°ÜÊû∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈö®Ê©üËÆäÊï∏ÂïèÈ°å (RV ÂïèÈ°å) ÁöÑËÉåÊôØÂÖßÂÆπÂèçÊò†‰∫ÜÁèæÊúâÊ®ôÊ∫ñÂü∫Ê∫ñ‰∏≠ÁöÑÂéüÂßãÂïèÈ°åÔºå‰ΩÜËÆäÊï∏ÁµÑÂêàË¢´Èö®Ê©üÂåñÁÇ∫‰∏çÂêåÁöÑÂÄº„ÄÇLLM ÂøÖÈ†àÂÖÖÂàÜÁêÜËß£ÂéüÂßãÂïèÈ°åÁöÑËß£È°åÈÅéÁ®ãÔºåÊâçËÉΩÊ≠£Á¢∫ÂõûÁ≠îÂÖ∑ÊúâÂêÑÁ®ÆËÆäÊï∏ÂÄºÁµÑÂêàÁöÑ RV ÂïèÈ°å„ÄÇÂõ†Ê≠§ÔºåLLM Âú®Êï∏Â≠∏Êé®ÁêÜ‰∏≠ÁöÑÁúüÂØ¶ËÉΩÂäõÂèçÊò†Âú®ÂÖ∂Âú® RV-Bench ‰∏äÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ‰ΩøÁî® 29 ÂÄãÂÖ∑‰ª£Ë°®ÊÄßÁöÑ LLM Â∞ç 900 Â§öÂÄã RV ÂïèÈ°åÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó„ÄÇRV-Bench ÁöÑÊéíË°åÊ¶úÂ∞çÈÄô‰∫õ LLM ÁöÑÁúüÂØ¶ËÉΩÂäõÈÄ≤Ë°å‰∫ÜÊéíÂêç„ÄÇÂ∞çÊ∫ñÁ¢∫Â∫¶‰∏ãÈôçÁöÑÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêË°®ÊòéÔºåÁï∂ÂâçÁöÑ LLM ‰ªçÁÑ∂Èõ£‰ª•Ëß£Ê±∫Ë§áÈõúÁöÑÊï∏Â≠∏Êé®ÁêÜÂïèÈ°å„ÄÇ

##### **Synthetic Data Can Mislead Evaluations: Membership Inference as Machine Text Detection**
2501.11786v1 by Ali Naseh, Niloofar Mireshghallah

Recent work shows membership inference attacks (MIAs) on large language
models (LLMs) produce inconclusive results, partly due to difficulties in
creating non-member datasets without temporal shifts. While researchers have
turned to synthetic data as an alternative, we show this approach can be
fundamentally misleading. Our experiments indicate that MIAs function as
machine-generated text detectors, incorrectly identifying synthetic data as
training samples regardless of the data source. This behavior persists across
different model architectures and sizes, from open-source models to commercial
ones such as GPT-3.5. Even synthetic text generated by different, potentially
larger models is classified as training data by the target model. Our findings
highlight a serious concern: using synthetic data in membership evaluations may
lead to false conclusions about model memorization and data leakage. We caution
that this issue could affect other evaluations using model signals such as loss
where synthetic or machine-generated translated data substitutes for real-world
samples.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÈáùÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÉÂì°Êé®Ë´ñÊîªÊìä (MIA) ÊúÉÁî¢Áîü‰∏çÁ¢∫ÂÆöÁöÑÁµêÊûúÔºåÈÉ®ÂàÜÂéüÂõ†ÊòØÈõ£‰ª•Âú®Ê≤íÊúâÊôÇÈñìËÆäÂãïÁöÑÊÉÖÊ≥Å‰∏ãÂª∫Á´ãÈùûÊúÉÂì°Ë≥áÊñôÈõÜ„ÄÇÂÑòÁÆ°Á†îÁ©∂‰∫∫Âì°Â∑≤ËΩâÂêëÂêàÊàêË≥áÊñô‰ΩúÁÇ∫Êõø‰ª£ÊñπÊ°àÔºå‰ΩÜÊàëÂÄëË≠âÊòéÈÄôÁ®ÆÊñπÊ≥ïÂèØËÉΩÊúÉÁî¢ÁîüÊ†πÊú¨ÊÄßÁöÑË™§Â∞é„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåMIA ÊúÉ‰ΩúÁÇ∫Ê©üÂô®Áî¢ÁîüÁöÑÊñáÂ≠óÂÅµÊ∏¨Âô®Ôºå‰∏çÊ≠£Á¢∫Âú∞Â∞áÂêàÊàêË≥áÊñôË≠òÂà•ÁÇ∫Ë®ìÁ∑¥Ê®£Êú¨ÔºåÁÑ°Ë´ñË≥áÊñô‰æÜÊ∫êÁÇ∫‰Ωï„ÄÇÈÄôÁ®ÆË°åÁÇ∫ÊúÉÊåÅÁ∫åÂ≠òÂú®Êñº‰∏çÂêåÁöÑÊ®°ÂûãÊû∂ÊßãÂíåË¶èÊ®°‰∏≠ÔºåÂæûÈñãÊ∫êÊ®°ÂûãÂà∞ÂïÜÊ•≠Ê®°ÂûãÔºå‰æãÂ¶Ç GPT-3.5„ÄÇÂç≥‰ΩøÊòØÁî±‰∏çÂêå‰∏îÊΩõÂú®Êõ¥Â§ßÁöÑÊ®°ÂûãÁî¢ÁîüÁöÑÂêàÊàêÊñáÂ≠óÔºå‰πüÊúÉË¢´ÁõÆÊ®ôÊ®°ÂûãÂàÜÈ°ûÁÇ∫Ë®ìÁ∑¥Ë≥áÊñô„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂá∏È°Ø‰∫Ü‰∏ÄÂÄãÂö¥ÈáçÁöÑÂïèÈ°åÔºöÂú®ÊúÉÂì°Ë©ï‰º∞‰∏≠‰ΩøÁî®ÂêàÊàêË≥áÊñôÂèØËÉΩÊúÉÂ∞éËá¥ÈóúÊñºÊ®°ÂûãË®òÊÜ∂ÂíåË≥áÊñôÂ§ñÊ¥©ÁöÑÈåØË™§ÁµêË´ñ„ÄÇÊàëÂÄëË¨πÊÖéÊèêÈÜíÔºåÈÄôÂÄãÂïèÈ°åÂèØËÉΩÊúÉÂΩ±ÈüøÂÖ∂‰ªñ‰ΩøÁî®Ê®°ÂûãË®äËôüÁöÑË©ï‰º∞Ôºå‰æãÂ¶ÇÊêçÂ§±ÔºåÂÖ∂‰∏≠ÂêàÊàêÊàñÊ©üÂô®Áî¢ÁîüÁöÑÁøªË≠ØË≥áÊñôÊúÉÂèñ‰ª£ÁúüÂØ¶‰∏ñÁïåÁöÑÊ®£Êú¨„ÄÇ

##### **Human-AI Collaborative Game Testing with Vision Language Models**
2501.11782v1 by Boran Zhang, Muhan Xu, Zhijun Pan

As modern video games become increasingly complex, traditional manual testing
methods are proving costly and inefficient, limiting the ability to ensure
high-quality game experiences. While advancements in Artificial Intelligence
(AI) offer the potential to assist human testers, the effectiveness of AI in
truly enhancing real-world human performance remains underexplored. This study
investigates how AI can improve game testing by developing and experimenting
with an AI-assisted workflow that leverages state-of-the-art machine learning
models for defect detection. Through an experiment involving 800 test cases and
276 participants of varying backgrounds, we evaluate the effectiveness of AI
assistance under four conditions: with or without AI support, and with or
without detailed knowledge of defects and design documentation. The results
indicate that AI assistance significantly improves defect identification
performance, particularly when paired with detailed knowledge. However,
challenges arise when AI errors occur, negatively impacting human
decision-making. Our findings show the importance of optimizing human-AI
collaboration and implementing strategies to mitigate the effects of AI
inaccuracies. By this research, we demonstrate AI's potential and problems in
enhancing efficiency and accuracy in game testing workflows and offers
practical insights for integrating AI into the testing process.

ÊëòË¶ÅÔºöÈö®ËëóÁèæ‰ª£Ë¶ñË®äÈÅäÊà≤ËÆäÂæóË∂ä‰æÜË∂äË§áÈõúÔºåÂÇ≥Áµ±ÁöÑÊâãÂãïÊ∏¨Ë©¶ÊñπÊ≥ïË¢´Ë≠âÊòéÊàêÊú¨È´òÊòÇ‰∏îÊïàÁéá‰Ωé‰∏ãÔºåÈôêÂà∂‰∫ÜÁ¢∫‰øùÈ´òÂìÅË≥™ÈÅäÊà≤È´îÈ©óÁöÑËÉΩÂäõ„ÄÇÈõñÁÑ∂‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÈÄ≤Ê≠•Êèê‰æõ‰∫ÜÂçîÂä©‰∫∫È°ûÊ∏¨Ë©¶‰∫∫Âì°ÁöÑÊΩõÂäõÔºå‰ΩÜ AI Âú®ÁúüÊ≠£ÊèêÂçáÁèæÂØ¶‰∏ñÁïå‰∫∫È°ûË°®ÁèæÊñπÈù¢ÁöÑÊúâÊïàÊÄß‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü AI Â¶Ç‰ΩïÈÄèÈÅéÈñãÁôºÂíåÂØ¶È©ó AI ËºîÂä©Â∑•‰ΩúÊµÅÁ®ã‰æÜÊîπÈÄ≤ÈÅäÊà≤Ê∏¨Ë©¶ÔºåË©≤Â∑•‰ΩúÊµÅÁ®ãÂà©Áî®ÊúÄÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÈÄ≤Ë°åÁº∫Èô∑Ê™¢Ê∏¨„ÄÇÈÄèÈÅé‰∏ÄÈ†ÖÊ∂âÂèä 800 ÂÄãÊ∏¨Ë©¶Ê°à‰æãÂíå 276 ‰ΩçËÉåÊôØÂêÑÁï∞ÁöÑÂèÉËàáËÄÖÁöÑÂØ¶È©óÔºåÊàëÂÄëË©ï‰º∞‰∫Ü AI ËºîÂä©Âú®ÂõõÁ®ÆÊ¢ù‰ª∂‰∏ãÁöÑÊúâÊïàÊÄßÔºöÊúâÊàñÊ≤íÊúâ AI ÊîØÊè¥Ôºå‰ª•ÂèäÊúâÊàñÊ≤íÊúâÁº∫Èô∑ÂíåË®≠Ë®àÊñá‰ª∂Ë©≥Á¥∞Áü•Ë≠ò„ÄÇÁµêÊûúË°®ÊòéÔºåAI ËºîÂä©È°ØËëóÊîπÈÄ≤‰∫ÜÁº∫Èô∑Ë≠òÂà•ÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®ÂÖ∑ÂÇôË©≥Á¥∞Áü•Ë≠òÊôÇ„ÄÇÁÑ∂ËÄåÔºåÁï∂ÁôºÁîü AI ÈåØË™§ÊôÇÊúÉÂá∫ÁèæÊåëÊà∞ÔºåÂ∞ç‰∫∫È°ûÊ±∫Á≠ñÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫‰∫ÜÊúÄ‰Ω≥Âåñ‰∫∫Ê©üÂçî‰Ωú‰ª•ÂèäÂØ¶ÊñΩÁ≠ñÁï•‰ª•Ê∏õËºï AI ‰∏çÊ∫ñÁ¢∫ÂΩ±ÈüøÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄèÈÅéÈÄôÈ†ÖÁ†îÁ©∂ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü AI Âú®ÊèêÈ´òÈÅäÊà≤Ê∏¨Ë©¶Â∑•‰ΩúÊµÅÁ®ãÁöÑÊïàÁéáÂíåÊ∫ñÁ¢∫ÊÄßÊñπÈù¢ÁöÑÊΩõÂäõËàáÂïèÈ°åÔºå‰∏¶Êèê‰æõ‰∫ÜÂ∞á AI Êï¥ÂêàÂà∞Ê∏¨Ë©¶ÊµÅÁ®ã‰∏≠ÁöÑÂØ¶Áî®Ë¶ãËß£„ÄÇ

##### **The Value of Nothing: Multimodal Extraction of Human Values Expressed by TikTok Influencers**
2501.11770v1 by Alina Starovolsky-Shitrit, Alon Neduva, Naama Appel Doron, Ella Daniel, Oren Tsur

Societal and personal values are transmitted to younger generations through
interaction and exposure. Traditionally, children and adolescents learned
values from parents, educators, or peers. Nowadays, social platforms serve as a
significant channel through which youth (and adults) consume information, as
the main medium of entertainment, and possibly the medium through which they
learn different values. In this paper we extract implicit values from TikTok
movies uploaded by online influencers targeting children and adolescents. We
curated a dataset of hundreds of TikTok movies and annotated them according to
the Schwartz Theory of Personal Values. We then experimented with an array of
Masked and Large language model, exploring how values can be detected.
Specifically, we considered two pipelines -- direct extraction of values from
video and a 2-step approach in which videos are first converted to elaborated
scripts and then values are extracted.
  Achieving state-of-the-art results, we find that the 2-step approach performs
significantly better than the direct approach and that using a trainable Masked
Language Model as a second step significantly outperforms a few-shot
application of a number of Large Language Models. We further discuss the impact
of fine-tuning and compare the performance of the different models on
identification of values present or contradicted in the TikTok. Finally, we
share the first values-annotated dataset of TikTok videos. Our results pave the
way to further research on influence and value transmission in video-based
social platforms.

ÊëòË¶ÅÔºöÁ§æÊúÉËàáÂÄã‰∫∫ÂÉπÂÄºËßÄÈÄèÈÅé‰∫íÂãïËàáÊé•Ëß∏ÂÇ≥ÈÅûÁµ¶Âπ¥Ëºï‰∏ñ‰ª£„ÄÇÂÇ≥Áµ±‰∏äÔºåÂÖíÁ´•ËàáÈùíÂ∞ëÂπ¥ÂæûÁà∂ÊØç„ÄÅÊïôËÇ≤ËÄÖÊàñÂêåÂÑïË∫´‰∏äÂ≠∏ÁøíÂÉπÂÄºËßÄ„ÄÇÁèæ‰ªäÔºåÁ§æÁæ§Âπ≥Âè∞ÊàêÁÇ∫ÈùíÂ∞ëÂπ¥ÔºàËàáÊàê‰∫∫ÔºâÊ∂àË≤ªË≥áË®äÁöÑÈáçË¶ÅÁÆ°ÈÅìÔºå‰ΩúÁÇ∫Â®õÊ®ÇÁöÑ‰∏ªË¶ÅÂ™í‰ªãÔºå‰πüÂèØËÉΩÊòØ‰ªñÂÄëÂ≠∏Áøí‰∏çÂêåÂÉπÂÄºËßÄÁöÑÂ™í‰ªã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂæûÁ∂≤Á¥Ö‰∏äÂÇ≥„ÄÅÈéñÂÆöÂÖíÁ´•ËàáÈùíÂ∞ëÂπ¥ÁöÑ TikTok ÂΩ±Áâá‰∏≠ËêÉÂèñÈö±Âê´ÁöÑÂÉπÂÄºËßÄ„ÄÇÊàëÂÄëÁ≠ñÂäÉ‰∫Ü‰∏ÄÂÄãÂåÖÂê´Êï∏ÁôæÈÉ® TikTok ÂΩ±ÁâáÁöÑË≥áÊñôÈõÜÔºå‰∏¶‰æùÊìö Schwartz ÂÄã‰∫∫ÂÉπÂÄºËßÄÁêÜË´ñÂ∞çÂÖ∂ÈÄ≤Ë°åË®ªËß£„ÄÇÊé•ËëóÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÁ≥ªÂàóÁöÑÈÅÆËîΩË™ûË®ÄÊ®°ÂûãËàáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÂØ¶È©óÔºåÊé¢Á¥¢Â¶Ç‰ΩïÂÅµÊ∏¨ÂÉπÂÄºËßÄ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëËÄÉÈáè‰∫ÜÂÖ©Á®ÆÁÆ°ÈÅì‚Äî‚ÄîÁõ¥Êé•ÂæûÂΩ±Áâá‰∏≠ËêÉÂèñÂÉπÂÄºËßÄÔºå‰ª•Âèä‰∏ÄÁ®ÆÂÖàÂ∞áÂΩ±ÁâáËΩâÊèõÁÇ∫Ë©≥Á¥∞ËÖ≥Êú¨ÔºåÂÜçËêÉÂèñÂÉπÂÄºËßÄÁöÑÂÖ©Ê≠•È©üÊñπÊ≥ï„ÄÇÊàëÂÄëÁôºÁèæÔºåÂÖ©Ê≠•È©üÊñπÊ≥ïÁöÑË°®ÁèæÈ°ØËëóÂÑ™ÊñºÁõ¥Êé•ÊñπÊ≥ïÔºå‰∏îÂú®Á¨¨‰∫åÊ≠•È©ü‰∏≠‰ΩøÁî®ÂèØË®ìÁ∑¥ÁöÑÈÅÆËîΩË™ûË®ÄÊ®°ÂûãÔºåÂÖ∂Ë°®Áèæ‰πüÈ°ØËëóÂÑ™ÊñºÂ∞ëÊ¨°ÂòóË©¶ÊáâÁî®Â§öÁ®ÆÂ§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé¢Ë®éÂæÆË™øÁöÑÂΩ±ÈüøÔºå‰∏¶ÊØîËºÉ‰∏çÂêåÊ®°ÂûãÂú®Ë≠òÂà• TikTok ‰∏≠Â≠òÂú®ÊàñÁüõÁõæÁöÑÂÉπÂÄºËßÄÊñπÈù¢ÁöÑË°®Áèæ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂàÜ‰∫´‰∫ÜÁ¨¨‰∏ÄÂÄã TikTok ÂΩ±ÁâáÂÉπÂÄºËßÄË®ªËß£Ë≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁÇ∫ÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÂΩ±ÁâáÁ§æÁæ§Âπ≥Âè∞‰∏≠ÁöÑÂΩ±ÈüøÂäõËàáÂÉπÂÄºËßÄÂÇ≥ÈÅûÈã™Ë∑Ø„ÄÇ

##### **Is logical analysis performed by transformers taking place in self-attention or in the fully connected part?**
2501.11765v1 by Evgeniy Shin, Heinrich Matzinger

Transformers architecture apply self-attention to tokens represented as
vectors, before a fully connected (neuronal network) layer. These two parts can
be layered many times. Traditionally, self-attention is seen as a mechanism for
aggregating information before logical operations are performed by the fully
connected layer. In this paper, we show, that quite counter-intuitively, the
logical analysis can also be performed within the self-attention. For this we
implement a handcrafted single-level encoder layer which performs the logical
analysis within self-attention. We then study the scenario in which a one-level
transformer model undergoes self-learning using gradient descent. We
investigate whether the model utilizes fully connected layers or self-attention
mechanisms for logical analysis when it has the choice. Given that gradient
descent can become stuck at undesired zeros, we explicitly calculate these
unwanted zeros and find ways to avoid them. We do all this in the context of
predicting grammatical category pairs of adjacent tokens in a text. We believe
that our findings have broader implications for understanding the potential
logical operations performed by self-attention.

ÊëòË¶ÅÔºöTransformer Êû∂ÊßãÂú®ÂÖ®ÈÄ£Êé•ÔºàÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºâÂ±§‰πãÂâçÔºåÂ∞áËá™Ê≥®ÊÑèÂäõÊáâÁî®ÊñºË°®Á§∫ÁÇ∫ÂêëÈáèÁöÑÁ¨¶Ëôü„ÄÇÈÄôÂÖ©ÂÄãÈÉ®ÂàÜÂèØ‰ª•ÂàÜÂ±§Â§öÊ¨°„ÄÇÂÇ≥Áµ±‰∏äÔºåËá™Ê≥®ÊÑèÂäõË¢´Ë¶ñÁÇ∫Âú®ÂÖ®ÈÄ£Êé•Â±§Âü∑Ë°åÈÇèËºØÈÅãÁÆó‰πãÂâçËÅöÂêàË≥áË®äÁöÑÊ©üÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËá™Ê≥®ÊÑèÂäõ‰∏≠‰πüÂèØ‰ª•Âü∑Ë°åÈÇèËºØÂàÜÊûêÔºåÈÄôÁõ∏Áï∂ÈÅïÂèçÁõ¥Ë¶∫„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂØ¶‰Ωú‰∫Ü‰∏ÄÂÄãÊâãÂ∑•Ë£Ω‰ΩúÁöÑÂñÆÂ±§Á∑®Á¢ºÂô®Â±§ÔºåÂÆÉÂú®Ëá™Ê≥®ÊÑèÂäõ‰∏≠Âü∑Ë°åÈÇèËºØÂàÜÊûê„ÄÇÁÑ∂ÂæåÊàëÂÄëÁ†îÁ©∂‰∫Ü‰∏ÄÁ®ÆÊÉÖÂ¢ÉÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÂñÆÂ±§ transformer Ê®°Âûã‰ΩøÁî®Ê¢ØÂ∫¶‰∏ãÈôçÈÄ≤Ë°åËá™Â≠∏Áøí„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÊ®°ÂûãÂú®ÊúâÈÅ∏ÊìáÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊòØÂê¶Âà©Áî®ÂÖ®ÈÄ£Êé•Â±§ÊàñËá™Ê≥®ÊÑèÂäõÊ©üÂà∂ÈÄ≤Ë°åÈÇèËºØÂàÜÊûê„ÄÇÁî±ÊñºÊ¢ØÂ∫¶‰∏ãÈôçÂèØËÉΩÊúÉÂÅúÁïôÂú®‰∏çÈúÄË¶ÅÁöÑÈõ∂ÈªûÔºåÂõ†Ê≠§ÊàëÂÄëÊòéÁ¢∫Ë®àÁÆóÈÄô‰∫õ‰∏çÈúÄË¶ÅÁöÑÈõ∂ÈªûÔºå‰∏¶ÊâæÂá∫ÈÅøÂÖçÂÆÉÂÄëÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÂú®È†êÊ∏¨ÊñáÂ≠ó‰∏≠Áõ∏ÈÑ∞Á¨¶ËôüÁöÑË™ûÊ≥ïÈ°ûÂà•Â∞çÊôÇÔºåÂü∑Ë°åÊâÄÊúâÈÄô‰∫õÊìç‰Ωú„ÄÇÊàëÂÄëÁõ∏‰ø°ÊàëÂÄëÁöÑÁôºÁèæÂ∞çÊñºÁêÜËß£Ëá™Ê≥®ÊÑèÂäõÂü∑Ë°åÁöÑÊΩõÂú®ÈÇèËºØÈÅãÁÆóÂÖ∑ÊúâÊõ¥Âª£Ê≥õÁöÑÊÑèÁæ©„ÄÇ

##### **Optimizing Pretraining Data Mixtures with LLM-Estimated Utility**
2501.11747v1 by William Held, Bhargavi Paranjape, Punit Singh Koura, Mike Lewis, Frank Zhang, Todor Mihaylov

Large Language Models improve with increasing amounts of high-quality
training data. However, leveraging larger datasets requires balancing quality,
quantity, and diversity across sources. After evaluating nine baseline methods
under both compute- and data-constrained scenarios, we find token-count
heuristics outperform manual and learned mixes, indicating that simple
approaches accounting for dataset size and diversity are surprisingly
effective. Building on this insight, we propose two complementary approaches:
UtiliMax, which extends token-based heuristics by incorporating utility
estimates from reduced-scale ablations, achieving up to a 10.6x speedup over
manual baselines; and Model Estimated Data Utility (MEDU), which leverages LLMs
to estimate data utility from small samples, matching ablation-based
performance while reducing computational requirements by $\sim$200x. Together,
these approaches establish a new framework for automated, compute-efficient
data mixing that is robust across training regimes.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊúÉÈö®ËëóÈ´òÂìÅË≥™Ë®ìÁ∑¥Ë≥áÊñôÁöÑÂ¢ûÂä†ËÄåÊúâÊâÄÈÄ≤Ê≠•„ÄÇÁÑ∂ËÄåÔºåÂà©Áî®Êõ¥Â§ßÁöÑË≥áÊñôÈõÜÈúÄË¶ÅÂú®‰æÜÊ∫ê‰πãÈñìÂπ≥Ë°°ÂìÅË≥™„ÄÅÊï∏ÈáèÂíåÂ§öÊ®£ÊÄß„ÄÇÂú®Ë®àÁÆóÂíåË≥áÊñôÂèóÈôêÁöÑÊÉÖÊ≥Å‰∏ãË©ï‰º∞‰∫Ü‰πùÁ®ÆÂü∫Ê∫ñÊñπÊ≥ïÂæåÔºåÊàëÂÄëÁôºÁèæÊ¨äÊùñË®àÊï∏ÂïüÁôºÂºèÂÑ™ÊñºÊâãÂãïÂíåÂ≠∏ÁøíÊ∑∑ÂêàÔºåÈÄôË°®ÊòéËÄÉÊÖÆË≥áÊñôÈõÜÂ§ßÂ∞èÂíåÂ§öÊ®£ÊÄßÁöÑÁ∞°ÂñÆÊñπÊ≥ïÂá∫‰πéÊÑèÊñôÂú∞ÊúâÊïà„ÄÇÂü∫ÊñºÈÄôÂÄãË¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ©Á®Æ‰∫íË£úÁöÑÊñπÊ≥ïÔºöUtiliMaxÔºåÂÆÉÈÄöÈÅéÁ¥çÂÖ•‰æÜËá™Á∏ÆÂ∞èË¶èÊ®°Ê∂àËûçÁöÑÊïàÁî®‰º∞Ë®à‰æÜÊì¥Â±ïÂü∫ÊñºÊ¨äÊùñÁöÑÂïüÁôºÂºèÔºåËàáÊâãÂãïÂü∫Ê∫ñÁõ∏ÊØîÔºåÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü 10.6 ÂÄçÔºõ‰ª•ÂèäÊ®°Âûã‰º∞Ë®àË≥áÊñôÊïàÁî® (MEDU)ÔºåÂÆÉÂà©Áî® LLM ÂæûÂ∞èÊ®£Êú¨‰º∞Ë®àË≥áÊñôÊïàÁî®ÔºåÂú®Ê∏õÂ∞ëË®àÁÆóÈúÄÊ±ÇÁöÑÂêåÊôÇÂåπÈÖçÂü∫ÊñºÊ∂àËûçÁöÑÊïàËÉΩ $\sim$200 ÂÄç„ÄÇÁ∂úÂêàËÄåË®ÄÔºåÈÄô‰∫õÊñπÊ≥ïÁÇ∫Ëá™ÂãïÂåñ„ÄÅË®àÁÆóÊïàÁéáÈ´òÁöÑË≥áÊñôÊ∑∑ÂêàÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊû∂ÊßãÔºåË©≤Êû∂ÊßãÂú®Ë®ìÁ∑¥Âà∂Â∫¶‰∏≠ÂÖ∑ÊúâÈ≠ØÊ£íÊÄß„ÄÇ

##### **SILO: Solving Inverse Problems with Latent Operators**
2501.11746v1 by Ron Raphaeli, Sean Man, Michael Elad

Consistent improvement of image priors over the years has led to the
development of better inverse problem solvers. Diffusion models are the
newcomers to this arena, posing the strongest known prior to date. Recently,
such models operating in a latent space have become increasingly predominant
due to their efficiency. In recent works, these models have been applied to
solve inverse problems. Working in the latent space typically requires multiple
applications of an Autoencoder during the restoration process, which leads to
both computational and restoration quality challenges. In this work, we propose
a new approach for handling inverse problems with latent diffusion models,
where a learned degradation function operates within the latent space,
emulating a known image space degradation. Usage of the learned operator
reduces the dependency on the Autoencoder to only the initial and final steps
of the restoration process, facilitating faster sampling and superior
restoration quality. We demonstrate the effectiveness of our method on a
variety of image restoration tasks and datasets, achieving significant
improvements over prior art.

ÊëòË¶ÅÔºöÂ§öÂπ¥Êù•ÂõæÂÉèÂÖàÈ™åÁöÑ‰∏çÊñ≠ÊîπËøõÂØºËá¥‰∫ÜÊõ¥Â•ΩÁöÑÈÄÜÈóÆÈ¢òÊ±ÇËß£Âô®ÁöÑÂºÄÂèë„ÄÇÊâ©Êï£Ê®°ÂûãÊòØËØ•È¢ÜÂüüÁöÑÊñ∞ÊâãÔºåÊèêÂá∫‰∫ÜËøÑ‰ªä‰∏∫Ê≠¢Â∑≤Áü•ÁöÑÊúÄÂº∑ÂÖàÈ™å„ÄÇÊúÄËøëÔºåÁî±‰∫éÂÖ∂ÊïàÁéáÔºåÂú®ÊΩúÂú®Á©∫Èó¥‰∏≠ËøêË°åÁöÑÊ≠§Á±ªÊ®°ÂûãÂèòÂæóË∂äÊù•Ë∂äÊôÆÈÅç„ÄÇÂú®ÊúÄËøëÁöÑÂ∑•‰Ωú‰∏≠ÔºåËøô‰∫õÊ®°ÂûãÂ∑≤Ë¢´Â∫îÁî®‰∫éËß£ÂÜ≥ÈÄÜÈóÆÈ¢ò„ÄÇÂú®ÊΩúÂú®Á©∫Èó¥‰∏≠Â∑•‰ΩúÈÄöÂ∏∏ÈúÄË¶ÅÂú®ÊÅ¢Â§çËøáÁ®ã‰∏≠Â§öÊ¨°Â∫îÁî®Ëá™Âä®ÁºñÁ†ÅÂô®ÔºåËøôÂØºËá¥ËÆ°ÁÆóÂíåÊÅ¢Â§çË¥®ÈáèÊåëÊàò„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂ§ÑÁêÜÊΩúÂú®Êâ©Êï£Ê®°ÂûãÈÄÜÈóÆÈ¢òÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÖ∂‰∏≠Â≠¶‰π†Âà∞ÁöÑÈÄÄÂåñÂáΩÊï∞Âú®ÊΩúÂú®Á©∫Èó¥ÂÜÖËøêË°åÔºåÊ®°ÊãüÂ∑≤Áü•ÁöÑÂõæÂÉèÁ©∫Èó¥ÈÄÄÂåñ„ÄÇÂ≠¶‰π†Âà∞ÁöÑÁÆóÂ≠êÁöÑ‰ΩøÁî®Â∞ÜÂØπËá™Âä®ÁºñÁ†ÅÂô®ÁöÑ‰æùËµñÊÄßÈôç‰ΩéÂà∞ÊÅ¢Â§çËøáÁ®ãÁöÑÂàùÂßãÂíåÊúÄÁªàÊ≠•È™§Ôºå‰ªéËÄåÂÆûÁé∞Êõ¥Âø´ÁöÑÈááÊ†∑ÂíåÊõ¥È´òÁöÑÊÅ¢Â§çË¥®Èáè„ÄÇÊàë‰ª¨Âú®ÂêÑÁßçÂõæÂÉèÊÅ¢Â§ç‰ªªÂä°ÂíåÊï∞ÊçÆÈõÜ‰∏äÂ±ïÁ§∫‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºå‰∏éÁé∞ÊúâÊäÄÊúØÁõ∏ÊØîÂèñÂæó‰∫ÜÊòæÁùÄÁöÑÊîπËøõ„ÄÇ

##### **Episodic memory in AI agents poses risks that should be studied and mitigated**
2501.11739v1 by Chad DeChant

Most current AI models have little ability to store and later retrieve a
record or representation of what they do. In human cognition, episodic memories
play an important role in both recall of the past as well as planning for the
future. The ability to form and use episodic memories would similarly enable a
broad range of improved capabilities in an AI agent that interacts with and
takes actions in the world. Researchers have begun directing more attention to
developing memory abilities in AI models. It is therefore likely that models
with such capability will be become widespread in the near future. This could
in some ways contribute to making such AI agents safer by enabling users to
better monitor, understand, and control their actions. However, as a new
capability with wide applications, we argue that it will also introduce
significant new risks that researchers should begin to study and address. We
outline these risks and benefits and propose four principles to guide the
development of episodic memory capabilities so that these will enhance, rather
than undermine, the effort to keep AI safe and trustworthy.

ÊëòË¶ÅÔºöÁèæ‰ªäÂ§ßÂ§öÊï∏ÁöÑ AI Ê®°ÂûãÂπæ‰πéÊ≤íÊúâÂÑ≤Â≠òÂíåÁ®çÂæåÊ™¢Á¥¢ÂÖ∂Âü∑Ë°åÁ¥ÄÈåÑÊàñË°®ÂæµÁöÑËÉΩÂäõ„ÄÇÂú®‰∫∫È°ûË™çÁü•‰∏≠ÔºåÊÉÖÁØÄË®òÊÜ∂Âú®ÂõûÊÜ∂ÈÅéÂéª‰ª•ÂèäË¶èÂäÉÊú™‰æÜ‰∏≠ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂΩ¢ÊàêÂíå‰ΩøÁî®ÊÉÖÁØÄË®òÊÜ∂ÁöÑËÉΩÂäõÂ∞áÂêåÊ®£‰ΩøËàá‰∏ñÁïå‰∫íÂãïÂíåÊé°ÂèñË°åÂãïÁöÑ AI ‰ª£ÁêÜÁ®ãÂºèÂÖ∑ÂÇôÂª£Ê≥õÁöÑÈÄ≤Ê≠•ËÉΩÂäõ„ÄÇÁ†îÁ©∂‰∫∫Âì°Â∑≤ÈñãÂßãÂ∞áÊõ¥Â§öÊ≥®ÊÑèÂäõÊîæÂú®ÁôºÂ±ï AI Ê®°ÂûãÁöÑË®òÊÜ∂ËÉΩÂäõ‰∏ä„ÄÇÂõ†Ê≠§ÔºåÂÖ∑ÂÇôÊ≠§È°ûËÉΩÂäõÁöÑÊ®°ÂûãÂæàÂèØËÉΩÊúÉÂú®‰∏ç‰πÖÁöÑÂ∞á‰æÜÊôÆÂèä„ÄÇÈÄôÂú®Êüê‰∫õÊñπÈù¢ÂèØËÉΩÊúâÂä©ÊñºÈÄèÈÅéËÆì‰ΩøÁî®ËÄÖËÉΩÂ§†Êõ¥ÂÆåÂñÑÂú∞Áõ£Êéß„ÄÅÁêÜËß£ÂíåÊéßÂà∂ÂÖ∂Ë°åÂãïÔºåÂæûËÄå‰ΩøÊ≠§È°û AI ‰ª£ÁêÜÁ®ãÂºèÊõ¥ÂÆâÂÖ®„ÄÇÁÑ∂ËÄåÔºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÂÖ∑ÊúâÂª£Ê≥õÊáâÁî®Á®ãÂºèÁöÑÊñ∞ËÉΩÂäõÔºåÊàëÂÄëË™çÁÇ∫ÂÆÉ‰πüÊúÉÂ∏∂‰æÜÈáçÂ§ßÁöÑÊñ∞È¢®Èö™ÔºåÁ†îÁ©∂‰∫∫Âì°ÊáâÈñãÂßãÁ†îÁ©∂ÂíåËß£Ê±∫ÈÄô‰∫õÈ¢®Èö™„ÄÇÊàëÂÄëÊ¶ÇËø∞ÈÄô‰∫õÈ¢®Èö™ÂíåÂ•ΩËôïÔºå‰∏¶ÊèêÂá∫ÂõõÈ†ÖÂéüÂâá‰æÜÂºïÂ∞éÊÉÖÁØÄË®òÊÜ∂ËÉΩÂäõÁöÑÁôºÂ±ïÔºå‰ª•‰æøÈÄô‰∫õËÉΩÂäõËÉΩÂä†Âº∑ËÄå‰∏çÊòØÁ†¥Â£ûËÆì AI ‰øùÊåÅÂÆâÂÖ®ÂíåÂÄºÂæó‰ø°Ë≥¥ÁöÑÂä™Âäõ„ÄÇ

##### **Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks**
2501.11733v1 by Zhenhailong Wang, Haiyang Xu, Junyang Wang, Xi Zhang, Ming Yan, Ji Zhang, Fei Huang, Heng Ji

Smartphones have become indispensable in modern life, yet navigating complex
tasks on mobile devices often remains frustrating. Recent advancements in large
multimodal model (LMM)-based mobile agents have demonstrated the ability to
perceive and act in mobile environments. However, current approaches face
significant limitations: they fall short in addressing real-world human needs,
struggle with reasoning-intensive and long-horizon tasks, and lack mechanisms
to learn and improve from prior experiences. To overcome these challenges, we
introduce Mobile-Agent-E, a hierarchical multi-agent framework capable of
self-evolution through past experience. By hierarchical, we mean an explicit
separation of high-level planning and low-level action execution. The framework
comprises a Manager, responsible for devising overall plans by breaking down
complex tasks into subgoals, and four subordinate agents--Perceptor, Operator,
Action Reflector, and Notetaker--which handle fine-grained visual perception,
immediate action execution, error verification, and information aggregation,
respectively. Mobile-Agent-E also features a novel self-evolution module which
maintains a persistent long-term memory comprising Tips and Shortcuts. Tips are
general guidance and lessons learned from prior tasks on how to effectively
interact with the environment. Shortcuts are reusable, executable sequences of
atomic operations tailored for specific subroutines. The inclusion of Tips and
Shortcuts facilitates continuous refinement in performance and efficiency.
Alongside this framework, we introduce Mobile-Eval-E, a new benchmark featuring
complex mobile tasks requiring long-horizon, multi-app interactions. Empirical
results show that Mobile-Agent-E achieves a 22% absolute improvement over
previous state-of-the-art approaches across three foundation model backbones.
Project page: https://x-plug.github.io/MobileAgent.

ÊëòË¶ÅÔºöÊô∫ÊÖßÂûãÊâãÊ©üÂú®Áèæ‰ª£ÁîüÊ¥ª‰∏≠Â∑≤‰∏çÂèØÊàñÁº∫ÔºåÁÑ∂ËÄåÂú®Ë°åÂãïË£ùÁΩÆ‰∏äÂü∑Ë°åË§áÈõúÁöÑ‰ªªÂãôÂæÄÂæÄ‰ª§‰∫∫Ê≤ÆÂñ™„ÄÇÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°Âûã (LMM) ÁÇ∫Âü∫Á§éÁöÑË°åÂãï‰ª£ÁêÜÁ®ãÂºèÂú®ÊúÄËøëÁöÑÈÄ≤Â±ï‰∏≠Â∑≤Â±ïÁèæÂá∫ÊÑüÁü•ÂíåÂú®Ë°åÂãïÁí∞Â¢É‰∏≠Âü∑Ë°åÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑ‰ΩúÊ≥ïÈù¢Ëá®ÈáçÂ§ßÁöÑÈôêÂà∂ÔºöÂÆÉÂÄëÁÑ°Ê≥ïÊªøË∂≥ÁèæÂØ¶‰∏ñÁïå‰∏≠‰∫∫È°ûÁöÑÈúÄÊ±Ç„ÄÅÈõ£‰ª•Êáâ‰ªòÈúÄË¶ÅÊé®ÁêÜ‰∏îÊôÇÈñìË∑®Â∫¶Èï∑ÁöÑ‰ªªÂãôÔºåËÄå‰∏îÁº∫‰πèÂæûÈÅéÂæÄÁ∂ìÈ©ó‰∏≠Â≠∏ÁøíÂíåÊîπÈÄ≤ÁöÑÊ©üÂà∂„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Mobile-Agent-EÔºåÈÄôÊòØ‰∏ÄÂÄãÂàÜÂ±§Â§ö‰ª£ÁêÜÊû∂ÊßãÔºåËÉΩÂ§†ÈÄèÈÅéÈÅéÂæÄÁ∂ìÈ©óËá™ÊàëÊºîÈÄ≤„ÄÇÊâÄË¨ÇÂàÜÂ±§ÔºåÊÑèÊåáÂ∞áÈ´òÈöéË¶èÂäÉÂíå‰ΩéÈöéÂãï‰ΩúÂü∑Ë°åÊòéÁ¢∫ÂàÜÈñã„ÄÇÊ≠§Êû∂ÊßãÂåÖÂê´‰∏ÄÂÄãÁÆ°ÁêÜÂì°ÔºåË≤†Ë≤¨ÈÄèÈÅéÂ∞áË§áÈõú‰ªªÂãôÂàÜËß£ÊàêÂ≠êÁõÆÊ®ô‰æÜÊì¨ÂÆöÊï¥È´îË®àÁï´Ôºå‰ª•ÂèäÂõõÂÄãÂæûÂ±¨‰ª£ÁêÜÁ®ãÂºèÔºåÂàÜÂà•ÁÇ∫ÊÑüÁü•Âô®„ÄÅÊìç‰ΩúÂì°„ÄÅÂãï‰ΩúÂèçÂ∞ÑÂô®ÂíåÁ≠ÜË®òÂì°ÔºåË≤†Ë≤¨ËôïÁêÜÁ¥∞ÂæÆÁöÑË¶ñË¶∫ÊÑüÁü•„ÄÅÁ´ãÂç≥Âãï‰ΩúÂü∑Ë°å„ÄÅÈåØË™§È©óË≠âÂíåË≥áË®äÂΩôÊï¥„ÄÇMobile-Agent-E ‰πüÂÖ∑ÂÇô‰∏ÄÂÄãÊñ∞Á©éÁöÑËá™ÊàëÊºîÈÄ≤Ê®°ÁµÑÔºåÁ∂≠Ë≠∑‰∏ÄÂÄãÊåÅ‰πÖÁöÑÈï∑ÊúüË®òÊÜ∂ÔºåÂåÖÂê´ÊèêÁ§∫ÂíåÊç∑Âæë„ÄÇÊèêÁ§∫ÊòØÂæûÈÅéÂæÄ‰ªªÂãô‰∏≠Â≠∏Âà∞ÁöÑÈÄöÁî®ÊåáÂ∞éÂíåÊïôË®ìÔºåË™™ÊòéÂ¶Ç‰ΩïÊúâÊïàËàáÁí∞Â¢É‰∫íÂãï„ÄÇÊç∑ÂæëÊòØÂèØ‰ª•ÈáçË§á‰ΩøÁî®ÁöÑÂèØÂü∑Ë°åÂéüÂ≠êÊìç‰ΩúÂ∫èÂàóÔºåÂ∞àÈñÄÁî®ÊñºÁâπÂÆöÂ≠êÂ∏∏Âºè„ÄÇÂåÖÂê´ÊèêÁ§∫ÂíåÊç∑ÂæëÊúâÂä©ÊñºÊåÅÁ∫åÊîπÂñÑÊïàËÉΩÂíåÊïàÁéá„ÄÇÈô§‰∫ÜÈÄôÂÄãÊû∂ÊßãÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü Mobile-Eval-EÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñÔºåÂåÖÂê´ÈúÄË¶ÅÈï∑ÊôÇÈñìË∑®Â∫¶„ÄÅÂ§öÊáâÁî®Á®ãÂºè‰∫íÂãïÁöÑË§áÈõúË°åÂãï‰ªªÂãô„ÄÇÂØ¶Ë≠âÁµêÊûúÈ°ØÁ§∫ÔºåMobile-Agent-E Âú®‰∏âÂÄãÂü∫Á§éÊ®°ÂûãÈ™®Âππ‰∏äÔºåÊØîÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤‰ΩúÊ≥ïÁç≤Âæó‰∫Ü 22% ÁöÑÁµïÂ∞çÊîπÂñÑ„ÄÇÂ∞àÊ°àÈ†ÅÈù¢Ôºöhttps://x-plug.github.io/MobileAgent„ÄÇ

##### **Transformer Vibration Forecasting for Advancing Rail Safety and Maintenance 4.0**
2501.11730v1 by Dar√≠o C. Larese, Almudena Bravo Cerrada, Gabriel Dambrosio Tomei, Alejandro Guerrero-L√≥pez, Pablo M. Olmos, Mar√≠a Jes√∫s G√≥mez Garc√≠a

Maintaining railway axles is critical to preventing severe accidents and
financial losses. The railway industry is increasingly interested in advanced
condition monitoring techniques to enhance safety and efficiency, moving beyond
traditional periodic inspections toward Maintenance 4.0.
  This study introduces a robust Deep Autoregressive solution that integrates
seamlessly with existing systems to avert mechanical failures. Our approach
simulates and predicts vibration signals under various conditions and fault
scenarios, improving dataset robustness for more effective detection systems.
These systems can alert maintenance needs, preventing accidents preemptively.
We use experimental vibration signals from accelerometers on train axles.
  Our primary contributions include a transformer model, ShaftFormer, designed
for processing time series data, and an alternative model incorporating
spectral methods and enhanced observation models. Simulating vibration signals
under diverse conditions mitigates the high cost of obtaining experimental
signals for all scenarios. Given the non-stationary nature of railway vibration
signals, influenced by speed and load changes, our models address these
complexities, offering a powerful tool for predictive maintenance in the rail
industry.

ÊëòË¶ÅÔºöÁ∂≠Ë≠∑ÈêµË∑ØËªäËª∏Â∞çÊñºÈ†êÈò≤Âö¥Èáç‰∫ãÊïÖÂíåË≤°ÂãôÊêçÂ§±Ëá≥ÈóúÈáçË¶Å„ÄÇÈêµË∑ØÁî¢Ê•≠Ë∂ä‰æÜË∂äÊúâËààË∂£Êé°Áî®ÂÖàÈÄ≤ÁöÑÁãÄÊÖãÁõ£ÊéßÊäÄË°ìÔºå‰ª•ÊèêÂçáÂÆâÂÖ®ÊÄßÂíåÊïàÁéáÔºåË∂ÖË∂äÂÇ≥Áµ±ÁöÑÂÆöÊúüÊ™¢Êü•ÔºåÈÇÅÂêëÁ∂≠Ë≠∑ 4.0„ÄÇ
Êú¨Á†îÁ©∂‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂº∑ÂÅ•ÁöÑÊ∑±Â∫¶Ëá™Ëø¥Ê≠∏Ëß£Ê±∫ÊñπÊ°àÔºåÂèØËàáÁèæÊúâÁ≥ªÁµ±ÁÑ°Á∏´Êï¥ÂêàÔºå‰ª•ÈÅøÂÖçÊ©üÊ¢∞ÊïÖÈöú„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ®°Êì¨ÂíåÈ†êÊ∏¨ÂêÑÁ®ÆÊ¢ù‰ª∂ÂíåÊïÖÈöúÊÉÖÂ¢É‰∏ãÁöÑÊåØÂãï‰ø°ËôüÔºåÊîπÂñÑË≥áÊñôÈõÜÁöÑÁ©©ÂÅ•ÊÄßÔºå‰ª•Âª∫Á´ãÊõ¥ÊúâÊïàÁöÑÂÅµÊ∏¨Á≥ªÁµ±„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÂèØ‰ª•ÁôºÂá∫Á∂≠Ë≠∑ÈúÄÊ±ÇÁöÑË≠¶Á§∫ÔºåÈ†êÈò≤‰∫ãÊïÖÁôºÁîü„ÄÇÊàëÂÄë‰ΩøÁî®‰æÜËá™ÁÅ´ËªäËªäËª∏Âä†ÈÄüÂ∫¶Ë®àÁöÑÂØ¶È©óÊåØÂãï‰ø°Ëôü„ÄÇ
ÊàëÂÄëÁöÑ‰∏ªË¶ÅË≤¢ÁçªÂåÖÊã¨‰∏ÄÂÄãÂ∞àÁÇ∫ËôïÁêÜÊôÇÈñìÂ∫èÂàóË≥áÊñôËÄåË®≠Ë®àÁöÑTransformerÊ®°Âûã ShaftFormerÔºå‰ª•Âèä‰∏ÄÂÄãÁµêÂêàÂÖâË≠úÊñπÊ≥ïÂíåÂ¢ûÂº∑ËßÄÊ∏¨Ê®°ÂûãÁöÑÊõø‰ª£Ê®°Âûã„ÄÇÂú®ÂêÑÁ®ÆÊ¢ù‰ª∂‰∏ãÊ®°Êì¨ÊåØÂãï‰ø°ËôüÂèØÈôç‰ΩéÂèñÂæóÊâÄÊúâÊÉÖÂ¢ÉÂØ¶È©ó‰ø°ËôüÁöÑÈ´òÊòÇÊàêÊú¨„ÄÇËÄÉÈáèÂà∞ÈêµË∑ØÊåØÂãï‰ø°ËôüÊúÉÂèóÂà∞ÈÄüÂ∫¶ÂíåË≤†ËºâËÆäÂåñÁöÑÂΩ±ÈüøÔºå‰∏îÂÖ∑ÊúâÈùûÁ©©ÊÖãÁâπÊÄßÔºåÊàëÂÄëÁöÑÊ®°ÂûãËß£Ê±∫‰∫ÜÈÄô‰∫õË§áÈõúÊÄßÔºåÁÇ∫ÈêµË∑ØÁî¢Ê•≠ÁöÑÈ†êÊ∏¨Á∂≠Ë≠∑Êèê‰æõ‰∫ÜÂº∑Â§ßÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **Explain-Query-Test: Self-Evaluating LLMs Via Explanation and Comprehension Discrepancy**
2501.11721v1 by Saeid Asgari Taghanaki, Joao Monteiro

Large language models (LLMs) have demonstrated remarkable proficiency in
generating detailed and coherent explanations of complex concepts. However, the
extent to which these models truly comprehend the concepts they articulate
remains unclear. To assess the level of comprehension of a model relative to
the content it generates, we implemented a self-evaluation pipeline where
models: (i) given a topic generate an excerpt with information about the topic,
(ii) given an excerpt generate question-answer pairs, and finally (iii) given a
question generate an answer. We refer to this self-evaluation approach as
Explain-Query-Test (EQT). Interestingly, the accuracy on generated questions
resulting from running the EQT pipeline correlates strongly with the model
performance as verified by typical benchmarks such as MMLU-Pro. In other words,
EQT's performance is predictive of MMLU-Pro's, and EQT can be used to rank
models without the need for any external source of evaluation data other than
lists of topics of interest. Moreover, our results reveal a disparity between
the models' ability to produce detailed explanations and their performance on
questions related to those explanations. This gap highlights fundamental
limitations in the internal knowledge representation and reasoning abilities of
current LLMs. We release the code at https://github.com/asgsaeid/EQT.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫ÂçìË∂äÁöÑÁÜüÁ∑¥Â∫¶ÔºåËÉΩÁî¢ÁîüË§áÈõúÊ¶ÇÂøµÁöÑË©≥Á¥∞‰∏îÈÄ£Ë≤´ÁöÑËß£Èáã„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÊòØÂê¶ÁúüÊ≠£ÁêÜËß£ÂÆÉÂÄëÊâÄË°®ÈÅîÁöÑÊ¶ÇÂøµÔºåÈÄô‰∏ÄÈªû‰ªç‰∏çÊ∏ÖÊ•ö„ÄÇÁÇ∫‰∫ÜË©ï‰º∞Ê®°ÂûãÁõ∏Â∞çÊñºÂÆÉÊâÄÁî¢ÁîüÂÖßÂÆπÁöÑÁêÜËß£Á®ãÂ∫¶ÔºåÊàëÂÄëÂØ¶‰Ωú‰∫Ü‰∏ÄÂÄãËá™ÊàëË©ï‰º∞ÁÆ°ÈÅìÔºåÂÖ∂‰∏≠Ê®°ÂûãÔºö(i) Áµ¶ÂÆö‰∏ÄÂÄã‰∏ªÈ°åÔºåÁî¢Áîü‰∏ÄÊÆµÂåÖÂê´ÈóúÊñºË©≤‰∏ªÈ°åÁöÑË≥áË®äÁöÑÊëòÈåÑÔºå(ii) Áµ¶ÂÆö‰∏ÄÂÄãÊëòÈåÑÔºåÁî¢ÁîüÂïèÈ°å-Á≠îÊ°àÂ∞çÔºåÊúÄÂæå (iii) Áµ¶ÂÆö‰∏ÄÂÄãÂïèÈ°åÔºåÁî¢Áîü‰∏ÄÂÄãÁ≠îÊ°à„ÄÇÊàëÂÄëÂ∞áÈÄôÁ®ÆËá™ÊàëË©ï‰º∞ÊñπÊ≥ïÁ®±ÁÇ∫„ÄåËß£Èáã-Êü•Ë©¢-Ê∏¨Ë©¶„Äç(EQT)„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂü∑Ë°å EQT ÁÆ°ÈÅìÊâÄÁî¢ÁîüÁöÑÂïèÈ°åÁöÑÊ∫ñÁ¢∫ÊÄßËàáÊ®°ÂûãÊïàËÉΩÂØÜÂàáÁõ∏ÈóúÔºåÈÄôÂ∑≤Áî±ÂÖ∏ÂûãÁöÑÂü∫Ê∫ñÔºà‰æãÂ¶Ç MMLU-ProÔºâÈ©óË≠â„ÄÇÊèõÂè•Ë©±Ë™™ÔºåEQT ÁöÑÊïàËÉΩÂèØ‰ª•È†êÊ∏¨ MMLU-Pro ÁöÑÊïàËÉΩÔºå‰∏î EQT ÂèØÁî®ÊñºÂ∞çÊ®°ÂûãÈÄ≤Ë°åÊéíÂêçÔºåËÄåÁÑ°ÈúÄ‰ªª‰ΩïÂ§ñÈÉ®Ë©ï‰º∞Ë≥áÊñô‰æÜÊ∫êÔºåÂè™Ë¶ÅÊúâÊÑüËààË∂£ÁöÑ‰∏ªÈ°åÊ∏ÖÂñÆÂç≥ÂèØ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÁµêÊûúÊè≠Á§∫‰∫ÜÊ®°ÂûãÁî¢ÁîüË©≥Á¥∞Ëß£ÈáãÁöÑËÉΩÂäõËàáÂÆÉÂÄëÂ∞çËàáÈÄô‰∫õËß£ÈáãÁõ∏ÈóúÁöÑÂïèÈ°åÁöÑÊïàËÉΩ‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÈÄôÂÄãÂ∑ÆË∑ùÁ™ÅÈ°Ø‰∫ÜÁï∂Ââç LLM Âú®ÂÖßÈÉ®Áü•Ë≠òË°®Á§∫ÂíåÊé®ÁêÜËÉΩÂäõÊñπÈù¢ÁöÑÊ†πÊú¨ÈôêÂà∂„ÄÇÊàëÂÄëÂú® https://github.com/asgsaeid/EQT ÈáãÂá∫Á®ãÂºèÁ¢º„ÄÇ

##### **GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**
2501.11715v1 by Wenjie Kang, Lize Jiskoot, Peter De Deyn, Geert Biessels, Huiberdina Koek, Jurgen Claassen, Huub Middelkoop, Wiesje Flier, Willemijn J. Jansen, Stefan Klein, Esther Bron

Deep learning methods based on Convolutional Neural Networks (CNNs) have
shown great potential to improve early and accurate diagnosis of Alzheimer's
disease (AD) dementia based on imaging data. However, these methods have yet to
be widely adopted in clinical practice, possibly due to the limited
interpretability of deep learning models. The Explainable Boosting Machine
(EBM) is a glass-box model but cannot learn features directly from input
imaging data. In this study, we propose a novel interpretable model that
combines CNNs and EBMs for the diagnosis and prediction of AD. We develop an
innovative training strategy that alternatingly trains the CNN component as a
feature extractor and the EBM component as the output block to form an
end-to-end model. The model takes imaging data as input and provides both
predictions and interpretable feature importance measures. We validated the
proposed model on the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset and the Health-RI Parelsnoer Neurodegenerative Diseases Biobank (PND)
as an external testing set. The proposed model achieved an area-under-the-curve
(AUC) of 0.956 for AD and control classification, and 0.694 for the prediction
of conversion of mild cognitive impairment (MCI) to AD on the ADNI cohort. The
proposed model is a glass-box model that achieves a comparable performance with
other state-of-the-art black-box models. Our code is publicly available at:
https://anonymous.4open.science/r/GL-ICNN.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÂ∑≤È°ØÁ§∫Âá∫Ê•µÂ§ßÁöÑÊΩõÂäõÔºåÂèØÊ†πÊìöÂΩ±ÂÉèË≥áÊñôÊîπÂñÑÈòøËå≤Êµ∑ÈªòÁóá (AD) Â§±Êô∫ÁóáÁöÑÊó©ÊúüÊ∫ñÁ¢∫Ë®∫Êñ∑„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂ∞öÊú™Âª£Ê≥õÊáâÁî®ÊñºËá®Â∫äÂØ¶Âãô‰∏≠ÔºåÈÄôÂèØËÉΩÊòØÁî±ÊñºÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÊúâÈôê„ÄÇÂèØËß£ÈáãÊèêÂçáÊ©ü (EBM) ÊòØÂÄãÁéªÁíÉÁõíÊ®°ÂûãÔºå‰ΩÜÁÑ°Ê≥ïÁõ¥Êé•ÂæûËº∏ÂÖ•ÂΩ±ÂÉèË≥áÊñô‰∏≠Â≠∏ÁøíÁâπÂæµ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁµêÂêà CNN Âíå EBM ÁöÑÊñ∞ÂèØËß£ÈáãÊ®°ÂûãÔºåÁî®ÊñºË®∫Êñ∑ÂíåÈ†êÊ∏¨ AD„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑË®ìÁ∑¥Á≠ñÁï•Ôºå‰∫§ÊõøË®ìÁ∑¥ CNN ÁµÑ‰ª∂‰ΩúÁÇ∫ÁâπÂæµËêÉÂèñÂô®Ôºå‰∏¶Ë®ìÁ∑¥ EBM ÁµÑ‰ª∂‰ΩúÁÇ∫Ëº∏Âá∫ÂçÄÂ°äÔºå‰ª•ÂΩ¢ÊàêÁ´ØÂ∞çÁ´ØÊ®°Âûã„ÄÇÊ≠§Ê®°ÂûãÂ∞áÂΩ±ÂÉèË≥áÊñô‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰∏¶Êèê‰æõÈ†êÊ∏¨ÂíåÂèØËß£ÈáãÁöÑÁâπÂæµÈáçË¶ÅÊÄßÊ∏¨Èáè„ÄÇÊàëÂÄëÂú®ÈòøËå≤Êµ∑ÈªòÁóáÁ•ûÁ∂ìÂΩ±ÂÉèÂÄ°Ë≠∞ (ADNI) Ë≥áÊñôÈõÜÂíå Health-RI Parelsnoer Á•ûÁ∂ìÈÄÄÂåñÁñæÁóÖÁîüÁâ©Ë≥áÊñôÂ∫´ (PND) ‰∏äÈ©óË≠â‰∫ÜÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÔºå‰ΩúÁÇ∫Â§ñÈÉ®Ê∏¨Ë©¶ÈõÜ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú® AD ÂíåÂ∞çÁÖßÂàÜÈ°û‰∏≠ÈÅîÂà∞‰∫Ü 0.956 ÁöÑÊõ≤Á∑ö‰∏ãÈù¢Á©ç (AUC)Ôºå‰∏¶Âú® ADNI ÈöäÂàó‰∏≠È†êÊ∏¨ËºïÂ∫¶Ë™çÁü•ÈöúÁ§ô (MCI) ËΩâÂåñÁÇ∫ AD ÊôÇÈÅîÂà∞‰∫Ü 0.694„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÊòØ‰∏ÄÂÄãÁéªÁíÉÁõíÊ®°ÂûãÔºåÂÖ∂ÊïàËÉΩËàáÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÈªëÁõíÊ®°ÂûãÁõ∏Áï∂„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂÖ¨ÈñãÂèñÂæóÔºöhttps://anonymous.4open.science/r/GL-ICNN„ÄÇ</paragraph>

##### **YouLeQD: Decoding the Cognitive Complexity of Questions and Engagement in Online Educational Videos from Learners' Perspectives**
2501.11712v1 by Nong Ming, Sachin Sharma, Jiho Noh

Questioning is a fundamental aspect of education, as it helps assess
students' understanding, promotes critical thinking, and encourages active
engagement. With the rise of artificial intelligence in education, there is a
growing interest in developing intelligent systems that can automatically
generate and answer questions and facilitate interactions in both virtual and
in-person education settings. However, to develop effective AI models for
education, it is essential to have a fundamental understanding of questioning.
In this study, we created the YouTube Learners' Questions on Bloom's Taxonomy
Dataset (YouLeQD), which contains learner-posed questions from YouTube lecture
video comments. Along with the dataset, we developed two RoBERTa-based
classification models leveraging Large Language Models to detect questions and
analyze their cognitive complexity using Bloom's Taxonomy. This dataset and our
findings provide valuable insights into the cognitive complexity of
learner-posed questions in educational videos and their relationship with
interaction metrics. This can aid in the development of more effective AI
models for education and improve the overall learning experience for students.

ÊëòË¶ÅÔºöÊèêÂïèÊòØÊïôËÇ≤ÁöÑÂü∫Êú¨Èù¢ÂêëÔºåÂõ†ÁÇ∫ÂÆÉÊúâÂä©ÊñºË©ïÈáèÂ≠∏ÁîüÁöÑÁêÜËß£Âäõ„ÄÅ‰øÉÈÄ≤ÊâπÂà§ÊÄßÊÄùËÄÉÔºå‰∏¶ÈºìÂãµÁ©çÊ•µÂèÉËàá„ÄÇÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖßÂú®ÊïôËÇ≤‰∏≠ÁöÑÂ¥õËµ∑ÔºåÈñãÁôºÊô∫ÊÖßÁ≥ªÁµ±‰ª•Ëá™ÂãïÁî¢ÁîüÂíåÂõûÁ≠îÂïèÈ°åÔºå‰∏¶‰øÉÈÄ≤ËôõÊì¨ÂíåÈù¢Â∞çÈù¢ÊïôËÇ≤Áí∞Â¢É‰∏≠ÁöÑ‰∫íÂãïÔºåË∂ä‰æÜË∂äÂèóÂà∞ÈáçË¶ñ„ÄÇÁÑ∂ËÄåÔºåË¶ÅÈñãÁôºÂá∫ÊúâÊïàÁöÑÊïôËÇ≤ AI Ê®°ÂûãÔºåÂ∞çÊñºÊèêÂïèÊúâÂü∫Êú¨ÁöÑ‰∫ÜËß£Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü YouTube Â≠∏ÁøíËÄÖÂú® Bloom ÂàÜÈ°ûÊ≥ï‰∏äÁöÑÂïèÈ°åË≥áÊñôÈõÜ (YouLeQD)ÔºåÂÖ∂‰∏≠ÂåÖÂê´Â≠∏ÁøíËÄÖÂú® YouTube Ë™≤Á®ãÂΩ±ÁâáÁïôË®Ä‰∏≠ÊèêÂá∫ÁöÑÂïèÈ°å„ÄÇÈô§‰∫ÜË≥áÊñôÈõÜ‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÈñãÁôº‰∫ÜÂÖ©ÂÄãÂü∫Êñº RoBERTa ÁöÑÂàÜÈ°ûÊ®°ÂûãÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã‰æÜÂÅµÊ∏¨ÂïèÈ°å‰∏¶‰ΩøÁî® Bloom ÂàÜÈ°ûÊ≥ïÂàÜÊûêÂÖ∂Ë™çÁü•Ë§áÈõúÊÄß„ÄÇÈÄôÂÄãË≥áÊñôÈõÜÂíåÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£ÔºåË™™ÊòéÂ≠∏ÁøíËÄÖÂú®ÊïôËÇ≤ÂΩ±Áâá‰∏≠ÊèêÂá∫ÁöÑÂïèÈ°åÁöÑË™çÁü•Ë§áÈõúÊÄßÔºå‰ª•ÂèäÂÆÉÂÄëËàá‰∫íÂãïÊåáÊ®ôÁöÑÈóú‰øÇ„ÄÇÈÄôÊúâÂä©ÊñºÈñãÁôºÊõ¥ÊúâÊïàÁöÑÊïôËÇ≤ AI Ê®°ÂûãÔºå‰∏¶ÊîπÂñÑÂ≠∏ÁîüÁöÑÊï¥È´îÂ≠∏ÁøíÈ´îÈ©ó„ÄÇ

##### **Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**
2501.11705v1 by Brian E. Perron, Lauri Goldkind, Zia Qi, Bryan G. Victor

This paper examines the responsible integration of artificial intelligence
(AI) in human services organizations (HSOs), proposing a nuanced framework for
evaluating AI applications across multiple dimensions of risk. The authors
argue that ethical concerns about AI deployment -- including professional
judgment displacement, environmental impact, model bias, and data laborer
exploitation -- vary significantly based on implementation context and specific
use cases. They challenge the binary view of AI adoption, demonstrating how
different applications present varying levels of risk that can often be
effectively managed through careful implementation strategies. The paper
highlights promising solutions, such as local large language models, that can
facilitate responsible AI integration while addressing common ethical concerns.
The authors propose a dimensional risk assessment approach that considers
factors like data sensitivity, professional oversight requirements, and
potential impact on client wellbeing. They conclude by outlining a path forward
that emphasizes empirical evaluation, starting with lower-risk applications and
building evidence-based understanding through careful experimentation. This
approach enables organizations to maintain high ethical standards while
thoughtfully exploring how AI might enhance their capacity to serve clients and
communities effectively.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®‰∫∫È°ûÊúçÂãôÁµÑÁπî (HSO) ‰∏≠Ë≤†Ë≤¨‰ªªÁöÑÊï¥ÂêàÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ¥∞Á∑ªÁöÑÊ°ÜÊû∂ÔºåÁî®ÊñºË©ï‰º∞ AI ÊáâÁî®Âú®Â§öÂÄãÈ¢®Èö™Á∂≠Â∫¶„ÄÇ‰ΩúËÄÖË™çÁÇ∫ÔºåÂ∞ç AI ÈÉ®ÁΩ≤ÁöÑÈÅìÂæ∑ËÄÉÈáè‚Äî‚ÄîÂåÖÊã¨Â∞àÊ•≠Âà§Êñ∑ÁöÑÂèñ‰ª£„ÄÅÁí∞Â¢ÉÂΩ±Èüø„ÄÅÊ®°ÂûãÂÅèÂ∑ÆÂíåË≥áÊñôÂ∑•‰ΩúËÄÖÁöÑÂâùÂâä‚Äî‚ÄîÊúÉÊ†πÊìöÂØ¶ÊñΩËÉåÊôØÂíåÂÖ∑È´î‰ΩøÁî®Ê°à‰æãËÄåÊúâÈ°ØËëóÁöÑ‰∏çÂêå„ÄÇ‰ªñÂÄëÊåëÊà∞‰∫Ü AI Êé°Áî®‰∫åÂÖÉË´ñÁöÑËßÄÈªûÔºåË™™Êòé‰∫Ü‰∏çÂêåÁöÑÊáâÁî®Â¶Ç‰ΩïÂëàÁèæ‰∏çÂêåÁ®ãÂ∫¶ÁöÑÈ¢®Èö™ÔºåËÄåÈÄô‰∫õÈ¢®Èö™ÈÄöÂ∏∏ÂèØ‰ª•ÈÄèÈÅé‰ªîÁ¥∞ÁöÑÂØ¶ÊñΩÁ≠ñÁï•‰æÜÊúâÊïàÁÆ°ÁêÜ„ÄÇÊú¨ÊñáÈáçÈªû‰ªãÁ¥π‰∫ÜÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰æãÂ¶ÇÊú¨Âú∞Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÂÆÉÂèØ‰ª•Âú®Ëß£Ê±∫Â∏∏Ë¶ãÁöÑÈÅìÂæ∑ÂïèÈ°åÁöÑÂêåÊôÇÔºå‰øÉÈÄ≤Ë≤†Ë≤¨‰ªªÁöÑ AI Êï¥Âêà„ÄÇ‰ΩúËÄÖÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∂≠Â∫¶È¢®Èö™Ë©ï‰º∞ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïËÄÉÊÖÆ‰∫ÜË≥áÊñôÊïèÊÑüÂ∫¶„ÄÅÂ∞àÊ•≠Áõ£Áù£ÈúÄÊ±ÇÂíåÂ∞çÂÆ¢Êà∂Á¶èÁ•âÁöÑÊΩõÂú®ÂΩ±ÈüøÁ≠âÂõ†Á¥†„ÄÇ‰ªñÂÄëÊúÄÂæåÊ¶ÇËø∞‰∫Ü‰∏ÄÊ¢ùÂâçÈÄ≤ÁöÑÈÅìË∑ØÔºåÂº∑Ë™øÂØ¶Ë≠âË©ï‰º∞ÔºåÂæû‰ΩéÈ¢®Èö™ÊáâÁî®ÈñãÂßãÔºå‰∏¶ÈÄèÈÅé‰ªîÁ¥∞ÁöÑÂØ¶È©óÂª∫Á´ãÂü∫ÊñºË≠âÊìöÁöÑÁêÜËß£„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰ΩøÁµÑÁπîËÉΩÂ§†Âú®Ê∑±ÊÄùÁÜüÊÖÆÂú∞Êé¢Ë®é AI Â¶Ç‰ΩïÂ¢ûÂº∑ÂÖ∂ÊúâÊïàÊúçÂãôÂÆ¢Êà∂ÂíåÁ§æÁæ§ÁöÑËÉΩÂäõÁöÑÂêåÊôÇÔºåÁ∂≠ÊåÅÈ´òÈÅìÂæ∑Ê®ôÊ∫ñ„ÄÇ

##### **Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling**
2501.11651v1 by Zhenyu Hou, Xin Lv, Rui Lu, Jiajie Zhang, Yujiang Li, Zijun Yao, Juanzi Li, Jie Tang, Yuxiao Dong

Large language models (LLMs) have demonstrated remarkable capabilities in
complex reasoning tasks. However, existing approaches mainly rely on imitation
learning and struggle to achieve effective test-time scaling. While
reinforcement learning (RL) holds promise for enabling self-exploration and
learning from feedback, recent attempts yield only modest improvements in
complex reasoning. In this paper, we present T1 to scale RL by encouraging
exploration and understand inference scaling. We first initialize the LLM using
synthesized chain-of-thought data that integrates trial-and-error and
self-verification. To scale RL training, we promote increased sampling
diversity through oversampling. We further employ an entropy bonus as an
auxiliary loss, alongside a dynamic anchor for regularization to facilitate
reward optimization. We demonstrate that T1 with open LLMs as its base exhibits
inference scaling behavior and achieves superior performance on challenging
math reasoning benchmarks. For example, T1 with Qwen2.5-32B as the base model
outperforms the recent Qwen QwQ-32B-Preview model on MATH500, AIME2024, and
Omni-math-500. More importantly, we present a simple strategy to examine
inference scaling, where increased inference budgets directly lead to T1's
better performance without any additional verification. We will open-source the
T1 models and the data used to train them at \url{https://github.com/THUDM/T1}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®Ë§áÈõúÊé®ÁêÜ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈùûÂá°ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ï‰∏ªË¶Å‰æùË≥¥ÊñºÊ®°‰ªøÂ≠∏ÁøíÔºå‰∏¶‰∏îÈõ£‰ª•ÂØ¶ÁèæÊúâÊïàÁöÑÊ∏¨Ë©¶ÊôÇÈñìÊì¥Â±ï„ÄÇÈõñÁÑ∂Âº∑ÂåñÂ≠∏ÁøíÔºàRLÔºâÊúâÊúõÂØ¶ÁèæËá™ÊàëÊé¢Á¥¢ÂíåÂæûÂõûÈ•ã‰∏≠Â≠∏ÁøíÔºå‰ΩÜÊúÄËøëÁöÑÂòóË©¶Âú®Ë§áÈõúÊé®ÁêÜ‰∏≠ÂÉÖÁî¢Áîü‰∫ÜÈÅ©Â∫¶ÁöÑÊîπÈÄ≤„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ T1 ‰æÜÊì¥Â±ï RLÔºå‰ª•ÈºìÂãµÊé¢Á¥¢‰∏¶‰∫ÜËß£Êé®ÁêÜÊì¥Â±ï„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®Á∂úÂêàÁöÑÊÄùÁ∂≠ÈèàÊï∏ÊìöÂàùÂßãÂåñ LLMÔºåË©≤Êï∏ÊìöÊï¥Âêà‰∫ÜË©¶ÈåØÂíåËá™ÊàëÈ©óË≠â„ÄÇÁÇ∫‰∫ÜÊì¥Â±ï RL Ë®ìÁ∑¥ÔºåÊàëÂÄëÈÄöÈÅéÈÅéÂ∫¶Êé°Ê®£‰æÜ‰øÉÈÄ≤Â¢ûÂä†Êé°Ê®£Â§öÊ®£ÊÄß„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé°Áî®ÁÜµÁçéÂãµ‰ΩúÁÇ∫ËºîÂä©ÊêçÂ§±Ôºå‰∏¶Êé°Áî®ÂãïÊÖãÈå®ÈªûÈÄ≤Ë°åÊ≠£ÂâáÂåñÔºå‰ª•‰øÉÈÄ≤ÁçéÂãµÂÑ™Âåñ„ÄÇÊàëÂÄëË≠âÊòé‰∫Ü‰ª•ÈñãÊîæÂºè LLM ÁÇ∫Âü∫Á§éÁöÑ T1 Ë°®ÁèæÂá∫Êé®ÁêÜÊì¥Â±ïË°åÁÇ∫Ôºå‰∏¶Âú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÊï∏Â≠∏Êé®ÁêÜÂü∫Ê∫ñ‰∏äÂèñÂæó‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇ‰æãÂ¶ÇÔºå‰ª• Qwen2.5-32B ‰ΩúÁÇ∫Âü∫Á§éÊ®°ÂûãÁöÑ T1 Âú® MATH500„ÄÅAIME2024 Âíå Omni-math-500 ‰∏äÂÑ™ÊñºÊúÄËøëÁöÑ Qwen QwQ-32B-Preview Ê®°Âûã„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆÁöÑÁ≠ñÁï•‰æÜÊ™¢Êü•Êé®ÁêÜÊì¥Â±ïÔºåÂÖ∂‰∏≠Â¢ûÂä†ÁöÑÊé®ÁêÜÈ†êÁÆóÁõ¥Êé•Â∞éËá¥ T1 ÁöÑÊõ¥Â•ΩÊÄßËÉΩÔºåËÄåÁÑ°ÈúÄ‰ªª‰ΩïÈ°çÂ§ñÁöÑÈ©óË≠â„ÄÇÊàëÂÄëÂ∞áÂú® https://github.com/THUDM/T1 ÈñãÊ∫ê T1 Ê®°ÂûãÂíåÁî®ÊñºË®ìÁ∑¥ÂÆÉÂÄëÁöÑÊï∏Êìö„ÄÇ

##### **StAyaL | Multilingual Style Transfer**
2501.11639v1 by Karishma Thakrar, Katrina Lawrence, Kyle Howard

Stylistic text generation plays a vital role in enhancing communication by
reflecting the nuances of individual expression. This paper presents a novel
approach for generating text in a specific speaker's style across different
languages. We show that by leveraging only 100 lines of text, an individuals
unique style can be captured as a high-dimensional embedding, which can be used
for both text generation and stylistic translation. This methodology breaks
down the language barrier by transferring the style of a speaker between
languages. The paper is structured into three main phases: augmenting the
speaker's data with stylistically consistent external sources, separating style
from content using machine learning and deep learning techniques, and
generating an abstract style profile by mean pooling the learned embeddings.
The proposed approach is shown to be topic-agnostic, with test accuracy and F1
scores of 74.9\% and 0.75, respectively. The results demonstrate the potential
of the style profile for multilingual communication, paving the way for further
applications in personalized content generation and cross-linguistic stylistic
transfer.

ÊëòË¶ÅÔºöÈ¢®Ê†ºÂåñÁöÑÊñáÂ≠óÁîüÊàêÂú®Âä†Âº∑Ê∫ùÈÄöÊñπÈù¢ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤ÔºåÈÄèÈÅéÂèçÊò†ÂÄã‰∫∫Ë°®ÈÅîÁöÑÁ¥∞ÂæÆÂ∑ÆÁï∞„ÄÇÈÄôÁØáË´ñÊñáÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÁî®‰æÜÁî¢ÁîüÁâπÂÆöË™™Ë©±ËÄÖÈ¢®Ê†ºÁöÑÊñáÂ≠óÔºåÊ©´Ë∑®‰∏çÂêåÁöÑË™ûË®Ä„ÄÇÊàëÂÄëÂ±ïÁ§∫Âá∫ÔºåÂè™Ë¶ÅÂà©Áî® 100 Ë°åÊñáÂ≠óÔºåÂÄã‰∫∫ÁöÑÁç®ÁâπÈ¢®Ê†ºÂ∞±ÂèØ‰ª•Ë¢´Êì∑ÂèñÁÇ∫‰∏ÄÂÄãÈ´òÁ∂≠Â∫¶ÁöÑÂÖßÂµåÔºåÈÄôÂÄãÂÖßÂµåÂèØ‰ª•Áî®ÊñºÊñáÂ≠óÁîüÊàêÂíåÈ¢®Ê†ºÂåñÁøªË≠Ø„ÄÇÈÄôÂÄãÊñπÊ≥ïÊâìÁ†¥Ë™ûË®ÄÁöÑËó©Á±¨ÔºåÂú®Ë™ûË®Ä‰πãÈñìËΩâÁßªË™™Ë©±ËÄÖÁöÑÈ¢®Ê†º„ÄÇÈÄôÁØáË´ñÊñáÁöÑÊû∂ÊßãÂàÜÊàê‰∏âÂÄã‰∏ªË¶ÅÈöéÊÆµÔºöÁî®È¢®Ê†º‰∏ÄËá¥ÁöÑÂ§ñÂú®‰æÜÊ∫ê‰æÜÊì¥ÂÖÖË™™Ë©±ËÄÖÁöÑË≥áÊñô„ÄÅ‰ΩøÁî®Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÂ∞áÈ¢®Ê†ºÂæûÂÖßÂÆπ‰∏≠ÂàÜÈõ¢Âá∫‰æÜ„ÄÅ‰ª•ÂèäÈÄèÈÅéÂπ≥ÂùáÊ±†ÂåñÂ≠∏ÁøíÂà∞ÁöÑÂÖßÂµå‰æÜÁî¢Áîü‰∏ÄÂÄãÊäΩË±°ÁöÑÈ¢®Ê†ºÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïË¢´È°ØÁ§∫ÁÇ∫Ëàá‰∏ªÈ°åÁÑ°ÈóúÔºåÊ∏¨Ë©¶Ê∫ñÁ¢∫ÁéáÂíå F1 ÂàÜÊï∏ÂàÜÂà•ÁÇ∫ 74.9% Âíå 0.75„ÄÇÁµêÊûúÂ±ïÁ§∫‰∫ÜÈ¢®Ê†ºÁâπÂæµÂú®Â§öË™ûË®ÄÊ∫ùÈÄö‰∏≠ÁöÑÊΩõÂäõÔºåÁÇ∫ÂÄã‰∫∫ÂåñÂÖßÂÆπÁîüÊàêÂíåË∑®Ë™ûË®ÄÈ¢®Ê†ºÂåñËΩâÁßªÁöÑÈÄ≤‰∏ÄÊ≠•ÊáâÁî®Èã™Ë∑Ø„ÄÇ

##### **Noise-Agnostic Multitask Whisper Training for Reducing False Alarm Errors in Call-for-Help Detection**
2501.11631v1 by Myeonghoon Ryu, June-Woo Kim, Minseok Oh, Suji Lee, Han Park

Keyword spotting is often implemented by keyword classifier to the encoder in
acoustic models, enabling the classification of predefined or open vocabulary
keywords. Although keyword spotting is a crucial task in various applications
and can be extended to call-for-help detection in emergencies, however, the
previous method often suffers from scalability limitations due to retraining
required to introduce new keywords or adapt to changing contexts. We explore a
simple yet effective approach that leverages off-the-shelf pretrained ASR
models to address these challenges, especially in call-for-help detection
scenarios. Furthermore, we observed a substantial increase in false alarms when
deploying call-for-help detection system in real-world scenarios due to noise
introduced by microphones or different environments. To address this, we
propose a novel noise-agnostic multitask learning approach that integrates a
noise classification head into the ASR encoder. Our method enhances the model's
robustness to noisy environments, leading to a significant reduction in false
alarms and improved overall call-for-help performance. Despite the added
complexity of multitask learning, our approach is computationally efficient and
provides a promising solution for call-for-help detection in real-world
scenarios.

ÊëòË¶ÅÔºöÈóúÈçµÂ≠óÈªûÈÅ∏ÈÄöÂ∏∏Áî±ÈóúÈçµÂ≠óÂàÜÈ°ûÂô®ÂØ¶‰ΩúÂà∞Á∑®Á¢ºÂô®‰∏≠ÔºåÂú®ËÅ≤Â≠∏Ê®°Âûã‰∏≠ÔºåËÉΩÂàÜÈ°ûÈ†êÂÖàÂÆöÁæ©ÊàñÈñãÊîæÂºèË©ûÂΩôÁöÑÈóúÈçµÂ≠ó„ÄÇÂÑòÁÆ°ÈóúÈçµÂ≠óÈªûÈÅ∏Âú®ÂêÑÁ®ÆÊáâÁî®Á®ãÂºè‰∏≠ÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãôÔºå‰∏¶‰∏îÂèØ‰ª•Êì¥ÂÖÖÂà∞Á∑äÊÄ•ÊÉÖÊ≥Å‰∏≠ÁöÑÊ±ÇÊïëÂÅµÊ∏¨ÔºåÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑÂÅöÊ≥ïÈÄöÂ∏∏ÊúÉÂõ†ÁÇ∫ÈúÄË¶ÅÈáçÊñ∞Ë®ìÁ∑¥‰ª•Â∞éÂÖ•Êñ∞ÈóúÈçµÂ≠óÊàñÈÅ©ÊáâËÆäÂãïÁöÑËÑàÁµ°ÔºåËÄåÈù¢Ëá®ÂèØÊì¥ÂÖÖÊÄßÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÊé¢Ë®é‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂà©Áî®ÁèæÊàêÁöÑÈ†êË®ìÁ∑¥ ASR Ê®°Âûã‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®Ê±ÇÊïëÂÅµÊ∏¨ÁöÑÂ†¥ÊôØ‰∏≠„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëËßÄÂØüÂà∞Âú®ÁúüÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØ‰∏≠ÈÉ®ÁΩ≤Ê±ÇÊïëÂÅµÊ∏¨Á≥ªÁµ±ÊôÇÔºåÁî±ÊñºÈ∫•ÂÖãÈ¢®Êàñ‰∏çÂêåÁí∞Â¢ÉÊâÄÁî¢ÁîüÁöÑÂô™Èü≥ÔºåÈåØË™§Ë≠¶Â†±Â§ßÂπÖÂ¢ûÂä†„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑËàáÂô™Èü≥ÁÑ°ÈóúÁöÑÂ§ö‰ªªÂãôÂ≠∏ÁøíÊñπÊ≥ïÔºåÂ∞áÂô™Èü≥ÂàÜÈ°ûÈ†≠Êï¥ÂêàÂà∞ ASR Á∑®Á¢ºÂô®‰∏≠„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÂ∞çÊúâÂô™Èü≥Áí∞Â¢ÉÁöÑÁ©©ÂÅ•ÊÄßÔºåÂ§ßÂπÖÊ∏õÂ∞ëÈåØË™§Ë≠¶Â†±Ôºå‰∏¶ÊîπÂñÑÊï¥È´îÁöÑÊ±ÇÊïëË°®Áèæ„ÄÇÂÑòÁÆ°Â§ö‰ªªÂãôÂ≠∏ÁøíÂ¢ûÂä†‰∫ÜË§áÈõúÊÄßÔºå‰ΩÜÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÈÅãÁÆó‰∏äÂæàÊúâÊïàÁéáÔºå‰∏¶ÁÇ∫ÁúüÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØ‰∏≠ÁöÑÊ±ÇÊïëÂÅµÊ∏¨Êèê‰æõ‰∏ÄÂÄãÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Early evidence of how LLMs outperform traditional systems on OCR/HTR tasks for historical records**
2501.11623v1 by Seorin Kim, Julien Baudru, Wouter Ryckbosch, Hugues Bersini, Vincent Ginis

We explore the ability of two LLMs -- GPT-4o and Claude Sonnet 3.5 -- to
transcribe historical handwritten documents in a tabular format and compare
their performance to traditional OCR/HTR systems: EasyOCR, Keras, Pytesseract,
and TrOCR. Considering the tabular form of the data, two types of experiments
are executed: one where the images are split line by line and the other where
the entire scan is used as input. Based on CER and BLEU, we demonstrate that
LLMs outperform the conventional OCR/HTR methods. Moreover, we also compare the
evaluated CER and BLEU scores to human evaluations to better judge the outputs
of whole-scan experiments and understand influential factors for CER and BLEU.
Combining judgments from all the evaluation metrics, we conclude that two-shot
GPT-4o for line-by-line images and two-shot Claude Sonnet 3.5 for whole-scan
images yield the transcriptions of the historical records most similar to the
ground truth.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Ë®éÂÖ©ÂÄã LLM -- GPT-4o Âíå Claude Sonnet 3.5 -- ‰ª•Ë°®Ê†ºÊ†ºÂºèËΩâÈåÑÊ≠∑Âè≤ÊâãÂØ´Êñá‰ª∂ÁöÑËÉΩ
ÂäõÔºå‰∏¶Â∞áÂÖ∂ÊïàËÉΩËàáÂÇ≥Áµ±ÁöÑ OCR/HTR Á≥ªÁµ±ÈÄ≤Ë°åÊØîËºÉÔºöEasyOCR„ÄÅKeras„ÄÅPytesseract Âíå TrOCR„ÄÇËÄÉÈáèÂà∞Ë≥áÊñôÁöÑË°®Ê†ºÂΩ¢ÂºèÔºåÂü∑Ë°å‰∫ÜÂÖ©Á®ÆÂØ¶È©óÔºö‰∏ÄÁ®ÆÊòØÂ∞áÂΩ±ÂÉèÈÄêË°åÂàÜÂâ≤ÔºåÂè¶‰∏ÄÁ®ÆÊòØ‰ΩøÁî®Êï¥ÂÄãÊéÉÊèè‰ΩúÁÇ∫Ëº∏ÂÖ•„ÄÇÊ†πÊìö CER Âíå BLEUÔºåÊàëÂÄëË≠âÊòé LLM ÁöÑË°®ÁèæÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ OCR/HTR ÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂ∞áË©ï‰º∞ÁöÑ CER Âíå BLEU ÂàÜÊï∏Ëàá‰∫∫Â∑•Ë©ïÂàÜÈÄ≤Ë°åÊØîËºÉÔºå‰ª•Êõ¥Â•ΩÂú∞Âà§Êñ∑ÂÖ®ÊéÉÊèèÂØ¶È©óÁöÑËº∏Âá∫Ôºå‰∏¶‰∫ÜËß£ÂΩ±Èüø CER Âíå BLEU ÁöÑÂõ†Á¥†„ÄÇÁµêÂêàÊâÄÊúâË©ïÂàÜÊåáÊ®ôÁöÑÂà§Êñ∑ÔºåÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÈÄêË°åÂΩ±ÂÉèÁöÑÂÖ©Ê¨° GPT-4o ÂíåÂÖ®ÊéÉÊèèÂΩ±ÂÉèÁöÑÂÖ©Ê¨° Claude Sonnet 3.5 Áî¢ÁîüËàáÁúüÂØ¶ÊÉÖÊ≥ÅÊúÄÁõ∏‰ººÁöÑÊ≠∑Âè≤Ë®òÈåÑËΩâÈåÑ„ÄÇ

##### **Trojan Detection Through Pattern Recognition for Large Language Models**
2501.11621v1 by Vedant Bhasin, Matthew Yudin, Razvan Stefanescu, Rauf Izmailov

Trojan backdoors can be injected into large language models at various
stages, including pretraining, fine-tuning, and in-context learning, posing a
significant threat to the model's alignment. Due to the nature of causal
language modeling, detecting these triggers is challenging given the vast
search space. In this study, we propose a multistage framework for detecting
Trojan triggers in large language models consisting of token filtration,
trigger identification, and trigger verification. We discuss existing trigger
identification methods and propose two variants of a black-box trigger
inversion method that rely on output logits, utilizing beam search and greedy
decoding respectively. We show that the verification stage is critical in the
process and propose semantic-preserving prompts and special perturbations to
differentiate between actual Trojan triggers and other adversarial strings that
display similar characteristics. The evaluation of our approach on the TrojAI
and RLHF poisoned model datasets demonstrates promising results.

ÊëòË¶ÅÔºöÊú®È¶¨ÂæåÈñÄÂèØ‰ª•Âú®ÂêÑÁ®ÆÈöéÊÆµÊ≥®ÂÖ•Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÂåÖÊã¨È†êË®ìÁ∑¥„ÄÅÂæÆË™øÂíåÊÉÖÂ¢ÉÂ≠∏ÁøíÔºåÂ∞çÊ®°ÂûãÁöÑÂ∞çÈΩäÊßãÊàêÈáçÂ§ßÂ®ÅËÑÖ„ÄÇÁî±ÊñºÂõ†ÊûúË™ûË®ÄÂª∫Ê®°ÁöÑÊÄßË≥™ÔºåÈëëÊñºÂª£Â§ßÁöÑÊêúÂ∞ãÁ©∫ÈñìÔºåÂÅµÊ∏¨ÈÄô‰∫õËß∏ÁôºÂô®ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ§öÈöéÊÆµÊû∂ÊßãÔºåÁî®ÊñºÂÅµÊ∏¨Â§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÊú®È¶¨Ëß∏ÁôºÂô®ÔºåÂåÖÊã¨Ê®ôË®òÈÅéÊøæ„ÄÅËß∏ÁôºÂô®Ë≠òÂà•ÂíåËß∏ÁôºÂô®È©óË≠â„ÄÇÊàëÂÄëË®éË´ñÁèæÊúâÁöÑËß∏ÁôºÂô®Ë≠òÂà•ÊñπÊ≥ïÔºå‰∏¶ÊèêÂá∫ÂÖ©Á®ÆÈªëÁõíËß∏ÁôºÂô®ÂèçËΩâÊñπÊ≥ïÁöÑËÆäÈ´îÔºåÂÆÉÂÄëÂàÜÂà•‰æùË≥¥ÊñºËº∏Âá∫Â∞çÊï∏Ê©üÁéáÔºåÂà©Áî®Ê≥¢ÊùüÊêúÂ∞ãÂíåË≤™Â©™Ëß£Á¢º„ÄÇÊàëÂÄëË°®ÊòéÈ©óË≠âÈöéÊÆµÂú®ÈÄôÂÄãÈÅéÁ®ã‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºå‰∏¶ÊèêÂá∫Ë™ûÁæ©‰øùÁïôÊèêÁ§∫ÂíåÁâπÊÆäÊìæÂãïÔºå‰ª•ÂçÄÂàÜÂØ¶ÈöõÁöÑÊú®È¶¨Ëß∏ÁôºÂô®ÂíåÈ°ØÁ§∫È°û‰ººÁâπÂæµÁöÑÂÖ∂‰ªñÂ∞çÊäóÊÄßÂ≠ó‰∏≤„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂú® TrojAI Âíå RLHF ‰∏≠ÊØíÊ®°ÂûãË≥áÊñôÈõÜ‰∏äÁöÑË©ï‰º∞È°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûú„ÄÇ

##### **Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems**
2501.11613v1 by Giorgio Robino

This study introduces Conversation Routines (CR), a structured prompt
engineering framework for developing task-oriented dialog systems using Large
Language Models (LLMs). While LLMs demonstrate remarkable natural language
understanding capabilities, engineering them to reliably execute complex
business workflows remains challenging. The proposed CR framework enables the
development of Conversation Agentic Systems (CAS) through natural language
specifications, embedding task-oriented logic within LLM prompts. This approach
provides a systematic methodology for designing and implementing complex
conversational workflows while maintaining behavioral consistency. We
demonstrate the framework's effectiveness through two proof of concept
implementations: a Train Ticket Booking System and an Interactive
Troubleshooting Copilot. These case studies validate CR's capability to encode
sophisticated behavioral patterns and decision logic while preserving natural
conversational flexibility. Results show that CR enables domain experts to
design conversational workflows in natural language while leveraging custom
enterprise functionalities (tools) developed by software engineers, creating an
efficient division of responsibilities where developers focus on core API
implementation and domain experts handle conversation design. While the
framework shows promise in accessibility and adaptability, we identify key
challenges including computational overhead, non-deterministic behavior, and
domain-specific logic optimization. Future research directions include
enhancing system robustness, improving scalability for complex multi-agent
interactions, and addressing the identified limitations across diverse business
applications.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ªãÁ¥π‰∫ÜÂ∞çË©±Â∏∏Ë¶è (CR)ÔºåÈÄôÊòØ‰∏ÄÂÄãÁµêÊßãÂåñÊèêÁ§∫Â∑•Á®ãÊû∂ÊßãÔºåÁî®Êñº‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈñãÁôº‰ª•‰ªªÂãôÁÇ∫Â∞éÂêëÁöÑÂ∞çË©±Á≥ªÁµ±„ÄÇÂÑòÁÆ° LLM Â±ïÁ§∫‰∫ÜÈùûÂá°ÁöÑËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ËÉΩÂäõÔºå‰ΩÜË¶ÅË®≠Ë®àÂÆÉÂÄë‰æÜÂèØÈù†Âú∞Âü∑Ë°åË§áÈõúÁöÑÊ•≠ÂãôÂ∑•‰ΩúÊµÅÁ®ã‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊèêÂá∫ÁöÑ CR Êû∂ÊßãËÉΩÂ§†ÈÄöÈÅéËá™ÁÑ∂Ë™ûË®ÄË¶èÁØÑÈñãÁôºÂ∞çË©±‰ª£ÁêÜÁ≥ªÁµ± (CAS)ÔºåÂú® LLM ÊèêÁ§∫‰∏≠ÂµåÂÖ•‰ª•‰ªªÂãôÁÇ∫Â∞éÂêëÁöÑÈÇèËºØ„ÄÇÊ≠§ÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±ÁöÑÊñπÊ≥ï‰æÜË®≠Ë®àÂíåÂØ¶‰ΩúË§áÈõúÁöÑÂ∞çË©±Â∑•‰ΩúÊµÅÁ®ãÔºåÂêåÊôÇ‰øùÊåÅË°åÁÇ∫‰∏ÄËá¥ÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÂÖ©ÂÄãÊ¶ÇÂøµÈ©óË≠âÂØ¶‰ΩúÂ±ïÁ§∫‰∫ÜË©≤Êû∂ÊßãÁöÑÊúâÊïàÊÄßÔºöÁÅ´ËªäÁ•®È†êË®ÇÁ≥ªÁµ±Âíå‰∫íÂãïÊïÖÈöúÊéíÈô§ÂâØÈßïÈßõ„ÄÇÈÄô‰∫õÊ°à‰æãÁ†îÁ©∂È©óË≠â‰∫Ü CR Á∑®Á¢ºË§áÈõúË°åÁÇ∫Ê®°ÂºèÂíåÊ±∫Á≠ñÈÇèËºØÁöÑËÉΩÂäõÔºåÂêåÊôÇ‰øùÁïô‰∫ÜËá™ÁÑ∂ÁöÑÂ∞çË©±ÈùàÊ¥ªÊÄß„ÄÇÁµêÊûúË°®ÊòéÔºåCR ËÉΩËÆìÈ†òÂüüÂ∞àÂÆ∂‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄË®≠Ë®àÂ∞çË©±Â∑•‰ΩúÊµÅÁ®ãÔºåÂêåÊôÇÂà©Áî®ËªüÈ´îÂ∑•Á®ãÂ∏´ÈñãÁôºÁöÑÂÆ¢Ë£ΩÂåñ‰ºÅÊ•≠ÂäüËÉΩÔºàÂ∑•ÂÖ∑ÔºâÔºåÂâµÈÄ†‰∏ÄÁ®ÆÊúâÊïàÁöÑË≤¨‰ªªÂäÉÂàÜÔºåÈñãÁôº‰∫∫Âì°Â∞àÊ≥®ÊñºÊ†∏ÂøÉ API ÂØ¶‰ΩúÔºåËÄåÈ†òÂüüÂ∞àÂÆ∂ÂâáËôïÁêÜÂ∞çË©±Ë®≠Ë®à„ÄÇÂÑòÁÆ°Ë©≤Êû∂ÊßãÂú®ÂèØÂèäÊÄßÂíåÈÅ©ÊáâÊÄßÊñπÈù¢È°ØÁ§∫Âá∫ÂâçÊôØÔºå‰ΩÜÊàëÂÄëÁôºÁèæ‰∫ÜÈóúÈçµÊåëÊà∞ÔºåÂåÖÊã¨ÈÅãÁÆóË≤†Êìî„ÄÅÈùûÁ¢∫ÂÆöÊÄßË°åÁÇ∫ÂíåÁâπÂÆöÈ†òÂüüÈÇèËºØÊúÄ‰Ω≥Âåñ„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÂåÖÊã¨Â¢ûÂº∑Á≥ªÁµ±Á©©ÂÅ•ÊÄß„ÄÅÊîπÂñÑË§áÈõúÂ§ö‰ª£ÁêÜ‰∫íÂãïÁöÑÂèØÊì¥ÂÖÖÊÄßÔºå‰ª•ÂèäËß£Ê±∫‰∏çÂêåÊ•≠ÂãôÊáâÁî®‰∏≠ÁöÑÂ∑≤Ë≠òÂà•ÈôêÂà∂„ÄÇ

##### **SR-FoT: A Syllogistic-Reasoning Framework of Thought for Large Language Models Tackling Knowledge-based Reasoning Tasks**
2501.11599v1 by Wentao Wan, Zhuojie Yang, Yongcan Chen, Chenglin Luo, Ruilin Wang, Kehao Cai, Nan Kang, Liang Lin, Keze Wang

Deductive reasoning is a crucial logical capability that assists us in
solving complex problems based on existing knowledge. Although augmented by
Chain-of-Thought prompts, Large Language Models (LLMs) might not follow the
correct reasoning paths. Enhancing the deductive reasoning abilities of LLMs,
and leveraging their extensive built-in knowledge for various reasoning tasks,
remains an open question. Attempting to mimic the human deductive reasoning
paradigm, we propose a multi-stage Syllogistic-Reasoning Framework of Thought
(SR-FoT) that enables LLMs to perform syllogistic deductive reasoning to handle
complex knowledge-based reasoning tasks. Our SR-FoT begins by interpreting the
question and then uses the interpretation and the original question to propose
a suitable major premise. It proceeds by generating and answering minor premise
questions in two stages to match the minor premises. Finally, it guides LLMs to
use the previously generated major and minor premises to perform syllogistic
deductive reasoning to derive the answer to the original question. Extensive
and thorough experiments on knowledge-based reasoning tasks have demonstrated
the effectiveness and advantages of our SR-FoT.

ÊëòË¶ÅÔºöÊºîÁªéÊé®ÁêÜÊòØ‰∏ÄÁßçËá≥ÂÖ≥ÈáçË¶ÅÁöÑÈÄªËæëËÉΩÂäõÔºåÂÆÉÂ∏ÆÂä©Êàë‰ª¨Âú®Áé∞ÊúâÁü•ËØÜÁöÑÂü∫Á°Ä‰∏äËß£ÂÜ≥Â§çÊùÇÁöÑÈóÆÈ¢ò„ÄÇËôΩÁÑ∂ÈÄöËøáÊÄùÊÉ≥ÈìæÊèêÁ§∫Â¢ûÂº∫‰∫ÜÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLM)Ôºå‰ΩÜÂÆÉ‰ª¨ÂèØËÉΩÊó†Ê≥ïÈÅµÂæ™Ê≠£Á°ÆÁöÑÊé®ÁêÜË∑ØÂæÑ„ÄÇÂ¢ûÂº∫ LLM ÁöÑÊºîÁªéÊé®ÁêÜËÉΩÂäõÔºåÂπ∂Âà©Áî®ÂÖ∂ÂπøÊ≥õÁöÑÂÜÖÁΩÆÁü•ËØÜÊù•ÊâßË°åÂêÑÁßçÊé®ÁêÜ‰ªªÂä°Ôºå‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÊÇ¨ËÄåÊú™ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇ‰∏∫‰∫ÜÊ®°‰ªø‰∫∫Á±ªÁöÑÊºîÁªéÊé®ÁêÜËåÉÂºèÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂ§öÈò∂ÊÆµ‰∏âÊÆµËÆ∫Êé®ÁêÜÊÄùÊÉ≥Ê°ÜÊû∂ (SR-FoT)ÔºåÂÆÉ‰Ωø LLM ËÉΩÂ§üÊâßË°å‰∏âÊÆµËÆ∫ÊºîÁªéÊé®ÁêÜÊù•Â§ÑÁêÜÂü∫‰∫éÂ§çÊùÇÁü•ËØÜÁöÑÊé®ÁêÜ‰ªªÂä°„ÄÇÊàë‰ª¨ÁöÑ SR-FoT ‰ªéËß£ÈáäÈóÆÈ¢òÂºÄÂßãÔºåÁÑ∂Âêé‰ΩøÁî®Ëß£ÈáäÂíåÂéüÂßãÈóÆÈ¢òÊù•ÊèêÂá∫ÂêàÈÄÇÁöÑÈáçÂ§ßÂâçÊèê„ÄÇÂÆÉÈÄöËøáÂàÜ‰∏§‰∏™Èò∂ÊÆµÁîüÊàêÂíåÂõûÁ≠îÊ¨°Ë¶ÅÂâçÊèêÈóÆÈ¢òÊù•ÂåπÈÖçÊ¨°Ë¶ÅÂâçÊèê„ÄÇÊúÄÂêéÔºåÂÆÉÊåáÂØº LLM ‰ΩøÁî®ÂÖàÂâçÁîüÊàêÁöÑÈáçÂ§ßÂâçÊèêÂíåÊ¨°Ë¶ÅÂâçÊèêÊù•ÊâßË°å‰∏âÊÆµËÆ∫ÊºîÁªéÊé®ÁêÜÔºå‰ª•ÂæóÂá∫ÂéüÂßãÈóÆÈ¢òÁöÑÁ≠îÊ°à„ÄÇÂú®Âü∫‰∫éÁü•ËØÜÁöÑÊé®ÁêÜ‰ªªÂä°‰∏äËøõË°åÁöÑÂπøÊ≥õËÄåÂΩªÂ∫ïÁöÑÂÆûÈ™åÂ∑≤ÁªèËØÅÊòé‰∫ÜÊàë‰ª¨ SR-FoT ÁöÑÊúâÊïàÊÄßÂíå‰ºòÂäø„ÄÇ

##### **Fairness Testing through Extreme Value Theory**
2501.11597v1 by Verya Monjezi, Ashutosh Trivedi, Vladik Kreinovich, Saeid Tizpaz-Niari

Data-driven software is increasingly being used as a critical component of
automated decision-support systems. Since this class of software learns its
logic from historical data, it can encode or amplify discriminatory practices.
Previous research on algorithmic fairness has focused on improving average-case
fairness. On the other hand, fairness at the extreme ends of the spectrum,
which often signifies lasting and impactful shifts in societal attitudes, has
received significantly less emphasis.
  Leveraging the statistics of extreme value theory (EVT), we propose a novel
fairness criterion called extreme counterfactual discrimination (ECD). This
criterion estimates the worst-case amounts of disadvantage in outcomes for
individuals solely based on their memberships in a protected group. Utilizing
tools from search-based software engineering and generative AI, we present a
randomized algorithm that samples a statistically significant set of points
from the tail of ML outcome distributions even if the input dataset lacks a
sufficient number of relevant samples.
  We conducted several experiments on four ML models (deep neural networks,
logistic regression, and random forests) over 10 socially relevant tasks from
the literature on algorithmic fairness. First, we evaluate the generative AI
methods and find that they generate sufficient samples to infer valid EVT
distribution in 95% of cases. Remarkably, we found that the prevalent bias
mitigators reduce the average-case discrimination but increase the worst-case
discrimination significantly in 5% of cases. We also observed that even the
tail-aware mitigation algorithm -- MiniMax-Fairness -- increased the worst-case
discrimination in 30% of cases. We propose a novel ECD-based mitigator that
improves fairness in the tail in 90% of cases with no degradation of the
average-case discrimination.

ÊëòË¶ÅÔºö<paragraph>Ë≥áÊñôÈ©ÖÂãïËªüÈ´îÊ≠£Êó•ÁõäË¢´Áî®‰ΩúËá™ÂãïÂåñÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁöÑÈáçË¶ÅÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁî±ÊñºÊ≠§È°ûËªüÈ´îÂæûÊ≠∑Âè≤Ë≥áÊñô‰∏≠Â≠∏ÁøíÂÖ∂ÈÇèËºØÔºåÂõ†Ê≠§ÂÆÉÂèØ‰ª•Á∑®Á¢ºÊàñÊì¥Â§ßÊ≠ßË¶ñÊÄßÂÅöÊ≥ï„ÄÇÂÖàÂâçÈáùÂ∞çÊºîÁÆóÊ≥ïÂÖ¨Âπ≥ÊÄßÁöÑÁ†îÁ©∂ËëóÈáçÊñºÊîπÂñÑÂπ≥ÂùáÁãÄÊ≥ÅÂÖ¨Âπ≥ÊÄß„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂÖâË≠úÂÖ©Ê•µÁöÑÂÖ¨Âπ≥ÊÄßÔºåÈÄöÂ∏∏Ë°®Á§∫Á§æÊúÉÊÖãÂ∫¶ÊåÅ‰πÖ‰∏îÊúâÂΩ±ÈüøÂäõÁöÑËΩâËÆäÔºåÂèóÂà∞ÁöÑÈáçË¶ñÂçªÊòéÈ°ØËºÉÂ∞ë„ÄÇ
  Âà©Áî®Ê•µÂÄºÁêÜË´ñ (EVT) ÁöÑÁµ±Ë®àË≥áÊñôÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÂêçÁÇ∫Ê•µÁ´ØÂèç‰∫ãÂØ¶Ê≠ßË¶ñ (ECD) ÁöÑÊñ∞ÂÖ¨Âπ≥ÊÄßÊ∫ñÂâá„ÄÇÊ≠§Ê∫ñÂâá‰º∞Ë®àÂÄã‰∫∫ÂÉÖÂü∫ÊñºÂÖ∂Âèó‰øùË≠∑Áæ§ÁµÑÁöÑÊàêÂì°Ë∫´‰ªΩËÄåÁî¢ÁîüÁöÑÊúÄÂ∑ÆÊÉÖÊ≥ÅÁµêÊûúÂä£Âã¢Èáè„ÄÇÂà©Áî®‰æÜËá™Âü∫ÊñºÊêúÂ∞ãÁöÑËªüÈ´îÂ∑•Á®ãÂíåÁîüÊàêÂºè AI ÁöÑÂ∑•ÂÖ∑ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈö®Ê©üÊºîÁÆóÊ≥ïÔºåÂç≥‰ΩøËº∏ÂÖ•Ë≥áÊñôÈõÜÁº∫‰πèË∂≥Â§†Êï∏ÈáèÁöÑÁõ∏ÈóúÊ®£Êú¨Ôºå‰πüËÉΩÂæû ML ÁµêÊûúÂàÜ‰ΩàÁöÑÂ∞æÁ´ØÊäΩÂèñ‰∏ÄÁµÑÂÖ∑ÊúâÁµ±Ë®àÈ°ØËëóÊÄßÁöÑÈªû„ÄÇ
  ÊàëÂÄëÈáùÂ∞ç‰æÜËá™ÊºîÁÆóÊ≥ïÂÖ¨Âπ≥ÊÄßÊñáÁçª‰∏≠ÁöÑ 10 È†ÖÁ§æÊúÉÁõ∏Èóú‰ªªÂãôÔºåÂ∞çÂõõÂÄã ML Ê®°ÂûãÔºàÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅÈÇèËºØËø¥Ê≠∏ÂíåÈö®Ê©üÊ£ÆÊûóÔºâÈÄ≤Ë°å‰∫ÜÂ§öÈ†ÖÂØ¶È©ó„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëË©ï‰º∞ÁîüÊàêÂºè AI ÊñπÊ≥ïÔºå‰∏¶ÁôºÁèæÂÆÉÂÄëÁî¢Áîü‰∫ÜË∂≥Â§†ÁöÑÊ®£Êú¨ÔºåÂèØ‰ª•Âú® 95% ÁöÑÊ°à‰æã‰∏≠Êé®Êñ∑Âá∫ÊúâÊïàÁöÑ EVT ÂàÜ‰Ωà„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæÊôÆÈÅçÁöÑÂÅèË¶ãÁ∑©Ëß£Âô®ÊúÉÈôç‰ΩéÂπ≥ÂùáÁãÄÊ≥ÅÊ≠ßË¶ñÔºå‰ΩÜÂú® 5% ÁöÑÊ°à‰æã‰∏≠È°ØËëóÂ¢ûÂä†‰∫ÜÊúÄÂ∑ÆÊÉÖÊ≥ÅÊ≠ßË¶ñ„ÄÇÊàëÂÄëÈÇÑËßÄÂØüÂà∞ÔºåÂç≥‰ΩøÊòØÂ∞æÁ´ØÊÑüÁü•Á∑©Ëß£ÊºîÁÆóÊ≥ï‚Äî‚ÄîMiniMax-Fairness‚Äî‚ÄîÂú® 30% ÁöÑÊ°à‰æã‰∏≠‰πüÂ¢ûÂä†‰∫ÜÊúÄÂ∑ÆÊÉÖÊ≥ÅÊ≠ßË¶ñ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂü∫Êñº ECD ÁöÑÁ∑©Ëß£Âô®ÔºåÂÆÉÂú® 90% ÁöÑÊ°à‰æã‰∏≠ÊîπÂñÑ‰∫ÜÂ∞æÁ´ØÁöÑÂÖ¨Âπ≥ÊÄßÔºåËÄå‰∏çÊúÉÈôç‰ΩéÂπ≥ÂùáÁãÄÊ≥ÅÊ≠ßË¶ñ„ÄÇ</paragraph>

##### **Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**
2501.11592v1 by Chaoqing Tang, Huanze Zhuang, Guiyun Tian, Zhenli Zeng, Yi Ding, Wenzhong Liu, Xiang Bai

Pre-trained large models attract widespread attention in recent years, but
they face challenges in applications that require high interpretability or have
limited resources, such as physical sensing, medical imaging, and
bioinformatics. Compressed Sensing (CS) is a well-proved theory that drives
many recent breakthroughs in these applications. However, as a typical
under-determined linear system, CS suffers from excessively long sparse
reconstruction times when using traditional iterative methods, particularly
with large-scale data. Current AI methods like deep unfolding fail to
substitute them because pre-trained models exhibit poor generality beyond their
training conditions and dataset distributions, or lack interpretability.
Instead of following the big model fervor, this paper proposes ultra-small
artificial neural models called coefficients learning (CL), enabling
training-free and rapid sparse reconstruction while perfectly inheriting the
generality and interpretability of traditional iterative methods, bringing new
feature of incorporating prior knowledges. In CL, a signal of length $n$ only
needs a minimal of $n$ trainable parameters. A case study model called CLOMP is
implemented for evaluation. Experiments are conducted on both synthetic and
real one-dimensional and two-dimensional signals, demonstrating significant
improvements in efficiency and accuracy. Compared to representative iterative
methods, CLOMP improves efficiency by 100 to 1000 folds for large-scale data.
Test results on eight diverse image datasets indicate that CLOMP improves
structural similarity index by 292%, 98%, 45% for sampling rates of 0.1, 0.3,
0.5, respectively. We believe this method can truly usher CS reconstruction
into the AI era, benefiting countless under-determined linear systems that rely
on sparse solution.

ÊëòË¶ÅÔºö<paragraph>È¢ÑËÆ≠ÁªÉÂ§ßÂûãÊ®°ÂûãËøëÂπ¥Êù•Â§áÂèóÂÖ≥Ê≥®Ôºå‰ΩÜÂÆÉ‰ª¨Âú®ÈúÄË¶ÅÈ´òÂèØËß£ÈáäÊÄßÊàñËµÑÊ∫êÊúâÈôêÁöÑÂ∫îÁî®‰∏≠Èù¢‰∏¥ÊåëÊàòÔºå‰æãÂ¶ÇÁâ©ÁêÜ‰º†ÊÑü„ÄÅÂåªÂ≠¶ÂΩ±ÂÉèÂíåÁîüÁâ©‰ø°ÊÅØÂ≠¶„ÄÇÂéãÁº©ÊÑüÁü• (CS) ÊòØ‰∏ÄÈ°πÁªèËøáÂÖÖÂàÜÈ™åËØÅÁöÑÁêÜËÆ∫ÔºåÊé®Âä®‰∫ÜËøô‰∫õÂ∫îÁî®‰∏≠ÁöÑËÆ∏Â§öÊúÄÊñ∞Á™ÅÁ†¥„ÄÇÁÑ∂ËÄåÔºå‰Ωú‰∏∫ÂÖ∏ÂûãÁöÑÊ¨†ÂÆöÁ∫øÊÄßÁ≥ªÁªüÔºåCS Âú®‰ΩøÁî®‰º†ÁªüËø≠‰ª£ÊñπÊ≥ïÊó∂‰ºö‰∫ßÁîüËøáÈïøÁöÑÁ®ÄÁñèÈáçÂª∫Êó∂Èó¥ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÂ§ßËßÑÊ®°Êï∞ÊçÆÊó∂„ÄÇÂΩìÂâçÁöÑÊ∑±Â∫¶Â±ïÂºÄÁ≠â AI ÊñπÊ≥ïÊó†Ê≥ïÊõø‰ª£ÂÆÉ‰ª¨ÔºåÂõ†‰∏∫È¢ÑËÆ≠ÁªÉÊ®°ÂûãÂú®ÂÖ∂ËÆ≠ÁªÉÊù°‰ª∂ÂíåÊï∞ÊçÆÈõÜÂàÜÂ∏É‰πãÂ§ñË°®Áé∞Âá∫ËæÉÂ∑ÆÁöÑÊ≥õÂåñÊÄßÔºåÊàñÁº∫‰πèÂèØËß£ÈáäÊÄß„ÄÇÊú¨ÊñáÊ≤°ÊúâËøΩÈöèÂ§ßÂûãÊ®°ÂûãÁÉ≠ÊΩÆÔºåËÄåÊòØÊèêÂá∫‰∫ÜÁß∞‰∏∫Á≥ªÊï∞Â≠¶‰π† (CL) ÁöÑË∂ÖÂ∞èÂûã‰∫∫Â∑•Á•ûÁªèÁΩëÁªúÊ®°ÂûãÔºåÂÆûÁé∞Êó†ËÆ≠ÁªÉ‰∏îÂø´ÈÄüÁöÑÁ®ÄÁñèÈáçÂª∫ÔºåÂêåÊó∂ÂÆåÁæéÁªßÊâø‰∫Ü‰º†ÁªüËø≠‰ª£ÊñπÊ≥ïÁöÑÊ≥õÂåñÊÄßÂíåÂèØËß£ÈáäÊÄßÔºåÂ∏¶Êù•‰∫ÜËûçÂêàÂÖàÈ™åÁü•ËØÜÁöÑÊñ∞ÁâπÊÄß„ÄÇÂú® CL ‰∏≠ÔºåÈïøÂ∫¶‰∏∫ $n$ ÁöÑ‰ø°Âè∑Âè™ÈúÄË¶ÅÊúÄÂ∞ë $n$ ‰∏™ÂèØËÆ≠ÁªÉÂèÇÊï∞„ÄÇÂÆûÁé∞‰∫Ü‰∏Ä‰∏™Áß∞‰∏∫ CLOMP ÁöÑÊ°à‰æãÁ†îÁ©∂Ê®°Âûã‰ª•ËøõË°åËØÑ‰º∞„ÄÇÂú®ÂêàÊàêÂíåÁúüÂÆûÁöÑ‰∏ÄÁª¥Âíå‰∫åÁª¥‰ø°Âè∑‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºåËØÅÊòé‰∫ÜÊïàÁéáÂíåÂáÜÁ°ÆÊÄßÁöÑÊòæÁùÄÊèêÈ´ò„ÄÇ‰∏éÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑËø≠‰ª£ÊñπÊ≥ïÁõ∏ÊØîÔºåCLOMP Â∞ÜÂ§ßËßÑÊ®°Êï∞ÊçÆÁöÑÊïàÁéáÊèêÈ´ò‰∫Ü 100 Âà∞ 1000 ÂÄç„ÄÇÂú®ÂÖ´‰∏™‰∏çÂêåÁöÑÂõæÂÉèÊï∞ÊçÆÈõÜ‰∏äÁöÑÊµãËØïÁªìÊûúË°®ÊòéÔºåCLOMP ÂàÜÂà´Â∞ÜÈááÊ†∑Áéá‰∏∫ 0.1„ÄÅ0.3„ÄÅ0.5 ÁöÑÁªìÊûÑÁõ∏‰ººÊÄßÊåáÊï∞ÊèêÈ´ò‰∫Ü 292%„ÄÅ98%„ÄÅ45%„ÄÇÊàë‰ª¨Áõ∏‰ø°ËøôÁßçÊñπÊ≥ïÂèØ‰ª•ÁúüÊ≠£Â∞Ü CS ÈáçÂª∫Â∏¶ÂÖ• AI Êó∂‰ª£Ôºå‰Ωø‰æùËµñÁ®ÄÁñèËß£ÁöÑÊó†Êï∞Ê¨†ÂÆöÁ∫øÊÄßÁ≥ªÁªüÂèóÁõä„ÄÇ</paragraph>

##### **Recurrent Diffusion for Large-Scale Parameter Generation**
2501.11587v1 by Kai Wang, Dongwen Tang, Wangbo Zhao, Yang You

Parameter generation has struggled to scale up for a long time, significantly
limiting its range of applications. In this study, we introduce
\textbf{R}ecurrent diffusion for large-scale \textbf{P}arameter
\textbf{G}eneration, called \textbf{RPG}. We first divide the trained
parameters into non-overlapping parts, after which a recurrent model is
proposed to learn their relationships. The recurrent model's outputs, as
conditions, are then fed into a diffusion model to generate the neural network
parameters. Using only a single GPU, recurrent diffusion enables us to generate
popular vision and language models such as ConvNeXt-L and LoRA parameters of
LLaMA-7B. Meanwhile, across various architectures and tasks, the generated
parameters consistently perform comparable results over trained networks.
Notably, our approach also shows the potential to generate models for handling
unseen tasks, which largely increases the practicality of parameter generation.
Our code is available
\href{https://github.com/NUS-HPC-AI-Lab/Recurrent-Parameter-Generation}{here}.

ÊëòË¶ÅÔºöÂèÉÊï∏ÁîüÊàêÈï∑Êúü‰ª•‰æÜ‰∏ÄÁõ¥Èõ£‰ª•Êì¥Â±ïÔºåÈÄôÈ°ØËëóÈôêÂà∂‰∫ÜÂÖ∂ÊáâÁî®ÁØÑÂúç„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁî®ÊñºÂ§ßË¶èÊ®°ÂèÉÊï∏ÁîüÊàêÁöÑÈÅûËø¥Êì¥Êï£ÔºåÁ®±ÁÇ∫ RPG„ÄÇÊàëÂÄëÈ¶ñÂÖàÂ∞áË®ìÁ∑¥Â•ΩÁöÑÂèÉÊï∏ÂàÜÊàê‰∏çÈáçÁñäÁöÑÈÉ®ÂàÜÔºåÁÑ∂ÂæåÊèêÂá∫‰∏ÄÂÄãÈÅûËø¥Ê®°Âûã‰æÜÂ≠∏ÁøíÂÆÉÂÄë‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÁÑ∂ÂæåÔºåÂ∞áÈÅûËø¥Ê®°ÂûãÁöÑËº∏Âá∫‰ΩúÁÇ∫Ê¢ù‰ª∂Ëº∏ÂÖ•Âà∞Êì¥Êï£Ê®°Âûã‰∏≠‰ª•ÁîüÊàêÁ•ûÁ∂ìÁ∂≤Ë∑ØÂèÉÊï∏„ÄÇÂÉÖ‰ΩøÁî®ÂñÆÂÄã GPUÔºåÈÅûËø¥Êì¥Êï£‰ΩøÊàëÂÄëËÉΩÂ§†ÁîüÊàêÊµÅË°åÁöÑË¶ñË¶∫ÂíåË™ûË®ÄÊ®°ÂûãÔºå‰æãÂ¶Ç ConvNeXt-L Âíå LLaMA-7B ÁöÑ LoRA ÂèÉÊï∏„ÄÇÂêåÊôÇÔºåÂú®ÂêÑÁ®ÆÊû∂ÊßãÂíå‰ªªÂãô‰∏≠ÔºåÁîüÊàêÁöÑÂèÉÊï∏ÂßãÁµÇÂ∞çË®ìÁ∑¥Â•ΩÁöÑÁ∂≤Ë∑ØÂü∑Ë°åÂèØÊØîËºÉÁöÑÁµêÊûú„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰πüÈ°ØÁ§∫‰∫ÜÁÇ∫ËôïÁêÜÊú™Ë¶ã‰ªªÂãôÁîüÊàêÊ®°ÂûãÁöÑÊΩõÂäõÔºåÈÄôÂ§ßÂ§ßÂ¢ûÂä†‰∫ÜÂèÉÊï∏ÁîüÊàêÁöÑÂØ¶Áî®ÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÁî®Êñº
\href{https://github.com/NUS-HPC-AI-Lab/Recurrent-Parameter-Generation}{ÈÄôË£°}„ÄÇ

##### **Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**
2501.11560v1 by M. Manzour, A. Ballardini, R. Izquierdo, M. √Å. Sotelo

Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.

ÊëòË¶ÅÔºöÊèõËªäÈÅìÂãï‰ΩúÔºåÂ∞§ÂÖ∂ÊòØÁ™ÅÁÑ∂ÊàñÂú®È¢®Èö™ÊÉÖÊ≥Å‰∏ãÂü∑Ë°åÁöÑÂãï‰ΩúÔºåÊòØÈÅìË∑Ø‰∫§ÈÄö‰∫ãÊïÖÁöÑÈáçË¶ÅÂéüÂõ†„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÁ†îÁ©∂ÊâÄ‰∏ªË¶ÅÈõÜ‰∏≠Âú®È†êÊ∏¨ÂÆâÂÖ®ÁöÑÊèõËªäÈÅì„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑ‰∫ãÊïÖË≥áÊñôÈõÜÈÄöÂ∏∏ÂÉÖÂü∫ÊñºÂΩ±ÂÉèÔºå‰∏îÁº∫‰πèÂÖ®Èù¢ÁöÑÊÑüÊ∏¨Ë≥áÊñô„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®Êñº‰ΩøÁî® CRASH Ë≥áÊñôÈõÜÔºàÊàëÂÄëËá™Â∑±Êî∂ÈõÜÁöÑÂ∞àÈñÄÈáùÂ∞çÈ¢®Èö™ÊèõËªäÈÅìË≥áÊñôÈõÜÔºâ‰æÜÈ†êÊ∏¨È¢®Èö™ÊèõËªäÈÅìÔºå‰ª•ÂèäÂÆâÂÖ®ÊèõËªäÈÅìÔºà‰ΩøÁî® HighD Ë≥áÊñôÈõÜÔºâ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂà©Áî® KG ÂíåË≤ùÊ∞èÊé®ÁêÜ‰æÜ‰ΩøÁî®Ë™ûË®ÄËÉåÊôØË≥áË®äÈ†êÊ∏¨ÈÄô‰∫õÂãï‰ΩúÔºåÂ¢ûÂº∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÂíåÈÄèÊòéÂ∫¶„ÄÇË©≤Ê®°ÂûãÂú®È¢®Èö™ÊèõËªäÈÅìÁöÑÈ†êÊ∏¨ÊôÇÈñìÂª∂Èï∑Ëá≥ÂõõÁßíÊôÇÔºåÈÅîÂà∞‰∫Ü 91.5% ÁöÑ f1 ÂàÜÊï∏ÔºåÂú®È†êÊ∏¨ÂÆâÂÖ®ÊèõËªäÈÅìÊôÇÔºåÂú®Áõ∏ÂêåÁöÑÈ†êÊ∏¨ÊôÇÈñìÂÖßÈÅîÂà∞‰∫Ü 90.0% ÁöÑ f1 ÂàÜÊï∏„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áÊ®°ÂûãÊï¥ÂêàÂà∞ CARLA Ê®°Êì¨Âô®‰∏≠ÁöÑËªäËºõ‰∏≠ÔºåÂú®Ê∂âÂèäÈ¢®Èö™ÊèõËªäÈÅìÁöÑÂ†¥ÊôØ‰∏≠È©óË≠âÊàëÂÄëÁöÑÊ®°Âûã„ÄÇË©≤Ê®°ÂûãË®≠Ê≥ïÈ†êÊ∏¨Á™ÅÁÑ∂ÁöÑÊèõËªäÈÅìÔºåÂæûËÄåÁÇ∫Ëá™ÂãïÈßïÈßõËªäËºõÊèê‰æõ‰∫ÜÊõ¥Â§öÊôÇÈñì‰æÜË¶èÂäÉÂíåÂü∑Ë°åÈÅ©Áï∂ÁöÑÂÆâÂÖ®ÂèçÊáâ„ÄÇÊúÄÂæåÔºåÁÇ∫‰∫ÜÂ¢ûÂº∑ÊàëÂÄëÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºåÊàëÂÄëÂà©Áî® RAG ÁÇ∫Áµ¶ÂÆöÁöÑÈ†êÊ∏¨Êèê‰æõÊ∏ÖÊô∞‰∏îËá™ÁÑ∂ÁöÑË™ûË®ÄËß£Èáã„ÄÇ

##### **PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation**
2501.11551v1 by Jinyu Wang, Jingjing Fu, Lei Song, Jiang Bian

Despite notable advancements in Retrieval-Augmented Generation (RAG) systems
that expand large language model (LLM) capabilities through external retrieval,
these systems often struggle to meet the complex and diverse needs of
real-world industrial applications. The reliance on retrieval alone proves
insufficient for extracting deep, domain-specific knowledge performing in
logical reasoning from specialized corpora. To address this, we introduce
sPecIalized KnowledgE and Rationale Augmentation Generation (PIKE-RAG),
focusing on extracting, understanding, and applying specialized knowledge,
while constructing coherent rationale to incrementally steer LLMs toward
accurate responses. Recognizing the diverse challenges of industrial tasks, we
introduce a new paradigm that classifies tasks based on their complexity in
knowledge extraction and application, allowing for a systematic evaluation of
RAG systems' problem-solving capabilities. This strategic approach offers a
roadmap for the phased development and enhancement of RAG systems, tailored to
meet the evolving demands of industrial applications. Furthermore, we propose
knowledge atomizing and knowledge-aware task decomposition to effectively
extract multifaceted knowledge from the data chunks and iteratively construct
the rationale based on original query and the accumulated knowledge,
respectively, showcasing exceptional performance across various benchmarks.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÁ≥ªÁµ±Âú®Êì¥Â±ïÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËÉΩÂäõÊñπÈù¢ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜÈÄô‰∫õÁ≥ªÁµ±Á∂ìÂ∏∏Èõ£‰ª•ÊªøË∂≥ÁèæÂØ¶‰∏ñÁïåÁî¢Ê•≠ÊáâÁî®ÁöÑË§áÈõú‰∏îÂ§öÊ®£ÂåñÁöÑÈúÄÊ±Ç„ÄÇÂÉÖ‰æùË≥¥Ê™¢Á¥¢Ë¢´Ë≠âÊòé‰∏çË∂≥‰ª•ÂæûÂ∞àÊ•≠Ë™ûÊñôÂ∫´‰∏≠ÊèêÂèñÊ∑±ÂÖ•ÁöÑ„ÄÅÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÔºå‰∏¶ÈÄ≤Ë°åÈÇèËºØÊé®ÁêÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂ∞àÊ•≠Áü•Ë≠òÂíåÂéüÁêÜÂ¢ûÂº∑ÁîüÊàêÔºàPIKE-RAGÔºâÔºåÂ∞àÊ≥®ÊñºÊèêÂèñ„ÄÅÁêÜËß£ÂíåÊáâÁî®Â∞àÊ•≠Áü•Ë≠òÔºåÂêåÊôÇÂª∫ÊßãÈÄ£Ë≤´ÁöÑÂéüÁêÜ‰ª•ÈÄêÊ≠•ÂºïÂ∞é LLM ÊúùÂêëÊ∫ñÁ¢∫ÁöÑÂõûÊáâ„ÄÇË™çË≠òÂà∞Áî¢Ê•≠‰ªªÂãôÁöÑÂ§öÊ®£ÂåñÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁØÑ‰æãÔºåÊ†πÊìöÁü•Ë≠òÊèêÂèñÂíåÊáâÁî®‰∏≠ÁöÑË§áÈõúÊÄßÂ∞ç‰ªªÂãôÈÄ≤Ë°åÂàÜÈ°ûÔºåÂæûËÄåÂèØ‰ª•Á≥ªÁµ±Âú∞Ë©ï‰º∞ RAG Á≥ªÁµ±ÁöÑËß£Ê±∫ÂïèÈ°åËÉΩÂäõ„ÄÇÈÄôÁ®ÆÁ≠ñÁï•ÊÄßÊñπÊ≥ïÁÇ∫ RAG Á≥ªÁµ±ÁöÑÂàÜÈöéÊÆµÈñãÁôºÂíåÂ¢ûÂº∑Êèê‰æõ‰∫ÜË∑ØÁ∑öÂúñÔºåÂ∞àÈñÄÁî®ÊñºÊªøË∂≥Áî¢Ê•≠ÊáâÁî®‰∏çÊñ∑ËÆäÂåñÁöÑÈúÄÊ±Ç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫Áü•Ë≠òÂéüÂ≠êÂåñÂíåÁü•Ë≠òÊÑüÁü•‰ªªÂãôÂàÜËß£Ôºå‰ª•ÊúâÊïàÂú∞ÂæûË≥áÊñôÂçÄÂ°ä‰∏≠ÊèêÂèñÂ§öÊñπÈù¢ÁöÑÁü•Ë≠òÔºå‰∏¶ÂàÜÂà•Ê†πÊìöÂéüÂßãÊü•Ë©¢ÂíåÁ¥ØÁ©çÁöÑÁü•Ë≠òÂèçË¶ÜÂª∫ÊßãÂéüÁêÜÔºåÂ±ïÁ§∫‰∫ÜÂú®ÂêÑÁ®ÆÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÁöÑÂá∫Ëâ≤ÊïàËÉΩ„ÄÇ

##### **Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas**
2501.11549v1 by Nishant Balepur, Vishakh Padmakumar, Fumeng Yang, Shi Feng, Rachel Rudinger, Jordan Lee Boyd-Graber

LLMs are tuned to follow instructions (aligned) by learning which of two
outputs users prefer for a prompt. However, this preference data format does
not convey why users prefer responses that are chosen or rejected, so LLMs
trained on these datasets cannot tailor responses to varied user needs. To
surface these parameters of personalization, we apply abductive reasoning to
preference data, inferring needs and interests of users, i.e. personas, that
may prefer each output. We test this idea in two steps: Persona Inference
(PI)-abductively inferring personas of users who prefer chosen or rejected
outputs-and Persona Tailoring (PT)-training models to tailor responses to
personas from PI. We find: 1) LLMs infer personas accurately explaining why
different users may prefer both chosen or rejected outputs; 2) Training on
preference data augmented with PI personas via PT boosts personalization,
enabling models to support user-written personas; and 3) Rejected response
personas form harder personalization evaluations, showing PT better aids users
with uncommon preferences versus typical alignment methods. We argue for an
abductive view of preferences for personalization, asking not only which
response is better but when, why, and for whom.

ÊëòË¶ÅÔºöLLM ÊúÉÈÄèÈÅéÂ≠∏Áøí‰ΩøÁî®ËÄÖÂÅèÂ•ΩÁöÑÂÖ©ÂÄãËº∏Âá∫ÔºåË™øÊï¥ÁÇ∫ÈÅµÂæ™Êåá‰ª§ÔºàÂ∞çÈΩäÔºâ„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÂÅèÂ•ΩË≥áÊñôÊ†ºÂºè‰∏¶Êú™ÂÇ≥ÈÅî‰ΩøÁî®ËÄÖÂÅèÂ•ΩÈÅ∏ÊìáÊàñÊãíÁµïÂõûÊáâÁöÑÂéüÂõ†ÔºåÂõ†Ê≠§Âú®ÈÄô‰∫õË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑ LLM ÁÑ°Ê≥ïÈáùÂ∞ç‰∏çÂêåÁöÑ‰ΩøÁî®ËÄÖÈúÄÊ±ÇË™øÊï¥ÂõûÊáâ„ÄÇÁÇ∫‰∫Ü‰∫ÜËß£ÈÄô‰∫õÂÄã‰∫∫ÂåñÂèÉÊï∏ÔºåÊàëÂÄëÂ∞áÊºîÁππÊé®ÁêÜÊáâÁî®ÊñºÂÅèÂ•ΩË≥áÊñôÔºåÊé®Ë´ñÂá∫ÂèØËÉΩÂÅèÂ•ΩÊØèÂÄãËº∏Âá∫ÁöÑ‰ΩøÁî®ËÄÖÈúÄÊ±ÇÂíåËààË∂£ÔºåÂç≥ËßíËâ≤„ÄÇÊàëÂÄëÂàÜÁÇ∫ÂÖ©ÂÄãÊ≠•È©üÊ∏¨Ë©¶ÈÄôÂÄãÊÉ≥Ê≥ïÔºöËßíËâ≤Êé®Ë´ñ (PI) - ÊºîÁππÊé®Ë´ñÂÅèÂ•ΩÈÅ∏ÂèñÊàñÊãíÁµïËº∏Âá∫ÁöÑ‰ΩøÁî®ËÄÖÁöÑËßíËâ≤Ôºå‰ª•ÂèäËßíËâ≤Ë™øÊï¥ (PT) - Ë®ìÁ∑¥Ê®°Âûã‰ª•Ë™øÊï¥ÂõûÊáâ‰ª•Á¨¶Âêà PI ‰∏≠ÁöÑËßíËâ≤„ÄÇÊàëÂÄëÁôºÁèæÔºö1) LLM Êé®Ë´ñËßíËâ≤Ê∫ñÁ¢∫Ëß£Èáã‰∫ÜÁÇ∫‰ªÄÈ∫º‰∏çÂêåÁöÑ‰ΩøÁî®ËÄÖÂèØËÉΩÂÅèÂ•ΩÈÅ∏ÂèñÊàñÊãíÁµïÁöÑËº∏Âá∫Ôºõ2) ÈÄèÈÅé PTÔºå‰ΩøÁî® PI ËßíËâ≤Êì¥ÂÖÖÂÅèÂ•ΩË≥áÊñôÈÄ≤Ë°åË®ìÁ∑¥ÔºåÊúÉÊèêÂçáÂÄã‰∫∫ÂåñÔºåËÆìÊ®°ÂûãËÉΩÊîØÊè¥‰ΩøÁî®ËÄÖÊí∞ÂØ´ÁöÑËßíËâ≤Ôºõ3) Ë¢´ÊãíÁµïÁöÑÂõûÊáâËßíËâ≤ÂΩ¢ÊàêÊõ¥Âõ∞Èõ£ÁöÑÂÄã‰∫∫ÂåñË©ï‰º∞ÔºåÈ°ØÁ§∫ PT ÊØîÂÖ∏ÂûãÁöÑÂ∞çÈΩäÊñπÊ≥ïÊõ¥ËÉΩÂçîÂä©ÂÖ∑Êúâ‰∏çÂ∏∏Ë¶ãÂÅèÂ•ΩÁöÑ‰ΩøÁî®ËÄÖ„ÄÇÊàëÂÄë‰∏ªÂºµÊºîÁππÂÅèÂ•Ω‰ª•ÈÄ≤Ë°åÂÄã‰∫∫ÂåñÔºå‰∏çÂÉÖË©¢ÂïèÂì™ÂÄãÂõûÊáâËºÉÂ•ΩÔºåÈÇÑË¶ÅË©¢Âïè‰ΩïÊôÇ„ÄÅÁÇ∫‰Ωï‰ª•ÂèäÂ∞çË™∞ËºÉÂ•Ω„ÄÇ

##### **Technical Report for the Forgotten-by-Design Project: Targeted Obfuscation for Machine Learning**
2501.11525v1 by Rickard Br√§nnvall, Laurynas Adomaitis, Olof G√∂rnerup, Anass Sedrati

The right to privacy, enshrined in various human rights declarations, faces
new challenges in the age of artificial intelligence (AI). This paper explores
the concept of the Right to be Forgotten (RTBF) within AI systems, contrasting
it with traditional data erasure methods. We introduce Forgotten by Design, a
proactive approach to privacy preservation that integrates instance-specific
obfuscation techniques during the AI model training process. Unlike machine
unlearning, which modifies models post-training, our method prevents sensitive
data from being embedded in the first place. Using the LIRA membership
inference attack, we identify vulnerable data points and propose defenses that
combine additive gradient noise and weighting schemes. Our experiments on the
CIFAR-10 dataset demonstrate that our techniques reduce privacy risks by at
least an order of magnitude while maintaining model accuracy (at 95%
significance). Additionally, we present visualization methods for the
privacy-utility trade-off, providing a clear framework for balancing privacy
risk and model accuracy. This work contributes to the development of
privacy-preserving AI systems that align with human cognitive processes of
motivated forgetting, offering a robust framework for safeguarding sensitive
information and ensuring compliance with privacy regulations.

ÊëòË¶ÅÔºöÈö±ÁßÅÊ¨äÂà©Âú®ÂêÑÁ®Æ‰∫∫Ê¨äÂÆ£Ë®Ä‰∏≠ÂèóÂà∞‰øùÈöúÔºåÂú®‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÊôÇ‰ª£Èù¢Ëá®Êñ∞ÁöÑÊåëÊà∞„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±‰∏≠ÁöÑË¢´ÈÅ∫ÂøòÊ¨äÔºàRTBFÔºâÊ¶ÇÂøµÔºå‰∏¶Â∞áÂÖ∂ËàáÂÇ≥Áµ±Êï∏ÊìöÂà™Èô§ÊñπÊ≥ïÈÄ≤Ë°åÂ∞çÊØî„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü„ÄåË®≠Ë®à‰∏≠ÁöÑÈÅ∫Âøò„ÄçÔºå‰∏ÄÁ®Æ‰∏ªÂãïÁöÑÈö±ÁßÅ‰øùË≠∑ÊñπÊ≥ïÔºåÂú®‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãË®ìÁ∑¥ÈÅéÁ®ã‰∏≠Êï¥Âêà‰∫ÜÁâπÂÆöÂØ¶‰æãÁöÑÊ®°Á≥äÂåñÊäÄË°ì„ÄÇËàáË®ìÁ∑¥Âæå‰øÆÊîπÊ®°ÂûãÁöÑÊ©üÂô®ÂéªÂ≠∏Áøí‰∏çÂêåÔºåÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïÂèØÈò≤Ê≠¢ÊïèÊÑüÊï∏ÊìöÂæû‰∏ÄÈñãÂßãÂ∞±Ë¢´ÂµåÂÖ•„ÄÇ‰ΩøÁî® LIRA ÊúÉÂì°Êé®Ë´ñÊîªÊìäÔºåÊàëÂÄëË≠òÂà•Âá∫ÊòìÂèóÊîªÊìäÁöÑÊï∏ÊìöÈªûÔºå‰∏¶ÊèêÂá∫ÁµêÂêàÂä†ÊÄßÊ¢ØÂ∫¶Âô™ËÅ≤ÂíåÂä†Ê¨äÊñπÊ°àÁöÑÈò≤Á¶¶Êé™ÊñΩ„ÄÇÊàëÂÄëÂú® CIFAR-10 Êï∏ÊìöÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊäÄË°ìÂèØÂ∞áÈö±ÁßÅÈ¢®Èö™Èôç‰ΩéËá≥Â∞ë‰∏ÄÂÄãÊï∏ÈáèÁ¥öÔºåÂêåÊôÇÁ∂≠ÊåÅÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÔºàÈ°ØËëóÊÄßÁÇ∫ 95%Ôºâ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫Èö±ÁßÅÊïàÁî®Ê¨äË°°ÁöÑÂèØË¶ñÂåñÊñπÊ≥ïÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂπ≥Ë°°Èö±ÁßÅÈ¢®Èö™ÂíåÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÁöÑÊ∏ÖÊô∞Ê°ÜÊû∂„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊúâÂä©ÊñºÈñãÁôºÁ¨¶Âêà‰∫∫È°ûÂãïÊ©üÈÅ∫ÂøòË™çÁü•ÈÅéÁ®ãÁöÑÈö±ÁßÅ‰øùË≠∑‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÔºåÊèê‰æõ‰∏ÄÂÄãÂº∑Â§ßÁöÑÊ°ÜÊû∂‰æÜ‰øùË≠∑ÊïèÊÑüË≥áË®ä‰∏¶Á¢∫‰øùÁ¨¶ÂêàÈö±ÁßÅÊ≥ïË¶è„ÄÇ

##### **Dialect2SQL: A Novel Text-to-SQL Dataset for Arabic Dialects with a Focus on Moroccan Darija**
2501.11498v1 by Salmane Chafik, Saad Ezzini, Ismail Berrada

The task of converting natural language questions (NLQs) into executable SQL
queries, known as text-to-SQL, has gained significant interest in recent years,
as it enables non-technical users to interact with relational databases. Many
benchmarks, such as SPIDER and WikiSQL, have contributed to the development of
new models and the evaluation of their performance. In addition, other
datasets, like SEDE and BIRD, have introduced more challenges and complexities
to better map real-world scenarios. However, these datasets primarily focus on
high-resource languages such as English and Chinese. In this work, we introduce
Dialect2SQL, the first large-scale, cross-domain text-to-SQL dataset in an
Arabic dialect. It consists of 9,428 NLQ-SQL pairs across 69 databases in
various domains. Along with SQL-related challenges such as long schemas, dirty
values, and complex queries, our dataset also incorporates the complexities of
the Moroccan dialect, which is known for its diverse source languages, numerous
borrowed words, and unique expressions. This demonstrates that our dataset will
be a valuable contribution to both the text-to-SQL community and the
development of resources for low-resource languages.

ÊëòË¶ÅÔºöÂ∞áËá™ÁÑ∂Ë™ûË®ÄÂïèÈ°å (NLQ) ËΩâÊèõÁÇ∫ÂèØÂü∑Ë°åÁöÑ SQL Êü•Ë©¢ÔºàÁ®±ÁÇ∫ÊñáÂ≠óËΩâ SQLÔºâÁöÑ‰ªªÂãôÂú®ËøëÂπ¥‰æÜÁç≤ÂæóÈ°ØËëóÁöÑÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÂÆÉËÆìÈùûÊäÄË°ì‰ΩøÁî®ËÄÖËÉΩÂ§†ËàáÈóú‰øÇË≥áÊñôÂ∫´‰∫íÂãï„ÄÇË®±Â§öÂü∫Ê∫ñÔºå‰æãÂ¶Ç SPIDER Âíå WikiSQLÔºåÂ∞çÊñ∞Ê®°ÂûãÁöÑÈñãÁôºÂíåÂÖ∂ÊïàËÉΩË©ï‰º∞ÊúâË≤¢Áçª„ÄÇÊ≠§Â§ñÔºåÂÖ∂‰ªñË≥áÊñôÈõÜÔºå‰æãÂ¶Ç SEDE Âíå BIRDÔºåÂºïÂÖ•‰∫ÜÊõ¥Â§öÊåëÊà∞ÂíåË§áÈõúÊÄßÔºå‰ª•Êõ¥Â•ΩÂú∞Â∞çÊáâÁúüÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õË≥áÊñôÈõÜ‰∏ªË¶ÅÈóúÊ≥®È´òË≥áÊ∫êË™ûË®ÄÔºå‰æãÂ¶ÇËã±Ë™ûÂíå‰∏≠Êñá„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π Dialect2SQLÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ§ßÂûã„ÄÅË∑®È†òÂüüÁöÑÈòøÊãâ‰ºØÊñπË®ÄÊñáÂ≠óËΩâ SQL Ë≥áÊñôÈõÜ„ÄÇÂÆÉÂåÖÂê´ 69 ÂÄã‰∏çÂêåÈ†òÂüüË≥áÊñôÂ∫´‰∏≠ÁöÑ 9,428 ÂÄã NLQ-SQL Â∞ç„ÄÇÈô§‰∫Ü SQL Áõ∏ÈóúÁöÑÊåëÊà∞Ôºå‰æãÂ¶ÇÈï∑Ê®°Âºè„ÄÅÈ´íÂÄºÂíåË§áÈõúÊü•Ë©¢ÔºåÊàëÂÄëÁöÑË≥áÊñôÈõÜÈÇÑÁ¥çÂÖ•‰∫ÜÊë©Ê¥õÂì•ÊñπË®ÄÁöÑË§áÈõúÊÄßÔºåÊë©Ê¥õÂì•ÊñπË®Ä‰ª•ÂÖ∂Â§öÊ®£ÁöÑÂéüÂßãË™ûË®Ä„ÄÅÂ§ßÈáèÁöÑÂÄüÁî®Ë©ûÂíåÁç®ÁâπÁöÑË°®ÈÅîÊñπÂºèËÄåËÅûÂêç„ÄÇÈÄôË°®Á§∫ÊàëÂÄëÁöÑË≥áÊñôÈõÜÂ∞áÂ∞çÊñáÂ≠óËΩâ SQL Á§æÁæ§Âíå‰ΩéË≥áÊ∫êË™ûË®ÄË≥áÊ∫êÁöÑÈñãÁôºÂÅöÂá∫ÂØ∂Ë≤¥ÁöÑË≤¢Áçª„ÄÇ

##### **Generative AI and Large Language Models in Language Preservation: Opportunities and Challenges**
2501.11496v1 by Vincent Koc

Generative AI and large-scale language models (LLM) have emerged as powerful
tools in language preservation, particularly for near-native and endangered
languages. With the increasing reliance on technology for communication,
education, and cultural documentation, new opportunities have emerged to
mitigate the dramatic decline of linguistic diversity worldwide. This paper
examines the role of generative AIs and LLMs in preserving endangered
languages, highlighting the risks and challenges associated with their use. We
analyze the underlying technologies driving these models, including natural
language processing (NLP) and deep learning, and explore several cases where
these technologies have been applied to low-resource languages. Additionally,
we discuss ethical considerations, data scarcity issues, and technical
challenges while proposing solutions to enhance AI-driven language
preservation.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊàêÁÇ∫Ë™ûË®Ä‰øùÂ≠òÁöÑÊúâÂäõÂ∑•ÂÖ∑ÔºåÁâπÂà•ÊòØÂ∞çÊñºÊé•ËøëÊØçË™ûÂíåÁÄïËá®ÊªÖÁµïÁöÑË™ûË®Ä„ÄÇÈö®ËëóË∂ä‰æÜË∂ä‰æùË≥¥ÊäÄË°ìÈÄ≤Ë°åÊ∫ùÈÄö„ÄÅÊïôËÇ≤ÂíåÊñáÂåñË®òÈåÑÔºåÂ∑≤Âá∫ÁèæÊñ∞ÁöÑÊ©üÊúÉ‰æÜÊ∏õËºïÂÖ®ÁêÉË™ûË®ÄÂ§öÊ®£ÊÄßÁöÑÊÄ•Âäá‰∏ãÈôç„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÁîüÊàêÂºè AI Âíå LLM Âú®‰øùË≠∑ÁÄïËá®ÊªÖÁµïÁöÑË™ûË®Ä‰∏≠ÊâÄÊâÆÊºîÁöÑËßíËâ≤Ôºå‰∏¶Âº∑Ë™ø‰∫ÜËàáÂÖ∂‰ΩøÁî®Áõ∏ÈóúÁöÑÈ¢®Èö™ÂíåÊåëÊà∞„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÈ©ÖÂãïÈÄô‰∫õÊ®°ÂûãÁöÑÂü∫Á§éÊäÄË°ìÔºåÂåÖÊã¨Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÊ∑±Â∫¶Â≠∏ÁøíÔºå‰∏¶Êé¢Ë®é‰∫ÜÈÄô‰∫õÊäÄË°ìÊáâÁî®Êñº‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÂπæÂÄãÊ°à‰æã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®ÊèêÂá∫Â¢ûÂº∑ AI È©ÖÂãïÁöÑË™ûË®Ä‰øùÂ≠òÁöÑËß£Ê±∫ÊñπÊ°àÊôÇÔºåË®éË´ñ‰∫ÜÈÅìÂæ∑ËÄÉÈáè„ÄÅË≥áÊñôÁ®ÄÂ∞ëÂïèÈ°åÂíåÊäÄË°ìÊåëÊà∞„ÄÇ

##### **Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification**
2501.11493v1 by Jonas Klotz, Barƒ±≈ü B√ºy√ºkta≈ü, Beg√ºm Demir

Federated learning (FL) is a decentralized machine learning paradigm, where
multiple clients collaboratively train a global model by exchanging only model
updates with the central server without sharing the local data of clients. Due
to the large volume of model updates required to be transmitted between clients
and the central server, most FL systems are associated with high transfer costs
(i.e., communication overhead). This issue is more critical for operational
applications in remote sensing (RS), especially when large-scale RS data is
processed and analyzed through FL systems with restricted communication
bandwidth. To address this issue, we introduce an explanation-guided pruning
strategy for communication-efficient FL in the context of RS image
classification. Our pruning strategy is defined based on the layerwise
relevance propagation (LRP) driven explanations to: 1) efficiently and
effectively identify the most relevant and informative model parameters (to be
exchanged between clients and the central server); and 2) eliminate the
non-informative ones to minimize the volume of model updates. The experimental
results on the BigEarthNet-S2 dataset demonstrate that our strategy effectively
reduces the number of shared model updates, while increasing the generalization
ability of the global model. The code of this work will be publicly available
at https://git.tu-berlin.de/rsim/FL-LRP

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏Áøí (FL) ÊòØ‰∏ÄÁ®ÆÂàÜÊï£ÂºèÊ©üÂô®Â≠∏ÁøíÁØÑ‰æãÔºåÂÖ∂‰∏≠Â§öÂÄãÁî®Êà∂ÈÄèÈÅéÂÉÖËàá‰∏≠Â§Æ‰º∫ÊúçÂô®‰∫§ÊèõÊ®°ÂûãÊõ¥Êñ∞ÔºåÂú®‰∏çÂÖ±Áî®Áî®Êà∂Á´ØÊú¨Âú∞Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂÖ±ÂêåË®ìÁ∑¥‰∏ÄÂÄãÂÖ®ÁêÉÊ®°Âûã„ÄÇÁî±ÊñºÁî®Êà∂Á´ØËàá‰∏≠Â§Æ‰º∫ÊúçÂô®‰πãÈñìÈúÄË¶ÅÂÇ≥Ëº∏Â§ßÈáèÁöÑÊ®°ÂûãÊõ¥Êñ∞ÔºåÂõ†Ê≠§Â§ßÂ§öÊï∏ FL Á≥ªÁµ±ÈÉΩËàáÈ´òÂÇ≥Ëº∏ÊàêÊú¨ÔºàÂç≥ÈÄöË®äË≤†ÊìîÔºâÊúâÈóú„ÄÇÈÄôÂÄãÂïèÈ°åÂ∞çÊñºÈÅôÊ∏¨ (RS) ‰∏≠ÁöÑÈÅã‰ΩúÊáâÁî®Á®ãÂºè‰æÜË™™Êõ¥ÁÇ∫Âö¥Â≥ªÔºåÁâπÂà•ÊòØÂú®ÈÄèÈÅéÈÄöË®äÈ†ªÂØ¨ÂèóÈôêÁöÑ FL Á≥ªÁµ±ËôïÁêÜÂíåÂàÜÊûêÂ§ßË¶èÊ®° RS Ë≥áÊñôÊôÇ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú® RS ÂΩ±ÂÉèÂàÜÈ°ûÁöÑËÑàÁµ°‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî±Ëß£ÈáãÂºïÂ∞éÁöÑÂâ™ÊûùÁ≠ñÁï•Ôºå‰ª•ÂØ¶ÁèæÈÄöË®äÊïàÁéáÈ´òÁöÑ FL„ÄÇÊàëÂÄëÁöÑÂâ™ÊûùÁ≠ñÁï•ÊòØÊ†πÊìöÁî±Â±§Á¥öÁõ∏ÈóúÊÄßÂÇ≥Êí≠ (LRP) È©ÖÂãïÁöÑËß£Èáã‰æÜÂÆöÁæ©ÁöÑÔºåÁõÆÁöÑÊòØÔºö1) ÊúâÊïà‰∏îÈ´òÊïàÁéáÂú∞ÊâæÂá∫ÊúÄÁõ∏Èóú‰∏îÂÖ∑ÊúâË≥áË®äÊÄßÁöÑÊ®°ÂûãÂèÉÊï∏ÔºàÂú®Áî®Êà∂Á´ØËàá‰∏≠Â§Æ‰º∫ÊúçÂô®‰πãÈñì‰∫§ÊèõÔºâÔºõ‰ª•Âèä 2) Ê∂àÈô§ÈùûË≥áË®äÊÄßÁöÑÂèÉÊï∏Ôºå‰ª•ÊúÄÂ∞èÂåñÊ®°ÂûãÊõ¥Êñ∞ÁöÑÊï∏Èáè„ÄÇÂú® BigEarthNet-S2 Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÁöÑÁ≠ñÁï•ÊúâÊïàÊ∏õÂ∞ë‰∫ÜÂÖ±Áî®Ê®°ÂûãÊõ¥Êñ∞ÁöÑÊï∏ÈáèÔºåÂêåÊôÇÂ¢ûÂä†‰∫ÜÂÖ®ÁêÉÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÁ®ãÂºèÁ¢ºÂ∞áÂú® https://git.tu-berlin.de/rsim/FL-LRP ÂÖ¨Èñã„ÄÇ

##### **Graph-defined Language Learning with LLMs**
2501.11478v1 by Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang

Recent efforts leverage Large Language Models (LLMs) for modeling
text-attributed graph structures in node classification tasks. These approaches
describe graph structures for LLMs to understand or aggregate LLM-generated
textual attribute embeddings through graph structure. However, these approaches
face two main limitations in modeling graph structures with LLMs. (i) Graph
descriptions become verbose in describing high-order graph structure. (ii)
Textual attributes alone do not contain adequate graph structure information.
It is challenging to model graph structure concisely and adequately with LLMs.
LLMs lack built-in mechanisms to model graph structures directly. They also
struggle with complex long-range dependencies between high-order nodes and
target nodes.
  Inspired by the observation that LLMs pre-trained on one language can achieve
exceptional performance on another with minimal additional training, we propose
\textbf{G}raph-\textbf{D}efined \textbf{L}anguage for \textbf{L}arge
\textbf{L}anguage \textbf{M}odel (GDL4LLM). This novel framework enables LLMs
to transfer their powerful language understanding capabilities to
graph-structured data. GDL4LLM translates graphs into a graph language corpus
instead of graph descriptions and pre-trains LLMs on this corpus to adequately
understand graph structures. During fine-tuning, this corpus describes the
structural information of target nodes concisely with only a few tokens. By
treating graphs as a new language, GDL4LLM enables LLMs to model graph
structures adequately and concisely for node classification tasks. Extensive
experiments on three real-world datasets demonstrate that GDL4LLM outperforms
description-based and textual attribute embeddings-based baselines by
efficiently modeling different orders of graph structure with LLMs.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÁöÑÁ†îÁ©∂Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÁØÄÈªûÂàÜÈ°û‰ªªÂãô‰∏≠Â∞çÊñáÊú¨Â±¨ÊÄßÂúñÁµêÊßãÈÄ≤Ë°åÂª∫Ê®°„ÄÇÈÄô‰∫õÊñπÊ≥ïÊèèËø∞ÂúñÁµêÊßãÔºåËÆì LLM ‰∫ÜËß£ÊàñÂΩôÁ∏ΩÈÄöÈÅéÂúñÁµêÊßãÁîüÊàêÁöÑ LLM ÊñáÊú¨Â±¨ÊÄßÂµåÂÖ•„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂú®‰ΩøÁî® LLM Â∞çÂúñÁµêÊßãÈÄ≤Ë°åÂª∫Ê®°ÊôÇÈù¢Ëá®ÂÖ©ÂÄã‰∏ªË¶ÅÈôêÂà∂„ÄÇ(i) ÂúñÊèèËø∞Âú®ÊèèËø∞È´òÈöéÂúñÁµêÊßãÊôÇËÆäÂæóÂÜóÈï∑„ÄÇ(ii) ÂÉÖÊñáÊú¨Â±¨ÊÄß‰∏çÂåÖÂê´Ë∂≥Â§†ÁöÑÂúñÁµêÊßãË≥áË®ä„ÄÇ‰ΩøÁî® LLM Â∞çÂúñÁµêÊßãÈÄ≤Ë°åÁ∞°ÊΩî‰∏îÂÖÖÂàÜÁöÑÂª∫Ê®°ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇLLM Áº∫‰πèÂÖßÂª∫Ê©üÂà∂‰æÜÁõ¥Êé•Â∞çÂúñÁµêÊßãÈÄ≤Ë°åÂª∫Ê®°„ÄÇÂÆÉÂÄëÈÇÑÈõ£‰ª•ËôïÁêÜÈ´òÈöéÁØÄÈªûÂíåÁõÆÊ®ôÁØÄÈªû‰πãÈñìË§áÈõúÁöÑÈï∑Á®ã‰æùË≥¥Èóú‰øÇ„ÄÇ
Âèó LLM Âú®‰∏ÄÁ®ÆË™ûË®Ä‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÂæåÔºåÂà©Áî®ÊúÄÂ∞ëÁöÑÈ°çÂ§ñË®ìÁ∑¥Â∞±ËÉΩÂú®Âè¶‰∏ÄÁ®ÆË™ûË®Ä‰∏äÂèñÂæóÈùûÂá°Ë°®ÁèæÁöÑËßÄÂØüÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂúñÂÆöÁæ©Ë™ûË®Ä (GDL4LLM)„ÄÇÈÄôÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂‰Ωø LLM ËÉΩÂ∞áÂÖ∂Âº∑Â§ßÁöÑË™ûË®ÄÁêÜËß£ËÉΩÂäõËΩâÁßªÂà∞ÂúñÁµêÊßãË≥áÊñô„ÄÇGDL4LLM Â∞áÂúñÂΩ¢ËΩâÊèõÊàêÂúñÂΩ¢Ë™ûË®ÄË™ûÊñôÂ∫´ÔºåËÄå‰∏çÊòØÂúñÂΩ¢ÊèèËø∞Ôºå‰∏¶Âú®ÈÄôÂÄãË™ûÊñôÂ∫´‰∏äÂ∞ç LLM ÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰ª•ÂÖÖÂàÜÁêÜËß£ÂúñÂΩ¢ÁµêÊßã„ÄÇÂú®ÂæÆË™øÈÅéÁ®ã‰∏≠ÔºåÈÄôÂÄãË™ûÊñôÂ∫´ÂÉÖ‰ΩøÁî®Â∞ëÊï∏ÂπæÂÄãÊ®ôË®òÔºåÂ∞±ËÉΩÁ∞°ÊΩîÂú∞ÊèèËø∞ÁõÆÊ®ôÁØÄÈªûÁöÑÁµêÊßãË≥áË®ä„ÄÇÈÄèÈÅéÂ∞áÂúñÂΩ¢Ë¶ñÁÇ∫‰∏ÄÁ®ÆÊñ∞ÁöÑË™ûË®ÄÔºåGDL4LLM ‰Ωø LLM ËÉΩÂ§†ÂÖÖÂàÜ‰∏îÁ∞°ÊΩîÂú∞ÁÇ∫ÁØÄÈªûÂàÜÈ°û‰ªªÂãôÂ∞çÂúñÂΩ¢ÁµêÊßãÈÄ≤Ë°åÂª∫Ê®°„ÄÇÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåGDL4LLM ËÉΩÊúâÊïàÂú∞‰ΩøÁî® LLM Â∞ç‰∏çÂêåÈ†ÜÂ∫èÁöÑÂúñÂΩ¢ÁµêÊßãÈÄ≤Ë°åÂª∫Ê®°ÔºåÂæûËÄåÂÑ™ÊñºÂü∫ÊñºÊèèËø∞ÂíåÂü∫ÊñºÊñáÊú¨Â±¨ÊÄßÂµåÂÖ•ÁöÑÂü∫Ê∫ñ„ÄÇ</paragraph>

##### **Curiosity-Driven Reinforcement Learning from Human Feedback**
2501.11463v1 by Haoran Sun, Yekun Chai, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang

Reinforcement learning from human feedback (RLHF) has proven effective in
aligning large language models (LLMs) with human preferences, but often at the
cost of reduced output diversity. This trade-off between diversity and
alignment quality remains a significant challenge. Drawing inspiration from
curiosity-driven exploration in reinforcement learning, we introduce
curiosity-driven RLHF (CD-RLHF), a framework that incorporates intrinsic
rewards for novel states, alongside traditional sparse extrinsic rewards, to
optimize both output diversity and alignment quality. We demonstrate the
effectiveness of CD-RLHF through extensive experiments on a range of tasks,
including text summarization and instruction following. Our approach achieves
significant gains in diversity on multiple diversity-oriented metrics while
maintaining alignment with human preferences comparable to standard RLHF. We
make our code publicly available at https://github.com/ernie-research/CD-RLHF.

ÊëòË¶ÅÔºöÈÄèÈÅé‰∫∫È°ûÂõûÈ•ãÁöÑÂº∑ÂåñÂ≠∏Áøí (RLHF) Â∑≤Ë¢´Ë≠âÂØ¶ËÉΩÊúâÊïàÂú∞Â∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëàá‰∫∫È°ûÂÅèÂ•ΩÂ∞çÈΩäÔºå‰ΩÜÈÄöÂ∏∏ÊúÉÁäßÁâ≤Ëº∏Âá∫Â§öÊ®£ÊÄß„ÄÇÈÄôÁ®ÆÂ§öÊ®£ÊÄßÂíåÂ∞çÈΩäÂìÅË≥™‰πãÈñìÁöÑÂèñÊç®‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂæûÂº∑ÂåñÂ≠∏Áøí‰∏≠ÁöÑÂ•ΩÂ•áÂøÉÈ©ÖÂãïÊé¢Á¥¢‰∏≠Ê±≤ÂèñÈùàÊÑüÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂ•ΩÂ•áÂøÉÈ©ÖÂãïÁöÑ RLHF (CD-RLHF)Ôºå‰∏ÄÂÄãÊ°ÜÊû∂ÔºåÂÆÉÁµêÂêà‰∫ÜÂ∞çÊñ∞ÁãÄÊÖãÁöÑÂÖßÂú®ÁçéÂãµÔºå‰ª•ÂèäÂÇ≥Áµ±ÁöÑÁ®ÄÁñèÂ§ñÂú®ÁçéÂãµÔºå‰ª•ÂêåÊôÇÊúÄ‰Ω≥ÂåñËº∏Âá∫Â§öÊ®£ÊÄßÂíåÂ∞çÈΩäÂìÅË≥™„ÄÇÊàëÂÄëÈÄèÈÅé‰∏ÄÁ≥ªÂàó‰ªªÂãôÁöÑÂª£Ê≥õÂØ¶È©óÔºåÂåÖÊã¨ÊñáÂ≠óÊëòË¶ÅÂíåÊåá‰ª§ÈÅµÂæ™Ôºå‰æÜÂ±ïÁ§∫ CD-RLHF ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Â§öÂÄã‰ª•Â§öÊ®£ÊÄßÁÇ∫Â∞éÂêëÁöÑÊåáÊ®ô‰∏äÈÅîÂà∞‰∫ÜÈ°ØËëóÁöÑÂ§öÊ®£ÊÄßÊèêÂçáÔºåÂêåÊôÇÁ∂≠ÊåÅËàá‰∫∫È°ûÂÅèÂ•ΩÁöÑÂ∞çÈΩäÔºåÈÄôËàáÊ®ôÊ∫ñ RLHF Áõ∏Áï∂„ÄÇÊàëÂÄëÂú® https://github.com/ernie-research/CD-RLHF ÂÖ¨ÈñãÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÇ

##### **Improving thermal state preparation of Sachdev-Ye-Kitaev model with reinforcement learning on quantum hardware**
2501.11454v1 by Akash Kundu

The Sachdev-Ye-Kitaev (SYK) model, known for its strong quantum correlations
and chaotic behavior, serves as a key platform for quantum gravity studies.
However, variationally preparing thermal states on near-term quantum processors
for large systems (N>12, where N is the number of Majorana fermions) presents a
significant challenge due to the rapid growth in the complexity of
parameterized quantum circuits. This paper addresses this challenge by
integrating reinforcement learning (RL) with convolutional neural networks,
employing an iterative approach to optimize the quantum circuit and its
parameters. The refinement process is guided by a composite reward signal
derived from entropy and the expectation values of the SYK Hamiltonian. This
approach reduces the number of CNOT gates by two orders of magnitude for
systems N>10 compared to traditional methods like first-order Trotterization.
We demonstrate the effectiveness of the RL framework in both noiseless and
noisy quantum hardware environments, maintaining high accuracy in thermal state
preparation. This work contributes to the advancement of a scalable, RL-based
framework with applications for computations of thermal out-of-time-order
correlators in quantum many-body systems and quantum gravity studies on
near-term quantum hardware.

ÊëòË¶ÅÔºöËñ©Â•áÂæ∑Â§´-Ëëâ-Âü∫Ê≥∞Â§´ÔºàSYKÔºâÊ®°Âûã‰ª•ÂÖ∂Âº∑ÁÉàÁöÑÈáèÂ≠êÈóúËÅØÊÄßÂíåÊ∑∑‰∫ÇË°åÁÇ∫ËÄåËÅûÂêçÔºåÂèØÁî®‰ΩúÈáèÂ≠êÈáçÂäõÁ†îÁ©∂ÁöÑ‰∏ÄÂÄãÈóúÈçµÂπ≥Âè∞„ÄÇ
ÁÑ∂ËÄåÔºåÂú®ËøëÊúüÁöÑÈáèÂ≠êËôïÁêÜÂô®‰∏äÁÇ∫Â§ßÂûãÁ≥ªÁµ±ÔºàN>12ÔºåÂÖ∂‰∏≠ N ÊòØÈ¶¨Á¥ÑÊãâÈÇ£Ë≤ªÁ±≥Â≠êÁöÑÊï∏ÈáèÔºâÊ∫ñÂÇôËÆäÂàÜÁÜ±ÊÖãÊòØ‰∏ÄÂÄãÈáçÂ§ßÊåëÊà∞ÔºåÂõ†ÁÇ∫ÂèÉÊï∏ÂåñÈáèÂ≠êÈõªË∑ØÁöÑË§áÈõúÊÄßÊúÉËøÖÈÄüÂ¢ûÂä†„ÄÇ
Êú¨ÊñáÈÄöÈÅéÂ∞áÂº∑ÂåñÂ≠∏ÁøíÔºàRLÔºâËàáÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊï¥ÂêàÔºåÊé°Áî®Ëø≠‰ª£ÊñπÊ≥ï‰æÜÂÑ™ÂåñÈáèÂ≠êÈõªË∑ØÂèäÂÖ∂ÂèÉÊï∏ÔºåÂæûËÄåÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞„ÄÇ
ÂÑ™ÂåñÈÅéÁ®ãÁî±‰∏ÄÂÄãË§áÂêàÁçéÂãµ‰ø°ËôüÂºïÂ∞éÔºåË©≤‰ø°Ëôü‰æÜËá™ÁÜµÂíå SYK ÂìàÂØÜÈ†ìÈáèÁöÑÊúüÊúõÂÄº„ÄÇ
Ëàá‰∏ÄÈöé Trotterization Á≠âÂÇ≥Áµ±ÊñπÊ≥ïÁõ∏ÊØîÔºåÈÄôÁ®ÆÊñπÊ≥ïÂ∞á N>10 Á≥ªÁµ±ÁöÑ CNOT ÈñÄÊï∏ÈáèÊ∏õÂ∞ë‰∫ÜÂÖ©ÂÄãÊï∏ÈáèÁ¥ö„ÄÇ
ÊàëÂÄëÂú®ÁÑ°Âô™ËÅ≤ÂíåÊúâÂô™ËÅ≤ÈáèÂ≠êÁ°¨È´îÁí∞Â¢É‰∏≠Â±ïÁ§∫‰∫Ü RL Ê°ÜÊû∂ÁöÑÊúâÊïàÊÄßÔºåÂú®ÁÜ±ÊÖãÊ∫ñÂÇô‰∏≠‰øùÊåÅ‰∫ÜÈ´òÁ≤æÂ∫¶„ÄÇ
ÈÄôÈ†ÖÂ∑•‰ΩúÊúâÂä©ÊñºÊé®ÂãïÂü∫Êñº RL ÁöÑÂèØÊì¥ÂÖÖÂ•ó‰ª∂Ê°ÜÊû∂ÁöÑÁôºÂ±ïÔºåË©≤Ê°ÜÊû∂ÂèØÊáâÁî®ÊñºÈáèÂ≠êÂ§öÈ´îÁ≥ªÁµ±‰∏≠ÁöÑÁÜ±ÊÖãÊôÇÈñìÈ†ÜÂ∫èÂ§ñÁõ∏ÈóúÂô®ÁöÑË®àÁÆóÂíåËøëÁ®ãÈáèÂ≠êÁ°¨È´î‰∏äÁöÑÈáèÂ≠êÈáçÂäõÁ†îÁ©∂„ÄÇ

##### **Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components**
2501.11447v1 by Abel Jansma

We introduce a novel framework for decomposing interventional causal effects
into synergistic, redundant, and unique components, building on the intuition
of Partial Information Decomposition (PID) and the principle of M\"obius
inversion. While recent work has explored a similar decomposition of an
observational measure, we argue that a proper causal decomposition must be
interventional in nature. We develop a mathematical approach that
systematically quantifies how causal power is distributed among variables in a
system, using a recently derived closed-form expression for the M\"obius
function of the redundancy lattice. The formalism is then illustrated by
decomposing the causal power in logic gates, cellular automata, and chemical
reaction networks. Our results reveal how the distribution of causal power can
be context- and parameter-dependent. This decomposition provides new insights
into complex systems by revealing how causal influences are shared and combined
among multiple variables, with potential applications ranging from attribution
of responsibility in legal or AI systems, to the analysis of biological
networks or climate models.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÁî®‰æÜÂ∞á‰ªãÂÖ•Âõ†ÊûúÈóú‰øÇÂàÜËß£ÁÇ∫ÂçîÂêå„ÄÅÂÜóÈ§òÂíåÁç®ÁâπÊàêÂàÜÔºåÂª∫Á´ãÂú®Â±ÄÈÉ®Ë≥áË®äÂàÜËß£ (PID) ÁöÑÁõ¥Ë¶∫ÂíåËé´ÊØîÁÉèÊñØÂèçÊºîÂéüÁêÜ‰πã‰∏ä„ÄÇÈõñÁÑ∂ÊúÄËøëÁöÑÁ†îÁ©∂Êé¢Á¥¢‰∫ÜËßÄÊ∏¨Ê∏¨ÈáèÁöÑÈ°û‰ººÂàÜËß£ÔºåÊàëÂÄë‰∏ªÂºµÈÅ©Áï∂ÁöÑÂõ†ÊûúÂàÜËß£Êú¨Ë≥™‰∏äÂøÖÈ†àÊòØ‰ªãÂÖ•ÁöÑ„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊï∏Â≠∏ÊñπÊ≥ïÔºåÁ≥ªÁµ±ÊÄßÂú∞ÈáèÂåñÂõ†ÊûúÂäõÂ¶Ç‰ΩïÂú®Á≥ªÁµ±‰∏≠ÁöÑËÆäÊï∏ÈñìÂàÜÈÖçÔºå‰ΩøÁî®ÊúÄËøëË°çÁîüÁöÑÂÜóÈ§òÊ†ºÁöÑËé´ÊØîÁÉèÊñØÂáΩÊï∏ÈñâÂêàÂΩ¢ÂºèË°®ÈÅîÂºè„ÄÇÂΩ¢Âºè‰∏ªÁæ©Èö®ÂæåÈÄèÈÅéÂàÜËß£ÈÇèËºØÈñò„ÄÅÁ¥∞ËÉûËá™ÂãïÊ©üÂíåÂåñÂ≠∏ÂèçÊáâÁ∂≤Ë∑Ø‰∏≠ÁöÑÂõ†ÊûúÂäõ‰æÜË™™Êòé„ÄÇÊàëÂÄëÁöÑÁµêÊûúÊè≠Á§∫‰∫ÜÂõ†ÊûúÂäõÁöÑÂàÜÈÖçÂ¶Ç‰ΩïÂèØËÉΩÊòØ‰æùË≥¥ÊñºËÑàÁµ°ÂíåÂèÉÊï∏ÁöÑ„ÄÇÈÄôÂÄãÂàÜËß£ÈÄèÈÅéÊè≠Á§∫Âõ†ÊûúÂΩ±ÈüøÂ¶Ç‰ΩïÂú®Â§öÂÄãËÆäÊï∏ÈñìÂÖ±‰∫´ÂíåÁµÑÂêàÔºåÊèê‰æõ‰∫ÜÂ∞çË§áÈõúÁ≥ªÁµ±ÁöÑÊñ∞Ë¶ãËß£ÔºåÊΩõÂú®ÊáâÁî®ÂæûÊ≥ïÂæãÊàñ AI Á≥ªÁµ±‰∏≠Ë≤¨‰ªªÁöÑÊ≠∏Â±¨ÔºåÂà∞ÁîüÁâ©Á∂≤Ë∑ØÊàñÊ∞£ÂÄôÊ®°ÂûãÁöÑÂàÜÊûê„ÄÇ

