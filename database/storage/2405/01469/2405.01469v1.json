{"2405.01469": {"publish_time": "2024-05-02", "title": "Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning", "paper_summary": "AI Foundation models are gaining traction in various applications, including\nmedical fields like radiology. However, medical foundation models are often\ntested on limited tasks, leaving their generalisability and biases unexplored.\nWe present RayDINO, a large visual encoder trained by self-supervision on 873k\nchest X-rays. We compare RayDINO to previous state-of-the-art models across\nnine radiology tasks, from classification and dense segmentation to text\ngeneration, and provide an in depth analysis of population, age and sex biases\nof our model. Our findings suggest that self-supervision allows patient-centric\nAI proving useful in clinical workflows and interpreting X-rays holistically.\nWith RayDINO and small task-specific adapters, we reach state-of-the-art\nresults and improve generalization to unseen populations while mitigating bias,\nillustrating the true promise of foundation models: versatility and robustness.", "paper_summary_zh": "", "author": "Th\u00e9o Moutakanni et.al.", "authors": "Th\u00e9o Moutakanni,Piotr Bojanowski,Guillaume Chassagnon,C\u00e9line Hudelot,Armand Joulin,Yann LeCun,Matthew Muckley,Maxime Oquab,Marie-Pierre Revel,Maria Vakalopoulou", "id": "2405.01469v1", "paper_url": "http://arxiv.org/abs/2405.01469v1", "repo": "null"}}