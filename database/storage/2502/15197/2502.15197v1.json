{"2502.15197": {"publish_time": "2025-02-21", "title": "TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding", "paper_summary": "We propose TETRIS, a novel method that optimizes the total throughput of\nbatch speculative decoding in multi-request settings. Unlike existing methods\nthat optimize for a single request or a group of requests as a whole, TETRIS\nactively selects the most promising draft tokens (for every request in a batch)\nto be accepted when verified in parallel, resulting in fewer rejected tokens\nand hence less wasted computing resources. Such an effective resource\nutilization to achieve fast inference in large language models (LLMs) is\nespecially important to service providers with limited inference capacity.\nCompared to baseline speculative decoding, TETRIS yields a consistently higher\nacceptance rate and more effective utilization of the limited inference\ncapacity. We show theoretically and empirically that TETRIS outperforms\nbaseline speculative decoding and existing methods that dynamically select\ndraft tokens, leading to a more efficient batch inference in LLMs.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa TETRIS\uff0c\u4e00\u7a2e\u65b0\u7684\u65b9\u6cd5\uff0c\u7528\u65bc\u6700\u4f73\u5316\u591a\u91cd\u8981\u6c42\u8a2d\u5b9a\u4e2d\u6279\u6b21\u63a8\u6e2c\u89e3\u78bc\u7684\u7e3d\u9ad4\u50b3\u8f38\u91cf\u3002\u8207\u73fe\u6709\u65b9\u6cd5\u4e0d\u540c\uff0c\u73fe\u6709\u65b9\u6cd5\u91dd\u5c0d\u55ae\u4e00\u8981\u6c42\u6216\u4e00\u7d44\u8981\u6c42\u4f5c\u70ba\u6574\u9ad4\u9032\u884c\u6700\u4f73\u5316\uff0cTETRIS \u4e3b\u52d5\u9078\u64c7\u6700\u6709\u5e0c\u671b\u7684\u8349\u7a3f\u4ee3\u78bc\uff08\u91dd\u5c0d\u6279\u6b21\u4e2d\u7684\u6bcf\u500b\u8981\u6c42\uff09\uff0c\u5728\u4e26\u884c\u9a57\u8b49\u6642\u4e88\u4ee5\u63a5\u53d7\uff0c\u9032\u800c\u6e1b\u5c11\u88ab\u62d2\u7d55\u7684\u4ee3\u78bc\uff0c\u56e0\u6b64\u6e1b\u5c11\u6d6a\u8cbb\u7684\u904b\u7b97\u8cc7\u6e90\u3002\u9019\u7a2e\u6709\u6548\u7684\u8cc7\u6e90\u5229\u7528\u5c0d\u65bc\u5728\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u5be6\u73fe\u5feb\u901f\u63a8\u8ad6\u81f3\u95dc\u91cd\u8981\uff0c\u5c0d\u65bc\u63a8\u8ad6\u5bb9\u91cf\u6709\u9650\u7684\u670d\u52d9\u4f9b\u61c9\u5546\u800c\u8a00\u5c24\u5176\u91cd\u8981\u3002\u8207\u57fa\u7dda\u63a8\u6e2c\u89e3\u78bc\u76f8\u6bd4\uff0cTETRIS \u7522\u751f\u6301\u7e8c\u66f4\u9ad8\u7684\u63a5\u53d7\u7387\uff0c\u4e26\u66f4\u6709\u6548\u5730\u5229\u7528\u6709\u9650\u7684\u63a8\u8ad6\u5bb9\u91cf\u3002\u6211\u5011\u5728\u7406\u8ad6\u4e0a\u548c\u7d93\u9a57\u4e0a\u8b49\u660e\uff0cTETRIS \u512a\u65bc\u57fa\u7dda\u63a8\u6e2c\u89e3\u78bc\u548c\u52d5\u614b\u9078\u64c7\u8349\u7a3f\u4ee3\u78bc\u7684\u73fe\u6709\u65b9\u6cd5\uff0c\u5f9e\u800c\u5c0e\u81f4 LLM \u4e2d\u66f4\u6709\u6548\u7684\u6279\u6b21\u63a8\u8ad6\u3002", "author": "Zhaoxuan Wu et.al.", "authors": "Zhaoxuan Wu, Zijian Zhou, Arun Verma, Alok Prakash, Daniela Rus, Bryan Kian Hsiang Low", "id": "2502.15197v1", "paper_url": "http://arxiv.org/abs/2502.15197v1", "repo": "null"}}