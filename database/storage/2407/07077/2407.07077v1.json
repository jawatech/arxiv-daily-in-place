{"2407.07077": {"publish_time": "2024-07-09", "title": "ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction", "paper_summary": "While personalized text-to-image generation has enabled the learning of a\nsingle concept from multiple images, a more practical yet challenging scenario\ninvolves learning multiple concepts within a single image. However, existing\nworks tackling this scenario heavily rely on extensive human annotations. In\nthis paper, we introduce a novel task named Unsupervised Concept Extraction\n(UCE) that considers an unsupervised setting without any human knowledge of the\nconcepts. Given an image that contains multiple concepts, the task aims to\nextract and recreate individual concepts solely relying on the existing\nknowledge from pretrained diffusion models. To achieve this, we present\nConceptExpress that tackles UCE by unleashing the inherent capabilities of\npretrained diffusion models in two aspects. Specifically, a concept\nlocalization approach automatically locates and disentangles salient concepts\nby leveraging spatial correspondence from diffusion self-attention; and based\non the lookup association between a concept and a conceptual token, a\nconcept-wise optimization process learns discriminative tokens that represent\neach individual concept. Finally, we establish an evaluation protocol tailored\nfor the UCE task. Extensive experiments demonstrate that ConceptExpress is a\npromising solution to the UCE task. Our code and data are available at:\nhttps://github.com/haoosz/ConceptExpress", "paper_summary_zh": "<paragraph>\u96d6\u7136\u500b\u4eba\u5316\u7684\u6587\u5b57\u8f49\u5716\u50cf\u751f\u6210\u5df2\u80fd\u5f9e\u591a\u5f35\u5716\u50cf\u4e2d\u5b78\u7fd2\u55ae\u4e00\u6982\u5ff5\uff0c\u4f46\u66f4\u5be6\u969b\u4e14\u5177\u6311\u6230\u6027\u7684\u5834\u666f\u662f\u5b78\u7fd2\u55ae\u4e00\u5716\u50cf\u4e2d\u7684\u591a\u500b\u6982\u5ff5\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u8655\u7406\u6b64\u5834\u666f\u7684\u4f5c\u54c1\u6975\u5ea6\u4f9d\u8cf4\u65bc\u5927\u91cf\u7684\u6a19\u8a3b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u540d\u70ba\u7121\u76e3\u7763\u6982\u5ff5\u8403\u53d6 (UCE) \u7684\u65b0\u4efb\u52d9\uff0c\u5b83\u8003\u616e\u4e86\u5728\u6c92\u6709\u4eba\u985e\u6982\u5ff5\u77e5\u8b58\u7684\u60c5\u6cc1\u4e0b\u7684\u7121\u76e3\u7763\u8a2d\u5b9a\u3002\u7d66\u5b9a\u5305\u542b\u591a\u500b\u6982\u5ff5\u7684\u5716\u50cf\uff0c\u6b64\u4efb\u52d9\u65e8\u5728\u50c5\u4f9d\u8cf4\u65bc\u9810\u8a13\u7df4\u64f4\u6563\u6a21\u578b\u7684\u73fe\u6709\u77e5\u8b58\u4f86\u8403\u53d6\u548c\u91cd\u5efa\u500b\u5225\u6982\u5ff5\u3002\u70ba\u9054\u6210\u6b64\u76ee\u7684\uff0c\u6211\u5011\u63d0\u51fa\u4e86 ConceptExpress\uff0c\u5b83\u900f\u904e\u91cb\u653e\u9810\u8a13\u7df4\u64f4\u6563\u6a21\u578b\u5728\u5169\u500b\u65b9\u9762\u7684\u56fa\u6709\u80fd\u529b\u4f86\u8655\u7406 UCE\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\u900f\u904e\u5229\u7528\u64f4\u6563\u81ea\u6ce8\u610f\u529b\u4e2d\u7684\u7a7a\u9593\u5c0d\u61c9\u81ea\u52d5\u5b9a\u4f4d\u548c\u89e3\u958b\u986f\u8457\u6982\u5ff5\uff1b\u800c\u57fa\u65bc\u6982\u5ff5\u548c\u6982\u5ff5 token \u4e4b\u9593\u7684\u67e5\u8a62\u95dc\u806f\uff0c\u6982\u5ff5\u512a\u5316\u7a0b\u5e8f\u6703\u5b78\u7fd2\u8868\u793a\u6bcf\u500b\u500b\u5225\u6982\u5ff5\u7684\u5340\u5206 token\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b\u5c08\u9580\u91dd\u5c0d UCE \u4efb\u52d9\u7684\u8a55\u4f30\u5354\u5b9a\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e ConceptExpress \u662f UCE \u4efb\u52d9\u7684\u6709\u524d\u9014\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u53ef\u5728\u4ee5\u4e0b\u53d6\u5f97\uff1ahttps://github.com/haoosz/ConceptExpress</paragraph>", "author": "Shaozhe Hao et.al.", "authors": "Shaozhe Hao, Kai Han, Zhengyao Lv, Shihao Zhao, Kwan-Yee K. Wong", "id": "2407.07077v1", "paper_url": "http://arxiv.org/abs/2407.07077v1", "repo": "https://github.com/haoosz/conceptexpress"}}