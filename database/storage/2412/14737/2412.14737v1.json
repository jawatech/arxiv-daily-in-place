{"2412.14737": {"publish_time": "2024-12-19", "title": "On Verbalized Confidence Scores for LLMs", "paper_summary": "The rise of large language models (LLMs) and their tight integration into our\ndaily life make it essential to dedicate efforts towards their trustworthiness.\nUncertainty quantification for LLMs can establish more human trust into their\nresponses, but also allows LLM agents to make more informed decisions based on\neach other's uncertainty. To estimate the uncertainty in a response, internal\ntoken logits, task-specific proxy models, or sampling of multiple responses are\ncommonly used. This work focuses on asking the LLM itself to verbalize its\nuncertainty with a confidence score as part of its output tokens, which is a\npromising way for prompt- and model-agnostic uncertainty quantification with\nlow overhead. Using an extensive benchmark, we assess the reliability of\nverbalized confidence scores with respect to different datasets, models, and\nprompt methods. Our results reveal that the reliability of these scores\nstrongly depends on how the model is asked, but also that it is possible to\nextract well-calibrated confidence scores with certain prompt methods. We argue\nthat verbalized confidence scores can become a simple but effective and\nversatile uncertainty quantification method in the future. Our code is\navailable at https://github.com/danielyxyang/llm-verbalized-uq .", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u8208\u8d77\u53ca\u5176\u8207\u6211\u5011\u65e5\u5e38\u751f\u6d3b\u7dca\u5bc6\u7684\u6574\u5408\uff0c\u81f4\u529b\u65bc\u63d0\u5347\u5176\u53ef\u4fe1\u5ea6\u81f3\u95dc\u91cd\u8981\u3002LLM \u7684\u4e0d\u78ba\u5b9a\u6027\u91cf\u5316\u53ef\u4ee5\u5efa\u7acb\u4eba\u985e\u5c0d\u5176\u56de\u61c9\u7684\u66f4\u591a\u4fe1\u4efb\uff0c\u4f46\u4e5f\u5141\u8a31 LLM \u4ee3\u7406\u6839\u64da\u5f7c\u6b64\u7684\u4e0d\u78ba\u5b9a\u6027\u505a\u51fa\u66f4\u660e\u667a\u7684\u6c7a\u7b56\u3002\u70ba\u4e86\u4f30\u8a08\u56de\u61c9\u4e2d\u7684\u4e0d\u78ba\u5b9a\u6027\uff0c\u901a\u5e38\u6703\u4f7f\u7528\u5167\u90e8\u6b0a\u91cd\u3001\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u4ee3\u7406\u6a21\u578b\u6216\u591a\u91cd\u56de\u61c9\u53d6\u6a23\u3002\u9019\u9805\u5de5\u4f5c\u91cd\u9ede\u5728\u65bc\u8981\u6c42 LLM \u672c\u8eab\u4ee5\u4fe1\u5fc3\u5206\u6578\u7684\u5f62\u5f0f\u5c0d\u5176\u4e0d\u78ba\u5b9a\u6027\u9032\u884c\u8a00\u8a9e\u5316\uff0c\u4f5c\u70ba\u5176\u8f38\u51fa\u6b0a\u91cd\u7684\u4e00\u90e8\u5206\uff0c\u9019\u662f\u4e00\u7a2e\u5f88\u6709\u524d\u666f\u7684\u63d0\u793a\u548c\u6a21\u578b\u4e0d\u53ef\u77e5\u7684\u4e0d\u78ba\u5b9a\u6027\u91cf\u5316\u65b9\u5f0f\uff0c\u4e14\u958b\u92b7\u4f4e\u3002\u4f7f\u7528\u5ee3\u6cdb\u7684\u57fa\u6e96\uff0c\u6211\u5011\u8a55\u4f30\u4e86\u8a00\u8a9e\u5316\u4fe1\u5fc3\u5206\u6578\u76f8\u5c0d\u65bc\u4e0d\u540c\u8cc7\u6599\u96c6\u3001\u6a21\u578b\u548c\u63d0\u793a\u65b9\u6cd5\u7684\u53ef\u4fe1\u5ea6\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u9019\u4e9b\u5206\u6578\u7684\u53ef\u4fe1\u5ea6\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u6c7a\u65bc\u5982\u4f55\u8a62\u554f\u6a21\u578b\uff0c\u4f46\u4e5f\u986f\u793a\u51fa\u4f7f\u7528\u7279\u5b9a\u63d0\u793a\u65b9\u6cd5\u63d0\u53d6\u6821\u6e96\u826f\u597d\u7684\u4fe1\u5fc3\u5206\u6578\u662f\u53ef\u884c\u7684\u3002\u6211\u5011\u8a8d\u70ba\uff0c\u8a00\u8a9e\u5316\u4fe1\u5fc3\u5206\u6578\u672a\u4f86\u53ef\u4ee5\u6210\u70ba\u4e00\u7a2e\u7c21\u55ae\u4f46\u6709\u6548\u4e14\u901a\u7528\u7684\u4e0d\u78ba\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/danielyxyang/llm-verbalized-uq \u53d6\u5f97\u3002", "author": "Daniel Yang et.al.", "authors": "Daniel Yang, Yao-Hung Hubert Tsai, Makoto Yamada", "id": "2412.14737v1", "paper_url": "http://arxiv.org/abs/2412.14737v1", "repo": "null"}}