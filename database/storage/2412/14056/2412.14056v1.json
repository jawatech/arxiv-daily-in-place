{"2412.14056": {"publish_time": "2024-12-18", "title": "A Review of Multimodal Explainable Artificial Intelligence: Past, Present and Future", "paper_summary": "Artificial intelligence (AI) has rapidly developed through advancements in\ncomputational power and the growth of massive datasets. However, this progress\nhas also heightened challenges in interpreting the \"black-box\" nature of AI\nmodels. To address these concerns, eXplainable AI (XAI) has emerged with a\nfocus on transparency and interpretability to enhance human understanding and\ntrust in AI decision-making processes. In the context of multimodal data fusion\nand complex reasoning scenarios, the proposal of Multimodal eXplainable AI\n(MXAI) integrates multiple modalities for prediction and explanation tasks.\nMeanwhile, the advent of Large Language Models (LLMs) has led to remarkable\nbreakthroughs in natural language processing, yet their complexity has further\nexacerbated the issue of MXAI. To gain key insights into the development of\nMXAI methods and provide crucial guidance for building more transparent, fair,\nand trustworthy AI systems, we review the MXAI methods from a historical\nperspective and categorize them across four eras: traditional machine learning,\ndeep learning, discriminative foundation models, and generative LLMs. We also\nreview evaluation metrics and datasets used in MXAI research, concluding with a\ndiscussion of future challenges and directions. A project related to this\nreview has been created at https://github.com/ShilinSun/mxai_review.", "paper_summary_zh": "\u4eba\u5de5\u667a\u6167 (AI) \u900f\u904e\u8a08\u7b97\u80fd\u529b\u7684\u9032\u6b65\u4ee5\u53ca\u5927\u91cf\u8cc7\u6599\u96c6\u7684\u6210\u9577\u800c\u5feb\u901f\u767c\u5c55\u3002\u7136\u800c\uff0c\u6b64\u9032\u5c55\u4e5f\u52a0\u5287\u4e86\u8a6e\u91cb AI \u6a21\u578b\u300c\u9ed1\u76d2\u5b50\u300d\u7279\u6027\u7684\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u53ef\u89e3\u91cb AI (XAI) \u5df2\u61c9\u904b\u800c\u751f\uff0c\u5c08\u6ce8\u65bc\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91cb\u6027\uff0c\u4ee5\u589e\u5f37\u4eba\u985e\u5c0d AI \u6c7a\u7b56\u6d41\u7a0b\u7684\u7406\u89e3\u548c\u4fe1\u4efb\u3002\u5728\u591a\u6a21\u614b\u8cc7\u6599\u878d\u5408\u548c\u8907\u96dc\u63a8\u7406\u60c5\u5883\u4e2d\uff0c\u591a\u6a21\u614b\u53ef\u89e3\u91cb AI (MXAI) \u7684\u63d0\u6848\u6574\u5408\u4e86\u591a\u7a2e\u6a21\u614b\uff0c\u4ee5\u9032\u884c\u9810\u6e2c\u548c\u89e3\u91cb\u4efb\u52d9\u3002\u540c\u6642\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u51fa\u73fe\u5df2\u5c0e\u81f4\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u7684\u986f\u8457\u7a81\u7834\uff0c\u4f46\u5176\u8907\u96dc\u6027\u9032\u4e00\u6b65\u52a0\u5287\u4e86 MXAI \u7684\u554f\u984c\u3002\u70ba\u4e86\u6df1\u5165\u4e86\u89e3 MXAI \u65b9\u6cd5\u7684\u767c\u5c55\uff0c\u4e26\u70ba\u5efa\u7acb\u66f4\u900f\u660e\u3001\u516c\u5e73\u4e14\u503c\u5f97\u4fe1\u8cf4\u7684 AI \u7cfb\u7d71\u63d0\u4f9b\u95dc\u9375\u6307\u5c0e\uff0c\u6211\u5011\u5f9e\u6b77\u53f2\u89d2\u5ea6\u56de\u9867 MXAI \u65b9\u6cd5\uff0c\u4e26\u5c07\u5176\u5206\u70ba\u56db\u500b\u6642\u4ee3\uff1a\u50b3\u7d71\u6a5f\u5668\u5b78\u7fd2\u3001\u6df1\u5ea6\u5b78\u7fd2\u3001\u5224\u5225\u57fa\u790e\u6a21\u578b\u548c\u751f\u6210\u5f0f LLM\u3002\u6211\u5011\u4e5f\u56de\u9867\u4e86 MXAI \u7814\u7a76\u4e2d\u4f7f\u7528\u7684\u8a55\u4f30\u6307\u6a19\u548c\u8cc7\u6599\u96c6\uff0c\u4e26\u5728\u6700\u5f8c\u8a0e\u8ad6\u672a\u4f86\u7684\u6311\u6230\u548c\u65b9\u5411\u3002\u8207\u6b64\u56de\u9867\u76f8\u95dc\u7684\u5c08\u6848\u5df2\u5efa\u7acb\u65bc https://github.com/ShilinSun/mxai_review\u3002", "author": "Shilin Sun et.al.", "authors": "Shilin Sun, Wenbin An, Feng Tian, Fang Nan, Qidong Liu, Jun Liu, Nazaraf Shah, Ping Chen", "id": "2412.14056v1", "paper_url": "http://arxiv.org/abs/2412.14056v1", "repo": "https://github.com/shilinsun/mxai_review"}}