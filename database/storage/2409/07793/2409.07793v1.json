{"2409.07793": {"publish_time": "2024-09-12", "title": "Lagrange Duality and Compound Multi-Attention Transformer for Semi-Supervised Medical Image Segmentation", "paper_summary": "Medical image segmentation, a critical application of semantic segmentation\nin healthcare, has seen significant advancements through specialized computer\nvision techniques. While deep learning-based medical image segmentation is\nessential for assisting in medical diagnosis, the lack of diverse training data\ncauses the long-tail problem. Moreover, most previous hybrid CNN-ViT\narchitectures have limited ability to combine various attentions in different\nlayers of the Convolutional Neural Network. To address these issues, we propose\na Lagrange Duality Consistency (LDC) Loss, integrated with Boundary-Aware\nContrastive Loss, as the overall training objective for semi-supervised\nlearning to mitigate the long-tail problem. Additionally, we introduce\nCMAformer, a novel network that synergizes the strengths of ResUNet and\nTransformer. The cross-attention block in CMAformer effectively integrates\nspatial attention and channel attention for multi-scale feature fusion.\nOverall, our results indicate that CMAformer, combined with the feature fusion\nframework and the new consistency loss, demonstrates strong complementarity in\nsemi-supervised learning ensembles. We achieve state-of-the-art results on\nmultiple public medical image datasets. Example code are available at:\n\\url{https://github.com/lzeeorno/Lagrange-Duality-and-CMAformer}.", "paper_summary_zh": "\u91ab\u5b78\u5f71\u50cf\u5206\u5272\u662f\u8a9e\u610f\u5206\u5272\u5728\u91ab\u7642\u4fdd\u5065\u9818\u57df\u4e2d\u7684\u4e00\u9805\u91cd\u8981\u61c9\u7528\uff0c\u5df2\u900f\u904e\u5c08\u696d\u7684\u96fb\u8166\u8996\u89ba\u6280\u8853\u7372\u5f97\u986f\u8457\u9032\u5c55\u3002\u96d6\u7136\u57fa\u65bc\u6df1\u5ea6\u5b78\u7fd2\u7684\u91ab\u5b78\u5f71\u50cf\u5206\u5272\u5c0d\u65bc\u5354\u52a9\u91ab\u7642\u8a3a\u65b7\u81f3\u95dc\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u591a\u6a23\u5316\u7684\u8a13\u7df4\u8cc7\u6599\u6703\u5c0e\u81f4\u9577\u5c3e\u554f\u984c\u3002\u6b64\u5916\uff0c\u5927\u591a\u6578\u5148\u524d\u7684\u6df7\u5408\u5f0f CNN-ViT \u67b6\u69cb\u5728\u7d50\u5408\u5377\u7a4d\u795e\u7d93\u7db2\u8def\u4e0d\u540c\u5c64\u4e2d\u7684\u5404\u7a2e\u6ce8\u610f\u529b\u65b9\u9762\u80fd\u529b\u6709\u9650\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u62c9\u683c\u6717\u65e5\u5c0d\u5076\u4e00\u81f4\u6027 (LDC) \u640d\u5931\uff0c\u4e26\u8207\u908a\u754c\u611f\u77e5\u5c0d\u6bd4\u640d\u5931\u6574\u5408\uff0c\u4f5c\u70ba\u534a\u76e3\u7763\u5f0f\u5b78\u7fd2\u7684\u6574\u9ad4\u8a13\u7df4\u76ee\u6a19\uff0c\u4ee5\u6e1b\u8f15\u9577\u5c3e\u554f\u984c\u3002\u6b64\u5916\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 CMAformer\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u7db2\u8def\uff0c\u5b83\u5354\u540c\u4e86 ResUNet \u548c Transformer \u7684\u512a\u9ede\u3002CMAformer \u4e2d\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u5340\u584a\u6709\u6548\u5730\u6574\u5408\u4e86\u7a7a\u9593\u6ce8\u610f\u529b\u548c\u901a\u9053\u6ce8\u610f\u529b\uff0c\u4ee5\u9032\u884c\u591a\u5c3a\u5ea6\u7279\u5fb5\u878d\u5408\u3002\u7e3d\u7684\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cCMAformer \u7d50\u5408\u7279\u5fb5\u878d\u5408\u67b6\u69cb\u548c\u65b0\u7684\u7a20\u5bc6\u640d\u5931\uff0c\u5728\u534a\u76e3\u7763\u5f0f\u5b78\u7fd2\u96c6\u5408\u4e2d\u5c55\u73fe\u51fa\u5f37\u5927\u7684\u4e92\u88dc\u6027\u3002\u6211\u5011\u5728\u591a\u500b\u516c\u958b\u91ab\u5b78\u5f71\u50cf\u8cc7\u6599\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u6210\u679c\u3002\u7bc4\u4f8b\u7a0b\u5f0f\u78bc\u53ef\u5728\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1a\\url{https://github.com/lzeeorno/Lagrange-Duality-and-CMAformer}\u3002", "author": "Fuchen Zheng et.al.", "authors": "Fuchen Zheng, Quanjun Li, Weixuan Li, Xuhang Chen, Yihang Dong, Guoheng Huang, Chi-Man Pun, Shoujun Zhou", "id": "2409.07793v1", "paper_url": "http://arxiv.org/abs/2409.07793v1", "repo": "https://github.com/lzeeorno/lagrange-duality-and-cmaformer"}}