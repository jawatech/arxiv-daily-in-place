{"2411.11937": {"publish_time": "2024-11-18", "title": "Value Imprint: A Technique for Auditing the Human Values Embedded in RLHF Datasets", "paper_summary": "LLMs are increasingly fine-tuned using RLHF datasets to align them with human\npreferences and values. However, very limited research has investigated which\nspecific human values are operationalized through these datasets. In this\npaper, we introduce Value Imprint, a framework for auditing and classifying the\nhuman values embedded within RLHF datasets. To investigate the viability of\nthis framework, we conducted three case study experiments by auditing the\nAnthropic/hh-rlhf, OpenAI WebGPT Comparisons, and Alpaca GPT-4-LLM datasets to\nexamine the human values embedded within them. Our analysis involved a\ntwo-phase process. During the first phase, we developed a taxonomy of human\nvalues through an integrated review of prior works from philosophy, axiology,\nand ethics. Then, we applied this taxonomy to annotate 6,501 RLHF preferences.\nDuring the second phase, we employed the labels generated from the annotation\nas ground truth data for training a transformer-based machine learning model to\naudit and classify the three RLHF datasets. Through this approach, we\ndiscovered that information-utility values, including Wisdom/Knowledge and\nInformation Seeking, were the most dominant human values within all three RLHF\ndatasets. In contrast, prosocial and democratic values, including Well-being,\nJustice, and Human/Animal Rights, were the least represented human values.\nThese findings have significant implications for developing language models\nthat align with societal values and norms. We contribute our datasets to\nsupport further research in this area.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u65e5\u76ca\u4f7f\u7528 RLHF \u8cc7\u6599\u96c6\u9032\u884c\u5fae\u8abf\uff0c\u4ee5\u4f7f\u5176\u8207\u4eba\u985e\u504f\u597d\u548c\u50f9\u503c\u89c0\u4fdd\u6301\u4e00\u81f4\u3002\u7136\u800c\uff0c\u5f88\u5c11\u6709\u7814\u7a76\u8abf\u67e5\u901a\u904e\u9019\u4e9b\u8cc7\u6599\u96c6\u904b\u4f5c\u4e86\u54ea\u4e9b\u5177\u9ad4\u7684\u4eba\u985e\u50f9\u503c\u89c0\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u50f9\u503c\u5370\u8a18\uff0c\u4e00\u500b\u7528\u65bc\u5be9\u67e5\u548c\u5206\u985e\u5d4c\u5165\u5728 RLHF \u8cc7\u6599\u96c6\u4e2d\u7684\u4eba\u985e\u50f9\u503c\u89c0\u7684\u6846\u67b6\u3002\u70ba\u4e86\u8abf\u67e5\u9019\u500b\u6846\u67b6\u7684\u53ef\u884c\u6027\uff0c\u6211\u5011\u901a\u904e\u5be9\u67e5 Anthropic/hh-rlhf\u3001OpenAI WebGPT \u6bd4\u8f03\u548c Alpaca GPT-4-LLM \u8cc7\u6599\u96c6\u4f86\u9032\u884c\u4e86\u4e09\u500b\u6848\u4f8b\u7814\u7a76\u5be6\u9a57\uff0c\u4ee5\u6aa2\u67e5\u5176\u4e2d\u5d4c\u5165\u7684\u4eba\u985e\u50f9\u503c\u89c0\u3002\u6211\u5011\u7684\u5206\u6790\u6d89\u53ca\u4e00\u500b\u5169\u968e\u6bb5\u7684\u904e\u7a0b\u3002\u5728\u7b2c\u4e00\u968e\u6bb5\uff0c\u6211\u5011\u901a\u904e\u5c0d\u54f2\u5b78\u3001\u50f9\u503c\u8ad6\u548c\u502b\u7406\u5b78\u4e4b\u524d\u5de5\u4f5c\u7684\u7d9c\u5408\u56de\u9867\uff0c\u958b\u767c\u4e86\u4e00\u500b\u4eba\u985e\u50f9\u503c\u89c0\u5206\u985e\u6cd5\u3002\u7136\u5f8c\uff0c\u6211\u5011\u61c9\u7528\u9019\u500b\u5206\u985e\u6cd5\u4f86\u8a3b\u91cb 6,501 \u500b RLHF \u504f\u597d\u3002\u5728\u7b2c\u4e8c\u968e\u6bb5\uff0c\u6211\u5011\u63a1\u7528\u5f9e\u8a3b\u91cb\u4e2d\u7522\u751f\u7684\u6a19\u7c64\u4f5c\u70ba\u8a13\u7df4\u4e00\u500b\u57fa\u65bc\u8f49\u63db\u5668\u7684\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u7684\u771f\u5be6\u6578\u64da\uff0c\u4ee5\u5be9\u67e5\u548c\u5206\u985e\u4e09\u500b RLHF \u8cc7\u6599\u96c6\u3002\u901a\u904e\u9019\u7a2e\u65b9\u6cd5\uff0c\u6211\u5011\u767c\u73fe\u8cc7\u8a0a\u6548\u7528\u50f9\u503c\uff0c\u5305\u62ec\u667a\u6167/\u77e5\u8b58\u548c\u8cc7\u8a0a\u5c0b\u6c42\uff0c\u662f\u6240\u6709\u4e09\u500b RLHF \u8cc7\u6599\u96c6\u4e2d\u6700\u4e3b\u8981\u7684\u4eba\u985e\u50f9\u503c\u89c0\u3002\u76f8\u53cd\uff0c\u89aa\u793e\u6703\u548c\u6c11\u4e3b\u50f9\u503c\u89c0\uff0c\u5305\u62ec\u798f\u7949\u3001\u6b63\u7fa9\u548c\u4eba\u985e/\u52d5\u7269\u6b0a\u5229\uff0c\u662f\u4ee3\u8868\u6027\u6700\u5c11\u7684\u4eba\u985e\u50f9\u503c\u89c0\u3002\u9019\u4e9b\u767c\u73fe\u5c0d\u958b\u767c\u8207\u793e\u6703\u50f9\u503c\u89c0\u548c\u898f\u7bc4\u4fdd\u6301\u4e00\u81f4\u7684\u8a9e\u8a00\u6a21\u578b\u5177\u6709\u91cd\u5927\u610f\u7fa9\u3002\u6211\u5011\u8ca2\u737b\u6211\u5011\u7684\u8cc7\u6599\u96c6\u4ee5\u652f\u6301\u9019\u65b9\u9762\u7684\u9032\u4e00\u6b65\u7814\u7a76\u3002", "author": "Ike Obi et.al.", "authors": "Ike Obi, Rohan Pant, Srishti Shekhar Agrawal, Maham Ghazanfar, Aaron Basiletti", "id": "2411.11937v1", "paper_url": "http://arxiv.org/abs/2411.11937v1", "repo": "null"}}