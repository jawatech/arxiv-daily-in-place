{"2405.04311": {"publish_time": "2024-05-07", "title": "Cross-IQA: Unsupervised Learning for Image Quality Assessment", "paper_summary": "Automatic perception of image quality is a challenging problem that impacts\nbillions of Internet and social media users daily. To advance research in this\nfield, we propose a no-reference image quality assessment (NR-IQA) method\ntermed Cross-IQA based on vision transformer(ViT) model. The proposed Cross-IQA\nmethod can learn image quality features from unlabeled image data. We construct\nthe pretext task of synthesized image reconstruction to unsupervised extract\nthe image quality information based ViT block. The pretrained encoder of\nCross-IQA is used to fine-tune a linear regression model for score prediction.\nExperimental results show that Cross-IQA can achieve state-of-the-art\nperformance in assessing the low-frequency degradation information (e.g., color\nchange, blurring, etc.) of images compared with the classical full-reference\nIQA and NR-IQA under the same datasets.", "paper_summary_zh": "\u5f71\u50cf\u54c1\u8cea\u7684\u81ea\u52d5\u611f\u77e5\u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u554f\u984c\uff0c\u5b83\u6bcf\u5929\u90fd\u6703\u5f71\u97ff\u6578\u5341\u5104\u7684\u7db2\u969b\u7db2\u8def\u548c\u793e\u7fa4\u5a92\u9ad4\u4f7f\u7528\u8005\u3002\u70ba\u4e86\u63a8\u9032\u6b64\u9818\u57df\u7684\u7814\u7a76\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u8996\u89ba\u8f49\u63db\u5668 (ViT) \u6a21\u578b\u7684\u7121\u53c3\u8003\u5f71\u50cf\u54c1\u8cea\u8a55\u4f30 (NR-IQA) \u65b9\u6cd5\uff0c\u7a31\u70ba Cross-IQA\u3002\u6240\u63d0\u51fa\u7684 Cross-IQA \u65b9\u6cd5\u53ef\u4ee5\u5f9e\u672a\u6a19\u7c64\u7684\u5f71\u50cf\u8cc7\u6599\u4e2d\u5b78\u7fd2\u5f71\u50cf\u54c1\u8cea\u7279\u5fb5\u3002\u6211\u5011\u5efa\u69cb\u4e86\u5408\u6210\u5f71\u50cf\u91cd\u5efa\u7684\u9810\u8a2d\u4efb\u52d9\uff0c\u4ee5\u975e\u76e3\u7763\u7684\u65b9\u5f0f\u6839\u64da ViT \u5340\u584a\u8403\u53d6\u5f71\u50cf\u54c1\u8cea\u8cc7\u8a0a\u3002Cross-IQA \u7684\u9810\u8a13\u7df4\u7de8\u78bc\u5668\u7528\u65bc\u5fae\u8abf\u7dda\u6027\u56de\u6b78\u6a21\u578b\u4ee5\u9032\u884c\u5206\u6578\u9810\u6e2c\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u8207\u5728\u76f8\u540c\u8cc7\u6599\u96c6\u4e0b\u7684\u50b3\u7d71\u5168\u53c3\u8003 IQA \u548c NR-IQA \u76f8\u6bd4\uff0cCross-IQA \u53ef\u4ee5\u9054\u6210\u8a55\u4f30\u5f71\u50cf\u4f4e\u983b\u52a3\u5316\u8cc7\u8a0a\uff08\u4f8b\u5982\uff0c\u8272\u5f69\u8b8a\u5316\u3001\u6a21\u7cca\u7b49\uff09\u7684\u6700\u65b0\u6280\u8853\u6548\u80fd\u3002", "author": "Zhen Zhang et.al.", "authors": "Zhen Zhang", "id": "2405.04311v1", "paper_url": "http://arxiv.org/abs/2405.04311v1", "repo": "null"}}