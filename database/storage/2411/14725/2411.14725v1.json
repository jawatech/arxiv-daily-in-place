{"2411.14725": {"publish_time": "2024-11-22", "title": "Evaluating and Advancing Multimodal Large Language Models in Ability Lens", "paper_summary": "As multimodal large language models (MLLMs) advance rapidly, rigorous\nevaluation has become essential, providing further guidance for their\ndevelopment. In this work, we focus on a unified and robust evaluation of\n\\textbf{vision perception} abilities, the foundational skill of MLLMs. We find\nthat existing perception benchmarks, each focusing on different question types,\ndomains, and evaluation metrics, introduce significant evaluation variance,\ncomplicating comprehensive assessments of perception abilities when relying on\nany single benchmark. To address this, we introduce \\textbf{AbilityLens}, a\nunified benchmark designed to evaluate MLLMs across six key perception\nabilities, focusing on both accuracy and stability, with each ability\nencompassing diverse question types, domains, and metrics. With the assistance\nof AbilityLens, we: (1) identify the strengths and weaknesses of current\nmodels, highlighting stability patterns and revealing a notable performance gap\nbetween open-source and closed-source models; (2) introduce an online\nevaluation mode, which uncovers interesting ability conflict and early\nconvergence phenomena during MLLM training; and (3) design a simple\nability-specific model merging method that combines the best ability checkpoint\nfrom early training stages, effectively mitigating performance decline due to\nability conflict. The benchmark and online leaderboard will be released soon.", "paper_summary_zh": "<paragraph>\u96a8\u8457\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u5feb\u901f\u9032\u6b65\uff0c\u56b4\u8b39\u7684\u8a55\u4f30\u5df2\u8b8a\u5f97\u81f3\u95dc\u91cd\u8981\uff0c\u70ba\u5176\u958b\u767c\u63d0\u4f9b\u9032\u4e00\u6b65\u7684\u6307\u5c0e\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u7d71\u4e00\u4e14\u7a69\u5065\u7684\u8a55\u4f30\uff0c\u5373 MLLM \u7684\u57fa\u790e\u6280\u80fd\u300c\u8996\u89ba\u611f\u77e5\u300d\u80fd\u529b\u3002\u6211\u5011\u767c\u73fe\u73fe\u6709\u7684\u611f\u77e5\u57fa\u6e96\uff0c\u6bcf\u500b\u90fd\u5c08\u6ce8\u65bc\u4e0d\u540c\u7684\u554f\u984c\u985e\u578b\u3001\u9818\u57df\u548c\u8a55\u4f30\u6307\u6a19\uff0c\u5f15\u5165\u4e86\u986f\u8457\u7684\u8a55\u4f30\u5dee\u7570\uff0c\u5728\u4f9d\u8cf4\u4efb\u4f55\u55ae\u4e00\u57fa\u6e96\u6642\uff0c\u6703\u4f7f\u611f\u77e5\u80fd\u529b\u7684\u5168\u9762\u8a55\u4f30\u8907\u96dc\u5316\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 AbilityLens\uff0c\u4e00\u500b\u7d71\u4e00\u7684\u57fa\u6e96\uff0c\u65e8\u5728\u8a55\u4f30 MLLM \u7684\u516d\u9805\u95dc\u9375\u611f\u77e5\u80fd\u529b\uff0c\u91cd\u9ede\u95dc\u6ce8\u6e96\u78ba\u6027\u548c\u7a69\u5b9a\u6027\uff0c\u6bcf\u9805\u80fd\u529b\u90fd\u5305\u542b\u4e0d\u540c\u7684\u554f\u984c\u985e\u578b\u3001\u9818\u57df\u548c\u6307\u6a19\u3002\u5728 AbilityLens \u7684\u5354\u52a9\u4e0b\uff0c\u6211\u5011\uff1a(1) \u627e\u51fa\u7576\u524d\u6a21\u578b\u7684\u512a\u7f3a\u9ede\uff0c\u5f37\u8abf\u7a69\u5b9a\u6027\u6a21\u5f0f\u4e26\u63ed\u793a\u958b\u6e90\u6a21\u578b\u548c\u9589\u6e90\u6a21\u578b\u4e4b\u9593\u986f\u8457\u7684\u6548\u80fd\u5dee\u8ddd\uff1b(2) \u4ecb\u7d39\u4e00\u7a2e\u7dda\u4e0a\u8a55\u4f30\u6a21\u5f0f\uff0c\u5b83\u63ed\u793a\u4e86 MLLM \u8a13\u7df4\u671f\u9593\u6709\u8da3\u7684\u80fd\u529b\u885d\u7a81\u548c\u65e9\u671f\u6536\u6582\u73fe\u8c61\uff1b(3) \u8a2d\u8a08\u4e86\u4e00\u500b\u7c21\u55ae\u7684\u80fd\u529b\u7279\u5b9a\u6a21\u578b\u5408\u4f75\u65b9\u6cd5\uff0c\u5b83\u7d50\u5408\u4e86\u65e9\u671f\u8a13\u7df4\u968e\u6bb5\u4e2d\u6700\u4f73\u7684\u80fd\u529b\u6aa2\u67e5\u9ede\uff0c\u6709\u6548\u6e1b\u8f15\u4e86\u56e0\u80fd\u529b\u885d\u7a81\u5c0e\u81f4\u7684\u6548\u80fd\u4e0b\u964d\u3002\u57fa\u6e96\u548c\u7dda\u4e0a\u6392\u884c\u699c\u5c07\u5f88\u5feb\u767c\u5e03\u3002</paragraph>", "author": "Feng Chen et.al.", "authors": "Feng Chen, Chenhui Gou, Jing Liu, Yang Yang, Zhaoyang Li, Jiyuan Zhang, Zhenbang Sun, Bohan Zhuang, Qi Wu", "id": "2411.14725v1", "paper_url": "http://arxiv.org/abs/2411.14725v1", "repo": "null"}}