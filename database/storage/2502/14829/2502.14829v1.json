{"2502.14829": {"publish_time": "2025-02-20", "title": "Measuring Faithfulness of Chains of Thought by Unlearning Reasoning Steps", "paper_summary": "When prompted to think step-by-step, language models (LMs) produce a chain of\nthought (CoT), a sequence of reasoning steps that the model supposedly used to\nproduce its prediction. However, despite much work on CoT prompting, it is\nunclear if CoT reasoning is faithful to the models' parameteric beliefs. We\nintroduce a framework for measuring parametric faithfulness of generated\nreasoning, and propose Faithfulness by Unlearning Reasoning steps (FUR), an\ninstance of this framework. FUR erases information contained in reasoning steps\nfrom model parameters. We perform experiments unlearning CoTs of four LMs\nprompted on four multi-choice question answering (MCQA) datasets. Our\nexperiments show that FUR is frequently able to change the underlying models'\nprediction by unlearning key steps, indicating when a CoT is parametrically\nfaithful. Further analysis shows that CoTs generated by models post-unlearning\nsupport different answers, hinting at a deeper effect of unlearning.\nImportantly, CoT steps identified as important by FUR do not align well with\nhuman notions of plausbility, emphasizing the need for specialized alignment", "paper_summary_zh": "\u5f53\u63d0\u793a\u9010\u6b65\u601d\u8003\u65f6\uff0c\u8bed\u8a00\u6a21\u578b (LM) \u4f1a\u4ea7\u751f\u4e00\u7cfb\u5217\u601d\u8003 (CoT)\uff0c\u8fd9\u662f\u6a21\u578b\u7528\u6765\u4ea7\u751f\u9884\u6d4b\u7684\u4e00\u7cfb\u5217\u63a8\u7406\u6b65\u9aa4\u3002\u7136\u800c\uff0c\u5c3d\u7ba1\u5728 CoT \u63d0\u793a\u4e0a\u505a\u4e86\u5f88\u591a\u5de5\u4f5c\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a CoT \u63a8\u7406\u662f\u5426\u7b26\u5408\u6a21\u578b\u7684\u53c2\u6570\u5316\u4fe1\u5ff5\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u6846\u67b6\u6765\u8861\u91cf\u751f\u6210\u63a8\u7406\u7684\u53c2\u6570\u5316\u4fdd\u771f\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u53d6\u6d88\u5b66\u4e60\u63a8\u7406\u6b65\u9aa4 (FUR) \u7684\u4fdd\u771f\u5ea6\uff0c\u8fd9\u662f\u8be5\u6846\u67b6\u7684\u4e00\u4e2a\u5b9e\u4f8b\u3002FUR \u4ece\u6a21\u578b\u53c2\u6570\u4e2d\u64e6\u9664\u63a8\u7406\u6b65\u9aa4\u4e2d\u5305\u542b\u7684\u4fe1\u606f\u3002\u6211\u4eec\u6267\u884c\u5b9e\u9a8c\uff0c\u53d6\u6d88\u5b66\u4e60\u63d0\u793a\u5728\u56db\u4e2a\u591a\u9879\u9009\u62e9\u95ee\u7b54 (MCQA) \u6570\u636e\u96c6\u4e0a\u7684\u56db\u4e2a LM \u7684 CoT\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFUR \u7ecf\u5e38\u80fd\u591f\u901a\u8fc7\u53d6\u6d88\u5b66\u4e60\u5173\u952e\u6b65\u9aa4\u6765\u6539\u53d8\u5e95\u5c42\u6a21\u578b\u7684\u9884\u6d4b\uff0c\u8868\u660e CoT \u5728\u53c2\u6570\u4e0a\u662f\u4fdd\u771f\u7684\u3002\u8fdb\u4e00\u6b65\u7684\u5206\u6790\u8868\u660e\uff0c\u6a21\u578b\u5728\u53d6\u6d88\u5b66\u4e60\u540e\u751f\u6210\u7684 CoT \u652f\u6301\u4e0d\u540c\u7684\u7b54\u6848\uff0c\u6697\u793a\u53d6\u6d88\u5b66\u4e60\u5177\u6709\u66f4\u6df1\u5c42\u6b21\u7684\u5f71\u54cd\u3002\u91cd\u8981\u7684\u662f\uff0cFUR \u786e\u5b9a\u7684 CoT \u6b65\u9aa4\u4e0e\u4eba\u7c7b\u5bf9\u5408\u7406\u6027\u7684\u6982\u5ff5\u4e0d\u592a\u4e00\u81f4\uff0c\u5f3a\u8c03\u4e86\u4e13\u95e8\u5bf9\u9f50\u7684\u5fc5\u8981\u6027", "author": "Martin Tutek et.al.", "authors": "Martin Tutek, Fateme Hashemi Chaleshtori, Ana Marasovi\u0107, Yonatan Belinkov", "id": "2502.14829v1", "paper_url": "http://arxiv.org/abs/2502.14829v1", "repo": "null"}}