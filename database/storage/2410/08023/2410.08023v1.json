{"2410.08023": {"publish_time": "2024-10-10", "title": "GrabDAE: An Innovative Framework for Unsupervised Domain Adaptation Utilizing Grab-Mask and Denoise Auto-Encoder", "paper_summary": "Unsupervised Domain Adaptation (UDA) aims to adapt a model trained on a\nlabeled source domain to an unlabeled target domain by addressing the domain\nshift. Existing Unsupervised Domain Adaptation (UDA) methods often fall short\nin fully leveraging contextual information from the target domain, leading to\nsuboptimal decision boundary separation during source and target domain\nalignment. To address this, we introduce GrabDAE, an innovative UDA framework\ndesigned to tackle domain shift in visual classification tasks. GrabDAE\nincorporates two key innovations: the Grab-Mask module, which blurs background\ninformation in target domain images, enabling the model to focus on essential,\ndomain-relevant features through contrastive learning; and the Denoising\nAuto-Encoder (DAE), which enhances feature alignment by reconstructing features\nand filtering noise, ensuring a more robust adaptation to the target domain.\nThese components empower GrabDAE to effectively handle unlabeled target domain\ndata, significantly improving both classification accuracy and robustness.\nExtensive experiments on benchmark datasets, including VisDA-2017, Office-Home,\nand Office31, demonstrate that GrabDAE consistently surpasses state-of-the-art\nUDA methods, setting new performance benchmarks. By tackling UDA's critical\nchallenges with its novel feature masking and denoising approach, GrabDAE\noffers both significant theoretical and practical advancements in domain\nadaptation.", "paper_summary_zh": "\u7121\u76e3\u7763\u57df\u9069\u61c9 (UDA) \u65e8\u5728\u900f\u904e\u89e3\u6c7a\u57df\u8f49\u79fb\uff0c\u5c07\u5728\u6a19\u7c64\u4f86\u6e90\u57df\u4e0a\u8a13\u7df4\u7684\u6a21\u578b\u9069\u61c9\u5230\u672a\u6a19\u7c64\u76ee\u6a19\u57df\u3002\u73fe\u6709\u7684\u7121\u76e3\u7763\u57df\u9069\u61c9 (UDA) \u65b9\u6cd5\u901a\u5e38\u7121\u6cd5\u5145\u5206\u5229\u7528\u4f86\u81ea\u76ee\u6a19\u57df\u7684\u4e0a\u4e0b\u6587\u8cc7\u8a0a\uff0c\u5c0e\u81f4\u5728\u4f86\u6e90\u548c\u76ee\u6a19\u57df\u6bd4\u5c0d\u671f\u9593\uff0c\u6b21\u4f73\u6c7a\u7b56\u908a\u754c\u5206\u96e2\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 GrabDAE\uff0c\u9019\u662f\u4e00\u500b\u5275\u65b0\u7684 UDA \u67b6\u69cb\uff0c\u65e8\u5728\u8655\u7406\u8996\u89ba\u5206\u985e\u4efb\u52d9\u4e2d\u7684\u57df\u8f49\u79fb\u3002GrabDAE \u7d50\u5408\u4e86\u5169\u9805\u95dc\u9375\u5275\u65b0\uff1aGrab-Mask \u6a21\u7d44\uff0c\u5b83\u6a21\u7cca\u4e86\u76ee\u6a19\u57df\u5f71\u50cf\u4e2d\u7684\u80cc\u666f\u8cc7\u8a0a\uff0c\u4f7f\u6a21\u578b\u80fd\u5920\u900f\u904e\u5c0d\u6bd4\u5b78\u7fd2\u5c08\u6ce8\u65bc\u5fc5\u8981\u7684\u3001\u8207\u57df\u76f8\u95dc\u7684\u7279\u5fb5\uff1b\u4ee5\u53ca\u53bb\u96dc\u8a0a\u81ea\u52d5\u7de8\u78bc\u5668 (DAE)\uff0c\u5b83\u900f\u904e\u91cd\u5efa\u7279\u5fb5\u548c\u904e\u6ffe\u96dc\u8a0a\u4f86\u589e\u5f37\u7279\u5fb5\u6bd4\u5c0d\uff0c\u78ba\u4fdd\u66f4\u5f37\u5065\u7684\u76ee\u6a19\u57df\u9069\u61c9\u3002\u9019\u4e9b\u5143\u4ef6\u8ce6\u4e88 GrabDAE \u6709\u6548\u8655\u7406\u672a\u6a19\u7c64\u76ee\u6a19\u57df\u8cc7\u6599\u7684\u80fd\u529b\uff0c\u5927\u5e45\u63d0\u5347\u5206\u985e\u6e96\u78ba\u5ea6\u548c\u5f37\u5065\u6027\u3002\u5728\u5305\u62ec VisDA-2017\u3001Office-Home \u548c Office31 \u5728\u5167\u7684\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\uff0cGrabDAE \u6301\u7e8c\u8d85\u8d8a\u6700\u5148\u9032\u7684 UDA \u65b9\u6cd5\uff0c\u8a2d\u5b9a\u65b0\u7684\u6548\u80fd\u57fa\u6e96\u3002\u900f\u904e\u5229\u7528\u5176\u65b0\u7a4e\u7684\u7279\u5fb5\u906e\u7f69\u548c\u53bb\u96dc\u8a0a\u65b9\u6cd5\u4f86\u89e3\u6c7a UDA \u7684\u95dc\u9375\u6311\u6230\uff0cGrabDAE \u5728\u57df\u9069\u61c9\u4e2d\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8ad6\u548c\u5be6\u52d9\u9032\u5c55\u3002", "author": "Junzhou Chen et.al.", "authors": "Junzhou Chen, Xuan Wen, Ronghui Zhang, Bingtao Ren, Di Wu, Zhigang Xu, Danwei Wang", "id": "2410.08023v1", "paper_url": "http://arxiv.org/abs/2410.08023v1", "repo": "null"}}