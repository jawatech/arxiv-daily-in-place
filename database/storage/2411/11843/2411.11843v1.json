{"2411.11843": {"publish_time": "2024-11-18", "title": "Bi-Mamba: Towards Accurate 1-Bit State Space Models", "paper_summary": "The typical selective state-space model (SSM) of Mamba addresses several\nlimitations of Transformers, such as quadratic computational complexity with\nsequence length and significant inference-time memory requirements due to the\nkey-value cache. However, the growing size of Mamba models continues to pose\ntraining and deployment challenges and raises environmental concerns due to\nconsiderable energy consumption. In this work, we introduce Bi-Mamba, a\nscalable and powerful 1-bit Mamba architecture designed for more efficient\nlarge language models with multiple sizes across 780M, 1.3B, and 2.7B. Bi-Mamba\nmodels are trained from scratch on data volume as regular LLM pertaining using\nan autoregressive distillation loss. Extensive experimental results on language\nmodeling demonstrate that Bi-Mamba achieves performance comparable to its\nfull-precision counterparts (e.g., FP16 or BF16) and much better accuracy than\npost-training-binarization (PTB) Mamba baselines, while significantly reducing\nmemory footprint and energy consumption compared to the original Mamba model.\nOur study pioneers a new linear computational complexity LLM framework under\nlow-bit representation and facilitates the future design of specialized\nhardware tailored for efficient 1-bit Mamba-based LLMs.", "paper_summary_zh": "\u5178\u578b\u7684 Mamba \u9078\u64c7\u6027\u72c0\u614b\u7a7a\u9593\u6a21\u578b (SSM) \u8655\u7406\u4e86 Transformer \u7684\u5e7e\u500b\u9650\u5236\uff0c\u4f8b\u5982\u4e8c\u6b21\u8a08\u7b97\u8907\u96dc\u5ea6\u8207\u5e8f\u5217\u9577\u5ea6\u548c\u7531\u65bc\u9375\u503c\u5feb\u53d6\u800c\u5c0e\u81f4\u7684\u986f\u8457\u63a8\u8ad6\u6642\u9593\u8a18\u61b6\u9ad4\u9700\u6c42\u3002\u7136\u800c\uff0cMamba \u6a21\u578b\u65e5\u76ca\u589e\u9577\u7684\u898f\u6a21\u6301\u7e8c\u5c0d\u8a13\u7df4\u548c\u90e8\u7f72\u9020\u6210\u6311\u6230\uff0c\u4e26\u7531\u65bc\u53ef\u89c0\u7684\u80fd\u8017\u800c\u5f15\u767c\u74b0\u5883\u554f\u984c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 Bi-Mamba\uff0c\u4e00\u7a2e\u53ef\u64f4\u5145\u4e14\u5f37\u5927\u7684 1 \u4f4d\u5143 Mamba \u67b6\u69cb\uff0c\u91dd\u5c0d\u66f4\u6709\u6548\u7387\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u800c\u8a2d\u8a08\uff0c\u5177\u6709 780M\u30011.3B \u548c 2.7B \u7b49\u591a\u7a2e\u5927\u5c0f\u3002Bi-Mamba \u6a21\u578b\u5f9e\u982d\u958b\u59cb\u8a13\u7df4\uff0c\u8cc7\u6599\u91cf\u8207\u4f7f\u7528\u81ea\u8ff4\u6b78\u84b8\u993e\u640d\u5931\u76f8\u95dc\u7684\u5e38\u898f LLM \u76f8\u540c\u3002\u8a9e\u8a00\u5efa\u6a21\u7684\u5ee3\u6cdb\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0c\u8207\u5176\u5168\u7cbe\u5ea6\u5c0d\u61c9\u7269\uff08\u4f8b\u5982 FP16 \u6216 BF16\uff09\u76f8\u6bd4\uff0cBi-Mamba \u9054\u5230\u4e86\u76f8\u7576\u7684\u6548\u80fd\uff0c\u800c\u4e14\u6bd4\u8a13\u7df4\u5f8c\u4e8c\u5143\u5316 (PTB) Mamba \u57fa\u6e96\u7684\u6e96\u78ba\u5ea6\u9ad8\u51fa\u8a31\u591a\uff0c\u540c\u6642\u8207\u539f\u59cb Mamba \u6a21\u578b\u76f8\u6bd4\uff0c\u986f\u8457\u6e1b\u5c11\u4e86\u8a18\u61b6\u9ad4\u4f54\u7528\u7a7a\u9593\u548c\u80fd\u8017\u3002\u6211\u5011\u7684\u7814\u7a76\u958b\u5275\u4e86\u4e00\u500b\u65b0\u7684\u7dda\u6027\u8a08\u7b97\u8907\u96dc\u5ea6 LLM \u6846\u67b6\uff0c\u5728\u4f4e\u4f4d\u5143\u8868\u793a\u4e0b\uff0c\u4e26\u4fc3\u9032\u4e86\u91dd\u5c0d\u6709\u6548\u7387\u7684 1 \u4f4d\u5143 Mamba \u57fa\u790e LLM \u800c\u91cf\u8eab\u6253\u9020\u7684\u5c08\u7528\u786c\u9ad4\u7684\u672a\u4f86\u8a2d\u8a08\u3002", "author": "Shengkun Tang et.al.", "authors": "Shengkun Tang, Liqun Ma, Haonan Li, Mingjie Sun, Zhiqiang Shen", "id": "2411.11843v1", "paper_url": "http://arxiv.org/abs/2411.11843v1", "repo": "null"}}