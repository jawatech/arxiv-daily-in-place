
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-13**|**Model Counting in the Wild**|Arijit Shaw et.al.|[2408.07059v1](http://arxiv.org/abs/2408.07059v1)|null|
|**2024-08-13**|**KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**|Daniele Rege Cambrin et.al.|[2408.07040v1](http://arxiv.org/abs/2408.07040v1)|null|
|**2024-08-13**|**PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**|Xiaomin Wu et.al.|[2408.07037v1](http://arxiv.org/abs/2408.07037v1)|null|
|**2024-08-13**|**Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**|Bauke Arends et.al.|[2408.06930v1](http://arxiv.org/abs/2408.06930v1)|null|
|**2024-08-13**|**BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**|Yuyang Xue et.al.|[2408.06890v1](http://arxiv.org/abs/2408.06890v1)|null|
|**2024-08-12**|**Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**|Trisha Das et.al.|[2408.06285v1](http://arxiv.org/abs/2408.06285v1)|null|
|**2024-08-12**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240v3](http://arxiv.org/abs/2408.06240v3)|null|
|**2024-08-12**|**ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation**|Qiaoxin Li et.al.|[2408.06163v1](http://arxiv.org/abs/2408.06163v1)|null|
|**2024-08-12**|**Med42-v2: A Suite of Clinical LLMs**|Clément Christophe et.al.|[2408.06142v1](http://arxiv.org/abs/2408.06142v1)|null|
|**2024-08-11**|**Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection**|Varun Shiva Krishna Rupani et.al.|[2408.05836v1](http://arxiv.org/abs/2408.05836v1)|null|
|**2024-08-11**|**TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling**|Ruiquan Ge et.al.|[2408.05705v1](http://arxiv.org/abs/2408.05705v1)|[link](https://github.com/lcbkmm/tc-kanrecon)|
|**2024-08-11**|**A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation**|Koushik Biswas et.al.|[2408.05692v1](http://arxiv.org/abs/2408.05692v1)|null|
|**2024-08-10**|**Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale**|Vindula Jayawardana et.al.|[2408.05609v1](http://arxiv.org/abs/2408.05609v1)|null|
|**2024-08-09**|**Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**|Shouyue Liu et.al.|[2408.05117v1](http://arxiv.org/abs/2408.05117v1)|null|
|**2024-08-09**|**RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**|Sangjoon Park et.al.|[2408.05074v1](http://arxiv.org/abs/2408.05074v1)|null|
|**2024-08-09**|**CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**|Gianluca Carloni et.al.|[2408.04949v1](http://arxiv.org/abs/2408.04949v1)|[link](https://github.com/gianlucarloni/crocodile)|
|**2024-08-09**|**Unleashing Artificial Cognition: Integrating Multiple AI Systems**|Muntasir Adnan et.al.|[2408.04910v3](http://arxiv.org/abs/2408.04910v3)|[link](https://github.com/TheOpenSI/cognitive_AI_experiments)|
|**2024-08-09**|**Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**|Kai Jiang et.al.|[2408.04849v1](http://arxiv.org/abs/2408.04849v1)|null|
|**2024-08-08**|**Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**|Vandan Gorade et.al.|[2408.04491v1](http://arxiv.org/abs/2408.04491v1)|null|
|**2024-08-08**|**Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review**|Anshu Ankolekar et.al.|[2408.05249v1](http://arxiv.org/abs/2408.05249v1)|null|
|**2024-08-08**|**Non-maximizing policies that fulfill multi-criterion aspirations in expectation**|Simon Dima et.al.|[2408.04385v1](http://arxiv.org/abs/2408.04385v1)|null|
|**2024-08-08**|**AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**|Mugheez Asif et.al.|[2408.04281v1](http://arxiv.org/abs/2408.04281v1)|null|
|**2024-08-08**|**Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications**|Philipp Zagar et.al.|[2408.04680v1](http://arxiv.org/abs/2408.04680v1)|null|
|**2024-08-08**|**The Data Addition Dilemma**|Judy Hanwen Shen et.al.|[2408.04154v1](http://arxiv.org/abs/2408.04154v1)|[link](https://github.com/the-chen-lab/data-addition-dilemma)|
|**2024-08-08**|**Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**|Haoran Yu et.al.|[2408.04138v1](http://arxiv.org/abs/2408.04138v1)|null|
|**2024-08-07**|**Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**|Panagiotis Fytas et.al.|[2408.04121v1](http://arxiv.org/abs/2408.04121v1)|null|
|**2024-08-07**|**Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**|Joseph Cameron et.al.|[2408.04026v1](http://arxiv.org/abs/2408.04026v1)|null|
|**2024-08-07**|**Inter-Series Transformer: Attending to Products in Time Series Forecasting**|Rares Cristian et.al.|[2408.03872v1](http://arxiv.org/abs/2408.03872v1)|null|
|**2024-08-07**|**HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**|Juho Jung et.al.|[2408.03648v1](http://arxiv.org/abs/2408.03648v1)|null|
|**2024-08-07**|**Improving the quality of Persian clinical text with a novel spelling correction system**|Seyed Mohammad Sadegh Dashti et.al.|[2408.03622v1](http://arxiv.org/abs/2408.03622v1)|null|
|**2024-08-06**|**Identifying treatment response subgroups in observational time-to-event data**|Vincent Jeanselme et.al.|[2408.03463v1](http://arxiv.org/abs/2408.03463v1)|null|
|**2024-08-06**|**Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**|Lucia Gordon et.al.|[2408.03405v1](http://arxiv.org/abs/2408.03405v1)|[link](https://github.com/lgordon99/heterogeneous-stochastic-bandits)|
|**2024-08-06**|**MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**|Wenqi Zhu et.al.|[2408.03358v1](http://arxiv.org/abs/2408.03358v1)|null|
|**2024-08-06**|**Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**|Jialang Xu et.al.|[2408.03208v1](http://arxiv.org/abs/2408.03208v1)|null|
|**2024-08-06**|**The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**|Vanessa Clairoux-Trepanier et.al.|[2408.03354v2](http://arxiv.org/abs/2408.03354v2)|null|
|**2024-08-06**|**VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**|Ju-Hyeon Nam et.al.|[2408.02888v1](http://arxiv.org/abs/2408.02888v1)|null|
|**2024-08-05**|**VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**|Zihan Li et.al.|[2408.02865v1](http://arxiv.org/abs/2408.02865v1)|[link](https://github.com/HUANGLIZI/VisionUnite)|
|**2024-08-05**|**Multistain Pretraining for Slide Representation Learning in Pathology**|Guillaume Jaume et.al.|[2408.02859v1](http://arxiv.org/abs/2408.02859v1)|[link](https://github.com/mahmoodlab/madeleine)|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**|Zheng Han et.al.|[2408.02713v1](http://arxiv.org/abs/2408.02713v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-08-05**|**Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**|Khanh Nguyen et.al.|[2408.02349v1](http://arxiv.org/abs/2408.02349v1)|null|
|**2024-08-04**|**MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**|Alireza Amirshahi et.al.|[2408.01988v1](http://arxiv.org/abs/2408.01988v1)|null|
|**2024-08-04**|**DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**|Bowen Wang et.al.|[2408.01933v2](http://arxiv.org/abs/2408.01933v2)|null|
|**2024-08-03**|**MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**|Jihye Choi et.al.|[2408.01869v1](http://arxiv.org/abs/2408.01869v1)|[link](https://github.com/jihyechoi77/malade)|
|**2024-08-03**|**Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools**|Jung In Park et.al.|[2408.04650v1](http://arxiv.org/abs/2408.04650v1)|null|
|**2024-08-03**|**ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**|Mridula Vijendran et.al.|[2408.01827v1](http://arxiv.org/abs/2408.01827v1)|null|
|**2024-08-03**|**Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment**|Jinwen Tang et.al.|[2408.01614v1](http://arxiv.org/abs/2408.01614v1)|null|
|**2024-08-02**|**Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference**|Hengrui Cai et.al.|[2408.01582v1](http://arxiv.org/abs/2408.01582v1)|null|
|**2024-08-02**|**High-Throughput Phenotyping of Clinical Text Using Large Language Models**|Daniel B. Hier et.al.|[2408.01214v1](http://arxiv.org/abs/2408.01214v1)|null|
|**2024-08-02**|**Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning**|Michael Kölle et.al.|[2408.01187v1](http://arxiv.org/abs/2408.01187v1)|null|
|**2024-08-02**|**Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**|Danbinaerin Han et.al.|[2408.01096v1](http://arxiv.org/abs/2408.01096v1)|null|
|**2024-08-01**|**CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**|Caiwen Jiang et.al.|[2408.00938v2](http://arxiv.org/abs/2408.00938v2)|null|
|**2024-08-01**|**Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**|Christopher Neves et.al.|[2408.00906v1](http://arxiv.org/abs/2408.00906v1)|null|
|**2024-08-01**|**UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**|Ziwen Guo et.al.|[2408.00860v2](http://arxiv.org/abs/2408.00860v2)|null|
|**2024-08-01**|**Segment anything model 2: an application to 2D and 3D medical images**|Haoyu Dong et.al.|[2408.00756v2](http://arxiv.org/abs/2408.00756v2)|null|
|**2024-08-01**|**Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**|Venkat Margapuri et.al.|[2408.00749v1](http://arxiv.org/abs/2408.00749v1)|null|
|**2024-08-01**|**Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**|Guangzhi Xiong et.al.|[2408.00727v1](http://arxiv.org/abs/2408.00727v1)|null|
|**2024-08-01**|**Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**|Xiaofeng Liu et.al.|[2408.00706v1](http://arxiv.org/abs/2408.00706v1)|null|
|**2024-08-01**|**HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**|Bolin Zhang et.al.|[2408.00481v1](http://arxiv.org/abs/2408.00481v1)|null|
|**2024-08-01**|**Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**|Angona Biswas et.al.|[2408.00348v1](http://arxiv.org/abs/2408.00348v1)|null|
|**2024-08-01**|**Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**|Sungmin Kang et.al.|[2408.00347v1](http://arxiv.org/abs/2408.00347v1)|null|
|**2024-07-31**|**S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**|Andrea Kim et.al.|[2408.00191v1](http://arxiv.org/abs/2408.00191v1)|null|
|**2024-07-31**|**A Taxonomy of Stereotype Content in Large Language Models**|Gandalf Nicolas et.al.|[2408.00162v1](http://arxiv.org/abs/2408.00162v1)|null|
|**2024-07-31**|**Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)**|Adam Gould et.al.|[2408.00108v2](http://arxiv.org/abs/2408.00108v2)|null|
|**2024-07-31**|**A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**|Mothilal Asokan et.al.|[2407.21739v1](http://arxiv.org/abs/2407.21739v1)|null|
|**2024-07-31**|**Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**|Krishan Agyakari Raja Babu et.al.|[2407.21674v1](http://arxiv.org/abs/2407.21674v1)|null|
|**2024-07-31**|**Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**|Hermione Warr et.al.|[2407.21638v1](http://arxiv.org/abs/2407.21638v1)|null|
|**2024-07-31**|**Optimizing Disease Prediction with Artificial Intelligence Driven Feature Selection and Attention Networks**|D. Dhinakaran et.al.|[2408.03151v1](http://arxiv.org/abs/2408.03151v1)|null|
|**2024-07-31**|**Voxel Scene Graph for Intracranial Hemorrhage**|Antoine P. Sanner et.al.|[2407.21580v1](http://arxiv.org/abs/2407.21580v1)|null|
|**2024-07-31**|**Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**|I. M. Chernenkiy et.al.|[2407.21516v1](http://arxiv.org/abs/2407.21516v1)|null|
|**2024-07-31**|**Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**|Junxuan Yu et.al.|[2407.21490v1](http://arxiv.org/abs/2407.21490v1)|null|
|**2024-07-31**|**Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data**|Mengtian Kang et.al.|[2407.21467v1](http://arxiv.org/abs/2407.21467v1)|null|
|**2024-07-31**|**Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering**|Danfeng Guo et.al.|[2407.21368v1](http://arxiv.org/abs/2407.21368v1)|null|
|**2024-07-31**|**MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework**|Adrian Celaya et.al.|[2407.21343v1](http://arxiv.org/abs/2407.21343v1)|null|
|**2024-07-31**|**Patient-centered data science: an integrative framework for evaluating and predicting clinical outcomes in the digital health era**|Mohsen Amoei et.al.|[2408.02677v1](http://arxiv.org/abs/2408.02677v1)|null|
|**2024-07-31**|**Robust Box Prompt based SAM for Medical Image Segmentation**|Yuhao Huang et.al.|[2407.21284v1](http://arxiv.org/abs/2407.21284v1)|null|
|**2024-07-31**|**Unlocking the Potential of Binding Corporate Rules (BCRs) in Health Data Transfers**|Marcelo Corrales Compagnucci et.al.|[2407.21281v1](http://arxiv.org/abs/2407.21281v1)|null|
|**2024-07-31**|**FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations**|Rujia Shen et.al.|[2407.21275v1](http://arxiv.org/abs/2407.21275v1)|null|
|**2024-07-31**|**Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net**|Rohini Banerjee et.al.|[2407.21273v1](http://arxiv.org/abs/2407.21273v1)|null|
|**2024-07-30**|**Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population**|Mayanka Chandrashekar et.al.|[2407.21149v1](http://arxiv.org/abs/2407.21149v1)|null|
|**2024-07-30**|**Zero Shot Health Trajectory Prediction Using Transformer**|Pawel Renc et.al.|[2407.21124v1](http://arxiv.org/abs/2407.21124v1)|null|
|**2024-07-30**|**CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**|Yuexi Du et.al.|[2407.21011v1](http://arxiv.org/abs/2407.21011v1)|[link](https://github.com/xypb/cleft)|
|**2024-07-30**|**Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**|Eugenio Lomurno et.al.|[2407.20830v1](http://arxiv.org/abs/2407.20830v1)|null|
|**2024-07-30**|**Interpretable Pre-Trained Transformers for Heart Time-Series Data**|Harry J. Davies et.al.|[2407.20775v2](http://arxiv.org/abs/2407.20775v2)|[link](https://github.com/harryjdavies/heartgpt)|
|**2024-07-30**|**Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization**|Michael Kölle et.al.|[2407.20739v1](http://arxiv.org/abs/2407.20739v1)|null|
|**2024-07-29**|**Dense Self-Supervised Learning for Medical Image Segmentation**|Maxime Seince et.al.|[2407.20395v1](http://arxiv.org/abs/2407.20395v1)|null|
|**2024-07-29**|**Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**|Ruochen Li et.al.|[2407.20108v1](http://arxiv.org/abs/2407.20108v1)|null|
|**2024-07-29**|**Robust Conformal Volume Estimation in 3D Medical Images**|Benjamin Lambert et.al.|[2407.19938v1](http://arxiv.org/abs/2407.19938v1)|[link](https://github.com/benolmbrt/wcp_miccai)|
|**2024-07-29**|**Yucca: A Deep Learning Framework For Medical Image Analysis**|Sebastian Nørgaard Llambias et.al.|[2407.19888v1](http://arxiv.org/abs/2407.19888v1)|[link](https://github.com/sllambias/yucca)|
|**2024-07-29**|**CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**|Jingwei Zhu et.al.|[2407.19705v2](http://arxiv.org/abs/2407.19705v2)|[link](https://github.com/cas-siat-xinhai/collectivesft)|
|**2024-07-29**|**Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks**|Marco AF Pimentel et.al.|[2407.21072v1](http://arxiv.org/abs/2407.21072v1)|null|
|**2024-07-29**|**Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**|Minxiao Chen et.al.|[2407.19668v1](http://arxiv.org/abs/2407.19668v1)|[link](https://github.com/faceless0124/mghstn)|
|**2024-07-28**|**Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Knowledge Distillation and Random Data Erasing**|Heejoon Koo et.al.|[2407.19540v1](http://arxiv.org/abs/2407.19540v1)|null|
|**2024-07-28**|**Nudging Consent and the New Opt Out System to the Processing of Health Data in England**|Janos Meszaros et.al.|[2407.19447v1](http://arxiv.org/abs/2407.19447v1)|null|
|**2024-07-28**|**ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding**|Zhen Chen et.al.|[2407.19435v1](http://arxiv.org/abs/2407.19435v1)|[link](https://github.com/zonmgin-zhang/asi-seg)|
|**2024-07-28**|**A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy**|Meng Jiang et.al.|[2407.19422v1](http://arxiv.org/abs/2407.19422v1)|null|
|**2024-07-28**|**Empowering Clinicians with Medical Decision Transformers: A Framework for Sepsis Treatment**|Aamer Abdul Rahman et.al.|[2407.19380v1](http://arxiv.org/abs/2407.19380v1)|null|
|**2024-07-28**|**Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction**|Yuan Xue et.al.|[2407.19359v1](http://arxiv.org/abs/2407.19359v1)|null|

#### Abstracts
##### **Model Counting in the Wild**
2408.07059v1 by Arijit Shaw, Kuldeep S. Meel

Model counting is a fundamental problem in automated reasoning with
applications in probabilistic inference, network reliability, neural network
verification, and more. Although model counting is computationally intractable
from a theoretical perspective due to its #P-completeness, the past decade has
seen significant progress in developing state-of-the-art model counters to
address scalability challenges.
  In this work, we conduct a rigorous assessment of the scalability of model
counters in the wild. To this end, we surveyed 11 application domains and
collected an aggregate of 2262 benchmarks from these domains. We then evaluated
six state-of-the-art model counters on these instances to assess scalability
and runtime performance.
  Our empirical evaluation demonstrates that the performance of model counters
varies significantly across different application domains, underscoring the
need for careful selection by the end user. Additionally, we investigated the
behavior of different counters with respect to two parameters suggested by the
model counting community, finding only a weak correlation. Our analysis
highlights the challenges and opportunities for portfolio-based approaches in
model counting.

摘要：模型計數是自動推理中的基本問題，在機率推論、網路可靠度、神經網路驗證等領域有其應用。儘管模型計數在理論上因其 #P-completeness 而在計算上難以處理，過去十年來，在開發最先進的模型計數器以解決可擴充性挑戰方面已取得顯著進展。
在本文中，我們對模型計數器的可擴充性進行了嚴謹的評估。為此，我們調查了 11 個應用領域，並從這些領域收集了 2262 個基準。然後，我們在這些實例上評估了六個最先進的模型計數器，以評估可擴充性和執行時間效能。
我們的實證評估表明，模型計數器的效能因不同的應用領域而異，這凸顯了最終使用者仔細選擇的必要性。此外，我們研究了不同計數器相對於模型計數社群建議的兩個參數的行為，發現只有微弱的相關性。我們的分析重點說明了模型計數中基於投資組合的方法所面臨的挑戰和機會。

##### **KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**
2408.07040v1 by Daniele Rege Cambrin, Eleonora Poeta, Eliana Pastor, Tania Cerquitelli, Elena Baralis, Paolo Garza

Segmentation of crop fields is essential for enhancing agricultural
productivity, monitoring crop health, and promoting sustainable practices. Deep
learning models adopted for this task must ensure accurate and reliable
predictions to avoid economic losses and environmental impact. The newly
proposed Kolmogorov-Arnold networks (KANs) offer promising advancements in the
performance of neural networks. This paper analyzes the integration of KAN
layers into the U-Net architecture (U-KAN) to segment crop fields using
Sentinel-2 and Sentinel-1 satellite images and provides an analysis of the
performance and explainability of these networks. Our findings indicate a 2\%
improvement in IoU compared to the traditional full-convolutional U-Net model
in fewer GFLOPs. Furthermore, gradient-based explanation techniques show that
U-KAN predictions are highly plausible and that the network has a very high
ability to focus on the boundaries of cultivated areas rather than on the areas
themselves. The per-channel relevance analysis also reveals that some channels
are irrelevant to this task.

摘要：農作物田區分割對於提升農業生產力、監控作物健康和促進永續實務至關重要。採用於此任務的深度學習模型必須確保準確且可靠的預測，以避免經濟損失和環境影響。新提出的柯爾莫哥洛夫-阿諾德網路 (KAN) 為神經網路的效能提供了有希望的進展。本文分析將 KAN 層整合到 U-Net 架構 (U-KAN) 中，以使用 Sentinel-2 和 Sentinel-1 衛星影像分割農作物田區，並提供對這些網路效能和可解釋性的分析。我們的研究結果顯示，與傳統的全卷積 U-Net 模型相比，IoU 提升了 2%，而 GFLOP 較少。此外，基於梯度的解釋技術顯示 U-KAN 預測非常合理，而且網路非常有能力專注於耕作區域的邊界，而不是區域本身。每個通道關聯性分析也顯示，有些通道與此任務無關。

##### **PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**
2408.07037v1 by Xiaomin Wu, Rui Xu, Pengchen Wei, Wenkang Qin, Peixiang Huang, Ziheng Li, Lin Luo

Pathological diagnosis remains the definitive standard for identifying
tumors. The rise of multimodal large models has simplified the process of
integrating image analysis with textual descriptions. Despite this advancement,
the substantial costs associated with training and deploying these complex
multimodal models, together with a scarcity of high-quality training datasets,
create a significant divide between cutting-edge technology and its application
in the clinical setting. We had meticulously compiled a dataset of
approximately 45,000 cases, covering over 6 different tasks, including the
classification of organ tissues, generating pathology report descriptions, and
addressing pathology-related questions and answers. We have fine-tuned
multimodal large models, specifically LLaVA, Qwen-VL, InternLM, with this
dataset to enhance instruction-based performance. We conducted a qualitative
assessment of the capabilities of the base model and the fine-tuned model in
performing image captioning and classification tasks on the specific dataset.
The evaluation results demonstrate that the fine-tuned model exhibits
proficiency in addressing typical pathological questions. We hope that by
making both our models and datasets publicly available, they can be valuable to
the medical and research communities.

摘要：病理診斷仍然是識別腫瘤的明確標準。多模態大型模型的興起簡化了將影像分析與文字描述整合的過程。儘管有此進展，但訓練和部署這些複雜的多模態模型相關的龐大成本，以及缺乏高品質的訓練資料集，導致尖端技術與其在臨床環境中的應用之間產生了顯著的差距。我們已細心編制了一個包含約 45,000 個案例的資料集，涵蓋 6 項不同的任務，包括器官組織分類、產生病理報告描述，以及回答與病理相關的問題。我們使用這個資料集微調了多模態大型模型，特別是 LLaVA、Qwen-VL、InternLM，以增強基於指令的效能。我們對基礎模型和微調模型在特定資料集上執行影像標題和分類任務的能力進行了定性評估。評估結果表明，微調模型在回答典型病理問題方面表現出熟練度。我們希望透過公開我們的模型和資料集，它們能對醫療和研究社群有價值。

##### **Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**
2408.06930v1 by Bauke Arends, Melle Vessies, Dirk van Osch, Arco Teske, Pim van der Harst, René van Es, Bram van Es

Clinical machine learning research and AI driven clinical decision support
models rely on clinically accurate labels. Manually extracting these labels
with the help of clinical specialists is often time-consuming and expensive.
This study tests the feasibility of automatic span- and document-level
diagnosis extraction from unstructured Dutch echocardiogram reports.
  We included 115,692 unstructured echocardiogram reports from the UMCU a large
university hospital in the Netherlands. A randomly selected subset was manually
annotated for the occurrence and severity of eleven commonly described cardiac
characteristics. We developed and tested several automatic labelling techniques
at both span and document levels, using weighted and macro F1-score, precision,
and recall for performance evaluation. We compared the performance of span
labelling against document labelling methods, which included both direct
document classifiers and indirect document classifiers that rely on span
classification results.
  The SpanCategorizer and MedRoBERTa.nl models outperformed all other span and
document classifiers, respectively. The weighted F1-score varied between
characteristics, ranging from 0.60 to 0.93 in SpanCategorizer and 0.96 to 0.98
in MedRoBERTa.nl. Direct document classification was superior to indirect
document classification using span classifiers. SetFit achieved competitive
document classification performance using only 10\% of the training data.
Utilizing a reduced label set yielded near-perfect document classification
results.
  We recommend using our published SpanCategorizer and MedRoBERTa.nl models for
span- and document-level diagnosis extraction from Dutch echocardiography
reports. For settings with limited training data, SetFit may be a promising
alternative for document classification.

摘要：<paragraph>臨床機器學習研究和 AI 驅動的臨床決策支援模型依賴於臨床精確標籤。在臨床專家的協助下手動提取這些標籤通常既耗時又昂貴。本研究測試了從非結構化荷蘭超音波心動圖報告中自動提取跨度和文件級別診斷的可行性。我們納入了來自荷蘭一家大型大學醫院 UMCU 的 115,692 份非結構化超音波心動圖報告。手動註解了一個隨機選取的子集，以了解十一種常見描述的心臟特徵的發生和嚴重程度。我們開發並測試了跨度和文件級別的幾種自動標籤技術，使用加權和巨集 F1 分數、精確度和召回率進行效能評估。我們比較了跨度標籤相對於文件標籤方法的效能，其中包括直接文件分類器和依賴於跨度分類結果的間接文件分類器。SpanCategorizer 和 MedRoBERTa.nl 模型分別優於所有其他跨度和文件分類器。加權 F1 分數因特徵而異，在 SpanCategorizer 中介於 0.60 到 0.93，在 MedRoBERTa.nl 中介於 0.96 到 0.98。使用跨度分類器的間接文件分類不如直接文件分類。SetFit 僅使用 10% 的訓練資料就達到了有競爭力的文件分類效能。利用減少的標籤組產生了近乎完美的文件分類結果。我們建議使用我們發布的 SpanCategorizer 和 MedRoBERTa.nl 模型從荷蘭超音波心動圖報告中提取跨度和文件級別診斷。對於訓練資料有限的設定，SetFit 可能是一種有前途的文件分類替代方案。</paragraph>

##### **BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**
2408.06890v1 by Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris

Developing models with robust group fairness properties is paramount,
particularly in ethically sensitive domains such as medical diagnosis. Recent
approaches to achieving fairness in machine learning require a substantial
amount of training data and depend on model retraining, which may not be
practical in real-world scenarios. To mitigate these challenges, we propose
Bias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method
that enhances the fairness of a trained model in significantly fewer epochs
without requiring access to the original training data. BMFT produces a mask
over model parameters, which efficiently identifies the weights contributing
the most towards biased predictions. Furthermore, we propose a two-step
debiasing strategy, wherein the feature extractor undergoes initial fine-tuning
on the identified bias-influenced weights, succeeded by a fine-tuning phase on
a reinitialised classification layer to uphold discriminative performance.
Extensive experiments across four dermatological datasets and two sensitive
attributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)
techniques in both diagnostic accuracy and fairness metrics. Our findings
underscore the efficacy and robustness of BMFT in advancing fairness across
various out-of-distribution (OOD) settings. Our code is available at:
https://github.com/vios-s/BMFT

摘要：<paragraph>開發具有穩健群組公平性特性的模型至關重要，特別是在醫療診斷等道德敏感領域。最近實現機器學習公平性的方法需要大量的訓練資料，並且依賴於模型再訓練，這在現實情況中可能不切實際。為了緩解這些挑戰，我們提出了基於偏差的權重遮罩微調 (BMFT)，這是一種新穎的後處理方法，可以在顯著更少的輪次中增強訓練模型的公平性，而無需訪問原始訓練資料。BMFT 在模型參數上產生一個遮罩，有效地識別出對偏差預測貢獻最大的權重。此外，我們提出了一種兩步去偏策略，其中特徵提取器對識別出的偏差影響權重進行初始微調，然後在重新初始化的分類層上進行微調階段以維持區分效能。在四個皮膚科資料集和兩個敏感屬性的廣泛實驗中證明，BMFT 在診斷準確性和公平性指標上都優於現有的最先進 (SOTA) 技術。我們的研究結果強調了 BMFT 在推進各種非分佈 (OOD) 設定中的公平性方面的效力和穩健性。我們的程式碼可在以下位置獲得：
https://github.com/vios-s/BMFT</paragraph>

##### **Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**
2408.06285v1 by Trisha Das, Dina Albassam, Jimeng Sun

Medical dialogue systems (MDS) enhance patient-physician communication,
improve healthcare accessibility, and reduce costs. However, acquiring suitable
data to train these systems poses significant challenges. Privacy concerns
prevent the use of real conversations, necessitating synthetic alternatives.
Synthetic dialogue generation from publicly available clinical notes offers a
promising solution to this issue, providing realistic data while safeguarding
privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot
prompting and a feedback loop to generate and refine high-quality synthetic
dialogues. The feedback consists of weighted evaluation scores for similarity
and extractiveness. The iterative process ensures dialogues meet predefined
thresholds, achieving superior extractiveness as a result of the feedback loop.
Additionally, evaluation shows that the generated dialogues excel in factuality
metric compared to the baselines and has comparable diversity scores with GPT4.

摘要：醫療對話系統 (MDS) 可增強病患與醫師的溝通、改善醫療保健的可近性，並降低成本。然而，取得適當的資料來訓練這些系統會造成重大的挑戰。隱私問題會妨礙真實對話的使用，因此需要合成替代方案。從公開可取得的臨床筆記生成合成對話提供了這個問題一個有前景的解決方案，在保護隱私的同時提供真實的資料。我們的 SynDial 方法使用單一 LLM 透過零次提示和回饋迴路，反覆生成和改善高品質的合成對話。回饋包含相似性和抽取性的加權評分。反覆的程序可確保對話符合預先定義的閾值，並因回饋迴路而達成優異的抽取性。此外，評估顯示生成的對話在事實性指標上優於基準，且與 GPT4 具有相當的多樣性評分。

##### **Decentralized Health Intelligence Network (DHIN)**
2408.06240v3 by Abraham Nash

Decentralized Health Intelligence Network (DHIN) is a theoretical framework
addressing significant challenges of health data sovereignty and AI utilization
in healthcare caused by data fragmentation across providers and institutions.
It establishes a sovereign architecture for healthcare provision as a
prerequisite to a sovereign health network, then facilitates effective AI
utilization by overcoming barriers to accessing diverse medical data sources.
This comprehensive framework leverages: 1) self-sovereign identity architecture
coupled with a personal health record (PHR) as a prerequisite for health data
sovereignty; 2) a scalable federated learning (FL) protocol implemented on a
public blockchain for decentralized AI training in healthcare, where health
data remains with participants and only model parameter updates are shared; and
3) a scalable, trustless rewards mechanism to incentivize participation and
ensure fair reward distribution. This framework ensures that no entity can
prevent or control access to training on health data offered by participants or
determine financial benefits, as these processes operate on a public blockchain
with an immutable record and without a third party. It supports effective AI
training in healthcare, allowing patients to maintain control over their health
data, benefit financially, and contribute to a decentralized, scalable
ecosystem that leverages collective AI to develop beneficial healthcare
algorithms. Patients receive rewards into their digital wallets as an incentive
to opt-in to the FL protocol, with a long-term roadmap to funding decentralized
insurance solutions. This approach introduces a novel, self-financed healthcare
model that adapts to individual needs, complements existing systems, and
redefines universal coverage. It highlights the potential to transform
healthcare data management and AI utilization while empowering patients.

摘要：分散式健康情報網路 (DHIN) 是個理論架構，
用來解決醫療保健中因資料分散在各個供應商和機構而產生的健康資料主權和 AI 使用的重大挑戰。
它建立了一個主權架構來提供醫療保健，作為主權健康網路的先決條件，然後透過克服取得多樣化醫療資料來源的障礙，促進有效的 AI 使用。
這個全面的架構利用：1) 自主權身分架構，結合個人健康紀錄 (PHR) 作為健康資料主權的先決條件；2) 在公共區塊鏈上實作的可擴充聯合學習 (FL) 協定，用於醫療保健中的分散式 AI 訓練，其中健康資料仍由參與者持有，只有模型參數更新會被分享；3) 可擴充的、無信任的獎勵機制，用於激勵參與並確保公平的獎勵分配。這個架構確保沒有任何實體可以阻止或控制參與者提供的健康資料訓練存取，或決定財務利益，因為這些程序是在公共區塊鏈上運作，具有不可變更的紀錄，而且沒有第三方。它支援在醫療保健中進行有效的 AI 訓練，讓患者可以維持對其健康資料的控制權，獲得財務利益，並貢獻到一個分散式、可擴充的生態系統，利用集體 AI 來開發有益的醫療保健演算法。患者會收到獎勵到他們的數位錢包中，作為選擇加入 FL 協定的誘因，長期目標是為分散式保險解決方案提供資金。這種方法引進了一個新穎的、自我資助的醫療保健模式，可以適應個別需求，補充現有系統，並重新定義全民健保。它突顯了轉型醫療保健資料管理和 AI 使用的潛力，同時賦予患者權力。

##### **ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation**
2408.06163v1 by Qiaoxin Li, Dong Liang, Yinsheng Li

Dual-energy computed tomography (DECT) has been widely used to obtain
quantitative elemental composition of imaged subjects for personalized and
precise medical diagnosis. Compared with existing high-end DECT leveraging
advanced X-ray source and/or detector technologies, the use of the
sequentially-scanning data acquisition scheme to implement DECT may make
broader impact on clinical practice because this scheme requires no specialized
hardware designs. However, since the concentration of iodinated contrast agent
in the imaged subject varies over time, sequentially-scanned data sets acquired
at two tube potentials are temporally inconsistent. As existing material
decomposition approaches for DECT assume that the data sets acquired at two
tube potentials are temporally consistent, the violation of this assumption
results in inaccurate quantification accuracy of iodine concentration. In this
work, we developed a technique to achieve sequentially-scanning DECT imaging
using high temporal resolution image reconstruction and temporal extrapolation,
ACCELERATION in short, to address the technical challenge induced by temporal
inconsistency of sequentially-scanned data sets and improve iodine
quantification accuracy in sequentially-scanning DECT. ACCELERATION has been
validated and evaluated using numerical simulation data sets generated from
clinical human subject exams. Results demonstrated the improvement of iodine
quantification accuracy using ACCELERATION.

摘要：雙能電腦斷層掃描 (DECT) 已廣泛用於取得影像化受試者的定量元素組成，以進行個人化且精確的醫療診斷。與利用先進 X 光源和/或偵測器技術的現有高階 DECT 相比，使用連續掃描資料擷取方案來實作 DECT 可能對臨床實務造成更廣泛的影響，因為此方案不需要專門的硬體設計。然而，由於影像化受試者中碘化對比劑的濃度會隨著時間而變化，因此在兩個管電位下擷取的連續掃描資料集在時間上並不一致。由於 DECT 現有的材料分解方法假設在兩個管電位下擷取的資料集在時間上是一致的，因此違反此假設會導致碘濃度的定量準確度不準確。在這項工作中，我們開發了一種技術，使用高時間解析度影像重建和時間外推法來達成連續掃描 DECT 影像，簡稱 ACCELERATION，以解決連續掃描資料集的時間不一致性所造成的技術挑戰，並改善連續掃描 DECT 中的碘定量準確度。ACCELERATION 已使用從臨床人體受試者檢查中產生的數值模擬資料集進行驗證和評估。結果證明使用 ACCELERATION 可改善碘定量準確度。

##### **Med42-v2: A Suite of Clinical LLMs**
2408.06142v1 by Clément Christophe, Praveen K Kanithi, Tathagata Raha, Shadab Khan, Marco AF Pimentel

Med42-v2 introduces a suite of clinical large language models (LLMs) designed
to address the limitations of generic models in healthcare settings. These
models are built on Llama3 architecture and fine-tuned using specialized
clinical data. They underwent multi-stage preference alignment to effectively
respond to natural prompts. While generic models are often preference-aligned
to avoid answering clinical queries as a precaution, Med42-v2 is specifically
trained to overcome this limitation, enabling its use in clinical settings.
Med42-v2 models demonstrate superior performance compared to the original
Llama3 models in both 8B and 70B parameter configurations and GPT-4 across
various medical benchmarks. These LLMs are developed to understand clinical
queries, perform reasoning tasks, and provide valuable assistance in clinical
environments. The models are now publicly available at
\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.

摘要：Med42-v2 引進了一套臨床大型語言模型 (LLM)，旨在解決醫療保健環境中通用模型的限制。這些模型建立在 Llama3 架構上，並使用專業臨床資料進行微調。它們經歷了多階段偏好調整，以有效回應自然提示。雖然通用模型通常偏好調整為避免預防性回答臨床查詢，但 Med42-v2 經過特別訓練以克服此限制，使其能夠在臨床環境中使用。與原始 Llama3 模型相比，Med42-v2 模型在 8B 和 70B 參數配置以及 GPT-4 中表現出優異的效能，橫跨各種醫療基準。這些 LLM 被開發用於理解臨床查詢、執行推理任務，並在臨床環境中提供有價值的協助。這些模型現在已於 \href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health} 公開提供。

##### **Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection**
2408.05836v1 by Varun Shiva Krishna Rupani, Velpooru Venkata Sai Thushar, Kondadi Tejith

Drowsiness detection is essential for improving safety in areas such as
transportation and workplace health. This study presents a real-time system
designed to detect drowsiness using the Eye Aspect Ratio (EAR) and facial
landmark detection techniques. The system leverages Dlibs pre-trained shape
predictor model to accurately detect and monitor 68 facial landmarks, which are
used to compute the EAR. By establishing a threshold for the EAR, the system
identifies when eyes are closed, indicating potential drowsiness. The process
involves capturing a live video stream, detecting faces in each frame,
extracting eye landmarks, and calculating the EAR to assess alertness. Our
experiments show that the system reliably detects drowsiness with high accuracy
while maintaining low computational demands. This study offers a strong
solution for real-time drowsiness detection, with promising applications in
driver monitoring and workplace safety. Future research will investigate
incorporating additional physiological and contextual data to further enhance
detection accuracy and reliability.

摘要：瞌睡檢測對於改善運輸和職場健康等領域的安全至關重要。本研究提出一個即時系統，旨在使用眼睛長寬比 (EAR) 和面部特徵檢測技術來檢測瞌睡。該系統利用 Dlibs 預先訓練的形狀預測模型來準確檢測和監控 68 個面部特徵，這些特徵用於計算 EAR。通過為 EAR 設定一個閾值，該系統可以識別眼睛閉上的時間，表明可能有瞌睡。這個過程包括擷取即時視訊串流、檢測每一幀中的臉部、提取眼睛特徵，並計算 EAR 來評估警覺性。我們的實驗表明，該系統可以可靠地檢測瞌睡，準確度高，同時保持低運算需求。本研究為即時瞌睡檢測提供了一個強大的解決方案，在駕駛員監控和職場安全方面有廣泛的應用前景。未來的研究將探討整合額外的生理和環境資料，以進一步提高檢測準確度和可靠性。

##### **TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling**
2408.05705v1 by Ruiquan Ge, Xiao Yu, Yifei Chen, Fan Jia, Shenghao Zhu, Guanyu Zhou, Yiyu Huang, Chenyan Zhang, Dong Zeng, Changmiao Wang, Qiegen Liu, Shanzhou Niu

Magnetic Resonance Imaging (MRI) has become essential in clinical diagnosis
due to its high resolution and multiple contrast mechanisms. However, the
relatively long acquisition time limits its broader application. To address
this issue, this study presents an innovative conditional guided diffusion
model, named as TC-KANRecon, which incorporates the Multi-Free U-KAN (MF-UKAN)
module and a dynamic clipping strategy. TC-KANRecon model aims to accelerate
the MRI reconstruction process through deep learning methods while maintaining
the quality of the reconstructed images. The MF-UKAN module can effectively
balance the tradeoff between image denoising and structure preservation.
Specifically, it presents the multi-head attention mechanisms and scalar
modulation factors, which significantly enhances the model's robustness and
structure preservation capabilities in complex noise environments. Moreover,
the dynamic clipping strategy in TC-KANRecon adjusts the cropping interval
according to the sampling steps, thereby mitigating image detail loss typically
caused by traditional cropping methods and enriching the visual features of the
images. Furthermore, the MC-Model module incorporates full-sampling k-space
information, realizing efficient fusion of conditional information, enhancing
the model's ability to process complex data, and improving the realism and
detail richness of reconstructed images. Experimental results demonstrate that
the proposed method outperforms other MRI reconstruction methods in both
qualitative and quantitative evaluations. Notably, TC-KANRecon method exhibits
excellent reconstruction results when processing high-noise, low-sampling-rate
MRI data. Our source code is available at
https://github.com/lcbkmm/TC-KANRecon.

摘要：磁振造影（MRI）由於其高解析度和多重對比機制，已成為臨床診斷中不可或缺的技術。然而，相對較長的擷取時間限制了其更廣泛的應用。為了解決這個問題，本研究提出了一個創新的條件引導擴散模型，稱為 TC-KANRecon，它結合了多自由 U-KAN（MF-UKAN）模組和一個動態裁剪策略。TC-KANRecon 模型旨在透過深度學習方法加速 MRI 重建過程，同時保持重建影像的品質。MF-UKAN 模組可以有效平衡影像去噪和結構保留之間的取捨。具體來說，它呈現多頭注意力機制和標量調製因子，這顯著增強了模型在複雜噪聲環境中的穩健性和結構保留能力。此外，TC-KANRecon 中的動態裁剪策略根據取樣步驟調整裁剪間隔，從而減輕傳統裁剪方法通常造成的影像細節損失，並豐富影像的視覺特徵。此外，MC-Model 模組結合了全取樣 k 空間資訊，實現條件資訊的有效融合，增強了模型處理複雜資料的能力，並改善了重建影像的真實感和細節豐富度。實驗結果表明，所提出的方法在定性和定量評估中都優於其他 MRI 重建方法。值得注意的是，TC-KANRecon 方法在處理高雜訊、低取樣率 MRI 資料時表現出優異的重建結果。我們的原始程式碼可在 https://github.com/lcbkmm/TC-KANRecon 取得。

##### **A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation**
2408.05692v1 by Koushik Biswas, Ridal Pal, Shaswat Patel, Debesh Jha, Meghana Karri, Amit Reza, Gorkem Durak, Alpay Medetalibeyoglu, Matthew Antalek, Yury Velichko, Daniela Ladner, Amir Borhani, Ulas Bagci

Accurately segmenting different organs from medical images is a critical
prerequisite for computer-assisted diagnosis and intervention planning. This
study proposes a deep learning-based approach for segmenting various organs
from CT and MRI scans and classifying diseases. Our study introduces a novel
technique integrating momentum within residual blocks for enhanced training
dynamics in medical image analysis. We applied our method in two distinct
tasks: segmenting liver, lung, & colon data and classifying abdominal pelvic CT
and MRI scans. The proposed approach has shown promising results, outperforming
state-of-the-art methods on publicly available benchmarking datasets. For
instance, in the lung segmentation dataset, our approach yielded significant
enhancements over the TransNetR model, including a 5.72% increase in dice
score, a 5.04% improvement in mean Intersection over Union (mIoU), an 8.02%
improvement in recall, and a 4.42% improvement in precision. Hence,
incorporating momentum led to state-of-the-art performance in both segmentation
and classification tasks, representing a significant advancement in the field
of medical imaging.

摘要：準確地從醫療影像中分割出不同的器官，是電腦輔助診斷和介入規劃的關鍵先決條件。本研究提出了一種基於深度學習的方法，用於分割 CT 和 MRI 掃描中的各種器官並對疾病進行分類。我們的研究引入了一種新技術，將動量整合到殘差塊中，以增強醫療影像分析中的訓練動態。我們將方法應用於兩個不同的任務：分割肝臟、肺臟和結腸資料，以及對腹部骨盆 CT 和 MRI 掃描進行分類。所提出的方法已顯示出有希望的結果，在公開的基準資料集上優於最先進的方法。例如，在肺部分割資料集中，我們的模型比 TransNetR 模型產生了顯著的提升，包括骰子係數增加了 5.72%，平均聯合交集 (mIoU) 提高了 5.04%，召回率提高了 8.02%，精度提高了 4.42%。因此，結合動量在分割和分類任務中都帶來了最先進的效能，代表了醫療影像領域的重大進展。

##### **Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale**
2408.05609v1 by Vindula Jayawardana, Baptiste Freydt, Ao Qu, Cameron Hickert, Edgar Sanchez, Catherine Tang, Mark Taylor, Blaine Leonard, Cathy Wu

The sheer scale and diversity of transportation make it a formidable sector
to decarbonize. Here, we consider an emerging opportunity to reduce carbon
emissions: the growing adoption of semi-autonomous vehicles, which can be
programmed to mitigate stop-and-go traffic through intelligent speed commands
and, thus, reduce emissions. But would such dynamic eco-driving move the needle
on climate change? A comprehensive impact analysis has been out of reach due to
the vast array of traffic scenarios and the complexity of vehicle emissions. We
address this challenge with large-scale scenario modeling efforts and by using
multi-task deep reinforcement learning with a carefully designed network
decomposition strategy. We perform an in-depth prospective impact assessment of
dynamic eco-driving at 6,011 signalized intersections across three major US
metropolitan cities, simulating a million traffic scenarios. Overall, we find
that vehicle trajectories optimized for emissions can cut city-wide
intersection carbon emissions by 11-22%, without harming throughput or safety,
and with reasonable assumptions, equivalent to the national emissions of Israel
and Nigeria, respectively. We find that 10% eco-driving adoption yields 25%-50%
of the total reduction, and nearly 70% of the benefits come from 20% of
intersections, suggesting near-term implementation pathways. However, the
composition of this high-impact subset of intersections varies considerably
across different adoption levels, with minimal overlap, calling for careful
strategic planning for eco-driving deployments. Moreover, the impact of
eco-driving, when considered jointly with projections of vehicle
electrification and hybrid vehicle adoption remains significant. More broadly,
this work paves the way for large-scale analysis of traffic externalities, such
as time, safety, and air quality, and the potential impact of solution
strategies.

摘要：<paragraph>運輸業的規模和多樣性使其成為一個難以脫碳的產業。在此，我們考慮一個新興的機會來減少碳排放：半自動車輛的採用日益增加，這些車輛可透過智慧型速度指令來編程以減少走走停停的交通，從而減少排放。但這種動態生態駕駛是否會對氣候變遷產生影響？由於交通狀況眾多且車輛排放複雜，因此無法進行全面的影響分析。我們透過大規模情境建模工作和使用多任務深度強化學習，以及精心設計的網路分解策略來應對這項挑戰。我們對美國三大都會城市 6,011 個有信號的交叉路口進行深入的前瞻性影響評估，模擬一百萬個交通狀況。總體而言，我們發現針對排放量最佳化的車輛軌跡可以減少 11-22% 的城市交叉路口碳排放，而不會損害吞吐量或安全性，且根據合理的假設，分別等於以色列和奈及利亞的國家排放量。我們發現 10% 的生態駕駛採用率會產生總減量的 25%-50%，而近 70% 的好處來自 20% 的交叉路口，這表明了近期的實施途徑。然而，這個高影響交叉路口子集的組成在不同的採用率之間變化很大，重疊性很小，這需要仔細的策略性規劃來進行生態駕駛部署。此外，生態駕駛的影響，在與車輛電氣化和混合動力車輛採用率的預測共同考量時，仍然顯著。更廣泛而言，這項工作為大規模分析交通外部性（例如時間、安全性和空氣品質）以及解決策略的潛在影響鋪平了道路。</paragraph>

##### **Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**
2408.05117v1 by Shouyue Liu, Jinkui Hao, Yonghuai Liu, Huazhu Fu, Xinyu Guo, Shuting Zhang, Yitian Zhao

Early detection of dementia, such as Alzheimer's disease (AD) or mild
cognitive impairment (MCI), is essential to enable timely intervention and
potential treatment. Accurate detection of AD/MCI is challenging due to the
high complexity, cost, and often invasive nature of current diagnostic
techniques, which limit their suitability for large-scale population screening.
Given the shared embryological origins and physiological characteristics of the
retina and brain, retinal imaging is emerging as a potentially rapid and
cost-effective alternative for the identification of individuals with or at
high risk of AD. In this paper, we present a novel PolarNet+ that uses retinal
optical coherence tomography angiography (OCTA) to discriminate early-onset AD
(EOAD) and MCI subjects from controls. Our method first maps OCTA images from
Cartesian coordinates to polar coordinates, allowing approximate sub-region
calculation to implement the clinician-friendly early treatment of diabetic
retinopathy study (ETDRS) grid analysis. We then introduce a multi-view module
to serialize and analyze the images along three dimensions for comprehensive,
clinically useful information extraction. Finally, we abstract the sequence
embedding into a graph, transforming the detection task into a general graph
classification problem. A regional relationship module is applied after the
multi-view module to excavate the relationship between the sub-regions. Such
regional relationship analyses validate known eye-brain links and reveal new
discriminative patterns.

摘要：早期偵測失智症，例如阿茲海默症 (AD) 或輕度認知障礙 (MCI)，對於及時介入和潛在治療至關重要。由於目前診斷技術的複雜性高、成本高，且常常具有侵入性，因此準確偵測 AD/MCI 極具挑戰性，這也限制了其用於大規模人群篩檢的適用性。考量到視網膜和腦部具有相同的胚胎起源和生理特性，視網膜影像正逐漸成為一種潛在的快速且具成本效益的替代方案，用於找出罹患 AD 或具有高風險的個人。在本文中，我們提出了一種創新的 PolarNet+，它使用視網膜光學相干斷層血管造影 (OCTA) 來區分早發性 AD (EOAD) 和 MCI 受試者與對照組。我們的做法首先將 OCTA 影像從笛卡爾坐標轉換為極坐標，讓近似子區域計算得以實作，進而執行對臨床醫師友善的糖尿病視網膜病變早期治療研究 (ETDRS) 格線分析。接著，我們引入一個多視圖模組，用於串列化並沿著三個向度分析影像，以進行全面的、臨床上有用的資訊萃取。最後，我們將序列嵌入抽象化為一個圖形，將偵測任務轉換為一個通用的圖形分類問題。在多視圖模組後應用區域關係模組，以探討子區域之間的關係。此類區域關係分析驗證了已知的視網膜與腦部關聯，並揭示了新的判別模式。

##### **RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**
2408.05074v1 by Sangjoon Park, Chan Woo Wee, Seo Hee Choi, Kyung Hwan Kim, Jee Suk Chang, Hong In Yoon, Ik Jae Lee, Yong Bae Kim, Jaeho Cho, Ki Chang Keum, Chang Geol Lee, Hwa Kyung Byun, Woong Sub Koom

Accurate patient selection is critical in radiotherapy (RT) to prevent
ineffective treatments. Traditional survival prediction models, relying on
structured data, often lack precision. This study explores the potential of
large language models (LLMs) to structure unstructured electronic health record
(EHR) data, thereby improving survival prediction accuracy through
comprehensive clinical information integration. Data from 34,276 patients
treated with RT at Yonsei Cancer Center between 2013 and 2023 were analyzed,
encompassing both structured and unstructured data. An open-source LLM was used
to structure the unstructured EHR data via single-shot learning, with its
performance compared against a domain-specific medical LLM and a smaller
variant. Survival prediction models were developed using statistical, machine
learning, and deep learning approaches, incorporating both structured and
LLM-structured data. Clinical experts evaluated the accuracy of the
LLM-structured data. The open-source LLM achieved 87.5% accuracy in structuring
unstructured EHR data without additional training, significantly outperforming
the domain-specific medical LLM, which reached only 35.8% accuracy. Larger LLMs
were more effective, particularly in extracting clinically relevant features
like general condition and disease extent, which closely correlated with
patient survival. Incorporating LLM-structured clinical features into survival
prediction models significantly improved accuracy, with the C-index of deep
learning models increasing from 0.737 to 0.820. These models also became more
interpretable by emphasizing clinically significant factors. This study shows
that general-domain LLMs, even without specific medical training, can
effectively structure large-scale unstructured EHR data, substantially
enhancing the accuracy and interpretability of clinical predictive models.

摘要：<paragraph>在放射治療中，準確的患者選擇至關重要，以防止無效的治療。傳統的存活預測模型依賴於結構化資料，通常缺乏精確度。本研究探討了大型語言模型 (LLM) 結構化非結構化電子健康記錄 (EHR) 資料的潛力，從而通過全面的臨床資訊整合來提高存活預測準確度。分析了 2013 年至 2023 年間在延世癌症中心接受放射治療的 34,276 名患者的資料，包括結構化和非結構化資料。使用開源 LLM 通過單次學習來結構化非結構化 EHR 資料，並將其效能與特定領域的醫療 LLM 和較小的變體進行比較。存活預測模型是使用統計、機器學習和深度學習方法開發的，結合了結構化和 LLM 結構化的資料。臨床專家評估了 LLM 結構化資料的準確性。開源 LLM 在不進行額外訓練的情況下，結構化非結構化 EHR 資料的準確度達到 87.5%，顯著優於特定領域的醫療 LLM，後者的準確度僅達到 35.8%。較大的 LLM 更有效，特別是在提取臨床相關特徵方面，例如一般狀況和疾病程度，這與患者存活率密切相關。將 LLM 結構化的臨床特徵納入存活預測模型顯著提高了準確性，深度學習模型的 C 指數從 0.737 提高到 0.820。這些模型也變得更具可解釋性，因為它們強調了臨床上重要的因素。本研究表明，即使沒有具體的醫療訓練，通用領域的 LLM 也可以有效地結構化大規模的非結構化 EHR 資料，從而顯著提高臨床預測模型的準確性和可解釋性。</paragraph>

##### **CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**
2408.04949v1 by Gianluca Carloni, Sotirios A Tsaftaris, Sara Colantonio

Due to domain shift, deep learning image classifiers perform poorly when
applied to a domain different from the training one. For instance, a classifier
trained on chest X-ray (CXR) images from one hospital may not generalize to
images from another hospital due to variations in scanner settings or patient
characteristics. In this paper, we introduce our CROCODILE framework, showing
how tools from causality can foster a model's robustness to domain shift via
feature disentanglement, contrastive learning losses, and the injection of
prior knowledge. This way, the model relies less on spurious correlations,
learns the mechanism bringing from images to prediction better, and outperforms
baselines on out-of-distribution (OOD) data. We apply our method to multi-label
lung disease classification from CXRs, utilizing over 750000 images from four
datasets. Our bias-mitigation method improves domain generalization and
fairness, broadening the applicability and reliability of deep learning models
for a safer medical image analysis. Find our code at:
https://github.com/gianlucarloni/crocodile.

摘要：由於領域轉換，深度學習圖像分類器在應用於與訓練不同的領域時表現不佳。例如，針對一家醫院的胸部 X 光（CXR）影像訓練的分類器，由於掃描儀設定或患者特徵的差異，可能無法概化到另一家醫院的影像。在本文中，我們介紹我們的 CROCODILE 框架，展示因果工具如何透過特徵解糾纏、對比學習損失和注入先驗知識來促進模型對領域轉換的穩健性。這樣一來，模型較不依賴虛假相關性，能更好地學習從影像到預測的機制，並在分佈外（OOD）資料上優於基線。我們將我們的模型應用於 CXR 的多標籤肺部疾病分類，利用來自四個資料集的超過 750,000 張影像。我們的偏差緩解方法改善了領域概化和公平性，擴大了深度學習模型在更安全醫學影像分析中的適用性和可靠性。在以下網址找到我們的程式碼：https://github.com/gianlucarloni/crocodile。

##### **Unleashing Artificial Cognition: Integrating Multiple AI Systems**
2408.04910v3 by Muntasir Adnan, Buddhi Gamage, Zhiwei Xu, Damith Herath, Carlos C. N. Kuhn

In this study, we present an innovative fusion of language models and query
analysis techniques to unlock cognition in artificial intelligence. Our system
seamlessly integrates a Chess engine with a language model, enabling it to
predict moves and provide strategic explanations. Leveraging a vector database
to achieve retrievable answer generation, our OpenSI AI system elucidates its
decision-making process, bridging the gap between raw computation and
human-like understanding. Our choice of Chess as the demonstration environment
underscores the versatility of our approach. Beyond Chess, our system holds
promise for diverse applications, from medical diagnostics to financial
forecasting.

摘要：在本次研究中，我們提出了語言模型和查詢分析技術的創新融合，以解鎖人工智慧中的認知。我們的系統將西洋棋引擎與語言模型無縫整合，使其能夠預測棋步並提供策略說明。我們的 OpenSI AI 系統利用向量資料庫來達成可擷取答案的產生，闡明其決策過程，縮小了原始運算與類人理解之間的差距。我們選擇西洋棋作為示範環境，突顯了我們方法的多功能性。除了西洋棋之外，我們的系統有望應用於各種領域，從醫療診斷到財務預測。

##### **Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**
2408.04849v1 by Kai Jiang, Honghao Yang, Yuexian Wang, Qianru Chen, Yiming Luo

The mental health assessment of middle school students has always been one of
the focuses in the field of education. This paper introduces a new ensemble
learning network based on BERT, employing the concept of enhancing model
performance by integrating multiple classifiers. We trained a range of
BERT-based learners, which combined using the majority voting method. We
collect social network text data of middle school students through China's
Weibo and apply the method to the task of classifying emotional tendencies in
middle school students' social network texts. Experimental results suggest that
the ensemble learning network has a better performance than the base model and
the performance of the ensemble learning model, consisting of three
single-layer BERT models, is barely the same as a three-layer BERT model but
requires 11.58% more training time. Therefore, in terms of balancing prediction
effect and efficiency, the deeper BERT network should be preferred for
training. However, for interpretability, network ensembles can provide
acceptable solutions.

摘要：中學生心理健康評估一直是教育領域的關注重點之一。本文介紹了一個基於 BERT 的新集成學習網路，採用整合多個分類器的概念來提升模型效能。我們訓練了一系列基於 BERT 的學習器，並使用多數決投票法進行組合。我們透過中國微博收集中學生的社群網路文字資料，並將此方法應用於分類中學生社群網路文字的情緒傾向的任務中。實驗結果表明，集成學習網路的效能優於基礎模型，且由三個單層 BERT 模型組成的集成學習模型的效能與三層 BERT 模型幾乎相同，但訓練時間卻多了 11.58%。因此，在平衡預測效果和效率方面，應優先考慮較深的 BERT 網路進行訓練。然而，對於可解釋性而言，網路集成可以提供可接受的解決方案。

##### **Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**
2408.04491v1 by Vandan Gorade, Onkar Susladkar, Gorkem Durak, Elif Keles, Ertugrul Aktas, Timurhan Cebeci, Alpay Medetalibeyoglu, Daniela Ladner, Debesh Jha, Ulas Bagci

Liver cirrhosis, a leading cause of global mortality, requires precise
segmentation of ROIs for effective disease monitoring and treatment planning.
Existing segmentation models often fail to capture complex feature interactions
and generalize across diverse datasets. To address these limitations, we
propose a novel synergistic theory that leverages complementary latent spaces
for enhanced feature interaction modeling. Our proposed architecture,
nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes
and features auto-configured training. This approach captures both fine-grained
and coarse features, enabling effective modeling of intricate feature
interactions. We empirically validated nnSynergyNet3D on a private dataset of
628 high-resolution T1 abdominal MRI scans from 339 patients. Our model
outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot
testing on healthy liver CT scans from the public LiTS dataset demonstrated
superior cross-modal generalization capabilities. These results highlight the
potential of synergistic latent space models to improve segmentation accuracy
and robustness, thereby enhancing clinical workflows by ensuring consistency
across CT and MRI modalities.

摘要：肝硬化是全球死亡的主要原因，需要对 ROI 进行精确分割，以进行有效的疾病监测和治疗计划。现有的分割模型通常无法捕捉复杂的特征交互，并在不同的数据集上进行泛化。为了解决这些限制，我们提出了一种新颖的协同理论，该理论利用互补的潜在空间来增强特征交互建模。我们提出的架构 nnSynergyNet3D 集成了连续和离散的潜在空间，用于 3D 体积，并具有自动配置的训练。这种方法捕捉到了细粒度和粗粒度特征，从而能够有效地对复杂的特征交互进行建模。我们根据 339 名患者的 628 个高分辨率 T1 腹部 MRI 扫描的私有数据集对 nnSynergyNet3D 进行了实证验证。我们的模型比基线 nnUNet3D 的性能提高了大约 2%。此外，在来自公共 LiTS 数据集的健康肝脏 CT 扫描上进行零样本测试证明了其卓越的跨模态泛化能力。这些结果突出了协同潜在空间模型在提高分割精度和鲁棒性方面的潜力，从而通过确保 CT 和 MRI 模态的一致性来增强临床工作流程。

##### **Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review**
2408.05249v1 by Anshu Ankolekar, Sebastian Boie, Maryam Abdollahyan, Emanuela Gadaleta, Seyed Alireza Hasheminasab, Guang Yang, Charles Beauville, Nikolaos Dikaios, George Anthony Kastis, Michael Bussmann, Sara Khalid, Hagen Kruger, Philippe Lambin, Giorgos Papanastasiou

Federated Learning (FL) has emerged as a promising solution to address the
limitations of centralised machine learning (ML) in oncology, particularly in
overcoming privacy concerns and harnessing the power of diverse, multi-center
data. This systematic review synthesises current knowledge on the
state-of-the-art FL in oncology, focusing on breast, lung, and prostate cancer.
Distinct from previous surveys, our comprehensive review critically evaluates
the real-world implementation and impact of FL on cancer care, demonstrating
its effectiveness in enhancing ML generalisability, performance and data
privacy in clinical settings and data. We evaluated state-of-the-art advances
in FL, demonstrating its growing adoption amid tightening data privacy
regulations. FL outperformed centralised ML in 15 out of the 25 studies
reviewed, spanning diverse ML models and clinical applications, and
facilitating integration of multi-modal information for precision medicine.
Despite the current challenges identified in reproducibility, standardisation
and methodology across studies, the demonstrable benefits of FL in harnessing
real-world data and addressing clinical needs highlight its significant
potential for advancing cancer research. We propose that future research should
focus on addressing these limitations and investigating further advanced FL
methods, to fully harness data diversity and realise the transformative power
of cutting-edge FL in cancer care.

摘要：聯邦學習 (FL) 已成為了解決腫瘤學中集中式機器學習 (ML) 限制的有前途的解決方案，特別是在克服隱私問題和利用多中心異質資料的力量方面。這項系統性回顧綜合了腫瘤學中最新 FL 的現有知識，重點關注乳癌、肺癌和前列腺癌。與先前的調查不同，我們的全面回顧批判性地評估了 FL 在癌症照護中的實際執行和影響，證明了它在增強 ML 的概括性、效能和臨床環境和資料中的資料隱私方面的有效性。我們評估了 FL 的最新進展，證明了它在日益嚴格的資料隱私法規中獲得越來越廣泛的採用。在所回顧的 25 項研究中，FL 在 15 項研究中優於集中式 ML，涵蓋了多種 ML 模型和臨床應用，並促進了多模式資訊整合以進行精準醫療。儘管在各項研究中發現了再現性、標準化和方法方面的現有挑戰，但 FL 在利用真實世界資料和解決臨床需求方面已展現出的好處突顯了其在推進癌症研究方面的巨大潛力。我們建議未來的研究應重點解決這些限制，並進一步研究先進的 FL 方法，以充分利用資料的多樣性，並實現尖端 FL 在癌症照護中的轉化力量。

##### **Non-maximizing policies that fulfill multi-criterion aspirations in expectation**
2408.04385v1 by Simon Dima, Simon Fischer, Jobst Heitzig, Joss Oliver

In dynamic programming and reinforcement learning, the policy for the
sequential decision making of an agent in a stochastic environment is usually
determined by expressing the goal as a scalar reward function and seeking a
policy that maximizes the expected total reward. However, many goals that
humans care about naturally concern multiple aspects of the world, and it may
not be obvious how to condense those into a single reward function.
Furthermore, maximization suffers from specification gaming, where the obtained
policy achieves a high expected total reward in an unintended way, often taking
extreme or nonsensical actions.
  Here we consider finite acyclic Markov Decision Processes with multiple
distinct evaluation metrics, which do not necessarily represent quantities that
the user wants to be maximized. We assume the task of the agent is to ensure
that the vector of expected totals of the evaluation metrics falls into some
given convex set, called the aspiration set. Our algorithm guarantees that this
task is fulfilled by using simplices to approximate feasibility sets and
propagate aspirations forward while ensuring they remain feasible. It has
complexity linear in the number of possible state-action-successor triples and
polynomial in the number of evaluation metrics. Moreover, the explicitly
non-maximizing nature of the chosen policy and goals yields additional degrees
of freedom, which can be used to apply heuristic safety criteria to the choice
of actions. We discuss several such safety criteria that aim to steer the agent
towards more conservative behavior.

摘要：在動態規劃和強化學習中，代理人在隨機環境中進行順序決策的策略通常通過將目標表達為標量獎勵函數並尋求最大化預期總獎勵的策略來確定。然而，人類關心的許多目標自然涉及世界的多個方面，並且可能並不清楚如何將這些目標濃縮成單一的獎勵函數。此外，最大化會受到規範博弈的影響，其中獲得的策略以意外的方式實現了很高的預期總獎勵，通常採取極端或荒謬的行動。
在這裡，我們考慮具有多個不同評估指標的有限無環馬可夫決策過程，這些指標不一定表示用戶希望最大化的數量。我們假設代理人的任務是確保評估指標預期總量的向量落入某個給定的凸集，稱為願望集。我們的演算法保證通過使用單形來逼近可行集並在確保可行性的同時向前傳播願望來完成此任務。它的複雜度與可能的狀態-動作-後繼三元組的數量呈線性關係，與評估指標的數量呈多項式關係。此外，所選策略和目標的顯式非最大化性質產生了額外的自由度，可用於將啟發式安全準則應用於動作的選擇。我們討論了幾個這樣的安全準則，旨在引導代理人採取更保守的行為。

##### **AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**
2408.04281v1 by Mugheez Asif, Abdul Manan, Abdul Moiz ur Rehman, Mamoona Naveed Asghar, Muhammad Umair

In today's contemporary digital landscape, chatbots have become indispensable
tools across various sectors, streamlining customer service, providing personal
assistance, automating routine tasks, and offering health advice. However,
their potential remains underexplored in the realm of network security,
particularly for intrusion detection. To bridge this gap, we propose an
architecture chatbot specifically designed to enhance security within edge
networks specifically for intrusion detection. Leveraging advanced machine
learning algorithms, this chatbot will monitor network traffic to identify and
mitigate potential intrusions. By securing the network environment using an
edge network managed by a Raspberry Pi module and ensuring ethical user consent
promoting transparency and trust, this innovative solution aims to safeguard
sensitive data and maintain a secure workplace, thereby addressing the growing
need for robust network security measures in the digital age.

摘要：在當今的現代數位環境中，聊天機器人已成為各個產業不可或缺的工具，簡化客戶服務、提供個人協助、自動化例行工作並提供健康建議。然而，它們在網路安全領域的潛力仍未得到充分探索，特別是在入侵偵測方面。為了彌補這個差距，我們提出了一種專門設計用於增強邊緣網路內部安全性的架構聊天機器人，特別是用於入侵偵測。透過利用先進的機器學習演算法，此聊天機器人將監控網路流量以識別和減輕潛在入侵。透過使用由 Raspberry Pi 模組管理的邊緣網路來保護網路環境，並確保合乎道德的使用者同意以促進透明度和信任，這個創新的解決方案旨在保護敏感資料並維護一個安全的工作場所，從而滿足數位時代對強大網路安全措施日益增長的需求。

##### **Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications**
2408.04680v1 by Philipp Zagar, Vishnu Ravi, Lauren Aalami, Stephan Krusche, Oliver Aalami, Paul Schmiedmayer

The ability of large language models (LLMs) to transform, interpret, and
comprehend vast quantities of heterogeneous data presents a significant
opportunity to enhance data-driven care delivery. However, the sensitive nature
of protected health information (PHI) raises valid concerns about data privacy
and trust in remote LLM platforms. In addition, the cost associated with
cloud-based artificial intelligence (AI) services continues to impede
widespread adoption. To address these challenges, we propose a shift in the LLM
execution environment from opaque, centralized cloud providers to a
decentralized and dynamic fog computing architecture. By executing open-weight
LLMs in more trusted environments, such as the user's edge device or a fog
layer within a local network, we aim to mitigate the privacy, trust, and
financial challenges associated with cloud-based LLMs. We further present
SpeziLLM, an open-source framework designed to facilitate rapid and seamless
leveraging of different LLM execution layers and lowering barriers to LLM
integration in digital health applications. We demonstrate SpeziLLM's broad
applicability across six digital health applications, showcasing its
versatility in various healthcare settings.

摘要：大型語言模型（LLM）轉換、詮釋和理解大量異質資料的能力，為提升資料驅動的照護提供顯著的契機。然而，受保護健康資訊（PHI）的敏感性質引發了對資料隱私和對遠端 LLM 平台信任的正當疑慮。此外，與雲端人工智慧（AI）服務相關的成本持續阻礙廣泛採用。為了解決這些挑戰，我們建議將 LLM 執行環境從不透明的集中式雲端供應商轉移到分散式動態霧運算架構。透過在更受信任的環境中執行開放權重的 LLM，例如使用者的邊緣裝置或區域網路內的霧層，我們旨在減輕與雲端 LLM 相關的隱私、信任和財務挑戰。我們進一步提出 SpeziLLM，一個開放原始碼架構，旨在促進快速且無縫地利用不同的 LLM 執行層，並降低 LLM 整合在數位健康應用程式的障礙。我們展示了 SpeziLLM 在六個數位健康應用程式中的廣泛適用性，展示了其在各種醫療保健環境中的多功能性。

##### **The Data Addition Dilemma**
2408.04154v1 by Judy Hanwen Shen, Inioluwa Deborah Raji, Irene Y. Chen

In many machine learning for healthcare tasks, standard datasets are
constructed by amassing data across many, often fundamentally dissimilar,
sources. But when does adding more data help, and when does it hinder progress
on desired model outcomes in real-world settings? We identify this situation as
the \textit{Data Addition Dilemma}, demonstrating that adding training data in
this multi-source scaling context can at times result in reduced overall
accuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.
We find that this possibly arises from an empirically observed trade-off
between model performance improvements due to data scaling and model
deterioration from distribution shift. We thus establish baseline strategies
for navigating this dilemma, introducing distribution shift heuristics to guide
decision-making on which data sources to add in data scaling, in order to yield
the expected model performance improvements. We conclude with a discussion of
the required considerations for data collection and suggestions for studying
data composition and scale in the age of increasingly larger models.

摘要：在許多醫療保健任務的機器學習中，標準資料集是透過收集來自許多通常根本不同的來源的資料而建構的。但是，何時新增更多資料有幫助，而何時會阻礙在現實世界設定中達成預期的模型成果？我們將此情況認定為「資料新增困境」，證明在此多來源擴充的背景下新增訓練資料，有時可能會導致整體準確度降低、不確定的公平性結果，以及最差子群體效能降低。我們發現這可能是由於資料擴充導致的模型效能提升與分配轉移導致的模型劣化之間的經驗性權衡所致。因此，我們建立了應對此困境的基本策略，引入了分配轉移啟發法，以指導有關在資料擴充中新增哪些資料來源的決策制定，以產生預期的模型效能提升。我們最後討論了資料收集所需的考量因素，並建議研究資料組成和規模在模型規模日益擴大的時代。

##### **Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**
2408.04138v1 by Haoran Yu, Chang Yu, Zihan Wang, Dongxian Zou, Hao Qin

In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.

摘要：近年來，大型語言模型 (LLM) 在醫療保健中的應用已展現出顯著的希望，可改善醫療知識的可及性和傳播。本文針對在 MedQuAD 醫療問答資料集上訓練的各種 LLM 進行詳細研究，重點在於找出提供準確醫療資訊最有效的模型。在測試的模型中，Sentence-t5 結合 Mistral 7B 表現優異，達到 0.762 的精準度分數。此模型的增強功能歸功於其先進的預訓練技術、強大的架構和有效的提示建構方法。Sentence-t5 + Mistral 7B 模型藉由運用這些優勢，在理解和產生精確的醫療答案方面表現出色。我們的研究結果突顯了將複雜的 LLM 整合到醫療背景中的潛力，以促進有效率且準確的醫療知識擷取，進而顯著提升病患教育和支持。

##### **Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**
2408.04121v1 by Panagiotis Fytas, Anna Breger, Ian Selby, Simon Baker, Shahab Shahipasand, Anna Korhonen

Developing imaging models capable of detecting pathologies from chest X-rays
can be cost and time-prohibitive for large datasets as it requires supervision
to attain state-of-the-art performance. Instead, labels extracted from
radiology reports may serve as distant supervision since these are routinely
generated as part of clinical practice. Despite their widespread use, current
rule-based methods for label extraction rely on extensive rule sets that are
limited in their robustness to syntactic variability. To alleviate these
limitations, we introduce RadPert, a rule-based system that integrates an
uncertainty-aware information schema with a streamlined set of rules, enhancing
performance. Additionally, we have developed RadPrompt, a multi-turn prompting
strategy that leverages RadPert to bolster the zero-shot predictive
capabilities of large language models, achieving a statistically significant
improvement in weighted average F1 score over GPT-4 Turbo. Most notably,
RadPrompt surpasses both its underlying models, showcasing the synergistic
potential of LLMs with rule-based models. We have evaluated our methods on two
English Corpora: the MIMIC-CXR gold-standard test set and a gold-standard
dataset collected from the Cambridge University Hospitals.

摘要：開發出能夠從胸部 X 光檢測病理的影像模型，對於大型資料集來說，在成本和時間上都可能是禁止的，因為它需要監督才能達到最先進的效能。相反地，從放射科報告中提取的標籤可以用作遠端監督，因為這些標籤通常作為臨床實務的一部分而產生。儘管廣泛使用，但目前用於標籤提取的基於規則的方法依賴於廣泛的規則集，其對語法變異的健壯性有限。為了減輕這些限制，我們引入了 RadPert，這是一個基於規則的系統，它將一個不確定性感知資訊架構與一組簡化的規則整合在一起，從而增強了效能。此外，我們還開發了 RadPrompt，這是一個多輪提示策略，它利用 RadPert 來加強大型語言模型的零次學習預測能力，在加權平均 F1 分數上實現了相對於 GPT-4 Turbo 的統計顯著改進。最值得注意的是，RadPrompt 超越了其基礎模型，展示了基於規則的模型與 LLM 的協同潛力。我們已在兩個英文語料庫上評估了我們的方法：MIMIC-CXR 黃金標準測試集和從劍橋大學醫院收集的黃金標準資料集。

##### **Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**
2408.04026v1 by Joseph Cameron, Jiaee Cheong, Micol Spitale, Hatice Gunes

Social agents and robots are increasingly being used in wellbeing settings.
However, a key challenge is that these agents and robots typically rely on
machine learning (ML) algorithms to detect and analyse an individual's mental
wellbeing. The problem of bias and fairness in ML algorithms is becoming an
increasingly greater source of concern. In concurrence, existing literature has
also indicated that mental health conditions can manifest differently across
genders and cultures. We hypothesise that the representation of features
(acoustic, textual, and visual) and their inter-modal relations would vary
among subjects from different cultures and genders, thus impacting the
performance and fairness of various ML models. We present the very first
evaluation of multimodal gender fairness in depression manifestation by
undertaking a study on two different datasets from the USA and China. We
undertake thorough statistical and ML experimentation and repeat the
experiments for several different algorithms to ensure that the results are not
algorithm-dependent. Our findings indicate that though there are differences
between both datasets, it is not conclusive whether this is due to the
difference in depression manifestation as hypothesised or other external
factors such as differences in data collection methodology. Our findings
further motivate a call for a more consistent and culturally aware data
collection process in order to address the problem of ML bias in depression
detection and to promote the development of fairer agents and robots for
wellbeing.

摘要：社群代理人和機器人在幸福感設定中正越來越廣泛地被使用。
然而，一個關鍵的挑戰是這些代理人和機器人通常依賴機器學習 (ML) 演算法來偵測和分析個人心理健康。ML 演算法中的偏差和公平性問題正成為越來越大的關注來源。同時，現有文獻也指出心理健康狀況會在不同性別和文化中以不同的方式顯現。我們假設特徵（聲音、文字和視覺）的呈現及其跨模態關係會因不同文化和性別的受試者而異，從而影響各種 ML 模型的效能和公平性。我們透過對來自美國和中國的兩個不同資料集進行研究，提出首次對憂鬱症表現的多模態性別公平性評估。我們進行徹底的統計和 ML 實驗，並針對多種不同的演算法重複實驗，以確保結果不依賴於演算法。我們的研究結果表明，儘管兩個資料集之間存在差異，但無法確定這是否是由於假設的憂鬱症表現差異或其他外部因素（例如資料收集方法的差異）所造成。我們的研究結果進一步呼籲採用更一致且具有文化意識的資料收集程序，以解決憂鬱症偵測中的 ML 偏差問題，並促進開發更公平的代理人和機器人，以提升幸福感。

##### **Inter-Series Transformer: Attending to Products in Time Series Forecasting**
2408.03872v1 by Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni

Time series forecasting is an important task in many fields ranging from
supply chain management to weather forecasting. Recently, Transformer neural
network architectures have shown promising results in forecasting on common
time series benchmark datasets. However, application to supply chain demand
forecasting, which can have challenging characteristics such as sparsity and
cross-series effects, has been limited.
  In this work, we explore the application of Transformer-based models to
supply chain demand forecasting. In particular, we develop a new
Transformer-based forecasting approach using a shared, multi-task per-time
series network with an initial component applying attention across time series,
to capture interactions and help address sparsity. We provide a case study
applying our approach to successfully improve demand prediction for a medical
device manufacturing company. To further validate our approach, we also apply
it to public demand forecasting datasets as well and demonstrate competitive to
superior performance compared to a variety of baseline and state-of-the-art
forecast methods across the private and public datasets.

摘要：時間序列預測在許多領域中都是一項重要的任務，從供應鏈管理到天氣預測都有涉及。最近，Transformer 神經網路架構在常見時間序列基準資料集的預測中展現了令人滿意的成果。然而，應用於供應鏈需求預測的範疇受到限制，因為供應鏈需求預測可能具有稀疏性和跨系列效應等具挑戰性的特徵。
  在這項工作中，我們探討了將基於 Transformer 的模型應用於供應鏈需求預測。特別是，我們開發了一種新的基於 Transformer 的預測方法，使用一個共用的、每個時間序列的多任務網路，並在初始元件中套用跨時間序列的注意力，以擷取互動並協助解決稀疏性問題。我們提供了一個案例研究，應用我們的做法成功改善了一家醫療器材製造公司的需求預測。為了進一步驗證我們的做法，我們也將其應用於公開的需求預測資料集，並證明與各種基線和最先進的預測方法相比，在私有和公開資料集中的表現具有競爭力或優於這些方法。

##### **HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**
2408.03648v1 by Juho Jung, Chaewon Kang, Jeewoo Yoon, Seungbae Kim, Jinyoung Han

The utilization of automated depression detection significantly enhances
early intervention for individuals experiencing depression. Despite numerous
proposals on automated depression detection using recorded clinical interview
videos, limited attention has been paid to considering the hierarchical
structure of the interview questions. In clinical interviews for diagnosing
depression, clinicians use a structured questionnaire that includes routine
baseline questions and follow-up questions to assess the interviewee's
condition. This paper introduces HiQuE (Hierarchical Question Embedding
network), a novel depression detection framework that leverages the
hierarchical relationship between primary and follow-up questions in clinical
interviews. HiQuE can effectively capture the importance of each question in
diagnosing depression by learning mutual information across multiple
modalities. We conduct extensive experiments on the widely-used clinical
interview data, DAIC-WOZ, where our model outperforms other state-of-the-art
multimodal depression detection models and emotion recognition models,
showcasing its clinical utility in depression detection.

摘要：自動憂鬱症偵測的利用顯著提升了憂鬱症患者的早期介入。儘管有許多使用錄製臨床訪談影片的自動憂鬱症偵測提案，但對於考量訪談問題的階層結構這方面卻鮮少關注。在用於診斷憂鬱症的臨床訪談中，臨床醫師會使用包含例行基準問題和追蹤問題的結構化問卷來評估受訪者的狀況。本文介紹了 HiQuE（階層式問題嵌入網路），這是一種新穎的憂鬱症偵測架構，它利用了臨床訪談中主要問題和追蹤問題之間的階層關係。HiQuE 能夠透過學習多種方式之間的互惠資訊，有效地擷取每個問題在憂鬱症診斷中的重要性。我們在廣泛使用的臨床訪談資料 DAIC-WOZ 上進行了廣泛的實驗，我們的模型優於其他最先進的多模態憂鬱症偵測模型和情緒辨識模型，展示了其在憂鬱症偵測中的臨床效用。

##### **Improving the quality of Persian clinical text with a novel spelling correction system**
2408.03622v1 by Seyed Mohammad Sadegh Dashti, Seyedeh Fatemeh Dashti

Background: The accuracy of spelling in Electronic Health Records (EHRs) is a
critical factor for efficient clinical care, research, and ensuring patient
safety. The Persian language, with its abundant vocabulary and complex
characteristics, poses unique challenges for real-word error correction. This
research aimed to develop an innovative approach for detecting and correcting
spelling errors in Persian clinical text.
  Methods: Our strategy employs a state-of-the-art pre-trained model that has
been meticulously fine-tuned specifically for the task of spelling correction
in the Persian clinical domain. This model is complemented by an innovative
orthographic similarity matching algorithm, PERTO, which uses visual similarity
of characters for ranking correction candidates.
  Results: The evaluation of our approach demonstrated its robustness and
precision in detecting and rectifying word errors in Persian clinical text. In
terms of non-word error correction, our model achieved an F1-Score of 90.0%
when the PERTO algorithm was employed. For real-word error detection, our model
demonstrated its highest performance, achieving an F1-Score of 90.6%.
Furthermore, the model reached its highest F1-Score of 91.5% for real-word
error correction when the PERTO algorithm was employed.
  Conclusions: Despite certain limitations, our method represents a substantial
advancement in the field of spelling error detection and correction for Persian
clinical text. By effectively addressing the unique challenges posed by the
Persian language, our approach paves the way for more accurate and efficient
clinical documentation, contributing to improved patient care and safety.
Future research could explore its use in other areas of the Persian medical
domain, enhancing its impact and utility.

摘要：背景：電子病歷 (EHR) 中拼寫的準確性是有效臨床照護、研究和確保患者安全性的關鍵因素。波斯語擁有豐富的詞彙和複雜的特徵，對真實世界的錯誤更正提出了獨特的挑戰。本研究旨在開發一種創新的方法來偵測和更正波斯語臨床文本中的拼寫錯誤。
方法：我們的策略採用了最先進的預訓練模型，該模型經過精心微調，專門用於波斯語臨床領域中的拼寫更正任務。此模型由創新的正字法相似性匹配演算法 PERTO 補充，該演算法使用字元的視覺相似性來對更正候選項進行排名。
結果：對我們方法的評估證明了其在偵測和糾正波斯語臨床文本中的文字錯誤方面的穩健性和準確性。在非文字錯誤更正方面，當使用 PERTO 演算法時，我們的模型實現了 90.0% 的 F1 分數。對於真實世界的錯誤偵測，我們的模型展示了其最高的效能，實現了 90.6% 的 F1 分數。此外，當使用 PERTO 演算法時，該模型達到了其最高的 F1 分數 91.5%，用於真實世界的錯誤更正。
結論：儘管存在某些限制，但我們的模型代表了波斯語臨床文本拼寫錯誤偵測和更正領域的重大進展。透過有效解決波斯語所帶來的獨特挑戰，我們的做法為更準確和有效的臨床文件鋪路，有助於改善患者照護和安全性。未來的研究可以探討其在波斯語醫學領域其他領域的應用，以增強其影響力和實用性。

##### **Identifying treatment response subgroups in observational time-to-event data**
2408.03463v1 by Vincent Jeanselme, Chang Ho Yoon, Fabian Falck, Brian Tom, Jessica Barrett

Identifying patient subgroups with different treatment responses is an
important task to inform medical recommendations, guidelines, and the design of
future clinical trials. Existing approaches for subgroup analysis primarily
focus on Randomised Controlled Trials (RCTs), in which treatment assignment is
randomised. Furthermore, the patient cohort of an RCT is often constrained by
cost, and is not representative of the heterogeneity of patients likely to
receive treatment in real-world clinical practice. Therefore, when applied to
observational studies, such approaches suffer from significant statistical
biases because of the non-randomisation of treatment. Our work introduces a
novel, outcome-guided method for identifying treatment response subgroups in
observational studies. Our approach assigns each patient to a subgroup
associated with two time-to-event distributions: one under treatment and one
under control regime. It hence positions itself in between individualised and
average treatment effect estimation. The assumptions of our model result in a
simple correction of the statistical bias from treatment non-randomisation
through inverse propensity weighting. In experiments, our approach
significantly outperforms the current state-of-the-art method for
outcome-guided subgroup analysis in both randomised and observational treatment
regimes.

摘要：識別具有不同治療反應的患者子群是為醫療建議、指南和未來臨床試驗的設計提供資訊的一項重要任務。現有的子群分析方法主要集中於隨機對照試驗 (RCT)，其中治療分配是隨機的。此外，RCT 的患者群體通常受到成本的限制，且無法代表在現實世界臨床實務中可能接受治療的患者異質性。因此，當應用於觀察性研究時，此類方法會因治療的非隨機化而產生顯著的統計偏差。我們的研究引入了一種新的、結果導向的方法，用於識別觀察性研究中的治療反應子群。我們的做法是將每個患者分配到一個子群，該子群與兩個事件發生時間分配相關：一個在治療下，另一個在對照機制下。因此，它介於個別化和平均治療效果估計之間。我們模型的假設導致通過逆向傾向加權對來自治療非隨機化的統計偏差進行簡單校正。在實驗中，我們的做法在隨機和觀察性治療機制中都顯著優於當前最先進的結果導向子群分析方法。

##### **Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**
2408.03405v1 by Lucia Gordon, Esther Rolf, Milind Tambe

Stochastic multi-agent multi-armed bandits typically assume that the rewards
from each arm follow a fixed distribution, regardless of which agent pulls the
arm. However, in many real-world settings, rewards can depend on the
sensitivity of each agent to their environment. In medical screening, disease
detection rates can vary by test type; in preference matching, rewards can
depend on user preferences; and in environmental sensing, observation quality
can vary across sensors. Since past work does not specify how to allocate
agents of heterogeneous but known sensitivity of these types in a stochastic
bandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates
information from diverse agents. In doing so, we address the joint challenges
of (i) aggregating the rewards, which follow different distributions for each
agent-arm pair, and (ii) coordinating the assignments of agents to arms.
Min-Width facilitates efficient collaboration among heterogeneous agents,
exploiting the known structure in the agents' reward functions to weight their
rewards accordingly. We analyze the regret of Min-Width and conduct
pseudo-synthetic and fully synthetic experiments to study the performance of
different levels of information sharing. Our results confirm that the gains to
modeling agent heterogeneity tend to be greater when the sensitivities are more
varied across agents, while combining more information does not always improve
performance.

摘要：隨機多智能體多臂賭徒通常假設每個手臂的回報遵循固定分佈，無論哪個智能體拉動手臂。然而，在許多真實世界設定中，回報可能取決於每個智能體對其環境的敏感度。在醫學篩檢中，疾病檢測率會因測試類型而異；在偏好匹配中，回報可能取決於使用者偏好；在環境感測中，觀察品質可能因感測器而異。由於過去的工作未說明如何配置這些類型異質但已知敏感度的智能體在隨機賭徒設定中，我們引入一種 UCB 風格演算法，Min-Width，它會彙總來自不同智能體的資訊。在這樣做的過程中，我們解決了 (i) 彙總回報的共同挑戰，這些回報遵循每個智能體手臂配對的不同分佈，以及 (ii) 協調將智能體指定給手臂。Min-Width 促進異質智能體之間的有效協作，利用智能體回報函數中的已知結構來適當地加權其回報。我們分析 Min-Width 的遺憾，並進行偽合成和完全合成實驗來研究不同層級資訊共享的效能。我們的結果證實，當敏感度在不同智能體間差異較大時，對智能體異質性建模的收益往往較高，而結合更多資訊並不總是會改善效能。

##### **MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**
2408.03358v1 by Wenqi Zhu, Yinghua Fu, Ze Wang

Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.
Accurately detecting AD, especially in the early stage, represents a high
research priority. AD is characterized by progressive cognitive impairments
that are related to alterations in brain functional connectivity (FC). Based on
this association, many studies have been published over the decades using FC
and machine learning to differentiate AD from healthy aging. The most recent
development in this detection method highlights the use of graph neural network
(GNN) as the brain functionality analysis. In this paper, we proposed a stack
of spatio-temporal feature extraction and graph generation based AD
classification model using resting state fMRI. The proposed multi-level
generated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)
contains a multi-graph generation block and a GCN prediction block. The
multi-graph generation block consists of a hierarchy of spatio-temporal feature
extraction layers for extracting spatio-temporal rsfMRI features at different
depths and building the corresponding connectomes. The GCN prediction block
takes the learned multi-level connectomes to build and optimize GCNs at each
level and concatenates the learned graphical features as the final predicting
features for AD classification. Through independent cohort validations, MLC-GCN
shows better performance for differentiating MCI, AD, and normal aging than
state-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also
showed high explainability in terms of learning clinically reasonable
connectome node and connectivity features from two independent datasets. While
we only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN
based outcome prediction strategy is valid for other diseases or clinical
outcomes.

摘要：阿茲海默症 (AD) 是一種目前無法治癒的神經退化性疾病。
準確地偵測 AD，特別是在早期階段，代表一項高度的研究優先事項。AD 的特徵是會逐漸認知功能受損，這與腦部功能連接性 (FC) 的改變有關。基於這種關聯，在過去的數十年中，許多研究已使用 FC 和機器學習來區分 AD 和健康老化。這種偵測方法的最新發展，突顯了使用圖神經網路 (GNN) 作為腦部功能分析。在本文中，我們提出了一個堆疊的時空特徵萃取和圖形生成，基於 AD 分類模型，使用靜止狀態 fMRI。所提出的多層級生成連接組 (MLC) 基於圖形卷積網路 (GCN) (MLC-GCN) 包含一個多圖形生成區塊和一個 GCN 預測區塊。多圖形生成區塊包含一個時空特徵萃取層的階層，用於萃取不同深度下的時空 rsfMRI 特徵，並建立對應的連接組。GCN 預測區塊採用已學習的多層級連接組，在每個層級建立並最佳化 GCN，並將已學習的圖形特徵串聯成用於 AD 分類的最終預測特徵。透過獨立的群組驗證，MLC-GCN 在區分 MCI、AD 和正常老化方面，表現優於最先進的 GCN 和基於 rsfMRI 的 AD 分類器。所提出的 MLC-GCN 也在從兩個獨立的資料集中學習臨床上合理的連接組節點和連接特徵方面，表現出高度的可解釋性。雖然我們只在 AD 上測試 MLC-GCN，但基本的基於 rsfMRI 的多層級學習 GCN 基於結果預測策略，對其他疾病或臨床結果有效。

##### **Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**
2408.03208v1 by Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin, Evangelos B. Mazomenos

Personalized federated learning (PFL) for surgical instrument segmentation
(SIS) is a promising approach. It enables multiple clinical sites to
collaboratively train a series of models in privacy, with each model tailored
to the individual distribution of each site. Existing PFL methods rarely
consider the personalization of multi-headed self-attention, and do not account
for appearance diversity and instrument shape similarity, both inherent in
surgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait
priors for SIS, incorporating global-personalized disentanglement (GPD),
appearance-regulation personalized enhancement (APE), and shape-similarity
global enhancement (SGE), to boost SIS performance in each site. GPD represents
the first attempt at head-wise assignment for multi-headed self-attention
personalization. To preserve the unique appearance representation of each site
and gradually leverage the inter-site difference, APE introduces appearance
regulation and provides customized layer-wise aggregation solutions via
hypernetworks for each site's personalized parameters. The mutual shape
information of instruments is maintained and shared via SGE, which enhances the
cross-style shape consistency on the image level and computes the
shape-similarity contribution of each site on the prediction level for updating
the global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%
Dice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding
code and models will be released at https://github.com/wzjialang/PFedSIS.

摘要：<paragraph>針對手術器械分割（SIS）的個人化聯邦學習（PFL）是一種有前景的方法。它讓多個臨床地點能夠在隱私的條件下共同訓練一系列模型，每個模型都根據每個地點的個別分佈進行調整。現有的 PFL 方法很少考慮多頭自我注意力的個人化，而且沒有考慮外觀的多樣性和器械形狀的相似性，這兩者都存在於手術場景中。因此，我們提出了 PFedSIS，這是一種具有視覺特徵先驗的 SIS 的新型 PFL 方法，它結合了全局個性化解糾纏（GPD）、外觀調節個性化增強（APE）和形狀相似性全局增強（SGE），以提升每個地點的 SIS 效能。GPD 代表了針對多頭自我注意力個性化進行頭部分配的首次嘗試。為了保留每個地點的獨特外觀表示並逐漸利用地點間的差異，APE 引入了外觀調節，並透過超網路為每個地點的個性化參數提供自訂的逐層聚合解決方案。器械的相互形狀資訊透過 SGE 進行維護和共享，這增強了影像層級上的跨風格形狀一致性，並計算每個地點在預測層級上的形狀相似性貢獻，以更新全局參數。PFedSIS 在骰子系數上優於現有最先進的方法，分別提升了 +1.51%、IoU 提升了 +2.11%、ASSD 降低了 -2.79、HD95 效能提升了 -15.55。對應的程式碼和模型將在 https://github.com/wzjialang/PFedSIS 上發布。</paragraph>

##### **The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**
2408.03354v2 by Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan, Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay

Large language models (LLMs) can be used to analyze cyber threat intelligence
(CTI) data from cybercrime forums, which contain extensive information and key
discussions about emerging cyber threats. However, to date, the level of
accuracy and efficiency of LLMs for such critical tasks has yet to be
thoroughly evaluated. Hence, this study assesses the accuracy of an LLM system
built on the OpenAI GPT-3.5-turbo model [7] to extract CTI information. To do
so, a random sample of 500 daily conversations from three cybercrime forums,
XSS, Exploit_in, and RAMP, was extracted, and the LLM system was instructed to
summarize the conversations and code 10 key CTI variables, such as whether a
large organization and/or a critical infrastructure is being targeted. Then,
two coders reviewed each conversation and evaluated whether the information
extracted by the LLM was accurate. The LLM system performed strikingly well,
with an average accuracy score of 98%. Various ways to enhance the model were
uncovered, such as the need to help the LLM distinguish between stories and
past events, as well as being careful with verb tenses in prompts.
Nevertheless, the results of this study highlight the efficiency and relevance
of using LLMs for cyber threat intelligence.

摘要：大型語言模型 (LLM) 可用於分析網路犯罪論壇中的網路威脅情報 (CTI) 資料，其中包含有關新興網路威脅的豐富資訊和關鍵討論。然而，到目前為止，LLM 對此類關鍵任務的準確性和效率尚未得到徹底評估。因此，本研究評估了建立在 OpenAI GPT-3.5-turbo 模型 [7] 上的 LLM 系統提取 CTI 資訊的準確性。為此，從三個網路犯罪論壇 XSS、Exploit_in 和 RAMP 中隨機抽取了 500 個每日對話，並指示 LLM 系統總結對話並編碼 10 個關鍵 CTI 變數，例如是否針對大型組織和/或關鍵基礎設施。然後，兩個編碼器檢閱每個對話並評估 LLM 提取的資訊是否準確。LLM 系統表現出色，平均準確度分數為 98%。發現了增強模型的各種方法，例如需要幫助 LLM 區分故事和過去事件，以及在提示中小心使用時態。儘管如此，本研究的結果突顯了使用 LLM 進行網路威脅情報的效率和相關性。

##### **VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**
2408.02888v1 by Ju-Hyeon Nam, Seo-Hyung Park, Su Jung Kim, Sang-Chul Lee

An electrocardiogram (ECG) captures the heart's electrical signal to assess
various heart conditions. In practice, ECG data is stored as either digitized
signals or printed images. Despite the emergence of numerous deep learning
models for digitized signals, many hospitals prefer image storage due to cost
considerations. Recognizing the unavailability of raw ECG signals in many
clinical settings, we propose VizECGNet, which uses only printed ECG graphics
to determine the prognosis of multiple cardiovascular diseases. During
training, cross-modal attention modules (CMAM) are used to integrate
information from two modalities - image and signal, while self-modality
attention modules (SMAM) capture inherent long-range dependencies in ECG data
of each modality. Additionally, we utilize knowledge distillation to improve
the similarity between two distinct predictions from each modality stream. This
innovative multi-modal deep learning architecture enables the utilization of
only ECG images during inference. VizECGNet with image input achieves higher
performance in precision, recall, and F1-Score compared to signal-based ECG
classification models, with improvements of 3.50%, 8.21%, and 7.38%,
respectively.

摘要：心電圖 (ECG) 可擷取心臟的電氣訊號，用於評估各種心臟疾病。實際上，心電圖資料儲存在數位化訊號或列印影像中。儘管已出現許多針對數位化訊號的深度學習模型，但許多醫院基於成本考量，仍偏好影像儲存。鑑於許多臨床環境中缺乏原始心電圖訊號，我們提出 VizECGNet，它僅使用列印的心電圖圖形來判斷多種心血管疾病的預後。在訓練期間，跨模態注意力模組 (CMAM) 用於整合來自兩種模態（影像和訊號）的資訊，而自我模態注意力模組 (SMAM) 則擷取每個模態中心電圖資料中固有的長程依賴性。此外，我們利用知識萃取來改善每個模態串流中兩個不同預測之間的相似性。這種創新的多模態深度學習架構，可以在推論期間僅使用心電圖影像。與基於訊號的心電圖分類模型相比，輸入影像的 VizECGNet 在精準度、召回率和 F1 分數方面獲得更高的效能，分別提升了 3.50%、8.21% 和 7.38%。

##### **VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**
2408.02865v1 by Zihan Li, Diping Song, Zefeng Yang, Deming Wang, Fei Li, Xiulan Zhang, Paul E. Kinahan, Yu Qiao

The need for improved diagnostic methods in ophthalmology is acute,
especially in the less developed regions with limited access to specialists and
advanced equipment. Therefore, we introduce VisionUnite, a novel
vision-language foundation model for ophthalmology enhanced with clinical
knowledge. VisionUnite has been pretrained on an extensive dataset comprising
1.24 million image-text pairs, and further refined using our proposed MMFundus
dataset, which includes 296,379 high-quality fundus image-text pairs and
889,137 simulated doctor-patient dialogue instances. Our experiments indicate
that VisionUnite outperforms existing generative foundation models such as
GPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable
to junior ophthalmologists. VisionUnite performs well in various clinical
scenarios including open-ended multi-disease diagnosis, clinical explanation,
and patient interaction, making it a highly versatile tool for initial
ophthalmic disease screening. VisionUnite can also serve as an educational aid
for junior ophthalmologists, accelerating their acquisition of knowledge
regarding both common and rare ophthalmic conditions. VisionUnite represents a
significant advancement in ophthalmology, with broad implications for
diagnostics, medical education, and understanding of disease mechanisms.

摘要：眼科診斷方法改良的必要性十分迫切，特別是在較不發達地區，那裡專科醫師和先進設備取得不易。因此，我們引進 VisionUnite，一種新穎的視覺語言基礎模型，並以臨床知識強化眼科。VisionUnite 已在包含 124 萬張影像文字對的大型資料集上進行預訓練，並透過我們建議的 MMFundus 資料集進一步優化，其中包含 296,379 張高品質眼底影像文字對和 889,137 個模擬的醫師病患對話實例。我們的實驗指出 VisionUnite 優於現有的生成式基礎模型，例如 GPT-4V 和 Gemini Pro。它也展現出與初階眼科醫師相當的診斷能力。VisionUnite 在各種臨床情境中表現良好，包括開放式多疾病診斷、臨床說明和病患互動，使其成為初步眼科疾病篩檢的高度多功能工具。VisionUnite 也可用作初階眼科醫師的教育輔助工具，加速他們對於常見和罕見眼科疾病知識的習得。VisionUnite 代表了眼科的重大進展，對診斷、醫學教育和疾病機轉的理解具有廣泛的影響。

##### **Multistain Pretraining for Slide Representation Learning in Pathology**
2408.02859v1 by Guillaume Jaume, Anurag Vaidya, Andrew Zhang, Andrew H. Song, Richard J. Chen, Sharifa Sahai, Dandan Mo, Emilio Madrigal, Long Phi Le, Faisal Mahmood

Developing self-supervised learning (SSL) models that can learn universal and
transferable representations of H&E gigapixel whole-slide images (WSIs) is
becoming increasingly valuable in computational pathology. These models hold
the potential to advance critical tasks such as few-shot classification, slide
retrieval, and patient stratification. Existing approaches for slide
representation learning extend the principles of SSL from small images (e.g.,
224 x 224 patches) to entire slides, usually by aligning two different
augmentations (or views) of the slide. Yet the resulting representation remains
constrained by the limited clinical and biological diversity of the views.
Instead, we postulate that slides stained with multiple markers, such as
immunohistochemistry, can be used as different views to form a rich
task-agnostic training signal. To this end, we introduce Madeleine, a
multimodal pretraining strategy for slide representation learning. Madeleine is
trained with a dual global-local cross-stain alignment objective on large
cohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney
transplant samples (N=12,070 WSIs across four stains). We demonstrate the
quality of slide representations learned by Madeleine on various downstream
evaluations, ranging from morphological and molecular classification to
prognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple
medical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.

摘要：開發自監督學習 (SSL) 模型，可以學習 H&E 吉像素全切片影像 (WSI) 的通用且可轉移表示，在計算病理學中正變得越來越有價值。這些模型有潛力推進關鍵任務，例如少次分類、切片檢索和患者分層。現有的切片表示學習方法將 SSL 的原理從小影像（例如 224 x 224 補丁）延伸到整個切片，通常透過對齊切片的兩個不同擴增（或視圖）。然而，生成的表示仍受到視圖有限的臨床和生物多樣性的限制。相反，我們假設使用多種標記染色的切片，例如免疫組織化學染色，可以用作不同的視圖來形成豐富的與任務無關的訓練訊號。為此，我們介紹 Madeleine，一種用於切片表示學習的多模式預訓練策略。Madeleine 使用雙重全局-局部跨染色對齊目標在大量乳癌樣本（N=4,211 個橫跨五種染色的 WSI）和腎臟移植樣本（N=12,070 個橫跨四種染色的 WSI）上進行訓練。我們在各種下游評估中展示了 Madeleine 學習的切片表示的品質，從形態和分子分類到預後預測，包括使用來自多個醫療中心的 7,299 個 WSI 的 21 項任務。程式碼可在 https://github.com/mahmoodlab/MADELEINE 取得。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**
2408.02713v1 by Zheng Han, Qi Dou

Augmented Reality (AR) holds the potential to revolutionize surgical
procedures by allowing surgeons to visualize critical structures within the
patient's body. This is achieved through superimposing preoperative organ
models onto the actual anatomy. Challenges arise from dynamic deformations of
organs during surgery, making preoperative models inadequate for faithfully
representing intraoperative anatomy. To enable reliable navigation in augmented
surgery, modeling of intraoperative deformation to obtain an accurate alignment
of the preoperative organ model with the intraoperative anatomy is
indispensable. Despite the existence of various methods proposed to model
intraoperative organ deformation, there are still few literature reviews that
systematically categorize and summarize these approaches. This review aims to
fill this gap by providing a comprehensive and technical-oriented overview of
modeling methods for intraoperative organ deformation in augmented reality in
surgery. Through a systematic search and screening process, 112 closely
relevant papers were included in this review. By presenting the current status
of organ deformation modeling methods and their clinical applications, this
review seeks to enhance the understanding of organ deformation modeling in
AR-guided surgery, and discuss the potential topics for future advancements.

摘要：擴增實境 (AR) 具有透過讓外科醫生可視化患者體內關鍵結構來革新外科手術程序的潛力。這是透過將術前器官模型疊加到實際解剖結構上來實現的。手術過程中器官的動態變形帶來了挑戰，這使得術前模型不足以忠實地呈現術中解剖結構。為了在擴增手術中實現可靠的導航，對術中變形進行建模以獲得術前器官模型與術中解剖結構的準確對齊是不可或缺的。儘管存在各種用於建模術中器官變形的方法，但系統地對這些方法進行分類和總結的文獻回顧仍然很少。本綜述旨在通過提供對擴增實境手術中術中器官變形的建模方法的全面且技術導向的概述來填補這一空白。通過系統的搜尋和篩選過程，本綜述納入了 112 篇密切相關的論文。通過呈現器官變形建模方法的現狀及其臨床應用，本綜述旨在加深對 AR 引導手術中器官變形建模的理解，並探討未來進展的潛在主題。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**
2408.02349v1 by Khanh Nguyen, Huy Hoang Nguyen, Egor Panfilov, Aleksei Tiulpin

Osteoarthritis (OA) is the most common musculoskeletal disease, which has no
cure. Knee OA (KOA) is one of the highest causes of disability worldwide, and
it costs billions of United States dollars to the global community. Prediction
of KOA progression has been of high interest to the community for years, as it
can advance treatment development through more efficient clinical trials and
improve patient outcomes through more efficient healthcare utilization.
Existing approaches for predicting KOA, however, are predominantly static, i.e.
consider data from a single time point to predict progression many years into
the future, and knee level, i.e. consider progression in a single joint only.
Due to these and related reasons, these methods fail to deliver the level of
predictive performance, which is sufficient to result in cost savings and
better patient outcomes. Collecting extensive data from all patients on a
regular basis could address the issue, but it is limited by the high cost at a
population level. In this work, we propose to go beyond static prediction
models in OA, and bring a novel Active Sensing (AS) approach, designed to
dynamically follow up patients with the objective of maximizing the number of
informative data acquisitions, while minimizing their total cost over a period
of time. Our approach is based on Reinforcement Learning (RL), and it leverages
a novel reward function designed specifically for AS of disease progression in
more than one part of a human body. Our method is end-to-end, relies on
multi-modal Deep Learning, and requires no human input at inference time.
Throughout an exhaustive experimental evaluation, we show that using RL can
provide a higher monetary benefit when compared to state-of-the-art baselines.

摘要：骨關節炎 (OA) 是一種最常見的肌肉骨骼疾病，目前尚無藥可醫。膝關節骨關節炎 (KOA) 是全球殘疾的首要原因之一，並使全球社會損失數十億美元。多年來，預測 KOA 的進展一直是社會關注的重點，因為它可以透過更有效的臨床試驗推進治療的發展，並透過更有效率的醫療保健利用來改善患者的預後。然而，現有的 KOA 預測方法主要都是靜態的，也就是說，僅考慮單一時間點的數據來預測未來多年的進展，而且是膝蓋層面的，也就是說，僅考慮單一關節的進展。由於這些原因和其他相關原因，這些方法無法提供足夠的預測效能，以致於無法節省成本並改善患者的預後。定期從所有患者身上收集廣泛的數據可以解決這個問題，但這會受到人口層級的高成本所限制。在這項工作中，我們建議超越 OA 中的靜態預測模型，並提出一個創新的主動感測 (AS) 方法，旨在動態追蹤患者，目標是最大化具有資訊性的數據擷取次數，同時在一段時間內將其總成本降至最低。我們的做法是基於強化學習 (RL)，並利用專門為人類身體多個部位的疾病進展的 AS 所設計的新型回饋函數。我們的做法是端到端的，依賴於多模態深度學習，並且在推論時間不需要人工輸入。在詳盡的實驗評估中，我們表明與最先進的基準相比，使用 RL 可以提供更高的金錢效益。

##### **MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**
2408.01988v1 by Alireza Amirshahi, Maedeh H. Toosi, Siamak Mohammadi, Stefano Albini, Pasquale Davide Schiavone, Giovanni Ansaloni, Amir Aminifar, David Atienza

Wearable systems provide continuous health monitoring and can lead to early
detection of potential health issues. However, the lifecycle of wearable
systems faces several challenges. First, effective model training for new
wearable devices requires substantial labeled data from various subjects
collected directly by the wearable. Second, subsequent model updates require
further extensive labeled data for retraining. Finally, frequent model updating
on the wearable device can decrease the battery life in long-term data
monitoring. Addressing these challenges, in this paper, we propose MetaWearS, a
meta-learning method to reduce the amount of initial data collection required.
Moreover, our approach incorporates a prototypical updating mechanism,
simplifying the update process by modifying the class prototype rather than
retraining the entire model. We explore the performance of MetaWearS in two
case studies, namely, the detection of epileptic seizures and the detection of
atrial fibrillation. We show that by fine-tuning with just a few samples, we
achieve 70% and 82% AUC for the detection of epileptic seizures and the
detection of atrial fibrillation, respectively. Compared to a conventional
approach, our proposed method performs better with up to 45% AUC. Furthermore,
updating the model with only 16 minutes of additional labeled data increases
the AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for
model updates by 456x and 418x for epileptic seizure and AF detection,
respectively.

摘要：<paragraph>穿戴式系統提供持續的健康監測，並可及早偵測潛在的健康問題。然而，穿戴式系統的生命週期面臨幾個挑戰。首先，新穿戴式裝置的有效模型訓練需要從各種受試者收集的大量標籤資料，且資料必須直接由穿戴式裝置收集。其次，後續的模型更新需要進一步的大量標籤資料才能重新訓練。最後，穿戴式裝置上頻繁的模型更新會縮短長期資料監測的電池續航力。為了應對這些挑戰，我們在本文中提出 MetaWearS，這是一種元學習方法，可減少所需的初始資料收集量。此外，我們的方法結合了一個原型更新機制，透過修改類別原型而非重新訓練整個模型來簡化更新過程。我們在兩個案例研究中探討 MetaWearS 的效能，分別是癲癇發作偵測和心房顫動偵測。我們展示了透過微調僅少數樣本，我們分別在癲癇發作偵測和心房顫動偵測中達到 70% 和 82% 的 AUC。與傳統方法相比，我們提出的方法表現更好，AUC 最高可達 45%。此外，僅使用 16 分鐘的額外標籤資料更新模型，即可將 AUC 提高多達 5.3%。最後，MetaWearS 分別將癲癇發作和心房顫動偵測的模型更新能耗降低了 456 倍和 418 倍。</paragraph>

##### **DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**
2408.01933v2 by Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara

Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 511 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.

摘要：大型語言模型 (LLM) 最近展示了非凡的能力，涵蓋廣泛的任務和應用，包括醫療領域的任務和應用。GPT-4 等模型在醫療問題解答方面表現出色，但在處理實際臨床場景中的複雜任務時，可能會面臨缺乏可解釋性的挑戰。因此，我們引入了臨床筆記診斷推理數據集 (DiReCT)，旨在評估 LLM 與人類醫生相比的推理能力和可解釋性。它包含 511 個臨床筆記，每個筆記都經過醫生仔細註解，詳細說明了從臨床筆記中的觀察結果到最終診斷的診斷推理過程。此外，還提供了診斷知識圖譜，以提供推理所需的基本知識，這可能未涵蓋在現有 LLM 的訓練數據中。在 DiReCT 上對領先的 LLM 進行評估，發現它們的推理能力與人類醫生的推理能力之間存在顯著差距，這突顯了在現實世界的臨床場景中能夠有效推理的模型的關鍵需求。

##### **MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**
2408.01869v1 by Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page

In the era of Large Language Models (LLMs), given their remarkable text
understanding and generation abilities, there is an unprecedented opportunity
to develop new, LLM-based methods for trustworthy medical knowledge synthesis,
extraction and summarization. This paper focuses on the problem of
Pharmacovigilance (PhV), where the significance and challenges lie in
identifying Adverse Drug Events (ADEs) from diverse text sources, such as
medical literature, clinical notes, and drug labels. Unfortunately, this task
is hindered by factors including variations in the terminologies of drugs and
outcomes, and ADE descriptions often being buried in large amounts of narrative
text. We present MALADE, the first effective collaborative multi-agent system
powered by LLM with Retrieval Augmented Generation for ADE extraction from drug
label data. This technique involves augmenting a query to an LLM with relevant
information extracted from text resources, and instructing the LLM to compose a
response consistent with the augmented data. MALADE is a general LLM-agnostic
architecture, and its unique capabilities are: (1) leveraging a variety of
external sources, such as medical literature, drug labels, and FDA tools (e.g.,
OpenFDA drug information API), (2) extracting drug-outcome association in a
structured format along with the strength of the association, and (3) providing
explanations for established associations. Instantiated with GPT-4 Turbo or
GPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area
Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our
implementation leverages the Langroid multi-agent LLM framework and can be
found at https://github.com/jihyechoi77/malade.

摘要：在大语言模型 (LLM) 时代，鉴于其卓越的文本理解和生成能力，出现了一个前所未有的机会，可以开发基于 LLM 的新方法，用于可信的医学知识综合、提取和摘要。本文重点关注药物警戒 (PhV) 的问题，其重要性和挑战在于从各种文本来源（如医学文献、临床笔记和药物标签）中识别不良药物事件 (ADE)。不幸的是，这项任务受到多种因素的阻碍，包括药物和结果术语的变化，以及 ADE 描述通常埋没在大量叙述性文本中。我们展示了 MALADE，这是第一个有效的协作多智能体系统，由 LLM 提供支持，并使用检索增强生成来从药物标签数据中提取 ADE。此技术涉及使用从文本资源中提取的相关信息来扩充对 LLM 的查询，并指示 LLM 编写与扩充数据一致的响应。MALADE 是一种通用的 LLM 不可知架构，其独特功能包括：(1) 利用各种外部来源，例如医学文献、药物标签和 FDA 工具（例如 OpenFDA 药物信息 API），(2) 以结构化格式提取药物-结果关联以及关联强度，以及 (3) 为已建立的关联提供解释。MALADE 使用 GPT-4 Turbo 或 GPT-4o 以及 FDA 药物标签数据实例化，并通过针对 ADE 的 OMOP 基本事实表，以 0.90 的 ROC 曲线下面积证明了其有效性。我们的实现利用了 Langroid 多智能体 LLM 框架，可以在 https://github.com/jihyechoi77/malade 中找到。

##### **Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools**
2408.04650v1 by Jung In Park, Mahyar Abbasian, Iman Azimi, Dawn Bounds, Angela Jun, Jaesu Han, Robert McCarron, Jessica Borelli, Jia Li, Mona Mahmoudi, Carmen Wiedenhoeft, Amir Rahmani

Objective: This study aims to develop and validate an evaluation framework to
ensure the safety and reliability of mental health chatbots, which are
increasingly popular due to their accessibility, human-like interactions, and
context-aware support. Materials and Methods: We created an evaluation
framework with 100 benchmark questions and ideal responses, and five guideline
questions for chatbot responses. This framework, validated by mental health
experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation
methods explored included large language model (LLM)-based scoring, an agentic
approach using real-time data, and embedding models to compare chatbot
responses against ground truth standards. Results: The results highlight the
importance of guidelines and ground truth for improving LLM evaluation
accuracy. The agentic method, dynamically accessing reliable information,
demonstrated the best alignment with human assessments. Adherence to a
standardized, expert-validated framework significantly enhanced chatbot
response safety and reliability. Discussion: Our findings emphasize the need
for comprehensive, expert-tailored safety evaluation metrics for mental health
chatbots. While LLMs have significant potential, careful implementation is
necessary to mitigate risks. The superior performance of the agentic approach
underscores the importance of real-time data access in enhancing chatbot
reliability. Conclusion: The study validated an evaluation framework for mental
health chatbots, proving its effectiveness in improving safety and reliability.
Future work should extend evaluations to accuracy, bias, empathy, and privacy
to ensure holistic assessment and responsible integration into healthcare.
Standardized evaluations will build trust among users and professionals,
facilitating broader adoption and improved mental health support through
technology.

摘要：<paragraph>目標：本研究旨在開發和驗證一個評估架構，以確保心理健康聊天機器人的安全性與可靠性，由於其可及性、擬人化的互動以及情境感知支援，這些聊天機器人正變得越來越受歡迎。材料與方法：我們建立了一個評估架構，其中包含 100 個基準問題和理想回應，以及針對聊天機器人回應的五個指南問題。這個架構經過心理健康專家驗證，並在一個基於 GPT-3.5-turbo 的聊天機器人上進行測試。探討的自動評估方法包括基於大型語言模型 (LLM) 的評分、使用即時資料的能動方法，以及將聊天機器人回應與基本事實標準進行比較的嵌入式模型。結果：結果強調了準則和基本事實對於提升 LLM 評估準確性的重要性。能動方法動態地存取可靠資訊，證明與人類評估最為一致。遵循標準化且經過專家驗證的架構，顯著提升了聊天機器人回應的安全性與可靠性。討論：我們的研究結果強調了針對心理健康聊天機器人制定全面且專家量身打造的安全評估指標的必要性。儘管 LLM 具有顯著的潛力，但仍需要謹慎實施以降低風險。能動方法的優異表現突顯了即時資料存取對於提升聊天機器人可靠性的重要性。結論：本研究驗證了一個針對心理健康聊天機器人的評估架構，證明其在提升安全性與可靠性方面的有效性。未來的研究應將評估擴展至準確性、偏見、同理心和隱私，以確保全面的評估，並負責任地整合至醫療保健中。標準化的評估將建立使用者和專業人士之間的信任，促進更廣泛的採用，並透過科技改善心理健康支援。</paragraph>

##### **ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**
2408.01827v1 by Mridula Vijendran, Frederick W. B. Li, Jingjing Deng, Hubert P. H. Shum

Painting classification plays a vital role in organizing, finding, and
suggesting artwork for digital and classic art galleries. Existing methods
struggle with adapting knowledge from the real world to artistic images during
training, leading to poor performance when dealing with different datasets. Our
innovation lies in addressing these challenges through a two-step process.
First, we generate more data using Style Transfer with Adaptive Instance
Normalization (AdaIN), bridging the gap between diverse styles. Then, our
classifier gains a boost with feature-map adaptive spatial attention modules,
improving its understanding of artistic details. Moreover, we tackle the
problem of imbalanced class representation by dynamically adjusting augmented
samples. Through a dual-stage process involving careful hyperparameter search
and model fine-tuning, we achieve an impressive 87.24\% accuracy using the
ResNet-50 backbone over 40 training epochs. Our study explores quantitative
analyses that compare different pretrained backbones, investigates model
optimization through ablation studies, and examines how varying augmentation
levels affect model performance. Complementing this, our qualitative
experiments offer valuable insights into the model's decision-making process
using spatial attention and its ability to differentiate between easy and
challenging samples based on confidence ranking.

摘要：繪畫分類在組織、尋找和建議數位和經典藝廊的藝術品中扮演重要的角色。現有的方法在訓練時難以將現實世界的知識適應到藝術圖像中，導致在處理不同資料集時效能不佳。我們的創新在於透過兩步驟的程序來解決這些挑戰。首先，我們使用具有自適應實例正規化 (AdaIN) 的風格轉移來產生更多資料，彌合了不同風格之間的差距。接著，我們的分類器透過具備特徵圖自適應空間注意力模組而獲得提升，進而改善其對藝術細節的理解。此外，我們透過動態調整擴充樣本來解決類別表示不平衡的問題。透過一個涉及仔細的超參數搜尋和模型微調的雙階段程序，我們使用 ResNet-50 主幹在超過 40 個訓練時期達到了令人印象深刻的 87.24% 準確度。我們的研究探討了比較不同預訓練主幹的定量分析，透過消融研究來探討模型最佳化，並檢視不同的擴充層級如何影響模型效能。作為補充，我們的定性實驗透過空間注意力提供了有價值的見解，了解模型的決策制定程序，以及它根據信心排名來區分容易和困難樣本的能力。

##### **Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment**
2408.01614v1 by Jinwen Tang, Yi Shang

This study introduces 'Psycho Analyst', a custom GPT model based on OpenAI's
GPT-4, optimized for pre-screening mental health disorders. Enhanced with
DSM-5, PHQ-8, detailed data descriptions, and extensive training data, the
model adeptly decodes nuanced linguistic indicators of mental health disorders.
It utilizes a dual-task framework that includes binary classification and a
three-stage PHQ-8 score computation involving initial assessment, detailed
breakdown, and independent assessment, showcasing refined analytic
capabilities. Validation with the DAIC-WOZ dataset reveals F1 and Macro-F1
scores of 0.929 and 0.949, respectively, along with the lowest MAE and RMSE of
2.89 and 3.69 in PHQ-8 scoring. These results highlight the model's precision
and transformative potential in enhancing public mental health support,
improving accessibility, cost-effectiveness, and serving as a second opinion
for professionals.

摘要：本研究推出了「心理分析師」，一個基於 OpenAI 的 GPT-4 的自訂 GPT 模型，針對心理健康障礙的預篩選而最佳化。此模型經過 DSM-5、PHQ-8、詳細資料描述和廣泛訓練資料的強化，能熟練地解碼心理健康障礙的細微語言指標。它採用一個雙任務架構，包括二元分類和一個三階段 PHQ-8 分數計算，涉及初步評估、詳細細分和獨立評估，展示了精緻的分析能力。使用 DAIC-WOZ 資料集進行驗證，F1 和巨集 F1 分數分別為 0.929 和 0.949，PHQ-8 評分中的 MAE 和 RMSE 最低，分別為 2.89 和 3.69。這些結果突顯了此模型在提升公眾心理健康支持、改善可及性、成本效益，以及作為專業人士的第二意見方面的精準度和變革潛力。

##### **Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference**
2408.01582v1 by Hengrui Cai, Huaqing Jin, Lexin Li

Estimating treatment effects from observational data is of central interest
across numerous application domains. Individual treatment effect offers the
most granular measure of treatment effect on an individual level, and is the
most useful to facilitate personalized care. However, its estimation and
inference remain underdeveloped due to several challenges. In this article, we
propose a novel conformal diffusion model-based approach that addresses those
intricate challenges. We integrate the highly flexible diffusion modeling, the
model-free statistical inference paradigm of conformal inference, along with
propensity score and covariate local approximation that tackle distributional
shifts. We unbiasedly estimate the distributions of potential outcomes for
individual treatment effect, construct an informative confidence interval, and
establish rigorous theoretical guarantees. We demonstrate the competitive
performance of the proposed method over existing solutions through extensive
numerical studies.

摘要：從觀察資料中估計治療效果在許多應用領域中都非常重要。個別治療效果提供了個人層級最細緻的治療效果衡量，且最有助於促進個人化照護。然而，由於有許多挑戰，其估計和推論仍處於發展不足的狀態。在本文中，我們提出了創新的共形擴散模型為基礎的方法，來因應這些複雜的挑戰。我們整合了高度彈性的擴散模型、共形推論的無模型統計推論範例，以及處理分佈轉移的傾向得分和協變數局部近似。我們無偏估計個別治療效果的潛在結果分佈，建構有意義的信心區間，並建立嚴謹的理論保證。我們透過廣泛的數值研究，展示了所提出方法相較於現有解決方案的競爭力。

##### **High-Throughput Phenotyping of Clinical Text Using Large Language Models**
2408.01214v1 by Daniel B. Hier, S. Ilyas Munzir, Anne Stahlfeld, Tayo Obafemi-Ajayi, Michael D. Carrithers

High-throughput phenotyping automates the mapping of patient signs to
standardized ontology concepts and is essential for precision medicine. This
study evaluates the automation of phenotyping of clinical summaries from the
Online Mendelian Inheritance in Man (OMIM) database using large language
models. Due to their rich phenotype data, these summaries can be surrogates for
physician notes. We conduct a performance comparison of GPT-4 and
GPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in
identifying, categorizing, and normalizing signs, achieving concordance with
manual annotators comparable to inter-rater agreement. Despite some limitations
in sign normalization, the extensive pre-training of GPT-4 results in high
performance and generalizability across several phenotyping tasks while
obviating the need for manually annotated training data. Large language models
are expected to be the dominant method for automating high-throughput
phenotyping of clinical text.

摘要：高通量表型自動化將患者症狀對應到標準化本体概念，對於精準醫療至關重要。本研究評估使用大型語言模型自動化來自人類孟德爾遺傳線上（OMIM）資料庫的臨床摘要表型。由於其豐富的表型資料，這些摘要可以作為醫師備忘錄的替代品。我們對 GPT-4 和 GPT-3.5-Turbo 進行效能比較。我們的結果顯示，GPT-4 在識別、分類和標準化症狀方面優於 GPT-3.5-Turbo，與手動註解者的符合度可媲美評分者間的一致性。儘管在症狀標準化方面有一些限制，但 GPT-4 的廣泛預訓練在多項表型任務中仍能帶來高效能和概括性，同時無需手動註解的訓練資料。大型語言模型預計將成為自動化臨床文字高通量表型的主要方法。

##### **Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning**
2408.01187v1 by Michael Kölle, Daniel Seidl, Maximilian Zorn, Philipp Altmann, Jonas Stein, Thomas Gabor

Quantum Reinforcement Learning (QRL) offers potential advantages over
classical Reinforcement Learning, such as compact state space representation
and faster convergence in certain scenarios. However, practical benefits
require further validation. QRL faces challenges like flat solution landscapes,
where traditional gradient-based methods are inefficient, necessitating the use
of gradient-free algorithms. This work explores the integration of
metaheuristic algorithms -- Particle Swarm Optimization, Ant Colony
Optimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony
Search -- into QRL. These algorithms provide flexibility and efficiency in
parameter optimization. Evaluations in $5\times5$ MiniGrid Reinforcement
Learning environments show that, all algorithms yield near-optimal results,
with Simulated Annealing and Particle Swarm Optimization performing best. In
the Cart Pole environment, Simulated Annealing, Genetic Algorithms, and
Particle Swarm Optimization achieve optimal results, while the others perform
slightly better than random action selection. These findings demonstrate the
potential of Particle Swarm Optimization and Simulated Annealing for efficient
QRL learning, emphasizing the need for careful algorithm selection and
adaptation.

摘要：量子強化學習 (QRL) 比傳統強化學習具有潛在優勢，例如緊湊的狀態空間表示和在某些情況下更快的收斂速度。然而，實際好處需要進一步驗證。QRL 面臨平坦的解決方案環境等挑戰，傳統的基於梯度的算法效率低下，因此需要使用無梯度算法。這項工作探討了元啟發式演算法（粒子群最佳化、蟻群最佳化、禁忌搜尋、遺傳演算法、模擬退火和和諧搜尋）整合到 QRL 中。這些演算法在參數最佳化中提供了靈活性與效率。在 $5\times5$ MiniGrid 強化學習環境中的評估顯示，所有演算法都產生近乎最佳的結果，其中模擬退火和粒子群最佳化表現最佳。在桿鈴環境中，模擬退火、遺傳演算法和粒子群最佳化實現最佳結果，而其他演算法的效能略優於隨機動作選擇。這些發現證明了粒子群最佳化和模擬退火在有效率的 QRL 學習中的潛力，強調了仔細選擇和調整演算法的必要性。

##### **Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**
2408.01096v1 by Danbinaerin Han, Mark Gotham, Dongmin Kim, Hannah Park, Sihun Lee, Dasaem Jeong

We introduce a project that revives a piece of 15th-century Korean court
music, Chihwapyeong and Chwipunghyeong, composed upon the poem Songs of the
Dragon Flying to Heaven. One of the earliest examples of Jeongganbo, a Korean
musical notation system, the remaining version only consists of a rudimentary
melody. Our research team, commissioned by the National Gugak (Korean
Traditional Music) Center, aimed to transform this old melody into a
performable arrangement for a six-part ensemble. Using Jeongganbo data acquired
through bespoke optical music recognition, we trained a BERT-like masked
language model and an encoder-decoder transformer model. We also propose an
encoding scheme that strictly follows the structure of Jeongganbo and denotes
note durations as positions. The resulting machine-transformed version of
Chihwapyeong and Chwipunghyeong were evaluated by experts and performed by the
Court Music Orchestra of National Gugak Center. Our work demonstrates that
generative models can successfully be applied to traditional music with limited
training data if combined with careful design.

摘要：我們介紹了一個復原 15 世紀韓國宮廷音樂的專案，即《飛龍歌》的《雉和拍》和《吹風詠》。這是韓國音樂記譜法「正干譜」最早的範例之一，現存版本僅包含基本的旋律。我們的研究團隊受國家國樂中心委託，旨在將這首古老的旋律轉化為六人合奏的表演編排。我們使用透過客製化光學音樂辨識取得的正干譜資料，訓練了一個類似 BERT 的遮蔽語言模型和一個編碼器-解碼器轉換器模型。我們還提出了一種編碼方案，它嚴格遵循正干譜的結構，並將音符時值標示為位置。由機器轉換後的《雉和拍》和《吹風詠》由專家評估，並由國家國樂中心的宮廷音樂樂團演奏。我們的研究證明，如果將生成模型與謹慎的設計結合，即使訓練資料有限，也能成功應用於傳統音樂。

##### **CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**
2408.00938v2 by Caiwen Jiang, Xiaodan Xing, Zaixin Ou, Mianxin Liu, Walsh Simon, Guang Yang, Dinggang Shen

The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly
correlates with higher patient mortality rates. Early detection of IPF
progression is critical for initiating timely treatment, which can effectively
slow down the advancement of the disease. However, the current clinical
criteria define disease progression requiring two CT scans with a one-year
interval, presenting a dilemma: a disease progression is identified only after
the disease has already progressed. To this end, in this paper, we develop a
novel diffusion model to accurately predict the progression of IPF by
generating patient's follow-up CT scan from the initial CT scan. Specifically,
from the clinical prior knowledge, we tailor improvements to the traditional
diffusion model and propose a Clinically-Informed Residual Diffusion model,
called CIResDiff. The key innovations of CIResDiff include 1) performing the
target region pre-registration to align the lung regions of two CT scans at
different time points for reducing the generation difficulty, 2) adopting the
residual diffusion instead of traditional diffusion to enable the model focus
more on differences (i.e., lesions) between the two CT scans rather than the
largely identical anatomical content, and 3) designing the clinically-informed
process based on CLIP technology to integrate lung function information which
is highly relevant to diagnosis into the reverse process for assisting
generation. Extensive experiments on clinical data demonstrate that our
approach can outperform state-of-the-art methods and effectively predict the
progression of IPF.

摘要：特發性肺纖維化 (IPF) 的進程與較高的患者死亡率顯著相關。早期偵測 IPF 進程對於及時開始治療至關重要，而治療可以有效減緩疾病的進展。然而，目前的臨床標準定義疾病進程需要兩次相隔一年的電腦斷層掃描，這造成了兩難：只有在疾病已經進展後才能識別出疾病進程。為此，在本文中，我們開發了一個創新的擴散模型，通過從初始電腦斷層掃描生成患者的後續電腦斷層掃描，來準確預測 IPF 的進程。具體來說，根據臨床先驗知識，我們對傳統擴散模型進行了改進，並提出了臨床知情殘差擴散模型，稱為 CIResDiff。CIResDiff 的關鍵創新包括：1) 執行目標區域預註冊，以對齊不同時間點的兩次電腦斷層掃描的肺部區域，以降低生成難度；2) 採用殘差擴散而不是傳統擴散，使模型更專注於兩次電腦斷層掃描之間的差異（即病灶），而不是在很大程度上相同的解剖結構；3) 設計基於 CLIP 技術的臨床知情流程，將與診斷高度相關的肺功能資訊整合到逆向過程中，以協助生成。臨床數據的大量實驗表明，我們的做法可以優於最先進的方法，並有效預測 IPF 的進程。

##### **Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**
2408.00906v1 by Christopher Neves, Yong Zeng, Yiming Xiao

Parkinson's disease (PD) is a debilitating neurodegenerative disease that has
severe impacts on an individual's quality of life. Compared with structural and
functional MRI-based biomarkers for the disease, electroencephalography (EEG)
can provide more accessible alternatives for clinical insights. While deep
learning (DL) techniques have provided excellent outcomes, many techniques fail
to model spatial information and dynamic brain connectivity, and face
challenges in robust feature learning, limited data sizes, and poor
explainability. To address these issues, we proposed a novel graph neural
network (GNN) technique for explainable PD detection using resting state EEG.
Specifically, we employ structured global convolutions with contrastive
learning to better model complex features with limited data, a novel multi-head
graph structure learner to capture the non-Euclidean structure of EEG data, and
a head-wise gradient-weighted graph attention explainer to offer neural
connectivity insights. We developed and evaluated our method using the UC San
Diego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy
in subject-wise leave-one-out cross-validation while generating intuitive
explanations for the learnt graph topology.

摘要：帕金森氏症（PD）是一种衰弱性神经退行性疾病，对个人的生活质量有严重影响。与用于该疾病的结构性和功能性 MRI 生物标记物相比，脑电图 (EEG) 可以提供更易于获取的临床见解替代方案。虽然深度学习 (DL) 技术提供了卓越的结果，但许多技术未能对空间信息和动态大脑连接进行建模，并且在稳健特征学习、有限的数据大小和较差的可解释性方面面临挑战。为了解决这些问题，我们提出了一种新颖的图神经网络 (GNN) 技术，用于使用静息状态脑电图进行可解释的 PD 检测。具体而言，我们采用具有对比学习的结构化全局卷积来更好地对具有有限数据的复杂特征进行建模，采用新颖的多头图结构学习器来捕获脑电图数据的非欧几里得结构，以及采用头权重梯度图注意解释器来提供神经连接见解。我们使用加州大学圣地亚哥分校帕金森氏症脑电图数据集开发并评估了我们的方法，并在按受试者留一法交叉验证中实现了 69.40% 的检测准确率，同时为学习到的图拓扑生成直观的解释。

##### **UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**
2408.00860v2 by Ziwen Guo, Zi Fang, Zhuang Fu

Three-dimensional ultrasound imaging is a critical technology widely used in
medical diagnostics. However, traditional 3D ultrasound imaging methods have
limitations such as fixed resolution, low storage efficiency, and insufficient
contextual connectivity, leading to poor performance in handling complex
artifacts and reflection characteristics. Recently, techniques based on NeRF
(Neural Radiance Fields) have made significant progress in view synthesis and
3D reconstruction, but there remains a research gap in high-quality ultrasound
imaging. To address these issues, we propose a new model, UlRe-NeRF, which
combines implicit neural networks and explicit ultrasound volume rendering into
an ultrasound neural rendering architecture. This model incorporates reflection
direction parameterization and harmonic encoding, using a directional MLP
module to generate view-dependent high-frequency reflection intensity
estimates, and a spatial MLP module to produce the medium's physical property
parameters. These parameters are used in the volume rendering process to
accurately reproduce the propagation and reflection behavior of ultrasound
waves in the medium. Experimental results demonstrate that the UlRe-NeRF model
significantly enhances the realism and accuracy of high-fidelity ultrasound
image reconstruction, especially in handling complex medium structures.

摘要：三維超音波影像是一項廣泛用於醫療診斷的重要技術。然而，傳統的 3D 超音波影像方法有解析度固定、儲存效率低、脈絡連接性不足等限制，導致在處理複雜的偽影和反射特性時效能不佳。最近，基於 NeRF（神經輻照場）的技術在視圖合成和 3D 重建方面取得重大進展，但高品質超音波影像仍存在研究空白。為了解決這些問題，我們提出了一種新的模型 UlRe-NeRF，它將隱式神經網路和明確的超音波體積渲染結合到超音波神經渲染架構中。此模型結合了反射方向參數化和諧波編碼，使用方向性 MLP 模組來產生視角依賴的高頻率反射強度估計，並使用空間 MLP 模組來產生介質的物理屬性參數。這些參數用於體積渲染過程中，以準確重現超音波在介質中的傳播和反射行為。實驗結果證明，UlRe-NeRF 模型顯著提升了高保真超音波影像重建的真實性和準確性，特別是在處理複雜介質結構時。

##### **Segment anything model 2: an application to 2D and 3D medical images**
2408.00756v2 by Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski

Segment Anything Model (SAM) has gained significant attention because of its
ability to segment varous objects in images given a prompt. The recently
developed SAM 2 has extended this ability to video inputs. This opens an
opportunity to apply SAM to 3D images, one of the fundamental tasks in the
medical imaging field. In this paper, we extensively evaluate SAM 2's ability
to segment both 2D and 3D medical images by first collecting 18 medical imaging
datasets, including common 3D modalities such as computed tomography (CT),
magnetic resonance imaging (MRI), and positron emission tomography (PET) as
well as 2D modalities such as X-ray and ultrasound. Two evaluation pipelines of
SAM 2 are considered: (1) multi-frame 3D segmentation, where prompts are
provided to one or multiple slice(s) selected from the volume, and (2)
single-frame 2D segmentation, where prompts are provided to each slice. The
former is only applicable to 3D modalities, while the latter applies to both 2D
and 3D modalities. Our results show that SAM 2 exhibits similar performance as
SAM under single-frame 2D segmentation, and has variable performance under
multi-frame 3D segmentation depending on the choices of slices to annotate, the
direction of the propagation, the predictions utilized during the propagation,
etc.

摘要：分段任何模型 (SAM) 因其根據提示分段圖像中的不同物件的能力而受到廣泛關注。最近開發的 SAM 2 已將此能力擴展到影片輸入。這為將 SAM 應用於 3D 影像開啟了機會，這是醫學影像領域的基本任務之一。在本文中，我們廣泛評估了 SAM 2 分段 2D 和 3D 醫學影像的能力，首先收集了 18 個醫學影像資料集，包括常見的 3D 模式，例如電腦斷層掃描 (CT)、磁振造影 (MRI) 和正子發射斷層掃描 (PET)，以及 2D 模式，例如 X 射線和超音波。考慮了 SAM 2 的兩個評估管道：(1) 多幀 3D 分段，其中提示提供給從體積中選擇的一個或多個切片，以及 (2) 單幀 2D 分段，其中提示提供給每個切片。前者僅適用於 3D 模式，而後者適用於 2D 和 3D 模式。我們的結果表明，SAM 2 在單幀 2D 分段下的表現與 SAM 類似，並且在多幀 3D 分段下的表現會根據要標註的切片選擇、傳播方向、傳播期間使用的預測等而有所不同。

##### **Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**
2408.00749v1 by Venkat Margapuri, Prapti Thapaliya, Trevor Rife

Modern day studies show a high degree of correlation between high yielding
crop varieties and plants with upright leaf angles. It is observed that plants
with upright leaf angles intercept more light than those without upright leaf
angles, leading to a higher rate of photosynthesis. Plant scientists and
breeders benefit from tools that can directly measure plant parameters in the
field i.e. on-site phenotyping. The estimation of leaf angles by manual means
in a field setting is tedious and cumbersome. We mitigate the tedium using a
combination of the Mask R-CNN instance segmentation neural network, and Line
Segment Transformer (LETR), a vision transformer. The proposed Computer Vision
(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer
2015- Ames MLA, with a combined total of 1,827 plant images collected in the
field using FieldBook, an Android application aimed at on-site phenotyping. The
leaf angles estimated by the proposed pipeline on the image datasets are
compared to two independent manual measurements using ImageJ, a Java-based
image processing program developed at the National Institutes of Health and the
Laboratory for Optical and Computational Instrumentation. The results, when
compared for similarity using the Cosine Similarity measure, exhibit 0.98
similarity scores on both independent measurements of Summer 2015-Ames ULA and
Summer 2015-Ames MLA image datasets, demonstrating the feasibility of the
proposed pipeline for on-site measurement of leaf angles.

摘要：<paragraph>現代研究顯示，高產量作物品種和葉片角度直立的植物之間有高度相關性。觀察到葉片角度直立的植物比葉片角度不直立的植物攔截更多光線，從而導致更高的光合作用速率。植物科學家和育種者受益於可以在田間直接測量植物參數的工具，即現場表型分析。在田間環境中通過手動方式估計葉片角度既繁瑣又麻煩。我們使用 Mask R-CNN 實例分割神經網路和線段Transformer (LETR)（一種視覺Transformer）的組合來減輕繁瑣性。所提出的計算機視覺 (CV) 管線應用於兩個圖像資料集，Summer 2015-Ames ULA 和 Summer 2015- Ames MLA，總共包含 1,827 張植物圖像，這些圖像是在田間使用 FieldBook（一種針對現場表型分析的 Android 應用程式）收集的。使用所提出的管線估計的圖像資料集上的葉片角度與使用 ImageJ（一種由美國國家衛生研究院和光學和計算儀器實驗室開發的基於 Java 的影像處理程式）進行的兩次獨立手動測量進行比較。將結果使用餘弦相似度測量進行相似性比較時，在 Summer 2015-Ames ULA 和 Summer 2015-Ames MLA 影像資料集的兩次獨立測量中都顯示出 0.98 的相似度分數，證明了所提出的管線用於現場測量葉片角度的可行性。</paragraph>

##### **Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**
2408.00727v1 by Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

The emergent abilities of large language models (LLMs) have demonstrated
great potential in solving medical questions. They can possess considerable
medical knowledge, but may still hallucinate and are inflexible in the
knowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed
to enhance the medical question-answering capabilities of LLMs with external
knowledge bases, it may still fail in complex cases where multiple rounds of
information-seeking are required. To address such an issue, we propose
iterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up
queries based on previous information-seeking attempts. In each iteration of
i-MedRAG, the follow-up queries will be answered by a vanilla RAG system and
they will be further used to guide the query generation in the next iteration.
Our experiments show the improved performance of various LLMs brought by
i-MedRAG compared with vanilla RAG on complex questions from clinical vignettes
in the United States Medical Licensing Examination (USMLE), as well as various
knowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.
Notably, our zero-shot i-MedRAG outperforms all existing prompt engineering and
fine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\% on the MedQA
dataset. In addition, we characterize the scaling properties of i-MedRAG with
different iterations of follow-up queries and different numbers of queries per
iteration. Our case studies show that i-MedRAG can flexibly ask follow-up
queries to form reasoning chains, providing an in-depth analysis of medical
questions. To the best of our knowledge, this is the first-of-its-kind study on
incorporating follow-up queries into medical RAG.

摘要：大型語言模型（LLM）的新興能力已證明在解決醫療問題方面具有巨大潛力。它們可能擁有大量的醫療知識，但仍可能產生幻覺，並且在知識更新方面缺乏靈活性。雖然已提出檢索增強生成（RAG）以利用外部知識庫增強 LLM 的醫療問題解答能力，但在需要多輪信息檢索的複雜情況下，它仍可能失敗。為了解決這個問題，我們提出了用於醫療的迭代 RAG（i-MedRAG），其中 LLM 可以根據先前的信息檢索嘗試反覆詢問後續查詢。在 i-MedRAG 的每次迭代中，後續查詢將由基本的 RAG 系統回答，並且它們將進一步用於指導下一次迭代中的查詢生成。我們的實驗表明，與美國醫學執照考試（USMLE）中臨床小插圖中的複雜問題以及 Massive Multitask Language Understanding（MMLU）數據集中各種知識測試中的基本 RAG 相比，i-MedRAG 帶來的各種 LLM 的改進性能。值得注意的是，我們的零次學習 i-MedRAG 在 GPT-3.5 上優於所有現有的提示工程和微調方法，在 MedQA 數據集上達到了 69.68% 的準確率。此外，我們描述了 i-MedRAG 的擴展屬性，包括不同的後續查詢迭代和每個迭代的不同查詢數量。我們的案例研究表明，i-MedRAG 可以靈活地詢問後續查詢以形成推理鏈，從而對醫療問題進行深入分析。據我們所知，這是第一個將後續查詢納入醫療 RAG 的同類研究。

##### **Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**
2408.00706v1 by Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri

Delineating lesions and anatomical structure is important for image-guided
interventions. Point-supervised medical image segmentation (PSS) has great
potential to alleviate costly expert delineation labeling. However, due to the
lack of precise size and boundary guidance, the effectiveness of PSS often
falls short of expectations. Although recent vision foundational models, such
as the medical segment anything model (MedSAM), have made significant
advancements in bounding-box-prompted segmentation, it is not straightforward
to utilize point annotation, and is prone to semantic ambiguity. In this
preliminary study, we introduce an iterative framework to facilitate
semantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt
generator (SBPG) module has the capacity to convert the point input into
potential pseudo bounding box suggestions, which are explicitly refined by the
prototype-based semantic similarity. This is then succeeded by a prompt-guided
spatial refinement (PGSR) module that harnesses the exceptional
generalizability of MedSAM to infer the segmentation mask, which also updates
the box proposal seed in SBPG. Performance can be progressively improved with
adequate iterations. We conducted an evaluation on BraTS2018 for the
segmentation of whole brain tumors and demonstrated its superior performance
compared to traditional PSS methods and on par with box-supervised methods.

摘要：描繪病灶和解剖結構對於影像導引介入非常重要。點監督醫學影像分割（PSS）具有減輕昂貴的專家描繪標籤的巨大潛力。然而，由於缺乏精確的大小和邊界引導，PSS 的有效性通常低於預期。儘管最近的視覺基礎模型，例如醫學分割任何模型（MedSAM），在邊界框提示分割方面取得了重大進展，但利用點註釋並不容易，而且容易產生語義歧義。在這項初步研究中，我們引入了一個迭代框架來促進語義感知點監督 MedSAM。具體來說，語義框提示生成器（SBPG）模組能夠將點輸入轉換為潛在的偽邊界框建議，這些建議由基於原型的語義相似性明確細化。然後，由提示引導的空間細化（PGSR）模組繼承，它利用 MedSAM 的出色可概化性來推斷分割蒙版，這也會更新 SBPG 中的框建議種子。通過充分的迭代可以逐步提高性能。我們對 BraTS2018 進行了全腦腫瘤分割評估，並證明其性能優於傳統的 PSS 方法，並且與框監督方法相當。

##### **HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**
2408.00481v1 by Bolin Zhang, Zhiwei Yi, Jiahao Wang, Dianbo Sui, Zhiying Tu, Dianhui Chu

The unique diagnosis and treatment techniques and remarkable clinical
efficacy of traditional Chinese medicine (TCM) make it play an important role
in the field of elderly care and healthcare, especially in the rehabilitation
of some common chronic diseases of the elderly. Therefore, building a TCM
chatbot for healthcare application will help users obtain consultation services
in a direct and natural way. However, concepts such as acupuncture points
(acupoints) and meridians involved in TCM always appear in the consultation,
which cannot be displayed intuitively. To this end, we develop a
\textbf{h}ealthcare chat\textbf{bot} (HBot) based on a human body model in 3D
and knowledge graph, which provides conversational services such as knowledge
Q\&A, prescription recommendation, moxibustion therapy recommendation, and
acupoint search. When specific acupoints are involved in the conversations
between user and HBot, the 3D body will jump to the corresponding acupoints and
highlight them. Moreover, Hbot can also be used in training scenarios to
accelerate the teaching process of TCM by intuitively displaying acupuncture
points and knowledge cards. The demonstration video is available at
https://www.youtube.com/watch?v=UhQhutSKkTU . Our code and dataset are publicly
available at Gitee: https://gitee.com/plabrolin/interactive-3d-acup.git

摘要：中醫獨特的診治手法和顯著的臨床療效，在老年照護與保健領域中扮演著重要的角色，特別是在老年人常見慢性疾病的復健上。因此，建構一個中醫醫療照護聊天機器人，將有助於使用者以直接且自然的方式取得諮詢服務。然而，中醫所涉及的穴位、經絡等概念，在諮詢時總是會出現，而這些無法直觀地顯示出來。為了解決這個問題，我們開發了一個基於 3D 人體模型和知識圖譜的醫療照護聊天機器人（HBot），它提供了知識問答、處方推薦、艾灸療法推薦和穴位查詢等對話服務。當使用者與 HBot 的對話中涉及到具體穴位時，3D 人體會跳轉到對應的穴位並將其高亮顯示。此外，HBot 還可以用於培訓場景中，通過直觀地顯示穴位和知識卡片，來加速中醫教學的進程。示範影片可於 https://www.youtube.com/watch?v=UhQhutSKkTU 取得。我們的程式碼和資料集已於 Gitee 公開：https://gitee.com/plabrolin/interactive-3d-acup.git

##### **Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**
2408.00348v1 by Angona Biswas, MD Abdullah Al Nasim, Kishor Datta Gupta, Roy George, Abdur Rashid

Machine learning (ML) is a rapidly developing area of medicine that uses
significant resources to apply computer science and statistics to medical
issues. ML's proponents laud its capacity to handle vast, complicated, and
erratic medical data. It's common knowledge that attackers might cause
misclassification by deliberately creating inputs for machine learning
classifiers. Research on adversarial examples has been extensively conducted in
the field of computer vision applications. Healthcare systems are thought to be
highly difficult because of the security and life-or-death considerations they
include, and performance accuracy is very important. Recent arguments have
suggested that adversarial attacks could be made against medical image analysis
(MedIA) technologies because of the accompanying technology infrastructure and
powerful financial incentives. Since the diagnosis will be the basis for
important decisions, it is essential to assess how strong medical DNN tasks are
against adversarial attacks. Simple adversarial attacks have been taken into
account in several earlier studies. However, DNNs are susceptible to more risky
and realistic attacks. The present paper covers recent proposed adversarial
attack strategies against DNNs for medical imaging as well as countermeasures.
In this study, we review current techniques for adversarial imaging attacks,
detections. It also encompasses various facets of these techniques and offers
suggestions for the robustness of neural networks to be improved in the future.

摘要：機器學習 (ML) 是醫學領域中快速發展的一個領域，它利用大量的資源將電腦科學和統計學應用於醫療問題。ML 的支持者讚揚它處理大量、複雜且不規則醫療資料的能力。眾所周知，攻擊者可能會透過故意為機器學習分類器建立輸入來導致錯誤分類。對抗範例的研究已在電腦視覺應用領域中廣泛進行。醫療保健系統被認為非常困難，因為它們包含安全性及生死攸關的考量，且效能準確性非常重要。最近的論點表明，由於伴隨而來的技術基礎設施和強大的財務誘因，對抗攻擊可能會針對醫學影像分析 (MedIA) 技術進行。由於診斷將成為重要決策的基礎，因此評估醫療 DNN 任務對抗攻擊的強弱非常重要。在先前的多項研究中已考慮了簡單的對抗攻擊。然而，DNN 容易受到風險更高且更逼真的攻擊。本文涵蓋了針對用於醫學影像的 DNN 所提出的最新對抗攻擊策略以及對策。在本研究中，我們回顧了當前對抗影像攻擊的技術和檢測方法。它還包含了這些技術的各個方面，並提供了改進神經網路在未來強健性的建議。

##### **Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**
2408.00347v1 by Sungmin Kang, Jaeha Song, Jihie Kim

Understanding the morphological structure of medical images and precisely
segmenting the region of interest or abnormality is an important task that can
assist in diagnosis. However, the unique properties of medical imaging make
clear segmentation difficult, and the high cost and time-consuming task of
labeling leads to a coarse-grained representation of ground truth. Facing with
these problems, we propose a novel Diffusion Transformer Segmentation (DTS)
model for robust segmentation in the presence of noise. We propose an
alternative to the dominant Denoising U-Net encoder through experiments
applying a transformer architecture, which captures global dependency through
self-attention. Additionally, we propose k-neighbor label smoothing, reverse
boundary attention, and self-supervised learning with morphology-driven
learning to improve the ability to identify complex structures. Our model,
which analyzes the morphological representation of images, shows better results
than the previous models in various medical imaging modalities, including CT,
MRI, and lesion images.

摘要：了解醫學影像的形態結構並精確分割感興趣或異常區域是一項重要的任務，有助於診斷。然而，醫學影像的獨特屬性使得清晰的分割變得困難，而標籤的高成本和耗時任務導致了地面實況的粗略表示。面對這些問題，我們提出了一個新的擴散Transformer分割（DTS）模型，用於在有噪聲的情況下進行穩健分割。我們通過應用捕獲全局依賴性的自注意力Transformer架構，提出了一個替代主流去噪 U-Net 編碼器的方案。此外，我們提出了 k 近鄰標籤平滑、反向邊界注意力，以及使用形態驅動學習的自監督學習，以提高識別複雜結構的能力。我們的模型分析了影像的形態表示，在各種醫學影像方式中顯示出比以前模型更好的結果，包括 CT、MRI 和病灶影像。

##### **S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**
2408.00191v1 by Andrea Kim, Niloufar Saharkhiz, Elena Sizikova, Miguel Lago, Berkman Sahiner, Jana Delfino, Aldo Badano

Development of artificial intelligence (AI) techniques in medical imaging
requires access to large-scale and diverse datasets for training and
evaluation. In dermatology, obtaining such datasets remains challenging due to
significant variations in patient populations, illumination conditions, and
acquisition system characteristics. In this work, we propose S-SYNTH, the first
knowledge-based, adaptable open-source skin simulation framework to rapidly
generate synthetic skin, 3D models and digitally rendered images, using an
anatomically inspired multi-layer, multi-component skin and growing lesion
model. The skin model allows for controlled variation in skin appearance, such
as skin color, presence of hair, lesion shape, and blood fraction among other
parameters. We use this framework to study the effect of possible variations on
the development and evaluation of AI models for skin lesion segmentation, and
show that results obtained using synthetic data follow similar comparative
trends as real dermatologic images, while mitigating biases and limitations
from existing datasets including small dataset size, lack of diversity, and
underrepresentation.

摘要：人工智慧 (AI) 技術在醫學影像方面的發展需要取得大規模且多元的資料集，以進行訓練和評估。在皮膚科中，取得此類資料集仍然具有挑戰性，原因在於患者族群、照明條件和取得系統特性有顯著的變化。在這項工作中，我們提出 S-SYNTH，這是第一個基於知識、可適應的開放原始碼皮膚模擬架構，可使用解剖學啟發的多層、多組成皮膚和生長病灶模型，快速產生合成皮膚、3D 模型和數位渲染影像。皮膚模型允許控制皮膚外觀的變化，例如膚色、毛髮存在、病灶形狀和血液比例等參數。我們使用這個架構來研究可能的變化對皮膚病灶分割 AI 模型的開發和評估的影響，並顯示使用合成資料取得的結果遵循與真實皮膚科影像類似的比較趨勢，同時減輕現有資料集的偏差和限制，包括資料集規模小、缺乏多元性以及代表性不足。

##### **A Taxonomy of Stereotype Content in Large Language Models**
2408.00162v1 by Gandalf Nicolas, Aylin Caliskan

This study introduces a taxonomy of stereotype content in contemporary large
language models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three
powerful and widely used LLMs, for the characteristics associated with 87
social categories (e.g., gender, race, occupations). We identify 14 stereotype
dimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for
~90% of LLM stereotype associations. Warmth and Competence facets were the most
frequent content, but all other dimensions were significantly prevalent.
Stereotypes were more positive in LLMs (vs. humans), but there was significant
variability across categories and dimensions. Finally, the taxonomy predicted
the LLMs' internal evaluations of social categories (e.g., how
positively/negatively the categories were represented), supporting the
relevance of a multidimensional taxonomy for characterizing LLM stereotypes.
Our findings suggest that high-dimensional human stereotypes are reflected in
LLMs and must be considered in AI auditing and debiasing to minimize
unidentified harms from reliance in low-dimensional views of bias in LLMs.

摘要：本研究針對當代大型語言模型 (LLM) 中的刻板印象內容進行分類。我們提示 ChatGPT 3.5、Llama 3 和 Mixtral 8x7B 這三種強大且廣泛使用的 LLM，了解與 87 個社會類別（例如性別、種族、職業）相關的特徵。我們識別出 14 個刻板印象面向（例如道德、能力、健康、信仰、情緒），約佔 LLM 刻板印象關聯的 90%。溫暖和能力面向是最頻繁的內容，但所有其他面向都很普遍。LLM 中的刻板印象比人類更正面，但不同類別和面向之間存在顯著差異。最後，分類法預測了 LLM 對社會類別的內部評估（例如類別的正面/負面呈現方式），支持了使用多維分類法來表徵 LLM 刻板印象的相關性。我們的研究結果表明，高維度的人類刻板印象反映在 LLM 中，並且必須在 AI 稽核和消除偏見中加以考慮，以將依賴 LLM 中偏見的低維度觀點造成的未識別危害降到最低。

##### **Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)**
2408.00108v2 by Adam Gould, Guilherme Paulino-Passos, Seema Dadhania, Matthew Williams, Francesca Toni

In the pursuit of enhancing the efficacy and flexibility of interpretable,
data-driven classification models, this work introduces a novel incorporation
of user-defined preferences with Abstract Argumentation and Case-Based
Reasoning (CBR). Specifically, we introduce Preference-Based Abstract
Argumentation for Case-Based Reasoning (which we call AA-CBR-P), allowing users
to define multiple approaches to compare cases with an ordering that specifies
their preference over these comparison approaches. We prove that the model
inherently follows these preferences when making predictions and show that
previous abstract argumentation for case-based reasoning approaches are
insufficient at expressing preferences over constituents of an argument. We
then demonstrate how this can be applied to a real-world medical dataset
sourced from a clinical trial evaluating differing assessment methods of
patients with a primary brain tumour. We show empirically that our approach
outperforms other interpretable machine learning models on this dataset.

摘要：為了提升可解釋、資料驅動分類模型的效能和靈活性，此研究引入了使用者自訂偏好與抽象論證和案例基礎推理 (CBR) 的新結合。具體來說，我們引入了案例基礎推理的偏好基礎抽象論證 (我們稱之為 AA-CBR-P)，允許使用者定義多種方法來比較案例，並透過排序來指定他們對這些比較方法的偏好。我們證明了此模型在進行預測時會自然遵循這些偏好，並顯示先前案例基礎推理的抽象論證方法不足以表達對論證組成的偏好。然後，我們展示了如何將此方法應用於實際的醫療資料集，該資料集來自評估原發性腦腫瘤患者不同評估方法的臨床試驗。我們經驗性地證明，我們的做法在這個資料集上優於其他可解釋的機器學習模型。

##### **A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**
2407.21739v1 by Mothilal Asokan, Joseph Geo Benjamin, Mohammad Yaqub, Karthik Nandakumar

Adapting foundation models for medical image analysis requires finetuning
them on a considerable amount of data because of extreme distribution shifts
between natural (source) data used for pretraining and medical (target) data.
However, collecting task-specific medical data for such finetuning at a central
location raises many privacy concerns. Although Federated learning (FL)
provides an effective means for training on private decentralized data,
communication costs in federating large foundation models can quickly become a
significant bottleneck, impacting the solution's scalability. In this work, we
address this problem of efficient communication while ensuring effective
learning in FL by combining the strengths of Parameter-Efficient Fine-tuning
(PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA)
in a federated manner to adapt the Segment Anything Model (SAM) for 3D medical
image segmentation. Unlike prior works that utilize LoRA and finetune the
entire decoder, we critically analyze the contribution of each granular
component of SAM on finetuning performance. Thus, we identify specific layers
to be federated that are very efficient in terms of communication cost while
producing on-par accuracy. Our experiments show that retaining the parameters
of the SAM model (including most of the decoder) in their original state during
adaptation is beneficial because fine-tuning on small datasets tends to distort
the inherent capabilities of the underlying foundation model. On Fed-KiTS, our
approach decreases communication cost (~48x) compared to full fine-tuning while
increasing performance (~6% Dice score) in 3D segmentation tasks. Our approach
performs similar to SAMed while achieving ~2.8x reduction in communication and
parameters to be finetuned. We further validate our approach with experiments
on Fed-IXI and Prostate MRI datasets.

摘要：<paragraph>由於預訓練所用的自然（來源）資料和醫療（目標）資料之間的極端分佈轉移，因此將基礎模型調整用於醫學影像分析需要在大量資料上對其進行微調。
然而，在中心位置收集此類微調的特定任務醫療資料會引發許多隱私問題。儘管聯合學習 (FL) 提供了一種在私有分散式資料上進行訓練的有效方法，但在聯合大型基礎模型時，通訊成本可能會迅速成為一個重大瓶頸，影響解決方案的可擴充性。在這項工作中，我們通過結合參數高效微調 (PEFT) 和 FL 的優勢，解決了在確保 FL 中有效學習的同時進行高效通訊的問題。具體來說，我們以聯合的方式研究即插即用低秩適配器 (LoRA)，以調整區段任何模型 (SAM) 以進行 3D 醫學影像分割。與利用 LoRA 和微調整個解碼器的先前工作不同，我們批判性地分析了 SAM 的每個粒狀組成部分對微調效能的貢獻。因此，我們確定了在通訊成本方面非常高效的特定層，同時產生了同等的準確度。我們的實驗表明，在調整過程中將 SAM 模型的參數（包括大部分解碼器）保留在其原始狀態是有益的，因為在小型資料集上進行微調往往會扭曲基礎模型的內在能力。在 Fed-KiTS 上，與完全微調相比，我們的做法降低了通訊成本（約 48 倍），同時提高了 3D 分割任務中的效能（約 6% 的骰子分數）。我們的做法與 SAMed 類似，同時將通訊和待微調參數減少了約 2.8 倍。我們進一步通過在 Fed-IXI 和 Prostate MRI 資料集上進行實驗驗證了我們的做法。</paragraph>

##### **Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**
2407.21674v1 by Krishan Agyakari Raja Babu, Rachana Sathish, Mrunal Pattanaik, Rahul Venkataramani

Synthetic data is becoming increasingly integral in data-scarce fields such
as medical imaging, serving as a substitute for real data. However, its
inherent statistical characteristics can significantly impact downstream tasks,
potentially compromising deployment performance. In this study, we empirically
investigate this issue and uncover a critical phenomenon: downstream neural
networks often exploit spurious distinctions between real and synthetic data
when there is a strong correlation between the data source and the task label.
This exploitation manifests as \textit{simplicity bias}, where models overly
rely on superficial features rather than genuine task-related complexities.
Through principled experiments, we demonstrate that the source of data (real
vs.\ synthetic) can introduce spurious correlating factors leading to poor
performance during deployment when the correlation is absent. We first
demonstrate this vulnerability on a digit classification task, where the model
spuriously utilizes the source of data instead of the digit to provide an
inference. We provide further evidence of this phenomenon in a medical imaging
problem related to cardiac view classification in echocardiograms, particularly
distinguishing between 2-chamber and 4-chamber views. Given the increasing role
of utilizing synthetic datasets, we hope that our experiments serve as
effective guidelines for the utilization of synthetic datasets in model
training.

摘要：合成資料在資料稀少的領域中變得越來越不可或缺，例如醫學影像，用作真實資料的替代品。然而，其內在的統計特性會顯著影響下游任務，可能損害部署效能。在本研究中，我們實證調查此問題，並揭露一個關鍵現象：當資料來源與任務標籤之間有很強的相關性時，下游神經網路通常會利用真實資料與合成資料之間的虛假區別。這種利用表現為「簡化偏差」，其中模型過度依賴表面特徵，而不是真正的與任務相關的複雜性。透過有原則的實驗，我們證明資料來源（真實資料與合成資料）可能會引入虛假的相關因素，導致在相關性不存在時部署期間效能不佳。我們首先在數字分類任務中證明此漏洞，其中模型虛假地利用資料來源而非數字來提供推論。我們在與超音波心臟視野分類相關的醫學影像問題中進一步提供此現象的證據，特別是區分二腔和四腔視野。鑑於合成資料集的使用角色日益增加，我們希望我們的實驗能作為在模型訓練中利用合成資料集的有效指南。

##### **Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**
2407.21638v1 by Hermione Warr, Yasin Ibrahim, Daniel R. McGowan, Konstantinos Kamnitsas

Automation of medical image interpretation could alleviate bottlenecks in
diagnostic workflows, and has become of particular interest in recent years due
to advancements in natural language processing. Great strides have been made
towards automated radiology report generation via AI, yet ensuring clinical
accuracy in generated reports is a significant challenge, hindering deployment
of such methods in clinical practice. In this work we propose a quality control
framework for assessing the reliability of AI-generated radiology reports with
respect to semantics of diagnostic importance using modular auxiliary auditing
components (AC). Evaluating our pipeline on the MIMIC-CXR dataset, our findings
show that incorporating ACs in the form of disease-classifiers can enable
auditing that identifies more reliable reports, resulting in higher F1 scores
compared to unfiltered generated reports. Additionally, leveraging the
confidence of the AC labels further improves the audit's effectiveness.

摘要：醫療影像判讀的自動化可以減輕診斷工作流程中的瓶頸，並且由於自然語言處理的進步，在近年來特別受到重視。在透過 AI 自動生成放射線報告方面已經取得了長足的進展，然而確保生成報告的臨床準確性是一項重大的挑戰，阻礙了此類方法在臨床實務中的部署。在這項工作中，我們提出了一個品質控制架構，用於評估 AI 生成的放射線報告的可靠性，並使用模組化輔助稽核元件 (AC) 針對診斷重要性的語義進行評估。在 MIMIC-CXR 資料集上評估我們的管道，我們的發現顯示，以疾病分類器的形式納入 AC 可以啟用稽核，以識別更可靠的報告，與未經篩選的生成報告相比，會產生更高的 F1 分數。此外，進一步利用 AC 標籤的信心可以提高稽核的有效性。

##### **Optimizing Disease Prediction with Artificial Intelligence Driven Feature Selection and Attention Networks**
2408.03151v1 by D. Dhinakaran, S. Edwin Raja, M. Thiyagarajan, J. Jeno Jasmine, P. Raghavan

The rapid integration of machine learning methodologies in healthcare has
ignited innovative strategies for disease prediction, particularly with the
vast repositories of Electronic Health Records (EHR) data. This article delves
into the realm of multi-disease prediction, presenting a comprehensive study
that introduces a pioneering ensemble feature selection model. This model,
designed to optimize learning systems, combines statistical, deep, and
optimally selected features through the innovative Stabilized Energy Valley
Optimization with Enhanced Bounds (SEV-EB) algorithm. The objective is to
achieve unparalleled accuracy and stability in predicting various disorders.
This work proposes an advanced ensemble model that synergistically integrates
statistical, deep, and optimally selected features. This combination aims to
enhance the predictive power of the model by capturing diverse aspects of the
health data. At the heart of the proposed model lies the SEV-EB algorithm, a
novel approach to optimal feature selection. The algorithm introduces enhanced
bounds and stabilization techniques, contributing to the robustness and
accuracy of the overall prediction model. To further elevate the predictive
capabilities, an HSC-AttentionNet is introduced. This network architecture
combines deep temporal convolution capabilities with LSTM, allowing the model
to capture both short-term patterns and long-term dependencies in health data.
Rigorous evaluations showcase the remarkable performance of the proposed model.
Achieving a 95% accuracy and 94% F1-score in predicting various disorders, the
model surpasses traditional methods, signifying a significant advancement in
disease prediction accuracy. The implications of this research extend beyond
the confines of academia.

摘要：<paragraph>機器學習方法在醫療保健領域的快速整合，點燃了疾病預測的創新策略，特別是電子健康記錄 (EHR) 資料的龐大儲存庫。本文深入探討多疾病預測的領域，提出了一項全面的研究，介紹了一個開創性的集成特徵選擇模型。這個模型旨在優化學習系統，結合統計、深度和最佳選擇的特徵，透過創新的穩定能量谷優化與增強邊界 (SEV-EB) 演算法。目標是在預測各種疾病時達到無與倫比的準確性和穩定性。這項研究提出了一個先進的集成模型，協同整合統計、深度和最佳選擇的特徵。這種組合旨在透過擷取健康資料的不同面向，來增強模型的預測能力。所提出的模型核心在於 SEV-EB 演算法，一種最佳特徵選擇的新方法。該演算法引入了增強的邊界和穩定技術，有助於整體預測模型的穩健性和準確性。為了進一步提升預測能力，引入了 HSC-AttentionNet。這個網路架構結合了深度時間卷積功能與 LSTM，使模型能夠擷取健康資料中的短期模式和長期依賴性。嚴謹的評估展示了所提出模型的卓越效能。在預測各種疾病時達到 95% 的準確度和 94% 的 F1 分數，該模型超越了傳統方法，標誌著疾病預測準確性的重大進展。這項研究的意義超越了學術界。</paragraph>

##### **Voxel Scene Graph for Intracranial Hemorrhage**
2407.21580v1 by Antoine P. Sanner, Nils F. Grauhan, Marc A. Brockmann, Ahmed E. Othman, Anirban Mukhopadhyay

Patients with Intracranial Hemorrhage (ICH) face a potentially
life-threatening condition, and patient-centered individualized treatment
remains challenging due to possible clinical complications. Deep-Learning-based
methods can efficiently analyze the routinely acquired head CTs to support the
clinical decision-making. The majority of early work focuses on the detection
and segmentation of ICH, but do not model the complex relations between ICH and
adjacent brain structures. In this work, we design a tailored object detection
method for ICH, which we unite with segmentation-grounded Scene Graph
Generation (SGG) methods to learn a holistic representation of the clinical
cerebral scene. To the best of our knowledge, this is the first application of
SGG for 3D voxel images. We evaluate our method on two head-CT datasets and
demonstrate that our model can recall up to 74% of clinically relevant
relations. This work lays the foundation towards SGG for 3D voxel data. The
generated Scene Graphs can already provide insights for the clinician, but are
also valuable for all downstream tasks as a compact and interpretable
representation.

摘要：腦出血 (ICH) 患者面臨可能危及生命的狀況，由於可能的臨床併發症，以患者為中心的個人化治療仍然具有挑戰性。基於深度學習的方法可以有效分析常規獲得的頭部電腦斷層掃描，以支持臨床決策制定。大多數早期工作都集中在 ICH 的檢測和分割，但沒有對 ICH 和相鄰大腦結構之間的複雜關係進行建模。在這項工作中，我們設計了一種針對 ICH 的客製化目標檢測方法，我們將其與基於分割的場景圖生成 (SGG) 方法結合，以學習臨床腦部場景的整體表徵。據我們所知，這是 SGG 第一次應用於 3D 體素影像。我們在兩個頭部電腦斷層掃描數據集上評估我們的模型，並證明我們的模型可以召回高達 74% 的臨床相關關係。這項工作為 3D 體素數據的 SGG 奠定了基礎。生成的場景圖已經可以為臨床醫生提供見解，但對於所有下游任務而言，它也是一種精簡且可解釋的表徵，因此非常有價值。

##### **Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**
2407.21516v1 by I. M. Chernenkiy, Y. A. Drach, S. R. Mustakimova, V. V. Kazantseva, N. A. Ushakov, S. K. Efetov, M. V. Feldsherov

Colorectal cancer is the third-most common cancer in the Western Hemisphere.
The segmentation of colorectal and colorectal cancer by computed tomography is
an urgent problem in medicine. Indeed, a system capable of solving this problem
will enable the detection of colorectal cancer at early stages of the disease,
facilitate the search for pathology by the radiologist, and significantly
accelerate the process of diagnosing the disease. However, scientific
publications on medical image processing mostly use closed, non-public data.
This paper presents an extension of the Medical Decathlon dataset with
colorectal markups in order to improve the quality of segmentation algorithms.
An experienced radiologist validated the data, categorized it into subsets by
quality, and published it in the public domain. Based on the obtained results,
we trained neural network models of the UNet architecture with 5-part
cross-validation and achieved a Dice metric quality of $0.6988 \pm 0.3$. The
published markups will improve the quality of colorectal cancer detection and
simplify the radiologist's job for study description.

摘要：大腸癌是西半球第三常見的癌症。
利用電腦斷層掃描對大腸癌與大腸癌進行分段是醫學上的緊急問題。事實上，一個能夠解決這個問題的系統將能夠在疾病的早期階段偵測大腸癌，協助放射科醫師尋找病理，並顯著加速診斷疾病的過程。然而，關於醫學影像處理的科學刊物大多使用封閉、非公開的資料。這篇論文提出了一個帶有大腸標記的醫學十項全能資料集的延伸，以提高分段演算法的品質。一位經驗豐富的放射科醫師驗證了資料，將其依品質分類成子集，並將其發布在公共領域。根據獲得的結果，我們訓練了具有 5 部分交叉驗證的 UNet 架構的神經網路模型，並達到了 $0.6988 \pm 0.3$ 的 Dice 指標品質。發布的標記將提高大腸癌偵測的品質，並簡化放射科醫師研究描述的工作。

##### **Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**
2407.21490v1 by Junxuan Yu, Rusi Chen, Yongsong Zhou, Yanlin Chen, Yaofei Duan, Yuhao Huang, Han Zhou, Tan Tao, Xin Yang, Dong Ni

Echocardiography video is a primary modality for diagnosing heart diseases,
but the limited data poses challenges for both clinical teaching and machine
learning training. Recently, video generative models have emerged as a
promising strategy to alleviate this issue. However, previous methods often
relied on holistic conditions during generation, hindering the flexible
movement control over specific cardiac structures. In this context, we propose
an explainable and controllable method for echocardiography video generation,
taking an initial frame and a motion curve as guidance. Our contributions are
three-fold. First, we extract motion information from each heart substructure
to construct motion curves, enabling the diffusion model to synthesize
customized echocardiography videos by modifying these curves. Second, we
propose the structure-to-motion alignment module, which can map semantic
features onto motion curves across cardiac structures. Third, The
position-aware attention mechanism is designed to enhance video consistency
utilizing Gaussian masks with structural position information. Extensive
experiments on three echocardiography datasets show that our method outperforms
others regarding fidelity and consistency. The full code will be released at
https://github.com/mlmi-2024-72/ECM.

摘要：超音波心動圖影片是診斷心臟疾病的主要方式，
但有限的數據對臨床教學和機器學習訓練都構成挑戰。最近，影片生成模型已成為緩解此問題的一種有前途的策略。然而，先前的辦法在生成過程中通常依賴整體條件，阻礙了對特定心臟結構的靈活運動控制。在此背景下，我們提出了一種可解釋且可控的超音波心動圖影片生成方法，以初始幀和運動曲線作為指導。我們的貢獻有三方面。首先，我們從每個心臟子結構中提取運動資訊以建構運動曲線，讓擴散模型能夠透過修改這些曲線來合成客製化的超音波心動圖影片。其次，我們提出了結構到運動對齊模組，它可以將語義特徵對應到心臟結構中的運動曲線。第三，位置感知注意力機制旨在利用具有結構位置資訊的高斯遮罩來增強影片的一致性。在三個超音波心動圖資料集上的廣泛實驗顯示，我們的辦法在保真度和一致性方面優於其他辦法。完整程式碼將在 https://github.com/mlmi-2024-72/ECM 上釋出。

##### **Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data**
2407.21467v1 by Mengtian Kang, Yansong Hu, Shuo Gao, Yuanyuan Liu, Hongbei Meng, Xuemeng Li, Xuhang Chen, Hubin Zhao, Jing Fu, Guohua Hu, Wei Wang, Yanning Dai, Arokia Nathan, Peter Smielewski, Ningli Wang, Shiming Li

Childhood myopia constitutes a significant global health concern. It exhibits
an escalating prevalence and has the potential to evolve into severe,
irreversible conditions that detrimentally impact familial well-being and
create substantial economic costs. Contemporary research underscores the
importance of precisely predicting myopia progression to enable timely and
effective interventions, thereby averting severe visual impairment in children.
Such predictions predominantly rely on subjective clinical assessments, which
are inherently biased and resource-intensive, thus hindering their widespread
application. In this study, we introduce a novel, high-accuracy method for
quantitatively predicting the myopic trajectory and myopia risk in children
using only fundus images and baseline refraction data. This approach was
validated through a six-year longitudinal study of 3,408 children in Henan,
utilizing 16,211 fundus images and corresponding refractive data. Our method
based on deep learning demonstrated predictive accuracy with an error margin of
0.311D per year and AUC scores of 0.944 and 0.995 for forecasting the risks of
developing myopia and high myopia, respectively. These findings confirm the
utility of our model in supporting early intervention strategies and in
significantly reducing healthcare costs, particularly by obviating the need for
additional metadata and repeated consultations. Furthermore, our method was
designed to rely only on fundus images and refractive error data, without the
need for meta data or multiple inquiries from doctors, strongly reducing the
associated medical costs and facilitating large-scale screening. Our model can
even provide good predictions based on only a single time measurement.
Consequently, the proposed method is an important means to reduce medical
inequities caused by economic disparities.

摘要：兒童近視構成全球重要的健康問題。它顯示出日益增加的盛行率，並可能演變成嚴重、不可逆轉的狀況，對家庭福祉造成不利影響，並產生大量的經濟成本。現代研究強調精準預測近視進展的重要性，以實現及時有效的干預，從而避免兒童出現嚴重的視力損害。此類預測主要依賴主觀的臨床評估，其本身具有偏見且資源密集，從而阻礙了它們的廣泛應用。在本研究中，我們引入了一種新穎、高精確度的方法，僅使用眼底圖像和基線屈光數據，就能定量預測兒童的近視軌跡和近視風險。這種方法通過對河南省 3,408 名兒童進行為期六年的縱向研究，利用 16,211 張眼底圖像和相應的屈光數據進行了驗證。我們基於深度學習的方法展示了預測準確度，年誤差範圍為 0.311D，預測發生近視和高度近視的風險的 AUC 分數分別為 0.944 和 0.995。這些發現證實了我們的模型在支持早期干預策略和顯著降低醫療保健成本方面的效用，特別是通過消除對額外元數據和重複諮詢的需要。此外，我們的方法被設計為僅依賴眼底圖像和屈光不正數據，而無需元數據或醫生的多次詢問，從而大大降低了相關的醫療成本，並促進了大規模篩查。我們的模型甚至可以僅根據單次時間測量提供良好的預測。因此，所提出的方法是減少由經濟差距造成的醫療不平等的重要手段。

##### **Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering**
2407.21368v1 by Danfeng Guo, Demetri Terzopoulos

Large Vision-Language Models (LVLMs) have achieved significant success in
recent years, and they have been extended to the medical domain. Although
demonstrating satisfactory performance on medical Visual Question Answering
(VQA) tasks, Medical LVLMs (MLVLMs) suffer from the hallucination problem,
which makes them fail to diagnose complex pathologies. Moreover, they readily
fail to learn minority pathologies due to imbalanced training data. We propose
two prompting strategies for MLVLMs that reduce hallucination and improve VQA
performance. In the first strategy, we provide a detailed explanation of the
queried pathology. In the second strategy, we fine-tune a cheap, weak learner
to achieve high performance on a specific metric, and textually provide its
judgment to the MLVLM. Tested on the MIMIC-CXR-JPG and Chexpert datasets, our
methods significantly improve the diagnostic F1 score, with the highest
increase being 0.27. We also demonstrate that our prompting strategies can be
extended to general LVLM domains. Based on POPE metrics, it effectively
suppresses the false negative predictions of existing LVLMs and improves Recall
by approximately 0.07.

摘要：大型視覺語言模型 (LVLMs) 在近年來取得顯著的成功，並已擴展到醫療領域。儘管在醫學視覺問答 (VQA) 任務中表現令人滿意，但醫學 LVLMs (MLVLMs) 仍存在幻覺問題，導致它們無法診斷出複雜的病理。此外，由於訓練資料不平衡，它們很容易無法學習少數病理。我們提出兩種針對 MLVLMs 的提示策略，以減少幻覺並改善 VQA 效能。在第一個策略中，我們提供查詢病理的詳細說明。在第二個策略中，我們微調一個便宜、效能不佳的學習器，以在特定指標上獲得高效能，並以文字方式向 MLVLM 提供其判斷。在 MIMIC-CXR-JPG 和 Chexpert 資料集上進行測試後，我們的模型顯著改善了診斷 F1 分數，最高提升幅度為 0.27。我們還展示了我們的提示策略可以擴展到一般的 LVLM 領域。根據 POPE 指標，它有效地抑制了現有 LVLMs 的假陰性預測，並將召回率提高了約 0.07。

##### **MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework**
2407.21343v1 by Adrian Celaya, Evan Lim, Rachel Glenn, Brayden Mi, Alex Balsells, Tucker Netherton, Caroline Chung, Beatrice Riviere, David Fuentes

Medical imaging segmentation is a highly active area of research, with deep
learning-based methods achieving state-of-the-art results in several
benchmarks. However, the lack of standardized tools for training, testing, and
evaluating new methods makes the comparison of methods difficult. To address
this, we introduce the Medical Imaging Segmentation Toolkit (MIST), a simple,
modular, and end-to-end medical imaging segmentation framework designed to
facilitate consistent training, testing, and evaluation of deep learning-based
medical imaging segmentation methods. MIST standardizes data analysis,
preprocessing, and evaluation pipelines, accommodating multiple architectures
and loss functions. This standardization ensures reproducible and fair
comparisons across different methods. We detail MIST's data format
requirements, pipelines, and auxiliary features and demonstrate its efficacy
using the BraTS Adult Glioma Post-Treatment Challenge dataset. Our results
highlight MIST's ability to produce accurate segmentation masks and its
scalability across multiple GPUs, showcasing its potential as a powerful tool
for future medical imaging research and development.

摘要：醫學影像分割是一個高度活躍的研究領域，深度學習方法在多個基準測試中取得了最先進的成果。然而，缺乏標準化的訓練、測試和評估新方法的工具，使得方法的比較變得困難。為了解決這個問題，我們引入了醫學影像分割工具包 (MIST)，一個簡單、模組化和端對端的醫學影像分割框架，旨在促進基於深度學習的醫學影像分割方法的一致訓練、測試和評估。MIST 標準化了數據分析、預處理和評估管道，容納多種架構和損失函數。這種標準化確保了不同方法之間可重現且公平的比較。我們詳細說明了 MIST 的數據格式要求、管道和輔助功能，並使用 BraTS 成人神經膠質瘤治療後挑戰數據集展示了它的功效。我們的結果突顯了 MIST 產生準確分割遮罩的能力以及它跨多個 GPU 的可擴展性，展示了它作為未來醫學影像研究和開發的有力工具的潛力。

##### **Patient-centered data science: an integrative framework for evaluating and predicting clinical outcomes in the digital health era**
2408.02677v1 by Mohsen Amoei, Dan Poenaru

This study proposes a novel, integrative framework for patient-centered data
science in the digital health era. We developed a multidimensional model that
combines traditional clinical data with patient-reported outcomes, social
determinants of health, and multi-omic data to create comprehensive digital
patient representations. Our framework employs a multi-agent artificial
intelligence approach, utilizing various machine learning techniques including
large language models, to analyze complex, longitudinal datasets. The model
aims to optimize multiple patient outcomes simultaneously while addressing
biases and ensuring generalizability. We demonstrate how this framework can be
implemented to create a learning healthcare system that continuously refines
strategies for optimal patient care. This approach has the potential to
significantly improve the translation of digital health innovations into
real-world clinical benefits, addressing current limitations in AI-driven
healthcare models.

摘要：本研究提出了一個創新的、整合性的架構，用於數位健康時代的以患者為中心的資料科學。我們開發了一個多面向模型，結合傳統的臨床資料、患者回報的結果、健康的社會決定因素和多組學資料，以建立全面的數位患者表徵。我們的架構採用多主體人工智慧方法，利用各種機器學習技術，包括大型語言模型，來分析複雜的縱向資料集。該模型旨在同時最佳化多個患者結果，同時解決偏差並確保可概化性。我們展示了如何實作此架構，以建立一個持續優化最佳患者照護策略的學習型醫療保健系統。此方法有可能顯著改善數位健康創新的轉譯，使其成為真實世界的臨床效益，解決 AI 驅動的醫療保健模型中的當前限制。

##### **Robust Box Prompt based SAM for Medical Image Segmentation**
2407.21284v1 by Yuhao Huang, Xin Yang, Han Zhou, Yan Cao, Haoran Dou, Fajin Dong, Dong Ni

The Segment Anything Model (SAM) can achieve satisfactory segmentation
performance under high-quality box prompts. However, SAM's robustness is
compromised by the decline in box quality, limiting its practicality in
clinical reality. In this study, we propose a novel Robust Box prompt based SAM
(\textbf{RoBox-SAM}) to ensure SAM's segmentation performance under prompts
with different qualities. Our contribution is three-fold. First, we propose a
prompt refinement module to implicitly perceive the potential targets, and
output the offsets to directly transform the low-quality box prompt into a
high-quality one. We then provide an online iterative strategy for further
prompt refinement. Second, we introduce a prompt enhancement module to
automatically generate point prompts to assist the box-promptable segmentation
effectively. Last, we build a self-information extractor to encode the prior
information from the input image. These features can optimize the image
embeddings and attention calculation, thus, the robustness of SAM can be
further enhanced. Extensive experiments on the large medical segmentation
dataset including 99,299 images, 5 modalities, and 25 organs/targets validated
the efficacy of our proposed RoBox-SAM.

摘要：分段任何模型 (SAM) 可以在高质量框提示下实现令人满意的分段性能。然而，SAM 的鲁棒性因框质量的下降而受到损害，限制了其在临床现实中的实用性。在这项研究中，我们提出了一个基于 SAM 的新型鲁棒框提示（**RoBox-SAM**），以确保 SAM 在具有不同质量的提示下的分段性能。我们的贡献是三方面的。首先，我们提出一个提示优化模块，以隐式感知潜在目标，并输出偏移量，以直接将低质量框提示转换为高质量提示。然后，我们提供了一个在线迭代策略，以便进一步优化提示。其次，我们引入了一个提示增强模块，以自动生成点提示，以有效地辅助框提示分段。最后，我们构建了一个自信息提取器，以对来自输入图像的先验信息进行编码。这些特征可以优化图像嵌入和注意力计算，因此，可以进一步增强 SAM 的鲁棒性。在包括 99,299 张图像、5 种方式和 25 个器官/目标的大型医学分段数据集上进行的广泛实验验证了我们提出的 RoBox-SAM 的功效。

##### **Unlocking the Potential of Binding Corporate Rules (BCRs) in Health Data Transfers**
2407.21281v1 by Marcelo Corrales Compagnucci, Mark Fenwick, Helena Haapio

This chapter explores the essential role of Binding Corporate Rules (BCRs) in
managing and facilitating secure health data transfers within corporate groups
under the EU General Data Protection Regulation (GDPR). BCRs are tailored to
ensure compliance with the GDPR and similar international data protection laws,
presenting a flexible mechanism for transferring sensitive health and genomic
data. The chapter situates BCRs within the broader spectrum of the GDPR
international data transfer mechanisms, addressing the unique challenges posed
by the sensitive nature of health data and the increased adoption of AI
technologies. The European Data Protection Board (EDPB) Recommendations 1/2022
on BCRs, issued following the Schrems II decision, are critically analyzed,
highlighting their stringent requirements and the need for a balanced approach
that prioritizes data protection and an AI governance framework. The chapter
outlines the BCR approval process, stressing the importance of streamlining
this process to encourage broader adoption. It underscores the necessity of a
multidisciplinary approach in developing BCRs, incorporating recently adopted
international standards and frameworks, which offer valuable guidance for
organizations to build trustworthy AI management systems. They guarantee the
ethical development, deployment, and operation of AI, which is essential for
its successful integration and the broader digital transformation. In
conclusion, BCRs are positioned as essential tools for secure health data
management, fostering transparency, accountability, and collaboration across
international borders. The chapter calls for proactive measures to incentivize
BCR adoption, streamline approval processes, and promote more innovative
approaches, ensuring BCRs remain a robust mechanism for global data protection
and compliance.

摘要：<paragraph>此章探討約束企業規則 (BCR) 在歐盟一般資料保護條例 (GDPR) 下管理和促進企業集團內部安全健康資料傳輸的基本角色。BCR 專門用於確保符合 GDPR 和類似的國際資料保護法，提供傳輸敏感健康和基因組資料的彈性機制。此章將 BCR 定位在 GDPR 國際資料傳輸機制的更廣泛範圍內，解決健康資料敏感性質和 AI 技術採用增加所帶來的獨特挑戰。歐洲資料保護委員會 (EDPB) 在 Schrems II 決定後發布的 BCR 建議 1/2022 受到嚴格分析，強調其嚴格要求和平衡方法的必要性，該方法優先考慮資料保護和 AI 治理架構。此章概述 BCR 核准程序，強調簡化此程序以鼓勵更廣泛採用的重要性。它強調在開發 BCR 時採用多學科方法的必要性，包括最近採用的國際標準和架構，這些標準和架構為組織建立可信賴的 AI 管理系統提供了寶貴的指導。它們保證 AI 的道德開發、部署和運作，這對其成功整合和更廣泛的數位轉型至關重要。結論是，BCR 被定位為安全健康資料管理的基本工具，促進跨國界的透明度、問責制和協作。此章呼籲採取積極措施來激勵 BCR 採用、簡化核准程序，並促進更具創新的方法，確保 BCR 仍然是全球資料保護和合規性的強大機制。</paragraph>

##### **FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations**
2407.21275v1 by Rujia Shen, Liangliang Liu, Boran Wang, Yi Guan, Yang Yang, Jingchi Jiang

Time series forecasting (TSF) is immensely important in extensive
applications, such as electricity transformation, financial trade, medical
monitoring, and smart agriculture. Although Transformer-based methods can
handle time series data, their ability to predict long-term time series is
limited due to the ``anti-order" nature of the self-attention mechanism. To
address this problem, we focus on frequency domain to weaken the impact of
order in TSF and propose the FreqBlock, where we first obtain frequency
representations through the Frequency Transform Module. Subsequently, a newly
designed Frequency Cross Attention is used to obtian enhanced frequency
representations between the real and imaginary parts, thus establishing a link
between the attention mechanism and the inherent Kramer-Kronig relations
(KKRs). Our backbone network, FreqTSF, adopts a residual structure by
concatenating multiple FreqBlocks to simulate KKRs in the frequency domain and
avoid degradation problems. On a theoretical level, we demonstrate that the
proposed two modules can significantly reduce the time and memory complexity
from $\mathcal{O}(L^2)$ to $\mathcal{O}(L)$ for each FreqBlock computation.
Empirical studies on four benchmark datasets show that FreqTSF achieves an
overall relative MSE reduction of 15\% and an overall relative MAE reduction of
11\% compared to the state-of-the-art methods. The code will be available soon.

摘要：時間序列預測 (TSF) 在廣泛的應用中非常重要，例如電力轉換、金融交易、醫療監控和智慧農業。雖然基於 Transformer 的方法可以處理時間序列資料，但由於自注意力機制的「反序」特性，它們預測長期時間序列的能力受到限制。為了解決這個問題，我們專注於頻域以減弱 TSF 中順序的影響，並提出 FreqBlock，我們首先透過頻率轉換模組取得頻率表示。隨後，使用新設計的頻率交叉注意力來獲得實部和虛部之間增強的頻率表示，從而建立注意力機制和固有 Kramer-Kronig 關係 (KKR) 之間的連結。我們的骨幹網路 FreqTSF 採用殘差結構，透過串接多個 FreqBlock 來模擬頻域中的 KKR 並避免退化問題。在理論層面上，我們證明所提出的兩個模組可以顯著降低每個 FreqBlock 計算的時間和記憶體複雜度，從 $\mathcal{O}(L^2)$ 降低到 $\mathcal{O}(L)$。在四個基準資料集上的實證研究顯示，與最先進的方法相比，FreqTSF 的整體相對 MSE 降低 15%，整體相對 MAE 降低 11%。程式碼將很快推出。

##### **Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net**
2407.21273v1 by Rohini Banerjee, Cecilia G. Morales, Artur Dubrawski

Efficient intravascular access in trauma and critical care significantly
impacts patient outcomes. However, the availability of skilled medical
personnel in austere environments is often limited. Autonomous robotic
ultrasound systems can aid in needle insertion for medication delivery and
support non-experts in such tasks. Despite advances in autonomous needle
insertion, inaccuracies in vessel segmentation predictions pose risks.
Understanding the uncertainty of predictive models in ultrasound imaging is
crucial for assessing their reliability. We introduce MSU-Net, a novel
multistage approach for training an ensemble of U-Nets to yield accurate
ultrasound image segmentation maps. We demonstrate substantial improvements,
18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model
transparency, and trustworthiness. By highlighting areas of model certainty,
MSU-Net can guide safe needle insertions, empowering non-experts to accomplish
such tasks.

摘要：在創傷和重症照護中，有效的血管內通路會顯著影響病患的治療結果。然而，在惡劣的環境中，熟練的醫療人員往往不足。自主機器人超音波系統可以協助針頭插入，以提供藥物並支援非專家執行此類任務。儘管自主針頭插入技術進步，但血管分割預測的不準確性會造成風險。了解超音波影像中預測模型的不確定性，對於評估其可靠性至關重要。我們引進 MSU-Net，這是一種新穎的多階段方法，用於訓練一組 U-Net 以產生準確的超音波影像分割圖。我們展示了大幅改善，比單一的蒙地卡羅 U-Net 改善了 18.1%，增強了不確定性評估、模型透明度和可信度。透過強調模型確定性的區域，MSU-Net 可以引導安全的針頭插入，讓非專家也能執行此類任務。

##### **Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population**
2407.21149v1 by Mayanka Chandrashekar, Ian Goethert, Md Inzamam Ul Haque, Benjamin McMahon, Sayera Dhaubhadel, Kathryn Knight, Joseph Erdos, Donna Reagan, Caroline Taylor, Peter Kuzmak, John Michael Gaziano, Eileen McAllister, Lauren Costa, Yuk-Lam Ho, Kelly Cho, Suzanne Tamang, Samah Fodeh-Jarad, Olga S. Ovchinnikova, Amy C. Justice, Jacob Hinkle, Ioana Danciu

Objectives: This study aims to assess the impact of domain shift on chest
X-ray classification accuracy and to analyze the influence of ground truth
label quality and demographic factors such as age group, sex, and study year.
Materials and Methods: We used a DenseNet121 model pretrained MIMIC-CXR dataset
for deep learning-based multilabel classification using ground truth labels
from radiology reports extracted using the CheXpert and CheXbert Labeler. We
compared the performance of the 14 chest X-ray labels on the MIMIC-CXR and
Veterans Healthcare Administration chest X-ray dataset (VA-CXR). The VA-CXR
dataset comprises over 259k chest X-ray images spanning between the years 2010
and 2022. Results: The validation of ground truth and the assessment of
multi-label classification performance across various NLP extraction tools
revealed that the VA-CXR dataset exhibited lower disagreement rates than the
MIMIC-CXR datasets. Additionally, there were notable differences in AUC scores
between models utilizing CheXpert and CheXbert. When evaluating multi-label
classification performance across different datasets, minimal domain shift was
observed in unseen datasets, except for the label "Enlarged Cardiomediastinum."
The study year's subgroup analyses exhibited the most significant variations in
multi-label classification model performance. These findings underscore the
importance of considering domain shifts in chest X-ray classification tasks,
particularly concerning study years. Conclusion: Our study reveals the
significant impact of domain shift and demographic factors on chest X-ray
classification, emphasizing the need for improved transfer learning and
equitable model development. Addressing these challenges is crucial for
advancing medical imaging and enhancing patient care.

摘要：<paragraph>目標：本研究旨在評估領域轉移對胸部 X 光分類精度的影響，並分析基本事實標籤品質和年齡組、性別和研究年份等人口因素的影響。
材料和方法：我們使用 DenseNet121 模型預訓練 MIMIC-CXR 資料集，使用從使用 CheXpert 和 CheXbert 標籤器從放射科報告中提取的基本事實標籤進行基於深度學習的多標籤分類。我們比較了 MIMIC-CXR 和退伍軍人健康管理局胸部 X 光資料集 (VA-CXR) 上 14 個胸部 X 光標籤的性能。VA-CXR 資料集包含超過 259k 張胸部 X 光影像，時間跨度為 2010 年至 2022 年。結果：基本事實的驗證和對各種 NLP 提取工具的多標籤分類性能的評估顯示，VA-CXR 資料集表現出的分歧率低於 MIMIC-CXR 資料集。此外，使用 CheXpert 和 CheXbert 的模型之間的 AUC 得分存在顯著差異。在評估不同資料集上的多標籤分類性能時，除了標籤「心縱隔增大」之外，在未見資料集中觀察到的領域轉移很小。研究年份的子群分析顯示，多標籤分類模型性能變化最大。這些發現強調了在胸部 X 光分類任務中考慮領域轉移的重要性，特別是關於研究年份。結論：我們的研究揭示了領域轉移和人口因素對胸部 X 光分類的顯著影響，強調了改進遷移學習和公平模型開發的必要性。應對這些挑戰對於推進醫學影像和加強患者護理至關重要。</paragraph>

##### **Zero Shot Health Trajectory Prediction Using Transformer**
2407.21124v1 by Pawel Renc, Yugang Jia, Anthony E. Samir, Jaroslaw Was, Quanzheng Li, David W. Bates, Arkadiusz Sitek

Integrating modern machine learning and clinical decision-making has great
promise for mitigating healthcare's increasing cost and complexity. We
introduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a
novel application of the transformer deep-learning architecture for analyzing
high-dimensional, heterogeneous, and episodic health data. ETHOS is trained
using Patient Health Timelines (PHTs)-detailed, tokenized records of health
events-to predict future health trajectories, leveraging a zero-shot learning
approach. ETHOS represents a significant advancement in foundation model
development for healthcare analytics, eliminating the need for labeled data and
model fine-tuning. Its ability to simulate various treatment pathways and
consider patient-specific factors positions ETHOS as a tool for care
optimization and addressing biases in healthcare delivery. Future developments
will expand ETHOS' capabilities to incorporate a wider range of data types and
data sources. Our work demonstrates a pathway toward accelerated AI development
and deployment in healthcare.

摘要：整合現代機器學習與臨床決策制定對於減輕醫療保健日益增加的成本和複雜性具有很大的前景。我們引入了健康結果模擬的增強式Transformer（ETHOS），這是一種Transformer深度學習架構的新穎應用，用於分析高維、異質且情節性的健康數據。ETHOS 使用患者健康時間軸 (PHT) 進行訓練，PHT 是健康事件的詳細、標記化記錄，用於預測未來的健康軌跡，並利用零次學習方法。ETHOS 代表了醫療保健分析基礎模型開發的重大進展，消除了對標記數據和模型微調的需求。它模擬各種治療途徑並考慮患者特定因素的能力，使 ETHOS 成為優化照護和解決醫療保健提供中偏差的工具。未來的發展將擴展 ETHOS 的功能，以納入更廣泛的數據類型和數據來源。我們的研究展示了一條加速醫療保健中 AI 開發和部署的途徑。

##### **CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**
2407.21011v1 by Yuexi Du, Brian Chang, Nicha C. Dvornek

Recent advancements in Contrastive Language-Image Pre-training (CLIP) have
demonstrated notable success in self-supervised representation learning across
various tasks. However, the existing CLIP-like approaches often demand
extensive GPU resources and prolonged training times due to the considerable
size of the model and dataset, making them poor for medical applications, in
which large datasets are not always common. Meanwhile, the language model
prompts are mainly manually derived from labels tied to images, potentially
overlooking the richness of information within training samples. We introduce a
novel language-image Contrastive Learning method with an Efficient large
language model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of
the extensive pre-trained language and visual models. Furthermore, we present
an efficient strategy for learning context-based prompts that mitigates the gap
between informative clinical diagnostic data and simple class labels. Our
method demonstrates state-of-the-art performance on multiple chest X-ray and
mammography datasets compared with various baselines. The proposed parameter
efficient framework can reduce the total trainable model size by 39% and reduce
the trainable language model to only 4% compared with the current BERT encoder.

摘要：對比語言影像預訓練 (CLIP) 的最新進展已展現出在各項任務中以自我監督表徵學習獲得顯著成功的成果。然而，現有的 CLIP 類似方法通常需要大量的 GPU 資源和漫長的訓練時間，因為模型和資料集的規模龐大，這使得它們不適合醫療應用，因為醫療應用中並不總是會有大型資料集。同時，語言模型提示主要來自與影像相關的標籤，而手動衍生，這可能會忽略訓練樣本中豐富的資訊。我們提出一個新穎的語言影像對比學習方法，其中包含一個高效的大語言模型和提示微調 (CLEFT)，它利用了廣泛預訓練的語言和視覺模型的優勢。此外，我們提出一個學習基於脈絡提示的有效策略，以縮小資訊豐富的臨床診斷資料和簡單類別標籤之間的差距。與各種基準相比，我們的模型在多個胸部 X 光和乳房攝影資料集上展現出最先進的效能。所提出的參數有效架構可以將總體可訓練模型大小減少 39%，並將可訓練語言模型減少到僅 4%，與目前的 BERT 編碼器相比。

##### **Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**
2407.20830v1 by Eugenio Lomurno, Matteo Matteucci

Federated learning has emerged as a paradigm for collaborative learning,
enabling the development of robust models without the need to centralise
sensitive data. However, conventional federated learning techniques have
privacy and security vulnerabilities due to the exposure of models, parameters
or updates, which can be exploited as an attack surface. This paper presents
Federated Knowledge Recycling (FedKR), a cross-silo federated learning approach
that uses locally generated synthetic data to facilitate collaboration between
institutions. FedKR combines advanced data generation techniques with a dynamic
aggregation process to provide greater security against privacy attacks than
existing methods, significantly reducing the attack surface. Experimental
results on generic and medical datasets show that FedKR achieves competitive
performance, with an average improvement in accuracy of 4.24% compared to
training models from local data, demonstrating particular effectiveness in data
scarcity scenarios.

摘要：聯邦學習已成為協作學習的典範，
無需集中敏感資料即可開發穩健模型。然而，由於模型、參數
或更新的公開，傳統的聯邦學習技術具有隱私和安全漏洞，可用作攻擊面。本文提出
聯邦知識再利用 (FedKR)，一種跨孤島的聯邦學習方法
使用本地生成的合成資料來促進
機構之間的合作。FedKR 將先進的資料生成技術與動態
聚合過程相結合，以提供比
現有方法更能抵禦隱私攻擊的安全保障，大幅縮小攻擊面。實驗
結果顯示，在一般和醫療資料集上，FedKR 達到競爭力
表現，與訓練模型相比，準確率平均提升 4.24%
來自本地資料，在資料稀缺的情況下展現出特別的有效性。

##### **Interpretable Pre-Trained Transformers for Heart Time-Series Data**
2407.20775v2 by Harry J. Davies, James Monsen, Danilo P. Mandic

Decoder-only transformers are the backbone of the popular generative
pre-trained transformer (GPT) series of large language models. In this work, we
employ this framework to the analysis of clinical heart time-series data, to
create two pre-trained general purpose cardiac models, termed PPG-PT and
ECG-PT. We place a special emphasis on making both such pre-trained models
fully interpretable. This is achieved firstly through aggregate attention maps
which show that, in order to make predictions, the model focuses on similar
points in previous cardiac cycles and gradually broadens its attention in
deeper layers. Next, we show that tokens with the same value, which occur at
different distinct points in the electrocardiography (ECG) and
photoplethysmography (PPG) cycle, form separate clusters in high dimensional
space. The clusters form according to phase, as the tokens propagate through
the transformer blocks. Finally, we highlight that individual attention heads
respond to specific physiologically relevent features, such as the dicrotic
notch in PPG and the P-wave in ECG. It is also demonstrated that these
pre-trained models are straightforward to fine-tune for tasks such as
classification of atrial fibrillation (AF), and beat detection in
photoplethysmography. For the example of AF, the fine-tuning took 11 minutes of
computer time, and achieved the respective leave-one-subject-out AUCs of 0.99
and 0.93 for ECG and PPG within the MIMIC Perform AF dataset. In addition, the
fine-tuned beat detector achieved a state-of-the-art F1 score of 98%, as well
as uniquely providing a beat confidence level which acts as a signal quality
estimator. Importantly, the fine-tuned models for AF screening are also fully
explainable, with attention shifting to regions in the context that are
strongly indicative of atrial fibrillation.

摘要：<paragraph>僅解碼器Transformer是大型語言模型熱門生成式預訓練Transformer (GPT) 系列的核心。在這項工作中，我們將此架構應用於臨床心臟時間序列資料分析，以建立兩個預訓練通用心臟模型，稱為 PPG-PT 和 ECG-PT。我們特別強調讓這兩個預訓練模型完全可解釋。這首先是透過總體注意圖實現的，它顯示模型為了做出預測，會專注於先前心臟週期中的類似點，並在更深層的層級逐漸擴大其注意範圍。接下來，我們顯示在心電圖 (ECG) 和光電容積描記法 (PPG) 週期中於不同特定點出現的具有相同值的代幣，會在高維空間中形成獨立的群集。群集會根據相位形成，因為代幣會透過Transformer區塊傳播。最後，我們強調個別注意權重會對特定的生理相關特徵做出回應，例如 PPG 中的二尖缺口和 ECG 中的 P 波。也已證實這些預訓練模型很容易針對任務進行微調，例如心房顫動 (AF) 分類和光電容積描記法中的節拍偵測。以 AF 為例，微調耗時 11 分鐘的電腦時間，並在 MIMIC Perform AF 資料集中分別達成 ECG 和 PPG 的留一法 AUC 為 0.99 和 0.93。此外，微調節拍偵測器達到了 98% 的最新 F1 分數，並獨特地提供了一個節拍信心等級，作為訊號品質估計器。重要的是，針對 AF 篩檢進行微調的模型也完全可解釋，注意力會轉移到文中強烈指示心房顫動的區域。</paragraph>

##### **Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization**
2407.20739v1 by Michael Kölle, Karola Schneider, Sabrina Egger, Felix Topp, Thomy Phan, Philipp Altmann, Jonas Nüßlein, Claudia Linnhoff-Popien

In recent years, Multi-Agent Reinforcement Learning (MARL) has found
application in numerous areas of science and industry, such as autonomous
driving, telecommunications, and global health. Nevertheless, MARL suffers
from, for instance, an exponential growth of dimensions. Inherent properties of
quantum mechanics help to overcome these limitations, e.g., by significantly
reducing the number of trainable parameters. Previous studies have developed an
approach that uses gradient-free quantum Reinforcement Learning and
evolutionary optimization for variational quantum circuits (VQCs) to reduce the
trainable parameters and avoid barren plateaus as well as vanishing gradients.
This leads to a significantly better performance of VQCs compared to classical
neural networks with a similar number of trainable parameters and a reduction
in the number of parameters by more than 97 \% compared to similarly good
neural networks. We extend an approach of K\"olle et al. by proposing a
Gate-Based, a Layer-Based, and a Prototype-Based concept to mutate and
recombine VQCs. Our results show the best performance for mutation-only
strategies and the Gate-Based approach. In particular, we observe a
significantly better score, higher total and own collected coins, as well as a
superior own coin rate for the best agent when evaluated in the Coin Game
environment.

摘要：近年來，多智能體強化學習 (MARL) 已在科學和產業的許多領域中找到應用，例如自動駕駛、電信和全球健康。儘管如此，MARL 還是會受到例如維度指數成長等問題的影響。量子力學的內在特性有助於克服這些限制，例如，透過大幅減少可訓練參數的數量。先前的研究已開發出一種方法，該方法使用無梯度的量子強化學習和變分量子電路 (VQC) 的演化最佳化，以減少可訓練參數並避免貧瘠高原和梯度消失。與具有類似可訓練參數數量的傳統神經網路相比，這會讓 VQC 的效能顯著提升，而且與同樣優良的神經網路相比，參數數量減少了超過 97%。我們擴充了 K\"olle 等人的方法，提出一個基於閘、基於層和基於原型的概念來變異和重組 VQC。我們的結果顯示，僅變異策略和基於閘的方法具有最佳效能。特別是，我們觀察到在 Coin Game 環境中進行評估時，最佳智能體的得分顯著提升、總計和自己收集的金幣數量較高，以及自己的金幣比率較高。

##### **Dense Self-Supervised Learning for Medical Image Segmentation**
2407.20395v1 by Maxime Seince, Loic Le Folgoc, Luiz Augusto Facury de Souza, Elsa Angelini

Deep learning has revolutionized medical image segmentation, but it relies
heavily on high-quality annotations. The time, cost and expertise required to
label images at the pixel-level for each new task has slowed down widespread
adoption of the paradigm. We propose Pix2Rep, a self-supervised learning (SSL)
approach for few-shot segmentation, that reduces the manual annotation burden
by learning powerful pixel-level representations directly from unlabeled
images. Pix2Rep is a novel pixel-level loss and pre-training paradigm for
contrastive SSL on whole images. It is applied to generic encoder-decoder deep
learning backbones (e.g., U-Net). Whereas most SSL methods enforce invariance
of the learned image-level representations under intensity and spatial image
augmentations, Pix2Rep enforces equivariance of the pixel-level
representations. We demonstrate the framework on a task of cardiac MRI
segmentation. Results show improved performance compared to existing semi- and
self-supervised approaches; and a 5-fold reduction in the annotation burden for
equivalent performance versus a fully supervised U-Net baseline. This includes
a 30% (resp. 31%) DICE improvement for one-shot segmentation under
linear-probing (resp. fine-tuning). Finally, we also integrate the novel
Pix2Rep concept with the Barlow Twins non-contrastive SSL, which leads to even
better segmentation performance.

摘要：深度學習徹底改變了醫學影像分割，但它極度依賴於高品質的註解。為每個新任務標記像素層級的影像所需的時間、成本和專業知識，已減緩了範例的廣泛採用。我們提出 Pix2Rep，一種針對少次分割的自監督式學習 (SSL) 方法，可透過直接從未標記的影像中學習強大的像素層級表示，來減輕手動註解負擔。Pix2Rep 是一種針對完整影像對比式 SSL 的新穎像素層級損失和預訓練範例。它被應用於通用編碼器-解碼器深度學習主幹 (例如 U-Net)。大多數 SSL 方法強制學習的影像層級表示在強度和空間影像擴充下具有不變性，而 Pix2Rep 則強制像素層級表示具有等變性。我們在心臟 MRI 分割任務中展示了這個架構。結果顯示與現有的半監督式和自監督式方法相比，效能有所提升；且在與完全監督式 U-Net 基準具有相同效能的情況下，註解負擔減少了 5 倍。這包括在線性探測 (resp. 微調) 下，單次分割的 DICE 提升了 30% (resp. 31%)。最後，我們也將新穎的 Pix2Rep 概念與 Barlow Twins 非對比式 SSL 整合，這導致了更好的分割效能。

##### **Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**
2407.20108v1 by Ruochen Li, Jiazhen Pan, Youxiang Zhu, Juncheng Ni, Daniel Rueckert

Cardiac Magnetic Resonance Imaging (CMR) is the gold standard for diagnosing
cardiovascular diseases. Clinical diagnoses predominantly rely on
magnitude-only Digital Imaging and Communications in Medicine (DICOM) images,
omitting crucial phase information that might provide additional diagnostic
benefits. In contrast, k-space is complex-valued and encompasses both magnitude
and phase information, while humans cannot directly perceive. In this work, we
propose KMAE, a Transformer-based model specifically designed to process
k-space data directly, eliminating conventional intermediary conversion steps
to the image domain. KMAE can handle critical cardiac disease classification,
relevant phenotype regression, and cardiac morphology segmentation tasks. We
utilize this model to investigate the potential of k-space-based diagnosis in
cardiac MRI. Notably, this model achieves competitive classification and
regression performance compared to image-domain methods e.g. Masked
Autoencoders (MAEs) and delivers satisfactory segmentation performance with a
myocardium dice score of 0.884. Last but not least, our model exhibits robust
performance with consistent results even when the k-space is 8* undersampled.
We encourage the MR community to explore the untapped potential of k-space and
pursue end-to-end, automated diagnosis with reduced human intervention.

摘要：心臟磁振造影 (CMR) 是診斷心血管疾病的黃金標準。臨床診斷主要依賴於醫學數位影像和通訊 (DICOM) 影像的幅度，而忽略了可能提供額外診斷好處的關鍵相位資訊。相較之下，k 空間是複數值且包含幅度和相位資訊，但人類無法直接感知。在這項工作中，我們提出 KMAE，一種特別設計用於直接處理 k 空間資料的 Transformer 基礎模型，消除了轉換到影像領域的傳統中介步驟。KMAE 可以處理關鍵的心臟疾病分類、相關表型回歸和心臟形態分割任務。我們利用此模型探討 k 空間基礎診斷在心臟 MRI 中的潛力。值得注意的是，與影像領域方法（例如遮罩式自動編碼器 (MAE)）相比，此模型達到了競爭性的分類和回歸效能，並以 0.884 的心肌骰子分數提供了令人滿意的分割效能。最後但並非最不重要的一點是，即使在 k 空間不足採樣 8* 時，我們的模型也能展現穩健的效能和一致的結果。我們鼓勵核磁共振社群探索 k 空間的未開發潛力，並追求減少人為干預的端到端自動化診斷。

##### **Robust Conformal Volume Estimation in 3D Medical Images**
2407.19938v1 by Benjamin Lambert, Florence Forbes, Senan Doyle, Michel Dojat

Volumetry is one of the principal downstream applications of 3D medical image
segmentation, for example, to detect abnormal tissue growth or for surgery
planning. Conformal Prediction is a promising framework for uncertainty
quantification, providing calibrated predictive intervals associated with
automatic volume measurements. However, this methodology is based on the
hypothesis that calibration and test samples are exchangeable, an assumption
that is in practice often violated in medical image applications. A weighted
formulation of Conformal Prediction can be framed to mitigate this issue, but
its empirical investigation in the medical domain is still lacking. A potential
reason is that it relies on the estimation of the density ratio between the
calibration and test distributions, which is likely to be intractable in
scenarios involving high-dimensional data. To circumvent this, we propose an
efficient approach for density ratio estimation relying on the compressed
latent representations generated by the segmentation model. Our experiments
demonstrate the efficiency of our approach to reduce the coverage error in the
presence of covariate shifts, in both synthetic and real-world settings. Our
implementation is available at https://github.com/benolmbrt/wcp_miccai

摘要：體積測量是 3D 醫學影像分割的主要下游應用之一，例如用於偵測異常組織生長或手術規劃。共形預測是一個有前途的不確定性量化架構，提供與自動體積量測相關的校正預測區間。然而，此方法基於校正和測試樣本可交換的假設，而此假設在實務上經常在醫學影像應用中遭到破壞。共形預測的加權公式可以被建構來減輕此問題，但其在醫學領域的經驗調查仍然不足。一個潛在原因是它依賴於校正和測試分佈之間的密度比估計，這在涉及高維度資料的場景中可能是棘手的。為了迴避此問題，我們提出一個有效率的密度比估計方法，依賴於分割模型產生的壓縮潛在表示。我們的實驗證明了我們的方法在合成和真實世界設定中減少共變異數偏移存在時的覆蓋率誤差的效率。我們的實作可以在 https://github.com/benolmbrt/wcp_miccai 取得

##### **Yucca: A Deep Learning Framework For Medical Image Analysis**
2407.19888v1 by Sebastian Nørgaard Llambias, Julia Machnio, Asbjørn Munk, Jakob Ambsdorf, Mads Nielsen, Mostafa Mehdipour Ghazi

Medical image analysis using deep learning frameworks has advanced healthcare
by automating complex tasks, but many existing frameworks lack flexibility,
modularity, and user-friendliness. To address these challenges, we introduce
Yucca, an open-source AI framework available at
https://github.com/Sllambias/yucca, designed specifically for medical imaging
applications and built on PyTorch and PyTorch Lightning. Yucca features a
three-tiered architecture: Functional, Modules, and Pipeline, providing a
comprehensive and customizable solution. Evaluated across diverse tasks such as
cerebral microbleeds detection, white matter hyperintensity segmentation, and
hippocampus segmentation, Yucca achieves state-of-the-art results,
demonstrating its robustness and versatility. Yucca offers a powerful,
flexible, and user-friendly platform for medical image analysis, inviting
community contributions to advance its capabilities and impact.

摘要：使用深度學習框架進行的醫學影像分析已經通過自動化複雜任務推動了醫療保健的進步，但許多現有框架缺乏靈活性、模組化和使用者友善性。為了應對這些挑戰，我們引入了 Yucca，一個開放原始碼的 AI 框架，可於 https://github.com/Sllambias/yucca 取得，專門為醫學影像應用設計，並建立在 PyTorch 和 PyTorch Lightning 之上。Yucca 具有三層架構：功能、模組和管線，提供全面且可自訂的解決方案。在各種任務中進行評估，例如腦微出血偵測、白質高訊號分割和海馬分割，Yucca 達到了最先進的結果，證明了它的穩健性和多功能性。Yucca 提供了一個強大、靈活且使用者友善的醫學影像分析平台，歡迎社群貢獻以提升其能力和影響力。

##### **CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**
2407.19705v2 by Jingwei Zhu, Minghuan Tan, Min Yang, Ruixue Li, Hamid Alinejad-Rokny

The rapid progress in Large Language Models (LLMs) has prompted the creation
of numerous benchmarks to evaluate their capabilities.This study focuses on the
Comprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset
diversity and distribution in supervised fine-tuning (SFT) may enhance LLM
performance.Remarkably, We successfully trained a smaller base model to achieve
scores comparable to larger models, indicating that a diverse and
well-distributed dataset can optimize performance regardless of model size.This
study suggests that even smaller models may reach high performance levels with
carefully curated and varied datasets. By integrating a wide range of
instructional content, our approach addresses potential issues such as data
quality inconsistencies. Our results imply that a broader spectrum of training
data may enhance a model's ability to generalize and perform effectively across
different medical scenarios, highlighting the importance of dataset quality and
diversity in fine-tuning processes. We open-source the model for future
research at https://github.com/CAS-SIAT-XinHai/CollectiveSFT

摘要：大型語言模型 (LLM) 的快速進展促成了許多基準的建立，以評估它們的能力。本研究專注於中文綜合醫療基準 (CMB)，展示了監督微調 (SFT) 中的資料集多樣性和分佈如何增強 LLM 效能。值得注意的是，我們成功地訓練了一個較小的基礎模型，以達到與較大型模型相當的分數，這表明一個多樣化且分佈良好的資料集可以最佳化效能，而與模型大小無關。本研究表明，即使是較小的模型，只要使用經過仔細策劃且多樣化的資料集，也能達到高水準的效能。透過整合廣泛的教學內容，我們的做法解決了資料品質不一致等潛在問題。我們的結果表明，更廣泛的訓練資料範圍可能會增強模型在不同醫療場景中概括和有效執行的能力，突顯了資料集品質和多樣性在微調過程中扮演的重要角色。我們在 https://github.com/CAS-SIAT-XinHai/CollectiveSFT 開源此模型以供將來研究。

##### **Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks**
2407.21072v1 by Marco AF Pimentel, Clément Christophe, Tathagata Raha, Prateek Munjal, Praveen K Kanithi, Shadab Khan

As large language models (LLMs) continue to evolve, the need for robust and
standardized evaluation benchmarks becomes paramount. Evaluating the
performance of these models is a complex challenge that requires careful
consideration of various linguistic tasks, model architectures, and
benchmarking methodologies. In recent years, various frameworks have emerged as
noteworthy contributions to the field, offering comprehensive evaluation tests
and benchmarks for assessing the capabilities of LLMs across diverse domains.
This paper provides an exploration and critical analysis of some of these
evaluation methodologies, shedding light on their strengths, limitations, and
impact on advancing the state-of-the-art in natural language processing.

摘要：隨著大型語言模型 (LLM) 持續演進，對於健全且標準化的評估基準的需求變得至關重要。評估這些模型的效能是一項複雜的挑戰，需要仔細考量各種語言任務、模型架構和基準方法。近年來，各種架構已成為該領域的顯著貢獻，提供全面的評估測試和基準，用於評估 LLM 在不同領域的能力。本文探討並批判性地分析其中一些評估方法，闡明其優點、限制和對自然語言處理領域進步的影響。

##### **Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**
2407.19668v1 by Minxiao Chen, Haitao Yuan, Nan Jiang, Zhifeng Bao, Shangguang Wang

Traffic accidents pose a significant risk to human health and property
safety. Therefore, to prevent traffic accidents, predicting their risks has
garnered growing interest. We argue that a desired prediction solution should
demonstrate resilience to the complexity of traffic accidents. In particular,
it should adequately consider the regional background, accurately capture both
spatial proximity and semantic similarity, and effectively address the sparsity
of traffic accidents. However, these factors are often overlooked or difficult
to incorporate. In this paper, we propose a novel multi-granularity
hierarchical spatio-temporal network. Initially, we innovate by incorporating
remote sensing data, facilitating the creation of hierarchical
multi-granularity structure and the comprehension of regional background. We
construct multiple high-level risk prediction tasks to enhance model's ability
to cope with sparsity. Subsequently, to capture both spatial proximity and
semantic similarity, region feature and multi-view graph undergo encoding
processes to distill effective representations. Additionally, we propose
message passing and adaptive temporal attention module that bridges different
granularities and dynamically captures time correlations inherent in traffic
accident patterns. At last, a multivariate hierarchical loss function is
devised considering the complexity of the prediction purpose. Extensive
experiments on two real datasets verify the superiority of our model against
the state-of-the-art methods.

摘要：交通事故對人類健康和財產安全構成重大風險。因此，預測交通事故風險已引起越來越大的興趣。我們認為，理想的預測解決方案應展現出對交通事故複雜性的韌性。具體而言，它應充分考慮區域背景，準確捕捉空間接近度和語義相似性，並有效解決交通事故的稀疏性。然而，這些因素通常被忽視或難以納入。在本文中，我們提出了一個新穎的多粒度分層時空網路。最初，我們創新地納入了遙感數據，促进了分層多粒度結構的創建和區域背景的理解。我們構建了多個高級風險預測任務，以增強模型應對稀疏性的能力。隨後，為了捕捉空間接近度和語義相似性，區域特徵和多視圖圖表經過編碼過程，以提取有效的表示。此外，我們提出了消息傳遞和自適應時間注意力模組，它架起了不同粒度之間的橋樑，並動態捕捉交通事故模式中固有的時間相關性。最後，考慮到預測目的的複雜性，設計了一個多變量分層損失函數。在兩個真實數據集上的大量實驗驗證了我們模型優於最先進方法的優越性。

##### **Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Knowledge Distillation and Random Data Erasing**
2407.19540v1 by Heejoon Koo

In this paper, we present NECHO v2, a novel framework designed to enhance the
predictive accuracy of multimodal sequential patient diagnoses under uncertain
missing visit sequences, a common challenge in clinical settings. Firstly, we
modify NECHO to handle uncertain modality representation dominance under the
imperfect data. Next, we develop a systematic knowledge distillation by
employing the modified NECHO as both teacher and student. It encompasses a
modality-wise contrastive and hierarchical distillation, transformer
representation random distillation, along with other distillations to align
representations tightly and effectively. We also utilise random erasing on
individual data points within sequences during both training and distillation
of teacher to lightly simulate scenario with missing visit information to
foster effective knowledge transfer. As a result, NECHO v2 verifies itself by
showing superiority in multimodal sequential diagnosis prediction on both
balanced and imbalanced incomplete settings on multimodal healthcare data.

摘要：在本文中，我們提出了 NECHO v2，一個新穎的框架，旨在增強多模態順序患者診斷的預測準確度，在臨床環境中常見的挑戰是不確定遺漏的訪問序列。首先，我們修改 NECHO 以處理不完美數據下的不確定模態表示優勢。接下來，我們通過使用修改後的 NECHO 作為教師和學生來開發系統的知識提煉。它包含模態對比和分層提煉、Transformer表示隨機提煉以及其他提煉，以緊密有效地對齊表示。我們還在訓練和教師提煉過程中對序列中的個別數據點使用隨機擦除，以輕微模擬遺漏訪問信息的場景，以促進有效的知識傳遞。因此，NECHO v2 通過在多模態醫療保健數據的平衡和不平衡不完整設置上顯示多模態順序診斷預測的優越性來驗證自身。

##### **Nudging Consent and the New Opt Out System to the Processing of Health Data in England**
2407.19447v1 by Janos Meszaros, Chih-hsing Ho, Marcelo Corrales Compagnucci

This chapter examines the challenges of the revised opt out system and the
secondary use of health data in England. The analysis of this data could be
very valuable for science and medical treatment as well as for the discovery of
new drugs. For this reason, the UK government established the care.data program
in 2013. The aim of the project was to build a central nationwide database for
research and policy planning. However, the processing of personal data was
planned without proper public engagement. Research has suggested that IT
companies, such as in the Google DeepMind deal case, had access to other kinds
of sensitive data and failed to comply with data protection law. Since May
2018, the government has launched the national data opt out system with the
hope of regaining public trust. Nevertheless, there are no evidence of
significant changes in the ND opt out, compared to the previous opt out system.
Neither in the use of secondary data, nor in the choices that patients can
make. The only notorious difference seems to be in the way that these options
are communicated and framed to the patients. Most importantly, according to the
new ND opt out, the type 1 opt out option, which is the only choice that truly
stops data from being shared outside direct care, will be removed in 2020.
According to the Behavioral Law and Economics literature (Nudge Theory),
default rules, such as the revised opt out system in England, are very
powerful, because people tend to stick to the default choices made readily
available to them. The crucial question analyzed in this chapter is whether it
is desirable for the UK government to stop promoting the type 1 opt outs, and
whether this could be seen as a kind of hard paternalism.

摘要：<paragraph>本章探討了英國修改後的退出機制和二次使用健康資料所面臨的挑戰。分析這些資料對於科學和醫療治療以及發現新藥物而言，可能非常有價值。基於此原因，英國政府於 2013 年建立了 care.data 計畫。該專案的目標是建立一個全國性的中央資料庫，以進行研究和政策規劃。然而，個人資料的處理是在沒有適當公眾參與的情況下進行規劃的。研究表明，例如在 Google DeepMind 交易案例中，IT 公司可以存取其他類型的敏感資料，且未能遵守資料保護法。自 2018 年 5 月以來，政府已推出全國資料退出機制，希望能重新獲得公眾信任。儘管如此，與先前的退出機制相比，並無證據顯示全國資料退出機制有顯著變化。無論是在二次資料的使用上，或是在患者可以做出的選擇上，皆是如此。唯一顯著的差異似乎在於這些選項的溝通和傳達方式。最重要的是，根據新的全國資料退出機制，類型 1 退出選項（這是唯一真正能阻止資料在直接照護之外被分享的選項）將於 2020 年被移除。根據行為法與經濟學文獻（推論理論），預設規則（例如英國修改後的退出機制）非常有效，因為人們傾向於堅持容易取得的預設選項。本章分析的關鍵問題是，英國政府停止推廣類型 1 退出是否可取，以及這是否可以視為一種嚴厲的父權主義。</paragraph>

##### **ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding**
2407.19435v1 by Zhen Chen, Zongming Zhang, Wenwu Guo, Xingjian Luo, Long Bai, Jinlin Wu, Hongliang Ren, Hongbin Liu

Surgical instrument segmentation is crucial in surgical scene understanding,
thereby facilitating surgical safety. Existing algorithms directly detected all
instruments of pre-defined categories in the input image, lacking the
capability to segment specific instruments according to the surgeon's
intention. During different stages of surgery, surgeons exhibit varying
preferences and focus toward different surgical instruments. Therefore, an
instrument segmentation algorithm that adheres to the surgeon's intention can
minimize distractions from irrelevant instruments and assist surgeons to a
great extent. The recent Segment Anything Model (SAM) reveals the capability to
segment objects following prompts, but the manual annotations for prompts are
impractical during the surgery. To address these limitations in operating
rooms, we propose an audio-driven surgical instrument segmentation framework,
named ASI-Seg, to accurately segment the required surgical instruments by
parsing the audio commands of surgeons. Specifically, we propose an
intention-oriented multimodal fusion to interpret the segmentation intention
from audio commands and retrieve relevant instrument details to facilitate
segmentation. Moreover, to guide our ASI-Seg segment of the required surgical
instruments, we devise a contrastive learning prompt encoder to effectively
distinguish the required instruments from the irrelevant ones. Therefore, our
ASI-Seg promotes the workflow in the operating rooms, thereby providing
targeted support and reducing the cognitive load on surgeons. Extensive
experiments are performed to validate the ASI-Seg framework, which reveals
remarkable advantages over classical state-of-the-art and medical SAMs in both
semantic segmentation and intention-oriented segmentation. The source code is
available at https://github.com/Zonmgin-Zhang/ASI-Seg.

摘要：手術器械分割對於手術場景理解至關重要，
從而促進手術安全。現有演算法直接偵測輸入影像中所有預定義類別的器械，缺乏根據外科醫師意圖分割特定器械的能力。在手術的不同階段，外科醫師會對不同的手術器械表現出不同的偏好和關注。因此，一種遵循外科醫師意圖的器械分割演算法可以最大程度地減少與手術無關的器械的干擾，並在很大程度上協助外科醫師。最近的 Segment Anything Model (SAM) 揭示了根據提示分割物件的能力，但提示的手動註解在手術過程中不切實際。為了解決手術室中的這些限制，我們提出了一個音訊驅動的手術器械分割架構，稱為 ASI-Seg，通過解析外科醫師的音訊命令來準確分割所需的器械。具體來說，我們提出了一個意圖導向的多模態融合，從音訊命令中解釋分割意圖並檢索相關器械細節以利於分割。此外，為了指導我們的 ASI-Seg 分割所需的器械，我們設計了一個對比學習提示編碼器，以有效區分所需的器械和不相關的器械。因此，我們的 ASI-Seg 促進了手術室中的工作流程，從而提供了有針對性的支援，並降低了外科醫師的認知負擔。進行了大量的實驗來驗證 ASI-Seg 架構，這揭示了在語義分割和意圖導向分割中，與傳統的最新技術和醫學 SAM 相比，它具有顯著的優勢。原始碼可在 https://github.com/Zonmgin-Zhang/ASI-Seg 獲得。

##### **A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy**
2407.19422v1 by Meng Jiang, Qing Zhao, Jianqiang Li, Fan Wang, Tianyu He, Xinyan Cheng, Bing Xiang Yang, Grace W. K. Ho, Guanghui Fu

Cognitive Behavioral Therapy (CBT) is a well-established intervention for
mitigating psychological issues by modifying maladaptive cognitive and
behavioral patterns. However, delivery of CBT is often constrained by resource
limitations and barriers to access. Advancements in artificial intelligence
(AI) have provided technical support for the digital transformation of CBT.
Particularly, the emergence of pre-training models (PTMs) and large language
models (LLMs) holds immense potential to support, augment, optimize and
automate CBT delivery. This paper reviews the literature on integrating AI into
CBT interventions. We begin with an overview of CBT. Then, we introduce the
integration of AI into CBT across various stages: pre-treatment, therapeutic
process, and post-treatment. Next, we summarized the datasets relevant to some
CBT-related tasks. Finally, we discuss the benefits and current limitations of
applying AI to CBT. We suggest key areas for future research, highlighting the
need for further exploration and validation of the long-term efficacy and
clinical utility of AI-enhanced CBT. The transformative potential of AI in
reshaping the practice of CBT heralds a new era of more accessible, efficient,
and personalized mental health interventions.

摘要：認知行為療法 (CBT) 是一種完善的干預措施，透過調整適應不良的認知和行為模式來減輕心理問題。然而，CBT 的提供往往受到資源限制和獲取障礙的限制。人工智慧 (AI) 的進步為 CBT 的數位轉型提供了技術支援。特別是，預訓練模型 (PTM) 和大型語言模型 (LLM) 的出現具有巨大的潛力，可以支援、擴充、最佳化和自動化 CBT 的提供。本文回顧了將 AI 整合到 CBT 干預措施的文獻。我們從 CBT 的概述開始。然後，我們介紹了在各種階段將 AI 整合到 CBT 中：治療前、治療過程和治療後。接下來，我們總結了與一些 CBT 相關任務相關的資料集。最後，我們討論了將 AI 應用於 CBT 的好處和目前的限制。我們建議未來研究的主要領域，強調需要進一步探索和驗證 AI 增強 CBT 的長期療效和臨床效用。AI 在重塑 CBT 實務中的轉化潛力預示著一個新的時代，即更易於取得、更有效率和更個人化的心理健康干預措施。

##### **Empowering Clinicians with Medical Decision Transformers: A Framework for Sepsis Treatment**
2407.19380v1 by Aamer Abdul Rahman, Pranav Agarwal, Rita Noumeir, Philippe Jouvet, Vincent Michalski, Samira Ebrahimi Kahou

Offline reinforcement learning has shown promise for solving tasks in
safety-critical settings, such as clinical decision support. Its application,
however, has been limited by the lack of interpretability and interactivity for
clinicians. To address these challenges, we propose the medical decision
transformer (MeDT), a novel and versatile framework based on the
goal-conditioned reinforcement learning paradigm for sepsis treatment
recommendation. MeDT uses the decision transformer architecture to learn a
policy for drug dosage recommendation. During offline training, MeDT utilizes
collected treatment trajectories to predict administered treatments for each
time step, incorporating known treatment outcomes, target acuity scores, past
treatment decisions, and current and past medical states. This analysis enables
MeDT to capture complex dependencies among a patient's medical history,
treatment decisions, outcomes, and short-term effects on stability. Our
proposed conditioning uses acuity scores to address sparse reward issues and to
facilitate clinician-model interactions, enhancing decision-making. Following
training, MeDT can generate tailored treatment recommendations by conditioning
on the desired positive outcome (survival) and user-specified short-term
stability improvements. We carry out rigorous experiments on data from the
MIMIC-III dataset and use off-policy evaluation to demonstrate that MeDT
recommends interventions that outperform or are competitive with existing
offline reinforcement learning methods while enabling a more interpretable,
personalized and clinician-directed approach.

摘要：離線強化學習已展現出解決諸如臨床決策支援等安全關鍵設定中任務的潛力。然而，其應用受到臨床醫師對可解釋性和互動性的缺乏所限制。為了應對這些挑戰，我們提出了醫療決策轉換器 (MeDT)，這是一個基於目標條件強化學習範例的新穎且多功能的架構，用於敗血症治療建議。MeDT 使用決策轉換器架構來學習藥物劑量建議的政策。在離線訓練期間，MeDT 利用收集的治療軌跡來預測每個時間步驟的管理治療，並納入已知的治療結果、目標嚴重程度評分、過去的治療決策以及當前和過去的醫療狀態。此分析使 MeDT 能夠捕捉患者病史、治療決策、結果以及對穩定性的短期影響之間的複雜依賴關係。我們提出的條件使用嚴重程度評分來解決稀疏獎勵問題並促進臨床醫師與模型的互動，從而增強決策制定。在訓練之後，MeDT 可以通過以所需的正面結果（存活）和使用者指定的短期穩定性改善為條件來產生量身打造的治療建議。我們對來自 MIMIC-III 資料集的資料進行了嚴格的實驗，並使用非策略評估來證明 MeDT 推薦的干預措施優於或與現有的離線強化學習方法具有競爭力，同時實現了更具可解釋性、個性化和臨床醫師指導的方法。

##### **Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction**
2407.19359v1 by Yuan Xue, Nan Du, Anne Mottram, Martin Seneviratne, Andrew M. Dai

We propose to meta-learn an a self-supervised patient trajectory forecast
learning rule by meta-training on a meta-objective that directly optimizes the
utility of the patient representation over the subsequent clinical outcome
prediction. This meta-objective directly targets the usefulness of a
representation generated from unlabeled clinical measurement forecast for later
supervised tasks.
  The meta-learned can then be directly used in target risk prediction, and the
limited available samples can be used for further fine-tuning the model
performance. The effectiveness of our approach is tested on a real open source
patient EHR dataset MIMIC-III. We are able to demonstrate that our
attention-based patient state representation approach can achieve much better
performance for predicting target risk with low resources comparing with both
direct supervised learning and pretraining with all-observation trajectory
forecast.

摘要：我們提議透過元訓練來元學習一個自我監督的患者軌跡預測學習規則，並透過元目標直接最佳化患者表徵在後續臨床結果預測中的效用。此元目標直接針對從未標記的臨床測量預測所產生的表徵在後續監督式任務中的效用。
元學習後，可以直接用於目標風險預測，且可使用有限的可用樣本進一步微調模型效能。我們的方法之有效性已在一個真實的開放原始碼患者電子病歷資料集 MIMIC-III 上進行測試。我們能夠證明，與直接監督式學習和使用所有觀察軌跡預測進行預訓練相比，我們基於注意力的患者狀態表徵方法可以達到更好的目標風險預測效能，且資源需求較低。

