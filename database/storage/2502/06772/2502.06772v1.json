{"2502.06772": {"publish_time": "2025-02-10", "title": "ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates", "paper_summary": "We present that hierarchical LLM reasoning via scaling thought templates can\neffectively optimize the reasoning search space and outperform the mathematical\nreasoning capabilities of powerful LLMs like OpenAI o1-preview and DeepSeek V3.\nWe train our ReasonFlux-32B model with only 8 GPUs and introduces three\ninnovations: (i) a structured and generic thought template library, containing\naround 500 high-level thought templates capable of generalizing to similar or\nrelevant reasoning problems; (ii) performing hierarchical reinforcement\nlearning on a sequence of thought templates instead of long CoTs, optimizing a\nbase LLM to plan out an optimal template trajectory for gradually handling\ncomplex problems; (iii) a brand new inference scaling system that enables\nhierarchical LLM reasoning by adaptively scaling thought templates at inference\ntime. With a template trajectory containing sequential thought templates, our\nReasonFlux-32B significantly advances math reasoning capabilities to\nstate-of-the-art levels. Notably, on the MATH benchmark, it achieves an\naccuracy of 91.2% and surpasses o1-preview by 6.7%. On the USA Math Olympiad\n(AIME) benchmark, ReasonFlux-32B solves an average of 56.7% of problems,\nsurpassing o1-preview and DeepSeek-V3 by 27% and 45%, respectively. Code:\nhttps://github.com/Gen-Verse/ReasonFlux", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u900f\u904e\u64f4\u5145\u601d\u8003\u7bc4\u672c\u7684\u5206\u5c64\u5f0f LLM \u63a8\u7406\uff0c\u53ef\u4ee5\u6709\u6548\u6700\u4f73\u5316\u63a8\u7406\u641c\u5c0b\u7a7a\u9593\uff0c\u4e26\u8d85\u8d8a OpenAI o1-preview \u548c DeepSeek V3 \u7b49\u5f37\u5927 LLM \u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u50c5\u4f7f\u7528 8 \u500b GPU \u8a13\u7df4\u6211\u5011\u7684 ReasonFlux-32B \u6a21\u578b\uff0c\u4e26\u5f15\u9032\u4e09\u9805\u5275\u65b0\uff1a(i) \u4e00\u500b\u7d50\u69cb\u5316\u4e14\u901a\u7528\u7684\u601d\u8003\u7bc4\u672c\u5eab\uff0c\u5305\u542b\u7d04 500 \u500b\u9ad8\u968e\u601d\u8003\u7bc4\u672c\uff0c\u80fd\u5920\u6982\u5316\u5230\u985e\u4f3c\u6216\u76f8\u95dc\u7684\u63a8\u7406\u554f\u984c\uff1b(ii) \u5c0d\u4e00\u7cfb\u5217\u601d\u8003\u7bc4\u672c\u57f7\u884c\u5206\u5c64\u5f37\u5316\u5b78\u7fd2\uff0c\u800c\u4e0d\u662f\u9577 CoT\uff0c\u6700\u4f73\u5316\u57fa\u790e LLM \u4ee5\u898f\u5283\u51fa\u6700\u4f73\u7bc4\u672c\u8ecc\u8de1\uff0c\u4ee5\u9010\u6b65\u8655\u7406\u8907\u96dc\u554f\u984c\uff1b(iii) \u4e00\u500b\u5168\u65b0\u7684\u63a8\u7406\u64f4\u5145\u7cfb\u7d71\uff0c\u900f\u904e\u5728\u63a8\u7406\u6642\u9593\u81ea\u9069\u61c9\u64f4\u5145\u601d\u8003\u7bc4\u672c\uff0c\u5be6\u73fe\u5206\u5c64\u5f0f LLM \u63a8\u7406\u3002\u900f\u904e\u5305\u542b\u9806\u5e8f\u601d\u8003\u7bc4\u672c\u7684\u7bc4\u672c\u8ecc\u8de1\uff0c\u6211\u5011\u7684 ReasonFlux-32B \u5927\u5e45\u63d0\u5347\u4e86\u6578\u5b78\u63a8\u7406\u80fd\u529b\uff0c\u9054\u5230\u6700\u5148\u9032\u7684\u6c34\u5e73\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728 MATH \u57fa\u6e96\u6e2c\u8a66\u4e2d\uff0c\u5b83\u7684\u6e96\u78ba\u7387\u9054\u5230 91.2%\uff0c\u4e26\u8d85\u8d8a o1-preview 6.7%\u3002\u5728\u7f8e\u570b\u6578\u5b78\u5967\u6797\u5339\u514b\u7af6\u8cfd (AIME) \u57fa\u6e96\u6e2c\u8a66\u4e2d\uff0cReasonFlux-32B \u5e73\u5747\u89e3\u6c7a\u4e86 56.7% \u7684\u554f\u984c\uff0c\u5206\u5225\u8d85\u8d8a o1-preview \u548c DeepSeek-V3 27% \u548c 45%\u3002\u7a0b\u5f0f\u78bc\uff1ahttps://github.com/Gen-Verse/ReasonFlux", "author": "Ling Yang et.al.", "authors": "Ling Yang, Zhaochen Yu, Bin Cui, Mengdi Wang", "id": "2502.06772v1", "paper_url": "http://arxiv.org/abs/2502.06772v1", "repo": "null"}}