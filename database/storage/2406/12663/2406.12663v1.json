{"2406.12663": {"publish_time": "2024-06-18", "title": "Do More Details Always Introduce More Hallucinations in LVLM-based Image Captioning?", "paper_summary": "Large Vision-Language Models (LVLMs) excel in integrating visual and\nlinguistic contexts to produce detailed content, facilitating applications such\nas image captioning. However, using LVLMs to generate descriptions often faces\nthe challenge of object hallucination (OH), where the output text misrepresents\nactual objects in the input image. While previous studies attribute the\noccurrence of OH to the inclusion of more details, our study finds technical\nflaws in existing metrics, leading to unreliable evaluations of models and\nconclusions about OH. This has sparked a debate on the question: Do more\ndetails always introduce more hallucinations in LVLM-based image captioning?\n  In this paper, we address this debate by proposing a novel decoding strategy,\nDifferentiated Beam Decoding (DBD), along with a reliable new set of evaluation\nmetrics: CLIP-Precision, CLIP-Recall, and CLIP-F1. DBD decodes the wealth of\ninformation hidden in visual input into distinct language representations\ncalled unit facts in parallel. This decoding is achieved via a well-designed\ndifferential score that guides the parallel search and candidate screening. The\nselected unit facts are then aggregated to generate the final caption. Our\nproposed metrics evaluate the comprehensiveness and accuracy of image captions\nby comparing the embedding groups of ground-truth image regions and generated\ntext partitions. Extensive experiments on the Visual Genome dataset validate\nthe effectiveness of our approach, demonstrating that it produces detailed\ndescriptions while maintaining low hallucination levels.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u64c5\u9577\u6574\u5408\u8996\u89ba\u548c\u8a9e\u8a00\u8108\u7d61\u4ee5\u7522\u751f\u8a73\u7d30\u5167\u5bb9\uff0c\u4fc3\u9032\u5f71\u50cf\u6a19\u984c\u7b49\u61c9\u7528\u7a0b\u5f0f\u3002\u7136\u800c\uff0c\u4f7f\u7528 LVLMs \u7522\u751f\u63cf\u8ff0\u6642\uff0c\u5e38\u6703\u9762\u81e8\u7269\u4ef6\u5e7b\u89ba (OH) \u7684\u6311\u6230\uff0c\u5176\u4e2d\u8f38\u51fa\u6587\u5b57\u932f\u8aa4\u5448\u73fe\u8f38\u5165\u5f71\u50cf\u4e2d\u7684\u5be6\u969b\u7269\u4ef6\u3002\u5118\u7ba1\u5148\u524d\u7684\u7814\u7a76\u5c07 OH \u7684\u767c\u751f\u6b78\u56e0\u65bc\u5305\u542b\u66f4\u591a\u7d30\u7bc0\uff0c\u4f46\u6211\u5011\u7684\u7814\u7a76\u767c\u73fe\u73fe\u6709\u6307\u6a19\u5b58\u5728\u6280\u8853\u7f3a\u9677\uff0c\u5c0e\u81f4\u6a21\u578b\u8a55\u4f30\u548c\u95dc\u65bc OH \u7684\u7d50\u8ad6\u4e0d\u53ef\u9760\u3002\u9019\u5f15\u767c\u4e86\u4e00\u5834\u8faf\u8ad6\uff1a\u5728\u57fa\u65bc LVLM \u7684\u5f71\u50cf\u6a19\u984c\u4e2d\uff0c\u66f4\u591a\u7d30\u7bc0\u662f\u5426\u7e3d\u662f\u6703\u5f15\u5165\u66f4\u591a\u5e7b\u89ba\uff1f\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u7684\u89e3\u78bc\u7b56\u7565\uff0c\u5373\u5dee\u7570\u5316\u6ce2\u675f\u89e3\u78bc (DBD)\uff0c\u4ee5\u53ca\u4e00\u7d44\u53ef\u9760\u7684\u65b0\u8a55\u4f30\u6307\u6a19\uff1aCLIP \u7cbe\u78ba\u5ea6\u3001CLIP \u53ec\u56de\u7387\u548c CLIP-F1 \u4f86\u89e3\u6c7a\u9019\u5834\u8faf\u8ad6\u3002DBD \u5c07\u96b1\u85cf\u5728\u8996\u89ba\u8f38\u5165\u4e2d\u7684\u5927\u91cf\u8cc7\u8a0a\u89e3\u78bc\u6210\u4e0d\u540c\u7684\u8a9e\u8a00\u8868\u793a\uff0c\u7a31\u70ba\u55ae\u5143\u4e8b\u5be6\u3002\u9019\u7a2e\u89e3\u78bc\u662f\u900f\u904e\u7cbe\u5fc3\u8a2d\u8a08\u7684\u5dee\u7570\u5206\u6578\u4f86\u5be6\u73fe\u7684\uff0c\u8a72\u5206\u6578\u5f15\u5c0e\u4e26\u884c\u641c\u5c0b\u548c\u5019\u9078\u7be9\u9078\u3002\u7136\u5f8c\u5c07\u9078\u5b9a\u7684\u55ae\u5143\u4e8b\u5be6\u532f\u7e3d\u8d77\u4f86\u4ee5\u7522\u751f\u6700\u7d42\u6a19\u984c\u3002\u6211\u5011\u63d0\u51fa\u7684\u6307\u6a19\u900f\u904e\u6bd4\u8f03\u771f\u5be6\u5f71\u50cf\u5340\u57df\u548c\u751f\u6210\u6587\u5b57\u5206\u5340\u7684\u5d4c\u5165\u7fa4\u7d44\u4f86\u8a55\u4f30\u5f71\u50cf\u6a19\u984c\u7684\u5168\u9762\u6027\u548c\u6e96\u78ba\u6027\u3002\u5728 Visual Genome \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u9a57\u8b49\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8b49\u660e\u5b83\u53ef\u4ee5\u5728\u7dad\u6301\u4f4e\u5e7b\u89ba\u6c34\u6e96\u7684\u540c\u6642\u7522\u751f\u8a73\u7d30\u7684\u63cf\u8ff0\u3002", "author": "Mingqian Feng et.al.", "authors": "Mingqian Feng, Yunlong Tang, Zeliang Zhang, Chenliang Xu", "id": "2406.12663v1", "paper_url": "http://arxiv.org/abs/2406.12663v1", "repo": "null"}}