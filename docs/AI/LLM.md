
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-08**|**Arctic-TILT. Business Document Understanding at Sub-Billion Scale**|Łukasz Borchmann et.al.|[2408.04632v1](http://arxiv.org/abs/2408.04632v1)|null|
|**2024-08-08**|**Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics**|Ruining Li et.al.|[2408.04631v1](http://arxiv.org/abs/2408.04631v1)|null|
|**2024-08-08**|**LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP**|Danlu Chen et.al.|[2408.04628v1](http://arxiv.org/abs/2408.04628v1)|null|
|**2024-08-08**|**Transformer Explainer: Interactive Learning of Text-Generative Models**|Aeree Cho et.al.|[2408.04619v1](http://arxiv.org/abs/2408.04619v1)|null|
|**2024-08-08**|**Better Alignment with Instruction Back-and-Forth Translation**|Thao Nguyen et.al.|[2408.04614v1](http://arxiv.org/abs/2408.04614v1)|null|
|**2024-08-08**|**Code-switching in text and speech reveals information-theoretic audience design**|Debasmita Bhattacharya et.al.|[2408.04596v1](http://arxiv.org/abs/2408.04596v1)|null|
|**2024-08-08**|**Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models**|Qirui Jiao et.al.|[2408.04594v1](http://arxiv.org/abs/2408.04594v1)|[link](https://github.com/modelscope/data-juicer)|
|**2024-08-08**|**HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts**|Hongjun Wang et.al.|[2408.04591v1](http://arxiv.org/abs/2408.04591v1)|null|
|**2024-08-08**|**Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness**|Xiaojing Fan et.al.|[2408.04585v1](http://arxiv.org/abs/2408.04585v1)|null|
|**2024-08-08**|**SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals**|Haoran Zheng et.al.|[2408.04575v1](http://arxiv.org/abs/2408.04575v1)|null|
|**2024-08-08**|**Learning Fine-Grained Grounded Citations for Attributed Large Language Models**|Lei Huang et.al.|[2408.04568v1](http://arxiv.org/abs/2408.04568v1)|[link](https://github.com/luckyyysta/fine-grained-attribution)|
|**2024-08-08**|**Conversational Prompt Engineering**|Liat Ein-Dor et.al.|[2408.04560v1](http://arxiv.org/abs/2408.04560v1)|null|
|**2024-08-08**|**Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models**|Yupeng Chang et.al.|[2408.04556v1](http://arxiv.org/abs/2408.04556v1)|[link](https://github.com/cyp-jlu-ai/ba-lora)|
|**2024-08-08**|**Molyé: A Corpus-based Approach to Language Contact in Colonial France**|Rasul Dent et.al.|[2408.04554v1](http://arxiv.org/abs/2408.04554v1)|null|
|**2024-08-08**|**MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic Text with Persuasion Techniques Identification**|Md Rafiul Biswas et.al.|[2408.04540v1](http://arxiv.org/abs/2408.04540v1)|null|
|**2024-08-08**|**Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models**|Fabio Pernisi et.al.|[2408.04522v1](http://arxiv.org/abs/2408.04522v1)|null|
|**2024-08-08**|**Articulatory Configurations across Genders and Periods in French Radio and TV archives**|Benjamin Elie et.al.|[2408.04519v1](http://arxiv.org/abs/2408.04519v1)|null|
|**2024-08-08**|**Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**|Vandan Gorade et.al.|[2408.04491v1](http://arxiv.org/abs/2408.04491v1)|null|
|**2024-08-08**|**SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios**|Sriram Mandalika et.al.|[2408.04482v1](http://arxiv.org/abs/2408.04482v1)|null|
|**2024-08-08**|**Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate**|Yiqun Zhang et.al.|[2408.04472v1](http://arxiv.org/abs/2408.04472v1)|[link](https://github.com/zhangyiqun018/agent-for-debate)|
|**2024-08-08**|**Crowd Intelligence for Early Misinformation Prediction on Social Media**|Megha Sundriyal et.al.|[2408.04463v1](http://arxiv.org/abs/2408.04463v1)|null|
|**2024-08-08**|**RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents**|Zihao Zhu et.al.|[2408.04449v1](http://arxiv.org/abs/2408.04449v1)|null|
|**2024-08-08**|**FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data**|Ahmed Anwar et.al.|[2408.04442v1](http://arxiv.org/abs/2408.04442v1)|null|
|**2024-08-08**|**Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models**|Philipp Müller et.al.|[2408.04420v1](http://arxiv.org/abs/2408.04420v1)|null|
|**2024-08-08**|**Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning**|Seong-Il Park et.al.|[2408.04414v1](http://arxiv.org/abs/2408.04414v1)|null|
|**2024-08-08**|**Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset**|Kentaro Ozeki et.al.|[2408.04403v1](http://arxiv.org/abs/2408.04403v1)|[link](https://github.com/kmineshima/neubaroco)|
|**2024-08-08**|**DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**|Xin Sun et.al.|[2408.04400v1](http://arxiv.org/abs/2408.04400v1)|null|
|**2024-08-08**|**Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation**|Nicy Scaria et.al.|[2408.04394v1](http://arxiv.org/abs/2408.04394v1)|null|
|**2024-08-08**|**Open-domain Implicit Format Control for Large Language Model Generation**|Yiqun Yao et.al.|[2408.04392v1](http://arxiv.org/abs/2408.04392v1)|null|
|**2024-08-08**|**MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**|Haoxuan Li et.al.|[2408.04388v1](http://arxiv.org/abs/2408.04388v1)|[link](https://github.com/luminosityx/mm-forecast)|
|**2024-08-08**|**Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**|Hsuan-Lei Shao et.al.|[2408.04382v1](http://arxiv.org/abs/2408.04382v1)|null|
|**2024-08-08**|**Overview of the NLPCC 2024 Shared Task on Chinese Metaphor Generation**|Xingwei Qu et.al.|[2408.04378v1](http://arxiv.org/abs/2408.04378v1)|null|
|**2024-08-08**|**Simulating Articulatory Trajectories with Phonological Feature Interpolation**|Angelo Ortiz Tandazo et.al.|[2408.04363v1](http://arxiv.org/abs/2408.04363v1)|null|
|**2024-08-08**|**Towards Explainable Network Intrusion Detection using Large Language Models**|Paul R. B. Houssel et.al.|[2408.04342v1](http://arxiv.org/abs/2408.04342v1)|null|
|**2024-08-08**|**KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination**|Yin Gu et.al.|[2408.04336v1](http://arxiv.org/abs/2408.04336v1)|null|
|**2024-08-08**|**Enhancing Journalism with AI: A Study of Contextualized Image Captioning for News Articles using LLMs and LMMs**|Aliki Anagnostopoulou et.al.|[2408.04331v1](http://arxiv.org/abs/2408.04331v1)|null|
|**2024-08-08**|**HydraFormer: One Encoder For All Subsampling Rates**|Yaoxun Xu et.al.|[2408.04325v1](http://arxiv.org/abs/2408.04325v1)|[link](https://github.com/hydraformer/hydraformer)|
|**2024-08-08**|**Learning with Digital Agents: An Analysis based on the Activity Theory**|Mateusz Dolata et.al.|[2408.04304v1](http://arxiv.org/abs/2408.04304v1)|null|
|**2024-08-08**|**Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP**|François Remy et.al.|[2408.04303v1](http://arxiv.org/abs/2408.04303v1)|[link](https://github.com/lagom-nlp/transtokenizer)|
|**2024-08-08**|**Tackling Noisy Clients in Federated Learning with End-to-end Label Correction**|Xuefeng Jiang et.al.|[2408.04301v1](http://arxiv.org/abs/2408.04301v1)|[link](https://github.com/sprinter1999/fedelc)|
|**2024-08-08**|**Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments**|Kunitomo Tanaka et.al.|[2408.04293v1](http://arxiv.org/abs/2408.04293v1)|null|
|**2024-08-08**|**EMTeC: A Corpus of Eye Movements on Machine-Generated Texts**|Lena Sophia Bolliger et.al.|[2408.04289v1](http://arxiv.org/abs/2408.04289v1)|[link](https://github.com/dili-lab/emtec)|
|**2024-08-08**|**LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection**|Mervat Abassy et.al.|[2408.04284v1](http://arxiv.org/abs/2408.04284v1)|null|
|**2024-08-08**|**LaDiMo: Layer-wise Distillation Inspired MoEfier**|Sungyoon Kim et.al.|[2408.04278v1](http://arxiv.org/abs/2408.04278v1)|null|
|**2024-08-08**|**Analysis of Argument Structure Constructions in the Large Language Model BERT**|Pegah Ramezani et.al.|[2408.04270v1](http://arxiv.org/abs/2408.04270v1)|null|
|**2024-08-08**|**Unveiling Hidden Visual Information: A Reconstruction Attack Against Adversarial Visual Information Hiding**|Jonggyu Jang et.al.|[2408.04261v1](http://arxiv.org/abs/2408.04261v1)|null|
|**2024-08-08**|**EfficientRAG: Efficient Retriever for Multi-Hop Question Answering**|Ziyuan Zhuang et.al.|[2408.04259v1](http://arxiv.org/abs/2408.04259v1)|null|
|**2024-08-08**|**Explicating the Implicit: Argument Detection Beyond Sentence Boundaries**|Paul Roit et.al.|[2408.04246v1](http://arxiv.org/abs/2408.04246v1)|null|
|**2024-08-08**|**Scalable Transformer for High Dimensional Multivariate Time Series Forecasting**|Xin Zhou et.al.|[2408.04245v1](http://arxiv.org/abs/2408.04245v1)|[link](https://github.com/xinzzzhou/scalabletransformer4highdimensionmtsf)|
|**2024-08-08**|**The Ungrounded Alignment Problem**|Marc Pickett et.al.|[2408.04242v1](http://arxiv.org/abs/2408.04242v1)|[link](https://github.com/EmergenceAI/babybeaver)|
|**2024-08-08**|**Learning to Rewrite: Generalized LLM-Generated Text Detection**|Wei Hao et.al.|[2408.04237v1](http://arxiv.org/abs/2408.04237v1)|null|
|**2024-08-08**|**Probabilistic Circuits for Cumulative Distribution Functions**|Oliver Broadrick et.al.|[2408.04229v1](http://arxiv.org/abs/2408.04229v1)|null|
|**2024-08-08**|**Evaluating Language Model Math Reasoning via Grounding in Educational Curricula**|Li Lucy et.al.|[2408.04226v1](http://arxiv.org/abs/2408.04226v1)|[link](https://github.com/allenai/mathfish)|
|**2024-08-08**|**VideoQA in the Era of LLMs: An Empirical Study**|Junbin Xiao et.al.|[2408.04223v1](http://arxiv.org/abs/2408.04223v1)|null|
|**2024-08-08**|**Connective Viewpoints of Signal-to-Noise Diffusion Models**|Khanh Doan et.al.|[2408.04221v1](http://arxiv.org/abs/2408.04221v1)|null|
|**2024-08-08**|**Diffusion Guided Language Modeling**|Justin Lovelace et.al.|[2408.04220v1](http://arxiv.org/abs/2408.04220v1)|[link](https://github.com/justinlovelace/diffusion-guided-lm)|
|**2024-08-08**|**Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs**|Masashi Oshika et.al.|[2408.04217v1](http://arxiv.org/abs/2408.04217v1)|[link](https://github.com/nttcslab-nlp/simplifyingmt_acl24)|
|**2024-08-08**|**Attention Mechanism and Context Modeling System for Text Mining Machine Translation**|Shi Bo et.al.|[2408.04216v1](http://arxiv.org/abs/2408.04216v1)|null|
|**2024-08-08**|**MMREC: LLM Based Multi-Modal Recommender System**|Jiahao Tian et.al.|[2408.04211v1](http://arxiv.org/abs/2408.04211v1)|null|
|**2024-08-08**|**MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents**|Yanqi Dai et.al.|[2408.04203v1](http://arxiv.org/abs/2408.04203v1)|[link](https://github.com/yanqidai/mmrole)|
|**2024-08-08**|**Pairwise Judgment Formulation for Semantic Embedding Model in Web Search**|Mengze Hong et.al.|[2408.04197v1](http://arxiv.org/abs/2408.04197v1)|null|
|**2024-08-08**|**Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks**|Zepu Wang et.al.|[2408.04193v1](http://arxiv.org/abs/2408.04193v1)|null|
|**2024-08-08**|**Listwise Reward Estimation for Offline Preference-based Reinforcement Learning**|Heewoong Choi et.al.|[2408.04190v1](http://arxiv.org/abs/2408.04190v1)|[link](https://github.com/chwoong/lire)|
|**2024-08-08**|**wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**|Khai Le-Duc et.al.|[2408.04174v1](http://arxiv.org/abs/2408.04174v1)|null|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168v1](http://arxiv.org/abs/2408.04168v1)|null|
|**2024-08-08**|**Semantics or spelling? Probing contextual word embeddings with orthographic noise**|Jacob A. Matthews et.al.|[2408.04162v1](http://arxiv.org/abs/2408.04162v1)|[link](https://github.com/jam963/semantics-or-spelling)|
|**2024-08-08**|**The Data Addition Dilemma**|Judy Hanwen Shen et.al.|[2408.04154v1](http://arxiv.org/abs/2408.04154v1)|[link](https://github.com/the-chen-lab/data-addition-dilemma)|
|**2024-08-08**|**UNLEARN Efficient Removal of Knowledge in Large Language Models**|Tyler Lizzo et.al.|[2408.04140v1](http://arxiv.org/abs/2408.04140v1)|null|
|**2024-08-08**|**Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**|Haoran Yu et.al.|[2408.04138v1](http://arxiv.org/abs/2408.04138v1)|null|
|**2024-08-07**|**Incorporating Spatial Awareness in Data-Driven Gesture Generation for Virtual Agents**|Anna Deichler et.al.|[2408.04127v1](http://arxiv.org/abs/2408.04127v1)|null|
|**2024-08-07**|**Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**|Panagiotis Fytas et.al.|[2408.04121v1](http://arxiv.org/abs/2408.04121v1)|null|
|**2024-08-07**|**Zero-shot Factual Consistency Evaluation Across Domains**|Raunak Agarwal et.al.|[2408.04114v1](http://arxiv.org/abs/2408.04114v1)|null|
|**2024-08-07**|**Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization**|John Joon Young Chung et.al.|[2408.04112v1](http://arxiv.org/abs/2408.04112v1)|null|
|**2024-08-07**|**Hardware-Assisted Virtualization of Neural Processing Units for Cloud Platforms**|Yuqi Xue et.al.|[2408.04104v1](http://arxiv.org/abs/2408.04104v1)|null|
|**2024-08-07**|**ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**|William Y. Zhu et.al.|[2408.04102v1](http://arxiv.org/abs/2408.04102v1)|null|
|**2024-08-07**|**Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters**|Vasudev Shyam et.al.|[2408.04093v1](http://arxiv.org/abs/2408.04093v1)|null|
|**2024-08-07**|**AEye: A Visualization Tool for Image Datasets**|Florian Grötschla et.al.|[2408.04072v1](http://arxiv.org/abs/2408.04072v1)|[link](https://github.com/eth-disco/aeye)|
|**2024-08-07**|**Digital Avatars: Framework Development and Their Evaluation**|Timothy Rupprecht et.al.|[2408.04068v1](http://arxiv.org/abs/2408.04068v1)|null|
|**2024-08-07**|**PowerPM: Foundation Model for Power Systems**|Shihao Tu et.al.|[2408.04057v1](http://arxiv.org/abs/2408.04057v1)|null|
|**2024-08-07**|**Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives**|Aida Afshar et.al.|[2408.04046v1](http://arxiv.org/abs/2408.04046v1)|null|
|**2024-08-07**|**Human Speech Perception in Noise: Can Large Language Models Paraphrase to Improve It?**|Anupama Chingacham et.al.|[2408.04029v1](http://arxiv.org/abs/2408.04029v1)|[link](https://github.com/uds-lsv/llm_eval_pi-spin)|
|**2024-08-07**|**Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**|Joseph Cameron et.al.|[2408.04026v1](http://arxiv.org/abs/2408.04026v1)|null|
|**2024-08-07**|**Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity**|Wrick Talukdar et.al.|[2408.04023v1](http://arxiv.org/abs/2408.04023v1)|null|
|**2024-08-07**|**Image-to-LaTeX Converter for Mathematical Formulas and Text**|Daniil Gurgurov et.al.|[2408.04015v1](http://arxiv.org/abs/2408.04015v1)|[link](https://github.com/d-gurgurov/im2latex)|
|**2024-08-07**|**SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature**|Vinícius Di Oliveira et.al.|[2408.03936v1](http://arxiv.org/abs/2408.03936v1)|null|
|**2024-08-07**|**From Words to Worth: Newborn Article Impact Prediction with LLM**|Penghai Zhao et.al.|[2408.03934v1](http://arxiv.org/abs/2408.03934v1)|null|
|**2024-08-07**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910v1](http://arxiv.org/abs/2408.03910v1)|[link](https://github.com/modelscope/modelscope-agent)|
|**2024-08-07**|**Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models**|Shachi H Kumar et.al.|[2408.03907v1](http://arxiv.org/abs/2408.03907v1)|null|
|**2024-08-07**|**Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond**|Beomseok Lee et.al.|[2408.03900v1](http://arxiv.org/abs/2408.03900v1)|[link](https://github.com/hlt-mt/speech-massive)|
|**2024-08-07**|**Simplifying Scholarly Abstracts for Accessible Digital Libraries**|Haining Wang et.al.|[2408.03899v1](http://arxiv.org/abs/2408.03899v1)|null|
|**2024-08-07**|**MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems**|Renzhi Wang et.al.|[2408.03892v1](http://arxiv.org/abs/2408.03892v1)|null|
|**2024-08-07**|**Personalized Clinical Note Generation from Doctor-Patient Conversations**|Nathan Brake et.al.|[2408.03874v1](http://arxiv.org/abs/2408.03874v1)|null|
|**2024-08-07**|**Inter-Series Transformer: Attending to Products in Time Series Forecasting**|Rares Cristian et.al.|[2408.03872v1](http://arxiv.org/abs/2408.03872v1)|null|
|**2024-08-07**|**BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability**|Zihao Li et.al.|[2408.03871v1](http://arxiv.org/abs/2408.03871v1)|[link](https://github.com/hecta-uom/plaba-mu)|
|**2024-08-07**|**Why transformers are obviously good models of language**|Felix Hill et.al.|[2408.03855v1](http://arxiv.org/abs/2408.03855v1)|null|
|**2024-08-07**|**Hate Speech Detection and Classification in Amharic Text with Deep Learning**|Samuel Minale Gashe et.al.|[2408.03849v1](http://arxiv.org/abs/2408.03849v1)|null|
|**2024-08-07**|**MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models**|Yuchen Dong et.al.|[2408.03841v1](http://arxiv.org/abs/2408.03841v1)|null|
|**2024-08-07**|**WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models**|Prannaya Gupta et.al.|[2408.03837v1](http://arxiv.org/abs/2408.03837v1)|null|
|**2024-08-07**|**Target Prompting for Information Extraction with Vision Language Model**|Dipankar Medhi et.al.|[2408.03834v1](http://arxiv.org/abs/2408.03834v1)|null|
|**2024-08-07**|**Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps**|Forough Mehralian et.al.|[2408.03827v1](http://arxiv.org/abs/2408.03827v1)|null|

#### Abstracts
##### **Arctic-TILT. Business Document Understanding at Sub-Billion Scale**
2408.04632v1 by Łukasz Borchmann, Michał Pietruszka, Wojciech Jaśkowski, Dawid Jurkiewicz, Piotr Halama, Paweł Józiak, Łukasz Garncarek, Paweł Liskowski, Karolina Szyndler, Andrzej Gretkowski, Julita Ołtusek, Gabriela Nowakowska, Artur Zawłocki, Łukasz Duhr, Paweł Dyda, Michał Turski

The vast portion of workloads employing LLMs involves answering questions
grounded on PDF or scan content. We introduce the Arctic-TILT achieving
accuracy on par with models 1000$\times$ its size on these use cases. It can be
fine-tuned and deployed on a single 24GB GPU, lowering operational costs while
processing Visually Rich Documents with up to 400k tokens. The model
establishes state-of-the-art results on seven diverse Document Understanding
benchmarks, as well as provides reliable confidence scores and quick inference,
which are essential for processing files in large-scale or time-sensitive
enterprise environments.

摘要：絕大多數使用大型語言模型的工作負載，都涉及回答基於 PDF 或掃描內容的問題。我們介紹了 Arctic-TILT，在這些用例上實現了與其大小 1000 倍的模型相當的準確度。它可以在單個 24GB GPU 上進行微調和部署，在處理多達 400k 個令牌的視覺豐富文件時降低運營成本。該模型在七個不同的文件理解基準上建立了最先進的結果，並提供了可靠的置信度分數和快速推理，這對於在大型或時間敏感的企業環境中處理文件至關重要。

##### **Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics**
2408.04631v1 by Ruining Li, Chuanxia Zheng, Christian Rupprecht, Andrea Vedaldi

We present Puppet-Master, an interactive video generative model that can
serve as a motion prior for part-level dynamics. At test time, given a single
image and a sparse set of motion trajectories (i.e., drags), Puppet-Master can
synthesize a video depicting realistic part-level motion faithful to the given
drag interactions. This is achieved by fine-tuning a large-scale pre-trained
video diffusion model, for which we propose a new conditioning architecture to
inject the dragging control effectively. More importantly, we introduce the
all-to-first attention mechanism, a drop-in replacement for the widely adopted
spatial attention modules, which significantly improves generation quality by
addressing the appearance and background issues in existing models. Unlike
other motion-conditioned video generators that are trained on in-the-wild
videos and mostly move an entire object, Puppet-Master is learned from
Objaverse-Animation-HQ, a new dataset of curated part-level motion clips. We
propose a strategy to automatically filter out sub-optimal animations and
augment the synthetic renderings with meaningful motion trajectories.
Puppet-Master generalizes well to real images across various categories and
outperforms existing methods in a zero-shot manner on a real-world benchmark.
See our project page for more results: vgg-puppetmaster.github.io.

摘要：我們提出 Puppet-Master，一個互動式影片生成模型，可用作部分層級動態的動作先驗。在測試時，給定單一影像和一組稀疏的動作軌跡（即拖曳），Puppet-Master 可以合成影片，描繪出符合給定拖曳互動的逼真部分層級動作。這是透過微調大型預先訓練影片擴散模型來實現的，我們為此提出新的制約架構，以有效注入拖曳控制。更重要的是，我們引入全對一注意力機制，這是廣泛採用的空間注意力模組的替代方案，透過解決現有模型中的外觀和背景問題，顯著改善生成品質。與其他在野外影片上訓練且主要移動整個物體的動作條件影片生成器不同，Puppet-Master 是從 Objaverse-Animation-HQ（一種經過整理的部分層級動作片段的新資料集）學習的。我們提出策略，自動過濾掉次佳動畫，並使用有意義的動作軌跡擴充合成渲染。Puppet-Master 在各種類別的真實影像中都能很好地概括，並在真實世界的基準上以零次學習的方式優於現有方法。請參閱我們的專案頁面以取得更多結果：vgg-puppetmaster.github.io。

##### **LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP**
2408.04628v1 by Danlu Chen, Freda Shi, Aditi Agarwal, Jacobo Myerston, Taylor Berg-Kirkpatrick

Standard natural language processing (NLP) pipelines operate on symbolic
representations of language, which typically consist of sequences of discrete
tokens. However, creating an analogous representation for ancient logographic
writing systems is an extremely labor intensive process that requires expert
knowledge. At present, a large portion of logographic data persists in a purely
visual form due to the absence of transcription -- this issue poses a
bottleneck for researchers seeking to apply NLP toolkits to study ancient
logographic languages: most of the relevant data are images of writing.
  This paper investigates whether direct processing of visual representations
of language offers a potential solution. We introduce LogogramNLP, the first
benchmark enabling NLP analysis of ancient logographic languages, featuring
both transcribed and visual datasets for four writing systems along with
annotations for tasks like classification, translation, and parsing. Our
experiments compare systems that employ recent visual and text encoding
strategies as backbones. The results demonstrate that visual representations
outperform textual representations for some investigated tasks, suggesting that
visual processing pipelines may unlock a large amount of cultural heritage data
of logographic languages for NLP-based analyses.

摘要：標準自然語言處理 (NLP) 管線運作在語言的符號表示上，通常由離散記號序列組成。然而，為古代表意文字系統建立類比表示法是一個極度勞力的過程，需要專家知識。目前，由於缺乏轉錄，大部分表意資料仍以純粹視覺形式存在——這個問題對尋求使用 NLP 工具包研究古代表意文字的的研究人員構成瓶頸：大部分相關資料都是文字影像。
本文探討是否直接處理語言的視覺表示能提供潛在解決方案。我們介紹 LogogramNLP，這是第一個能對古代表意文字進行 NLP 分析的基準測試，提供四個文字系統的轉錄和視覺資料集，以及分類、翻譯和剖析等任務的註解。我們的實驗比較採用近期視覺和文字編碼策略作為主幹的系統。結果顯示，對於一些研究任務，視覺表示的表現優於文字表示，這表示視覺處理管線可能為 NLP 分析解鎖大量表意文字的文化遺產資料。

##### **Transformer Explainer: Interactive Learning of Text-Generative Models**
2408.04619v1 by Aeree Cho, Grace C. Kim, Alexander Karpekov, Alec Helbling, Zijie J. Wang, Seongmin Lee, Benjamin Hoover, Duen Horng Chau

Transformers have revolutionized machine learning, yet their inner workings
remain opaque to many. We present Transformer Explainer, an interactive
visualization tool designed for non-experts to learn about Transformers through
the GPT-2 model. Our tool helps users understand complex Transformer concepts
by integrating a model overview and enabling smooth transitions across
abstraction levels of mathematical operations and model structures. It runs a
live GPT-2 instance locally in the user's browser, empowering users to
experiment with their own input and observe in real-time how the internal
components and parameters of the Transformer work together to predict the next
tokens. Our tool requires no installation or special hardware, broadening the
public's education access to modern generative AI techniques. Our open-sourced
tool is available at https://poloclub.github.io/transformer-explainer/. A video
demo is available at https://youtu.be/ECR4oAwocjs.

摘要：Transformer 徹底改變了機器學習，但其內部運作對許多人來說仍然不透明。我們展示 Transformer Explainer，這是一個互動式視覺化工具，專為非專家設計，透過 GPT-2 模型來了解 Transformer。我們的工具透過整合模型概觀並在數學運算和模型結構的抽象層級之間實現平滑過渡，幫助使用者了解複雜的 Transformer 概念。它在使用者的瀏覽器中本地執行一個即時的 GPT-2 執行個體，使用戶能夠使用自己的輸入進行實驗，並即時觀察 Transformer 的內部組件和參數如何協同運作來預測下一個代幣。我們的工具不需要安裝或特殊硬體，擴大了大眾對現代生成式 AI 技術的教育管道。我們的開源工具可在 https://poloclub.github.io/transformer-explainer/ 取得。影片示範可在 https://youtu.be/ECR4oAwocjs 取得。

##### **Better Alignment with Instruction Back-and-Forth Translation**
2408.04614v1 by Thao Nguyen, Jeffrey Li, Sewoong Oh, Ludwig Schmidt, Jason Weston, Luke Zettlemoyer, Xian Li

We propose a new method, instruction back-and-forth translation, to construct
high-quality synthetic data grounded in world knowledge for aligning large
language models (LLMs). Given documents from a web corpus, we generate and
curate synthetic instructions using the backtranslation approach proposed by Li
et al.(2023a), and rewrite the responses to improve their quality further based
on the initial documents. Fine-tuning with the resulting (backtranslated
instruction, rewritten response) pairs yields higher win rates on AlpacaEval
than using other common instruction datasets such as Humpback, ShareGPT, Open
Orca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the
responses with an LLM outperforms direct distillation, and the two generated
text distributions exhibit significant distinction in embedding space. Further
analysis shows that our backtranslated instructions are of higher quality than
other sources of synthetic instructions, while our responses are more diverse
and complex than those obtained from distillation. Overall we find that
instruction back-and-forth translation combines the best of both worlds --
making use of the information diversity and quantity found on the web, while
ensuring the quality of the responses which is necessary for effective
alignment.

摘要：我們提出了一種新的方法，即指令來回翻譯，用於構建
基於世界知識的高品質合成資料，以對齊大型
語言模型 (LLM)。給定來自網路語料庫的文件，我們生成並
使用 Li
et al.(2023a) 提出的回譯方法整理合成指令，並根據
原始文件進一步改寫回應以提升其品質。使用產生的（回譯
指令、改寫回應）配對進行微調，在 AlpacaEval 上產生的獲勝率
高於使用其他常見指令資料集，例如 Humpback、ShareGPT、Open
Orca、Alpaca-GPT4 和 Self-instruct。我們也證明了使用 LLM 改寫
回應的表現優於直接萃取，而且這兩個生成的
文字分佈在嵌入空間中展現出顯著的區別。進一步的分析顯示，我們的回譯
指令品質高於其他合成指令來源，而我們的回應則比從萃取中獲得的
回應更為多元且複雜。總體而言，我們發現指令來回翻譯結合了兩全其美的優點
——利用網路上的資訊多元性和數量，同時
確保回應的品質，這對於有效的對齊是必要的。

##### **Code-switching in text and speech reveals information-theoretic audience design**
2408.04596v1 by Debasmita Bhattacharya, Marten van Schijndel

In this work, we use language modeling to investigate the factors that
influence code-switching. Code-switching occurs when a speaker alternates
between one language variety (the primary language) and another (the secondary
language), and is widely observed in multilingual contexts. Recent work has
shown that code-switching is often correlated with areas of high information
load in the primary language, but it is unclear whether high primary language
load only makes the secondary language relatively easier to produce at
code-switching points (speaker-driven code-switching), or whether
code-switching is additionally used by speakers to signal the need for greater
attention on the part of listeners (audience-driven code-switching). In this
paper, we use bilingual Chinese-English online forum posts and transcripts of
spontaneous Chinese-English speech to replicate prior findings that high
primary language (Chinese) information load is correlated with switches to the
secondary language (English). We then demonstrate that the information load of
the English productions is even higher than that of meaning equivalent Chinese
alternatives, and these are therefore not easier to produce, providing evidence
of audience-driven influences in code-switching at the level of the
communication channel, not just at the sociolinguistic level, in both writing
and speech.

摘要：在這項工作中，我們使用語言模型來探討影響代碼轉換的因素。代碼轉換發生在說話者在一個語言變體（主要語言）和另一個（次要語言）之間交替時，並且在多語言環境中廣泛觀察到。最近的研究表明，代碼轉換通常與主要語言中資訊負載高的區域相關，但目前尚不清楚高主要語言負載是否僅使次要語言在代碼轉換點更容易產生（說話者驅動的代碼轉換），或是否代碼轉換進一步由說話者用於傳達聽眾需要更多注意的需要（受眾驅動的代碼轉換）。在本文中，我們使用雙語中英語線上論壇文章和自發中英語語音的轉錄，以複製先前的發現，即高主要語言（中文）資訊負載與轉換到次要語言（英語）相關。然後，我們證明英語產出的資訊負載甚至高於意義等價的中文選項，因此這些選項並不容易產生，提供了在代碼轉換中受眾驅動影響的證據，不僅在社會語言層面，也在寫作和語音中，在溝通管道層面。

##### **Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models**
2408.04594v1 by Qirui Jiao, Daoyuan Chen, Yilun Huang, Yaliang Li, Ying Shen

High-performance Multimodal Large Language Models (MLLMs) rely heavily on
data quality. This study introduces a novel dataset named Img-Diff, designed to
enhance fine-grained image recognition in MLLMs by leveraging insights from
contrastive learning and image difference captioning. By analyzing object
differences between similar images, we challenge models to identify both
matching and distinct components. We utilize the Stable-Diffusion-XL model and
advanced image editing techniques to create pairs of similar images that
highlight object replacements. Our methodology includes a Difference Area
Generator for object differences identifying, followed by a Difference Captions
Generator for detailed difference descriptions. The result is a relatively
small but high-quality dataset of "object replacement" samples. We use the the
proposed dataset to fine-tune state-of-the-art (SOTA) MLLMs such as MGM-7B,
yielding comprehensive improvements of performance scores over SOTA models that
trained with larger-scale datasets, in numerous image difference and Visual
Question Answering tasks. For instance, our trained models notably surpass the
SOTA models GPT-4V and Gemini on the MMVP benchmark. Besides, we investigate
alternative methods for generating image difference data through "object
removal" and conduct thorough evaluation to confirm the dataset's diversity,
quality, and robustness, presenting several insights on synthesis of such
contrastive dataset. To encourage further research and advance the field of
multimodal data synthesis and enhancement of MLLMs' fundamental capabilities
for image understanding, we release our codes and dataset at
https://github.com/modelscope/data-juicer/tree/ImgDiff.

摘要：高性能多模态大型语言模型 (MLLM) 严重依赖数据质量。本研究引入了一个名为 Img-Diff 的新数据集，旨在通过利用对比学习和图像差异描述的见解来增强 MLLM 中的细粒度图像识别。通过分析相似图像之间的对象差异，我们挑战模型识别匹配和不同的组件。我们利用 Stable-Diffusion-XL 模型和先进的图像编辑技术创建了一对相似图像，突出显示对象替换。我们的方法包括用于识别对象差异的差异区域生成器，然后是用于详细差异描述的差异描述生成器。结果是一个相对较小但高质量的“对象替换”样本数据集。我们使用所提出的数据集对最先进 (SOTA) MLLM（例如 MGM-7B）进行微调，在众多图像差异和视觉问答任务中，与使用更大规模数据集训练的 SOTA 模型相比，性能得分得到了全面提高。例如，我们训练的模型在 MMVP 基准上明显超越了 SOTA 模型 GPT-4V 和 Gemini。此外，我们研究了通过“对象移除”生成图像差异数据的替代方法，并进行了彻底的评估以确认数据集的多样性、质量和鲁棒性，提出了对这种对比数据集合成的若干见解。为了鼓励进一步的研究和推进多模态数据合成和增强 MLLM 对图像理解的基本能力的领域，我们在 https://github.com/modelscope/data-juicer/tree/ImgDiff 上发布了我们的代码和数据集。

##### **HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts**
2408.04591v1 by Hongjun Wang, Sagar Vaze, Kai Han

Generalized Category Discovery (GCD) is a challenging task in which, given a
partially labelled dataset, models must categorize all unlabelled instances,
regardless of whether they come from labelled categories or from new ones. In
this paper, we challenge a remaining assumption in this task: that all images
share the same domain. Specifically, we introduce a new task and method to
handle GCD when the unlabelled data also contains images from different domains
to the labelled set. Our proposed `HiLo' networks extract High-level semantic
and Low-level domain features, before minimizing the mutual information between
the representations. Our intuition is that the clusterings based on domain
information and semantic information should be independent. We further extend
our method with a specialized domain augmentation tailored for the GCD task, as
well as a curriculum learning approach. Finally, we construct a benchmark from
corrupted fine-grained datasets as well as a large-scale evaluation on
DomainNet with real-world domain shifts, reimplementing a number of GCD
baselines in this setting. We demonstrate that HiLo outperforms SoTA category
discovery models by a large margin on all evaluations.

摘要：廣義類別發現 (GCD) 是一項具有挑戰性的任務，其中，在給定部分標籤資料集的情況下，模型必須對所有未標籤實例進行分類，無論它們來自標籤類別還是新類別。在本文中，我們挑戰了這項任務中的一個剩餘假設：所有圖像共享相同的網域。具體來說，我們引入了一個新任務和方法來處理 GCD，當未標籤資料也包含來自與標籤集不同網域的圖像時。我們提出的 `HiLo` 網路提取高級語義和低級網域特徵，然後最小化表示之間的互信息。我們的直覺是基於網域信息和語義信息的聚類應該是獨立的。我們進一步擴展了我們的方法，使用專門針對 GCD 任務量身定制的網域擴充，以及課程學習方法。最後，我們從損壞的細粒度資料集構建了一個基準，以及在具有真實世界網域轉移的 DomainNet 上進行大規模評估，在此設置中重新實現了許多 GCD 基線。我們證明 HiLo 在所有評估中都比 SoTA 類別發現模型表現出色。

##### **Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness**
2408.04585v1 by Xiaojing Fan, Chunliang Tao

With the increasing demand for practical applications of Large Language
Models (LLMs), many attention-efficient models have been developed to balance
performance and computational cost. However, the adversarial robustness of
these models remains under-explored. In this work, we design a framework to
investigate the trade-off between efficiency, performance, and adversarial
robustness of LLMs by comparing three prominent models with varying levels of
complexity and efficiency -- Transformer++, Gated Linear Attention (GLA)
Transformer, and MatMul-Free LM -- utilizing the GLUE and AdvGLUE datasets. The
AdvGLUE dataset extends the GLUE dataset with adversarial samples designed to
challenge model robustness. Our results show that while the GLA Transformer and
MatMul-Free LM achieve slightly lower accuracy on GLUE tasks, they demonstrate
higher efficiency and either superior or comparative robustness on AdvGLUE
tasks compared to Transformer++ across different attack levels. These findings
highlight the potential of simplified architectures to achieve a compelling
balance between efficiency, performance, and adversarial robustness, offering
valuable insights for applications where resource constraints and resilience to
adversarial attacks are critical.

摘要：隨著大型語言模型 (LLM) 實用應用需求的增加，許多注重效率的模型已被開發出來，以平衡效能和運算成本。然而，這些模型的對抗性穩健性仍未受到充分探討。在這項研究中，我們設計了一個架構來探討 LLM 的效率、效能和對抗性穩健性之間的取捨，方法是比較三個具有不同程度複雜性和效率的著名模型——Transformer++、門控線性注意力 (GLA) Transformer 和無 MatMul LM——並利用 GLUE 和 AdvGLUE 資料集。AdvGLUE 資料集擴充了 GLUE 資料集，其中包含旨在挑戰模型穩健性的對抗性樣本。我們的結果顯示，雖然 GLA Transformer 和無 MatMul LM 在 GLUE 任務上的準確度略低，但它們展現出更高的效率，並且在不同攻擊層級下，在 AdvGLUE 任務上展現出優於或相當的穩健性，優於 Transformer++。這些發現突顯了簡化架構在效率、效能和對抗性穩健性之間取得令人信服的平衡的潛力，為資源受限且對抗攻擊復原力至關重要的應用程式提供了寶貴的見解。

##### **SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals**
2408.04575v1 by Haoran Zheng, Utku Pamuksuz

Explainable Artificial Intelligence (XAI) is essential for enhancing the
transparency and accountability of AI models, especially in natural language
processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual
Evaluation for Natural language Explainability), a novel evaluation method that
leverages large language models (LLMs) to generate Soft Counterfactual
explanations in a zero-shot manner. By focusing on token-based substitutions,
SCENE creates contextually appropriate and seman-tically meaningful Soft
Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and
Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in
text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE
provides valuable insights into the strengths and limitations of various XAI
techniques.

摘要：可解釋人工智慧 (XAI) 對於提升人工智慧模型的透明度與可問責性至關重要，特別是在自然語言處理 (NLP) 任務中。本文介紹 SCENE（自然語言可解釋性的軟反事實評估），這是一種新穎的評估方法，利用大型語言模型 (LLM) 以零次學習的方式產生軟反事實解釋。SCENE 專注於基於代碼的替換，在不進行廣泛微調的情況下，建立符合脈絡且具有語義意義的軟反事實。SCENE 採用 Validitysoft 和 Csoft 指標來評估模型不可知 XAI 方法在文字分類任務中的有效性。SCENE 應用於 CNN、RNN 和 BERT 架構，提供了寶貴的見解，了解各種 XAI 技術的優點和限制。

##### **Learning Fine-Grained Grounded Citations for Attributed Large Language Models**
2408.04568v1 by Lei Huang, Xiaocheng Feng, Weitao Ma, Yuxuan Gu, Weihong Zhong, Xiachong Feng, Weijiang Yu, Weihua Peng, Duyu Tang, Dandan Tu, Bing Qin

Despite the impressive performance on information-seeking tasks, large
language models (LLMs) still struggle with hallucinations. Attributed LLMs,
which augment generated text with in-line citations, have shown potential in
mitigating hallucinations and improving verifiability. However, current
approaches suffer from suboptimal citation quality due to their reliance on
in-context learning. Furthermore, the practice of citing only coarse document
identifiers makes it challenging for users to perform fine-grained
verification. In this work, we introduce FRONT, a training framework designed
to teach LLMs to generate Fine-Grained Grounded Citations. By grounding model
outputs in fine-grained supporting quotes, these quotes guide the generation of
grounded and consistent responses, not only improving citation quality but also
facilitating fine-grained verification. Experiments on the ALCE benchmark
demonstrate the efficacy of FRONT in generating superior grounded responses and
highly supportive citations. With LLaMA-2-7B, the framework significantly
outperforms all the baselines, achieving an average of 14.21% improvement in
citation quality across all datasets, even surpassing ChatGPT.

摘要：儘管在資訊搜尋任務中表現出色，大型語言模型 (LLM) 仍難以克服幻覺問題。具歸因功能的 LLM 可在產生的文字中加入內文引文，已展現出減輕幻覺並提升可驗證性的潛力。然而，現行的做法仰賴於情境學習，因此引文品質不佳。此外，僅引述粗略的文件識別碼，使用戶難以進行細微的驗證。在本文中，我們介紹 FRONT，一種訓練架構，旨在教導 LLM 產生細微的 обосно引文。透過將模型輸出建立在細微的支援引文中，這些引文可引導產生 обосно且一致的回應，不僅提升引文品質，還能促進細微的驗證。在 ALCE 基準上的實驗證明了 FRONT 在產生優異的 обосно回應和高度支持性引文方面的效能。透過 LLaMA-2-7B，此架構大幅優於所有基線，在所有資料集中的引文品質平均提升 14.21%，甚至超越了 ChatGPT。

##### **Conversational Prompt Engineering**
2408.04560v1 by Liat Ein-Dor, Orith Toledo-Ronen, Artem Spector, Shai Gretz, Lena Dankin, Alon Halfon, Yoav Katz, Noam Slonim

Prompts are how humans communicate with LLMs. Informative prompts are
essential for guiding LLMs to produce the desired output. However, prompt
engineering is often tedious and time-consuming, requiring significant
expertise, limiting its widespread use. We propose Conversational Prompt
Engineering (CPE), a user-friendly tool that helps users create personalized
prompts for their specific tasks. CPE uses a chat model to briefly interact
with users, helping them articulate their output preferences and integrating
these into the prompt. The process includes two main stages: first, the model
uses user-provided unlabeled data to generate data-driven questions and utilize
user responses to shape the initial instruction. Then, the model shares the
outputs generated by the instruction and uses user feedback to further refine
the instruction and the outputs. The final result is a few-shot prompt, where
the outputs approved by the user serve as few-shot examples. A user study on
summarization tasks demonstrates the value of CPE in creating personalized,
high-performing prompts. The results suggest that the zero-shot prompt obtained
is comparable to its - much longer - few-shot counterpart, indicating
significant savings in scenarios involving repetitive tasks with large text
volumes.

摘要：提示是人類與 LLM 溝通的方式。提供資訊的提示對於引導 LLM 產生所需的輸出至關重要。然而，提示工程通常既乏味又耗時，需要大量的專業知識，限制了其廣泛使用。我們提出對話式提示工程 (CPE)，這是一個使用者友善的工具，可協助使用者為其特定任務建立個人化的提示。CPE 使用聊天模型與使用者進行簡短的互動，協助他們表達其輸出偏好並將這些偏好整合到提示中。這個過程包含兩個主要階段：首先，模型使用使用者提供的未標記資料來產生資料驅動的問題，並利用使用者的回應來塑造初始指令。然後，模型分享由指令產生的輸出，並使用使用者的回饋進一步改善指令和輸出。最終結果是一個少次提示，其中使用者核准的輸出作為少次範例。針對摘要任務進行的使用者研究證明了 CPE 在建立個人化、高執行效能提示方面的價值。結果顯示，獲得的零次提示與其長得多的少次對應提示相當，這表示在涉及大量文字內容的重複性任務中可以大幅節省。

##### **Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models**
2408.04556v1 by Yupeng Chang, Yi Chang, Yuan Wu

Large language models (LLMs) have exhibited remarkable proficiency across a
diverse array of natural language processing (NLP) tasks. However, adapting
LLMs to downstream applications typically necessitates computationally
intensive and memory-demanding fine-tuning procedures. To mitigate these
burdens, parameter-efficient fine-tuning (PEFT) techniques have emerged as a
promising approach to tailor LLMs with minimal computational overhead. While
PEFT methods offer substantial advantages, they do not fully address the
pervasive issue of bias propagation from pre-training data. In this work, we
introduce Bias-Aware Low-Rank Adaptation (BA-LoRA), a novel PEFT method
designed to counteract bias inheritance. BA-LoRA incorporates three distinct
regularization terms: (1) consistency regularizer, (2) diversity regularizer,
and (3) singular vector decomposition regularizer. These regularizers
collectively aim to improve the generative models' consistency, diversity, and
generalization capabilities during the fine-tuning process. Through extensive
experiments on a variety of natural language understanding (NLU) and natural
language generation (NLG) tasks, employing prominent LLMs such as LLaMA,
Mistral, and Gemma, we demonstrate that BA-LoRA surpasses the performance of
LoRA and its state-of-the-art variants. Moreover, our method effectively
mitigates the deleterious effects of pre-training bias, leading to more
reliable and robust model outputs. The code is available at
https://github.com/cyp-jlu-ai/BA-LoRA.

摘要：大型語言模型 (LLM) 已在各種自然語言處理 (NLP) 任務中展現出卓越的能力。然而，要將 LLM 調整到下游應用程式通常需要計算密集且需要大量記憶體的微調程序。為了減輕這些負擔，參數有效微調 (PEFT) 技術已成為一種有前途的方法，可針對 LLM 進行客製化，且計算負擔最小。儘管 PEFT 方法具有顯著的優勢，但它們並未完全解決預訓練資料中偏差傳播的普遍問題。在這項工作中，我們引入了具備偏差感知能力的低秩適應 (BA-LoRA)，這是一種新穎的 PEFT 方法，旨在對抗偏差遺傳。BA-LoRA 結合了三個不同的正則化項目：(1) 一致性正則化器、(2) 多樣性正則化器，以及 (3) 奇異值分解正則化器。這些正則化器共同旨在改善生成模型在微調過程中的一致性、多樣性和泛化能力。透過在各種自然語言理解 (NLU) 和自然語言生成 (NLG) 任務上進行廣泛的實驗，採用 LLaMA、Mistral 和 Gemma 等著名的 LLM，我們證明了 BA-LoRA 超越了 LoRA 及其最先進的變體的效能。此外，我們的模型有效減輕了預訓練偏差的有害影響，進而產生更可靠且穩健的模型輸出。程式碼可在 https://github.com/cyp-jlu-ai/BA-LoRA 取得。

##### **Molyé: A Corpus-based Approach to Language Contact in Colonial France**
2408.04554v1 by Rasul Dent, Juliette Janès, Thibault Clérice, Pedro Ortiz Suarez, Benoît Sagot

Whether or not several Creole languages which developed during the early
modern period can be considered genetic descendants of European languages has
been the subject of intense debate. This is in large part due to the absence of
evidence of intermediate forms. This work introduces a new open corpus, the
Moly\'e corpus, which combines stereotypical representations of three kinds of
language variation in Europe with early attestations of French-based Creole
languages across a period of 400 years. It is intended to facilitate future
research on the continuity between contact situations in Europe and Creolophone
(former) colonies.

摘要：早期現代時期發展出的幾種克里奧爾語是否可以視為歐洲語言的遺傳後裔，一直是爭論激烈的議題。這在很大程度上是因為缺乏中間形式的證據。這項研究引入了新的開放語料庫，即 Moly\'e 語料庫，結合了歐洲三種語言變體的刻板印象，以及 400 年來以法語為基礎的克里奧爾語的早期證明。其目的是促進未來對歐洲接觸狀況與克里奧爾語（前）殖民地之間的連續性的研究。

##### **MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic Text with Persuasion Techniques Identification**
2408.04540v1 by Md Rafiul Biswas, Zubair Shah, Wajdi Zaghouani

This paper focuses on detecting propagandistic spans and persuasion
techniques in Arabic text from tweets and news paragraphs. Each entry in the
dataset contains a text sample and corresponding labels that indicate the start
and end positions of propaganda techniques within the text. Tokens falling
within a labeled span were assigned "B" (Begin) or "I" (Inside), "O",
corresponding to the specific propaganda technique. Using attention masks, we
created uniform lengths for each span and assigned BIO tags to each token based
on the provided labels. Then, we used AraBERT-base pre-trained model for Arabic
text tokenization and embeddings with a token classification layer to identify
propaganda techniques. Our training process involves a two-phase fine-tuning
approach. First, we train only the classification layer for a few epochs,
followed by full model fine-tuning, updating all parameters. This methodology
allows the model to adapt to the specific characteristics of the propaganda
detection task while leveraging the knowledge captured by the pre-trained
AraBERT model. Our approach achieved an F1 score of 0.2774, securing the 3rd
position in the leaderboard of Task 1.

摘要：本文重點在於偵測推文和新聞段落中的阿拉伯語宣傳範圍和說服技巧。資料集中每個條目包含一個文字範本和對應標籤，標籤會指出文字中宣傳技巧的開始和結束位置。落在標籤範圍內的標記會被指定為「B」（開頭）或「I」（中間）、「O」，對應到特定的宣傳技巧。我們使用注意力遮罩，為每個範圍建立統一長度，並根據提供的標籤為每個標記指定 BIO 標籤。然後，我們使用 AraBERT-base 預訓練模型進行阿拉伯語文字標記化和內嵌，並使用標記分類層來識別宣傳技巧。我們的訓練過程包含一個兩階段微調方法。首先，我們只訓練分類層幾個時期，接著進行完整模型微調，更新所有參數。這種方法讓模型能夠適應宣傳偵測任務的特定特徵，同時運用預訓練 AraBERT 模型擷取的知識。我們的做法達到 0.2774 的 F1 分數，在任務 1 的排行榜中取得第 3 名。

##### **Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models**
2408.04522v1 by Fabio Pernisi, Dirk Hovy, Paul Röttger

As diverse linguistic communities and users adopt large language models
(LLMs), assessing their safety across languages becomes critical. Despite
ongoing efforts to make LLMs safe, they can still be made to behave unsafely
with jailbreaking, a technique in which models are prompted to act outside
their operational guidelines. Research on LLM safety and jailbreaking, however,
has so far mostly focused on English, limiting our understanding of LLM safety
in other languages. We contribute towards closing this gap by investigating the
effectiveness of many-shot jailbreaking, where models are prompted with unsafe
demonstrations to induce unsafe behaviour, in Italian. To enable our analysis,
we create a new dataset of unsafe Italian question-answer pairs. With this
dataset, we identify clear safety vulnerabilities in four families of
open-weight LLMs. We find that the models exhibit unsafe behaviors even when
prompted with few unsafe demonstrations, and -- more alarmingly -- that this
tendency rapidly escalates with more demonstrations.

摘要：隨著多元的語言社群和使用者採用大型語言模型 (LLM)，評估其跨語言安全性變得至關重要。儘管持續努力讓 LLM 安全，但仍可透過越獄技術讓它們表現得並不安全，這是一種提示模型在運作準則之外採取行動的技術。然而，針對 LLM 安全性和越獄的研究迄今主要集中在英文，這限制了我們對其他語言中 LLM 安全性的了解。我們透過調查多發越獄的有效性來縮小這個差距，其中提示模型透過不安全的示範來誘發不安全的行為，以義大利文進行。為了進行分析，我們建立了一個新的不安全義大利文問答配對資料集。透過這個資料集，我們在四個開放權重 LLM 家族中找出明確的安全漏洞。我們發現，即使提示的示範不多，這些模型也會表現出不安全的行為，而且更令人擔憂的是，這種趨勢會隨著示範的增加而迅速升高。

##### **Articulatory Configurations across Genders and Periods in French Radio and TV archives**
2408.04519v1 by Benjamin Elie, David Doukhan, Rémi Uro, Lucas Ondel-Yang, Albert Rilliard, Simon Devauchelle

This paper studies changes in articulatory configurations across genders and
periods using an inversion from acoustic to articulatory parameters. From a
diachronic corpus based on French media archives spanning 60 years from 1955 to
2015, automatic transcription and forced alignment allowed extracting the
central frame of each vowel. More than one million frames were obtained from
over a thousand speakers across gender and age categories. Their formants were
used from these vocalic frames to fit the parameters of Maeda's articulatory
model. Evaluations of the quality of these processes are provided. We focus
here on two parameters of Maeda's model linked to total vocal tract length: the
relative position of the larynx (higher for females) and the lips protrusion
(more protruded for males). Implications for voice quality across genders are
discussed. The effect across periods seems gender independent; thus, the
assertion that females lowered their pitch with time is not supported.

摘要：本文使用從聲學到語音參數的反演研究了跨性別和時期的語音配置變化。從一個基於法語媒體檔案的歷時語料庫，跨越 1955 年至 2015 年的 60 年，自動轉錄和強制對齊允許提取每個元音的中心幀。從跨性別和年齡類別的 1000 多名說話者中獲得了超過一百萬個幀。從這些元音幀中使用它們的共振峰來擬合 Maeda 語音模型的參數。提供了這些過程質量的評估。我們這裡重點關注與總聲道長度相關的 Maeda 模型的兩個參數：喉頭的相對位置（女性較高）和嘴唇突出（男性較突出）。討論了跨性別的聲音品質的影響。跨時期的影響似乎與性別無關；因此，女性隨著時間降低音高的說法得不到支持。

##### **Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**
2408.04491v1 by Vandan Gorade, Onkar Susladkar, Gorkem Durak, Elif Keles, Ertugrul Aktas, Timurhan Cebeci, Alpay Medetalibeyoglu, Daniela Ladner, Debesh Jha, Ulas Bagci

Liver cirrhosis, a leading cause of global mortality, requires precise
segmentation of ROIs for effective disease monitoring and treatment planning.
Existing segmentation models often fail to capture complex feature interactions
and generalize across diverse datasets. To address these limitations, we
propose a novel synergistic theory that leverages complementary latent spaces
for enhanced feature interaction modeling. Our proposed architecture,
nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes
and features auto-configured training. This approach captures both fine-grained
and coarse features, enabling effective modeling of intricate feature
interactions. We empirically validated nnSynergyNet3D on a private dataset of
628 high-resolution T1 abdominal MRI scans from 339 patients. Our model
outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot
testing on healthy liver CT scans from the public LiTS dataset demonstrated
superior cross-modal generalization capabilities. These results highlight the
potential of synergistic latent space models to improve segmentation accuracy
and robustness, thereby enhancing clinical workflows by ensuring consistency
across CT and MRI modalities.

摘要：肝硬化是全球死亡的主要原因，需要对 ROI 进行精确分割，以进行有效的疾病监测和治疗计划。现有的分割模型通常无法捕捉复杂的特征交互，并在不同的数据集上进行泛化。为了解决这些限制，我们提出了一种新颖的协同理论，该理论利用互补的潜在空间来增强特征交互建模。我们提出的架构 nnSynergyNet3D 集成了连续和离散的潜在空间，用于 3D 体积，并具有自动配置的训练。这种方法捕捉到了细粒度和粗粒度特征，从而能够有效地对复杂的特征交互进行建模。我们根据 339 名患者的 628 个高分辨率 T1 腹部 MRI 扫描的私有数据集对 nnSynergyNet3D 进行了实证验证。我们的模型比基线 nnUNet3D 的性能提高了大约 2%。此外，在来自公共 LiTS 数据集的健康肝脏 CT 扫描上进行零样本测试证明了其卓越的跨模态泛化能力。这些结果突出了协同潜在空间模型在提高分割精度和鲁棒性方面的潜力，从而通过确保 CT 和 MRI 模态的一致性来增强临床工作流程。

##### **SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios**
2408.04482v1 by Sriram Mandalika, Athira Nambiar

Most of the sophisticated AI models utilize huge amounts of annotated data
and heavy training to achieve high-end performance. However, there are certain
challenges that hinder the deployment of AI models "in-the-wild" scenarios,
i.e., inefficient use of unlabeled data, lack of incorporation of human
expertise, and lack of interpretation of the results. To mitigate these
challenges, we propose a novel Explainable Active Learning (XAL) model,
XAL-based semantic segmentation model "SegXAL", that can (i) effectively
utilize the unlabeled data, (ii) facilitate the "Human-in-the-loop" paradigm,
and (iii) augment the model decisions in an interpretable way. In particular,
we investigate the application of the SegXAL model for semantic segmentation in
driving scene scenarios. The SegXAL model proposes the image regions that
require labeling assistance from Oracle by dint of explainable AI (XAI) and
uncertainty measures in a weakly-supervised manner. Specifically, we propose a
novel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty
(EBU) module to get an Explainable Error Mask, which enables the machine
teachers/human experts to provide intuitive reasoning behind the results and to
solicit feedback to the AI system via an active learning strategy. Such a
mechanism bridges the semantic gap between man and machine through
collaborative intelligence, where humans and AI actively enhance each other's
complementary strengths. A novel high-confidence sample selection technique
based on the DICE similarity coefficient is also presented within the SegXAL
framework. Extensive quantitative and qualitative analyses are carried out in
the benchmarking Cityscape dataset. Results show the outperformance of our
proposed SegXAL against other state-of-the-art models.

摘要：大多數先進的 AI 模型都利用大量標註資料和嚴格訓練來達成高階效能。然而，在 AI 模型「在野」場景中部署時，會遇到某些挑戰，例如：非標註資料使用效率不彰、缺乏整合人類專業知識，以及缺乏對結果的詮釋。為了減輕這些挑戰，我們提出一個新穎的可解釋主動學習 (XAL) 模型，基於 XAL 的語意分割模型「SegXAL」，它可以 (i) 有效利用非標註資料，(ii) 促成「人類在迴圈中」的模式，以及 (iii) 以可解釋的方式擴充模型的決策。特別是，我們探討 SegXAL 模型在駕駛場景中用於語意分割的應用。SegXAL 模型提出需要標籤協助的影像區域，藉由可解釋 AI (XAI) 和不確定性測量，以弱監督的方式來達成。具體來說，我們提出一個新穎的鄰近感知可解釋 AI (PAE) 模組和基於熵的不確定性 (EBU) 模組，以取得可解釋錯誤遮罩，這讓機器教師/人類專家能夠對結果提供直覺性的推理，並透過主動學習策略向 AI 系統徵求回饋。這種機制透過協作智慧，縮小人類與機器之間的語意差距，人類與 AI 能夠積極地增強彼此的互補優勢。SegXAL 架構中也提出一個新穎的高信心樣本選取技術，基於 DICE 相似係數。在基準 Cityscape 資料集中進行廣泛的量化和質化分析。結果顯示我們提出的 SegXAL 優於其他現有技術模型。

##### **Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate**
2408.04472v1 by Yiqun Zhang, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song

Competitive debate is a comprehensive and complex computational argumentation
task. Large Language Models (LLMs) encounter hallucinations and lack
competitiveness in this task. To address these challenges, we introduce Agent
for Debate (Agent4Debate), a dynamic, multi-agent framework based on LLMs
designed to enhance their capabilities in competitive debate. Drawing
inspiration from human behavior in debate preparation and execution,
Agent4Debate employs a collaborative architecture where four specialized agents
(Searcher, Analyzer, Writer, and Reviewer) dynamically interact and cooperate.
These agents work throughout the debate process, covering multiple stages from
initial research and argument formulation to rebuttal and summary. To
comprehensively evaluate framework performance, we construct the Chinese Debate
Arena, comprising 66 carefully selected Chinese debate motions. We recruite ten
experienced human debaters and collect records of 200 debates involving
Agent4Debate, baseline models, and humans. The evaluation employs the Debatrix
automatic scoring system and professional human reviewers based on the
established Debatrix-Elo and Human-Elo ranking. Experimental results indicate
that the state-of-the-art Agent4Debate exhibits capabilities comparable to
those of humans. Furthermore, ablation studies demonstrate the effectiveness of
each component in the agent structure.

摘要：競爭性辯論是一種全面且複雜的計算論證任務。大型語言模型 (LLM) 在此任務中會遇到幻覺，且缺乏競爭力。為了應對這些挑戰，我們引入了辯論代理 (Agent4Debate)，這是一個基於 LLM 的動態多代理架構，旨在增強其在競爭性辯論中的能力。Agent4Debate 從人類在辯論準備和執行中的行為中汲取靈感，採用協作架構，其中四個專門代理（搜尋者、分析師、撰稿人和審閱者）動態互動並合作。這些代理在整個辯論過程中工作，涵蓋從初始研究和論證制定到反駁和總結的多個階段。為了全面評估框架效能，我們構建了包含 66 個精心挑選的中文辯論動議的中文辯論競技場。我們招募了十位經驗豐富的人類辯論者，並收集了 200 場涉及 Agent4Debate、基線模型和人類的辯論記錄。評估採用 Debatrix 自動評分系統和專業的人類審閱者，根據既定的 Debatrix-Elo 和 Human-Elo 排名。實驗結果表明，最先進的 Agent4Debate 所表現出的能力可與人類相媲美。此外，消融研究證明了代理結構中每個組成的有效性。

##### **Crowd Intelligence for Early Misinformation Prediction on Social Media**
2408.04463v1 by Megha Sundriyal, Harshit Choudhary, Tanmoy Chakraborty, Md Shad Akhtar

Misinformation spreads rapidly on social media, causing serious damage by
influencing public opinion, promoting dangerous behavior, or eroding trust in
reliable sources. It spreads too fast for traditional fact-checking, stressing
the need for predictive methods. We introduce CROWDSHIELD, a crowd
intelligence-based method for early misinformation prediction. We hypothesize
that the crowd's reactions to misinformation reveal its accuracy. Furthermore,
we hinge upon exaggerated assertions/claims and replies with particular
positions/stances on the source post within a conversation thread. We employ
Q-learning to capture the two dimensions -- stances and claims. We utilize deep
Q-learning due to its proficiency in navigating complex decision spaces and
effectively learning network properties. Additionally, we use a
transformer-based encoder to develop a comprehensive understanding of both
content and context. This multifaceted approach helps ensure the model pays
attention to user interaction and stays anchored in the communication's
content. We propose MIST, a manually annotated misinformation detection Twitter
corpus comprising nearly 200 conversation threads with more than 14K replies.
In experiments, CROWDSHIELD outperformed ten baseline systems, achieving an
improvement of ~4% macro-F1 score. We conduct an ablation study and error
analysis to validate our proposed model's performance. The source code and
dataset are available at https://github.com/LCS2-IIITD/CrowdShield.git.

摘要：错误信息在社交媒體上迅速傳播，通過影響公眾輿論、宣傳危險行為或侵蝕對可靠來源的信任，造成嚴重損害。它的傳播速度太快，以至於傳統的事實查核無法應對，這強調了對預測方法的需求。我們引入了 CROWDSHIELD，這是一種基於群眾智慧的早期錯誤信息預測方法。我們假設群眾對錯誤信息的反應揭示了它的準確性。此外，我們依賴於對話線程中源帖子的誇張斷言/主張和具有特定立場/態度的回復。我們採用 Q 學習來捕捉這兩個維度——立場和主張。我們利用深度 Q 學習，因為它擅長在複雜的決策空間中導航並有效地學習網路屬性。此外，我們使用基於 Transformer 的編碼器來全面理解內容和上下文。這種多方面的途徑有助於確保模型關注用戶互動並錨定在通信內容中。我們提出了 MIST，這是一個手動標註的錯誤信息檢測 Twitter 語料庫，包含近 200 個對話線程，其中有超過 14K 條回復。在實驗中，CROWDSHIELD 優於十個基準系統，宏觀 F1 分數提高了約 4%。我們進行消融研究和錯誤分析，以驗證我們提出的模型的性能。源代碼和數據集可在 https://github.com/LCS2-IIITD/CrowdShield.git 上獲得。

##### **RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents**
2408.04449v1 by Zihao Zhu, Bingzhe Wu, Zhengyou Zhang, Baoyuan Wu

The integration of large language models (LLMs) into robotics significantly
enhances the capabilities of embodied agents in understanding and executing
complex natural language instructions. However, the unmitigated deployment of
LLM-based embodied systems in real-world environments may pose potential
physical risks, such as property damage and personal injury. Existing security
benchmarks for LLMs overlook risk awareness for LLM-based embodied agents. To
address this gap, we propose RiskAwareBench, an automated framework designed to
assess physical risks awareness in LLM-based embodied agents. RiskAwareBench
consists of four modules: safety tips generation, risky scene generation, plan
generation, and evaluation, enabling comprehensive risk assessment with minimal
manual intervention. Utilizing this framework, we compile the PhysicalRisk
dataset, encompassing diverse scenarios with associated safety tips,
observations, and instructions. Extensive experiments reveal that most LLMs
exhibit insufficient physical risk awareness, and baseline risk mitigation
strategies yield limited enhancement, which emphasizes the urgency and
cruciality of improving risk awareness in LLM-based embodied agents in the
future.

摘要：大型語言模型 (LLM) 整合到機器人技術中，顯著提升了具身代理理解和執行複雜自然語言指令的能力。然而，在現實世界環境中部署基於 LLM 的具身系統可能會造成潛在的物理風險，例如財產損壞和人身傷害。現有的 LLM 安全基準忽略了對基於 LLM 的具身代理的風險意識。為了解決這個問題，我們提出了 RiskAwareBench，這是一個自動化框架，旨在評估基於 LLM 的具身代理中的物理風險意識。RiskAwareBench 包含四個模組：安全提示生成、風險場景生成、計畫生成和評估，以最少的介入實現全面的風險評估。利用這個框架，我們編制了 PhysicalRisk 資料集，其中包含各種場景以及相關的安全提示、觀察和說明。大量的實驗顯示，大多數 LLM 都表現出不足的物理風險意識，而且基準風險緩解策略產生的改善有限，這強調了在未來改善基於 LLM 的具身代理中的風險意識的迫切性和重要性。

##### **FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data**
2408.04442v1 by Ahmed Anwar, Brian Moser, Dayananda Herurkar, Federico Raue, Vinit Hegiste, Tatjana Legler, Andreas Dengel

The emergence of federated learning (FL) presents a promising approach to
leverage decentralized data while preserving privacy. Furthermore, the
combination of FL and anomaly detection is particularly compelling because it
allows for detecting rare and critical anomalies (usually also rare in locally
gathered data) in sensitive data from multiple sources, such as cybersecurity
and healthcare. However, benchmarking the performance of anomaly detection
methods in FL environments remains an underexplored area. This paper introduces
FedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection
algorithms within the context of FL. We systematically analyze and compare the
performance of recent deep learning anomaly detection models under federated
settings, which were typically assessed solely in centralized settings.
FedAD-Bench encompasses diverse datasets and metrics to provide a holistic
evaluation. Through extensive experiments, we identify key challenges such as
model aggregation inefficiencies and metric unreliability. We present insights
into FL's regularization effects, revealing scenarios in which it outperforms
centralized approaches due to its inherent ability to mitigate overfitting. Our
work aims to establish a standardized benchmark to guide future research and
development in federated anomaly detection, promoting reproducibility and fair
comparison across studies.

摘要：聯邦學習 (FL) 的出現提供了一個有前途的方法，可以在維護隱私的同時利用分散的數據。此外，FL 和異常檢測的結合特別引人注目，因為它允許從多個來源（例如網路安全和醫療保健）中檢測罕見和關鍵的異常（通常在本地收集的數據中也很罕見）。然而，在 FL 環境中對異常檢測方法的性能進行基準測試仍然是一個未被充分探索的領域。本文介紹了 FedAD-Bench，這是一個用於評估 FL 背景下無監督異常檢測演算法的統一基準。我們系統地分析並比較了最近深度學習異常檢測模型在聯邦設置下的性能，這些模型通常僅在集中式設置中進行評估。FedAD-Bench 涵蓋了多樣化的數據集和指標，以提供全面的評估。通過大量的實驗，我們確定了關鍵挑戰，例如模型聚合效率低下和指標不可靠。我們深入了解 FL 的正則化效應，揭示了由於其固有的減輕過度擬合的能力，它在哪些場景中優於集中式方法。我們的目標是建立一個標準化基準，以指導聯邦異常檢測的未來研究和開發，促進跨研究的可重複性和公平比較。

##### **Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models**
2408.04420v1 by Philipp Müller, Alexander Heimerl, Sayed Muddashir Hossain, Lea Siegel, Jan Alexandersson, Patrick Gebhard, Elisabeth André, Tanja Schneeberger

Human emotions are often not expressed directly, but regulated according to
internal processes and social display rules. For affective computing systems,
an understanding of how users regulate their emotions can be highly useful, for
example to provide feedback in job interview training, or in psychotherapeutic
scenarios. However, at present no method to automatically classify different
emotion regulation strategies in a cross-user scenario exists. At the same
time, recent studies showed that instruction-tuned Large Language Models (LLMs)
can reach impressive performance across a variety of affect recognition tasks
such as categorical emotion recognition or sentiment analysis. While these
results are promising, it remains unclear to what extent the representational
power of LLMs can be utilized in the more subtle task of classifying users'
internal emotion regulation strategy. To close this gap, we make use of the
recently introduced \textsc{Deep} corpus for modeling the social display of the
emotion shame, where each point in time is annotated with one of seven
different emotion regulation classes. We fine-tune Llama2-7B as well as the
recently introduced Gemma model using Low-rank Optimization on prompts
generated from different sources of information on the \textsc{Deep} corpus.
These include verbal and nonverbal behavior, person factors, as well as the
results of an in-depth interview after the interaction. Our results show, that
a fine-tuned Llama2-7B LLM is able to classify the utilized emotion regulation
strategy with high accuracy (0.84) without needing access to data from
post-interaction interviews. This represents a significant improvement over
previous approaches based on Bayesian Networks and highlights the importance of
modeling verbal behavior in emotion regulation.

摘要：人類的情緒通常不會直接表達出來，而是根據內部過程和社會展示規則進行調節。對於情感運算系統而言，了解使用者如何調節情緒可能非常有用，例如在面試培訓或心理治療場景中提供回饋。然而，目前尚無方法可在跨使用者場景中自動分類不同的情緒調節策略。同時，最近的研究表明，經過指示調整的大型語言模型 (LLM) 可以在一系列情感辨識任務中達到令人印象深刻的表現，例如分類情緒辨識或情緒分析。雖然這些結果令人振奮，但 LLM 的表徵能力在更細微的使用者內部情緒調節策略分類任務中能發揮多大作用仍不清楚。為了縮小這個差距，我們利用最近推出的「深度」語料庫來建模情緒羞恥的社會展示，其中每個時間點都標註了七種不同的情緒調節類別之一。我們微調了 Llama2-7B 以及最近推出的 Gemma 模型，使用低秩最佳化處理從「深度」語料庫中不同資訊來源產生的提示。這些資訊包括言語和非言語行為、個人因素，以及互動後深入訪談的結果。我們的結果顯示，微調後的 Llama2-7B LLM 能夠以高準確度 (0.84) 分類所使用的情緒調節策略，而不需要存取互動後訪談的資料。這代表相較於基於貝氏網路的先前方法有顯著的進步，並突顯了在情緒調節中建模言語行為的重要性。

##### **Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning**
2408.04414v1 by Seong-Il Park, Seung-Woo Choi, Na-Hyun Kim, Jay-Yoon Lee

Retrieval-Augmented Language Models (RALMs) have significantly improved
performance in open-domain question answering (QA) by leveraging external
knowledge. However, RALMs still struggle with unanswerable queries, where the
retrieved contexts do not contain the correct answer, and with conflicting
information, where different sources provide contradictory answers due to
imperfect retrieval. This study introduces an in-context learning-based
approach to enhance the reasoning capabilities of RALMs, making them more
robust in imperfect retrieval scenarios. Our method incorporates Machine
Reading Comprehension (MRC) demonstrations, referred to as cases, to boost the
model's capabilities to identify unanswerabilities and conflicts among the
retrieved contexts. Experiments on two open-domain QA datasets show that our
approach increases accuracy in identifying unanswerable and conflicting
scenarios without requiring additional fine-tuning. This work demonstrates that
in-context learning can effectively enhance the robustness of RALMs in
open-domain QA tasks.

摘要：檢索增強語言模型 (RALM) 透過利用外部知識，大幅提升了開放領域問答 (QA) 的效能。然而，RALM 仍難以應對無法回答的查詢，其中檢索到的脈絡不包含正確答案，以及矛盾資訊，其中不同的來源因檢索不完美而提供相互矛盾的答案。本研究引入基於脈絡中學習的方法，以增強 RALM 的推理能力，使其在不完美的檢索情境中更強健。我們的做法結合了機器閱讀理解 (MRC) 示範，稱為案例，以提升模型辨識檢索到的脈絡中無法回答和矛盾之處的能力。在兩個開放領域 QA 資料集上的實驗顯示，我們的做法提升了辨識無法回答和矛盾情境的準確度，而無需額外的微調。這項工作證明了脈絡中學習可以有效增強 RALM 在開放領域 QA 任務中的強健性。

##### **Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset**
2408.04403v1 by Kentaro Ozeki, Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima, Mitsuhiro Okada

This paper explores the question of how accurately current large language
models can perform logical reasoning in natural language, with an emphasis on
whether these models exhibit reasoning biases similar to humans. Specifically,
our study focuses on syllogistic reasoning, a form of deductive reasoning
extensively studied in cognitive science as a natural form of human reasoning.
We present a syllogism dataset called NeuBAROCO, which consists of syllogistic
reasoning problems in English and Japanese. This dataset was originally
designed for psychological experiments to assess human reasoning capabilities
using various forms of syllogisms. Our experiments with leading large language
models indicate that these models exhibit reasoning biases similar to humans,
along with other error tendencies. Notably, there is significant room for
improvement in reasoning problems where the relationship between premises and
hypotheses is neither entailment nor contradiction. We also present
experimental results and in-depth analysis using a new Chain-of-Thought
prompting method, which asks LLMs to translate syllogisms into abstract logical
expressions and then explain their reasoning process. Our analysis using this
method suggests that the primary limitations of LLMs lie in the reasoning
process itself rather than the interpretation of syllogisms.

摘要：這篇論文探討了目前大型語言模型在自然語言中執行邏輯推理的準確性，重點在於這些模型是否表現出與人類類似的推理偏差。具體來說，我們的研究重點在於三段論推理，這是一種演繹推理形式，在認知科學中被廣泛研究為人類推理的自然形式。我們提出了一個名為 NeuBAROCO 的三段論數據集，其中包含英語和日語的三段論推理問題。此數據集最初是為心理實驗設計的，用於使用各種形式的三段論評估人類推理能力。我們與領先的大型語言模型進行的實驗表明，這些模型表現出與人類類似的推理偏差，以及其他錯誤傾向。值得注意的是，在前提和假設之間的關係既不是蘊涵也不是矛盾的推理問題中，有很大的改進空間。我們還使用新的思想鏈提示方法提供了實驗結果和深入分析，該方法要求 LLM 將三段論翻譯成抽象邏輯表達式，然後解釋他們的推理過程。我們使用此方法進行的分析表明，LLM 的主要限制在於推理過程本身，而不是對三段論的解釋。

##### **DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**
2408.04400v1 by Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang

This paper addresses the challenge of out-of-distribution (OOD)
generalization in graph machine learning, a field rapidly advancing yet
grappling with the discrepancy between source and target data distributions.
Traditional graph learning algorithms, based on the assumption of uniform
distribution between training and test data, falter in real-world scenarios
where this assumption fails, resulting in suboptimal performance. A principal
factor contributing to this suboptimal performance is the inherent simplicity
bias of neural networks trained through Stochastic Gradient Descent (SGD),
which prefer simpler features over more complex yet equally or more predictive
ones. This bias leads to a reliance on spurious correlations, adversely
affecting OOD performance in various tasks such as image recognition, natural
language understanding, and graph classification. Current methodologies,
including subgraph-mixup and information bottleneck approaches, have achieved
partial success but struggle to overcome simplicity bias, often reinforcing
spurious correlations. To tackle this, we propose DIVE, training a collection
of models to focus on all label-predictive subgraphs by encouraging the models
to foster divergence on the subgraph mask, which circumvents the limitation of
a model solely focusing on the subgraph corresponding to simple structural
patterns. Specifically, we employs a regularizer to punish overlap in extracted
subgraphs across models, thereby encouraging different models to concentrate on
distinct structural patterns. Model selection for robust OOD performance is
achieved through validation accuracy. Tested across four datasets from GOOD
benchmark and one dataset from DrugOOD benchmark, our approach demonstrates
significant improvement over existing methods, effectively addressing the
simplicity bias and enhancing generalization in graph machine learning.

摘要：<paragraph>這篇論文探討了圖形機器學習中非分佈 (OOD) 概化的挑戰，這是一個快速發展的領域，但卻在應對來源和目標資料分佈之間的差異上遇到困難。傳統的圖形學習演算法基於訓練資料和測試資料之間均勻分佈的假設，但在這個假設失效的實際情況中會出現問題，導致次佳效能。造成這種次佳效能的主要因素是透過隨機梯度下降 (SGD) 訓練的神經網路固有的簡化偏差，它偏好較簡單的特徵，而非更複雜但預測能力相同或更高的特徵。這種偏差會導致依賴虛假相關性，對各種任務（例如影像辨識、自然語言理解和圖形分類）的 OOD 效能產生負面影響。目前的技術方法，包括子圖混合和資訊瓶頸方法，已取得部分成功，但仍難以克服簡化偏差，而且常常會強化虛假相關性。為了解決這個問題，我們提出了 DIVE，訓練一組模型以關注所有標籤預測子圖，方法是鼓勵模型在子圖遮罩上促進差異，這避開了模型僅關注對應於簡單結構模式的子圖的限制。具體來說，我們採用一個正規化器來懲罰模型之間提取的子圖中的重疊，從而鼓勵不同的模型專注於不同的結構模式。透過驗證準確度，可以選擇模型以獲得穩健的 OOD 效能。我們的做法在 GOOD 基準中的四個資料集和 DrugOOD 基準中的其中一個資料集上進行了測試，結果顯示出比現有方法有顯著的進步，有效地解決了簡化偏差，並增強了圖形機器學習中的概化能力。</paragraph>

##### **Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation**
2408.04394v1 by Nicy Scaria, Suma Dharani Chenna, Deepak Subramani

Developing questions that are pedagogically sound, relevant, and promote
learning is a challenging and time-consuming task for educators. Modern-day
large language models (LLMs) generate high-quality content across multiple
domains, potentially helping educators to develop high-quality questions.
Automated educational question generation (AEQG) is important in scaling online
education catering to a diverse student population. Past attempts at AEQG have
shown limited abilities to generate questions at higher cognitive levels. In
this study, we examine the ability of five state-of-the-art LLMs of different
sizes to generate diverse and high-quality questions of different cognitive
levels, as defined by Bloom's taxonomy. We use advanced prompting techniques
with varying complexity for AEQG. We conducted expert and LLM-based evaluations
to assess the linguistic and pedagogical relevance and quality of the
questions. Our findings suggest that LLms can generate relevant and
high-quality educational questions of different cognitive levels when prompted
with adequate information, although there is a significant variance in the
performance of the five LLms considered. We also show that automated evaluation
is not on par with human evaluation.

摘要：<paragraph>對於教育工作者來說，制定具有教學意義、相關且能促進學習的問題是一項具有挑戰性且耗時的任務。現代大型語言模型 (LLM) 可產生跨多個領域的高品質內容，潛在有助於教育工作者制定高品質的問題。自動化教育問題產生 (AEQG) 在擴展線上教育以迎合多元的學生族群方面非常重要。過去嘗試 AEQG 已顯示出在產生較高認知層級問題方面的能力有限。在本研究中，我們探討五種不同規模的最新 LLM 產生不同認知層級的多樣化且高品質問題的能力，正如布魯姆分類法所定義的。我們使用具有不同複雜性的進階提示技術進行 AEQG。我們進行專家和基於 LLM 的評估，以評估問題的語言和教學相關性及品質。我們的研究結果表明，當提示提供足夠的資訊時，LLM 可以產生不同認知層級的相關且高品質教育問題，儘管所考慮的五種 LLM 在效能上存在顯著差異。我們也表明，自動化評估無法與人類評估相提並論。</paragraph>

##### **Open-domain Implicit Format Control for Large Language Model Generation**
2408.04392v1 by Yiqun Yao, Wenjia Ma, Xuezhi Fang, Xin Jiang, Xiang Li, Xuying Meng, Peng Han, Jing Li, Aixin Sun, Yequan Wang

Controlling the format of outputs generated by large language models (LLMs)
is a critical functionality in various applications. Current methods typically
employ constrained decoding with rule-based automata or fine-tuning with
manually crafted format instructions, both of which struggle with open-domain
format requirements. To address this limitation, we introduce a novel framework
for controlled generation in LLMs, leveraging user-provided, one-shot QA pairs.
This study investigates LLMs' capabilities to follow open-domain, one-shot
constraints and replicate the format of the example answers. We observe that
this is a non-trivial problem for current LLMs. We also develop a dataset
collection methodology for supervised fine-tuning that enhances the open-domain
format control of LLMs without degrading output quality, as well as a benchmark
on which we evaluate both the helpfulness and format correctness of LLM
outputs. The resulting datasets, named OIFC-SFT, along with the related code,
will be made publicly available at https://github.com/cofe-ai/OIFC.

摘要：控制大型語言模型 (LLM) 生成的輸出格式在各種應用中是一項關鍵功能。目前的方法通常使用基於規則的自動機進行約束解碼或使用人工製作的格式指令進行微調，這兩種方法都難以滿足開放領域的格式要求。為了解決這個限制，我們引入了一個新的框架，用於在 LLM 中進行受控生成，利用用戶提供的單次問答對。這項研究調查了 LLM 遵循開放領域、單次約束和複製範例答案格式的能力。我們觀察到這對於目前的 LLM 來說是一個不平凡的問題。我們還開發了一種用於監督微調的數據集收集方法，該方法增強了 LLM 的開放領域格式控制，而不會降低輸出質量，並建立了一個基準，我們根據此基準評估 LLM 輸出的有用性和格式正確性。生成的數據集名為 OIFC-SFT，連同相關代碼，將在 https://github.com/cofe-ai/OIFC 上公開。

##### **MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**
2408.04388v1 by Haoxuan Li, Zhengmao Yang, Yunshan Ma, Yi Bin, Yang Yang, Tat-Seng Chua

We study an emerging and intriguing problem of multimodal temporal event
forecasting with large language models. Compared to using text or graph
modalities, the investigation of utilizing images for temporal event
forecasting has not been fully explored, especially in the era of large
language models (LLMs). To bridge this gap, we are particularly interested in
two key questions of: 1) why images will help in temporal event forecasting,
and 2) how to integrate images into the LLM-based forecasting framework. To
answer these research questions, we propose to identify two essential functions
that images play in the scenario of temporal event forecasting, i.e.,
highlighting and complementary. Then, we develop a novel framework, named
MM-Forecast. It employs an Image Function Identification module to recognize
these functions as verbal descriptions using multimodal large language models
(MLLMs), and subsequently incorporates these function descriptions into
LLM-based forecasting models. To evaluate our approach, we construct a new
multimodal dataset, MidEast-TE-mm, by extending an existing event dataset
MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast
can correctly identify the image functions, and further more, incorporating
these verbal function descriptions significantly improves the forecasting
performance. The dataset, code, and prompts are available at
https://github.com/LuminosityX/MM-Forecast.

摘要：我們研究多模態時間事件預測中一個新興且有趣的語言模型問題。相較於使用文字或圖表模態，利用影像進行時間事件預測的研究尚未被充分探索，特別是在大型語言模型 (LLM) 的時代。為了填補這個空白，我們特別感興趣的兩個關鍵問題是：1) 為什麼影像有助於時間事件預測，以及 2) 如何將影像整合到基於 LLM 的預測框架中。為了回答這些研究問題，我們提議找出影像在時間事件預測場景中扮演的兩個基本功能，即突顯和補充。然後，我們開發一個名為 MM-Forecast 的新框架。它使用影像功能識別模組，使用多模態大型語言模型 (MLLM) 將這些功能識別為文字描述，並隨後將這些功能描述納入基於 LLM 的預測模型中。為了評估我們的方法，我們通過使用影像擴充現有的事件資料集 MidEast-TE-mini，建構了一個新的多模態資料集 MidEast-TE-mm。實證研究表明，我們的 MM-Forecast 可以正確識別影像功能，此外，納入這些文字功能描述可以顯著改善預測效能。資料集、程式碼和提示可在 https://github.com/LuminosityX/MM-Forecast 取得。

##### **Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**
2408.04382v1 by Hsuan-Lei Shao

In court practice, legal professionals rely on their training to provide
opinions that resolve cases, one of the most crucial aspects being the ability
to identify similar judgments from previous courts efficiently. However,
finding a similar case is challenging and often depends on experience, legal
domain knowledge, and extensive labor hours, making veteran lawyers or judges
indispensable. This research aims to automate the analysis of judgment text
similarity. We utilized a judgment dataset labeled as the "golden standard" by
experts, which includes human-verified features that can be converted into an
"expert similarity score." We then constructed a knowledge graph based on
"case-article" relationships, ranking each case using natural language
processing to derive a "Node2vec similarity score." By evaluating these two
similarity scores, we identified their discrepancies and relationships. The
results can significantly reduce the labor hours required for legal searches
and recommendations, with potential applications extending to various fields of
information retrieval.

摘要：在法庭實務中，法律專業人士依賴其培訓提供意見以解決案件，其中最關鍵的方面之一是有效識別先前法院的類似判決的能力。然而，找出類似案件具有挑戰性，且通常取決於經驗、法律領域知識和大量的勞動時間，這使得資深律師或法官不可或缺。本研究旨在自動化判決文本相似性的分析。我們利用專家標記為「黃金標準」的判決資料集，其中包括可轉換為「專家相似性評分」的人工驗證特徵。然後，我們根據「案例-條文」關係建構知識圖譜，使用自然語言處理對每個案例進行排名，以得出「Node2vec 相似性評分」。透過評估這兩個相似性評分，我們找出其差異和關係。結果可以大幅減少法律搜尋和建議所需的勞動時間，潛在應用範圍擴及資訊檢索的各個領域。

##### **Overview of the NLPCC 2024 Shared Task on Chinese Metaphor Generation**
2408.04378v1 by Xingwei Qu, Ge Zhang, Siwei Wu, Yizhi Li, Chenghua Lin

This paper presents the results of the shared task on Chinese metaphor
generation, hosted at the 13th CCF Conference on Natural Language Processing
and Chinese Computing (NLPCC 2024). The goal of this shared task is to generate
Chinese metaphors using machine learning techniques and effectively identifying
basic components of metaphorical sentences. It is divided into two subtasks: 1)
Metaphor Generation, which involves creating a metaphor from a provided tuple
consisting of TENOR, GROUND, and VEHICLE. The goal here is to synthesize a
metaphor that connects the subject (i.e. TENOR) with the object (i.e. VEHICLE),
guided by the concept of the GROUND. 2) Metaphor Components Identification,
which extracts the most fitting TENORs, GROUNDs, and VEHICLEs from a
metaphorical sentence. This component requires the identification of the most
fitting metaphor elements that correspond to the specified grounds. In addition
to overall results, we report on the setup and insights from the metaphor
generation shared task, which attracted a total of 4 participating teams across
both subtasks.

摘要：本文展示了在自然語言處理和中文計算的第 13 屆中國計算機聯合會會議 (NLPCC 2024) 上舉辦的中文隱喻生成共享任務的結果。此共享任務的目標是使用機器學習技術生成中文隱喻，並有效識別隱喻句子的基本組成部分。它分為兩個子任務：1) 隱喻生成，包括從提供的包含 TENOR、GROUND 和 VEHICLE 的元組中創建隱喻。此處的目標是綜合一個將主體 (即 TENOR) 與客體 (即 VEHICLE) 聯繫起來的隱喻，並以 GROUND 的概念為指導。2) 隱喻組成部分識別，從隱喻句子中提取最合適的 TENOR、GROUND 和 VEHICLE。此組成部分需要識別與指定 GROUND 相應的最合適隱喻元素。除了整體結果外，我們還報告了隱喻生成共享任務的設置和見解，該任務共吸引了 4 個參與團隊參與兩個子任務。

##### **Simulating Articulatory Trajectories with Phonological Feature Interpolation**
2408.04363v1 by Angelo Ortiz Tandazo, Thomas Schatz, Thomas Hueber, Emmanuel Dupoux

As a first step towards a complete computational model of speech learning
involving perception-production loops, we investigate the forward mapping
between pseudo-motor commands and articulatory trajectories. Two phonological
feature sets, based respectively on generative and articulatory phonology, are
used to encode a phonetic target sequence. Different interpolation techniques
are compared to generate smooth trajectories in these feature spaces, with a
potential optimisation of the target value and timing to capture
co-articulation effects. We report the Pearson correlation between a linear
projection of the generated trajectories and articulatory data derived from a
multi-speaker dataset of electromagnetic articulography (EMA) recordings. A
correlation of 0.67 is obtained with an extended feature set based on
generative phonology and a linear interpolation technique. We discuss the
implications of our results for our understanding of the dynamics of biological
motion.

摘要：作為朝向涉及知覺-產生迴路的完整語音學習計算模型邁出的第一步，我們研究了偽動作命令和語音軌跡之間的前向映射。兩個音韻特徵集分別基於生成音韻學和語音音韻學，用於編碼音標目標序列。比較不同的插值技術以在這些特徵空間中產生平滑軌跡，並對目標值和時間進行潛在最佳化以捕捉共發音效應。我們報告了生成軌跡的線性投影與從電磁語音描記 (EMA) 記錄的多說話者數據集派生的語音數據之間的皮爾森相關性。使用基於生成音韻學和線性插值技術的擴展特徵集，獲得 0.67 的相關性。我們討論了我們的結果對我們理解生物運動動力學的影響。

##### **Towards Explainable Network Intrusion Detection using Large Language Models**
2408.04342v1 by Paul R. B. Houssel, Priyanka Singh, Siamak Layeghy, Marius Portmann

Large Language Models (LLMs) have revolutionised natural language processing
tasks, particularly as chat agents. However, their applicability to threat
detection problems remains unclear. This paper examines the feasibility of
employing LLMs as a Network Intrusion Detection System (NIDS), despite their
high computational requirements, primarily for the sake of explainability.
Furthermore, considerable resources have been invested in developing LLMs, and
they may offer utility for NIDS. Current state-of-the-art NIDS rely on
artificial benchmarking datasets, resulting in skewed performance when applied
to real-world networking environments. Therefore, we compare the GPT-4 and
LLama3 models against traditional architectures and transformer-based models to
assess their ability to detect malicious NetFlows without depending on
artificially skewed datasets, but solely on their vast pre-trained acquired
knowledge. Our results reveal that, although LLMs struggle with precise attack
detection, they hold significant potential for a path towards explainable NIDS.
Our preliminary exploration shows that LLMs are unfit for the detection of
Malicious NetFlows. Most promisingly, however, these exhibit significant
potential as complementary agents in NIDS, particularly in providing
explanations and aiding in threat response when integrated with Retrieval
Augmented Generation (RAG) and function calling capabilities.

摘要：大型語言模型 (LLM) 徹底改變了自然語言處理任務，特別是作為聊天機器人。然而，它們在威脅偵測問題中的適用性仍不明朗。本文探討了使用 LLM 作為網路入侵偵測系統 (NIDS) 的可行性，儘管它們的運算需求很高，但主要是為了可解釋性。此外，已經投入大量資源開發 LLM，它們可能為 NIDS 提供效用。目前最先進的 NIDS 依賴人工基準資料集，導致在應用於實際網路環境時效能偏差。因此，我們將 GPT-4 和 LLaMa3 模型與傳統架構和基於轉換器的模型進行比較，以評估它們在不依賴人工偏差資料集，而僅依賴它們龐大的預先訓練獲得的知識來偵測惡意 NetFlow 的能力。我們的結果顯示，儘管 LLM 在精確的攻擊偵測方面有困難，但它們在可解釋的 NIDS 路徑方面具有顯著的潛力。我們的初步探討表明，LLM 不適合偵測惡意的 NetFlow。然而，最令人振奮的是，這些模型作為 NIDS 中的輔助代理具有顯著的潛力，特別是在提供解釋和在與檢索擴充生成 (RAG) 和函式呼叫功能整合時協助威脅回應方面。

##### **KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination**
2408.04336v1 by Yin Gu, Qi Liu, Zhi Li, Kai Zhang

Zero-shot coordination (ZSC) remains a major challenge in the cooperative AI
field, which aims to learn an agent to cooperate with an unseen partner in
training environments or even novel environments. In recent years, a popular
ZSC solution paradigm has been deep reinforcement learning (DRL) combined with
advanced self-play or population-based methods to enhance the neural policy's
ability to handle unseen partners. Despite some success, these approaches
usually rely on black-box neural networks as the policy function. However,
neural networks typically lack interpretability and logic, making the learned
policies difficult for partners (e.g., humans) to understand and limiting their
generalization ability. These shortcomings hinder the application of
reinforcement learning methods in diverse cooperative scenarios.We suggest to
represent the agent's policy with an interpretable program. Unlike neural
networks, programs contain stable logic, but they are non-differentiable and
difficult to optimize.To automatically learn such programs, we introduce
Knowledge-driven Programmatic reinforcement learning for zero-shot Coordination
(KnowPC). We first define a foundational Domain-Specific Language (DSL),
including program structures, conditional primitives, and action primitives. A
significant challenge is the vast program search space, making it difficult to
find high-performing programs efficiently. To address this, KnowPC integrates
an extractor and an reasoner. The extractor discovers environmental transition
knowledge from multi-agent interaction trajectories, while the reasoner deduces
the preconditions of each action primitive based on the transition knowledge.

摘要：零次學習協調 (ZSC) 仍然是合作 AI 領域的一項重大挑戰，其目標是讓代理學習與訓練環境甚至新穎環境中未見的合作夥伴合作。近年來，一種流行的 ZSC 解決方案範例是深度強化學習 (DRL)，結合先進的自我對弈或基於族群的方法，以增強神經策略處理未見合作夥伴的能力。儘管取得一些成功，這些方法通常依賴黑盒神經網路作為策略函數。然而，神經網路通常缺乏可解釋性和邏輯，這使得合作夥伴（例如人類）難以理解所學習的策略，並限制其泛化能力。這些缺點阻礙了強化學習方法在各種合作場景中的應用。我們建議使用可解釋程式表示代理的策略。與神經網路不同，程式包含穩定的邏輯，但它們不可微分且難以最佳化。為了自動學習此類程式，我們引入了針對零次學習協調的知識驅動程式化強化學習 (KnowPC)。我們首先定義了一個基礎的特定領域語言 (DSL)，包括程式結構、條件基本元素和動作基本元素。一個重大的挑戰是龐大的程式搜尋空間，這使得難以有效找到高執行效能的程式。為了解決這個問題，KnowPC 整合了一個萃取器和一個推理器。萃取器從多重代理互動軌跡中發現環境轉換知識，而推理器則根據轉換知識推論每個動作基本元素的前提條件。

##### **Enhancing Journalism with AI: A Study of Contextualized Image Captioning for News Articles using LLMs and LMMs**
2408.04331v1 by Aliki Anagnostopoulou, Thiago Gouvea, Daniel Sonntag

Large language models (LLMs) and large multimodal models (LMMs) have
significantly impacted the AI community, industry, and various economic
sectors. In journalism, integrating AI poses unique challenges and
opportunities, particularly in enhancing the quality and efficiency of news
reporting. This study explores how LLMs and LMMs can assist journalistic
practice by generating contextualised captions for images accompanying news
articles. We conducted experiments using the GoodNews dataset to evaluate the
ability of LMMs (BLIP-2, GPT-4v, or LLaVA) to incorporate one of two types of
context: entire news articles, or extracted named entities. In addition, we
compared their performance to a two-stage pipeline composed of a captioning
model (BLIP-2, OFA, or ViT-GPT2) with post-hoc contextualisation with LLMs
(GPT-4 or LLaMA). We assess a diversity of models, and we find that while the
choice of contextualisation model is a significant factor for the two-stage
pipelines, this is not the case in the LMMs, where smaller, open-source models
perform well compared to proprietary, GPT-powered ones. Additionally, we found
that controlling the amount of provided context enhances performance. These
results highlight the limitations of a fully automated approach and underscore
the necessity for an interactive, human-in-the-loop strategy.

摘要：大型語言模型 (LLM) 和大型多模態模型 (LMM) 已顯著影響了 AI 社群、產業和各種經濟部門。在新聞業中，整合 AI 構成了獨特的挑戰和機遇，特別是在提升新聞報導的品質和效率方面。本研究探討了 LLM 和 LMM 如何透過為新聞文章附圖產生情境化標題，來協助新聞實務。我們使用 GoodNews 資料集進行實驗，以評估 LMM（BLIP-2、GPT-4v 或 LLaVA）納入兩種情境類型（整篇新聞文章或抽取的命名實體）的能力。此外，我們將其效能與由標題模型（BLIP-2、OFA 或 ViT-GPT2）組成的兩階段管線進行比較，並搭配 LLM（GPT-4 或 LLaMA）進行事後情境化。我們評估了各種模型，發現雖然情境化模型的選擇是兩階段管線的重要因素，但在 LMM 中並非如此，其中較小型、開放原始碼的模型表現良好，優於專有的 GPT 驅動模型。此外，我們發現控制提供的脈絡數量會提升效能。這些結果突顯了全自動化方法的限制，並強調了互動式、人類參與策略的必要性。

##### **HydraFormer: One Encoder For All Subsampling Rates**
2408.04325v1 by Yaoxun Xu, Xingchen Song, Zhiyong Wu, Di Wu, Zhendong Peng, Binbin Zhang

In automatic speech recognition, subsampling is essential for tackling
diverse scenarios. However, the inadequacy of a single subsampling rate to
address various real-world situations often necessitates training and deploying
multiple models, consequently increasing associated costs. To address this
issue, we propose HydraFormer, comprising HydraSub, a Conformer-based encoder,
and a BiTransformer-based decoder. HydraSub encompasses multiple branches, each
representing a distinct subsampling rate, allowing for the flexible selection
of any branch during inference based on the specific use case. HydraFormer can
efficiently manage different subsampling rates, significantly reducing training
and deployment expenses. Experiments on AISHELL-1 and LibriSpeech datasets
reveal that HydraFormer effectively adapts to various subsampling rates and
languages while maintaining high recognition performance. Additionally,
HydraFormer showcases exceptional stability, sustaining consistent performance
under various initialization conditions, and exhibits robust transferability by
learning from pretrained single subsampling rate automatic speech recognition
models\footnote{Model code and scripts:
https://github.com/HydraFormer/hydraformer}.

摘要：在自動語音辨識中，次抽樣對於處理各種場景至關重要。然而，單一抽樣率不足以應對各種現實世界的狀況，通常需要訓練和部署多個模型，從而增加相關成本。為了解決這個問題，我們提出了 HydraFormer，它包含一個基於 Conformer 的編碼器 HydraSub 和一個基於 BiTransformer 的解碼器。HydraSub 涵蓋多個分支，每個分支代表一個不同的抽樣率，允許在推理過程中根據具體用例靈活地選擇任何分支。HydraFormer 可以有效地管理不同的抽樣率，顯著降低訓練和部署費用。在 AISHELL-1 和 LibriSpeech 數據集上的實驗表明，HydraFormer 可以有效地適應各種抽樣率和語言，同時保持較高的辨識性能。此外，HydraFormer 展現出卓越的穩定性，在各種初始化條件下都能保持一致的性能，並通過從預訓練的單抽樣率自動語音辨識模型中學習，展現出強大的可移植性。

##### **Learning with Digital Agents: An Analysis based on the Activity Theory**
2408.04304v1 by Mateusz Dolata, Dzmitry Katsiuba, Natalie Wellnhammer, Gerhard Schwabe

Digital agents are considered a general-purpose technology. They spread
quickly in private and organizational contexts, including education. Yet,
research lacks a conceptual framing to describe interaction with such agents in
a holistic manner. While focusing on the interaction with a pedagogical agent,
i.e., a digital agent capable of natural-language interaction with a learner,
we propose a model of learning activity based on activity theory. We use this
model and a review of prior research on digital agents in education to analyze
how various characteristics of the activity, including features of a
pedagogical agent or learner, influence learning outcomes. The analysis leads
to identification of IS research directions and guidance for developers of
pedagogical agents and digital agents in general. We conclude by extending the
activity theory-based model beyond the context of education and show how it
helps designers and researchers ask the right questions when creating a digital
agent.

摘要：數位代理被視為一種通用技術。它們在私人和組織環境中迅速傳播，包括教育。然而，研究缺乏一個概念框架來描述與此類代理互動的整體方式。雖然專注於與教學代理的互動，即一種能夠與學習者進行自然語言互動的數位代理，我們根據活動理論提出了一個學習活動模型。我們使用此模型和對教育中數位代理的先前研究的回顧來分析活動的各種特徵，包括教學代理或學習者的特徵，如何影響學習成果。分析導致識別資訊系統研究方向和對教學代理和一般數位代理開發人員的指導。我們最後擴展了基於活動理論的模型，超越教育的範疇，並展示它如何幫助設計師和研究人員在建立數位代理時提出正確的問題。

##### **Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP**
2408.04303v1 by François Remy, Pieter Delobelle, Hayastan Avetisyan, Alfiya Khabibullina, Miryam de Lhoneux, Thomas Demeester

The development of monolingual language models for low and mid-resource
languages continues to be hindered by the difficulty in sourcing high-quality
training data. In this study, we present a novel cross-lingual vocabulary
transfer strategy, trans-tokenization, designed to tackle this challenge and
enable more efficient language adaptation. Our approach focuses on adapting a
high-resource monolingual LLM to an unseen target language by initializing the
token embeddings of the target language using a weighted average of
semantically similar token embeddings from the source language. For this, we
leverage a translation resource covering both the source and target languages.
We validate our method with the Tweeties, a series of trans-tokenized LLMs, and
demonstrate their competitive performance on various downstream tasks across a
small but diverse set of languages. Additionally, we introduce Hydra LLMs,
models with multiple swappable language modeling heads and embedding tables,
which further extend the capabilities of our trans-tokenization strategy. By
designing a Hydra LLM based on the multilingual model TowerInstruct, we
developed a state-of-the-art machine translation model for Tatar, in a
zero-shot manner, completely bypassing the need for high-quality parallel data.
This breakthrough is particularly significant for low-resource languages like
Tatar, where high-quality parallel data is hard to come by. By lowering the
data and time requirements for training high-quality models, our
trans-tokenization strategy allows for the development of LLMs for a wider
range of languages, especially those with limited resources. We hope that our
work will inspire further research and collaboration in the field of
cross-lingual vocabulary transfer and contribute to the empowerment of
languages on a global scale.

摘要：<paragraph>低資源和中資源語言的單語語言模型的開發，持續受到高品質訓練資料來源的困難所阻礙。在這項研究中，我們提出了一個新穎的跨語言詞彙轉移策略，稱為跨標記化，旨在解決這個挑戰，並實現更有效率的語言適應。我們的做法著重於透過使用來自來源語言的語義相似標記嵌入的加權平均值，將高資源單語 LLM 適應到未見的目標語言，來初始化目標語言的標記嵌入。為此，我們利用涵蓋來源語言和目標語言的翻譯資源。我們使用一系列跨標記化 LLM，也就是 Tweeties，驗證我們的模型，並在各種下游任務中，於一組數量少但多樣化的語言中，展示出它們具有競爭力的表現。此外，我們引入了 Hydra LLM，這是一種具有多個可交換語言模型頭和嵌入表的模型，進一步擴展了我們的跨標記化策略的功能。透過根據多語言模型 TowerInstruct 設計 Hydra LLM，我們開發了一個最先進的韃靼語機器翻譯模型，以零次學習的方式，完全繞過對高品質平行資料的需求。對於像韃靼語這種高品質平行資料難以取得的低資源語言而言，這個突破特別重要。透過降低訓練高品質模型的資料和時間需求，我們的跨標記化策略允許為更多語言開發 LLM，特別是那些資源有限的語言。我們希望我們的研究能激勵跨語言詞彙轉移領域進一步的研究和合作，並有助於在全球範圍內賦能語言。</paragraph>

##### **Tackling Noisy Clients in Federated Learning with End-to-end Label Correction**
2408.04301v1 by Xuefeng Jiang, Sheng Sun, Jia Li, Jingjing Xue, Runhan Li, Zhiyuan Wu, Gang Xu, Yuwei Wang, Min Liu

Recently, federated learning (FL) has achieved wide successes for diverse
privacy-sensitive applications without sacrificing the sensitive private
information of clients. However, the data quality of client datasets can not be
guaranteed since corresponding annotations of different clients often contain
complex label noise of varying degrees, which inevitably causes the performance
degradation. Intuitively, the performance degradation is dominated by clients
with higher noise rates since their trained models contain more misinformation
from data, thus it is necessary to devise an effective optimization scheme to
mitigate the negative impacts of these noisy clients. In this work, we propose
a two-stage framework FedELC to tackle this complicated label noise issue. The
first stage aims to guide the detection of noisy clients with higher label
noise, while the second stage aims to correct the labels of noisy clients' data
via an end-to-end label correction framework which is achieved by learning
possible ground-truth labels of noisy clients' datasets via back propagation.
We implement sixteen related methods and evaluate five datasets with three
types of complicated label noise scenarios for a comprehensive comparison.
Extensive experimental results demonstrate our proposed framework achieves
superior performance than its counterparts for different scenarios.
Additionally, we effectively improve the data quality of detected noisy
clients' local datasets with our label correction framework. The code is
available at https://github.com/Sprinter1999/FedELC.

摘要：近年来，联邦学习 (FL) 在不牺牲客户端敏感的私人信息的情况下，在各种注重隐私的应用程序中取得了广泛的成功。然而，由于不同客户端的相应注释通常包含不同程度的复杂标签噪声，因此无法保证客户端数据集的数据质量，这不可避免地会导致性能下降。直观地说，性能下降主要由噪声率较高的客户端主导，因为他们训练的模型包含更多来自数据错误信息，因此有必要设计一个有效的优化方案来减轻这些噪声客户端的负面影响。在这项工作中，我们提出了一个两阶段框架 FedELC 来解决这个复杂的标签噪声问题。第一阶段旨在指导检测标签噪声较高的噪声客户端，而第二阶段旨在通过端到端标签校正框架来校正噪声客户端数据的标签，这是通过反向传播学习噪声客户端数据集的可能真实标签来实现的。我们实现了十六种相关方法，并使用五种数据集评估了三种类型的复杂标签噪声场景，以进行全面比较。大量的实验结果表明，我们提出的框架在不同场景下比其对应框架实现了更好的性能。此外，我们通过标签校正框架有效地提高了检测到的噪声客户端本地数据集的数据质量。代码可在 https://github.com/Sprinter1999/FedELC 中获得。

##### **Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments**
2408.04293v1 by Kunitomo Tanaka, Ryohei Sasano, Koichi Takeda

Large language models (LLMs) are supposed to acquire unconscious human
knowledge and feelings, such as social common sense and biases, by training
models from large amounts of text. However, it is not clear how much the
sentiments of specific social groups can be captured in various LLMs. In this
study, we focus on social groups defined in terms of nationality, religion, and
race/ethnicity, and validate the extent to which sentiments between social
groups can be captured in and extracted from LLMs. Specifically, we input
questions regarding sentiments from one group to another into LLMs, apply
sentiment analysis to the responses, and compare the results with social
surveys. The validation results using five representative LLMs showed higher
correlations with relatively small p-values for nationalities and religions,
whose number of data points were relatively large. This result indicates that
the LLM responses including the inter-group sentiments align well with actual
social survey results.

摘要：大型語言模型 (LLM) 透過從大量的文字訓練模型，假設會習得無意識的人類知識和感受，例如社會常識和偏見。然而，尚不清楚特定社會群體的情緒可以在不同 LLM 中被捕捉到多少。在本研究中，我們專注於以國籍、宗教和種族/民族定義的社會群體，並驗證了 LLM 中可以捕捉和提取社會群體之間情緒的程度。具體來說，我們將關於一組對另一組的情緒問題輸入 LLM，對回應進行情緒分析，並將結果與社會調查進行比較。使用五個代表性 LLM 進行驗證的結果顯示，國籍和宗教的情緒相關性較高，且 p 值相對較小，其數據點數量相對較大。此結果表明，包括群際情緒在內的 LLM 回應與實際社會調查結果非常吻合。

##### **EMTeC: A Corpus of Eye Movements on Machine-Generated Texts**
2408.04289v1 by Lena Sophia Bolliger, Patrick Haller, Isabelle Caroline Rose Cretton, David Robert Reich, Tannon Kew, Lena Ann Jäger

The Eye Movements on Machine-Generated Texts Corpus (EMTeC) is a naturalistic
eye-movements-while-reading corpus of 107 native English speakers reading
machine-generated texts. The texts are generated by three large language models
using five different decoding strategies, and they fall into six different text
type categories. EMTeC entails the eye movement data at all stages of
pre-processing, i.e., the raw coordinate data sampled at 2000 Hz, the fixation
sequences, and the reading measures. It further provides both the original and
a corrected version of the fixation sequences, accounting for vertical
calibration drift. Moreover, the corpus includes the language models' internals
that underlie the generation of the stimulus texts: the transition scores, the
attention scores, and the hidden states. The stimuli are annotated for a range
of linguistic features both at text and at word level. We anticipate EMTeC to
be utilized for a variety of use cases such as, but not restricted to, the
investigation of reading behavior on machine-generated text and the impact of
different decoding strategies; reading behavior on different text types; the
development of new pre-processing, data filtering, and drift correction
algorithms; the cognitive interpretability and enhancement of language models;
and the assessment of the predictive power of surprisal and entropy for human
reading times. The data at all stages of pre-processing, the model internals,
and the code to reproduce the stimulus generation, data pre-processing and
analyses can be accessed via https://github.com/DiLi-Lab/EMTeC/.

摘要：<paragraph>機譯文本語料庫中的眼球運動 (EMTeC) 是一個自然主義語料庫，包含 107 位英語母語人士在閱讀機器產生的文本時的視線運動。這些文本由三個大型語言模型使用五種不同的解碼策略產生，並分為六種類型的文本。EMTeC 包含預處理所有階段的眼球運動數據，即以 2000 赫茲採樣的原始坐標數據、注視序列和閱讀測量。它進一步提供了注視序列的原始版本和校正版本，並考慮了垂直校準漂移。此外，語料庫還包括生成刺激文本的語言模型內部：轉換分數、注意力分數和隱藏狀態。刺激物會根據文本和詞彙層級的各種語言特徵進行標註。我們預期 EMTeC 可用於各種使用案例，例如，但不限於，調查機器產生的文本上的閱讀行為以及不同解碼策略的影響；不同文本類型上的閱讀行為；開發新的預處理、數據過濾和漂移校正演算法；語言模型的認知可解釋性和增強；以及評估驚訝度和熵對人類閱讀時間的預測能力。可以在 https://github.com/DiLi-Lab/EMTeC/ 訪問預處理所有階段的數據、模型內部以及用於重現刺激生成、數據預處理和分析的程式碼。</paragraph>

##### **LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection**
2408.04284v1 by Mervat Abassy, Kareem Elozeiri, Alexander Aziz, Minh Ngoc Ta, Raj Vardhan Tomar, Bimarsha Adhikari, Saad El Dine Ahmed, Yuxia Wang, Osama Mohammed Afzal, Zhuohan Xie, Jonibek Mansurov, Ekaterina Artemova, Vladislav Mikhailov, Rui Xing, Jiahui Geng, Hasan Iqbal, Zain Muhammad Mujahid, Tarek Mahmoud, Akim Tsvigun, Alham Fikri Aji, Artem Shelmanov, Nizar Habash, Iryna Gurevych, Preslav Nakov

The widespread accessibility of large language models (LLMs) to the general
public has significantly amplified the dissemination of machine-generated texts
(MGTs). Advancements in prompt manipulation have exacerbated the difficulty in
discerning the origin of a text (human-authored vs machinegenerated). This
raises concerns regarding the potential misuse of MGTs, particularly within
educational and academic domains. In this paper, we present
$\textbf{LLM-DetectAIve}$ -- a system designed for fine-grained MGT detection.
It is able to classify texts into four categories: human-written,
machine-generated, machine-written machine-humanized, and human-written
machine-polished. Contrary to previous MGT detectors that perform binary
classification, introducing two additional categories in LLM-DetectiAIve offers
insights into the varying degrees of LLM intervention during the text creation.
This might be useful in some domains like education, where any LLM intervention
is usually prohibited. Experiments show that LLM-DetectAIve can effectively
identify the authorship of textual content, proving its usefulness in enhancing
integrity in education, academia, and other domains. LLM-DetectAIve is publicly
accessible at https://huggingface.co/spaces/raj-tomar001/MGT-New. The video
describing our system is available at https://youtu.be/E8eT_bE7k8c.

摘要：大型語言模型 (LLM) 被廣泛應用於大眾，大幅擴大了機器產生的文本 (MGT) 的傳播。提示操作的進步加劇了辨別文本來源（人工撰寫與機器產生）的難度。這引起了對 MGT 可能被濫用的擔憂，特別是在教育和學術領域。在本文中，我們提出了 $\textbf{LLM-DetectAIve}$，一個專門設計用於精細 MGT 檢測的系統。它能夠將文本分類為四種類別：人工撰寫、機器產生、機器撰寫人工化，以及人工撰寫機器潤飾。與執行二元分類的先前 MGT 檢測器相反，在 LLM-DetectiAIve 中引入兩個額外的類別，提供了對文本創建過程中 LLM 介入程度的不同見解。這可能在某些領域（如教育）中很有用，在這些領域中通常禁止任何 LLM 介入。實驗表明，LLM-DetectAIve 可以有效識別文本內容的作者，證明了它在加強教育、學術和其他領域的誠信方面的有用性。LLM-DetectAIve 可在 https://huggingface.co/spaces/raj-tomar001/MGT-New 公開獲得。描述我們系統的影片可在 https://youtu.be/E8eT_bE7k8c 取得。

##### **LaDiMo: Layer-wise Distillation Inspired MoEfier**
2408.04278v1 by Sungyoon Kim, Youngjun Kim, Kihyo Moon, Minsung Jang

The advent of large language models has revolutionized natural language
processing, but their increasing complexity has led to substantial training
costs, resource demands, and environmental impacts. In response, sparse
Mixture-of-Experts (MoE) models have emerged as a promising alternative to
dense models. Since training MoE models from scratch can be prohibitively
expensive, recent studies have explored leveraging knowledge from pre-trained
non-MoE models. However, existing approaches have limitations, such as
requiring significant hardware resources and data. We propose a novel
algorithm, LaDiMo, which efficiently converts a Transformer-based non-MoE model
into a MoE model with minimal additional training cost. LaDiMo consists of two
stages: layer-wise expert construction and routing policy decision. By
harnessing the concept of Knowledge Distillation, we compress the model and
rapidly recover its performance. Furthermore, we develop an adaptive router
that optimizes inference efficiency by profiling the distribution of routing
weights and determining a layer-wise policy that balances accuracy and latency.
We demonstrate the effectiveness of our method by converting the LLaMA2-7B
model to a MoE model using only 100K tokens, reducing activated parameters by
over 20% while keeping accuracy. Our approach offers a flexible and efficient
solution for building and deploying MoE models.

摘要：大型語言模型的出現徹底改變了自然語言處理，但它們日益增長的複雜性導致了大量的訓練成本、資源需求和環境影響。為了解決這個問題，稀疏混合專家 (MoE) 模型已成為稠密模型的有前途的替代方案。由於從頭開始訓練 MoE 模型可能會非常昂貴，因此最近的研究探索了利用預訓練非 MoE 模型的知識。然而，現有方法存在局限性，例如需要大量的硬體資源和資料。我們提出了一種新演算法 LaDiMo，它可以有效地將基於 Transformer 的非 MoE 模型轉換為 MoE 模型，而額外的訓練成本極低。LaDiMo 包含兩個階段：逐層專家構造和路由策略決策。通過利用知識蒸餾的概念，我們壓縮模型並快速恢復其效能。此外，我們開發了一個自適應路由器，它通過分析路由權重的分佈並確定平衡準確性和延遲的逐層策略，來最佳化推理效率。我們通過使用僅 100K 個符號將 LLaMA2-7B 模型轉換為 MoE 模型來證明我們方法的有效性，在保持準確性的同時，將已啟用的參數減少了 20% 以上。我們的做法為建構和部署 MoE 模型提供了一個靈活且有效率的解決方案。

##### **Analysis of Argument Structure Constructions in the Large Language Model BERT**
2408.04270v1 by Pegah Ramezani, Achim Schilling, Patrick Krauss

This study investigates how BERT processes and represents Argument Structure
Constructions (ASCs), extending previous LSTM analyses. Using a dataset of 2000
sentences across four ASC types (transitive, ditransitive, caused-motion,
resultative), we analyzed BERT's token embeddings across 12 layers.
Visualizations with MDS and t-SNE and clustering quantified by Generalized
Discrimination Value (GDV) were used. Feedforward classifiers (probes)
predicted construction categories from embeddings. CLS token embeddings
clustered best in layers 2-4, decreased in intermediate layers, and slightly
increased in final layers. DET and SUBJ embeddings showed consistent clustering
in intermediate layers, VERB embeddings increased in clustering from layer 1 to
12, and OBJ embeddings peaked in layer 10. Probe accuracies indicated low
construction information in layer 1, with over 90 percent accuracy from layer 2
onward, revealing latent construction information beyond GDV clustering. Fisher
Discriminant Ratio (FDR) analysis of attention weights showed OBJ tokens were
crucial for differentiating ASCs, followed by VERB and DET tokens. SUBJ, CLS,
and SEP tokens had insignificant FDR scores. This study highlights BERT's
layered processing of linguistic constructions and its differences from LSTMs.
Future research will compare these findings with neuroimaging data to
understand the neural correlates of ASC processing. This research underscores
neural language models' potential to mirror linguistic processing in the human
brain, offering insights into the computational and neural mechanisms
underlying language understanding.

摘要：本研究探討 BERT 如何處理和表示論證結構構作 (ASC)，並擴展先前的 LSTM 分析。我們使用包含四種 ASC 類型的 2000 個句子的資料集（及物、雙及物、致使動態、結果），分析了 BERT 在 12 層中的標記嵌入。我們使用了 MDS 和 t-SNE 視覺化以及由廣義區分值 (GDV) 量化的分群。前饋分類器（探測器）根據嵌入預測構作類別。CLS 標記嵌入在第 2-4 層中最佳分群，在中間層中減少，在最後一層中略有增加。DET 和 SUBJ 嵌入在中間層中顯示一致的分群，VERB 嵌入從第 1 層到第 12 層的分群增加，而 OBJ 嵌入在第 10 層達到峰值。探測準確度表明第 1 層中的構作資訊較低，從第 2 層開始準確度超過 90%，揭示了超越 GDV 分群的潛在構作資訊。注意力權重的 Fisher 判別比 (FDR) 分析顯示，OBJ 標記對於區分 ASC 至關重要，其次是 VERB 和 DET 標記。SUBJ、CLS 和 SEP 標記的 FDR 分數微不足道。本研究強調了 BERT 對語言構作的分層處理及其與 LSTM 的區別。未來的研究將把這些發現與神經影像資料進行比較，以了解 ASC 處理的神經相關性。本研究強調了神經語言模型在反映人類大腦中語言處理方面的潛力，並提供了對語言理解的計算和神經機制的見解。

##### **Unveiling Hidden Visual Information: A Reconstruction Attack Against Adversarial Visual Information Hiding**
2408.04261v1 by Jonggyu Jang, Hyeonsu Lyu, Seongjin Hwang, Hyun Jong Yang

This paper investigates the security vulnerabilities of
adversarial-example-based image encryption by executing data reconstruction
(DR) attacks on encrypted images. A representative image encryption method is
the adversarial visual information hiding (AVIH), which uses type-I adversarial
example training to protect gallery datasets used in image recognition tasks.
In the AVIH method, the type-I adversarial example approach creates images that
appear completely different but are still recognized by machines as the
original ones. Additionally, the AVIH method can restore encrypted images to
their original forms using a predefined private key generative model. For the
best security, assigning a unique key to each image is recommended; however,
storage limitations may necessitate some images sharing the same key model.
This raises a crucial security question for AVIH: How many images can safely
share the same key model without being compromised by a DR attack? To address
this question, we introduce a dual-strategy DR attack against the AVIH
encryption method by incorporating (1) generative-adversarial loss and (2)
augmented identity loss, which prevent DR from overfitting -- an issue akin to
that in machine learning. Our numerical results validate this approach through
image recognition and re-identification benchmarks, demonstrating that our
strategy can significantly enhance the quality of reconstructed images, thereby
requiring fewer key-sharing encrypted images. Our source code to reproduce our
results will be available soon.

摘要：本論文透過對加密影像執行資料重建 (DR) 攻擊，探討對抗範例基礎影像加密的安全漏洞。具有代表性的影像加密方法為對抗視覺資訊隱藏 (AVIH)，它使用類型 I 對抗範例訓練，以保護用於影像辨識任務的圖庫資料集。在 AVIH 方法中，類型 I 對抗範例方法會產生看起來完全不同，但機器仍將其辨識為原始影像的影像。此外，AVIH 方法可以使用預先定義的私密金鑰生成模型，將加密影像還原為其原始形式。為了獲得最佳安全性，建議為每個影像指定一個唯一金鑰；但是，儲存限制可能需要一些影像共用同一個金鑰模型。這為 AVIH 提出了一個重要的安全性問題：有多少影像可以安全地共用同一個金鑰模型，而不會受到 DR 攻擊的危害？為了回答這個問題，我們針對 AVIH 加密方法引入了一個雙重策略 DR 攻擊，方法是納入 (1) 生成對抗損失和 (2) 增強身分損失，以防止 DR 過度擬合，這是一個類似於機器學習中的問題。我們的數值結果透過影像辨識和重新辨識基準驗證了這個方法，證明我們的策略可以顯著提升重建影像的品質，進而減少需要金鑰共用的加密影像。我們用來產生結果的原始碼將很快提供。

##### **EfficientRAG: Efficient Retriever for Multi-Hop Question Answering**
2408.04259v1 by Ziyuan Zhuang, Zhiyang Zhang, Sitao Cheng, Fangkai Yang, Jia Liu, Shujian Huang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

Retrieval-augmented generation (RAG) methods encounter difficulties when
addressing complex questions like multi-hop queries. While iterative retrieval
methods improve performance by gathering additional information, current
approaches often rely on multiple calls of large language models (LLMs). In
this paper, we introduce EfficientRAG, an efficient retriever for multi-hop
question answering. EfficientRAG iteratively generates new queries without the
need for LLM calls at each iteration and filters out irrelevant information.
Experimental results demonstrate that EfficientRAG surpasses existing RAG
methods on three open-domain multi-hop question-answering datasets.

摘要：檢索增強生成（RAG）方法在處理複雜問題（例如多跳查詢）時會遇到困難。雖然反覆檢索方法透過收集額外資訊來提升效能，但目前的作法通常仰賴大型語言模型（LLM）的多重呼叫。在本文中，我們介紹 EfficientRAG，這是一種用於多跳問答的高效檢索器。EfficientRAG 會反覆產生新查詢，而無需在每次反覆時呼叫 LLM，並會過濾掉無關的資訊。實驗結果證明，EfficientRAG 在三個開放領域多跳問答資料集上優於現有的 RAG 方法。

##### **Explicating the Implicit: Argument Detection Beyond Sentence Boundaries**
2408.04246v1 by Paul Roit, Aviv Slobodkin, Eran Hirsch, Arie Cattan, Ayal Klein, Valentina Pyatkin, Ido Dagan

Detecting semantic arguments of a predicate word has been conventionally
modeled as a sentence-level task. The typical reader, however, perfectly
interprets predicate-argument relations in a much wider context than just the
sentence where the predicate was evoked. In this work, we reformulate the
problem of argument detection through textual entailment to capture semantic
relations across sentence boundaries. We propose a method that tests whether
some semantic relation can be inferred from a full passage by first encoding it
into a simple and standalone proposition and then testing for entailment
against the passage. Our method does not require direct supervision, which is
generally absent due to dataset scarcity, but instead builds on existing NLI
and sentence-level SRL resources. Such a method can potentially explicate
pragmatically understood relations into a set of explicit sentences. We
demonstrate it on a recent document-level benchmark, outperforming some
supervised methods and contemporary language models.

摘要：傳統上，偵測謂詞字的語義論元被建模為句子層級的任務。然而，典型的讀者會在比謂詞被引發的句子更廣泛的脈絡中完美地詮釋謂詞-論元關係。在這項工作中，我們透過文本蘊涵重新制定論元偵測的問題，以捕捉跨越句子邊界的語義關係。我們提出一個方法，透過將語義關係編碼成一個簡單且獨立的命題，然後測試與段落的蘊涵關係，來測試是否可以從一個完整的段落中推論出一些語義關係。我們的這種方法不需要直接監督，這通常由於資料集的稀少而無法進行，但它建立在現有的 NLI 和句子層級 SRL 資源之上。這種方法有可能將語用理解的關係解釋為一組明確的句子。我們在最近的文件層級基準上展示了它，其表現優於一些監督式方法和當代語言模型。

##### **Scalable Transformer for High Dimensional Multivariate Time Series Forecasting**
2408.04245v1 by Xin Zhou, Weiqing Wang, Wray Buntine, Shilin Qu, Abishek Sriramulu, Weicong Tan, Christoph Bergmeir

Deep models for Multivariate Time Series (MTS) forecasting have recently
demonstrated significant success. Channel-dependent models capture complex
dependencies that channel-independent models cannot capture. However, the
number of channels in real-world applications outpaces the capabilities of
existing channel-dependent models, and contrary to common expectations, some
models underperform the channel-independent models in handling high-dimensional
data, which raises questions about the performance of channel-dependent models.
To address this, our study first investigates the reasons behind the suboptimal
performance of these channel-dependent models on high-dimensional MTS data. Our
analysis reveals that two primary issues lie in the introduced noise from
unrelated series that increases the difficulty of capturing the crucial
inter-channel dependencies, and challenges in training strategies due to
high-dimensional data. To address these issues, we propose STHD, the Scalable
Transformer for High-Dimensional Multivariate Time Series Forecasting. STHD has
three components: a) Relation Matrix Sparsity that limits the noise introduced
and alleviates the memory issue; b) ReIndex applied as a training strategy to
enable a more flexible batch size setting and increase the diversity of
training data; and c) Transformer that handles 2-D inputs and captures channel
dependencies. These components jointly enable STHD to manage the
high-dimensional MTS while maintaining computational feasibility. Furthermore,
experimental results show STHD's considerable improvement on three
high-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source
code and dataset are publicly available
https://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.

摘要：多元時間序列 (MTS) 預測的深度模型最近已展現顯著的成功。通道依賴模型捕捉通道獨立模型無法捕捉的複雜依賴關係。然而，實際應用中的通道數量超過現有通道依賴模型的能力，而且與一般預期相反，有些模型在處理高維度數據時表現不如通道獨立模型，這引發了關於通道依賴模型效能的問題。為了解決這個問題，我們的研究首先探討這些通道依賴模型在高維度 MTS 數據上表現不佳的原因。我們的分析顯示，兩個主要問題在於來自不相關序列的雜訊，增加了捕捉關鍵通道間依賴關係的難度，以及由於高維度數據造成的訓練策略挑戰。為了解決這些問題，我們提出了 STHD，即高維度多元時間序列預測的可擴充Transformer。STHD 有三個組成部分：a) 關係矩陣稀疏性，限制引進的雜訊並減輕記憶體問題；b) ReIndex 作為訓練策略應用，以啟用更靈活的批次大小設定並增加訓練數據的多樣性；c) Transformer，處理 2D 輸入並捕捉通道依賴關係。這些組成部分共同使 STHD 能管理高維度 MTS，同時維持運算可行性。此外，實驗結果顯示 STHD 在三個高維度資料集上大幅進步：Crime-Chicago、Wiki-People 和 Traffic。原始程式碼和資料集公開於 https://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git。

##### **The Ungrounded Alignment Problem**
2408.04242v1 by Marc Pickett, Aakash Kumar Nain, Joseph Modayil, Llion Jones

Modern machine learning systems have demonstrated substantial abilities with
methods that either embrace or ignore human-provided knowledge, but combining
benefits of both styles remains a challenge. One particular challenge involves
designing learning systems that exhibit built-in responses to specific abstract
stimulus patterns, yet are still plastic enough to be agnostic about the
modality and exact form of their inputs. In this paper, we investigate what we
call The Ungrounded Alignment Problem, which asks How can we build in
predefined knowledge in a system where we don't know how a given stimulus will
be grounded? This paper examines a simplified version of the general problem,
where an unsupervised learner is presented with a sequence of images for the
characters in a text corpus, and this learner is later evaluated on its ability
to recognize specific (possibly rare) sequential patterns. Importantly, the
learner is given no labels during learning or evaluation, but must map images
from an unknown font or permutation to its correct class label. That is, at no
point is our learner given labeled images, where an image vector is explicitly
associated with a class label. Despite ample work in unsupervised and
self-supervised loss functions, all current methods require a labeled
fine-tuning phase to map the learned representations to correct classes.
Finding this mapping in the absence of labels may seem a fool's errand, but our
main result resolves this seeming paradox. We show that leveraging only letter
bigram frequencies is sufficient for an unsupervised learner both to reliably
associate images to class labels and to reliably identify trigger words in the
sequence of inputs. More generally, this method suggests an approach for
encoding specific desired innate behaviour in modality-agnostic models.

摘要：現代機器學習系統已透過採用或忽略人類提供的知識的方法展示出驚人的能力，但結合兩種風格的優點仍然是一項挑戰。其中一個特別的挑戰涉及設計學習系統，這些系統對特定的抽象刺激模式表現出內建反應，但仍具有足夠的可塑性，可以對輸入的模式和確切形式保持不可知論。在本文中，我們探討我們稱之為「未接地對齊問題」的問題，它提出了一個問題：我們如何在我們不知道給定刺激將如何接地的系統中建構預定義的知識？本文探討了這個一般問題的簡化版本，其中非監督式學習者會看到文本語料庫中角色的一系列圖像，而這個學習者稍後會根據其識別特定（可能是罕見）順序模式的能力進行評估。重要的是，學習者在學習或評估期間不會獲得任何標籤，但必須將來自未知字體或排列的圖像映射到其正確的類別標籤。也就是說，在任何時候，我們的學習者都不會獲得標籤圖像，其中圖像向量與類別標籤明確關聯。儘管在非監督式和自監督式損失函數方面有充足的工作，但所有目前的方法都需要一個標籤微調階段，才能將學習到的表示映射到正確的類別。在沒有標籤的情況下找到此映射可能看起來像傻瓜的差事，但我們的成果解決了這個看似矛盾的現象。我們表明，僅利用字母二元組頻率就足以讓非監督式學習者將圖像可靠地關聯到類別標籤，並可靠地識別輸入序列中的觸發字。更普遍地說，此方法提出了一種在與模式無關的模型中編碼特定所需先天行為的方法。

##### **Learning to Rewrite: Generalized LLM-Generated Text Detection**
2408.04237v1 by Wei Hao, Ran Li, Weiliang Zhao, Junfeng Yang, Chengzhi Mao

Large language models (LLMs) can be abused at scale to create non-factual
content and spread disinformation. Detecting LLM-generated content is essential
to mitigate these risks, but current classifiers often fail to generalize in
open-world contexts. Prior work shows that LLMs tend to rewrite LLM-generated
content less frequently, which can be used for detection and naturally
generalizes to unforeseen data. However, we find that the rewriting edit
distance between human and LLM content can be indistinguishable across domains,
leading to detection failures. We propose training an LLM to rewrite input
text, producing minimal edits for LLM-generated content and more edits for
human-written text, deriving a distinguishable and generalizable edit distance
difference across different domains. Experiments on text from 21 independent
domains and three popular LLMs (e.g., GPT-4o, Gemini, and Llama-3) show that
our classifier outperforms the state-of-the-art zero-shot classifier by up to
20.6% on AUROC score and the rewriting classifier by 9.2% on F1 score. Our work
suggests that LLM can effectively detect machine-generated text if they are
trained properly.

摘要：大型語言模型 (LLM) 可能會被大規模濫用，用於建立非事實內容並散布錯誤訊息。偵測 LLM 生成的內容對於減輕這些風險至關重要，但目前的分類器通常無法在開放世界的環境中進行概化。先前的研究顯示，LLM 傾向於減少改寫 LLM 生成的內容，這可用於偵測並自然概化到無法預見的資料。然而，我們發現人類和 LLM 內容之間的改寫編輯距離在不同領域中可能無法區分，導致偵測失敗。我們建議訓練 LLM 改寫輸入文字，對 LLM 生成的內容產生最小的編輯，對人類撰寫的文字產生較多的編輯，從而得出不同領域中可區分且可概化的編輯距離差異。針對來自 21 個獨立領域和三個熱門 LLM（例如 GPT-4o、Gemini 和 Llama-3）的文字進行的實驗顯示，我們的分類器在 AUROC 分數上比最先進的零次學習分類器高出 20.6%，在 F1 分數上比改寫分類器高出 9.2%。我們的研究表明，只要經過適當的訓練，LLM 可以有效偵測機器產生的文字。

##### **Probabilistic Circuits for Cumulative Distribution Functions**
2408.04229v1 by Oliver Broadrick, William Cao, Benjie Wang, Martin Trapp, Guy Van den Broeck

A probabilistic circuit (PC) succinctly expresses a function that represents
a multivariate probability distribution and, given sufficient structural
properties of the circuit, supports efficient probabilistic inference.
Typically a PC computes the probability mass (or density) function (PMF or PDF)
of the distribution. We consider PCs instead computing the cumulative
distribution function (CDF). We show that for distributions over binary random
variables these representations (PMF and CDF) are essentially equivalent, in
the sense that one can be transformed to the other in polynomial time. We then
show how a similar equivalence holds for distributions over finite discrete
variables using a modification of the standard encoding with binary variables
that aligns with the CDF semantics. Finally we show that for continuous
variables, smooth, decomposable PCs computing PDFs and CDFs can be efficiently
transformed to each other by modifying only the leaves of the circuit.

摘要：機率電路 (PC) 簡潔地表達一個表示多變量機率分佈的函數，並且在電路具有足夠結構特性的情況下，支援有效的機率推論。PC 通常會計算分佈的機率質量 (或密度) 函數 (PMF 或 PDF)。我們考慮 PC 計算累積分佈函數 (CDF)。我們證明，對於二元隨機變數上的分佈，這些表示法 (PMF 和 CDF) 本質上是等效的，因為其中一個可以在多項式時間內轉換為另一個。然後，我們展示類似的等價性如何適用於有限離散變數上的分佈，方法是修改具有二元變數的標準編碼，使其與 CDF 語義保持一致。最後，我們證明對於連續變數，計算 PDF 和 CDF 的平滑、可分解 PC 可以透過僅修改電路的葉節點來有效地相互轉換。

##### **Evaluating Language Model Math Reasoning via Grounding in Educational Curricula**
2408.04226v1 by Li Lucy, Tal August, Rose E. Wang, Luca Soldaini, Courtney Allison, Kyle Lo

Our work presents a novel angle for evaluating language models' (LMs)
mathematical abilities, by investigating whether they can discern skills and
concepts enabled by math content. We contribute two datasets: one consisting of
385 fine-grained descriptions of K-12 math skills and concepts, or standards,
from Achieve the Core (ATC), and another of 9.9K problems labeled with these
standards (MathFish). Working with experienced teachers, we find that LMs
struggle to tag and verify standards linked to problems, and instead predict
labels that are close to ground truth, but differ in subtle ways. We also show
that LMs often generate problems that do not fully align with standards
described in prompts. Finally, we categorize problems in GSM8k using math
standards, allowing us to better understand why some problems are more
difficult to solve for models than others.

摘要：我們的研究提出了一個評估語言模型 (LM) 數學能力的新角度，方法是調查它們是否能辨別數學內容所啟用的技能和概念。我們貢獻了兩個數據集：一個包含 385 個 K-12 數學技能和概念或標準的細緻描述，來自 Achieve the Core (ATC)，另一個包含 9.9K 個標記了這些標準的問題 (MathFish)。與經驗豐富的老師合作，我們發現 LM 很難標記和驗證與問題相關的標準，而是預測接近真實情況但以微妙方式不同的標籤。我們還展示了 LM 通常會產生與提示中描述的標準完全不一致的問題。最後，我們使用數學標準對 GSM8k 中的問題進行分類，讓我們能更好地了解為什麼某些問題對模型來說比其他問題更難解決。

##### **VideoQA in the Era of LLMs: An Empirical Study**
2408.04223v1 by Junbin Xiao, Nanxin Huang, Hangyu Qin, Dongyang Li, Yicong Li, Fengbin Zhu, Zhulin Tao, Jianxing Yu, Liang Lin, Tat-Seng Chua, Angela Yao

Video Large Language Models (Video-LLMs) are flourishing and has advanced
many video-language tasks. As a golden testbed, Video Question Answering
(VideoQA) plays pivotal role in Video-LLM developing. This work conducts a
timely and comprehensive study of Video-LLMs' behavior in VideoQA, aiming to
elucidate their success and failure modes, and provide insights towards more
human-like video understanding and question answering. Our analyses demonstrate
that Video-LLMs excel in VideoQA; they can correlate contextual cues and
generate plausible responses to questions about varied video contents. However,
models falter in handling video temporality, both in reasoning about temporal
content ordering and grounding QA-relevant temporal moments. Moreover, the
models behave unintuitively - they are unresponsive to adversarial video
perturbations while being sensitive to simple variations of candidate answers
and questions. Also, they do not necessarily generalize better. The findings
demonstrate Video-LLMs' QA capability in standard condition yet highlight their
severe deficiency in robustness and interpretability, suggesting the urgent
need on rationales in Video-LLM developing.

摘要：影片大型語言模型（Video-LLM）蓬勃發展，並提升了許多影片語言任務。影片問答（VideoQA）作為一個黃金測試平台，在 Video-LLM 的發展中扮演著舉足輕重的角色。這項工作對 Video-LLM 在 VideoQA 中的行為進行及時且全面的研究，旨在闡明它們的成功與失敗模式，並提供洞見以朝向更類似人類的影片理解和問題解答。我們的分析證明 Video-LLM 在 VideoQA 中表現出色；它們可以關聯脈絡線索，並對各種影片內容的問題產生合理的回應。然而，模型在處理影片時間性方面表現不佳，無論是在推論時間內容排序，還是建立與 QA 相關的時間點方面。此外，這些模型的行為不直觀——它們對對抗性影片擾動沒有反應，但對候選答案和問題的簡單變化很敏感。此外，它們不一定能進行更好的概括。這些發現證明了 Video-LLM 在標準條件下的 QA 能力，但也突出了它們在穩健性和可解釋性方面的嚴重不足，這表明在 Video-LLM 開發中迫切需要依據。

##### **Connective Viewpoints of Signal-to-Noise Diffusion Models**
2408.04221v1 by Khanh Doan, Long Tung Vuong, Tuan Nguyen, Anh Tuan Bui, Quyen Tran, Thanh-Toan Do, Dinh Phung, Trung Le

Diffusion models (DM) have become fundamental components of generative
models, excelling across various domains such as image creation, audio
generation, and complex data interpolation. Signal-to-Noise diffusion models
constitute a diverse family covering most state-of-the-art diffusion models.
While there have been several attempts to study Signal-to-Noise (S2N) diffusion
models from various perspectives, there remains a need for a comprehensive
study connecting different viewpoints and exploring new perspectives. In this
study, we offer a comprehensive perspective on noise schedulers, examining
their role through the lens of the signal-to-noise ratio (SNR) and its
connections to information theory. Building upon this framework, we have
developed a generalized backward equation to enhance the performance of the
inference process.

摘要：擴散模型 (DM) 已成為生成模型的基本組成部分，在各種領域中表現優異，例如影像建立、音訊生成和複雜資料內插。信號對雜訊擴散模型構成一個多元的家族，涵蓋大多數最先進的擴散模型。雖然已經有幾項嘗試從各種角度研究信號對雜訊 (S2N) 擴散模型，但仍需要一項綜合研究，連結不同的觀點並探索新的觀點。在本研究中，我們針對雜訊排程器提供全面的觀點，透過信號對雜訊比 (SNR) 的觀點審查它們的角色及其與資訊理論的關聯。建立在這個架構之上，我們開發了一個廣義後向方程式，以增強推理程序的效能。

##### **Diffusion Guided Language Modeling**
2408.04220v1 by Justin Lovelace, Varsha Kishore, Yiwei Chen, Kilian Q. Weinberger

Current language models demonstrate remarkable proficiency in text
generation. However, for many applications it is desirable to control
attributes, such as sentiment, or toxicity, of the generated language --
ideally tailored towards each specific use case and target audience. For
auto-regressive language models, existing guidance methods are prone to
decoding errors that cascade during generation and degrade performance. In
contrast, text diffusion models can easily be guided with, for example, a
simple linear sentiment classifier -- however they do suffer from significantly
higher perplexity than auto-regressive alternatives. In this paper we use a
guided diffusion model to produce a latent proposal that steers an
auto-regressive language model to generate text with desired properties. Our
model inherits the unmatched fluency of the auto-regressive approach and the
plug-and-play flexibility of diffusion. We show that it outperforms previous
plug-and-play guidance methods across a wide range of benchmark data sets.
Further, controlling a new attribute in our framework is reduced to training a
single logistic regression classifier.

摘要：<paragraph>目前的語言模型在文字生成方面展現出卓越的熟練度。然而，對於許多應用程式來說，控制生成語言的屬性（例如情緒或毒性）是必要的，理想情況下應針對每個特定用例和目標受眾進行調整。對於自迴歸語言模型，現有的引導方法容易出現解碼錯誤，這些錯誤會在生成過程中級聯並降低效能。相比之下，文字擴散模型可以很容易地被引導，例如，使用一個簡單的線性情緒分類器，但它們的困惑度顯著高於自迴歸替代方案。在本文中，我們使用引導擴散模型來產生一個潛在提案，引導自迴歸語言模型生成具有所需屬性的文字。我們的模型繼承了自迴歸方法無與倫比的流暢性以及擴散的即插即用靈活性。我們表明，它在廣泛的基準資料集上優於先前的即插即用引導方法。此外，在我們的框架中控制一個新的屬性被簡化為訓練一個單一的邏輯迴歸分類器。</paragraph>

##### **Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs**
2408.04217v1 by Masashi Oshika, Makoto Morishita, Tsutomu Hirao, Ryohei Sasano, Koichi Takeda

In recent years, neural machine translation (NMT) has been widely used in
everyday life. However, the current NMT lacks a mechanism to adjust the
difficulty level of translations to match the user's language level.
Additionally, due to the bias in the training data for NMT, translations of
simple source sentences are often produced with complex words. In particular,
this could pose a problem for children, who may not be able to understand the
meaning of the translations correctly. In this study, we propose a method that
replaces words with high Age of Acquisitions (AoA) in translations with simpler
words to match the translations to the user's level. We achieve this by using
large language models (LLMs), providing a triple of a source sentence, a
translation, and a target word to be replaced. We create a benchmark dataset
using back-translation on Simple English Wikipedia. The experimental results
obtained from the dataset show that our method effectively replaces high-AoA
words with lower-AoA words and, moreover, can iteratively replace most of the
high-AoA words while still maintaining high BLEU and COMET scores.

摘要：近年來，神經機器翻譯（NMT）已廣泛應用於日常生活。然而，現有 NMT 缺乏調整翻譯難度以符合使用者語言程度的機制。此外，由於 NMT 訓練資料的偏差，簡單的原始句有時會翻譯成使用複雜詞彙的句子。特別是，這可能會對兒童造成問題，因為他們可能無法正確理解翻譯的含義。在本研究中，我們提出了一種方法，將翻譯中高習得年齡 (AoA) 的字詞替換為較簡單的字詞，以符合使用者的程度。我們透過使用大型語言模型 (LLM) 來達成此目的，提供原始句子、翻譯和要替換的目標字詞的三元組。我們使用簡單英語維基百科上的反向翻譯建立基准資料集。從資料集中獲得的實驗結果顯示，我們的模型有效地將高 AoA 字詞替換為低 AoA 字詞，而且還能反覆替換大多數高 AoA 字詞，同時仍維持高 BLEU 和 COMET 分數。

##### **Attention Mechanism and Context Modeling System for Text Mining Machine Translation**
2408.04216v1 by Shi Bo, Yuwei Zhang, Junming Huang, Sitong Liu, Zexi Chen, Zizheng Li

This paper advances a novel architectural schema anchored upon the
Transformer paradigm and innovatively amalgamates the K-means categorization
algorithm to augment the contextual apprehension capabilities of the schema.
The transformer model performs well in machine translation tasks due to its
parallel computing power and multi-head attention mechanism. However, it may
encounter contextual ambiguity or ignore local features when dealing with
highly complex language structures. To circumvent this constraint, this
exposition incorporates the K-Means algorithm, which is used to stratify the
lexis and idioms of the input textual matter, thereby facilitating superior
identification and preservation of the local structure and contextual
intelligence of the language. The advantage of this combination is that K-Means
can automatically discover the topic or concept regions in the text, which may
be directly related to translation quality. Consequently, the schema contrived
herein enlists K-Means as a preparatory phase antecedent to the Transformer and
recalibrates the multi-head attention weights to assist in the discrimination
of lexis and idioms bearing analogous semantics or functionalities. This
ensures the schema accords heightened regard to the contextual intelligence
embodied by these clusters during the training phase, rather than merely
focusing on locational intelligence.

摘要：這篇論文提出了一個新穎的架構模式，以 Transformer 典範為基礎，並創新地融合了 K-means 分類演算法，以增強模式的語境理解能力。Transformer 模型在機器翻譯任務中表現良好，這要歸功於其並行運算能力和多頭注意力機制。然而，在處理高度複雜的語言結構時，它可能會遇到語境歧義或忽略局部特徵。為了規避這個限制，本論文結合了 K-Means 演算法，用於對輸入文本資料的詞彙和慣用語進行分層，從而促進對語言的局部結構和語境智慧的優越識別和保留。這種組合的優點在於 K-Means 可以自動發現文本中的主題或概念區域，這可能與翻譯品質直接相關。因此，本文設計的模式將 K-Means 作為 Transformer 之前的準備階段，並重新校準多頭注意力權重，以協助區分具有類似語義或功能的詞彙和慣用語。這確保了模式在訓練階段高度重視這些群集所體現的語境智慧，而不仅仅關注位置智慧。

##### **MMREC: LLM Based Multi-Modal Recommender System**
2408.04211v1 by Jiahao Tian, Jinman Zhao, Zhenkai Wang, Zhicheng Ding

The importance of recommender systems is growing rapidly due to the
exponential increase in the volume of content generated daily. This surge in
content presents unique challenges for designing effective recommender systems.
Key among these challenges is the need to effectively leverage the vast amounts
of natural language data and images that represent user preferences. This paper
presents a novel approach to enhancing recommender systems by leveraging Large
Language Models (LLMs) and deep learning techniques. The proposed framework
aims to improve the accuracy and relevance of recommendations by incorporating
multi-modal information processing and by the use of unified latent space
representation. The study explores the potential of LLMs to better understand
and utilize natural language data in recommendation contexts, addressing the
limitations of previous methods. The framework efficiently extracts and
integrates text and image information through LLMs, unifying diverse modalities
in a latent space to simplify the learning process for the ranking model.
Experimental results demonstrate the enhanced discriminative power of the model
when utilizing multi-modal information. This research contributes to the
evolving field of recommender systems by showcasing the potential of LLMs and
multi-modal data integration to create more personalized and contextually
relevant recommendations.

摘要：推薦系統的重要性正快速提升，原因在於每天產生的內容量呈指數級增長。這種內容激增對設計有效的推薦系統提出了獨特的挑戰。這些挑戰中的關鍵在於需要有效利用大量的自然語言資料和代表使用者偏好的圖片。本文提出了一種新方法，透過利用大型語言模型 (LLM) 和深度學習技術來增強推薦系統。所提出的架構旨在透過整合多模態資訊處理和使用統一的潛在空間表示來改善推薦的準確性和相關性。本研究探討了大型語言模型在推薦情境中更了解和利用自然語言資料的潛力，並解決了先前方法的限制。該架構透過大型語言模型有效地萃取和整合文字和圖片資訊，在潛在空間中統一不同的模態，以簡化排名模型的學習歷程。實驗結果證明了該模型在使用多模態資訊時增強的判別能力。這項研究透過展示大型語言模型和多模態資料整合在建立更個人化和與情境相關的推薦方面的潛力，為推薦系統的演進領域做出貢獻。

##### **MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents**
2408.04203v1 by Yanqi Dai, Huanran Hu, Lei Wang, Shengjie Jin, Xu Chen, Zhiwu Lu

Recently, Role-Playing Agents (RPAs) have garnered increasing attention for
their potential to deliver emotional value and facilitate sociological
research. However, existing studies are primarily confined to the textual
modality, unable to simulate humans' multimodal perceptual capabilities. To
bridge this gap, we introduce the concept of Multimodal Role-Playing Agents
(MRPAs), and propose a comprehensive framework, MMRole, for their development
and evaluation, which comprises a personalized multimodal dataset and a robust
evaluation method. Specifically, we construct a large-scale, high-quality
dataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single
or multi-turn dialogues. Additionally, we present a robust evaluation method,
MMRole-Eval, encompassing eight metrics across three dimensions, where a reward
model is trained to score MRPAs with the constructed ground-truth data for
comparison. Moreover, we develop the first specialized MRPA, MMRole-Agent.
Extensive evaluation results demonstrate the improved performance of
MMRole-Agent and highlight the primary challenges in developing MRPAs,
emphasizing the need for enhanced multimodal understanding and role-playing
consistency. The data, code, and models will be available at
https://github.com/YanqiDai/MMRole.

摘要：<paragraph>最近，角色扮演代理（RPA）因其提供情感价值和促进社会学研究的潜力而备受关注。然而，现有研究主要局限于文本模式，无法模拟人类的多模态感知能力。为了弥合理论差距，我们引入了多模态角色扮演代理（MRPA）的概念，并提出了一个用于开发和评估的综合框架 MMRole，其中包括个性化多模态数据集和健壮的评估方法。具体来说，我们构建了一个大规模、高质量的数据集 MMRole-Data，其中包括 85 个角色、11K 张图像和 14K 个单轮或多轮对话。此外，我们提出了一个健壮的评估方法 MMRole-Eval，它包含三个维度上的八个指标，其中训练了一个奖励模型，使用构建好的基本事实数据对 MRPA 进行评分以进行比较。此外，我们开发了第一个专门的 MRPA，即 MMRole-Agent。广泛的评估结果证明了 MMRole-Agent 的性能得到改善，并突出了开发 MRPA 的主要挑战，强调了对增强的多模态理解和角色扮演一致性的需求。数据、代码和模型将在 https://github.com/YanqiDai/MMRole 上提供。</paragraph>

##### **Pairwise Judgment Formulation for Semantic Embedding Model in Web Search**
2408.04197v1 by Mengze Hong, Chen Jason Zhang

Semantic Embedding Model (SEM), a neural network-based Siamese architecture,
is gaining momentum in information retrieval and natural language processing.
In order to train SEM in a supervised fashion for Web search, the search engine
query log is typically utilized to automatically formulate pairwise judgments
as training data. Despite the growing application of semantic embeddings in the
search engine industry, little work has been done on formulating effective
pairwise judgments for training SEM. In this paper, we make the first in-depth
investigation of a wide range of strategies for generating pairwise judgments
for SEM. An interesting (perhaps surprising) discovery reveals that the
conventional pairwise judgment formulation strategy wildly used in the field of
pairwise Learning-to-Rank (LTR) is not necessarily effective for training SEM.
Through a large-scale empirical study based on query logs and click-through
activities from a major commercial search engine, we demonstrate the effective
strategies for SEM and highlight the advantages of a hybrid heuristic (i.e.,
Clicked > Non-Clicked) in comparison to the atomic heuristics (e.g., Clicked >
Skipped) in LTR. We conclude with best practices for training SEM and offer
promising insights for future research.

摘要：語意嵌入模型 (SEM)，一種基於神經網路的連體架構，在資訊檢索和自然語言處理中正獲得廣泛的應用。為了以監督式的方式訓練網路搜尋的 SEM，搜尋引擎查詢記錄通常用於自動建立成對的判斷，作為訓練資料。儘管語意嵌入在搜尋引擎產業的應用日益廣泛，但對於建立有效的成對判斷以訓練 SEM，卻鮮少有研究。在本文中，我們首次深入探討了廣泛的策略，以產生 SEM 的成對判斷。一個有趣的（也許令人驚訝的）發現表明，成對學習排名 (LTR) 領域中廣泛使用的傳統成對判斷制定策略，對於訓練 SEM 並非一定有效。透過大型的實證研究，根據主要商業搜尋引擎的查詢記錄和點擊活動，我們展示了 SEM 的有效策略，並強調了混合啟發式方法（即，已點擊 > 未點擊）與 LTR 中的原子啟發式方法（例如，已點擊 > 已略過）相比的優點。我們總結了訓練 SEM 的最佳實務，並為未來的研究提供了有前景的見解。

##### **Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks**
2408.04193v1 by Zepu Wang, Xiaobo Ma, Huajie Yang, Weimin Lvu, Peng Sun, Sharath Chandra Guntuku

Crime forecasting is a critical component of urban analysis and essential for
stabilizing society today. Unlike other time series forecasting problems, crime
incidents are sparse, particularly in small regions and within specific time
periods. Traditional spatial-temporal deep learning models often struggle with
this sparsity, as they typically cannot effectively handle the non-Gaussian
nature of crime data, which is characterized by numerous zeros and
over-dispersed patterns. To address these challenges, we introduce a novel
approach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial
Graph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and
convolution networks to analyze spatial, temporal, and multivariate
correlations, enabling the parameterization of probabilistic distributions of
crime incidents. By incorporating a Zero-Inflated Negative Binomial model,
STMGNN-ZINB effectively manages the sparse nature of crime data, enhancing
prediction accuracy and the precision of confidence intervals. Our evaluation
on real-world datasets confirms that STMGNN-ZINB outperforms existing models,
providing a more reliable tool for predicting and understanding crime dynamics.

摘要：犯罪預測是都市分析中的關鍵組成，也是當今社會穩定的必要條件。與其他時間序列預測問題不同，犯罪事件是稀疏的，特別是在小區域和特定時間段內。傳統的時空深度學習模型通常難以處理這種稀疏性，因為它們通常無法有效處理犯罪數據的非高斯性質，而犯罪數據的特徵是零值多且過度分散的模式。為了應對這些挑戰，我們引入了一種新方法，稱為時空多元零膨脹負二項圖神經網路 (STMGNN-ZINB)。此架構利用擴散和卷積網路來分析時空和多元相關性，從而能夠對犯罪事件的機率分佈進行參數化。透過納入零膨脹負二項模型，STMGNN-ZINB 有效地管理犯罪數據的稀疏性質，提升預測準確度和信賴區間的精確度。我們對真實世界資料集的評估確認，STMGNN-ZINB 優於現有模型，提供了一個更可靠的工具來預測和理解犯罪動態。

##### **Listwise Reward Estimation for Offline Preference-based Reinforcement Learning**
2408.04190v1 by Heewoong Choi, Sangwon Jung, Hongjoon Ahn, Taesup Moon

In Reinforcement Learning (RL), designing precise reward functions remains to
be a challenge, particularly when aligning with human intent. Preference-based
RL (PbRL) was introduced to address this problem by learning reward models from
human feedback. However, existing PbRL methods have limitations as they often
overlook the second-order preference that indicates the relative strength of
preference. In this paper, we propose Listwise Reward Estimation (LiRE), a
novel approach for offline PbRL that leverages second-order preference
information by constructing a Ranked List of Trajectories (RLT), which can be
efficiently built by using the same ternary feedback type as traditional
methods. To validate the effectiveness of LiRE, we propose a new offline PbRL
dataset that objectively reflects the effect of the estimated rewards. Our
extensive experiments on the dataset demonstrate the superiority of LiRE, i.e.,
outperforming state-of-the-art baselines even with modest feedback budgets and
enjoying robustness with respect to the number of feedbacks and feedback noise.
Our code is available at https://github.com/chwoong/LiRE

摘要：在強化學習 (RL) 中，設計精確的獎勵函數仍然是一個挑戰，特別是在與人類意圖保持一致時。基於偏好的 RL (PbRL) 被引入來解決這個問題，方法是從人類回饋中學習獎勵模型。然而，現有的 PbRL 方法有其局限性，因為它們常常忽略指示偏好相對強度的二階偏好。在本文中，我們提出了名單獎勵估計 (LiRE)，這是一種離線 PbRL 的新方法，它通過構建軌道排名清單 (RLT) 來利用二階偏好資訊，而 RLT 可以透過使用與傳統方法相同的三人回饋類型來有效建構。為了驗證 LiRE 的有效性，我們提出了新的離線 PbRL 資料集，該資料集客觀地反映了估計獎勵的效果。我們在資料集上進行的廣泛實驗證明了 LiRE 的優越性，即即使在適度的回饋預算下，也能優於最先進的基線，並且在回饋數量和回饋雜訊方面表現出穩健性。我們的程式碼可在 https://github.com/chwoong/LiRE 取得

##### **wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**
2408.04174v1 by Khai Le-Duc, Quy-Anh Dang, Tan-Hanh Pham, Truong-Son Hy

Knowledge graphs (KGs) enhance the performance of large language models
(LLMs) and search engines by providing structured, interconnected data that
improves reasoning and context-awareness. However, KGs only focus on text data,
thereby neglecting other modalities such as speech. In this work, we introduce
wav2graph, the first framework for supervised learning knowledge graph from
speech data. Our pipeline are straightforward: (1) constructing a KG based on
transcribed spoken utterances and a named entity database, (2) converting KG
into embedding vectors, and (3) training graph neural networks (GNNs) for node
classification and link prediction tasks. Through extensive experiments
conducted in inductive and transductive learning contexts using
state-of-the-art GNN models, we provide baseline results and error analysis for
node classification and link prediction tasks on human transcripts and
automatic speech recognition (ASR) transcripts, including evaluations using
both encoder-based and decoder-based node embeddings, as well as monolingual
and multilingual acoustic pre-trained models. All related code, data, and
models are published online.

摘要：知識圖譜 (KG) 透過提供結構化、相互連結的資料，進而改善大型語言模型 (LLM) 和搜尋引擎的效能，提升推理和脈絡感知。然而，KG 只關注文字資料，因此忽略了其他形式，例如語音。在這項工作中，我們介紹 wav2graph，這是第一個從語音資料中監督學習知識圖譜的架構。我們的流程很直接：(1) 根據轉錄的口語表達和命名實體資料庫建構 KG，(2) 將 KG 轉換為嵌入向量，以及 (3) 訓練圖形神經網路 (GNN) 以進行節點分類和連結預測任務。透過使用最先進的 GNN 模型在歸納和轉導學習的環境中進行廣泛的實驗，我們提供節點分類和連結預測任務的基準結果和錯誤分析，其中包括使用編碼器為基礎和解碼器為基礎的節點嵌入，以及單語和多語音學預訓練模型的評估。所有相關程式碼、資料和模型皆已在線上發布。

##### **Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**
2408.04168v1 by Qingbin Zeng, Qinglong Yang, Shunan Dong, Heming Du, Liang Zheng, Fengli Xu, Yong Li

This paper considers a scenario in city navigation: an AI agent is provided
with language descriptions of the goal location with respect to some well-known
landmarks; By only observing the scene around, including recognizing landmarks
and road network connections, the agent has to make decisions to navigate to
the goal location without instructions. This problem is very challenging,
because it requires agent to establish self-position and acquire spatial
representation of complex urban environment, where landmarks are often
invisible. In the absence of navigation instructions, such abilities are vital
for the agent to make high-quality decisions in long-range city navigation.
With the emergent reasoning ability of large language models (LLMs), a tempting
baseline is to prompt LLMs to "react" on each observation and make decisions
accordingly. However, this baseline has very poor performance that the agent
often repeatedly visits same locations and make short-sighted, inconsistent
decisions. To address these issues, this paper introduces a novel agentic
workflow featured by its abilities to perceive, reflect and plan. Specifically,
we find LLaVA-7B can be fine-tuned to perceive the direction and distance of
landmarks with sufficient accuracy for city navigation. Moreover, reflection is
achieved through a memory mechanism, where past experiences are stored and can
be retrieved with current perception for effective decision argumentation.
Planning uses reflection results to produce long-term plans, which can avoid
short-sighted decisions in long-range navigation. We show the designed workflow
significantly improves navigation ability of the LLM agent compared with the
state-of-the-art baselines.

摘要：<paragraph>本文探討城市導航中的場景：提供給 AI 代理關於目標位置的語言描述，相對於一些著名的地標；僅透過觀察周圍場景，包括辨識地標和道路網路連接，代理必須做出決定，在沒有指示的情況下導航到目標位置。這個問題非常具有挑戰性，因為它要求代理建立自我定位並取得複雜城市環境的空間表徵，其中地標通常是不可見的。在沒有導航指示的情況下，這些能力對於代理在長距離城市導航中做出高品質的決策至關重要。隨著大型語言模型 (LLM) 的推理能力出現，一個誘人的基準是提示 LLM 對每個觀察「做出反應」並據此做出決策。然而，這個基準的效能很差，代理經常重複造訪相同地點，並做出短視且不一致的決策。為了解決這些問題，本文介紹了一種新穎的代理工作流程，其特點是具有感知、反省和規劃的能力。具體來說，我們發現 LLaVA-7B 可以微調以感知地標的方向和距離，並具有足夠的準確度進行城市導航。此外，反省是透過記憶機制實現的，其中過去的經驗被儲存，並可與當前的感知一起檢索，以進行有效的決策論證。規劃使用反省結果產生長期計畫，這可以避免在長距離導航中做出短視的決策。我們展示設計的工作流程顯著提升了 LLM 代理的導航能力，優於最先進的基準。</paragraph>

##### **Semantics or spelling? Probing contextual word embeddings with orthographic noise**
2408.04162v1 by Jacob A. Matthews, John R. Starr, Marten van Schijndel

Pretrained language model (PLM) hidden states are frequently employed as
contextual word embeddings (CWE): high-dimensional representations that encode
semantic information given linguistic context. Across many areas of
computational linguistics research, similarity between CWEs is interpreted as
semantic similarity. However, it remains unclear exactly what information is
encoded in PLM hidden states. We investigate this practice by probing PLM
representations using minimal orthographic noise. We expect that if CWEs
primarily encode semantic information, a single character swap in the input
word will not drastically affect the resulting representation,given sufficient
linguistic context. Surprisingly, we find that CWEs generated by popular PLMs
are highly sensitive to noise in input data, and that this sensitivity is
related to subword tokenization: the fewer tokens used to represent a word at
input, the more sensitive its corresponding CWE. This suggests that CWEs
capture information unrelated to word-level meaning and can be manipulated
through trivial modifications of input data. We conclude that these PLM-derived
CWEs may not be reliable semantic proxies, and that caution is warranted when
interpreting representational similarity

摘要：預訓練語言模型 (PLM) 的隱藏狀態經常被用作
語境化字詞嵌入 (CWE)：編碼
給定語言語境的語義訊息的高維表示。在
計算語言學研究的許多領域中，CWE 之間的相似性被解釋為
語義相似性。然而，仍不清楚 PLM 隱藏狀態中編碼了哪些訊息。我們使用最小的正字法雜訊探測 PLM
表示來調查此做法。我們預期，如果 CWE 主要編碼語義訊息，輸入
字詞中的單一字元交換將不會大幅影響產生的表示，只要有足夠的
語言語境。令人驚訝的是，我們發現由熱門 PLM 產生的 CWE 對輸入資料中的雜訊高度敏感，而且這種敏感性與子字詞標記化有關：用於表示輸入中字詞的標記越少，其對應的 CWE 就越敏感。這表明 CWE 擷取與字詞層級意義無關的訊息，並且可以透過輸入資料的微小修改來操縱。我們得出結論，這些 PLM 衍生的 CWE 可能不是可靠的語義代理，並且在
解釋表示相似性時應謹慎

##### **The Data Addition Dilemma**
2408.04154v1 by Judy Hanwen Shen, Inioluwa Deborah Raji, Irene Y. Chen

In many machine learning for healthcare tasks, standard datasets are
constructed by amassing data across many, often fundamentally dissimilar,
sources. But when does adding more data help, and when does it hinder progress
on desired model outcomes in real-world settings? We identify this situation as
the \textit{Data Addition Dilemma}, demonstrating that adding training data in
this multi-source scaling context can at times result in reduced overall
accuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.
We find that this possibly arises from an empirically observed trade-off
between model performance improvements due to data scaling and model
deterioration from distribution shift. We thus establish baseline strategies
for navigating this dilemma, introducing distribution shift heuristics to guide
decision-making on which data sources to add in data scaling, in order to yield
the expected model performance improvements. We conclude with a discussion of
the required considerations for data collection and suggestions for studying
data composition and scale in the age of increasingly larger models.

摘要：在許多醫療保健任務的機器學習中，標準資料集是透過收集來自許多通常根本不同的來源的資料而建構的。但是，何時新增更多資料有幫助，而何時會阻礙在現實世界設定中達成預期的模型成果？我們將此情況認定為「資料新增困境」，證明在此多來源擴充的背景下新增訓練資料，有時可能會導致整體準確度降低、不確定的公平性結果，以及最差子群體效能降低。我們發現這可能是由於資料擴充導致的模型效能提升與分配轉移導致的模型劣化之間的經驗性權衡所致。因此，我們建立了應對此困境的基本策略，引入了分配轉移啟發法，以指導有關在資料擴充中新增哪些資料來源的決策制定，以產生預期的模型效能提升。我們最後討論了資料收集所需的考量因素，並建議研究資料組成和規模在模型規模日益擴大的時代。

##### **UNLEARN Efficient Removal of Knowledge in Large Language Models**
2408.04140v1 by Tyler Lizzo, Larry Heck

Given the prevalence of large language models (LLMs) and the prohibitive cost
of training these models from scratch, dynamically forgetting specific
knowledge e.g., private or proprietary, without retraining the model has become
an important capability. This paper proposes a novel method to achieve this
objective called UNLEARN. The approach builds upon subspace methods to identify
and specifically target the removal of knowledge without adversely affecting
other knowledge in the LLM. Results demonstrate 96% of targeted knowledge can
be forgotten while maintaining performance on other knowledge within 2.5% of
the original model, significantly outperforming the discriminatory abilities of
the previous state-of-the-art. A dual method called LEARN is also proposed for
targeted knowledge addition. Results show LEARN can match the fine-tuning
accuracy of Low-Rank Adaptation (LoRA) without adversely affecting similar
tasks.

摘要：鑑於大型語言模型 (LLM) 的盛行，以及從頭訓練這些模型的高昂成本，動態遺忘特定知識（例如私人或專有知識），而無需重新訓練模型，已成為一項重要的功能。本文提出了一種新的方法來實現這個目標，稱為 UNLEARN。此方法建立在子空間方法之上，用於識別並特別針對知識移除，而不會對 LLM 中的其他知識造成不利影響。結果表明，96% 的目標知識可以被遺忘，同時在其他知識上的效能維持在原始模型的 2.5% 以內，顯著優於先前最先進技術的識別能力。還提出了一種稱為 LEARN 的雙重方法，用於目標知識新增。結果顯示，LEARN 可以匹配低秩適應 (LoRA) 的微調準確度，而不會對類似任務造成不利影響。

##### **Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**
2408.04138v1 by Haoran Yu, Chang Yu, Zihan Wang, Dongxian Zou, Hao Qin

In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.

摘要：近年來，大型語言模型 (LLM) 在醫療保健中的應用已展現出顯著的希望，可改善醫療知識的可及性和傳播。本文針對在 MedQuAD 醫療問答資料集上訓練的各種 LLM 進行詳細研究，重點在於找出提供準確醫療資訊最有效的模型。在測試的模型中，Sentence-t5 結合 Mistral 7B 表現優異，達到 0.762 的精準度分數。此模型的增強功能歸功於其先進的預訓練技術、強大的架構和有效的提示建構方法。Sentence-t5 + Mistral 7B 模型藉由運用這些優勢，在理解和產生精確的醫療答案方面表現出色。我們的研究結果突顯了將複雜的 LLM 整合到醫療背景中的潛力，以促進有效率且準確的醫療知識擷取，進而顯著提升病患教育和支持。

##### **Incorporating Spatial Awareness in Data-Driven Gesture Generation for Virtual Agents**
2408.04127v1 by Anna Deichler, Simon Alexanderson, Jonas Beskow

This paper focuses on enhancing human-agent communication by integrating
spatial context into virtual agents' non-verbal behaviors, specifically
gestures. Recent advances in co-speech gesture generation have primarily
utilized data-driven methods, which create natural motion but limit the scope
of gestures to those performed in a void. Our work aims to extend these methods
by enabling generative models to incorporate scene information into
speech-driven gesture synthesis. We introduce a novel synthetic gesture dataset
tailored for this purpose. This development represents a critical step toward
creating embodied conversational agents that interact more naturally with their
environment and users.

摘要：本文重點在於透過將空間脈絡整合至虛擬代理人的非語言行為，特別是手勢，來增進人機溝通。近期在共語手勢生成方面的進展主要使用資料驅動方法，這種方法會產生自然動作，但會將手勢範圍限制為在真空中執行的動作。我們的研究旨在透過讓生成模型將場景資訊納入語音驅動手勢合成中，來延伸這些方法。我們引入一個新的合成手勢資料集，專門用於此目的。此發展代表了在創造與環境和使用者互動更自然的身體化對話代理人方面邁出的關鍵一步。

##### **Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**
2408.04121v1 by Panagiotis Fytas, Anna Breger, Ian Selby, Simon Baker, Shahab Shahipasand, Anna Korhonen

Developing imaging models capable of detecting pathologies from chest X-rays
can be cost and time-prohibitive for large datasets as it requires supervision
to attain state-of-the-art performance. Instead, labels extracted from
radiology reports may serve as distant supervision since these are routinely
generated as part of clinical practice. Despite their widespread use, current
rule-based methods for label extraction rely on extensive rule sets that are
limited in their robustness to syntactic variability. To alleviate these
limitations, we introduce RadPert, a rule-based system that integrates an
uncertainty-aware information schema with a streamlined set of rules, enhancing
performance. Additionally, we have developed RadPrompt, a multi-turn prompting
strategy that leverages RadPert to bolster the zero-shot predictive
capabilities of large language models, achieving a statistically significant
improvement in weighted average F1 score over GPT-4 Turbo. Most notably,
RadPrompt surpasses both its underlying models, showcasing the synergistic
potential of LLMs with rule-based models. We have evaluated our methods on two
English Corpora: the MIMIC-CXR gold-standard test set and a gold-standard
dataset collected from the Cambridge University Hospitals.

摘要：開發出能夠從胸部 X 光檢測病理的影像模型，對於大型資料集來說，在成本和時間上都可能是禁止的，因為它需要監督才能達到最先進的效能。相反地，從放射科報告中提取的標籤可以用作遠端監督，因為這些標籤通常作為臨床實務的一部分而產生。儘管廣泛使用，但目前用於標籤提取的基於規則的方法依賴於廣泛的規則集，其對語法變異的健壯性有限。為了減輕這些限制，我們引入了 RadPert，這是一個基於規則的系統，它將一個不確定性感知資訊架構與一組簡化的規則整合在一起，從而增強了效能。此外，我們還開發了 RadPrompt，這是一個多輪提示策略，它利用 RadPert 來加強大型語言模型的零次學習預測能力，在加權平均 F1 分數上實現了相對於 GPT-4 Turbo 的統計顯著改進。最值得注意的是，RadPrompt 超越了其基礎模型，展示了基於規則的模型與 LLM 的協同潛力。我們已在兩個英文語料庫上評估了我們的方法：MIMIC-CXR 黃金標準測試集和從劍橋大學醫院收集的黃金標準資料集。

##### **Zero-shot Factual Consistency Evaluation Across Domains**
2408.04114v1 by Raunak Agarwal

This work addresses the challenge of factual consistency in text generation
systems. We unify the tasks of Natural Language Inference, Summarization
Evaluation, Factuality Verification and Factual Consistency Evaluation to train
models capable of evaluating the factual consistency of source-target pairs
across diverse domains. We rigorously evaluate these against eight baselines on
a comprehensive benchmark suite comprising 22 datasets that span various tasks,
domains, and document lengths. Results demonstrate that our method achieves
state-of-the-art performance on this heterogeneous benchmark while addressing
efficiency concerns and attaining cross-domain generalization.

摘要：這項工作探討了文本生成系統中事實一致性的挑戰。我們統一自然語言推論、摘要評估、事實驗證和事實一致性評估的任務，以訓練出能夠評估跨不同領域的來源目標對的事實一致性的模型。我們使用包含 22 個資料集的綜合基準套件，嚴格評估這些模型，這些資料集涵蓋各種任務、領域和文件長度。結果表明，我們的模型在此異質基準上取得了最先進的效能，同時解決了效率問題並實現了跨領域概化。

##### **Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization**
2408.04112v1 by John Joon Young Chung, Max Kreminski

Large language models (LLMs) can help writers build story worlds by
generating world elements, such as factions, characters, and locations.
However, making sense of many generated elements can be overwhelming. Moreover,
if the user wants to precisely control aspects of generated elements that are
difficult to specify verbally, prompting alone may be insufficient. We
introduce Patchview, a customizable LLM-powered system that visually aids
worldbuilding by allowing users to interact with story concepts and elements
through the physical metaphor of magnets and dust. Elements in Patchview are
visually dragged closer to concepts with high relevance, facilitating
sensemaking. The user can also steer the generation with verbally elusive
concepts by indicating the desired position of the element between concepts.
When the user disagrees with the LLM's visualization and generation, they can
correct those by repositioning the element. These corrections can be used to
align the LLM's future behaviors to the user's perception. With a user study,
we show that Patchview supports the sensemaking of world elements and steering
of element generation, facilitating exploration during the worldbuilding
process. Patchview provides insights on how customizable visual representation
can help sensemake, steer, and align generative AI model behaviors with the
user's intentions.

摘要：大型語言模型 (LLM) 可以透過產生世界元素（例如派系、角色和地點）來協助作家建構故事世界。不過，要理解許多產生的元素可能會讓人不知所措。此外，如果使用者想要精確控制難以用言語說明的產生元素面向，那麼單純的提示可能不足夠。我們介紹 Patchview，這是一個可自訂的 LLM 驅動系統，透過磁鐵和灰塵的實體隱喻，讓使用者能與故事概念和元素進行互動，進而視覺化協助建構世界。Patchview 中的元素會被視覺化地拖曳到高度相關的概念附近，促進理解。使用者也可以透過指出元素在概念之間的理想位置，來引導產生難以用言語表達的概念。當使用者不同意 LLM 的視覺化和產生時，他們可以透過重新定位元素來進行修正。這些修正可以調整 LLM 未來的行為，與使用者的認知保持一致。透過使用者研究，我們展示 Patchview 支援世界元素的理解和元素產生的引導，促進建構世界過程中的探索。Patchview 提供見解，說明可自訂的視覺化表示如何協助理解、引導和調整產生式 AI 模型的行為，以符合使用者的意圖。

##### **Hardware-Assisted Virtualization of Neural Processing Units for Cloud Platforms**
2408.04104v1 by Yuqi Xue, Yiqi Liu, Lifeng Nai, Jian Huang

Cloud platforms today have been deploying hardware accelerators like neural
processing units (NPUs) for powering machine learning (ML) inference services.
To maximize the resource utilization while ensuring reasonable quality of
service, a natural approach is to virtualize NPUs for efficient resource
sharing for multi-tenant ML services. However, virtualizing NPUs for modern
cloud platforms is not easy. This is not only due to the lack of system
abstraction support for NPU hardware, but also due to the lack of architectural
and ISA support for enabling fine-grained dynamic operator scheduling for
virtualized NPUs.
  We present TCloud, a holistic NPU virtualization framework. We investigate
virtualization techniques for NPUs across the entire software and hardware
stack. TCloud consists of (1) a flexible NPU abstraction called vNPU, which
enables fine-grained virtualization of the heterogeneous compute units in a
physical NPU (pNPU); (2) a vNPU resource allocator that enables pay-as-you-go
computing model and flexible vNPU-to-pNPU mappings for improved resource
utilization and cost-effectiveness; (3) an ISA extension of modern NPU
architecture for facilitating fine-grained tensor operator scheduling for
multiple vNPUs. We implement TCloud based on a production-level NPU simulator.
Our experiments show that TCloud improves the throughput of ML inference
services by up to 1.4$\times$ and reduces the tail latency by up to
4.6$\times$, while improving the NPU utilization by 1.2$\times$ on average,
compared to state-of-the-art NPU sharing approaches.

摘要：現今的雲端平台已部署神經處理單元 (NPU) 等硬體加速器，用於支援機器學習 (ML) 推論服務。為了在確保合理服務品質的同時最大化資源使用率，一種自然的方法是將 NPU 虛擬化，以有效率地為多租戶 ML 服務共享資源。然而，為現代雲端平台虛擬化 NPU 並不容易。這不僅是因為缺乏對 NPU 硬體的系統抽象支援，還因為缺乏架構和 ISA 支援，無法對虛擬化 NPU 進行細粒度的動態運算子排程。
我們提出 TCloud，一個整體的 NPU 虛擬化架構。我們研究了針對整個軟體和硬體堆疊的 NPU 虛擬化技術。TCloud 包含 (1) 一個稱為 vNPU 的彈性 NPU 抽象，它能對實體 NPU (pNPU) 中的異質運算單元進行細粒度的虛擬化；(2) 一個 vNPU 資源分配器，它能支援按需付費的運算模式和彈性的 vNPU 對應 pNPU 映射，以改善資源使用率和成本效益；(3) 現代 NPU 架構的 ISA 延伸，用於促進針對多個 vNPU 的細粒度張量運算子排程。我們根據生產級別的 NPU 模擬器實作 TCloud。我們的實驗顯示，與最先進的 NPU 共享方法相比，TCloud 將 ML 推論服務的吞吐量提升了 1.4 倍，將尾部延遲降低了 4.6 倍，同時將 NPU 使用率平均提升了 1.2 倍。

##### **ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**
2408.04102v1 by William Y. Zhu, Keren Ye, Junjie Ke, Jiahui Yu, Leonidas Guibas, Peyman Milanfar, Feng Yang

Recognizing and disentangling visual attributes from objects is a foundation
to many computer vision applications. While large vision language
representations like CLIP had largely resolved the task of zero-shot object
recognition, zero-shot visual attribute recognition remains a challenge because
CLIP's contrastively-learned vision-language representation cannot effectively
capture object-attribute dependencies. In this paper, we target this weakness
and propose a sentence generation-based retrieval formulation for attribute
recognition that is novel in 1) explicitly modeling a to-be-measured and
retrieved object-attribute relation as a conditional probability graph, which
converts the recognition problem into a dependency-sensitive language-modeling
problem, and 2) applying a large pretrained Vision-Language Model (VLM) on this
reformulation and naturally distilling its knowledge of image-object-attribute
relations to use towards attribute recognition. Specifically, for each
attribute to be recognized on an image, we measure the visual-conditioned
probability of generating a short sentence encoding the attribute's relation to
objects on the image. Unlike contrastive retrieval, which measures likelihood
by globally aligning elements of the sentence to the image, generative
retrieval is sensitive to the order and dependency of objects and attributes in
the sentence. We demonstrate through experiments that generative retrieval
consistently outperforms contrastive retrieval on two visual reasoning
datasets, Visual Attribute in the Wild (VAW), and our newly-proposed Visual
Genome Attribute Ranking (VGARank).

摘要：辨識和區分物件的視覺屬性，是許多電腦視覺應用程式的基礎。雖然像 CLIP 這樣的大型視覺語言表徵，已在很大程度上解決了零次學習物件辨識的任務，但零次學習視覺屬性辨識仍然是一個挑戰，因為 CLIP 對比學習的視覺語言表徵，無法有效擷取物件屬性依賴性。在本文中，我們針對此弱點，並提出一個基於句子生成的檢索公式，用於屬性辨識，其新穎之處在於：1) 明確地將待測量和檢索的物件屬性關係建模為條件機率圖，這將辨識問題轉換為依賴敏感的語言模型問題；2) 在此重新公式化上應用大型預訓練的視覺語言模型 (VLM)，並自然地萃取其對影像物件屬性關係的知識，用於屬性辨識。具體來說，對於要在影像上辨識的每個屬性，我們測量在影像上編碼屬性與物件關係的簡短句子的視覺條件機率。與對比檢索不同，對比檢索是透過將句子的元素整體比對到影像來測量可能性，生成檢索則對句子中物件和屬性的順序和依賴性很敏感。我們透過實驗證明，生成檢索在兩個視覺推理資料集，野外視覺屬性 (VAW) 和我們新提出的視覺基因組屬性排名 (VGARank) 上，始終優於對比檢索。

##### **Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters**
2408.04093v1 by Vasudev Shyam, Jonathan Pilault, Emily Shepperd, Quentin Anthony, Beren Millidge

Self-attention is the core mathematical operation of modern transformer
architectures and is also a significant computational bottleneck due to its
quadratic complexity in the sequence length. In this work, we derive the scalar
energy function whose gradient computes the self-attention block, thus
elucidating the theoretical underpinnings of self-attention, providing a
Bayesian interpretation of the operation and linking it closely with
energy-based models such as Hopfield Networks. Moreover, due to this
formulation, we discover that we can use efficient and optimized
automatic-differentiation techniques to derive a highly efficient Tree
Attention algorithm to compute the gradient of the energy and hence
self-attention. Our formulation reveals that the reduction across the sequence
axis can be efficiently computed in parallel through a tree reduction. Our
algorithm, for parallelizing attention computation across multiple GPUs,
enables cross-device decoding to be performed asymptotically faster (up to 8x
faster) than alternative approaches such as Ring Attention, while also
requiring significantly less communication volume and incurring 2x less peak
memory. Our code is publicly available here:
\url{https://github.com/Zyphra/tree_attention}

摘要：自我注意力是現代Transformer架構的核心數學運算，而且由於其在序列長度中的二次複雜性，它也是一個重要的計算瓶頸。在這項工作中，我們推導出標量能量函數，其梯度計算自我注意力區塊，從而闡明自我注意力的理論基礎，提供該運算的貝葉斯詮釋，並將其與基於能量的模型（例如霍普菲爾德網路）緊密連結。此外，由於這個公式，我們發現我們可以使用高效且最佳化的自動微分技術來推導一個高效的樹注意力演算法，以計算能量的梯度，從而自我注意。我們的公式揭示了序列軸上的約簡可以透過樹約簡有效地並行計算。我們的演算法，用於在多個 GPU 上並行化注意力計算，使跨裝置解碼能夠比替代方法（例如環形注意力）執行得更快（快 8 倍），同時也需要顯著減少通訊量，並減少 2 倍的峰值記憶體。我們的程式碼在此公開：
\url{https://github.com/Zyphra/tree_attention}

##### **AEye: A Visualization Tool for Image Datasets**
2408.04072v1 by Florian Grötschla, Luca A. Lanzendörfer, Marco Calzavara, Roger Wattenhofer

Image datasets serve as the foundation for machine learning models in
computer vision, significantly influencing model capabilities, performance, and
biases alongside architectural considerations. Therefore, understanding the
composition and distribution of these datasets has become increasingly crucial.
To address the need for intuitive exploration of these datasets, we propose
AEye, an extensible and scalable visualization tool tailored to image datasets.
AEye utilizes a contrastively trained model to embed images into semantically
meaningful high-dimensional representations, facilitating data clustering and
organization. To visualize the high-dimensional representations, we project
them onto a two-dimensional plane and arrange images in layers so users can
seamlessly navigate and explore them interactively. AEye facilitates semantic
search functionalities for both text and image queries, enabling users to
search for content. We open-source the codebase for AEye, and provide a simple
configuration to add datasets.

摘要：圖像資料集作為電腦視覺中機器學習模型的基礎，除了架構考量外，也顯著影響模型的能力、效能和偏差。因此，了解這些資料集的組成和分佈變得越來越重要。為了滿足直觀探索這些資料集的需求，我們提出 AEye，一種針對圖像資料集量身打造的可延伸和可擴充視覺化工具。AEye 利用對比訓練模型將圖像嵌入到具有語義意義的高維表示中，促進資料群集和組織。為了視覺化高維表示，我們將它們投影到一個二維平面，並將圖像分層排列，以便使用者可以無縫地瀏覽和互動探索它們。AEye 促進語義搜尋功能，適用於文字和圖像查詢，使用戶能夠搜尋內容。我們開放 AEye 的程式碼庫，並提供一個簡單的組態來新增資料集。

##### **Digital Avatars: Framework Development and Their Evaluation**
2408.04068v1 by Timothy Rupprecht, Sung-En Chang, Yushu Wu, Lei Lu, Enfu Nan, Chih-hsiang Li, Caiyue Lai, Zhimin Li, Zhijun Hu, Yumei He, David Kaeli, Yanzhi Wang

We present a novel prompting strategy for artificial intelligence driven
digital avatars. To better quantify how our prompting strategy affects
anthropomorphic features like humor, authenticity, and favorability we present
Crowd Vote - an adaptation of Crowd Score that allows for judges to elect a
large language model (LLM) candidate over competitors answering the same or
similar prompts. To visualize the responses of our LLM, and the effectiveness
of our prompting strategy we propose an end-to-end framework for creating
high-fidelity artificial intelligence (AI) driven digital avatars. This
pipeline effectively captures an individual's essence for interaction and our
streaming algorithm delivers a high-quality digital avatar with real-time
audio-video streaming from server to mobile device. Both our visualization
tool, and our Crowd Vote metrics demonstrate our AI driven digital avatars have
state-of-the-art humor, authenticity, and favorability outperforming all
competitors and baselines. In the case of our Donald Trump and Joe Biden
avatars, their authenticity and favorability are rated higher than even their
real-world equivalents.

摘要：我們提出了一種用於人工智能驅動數位替身的新提示策略。為了更好地量化我們的提示策略如何影響幽默、真實性和好感度等擬人化特徵，我們提出了群眾投票 - Crowd Score 的一種改編，它允許評審在回答相同或類似提示的競爭者中選出一位大型語言模型 (LLM) 候選人。為了視覺化我們的 LLM 的回應以及我們提示策略的有效性，我們提出了一個端到端的框架，用於創建高保真度的人工智能 (AI) 驅動的數位替身。此管線有效捕捉個人的互動本質，我們的串流演算法從伺服器到行動裝置提供高品質的數位替身，並進行即時音訊串流。我們的視覺化工具和群眾投票指標都證明了我們的人工智慧驅動的數位替身具備最先進的幽默感、真實性和好感度，優於所有競爭者和基準。就我們的唐納德·川普和喬·拜登替身而言，他們的真實性和好感度甚至高於他們在現實世界中的對應者。

##### **PowerPM: Foundation Model for Power Systems**
2408.04057v1 by Shihao Tu, Yupeng Zhang, Jing Zhang, Yang Yang

The emergence of abundant electricity time series (ETS) data provides ample
opportunities for various applications in the power systems, including
demand-side management, grid stability, and consumer behavior analysis. Deep
learning models have advanced ETS modeling by effectively capturing sequence
dependence. Nevertheless, learning a generic representation of ETS data for
various applications remains challenging due to the inherently complex
hierarchical structure of ETS data. Moreover, ETS data exhibits intricate
temporal dependencies and is suscepti ble to the influence of exogenous
variables. Furthermore, different instances exhibit diverse electricity
consumption behavior. In this paper, we propose a foundation model PowerPM to
model ETS data, providing a large-scale, off-the-shelf model for power systems.
PowerPM consists of a temporal encoder and a hierarchical encoder. The temporal
encoder captures both temporal dependencies in ETS data, considering exogenous
variables. The hierarchical encoder models the correlation between hierarchy.
Furthermore, PowerPM leverages a novel self-supervised pretraining framework
consisting of masked ETS modeling and dual-view contrastive learning, which
enable PowerPM to capture temporal dependency within ETS windows and aware the
discrepancy across ETS windows, providing two different perspectives to learn
generic representation. Our experiments involve five real world scenario
datasets, comprising private and public data. Through pre-training on massive
ETS data, PowerPM achieves SOTA performance on diverse downstream tasks within
the private dataset. Impressively, when transferred to the public datasets,
PowerPM maintains its superiority, showcasing its remarkable generalization
ability across various tasks and domains. Moreover, ablation studies, few-shot
experiments provide additional evidence of the effectiveness of our model.

摘要：豐富電力時間序列 (ETS) 資料的出現，為電力系統中的各種應用提供了充足的機會，包括需求側管理、電網穩定性和消費者行為分析。深度學習模型透過有效擷取序列依賴性，提升了 ETS 建模。儘管如此，由於 ETS 資料固有的複雜階層結構，學習通用 ETS 資料表示以供各種應用仍然具有挑戰性。此外，ETS 資料表現出複雜的時間依賴性，並且容易受到外生變數的影響。此外，不同的實例表現出不同的電力消耗行為。在本文中，我們提出了一個基礎模型 PowerPM 來建模 ETS 資料，為電力系統提供一個大規模的現成模型。PowerPM 包含一個時間編碼器和一個階層編碼器。時間編碼器擷取 ETS 資料中的時間依賴性，並考慮外生變數。階層編碼器對階層之間的相關性進行建模。此外，PowerPM 利用一個新穎的自監督預訓練架構，其中包含遮蔽 ETS 建模和雙視對比學習，這使 PowerPM 能夠擷取 ETS 視窗中的時間依賴性，並了解 ETS 視窗之間的差異，提供兩種不同的觀點來學習通用表示。我們的實驗涉及五個真實世界場景資料集，包含私人和公共資料。透過在大量 ETS 資料上進行預訓練，PowerPM 在私人資料集中實現了 SOTA 在各種下游任務上的效能。令人印象深刻的是，當轉移到公共資料集時，PowerPM 保持其優越性，展示其在各種任務和領域中的顯著泛化能力。此外，消融研究、小樣本實驗提供了我們模型有效性的額外證據。

##### **Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives**
2408.04046v1 by Aida Afshar, Aldo Pacchiano

The performance of reinforcement learning (RL) algorithms is sensitive to the
choice of hyperparameters, with the learning rate being particularly
influential. RL algorithms fail to reach convergence or demand an extensive
number of samples when the learning rate is not optimally set. In this work, we
show that model selection can help to improve the failure modes of RL that are
due to suboptimal choices of learning rate. We present a model selection
framework for Learning Rate-Free Reinforcement Learning that employs model
selection methods to select the optimal learning rate on the fly. This approach
of adaptive learning rate tuning neither depends on the underlying RL algorithm
nor the optimizer and solely uses the reward feedback to select the learning
rate; hence, the framework can input any RL algorithm and produce a learning
rate-free version of it. We conduct experiments for policy optimization methods
and evaluate various model selection strategies within our framework. Our
results indicate that data-driven model selection algorithms are better
alternatives to standard bandit algorithms when the optimal choice of
hyperparameter is time-dependent and non-stationary.

摘要：強化學習 (RL) 演算法的效能取決於超參數的選擇，其中學習率特別具有影響力。當學習率未最佳設定時，RL 演算法無法達到收斂或需要大量的樣本。在這項工作中，我們證明模型選擇有助於改善 RL 的失敗模式，這些失敗模式是由次佳學習率選擇造成的。我們提出一個學習率無關強化學習的模型選擇架構，採用模型選擇方法來動態選擇最佳學習率。這種自適應學習率調整方法既不依賴於基礎 RL 演算法，也不依賴於最佳化器，而且僅使用回饋獎勵來選擇學習率；因此，此架構可以輸入任何 RL 演算法並產生其學習率無關版本。我們針對策略最佳化方法進行實驗，並在我們的架構中評估各種模型選擇策略。我們的結果表明，當超參數的最佳選擇與時間相關且非平穩時，資料驅動的模型選擇演算法是標準多臂老虎機演算法的較佳替代方案。

##### **Human Speech Perception in Noise: Can Large Language Models Paraphrase to Improve It?**
2408.04029v1 by Anupama Chingacham, Miaoran Zhang, Vera Demberg, Dietrich Klakow

Large Language Models (LLMs) can generate text by transferring style
attributes like formality resulting in formal or informal text. However,
instructing LLMs to generate text that when spoken, is more intelligible in an
acoustically difficult environment, is an under-explored topic. We conduct the
first study to evaluate LLMs on a novel task of generating acoustically
intelligible paraphrases for better human speech perception in noise. Our
experiments in English demonstrated that with standard prompting, LLMs struggle
to control the non-textual attribute, i.e., acoustic intelligibility, while
efficiently capturing the desired textual attributes like semantic equivalence.
To remedy this issue, we propose a simple prompting approach,
prompt-and-select, which generates paraphrases by decoupling the desired
textual and non-textual attributes in the text generation pipeline. Our
approach resulted in a 40% relative improvement in human speech perception, by
paraphrasing utterances that are highly distorted in a listening condition with
babble noise at a signal-to-noise ratio (SNR) -5 dB. This study reveals the
limitation of LLMs in capturing non-textual attributes, and our proposed method
showcases the potential of using LLMs for better human speech perception in
noise.

摘要：大型語言模型（LLM）可以透過轉移形式屬性（例如正式性）來產生文字，產生正式或非正式的文字。然而，指示 LLM 產生在口說時在聲學困難的環境中更易懂的文字，是一個尚未充分探討的主題。我們進行了第一個研究，以評估 LLM 在一個新的任務上，即產生聲學上可理解的同義詞，以改善人類在噪音中的言語感知。我們的英語實驗證明，在標準提示下，LLM 難以控制非文字屬性，即聲學可理解性，同時有效地捕捉所需的文字屬性，例如語義等價性。為了解決這個問題，我們提出了一個簡單的提示方法，提示和選擇，它透過在文字產生管道中解耦所需的文字和非文字屬性來產生同義詞。我們的做法在人類言語感知方面產生了 40% 的相對改善，透過在信號雜訊比 (SNR) -5 dB 的喧鬧噪音中聽取條件下，對失真嚴重的語句進行同義詞替換。這項研究揭示了 LLM 在捕捉非文字屬性方面的限制，而我們提出的方法展示了使用 LLM 在噪音中改善人類言語感知的潛力。

##### **Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**
2408.04026v1 by Joseph Cameron, Jiaee Cheong, Micol Spitale, Hatice Gunes

Social agents and robots are increasingly being used in wellbeing settings.
However, a key challenge is that these agents and robots typically rely on
machine learning (ML) algorithms to detect and analyse an individual's mental
wellbeing. The problem of bias and fairness in ML algorithms is becoming an
increasingly greater source of concern. In concurrence, existing literature has
also indicated that mental health conditions can manifest differently across
genders and cultures. We hypothesise that the representation of features
(acoustic, textual, and visual) and their inter-modal relations would vary
among subjects from different cultures and genders, thus impacting the
performance and fairness of various ML models. We present the very first
evaluation of multimodal gender fairness in depression manifestation by
undertaking a study on two different datasets from the USA and China. We
undertake thorough statistical and ML experimentation and repeat the
experiments for several different algorithms to ensure that the results are not
algorithm-dependent. Our findings indicate that though there are differences
between both datasets, it is not conclusive whether this is due to the
difference in depression manifestation as hypothesised or other external
factors such as differences in data collection methodology. Our findings
further motivate a call for a more consistent and culturally aware data
collection process in order to address the problem of ML bias in depression
detection and to promote the development of fairer agents and robots for
wellbeing.

摘要：社群代理人和機器人在幸福感設定中正越來越廣泛地被使用。
然而，一個關鍵的挑戰是這些代理人和機器人通常依賴機器學習 (ML) 演算法來偵測和分析個人心理健康。ML 演算法中的偏差和公平性問題正成為越來越大的關注來源。同時，現有文獻也指出心理健康狀況會在不同性別和文化中以不同的方式顯現。我們假設特徵（聲音、文字和視覺）的呈現及其跨模態關係會因不同文化和性別的受試者而異，從而影響各種 ML 模型的效能和公平性。我們透過對來自美國和中國的兩個不同資料集進行研究，提出首次對憂鬱症表現的多模態性別公平性評估。我們進行徹底的統計和 ML 實驗，並針對多種不同的演算法重複實驗，以確保結果不依賴於演算法。我們的研究結果表明，儘管兩個資料集之間存在差異，但無法確定這是否是由於假設的憂鬱症表現差異或其他外部因素（例如資料收集方法的差異）所造成。我們的研究結果進一步呼籲採用更一致且具有文化意識的資料收集程序，以解決憂鬱症偵測中的 ML 偏差問題，並促進開發更公平的代理人和機器人，以提升幸福感。

##### **Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity**
2408.04023v1 by Wrick Talukdar, Anjanava Biswas

As Large Language Models (LLMs) become increasingly sophisticated and
ubiquitous in natural language processing (NLP) applications, ensuring their
robustness, trustworthiness, and alignment with human values has become a
critical challenge. This paper presents a novel framework for contextual
grounding in textual models, with a particular emphasis on the Context
Representation stage. Our approach aims to enhance the reliability and ethical
alignment of these models through a comprehensive, context-aware methodology.
By explicitly capturing and representing relevant situational, cultural, and
ethical contexts in a machine-readable format, we lay the foundation for
anchoring a model's behavior within these contexts. Our approach leverages
techniques from knowledge representation and reasoning, such as ontologies,
semantic web technologies, and logic-based formalisms. We evaluate our
framework on real-world textual datasets, demonstrating its effectiveness in
improving model performance, fairness, and alignment with human expectations,
while maintaining high accuracy. Furthermore, we discuss the other key
components of the framework, including context-aware encoding, context-aware
learning, interpretability and explainability, and continuous monitoring and
adaptation. This research contributes to the growing body of work on
responsible AI, offering a practical approach to developing more reliable,
trustworthy, and ethically-aligned language models. Our findings have
significant implications for the deployment of LLMs in sensitive domains such
as healthcare, legal systems, and social services, where contextual
understanding is paramount.

摘要：隨著大型語言模型 (LLM) 在自然語言處理 (NLP) 應用中變得越來越複雜且普遍，確保它們的穩健性、可信度和與人類價值觀的一致性已成為一項關鍵挑戰。本文提出了文本模型中情境基礎的新框架，特別強調情境表徵階段。我們的做法旨在通過全面且重視情境的的方法來增強這些模型的可靠性和倫理一致性。通過以機器可讀的格式明確擷取和表徵相關的情境、文化和倫理情境，我們為在這些情境中錨定模型的行為奠定了基礎。我們的做法利用了知識表徵和推理的技術，例如本体論、語義網技術和基於邏輯的形式化。我們在真實世界的文本資料集上評估我們的框架，證明其在改善模型效能、公平性和與人類預期的吻合度方面的有效性，同時保持高準確度。此外，我們討論了框架的其他關鍵組成部分，包括情境感知編碼、情境感知學習、可解釋性和可說明性，以及持續監控和適應。這項研究有助於負責任的人工智慧的日益增長的工作，提供了一種實用的方法來開發更可靠、可信賴且符合倫理的語言模型。我們的研究結果對 LLM 在醫療保健、法律系統和社會服務等敏感領域的部署具有重大意義，在這些領域中，情境理解至關重要。

##### **Image-to-LaTeX Converter for Mathematical Formulas and Text**
2408.04015v1 by Daniil Gurgurov, Aleksey Morshnev

In this project, we train a vision encoder-decoder model to generate LaTeX
code from images of mathematical formulas and text. Utilizing a diverse
collection of image-to-LaTeX data, we build two models: a base model with a
Swin Transformer encoder and a GPT-2 decoder, trained on machine-generated
images, and a fine-tuned version enhanced with Low-Rank Adaptation (LoRA)
trained on handwritten formulas. We then compare the BLEU performance of our
specialized model on a handwritten test set with other similar models, such as
Pix2Text, TexTeller, and Sumen. Through this project, we contribute open-source
models for converting images to LaTeX and provide from-scratch code for
building these models with distributed training and GPU optimizations.

摘要：在這個專案中，我們訓練一個視覺編碼器-解碼器模型，從數學公式和文字的影像產生 LaTeX 程式碼。利用多樣化的影像到 LaTeX 資料集，我們建立了兩個模型：一個使用 Swin Transformer 編碼器和 GPT-2 解碼器的基礎模型，訓練於機器產生的影像，以及一個使用低秩適應 (LoRA) 微調的版本，訓練於手寫公式。接著，我們將我們專門模型在手寫測試集上的 BLEU 效能與其他類似模型進行比較，例如 Pix2Text、TexTeller 和 Sumen。透過這個專案，我們貢獻了用於將影像轉換為 LaTeX 的開源模型，並提供從頭開始建構這些模型的原始碼，包含分散式訓練和 GPU 最佳化。

##### **SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature**
2408.03936v1 by Vinícius Di Oliveira, Yuri Façanha Bezerra, Li Weigang, Pedro Carvalho Brom, Victor Rafael R. Celestino

Natural language processing (NLP) has seen significant advancements with the
advent of large language models (LLMs). However, substantial improvements are
still needed for languages other than English, especially for specific domains
like the applications of Mercosur Common Nomenclature (NCM), a Brazilian
Harmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a
foundational Portuguese LLM, as an LLM source to implement the NCM application
processing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)
technique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.
This approach retains the chain-of-thought (CoT) methodology for prompt
development in a more concise and streamlined manner, utilizing brief and
focused documents for training. The proposed model demonstrates an efficient
and cost-effective alternative for fine-tuning smaller LLMs, significantly
outperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although the
research focuses on NCM applications, the methodology can be easily adapted for
HS applications worldwide.

摘要：自然語言處理 (NLP) 隨著大型語言模型 (LLM) 的出現而獲得顯著進展。然而，對於英語以外的語言，特別是像巴西統一制度 (HS) 的南方共同市場共同法規 (NCM) 應用等特定領域，仍需要大幅改進。為了解決這個差距，本研究使用 TeenyTineLLaMA（一種基礎的葡萄牙語 LLM）作為 LLM 來源，來實作 NCM 應用處理。此外，提出了一種簡化的檢索增強微調 (RAFT) 技術，稱為 SLIM-RAFT，用於 LLM 的任務特定微調。這種方法保留了思考鏈 (CoT) 方法，用於以更簡潔和流暢的方式開發提示，並利用簡短且重點明確的文件進行訓練。所提出的模型展示了一個有效且經濟的替代方案，用於微調較小的 LLM，在相同的任務中顯著優於 TeenyTineLLaMA 和 ChatGPT-4。儘管研究重點在於 NCM 應用，但該方法可以很容易地適用於全球的 HS 應用。

##### **From Words to Worth: Newborn Article Impact Prediction with LLM**
2408.03934v1 by Penghai Zhao, Qinghua Xing, Kairan Dou, Jinyu Tian, Ying Tai, Jian Yang, Ming-Ming Cheng, Xiang Li

As the academic landscape expands, the challenge of efficiently identifying
potentially high-impact articles among the vast number of newly published works
becomes critical. This paper introduces a promising approach, leveraging the
capabilities of fine-tuned LLMs to predict the future impact of newborn
articles solely based on titles and abstracts. Moving beyond traditional
methods heavily reliant on external information, the proposed method discerns
the shared semantic features of highly impactful papers from a large collection
of title-abstract and potential impact pairs. These semantic features are
further utilized to regress an improved metric, TNCSI_SP, which has been
endowed with value, field, and time normalization properties. Additionally, a
comprehensive dataset has been constructed and released for fine-tuning the
LLM, containing over 12,000 entries with corresponding titles, abstracts, and
TNCSI_SP. The quantitative results, with an NDCG@20 of 0.901, demonstrate that
the proposed approach achieves state-of-the-art performance in predicting the
impact of newborn articles when compared to competitive counterparts. Finally,
we demonstrate a real-world application for predicting the impact of newborn
journal articles to demonstrate its noteworthy practical value. Overall, our
findings challenge existing paradigms and propose a shift towards a more
content-focused prediction of academic impact, offering new insights for
assessing newborn article impact.

摘要：隨著學術領域的擴展，在大量新出版的作品中有效找出潛在高影響力文章的挑戰變得至關重要。本文介紹了一種有前途的方法，利用微調 LLM 的能力來預測新生文章的未來影響，僅根據標題和摘要。超越了傳統方法，該方法依賴於外部資訊，提出的方法從大量的標題摘要和潛在影響對中辨別出高影響力論文的共用語義特徵。這些語義特徵進一步用於回歸一個改進的指標 TNCSI_SP，該指標已賦予值、欄位和時間正規化屬性。此外，還構建並發布了一個綜合資料集，用於微調 LLM，其中包含超過 12,000 個條目，以及對應的標題、摘要和 TNCSI_SP。定量結果，NDCG@20 為 0.901，證明了與競爭對手相比，所提出的方法在預測新生文章的影響方面達到了最先進的效能。最後，我們展示了一個現實世界的應用，用於預測新生期刊文章的影響，以證明其顯著的實用價值。總的來說，我們的發現挑戰了現有的範例，並建議轉向更注重內容的學術影響預測，為評估新生文章影響提供了新的見解。

##### **CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**
2408.03910v1 by Xiangyan Liu, Bo Lan, Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Wenmeng Zhou, Fei Wang, Michael Shieh

Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval
and MBPP, but struggle with handling entire code repositories. This challenge
has prompted research on enhancing LLM-codebase interaction at a repository
scale. Current solutions rely on similarity-based retrieval or manual tools and
APIs, each with notable drawbacks. Similarity-based retrieval often has low
recall in complex tasks, while manual tools and APIs are typically
task-specific and require expert knowledge, reducing their generalizability
across diverse code tasks and real-world applications. To mitigate these
limitations, we introduce \framework, a system that integrates LLM agents with
graph database interfaces extracted from code repositories. By leveraging the
structural properties of graph databases and the flexibility of the graph query
language, \framework enables the LLM agent to construct and execute queries,
allowing for precise, code structure-aware context retrieval and code
navigation. We assess \framework using three benchmarks: CrossCodeEval,
SWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding
applications. With a unified graph database schema, \framework demonstrates
competitive performance and potential in both academic and real-world
environments, showcasing its versatility and efficacy in software engineering.
Our application demo:
https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.

摘要：大型語言模型 (LLM) 在獨立程式碼任務中表現出色，例如 HumanEval 和 MBPP，但處理整個程式碼儲存庫時卻遇到困難。這個挑戰促使研究人員加強 LLM 與程式碼庫的互動，並以儲存庫為規模。目前的解決方案依賴於基於相似性的擷取或手動工具和 API，每種方法都有顯著的缺點。基於相似性的擷取在複雜任務中通常召回率低，而手動工具和 API 通常是特定於任務的，需要專家知識，這會降低它們在不同程式碼任務和實際應用中的概括性。為了減輕這些限制，我們引入了 \framework，一個將 LLM 代理與從程式碼儲存庫中提取的圖形資料庫介面整合的系統。透過利用圖形資料庫的結構特性和圖形查詢語言的靈活性，\framework 使 LLM 代理能夠建構和執行查詢，允許精確、有程式碼結構意識的內容擷取和程式碼導覽。我們使用三個基準來評估 \framework：CrossCodeEval、SWE-bench 和 EvoCodeBench。此外，我們開發了五個實際的程式碼應用程式。有了統一的圖形資料庫架構，\framework 在學術和實際環境中都展現出競爭力的效能和潛力，展示了它在軟體工程中的多功能性和有效性。我們的應用程式示範：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。

##### **Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models**
2408.03907v1 by Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, Lama Nachman

Large Language Models (LLMs) have excelled at language understanding and
generating human-level text. However, even with supervised training and human
alignment, these LLMs are susceptible to adversarial attacks where malicious
users can prompt the model to generate undesirable text. LLMs also inherently
encode potential biases that can cause various harmful effects during
interactions. Bias evaluation metrics lack standards as well as consensus and
existing methods often rely on human-generated templates and annotations which
are expensive and labor intensive. In this work, we train models to
automatically create adversarial prompts to elicit biased responses from target
LLMs. We present LLM- based bias evaluation metrics and also analyze several
existing automatic evaluation methods and metrics. We analyze the various
nuances of model responses, identify the strengths and weaknesses of model
families, and assess where evaluation methods fall short. We compare these
metrics to human evaluation and validate that the LLM-as-a-Judge metric aligns
with human judgement on bias in response generation.

摘要：大型語言模型 (LLM) 在語言理解和產生人類層級文字方面表現出色。然而，即使經過監督式訓練和人類校準，這些 LLM 仍容易受到對抗性攻擊，惡意使用者可以提示模型產生不良文字。LLM 本身也編碼了潛在偏見，可能在互動過程中造成各種有害影響。偏見評估指標缺乏標準和共識，現有方法通常依賴於人工產生的範本和註解，這些範本和註解昂貴且耗費人力。在這項工作中，我們訓練模型自動建立對抗性提示，從目標 LLM 引出有偏見的回應。我們提出基於 LLM 的偏見評估指標，並分析了幾種現有的自動評估方法和指標。我們分析模型回應的各種細微差別，找出模型系列的優缺點，並評估評估方法的不足之處。我們將這些指標與人類評估進行比較，並驗證 LLM 作為評判指標與人類對回應中偏見的判斷一致。

##### **Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond**
2408.03900v1 by Beomseok Lee, Ioan Calapodescu, Marco Gaido, Matteo Negri, Laurent Besacier

We present Speech-MASSIVE, a multilingual Spoken Language Understanding (SLU)
dataset comprising the speech counterpart for a portion of the MASSIVE textual
corpus. Speech-MASSIVE covers 12 languages from different families and inherits
from MASSIVE the annotations for the intent prediction and slot-filling tasks.
Our extension is prompted by the scarcity of massively multilingual SLU
datasets and the growing need for versatile speech datasets to assess
foundation models (LLMs, speech encoders) across languages and tasks. We
provide a multimodal, multitask, multilingual dataset and report SLU baselines
using both cascaded and end-to-end architectures in various training scenarios
(zero-shot, few-shot, and full fine-tune). Furthermore, we demonstrate the
suitability of Speech-MASSIVE for benchmarking other tasks such as speech
transcription, language identification, and speech translation. The dataset,
models, and code are publicly available at:
https://github.com/hlt-mt/Speech-MASSIVE

摘要：我們提出 Speech-MASSIVE，一個多語言的口語理解 (SLU)
資料集，包含 MASSIVE 文本語料庫一部分的口語對應部分。Speech-MASSIVE 涵蓋了來自不同語系的 12 種語言，並繼承了 MASSIVE 中用於意圖預測和槽位填補任務的註解。
我們的擴展是由大量的多語言 SLU 資料集的稀缺性以及評估跨語言和任務的基礎模型 (LLM、語音編碼器) 對通用語音資料集日益增長的需求所推動的。我們提供了一個多模態、多任務、多語言的資料集，並在各種訓練場景（零次學習、少次學習和完全微調）中報告了使用串聯和端到端架構的 SLU 基線。此外，我們展示了 Speech-MASSIVE 適用於對其他任務（例如語音轉錄、語言識別和語音翻譯）進行基準測試。資料集、模型和程式碼可在以下位置公開獲得：
https://github.com/hlt-mt/Speech-MASSIVE

##### **Simplifying Scholarly Abstracts for Accessible Digital Libraries**
2408.03899v1 by Haining Wang, Jason Clark

Standing at the forefront of knowledge dissemination, digital libraries
curate vast collections of scientific literature. However, these scholarly
writings are often laden with jargon and tailored for domain experts rather
than the general public. As librarians, we strive to offer services to a
diverse audience, including those with lower reading levels. To extend our
services beyond mere access, we propose fine-tuning a language model to rewrite
scholarly abstracts into more comprehensible versions, thereby making scholarly
literature more accessible when requested. We began by introducing a corpus
specifically designed for training models to simplify scholarly abstracts. This
corpus consists of over three thousand pairs of abstracts and significance
statements from diverse disciplines. We then fine-tuned four language models
using this corpus. The outputs from the models were subsequently examined both
quantitatively for accessibility and semantic coherence, and qualitatively for
language quality, faithfulness, and completeness. Our findings show that the
resulting models can improve readability by over three grade levels, while
maintaining fidelity to the original content. Although commercial
state-of-the-art models still hold an edge, our models are much more compact,
can be deployed locally in an affordable manner, and alleviate the privacy
concerns associated with using commercial models. We envision this work as a
step toward more inclusive and accessible libraries, improving our services for
young readers and those without a college degree.

摘要：作為知識傳播的最前線，數位圖書館管理著龐大科學文獻的集合。然而，這些學術寫作通常充滿術語，並針對領域專家量身打造，而非一般大眾。身為圖書館員，我們致力於為多元受眾提供服務，包括閱讀能力較低者。為了將我們的服務擴展到單純存取之外，我們建議微調語言模型，將學術摘要改寫為更易於理解的版本，從而讓學術文獻在需要時更易於存取。我們首先引入一個專門設計用於訓練模型以簡化學術摘要的語料庫。此語料庫包含來自不同領域的三千多對摘要和重要性聲明。然後，我們使用此語料庫微調了四個語言模型。接著，從模型輸出的結果中，我們定量檢查了可存取性和語義相干性，並定性檢查了語言品質、忠實度和完整性。我們的研究結果顯示，這些模型可以將可讀性提升超過三個年級程度，同時維持對原始內容的忠實度。儘管商業最先進的模型仍佔有一席之地，但我們的模型更為精簡，可以經濟實惠的方式在本地部署，並減輕與使用商業模型相關的隱私問題。我們將這項工作視為邁向更具包容性和可存取性的圖書館的一步，改善我們對年輕讀者和沒有大學學位的讀者的服務。

##### **MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems**
2408.03892v1 by Renzhi Wang, Zhehua Zhou, Jiayang Song, Xuan Xie, Xiaofei Xie, Lei Ma

Cyber-Physical Systems (CPSs) are increasingly prevalent across various
industrial and daily-life domains, with applications ranging from robotic
operations to autonomous driving. With recent advancements in artificial
intelligence (AI), learning-based components, especially AI controllers, have
become essential in enhancing the functionality and efficiency of CPSs.
However, the lack of interpretability in these AI controllers presents
challenges to the safety and quality assurance of AI-enabled CPSs (AI-CPSs).
Existing methods for improving the safety of AI controllers often involve
neural network repair, which requires retraining with additional adversarial
examples or access to detailed internal information of the neural network.
Hence, these approaches have limited applicability for black-box policies,
where only the inputs and outputs are accessible during operation. To overcome
this, we propose MORTAR, a runtime action repair framework designed for AI-CPSs
in this work. MORTAR begins by constructing a prediction model that forecasts
the quality of actions proposed by the AI controller. If an unsafe action is
detected, MORTAR then initiates a repair process to correct it. The generation
of repaired actions is achieved through an optimization process guided by the
safety estimates from the prediction model. We evaluate the effectiveness of
MORTAR across various CPS tasks and AI controllers. The results demonstrate
that MORTAR can efficiently improve task completion rates of AI controllers
under specified safety specifications. Meanwhile, it also maintains minimal
computational overhead, ensuring real-time operation of the AI-CPSs.

摘要：網路物理系統 (CPS) 在各種產業和日常生活領域中越來越普遍，應用範圍從機器人作業到自動駕駛。隨著人工智慧 (AI) 的最新進展，基於學習的元件，尤其是 AI 控制器，已成為增強 CPS 功能和效率的必要條件。
然而，這些 AI 控制器缺乏可解釋性，對 AI 驅動的 CPS (AI-CPS) 的安全性與品質保證提出了挑戰。現有的改善 AI 控制器安全性的方法通常涉及神經網路修復，這需要使用額外的對抗性範例重新訓練或取得神經網路的詳細內部資訊。
因此，這些方法對於黑盒政策的適用性有限，因為在操作期間只能存取輸入和輸出。為了克服這個問題，我們在這項工作中提出了 MORTAR，一個專為 AI-CPS 設計的執行時間動作修復架構。MORTAR 首先建立一個預測模型，用於預測 AI 控制器建議的動作品質。如果偵測到不安全的動作，MORTAR 接著會啟動一個修復程序來修正它。修復動作的產生是透過一個最佳化程序達成，這個程序由預測模型的安全估計值引導。我們評估了 MORTAR 在各種 CPS 任務和 AI 控制器中的有效性。結果證明 MORTAR 能在指定的安全性規範下有效率地改善 AI 控制器的任務完成率。同時，它也維持最小的運算負擔，確保 AI-CPS 的即時操作。

##### **Personalized Clinical Note Generation from Doctor-Patient Conversations**
2408.03874v1 by Nathan Brake, Thomas Schaaf

In this work, we present a novel technique to improve the quality of draft
clinical notes for physicians. This technique is concentrated on the ability to
model implicit physician conversation styles and note preferences. We also
introduce a novel technique for the enrollment of new physicians when a limited
number of clinical notes paired with conversations are available for that
physician, without the need to re-train a model to support them. We show that
our technique outperforms the baseline model by improving the ROUGE-2 score of
the History of Present Illness section by 13.8%, the Physical Examination
section by 88.6%, and the Assessment & Plan section by 50.8%.

摘要：在這項工作中，我們提出了一種新的技術來改善醫師的臨床草稿筆記品質。此技術集中在模擬隱含的醫師對話風格和筆記偏好的能力。我們還引入了一種新的技術，用於在只有少數配對對話的臨床筆記可用於該醫師時註冊新醫師，而無需重新訓練模型來支援他們。我們展示了我們的技術通過將現病史部分的 ROUGE-2 分數提高 13.8%、身體檢查部分提高 88.6%、評估和計畫部分提高 50.8%，表現優於基準模型。

##### **Inter-Series Transformer: Attending to Products in Time Series Forecasting**
2408.03872v1 by Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni

Time series forecasting is an important task in many fields ranging from
supply chain management to weather forecasting. Recently, Transformer neural
network architectures have shown promising results in forecasting on common
time series benchmark datasets. However, application to supply chain demand
forecasting, which can have challenging characteristics such as sparsity and
cross-series effects, has been limited.
  In this work, we explore the application of Transformer-based models to
supply chain demand forecasting. In particular, we develop a new
Transformer-based forecasting approach using a shared, multi-task per-time
series network with an initial component applying attention across time series,
to capture interactions and help address sparsity. We provide a case study
applying our approach to successfully improve demand prediction for a medical
device manufacturing company. To further validate our approach, we also apply
it to public demand forecasting datasets as well and demonstrate competitive to
superior performance compared to a variety of baseline and state-of-the-art
forecast methods across the private and public datasets.

摘要：時間序列預測在許多領域中都是一項重要的任務，從供應鏈管理到天氣預測都有涉及。最近，Transformer 神經網路架構在常見時間序列基準資料集的預測中展現了令人滿意的成果。然而，應用於供應鏈需求預測的範疇受到限制，因為供應鏈需求預測可能具有稀疏性和跨系列效應等具挑戰性的特徵。
  在這項工作中，我們探討了將基於 Transformer 的模型應用於供應鏈需求預測。特別是，我們開發了一種新的基於 Transformer 的預測方法，使用一個共用的、每個時間序列的多任務網路，並在初始元件中套用跨時間序列的注意力，以擷取互動並協助解決稀疏性問題。我們提供了一個案例研究，應用我們的做法成功改善了一家醫療器材製造公司的需求預測。為了進一步驗證我們的做法，我們也將其應用於公開的需求預測資料集，並證明與各種基線和最先進的預測方法相比，在私有和公開資料集中的表現具有競爭力或優於這些方法。

##### **BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability**
2408.03871v1 by Zihao Li, Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Matthew Shardlow, Goran Nenadic

In this system report, we describe the models and methods we used for our
participation in the PLABA2023 task on biomedical abstract simplification, part
of the TAC 2023 tracks. The system outputs we submitted come from the following
three categories: 1) domain fine-tuned T5-like models including Biomedical-T5
and Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes
(via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work we
carried out for this task on BioGPT finetuning. In the official automatic
evaluation using SARI scores, BeeManc ranks 2nd among all teams and our model
LaySciFive ranks 3rd among all 13 evaluated systems. In the official human
evaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score
92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It
also produced a high score 91.57 on Fluency in comparison to the highest score
93.53. In the second round of submissions, our team using ChatGPT-prompting
ranks the 2nd in several categories including simplified term accuracy score
92.26 and completeness score 96.58, and a very similar score on faithfulness
score 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations. Our
codes, fine-tuned models, prompts, and data splits from the system development
stage will be available at https://github.com/ HECTA-UoM/PLABA-MU

摘要：<paragraph>在這個系統報告中，我們描述了我們在 TAC 2023 軌道的一部分，PLABA2023 生物醫學摘要簡化任務中所使用的模型和方法。我們提交的系統輸出來自以下三種類別：1) 領域微調的 T5 類似模型，包括 Biomedical-T5 和 Lay-SciFive；2) 微調 BARTLarge 模型，具有可控屬性（通過代幣）BART-w-CTs；3) ChatGPT 提示。我們還展示了我們在 BioGPT 微調中為這項任務所做的工作。在使用 SARI 分數的官方自動評估中，BeeManc 在所有團隊中排名第 2，我們的模型 LaySciFive 在所有 13 個評估系統中排名第 3。在官方人工評估中，我們的模型 BART-w-CTs 在句子簡潔性（分數 92.84）中排名第 2，在術語簡潔性（分數 82.33）中排名第 3，在所有 7 個評估系統中排名第 3；它還產生了 91.57 的高流暢度分數，而最高分為 93.53。在第二輪提交中，我們使用 ChatGPT 提示的團隊在幾個類別中排名第 2，包括簡化術語準確度分數 92.26 和完整性分數 96.58，以及對 PLABA-base-1（95.73）重新評估的忠實度分數 95.3 非常相似通過人工評估。我們的代碼、微調模型、提示和系統開發階段的數據分割將在 https://github.com/ HECTA-UoM/PLABA-MU 中提供</paragraph>

##### **Why transformers are obviously good models of language**
2408.03855v1 by Felix Hill

Nobody knows how language works, but many theories abound. Transformers are a
class of neural networks that process language automatically with more success
than alternatives, both those based on neural computations and those that rely
on other (e.g. more symbolic) mechanisms. Here, I highlight direct connections
between the transformer architecture and certain theoretical perspectives on
language. The empirical success of transformers relative to alternative models
provides circumstantial evidence that the linguistic approaches that
transformers embody should be, at least, evaluated with greater scrutiny by the
linguistics community and, at best, considered to be the currently best
available theories.

摘要：沒有人知道語言是如何運作的，但有許多理論流傳。Transformer是一種神經網路，可以自動處理語言，比其他基於神經運算和依賴其他（例如更具象徵性的）機制的替代方案更成功。在此，我重點說明Transformer架構與語言的某些理論觀點之間的直接關聯。Transformer相對於替代模型的經驗成功提供了環境證據，證明Transformer所體現的語言方法應至少受到語言學界的更嚴格評估，並在最好的情況下被認為是當前可用的最佳理論。

##### **Hate Speech Detection and Classification in Amharic Text with Deep Learning**
2408.03849v1 by Samuel Minale Gashe, Seid Muhie Yimam, Yaregal Assabie

Hate speech is a growing problem on social media. It can seriously impact
society, especially in countries like Ethiopia, where it can trigger conflicts
among diverse ethnic and religious groups. While hate speech detection in
resource rich languages are progressing, for low resource languages such as
Amharic are lacking. To address this gap, we develop Amharic hate speech data
and SBi-LSTM deep learning model that can detect and classify text into four
categories of hate speech: racial, religious, gender, and non-hate speech. We
have annotated 5k Amharic social media post and comment data into four
categories. The data is annotated using a custom annotation tool by a total of
100 native Amharic speakers. The model achieves a 94.8 F1-score performance.
Future improvements will include expanding the dataset and develop state-of-the
art models.
  Keywords: Amharic hate speech detection, classification, Amharic dataset,
Deep Learning, SBi-LSTM

摘要：仇恨言論是社群媒體上日益嚴重的問題。它會嚴重影響社會，特別是在像衣索比亞這樣的國家，它會引發不同種族和宗教團體之間的衝突。雖然資源豐富的語言仇恨言論偵測正在進展中，但像阿姆哈拉語這樣的低資源語言卻缺乏。為了解決這個差距，我們開發了阿姆哈拉語仇恨言論資料和 SBi-LSTM 深度學習模型，可以偵測並將文字分類為四種類別的仇恨言論：種族、宗教、性別和非仇恨言論。我們已將 5 千個阿姆哈拉語社群媒體貼文和留言資料註解為四種類別。資料是由總共 100 位母語為阿姆哈拉語的講者使用自訂註解工具進行註解。該模型達到了 94.8 的 F1 分數表現。未來的改進將包括擴充資料集和開發最先進的模型。
關鍵字：阿姆哈拉語仇恨言論偵測、分類、阿姆哈拉語資料集、深度學習、SBi-LSTM

##### **MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models**
2408.03841v1 by Yuchen Dong, XiaoXiang Fang, Yuchen Hu, Renshuang Jiang, Zhe Jiang

The application of large language models to facilitate automated software
operations and tool generation (SOTG), thus augmenting software productivity,
mirrors the early stages of human evolution when the ability to create and use
tools accelerated the progress of civilization. These complex tasks require AI
to continuously summarize and improve. Current research often overlooks the
importance of converting real-time task experiences into system memory and
differentiating the value of existing knowledge for future reference. This
paper addresses these issues by evolving external memory models into
Memory-Loop Networks for timely memorization and experience referencing. We
also enhance a RAG mechanism with knowledge precision segmentation to utilize
memory based on value differentiation, and design the MaxMind model for SOTG
accordingly.To demonstrate our approach, we developed MaxMind4Sheet, an
electronic spreadsheet processing system aligned with the MaxMind philosophy.
Comparative experiments with SheetCopilot have demonstrated that the
accumulation and recycling of task memories lead to a steady enhancement in
task success rate, with an improvement rate of approximately 3%-6% per round in
this implementation example. Note that as the memories continue to grow, this
cumulative improvement may be substantial. The inclusion of memory recycling
can also boost the system's task execution efficiency by up to 25%, and it can
address the retraining issue faced by LLMs when handling specialized tasks
through memories transfer.These suggest that MaxMind has significant potential
to enhance the capabilities and productivity of LLM systems in SOTG.

摘要：大型語言模型的應用有助於促進自動化軟體操作和工具生成 (SOTG)，進而提升軟體生產力，這反映了人類演化的早期階段，當時創造和使用工具的能力加速了文明的進步。這些複雜的任務需要 AI 持續總結和改進。目前的許多研究常常忽略將即時任務經驗轉換為系統記憶，以及區分現有知識對未來參考價值的重要性。本文透過將外部記憶模型演變成記憶迴圈網路，以實現及時記憶和經驗參考，來解決這些問題。我們也透過知識精準分段來強化 RAG 機制，以根據價值區分來利用記憶，並據此設計用於 SOTG 的 MaxMind 模型。為了展示我們的做法，我們開發了 MaxMind4Sheet，這是一個與 MaxMind 理念一致的電子試算表處理系統。與 SheetCopilot 進行的比較實驗已證明，任務記憶的累積和再利用會持續提升任務成功率，在此實作範例中，每回合的提升率約為 3%-6%。請注意，隨著記憶的持續增加，這種累積提升可能會很可觀。納入記憶再利用也能提升系統的任務執行效率，最高可達 25%，而且它能透過記憶轉移來解決 LLM 在處理專業任務時所面臨的重新訓練問題。這些都顯示出 MaxMind 在提升 LLM 系統在 SOTG 中的能力和生產力方面具有顯著的潛力。

##### **WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models**
2408.03837v1 by Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria

WalledEval is a comprehensive AI safety testing toolkit designed to evaluate
large language models (LLMs). It accommodates a diverse range of models,
including both open-weight and API-based ones, and features over 35 safety
benchmarks covering areas such as multilingual safety, exaggerated safety, and
prompt injections. The framework supports both LLM and judge benchmarking, and
incorporates custom mutators to test safety against various text-style
mutations such as future tense and paraphrasing. Additionally, WalledEval
introduces WalledGuard, a new, small and performant content moderation tool,
and SGXSTest, a benchmark for assessing exaggerated safety in cultural
contexts. We make WalledEval publicly available at
https://github.com/walledai/walledevalA.

摘要：WalledEval 是一個全面的 AI 安全測試工具包，旨在評估大型語言模型 (LLM)。它容納了各種模型，包括開放權重和基於 API 的模型，並具有超過 35 個安全基準，涵蓋多語言安全、誇張安全和提示注入等領域。該框架支援 LLM 和評審基準測試，並整合自訂變異器，以針對各種文字樣式變異（例如未來式和同義改寫）測試安全性。此外，WalledEval 引入了 WalledGuard，這是一個新的、小巧且高效的內容審核工具，以及 SGXSTest，一個用於評估文化背景中誇大安全性的基準。我們在 https://github.com/walledai/walledevalA 上公開 WalledEval。

##### **Target Prompting for Information Extraction with Vision Language Model**
2408.03834v1 by Dipankar Medhi

The recent trend in the Large Vision and Language model has brought a new
change in how information extraction systems are built. VLMs have set a new
benchmark with their State-of-the-art techniques in understanding documents and
building question-answering systems across various industries. They are
significantly better at generating text from document images and providing
accurate answers to questions. However, there are still some challenges in
effectively utilizing these models to build a precise conversational system.
General prompting techniques used with large language models are often not
suitable for these specially designed vision language models. The output
generated by such generic input prompts is ordinary and may contain information
gaps when compared with the actual content of the document. To obtain more
accurate and specific answers, a well-targeted prompt is required by the vision
language model, along with the document image. In this paper, a technique is
discussed called Target prompting, which focuses on explicitly targeting parts
of document images and generating related answers from those specific regions
only. The paper also covers the evaluation of response for each prompting
technique using different user queries and input prompts.

摘要：近期大型視覺與語言模型的趨勢為資訊萃取系統的建置方式帶來了新的變化。VLMs 以其在理解文件和建立跨產業問答系統的最新技術樹立了新的基準。它們在從文件影像產生文字和提供準確的答案方面顯著地更出色。然而，在有效利用這些模型來建立精確的對話系統方面仍有一些挑戰。與大型語言模型一起使用的一般提示技術通常不適合這些特別設計的視覺語言模型。此類一般輸入提示產生的輸出很普通，與文件的實際內容相比時可能會包含資訊差距。為了獲得更準確且具體的答案，視覺語言模型需要一個明確的目標提示，以及文件影像。在本文中，討論了一種稱為目標提示的技術，其專注於明確鎖定文件影像的部分，並僅從那些特定區域產生相關答案。本文還涵蓋了使用不同的使用者查詢和輸入提示對每種提示技術的回應評估。

##### **Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps**
2408.03827v1 by Forough Mehralian, Titus Barik, Jeff Nichols, Amanda Swearngin

Accessibility is crucial for inclusive app usability, yet developers often
struggle to identify and fix app accessibility issues due to a lack of
awareness, expertise, and inadequate tools. Current accessibility testing tools
can identify accessibility issues but may not always provide guidance on how to
address them. We introduce FixAlly, an automated tool designed to suggest
source code fixes for accessibility issues detected by automated accessibility
scanners. FixAlly employs a multi-agent LLM architecture to generate fix
strategies, localize issues within the source code, and propose code
modification suggestions to fix the accessibility issue. Our empirical study
demonstrates FixAlly's capability in suggesting fixes that resolve issues found
by accessibility scanners -- with an effectiveness of 77% in generating
plausible fix suggestions -- and our survey of 12 iOS developers finds they
would be willing to accept 69.4% of evaluated fix suggestions.

摘要：無障礙功能對於包容性應用程式可用性至關重要，但開發人員經常因缺乏意識、專業知識和工具不足而難以識別和修復應用程式無障礙性問題。目前的無障礙性測試工具可以識別無障礙性問題，但可能無法始終提供如何解決這些問題的指導。我們介紹 FixAlly，這是一個自動化工具，旨在為自動化無障礙性掃描器檢測到的無障礙性問題建議原始碼修復程式。FixAlly 採用多代理 LLM 架構來產生修復策略，在原始碼中找出問題，並提出修復無障礙性問題的程式碼修改建議。我們的實證研究證明了 FixAlly 在建議修復程式以解決無障礙性掃描器發現的問題方面的能力——在產生看似合理的修復建議方面有效率為 77%——而且我們對 12 位 iOS 開發人員的調查發現，他們願意接受 69.4% 的評估修復建議。

