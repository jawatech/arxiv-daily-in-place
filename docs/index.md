# arxiv-daily
 Automated deployment @ 2024-11-10 09:08:18 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v1](http://arxiv.org/abs/2411.00916v1)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|

#### Abstracts
##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v1 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, U. Rajendra Acharya, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡ååè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨ææ°ï¼ä¾å¦æ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼å®æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´ç¶²è·¯ - VGG19ãInceptionV3 å ResNet50 - å¾ X åå½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æï¼ä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼ç¾¤éçé¸æéç¨è­å¥æå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°å¶èé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) èçä»¥é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªé¡¯äºééµè®æ¸ï¼é¡¯ç¤ºçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»èï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãéåæ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·çä¿¡ä»»ï¼ä»¥é²è¡è¨åºæ´åã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çä¸é ééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æå°æ£èççµæç¢çéå¤§å½±é¿ãå³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨æ­¤é ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éæ¯è¨åºç°å¢ä¸­çééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼å¯è§£éçè¨ºæ·é æ¸¬æ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼è©²æ¨¡åéééè¼¯è¦ååå¯å­¸ç¿çé¾å¼æ´åé åç¹å®çç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåè¶æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­ï¼éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸æå®³é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼ç²¾æºé«ççé²æ­¥ï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

æè¦ï¼<paragraph>éè¦æ§ä¼°è¨å¨æ¯ä¸ç¨®å¯è§£éæ§æ¹æ³ï¼ç¨æ¼éåæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¹å¾µéè¦æ§ãå¨è¦è¦ºTransformer (ViT) ä¸­ï¼èªææ³¨ææ©å¶èªç¶æå°è´æ³¨æååï¼æææå°å¶è§£éçºéè¦æ§åæ¸ï¼è¡¨ç¤º ViT æ¨¡åéæ³¨åªäºè¼¸å¥ç¹å¾µãç¶èï¼æ³¨æååä¸¦æªèæ®ä¾èªä¸æ¸¸ä»»åçä¿¡èãçºäºç¢çå°ä¸æ¸¸ä»»åææçè§£éï¼æåéç¼äºé¡å¥ååæ³¨æåå (CDAM)ï¼éæ¯ä¸ç¨®åºæ¼æ¢¯åº¦çæ´åï¼ç¨æ¼ä¼°è¨ç¸å°æ¼å·²ç¥é¡å¥ææ½å¨æ¦å¿µçç¹å¾µéè¦æ§ãCDAM æ ¹æå°æçç¬¦èèåé¡å¨é ­çé æ¸¬ç¸éç¨åº¦ï¼èª¿æ´æ³¨æååæ¸ãé¤äºéå°ç£ç£åé¡å¨å¤ï¼CDAM éå¯ä»¥ééæ¸¬é ViT çæ½å¨ç©ºéä¸­çç¸ä¼¼æ§ä¾è§£éé¸å®æ¨£æ¬å±æçä»»ææ¦å¿µãæ­¤å¤ï¼æåå¼å¥äºå¹³æ» CDAM åç©å CDAMï¼å®åå°ä¸ç³»åå·æç¥å¾®æ¹è®çç¬¦èç CDAM é²è¡å¹³åãæåçéååºæºåæ¬æ­£ç¢ºæ§ãç·æ¹æ§åé¡å¥æææ§ï¼èå¶ä» 7 åéè¦æ§ä¼°è¨å¨ç¸æ¯ãé¦èãå¹³æ»åç©å CDAM å¨ææä¸ååºæºä¸­è¡¨ç¾åºè²ãç¹å¥æ¯ï¼æåççµæè¡¨æç¾æçéè¦æ§ä¼°è¨å¨å¯è½ç¡æ³æä¾è¶³å¤ çé¡å¥æææ§ãæåééåºæ¼èºé¨é»è¦æ·å±¤ææ (CT) ææè¨ç·´åè§£éæ¡æ§è«ç¤åçç©æ¨è¨é æ¸¬æ¨¡åï¼è­æäº CDAM å¨é«å­¸å½±åä¸­çæç¨ãç¸½çä¾èªªï¼CDAM è¢«è­æå·æé«åº¦é¡å¥ååæ§åèªç¾©ç¸éæ§ï¼åææä¾ç°¡æ½çè§£éã</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI éç¼ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»æ©æ§æä¾ç¨æ¶ä¸å³çæ¨¡ååè¨ç·´è³æçç°¡æå­åæ¬éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åç¨æ¶çæè¡é¨ç½²éç¤ï¼ä½å¯è½æè¢«ç¨æ¼è¨±å¤æ½å¨æå®³åéæ³çæ¹å¼ãå¨æ¬æä¸­ï¼æåèªªæ AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼åå¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æª¢è¦æ¨¡åå¸éå¦ä½å¯©æ ¸æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°ç¢æ¥­çºåæå¯©æ ¸éæ±èéç¼çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªååå§å®¹å¯©æ ¸åéæ¾æ¿ç­å¶å®ãéç¶ç¶åæ¿ç­ææ°ç¸ç¶å¯è§ï¼æåæå¾æåºä¸äºæ§æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³ä¸é©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

æè¦ï¼<paragraph>ä½¿ç¨é«çå½±åè¨ç·´çäººå·¥æºæ§ (AI) æ¨¡åï¼ç¨æ¼è¨åºä»»åæï¼å¸¸æå¨æè½ä¸å±ç¾åºæ¬¡ç¾¤é«ä¹éçå·®ç°ï¼å½¢æåè¦ãç±æ¼ä¸¦éææçå¯¦ä¸çé«çå½±åè³æä¸­çåè¦ä¾æºé½å®¹æè¾¨è­ï¼å æ­¤å¨é¢è©ä¼°éäºåè¦æ¯å¦ä½ç·¨ç¢¼å°æ¨¡åä¸­ï¼ä»¥ååè¦ç·©è§£æ¹æ³å¨æ¹åæè½å·®ç°æ¹é¢çè½åï¼æ¯ä¸é ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çåææ¶æ§ï¼ç¨æ¼ç³»çµ±åä¸å®¢è§å°èª¿æ¥é«çå½±åä¸­çåè¦å° AI æ¨¡åçå½±é¿ãæåéç¼ä¸¦æ¸¬è©¦äºéåæ¶æ§ï¼ä»¥é²è¡åæ§çé»è¦æ¨¡æ¬è©¦é©ï¼ä½¿ç¨ä¸åå·¥å·ä¾è©ä¼°é«çå½±å AI ä¸­çåè¦ï¼è©²å·¥å·ç¨æ¼ç¢çå·æå·²ç¥ç¾çå½±é¿ååè¦ä¾æºçåæç£å±æ¯å½±åãå¯è¡æ§ééä½¿ç¨ä¸ååäºå¯¦åè¦æå¢ä¾è¡¡éæ¨¡æ¬åè¦ææå°å·ç©ç¥ç¶ç¶²è·¯ (CNN) åé¡å¨åä¸ååè¦ç·©è§£ç­ç¥çå½±é¿ï¼ä¸¦å±ç¤ºåºä¾ãåæé¡¯ç¤ºï¼ç¶ CNN å¨åæè³æéä¸åè¨æï¼æ¨¡æ¬åè¦æå°è´é æçæ¬¡ç¾¤é«æè½å·®ç°ãæ­¤å¤ï¼éæ°å æ¬è¢«èªçºæ¯æ­¤è¨­å®ä¸­ææåçåè¦ç·©è§£ç­ç¥ï¼æåå±ç¤ºäºè§£éæ§ AI æ¹æ³å¦ä½åå©ä½¿ç¨éåæ¶æ§èª¿æ¥æ¨¡åä¸­åè¦çè¡¨ç¾ãéç¼å¬å¹³ç AI æ¨¡åæ¯ä¸é éå¤§çææ°ï¼å çºé«çå½±åè³æéä¸­å¯è½å­å¨è¨±å¤ä¸ç¶å¸¸æªç¥çåè¦ä¾æºãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å®¢è§å°ç ç©¶åè¦åç·©è§£ç­ç¥å°æ·±åº¦å­¸ç¿ç®¡ç·çå½±é¿ï¼éå¯ä»¥æ¯æ´å¥å¨ä¸è² è²¬ä»»çè¨åº AI çéç¼ã</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

æè¦ï¼æ©å¨å­¸ç¿çºèªåé æ¸¬ä¸­é¢¨å¾ççåå¶å°å¾©å¥çåææä¾äºæ¥µå¤§çæ½åãéé å·¥ä½çéå¤§ææ°åæ¬ç¥ç¶å½±åè³æçç¶­åº¦éå¸¸é«ãå¯ç¨æ¼å­¸ç¿çè³æéè¦æ¨¡ç¸å°è¼å°ï¼ä»¥åå¦ä½ææçµåç¥ç¶å½±ååè¡¨æ ¼è³æï¼ä¾å¦äººå£çµ±è¨è³è¨åè¨åºç¹å¾µï¼ãæ¬ææ ¹æå©ç¨®ç­ç¥è©ä¼°äºå¤ç¨®è§£æ±ºæ¹æ¡ãç¬¬ä¸ç¨®æ¯ä½¿ç¨ç¸½çµ MRI ææç 2D å½±åãç¬¬äºç¨®æ¯é¸ææå©æ¼æé«åé¡ç²¾ç¢ºåº¦çééµç¹å¾µãæ­¤å¤ï¼æåå¼å¥äºå¨çµåå¾ MRI ä¸­æåçæèè¶£ååèè¡¨æ ¼è³æçç¬¦èè¡¨ç¤ºçå½±åä¸è¨ç·´å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ°ç©æ¹æ³ãæåè©ä¼°äºä¸ç³»å CNN æ¶æ§ï¼2D å 3Dï¼ï¼éäºæ¶æ§å¨ MRI åè¡¨æ ¼è³æçä¸åè¡¨ç¤ºä¸é²è¡è¨ç·´ï¼ä»¥é æ¸¬ä¸­é¢¨å¾å£è¿°åçæè¿°è½åçç¶åæ¸¬éæ¯å¦å¨å¤±èªçæéå¤±èªçç¯åå§ãMRI åè¡¨æ ¼è³æä¾èª 758 ååè PLORAS ç ç©¶çè±èªä¸­é¢¨åå­èãåéå°çç¶å¤§å°çåºç·éè¼¯è¿´æ­¸åé¡æºç¢ºåº¦çº 0.678ï¼ç¶ä¾åºå å¥åå§ççå´éç¨åº¦åæ¢å¾©æéæï¼ä¸åè³ 0.757 å 0.813ãå¨å¾æ¯å MRI ææä¸­æå 8 åæèè¶£ååä¸¦å¨ 2D æ®å·®ç¥ç¶ç¶²è·¯ä¸­èçç¶å¤§å°ãåå§å´éç¨åº¦åæ¢å¾©æéçµåæï¼è§å¯å°æé«çåé¡æºç¢ºåº¦ 0.854ãæåçç ç©¶çµæå±ç¤ºäºå¦ä½å°å½±ååè¡¨æ ¼è³æçµåèµ·ä¾ä»¥ç²å¾é«æ¼ä¸­é¢¨å¾åé¡æºç¢ºåº¦ï¼å³ä½¿å¨æ©å¨å­¸ç¿è¡èªä¸­è³æéå¾å°çææ³ä¸ä¹æ¯å¦æ­¤ãæå¾ï¼æåæåºå¦ä½æ¹é²ç®åçæ¨¡åï¼ä»¥ä½¿ç¨ä¾èªé«é¢ææåçå½±åä¾å¯¦ç¾æ´é«çæºç¢ºåº¦ã

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºèçä»»åééµæç¨ç¨å¼æçä¸é åºæ¬éæ±ï¼ç¢ºä¿æ¡ç¨é»ç AI æ¨¡åçéæåº¦åå¯è§£éæ§ãXAI çéè¦æ§æ¶µèå¾é«çä¿å¥å°éèçåç¨®é åï¼å¨éäºé åä¸­ï¼äºè§£æ·±åº¦å­¸ç¿æ¼ç®æ³çæ±ºç­å¶å®éç¨è³ééè¦ãå¤§å¤æ¸åºæ¼ AI çé»è¦è¦è¦ºæ¨¡åéå¸¸æ¯é»çå­ï¼å æ­¤ï¼å¨å½±åèçä¸­æä¾æ·±åº¦ç¥ç¶ç¶²è·¯çå¯è§£éæ§å°æ¼å¶å¨é«å­¸å½±ååæãèªåé§é§åéæ¸¬æç¨ä¸­çå»£æ³æ¡ç¨åé¨ç½²è³ééè¦ãæè¿ï¼å·²éå°å½±ååé¡ä»»åå¼å¥äºå¤ç¨® XAI æ¹æ³ãç¸åå°ï¼å½±ååå²å¨å¯è§£éæ§çèæ¯ä¸åå°çéæ³¨ç¸å°è¼å°ï¼åç®¡å®æ¯é»è¦è¦è¦ºæç¨ä¸­çä¸é åºæ¬ä»»åï¼ç¹å¥æ¯å¨éæ¸¬ä¸­ãåªæé¨åç ç©¶æåºç¨æ¼å½±ååå²çåºæ¼æ¢¯åº¦ç XAI æ¼ç®æ³ãæ¬ææ¹ç·¨äºæè¿çç¡æ¢¯åº¦ Sobol XAI æ¹æ³ä»¥é²è¡èªæåå²ãçºäºè¡¡é Sobol æ¹æ³å¨åå²ä¸­çæè½ï¼æåæåºäºä¸ç¨®åºæ¼å¯å­¸ç¿éè¨æ¨¡åçå®é XAI è©ä¼°æ¹æ³ãæ­¤æ¨¡åçä¸»è¦ç®çæ¯å¨è§£éåä¸èªç¼éè¨ï¼å¶ä¸­è¼é«çèªç¼éè¨è¡¨ç¤ºè¼ä½çæºç¢ºåº¦ï¼åä¹äº¦ç¶ãé²è¡åºæºåæä»¥è©ä¼°åæ¯è¼ä¸ç¨® XAI æ¹æ³çæè½ï¼åæ¬ Seg-Grad-CAMãSeg-Grad-CAM++ å Seg-Sobolï¼ä¸¦ä½¿ç¨ææåºçåºæ¼éè¨çè©ä¼°æè¡ãéæ§æäºä½¿ç¨é«è§£æåº¦è¡æå½±åå·è¡åè©ä¼° XAI æ¹æ³çé¦æ¬¡åè©¦ã

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨ç­æéå§å·²å¨å¤åé åä¸­å¤§éæ¿å¢ãç¶èï¼ç±æ¼äºå¯¦æ§ãé£è²«æ§åå¹»è¦ºç­åé¡ï¼é«çåä¿å¥é åå°å¶æ¡ç¨ç¶è±«ä¸æ±ºãéæ¼é«çä¿å¥çé«é¢¨éªæ§è³ªï¼è¨±å¤ç ç©¶äººå¡çè³è­¦åä¸è¦ä½¿ç¨å®ï¼ç´å°éäºåé¡å¾å°è§£æ±ºãå¨é«çä¿å¥ä¸­å¯¦æ½åé¨ç½² LLM çééµæ¯ä½¿éäºæ¨¡åå¼å¾ä¿¡è³´ãéæï¼ç¡å¯è½å¤ï¼ä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæè¿°äºå»ºç«å¯é ãå¼å¾ä¿¡è³´åç¡åè¦æ¨¡åçééµè¦ç´ ï¼ä½çºå®åå¨é«çä¿å¥ä¸­å¾å°æ¡ç¨çå¿è¦æ¢ä»¶ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å¨é«çä¿å¥èæ¯ä¸å°å¹»è¦ºé²è¡éåãé©è­åç·©è§£ãæå¾ï¼æåè¨è«äº LLM å¨é«çä¿å¥ä¸­çæªä¾å¯è½æ¯ä»éº¼æ¨£å­ã

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²å¿«éé²æ­¥ï¼ç¾å·²æºåé¨ç½²æ¼å»£æ³çæç¨ç¨å¼ä¸­ï¼ä¾å¦èªä¸»ç³»çµ±ãé«çè¨ºæ·åèªç¶èªè¨èçãåæ©æ¡ç¨ AI æè¡æ¼å¯¦éæç¨ç¨å¼ä¸¦éæ²æåé¡ï¼ç¹å¥æ¯å°æ¼ç¥ç¶ç¶²è·¯ï¼å®å¯è½ä¸ç©©å®ä¸å®¹æåå°å°ææ§ç¯ä¾çå½±é¿ãå¾é·é ä¾çï¼éè¦éç¼é©ç¶çå®å¨ä¿è­æè¡ï¼ä»¥æ¸å°å å¯é¿åçç³»çµ±æéèé æçæ½å¨å·å®³ï¼ä¸¦ç¢ºä¿å¯ä¿¡è³´æ§ãæ¬æèéæ¼èªè­åå¯è§£éæ§ï¼æ¦è¿°äºå·²éç¼ç¨æ¼ç¢ºä¿ AI æ±ºç­å®å¨çæè¡ï¼ä¸¦è¨è«æªä¾çææ°ã


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-07**|**Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**|Yanjun Gao et.al.|[2411.04962v1](http://arxiv.org/abs/2411.04962v1)|null|
|**2024-11-07**|**AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**|Tianyi Zhang et.al.|[2411.04691v1](http://arxiv.org/abs/2411.04691v1)|null|
|**2024-11-07**|**FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**|Liangrui Pan et.al.|[2411.04509v1](http://arxiv.org/abs/2411.04509v1)|null|
|**2024-11-06**|**Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning**|Thomas Frost et.al.|[2411.04285v1](http://arxiv.org/abs/2411.04285v1)|[link](https://github.com/tdgfrost/td-icu-mortality)|
|**2024-11-06**|**Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**|Daniel P. Jeong et.al.|[2411.04118v1](http://arxiv.org/abs/2411.04118v1)|null|
|**2024-11-06**|**RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**|Maya Varma et.al.|[2411.04097v1](http://arxiv.org/abs/2411.04097v1)|[link](https://github.com/stanford-aimi/ravl)|
|**2024-11-06**|**Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**|Bharat Chandra Yalavarthi et.al.|[2411.04008v1](http://arxiv.org/abs/2411.04008v1)|null|
|**2024-11-06**|**Fine-tuning -- a Transfer Learning approach**|Joseph Arul Raj et.al.|[2411.03941v1](http://arxiv.org/abs/2411.03941v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**|Daan Schouten et.al.|[2411.03782v1](http://arxiv.org/abs/2411.03782v1)|null|
|**2024-11-06**|**Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**|Yu Guan et.al.|[2411.03758v1](http://arxiv.org/abs/2411.03758v1)|null|
|**2024-11-06**|**Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?**|Pedro R. A. S. Bassi et.al.|[2411.03670v1](http://arxiv.org/abs/2411.03670v1)|[link](https://github.com/mrgiovanni/touchstone)|
|**2024-11-06**|**Requirements Engineering for Older Adult Digital Health Software: A Systematic Literature Review**|Yuqing Xiao et.al.|[2411.03656v1](http://arxiv.org/abs/2411.03656v1)|null|
|**2024-11-06**|**Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**|Dahyun Mok et.al.|[2411.03618v1](http://arxiv.org/abs/2411.03618v1)|null|
|**2024-11-05**|**The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**|Souren Pashangpour et.al.|[2411.03287v1](http://arxiv.org/abs/2411.03287v1)|null|
|**2024-11-05**|**Discovering Data Structures: Nearest Neighbor Search and Beyond**|Omar Salemohamed et.al.|[2411.03253v1](http://arxiv.org/abs/2411.03253v1)|null|
|**2024-11-05**|**Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care**|Christel Sirocchi et.al.|[2411.03105v1](http://arxiv.org/abs/2411.03105v1)|[link](https://github.com/ChristelSirocchi/XAI-similarity)|
|**2024-11-05**|**Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting**|Adrian B. ChÅopowiec et.al.|[2411.03098v1](http://arxiv.org/abs/2411.03098v1)|null|
|**2024-11-05**|**Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status**|Samuel Lee et.al.|[2411.03004v1](http://arxiv.org/abs/2411.03004v1)|null|
|**2024-11-05**|**Region-Guided Attack on the Segment Anything Model (SAM)**|Xiaoliang Liu et.al.|[2411.02974v1](http://arxiv.org/abs/2411.02974v1)|null|
|**2024-11-05**|**[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI**|Maren Pielka et.al.|[2411.02973v1](http://arxiv.org/abs/2411.02973v1)|null|
|**2024-11-05**|**Membership Inference Attacks against Large Vision-Language Models**|Zhan Li et.al.|[2411.02902v1](http://arxiv.org/abs/2411.02902v1)|[link](https://github.com/lions-epfl/vl-mia)|
|**2024-11-04**|**Advanced XR-Based 6-DOF Catheter Tracking System for Immersive Cardiac Intervention Training**|Mohsen Annabestani et.al.|[2411.02611v1](http://arxiv.org/abs/2411.02611v1)|null|
|**2024-11-04**|**"It's a conversation, not a quiz": A Risk Taxonomy and Reflection Tool for LLM Adoption in Public Health**|Jiawei Zhou et.al.|[2411.02594v1](http://arxiv.org/abs/2411.02594v1)|null|
|**2024-11-04**|**Digitizing Touch with an Artificial Multimodal Fingertip**|Mike Lambeta et.al.|[2411.02479v1](http://arxiv.org/abs/2411.02479v1)|[link](https://github.com/facebookresearch/digit360)|
|**2024-11-04**|**Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**|Shahab Kavousinejad et.al.|[2411.02345v1](http://arxiv.org/abs/2411.02345v1)|[link](https://github.com/shahab-k93/cancer-and-smart-nanorobot)|
|**2024-11-04**|**Taking AI Welfare Seriously**|Robert Long et.al.|[2411.00986v1](http://arxiv.org/abs/2411.00986v1)|null|
|**2024-11-04**|**Federated GNNs for EEG-Based Stroke Assessment**|Andrea Protani et.al.|[2411.02286v1](http://arxiv.org/abs/2411.02286v1)|null|
|**2024-11-04**|**Weakly supervised deep learning model with size constraint for prostate cancer detection in multiparametric MRI and generalization to unseen domains**|Robin Trombetta et.al.|[2411.02466v1](http://arxiv.org/abs/2411.02466v1)|null|
|**2024-11-04**|**Evaluating the quality of published medical research with ChatGPT**|Mike Thelwall et.al.|[2411.01952v1](http://arxiv.org/abs/2411.01952v1)|null|
|**2024-11-04**|**You are out of context!**|Giancarlo Cobino et.al.|[2411.02464v1](http://arxiv.org/abs/2411.02464v1)|null|
|**2024-11-03**|**Diagnosing Medical Datasets with Training Dynamics**|Laura Wenderoth et.al.|[2411.01653v1](http://arxiv.org/abs/2411.01653v1)|[link](https://github.com/laurawenderoth/training-dynamics)|
|**2024-11-03**|**Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**|Zhenbin Wang et.al.|[2411.01647v1](http://arxiv.org/abs/2411.01647v1)|null|
|**2024-11-03**|**Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction**|Haotong Du et.al.|[2411.01535v1](http://arxiv.org/abs/2411.01535v1)|null|
|**2024-11-03**|**Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design**|Onur Boyar et.al.|[2411.01423v1](http://arxiv.org/abs/2411.01423v1)|null|
|**2024-11-02**|**Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization**|Sohrab Namazi Nia et.al.|[2411.01373v1](http://arxiv.org/abs/2411.01373v1)|null|
|**2024-11-02**|**Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles**|Tim Ruschke et.al.|[2411.01351v1](http://arxiv.org/abs/2411.01351v1)|null|
|**2024-11-02**|**Causal reasoning in difference graphs**|Charles K. Assaad et.al.|[2411.01292v1](http://arxiv.org/abs/2411.01292v1)|null|
|**2024-11-02**|**Designing a Robust Radiology Report Generation System**|Sonit Singh et.al.|[2411.01153v1](http://arxiv.org/abs/2411.01153v1)|null|
|**2024-11-02**|**LEARNER: Learning Granular Labels from Coarse Labels using Contrastive Learning**|Gautam Gare et.al.|[2411.01144v1](http://arxiv.org/abs/2411.01144v1)|null|
|**2024-11-02**|**Artificial Intelligence for Microbiology and Microbiome Research**|Xu-Wen Wang et.al.|[2411.01098v1](http://arxiv.org/abs/2411.01098v1)|null|
|**2024-11-01**|**Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities**|Adriel Saporta et.al.|[2411.01053v1](http://arxiv.org/abs/2411.01053v1)|[link](https://github.com/rajesh-lab/symile)|
|**2024-11-01**|**Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading with Cataract**|Fan Xiao et.al.|[2411.00726v1](http://arxiv.org/abs/2411.00726v1)|null|
|**2024-11-01**|**CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis**|Fuying Wang et.al.|[2411.00696v1](http://arxiv.org/abs/2411.00696v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v1](http://arxiv.org/abs/2411.00916v1)|null|
|**2024-11-01**|**Deep learning-based auto-contouring of organs/structures-at-risk for pediatric upper abdominal radiotherapy**|Mianyong Ding et.al.|[2411.00594v1](http://arxiv.org/abs/2411.00594v1)|[link](https://github.com/MMianyong/-PedAbdSeg-)|
|**2024-11-01**|**Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback**|Song Yu et.al.|[2411.00897v1](http://arxiv.org/abs/2411.00897v1)|null|
|**2024-11-01**|**StepCountJITAI: simulation environment for RL with application to physical activity adaptive intervention**|Karine Karine et.al.|[2411.00336v1](http://arxiv.org/abs/2411.00336v1)|null|
|**2024-11-01**|**Strongly Topology-preserving GNNs for Brain Graph Super-resolution**|Pragya Singh et.al.|[2411.02525v1](http://arxiv.org/abs/2411.02525v1)|null|
|**2024-11-01**|**Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**|Balu Bhasuran et.al.|[2411.02523v1](http://arxiv.org/abs/2411.02523v1)|null|
|**2024-10-31**|**Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images**|Arianna Bunnell et.al.|[2411.00891v1](http://arxiv.org/abs/2411.00891v1)|null|
|**2024-10-31**|**Monitoring fairness in machine learning models that predict patient mortality in the ICU**|Tempest A. van Schaik et.al.|[2411.00190v2](http://arxiv.org/abs/2411.00190v2)|null|
|**2024-10-31**|**Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy**|Panagiota Gatoula et.al.|[2411.00178v1](http://arxiv.org/abs/2411.00178v1)|null|
|**2024-10-31**|**Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning**|John Wu et.al.|[2411.00173v1](http://arxiv.org/abs/2411.00173v1)|null|
|**2024-10-31**|**Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks**|Yingzhe Peng et.al.|[2410.24032v1](http://arxiv.org/abs/2410.24032v1)|null|
|**2024-10-31**|**Neural Network Verification with PyRAT**|Augustin Lemesle et.al.|[2410.23903v1](http://arxiv.org/abs/2410.23903v1)|null|
|**2024-10-31**|**Counterfactual MRI Data Augmentation using Conditional Denoising Diffusion Generative Models**|Pedro MorÃ£o et.al.|[2410.23835v1](http://arxiv.org/abs/2410.23835v1)|[link](https://github.com/pedromorao/counterfactual-mri-data-augmentation)|
|**2024-10-31**|**Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding**|Jinlong He et.al.|[2410.23822v1](http://arxiv.org/abs/2410.23822v1)|null|
|**2024-10-31**|**Improving snore detection under limited dataset through harmonic/percussive source separation and convolutional neural networks**|F. D. Gonzalez-Martinez et.al.|[2410.23796v1](http://arxiv.org/abs/2410.23796v1)|null|
|**2024-10-31**|**The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams**|Yunqi Zhu et.al.|[2410.23769v1](http://arxiv.org/abs/2410.23769v1)|null|
|**2024-10-31**|**Artificial intelligence to improve clinical coding practice in Scandinavia: a crossover randomized controlled trial**|Taridzo Chomutare et.al.|[2410.23725v1](http://arxiv.org/abs/2410.23725v1)|null|
|**2024-10-31**|**Enhancing Brain Tumor Classification Using TrAdaBoost and Multi-Classifier Deep Learning Approaches**|Mahin Mohammadi et.al.|[2411.00875v1](http://arxiv.org/abs/2411.00875v1)|null|
|**2024-10-31**|**Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction**|Guan-Hua Huang et.al.|[2410.23649v1](http://arxiv.org/abs/2410.23649v1)|null|
|**2024-10-31**|**MS-Glance: Non-semantic context vectors and the applications in supervising image reconstruction**|Ziqi Gao et.al.|[2410.23577v1](http://arxiv.org/abs/2410.23577v1)|[link](https://github.com/z7gao/msglance)|
|**2024-10-31**|**LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models**|Hieu Tran et.al.|[2410.23526v1](http://arxiv.org/abs/2410.23526v1)|null|
|**2024-10-30**|**Emory Knee Radiograph (MRKR) Dataset**|Brandon Price et.al.|[2411.00866v1](http://arxiv.org/abs/2411.00866v1)|null|
|**2024-10-30**|**STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG**|Raquel FernÃ¡ndez-MartÃ­n et.al.|[2410.23386v1](http://arxiv.org/abs/2410.23386v1)|null|
|**2024-10-30**|**Larger models yield better results? Streamlined severity classification of ADHD-related concerns using BERT-based knowledge distillation**|Ahmed Akib Jawad Karim et.al.|[2411.00052v1](http://arxiv.org/abs/2411.00052v1)|null|
|**2024-10-30**|**DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET**|Yitong Li et.al.|[2410.23219v1](http://arxiv.org/abs/2410.23219v1)|[link](https://github.com/ai-med/diamond)|
|**2024-10-30**|**Variable Resolution Sampling and Deep Learning Image Recovery for Accelerated Multi-Spectral MRI Near Metal Implants**|Azadeh Sharafi et.al.|[2410.23329v1](http://arxiv.org/abs/2410.23329v1)|null|
|**2024-10-30**|**DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection**|Vahideh Hayyolalam et.al.|[2411.00858v1](http://arxiv.org/abs/2411.00858v1)|null|
|**2024-10-30**|**Revisiting MAE pre-training for 3D medical image segmentation**|Tassilo Wald et.al.|[2410.23132v1](http://arxiv.org/abs/2410.23132v1)|null|
|**2024-10-30**|**SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**|Ankita Kumari Jain et.al.|[2410.22950v1](http://arxiv.org/abs/2410.22950v1)|null|
|**2024-10-30**|**Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**|Plabon Paul et.al.|[2410.22619v1](http://arxiv.org/abs/2410.22619v1)|null|
|**2024-10-29**|**Do Large Language Models Align with Core Mental Health Counseling Competencies?**|Viet Cuong Nguyen et.al.|[2410.22446v1](http://arxiv.org/abs/2410.22446v1)|null|
|**2024-10-29**|**MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation**|Ovais Iqbal Shah et.al.|[2410.22223v1](http://arxiv.org/abs/2410.22223v1)|null|
|**2024-10-29**|**Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review**|Muhammad Bilal et.al.|[2410.22180v1](http://arxiv.org/abs/2410.22180v1)|null|
|**2024-10-29**|**Advanced Hybrid Deep Learning Model for Enhanced Classification of Osteosarcoma Histopathology Images**|Arezoo Borji et.al.|[2411.00832v1](http://arxiv.org/abs/2411.00832v1)|null|
|**2024-10-29**|**Unsupervised Training of a Dynamic Context-Aware Deep Denoising Framework for Low-Dose Fluoroscopic Imaging**|Sun-Young Jeon et.al.|[2411.00830v1](http://arxiv.org/abs/2411.00830v1)|null|
|**2024-10-29**|**Coupling quantum-like cognition with the neuronal networks within generalized probability theory**|Andrei Khrennikov et.al.|[2411.00036v1](http://arxiv.org/abs/2411.00036v1)|null|
|**2024-10-29**|**Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning**|Yinyi Lai et.al.|[2410.21872v2](http://arxiv.org/abs/2410.21872v2)|null|
|**2024-10-29**|**How Does Critical Batch Size Scale in Pre-training?**|Hanlin Zhang et.al.|[2410.21676v1](http://arxiv.org/abs/2410.21676v1)|null|
|**2024-10-29**|**A Tutorial on Clinical Speech AI Development: From Data Collection to Model Validation**|Si-Ioi Ng et.al.|[2410.21640v1](http://arxiv.org/abs/2410.21640v1)|null|
|**2024-10-28**|**Can Large Language Models Replace Data Scientists in Clinical Research?**|Zifeng Wang et.al.|[2410.21591v1](http://arxiv.org/abs/2410.21591v1)|null|
|**2024-10-28**|**A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges**|Zifeng Wang et.al.|[2411.00024v1](http://arxiv.org/abs/2411.00024v1)|null|
|**2024-10-28**|**Going Beyond H&E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?**|Amaya Gallagher-Syed et.al.|[2410.21560v1](http://arxiv.org/abs/2410.21560v1)|[link](https://github.com/amayags/immunohistobench)|
|**2024-10-28**|**Towards Multi-dimensional Explanation Alignment for Medical Classification**|Lijie Hu et.al.|[2410.21494v1](http://arxiv.org/abs/2410.21494v1)|null|
|**2024-10-28**|**Multi-modal AI for comprehensive breast cancer prognostication**|Jan Witowski et.al.|[2410.21256v1](http://arxiv.org/abs/2410.21256v1)|null|
|**2024-10-28**|**Belief in the Machine: Investigating Epistemological Blind Spots of Language Models**|Mirac Suzgun et.al.|[2410.21195v1](http://arxiv.org/abs/2410.21195v1)|[link](https://github.com/suzgunmirac/belief-in-the-machine)|
|**2024-10-28**|**Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks**|Jiawei Zhang et.al.|[2410.21175v1](http://arxiv.org/abs/2410.21175v1)|null|
|**2024-10-28**|**Trajectory Flow Matching with Applications to Clinical Time Series Modeling**|Xi Zhang et.al.|[2410.21154v1](http://arxiv.org/abs/2410.21154v1)|[link](https://github.com/nzhangx/trajectoryflowmatching)|
|**2024-10-28**|**Diagnostic Performance of Deep Learning for Predicting Gliomas' IDH and 1p/19q Status in MRI: A Systematic Review and Meta-Analysis**|Somayeh Farahani et.al.|[2411.02426v1](http://arxiv.org/abs/2411.02426v1)|null|
|**2024-10-28**|**Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems**|Helen Schneider et.al.|[2410.21014v1](http://arxiv.org/abs/2410.21014v1)|null|
|**2024-10-28**|**Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering**|Zhilin Zhang et.al.|[2410.21000v1](http://arxiv.org/abs/2410.21000v1)|null|
|**2024-10-28**|**Large Language Model Benchmarks in Medical Tasks**|Lawrence K. Q. Yan et.al.|[2410.21348v1](http://arxiv.org/abs/2410.21348v1)|null|
|**2024-10-28**|**Vascular Segmentation of Functional Ultrasound Images using Deep Learning**|Hana Sebia et.al.|[2410.22365v1](http://arxiv.org/abs/2410.22365v1)|null|
|**2024-10-27**|**Language Models And A Second Opinion Use Case: The Pocket Professional**|David Noever et.al.|[2410.20636v1](http://arxiv.org/abs/2410.20636v1)|null|
|**2024-10-27**|**Improving Decision Sparsity**|Yiyang Sun et.al.|[2410.20483v1](http://arxiv.org/abs/2410.20483v1)|null|
|**2024-10-27**|**MedGo: A Chinese Medical Large Language Model**|Haitao Zhang et.al.|[2410.20428v1](http://arxiv.org/abs/2410.20428v1)|null|
|**2024-10-27**|**Addressing the Pitfalls of Image-Based Structural Health Monitoring: A Focus on False Positives, False Negatives, and Base Rate Bias**|Vagelis Plevris et.al.|[2410.20384v1](http://arxiv.org/abs/2410.20384v1)|null|

#### Abstracts
##### **Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**
2411.04962v1 by Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Guanhua Chen, Anoop Mayampurath, Matthew Churpek, Majid Afshar

Large language models (LLMs) are being explored for diagnostic decision
support, yet their ability to estimate pre-test probabilities, vital for
clinical decision-making, remains limited. This study evaluates two LLMs,
Mistral-7B and Llama3-70B, using structured electronic health record data on
three diagnosis tasks. We examined three current methods of extracting LLM
probability estimations and revealed their limitations. We aim to highlight the
need for improved techniques in LLM confidence estimation.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨è¢«æ¢ç´¢ç¨æ¼è¨ºæ·æ±ºç­æ¯æï¼ä½å®åä¼°è¨è¨åºæ±ºç­å¶å®ä¸­è³ééè¦çé æ¸¬è©¦æ¦ççè½åä»ç¶æéãæ¬ç ç©¶ä½¿ç¨ä¸åè¨ºæ·ä»»åççµæ§åé»å­å¥åº·è¨éæ¸æè©ä¼°äºå©å LLMï¼Mistral-7B å Llama3-70Bãæåæª¢æ¥äºæå LLM æ¦çä¼°è¨çä¸ç¨®ç¶åæ¹æ³ä¸¦æ­ç¤ºäºå®åçå±éæ§ãæåçç®æ¨æ¯å¼·èª¿æ¹é² LLM ç½®ä¿¡åº¦ä¼°è¨æè¡çå¿è¦æ§ã

##### **AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**
2411.04691v1 by Tianyi Zhang, Miu Kojima, Simon D'Alfonso

Smartphones, equipped with an array of sensors, have become valuable tools
for personal sensing. Particularly in digital health, smartphones facilitate
the tracking of health-related behaviors and contexts, contributing
significantly to digital phenotyping, a process where data from digital
interactions is analyzed to infer behaviors and assess mental health.
Traditional methods process raw sensor data into information features for
statistical and machine learning analyses. In this paper, we introduce a novel
approach that systematically converts smartphone-collected data into
structured, chronological narratives. The AWARE Narrator translates
quantitative smartphone sensing data into English language descriptions,
forming comprehensive narratives of an individual's activities. We apply the
framework to the data collected from university students over a week,
demonstrating the potential of utilizing the narratives to summarize individual
behavior, and analyzing psychological states by leveraging large language
models.

æè¦ï¼æºæ§åææ©éåäºåå¼ææ¸¬å¨ï¼å·²æçºåäººææ¸¬çå¯¶è²´å·¥å·ãç¹å¥æ¯å¨æ¸ä½å¥åº·é åï¼æºæ§åææ©ä¿é²äºå¥åº·ç¸éè¡çºåæå¢çè¿½è¹¤ï¼å°æ¸ä½è¡¨ååæååºäºéå¤§è²¢ç»ï¼æ¸ä½è¡¨ååææ¯ä¸ç¨®å¾æ¸ä½äºåä¸­åæè³æä»¥æ¨è«è¡çºåè©ä¼°å¿çå¥åº·çç¨åºãå³çµ±æ¹æ³å°åå§ææ¸¬å¨è³æèçæè³è¨ç¹å¾µï¼ä»¥é²è¡çµ±è¨åæ©å¨å­¸ç¿åæãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³ç³»çµ±æ§å°å°æºæ§åææ©æ¶éçè³æè½ææçµæ§åçæéé åºæäºãAWARE Narrator å°å®éçæºæ§åææ©ææ¸¬è³æè½ææè±æèªè¨æè¿°ï¼å½¢æåäººæ´»åçç¶åæäºãæåå°æ­¤æ¶æ§å¥ç¨å¨å¤§å­¸çä¸é±å§æ¶éçè³æä¸ï¼è­æäºå©ç¨æäºç¸½çµåäººè¡çºçæ½åï¼ä¸¦éééç¨å¤§åèªè¨æ¨¡åä¾åæå¿ççæã

##### **FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**
2411.04509v1 by Liangrui Pan, Mao Huang, Lian Wang, Pinle Qin, Shaoliang Peng

Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is
considered the gold standard for pathologists and medical practitioners for
tumor diagnosis, surgical planning, and post-operative assessment. With the
rapid advancement of deep learning technologies, the development of numerous
models based on convolutional neural networks and transformer-based models has
been applied to the precise segmentation of WSIs. However, due to privacy
regulations and the need to protect patient confidentiality, centralized
storage and processing of image data are impractical. Training a centralized
model directly is challenging to implement in medical settings due to these
privacy concerns.This paper addresses the dispersed nature and privacy
sensitivity of medical image data by employing a federated learning framework,
allowing medical institutions to collaboratively learn while protecting patient
privacy. Additionally, to address the issue of original data reconstruction
through gradient inversion during the federated learning training process,
differential privacy introduces noise into the model updates, preventing
attackers from inferring the contributions of individual samples, thereby
protecting the privacy of the training data.Experimental results show that the
proposed method, FedDP, minimally impacts model accuracy while effectively
safeguarding the privacy of cancer pathology image data, with only a slight
decrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%,
respectively. This approach facilitates cross-institutional collaboration and
knowledge sharing while protecting sensitive data privacy, providing a viable
solution for further research and application in the medical field.

æè¦ï¼èæ¨ç²¾åä¼ç´ï¼H&Eï¼æè²å¨åçååï¼WSIï¼è¢«èªçºæ¯ççå­¸å®¶åé«çå¾æ¥­äººå¡ç¨æ¼è«ç¤è¨ºæ·ãæè¡è¦ååè¡å¾è©ä¼°çé»éæ¨æºãé¨èæ·±åº¦å­¸ç¿æè¡çå¿«éé²å±ï¼åºæ¼å·ç©ç¥ç¶ç¶²è·¯ååºæ¼Transformerçæ¨¡åçç¾å¤æ¨¡åå·²è¢«æç¨æ¼ WSI çç²¾ç¢ºåå²ãç¶èï¼ç±æ¼é±ç§æ³è¦åä¿è­·æ£èæ©å¯æ§çéè¦ï¼éä¸­å¼å²å­åèçå½±åè³ææ¯ä¸åå¯¦éçãç±æ¼éäºé±ç§åé¡ï¼å¨é«çç°å¢ä¸­ç´æ¥è¨ç·´éä¸­å¼æ¨¡åé£ä»¥å¯¦æ½ãæ¬æééæ¡ç¨è¯åå­¸ç¿æ¡æ¶ä¾è§£æ±ºé«çå½±åè³æçåæ£æ§è³ªåé±ç§æææ§ï¼åè¨±é«çæ©æ§å¨ä¿è­·æ£èé±ç§çåæé²è¡åä½å­¸ç¿ãæ­¤å¤ï¼çºäºè§£æ±ºè¯åå­¸ç¿è¨ç·´éç¨ä¸­ééæ¢¯åº¦åè½é²è¡åå§è³æéå»ºçåé¡ï¼å·®åé±ç§æå¨æ¨¡åæ´æ°ä¸­å¼å¥éè¨ï¼é²æ­¢æ»æèæ¨æ·åå¥æ¨£æ¬çè²¢ç»ï¼å¾èä¿è­·è¨ç·´è³æçé±ç§ãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³ FedDP å°æ¨¡åæºç¢ºåº¦çå½±é¿æå°ï¼åæææä¿è­·äºççççå½±åè³æçé±ç§ï¼DiceãJaccard å Acc ææ¸åå¥åç¥å¾®ä¸éäº 0.55%ã0.63% å 0.42%ãéç¨®æ¹æ³ä¿é²äºæ©æ§éçåä½åç¥è­å±äº«ï¼åæä¿è­·äºææè³æçé±ç§ï¼çºé«çé åçé²ä¸æ­¥ç ç©¶åæç¨æä¾äºå¯è¡çè§£æ±ºæ¹æ¡ã

##### **Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning**
2411.04285v1 by Thomas Frost, Kezhi Li, Steve Harris

The task of predicting long-term patient outcomes using supervised machine
learning is a challenging one, in part because of the high variance of each
patient's trajectory, which can result in the model over-fitting to the
training data. Temporal difference (TD) learning, a common reinforcement
learning technique, may reduce variance by generalising learning to the pattern
of state transitions rather than terminal outcomes. However, in healthcare this
method requires several strong assumptions about patient states, and there
appears to be limited literature evaluating the performance of TD learning
against traditional supervised learning methods for long-term health outcome
prediction tasks. In this study, we define a framework for applying TD learning
to real-time irregularly sampled time series data using a Semi-Markov Reward
Process. We evaluate the model framework in predicting intensive care mortality
and show that TD learning under this framework can result in improved model
robustness compared to standard supervised learning methods. and that this
robustness is maintained even when validated on external datasets. This
approach may offer a more reliable method when learning to predict patient
outcomes using high-variance irregular time series data.

æè¦ï¼é æ¸¬é·ææ£èçµæçä»»åä½¿ç¨ç£ç£å¼æ©å¨å­¸ç¿ï¼éæ¯ä¸åå·æææ°æ§çä»»åï¼é¨ååå æ¯æ¯åæ£èçè»è·¡çè®ç°æ§å¾é«ï¼éå¯è½å°è´æ¨¡åéåº¦æ¬åå°è¨ç·´æ¸æãæéå·®å (TD) å­¸ç¿ï¼ä¸ç¨®å¸¸è¦çå¼·åå­¸ç¿æè¡ï¼å¯ä»¥ééå°å­¸ç¿æ¦æ¬çºçæè½ææ¨¡å¼èä¸æ¯çµç«¯çµæä¾æ¸å°è®ç°ãç¶èï¼å¨é«çä¿å¥ä¸­ï¼éç¨®æ¹æ³éè¦å°æ£èçæååºå¹¾åå¼·æåçåè¨­ï¼èä¸ä¼¼ä¹æéçæç»è©ä¼°äº TD å­¸ç¿ç¸å°æ¼å³çµ±ç£ç£å¼å­¸ç¿æ¹æ³å¨é·æå¥åº·çµæé æ¸¬ä»»åä¸­çæ§è½ãå¨éé ç ç©¶ä¸­ï¼æåå®ç¾©äºä¸åæ¡æ¶ï¼ç¨æ¼å° TD å­¸ç¿æç¨æ¼ä½¿ç¨åé¦¬ç¾å¯å¤«çåµéç¨çå¯¦æä¸è¦åæ¡æ¨£æéåºåæ¸æãæåè©ä¼°äºæ¨¡åæ¡æ¶å¨é æ¸¬éçç£è­·æ­»äº¡çä¸­çè¡¨ç¾ï¼ä¸¦è¡¨æå¨éåæ¡æ¶ä¸ç TD å­¸ç¿å¯ä»¥å°è´èæ¨æºç£ç£å¼å­¸ç¿æ¹æ³ç¸æ¯æ¨¡åé­¯æ£æ§å¾å°æ¹åãèä¸éç¨®é­¯æ£æ§å³ä½¿å¨å¤é¨æ¸æéä¸é©è­ä¹è½ä¿æãå¨ä½¿ç¨é«è®ç°ä¸è¦åæéåºåæ¸æå­¸ç¿é æ¸¬æ£èçµææï¼éç¨®æ¹æ³å¯è½ææä¾ä¸ç¨®æ´å¯é çæ¹æ³ã

##### **Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**
2411.04118v1 by Daniel P. Jeong, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare seven
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting regime for medical question-answering (QA) tasks. For instance,
across the tasks and model pairs we consider in the 3-shot setting, medical
LLMs only outperform their base models in 12.1% of cases, reach a (statistical)
tie in 49.8% of cases, and are significantly worse than their base models in
the remaining 38.2% of cases. Our conclusions are based on (i) comparing each
medical model head-to-head, directly against the corresponding base model; (ii)
optimizing the prompts for each model separately; and (iii) accounting for
statistical uncertainty in comparisons. While these basic practices are not
consistently adopted in the literature, our ablations show that they
substantially impact conclusions. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

æè¦ï¼<paragraph>è¿æçå¹¾é ç ç©¶è´åæ¼å°ééå°é«çæç¨éç¼åºç¤æ¨¡åï¼ééå¨å¬éççç©é«å­¸èªæåº«ä¸æçºé è¨ç·´ï¼èª¿æ´éç¨çå¤§åèªè¨æ¨¡å (LLM) åè¦è¦ºèªè¨æ¨¡å (VLM)ãéäºç ç©¶éå¸¸è²ç¨±ï¼éç¨®é åé©ææ§é è¨ç·´ (DAPT) è½æ¹åä¸æ¸¸é«çä»»åçæè½ï¼ä¾å¦åç­é«çå·ç§èè©¦é¡ç®ãå¨æ¬æä¸­ï¼æåæ¯è¼äºä¸åå¬éçãé«çãLLM åå©å VLM èå®åå°æçåºæ¬æ¨¡åï¼ä¸¦å¾åºä¸åççµè«ï¼å¨é«çåé¡åç­ (QA) ä»»åçé¶æ¬¡ï¼å°æ¨£æ¬æç¤ºæ©å¶ä¸­ï¼ææé«ç VLM åå¹¾ä¹ææé«ç LLM é½ç¡æ³æçºåªæ¼å®åçåºæ¬æ¨¡åãä¾å¦ï¼å¨æåå¨ 3 æ¬¡æç¤ºè¨­å®ä¸­èæ®çä»»ååæ¨¡åéå°ä¸­ï¼é«ç LLM åå¨ 12.1% çææ³ä¸åªæ¼å®åçåºæ¬æ¨¡åï¼å¨ 49.8% çææ³ä¸éå°ï¼çµ±è¨ï¼å¹³æï¼èå¨å¶é¤ 38.2% çææ³ä¸é¡¯èä½æ¼å®åçåºæ¬æ¨¡åãæåççµè«åºæ¼ (i) ç´æ¥éå°å°æçåºæ¬æ¨¡åï¼éä¸æ¯è¼æ¯åé«çæ¨¡åï¼(ii) åå¥éå°æ¯åæ¨¡åæä½³åæç¤ºï¼ä»¥å (iii) èæ®æ¯è¼ä¸­ççµ±è¨ä¸ç¢ºå®æ§ãéç¶éäºåºæ¬åæ³ä¸¦æªæçºæ¡ç¨å¨æç»ä¸­ï¼ä½æåçæ¶èç ç©¶è¡¨æï¼å®åæå¤§å¹å½±é¿çµè«ãæåçç ç©¶çµæè¡¨æï¼æåé²çéç¨é åæ¨¡åå¯è½å·²ç¶å±ç¾åºå¼·å¤§çé«çç¥è­åæ¨çè½åï¼ä¸¦æåºå»ºè­°ä»¥å¼·åæªä¾ç ç©¶ççµè«ã</paragraph>

##### **RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**
2411.04097v1 by Maya Varma, Jean-Benoit Delbrouck, Zhihong Chen, Akshay Chaudhari, Curtis Langlotz

Fine-tuned vision-language models (VLMs) often capture spurious correlations
between image features and textual attributes, resulting in degraded zero-shot
performance at test time. Existing approaches for addressing spurious
correlations (i) primarily operate at the global image-level rather than
intervening directly on fine-grained image features and (ii) are predominantly
designed for unimodal settings. In this work, we present RaVL, which takes a
fine-grained perspective on VLM robustness by discovering and mitigating
spurious correlations using local image features rather than operating at the
global image level. Given a fine-tuned VLM, RaVL first discovers spurious
correlations by leveraging a region-level clustering approach to identify
precise image features contributing to zero-shot classification errors. Then,
RaVL mitigates the identified spurious correlation with a novel region-aware
loss function that enables the VLM to focus on relevant regions and ignore
spurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with
various model architectures, data domains, and learned spurious correlations.
Our results show that RaVL accurately discovers (191% improvement over the
closest baseline) and mitigates (8.2% improvement on worst-group image
classification accuracy) spurious correlations. Qualitative evaluations on
general-domain and medical-domain VLMs confirm our findings.

æè¦ï¼å¾®è°çè§è§è¯­è¨æ¨¡åï¼VLMï¼éå¸¸ä¼ææå¾åç¹å¾åææ¬å±æ§ä¹é´çèåç¸å³æ§ï¼å¯¼è´å¨æµè¯æ¶é¶æ ·æ¬æ§è½ä¸éãç°æçè§£å³èåç¸å³æ§çæ¹æ³ï¼iï¼ä¸»è¦å¨å¨å±å¾åçº§å«æä½ï¼èä¸æ¯ç´æ¥å¹²é¢ç»ç²åº¦çå¾åç¹å¾ï¼å¹¶ä¸ï¼iiï¼ä¸»è¦è®¾è®¡ç¨äºåæ¨¡æè®¾ç½®ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäº RaVLï¼å®éè¿ä½¿ç¨å±é¨å¾åç¹å¾èä¸æ¯å¨å¨å±å¾åçº§å«æä½æ¥åç°ååè½»èåç¸å³æ§ï¼ä»èå¯¹ VLM é²æ£æ§éåäºç»ç²åº¦çè§è§ãç»å®ä¸ä¸ªå¾®è°ç VLMï¼RaVL é¦åéè¿å©ç¨åºåçº§èç±»æ¹æ³åç°èåç¸å³æ§ï¼ä»¥è¯å«å¯¼è´é¶æ ·æ¬åç±»éè¯¯çç²¾ç¡®å¾åç¹å¾ãç¶åï¼RaVL ä½¿ç¨ä¸ç§æ°é¢çåºåæç¥æå¤±å½æ°æ¥åè½»å·²è¯å«çèåç¸å³æ§ï¼è¯¥æå¤±å½æ°ä½¿ VLM è½å¤å¨å¾®è°æé´å³æ³¨ç¸å³åºåå¹¶å¿½ç¥èåå³ç³»ãæä»¬ä½¿ç¨ 654 ä¸ª VLM å¯¹ RaVL è¿è¡äºè¯ä¼°ï¼è¿äº VLM å·æåç§æ¨¡åæ¶æãæ°æ®ååå­¦ä¹ å°çèåç¸å³æ§ãæä»¬çç»æè¡¨æï¼RaVL åç¡®å°åç°äºï¼æ¯ææ¥è¿çåºçº¿æé«äº 191%ï¼ååè½»äºï¼å¨æå·®ç»å¾ååç±»åç¡®æ§ä¸æé«äº 8.2%ï¼èåç¸å³æ§ãå¯¹éç¨ååå»å­¦å VLM çå®æ§è¯ä¼°è¯å®äºæä»¬çåç°ã

##### **Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**
2411.04008v1 by Bharat Chandra Yalavarthi, Nalini Ratha

In mission-critical domains such as law enforcement and medical diagnosis,
the ability to explain and interpret the outputs of deep learning models is
crucial for ensuring user trust and supporting informed decision-making.
Despite advancements in explainability, existing methods often fall short in
providing explanations that mirror the depth and clarity of those given by
human experts. Such expert-level explanations are essential for the dependable
application of deep learning models in law enforcement and medical contexts.
Additionally, we recognize that most explanations in real-world scenarios are
communicated primarily through natural language. Addressing these needs, we
propose a novel approach that utilizes characteristic descriptors to explain
model decisions by identifying their presence in images, thereby generating
expert-like explanations. Our method incorporates a concept bottleneck layer
within the model architecture, which calculates the similarity between image
and descriptor encodings to deliver inherent and faithful explanations. Through
experiments in face recognition and chest X-ray diagnosis, we demonstrate that
our approach offers a significant contrast over existing techniques, which are
often limited to the use of saliency maps. We believe our approach represents a
significant step toward making deep learning systems more accountable,
transparent, and trustworthy in the critical domains of face recognition and
medical diagnosis.

æè¦ï¼å¨æ§æ³åå»çè¯æ­ç­ä»»å¡å³é®åé¢åï¼
è§£éåè¯ éæ·±åº¦å­¦ä¹ æ¨¡åçè¾åºå¯¹äºç¡®ä¿ç¨æ·ä¿¡ä»»åæ¯æç¥æå³ç­è³å³éè¦ã
å°½ç®¡å¯è§£éæ§æ¹é¢åå¾äºè¿æ­¥ï¼ä½ç°ææ¹æ³å¨æä¾è§£éæ¶å¾å¾è¾¾ä¸å°äººç±»ä¸å®¶ç»åºçæ·±åº¦åæ¸æ°åº¦ãè¿ç§ä¸å®¶çº§å«çè§£éå¯¹äºå¨æ§æ³åå»çç¯å¢ä¸­å¯é å°åºç¨æ·±åº¦å­¦ä¹ æ¨¡åè³å³éè¦ã
æ­¤å¤ï¼æä»¬è®¤è¯å°ï¼å¨ç°å®ä¸çåºæ¯ä¸­ï¼å¤§å¤æ°è§£éä¸»è¦æ¯éè¿èªç¶è¯­è¨è¿è¡äº¤æµçãä¸ºäºæ»¡è¶³è¿äºéæ±ï¼æä»¬æåºäºä¸ç§æ°é¢çæ¹æ³ï¼è¯¥æ¹æ³å©ç¨ç¹å¾æè¿°ç¬¦éè¿è¯å«å¾åä¸­çç¹å¾æè¿°ç¬¦çå­å¨æ¥è§£éæ¨¡åå³ç­ï¼ä»èçæç±»ä¼¼ä¸å®¶çè§£éãæä»¬çæ¹æ³å¨æ¨¡åæ¶æä¸­å å¥äºä¸ä¸ªæ¦å¿µç¶é¢å±ï¼è¯¥å±è®¡ç®å¾ååæè¿°ç¬¦ç¼ç ä¹é´çç¸ä¼¼æ§ï¼ä»¥æä¾åå¨ä¸å¯é çè§£éãéè¿é¢é¨è¯å«åè¸é¨ X å°çº¿è¯æ­çå®éªï¼æä»¬è¯æäºæä»¬çæ¹æ³ä¸ç°æææ¯ç¸æ¯å·ææ¾çä¼å¿ï¼èç°æææ¯éå¸¸ä»éäºä½¿ç¨æ¾çæ§å¾ãæä»¬ç¸ä¿¡ï¼æä»¬çæ¹æ³ä»£è¡¨äºæçä½¿æ·±åº¦å­¦ä¹ ç³»ç»å¨é¢é¨è¯å«åå»çè¯æ­çå³é®é¢åæ´å è´è´£ãéæåå¼å¾ä¿¡èµè¿åºçéè¦ä¸æ­¥ã

##### **Fine-tuning -- a Transfer Learning approach**
2411.03941v1 by Joseph Arul Raj, Linglong Qian, Zina Ibrahim

Secondary research use of Electronic Health Records (EHRs) is often hampered
by the abundance of missing data in this valuable resource. Missingness in EHRs
occurs naturally as a result of the data recording practices during routine
clinical care, but handling it is crucial to the precision of medical analysis
and the decision-making that follows. The literature contains a variety of
imputation methodologies based on deep neural networks. Those aim to overcome
the dynamic, heterogeneous and multivariate missingness patterns of EHRs, which
cannot be handled by classical and statistical imputation methods. However, all
existing deep imputation methods rely on end-to-end pipelines that incorporate
both imputation and downstream analyses, e.g. classification. This coupling
makes it difficult to assess the quality of imputation and takes away the
flexibility of re-using the imputer for a different task. Furthermore, most
end-to-end deep architectures tend to use complex networks to perform the
downstream task, in addition to the already sophisticated deep imputation
network. We, therefore ask if the high performance reported in the literature
is due to the imputer or the classifier and further ask if an optimised
state-of-the-art imputer is used, a simpler classifier can achieve comparable
performance. This paper explores the development of a modular, deep
learning-based imputation and classification pipeline, specifically built to
leverage the capabilities of state-of-the-art imputation models for downstream
classification tasks. Such a modular approach enables a) objective assessment
of the quality of the imputer and classifier independently, and b) enables the
exploration of the performance of simpler classification architectures using an
optimised imputer.

æè¦ï¼é»å­å¥åº·ç´é (EHR) çäºæ¬¡ç ç©¶ç¨éç¶å¸¸åå°æ­¤å¯¶è²´è³æºä¸­å¤§ééºå¤±è³æçé»ç¤ãEHR ä¸­çéºå¤±è³ææå¨ä¾è¡è¨åºç§è­·æéçè³æè¨éå¯¦åä¸­èªç¶ç¼çï¼ä½èçéºå¤±è³æå°æ¼é«çåæçç²¾ç¢ºåº¦åå¾çºæ±ºç­è³ééè¦ãæç»ä¸­åå«åç¨®åºæ¼æ·±åº¦ç¥ç¶ç¶²è·¯çå§ææ¹æ³ãéäºæ¹æ³æ¨å¨åæ EHR ä¸­åæãç°è³ªä¸å¤è®éçéºå¤±è³ææ¨¡å¼ï¼èéç¡æ³ééå³çµ±åçµ±è¨å§ææ¹æ³ä¾èçãç¶èï¼ææç¾æçæ·±åº¦å§ææ¹æ³é½ä¾è³´æ¼å°å§æåä¸æ¸¸åæï¼ä¾å¦åé¡ï¼çµåå¨ä¸èµ·çç«¯å°ç«¯ç®¡éãéç¨®çµåä½¿å¾é£ä»¥è©ä¼°å§æçåè³ªï¼ä¸¦æ¶é¤äºéæ°ä½¿ç¨å§æå¨é²è¡ä¸åä»»åçéæ´»æ§ãæ­¤å¤ï¼å¤§å¤æ¸ç«¯å°ç«¯æ·±åº¦æ¶æ§å¾åæ¼ä½¿ç¨è¤éçç¶²è·¯ä¾å·è¡ä¸æ¸¸ä»»åï¼é¤äºå·²ç¶å¾è¤éçæ·±åº¦å§æç¶²è·¯ä¹å¤ãå æ­¤ï¼æåè©¢åæç»ä¸­å ±å°çé«æè½æ¯ç±æ¼å§æå¨éæ¯åé¡å¨ï¼ä¸¦é²ä¸æ­¥è©¢åæ¯å¦ä½¿ç¨äºæä½³åçææ°å§æå¨ï¼è¼ç°¡å®çåé¡å¨æ¯å¦å¯ä»¥éå°ç¸è¿çæè½ãæ¬ææ¢è¨æ¨¡çµåãåºæ¼æ·±åº¦å­¸ç¿çå§æååé¡ç®¡éçéç¼ï¼ç¹å¥æ¯å»ºæ§ä¾å©ç¨ææ°å§ææ¨¡åçè½åï¼ä»¥é²è¡ä¸æ¸¸åé¡ä»»åãéç¨®æ¨¡çµåæ¹æ³è½ a) å®¢è§è©ä¼°å§æå¨ååé¡å¨çåè³ªï¼ä»¥å b) è½å¤ ä½¿ç¨æä½³åçå§æå¨ä¾æ¢è¨è¼ç°¡å®åé¡æ¶æ§çæè½ã

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders SÃ¸gaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

æè¦ï¼åç­æ¯èªç¶èªè¨çè§£ä»»åï¼æ¶åå°æç¢ºçä¸ä¸æåæªèªªæçç¸éé åç¥è­é²è¡æ¨çãæ¯æå¤§å¤æ¸ç¶ä»£åç­ç³»çµ±çå¤§åèªè¨æ¨¡å (LLM) é£ä»¥æ¨è«æ¦å¿µå¦ä½å¨é«å­¸ç­å°æ¥­é åä¸­éè¯ãç¾æçé«å­¸ LLM è¨ç·´ææ¬ä¹å¾é«ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº MEGï¼éæ¯ä¸ç¨®ç¨æ¼é«å­¸ç¥è­å¢å¼· LLM çåæ¸æææ¹æ³ãMEG ä½¿ç¨è¼éç´æ å°ç¶²è·¯å°åè¡¨åµå¥æ´åå° LLM ä¸­ï¼ä½¿å¶è½å¤ ä»¥ç¶æ¿ææçæ¹å¼å©ç¨å¤é¨ç¥è­ãæåå¨ååæµè¡çé«å­¸å¤é¸é¡è³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ä¸¦è¡¨æ LLM å¾ç¥è­åè¡¨åµå¥æä¾çå¯¦éä¾æä¸­åçåªæ·ºãMEG å¨ Mistral-Instruct åºæºä¸å¹³åæé«äº +10.2% çæºç¢ºåº¦ï¼å¨ BioMistral ç­å°éæ¨¡åä¸æé«äº +6.7%ãæåéå±ç¤ºäºåºæ¼ Llama-3 ççµæãæå¾ï¼æåè¡¨æ MEG çæ§è½å°åè¡¨ç·¨ç¢¼å¨çé¸æä¿æç©©å¥ã

##### **Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**
2411.03782v1 by Daan Schouten, Giulia Nicoletti, Bas Dille, Catherine Chia, Pierpaolo Vendittelli, Megan Schuurmans, Geert Litjens, Nadieh Khalili

Recent technological advances in healthcare have led to unprecedented growth
in patient data quantity and diversity. While artificial intelligence (AI)
models have shown promising results in analyzing individual data modalities,
there is increasing recognition that models integrating multiple complementary
data sources, so-called multimodal AI, could enhance clinical decision-making.
This scoping review examines the landscape of deep learning-based multimodal AI
applications across the medical domain, analyzing 432 papers published between
2018 and 2024. We provide an extensive overview of multimodal AI development
across different medical disciplines, examining various architectural
approaches, fusion strategies, and common application areas. Our analysis
reveals that multimodal AI models consistently outperform their unimodal
counterparts, with an average improvement of 6.2 percentage points in AUC.
However, several challenges persist, including cross-departmental coordination,
heterogeneous data characteristics, and incomplete datasets. We critically
assess the technical and practical challenges in developing multimodal AI
systems and discuss potential strategies for their clinical implementation,
including a brief overview of commercially available multimodal AI models for
clinical decision-making. Additionally, we identify key factors driving
multimodal AI development and propose recommendations to accelerate the field's
maturation. This review provides researchers and clinicians with a thorough
understanding of the current state, challenges, and future directions of
multimodal AI in medicine.

æè¦ï¼é«çä¿å¥é åçè¿æç§æé²å±å°è´çæ£è³ææ¸éåå¤æ¨£æ§åææªæçæé·ãåç®¡äººå·¥æºæ§ (AI) æ¨¡åå¨åæåå¥è³ææ¨¡å¼ä¸­å±ç¾åºæåéçææï¼ä½æ´åå¤åäºè£è³æä¾æºçæ¨¡åï¼å³æè¬çå¤æ¨¡å¼ AIï¼å¯ä»¥æåè¨åºæ±ºç­å¶å®ï¼éé èªç¥æ­£èæ¥ä¿±å¢ãéç¯ç¯åæ¢è¨åé¡§ç ç©¶æ¢è¨äºæ¶µèé«çé åçæ·±åº¦å­¸ç¿åºç¤å¤æ¨¡å¼ AI æç¨ç¾æ³ï¼åæ 2018 å¹´è³ 2024 å¹´éç¼è¡¨ç 432 ç¯è«æãæåæä¾äºå¤æ¨¡å¼ AI ç¼å±çå»£æ³æ¦è§ï¼æ¶µèä¸åçé«çé åï¼æ¢è¨åç¨®æ¶æ§æ¹æ³ãèåç­ç¥åå¸¸è¦æç¨é åãæåçåæé¡¯ç¤ºï¼å¤æ¨¡å¼ AI æ¨¡åå§çµåªæ¼å¶å®ä¸æ¨¡å¼çå°ææ¨¡åï¼AUC å¹³åæ¹å 6.2 åç¾åé»ãç¶èï¼ä»æè¨±å¤ææ°æçºå­å¨ï¼åæ¬è·¨é¨éåèª¿ãç°è³ªè³æç¹æ§åä¸å®æ´è³æéãæåæ¹å¤æ§å°è©ä¼°éç¼å¤æ¨¡å¼ AI ç³»çµ±å¨æè¡åå¯¦åä¸çææ°ï¼ä¸¦è¨è«å¶è¨åºå¯¦ä½çæ½å¨ç­ç¥ï¼åæ¬å°å¸å®å¤æ¨¡å¼ AI æ¨¡åçç°¡è¦æ¦è¿°ï¼ç¨æ¼è¨åºæ±ºç­å¶å®ãæ­¤å¤ï¼æåæ¾åºæ¨åå¤æ¨¡å¼ AI ç¼å±çä¸»è¦å ç´ ï¼ä¸¦æåºå»ºè­°ä»¥å éè©²é åçæçãæ¬åé¡§ç ç©¶è®ç ç©¶äººå¡åè¨åºé«å¸«æ·±å¥äºè§£å¤æ¨¡å¼ AI å¨é«å­¸é åçç¾æ³ãææ°åæªä¾æ¹åã

##### **Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**
2411.03758v1 by Yu Guan, Qinrong Cai, Wei Li, Qiuyun Fan, Dong Liang, Qiegen Liu

Diffusion model-based approaches recently achieved re-markable success in MRI
reconstruction, but integration into clinical routine remains challenging due
to its time-consuming convergence. This phenomenon is partic-ularly notable
when directly apply conventional diffusion process to k-space data without
considering the inherent properties of k-space sampling, limiting k-space
learning efficiency and image reconstruction quality. To tackle these
challenges, we introduce subspace diffusion model with orthogonal
decomposition, a method (referred to as Sub-DM) that restrict the diffusion
process via projections onto subspace as the k-space data distribution evolves
toward noise. Particularly, the subspace diffusion model circumvents the
inference challenges posed by the com-plex and high-dimensional characteristics
of k-space data, so the highly compact subspace ensures that diffusion process
requires only a few simple iterations to produce accurate prior information.
Furthermore, the orthogonal decomposition strategy based on wavelet transform
hin-ders the information loss during the migration of the vanilla diffusion
process to the subspace. Considering the strate-gy is approximately reversible,
such that the entire pro-cess can be reversed. As a result, it allows the
diffusion processes in different spaces to refine models through a mutual
feedback mechanism, enabling the learning of ac-curate prior even when dealing
with complex k-space data. Comprehensive experiments on different datasets
clearly demonstrate that the superiority of Sub-DM against state of-the-art
methods in terms of reconstruction speed and quality.

æè¦ï¼åºæ¼æ´æ£æ¨¡åçæ¹æ³æè¿å¨ MRI éå»ºä¸­åå¾äºé¡¯èçæåï¼ä½ç±æ¼å¶èæçæ¶ææ§ï¼æ´åå°è¨åºå¸¸è¦ä¸­ä»ç¶å·æææ°æ§ãç¶ç´æ¥å°å³çµ±æ´æ£éç¨æç¨å° k-space è³æï¼èæ²æèæ® k-space åæ¨£çåºæç¹æ§æï¼éç¨®ç¾è±¡å°¤å¶æé¡¯ï¼éå¶äº k-space å­¸ç¿æçåå½±åéå»ºåè³ªãçºäºæå°éäºææ°ï¼æåå¼å¥äºå·ææ­£äº¤åè§£çå­ç©ºéæ´æ£æ¨¡åï¼ä¸ç¨®æ¹æ³ï¼ç¨±çº Sub-DMï¼ï¼å®ééæå½±å°å­ç©ºéä¾éå¶æ´æ£éç¨ï¼å çº k-space è³æåä½ææ¼è®æéè¨ãç¹å¥æ¯ï¼å­ç©ºéæ´æ£æ¨¡åè¿´é¿äº k-space è³æçè¤éåé«ç¶­ç¹å¾µæå¸¶ä¾çæ¨è«ææ°ï¼å æ­¤é«åº¦ç·æ¹çå­ç©ºéç¢ºä¿æ´æ£éç¨åªéè¦å¹¾åç°¡å®çè¿­ä»£å³å¯ç¢çæºç¢ºçåé©è³è¨ãæ­¤å¤ï¼åºæ¼å°æ³¢è½æçæ­£äº¤åè§£ç­ç¥é»ç¤äºé¦èæ´æ£éç¨é·ç§»å°å­ç©ºéæéçè³è¨éºå¤±ãèæ®å°è©²ç­ç¥è¿ä¼¼å¯éï¼å æ­¤æ´åéç¨å¯ä»¥éè½ãå æ­¤ï¼å®åè¨±ä¸åç©ºéä¸­çæ´æ£éç¨ééç¸äºåé¥æ©å¶ä¾åªåæ¨¡åï¼å³ä½¿å¨èçè¤éç k-space è³ææä¹è½å­¸ç¿æºç¢ºçåé©ãå¨ä¸åè³æéä¸çå¨é¢å¯¦é©æ¸æ¥å°è­æäº Sub-DM å¨éå»ºéåº¦ååè³ªæ¹é¢åªæ¼æåé²çæ¹æ³ã

##### **Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?**
2411.03670v1 by Pedro R. A. S. Bassi, Wenxuan Li, Yucheng Tang, Fabian Isensee, Zifu Wang, Jieneng Chen, Yu-Cheng Chou, Yannick Kirchhoff, Maximilian Rokuss, Ziyan Huang, Jin Ye, Junjun He, Tassilo Wald, Constantin Ulrich, Michael Baumgartner, Saikat Roy, Klaus H. Maier-Hein, Paul Jaeger, Yiwen Ye, Yutong Xie, Jianpeng Zhang, Ziyang Chen, Yong Xia, Zhaohu Xing, Lei Zhu, Yousef Sadegheih, Afshin Bozorgpour, Pratibha Kumari, Reza Azad, Dorit Merhof, Pengcheng Shi, Ting Ma, Yuxin Du, Fan Bai, Tiejun Huang, Bo Zhao, Haonan Wang, Xiaomeng Li, Hanxue Gu, Haoyu Dong, Jichen Yang, Maciej A. Mazurowski, Saumya Gupta, Linshan Wu, Jiaxin Zhuang, Hao Chen, Holger Roth, Daguang Xu, Matthew B. Blaschko, Sergio Decherchi, Andrea Cavalli, Alan L. Yuille, Zongwei Zhou

How can we test AI performance? This question seems trivial, but it isn't.
Standard benchmarks often have problems such as in-distribution and small-size
test sets, oversimplified metrics, unfair comparisons, and short-term outcome
pressure. As a consequence, good performance on standard benchmarks does not
guarantee success in real-world scenarios. To address these problems, we
present Touchstone, a large-scale collaborative segmentation benchmark of 9
types of abdominal organs. This benchmark is based on 5,195 training CT scans
from 76 hospitals around the world and 5,903 testing CT scans from 11
additional hospitals. This diverse test set enhances the statistical
significance of benchmark results and rigorously evaluates AI algorithms across
various out-of-distribution scenarios. We invited 14 inventors of 19 AI
algorithms to train their algorithms, while our team, as a third party,
independently evaluated these algorithms on three test sets. In addition, we
also evaluated pre-existing AI frameworks--which, differing from algorithms,
are more flexible and can support different algorithms--including MONAI from
NVIDIA, nnU-Net from DKFZ, and numerous other open-source frameworks. We are
committed to expanding this benchmark to encourage more innovation of AI
algorithms for the medical domain.

æè¦ï¼å¦ä½æ¸¬è©¦ AI æè½ï¼éååé¡çä¼¼ç°¡å®ï¼ä½ä¸¦éå¦æ­¤ã
æ¨æºåºæºç¶å¸¸æè«¸å¦åä½å§åå°åæ¸¬è©¦éãéæ¼ç°¡åçææ¨ãä¸å¬å¹³çæ¯è¼åç­æçµæå£åç­åé¡ãå æ­¤ï¼å¨æ¨æºåºæºä¸çè¯å¥½æè½ç¡æ³ä¿è­å¨å¯¦éææ³ä¸­ä¹è½æåãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº Touchstoneï¼ä¸ç¨®å¤§ååä½åå²åºæºï¼åå« 9 ç¨®é¡åçè¹é¨å¨å®ãæ­¤åºæºåºæ¼ä¾èªå¨ç 76 å®¶é«é¢ç 5,195 åè¨ç·´ CT ææåä¾èª 11 å®¶å¶ä»é«é¢ç 5,903 åæ¸¬è©¦ CT ææãéåå¤æ¨£åçæ¸¬è©¦éå¢å¼·äºåºæºçµæççµ±è¨é¡¯èæ§ï¼ä¸¦å´æ ¼è©ä¼°äºåç¨®åä½å¤ææ³ä¸ç AI æ¼ç®æ³ãæåéè«äº 19 ç¨® AI æ¼ç®æ³ç 14 ä½ç¼æèè¨ç·´ä»åçæ¼ç®æ³ï¼èæåçåéä½çºç¬¬ä¸æ¹ï¼ç¨ç«è©ä¼°äºéäºæ¼ç®æ³å¨ä¸åæ¸¬è©¦éä¸çè¡¨ç¾ãæ­¤å¤ï¼æåéè©ä¼°äºç¾æç AI æ¡æ¶ï¼éäºæ¡æ¶èæ¼ç®æ³ä¸åï¼æ´å·å½æ§ï¼ä¸å¯ä»¥æ¯æ´ä¸åçæ¼ç®æ³ï¼åæ¬ NVIDIA ç MONAIãDKFZ ç nnU-Net åè¨±å¤å¶ä»éæºæ¡æ¶ãæåè´åæ¼æ´å±æ­¤åºæºï¼ä»¥é¼åµæ´å¤ AI æ¼ç®æ³å¨é«çé åçåµæ°ã

##### **Requirements Engineering for Older Adult Digital Health Software: A Systematic Literature Review**
2411.03656v1 by Yuqing Xiao, John Grundy, Anuradha Madugalla

Growth of the older adult population has led to an increasing interest in
technology-supported aged care. However, the area has some challenges such as a
lack of caregivers and limitations in understanding the emotional, social,
physical, and mental well-being needs of seniors. Furthermore, there is a gap
in the understanding between developers and ageing people of their
requirements. Digital health can be important in supporting older adults
wellbeing, emotional requirements, and social needs. Requirements Engineering
(RE) is a major software engineering field, which can help to identify, elicit
and prioritize the requirements of stakeholders and ensure that the systems
meet standards for performance, reliability, and usability. We carried out a
systematic review of the literature on RE for older adult digital health
software. This was necessary to show the representatives of the current stage
of understanding the needs of older adults in aged care digital health. Using
established guidelines outlined by the Kitchenham method, the PRISMA and the
PICO guideline, we developed a protocol, followed by the systematic exploration
of eight databases. This resulted in 69 primary studies of high relevance,
which were subsequently subjected to data extraction, synthesis, and reporting.
We highlight key RE processes in digital health software for ageing people. It
explored the utilization of technology for older user well-being and care, and
the evaluations of such solutions. The review also identified key limitations
found in existing primary studies that inspire future research opportunities.
The results indicate that requirement gathering and understanding have a
significant variation between different studies. The differences are in the
quality, depth, and techniques adopted for requirement gathering and these
differences are largely due to uneven adoption of RE methods.

æè¦ï¼é«é½¡äººå£çå¢é·ï¼å°è´å°ç§æè¼å©é·ç§æåçéæ±èæ¥ä¿±å¢ãç¶èï¼è©²é åä¹é¢è¨ä¸äºææ°ï¼ä¾å¦ç§è­·äººå¡çç­ç¼ºï¼ä»¥åå¨çè§£é·èå¨æç·ãç¤¾äº¤ãççåå¿çæ¹é¢çç¦ç¥éæ±ææå­å¨çéå¶ãæ­¤å¤ï¼éç¼äººå¡åé·èå¨éæ±çè§£ä¸ä¹å­å¨å·®è·ãæ¸ä½å¥åº·å¨æ¯æé·èçç¦ç¥ãæç·éæ±åç¤¾æéæ±æ¹é¢æ®æ¼èéè¦çè§è²ãéæ±å·¥ç¨ï¼REï¼æ¯è»é«å·¥ç¨é åçä¸å¤§é åï¼æå©æ¼è­å¥ãå¼å°ååªåèçå©å®³éä¿äººçéæ±ï¼ä¸¦ç¢ºä¿ç³»çµ±ç¬¦åæè½ãå¯é æ§åå¯ç¨æ§çæ¨æºãæåå°é·èæ¸ä½å¥åº·è»é«çREæç»é²è¡äºç³»çµ±æ§çåé¡§ãéå°æ¼å±ç¾ç®åå¨é·ç§æ¸ä½å¥åº·é åä¸­çè§£é·èéæ±çéæ®µä»£è¡¨æ§æ¯å¿è¦çãæåæ ¹æKitchenhamæ¹æ³ãPRISMAåPICOæåæååºçæ¢å®æºåï¼å¶å®äºä¸å¥åå®ï¼æ¥èç³»çµ±æ§å°æ¢è¨äºå«åè³æåº«ãéç¢çäº69é é«åº¦ç¸éçä¸»è¦ç ç©¶ï¼å¶å¾é²è¡äºè³æèåãç¶åååå ±ãæåéé»ä»ç´¹äºé·èæ¸ä½å¥åº·è»é«ä¸­çééµREæµç¨ãå®æ¢è¨äºç§æå¨é·èä½¿ç¨èç¦ç¥åç§è­·ä¸­çæç¨ï¼ä»¥åéäºè§£æ±ºæ¹æ¡çè©ä¼°ãéä»½åé¡§ä¹æ¾åºäºç¾æä¸»è¦ç ç©¶ä¸­ç¼ç¾çä¸»è¦éå¶ï¼æ¿åµäºæªä¾çç ç©¶æ©æãçµæé¡¯ç¤ºï¼ä¸åç ç©¶ä¹éå¨éæ±æ¶éåçè§£æ¹é¢æé¡¯èçå·®ç°ãå·®ç°å¨æ¼éæ±æ¶éææ¡ç¨çåè³ªãæ·±åº¦åæè¡ï¼èéäºå·®ç°å¨å¾å¤§ç¨åº¦ä¸æ¯ç±æ¼REæ¹æ³æ¡ç¨ä¸åæè´ã

##### **Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**
2411.03618v1 by Dahyun Mok, Junghyun Bum, Le Duc Tai, Hyunseung Choo

Diabetic Retinopathy (DR) is a primary cause of blindness, necessitating
early detection and diagnosis. This paper focuses on referable DR
classification to enhance the applicability of the proposed method in clinical
practice. We develop an advanced cross-learning DR classification method
leveraging transfer learning and cross-attention mechanisms. The proposed
method employs the Swin U-Net architecture to segment lesion maps from DR
fundus images. The Swin U-Net segmentation model, enriched with DR lesion
insights, is transferred to generate a lesion map. Both the fundus image and
its segmented lesion map are used as complementary inputs for the
classification model. A cross-attention mechanism is deployed to improve the
model's ability to capture fine-grained details from the input pairs. Our
experiments, utilizing two public datasets, FGADR and EyePACS, demonstrate a
superior accuracy of 94.6%, surpassing current state-of-the-art methods by
4.4%. To this end, we aim for the proposed method to be seamlessly integrated
into clinical workflows, enhancing accuracy and efficiency in identifying
referable DR.

æè¦ï¼ç³å°¿çè¦ç¶²èçè® (DR) æ¯å¤±æçé¦è¦åå ï¼éè¦æ©ææª¢æ¸¬åè¨ºæ·ãæ¬æéé»éæ³¨å¯è½è¨ºç DR åé¡ï¼ä»¥å¢å¼·ææåºæ¹æ³å¨è¨åºå¯¦åä¸­çé©ç¨æ§ãæåéç¼äºä¸ç¨®åé²çäº¤åå­¸ç¿ DR åé¡æ¹æ³ï¼å©ç¨é·ç§»å­¸ç¿åäº¤åæ³¨ææ©å¶ãææåºçæ¹æ³æ¡ç¨ Swin U-Net æ¶æ§ï¼å¾ DR ç¼åºååä¸­åå²çç¶åãè±å¯äº DR çç¶è¦è§£ç Swin U-Net åå²æ¨¡åè¢«è½ç§»ä»¥çæçç¶åãç¼åºåååå¶åå²ççç¶åé½è¢«ç¨ä½åé¡æ¨¡åçè£åè¼¸å¥ãé¨ç½²äº¤åæ³¨ææ©å¶ä»¥æé«æ¨¡åå¾è¼¸å¥å°ä¸­æ·åç´°ç²åº¦ç´°ç¯çè½åãæåçå¯¦é©å©ç¨äºå©åå¬éæ¸æéï¼FGADR å EyePACSï¼å±ç¤ºäº 94.6% çåªç°æºç¢ºçï¼æ¯ç¶åæåé²çæ¹æ³é«åº 4.4%ãçºæ­¤ï¼æåå¸æææåºçæ¹æ³è½ç¡ç¸«æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼æé«æºç¢ºåº¦åæçï¼ä»¥è­å¥å¯è½è¨ºç DRã

##### **The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**
2411.03287v1 by Souren Pashangpour, Goldie Nejat

The potential use of large language models (LLMs) in healthcare robotics can
help address the significant demand put on healthcare systems around the world
with respect to an aging demographic and a shortage of healthcare
professionals. Even though LLMs have already been integrated into medicine to
assist both clinicians and patients, the integration of LLMs within healthcare
robots has not yet been explored for clinical settings. In this perspective
paper, we investigate the groundbreaking developments in robotics and LLMs to
uniquely identify the needed system requirements for designing health specific
LLM based robots in terms of multi modal communication through human robot
interactions (HRIs), semantic reasoning, and task planning. Furthermore, we
discuss the ethical issues, open challenges, and potential future research
directions for this emerging innovative field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥æ©å¨äººä¸­æ½å¨çæç¨ï¼æå©æ¼æ»¿è¶³å¨çé«çä¿å¥ç³»çµ±å°æèé½¡åäººå£åé«çä¿å¥å°æ¥­äººå¡ç­ç¼ºåé¡çéå¤§éæ±ãåç®¡ LLM å·²æ´åå°é«çé åä¸­ï¼ä»¥åå©è¨åºé«çåæ£èï¼ä½ LLM å¨é«çä¿å¥æ©å¨äººä¸­çæ´åå°æªéå°è¨åºç°å¢é²è¡æ¢è¨ãå¨æ­¤è§é»è«æä¸­ï¼æåæ¢è¨æ©å¨äººå LLM çåµæ°ç¼å±ï¼ä»¥ç¨ç¹å°æ¾åºè¨­è¨ç¹å®æ¼å¥åº·ç LLM æ©å¨äººçç³»çµ±éæ±ï¼åæ¬ééäººæ©äºå (HRI)ãèªç¾©æ¨çåä»»åè¦åçå¤æ¨¡å¼æºéãæ­¤å¤ï¼æåè¨è«äºéåæ°èåµæ°é åçå«çè­°é¡ãéæ¾æ§ææ°åæ½å¨çæªä¾ç ç©¶æ¹åã

##### **Discovering Data Structures: Nearest Neighbor Search and Beyond**
2411.03253v1 by Omar Salemohamed, Laurent Charlin, Shivam Garg, Vatsal Sharan, Gregory Valiant

We propose a general framework for end-to-end learning of data structures.
Our framework adapts to the underlying data distribution and provides
fine-grained control over query and space complexity. Crucially, the data
structure is learned from scratch, and does not require careful initialization
or seeding with candidate data structures/algorithms. We first apply this
framework to the problem of nearest neighbor search. In several settings, we
are able to reverse-engineer the learned data structures and query algorithms.
For 1D nearest neighbor search, the model discovers optimal distribution
(in)dependent algorithms such as binary search and variants of interpolation
search. In higher dimensions, the model learns solutions that resemble k-d
trees in some regimes, while in others, they have elements of
locality-sensitive hashing. The model can also learn useful representations of
high-dimensional data and exploit them to design effective data structures. We
also adapt our framework to the problem of estimating frequencies over a data
stream, and believe it could also be a powerful discovery tool for new
problems.

æè¦ï¼æåæåºä¸åéç¨çæ¶æ§ï¼ç¨æ¼è³æçµæ§çç«¯å°ç«¯å­¸ç¿ã
æåçæ¶æ§æé©æåºç¤è³æåä½ï¼ä¸¦æä¾å°æ¥è©¢åç©ºéè¤éåº¦çç´°ç·»æ§å¶ãè³ééè¦çæ¯ï¼è³æçµæ§æ¯å¾é ­éå§å­¸ç¿ï¼ä¸éè¦ä»ç´°åå§åæä½¿ç¨åé¸è³æçµæ§/æ¼ç®æ³é²è¡è¨­å®ãæåé¦åå°éåæ¶æ§æç¨å°æè¿é°æå°çåé¡ãå¨å¤ç¨®è¨­å®ä¸­ï¼æåè½å¤ éåå·¥ç¨å·²å­¸ç¿çè³æçµæ§åæ¥è©¢æ¼ç®æ³ãå°æ¼ 1D æè¿é°æå°ï¼æ¨¡åæç¼ç¾æä½³åä½ï¼å§é¨ï¼ç¨ç«æ¼ç®æ³ï¼ä¾å¦äºåæå°åå§ææå°è®é«ãå¨æ´é«ç¶­åº¦ä¸­ï¼æ¨¡åå­¸ç¿å°çè§£æå¨æäºæ¨¡å¼ä¸é¡ä¼¼æ¼ k-d æ¨¹ï¼èå¨å¶ä»æ¨¡å¼ä¸ï¼å®åæåå«å±é¨ææéæ¹çåç´ ãè©²æ¨¡åéå¯ä»¥å­¸ç¿é«ç¶­è³æçæç¨è¡¨ç¤ºï¼ä¸¦å©ç¨å®åä¾è¨­è¨ææçè³æçµæ§ãæåä¹å°æåçæ¶æ§èª¿æ´å°è³æä¸²æµä¸é »çä¼°è¨çåé¡ï¼ä¸¦ç¸ä¿¡å®å°æ¼æ°åé¡ä¾èªªä¹å¯è½æ¯ä¸åå¼·å¤§çç¼ç¾å·¥å·ã

##### **Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care**
2411.03105v1 by Christel Sirocchi, Muhammad Suffian, Federico Sabbatini, Alessandro Bogliolo, Sara Montagna

In clinical practice, decision-making relies heavily on established
protocols, often formalised as rules. Concurrently, Machine Learning (ML)
models, trained on clinical data, aspire to integrate into medical
decision-making processes. However, despite the growing number of ML
applications, their adoption into clinical practice remains limited. Two
critical concerns arise, relevant to the notions of consistency and continuity
of care: (a) accuracy - the ML model, albeit more accurate, might introduce
errors that would not have occurred by applying the protocol; (b)
interpretability - ML models operating as black boxes might make predictions
based on relationships that contradict established clinical knowledge. In this
context, the literature suggests using ML models integrating domain knowledge
for improved accuracy and interpretability. However, there is a lack of
appropriate metrics for comparing ML models with clinical rules in addressing
these challenges. Accordingly, in this article, we first propose metrics to
assess the accuracy of ML models with respect to the established protocol.
Secondly, we propose an approach to measure the distance of explanations
provided by two rule sets, with the goal of comparing the explanation
similarity between clinical rule-based systems and rules extracted from ML
models. The approach is validated on the Pima Indians Diabetes dataset by
training two neural networks - one exclusively on data, and the other
integrating a clinical protocol. Our findings demonstrate that the integrated
ML model achieves comparable performance to that of a fully data-driven model
while exhibiting superior accuracy relative to the clinical protocol, ensuring
enhanced continuity of care. Furthermore, we show that our integrated model
provides explanations for predictions that align more closely with the clinical
protocol compared to the data-driven model.

æè¦ï¼<paragraph>å¨è¨åºå¯¦åä¸­ï¼æ±ºç­ä»°è³´æ¢å®çåå®ï¼éå¸¸ä»¥è¦åå½¢å¼åãåæï¼ä»¥è¨åºè³æè¨ç·´çæ©å¨å­¸ç¿ (ML) æ¨¡åï¼æ¸´ææ´åå°é«çæ±ºç­æµç¨ä¸­ãç¶èï¼åç®¡ ML æç¨æ¸éæ¥å¢ï¼å®åå¨è¨åºå¯¦åä¸­çæ¡ç¨ä»åéãå©åééµçæ®æµ®ç¾ï¼èç§è­·çä¸è´æ§åé£çºæ§æ¦å¿µç¸éï¼(a) æºç¢ºæ§ - ML æ¨¡åéç¶æ´æºç¢ºï¼ä½å¯è½æå¼å¥å¥ç¨åå®æä¸æç¼ççé¯èª¤ï¼(b) å¯è§£éæ§ - ä½çºé»çéä½ç ML æ¨¡åå¯è½ææ ¹æèæ¢å®è¨åºç¥è­ç¸çç¾çéä¿é²è¡é æ¸¬ãå¨æ­¤èçµ¡ä¸­ï¼æç»å»ºè­°ä½¿ç¨æ´åé åç¥è­ç ML æ¨¡åä»¥æåæºç¢ºæ§åå¯è§£éæ§ãç¶èï¼ç¼ºä¹é©ç¶çææ¨ä¾æ¯è¼ ML æ¨¡åèè¨åºè¦åï¼ä»¥æå°éäºææ°ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåé¦åæåºææ¨ä¾è©ä¼° ML æ¨¡åç¸å°æ¼æ¢å®åå®çæºç¢ºæ§ãå¶æ¬¡ï¼æåæåºä¸åæ¹æ³ä¾è¡¡éå©çµè¦åææä¾çè§£éçè·é¢ï¼ç®æ¨æ¯æ¯è¼åºæ¼è¨åºè¦åçç³»çµ±èå¾ ML æ¨¡åä¸­æåçè¦åä¹éçè§£éç¸ä¼¼æ§ãæ­¤æ¹æ³å¨ Pima å°å°å®äººç³å°¿çè³æéä¸é©è­ï¼æ¹æ³æ¯è¨ç·´å©åç¥ç¶ç¶²è·¯ - ä¸ååéå°è³æï¼å¦ä¸åæ´åè¨åºåå®ãæåçç ç©¶çµæè­æï¼æ´åå¼ ML æ¨¡åéå°äºèå®å¨è³æé©åæ¨¡åç¸ç¶çæè½ï¼åæå±ç¾åºç¸å°æ¼è¨åºåå®çåªç°æºç¢ºæ§ï¼ç¢ºä¿å¢å¼·çç§è­·é£çºæ§ãæ­¤å¤ï¼æåè­ææåçæ´åæ¨¡åæä¾çé æ¸¬è§£éèè¨åºåå®ç¸æ¯ï¼æ´çºç·å¯å°çµåã</paragraph>

##### **Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting**
2411.03098v1 by Adrian B. ChÅopowiec, Adam R. ChÅopowiec, Krzysztof Galus, Wojciech Cebula, Martin Tabakov

Limited medical imaging datasets challenge deep learning models by increasing
risks of overfitting and reduced generalization, particularly in Generative
Adversarial Networks (GANs), where discriminators may overfit, leading to
training divergence. This constraint also impairs classification models trained
on small datasets. Generative Data Augmentation (GDA) addresses this by
expanding training datasets with synthetic data, although it requires training
a generative model. We propose and evaluate two local lesion generation
approaches to address the challenge of augmenting small medical image datasets.
The first approach employs the Poisson Image Editing algorithm, a classical
image processing technique, to create realistic image composites that
outperform current state-of-the-art methods. The second approach introduces a
novel generative method, leveraging a fine-tuned Image Inpainting GAN to
synthesize realistic lesions within specified regions of real training images.
A comprehensive comparison of the two proposed methods demonstrates that
effective local lesion generation in a data-constrained setting allows for
reaching new state-of-the-art results in capsule endoscopy lesion
classification. Combination of our techniques achieves a macro F1-score of
33.07%, surpassing the previous best result by 7.84 percentage points (p.p.) on
the highly imbalanced Kvasir Capsule Dataset, a benchmark for capsule
endoscopy. To the best of our knowledge, this work is the first to apply a
fine-tuned Image Inpainting GAN for GDA in medical imaging, demonstrating that
an image-conditional GAN can be adapted effectively to limited datasets to
generate high-quality examples, facilitating effective data augmentation.
Additionally, we show that combining this GAN-based approach with classical
image processing techniques further enhances the results.

æè¦ï¼<paragraph>åéçé«å­¸å½±åè³æéæééå¢å éåº¦æ¬åçé¢¨éªåéä½æ¦åè½åï¼ç¹å¥æ¯å¨çæå°æç¶²è·¯ (GAN) ä¸­ï¼å¶ä¸­å¤å¥å¨å¯è½æéåº¦æ¬åï¼å°è´è¨ç·´åæ­§ï¼å°æ·±åº¦å­¸ç¿æ¨¡åæ§æææ°ãéç¨®éå¶ä¹æå®³äºå¨å°åè³æéä¸è¨ç·´çåé¡æ¨¡åãçæè³ææ´å (GDA) ééä½¿ç¨åæè³ææ´åè¨ç·´è³æéä¾è§£æ±ºæ­¤åé¡ï¼åç®¡å®éè¦è¨ç·´çææ¨¡åãæåæåºä¸¦è©ä¼°å©ç¨®å±é¨çç¶çææ¹æ³ï¼ä»¥è§£æ±ºæ´åå°åé«å­¸å½±åè³æéçææ°ãç¬¬ä¸ç¨®æ¹æ³æ¡ç¨æ³æ¾å½±åç·¨è¼¯æ¼ç®æ³ï¼ä¸ç¨®ç¶å¸å½±åèçæè¡ï¼ä¾å»ºç«é¼ççå½±ååæï¼å¶åªæ¼ç®åæåé²çæ¹æ³ãç¬¬äºç¨®æ¹æ³å¼é²ä¸ç¨®æ°ç©ççææ¹æ³ï¼å©ç¨å¾®èª¿çå½±åä¿®å¾© GANï¼å¨çå¯¦è¨ç·´å½±åçç¹å®ååå§åæé¼çççç¶ãå°éå©ç¨®æè­°æ¹æ³çå¨é¢æ¯è¼è­æï¼å¨è³æåéçè¨­å®ä¸­ï¼ææçå±é¨çç¶çæåè¨±å¨è åå§è¦é¡çç¶åé¡ä¸­éå°æ°çæåé²çµæãæåçæè¡çµåå¨é«åº¦ä¸å¹³è¡¡ç Kvasir Capsule è³æéï¼è åå§è¦é¡çåºæºï¼ä¸ï¼éå°äº 33.07% çå·¨è§ F1 åæ¸ï¼æ¯ååçæä½³çµæé«åº 7.84 åç¾åé» (p.p.)ãææåæç¥ï¼éé å·¥ä½æ¯ç¬¬ä¸åå°å¾®èª¿çå½±åä¿®å¾© GAN æç¨æ¼é«å­¸å½±åä¸­ç GDAï¼è­æäºå½±åæ¢ä»¶ GAN å¯ä»¥ææå°é©æåéçè³æéï¼ä»¥ç¢çé«åè³ªçç¯ä¾ï¼ä¿é²ææçè³ææ´åãæ­¤å¤ï¼æåè¡¨æå°éç¨®åºæ¼ GAN çæ¹æ³èç¶å¸å½±åèçæè¡ç¸çµåï¼é²ä¸æ­¥å¢å¼·äºçµæã</paragraph>

##### **Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status**
2411.03004v1 by Samuel Lee, Zach Wood-Doughty

Causal understanding is a fundamental goal of evidence-based medicine. When
randomization is impossible, causal inference methods allow the estimation of
treatment effects from retrospective analysis of observational data. However,
such analyses rely on a number of assumptions, often including that of no
unobserved confounding. In many practical settings, this assumption is violated
when important variables are not explicitly measured in the clinical record.
Prior work has proposed to address unobserved confounding with machine learning
by imputing unobserved variables and then correcting for the classifier's
mismeasurement. When such a classifier can be trained and the necessary
assumptions are met, this method can recover an unbiased estimate of a causal
effect. However, such work has been limited to synthetic data, simple
classifiers, and binary variables. This paper extends this methodology by using
a large language model trained on clinical notes to predict patients' smoking
status, which would otherwise be an unobserved confounder. We then apply a
measurement error correction on the categorical predicted smoking status to
estimate the causal effect of transthoracic echocardiography on mortality in
the MIMIC dataset.

æè¦ï¼å æçè§£æ¯å¾ªè¯å»å­¦çåºæ¬ç®æ ãå½éæºåä¸å¯è¡æ¶ï¼å ææ¨è®ºæ¹æ³åè®¸ä»è§å¯æ§æ°æ®çåé¡¾æ§åæä¸­ä¼°è®¡æ²»çææãç¶èï¼æ­¤ç±»åæä¾èµäºè®¸å¤åè®¾ï¼éå¸¸åæ¬æ²¡ææªè§å¯å°çæ··æå ç´ ãå¨è®¸å¤å®éæåµä¸ï¼å½éè¦çåéå¨ä¸´åºè®°å½ä¸­æ²¡ææç¡®æµéæ¶ï¼è¿ä¸åè®¾å°±ä¼è¢«è¿åãååçå·¥ä½æåºç¨æºå¨å­¦ä¹ æ¥è§£å³æªè§å¯å°çæ··æé®é¢ï¼æ¹æ³æ¯æ¨ç®æªè§å¯å°çåéï¼ç¶åæ ¡æ­£åç±»å¨çæµéè¯¯å·®ãå½å¯ä»¥è®­ç»è¿æ ·çåç±»å¨å¹¶ä¸æ»¡è¶³å¿è¦çåè®¾æ¶ï¼è¿ç§æ¹æ³å¯ä»¥æ¢å¤å ææåºçæ åä¼°è®¡ãç¶èï¼æ­¤ç±»å·¥ä½ä»éäºåææ°æ®ãç®åçåç±»å¨åäºååéãæ¬æéè¿ä½¿ç¨å¨ä¸´åºè®°å½ä¸è®­ç»çå¤§è¯­è¨æ¨¡åæ¥é¢æµæ£èçå¸çç¶åµæ¥æ©å±è¿ç§æ¹æ³ï¼å¦åè¿å°æ¯ä¸ä¸ªæªè§å¯å°çæ··æå ç´ ãç¶åï¼æä»¬å¯¹åç±»é¢æµçå¸çç¶æåºç¨æµéè¯¯å·®æ ¡æ­£ï¼ä»¥ä¼°è®¡ç»è¸è¶å£°å¿å¨å¾å¯¹ MIMIC æ°æ®éä¸­æ­»äº¡ççå ææåºã

##### **Region-Guided Attack on the Segment Anything Model (SAM)**
2411.02974v1 by Xiaoliang Liu, Furao Shen, Jian Zhao

The Segment Anything Model (SAM) is a cornerstone of image segmentation,
demonstrating exceptional performance across various applications, particularly
in autonomous driving and medical imaging, where precise segmentation is
crucial. However, SAM is vulnerable to adversarial attacks that can
significantly impair its functionality through minor input perturbations.
Traditional techniques, such as FGSM and PGD, are often ineffective in
segmentation tasks due to their reliance on global perturbations that overlook
spatial nuances. Recent methods like Attack-SAM-K and UAD have begun to address
these challenges, but they frequently depend on external cues and do not fully
leverage the structural interdependencies within segmentation processes. This
limitation underscores the need for a novel adversarial strategy that exploits
the unique characteristics of segmentation tasks. In response, we introduce the
Region-Guided Attack (RGA), designed specifically for SAM. RGA utilizes a
Region-Guided Map (RGM) to manipulate segmented regions, enabling targeted
perturbations that fragment large segments and expand smaller ones, resulting
in erroneous outputs from SAM. Our experiments demonstrate that RGA achieves
high success rates in both white-box and black-box scenarios, emphasizing the
need for robust defenses against such sophisticated attacks. RGA not only
reveals SAM's vulnerabilities but also lays the groundwork for developing more
resilient defenses against adversarial threats in image segmentation.

æè¦ï¼åæ®µä»»ä½æ¨¡å (SAM) æ¯å½±ååæ®µçåºç³ï¼å¨åç¨®æç¨ä¸­å±ç¾åºè²çæè½ï¼ç¹å¥æ¯å¨èªåé§é§åé«å­¸å½±åä¸­ï¼ç²¾ç¢ºåæ®µè³ééè¦ãç¶èï¼SAM å®¹æåå°å°ææ§æ»æï¼éç¨®æ»ææééå¾®å°çè¼¸å¥æ¾åé¡¯èæå®³å¶åè½ãå³çµ±æè¡ï¼ä¾å¦ FGSM å PGDï¼ç±æ¼ä¾è³´æå¿½ç¥ç©ºéç´°å¾®å·®çå¨å±æ¾åï¼å æ­¤å¨åæ®µä»»åä¸­å¸¸å¸¸ç¡æãæè¿çæ¹æ³ï¼ä¾å¦ Attack-SAM-K å UADï¼å·²éå§è§£æ±ºéäºææ°ï¼ä½å®åç¶å¸¸ä¾è³´å¤é¨æç¤ºï¼ä¸ç¡æ³ååå©ç¨åæ®µéç¨ä¸­çµæ§ä¸çç¸äºä¾è³´æ§ãéç¨®éå¶å¸é¡¯äºéè¦ä¸ç¨®æ°çå°æç­ç¥ï¼ä»¥å©ç¨åæ®µä»»åçç¨ç¹ç¹æ§ãçºäºè§£æ±ºæ­¤åé¡ï¼æåå¼å¥äºå°éçº SAM è¨­è¨çååå¼å°æ»æ (RGA)ãRGA å©ç¨ååå¼å°å°å (RGM) ä¾æä½åæ®µååï¼é²èéå°æ¾åé²è¡èª¿æ´ï¼å°å¤§ååæ®µåæçæ®µï¼ä¸¦æ´å±è¼å°çåæ®µï¼å°è´ SAM ç¢çé¯èª¤è¼¸åºãæåçå¯¦é©è­æï¼RGA å¨ç½çåé»çå ´æ¯ä¸­é½è½éå°é«æåçï¼å¼·èª¿äºéè¦éå°æ­¤é¡è¤éæ»ææ¡åå¼·èæåçé²ç¦¦æªæ½ãRGA ä¸åæ­é²äº SAM çæ¼æ´ï¼ä¹çºå¨å½±ååæ®µä¸­éå°å°ææ§å¨èéç¼æ´å·éæ§çé²ç¦¦æªæ½å¥ å®äºåºç¤ã

##### **[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI**
2411.02973v1 by Maren Pielka, Tobias Schneider, Jan Terheyden, Rafet Sifa

We present an outline of the first large language model (LLM) based chatbot
application in the context of patient-reported outcome measures (PROMs) for
diabetic retinopathy. By utilizing the capabilities of current LLMs, we enable
patients to provide feedback about their quality of life and treatment progress
via an interactive application. The proposed framework offers significant
advantages over the current approach, which encompasses only qualitative
collection of survey data or a static survey with limited answer options. Using
the PROBot LLM-PROM application, patients will be asked tailored questions
about their individual challenges, and can give more detailed feedback on the
progress of their treatment. Based on this input, we will use machine learning
to infer conventional PROM scores, which can be used by clinicians to evaluate
the treatment status. The goal of the application is to improve adherence to
the healthcare system and treatments, and thus ultimately reduce cases of
subsequent vision impairment. The approach needs to be further validated using
a survey and a clinical study.

æè¦ï¼æåæåºä¸ååºæ¼ç¬¬ä¸åå¤§åèªè¨æ¨¡å (LLM) çèå¤©æ©å¨äººæç¨ç¨å¼ï¼ç¨æ¼ç³å°¿çè¦ç¶²èçè®ççäººåå ±çµææ¸¬é (PROM)ãééå©ç¨ç¶å LLM çåè½ï¼æåè®çäººè½å¤ ééäºåå¼æç¨ç¨å¼æä¾æéå¶çæ´»åè³ªåæ²»çé²åº¦çåé¥ãææåºçæ¶æ§æä¾é¡¯èåªæ¼ç®åæ¹æ³çåªé»ï¼ç®åæ¹æ³ååå«èª¿æ¥è³æçè³ªæ§æ¶éæå·ææéç­æ¡é¸é çéæèª¿æ¥ãä½¿ç¨ PROBot LLM-PROM æç¨ç¨å¼ï¼çäººå°æè¢«è©¢åæéå¶åäººææ°çå®¢è£½ååé¡ï¼ä¸¦è½æä¾æ´è©³ç´°çåé¥ï¼èªªæå¶æ²»çé²åº¦ãæ ¹ææ­¤è¼¸å¥ï¼æåå°ä½¿ç¨æ©å¨å­¸ç¿æ¨è«å³çµ± PROM åæ¸ï¼è¨åºé«çå¯ä»¥ä½¿ç¨éäºåæ¸ä¾è©ä¼°æ²»ççæãæ­¤æç¨ç¨å¼çç®æ¨æ¯æ¹åå°é«çä¿å¥ç³»çµ±åæ²»ççä¾å¾æ§ï¼ä¸¦å æ­¤æçµæ¸å°å¾çºè¦åæå®³ççä¾ãéè¦ä½¿ç¨èª¿æ¥åè¨åºç ç©¶é²ä¸æ­¥é©è­æ­¤æ¹æ³ã

##### **Membership Inference Attacks against Large Vision-Language Models**
2411.02902v1 by Zhan Li, Yongtao Wu, Yihang Chen, Francesco Tonin, Elias Abad Rocamora, Volkan Cevher

Large vision-language models (VLLMs) exhibit promising capabilities for
processing multi-modal tasks across various application scenarios. However,
their emergence also raises significant data security concerns, given the
potential inclusion of sensitive information, such as private photos and
medical records, in their training datasets. Detecting inappropriately used
data in VLLMs remains a critical and unresolved issue, mainly due to the lack
of standardized datasets and suitable methodologies. In this study, we
introduce the first membership inference attack (MIA) benchmark tailored for
various VLLMs to facilitate training data detection. Then, we propose a novel
MIA pipeline specifically designed for token-level image detection. Lastly, we
present a new metric called MaxR\'enyi-K%, which is based on the confidence of
the model output and applies to both text and image data. We believe that our
work can deepen the understanding and methodology of MIAs in the context of
VLLMs. Our code and datasets are available at
https://github.com/LIONS-EPFL/VL-MIA.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (VLLM) å¨èçåç¨®æç¨å ´æ¯çå¤æ¨¡æä»»åæ¹é¢è¡¨ç¾åºæåæ¯çè½åãç¶èï¼å®åçåºç¾ä¹å¼ç¼äºéå¤§çè³æå®å¨åé¡ï¼å çºå®åçè¨ç·´è³æéä¸­å¯è½æåå«ææè³è¨ï¼ä¾å¦ç§äººç§çåé«çè¨éãåµæ¸¬ VLLM ä¸­ä¸ç¶ä½¿ç¨çè³æä»ç¶æ¯ä¸åééµä¸å°æªè§£æ±ºçåé¡ï¼ä¸»è¦æ¯ç±æ¼ç¼ºä¹æ¨æºåçè³æéåé©ç¶çæ¹æ³ãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äºç¬¬ä¸åéå°åç¨® VLLM éèº«æé çæå¡æ¨è«æ»æ (MIA) åºæºï¼ä»¥å©æ¼è¨ç·´è³æåµæ¸¬ãç¶å¾ï¼æåæåºäºä¸åå°éè¨­è¨ç¨æ¼ä»¤çç´å¥å½±ååµæ¸¬çå¨æ° MIA ç®¡ç·ãæå¾ï¼æåæåºä¸ååçº MaxR\'enyi-K% çæ°ææ¨ï¼å®åºæ¼æ¨¡åè¼¸åºçä¿¡å¿ï¼ä¸¦é©ç¨æ¼æå­åå½±åè³æãæåç¸ä¿¡ï¼æåçç ç©¶å¯ä»¥å æ·±å° VLLM èæ¯ä¸ MIA ççè§£åæ¹æ³ãæåçç¨å¼ç¢¼åè³æéå¯å¨ https://github.com/LIONS-EPFL/VL-MIA åå¾ã

##### **Advanced XR-Based 6-DOF Catheter Tracking System for Immersive Cardiac Intervention Training**
2411.02611v1 by Mohsen Annabestani, Sandhya Sriram, S. Chiu Wong, Alexandros Sigaras, Bobak Mosadegh

Extended Reality (XR) technologies are gaining traction as effective tools
for medical training and procedural guidance, particularly in complex cardiac
interventions. This paper presents a novel system for real-time 3D tracking and
visualization of intracardiac echocardiography (ICE) catheters, with precise
measurement of the roll angle. A custom 3D-printed setup, featuring orthogonal
cameras, captures biplane video of the catheter, while a specialized computer
vision algorithm reconstructs its 3D trajectory, localizing the tip with
sub-millimeter accuracy and tracking the roll angle in real-time. The system's
data is integrated into an interactive Unity-based environment, rendered
through the Meta Quest 3 XR headset, combining a dynamically tracked catheter
with a patient-specific 3D heart model. This immersive environment allows the
testing of the importance of 3D depth perception, in comparison to 2D
projections, as a form of visualization in XR. Our experimental study,
conducted using the ICE catheter with six participants, suggests that 3D
visualization is not necessarily beneficial over 2D views offered by the XR
system; although all cardiologists saw its utility for pre-operative training,
planning, and intra-operative guidance. The proposed system qualitatively shows
great promise in transforming catheter-based interventions, particularly ICE
procedures, by improving visualization, interactivity, and skill development.

æè¦ï¼æ´å¢å¯¦å¢ (XR) æè¡æ­£ä½çºé«çè¨ç·´åç¨åºæå°çææå·¥å·èç²å¾éè¦ï¼ç¹å¥æ¯å¨è¤éçå¿èä»å¥æ²»çä¸­ãæ¬ææåºäºä¸åæ°çç³»çµ±ï¼ç¨æ¼å¯¦æ 3D è¿½è¹¤åå¯è¦åå¿å§è¶è²å¿åå (ICE) å°ç®¡ï¼ä¸¦ç²¾ç¢ºæ¸¬éæ»¾åè§åº¦ãä¸åå®¢è£½åç 3D åå°è¨­å®ï¼éåæ­£äº¤ç¸æ©ï¼ææå°ç®¡çéå¹³é¢å½±çï¼èä¸åå°éçé»è¦è¦è¦ºæ¼ç®æ³éå»ºå¶ 3D è»è·¡ï¼ä»¥å°æ¼æ¯«ç±³çç²¾ç¢ºåº¦å®ä½å°ç«¯ä¸¦å³æè¿½è¹¤æ»¾åè§åº¦ãç³»çµ±çè³ææ´åå°ä¸åäºåå¼ç Unity çºåºç¤çç°å¢ä¸­ï¼éé Meta Quest 3 XR é ­æ´å¼è£ç½®åç¾ï¼çµååæè¿½è¹¤çå°ç®¡åç¹å®çæ£ç 3D å¿èæ¨¡åãéåæ²æµ¸å¼çç°å¢åè¨±æ¸¬è©¦ 3D æ·±åº¦æç¥çéè¦æ§ï¼è 2D æå½±ç¸æ¯ï¼ä½çº XR ä¸­çä¸ç¨®è¦è¦ºåå½¢å¼ãæåçå¯¦é©ç ç©¶ï¼ä½¿ç¨ ICE å°ç®¡é²è¡ï¼æå­ä½åèèï¼é¡¯ç¤º 3D è¦è¦ºåä¸ä¸å®æ¯ XR ç³»çµ±æä¾ç 2D è¦åæçï¼åç®¡ææå¿èç§é«å¸«é½çå°å®å¨è¡åè¨ç·´ãè¦ååè¡ä¸­æå°ä¸­çç¨éãææåºçç³»çµ±å¨è³ªåä¸é¡¯ç¤ºåºå¨è½æå°ç®¡ä»å¥æ²»çï¼ç¹å¥æ¯ ICE ç¨åºæ¹é¢ï¼ééæ¹åè¦è¦ºåãäºåæ§åæè½ç¼å±ï¼å·æå¾å¤§çåæ¯ã

##### **"It's a conversation, not a quiz": A Risk Taxonomy and Reflection Tool for LLM Adoption in Public Health**
2411.02594v1 by Jiawei Zhou, Amy Z. Chen, Darshi Shah, Laura Schwab Reese, Munmun De Choudhury

Recent breakthroughs in large language models (LLMs) have generated both
interest and concern about their potential adoption as accessible information
sources or communication tools across different domains. In public health --
where stakes are high and impacts extend across populations -- adopting LLMs
poses unique challenges that require thorough evaluation. However, structured
approaches for assessing potential risks in public health remain
under-explored. To address this gap, we conducted focus groups with health
professionals and health issue experiencers to unpack their concerns, situated
across three distinct and critical public health issues that demand
high-quality information: vaccines, opioid use disorder, and intimate partner
violence. We synthesize participants' perspectives into a risk taxonomy,
distinguishing and contextualizing the potential harms LLMs may introduce when
positioned alongside traditional health communication. This taxonomy highlights
four dimensions of risk in individual behaviors, human-centered care,
information ecosystem, and technology accountability. For each dimension, we
discuss specific risks and example reflection questions to help practitioners
adopt a risk-reflexive approach. This work offers a shared vocabulary and
reflection tool for experts in both computing and public health to
collaboratively anticipate, evaluate, and mitigate risks in deciding when to
employ LLM capabilities (or not) and how to mitigate harm when they are used.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´å¼èµ·äºäººåçèè¶£ï¼ä¹å¼èµ·äºäººåå°å¶ä½çºä¸åé åçç¡éç¤ä¿¡æ¯ä¾æºæéä¿¡å·¥å·çæ½å¨æ¡ç¨æç¢ççææãå¨å¬å±è¡çé åââå©å®³éä¿å¾é«ä¸å½±é¿éåäººç¾¤ââæ¡ç¨ LLM æ§æäºç¨ç¹çææ°ï¼éè¦å¾¹åºè©ä¼°ãç¶èï¼è©ä¼°å¬å±è¡çä¸­æ½å¨é¢¨éªççµæ§åæ¹æ³ä»æªå¾å°ååæ¢ç´¢ãçºäºè§£æ±ºéä¸å·®è·ï¼æåèé«çå°æ¥­äººå¡åå¥åº·åé¡é«é©èé²è¡äºç¦é»å°çµï¼ä»¥è§£éä»åççæ®ï¼éäºçæ®æ¶åä¸åä¸åçééµå¬å±è¡çåé¡ï¼éäºåé¡éè¦é«è³ªéçè³è¨ï¼ç«èãé¿çé¡è¥ç©ä½¿ç¨éç¤åè¦ªå¯ä¼´ä¾¶æ´åãæåå°åèèçè§é»ç¶åå°é¢¨éªåé¡æ³ä¸­ï¼åååæå¢å LLM å¨èå³çµ±å¥åº·å³æ­ä¸¦åæå¯è½é æçæ½å¨å±å®³ãéç¨®åé¡æ³çªåºäºåäººè¡çºãä»¥äººçºä¸­å¿çè­·çãè³è¨çæç³»çµ±åæè¡åè²¬å¶éååç¶­åº¦çé¢¨éªãå°æ¼æ¯åç¶­åº¦ï¼æåè¨è«å·é«çé¢¨éªåç¯ä¾åæåé¡ï¼ä»¥å¹«å©å¾æ¥­èæ¡ç¨é¢¨éªåææ¹æ³ãéé å·¥ä½çºè¨ç®åå¬å±è¡çé åçå°å®¶æä¾äºä¸åå±åçè©å½ååæå·¥å·ï¼ä»¥ä¾¿å¨æ±ºå®ä½ææ¡ç¨ LLM åè½ï¼æä¸æ¡ç¨ï¼ä»¥åå¨ä½¿ç¨ LLM åè½æå¦ä½æ¸è¼å±å®³æï¼å±åé æ¸¬ãè©ä¼°åæ¸è¼é¢¨éªã

##### **Digitizing Touch with an Artificial Multimodal Fingertip**
2411.02479v1 by Mike Lambeta, Tingfan Wu, Ali Sengul, Victoria Rose Most, Nolan Black, Kevin Sawyer, Romeo Mercado, Haozhi Qi, Alexander Sohn, Byron Taylor, Norb Tydingco, Gregg Kammerer, Dave Stroud, Jake Khatha, Kurt Jenkins, Kyle Most, Neal Stein, Ricardo Chavira, Thomas Craven-Bartle, Eric Sanchez, Yitian Ding, Jitendra Malik, Roberto Calandra

Touch is a crucial sensing modality that provides rich information about
object properties and interactions with the physical environment. Humans and
robots both benefit from using touch to perceive and interact with the
surrounding environment (Johansson and Flanagan, 2009; Li et al., 2020;
Calandra et al., 2017). However, no existing systems provide rich, multi-modal
digital touch-sensing capabilities through a hemispherical compliant
embodiment. Here, we describe several conceptual and technological innovations
to improve the digitization of touch. These advances are embodied in an
artificial finger-shaped sensor with advanced sensing capabilities.
Significantly, this fingertip contains high-resolution sensors (~8.3 million
taxels) that respond to omnidirectional touch, capture multi-modal signals, and
use on-device artificial intelligence to process the data in real time.
Evaluations show that the artificial fingertip can resolve spatial features as
small as 7 um, sense normal and shear forces with a resolution of 1.01 mN and
1.27 mN, respectively, perceive vibrations up to 10 kHz, sense heat, and even
sense odor. Furthermore, it embeds an on-device AI neural network accelerator
that acts as a peripheral nervous system on a robot and mimics the reflex arc
found in humans. These results demonstrate the possibility of digitizing touch
with superhuman performance. The implications are profound, and we anticipate
potential applications in robotics (industrial, medical, agricultural, and
consumer-level), virtual reality and telepresence, prosthetics, and e-commerce.
Toward digitizing touch at scale, we open-source a modular platform to
facilitate future research on the nature of touch.

æè¦ï¼è§¸è¦ºæ¯ä¸ç¨®è³ééè¦çææ¸¬æ¹å¼ï¼å¯æä¾éæ¼ç©é«å±¬æ§åèç©çç°å¢äº¤äºä½ç¨çè±å¯è³è¨ãäººé¡åæ©å¨äººé½åçæ¼ä½¿ç¨è§¸è¦ºä¾æç¥åèå¨åç°å¢äºåï¼Johansson and Flanagan, 2009; Li et al., 2020; Calandra et al., 2017ï¼ãç¶èï¼æ²æç¾æç³»çµ±ééåçå½¢é ææ§å·èº«åæä¾è±å¯çå¤æ¨¡å¼æ¸ä½è§¸è¦ºææ¸¬åè½ãå¨æ­¤ï¼æåæè¿°äºå¹¾åæ¦å¿µåæè¡åµæ°ï¼ä»¥æ¹åè§¸è¦ºçæ¸ä½åãéäºé²å±é«ç¾å¨å·ååé²ææ¸¬åè½çäººå·¥ææå½¢ææ¸¬å¨ä¸­ãéè¦çæ¯ï¼éåæå°åå«é«è§£æåº¦ææ¸¬å¨ï¼ç´ 830 è¬åè§¸è¦ºé»ï¼ï¼å¯å°å¨æ¹ä½è§¸è¦ºååºåæãæ·åå¤æ¨¡å¼è¨èï¼ä¸¦ä½¿ç¨è£ç½®ä¸çäººå·¥æºæ§å³æèçè³æãè©ä¼°é¡¯ç¤ºï¼äººå·¥æå°å¯ä»¥è§£æå°è³ 7 å¾®ç±³çç©ºéç¹å¾µï¼ä»¥ 1.01 æ¯«çé å 1.27 æ¯«çé çè§£æåº¦ææ¸¬æ³ååååªååï¼æç¥é«é 10 åèµ«çæ¯åãææ¸¬ç±ï¼çè³ææ¸¬æ°£å³ãæ­¤å¤ï¼å®å§åµäºä¸åè£ç½®ä¸ç AI ç¥ç¶ç¶²è·¯å éå¨ï¼ä½çºæ©å¨äººçå¨éç¥ç¶ç³»çµ±ï¼ä¸¦æ¨¡ä»¿äººé¡çåå°å¼§ãéäºçµæè­æäºä»¥è¶äººé¡æè½æ¸ä½åè§¸è¦ºçå¯è½æ§ãå¶å½±é¿æ·±é ï¼æåé æå¨æ©å¨äººæè¡ï¼å·¥æ¥­ãé«çãè¾²æ¥­åæ¶è²»èå±¤ç´ï¼ãèæ¬å¯¦å¢åé è·è¨å ´ãåè¢åé»å­ååä¸­æ½å¨çæç¨ãçºäºå¤§è¦æ¨¡æ¸ä½åè§¸è¦ºï¼æåéæ¾åå§ç¢¼ä¸åæ¨¡çµåå¹³å°ï¼ä»¥ä¿é²æªä¾å°è§¸è¦ºæ¬è³ªçç ç©¶ã

##### **Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**
2411.02345v1 by Shahab Kavousinejad

Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.

æè¦ï¼å¥ç±³æ©å¨äººå¨æ¨é¶è¥ç©å³è¼¸åç¥ç¶ç¾çæ²»çä¸­æ¯ä¸é æåæ¯çç¼å±ï¼ä¸¦å·æç©¿è¶è¡è¦å±é (BBB) çæ½åãéäºå°åè£ç½®å©ç¨å¥ç±³æè¡åçç©å·¥ç¨çé²å±ï¼é²è¡ç²¾ç¢ºå°èªåæ¨é¶ææè¼è·å³è¼¸ï¼ç¹å¥æ¯éå°è¦ç¤ãé¿è²æµ·é»çåå¸éæ£®æ°çç­ç¾çãäººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) çææ°é²å±æ¹åäºå¥ç±³æ©å¨äººçå°èªåæè½ï¼è®å®åè½ééçç©æ¨è¨åæä¾åµæ¸¬åèçç´°èäºåãæ¬ç ç©¶æåºäºä¸åæ°çå¼·åå­¸ç¿ (RL) æ¶æ§ï¼ç¨æ¼æä½³åå¥ç±³æ©å¨äººå¨è¤éçç©ç°å¢ä¸­çå°èªï¼éé»å¨æ¼ééåæå¨åçç©æ¨è¨çæ¿åº¦æ¢¯åº¦ä¾åµæ¸¬çç´°èãæåå©ç¨é»è¦æ¨¡æ¬æ¨¡åä¾æ¢ç´¢å¥ç±³æ©å¨äººå¨ä¸ç¶­ç©ºéä¸­èçç´°èåçç©éç¤ç©ä¹éçè¡çºãææåºçæ¹æ³ä½¿ç¨ Q å­¸ç¿ä¾æ ¹æå³æçç©æ¨è¨æ¿åº¦è³æèª¿æ´ç§»åç­ç¥ï¼è®å¥ç±³æ©å¨äººè½èªä¸»å°èªè³ççµç¹é²è¡æ¨é¶è¥ç©å³è¼¸ãéé ç ç©¶çºæªä¾çå¯¦é©å®¤å¯¦é©åè¨åºæç¨å¥ å®äºåºç¤ï¼ä¸¦å°åäººåé«çåä¾µå¥æ§è¼å°çççæ²»çç¢çå½±é¿ãæ´åæºæ§å¥ç±³æ©å¨äººå¯ä»¥é©æ°æ²»çç­ç¥ï¼æ¸å°å¯ä½ç¨ä¸¦æé«ççæ£èçæ²»çææãé²ä¸æ­¥çç ç©¶å°æ¢è¨éäºæè¡å¨é«çç°å¢ä¸­çå¯¦éé¨ç½²ï¼ç®æ¨æ¯ç¼æ®å¥ç±³æ©å¨äººå¨é«çä¿å¥ä¸­çå¨é¨æ½åã

##### **Taking AI Welfare Seriously**
2411.00986v1 by Robert Long, Jeff Sebo, Patrick Butlin, Kathleen Finlinson, Kyle Fish, Jacqueline Harding, Jacob Pfau, Toni Sims, Jonathan Birch, David Chalmers

In this report, we argue that there is a realistic possibility that some AI
systems will be conscious and/or robustly agentic in the near future. That
means that the prospect of AI welfare and moral patienthood, i.e. of AI systems
with their own interests and moral significance, is no longer an issue only for
sci-fi or the distant future. It is an issue for the near future, and AI
companies and other actors have a responsibility to start taking it seriously.
We also recommend three early steps that AI companies and other actors can
take: They can (1) acknowledge that AI welfare is an important and difficult
issue (and ensure that language model outputs do the same), (2) start assessing
AI systems for evidence of consciousness and robust agency, and (3) prepare
policies and procedures for treating AI systems with an appropriate level of
moral concern. To be clear, our argument in this report is not that AI systems
definitely are, or will be, conscious, robustly agentic, or otherwise morally
significant. Instead, our argument is that there is substantial uncertainty
about these possibilities, and so we need to improve our understanding of AI
welfare and our ability to make wise decisions about this issue. Otherwise
there is a significant risk that we will mishandle decisions about AI welfare,
mistakenly harming AI systems that matter morally and/or mistakenly caring for
AI systems that do not.

æè¦ï¼å¨éä»½å ±åä¸­ï¼æåèªçºæäº AI ç³»çµ±å¨ä¸ä¹çå°ä¾æç¾å¯¦çå¯è½æ§æå·ææè­å/æå¼·å¤§çè½åæ§ãéè¡¨ç¤º AI ç¦å©åéå¾·ä¸ççäººå°ä½çåæ¯ï¼äº¦å³å·æèªèº«å©çåéå¾·æç¾©ç AI ç³»çµ±ï¼ä¸ååªæ¯ç§å¹»å°èªªæéé æªä¾çè­°é¡ãéæ¯è¿æªä¾çè­°é¡ï¼è AI å¬å¸åå¶ä»è¡çºèæè²¬ä»»éå§èªççå¾å®ãæåä¹å»ºè­° AI å¬å¸åå¶ä»è¡çºèå¯ä»¥æ¡åä¸åæ©æçæ­¥é©ï¼ä»åå¯ä»¥ (1) æ¿èª AI ç¦å©æ¯ä¸åéè¦ä¸å°é£çè­°é¡ï¼ä¸¦ç¢ºä¿èªè¨æ¨¡åçè¼¸åºä¹ééº¼åï¼ï¼(2) éå§è©ä¼° AI ç³»çµ±æ¯å¦ææè­åå¼·å¤§è½åæ§çè­æï¼ä»¥å (3) æºåæ¿ç­åç¨åºï¼ä»¥é©ç¶çéå¾·éæ³¨å±¤ç´ä¾å°å¾ AI ç³»çµ±ãæç¢ºä¾èªªï¼æåå¨éä»½å ±åä¸­çè«é»ä¸¦é AI ç³»çµ±çµå°æ¯æå°æå·ææè­ãå¼·å¤§çè½åæ§æå¶ä»éå¾·æç¾©ãç¸åå°ï¼æåçè«é»æ¯éæ¼éäºå¯è½æ§å­å¨èå¯¦è³ªçä¸ç¢ºå®æ§ï¼å æ­¤æåéè¦å¢é²æåå° AI ç¦å©çäºè§£ï¼ä»¥åæåååºéæ¼æ­¤è­°é¡çææºæ±ºå®çè½åãå¦åï¼æåå°é¢è¨éå¤§é¢¨éªï¼é¯èª¤å°èçéæ¼ AI ç¦å©çæ±ºç­ï¼é¯èª¤å°å·å®³å°å¨éå¾·ä¸éè¦ç AI ç³»çµ±ï¼å/æé¯èª¤å°ç§é¡§å°å¨éå¾·ä¸ä¸éè¦ç AI ç³»çµ±ã

##### **Federated GNNs for EEG-Based Stroke Assessment**
2411.02286v1 by Andrea Protani, Lorenzo Giusti, Albert Sund Aillet, Simona Sacco, Paolo Manganotti, Lucio Marinelli, Diogo Reis Santos, Pierpaolo Brutti, Pietro Caliandro, Luigi Serio

Machine learning (ML) has the potential to become an essential tool in
supporting clinical decision-making processes, offering enhanced diagnostic
capabilities and personalized treatment plans. However, outsourcing medical
records to train ML models using patient data raises legal, privacy, and
security concerns. Federated learning has emerged as a promising paradigm for
collaborative ML, meeting healthcare institutions' requirements for robust
models without sharing sensitive data and compromising patient privacy. This
study proposes a novel method that combines federated learning (FL) and Graph
Neural Networks (GNNs) to predict stroke severity using electroencephalography
(EEG) signals across multiple medical institutions. Our approach enables
multiple hospitals to jointly train a shared GNN model on their local EEG data
without exchanging patient information. Specifically, we address a regression
problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a
key indicator of stroke severity. The proposed model leverages a masked
self-attention mechanism to capture salient brain connectivity patterns and
employs EdgeSHAP to provide post-hoc explanations of the neurological states
after a stroke. We evaluated our method on EEG recordings from four
institutions, achieving a mean absolute error (MAE) of 3.23 in predicting
NIHSS, close to the average error made by human experts (MAE $\approx$ 3.0).
This demonstrates the method's effectiveness in providing accurate and
explainable predictions while maintaining data privacy.

æè¦ï¼æ©å¨å­¸ç¿ (ML) ææ½åæçºæ¯æ´è¨åºæ±ºç­å¶å®æµç¨çå¿è¦å·¥å·ï¼æä¾å¢å¼·çè¨ºæ·è½åååäººåæ²»çè¨ç«ãç¶èï¼ä½¿ç¨çæ£è³æè¨ç·´æ©å¨å­¸ç¿æ¨¡åçå¤åé«çç´éå¼ç¼äºæ³å¾ãé±ç§åå®å¨æ¹é¢ççæ®ãè¯åå­¸ç¿å·²æçºåä½æ©å¨å­¸ç¿çä¸ç¨®æåæ¯çå¸ç¯ï¼å®ç¬¦åé«çä¿å¥æ©æ§å°ç©©å¥æ¨¡åçè¦æ±ï¼åæä¸æåäº«ææè³æåå±å®³çæ£é±ç§ãæ¬ç ç©¶æåºäºä¸ç¨®æ°çæ¹æ³ï¼çµåè¯åå­¸ç¿ (FL) ååå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¾ä½¿ç¨è¦é»å (EEG) è¨èé æ¸¬å¤åé«çæ©æ§çè¦ä¸­é¢¨å´éç¨åº¦ãæåçåæ³è®å¤å®¶é«é¢è½å¤ å±åå¨ä»åçæ¬å° EEG è³æä¸è¨ç·´ä¸åå±äº«ç GNN æ¨¡åï¼èç¡éäº¤æçæ£è³è¨ãå·é«ä¾èªªï¼æåééé æ¸¬ç¾ååå®¶è¡çç ç©¶é¢è¦ä¸­é¢¨éè¡¨ (NIHSS) ä¾è§£æ±ºåæ­¸åé¡ï¼NIHSS æ¯è¦ä¸­é¢¨å´éç¨åº¦çä¸åééµææ¨ãææåºçæ¨¡åå©ç¨é®ç½©èªææ³¨ææ©å¶ä¾æ·åé¡¯èçè¦é¨é£çµæ¨¡å¼ï¼ä¸¦æ¡ç¨ EdgeSHAP å¨ä¸­é¢¨å¾æä¾ç¥ç¶çæçäºå¾è§£éãæåå¨ä¾èªåå®¶æ©æ§ç EEG è¨éä¸è©ä¼°äºæåçæ¨¡åï¼å¨é æ¸¬ NIHSS æéå°äº 3.23 çå¹³åçµå°èª¤å·® (MAE)ï¼æ¥è¿äººé¡å°å®¶æç¯çå¹³åèª¤å·® (MAE â 3.0)ãéè­æäºè©²æ¹æ³å¨ç¶­æè³æé±ç§çåæï¼è½æä¾æºç¢ºä¸å¯è§£éçé æ¸¬ï¼é²èå±ç¾å¶æè½ã

##### **Weakly supervised deep learning model with size constraint for prostate cancer detection in multiparametric MRI and generalization to unseen domains**
2411.02466v1 by Robin Trombetta, Olivier RouviÃ¨re, Carole Lartizien

Fully supervised deep models have shown promising performance for many
medical segmentation tasks. Still, the deployment of these tools in clinics is
limited by the very timeconsuming collection of manually expert-annotated data.
Moreover, most of the state-ofthe-art models have been trained and validated on
moderately homogeneous datasets. It is known that deep learning methods are
often greatly degraded by domain or label shifts and are yet to be built in
such a way as to be robust to unseen data or label distributions. In the
clinical setting, this problematic is particularly relevant as the deployment
institutions may have different scanners or acquisition protocols than those
from which the data has been collected to train the model. In this work, we
propose to address these two challenges on the detection of clinically
significant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the
method proposed by (Kervadec et al., 2018), which introduces a size constaint
loss to produce fine semantic cancer lesions segmentations from weak circle
scribbles annotations. Performance of the model is based on two public (PI-CAI
and Prostate158) and one private databases. First, we show that the model
achieves on-par performance with strong fully supervised baseline models, both
on in-distribution validation data and unseen test images. Second, we observe a
performance decrease for both fully supervised and weakly supervised models
when tested on unseen data domains. This confirms the crucial need for
efficient domain adaptation methods if deep learning models are aimed to be
deployed in a clinical environment. Finally, we show that ensemble predictions
from multiple trainings increase generalization performance.

æè¦ï¼<paragraph>å®å¨ç£ç£çæ·±åº¦æ¨¡åå¨è¨±å¤é«çå½±ååå²ä»»åä¸­å±ç¾åºè¯å¥½çæè½ãç¶èï¼éäºå·¥å·å¨è¨åºä¸çé¨ç½²åå°èæçäººå·¥æ¨è¨è³æèééå¶ãæ­¤å¤ï¼å¤§å¤æ¸æåé²çæ¨¡åé½å¨ä¸­ç­åè³ªçè³æéä¸è¨ç·´åé©è­ãç¾æå¨ç¥ï¼æ·±åº¦å­¸ç¿æ¹æ³ç¶å¸¸æå é åææ¨ç±¤è½ç§»èå¤§å¹éä½ï¼èä¸å°æªå»ºæ§åºå°æªè¦è³æææ¨ç±¤åä½å·æç©©å¥æ§çæ¹æ³ãå¨è¨åºç°å¢ä¸­ï¼éååé¡ç¹å¥ç¸éï¼å çºé¨ç½²æ©æ§å¯è½ææèç¨æ¼è¨ç·´æ¨¡åçè³æä¸åçææå¨ææ·ååå®ãå¨éé å·¥ä½ä¸­ï¼æåæè­°éå°å¾éåæ¸ MRI ä¸­åµæ¸¬è¨åºé¡¯èçååèºç (csPCa) ä¾è§£æ±ºéå©åææ°ãæåè©ä¼°ç± (Kervadec ç­äººï¼2018 å¹´) æåºï¼ä¸¦å¼å¥å¤§å°ç´ææå¤±çæ¹æ³ï¼ä»¥å¾å¼±åå½¢å¡é´æ¨è¨»ä¸­ç¢çç²¾ç´°çèªç¾©çççç¶åå²ãæ¨¡åçæè½åºæ¼å©åå¬éè³æåº« (PI-CAI å Prostate158) åä¸åç§äººè³æåº«ãé¦åï¼æåå±ç¤ºè©²æ¨¡åå¨åä½å§é©è­è³æåæªè¦æ¸¬è©¦å½±åä¸é½éå°èå¼·å¤§çå®å¨ç£ç£åºç·æ¨¡ååç­çæè½ãå¶æ¬¡ï¼æåè§å¯å°å¨æªè¦è³æé åä¸æ¸¬è©¦æï¼å®å¨ç£ç£åå¼±ç£ç£æ¨¡åçæè½é½æä¸éãéè­å¯¦äºå°ææé åé©ææ¹æ³çè¿«åéæ±ï¼å¦ææ·±åº¦å­¸ç¿æ¨¡åæ¨å¨é¨ç½²å¨è¨åºç°å¢ä¸­ãæå¾ï¼æåå±ç¤ºä¾èªå¤éè¨ç·´çæ´é«é æ¸¬ææåæ¦åæè½ã</paragraph>

##### **Evaluating the quality of published medical research with ChatGPT**
2411.01952v1 by Mike Thelwall, Xiaorui Jiang, Peter A. Bath

Evaluating the quality of published research is time-consuming but important
for departmental evaluations, appointments, and promotions. Previous research
has shown that ChatGPT can score articles for research quality, with the
results correlating positively with an indicator of quality in all fields
except Clinical Medicine. This article investigates this anomaly with the
largest dataset yet and a more detailed analysis. The results showed that
ChatGPT 4o-mini scores for articles submitted to the UK's Research Excellence
Framework (REF) 2021 Unit of Assessment (UoA) 1 Clinical Medicine correlated
positively (r=0.134, n=9872) with departmental mean REF scores, against a
theoretical maximum correlation of r=0.226 (due to the departmental averaging
involved). At the departmental level, mean ChatGPT scores correlated more
strongly with departmental mean REF scores (r=0.395, n=31). For the 100
journals with the most articles in UoA 1, their mean ChatGPT score correlated
strongly with their REF score (r=0.495) but negatively with their citation rate
(r=-0.148). Journal and departmental anomalies in these results point to
ChatGPT being ineffective at assessing the quality of research in prestigious
medical journals or research directly affecting human health, or both.
Nevertheless, the results give evidence of ChatGPT's ability to assess research
quality overall for Clinical Medicine, so now there is evidence of its ability
in all academic fields.

æè¦ï¼<paragraph>è©ä¼°å·²ç¼è¡¨çåè³ªç ç©¶å¾èæï¼ä½å°æ¼é¨éè©éãä»»å½åæåä¾èªªå¾éè¦ãååçç ç©¶é¡¯ç¤ºï¼ChatGPT å¯ä»¥çºç ç©¶åè³ªè©åï¼å¶çµæèææé åï¼è¨åºé«å­¸é¤å¤ï¼çåè³ªææ¨åæ­£ç¸éãæ¬æä½¿ç¨è¿ä»çºæ­¢æå¤§çè³æéåæ´è©³ç´°çåæä¾æ¢è¨éç¨®ç°å¸¸ç¾è±¡ãçµæé¡¯ç¤ºï¼æäº¤çµ¦è±åç ç©¶åè¶æ¶æ§ (REF) 2021 è©ä¼°å®ä½ (UoA) 1 è¨åºé«å­¸ç ChatGPT 4o-mini åæ¸èé¨éå¹³å REF åæ¸åæ­£ç¸éï¼r=0.134ï¼n=9872ï¼ï¼èçè«æå¤§ç¸éä¿æ¸çº r=0.226ï¼ç±æ¼æ¶åé¨éå¹³åï¼ãå¨é¨éå±¤ç´ï¼å¹³å ChatGPT åæ¸èé¨éå¹³å REF åæ¸ç¸éæ§æ´å¼·ï¼r=0.395ï¼n=31ï¼ãå°æ¼ UoA 1 ä¸­æç« æå¤ç 100 æ¬æåï¼å¶å¹³å ChatGPT åæ¸èå¶ REF åæ¸åå¼·æ­£ç¸éï¼r=0.495ï¼ï¼ä½èå¶å¼ç¨çåè² ç¸éï¼r=-0.148ï¼ãéäºçµæä¸­çæååé¨éç°å¸¸ç¾è±¡è¡¨æï¼ChatGPT ç¡æ³è©ä¼°è²æåèçé«å­¸æåæç´æ¥å½±é¿äººé¡å¥åº·çç ç©¶ï¼æå©èï¼çåè³ªãåç®¡å¦æ­¤ï¼çµæè­æäº ChatGPT æ´é«è©ä¼°è¨åºé«å­¸ç ç©¶åè³ªçè½åï¼å æ­¤ç¾å¨æè­æè­æå¶å¨ææå­¸è¡é åçè½åã</paragraph>

##### **You are out of context!**
2411.02464v1 by Giancarlo Cobino, Simone Farci

This research proposes a novel drift detection methodology for machine
learning (ML) models based on the concept of ''deformation'' in the vector
space representation of data. Recognizing that new data can act as forces
stretching, compressing, or twisting the geometric relationships learned by a
model, we explore various mathematical frameworks to quantify this deformation.
We investigate measures such as eigenvalue analysis of covariance matrices to
capture global shape changes, local density estimation using kernel density
estimation (KDE), and Kullback-Leibler divergence to identify subtle shifts in
data concentration. Additionally, we draw inspiration from continuum mechanics
by proposing a ''strain tensor'' analogy to capture multi-faceted deformations
across different data types. This requires careful estimation of the
displacement field, and we delve into strategies ranging from density-based
approaches to manifold learning and neural network methods. By continuously
monitoring these deformation metrics and correlating them with model
performance, we aim to provide a sensitive, interpretable, and adaptable drift
detection system capable of distinguishing benign data evolution from true
drift, enabling timely interventions and ensuring the reliability of machine
learning systems in dynamic environments. Addressing the computational
challenges of this methodology, we discuss mitigation strategies like
dimensionality reduction, approximate algorithms, and parallelization for
real-time and large-scale applications. The method's effectiveness is
demonstrated through experiments on real-world text data, focusing on detecting
context shifts in Generative AI. Our results, supported by publicly available
code, highlight the benefits of this deformation-based approach in capturing
subtle drifts that traditional statistical methods often miss. Furthermore, we
present a detailed application example within the healthcare domain, showcasing
the methodology's potential in diverse fields. Future work will focus on
further improving computational efficiency and exploring additional
applications across different ML domains.

æè¦ï¼æ¬ç ç©¶æåºä¸åæ°ç©çæ¼ç§»åµæ¸¬æ¹æ³ï¼è©²æ¹æ³éå°æ©å¨å­¸ç¿ (ML) æ¨¡åï¼ä¸¦åºæ¼è³æåéç©ºéè¡¨ç¤ºä¸­çãè®å½¢ãæ¦å¿µãæåäºè§£å°æ°è³æå¯ä»¥ä½çºåéï¼å»¶ä¼¸ãå£ç¸®ææ­æ²æ¨¡åå­¸ç¿å°çå¹¾ä½éä¿ï¼æåæ¢ç´¢åç¨®æ¸å­¸æ¶æ§ä¾éåéç¨®è®å½¢ãæåç ç©¶äºè«¸å¦åæ¹å·®ç©é£çç¹å¾µå¼åæä¾æ·åæ´é«å½¢çè®åãä½¿ç¨æ ¸å¯åº¦ä¼°è¨ (KDE) çå±é¨å¯åº¦ä¼°è¨ï¼ä»¥å Kullback-Leibler è·é¢ä¾è­å¥è³æéä¸­å¾®å¦çåç§»ãæ­¤å¤ï¼æåå¾é£çºåå­¸ä¸­æ±²åéæï¼æåºä¸åãæè®å¼µéãé¡æ¯ä¾æ·åä¸åè³æé¡åä¸­çå¤é¢åè®å½¢ãééè¦ä»ç´°ä¼°è¨ä½ç§»å ´ï¼æåæ·±å¥æ¢è¨å¾åºæ¼å¯åº¦çéå¾å°æµå½¢å­¸ç¿åç¥ç¶ç¶²è·¯æ¹æ³çç­ç¥ãééæçºç£æ§éäºè®å½¢éåº¦ä¸¦å°å®åèæ¨¡åæè½ç¸éè¯ï¼æåæ¨å¨æä¾ä¸åéæãå¯è§£éä¸é©ææ§å¼·çæ¼ç§»åµæ¸¬ç³»çµ±ï¼è½å¤ ååè¯æ§çè³ææ¼ååçæ­£çæ¼ç§»ï¼å¾èå¯¦ç¾åæçå¹²é ä¸¦ç¢ºä¿æ©å¨å­¸ç¿ç³»çµ±å¨åæç°å¢ä¸­çå¯é æ§ãçºäºæå°éç¨®æ¹æ³çè¨ç®ææ°ï¼æåè¨è«äºéç¶­ãè¿ä¼¼æ¼ç®æ³åä¸¦è¡åç­ç·©è§£ç­ç¥ï¼ä»¥ç¨æ¼å³æåå¤§è¦æ¨¡æç¨ãééå¨çå¯¦ä¸çæå­è³æä¸é²è¡å¯¦é©ï¼è­æäºè©²æ¹æ³çæææ§ï¼éé»å¨æ¼åµæ¸¬çæå¼ AI ä¸­çèçµ¡è½ç§»ãæåççµæç±å¬éå¯ç¨çç¨å¼ç¢¼æ¯æ´ï¼çªé¡¯äºéç¨®åºæ¼è®å½¢çéå¾å¨æ·åå³çµ±çµ±è¨æ¹æ³ç¶å¸¸éºæ¼çå¾®å¦æ¼ç§»æ¹é¢çåªé»ãæ­¤å¤ï¼æåå¨é«çä¿å¥é åä¸­å±ç¤ºäºä¸åè©³ç´°çæç¨ç¯ä¾ï¼å±ç¤ºäºè©²æ¹æ³å¨ä¸åé åçæ½åãæªä¾çç ç©¶å°éä¸­å¨é²ä¸æ­¥æé«è¨ç®æçï¼ä¸¦æ¢ç´¢ä¸å ML é åä¸­çå¶ä»æç¨ã

##### **Diagnosing Medical Datasets with Training Dynamics**
2411.01653v1 by Laura Wenderoth

This study explores the potential of using training dynamics as an automated
alternative to human annotation for evaluating the quality of training data.
The framework used is Data Maps, which classifies data points into categories
such as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).
Swayamdipta et al. (2020) highlight that difficult-to-learn examples often
contain errors, and ambiguous cases significantly impact model training. To
confirm the reliability of these findings, we replicated the experiments using
a challenging dataset, with a focus on medical question answering. In addition
to text comprehension, this field requires the acquisition of detailed medical
knowledge, which further complicates the task. A comprehensive evaluation was
conducted to assess the feasibility and transferability of the Data Maps
framework to the medical domain. The evaluation indicates that the framework is
unsuitable for addressing datasets' unique challenges in answering medical
questions.

æè¦ï¼æ¬ç ç©¶æ¢è¨ä½¿ç¨è¨ç·´åæä½çºèªååæ¿ä»£æ¹æ¡ï¼ä»¥è©ä¼°è¨ç·´è³æåè³ªï¼ä»¥åä»£äººå·¥æ¨è¨»ãæä½¿ç¨çæ¶æ§çºè³æå°åï¼å¶å°è³æé»åé¡çºææ¼å­¸ç¿ãé£ä»¥å­¸ç¿åæ¨¡ç¨å©å¯ç­é¡å¥ï¼Swayamdipta ç­äººï¼2020 å¹´ï¼ãSwayamdipta ç­äººï¼2020 å¹´ï¼å¼·èª¿ï¼é£ä»¥å­¸ç¿çç¯ä¾éå¸¸åå«é¯èª¤ï¼èæ¨¡ç¨å©å¯çææ³æå°æ¨¡åè¨ç·´ç¢çéå¤§å½±é¿ãçºäºç¢ºèªéäºç¼ç¾çå¯é æ§ï¼æåä½¿ç¨å·æææ°æ§çè³æéè¤è£½äºå¯¦é©ï¼éé»æ¾å¨é«å­¸åé¡è§£ç­ä¸ãé¤äºæå­çè§£ä¹å¤ï¼éåé åééè¦ç²åè©³ç´°çé«å­¸ç¥è­ï¼éé²ä¸æ­¥ä½¿ä»»åè¤éåãæåé²è¡äºå¨é¢çè©ä¼°ï¼ä»¥è©ä¼°è³æå°åæ¶æ§å¨é«å­¸é åçå¯è¡æ§åå¯è½ç§»æ§ãè©ä¼°çµæè¡¨æï¼è©²æ¶æ§ä¸é©åè§£æ±ºè³æéå¨åç­é«å­¸åé¡æé¢è¨çç¨ç¹ææ°ã

##### **Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**
2411.01647v1 by Zhenbin Wang, Lei Zhang, Lituan Wang, Minjuan Zhu, Zhenwei Zhang

Medical video generation models are expected to have a profound impact on the
healthcare industry, including but not limited to medical education and
training, surgical planning, and simulation. Current video diffusion models
typically build on image diffusion architecture by incorporating temporal
operations (such as 3D convolution and temporal attention). Although this
approach is effective, its oversimplification limits spatio-temporal
performance and consumes substantial computational resources. To counter this,
we propose Medical Simulation Video Generator (MedSora), which incorporates
three key elements: i) a video diffusion framework integrates the advantages of
attention and Mamba, balancing low computational load with high-quality video
generation, ii) an optical flow representation alignment method that implicitly
enhances attention to inter-frame pixels, and iii) a video variational
autoencoder (VAE) with frequency compensation addresses the information loss of
medical features that occurs when transforming pixel space into latent features
and then back to pixel frames. Extensive experiments and applications
demonstrate that MedSora exhibits superior visual quality in generating medical
videos, outperforming the most advanced baseline methods. Further results and
code are available at https://wongzbb.github.io/MedSora

æè¦ï¼é«çå½±ççææ¨¡åé è¨å°å°é«çä¿å¥ç¢æ¥­ç¢çæ·±é çå½±é¿ï¼åæ¬ä½ä¸éæ¼é«å­¸æè²åè¨ç·´ãæè¡è¦ååæ¨¡æ¬ãç®åçå½±çæ´æ£æ¨¡åéå¸¸å»ºç«å¨å½±åæ´æ£æ¶æ§ä¸ï¼ä¸¦çµåæééç®ï¼ä¾å¦ 3D æºç©åæéæ³¨æåï¼ãåç®¡æ­¤æ¹æ³ææï¼ä½å¶éæ¼ç°¡åéå¶äºæç©ºæè½ï¼ä¸¦æ¶èå¤§éçéç®è³æºãçºäºè§£æ±ºéååé¡ï¼æåæåºé«å­¸æ¨¡æ¬å½±ççæå¨ (MedSora)ï¼å®çµåäºä¸åééµè¦ç´ ï¼i) ä¸åå½±çæ´æ£æ¶æ§æ´åäºæ³¨æåå Mamba çåªé»ï¼å¨ä½éç®è² è¼åé«åè³ªå½±ççæä¹éåå¾å¹³è¡¡ï¼ii) ä¸ååæµè¡¨ç¤ºå°é½æ¹æ³ï¼å¯ä»¥é±å«å°å¢å¼·å°å½±æ ¼éåç´ çæ³¨æåï¼ä»¥å iii) ä¸åå·æé »çè£åçå½±çè®ç°èªåç·¨ç¢¼å¨ (VAE)ï¼ç¨æ¼è§£æ±ºå¨å°åç´ ç©ºéè½æçºæ½å¨ç¹å¾µï¼ç¶å¾åè½ååç´ å½±æ ¼æç¼ççé«çç¹å¾µè³è¨éºå¤±åé¡ãå»£æ³çå¯¦é©åæç¨è­æï¼MedSora å¨çæé«çå½±çæ¹é¢å±ç¾åºåªç°çè¦è¦ºåè³ªï¼åªæ¼æåé²çåºæºæ¹æ³ãé²ä¸æ­¥ççµæåç¨å¼ç¢¼å¯ä»¥å¨ https://wongzbb.github.io/MedSora åå¾

##### **Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction**
2411.01535v1 by Haotong Du, Quanming Yao, Juzheng Zhang, Yang Liu, Zhen Wang

Subgraph-based methods have proven to be effective and interpretable in
predicting drug-drug interactions (DDIs), which are essential for medical
practice and drug development. Subgraph selection and encoding are critical
stages in these methods, yet customizing these components remains underexplored
due to the high cost of manual adjustments. In this study, inspired by the
success of neural architecture search (NAS), we propose a method to search for
data-specific components within subgraph-based frameworks. Specifically, we
introduce extensive subgraph selection and encoding spaces that account for the
diverse contexts of drug interactions in DDI prediction. To address the
challenge of large search spaces and high sampling costs, we design a
relaxation mechanism that uses an approximation strategy to efficiently explore
optimal subgraph configurations. This approach allows for robust exploration of
the search space. Extensive experiments demonstrate the effectiveness and
superiority of the proposed method, with the discovered subgraphs and encoding
functions highlighting the model's adaptability.

æè¦ï¼åºæ¼å­åçæ¹æ³å·²è¢«è­æå¨é æ¸¬è¥ç©-è¥ç©äº¤äºä½ç¨ (DDI) ä¸­ææä¸ææ¼è§£éï¼éå°æ¼é«çå¯¦ååè¥ç©éç¼è³ééè¦ãå­åé¸æåç·¨ç¢¼æ¯éäºæ¹æ³ä¸­çééµéæ®µï¼ç¶èï¼ç±æ¼æåèª¿æ´çææ¬é«æï¼å®¢è£½åéäºåä»¶ä»æªè¢«ååæ¢è¨ãå¨æ¬ç ç©¶ä¸­ï¼åå°ç¥ç¶æ¶æ§æå° (NAS) æååç¼ï¼æåæåºä¸åæ¹æ³ä¾æå°å­åæ¶æ§ä¸­çè³æç¹å®åä»¶ãå·é«ä¾èªªï¼æåå¼å¥äºå»£æ³çå­åé¸æåç·¨ç¢¼ç©ºéï¼ä»¥èªªæ DDI é æ¸¬ä¸­è¥ç©äº¤äºä½ç¨çä¸åèæ¯ãçºäºæå°å¤§åæå°ç©ºéåé«åæ¨£ææ¬çææ°ï¼æåè¨­è¨äºä¸åæ¾é¬æ©å¶ï¼ä½¿ç¨è¿ä¼¼ç­ç¥ä¾æææ¢ç´¢æä½³å­åéç½®ãéç¨®æ¹æ³åè¨±å°æå°ç©ºéé²è¡ç©©å¥çæ¢ç´¢ãå»£æ³çå¯¦é©è­æäºææåºæ¹æ³çæææ§ååªè¶æ§ï¼ç¼ç¾çå­ååç·¨ç¢¼å½æ¸çªé¡¯äºæ¨¡åçé©ææ§ã

##### **Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design**
2411.01423v1 by Onur Boyar, Hiroyuki Hanada, Ichiro Takeuchi

The rapid discovery of new chemical compounds is essential for advancing
global health and developing treatments. While generative models show promise
in creating novel molecules, challenges remain in ensuring the real-world
applicability of these molecules and finding such molecules efficiently. To
address this, we introduce Conditional Latent Space Molecular Scaffold
Optimization (CLaSMO), which combines a Conditional Variational Autoencoder
(CVAE) with Latent Space Bayesian Optimization (LSBO) to modify molecules
strategically while maintaining similarity to the original input. Our LSBO
setting improves the sample-efficiency of our optimization, and our
modification approach helps us to obtain molecules with higher chances of
real-world applicability. CLaSMO explores substructures of molecules in a
sample-efficient manner by performing BO in the latent space of a CVAE
conditioned on the atomic environment of the molecule to be optimized. Our
experiments demonstrate that CLaSMO efficiently enhances target properties with
minimal substructure modifications, achieving state-of-the-art results with a
smaller model and dataset compared to existing methods. We also provide an
open-source web application that enables chemical experts to apply CLaSMO in a
Human-in-the-Loop setting.

æè¦ï¼æ°åå­¸ååç©çå¿«éç¼ç¾å°æ¼ä¿é²å¨çå¥åº·åéç¼æ²»çæ¹æ³è³ééè¦ãåç®¡çææ¨¡åå¨åµé æ°åå­æ¹é¢é¡¯ç¤ºåºåæ¯ï¼ä½ä»ç¶å­å¨ææ°ï¼ä»¥ç¢ºä¿éäºåå­çå¯¦éé©ç¨æ§ä¸¦ææå°æ¾å°éäºåå­ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºæ¢ä»¶æ½å¨ç©ºéåå­æ¯æ¶æä½³å (CLaSMO)ï¼å®çµåäºæ¢ä»¶è®ç°èªåç·¨ç¢¼å¨ (CVAE) èæ½å¨ç©ºéè²æ°æä½³å (LSBO)ï¼ä»¥ç­ç¥æ§å°ä¿®æ¹åå­ï¼åæä¿æèåå§è¼¸å¥çç¸ä¼¼æ§ãæåç LSBO è¨­å®æ¹åäºæåæä½³åçæ¨£æ¬æçï¼æåçä¿®æ¹æ¹æ³å¹«å©æåç²å¾å·ææ´é«å¯¦éé©ç¨æ©æçåå­ãCLaSMO ä»¥æ¨£æ¬ææçæ¹å¼æ¢ç´¢åå­çå­çµæ§ï¼æ¹æ³æ¯å¨ CVAE çæ½å¨ç©ºéä¸­å·è¡ BOï¼è©²ç©ºéä»¥è¦æä½³åçåå­çåå­ç°å¢çºæ¢ä»¶ãæåçå¯¦é©è¡¨æï¼CLaSMO ä»¥æå°çå­çµæ§ä¿®æ¹ææå°å¢å¼·äºç®æ¨å±¬æ§ï¼èç¾ææ¹æ³ç¸æ¯ï¼ä½¿ç¨è¼å°çæ¨¡ååæ¸æéå¯¦ç¾äºæåé²ççµæãæåéæä¾äºä¸åéæºç¶²è·¯æç¨ç¨å¼ï¼è®åå­¸å°å®¶è½å¤ å¨äººæ©è¿´åè¨­å®ä¸­æç¨ CLaSMOã

##### **Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization**
2411.01373v1 by Sohrab Namazi Nia, Frank Y. Shih

In medical imaging, accurate diagnosis heavily relies on effective image
enhancement techniques, particularly for X-ray images. Existing methods often
suffer from various challenges such as sacrificing global image characteristics
over local image characteristics or vice versa. In this paper, we present a
novel approach, called G-CLAHE (Global-Contrast Limited Adaptive Histogram
Equalization), which perfectly suits medical imaging with a focus on X-rays.
This method adapts from Global Histogram Equalization (GHE) and Contrast
Limited Adaptive Histogram Equalization (CLAHE) to take both advantages and
avoid weakness to preserve local and global characteristics. Experimental
results show that it can significantly improve current state-of-the-art
algorithms to effectively address their limitations and enhance the contrast
and quality of X-ray images for diagnostic accuracy.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼æºç¢ºçè¨ºæ·é«åº¦ä¾è³´æ¼ææçå½±åå¢å¼·æè¡ï¼ç¹å¥æ¯ X åå½±åãç¾æçæ¹æ³éå¸¸æéå°åç¨®ææ°ï¼ä¾å¦ç§ç²æ´é«å½±åç¹æ§ä»¥æåå±é¨å½±åç¹æ§ï¼åä¹äº¦ç¶ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨±çº G-CLAHEï¼å¨å±å°æ¯åº¦éå¶èªé©æç´æ¹ååè¡¡åï¼ï¼å®éå¸¸é©åæ¼ä»¥ X åçºéé»çé«å­¸å½±åãæ­¤æ¹æ³æ¹ç·¨èªå¨å±ç´æ¹ååè¡¡å (GHE) åå°æ¯åº¦éå¶èªé©æç´æ¹ååè¡¡å (CLAHE)ï¼ä»¥åå¾å©èçåªé»ï¼ä¸¦é¿åå¼±é»ï¼ä»¥ä¿çå±é¨åå¨å±ç¹æ§ãå¯¦é©çµæè¡¨æï¼å®å¯ä»¥é¡¯èæ¹åç¶åæåé²çæ¼ç®æ³ï¼ä»¥ææè§£æ±ºå¶éå¶ï¼ä¸¦å¢å¼· X åå½±åçå°æ¯åº¦ååè³ªï¼ä»¥å©æ¼è¨ºæ·æºç¢ºæ§ã

##### **Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles**
2411.01351v1 by Tim Ruschke, Jonathan Frederik Carlsen, Adam Espe Hansen, Ulrich Lindberg, Amalie Monberg Hindsholm, Martin Norgaard, Claes NÃ¸hr Ladefoged

Deep learning models in medical contexts face challenges like data scarcity,
inhomogeneity, and privacy concerns. This study focuses on improving
ventricular segmentation in brain MRI images using synthetic data. We employed
two latent diffusion models (LDMs): a mask generator trained using 10,000
masks, and a corresponding SPADE image generator optimized using 6,881 scans to
create an MRI conditioned on a 3D brain mask. Conditioning the mask generator
on ventricular volume in combination with classifier-free guidance enabled the
control of the ventricular volume distribution of the generated synthetic
images. Next, the performance of the synthetic data was tested using three
nnU-Net segmentation models trained on a real, augmented and entirely synthetic
data, respectively. The resulting models were tested on a completely
independent hold-out dataset of patients with enlarged ventricles, with manual
delineation of the ventricles used as ground truth. The model trained on real
data showed a mean absolute error (MAE) of 9.09 \pm 12.18 mL in predicted
ventricular volume, while the models trained on synthetic and augmented data
showed MAEs of 7.52 \pm 4.81 mL and 6.23 \pm 4.33 mL, respectively. Both the
synthetic and augmented model also outperformed the state-of-the-art model
SynthSeg, which due to limited performance in cases of large ventricular
volumes, showed an MAE of 7.73 \pm 12.12 mL with a factor of 3 higher standard
deviation. The model trained on augmented data showed the highest Dice score of
0.892 \pm 0.05, slightly outperforming SynthSeg and on par with the model
trained on real data. The synthetic model performed similar to SynthSeg. In
summary, we provide evidence that guided synthesis of labeled brain MRI data
using LDMs improves the segmentation of enlarged ventricles and outperforms
existing state-of-the-art segmentation models.

æè¦ï¼<paragraph>å¨å»å­¦èæ¯ä¸­ï¼æ·±åº¦å­¦ä¹ æ¨¡åé¢ä¸´çæ°æ®ç¨ç¼ºæ§ãä¸ååæ§åéç§é®é¢ç­ææãæ¬ç ç©¶ä¸æ³¨äºä½¿ç¨åææ°æ®æ¹è¿èé¨ MRI å¾åä¸­çå¿å®¤åå²ãæä»¬éç¨äºä¸¤ä¸ªæ½å¨æ©æ£æ¨¡å (LDM)ï¼ä¸ä¸ªä½¿ç¨ 10,000 ä¸ªèçè®­ç»çèççæå¨ï¼ä»¥åä¸ä¸ªä½¿ç¨ 6,881 æ¬¡æ«æè¿è¡ä¼åçç¸åº SPADE å¾åçæå¨ï¼ä»¥åå»ºåºäº 3D èé¨èçç MRIãå¯¹èççæå¨è¿è¡å¿å®¤ä½ç§¯è°èï¼å¹¶ç»åæ åç±»å¨æå¯¼ï¼è½å¤æ§å¶çæåæå¾åçå¿å®¤ä½ç§¯åå¸ãæ¥ä¸æ¥ï¼ä½¿ç¨åå«è®­ç»äºçå®ãå¢å¼ºåå®å¨åææ°æ®ä¸çä¸ä¸ª nnU-Net åå²æ¨¡åæµè¯äºåææ°æ®çæ§è½ãå°è®­ç»æå¾çæ¨¡åå¨å®å¨ç¬ç«çãå·ææ©å¤§å¿å®¤çæ£èçä¿çæ°æ®éä¸è¿è¡æµè¯ï¼å¹¶ä½¿ç¨å¿å®¤çæå¨æç»ä½ä¸ºçå®æåµãå¨çå®æ°æ®ä¸è®­ç»çæ¨¡åå¨é¢æµçå¿å®¤ä½ç§¯ä¸­æ¾ç¤ºåº 9.09 Â± 12.18 mL çå¹³åç»å¯¹è¯¯å·® (MAE)ï¼èå¨åæåå¢å¼ºæ°æ®ä¸è®­ç»çæ¨¡åæ¾ç¤ºåº 7.52 Â± 4.81 mL å 6.23 Â± 4.33 mL ç MAEãåææ¨¡ååå¢å¼ºæ¨¡åçæ§è½åä¼äºæåè¿çæ¨¡å SynthSegï¼åèç±äºå¨å¤§å¿å®¤ä½ç§¯çæåµä¸æ§è½æéï¼æ¾ç¤ºåº 7.73 Â± 12.12 mL ç MAEï¼æ åå·®é«åº 3 åãå¨å¢å¼ºæ°æ®ä¸è®­ç»çæ¨¡åæ¾ç¤ºåºæé«ç Dice å¾å 0.892 Â± 0.05ï¼ç¥ä¼äº SynthSegï¼å¹¶ä¸ä¸å¨çå®æ°æ®ä¸è®­ç»çæ¨¡åç¸å½ãåææ¨¡åçæ§è½ä¸ SynthSeg ç±»ä¼¼ãæ»ä¹ï¼æä»¬æä¾äºè¯æ®è¡¨æï¼ä½¿ç¨ LDM å¯¹æ è®°çèé¨ MRI æ°æ®è¿è¡å¼å¯¼åæå¯ä»¥æ¹åæ©å¤§å¿å®¤çåå²ï¼å¹¶ä¸ä¼äºç°æçæåè¿çåå²æ¨¡åã</paragraph>

##### **Causal reasoning in difference graphs**
2411.01292v1 by Charles K. Assaad

In epidemiology, understanding causal mechanisms across different populations
is essential for designing effective public health interventions. Recently,
difference graphs have been introduced as a tool to visually represent causal
variations between two distinct populations. While there has been progress in
inferring these graphs from data through causal discovery methods, there
remains a gap in systematically leveraging their potential to enhance causal
reasoning. This paper addresses that gap by establishing conditions for
identifying causal changes and effects using difference graphs and
observational data. It specifically focuses on identifying total causal changes
and total effects in a nonparametric framework, as well as direct causal
changes and direct effects in a linear context. In doing so, it provides a
novel approach to causal reasoning that holds potential for various public
health applications.

æè¦ï¼å¨æµè¡çå­¸ä¸­ï¼äºè§£ä¸åäººç¾¤ä¹éçå ææ©å¶å°æ¼è¨­è¨ææçå¬å±è¡çå¹²é æªæ½è³ééè¦ãæè¿ï¼å·®ç°åè¡¨å·²è¢«å¼å¥ä½çºä¸ç¨®å·¥å·ï¼ç¨æ¼ç´è§å°è¡¨ç¤ºå©åä¸åäººç¾¤ä¹éçå æè®åãåç®¡ééå æç¼ç¾æ¹æ³å¾æ¸æä¸­æ¨æ·éäºåè¡¨æ¹é¢åå¾äºé²å±ï¼ä½å¨ç³»çµ±æ§å°å©ç¨å¶å¢å¼·å ææ¨ççæ½åæ¹é¢ä»ç¶å­å¨å·®è·ãæ¬æééå»ºç«ä½¿ç¨å·®ç°åè¡¨åè§å¯æ¸æè­å¥å æè®ååå æææçæ¢ä»¶ä¾è§£æ±ºéä¸å·®è·ãå®ç¹å¥å´éæ¼å¨éåæ¸æ¡æ¶ä¸­è­å¥ç¸½å æè®ååç¸½ææï¼ä»¥åå¨ç·æ§èæ¯ä¸­è­å¥ç´æ¥å æè®ååç´æ¥ææãéæ¨£ä¸ä¾ï¼å®æä¾äºä¸ç¨®å ææ¨ççæ°æ¹æ³ï¼å°åç¨®å¬å±è¡çæç¨å·ææ½åã

##### **Designing a Robust Radiology Report Generation System**
2411.01153v1 by Sonit Singh

Recent advances in deep learning have enabled researchers to explore tasks at
the intersection of computer vision and natural language processing, such as
image captioning, visual question answering, visual dialogue, and visual
language navigation. Taking inspiration from image captioning, the task of
radiology report generation aims at automatically generating radiology reports
by having a comprehensive understanding of medical images. However,
automatically generating radiology reports from medical images is a challenging
task due to the complexity, diversity, and nature of medical images. In this
paper, we outline the design of a robust radiology report generation system by
integrating different modules and highlighting best practices drawing upon
lessons from our past work and also from relevant studies in the literature. We
also discuss the impact of integrating different components to form a single
integrated system. We believe that these best practices, when implemented,
could improve automatic radiology report generation, augment radiologists in
decision making, and expedite diagnostic workflow, in turn improve healthcare
and save human lives.

æè¦ï¼æè¿æ·±åº¦å­¸ç¿çé²å±ä½¿ç ç©¶äººå¡è½å¤ æ¢ç´¢é»è¦è¦è¦ºåèªç¶èªè¨èçäº¤éä¸­çä»»åï¼ä¾å¦å½±åæ¨é¡ãè¦è¦ºåç­ãè¦è¦ºå°è©±åè¦è¦ºèªè¨å°èªãåå½±åæ¨é¡çåç¼ï¼æ¾å°ç§å ±åçæçä»»åæ¨å¨ééå¨é¢äºè§£é«å­¸å½±åèªåçææ¾å°ç§å ±åãç¶èï¼ç±æ¼é«å­¸å½±åçè¤éæ§ãå¤æ¨£æ§åæ§è³ªï¼èªåå¾é«å­¸å½±åçææ¾å°ç§å ±åæ¯ä¸é å·æææ°æ§çä»»åãå¨æ¬æä¸­ï¼æåééæ´åä¸åçæ¨¡çµä¸¦å¼·èª¿æä½³å¯¦åï¼æ¦è¿°äºå¥å¨çæ¾å°ç§å ±åçæç³»çµ±çè¨­è¨ï¼éäºå¯¦åæ±²åèªæåéå»çå·¥ä½ä»¥åæç»ä¸­çç¸éç ç©¶ãæåä¹è¨è«äºæ´åä¸åçµä»¶ä»¥å½¢æå®ä¸æ´åç³»çµ±çå½±é¿ãæåç¸ä¿¡ï¼éäºæä½³å¯¦åå¨å¯¦æ½å¾ï¼å¯ä»¥æ¹åèªåæ¾å°ç§å ±åçæï¼å¢å¼·æ¾å°ç§é«å¸«å¨æ±ºç­å¶å®ä¸­çè½åï¼ä¸¦å å¿«è¨ºæ·å·¥ä½æµç¨ï¼é²èæ¹åé«çä¿å¥ä¸¦æ¯æäººå½ã

##### **LEARNER: Learning Granular Labels from Coarse Labels using Contrastive Learning**
2411.01144v1 by Gautam Gare, Jana Armouti, Nikhil Madaan, Rohan Panda, Tom Fox, Laura Hutchins, Amita Krishnan, Ricardo Rodriguez, Bennett DeBoisblanc, Deva Ramanan, John Galeotti

A crucial question in active patient care is determining if a treatment is
having the desired effect, especially when changes are subtle over short
periods. We propose using inter-patient data to train models that can learn to
detect these fine-grained changes within a single patient. Specifically, can a
model trained on multi-patient scans predict subtle changes in an individual
patient's scans? Recent years have seen increasing use of deep learning (DL) in
predicting diseases using biomedical imaging, such as predicting COVID-19
severity using lung ultrasound (LUS) data. While extensive literature exists on
successful applications of DL systems when well-annotated large-scale datasets
are available, it is quite difficult to collect a large corpus of personalized
datasets for an individual. In this work, we investigate the ability of recent
computer vision models to learn fine-grained differences while being trained on
data showing larger differences. We evaluate on an in-house LUS dataset and a
public ADNI brain MRI dataset. We find that models pre-trained on clips from
multiple patients can better predict fine-grained differences in scans from a
single patient by employing contrastive learning.

æè¦ï¼å¨ä¸»åæ£èç§è­·ä¸­ï¼ä¸åééµåé¡æ¯ç¢ºå®æ²»çæ¯å¦ç¢çé æçææï¼ç¹å¥æ¯å¨ç­æéå§è®åç´°å¾®çææ³ä¸ãæåæè­°ä½¿ç¨æ£èéæ¸æä¾è¨ç·´æ¨¡åï¼ä»¥ä¾¿å­¸ç¿åµæ¸¬å®ä¸æ£èå§éäºç´°å¾®çè®åãå·é«ä¾èªªï¼å¨å¤ä½æ£èææä¸­è¨ç·´çæ¨¡åæ¯å¦å¯ä»¥é æ¸¬åå¥æ£èææä¸­çç´°å¾®è®åï¼è¿å¹´ä¾ï¼æ·±åº¦å­¸ç¿ (DL) å¨ä½¿ç¨çç©é«å­¸å½±åé æ¸¬ç¾çæ¹é¢æç¨æ¥çå»£æ³ï¼ä¾å¦ä½¿ç¨èºé¨è¶é³æ³¢ (LUS) æ¸æé æ¸¬ COVID-19 çå´éç¨åº¦ãåç®¡æå¤§éæç»è¨è¼äºå¨ææ¨è¨»çå¤§è¦æ¨¡æ¸æéå¯ç¨æ DL ç³»çµ±çæåæç¨ï¼ä½è¦çºåäººæ¶éå¤§éåäººåæ¸æéç¸ç¶å°é£ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºè¿æé»è¦è¦è¦ºæ¨¡åå¨éå°é¡¯ç¤ºè¼å¤§å·®ç°çæ¸æé²è¡è¨ç·´æï¼å­¸ç¿ç´°å¾®å·®ç°çè½åãæåå¨å§é¨ LUS æ¸æéåå¬éç ADNI å¤§è¦ MRI æ¸æéä¸é²è¡è©ä¼°ãæåç¼ç¾ï¼ééä½¿ç¨å°æ¯å­¸ç¿ï¼å¨å¤ä½æ£èççæ®µä¸é åè¨ç·´çæ¨¡åå¯ä»¥æ´å¥½å°é æ¸¬å®ä¸æ£èææä¸­çç´°å¾®å·®ç°ã

##### **Artificial Intelligence for Microbiology and Microbiome Research**
2411.01098v1 by Xu-Wen Wang, Tong Wang, Yang-Yu Liu

Advancements in artificial intelligence (AI) have transformed many scientific
fields, with microbiology and microbiome research now experiencing significant
breakthroughs through machine learning and deep learning applications. This
review provides a comprehensive overview of AI-driven approaches tailored for
microbiology and microbiome studies, emphasizing both technical advancements
and biological insights. We begin with an introduction to foundational AI
techniques, including primary machine learning paradigms and various deep
learning architectures, and offer guidance on choosing between machine learning
and deep learning methods based on specific research goals. The primary section
on application scenarios spans diverse research areas, from taxonomic
profiling, functional annotation & prediction, microbe-X interactions,
microbial ecology, metabolic modeling, precision nutrition, clinical
microbiology, to prevention & therapeutics. Finally, we discuss challenges
unique to this field, including the balance between interpretability and
complexity, the "small n, large p" problem, and the critical need for
standardized benchmarking datasets to validate and compare models. Together,
this review underscores AI's transformative role in microbiology and microbiome
research, paving the way for innovative methodologies and applications that
enhance our understanding of microbial life and its impact on our planet and
our health.

æè¦ï¼äººå·¥æºæ§ (AI) çé²æ­¥å·²è½è®è¨±å¤ç§å­¸é åï¼èå¾®çç©å­¸åå¾®çç©çµç ç©¶ç¾å¨æ­£ééæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æç¨é«é©å°é¡¯èççªç ´ãæ¬ç¯è©è«æä¾ AI é©åæ¹æ³çå¨é¢æ¦è¿°ï¼éäºæ¹æ³å°çºå¾®çç©å­¸åå¾®çç©çµç ç©¶éèº«æé ï¼å¼·èª¿æè¡é²æ­¥åçç©è¦è§£ãæåå¾åºç¤ AI æè¡çä»ç´¹éå§ï¼åæ¬ä¸»è¦çæ©å¨å­¸ç¿ç¯ä¾ååç¨®æ·±åº¦å­¸ç¿æ¶æ§ï¼ä¸¦æä¾æ ¹æå·é«ç ç©¶ç®æ¨å¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ä¹éé²è¡é¸æçæå°ãæç¨å ´æ¯çä¸»è¦é¨åæ¶µèäºå¾åé¡åæãåè½è¨»è§£åé æ¸¬ãå¾®çç© X ç¸äºä½ç¨ãå¾®çç©çæãä»£è¬å»ºæ¨¡ãç²¾æºçé¤ãè¨åºå¾®çç©å­¸å°é é²åæ²»çç­å¤åç ç©¶é åãæå¾ï¼æåè¨è«äºè©²é åç¨æçææ°ï¼åæ¬å¯è§£éæ§åè¤éæ§ä¹éçå¹³è¡¡ããå° nï¼å¤§ pãåé¡ï¼ä»¥åé©è­åæ¯è¼æ¨¡åçæ¨æºååºæºæ¸æéçééµéæ±ãæ¬ç¯è©è«å±åå¼·èª¿äº AI å¨å¾®çç©å­¸åå¾®çç©çµç ç©¶ä¸­çè½åä½ç¨ï¼çºåµæ°æ¹æ³åæç¨éªå¹³éè·¯ï¼éäºæ¹æ³åæç¨å¢å¼·äºæåå°å¾®çç©çå½åå¶å°æåæçåæåå¥åº·çå½±é¿ççè§£ã

##### **Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities**
2411.01053v1 by Adriel Saporta, Aahlad Puli, Mark Goldstein, Rajesh Ranganath

Contrastive learning methods, such as CLIP, leverage naturally paired
data-for example, images and their corresponding text captions-to learn general
representations that transfer efficiently to downstream tasks. While such
approaches are generally applied to two modalities, domains such as robotics,
healthcare, and video need to support many types of data at once. We show that
the pairwise application of CLIP fails to capture joint information between
modalities, thereby limiting the quality of the learned representations. To
address this issue, we present Symile, a simple contrastive learning approach
that captures higher-order information between any number of modalities. Symile
provides a flexible, architecture-agnostic objective for learning
modality-specific representations. To develop Symile's objective, we derive a
lower bound on total correlation, and show that Symile representations for any
set of modalities form a sufficient statistic for predicting the remaining
modalities. Symile outperforms pairwise CLIP, even with modalities missing in
the data, on cross-modal classification and retrieval across several
experiments including on an original multilingual dataset of 33M image, text
and audio samples and a clinical dataset of chest X-rays, electrocardiograms,
and laboratory measurements. All datasets and code used in this work are
publicly available at https://github.com/rajesh-lab/symile.

æè¦ï¼å°æ¯å­¸ç¿æ¹æ³ï¼ä¾å¦ CLIPï¼å©ç¨èªç¶éå°çè³æï¼ä¾å¦å½±ååå¶å°æçæå­æ¨é¡ï¼ä¾å­¸ç¿ä¸è¬åè¡¨å¾µï¼ä¸¦ææçå°è½ç§»å°ä¸æ¸¸ä»»åãéç¶æ­¤é¡æ¹æ³éå¸¸æç¨æ¼å©ç¨®å½¢å¼ï¼ä½æ©å¨äººæè¡ãé«çä¿å¥åè¦è¨ç­é åéè¦ä¸æ¬¡æ¯æ´å¤ç¨®é¡åçè³æãæåé¡¯ç¤ºï¼CLIP çæå°æç¨ç¡æ³æ·åå½¢å¼éçè¯åè³è¨ï¼å æ­¤éå¶äºå­¸ç¿è¡¨å¾µçåè³ªãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº Symileï¼éæ¯ä¸ç¨®ç°¡å®çå°æ¯å­¸ç¿æ¹æ³ï¼å¯ä»¥æ·åä»»ææ¸éçå½¢å¼ä¹éçé«éè³è¨ãSymile æä¾äºä¸åéæ´»ä¸èæ¶æ§ç¡éçç®æ¨ï¼ç¨æ¼å­¸ç¿ç¹å®æ¼å½¢å¼çè¡¨å¾µãçºéç¼ Symile çç®æ¨ï¼æåæ¨å°åºç¸½ç¸éæ§çä¸çï¼ä¸¦é¡¯ç¤ºä»»ä½å½¢å¼éåç Symile è¡¨å¾µå½¢æä¸åååççµ±è¨éï¼ç¨æ¼é æ¸¬å¶é¤å½¢å¼ãSymile åªæ¼æå° CLIPï¼å³ä½¿è³æä¸­ç¼ºå°å½¢å¼ï¼ä¹è½å¨è·¨å½¢å¼åé¡åæª¢ç´¢ä¸­è¡¨ç¾åºè²ï¼åæ¬å¨ä¸ååå« 3300 è¬å¼µå½±åãæå­åé³è¨æ¨£æ¬çåå§å¤èªè¨è³æéåä¸ååå«è¸é¨ X åãå¿é»ååå¯¦é©å®¤æ¸¬éçè¨åºè³æéä¸é²è¡çå¤æ¬¡å¯¦é©ãæ¬ç ç©¶ä¸­ä½¿ç¨ææè³æéåç¨å¼ç¢¼çå¬éæ¼ https://github.com/rajesh-lab/symileã

##### **Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading with Cataract**
2411.00726v1 by Fan Xiao, Junlin Hou, Ruiwei Zhao, Rui Feng, Haidong Zou, Lina Lu, Yi Xu, Juzhao Zhang

Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a
common complication of diabetes. As two different imaging tools for DR grading,
color fundus photography (CFP) and infrared fundus photography (IFP) are
highly-correlated and complementary in clinical applications. To the best of
our knowledge, this is the first study that explores a novel multi-modal deep
learning framework to fuse the information from CFP and IFP towards more
accurate DR grading. Specifically, we construct a dual-stream architecture
Cross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus
image modalities. In particular, a meticulously engineered Cross-Fundus
Attention (CFA) module is introduced to capture the correspondence between CFP
and IFP images. Moreover, we adopt both the single-modality and multi-modality
supervisions to maximize the overall performance for DR grading. Extensive
experiments on a clinical dataset consisting of 1,713 pairs of multi-modal
fundus images demonstrate the superiority of our proposed method. Our code will
be released for public access.

æè¦ï¼ç³å°¿çè¦ç¶²èçè® (DR) æ¯å¨çå¤±æçä¸»è¦åå ï¼ä¹æ¯ç³å°¿ççå¸¸è¦ä½µç¼çãä½çº DR åç´çå©ç¨®ä¸åçå½±åå·¥å·ï¼å½©è²ç¼åºæå½± (CFP) åç´å¤ç·ç¼åºæå½± (IFP) å¨è¨åºæç¨ä¸­é«åº¦ç¸éä¸äºè£ãææåæç¥ï¼éæ¯ç¬¬ä¸åæ¢è¨åµæ°çå¤æ¨¡å¼æ·±åº¦å­¸ç¿æ¡æ¶ï¼ä»¥èå CFP å IFP çè³è¨ï¼ä»¥é²è¡æ´æºç¢ºç DR åç´ãå·é«ä¾èªªï¼æåæ§å»ºäºä¸åéæµæ¶æ§ Cross-Fundus Transformer (CFT)ï¼ä»¥èåå©ç¨®ç¼åºå½±åæ¨¡å¼çåºæ¼ ViT çç¹å¾µãç¹å¥æ¯ï¼å¼å¥äºç²¾å¿è¨­è¨ç Cross-Fundus Attention (CFA) æ¨¡çµï¼ä»¥ææ CFP å IFP å½±åä¹éçå°æéä¿ãæ­¤å¤ï¼æåæ¡ç¨å®ä¸æ¨¡å¼åå¤æ¨¡å¼ç£ç£ï¼ä»¥æå¤§å DR åç´çæ´é«æè½ãå¨ç± 1,713 å°å¤æ¨¡å¼ç¼åºå½±åçµæçè¨åºè³æéä¸é²è¡çå»£æ³å¯¦é©è­æäºæåæåºçæ¹æ³çåªè¶æ§ãæåçç¨å¼ç¢¼å°æå¬éç¼å¸ã

##### **CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis**
2411.00696v1 by Fuying Wang, Feng Wu, Yihan Tang, Lequan Yu

Integrating multimodal Electronic Health Records (EHR) data, such as
numerical time series and free-text clinical reports, has great potential in
predicting clinical outcomes. However, prior work has primarily focused on
capturing temporal interactions within individual samples and fusing multimodal
information, overlooking critical temporal patterns across patients. These
patterns, such as trends in vital signs like abnormal heart rate or blood
pressure, can indicate deteriorating health or an impending critical event.
Similarly, clinical notes often contain textual descriptions that reflect these
patterns. Identifying corresponding temporal patterns across different
modalities is crucial for improving the accuracy of clinical outcome
predictions, yet it remains a challenging task. To address this gap, we
introduce a Cross-Modal Temporal Pattern Discovery (CTPD) framework, designed
to efficiently extract meaningful cross-modal temporal patterns from multimodal
EHR data. Our approach introduces shared initial temporal pattern
representations which are refined using slot attention to generate temporal
semantic embeddings. To ensure rich cross-modal temporal semantics in the
learned patterns, we introduce a contrastive-based TPNCE loss for cross-modal
alignment, along with two reconstruction losses to retain core information of
each modality. Evaluations on two clinically critical tasks, 48-hour
in-hospital mortality and 24-hour phenotype classification, using the MIMIC-III
database demonstrate the superiority of our method over existing approaches.

æè¦ï¼æ´åå¤æ¨¡æçµå­å¥åº·è®°å½ (EHR) æ°æ®ï¼ä¾å¦æ°å¼æ¶é´åºååèªç±ææ¬ä¸´åºæ¥åï¼å¨é¢æµä¸´åºç»ææ¹é¢å·æå·¨å¤§æ½åãç¶èï¼ä»¥åçå·¥ä½ä¸»è¦éä¸­å¨ææåä¸ªæ ·æ¬ä¸­çæ¶é´äº¤äºå¹¶èåå¤æ¨¡æä¿¡æ¯ï¼èå¿½ç¥äºæ£èä¹é´çå³é®æ¶é´æ¨¡å¼ãè¿äºæ¨¡å¼ï¼ä¾å¦çå½ä½å¾è¶å¿ï¼å¦å¼å¸¸å¿çæè¡åï¼å¯è½è¡¨æå¥åº·ç¶åµæ¶åæå³å°åççå±éäºä»¶ãç±»ä¼¼å°ï¼ä¸´åºç¬è®°éå¸¸åå«åæ è¿äºæ¨¡å¼çææ¬æè¿°ãè¯å«ä¸åæ¨¡æä¹é´ç¸åºçæ¶é´æ¨¡å¼å¯¹äºæé«ä¸´åºç»æé¢æµçåç¡®æ§è³å³éè¦ï¼ä½å®ä»ç¶æ¯ä¸é¡¹å·ææææ§çä»»å¡ãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬å¼å¥äºä¸ä¸ªè·¨æ¨¡ææ¶é´æ¨¡å¼åç° (CTPD) æ¡æ¶ï¼æ¨å¨ä»å¤æ¨¡æ EHR æ°æ®ä¸­æææåææä¹çè·¨æ¨¡ææ¶é´æ¨¡å¼ãæä»¬çæ¹æ³å¼å¥äºå±äº«çåå§æ¶é´æ¨¡å¼è¡¨ç¤ºï¼è¿äºè¡¨ç¤ºä½¿ç¨ææ§½æ³¨æåè¿è¡ä¼åä»¥çææ¶é´è¯­ä¹åµå¥ãä¸ºäºç¡®ä¿å­¦ä¹ æ¨¡å¼ä¸­ä¸°å¯çè·¨æ¨¡ææ¶é´è¯­ä¹ï¼æä»¬å¼å¥äºåºäºå¯¹æ¯ç TPNCE æå¤±ç¨äºè·¨æ¨¡æå¯¹é½ï¼ä»¥åä¸¤ä¸ªéå»ºæå¤±ä»¥ä¿çæ¯ä¸ªæ¨¡æçæ ¸å¿ä¿¡æ¯ãå¨ä¸¤ä¸ªä¸´åºå³é®ä»»å¡ï¼48 å°æ¶é¢åæ­»äº¡çå 24 å°æ¶è¡¨ååç±»ï¼ä¸çè¯ä¼°ï¼ä½¿ç¨ MIMIC-III æ°æ®åºè¯æäºæä»¬æ¹æ³ä¼äºç°ææ¹æ³ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v1 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, U. Rajendra Acharya, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡ååè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨ææ°ï¼ä¾å¦æ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼å®æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´ç¶²è·¯ - VGG19ãInceptionV3 å ResNet50 - å¾ X åå½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æï¼ä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼ç¾¤éçé¸æéç¨è­å¥æå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°å¶èé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) èçä»¥é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªé¡¯äºééµè®æ¸ï¼é¡¯ç¤ºçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»èï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãéåæ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·çä¿¡ä»»ï¼ä»¥é²è¡è¨åºæ´åã

##### **Deep learning-based auto-contouring of organs/structures-at-risk for pediatric upper abdominal radiotherapy**
2411.00594v1 by Mianyong Ding, Matteo Maspero, Annemieke S Littooij, Martine van Grotel, Raquel Davila Fajardo, Max M van Noesel, Marry M van den Heuvel-Eibrink, Geert O Janssens

Purposes: This study aimed to develop a computed tomography (CT)-based
multi-organ segmentation model for delineating organs-at-risk (OARs) in
pediatric upper abdominal tumors and evaluate its robustness across multiple
datasets. Materials and methods: In-house postoperative CTs from pediatric
patients with renal tumors and neuroblastoma (n=189) and a public dataset
(n=189) with CTs covering thoracoabdominal regions were used. Seventeen OARs
were delineated: nine by clinicians (Type 1) and eight using TotalSegmentator
(Type 2). Auto-segmentation models were trained using in-house (ModelPMC-UMCU)
and a combined dataset of public data (Model-Combined). Performance was
assessed with Dice Similarity Coefficient (DSC), 95% Hausdorff Distance (HD95),
and mean surface distance (MSD). Two clinicians rated clinical acceptability on
a 5-point Likert scale across 15 patient contours. Model robustness was
evaluated against sex, age, intravenous contrast, and tumor type. Results:
Model-PMC-UMCU achieved mean DSC values above 0.95 for five of nine OARs, while
spleen and heart ranged between 0.90 and 0.95. The stomach-bowel and pancreas
exhibited DSC values below 0.90. Model-Combined demonstrated improved
robustness across both datasets. Clinical evaluation revealed good usability,
with both clinicians rating six of nine Type 1 OARs above four and six of eight
Type 2 OARs above three. Significant performance 2 differences were only found
across age groups in both datasets, specifically in the left lung and pancreas.
The 0-2 age group showed the lowest performance. Conclusion: A multi-organ
segmentation model was developed, showcasing enhanced robustness when trained
on combined datasets. This model is suitable for various OARs and can be
applied to multiple datasets in clinical settings.

æè¦ï¼<paragraph>ç®çï¼æ¬ç ç©¶æ¨å¨å¼åä¸ä¸ªåºäºè®¡ç®æºæ­å±æ«æ (CT) çå¤å¨å®åå²æ¨¡åï¼ç¨äºæç»å°å¿ä¸è¹é¨è¿ç¤ä¸­çå±é©å¨å® (OAR)ï¼å¹¶è¯ä¼°å¶å¨å¤ä¸ªæ°æ®éä¸­çç¨³å¥æ§ãææåæ¹æ³ï¼ä½¿ç¨å°å¿è¾è¿ç¤åç¥ç»æ¯ç»èç¤æ£è (n=189) çé¢åæ¯å CT ä»¥ååå«è¸è¹åºå CT çå¬å±æ°æ®é (n=189)ãæç»äº 17 ä¸ª OARï¼9 ä¸ªç±ä¸´åºå»çæç» (ç±»å 1)ï¼8 ä¸ªä½¿ç¨ TotalSegmentator æç» (ç±»å 2)ãä½¿ç¨é¢å (ModelPMC-UMCU) åå¬å±æ°æ®ç»åæ°æ®é (Model-Combined) è®­ç»èªå¨åå²æ¨¡åãä½¿ç¨éª°å­ç¸ä¼¼æ§ç³»æ° (DSC)ã95% éæ¯å¤å¤«è·ç¦» (HD95) åå¹³åè¡¨é¢è·ç¦» (MSD) è¯ä¼°æ§è½ãä¸¤ä½ä¸´åºå»çä½¿ç¨ 5 ç¹æåç¹éè¡¨å¯¹ 15 ä¸ªæ£èè½®å»çä¸´åºå¯æ¥åæ§è¿è¡è¯çº§ãéå¯¹æ§å«ãå¹´é¾ãéèå¯¹æ¯åè¿ç¤ç±»åè¯ä¼°æ¨¡åçç¨³å¥æ§ãç»æï¼Model-PMC-UMCU å¯¹ä¹ä¸ª OAR ä¸­çäºä¸ª OAR çå¹³å DSC å¼è¾¾å° 0.95 ä»¥ä¸ï¼èè¾èåå¿èå¨ 0.90 å° 0.95 ä¹é´ãèè åè°èºç DSC å¼ä½äº 0.90ãModel-Combined å¨ä¸¤ä¸ªæ°æ®éä¸é½è¡¨ç°åºæ¹è¿çç¨³å¥æ§ãä¸´åºè¯ä¼°æ¾ç¤ºåºè¯å¥½çå¯ç¨æ§ï¼ä¸¤ä½ä¸´åºå»çå¯¹å­ä¸ªä¹ä¸ªç±»å 1 OAR çè¯ååé«äºååï¼å¯¹å«ä¸ªç±»å 2 OAR ä¸­çå­ä¸ªè¯ååé«äºä¸åãä»å¨ä¸¤ä¸ªæ°æ®éçå¹´é¾ç»ä¸­åç°äºæ¾ççæ§è½ 2 å·®å¼ï¼ç¹å«æ¯å¨å·¦èºåè°èºä¸­ã0-2 å²å¹´é¾ç»è¡¨ç°æå·®ãç»è®ºï¼å¼åäºä¸ä¸ªå¤å¨å®åå²æ¨¡åï¼å¨åå¹¶æ°æ®éä¸è®­ç»æ¶æ¾ç¤ºåºå¢å¼ºçç¨³å¥æ§ãè¯¥æ¨¡åéç¨äºåç§ OARï¼å¹¶ä¸å¯ä»¥å¨ä¸´åºç¯å¢ä¸­åºç¨äºå¤ä¸ªæ°æ®éã</paragraph>

##### **Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback**
2411.00897v1 by Song Yu, Xiaofei Xu, Fangfei Xu, Li Li

Although large language models perform well in understanding and responding
to user intent, their performance in specialized domains such as Traditional
Chinese Medicine (TCM) remains limited due to lack of expertise. In addition,
high-quality data related to TCM is scarce and difficult to obtain, making
large language models ineffective in handling TCM tasks. In this work, we
propose a framework to improve the performance of large language models for TCM
tasks using only a small amount of data. First, we use medical case data for
supervised fine-tuning of the large model, making it initially capable of
performing TCM tasks. Subsequently, we further optimize the model's performance
using reinforcement learning from AI feedback (RLAIF) to align it with the
preference data. The ablation study also demonstrated the performance gain is
attributed to both supervised fine-tuning and the direct policy optimization.
The experimental results show that the model trained with a small amount of
data achieves a significant performance improvement on a representative TCM
task.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡åå¨çè§£ååæä½¿ç¨èæåæ¹é¢è¡¨ç¾è¯å¥½ï¼ä½ç±æ¼ç¼ºä¹å°æ¥­ç¥è­ï¼å®åå¨å³çµ±ä¸­é« (TCM) ç­å°æ¥­é åçè¡¨ç¾ä»ç¶æéãæ­¤å¤ï¼èä¸­é«ç¸éçé«åè³ªè³æç¨å°ä¸é£ä»¥åå¾ï¼éä½¿å¾å¤§åèªè¨æ¨¡åå¨èçä¸­é«ä»»åæææä¸å½°ãå¨éé å·¥ä½ä¸­ï¼æåæåºä¸åæ¶æ§ï¼ä½¿ç¨å°éè³æä¾æ¹åå¤§åèªè¨æ¨¡åå¨ä¸­é«ä»»åä¸­çè¡¨ç¾ãé¦åï¼æåä½¿ç¨é«çæ¡ä¾è³æå°å¤§åæ¨¡åé²è¡ç£ç£å¾®èª¿ï¼ä½¿å¶æåå·åå·è¡ä¸­é«ä»»åçè½åãé¨å¾ï¼æåé²ä¸æ­¥ä½¿ç¨äººå·¥æºæ§åé¥çå¼·åå­¸ç¿ (RLAIF) ä¾æä½³åæ¨¡åçè¡¨ç¾ï¼ä½¿å¶èåå¥½è³æä¿æä¸è´ãæ¶èç ç©¶ä¹è­æï¼è¡¨ç¾æåæ­¸åæ¼ç£ç£å¾®èª¿åç´æ¥ç­ç¥æä½³åãå¯¦é©çµæé¡¯ç¤ºï¼ä½¿ç¨å°éè³æè¨ç·´çæ¨¡åå¨ä»£è¡¨æ§çä¸­é«ä»»åä¸åå¾é¡¯èçè¡¨ç¾æåã

##### **StepCountJITAI: simulation environment for RL with application to physical activity adaptive intervention**
2411.00336v1 by Karine Karine, Benjamin M. Marlin

The use of reinforcement learning (RL) to learn policies for just-in-time
adaptive interventions (JITAIs) is of significant interest in many behavioral
intervention domains including improving levels of physical activity. In a
messaging-based physical activity JITAI, a mobile health app is typically used
to send messages to a participant to encourage engagement in physical activity.
In this setting, RL methods can be used to learn what intervention options to
provide to a participant in different contexts. However, deploying RL methods
in real physical activity adaptive interventions comes with challenges: the
cost and time constraints of real intervention studies result in limited data
to learn adaptive intervention policies. Further, commonly used RL simulation
environments have dynamics that are of limited relevance to physical activity
adaptive interventions and thus shed little light on what RL methods may be
optimal for this challenging application domain. In this paper, we introduce
StepCountJITAI, an RL environment designed to foster research on RL methods
that address the significant challenges of policy learning for adaptive
behavioral interventions.

æè¦ï¼å©ç¨å¼·åå­¸ç¿ (RL) ä¾å­¸ç¿å³æé©ææ§ä»å¥ (JITAI) çç­ç¥ï¼å¨è¨±å¤è¡çºä»å¥é åä¸­ååéæ³¨ï¼åæ¬æåé«è½æ´»åçå±¤ç´ãå¨åºæ¼è¨æ¯çé«è½æ´»å JITAI ä¸­ï¼è¡åå¥åº·æç¨ç¨å¼éå¸¸ç¨æ¼ååèèå³éè¨æ¯ï¼ä»¥é¼åµåèé«è½æ´»åãå¨æ­¤è¨­å®ä¸­ï¼RL æ¹æ³å¯è¢«ç¨æ¼å­¸ç¿å¨ä¸åæå¢ä¸æä¾çµ¦åèèçä»å¥é¸é ãç¶èï¼å¨å¯¦éé«è½æ´»åé©ææ§ä»å¥ä¸­é¨ç½² RL æ¹æ³æéå°ææ°ï¼å¯¦éä»å¥ç ç©¶çææ¬åæééå¶ï¼å°è´å¯ä¾å­¸ç¿é©ææ§ä»å¥ç­ç¥çè³ææéãæ­¤å¤ï¼å¸¸ç¨ç RL æ¨¡æ¬ç°å¢å·æèé«è½æ´»åé©ææ§ä»å¥ç¸éæ§æéçåæï¼å æ­¤é£ä»¥äºè§£åªäº RL æ¹æ³å¯è½æé©åéåå·ææ°æ§çæç¨é åãå¨æ¬æä¸­ï¼æåä»ç´¹ StepCountJITAIï¼éæ¯ä¸å RL ç°å¢ï¼æ¨å¨ä¿é²å° RL æ¹æ³çç ç©¶ï¼ä»¥æå°é©ææ§è¡çºä»å¥ç­ç¥å­¸ç¿çéå¤§ææ°ã

##### **Strongly Topology-preserving GNNs for Brain Graph Super-resolution**
2411.02525v1 by Pragya Singh, Islem Rekik

Brain graph super-resolution (SR) is an under-explored yet highly relevant
task in network neuroscience. It circumvents the need for costly and
time-consuming medical imaging data collection, preparation, and processing.
Current SR methods leverage graph neural networks (GNNs) thanks to their
ability to natively handle graph-structured datasets. However, most GNNs
perform node feature learning, which presents two significant limitations: (1)
they require computationally expensive methods to learn complex node features
capable of inferring connectivity strength or edge features, which do not scale
to larger graphs; and (2) computations in the node space fail to adequately
capture higher-order brain topologies such as cliques and hubs. However,
numerous studies have shown that brain graph topology is crucial in identifying
the onset and presence of various neurodegenerative disorders like Alzheimer
and Parkinson. Motivated by these challenges and applications, we propose our
STP-GSR framework. It is the first graph SR architecture to perform
representation learning in higher-order topological space. Specifically, using
the primal-dual graph formulation from graph theory, we develop an efficient
mapping from the edge space of our low-resolution (LR) brain graphs to the node
space of a high-resolution (HR) dual graph. This approach ensures that
node-level computations on this dual graph correspond naturally to edge-level
learning on our HR brain graphs, thereby enforcing strong topological
consistency within our framework. Additionally, our framework is GNN layer
agnostic and can easily learn from smaller, scalable GNNs, reducing
computational requirements. We comprehensively benchmark our framework across
seven key topological measures and observe that it significantly outperforms
the previous state-of-the-art methods and baselines.

æè¦ï¼è¦ååè¶è§£æåº¦ (SR) æ¯ç¶²è·¯ç¥ç¶ç§å­¸ä¸­ä¸åå°æªååæ¢ç´¢ä½é«åº¦ç¸éçä»»åãå®é¿éäºä»£å¹é«æä¸èæçé«å­¸å½±åè³ææ¶éãæºååèççéè¦ãç®åç SR æ¹æ³å©ç¨åç¥ç¶ç¶²è·¯ (GNN)ï¼å çºå®åè½å¤ åçèçåå½¢çµæ§çè³æéãç¶èï¼å¤§å¤æ¸ GNN é½å·è¡ç¯é»ç¹å¾µå­¸ç¿ï¼éæåºäºå©åéå¤§çéå¶ï¼(1) å®åéè¦ä»¥è¨ç®ææ¬é«çæ¹å¼ä¾å­¸ç¿è¤éçç¯é»ç¹å¾µï¼éäºç¹å¾µè½å¤ æ¨è«é£æ¥å¼·åº¦æéç·£ç¹å¾µï¼éç¡æ³æ´å±å°æ´å¤§çåå½¢ï¼(2) ç¯é»ç©ºéä¸­çè¨ç®ç¡æ³ååæ·åé«éè¦é¨ææ²ï¼ä¾å¦æ´¾ç³»åæ¨ç´ãç¶èï¼è¨±å¤ç ç©¶è¡¨æï¼è¦åå½¢ææ²å°æ¼è­å¥åç¨®ç¥ç¶éåæ§ç¾çï¼å¦é¿è²æµ·é»çåå¸éæ£®æ°çï¼çç¼çåå­å¨è³ééè¦ãåå°éäºææ°åæç¨æ¿åµï¼æåæåºäºæåç STP-GSR æ¶æ§ãå®æ¯ç¬¬ä¸åå¨é«éææ²ç©ºéä¸­å·è¡è¡¨ç¤ºå­¸ç¿çåå½¢ SR æ¶æ§ãå·é«ä¾èªªï¼æåä½¿ç¨åè«ä¸­çåå§å°å¶åå½¢å¬å¼ï¼å¾æåä½è§£æåº¦ (LR) è¦åå½¢çéç·£ç©ºééç¼äºä¸åé«æçå°æ ï¼å°æ å°é«è§£æåº¦ (HR) å°å¶åå½¢ç¯é»ç©ºéãéç¨®æ¹æ³ç¢ºä¿äºå¨éåå°å¶åå½¢ä¸çç¯é»å±¤ç´è¨ç®èªç¶å°å°ææ¼æå HR è¦åå½¢ä¸çéç·£å±¤ç´å­¸ç¿ï¼å¾èå¼·å¶å·è¡æåæ¡æ¶å§å¼·å¤§çææ²ä¸è´æ§ãæ­¤å¤ï¼æåçæ¡æ¶è GNN å±¤ç¡éï¼ä¸¦ä¸å¯ä»¥è¼é¬å°å¾æ´å°ãå¯æ´å±ç GNN ä¸­å­¸ç¿ï¼å¾èæ¸å°è¨ç®éæ±ãæåå¨ä¸é ééµææ²æ¸¬éä¸­å¨é¢è©å®äºæåçæ¡æ¶ï¼ä¸¦è§å¯å°å®é¡¯èåªæ¼ä»¥å¾çåé²æ¹æ³ååºç·ã

##### **Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**
2411.02523v1 by Balu Bhasuran, Qiao Jin, Yuzhang Xie, Carl Yang, Karim Hanna, Jennifer Costa, Cindy Shavor, Zhiyong Lu, Zhe He

Differential diagnosis is crucial for medicine as it helps healthcare
providers systematically distinguish between conditions that share similar
symptoms. This study assesses the impact of lab test results on differential
diagnoses (DDx) made by large language models (LLMs). Clinical vignettes from
50 case reports from PubMed Central were created incorporating patient
demographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,
Claude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx
with and without lab data. A comprehensive evaluation involving GPT-4, a
knowledge graph, and clinicians was conducted. GPT-4 performed best, achieving
55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient
accuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and
Mixtral excelling, though exact match rates were low. Lab tests, including
liver function, metabolic/toxicology panels, and serology/immune tests, were
generally interpreted correctly by LLMs for differential diagnosis.

æè¦ï¼éå¥è¨ºæ·å°æ¼é«å­¸è³ééè¦ï¼å çºå®æå©æ¼é«çä¿å¥æä¾èç³»çµ±ååå·æç¸ä¼¼çççç¾çãéé ç ç©¶è©ä¼°äºå¯¦é©å®¤æª¢é©çµæå°å¤§åèªè¨æ¨¡å (LLM) ååºçéå¥è¨ºæ· (DDx) çå½±é¿ãå¾ PubMed Central ç 50 ä»½çä¾å ±åä¸­å»ºç«äºè¨åºç°¡å ±ï¼å¶ä¸­åå«æ£èäººå£çµ±è¨ãççåå¯¦é©å®¤çµæãæ¸¬è©¦äºäºå LLM GPT-4ãGPT-3.5ãLlama-2-70bãClaude-2 å Mixtral-8x7Bï¼ä»¥çæå¸¶åä¸å¸¶å¯¦é©å®¤æ¸æçå 10ãå 5 åå 1 DDxãé²è¡äºä¸é æ¶å GPT-4ãç¥è­åè­åè¨åºé«ççç¶åè©ä¼°ãGPT-4 è¡¨ç¾æä½³ï¼å¨æå¯¦é©å®¤æ¸æçææ³ä¸ï¼å 1 åè¨ºæ·çæºç¢ºçéå° 55%ï¼å 10 åçæºç¢ºçéå° 60%ï¼å¯¬é¬æºç¢ºçé«é 80%ãå¯¦é©å®¤çµæé¡¯èæé«äºæºç¢ºçï¼GPT-4 å Mixtral è¡¨ç¾åºè²ï¼åç®¡å®å¨å¹éçè¼ä½ãLLM éå¸¸å¯ä»¥æ­£ç¢ºè§£éåæ¬èåè½ãä»£è¬/æ¯çå­¸æª¢æ¥åè¡æ¸å­¸/åç«æ¸¬è©¦å¨å§çå¯¦é©å®¤æª¢é©ï¼ä»¥é²è¡éå¥è¨ºæ·ã

##### **Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images**
2411.00891v1 by Arianna Bunnell, Thomas Wolfgruber, Brandon Quon, Kailee Hung, Brenda Hernandez, Peter Sadowski, John A. Shepherd

Background: Mammographic breast density, as defined by the American College
of Radiology's Breast Imaging Reporting and Data System (BI-RADS), is one of
the strongest risk factors for breast cancer, but is derived from mammographic
images. Breast ultrasound (BUS) is an alternative breast cancer screening
modality, particularly useful for early detection in low-resource, rural
contexts. The purpose of this study was to explore an artificial intelligence
(AI) model to predict BI-RADS mammographic breast density category from
clinical, handheld BUS imaging. Methods: All data are sourced from the Hawaii
and Pacific Islands Mammography Registry. We compared deep learning methods
from BUS imaging, as well as machine learning models from image statistics
alone. The use of AI-derived BUS density as a risk factor for breast cancer was
then compared to clinical BI-RADS breast density while adjusting for age. The
BUS data were split by individual into 70/20/10% groups for training,
validation, and testing. Results: 405,120 clinical BUS images from 14.066 women
were selected for inclusion in this study, resulting in 9.846 women for
training (302,574 images), 2,813 for validation (11,223 images), and 1,406 for
testing (4,042 images). On the held-out testing set, the strongest AI model
achieves AUROC 0.854 predicting BI-RADS mammographic breast density from BUS
imaging and outperforms all shallow machine learning methods based on image
statistics. In cancer risk prediction, age-adjusted AI BUS breast density
predicted 5-year breast cancer risk with 0.633 AUROC, as compared to 0.637
AUROC from age-adjusted clinical breast density. Conclusions: BI-RADS
mammographic breast density can be estimated from BUS imaging with high
accuracy using a deep learning model. Furthermore, we demonstrate that
AI-derived BUS breast density is predictive of 5-year breast cancer risk in our
population.

æè¦ï¼<paragraph>èæ¯ï¼ç±ç¾åæ¾å°å­¸é¢çä¹³æ¿å½±åå ±ååè³æç³»çµ± (BI-RADS) æå®ç¾©çä¹³æ¿æå½±ä¹³æ¿å¯åº¦ï¼æ¯ä¹³çæå¼·çé¢¨éªå å­ä¹ä¸ï¼ä½å»æ¯ä¾èªä¹³æ¿æå½±ååãä¹³æ¿è¶é³æ³¢ (BUS) æ¯å¦ä¸ç¨®ä¹³çç¯©æª¢æ¹å¼ï¼ç¹å¥é©ç¨æ¼è³æºå±ä¹çéæå°åçæ©æåµæ¸¬ãæ¬ç ç©¶çç®çæ¯æ¢ç´¢ä¸ç¨®äººå·¥æºæ§ (AI) æ¨¡åï¼å¾è¨åºææå¼ BUS å½±åé æ¸¬ BI-RADS ä¹³æ¿æå½±ä¹³æ¿å¯åº¦é¡å¥ãæ¹æ³ï¼ææè³æé½ä¾èªå¤å¨å¤·åå¤ªå¹³æ´ç¾¤å³¶ä¹³æ¿æå½±ç»è¨èãæåæ¯è¼äºä¾èª BUS å½±åçæ·±åº¦å­¸ç¿æ¹æ³ï¼ä»¥ååä¾èªå½±åçµ±è¨è³æçæ©å¨å­¸ç¿æ¨¡åãæ¥èå° AI è¡çç BUS å¯åº¦ç¨ä½ä¹³çé¢¨éªå å­ï¼èèª¿æ´å¹´é½¡å¾çè¨åº BI-RADS ä¹³æ¿å¯åº¦é²è¡æ¯è¼ãBUS è³ææåäººåçº 70/20/10% çç¾¤çµï¼ç¨æ¼è¨ç·´ãé©è­åæ¸¬è©¦ãçµæï¼æ¬ç ç©¶é¸åäºä¾èª 14.066 ä½å¥³æ§ç 405,120 å¼µè¨åº BUS å½±åï¼å¾åº 9.846 ä½å¥³æ§ç¨æ¼è¨ç·´ (302,574 å¼µå½±å)ã2,813 ä½ç¨æ¼é©è­ (11,223 å¼µå½±å) å 1,406 ä½ç¨æ¼æ¸¬è©¦ (4,042 å¼µå½±å)ãå¨ä¿ççæ¸¬è©¦éä¸­ï¼æå¼·å¤§ç AI æ¨¡åå¨å¾ BUS å½±åé æ¸¬ BI-RADS ä¹³æ¿æå½±ä¹³æ¿å¯åº¦æï¼éå° 0.854 ç AUROCï¼ä¸¦åªæ¼ææåºæ¼å½±åçµ±è¨è³æçæ·ºå±¤æ©å¨å­¸ç¿æ¹æ³ãå¨ççé¢¨éªé æ¸¬ä¸­ï¼èª¿æ´å¹´é½¡å¾ç AI BUS ä¹³æ¿å¯åº¦é æ¸¬äº 5 å¹´ä¹³çé¢¨éªï¼AUROC çº 0.633ï¼èèª¿æ´å¹´é½¡å¾çè¨åºä¹³æ¿å¯åº¦ç AUROC çº 0.637ãçµè«ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼å¯ä»¥å¾ BUS å½±åä¼°è¨åº BI-RADS ä¹³æ¿æå½±ä¹³æ¿å¯åº¦ï¼ä¸æºç¢ºåº¦å¾é«ãæ­¤å¤ï¼æåè­æ AI è¡çç BUS ä¹³æ¿å¯åº¦å¯ä»¥é æ¸¬æåæç¾¤ç 5 å¹´ä¹³çé¢¨éªã</paragraph>

##### **Monitoring fairness in machine learning models that predict patient mortality in the ICU**
2411.00190v2 by Tempest A. van Schaik, Xinggang Liu, Louis Atallah, Omar Badawi

This work proposes a fairness monitoring approach for machine learning models
that predict patient mortality in the ICU. We investigate how well models
perform for patient groups with different race, sex and medical diagnoses. We
investigate Documentation bias in clinical measurement, showing how fairness
analysis provides a more detailed and insightful comparison of model
performance than traditional accuracy metrics alone.

æè¦ï¼éé ç ç©¶æåºä¸åå¬å¹³æ§ç£æ§æ¹æ³ï¼ç¨æ¼é æ¸¬å è­·çæ¿ä¸­çæ£æ­»äº¡ççæ©å¨å­¸ç¿æ¨¡åãæåæ¢è¨æ¨¡åå¨ä¸åç¨®æãæ§å¥åé«çè¨ºæ·ççæ£ç¾¤é«ä¸­è¡¨ç¾å¦ä½ãæåæ¢è¨è¨åºæ¸¬éä¸­çæä»¶åå·®ï¼èªªæå¬å¹³æ§åæå¦ä½æä¾æ¯å³çµ±æºç¢ºæ§ææ¨æ´è©³ç´°ä¸æè¦å°çæ¨¡åæè½æ¯è¼ã

##### **Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy**
2411.00178v1 by Panagiota Gatoula, Dimitrios E. Diamantis, Anastasios Koulaouzidis, Cristina Carretero, Stefania Chetcuti-Zammit, Pablo Cortegoso Valdivia, BegoÃ±a GonzÃ¡lez-SuÃ¡rez, Alessandro Mussetto, John Plevris, Alexander Robertson, Bruno Rosa, Ervin Toth, Dimitris K. Iakovidis

Sharing retrospectively acquired data is essential for both clinical research
and training. Synthetic Data Generation (SDG), using Artificial Intelligence
(AI) models, can overcome privacy barriers in sharing clinical data, enabling
advancements in medical diagnostics. This study focuses on the clinical
evaluation of medical SDG, with a proof-of-concept investigation on diagnosing
Inflammatory Bowel Disease (IBD) using Wireless Capsule Endoscopy (WCE) images.
The paper contributes by a) presenting a protocol for the systematic evaluation
of synthetic images by medical experts and b) applying it to assess TIDE-II, a
novel variational autoencoder-based model for high-resolution WCE image
synthesis, with a comprehensive qualitative evaluation conducted by 10
international WCE specialists, focusing on image quality, diversity, realism,
and clinical decision-making. The results show that TIDE-II generates
clinically relevant WCE images, helping to address data scarcity and enhance
diagnostic tools. The proposed protocol serves as a reference for future
research on medical image-generation techniques.

æè¦ï¼åé¡§æ§ç²åçè³æåäº«å°æ¼è¨åºç ç©¶åè¨ç·´è³ééè¦ãä½¿ç¨äººå·¥æºæ§ (AI) æ¨¡åçåæè³æç¢ç (SDG) è½å¤ åæè¨åºè³æå±äº«ä¸­çé±ç§éç¤ï¼ä¿é²é«çè¨ºæ·çé²å±ãæ¬ç ç©¶å°æ³¨æ¼è¨åºè©ä¼°é«å­¸ SDGï¼ä¸¦ééç¡ç·è åå§è¦é¡ (WCE) å½±åè¨ºæ·ç¼çæ§è¸éç¾ç (IBD) çæ¦å¿µé©è­èª¿æ¥ãæ¬æçè²¢ç»åæ¬ï¼a) æåºç±é«å­¸å°å®¶ç³»çµ±æ§è©ä¼°åæå½±åçåå®ï¼ä»¥å b) å°å¶æç¨æ¼è©ä¼° TIDE-IIï¼éæ¯ä¸åç¨æ¼é«è§£æåº¦ WCE å½±ååæçè®ç°èªåç·¨ç¢¼å¨æ¨¡åï¼ä¸¦ç± 10 ä½åé WCE å°å®¶é²è¡å¨é¢çåè³ªè©ä¼°ï¼éé»å¨æ¼å½±ååè³ªãå¤æ¨£æ§ãçå¯¦æ§ï¼ä»¥åè¨åºæ±ºç­å¶å®ãçµæé¡¯ç¤º TIDE-II ç¢çäºè¨åºç¸éç WCE å½±åï¼æå©æ¼è§£æ±ºè³æç¨å°çåé¡ï¼ä¸¦å¢å¼·è¨ºæ·å·¥å·ãææåºçåå®å¯ä½çºæªä¾é«å­¸å½±åç¢çæè¡ç ç©¶çåèã

##### **Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning**
2411.00173v1 by John Wu, David Wu, Jimeng Sun

Medical coding, the translation of unstructured clinical text into
standardized medical codes, is a crucial but time-consuming healthcare
practice. Though large language models (LLM) could automate the coding process
and improve the efficiency of such tasks, interpretability remains paramount
for maintaining patient trust. Current efforts in interpretability of medical
coding applications rely heavily on label attention mechanisms, which often
leads to the highlighting of extraneous tokens irrelevant to the ICD code. To
facilitate accurate interpretability in medical language models, this paper
leverages dictionary learning that can efficiently extract sparsely activated
representations from dense language model embeddings in superposition. Compared
with common label attention mechanisms, our model goes beyond token-level
representations by building an interpretable dictionary which enhances the
mechanistic-based explanations for each ICD code prediction, even when the
highlighted tokens are medically irrelevant. We show that dictionary features
can steer model behavior, elucidate the hidden meanings of upwards of 90% of
medically irrelevant tokens, and are human interpretable.

æè¦ï¼é«çç·¨ç¢¼æ¯å°éçµæ§åçè¨åºææ¬è½æçºæ¨æºåé«çä»£ç¢¼çéç¨ï¼æ¯ä¸é è³ééè¦çé«çä¿å¥å¯¦åï¼ä½èæè²»åãåç®¡å¤§åèªè¨æ¨¡å (LLM) å¯ä»¥èªååç·¨ç¢¼æµç¨ä¸¦æåæ­¤é¡ä»»åçæçï¼ä½å¯è§£éæ§å°æ¼ç¶­è­·æ£èä¿¡ä»»ä»ç¶è³ééè¦ãç®åå¨é«çç·¨ç¢¼æç¨ç¨å¼çå¯è§£éæ§æ¹é¢æåçåªåï¼æ¥µåº¦ä¾è³´æ¨ç±¤æ³¨ææ©å¶ï¼ééå¸¸æå°è´å¼·èª¿è ICD ä»£ç¢¼ç¡éçç¡éç¬¦èãçºäºä¿é²é«çèªè¨æ¨¡åçæºç¢ºå¯è§£éæ§ï¼æ¬æå©ç¨å­å¸å­¸ç¿ï¼å¯ä»¥ææå°å¾çå çç¨ å¯èªè¨æ¨¡ååµå¥ä¸­æåç¨çæ¿æ´»çè¡¨ç¤ºãèå¸¸è¦çæ¨ç±¤æ³¨ææ©å¶ç¸æ¯ï¼æåçæ¨¡åè¶è¶äºç¬¦èå±¤ç´çè¡¨ç¤ºï¼å»ºç«äºä¸åå¯è§£éçå­å¸ï¼å¢å¼·äºå°æ¯å ICD ä»£ç¢¼é æ¸¬çåºæ¼æ©å¶çè§£éï¼å³ä½¿å¼·èª¿çç¬¦èå¨é«å­¸ä¸ç¡éç·è¦ãæåè­æå­å¸ç¹å¾µå¯ä»¥å¼å°æ¨¡åè¡çºï¼é¡æ 90% ä»¥ä¸å¨é«å­¸ä¸ç¡éçç¬¦èçé±èæç¾©ï¼ä¸¦ä¸äººé¡å¯ä»¥è§£éã

##### **Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks**
2410.24032v1 by Yingzhe Peng, Xiaoting Qin, Zhiyang Zhang, Jue Zhang, Qingwei Lin, Xu Yang, Dongmei Zhang, Saravan Rajmohan, Qi Zhang

The rise of large language models (LLMs) has revolutionized user interactions
with knowledge-based systems, enabling chatbots to synthesize vast amounts of
information and assist with complex, exploratory tasks. However, LLM-based
chatbots often struggle to provide personalized support, particularly when
users start with vague queries or lack sufficient contextual information. This
paper introduces the Collaborative Assistant for Personalized Exploration
(CARE), a system designed to enhance personalization in exploratory tasks by
combining a multi-agent LLM framework with a structured user interface. CARE's
interface consists of a Chat Panel, Solution Panel, and Needs Panel, enabling
iterative query refinement and dynamic solution generation. The multi-agent
framework collaborates to identify both explicit and implicit user needs,
delivering tailored, actionable solutions. In a within-subject user study with
22 participants, CARE was consistently preferred over a baseline LLM chatbot,
with users praising its ability to reduce cognitive load, inspire creativity,
and provide more tailored solutions. Our findings highlight CARE's potential to
transform LLM-based systems from passive information retrievers to proactive
partners in personalized problem-solving and exploration.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çèèµ·å¾¹åºæ¹è®äºä½¿ç¨èèåºæ¼ç¥è­çç³»çµ±äºåçæ¹å¼ï¼è®èå¤©æ©å¨äººè½å¤ ç¶åå¤§éçè³è¨ï¼ä¸¦åå©é²è¡è¤éçæ¢ç´¢æ§ä»»åãç¶èï¼åºæ¼ LLM çèå¤©æ©å¨äººéå¸¸é£ä»¥æä¾åäººåçæ¯æ´ï¼ç¹å¥æ¯å¨ä½¿ç¨èä¸éå§æåºçæ¥è©¢å¾æ¨¡ç³ï¼æç¼ºä¹è¶³å¤ çèçµ¡è³è¨æãæ¬æä»ç´¹äºåäººåæ¢ç´¢çåä½å©ç (CARE)ï¼ä¸åæ¨å¨ééçµåå¤éä»£ç LLM æ¶æ§èçµæ§åçä½¿ç¨èä»é¢ä¾å¢å¼·æ¢ç´¢æ§ä»»åä¸­åäººåçç³»çµ±ãCARE çä»é¢åå«èå¤©é¢æ¿ãè§£æ±ºæ¹æ¡é¢æ¿åéæ±é¢æ¿ï¼å¯é²è¡åè¦çæ¥è©¢ç²¾çååæçè§£æ±ºæ¹æ¡ç¢çãå¤éä»£çæ¶æ§åä½è­å¥æç¢ºåé±å«çä½¿ç¨èéæ±ï¼æä¾å®¢è£½åä¸å¯è¡çè§£æ±ºæ¹æ¡ãå¨ä¸åæ 22 ä½åèèçåè©¦èå§ç ç©¶ä¸­ï¼CARE æçºç²å¾æ¯åºæº LLM èå¤©æ©å¨äººæ´å¥½çè©å¹ï¼ä½¿ç¨èè®è³å¶æ¸è¼èªç¥è² æãæ¿ç¼åµé åï¼ä»¥åæä¾æ´å®¢è£½åè§£æ±ºæ¹æ¡çè½åãæåçç¼ç¾çªé¡¯äº CARE å°åºæ¼ LLM çç³»çµ±å¾è¢«åçè³è¨æª¢ç´¢èè½è®çºåäººååé¡è§£æ±ºåæ¢ç´¢ä¸­çä¸»åå¤¥ä¼´çæ½åã

##### **Neural Network Verification with PyRAT**
2410.23903v1 by Augustin Lemesle, Julien Lehmann, Tristan Le Gall

As AI systems are becoming more and more popular and used in various critical
domains (health, transport, energy, ...), the need to provide guarantees and
trust of their safety is undeniable. To this end, we present PyRAT, a tool
based on abstract interpretation to verify the safety and the robustness of
neural networks. In this paper, we describe the different abstractions used by
PyRAT to find the reachable states of a neural network starting from its input
as well as the main features of the tool to provide fast and accurate analysis
of neural networks. PyRAT has already been used in several collaborations to
ensure safety guarantees, with its second place at the VNN-Comp 2024 showcasing
its performance.

æè¦ï¼é¨è AI ç³»çµ±è¶ä¾è¶æ®åï¼ä¸¦ç¨æ¼åç¨®ééµé åï¼å¥åº·ãéè¼¸ãè½æºï¼...ï¼ï¼æä¾å¶å®å¨ä¿è­åä¿¡ä»»çéæ±æ¯ä¸å®¹å¦èªçãçºæ­¤ï¼æåæåºäº PyRATï¼ä¸ååºæ¼æ½è±¡è©®éçå·¥å·ï¼ç¨æ¼é©è­ç¥ç¶ç¶²è·¯çå®å¨æ§åç©©å¥æ§ãå¨æ¬æä¸­ï¼æåæè¿°äº PyRAT ç¨æ¼å¾ç¥ç¶ç¶²è·¯è¼¸å¥ä¸­æ¾åºå¯éçæçä¸åæ½è±¡ï¼ä»¥åè©²å·¥å·çä¸»è¦åè½ï¼ä»¥æä¾å¿«éä¸æºç¢ºçç¥ç¶ç¶²è·¯åæãPyRAT å·²å¨å¤é åä½ä¸­ç¨æ¼ç¢ºä¿å®å¨ä¿è­ï¼å¶å¨ VNN-Comp 2024 ä¸­ç²å¾ç¬¬äºåï¼å±ç¤ºäºå¶æè½ã

##### **Counterfactual MRI Data Augmentation using Conditional Denoising Diffusion Generative Models**
2410.23835v1 by Pedro MorÃ£o, Joao Santinha, Yasna Forghani, Nuno LouÃ§Ã£o, Pedro Gouveia, Mario A. T. Figueiredo

Deep learning (DL) models in medical imaging face challenges in
generalizability and robustness due to variations in image acquisition
parameters (IAP). In this work, we introduce a novel method using conditional
denoising diffusion generative models (cDDGMs) to generate counterfactual
magnetic resonance (MR) images that simulate different IAP without altering
patient anatomy. We demonstrate that using these counterfactual images for data
augmentation can improve segmentation accuracy, particularly in
out-of-distribution settings, enhancing the overall generalizability and
robustness of DL models across diverse imaging conditions. Our approach shows
promise in addressing domain and covariate shifts in medical imaging. The code
is publicly available at https:
//github.com/pedromorao/Counterfactual-MRI-Data-Augmentation

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) æ¨¡åå¨é«å­¸å½±åä¸­æå å½±åæ·ååæ¸ (IAP) çè®åèé¢è¨å¯æ¦æ¬æ§åç©©å¥æ§çææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®ä½¿ç¨æ¢ä»¶å¼å»åªæ´æ£çææ¨¡å (cDDGMs) çæ°æ¹æ³ï¼ä»¥ç¢çåäºå¯¦ç£å±æ¯ (MR) å½±åï¼æ¨¡æ¬ä¸åç IAPï¼èä¸ææ¹è®æ£èçè§£åçµæ§ãæåè­æä½¿ç¨éäºåäºå¯¦å½±åé²è¡è³ææ´åå¯ä»¥æé«åå²æºç¢ºåº¦ï¼ç¹å¥æ¯å¨åä½å¤è¨­å®ä¸­ï¼å¢å¼· DL æ¨¡åå¨ä¸åå½±åæ¢ä»¶ä¸çæ´é«å¯æ¦æ¬æ§åç©©å¥æ§ãæåçåæ³é¡¯ç¤ºäºè§£æ±ºé«å­¸å½±åä¸­çé åååè®æ¸è½ç§»çåæ¯ãç¨å¼ç¢¼å·²å¬éæ¼ https:
//github.com/pedromorao/Counterfactual-MRI-Data-Augmentation

##### **Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding**
2410.23822v1 by Jinlong He, Pengfei Li, Gang Liu, Shenjun Zhong

Multimodal Large Language Models (MLLMs) inherit the superior text
understanding capabilities of LLMs and extend these capabilities to multimodal
scenarios. These models achieve excellent results in the general domain of
multimodal tasks. However, in the medical domain, the substantial training
costs and the requirement for extensive medical data pose challenges to the
development of medical MLLMs. Furthermore, due to the free-text form of
answers, tasks such as visual grounding that need to produce output in a
prescribed form become difficult for MLLMs. So far, there have been no medical
MLLMs works in medical visual grounding area. For the medical vision grounding
task, which involves identifying locations in medical images based on short
text descriptions, we propose Parameter-efficient Fine-tuning medical
multimodal large language models for Medcial Visual Grounding (PFMVG). To
validate the performance of the model, we evaluate it on a public benchmark
dataset for medical visual grounding, where it achieves competitive results,
and significantly outperforming GPT-4v. Our code will be open sourced after
peer review.

æè¦ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) ç»§æ¿äº LLM ä¼è¶çææ¬çè§£è½åï¼å¹¶å°è¿äºè½åæ©å±å°å¤æ¨¡æåºæ¯ãè¿äºæ¨¡åå¨å¤æ¨¡æä»»å¡çéç¨é¢åä¸­åå¾äºåºè²çææãç¶èï¼å¨å»å­¦é¢åï¼å¤§éçè®­ç»ææ¬åå¯¹å¹¿æ³å»å­¦æ°æ®çéæ±å¯¹å»å­¦ MLLM çåå±ææäºææãæ­¤å¤ï¼ç±äºç­æ¡çèªç±ææ¬å½¢å¼ï¼éè¦ä»¥è§å®å½¢å¼çæè¾åºçä»»å¡ï¼ä¾å¦è§è§åºç¡ï¼å¯¹äº MLLM æ¥è¯´åå¾å°é¾ãå°ç®åä¸ºæ­¢ï¼è¿æ²¡æå»å­¦ MLLM å¨å»å­¦è§è§åºç¡é¢åå·¥ä½ãå¯¹äºå»å­¦è§è§åºç¡ä»»å¡ï¼å®æ¶åæ ¹æ®ç®ç­çææ¬æè¿°è¯å«å»å­¦å¾åä¸­çä½ç½®ï¼æä»¬æåºäºç¨äºå»å­¦è§è§åºç¡çåæ°é«æå¾®è°å»å­¦å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (PFMVG)ãä¸ºäºéªè¯æ¨¡åçæ§è½ï¼æä»¬å¨å»å­¦è§è§åºç¡çå¬å±åºåæ°æ®éä¸å¯¹å¶è¿è¡äºè¯ä¼°ï¼å®åå¾äºæç«äºåçç»æï¼å¹¶ä¸ææ¾ä¼äº GPT-4vãæä»¬çä»£ç å°å¨åè¡è¯å®¡åå¼æºã

##### **Improving snore detection under limited dataset through harmonic/percussive source separation and convolutional neural networks**
2410.23796v1 by F. D. Gonzalez-Martinez, J. J. Carabias-Orti, F. J. Canadas-Quesada, N. Ruiz-Reyes, D. Martinez-Munoz, S. Garcia-Galan

Snoring, an acoustic biomarker commonly observed in individuals with
Obstructive Sleep Apnoea Syndrome (OSAS), holds significant potential for
diagnosing and monitoring this recognized clinical disorder. Irrespective of
snoring types, most snoring instances exhibit identifiable harmonic patterns
manifested through distinctive energy distributions over time. In this work, we
propose a novel method to differentiate monaural snoring from non-snoring
sounds by analyzing the harmonic content of the input sound using
harmonic/percussive sound source separation (HPSS). The resulting feature,
based on the harmonic spectrogram from HPSS, is employed as input data for
conventional neural network architectures, aiming to enhance snoring detection
performance even under a limited data learning framework. To evaluate the
performance of our proposal, we studied two different scenarios: 1) using a
large dataset of snoring and interfering sounds, and 2) using a reduced
training set composed of around 1% of the data material. In the former
scenario, the proposed HPSS-based feature provides competitive results compared
to other input features from the literature. However, the key advantage of the
proposed method lies in the superior performance of the harmonic spectrogram
derived from HPSS in a limited data learning context. In this particular
scenario, using the proposed harmonic feature significantly enhances the
performance of all the studied architectures in comparison to the classical
input features documented in the existing literature. This finding clearly
demonstrates that incorporating harmonic content enables more reliable learning
of the essential time-frequency characteristics that are prevalent in most
snoring sounds, even in scenarios where the amount of training data is limited.

æè¦ï¼é¼¾è²æ¯ä¸ç¨®å¨é»å¡æ§ç¡ç å¼å¸ä¸­æ­¢çåç¾¤ (OSAS) æ£èä¸­å¸¸è¦çè²å­¸çç©æ¨è¨ï¼å°æ¼è¨ºæ·åç£æ§æ­¤å¬èªçè¨åºç¾çå·æé¡¯èæ½åãç¡è«é¼¾è²é¡åå¦ä½ï¼å¤§å¤æ¸é¼¾è²é½è¡¨ç¾åºå¯è­å¥çè«§æ³¢æ¨¡å¼ï¼ä¸¦é¨èæéæ¨ç§»è¡¨ç¾åºç¨ç¹çè½éåä½ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼ééä½¿ç¨è«§æ³¢/ææè²æºåé¢ (HPSS) åæè¼¸å¥è²é³çè«§æ³¢å§å®¹ï¼å°å®è²éé¼¾è²èéé¼¾è²ååéä¾ãåºæ¼ HPSS çè«§æ³¢é »è­åæç¢ççç¹å¾µï¼è¢«ç¨ä½å³çµ±ç¥ç¶ç¶²è·¯æ¶æ§çè¼¸å¥è³æï¼æ¨å¨å³ä½¿å¨æéè³æå­¸ç¿æ¶æ§ä¸ä¹è½å¢å¼·é¼¾è²åµæ¸¬æè½ãçºäºè©ä¼°æåææ¡çæè½ï¼æåç ç©¶äºå©ç¨®ä¸åçæå¢ï¼1) ä½¿ç¨å¤§éçé¼¾è²åå¹²æ¾è²è³æéï¼ä»¥å 2) ä½¿ç¨ç±ç´ 1% è³æç´ æçµæçç¸®æ¸è¨ç·´éãå¨åä¸ç¨®æå¢ä¸­ï¼èæç»ä¸­çå¶ä»è¼¸å¥ç¹å¾µç¸æ¯ï¼ææåºçåºæ¼ HPSS çç¹å¾µæä¾äºå·æç«¶ç­åççµæãç¶èï¼ææåºæ¹æ³çä¸»è¦åªé»å¨æ¼ï¼å¨æéè³æå­¸ç¿æå¢ä¸­ï¼æºèª HPSS çè«§æ³¢é »è­åå·æåªç°çæè½ãå¨éåç¹å®æå¢ä¸­ï¼èç¾ææç»ä¸­è¨è¼çå³çµ±è¼¸å¥ç¹å¾µç¸æ¯ï¼ä½¿ç¨ææåºçè«§æ³¢ç¹å¾µé¡¯èå¢å¼·äºææç ç©¶æ¶æ§çæè½ãéä¸ç¼ç¾æ¸æ¥å°è¡¨æï¼å³ä½¿å¨è¨ç·´è³æéæéçæå¢ä¸­ï¼ç´å¥è«§æ³¢å§å®¹ä¹è½å¤ æ´å¯é å°å­¸ç¿å¤§å¤æ¸é¼¾è²ä¸­æ®éå­å¨çå¿è¦æé »ç¹å¾µã

##### **The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams**
2410.23769v1 by Yunqi Zhu, Wen Tang, Ying Sun, Xuebing Yang

Recent research on large language models (LLMs) has primarily focused on
their adaptation and application in specialized domains. The application of
LLMs in the medical field is mainly concentrated on tasks such as the
automation of medical report generation, summarization, diagnostic reasoning,
and question-and-answer interactions between doctors and patients. The
challenge of becoming a good teacher is more formidable than that of becoming a
good student, and this study pioneers the application of LLMs in the field of
medical education. In this work, we investigate the extent to which LLMs can
generate medical qualification exam questions and corresponding answers based
on few-shot prompts. Utilizing a real-world Chinese dataset of elderly chronic
diseases, we tasked the LLMs with generating open-ended questions and answers
based on a subset of sampled admission reports across eight widely used LLMs,
including ERNIE 4, ChatGLM 4, Doubao, Hunyuan, Spark 4, Qwen, Llama 3, and
Mistral. Furthermore, we engaged medical experts to manually evaluate these
open-ended questions and answers across multiple dimensions. The study found
that LLMs, after using few-shot prompts, can effectively mimic real-world
medical qualification exam questions, whereas there is room for improvement in
the correctness, evidence-based statements, and professionalism of the
generated answers. Moreover, LLMs also demonstrate a decent level of ability to
correct and rectify reference answers. Given the immense potential of
artificial intelligence in the medical field, the task of generating questions
and answers for medical qualification exams aimed at medical students, interns
and residents can be a significant focus of future research.

æè¦ï¼<paragraph>éå°å¤§åèªè¨æ¨¡å (LLM) çè¿æç ç©¶ä¸»è¦éä¸­å¨å®åå¨ç¹å®é åçé©æåæç¨ãLLM å¨é«å­¸é åçæç¨ä¸»è¦éä¸­å¨èªååçæ­·ç¢çãæè¦ãè¨ºæ·æ¨çä»¥åé«çèçäººä¹éåç­äºåç­ä»»åãæçºä¸åå¥½èå¸«çææ°æ¯æçºä¸åå¥½å­¸çæ´è±éï¼èæ¬ç ç©¶éåµäº LLM å¨é«å­¸æè²é åçæç¨ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äº LLM å¨å°æ¸æç¤ºä¸ç¢çé«å­¸è³æ ¼èè©¦é¡ç®åå°æç­æ¡çç¨åº¦ãå©ç¨ä¸åçå¯¦ä¸ççèå¹´æ¢æ§ç¾çä¸­ææ¸æéï¼æåè® LLM æ ¹æå«åå»£æ³ä½¿ç¨ç LLMï¼åæ¬ ERNIE 4ãChatGLM 4ãè±åãæ··åãSpark 4ãQwenãLlama 3 å Mistralï¼æ½åçå¥é¢å ±åå­éç¢çéæ¾å¼åé¡åç­æ¡ãæ­¤å¤ï¼æåèè«é«å­¸å°å®¶æåè©ä¼°éäºéæ¾å¼åé¡åç­æ¡çå¤åé¢åãç ç©¶ç¼ç¾ï¼LLM å¨ä½¿ç¨å°æ¸æç¤ºå¾ï¼å¯ä»¥æææ¨¡æ¬çå¯¦ä¸ççé«å­¸è³æ ¼èè©¦é¡ç®ï¼èç¢ççç­æ¡å¨æ­£ç¢ºæ§ãå¾ªè­é³è¿°åå°æ¥­æ§æ¹é¢ä»ææ¹é²ç©ºéãæ­¤å¤ï¼LLM ä¹å±ç¾åºç¸ç¶ç¨åº¦æ´æ­£åä¿®æ­£åèç­æ¡çè½åãéæ¼äººå·¥æºè½å¨é«å­¸é åçå·¨å¤§æ½åï¼ç¢çéå°é«å­¸çãå¯¦ç¿é«çåä½é¢é«ççé«å­¸è³æ ¼èè©¦é¡ç®åç­æ¡çä»»åï¼å¯ä»¥æçºæªä¾ç ç©¶çéè¦éé»ã</paragraph>

##### **Artificial intelligence to improve clinical coding practice in Scandinavia: a crossover randomized controlled trial**
2410.23725v1 by Taridzo Chomutare, Therese Olsen Svenning, Miguel Ãngel Tejedor HernÃ¡ndez, Phuong Dinh Ngo, Andrius Budrionis, Kaisa Markljung, Lill Irene Hind, TorbjÃ¸rn Torsvik, Karl Ãyvind Mikalsen, Aleksandar Babic, Hercules Dalianis

\textbf{Trial design} Crossover randomized controlled trial. \textbf{Methods}
An AI tool, Easy-ICD, was developed to assist clinical coders and was tested
for improving both accuracy and time in a user study in Norway and Sweden.
Participants were randomly assigned to two groups, and crossed over between
coding complex (longer) texts versus simple (shorter) texts, while using our
tool versus not using our tool. \textbf{Results} Based on Mann-Whitney U test,
the median coding time difference for complex clinical text sequences was 123
seconds (\emph{P}\textless.001, 95\% CI: 81 to 164), representing a 46\%
reduction in median coding time when our tool is used. There was no significant
time difference for simpler text sequences. For coding accuracy, the
improvement we noted for both complex and simple texts was not significant.
\textbf{Conclusions} This study demonstrates the potential of AI to transform
common tasks in clinical workflows, with ostensible positive impacts on work
efficiencies for complex clinical coding tasks. Further studies within hospital
workflows are required before these presumed impacts can be more clearly
understood.

æè¦ï¼**è©¦é©è¨­è¨** äº¤åé¨æ©å°ç§è©¦é©ã**æ¹æ³**éç¼äºä¸ç¨® AI å·¥å· Easy-ICDï¼ä»¥åå©è¨åºç·¨ç¢¼å¡ï¼ä¸¦å¨æªå¨åçå¸é²è¡çä¸é ä½¿ç¨èç ç©¶ä¸­æ¸¬è©¦å¶å¨æºç¢ºæ§åæéä¸çæ¹é²ãåèèè¢«é¨æ©åçºå©çµï¼ä¸¦å¨ä½¿ç¨æåçå·¥å·èä¸ä½¿ç¨æåçå·¥å·çææ³ä¸ï¼å°è¤éï¼è¼é·ï¼ææ¬èç°¡å®ï¼è¼ç­ï¼ææ¬é²è¡ç·¨ç¢¼äº¤åã**çµæ**æ ¹æ Mann-Whitney U æª¢å®ï¼è¤éè¨åºææ¬åºåçä¸­ä½æ¸ç·¨ç¢¼æéå·®çº 123 ç§ï¼\emph{P}\textless.001ï¼95% CIï¼81 è³ 164ï¼ï¼è¡¨ç¤ºä½¿ç¨æåçå·¥å·æä¸­ä½æ¸ç·¨ç¢¼æéæ¸å°äº 46%ãå°æ¼è¼ç°¡å®çææ¬åºåï¼æ²æé¡¯èçæéå·®ç°ãå°æ¼ç·¨ç¢¼æºç¢ºæ§ï¼æåå°è¤éææ¬åç°¡å®ææ¬æè§å¯å°çæ¹é²ä¸¦ä¸é¡¯èã**çµè«**éé ç ç©¶å±ç¤ºäº AI å¨è½æè¨åºå·¥ä½æµç¨ä¸­å¸¸è¦ä»»åçæ½åï¼å°è¤éè¨åºç·¨ç¢¼ä»»åçå·¥ä½æçææé¡¯çæ­£é¢å½±é¿ãå¨éäºåè¨­å½±é¿è½æ´æ¸æ¥å°è¢«çè§£ä¹åï¼éè¦å¨é«é¢å·¥ä½æµç¨ä¸­é²è¡é²ä¸æ­¥çç ç©¶ã

##### **Enhancing Brain Tumor Classification Using TrAdaBoost and Multi-Classifier Deep Learning Approaches**
2411.00875v1 by Mahin Mohammadi, Saman Jamshidi

Brain tumors pose a serious health threat due to their rapid growth and
potential for metastasis. While medical imaging has advanced significantly,
accurately identifying and characterizing these tumors remains a challenge.
This study addresses this challenge by leveraging the innovative TrAdaBoost
methodology to enhance the Brain Tumor Segmentation (BraTS2020) dataset, aiming
to improve the efficiency and accuracy of brain tumor classification. Our
approach combines state-of-the-art deep learning algorithms, including the
Vision Transformer (ViT), Capsule Neural Network (CapsNet), and convolutional
neural networks (CNNs) such as ResNet-152 and VGG16. By integrating these
models within a multi-classifier framework, we harness the strengths of each
approach to achieve more robust and reliable tumor classification. A novel
decision template is employed to synergistically combine outputs from different
algorithms, further enhancing classification accuracy. To augment the training
process, we incorporate a secondary dataset, "Brain Tumor MRI Dataset," as a
source domain, providing additional data for model training and improving
generalization capabilities. Our findings demonstrate a high accuracy rate in
classifying tumor versus non-tumor images, signifying the effectiveness of our
approach in the medical imaging domain. This study highlights the potential of
advanced machine learning techniques to contribute significantly to the early
and accurate diagnosis of brain tumors, ultimately improving patient outcomes.

æè¦ï¼è¦ç¤ç±æ¼çé·å¿«éä¸æè½ç§»çå¯è½æ§ï¼å°å¥åº·æ§æå´éå¨èãéç¶é«å­¸å½±åæè¡å·²å¤§å¹é²æ­¥ï¼ä½ç²¾æºè¾¨è­åæè¿°éäºè«ç¤ä»ç¶æ¯ä¸å¤§ææ°ãæ¬ç ç©¶éééç¨åµæ°ç TrAdaBoost æ¹æ³æåè¦ç¤åå² (BraTS2020) è³æéä¾è§£æ±ºéåææ°ï¼ç®æ¨æ¯æåè¦ç¤åé¡çæçåæºç¢ºåº¦ãæåçåæ³çµåäºæåé²çæ·±åº¦å­¸ç¿æ¼ç®æ³ï¼åæ¬è¦è¦ºè½æå¨ (ViT)ãè åç¥ç¶ç¶²è·¯ (CapsNet) åå·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ä¾å¦ ResNet-152 å VGG16ãééå¨å¤åé¡å¨æ¶æ§ä¸­æ´åéäºæ¨¡åï¼æåå©ç¨æ¯ç¨®æ¹æ³çåªé»ä¾éææ´å¼·å¥ä¸å¯é çè«ç¤åé¡ãæ¡ç¨æ°ç©çæ±ºç­ç¯æ¬ï¼ä»¥ç¶æçµåä¸åæ¼ç®æ³çè¼¸åºï¼é²ä¸æ­¥æååé¡æºç¢ºåº¦ãçºäºæ´åè¨ç·´æµç¨ï¼æåç´å¥æ¬¡è¦è³æéãè¦ç¤ MRI è³æéãä½çºä¾æºç¶²åï¼æä¾é¡å¤çè³æç¨æ¼æ¨¡åè¨ç·´ï¼ä¸¦æåæ¦åè½åãæåçç ç©¶çµæé¡¯ç¤ºï¼å¨åé¡è«ç¤èéè«ç¤å½±åæï¼æºç¢ºçå¾é«ï¼è¡¨ç¤ºæåçæ¹æ³å¨é«å­¸å½±åé åä¸­å¾ææãæ¬ç ç©¶å¼·èª¿é²éæ©å¨å­¸ç¿æè¡çæ½åï¼å°è¦ç¤çæ©æä¸ç²¾æºè¨ºæ·æé¡¯èè²¢ç»ï¼é²èæ¹åçæ£çæ²»ççµæã

##### **Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction**
2410.23649v1 by Guan-Hua Huang, Wan-Chen Lai, Tai-Been Chen, Chien-Chin Hsu, Huei-Yung Chen, Yi-Chen Wu, Li-Ren Yeh

Parkinson's disease (PD), a degenerative disorder of the central nervous
system, is commonly diagnosed using functional medical imaging techniques such
as single-photon emission computed tomography (SPECT). In this study, we
utilized two SPECT data sets (n = 634 and n = 202) from different hospitals to
develop a model capable of accurately predicting PD stages, a multiclass
classification task. We used the entire three-dimensional (3D) brain images as
input and experimented with various model architectures. Initially, we treated
the 3D images as sequences of two-dimensional (2D) slices and fed them
sequentially into 2D convolutional neural network (CNN) models pretrained on
ImageNet, averaging the outputs to obtain the final predicted stage. We also
applied 3D CNN models pretrained on Kinetics-400. Additionally, we incorporated
an attention mechanism to account for the varying importance of different
slices in the prediction process. To further enhance model efficacy and
robustness, we simultaneously trained the two data sets using weight sharing, a
technique known as cotraining. Our results demonstrated that 2D models
pretrained on ImageNet outperformed 3D models pretrained on Kinetics-400, and
models utilizing the attention mechanism outperformed both 2D and 3D models.
The cotraining technique proved effective in improving model performance when
the cotraining data sets were sufficiently large.

æè¦ï¼å¸éæ£®æ°ç (PD) æ¯ä¸ç¨®ä¸­æ¨ç¥ç¶ç³»çµ±éåæ§ç¾çï¼éå¸¸ä½¿ç¨åè½æ§é«å­¸å½±åæè¡ï¼ä¾å¦å®åå­ç¼å°æ·å±¤ææ (SPECT) ä¾è¨ºæ·ãå¨éé ç ç©¶ä¸­ï¼æåå©ç¨ä¾èªä¸åé«é¢çå©å SPECT è³æé (n = 634 å n = 202) ä¾éç¼ä¸åæ¨¡åï¼è½å¤ æºç¢ºé æ¸¬ PD åæï¼éæ¯ä¸åå¤é¡å¥åé¡ä»»åãæåä½¿ç¨æ´åä¸ç¶­ (3D) å¤§è¦å½±åä½çºè¼¸å¥ï¼ä¸¦åè©¦ä½¿ç¨åç¨®æ¨¡åæ¶æ§ãæåï¼æåå° 3D å½±åè¦çºäºç¶­ (2D) åççåºåï¼ä¸¦å°å®åä¾åºè¼¸å¥å°é åå¨ ImageNet ä¸è¨ç·´éç 2D å·ç©ç¥ç¶ç¶²è·¯ (CNN) æ¨¡åä¸­ï¼åå¹³åè¼¸åºå¼ä¾åå¾æçµé æ¸¬çæå¥ãæåä¹æç¨é åå¨ Kinetics-400 ä¸è¨ç·´éç 3D CNN æ¨¡åãæ­¤å¤ï¼æåç´å¥ä¸åæ³¨æåæ©å¶ï¼ä»¥èéä¸ååçå¨é æ¸¬éç¨ä¸­çéè¦æ§å·®ç°ãçºäºé²ä¸æ­¥å¢å¼·æ¨¡åçæè½åç©©å¥æ§ï¼æåä½¿ç¨æ¬éå±äº«åæè¨ç·´å©åè³æéï¼éæ¯ä¸ç¨®ç¨±çºå±åè¨ç·´çæè¡ãæåççµæé¡¯ç¤ºï¼é åå¨ ImageNet ä¸è¨ç·´éç 2D æ¨¡ååªæ¼é åå¨ Kinetics-400 ä¸è¨ç·´éç 3D æ¨¡åï¼èä½¿ç¨æ³¨æåæ©å¶çæ¨¡åååªæ¼ 2D å 3D æ¨¡åãç¶å±åè¨ç·´çè³æéå¤ å¤§çæåï¼å±åè¨ç·´æè¡å·²è¢«è­æè½æææ¹åæ¨¡åæè½ã

##### **MS-Glance: Non-semantic context vectors and the applications in supervising image reconstruction**
2410.23577v1 by Ziqi Gao, Wendi Yang, Yujia Li, Lei Xing, S. Kevin Zhou

Non-semantic context information is crucial for visual recognition, as the
human visual perception system first uses global statistics to process scenes
rapidly before identifying specific objects. However, while semantic
information is increasingly incorporated into computer vision tasks such as
image reconstruction, non-semantic information, such as global spatial
structures, is often overlooked. To bridge the gap, we propose a biologically
informed non-semantic context descriptor, \textbf{MS-Glance}, along with the
Glance Index Measure for comparing two images. A Global Glance vector is
formulated by randomly retrieving pixels based on a perception-driven rule from
an image to form a vector representing non-semantic global context, while a
local Glance vector is a flattened local image window, mimicking a zoom-in
observation. The Glance Index is defined as the inner product of two
standardized sets of Glance vectors. We evaluate the effectiveness of
incorporating Glance supervision in two reconstruction tasks: image fitting
with implicit neural representation (INR) and undersampled MRI reconstruction.
Extensive experimental results show that MS-Glance outperforms existing image
restoration losses across both natural and medical images. The code is
available at \url{https://github.com/Z7Gao/MSGlance}.

æè¦ï¼éè¯­ä¹ä¸ä¸æä¿¡æ¯å¯¹äºè§è§è¯å«è³å³éè¦ï¼å ä¸ºäººç±»è§è§æç¥ç³»ç»é¦åä½¿ç¨å¨å±ç»è®¡æ°æ®æ¥å¿«éå¤çåºæ¯ï¼ç¶ååè¯å«ç¹å®å¯¹è±¡ãç¶èï¼è½ç¶è¯­ä¹ä¿¡æ¯æ­£è¶æ¥è¶å¤å°èå¥å°å¾åéå»ºç­è®¡ç®æºè§è§ä»»å¡ä¸­ï¼ä½éè¯­ä¹ä¿¡æ¯ï¼å¦å¨å±ç©ºé´ç»æï¼å´å¸¸å¸¸è¢«å¿½è§ãä¸ºäºå¼¥åè¿ä¸å·®è·ï¼æä»¬æåºäºä¸ä¸ªçç©ä¿¡æ¯å¯åçéè¯­ä¹ä¸ä¸ææè¿°ç¬¦ï¼å³ \textbf{MS-Glance}ï¼ä»¥åç¨äºæ¯è¾ä¸¤å¹å¾åç Glance ææ°åº¦éãéè¿æ ¹æ®æç¥é©±å¨çè§åä»å¾åä¸­éæºæ£ç´¢åç´ æ¥æå»ºä¸ä¸ªå¨å± Glance åéï¼ä»¥å½¢æä¸ä¸ªè¡¨ç¤ºéè¯­ä¹å¨å±ä¸ä¸æçåéï¼èå±é¨ Glance åéæ¯ä¸ä¸ªæå¹³çå±é¨å¾åçªå£ï¼æ¨¡ä»¿äºæ¾å¤§è§å¯ãGlance ææ°è¢«å®ä¹ä¸ºä¸¤ç»æ ååç Glance åéçåç§¯ãæä»¬è¯ä¼°äºå¨ä¸¤ä¸ªéå»ºä»»å¡ä¸­çº³å¥ Glance çç£çæææ§ï¼å·æéå¼ç¥ç»è¡¨å¾ (INR) çå¾åæååæ¬ éæ · MRI éå»ºãå¤§éçå®éªç»æè¡¨æï¼MS-Glance å¨èªç¶å¾ååå»å­¦å¾åä¸­é½ä¼äºç°æçå¾åæ¢å¤æå¤±ãä»£ç å¯å¨ \url{https://github.com/Z7Gao/MSGlance} è·å¾ã

##### **LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models**
2410.23526v1 by Hieu Tran, Junda Wang, Yujan Ting, Weijing Huang, Terrence Chen

Large language models (LLMs) have shown remarkable capabilities in various
natural language processing tasks, yet they often struggle with maintaining
factual accuracy, particularly in knowledge-intensive domains like healthcare.
This study introduces LEAF: Learning and Evaluation Augmented by Fact-Checking,
a novel approach designed to enhance the factual reliability of LLMs, with a
focus on medical question answering (QA). LEAF utilizes a dual strategy to
enhance the factual accuracy of responses from models such as Llama 3 70B
Instruct and Llama 3 8B Instruct. The first strategy, Fact-Check-Then-RAG,
improves Retrieval-Augmented Generation (RAG) by incorporating fact-checking
results to guide the retrieval process without updating model parameters. The
second strategy, Learning from Fact-Checks via Self-Training, involves
supervised fine-tuning (SFT) on fact-checked responses or applying Simple
Preference Optimization (SimPO) with fact-checking as a ranking mechanism, both
updating LLM parameters from supervision. These findings suggest that
integrating fact-checked responses whether through RAG enhancement or
self-training enhances the reliability and factual correctness of LLM outputs,
offering a promising solution for applications where information accuracy is
crucial.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èçä»»åä¸­å±ç¾åºåè¶çè½åï¼ç¶èå®åå¨ç¶­æäºå¯¦æºç¢ºæ§æ¹é¢å¸¸å¸¸é¢è¨å°é£ï¼ç¹å¥æ¯å¨åé«çä¿å¥éæ¨£çç¥è­å¯éé åãæ¬ç ç©¶å¼å¥äº LEAFï¼ééäºå¯¦æ¥æ ¸å¢å¼·çå­¸ç¿èè©ä¼°ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨å¨æå LLM çäºå¯¦å¯é æ§ï¼ä¸¦å°æ³¨æ¼é«çåé¡è§£ç­ (QA)ãLEAF å©ç¨ééç­ç¥ä¾æå LLM åæçäºå¯¦æºç¢ºæ§ï¼ä¾å¦ Llama 3 70B Instruct å Llama 3 8B Instructãç¬¬ä¸ç¨®ç­ç¥ Fact-Check-Then-RAGï¼ééæ´åäºå¯¦æ¥æ ¸çµæä¾æ¹é²æª¢ç´¢å¢å¼·çæ (RAG)ï¼ä»¥å¼å°æª¢ç´¢ç¨åºï¼èä¸ææ´æ°æ¨¡ååæ¸ãç¬¬äºç¨®ç­ç¥ééèªæè¨ç·´å­¸ç¿äºå¯¦æ¥æ ¸ï¼æ¶åéå°ç¶éäºå¯¦æ¥æ ¸çåæé²è¡ç£ç£å¾®èª¿ (SFT)ï¼æå°ç°¡å®åå¥½æä½³å (SimPO) æç¨æ¼äºå¯¦æ¥æ ¸ä½çºæåæ©å¶ï¼éå©ç¨®æ¹æ³é½æå¾ç£ç£ä¸­æ´æ° LLM åæ¸ãéäºç¼ç¾è¡¨æï¼ç¡è«æ¯éé RAG å¢å¼·æèªæè¨ç·´ï¼æ´åç¶éäºå¯¦æ¥æ ¸çåæï¼é½è½æå LLM è¼¸åºçå¯é æ§åäºå¯¦æ­£ç¢ºæ§ï¼çºè³è¨æºç¢ºæ§è³ééè¦çæç¨ç¨å¼æä¾äºä¸åæåæ¯çè§£æ±ºæ¹æ¡ã

##### **Emory Knee Radiograph (MRKR) Dataset**
2411.00866v1 by Brandon Price, Jason Adleberg, Kaesha Thomas, Zach Zaiman, Aawez Mansuri, Beatrice Brown-Mulry, Chima Okecheukwu, Judy Gichoya, Hari Trivedi

The Emory Knee Radiograph (MRKR) dataset is a large, demographically diverse
collection of 503,261 knee radiographs from 83,011 patients, 40% of which are
African American. This dataset provides imaging data in DICOM format along with
detailed clinical information, including patient-reported pain scores,
diagnostic codes, and procedural codes, which are not commonly available in
similar datasets. The MRKR dataset also features imaging metadata such as image
laterality, view type, and presence of hardware, enhancing its value for
research and model development. MRKR addresses significant gaps in existing
datasets by offering a more representative sample for studying osteoarthritis
and related outcomes, particularly among minority populations, thereby
providing a valuable resource for clinicians and researchers.

æè¦ï¼åé»éèé¨ X åç (MRKR) è³æéæ¯ä¸åé¾å¤§ãäººå£çµ±è¨è³æå¤åçè³æéï¼åå«ä¾èª 83,011 åæ£èç 503,261 å¼µèé¨ X åçï¼å¶ä¸­ 40% çºéè£ç¾åäººãæ­¤è³æéæä¾ DICOM æ ¼å¼çå½±åè³æï¼ä»¥åè©³ç´°çè¨åºè³è¨ï¼åæ¬æ£èåå ±çç¼çè©åãè¨ºæ·ç¢¼åç¨åºç¢¼ï¼éäºè³æå¨é¡ä¼¼çè³æéä¸­ä¸¦ä¸å¸¸è¦ãMRKR è³æéä¹åå«å½±åçå¾è¨­è³æï¼ä¾å¦å½±åçå·¦å³å´ãæª¢è¦é¡ååç¡¬é«çå­å¨ï¼æåå¶å¨ç ç©¶åæ¨¡åéç¼æ¹é¢çå¹å¼ãMRKR ééæä¾æ´å·ä»£è¡¨æ§çæ¨£æ¬ï¼ä¾æ¢è¨éª¨éç¯çåç¸éçµæï¼ç¹å¥æ¯å¨å°æ¸æç¾¤ä¸­ï¼å¾èå¡«è£ç¾æè³æéä¸­é¡¯èçç¼ºå£ï¼çºè¨åºé«çåç ç©¶äººå¡æä¾æå¹å¼çè³æºã

##### **STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG**
2410.23386v1 by Raquel FernÃ¡ndez-MartÃ­n, Alfonso GijÃ³n, Odile Feys, Elodie JuvenÃ©, Alec Aeby, Charline Urbain, Xavier De TiÃ¨ge, Vincent Wens

Magnetoencephalography (MEG) allows the non-invasive detection of interictal
epileptiform discharges (IEDs). Clinical MEG analysis in epileptic patients
traditionally relies on the visual identification of IEDs, which is time
consuming and partially subjective. Automatic, data-driven detection methods
exist but show limited performance. Still, the rise of deep learning (DL)-with
its ability to reproduce human-like abilities-could revolutionize clinical MEG
practice. Here, we developed and validated STIED, a simple yet powerful
supervised DL algorithm combining two convolutional neural networks with
temporal (1D time-course) and spatial (2D topography) features of MEG signals
inspired from current clinical guidelines. Our DL model enabled both temporal
and spatial localization of IEDs in patients suffering from focal epilepsy with
frequent and high amplitude spikes (FE group), with high-performance
metrics-accuracy, specificity, and sensitivity all exceeding 85%-when learning
from spatiotemporal features of IEDs. This performance can be attributed to our
handling of input data, which mimics established clinical MEG practice. Reverse
engineering further revealed that STIED encodes fine spatiotemporal features of
IEDs rather than their mere amplitude. The model trained on the FE group also
showed promising results when applied to a separate group of presurgical
patients with different types of refractory focal epilepsy, though further work
is needed to distinguish IEDs from physiological transients. This study paves
the way of incorporating STIED and DL algorithms into the routine clinical MEG
evaluation of epilepsy.

æè¦ï¼è¦ç£åï¼MEGï¼åè¨±å°ç¼ä½éæç²çæ¨£æ¾é»ï¼IEDï¼é²è¡éä¾µå¥æ§æª¢æ¸¬ãç²çæ£èçè¨åº MEG åæå³çµ±ä¸ä¾è³´æ¼ IED çè¦è¦ºè­å¥ï¼éæ¢èæåé¨åä¸»è§ãèªååãæ¸æé©åçæª¢æ¸¬æ¹æ³å­å¨ï¼ä½é¡¯ç¤ºæ§è½æéãåç®¡å¦æ­¤ï¼æ·±åº¦å­¸ç¿ (DL) çèèµ·ââå®å·æè¤è£½é¡äººè½åçè½åââå¯ä»¥å¾¹åºæ¹è®è¨åº MEG å¯¦è¸ãå¨éè£¡ï¼æåéç¼ä¸¦é©è­äº STIEDï¼éæ¯ä¸ç¨®ç°¡å®ä½å¼·å¤§çç£ç£å¼ DL æ¼ç®æ³ï¼å®çµåäºå©åå·ç©ç¥ç¶ç¶²è·¯ï¼å·æ MEG è¨èçæéï¼1D æééç¨ï¼åç©ºéï¼2D å°å½¢ï¼ç¹å¾µï¼éæä¾èªç¶åçè¨åºæåãæåç DL æ¨¡åè½å¤ å°æ£æå±ç¶æ§ç²çä¸å°å³°é »ç¹ä¸æ¯å¹é«çæ£èï¼FE çµï¼ä¸­ç IED é²è¡æéåç©ºéå®ä½ï¼ä¸¦å·æé«æ§è½ææ¨ââæºç¢ºåº¦ãç¹ç°æ§åæææ§åè¶é 85%ââå¾ IED çæç©ºç¹å¾µä¸­å­¸ç¿ãéç¨®æ§è½å¯ä»¥æ­¸å æ¼æåå°è¼¸å¥è³æçèçï¼å®æ¨¡æ¬äºæ¢å®çè¨åº MEG å¯¦åãéåå·¥ç¨é²ä¸æ­¥æ­ç¤º STIED ç·¨ç¢¼äº IED çç²¾ç´°æç©ºç¹å¾µï¼èä¸æ¯å®åçå®ç´æ¯å¹ãå¨ FE çµä¸è¨ç·´çæ¨¡åå¨æç¨æ¼å¦ä¸çµæ£æä¸åé¡åé£æ²»æ§å±ç¶æ§ç²ççè¡åæ£èæä¹é¡¯ç¤ºåºæå¸æççµæï¼åç®¡éè¦é²ä¸æ­¥çå·¥ä½ä¾åå IED åççæ§æ«æãéé ç ç©¶çºå° STIED å DL æ¼ç®æ³ç´å¥ç²ççå¸¸è¦è¨åº MEG è©ä¼°éªå¹³äºéè·¯ã

##### **Larger models yield better results? Streamlined severity classification of ADHD-related concerns using BERT-based knowledge distillation**
2411.00052v1 by Ahmed Akib Jawad Karim, Kazi Hafiz Md. Asad, Md. Golam Rabiul Alam

This work focuses on the efficiency of the knowledge distillation approach in
generating a lightweight yet powerful BERT based model for natural language
processing applications. After the model creation, we applied the resulting
model, LastBERT, to a real-world task classifying severity levels of Attention
Deficit Hyperactivity Disorder (ADHD)-related concerns from social media text
data. Referring to LastBERT, a customized student BERT model, we significantly
lowered model parameters from 110 million BERT base to 29 million, resulting in
a model approximately 73.64% smaller. On the GLUE benchmark, comprising
paraphrase identification, sentiment analysis, and text classification, the
student model maintained strong performance across many tasks despite this
reduction. The model was also used on a real-world ADHD dataset with an
accuracy and F1 score of 85%. When compared to DistilBERT (66M) and
ClinicalBERT (110M), LastBERT demonstrated comparable performance, with
DistilBERT slightly outperforming it at 87%, and ClinicalBERT achieving 86%
across the same metrics. These findings highlight the LastBERT model's capacity
to classify degrees of ADHD severity properly, so it offers a useful tool for
mental health professionals to assess and comprehend material produced by users
on social networking platforms. The study emphasizes the possibilities of
knowledge distillation to produce effective models fit for use in
resource-limited conditions, hence advancing NLP and mental health diagnosis.
Furthermore underlined by the considerable decrease in model size without
appreciable performance loss is the lower computational resources needed for
training and deployment, hence facilitating greater applicability. Especially
using readily available computational tools like Google Colab. This study shows
the accessibility and usefulness of advanced NLP methods in pragmatic world
applications.

æè¦ï¼<paragraph>æ¬ç ç©¶éé»å¨æ¼ç¥è­èåæ¹æ³å¨ç¢çè¼éç´ä¸å¼·å¤§çåºæ¼ BERT çæ¨¡åä»¥ç¨æ¼èªç¶èªè¨èçæç¨æ¹é¢çæçãå¨æ¨¡åå»ºç«å¾ï¼æåå°ç¢ççæ¨¡å LastBERT æç¨æ¼ä¸åçå¯¦ä¸ççä»»åï¼å³å¾ç¤¾ç¾¤åªé«æå­è³æä¸­åé¡æ³¨æåä¸è¶³éåç (ADHD) ç¸éåé¡çå´éç¨åº¦å±¤ç´ãæå° LastBERTï¼ä¸åå®¢è£½åçå­¸ç BERT æ¨¡åï¼æåå¤§å¹éä½äºæ¨¡ååæ¸ï¼å¾ 1.1 åå BERT åºåºæ¸å°è³ 2900 è¬åï¼å°è´æ¨¡åç¸®å°äºå¤§ç´ 73.64%ãå¨ GLUE åºæºï¼åæ¬åç¾©å¥è¾¨è­ãæç·åæåæå­åé¡ï¼åç®¡ææ­¤ç¸®æ¸ï¼å­¸çæ¨¡åå¨è¨±å¤ä»»åä¸­ä»ç¶­æå¼·åçè¡¨ç¾ãæ­¤æ¨¡åä¹ç¨æ¼ä¸åçå¯¦ä¸çç ADHD è³æéï¼å¶æºç¢ºåº¦å F1 åæ¸çº 85%ãè DistilBERT (66M) å ClinicalBERT (110M) ç¸è¼ï¼LastBERT è¡¨ç¾åºå¯æ¯è¼çè¡¨ç¾ï¼DistilBERT ä»¥ 87% çè¡¨ç¾ç¥åä¸ç±ï¼è ClinicalBERT å¨ç¸åçææ¨ä¸­éå° 86%ãéäºç¼ç¾çªé¡¯äº LastBERT æ¨¡åé©ç¶å°åé¡ ADHD å´éç¨åº¦çè½åï¼å æ­¤å®çºå¿çå¥åº·å°æ¥­äººå¡æä¾äºä¸åæç¨çå·¥å·ï¼ç¨æ¼è©ä¼°åçè§£ç¤¾ç¾¤ç¶²è·¯å¹³å°ä¸ä½¿ç¨èç¢åºçè³æãæ¬ç ç©¶å¼·èª¿äºç¥è­èåå¨ç¢çé©ç¨æ¼è³æºæéæ¢ä»¶çæææ¨¡åæ¹é¢çå¯è½æ§ï¼å æ­¤ä¿é²äº NLP åå¿çå¥åº·è¨ºæ·ãæ­¤å¤ï¼å¨æ²æé¡¯èæè½æå¤±çææ³ä¸å¤§å¹ç¸®å°æ¨¡åå¤§å°ï¼ä¹çªé¡¯äºè¨ç·´åé¨ç½²æéçè¼ä½éç®è³æºï¼å æ­¤ä¿é²äºæ´å»£æ³çæç¨æ§ãç¹å¥æ¯ä½¿ç¨ç¾æçéç®å·¥å·ï¼ä¾å¦ Google Colabãæ¬ç ç©¶é¡¯ç¤ºäºåé² NLP æ¹æ³å¨åå¯¦ä¸çæç¨ä¸­çå¯åæ§åå¯¦ç¨æ§ã</paragraph>

##### **DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET**
2410.23219v1 by Yitong Li, Morteza Ghahremani, Youssef Wally, Christian Wachinger

Diagnosing dementia, particularly for Alzheimer's Disease (AD) and
frontotemporal dementia (FTD), is complex due to overlapping symptoms. While
magnetic resonance imaging (MRI) and positron emission tomography (PET) data
are critical for the diagnosis, integrating these modalities in deep learning
faces challenges, often resulting in suboptimal performance compared to using
single modalities. Moreover, the potential of multi-modal approaches in
differential diagnosis, which holds significant clinical importance, remains
largely unexplored. We propose a novel framework, DiaMond, to address these
issues with vision Transformers to effectively integrate MRI and PET. DiaMond
is equipped with self-attention and a novel bi-attention mechanism that
synergistically combine MRI and PET, alongside a multi-modal normalization to
reduce redundant dependency, thereby boosting the performance. DiaMond
significantly outperforms existing multi-modal methods across various datasets,
achieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CN
classification, and 76.5% in differential diagnosis of AD and FTD. We also
validated the robustness of DiaMond in a comprehensive ablation study. The code
is available at https://github.com/ai-med/DiaMond.

æè¦ï¼è¨ºæ·å¤±æºçï¼å°¤å¶æ¯é¿è²æµ·é»ç (AD) åé¡é¡³èåå¤±æºç (FTD)ï¼ç±æ¼ççéçï¼å æ­¤å¾è¤éãéç¶ç£å±æ¯é å½± (MRI) åæ­£å­æ·å±¤ææ (PET) æ¸æå°æ¼è¨ºæ·è³ééè¦ï¼ä½å°éäºæ¹å¼æ´åå°æ·±åº¦å­¸ç¿ä¸­æé¢è¨ææ°ï¼éå¸¸æå°è´èä½¿ç¨å®ä¸æ¹å¼ç¸æ¯æ§è½ä¸ä½³ãæ­¤å¤ï¼å¤æ¨¡å¼æ¹æ³å¨éå¥è¨ºæ·ä¸­çæ½åå·æéè¦çè¨åºæç¾©ï¼ä½ä»æªå¾å°ååæ¢ç´¢ãæåæåºä¸åæ°çæ¡æ¶ DiaMondï¼ä»¥è§£æ±ºéäºåé¡ï¼ä½¿ç¨è¦è¦ºè½æå¨æææ´å MRI å PETãDiaMond å·åèªæ³¨æååæ°ç©çéæ³¨æåæ©å¶ï¼å¯ä»¥ååçµå MRI å PETï¼ä¸¦æ¡ç¨å¤æ¨¡å¼æ­£è¦åä¾æ¸å°åé¤ä¾è³´ï¼å¾èæåæ§è½ãDiaMond å¨åç¨®æ¸æéä¸­çè¡¨ç¾æé¡¯åªæ¼ç¾æçå¤æ¨¡å¼æ¹æ³ï¼å¨ AD è¨ºæ·ä¸­éå° 92.4% çå¹³è¡¡æºç¢ºåº¦ï¼å¨ AD-MCI-CN åé¡ä¸­éå° 65.2%ï¼å¨ AD å FTD çéå¥è¨ºæ·ä¸­éå° 76.5%ãæåéå¨å¨é¢çæ¶èç ç©¶ä¸­é©è­äº DiaMond çç©©å¥æ§ãç¨å¼ç¢¼å¯å¨ https://github.com/ai-med/DiaMond åå¾ã

##### **Variable Resolution Sampling and Deep Learning Image Recovery for Accelerated Multi-Spectral MRI Near Metal Implants**
2410.23329v1 by Azadeh Sharafi, Nikolai J. Mickevicius, Mehran Baboli, Andrew S. Nencka, Kevin M. Koch

Purpose: This study presents a variable resolution (VR) sampling and deep
learning reconstruction approach for multi-spectral MRI near metal implants,
aiming to reduce scan times while maintaining image quality. Background: The
rising use of metal implants has increased MRI scans affected by metal
artifacts. Multi-spectral imaging (MSI) reduces these artifacts but sacrifices
acquisition efficiency. Methods: This retrospective study on 1.5T MSI knee and
hip data from patients with metal hardware used a novel spectral undersampling
scheme to improve acquisition efficiency by ~40%. U-Net-based deep learning
models were trained for reconstruction. Image quality was evaluated using SSIM,
PSNR, and RESI metrics. Results: Deep learning reconstructions of undersampled
VR data (DL-VR) showed significantly higher SSIM and PSNR values (p<0.001)
compared to conventional reconstruction (CR-VR), with improved edge sharpness.
Edge sharpness in DL-reconstructed images matched fully sampled references
(p=0.5). Conclusion: This approach can potentially enhance MRI examinations
near metal implants by reducing scan times or enabling higher resolution.
Further prospective studies are needed to assess clinical value.

æè¦ï¼ç®çï¼æ¬ç ç©¶æåºä¸ç§å¯ååè¾¨ç (VR) éæ ·åæ·±åº¦å­¦ä¹ éå»ºæ¹æ³ï¼ç¨äºéå±æ¤å¥ç©éè¿çå¤åå MRIï¼æ¨å¨å¨ä¿æå¾åè´¨éçåæ¶åå°æ«ææ¶é´ãèæ¯ï¼éå±æ¤å¥ç©çä½¿ç¨å¢å ï¼å¯¼è´åéå±ä¼ªå½±å½±åç MRI æ«æå¢å ãå¤ååæå (MSI) åå°äºè¿äºä¼ªå½±ï¼ä½çºç²äºééæçãæ¹æ³ï¼è¿é¡¹éå¯¹ 1.5T MSI èçåé«é¨æ°æ®çåé¡¾æ§ç ç©¶ï¼æ¥èªè£æéå±ç¡¬ä»¶çæ£èï¼ä½¿ç¨äºä¸ç§æ°é¢çåè°±æ¬ éæ ·æ¹æ¡ï¼å°ééæçæé«äºçº¦ 40%ãåºäº U-Net çæ·±åº¦å­¦ä¹ æ¨¡åç»è¿è®­ç»ç¨äºéå»ºãä½¿ç¨ SSIMãPSNR å RESI ææ è¯ä¼°å¾åè´¨éãç»æï¼æ¬ éæ · VR æ°æ®çæ·±åº¦å­¦ä¹ éå»º (DL-VR) ä¸ä¼ ç»éå»º (CR-VR) ç¸æ¯ï¼æ¾ç¤ºåºææ¾æ´é«ç SSIM å PSNR å¼ï¼p<0.001ï¼ï¼å¹¶æé«äºè¾¹ç¼æ¸æ°åº¦ãDL éå»ºå¾åä¸­çè¾¹ç¼æ¸æ°åº¦ä¸å®å¨éæ ·çåèå¼ç¸å¹éï¼p=0.5ï¼ãç»è®ºï¼è¿ç§æ¹æ³å¯ä»¥éè¿åå°æ«ææ¶é´æå¯ç¨æ´é«åè¾¨çæ¥å¢å¼ºéå±æ¤å¥ç©éè¿ç MRI æ£æ¥ãéè¦è¿ä¸æ­¥çåç»æ§ç ç©¶æ¥è¯ä¼°ä¸´åºä»·å¼ã

##### **DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection**
2411.00858v1 by Vahideh Hayyolalam, Ãznur Ãzkasap

Diabetes is a chronic disorder identified by the high sugar level in the
blood that can cause various different disorders such as kidney failure, heart
attack, sightlessness, and stroke. Developments in the healthcare domain by
facilitating the early detection of diabetes risk can help not only caregivers
but also patients. AIoMT is a recent technology that integrates IoT and machine
learning methods to give services for medical purposes, which is a powerful
technology for the early detection of diabetes. In this paper, we take
advantage of AIoMT and propose a hybrid diabetes risk detection method, DiabML,
which uses the BWO algorithm and ML methods. BWO is utilized for feature
selection and SMOTE for imbalance handling in the pre-processing procedure. The
simulation results prove the superiority of the proposed DiabML method compared
to the existing works. DiabML achieves 86.1\% classification accuracy by
AdaBoost classifier outperforms the relevant existing methods.

æè¦ï¼ç³å°¿çæ¯ä¸ç¨®æ¢æ§ç¾çï¼ç¹å¾µæ¯è¡æ¶²ä¸­çé«ç³åï¼å¯è½å°è´åç¨®ä¸åçç¾çï¼ä¾å¦èè¡°ç«­ãå¿èçç¼ä½ãå¤±æåä¸­é¢¨ãé«çä¿å¥é åçç¼å±ééä¿é²æ©æç¼ç¾ç³å°¿çé¢¨éªï¼ä¸åå¯ä»¥å¹«å©ç§è­·èï¼éå¯ä»¥å¹«å©æ£èãAIoMT æ¯ä¸ç¨®å°ç©è¯ç¶²åæ©å¨å­¸ç¿æ¹æ³æ´åå¨ä¸èµ·çæ°æè¡ï¼ç¨æ¼æä¾é«çç®ççæåï¼éæ¯ä¸ç¨®ç¨æ¼æ©æç¼ç¾ç³å°¿ççå¼·å¤§æè¡ãå¨æ¬æä¸­ï¼æåå©ç¨ AIoMT ä¸¦æåºäºä¸ç¨®æ··åç³å°¿çé¢¨éªæª¢æ¸¬æ¹æ³ DiabMLï¼å®ä½¿ç¨ BWO æ¼ç®æ³å ML æ¹æ³ãBWO ç¨æ¼é èçç¨åºä¸­çç¹å¾µé¸æï¼è SMOTE ç¨æ¼èçä¸å¹³è¡¡ãæ¨¡æ¬çµæè­æäºææåºç DiabML æ¹æ³åªæ¼ç¾ææ¹æ³ãDiabML éé AdaBoost åé¡å¨å¯¦ç¾äº 86.1% çåé¡æºç¢ºåº¦ï¼åªæ¼ç¸éçç¾ææ¹æ³ã

##### **Revisiting MAE pre-training for 3D medical image segmentation**
2410.23132v1 by Tassilo Wald, Constantin Ulrich, Stanislav Lukyanenko, Andrei Goncharov, Alberto Paderno, Leander Maerkisch, Paul F. JÃ¤ger, Klaus Maier-Hein

Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the
potential of vast, untapped clinical datasets, for various downstream
applications that suffer from the scarcity of labeled data. While SSL has
revolutionized fields like natural language processing and computer vision,
their adoption in 3D medical image computing has been limited by three key
pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D
medical image analysis, and insufficient evaluation practices. We address these
issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and
ii) using a Residual Encoder U-Net architecture within the state-of-the-art
nnU-Net framework. iii) A robust development framework, incorporating 5
development and 8 testing brain MRI segmentation datasets, allowed
performance-driven design decisions to optimize the simple concept of Masked
Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses
previous SSL methods but also outperforms the strong nnU-Net baseline by an
average of approximately 3 Dice points. Furthermore, our model demonstrates
exceptional stability, achieving the highest average rank of 2 out of 7
methods, compared to the second-best method's mean rank of 3.

æè¦ï¼èªçç£å­¦ä¹  (SSL) ä¸ºè§£éå¤§éæªå¼åä¸´åºæ°æ®éçæ½åæä¾äºä¸ä¸ªæ¿å¨äººå¿çæºä¼ï¼ç¨äºåç§ä¸æ¸¸åºç¨ç¨åºï¼è¿äºåºç¨ç¨åºå æ è®°æ°æ®ç¨ç¼ºèåå°å½±åãè½ç¶ SSL å·²å½»åºæ¹åäºèªç¶è¯­è¨å¤çåè®¡ç®æºè§è§ç­é¢åï¼ä½å¶å¨ 3D å»å­¦å¾åè®¡ç®ä¸­çéç¨åå°ä¸ä¸ªä¸»è¦ç¼ºé·çéå¶ï¼å°åé¢è®­ç»æ°æ®éå¤§å°ãä¸éç¨äº 3D å»å­¦å¾ååæçæ¶æä»¥åè¯ä¼°å®è·µä¸è¶³ãæä»¬éè¿ä»¥ä¸æ¹å¼è§£å³è¿äºé®é¢ï¼i) å©ç¨ 44k 3D å¤§è MRI ä½ç§¯çå¤§è§æ¨¡æ°æ®éï¼ä»¥å ii) å¨æåè¿ç nnU-Net æ¡æ¶åä½¿ç¨æ®å·®ç¼ç å¨ U-Net æ¶æãiii) ä¸ä¸ªç¨³å¥çå¼åæ¡æ¶ï¼åå« 5 ä¸ªå¼åå 8 ä¸ªæµè¯å¤§è MRI åå²æ°æ®éï¼åè®¸åºäºæ§è½çè®¾è®¡å³ç­æ¥ä¼å 3D CNN çæ©è½èªå¨ç¼ç å¨ (MAE) çç®åæ¦å¿µãç±æ­¤äº§ççæ¨¡åä¸ä»è¶è¶äºä¹åç SSL æ¹æ³ï¼èä¸æ¯å¼ºå¤§ç nnU-Net åºçº¿å¹³åé«åºå¤§çº¦ 3 ä¸ªéª°å­ç¹ãæ­¤å¤ï¼æä»¬çæ¨¡åè¡¨ç°åºéå¡çç¨³å®æ§ï¼å¨ 7 ç§æ¹æ³ä¸­è¾¾å° 2 çæé«å¹³åæåï¼èç¬¬äºå¥½çæ¹æ³çå¹³åæåä¸º 3ã

##### **SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**
2410.22950v1 by Ankita Kumari Jain, Nitish Sharma, Madhav Kanda, Nipun Batra

Respiratory illnesses are a significant global health burden. Respiratory
illnesses, primarily Chronic obstructive pulmonary disease (COPD), is the
seventh leading cause of poor health worldwide and the third leading cause of
death worldwide, causing 3.23 million deaths in 2019, necessitating early
identification and diagnosis for effective mitigation. Among the diagnostic
tools employed, spirometry plays a crucial role in detecting respiratory
abnormalities. However, conventional clinical spirometry methods often entail
considerable costs and practical limitations like the need for specialized
equipment, trained personnel, and a dedicated clinical setting, making them
less accessible. To address these challenges, wearable spirometry technologies
have emerged as promising alternatives, offering accurate, cost-effective, and
convenient solutions. The development of machine learning models for wearable
spirometry heavily relies on the availability of high-quality ground truth
spirometry data, which is a laborious and expensive endeavor. In this research,
we propose using active learning, a sub-field of machine learning, to mitigate
the challenges associated with data collection and labeling. By strategically
selecting samples from the ground truth spirometer, we can mitigate the need
for resource-intensive data collection. We present evidence that models trained
on small subsets obtained through active learning achieve comparable/better
results than models trained on the complete dataset.

æè¦ï¼å¼å¸éç¾çæ¯å¨çéå¤§çå¥åº·è² æãå¼å¸éç¾çï¼ä¸»è¦æ¯æ¢æ§é»å¡æ§èºç (COPD)ï¼æ¯å¨çç¬¬ä¸å¤§ä¸è¯å¥åº·åå ï¼ä¹æ¯å¨çç¬¬ä¸å¤§æ­»äº¡åå ï¼2019 å¹´é æ 323 è¬äººæ­»äº¡ï¼éè¦åæ©è­å¥åè¨ºæ·ä»¥æææ¸è¼ççãå¨ææ¡ç¨çè¨ºæ·å·¥å·ä¸­ï¼èºæ´»éæ¸¬éå¨æª¢æ¸¬å¼å¸éç°å¸¸æ¹é¢ç¼æ®èè³ééè¦çä½ç¨ãç¶èï¼å³çµ±çè¨åºèºæ´»éæ¸¬éæ¹æ³éå¸¸éè¦å¤§éçææ¬åå¯¦ééå¶ï¼ä¾å¦éè¦å°æ¥­è¨­åãè¨ç·´æç´ çäººå¡åå°éçè¨åºç°å¢ï¼éä½¿å¾å®åçå¯åæ§è¼ä½ãçºäºæå°éäºææ°ï¼å¯ç©¿æ´å¼èºæ´»éæ¸¬éæè¡å·²æçºæå¸æçæ¿ä»£æ¹æ¡ï¼æä¾æºç¢ºãç¶æ¿é«æä¸ä¾¿å©çè§£æ±ºæ¹æ¡ãå¯ç©¿æ´å¼èºæ´»éæ¸¬éæ©å¨å­¸ç¿æ¨¡åçéç¼å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼é«åè³ªçåºæºèºæ´»éæ¸¬éæ¸æï¼éæ¯ä¸é è²»æä¸æè²´çå·¥ä½ãå¨éé ç ç©¶ä¸­ï¼æåå»ºè­°ä½¿ç¨ä¸»åå­¸ç¿ï¼æ©å¨å­¸ç¿çä¸åå­é åï¼ä¾æ¸è¼èæ¸ææ¶éåæ¨è¨ç¸éçææ°ãééå¾åºæºèºæ´»éè¨ä¸­ç­ç¥æ§å°é¸ææ¨£æ¬ï¼æåå¯ä»¥æ¸å°å°è³æºå¯éåæ¸ææ¶éçéæ±ãæåæä¾çè­æè¡¨æï¼å¨ééä¸»åå­¸ç¿ç²å¾çå°å­éä¸­è¨ç·´çæ¨¡åï¼ç²å¾ççµæèå¨å®æ´æ¸æéä¸è¨ç·´çæ¨¡åç¸ç¶/æ´å¥½ã

##### **Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**
2410.22619v1 by Plabon Paul, Md. Nazmul Islam, Fazle Rafsani, Pegah Khorasani, Shovito Barua Soumma

Uncontrolled cell division in the brain is what gives rise to brain tumors.
If the tumor size increases by more than half, there is little hope for the
patient's recovery. This emphasizes the need of rapid and precise brain tumor
diagnosis. When it comes to analyzing, diagnosing, and planning therapy for
brain tumors, MRI imaging plays a crucial role. A brain tumor's development
history is crucial information for doctors to have. When it comes to
distinguishing between human soft tissues, MRI scans are superior. In order to
get reliable classification results from MRI scans quickly, deep learning is
one of the most practical methods. Early human illness diagnosis has been
demonstrated to be more accurate when deep learning methods are used. In the
case of diagnosing a brain tumor, when even a little misdiagnosis might have
serious consequences, accuracy is especially important. Disclosure of brain
tumors in medical images is still a difficult task. Brain MRIs are notoriously
imprecise in revealing the presence or absence of tumors. Using MRI scans of
the brain, a Convolutional Neural Network (CNN) was trained to identify the
presence of a tumor in this research. Results from the CNN model showed an
accuracy of 99.17%. The CNN model's characteristics were also retrieved. In
order to evaluate the CNN model's capability for processing images, we applied
the features via the following machine learning models: KNN, Logistic
regression, SVM, Random Forest, Naive Bayes, and Perception. CNN and machine
learning models were also evaluated using the standard metrics of Precision,
Recall, Specificity, and F1 score. The significance of the doctor's diagnosis
enhanced the accuracy of the CNN model's assistance in identifying the
existence of tumor and treating the patient.

æè¦ï¼è¦é¨ç´°èåè£å¤±æ§ï¼å°±æç¢çè¦ç¤ã
å¦æè«ç¤å¤§å°å¢å è¶éä¸åï¼çæ£åº·å¾©çå¸æå¾æ¸ºè«ãéå¼·èª¿äºå¿«éä¸ç²¾æºè¨ºæ·è¦ç¤çå¿è¦æ§ã
å¨åæãè¨ºæ·åè¦åè¦ç¤æ²»çæï¼æ ¸ç£å±æ¯é å½±æ®æ¼äºè³ééè¦çè§è²ãè¦ç¤çç¼å±å²æ¯é«çå¿åçéè¦è³è¨ã
å¨ååäººé«è»çµç¹æï¼æ ¸ç£å±æ¯ææçè¡¨ç¾åªç°ãçºäºå¾æ ¸ç£å±æ¯ææä¸­å¿«éåå¾å¯é çåé¡çµæï¼æ·±åº¦å­¸ç¿æ¯æå¯¦ç¨çæ¹æ³ä¹ä¸ã
ç ç©¶é¡¯ç¤ºï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³å¯ä»¥æ´æºç¢ºå°è¨ºæ·äººé¡æ©æç¾çãå¨è¨ºæ·è¦ç¤æï¼å³ä½¿æ¯è¼å¾®çèª¤è¨ºé½å¯è½é æå´éå¾æï¼å æ­¤æºç¢ºæ§ç¹å¥éè¦ã
å¨é«å­¸å½±åä¸­æ­é²è¦ç¤ä»ç¶æ¯ä¸é è±é£çä»»åãè¦é¨æ ¸ç£å±æ¯é å½±å¨æ­é²è«ç¤çå­å¨èå¦æ¹é¢åºäºåçä¸ç²¾ç¢ºã
æ¬ç ç©¶è¨ç·´äºä¸åå·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ä½¿ç¨è¦é¨æ ¸ç£å±æ¯ææä¾è¾¨è­è«ç¤çå­å¨ãCNN æ¨¡åççµæé¡¯ç¤ºæºç¢ºåº¦çº 99.17%ãCNN æ¨¡åçç¹å¾µä¹å·²æ·åã
çºäºè©ä¼° CNN æ¨¡åèçå½±åçè½åï¼æåééä»¥ä¸æ©å¨å­¸ç¿æ¨¡åå¥ç¨éäºç¹å¾µï¼KNNãéè¼¯è¿´æ­¸ãSVMãé¨æ©æ£®æãæ¨¸ç´ è²æ°åæç¥å¨ãCNN åæ©å¨å­¸ç¿æ¨¡åä¹ä½¿ç¨ç²¾æºåº¦ãå¬åçãç¹ç°æ§å F1 åæ¸ç­æ¨æºææ¨é²è¡è©ä¼°ã
é«ççè¨ºæ·æç¾©æåäº CNN æ¨¡åå¨åå©è¾¨è­è«ç¤å­å¨åæ²»ççæ£æ¹é¢çæºç¢ºæ§ã

##### **Do Large Language Models Align with Core Mental Health Counseling Competencies?**
2410.22446v1 by Viet Cuong Nguyen, Mohammad Taher, Dongwan Hong, Vinicius Konkolics Possobom, Vibha Thirunellayi Gopalakrishnan, Ekta Raj, Zihang Li, Heather J. Soled, Michael L. Birnbaum, Srijan Kumar, Munmun De Choudhury

The rapid evolution of Large Language Models (LLMs) offers promising
potential to alleviate the global scarcity of mental health professionals.
However, LLMs' alignment with essential mental health counseling competencies
remains understudied. We introduce CounselingBench, a novel NCMHCE-based
benchmark evaluating LLMs across five key mental health counseling
competencies. Testing 22 general-purpose and medical-finetuned LLMs, we find
frontier models exceed minimum thresholds but fall short of expert-level
performance, with significant variations: they excel in Intake, Assessment &
Diagnosis yet struggle with Core Counseling Attributes and Professional
Practice & Ethics. Medical LLMs surprisingly underperform generalist models
accuracy-wise, while at the same time producing slightly higher-quality
justifications but making more context-related errors. Our findings highlight
the complexities of developing AI systems for mental health counseling,
particularly for competencies requiring empathy and contextual understanding.
We found that frontier LLMs perform at a level exceeding the minimal required
level of aptitude for all key mental health counseling competencies, but fall
short of expert-level performance, and that current medical LLMs do not
significantly improve upon generalist models in mental health counseling
competencies. This underscores the critical need for specialized, mental health
counseling-specific fine-tuned LLMs that rigorously aligns with core
competencies combined with appropriate human supervision before any responsible
real-world deployment can be considered.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éç¼å±ï¼æä¾äºç·©è§£å¨çå¿çå¥åº·å°æ¥­äººå¡ç­ç¼ºçæ½å¨å¸æã
ç¶èï¼LLM èåºæ¬å¿çå¥åº·è«®åè½åçå°é½ç¨åº¦ï¼ä»æªç²å¾ååç ç©¶ãæåå¼å¥äº CounselingBenchï¼ä¸ååºæ¼ NCMHCE çæ°åºæºï¼ç¨æ¼è©ä¼° LLM å¨äºé ééµå¿çå¥åº·è«®åè½åä¸çè¡¨ç¾ãæåæ¸¬è©¦äº 22 åéç¨åé«å­¸å¾®èª¿ç LLMï¼ç¼ç¾åæ²¿æ¨¡åè¶éäºæä½éæª»ï¼ä½æªéå°å°å®¶ç´å¥çè¡¨ç¾ï¼ä¸å·®ç°é¡¯èï¼å®åå¨ãæåãè©ä¼°åè¨ºæ·ãæ¹é¢è¡¨ç¾åºè²ï¼ä½å¨ãæ ¸å¿è«®åå±¬æ§ãåãå°æ¥­å¯¦ååå«çãæ¹é¢å»æå°é£ãä»¤äººé©è¨çæ¯ï¼é«ç LLM å¨æºç¢ºæ§æ¹é¢è¡¨ç¾ä¸å¦éç¨æ¨¡åï¼ä½åæç¢çççç±åè³ªç¥é«ï¼ä½ç¢çæ´å¤èèçµ¡ç¸éçé¯èª¤ãæåçç ç©¶çµæçªåºäºçºå¿çå¥åº·è«®åéç¼ AI ç³»çµ±çè¤éæ§ï¼ç¹å¥æ¯å°æ¼éè¦åçå¿åèçµ¡çè§£çè½åãæåç¼ç¾ï¼åæ²¿ LLM çè¡¨ç¾æ°´å¹³è¶éäºææééµå¿çå¥åº·è«®åè½åæéçæä½è½åæ°´æºï¼ä½æªéå°å°å®¶ç´å¥çè¡¨ç¾ï¼èä¸ç®åçé«ç LLM ä¸¦æªé¡¯èæ¹åéç¨æ¨¡åå¨å¿çå¥åº·è«®åè½åä¸çè¡¨ç¾ãéå¼·èª¿äºå°å°éçãéå°å¿çå¥åº·è«®è©¢çå¾®èª¿ LLM çè¿«åéæ±ï¼éäº LLM å¿é å´æ ¼ç¬¦åæ ¸å¿è½åï¼ä¸¦çµåé©ç¶çäººé¡ç£ç£ï¼æè½èæ®ä»»ä½è² è²¬ä»»çå¯¦éé¨ç½²ã

##### **MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation**
2410.22223v1 by Ovais Iqbal Shah, Danish Raza Rizvi, Aqib Nazir Mir

Medical image segmentation is pivotal in healthcare, enhancing diagnostic
accuracy, informing treatment strategies, and tracking disease progression.
This process allows clinicians to extract critical information from visual
data, enabling personalized patient care. However, developing neural networks
for segmentation remains challenging, especially when preserving image
resolution, which is essential in detecting subtle details that influence
diagnoses. Moreover, the lack of transparency in these deep learning models has
slowed their adoption in clinical practice. Efforts in model interpretability
are increasingly focused on making these models' decision-making processes more
transparent. In this paper, we introduce MAPUNetR, a novel architecture that
synergizes the strengths of transformer models with the proven U-Net framework
for medical image segmentation. Our model addresses the resolution preservation
challenge and incorporates attention maps highlighting segmented regions,
increasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset,
MAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on the
ISIC 2018 dataset. Our experiments show that the model maintains stable
performance and potential as a powerful tool for medical image segmentation in
clinical practice.

æè¦ï¼é«å­¸å½±ååå²å¨é«çä¿å¥ä¸­è³ééè¦ï¼è½æåè¨ºæ·æºç¢ºåº¦ãæä¾æ²»çç­ç¥è³è¨ï¼ä¸¦è¿½è¹¤ç¾çé²ç¨ãæ­¤ç¨åºè®è¨åºé«çè½å¾è¦è¦ºè³æä¸­èåééµè³è¨ï¼é²èæä¾åäººåçæ£èç§è­·ãç¶èï¼éç¼ç¨æ¼åå²çç¥ç¶ç¶²è·¯ä»å·ææ°æ§ï¼ç¹å¥æ¯å¨ä¿çå½±åè§£æåº¦æï¼éå°æ¼åµæ¸¬å½±é¿è¨ºæ·çç´°å¾®ç´°ç¯è³ééè¦ãæ­¤å¤ï¼éäºæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹éæåº¦ï¼å°è´å¶å¨è¨åºå¯¦åä¸­çæ¡ç¨éåº¦è®æ¢ãæ¨¡åå¯è§£éæ§çåªåè¶ä¾è¶å°æ³¨æ¼è®éäºæ¨¡åçæ±ºç­éç¨æ´éæãå¨æ¬æä¸­ï¼æåä»ç´¹äº MAPUNetRï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼çµåäºTransformeræ¨¡åçåªé»åå·²è­å¯¦ç U-Net æ¡æ¶ï¼ç¨æ¼é«å­¸å½±ååå²ãæåçæ¨¡åè§£æ±ºäºè§£æåº¦ä¿ççææ°ï¼ä¸¦çµåäºçªé¡¯åå²ååçæ³¨æååï¼æé«äºæºç¢ºåº¦åå¯è§£éæ§ãå¨ BraTS 2020 è³æéä¸é²è¡è©ä¼°ï¼MAPUNetR å¨ ISIC 2018 è³æéä¸éå°äº 0.88 çéª°å­ä¿æ¸å 0.92 çéª°å­ç³»æ¸ãæåçå¯¦é©è¡¨æï¼è©²æ¨¡åå¨è¨åºå¯¦åä¸­ä½çºé«å­¸å½±ååå²çå¼·å¤§å·¥å·ï¼å·æç©©å®çæè½åæ½åã

##### **Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review**
2410.22180v1 by Muhammad Bilal, Ameer Hamza, Nadia Malik

Objective: This review aims to analyze the application of natural language
processing (NLP) techniques in cancer research using electronic health records
(EHRs) and clinical notes. This review addresses gaps in the existing
literature by providing a broader perspective than previous studies focused on
specific cancer types or applications. Methods: A comprehensive literature
search was conducted using the Scopus database, identifying 94 relevant studies
published between 2019 and 2024. Data extraction included study
characteristics, cancer types, NLP methodologies, dataset information,
performance metrics, challenges, and future directions. Studies were
categorized based on cancer types and NLP applications. Results: The results
showed a growing trend in NLP applications for cancer research, with breast,
lung, and colorectal cancers being the most studied. Information extraction and
text classification emerged as predominant NLP tasks. A shift from rule-based
to advanced machine learning techniques, particularly transformer-based models,
was observed. The Dataset sizes used in existing studies varied widely. Key
challenges included the limited generalizability of proposed solutions and the
need for improved integration into clinical workflows. Conclusion: NLP
techniques show significant potential in analyzing EHRs and clinical notes for
cancer research. However, future work should focus on improving model
generalizability, enhancing robustness in handling complex clinical language,
and expanding applications to understudied cancer types. Integration of NLP
tools into clinical practice and addressing ethical considerations remain
crucial for utilizing the full potential of NLP in enhancing cancer diagnosis,
treatment, and patient outcomes.

æè¦ï¼<paragraph>ç®æ¨ï¼æ¬ç¯è©è«æ¨å¨åæèªç¶èªè¨èç (NLP) æè¡å¨ççç ç©¶ä¸­ä½¿ç¨é»å­å¥åº·ç´é (EHR) åè¨åºç­è¨çæç¨ãæ¬ç¯è©è«ééæä¾æ¯ååå°æ³¨æ¼ç¹å®ççé¡åææç¨çç ç©¶æ´å»£æ³çè§é»ï¼ä¾æ¢è¨ç¾ææç»ä¸­çå·®è·ãæ¹æ³ï¼ä½¿ç¨ Scopus è³æåº«é²è¡å¨é¢çæç»æå°ï¼æ¾åº 2019 å¹´è³ 2024 å¹´éç¼è¡¨ç 94 ç¯ç¸éç ç©¶ãè³ææ·ååå«ç ç©¶ç¹å¾µãççé¡åãNLP æ¹æ³è«ãè³æéè³è¨ãæè½ææ¨ãææ°åæªä¾æ¹åãç ç©¶æ ¹æççé¡åå NLP æç¨é²è¡åé¡ãçµæï¼çµæé¡¯ç¤º NLP å¨ççç ç©¶ä¸­çæç¨æéæ¼¸å¢å çè¶¨å¢ï¼å¶ä¸­ä¹³çãèºçåå¤§è¸ç´è¸ççç ç©¶æå¤ãè³è¨æ·ååæå­åé¡æçºä¸»è¦ç NLP ä»»åãè§å¯å°å¾åºæ¼è¦åçæè¡è½ç§»å°é²éæ©å¨å­¸ç¿æè¡ï¼ç¹å¥æ¯åºæ¼è½æå¨çæ¨¡åãç¾æç ç©¶ä¸­ä½¿ç¨çè³æéå¤§å°å·®ç°å¾å¤§ãä¸»è¦çææ°åæ¬ææåºè§£æ±ºæ¹æ¡çæ®éæ§æéï¼ä»¥åéè¦æ´é²ä¸æ­¥æ´åå°è¨åºå·¥ä½æµç¨ä¸­ãçµè«ï¼NLP æè¡å¨åæé»å­å¥åº·ç´éåè¨åºç­è¨ä»¥é²è¡ççç ç©¶æ¹é¢é¡¯ç¤ºåºé¡¯èçæ½åãç¶èï¼æªä¾çç ç©¶æå°æ³¨æ¼æ¹åæ¨¡åçæ®éæ§ãå å¼·èçè¤éè¨åºèªè¨çç©©å¥æ§ï¼ä»¥åå°æç¨æ´å±å°ç ç©¶ä¸è¶³çççé¡åãå° NLP å·¥å·æ´åå°è¨åºå¯¦åä¸­ï¼ä¸¦æ¢è¨å«çèéï¼å°æ¼ååå©ç¨ NLP å¨æåççè¨ºæ·ãæ²»çåæ£èé å¾æ¹é¢çæ½åè³ééè¦ã</paragraph>

##### **Advanced Hybrid Deep Learning Model for Enhanced Classification of Osteosarcoma Histopathology Images**
2411.00832v1 by Arezoo Borji, Gernot Kronreif, Bernhard Angermayr, Sepideh Hatamikia

Recent advances in machine learning are transforming medical image analysis,
particularly in cancer detection and classification. Techniques such as deep
learning, especially convolutional neural networks (CNNs) and vision
transformers (ViTs), are now enabling the precise analysis of complex
histopathological images, automating detection, and enhancing classification
accuracy across various cancer types. This study focuses on osteosarcoma (OS),
the most common bone cancer in children and adolescents, which affects the long
bones of the arms and legs. Early and accurate detection of OS is essential for
improving patient outcomes and reducing mortality. However, the increasing
prevalence of cancer and the demand for personalized treatments create
challenges in achieving precise diagnoses and customized therapies. We propose
a novel hybrid model that combines convolutional neural networks (CNN) and
vision transformers (ViT) to improve diagnostic accuracy for OS using
hematoxylin and eosin (H&E) stained histopathological images. The CNN model
extracts local features, while the ViT captures global patterns from
histopathological images. These features are combined and classified using a
Multi-Layer Perceptron (MLP) into four categories: non-tumor (NT), non-viable
tumor (NVT), viable tumor (VT), and none-viable ratio (NVR). Using the Cancer
Imaging Archive (TCIA) dataset, the model achieved an accuracy of 99.08%,
precision of 99.10%, recall of 99.28%, and an F1-score of 99.23%. This is the
first successful four-class classification using this dataset, setting a new
benchmark in OS research and offering promising potential for future diagnostic
advancements.

æè¦ï¼æ©å¨å­¸ç¿çææ°é²å±æ­£å¨è½è®é«å­¸å½±ååæï¼ç¹å¥æ¯å¨ççæª¢æ¸¬ååé¡æ¹é¢ãè«¸å¦æ·±åº¦å­¸ç¿ç­æè¡ï¼å°¤å¶æ¯å·ç©ç¥ç¶ç¶²è·¯ (CNN) åè¦è¦ºè½æå¨ (ViT)ï¼ç¾å¨è½ç²¾ç¢ºåæè¤éççµç¹ççå­¸å½±åãèªååæª¢æ¸¬ï¼ä¸¦æååç¨®ççé¡åçåé¡æºç¢ºåº¦ãæ¬ç ç©¶å°æ³¨æ¼éª¨èç¤ (OS)ï¼éæ¯åç«¥åéå°å¹´ä¸­æå¸¸è¦çéª¨çï¼æå½±é¿æèåè¿é¨çé·éª¨ãæ©æä¸æºç¢ºå°æª¢æ¸¬åºéª¨èç¤å°æ¼æ¹åæ£èé å¾åéä½æ­»äº¡çè³ééè¦ãç¶èï¼çççè¡ççå¢å åå°åäººåæ²»ççéæ±ï¼å¨éæç²¾ç¢ºè¨ºæ·åå®¢è£½åæ²»çæ¹é¢é æäºææ°ãæåæåºäºä¸ç¨®çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åè¦è¦ºè½æå¨ (ViT) çæ°åæ··åæ¨¡åï¼ä»¥ä½¿ç¨èæ¨ç²¾åæç´ (H&E) æè²ççµç¹ççå­¸å½±åä¾æåéª¨èç¤çè¨ºæ·æºç¢ºåº¦ãCNN æ¨¡åæèåå±é¨ç¹å¾µï¼è ViT åå¾çµç¹ççå­¸å½±åä¸­æ·åå¨å±æ¨¡å¼ãéäºç¹å¾µæçµåèµ·ä¾ï¼ä¸¦ä½¿ç¨å¤å±¤æç¥å¨ (MLP) åé¡æåç¨®é¡å¥ï¼éè«ç¤ (NT)ãä¸å¯å­æ´»è«ç¤ (NVT)ãå¯å­æ´»è«ç¤ (VT) åä¸å¯å­æ´»ç (NVR)ãä½¿ç¨ççå½±åæªæ¡ (TCIA) è³æéï¼è©²æ¨¡åéå°äº 99.08% çæºç¢ºåº¦ã99.10% çç²¾ç¢ºåº¦ã99.28% çå¬åçå 99.23% ç F1 å¼ãéæ¯ä½¿ç¨æ­¤è³æéé²è¡çé¦æ¬¡æåçåé¡å¥åé¡ï¼çºéª¨èç¤ç ç©¶è¨­å®äºæ°çåºæºï¼ä¸¦çºæªä¾çè¨ºæ·é²å±æä¾äºæå¸æçæ½åã

##### **Unsupervised Training of a Dynamic Context-Aware Deep Denoising Framework for Low-Dose Fluoroscopic Imaging**
2411.00830v1 by Sun-Young Jeon, Sen Wang, Adam S. Wang, Garry E. Gold, Jang-Hwan Choi

Fluoroscopy is critical for real-time X-ray visualization in medical imaging.
However, low-dose images are compromised by noise, potentially affecting
diagnostic accuracy. Noise reduction is crucial for maintaining image quality,
especially given such challenges as motion artifacts and the limited
availability of clean data in medical imaging. To address these issues, we
propose an unsupervised training framework for dynamic context-aware denoising
of fluoroscopy image sequences. First, we train the multi-scale recurrent
attention U-Net (MSR2AU-Net) without requiring clean data to address the
initial noise. Second, we incorporate a knowledge distillation-based
uncorrelated noise suppression module and a recursive filtering-based
correlated noise suppression module enhanced with motion compensation to
further improve motion compensation and achieve superior denoising performance.
Finally, we introduce a novel approach by combining these modules with a
pixel-wise dynamic object motion cross-fusion matrix, designed to adapt to
motion, and an edge-preserving loss for precise detail retention. To validate
the proposed method, we conducted extensive numerical experiments on medical
image datasets, including 3500 fluoroscopy images from dynamic phantoms (2,400
images for training, 1,100 for testing) and 350 clinical images from a spinal
surgery patient. Moreover, we demonstrated the robustness of our approach
across different imaging modalities by testing it on the publicly available
2016 Low Dose CT Grand Challenge dataset, using 4,800 images for training and
1,136 for testing. The results demonstrate that the proposed approach
outperforms state-of-the-art unsupervised algorithms in both visual quality and
quantitative evaluation while achieving comparable performance to
well-established supervised learning methods across low-dose fluoroscopy and CT
imaging.

æè¦ï¼<paragraph>è¢åéè¦å°æ¼é«å­¸å½±åä¸­çå³æ X åè¦è¦ºåè³ééè¦ã
ç¶èï¼ä½åéå½±åæåå°éè¨å½±é¿ï¼å¯è½å½±é¿è¨ºæ·æºç¢ºæ§ãéè¨æå¶å°æ¼ç¶­æå½±ååè³ªè³ééè¦ï¼ç¹å¥æ¯å¨é«å­¸å½±åä¸­å­å¨éåå½å½±åä¹¾æ·¨è³ææéç­ææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸åç¡ç£ç£è¨ç·´æ¶æ§ï¼ç¨æ¼è¢åéè¦å½±ååºåçåææå¢æç¥å»éè¨ãé¦åï¼æåè¨ç·´å¤å°ºåº¦éè¿´æ³¨æå U-Net (MSR2AU-Net)ï¼ç¡éä¹¾æ·¨è³æå³å¯èçåå§éè¨ãå¶æ¬¡ï¼æåçµåäºä¸ååºæ¼ç¥è­è¸é¤¾çéç¸ééè¨æå¶æ¨¡çµåä¸ååºæ¼éè¿´æ¿¾æ³¢çç¸ééè¨æå¶æ¨¡çµï¼ä¸¦å¢å¼·äºéåè£åï¼ä»¥é²ä¸æ­¥æ¹åéåè£åä¸¦å¯¦ç¾åè¶çå»éè¨æè½ãæå¾ï¼æåå¼å¥äºä¸ç¨®æ°æ¹æ³ï¼å°éäºæ¨¡çµèéåç´ åæç©ä»¶éåäº¤åèåç©é£çµåèµ·ä¾ï¼è©²ç©é£æ¨å¨é©æéåï¼ä¸¦æ¡ç¨éç·£ä¿çæå¤±ä»¥ç²¾ç¢ºä¿çç´°ç¯ãçºäºé©è­ææåºçæ¹æ³ï¼æåå°é«å­¸å½±åè³æéé²è¡äºå»£æ³çæ¸å¼å¯¦é©ï¼åæ¬ä¾èªåææ¨¡æ¬äººé«ç 3500 å¼µè¢åéè¦å½±åï¼2,400 å¼µç¨æ¼è¨ç·´ï¼1,100 å¼µç¨æ¼æ¸¬è©¦ï¼åä¾èªèæ¤æè¡æ£èç 350 å¼µè¨åºå½±åãæ­¤å¤ï¼æåééå¨å¬éç 2016 å¹´ä½åé CT å¤§ææ°è³æéä¸é²è¡æ¸¬è©¦ï¼ä½¿ç¨ 4,800 å¼µå½±åé²è¡è¨ç·´å 1,136 å¼µé²è¡æ¸¬è©¦ï¼è­æäºæåçæ¹æ³å¨ä¸åå½±åæ¨¡å¼ä¸çç©©å¥æ§ãçµæè¡¨æï¼ææåºçæ¹æ³å¨è¦è¦ºåè³ªåéåè©ä¼°ä¸­é½åªæ¼æåé²çç¡ç£ç£æ¼ç®æ³ï¼åæå¨ä½åéè¢åéè¦å CT å½±åä¸­å¯¦ç¾äºèå®åçç£ç£å¼å­¸ç¿æ¹æ³ç¸ç¶çæè½ã</paragraph>

##### **Coupling quantum-like cognition with the neuronal networks within generalized probability theory**
2411.00036v1 by Andrei Khrennikov, Masanao Ozawa, Felix Benninger, Oded Shor

The recent years are characterized by intensive applications of the
methodology and mathematical apparatus of quantum theory, quantum-like
modeling, in cognition, psychology, and decision making. In spite of the
successful applications of this approach to a variety of psychological effects,
e.g., the order, conjunction, disjunction, and response replicability effects,
one may (but need not) feel dissatisfaction due to the absence of clear
coupling to the neurophysiological processes in the brain. For the moment, this
is just a phenomenological approach. In this paper we construct the
quantum-like representation of the networks of communicating neurons. It is
based not on standard quantum theory, but on generalized probability theory
(GPT) with the emphasis of the operational measurement approach. We employ
GPT's version which is based on ordered linear state space (instead of complex
Hilbert space). A network of communicating neurons is described as a weighted
ordered graph that in turn is encoded by its weight matrix. The state space of
weight matrices is embedded in GPT with effect-observables and state updates
within measurement instruments theory. The latter plays the crucial role. This
GPT based model shows the basic quantum-like effects, as e.g. the order,
non-repeatability, and disjunction effects; the latter is also known as
interference of decisions. This GPT coupling also supports quantum-like
modeling in medical diagnostic for neurological diseases, as depression and
epilepsy. Although the paper is concentrated on cognition and neuronal
networks, the formalism and methodology can be straightforwardly applied to a
variety of biological and social networks.

æè¦ï¼è¿å¹´ä¾ï¼éå­çè«ãé¡éå­æ¨¡åå¨èªç¥ãå¿çå­¸åæ±ºç­å¶å®ä¸­çæ¹æ³è«åæ¸å­¸è£ç½®å¾å°å»£æ³æç¨ãåç®¡éç¨®æ¹æ³æåæç¨æ¼åç¨®å¿çææï¼ä¾å¦é åºãååãæåååæå¯è¤è£½ææï¼ä½ç±æ¼ç¼ºä¹èå¤§è¦ç¥ç¶ççéç¨çæç¢ºè¯ç¹«ï¼äººåå¯è½æï¼ä½ä¸å¿ï¼æå°ä¸æ»¿ãç®åï¼éåªæ¯ä¸ç¨®ç¾è±¡å­¸æ¹æ³ãå¨æ¬æä¸­ï¼æåæ§å»ºäºéä¿¡ç¥ç¶åç¶²è·¯çé¡éå­è¡¨ç¤ºãå®ä¸æ¯åºæ¼æ¨æºéå­çè«ï¼èæ¯åºæ¼å»£ç¾©æ¦çè« (GPT)ï¼ä¸¦å¼·èª¿éç®æ¸¬éæ¹æ³ãæåæ¡ç¨åºæ¼æåºç·æ§çæç©ºéï¼èä¸æ¯è¤éå¸ç¾ä¼¯ç¹ç©ºéï¼ç GPT çæ¬ãéä¿¡ç¥ç¶åç¶²è·¯è¢«æè¿°çºä¸åå æ¬æåºåï¼èå æ¬æåºååç±å¶æ¬éç©é£ç·¨ç¢¼ãæ¬éç©é£ççæç©ºéåµå¥ GPT ä¸­ï¼å¶ä¸­ææè§æ¸¬å¼åçææ´æ°å¨æ¸¬éåå¨çè«ä¸­ãå¾èç¼æ®èè³ééè¦çä½ç¨ãéååºæ¼ GPT çæ¨¡åå±ç¤ºäºåºæ¬çé¡éå­ææï¼ä¾å¦é åºãä¸å¯éè¤æ§åæåææï¼å¾èä¹è¢«ç¨±çºæ±ºç­å¹²æ¾ãéç¨® GPT è¦åéæ¯æ´ç¥ç¶ç¾çï¼å¦æé¬±çåç²ççï¼çé«çè¨ºæ·ä¸­çé¡éå­å»ºæ¨¡ãåç®¡æ¬æéä¸­æ¼èªç¥åç¥ç¶åç¶²è·¯ï¼ä½å½¢å¼ä¸»ç¾©åæ¹æ³è«å¯ä»¥ç´æ¥æç¨æ¼åç¨®çç©åç¤¾æç¶²è·¯ã

##### **Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning**
2410.21872v2 by Yinyi Lai, Anbo Cao, Yuan Gao, Jiaqi Shang, Zongyu Li, Jia Guo

Early and accurate diagnosis of brain tumors is crucial for improving patient
survival rates. However, the detection and classification of brain tumors are
challenging due to their diverse types and complex morphological
characteristics. This study investigates the application of pre-trained models
for brain tumor classification, with a particular focus on deploying the Mamba
model. We fine-tuned several mainstream transfer learning models and applied
them to the multi-class classification of brain tumors. By comparing these
models to those trained from scratch, we demonstrated the significant
advantages of transfer learning, especially in the medical imaging field, where
annotated data is often limited. Notably, we introduced the Vision Mamba (Vim),
a novel network architecture, and applied it for the first time in brain tumor
classification, achieving exceptional classification accuracy. Experimental
results indicate that the Vim model achieved 100% classification accuracy on an
independent test set, emphasizing its potential for tumor classification tasks.
These findings underscore the effectiveness of transfer learning in brain tumor
classification and reveal that, compared to existing state-of-the-art models,
the Vim model is lightweight, efficient, and highly accurate, offering a new
perspective for clinical applications. Furthermore, the framework proposed in
this study for brain tumor classification, based on transfer learning and the
Vision Mamba model, is broadly applicable to other medical imaging
classification problems.

æè¦ï¼è¦ç¤çæ©ææºç¢ºè¨ºæ·å°æ¼æé«æ£èå­æ´»çè³ééè¦ãç¶èï¼ç±æ¼è¦ç¤ç¨®é¡ç¹å¤ä¸å½¢æç¹å¾µè¤éï¼å æ­¤æª¢æ¸¬ååé¡è¦ç¤å·æææ°æ§ãæ¬ç ç©¶æ¢è¨äºé è¨ç·´æ¨¡åå¨è¦ç¤åé¡ä¸­çæç¨ï¼ç¹å¥éæ³¨ Mamba æ¨¡åçé¨ç½²ãæåå¾®èª¿äºå¹¾åä¸»æµçé·ç§»å­¸ç¿æ¨¡åï¼ä¸¦å°å®åæç¨æ¼è¦ç¤çå¤é¡å¥åé¡ãééå°éäºæ¨¡åèå¾é ­éå§è¨ç·´çæ¨¡åé²è¡æ¯è¼ï¼æåè­æäºé·ç§»å­¸ç¿çé¡¯èåªå¢ï¼ç¹å¥æ¯å¨é«çå½±åé åï¼å¶ä¸­è¨»éæ¸æéå¸¸æéãå¼å¾æ³¨æçæ¯ï¼æåå¼å¥äº Vision Mamba (Vim)ï¼ä¸ç¨®æ°ç©çç¶²è·¯æ¶æ§ï¼ä¸¦é¦æ¬¡å°å¶æç¨æ¼è¦ç¤åé¡ï¼éå°äºåºè²çåé¡æºç¢ºåº¦ãå¯¦é©çµæè¡¨æï¼Vim æ¨¡åå¨ç¨ç«æ¸¬è©¦éä¸å¯¦ç¾äº 100% çåé¡æºç¢ºåº¦ï¼å¼·èª¿äºå¶å¨è«ç¤åé¡ä»»åä¸­çæ½åãéäºç¼ç¾å¼·èª¿äºé·ç§»å­¸ç¿å¨è¦ç¤åé¡ä¸­çæææ§ï¼ä¸¦æ­ç¤ºèç¾æçæåé²æ¨¡åç¸æ¯ï¼Vim æ¨¡åè¼éãé«æä¸æºç¢ºåº¦é«ï¼çºè¨åºæç¨æä¾äºæ°çè¦è§ãæ­¤å¤ï¼æ¬ç ç©¶ä¸­æåºçåºæ¼é·ç§»å­¸ç¿å Vision Mamba æ¨¡åçè¦ç¤åé¡æ¡æ¶å»£æ³é©ç¨æ¼å¶ä»é«å­¸å½±ååé¡åé¡ã

##### **How Does Critical Batch Size Scale in Pre-training?**
2410.21676v1 by Hanlin Zhang, Depen Morwani, Nikhil Vyas, Jingfeng Wu, Difan Zou, Udaya Ghai, Dean Foster, Sham Kakade

Training large-scale models under given resources requires careful design of
parallelism strategies. In particular, the efficiency notion of critical batch
size, concerning the compromise between time and compute, marks the threshold
beyond which greater data parallelism leads to diminishing returns. To
operationalize it, we propose a measure of CBS and pre-train a series of
auto-regressive language models, ranging from 85 million to 1.2 billion
parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and
careful control on factors such as batch size, momentum, and learning rate
along with its scheduling, we systematically investigate the impact of scale on
CBS. Then we fit scaling laws with respect to model and data sizes to decouple
their effects. Overall, our results demonstrate that CBS scales primarily with
data size rather than model size, a finding we justify theoretically through
the analysis of infinite-width limits of neural networks and
infinite-dimensional least squares regression. Of independent interest, we
highlight the importance of common hyper-parameter choices and strategies for
studying large-scale pre-training beyond fixed training durations.

æè¦ï¼å¨æ¢å®è³æºä¸è¨ç·´å¤§åæ¨¡åéè¦ä»ç´°è¨­è¨å¹³è¡èçç­ç¥ãç¹å¥æ¯ï¼ééµæ¹æ¬¡å¤§å°çæçæ¦å¿µï¼æ¶åæéåéç®ä¹éçæè¡·ï¼æ¨èªèè¶è¶æ­¤è¨çé»å¾ï¼æ´å¤§çè³æå¹³è¡èçå°å°è´å ±é¬éæ¸ãçºäºå°å¶ä»è«¸å¯¦æ½ï¼æåæåºä¸å CBS éåº¦ï¼ä¸¦é åè¨ç·´ä¸ç³»åèªè¿´æ­¸èªè¨æ¨¡åï¼ç¯åå¾ 8500 è¬å° 12 åååæ¸ï¼å¨ C4 è³æéä¸ãééå»£æ³çè¶åæ¸ææåä»ç´°æ§å¶æ¹æ¬¡å¤§å°ãåéåå­¸ç¿çç­å ç´ ä»¥åå¶æç¨ï¼æåç³»çµ±æ§å°ç ç©¶è¦æ¨¡å° CBS çå½±é¿ãç¶å¾ï¼æåæ¬åéæ¼æ¨¡ååè³æå¤§å°çç¸®æ¾å®å¾ï¼ä»¥åé¢å®åçå½±é¿ãç¸½é«èè¨ï¼æåççµæè¡¨æ CBS ä¸»è¦é¨èè³æå¤§å°èä¸æ¯æ¨¡åå¤§å°èç¸®æ¾ï¼æåééå°ç¥ç¶ç¶²è·¯çç¡éå¯¬åº¦éå¶åç¡éç¶­æå°äºä¹è¿´æ­¸çåæï¼å¨çè«ä¸è­æäºéä¸ç¼ç¾ãç¨ç«çèè¶£æ¯ï¼æåå¼·èª¿äºéç¨è¶åæ¸é¸æåç­ç¥çéè¦æ§ï¼ç¨æ¼ç ç©¶è¶è¶åºå®è¨ç·´æçºæéçå¤§è¦æ¨¡é è¨ç·´ã

##### **A Tutorial on Clinical Speech AI Development: From Data Collection to Model Validation**
2410.21640v1 by Si-Ioi Ng, Lingfeng Xu, Ingo Siegert, Nicholas Cummins, Nina R. Benway, Julie Liss, Visar Berisha

There has been a surge of interest in leveraging speech as a marker of health
for a wide spectrum of conditions. The underlying premise is that any
neurological, mental, or physical deficits that impact speech production can be
objectively assessed via automated analysis of speech. Recent advances in
speech-based Artificial Intelligence (AI) models for diagnosing and tracking
mental health, cognitive, and motor disorders often use supervised learning,
similar to mainstream speech technologies like recognition and verification.
However, clinical speech AI has distinct challenges, including the need for
specific elicitation tasks, small available datasets, diverse speech
representations, and uncertain diagnostic labels. As a result, application of
the standard supervised learning paradigm may lead to models that perform well
in controlled settings but fail to generalize in real-world clinical
deployments. With translation into real-world clinical scenarios in mind, this
tutorial paper provides an overview of the key components required for robust
development of clinical speech AI. Specifically, this paper will cover the
design of speech elicitation tasks and protocols most appropriate for different
clinical conditions, collection of data and verification of hardware,
development and validation of speech representations designed to measure
clinical constructs of interest, development of reliable and robust clinical
prediction models, and ethical and participant considerations for clinical
speech AI. The goal is to provide comprehensive guidance on building models
whose inputs and outputs link to the more interpretable and clinically
meaningful aspects of speech, that can be interrogated and clinically validated
on clinical datasets, and that adhere to ethical, privacy, and security
considerations by design.

æè¦ï¼<paragraph>æè¿åºç¾ä¸è¡å©ç¨èªè¨ä½çºåç¨®ç¾çæ¨è¨çç±æ½®ãå¶åºæ¬åææ¯ä»»ä½å½±é¿èªè¨ç¢ççç¥ç¶ãå¿çæççç¼ºé·ï¼é½å¯ä»¥ééèªè¨çèªåååæé²è¡å®¢è§è©ä¼°ãæè¿å¨èªè¨åºç¤äººå·¥æºæ§ (AI) æ¨¡åä¸çé²å±ï¼ç¨æ¼è¨ºæ·åè¿½è¹¤å¿çå¥åº·ãèªç¥åéåéç¤ï¼éå¸¸ä½¿ç¨ç£ç£å¼å­¸ç¿ï¼é¡ä¼¼æ¼ä¸»æµèªè¨æè¡ï¼ä¾å¦è¾¨è­åé©è­ãç¶èï¼è¨åºèªè¨ AI æå¶ç¨ç¹çææ°ï¼åæ¬éè¦ç¹å®çå¼å°ä»»åãå¯ç¨çè³æéå°ãèªè¨è¡¨è¿°å¤æ¨£ï¼ä»¥åè¨ºæ·æ¨ç±¤ä¸ç¢ºå®ãå æ­¤ï¼æç¨æ¨æºçç£ç£å¼å­¸ç¿ç¯ä¾å¯è½æå°è´å¨åæ§ç°å¢ä¸­è¡¨ç¾è¯å¥½çæ¨¡åï¼ä½å¨ç¾å¯¦ä¸ççè¨åºé¨ç½²ä¸­å»ç¡æ³æ¦åãæ¬æå­¸è«æèéäºå°å¶è½è­¯å°ç¾å¯¦ä¸ççè¨åºæå¢ï¼æä¾äºå¥å¨éç¼è¨åºèªè¨ AI æéééµçµæçæ¦è§ãå·é«ä¾èªªï¼æ¬æå°æ¶µèæé©åä¸åè¨åºçæ³çèªè¨å¼å°ä»»åååå®çè¨­è¨ãè³ææ¶éåç¡¬é«é©è­ãç¨æ¼è¡¡éè¨åºéæ³¨çµæ§çèªè¨è¡¨è¿°çéç¼åé©è­ãå¯é ä¸å¥å¨çè¨åºé æ¸¬æ¨¡åçéç¼ï¼ä»¥åè¨åºèªè¨ AI çå«çååèèèéãç®æ¨æ¯æä¾å¨é¢çæå°æ¹éï¼ä»¥å»ºç«å¶è¼¸å¥åè¼¸åºé£çµå°æ´ææ¼çè§£ä¸è¨åºä¸ææç¾©çèªè¨é¢åçæ¨¡åï¼å¯ä»¥å¨è¨åºè³æéä¸é²è¡è©¢ååè¨åºé©è­ï¼ä¸¦ä¸å¨è¨­è¨ä¸éµå®å«çãé±ç§åå®å¨èéã</paragraph>

##### **Can Large Language Models Replace Data Scientists in Clinical Research?**
2410.21591v1 by Zifeng Wang, Benjamin Danek, Ziwei Yang, Zheng Chen, Jimeng Sun

Data science plays a critical role in clinical research, but it requires
professionals with expertise in coding and medical data analysis. Large
language models (LLMs) have shown great potential in supporting medical tasks
and performing well in general coding tests. However, these tests do not assess
LLMs' ability to handle data science tasks in medicine, nor do they explore
their practical utility in clinical research. To address this, we developed a
dataset consisting of 293 real-world data science coding tasks, based on 39
published clinical studies, covering 128 tasks in Python and 165 tasks in R.
This dataset simulates realistic clinical research scenarios using patient
data. Our findings reveal that cutting-edge LLMs struggle to generate perfect
solutions, frequently failing to follow input instructions, understand target
data, and adhere to standard analysis practices. Consequently, LLMs are not yet
ready to fully automate data science tasks. We benchmarked advanced adaptation
methods and found two to be particularly effective: chain-of-thought prompting,
which provides a step-by-step plan for data analysis, which led to a 60%
improvement in code accuracy; and self-reflection, enabling LLMs to iteratively
refine their code, yielding a 38% accuracy improvement. Building on these
insights, we developed a platform that integrates LLMs into the data science
workflow for medical professionals. In a user study with five medical doctors,
we found that while LLMs cannot fully automate coding tasks, they significantly
streamline the programming process. We found that 80% of their submitted code
solutions were incorporated from LLM-generated code, with up to 96% reuse in
some cases. Our analysis highlights the potential of LLMs, when integrated into
expert workflows, to enhance data science efficiency in clinical research.

æè¦ï¼<paragraph>è³æç§å­¸å¨è¨åºç ç©¶ä¸­ç¼æ®ééµä½ç¨ï¼ä½å®éè¦å·åç·¨ç¢¼åé«çè³æåæå°æ¥­ç¥è­çå°æ¥­äººå¡ãå¤§åèªè¨æ¨¡å (LLM) å¨æ¯æ´é«çä»»ååå·è¡ä¸è¬ç·¨ç¢¼æ¸¬è©¦æ¹é¢å±ç¾äºæ¥µå¤§çæ½åãç¶èï¼éäºæ¸¬è©¦ä¸¦æªè©ä¼° LLM èçé«å­¸ä¸­è³æç§å­¸ä»»åçè½åï¼ä¹æ²ææ¢è¨å®åå¨è¨åºç ç©¶ä¸­çå¯¦éæç¨ãçºäºè§£æ±ºéååé¡ï¼æåéç¼äºä¸åç± 293 åçå¯¦ä¸çè³æç§å­¸ç·¨ç¢¼ä»»åçµæçè³æéï¼éäºä»»ååºæ¼ 39 é å·²ç¼è¡¨çè¨åºç ç©¶ï¼æ¶µè 128 å Python ä»»åå 165 å R ä»»åãæ­¤è³æéä½¿ç¨æ£èè³ææ¨¡æ¬çå¯¦çè¨åºç ç©¶å ´æ¯ãæåçç ç©¶çµæé¡¯ç¤ºï¼æåé²ç LLM é£ä»¥ç¢çå®ç¾çè§£æ±ºæ¹æ¡ï¼å¸¸å¸¸ç¡æ³éµå¾ªè¼¸å¥èªªæãçè§£ç®æ¨è³æï¼ä»¥åéµå®æ¨æºåæå¯¦åãå æ­¤ï¼LLM å°æªæºåå¥½å®å¨èªååè³æç§å­¸ä»»åãæåå°é²éé©ææ¹æ³é²è¡äºåºæºæ¸¬è©¦ï¼ç¼ç¾æå©åæ¹æ³ç¹å¥ææï¼æèéæç¤ºï¼å®æä¾äºè³æåæçéæ­¥è¨ç«ï¼ä½¿ç¨å¼ç¢¼æºç¢ºåº¦æåäº 60%ï¼ä»¥åèªæåçï¼ä½¿ LLM è½å¤ åè¦æ¹åå¶ç¨å¼ç¢¼ï¼ä½¿æºç¢ºåº¦æåäº 38%ãæ ¹æéäºè¦è§£ï¼æåéç¼äºä¸åå° LLM æ´åå°é«çå°æ¥­äººå¡è³æç§å­¸å·¥ä½æµç¨ä¸­çå¹³å°ãå¨èäºä½é«ççä½¿ç¨èç ç©¶ä¸­ï¼æåç¼ç¾ï¼éç¶ LLM ç¡æ³å®å¨èªååç·¨ç¢¼ä»»åï¼ä½å®åå¤§å¹ç°¡åäºç¨å¼è¨­è¨æµç¨ãæåç¼ç¾ï¼ä»åæäº¤çç¨å¼ç¢¼è§£æ±ºæ¹æ¡ä¸­æ 80% æ¯å¾ LLM çæçç¨å¼ç¢¼ä¸­ç´å¥çï¼å¨æäºææ³ä¸éç¨çé«é 96%ãæåçåæå¼·èª¿äº LLM å¨æ´åå°å°å®¶å·¥ä½æµç¨ä¸­çæ½åï¼ä»¥æé«è¨åºç ç©¶ä¸­çè³æç§å­¸æçã</paragraph>

##### **A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges**
2411.00024v1 by Zifeng Wang, Hanyin Wang, Benjamin Danek, Ying Li, Christina Mack, Hoifung Poon, Yajun Wang, Pranav Rajpurkar, Jimeng Sun

The integration of Large Language Models (LLMs) into medical applications has
sparked widespread interest across the healthcare industry, from drug discovery
and development to clinical decision support, assisting telemedicine, medical
devices, and healthcare insurance applications. This perspective paper aims to
discuss the inner workings of building LLM-powered medical AI applications and
introduces a comprehensive framework for their development. We review existing
literature and outline the unique challenges of applying LLMs in specialized
medical contexts. Additionally, we introduce a three-step framework to organize
medical LLM research activities: 1) Modeling: breaking down complex medical
workflows into manageable steps for developing medical-specific models; 2)
Optimization: optimizing the model performance with crafted prompts and
integrating external knowledge and tools, and 3) System engineering:
decomposing complex tasks into subtasks and leveraging human expertise for
building medical AI applications. Furthermore, we offer a detailed use case
playbook that describes various LLM-powered medical AI applications, such as
optimizing clinical trial design, enhancing clinical decision support, and
advancing medical imaging analysis. Finally, we discuss various challenges and
considerations for building medical AI applications with LLMs, such as handling
hallucination issues, data ownership and compliance, privacy, intellectual
property considerations, compute cost, sustainability issues, and responsible
AI requirements.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼æ´åå°é«çæç¨ä¸­ï¼å¨é«çç¢æ¥­ä¸­å¼èµ·å»£æ³èè¶£ï¼å¾è¥ç©ç¼ç¾åéç¼å°è¨åºæ±ºç­æ¯æ´ï¼åå©é è·é«çãé«çè¨­ååé«çä¿éªæç¨ãæ¬è§é»è«ææ¨å¨æ¢è¨å»ºæ§ LLM é©åçé«ç AI æç¨ç¨å¼çå§é¨éä½ï¼ä¸¦ä»ç´¹ä¸åå¨é¢çéç¼æ¶æ§ãæåæª¢è¦ç¾ææç»ä¸¦æ¦è¿°å¨å°æ¥­é«çæå¢ä¸­æç¨ LLM çç¨ç¹ææ°ãæ­¤å¤ï¼æåå¼å¥ä¸åä¸æ­¥é©æ¶æ§ä¾çµç¹é«ç LLM ç ç©¶æ´»åï¼1) å»ºæ¨¡ï¼å°è¤éçé«çå·¥ä½æµç¨åè§£çºå¯ç®¡ççæ­¥é©ï¼ä»¥éç¼ç¹å®æ¼é«ççæ¨¡åï¼2) æä½³åï¼ä½¿ç¨ç²¾å¿è¨­è¨çæç¤ºæä½³åæ¨¡åæè½ï¼ä¸¦æ´åå¤é¨ç¥è­åå·¥å·ï¼3) ç³»çµ±å·¥ç¨ï¼å°è¤éçä»»ååè§£çºå­ä»»åï¼ä¸¦å©ç¨äººé¡å°æ¥­ç¥è­ä¾å»ºæ§é«ç AI æç¨ç¨å¼ãæ­¤å¤ï¼æåæä¾ä¸åè©³ç´°çä½¿ç¨æ¡ä¾ç¯ä¾ï¼èªªæåç¨® LLM é©åçé«ç AI æç¨ç¨å¼ï¼ä¾å¦æä½³åè¨åºè©¦é©è¨­è¨ãå¢å¼·è¨åºæ±ºç­æ¯æ´åæ¨é²é«çå½±ååæãæå¾ï¼æåè¨è«å»ºæ§å·æ LLM çé«ç AI æç¨ç¨å¼çåç¨®ææ°åèéï¼ä¾å¦èçå¹»è¦ºåé¡ãè³ææææ¬ååè¦æ§ãé±ç§ãæºæ§è²¡ç¢æ¬èéãéç®ææ¬ãæ°¸çºæ§åé¡åè² è²¬ä»»ç AI éæ±ã

##### **Going Beyond H&E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?**
2410.21560v1 by Amaya Gallagher-Syed, Elena Pontarini, Myles J. Lewis, Michael R. Barnes, Gregory Slabaugh

This study evaluates the generalisation capabilities of state-of-the-art
histopathology foundation models on out-of-distribution multi-stain autoimmune
Immunohistochemistry datasets. We compare 13 feature extractor models,
including ImageNet-pretrained networks, and histopathology foundation models
trained on both public and proprietary data, on Rheumatoid Arthritis subtyping
and Sjogren's Disease detection tasks. Using a simple Attention-Based Multiple
Instance Learning classifier, we assess the transferability of learned
representations from cancer H&E images to autoimmune IHC images. Contrary to
expectations, histopathology-pretrained models did not significantly outperform
ImageNet-pretrained models. Furthermore, there was evidence of both autoimmune
feature misinterpretation and biased feature importance. Our findings highlight
the challenges in transferring knowledge from cancer to autoimmune
histopathology and emphasise the need for careful evaluation of AI models
across diverse histopathological tasks. The code to run this benchmark is
available at https://github.com/AmayaGS/ImmunoHistoBench.

æè¦ï¼æ¬ç ç©¶è©ä¼°äºæåé²ççµç¹ççå­¸åºç¤æ¨¡åå¨åå¸å¤å¤æè²èªèº«åç«åç«çµç¹åå­¸æ¸æéä¸çæ³åè½åãæåæ¯è¼äº 13 åç¹å¾µæåå¨æ¨¡åï¼åæ¬ ImageNet é è¨ç·´ç¶²è·¯ï¼ä»¥åå¨å¬å±åå°ææ¸æä¸è¨ç·´ççµç¹ççå­¸åºç¤æ¨¡åï¼å¨é¡é¢¨æ¿æ§éç¯çäºååä¹¾ç¥çæª¢æ¸¬ä»»åä¸ãä½¿ç¨ä¸åç°¡å®çåºæ¼æ³¨æåçå¤å¯¦ä¾å­¸ç¿åé¡å¨ï¼æåè©ä¼°äºå¾çç H&E å½±åå°èªèº«åç« IHC å½±åçå­¸ç¿è¡¨å¾µçå¯å³éæ§ãèé æç¸åï¼çµç¹ççå­¸é è¨ç·´æ¨¡åä¸¦æ²æé¡¯èåªæ¼ ImageNet é è¨ç·´æ¨¡åãæ­¤å¤ï¼æè­æè¡¨æå­å¨èªèº«åç«ç¹å¾µèª¤è§£ååå·®ç¹å¾µéè¦æ§ãæåçç ç©¶çµæå¼·èª¿äºå°ç¥è­å¾ççè½ç§»å°èªèº«åç«çµç¹ççå­¸çææ°ï¼ä¸¦å¼·èª¿äºè·¨ä¸åçµç¹ççå­¸ä»»åä»ç´°è©ä¼° AI æ¨¡åçå¿è¦æ§ãéè¡æ­¤åºæºæ¸¬è©¦çç¨å¼ç¢¼å¯å¨ https://github.com/AmayaGS/ImmunoHistoBench ç²å¾ã

##### **Towards Multi-dimensional Explanation Alignment for Medical Classification**
2410.21494v1 by Lijie Hu, Songning Lai, Wenshuo Chen, Hongru Xiao, Hongbin Lin, Lu Yu, Jingfeng Zhang, Di Wang

The lack of interpretability in the field of medical image analysis has
significant ethical and legal implications. Existing interpretable methods in
this domain encounter several challenges, including dependency on specific
models, difficulties in understanding and visualization, as well as issues
related to efficiency. To address these limitations, we propose a novel
framework called Med-MICN (Medical Multi-dimensional Interpretable Concept
Network). Med-MICN provides interpretability alignment for various angles,
including neural symbolic reasoning, concept semantics, and saliency maps,
which are superior to current interpretable methods. Its advantages include
high prediction accuracy, interpretability across multiple dimensions, and
automation through an end-to-end concept labeling process that reduces the need
for extensive human training effort when working with new datasets. To
demonstrate the effectiveness and interpretability of Med-MICN, we apply it to
four benchmark datasets and compare it with baselines. The results clearly
demonstrate the superior performance and interpretability of our Med-MICN.

æè¦ï¼é«çå½±ååæé åç¼ºä¹å¯è§£éæ§ï¼éå¸¶ä¾éå¤§çå«çåæ³å¾å½±é¿ãç¾æçå¯è§£éæ¹æ³å¨éåé åä¸­æé­éè¨±å¤ææ°ï¼åæ¬ä¾è³´ç¹å®æ¨¡åãé£ä»¥çè§£åè¦è¦ºåï¼ä»¥åèæçç¸éçåé¡ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºä¸åæ°çæ¶æ§ï¼ç¨±çº Med-MICNï¼é«çå¤ç¶­å¯è§£éæ¦å¿µç¶²è·¯ï¼ãMed-MICN æä¾åç¨®è§åº¦çå¯è§£éæ§æ¯å°ï¼åæ¬ç¥ç¶ç¬¦èæ¨çãæ¦å¿µèªæåé¡¯èæ§åï¼éäºé½åªæ¼ç®åçå¯è§£éæ¹æ³ãå®çåªé»åæ¬é«é æ¸¬æºç¢ºåº¦ãå¤ç¶­åº¦çå¯è§£éæ§ï¼ä»¥åééç«¯å°ç«¯æ¦å¿µæ¨è¨æµç¨èªååï¼éæ¸å°äºå¨ä½¿ç¨æ°è³æéæéè¦å¤§éäººå·¥è¨ç·´çå·¥ä½ãçºäºè­æ Med-MICN çæææ§åå¯è§£éæ§ï¼æåå°å¶æç¨æ¼åååºæºè³æéï¼ä¸¦èåºæºç·é²è¡æ¯è¼ãçµææ¸æ¥å°è­æäºæåç Med-MICN å·æåªç°çæè½åå¯è§£éæ§ã

##### **Multi-modal AI for comprehensive breast cancer prognostication**
2410.21256v1 by Jan Witowski, Ken Zeng, Joseph Cappadona, Jailan Elayoubi, Elena Diana Chiru, Nancy Chan, Young-Joon Kang, Frederick Howard, Irina Ostrovnaya, Carlos Fernandez-Granda, Freya Schnabel, Ugur Ozerdem, Kangning Liu, Zoe Steinsnyder, Nitya Thakore, Mohammad Sadic, Frank Yeung, Elisa Liu, Theodore Hill, Benjamin Swett, Danielle Rigau, Andrew Clayburn, Valerie Speirs, Marcus Vetter, Lina Sojak, Simone Muenst Soysal, Daniel Baumhoer, Khalil Choucair, Yu Zong, Lina Daoud, Anas Saad, Waleed Abdulsattar, Rafic Beydoun, Jia-Wern Pan, Haslina Makmur, Soo-Hwang Teo, Linda Ma Pak, Victor Angel, Dovile Zilenaite-Petrulaitiene, Arvydas Laurinavicius, Natalie Klar, Brian D. Piening, Carlo Bifulco, Sun-Young Jun, Jae Pak Yi, Su Hyun Lim, Adam Brufsky, Francisco J. Esteva, Lajos Pusztai, Yann LeCun, Krzysztof J. Geras

Treatment selection in breast cancer is guided by molecular subtypes and
clinical characteristics. Recurrence risk assessment plays a crucial role in
personalizing treatment. Current methods, including genomic assays, have
limited accuracy and clinical utility, leading to suboptimal decisions for many
patients. We developed a test for breast cancer patient stratification based on
digital pathology and clinical characteristics using novel AI methods.
Specifically, we utilized a vision transformer-based pan-cancer foundation
model trained with self-supervised learning to extract features from digitized
H&E-stained slides. These features were integrated with clinical data to form a
multi-modal AI test predicting cancer recurrence and death. The test was
developed and evaluated using data from a total of 8,161 breast cancer patients
across 15 cohorts originating from seven countries. Of these, 3,502 patients
from five cohorts were used exclusively for evaluation, while the remaining
patients were used for training. Our test accurately predicted our primary
endpoint, disease-free interval, in the five external cohorts (C-index: 0.71
[0.68-0.75], HR: 3.63 [3.02-4.37, p<0.01]). In a direct comparison (N=858), the
AI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay,
with a C-index of 0.67 [0.61-0.74] versus 0.61 [0.49-0.73], respectively.
Additionally, the AI test added independent information to Oncotype DX in a
multivariate analysis (HR: 3.11 [1.91-5.09, p<0.01)]). The test demonstrated
robust accuracy across all major breast cancer subtypes, including TNBC
(C-index: 0.71 [0.62-0.81], HR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic
tools are currently recommended by clinical guidelines. These results suggest
that our AI test can improve accuracy, extend applicability to a wider range of
patients, and enhance access to treatment selection tools.

æè¦ï¼<paragraph>ä¹³ççæ²»çé¸ææ¯ç±åå­äºååè¨åºç¹å¾µæå¼å°ãå¾©ç¼é¢¨éªè©ä¼°å¨åäººåæ²»çä¸­æ®æ¼è³ééè¦çè§è²ãç®åçæè¡ï¼åæ¬åºå é«åæï¼å·ææéçæºç¢ºåº¦åè¨åºæç¨ï¼å°è´è¨±å¤æ£èçæ²»çæ±ºç­æ¬¡æ¼æä½³ãæåéç¼äºä¸ç¨®åºæ¼æ¸ä½ççå­¸åè¨åºç¹å¾µçä¹³çæ£èåå±¤æª¢æ¸¬ï¼æ¡ç¨æ°ç©çäººå·¥æºæ§æ¹æ³ãå·é«ä¾èªªï¼æåå©ç¨äºä¸ååºæ¼è¦è¦ºè½æå¨çæ³çåºç¤æ¨¡åï¼ä¸¦ééèªæç£ç£å­¸ç¿é²è¡è¨ç·´ï¼ä»¥å¾æ¸ä½åç H&E æè²ç»çä¸­æåç¹å¾µãéäºç¹å¾µèè¨åºè³ææ´åï¼å½¢æä¸åå¤æ¨¡å¼çäººå·¥æºæ§æª¢æ¸¬ï¼ç¨æ¼é æ¸¬ççå¾©ç¼åæ­»äº¡ãè©²æª¢æ¸¬çéç¼åè©ä¼°ä½¿ç¨äºä¾èªä¸ååå®¶/å°åç 15 åç¾¤çµå± 8,161 åä¹³çæ£èçè³æãå¶ä¸­ï¼ä¾èªäºåç¾¤çµç 3,502 åæ£èå°éç¨æ¼è©ä¼°ï¼èå¶é¤æ£èåç¨æ¼è¨ç·´ãæåçæª¢æ¸¬æºç¢ºå°é æ¸¬äºæåçä¸»è¦çµé»ï¼å³äºåå¤é¨ç¾¤çµçç¡ç¾çéæï¼C ææ¸ï¼0.71 [0.68-0.75]ï¼HRï¼3.63 [3.02-4.37ï¼p<0.01]ï¼ãå¨ç´æ¥æ¯è¼ï¼N=858ï¼ä¸­ï¼äººå·¥æºæ§æª¢æ¸¬æ¯å®ç§æ³°Dxï¼æ¨æºç§è­·ç 21 åºå æª¢æ¸¬æ´æºç¢ºï¼C ææ¸åå¥çº 0.67 [0.61-0.74] å 0.61 [0.49-0.73]ãæ­¤å¤ï¼äººå·¥æºæ§æª¢æ¸¬å¨å¤è®éåæä¸­å¢å äºå®ç§æ³° Dx çç¨ç«è³è¨ï¼HRï¼3.11 [1.91-5.09ï¼p<0.01]ï¼ãè©²æª¢æ¸¬å¨ææä¸»è¦çä¹³çäºåä¸­é½è¡¨ç¾åºå¼·å¤§çæºç¢ºåº¦ï¼åæ¬ TNBCï¼C ææ¸ï¼0.71 [0.62-0.81]ï¼HRï¼3.81 [2.35-6.17ï¼p=0.02]ï¼ï¼è¨åºæåç®åä¸å»ºè­°ä½¿ç¨ä»»ä½è¨ºæ·å·¥å·ãéäºçµæè¡¨æï¼æåçäººå·¥æºæ§æª¢æ¸¬å¯ä»¥æé«æºç¢ºåº¦ï¼å°é©ç¨ç¯åæ´å±å°æ´å¤æ£èï¼ä¸¦å¢å ç²å¾æ²»çé¸æå·¥å·çæ©æã</paragraph>

##### **Belief in the Machine: Investigating Epistemological Blind Spots of Language Models**
2410.21195v1 by Mirac Suzgun, Tayfun Gur, Federico Bianchi, Daniel E. Ho, Thomas Icard, Dan Jurafsky, James Zou

As language models (LMs) become integral to fields like healthcare, law, and
journalism, their ability to differentiate between fact, belief, and knowledge
is essential for reliable decision-making. Failure to grasp these distinctions
can lead to significant consequences in areas such as medical diagnosis, legal
judgments, and dissemination of fake news. Despite this, current literature has
largely focused on more complex issues such as theory of mind, overlooking more
fundamental epistemic challenges. This study systematically evaluates the
epistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and
Llama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13
tasks. Our results reveal key limitations. First, while LMs achieve 86%
accuracy on factual scenarios, their performance drops significantly with false
scenarios, particularly in belief-related tasks. Second, LMs struggle with
recognizing and affirming personal beliefs, especially when those beliefs
contradict factual data, which raises concerns for applications in healthcare
and counseling, where engaging with a person's beliefs is critical. Third, we
identify a salient bias in how LMs process first-person versus third-person
beliefs, performing better on third-person tasks (80.7%) compared to
first-person tasks (54.4%). Fourth, LMs lack a robust understanding of the
factive nature of knowledge, namely, that knowledge inherently requires truth.
Fifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the
deeper reasoning. These findings highlight significant concerns about current
LMs' ability to reason about truth, belief, and knowledge while emphasizing the
need for advancements in these areas before broad deployment in critical
sectors.

æè¦ï¼é¨èèªè¨æ¨¡å (LM) æçºé«çä¿å¥ãæ³å¾åæ°èç­é åä¸å¯æç¼ºçä¸é¨åï¼å®åååäºå¯¦ãä¿¡å¿µåç¥è­çè½åå°æ¼å¯é çæ±ºç­è³ééè¦ãç¡æ³ææ¡éäºåå¥å¯è½æå¨é«çè¨ºæ·ãæ³å¾å¤æ±ºååæ°èå³æ­ç­é åé æéå¤§å¾æãåç®¡å¦æ­¤ï¼ç®åçæç»å¨å¾å¤§ç¨åº¦ä¸éæ³¨æ¼æ´è¤éçåé¡ï¼ä¾å¦å¿æºçè«ï¼èå¿½è¦äºæ´åºæ¬çèªè­è«ææ°ãæ¬ç ç©¶ä½¿ç¨æ°çè³æé KaBLEï¼å°ç¾ä»£ LMï¼åæ¬ GPT-4ãClaude-3 å Llama-3ï¼çèªè­è«æ¨çè½åé²è¡äºç³»çµ±è©ä¼°ï¼è©²è³æéåå« 13 åä»»åä¸­ç 13,000 ååé¡ãæåççµææ­ç¤ºäºééµéå¶ãé¦åï¼éç¶ LM å¨äºå¯¦å ´æ¯ä¸­éå° 86% çæºç¢ºåº¦ï¼ä½å®åå¨é¯èª¤å ´æ¯ä¸­çè¡¨ç¾å¤§å¹ä¸éï¼ç¹å¥æ¯å¨èä¿¡å¿µç¸éçä»»åä¸­ãå¶æ¬¡ï¼LM é£ä»¥è­å¥åè¯å®åäººä¿¡å¿µï¼ç¹å¥æ¯ç¶éäºä¿¡å¿µèäºå¯¦è³æç¸çç¾æï¼éå¼èµ·äºå°é«çä¿å¥åè«®è©¢æç¨ç¨å¼çææï¼å¨éäºæç¨ç¨å¼ä¸­ï¼èåäººçä¿¡å¿µäºåè³ééè¦ãç¬¬ä¸ï¼æåç¼ç¾ LM èçç¬¬ä¸äººç¨±èç¬¬ä¸äººç¨±ä¿¡å¿µçæ¹å¼å­å¨é¡¯èåå·®ï¼å¨ç¬¬ä¸äººç¨±ä»»åï¼80.7%ï¼ä¸çè¡¨ç¾åªæ¼ç¬¬ä¸äººç¨±ä»»åï¼54.4%ï¼ãç¬¬åï¼LM ç¼ºä¹å°ç¥è­çäºå¯¦æ§è³ªçç©©å¥çè§£ï¼å³ç¥è­æ¬è³ªä¸éè¦ççãç¬¬äºï¼LM ä¾è³´èªè¨ç·ç´¢é²è¡äºå¯¦æ¥æ ¸ï¼æææç¹éæ´æ·±å¥çæ¨çãéäºç¼ç¾çªé¡¯äºç¶å LM æ¨çççãä¿¡å¿µåç¥è­çè½åå­å¨éå¤§çæ®ï¼åæå¼·èª¿å¨å»£æ³é¨ç½²æ¼ééµé¨éä¹åï¼éè¦å¨éäºé ååå¾é²å±ã

##### **Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks**
2410.21175v1 by Jiawei Zhang, Jun Li, Reachsak Ly, Yunyi Liu, Jiangpeng Shu

For structural health monitoring, continuous and automatic crack detection
has been a challenging problem. This study is conducted to propose a framework
of automatic crack segmentation from high-resolution images containing crack
information about steel box girders of bridges. Considering the multi-scale
feature of cracks, convolutional neural network architecture of Feature Pyramid
Networks (FPN) for crack detection is proposed. As for input, 120 raw images
are processed via two approaches (shrinking the size of images and splitting
images into sub-images). Then, models with the proposed structure of FPN for
crack detection are developed. The result shows all developed models can
automatically detect the cracks at the raw images. By shrinking the images, the
computation efficiency is improved without decreasing accuracy. Because of the
separable characteristic of crack, models using the splitting method provide
more accurate crack segmentations than models using the resizing method.
Therefore, for high-resolution images, the FPN structure coupled with the
splitting method is an promising solution for the crack segmentation and
detection.

æè¦ï¼å°æ¼çµæ§å¥åº·ç£æ¸¬ï¼é£çºä¸èªåçè£ç¸«åµæ¸¬ä¸ç´æ¯ä¸åå·æææ°æ§çåé¡ãæ¬ç ç©¶æ¨å¨æåºä¸åå¾åå«æ©æ¨é¼ç®±æ¢è£ç¸«è³è¨çé«è§£æåº¦å½±åä¸­èªååå²è£ç¸«çæ¶æ§ãèéå°è£ç¸«çå¤å°ºåº¦ç¹å¾µï¼æåºç¨æ¼è£ç¸«åµæ¸¬ç Feature Pyramid Networks (FPN) æ²ç©ç¥ç¶ç¶²è·¯æ¶æ§ãè³æ¼è¼¸å¥ï¼120 å¼µåå§å½±åééå©ç¨®æ¹æ³èçï¼ç¸®å°å½±åå°ºå¯¸åå°å½±ååå²æå­å½±åï¼ãç¶å¾ï¼éç¼å·æ FPN æè­°çµæ§çè£ç¸«åµæ¸¬æ¨¡åãçµæé¡¯ç¤ºææå·²éç¼çæ¨¡åé½è½èªååµæ¸¬åå§å½±åä¸­çè£ç¸«ãèç±ç¸®å°å½±åï¼å¨ä¸éä½æºç¢ºåº¦ççæ³ä¸æåéç®æçãç±æ¼è£ç¸«å·æå¯åé¢çç¹å¾µï¼ä½¿ç¨åå²æ¹æ³çæ¨¡åæä¾æ¯ä½¿ç¨ç¸®æ¾æ¹æ³çæ¨¡åæ´æºç¢ºçè£ç¸«åå²ãå æ­¤ï¼å°æ¼é«è§£æåº¦å½±åï¼FPN çµæ§çµååå²æ¹æ³æ¯è£ç¸«åå²ååµæ¸¬çæåéçè§£æ±ºæ¹æ¡ã

##### **Trajectory Flow Matching with Applications to Clinical Time Series Modeling**
2410.21154v1 by Xi Zhang, Yuan Pu, Yuki Kawamura, Andrew Loza, Yoshua Bengio, Dennis L. Shung, Alexander Tong

Modeling stochastic and irregularly sampled time series is a challenging
problem found in a wide range of applications, especially in medicine. Neural
stochastic differential equations (Neural SDEs) are an attractive modeling
technique for this problem, which parameterize the drift and diffusion terms of
an SDE with neural networks. However, current algorithms for training Neural
SDEs require backpropagation through the SDE dynamics, greatly limiting their
scalability and stability. To address this, we propose Trajectory Flow Matching
(TFM), which trains a Neural SDE in a simulation-free manner, bypassing
backpropagation through the dynamics. TFM leverages the flow matching technique
from generative modeling to model time series. In this work we first establish
necessary conditions for TFM to learn time series data. Next, we present a
reparameterization trick which improves training stability. Finally, we adapt
TFM to the clinical time series setting, demonstrating improved performance on
three clinical time series datasets both in terms of absolute performance and
uncertainty prediction.

æè¦ï¼é¨æ©ä¸ä¸è¦ååæ¨£çæåºå»ºæ¨¡æ¯ä¸åå·æææ°æ§çåé¡ï¼å¨å»£æ³çæç¨ä¸­ç¼ç¾ï¼ç¹å¥æ¯å¨é«å­¸ä¸­ãç¥ç¶é¨æ©å¾®åæ¹ç¨ (Neural SDE) æ¯éååé¡ä¸åæå¸å¼åçå»ºæ¨¡æè¡ï¼å®ç¨ç¥ç¶ç¶²è·¯åæ¸å SDE çæ¼ç§»åæ´æ£é ãç¶èï¼ç®åè¨ç·´ç¥ç¶ SDE çæ¼ç®æ³éè¦éé SDE åæé²è¡ååå³æ­ï¼æ¥µå¤§å°éå¶äºå®åçå¯æ´åæ§åç©©å®æ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºè»è·¡æµå¹é (TFM)ï¼å®ä»¥ç¡æ¨¡æ¬çæ¹å¼è¨ç·´ä¸åç¥ç¶ SDEï¼ç¹éåæçååå³æ­ãTFM å©ç¨çæå¼å»ºæ¨¡ä¸­çæµå¹éæè¡ä¾å»ºæ¨¡æåºãå¨éé å·¥ä½ä¸­ï¼æåé¦åå»ºç« TFM å­¸ç¿æåºè³æçå¿è¦æ¢ä»¶ãæ¥ä¸ä¾ï¼æåæåºä¸åéæ°åæ¸åçæå·§ï¼å®æ¹é²äºè¨ç·´ç©©å®æ§ãæå¾ï¼æåå° TFM é©æå°è¨åºæåºè¨­å®ï¼è­æäºå¨çµå°æè½åä¸ç¢ºå®æ§é æ¸¬æ¹é¢ï¼å¨ä¸åè¨åºæåºè³æéä¸é½ææè½çæåã

##### **Diagnostic Performance of Deep Learning for Predicting Gliomas' IDH and 1p/19q Status in MRI: A Systematic Review and Meta-Analysis**
2411.02426v1 by Somayeh Farahani, Marjaneh Hejazi, Mehnaz Tabassum, Antonio Di Ieva, Neda Mahdavifar, Sidong Liu

Gliomas, the most common primary brain tumors, show high heterogeneity in
histological and molecular characteristics. Accurate molecular profiling, like
isocitrate dehydrogenase (IDH) mutation and 1p/19q codeletion, is critical for
diagnosis, treatment, and prognosis. This review evaluates MRI-based deep
learning (DL) models' efficacy in predicting these biomarkers. Following PRISMA
guidelines, we systematically searched major databases (PubMed, Scopus, Ovid,
and Web of Science) up to February 2024, screening studies that utilized DL to
predict IDH and 1p/19q codeletion status from MRI data of glioma patients. We
assessed the quality and risk of bias using the radiomics quality score and
QUADAS-2 tool. Our meta-analysis used a bivariate model to compute pooled
sensitivity, specificity, and meta-regression to assess inter-study
heterogeneity. Of the 565 articles, 57 were selected for qualitative synthesis,
and 52 underwent meta-analysis. The pooled estimates showed high diagnostic
performance, with validation sensitivity, specificity, and area under the curve
(AUC) of 0.84 [prediction interval (PI): 0.67-0.93, I2=51.10%, p < 0.05], 0.87
[PI: 0.49-0.98, I2=82.30%, p < 0.05], and 0.89 for IDH prediction, and 0.76
[PI: 0.28-0.96, I2=77.60%, p < 0.05], 0.85 [PI: 0.49-0.97, I2=80.30%, p <
0.05], and 0.90 for 1p/19q prediction, respectively. Meta-regression analyses
revealed significant heterogeneity influenced by glioma grade, data source,
inclusion of non-radiomics data, MRI sequences, segmentation and feature
extraction methods, and validation techniques. DL models demonstrate strong
potential in predicting molecular biomarkers from MRI scans, with significant
variability influenced by technical and clinical factors. Thorough external
validation is necessary to increase clinical utility.

æè¦ï¼è è³ªç¤æ¯æå¸¸è¦çåç¼æ§è¦è«ç¤ï¼å¨çµç¹å­¸ååå­ç¹å¾µä¸è¡¨ç¾åºé«åº¦ç°è³ªæ§ãæºç¢ºçåå­åæï¼å¦ç°æª¸æª¬é¸è«æ°«é¶ (IDH) çªè®å 1p/19q å±ç¼ºå¤±ï¼å°æ¼è¨ºæ·ãæ²»çåé å¾è³ééè¦ãæ¬ç¶è¿°è©ä¼°äºåºæ¼ MRI çæ·±åº¦å­¸ç¿ (DL) æ¨¡åå¨é æ¸¬éäºçç©æ¨èªç©æ¹é¢çæè½ãæç§ PRISMA æåï¼æåç³»çµ±å°æå°äºä¸»è¦è³æåº«ï¼PubMedãScopusãOvid å Web of Scienceï¼ï¼æéæªè³ 2024 å¹´ 2 æï¼ç¯©é¸äºå©ç¨ DL å¾è è³ªç¤æ£èç MRI è³æä¸­é æ¸¬ IDH å 1p/19q å±ç¼ºå¤±çæçç ç©¶ãæåä½¿ç¨æ¾å°çµå­¸åè³ªè©åå QUADAS-2 å·¥å·è©ä¼°äºåè³ªååå·®é¢¨éªãæåçå¾è¨­åæä½¿ç¨éè®æ¸æ¨¡åä¾è¨ç®åä½µæææ§ãç¹ç°æ§åå¾è¨­è¿´æ­¸ï¼ä»¥è©ä¼°ç ç©¶éç°è³ªæ§ãå¨ 565 ç¯æç« ä¸­ï¼æ 57 ç¯è¢«é¸ç¨é²è¡å®æ§ç¶åï¼52 ç¯é²è¡äºå¾è¨­åæãåä½µä¼°è¨å¼é¡¯ç¤ºåºå¾é«çè¨ºæ·æè½ï¼é©è­æææ§ãç¹ç°æ§åæ²ç·ä¸é¢ç© (AUC) åå¥çº 0.84 [é æ¸¬åé (PI)ï¼0.67-0.93ï¼I2=51.10%ï¼p < 0.05]ã0.87 [PIï¼0.49-0.98ï¼I2=82.30%ï¼p < 0.05] å 0.89ï¼ç¨æ¼ IDH é æ¸¬ï¼0.76 [PIï¼0.28-0.96ï¼I2=77.60%ï¼p < 0.05]ã0.85 [PIï¼0.49-0.97ï¼I2=80.30%ï¼p < 0.05] å 0.90ï¼ç¨æ¼ 1p/19q é æ¸¬ãå¾è¨­è¿´æ­¸åæé¡¯ç¤ºï¼è è³ªç¤åç´ãè³æä¾æºãæ¯å¦åå«éæ¾å°çµå­¸è³æãMRI åºåãåå²åç¹å¾µæåæ¹æ³ä»¥åé©è­æè¡ç­å ç´ æé æé¡¯èçç°è³ªæ§ãDL æ¨¡åå±ç¤ºäºå¾ MRI ææä¸­é æ¸¬åå­çç©æ¨èªç©çå¼·å¤§æ½åï¼ä½æè¡åè¨åºå ç´ æé æé¡¯èçè®ç°æ§ãå¾¹åºçå¤é¨åé©è­å°æ¼æé«è¨åºæç¨æ¯å¿è¦çã

##### **Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems**
2410.21014v1 by Helen Schneider, Sebastian Nowak, Aditya Parikh, Yannik C. Layer, Maike Theis, Wolfgang Block, Alois M. Sprinkart, Ulrike Attenberger, Rafet Sifa

Image-based diagnostic decision support systems (DDSS) utilizing deep
learning have the potential to optimize clinical workflows. However, developing
DDSS requires extensive datasets with expert annotations and is therefore
costly. Leveraging report contents from radiological data bases with Natural
Language Processing to annotate the corresponding image data promises to
replace labor-intensive manual annotation. As mining "real world" databases can
introduce label noise, noise-robust training losses are of great interest.
However, current noise-robust losses do not consider noise estimations that can
for example be derived based on the performance of the automatic label
generator used. In this study, we expand the noise-robust Deep Abstaining
Classifier (DAC) loss to an Informed Deep Abstaining Classifier (IDAC) loss by
incorporating noise level estimations during training. Our findings demonstrate
that IDAC enhances the noise robustness compared to DAC and several
state-of-the-art loss functions. The results are obtained on various simulated
noise levels using a public chest X-ray data set. These findings are reproduced
on an in-house noisy data set, where labels were extracted from the clinical
systems of the University Hospital Bonn by a text-based transformer. The IDAC
can therefore be a valuable tool for researchers, companies or clinics aiming
to develop accurate and reliable DDSS from routine clinical data.

æè¦ï¼<paragraph>å©ç¨æ·±åº¦å­¸ç¿çå½±åè¨ºæ·æ±ºç­æ¯æ´ç³»çµ± (DDSS) æå¯è½æä½³åè¨åºå·¥ä½æµç¨ãç¶èï¼éç¼ DDSS éè¦å¤§éå·åå°å®¶è¨»è§£çè³æéï¼å æ­¤ææ¬é«æãå©ç¨èªç¶èªè¨èçå¾æ¾å°ç§è³æåº«çå ±åå§å®¹ä¸­æ¨è¨»å°æçå½±åè³æï¼ææåä»£ååå¯éçæåæ¨è¨»ãç±æ¼ææãçå¯¦ä¸çãè³æåº«å¯è½æå¼å¥æ¨ç±¤éè¨ï¼å æ­¤å°éè¨ç©©å¥çè¨ç·´æå¤±éå¸¸éè¦ãç¶èï¼ç®åå°éè¨ç©©å¥çæå¤±å½æ¸ä¸¦æªèæ®éè¨ä¼°è¨ï¼ä¾å¦å¯ä»¥æ ¹ææä½¿ç¨çèªåæ¨ç±¤ç¢çå¨çæè½æ¨å°åºä¾ãå¨æ¬ç ç©¶ä¸­ï¼æåééå¨è¨ç·´æéç´å¥éè¨ç­ç´ä¼°è¨ï¼å°å°éè¨ç©©å¥çæ·±åº¦æ£æ¬åé¡å¨ (DAC) æå¤±å½æ¸æ´åçºææºæ·±åº¦æ£æ¬åé¡å¨ (IDAC) æå¤±å½æ¸ãæåçç ç©¶çµæé¡¯ç¤ºï¼è DAC åå¤ç¨®æåé²çæå¤±å½æ¸ç¸æ¯ï¼IDAC å¢å¼·äºå°éè¨çç©©å¥æ§ãéäºçµææ¯ä½¿ç¨å¬éçè¸é¨ X åè³æéï¼å¨åç¨®æ¨¡æ¬éè¨ç­ç´ä¸­ç²å¾çãéäºç ç©¶çµæå¨å§é¨éè¨è³æéä¸éç¾ï¼å¶ä¸­æ¨ç±¤æ¯ç±ææ¬è½æå¨å¾æ³¢æ©å¤§å­¸é«é¢çè¨åºç³»çµ±ä¸­èååºä¾çãå æ­¤ï¼IDAC å¯ä»¥æçºç ç©¶äººå¡ãå¬å¸æè¨ºæå¾ä¾è¡è¨åºè³æéç¼æºç¢ºä¸å¯é ç DDSS çæå¹å¼å·¥å·ã</paragraph>

##### **Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering**
2410.21000v1 by Zhilin Zhang, Jie Wang, Ruiqi Zhu, Xiaoliang Gong

Medical Visual Question Answering (MedVQA) has gained increasing attention at
the intersection of computer vision and natural language processing. Its
capability to interpret radiological images and deliver precise answers to
clinical inquiries positions MedVQA as a valuable tool for supporting
diagnostic decision-making for physicians and alleviating the workload on
radiologists. While recent approaches focus on using unified pre-trained large
models for multi-modal fusion like cross-modal Transformers, research on more
efficient fusion methods remains relatively scarce within this discipline. In
this paper, we introduce a novel fusion model that integrates Orthogonality
loss, Multi-head attention and Bilinear Attention Network (OMniBAN) to achieve
high computational efficiency and strong performance without the need for
pre-training. We conduct comprehensive experiments and clarify aspects of how
to enhance bilinear attention fusion to achieve performance comparable to that
of large models. Experimental results show that OMniBAN outperforms traditional
models on key MedVQA benchmarks while maintaining a lower computational cost,
which indicates its potential for efficient clinical application in radiology
and pathology image question answering.

æè¦ï¼é«çè¦è¦ºåç­ (MedVQA) å¨é»è¦è¦è¦ºåèªç¶èªè¨èççäº¤éä¸­ç²å¾è¶ä¾è¶å¤çéæ³¨ãå®è½å¤ è§£è®æ¾å°å½±åä¸¦å°è¨åºè©¢åæä¾ç²¾ç¢ºç­æ¡çè½åï¼ä½¿ MedVQA æçºæ¯æ´é«å¸«è¨ºæ·æ±ºç­åæ¸è¼æ¾å°ç§é«å¸«å·¥ä½è² æçå¯¶è²´å·¥å·ãéç¶æè¿çæ¹æ³èéæ¼ä½¿ç¨çµ±ä¸çé åè¨ç·´å¤§åæ¨¡åé²è¡å¤æ¨¡å¼èåï¼ä¾å¦è·¨æ¨¡æ Transformerï¼ä½å°æ¼æ´ææççèåæ¹æ³çç ç©¶å¨æ­¤é åä¸­ä»ç¶ç¸å°ç¨å°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çèåæ¨¡åï¼å®æ´åäºæ­£äº¤æå¤±ãå¤é ­æ³¨æååéç·æ§æ³¨æåç¶²è·¯ (OMniBAN)ï¼ä»¥å¨ä¸éè¦é åè¨ç·´çææ³ä¸å¯¦ç¾é«è¨ç®æçåå¼·å¤§æè½ãæåé²è¡äºå¨é¢çå¯¦é©ï¼ä¸¦éæ¸äºå¦ä½å¢å¼·éç·æ§æ³¨æåèåä»¥å¯¦ç¾èå¤§åæ¨¡åç¸ç¶çæè½ãå¯¦é©çµæè¡¨æï¼OMniBAN å¨ééµç MedVQA åºæºä¸åªæ¼å³çµ±æ¨¡åï¼åæç¶­æè¼ä½çè¨ç®ææ¬ï¼éè¡¨æå®å¨æ¾å°å­¸åççå½±ååç­ä¸­å·æé«æè¨åºæç¨çæ½åã

##### **Large Language Model Benchmarks in Medical Tasks**
2410.21348v1 by Lawrence K. Q. Yan, Ming Li, Yichao Zhang, Caitlyn Heqi Yin, Cheng Fei, Benji Peng, Ziqian Bi, Pohsun Feng, Keyu Chen, Junyu Liu, Qian Niu

With the increasing application of large language models (LLMs) in the
medical domain, evaluating these models' performance using benchmark datasets
has become crucial. This paper presents a comprehensive survey of various
benchmark datasets employed in medical LLM tasks. These datasets span multiple
modalities including text, image, and multimodal benchmarks, focusing on
different aspects of medical knowledge such as electronic health records
(EHRs), doctor-patient dialogues, medical question-answering, and medical image
captioning. The survey categorizes the datasets by modality, discussing their
significance, data structure, and impact on the development of LLMs for
clinical tasks such as diagnosis, report generation, and predictive decision
support. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and
CheXpert, which have facilitated advancements in tasks like medical report
generation, clinical summarization, and synthetic data generation. The paper
summarizes the challenges and opportunities in leveraging these benchmarks for
advancing multimodal medical intelligence, emphasizing the need for datasets
with a greater degree of language diversity, structured omics data, and
innovative approaches to synthesis. This work also provides a foundation for
future research in the application of LLMs in medicine, contributing to the
evolving field of medical artificial intelligence.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¨é«çé åçæç¨æ¥çå»£æ³ï¼ä½¿ç¨åºæºè³æéè©ä¼°éäºæ¨¡åçæè½å·²è®å¾è³ééè¦ãæ¬æå°ç¨æ¼é«ç LLM ä»»åçåç¨®åºæºè³æéé²è¡äºå¨é¢çèª¿æ¥ãéäºè³æéè·¨è¶å¤ç¨®æ¨¡å¼ï¼åæ¬æå­ãå½±ååå¤æ¨¡æåºæºï¼éé»éæ³¨é»å­å¥åº·ç´é (EHR)ãé«çå°è©±ãé«çåç­åé«çå½±åæ¨é¡ç­é«çç¥è­çä¸åé¢åãèª¿æ¥ææ¨¡å¼å°è³æéé²è¡åé¡ï¼è¨è«å®åçéè¦æ§ãè³æçµæ§åå°ç¨æ¼è¨ºæ·ãå ±åçæåé æ¸¬æ§æ±ºç­æ¯æ´ç­è¨åºä»»åç LLM éç¼çå½±é¿ãä¸»è¦åºæºåæ¬ MIMIC-IIIãMIMIC-IVãBioASQãPubMedQA å CheXpertï¼å®åä¿è¿äºé«çå ±åçæãè¨åºæè¦ååæè³æçæç­ä»»åçé²å±ãæ¬æç¸½çµäºå©ç¨éäºåºæºä¾æ¨é²å¤æ¨¡æé«çæºè½çææ°åæ©éï¼å¼·èª¿äºå°å·ææ´å¤§èªè¨å¤æ¨£æ§ãçµæ§åçµå­¸è³æååµæ°åææ¹æ³çè³æéçéæ±ãéé å·¥ä½ä¹çº LLM å¨é«å­¸ä¸­çæç¨æä¾äºæªä¾ç ç©¶çåºç¤ï¼çºé«çäººå·¥æºæ§çæ¼é²é åååºè²¢ç»ã

##### **Vascular Segmentation of Functional Ultrasound Images using Deep Learning**
2410.22365v1 by Hana Sebia, Thomas Guyet, MickaÃ«l Pereira, Marco Valdebenito, Hugues Berry, Benjamin Vidal

Segmentation of medical images is a fundamental task with numerous
applications. While MRI, CT, and PET modalities have significantly benefited
from deep learning segmentation techniques, more recent modalities, like
functional ultrasound (fUS), have seen limited progress. fUS is a non invasive
imaging method that measures changes in cerebral blood volume (CBV) with high
spatio-temporal resolution. However, distinguishing arterioles from venules in
fUS is challenging due to opposing blood flow directions within the same pixel.
Ultrasound localization microscopy (ULM) can enhance resolution by tracking
microbubble contrast agents but is invasive, and lacks dynamic CBV
quantification. In this paper, we introduce the first deep learning-based
segmentation tool for fUS images, capable of differentiating signals from
different vascular compartments, based on ULM automatic annotation and enabling
dynamic CBV quantification. We evaluate various UNet architectures on fUS
images of rat brains, achieving competitive segmentation performance, with 90%
accuracy, a 71% F1 score, and an IoU of 0.59, using only 100 temporal frames
from a fUS stack. These results are comparable to those from tubular structure
segmentation in other imaging modalities. Additionally, models trained on
resting-state data generalize well to images captured during visual
stimulation, highlighting robustness. This work offers a non-invasive,
cost-effective alternative to ULM, enhancing fUS data interpretation and
improving understanding of vessel function. Our pipeline shows high linear
correlation coefficients between signals from predicted and actual compartments
in both cortical and deeperregions, showcasing its ability to accurately
capture blood flow dynamics.

æè¦ï¼<paragraph>é«å­¸å½±åçåå²æ¯é åºç¤ä»»åï¼æè¨±å¤æç¨ãéç¶ MRIãCT å PET ç­æ¹å¼å·²å¾æ·±åº¦å­¸ç¿åå²æè¡ä¸­åçè¯å¤ï¼ä½ååè½æ§è¶é³æ³¢ (fUS) ç­è¼æ°çæ¹å¼é²å±æéãfUS æ¯ä¸ç¨®éä¾µå¥æ§çå½±åæ¹æ³ï¼å¯æ¸¬éè¦è¡å®¹é (CBV) çè®åï¼å·æé«æç©ºè§£æåº¦ãç¶èï¼ç±æ¼åä¸ååç´ ä¸­è¡æµæ¹åç¸åï¼å æ­¤å¨ fUS ä¸­ååå°åèåå°éèå·æææ°æ§ãè¶é³æ³¢å®ä½é¡¯å¾®é¡ (ULM) å¯ä»¥ééè¿½è¹¤å¾®æ°£æ³¡å°æ¯åä¾å¢å¼·è§£æåº¦ï¼ä½å·æä¾µå¥æ§ï¼ä¸ç¼ºä¹åæ CBV éåãå¨æ¬æä¸­ï¼æåä»ç´¹äºç¬¬ä¸ååºæ¼æ·±åº¦å­¸ç¿ç fUS å½±ååå²å·¥å·ï¼å®è½å¤ æ ¹æ ULM èªåè¨»è§£ååä¸åè¡ç®¡åå®¤çè¨èï¼ä¸¦åç¨åæ CBV éåãæåå¨èé¼ å¤§è¦ç fUS å½±åä¸è©ä¼°äºåç¨® UNet æ¶æ§ï¼åä½¿ç¨ fUS å çä¸­ç 100 åæéå¹ï¼å°±éå°äºå·æç«¶ç­åçåå²æè½ï¼æºç¢ºççº 90%ï¼F1 åæ¸çº 71%ï¼IoU çº 0.59ãéäºçµæèå¶ä»å½±åæ¹å¼ä¸­ç®¡ççµæ§åå²ççµæç¸ç¶ãæ­¤å¤ï¼å¨éæ­¢çæè³æä¸è¨ç·´çæ¨¡åå¯ä»¥å¾å¥½å°æ¨å»£å°å¨è¦è¦ºåºæ¿æéæ·åçå½±åï¼çªé¡¯äºå¶ç©©å¥æ§ãéé å·¥ä½æä¾äºä¸åéä¾µå¥æ§ãå·æææ¬æçç ULM æ¿ä»£æ¹æ¡ï¼å¢å¼·äº fUS è³æçè©®éï¼ä¸¦æ¹åäºå°è¡ç®¡åè½ççè§£ãæåçç®¡ç·å¨é æ¸¬åå®¤åå¯¦éåå®¤çè¨èä¹éé¡¯ç¤ºåºå¾é«çç·æ§ç¸éä¿æ¸ï¼ç¡è«æ¯å¨ç®è³ªéæ¯æ·±å±¤ååï¼é½å±ç¤ºäºå¶æºç¢ºææè¡æµåæçè½åã</paragraph>

##### **Language Models And A Second Opinion Use Case: The Pocket Professional**
2410.20636v1 by David Noever

This research tests the role of Large Language Models (LLMs) as formal second
opinion tools in professional decision-making, particularly focusing on complex
medical cases where even experienced physicians seek peer consultation. The
work analyzed 183 challenging medical cases from Medscape over a 20-month
period, testing multiple LLMs' performance against crowd-sourced physician
responses. A key finding was the high overall score possible in the latest
foundational models (>80% accuracy compared to consensus opinion), which
exceeds most human metrics reported on the same clinical cases (450 pages of
patient profiles, test results). The study rates the LLMs' performance
disparity between straightforward cases (>81% accuracy) and complex scenarios
(43% accuracy), particularly in these cases generating substantial debate among
human physicians. The research demonstrates that LLMs may be valuable as
generators of comprehensive differential diagnoses rather than as primary
diagnostic tools, potentially helping to counter cognitive biases in clinical
decision-making, reduce cognitive loads, and thus remove some sources of
medical error. The inclusion of a second comparative legal dataset (Supreme
Court cases, N=21) provides added empirical context to the AI use to foster
second opinions, though these legal challenges proved considerably easier for
LLMs to analyze. In addition to the original contributions of empirical
evidence for LLM accuracy, the research aggregated a novel benchmark for others
to score highly contested question and answer reliability between both LLMs and
disagreeing human practitioners. These results suggest that the optimal
deployment of LLMs in professional settings may differ substantially from
current approaches that emphasize automation of routine tasks.

æè¦ï¼éé ç ç©¶æ¸¬è©¦äºå¤§åèªè¨æ¨¡å (LLM) å¨å°æ¥­æ±ºç­ä¸­ä½çºæ­£å¼ç¬¬äºæè¦å·¥å·çè§è²ï¼ç¹å¥èéæ¼è¤éçé«çæ¡ä¾ï¼å³ä½¿ç¶é©è±å¯çé«å¸«ä¹æå°æ±ååè«®è©¢ãéé å·¥ä½åæäº Medscape å¨ 20 åææéç 183 åå·æææ°æ§çé«çæ¡ä¾ï¼æ¸¬è©¦å¤å LLM çè¡¨ç¾ï¼ä¸¦èç¾¤ç¾å¤åçé«å¸«åæé²è¡æ¯è¼ãä¸åééµç¼ç¾æ¯ææ°åºç¤æ¨¡åä¸­å¯è½çé«ç¸½é«åæ¸ï¼èå±è­æè¦ç¸æ¯ï¼æºç¢ºç >80%ï¼ï¼éè¶éäºéå°ç¸åè¨åºæ¡ä¾å ±åçå¤§å¤æ¸äººé¡ææ¨ï¼450 é çæ£èæªæ¡ãæª¢é©çµæï¼ãéé ç ç©¶è©ä¼°äº LLM å¨ç´æ¥æ¡ä¾ï¼æºç¢ºç >81%ï¼åè¤éæå¢ï¼æºç¢ºç 43%ï¼ä¹éçè¡¨ç¾å·®ç°ï¼ç¹å¥æ¯å¨éäºæ¡ä¾ä¸­ï¼æå¨äººé¡é«å¸«éç¢çå¤§éçè¾¯è«ãéé ç ç©¶è­æï¼LLM å¯è½æ¯æå¹å¼çå¨é¢éå¥è¨ºæ·ç¢çå¨ï¼èéä¸»è¦çè¨ºæ·å·¥å·ï¼æ½å¨æå©æ¼å°æè¨åºæ±ºç­ä¸­çèªç¥åèª¤ãæ¸å°èªç¥è² æï¼ä¸¦å æ­¤æ¶é¤ä¸äºé«çé¯èª¤çæ ¹æºãå å¥ç¬¬äºåæ¯è¼æ³å¾è³æéï¼æé«æ³é¢æ¡ä¾ï¼N=21ï¼çº AI ç¨æ¼ä¿é²ç¬¬äºæè¦æä¾äºé¡å¤çç¶é©èæ¯ï¼åç®¡éäºæ³å¾ææ°è¢«è­æå° LLM ä¾èªªæ´å®¹æåæãé¤äº LLM æºç¢ºæ§çç¶é©è­æçåå§è²¢ç»å¤ï¼éé ç ç©¶éå¯ç¸½äºä¸åæ°çåºæºï¼ä¾å¶ä»äººçº LLM åæè¦åæ­§çäººé¡å¾æ¥­äººå¡ä¹éé«åº¦æç­è­°çåé¡åç­æ¡çå¯é æ§é²è¡è©åãéäºçµæè¡¨æï¼LLM å¨å°æ¥­ç°å¢ä¸­çæä½³é¨ç½²å¯è½èå¼·èª¿èªååä¾è¡ä»»åçç¶åæ¹æ³æå¾å¤§ä¸åã

##### **Improving Decision Sparsity**
2410.20483v1 by Yiyang Sun, Tong Wang, Cynthia Rudin

Sparsity is a central aspect of interpretability in machine learning.
Typically, sparsity is measured in terms of the size of a model globally, such
as the number of variables it uses. However, this notion of sparsity is not
particularly relevant for decision-making; someone subjected to a decision does
not care about variables that do not contribute to the decision. In this work,
we dramatically expand a notion of decision sparsity called the Sparse
Explanation Value(SEV) so that its explanations are more meaningful. SEV
considers movement along a hypercube towards a reference point. By allowing
flexibility in that reference and by considering how distances along the
hypercube translate to distances in feature space, we can derive sparser and
more meaningful explanations for various types of function classes. We present
cluster-based SEV and its variant tree-based SEV, introduce a method that
improves credibility of explanations, and propose algorithms that optimize
decision sparsity in machine learning models.

æè¦ï¼ç¨çæ§æ¯æ©å¨å­¸ç¿ä¸­å¯è§£éæ§çæ ¸å¿é¢åã
ä¸è¬ä¾èªªï¼ç¨çæ§æ¯ä»¥æ¨¡åæ´é«çå¤§å°ä¾è¡¡éï¼ä¾å¦å®ä½¿ç¨çè®æ¸æ¸éãç¶èï¼éç¨®ç¨çæ§æ¦å¿µèæ±ºç­å¶å®ä¸¦ç¡ç¹å¥ç¸éï¼åå°æ±ºç­å½±é¿çäººä¸¦ä¸å¨ä¹é£äºèæ±ºç­ç¡éçè®æ¸ãå¨éé å·¥ä½ä¸­ï¼æåå¤§å¹æ´å±äºä¸åç¨±çºç¨çè§£éå¼ (SEV) çæ±ºç­ç¨çæ§æ¦å¿µï¼ä½¿å¶è§£éæ´å·æç¾©ãSEV èéæ²¿èè¶ç«æ¹é«æååèé»çç§»åãééåè¨±è©²åèçéæ´»æ§ï¼ä¸¦èéæ²¿èè¶ç«æ¹é«çè·é¢å¦ä½è½æçºç¹å¾µç©ºéä¸­çè·é¢ï¼æåå¯ä»¥éå°åç¨®å½æ¸é¡å¥æ¨å°åºæ´ç¨çä¸æ´ææç¾©çè§£éãæåæåºåºæ¼å¢éç SEV åå¶è®é«åºæ¼æ¨¹ççµæ§ç SEVï¼å¼å¥ä¸ç¨®æ¹æ³ä¾æåè§£éçå¯ä¿¡åº¦ï¼ä¸¦æåºæä½³åæ©å¨å­¸ç¿æ¨¡åä¸­æ±ºç­ç¨çæ§çæ¼ç®æ³ã

##### **MedGo: A Chinese Medical Large Language Model**
2410.20428v1 by Haitao Zhang, Bo An

Large models are a hot research topic in the field of artificial
intelligence. Leveraging their generative capabilities has the potential to
enhance the level and quality of medical services. In response to the
limitations of current large language models, which often struggle with
accuracy and have narrow capabilities in medical applications, this paper
presents a Chinese medical large language model, MedGo. MedGo was trained using
a combination of high quality unsupervised medical data, supervised data, and
preference alignment data, aimed at enhancing both its versatility and
precision in medical tasks. The model was evaluated through the public CBLUE
benchmark and a manually constructed dataset ClinicalQA. The results
demonstrate that MedGo achieved promising performance across various Chinese
medical information processing tasks, achieved the first place in the CBLUE
evaluation. Additionally, on our constructed dataset ClinicalQA, MedGo
outperformed its base model Qwen2, highlighting its potential to improve both
automated medical question answering and clinical decision support. These
experimental results demonstrate that MedGo possesses strong information
processing capabilities in the medical field. At present, we have successfully
deployed MedGo at Shanghai East Hospital.

æè¦ï¼å¤§åæ¨¡åæ¯äººå·¥æºè½é¢åçç ç©¶ç­ç¹ãå©ç¨å®ä»¬çæçè½åæå¯è½æé«å»çæå¡çæ°´å¹³åè´¨éãä¸ºäºè§£å³å½åå¤§åè¯­è¨æ¨¡åçå±éæ§ï¼è¿äºæ¨¡åéå¸¸é¾ä»¥è¾¾å°åç¡®æ§ï¼å¹¶ä¸å¨å»çåºç¨ä¸­çè½åè¾çªï¼æ¬ææåºäºä¸ä¸ªä¸­æå»çå¤§åè¯­è¨æ¨¡å MedGoãMedGo ä½¿ç¨é«è´¨éæ çç£å»çæ°æ®ãçç£æ°æ®ååå¥½å¯¹é½æ°æ®çç»åè¿è¡è®­ç»ï¼æ¨å¨å¢å¼ºå¶å¨å»çä»»å¡ä¸­çå¤åè½æ§ååç¡®æ§ãè¯¥æ¨¡åéè¿å¬å± CBLUE åºååæå¨æå»ºçæ°æ®é ClinicalQA è¿è¡äºè¯ä¼°ãç»æè¡¨æï¼MedGo å¨åç§ä¸­æå»çä¿¡æ¯å¤çä»»å¡ä¸­åå¾äºå¯åçæ§è½ï¼å¨ CBLUE è¯ä¼°ä¸­åå¾äºç¬¬ä¸åãæ­¤å¤ï¼å¨æä»¬çæå»ºæ°æ®é ClinicalQA ä¸ï¼MedGo ä¼äºå¶åºç¡æ¨¡å Qwen2ï¼çªåºäºå¶å¨æ¹è¿èªå¨åå»çé®é¢è§£ç­åä¸´åºå³ç­æ¯ææ¹é¢çæ½åãè¿äºå®éªç»æè¡¨æï¼MedGo å¨å»çé¢åæ¥æå¼ºå¤§çä¿¡æ¯å¤çè½åãç®åï¼æä»¬å·²æåå¨ä¸æµ·ä¸æ¹å»é¢é¨ç½²äº MedGoã

##### **Addressing the Pitfalls of Image-Based Structural Health Monitoring: A Focus on False Positives, False Negatives, and Base Rate Bias**
2410.20384v1 by Vagelis Plevris

This study explores the limitations of image-based structural health
monitoring (SHM) techniques in detecting structural damage. Leveraging machine
learning and computer vision, image-based SHM offers a scalable and efficient
alternative to manual inspections. However, its reliability is impacted by
challenges such as false positives, false negatives, and environmental
variability, particularly in low base rate damage scenarios. The Base Rate Bias
plays a significant role, as low probabilities of actual damage often lead to
misinterpretation of positive results. This study uses both Bayesian analysis
and a frequentist approach to evaluate the precision of damage detection
systems, revealing that even highly accurate models can yield misleading
results when the occurrence of damage is rare. Strategies for mitigating these
limitations are discussed, including hybrid systems that combine multiple data
sources, human-in-the-loop approaches for critical assessments, and improving
the quality of training data. These findings provide essential insights into
the practical applicability of image-based SHM techniques, highlighting both
their potential and their limitations for real-world infrastructure monitoring.

æè¦ï¼æ¬ç ç©¶æ¢è¨äºåºæ¼å½±åççµæ§å¥åº·ç£æ¸¬ (SHM) æè¡å¨æª¢æ¸¬çµæ§æå£æ¹é¢çéå¶ãèç±æ©å¨å­¸ç¿åé»è¦è¦è¦ºï¼åºæ¼å½±åç SHM æä¾äºå¯æ´åä¸ææççæ¿ä»£äººå·¥æª¢æ¥çæ¹æ³ãç¶èï¼å¶å¯é æ§åå°ææ°çå½±é¿ï¼ä¾å¦åé½æ§ãåé°æ§ï¼ä»¥åç°å¢è®ç°æ§ï¼ç¹å¥æ¯å¨ä½åºåºæå£æå¢ä¸­ãåºåºæ¯çåå·®æ®æ¼äºéè¦çè§è²ï¼å çºå¯¦éæå£çä½æ©çå¸¸å¸¸å°è´å°æ¼é½æ§çµæçèª¤è§£ãæ¬ç ç©¶åæä½¿ç¨è²æ°åæåé »çè«æ¹æ³ä¾è©ä¼°æå£æª¢æ¸¬ç³»çµ±çç²¾æºåº¦ï¼æ­ç¤ºå³ä½¿é«åº¦ç²¾ç¢ºçæ¨¡åå¨æå£ç¼ççç¨å°æä¹å¯è½ç¢çèª¤å°æ§ççµæãè¨è«äºæ¸è¼éäºéå¶çç­ç¥ï¼åæ¬çµåå¤éè³æä¾æºçæ··åç³»çµ±ãå°æ¼ééµè©ä¼°çäººé¡ä»å¥æ¹æ³ï¼ä»¥åæ¹åè¨ç·´è³æåè³ªãéäºç¼ç¾æä¾äºå°æ¼åºæ¼å½±åç SHM æè¡å¯¦åé©ç¨æ§çéè¦è¦è§£ï¼çªé¡¯äºå®åå¨ç¾å¯¦ä¸çåºç¤è¨­æ½ç£æ¸¬æ¹é¢çæ½ååéå¶ã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-07**|**ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning**|David Junhao Zhang et.al.|[2411.05003v1](http://arxiv.org/abs/2411.05003v1)|null|
|**2024-11-07**|**Analyzing The Language of Visual Tokens**|David M. Chan et.al.|[2411.05001v1](http://arxiv.org/abs/2411.05001v1)|null|
|**2024-11-07**|**Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?**|Jonathan Roberts et.al.|[2411.05000v1](http://arxiv.org/abs/2411.05000v1)|null|
|**2024-11-07**|**LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation**|Weiquan Huang et.al.|[2411.04997v1](http://arxiv.org/abs/2411.04997v1)|[link](https://github.com/microsoft/LLM2CLIP)|
|**2024-11-07**|**HourVideo: 1-Hour Video-Language Understanding**|Keshigeyan Chandrasegaran et.al.|[2411.04998v1](http://arxiv.org/abs/2411.04998v1)|null|
|**2024-11-07**|**Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models**|Weixin Liang et.al.|[2411.04996v1](http://arxiv.org/abs/2411.04996v1)|null|
|**2024-11-07**|**Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives**|Hao Sun et.al.|[2411.04991v1](http://arxiv.org/abs/2411.04991v1)|[link](https://github.com/holarissun/rewardmodelingbeyondbradleyterry)|
|**2024-11-07**|**Few-Shot Task Learning through Inverse Generative Modeling**|Aviv Netanyahu et.al.|[2411.04987v1](http://arxiv.org/abs/2411.04987v1)|null|
|**2024-11-07**|**The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities**|Zhaofeng Wu et.al.|[2411.04986v1](http://arxiv.org/abs/2411.04986v1)|[link](https://github.com/ZhaofengWu/semantic-hub)|
|**2024-11-07**|**DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning**|Gaoyue Zhou et.al.|[2411.04983v1](http://arxiv.org/abs/2411.04983v1)|null|
|**2024-11-07**|**Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries**|Dylan Manuel et.al.|[2411.04981v1](http://arxiv.org/abs/2411.04981v1)|null|
|**2024-11-07**|**SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference**|Gabriele Oliaro et.al.|[2411.04975v1](http://arxiv.org/abs/2411.04975v1)|null|
|**2024-11-07**|**BitNet a4.8: 4-bit Activations for 1-bit LLMs**|Hongyu Wang et.al.|[2411.04965v1](http://arxiv.org/abs/2411.04965v1)|null|
|**2024-11-07**|**Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**|Yanjun Gao et.al.|[2411.04962v1](http://arxiv.org/abs/2411.04962v1)|null|
|**2024-11-07**|**Uncovering Hidden Subspaces in Video Diffusion Models Using Re-Identification**|Mischa Dombrowski et.al.|[2411.04956v1](http://arxiv.org/abs/2411.04956v1)|null|
|**2024-11-07**|**M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding**|Jaemin Cho et.al.|[2411.04952v1](http://arxiv.org/abs/2411.04952v1)|null|
|**2024-11-07**|**Estimating the Influence of Sequentially Correlated Literary Properties in Textual Classification: A Data-Centric Hypothesis-Testing Approach**|Gideon Yoffe et.al.|[2411.04950v1](http://arxiv.org/abs/2411.04950v1)|[link](https://github.com/YoffeG/Thematic-nonThematic_Hypothesis_Testing)|
|**2024-11-07**|**DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion**|Wenqiang Sun et.al.|[2411.04928v1](http://arxiv.org/abs/2411.04928v1)|null|
|**2024-11-07**|**StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration**|Panwen Hu et.al.|[2411.04925v1](http://arxiv.org/abs/2411.04925v1)|null|
|**2024-11-07**|**GPTKB: Building Very Large Knowledge Bases from Language Models**|Yujia Hu et.al.|[2411.04920v1](http://arxiv.org/abs/2411.04920v1)|null|
|**2024-11-07**|**Evaluating Robustness of Reinforcement Learning Algorithms for Autonomous Shipping**|Bavo Lesy et.al.|[2411.04915v1](http://arxiv.org/abs/2411.04915v1)|null|
|**2024-11-07**|**GASE: Generatively Augmented Sentence Encoding**|Manuel Frank et.al.|[2411.04914v1](http://arxiv.org/abs/2411.04914v1)|null|
|**2024-11-07**|**OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models**|Siming Huang et.al.|[2411.04905v1](http://arxiv.org/abs/2411.04905v1)|null|
|**2024-11-07**|**GUI Agents with Foundation Models: A Comprehensive Survey**|Shuai Wang et.al.|[2411.04890v1](http://arxiv.org/abs/2411.04890v1)|null|
|**2024-11-07**|**FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI**|Elliot Glazer et.al.|[2411.04872v1](http://arxiv.org/abs/2411.04872v1)|null|
|**2024-11-07**|**Think Smart, Act SMARL! Analyzing Probabilistic Logic Driven Safety in Multi-Agent Reinforcement Learning**|Satchit Chatterji et.al.|[2411.04867v1](http://arxiv.org/abs/2411.04867v1)|[link](https://github.com/satchitchatterji/shieldedmarlthesis)|
|**2024-11-07**|**ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset**|Olaf Wysocki et.al.|[2411.04865v1](http://arxiv.org/abs/2411.04865v1)|[link](https://github.com/oloocki/zaha)|
|**2024-11-07**|**Sentiment Analysis of Spanish Political Party Tweets Using Pre-trained Language Models**|Chuqiao Song et.al.|[2411.04862v1](http://arxiv.org/abs/2411.04862v1)|null|
|**2024-11-07**|**Prompt-Guided Internal States for Hallucination Detection of Large Language Models**|Fujie Zhang et.al.|[2411.04847v1](http://arxiv.org/abs/2411.04847v1)|[link](https://github.com/fujie-math/PRISM)|
|**2024-11-07**|**Machine learning and optimization-based approaches to duality in statistical physics**|Andrea E. V. Ferrari et.al.|[2411.04838v1](http://arxiv.org/abs/2411.04838v1)|null|
|**2024-11-07**|**VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and Benchmark Models**|Ming Cheng et.al.|[2411.04825v1](http://arxiv.org/abs/2411.04825v1)|null|
|**2024-11-07**|**When Does Classical Chinese Help? Quantifying Cross-Lingual Transfer in Hanja and Kanbun**|Seyoung Song et.al.|[2411.04822v1](http://arxiv.org/abs/2411.04822v1)|null|
|**2024-11-07**|**LuxBank: The First Universal Dependency Treebank for Luxembourgish**|Alistair Plum et.al.|[2411.04813v1](http://arxiv.org/abs/2411.04813v1)|null|
|**2024-11-07**|**Defending Deep Regression Models against Backdoor Attacks**|Lingyu Du et.al.|[2411.04811v1](http://arxiv.org/abs/2411.04811v1)|null|
|**2024-11-07**|**Kwai-STaR: Transform LLMs into State-Transition Reasoners**|Xingyu Lu et.al.|[2411.04799v1](http://arxiv.org/abs/2411.04799v1)|null|
|**2024-11-07**|**MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation**|Sayan Paul et.al.|[2411.04796v1](http://arxiv.org/abs/2411.04796v1)|null|
|**2024-11-07**|**AlignXIE: Improving Multilingual Information Extraction by Cross-Lingual Alignment**|Yuxin Zuo et.al.|[2411.04794v1](http://arxiv.org/abs/2411.04794v1)|null|
|**2024-11-07**|**Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research**|Xuewen Han et.al.|[2411.04788v1](http://arxiv.org/abs/2411.04788v1)|[link](https://github.com/ai4finance-foundation/finrobot)|
|**2024-11-07**|**A study of Vietnamese readability assessing through semantic and statistical features**|Hung Tuan Le et.al.|[2411.04756v1](http://arxiv.org/abs/2411.04756v1)|null|
|**2024-11-07**|**RetrieveGPT: Merging Prompts and Mathematical Models for Enhanced Code-Mixed Information Retrieval**|Aniket Deroy et.al.|[2411.04752v1](http://arxiv.org/abs/2411.04752v1)|null|
|**2024-11-07**|**Equivariant Graph Attention Networks with Structural Motifs for Predicting Cell Line-Specific Synergistic Drug Combinations**|Zachary Schwehr et.al.|[2411.04747v1](http://arxiv.org/abs/2411.04747v1)|[link](https://github.com/wetothemoon/egat_drugsynergy)|
|**2024-11-07**|**BhasaAnuvaad: A Speech Translation Dataset for 14 Indian Languages**|Sparsh Jain et.al.|[2411.04699v1](http://arxiv.org/abs/2411.04699v1)|null|
|**2024-11-07**|**The Multiple Dimensions of Spuriousness in Machine Learning**|Samuel J. Bell et.al.|[2411.04696v1](http://arxiv.org/abs/2411.04696v1)|null|
|**2024-11-07**|**Reciprocal Point Learning Network with Large Electromagnetic Kernel for SAR Open-Set Recognition**|Xiayang Xiao et.al.|[2411.04693v1](http://arxiv.org/abs/2411.04693v1)|null|
|**2024-11-07**|**Personalized Federated Learning for Cross-view Geo-localization**|Christos Anagnostopoulos et.al.|[2411.04692v1](http://arxiv.org/abs/2411.04692v1)|null|
|**2024-11-07**|**AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**|Tianyi Zhang et.al.|[2411.04691v1](http://arxiv.org/abs/2411.04691v1)|null|
|**2024-11-07**|**Solving Generalized Grouping Problems in Cellular Manufacturing Systems Using a Network Flow Model**|Md. Kutub Uddin et.al.|[2411.04685v1](http://arxiv.org/abs/2411.04685v1)|null|
|**2024-11-07**|**CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation**|Jie Liu et.al.|[2411.04679v1](http://arxiv.org/abs/2411.04679v1)|null|
|**2024-11-07**|**CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational Agents in XR**|Kadir Burak Buldu et.al.|[2411.04671v1](http://arxiv.org/abs/2411.04671v1)|null|
|**2024-11-07**|**EffiCANet: Efficient Time Series Forecasting with Convolutional Attention**|Xinxing Zhou et.al.|[2411.04669v1](http://arxiv.org/abs/2411.04669v1)|null|
|**2024-11-07**|**DISCO: DISCovering Overfittings as Causal Rules for Text Classification Models**|Zijian Zhang et.al.|[2411.04649v1](http://arxiv.org/abs/2411.04649v1)|null|
|**2024-11-07**|**wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification from Physiological Signals**|Jonathan F. Carter et.al.|[2411.04644v1](http://arxiv.org/abs/2411.04644v1)|[link](https://github.com/joncarter1/wav2sleep)|
|**2024-11-07**|**TAP-VL: Text Layout-Aware Pre-training for Enriched Vision-Language Models**|Jonathan Fhima et.al.|[2411.04642v1](http://arxiv.org/abs/2411.04642v1)|null|
|**2024-11-07**|**Hands-On Tutorial: Labeling with LLM and Human-in-the-Loop**|Ekaterina Artemova et.al.|[2411.04637v1](http://arxiv.org/abs/2411.04637v1)|null|
|**2024-11-07**|**FASSILA: A Corpus for Algerian Dialect Fake News Detection and Sentiment Analysis**|Amin Abdedaiem et.al.|[2411.04604v1](http://arxiv.org/abs/2411.04604v1)|[link](https://github.com/amincoding/fassila)|
|**2024-11-07**|**Self-Calibrated Listwise Reranking with Large Language Models**|Ruiyang Ren et.al.|[2411.04602v1](http://arxiv.org/abs/2411.04602v1)|null|
|**2024-11-07**|**Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction**|Ahlam Alrehili et.al.|[2411.04588v1](http://arxiv.org/abs/2411.04588v1)|null|
|**2024-11-07**|**On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data**|Aitor Martinez-Seras et.al.|[2411.04586v1](http://arxiv.org/abs/2411.04586v1)|null|
|**2024-11-07**|**The State and Fate of Summarization Datasets**|Noam Dahan et.al.|[2411.04585v1](http://arxiv.org/abs/2411.04585v1)|null|
|**2024-11-07**|**Interpreting the Learned Model in MuZero Planning**|Hung Guei et.al.|[2411.04580v1](http://arxiv.org/abs/2411.04580v1)|null|
|**2024-11-07**|**Multistage Fine-tuning Strategies for Automatic Speech Recognition in Low-resource Languages**|Leena G Pillai et.al.|[2411.04573v1](http://arxiv.org/abs/2411.04573v1)|null|
|**2024-11-07**|**Impact of Label Noise on Learning Complex Features**|Rahul Vashisht et.al.|[2411.04569v1](http://arxiv.org/abs/2411.04569v1)|null|
|**2024-11-07**|**A Generalisation of Voter Model: Influential Nodes and Convergence Properties**|Abhiram Manohara et.al.|[2411.04564v1](http://arxiv.org/abs/2411.04564v1)|null|
|**2024-11-07**|**Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning**|Marvin Alles et.al.|[2411.04562v1](http://arxiv.org/abs/2411.04562v1)|null|
|**2024-11-07**|**Pruning Literals for Highly Efficient Explainability at Word Level**|Rohan Kumar Yadav et.al.|[2411.04557v1](http://arxiv.org/abs/2411.04557v1)|null|
|**2024-11-07**|**Vision Language Models are In-Context Value Learners**|Yecheng Jason Ma et.al.|[2411.04549v1](http://arxiv.org/abs/2411.04549v1)|null|
|**2024-11-07**|**Best Practices for Distilling Large Language Models into BERT for Web Search Ranking**|Dezhi Ye et.al.|[2411.04539v1](http://arxiv.org/abs/2411.04539v1)|null|
|**2024-11-07**|**Meta-Reasoning Improves Tool Use in Large Language Models**|Lisa Alazraki et.al.|[2411.04535v1](http://arxiv.org/abs/2411.04535v1)|[link](https://github.com/lisaalaz/tecton)|
|**2024-11-07**|**Tomato, Tomahto, Tomate: Measuring the Role of Shared Semantics among Subwords in Multilingual Language Models**|Xinyu Zhang et.al.|[2411.04530v1](http://arxiv.org/abs/2411.04530v1)|null|
|**2024-11-07**|**GenJoin: Conditional Generative Plan-to-Plan Query Optimizer that Learns from Subplan Hints**|Pavel Sulimov et.al.|[2411.04525v1](http://arxiv.org/abs/2411.04525v1)|null|
|**2024-11-07**|**Continuous Sign Language Recognition System using Deep Learning with MediaPipe Holistic**|Sharvani Srivastava et.al.|[2411.04517v1](http://arxiv.org/abs/2411.04517v1)|null|
|**2024-11-07**|**FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**|Liangrui Pan et.al.|[2411.04509v1](http://arxiv.org/abs/2411.04509v1)|null|
|**2024-11-07**|**Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model**|Young-Jun Lee et.al.|[2411.04496v1](http://arxiv.org/abs/2411.04496v1)|[link](https://github.com/passing2961/thanos)|
|**2024-11-07**|**Series-to-Series Diffusion Bridge Model**|Hao Yang et.al.|[2411.04491v1](http://arxiv.org/abs/2411.04491v1)|null|
|**2024-11-07**|**ML-Promise: A Multilingual Dataset for Corporate Promise Verification**|Yohei Seki et.al.|[2411.04473v1](http://arxiv.org/abs/2411.04473v1)|null|
|**2024-11-07**|**Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks**|Adam Fourney et.al.|[2411.04468v1](http://arxiv.org/abs/2411.04468v1)|null|
|**2024-11-07**|**Can CDT rationalise the ex ante optimal policy via modified anthropics?**|Emery Cooper et.al.|[2411.04462v1](http://arxiv.org/abs/2411.04462v1)|null|
|**2024-11-07**|**Gradient Localization Improves Lifelong Pretraining of Language Models**|Jared Fernandez et.al.|[2411.04448v1](http://arxiv.org/abs/2411.04448v1)|null|
|**2024-11-07**|**ACCIO: Table Understanding Enhanced via Contrastive Learning with Aggregations**|Whanhee Cho et.al.|[2411.04443v1](http://arxiv.org/abs/2411.04443v1)|[link](https://github.com/whnhch/accio)|
|**2024-11-07**|**Scaling Laws for Pre-training Agents and World Models**|Tim Pearce et.al.|[2411.04434v1](http://arxiv.org/abs/2411.04434v1)|null|
|**2024-11-07**|**One fish, two fish, but not the whole sea: Alignment reduces language models' conceptual diversity**|Sonia K. Murthy et.al.|[2411.04427v1](http://arxiv.org/abs/2411.04427v1)|[link](https://github.com/skmur/onefish-twofish)|
|**2024-11-07**|**DELIFT: Data Efficient Language model Instruction Fine Tuning**|Ishika Agarwal et.al.|[2411.04425v1](http://arxiv.org/abs/2411.04425v1)|[link](https://github.com/agarwalishika/delift)|
|**2024-11-07**|**Bayesian Calibration of Win Rate Estimation with LLM Evaluators**|Yicheng Gao et.al.|[2411.04424v1](http://arxiv.org/abs/2411.04424v1)|[link](https://github.com/yale-nlp/bay-calibration-llm-evaluators)|
|**2024-11-07**|**Variational Low-Rank Adaptation Using IVON**|Bai Cong et.al.|[2411.04421v1](http://arxiv.org/abs/2411.04421v1)|[link](https://github.com/team-approx-bayes/ivon-lora)|
|**2024-11-07**|**Towards Competitive Search Relevance For Inference-Free Learned Sparse Retrievers**|Zhichao Geng et.al.|[2411.04403v1](http://arxiv.org/abs/2411.04403v1)|null|
|**2024-11-07**|**A Bayesian Mixture Model of Temporal Point Processes with Determinantal Point Process Prior**|Yiwei Dong et.al.|[2411.04397v1](http://arxiv.org/abs/2411.04397v1)|null|
|**2024-11-07**|**Bridging the Gap: Representation Spaces in Neuro-Symbolic AI**|Xin Zhang et.al.|[2411.04393v1](http://arxiv.org/abs/2411.04393v1)|null|
|**2024-11-07**|**Neuro-Symbolic AI: Explainability, Challenges, and Future Trends**|Xin Zhang et.al.|[2411.04383v1](http://arxiv.org/abs/2411.04383v1)|null|
|**2024-11-07**|**Benchmarking Large Language Models with Integer Sequence Generation Tasks**|Daniel O'Malley et.al.|[2411.04372v1](http://arxiv.org/abs/2411.04372v1)|null|
|**2024-11-07**|**ComFairGNN: Community Fair Graph Neural Network**|Yonas Sium et.al.|[2411.04371v1](http://arxiv.org/abs/2411.04371v1)|null|
|**2024-11-07**|**Measuring short-form factuality in large language models**|Jason Wei et.al.|[2411.04368v1](http://arxiv.org/abs/2411.04368v1)|[link](https://github.com/openai/simple-evals)|
|**2024-11-07**|**Robust and Efficient Fine-tuning of LLMs with Bayesian Reparameterization of Low-Rank Adaptation**|Vaibhav Seth et.al.|[2411.04358v1](http://arxiv.org/abs/2411.04358v1)|[link](https://github.com/lcs2-iiitd/monteclora)|
|**2024-11-07**|**Model and Deep learning based Dynamic Range Compression Inversion**|Haoran Sun et.al.|[2411.04337v1](http://arxiv.org/abs/2411.04337v1)|null|
|**2024-11-07**|**Scaling Laws for Precision**|Tanishq Kumar et.al.|[2411.04330v1](http://arxiv.org/abs/2411.04330v1)|null|
|**2024-11-07**|**CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models**|Jierui Li et.al.|[2411.04329v1](http://arxiv.org/abs/2411.04329v1)|null|
|**2024-11-07**|**Balancing Transparency and Accuracy: A Comparative Analysis of Rule-Based and Deep Learning Models in Political Bias Classification**|Manuel Nunez Martinez et.al.|[2411.04328v1](http://arxiv.org/abs/2411.04328v1)|null|
|**2024-11-06**|**Gradient Boosting Trees and Large Language Models for Tabular Data Few-Shot Learning**|Carlos Huertas et.al.|[2411.04324v1](http://arxiv.org/abs/2411.04324v1)|null|
|**2024-11-06**|**A Multilingual Sentiment Lexicon for Low-Resource Language Translation using Large Languages Models and Explainable AI**|Melusi Malinga et.al.|[2411.04316v1](http://arxiv.org/abs/2411.04316v1)|null|
|**2024-11-06**|**Improving Bilingual Capabilities of Language Models to Support Diverse Linguistic Practices in Education**|Anand Syamkumar et.al.|[2411.04308v1](http://arxiv.org/abs/2411.04308v1)|null|
|**2024-11-06**|**A Capabilities Approach to Studying Bias and Harm in Language Technologies**|Hellina Hailu Nigatu et.al.|[2411.04298v1](http://arxiv.org/abs/2411.04298v1)|null|

#### Abstracts
##### **ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning**
2411.05003v1 by David Junhao Zhang, Roni Paiss, Shiran Zada, Nikhil Karnad, David E. Jacobs, Yael Pritch, Inbar Mosseri, Mike Zheng Shou, Neal Wadhwa, Nataniel Ruiz

Recently, breakthroughs in video modeling have allowed for controllable
camera trajectories in generated videos. However, these methods cannot be
directly applied to user-provided videos that are not generated by a video
model. In this paper, we present ReCapture, a method for generating new videos
with novel camera trajectories from a single user-provided video. Our method
allows us to re-generate the reference video, with all its existing scene
motion, from vastly different angles and with cinematic camera motion. Notably,
using our method we can also plausibly hallucinate parts of the scene that were
not observable in the reference video. Our method works by (1) generating a
noisy anchor video with a new camera trajectory using multiview diffusion
models or depth-based point cloud rendering and then (2) regenerating the
anchor video into a clean and temporally consistent reangled video using our
proposed masked video fine-tuning technique.

æè¦ï¼æè¿ï¼å½±çå»ºæ¨¡ççªç ´æ§é²å±è®çæå½±çä¸­çç¸æ©è»è·¡å¯æ§ãç¶èï¼éäºæ¹æ³ç¡æ³ç´æ¥æç¨æ¼éå½±çæ¨¡åçæçä½¿ç¨èæä¾å½±çãå¨æ¬æä¸­ï¼æåæåº ReCaptureï¼éæ¯ä¸ç¨®æ¹æ³ï¼å¯å¾å®ä¸ä½¿ç¨èæä¾çå½±çä¸­çæå·ææ°ç©ç¸æ©è»è·¡çæ°å½±çãæåçéç¨®æ¹æ³è®æåè½å¤ å¾æªç¶ä¸åçè§åº¦åé»å½±ç¸æ©éåä¸­éæ°çæåèå½±çï¼ä¸¦åå«å¶ææç¾æçå ´æ¯åä½ãå¼å¾æ³¨æçæ¯ï¼ä½¿ç¨æåçæ¹æ³ï¼æåéå¯ä»¥åçå°å°åèå½±çä¸­ç¡æ³è§å¯å°çå ´æ¯é¨åé²è¡å¹»è¦ºãæåçéç¨®æ¹æ³éä½æ¹å¼çºï¼(1) ä½¿ç¨å¤è¦åæ´æ£æ¨¡åæåºæ¼æ·±åº¦é»é²æ¸²æä¾çæå·ææ°ç¸æ©è»è·¡çéè¨é¨å®å½±çï¼ç¶å¾ (2) ä½¿ç¨æåæåºçé®ç½©å½±çå¾®èª¿æè¡ï¼å°é¨å®å½±çéæ°çæçºä¹¾æ·¨ä¸æéä¸è´çéæ°èª¿æ´è§åº¦å½±çã

##### **Analyzing The Language of Visual Tokens**
2411.05001v1 by David M. Chan, Rodolfo Corona, Joonyong Park, Cheol Jun Cho, Yutong Bai, Trevor Darrell

With the introduction of transformer-based models for vision and language
tasks, such as LLaVA and Chameleon, there has been renewed interest in the
discrete tokenized representation of images. These models often treat image
patches as discrete tokens, analogous to words in natural language, learning
joint alignments between visual and human languages. However, little is known
about the statistical behavior of these visual languages - whether they follow
similar frequency distributions, grammatical structures, or topologies as
natural languages. In this paper, we take a natural-language-centric approach
to analyzing discrete visual languages and uncover striking similarities and
fundamental differences. We demonstrate that, although visual languages adhere
to Zipfian distributions, higher token innovation drives greater entropy and
lower compression, with tokens predominantly representing object parts,
indicating intermediate granularity. We also show that visual languages lack
cohesive grammatical structures, leading to higher perplexity and weaker
hierarchical organization compared to natural languages. Finally, we
demonstrate that, while vision models align more closely with natural languages
than other models, this alignment remains significantly weaker than the
cohesion found within natural languages. Through these experiments, we
demonstrate how understanding the statistical properties of discrete visual
languages can inform the design of more effective computer vision models.

æè¦ï¼é¨èåºæ¼Transformerçè¦è¦ºåèªè¨ä»»åæ¨¡åï¼ä¾å¦ LLaVA å Chameleonï¼çå¼å¥ï¼äººåå°å½±åçé¢æ£æ¨è¨åè¡¨ç¤ºæ³éæ°ç¢çèè¶£ãéäºæ¨¡åéå¸¸å°å½±ååå¡è¦çºé¢æ£æ¨è¨ï¼é¡ä¼¼æ¼èªç¶èªè¨ä¸­çå®å­ï¼ä¸¦å­¸ç¿è¦è¦ºèªè¨åäººé¡èªè¨ä¹éçè¯åå°é½ãç¶èï¼å°æ¼éäºè¦è¦ºèªè¨ççµ±è¨è¡çºæç¥çå°ï¼ä¾å¦å®åæ¯å¦éµå¾ªèèªç¶èªè¨é¡ä¼¼çé »çåä½ãèªæ³çµæ§æææ²çµæ§ãå¨æ¬æä¸­ï¼æåæ¡ç¨ä»¥èªç¶èªè¨çºä¸­å¿çéå¾ä¾åæé¢æ£è¦è¦ºèªè¨ï¼ä¸¦æ­ç¤ºé©äººçç¸ä¼¼æ§åæ ¹æ¬å·®ç°ãæåè­æï¼åç®¡è¦è¦ºèªè¨éµå¾ªé½å¤«åå¸ï¼ä½è¼é«çæ¨è¨åµæ°æå°è´æ´å¤§ççµåæ´ä½çå£ç¸®ï¼èæ¨è¨ä¸»è¦ä»£è¡¨ç©ä»¶é¨åï¼è¡¨ç¤ºä¸­éç²åº¦ãæåéè¡¨æï¼è¦è¦ºèªè¨ç¼ºä¹é£è²«çèªæ³çµæ§ï¼å°è´èèªç¶èªè¨ç¸æ¯ï¼å°æåº¦è¼é«ä¸å±¤ç´çµç¹è¼å¼±ãæå¾ï¼æåè­æï¼åç®¡è¦è¦ºæ¨¡åèèªç¶èªè¨çå°é½æ¯å¶ä»æ¨¡åæ´ç·å¯ï¼ä½éç¨®å°é½ä»ç¶é¡¯èå¼±æ¼èªç¶èªè¨ä¸­ç¼ç¾çå§èæ§ãéééäºå¯¦é©ï¼æåå±ç¤ºäºçè§£é¢æ£è¦è¦ºèªè¨ççµ±è¨å±¬æ§å¦ä½çºæ´ææçé»è¦è¦è¦ºæ¨¡åçè¨­è¨æä¾è³è¨ã

##### **Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?**
2411.05000v1 by Jonathan Roberts, Kai Han, Samuel Albanie

As the context limits of Large Language Models (LLMs) increase, the range of
possible applications and downstream functions broadens. In many real-world
tasks, decisions depend on details scattered across collections of often
disparate documents containing mostly irrelevant information. Long-context LLMs
appear well-suited to this form of complex information retrieval and reasoning,
which has traditionally proven costly and time-consuming. However, although the
development of longer context models has seen rapid gains in recent years, our
understanding of how effectively LLMs use their context has not kept pace. To
address this, we conduct a set of retrieval experiments designed to evaluate
the capabilities of 17 leading LLMs, such as their ability to follow threads of
information through the context window. Strikingly, we find that many models
are remarkably threadsafe: capable of simultaneously following multiple threads
without significant loss in performance. Still, for many models, we find the
effective context limit is significantly shorter than the supported context
length, with accuracy decreasing as the context window grows. Our study also
highlights the important point that token counts from different tokenizers
should not be directly compared -- they often correspond to substantially
different numbers of written characters. We release our code and long-context
experimental data.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çå§å®¹éå¶å¢å ï¼å¯è½çæç¨ç¯ååä¸æ¸¸åè½ä¹é¨ä¹æ´å±ãå¨è¨±å¤çå¯¦ä¸ççä»»åä¸­ï¼æ±ºç­åæ±ºæ¼åæ£å¨éå¸¸åå«å¤§éç¡éè¨æ¯çæä»¶éåä¸­çç´°ç¯ãé·å§å®¹éå¶ç LLM ä¼¼ä¹å¾é©åéç¨®è¤éçè³è¨æª¢ç´¢åæ¨çå½¢å¼ï¼èéç¨®å½¢å¼å³çµ±ä¸è¢«è­ææ¢æè²´åèæãç¶èï¼åç®¡è¼é·å§å®¹éå¶æ¨¡åçéç¼å¨è¿å¹´ä¾å·²å¿«éé²æ­¥ï¼ä½æåå°æ¼ LLM å¦ä½ææä½¿ç¨å¶å§å®¹éå¶ççè§£ä¸¦æªè·ä¸è³æ­¥ãçºäºè§£æ±ºéååé¡ï¼æåé²è¡äºä¸çµæª¢ç´¢å¯¦é©ï¼æ¨å¨è©ä¼° 17 åé å LLM çåè½ï¼ä¾å¦å®åééå§å®¹éå¶è¦çªè¿½è¹¤è³è¨ä¸²çè½åãä»¤äººé©è¨çæ¯ï¼æåç¼ç¾è¨±å¤æ¨¡åå·æé¡¯èçå·è¡ç·å®å¨æ§ï¼è½å¤ åæè¿½è¹¤å¤åå·è¡ç·ï¼èä¸æé¡¯èæå¤±æè½ãåç®¡å¦æ­¤ï¼å°æ¼è¨±å¤æ¨¡åï¼æåç¼ç¾ææçå§å®¹éå¶é¡¯èç­æ¼åæ¯æ´çå§å®¹éå¶é·åº¦ï¼èä¸é¨èå§å®¹éå¶è¦çªçå¢å ï¼æºç¢ºåº¦ä¹æä¸éãæåçç ç©¶ä¹å¼·èª¿äºä¸åéè¦è§é»ï¼å³ä¾èªä¸ååè©å¨çä»£ç¢¼è¨æ¸ä¸æç´æ¥æ¯è¼ââå®åéå¸¸å°ææ¼å¤§éä¸åçæ¸é¢å­åãæåç¼å¸æåçç¨å¼ç¢¼åé·å§å®¹éå¶çå¯¦é©è³æã

##### **LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation**
2411.04997v1 by Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, Lili Qiu

CLIP is one of the most important multimodal foundational models today. What
powers CLIP's capabilities? The rich supervision signals provided by natural
language, the carrier of human knowledge, shape a powerful cross-modal
representation space. However, with the rapid advancements in large language
models LLMs like GPT-4 and LLaMA, the boundaries of language comprehension and
generation are continually being pushed. This raises an intriguing question:
can the capabilities of LLMs be harnessed to further improve multimodal
representation learning? The potential benefits of incorporating LLMs into CLIP
are clear. LLMs' strong textual understanding can fundamentally improve CLIP's
ability to handle image captions, drastically enhancing its ability to process
long and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMs
are trained on a vast corpus of text, possessing open-world knowledge. This
allows them to expand on caption information during training, increasing the
efficiency of the learning process. In this paper, we propose LLM2CLIP, a novel
approach that embraces the power of LLMs to unlock CLIP's potential. By
fine-tuning the LLM in the caption space with contrastive learning, we extract
its textual capabilities into the output embeddings, significantly improving
the output layer's textual discriminability. We then design an efficient
training process where the fine-tuned LLM acts as a powerful teacher for CLIP's
visual encoder. Thanks to the LLM's presence, we can now incorporate longer and
more complex captions without being restricted by vanilla CLIP's text encoder's
context window and ability limitations. Our experiments demonstrate that this
approach brings substantial improvements in cross-modal tasks.

æè¦ï¼CLIP æ¯ç¶ä»æéè¦çå¤æ¨¡æåºç¤æ¨¡åä¹ä¸ãæ¯ä»éº¼è³¦äºäº CLIP çè½åï¼èªç¶èªè¨æä¾çè±å¯ç£ç£è¨èï¼äººé¡ç¥è­çè¼é«ï¼å¡é äºä¸åå¼·å¤§çè·¨æ¨¡æè¡¨ç¤ºç©ºéãç¶èï¼é¨è GPT-4 å LLaMA ç­å¤§åèªè¨æ¨¡å LLM çå¿«éé²å±ï¼èªè¨çè§£åçæççéä¸æ·è¢«æ¨åãéå¼ç¼äºä¸åæè¶£çåé¡ï¼LLM çè½åæ¯å¦å¯ä»¥è¢«å©ç¨ä¾é²ä¸æ­¥æ¹é²å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ï¼å° LLM ç´å¥ CLIP çæ½å¨å¥½èå¾æé¡¯ãLLM å¼·å¤§çææ¬çè§£åå¯ä»¥å¾æ ¹æ¬ä¸æé« CLIP èçååæ¨é¡çè½åï¼å¤§å¹å¢å¼·å¶èçé·èè¤éææ¬çè½åï¼éæ¯é¦è CLIP çä¸åç¾æå¨ç¥éå¶ãæ­¤å¤ï¼LLM æ¯å¨å¤§éçææ¬èªæåº«ä¸è¨ç·´çï¼ææéæ¾ä¸ççç¥è­ãéä½¿ä»åè½å¤ å¨è¨ç·´æéæ´å±æ¨é¡ä¿¡æ¯ï¼å¾èæé«å­¸ç¿éç¨çæçãå¨æ¬æä¸­ï¼æåæåºäº LLM2CLIPï¼ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å©ç¨ LLM çåéä¾éæ¾ CLIP çæ½åãééå¨å°æ¯å­¸ç¿çæ¨é¡ç©ºéä¸­å¾®èª¿ LLMï¼æåå°å¶ææ¬è½åæåå°è¼¸åºåµå¥ä¸­ï¼é¡¯èæé«äºè¼¸åºå±¤çææ¬å¯ååæ§ãç¶å¾ï¼æåè¨­è¨äºä¸åé«æçè¨ç·´éç¨ï¼å¶ä¸­å¾®èª¿å¾ç LLM åç¶ CLIP è¦è¦ºç·¨ç¢¼å¨çå¼·å¤§æå¸«ãç±æ¼ LLM çå­å¨ï¼æåç¾å¨å¯ä»¥ç´å¥æ´é·ãæ´è¤éçæ¨é¡ï¼èä¸æåå°é¦è CLIP çææ¬ç·¨ç¢¼å¨çä¸ä¸æçªå£åè½åéå¶ãæåçå¯¦é©è¡¨æï¼éç¨®æ¹æ³å¨è·¨æ¨¡æä»»åä¸­å¸¶ä¾äºé¡¯èçæ¹é²ã

##### **HourVideo: 1-Hour Video-Language Understanding**
2411.04998v1 by Keshigeyan Chandrasegaran, Agrim Gupta, Lea M. Hadzic, Taran Kota, Jimming He, CristÃ³bal Eyzaguirre, Zane Durante, Manling Li, Jiajun Wu, Li Fei-Fei

We present HourVideo, a benchmark dataset for hour-long video-language
understanding. Our dataset consists of a novel task suite comprising
summarization, perception (recall, tracking), visual reasoning (spatial,
temporal, predictive, causal, counterfactual), and navigation (room-to-room,
object retrieval) tasks. HourVideo includes 500 manually curated egocentric
videos from the Ego4D dataset, spanning durations of 20 to 120 minutes, and
features 12,976 high-quality, five-way multiple-choice questions. Benchmarking
results reveal that multimodal models, including GPT-4 and LLaVA-NeXT, achieve
marginal improvements over random chance. In stark contrast, human experts
significantly outperform the state-of-the-art long-context multimodal model,
Gemini Pro 1.5 (85.0% vs. 37.3%), highlighting a substantial gap in multimodal
capabilities. Our benchmark, evaluation toolkit, prompts, and documentation are
available at https://hourvideo.stanford.edu

æè¦ï¼æåæåº HourVideoï¼éæ¯é·éä¸å°æçå½±çèªè¨çè§£åºæºè³æéãæåçè³æéåå«ä¸ç³»åæ°ç©çä»»åå¥ä»¶ï¼åå«æè¦ãæç¥ï¼åæ¶ãè¿½è¹¤ï¼ãè¦è¦ºæ¨çï¼ç©ºéãæéãé æ¸¬ãå æãåäºå¯¦ï¼åå°èªï¼æ¿éå°æ¿éãç©ä»¶æª¢ç´¢ï¼ä»»åãHourVideo åå«ä¾èª Ego4D è³æéç 500 åæåç­åçç¬¬ä¸äººç¨±è¦è§å½±çï¼è·¨è¶ 20 å° 120 åéçæé·ï¼ä¸¦æä¾ 12,976 åé«åè³ªãäºé¸ä¸çé¸æé¡ãåºæºæ¸¬è©¦çµæé¡¯ç¤ºï¼åæ¬ GPT-4 å LLaVA-NeXT å¨å§çå¤æ¨¡ææ¨¡åï¼æ¯é¨æ©æ©æç²å¾ééæ¹åãèä¹å½¢æé®®æå°æ¯çæ¯ï¼äººé¡å°å®¶é¡¯èåªæ¼æåé²çé·èçµ¡å¤æ¨¡ææ¨¡å Gemini Pro 1.5ï¼85.0% å°æ¯ 37.3%ï¼ï¼çªé¡¯åºå¤æ¨¡æè½åçå·¨å¤§å·®è·ãæåçåºæºãè©ä¼°å·¥å·åãæç¤ºåæä»¶å¯å¨ https://hourvideo.stanford.edu åå¾

##### **Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models**
2411.04996v1 by Weixin Liang, Lili Yu, Liang Luo, Srinivasan Iyer, Ning Dong, Chunting Zhou, Gargi Ghosh, Mike Lewis, Wen-tau Yih, Luke Zettlemoyer, Xi Victoria Lin

The development of large language models (LLMs) has expanded to multi-modal
systems capable of processing text, images, and speech within a unified
framework. Training these models demands significantly larger datasets and
computational resources compared to text-only LLMs. To address the scaling
challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal
transformer architecture that significantly reduces pretraining computational
costs. MoT decouples non-embedding parameters of the model by modality --
including feed-forward networks, attention matrices, and layer normalization --
enabling modality-specific processing with global self-attention over the full
input sequence. We evaluate MoT across multiple settings and model scales. In
the Chameleon 7B setting (autoregressive text-and-image generation), MoT
matches the dense baseline's performance using only 55.8\% of the FLOPs. When
extended to include speech, MoT reaches speech performance comparable to the
dense baseline with only 37.2\% of the FLOPs. In the Transfusion setting, where
text and image are trained with different objectives, a 7B MoT model matches
the image modality performance of the dense baseline with one third of the
FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image
generation metrics. System profiling further highlights MoT's practical
benefits, achieving dense baseline image quality in 47.2\% of the wall-clock
time and text quality in 75.6\% of the wall-clock time (measured on AWS
p4de.24xlarge instances with NVIDIA A100 GPUs).

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çç¼å±å·²æ´å±å°å¤æ¨¡æç³»çµ±ï¼è½å¤ å¨çµ±ä¸çæ¶æ§å§èçæå­ãå½±ååèªé³ãè¨ç·´éäºæ¨¡åéè¦æ¯åæå­ç LLM å¤§å¾å¤çè³æéåéç®è³æºãçºäºæå°æ´åææ°ï¼æåå¼é²æ··åTransformer (MoT)ï¼éæ¯ä¸ç¨®ç¨çå¤æ¨¡æTransformeræ¶æ§ï¼å¯å¤§å¹æ¸å°é è¨ç·´çéç®ææ¬ãMoT ééæ¨¡æè§£è¦æ¨¡åçéåµå¥åæ¸ï¼åæ¬åé¥ç¶²è·¯ãæ³¨æåç©é£åå±¤æ¬¡æ¨æºåï¼ä¸¦å¨å®æ´çè¼¸å¥åºåä¸åç¨å·åå¨å±èªææ³¨æåçæ¨¡æç¹å®èçãæåå¨å¤ç¨®è¨­å®åæ¨¡åè¦æ¨¡ä¸­è©ä¼° MoTãå¨è®è²é¾ 7B è¨­å®ï¼èªè¿´æ­¸æå­åå½±åç¢çï¼ä¸­ï¼MoT åä½¿ç¨ 55.8% çæµ®é»éç®æ¬¡æ¸ (FLOP) å°±éå°å¯éåºç·çæè½ãç¶æ´åå°åå«èªé³æï¼MoT éå°çèªé³æè½å¯èå¯éåºç·ç¸æ¯ï¼ä½åä½¿ç¨ 37.2% çæµ®é»éç®æ¬¡æ¸ãå¨è¼¸è¡è¨­å®ä¸­ï¼æå­åå½±åä½¿ç¨ä¸åçç®æ¨é²è¡è¨ç·´ï¼7B MoT æ¨¡åçå½±åæ¨¡ææè½èå¯éåºç·ç¸ç¶ï¼ä½æµ®é»éç®æ¬¡æ¸åªæä¸åä¹ä¸ï¼è 760M MoT æ¨¡ååå¨ééµå½±åç¢çææ¨ä¸åªæ¼ 1.4B å¯éåºç·ãç³»çµ±åæé²ä¸æ­¥çªé¡¯äº MoT çå¯¦éæçï¼å¨ 47.2% çå¯¦éæéå§éæå¯éåºç·å½±ååè³ªï¼å¨ 75.6% çå¯¦éæéå§éææå­åè³ªï¼å¨éå NVIDIA A100 GPU ç AWS p4de.24xlarge å¯¦ä¾ä¸æ¸¬éï¼ã

##### **Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives**
2411.04991v1 by Hao Sun, Yunyi Shen, Jean-Francois Ton

The Bradley-Terry (BT) model is a common and successful practice in reward
modeling for Large Language Model (LLM) alignment. However, it remains unclear
why this model -- originally developed for multi-player stochastic game
matching -- can be adopted to convert pairwise response comparisons to reward
values and make predictions. Especially given the fact that only a limited
number of prompt-response pairs are sparsely compared with others. In this
paper, we first revisit the foundations of using BT models in reward modeling,
and establish the convergence rate of BT reward models based on deep neural
networks using embeddings, providing a theoretical foundation for their use.
Despite theoretically sound, we argue that the BT model is not a necessary
choice from the perspective of downstream optimization. This is because a
reward model only needs to preserve the correct ranking predictions through a
monotonic transformation of the true reward. We highlight the critical concept
of order consistency in reward modeling and demonstrate that the BT model
possesses this property. Consequently, we propose a simple and straightforward
upper-bound algorithm, compatible with off-the-shelf binary classifiers, as an
alternative order-consistent reward modeling objective. To offer practical
insights, we empirically evaluate the performance of these different reward
modeling approaches across more than 12,000 experimental setups, using $6$ base
LLMs, $2$ datasets, and diverse annotation designs that vary in quantity,
quality, and pairing choices in preference annotations.

æè¦ï¼Bradley-Terry (BT) æ¨¡åæ¯å¤§åèªè¨æ¨¡å (LLM) å°é½ä¸­çåµå»ºæ¨¡çå¸¸è¦ä¸æåçå¯¦åãç¶èï¼éåæ¨¡åæåæ¯çºå¤ç©å®¶é¨æ©éæ²éå°èéç¼çï¼çºä»éº¼å®å¯ä»¥è¢«æ¡ç¨ä¾å°æå°çåææ¯è¼è½æçºçåµå¼ä¸¦ååºé æ¸¬ï¼éä»ç¶ä¸æ¸æ¥ãç¹å¥æ¯èæ®å°åªææéæ¸éçæç¤ºåæå°èå¶ä»å°ç¨çå°é²è¡æ¯è¼ãå¨æ¬æä¸­ï¼æåé¦åéæ°æ¢è¨å¨çåµå»ºæ¨¡ä¸­ä½¿ç¨ BT æ¨¡åçåºç¤ï¼ä¸¦ä½¿ç¨åµå¥å»ºç«åºæ¼æ·±åº¦ç¥ç¶ç¶²è·¯ç BT çåµæ¨¡åçæ¶æéåº¦ï¼çºå®åçä½¿ç¨æä¾çè«åºç¤ãåç®¡å¨çè«ä¸æ¯åççï¼æåèªçºå¾ä¸æ¸¸æä½³åçè§åº¦ä¾çï¼BT æ¨¡åä¸¦éå¿è¦çé¸æãéæ¯å çºçåµæ¨¡ååªéè¦ééçå¯¦çåµçå®èª¿è½æä¾ä¿çæ­£ç¢ºçæåé æ¸¬ãæåå¼·èª¿äºçåµå»ºæ¨¡ä¸­è¨å®ä¸è´æ§çééµæ¦å¿µï¼ä¸¦è­æäº BT æ¨¡åå·åæ­¤ç¹æ§ãå æ­¤ï¼æåæåºäºä¸åç°¡å®ä¸ç´æ¥çä¸çæ¼ç®æ³ï¼èç¾æçäºååé¡å¨ç¸å®¹ï¼ä½çºæ¿ä»£çè¨å®ä¸è´çåµå»ºæ¨¡ç®æ¨ãçºäºæä¾å¯¦ç¨çè¦è§£ï¼æåæ ¹æ 6 ååºç¤ LLMã2 åè³æéåå¨æ¸éãåè³ªååå¥½è¨»è§£ä¸­çéå°é¸æä¸ææä¸åçå¤æ¨£åè¨»è§£è¨­è¨ï¼å°éäºä¸åççåµå»ºæ¨¡æ¹æ³å¨è¶é 12,000 åå¯¦é©è¨­å®ä¸­çæè½é²è¡ç¶é©è©ä¼°ã

##### **Few-Shot Task Learning through Inverse Generative Modeling**
2411.04987v1 by Aviv Netanyahu, Yilun Du, Antonia Bronars, Jyothish Pari, Joshua Tenenbaum, Tianmin Shu, Pulkit Agrawal

Learning the intents of an agent, defined by its goals or motion style, is
often extremely challenging from just a few examples. We refer to this problem
as task concept learning and present our approach, Few-Shot Task Learning
through Inverse Generative Modeling (FTL-IGM), which learns new task concepts
by leveraging invertible neural generative models. The core idea is to pretrain
a generative model on a set of basic concepts and their demonstrations. Then,
given a few demonstrations of a new concept (such as a new goal or a new
action), our method learns the underlying concepts through backpropagation
without updating the model weights, thanks to the invertibility of the
generative model. We evaluate our method in five domains -- object
rearrangement, goal-oriented navigation, motion caption of human actions,
autonomous driving, and real-world table-top manipulation. Our experimental
results demonstrate that via the pretrained generative model, we successfully
learn novel concepts and generate agent plans or motion corresponding to these
concepts in (1) unseen environments and (2) in composition with training
concepts.

æè¦ï¼ééå¶ç®æ¨æåä½é¢¨æ ¼å®ç¾©çä»£çæåå­¸ç¿ï¼éå¸¸åå¾å¹¾åç¯ä¾ä¸­å­¸ç¿æ¥µå·ææ°æ§ãæåå°æ­¤åé¡ç¨±çºä»»åæ¦å¿µå­¸ç¿ï¼ä¸¦æåºæåçåæ³ï¼ééååçæå¼å»ºæ¨¡ï¼FTL-IGMï¼é²è¡å°éä»»åå­¸ç¿ï¼ééå©ç¨å¯éç¥ç¶çæå¼æ¨¡åä¾å­¸ç¿æ°çä»»åæ¦å¿µãæ ¸å¿æ¦å¿µæ¯å¨ä¸çµåºæ¬æ¦å¿µåå¶ç¤ºç¯ä¸é è¨ç·´çæå¼æ¨¡åãç¶å¾ï¼çµ¦å®æ°æ¦å¿µçå¹¾åç¤ºç¯ï¼ä¾å¦æ°ç®æ¨ææ°åä½ï¼ï¼æåçæ¨¡åééååå³æ­å­¸ç¿åºç¤æ¦å¿µï¼èç¡éæ´æ°æ¨¡åæ¬éï¼éè¦æ­¸åæ¼çæå¼æ¨¡åçå¯éæ§ãæåå¨äºåé åè©ä¼°æåçæ¨¡åââç©é«éæ°æåãç®æ¨å°åå°èªãäººé¡åä½çåä½æ¨é¡ãèªåé§é§åç¾å¯¦ä¸ççæ¡é¢æä½ãæåçå¯¦é©çµæè¡¨æï¼ééé è¨ç·´ççæå¼æ¨¡åï¼æåæåå­¸ç¿æ°æ¦å¿µä¸¦ç¢çèéäºæ¦å¿µç¸æçä»£çè¨ç«æåä½ï¼å¨ï¼1ï¼æªè¦éçç°å¢ä¸­ï¼ä»¥åï¼2ï¼èè¨ç·´æ¦å¿µççµåä¸­ã

##### **The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities**
2411.04986v1 by Zhaofeng Wu, Xinyan Velocity Yu, Dani Yogatama, Jiasen Lu, Yoon Kim

Modern language models can process inputs across diverse languages and
modalities. We hypothesize that models acquire this capability through learning
a shared representation space across heterogeneous data types (e.g., different
languages and modalities), which places semantically similar inputs near one
another, even if they are from different modalities/languages. We term this the
semantic hub hypothesis, following the hub-and-spoke model from neuroscience
(Patterson et al., 2007) which posits that semantic knowledge in the human
brain is organized through a transmodal semantic "hub" which integrates
information from various modality-specific "spokes" regions. We first show that
model representations for semantically equivalent inputs in different languages
are similar in the intermediate layers, and that this space can be interpreted
using the model's dominant pretraining language via the logit lens. This
tendency extends to other data types, including arithmetic expressions, code,
and visual/audio inputs. Interventions in the shared representation space in
one data type also predictably affect model outputs in other data types,
suggesting that this shared representations space is not simply a vestigial
byproduct of large-scale training on broad data, but something that is actively
utilized by the model during input processing.

æè¦ï¼ç¾ä»£èªè¨æ¨¡åå¯ä»¥èçè·¨è¶ä¸åèªè¨åæ¨¡å¼çè¼¸å¥ãæååè¨­æ¨¡åééå­¸ç¿è·¨è¶ç°è³ªè³æé¡åï¼ä¾å¦ï¼ä¸åçèªè¨åæ¨¡å¼ï¼çå±äº«è¡¨ç¤ºç©ºéä¾ç²å¾æ­¤è½åï¼éåç©ºéå°èªç¾©ä¸ç¸ä¼¼çè¼¸å¥æ¾ç½®å¨å½¼æ­¤éè¿ï¼å³ä½¿å®åä¾èªä¸åçæ¨¡å¼/èªè¨ãæåç¨±ä¹çºèªç¾©ä¸­å¿åè¨­ï¼éµå¾ªç¥ç¶ç§å­¸ä¸­çæ¨ç´è¼»å°æ¨¡åï¼Patterson ç­äººï¼2007 å¹´ï¼ï¼è©²æ¨¡ååè¨­äººé¡å¤§è¦ä¸­çèªç¾©ç¥è­æ¯ééè·¨æ¨¡å¼èªç¾©ãæ¨ç´ãçµç¹çï¼å®æ´åä¾èªåç¨®ç¹å®æ¨¡å¼ãè¼»æ¢ãååçè³è¨ãæåé¦åå±ç¤ºä¸åèªè¨ä¸­èªç¾©ç­æè¼¸å¥çæ¨¡åè¡¨ç¤ºå¨ä¸­éå±¤ä¸­æ¯ç¸ä¼¼çï¼ä¸¦ä¸éåç©ºéå¯ä»¥ä½¿ç¨æ¨¡åçä¸»å°é è¨ç·´èªè¨éé logit éé¡ä¾è©®éãéç¨®è¶¨å¢å»¶ä¼¸å°å¶ä»è³æé¡åï¼åæ¬ç®è¡è¡¨éå¼ãç¨å¼ç¢¼ä»¥åè¦è¦º/é³è¨è¼¸å¥ãå±äº«è¡¨ç¤ºç©ºéä¸­çä¸ç¨®è³æé¡åçä»å¥ä¹æå¯é æ¸¬å°å½±é¿å¶ä»è³æé¡åä¸­çæ¨¡åè¼¸åºï¼éè¡¨æéåå±äº«è¡¨ç¤ºç©ºéä¸ååæ¯å¤§è¦æ¨¡è¨ç·´å»£æ³è³æçæ®é¤å¯ç¢åï¼èä¸æ¯æ¨¡åå¨è¼¸å¥èçæéç©æ¥µå©ç¨çæ±è¥¿ã

##### **DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning**
2411.04983v1 by Gaoyue Zhou, Hengkai Pan, Yann LeCun, Lerrel Pinto

The ability to predict future outcomes given control actions is fundamental
for physical reasoning. However, such predictive models, often called world
models, have proven challenging to learn and are typically developed for
task-specific solutions with online policy learning. We argue that the true
potential of world models lies in their ability to reason and plan across
diverse problems using only passive data. Concretely, we require world models
to have the following three properties: 1) be trainable on offline,
pre-collected trajectories, 2) support test-time behavior optimization, and 3)
facilitate task-agnostic reasoning. To realize this, we present DINO World
Model (DINO-WM), a new method to model visual dynamics without reconstructing
the visual world. DINO-WM leverages spatial patch features pre-trained with
DINOv2, enabling it to learn from offline behavioral trajectories by predicting
future patch features. This design allows DINO-WM to achieve observational
goals through action sequence optimization, facilitating task-agnostic behavior
planning by treating desired goal patch features as prediction targets. We
evaluate DINO-WM across various domains, including maze navigation, tabletop
pushing, and particle manipulation. Our experiments demonstrate that DINO-WM
can generate zero-shot behavioral solutions at test time without relying on
expert demonstrations, reward modeling, or pre-learned inverse models. Notably,
DINO-WM exhibits strong generalization capabilities compared to prior
state-of-the-art work, adapting to diverse task families such as arbitrarily
configured mazes, push manipulation with varied object shapes, and
multi-particle scenarios.

æè¦ï¼é æ¸¬æªä¾çµæçè½åæ¯ç©çæ¨ççåºç¤ãç¶èï¼éç¨®é æ¸¬æ¨¡åï¼éå¸¸ç¨±çºä¸çæ¨¡åï¼å·²è¢«è­æé£ä»¥å­¸ç¿ï¼ä¸¦ä¸éå¸¸æ¯éå°å·æç·ä¸ç­ç¥å­¸ç¿çç¹å®ä»»åè§£æ±ºæ¹æ¡èéç¼çãæåèªçºï¼ä¸çæ¨¡åççæ­£æ½åå¨æ¼å®ååä½¿ç¨è¢«åæ¸æå°±è½æ¨çåè¦ååç¨®åé¡çè½åãå·é«ä¾èªªï¼æåè¦æ±ä¸çæ¨¡åå·åä»¥ä¸ä¸åç¹æ§ï¼1) å¯å¨é¢ç·ãé åæ¶éçè»è·¡ä¸é²è¡è¨ç·´ï¼2) æ¯æ´æ¸¬è©¦æéè¡çºæä½³åï¼ä»¥å 3) ä¿é²èä»»åç¡éçæ¨çãçºå¯¦ç¾æ­¤ç®æ¨ï¼æåæåºäº DINO ä¸çæ¨¡å (DINO-WM)ï¼éæ¯ä¸ç¨®å¨ä¸éå»ºè¦è¦ºä¸ççæ¢ä»¶ä¸å°è¦è¦ºåæé²è¡å»ºæ¨¡çæ°æ¹æ³ãDINO-WM å©ç¨é åä½¿ç¨ DINOv2 è¨ç·´çç©ºéåå¡ç¹å¾µï¼ä½¿å¶è½å¤ ééé æ¸¬æªä¾çåå¡ç¹å¾µï¼å¾é¢ç·è¡çºè»è·¡ä¸­å­¸ç¿ãæ­¤è¨­è¨åè¨± DINO-WM ééåä½åºåæä½³åä¾å¯¦ç¾è§å¯ç®æ¨ï¼ä¸¦å°æéçç®æ¨åå¡ç¹å¾µè¦çºé æ¸¬ç®æ¨ï¼å¾èä¿é²èä»»åç¡éçè¡çºè¦åãæåå¨åç¨®é åè©ä¼°äº DINO-WMï¼åæ¬è¿·å®®å°èªãæ¡é¢æ¨ååç²å­æä½ãæåçå¯¦é©è­æï¼DINO-WM è½å¤ å¨æ¸¬è©¦æç¢çé¶æ¬¡å­¸ç¿çè¡çºè§£æ±ºæ¹æ¡ï¼èç¡éä¾è³´å°å®¶ç¤ºç¯ãçåµå»ºæ¨¡æé åå­¸ç¿çéåæ¨¡åãå¼å¾æ³¨æçæ¯ï¼èååçæåé²å·¥ä½ç¸æ¯ï¼DINO-WM è¡¨ç¾åºå¼·å¤§çæ³åè½åï¼é©ç¨æ¼åç¨®ä»»åå®¶æï¼ä¾å¦ä»»æéç½®çè¿·å®®ãå·æä¸åç©é«å½¢ççæ¨åæä½åå¤ç²å­å ´æ¯ã

##### **Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries**
2411.04981v1 by Dylan Manuel, Nafis Tanveer Islam, Joseph Khoury, Ana Nunez, Elias Bou-Harb, Peyman Najafirad

Security experts reverse engineer (decompile) binary code to identify
critical security vulnerabilities. The limited access to source code in vital
systems - such as firmware, drivers, and proprietary software used in Critical
Infrastructures (CI) - makes this analysis even more crucial on the binary
level. Even with available source code, a semantic gap persists after
compilation between the source and the binary code executed by the processor.
This gap may hinder the detection of vulnerabilities in source code. That being
said, current research on Large Language Models (LLMs) overlooks the
significance of decompiled binaries in this area by focusing solely on source
code. In this work, we are the first to empirically uncover the substantial
semantic limitations of state-of-the-art LLMs when it comes to analyzing
vulnerabilities in decompiled binaries, largely due to the absence of relevant
datasets. To bridge the gap, we introduce DeBinVul, a novel decompiled binary
code vulnerability dataset. Our dataset is multi-architecture and
multi-optimization, focusing on C/C++ due to their wide usage in CI and
association with numerous vulnerabilities. Specifically, we curate 150,872
samples of vulnerable and non-vulnerable decompiled binary code for the task of
(i) identifying; (ii) classifying; (iii) describing vulnerabilities; and (iv)
recovering function names in the domain of decompiled binaries. Subsequently,
we fine-tune state-of-the-art LLMs using DeBinVul and report on a performance
increase of 19%, 24%, and 21% in the capabilities of CodeLlama, Llama3, and
CodeGen2 respectively, in detecting binary code vulnerabilities. Additionally,
using DeBinVul, we report a high performance of 80-90% on the vulnerability
classification task. Furthermore, we report improved performance in function
name recovery and vulnerability description tasks.

æè¦ï¼<paragraph>å®å¨å°å®¶éåå·¥ç¨ï¼åç·¨è­¯ï¼äºé²å¶ç¨å¼ç¢¼ï¼ä»¥æ¾åºééµçå®å¨æ¼æ´ãå¨éè¦ç³»çµ±ï¼ä¾å¦éé«ãé©åç¨å¼åééµåºç¤è¨­æ½ (CI) ä¸­ä½¿ç¨çå°æè»é«ï¼ä¸­ï¼å°åå§ç¢¼çå­åæéï¼éä½¿å¾å¨äºé²å¶å±¤ç´é²è¡æ­¤åæè®å¾æ´å éè¦ãå³ä½¿æåå§ç¢¼å¯ç¨ï¼å¨ç·¨è­¯å¾ï¼åå§ç¢¼åèçå¨å·è¡çäºé²å¶ç¨å¼ç¢¼ä¹éä»å­å¨èªæå·®è·ãæ­¤å·®è·å¯è½æé»ç¤å¨åå§ç¢¼ä¸­åµæ¸¬æ¼æ´ãè©±éå¦æ­¤ï¼ç®åå°å¤§åèªè¨æ¨¡å (LLM) çç ç©¶å¿½ç¥äºåç·¨è­¯äºé²å¶ç¨å¼ç¢¼å¨æ­¤é åçéè¦æ§ï¼å çºå®ååªå°æ³¨æ¼åå§ç¢¼ãå¨éé å·¥ä½ä¸­ï¼æåçåæç¶é©æ­é²æåé²ç LLM å¨åæåç·¨è­¯äºé²å¶ç¨å¼ç¢¼ä¸­çæ¼æ´æå­å¨å¤§éçèªæéå¶ï¼éä¸»è¦æ¯å çºç¼ºä¹ç¸éçè³æéãçºäºå½è£éåå·®è·ï¼æåå¼å¥äº DeBinVulï¼éæ¯ä¸åæ°ç©çåç·¨è­¯äºé²å¶ç¨å¼ç¢¼æ¼æ´è³æéãæåçè³æéæ¯å¤æ¶æ§åå¤æä½³åçï¼ç±æ¼ C/C++ å¨ CI ä¸­å»£æ³ä½¿ç¨ä¸èè¨±å¤æ¼æ´ç¸éï¼å æ­¤æåå°æ³¨æ¼ C/C++ãå·é«ä¾èªªï¼æåç­åäº 150,872 åææ¼æ´åç¡æ¼æ´çåç·¨è­¯äºé²å¶ç¨å¼ç¢¼ç¯ä¾ï¼ç¨æ¼ (i) è­å¥ï¼(ii) åé¡ï¼(iii) æè¿°æ¼æ´ï¼ä»¥å (iv) å¨åç·¨è­¯äºé²å¶ç¨å¼ç¢¼çé åä¸­å¾©åå½å¼åç¨±ãé¨å¾ï¼æåä½¿ç¨ DeBinVul å¾®èª¿æåé²ç LLMï¼ä¸¦å ±å CodeLlamaãLlama3 å CodeGen2 å¨åµæ¸¬äºé²å¶ç¨å¼ç¢¼æ¼æ´æ¹é¢çè½ååå¥æåäº 19%ã24% å 21%ãæ­¤å¤ï¼ä½¿ç¨ DeBinVulï¼æåå ±åäºå¨æ¼æ´åé¡ä»»åä¸­ 80-90% çé«æ§è½ãæ­¤å¤ï¼æåå ±åäºå½å¼åç¨±å¾©ååæ¼æ´æè¿°ä»»åçæè½æåã</paragraph>

##### **SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference**
2411.04975v1 by Gabriele Oliaro, Zhihao Jia, Daniel Campos, Aurick Qiao

We present SuffixDecoding, a novel model-free approach to accelerating large
language model (LLM) inference through speculative decoding. Unlike existing
methods that rely on draft models or specialized decoding heads, SuffixDecoding
leverages suffix trees built from previously generated outputs to efficiently
predict candidate token sequences. Our approach enables flexible
tree-structured speculation without the overhead of maintaining and
orchestrating additional models. SuffixDecoding builds and dynamically updates
suffix trees to capture patterns in the generated text, using them to construct
speculation trees through a principled scoring mechanism based on empirical
token frequencies. SuffixDecoding requires only CPU memory which is plentiful
and underutilized on typical LLM serving nodes. We demonstrate that
SuffixDecoding achieves competitive speedups compared to model-based approaches
across diverse workloads including open-domain chat, code generation, and
text-to-SQL tasks. For open-ended chat and code generation tasks,
SuffixDecoding achieves up to $1.4\times$ higher output throughput than
SpecInfer and up to $1.1\times$ lower time-per-token (TPOT) latency. For a
proprietary multi-LLM text-to-SQL application, SuffixDecoding achieves up to
$2.9\times$ higher output throughput and $3\times$ lower latency than
speculative decoding. Our evaluation shows that SuffixDecoding maintains high
acceptance rates even with small reference corpora of 256 examples, while
continuing to improve performance as more historical outputs are incorporated.

æè¦ï¼<paragraph>æåæåº SuffixDecodingï¼ä¸ç¨®æ°ç©çç¡æ¨¡åæ¹æ³ï¼ééæ¨æ¸¬æ§è§£ç¢¼ä¾å éå¤§åèªè¨æ¨¡å (LLM) æ¨è«ãèä¾è³´èç¨¿æ¨¡åæç¹å®è§£ç¢¼é ­çç¾ææ¹æ³ä¸åï¼SuffixDecoding å©ç¨å¾ååçæçè¼¸åºæ§å»ºçå¾ç¶´æ¨¹ï¼ä»¥ææé æ¸¬åé¸è©å½åºåãæåçåæ³å¯¦ç¾äºéæ´»çæ¨¹ççµæ§æ¨æ¸¬ï¼èç¡éç¶­è­·ååèª¿é¡å¤æ¨¡åçéé·ãSuffixDecoding æ§å»ºä¸¦åææ´æ°å¾ç¶´æ¨¹ï¼ä»¥æ·åçæææ¬ä¸­çæ¨¡å¼ï¼ä¸¦ä½¿ç¨å®åééåºæ¼ç¶é©è©å½é »ççååæ§è©åæ©å¶æ§å»ºæ¨æ¸¬æ¨¹ãSuffixDecoding åªéè¦ CPU è¨æ¶é«ï¼éå¨å¸åç LLM æåç¯é»ä¸å¾è±å¯ä¸æªååå©ç¨ãæåè­æ SuffixDecoding èåºæ¼æ¨¡åçæ¹æ³ç¸æ¯ï¼å¨åæ¬éæ¾åèå¤©ãç¨å¼ç¢¼çæåæå­å° SQL ä»»åå¨å§çåç¨®å·¥ä½è² è¼ä¸­å¯¦ç¾äºå·æç«¶ç­åçå éãå°æ¼éæ¾å¼èå¤©åç¨å¼ç¢¼çæä»»åï¼SuffixDecoding çè¼¸åºååéæ¯ SpecInfer é«é 1.4 åï¼æ¯ä»¤çæé (TPOT) å»¶é²ä½é 1.1 åãå°æ¼å°æçä¸é«å¤ç¨ LLM æå­å° SQL æç¨ç¨å¼ï¼SuffixDecoding çè¼¸åºååéæ¯æ¨æ¸¬æ§è§£ç¢¼é«é 2.9 åï¼å»¶é²ä½ 3 åãæåçè©ä¼°è¡¨æï¼å³ä½¿åªæ 256 åç¯ä¾çå°ååèèªæåº«ï¼SuffixDecoding ä»è½ç¶­æå¾é«çæ¥åçï¼åæé¨èæ´å¤æ­·å²è¼¸åºçç´å¥ï¼æè½ææçºæåã</paragraph>

##### **BitNet a4.8: 4-bit Activations for 1-bit LLMs**
2411.04965v1 by Hongyu Wang, Shuming Ma, Furu Wei

Recent research on the 1-bit Large Language Models (LLMs), such as BitNet
b1.58, presents a promising direction for reducing the inference cost of LLMs
while maintaining their performance. In this work, we introduce BitNet a4.8,
enabling 4-bit activations for 1-bit LLMs. BitNet a4.8 employs a hybrid
quantization and sparsification strategy to mitigate the quantization errors
introduced by the outlier channels. Specifically, we utilize 4-bit activations
for inputs to the attention and feed-forward network layers, while sparsifying
intermediate states followed with 8-bit quantization. Extensive experiments
demonstrate that BitNet a4.8 achieves performance comparable to BitNet b1.58
with equivalent training costs, while being faster in inference with enabling
4-bit (INT4/FP4) kernels. Additionally, BitNet a4.8 activates only 55% of
parameters and supports 3-bit KV cache, further enhancing the efficiency of
large-scale LLM deployment and inference.

æè¦ï¼æè¿å° 1 ä½åå¤§åèªè¨æ¨¡å (LLM) çç ç©¶ï¼ä¾å¦ BitNet b1.58ï¼æåºäºå¨ç¶­æå¶æè½çåææ¸å° LLM æ¨è«ææ¬çæå¸æçæ¹åãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº BitNet a4.8ï¼çº 1 ä½å LLM åç¨ 4 ä½ååæ¿æ´»ãBitNet a4.8 æ¡ç¨æ··åéåèç¨çåç­ç¥ä¾æ¸è¼ç°å¸¸ééå¼å¥çéåèª¤å·®ãå·é«ä¾èªªï¼æåä½¿ç¨ 4 ä½ååæ¿æ´»ä½çºæ³¨æåååé¥ç¶²è·¯å±¤çè¼¸å¥ï¼åæç¨çåä¸­éçæä¸¦é²è¡ 8 ä½ååéåãå»£æ³çå¯¦é©è­æï¼BitNet a4.8 éå°è BitNet b1.58 ç¸ç¶çæè½ï¼ä¸è¨ç·´ææ¬ç¸ç¶ï¼åæå¨åç¨ 4 ä½åå (INT4/FP4) æ ¸å¿ææ¨è«éåº¦æ´å¿«ãæ­¤å¤ï¼BitNet a4.8 ååç¨ 55% çåæ¸ä¸¦æ¯æ´ 3 ä½åå KV å¿«åï¼é²ä¸æ­¥æåå¤§è¦æ¨¡ LLM é¨ç½²åæ¨è«çæçã

##### **Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**
2411.04962v1 by Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Guanhua Chen, Anoop Mayampurath, Matthew Churpek, Majid Afshar

Large language models (LLMs) are being explored for diagnostic decision
support, yet their ability to estimate pre-test probabilities, vital for
clinical decision-making, remains limited. This study evaluates two LLMs,
Mistral-7B and Llama3-70B, using structured electronic health record data on
three diagnosis tasks. We examined three current methods of extracting LLM
probability estimations and revealed their limitations. We aim to highlight the
need for improved techniques in LLM confidence estimation.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨è¢«æ¢ç´¢ç¨æ¼è¨ºæ·æ±ºç­æ¯æï¼ä½å®åä¼°è¨è¨åºæ±ºç­å¶å®ä¸­è³ééè¦çé æ¸¬è©¦æ¦ççè½åä»ç¶æéãæ¬ç ç©¶ä½¿ç¨ä¸åè¨ºæ·ä»»åççµæ§åé»å­å¥åº·è¨éæ¸æè©ä¼°äºå©å LLMï¼Mistral-7B å Llama3-70Bãæåæª¢æ¥äºæå LLM æ¦çä¼°è¨çä¸ç¨®ç¶åæ¹æ³ä¸¦æ­ç¤ºäºå®åçå±éæ§ãæåçç®æ¨æ¯å¼·èª¿æ¹é² LLM ç½®ä¿¡åº¦ä¼°è¨æè¡çå¿è¦æ§ã

##### **Uncovering Hidden Subspaces in Video Diffusion Models Using Re-Identification**
2411.04956v1 by Mischa Dombrowski, Hadrien Reynaud, Bernhard Kainz

Latent Video Diffusion Models can easily deceive casual observers and domain
experts alike thanks to the produced image quality and temporal consistency.
Beyond entertainment, this creates opportunities around safe data sharing of
fully synthetic datasets, which are crucial in healthcare, as well as other
domains relying on sensitive personal information. However, privacy concerns
with this approach have not fully been addressed yet, and models trained on
synthetic data for specific downstream tasks still perform worse than those
trained on real data. This discrepancy may be partly due to the sampling space
being a subspace of the training videos, effectively reducing the training data
size for downstream models. Additionally, the reduced temporal consistency when
generating long videos could be a contributing factor.
  In this paper, we first show that training privacy-preserving models in
latent space is computationally more efficient and generalize better.
Furthermore, to investigate downstream degradation factors, we propose to use a
re-identification model, previously employed as a privacy preservation filter.
We demonstrate that it is sufficient to train this model on the latent space of
the video generator. Subsequently, we use these models to evaluate the subspace
covered by synthetic video datasets and thus introduce a new way to measure the
faithfulness of generative machine learning models. We focus on a specific
application in healthcare echocardiography to illustrate the effectiveness of
our novel methods. Our findings indicate that only up to 30.8% of the training
videos are learned in latent video diffusion models, which could explain the
lack of performance when training downstream tasks on synthetic data.

æè¦ï¼æ½å¨å½±çæ´æ£æ¨¡åå¾çæ¼ç¢ççå½±ååè³ªåæéä¸è´æ§ï¼å¯ä»¥è¼ææ¬ºé¨é¨æè§å¯èåé åå°å®¶ãé¤äºå¨æ¨ä¹å¤ï¼éåµé äºå®å¨è³æåäº«çæ©æï¼åäº«å®å¨åæçè³æéï¼éå¨é«çä¿å¥ä»¥åå¶ä»ä¾è³´åäººææè³è¨çé åä¸­è³ééè¦ãç¶èï¼éç¨®æ¹æ³çé±ç§åé¡å°æªå®å¨è§£æ±ºï¼éå°ç¹å®ä¸æ¸¸ä»»åè¨ç·´çåæè³ææ¨¡åï¼å¶è¡¨ç¾ä»æ¯å¨çå¯¦è³æä¸è¨ç·´çæ¨¡åå·®ãéç¨®å·®ç°å¯è½é¨åæ¯å çºåæ¨£ç©ºéæ¯è¨ç·´å½±ççå­ç©ºéï¼æææ¸å°äºä¸æ¸¸æ¨¡åçè¨ç·´è³æå¤§å°ãæ­¤å¤ï¼å¨ç¢çé·å½±çææéä¸è´æ§éä½ï¼ä¹å¯è½æ¯ä¸åä¿æå ç´ ãå¨æ¬æä¸­ï¼æåé¦åè¡¨æå¨æ½å¨ç©ºéä¸­è¨ç·´é±ç§ä¿è­·æ¨¡åå¨è¨ç®ä¸æ´ææçï¼ä¸¦ä¸è½æ´å¥½å°æ¦åãæ­¤å¤ï¼çºäºèª¿æ¥ä¸æ¸¸éåçå ç´ ï¼æåå»ºè­°ä½¿ç¨éæ°è­å¥æ¨¡åï¼ååç¨ä½é±ç§ä¿è­·ç¯©é¸å¨ãæåè­æäºå¨å½±ççæå¨çæ½å¨ç©ºéä¸è¨ç·´æ­¤æ¨¡åå°±è¶³å¤ äºãé¨å¾ï¼æåä½¿ç¨éäºæ¨¡åä¾è©ä¼°åæå½±çè³æéæ¶µèçå­ç©ºéï¼å¾èå¼å¥ä¸ç¨®è¡¡éçæå¼æ©å¨å­¸ç¿æ¨¡åå¿ å¯¦åº¦çæ°æ¹æ³ãæåå°æ³¨æ¼é«çä¿å¥è¶é³æ³¢å¿ååä¸­çç¹å®æç¨ï¼ä»¥èªªææåæ°æ¹æ³çæææ§ãæåçç ç©¶çµæè¡¨æï¼æ½å¨å½±çæ´æ£æ¨¡ååå­¸ç¿äºé«é 30.8% çè¨ç·´å½±çï¼éå¯ä»¥è§£éå¨åæè³æä¸è¨ç·´ä¸æ¸¸ä»»åæç¼ºä¹æè½çåå ã

##### **M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding**
2411.04952v1 by Jaemin Cho, Debanjan Mahata, Ozan Irsoy, Yujie He, Mohit Bansal

Document visual question answering (DocVQA) pipelines that answer questions
from documents have broad applications. Existing methods focus on handling
single-page documents with multi-modal language models (MLMs), or rely on
text-based retrieval-augmented generation (RAG) that uses text extraction tools
such as optical character recognition (OCR). However, there are difficulties in
applying these methods in real-world scenarios: (a) questions often require
information across different pages or documents, where MLMs cannot handle many
long documents; (b) documents often have important information in visual
elements such as figures, but text extraction tools ignore them. We introduce
M3DocRAG, a novel multi-modal RAG framework that flexibly accommodates various
document contexts (closed-domain and open-domain), question hops (single-hop
and multi-hop), and evidence modalities (text, chart, figure, etc.). M3DocRAG
finds relevant documents and answers questions using a multi-modal retriever
and an MLM, so that it can efficiently handle single or many documents while
preserving visual information. Since previous DocVQA datasets ask questions in
the context of a specific document, we also present M3DocVQA, a new benchmark
for evaluating open-domain DocVQA over 3,000+ PDF documents with 40,000+ pages.
In three benchmarks (M3DocVQA/MMLongBench-Doc/MP-DocVQA), empirical results
show that M3DocRAG with ColPali and Qwen2-VL 7B achieves superior performance
than many strong baselines, including state-of-the-art performance in
MP-DocVQA. We provide comprehensive analyses of different indexing, MLMs, and
retrieval models. Lastly, we qualitatively show that M3DocRAG can successfully
handle various scenarios, such as when relevant information exists across
multiple pages and when answer evidence only exists in images.

æè¦ï¼æä»¶è§è§é®ç­ (DocVQA) ç®¡éå¯ä»¥åç­ææ¡£ä¸­çé®é¢ï¼å·æå¹¿æ³çåºç¨ãç°ææ¹æ³ä¸æ³¨äºä½¿ç¨å¤æ¨¡æè¯­è¨æ¨¡å (MLM) å¤çåé¡µææ¡£ï¼æä¾èµäºä½¿ç¨åå­¦å­ç¬¦è¯å« (OCR) ç­ææ¬æåå·¥å·çåºäºææ¬çæ£ç´¢å¢å¼ºçæ (RAG)ãç¶èï¼å¨å®éåºæ¯ä¸­åºç¨è¿äºæ¹æ³å­å¨å°é¾ï¼(a) é®é¢éå¸¸éè¦è·¨ä¸åé¡µé¢æææ¡£çä¿¡æ¯ï¼è MLM æ æ³å¤çè®¸å¤é¿ææ¡£ï¼(b) ææ¡£éå¸¸å¨è§è§åç´ ï¼å¦æ°å­ï¼ä¸­åå«éè¦ä¿¡æ¯ï¼ä½ææ¬æåå·¥å·ä¼å¿½ç¥å®ä»¬ãæä»¬å¼å¥äº M3DocRAGï¼è¿æ¯ä¸ç§æ°é¢çå¤æ¨¡æ RAG æ¡æ¶ï¼å¯ä»¥çµæ´»å°éåºåç§ææ¡£ä¸ä¸æï¼å°é­ååå¼æ¾åï¼ãé®é¢è·³è·ï¼åè·³åå¤è·³ï¼åè¯æ®æ¨¡å¼ï¼ææ¬ãå¾è¡¨ãæ°å­ç­ï¼ãM3DocRAG ä½¿ç¨å¤æ¨¡ææ£ç´¢å¨å MLM æ¥æ¥æ¾ç¸å³ææ¡£å¹¶åç­é®é¢ï¼ä»¥ä¾¿å¨ä¿çè§è§ä¿¡æ¯çåæ¶ææå°å¤çåä¸ªæå¤ä¸ªææ¡£ãç±äºä¹åç DocVQA æ°æ®éå¨ç¹å®ææ¡£çä¸ä¸æä¸­æé®ï¼å æ­¤æä»¬è¿æåºäº M3DocVQAï¼è¿æ¯ä¸ä¸ªæ°çåºåï¼ç¨äºè¯ä¼°è¶è¿ 3000 ä¸ª PDF ææ¡£ï¼è¶è¿ 40000 é¡µï¼çå¼æ¾å DocVQAãå¨ä¸ä¸ªåºåï¼M3DocVQA/MMLongBench-Doc/MP-DocVQAï¼ä¸­ï¼å®è¯ç»æè¡¨æï¼å¸¦æ ColPali å Qwen2-VL 7B ç M3DocRAG æ¯è®¸å¤å¼ºå¤§çåºçº¿è·å¾äºæ´å¥½çæ§è½ï¼åæ¬ MP-DocVQA ä¸­çææ°æ§è½ãæä»¬å¯¹ä¸åçç´¢å¼ãMLM åæ£ç´¢æ¨¡åè¿è¡äºå¨é¢åæãæåï¼æä»¬å®æ§å°è¡¨æ M3DocRAG å¯ä»¥æåå¤çåç§åºæ¯ï¼ä¾å¦ç¸å³ä¿¡æ¯å­å¨äºå¤ä¸ªé¡µé¢ä¸­ä»¥åç­æ¡è¯æ®ä»å­å¨äºå¾åä¸­çæåµã

##### **Estimating the Influence of Sequentially Correlated Literary Properties in Textual Classification: A Data-Centric Hypothesis-Testing Approach**
2411.04950v1 by Gideon Yoffe, Nachum Dershowitz, Ariel Vishne, Barak Sober

Stylometry aims to distinguish authors by analyzing literary traits assumed
to reflect semi-conscious choices distinct from elements like genre or theme.
However, these components often overlap, complicating text classification based
solely on feature distributions. While some literary properties, such as
thematic content, are likely to manifest as correlations between adjacent text
units, others, like authorial style, may be independent thereof. We introduce a
hypothesis-testing approach to evaluate the influence of sequentially
correlated literary properties on text classification, aiming to determine when
these correlations drive classification. Using a multivariate binary
distribution, our method models sequential correlations between text units as a
stochastic process, assessing the likelihood of clustering across varying
adjacency scales. This enables us to examine whether classification is
dominated by sequentially correlated properties or remains independent. In
experiments on a diverse English prose corpus, our analysis integrates
traditional and neural embeddings within supervised and unsupervised
frameworks. Results demonstrate that our approach effectively identifies when
textual classification is not primarily influenced by sequentially correlated
literary properties, particularly in cases where texts differ in authorial
style or genre rather than by a single author within a similar genre.

æè¦ï¼é¢¨æ ¼è¨éå­¸æ¨å¨ééåæåè¨­çåæ äºåæè­é¸æçæå­¸ç¹å¾µä¾ååä½èï¼éäºç¹å¾µä¸åæ¼é¡åæä¸»é¡ç­åç´ ãç¶èï¼éäºçµæé¨åéå¸¸æéçï¼éä½¿å¾ååºæ¼ç¹å¾µåä½çææ¬åé¡è®å¾è¤éãéç¶ä¸äºæå­¸å±¬æ§ï¼ä¾å¦ä¸»é¡å§å®¹ï¼å¯è½æè¡¨ç¾çºç¸é°ææ¬å®åä¹éçç¸éæ§ï¼ä½å¶ä»å±¬æ§ï¼ä¾å¦ä½èé¢¨æ ¼ï¼å¯è½èæ­¤ç¡éãæåå¼å¥äºä¸ååè¨­æª¢é©æ¹æ³ä¾è©ä¼°åºåç¸éæå­¸å±¬æ§å°ææ¬åé¡çå½±é¿ï¼æ¨å¨ç¢ºå®éäºç¸éæ§ä½æé©ååé¡ãä½¿ç¨å¤åäºååä½ï¼æåçæ¨¡åå°ææ¬å®åä¹éçåºåç¸éæ§å»ºæ¨¡çºä¸åé¨æ©éç¨ï¼è©ä¼°å¨ä¸åé°æ¥å°ºåº¦ä¸èé¡çå¯è½æ§ãéä½¿æåè½å¤ æª¢æ¥åé¡æ¯ç±åºåç¸éå±¬æ§ä¸»å°éæ¯ä¿æç¨ç«ãå¨å°å¤æ¨£åçè±èªæ£æèªæåº«é²è¡çå¯¦é©ä¸­ï¼æåçåæå°å³çµ±åµå¥åç¥ç¶åµå¥æ´åå°æç£ç£åç¡ç£ç£çæ¡æ¶ä¸­ãçµæè¡¨æï¼æåçæ¨¡åææå°è­å¥äºä½æææ¬åé¡ä¸ååºåç¸éæå­¸å±¬æ§çä¸»è¦å½±é¿ï¼ç¹å¥æ¯å¨ææ¬å¨ä½èé¢¨æ ¼æé¡åä¸ææä¸åçææ³ä¸ï¼èä¸æ¯å¨é¡ä¼¼é¡åä¸­çå®åä½èã

##### **DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion**
2411.04928v1 by Wenqiang Sun, Shuo Chen, Fangfu Liu, Zilong Chen, Yueqi Duan, Jun Zhang, Yikai Wang

In this paper, we introduce \textbf{DimensionX}, a framework designed to
generate photorealistic 3D and 4D scenes from just a single image with video
diffusion. Our approach begins with the insight that both the spatial structure
of a 3D scene and the temporal evolution of a 4D scene can be effectively
represented through sequences of video frames. While recent video diffusion
models have shown remarkable success in producing vivid visuals, they face
limitations in directly recovering 3D/4D scenes due to limited spatial and
temporal controllability during generation. To overcome this, we propose
ST-Director, which decouples spatial and temporal factors in video diffusion by
learning dimension-aware LoRAs from dimension-variant data. This controllable
video diffusion approach enables precise manipulation of spatial structure and
temporal dynamics, allowing us to reconstruct both 3D and 4D representations
from sequential frames with the combination of spatial and temporal dimensions.
Additionally, to bridge the gap between generated videos and real-world scenes,
we introduce a trajectory-aware mechanism for 3D generation and an
identity-preserving denoising strategy for 4D generation. Extensive experiments
on various real-world and synthetic datasets demonstrate that DimensionX
achieves superior results in controllable video generation, as well as in 3D
and 4D scene generation, compared with previous methods.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåä»ç´¹äº DimensionXï¼ä¸åæ¨å¨åä½¿ç¨å½±çæ´æ£å¾å®ä¸å½±åçæé¼çç 3D å 4D å ´æ¯çæ¶æ§ãæåçåæ³å§æ¼éæ¨£çè¦è§£ï¼3D å ´æ¯çç©ºéçµæ§å 4D å ´æ¯çæéæ¼è®é½å¯ä»¥ééå½±çç«é¢çåºåææå°åç¾ãéç¶æè¿çå½±çæ´æ£æ¨¡åå¨ç¢ççåè¦è¦ºæææ¹é¢å±ç¾äºé¡¯èçæåï¼ä½ç±æ¼çæéç¨ä¸­åéçç©ºéåæéå¯æ§æ§ï¼å®åå¨ç´æ¥éå 3D/4D å ´æ¯æ¹é¢é¢è¨éå¶ãçºäºåæéååé¡ï¼æåæåºäº ST-Directorï¼å®ééå¾ç¶­åº¦è®ç°è³æå­¸ç¿å·æç¶­åº¦æç¥è½åç LoRAï¼å°å½±çæ´æ£ä¸­çç©ºéåæéå ç´ è§£è¦ãéç¨®å¯æ§çå½±çæ´æ£æ¹æ³è½ç²¾ç¢ºå°æä½ç©ºéçµæ§åæéåæï¼è®æåè½å¤ å¾é£çºç«é¢çç©ºéåæéç¶­åº¦çµåä¸­éå»º 3D å 4D è¡¨å¾µãæ­¤å¤ï¼çºäºå½åçæçå½±çåçå¯¦å ´æ¯ä¹éçå·®è·ï¼æåå¼å¥äºç¨æ¼ 3D çæçè»è·¡æç¥æ©å¶åç¨æ¼ 4D çæçèº«ä»½ä¿çå»åªç­ç¥ãå¨åç¨®çå¯¦ä¸çååæè³æéä¸çå»£æ³å¯¦é©è­æï¼èååçæè¡ç¸æ¯ï¼DimensionX å¨å¯æ§å½±ççæä»¥å 3D å 4D å ´æ¯çææ¹é¢é½åå¾äºåè¶çææã</paragraph>

##### **StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration**
2411.04925v1 by Panwen Hu, Jin Jiang, Jianqi Chen, Mingfei Han, Shengcai Liao, Xiaojun Chang, Xiaodan Liang

The advent of AI-Generated Content (AIGC) has spurred research into automated
video generation to streamline conventional processes. However, automating
storytelling video production, particularly for customized narratives, remains
challenging due to the complexity of maintaining subject consistency across
shots. While existing approaches like Mora and AesopAgent integrate multiple
agents for Story-to-Video (S2V) generation, they fall short in preserving
protagonist consistency and supporting Customized Storytelling Video Generation
(CSVG). To address these limitations, we propose StoryAgent, a multi-agent
framework designed for CSVG. StoryAgent decomposes CSVG into distinct subtasks
assigned to specialized agents, mirroring the professional production process.
Notably, our framework includes agents for story design, storyboard generation,
video creation, agent coordination, and result evaluation. Leveraging the
strengths of different models, StoryAgent enhances control over the generation
process, significantly improving character consistency. Specifically, we
introduce a customized Image-to-Video (I2V) method, LoRA-BE, to enhance
intra-shot temporal consistency, while a novel storyboard generation pipeline
is proposed to maintain subject consistency across shots. Extensive experiments
demonstrate the effectiveness of our approach in synthesizing highly consistent
storytelling videos, outperforming state-of-the-art methods. Our contributions
include the introduction of StoryAgent, a versatile framework for video
generation tasks, and novel techniques for preserving protagonist consistency.

æè¦ï¼äººå·¥æºè½çæå§å®¹ (AIGC) çåºç¾ï¼åºæ¿äºèªååå½±ççæçç ç©¶ï¼ä»¥ç°¡åå³çµ±æµç¨ãç¶èï¼èªååèªªæäºå½±çè£½ä½ï¼ç¹å¥æ¯å®¢è£½åæäºï¼ç±æ¼å¨é¡é ­éç¶­æä¸»é¡ä¸è´æ§çè¤éæ§ï¼ä»ç¶å·æææ°æ§ãéç¶ç¾æçæ¹æ³ï¼å¦ Mora å AesopAgentï¼æ´åå¤åä»£çï¼ç¨æ¼æäºå°å½±ç (S2V) çæï¼ä½å¨ä¿çä¸»è§ä¸è´æ§åæ¯æ´å®¢è£½åèªªæäºå½±ççæ (CSVG) æ¹é¢ä»æä¸è¶³ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº StoryAgentï¼ä¸åå°çº CSVG è¨­è¨çå¤ä»£çæ¶æ§ãStoryAgent å° CSVG åè§£æåéçµ¦å°éä»£ççä¸åå­ä»»åï¼åæ äºå°æ¥­è£½ä½æµç¨ãå¼å¾æ³¨æçæ¯ï¼æåçæ¶æ§åæ¬æäºè¨­è¨ãåé¡ç¢çãå½±çè£½ä½ãä»£çåèª¿åçµæè©ä¼°çä»£çãå©ç¨ä¸åæ¨¡åçåªå¢ï¼StoryAgent å¢å¼·äºå°çæéç¨çæ§å¶ï¼é¡¯èæ¹åäºè§è²ä¸è´æ§ãå·é«ä¾èªªï¼æåå¼å¥äºä¸åå®¢è£½åçå½±åå°å½±ç (I2V) æ¹æ³ï¼LoRA-BEï¼ä»¥å¢å¼·é¡é ­å§çæéä¸è´æ§ï¼åææåºäºä¸åæ°ç©çåé¡çæç®¡éï¼ä»¥å¨é¡é ­éç¶­æä¸»é¡ä¸è´æ§ãå»£æ³çå¯¦é©è­æäºæåçæ¹æ³å¨åæé«åº¦ä¸è´çèªªæäºå½±çæ¹é¢çæææ§ï¼åªæ¼æåé²çæ¹æ³ãæåçè²¢ç»åæ¬å¼å¥äº StoryAgentï¼ä¸åç¨æ¼å½±ççæä»»åçå¤åè½æ¶æ§ï¼ä»¥åä¿çä¸»è§ä¸è´æ§çæ°æè¡ã

##### **GPTKB: Building Very Large Knowledge Bases from Language Models**
2411.04920v1 by Yujia Hu, Shrestha Ghosh, Tuan-Phong Nugyen, Simon Razniewski

General-domain knowledge bases (KB), in particular the "big three" --
Wikidata, Yago and DBpedia -- are the backbone of many intelligent
applications. While these three have seen steady development, comprehensive KB
construction at large has seen few fresh attempts. In this work, we propose to
build a large general-domain KB entirely from a large language model (LLM). We
demonstrate the feasibility of large-scale KB construction from LLMs, while
highlighting specific challenges arising around entity recognition, entity and
property canonicalization, and taxonomy construction. As a prototype, we use
GPT-4o-mini to construct GPTKB, which contains 105 million triples for more
than 2.9 million entities, at a cost 100x less than previous KBC projects. Our
work is a landmark for two fields: For NLP, for the first time, it provides
\textit{constructive} insights into the knowledge (or beliefs) of LLMs. For the
Semantic Web, it shows novel ways forward for the long-standing challenge of
general-domain KB construction. GPTKB is accessible at https://gptkb.org.

æè¦ï¼ä¸è¬é åç¥è­åº« (KB)ï¼ç¹å¥æ¯ãä¸å¤§ç¥è­åº«ã-- WikidataãYago å DBpedia -- æ¯è¨±å¤æºæ§åæç¨ç¨å¼çéª¨å¹¹ãåç®¡éä¸åç¥è­åº«æçºç¼å±ï¼ä½æ´é«èè¨ï¼å¨é¢çç¥è­åº«å»ºæ§é®®å°ææ°çåè©¦ãå¨æ­¤ç ç©¶ä¸­ï¼æåæè­°å®å¨å¾å¤§åèªè¨æ¨¡å (LLM) å»ºç«ä¸åå¤§åä¸è¬é åç¥è­åº«ãæåå±ç¤ºäºå¾ LLM å»ºæ§å¤§è¦æ¨¡ç¥è­åº«çå¯è¡æ§ï¼åæå¼·èª¿äºå¯¦é«è¾¨è­ãå¯¦é«åå±¬æ§æ­£è¦åä»¥ååé¡æ³å»ºæ§ç­ç¹å®ææ°ãä½çºååï¼æåä½¿ç¨ GPT-4o-mini å»ºæ§ GPTKBï¼å¶ä¸­åå«è¶é 290 è¬åå¯¦é«ç 1.05 ååä¸åçµï¼ææ¬æ¯ååç KBC å°æ¡ä½ 100 åãæåçç ç©¶æ¯å©åé åçéç¨ç¢ï¼å°æ¼èªç¶èªè¨èç (NLP)ï¼å®é¦æ¬¡æä¾äº LLM çç¥è­ï¼æä¿¡å¿µï¼çãå»ºæ§æ§ãè¦è§£ãå°æ¼èªæç¶²è·¯ï¼å®å±ç¤ºäºé·æå­å¨çä¸è¬é åç¥è­åº«å»ºæ§ææ°çæ°ç©æ¹æ³ãGPTKB å¯å¨ https://gptkb.org åå¾ã

##### **Evaluating Robustness of Reinforcement Learning Algorithms for Autonomous Shipping**
2411.04915v1 by Bavo Lesy, Ali Anwar, Siegfried Mercelis

Recently, there has been growing interest in autonomous shipping due to its
potential to improve maritime efficiency and safety. The use of advanced
technologies, such as artificial intelligence, can address the current
navigational and operational challenges in autonomous shipping. In particular,
inland waterway transport (IWT) presents a unique set of challenges, such as
crowded waterways and variable environmental conditions. In such dynamic
settings, the reliability and robustness of autonomous shipping solutions are
critical factors for ensuring safe operations. This paper examines the
robustness of benchmark deep reinforcement learning (RL) algorithms,
implemented for IWT within an autonomous shipping simulator, and their ability
to generate effective motion planning policies. We demonstrate that a
model-free approach can achieve an adequate policy in the simulator,
successfully navigating port environments never encountered during training. We
focus particularly on Soft-Actor Critic (SAC), which we show to be inherently
more robust to environmental disturbances compared to MuZero, a
state-of-the-art model-based RL algorithm. In this paper, we take a significant
step towards developing robust, applied RL frameworks that can be generalized
to various vessel types and navigate complex port- and inland environments and
scenarios.

æè¦ï¼<paragraph>æè¿ï¼ç±æ¼èªåèªéæææåèªæµ·æçåå®å¨æ§ï¼å æ­¤ååéæ³¨ãä½¿ç¨äººå·¥æºæ§ç­åé²æè¡ï¼å¯ä»¥è§£æ±ºèªåèªéä¸­ç¾æçå°èªåçéææ°ãç¹å¥æ¯ï¼å§é¸æ°´ééè¼¸ (IWT) æåºäºä¸çµç¨ç¹çææ°ï¼ä¾å¦ææ çæ°´éåå¤è®çç°å¢æ¢ä»¶ãå¨éç¨®åæç°å¢ä¸­ï¼èªåèªéè§£æ±ºæ¹æ¡çå¯é æ§åç©©å¥æ§æ¯ç¢ºä¿å®å¨çéçééµå ç´ ãæ¬ææ¢è¨äºåºæºæ·±åº¦å¼·åå­¸ç¿ (RL) æ¼ç®æ³çç©©å¥æ§ï¼éäºæ¼ç®æ³æ¯å¨èªåèªéæ¨¡æ¬å¨ä¸­çº IWT å¯¦ä½ï¼ä»¥åå®åç¢çææéåè¦åæ¿ç­çè½åãæåè­æäºç¡æ¨¡åæ¹æ³å¯ä»¥å¨æ¨¡æ¬å¨ä¸­å¯¦ç¾é©ç¶çæ¿ç­ï¼æåå°èªå¨è¨ç·´æéå¾æªé­ééçæ¸¯å£ç°å¢ãæåç¹å¥éæ³¨ Soft-Actor Critic (SAC)ï¼æåå±ç¤ºå®è MuZeroï¼ä¸ç¨®æåé²çåºæ¼æ¨¡åç RL æ¼ç®æ³ï¼ç¸æ¯ï¼æ¬è³ªä¸å°ç°å¢å¹²æ¾æ´ç©©å¥ãå¨æ¬æä¸­ï¼æåéåºäºéè¦ä¸æ­¥ï¼éç¼ç©©å¥çæç¨ RL æ¶æ§ï¼å¯ä»¥æ¨å»£å°åç¨®è¹è¶é¡åï¼ä¸¦å°èªè¤éçæ¸¯å£åå§é¸ç°å¢åå ´æ¯ã</paragraph>

##### **GASE: Generatively Augmented Sentence Encoding**
2411.04914v1 by Manuel Frank, Haithem Afli

We propose an approach to enhance sentence embeddings by applying generative
text models for data augmentation at inference time. Unlike conventional data
augmentation that utilises synthetic training data, our approach does not
require access to model parameters or the computational resources typically
required for fine-tuning state-of-the-art models. Generatively Augmented
Sentence Encoding uses diverse linguistic synthetic variants of input texts
generated by paraphrasing, summarising, or extracting keywords, followed by
pooling the original and synthetic embeddings. Experimental results on the
Massive Text Embedding Benchmark for Semantic Textual Similarity (STS)
demonstrate performance improvements across a range of embedding models using
different generative models for augmentation. We find that generative
augmentation leads to larger performance improvements for embedding models with
lower baseline performance. These findings suggest that integrating generative
augmentation at inference time adds semantic diversity and can enhance the
robustness and generalizability of sentence embeddings for embedding models.
Our results show that the degree to which generative augmentation can improve
STS performance depends not only on the embedding model but also on the
dataset. From a broader perspective, the approach allows trading training for
inference compute.

æè¦ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼ééå¨æ¨è«æéæç¨çæå¼æå­æ¨¡åä¾å¢å¼·å¥å­åµå¥ï¼ä»¥é²è¡è³ææ´åãèå©ç¨åæè¨ç·´è³æçå³çµ±è³ææ´åä¸åï¼æåçåæ³ä¸éè¦å­åæ¨¡ååæ¸æå¾®èª¿æåé²æ¨¡åéå¸¸éè¦çè¨ç®è³æºãçæå¼å¢å¼·å¥å­ç·¨ç¢¼ä½¿ç¨ç±åç¾©æ¹å¯«ãæè¦ææåééµå­ç¢ççè¼¸å¥æå­çä¸åèªè¨åæè®é«ï¼ç¶å¾å¯éåå§ååæåµå¥ãå¨èªç¾©æå­ç¸ä¼¼åº¦ (STS) çå¤§éæå­åµå¥åºæºä¸çå¯¦é©çµæé¡¯ç¤ºï¼ä½¿ç¨ä¸åççæå¼æ¨¡åé²è¡æ´åï¼åç¨®åµå¥æ¨¡åçæè½é½æææåãæåç¼ç¾ï¼çæå¼æ´åå°æ¼åºæºæè½è¼ä½çåµå¥æ¨¡åï¼æå¸¶ä¾è¼å¤§çæè½æåãéäºç¼ç¾è¡¨æï¼å¨æ¨è«æéæ´åçæå¼æ´åæå¢å èªç¾©å¤æ¨£æ§ï¼ä¸¦å¯ä»¥å¢å¼·åµå¥æ¨¡åçå¥å­åµå¥çç©©å¥æ§åæ¦æ¬æ§ãæåççµæé¡¯ç¤ºï¼çæå¼æ´åå¯ä»¥æ¹å STS æè½çç¨åº¦ï¼ä¸ååæ±ºæ¼åµå¥æ¨¡åï¼éåæ±ºæ¼è³æéãå¾æ´å»£æ³çè§åº¦ä¾çï¼éç¨®æ¹æ³åè¨±å¨è¨ç·´åæ¨è«è¨ç®ä¹éé²è¡äº¤æã

##### **OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models**
2411.04905v1 by Siming Huang, Tianhao Cheng, Jason Klein Liu, Jiaran Hao, Liuyihan Song, Yang Xu, J. Yang, J. H. Liu, Chenchen Zhang, Linzheng Chai, Ruifeng Yuan, Zhaoxiang Zhang, Jie Fu, Qian Liu, Ge Zhang, Zili Wang, Yuan Qi, Yinghui Xu, Wei Chu

Large language models (LLMs) for code have become indispensable in various
domains, including code generation, reasoning tasks and agent systems.While
open-access code LLMs are increasingly approaching the performance levels of
proprietary models, high-quality code LLMs suitable for rigorous scientific
investigation, particularly those with reproducible data processing pipelines
and transparent training protocols, remain limited. The scarcity is due to
various challenges, including resource constraints, ethical considerations, and
the competitive advantages of keeping models advanced. To address the gap, we
introduce OpenCoder, a top-tier code LLM that not only achieves performance
comparable to leading models but also serves as an ``open cookbook'' for the
research community. Unlike most prior efforts, we release not only model
weights and inference code, but also the reproducible training data, complete
data processing pipeline, rigorous experimental ablation results, and detailed
training protocols for open scientific research. Through this comprehensive
release, we identify the key ingredients for building a top-tier code LLM: (1)
code optimized heuristic rules for data cleaning and methods for data
deduplication, (2) recall of text corpus related to code and (3) high-quality
synthetic data in both annealing and supervised fine-tuning stages. By offering
this level of openness, we aim to broaden access to all aspects of a top-tier
code LLM, with OpenCoder serving as both a powerful model and an open
foundation to accelerate research, and enable reproducible advancements in code
AI.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²æçºåç¨®é åä¸å¯æç¼ºçç¨å¼ç¢¼ï¼åæ¬ç¨å¼ç¢¼çæãæ¨çä»»ååä»£çç³»çµ±ãéç¶éæ¾åç¨çç¨å¼ç¢¼ LLM éæ¼¸æ¥è¿å°ææ¨¡åçæè½æ°´æºï¼ä½é©åå´è¬¹ç§å­¸èª¿æ¥çé«åè³ªç¨å¼ç¢¼ LLMï¼ç¹å¥æ¯é£äºå·æå¯è¤è£½è³æèçç®¡ç·åéæè¨ç·´åå®çç¨å¼ç¢¼ LLMï¼ä»ç¶æéãéç¨®ç¨ç¼ºæ§æ¯ç±æ¼åç¨®ææ°ï¼åæ¬è³æºéå¶ãå«çèéä»¥åä¿ææ¨¡ååé²çç«¶ç­åªå¢ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº OpenCoderï¼éæ¯ä¸åé ç´ç¨å¼ç¢¼ LLMï¼ä¸åè½éå°èé åæ¨¡åç¸ç¶çæè½ï¼éè½ä½çºç ç©¶ç¤¾ç¾¤çãéæ¾é£è­ããèå¤§å¤æ¸ååçåªåä¸åï¼æåä¸åéåºæ¨¡åæ¬éåæ¨è«ç¨å¼ç¢¼ï¼ééåºå¯è¤è£½çè¨ç·´è³æãå®æ´çè³æèçç®¡ç·ãå´è¬¹çå¯¦é©æ¶èçµæï¼ä»¥åéæ¾ç§å­¸ç ç©¶çè©³ç´°è¨ç·´åå®ãéééåå¨é¢çéåºï¼æåæ¾åºå»ºç«é ç´ç¨å¼ç¢¼ LLM çééµè¦ç´ ï¼(1) è³ææ¸ççæä½³ååç¼å¼è¦ååè³æéè¤æ¶é¤çæ¹æ³ï¼(2) èç¨å¼ç¢¼ç¸éçæå­èªæåº«çå¬åï¼ä»¥å (3) éç«åç£ç£å¾®èª¿éæ®µä¸­çé«åè³ªåæè³æãééæä¾éç¨®ç¨åº¦çéæ¾æ§ï¼æåæ¨å¨æ´å¤§å°é ç´ç¨å¼ç¢¼ LLM ååæ¹é¢çä½¿ç¨ï¼è® OpenCoder åææçºå¼·å¤§çæ¨¡ååéæ¾åºç¤ï¼ä»¥å éç ç©¶ï¼ä¸¦ä¿é²ç¨å¼ç¢¼ AI çå¯è¤è£½é²å±ã

##### **GUI Agents with Foundation Models: A Comprehensive Survey**
2411.04890v1 by Shuai Wang, Weiwen Liu, Jingxuan Chen, Weinan Gan, Xingshan Zeng, Shuai Yu, Xinlong Hao, Kun Shao, Yasheng Wang, Ruiming Tang

Recent advances in foundation models, particularly Large Language Models
(LLMs) and Multimodal Large Language Models (MLLMs), facilitate intelligent
agents being capable of performing complex tasks. By leveraging the ability of
(M)LLMs to process and interpret Graphical User Interfaces (GUIs), these agents
can autonomously execute user instructions by simulating human-like
interactions such as clicking and typing. This survey consolidates recent
research on (M)LLM-based GUI agents, highlighting key innovations in data,
frameworks, and applications. We begin by discussing representative datasets
and benchmarks. Next, we summarize a unified framework that captures the
essential components used in prior research, accompanied by a taxonomy.
Additionally, we explore commercial applications of (M)LLM-based GUI agents.
Drawing from existing work, we identify several key challenges and propose
future research directions. We hope this paper will inspire further
developments in the field of (M)LLM-based GUI agents.

æè¦ï¼æè¿å¨åºç¤æ¨¡åçé²å±ï¼ç¹å¥æ¯å¤§åèªè¨æ¨¡å (LLM) åå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM)ï¼ä¿é²æºè½ä»£çè½å¤ å·è¡è¤éçä»»åãèç±éç¨ (M)LLM èçåè©®éåå½¢ä½¿ç¨èä»é¢ (GUI) çè½åï¼éäºä»£çå¯ä»¥ééæ¨¡æ¬é»æåè¼¸å¥ç­é¡ä¼¼äººé¡çäºåï¼èªåå·è¡ä½¿ç¨èçæä»¤ãæ­¤èª¿æ¥å½æ´äºæè¿éæ¼ (M)LLM çºåºç¤ç GUI ä»£ççç ç©¶ï¼éé»èªªæäºè³æãæ¶æ§åæç¨ç¨å¼çééµåµæ°ãæåå¾è¨è«å·ä»£è¡¨æ§çè³æéååºæºéå§ãæ¥èï¼æåæè¦ä¸åçµ±ä¸çæ¶æ§ï¼å¶ä¸­åå«ååç ç©¶ä¸­ä½¿ç¨çåºæ¬åä»¶ï¼ä¸¦éä¸åé¡æ³ãæ­¤å¤ï¼æåæ¢è¨ (M)LLM çºåºç¤ç GUI ä»£ççåæ¥­æç¨ãæ ¹æç¾æå·¥ä½ï¼æåæ¾åºå¹¾åééµææ°ï¼ä¸¦æåºæªä¾çç ç©¶æ¹åãæåå¸æéç¯è«æè½æ¿ç¼ (M)LLM çºåºç¤ç GUI ä»£çé åçé²ä¸æ­¥ç¼å±ã

##### **FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI**
2411.04872v1 by Elliot Glazer, Ege Erdil, Tamay Besiroglu, Diego Chicharro, Evan Chen, Alex Gunning, Caroline Falkman Olsson, Jean-Stanislas Denain, Anson Ho, Emily de Oliveira Santos, Olli JÃ¤rviniemi, Matthew Barnett, Robert Sandler, Jaime Sevilla, Qiuyu Ren, Elizabeth Pratt, Lionel Levine, Grant Barkley, Natalie Stewart, Bogdan Grechuk, Tetiana Grechuk, Shreepranav Varma Enugandla

We introduce FrontierMath, a benchmark of hundreds of original, exceptionally
challenging mathematics problems crafted and vetted by expert mathematicians.
The questions cover most major branches of modern mathematics -- from
computationally intensive problems in number theory and real analysis to
abstract questions in algebraic geometry and category theory. Solving a typical
problem requires multiple hours of effort from a researcher in the relevant
branch of mathematics, and for the upper end questions, multiple days.
FrontierMath uses new, unpublished problems and automated verification to
reliably evaluate models while minimizing risk of data contamination. Current
state-of-the-art AI models solve under 2% of problems, revealing a vast gap
between AI capabilities and the prowess of the mathematical community. As AI
systems advance toward expert-level mathematical abilities, FrontierMath offers
a rigorous testbed that quantifies their progress.

æè¦ï¼æåæ¨åº FrontierMathï¼éæ¯æ¸ç¾åç±å°å®¶æ¸å­¸å®¶ç²¾å¿è£½ä½åå¯©æ¥çååµãæ¥µå·ææ°æ§çæ¸å­¸åé¡çåºæºãéäºåé¡æ¶µèäºç¾ä»£æ¸å­¸çå¤§å¤æ¸ä¸»è¦åæ¯ââå¾æ¸è«åå¯¦åæä¸­çè¨ç®å¯éååé¡å°ä»£æ¸å¹¾ä½åç¯çè«ä¸­çæ½è±¡åé¡ãè§£æ±ºä¸åå¸ååé¡éè¦ç¸éæ¸å­¸åæ¯çç ç©¶äººå¡è±è²»æ¸å°æçç²¾åï¼èå°æ¼è¼é£çåé¡ï¼åéè¦æ¸å¤©æéãFrontierMath ä½¿ç¨æ°çãæªç¼è¡¨çé¡ç®åèªååé©è­ä¾å¯é å°è©ä¼°æ¨¡åï¼åææå¤§éåº¦å°éä½æ¸ææ±¡æçé¢¨éªãç¶åçæåé² AI æ¨¡ååªè½è§£æ±ºä¸å° 2% çåé¡ï¼éæ­ç¤ºäº AI è½åèæ¸å­¸ççå¯¦åä¹éå­å¨å·¨å¤§å·®è·ãé¨è AI ç³»çµ±åå°å®¶ç´æ¸å­¸è½åéé²ï¼FrontierMath æä¾äºä¸åå´æ ¼çæ¸¬è©¦å¹³å°ï¼å¯ä»¥éåå®åçé²åº¦ã

##### **Think Smart, Act SMARL! Analyzing Probabilistic Logic Driven Safety in Multi-Agent Reinforcement Learning**
2411.04867v1 by Satchit Chatterji, Erman Acar

An important challenge for enabling the deployment of reinforcement learning
(RL) algorithms in the real world is safety. This has resulted in the recent
research field of Safe RL, which aims to learn optimal policies that are safe.
One successful approach in that direction is probabilistic logic shields (PLS),
a model-based Safe RL technique that uses formal specifications based on
probabilistic logic programming, constraining an agent's policy to comply with
those specifications in a probabilistic sense. However, safety is inherently a
multi-agent concept, since real-world environments often involve multiple
agents interacting simultaneously, leading to a complex system which is hard to
control. Moreover, safe multi-agent RL (Safe MARL) is still underexplored. In
order to address this gap, in this paper we ($i$) introduce Shielded MARL
(SMARL) by extending PLS to MARL -- in particular, we introduce Probabilistic
Logic Temporal Difference Learning (PLTD) to enable shielded independent
Q-learning (SIQL), and introduce shielded independent PPO (SIPPO) using
probabilistic logic policy gradients; ($ii$) show its positive effect and use
as an equilibrium selection mechanism in various game-theoretic environments
including two-player simultaneous games, extensive-form games, stochastic
games, and some grid-world extensions in terms of safety, cooperation, and
alignment with normative behaviors; and ($iii$) look into the asymmetric case
where only one agent is shielded, and show that the shielded agent has a
significant influence on the unshielded one, providing further evidence of
SMARL's ability to enhance safety and cooperation in diverse multi-agent
environments.

æè¦ï¼<paragraph>å¨ç¾å¯¦ä¸çä¸­é¨ç½²å¼·åå­¸ç¿ (RL) æ¼ç®æ³çä¸é éè¦ææ°å¨æ¼å®å¨æ§ãéå°è´äºè¿æç ç©¶é åçå®å¨ RLï¼å¶ç®æ¨æ¯å­¸ç¿å®å¨çæä½³ç­ç¥ãæéåæ¹åç¼å±çä¸ç¨®æåæ¹æ³æ¯æ©çéè¼¯é²è­· (PLS)ï¼éæ¯ä¸ç¨®åºæ¼æ¨¡åçå®å¨ RL æè¡ï¼å®ä½¿ç¨åºæ¼æ©çéè¼¯ç¨å¼è¨­è¨çå½¢å¼åè¦ç¯ï¼ä»¥æ©çæç¾©éå¶ä»£ççç­ç¥ä»¥ç¬¦åéäºè¦ç¯ãç¶èï¼å®å¨æ§æ¬è³ªä¸æ¯ä¸åå¤éä»£çæ¦å¿µï¼å çºç¾å¯¦ä¸ççç°å¢éå¸¸æ¶åå¤åä»£çåæäºåï¼å°è´ä¸åé£ä»¥æ§å¶çè¤éç³»çµ±ãæ­¤å¤ï¼å®å¨å¤éä»£ç RL (Safe MARL) ä»æªå¾å°ååæ¢ç´¢ãçºäºè§£æ±ºéåå·®è·ï¼å¨æ¬æä¸­æå ($i$) ééå° PLS æ´åå° MARL ä¾ä»ç´¹é²è­·å¼ MARL (SMARL) -- ç¹å¥æ¯ï¼æåä»ç´¹æ©çéè¼¯æåºå·®åå­¸ç¿ (PLTD) ä»¥åç¨é²è­·å¼ç¨ç« Q å­¸ç¿ (SIQL)ï¼ä¸¦ä½¿ç¨æ©çéè¼¯ç­ç¥æ¢¯åº¦å¼å¥é²è­·å¼ç¨ç« PPO (SIPPO)ï¼($ii$) å±ç¤ºå¶æ­£é¢ææï¼ä¸¦ç¨ä½åç¨®åå¼è«ç°å¢ä¸­çåè¡¡é¸ææ©å¶ï¼åæ¬éäººåæåå¼ãå»£ç¾©ååå¼ãé¨æ©åå¼ï¼ä»¥åå¨å®å¨æ§ãåä½åèè¦ç¯è¡çºä¸è´æ§æ¹é¢çæäºæ ¼çä¸çæ´åï¼ä»¥å ($iii$) æ¢è¨åªæå®ä¸ä»£çé²è­·çä¸å°ç¨±æ¡ä¾ï¼ä¸¦å±ç¤ºé²è­·å¼ä»£çå°æªé²è­·å¼ä»£çæé¡¯èå½±é¿ï¼é²ä¸æ­¥è­æ SMARL è½å¤ å¢å¼·ä¸åå¤éä»£çç°å¢ä¸­çå®å¨æ§èåä½ã</paragraph>

##### **ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset**
2411.04865v1 by Olaf Wysocki, Yue Tan, Thomas Froech, Yan Xia, Magdalena Wysocki, Ludwig Hoegner, Daniel Cremers, Christoph Holst

Facade semantic segmentation is a long-standing challenge in photogrammetry
and computer vision. Although the last decades have witnessed the influx of
facade segmentation methods, there is a lack of comprehensive facade classes
and data covering the architectural variability. In ZAHA, we introduce Level of
Facade Generalization (LoFG), novel hierarchical facade classes designed based
on international urban modeling standards, ensuring compatibility with
real-world challenging classes and uniform methods' comparison. Realizing the
LoFG, we present to date the largest semantic 3D facade segmentation dataset,
providing 601 million annotated points at five and 15 classes of LoFG2 and
LoFG3, respectively. Moreover, we analyze the performance of baseline semantic
segmentation methods on our introduced LoFG classes and data, complementing it
with a discussion on the unresolved challenges for facade segmentation. We
firmly believe that ZAHA shall facilitate further development of 3D facade
semantic segmentation methods, enabling robust segmentation indispensable in
creating urban digital twins.

æè¦ï¼å¤è§èªç¾©åå²æ¯æå½±æ¸¬éåé»è¦è¦è¦ºä¸­é·æå­å¨çææ°ãåç®¡å¨éå»çå¹¾åå¹´ä¸­è¦è­äºå¤è§åå²æ¹æ³çæ¹§å¥ï¼ä½ä»ç¼ºä¹æ¶µèå»ºç¯å¯è®æ§çç¶åå¤è§é¡å¥åè³æãå¨ ZAHA ä¸­ï¼æåå¼å¥äºå¤è§æ¦æ¬å±¤ç´ (LoFG)ï¼ä¸ç¨®åºæ¼åéåå¸å»ºæ¨¡æ¨æºè¨­è¨çæ°éå±¤å¼å¤è§é¡å¥ï¼ç¢ºä¿èç¾å¯¦ä¸çä¸­çææ°æ§é¡å¥åçµ±ä¸æ¹æ³çæ¯è¼ç¸å®¹ãå¯¦ç¾ LoFG å¾ï¼æåè¿ä»çºæ­¢æä¾äºæå¤§çèªç¾© 3D å¤è§åå²è³æéï¼åå¥å¨ LoFG2 å LoFG3 çäºåå 15 åé¡å¥ä¸­æä¾äº 6 ååè¨»è§£é»ãæ­¤å¤ï¼æååæäºåºç·èªç¾©åå²æ¹æ³å¨å¶å¼å¥ç LoFG é¡å¥åè³æä¸çæè½ï¼ä¸¦è£åè¨è«äºå¤è§åå²ä¸­æªè§£æ±ºçææ°ãæåå ä¿¡ ZAHA å°ä¿é² 3D å¤è§èªç¾©åå²æ¹æ³çé²ä¸æ­¥ç¼å±ï¼å¯¦ç¾å¼·å¥çåå²ï¼éå°æ¼å»ºç«åå¸æ¸ä½éèèè³ééè¦ã

##### **Sentiment Analysis of Spanish Political Party Tweets Using Pre-trained Language Models**
2411.04862v1 by Chuqiao Song, Shunzhang Chen, Xinyi Cai, Hao Chen

Title: Sentiment Analysis of Spanish Political Party Communications on
Twitter Using Pre-trained Language Models
  Authors: Chuqiao Song, Shunzhang Chen, Xinyi Cai, Hao Chen
  Comments: 21 pages, 6 figures
  Abstract: This study investigates sentiment patterns within Spanish political
party communications on Twitter by leveraging BETO and RoBERTuito, two
pre-trained language models optimized for Spanish text. Using a dataset of
tweets from major Spanish political parties: PSOE, PP, Vox, Podemos, and
Ciudadanos, spanning 2019 to 2024, this research analyzes sentiment
distributions and explores the relationship between sentiment expression and
party ideology. The findings indicate that both models consistently identify a
predominant Neutral sentiment across all parties, with significant variations
in Negative and Positive sentiments that align with ideological distinctions.
Specifically, Vox exhibits higher levels of Negative sentiment, while PSOE
demonstrates relatively high Positive sentiment, supporting the hypothesis that
emotional appeals in political messaging reflect ideological stances. This
study underscores the potential of pre-trained language models for non-English
sentiment analysis on social media, providing insights into sentiment dynamics
that shape public discourse within Spain's multi-party political system.
  Keywords: Spanish politics, sentiment analysis, pre-trained language models,
Twitter, BETO, RoBERTuito, political ideology, multi-party system

æè¦ï¼<paragraph>æ¨é¡ï¼ä½¿ç¨é åè¨ç·´èªè¨æ¨¡åå°è¥¿ç­çæ¿é»¨å¨æ¨ç¹ä¸çæºéé²è¡æç·åæ
ä½èï¼å®æ¥å¬ãé³é ç« ãè¡æ¬£æ¡ãé³æµ©
è©è«ï¼21 é ã6 å¼µå
æè¦ï¼æ¬ç ç©¶å©ç¨éå°è¥¿ç­çèªææ¬æä½³åçå©åé åè¨ç·´èªè¨æ¨¡å BETO å RoBERTuitoï¼æ¢è¨è¥¿ç­çæ¿é»¨å¨æ¨ç¹ä¸çæºéä¸­çæç·æ¨¡å¼ãæ¬ç ç©¶ä½¿ç¨ 2019 å¹´è³ 2024 å¹´éè¥¿ç­çä¸»è¦æ¿é»¨ï¼PSOEãPPãVoxãPodemos å Ciudadanosï¼çæ¨æè³æéï¼åææç·åä½ï¼ä¸¦æ¢è¨æç·è¡¨éèæ¿é»¨æè­å½¢æä¹éçéä¿ãç ç©¶çµæé¡¯ç¤ºï¼éå©åæ¨¡åä¸è´å°ç¼ç¾æææ¿é»¨çæç·ä»¥ä¸­ç«æç·çºä¸»ï¼èè² é¢åæ­£é¢æç·çé¡¯èè®åèæè­å½¢æåå¥ä¸è´ãå·é«ä¾èªªï¼Vox è¡¨ç¾åºè¼é«çè² é¢æç·ï¼è PSOE è¡¨ç¾åºè¼é«çæ­£é¢æç·ï¼éæ¯æäºæ¿æ²»è¨æ¯ä¸­çæç·è¨´æ±åæ æè­å½¢æç«å ´çåè¨­ãæ¬ç ç©¶å¼·èª¿äºé åè¨ç·´èªè¨æ¨¡åå¨éè±èªç¤¾ç¾¤åªé«æç·åæä¸­çæ½åï¼ä¸¦æä¾äºå°æç·åæçè¦è§£ï¼éäºåæå¡é äºè¥¿ç­çå¤é»¨æ¿æ²»é«ç³»ä¸­çå¬å±è«è¿°ã
ééµå­ï¼è¥¿ç­çæ¿æ²»ãæç·åæãé åè¨ç·´èªè¨æ¨¡åãæ¨ç¹ãBETOãRoBERTuitoãæ¿æ²»æè­å½¢æãå¤é»¨å¶</paragraph>

##### **Prompt-Guided Internal States for Hallucination Detection of Large Language Models**
2411.04847v1 by Fujie Zhang, Peiqi Yu, Biao Yi, Baolei Zhang, Tong Li, Zheli Liu

Large Language Models (LLMs) have demonstrated remarkable capabilities across
a variety of tasks in different domains. However, they sometimes generate
responses that are logically coherent but factually incorrect or misleading,
which is known as LLM hallucinations. Data-driven supervised methods train
hallucination detectors by leveraging the internal states of LLMs, but
detectors trained on specific domains often struggle to generalize well to
other domains. In this paper, we aim to enhance the cross-domain performance of
supervised detectors with only in-domain data. We propose a novel framework,
prompt-guided internal states for hallucination detection of LLMs, namely
PRISM. By utilizing appropriate prompts to guide changes in the structure
related to text truthfulness within the LLM's internal states, we make this
structure more salient and consistent across texts from different domains. We
integrated our framework with existing hallucination detection methods and
conducted experiments on datasets from different domains. The experimental
results indicate that our framework significantly enhances the cross-domain
generalization of existing hallucination detection methods.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¤ºåºå¨ä¸åé åçåç¨®ä»»åä¸­å·æéå¡çè½åãç¶èï¼å®åæææç¢çå¨éè¼¯ä¸é£è²«ä½äºå¯¦ä¸ä¸æ­£ç¢ºæå·æèª¤å°æ§çåæï¼éè¢«ç¨±çº LLM å¹»è¦ºãæ¸æé©åçç£ç£æ¹æ³ééå©ç¨ LLM çå§é¨çæä¾è¨ç·´å¹»è¦ºæª¢æ¸¬å¨ï¼ä½éå°ç¹å®é åè¨ç·´çæª¢æ¸¬å¨éå¸¸é£ä»¥å¾å¥½å°æ¨å»£å°å¶ä»é åãå¨æ¬æä¸­ï¼æåæ¨å¨åä½¿ç¨åå§æ¸æä¾å¢å¼·ç£ç£æª¢æ¸¬å¨çè·¨åæ§è½ãæåæåºäºä¸åæ°æ¡æ¶ï¼å³ç¨æ¼ LLM å¹»è¦ºæª¢æ¸¬çæç¤ºå¼å°å§é¨çæï¼å³ PRISMãééä½¿ç¨é©ç¶çæç¤ºä¾æå°è LLM å§é¨çæä¸­èææ¬çå¯¦æ§ç¸éççµæ§çè®åï¼æåä½¿è©²çµæ§æ´çªåºï¼ä¸¦å¨ä¾èªä¸åé åçææ¬ä¸­ä¿æä¸è´ãæåå°æåçæ¡æ¶èç¾æçå¹»è¦ºæª¢æ¸¬æ¹æ³éæå¨ä¸èµ·ï¼ä¸¦å°ä¾èªä¸åé åçæ¸æéé²è¡äºå¯¦é©ãå¯¦é©çµæè¡¨æï¼æåçæ¡æ¶é¡¯èå¢å¼·äºç¾æå¹»è¦ºæª¢æ¸¬æ¹æ³çè·¨åæ³åã

##### **Machine learning and optimization-based approaches to duality in statistical physics**
2411.04838v1 by Andrea E. V. Ferrari, Prateek Gupta, Nabil Iqbal

The notion of duality -- that a given physical system can have two different
mathematical descriptions -- is a key idea in modern theoretical physics.
Establishing a duality in lattice statistical mechanics models requires the
construction of a dual Hamiltonian and a map from the original to the dual
observables. By using simple neural networks to parameterize these maps and
introducing a loss function that penalises the difference between correlation
functions in original and dual models, we formulate the process of duality
discovery as an optimization problem. We numerically solve this problem and
show that our framework can rediscover the celebrated Kramers-Wannier duality
for the 2d Ising model, reconstructing the known mapping of temperatures. We
also discuss an alternative approach which uses known features of the mapping
of topological lines to reduce the problem to optimizing the couplings in a
dual Hamiltonian, and explore next-to-nearest neighbour deformations of the 2d
Ising duality. We discuss future directions and prospects for discovering new
dualities within this framework.

æè¦ï¼å°å¶æ§çæ¦å¿µââå³ä¸åçµ¦å®çç©çç³»çµ±å¯ä»¥æå©åä¸åçæ¸å­¸æè¿°ââæ¯ç¾ä»£çè«ç©çå­¸ä¸­çééµææ³ãå¨æ¶æ ¼çµ±è¨åå­¸æ¨¡åä¸­å»ºç«å°å¶æ§éè¦æ§å»ºä¸åå°å¶åå¯é éåä¸åå¾åå§å¯è§æ¸¬éå°å°å¶å¯è§æ¸¬éçæ å°ãééä½¿ç¨ç°¡å®çç¥ç¶ç¶²è·¯å°éäºæ å°é²è¡åæ¸åï¼ä¸¦å¼å¥ä¸åæå¤±å½æ¸ä¾æ²ç½°åå§æ¨¡ååå°å¶æ¨¡åä¸­ç¸éå½æ¸ä¹éçå·®ç°ï¼æåå°å°å¶æ§ç¼ç¾éç¨è¡¨è¿°çºä¸ååªååé¡ãæåå°éååé¡é²è¡æ¸å¼æ±è§£ï¼ä¸¦è¡¨ææåçæ¡æ¶å¯ä»¥éæ°ç¼ç¾ 2d Ising æ¨¡åçèå Kramers-Wannier å°å¶æ§ï¼éå»ºå·²ç¥çæº«åº¦æ å°ãæåéè¨è«äºå¦ä¸ç¨®æ¹æ³ï¼è©²æ¹æ³ä½¿ç¨ææ²ç·æ å°çå·²ç¥ç¹å¾µå°åé¡ç°¡åçºåªåå°å¶åå¯é éä¸­çè¦åï¼ä¸¦æ¢ç´¢äº 2d Ising å°å¶æ§çæ¬¡è¿é°è®å½¢ãæåè¨è«äºå¨éåæ¡æ¶å§ç¼ç¾æ°å°å¶æ§çæªä¾æ¹åååæ¯ã

##### **VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and Benchmark Models**
2411.04825v1 by Ming Cheng, Jiaying Gong, Chenhan Yuan, William A. Ingram, Edward Fox, Hoda Eldardiry

Existing text simplification or paraphrase datasets mainly focus on
sentence-level text generation in a general domain. These datasets are
typically developed without using domain knowledge. In this paper, we release a
novel dataset, VTechAGP, which is the first academic-to-general-audience text
paraphrase dataset consisting of 4,938 document-level these and dissertation
academic and general-audience abstract pairs from 8 colleges authored over 25
years. We also propose a novel dynamic soft prompt generative language model,
DSPT5. For training, we leverage a contrastive-generative loss function to
learn the keyword vectors in the dynamic prompt. For inference, we adopt a
crowd-sampling decoding strategy at both semantic and structural levels to
further select the best output candidate. We evaluate DSPT5 and various
state-of-the-art large language models (LLMs) from multiple perspectives.
Results demonstrate that the SOTA LLMs does not provide satisfactory outcomes,
while the lightweight DSPT5 can achieve competitive results. To the best of our
knowledge, we are the first to build a benchmark dataset and solutions for
academic-to-general-audience text paraphrase dataset.

æè¦ï¼ç¾æçæå­ç°¡åææ¹å¯«è³æéä¸»è¦éä¸­å¨ä¸è¬é åçå¥å­ç´æå­ç¢çãéäºè³æééå¸¸å¨ä¸ä½¿ç¨é åç¥è­çææ³ä¸éç¼ãå¨æ¬æä¸­ï¼æåç¼å¸äºä¸åæ°çè³æé VTechAGPï¼å®æ¯ç¬¬ä¸åç±å­¸è¡è½åå¤§ç¾çæå­æ¹å¯«è³æéï¼åå« 4,938 åæä»¶ç´å¥çè«æåè«æå­¸è¡åä¸è¬åç¾æè¦å°ï¼ä¾èª 8 æå¤§å­¸ï¼æ°å¯«æ¼ 25 å¹´ä»¥ä¸ãæåéæåºäºä¸ç¨®æ°çåæè»æç¤ºçæèªè¨æ¨¡å DSPT5ãå°æ¼è¨ç·´ï¼æåå©ç¨å°æ¯çææå¤±å½æ¸ä¾å­¸ç¿åææç¤ºä¸­çééµå­åéãå°æ¼æ¨çï¼æåå¨èªç¾©åçµæ§å±¤ç´æ¡ç¨ç¾¤ç¾æ¡æ¨£è§£ç¢¼ç­ç¥ï¼é²ä¸æ­¥é¸ææä½³è¼¸åºåé¸ãæåå¾å¤åè§åº¦è©ä¼°äº DSPT5 ååç¨®æåé²çå¤§èªè¨æ¨¡å (LLM)ãçµæè¡¨æï¼SOTA LLM æ²ææä¾ä»¤äººæ»¿æççµæï¼èè¼éç´ç DSPT5 å¯ä»¥å¯¦ç¾æç«¶ç­åççµæãææåæç¥ï¼æåæ¯ç¬¬ä¸åçºå­¸è¡å°ä¸è¬åç¾çæå­æ¹å¯«è³æéæ§å»ºåºæºè³æéåè§£æ±ºæ¹æ¡çäººã

##### **When Does Classical Chinese Help? Quantifying Cross-Lingual Transfer in Hanja and Kanbun**
2411.04822v1 by Seyoung Song, Haneul Yoo, Jiho Jin, Kyunghyun Cho, Alice Oh

Historical and linguistic connections within the Sinosphere have led
researchers to use Classical Chinese resources for cross-lingual transfer when
processing historical documents from Korea and Japan. In this paper, we
question the assumption of cross-lingual transferability from Classical Chinese
to Hanja and Kanbun, the ancient written languages of Korea and Japan,
respectively. Our experiments across machine translation, named entity
recognition, and punctuation restoration tasks show minimal impact of Classical
Chinese datasets on language model performance for ancient Korean documents
written in Hanja, with performance differences within $\pm{}0.0068$ F1-score
for sequence labeling tasks and up to $+0.84$ BLEU score for translation. These
limitations persist consistently across various model sizes, architectures, and
domain-specific datasets. Our analysis reveals that the benefits of Classical
Chinese resources diminish rapidly as local language data increases for Hanja,
while showing substantial improvements only in extremely low-resource scenarios
for both Korean and Japanese historical documents. These mixed results
emphasize the need for careful empirical validation rather than assuming
benefits from indiscriminate cross-lingual transfer.

æè¦ï¼æ­·å²åèªè¨å¨æ¼¢èªåå§çè¯ç¹«ï¼å°è´ç ç©¶äººå¡å¨èçéååæ¥æ¬çæ­·å²æä»¶æï¼ä½¿ç¨å¤å¸ä¸­æè³æºé²è¡è·¨èªè¨è½ç§»ãå¨æ¬æä¸­ï¼æåè³ªçäºå¾å¤å¸ä¸­æå°éæåæ¥æçå¤ä»£æ¸é¢èªè¨éæåæ¼¢æï¼å¨è·¨èªè¨å¯è½ç§»æ§çåè¨­ãæåå¨æ©å¨ç¿»è­¯ãå½åå¯¦é«è¾¨è­åæ¨é»ç¬¦èéåä»»åä¸­çå¯¦é©ï¼é¡¯ç¤ºå¤å¸ä¸­æè³æéå°ç¨éæå¯«æçå¤ä»£éææä»¶çèªè¨æ¨¡åæè½å½±é¿å¾å°ï¼åºåæ¨ç±¤ä»»åçæè½å·®ç°å¨ $\pm{}0.0068$ F1 åæ¸å§ï¼èç¿»è­¯ç BLEU åæ¸æé«å¯é $+0.84$ãéäºéå¶å¨åç¨®æ¨¡åå¤§å°ãæ¶æ§åç¹å®é åè³æéä¸æçºå­å¨ãæåçåæé¡¯ç¤ºï¼é¨èéæçå¨å°èªè¨è³æå¢å ï¼å¤å¸ä¸­æè³æºçåªå¢è¿éä¸éï¼èåªå¨éæåæ¥ææ­·å²æä»¶çæ¥µä½è³æºå ´æ¯ä¸­ï¼æé¡¯ç¤ºåºé¡¯èçæ¹åãéäºæ··åççµæå¼·èª¿äºä»ç´°å¯¦è­é©è­çå¿è¦æ§ï¼èä¸æ¯åè¨­ä¸å åå¥çè·¨èªè¨è½ç§»çåªé»ã

##### **LuxBank: The First Universal Dependency Treebank for Luxembourgish**
2411.04813v1 by Alistair Plum, Caroline DÃ¶hmer, Emilia Milano, Anne-Marie Lutgen, Christoph Purschke

The Universal Dependencies (UD) project has significantly expanded linguistic
coverage across 161 languages, yet Luxembourgish, a West Germanic language
spoken by approximately 400,000 people, has remained absent until now. In this
paper, we introduce LuxBank, the first UD Treebank for Luxembourgish,
addressing the gap in syntactic annotation and analysis for this `low-research'
language. We establish formal guidelines for Luxembourgish language annotation,
providing the foundation for the first large-scale quantitative analysis of its
syntax. LuxBank serves not only as a resource for linguists and language
learners but also as a tool for developing spell checkers and grammar checkers,
organising existing text archives and even training large language models. By
incorporating Luxembourgish into the UD framework, we aim to enhance the
understanding of syntactic variation within West Germanic languages and offer a
model for documenting smaller, semi-standardised languages. This work positions
Luxembourgish as a valuable resource in the broader linguistic and NLP
communities, contributing to the study of languages with limited research and
resources.

æè¦ï¼éç¨ä¾è³´éä¿ (UD) å°æ¡å·²å¤§å¹æ´å± 161 ç¨®èªè¨çèªè¨æ¶µèç¯åï¼ä½ç§æ£®å ¡èªï¼ä¸ç¨®ç´æ 40 è¬äººä½¿ç¨çè¥¿æ¥è³æ¼èªï¼è³ä»ä»æªç´å¥å¶ä¸­ãå¨æ¬æä¸­ï¼æåå°ä»ç´¹ LuxBankï¼éæ¯ç§æ£®å ¡èªçç¬¬ä¸å UD æ¨¹åº«ï¼ç¨æ¼è§£æ±ºéç¨®ãä½ç ç©¶ãèªè¨å¨å¥æ³è¨»éååææ¹é¢çå·®è·ãæåçºç§æ£®å ¡èªè¨»éå»ºç«äºæ­£å¼æºåï¼çºå¶é¦æ¬¡å¤§è¦æ¨¡éååæå¥ å®åºç¤ãLuxBank ä¸åå¯ç¨æ¼èªè¨å­¸å®¶åèªè¨å­¸ç¿èï¼éå¯ç¨æ¼éç¼æ¼å¯«æª¢æ¥å¨åèªæ³æª¢æ¥å¨ï¼çµç¹ç¾ææå­æªæ¡ï¼çè³è¨ç·´å¤§åèªè¨æ¨¡åãééå°ç§æ£®å ¡èªç´å¥ UD æ¶æ§ï¼æåæ¨å¨å å¼·å°è¥¿æ¥è³æ¼èªå¥æ³è®åççè§£ï¼ä¸¦æä¾ä¸åç¨æ¼è¨éè¼å°çåæ¨æºåèªè¨çæ¨¡åãéé å·¥ä½å°ç§æ£®å ¡èªå®ä½çºæ´å»£æ³çèªè¨å­¸å NLP ç¤¾ç¾¤ä¸­çå¯¶è²´è³æºï¼æå©æ¼ç ç©¶ç ç©¶åè³æºæéçèªè¨ã

##### **Defending Deep Regression Models against Backdoor Attacks**
2411.04811v1 by Lingyu Du, Yupei Liu, Jinyuan Jia, Guohao Lan

Deep regression models are used in a wide variety of safety-critical
applications, but are vulnerable to backdoor attacks. Although many defenses
have been proposed for classification models, they are ineffective as they do
not consider the uniqueness of regression models. First, the outputs of
regression models are continuous values instead of discretized labels. Thus,
the potential infected target of a backdoored regression model has infinite
possibilities, which makes it impossible to be determined by existing defenses.
Second, the backdoor behavior of backdoored deep regression models is triggered
by the activation values of all the neurons in the feature space, which makes
it difficult to be detected and mitigated using existing defenses. To resolve
these problems, we propose DRMGuard, the first defense to identify if a deep
regression model in the image domain is backdoored or not. DRMGuard formulates
the optimization problem for reverse engineering based on the unique
output-space and feature-space characteristics of backdoored deep regression
models. We conduct extensive evaluations on two regression tasks and four
datasets. The results show that DRMGuard can consistently defend against
various backdoor attacks. We also generalize four state-of-the-art defenses
designed for classifiers to regression models, and compare DRMGuard with them.
The results show that DRMGuard significantly outperforms all those defenses.

æè¦ï¼æ·±åº¦è¿´æ­¸æ¨¡åè¢«å»£æ³æç¨æ¼åç¨®å®å¨ééµæç¨ç¨å¼ä¸­ï¼ä½å®¹æåå°å¾éæ»æãåç®¡å·²æåºè¨±å¤éå°åé¡æ¨¡åçé²ç¦¦æªæ½ï¼ä½å®åç¡æï¼å çºå®åæ²æèæ®è¿´æ­¸æ¨¡åçç¨ç¹æ§ãé¦åï¼è¿´æ­¸æ¨¡åçè¼¸åºæ¯é£çºå¼ï¼èä¸æ¯é¢æ£æ¨ç±¤ãå æ­¤ï¼å¾éè¿´æ­¸æ¨¡åæ½å¨çåææç®æ¨å·æç¡éå¯è½æ§ï¼éä½¿å¾ç¾æé²ç¦¦æªæ½ç¡æ³ç¢ºå®ãå¶æ¬¡ï¼å¾éæ·±åº¦è¿´æ­¸æ¨¡åçå¾éè¡çºæ¯ç±ç¹å¾µç©ºéä¸­ææç¥ç¶åçæ¿æ´»å¼è§¸ç¼çï¼éä½¿å¾ä½¿ç¨ç¾æé²ç¦¦æªæ½é£ä»¥æª¢æ¸¬åæ¸è¼ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº DRMGuardï¼éæ¯ç¬¬ä¸åç¨æ¼è­å¥å½±ååä¸­çæ·±åº¦è¿´æ­¸æ¨¡åæ¯å¦è¢«å¾éåçé²ç¦¦æªæ½ãDRMGuard æ ¹æå¾éæ·±åº¦è¿´æ­¸æ¨¡åçç¨ç¹è¼¸åºç©ºéåç¹å¾µç©ºéç¹å¾µä¾å¶å®éåå·¥ç¨çæä½³ååé¡ãæåå°å©åè¿´æ­¸ä»»ååååè³æéé²è¡äºå»£æ³çè©ä¼°ãçµæè¡¨æï¼DRMGuard å¯ä»¥æçºæµç¦¦åç¨®å¾éæ»æãæåéå°åç¨®éå°åé¡å¨çæåé²é²ç¦¦æªæ½æ¨å»£å°è¿´æ­¸æ¨¡åï¼ä¸¦å° DRMGuard èå®åé²è¡æ¯è¼ãçµæè¡¨æï¼DRMGuard æé¡¯åªæ¼ææéäºé²ç¦¦æªæ½ã

##### **Kwai-STaR: Transform LLMs into State-Transition Reasoners**
2411.04799v1 by Xingyu Lu, Yuhang Hu, Changyi Liu, Tianke Zhang, Zhenyu Yang, Zhixiang Ding, Shengsheng Qian, Meng Du, Ruiwen Kang, Kaiyu Tang, Fan Yang, Tingting Gao, Di Zhang, Hai-Tao Zheng, Bin Wen

Mathematical reasoning presents a significant challenge to the cognitive
capabilities of LLMs. Various methods have been proposed to enhance the
mathematical ability of LLMs. However, few recognize the value of state
transition for LLM reasoning. In this work, we define mathematical
problem-solving as a process of transiting from an initial unsolved state to
the final resolved state, and propose Kwai-STaR framework, which transforms
LLMs into State-Transition Reasoners to improve their intuitive reasoning
capabilities. Our approach comprises three main steps: (1) Define the state
space tailored to the mathematical reasoning. (2) Generate state-transition
data based on the state space. (3) Convert original LLMs into State-Transition
Reasoners via a curricular training strategy. Our experiments validate the
effectiveness of Kwai-STaR in enhancing mathematical reasoning: After training
on the small-scale Kwai-STaR dataset, general LLMs, including Mistral-7B and
LLaMA-3, achieve considerable performance gain on the GSM8K and GSM-Hard
dataset. Additionally, the state transition-based design endows Kwai-STaR with
remarkable training and inference efficiency. Further experiments are underway
to establish the generality of Kwai-STaR.

æè¦ï¼æ¸å­¸æ¨çå° LLM çèªç¥è½åæåºéå¤§ææ°ãå·²ç¶æåºåç¨®æ¹æ³ä¾å¢å¼· LLM çæ¸å­¸è½åãç¶èï¼å¾å°æäººèªè­å°çæè½æå° LLM æ¨ççå¹å¼ãå¨éé å·¥ä½ä¸­ï¼æåå°æ¸å­¸åé¡æ±è§£å®ç¾©çºå¾åå§æªè§£æ±ºçæè½æå°æçµå·²è§£æ±ºçæçéç¨ï¼ä¸¦æåº Kwai-STaR æ¡æ¶ï¼å®å° LLM è½æçºçæè½ææ¨çå¨ä»¥æé«å¶ç´è¦ºæ¨çè½åãæåçåæ³åå«ä¸åä¸»è¦æ­¥é©ï¼(1) å®ç¾©é©åæ¸å­¸æ¨çççæç©ºéã(2) åºæ¼çæç©ºéçæçæè½ææ¸æã(3) ééèª²ç¨è¨ç·´ç­ç¥å°åå§ LLM è½æçºçæè½ææ¨çå¨ãæåçå¯¦é©é©è­äº Kwai-STaR å¨å¢å¼·æ¸å­¸æ¨çæ¹é¢çæææ§ï¼å¨å°è¦æ¨¡ Kwai-STaR æ¸æéä¸è¨ç·´å¾ï¼åæ¬ Mistral-7B å LLaMA-3 å¨å§çéç¨ LLM å¨ GSM8K å GSM-Hard æ¸æéä¸åå¾äºé¡¯èçæ§è½æåãæ­¤å¤ï¼åºæ¼çæè½æçè¨­è¨è³¦äº Kwai-STaR åè¶çè¨ç·´åæ¨çæçãé²ä¸æ­¥çå¯¦é©æ­£å¨é²è¡ä¸­ï¼ä»¥å»ºç« Kwai-STaR çæ®éæ§ã

##### **MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation**
2411.04796v1 by Sayan Paul, Ruddra dev Roychoudhury, Brojeshwar Bhowmick

Visual odometry (VO) is essential for enabling accurate point-goal navigation
of embodied agents in indoor environments where GPS and compass sensors are
unreliable and inaccurate. However, traditional VO methods face challenges in
wide-baseline scenarios, where fast robot motions and low frames per second
(FPS) during inference hinder their performance, leading to drift and
catastrophic failures in point-goal navigation. Recent deep-learned VO methods
show robust performance but suffer from sample inefficiency during training;
hence, they require huge datasets and compute resources. So, we propose a
robust and sample-efficient VO pipeline based on motion priors available while
an agent is navigating an environment. It consists of a training-free
action-prior based geometric VO module that estimates a coarse relative pose
which is further consumed as a motion prior by a deep-learned VO model, which
finally produces a fine relative pose to be used by the navigation policy. This
strategy helps our pipeline achieve up to 2x sample efficiency during training
and demonstrates superior accuracy and robustness in point-goal navigation
tasks compared to state-of-the-art VO method(s). Realistic indoor environments
of the Gibson dataset is used in the AI-Habitat simulator to evaluate the
proposed approach using navigation metrics (like success/SPL) and pose metrics
(like RPE/ATE). We hope this method further opens a direction of work where
motion priors from various sources can be utilized to improve VO estimates and
achieve better results in embodied navigation tasks.

æè¦ï¼è¦è¦ºéç¨è¨ (VO) å°æ¼å¨ GPS åæåéææ¸¬å¨ä¸å¯é ä¸ä¸æºç¢ºçå®¤å§ç°å¢ä¸­ï¼è®å·èº«ä»£çå·è¡ç²¾ç¢ºçé»ç®æ¨å°èªè³ééè¦ãç¶èï¼å³çµ±ç VO æ¹æ³å¨å»£åºç·å ´æ¯ä¸­æéå°ææ°ï¼å¶ä¸­æ©å¨äººçå¿«éç§»ååå¨æ¨è«æéæ¯ç§ä½å¹æ¸ (FPS) æé»ç¤å¶æè½ï¼å°è´é»ç®æ¨å°èªä¸­çæ¼ç§»åç½é£æ§æéãæè¿æ·±åº¦å­¸ç¿ç VO æ¹æ³é¡¯ç¤ºåºç©©å¥çæè½ï¼ä½å¨è¨ç·´æéæéå°æ¨£æ¬æçä½ä¸ï¼å æ­¤ï¼å®åéè¦å¤§éçè³æéåéç®è³æºãå æ­¤ï¼æåæåºä¸åç©©å¥ä¸æ¨£æ¬æçé«ç VO ç®¡ç·ï¼åºæ¼å¨ä»£çå°èªç°å¢æå¯ç¨çéååé©ãå®åå«ä¸ååè¨ç·´çåºæ¼åä½åé©çå¹¾ä½ VO æ¨¡çµï¼ç¨æ¼ä¼°è¨ç²ç¥çç¸å°ä½å§¿ï¼èå¾ç±æ·±åº¦å­¸ç¿ç VO æ¨¡åå°å¶ç¨ä½éååé©ï¼æçµç¢çä¸åç²¾ç´°çç¸å°ä½å§¿ï¼ä¾å°èªç­ç¥ä½¿ç¨ãæ­¤ç­ç¥æå©æ¼æåçç®¡ç·å¨è¨ç·´æééå°é«é 2 åçæ¨£æ¬æçï¼ä¸¦å¨é»ç®æ¨å°èªä»»åä¸­å±ç¾åºæ¯ç¾æ VO æ¹æ³æ´å¥½çæºç¢ºåº¦åç©©å¥æ§ãGibson è³æéçé¼çå®¤å§ç°å¢ç¨æ¼ AI-Habitat æ¨¡æ¬å¨ï¼ä»¥ä½¿ç¨å°èªææ¨ï¼ä¾å¦æå/SPLï¼åä½å§¿ææ¨ï¼ä¾å¦ RPE/ATEï¼è©ä¼°ææåºçæ¹æ³ãæåå¸ææ­¤æ¹æ³é²ä¸æ­¥éåä¸åå·¥ä½æ¹åï¼å¶ä¸­å¯ä»¥å©ç¨ä¾èªåç¨®ä¾æºçéååé©ä¾æ¹å VO ä¼°è¨ï¼ä¸¦å¨å·èº«å°èªä»»åä¸­åå¾æ´å¥½ççµæã

##### **AlignXIE: Improving Multilingual Information Extraction by Cross-Lingual Alignment**
2411.04794v1 by Yuxin Zuo, Wenxuan Jiang, Wenxuan Liu, Zixuan Li, Long Bai, Hanbin Wang, Yutao Zeng, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng

Empirical evidence suggests that LLMs exhibit spontaneous cross-lingual
alignment. Our findings suggest that although LLMs also demonstrate promising
cross-lingual alignment in Information Extraction, there remains significant
imbalance across languages, revealing an underlying deficiency in the IE
alignment. To address this issue, we propose AlignXIE, a powerful code-based
LLM that significantly enhances cross-lingual IE alignment through two
strategies. Firstly, AlignXIE formulates IE across different languages,
especially non-English ones, as code generation tasks, standardizing the
representation of various schemas using Python classes to ensure consistency of
the same ontology in different languages and align the schema. Secondly, it
incorporates an IE cross-lingual alignment phase through a translated instance
prediction task proposed in this paper to align the extraction process,
utilizing ParallelNER, an IE bilingual parallel dataset with 257,190 samples,
generated by our proposed LLM-based automatic pipeline for IE parallel data
construction, with manual annotation to ensure quality. Ultimately, we obtain
AlignXIE through multilingual IE instruction tuning. Although without training
in 9 unseen languages, AlignXIE surpasses ChatGPT by $30.17\%$ and SoTA by
$20.03\%$, thereby demonstrating superior cross-lingual IE capabilities.
Comprehensive evaluations on 63 IE benchmarks in Chinese and English under
various settings, demonstrate that AlignXIE significantly enhances
cross-lingual and multilingual IE through boosting the IE alignment.

æè¦ï¼ç¶é©è­æè¡¨æï¼LLM è¡¨ç¾åºèªç¼çè·¨èªè¨å°é½ãæåçç ç©¶çµæè¡¨æï¼åç®¡ LLM ä¹å¨è³è¨æ·åä¸­å±ç¤ºåºæå¸æçè·¨èªè¨å°é½ï¼ä½ä¸åèªè¨ä¹éä»ç¶å­å¨é¡¯èçä¸å¹³è¡¡ï¼éæ­ç¤ºäº IE å°é½ä¸­çæ½å¨ç¼ºé·ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº AlignXIEï¼ä¸ç¨®å¼·å¤§çåºæ¼ç¨å¼ç¢¼ç LLMï¼å®ééå©ç¨®ç­ç¥é¡¯èå¢å¼·äºè·¨èªè¨ IE å°é½ãé¦åï¼AlignXIE å°ä¸åèªè¨ï¼ç¹å¥æ¯éè±èªèªè¨ï¼ä¸­ç IE å¶å®çºç¨å¼ç¢¼çæä»»åï¼ä½¿ç¨ Python é¡æ¨æºååç¨®æ¨¡å¼çè¡¨ç¤ºï¼ä»¥ç¢ºä¿ä¸åèªè¨ä¸­ç¸åæ¬ä½çä¸è´æ§ä¸¦å°é½æ¨¡å¼ãå¶æ¬¡ï¼å®ééæ¬ææåºçç¿»è­¯å¯¦ä¾é æ¸¬ä»»åï¼çµåäº IE è·¨èªè¨å°é½éæ®µï¼ä»¥å°é½æ·åéç¨ï¼å©ç¨ ParallelNERï¼ä¸åç±æåæåºçåºæ¼ LLM çèªåç®¡éçæçåå« 257,190 åç¯ä¾ç IE éèªå¹³è¡è³æéï¼ä¸¦ééäººå·¥è¨»è§£ç¢ºä¿åè³ªãæçµï¼æåééå¤èªè¨ IE æä»¤èª¿æ´ç²å¾ AlignXIEãåç®¡æ²æå¨ 9 ç¨®æªè¦éçèªè¨ä¸­é²è¡è¨ç·´ï¼ä½ AlignXIE è¶è¶äº ChatGPT 30.17%ï¼è¶è¶äº SoTA 20.03%ï¼å¾èå±ç¤ºäºåè¶çè·¨èªè¨ IE è½åãå¨åç¨®è¨­å®ä¸å°ä¸­æåè±æä¸­ç 63 å IE åºæºé²è¡çç¶åè©ä¼°è¡¨æï¼AlignXIE ééæå IE å°é½ï¼é¡¯èå¢å¼·äºè·¨èªè¨åå¤èªè¨ IEã

##### **Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research**
2411.04788v1 by Xuewen Han, Neng Wang, Shangkun Che, Hongyang Yang, Kunpeng Zhang, Sean Xin Xu

In recent years, the application of generative artificial intelligence
(GenAI) in financial analysis and investment decision-making has gained
significant attention. However, most existing approaches rely on single-agent
systems, which fail to fully utilize the collaborative potential of multiple AI
agents. In this paper, we propose a novel multi-agent collaboration system
designed to enhance decision-making in financial investment research. The
system incorporates agent groups with both configurable group sizes and
collaboration structures to leverage the strengths of each agent group type. By
utilizing a sub-optimal combination strategy, the system dynamically adapts to
varying market conditions and investment scenarios, optimizing performance
across different tasks. We focus on three sub-tasks: fundamentals, market
sentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30
companies listed on the Dow Jones Index. Our findings reveal significant
performance variations based on the configurations of AI agents for different
tasks. The results demonstrate that our multi-agent collaboration system
outperforms traditional single-agent models, offering improved accuracy,
efficiency, and adaptability in complex financial environments. This study
highlights the potential of multi-agent systems in transforming financial
analysis and investment decision-making by integrating diverse analytical
perspectives.

æè¦ï¼è¿å¹´ä¾ï¼çæå¼äººå·¥æºæ§ (GenAI) å¨è²¡ååæåæè³æ±ºç­ä¸­çæç¨ååçç®ãç¶èï¼ç¾æçæ¹æ³å¤§å¤ä¾è³´æ¼å®ä¸ä»£çç³»çµ±ï¼ç¡æ³ååå©ç¨å¤å AI ä»£ççåä½æ½åãå¨æ¬æä¸­ï¼æåæåºä¸åæ°ç©çå¤ä»£çåä½ç³»çµ±ï¼æ¨å¨å¢å¼·è²¡åæè³ç ç©¶ä¸­çæ±ºç­å¶å®ãè©²ç³»çµ±çµåäºå·æå¯éç½®ç¾¤çµè¦æ¨¡ååä½çµæ§çä»£çç¾¤çµï¼ä»¥å©ç¨æ¯åä»£çç¾¤çµé¡åçåªå¢ãééä½¿ç¨æ¬¡åªçµåç­ç¥ï¼è©²ç³»çµ±å¯åæé©æä¸åçå¸å ´æ¢ä»¶åæè³æå¢ï¼åªåä¸åä»»åçç¸¾æãæåå°æ³¨æ¼ä¸é å­ä»»åï¼åºæ¬é¢ãå¸å ´æç·åé¢¨éªåæï¼æ¹æ³æ¯åæéçææ¸ä¸­ 30 å®¶å¬å¸ç 2023 å¹´ SEC 10-K è¡¨æ ¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼æ ¹æä¸åä»»åç AI ä»£çéç½®ï¼ç¸¾æå·®ç°é¡¯èãçµæè¡¨æï¼æåçå¤ä»£çåä½ç³»çµ±åªæ¼å³çµ±çå®ä¸ä»£çæ¨¡åï¼å¨è¤éçè²¡åç°å¢ä¸­æä¾æ´é«çæºç¢ºæ§ãæçåé©ææ§ãæ¬ç ç©¶å¼·èª¿äºå¤ä»£çç³»çµ±å¨è½è®è²¡ååæåæè³æ±ºç­æ¹é¢çæ½åï¼æ¹æ³æ¯æ´åä¸åçåæè§é»ã

##### **A study of Vietnamese readability assessing through semantic and statistical features**
2411.04756v1 by Hung Tuan Le, Long Truong To, Manh Trong Nguyen, Quyen Nguyen, Trong-Hop Do

Determining the difficulty of a text involves assessing various textual
features that may impact the reader's text comprehension, yet current research
in Vietnamese has only focused on statistical features. This paper introduces a
new approach that integrates statistical and semantic approaches to assessing
text readability. Our research utilized three distinct datasets: the Vietnamese
Text Readability Dataset (ViRead), OneStopEnglish, and RACE, with the latter
two translated into Vietnamese. Advanced semantic analysis methods were
employed for the semantic aspect using state-of-the-art language models such as
PhoBERT, ViDeBERTa, and ViBERT. In addition, statistical methods were
incorporated to extract syntactic and lexical features of the text. We
conducted experiments using various machine learning models, including Support
Vector Machine (SVM), Random Forest, and Extra Trees and evaluated their
performance using accuracy and F1 score metrics. Our results indicate that a
joint approach that combines semantic and statistical features significantly
enhances the accuracy of readability classification compared to using each
method in isolation. The current study emphasizes the importance of considering
both statistical and semantic aspects for a more accurate assessment of text
difficulty in Vietnamese. This contribution to the field provides insights into
the adaptability of advanced language models in the context of Vietnamese text
readability. It lays the groundwork for future research in this area.

æè¦ï¼<paragraph>è©éææ¬é£åº¦æ¶åè©ä¼°åç¨®å¯è½å½±é¿è®èææ¬çè§£çææ¬ç¹å¾µï¼ç¶èç®åè¶åèªçç ç©¶åéæ³¨æ¼çµ±è¨ç¹å¾µãæ¬æä»ç´¹ä¸ç¨®æ°çæ¹æ³ï¼å°çµ±è¨æ¹æ³åèªç¾©æ¹æ³æ´åèµ·ä¾è©ä¼°ææ¬å¯è®æ§ãæåçç ç©¶å©ç¨äºä¸åä¸åçè³æéï¼è¶åèªææ¬å¯è®æ§è³æé (ViRead)ãOneStopEnglish å RACEï¼å¾å©åå·²ç¿»è­¯æè¶åèªãä½¿ç¨æåé²çèªè¨æ¨¡åï¼ä¾å¦ PhoBERTãViDeBERTa å ViBERTï¼å°èªç¾©æ¹é¢æ¡ç¨äºåé²çèªç¾©åææ¹æ³ãæ­¤å¤ï¼éç´å¥äºçµ±è¨æ¹æ³ä¾æåææ¬çå¥æ³åè©å½ç¹å¾µãæåä½¿ç¨åç¨®æ©å¨å­¸ç¿æ¨¡åé²è¡äºå¯¦é©ï¼åæ¬æ¯æåéæ© (SVM)ãé¨æ©æ£®æåæ¥µç«¯æ¨¹ï¼ä¸¦ä½¿ç¨æºç¢ºåº¦å F1 åæ¸ææ¨è©ä¼°äºå®åçæ§è½ãæåççµæè¡¨æï¼èå­¤ç«å°ä½¿ç¨æ¯ç¨®æ¹æ³ç¸æ¯ï¼çµåèªç¾©åçµ±è¨ç¹å¾µçè¯åæ¹æ³é¡¯èæé«äºå¯è®æ§åé¡çæºç¢ºåº¦ãç®åçç ç©¶å¼·èª¿äºå¨è¶åèªä¸­æ´æºç¢ºè©ä¼°ææ¬é£åº¦æèæ®çµ±è¨åèªç¾©æ¹é¢çåæéè¦æ§ãå°è©²é åçéé è²¢ç»æä¾äºå°è¶åèªææ¬å¯è®æ§èæ¯ä¸åé²èªè¨æ¨¡åçé©ææ§çè¦è§£ãå®çºè©²é åçæªä¾ç ç©¶å¥ å®äºåºç¤ã</paragraph>

##### **RetrieveGPT: Merging Prompts and Mathematical Models for Enhanced Code-Mixed Information Retrieval**
2411.04752v1 by Aniket Deroy, Subhankar Maity

Code-mixing, the integration of lexical and grammatical elements from
multiple languages within a single sentence, is a widespread linguistic
phenomenon, particularly prevalent in multilingual societies. In India, social
media users frequently engage in code-mixed conversations using the Roman
script, especially among migrant communities who form online groups to share
relevant local information. This paper focuses on the challenges of extracting
relevant information from code-mixed conversations, specifically within Roman
transliterated Bengali mixed with English. This study presents a novel approach
to address these challenges by developing a mechanism to automatically identify
the most relevant answers from code-mixed conversations. We have experimented
with a dataset comprising of queries and documents from Facebook, and Query
Relevance files (QRels) to aid in this task. Our results demonstrate the
effectiveness of our approach in extracting pertinent information from complex,
code-mixed digital conversations, contributing to the broader field of natural
language processing in multilingual and informal text environments. We use
GPT-3.5 Turbo via prompting alongwith using the sequential nature of relevant
documents to frame a mathematical model which helps to detect relevant
documents corresponding to a query.

æè¦ï¼ä»£ç¢¼æ··åï¼å¨å®ä¸å¥å­ä¸­æ´åä¾èªå¤ç¨®èªè¨çè©å½åèªæ³åç´ ï¼æ¯ä¸ç¨®å»£æ³çèªè¨ç¾è±¡ï¼ç¹å¥æ®éå­å¨æ¼å¤èªè¨ç¤¾æä¸­ãå¨å°åº¦ï¼ç¤¾äº¤åªé«ä½¿ç¨èç¶å¸¸ä½¿ç¨ç¾é¦¬å­æ¯é²è¡ä»£ç¢¼æ··åå°è©±ï¼å°¤å¶æ¯å¨çµæç·ä¸ç¾¤çµä»¥åäº«ç¸éç¶å°è³è¨çç§»æ°ç¤¾ç¾¤ä¸­ãæ¬æéé»æ¢è¨å¾ä»£ç¢¼æ··åå°è©±ä¸­æ·åç¸éè³è¨çææ°ï¼ç¹å¥æ¯å¨èè±ææ··åçç¾é¦¬è½å¯«å­å ææä¸­ãæ¬ç ç©¶æåºäºä¸ç¨®æ°ç©çæ¹æ³ä¾è§£æ±ºéäºææ°ï¼æ¹æ³æ¯éç¼ä¸ç¨®æ©å¶ä¾èªåè­å¥ä»£ç¢¼æ··åå°è©±ä¸­æç¸éçç­æ¡ãæåå·²ç¶éå°åå«ä¾èª Facebook çæ¥è©¢åæä»¶ä»¥åæ¥è©¢ç¸éæ§æªæ¡ (QRels) çè³æéé²è¡å¯¦é©ï¼ä»¥åå©éé ä»»åãæåççµæè­æäºæåçæ¹æ³å¨å¾è¤éçä»£ç¢¼æ··åæ¸ä½å°è©±ä¸­æ·åç¸éè³è¨çæææ§ï¼æå©æ¼å¤èªè¨åéæ­£å¼æå­ç°å¢ä¸­çèªç¶èªè¨èçæ´å»£æ³çé åãæåééæç¤ºä½¿ç¨ GPT-3.5 Turboï¼ä¸¦å©ç¨ç¸éæä»¶é åºæ§è³ªä¾å»ºæ§ä¸åæ¸å­¸æ¨¡åï¼æå©æ¼åµæ¸¬èæ¥è©¢ç¸æçç¸éæä»¶ã

##### **Equivariant Graph Attention Networks with Structural Motifs for Predicting Cell Line-Specific Synergistic Drug Combinations**
2411.04747v1 by Zachary Schwehr

Cancer is the second leading cause of death, with chemotherapy as one of the
primary forms of treatment. As a result, researchers are turning to drug
combination therapy to decrease drug resistance and increase efficacy. Current
methods of drug combination screening, such as in vivo and in vitro, are
inefficient due to stark time and monetary costs. In silico methods have become
increasingly important for screening drugs, but current methods are inaccurate
and generalize poorly to unseen anticancer drugs. In this paper, I employ a
geometric deep-learning model utilizing a graph attention network that is
equivariant to 3D rotations, translations, and reflections with structural
motifs. Additionally, the gene expression of cancer cell lines is utilized to
classify synergistic drug combinations specific to each cell line. I compared
the proposed geometric deep learning framework to current state-of-the-art
(SOTA) methods, and the proposed model architecture achieved greater
performance on all 12 benchmark tasks performed on the DrugComb dataset.
Specifically, the proposed framework outperformed other SOTA methods by an
accuracy difference greater than 28%. Based on these results, I believe that
the equivariant graph attention network's capability of learning geometric data
accounts for the large performance improvements. The model's ability to
generalize to foreign drugs is thought to be due to the structural motifs
providing a better representation of the molecule. Overall, I believe that the
proposed equivariant geometric deep learning framework serves as an effective
tool for virtually screening anticancer drug combinations for further
validation in a wet lab environment. The code for this work is made available
online at: https://github.com/WeToTheMoon/EGAT_DrugSynergy.

æè¦ï¼ççæ¯ç¬¬äºå¤§æ­»äº¡åå ï¼åçæ¯ä¸»è¦çæ²»çæ¹å¼ä¹ä¸ãå æ­¤ï¼ç ç©¶äººåè½¬åè¯ç©èåçæ³æ¥éä½è¯ç©ææ§åæé«çæãå½åçè¯ç©ç»åç­éæ¹æ³ï¼å¦ä½ååä½å¤ï¼ç±äºæ¶é´åéé±ææ¬é«æèæçä½ä¸ãè®¡ç®æºæ¨¡ææ¹æ³å¯¹äºè¯ç©ç­éåå¾è¶æ¥è¶éè¦ï¼ä½å½åçæ¹æ³ä¸åç¡®ï¼å¹¶ä¸å¯¹æªè§çæçè¯ç©çæ¦æ¬æ§è¾å·®ãå¨æ¬æä¸­ï¼æéç¨äºä¸ä¸ªå ä½æ·±åº¦å­¦ä¹ æ¨¡åï¼è¯¥æ¨¡åå©ç¨äºä¸ä¸ªå¾æ³¨æåç½ç»ï¼è¯¥ç½ç»å¯¹ 3D æè½¬ãå¹³ç§»åå·æç»æåºåºçåå°æ¯ç­åçãæ­¤å¤ï¼å©ç¨çç»èç³»çåºå è¡¨è¾¾å¯¹ç¹å®äºæ¯ä¸ªç»èç³»çååè¯ç©ç»åè¿è¡åç±»ãæå°æåºçå ä½æ·±åº¦å­¦ä¹ æ¡æ¶ä¸å½åæåè¿ (SOTA) æ¹æ³è¿è¡äºæ¯è¾ï¼å¹¶ä¸æåºçæ¨¡åæ¶æå¨ DrugComb æ°æ®éä¸æ§è¡çææ 12 é¡¹åºåä»»å¡ä¸é½åå¾äºæ´å¥½çæ§è½ãå·ä½æ¥è¯´ï¼æåºçæ¡æ¶æ¯å¶ä» SOTA æ¹æ³çåç¡®æ§å·®å¼è¶è¿ 28%ãåºäºè¿äºç»æï¼æç¸ä¿¡ç­åå¾æ³¨æåç½ç»å­¦ä¹ å ä½æ°æ®çè½åå¯ä»¥è§£éå·¨å¤§çæ§è½æåãè¯¥æ¨¡åå¯¹å¤å½è¯ç©è¿è¡æ¦æ¬çè½åè¢«è®¤ä¸ºæ¯ç±äºç»æåºåºæä¾äºåå­çæ´å¥½è¡¨ç¤ºãæ»ä½èè¨ï¼æç¸ä¿¡æåºçç­åå ä½æ·±åº¦å­¦ä¹ æ¡æ¶ä½ä¸ºä¸ç§ææçå·¥å·ï¼ç¨äºèæç­éæçè¯ç©ç»åï¼ä»¥ä¾¿å¨æ¹¿å®éªå®¤ç¯å¢ä¸­è¿ä¸æ­¥éªè¯ãè¿é¡¹å·¥ä½çä»£ç å¨çº¿æä¾ï¼https://github.com/WeToTheMoon/EGAT_DrugSynergyã

##### **BhasaAnuvaad: A Speech Translation Dataset for 14 Indian Languages**
2411.04699v1 by Sparsh Jain, Ashwin Sankar, Devilal Choudhary, Dhairya Suman, Nikhil Narasimhan, Mohammed Safi Ur Rahman Khan, Anoop Kunchukuttan, Mitesh M Khapra, Raj Dabre

Automatic Speech Translation (AST) datasets for Indian languages remain
critically scarce, with public resources covering fewer than 10 of the 22
official languages. This scarcity has resulted in AST systems for Indian
languages lagging far behind those available for high-resource languages like
English. In this paper, we first evaluate the performance of widely-used AST
systems on Indian languages, identifying notable performance gaps and
challenges. Our findings show that while these systems perform adequately on
read speech, they struggle significantly with spontaneous speech, including
disfluencies like pauses and hesitations. Additionally, there is a striking
absence of systems capable of accurately translating colloquial and informal
language, a key aspect of everyday communication. To this end, we introduce
BhasaAnuvaad, the largest publicly available dataset for AST involving 14
scheduled Indian languages spanning over 44,400 hours and 17M text segments.
BhasaAnuvaad contains data for English speech to Indic text, as well as Indic
speech to English text. This dataset comprises three key categories: (1)
Curated datasets from existing resources, (2) Large-scale web mining, and (3)
Synthetic data generation. By offering this diverse and expansive dataset, we
aim to bridge the resource gap and promote advancements in AST for low-resource
Indian languages, especially in handling spontaneous and informal speech
patterns.

æè¦ï¼å°åº¦èªè¨çèªåèªé³ç¿»è­¯ (AST) è³æéä»ç¶å´éç¨ç¼ºï¼å¬éè³æºæ¶µèç 22 ç¨®å®æ¹èªè¨ä¸å° 10 ç¨®ãéç¨®ç¨ç¼ºæ§å°è´å°åº¦èªè¨ç AST ç³»çµ±é é è½å¾æ¼è±èªç­é«è³æºèªè¨çç³»çµ±ãå¨æ¬æä¸­ï¼æåé¦åè©ä¼°å»£æ³ä½¿ç¨ç AST ç³»çµ±å¨å°åº¦èªè¨ä¸çæè½ï¼æ¾åºé¡¯èçæè½å·®è·åææ°ãæåçç ç©¶çµæé¡¯ç¤ºï¼éç¶éäºç³»çµ±å¨æè®èªé³ä¸è¡¨ç¾å¾å¾å¥½ï¼ä½å®åå¨èªç¼èªé³æ¹é¢å»æå¾å¤§çå°é£ï¼åæ¬åé åç¶è±«ç­ä¸æµæ¢çç¾è±¡ãæ­¤å¤ï¼é¡¯èç¼ºä¹è½å¤ æºç¢ºç¿»è­¯å£èªåéæ­£å¼èªè¨çç³»çµ±ï¼èéæ¯æ¥å¸¸æºéçä¸åééµæ¹é¢ãçºæ­¤ï¼æåæ¨åºäº BhasaAnuvaadï¼éæ¯æå¤§çå¬é AST è³æéï¼æ¶å 14 ç¨®å°åº¦æç¨èªè¨ï¼è·¨è¶ 44,400 å°æå 1700 è¬åæå­åå¡ãBhasaAnuvaad åå«è±èªèªé³è½æçºå°åº¦æå­ï¼ä»¥åå°åº¦èªé³è½æçºè±èªæå­çè³æãæ­¤è³æéåå«ä¸åä¸»è¦é¡å¥ï¼(1) ä¾èªç¾æè³æºçç­å±è³æéï¼(2) å¤§è¦æ¨¡ç¶²è·¯ææï¼ä»¥å (3) åæè³æç¢çãééæä¾éåå¤åä¸å»£æ³çè³æéï¼æåæ¨å¨å½è£è³æºå·®è·ï¼ä¸¦ä¿é²ä½è³æºå°åº¦èªè¨ AST çé²æ­¥ï¼ç¹å¥æ¯å¨èçèªç¼åéæ­£å¼çèªé³æ¨¡å¼æ¹é¢ã

##### **The Multiple Dimensions of Spuriousness in Machine Learning**
2411.04696v1 by Samuel J. Bell, Skyler Wang

Learning correlations from data forms the foundation of today's machine
learning (ML) and artificial intelligence (AI) research. While such an approach
enables the automatic discovery of patterned relationships within big data
corpora, it is susceptible to failure modes when unintended correlations are
captured. This vulnerability has expanded interest in interrogating
spuriousness, often critiqued as an impediment to model performance, fairness,
and robustness. In this article, we trace deviations from the conventional
definition of statistical spuriousness-which denotes a non-causal observation
arising from either coincidence or confounding variables-to articulate how ML
researchers make sense of spuriousness in practice. Drawing on a broad survey
of ML literature, we conceptualize the "multiple dimensions of spuriousness,"
encompassing: relevance ("Models should only use correlations that are relevant
to the task."), generalizability ("Models should only use correlations that
generalize to unseen data"), human-likeness ("Models should only use
correlations that a human would use to perform the same task"), and harmfulness
("Models should only use correlations that are not harmful"). These dimensions
demonstrate that ML spuriousness goes beyond the causal/non-causal dichotomy
and that the disparate interpretative paths researchers choose could
meaningfully influence the trajectory of ML development. By underscoring how a
fundamental problem in ML is contingently negotiated in research contexts, we
contribute to ongoing debates about responsible practices in AI development.

æè¦ï¼å¾è³æä¸­å­¸ç¿éè¯æ§ï¼æ¯ç¶ä»æ©å¨å­¸ç¿ (ML) åäººå·¥æºæ§ (AI) ç ç©¶çåºç¤ãéç¶éç¨®æ¹æ³è½èªåç¼ç¾å¤§æ¸æèªæåº«ä¸­æ¨¡å¼åçéä¿ï¼ä½ç¶æ·åå°éé æçéè¯æ§æï¼å®å®¹æç¼çæéæ¨¡å¼ãéç¨®èå¼±æ§æ´å¤§äºå°å¯©æ¥èåæ§çèè¶£ï¼èåæ§éå¸¸è¢«æ¹è©çºæ¨¡åæè½ãå¬å¹³æ§åç©©å¥æ§çéç¤ãå¨æ¬æä¸­ï¼æåè¿½æº¯çµ±è¨èåæ§çå³çµ±å®ç¾©çåå·®ï¼è©²å®ç¾©è¡¨ç¤ºéå æè§å¯æºèªå·§åææ··æ·è®æ¸ï¼ä»¥é¡æ ML ç ç©¶äººå¡å¦ä½å¯¦éçè§£èåæ§ãæ ¹æ ML æç»çå»£æ³èª¿æ¥ï¼æåæ¦å¿µåäºãèåæ§çå¤éé¢åãï¼åæ¬ï¼ç¸éæ§ï¼ãæ¨¡åæåä½¿ç¨èä»»åç¸éçéè¯æ§ããï¼ãå¯æ¦åæ§ï¼ãæ¨¡åæåä½¿ç¨å¯æ¦åå°æªè¦æ¸æçéè¯æ§ããï¼ãé¡äººåï¼ãæ¨¡åæåä½¿ç¨äººé¡æç¨ä¾å·è¡ç¸åä»»åçéè¯æ§ããï¼åæå®³æ§ï¼ãæ¨¡åæåä½¿ç¨ç¡å®³çéè¯æ§ããï¼ãéäºé¢åè­æäº ML èåæ§è¶è¶äºå æ/éå æäºåæ³ï¼èä¸ç ç©¶äººå¡é¸æçä¸åè©®éè·¯å¾å¯è½æé¡¯èå½±é¿ ML ç¼å±çè»è·¡ãééå¼·èª¿ ML ä¸­çåºæ¬åé¡å¦ä½å¨ç ç©¶èæ¯ä¸­è¢«å¶ç¶ååï¼æåçº AI éç¼ä¸­éæ¼è² è²¬ä»»å¯¦åçæçºè¾¯è«ååºè²¢ç»ã

##### **Reciprocal Point Learning Network with Large Electromagnetic Kernel for SAR Open-Set Recognition**
2411.04693v1 by Xiayang Xiao, Zhuoxuan Li, Ruyi Zhang, Jiacheng Chen, Haipeng Wang

The limitations of existing Synthetic Aperture Radar (SAR) Automatic Target
Recognition (ATR) methods lie in their confinement by the closed-environment
assumption, hindering their effective and robust handling of unknown target
categories in open environments. Open Set Recognition (OSR), a pivotal facet
for algorithmic practicality, intends to categorize known classes while
denoting unknown ones as "unknown." The chief challenge in OSR involves
concurrently mitigating risks associated with generalizing features from a
restricted set of known classes to numerous unknown samples and the open space
exposure to potential unknown data. To enhance open-set SAR classification, a
method called scattering kernel with reciprocal learning network is proposed.
Initially, a feature learning framework is constructed based on reciprocal
point learning (RPL), establishing a bounded space for potential unknown
classes. This approach indirectly introduces unknown information into a learner
confined to known classes, thereby acquiring more concise and discriminative
representations. Subsequently, considering the variability in the imaging of
targets at different angles and the discreteness of components in SAR images, a
proposal is made to design convolutional kernels based on large-sized attribute
scattering center models. This enhances the ability to extract intrinsic
non-linear features and specific scattering characteristics in SAR images,
thereby improving the discriminative features of the model and mitigating the
impact of imaging variations on classification performance. Experiments on the
MSTAR datasets substantiate the superior performance of the proposed approach
called ASC-RPL over mainstream methods.

æè¦ï¼ç¾æåæå­å¾é·é (SAR) èªåç®æ¨è­å¥ (ATR) æ¹æ³çéå¶å¨æ¼å®ååéæ¼å°éç°å¢åè¨­ï¼é»ç¤å®åå¨éæ¾ç°å¢ä¸­ææä¸ç©©å¥å°èçæªç¥ç®æ¨é¡å¥ãéæ¾éè­å¥ (OSR) æ¯æ¼ç®æ³å¯¦ç¨æ§çééµé¢åï¼æ¨å¨å°å·²ç¥é¡å¥é²è¡åé¡ï¼åæå°æªç¥é¡å¥æ¨ç¤ºçºãæªç¥ããOSR çä¸»è¦ææ°æ¶ååæéä½èå°ç¹å¾µå¾å·²ç¥é¡å¥çåééåæ¦æ¬å°å¤§éæªç¥æ¨£æ¬ç¸éçé¢¨éªï¼ä»¥åéæ¾ç©ºéæé²æ¼æ½å¨æªç¥è³æãçºäºå¢å¼·éæ¾é SAR åé¡ï¼æåºäºä¸ç¨®ç¨±çºæ£å°æ ¸èäºæ å­¸ç¿ç¶²è·¯çæ¹æ³ãæåï¼åºæ¼äºæ é»å­¸ç¿ (RPL) å»ºæ§ç¹å¾µå­¸ç¿æ¶æ§ï¼çºæ½å¨æªç¥é¡å¥å»ºç«æçç©ºéãæ­¤æ¹æ³éæ¥å°æªç¥è³è¨å¼å¥åéæ¼å·²ç¥é¡å¥çå­¸ç¿å¨ï¼å¾èç²å¾æ´ç°¡æ½ä¸å·åè¾¨åçè¡¨ç¤ºãé¨å¾ï¼èæ®ç®æ¨å¨ä¸åè§åº¦æåçå¯è®æ§ä»¥å SAR å½±åä¸­åä»¶çé¢æ£æ§ï¼æåºåºæ¼å¤§åå±¬æ§æ£å°ä¸­å¿æ¨¡åè¨­è¨å·ç©æ ¸ãéå¢å¼·äºå¾ SAR å½±åä¸­æåå§å¨éç·æ§ç¹å¾µåç¹å®æ£å°ç¹å¾µçè½åï¼å¾èæ¹åæ¨¡åçåè¾¨ç¹å¾µä¸¦æ¸è¼æåè®åå°åé¡æè½çå½±é¿ãMSTAR è³æéä¸çå¯¦é©è­å¯¦äºææåºç ASC-RPL æ¹æ³åªæ¼ä¸»æµæ¹æ³çåè¶æè½ã

##### **Personalized Federated Learning for Cross-view Geo-localization**
2411.04692v1 by Christos Anagnostopoulos, Alexandros Gkillas, Nikos Piperigkos, Aris S. Lalos

In this paper we propose a methodology combining Federated Learning (FL) with
Cross-view Image Geo-localization (CVGL) techniques. We address the challenges
of data privacy and heterogeneity in autonomous vehicle environments by
proposing a personalized Federated Learning scenario that allows selective
sharing of model parameters. Our method implements a coarse-to-fine approach,
where clients share only the coarse feature extractors while keeping
fine-grained features specific to local environments. We evaluate our approach
against traditional centralized and single-client training schemes using the
KITTI dataset combined with satellite imagery. Results demonstrate that our
federated CVGL method achieves performance close to centralized training while
maintaining data privacy. The proposed partial model sharing strategy shows
comparable or slightly better performance than classical FL, offering
significant reduced communication overhead without sacrificing accuracy. Our
work contributes to more robust and privacy-preserving localization systems for
autonomous vehicles operating in diverse environments

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®çµåè¯é¦å­¸ç¿ (FL) èè·¨è¦åå½±åå°çå®ä½ (CVGL) æè¡çæ¹æ³ãæåééæåºåè¨±é¸ææ§åäº«æ¨¡ååæ¸çåäººåè¯é¦å­¸ç¿å ´æ¯ï¼ä¾è§£æ±ºèªé§è»ç°å¢ä¸­çè³æé±ç§åç°è³ªæ§ææ°ãæåçæ¨¡åå¯¦ä½ä¸ç¨®ç±ç²å°ç´°çæ¹æ³ï¼å®¢æ¶ç«¯ååäº«ç²ç¥çç¹å¾µèåå¨ï¼åæä¿çç¹å®æ¼ç¶å°ç°å¢çç´°ç²åº¦ç¹å¾µãæåä½¿ç¨çµåäºè¡æå½±åç KITTI è³æéï¼éå°å³çµ±çéä¸­å¼åå®ä¸å®¢æ¶ç«¯è¨ç·´æ¶æ§è©ä¼°æåçæ¨¡åãçµæè­æï¼æåçè¯é¦ CVGL æ¹æ³éå°äºæ¥è¿éä¸­å¼è¨ç·´çæè½ï¼åæç¶­è­·è³æé±ç§ãææåºçé¨åæ¨¡ååäº«ç­ç¥å±ç¾åºèå³çµ± FL ç¸ç¶æç¥ä½³çæè½ï¼å¨ä¸ç§ç²æºç¢ºåº¦çæ¢ä»¶ä¸ï¼å¤§å¹æ¸å°éè¨éé·ãæåçç ç©¶æå©æ¼å»ºç«å¨åç¨®ç°å¢ä¸­éä½çèªé§è»çæ´å¼·å¤§ä¸æ³¨éé±ç§çå®ä½ç³»çµ±

##### **AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**
2411.04691v1 by Tianyi Zhang, Miu Kojima, Simon D'Alfonso

Smartphones, equipped with an array of sensors, have become valuable tools
for personal sensing. Particularly in digital health, smartphones facilitate
the tracking of health-related behaviors and contexts, contributing
significantly to digital phenotyping, a process where data from digital
interactions is analyzed to infer behaviors and assess mental health.
Traditional methods process raw sensor data into information features for
statistical and machine learning analyses. In this paper, we introduce a novel
approach that systematically converts smartphone-collected data into
structured, chronological narratives. The AWARE Narrator translates
quantitative smartphone sensing data into English language descriptions,
forming comprehensive narratives of an individual's activities. We apply the
framework to the data collected from university students over a week,
demonstrating the potential of utilizing the narratives to summarize individual
behavior, and analyzing psychological states by leveraging large language
models.

æè¦ï¼æºæ§åææ©éåäºåå¼ææ¸¬å¨ï¼å·²æçºåäººææ¸¬çå¯¶è²´å·¥å·ãç¹å¥æ¯å¨æ¸ä½å¥åº·é åï¼æºæ§åææ©ä¿é²äºå¥åº·ç¸éè¡çºåæå¢çè¿½è¹¤ï¼å°æ¸ä½è¡¨ååæååºäºéå¤§è²¢ç»ï¼æ¸ä½è¡¨ååææ¯ä¸ç¨®å¾æ¸ä½äºåä¸­åæè³æä»¥æ¨è«è¡çºåè©ä¼°å¿çå¥åº·çç¨åºãå³çµ±æ¹æ³å°åå§ææ¸¬å¨è³æèçæè³è¨ç¹å¾µï¼ä»¥é²è¡çµ±è¨åæ©å¨å­¸ç¿åæãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³ç³»çµ±æ§å°å°æºæ§åææ©æ¶éçè³æè½ææçµæ§åçæéé åºæäºãAWARE Narrator å°å®éçæºæ§åææ©ææ¸¬è³æè½ææè±æèªè¨æè¿°ï¼å½¢æåäººæ´»åçç¶åæäºãæåå°æ­¤æ¶æ§å¥ç¨å¨å¤§å­¸çä¸é±å§æ¶éçè³æä¸ï¼è­æäºå©ç¨æäºç¸½çµåäººè¡çºçæ½åï¼ä¸¦éééç¨å¤§åèªè¨æ¨¡åä¾åæå¿ççæã

##### **Solving Generalized Grouping Problems in Cellular Manufacturing Systems Using a Network Flow Model**
2411.04685v1 by Md. Kutub Uddin, Md. Saiful Islam, Md Abrar Jahin, Md. Saiful Islam Seam, M. F. Mridha

This paper focuses on the generalized grouping problem in the context of
cellular manufacturing systems (CMS), where parts may have more than one
process route. A process route lists the machines corresponding to each part of
the operation. Inspired by the extensive and widespread use of network flow
algorithms, this research formulates the process route family formation for
generalized grouping as a unit capacity minimum cost network flow model. The
objective is to minimize dissimilarity (based on the machines required) among
the process routes within a family. The proposed model optimally solves the
process route family formation problem without pre-specifying the number of
part families to be formed. The process route of family formation is the first
stage in a hierarchical procedure. For the second stage (machine cell
formation), two procedures, a quadratic assignment programming (QAP)
formulation and a heuristic procedure, are proposed. The QAP simultaneously
assigns process route families and machines to a pre-specified number of cells
in such a way that total machine utilization is maximized. The heuristic
procedure for machine cell formation is hierarchical in nature. Computational
results for some test problems show that the QAP and the heuristic procedure
yield the same results.

æè¦ï¼æ¬æéé»æ¢è¨å·æå¤åè£½ç¨è·¯å¾çèå·¢å¼è£½é ç³»çµ± (CMS) ä¸­çå»£ç¾©ç¾¤çµåé¡ãè£½ç¨è·¯å¾ååºå°ææ¼ä½æ¥­åé¨åçæ©å¨ãåå°ç¶²è·¯æµæ¼ç®æ³å»£æ³ä½¿ç¨çåç¼ï¼æ¬ç ç©¶å°å»£ç¾©ç¾¤çµçè£½ç¨è·¯å¾æå½¢æå¶å®çºå®ä½å®¹éæå°ææ¬ç¶²è·¯æµæ¨¡åãç®æ¨æ¯å°ä¸åæå§è£½ç¨è·¯å¾ä¹éçå·®ç°æ§ï¼ä¾ææéçæ©å¨ï¼éå°æä½ãææåºçæ¨¡åå¯ä»¥æä½³åè§£æ±ºè£½ç¨è·¯å¾æå½¢æåé¡ï¼èç¡é é åæå®è¦å½¢æçé¶ä»¶ææ¸éãè£½ç¨è·¯å¾æå½¢ææ¯éå±¤å¼ç¨åºçç¬¬ä¸éæ®µãå°æ¼ç¬¬äºéæ®µï¼æ©å¨å®åå½¢æï¼ï¼æ¬ææåºå©ç¨®ç¨åºï¼äºæ¬¡ææ´¾è¦å (QAP) å¬å¼ååç¼å¼ç¨åºãQAP åæå°è£½ç¨è·¯å¾æåæ©å¨ææ´¾å°é åæå®æ¸éçå®åä¸­ï¼ä»¥ä½¿ç¸½æ©å¨ä½¿ç¨çæå¤§åãæ©å¨å®åå½¢æçåç¼å¼ç¨åºæ¬è³ªä¸æ¯éå±¤å¼çãä¸äºæ¸¬è©¦åé¡çè¨ç®çµæé¡¯ç¤ºï¼QAP ååç¼å¼ç¨åºæç¢çç¸åççµæã

##### **CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation**
2411.04679v1 by Jie Liu, Pan Zhou, Yingjun Du, Ah-Hwee Tan, Cees G. M. Snoek, Jan-Jakob Sonke, Efstratios Gavves

In this work, we address the cooperation problem among large language model
(LLM) based embodied agents, where agents must cooperate to achieve a common
goal. Previous methods often execute actions extemporaneously and incoherently,
without long-term strategic and cooperative planning, leading to redundant
steps, failures, and even serious repercussions in complex tasks like
search-and-rescue missions where discussion and cooperative plan are crucial.
To solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance
the cooperation efficiency of LLM-based embodied agents. Inspired by human
cooperation schemes, CaPo improves cooperation efficiency with two phases: 1)
meta-plan generation, and 2) progress-adaptive meta-plan and execution. In the
first phase, all agents analyze the task, discuss, and cooperatively create a
meta-plan that decomposes the task into subtasks with detailed steps, ensuring
a long-term strategic and coherent plan for efficient coordination. In the
second phase, agents execute tasks according to the meta-plan and dynamically
adjust it based on their latest progress (e.g., discovering a target object)
through multi-turn discussions. This progress-based adaptation eliminates
redundant actions, improving the overall cooperation efficiency of agents.
Experimental results on the ThreeDworld Multi-Agent Transport and Communicative
Watch-And-Help tasks demonstrate that CaPo achieves much higher task completion
rate and efficiency compared with state-of-the-arts.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) æä¾æçå·èº«ä»£çä¹éçåä½åé¡ï¼å¶ä¸­ä»£çå¿é åä½æè½éæå±åç®æ¨ãååçåæ³éå¸¸è¨æä¸ä¸é£è²«å°å·è¡åä½ï¼ç¼ºä¹é·æç­ç¥ååä½è¦åï¼å°è´å¨æå°åææ´ä»»åç­è¤éä»»åä¸­åºç¾éè¤æ­¥é©ãå¤±æï¼çè³å´éçå¾æï¼èè¨è«ååä½è¨ç«å¨éäºä»»åä¸­è³ééè¦ãçºäºè§£æ±ºéååé¡ï¼æåæåºåä½è¨ç«æä½³å (CaPo) ä¾æå LLM æä¾æçå·èº«ä»£ççåä½æçãCaPo åå°äººé¡åä½è¨ç«çåç¼ï¼ééå©åéæ®µä¾æ¹ååä½æçï¼1) åè¨ç«ç¢çï¼ä»¥å 2) é²åº¦é©æåè¨ç«åå·è¡ãå¨ç¬¬ä¸éæ®µï¼ææä»£çé½æåæä»»åãè¨è«ï¼ä¸¦åä½å»ºç«ä¸ååè¨ç«ï¼å°ä»»ååè§£æå·æè©³ç´°æ­¥é©çå­ä»»åï¼ç¢ºä¿é·æç­ç¥åé£è²«è¨ç«ï¼ä»¥é²è¡ææççåèª¿ãå¨ç¬¬äºéæ®µï¼ä»£çææ ¹æåè¨ç«å·è¡ä»»åï¼ä¸¦ééå¤è¼ªè¨è«æ ¹æä»åçææ°é²åº¦ï¼ä¾å¦ï¼ç¼ç¾ç®æ¨ç©é«ï¼åæèª¿æ´åè¨ç«ãéç¨®åºæ¼é²åº¦çèª¿æ´æ¶é¤äºéè¤çåä½ï¼æ¹åäºä»£ççæ´é«åä½æçãå¨ ThreeDworld å¤ä»£çéè¼¸åæºéè§å¯èåå©ä»»åä¸çå¯¦é©çµæé¡¯ç¤ºï¼èç¾ææè¡ç¸æ¯ï¼CaPo éå°äºæ´é«çä»»åå®æçåæçã

##### **CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational Agents in XR**
2411.04671v1 by Kadir Burak Buldu, SÃ¼leyman Ãzdel, Ka Hei Carrie Lau, Mengdi Wang, Daniel Saad, Sofie SchÃ¶nborn, Auxane Boch, Enkelejda Kasneci, Efe Bozkir

Recent developments in computer graphics, machine learning, and sensor
technologies enable numerous opportunities for extended reality (XR) setups for
everyday life, from skills training to entertainment. With large corporations
offering consumer-grade head-mounted displays (HMDs) in an affordable way, it
is likely that XR will become pervasive, and HMDs will develop as personal
devices like smartphones and tablets. However, having intelligent spaces and
naturalistic interactions in XR is as important as technological advances so
that users grow their engagement in virtual and augmented spaces. To this end,
large language model (LLM)--powered non-player characters (NPCs) with
speech-to-text (STT) and text-to-speech (TTS) models bring significant
advantages over conventional or pre-scripted NPCs for facilitating more natural
conversational user interfaces (CUIs) in XR. In this paper, we provide the
community with an open-source, customizable, extensible, and privacy-aware
Unity package, CUIfy, that facilitates speech-based NPC-user interaction with
various LLMs, STT, and TTS models. Our package also supports multiple
LLM-powered NPCs per environment and minimizes the latency between different
computational models through streaming to achieve usable interactions between
users and NPCs. We publish our source code in the following repository:
https://gitlab.lrz.de/hctl/cuify

æè¦ï¼<paragraph>é»è¦åå­¸ãæ©å¨å­¸ç¿åææ¸¬æè¡çææ°ç¼å±ï¼çºæ¥å¸¸çæ´»çæ´å¢å¯¦å¢ (XR) è¨­å®æä¾äºè¨±å¤æ©æï¼å¾æè½è¨ç·´å°å¨æ¨ãé¨èå¤§åä¼æ¥­ä»¥å¯¦æ çæ¹å¼æä¾æ¶è²»èç´é ­æ´å¼é¡¯ç¤ºå¨ (HMD)ï¼XR å¾å¯è½æè®å¾æ®éï¼è HMD å°åæºæ§åææ©åå¹³æ¿é»è¦ä¸æ¨£ç¼å±çºåäººè£ç½®ãç¶èï¼å¨ XR ä¸­æææºæ§ç©ºéåèªç¶äºåèæè¡é²æ­¥ä¸æ¨£éè¦ï¼ä»¥ä¾¿ä½¿ç¨èå¨èæ¬åæ´å¢ç©ºéä¸­å¢å åèåº¦ãçºæ­¤ï¼ç±å¤§åèªè¨æ¨¡å (LLM) é©åçéç©å®¶è§è² (NPC) å·åèªé³è½æå­ (STT) åæå­è½èªé³ (TTS) æ¨¡åï¼èå³çµ±æé åç·¨å¯«ç NPC ç¸æ¯ï¼å¨ä¿é² XR ä¸­æ´èªç¶çå°è©±å¼ä½¿ç¨èä»é¢ (CUI) æ¹é¢å·æé¡¯èåªå¢ãå¨æ¬æä¸­ï¼æåçºç¤¾ç¾¤æä¾ä¸åéæºãå¯èªè¨ãå¯æ´ååæ³¨éé±ç§ç Unity å¥ä»¶ CUIfyï¼å®ä¿é²äºåºæ¼èªé³ç NPC ä½¿ç¨èäºåï¼ä¸¦æ¯æ´åç¨® LLMãSTT å TTS æ¨¡åãæåçå¥ä»¶éæ¯æ´æ¯åç°å¢ä¸­æå¤åç± LLM é©åç NPCï¼ä¸¦ééä¸²æµå°ä¸åéç®æ¨¡åä¹éçå»¶é²éè³æä½ï¼ä»¥å¯¦ç¾ä½¿ç¨èå NPC ä¹éå¯ç¨çäºåãæåå¨ä»¥ä¸å­æ¾åº«ä¸­ç¼å¸æåçåå§ç¨å¼ç¢¼ï¼
https://gitlab.lrz.de/hctl/cuify</paragraph>

##### **EffiCANet: Efficient Time Series Forecasting with Convolutional Attention**
2411.04669v1 by Xinxing Zhou, Jiaqi Ye, Shubao Zhao, Ming Jin, Chengyi Yang, Yanlong Wen, Xiaojie Yuan

The exponential growth of multivariate time series data from sensor networks
in domains like industrial monitoring and smart cities requires efficient and
accurate forecasting models. Current deep learning methods often fail to
adequately capture long-range dependencies and complex inter-variable
relationships, especially under real-time processing constraints. These
limitations arise as many models are optimized for either short-term
forecasting with limited receptive fields or long-term accuracy at the cost of
efficiency. Additionally, dynamic and intricate interactions between variables
in real-world data further complicate modeling efforts. To address these
limitations, we propose EffiCANet, an Efficient Convolutional Attention Network
designed to enhance forecasting accuracy while maintaining computational
efficiency. EffiCANet integrates three key components: (1) a Temporal
Large-kernel Decomposed Convolution (TLDC) module that captures long-term
temporal dependencies while reducing computational overhead; (2) an
Inter-Variable Group Convolution (IVGC) module that captures complex and
evolving relationships among variables; and (3) a Global Temporal-Variable
Attention (GTVA) mechanism that prioritizes critical temporal and
inter-variable features. Extensive evaluations across nine benchmark datasets
show that EffiCANet achieves the maximum reduction of 10.02% in MAE over
state-of-the-art models, while cutting computational costs by 26.2% relative to
conventional large-kernel convolution methods, thanks to its efficient
decomposition strategy.

æè¦ï¼ææ¸¬å¨ç¶²è·¯ä¸­å¤è®éæéåºåè³æçææ¸æé·ï¼å¨å·¥æ¥­ç£æ§åæºæ§åå¸ç­é åï¼éè¦ææçä¸æºç¢ºçé æ¸¬æ¨¡åãç¾æçæ·±åº¦å­¸ç¿æ¹æ³éå¸¸ç¡æ³ååææé·ç¨ä¾è³´éä¿åè¤éçè®æ¸ééä¿ï¼ç¹å¥æ¯å¨å³æèççéå¶ä¸ãéäºéå¶æåºç¾ï¼å çºè¨±å¤æ¨¡åæ¯éå°ç­æé æ¸¬é²è¡æä½³åï¼å·æåéçæåéï¼æä»¥æççºä»£å¹æåé·ææºç¢ºåº¦ãæ­¤å¤ï¼ç¾å¯¦ä¸çè³æä¸­è®æ¸ä¹éçåæåè¤éäºåï¼é²ä¸æ­¥ä½¿å»ºæ¨¡å·¥ä½è¤éåãçºäºè§£æ±ºéäºéå¶ï¼æåæåº EffiCANetï¼ä¸ç¨®é«æçå·ç©æ³¨æåç¶²è·¯ï¼æ¨å¨æé«é æ¸¬æºç¢ºåº¦ï¼åæç¶­æéç®æçãEffiCANet æ´åäºä¸åééµåä»¶ï¼(1) æéå¤§æ ¸åè§£å·ç© (TLDC) æ¨¡çµï¼å¯ææé·ææéä¾è³´éä¿ï¼åæéä½éç®è² æï¼(2) è®æ¸éç¾¤çµå·ç© (IVGC) æ¨¡çµï¼å¯ææè®æ¸ä¹éè¤éä¸ä¸æ·è®åçéä¿ï¼(3) å¨åæéè®æ¸æ³¨æå (GTVA) æ©å¶ï¼å¯åªåèçééµæéåè®æ¸éç¹å¾µãå¨ä¹ååºæºè³æéçå»£æ³è©ä¼°é¡¯ç¤ºï¼EffiCANet å¨ MAE ä¸éå°äº 10.02% çæå¤§æ¸å°ï¼ç¸è¼æ¼ç¾ææåé²çæ¨¡åï¼åæå°éç®ææ¬éä½äº 26.2%ï¼éè¦æ­¸åæ¼å¶ææççåè§£ç­ç¥ã

##### **DISCO: DISCovering Overfittings as Causal Rules for Text Classification Models**
2411.04649v1 by Zijian Zhang, Vinay Setty, Yumeng Wang, Avishek Anand

With the rapid advancement of neural language models, the deployment of
over-parameterized models has surged, increasing the need for interpretable
explanations comprehensible to human inspectors. Existing post-hoc
interpretability methods, which often focus on unigram features of single input
textual instances, fail to capture the models' decision-making process fully.
Additionally, many methods do not differentiate between decisions based on
spurious correlations and those based on a holistic understanding of the input.
Our paper introduces DISCO, a novel method for discovering global, rule-based
explanations by identifying causal n-gram associations with model predictions.
This method employs a scalable sequence mining technique to extract relevant
text spans from training data, associate them with model predictions, and
conduct causality checks to distill robust rules that elucidate model behavior.
These rules expose potential overfitting and provide insights into misleading
feature combinations. We validate DISCO through extensive testing,
demonstrating its superiority over existing methods in offering comprehensive
insights into complex model behaviors. Our approach successfully identifies all
shortcuts manually introduced into the training data (100% detection rate on
the MultiRC dataset), resulting in an 18.8% regression in model performance --
a capability unmatched by any other method. Furthermore, DISCO supports
interactive explanations, enabling human inspectors to distinguish spurious
causes in the rule-based output. This alleviates the burden of abundant
instance-wise explanations and helps assess the model's risk when encountering
out-of-distribution (OOD) data.

æè¦ï¼<paragraph>é¨èç¥ç¶èªè¨æ¨¡åçå¿«éé²å±ï¼éåº¦åæ¸åæ¨¡åçé¨ç½²æ¿å¢ï¼å¢å äºå°äººé¡æª¢æ¥å¡å¯ä»¥çè§£çå¯è§£éè§£éçéæ±ãç¾æçäºå¾å¯è§£éæ§æ¹æ³éå¸¸éæ³¨å®åè¼¸å¥ææ¬å¯¦ä¾çå®å­åç¹å¾µï¼ç¡æ³å®å¨æææ¨¡åçæ±ºç­éç¨ãæ­¤å¤ï¼è¨±å¤æ¹æ³ç¡æ³åååºæ¼èåç¸éæ§çæ±ºç­ååºæ¼å°è¼¸å¥æ´é«çè§£çæ±ºç­ãæåçè«æä»ç´¹äº DISCOï¼éæ¯ä¸ç¨®ç¼ç¾å¨å±åºæ¼è¦åçè§£éçæ°æ¹æ³ï¼ééè­å¥èæ¨¡åé æ¸¬ç¸éçå æ n-gram éè¯ä¾å¯¦ç¾ãæ­¤æ¹æ³æ¡ç¨å¯æ´åçåºåæææè¡å¾è¨ç·´æ¸æä¸­æåç¸éçæå­è·¨åº¦ï¼å°å®åèæ¨¡åé æ¸¬éè¯èµ·ä¾ï¼ä¸¦é²è¡å æéä¿æª¢æ¥ä»¥æçé¡ææ¨¡åè¡çºçå¼·å¥è¦åãéäºè¦åæ­ç¤ºäºæ½å¨çéæ¬åï¼ä¸¦æä¾äºå°èª¤å°æ§ç¹å¾µçµåçè¦è§£ãæåééå»£æ³çæ¸¬è©¦é©è­äº DISCOï¼è­æäºå®å¨æä¾å°è¤éæ¨¡åè¡çºçå¨é¢è¦è§£æ¹é¢åªæ¼ç¾ææ¹æ³ãæåçåæ³æåè­å¥äºæåå¼å¥è¨ç·´æ¸æä¸­çæææ·å¾ï¼å¨ MultiRC æ¸æéä¸æª¢æ¸¬ççº 100%ï¼ï¼å°è´æ¨¡åæ§è½ä¸é 18.8%ââéæ¯ä»»ä½å¶ä»æ¹æ³é½ç¡æ³æ¯æ¬çè½åãæ­¤å¤ï¼DISCO æ¯æäºåå¼è§£éï¼ä½¿äººé¡æª¢æ¥å¡è½å¤ åååºæ¼è¦åçè¼¸åºä¸­çèååå ãéæ¸è¼äºå¤§éåºæ¼å¯¦ä¾çè§£éçè² æï¼ä¸¦æå©æ¼è©ä¼°æ¨¡åå¨éå°åå¸å¤ (OOD) æ¸ææçé¢¨éªã</paragraph>

##### **wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification from Physiological Signals**
2411.04644v1 by Jonathan F. Carter, Lionel Tarassenko

Accurate classification of sleep stages from less obtrusive sensor
measurements such as the electrocardiogram (ECG) or photoplethysmogram (PPG)
could enable important applications in sleep medicine. Existing approaches to
this problem have typically used deep learning models designed and trained to
operate on one or more specific input signals. However, the datasets used to
develop these models often do not contain the same sets of input signals. Some
signals, particularly PPG, are much less prevalent than others, and this has
previously been addressed with techniques such as transfer learning.
Additionally, only training on one or more fixed modalities precludes
cross-modal information transfer from other sources, which has proved valuable
in other problem domains. To address this, we introduce wav2sleep, a unified
model designed to operate on variable sets of input signals during training and
inference. After jointly training on over 10,000 overnight recordings from six
publicly available polysomnography datasets, including SHHS and MESA, wav2sleep
outperforms existing sleep stage classification models across test-time input
combinations including ECG, PPG, and respiratory signals.

æè¦ï¼ééè¼ä¸å·ä¾µå¥æ§çææ¸¬å¨éæ¸¬ï¼ä¾å¦å¿é»å (ECG) æåé»å®¹ç©æè¨å (PPG)ï¼æºç¢ºåé¡ç¡ç éæ®µï¼è½æç¨æ¼ç¡ç é«å­¸ä¸­ãç¾æçæ¹æ³éå¸¸ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼è¨­è¨åè¨ç·´éäºæ¨¡åä»¥èçä¸åæå¤åç¹å®è¼¸å¥è¨èãç¶èï¼ç¨æ¼éç¼éäºæ¨¡åçè³æééå¸¸ä¸åå«ç¸åçè¼¸å¥è¨èçµãæäºè¨èï¼ç¹å¥æ¯ PPGï¼é æ¯å¶ä»è¨èä¸æ®éï¼èéååå·²ééè½ç§»å­¸ç¿ç­æè¡ä¾è§£æ±ºãæ­¤å¤ï¼åè¨ç·´ä¸ç¨®æå¤ç¨®åºå®æ¨¡å¼ææé¤ä¾èªå¶ä»ä¾æºçè·¨æ¨¡å¼è³è¨å³è¼¸ï¼éå·²è­æå¨å¶ä»åé¡é åä¸­å¾æå¹å¼ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº wav2sleepï¼éæ¯ä¸åçµ±ä¸çæ¨¡åï¼è¨­è¨ç¨æ¼å¨è¨ç·´åæ¨è«æéèçè®æ¸çµçè¼¸å¥è¨èãå¨å°ä¾èªå­åå¬éå¯ç¨çå¤éç¡ç ççæª¢æ¥è³æéï¼åæ¬ SHHS å MESAï¼ç 10,000 å¤åéå¤è¨éé²è¡è¯åè¨ç·´å¾ï¼wav2sleep å¨æ¸¬è©¦æéè¼¸å¥çµåï¼åæ¬ ECGãPPG åå¼å¸è¨èï¼ä¸­åªæ¼ç¾æçç¡ç éæ®µåé¡æ¨¡åã

##### **TAP-VL: Text Layout-Aware Pre-training for Enriched Vision-Language Models**
2411.04642v1 by Jonathan Fhima, Elad Ben Avraham, Oren Nuriel, Yair Kittenplon, Roy Ganz, Aviad Aberdam, Ron Litman

Vision-Language (VL) models have garnered considerable research interest;
however, they still face challenges in effectively handling text within images.
To address this limitation, researchers have developed two approaches. The
first method involves utilizing external Optical Character Recognition (OCR)
tools to extract textual information from images, which is then prepended to
other textual inputs. The second strategy focuses on employing extremely
high-resolution images to improve text recognition capabilities. In this paper,
we focus on enhancing the first strategy by introducing a novel method, named
TAP-VL, which treats OCR information as a distinct modality and seamlessly
integrates it into any VL model. TAP-VL employs a lightweight transformer-based
OCR module to receive OCR with layout information, compressing it into a short
fixed-length sequence for input into the LLM. Initially, we conduct
model-agnostic pretraining of the OCR module on unlabeled documents, followed
by its integration into any VL architecture through brief fine-tuning.
Extensive experiments demonstrate consistent performance improvements when
applying TAP-VL to top-performing VL models, across scene-text and
document-based VL benchmarks.

æè¦ï¼è¦è¦ºèªè¨ (VL) æ¨¡åå¼èµ·äºç¸ç¶å¤§çç ç©¶èè¶£ï¼
ç¶èï¼å®åå¨ææèçå½±åä¸­çæå­æä»é¢è¨ææ°ã
çºäºè§£æ±ºéåéå¶ï¼ç ç©¶äººå¡éç¼äºå©ç¨®æ¹æ³ãç¬¬ä¸ç¨®æ¹æ³æ¶åå©ç¨å¤é¨åå­¸å­åè¾¨è­ (OCR)
å·¥å·å¾å½±åä¸­æ·åæå­è³è¨ï¼ç¶å¾å°å¶é åå å°
å¶ä»æå­è¼¸å¥ãç¬¬äºç¨®ç­ç¥å°æ³¨æ¼æ¡ç¨æ¥µé«è§£æåº¦çå½±åä¾æ¹åæå­è¾¨è­è½åãå¨æ¬æä¸­ï¼
æåå°æ³¨æ¼ééå¼å¥ä¸ç¨®åçº TAP-VL çæ°æ¹æ³ä¾å¢å¼·ç¬¬ä¸ç¨®ç­ç¥ï¼å®å° OCR è³è¨è¦çºä¸ç¨®ä¸åçæ¹å¼ï¼ä¸¦å°å¶ç¡ç¸«æ´åå°ä»»ä½ VL æ¨¡åä¸­ãTAP-VL æ¡ç¨è¼éç´çåºæ¼è½æå¨ç
OCR æ¨¡çµä¾æ¥æ¶å·æçé¢è³è¨ç OCRï¼å°å¶å£ç¸®æä¸åç­çåºå®é·åº¦åºåï¼ä½çºè¼¸å¥å° LLMãæåï¼æåå° OCR æ¨¡çµé²è¡èæ¨¡åç¡éçé è¨ç·´ï¼ä½¿ç¨æªæ¨è¨çææªï¼ç¶å¾
ééç°¡ç­çå¾®èª¿å°å¶æ´åå°ä»»ä½ VL æ¶æ§ä¸­ã
å»£æ³çå¯¦é©è¡¨æï¼å° TAP-VL æç¨æ¼æè½æä½³ç VL æ¨¡åæï¼å¨å ´æ¯æå­å
åºæ¼æä»¶ç VL åºæºæ¸¬è©¦ä¸­ï¼é½è½æçºæ¹åæè½ã

##### **Hands-On Tutorial: Labeling with LLM and Human-in-the-Loop**
2411.04637v1 by Ekaterina Artemova, Akim Tsvigun, Dominik Schlechtweg, Natalia Fedorova, Sergei Tilga, Boris Obmoroshev

Training and deploying machine learning models relies on a large amount of
human-annotated data. As human labeling becomes increasingly expensive and
time-consuming, recent research has developed multiple strategies to speed up
annotation and reduce costs and human workload: generating synthetic training
data, active learning, and hybrid labeling. This tutorial is oriented toward
practical applications: we will present the basics of each strategy, highlight
their benefits and limitations, and discuss in detail real-life case studies.
Additionally, we will walk through best practices for managing human annotators
and controlling the quality of the final dataset. The tutorial includes a
hands-on workshop, where attendees will be guided in implementing a hybrid
annotation setup. This tutorial is designed for NLP practitioners from both
research and industry backgrounds who are involved in or interested in
optimizing data labeling projects.

æè¦ï¼è¨ç·´åé¨ç½²æ©å¨å­¸ç¿æ¨¡åä»°è³´å¤§éç
äººå·¥æ¨è¨è³æãç±æ¼äººå·¥æ¨è¨çææ¬è¶ä¾è¶é«æä¸èæï¼æè¿çç ç©¶å·²éç¼åºå¤ç¨®ç­ç¥ä¾å é
æ¨è¨ä¸¦éä½ææ¬åäººåè² æï¼ç¢çåæè¨ç·´
è³æãä¸»åå­¸ç¿åæ··åæ¨è¨ãæ¬æå­¸èª²ç¨ä»¥
å¯¦éæç¨çºå°åï¼æåå°ä»ç´¹æ¯ç¨®ç­ç¥çåºæ¬åçï¼å¼·èª¿
å®åçåªé»åéå¶ï¼ä¸¦è©³ç´°è¨è«å¯¦éæ¡ä¾ç ç©¶ã
æ­¤å¤ï¼æåå°éæ­¥ä»ç´¹ç®¡çäººå·¥æ¨è¨å¡åæ§å¶æçµ
è³æéåè³ªçæä½³å¯¦åãæ¬æå­¸èª²ç¨åæ¬å¯¦ä½å·¥ä½åï¼åèèå°å¨å¶ä¸­æ¥åæå°ï¼å¯¦ä½æ··å
æ¨è¨è¨­å®ãæ¬æå­¸èª²ç¨å°çºä¾èª
ç ç©¶åç¢æ¥­èæ¯ï¼ä¸åèææèè¶£
æä½³åè³ææ¨è¨å°æ¡ç NLP å¯¦åäººå¡æè¨­è¨ã

##### **FASSILA: A Corpus for Algerian Dialect Fake News Detection and Sentiment Analysis**
2411.04604v1 by Amin Abdedaiem, Abdelhalim Hafedh Dahou, Mohamed Amine Cheragui, Brigitte Mathiak

In the context of low-resource languages, the Algerian dialect (AD) faces
challenges due to the absence of annotated corpora, hindering its effective
processing, notably in Machine Learning (ML) applications reliant on corpora
for training and assessment. This study outlines the development process of a
specialized corpus for Fake News (FN) detection and sentiment analysis (SA) in
AD called FASSILA. This corpus comprises 10,087 sentences, encompassing over
19,497 unique words in AD, and addresses the significant lack of linguistic
resources in the language and covers seven distinct domains. We propose an
annotation scheme for FN detection and SA, detailing the data collection,
cleaning, and labelling process. Remarkable Inter-Annotator Agreement indicates
that the annotation scheme produces consistent annotations of high quality.
Subsequent classification experiments using BERT-based models and ML models are
presented, demonstrate promising results and highlight avenues for further
research. The dataset is made freely available on GitHub
(https://github.com/amincoding/FASSILA) to facilitate future advancements in
the field.

æè¦ï¼å¨ä½è³æºèªè¨çèæ¯ä¸ï¼é¿ç¾åå©äºæ¹è¨ (AD) å ç¼ºä¹è¨»è§£èªæåº«èé¢è¨ææ°ï¼é»ç¤äºå¶ææèçï¼ç¹å¥æ¯å¨ä¾è³´èªæåº«é²è¡è¨ç·´åè©ä¼°çæ©å¨å­¸ç¿ (ML) æç¨ä¸­ãæ¬ç ç©¶æ¦è¿°äºéå° AD ä¸­çåæ°è (FN) æª¢æ¸¬åæç·åæ (SA) èéç¼çå°éèªæåº« FASSILA çéç¼éç¨ãæ­¤èªæåº«åå« 10,087 åå¥å­ï¼æ¶µè AD ä¸­è¶é 19,497 åå®è©ï¼ä¸¦è§£æ±ºäºè©²èªè¨ä¸­èªè¨è³æºçå´éç¼ºä¹ï¼ä¸æ¶µèä¸åä¸åçé åãæåæåºäº FN æª¢æ¸¬å SA çè¨»è§£æ¹æ¡ï¼è©³ç´°èªªæäºæ¸ææ¶éãæ¸çåæ¨è¨éç¨ãé¡¯èçæ¨è¨éä¸è´æ§è¡¨æè¨»è§£æ¹æ¡ç¢çäºä¸è´ä¸é«åè³ªçè¨»è§£ãé¨å¾ä½¿ç¨åºæ¼ BERT çæ¨¡åå ML æ¨¡åé²è¡çå¾çºåé¡å¯¦é©ï¼å±ç¤ºäºæå¸æççµæï¼ä¸¦éé»ä»ç´¹äºé²ä¸æ­¥ç ç©¶çéå¾ãè©²æ¸æéå·²å¨ GitHub (https://github.com/amincoding/FASSILA) ä¸åè²»æä¾ï¼ä»¥ä¿é²è©²é åçæªä¾é²å±ã

##### **Self-Calibrated Listwise Reranking with Large Language Models**
2411.04602v1 by Ruiyang Ren, Yuhao Wang, Kun Zhou, Wayne Xin Zhao, Wenjie Wang, Jing Liu, Ji-Rong Wen, Tat-Seng Chua

Large language models (LLMs), with advanced linguistic capabilities, have
been employed in reranking tasks through a sequence-to-sequence approach. In
this paradigm, multiple passages are reranked in a listwise manner and a
textual reranked permutation is generated. However, due to the limited context
window of LLMs, this reranking paradigm requires a sliding window strategy to
iteratively handle larger candidate sets. This not only increases computational
costs but also restricts the LLM from fully capturing all the comparison
information for all candidates. To address these challenges, we propose a novel
self-calibrated listwise reranking method, which aims to leverage LLMs to
produce global relevance scores for ranking. To achieve it, we first propose
the relevance-aware listwise reranking framework, which incorporates explicit
list-view relevance scores to improve reranking efficiency and enable global
comparison across the entire candidate set. Second, to ensure the comparability
of the computed scores, we propose self-calibrated training that uses
point-view relevance assessments generated internally by the LLM itself to
calibrate the list-view relevance assessments. Extensive experiments and
comprehensive analysis on the BEIR benchmark and TREC Deep Learning Tracks
demonstrate the effectiveness and efficiency of our proposed method.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·æåé²çèªè¨è½åï¼å·²ééåºåå°åºåæ¹æ³ç¨æ¼éæ°æåºä»»åãå¨æ­¤ç¯ä¾ä¸­ï¼å¤åæ®µè½æä»¥åè¡¨æ¹å¼éæ°æåºï¼ä¸¦ç¢çæå­éæ°æåºæåãä½æ¯ï¼ç±æ¼ LLM çå§å®¹è¦çªæéï¼æ­¤éæ°æåºç¯ä¾éè¦æ»åè¦çªç­ç¥ä¾åè¦èçè¼å¤§çåé¸éãéä¸åæå¢å éç®ææ¬ï¼éæéå¶ LLM å®æ´æ·åææåé¸éçæææ¯è¼è³è¨ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ç¨®æ°ç©çèªæ ¡æºåè¡¨éæ°æåºæ¹æ³ï¼æ¨å¨å©ç¨ LLM ç¢çç¨æ¼æåçæ´é«ç¸éæ§åæ¸ãçºéææ­¤ç®æ¨ï¼æåé¦åæåºèç¸éæ§ç¸éçåè¡¨éæ°æåºæ¶æ§ï¼å¶ä¸­åå«æç¢ºçåè¡¨æª¢è¦ç¸éæ§åæ¸ï¼ä»¥æé«éæ°æåºæçä¸¦éå°æ´ååé¸éåç¨æ´é«æ¯è¼ãå¶æ¬¡ï¼çºäºç¢ºä¿è¨ç®åæ¸çå¯æ¯è¼æ§ï¼æåæåºä½¿ç¨ LLM æ¬èº«å§é¨ç¢ççè§é»ç¸éæ§è©ä¼°çèªæ ¡æºè¨ç·´ï¼ä»¥æ ¡æºåè¡¨æª¢è¦ç¸éæ§è©ä¼°ãå¨ BEIR åºæºå TREC æ·±åº¦å­¸ç¿è»éä¸çå»£æ³å¯¦é©åå¨é¢åæè­æäºæåæåºçæ¹æ³çæææ§åæçã

##### **Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction**
2411.04588v1 by Ahlam Alrehili, Areej Alhothali

Natural language processing (NLP) utilizes text data augmentation to overcome
sample size constraints. Increasing the sample size is a natural and widely
used strategy for alleviating these challenges. In this study, we chose Arabic
to increase the sample size and correct grammatical errors. Arabic is
considered one of the languages with limited resources for grammatical error
correction (GEC). Furthermore, QALB-14 and QALB-15 are the only datasets used
in most Arabic grammatical error correction research, with approximately 20,500
parallel examples, which is considered low compared with other languages.
Therefore, this study aims to develop an Arabic corpus called "Tibyan" for
grammatical error correction using ChatGPT. ChatGPT is used as a data augmenter
tool based on a pair of Arabic sentences containing grammatical errors matched
with a sentence free of errors extracted from Arabic books, called guide
sentences. Multiple steps were involved in establishing our corpus, including
the collection and pre-processing of a pair of Arabic texts from various
sources, such as books and open-access corpora. We then used ChatGPT to
generate a parallel corpus based on the text collected previously, as a guide
for generating sentences with multiple types of errors. By engaging linguistic
experts to review and validate the automatically generated sentences, we
ensured that they were correct and error-free. The corpus was validated and
refined iteratively based on feedback provided by linguistic experts to improve
its accuracy. Finally, we used the Arabic Error Type Annotation tool (ARETA) to
analyze the types of errors in the Tibyan corpus. Our corpus contained 49 of
errors, including seven types: orthography, morphology, syntax, semantics,
punctuation, merge, and split. The Tibyan corpus contains approximately 600 K
tokens.

æè¦ï¼èªç¶èªè¨èç (NLP) å©ç¨æå­è³ææ´åä¾åææ¨£æ¬ééå¶ãå¢å æ¨£æ¬éæ¯ç·©è§£éäºææ°çèªç¶ä¸å»£æ³ä½¿ç¨çç­ç¥ãå¨æ¬ç ç©¶ä¸­ï¼æåé¸æé¿æä¼¯èªä¾å¢å æ¨£æ¬éä¸¦æ´æ­£èªæ³é¯èª¤ãé¿æä¼¯èªè¢«èªçºæ¯èªæ³é¯èª¤æ´æ­£ (GEC) è³æºæéçèªè¨ä¹ä¸ãæ­¤å¤ï¼QALB-14 å QALB-15 æ¯å¤§å¤æ¸é¿æä¼¯èªèªæ³é¯èª¤æ´æ­£ç ç©¶ä¸­å¯ä¸ä½¿ç¨çè³æéï¼å¤§ç´æ 20,500 åå¹³è¡ç¯ä¾ï¼èå¶ä»èªè¨ç¸æ¯ï¼éè¢«èªçºæ¯è¼å°çãå æ­¤ï¼æ¬ç ç©¶æ¨å¨éç¼ä¸ååçºãTibyanãçé¿æä¼¯èªèªæåº«ï¼ç¨æ¼ä½¿ç¨ ChatGPT é²è¡èªæ³é¯èª¤æ´æ­£ãChatGPT è¢«ç¨ä½è³ææ´åå·¥å·ï¼åºæ¼ä¸å°åå«èªæ³é¯èª¤çé¿æä¼¯èªå¥å­ï¼ä¸¦èå¾é¿æä¼¯èªæ¸ç±ä¸­æåçæ²æé¯èª¤çå¥å­ï¼ç¨±çºå¼å°å¥å­ï¼ç¸å¹éãå»ºç«æåçèªæåº«æ¶åå¤åæ­¥é©ï¼åæ¬å¾åç¨®ä¾æºï¼ä¾å¦æ¸ç±åéæ¾ç²åèªæåº«ï¼æ¶éåé èçä¸å°é¿æä¼¯èªææ¬ãç¶å¾ï¼æåä½¿ç¨ ChatGPT æ ¹æååæ¶éçææ¬çæä¸åå¹³è¡èªæåº«ï¼ä½çºçæå·æå¤ç¨®é¡åé¯èª¤çå¥å­çæåãééèè«èªè¨å°å®¶ä¾å¯©æ¥åé©è­èªåçæçå¥å­ï¼æåç¢ºä¿å®åæ­£ç¢ºç¡èª¤ãèªæåº«æ ¹æèªè¨å°å®¶æä¾çåé¥é²è¡é©è­ååè¦ä¿®æ¹ï¼ä»¥æé«å¶æºç¢ºæ§ãæå¾ï¼æåä½¿ç¨é¿æä¼¯èªé¯èª¤é¡åè¨»è§£å·¥å· (ARETA) ä¾åæ Tibyan èªæåº«ä¸­çé¯èª¤é¡åãæåçèªæåº«åå« 49 åé¯èª¤ï¼åæ¬ä¸ç¨®é¡åï¼æ­£å­æ³ãå½¢æãå¥æ³ãèªç¾©ãæ¨é»ç¬¦èãåä½µåæåãTibyan èªæåº«åå«ç´ 600 K åè©åã

##### **On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data**
2411.04586v1 by Aitor Martinez-Seras, Javier Del Ser, Alain Andres, Pablo Garcia-Bringas

Robustness is a fundamental aspect for developing safe and trustworthy
models, particularly when they are deployed in the open world. In this work we
analyze the inherent capability of one-stage object detectors to robustly
operate in the presence of out-of-distribution (OoD) data. Specifically, we
propose a novel detection algorithm for detecting unknown objects in image
data, which leverages the features extracted by the model from each sample.
Differently from other recent approaches in the literature, our proposal does
not require retraining the object detector, thereby allowing for the use of
pretrained models. Our proposed OoD detector exploits the application of
supervised dimensionality reduction techniques to mitigate the effects of the
curse of dimensionality on the features extracted by the model. Furthermore, it
utilizes high-resolution feature maps to identify potential unknown objects in
an unsupervised fashion. Our experiments analyze the Pareto trade-off between
the performance detecting known and unknown objects resulting from different
algorithmic configurations and inference confidence thresholds. We also compare
the performance of our proposed algorithm to that of logits-based post-hoc OoD
methods, as well as possible fusion strategies. Finally, we discuss on the
competitiveness of all tested methods against state-of-the-art OoD approaches
for object detection models over the recently published Unknown Object
Detection benchmark. The obtained results verify that the performance of
avant-garde post-hoc OoD detectors can be further improved when combined with
our proposed algorithm.

æè¦ï¼ç©©å¥æ§æ¯éç¼å®å¨åå¼å¾ä¿¡è³´æ¨¡åçåºæ¬é¢åï¼ç¹å¥æ¯ç¶éäºæ¨¡åé¨ç½²å¨éæ¾çä¸çä¸­ãå¨éé å·¥ä½ä¸­ï¼æååæäºå®éæ®µç®æ¨åµæ¸¬å¨å¨å­å¨éåå¸ (OoD) è³æçææ³ä¸ç©©å¥éä½çå§å¨è½åãå·é«ä¾èªªï¼æåæåºäºä¸ç¨®æ°ç©çåµæ¸¬æ¼ç®æ³ï¼ç¨æ¼åµæ¸¬å½±åè³æä¸­çæªç¥ç©ä»¶ï¼å®å©ç¨æ¨¡åå¾æ¯åæ¨£æ¬ä¸­æåçç¹å¾µãèæç»ä¸­å¶ä»è¿ææ¹æ³ä¸åï¼æåçæè­°ä¸éè¦éæ°è¨ç·´ç®æ¨åµæ¸¬å¨ï¼å¾èåè¨±ä½¿ç¨é è¨ç·´æ¨¡åãæåæåºç OoD åµæ¸¬å¨å©ç¨ç£ç£éç¶­æè¡çæç¨ä¾æ¸è¼ç¶­åº¦è©åå°æ¨¡åæåçç¹å¾µçå½±é¿ãæ­¤å¤ï¼å®å©ç¨é«è§£æåº¦ç¹å¾µåä»¥éç£ç£çæ¹å¼è­å¥æ½å¨çæªç¥ç©ä»¶ãæåçå¯¦é©åæäºå¸ç´¯ææ¬è¡¡ï¼å¨ä¸åæ¼ç®æ³çµæåæ¨è«ä¿¡å¿é¾å¼ä¸åµæ¸¬å·²ç¥åæªç¥ç©ä»¶çæè½ãæåéå°æåæåºçæ¼ç®æ³çæè½èåºæ¼éè¼¯çå¾è¨­ OoD æ¹æ³ä»¥åå¯è½çèåç­ç¥é²è¡æ¯è¼ãæå¾ï¼æåè¨è«äºæææ¸¬è©¦æ¹æ³å¨éå°ç©ä»¶åµæ¸¬æ¨¡åçææ° OoD æ¹æ³çç«¶ç­åï¼ä»¥åæè¿ç¼è¡¨çæªç¥ç©ä»¶åµæ¸¬åºæºãç²å¾ççµæé©è­äºç¶èæåæåºçæ¼ç®æ³çµåæï¼åè¡çå¾è¨­ OoD åµæ¸¬å¨çæè½å¯ä»¥é²ä¸æ­¥æé«ã

##### **The State and Fate of Summarization Datasets**
2411.04585v1 by Noam Dahan, Gabriel Stanovsky

Automatic summarization has consistently attracted attention, due to its
versatility and wide application in various downstream tasks. Despite its
popularity, we find that annotation efforts have largely been disjointed, and
have lacked common terminology. Consequently, it is challenging to discover
existing resources or identify coherent research directions. To address this,
we survey a large body of work spanning 133 datasets in over 100 languages,
creating a novel ontology covering sample properties, collection methods and
distribution. With this ontology we make key observations, including the lack
in accessible high-quality datasets for low-resource languages, and the field's
over-reliance on the news domain and on automatically collected distant
supervision. Finally, we make available a web interface that allows users to
interact and explore our ontology and dataset collection, as well as a template
for a summarization data card, which can be used to streamline future research
into a more coherent body of work.

æè¦ï¼èªåæè¦ä¸ç´ååéæ³¨ï¼å çºå®å·æå¤åè½æ§ï¼ä¸å»£æ³æç¨æ¼åç¨®ä¸æ¸¸ä»»åãåç®¡å®å¾åæ­¡è¿ï¼ä½æåç¼ç¾è¨»è§£å·¥ä½å¨å¾å¤§ç¨åº¦ä¸æ¯è«ç¯çï¼ä¸¦ä¸ç¼ºä¹éç¨çè¡èªãå æ­¤ï¼å¾é£ç¼ç¾ç¾æè³æºæç¢ºå®é£è²«çç ç©¶æ¹åãçºäºè§£æ±ºéååé¡ï¼æåèª¿æ¥äºæ¶µè 100 å¤ç¨®èªè¨ç 133 åè³æéçå¤§éå·¥ä½ï¼åµå»ºäºä¸åæ¶µèç¯ä¾å±¬æ§ãæ¶éæ¹æ³ååä½çæ°ç©æ¬é«è«ãæäºéåæ¬é«è«ï¼æåååºäºééµè§å¯ï¼åæ¬ç¼ºä¹ä½è³æºèªè¨çå¯è¨ªåé«åè³ªè³æéï¼ä»¥åè©²é åéåº¦ä¾è³´æ°èé ååèªåæ¶éçé ç¨ç£ç£ãæå¾ï¼æåæä¾äºä¸å Web ä»é¢ï¼åè¨±ä½¿ç¨èäºåä¸¦æ¢ç´¢æåçæ¬é«è«åè³æéæ¶éï¼ä»¥åä¸åæè¦è³æå¡ç¯æ¬ï¼å¯ç¨æ¼ç°¡åæªä¾ç ç©¶ï¼ä½¿å¶æçºä¸åæ´é£è²«çå·¥ä½ä¸»é«ã

##### **Interpreting the Learned Model in MuZero Planning**
2411.04580v1 by Hung Guei, Yan-Ru Ju, Wei-Yu Chen, Ti-Rong Wu

MuZero has achieved superhuman performance in various games by using a
dynamics network to predict environment dynamics for planning, without relying
on simulators. However, the latent states learned by the dynamics network make
its planning process opaque. This paper aims to demystify MuZero's model by
interpreting the learned latent states. We incorporate observation
reconstruction and state consistency into MuZero training and conduct an
in-depth analysis to evaluate latent states across two board games: 9x9 Go and
Outer-Open Gomoku, and three Atari games: Breakout, Ms. Pacman, and Pong. Our
findings reveal that while the dynamics network becomes less accurate over
longer simulations, MuZero still performs effectively by using planning to
correct errors. Our experiments also show that the dynamics network learns
better latent states in board games than in Atari games. These insights
contribute to a better understanding of MuZero and offer directions for future
research to improve the playing performance, robustness, and interpretability
of the MuZero algorithm.

æè¦ï¼MuZero å©ç¨åæç¶²è·¯ä¾é æ¸¬ç°å¢åæä»¥é²è¡è¦åï¼å¨åç¨®éæ²ä¸­éå°äºè¶è¶äººé¡çè¡¨ç¾ï¼èç¡éä¾è³´æ¨¡æ¬å¨ãç¶èï¼åæç¶²è·¯æå­¸ç¿çæ½å¨çæä½¿å¶è¦åéç¨ä¸éæãæ¬ææ¨å¨ééè§£è®å­¸ç¿å°çæ½å¨çæä¾æ­é MuZero æ¨¡åçç¥ç§é¢ç´ãæåå°è§å¯éå»ºåçæä¸è´æ§ç´å¥ MuZero è¨ç·´ï¼ä¸¦é²è¡æ·±å¥åæä»¥è©ä¼°å©åæ£ç¤éæ²ï¼9x9 åæ£åéæ¾å¼äºå­æ£ï¼åä¸å Atari éæ²ï¼BreakoutãMs. Pacman å Pongï¼ä¸­çæ½å¨çæãæåçç¼ç¾æ­ç¤ºï¼åç®¡åæç¶²è·¯å¨è¼é·çæ¨¡æ¬ä¸­è®å¾ä¸é£éº¼æºç¢ºï¼ä½ MuZero ä»è½ééè¦åä¾ä¿®æ­£é¯èª¤ï¼ææå·è¡ãæåçå¯¦é©éè¡¨æï¼åæç¶²è·¯å¨æ£ç¤éæ²ä¸­å­¸ç¿çæ½å¨çææ¯å¨ Atari éæ²ä¸­æ´å¥½ãéäºè¦è§£æå©æ¼æåæ´æ·±å¥å°äºè§£ MuZeroï¼ä¸¦çºæªä¾çç ç©¶æä¾äºæ¹åï¼ä»¥æ¹å MuZero æ¼ç®æ³çéæ²è¡¨ç¾ãç©©å¥æ§åå¯è§£éæ§ã

##### **Multistage Fine-tuning Strategies for Automatic Speech Recognition in Low-resource Languages**
2411.04573v1 by Leena G Pillai, Kavya Manohar, Basil K Raju, Elizabeth Sherly

This paper presents a novel multistage fine-tuning strategy designed to
enhance automatic speech recognition (ASR) performance in low-resource
languages using OpenAI's Whisper model. In this approach we aim to build ASR
model for languages with limited digital resources by sequentially adapting the
model across linguistically similar languages. We experimented this on the
Malasar language, a Dravidian language spoken by approximately ten thousand
people in the Western Ghats of South India. Malasar language faces critical
challenges for technological intervention due to its lack of a native script
and absence of digital or spoken data resources. Working in collaboration with
Wycliffe India and Malasar community members, we created a spoken Malasar
corpus paired with transcription in Tamil script, a closely related major
language. In our approach to build ASR model for Malasar, we first build an
intermediate Tamil ASR, leveraging higher data availability for Tamil annotated
speech. This intermediate model is subsequently fine-tuned on Malasar data,
allowing for more effective ASR adaptation despite limited resources. The
multistage fine-tuning strategy demonstrated significant improvements over
direct fine-tuning on Malasar data alone, achieving a word error rate (WER) of
51.9%, which is 4.5% absolute reduction when compared to the direct fine-tuning
method. Further a WER reduction to 47.3% was achieved through punctuation
removal in post-processing, which addresses formatting inconsistencies that
impact evaluation. Our results underscore the effectiveness of sequential
multistage fine-tuning combined with targeted post-processing as a scalable
strategy for ASR system development in low-resource languages, especially where
linguistic similarities can be leveraged to bridge gaps in training data.

æè¦ï¼<paragraph>æ¬ææåºäºä¸ç¨®æ°ç©çå¤éæ®µå¾®èª¿ç­ç¥ï¼æ¨å¨ä½¿ç¨ OpenAI ç Whisper æ¨¡åå¢å¼·ä½è³æºèªè¨ä¸­çèªåèªé³è­å¥ (ASR) æè½ãå¨æ­¤æ¹æ³ä¸­ï¼æåæ¨å¨ééè·¨èªè¨ç¸ä¼¼èªè¨å¾ªåºæ¼¸å¹åº¦å°èª¿æ´æ¨¡åï¼çºè³æºæéçèªè¨å»ºç« ASR æ¨¡åãæåå¨é¦¬æè©ç¾èªä¸é²è¡äºå¯¦é©ï¼é¦¬æè©ç¾èªæ¯ä¸ç¨®å¾·æå¨èªï¼ç±åå°åº¦è¥¿é«æ­¢å±±èç´ä¸è¬äººä½¿ç¨ãç±æ¼é¦¬æè©ç¾èªç¼ºä¹åçæå­ï¼ä¸æ²ææ¸ä½æå£èªè³æè³æºï¼å æ­¤é¢è¨æè¡ä»å¥çå´å³»ææ°ãæåè Wycliffe India åé¦¬æè©ç¾ç¤¾åæå¡åä½ï¼å»ºç«äºä¸åå£èªé¦¬æè©ç¾èªèªæåº«ï¼ä¸¦éä¸ä»¥æ³°ç±³ç¾æï¼ä¸ç¨®å¯åç¸éçä¸»è¦èªè¨ï¼æ¸å¯«çè½éãå¨æåå»ºç«é¦¬æè©ç¾èª ASR æ¨¡åçæ¹æ³ä¸­ï¼æåé¦åå»ºç«ä¸åä¸­éæ³°ç±³ç¾èª ASRï¼å©ç¨æ³°ç±³ç¾èªæ¨è¨»èªé³è¼é«çè³æå¯ç¨æ§ãéåä¸­éæ¨¡åé¨å¾å¨é¦¬æè©ç¾èªè³æä¸é²è¡å¾®èª¿ï¼åç®¡è³æºæéï¼ä»è½æ´ææå°èª¿æ´ ASRãå¤éæ®µå¾®èª¿ç­ç¥è­æäºèåå°é¦¬æè©ç¾èªè³æé²è¡ç´æ¥å¾®èª¿ç¸æ¯ï¼æé¡¯èçæ¹åï¼éå° 51.9% çè©èªé¯èª¤ç (WER)ï¼èç´æ¥å¾®èª¿æ¹æ³ç¸æ¯ï¼çµå°éä½äº 4.5%ãæ­¤å¤ï¼ééå¾èçä¸­çæ¨é»ç¬¦èç§»é¤ï¼WER é²ä¸æ­¥éä½è³ 47.3%ï¼éè§£æ±ºäºå½±é¿è©ä¼°çæ ¼å¼ä¸ä¸è´åé¡ãæåççµæå¼·èª¿äºå¾ªåºå¤éæ®µå¾®èª¿çµåç®æ¨å¾èçä½çºä½è³æºèªè¨ä¸­ ASR ç³»çµ±éç¼çå¯æ´åç­ç¥çæææ§ï¼ç¹å¥æ¯å¨èªè¨ç¸ä¼¼æ§å¯ç¨æ¼å½åè¨ç·´è³æå·®è·çææ³ä¸ã</paragraph>

##### **Impact of Label Noise on Learning Complex Features**
2411.04569v1 by Rahul Vashisht, P. Krishna Kumar, Harsha Vardhan Govind, Harish G. Ramaswamy

Neural networks trained with stochastic gradient descent exhibit an inductive
bias towards simpler decision boundaries, typically converging to a narrow
family of functions, and often fail to capture more complex features. This
phenomenon raises concerns about the capacity of deep models to adequately
learn and represent real-world datasets. Traditional approaches such as
explicit regularization, data augmentation, architectural modifications, etc.,
have largely proven ineffective in encouraging the models to learn diverse
features. In this work, we investigate the impact of pre-training models with
noisy labels on the dynamics of SGD across various architectures and datasets.
We show that pretraining promotes learning complex functions and diverse
features in the presence of noise. Our experiments demonstrate that
pre-training with noisy labels encourages gradient descent to find alternate
minima that do not solely depend upon simple features, rather learns more
complex and broader set of features, without hurting performance.

æè¦ï¼ç¥ç¶ç¶²è·¯ä½¿ç¨é¨æ©æ¢¯åº¦ä¸éè¨ç·´æå±ç¾åºå°è¼ç°¡å®æ±ºç­éççæ­¸ç´åèª¤ï¼éå¸¸ææ¶æå°çªå°çå½æ¸æï¼èä¸ç¶å¸¸ç¡æ³ææå°è¼è¤éçç¹å¾µãæ­¤ç¾è±¡å¼ç¼äºå°æ·±åº¦æ¨¡åæ¯å¦å·åè¶³å¤ è½åååå­¸ç¿ååç¾çå¯¦ä¸çè³æéççæ®ãå³çµ±æ¹æ³ï¼ä¾å¦æç¢ºæ­£ååãè³ææ´åãæ¶æ§ä¿®æ¹ç­ï¼å¨é¼åµæ¨¡åå­¸ç¿å¤æ¨£åç¹å¾µæ¹é¢å·²æ®éè¢«è­æç¡æãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºä½¿ç¨æéè¨æ¨ç±¤é åè¨ç·´æ¨¡åå°åç¨®æ¶æ§åè³æéä¸­ç SGD åæçå½±é¿ãæåè­æäºé åè¨ç·´æå¨æéè¨çææ³ä¸ä¿é²å­¸ç¿è¤éå½æ¸åå¤æ¨£åç¹å¾µãæåçå¯¦é©è­æäºä½¿ç¨æéè¨æ¨ç±¤é²è¡é åè¨ç·´æé¼åµæ¢¯åº¦ä¸éå°æ¾ä¸å®å¨ä¾è³´æ¼ç°¡å®ç¹å¾µçæ¿ä»£æå°å¼ï¼èæå­¸ç¿æ´è¤éä¸æ´å»£æ³çç¹å¾µéï¼ä¸ä¸ææå®³æè½ã

##### **A Generalisation of Voter Model: Influential Nodes and Convergence Properties**
2411.04564v1 by Abhiram Manohara, Ahad N. Zehmakan

Consider an undirected graph G, representing a social network, where each
node is blue or red, corresponding to positive or negative opinion on a topic.
In the voter model, in discrete time rounds, each node picks a neighbour
uniformly at random and adopts its colour. Despite its significant popularity,
this model does not capture some fundamental real-world characteristics such as
the difference in the strengths of individuals connections, individuals with
neutral opinion on a topic, and individuals who are reluctant to update their
opinion. To address these issues, we introduce and study a generalisation of
the voter model. Motivating by campaigning strategies, we study the problem of
selecting a set of seeds blue nodes to maximise the expected number of blue
nodes after some rounds. We prove that the problem is NP- hard and provide a
polynomial time approximation algorithm with the best possible approximation
guarantee. Our experiments on real-world and synthetic graph data demonstrate
that the proposed algorithm outperforms other algorithms. We also investigate
the convergence properties of the model. We prove that the process could take
an exponential number of rounds to converge. However, if we limit ourselves to
strongly connected graphs, the convergence time is polynomial and the period
(the number of states in convergence) divides the length of all cycles in the
graph.

æè¦ï¼<paragraph>èæ®ä¸åç¡åå Gï¼è¡¨ç¤ºä¸åç¤¾äº¤ç¶²è·¯ï¼å¶ä¸­æ¯åç¯é»çºèè²æç´è²ï¼å°ææ¼å°ä¸åä¸»é¡çæ­£é¢æè² é¢æè¦ãå¨æç¥¨èæ¨¡åä¸­ï¼å¨é¢æ£æéååä¸­ï¼æ¯åç¯é»é¨æ©é¸æä¸åé°å±ä¸¦æ¡ç¨å¶é¡è²ãåç®¡å®ç¸ç¶åæ­¡è¿ï¼ä½æ­¤æ¨¡åä¸¦æªææå°ä¸äºåºæ¬çç¾å¯¦ä¸çç¹å¾µï¼ä¾å¦åäººé£æ¥å¼·åº¦ãå°ä¸»é¡æä¸­ç«æè¦çåäººä»¥åä¸é¡ææ´æ°å¶æè¦çåäººãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥ä¸¦ç ç©¶äºæç¥¨èæ¨¡åçæ¦æ¬ãèç±ç«¶é¸ç­ç¥ï¼æåç ç©¶äºé¸æä¸çµèè²ç¨®å­ç¯é»ä»¥æå¤§åå¤è¼ªå¾èè²ç¯é»çé ææ¸éçåé¡ãæåè­ææ­¤åé¡æ¯ NP é£çï¼ä¸¦æä¾äºä¸åå·ææä½³å¯è½è¿ä¼¼ä¿è­çå¤é å¼æéè¿ä¼¼æ¼ç®æ³ãæåå¨çå¯¦ä¸çååæåå½¢è³æä¸çå¯¦é©è­æï¼ææåºçæ¼ç®æ³åªæ¼å¶ä»æ¼ç®æ³ãæåä¹ç ç©¶äºæ¨¡åçæ¶ææ§è³ªãæåè­ææ­¤ç¨åºå¯è½éè¦ææ¸è¼ªæ¸æè½æ¶æãç¶èï¼å¦ææåå°èªå·±éå¶å¨å¼·é£éåå½¢ï¼åæ¶ææéæ¯å¤é å¼çï¼ä¸é±æï¼æ¶æä¸­ççææ¸ï¼é¤ä»¥åå½¢ä¸­ææé±æçé·åº¦ã</paragraph>

##### **Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning**
2411.04562v1 by Marvin Alles, Philip Becker-Ehmck, Patrick van der Smagt, Maximilian Karl

In offline reinforcement learning, a policy is learned using a static dataset
in the absence of costly feedback from the environment. In contrast to the
online setting, only using static datasets poses additional challenges, such as
policies generating out-of-distribution samples. Model-based offline
reinforcement learning methods try to overcome these by learning a model of the
underlying dynamics of the environment and using it to guide policy search. It
is beneficial but, with limited datasets, errors in the model and the issue of
value overestimation among out-of-distribution states can worsen performance.
Current model-based methods apply some notion of conservatism to the Bellman
update, often implemented using uncertainty estimation derived from model
ensembles. In this paper, we propose Constrained Latent Action Policies (C-LAP)
which learns a generative model of the joint distribution of observations and
actions. We cast policy learning as a constrained objective to always stay
within the support of the latent action distribution, and use the generative
capabilities of the model to impose an implicit constraint on the generated
actions. Thereby eliminating the need to use additional uncertainty penalties
on the Bellman update and significantly decreasing the number of gradient steps
required to learn a policy. We empirically evaluate C-LAP on the D4RL and
V-D4RL benchmark, and show that C-LAP is competitive to state-of-the-art
methods, especially outperforming on datasets with visual observations.

æè¦ï¼å¨é¢ç·å¼·åå­¸ç¿ä¸­ï¼æä½¿ç¨éæè³æéä¾å­¸ç¿æ¿ç­ï¼èä¸æå¾ç°å¢ä¸­ç²å¾æè²´çåé¥ãèç·ä¸è¨­å®ç¸åï¼åä½¿ç¨éæè³æéæç¢çé¡å¤çææ°ï¼ä¾å¦æ¿ç­ç¢çåºåä½å¤çç¯ä¾ãåºæ¼æ¨¡åçé¢ç·å¼·åå­¸ç¿æ¹æ³æåè©¦ééå­¸ç¿ç°å¢åºç¤åæçæ¨¡åä¸¦ä½¿ç¨è©²æ¨¡åä¾å¼å°æ¿ç­æå°ä¾åæéäºææ°ãéæ¯æççï¼ä½å°æ¼æéçè³æéï¼æ¨¡åä¸­çé¯èª¤ååºåä½çæçå¹å¼é«ä¼°åé¡ææ¡åæè½ãç®åçåºæ¼æ¨¡åçæ¹æ³æå°è²ç¾æ¼æ´æ°å¥ç¨ä¸äºä¿å®æ¦å¿µï¼éå¸¸æä½¿ç¨å¾æ¨¡åæ´é«ä¸­è¡ççä¸ç¢ºå®æ§ä¼°è¨ä¾å¯¦ä½ãå¨æ¬æä¸­ï¼æåæåºåç´ææ½å¨åä½æ¿ç­ (C-LAP)ï¼å®æå­¸ç¿è§æ¸¬å¼ååä½çè¯ååä½ççææ¨¡åãæåå°æ¿ç­å­¸ç¿è¨­å®çºåç´æç®æ¨ï¼ä»¥å§çµä¿æå¨æ½å¨åä½åä½çæ¯æ´ç¯åå§ï¼ä¸¦ä½¿ç¨æ¨¡åççæè½åå°ç¢ççåä½æ½å é±å¼ç´æãå¾èæ¶é¤äºå°è²ç¾æ¼æ´æ°ä½¿ç¨é¡å¤ä¸ç¢ºå®æ§æ²ç½°çéæ±ï¼ä¸¦å¤§å¹æ¸å°å­¸ç¿æ¿ç­æéçæ¢¯åº¦æ­¥é©æ¸ãæåå¨ D4RL å V-D4RL åºæºä¸å° C-LAP é²è¡ç¶é©è©ä¼°ï¼ä¸¦é¡¯ç¤º C-LAP å¯èæåé²çæ¹æ³ç«¶ç­ï¼ç¹å¥æ¯å¨å·æè¦è¦ºè§æ¸¬å¼çè³æéä¸è¡¨ç¾åºè²ã

##### **Pruning Literals for Highly Efficient Explainability at Word Level**
2411.04557v1 by Rohan Kumar Yadav, Bimal Bhattarai, Abhik Jana, Lei Jiao, Seid Muhie Yimam

Designing an explainable model becomes crucial now for Natural Language
Processing(NLP) since most of the state-of-the-art machine learning models
provide a limited explanation for the prediction. In the spectrum of an
explainable model, Tsetlin Machine(TM) is promising because of its capability
of providing word-level explanation using proposition logic. However, concern
rises over the elaborated combination of literals (propositional logic) in the
clause that makes the model difficult for humans to comprehend, despite having
a transparent learning process. In this paper, we design a post-hoc pruning of
clauses that eliminate the randomly placed literals in the clause thereby
making the model more efficiently interpretable than the vanilla TM.
Experiments on the publicly available YELP-HAT Dataset demonstrate that the
proposed pruned TM's attention map aligns more with the human attention map
than the vanilla TM's attention map. In addition, the pairwise similarity
measure also surpasses the attention map-based neural network models. In terms
of accuracy, the proposed pruning method does not degrade the accuracy
significantly but rather enhances the performance up to 4% to 9% in some test
data.

æè¦ï¼<paragraph>å¨èªç¶èªè¨èçï¼NLPï¼ä¸­ï¼è¨­è¨ä¸åå¯è§£éçæ¨¡åç¾å¨è®å¾è³ééè¦ï¼å çºå¤§å¤æ¸æåé²çæ©å¨å­¸ç¿æ¨¡åå°é æ¸¬æä¾çè§£éæéãå¨å¯è§£éæ¨¡åçç¯çä¸­ï¼Tsetlin æ©å¨ï¼TMï¼å å¶ä½¿ç¨å½é¡éè¼¯æä¾å­åç­ç´è§£éçè½åèå¾æåæ¯ãç¶èï¼åç®¡å­¸ç¿éç¨éæï¼ä½å°å­å¥ä¸­ç²¾ç´°çå­é¢éï¼å½é¡éè¼¯ï¼çµåçéæ³¨å»è®äººé¡é£ä»¥çè§£è©²æ¨¡åãå¨æ¬æä¸­ï¼æåè¨­è¨äºä¸åå­å¥çå¾è¨­åªæï¼æ¶é¤äºå­å¥ä¸­é¨æ©æ¾ç½®çå­é¢éï¼å¾èä½¿æ¨¡åæ¯é¦è TM æ´å®¹æè§£éãå¨å¬éç YELP-HAT è³æéä¸çå¯¦é©è¡¨æï¼ææåºçåªæ TM çæ³¨æååæ¯é¦è TM çæ³¨æååæ´ç¬¦åäººé¡çæ³¨æååãæ­¤å¤ï¼æå°ç¸ä¼¼æ§æ¸¬éä¹è¶è¶äºåºæ¼æ³¨æååçç¥ç¶ç¶²è·¯æ¨¡åãå¨æºç¢ºæ§æ¹é¢ï¼ææåºçåªææ¹æ³ä¸¦æªé¡¯èéä½æºç¢ºæ§ï¼åèå¨æäºæ¸¬è©¦è³æä¸­å°æè½æé«äº 4% å° 9%ã</paragraph>

##### **Vision Language Models are In-Context Value Learners**
2411.04549v1 by Yecheng Jason Ma, Joey Hejna, Ayzaan Wahid, Chuyuan Fu, Dhruv Shah, Jacky Liang, Zhuo Xu, Sean Kirmani, Peng Xu, Danny Driess, Ted Xiao, Jonathan Tompson, Osbert Bastani, Dinesh Jayaraman, Wenhao Yu, Tingnan Zhang, Dorsa Sadigh, Fei Xia

Predicting temporal progress from visual trajectories is important for
intelligent robots that can learn, adapt, and improve. However, learning such
progress estimator, or temporal value function, across different tasks and
domains requires both a large amount of diverse data and methods which can
scale and generalize. To address these challenges, we present Generative Value
Learning (\GVL), a universal value function estimator that leverages the world
knowledge embedded in vision-language models (VLMs) to predict task progress.
Naively asking a VLM to predict values for a video sequence performs poorly due
to the strong temporal correlation between successive frames. Instead, GVL
poses value estimation as a temporal ordering problem over shuffled video
frames; this seemingly more challenging task encourages VLMs to more fully
exploit their underlying semantic and temporal grounding capabilities to
differentiate frames based on their perceived task progress, consequently
producing significantly better value predictions. Without any robot or task
specific training, GVL can in-context zero-shot and few-shot predict effective
values for more than 300 distinct real-world tasks across diverse robot
platforms, including challenging bimanual manipulation tasks. Furthermore, we
demonstrate that GVL permits flexible multi-modal in-context learning via
examples from heterogeneous tasks and embodiments, such as human videos. The
generality of GVL enables various downstream applications pertinent to
visuomotor policy learning, including dataset filtering, success detection, and
advantage-weighted regression -- all without any model training or finetuning.

æè¦ï¼é æ¸¬è¦è¦ºè»è·¡çæéé²åº¦å°æ¼è½å­¸ç¿ãé©æåæ¹é²çæºæ§åæ©å¨äººèè¨ååéè¦ãç¶èï¼å­¸ç¿æ­¤é¡é²åº¦ä¼°è¨å¨ææéå¹å¼å½æ¸ï¼å¨ä¸åçä»»ååé åä¸­éè¦å¤§éå¤æ¨£åçè³æåå¯æ´åä¸å¯æ¦æ¬çæ¹æ³ãçºäºæå°éäºææ°ï¼æåæåºäºçæå¼å¹å¼å­¸ç¿ (\GVL)ï¼éæ¯ä¸åéç¨å¹å¼å½æ¸ä¼°è¨å¨ï¼å®å©ç¨åµå¥å¨è¦è¦ºèªè¨æ¨¡å (VLM) ä¸­çä¸çç¥è­ä¾é æ¸¬ä»»åé²åº¦ãå¤©çå°è¦æ± VLM é æ¸¬å½±çåºåçå¹å¼æè¡¨ç¾ä¸ä½³ï¼å çºé£çºå¹ä¹éæå¾å¼·çæéç¸éæ§ãç¸åå°ï¼GVL å°å¹å¼ä¼°è¨è¨­å®çºæäºå½±çå¹çæåºæåºåé¡ï¼éåçä¼¼æ´å·ææ°æ§çä»»åé¼åµ VLM æ´ååå°å©ç¨å¶åºå±¤èªç¾©åæåºåºç¤åè½ï¼æ ¹ææç¥ä»»åé²åº¦ä¾ååå¹ï¼å¾èç¢çé¡¯èæ´å¥½çå¹å¼é æ¸¬ãGVL ç¡éä»»ä½æ©å¨äººæä»»åç¹å®è¨ç·´ï¼å³å¯å¨æå¢ä¸­é²è¡é¶æ¬¡å­¸ç¿åå°éå­¸ç¿ï¼é æ¸¬è¶é 300 åè·¨è¶ä¸åæ©å¨äººå¹³å°ççå¯¦ä¸çä»»åçææå¹å¼ï¼åæ¬å·æææ°æ§çéææä½ä»»åãæ­¤å¤ï¼æåè­æ GVL åè¨±ééç°è³ªä»»ååå·é«å¯¦ä¾ï¼ä¾å¦äººé¡å½±çï¼ä¸­çç¯ä¾é²è¡éæ´»çå¤æ¨¡å¼æå¢å­¸ç¿ãGVL çæ®éæ§æ¯æ´åç¨®èè¦åéåç­ç¥å­¸ç¿ç¸éçä¸æ¸¸æç¨ï¼åæ¬è³æééæ¿¾ãæåæª¢æ¸¬ååªå¢å æ¬åæ­¸ï¼ææéäºé½ä¸éè¦ä»»ä½æ¨¡åè¨ç·´æå¾®èª¿ã

##### **Best Practices for Distilling Large Language Models into BERT for Web Search Ranking**
2411.04539v1 by Dezhi Ye, Junwei Hu, Jiabin Fan, Bowen Tian, Jie Liu, Haijin Liang, Jin Ma

Recent studies have highlighted the significant potential of Large Language
Models (LLMs) as zero-shot relevance rankers. These methods predominantly
utilize prompt learning to assess the relevance between queries and documents
by generating a ranked list of potential documents. Despite their promise, the
substantial costs associated with LLMs pose a significant challenge for their
direct implementation in commercial search systems. To overcome this barrier
and fully exploit the capabilities of LLMs for text ranking, we explore
techniques to transfer the ranking expertise of LLMs to a more compact model
similar to BERT, using a ranking loss to enable the deployment of less
resource-intensive models. Specifically, we enhance the training of LLMs
through Continued Pre-Training, taking the query as input and the clicked title
and summary as output. We then proceed with supervised fine-tuning of the LLM
using a rank loss, assigning the final token as a representative of the entire
sentence. Given the inherent characteristics of autoregressive language models,
only the final token </s> can encapsulate all preceding tokens. Additionally,
we introduce a hybrid point-wise and margin MSE loss to transfer the ranking
knowledge from LLMs to smaller models like BERT. This method creates a viable
solution for environments with strict resource constraints. Both offline and
online evaluations have confirmed the efficacy of our approach, and our model
has been successfully integrated into a commercial web search engine as of
February 2024.

æè¦ï¼æè¿çç ç©¶å¼·èª¿äºå¤§åèªè¨æ¨¡å (LLM) ä½çºé¶æ¬¡å­¸ç¿ç¸éæ§æåºå¨çé¡¯èæ½åãéäºæ¹æ³ä¸»è¦å©ç¨æç¤ºå­¸ç¿ï¼ééç¢çæ½å¨æä»¶çæåºæ¸å®ï¼ä¾è©ä¼°æ¥è©¢èæä»¶ä¹éçç¸éæ§ãåç®¡å®åå¾æåéï¼ä½è LLM ç¸éçé¾å¤§ææ¬å°å®åå¨åæ¥­æå°ç³»çµ±ä¸­çç´æ¥å¯¦ä½æ§æéå¤§ææ°ãçºäºåææ­¤éç¤ä¸¦ååå©ç¨ LLM çæå­æåºåè½ï¼æåæ¢ç´¢äºå° LLM çæåºå°æ¥­ç¥è­è½ç§»å°æ´ç²¾ç°¡çæ¨¡åï¼é¡ä¼¼æ¼ BERTï¼çæè¡ï¼ä½¿ç¨æåºæå¤±ä¾å¯¦ç¾è³æºå¯éåº¦è¼ä½çæ¨¡åçé¨ç½²ãå·é«ä¾èªªï¼æåééæçºé è¨ç·´ä¾å¢å¼· LLM çè¨ç·´ï¼å°æ¥è©¢ä½çºè¼¸å¥ï¼ä¸¦å°é»æçæ¨é¡åæè¦ä½çºè¼¸åºãç¶å¾ï¼æåä½¿ç¨æåºæå¤±å° LLM é²è¡ç£ç£å¼å¾®èª¿ï¼å°æçµä»£å¹£æå®çºæ´åå¥å­çä»£è¡¨ãç±æ¼èªè¿´æ­¸èªè¨æ¨¡åçåºæç¹æ§ï¼åªææçµä»£å¹£ </s> æè½åæ¬ææåä¸åä»£å¹£ãæ­¤å¤ï¼æåå¼å¥äºæ··åé»å¼åéé MSE æå¤±ï¼å° LLM çæåºç¥è­è½ç§»å°è¼å°çæ¨¡åï¼å¦ BERTï¼ä¸­ãæ­¤æ¹æ³çºè³æºéå¶å´æ ¼çç°å¢åµé äºå¯è¡çè§£æ±ºæ¹æ¡ãé¢ç·åç·ä¸è©ä¼°é½è­å¯¦äºæåæ¹æ³çæææ§ï¼èæåçæ¨¡åå·²æ¼ 2024 å¹´ 2 ææåæ´åå°åæ¥­ç¶²è·¯æå°å¼æä¸­ã

##### **Meta-Reasoning Improves Tool Use in Large Language Models**
2411.04535v1 by Lisa Alazraki, Marek Rei

External tools help large language models (LLMs) succeed at tasks where they
would otherwise typically fail. In existing frameworks, LLMs learn tool use
either by in-context demonstrations or via full model fine-tuning on annotated
data. As these approaches do not easily scale, a recent trend is to abandon
them in favor of lightweight, parameter-efficient tuning paradigms. These
methods allow quickly alternating between the frozen LLM and its specialised
fine-tuned version, by switching on or off a handful of additional custom
parameters. Hence, we postulate that the generalization ability of the frozen
model can be leveraged to improve tool selection. We present Tool selECTion via
meta-reasONing (TECTON), a two-phase system that first reasons over a task
using a custom fine-tuned LM head and outputs candidate tools. Then, with the
custom head disabled, it meta-reasons (i.e., it reasons over the previous
reasoning process) to make a final choice. We show that TECTON results in
substantial gains - both in-distribution and out-of-distribution - on a range
of math reasoning datasets.

æè¦ï¼å¤é¨å·¥å·å¯åå©å¤§åèªè¨æ¨¡å (LLM) å¨å¶åæ¬éå¸¸æå¤±æçä»»åä¸­ç²å¾æåãå¨ç¾æçæ¶æ§ä¸­ï¼LLM ééæå¢ä¸­çç¤ºç¯æéééå°è¨»è§£è³æé²è¡å®æ´çæ¨¡åå¾®èª¿ä¾å­¸ç¿ä½¿ç¨å·¥å·ãç±æ¼éäºæ¹æ³ä¸ææ´å±ï¼å æ­¤æè¿çè¶¨å¢æ¯æ¾æ£å®åï¼è½èæ¡ç¨è¼éç´ãåæ¸é«æçå¾®èª¿ç¯ä¾ãéäºæ¹æ³åè¨±ééåç¨æåç¨å°æ¸é¡å¤çèªè¨åæ¸ï¼å¨åçµç LLM åå¶ç¶éå°éå¾®èª¿ççæ¬ä¹éå¿«éäº¤æ¿ãå æ­¤ï¼æååè¨­å¯ä»¥å©ç¨åçµæ¨¡åçæ³åè½åä¾æ¹åå·¥å·é¸æãæåæåºäºééåæ¨çé²è¡å·¥å·é¸æ (TECTON)ï¼éæ¯ä¸ååçºå©åéæ®µçç³»çµ±ï¼å®æåä½¿ç¨èªè¨å¾®èª¿ç LM é ­éå°ä»»åé²è¡æ¨çï¼ä¸¦è¼¸åºåé¸å·¥å·ãç¶å¾ï¼å¨åç¨èªè¨é ­çææ³ä¸ï¼å®æé²è¡åæ¨çï¼å³å°ååçæ¨çéç¨é²è¡æ¨çï¼ä»¥ååºæçµé¸æãæåè¡¨æ TECTON å¨ä¸ç³»åæ¸å­¸æ¨çè³æéä¸ç¢çäºå¯¦è³ªçæ¶çï¼ç¡è«æ¯å¨åä½å§éæ¯åä½å¤ã

##### **Tomato, Tomahto, Tomate: Measuring the Role of Shared Semantics among Subwords in Multilingual Language Models**
2411.04530v1 by Xinyu Zhang, Jing Lu, Vinh Q. Tran, Tal Schuster, Donald Metzler, Jimmy Lin

Human understanding of language is robust to different word choices as far as
they represent similar semantic concepts. To what extent does our human
intuition transfer to language models, which represent all subwords as distinct
embeddings? In this work, we take an initial step on measuring the role of
shared semantics among subwords in the encoder-only multilingual language
models (mLMs). To this end, we form "semantic tokens" by merging the
semantically similar subwords and their embeddings, and evaluate the updated
mLMs on 5 heterogeneous multilingual downstream tasks. Results show that the
general shared semantics could get the models a long way in making the
predictions on mLMs with different tokenizers and model sizes. Inspections on
the grouped subwords show that they exhibit a wide range of semantic
similarities, including synonyms and translations across many languages and
scripts. Lastly, we found the zero-shot results with semantic tokens are on par
or even better than the original models on certain classification tasks,
suggesting that the shared subword-level semantics may serve as the anchors for
cross-lingual transferring.

æè¦ï¼äººé¡å°èªè¨ççè§£åå°æ¼ä¸åçè©å½é¸ææ¯å¼·å¥çï¼åªè¦å®åä»£è¡¨ç¸ä¼¼çèªç¾©æ¦å¿µãæåçç´è¦ºå¨å¤å¤§ç¨åº¦ä¸å¯ä»¥è½ç§»å°èªè¨æ¨¡åï¼èèªè¨æ¨¡åå°ææå­è©è¡¨ç¤ºçºä¸åçåµå¥ï¼å¨éé å·¥ä½ä¸­ï¼æåè¸åºäºåæ­¥æ­¥é©ï¼æ¸¬éç·¨ç¢¼å¨å°ç¨å¤èªè¨èªè¨æ¨¡å (mLMs) ä¸­å­è©ä¹éå±äº«èªç¾©çè§è²ãçºæ­¤ï¼æåééåä½µèªç¾©ç¸ä¼¼çå­è©åå¶åµå¥ï¼å½¢æäºãèªç¾©æ¨è¨ãï¼ä¸¦å¨ 5 åç°è³ªå¤èªè¨ä¸æ¸¸ä»»åä¸è©ä¼°æ´æ°ç mLMsãçµæè¡¨æï¼éç¨çå±äº«èªç¾©å¯ä»¥è®æ¨¡åå¨ä½¿ç¨ä¸åæ¨è¨å¨åæ¨¡åå¤§å°ç mLMs ä¸é²è¡é æ¸¬æèµ°å¾å¾é ãå°åçµå­è©çæª¢æ¥è¡¨æï¼å®åå±ç¾åºå»£æ³çèªç¾©ç¸ä¼¼æ§ï¼åæ¬è¨±å¤èªè¨åè³æ¬ä¸­çåç¾©è©åç¿»è­¯ãæå¾ï¼æåç¼ç¾ä½¿ç¨èªç¾©æ¨è¨çé¶æ¬¡å­¸ç¿çµæèåå§æ¨¡åå¨æäºåé¡ä»»åä¸ç¸ç¶çè³æ´å¥½ï¼éè¡¨æå±äº«çå­è©ç´èªç¾©å¯ä»¥ä½çºè·¨èªè¨è½ç§»çé¨é»ã

##### **GenJoin: Conditional Generative Plan-to-Plan Query Optimizer that Learns from Subplan Hints**
2411.04525v1 by Pavel Sulimov, Claude Lehmann, Kurt Stockinger

Query optimization has become a research area where classical algorithms are
being challenged by machine learning algorithms. At the same time, recent
trends in learned query optimizers have shown that it is prudent to take
advantage of decades of database research and augment classical query
optimizers by shrinking the plan search space through different types of hints
(e.g. by specifying the join type, scan type or the order of joins) rather than
completely replacing the classical query optimizer with machine learning
models. It is especially relevant for cases when classical optimizers cannot
fully enumerate all logical and physical plans and, as an alternative, need to
rely on less robust approaches like genetic algorithms. However, even
symbiotically learned query optimizers are hampered by the need for vast
amounts of training data, slow plan generation during inference and unstable
results across various workload conditions. In this paper, we present GenJoin -
a novel learned query optimizer that considers the query optimization problem
as a generative task and is capable of learning from a random set of subplan
hints to produce query plans that outperform the classical optimizer. GenJoin
is the first learned query optimizer that significantly and consistently
outperforms PostgreSQL as well as state-of-the-art methods on two well-known
real-world benchmarks across a variety of workloads using rigorous machine
learning evaluations.

æè¦ï¼æ¥è©¢æä½³åå·²æçºä¸åç ç©¶é åï¼å¶ä¸­å¤å¸æ¼ç®æ³åå°æ©å¨å­¸ç¿æ¼ç®æ³çææ°ãåæï¼å·²å­¸ç¿æ¥è©¢æä½³åå¨çè¿æè¶¨å¢é¡¯ç¤ºï¼å¯©æå©ç¨æ¸åå¹´çè³æåº«ç ç©¶åééä¸åé¡åçæç¤ºï¼ä¾å¦ï¼ééæå®é£æ¥é¡åãææé¡åæé£æ¥é åºï¼ä¾ç¸®å°è¨ç«æå°ç©ºéï¼èéå®å¨ä»¥æ©å¨å­¸ç¿æ¨¡ååä»£å¤å¸æ¥è©¢æä½³åå¨ï¼æ¯ææºä¹èãéå°å¤å¸æä½³åå¨ç¡æ³å®å¨åèææéè¼¯åå¯¦é«è¨ç«ï¼ä¸éè¦ä¾è³´éºå³æ¼ç®æ³ç­è¼ä¸ç©©å¥çæ¹æ³ä½çºæ¿ä»£æ¹æ¡çææ³å°¤å¶ç¸éãç¶èï¼å³ä½¿æ¯å±çå­¸ç¿çæ¥è©¢æä½³åå¨ä¹åå°å¤§éè¨ç·´è³æéæ±ãæ¨è«æéçè¨ç«ç¢çç·©æ¢ä»¥åå¨åç¨®å·¥ä½è² è¼æ¢ä»¶ä¸çµæä¸ç©©å®çé»ç¤ãå¨æ¬æä¸­ï¼æåæåº GenJoinï¼éæ¯ä¸åæ°ç©çå·²å­¸ç¿æ¥è©¢æä½³åå¨ï¼å®å°æ¥è©¢æä½³ååé¡è¦çºçæä»»åï¼ä¸¦è½å¤ å¾ä¸çµé¨æ©å­è¨ç«æç¤ºä¸­å­¸ç¿ï¼ä»¥ç¢çåªæ¼å¤å¸æä½³åå¨çæ¥è©¢è¨ç«ãGenJoin æ¯ç¬¬ä¸åå·²å­¸ç¿æ¥è©¢æä½³åå¨ï¼å®é¡¯èä¸æçºåªæ¼ PostgreSQLï¼ä»¥åå¨ä½¿ç¨å´è¬¹æ©å¨å­¸ç¿è©ä¼°çåç¨®å·¥ä½è² è¼ä¸­ï¼æ¼å©åèåççå¯¦ä¸çåºæºæ¸¬è©¦ä¸çææ°æ¹æ³ã

##### **Continuous Sign Language Recognition System using Deep Learning with MediaPipe Holistic**
2411.04517v1 by Sharvani Srivastava, Sudhakar Singh, Pooja, Shiv Prakash

Sign languages are the language of hearing-impaired people who use visuals
like the hand, facial, and body movements for communication. There are
different signs and gestures representing alphabets, words, and phrases.
Nowadays approximately 300 sign languages are being practiced worldwide such as
American Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language
(ISL), and many more. Sign languages are dependent on the vocal language of a
place. Unlike vocal or spoken languages, there are no helping words in sign
language like is, am, are, was, were, will, be, etc. As only a limited
population is well-versed in sign language, this lack of familiarity of sign
language hinders hearing-impaired people from communicating freely and easily
with everyone. This issue can be addressed by a sign language recognition (SLR)
system which has the capability to translate the sign language into vocal
language. In this paper, a continuous SLR system is proposed using a deep
learning model employing Long Short-Term Memory (LSTM), trained and tested on
an ISL primary dataset. This dataset is created using MediaPipe Holistic
pipeline for tracking face, hand, and body movements and collecting landmarks.
The system recognizes the signs and gestures in real-time with 88.23% accuracy.

æè¦ï¼æèªæ¯è½éäººå£«çèªè¨ï¼ä»åä½¿ç¨è¦è¦º
ä¾å¦æé¨ãé¢é¨åèº«é«åä½é²è¡æºéãæ
ä¸åçç¬¦èåæå¢ä»£è¡¨å­æ¯ãå®è©åç­èªã
å¦ä»ï¼å¨ä¸çç´æ 300 ç¨®æèªæ­£å¨ä½¿ç¨ï¼ä¾å¦
ç¾åæèª (ASL)ãä¸­åæèª (CSL)ãå°åº¦æèª
(ISL) ç­ãæèªä¾è³´æ¼ä¸åå°æ¹çå£èªãèå£èªä¸å
èªè¨ï¼æèªä¸­æ²æå¹«å©è©ï¼ä¾å¦ isãamãareãwasãwereãwillãbe ç­ãç±æ¼åªæå°æ¸äººç²¾éæèªï¼éç¨®å°æèªçä¸çææé»ç¤è½éäººå£«èæ¯åäººèªç±è¼é¬å°äº¤æµãéååé¡å¯ä»¥ééæèªè­å¥ (SLR) ç³»çµ±ä¾è§£æ±ºï¼è©²ç³»çµ±å·æå°æèªç¿»è­¯æå£èªçè½åãå¨æ¬æä¸­ï¼ä½¿ç¨æ¡ç¨é·ç­æè¨æ¶ (LSTM) çæ·±åº¦å­¸ç¿æ¨¡åæåºäºä¸åé£çº SLR ç³»çµ±ï¼ä¸¦å¨ ISL åç´æ¸æéä¸é²è¡äºè¨ç·´åæ¸¬è©¦ãæ­¤æ¸æéä½¿ç¨ MediaPipe Holistic ç®¡éåµå»ºï¼ç¨æ¼è·è¹¤é¢é¨ãæé¨åèº«é«åä½ä¸¦æ¶éå°æ¨ãè©²ç³»çµ±å¯¦æè­å¥ç¬¦èåæå¢ï¼æºç¢ºççº 88.23%ã

##### **FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**
2411.04509v1 by Liangrui Pan, Mao Huang, Lian Wang, Pinle Qin, Shaoliang Peng

Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is
considered the gold standard for pathologists and medical practitioners for
tumor diagnosis, surgical planning, and post-operative assessment. With the
rapid advancement of deep learning technologies, the development of numerous
models based on convolutional neural networks and transformer-based models has
been applied to the precise segmentation of WSIs. However, due to privacy
regulations and the need to protect patient confidentiality, centralized
storage and processing of image data are impractical. Training a centralized
model directly is challenging to implement in medical settings due to these
privacy concerns.This paper addresses the dispersed nature and privacy
sensitivity of medical image data by employing a federated learning framework,
allowing medical institutions to collaboratively learn while protecting patient
privacy. Additionally, to address the issue of original data reconstruction
through gradient inversion during the federated learning training process,
differential privacy introduces noise into the model updates, preventing
attackers from inferring the contributions of individual samples, thereby
protecting the privacy of the training data.Experimental results show that the
proposed method, FedDP, minimally impacts model accuracy while effectively
safeguarding the privacy of cancer pathology image data, with only a slight
decrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%,
respectively. This approach facilitates cross-institutional collaboration and
knowledge sharing while protecting sensitive data privacy, providing a viable
solution for further research and application in the medical field.

æè¦ï¼èæ¨ç²¾åä¼ç´ï¼H&Eï¼æè²å¨åçååï¼WSIï¼è¢«èªçºæ¯ççå­¸å®¶åé«çå¾æ¥­äººå¡ç¨æ¼è«ç¤è¨ºæ·ãæè¡è¦ååè¡å¾è©ä¼°çé»éæ¨æºãé¨èæ·±åº¦å­¸ç¿æè¡çå¿«éé²å±ï¼åºæ¼å·ç©ç¥ç¶ç¶²è·¯ååºæ¼Transformerçæ¨¡åçç¾å¤æ¨¡åå·²è¢«æç¨æ¼ WSI çç²¾ç¢ºåå²ãç¶èï¼ç±æ¼é±ç§æ³è¦åä¿è­·æ£èæ©å¯æ§çéè¦ï¼éä¸­å¼å²å­åèçå½±åè³ææ¯ä¸åå¯¦éçãç±æ¼éäºé±ç§åé¡ï¼å¨é«çç°å¢ä¸­ç´æ¥è¨ç·´éä¸­å¼æ¨¡åé£ä»¥å¯¦æ½ãæ¬æééæ¡ç¨è¯åå­¸ç¿æ¡æ¶ä¾è§£æ±ºé«çå½±åè³æçåæ£æ§è³ªåé±ç§æææ§ï¼åè¨±é«çæ©æ§å¨ä¿è­·æ£èé±ç§çåæé²è¡åä½å­¸ç¿ãæ­¤å¤ï¼çºäºè§£æ±ºè¯åå­¸ç¿è¨ç·´éç¨ä¸­ééæ¢¯åº¦åè½é²è¡åå§è³æéå»ºçåé¡ï¼å·®åé±ç§æå¨æ¨¡åæ´æ°ä¸­å¼å¥éè¨ï¼é²æ­¢æ»æèæ¨æ·åå¥æ¨£æ¬çè²¢ç»ï¼å¾èä¿è­·è¨ç·´è³æçé±ç§ãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³ FedDP å°æ¨¡åæºç¢ºåº¦çå½±é¿æå°ï¼åæææä¿è­·äºççççå½±åè³æçé±ç§ï¼DiceãJaccard å Acc ææ¸åå¥åç¥å¾®ä¸éäº 0.55%ã0.63% å 0.42%ãéç¨®æ¹æ³ä¿é²äºæ©æ§éçåä½åç¥è­å±äº«ï¼åæä¿è­·äºææè³æçé±ç§ï¼çºé«çé åçé²ä¸æ­¥ç ç©¶åæç¨æä¾äºå¯è¡çè§£æ±ºæ¹æ¡ã

##### **Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model**
2411.04496v1 by Young-Jun Lee, Dokyong Lee, Junyoung Youn, Kyeongjin Oh, Ho-Jin Choi

To increase social bonding with interlocutors, humans naturally acquire the
ability to respond appropriately in a given situation by considering which
conversational skill is most suitable for the response - a process we call
skill-of-mind. For large language model (LLM)-based conversational agents,
planning appropriate conversational skills, as humans do, is challenging due to
the complexity of social dialogue, especially in interactive scenarios. To
address this, we propose a skill-of-mind-annotated conversation dataset, named
Multifaceted Skill-of-Mind, which includes multi-turn and multifaceted
conversational skills across various interactive scenarios (e.g., long-term,
counseling, task-oriented), grounded in diverse social contexts (e.g.,
demographics, persona, rules of thumb). This dataset consists of roughly 100K
conversations. Using this dataset, we introduce a new family of
skill-of-mind-infused LLMs, named Thanos, with model sizes of 1B, 3B, and 8B
parameters. With extensive experiments, these models successfully demonstrate
the skill-of-mind process and exhibit strong generalizability in inferring
multifaceted skills across a variety of domains. Moreover, we show that Thanos
significantly enhances the quality of responses generated by LLM-based
conversational agents and promotes prosocial behavior in human evaluations.

æè¦ï¼çºäºå¢å èå°è©±èçç¤¾äº¤é£çµï¼äººé¡èªç¶æç¿å¾å¨ç¹å®ææ³ä¸é©ç¶å°åæçè½åï¼èéåªç¨®å°è©±æå·§æé©ååæï¼éé éç¨æåç¨±çºå¿æºæå·§ãå°æ¼å¤§åèªè¨æ¨¡å (LLM) çºåºç¤çå°è©±ä»£çä¾èªªï¼è¦åé©ç¶çå°è©±æå·§ï¼å°±åäººé¡ä¸æ¨£ï¼æ¯ä¸é ææ°ï¼å çºç¤¾äº¤å°è©±å¾è¤éï¼å°¤å¶æ¯å¨äºåå¼æå¢ä¸­ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åå¿æºæå·§è¨»è§£å°è©±è³æéï¼ç¨±çºå¤é¢åå¿æºæå·§ï¼å¶ä¸­åå«åç¨®äºåå¼æå¢ï¼ä¾å¦é·æãè«®è©¢ãä»¥ä»»åçºå°åï¼çå¤è¼ªä¸å¤é¢åå°è©±æå·§ï¼ä¸¦å¥ åºæ¼ä¸åçç¤¾äº¤èçµ¡ï¼ä¾å¦äººå£çµ±è¨ãè§è²ãç¶é©æ³åï¼ãæ­¤è³æéåå«ç´ 100K å°è©±ãä½¿ç¨æ­¤è³æéï¼æåå¼é²ä¸åæ°ç³»åçå¿æºæå·§æ³¨å¥å¼ LLMï¼ç¨±çº Thanosï¼æ¨¡åå¤§å°çº 1Bã3B å 8B åæ¸ãééå»£æ³çå¯¦é©ï¼éäºæ¨¡åæåç¤ºç¯å¿æºæå·§éç¨ï¼ä¸¦å±ç¾å¼·å¤§çæ¦æ¬è½åï¼ç¨æ¼æ¨è«åç¨®é åçå¤é¢åæå·§ãæ­¤å¤ï¼æåè­æ Thanos å¤§å¹æå LLM çºåºç¤çå°è©±ä»£çæç¢ççåæåè³ªï¼ä¸¦å¨äººé¡è©ä¼°ä¸­ä¿é²è¦ªç¤¾æè¡çºã

##### **Series-to-Series Diffusion Bridge Model**
2411.04491v1 by Hao Yang, Zhanbo Feng, Feng Zhou, Robert C Qiu, Zenan Ling

Diffusion models have risen to prominence in time series forecasting,
showcasing their robust capability to model complex data distributions.
However, their effectiveness in deterministic predictions is often constrained
by instability arising from their inherent stochasticity. In this paper, we
revisit time series diffusion models and present a comprehensive framework that
encompasses most existing diffusion-based methods. Building on this theoretical
foundation, we propose a novel diffusion-based time series forecasting model,
the Series-to-Series Diffusion Bridge Model ($\mathrm{S^2DBM}$), which
leverages the Brownian Bridge process to reduce randomness in reverse
estimations and improves accuracy by incorporating informative priors and
conditions derived from historical time series data. Experimental results
demonstrate that $\mathrm{S^2DBM}$ delivers superior performance in
point-to-point forecasting and competes effectively with other diffusion-based
models in probabilistic forecasting.

æè¦ï¼æ´æ£æ¨¡åå¨æéåºåé æ¸¬ä¸­å·²æ¥çåå°éè¦ï¼å±ç¤ºäºå¶å°è¤éæ¸æåä½å»ºæ¨¡çå¼·å¤§è½åãç¶èï¼å®åå¨ç¢ºå®æ§é æ¸¬ä¸­çæææ§éå¸¸åå°å¶åºæé¨æ©æ§æç¢ççä¸ç©©å®æ§çéå¶ãå¨æ¬æä¸­ï¼æåéæ°æ¢è¨äºæéåºåæ´æ£æ¨¡åï¼ä¸¦æåºäºæ¶µèå¤§å¤æ¸ç¾æåºæ¼æ´æ£çæ¹æ³çç¶åæ¡æ¶ãå¨æ­¤çè«åºç¤ä¹ä¸ï¼æåæåºäºä¸åæ°ç©çåºæ¼æ´æ£çæéåºåé æ¸¬æ¨¡åï¼å³åºåå°åºåæ´æ£æ©æ¨¡åï¼$\mathrm{S^2DBM}$ï¼ï¼å®å©ç¨å¸ææ©éç¨ä¾æ¸å°ååä¼°è¨ä¸­çé¨æ©æ§ï¼ä¸¦ééæ´åå¾æ­·å²æéåºåæ¸æä¸­å¾åºçä¿¡æ¯åé©åæ¢ä»¶ä¾æé«æºç¢ºæ§ãå¯¦é©çµæè¡¨æï¼$\mathrm{S^2DBM}$ å¨é»å°é»é æ¸¬ä¸­æä¾äºåè¶çæ§è½ï¼ä¸¦å¨æ¦çé æ¸¬ä¸­èå¶ä»åºæ¼æ´æ£çæ¨¡åææç«¶ç­ã

##### **ML-Promise: A Multilingual Dataset for Corporate Promise Verification**
2411.04473v1 by Yohei Seki, Hakusen Shu, AnaÃ¯s Lhuissier, Hanwool Lee, Juyeon Kang, Min-Yuh Day, Chung-Chi Chen

Promises made by politicians, corporate leaders, and public figures have a
significant impact on public perception, trust, and institutional reputation.
However, the complexity and volume of such commitments, coupled with
difficulties in verifying their fulfillment, necessitate innovative methods for
assessing their credibility. This paper introduces the concept of Promise
Verification, a systematic approach involving steps such as promise
identification, evidence assessment, and the evaluation of timing for
verification. We propose the first multilingual dataset, ML-Promise, which
includes English, French, Chinese, Japanese, and Korean, aimed at facilitating
in-depth verification of promises, particularly in the context of
Environmental, Social, and Governance (ESG) reports. Given the growing emphasis
on corporate environmental contributions, this dataset addresses the challenge
of evaluating corporate promises, especially in light of practices like
greenwashing. Our findings also explore textual and image-based baselines, with
promising results from retrieval-augmented generation (RAG) approaches. This
work aims to foster further discourse on the accountability of public
commitments across multiple languages and domains.

æè¦ï¼æ¿å®¢ãä¼æ¥­é è¢åå¬ç¾äººç©ååºçæ¿è«¾å°å¬ç¾è§æãä¿¡ä»»åæ©æ§è²è­½æéå¤§å½±é¿ãç¶èï¼æ­¤é¡æ¿è«¾çè¤éæ§åæ¸éï¼å ä¸é£ä»¥é©è­å¶å±¥è¡çé£åº¦ï¼éè¦åµæ°çæ¹æ³ä¾è©ä¼°å¶å¯ä¿¡åº¦ãæ¬æä»ç´¹äºæ¿è«¾é©è­çæ¦å¿µï¼éæ¯ä¸ç¨®ç³»çµ±åçæ¹æ³ï¼æ¶åæ¿è«¾è­å¥ãè­æè©ä¼°åé©è­ææ©è©ä¼°ç­æ­¥é©ãæåæåºäºç¬¬ä¸åå¤èªè¨æ¸æé ML-Promiseï¼å¶ä¸­åæ¬è±èªãæ³èªãä¸­æãæ¥èªåéèªï¼æ¨å¨ä¿é²å°æ¿è«¾çæ·±å¥é©è­ï¼ç¹å¥æ¯å¨ç°å¢ãç¤¾æåæ²»ç (ESG) å ±åçèæ¯ä¸ãéæ¼å°ä¼æ¥­ç°å¢è²¢ç»çæ¥çéè¦ï¼æ­¤æ¸æéæå°äºè©ä¼°ä¼æ¥­æ¿è«¾çææ°ï¼ç¹å¥æ¯èæ®å°ç¶ è²æ¼ç½ç­åæ³ãæåçç ç©¶çµæéæ¢ç´¢äºææ¬ååºæ¼ååçåºæºï¼å¾æª¢ç´¢å¢å¼·çæ (RAG) æ¹æ³ä¸­ç²å¾äºæå¸æççµæãéé å·¥ä½æ¨å¨ä¿é²å°è·¨å¤ç¨®èªè¨åé åçå¬éæ¿è«¾çåè²¬å¶çé²ä¸æ­¥è¨è«ã

##### **Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks**
2411.04468v1 by Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang, Zhu, Friederike Niedtner, Grace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor Dibia, Ahmed Awadallah, Ece Kamar, Rafah Hosn, Saleema Amershi

Modern AI agents, driven by advances in large foundation models, promise to
enhance our productivity and transform our lives by augmenting our knowledge
and capabilities. To achieve this vision, AI agents must effectively plan,
perform multi-step reasoning and actions, respond to novel observations, and
recover from errors, to successfully complete complex tasks across a wide range
of scenarios. In this work, we introduce Magentic-One, a high-performing
open-source agentic system for solving such tasks. Magentic-One uses a
multi-agent architecture where a lead agent, the Orchestrator, plans, tracks
progress, and re-plans to recover from errors. Throughout task execution, the
Orchestrator directs other specialized agents to perform tasks as needed, such
as operating a web browser, navigating local files, or writing and executing
Python code. We show that Magentic-One achieves statistically competitive
performance to the state-of-the-art on three diverse and challenging agentic
benchmarks: GAIA, AssistantBench, and WebArena. Magentic-One achieves these
results without modification to core agent capabilities or to how they
collaborate, demonstrating progress towards generalist agentic systems.
Moreover, Magentic-One's modular design allows agents to be added or removed
from the team without additional prompt tuning or training, easing development
and making it extensible to future scenarios. We provide an open-source
implementation of Magentic-One, and we include AutoGenBench, a standalone tool
for agentic evaluation. AutoGenBench provides built-in controls for repetition
and isolation to run agentic benchmarks in a rigorous and contained manner --
which is important when agents' actions have side-effects. Magentic-One,
AutoGenBench and detailed empirical performance evaluations of Magentic-One,
including ablations and error analysis are available at
https://aka.ms/magentic-one

æè¦ï¼<paragraph>ç±å¤§ååºç¡æ¨¡åçè¿æ­¥æ¨å¨çç°ä»£ AI ä»£çææéè¿å¢å¼ºæä»¬çç¥è¯åè½åæ¥æé«æä»¬ççäº§åå¹¶æ¹åæä»¬ççæ´»ãä¸ºäºå®ç°è¿ä¸æ¿æ¯ï¼AI ä»£çå¿é¡»ææå°è§åãæ§è¡å¤æ­¥éª¤æ¨çåå¨ä½ãååºæ°é¢çè§å¯ç»æä»¥åä»éè¯¯ä¸­æ¢å¤ï¼ä»¥æåå®æå¹¿æ³åºæ¯ä¸­çå¤æä»»å¡ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬ä»ç»äº Magentic-Oneï¼è¿æ¯ä¸ä¸ªç¨äºè§£å³æ­¤ç±»ä»»å¡çé«æ§è½å¼æºä»£çç³»ç»ãMagentic-One ä½¿ç¨å¤ä»£çæ¶æï¼å¶ä¸­ä¸ä¸ªé¢å¯¼ä»£çï¼Orchestratorï¼è®¡åãè·è¸ªè¿åº¦å¹¶éæ°è®¡åä»¥ä»éè¯¯ä¸­æ¢å¤ãå¨æ´ä¸ªä»»å¡æ§è¡è¿ç¨ä¸­ï¼Orchestrator æå¯¼å¶ä»ä¸é¨ä»£çæ ¹æ®éè¦æ§è¡ä»»å¡ï¼ä¾å¦æä½ç½ç»æµè§å¨ãå¯¼èªæ¬å°æä»¶æç¼ååæ§è¡ Python ä»£ç ãæä»¬å±ç¤ºäº Magentic-One å¨ä¸ä¸ªä¸åä¸å·ææææ§çä»£çåºåæµè¯ï¼GAIAãAssistantBench å WebArenaï¼ä¸å®ç°äºä¸æåè¿ææ¯å·æç»è®¡ç«äºåçæ§è½ãMagentic-One å¨ä¸ä¿®æ¹æ ¸å¿ä»£çåè½æå®ä»¬å¦ä½åä½çæåµä¸å®ç°äºè¿äºç»æï¼å±ç¤ºäºæçéæä»£çç³»ç»åå¾çè¿å±ãæ­¤å¤ï¼Magentic-One çæ¨¡ååè®¾è®¡åè®¸å¨ä¸è¿è¡é¢å¤æç¤ºè°æ´æå¹è®­çæåµä¸åå¢éæ·»å æå é¤ä»£çï¼ä»èç®åå¼åå¹¶ä½¿å¶å¯æ©å±å°æªæ¥çåºæ¯ãæä»¬æä¾äº Magentic-One çå¼æºå®ç°ï¼å¹¶ä¸æä»¬åå«äº AutoGenBenchï¼è¿æ¯ä¸ä¸ªç¨äºä»£çè¯ä¼°çç¬ç«å·¥å·ãAutoGenBench æä¾äºåç½®çéå¤åéç¦»æ§ä»¶ï¼ä»¥ä¸¥æ ¼ä¸åæ§çæ¹å¼è¿è¡ä»£çåºåæµè¯ââå½ä»£ççå¨ä½äº§çå¯ä½ç¨æ¶è¿ä¸ç¹éå¸¸éè¦ãMagentic-OneãAutoGenBench å Magentic-One çè¯¦ç»ç»éªæ§è½è¯ä¼°ï¼åæ¬æ¶èåéè¯¯åæï¼å¯å¨ https://aka.ms/magentic-one è·å¾</paragraph>

##### **Can CDT rationalise the ex ante optimal policy via modified anthropics?**
2411.04462v1 by Emery Cooper, Caspar Oesterheld, Vincent Conitzer

In Newcomb's problem, causal decision theory (CDT) recommends two-boxing and
thus comes apart from evidential decision theory (EDT) and ex ante policy
optimisation (which prescribe one-boxing). However, in Newcomb's problem, you
should perhaps believe that with some probability you are in a simulation run
by the predictor to determine whether to put a million dollars into the opaque
box. If so, then causal decision theory might recommend one-boxing in order to
cause the predictor to fill the opaque box. In this paper, we study
generalisations of this approach. That is, we consider general Newcomblike
problems and try to form reasonable self-locating beliefs under which CDT's
recommendations align with an EDT-like notion of ex ante policy optimisation.
We consider approaches in which we model the world as running simulations of
the agent, and an approach not based on such models (which we call 'Generalised
Generalised Thirding', or GGT). For each approach, we characterise the
resulting CDT policies, and prove that under certain conditions, these include
the ex ante optimal policies.

æè¦ï¼å¨ç´åº·åé¡ä¸­ï¼å ææ±ºç­çè«ï¼CDTï¼å»ºè­°éçç­ç¥ï¼å æ­¤èè­ææ±ºç­çè«ï¼EDTï¼åäºåç­ç¥æä½³åï¼å»ºè­°å®çç­ç¥ï¼ææä¸åãç¶èï¼å¨ç´åº·åé¡ä¸­ï¼ä½ æè¨±æè©²ç¸ä¿¡ä½ æä¸å®æ©çèæ¼é æ¸¬èå·è¡çæ¨¡æ¬ä¸­ï¼ä»¥æ±ºå®æ¯å¦å°ä¸ç¾è¬ç¾åæ¾å¥ä¸éæççå­ä¸­ãå¦ææ¯éæ¨£ï¼é£éº¼å ææ±ºç­çè«å¯è½æå»ºè­°å®çç­ç¥ï¼ä»¥ä¿ä½¿é æ¸¬èå¡«æ»¿ä¸éæççå­ãå¨æ¬æä¸­ï¼æåç ç©¶äºéç¨®æ¹æ³çæ¦æ¬ãä¹å°±æ¯èªªï¼æåèæ®ä¸è¬çæ°åº·å¼åé¡ï¼ä¸¦åè©¦å½¢æåççèªæå®ä½ä¿¡å¿µï¼å¨éäºä¿¡å¿µä¸ï¼CDT çå»ºè­°è EDT å¼çäºåç­ç¥æä½³åçæ¦å¿µç¸ä¸è´ãæåèæ®çæ¹æ³åæ¬å°ä¸çå»ºæ¨¡çºå·è¡ä»£çæ¨¡æ¬ï¼ä»¥åä¸åºæ¼æ­¤é¡æ¨¡åçæ¹æ³ï¼æåç¨±ä¹çºãå»£ç¾©å»£ç¾©ä¸åæ³ãï¼æ GGTï¼ãå°æ¼æ¯ç¨®æ¹æ³ï¼æåæè¿°äºç±æ­¤ç¢çç CDT ç­ç¥ï¼ä¸¦è­æå¨ç¹å®æ¢ä»¶ä¸ï¼éäºç­ç¥åæ¬äºåæä½³ç­ç¥ã

##### **Gradient Localization Improves Lifelong Pretraining of Language Models**
2411.04448v1 by Jared Fernandez, Yonatan Bisk, Emma Strubell

Large Language Models (LLMs) trained on web-scale text corpora have been
shown to capture world knowledge in their parameters. However, the mechanism by
which language models store different types of knowledge is poorly understood.
In this work, we examine two types of knowledge relating to temporally
sensitive entities and demonstrate that each type is localized to different
sets of parameters within the LLMs. We hypothesize that the lack of
consideration of the locality of knowledge in existing continual learning
methods contributes to both: the failed uptake of new information, and
catastrophic forgetting of previously learned information. We observe that
sequences containing references to updated and newly mentioned entities exhibit
larger gradient norms in a subset of layers. We demonstrate that targeting
parameter updates to these relevant layers can improve the performance of
continually pretraining on language containing temporal drift.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) å¨ç½ç»è§æ¨¡ææ¬è¯­æåºä¸è¿è¡è®­ç»ï¼å·²æ¾ç¤ºåºå¨å¶åæ°ä¸­æè·ä¸çç¥è¯ãç¶èï¼è¯­è¨æ¨¡åå­å¨ä¸åç±»åç¥è¯çæºå¶å´é²ä¸ºäººç¥ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æ£æ¥äºä¸æ¶é´ææå®ä½ç¸å³çä¸¤ç§ç±»åçç¥è¯ï¼å¹¶è¯ææ¯ç§ç±»åé½å®ä½äº LLM åçä¸ååæ°éãæä»¬åè®¾å¨ç°æçæç»­å­¦ä¹ æ¹æ³ä¸­ç¼ºä¹å¯¹ç¥è¯å±é¨æ§çèèï¼å¯¼è´äºæ°ä¿¡æ¯çå¸æ¶å¤±è´¥åååå­¦ä¹ ä¿¡æ¯çç¾é¾æ§éå¿ãæä»¬è§å¯å°ï¼åå«å¯¹æ´æ°åæ°æåå®ä½çå¼ç¨çåºåå¨å­éä¸­è¡¨ç°åºæ´å¤§çæ¢¯åº¦èæ°ãæä»¬è¯æï¼å°åæ°æ´æ°ç®æ å®ä½å°è¿äºç¸å³å±å¯ä»¥æé«å¨åå«æ¶é´æ¼ç§»çè¯­è¨ä¸æç»­é¢è®­ç»çæ§è½ã

##### **ACCIO: Table Understanding Enhanced via Contrastive Learning with Aggregations**
2411.04443v1 by Whanhee Cho

The attention to table understanding using recent natural language models has
been growing. However, most related works tend to focus on learning the
structure of the table directly. Just as humans improve their understanding of
sentences by comparing them, they can also enhance their understanding by
comparing tables. With this idea, in this paper, we introduce ACCIO, tAble
understanding enhanCed via Contrastive learnIng with aggregatiOns, a novel
approach to enhancing table understanding by contrasting original tables with
their pivot summaries through contrastive learning. ACCIO trains an encoder to
bring these table pairs closer together. Through validation via column type
annotation, ACCIO achieves competitive performance with a macro F1 score of
91.1 compared to state-of-the-art methods. This work represents the first
attempt to utilize pairs of tables for table embedding, promising significant
advancements in table comprehension. Our code is available at
https://github.com/whnhch/ACCIO/.

æè¦ï¼è¿ä¾ä½¿ç¨èªç¶èªè¨æ¨¡åä¾çè§£è¡¨æ ¼çéæ³¨åº¦æ­£å¨å¢å ãç¶èï¼å¤§å¤æ¸ç¸éå·¥ä½å¾åæ¼ç´æ¥å­¸ç¿è¡¨æ ¼ççµæ§ãå°±åäººé¡ééæ¯è¼å¥å­ä¾æåå°å¥å­ççè§£ï¼ä»åä¹è½ééæ¯è¼è¡¨æ ¼ä¾å¢å¼·å°è¡¨æ ¼ççè§£ãæäºéåæ³æ³ï¼å¨æ¬æä¸­ï¼æåå¼å¥äº ACCIOï¼ä¸ç¨®ééå°æ¯å­¸ç¿ï¼å©ç¨èåä¾å¢å¼·è¡¨æ ¼çè§£çè¡¨æ ¼çè§£å¢å¼·æ¹æ³ï¼éæ¯ä¸ç¨®ééå°æ¯å­¸ç¿å°åå§è¡¨æ ¼èå¶æ¨ç´æè¦é²è¡å°æ¯çæ°ç©æ¹æ³ãACCIO è¨ç·´ä¸åç·¨ç¢¼å¨ï¼è®éäºè¡¨æ ¼å°æ´æ¥è¿ãééæ¬ä½é¡åè¨»è§£çé©è­ï¼ACCIO éå°äºç«¶ç­åçæè½ï¼å·¨è§ F1 åæ¸çº 91.1ï¼èæåé²çæ¹æ³ç¸æ¯ãéé å·¥ä½ä»£è¡¨äºé¦æ¬¡åè©¦å©ç¨è¡¨æ ¼å°ä¾é²è¡è¡¨æ ¼åµå¥ï¼ææå¨è¡¨æ ¼çè§£æ¹é¢åå¾éå¤§é²å±ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/whnhch/ACCIO/ åå¾ã

##### **Scaling Laws for Pre-training Agents and World Models**
2411.04434v1 by Tim Pearce, Tabish Rashid, Dave Bignell, Raluca Georgescu, Sam Devlin, Katja Hofmann

The performance of embodied agents has been shown to improve by increasing
model parameters, dataset size, and compute. This has been demonstrated in
domains from robotics to video games, when generative learning objectives on
offline datasets (pre-training) are used to model an agent's behavior
(imitation learning) or their environment (world modeling). This paper
characterizes the role of scale in these tasks more precisely. Going beyond the
simple intuition that `bigger is better', we show that the same types of power
laws found in language modeling (e.g. between loss and optimal model size),
also arise in world modeling and imitation learning. However, the coefficients
of these laws are heavily influenced by the tokenizer, task \& architecture --
this has important implications on the optimal sizing of models and data.

æè¦ï¼å·èº«ä»£ççæè½å·²è­å¯¦è½ééå¢å æ¨¡ååæ¸ãè³æéå¤§å°åéç®èæåãéå·²å¨æ©å¨äººæè¡å°é»ç©éæ²ç­é åä¸­ç²å¾é©è­ï¼ç¶é¢ç·è³æéï¼é è¨ç·´ï¼ä¸ççæå¼å­¸ç¿ç®æ¨ç¨æ¼å»ºæ¨¡ä»£çè¡çºï¼æ¨¡ä»¿å­¸ç¿ï¼æå¶ç°å¢ï¼ä¸çå»ºæ¨¡ï¼æãæ¬ææ´ç²¾ç¢ºå°æè¿°äºè¦æ¨¡å¨éäºä»»åä¸­çè§è²ãé¤äºãè¶å¤§è¶å¥½ãçç´è¦ºä¹å¤ï¼æåå±ç¤ºäºå¨èªè¨å»ºæ¨¡ä¸­ç¼ç¾çç¸åé¡åçåªå¾ï¼ä¾å¦ï¼æå¤±åæä½³æ¨¡åå¤§å°ä¹éï¼ä¹åºç¾å¨ä¸çå»ºæ¨¡åæ¨¡ä»¿å­¸ç¿ä¸­ãç¶èï¼éäºå®å¾çä¿æ¸åå°åè©å¨ãä»»ååæ¶æ§çæ¥µå¤§å½±é¿ââéå°æ¨¡ååè³æçæä½³å¤§å°æéè¦çå½±é¿ã

##### **One fish, two fish, but not the whole sea: Alignment reduces language models' conceptual diversity**
2411.04427v1 by Sonia K. Murthy, Tomer Ullman, Jennifer Hu

Researchers in social science and psychology have recently proposed using
large language models (LLMs) as replacements for humans in behavioral research.
In addition to arguments about whether LLMs accurately capture population-level
patterns, this has raised questions about whether LLMs capture human-like
conceptual diversity. Separately, it is debated whether post-training alignment
(RLHF or RLAIF) affects models' internal diversity. Inspired by human studies,
we use a new way of measuring the conceptual diversity of
synthetically-generated LLM "populations" by relating the internal variability
of simulated individuals to the population-level variability. We use this
approach to evaluate non-aligned and aligned LLMs on two domains with rich
human behavioral data. While no model reaches human-like diversity, aligned
models generally display less diversity than their instruction fine-tuned
counterparts. Our findings highlight potential trade-offs between increasing
models' value alignment and decreasing the diversity of their conceptual
representations.

æè¦ï¼ç¤¾æç§å­¸åå¿çå­¸çç ç©¶äººå¡æè¿æåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾åä»£äººé¡é²è¡è¡çºç ç©¶ãé¤äºéæ¼ LLM æ¯å¦æºç¢ºææäººå£å±¤ç´æ¨¡å¼çè«é»ä¹å¤ï¼éä¹å¼ç¼äº LLM æ¯å¦ææå°é¡äººæ¦å¿µå¤æ¨£æ§çåé¡ãå¦å¤ï¼ç­è«çç¦é»å¨æ¼è¨ç·´å¾çæ¯å°ï¼RLHF æ RLAIFï¼æ¯å¦æå½±é¿æ¨¡åçå§é¨å¤æ¨£æ§ãåå°äººé¡ç ç©¶çåç¼ï¼æåä½¿ç¨ä¸ç¨®æ°çæ¹å¼ä¾è¡¡éåæç¢çç LLMãæç¾¤ãçæ¦å¿µå¤æ¨£æ§ï¼æ¹æ³æ¯å°æ¨¡æ¬åé«çå§é¨è®ç°èæç¾¤å±¤ç´çè®ç°éè¯èµ·ä¾ãæåä½¿ç¨éç¨®æ¹æ³å¨å©åå·æè±å¯äººé¡è¡çºè³æçé åä¸­è©ä¼°æªæ¯å°åå·²æ¯å°ç LLMãéç¶æ²æä»»ä½æ¨¡åéå°é¡äººçå¤æ¨£æ§ï¼ä½å·²æ¯å°çæ¨¡åéå¸¸æ¯å¶å¾®èª¿æä»¤çå°ææ¨¡åé¡¯ç¤ºåºè¼ä½çå¤æ¨£æ§ãæåçç ç©¶çµæçªåºäºå¨å¢å æ¨¡åå¹å¼æ¯å°åéä½å¶æ¦å¿µè¡¨å¾µå¤æ¨£æ§ä¹éçæ½å¨åæ¨ã

##### **DELIFT: Data Efficient Language model Instruction Fine Tuning**
2411.04425v1 by Ishika Agarwal, Krishna Killamsetty, Lucian Popa, Marina Danilevksy

Fine-tuning large language models (LLMs) is essential for enhancing their
performance on specific tasks but is often resource-intensive due to redundant
or uninformative data. To address this inefficiency, we introduce DELIFT (Data
Efficient Language model Instruction Fine-Tuning), a novel algorithm that
systematically optimizes data selection across the three key stages of
fine-tuning: (1) instruction tuning, (2) task-specific fine-tuning (e.g.,
reasoning, question-answering), and (3) continual fine-tuning (e.g.,
incorporating new data versions). Unlike existing methods that focus on
single-stage optimization or rely on computationally intensive gradient
calculations, DELIFT operates efficiently across all stages. Central to our
approach is a pairwise utility metric that quantifies how beneficial a data
sample is for improving the model's responses to other samples, effectively
measuring the informational value relative to the model's current capabilities.
By leveraging different submodular functions applied to this metric, DELIFT
selects diverse and optimal subsets that are useful across all stages of
fine-tuning. Experiments across various tasks and model scales demonstrate that
DELIFT can reduce the fine-tuning data size by up to 70% without compromising
performance, offering significant computational savings and outperforming
existing methods in both efficiency and efficacy.

æè¦ï¼å¾®èª¿å¤§åèªè¨æ¨¡å (LLM) å°æ¼æåå¶å¨ç¹å®ä»»åä¸çè¡¨ç¾è³ééè¦ï¼ä½ç±æ¼åé¤æç¡è³è¨è³æï¼éå¸¸æèè²»å¤§éè³æºãçºäºè§£æ±ºæ­¤ä½æçåé¡ï¼æåå¼å¥äº DELIFTï¼è³æææèªè¨æ¨¡åæä»¤å¾®èª¿ï¼ï¼ä¸ç¨®æ°æ¼ç®æ³ï¼å¯ç³»çµ±æ§å°æä½³åå¾®èª¿ä¸åééµéæ®µçè³æé¸åï¼(1) æä»¤å¾®èª¿ã(2) ä»»åç¹å®å¾®èª¿ï¼ä¾å¦æ¨çãåç­ï¼ï¼ä»¥å (3) æçºå¾®èª¿ï¼ä¾å¦ç´å¥æ°è³æçæ¬ï¼ãèç¾ææ¹æ³ä¸åï¼ç¾ææ¹æ³å°æ³¨æ¼å®éæ®µæä½³åæä¾è³´æ¼è¨ç®å¯éçæ¢¯åº¦è¨ç®ï¼DELIFT å¨ææéæ®µé½è½ææéä½ãæåæ¹æ³çæ ¸å¿æ¯ä¸åæå°æç¨ææ¨ï¼ç¨æ¼éåè³æç¯ä¾å°æ¼æ¹åæ¨¡åå°å¶ä»ç¯ä¾çåææå¤å¤§çå¥½èï¼ææå°è¡¡éç¸å°æ¼æ¨¡åç¶ååè½çè³è¨å¹å¼ãééå°æ­¤ææ¨æç¨ä¸åçæ¬¡æ¨¡å½æ¸ï¼DELIFT é¸åå¨å¾®èª¿çææéæ®µé½æç¨çå¤æ¨£åä¸æä½³å­éãå¨åç¨®ä»»ååæ¨¡åè¦æ¨¡çå¯¦é©ä¸­é¡¯ç¤ºï¼DELIFT å¯ä»¥å°å¾®èª¿è³æå¤§å°æ¸å°å¤é 70%ï¼åæä¸å½±é¿æè½ï¼æä¾é¡¯èçè¨ç®ç¯çï¼ä¸¦å¨æçåæåæ¹é¢åªæ¼ç¾ææ¹æ³ã

##### **Bayesian Calibration of Win Rate Estimation with LLM Evaluators**
2411.04424v1 by Yicheng Gao, Gonghan Xu, Zhe Wang, Arman Cohan

Recent advances in large language models (LLMs) show the potential of using
LLMs as evaluators for assessing the quality of text generations from LLMs.
However, applying LLM evaluators naively to compare or judge between different
systems can lead to unreliable results due to the intrinsic win rate estimation
bias of LLM evaluators. In order to mitigate this problem, we propose two
calibration methods, Bayesian Win Rate Sampling (BWRS) and Bayesian
Dawid-Skene, both of which leverage Bayesian inference to more accurately infer
the true win rate of generative language models. We empirically validate our
methods on six datasets covering story generation, summarization, and
instruction following tasks. We show that both our methods are effective in
improving the accuracy of win rate estimation using LLMs as evaluators,
offering a promising direction for reliable automatic text quality evaluation.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯ç¤ºäºä½¿ç¨ LLM ä½çºè©ä¼°å¨è©ä¼° LLM çæçæå­åè³ªçæ½åã
ç¶èï¼å¤©çå°å¥ç¨ LLM è©ä¼°å¨ä¾æ¯è¼æå¤æ·ä¸åçç³»çµ±æå°è´ä¸å¯é ççµæï¼éæ¯ç±æ¼ LLM è©ä¼°å¨å§å¨çåçä¼°è¨åå·®ãçºäºæ¸è¼éååé¡ï¼æåæåºäºå©ç¨®æ ¡æºæ¹æ³ï¼è²æ°åçæ½æ¨£ (BWRS) åè²æ° Dawid-Skeneï¼éå©ç¨®æ¹æ³é½å©ç¨è²æ°æ¨è«ä¾æ´æºç¢ºå°æ¨æ·çæèªè¨æ¨¡åççå¯¦åçãæåå¨æ¶µèæäºçæãæè¦åæä»¤éµå¾ªä»»åçå­åè³æéä¸å¯¦è­é©è­äºæåçéäºæ¹æ³ãæåè­æäºæåçå©ç¨®æ¹æ³é½è½ææå°æé«ä½¿ç¨ LLM ä½çºè©ä¼°å¨çåçä¼°è¨æºç¢ºåº¦ï¼çºå¯é çèªåæå­åè³ªè©ä¼°æä¾äºæå¸æçæ¹åã

##### **Variational Low-Rank Adaptation Using IVON**
2411.04421v1 by Bai Cong, Nico Daheim, Yuesong Shen, Daniel Cremers, Rio Yokota, Mohammad Emtiyaz Khan, Thomas MÃ¶llenhoff

We show that variational learning can significantly improve the accuracy and
calibration of Low-Rank Adaptation (LoRA) without a substantial increase in the
cost. We replace AdamW by the Improved Variational Online Newton (IVON)
algorithm to finetune large language models. For Llama-2 with 7 billion
parameters, IVON improves the accuracy over AdamW by 2.8% and expected
calibration error by 4.6%. The accuracy is also better than the other Bayesian
alternatives, yet the cost is lower and the implementation is easier. Our work
provides additional evidence for the effectiveness of IVON for large language
models. The code is available at
https://github.com/team-approx-bayes/ivon-lora.

æè¦ï¼æåå±ç¤ºè®ç°å­¸ç¿å¯ä»¥é¡¯èæåä½éå±¤é©æ (LoRA) çæºç¢ºåº¦èæ ¡æºï¼èä¸æå¤§å¹å¢å ææ¬ãæåç¨æ¹è¯è®ç°å¨ç·çé  (IVON) æ¼ç®æ³åä»£ AdamWï¼ä»¥å¾®èª¿å¤§åèªè¨æ¨¡åãå°æ¼ææ 70 åååæ¸ç Llama-2ï¼IVON å°æºç¢ºåº¦æå 2.8%ï¼é æ¸¬æ ¡æºèª¤å·®åéä½ 4.6%ãæºç¢ºåº¦ä¹åªæ¼å¶ä»è²æ°æ¿ä»£æ¹æ¡ï¼ä½ææ¬è¼ä½ï¼ä¸å¯¦ä½ä¹è¼å®¹æãæåçç ç©¶çº IVON å°å¤§åèªè¨æ¨¡åçæææ§æä¾äºé¡å¤çè­æãç¨å¼ç¢¼å¯å¨ https://github.com/team-approx-bayes/ivon-lora åå¾ã

##### **Towards Competitive Search Relevance For Inference-Free Learned Sparse Retrievers**
2411.04403v1 by Zhichao Geng, Dongyu Ru, Yang Yang

Learned sparse retrieval, which can efficiently perform retrieval through
mature inverted-index engines, has garnered growing attention in recent years.
Particularly, the inference-free sparse retrievers are attractive as they
eliminate online model inference in the retrieval phase thereby avoids huge
computational cost, offering reasonable throughput and latency. However, even
the state-of-the-art (SOTA) inference-free sparse models lag far behind in
terms of search relevance when compared to both sparse and dense siamese
models. Towards competitive search relevance for inference-free sparse
retrievers, we argue that they deserve dedicated training methods other than
using same ones with siamese encoders. In this paper, we propose two different
approaches for performance improvement. First, we introduce the IDF-aware FLOPS
loss, which introduces Inverted Document Frequency (IDF) to the sparsification
of representations. We find that it mitigates the negative impact of the FLOPS
regularization on search relevance, allowing the model to achieve a better
balance between accuracy and efficiency. Moreover, we propose a heterogeneous
ensemble knowledge distillation framework that combines siamese dense and
sparse retrievers to generate supervisory signals during the pre-training
phase. The ensemble framework of dense and sparse retriever capitalizes on
their strengths respectively, providing a strong upper bound for knowledge
distillation. To concur the diverse feedback from heterogeneous supervisors, we
normalize and then aggregate the outputs of the teacher models to eliminate
score scale differences. On the BEIR benchmark, our model outperforms existing
SOTA inference-free sparse model by \textbf{3.3 NDCG@10 score}. It exhibits
search relevance comparable to siamese sparse retrievers and client-side
latency only \textbf{1.1x that of BM25}.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼è½ææéè¿æççååç´¢å¼å¼ææ§è¡æ£ç´¢çå­¦ä¹ ç¨çæ£ç´¢å¤åå³æ³¨ãç¹å«æ¯ï¼æ æ¨çç¨çæ£ç´¢å¨æå·å¸å¼åï¼å ä¸ºå®ä»¬æ¶é¤äºæ£ç´¢é¶æ®µçå¨çº¿æ¨¡åæ¨çï¼ä»èé¿åäºå·¨å¤§çè®¡ç®ææ¬ï¼æä¾äºåççååéåå»¶è¿ãç¶èï¼å³ä½¿æ¯æåè¿ç (SOTA) æ æ¨çç¨çæ¨¡åå¨ä¸ç¨çåå¯éå­ªçæ¨¡åç¸æ¯æ¶ï¼å¨æç´¢ç¸å³æ§æ¹é¢ä¹è¿è¿è½åãä¸ºäºæé«æ æ¨çç¨çæ£ç´¢å¨çç«äºæ§æç´¢ç¸å³æ§ï¼æä»¬è®¤ä¸ºå®ä»¬åºè¯¥æä¸é¨çè®­ç»æ¹æ³ï¼èä¸æ¯ä¸å­ªçç¼ç å¨ä½¿ç¨ç¸åçæ¹æ³ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸¤ç§ä¸åçæ§è½æ¹è¿æ¹æ³ãé¦åï¼æä»¬å¼å¥äºæç¥ IDF ç FLOPS æå¤±ï¼å®å°éåææ¡£é¢ç (IDF) å¼å¥è¡¨ç¤ºçç¨çåãæä»¬åç°å®åè½»äº FLOPS æ­£ååå¯¹æç´¢ç¸å³æ§çè´é¢å½±åï¼ä½¿æ¨¡åè½å¤å¨åç¡®æ§åæçä¹é´åå¾æ´å¥½çå¹³è¡¡ãæ­¤å¤ï¼æä»¬æåºäºä¸ä¸ªå¼æéæç¥è¯è¸é¦æ¡æ¶ï¼è¯¥æ¡æ¶ç»åäºå­ªçå¯éåç¨çæ£ç´¢å¨ï¼ä»¥å¨é¢è®­ç»é¶æ®µçæçç£ä¿¡å·ãå¯éåç¨çæ£ç´¢å¨çéææ¡æ¶åå«å©ç¨äºå®ä»¬çä¼å¿ï¼ä¸ºç¥è¯è¸é¦æä¾äºå¼ºå¤§çä¸éãä¸ºäºå¯¹æ¥èªå¼æçç£èçä¸ååé¦è¾¾æå±è¯ï¼æä»¬å¯¹æå¸æ¨¡åçè¾åºè¿è¡å½ä¸åï¼ç¶åè¿è¡èåï¼ä»¥æ¶é¤è¯åå°ºåº¦çå·®å¼ãå¨ BEIR åºåæµè¯ä¸­ï¼æä»¬çæ¨¡åå¨ **3.3 NDCG@10 åæ°** ä¸ä¼äºç°æç SOTA æ æ¨çç¨çæ¨¡åãå®è¡¨ç°åºçæç´¢ç¸å³æ§ä¸å­ªçç¨çæ£ç´¢å¨ç¸å½ï¼å®¢æ·ç«¯å»¶è¿ä»ä¸º **BM25 ç 1.1 å**ã</paragraph>

##### **A Bayesian Mixture Model of Temporal Point Processes with Determinantal Point Process Prior**
2411.04397v1 by Yiwei Dong, Shaoxin Ye, Yuwen Cao, Qiyu Han, Hongteng Xu, Hanfang Yang

Asynchronous event sequence clustering aims to group similar event sequences
in an unsupervised manner. Mixture models of temporal point processes have been
proposed to solve this problem, but they often suffer from overfitting, leading
to excessive cluster generation with a lack of diversity. To overcome these
limitations, we propose a Bayesian mixture model of Temporal Point Processes
with Determinantal Point Process prior (TP$^2$DP$^2$) and accordingly an
efficient posterior inference algorithm based on conditional Gibbs sampling.
Our work provides a flexible learning framework for event sequence clustering,
enabling automatic identification of the potential number of clusters and
accurate grouping of sequences with similar features. It is applicable to a
wide range of parametric temporal point processes, including neural
network-based models. Experimental results on both synthetic and real-world
data suggest that our framework could produce moderately fewer yet more diverse
mixture components, and achieve outstanding results across multiple evaluation
metrics.

æè¦ï¼éåæ­¥äºä»¶åºååç¾¤æ¨å¨ä»¥éç£ç£çæ¹å¼å°é¡ä¼¼çäºä»¶åºåé²è¡åçµãå·²ç¶æåºæéé»éç¨çæ··åæ¨¡åä¾è§£æ±ºéååé¡ï¼ä½å®åç¶å¸¸æéåº¦æ¬åï¼å°è´éåº¦ç¢çåç¾¤ï¼ä¸ç¼ºä¹å¤æ¨£æ§ãçºäºåæéäºéå¶ï¼æåæåºäºä¸åå·æè¡åå¼é»éç¨åé© (TP$^2$DP$^2$) çæéé»éç¨è²æ°æ··åæ¨¡åï¼ä¸¦ç¸æå°æåºäºä¸ååºæ¼æ¢ä»¶ Gibbs æ½æ¨£çææå¾é©æ¨è«æ¼ç®æ³ãæåçç ç©¶æä¾äºä¸åç¨æ¼äºä»¶åºååç¾¤çå½æ§å­¸ç¿æ¡æ¶ï¼è½å¤ èªåè­å¥åç¾¤çæ½å¨æ¸éï¼ä¸¦æºç¢ºå°å°å·æé¡ä¼¼ç¹å¾µçåºååçµãå®é©ç¨æ¼å»£æ³çåæ¸åæéé»éç¨ï¼åæ¬åºæ¼ç¥ç¶ç¶²è·¯çæ¨¡åãå¨åæè³æåçå¯¦ä¸çè³æä¸çå¯¦é©çµæè¡¨æï¼æåçæ¡æ¶å¯ä»¥ç¢çæ¸éé©ä¸­ä½æ´å¤æ¨£åçæ··åçµæï¼ä¸¦å¨å¤åè©ä¼°ææ¨ä¸­åå¾ååºççµæã

##### **Bridging the Gap: Representation Spaces in Neuro-Symbolic AI**
2411.04393v1 by Xin Zhang, Victor S. Sheng

Neuro-symbolic AI is an effective method for improving the overall
performance of AI models by combining the advantages of neural networks and
symbolic learning. However, there are differences between the two in terms of
how they process data, primarily because they often use different data
representation methods, which is often an important factor limiting the overall
performance of the two. From this perspective, we analyzed 191 studies from
2013 by constructing a four-level classification framework. The first level
defines five types of representation spaces, and the second level focuses on
five types of information modalities that the representation space can
represent. Then, the third level describes four symbolic logic methods.
Finally, the fourth-level categories propose three collaboration strategies
between neural networks and symbolic learning. Furthermore, we conducted a
detailed analysis of 46 research based on their representation space.

æè¦ï¼ç¥ç¶ç¬¦è AI æ¯ä¸ç¨®ææçæ¹æ³ï¼å¯ä»¥çµåç¥ç¶ç¶²è·¯åç¬¦èå­¸ç¿çåªé»ä¾æå AI æ¨¡åçæ´é«æè½ãç¶èï¼å©èå¨èçè³æçæ¹å¼ä¸å­å¨å·®ç°ï¼éä¸»è¦æ¯å çºå®åç¶å¸¸ä½¿ç¨ä¸åçè³æè¡¨å¾µæ¹æ³ï¼èééå¸¸æ¯éå¶å©èæ´é«æè½çéè¦å ç´ ãå¾éåè§åº¦ä¾çï¼æåééå»ºæ§ä¸ååå±¤ç´åé¡æ¶æ§ä¾åæ 2013 å¹´ä»¥ä¾ç 191 é ç ç©¶ãç¬¬ä¸å±¤å®ç¾©äºäºç¨®é¡åçè¡¨å¾µç©ºéï¼ç¬¬äºå±¤åå°æ³¨æ¼è¡¨å¾µç©ºéå¯ä»¥è¡¨å¾µçäºç¨®é¡åè³è¨æ¨¡å¼ãæ¥èï¼ç¬¬ä¸å±¤æè¿°äºåç¨®ç¬¦èéè¼¯æ¹æ³ãæå¾ï¼ç¬¬åå±¤é¡å¥æåºäºç¥ç¶ç¶²è·¯åç¬¦èå­¸ç¿ä¹éçä¸ç¨®åä½ç­ç¥ãæ­¤å¤ï¼æåå° 46 é ç ç©¶æ ¹æå¶è¡¨å¾µç©ºéé²è¡äºè©³ç´°åæã

##### **Neuro-Symbolic AI: Explainability, Challenges, and Future Trends**
2411.04383v1 by Xin Zhang, Victor S. Sheng

Explainability is an essential reason limiting the application of neural
networks in many vital fields. Although neuro-symbolic AI hopes to enhance the
overall explainability by leveraging the transparency of symbolic learning, the
results are less evident than imagined. This article proposes a classification
for explainability by considering both model design and behavior of 191 studies
from 2013, focusing on neuro-symbolic AI, hoping to inspire scholars who want
to understand the explainability of neuro-symbolic AI. Precisely, we classify
them into five categories by considering whether the form of bridging the
representation differences is readable as their design factor, if there are
representation differences between neural networks and symbolic logic learning,
and whether a model decision or prediction process is understandable as their
behavior factor: implicit intermediate representations and implicit prediction,
partially explicit intermediate representations and partially explicit
prediction, explicit intermediate representations or explicit prediction,
explicit intermediate representation and explicit prediction, unified
representation and explicit prediction. We also analyzed the research trends
and three significant challenges: unified representations, explainability and
transparency, and sufficient cooperation from neural networks and symbolic
learning. Finally, we put forward suggestions for future research in three
aspects: unified representations, enhancing model explainability, ethical
considerations, and social impact.

æè¦ï¼å¯è§£éæ§æ¯éå¶ç¥ç¶ç¶²è·¯å¨è¨±å¤éè¦é åæç¨çåºæ¬åå ãåç®¡ç¥ç¶ç¬¦è AI å¸æééå©ç¨ç¬¦èå­¸ç¿çéææ§ä¾å¢å¼·æ´é«å¯è§£éæ§ï¼ä½çµæä¸å¦æ³åä¸­æé¡¯ãæ¬ææåºäºä¸åå¯è§£éæ§çåé¡ï¼ééèé 191 ç¯ç ç©¶ï¼èª 2013 å¹´ï¼çæ¨¡åè¨­è¨åè¡çºï¼å°æ³¨æ¼ç¥ç¶ç¬¦è AIï¼å¸æè½åç¼æ³è¦äºè§£ç¥ç¶ç¬¦è AI å¯è§£éæ§çå­¸èãå·é«ä¾èªªï¼æåå°å®ååçºäºé¡ï¼èéé£çµè¡¨ç¤ºå·®ç°çå½¢å¼æ¯å¦å¯ä½çºè¨­è¨å ç´ ä¾é±è®ï¼ç¥ç¶ç¶²è·¯åç¬¦èéè¼¯å­¸ç¿ä¹éæ¯å¦å­å¨è¡¨ç¤ºå·®ç°ï¼ä»¥åæ¨¡åæ±ºç­æé æ¸¬éç¨æ¯å¦å¯ä½çºè¡çºå ç´ ä¾çè§£ï¼é±å«ä¸­éè¡¨ç¤ºåé±å«é æ¸¬ãé¨åæç¢ºä¸­éè¡¨ç¤ºåé¨åæç¢ºé æ¸¬ãæç¢ºä¸­éè¡¨ç¤ºææç¢ºé æ¸¬ãæç¢ºä¸­éè¡¨ç¤ºåæç¢ºé æ¸¬ãçµ±ä¸è¡¨ç¤ºåæç¢ºé æ¸¬ãæåéåæäºç ç©¶è¶¨å¢åä¸åéå¤§ææ°ï¼çµ±ä¸è¡¨ç¤ºãå¯è§£éæ§åéææ§ï¼ä»¥åä¾èªç¥ç¶ç¶²è·¯åç¬¦èå­¸ç¿çåååä½ãæå¾ï¼æåå¨çµ±ä¸è¡¨ç¤ºãå¢å¼·æ¨¡åå¯è§£éæ§ãå«çèéåç¤¾æå½±é¿ä¸åæ¹é¢æåºäºæªä¾ç ç©¶å»ºè­°ã

##### **Benchmarking Large Language Models with Integer Sequence Generation Tasks**
2411.04372v1 by Daniel O'Malley, Manish Bhattarai, Javier Santos

This paper presents a novel benchmark where the large language model (LLM)
must write code that computes integer sequences from the Online Encyclopedia of
Integer Sequences (OEIS), a widely-used resource for mathematical sequences.
The benchmark is designed to evaluate both the correctness of the generated
code and its computational efficiency. Our benchmark reveals that the o1 series
of models outperform other frontier models from OpenAI, Anthropic, Meta, and
Google in accuracy and cheating rates across both easy and hard integer
sequences. In order to ensure models do not exploit memorized sequence values,
we introduce an automated cheating detection mechanism that flags the use of
lookup tables and validated this automation against human cheating evaluations.
This benchmark provides a meaningful challenge for current LLMs, offering
insights into their mathematical reasoning and code writing capabilities, which
can guide future research directions and model development in mathematical
reasoning and code synthesis.

æè¦ï¼æ¬ææåºäºä¸ä¸ªæ°åºæºï¼å¶ä¸­å¤§åèªè¨æ¨¡å (LLM)
å¿é æ°å¯«ç¨å¼ç¢¼ä¾è¨ç®ä¾èªæ´æ¸åºåç·ä¸ç¾ç§å¨æ¸ (OEIS) çæ´æ¸åºåï¼éæ¯ä¸åå»£æ³ç¨æ¼æ¸å­¸åºåçè³æºã
åºæºæ¨å¨è©ä¼°æç¢çç¨å¼ç¢¼çæ­£ç¢ºæ§åå¶è¨ç®æçãæåçåºæºé¡¯ç¤ºï¼o1 ç³»åçæ¨¡åå¨æºç¢ºåº¦åä½å¼çæ¹é¢åªæ¼ OpenAIãAnthropicãMeta å Google ç­å¶ä»åæ²¿æ¨¡åï¼é©ç¨æ¼ç°¡å®åå°é£çæ´æ¸åºåãçºäºç¢ºä¿æ¨¡åä¸æå©ç¨è¨æ¶çåºåå¼ï¼æåå¼å¥äºä¸åèªåä½å¼åµæ¸¬æ©å¶ï¼æ¨ç¤ºä½¿ç¨æ¥è©¢è¡¨ï¼ä¸¦æ ¹æäººé¡ä½å¼è©ä¼°é©è­æ­¤èªååãæ­¤åºæºçºç®åç LLM æä¾äºä¸åææç¾©çææ°ï¼æä¾äºå°å¶æ¸å­¸æ¨çåç¨å¼ç¢¼æ°å¯«è½åçè¦è§£ï¼éå¯ä»¥å¼å°æªä¾çç ç©¶æ¹ååæ¸å­¸æ¨çåç¨å¼ç¢¼åæä¸­çæ¨¡åéç¼ã

##### **ComFairGNN: Community Fair Graph Neural Network**
2411.04371v1 by Yonas Sium, Qi Li

Graph Neural Networks (GNNs) have become the leading approach for addressing
graph analytical problems in various real-world scenarios. However, GNNs may
produce biased predictions against certain demographic subgroups due to node
attributes and neighbors surrounding a node. Most current research on GNN
fairness focuses predominantly on debiasing GNNs using oversimplified fairness
evaluation metrics, which can give a misleading impression of fairness.
Understanding the potential evaluation paradoxes due to the complicated nature
of the graph structure is crucial for developing effective GNN debiasing
mechanisms. In this paper, we examine the effectiveness of current GNN
debiasing methods in terms of unfairness evaluation. Specifically, we introduce
a community-level strategy to measure bias in GNNs and evaluate debiasing
methods at this level. Further, We introduce ComFairGNN, a novel framework
designed to mitigate community-level bias in GNNs. Our approach employs a
learnable coreset-based debiasing function that addresses bias arising from
diverse local neighborhood distributions during GNNs neighborhood aggregation.
Comprehensive evaluations on three benchmark datasets demonstrate our model's
effectiveness in both accuracy and fairness metrics.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) å·²æçºè§£æ±ºåç¨®å¯¦éå ´æ¯ä¸­åå½¢åæåé¡çä¸»è¦æ¹æ³ãç¶èï¼ç±æ¼ç¯é»å±¬æ§åç¯é»å¨åçé°å±ï¼GNN å¯è½æå°æäºäººå£çµ±è¨å­ç¾¤ç¢çæåè¦çé æ¸¬ãç®åå¤§å¤æ¸éæ¼ GNN å¬å¹³æ§çç ç©¶ä¸»è¦éä¸­å¨ä½¿ç¨éæ¼ç°¡åçå¬å¹³æ§è©ä¼°ææ¨å° GNN é²è¡å»åï¼éå¯è½æçµ¦äººé æå¬å¹³æ§çé¯èª¤å°è±¡ãäºè§£ç±æ¼åå½¢çµæ§çè¤éæ§èå°è´çæ½å¨è©ä¼°æè«å°æ¼éç¼ææç GNN å»åæ©å¶è³ééè¦ãå¨æ¬æä¸­ï¼æåæª¢æ¥äºç¶å GNN å»åæ¹æ³å¨ä¸å¬å¹³è©ä¼°æ¹é¢çæææ§ãå·é«ä¾èªªï¼æåå¼å¥äºä¸åç¤¾åç´ç­ç¥ä¾è¡¡é GNN ä¸­çåå·®ï¼ä¸¦å¨æ­¤ç´å¥è©ä¼°å»åæ¹æ³ãæ­¤å¤ï¼æåå¼å¥äº ComFairGNNï¼éæ¯ä¸åæ¨å¨æ¸è¼ GNN ä¸­ç¤¾åç´åå·®çæ°æ¡æ¶ãæåçåæ³æ¡ç¨äºä¸åå¯å­¸ç¿çåºæ¼æ ¸å¿çå»åå½æ¸ï¼è©²å½æ¸è§£æ±ºäº GNN é°åèåéç¨ä¸­ä¾èªä¸åå±é¨é°ååä½çåå·®ãå¨ä¸ååºæºæ¸æéä¸çç¶åè©ä¼°è­æäºæåçæ¨¡åå¨æºç¢ºæ§åå¬å¹³æ§ææ¨æ¹é¢çæææ§ã

##### **Measuring short-form factuality in large language models**
2411.04368v1 by Jason Wei, Nguyen Karina, Hyung Won Chung, Yunxin Joy Jiao, Spencer Papay, Amelia Glaese, John Schulman, William Fedus

We present SimpleQA, a benchmark that evaluates the ability of language
models to answer short, fact-seeking questions. We prioritized two properties
in designing this eval. First, SimpleQA is challenging, as it is adversarially
collected against GPT-4 responses. Second, responses are easy to grade, because
questions are created such that there exists only a single, indisputable
answer. Each answer in SimpleQA is graded as either correct, incorrect, or not
attempted. A model with ideal behavior would get as many questions correct as
possible while not attempting the questions for which it is not confident it
knows the correct answer. SimpleQA is a simple, targeted evaluation for whether
models "know what they know," and our hope is that this benchmark will remain
relevant for the next few generations of frontier models. SimpleQA can be found
at https://github.com/openai/simple-evals.

æè¦ï¼æåæåº SimpleQAï¼ä¸åè©éèªè¨æ¨¡ååç­ç°¡ç­äºå¯¦åé¡çè½åçåºæºãæåå¨è¨­è¨æ­¤è©éæåªåèæ®å©åç¹æ§ãé¦åï¼SimpleQA å·æææ°æ§ï¼å çºå®æéå° GPT-4 åæé²è¡å°ææ¶éãå¶æ¬¡ï¼åæå¾å®¹æè©åï¼å çºåé¡çå»ºç«æ¹å¼ä½¿å¾åªå­å¨ä¸åç¡å¯ç­è­°çç­æ¡ãSimpleQA ä¸­çæ¯åç­æ¡é½è©åçºæ­£ç¢ºãä¸æ­£ç¢ºææªåè©¦ãçæ³è¡çºçæ¨¡åæç¡å¯è½åç­æ­£ç¢ºçåé¡ï¼åæä¸åè©¦å®ä¸ç¢ºå®èªå·±ç¥éæ­£ç¢ºç­æ¡çåé¡ãSimpleQA æ¯éå°æ¨¡åãç¥éèªå·±ç¥éä»éº¼ãçç°¡å®ãæéå°æ§çè©éï¼æåå¸ææ­¤åºæºå°æ¼ä¸ä¸ä»£åæ²¿æ¨¡åä¾èªªä»ç¶ç¸éãSimpleQA å¯å¨ https://github.com/openai/simple-evals æ¾å°ã

##### **Robust and Efficient Fine-tuning of LLMs with Bayesian Reparameterization of Low-Rank Adaptation**
2411.04358v1 by Vaibhav Seth, Arinjay Pathak, Ayan Sengupta, Natraj Raman, Sriram Gopalakrishnan, Tanmoy Chakraborty

Large Language Models (LLMs) are highly resource-intensive to fine-tune due
to their enormous size. While low-rank adaptation is a prominent
parameter-efficient fine-tuning approach, it suffers from sensitivity to
hyperparameter choices, leading to instability in model performance on
fine-tuning downstream tasks. This paper highlights the importance of effective
parameterization in low-rank fine-tuning to reduce estimator variance and
enhance the stability of final model outputs. We propose MonteCLoRA, an
efficient fine-tuning technique, employing Monte Carlo estimation to learn an
unbiased posterior estimation of low-rank parameters with low expected
variance, which stabilizes fine-tuned LLMs with only O(1) additional
parameters. MonteCLoRA shows significant improvements in accuracy and
robustness, achieving up to 3.8% higher accuracy and 8.6% greater robustness
than existing efficient fine-tuning methods on natural language understanding
tasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with
pre-trained LLaMA-1-7B, MonteCLoRA demonstrates robust zero-shot performance
with 50% lower variance than the contemporary efficient fine-tuning methods.
The theoretical and empirical results presented in the paper underscore how
parameterization and hyperpriors balance exploration-exploitation in the
low-rank parametric space, therefore leading to more optimal and robust
parameter estimation during efficient fine-tuning.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å å¶é¾å¤§è¦æ¨¡èéè¦å¤§éè³æºé²è¡å¾®èª¿ãåç®¡ä½ç§©é©ææ¯ä¸ç¨®çªåºçåæ¸é«æå¾®èª¿æ¹æ³ï¼ä½å®å°è¶åæ¸é¸æå¾ææï¼å°è´æ¨¡åå¨å¾®èª¿ä¸æ¸¸ä»»åæçæè½ä¸ç©©å®ãæ¬æå¼·èª¿äºå¨ä½ç§©å¾®èª¿ä¸­ææåæ¸åçéè¦æ§ï¼ä»¥æ¸å°ä¼°è¨å¨è®ç°ä¸¦å¢å¼·æçµæ¨¡åè¼¸åºçç©©å®æ§ãæåæåºäº MonteCLoRAï¼ä¸ç¨®é«æçå¾®èª¿æè¡ï¼æ¡ç¨èå°å¡ç¾ä¼°è¨ä¾å­¸ç¿ä½ç§©åæ¸çç¡åå¾é©ä¼°è¨ï¼ä¸é æè®ç°ä½ï¼éå¯ä»¥ç©©å®å¾®èª¿å¾ç LLMï¼èé¡å¤åæ¸åçº O(1)ãMonteCLoRA å¨æºç¢ºæ§åç©©å¥æ§æ¹é¢é¡¯ç¤ºåºé¡¯èçæ¹é²ï¼å¨ä½¿ç¨é è¨ç·´ RoBERTa-base çèªç¶èªè¨çè§£ä»»åä¸­ï¼æºç¢ºåº¦æé«äº 3.8%ï¼ç©©å¥æ§æé«äº 8.6%ãæ­¤å¤ï¼å¨ä½¿ç¨é è¨ç·´ LLaMA-1-7B ççæä»»åä¸­ï¼MonteCLoRA è¡¨ç¾åºç©©å¥çé¶æ¬¡å­¸ç¿æè½ï¼è®ç°æ¯ç¾æçé«æå¾®èª¿æ¹æ³ä½ 50%ãæ¬ææåºççè«åå¯¦è­çµæå¼·èª¿äºåæ¸ååè¶åé©å¦ä½å¨ä½ç§©åæ¸ç©ºéä¸­å¹³è¡¡æ¢ç´¢èéç¼ï¼å¾èå°è´å¨é«æå¾®èª¿æéé²è¡æ´ä½³ä¸ç©©å¥çåæ¸ä¼°è¨ã

##### **Model and Deep learning based Dynamic Range Compression Inversion**
2411.04337v1 by Haoran Sun, Dominique Fourer, Hichem Maaref

Dynamic Range Compression (DRC) is a popular audio effect used to control the
dynamic range of a signal. Inverting DRC can also help to restore the original
dynamics to produce new mixes and/or to improve the overall quality of the
audio signal. Since, state-of-the-art DRC inversion techniques either ignore
parameters or require precise parameters that are difficult to estimate, we
fill the gap by combining a model-based approach with neural networks for DRC
inversion. To this end, depending on the scenario, we use different neural
networks to estimate DRC parameters. Then, a model-based inversion is completed
to restore the original audio signal. Our experimental results show the
effectiveness and robustness of the proposed method in comparison to several
state-of-the-art methods, when applied on two music datasets.

æè¦ï¼åæç¯åå£ç¸® (DRC) æ¯ä¸ç¨®æµè¡çé³è¨ææï¼ç¨æ¼æ§å¶è¨èçåæç¯åãåè½ DRC ä¹å¯ä»¥å¹«å©æ¢å¾©åå§åæï¼ä»¥ç¢çæ°çæ··é³å/ææ¹åé³è¨è¨èçæ´é«åè³ªãç±æ¼æåé²ç DRC åè½æè¡æå¿½ç¥åæ¸æéè¦é£ä»¥ä¼°è¨çç²¾ç¢ºåæ¸ï¼å æ­¤æåééçµååºæ¼æ¨¡åçæ¹æ³èç¥ç¶ç¶²è·¯ä¾å¡«è£éåç¼ºå£ï¼ä»¥é²è¡ DRC åè½ãçºæ­¤ï¼æåæ ¹æå ´æ¯ä½¿ç¨ä¸åçç¥ç¶ç¶²è·¯ä¾ä¼°è¨ DRC åæ¸ãç¶å¾ï¼å®æåºæ¼æ¨¡åçåè½ä»¥æ¢å¾©åå§é³è¨è¨èãæåçå¯¦é©çµæé¡¯ç¤ºï¼èå¨å©åé³æ¨è³æéä¸æç¨æï¼ææåºçæ¹æ³èå¹¾ç¨®æåé²çæ¹æ³ç¸æ¯ï¼å·ææææ§åç©©å¥æ§ã

##### **Scaling Laws for Precision**
2411.04330v1 by Tanishq Kumar, Zachary Ankner, Benjamin F. Spector, Blake Bordelon, Niklas Muennighoff, Mansheej Paul, Cengiz Pehlevan, Christopher RÃ©, Aditi Raghunathan

Low precision training and inference affect both the quality and cost of
language models, but current scaling laws do not account for this. In this
work, we devise "precision-aware" scaling laws for both training and inference.
We propose that training in lower precision reduces the model's "effective
parameter count," allowing us to predict the additional loss incurred from
training in low precision and post-train quantization. For inference, we find
that the degradation introduced by post-training quantization increases as
models are trained on more data, eventually making additional pretraining data
actively harmful. For training, our scaling laws allow us to predict the loss
of a model with different parts in different precisions, and suggest that
training larger models in lower precision may be compute optimal. We unify the
scaling laws for post and pretraining quantization to arrive at a single
functional form that predicts degradation from training and inference in varied
precisions. We fit on over 465 pretraining runs and validate our predictions on
model sizes up to 1.7B parameters trained on up to 26B tokens.

æè¦ï¼ä½ç²¾åº¦è®­ç»åæ¨çå½±åè¯­è¨æ¨¡åçè´¨éåææ¬ï¼ä½å½åçç¼©æ¾å®å¾å¹¶æªèèè¿ä¸ç¹ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬ä¸ºè®­ç»åæ¨çè®¾è®¡äºâç²¾åº¦æç¥âç¼©æ¾å®å¾ãæä»¬æåºä½ç²¾åº¦è®­ç»ä¼åå°æ¨¡åçâææåæ°è®¡æ°âï¼è®©æä»¬è½å¤é¢æµä½ç²¾åº¦è®­ç»åè®­ç»åéåå¸¦æ¥çé¢å¤æå¤±ãå¯¹äºæ¨çï¼æä»¬åç°è®­ç»åéåå¼å¥çéåéçæ¨¡åå¨æ´å¤æ°æ®ä¸è¿è¡è®­ç»èå¢å ï¼æç»ä½¿é¢å¤çé¢è®­ç»æ°æ®åå¾æå®³ãå¯¹äºè®­ç»ï¼æä»¬çç¼©æ¾å®å¾è®©æä»¬è½å¤é¢æµå·æä¸åç²¾åº¦ä¸åé¨åçæ¨¡åçæå¤±ï¼å¹¶è¡¨æä»¥è¾ä½ç²¾åº¦è®­ç»è¾å¤§çæ¨¡åå¯è½æ¯è®¡ç®æä¼çãæä»¬ç»ä¸è®­ç»ååé¢è®­ç»éåçç¼©æ¾å®å¾ï¼å¾å°ä¸ä¸ªåä¸çå½æ°å½¢å¼ï¼è¯¥å½¢å¼é¢æµäºå¨ä¸åç²¾åº¦ä¸è®­ç»åæ¨ççéåãæä»¬å¯¹è¶è¿ 465 æ¬¡é¢è®­ç»è¿è¡è¿è¡äºæåï¼å¹¶å¯¹å¨å¤è¾¾ 26B ä¸ªæ è®°ä¸è®­ç»çå¤è¾¾ 1.7B ä¸ªåæ°çæ¨¡åå¤§å°è¿è¡äºé¢æµéªè¯ã

##### **CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models**
2411.04329v1 by Jierui Li, Hung Le, Yinbo Zhou, Caiming Xiong, Silvio Savarese, Doyen Sahoo

Pre-trained on massive amounts of code and text data, large language models
(LLMs) have demonstrated remarkable achievements in performing code generation
tasks. With additional execution-based feedback, these models can act as agents
with capabilities to self-refine and improve generated code autonomously.
However, on challenging coding tasks with extremely large search space, current
agentic approaches still struggle with multi-stage planning, generating, and
debugging. To address this problem, we propose CodeTree, a framework for LLM
agents to efficiently explore the search space in different stages of the code
generation process. Specifically, we adopted a unified tree structure to
explicitly explore different coding strategies, generate corresponding coding
solutions, and subsequently refine the solutions. In each stage, critical
decision-making (ranking, termination, expanding) of the exploration process is
guided by both the environmental execution-based feedback and
LLM-agent-generated feedback. We comprehensively evaluated CodeTree on 7 code
generation benchmarks and demonstrated the significant performance gains of
CodeTree against strong baselines. Using GPT-4o as the base model, we
consistently achieved top results of 95.1 on HumanEval, 98.7 on MBPP, and 43.0
on CodeContests. On the challenging SWEBench benchmark, our approach led to
significant performance gains.

æè¦ï¼ééå¤§éç¨å¼ç¢¼åæå­è³æé²è¡é åè¨ç·´ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å·è¡ç¨å¼ç¢¼ç¢çä»»åæ¹é¢å±ç¾åºåè¶çæå°±ãééé¡å¤çå·è¡åé¥ï¼éäºæ¨¡åå¯ç¨ä½å·åèªæä¿®æ­£åèªä¸»æ¹åç¢çç¨å¼ç¢¼è½åçä»£çäººãç¶èï¼å¨æå°ç©ºéæ¥µå¤§çå·ææ°æ§ç·¨ç¢¼ä»»åä¸­ï¼ç®åçä»£çæ¹æ³ä»é£ä»¥æä»å¤éæ®µè¦åãç¢çåé¤é¯ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº CodeTreeï¼ä¸å LLM ä»£çæ¶æ§ï¼å¯å¨ç¨å¼ç¢¼ç¢çç¨åºçä¸åéæ®µæææ¢ç´¢æå°ç©ºéãå·é«ä¾èªªï¼æåæ¡ç¨çµ±ä¸çæ¨¹ççµæ§ä¾æç¢ºæ¢ç´¢ä¸åçç·¨ç¢¼ç­ç¥ãç¢çå°æçç·¨ç¢¼è§£æ±ºæ¹æ¡ï¼ä¸¦é¨å¾ä¿®æ­£éäºè§£æ±ºæ¹æ¡ãå¨æ¯åéæ®µï¼æ¢ç´¢ç¨åºçééµæ±ºç­å¶å®ï¼æåºãçµæ­¢ãæ´åï¼é½åå°ç°å¢å·è¡åé¥å LLM ä»£çç¢çåé¥çæå°ãæåå¨ 7 åç¨å¼ç¢¼ç¢çåºæºä¸å¨é¢è©ä¼°äº CodeTreeï¼ä¸¦è­æäº CodeTree ç¸è¼æ¼å¼·å¤§çåºæºè¡¨ç¾åºé¡¯èçæè½æåãä½¿ç¨ GPT-4o ä½çºåºç¤æ¨¡åï¼æåå¨ HumanEval ä¸æçºç²å¾ 95.1 çé å°çµæãå¨ MBPP ä¸ç²å¾ 98.7ï¼ä»¥åå¨ CodeContests ä¸ç²å¾ 43.0ãå¨å·ææ°æ§ç SWEBench åºæºä¸ï¼æåçåæ³å¸¶ä¾äºé¡¯èçæè½æåã

##### **Balancing Transparency and Accuracy: A Comparative Analysis of Rule-Based and Deep Learning Models in Political Bias Classification**
2411.04328v1 by Manuel Nunez Martinez, Sonja Schmer-Galunder, Zoey Liu, Sangpil Youm, Chathuri Jayaweera, Bonnie J. Dorr

The unchecked spread of digital information, combined with increasing
political polarization and the tendency of individuals to isolate themselves
from opposing political viewpoints, has driven researchers to develop systems
for automatically detecting political bias in media. This trend has been
further fueled by discussions on social media. We explore methods for
categorizing bias in US news articles, comparing rule-based and deep learning
approaches. The study highlights the sensitivity of modern self-learning
systems to unconstrained data ingestion, while reconsidering the strengths of
traditional rule-based systems. Applying both models to left-leaning (CNN) and
right-leaning (FOX) news articles, we assess their effectiveness on data beyond
the original training and test sets.This analysis highlights each model's
accuracy, offers a framework for exploring deep-learning explainability, and
sheds light on political bias in US news media. We contrast the opaque
architecture of a deep learning model with the transparency of a linguistically
informed rule-based model, showing that the rule-based model performs
consistently across different data conditions and offers greater transparency,
whereas the deep learning model is dependent on the training set and struggles
with unseen data.

æè¦ï¼æ¸ä½è³è¨çæ£å¸æªåæ§ç®¡ï¼å ä¸æ¿æ²»å©æ¥µååæ¥çå´éï¼ä»¥ååäººå¾åæ¼å­¤ç«èªå·±ï¼é¿åæ¥è§¸å°ç«çæ¿æ²»è§é»ï¼ä¿ä½¿ç ç©¶äººå¡éç¼ç³»çµ±ï¼ä»¥èªååµæ¸¬åªé«ä¸­çæ¿æ²»åè¦ãç¤¾ç¾¤åªé«ä¸çè¨è«é²ä¸æ­¥å©é·äºéè¡è¶¨å¢ãæåæ¢è¨äºåé¡ç¾åæ°èæç« åè¦çæ¹æ³ï¼ä¸¦æ¯è¼äºåºæ¼è¦ååæ·±åº¦å­¸ç¿çæ¹æ³ãéé ç ç©¶å¼·èª¿äºç¾ä»£èªå­¸ç³»çµ±å°ä¸åç´æçè³æè¼¸å¥çæææ§ï¼åæéæ°èæ®äºå³çµ±åºæ¼è¦åç³»çµ±çåªé»ãå°éå©ç¨®æ¨¡åæç¨æ¼å·¦å¾ï¼CNNï¼åå³å¾ï¼FOXï¼æ°èæç« ï¼æåè©ä¼°äºå®åå¨åå§è¨ç·´åæ¸¬è©¦éä¹å¤è³æä¸çæææ§ãæ­¤åæéé»èªªæäºæ¯åæ¨¡åçæºç¢ºæ§ï¼æä¾äºä¸åæ¢ç´¢æ·±åº¦å­¸ç¿å¯è§£éæ§çæ¡æ¶ï¼ä¸¦é¡æäºç¾åæ°èåªé«ä¸­çæ¿æ²»åè¦ãæåå°æ·±åº¦å­¸ç¿æ¨¡åçä¸éææ¶æ§èåºæ¼èªè¨çåºæ¼è¦åæ¨¡åçéæåº¦é²è¡å°æ¯ï¼é¡¯ç¤ºåºæ¼è¦åçæ¨¡åå¨ä¸åçè³ææ¢ä»¶ä¸è¡¨ç¾ä¸è´ï¼ä¸¦æä¾æ´é«çéæåº¦ï¼èæ·±åº¦å­¸ç¿æ¨¡ååä¾è³´æ¼è¨ç·´éï¼ä¸¦ä¸é£ä»¥èçæªè¦éçè³æã

##### **Gradient Boosting Trees and Large Language Models for Tabular Data Few-Shot Learning**
2411.04324v1 by Carlos Huertas

Large Language Models (LLM) have brought numerous of new applications to
Machine Learning (ML). In the context of tabular data (TD), recent studies show
that TabLLM is a very powerful mechanism for few-shot-learning (FSL)
applications, even if gradient boosting decisions trees (GBDT) have
historically dominated the TD field. In this work we demonstrate that although
LLMs are a viable alternative, the evidence suggests that baselines used to
gauge performance can be improved. We replicated public benchmarks and our
methodology improves LightGBM by 290%, this is mainly driven by forcing node
splitting with few samples, a critical step in FSL with GBDT. Our results show
an advantage to TabLLM for 8 or fewer shots, but as the number of samples
increases GBDT provides competitive performance at a fraction of runtime. For
other real-life applications with vast number of samples, we found FSL still
useful to improve model diversity, and when combined with ExtraTrees it
provides strong resilience to overfitting, our proposal was validated in a ML
competition setting ranking first place.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çºæ©å¨å­¸ç¿ (ML) å¸¶ä¾äºè¨±å¤æ°çæç¨ãå¨è¡¨æ ¼è³æ (TD) çèæ¯ä¸ï¼æè¿çç ç©¶é¡¯ç¤º TabLLM æ¯ä¸ç¨®éå¸¸å¼·å¤§çæ©å¶ï¼å¯ç¨æ¼å°éæ¨£æ¬å­¸ç¿ (FSL) æç¨ï¼å³ä½¿æ¢¯åº¦æåæ±ºç­æ¨¹ (GBDT) å¨æ­·å²ä¸ä¸ç´ä¸»å° TD é åãå¨éé å·¥ä½ä¸­ï¼æåè­æäºåç®¡ LLM æ¯ä¸åå¯è¡çæ¿ä»£æ¹æ¡ï¼ä½è­æè¡¨æç¨æ¼è¡¡éæè½çåºæºç·å¯ä»¥å¾å°æ¹é²ãæåè¤è£½äºå¬éåºæºï¼æåçæè¡æ¹æ³å° LightGBM æåäº 290%ï¼éä¸»è¦æ¯ééå¼·å¶ä½¿ç¨å°éæ¨£æ¬é²è¡ç¯é»åå²ï¼éæ¯ FSL ä¸­ä½¿ç¨ GBDT çééµæ­¥é©ãæåççµæé¡¯ç¤º TabLLM å¨ 8 åææ´å°çæ¨£æ¬ä¸­å·æåªå¢ï¼ä½é¨èæ¨£æ¬æ¸éçå¢å ï¼GBDT å¨ä¸å°é¨åå·è¡æéå§æä¾äºæç«¶ç­åçæè½ãå°æ¼å¶ä»å·æå¤§éæ¨£æ¬çå¯¦éæç¨ï¼æåç¼ç¾ FSL ä»ç¶æå©æ¼æé«æ¨¡åå¤æ¨£æ§ï¼ä¸¦ä¸è ExtraTrees çµåä½¿ç¨æï¼å®æä¾äºå¼·å¤§çéæ¬åå¾©ååï¼æåçææ¡å¨æ©å¨å­¸ç¿ç«¶è³½ä¸­ç²å¾ç¬¬ä¸åï¼å¾å°é©è­ã

##### **A Multilingual Sentiment Lexicon for Low-Resource Language Translation using Large Languages Models and Explainable AI**
2411.04316v1 by Melusi Malinga, Isaac Lupanda, Mike Wa Nkongolo, Phil van Deventer

South Africa and the Democratic Republic of Congo (DRC) present a complex
linguistic landscape with languages such as Zulu, Sepedi, Afrikaans, French,
English, and Tshiluba (Ciluba), which creates unique challenges for AI-driven
translation and sentiment analysis systems due to a lack of accurately labeled
data. This study seeks to address these challenges by developing a multilingual
lexicon designed for French and Tshiluba, now expanded to include translations
in English, Afrikaans, Sepedi, and Zulu. The lexicon enhances cultural
relevance in sentiment classification by integrating language-specific
sentiment scores. A comprehensive testing corpus is created to support
translation and sentiment analysis tasks, with machine learning models such as
Random Forest, Support Vector Machine (SVM), Decision Trees, and Gaussian Naive
Bayes (GNB) trained to predict sentiment across low resource languages (LRLs).
Among them, the Random Forest model performed particularly well, capturing
sentiment polarity and handling language-specific nuances effectively.
Furthermore, Bidirectional Encoder Representations from Transformers (BERT), a
Large Language Model (LLM), is applied to predict context-based sentiment with
high accuracy, achieving 99% accuracy and 98% precision, outperforming other
models. The BERT predictions were clarified using Explainable AI (XAI),
improving transparency and fostering confidence in sentiment classification.
Overall, findings demonstrate that the proposed lexicon and machine learning
models significantly enhance translation and sentiment analysis for LRLs in
South Africa and the DRC, laying a foundation for future AI models that support
underrepresented languages, with applications across education, governance, and
business in multilingual contexts.

æè¦ï¼åéååææ°ä¸»å±åå (DRC) åç¾åºè¤éçèªè¨ç°å¢ï¼å¶ä¸­åå«ç¥é­¯èªãåç´¢æèªãåéè·è­èªãæ³èªãè±èªåå¥ç§å·´èª (å¥ç§å·´èª)ï¼ç±æ¼ç¼ºä¹æºç¢ºæ¨è¨çè³æï¼éå° AI é©åçç¿»è­¯åæç·åæç³»çµ±é æäºç¨ç¹çææ°ãæ¬ç ç©¶æ¨å¨éééç¼ä¸ç¨®å°çºæ³èªåå¥ç§å·´èªè¨­è¨çå¤èªè¨è©å½è¡¨ä¾æå°éäºææ°ï¼ç¾å¨å·²æ´å±å°åæ¬è±èªãåéè·è­èªãåç´¢æèªåç¥é­¯èªçç¿»è­¯ãè©²è©å½è¡¨ééæ´åç¹å®èªè¨çæç·åæ¸ä¾å¢å¼·æç·åé¡ä¸­çæåç¸éæ§ãå»ºç«äºä¸åå¨é¢çæ¸¬è©¦èªæåº«ä¾æ¯æç¿»è­¯åæç·åæä»»åï¼ä¸¦è¨ç·´äºé¨æ©æ£®æãæ¯æåéæ© (SVM)ãæ±ºç­æ¨¹åé«æ¯æ¨¸ç´ è²èæ¯ (GNB) ç­æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ä½è³æºèªè¨ (LRL) çæç·ãå¶ä¸­ï¼é¨æ©æ£®ææ¨¡åè¡¨ç¾ç¹å¥åºè²ï¼æææææç·æ¥µæ§åèçç¹å®èªè¨çç´°å¾®å·®å¥ãæ­¤å¤ï¼ä¾èª Transformer çéåç·¨ç¢¼å¨è¡¨ç¤º (BERT)ï¼ä¸ç¨®å¤§åèªè¨æ¨¡å (LLM)ï¼è¢«ç¨æ¼é æ¸¬åºæ¼ä¸ä¸æçèªæï¼å·æå¾é«çæºç¢ºåº¦ï¼éå° 99% çæºç¢ºåº¦å 98% çç²¾ç¢ºåº¦ï¼åªæ¼å¶ä»æ¨¡åãBERT é æ¸¬ä½¿ç¨å¯è§£é AI (XAI) é²è¡æ¾æ¸ï¼æé«éæåº¦ä¸¦å¢å¼·å°æç·åé¡çä¿¡å¿ãç¸½é«èè¨ï¼ç ç©¶çµæè¡¨æï¼ææåºçè©å½è¡¨åæ©å¨å­¸ç¿æ¨¡åé¡¯èå¢å¼·äºåéååææ°ä¸»å±ååç LRL çç¿»è­¯åæç·åæï¼çºæªä¾æ¯æä»£è¡¨æ§ä¸è¶³çèªè¨ç AI æ¨¡åå¥ å®äºåºç¤ï¼ä¸¦å¨å¤èªè¨ç°å¢ä¸­çæè²ãæ²»çååæ¥­ä¸­æç¨ã

##### **Improving Bilingual Capabilities of Language Models to Support Diverse Linguistic Practices in Education**
2411.04308v1 by Anand Syamkumar, Nora Tseng, Kaycie Barron, Shanglin Yang, Shamya Karumbaiah, Rheeya Uppal, Junjie Hu

Large language models (LLMs) offer promise in generating educational content,
providing instructor feedback, and reducing teacher workload on assessments.
While prior studies have focused on studying LLM-powered learning analytics,
limited research has examined how effective LLMs are in a bilingual context. In
this paper, we study the effectiveness of multilingual large language models
(MLLMs) across monolingual (English-only, Spanish-only) and bilingual
(Spanglish) student writing. We present a learning analytics use case that
details LLM performance in assessing acceptable and unacceptable explanations
of Science and Social Science concepts. Our findings reveal a significant bias
in the grading performance of pre-trained models for bilingual writing compared
to English-only and Spanish-only writing. Following this, we fine-tune
open-source MLLMs including Llama 3.1 and Mistral NeMo using synthetic datasets
generated in English, Spanish, and Spanglish. Our experiments indicate that the
models perform significantly better for all three languages after fine-tuning
with bilingual data. This study highlights the potential of enhancing MLLM
effectiveness to support authentic language practices amongst bilingual
learners. It also aims to illustrate the value of incorporating non-English
languages into the design and implementation of language models in education.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç¢çæè²å§å®¹ãæä¾æå¸«åé¥åæ¸å°æå¸«è©éå·¥ä½è² ææ¹é¢å¾æåæ¯ãéç¶ååçç ç©¶å°æ³¨æ¼ç ç©¶ç± LLM é©åçå­¸ç¿åæï¼ä½æéçç ç©¶æ¢è¨äº LLM å¨éèªç°å¢ä¸­çæææ§ãå¨æ¬æä¸­ï¼æåç ç©¶äºå¤èªè¨å¤§åèªè¨æ¨¡å (MLLM) å¨å®èª (åè±èªãåè¥¿ç­çèª) åéèª (Spanglish) å­¸çå¯«ä½ä¸­çæææ§ãæåæåºäºå­¸ç¿åæä½¿ç¨æ¡ä¾ï¼è©³ç´°èªªæäº LLM å¨è©ä¼°ç§å­¸åç¤¾æç§å­¸æ¦å¿µçå¯æ¥ååä¸å¯æ¥åçè§£éæ¹é¢çè¡¨ç¾ãæåçç ç©¶çµææ­ç¤ºäºèåè±èªååè¥¿ç­çèªå¯«ä½ç¸æ¯ï¼é è¨ç·´æ¨¡åå°éèªå¯«ä½çè©åè¡¨ç¾å­å¨é¡¯èåå·®ãå¨æ­¤ä¹å¾ï¼æåä½¿ç¨è±èªãè¥¿ç­çèªå Spanglish çæçåæè³æéå¾®èª¿äºåæ¬ Llama 3.1 å Mistral NeMo å¨å§çéæº MLLMãæåçå¯¦é©è¡¨æï¼å¨ä½¿ç¨éèªè³æé²è¡å¾®èª¿å¾ï¼éäºæ¨¡åå¨ææä¸ç¨®èªè¨ä¸­çè¡¨ç¾é½é¡¯èæåãéé ç ç©¶å¼·èª¿äºå¢å¼· MLLM çæææ§ä»¥æ¯æéèªå­¸ç¿èççå¯¦èªè¨å¯¦è¸çæ½åãå®éæ¨å¨èªªæå°éè±èªèªè¨ç´å¥æè²ä¸­èªè¨æ¨¡åçè¨­è¨åå¯¦æ½çå¹å¼ã

##### **A Capabilities Approach to Studying Bias and Harm in Language Technologies**
2411.04298v1 by Hellina Hailu Nigatu, Zeerak Talat

Mainstream Natural Language Processing (NLP) research has ignored the
majority of the world's languages. In moving from excluding the majority of the
world's languages to blindly adopting what we make for English, we first risk
importing the same harms we have at best mitigated and at least measured for
English. However, in evaluating and mitigating harms arising from adopting new
technologies into such contexts, we often disregard (1) the actual community
needs of Language Technologies, and (2) biases and fairness issues within the
context of the communities. In this extended abstract, we consider fairness,
bias, and inclusion in Language Technologies through the lens of the
Capabilities Approach. The Capabilities Approach centers on what people are
capable of achieving, given their intersectional social, political, and
economic contexts instead of what resources are (theoretically) available to
them. We detail the Capabilities Approach, its relationship to multilingual and
multicultural evaluation, and how the framework affords meaningful
collaboration with community members in defining and measuring the harms of
Language Technologies.

æè¦ï¼ä¸»æµèªç¶èªè¨èç (NLP) ç ç©¶å¿½ç¥äºä¸çä¸å¤§é¨åèªè¨ãå¨å¾æé¤ä¸çä¸å¤§é¨åèªè¨è½è®çºç²ç®æ¡ç¨æåçºè±èªè£½ä½çå§å®¹æï¼æåé¦ååèè¼¸å¥æåå¨è±èªä¸­è³å¤æ¸è¼ãè³å°è¡¡éçç¸åå±å®³çé¢¨éªãç¶èï¼å¨è©ä¼°åæ¸è¼å å¨éäºç°å¢ä¸­æ¡ç¨æ°æè¡èç¢ççå±å®³æï¼æåå¸¸å¸¸å¿½è¦ (1) èªè¨æè¡çå¯¦éç¤¾åéæ±ï¼ä»¥å (2) ç¤¾åç°å¢ä¸­çåè¦åå¬å¹³æ§åé¡ãå¨æ­¤å»¶ä¼¸æè¦ä¸­ï¼æåééè½åæ¹æ³çè§é»ä¾èéèªè¨æè¡ä¸­çå¬å¹³æ§ãåè¦ååå®¹æ§ãè½åæ¹æ³èéæ¼äººåå¨äº¤ç¹çç¤¾æãæ¿æ²»åç¶æ¿èæ¯ä¸è½å¤ éæä»éº¼ï¼èä¸æ¯ä»åï¼çè«ä¸ï¼å¯ä»¥ç²å¾ä»éº¼è³æºãæåè©³ç´°èªªæè½åæ¹æ³ãå®èå¤èªè¨åå¤æåè©ä¼°çéä¿ï¼ä»¥åè©²æ¡æ¶å¦ä½è®ç¤¾åæå¡å¨å®ç¾©åè¡¡éèªè¨æè¡çå±å®³æé²è¡ææç¾©çåä½ã


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**|Lee Kezar et.al.|[2411.03568v1](http://arxiv.org/abs/2411.03568v1)|null|
|**2024-11-05**|**Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**|Tao Zhang et.al.|[2411.02864v1](http://arxiv.org/abs/2411.02864v1)|null|
|**2024-11-05**|**Multimodal Commonsense Knowledge Distillation for Visual Question Answering**|Shuo Yang et.al.|[2411.02722v1](http://arxiv.org/abs/2411.02722v1)|null|
|**2024-11-04**|**Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**|Harshavardhana T. Gowda et.al.|[2411.02591v1](http://arxiv.org/abs/2411.02591v1)|[link](https://github.com/HarshavardhanaTG/geometryOfOrofacialNeuromuscularSystem)|
|**2024-11-04**|**GraphXAIN: Narratives to Explain Graph Neural Networks**|Mateusz Cedro et.al.|[2411.02540v1](http://arxiv.org/abs/2411.02540v1)|[link](https://github.com/ADMAntwerp/GraphXAIN)|
|**2024-11-04**|**Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**|Guangzhi Xiong et.al.|[2411.02382v1](http://arxiv.org/abs/2411.02382v1)|null|
|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807v1](http://arxiv.org/abs/2411.01807v1)|null|
|**2024-11-03**|**Graph-based Confidence Calibration for Large Language Models**|Yukun Li et.al.|[2411.02454v1](http://arxiv.org/abs/2411.02454v1)|null|
|**2024-11-03**|**Ontology Population using LLMs**|Sanaz Saki Norouzi et.al.|[2411.01612v1](http://arxiv.org/abs/2411.01612v1)|null|
|**2024-11-03**|**Pre-trained Molecular Language Models with Random Functional Group Masking**|Tianhao Peng et.al.|[2411.01401v1](http://arxiv.org/abs/2411.01401v1)|null|
|**2024-11-01**|**Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**|Xinyi Leng et.al.|[2411.02435v1](http://arxiv.org/abs/2411.02435v1)|null|
|**2024-11-01**|**WLPlan: Relational Features for Symbolic Planning**|Dillon Z. Chen et.al.|[2411.00577v1](http://arxiv.org/abs/2411.00577v1)|null|
|**2024-11-01**|**GRSQA -- Graph Reasoning-Structured Question Answering Dataset**|Anish Pahilajani et.al.|[2411.00369v2](http://arxiv.org/abs/2411.00369v2)|null|
|**2024-11-01**|**Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**|Balu Bhasuran et.al.|[2411.02523v1](http://arxiv.org/abs/2411.02523v1)|null|
|**2024-10-31**|**Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**|Beyazit Yalcinkaya et.al.|[2411.00205v1](http://arxiv.org/abs/2411.00205v1)|null|
|**2024-10-31**|**Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**|Yu Pan et.al.|[2411.00188v1](http://arxiv.org/abs/2411.00188v1)|null|
|**2024-10-31**|**Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**|Phil Wee et.al.|[2411.00878v1](http://arxiv.org/abs/2411.00878v1)|null|
|**2024-10-31**|**Failure Modes of LLMs for Causal Reasoning on Narratives**|Khurram Yamin et.al.|[2410.23884v1](http://arxiv.org/abs/2410.23884v1)|[link](https://github.com/shantanu95/llm_causal_reasoning)|
|**2024-10-31**|**Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**|Liyi Chen et.al.|[2410.23875v1](http://arxiv.org/abs/2410.23875v1)|[link](https://github.com/liyichen-cly/pog)|
|**2024-10-31**|**LLaMo: Large Language Model-based Molecular Graph Assistant**|Jinyoung Park et.al.|[2411.00871v1](http://arxiv.org/abs/2411.00871v1)|null|
|**2024-10-31**|**End-to-End Ontology Learning with Large Language Models**|Andy Lo et.al.|[2410.23584v1](http://arxiv.org/abs/2410.23584v1)|[link](https://github.com/andylolu2/ollm)|
|**2024-10-30**|**Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**|Vicky Dong et.al.|[2410.23452v1](http://arxiv.org/abs/2410.23452v1)|null|
|**2024-10-30**|**FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**|Anuroop Sriram et.al.|[2410.23405v1](http://arxiv.org/abs/2410.23405v1)|[link](https://github.com/facebookresearch/flowmm)|
|**2024-10-30**|**EMMA: End-to-End Multimodal Model for Autonomous Driving**|Jyh-Jing Hwang et.al.|[2410.23262v2](http://arxiv.org/abs/2410.23262v2)|null|
|**2024-10-30**|**ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**|Zhichao Hou et.al.|[2410.23182v1](http://arxiv.org/abs/2410.23182v1)|null|
|**2024-10-30**|**Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**|Deperias Kerre et.al.|[2410.22996v1](http://arxiv.org/abs/2410.22996v1)|null|
|**2024-10-30**|**How Well Do Large Language Models Disambiguate Swedish Words?**|Richard Johansson et.al.|[2410.22827v1](http://arxiv.org/abs/2410.22827v1)|null|
|**2024-10-30**|**Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**|Sejin Lee et.al.|[2410.22767v1](http://arxiv.org/abs/2410.22767v1)|[link](https://github.com/eastha0526/beyond-ontology-in-dst)|
|**2024-10-30**|**The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**|Reza Moravej et.al.|[2411.00843v1](http://arxiv.org/abs/2411.00843v1)|null|
|**2024-10-29**|**Are Large-Language Models Graph Algorithmic Reasoners?**|Alexander K Taylor et.al.|[2410.22597v1](http://arxiv.org/abs/2410.22597v1)|[link](https://github.com/ataylor24/magma)|
|**2024-10-29**|**Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**|Adrian Garret Gabriel et.al.|[2410.22457v1](http://arxiv.org/abs/2410.22457v1)|null|
|**2024-10-29**|**DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**|Chengke Zou et.al.|[2411.00836v1](http://arxiv.org/abs/2411.00836v1)|null|
|**2024-10-29**|**ADAM: An Embodied Causal Agent in Open-World Environments**|Shu Yu et.al.|[2410.22194v1](http://arxiv.org/abs/2410.22194v1)|null|
|**2024-10-29**|**Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**|Zhilun Zhou et.al.|[2411.00028v1](http://arxiv.org/abs/2411.00028v1)|null|
|**2024-10-29**|**A Hierarchical Language Model For Interpretable Graph Reasoning**|Sambhav Khurana et.al.|[2410.22372v1](http://arxiv.org/abs/2410.22372v1)|null|
|**2024-10-28**|**LLM-Forest for Health Tabular Data Imputation**|Xinrui He et.al.|[2410.21520v1](http://arxiv.org/abs/2410.21520v1)|null|
|**2024-10-28**|**Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**|Zhantao Yang et.al.|[2410.21237v1](http://arxiv.org/abs/2410.21237v1)|null|
|**2024-10-28**|**CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**|Meiqi Chen et.al.|[2410.21067v1](http://arxiv.org/abs/2410.21067v1)|null|
|**2024-10-28**|**CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**|Yutong Cheng et.al.|[2410.21060v1](http://arxiv.org/abs/2410.21060v1)|null|
|**2024-10-28**|**Graph-based Uncertainty Metrics for Long-form Language Model Outputs**|Mingjian Jiang et.al.|[2410.20783v1](http://arxiv.org/abs/2410.20783v1)|[link](https://github.com/mingjianjiang-1/graph-based-uncertainty)|
|**2024-10-28**|**Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**|Prakhar Verma et.al.|[2410.20753v1](http://arxiv.org/abs/2410.20753v1)|null|
|**2024-10-28**|**Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**|Mufei Li et.al.|[2410.20724v1](http://arxiv.org/abs/2410.20724v1)|null|
|**2024-10-27**|**Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**|Xingrui Zhuo et.al.|[2410.20321v1](http://arxiv.org/abs/2410.20321v1)|null|
|**2024-10-26**|**Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**|Vishesh Prasad et.al.|[2410.21324v1](http://arxiv.org/abs/2410.21324v1)|null|
|**2024-10-25**|**DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**|Pengfei Hu et.al.|[2410.19955v1](http://arxiv.org/abs/2410.19955v1)|null|
|**2024-10-25**|**FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**|Nicole Cho et.al.|[2410.19727v1](http://arxiv.org/abs/2410.19727v1)|null|
|**2024-10-25**|**Knowledge Graph Enhanced Language Agents for Recommendation**|Taicheng Guo et.al.|[2410.19627v1](http://arxiv.org/abs/2410.19627v1)|null|
|**2024-10-25**|**Graph Linearization Methods for Reasoning on Graphs with Large Language Models**|Christos Xypolopoulos et.al.|[2410.19494v1](http://arxiv.org/abs/2410.19494v1)|null|
|**2024-10-25**|**Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**|Weikai Li et.al.|[2410.19225v1](http://arxiv.org/abs/2410.19225v1)|null|
|**2024-10-24**|**Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**|Bruno Croso Cunha da Silva et.al.|[2410.19193v1](http://arxiv.org/abs/2410.19193v1)|null|
|**2024-10-24**|**GCoder: Improving Large Language Model for Generalized Graph Problem Solving**|Qifan Zhang et.al.|[2410.19084v1](http://arxiv.org/abs/2410.19084v1)|[link](https://github.com/bklight999/www25-gcoder)|
|**2024-10-24**|**LLM-based Online Prediction of Time-varying Graph Signals**|Dayu Qin et.al.|[2410.18718v1](http://arxiv.org/abs/2410.18718v1)|null|
|**2024-10-24**|**Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**|Kexuan Xin et.al.|[2410.18475v2](http://arxiv.org/abs/2410.18475v2)|null|
|**2024-10-24**|**ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**|Zezhong Wang et.al.|[2410.18447v1](http://arxiv.org/abs/2410.18447v1)|null|
|**2024-10-24**|**Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**|Kun Li et.al.|[2410.18415v1](http://arxiv.org/abs/2410.18415v1)|null|
|**2024-10-23**|**Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**|Jaime Sevilla et.al.|[2410.18060v1](http://arxiv.org/abs/2410.18060v1)|null|
|**2024-10-23**|**Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**|Rui Yang et.al.|[2410.17600v1](http://arxiv.org/abs/2410.17600v1)|null|
|**2024-10-23**|**Navigate Complex Physical Worlds via Geometrically Constrained LLM**|Yongqiang Huang et.al.|[2410.17529v1](http://arxiv.org/abs/2410.17529v1)|null|
|**2024-10-22**|**Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs**|Leyao Wang et.al.|[2410.16882v1](http://arxiv.org/abs/2410.16882v1)|null|
|**2024-10-22**|**Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning**|Muzhi Li et.al.|[2410.16803v1](http://arxiv.org/abs/2410.16803v1)|null|
|**2024-10-22**|**The Scene Language: Representing Scenes with Programs, Words, and Embeddings**|Yunzhi Zhang et.al.|[2410.16770v1](http://arxiv.org/abs/2410.16770v1)|null|
|**2024-10-22**|**Atomic Fact Decomposition Helps Attributed Question Answering**|Zhichao Yan et.al.|[2410.16708v1](http://arxiv.org/abs/2410.16708v1)|null|
|**2024-10-22**|**PLDR-LLM: Large Language Model from Power Law Decoder Representations**|Burc Gokden et.al.|[2410.16703v1](http://arxiv.org/abs/2410.16703v1)|[link](https://github.com/burcgokden/llm-from-power-law-decoder-representations)|
|**2024-10-22**|**Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency**|Prafulla Kumar Choubey et.al.|[2410.16597v1](http://arxiv.org/abs/2410.16597v1)|null|
|**2024-10-21**|**Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight**|Oliver Bensch et.al.|[2410.16397v1](http://arxiv.org/abs/2410.16397v1)|null|
|**2024-10-21**|**A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**|Tianyi Men et.al.|[2410.16155v1](http://arxiv.org/abs/2410.16155v1)|null|
|**2024-10-21**|**CausalGraph2LLM: Evaluating LLMs for Causal Queries**|Ivaxi Sheth et.al.|[2410.15939v1](http://arxiv.org/abs/2410.15939v1)|[link](https://github.com/ivaxi0s/causalgraph2llm)|
|**2024-10-21**|**LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**|Tejumade Afonja et.al.|[2410.15828v1](http://arxiv.org/abs/2410.15828v1)|null|
|**2024-10-21**|**NetSafe: Exploring the Topological Safety of Multi-agent Networks**|Miao Yu et.al.|[2410.15686v1](http://arxiv.org/abs/2410.15686v1)|null|
|**2024-10-20**|**TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models**|Bo Pan et.al.|[2410.15268v1](http://arxiv.org/abs/2410.15268v1)|null|
|**2024-10-19**|**Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction**|Yinhan He et.al.|[2410.15165v1](http://arxiv.org/abs/2410.15165v1)|null|
|**2024-10-19**|**MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science**|Junho Kim et.al.|[2410.15126v1](http://arxiv.org/abs/2410.15126v1)|null|
|**2024-10-19**|**Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models**|Qitan Lv et.al.|[2410.15116v1](http://arxiv.org/abs/2410.15116v1)|null|
|**2024-10-19**|**A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers**|George Hannah et.al.|[2410.15064v1](http://arxiv.org/abs/2410.15064v1)|null|
|**2024-10-19**|**LangGFM: A Large Language Model Alone Can be a Powerful Graph Foundation Model**|Tianqianjin Lin et.al.|[2410.14961v1](http://arxiv.org/abs/2410.14961v1)|null|
|**2024-10-18**|**TransBox: EL++-closed Ontology Embedding**|Hui Yang et.al.|[2410.14571v1](http://arxiv.org/abs/2410.14571v1)|null|
|**2024-10-18**|**Enabling Scalable Evaluation of Bias Patterns in Medical LLMs**|Hamed Fayyaz et.al.|[2410.14763v1](http://arxiv.org/abs/2410.14763v1)|[link](https://github.com/healthylaife/autofair)|
|**2024-10-18**|**Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning**|Xingyu Tan et.al.|[2410.14211v2](http://arxiv.org/abs/2410.14211v2)|null|
|**2024-10-18**|**UniMTS: Unified Pre-training for Motion Time Series**|Xiyuan Zhang et.al.|[2410.19818v1](http://arxiv.org/abs/2410.19818v1)|[link](https://github.com/xiyuanzh/unimts)|
|**2024-10-18**|**Supervised Chain of Thought**|Xiang Zhang et.al.|[2410.14198v1](http://arxiv.org/abs/2410.14198v1)|null|
|**2024-10-17**|**Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs**|Simone Conia et.al.|[2410.14057v1](http://arxiv.org/abs/2410.14057v1)|null|
|**2024-10-17**|**RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs**|Jiatan Huang et.al.|[2410.13987v1](http://arxiv.org/abs/2410.13987v1)|null|
|**2024-10-17**|**The Mystery of the Pathological Path-star Task for Language Models**|Arvid Frydenlund et.al.|[2410.13779v1](http://arxiv.org/abs/2410.13779v1)|null|
|**2024-10-17**|**Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**|Yu Xia et.al.|[2410.13765v1](http://arxiv.org/abs/2410.13765v1)|null|
|**2024-10-17**|**LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models**|David Hoffmann et.al.|[2410.13299v1](http://arxiv.org/abs/2410.13299v1)|null|
|**2024-10-17**|**Trust but Verify: Programmatic VLM Evaluation in the Wild**|Viraj Prabhu et.al.|[2410.13121v1](http://arxiv.org/abs/2410.13121v1)|null|
|**2024-10-16**|**Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models**|Linhao Luo et.al.|[2410.13080v1](http://arxiv.org/abs/2410.13080v1)|[link](https://github.com/RManLuo/graph-constrained-reasoning)|
|**2024-10-16**|**Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models**|Tong Liu et.al.|[2410.13051v1](http://arxiv.org/abs/2410.13051v1)|null|
|**2024-10-16**|**Learning Representations for Reasoning: Generalizing Across Diverse Structures**|Zhaocheng Zhu et.al.|[2410.13018v1](http://arxiv.org/abs/2410.13018v1)|null|
|**2024-10-16**|**Large Language Models as a Tool for Mining Object Knowledge**|Hannah YoungEun An et.al.|[2410.12959v1](http://arxiv.org/abs/2410.12959v1)|null|
|**2024-10-16**|**FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**|Zhenheng Tang et.al.|[2410.12707v1](http://arxiv.org/abs/2410.12707v1)|null|
|**2024-10-16**|**The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**|Minghao Wu et.al.|[2410.12458v1](http://arxiv.org/abs/2410.12458v1)|null|
|**2024-10-16**|**PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**|Markus J. Buehler et.al.|[2410.12375v1](http://arxiv.org/abs/2410.12375v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2024-10-16**|**Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs**|Lei Sun et.al.|[2410.12298v2](http://arxiv.org/abs/2410.12298v2)|null|
|**2024-10-16**|**LLM-based Cognitive Models of Students with Misconceptions**|Shashank Sonkar et.al.|[2410.12294v2](http://arxiv.org/abs/2410.12294v2)|null|
|**2024-10-16**|**Comprehending Knowledge Graphs with Large Language Models for Recommender Systems**|Ziqiang Cui et.al.|[2410.12229v1](http://arxiv.org/abs/2410.12229v1)|null|
|**2024-10-16**|**Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations**|Luyi Ma et.al.|[2410.12228v1](http://arxiv.org/abs/2410.12228v1)|null|
|**2024-10-16**|**Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning**|Huiwen Wu et.al.|[2410.12130v1](http://arxiv.org/abs/2410.12130v1)|null|
|**2024-10-15**|**Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning**|Guangxin Su et.al.|[2410.12096v1](http://arxiv.org/abs/2410.12096v1)|null|

#### Abstracts
##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders SÃ¸gaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

æè¦ï¼åç­æ¯èªç¶èªè¨çè§£ä»»åï¼æ¶åå°æç¢ºçä¸ä¸æåæªèªªæçç¸éé åç¥è­é²è¡æ¨çãæ¯æå¤§å¤æ¸ç¶ä»£åç­ç³»çµ±çå¤§åèªè¨æ¨¡å (LLM) é£ä»¥æ¨è«æ¦å¿µå¦ä½å¨é«å­¸ç­å°æ¥­é åä¸­éè¯ãç¾æçé«å­¸ LLM è¨ç·´ææ¬ä¹å¾é«ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº MEGï¼éæ¯ä¸ç¨®ç¨æ¼é«å­¸ç¥è­å¢å¼· LLM çåæ¸æææ¹æ³ãMEG ä½¿ç¨è¼éç´æ å°ç¶²è·¯å°åè¡¨åµå¥æ´åå° LLM ä¸­ï¼ä½¿å¶è½å¤ ä»¥ç¶æ¿ææçæ¹å¼å©ç¨å¤é¨ç¥è­ãæåå¨ååæµè¡çé«å­¸å¤é¸é¡è³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ä¸¦è¡¨æ LLM å¾ç¥è­åè¡¨åµå¥æä¾çå¯¦éä¾æä¸­åçåªæ·ºãMEG å¨ Mistral-Instruct åºæºä¸å¹³åæé«äº +10.2% çæºç¢ºåº¦ï¼å¨ BioMistral ç­å°éæ¨¡åä¸æé«äº +6.7%ãæåéå±ç¤ºäºåºæ¼ Llama-3 ççµæãæå¾ï¼æåè¡¨æ MEG çæ§è½å°åè¡¨ç·¨ç¢¼å¨çé¸æä¿æç©©å¥ã

##### **The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**
2411.03568v1 by Lee Kezar, Nidhi Munikote, Zian Zeng, Zed Sehyr, Naomi Caselli, Jesse Thomason

Language models for American Sign Language (ASL) could make language
technologies substantially more accessible to those who sign. To train models
on tasks such as isolated sign recognition (ISR) and ASL-to-English
translation, datasets provide annotated video examples of ASL signs. To
facilitate the generalizability and explainability of these models, we
introduce the American Sign Language Knowledge Graph (ASLKG), compiled from
twelve sources of expert linguistic knowledge. We use the ASLKG to train
neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of
91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%
for classifying the topic of Youtube-ASL videos.

æè¦ï¼ç¾åæèª (ASL) çèªè¨æ¨¡åå¯ä»¥è®èªè¨æè¡å°æèªä½¿ç¨èæ´ææ¼ä½¿ç¨ãçºäºè¨ç·´æ¨¡åå·è¡æèªè¾¨è­ (ISR) å ASL è½ææè±æç­ä»»åï¼è³æéæä¾ ASL æå¢çè¨»è§£å½±çç¯ä¾ãçºäºä¿é²éäºæ¨¡åçæ¦æ¬æ§åå¯è§£éæ§ï¼æåå¼å¥äºç¾åæèªç¥è­åè­ (ASLKG)ï¼å®æ¯ç±åäºåå°å®¶èªè¨ç¥è­ä¾æºç·¨è­¯èæçãæåä½¿ç¨ ASLKG è¨ç·´ç¥ç¶ç¬¦èæ¨¡åä¾å·è¡ 3 é  ASL çè§£ä»»åï¼å¨ ISR ä¸éå° 91% çæºç¢ºåº¦ãå¨é æ¸¬æªè¦æå¢çèªç¾©ç¹å¾µä¸éå° 14%ï¼ä»¥åå¨åé¡ YouTube-ASL å½±çä¸»é¡ä¸éå° 36%ã

##### **Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**
2411.02864v1 by Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu

Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
"ensemble-play", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æµ·éèªæåº«ä¸é åè¨ç·´ï¼å·²å¨è¨±å¤èªç¶èªè¨èçä»»åä¸å±ç¾åºä»¤äººå°è±¡æ·±å»çå°éæ¨£æ¬å­¸ç¿è½åãå°èªç¶èªè¨èçä»»åè½åçºæå­å°æå­ççæä»»åæ¯ä¸ç¨®å¸¸è¦åæ³ï¼éæ¨£çæå¼å¤§åèªè¨æ¨¡åå°±å¯ä»¥æç¤ºè§£æ±ºå®ãç¶èï¼ç±æ¼ DocRE ççµæ§åè¼¸åºæ ¼å¼ï¼ä½¿ç¨çæå¼å¤§åèªè¨æ¨¡åä¾å·è¡æä»¶ç´å¥éä¿èå (DocRE) ä»»åä»ç¶å·æææ°æ§ï¼éä½¿å¾è½æçºç´æå­è®å¾è¤éãå°éæ¨£æ¬åæç¤ºèªªæä¸­å¯ç¨çè³è¨æéï¼æå°è´å¨æä»¶ä¸­æå°å¯¦é«çéä¿èåä¸­ç¢çé²ä¸æ­¥çå°é£åææ°ãå¨æ¬æä¸­ï¼æåå°çµæ§åè¼¸åºè¡¨ç¤ºçºåå½¢æ¨£å¼çä¸åçµï¼èä¸æ¯èªç¶èªè¨è¡¨éï¼ä¸¦å©ç¨çæå¼å¤§åèªè¨æ¨¡åä¾å·è¡ DocRE ä»»åãæåçåæ³ï¼åå½¢ DPEP æ¡æ¶ï¼æ¯åºæ¼èªç¶èªè¨ä¸­åç¾çä¸åçµè§£éææ³èå¾çæ¨çãå¨éåæ¡æ¶ä¸­ï¼æåé¦åä»ç´¹ä¸ç¨®ãåè§£æå¥ãæ¹æ³ï¼ç¨æ¼å°å·æé¡åç©ºéåè§£çæç¤ºé²è¡å¤§åèªè¨æ¨¡åçæï¼ä»¥æ¸è¼ååææéä¿é¡åçè² æãå¶æ¬¡ï¼æåä½¿ç¨é©è­å¨ä¾æ ¡æºçæä¸¦è­å¥è¢«å¿½ç¥çæ¥è©¢å¯¦é«å°ãç¬¬ä¸ï¼æåéç¼ãæ´é«éæ²ãï¼ééå©ç¨èéºå¤±æ¥è©¢å°ç¸éçå­åä¸­åµå¥çæ¨çææ³ï¼å¨æ´åé¡ååè¡¨ä¸éæ°æç¨çæï¼ä»¥è§£æ±ºéºå¤±åé¡ãééèç¾ææç¤ºæè¡åæ¿ä»£èªè¨æ¨¡å (LLM) çå»£æ³æ¯è¼ï¼æåçæ¡æ¶å¨å¯¦é©ä¸­è­æäºå¨å¬éåºæºä¸çåªç°æ§è½ã

##### **Multimodal Commonsense Knowledge Distillation for Visual Question Answering**
2411.02722v1 by Shuo Yang, Siwen Luo, Soyeon Caren Han

Existing Multimodal Large Language Models (MLLMs) and Visual Language
Pretrained Models (VLPMs) have shown remarkable performances in the general
Visual Question Answering (VQA). However, these models struggle with VQA
questions that require external commonsense knowledge due to the challenges in
generating high-quality prompts and the high computational costs of
fine-tuning. In this work, we propose a novel graph-based multimodal
commonsense knowledge distillation framework that constructs a unified
relational graph over commonsense knowledge, visual objects and questions
through a Graph Convolutional Network (GCN) following a teacher-student
environment. This proposed framework is flexible with any type of teacher and
student models without further fine-tuning, and has achieved competitive
performances on the ScienceQA dataset.

æè¦ï¼ç¾æçå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) åè¦è¦ºèªè¨é è¨ç·´æ¨¡å (VLPM) å¨ä¸è¬çè¦è¦ºåç­ (VQA) ä¸­å±ç¾äºåè¶çè¡¨ç¾ãç¶èï¼éäºæ¨¡åå¨éè¦å¤é¨å¸¸è­ç¥è­ç VQA åé¡ä¸æéå°å°é£ï¼åå å¨æ¼ç¢çé«åè³ªæç¤ºçææ°ä»¥åå¾®èª¿çé«éç®ææ¬ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åæ°ç©çåºæ¼åå½¢çæ¨¡æå¸¸è­ç¥è­èåæ¶æ§ï¼ééåå½¢å·ç©ç¶²è·¯ (GCN) å¨å¸¸è­ç¥è­ãè¦è¦ºç©ä»¶ååé¡ä¸å»ºæ§ä¸åçµ±ä¸çéè¯åå½¢ï¼éµå¾ªå¸«çç°å¢ãéåæåºçæ¶æ§å°æ¼ä»»ä½é¡åçæå¸«åå­¸çæ¨¡åé½å·æå½æ§ï¼ç¡éé²ä¸æ­¥å¾®èª¿ï¼ä¸¦å¨ ScienceQA è³æéä¸åå¾äºæç«¶ç­åçè¡¨ç¾ã

##### **Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**
2411.02591v1 by Harshavardhana T. Gowda, Zachary D. McNaughton, Lee M. Miller

Each year, millions of individuals lose the ability to speak intelligibly due
to causes such as neuromuscular disease, stroke, trauma, and head/neck cancer
surgery (e.g. laryngectomy) or treatment (e.g. radiotherapy toxicity to the
speech articulators). Effective communication is crucial for daily activities,
and losing the ability to speak leads to isolation, depression, anxiety, and a
host of detrimental sequelae. Noninvasive surface electromyography (sEMG) has
shown promise to restore speech output in these individuals. The goal is to
collect sEMG signals from multiple articulatory sites as people silently
produce speech and then decode the signals to enable fluent and natural
communication. Currently, many fundamental properties of orofacial
neuromuscular signals relating to speech articulation remain unanswered. They
include questions relating to 1) the data structure of the orofacial sEMG
signals, 2)the signal distribution shift of sEMG across individuals, 3) ability
of sEMG signals to span the entire English language phonetic space during
silent speech articulations, and 4) the generalization capability of
non-invasive sEMG based silent speech interfaces. We address these questions
through a series of experiments involving healthy human subjects. We show that
sEMG signals evince graph data structure and that the signal distribution shift
is given by a change of basis. Furthermore, we show that silently voiced
articulations spanning the entire English language phonetic space can be
decoded using small neural networks which can be trained with little data and
that such architectures work well across individuals. To ensure transparency
and reproducibility, we open-source all the data and codes used in this study.

æè¦ï¼æ¯å¹´ï¼æ¸ç¾è¬äººå çºç¥ç¶èèç¾çãä¸­é¢¨ãåµå·åé ­é ¸çæè¡ï¼ä¾å¦ååé¤è¡ï¼ææ²»çï¼ä¾å¦æ¾å°æ²»çå°è¨èªç¼é³å¨å®çæ¯æ§ï¼ç­åå èå¤±å»æ¸æ°èªªè©±çè½åãææçæºéå°æ¼æ¥å¸¸çæ´»è³ééè¦ï¼èå¤±å»èªªè©±è½åæå°è´å­¤ç«ãæ²®åªãç¦æ®åä¸ç³»åæå®³çå¾éºçãéä¾µå¥æ§è¡¨é¢èé»å (sEMG) å·²é¡¯ç¤ºåºæ¢å¾©éäºäººèªªè©±è¼¸åºçå¸æãç®æ¨æ¯å¾å¤åç¼é³é¨ä½æ¶é sEMG ä¿¡èï¼å çºäººåå¨ç¡è²å°ç¼åºè¨èªï¼ç¶å¾è§£ç¢¼ä¿¡èä»¥å¯¦ç¾æµå©åèªç¶çæºéãç®åï¼è¨±å¤èè¨èªç¼é³æéçé¡é¢ç¥ç¶èèä¿¡èçåºæ¬ç¹æ§ä»ç¶æ²æå¾å°è§£ç­ãå®ååæ¬è 1) é¡é¢ sEMG ä¿¡èçæ¸æçµæ§ã2) sEMG å¨åé«éçä¿¡èåä½è½ç§»ã3) sEMG ä¿¡èå¨ç¡è²è¨èªç¼é³éç¨ä¸­è·¨è¶æ´åè±èªèªè¨é³æ¨ç©ºéçè½åä»¥å 4) åºæ¼éä¾µå¥æ§ sEMG çç¡è²è¨èªä»é¢çæ¦æ¬è½åç¸éçåé¡ãæåééä¸ç³»åæ¶åå¥åº·äººé¡åè©¦èçå¯¦é©ä¾è§£æ±ºéäºåé¡ãæåè¡¨æ sEMG ä¿¡èè­æåæ¸æçµæ§ï¼ä¸¦ä¸ä¿¡èåä½è½ç§»æ¯ç±åºè®åççµ¦åºãæ­¤å¤ï¼æåè¡¨æä½¿ç¨å¯ä»¥ééå°éæ¸æè¨ç·´çå°ç¥ç¶ç¶²è·¯å¯ä»¥è§£ç¢¼è·¨è¶æ´åè±èªèªè¨é³æ¨ç©ºéçç¡è²ç¼é³ï¼ä¸¦ä¸æ­¤é¡æ¶æ§å¨ä¸ååé«ä¹ééè¡è¯å¥½ãçºäºç¢ºä¿éæåº¦åå¯éç¾æ§ï¼æåå¬éäºæ¬ç ç©¶ä¸­ä½¿ç¨çæææ¸æåä»£ç¢¼ã

##### **GraphXAIN: Narratives to Explain Graph Neural Networks**
2411.02540v1 by Mateusz Cedro, David Martens

Graph Neural Networks (GNNs) are a powerful technique for machine learning on
graph-structured data, yet they pose interpretability challenges, especially
for non-expert users. Existing GNN explanation methods often yield technical
outputs such as subgraphs and feature importance scores, which are not easily
understood. Building on recent insights from social science and other
Explainable AI (XAI) methods, we propose GraphXAIN, a natural language
narrative that explains individual predictions made by GNNs. We present a
model-agnostic and explainer-agnostic XAI approach that complements graph
explainers by generating GraphXAINs, using Large Language Models (LLMs) and
integrating graph data, individual predictions from GNNs, explanatory
subgraphs, and feature importances. We define XAI Narratives and XAI
Descriptions, highlighting their distinctions and emphasizing the importance of
narrative principles in effective explanations. By incorporating natural
language narratives, our approach supports graph practitioners and non-expert
users, aligning with social science research on explainability and enhancing
user understanding and trust in complex GNN models. We demonstrate GraphXAIN's
capabilities on a real-world graph dataset, illustrating how its generated
narratives can aid understanding compared to traditional graph explainer
outputs or other descriptive explanation methods.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) æ¯æ©å¨å­¸ç¿ä¸­ç¨æ¼åå½¢çµæ§è³æçå¼·å¤§æè¡ï¼ä½å®åæåºäºå¯è§£éæ§çææ°ï¼ç¹å¥æ¯å°æ¼éå°å®¶ä½¿ç¨èãç¾æç GNN è§£éæ¹æ³éå¸¸æç¢çæè¡è¼¸åºï¼ä¾å¦å­ååç¹å¾µéè¦æ§åæ¸ï¼éäºè¼¸åºä¸å®¹æçè§£ãå»ºç«å¨ç¤¾æç§å­¸åå¶ä»å¯è§£é AI (XAI) æ¹æ³çææ°è¦è§£ä¸ï¼æåæåºäº GraphXAINï¼éæ¯ä¸ç¨®èªç¶èªè¨æè¿°ï¼ç¨æ¼è§£é GNN ååºçåå¥é æ¸¬ãæåæåºäºä¸ç¨®èæ¨¡åç¡éä¸èè§£éå¨ç¡éç XAI æ¹æ³ï¼å®ééä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åæ´ååå½¢è³æãGNN çåå¥é æ¸¬ãè§£éæ§å­ååç¹å¾µéè¦æ§ä¾è£ååå½¢è§£éå¨ï¼é²èç¢ç GraphXAINãæåå®ç¾©äº XAI æè¿°å XAI æè¿°ï¼å¼·èª¿å®åçåå¥ä¸¦å¼·èª¿æè¿°ååå¨ææè§£éä¸­çéè¦æ§ãééç´å¥èªç¶èªè¨æè¿°ï¼æåçåæ³æ¯æ´åå½¢å¾æ¥­äººå¡åéå°å®¶ä½¿ç¨èï¼èç¤¾æç§å­¸å°å¯è§£éæ§çç ç©¶ä¿æä¸è´ï¼ä¸¦å¢å¼·ä½¿ç¨èå°è¤é GNN æ¨¡åççè§£åä¿¡ä»»ãæåå¨çå¯¦ä¸ççåå½¢è³æéä¸å±ç¤ºäº GraphXAIN çåè½ï¼èªªæèå³çµ±çåå½¢è§£éå¨è¼¸åºæå¶ä»æè¿°æ§è§£éæ¹æ³ç¸æ¯ï¼å®ç¢ççæè¿°å¦ä½æå©æ¼çè§£ã

##### **Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**
2411.02382v1 by Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ç§å­¸é åå±ç¾åè¶çè½åï¼å¾èªç¶èªè¨èçå°è¤éçè§£æ±ºåé¡ä»»åãå®åçè§£åç¢çé¡ä¼¼äººé¡æå­çè½åçºæ¨é²ç§å­¸ç ç©¶éåäºæ°çå¯è½æ§ï¼è®è³æåæãæç»åé¡§ï¼çè³å¯¦é©è¨­è¨ç­ä»»åæçºå¯è½ãLLM å¨æ­¤èçµ¡ä¸­ææå¸æçæç¨ä¹ä¸æ¯åè¨­ç¢çï¼å®åè½ééåæç¾æç¥è­ä¾æ¾åºæ°çç ç©¶æ¹åãç¶èï¼åç®¡ LLM å·ææ½åï¼å®åå»å®¹æç¢çãå¹»è¦ºãï¼ä¹å°±æ¯è½èµ·ä¾åçä½äºå¯¦ä¸ä¸æ­£ç¢ºçè¼¸åºãæ­¤é¡åé¡å¨éè¦å´è¬¹æºç¢ºæ§åå¯é©è­æ§çç§å­¸é åä¸­æé æéå¤§ææ°ï¼æå¯è½å°è´é¯èª¤æèª¤å°æ§ççµè«ãçºäºåæéäºææ°ï¼æåæåº KG-CoIï¼ç¥è­åºç¤è§å¿µéï¼ï¼éæ¯ä¸ååµæ°çç³»çµ±ï¼å®ééæ´åç¥è­åè­ (KG) ä¸­çå¤é¨çµæ§åç¥è­ä¾å¢å¼· LLM åè¨­ç¢çãKG-CoI å¼å° LLM é²è¡çµæ§åæ¨çç¨åºï¼å°å¶è¼¸åºæ´çæè§å¿µé (CoI)ï¼ä¸¦åå«ä¸åç± KG æ¯æ´çæ¨¡çµä¾åµæ¸¬å¹»è¦ºãééæåæ°å»ºç«çåè¨­ç¢çè³æéé²è¡çå¯¦é©ï¼æåè­æ KG-CoI ä¸åæ¹åäº LLM ç¢ççåè¨­çæºç¢ºæ§ï¼ä¹æ¸å°äºå¶æ¨çéä¸­çå¹»è¦ºï¼çªé¡¯äºå¶å¨æ¨é²ç¾å¯¦ä¸çç§å­¸ç ç©¶ä¸­çæè½ã

##### **Can Language Models Enable In-Context Database?**
2411.01807v1 by Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun

Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) éæ¼¸æçºåéå°éç¯ä¾å°±è½èçåç¨®ä»»åçå­¸ç¿èï¼åæ¬çè§£ãè¦åãæ¨çãåç­ãç®è¡è¨ç®ç­ãéäºè½åçæ ¸å¿æ¯ LLM å¨è¡¨ç¤ºåçè§£çµæ§åæåçµæ§åè³æï¼ä¾å¦è¡¨æ ¼ååå½¢ï¼æ¹é¢çè½åãè¨±å¤ç ç©¶å·²è­æï¼LLM ä¸åå¯ä»¥æ¨è«è¡¨æ ¼è³ææåå½¢ï¼éæä¾äºä¸åæåæ¯çç ç©¶æ¹åï¼å°éäºè³æè¦çºèªå¢è³æãèªå¢è³æåº«çè¼éç´åäººé¡å¯è®åç¹æ§æå¯è½ä½¿å¶æçºå¸å RAGï¼æª¢ç´¢æ´åçæï¼è¨­å®ä¸­å³çµ±è³æåº«çæ¿ä»£æ¹æ¡ãç¶èï¼å¹¾ä¹ææç®åçå·¥ä½é½å°æ³¨æ¼éæèªå¢è³æï¼éä¸åè¨±åææ´æ°ãå¨æ¬æä¸­ï¼çºäºå¯¦ç¾åæè³æåº«æ´æ°ï¼æåºäºè³æåº«ç delta ç·¨ç¢¼ãæåæ¢è¨äºå¦ä½å°å²å­å¨å³çµ± RDBMS ä¸­çè³æç·¨ç¢¼çºèªå¢æå­ï¼ä¸¦è©ä¼° LLM å¨èªå¢è³æåº«ä¸é²è¡ CRUDï¼å»ºç«ãè®åãæ´æ°ååªé¤ï¼æä½çè½åãæåºäºåçº InConDB çåºæºï¼ä¸¦é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é¡¯ç¤ºä¸åèªè¨æ¨¡åå¨ééæ¹è®è³æåº«ç·¨ç¢¼æ¹æ³ãæç¤ºæ¹æ³ãæä½é¡ååè¼¸å¥è³æåä½ä¾åç¨èªå¢è³æåº«æ¹é¢çæè½ï¼æ­ç¤ºäºè½ååéå¶ã

##### **Graph-based Confidence Calibration for Large Language Models**
2411.02454v1 by Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu

One important approach to improving the reliability of large language models
(LLMs) is to provide accurate confidence estimations regarding the correctness
of their answers. However, developing a well-calibrated confidence estimation
model is challenging, as mistakes made by LLMs can be difficult to detect. We
propose a novel method combining the LLM's self-consistency with labeled data
and training an auxiliary model to estimate the correctness of its responses to
questions. This auxiliary model predicts the correctness of responses based
solely on their consistent information. To set up the learning problem, we use
a weighted graph to represent the consistency among the LLM's multiple
responses to a question. Correctness labels are assigned to these responses
based on their similarity to the correct answer. We then train a graph neural
network to estimate the probability of correct responses. Experiments
demonstrate that the proposed approach substantially outperforms several of the
most recent methods in confidence calibration across multiple widely adopted
benchmark datasets. Furthermore, the proposed approach significantly improves
the generalization capability of confidence calibration on out-of-domain (OOD)
data.

æè¦ï¼ä¸ç¨®æ¹åå¤§åèªè¨æ¨¡å (LLM) å¯é æ§çéè¦æ¹æ³æ¯æä¾æéå¶ç­æ¡æ­£ç¢ºæ§çæºç¢ºä¿¡å¿ä¼°è¨ãç¶èï¼éç¼ä¸åæ ¡æºè¯å¥½çä¿¡å¿ä¼°è¨æ¨¡åå·æææ°æ§ï¼å çº LLM æç¯çé¯èª¤å¯è½é£ä»¥åµæ¸¬ãæåæåºä¸åæ°æ¹æ³ï¼çµå LLM çèªæä¸è´æ§èæ¨ç±¤è³æï¼ä¸¦è¨ç·´ä¸åè¼å©æ¨¡åä¾ä¼°è¨å¶å°åé¡çåææ­£ç¢ºæ§ãéåè¼å©æ¨¡ååæ ¹æå¶ä¸è´æ§è³è¨ä¾é æ¸¬åæçæ­£ç¢ºæ§ãçºäºè¨­å®å­¸ç¿åé¡ï¼æåä½¿ç¨ä¸åå æ¬åå½¢ä¾è¡¨ç¤º LLM å°ä¸ååé¡çå¤æ¬¡åæä¹éçä¸è´æ§ãæ­£ç¢ºæ§æ¨ç±¤ææ ¹æéäºåæèæ­£ç¢ºç­æ¡çç¸ä¼¼æ§åéçµ¦éäºåæãç¶å¾ï¼æåè¨ç·´ä¸ååå½¢ç¥ç¶ç¶²è·¯ä¾ä¼°è¨æ­£ç¢ºåæçæ©çãå¯¦é©è­æï¼ææåºçæ¹æ³å¨å¤åå»£æ³æ¡ç¨çåºæºè³æéä¸ï¼å¨ä¿¡å¿æ ¡æºæ¹é¢æé¡¯åªæ¼å¤ç¨®ææ°æ¹æ³ãæ­¤å¤ï¼ææåºçæ¹æ³é¡¯èæ¹åäºå¨é åå¤ (OOD) è³æä¸ä¿¡å¿æ ¡æºçæ³åè½åã

##### **Ontology Population using LLMs**
2411.01612v1 by Sanaz Saki Norouzi, Adrita Barua, Antrea Christou, Nikita Gautam, Andrew Eells, Pascal Hitzler, Cogan Shimizu

Knowledge graphs (KGs) are increasingly utilized for data integration,
representation, and visualization. While KG population is critical, it is often
costly, especially when data must be extracted from unstructured text in
natural language, which presents challenges, such as ambiguity and complex
interpretations. Large Language Models (LLMs) offer promising capabilities for
such tasks, excelling in natural language understanding and content generation.
However, their tendency to ``hallucinate'' can produce inaccurate outputs.
Despite these limitations, LLMs offer rapid and scalable processing of natural
language data, and with prompt engineering and fine-tuning, they can
approximate human-level performance in extracting and structuring data for KGs.
This study investigates LLM effectiveness for the KG population, focusing on
the Enslaved.org Hub Ontology. In this paper, we report that compared to the
ground truth, LLM's can extract ~90% of triples, when provided a modular
ontology as guidance in the prompts.

æè¦ï¼ç¥è­åè­ (KG) æä¾æå¤ç¨æ¼è³ææ´åãè¡¨ç¤ºåè¦è¦ºåãåç®¡ KG å¡«åè³ééè¦ï¼ä½å®éå¸¸å¾æè²´ï¼ç¹å¥æ¯å¨å¿é å¾èªç¶èªè¨ä¸­éçµæ§åæå­ä¸­æåè³ææï¼éæå¸¶ä¾ææ°ï¼ä¾å¦æ­§ç¾©åè¤éçè©®éãå¤§åèªè¨æ¨¡å (LLM) çºæ­¤é¡ä»»åæä¾äºæåæ¯çè½åï¼æé·èªç¶èªè¨çè§£åå§å®¹çæãç¶èï¼å®åãç¢çå¹»è¦ºãçå¾åå¯è½æç¢çä¸æºç¢ºçè¼¸åºãåç®¡æéäºéå¶ï¼LLM æä¾äºèªç¶èªè¨è³æçå¿«éä¸å¯æ´åèçï¼ä¸¦ä¸ééæç¤ºå·¥ç¨åå¾®èª¿ï¼å®åå¯ä»¥è¿ä¼¼äººé¡å±¤ç´çæè½ï¼ä»¥æååå»ºæ§ KG çè³æãæ¬ç ç©¶èª¿æ¥ LLM å° KG å¡«åçæææ§ï¼éé»éæ³¨ Enslaved.org Hub Ontologyãå¨æ¬æä¸­ï¼æåå ±åèçå¯¦ææ³ç¸æ¯ï¼ç¶å¨æç¤ºä¸­æä¾æ¨¡çµåæ¬ä½ä½çºæå°æï¼LLM å¯ä»¥æåç´ 90% çä¸åçµã

##### **Pre-trained Molecular Language Models with Random Functional Group Masking**
2411.01401v1 by Tianhao Peng, Yuchen Li, Xuhong Li, Jiang Bian, Zeke Xie, Ning Sui, Shahid Mumtaz, Yanwu Xu, Linghe Kong, Haoyi Xiong

Recent advancements in computational chemistry have leveraged the power of
trans-former-based language models, such as MoLFormer, pre-trained using a vast
amount of simplified molecular-input line-entry system (SMILES) sequences, to
understand and predict molecular properties and activities, a critical step in
fields like drug discovery and materials science. To further improve
performance, researchers have introduced graph neural networks with graph-based
molecular representations, such as GEM, incorporating the topology, geometry,
2D or even 3D structures of molecules into pre-training. While most of
molecular graphs in existing studies were automatically converted from SMILES
sequences, it is to assume that transformer-based language models might be able
to implicitly learn structure-aware representations from SMILES sequences. In
this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular
\underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES
subsequences corresponding to specific molecular \underline{\em F}unctional
\underline{\em G}roups to incorporate structure information of atoms during the
pre-training phase. This technique aims to compel the model to better infer
molecular structures and properties, thus enhancing its predictive
capabilities. Extensive experimental evaluations across 11 benchmark
classification and regression tasks in the chemical domain demonstrate the
robustness and superiority of \ours{}. Our findings reveal that \ours{}
outperforms existing pre-training models, either based on SMILES or graphs, in
9 out of the 11 downstream tasks, ranking as a close second in the remaining
ones.

æè¦ï¼<paragraph>è¨ç®åå­¸çè¿æé²å±å·²å©ç¨è½æå¨èªè¨æ¨¡åçåéï¼ä¾å¦ MoLFormerï¼ä½¿ç¨å¤§éç°¡ååå­è¼¸å¥ç·æ¢è¼¸å¥ç³»çµ± (SMILES) åºåé²è¡é è¨ç·´ï¼ä»¥äºè§£åé æ¸¬åå­ç¹æ§åæ´»æ§ï¼éæ¯è¥ç©ç¼ç¾åææç§å­¸ç­é åçéè¦æ­¥é©ãçºäºé²ä¸æ­¥æåæè½ï¼ç ç©¶äººå¡å¼å¥äºå·æåå½¢çºåºç¤çåå­è¡¨ç¤ºçåå½¢ç¥ç¶ç¶²è·¯ï¼ä¾å¦ GEMï¼å°åå­çææ¨¸ãå¹¾ä½ã2D çè³ 3D çµæ§ç´å¥é è¨ç·´ä¸­ãéç¶ç¾æç ç©¶ä¸­çå¤§å¤æ¸åå­åå½¢é½æ¯å¾ SMILES åºåèªåè½æèä¾çï¼ä½å¯ä»¥åè¨­åºæ¼è½æå¨çèªè¨æ¨¡åå¯è½è½å¤ å¾ SMILES åºåä¸­é±å¼å­¸ç¿çµæ§æç¥è¡¨ç¤ºãå¨æ¬æä¸­ï¼æåæåº \ours{} -- ä¸ååºæ¼ SMILES ç\underline{\em M}olecular\underline{\em L}anguage \underline{\em M}odelï¼å®é¨æ©é®è½å°ææ¼ç¹å®åå­\underline{\em F}unctional\underline{\em G}roups ç SMILES å­åºåï¼ä»¥å¨é è¨ç·´éæ®µç´å¥åå­ççµæ§è³è¨ãæ­¤æè¡æ¨å¨å¼·å¶æ¨¡åæ´å¥½å°æ¨æ·åå­çµæ§åç¹æ§ï¼å¾èå¢å¼·å¶é æ¸¬è½åãå¨åå­¸é åç 11 ååºæºåé¡ååæ­¸ä»»åä¸­é²è¡çå»£æ³å¯¦é©è©ä¼°è­æäº \ours{} çç©©å¥æ§ååªè¶æ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼\ours{} å¨ 11 åä¸æ¸¸ä»»åä¸­ç 9 åä»»åä¸­åªæ¼ç¾æçé è¨ç·´æ¨¡åï¼åºæ¼ SMILES æåå½¢ï¼ï¼å¨å©ä¸çä»»åä¸­æåç¬¬äºã</paragraph>

##### **Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**
2411.02435v1 by Xinyi Leng, Jason Liang, Jack Mauro, Xu Wang, Andrea L. Bertozzi, James Chapman, Junyuan Lin, Bohan Chen, Chenchen Ye, Temple Daniel, P. Jeffrey Brantingham

Narrative data spans all disciplines and provides a coherent model of the
world to the reader or viewer. Recent advancement in machine learning and Large
Language Models (LLMs) have enable great strides in analyzing natural language.
However, Large language models (LLMs) still struggle with complex narrative
arcs as well as narratives containing conflicting information. Recent work
indicates LLMs augmented with external knowledge bases can improve the accuracy
and interpretability of the resulting models. In this work, we analyze the
effectiveness of applying knowledge graphs (KGs) in understanding true-crime
podcast data from both classical Natural Language Processing (NLP) and LLM
approaches. We directly compare KG-augmented LLMs (KGLLMs) with classical
methods for KG construction, topic modeling, and sentiment analysis.
Additionally, the KGLLM allows us to query the knowledge base in natural
language and test its ability to factually answer questions. We examine the
robustness of the model to adversarial prompting in order to test the model's
ability to deal with conflicting information. Finally, we apply classical
methods to understand more subtle aspects of the text such as the use of
hearsay and sentiment in narrative construction and propose future directions.
Our results indicate that KGLLMs outperform LLMs on a variety of metrics, are
more robust to adversarial prompts, and are more capable of summarizing the
text into topics.

æè¦ï¼æäºè³ææ¶µèææå­¸ç§ï¼ä¸¦çºè®èæè§ç¾æä¾ä¸åé£è²«çä¸çæ¨¡åãæ©å¨å­¸ç¿åå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å¨åæèªç¶èªè¨æ¹é¢åå¾äºé·è¶³çé²æ­¥ãç¶èï¼å¤§åèªè¨æ¨¡å (LLM) ä»ç¶é£ä»¥æä»è¤éçæäºå¼§ç·ä»¥ååå«ç¸äºçç¾è³è¨çæäºãæè¿çç ç©¶è¡¨æï¼ä½¿ç¨å¤é¨ç¥è­åº«å¢å¼·ç LLM å¯ä»¥æé«æç¢çæ¨¡åçæºç¢ºæ§åå¯è§£éæ§ãå¨éé å·¥ä½ä¸­ï¼æååæäºå¨å¾å³çµ±èªç¶èªè¨èç (NLP) å LLM æ¹æ³ä¸­çè§£çå¯¦ç¯ç½ªæ­å®¢è³ææï¼æç¨ç¥è­åè­ (KG) çæææ§ãæåç´æ¥æ¯è¼äº KG å¢å¼·ç LLM (KGLLM) èç¨æ¼ KG å»ºæ§ãä¸»é¡å»ºæ¨¡åæç·åæçå³çµ±æ¹æ³ãæ­¤å¤ï¼KGLLM åè¨±æåä»¥èªç¶èªè¨æ¥è©¢ç¥è­åº«ï¼ä¸¦æ¸¬è©¦å¶äºå¯¦åç­åé¡çè½åãæåæª¢æ¥äºæ¨¡åå°å°ææ§æç¤ºçç©©å¥æ§ï¼ä»¥æ¸¬è©¦æ¨¡åèçç¸äºçç¾è³è¨çè½åãæå¾ï¼æåæç¨å³çµ±æ¹æ³ä¾çè§£ææ¬çæ´ç´°å¾®æ¹é¢ï¼ä¾å¦å¨æäºå»ºæ§ä¸­ä½¿ç¨éè½éèªªåæç·ï¼ä¸¦æåºæªä¾çæ¹åãæåççµæè¡¨æï¼KGLLM å¨åç¨®ææ¨ä¸åªæ¼ LLMï¼å°å°ææç¤ºæ´ç©©å¥ï¼ä¸¦ä¸æ´è½å¤ å°ææ¬ç¸½çµçºä¸»é¡ã

##### **WLPlan: Relational Features for Symbolic Planning**
2411.00577v1 by Dillon Z. Chen

Scalable learning for planning research generally involves juggling between
different programming languages for handling learning and planning modules
effectively. Interpreted languages such as Python are commonly used for
learning routines due to their ease of use and the abundance of highly
maintained learning libraries they exhibit, while compiled languages such as
C++ are used for planning routines due to their optimised resource usage.
Motivated by the need for tools for developing scalable learning planners, we
introduce WLPlan, a C++ package with Python bindings which implements recent
promising work for automatically generating relational features of planning
tasks. Such features can be used for any downstream routine, such as learning
domain control knowledge or probing and understanding planning tasks. More
specifically, WLPlan provides functionality for (1) transforming planning tasks
into graphs, and (2) embedding planning graphs into feature vectors via graph
kernels. The source code and instructions for the installation and usage of
WLPlan are available at tinyurl.com/42kymswc

æè¦ï¼å¯æ´åçå­¸ç¿è¦åç ç©¶éå¸¸éè¦å¨ä¸åçç¨å¼èªè¨ä¹éåæï¼æè½ææå°èçå­¸ç¿åè¦åæ¨¡çµãä¾å¦ Python ç­ç´è­¯èªè¨éå¸¸ç¨æ¼å­¸ç¿å¸¸å¼ï¼å çºå®åææ¼ä½¿ç¨ï¼ä¸æè¨±å¤ç¶­è­·å®åçå­¸ç¿å½å¼åº«ï¼èä¾å¦ C++ ç­ç·¨è­¯èªè¨åç¨æ¼è¦åå¸¸å¼ï¼å çºå®åè½æä½³åè³æºä½¿ç¨ãç±æ¼éè¦éç¼å¯æ´åå­¸ç¿è¦åå¨çå·¥å·ï¼æåå¼é²äº WLPlanï¼éæ¯ä¸åå·æ Python ç¹«çµç C++ å¥ä»¶ï¼å¯¦ä½äºè¿ææåéçèªåç¢çè¦åä»»åéä¿ç¹å¾µçå·¥ä½ãæ­¤é¡ç¹å¾µå¯ç¨æ¼ä»»ä½ä¸æ¸¸å¸¸å¼ï¼ä¾å¦å­¸ç¿é åæ§å¶ç¥è­ææ¢æ¸¬åçè§£è¦åä»»åãæ´å·é«å°èªªï¼WLPlan æä¾äºä»¥ä¸åè½ï¼(1) å°è¦åä»»åè½æçºåå½¢ï¼ä»¥å (2) ééåå½¢æ ¸å°è¦ååå½¢åµå¥ç¹å¾µåéãWLPlan çåå§ç¢¼åå®è£åä½¿ç¨èªªæå¯å¨ tinyurl.com/42kymswc åå¾

##### **GRSQA -- Graph Reasoning-Structured Question Answering Dataset**
2411.00369v2 by Anish Pahilajani, Devasha Trivedi, Jincen Shuai, Khin S. Yone, Samyak Rajesh Jain, Namyong Park, Ryan A. Rossi, Nesreen K. Ahmed, Franck Dernoncourt, Yu Wang

Large Language Models (LLMs) have excelled in multi-hop question-answering
(M-QA) due to their advanced reasoning abilities. However, the impact of the
inherent reasoning structures on LLM M-QA performance remains unclear, largely
due to the absence of QA datasets that provide fine-grained reasoning
structures. To address this gap, we introduce the Graph Reasoning-Structured
Question Answering Dataset (GRS-QA), which includes both semantic contexts and
reasoning structures for QA pairs. Unlike existing M-QA datasets, where
different reasoning structures are entangled together, GRS-QA explicitly
captures intricate reasoning pathways by constructing reasoning graphs, where
nodes represent textual contexts and edges denote logical flows. These
reasoning graphs of different structures enable a fine-grained evaluation of
LLM reasoning capabilities across various reasoning structures. Our empirical
analysis reveals that LLMs perform differently when handling questions with
varying reasoning structures. This finding facilitates the exploration of
textual structures as compared with semantics.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼å¶åé²çæ¨çè½åï¼å¨å¤è·³åç­ (M-QA) æ¹é¢è¡¨ç¾åºè²ãç¶èï¼åºææ¨ççµæ§å° LLM M-QA æè½çå½±é¿ä»ä¸æç¢ºï¼éä¸»è¦æ­¸å æ¼ç¼ºä¹æä¾ç´°ç²åº¦æ¨ççµæ§çåç­è³æéãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºåå½¢æ¨ççµæ§å¼åç­è³æé (GRS-QA)ï¼å¶ä¸­åå«èªç¾©èçµ¡ååç­å°çæ¨ççµæ§ãèç¾æç M-QA è³æéä¸åï¼å¨ç¾æè³æéä¸­ï¼ä¸åçæ¨ççµæ§ç³¾çºå¨ä¸èµ·ï¼GRS-QA ééå»ºæ§æ¨çåå½¢ï¼æç¢ºææè¤éçæ¨çè·¯å¾ï¼å¶ä¸­ç¯é»ä»£è¡¨æå­èçµ¡ï¼èéç·£è¡¨ç¤ºéè¼¯æµãéäºä¸åçµæ§çæ¨çåå½¢è½å¤ å° LLM å¨åç¨®æ¨ççµæ§ä¸­çæ¨çè½åé²è¡ç´°ç²åº¦çè©ä¼°ãæåçå¯¦è­åæé¡¯ç¤ºï¼LLM å¨èçå·æä¸åæ¨ççµæ§çåé¡æï¼è¡¨ç¾ä¸åãéåç¼ç¾ä¿é²äºå°æå­çµæ§èèªç¾©é²è¡æ¯è¼çç ç©¶ã

##### **Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**
2411.02523v1 by Balu Bhasuran, Qiao Jin, Yuzhang Xie, Carl Yang, Karim Hanna, Jennifer Costa, Cindy Shavor, Zhiyong Lu, Zhe He

Differential diagnosis is crucial for medicine as it helps healthcare
providers systematically distinguish between conditions that share similar
symptoms. This study assesses the impact of lab test results on differential
diagnoses (DDx) made by large language models (LLMs). Clinical vignettes from
50 case reports from PubMed Central were created incorporating patient
demographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,
Claude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx
with and without lab data. A comprehensive evaluation involving GPT-4, a
knowledge graph, and clinicians was conducted. GPT-4 performed best, achieving
55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient
accuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and
Mixtral excelling, though exact match rates were low. Lab tests, including
liver function, metabolic/toxicology panels, and serology/immune tests, were
generally interpreted correctly by LLMs for differential diagnosis.

æè¦ï¼éå¥è¨ºæ·å°æ¼é«å­¸è³ééè¦ï¼å çºå®æå©æ¼é«çä¿å¥æä¾èç³»çµ±ååå·æç¸ä¼¼çççç¾çãéé ç ç©¶è©ä¼°äºå¯¦é©å®¤æª¢é©çµæå°å¤§åèªè¨æ¨¡å (LLM) ååºçéå¥è¨ºæ· (DDx) çå½±é¿ãå¾ PubMed Central ç 50 ä»½çä¾å ±åä¸­å»ºç«äºè¨åºç°¡å ±ï¼å¶ä¸­åå«æ£èäººå£çµ±è¨ãççåå¯¦é©å®¤çµæãæ¸¬è©¦äºäºå LLM GPT-4ãGPT-3.5ãLlama-2-70bãClaude-2 å Mixtral-8x7Bï¼ä»¥çæå¸¶åä¸å¸¶å¯¦é©å®¤æ¸æçå 10ãå 5 åå 1 DDxãé²è¡äºä¸é æ¶å GPT-4ãç¥è­åè­åè¨åºé«ççç¶åè©ä¼°ãGPT-4 è¡¨ç¾æä½³ï¼å¨æå¯¦é©å®¤æ¸æçææ³ä¸ï¼å 1 åè¨ºæ·çæºç¢ºçéå° 55%ï¼å 10 åçæºç¢ºçéå° 60%ï¼å¯¬é¬æºç¢ºçé«é 80%ãå¯¦é©å®¤çµæé¡¯èæé«äºæºç¢ºçï¼GPT-4 å Mixtral è¡¨ç¾åºè²ï¼åç®¡å®å¨å¹éçè¼ä½ãLLM éå¸¸å¯ä»¥æ­£ç¢ºè§£éåæ¬èåè½ãä»£è¬/æ¯çå­¸æª¢æ¥åè¡æ¸å­¸/åç«æ¸¬è©¦å¨å§çå¯¦é©å®¤æª¢é©ï¼ä»¥é²è¡éå¥è¨ºæ·ã

##### **Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**
2411.00205v1 by Beyazit Yalcinkaya, Niklas Lauffer, Marcell Vazquez-Chanlatte, Sanjit A. Seshia

Goal-conditioned reinforcement learning is a powerful way to control an AI
agent's behavior at runtime. That said, popular goal representations, e.g.,
target states or natural language, are either limited to Markovian tasks or
rely on ambiguous task semantics. We propose representing temporal goals using
compositions of deterministic finite automata (cDFAs) and use cDFAs to guide RL
agents. cDFAs balance the need for formal temporal semantics with ease of
interpretation: if one can understand a flow chart, one can understand a cDFA.
On the other hand, cDFAs form a countably infinite concept class with Boolean
semantics, and subtle changes to the automaton can result in very different
tasks, making them difficult to condition agent behavior on. To address this,
we observe that all paths through a DFA correspond to a series of reach-avoid
tasks and propose pre-training graph neural network embeddings on "reach-avoid
derived" DFAs. Through empirical evaluation, we demonstrate that the proposed
pre-training method enables zero-shot generalization to various cDFA task
classes and accelerated policy specialization without the myopic suboptimality
of hierarchical methods.

æè¦ï¼ç®æ¨æ¢ä»¶å¼·åå­¸ç¿æ¯ä¸ç¨®å¨å·è¡éæ®µæ§å¶ AI ä»£çè¡çºçå¼·å¤§æ¹æ³ãè©±éå¦æ­¤ï¼ç±éçç®æ¨è¡¨ç¤ºï¼ä¾å¦ç®æ¨çææèªç¶èªè¨ï¼åéæ¼é¦¬å¯å¤«ä»»åæä¾è³´æ¼å«ç³ä¸æ¸çä»»åèªç¾©ãæåå»ºè­°ä½¿ç¨ç¢ºå®æ§æéçæèªåæ© (cDFA) ççµåä¾è¡¨ç¤ºæéç®æ¨ï¼ä¸¦ä½¿ç¨ cDFA ä¾æå° RL ä»£çãcDFA å¹³è¡¡äºå°å½¢å¼æéèªç¾©çéæ±èææ¼è§£éä¹éçéä¿ï¼å¦æä¸åäººè½çè§£æµç¨åï¼é£éº¼ä»å°±è½çè§£ cDFAãå¦ä¸æ¹é¢ï¼cDFA å½¢æäºä¸åå·æå¸æèªç¾©çå¯æ¸ç¡éæ¦å¿µé¡ï¼èå°èªåæ©çç´°å¾®æ´æ¹å¯è½æå°è´éå¸¸ä¸åçä»»åï¼éä½¿å¾å®åé£ä»¥å°ä»£çè¡çºé²è¡æ¢ä»¶åãçºäºè§£æ±ºéååé¡ï¼æåè§å¯å°éé DFA çææè·¯å¾é½å°ææ¼ä¸ç³»åå°éé¿åä»»åï¼ä¸¦æåºå°ãå°éé¿åè¡çãDFA é²è¡é è¨ç·´åç¥ç¶ç¶²è·¯åµå¥ãééç¶é©è©ä¼°ï¼æåè­æäºææåºçé è¨ç·´æ¹æ³è½å¤ å°åç¨® cDFA ä»»åé¡å¥é²è¡é¶æ¬¡å­¸ç¿æ³åï¼ä¸¦å éç­ç¥å°æ¥­åï¼èæ²æåå±¤æ¹æ³çè¿è¦æ¬¡åªæ§ã

##### **Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**
2411.00188v1 by Yu Pan, Jianxin Sun, Hongfeng Yu, Joe Luck, Geng Bai, Nipuna Chamara, Yufeng Ge, Tala Awada

Current agricultural data management and analysis paradigms are to large
extent traditional, in which data collecting, curating, integration, loading,
storing, sharing and analyzing still involve too much human effort and
know-how. The experts, researchers and the farm operators need to understand
the data and the whole process of data management pipeline to make fully use of
the data. The essential problem of the traditional paradigm is the lack of a
layer of orchestrational intelligence which can understand, organize and
coordinate the data processing utilities to maximize data management and
analysis outcome. The emerging reasoning and tool mastering abilities of large
language models (LLM) make it a potentially good fit to this position, which
helps a shift from the traditional user-driven paradigm to AI-driven paradigm.
In this paper, we propose and explore the idea of a LLM based copilot for
autonomous agricultural data management and analysis. Based on our previously
developed platform of Agricultural Data Management and Analytics (ADMA), we
build a proof-of-concept multi-agent system called ADMA Copilot, which can
understand user's intent, makes plans for data processing pipeline and
accomplishes tasks automatically, in which three agents: a LLM based
controller, an input formatter and an output formatter collaborate together.
Different from existing LLM based solutions, by defining a meta-program graph,
our work decouples control flow and data flow to enhance the predictability of
the behaviour of the agents. Experiments demonstrates the intelligence,
autonomy, efficacy, efficiency, extensibility, flexibility and privacy of our
system. Comparison is also made between ours and existing systems to show the
superiority and potential of our system.

æè¦ï¼<paragraph>ç®åçè¾²æ¥­è³æç®¡çèåææ¨¡å¼å¨å¾å¤§ç¨åº¦ä¸ä»æ¯å³çµ±çï¼å¶ä¸­è³ææ¶éãæ´çãæ´åãè¼å¥ãå²å­ãåäº«ååæä»ç¶éè¦å¤ªå¤çäººåèå°æ¥­ç¥è­ãå°å®¶ãç ç©¶äººå¡åè¾²å ´ç¶çèéè¦äºè§£è³æåæ´åè³æç®¡çæµç¨ï¼æè½ååå©ç¨è³æãå³çµ±æ¨¡å¼çåºæ¬åé¡æ¯ç¼ºä¹ä¸å±¤ç·¨ææºè½ï¼ç¡æ³çè§£ãçµç¹ååèª¿è³æèçå·¥å·ï¼ä»¥æå¤§åè³æç®¡çååæææãå¤§åèªè¨æ¨¡å (LLM) æ°èçæ¨çåå·¥å·ææ¡è½åä½¿å¶æ½å¨é©åéåè·ä½ï¼éæå©æ¼å¾å³çµ±çä½¿ç¨èé©åæ¨¡å¼è½è®çº AI é©åæ¨¡å¼ãå¨æ¬æä¸­ï¼æåæåºä¸¦æ¢è¨äºåºæ¼ LLM çå¯é§é§çæ³æ³ï¼ç¨æ¼èªååè¾²æ¥­è³æç®¡çååæãåºæ¼æåååéç¼çè¾²æ¥­è³æç®¡çååæ (ADMA) å¹³å°ï¼æåå»ºç«äºä¸ååçº ADMA Copilot çæ¦å¿µé©è­å¤ä»£çç³»çµ±ï¼å®å¯ä»¥çè§£ä½¿ç¨èçæåãè¦åè³æèçæµç¨ä¸¦èªåå®æä»»åï¼å¶ä¸­ä¸åä»£çï¼åºæ¼ LLM çæ§å¶å¨ãè¼¸å¥æ ¼å¼åç¨å¼åè¼¸åºæ ¼å¼åç¨å¼å±ååä½ãèç¾æçåºæ¼ LLM çè§£æ±ºæ¹æ¡ä¸åï¼ééå®ç¾©åç¨å¼åï¼æåçç ç©¶å°æ§å¶æµç¨åè³ææµç¨è§£è¦ï¼ä»¥å¢å¼·ä»£çè¡çºçå¯é æ¸¬æ§ãå¯¦é©è­æäºæåç³»çµ±çæºæ§ãèªä¸»æ§ãæè½ãæçãå¯æ´åæ§ãéæ´»æ§èé±ç§æ§ãæåä¹èç¾æç³»çµ±é²è¡æ¯è¼ï¼ä»¥é¡¯ç¤ºæåç³»çµ±çåªè¶æ§åæ½åã</paragraph>

##### **Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**
2411.00878v1 by Phil Wee, Riyadh Baghdadi

Recently, there has been an explosion of large language models created
through fine-tuning with data from larger models. These small models able to
produce outputs that appear qualitatively similar to significantly larger
models. However, one of the key limitations that have been observed with these
models is their propensity to hallucinate significantly more often than larger
models. In particular, they have been observed to generate coherent outputs
that involve factually incorrect information and spread misinformation,
toxicity, and stereotypes. There are many potential causes of hallucination, of
which, one hypothesis is that fine-tuning a model on data produced by a larger
model leads to a knowledge mismatch which contributes to hallucination. In
particular, it is hypothesized that there is a mismatch between the knowledge
that is fed to the model to fine-tune it and the knowledge that is already
present in the graph. Fine-tuning the model on data that has such mismatch
could contribute to an increased propensity to hallucinate. We show that on an
unseen test set, a smaller model fine-tuned on data generated from a larger
model produced more wrong answers when compared to models fine-tuned on data
created by the small model, which confirms the hypothesis.

æè¦ï¼æè¿ï¼éè¿ä½¿ç¨æ´å¤§æ¨¡åçæ°æ®è¿è¡å¾®è°ï¼åå»ºäºå¤§éè¯­è¨æ¨¡åçç¸ãè¿äºå°æ¨¡åè½å¤äº§çä¸ææ¾æ´å¤§çæ¨¡åå¨è´¨éä¸ç±»ä¼¼çè¾åºãç¶èï¼å¨è¿äºæ¨¡åä¸­è§å¯å°çä¸ä¸ªå³é®éå¶æ¯ï¼å®ä»¬æ¯æ´å¤§çæ¨¡åæ´å®¹æåºç°å¹»è§ãç¹å«æ¯ï¼å·²ç»è§å¯å°å®ä»¬ä¼çææ¶åäºå®ä¸æ­£ç¡®çä¿¡æ¯å¹¶ä¼ æ­éè¯¯ä¿¡æ¯ãæ¯æ§åå»æ¿å°è±¡çè¿è´¯è¾åºãå¹»è§æå¾å¤æ½å¨åå ï¼å¶ä¸­ä¸ä¸ªåè®¾æ¯ï¼å¨æ´å¤§æ¨¡åçæçæ°æ®ä¸å¾®è°æ¨¡åä¼å¯¼è´ç¥è¯ä¸å¹éï¼ä»èå¯¼è´å¹»è§ãç¹å«æ¯ï¼åè®¾æ¨¡åå¾®è°æé¦éçç¥è¯ä¸å¾ä¸­å·²æçç¥è¯ä¹é´å­å¨ä¸å¹éãå¨å·æè¿ç§ä¸å¹éçæ°æ®ä¸å¾®è°æ¨¡åå¯è½ä¼å¯¼è´å¹»è§å¾åå¢å ãæä»¬è¡¨æï¼å¨ä¸ä¸ªçä¸è§çæµè¯éä¸­ï¼ä¸ä¸ªå¨ä»ä¸ä¸ªæ´å¤§çæ¨¡åçæçæ°æ®ä¸å¾®è°çå°æ¨¡åï¼ä¸å¨å°æ¨¡ååå»ºçæ°æ®ä¸å¾®è°çæ¨¡åç¸æ¯ï¼äº§çäºæ´å¤éè¯¯çç­æ¡ï¼è¿è¯å®äºè¿ä¸åè®¾ã

##### **Failure Modes of LLMs for Causal Reasoning on Narratives**
2410.23884v1 by Khurram Yamin, Shantanu Gupta, Gaurav R. Ghosal, Zachary C. Lipton, Bryan Wilder

In this work, we investigate the causal reasoning abilities of large language
models (LLMs) through the representative problem of inferring causal
relationships from narratives. We find that even state-of-the-art language
models rely on unreliable shortcuts, both in terms of the narrative
presentation and their parametric knowledge. For example, LLMs tend to
determine causal relationships based on the topological ordering of events
(i.e., earlier events cause later ones), resulting in lower performance
whenever events are not narrated in their exact causal order. Similarly, we
demonstrate that LLMs struggle with long-term causal reasoning and often fail
when the narratives are long and contain many events. Additionally, we show
LLMs appear to rely heavily on their parametric knowledge at the expense of
reasoning over the provided narrative. This degrades their abilities whenever
the narrative opposes parametric knowledge. We extensively validate these
failure modes through carefully controlled synthetic experiments, as well as
evaluations on real-world narratives. Finally, we observe that explicitly
generating a causal graph generally improves performance while naive
chain-of-thought is ineffective. Collectively, our results distill precise
failure modes of current state-of-the-art models and can pave the way for
future techniques to enhance causal reasoning in LLMs.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåééæ¨è«æè¿°ä¸­çå æéä¿éåä»£è¡¨æ§åé¡ï¼ä¾æ¢è¨å¤§åèªè¨æ¨¡å (LLM) çå ææ¨çè½åãæåç¼ç¾ï¼å³ä½¿æ¯æåé²çèªè¨æ¨¡åï¼ä¹æä¾è³´æ¼ä¸å¯é çæ·å¾ï¼ç¡è«æ¯å¨æè¿°åç¾æå¶åæ¸ç¥è­æ¹é¢ãä¾å¦ï¼LLM å¾åæ¼æ ¹æäºä»¶çææ²é åºï¼å³ï¼è¼æ©çäºä»¶å°è´è¼æçäºä»¶ï¼ä¾ç¢ºå®å æéä¿ï¼ç¶äºä»¶æªæå¶ç¢ºåçå æé åºæè¿°æï¼å°±æå°è´è¼ä½çæè½ãåæ¨£å°ï¼æåè­æ LLM é£ä»¥é²è¡é·æå ææ¨çï¼ä¸¦ä¸ç¶æè¿°å¾é·ä¸åå«è¨±å¤äºä»¶æï¼å®åéå¸¸æå¤±æãæ­¤å¤ï¼æåè¡¨æ LLM ä¼¼ä¹éåº¦ä¾è³´å¶åæ¸ç¥è­ï¼èç§ç²äºå°ææä¾æè¿°çæ¨çãæ¯ç¶æè¿°èåæ¸ç¥è­ç¸è¡çªæï¼éå°±æéä½å®åçè½åãæåééä»ç´°æ§å¶çåæå¯¦é©ä»¥åå°çå¯¦ä¸çæè¿°çè©ä¼°ï¼å»£æ³é©è­äºéäºå¤±ææ¨¡å¼ãæå¾ï¼æåè§å¯å°ï¼æç¢ºç¢çå æåéå¸¸ææ¹åæè½ï¼èå¤©ççæèéåç¡æãç¸½çä¾èªªï¼æåççµæç²¾ç¢ºå°æçäºç¶åæåé²æ¨¡åçå¤±ææ¨¡å¼ï¼ä¸¦å¯ä»¥çºæªä¾å¢å¼· LLM ä¸­å ææ¨ççæè¡éªè·¯ã

##### **Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**
2410.23875v1 by Liyi Chen, Panrong Tong, Zhongming Jin, Ying Sun, Jieping Ye, Hui Xiong

Large Language Models (LLMs) have shown remarkable reasoning capabilities on
complex tasks, but they still suffer from out-of-date knowledge,
hallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)
can provide explicit and editable knowledge for LLMs to alleviate these issues.
Existing paradigm of KG-augmented LLM manually predefines the breadth of
exploration space and requires flawless navigation in KGs. However, this
paradigm cannot adaptively explore reasoning paths in KGs based on the question
semantics and self-correct erroneous reasoning paths, resulting in a bottleneck
in efficiency and effect. To address these limitations, we propose a novel
self-correcting adaptive planning paradigm for KG-augmented LLM named
Plan-on-Graph (PoG), which first decomposes the question into several
sub-objectives and then repeats the process of adaptively exploring reasoning
paths, updating memory, and reflecting on the need to self-correct erroneous
reasoning paths until arriving at the answer. Specifically, three important
mechanisms of Guidance, Memory, and Reflection are designed to work together,
to guarantee the adaptive breadth of self-correcting planning for graph
reasoning. Finally, extensive experiments on three real-world datasets
demonstrate the effectiveness and efficiency of PoG.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨è¤éä»»åä¸­å±ç¾åºéå¡çæ¨çè½åï¼ä½ä»å­å¨ç¥è­éæãå¹»è¦ºåæ±ºç­ä¸éæçåé¡ãç¸åå°ï¼ç¥è­åè­ (KG) å¯ä»¥æä¾æç¢ºä¸å¯ç·¨è¼¯çç¥è­ï¼ä¾ LLM ç·©è§£éäºåé¡ãç¾æç KG å¢å¼· LLM å¸ç¯æåé åå®ç¾©æ¢ç´¢ç©ºéçå»£åº¦ï¼ä¸¦éè¦å¨ KG ä¸­å®ç¾å°èªãç¶èï¼æ­¤å¸ç¯ç¡æ³æ ¹æåé¡èªæèªé©æå°æ¢ç´¢ KG ä¸­çæ¨çè·¯å¾ï¼ä¸¦èªè¡ç³¾æ­£é¯èª¤çæ¨çè·¯å¾ï¼å°è´æçåææçç¶é ¸ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ååçºåå½¢è¨ç« (PoG) ç KG å¢å¼· LLM çæ°ç©èªä¿®æ­£èªé©æè¦åå¸ç¯ï¼å®é¦åå°åé¡åè§£æå¹¾åå­ç®æ¨ï¼ç¶å¾éè¤èªé©ææ¢ç´¢æ¨çè·¯å¾ãæ´æ°è¨æ¶é«ååæéè¦èªè¡ç³¾æ­£é¯èª¤æ¨çè·¯å¾çéç¨ï¼ç´å°å¾åºç­æ¡ãå·é«ä¾èªªï¼æå°ãè¨æ¶ååæéä¸åéè¦æ©å¶è¢«è¨­è¨çºååéä½ï¼ä»¥ä¿è­èªä¿®æ­£è¦åå¨åå½¢æ¨çä¸­çèªé©æå»£åº¦ãæå¾ï¼å¨ä¸åçå¯¦ä¸çè³æéä¸çå»£æ³å¯¦é©è­æäº PoG çæææ§åæçã

##### **LLaMo: Large Language Model-based Molecular Graph Assistant**
2411.00871v1 by Jinyoung Park, Minseong Bae, Dohwan Ko, Hyunwoo J. Kim

Large Language Models (LLMs) have demonstrated remarkable generalization and
instruction-following capabilities with instruction tuning. The advancements in
LLMs and instruction tuning have led to the development of Large
Vision-Language Models (LVLMs). However, the competency of the LLMs and
instruction tuning have been less explored in the molecular domain. Thus, we
propose LLaMo: Large Language Model-based Molecular graph assistant, which is
an end-to-end trained large molecular graph-language model. To bridge the
discrepancy between the language and graph modalities, we present the
multi-level graph projector that transforms graph representations into graph
tokens by abstracting the output representations of each GNN layer and motif
representations with the cross-attention mechanism. We also introduce
machine-generated molecular graph instruction data to instruction-tune the
large molecular graph-language model for general-purpose molecule and language
understanding. Our extensive experiments demonstrate that LLaMo shows the best
performance on diverse tasks, such as molecular description generation,
property prediction, and IUPAC name prediction. The code of LLaMo is available
at https://github.com/mlvlab/LLaMo.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) å·²å±ç¤ºåºåè¶çæ¦æ¬åæä»¤éµå¾ªè½åï¼å¹¶è¿è¡æä»¤è°æ´ãLLM åæä»¤è°æ´çè¿æ­¥å¯¼è´äºå¤§åè§è§è¯­è¨æ¨¡å (LVLMs) çåå±ãç¶èï¼LLM åæä»¤è°æ´çè½åå¨åå­é¢åçç ç©¶è¾å°ãå æ­¤ï¼æä»¬æåºäº LLaMoï¼åºäºå¤§è¯­è¨æ¨¡åçåå­å¾å©æï¼è¿æ¯ä¸ä¸ªç«¯å°ç«¯è®­ç»çå¤§åå­å¾è¯­è¨æ¨¡åãä¸ºäºå¼¥åè¯­è¨åå¾æ¨¡å¼ä¹é´çå·®å¼ï¼æä»¬æåºäºå¤çº§å¾æå½±ä»ªï¼å®éè¿æ½è±¡æ¯ä¸ª GNN å±çè¾åºè¡¨ç¤ºååºåºè¡¨ç¤ºï¼ä½¿ç¨äº¤åæ³¨æåæºå¶ï¼å°å¾è¡¨ç¤ºè½¬æ¢ä¸ºå¾æ è®°ãæä»¬è¿å¼å¥äºæºå¨çæçåå­å¾æä»¤æ°æ®ï¼ä»¥å¯¹å¤§ååå­å¾è¯­è¨æ¨¡åè¿è¡æä»¤è°æ´ï¼ä»¥ç¨äºéç¨åå­åè¯­è¨çè§£ãæä»¬å¹¿æ³çå®éªè¡¨æï¼LLaMo å¨åå­æè¿°çæãå±æ§é¢æµå IUPAC åç§°é¢æµç­ä¸åä»»å¡ä¸è¡¨ç°åºæä½³æ§è½ãLLaMo çä»£ç å¯å¨ https://github.com/mlvlab/LLaMo è·å¾ã

##### **End-to-End Ontology Learning with Large Language Models**
2410.23584v1 by Andy Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik

Ontologies are useful for automatic machine processing of domain knowledge as
they represent it in a structured format. Yet, constructing ontologies requires
substantial manual effort. To automate part of this process, large language
models (LLMs) have been applied to solve various subtasks of ontology learning.
However, this partial ontology learning does not capture the interactions
between subtasks. We address this gap by introducing OLLM, a general and
scalable method for building the taxonomic backbone of an ontology from
scratch. Rather than focusing on subtasks, like individual relations between
entities, we model entire subcomponents of the target ontology by finetuning an
LLM with a custom regulariser that reduces overfitting on high-frequency
concepts. We introduce a novel suite of metrics for evaluating the quality of
the generated ontology by measuring its semantic and structural similarity to
the ground truth. In contrast to standard metrics, our metrics use deep
learning techniques to define more robust distance measures between graphs.
Both our quantitative and qualitative results on Wikipedia show that OLLM
outperforms subtask composition methods, producing more semantically accurate
ontologies while maintaining structural integrity. We further demonstrate that
our model can be effectively adapted to new domains, like arXiv, needing only a
small number of training examples. Our source code and datasets are available
at https://github.com/andylolu2/ollm.

æè¦ï¼æ¬ä½å¯¹äºé¢åç¥è¯çèªå¨æºå¨å¤çå¾æç¨ï¼å ä¸ºå®ä»¬ä»¥ç»æåæ ¼å¼è¡¨ç¤ºç¥è¯ãç¶èï¼æå»ºæ¬ä½éè¦å¤§éçæå¨å·¥ä½ãä¸ºäºèªå¨åè¿ä¸ªè¿ç¨çä¸é¨åï¼å¤§åè¯­è¨æ¨¡åï¼LLMï¼å·²è¢«åºç¨äºè§£å³æ¬ä½å­¦ä¹ çåç§å­ä»»å¡ãç¶èï¼è¿ç§é¨åæ¬ä½å­¦ä¹ å¹¶æ²¡æææå°å­ä»»å¡ä¹é´çäº¤äºãæä»¬éè¿å¼å¥ OLLM æ¥è§£å³è¿ä¸å·®è·ï¼è¿æ¯ä¸ç§ä»å¤´å¼å§æå»ºæ¬ä½åç±»éª¨æ¶çéç¨ä¸å¯æ©å±çæ¹æ³ãæä»¬æ²¡æä¸æ³¨äºå­ä»»å¡ï¼ä¾å¦å®ä½ä¹é´çä¸ªå«å³ç³»ï¼èæ¯éè¿ä½¿ç¨èªå®ä¹æ­£ååå¨å¾®è° LLM æ¥å¯¹ç®æ æ¬ä½çæ´ä¸ªå­ç»ä»¶è¿è¡å»ºæ¨¡ï¼è¯¥æ­£ååå¨åå°äºå¯¹é«é¢æ¦å¿µçè¿åº¦æåãæä»¬å¼å¥äºä¸å¥æ°çææ æ¥è¯ä¼°çææ¬ä½çè´¨éï¼æ¹æ³æ¯æµéå®ä¸å°é¢çå®å¼çè¯­ä¹åç»æç¸ä¼¼æ§ãä¸æ åææ ç¸åï¼æä»¬çææ ä½¿ç¨æ·±åº¦å­¦ä¹ ææ¯æ¥å®ä¹å¾ä¹é´çæ´ç¨³å¥çè·ç¦»åº¦éãæä»¬å¨ç»´åºç¾ç§ä¸çå®éåå®æ§ç»æè¡¨æï¼OLLM ä¼äºå­ä»»å¡ç»åæ¹æ³ï¼å¨ä¿æç»æå®æ´æ§çåæ¶çæè¯­ä¹ä¸æ´åç¡®çæ¬ä½ãæä»¬è¿ä¸æ­¥è¯æï¼æä»¬çæ¨¡åå¯ä»¥ææå°éåºæ°çé¢åï¼å¦ arXivï¼åªéè¦å°éçè®­ç»æ ·æ¬ãæä»¬çæºä»£ç åæ°æ®éå¯å¨ https://github.com/andylolu2/ollm è·å¾ã

##### **Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**
2410.23452v1 by Vicky Dong, Hao Yu, Yao Chen

This study introduces a novel approach to sentence-level relation extraction
(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models
(LLMs) to generate contextually enriched support documents. By harnessing the
power of LLMs to generate auxiliary information, our approach crafts an
intricate graph representation of textual data. This graph is subsequently
processed through a Graph Neural Network (GNN) to refine and enrich the
embeddings associated with each entity ensuring a more nuanced and
interconnected understanding of the data. This methodology addresses the
limitations of traditional sentence-level RE models by incorporating broader
contexts and leveraging inter-entity interactions, thereby improving the
model's ability to capture complex relationships across sentences. Our
experiments, conducted on the CrossRE dataset, demonstrate the effectiveness of
our approach, with notable improvements in performance across various domains.
The results underscore the potential of combining GNNs with LLM-generated
context to advance the field of relation extraction.

æè¦ï¼æ¬ç ç©¶æåºäºä¸åå¥å­å±¤ç´éä¿èå (RE) çæ°æ¹æ³ï¼è©²æ¹æ³æ´åäºåå½¢ç¥ç¶ç¶²è·¯ (GNN) åå¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥ç¢çèçµ¡è±å¯çæ¯æ´æä»¶ãééå©ç¨ LLM çåè½ä¾ç¢çè¼å©è³è¨ï¼æåçåæ³å»ºç«äºä¸åææ¬è³æçè¤éåå½¢è¡¨ç¤ºãæ­¤åå½¢é¨å¾ééåå½¢ç¥ç¶ç¶²è·¯ (GNN) é²è¡èçï¼ä»¥æ¹ååè±å¯èæ¯åå¯¦é«ç¸éçåµå¥ï¼ç¢ºä¿å°è³æææ´ç´°ç·»ä¸ç¸äºé£çµççè§£ãæ­¤æ¹æ³ééç´å¥æ´å»£æ³çèçµ¡ä¸¦å©ç¨å¯¦é«éäºåï¼ä¾è§£æ±ºå³çµ±å¥å­å±¤ç´ RE æ¨¡åçéå¶ï¼é²èæåæ¨¡åææè·¨å¥å­çè¤ééä¿çè½åãæåå¨ CrossRE è³æéä¸å·è¡çå¯¦é©è­æäºæåæ¹æ³çæææ§ï¼å¨åç¨®é åçæè½é½æé¡¯èçæåãéäºçµæå¼·èª¿äºå° GNN è LLM ç¢ççèçµ¡ç¸çµåï¼ä»¥æ¨é²éä¿èåé åçæ½åã

##### **FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**
2410.23405v1 by Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M. Wood

Material discovery is a critical area of research with the potential to
revolutionize various fields, including carbon capture, renewable energy, and
electronics. However, the immense scale of the chemical space makes it
challenging to explore all possible materials experimentally. In this paper, we
introduce FlowLLM, a novel generative model that combines large language models
(LLMs) and Riemannian flow matching (RFM) to design novel crystalline
materials. FlowLLM first fine-tunes an LLM to learn an effective base
distribution of meta-stable crystals in a text representation. After converting
to a graph representation, the RFM model takes samples from the LLM and
iteratively refines the coordinates and lattice parameters. Our approach
significantly outperforms state-of-the-art methods, increasing the generation
rate of stable materials by over three times and increasing the rate for
stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a
difficult problem. Additionally, the crystals generated by FlowLLM are much
closer to their relaxed state when compared with another leading model,
significantly reducing post-hoc computational cost.

æè¦ï¼ææç¼ç¾æ¯ä¸åéè¦çç ç©¶é åï¼å·æé©æ°åç¨®é åçæ½åï¼åæ¬ç¢³æéãå¯åçè½æºåé»å­ç¢åãç¶èï¼åå­¸ç©ºéçå·¨å¤§è¦æ¨¡ä½¿å¾å¯¦é©æ¢ç´¢ææå¯è½çææå·æææ°æ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äº FlowLLMï¼éæ¯ä¸ç¨®æ°ç©ççææ¨¡åï¼çµåäºå¤§åèªè¨æ¨¡å (LLM) åé»æ¼æµå¹é (RFM) ä¾è¨­è¨æ°åæ¶é«ææãFlowLLM é¦åå¾®èª¿ LLMï¼ä»¥å­¸ç¿ææ¬è¡¨ç¤ºä¸­äºç©©ææ¶é«çææåºç¤åä½ãå¨è½æçºåå½¢è¡¨ç¤ºå¾ï¼RFM æ¨¡åå¾ LLM ä¸­ç²åæ¨£æ¬ï¼ä¸¦åè¦ç²¾çåæ¨åæ¶æ ¼åæ¸ãæåçåæ³é¡¯èåªæ¼æåé²çæ¹æ³ï¼å°ç©©å®ææççæçæé«äºä¸åä»¥ä¸ï¼ä¸¦å°ç©©å®ãç¨ç¹åæ°ç©æ¶é«ççæçæé«äºç´ 50%ââéå¨ä¸åå°é£çåé¡ä¸æ¯ä¸åå·¨å¤§çæ¹é²ãæ­¤å¤ï¼èå¦ä¸ç¨®é åæ¨¡åç¸æ¯ï¼FlowLLM çæçæ¶é«æ´æ¥è¿å¶é¬å¼çæï¼é¡¯èéä½äºäºå¾è¨ç®ææ¬ã

##### **EMMA: End-to-End Multimodal Model for Autonomous Driving**
2410.23262v2 by Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan

We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.

æè¦ï¼<paragraph>æåä»ç´¹ EMMAï¼ä¸ç¨®ç¨æ¼èªåé§é§çç«¯å°ç«¯å¤æ¨¡ææ¨¡åã
å»ºç«å¨å¤æ¨¡æå¤§åèªè¨æ¨¡ååºç¤ä¸ï¼EMMA ç´æ¥å°åå§
ç¸æ©ææ¸¬å¨è³æå°æå°åç¨®ç¹å®æ¼é§é§çè¼¸åºï¼åæ¬è¦åå¨
è»è·¡ãæç¥ç©ä»¶åéè·¯åå½¢åç´ ãEMMA æå¤§åå©ç¨é è¨ç·´å¤§åèªè¨æ¨¡åä¸­çä¸çç¥è­ï¼æ¹æ³æ¯
å°ææéææ¸¬å¨è¼¸å¥ï¼ä¾å¦å°èªæç¤ºåèªæ
è»è¼çæï¼åè¼¸åºï¼ä¾å¦è»è·¡å 3D ä½ç½®ï¼è¡¨ç¤ºçºèªç¶
èªè¨æå­ãéç¨®æ¹æ³åè¨± EMMA å¨çµ±ä¸çèªè¨ç©ºéä¸­å±åèçåç¨®é§é§
ä»»åï¼ä¸¦ä½¿ç¨ç¹å®æ¼ä»»åçæç¤ºçºæ¯åä»»åç¢çè¼¸åºã
æ ¹æç¶é©ï¼æåè­æäº EMMA çæææ§ï¼å¨ nuScenes ä¸çéåè¦åä¸­éå°äºæåé²çæ§è½ï¼ä»¥å
å¨ Waymo éæ¾éåè³æé (WOMD) ä¸åå¾äºæç«¶ç­åççµæãEMMA ä¹
å¨ Waymo éæ¾è³æé (WOD) ä¸å°ç¸æ©åªåç 3D ç©ä»¶åµæ¸¬ç¢çäºæç«¶ç­åççµæãæåå±ç¤ºäºä½¿ç¨è¦åå¨è»è·¡ã
ç©ä»¶åµæ¸¬åéè·¯åå½¢ä»»åå±åè¨ç·´ EMMA æå¨ææä¸å
é åç¢çæ¹é²ï¼çªé¡¯äº EMMA ä½çºèªåé§é§æç¨ç¨å¼éç¨æ¨¡åçæ½åãç¶èï¼EMMA ä¹è¡¨ç¾åºæäºéå¶ï¼å®åªè½
èçå°éçå½±åå¹ï¼ä¸åå«å LiDAR æé·éç­æºç¢ºç 3D ææ¸¬æ¨¡å¼ï¼ä¸¦ä¸è¨ç®ææ¬æè²´ãæå
å¸ææåççµæè½æ¿åµé²ä¸æ­¥çç ç©¶ï¼ä»¥æ¸è¼éäºåé¡ä¸¦é²ä¸æ­¥ç¼å±èªåé§é§æ¨¡å
æ¶æ§çææ°æè¡ã</paragraph>

##### **ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**
2410.23182v1 by Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu

Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åºæ¼ Transformer çæ¶æ§ä¸»å°äºæ©å¨å­¸ç¿çååé åãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°ç©ä¸å¼·å¤§çæ³¨æåæ©å¶ï¼æ¨å¨å¢å¼·åºæ¼ Transformer çæ¶æ§çéæ§ãè³ééè¦çæ¯ï¼æ­¤æè¡å¯ä»¥ä½çºå³æå³ç¨çå±¤æ´åå°ç¾æç Transformer ä¸­ï¼å¨ç¡éé¡å¤è¨ç·´æå¾®èª¿çææ³ä¸æé«å¶ç©©å¥æ§ãééå¨é¢çå¯¦é©åæ¶èç ç©¶ï¼æåè­æäºæåç ProTransformer å¨åç¨®é æ¸¬ä»»åãæ»ææ©å¶ãä¸»å¹¹æ¶æ§åæ¸æé åä¸­é¡¯èå¢å¼·äº Transformer æ¨¡åçç©©å¥æ§ãå¼å¾æ³¨æçæ¯ï¼å¨ä¸é²ä¸æ­¥å¾®èª¿çææ³ä¸ï¼ProTransformer å¨ç¶å¸ç TextFooler æ»æä¸ï¼åå¥çº BERTãALBERTãDistilBERT å RoBERTa æåäº 19.5%ã28.3%ã16.1% å 11.4% çæ§è½ãæ­¤å¤ï¼ProTransformer å¨åºæ¼æç¤ºçæ»æä¸­å°å¤§åèªè¨æ¨¡å (LLM) é¡¯ç¤ºåºæå¸æçéæ§ï¼åå¥å° T5 å LLaMA çæ§è½æåäº 24.8% å 17.8%ï¼ä¸¦å¨è¶çæ»æä¸­å° Vicuna çæ§è½å¹³åæåäº 10.4%ãé¤äºèªè¨é åä¹å¤ï¼ProTransformer å¨è¦è¦ºååå½¢é åä¹è¡¨ç¾åºåºè²çç©©å¥æ§ã</paragraph>

##### **Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**
2410.22996v1 by Deperias Kerre, Anne Laurent, Kenneth Maussang, Dickson Owuor

A well structured collection of the various Quantum Cascade Laser (QCL)
design and working properties data provides a platform to analyze and
understand the relationships between these properties. By analyzing these
relationships, we can gain insights into how different design features impact
laser performance properties such as the working temperature. Most of these QCL
properties are captured in scientific text. There is therefore need for
efficient methodologies that can be utilized to extract QCL properties from
text and generate a semantically enriched and interlinked platform where the
properties can be analyzed to uncover hidden relations. There is also the need
to maintain provenance and reference information on which these properties are
based. Semantic Web technologies such as Ontologies and Knowledge Graphs have
proven capability in providing interlinked data platforms for knowledge
representation in various domains. In this paper, we propose an approach for
generating a QCL properties Knowledge Graph (KG) from text for semantic
enrichment of the properties. The approach is based on the QCL ontology and a
Retrieval Augmented Generation (RAG) enabled information extraction pipeline
based on GPT 4-Turbo language model. The properties of interest include:
working temperature, laser design type, lasing frequency, laser optical power
and the heterostructure. The experimental results demonstrate the feasibility
and effectiveness of this approach for efficiently extracting QCL properties
from unstructured text and generating a QCL properties Knowledge Graph, which
has potential applications in semantic enrichment and analysis of QCL data.

æè¦ï¼ä¸åçµæ§è¯å¥½çåç¨®éå­å±¤çé·å° (QCL) è¨­è¨åå·¥ä½ç¹æ§æ¸æéåï¼æä¾äºä¸åå¹³å°ä¾åæåçè§£éäºç¹æ§ä¹éçéä¿ãééåæéäºéä¿ï¼æåå¯ä»¥æ·±å¥äºè§£ä¸åçè¨­è¨ç¹å¾µå¦ä½å½±é¿é·å°æè½ç¹æ§ï¼ä¾å¦å·¥ä½æº«åº¦ãéäº QCL ç¹æ§å¤§å¤æ¸é½ææå¨ç§å­¸æå­ä¸­ãå æ­¤ï¼éè¦ææçæ¹æ³ï¼å¯ä»¥ç¨æ¼å¾æå­ä¸­èå QCL ç¹æ§ï¼ä¸¦ç¢çä¸åèªç¾©è±å¯ä¸ç¸äºé£çµçå¹³å°ï¼å¯ä»¥å¨å¶ä¸­åæéäºç¹æ§ä»¥ç¼ç¾é±èçéä¿ãééè¦ç¶­è­·éäºç¹æ§æä¾æçä¾æºååèè³è¨ãèªç¾©ç¶²è·¯æè¡ï¼ä¾å¦æ¬ä½åç¥è­åè­ï¼å·²è­æå®åå¨æä¾åç¨®é åä¸­ç¥è­è¡¨å¾µçç¸äºé£çµè³æå¹³å°æ¹é¢å·æè½åãå¨æ¬æä¸­ï¼æåæåºä¸åå¾æå­ä¸­ç¢ç QCL ç¹æ§ç¥è­åè­ (KG) çæ¹æ³ï¼ä»¥é²è¡ç¹æ§çèªç¾©è±å¯åãæ­¤æ¹æ³åºæ¼ QCL æ¬ä½ååºæ¼ GPT 4-Turbo èªè¨æ¨¡åçæª¢ç´¢æ´å¢çæ (RAG) åç¨è³è¨èåç®¡ç·ãæèè¶£çç¹æ§åæ¬ï¼å·¥ä½æº«åº¦ãé·å°è¨­è¨é¡åãé·å°é »çãé·å°ååçåç°è³ªçµæ§ãå¯¦é©çµæè­æäºæ­¤æ¹æ³å°æ¼å¾éçµæ§åæå­ä¸­ææèå QCL ç¹æ§åç¢ç QCL ç¹æ§ç¥è­åè­çå¯è¡æ§åæææ§ï¼éå¨ QCL æ¸æçèªç¾©è±å¯åååæä¸­å·ææ½å¨æç¨ã

##### **How Well Do Large Language Models Disambiguate Swedish Words?**
2410.22827v1 by Richard Johansson

We evaluate a battery of recent large language models on two benchmarks for
word sense disambiguation in Swedish. At present, all current models are less
accurate than the best supervised disambiguators in cases where a training set
is available, but most models outperform graph-based unsupervised systems.
Different prompting approaches are compared, with a focus on how to express the
set of possible senses in a given context. The best accuracies are achieved
when human-written definitions of the senses are included in the prompts.

æè¦ï¼æåéå°å©åçå¸èªè©å½æç¾©æ¶æ­§åºæºï¼è©ä¼°ä¸ç³»åè¿æçå¤§åèªè¨æ¨¡åãç®åï¼å¨æè¨ç·´éå¯ç¨çææ³ä¸ï¼ææç¾ææ¨¡åçæºç¢ºåº¦é½ä½æ¼æä½³ç£ç£å¼æ¶æ­§å¨ï¼ä½å¤§å¤æ¸æ¨¡åçè¡¨ç¾é½åªæ¼åºæ¼åå½¢çéç£ç£å¼ç³»çµ±ãæ¯è¼äºä¸åçæç¤ºæ¹æ³ï¼éé»å¨æ¼å¦ä½å¨ç¹å®èçµ¡ä¸­è¡¨éå¯è½çæç¾©éåãç¶æç¤ºä¸­åå«äººé¡æ°å¯«çæç¾©å®ç¾©æï¼å¯éå°æä½³æºç¢ºåº¦ã

##### **Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**
2410.22767v1 by Sejin Lee, Dongha Kim, Min Song

Goal-oriented chatbots are essential for automating user tasks, such as
booking flights or making restaurant reservations. A key component of these
systems is Dialogue State Tracking (DST), which interprets user intent and
maintains the dialogue state. However, existing DST methods often rely on fixed
ontologies and manually compiled slot values, limiting their adaptability to
open-domain dialogues. We propose a novel approach that leverages instruction
tuning and advanced prompt strategies to enhance DST performance, without
relying on any predefined ontologies. Our method enables Large Language Model
(LLM) to infer dialogue states through carefully designed prompts and includes
an anti-hallucination mechanism to ensure accurate tracking in diverse
conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder
(VGAE) to model and predict subsequent user intent. Our approach achieved
state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST
models, and performed well in open-domain real-world conversations. This work
presents a significant advancement in creating more adaptive and accurate
goal-oriented chatbots.

æè¦ï¼ä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººå¨èªååä½¿ç¨èä»»åä¸­è³ééè¦ï¼ä¾å¦é è¨èªç­æé²è¡é¤å»³è¨ä½ãéäºç³»çµ±çä¸åééµçµæé¨åæ¯å°è©±çæè¿½è¹¤ (DST)ï¼å®æè§£è­¯ä½¿ç¨èçæåä¸¦ç¶­è­·å°è©±çæãç¶èï¼ç¾æç DST æ¹æ³éå¸¸ä¾è³´æ¼åºå®çæ¬ä½åæåç·¨è­¯çæ§½ä½å¼ï¼ééå¶äºå®åå°éæ¾é åå°è©±çé©ææ§ãæåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼å®å©ç¨æä»¤èª¿æ´ååé²çæç¤ºç­ç¥ä¾å¢å¼· DST æè½ï¼èç¡éä¾è³´ä»»ä½é å®ç¾©çæ¬ä½ãæåçæ¹æ³ä½¿å¤§åèªè¨æ¨¡å (LLM) è½å¤ ééç²¾å¿è¨­è¨çæç¤ºä¾æ¨è«å°è©±çæï¼ä¸¦åå«ä¸ååå¹»è¦ºæ©å¶ï¼ä»¥ç¢ºä¿å¨ä¸åçå°è©±æå¢ä¸­æºç¢ºè¿½è¹¤ãæ­¤å¤ï¼æåæ¡ç¨è®ååèªç·¨ç¢¼å¨ (VGAE) ä¾å»ºæ¨¡åé æ¸¬å¾çºä½¿ç¨èçæåãæåçåæ³ä»¥ 42.57% ç JGA éå°äºç¾ææè¡çé å³°ï¼åªæ¼ç¾æçç¡æ¬ä½ DST æ¨¡åï¼ä¸¦å¨éæ¾é åççå¯¦å°è©±ä¸­è¡¨ç¾è¯å¥½ãéé å·¥ä½å¨å»ºç«æ´å·é©ææ§åæºç¢ºæ§çä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººæ¹é¢åå¾äºéå¤§é²å±ã

##### **The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**
2411.00843v1 by Reza Moravej, Saurabh Bodhe, Zhanguang Zhang, Didier Chetelat, Dimitrios Tsaras, Yingxue Zhang, Hui-Ling Zhen, Jianye Hao, Mingxuan Yuan

Logic synthesis is a crucial phase in the circuit design process, responsible
for transforming hardware description language (HDL) designs into optimized
netlists. However, traditional logic synthesis methods are computationally
intensive, restricting their iterative use in refining chip designs. Recent
advancements in large language models (LLMs), particularly those fine-tuned on
programming languages, present a promising alternative. In this paper, we
introduce VeriDistill, the first end-to-end machine learning model that
directly processes raw Verilog code to predict circuit quality-of-result
metrics. Our model employs a novel knowledge distillation method, transferring
low-level circuit insights via graphs into the predictor based on LLM.
Experiments show VeriDistill outperforms state-of-the-art baselines on
large-scale Verilog datasets and demonstrates robust performance when evaluated
on out-of-distribution datasets.

æè¦ï¼éè¼¯åææ¯é»è·¯è¨­è¨éç¨ä¸­è³ééè¦çä¸åéæ®µï¼è² è²¬å°ç¡¬é«æè¿°èªè¨ (HDL) è¨­è¨è½æçºæä½³åçç¶²è·¯è¡¨ãç¶èï¼å³çµ±çéè¼¯åææ¹æ³å¨éç®ä¸å¾å¯éï¼éå¶äºå®åå¨ç²¾çæ¶çè¨­è¨ä¸­çåè¦ä½¿ç¨ãæè¿å¤§åèªè¨æ¨¡å (LLM) çé²å±ï¼ç¹å¥æ¯é£äºç¶éç¨å¼èªè¨å¾®èª¿çï¼æä¾äºä¸åæå¸æçæ¿ä»£æ¹æ¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äº VeriDistillï¼ç¬¬ä¸åç«¯å°ç«¯çæ©å¨å­¸ç¿æ¨¡åï¼å®ç´æ¥èçåå§ Verilog ç¨å¼ç¢¼ä»¥é æ¸¬é»è·¯åè³ªçµæææ¨ãæåçæ¨¡åæ¡ç¨äºä¸ç¨®æ°ç©çç¥è­æçæ¹æ³ï¼ééåè¡¨å°ä½éé»è·¯è¦è§£å³è¼¸å°åºæ¼ LLM çé æ¸¬å¨ä¸­ãå¯¦é©è¡¨æï¼VeriDistill å¨å¤§è¦æ¨¡ Verilog è³æéä¸åªæ¼æåé²çåºæºï¼ä¸¦ä¸å¨å¨åä½å¤è³æéä¸é²è¡è©ä¼°æè¡¨ç¾åºç©©å¥çæè½ã

##### **Are Large-Language Models Graph Algorithmic Reasoners?**
2410.22597v1 by Alexander K Taylor, Anthony Cuturrufo, Vishal Yathish, Mingyu Derek Ma, Wei Wang

We seek to address a core challenge facing current Large Language Models
(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue
to struggle with reasoning problems on explicit graphs that require multiple
steps. To address this gap, we introduce a novel benchmark designed to evaluate
LLM performance on classical algorithmic reasoning tasks on explicit graphs.
Our benchmark encompasses five fundamental algorithms: Breadth-First Search
(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and
Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum
Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we
assess the capabilities of state-of-the-art LLMs in executing these algorithms
step-by-step and systematically evaluate their performance at each stage. Our
findings highlight the persistent challenges LLMs face in this domain and
underscore the necessity for advanced prompting techniques and algorithmic
instruction to enhance their graph reasoning abilities. This work presents
MAGMA, the first comprehensive benchmark focused on LLMs completing classical
graph algorithms, and provides a critical step toward understanding and
improving their structured problem-solving skills.

æè¦ï¼æåè©¦åè§£æ±ºç¶åå¤§åèªè¨æ¨¡å (LLM) é¢è¨çæ ¸å¿ææ°ãLLM å¨è¨±å¤ä»»åä¸­è¡¨ç¾åºåªç°çæ§è½ï¼ä½ä»é£ä»¥æå°éè¦å¤åæ­¥é©çæç¢ºåè¡¨ä¸­çæ¨çåé¡ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºä¸åæ°çåºæºï¼ç¨æ¼è©ä¼° LLM å¨æç¢ºåè¡¨ä¸çç¶å¸æ¼ç®æ³æ¨çä»»åä¸çæ§è½ãæåçåºæºåå«äºååºæ¬æ¼ç®æ³ï¼å»£åº¦åªåæå° (BFS) åæ·±åº¦åªåæå° (DFS) ä»¥é²è¡é£éæ§ãDijkstra æ¼ç®æ³å Floyd-Warshall æ¼ç®æ³ä»¥æ¾åºææç¯é»çæç­è·¯å¾ï¼ä»¥å Prim æå°çææ¨¹ (MST-Prim) æ¼ç®æ³ãééå»£æ³çå¯¦é©ï¼æåè©ä¼°äºæåé²ç LLM å¨éæ­¥å·è¡éäºæ¼ç®æ³çè½åï¼ä¸¦ç³»çµ±æ§å°è©ä¼°å®åå¨æ¯åéæ®µçæ§è½ãæåçç ç©¶çµæçªåºäº LLM å¨éåé åé¢è¨çæçºææ°ï¼ä¸¦å¼·èª¿äºä½¿ç¨é²éæç¤ºæè¡åæ¼ç®æ³æä»¤ä¾å¢å¼·å¶åå½¢æ¨çè½åçå¿è¦æ§ãéé å·¥ä½æåºäº MAGMAï¼éæ¯ç¬¬ä¸åå°æ³¨æ¼ LLM å®æç¶å¸åå½¢æ¼ç®æ³çç¶ååºæºï¼ä¸¦çºäºè§£åæ¹é²å¶çµæ§ååé¡è§£æ±ºæè½æä¾äºééµçä¸æ­¥ã

##### **Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**
2410.22457v1 by Adrian Garret Gabriel, Alaa Alameer Ahmad, Shankar Kumar Jeyakumar

Advancements in Large Language Models (LLMs) are revolutionizing the
development of autonomous agentic systems by enabling dynamic, context-aware
task decomposition and automated tool selection. These sophisticated systems
possess significant automation potential across various industries, managing
complex tasks, interacting with external systems to enhance knowledge, and
executing actions independently. This paper presents three primary
contributions to advance this field:
  - Advanced Agentic Framework: A system that handles multi-hop queries,
generates and executes task graphs, selects appropriate tools, and adapts to
real-time changes.
  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural
Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic
systems.
  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing
agent behavior across different task complexities.
  Our findings reveal that asynchronous and dynamic task graph decomposition
significantly enhances system responsiveness and scalability, particularly for
complex, multi-step tasks. Detailed analysis shows that structural and
node-level metrics are crucial for sequential tasks, while tool-related metrics
are more important for parallel tasks. Specifically, the Structural Similarity
Index (SSI) is the most significant predictor of performance in sequential
tasks, and the Tool F1 Score is essential for parallel tasks. These insights
highlight the need for balanced evaluation methods that capture both structural
and operational dimensions of agentic systems. Additionally, our evaluation
framework, validated through empirical analysis and statistical testing,
provides valuable insights for improving the adaptability and reliability of
agentic systems in dynamic environments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çé²å±æ­£ééåç¨åæãå·æå¢æç¥è½åçä»»ååè§£åèªååå·¥å·é¸æï¼é©æ°èªä¸»ä»£çç³»çµ±çéç¼ãéäºç²¾å¯çç³»çµ±å¨åç¢æ¥­ä¸­ææé¡¯èçèªååæ½åï¼ç®¡çè¤éçä»»åãèå¤é¨ç³»çµ±äºåä»¥å¢å¼·ç¥è­ï¼ä¸¦ç¨ç«å·è¡åä½ãæ¬ææåºäºä¸åä¸»è¦è²¢ç»ä»¥æ¨åéåé åçé²å±ï¼
  - é²éä»£çæ¶æ§ï¼ä¸ç¨®èçå¤éè·³èºæ¥è©¢ãç¢çä¸¦å·è¡ä»»ååè¡¨ãé¸æé©ç¶çå·¥å·ï¼ä¸¦é©æå³æè®åçç³»çµ±ã
  - æ°ç©çè©ä¼°ææ¨ï¼å°å¥ç¯é» F1 åæ¸ãçµæ§ç¸ä¼¼æ§ææ¨ (SSI) åå·¥å· F1 åæ¸ï¼ä»¥å¨é¢è©ä¼°ä»£çç³»çµ±ã
  - å°æ¥­è³æéï¼éç¼ä¸ååºæ¼ AsyncHow çè³æéï¼ç¨æ¼åæä»£çè¡çºå¨ä¸åä»»åè¤éåº¦ä¹éçå·®ç°ã
  æåçç ç©¶çµæé¡¯ç¤ºï¼éåæ­¥ååæä»»ååè¡¨åè§£è½é¡¯èå¢å¼·ç³»çµ±çåæè½ååå¯æ´åæ§ï¼ç¹å¥æ¯å°æ¼è¤éçå¤æ­¥é©ä»»åãè©³ç´°çåæé¡¯ç¤ºï¼çµæ§åç¯é»å±¤ç´çææ¨å°æ¼é åºä»»åè³ééè¦ï¼èèå·¥å·ç¸éçææ¨å°æ¼ä¸¦è¡ä»»åæ´çºéè¦ãå·é«ä¾èªªï¼çµæ§ç¸ä¼¼æ§ææ¨ (SSI) æ¯é åºä»»åä¸­æè½æé¡¯èçé æ¸¬ææ¨ï¼èå·¥å· F1 åæ¸å°æ¼ä¸¦è¡ä»»åè³ééè¦ãéäºè¦è§£çªé¡¯äºå¹³è¡¡è©ä¼°æ¹æ³çéæ±ï¼è©²æ¹æ³è½ææä»£çç³»çµ±ççµæ§åæä½é¢åãæ­¤å¤ï¼æåçè©ä¼°æ¶æ§ééå¯¦è­åæåçµ±è¨æª¢å®é©è­ï¼çºæ¹åä»£çç³»çµ±å¨åæç°å¢ä¸­çé©ææ§åå¯é æ§æä¾äºæå¹å¼çè¦è§£ã

##### **DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**
2411.00836v1 by Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang

The rapid advancements in Vision-Language Models (VLMs) have shown great
potential in tackling mathematical reasoning tasks that involve visual context.
Unlike humans who can reliably apply solution steps to similar problems with
minor modifications, we found that SOTA VLMs like GPT-4o can consistently fail
in these scenarios, revealing limitations in their mathematical reasoning
capabilities. In this paper, we investigate the mathematical reasoning
robustness in VLMs and evaluate how well these models perform under different
variants of the same question, such as changes in visual numerical values or
function graphs. While several vision-based math benchmarks have been developed
to assess VLMs' problem-solving capabilities, these benchmarks contain only
static sets of problems and cannot easily evaluate mathematical reasoning
robustness. To fill this gap, we introduce DynaMath, a dynamic visual math
benchmark designed for in-depth assessment of VLMs. DynaMath includes 501
high-quality, multi-topic seed questions, each represented as a Python program.
Those programs are carefully designed and annotated to enable the automatic
generation of a much larger set of concrete questions, including many different
types of visual and textual variations. DynaMath allows us to evaluate the
generalization ability of VLMs, by assessing their performance under varying
input conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010
generated concrete questions. Our results show that the worst-case model
accuracy, defined as the percentage of correctly answered seed questions in all
10 variants, is significantly lower than the average-case accuracy. Our
analysis emphasizes the need to study the robustness of VLMs' reasoning
abilities, and DynaMath provides valuable insights to guide the development of
more reliable models for mathematical reasoning.

æè¦ï¼<paragraph>è¦è¦ºèªè¨æ¨¡å (VLM) çå¿«éé²æ­¥å¨è§£æ±ºæ¶åè¦è¦ºèæ¯çæ¸å­¸æ¨çä»»åæ¹é¢å±ç¾äºå·¨å¤§çæ½åãèäººé¡å¯ä»¥å°è§£æ±ºæ­¥é©å¯é å°æç¨æ¼é¡ä¼¼åé¡ï¼ä¸¦é²è¡å¾®å°çä¿®æ¹ï¼ä¸åï¼æåç¼ç¾å GPT-4o ç­ SOTA VLM å¨éäºå ´æ¯ä¸­å¯è½ææçºå¤±æï¼æ­é²äºå¶æ¸å­¸æ¨çè½åçéå¶ãå¨æ¬æä¸­ï¼æåç ç©¶äº VLM ä¸­çæ¸å­¸æ¨çç©©å¥æ§ï¼ä¸¦è©ä¼°äºéäºæ¨¡åå¨åä¸åé¡çä¸åè®é«ï¼ä¾å¦è¦è¦ºæ¸å¼æå½æ¸åå½¢çè®åï¼ä¸çè¡¨ç¾ãéç¶å·²ç¶éç¼äºå¤ååºæ¼è¦è¦ºçæ¸å­¸åºæºä¾è©ä¼° VLM çåé¡è§£æ±ºè½åï¼ä½éäºåºæºåªåå«éæåé¡éï¼ç¡æ³è¼é¬è©ä¼°æ¸å­¸æ¨çç©©å¥æ§ãçºäºå¡«è£éä¸ç©ºç½ï¼æåå¼å¥äº DynaMathï¼éæ¯ä¸ååæè¦è¦ºæ¸å­¸åºæºï¼å°éç¨æ¼æ·±å¥è©ä¼° VLMãDynaMath åå« 501 åé«åè³ªãå¤ä¸»é¡ç¨®å­åé¡ï¼æ¯ååé¡é½è¡¨ç¤ºçºä¸å Python ç¨å¼ãéäºç¨å¼ç¶éä»ç´°è¨­è¨åè¨»è§£ï¼ä»¥ä¾¿èªåç¢çä¸çµæ´å¤§çå·é«åé¡ï¼åæ¬è¨±å¤ä¸åé¡åçè¦è¦ºåæå­è®é«ãDynaMath åè¨±æåè©ä¼° VLM çæ³åè½åï¼æ¹æ³æ¯å¨ç¨®å­åé¡çä¸åè¼¸å¥æ¢ä»¶ä¸è©ä¼°å¶è¡¨ç¾ãæåä½¿ç¨ 5,010 åçæçå·é«åé¡è©ä¼°äº 14 å SOTA VLMãæåççµæé¡¯ç¤ºï¼æå·®ææ³çæ¨¡åæºç¢ºåº¦ï¼å®ç¾©çºå¨ææ 10 åè®é«ä¸­æ­£ç¢ºåç­çç¨®å­åé¡çç¾åæ¯ï¼é¡¯èä½æ¼å¹³åææ³æºç¢ºåº¦ãæåçåæå¼·èª¿äºç ç©¶ VLM æ¨çè½åç©©å¥æ§çå¿è¦æ§ï¼è DynaMath æä¾äºæå¹å¼çè¦è§£ï¼ä»¥æå°éç¼æ´å¯é çæ¸å­¸æ¨çæ¨¡åã</paragraph>

##### **ADAM: An Embodied Causal Agent in Open-World Environments**
2410.22194v1 by Shu Yu, Chaochao Lu

In open-world environments like Minecraft, existing agents face challenges in
continuously learning structured knowledge, particularly causality. These
challenges stem from the opacity inherent in black-box models and an excessive
reliance on prior knowledge during training, which impair their
interpretability and generalization capability. To this end, we introduce ADAM,
An emboDied causal Agent in Minecraft, that can autonomously navigate the open
world, perceive multimodal contexts, learn causal world knowledge, and tackle
complex tasks through lifelong learning. ADAM is empowered by four key
components: 1) an interaction module, enabling the agent to execute actions
while documenting the interaction processes; 2) a causal model module, tasked
with constructing an ever-growing causal graph from scratch, which enhances
interpretability and diminishes reliance on prior knowledge; 3) a controller
module, comprising a planner, an actor, and a memory pool, which uses the
learned causal graph to accomplish tasks; 4) a perception module, powered by
multimodal large language models, which enables ADAM to perceive like a human
player. Extensive experiments show that ADAM constructs an almost perfect
causal graph from scratch, enabling efficient task decomposition and execution
with strong interpretability. Notably, in our modified Minecraft games where no
prior knowledge is available, ADAM maintains its performance and shows
remarkable robustness and generalization capability. ADAM pioneers a novel
paradigm that integrates causal methods and embodied agents in a synergistic
manner. Our project page is at https://opencausalab.github.io/ADAM.

æè¦ï¼å¨å Minecraft éæ¨£çéæ¾ä¸çç°å¢ä¸­ï¼ç¾æçä»£çäººé¢è¨æçºå­¸ç¿çµæ§åç¥è­çææ°ï¼å°¤å¶æ¯å æéä¿ãéäºææ°æºæ¼é»çæ¨¡ååºæçä¸éææ§ï¼ä»¥åå¨è¨ç·´æééåº¦ä¾è³´åé©ç¥è­ï¼éææå®³å®åçå¯è§£éæ§åæ³åè½åãçºæ­¤ï¼æåå¼å¥äº ADAMï¼Minecraft ä¸­çä¸åå·èº«å æä»£çï¼å®å¯ä»¥èªä¸»å°èªéæ¾ä¸çï¼æç¥å¤æ¨¡å¼ä¸ä¸æï¼å­¸ç¿å æä¸çç¥è­ï¼ä¸¦ééçµèº«å­¸ç¿ä¾æå°è¤éä»»åãADAM ç±ååééµçµæé¨åè³¦è½ï¼1) ä¸åäº¤äºæ¨¡çµï¼ä½¿ä»£çè½å¤ å·è¡åä½ï¼åæè¨éäº¤äºéç¨ï¼2) ä¸åå ææ¨¡åæ¨¡çµï¼è² è²¬å¾é ­éå§æ§å»ºä¸åä¸æ·å¢é·çå æåï¼éå¢å¼·äºå¯è§£éæ§ä¸¦æ¸å°äºå°åé©ç¥è­çä¾è³´ï¼3) ä¸åæ§å¶å¨æ¨¡çµï¼åæ¬ä¸åè¦åå¨ãä¸åå·è¡å¨åä¸åè¨æ¶æ± ï¼å®ä½¿ç¨å­¸ç¿å°çå æåä¾å®æä»»åï¼4) ä¸åæç¥æ¨¡çµï¼ç±å¤æ¨¡å¼å¤§åèªè¨æ¨¡åæä¾æ¯æ´ï¼ä½¿ ADAM è½å¤ åäººé¡ç©å®¶ä¸æ¨£æç¥ãå¤§éçå¯¦é©è¡¨æï¼ADAM å¾é ­éå§æ§å»ºäºä¸åå¹¾ä¹å®ç¾çå æåï¼å¯¦ç¾äºé«æçä»»ååè§£åå·è¡ï¼ä¸¦å·æå¾å¼·çå¯è§£éæ§ãå¼å¾æ³¨æçæ¯ï¼å¨æåä¿®æ¹éç Minecraft éæ²ä¸­ï¼æ²æå¯ç¨çåé©ç¥è­ï¼ADAM ä¿æäºå¶æ§è½ï¼ä¸¦è¡¨ç¾åºé¡¯èçé­¯æ£æ§åæ³åè½åãADAM éåµäºä¸ç¨®æ°ç©çç¯ä¾ï¼ä»¥ååæ¹å¼æ´åå ææ¹æ³åå·èº«ä»£çãæåçå°æ¡é é¢ä½æ¼ https://opencausalab.github.io/ADAMã

##### **Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**
2411.00028v1 by Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li

The fast development of location-based social networks (LBSNs) has led to
significant changes in society, resulting in popular studies of using LBSN data
for socioeconomic prediction, e.g., regional population and commercial activity
estimation. Existing studies design various graphs to model heterogeneous LBSN
data, and further apply graph representation learning methods for socioeconomic
prediction. However, these approaches heavily rely on heuristic ideas and
expertise to extract task-relevant knowledge from diverse data, which may not
be optimal for specific tasks. Additionally, they tend to overlook the inherent
relationships between different indicators, limiting the prediction accuracy.
Motivated by the remarkable abilities of large language models (LLMs) in
commonsense reasoning, embedding, and multi-agent collaboration, in this work,
we synergize LLM agents and knowledge graph for socioeconomic prediction. We
first construct a location-based knowledge graph (LBKG) to integrate
multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to
identify relevant meta-paths in the LBKG for each type of socioeconomic
prediction task, and design a semantic-guided attention module for knowledge
fusion with meta-paths. Moreover, we introduce a cross-task communication
mechanism to further enhance performance by enabling knowledge sharing across
tasks at both LLM agent and KG levels. On the one hand, the LLM agents for
different tasks collaborate to generate more diverse and comprehensive
meta-paths. On the other hand, the embeddings from different tasks are
adaptively merged for better socioeconomic prediction. Experiments on two
datasets demonstrate the effectiveness of the synergistic design between LLM
and KG, providing insights for information sharing across socioeconomic
prediction tasks.

æè¦ï¼åºæ¼ä½ç½®çç¤¾äº¤ç¶²è·¯ (LBSN) çå¿«éç¼å±å·²å°è´ç¤¾æç¼çéå¤§è®é©ï¼é²èä¿æä½¿ç¨ LBSN è³æé²è¡ç¤¾æç¶æ¿é æ¸¬çç±éç ç©¶ï¼ä¾å¦ååäººå£ååæ¥­æ´»åä¼°è¨ãç¾æç ç©¶è¨­è¨åç¨®åå½¢ä¾å»ºæ¨¡ç°è³ªç LBSN è³æï¼ä¸¦é²ä¸æ­¥æç¨åå½¢è¡¨ç¤ºå­¸ç¿æ¹æ³é²è¡ç¤¾æç¶æ¿é æ¸¬ãç¶èï¼éäºæ¹æ³æ¥µåº¦ä¾è³´åç¼å¼æ³æ³åå°æ¥­ç¥è­å¾ä¸åçè³æä¸­èåèä»»åç¸éçç¥è­ï¼éå°æ¼ç¹å®ä»»åèè¨å¯è½ä¸æ¯æä½³çãæ­¤å¤ï¼å®åå¾åæ¼å¿½ç¥ä¸åææ¨ä¹éçåºæéä¿ï¼é²èéå¶é æ¸¬æºç¢ºåº¦ãåæ æ¼å¤§åèªè¨æ¨¡å (LLM) å¨å¸¸è­æ¨çãåµå¥åå¤éä»£çåä½æ¹é¢çåè¶è½åï¼å¨éé å·¥ä½ä¸­ï¼æåå° LLM ä»£çåç¥è­åå½¢çµåèµ·ä¾é²è¡ç¤¾æç¶æ¿é æ¸¬ãæåé¦åå»ºæ§ä¸ååºæ¼ä½ç½®çç¥è­åå½¢ (LBKG) ä¾æ´åå¤ä¾æºç LBSN è³æãç¶å¾ï¼æåå©ç¨ LLM ä»£ççæ¨çè½åï¼éå°æ¯ç¨®é¡åçç¤¾æç¶æ¿é æ¸¬ä»»åè­å¥ LBKG ä¸­ç¸éç meta è·¯å¾ï¼ä¸¦è¨­è¨ä¸åèªç¾©å°åçæ³¨æåæ¨¡çµï¼ç¨æ¼è meta è·¯å¾çç¥è­èåãæ­¤å¤ï¼æåå¼å¥ä¸åè·¨ä»»åæºéæ©å¶ï¼ä»¥ééå¨ LLM ä»£çå KG å±¤ç´ä¸è·¨ä»»ååç¨ç¥è­å±äº«é²ä¸æ­¥æåæè½ãä¸æ¹é¢ï¼ä¸åä»»åç LLM ä»£çåä½ç¢çæ´å¤æ¨£åä¸å¨é¢ç meta è·¯å¾ãå¦ä¸æ¹é¢ï¼ä¾èªä¸åä»»åçåµå¥æèªé©æå°åä½µï¼ä»¥é²è¡æ´å¥½çç¤¾æç¶æ¿é æ¸¬ãå¨å©åè³æéä¸çå¯¦é©è­æäº LLM å KG ä¹éååè¨­è¨çæææ§ï¼ä¸¦æä¾è·¨ç¤¾æç¶æ¿é æ¸¬ä»»åé²è¡è³è¨å±äº«çè¦è§£ã

##### **A Hierarchical Language Model For Interpretable Graph Reasoning**
2410.22372v1 by Sambhav Khurana, Xiner Li, Shurui Gui, Shuiwang Ji

Large language models (LLMs) are being increasingly explored for graph tasks.
Despite their remarkable success in text-based tasks, LLMs' capabilities in
understanding explicit graph structures remain limited, particularly with large
graphs. In this work, we introduce Hierarchical Language Model for Graph
(HLM-G), which employs a two-block architecture to capture node-centric local
information and interaction-centric global structure, effectively enhancing
graph structure understanding abilities. The proposed scheme allows LLMs to
address various graph queries with high efficacy, efficiency, and robustness,
while reducing computational costs on large-scale graph tasks. Furthermore, we
demonstrate the interpretability of our model using intrinsic attention weights
and established explainers. Comprehensive evaluations across diverse graph
reasoning and real-world tasks of node, link, and graph-levels highlight the
superiority of our method, marking a significant advancement in the application
of LLMs to graph understanding.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æä¾æå¤ç¨æ¼åå½¢ä»»åã
åç®¡ LLM å¨åºæ¼æå­çä»»åä¸­åå¾é¡¯èçæåï¼ä½å¶å¨çè§£æç¢ºåå½¢çµæ§æ¹é¢çè½åä»ç¶æéï¼ç¹å¥æ¯å°æ¼å¤§ååå½¢ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºåå½¢éå±¤èªè¨æ¨¡å (HLM-G)ï¼å®æ¡ç¨éåå¡æ¶æ§ä¾æ·åä»¥ç¯é»çºä¸­å¿çå±é¨è³è¨åä»¥äºåçºä¸­å¿çæ´é«çµæ§ï¼ææå°å¢å¼·äºåå½¢çµæ§çè§£è½åãææåºçæ¶æ§åè¨± LLM ä»¥é«æçãé«æçåé«ç©©å¥æ§ä¾èçåç¨®åå½¢æ¥è©¢ï¼åæéä½å¤§ååå½¢ä»»åçéç®ææ¬ãæ­¤å¤ï¼æåä½¿ç¨å§å¨æ³¨æåæ¬éåå·²å»ºç«çè§£éå¨ä¾å±ç¤ºæåæ¨¡åçå¯è§£éæ§ãå¨ç¯é»ãé£çµååå½¢å±¤ç´çåç¨®åå½¢æ¨çåçå¯¦ä¸çä»»åä¸­é²è¡çå¨é¢è©ä¼°çªé¡¯äºæåæ¹æ³çåªè¶æ§ï¼æ¨èªè LLM å¨åå½¢çè§£æç¨æ¹é¢åå¾éå¤§é²å±ã

##### **LLM-Forest for Health Tabular Data Imputation**
2410.21520v1 by Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B. Cook, Jingrui He

Missing data imputation is a critical challenge in tabular datasets,
especially in healthcare, where data completeness is vital for accurate
analysis. Large language models (LLMs), trained on vast corpora, have shown
strong potential in data generation, making them a promising tool for tabular
data imputation. However, challenges persist in designing effective prompts for
a finetuning-free process and in mitigating the risk of LLM hallucinations. To
address these issues, we propose a novel framework, LLM-Forest, which
introduces a "forest" of few-shot learning LLM "trees" with confidence-based
weighted voting. This framework is established on a new concept of bipartite
information graphs to identify high-quality relevant neighboring entries with
both feature and value granularity. Extensive experiments on four real-world
healthcare datasets demonstrate the effectiveness and efficiency of LLM-Forest.

æè¦ï¼éºå¤±è³ææ¨ä¼°æ¯è¡¨æ ¼è³æéä¸­çéå¤§ææ°ï¼
ç¹å¥æ¯å¨é«çä¿å¥ä¸­ï¼è³æå®æ´æ§å°æ¼æºç¢ºåæè³ééè¦ã
å¤§åèªè¨æ¨¡å (LLM) å¨é¾å¤§çèªæåº«ä¸è¨ç·´ï¼å¨è³æç¢çæ¹é¢å±ç¾åºå¼·å¤§çæ½åï¼ä½¿å¶æçºè¡¨æ ¼è³ææ¨ä¼°çæåéå·¥å·ã
ç¶èï¼å¨è¨­è¨æææç¤ºä»¥é²è¡å¾®èª¿åè²»æµç¨åæ¸è¼ LLM å¹»è¦ºé¢¨éªæ¹é¢ä»å­å¨ææ°ã
çºäºè§£æ±ºéäºåé¡ï¼æåæåºä¸åæ°çæ¡æ¶ï¼LLM-Forestï¼å®å¼å¥äºä¸åãæ£®æãçå°éå­¸ç¿ LLMãæ¨¹ãï¼ä¸¦æ¡ç¨åºæ¼ä¿¡å¿çå æ¬æç¥¨ã
éåæ¡æ¶å»ºç«å¨éåè³è¨åçæ°æ¦å¿µä¸ï¼ä»¥è­å¥å·æç¹å¾µåå¼ç²åº¦çåªè³ªç¸éé°è¿é ç®ã
å¨ååçå¯¦ä¸ççé«çä¿å¥è³æéä¸é²è¡çå»£æ³å¯¦é©è­æäº LLM-Forest çæææ§åæçã

##### **Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**
2410.21237v1 by Zhantao Yang, Han Zhang, Fangyi Chen, Anudeepsekhar Bolimera, Marios Savvides

Knowledge Graph (KG) is playing an increasingly important role in various AI
systems. For e-commerce, an efficient and low-cost automated knowledge graph
construction method is the foundation of enabling various successful downstream
applications. In this paper, we propose a novel method for constructing
structured product knowledge graphs from raw product images. The method
cooperatively leverages recent advances in the vision-language model (VLM) and
large language model (LLM), fully automating the process and allowing timely
graph updates. We also present a human-annotated e-commerce product dataset for
benchmarking product property extraction in knowledge graph construction. Our
method outperforms our baseline in all metrics and evaluated properties,
demonstrating its effectiveness and bright usage potential.

æè¦ï¼ç¥è­åè­ (KG) å¨åç¨® AI ç³»çµ±ä¸­æ®æ¼è¶ä¾è¶éè¦çè§è²ãå°æ¼é»å­ååä¾èªªï¼ä¸ç¨®ææä¸ä½ææ¬çèªååç¥è­åè­å»ºæ§æ¹æ³æ¯ä¿æåç¨®æåçä¸æ¸¸æç¨ç¨å¼çåºç¤ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®å¾åå§ç¢åå½±åå»ºæ§çµæ§åç¢åç¥è­åè­çæ°ç©æ¹æ³ãè©²æ¹æ³ååå©ç¨äºè¦è¦ºèªè¨æ¨¡å (VLM) åå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±ï¼å®å¨èªååäºæµç¨ä¸¦åè¨±åææ´æ°åè­ãæåéæä¾äºä¸åç±äººå·¥æ¨è¨»çé»å­ååç¢åè³æéï¼ç¨æ¼è©éç¥è­åè­å»ºæ§ä¸­çç¢åå±¬æ§èåãæåçæ¨¡åå¨ææææ¨åè©ä¼°å±¬æ§ä¸é½åªæ¼æåçåºæºï¼è­æäºå¶æææ§åå»£éçä½¿ç¨æ½åã

##### **CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**
2410.21067v1 by Meiqi Chen, Fandong Meng, Yingxue Zhang, Yan Zhang, Jie Zhou

Large language models (LLMs) have shown great promise in machine translation,
but they still struggle with contextually dependent terms, such as new or
domain-specific words. This leads to inconsistencies and errors that are
difficult to address. Existing solutions often depend on manual identification
of such terms, which is impractical given the complexity and evolving nature of
language. While Retrieval-Augmented Generation (RAG) could provide some
assistance, its application to translation is limited by issues such as
hallucinations from information overload. In this paper, we propose CRAT, a
novel multi-agent translation framework that leverages RAG and
causality-enhanced self-reflection to address these challenges. This framework
consists of several specialized agents: the Unknown Terms Identification agent
detects unknown terms within the context, the Knowledge Graph (KG) Constructor
agent extracts relevant internal knowledge about these terms and retrieves
bilingual information from external sources, the Causality-enhanced Judge agent
validates the accuracy of the information, and the Translator agent
incorporates the refined information into the final output. This automated
process allows for more precise and consistent handling of key terms during
translation. Our results show that CRAT significantly improves translation
accuracy, particularly in handling context-sensitive terms and emerging
vocabulary.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨æ©å¨ç¿»è­¯æ¹é¢å±ç¾åºæ¥µå¤§çåæ¯ï¼
ä½å®åä»ç¶é£ä»¥æå°ä¾è³´æ¼èªå¢çè©å½ï¼ä¾å¦æ°è©æç¹å®é åçè©å½ãéæå°è´ä¸ä¸è´åé¯èª¤ï¼èéäºé¯èª¤å¾é£è§£æ±ºãç¾æçè§£æ±ºæ¹æ¡éå¸¸ä¾è³´æ¼æåè­å¥æ­¤é¡è©å½ï¼ä½ç±æ¼èªè¨çè¤éæ§åä¸æ·æ¼è®çç¹æ§ï¼éä¸¦ä¸å¯è¡ãéç¶æª¢ç´¢å¢å¼·çæï¼RAGï¼å¯ä»¥æä¾ä¸äºåå©ï¼ä½å¶å¨ç¿»è­¯ä¸­çæç¨åå°è«¸å¦è³è¨è¶è¼ç¢ççå¹»è¦ºç­åé¡çéå¶ãå¨æ¬æä¸­ï¼æåæåº CRATï¼éæ¯ä¸åæ°ç©çå¤ä»£çç¿»è­¯æ¶æ§ï¼å®å©ç¨ RAG åå æå¢å¼·èªçä¾æå°éäºææ°ãæ­¤æ¶æ§åå«å¹¾åå°éçä»£çï¼æªç¥è©å½è­å¥ä»£çæåµæ¸¬èªå¢ä¸­çæªç¥è©å½ï¼ç¥è­åè­ï¼KGï¼å»ºæ§ä»£çææ·åéäºè©å½ç¸éçå§é¨ç¥è­ï¼ä¸¦å¾å¤é¨ä¾æºä¸­æª¢ç´¢éèªè³è¨ï¼å æå¢å¼·å¤æ·ä»£çæé©è­è³è¨çæºç¢ºæ§ï¼èç¿»è­¯ä»£çæå°ç²¾çéçè³è¨ç´å¥æçµè¼¸åºãéåèªååçæµç¨åè¨±å¨ç¿»è­¯éç¨ä¸­æ´ç²¾ç¢ºä¸ä¸è´å°èçééµè©å½ãæåççµæé¡¯ç¤ºï¼CRAT å¤§å¹æåäºç¿»è­¯æºç¢ºæ§ï¼ç¹å¥æ¯å¨èçå°èªå¢ææçè©å½åæ°èè©å½æ¹é¢ã

##### **CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**
2410.21060v1 by Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao

Textual descriptions in cyber threat intelligence (CTI) reports, such as
security articles and news, are rich sources of knowledge about cyber threats,
crucial for organizations to stay informed about the rapidly evolving threat
landscape. However, current CTI extraction methods lack flexibility and
generalizability, often resulting in inaccurate and incomplete knowledge
extraction. Syntax parsing relies on fixed rules and dictionaries, while model
fine-tuning requires large annotated datasets, making both paradigms
challenging to adapt to new threats and ontologies. To bridge the gap, we
propose CTINexus, a novel framework leveraging optimized in-context learning
(ICL) of large language models (LLMs) for data-efficient CTI knowledge
extraction and high-quality cybersecurity knowledge graph (CSKG) construction.
Unlike existing methods, CTINexus requires neither extensive data nor parameter
tuning and can adapt to various ontologies with minimal annotated examples.
This is achieved through (1) a carefully designed automatic prompt construction
strategy with optimal demonstration retrieval for extracting a wide range of
cybersecurity entities and relations; (2) a hierarchical entity alignment
technique that canonicalizes the extracted knowledge and removes redundancy;
(3) an ICL-enhanced long-distance relation prediction technique to further
complete the CKSG with missing links. Our extensive evaluations using 150
real-world CTI reports collected from 10 platforms demonstrate that CTINexus
significantly outperforms existing methods in constructing accurate and
complete CSKGs, highlighting its potential to transform CTI analysis with an
efficient and adaptable solution for the dynamic threat landscape.

æè¦ï¼ç¶²è·¯å¨èæå ± (CTI) å ±åä¸­çæå­æè¿°ï¼ä¾å¦å®å¨æç« åæ°èï¼æ¯ç¶²è·¯å¨èçè±å¯ç¥è­ä¾æºï¼å°æ¼çµç¹èè¨è³ééè¦ï¼å¯ä»¥é¨æäºè§£å¿«éæ¼è®çå¨èç°å¢ãç¶èï¼ç®åç CTI æåæ¹æ³ç¼ºä¹éæ´»æ§ä¸é£ä»¥æ¦æ¬ï¼éå¸¸æå°è´ç¥è­æåä¸æºç¢ºä¸ä¸å®æ´ãèªæ³è§£æä¾è³´æ¼åºå®è¦ååå­å¸ï¼èæ¨¡åå¾®èª¿éè¦å¤§éæ¨è¨»çè³æéï¼éä½¿å¾éå©ç¨®ç¯ä¾é½é£ä»¥é©ææ°çå¨èåæ¬ä½ãçºäºå½è£å·®è·ï¼æåæåºäº CTINexusï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) çæä½³åæå¢å­¸ç¿ (ICL) ä¾é²è¡è³æææçç CTI ç¥è­æååé«åè³ªçç¶²è·¯å®å¨ç¥è­å (CSKG) å»ºæ§ãèç¾ææ¹æ³ä¸åï¼CTINexus ä¸éè¦å»£æ³çè³ææåæ¸èª¿æ´ï¼ä¸¦ä¸å¯ä»¥ééæå°çæ¨è¨»ç¯ä¾é©æåç¨®æ¬ä½ãéæ¯éé (1) ç¶éç²¾å¿è¨­è¨çèªåæç¤ºå»ºæ§ç­ç¥ï¼ä¸¦ééæä½³ç¤ºç¯æª¢ç´¢ä¾æåå»£æ³çç¶²è·¯å®å¨å¯¦é«åéä¿ä¾å¯¦ç¾çï¼(2) ä¸ç¨®éå±¤å¼å¯¦é«æ¯å°æè¡ï¼å¯ä»¥å°æåçç¥è­æ¨æºåä¸¦æ¶é¤åé¤ï¼(3) ä¸ç¨® ICL å¢å¼·çé·è·é¢éä¿é æ¸¬æè¡ï¼å¯ä»¥é²ä¸æ­¥å®æå·æéºå¤±é£çµç CKSGãæåä½¿ç¨å¾ 10 åå¹³å°æ¶éç 150 ä»½çå¯¦ä¸ç CTI å ±åé²è¡å»£æ³è©ä¼°ï¼è­æ CTINexus å¨å»ºæ§æºç¢ºä¸å®æ´ç CSKG æ¹é¢æé¡¯åªæ¼ç¾ææ¹æ³ï¼çªé¡¯äºå¶ä»¥ææä¸é©ææ§å¼·çè§£æ±ºæ¹æ¡è½æ CTI åæçæ½åï¼ä»¥æå°åæçå¨èç°å¢ã

##### **Graph-based Uncertainty Metrics for Long-form Language Model Outputs**
2410.20783v1 by Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto

Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities, but these systems are still known to
hallucinate, and granular uncertainty estimation for long-form LLM generations
remains challenging. In this work, we propose Graph Uncertainty -- which
represents the relationship between LLM generations and claims within them as a
bipartite graph and estimates the claim-level uncertainty with a family of
graph centrality metrics. Under this view, existing uncertainty estimation
methods based on the concept of self-consistency can be viewed as using degree
centrality as an uncertainty measure, and we show that more sophisticated
alternatives such as closeness centrality provide consistent gains at
claim-level uncertainty estimation. Moreover, we present uncertainty-aware
decoding techniques that leverage both the graph structure and uncertainty
estimates to improve the factuality of LLM generations by preserving only the
most reliable claims. Compared to existing methods, our graph-based uncertainty
metrics lead to an average of 6.8% relative gains on AUPRC across various
long-form generation settings, and our end-to-end system provides consistent
2-4% gains in factuality over existing decoding techniques while significantly
improving the informativeness of generated responses.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯èæåäºæå­çæè½åï¼ä½éäºç³»çµ±ä»ä»¥ç¢çå¹»è¦ºèç¨±ï¼èéå°é·ç¯ LLM çæçç´°ç·»ä¸ç¢ºå®æ§ä¼°è¨ä»æ¯ä¸é ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºåå½¢ä¸ç¢ºå®æ§ï¼å®å° LLM çæåå¶ä¸­çä¸»å¼µè¡¨ç¤ºçºäºé¨åï¼ä¸¦ä½¿ç¨ä¸ç³»ååå½¢ä¸­å¿æ§ææ¨ä¼°è¨ä¸»å¼µå±¤ç´çä¸ç¢ºå®æ§ãå¨æ­¤è§é»ä¸ï¼ç¾æçåºæ¼èªæ´½æ§æ¦å¿µçä¸ç¢ºå®æ§ä¼°è¨æ¹æ³å¯è¦çºä½¿ç¨åº¦éä¸­å¿æ§ä½çºä¸ç¢ºå®æ§ææ¨ï¼æåè­æäºæ´ç²¾å¯çæ¿ä»£æ¹æ¡ï¼ä¾å¦æ¥è¿ä¸­å¿æ§ï¼å¨ä¸»å¼µå±¤ç´ä¸ç¢ºå®æ§ä¼°è¨ä¸­æä¾äºç©©å®çå¢çãæ­¤å¤ï¼æåæåºäºä¸ç¢ºå®æ§æç¥è§£ç¢¼æè¡ï¼è©²æè¡å©ç¨åå½¢çµæ§åä¸ç¢ºå®æ§ä¼°è¨ä¾æå LLM çæççå¯¦æ§ï¼æ¹æ³æ¯åä¿çæå¯é çä¸»å¼µãèç¾ææ¹æ³ç¸æ¯ï¼æåçåºæ¼åå½¢çææ¨å¨åç¨®é·ç¯çæè¨­å®ä¸­å¹³åæåäº AUPRC ç 6.8%ï¼èæåçç«¯å°ç«¯ç³»çµ±å¨çå¯¦æ§æ¹é¢æä¾äº 2-4% çç©©å®å¢çï¼åæé¡¯èæåäºçæåæçè³è¨æ§ã

##### **Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**
2410.20753v1 by Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma

We introduce Planning-guided Retrieval Augmented Generation
(Plan$\times$RAG), a novel framework that augments the
\emph{retrieve-then-reason} paradigm of existing RAG frameworks to
\emph{plan-then-retrieve}. Plan$\times$RAG formulates a reasoning plan as a
directed acyclic graph (DAG), decomposing queries into interrelated atomic
sub-queries. Answer generation follows the DAG structure, allowing significant
gains in efficiency through parallelized retrieval and generation. While
state-of-the-art RAG solutions require extensive data generation and
fine-tuning of language models (LMs), Plan$\times$RAG incorporates frozen LMs
as plug-and-play experts to generate high-quality answers. Compared to existing
RAG solutions, Plan$\times$RAG demonstrates significant improvements in
reducing hallucinations and bolstering attribution due to its structured
sub-query decomposition. Overall, Plan$\times$RAG offers a new perspective on
integrating external knowledge in LMs while ensuring attribution by design,
contributing towards more reliable LM-based systems.

æè¦ï¼<paragraph>æåå¼å¥äºè¦åå¼å°çæª¢ç´¢å¢å¼·çæ (Plan$\times$RAG)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®æ´åäºç¾æ RAG æ¡æ¶çãåæª¢ç´¢å¾æ¨çãç¯ä¾ï¼æ¹çºãåè¦åå¾æª¢ç´¢ããPlan$\times$RAG å°æ¨çè¨ç«å¶å®çºæåç¡ç°å (DAG)ï¼å°æ¥è©¢åè§£æç¸äºéè¯çåå­å­æ¥è©¢ãç­æ¡çæéµå¾ª DAG çµæ§ï¼ééä¸¦è¡æª¢ç´¢åçæï¼å¤§å¹æåæçãéç¶æåé²ç RAG è§£å³æ¹æ¡éè¦å¤§éè³æçæåèªè¨æ¨¡å (LM) çå¾®èª¿ï¼ä½ Plan$\times$RAG å°åçµç LM æ´åçºå³æå³ç¨çå°å®¶ï¼ä»¥çæé«åè³ªçç­æ¡ãèç¾æç RAG è§£å³æ¹æ¡ç¸æ¯ï¼Plan$\times$RAG å¨æ¸å°å¹»è¦ºåå å¼·æ­¸å æ¹é¢è¡¨ç¾åºé¡¯èçé²æ­¥ï¼éè¦æ­¸åæ¼å¶çµæ§åçå­æ¥è©¢åè§£ãç¸½é«èè¨ï¼Plan$\times$RAG æä¾äºä¸åæ°çè§é»ï¼ä»¥æ´å LM ä¸­çå¤é¨ç¥è­ï¼åæç¢ºä¿æ­¸å è¨­è¨ï¼æå©æ¼å»ºç«æ´å¯é çåºæ¼ LM çç³»çµ±ã</paragraph>

##### **Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**
2410.20724v1 by Mufei Li, Siqi Miao, Pan Li

Large Language Models (LLMs) demonstrate strong reasoning abilities but face
limitations such as hallucinations and outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by
grounding LLM outputs in structured external knowledge from KGs. However,
current KG-based RAG frameworks still struggle to optimize the trade-off
between retrieval effectiveness and efficiency in identifying a suitable amount
of relevant graph information for the LLM to digest. We introduce SubgraphRAG,
extending the KG-based RAG framework that retrieves subgraphs and leverages
LLMs for reasoning and answer prediction. Our approach innovatively integrates
a lightweight multilayer perceptron with a parallel triple-scoring mechanism
for efficient and flexible subgraph retrieval while encoding directional
structural distances to enhance retrieval effectiveness. The size of retrieved
subgraphs can be flexibly adjusted to match the query's need and the downstream
LLM's capabilities. This design strikes a balance between model complexity and
reasoning power, enabling scalable and generalizable retrieval processes.
Notably, based on our retrieved subgraphs, smaller LLMs like
Llama3.1-8B-Instruct deliver competitive results with explainable reasoning,
while larger models like GPT-4o achieve state-of-the-art accuracy compared with
previous baselines -- all without fine-tuning. Extensive evaluations on the
WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,
accuracy, and reliability by reducing hallucinations and improving response
grounding.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¤ºäºå¼·å¤§çæ¨çè½åï¼ä½é¢è¨å¹»è¦ºåéæç¥è­ç­éå¶ãåºæ¼ç¥è­åè­ (KG) çæª¢ç´¢å¢å¼·çæ (RAG) ééå° LLM è¼¸åºå»ºç«å¨ä¾èª KG ççµæ§åå¤é¨ç¥è­ä¸ï¼ä¾è§£æ±ºéäºåé¡ãç¶èï¼ç¶åçåºæ¼ KG ç RAG æ¶æ§ä»é£ä»¥åªåæª¢ç´¢ææèæçä¹éçæ¬è¡¡ï¼ä»¥è­å¥é©éçç¸éåå½¢è³è¨ä¾ LLM æ¶åãæåå¼å¥äº SubgraphRAGï¼æ´åäºåºæ¼ KG ç RAG æ¶æ§ï¼å®ææª¢ç´¢å­åä¸¦å©ç¨ LLM é²è¡æ¨çåç­æ¡é æ¸¬ãæåçåæ³åµæ°å°æ´åäºä¸åè¼éç´å¤å±¤æç¥å¨åä¸åä¸¦è¡çä¸åçµè©åæ©å¶ï¼ä»¥é²è¡ææä¸å½æ§çå­åæª¢ç´¢ï¼åæç·¨ç¢¼æ¹åçµæ§è·é¢ä»¥å¢å¼·æª¢ç´¢ææãæª¢ç´¢çå­åå¤§å°å¯ä»¥éæ´»èª¿æ´ï¼ä»¥ç¬¦åæ¥è©¢çéæ±åä¸æ¸¸ LLM çåè½ãæ­¤è¨­è¨å¨æ¨¡åè¤éåº¦åæ¨çè½åä¹éåå¾å¹³è¡¡ï¼å¯¦ç¾å¯æ´åä¸å¯æ¦åçæª¢ç´¢æµç¨ãå¼å¾æ³¨æçæ¯ï¼æ ¹ææåæª¢ç´¢çå­åï¼å Llama3.1-8B-Instruct ç­è¼å°ç LLM å¯ä»¥ééå¯è§£éçæ¨çæä¾å·æç«¶ç­åççµæï¼èå GPT-4o ç­è¼å¤§çæ¨¡ååå¯éå°èåååºæºç¸æ¯çææ°æºç¢ºåº¦ï¼èä¸ææéäºé½ä¸éè¦å¾®èª¿ãå¨ WebQSP å CWQ åºæºä¸çå»£æ³è©ä¼°çªåºäº SubgraphRAG å¨æçãæºç¢ºæ§åå¯é æ§æ¹é¢çåªå¢ï¼æ¹æ³æ¯æ¸å°å¹»è¦ºä¸¦æ¹ååæä¾æã

##### **Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**
2410.20321v1 by Xingrui Zhuo, Jiapu Wang, Gongqing Wu, Shirui Pan, Xindong Wu

Knowledge Graph Query Embedding (KGQE) aims to embed First-Order Logic (FOL)
queries in a low-dimensional KG space for complex reasoning over incomplete
KGs. To enhance the generalization of KGQE models, recent studies integrate
various external information (such as entity types and relation context) to
better capture the logical semantics of FOL queries. The whole process is
commonly referred to as Query Pattern Learning (QPL). However, current QPL
methods typically suffer from the pattern-entity alignment bias problem,
leading to the learned defective query patterns limiting KGQE models'
performance. To address this problem, we propose an effective Query Instruction
Parsing Plugin (QIPP) that leverages the context awareness of Pre-trained
Language Models (PLMs) to capture latent query patterns from code-like query
instructions. Unlike the external information introduced by previous QPL
methods, we first propose code-like instructions to express FOL queries in an
alternative format. This format utilizes textual variables and nested tuples to
convey the logical semantics within FOL queries, serving as raw materials for a
PLM-based instruction encoder to obtain complete query patterns. Building on
this, we design a query-guided instruction decoder to adapt query patterns to
KGQE models. To further enhance QIPP's effectiveness across various KGQE
models, we propose a query pattern injection mechanism based on compressed
optimization boundaries and an adaptive normalization component, allowing KGQE
models to utilize query patterns more efficiently. Extensive experiments
demonstrate that our plug-and-play method improves the performance of eight
basic KGQE models and outperforms two state-of-the-art QPL methods.

æè¦ï¼ç¥è­åè­æ¥è©¢åµå¥ï¼KGQEï¼æ¨å¨å°ä¸ééè¼¯ï¼FOLï¼æ¥è©¢åµå¥å°ä½ç¶­ KG ç©ºéä¸­ï¼ä»¥ä¾¿å°ä¸å®æ´ç KG é²è¡è¤éæ¨çãçºäºå¢å¼· KGQE æ¨¡åçæ³åè½åï¼æè¿çç ç©¶æ´åäºåç¨®å¤é¨è³è¨ï¼ä¾å¦å¯¦é«é¡ååéä¿ä¸ä¸æï¼ï¼ä»¥æ´å¥½å°ææ FOL æ¥è©¢çéè¼¯èªç¾©ãæ´åéç¨éå¸¸ç¨±çºæ¥è©¢æ¨¡å¼å­¸ç¿ï¼QPLï¼ãç¶èï¼ç¶åç QPL æ¹æ³éå¸¸æåå°æ¨¡å¼å¯¦é«å°é½åå·®åé¡çå½±é¿ï¼å°è´å­¸ç¿å°çæç¼ºé·æ¥è©¢æ¨¡å¼éå¶äº KGQE æ¨¡åçæè½ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åææçæ¥è©¢æä»¤è§£æå¤æç¨å¼ï¼QIPPï¼ï¼å®å©ç¨é è¨ç·´èªè¨æ¨¡åï¼PLMï¼çä¸ä¸ææç¥ä¾å¾é¡ä»£ç¢¼çæ¥è©¢æä»¤ä¸­æ·åæ½å¨æ¥è©¢æ¨¡å¼ãèåå QPL æ¹æ³å¼å¥çå¤é¨è³è¨ä¸åï¼æåé¦åæåºé¡ä»£ç¢¼çæä»¤ä»¥å¦é¡æ ¼å¼è¡¨é FOL æ¥è©¢ãæ­¤æ ¼å¼å©ç¨æå­è®æ¸åå·¢çåçµä¾å³é FOL æ¥è©¢ä¸­çéè¼¯èªç¾©ï¼ä½çºåºæ¼ PLM çæä»¤ç·¨ç¢¼å¨çåæï¼ä»¥åå¾å®æ´çæ¥è©¢æ¨¡å¼ãå¨æ­¤åºç¤ä¸ï¼æåè¨­è¨äºä¸åæ¥è©¢å¼å°çæä»¤è§£ç¢¼å¨ï¼ä»¥å°æ¥è©¢æ¨¡å¼èª¿æ´å° KGQE æ¨¡åãçºäºé²ä¸æ­¥å¢å¼· QIPP å¨åç¨® KGQE æ¨¡åä¸­çæææ§ï¼æåæåºäºä¸ååºæ¼å£ç¸®æä½³åéçåèªé©ææ­£è¦ååä»¶çæ¥è©¢æ¨¡å¼æ³¨å¥æ©å¶ï¼åè¨± KGQE æ¨¡åæ´ææå°å©ç¨æ¥è©¢æ¨¡å¼ãå»£æ³çå¯¦é©è¡¨æï¼æåçå³æå³ç¨æ¹æ³æ¹åäºå«ååºæ¬ KGQE æ¨¡åçæè½ï¼ä¸¦åªæ¼å©ç¨®æåé²ç QPL æ¹æ³ã

##### **Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**
2410.21324v1 by Vishesh Prasad, Brian Kim, Nickvash Kani

Recent advances in natural language processing (NLP), particularly with the
emergence of large language models (LLMs), have significantly enhanced the
field of textual analysis. However, while these developments have yielded
substantial progress in analyzing textual data, applying analysis to
mathematical equations and their relationships within texts has produced mixed
results. In this paper, we take the initial steps toward understanding the
dependency relationships between mathematical expressions in STEM articles. Our
dataset, sourced from a random sampling of the arXiv corpus, contains an
analysis of 107 published STEM manuscripts whose inter-equation dependency
relationships have been hand-labeled, resulting in a new object we refer to as
a derivation graph that summarizes the mathematical content of the manuscript.
We exhaustively evaluate analytical and NLP-based models to assess their
capability to identify and extract the derivation relationships for each
article and compare the results with the ground truth. Our comprehensive
testing finds that both analytical and NLP models (including LLMs) achieve
$\sim$40-50% F1 scores for extracting derivation graphs from articles,
revealing that the recent advances in NLP have not made significant inroads in
comprehending mathematical texts compared to simpler analytic models. While
current approaches offer a solid foundation for extracting mathematical
information, further research is necessary to improve accuracy and depth in
this area.

æè¦ï¼èªç¶èªè¨èçï¼NLPï¼çææ°é²å±ï¼ç¹å¥æ¯å¤§èªè¨æ¨¡åï¼LLMï¼çåºç¾ï¼å·²é¡¯èå¢å¼·äºææ¬åæé åãç¶èï¼åç®¡éäºç¼å±å¨åæææ¬è³ææ¹é¢åå¾äºå¯¦è³ªæ§é²å±ï¼ä½å°åææç¨æ¼æ¸å­¸æ¹ç¨å¼åå¶å¨ææ¬ä¸­çéä¿å»ç¢çäºä¸åççµæãå¨æ¬æä¸­ï¼æåæ¡åäºåæ­¥æ­¥é©ä¾äºè§£ STEM æç« ä¸­æ¸å­¸è¡¨éå¼ä¹éçä¾è³´éä¿ãæåçè³æéåèª arXiv èªæåº«çé¨æ©æ½æ¨£ï¼å¶ä¸­åå«å° 107 ç¯å·²ç¼è¡¨ç STEM æç¨¿çåæï¼å¶æ¹ç¨å¼éçä¾è³´éä¿å·²é²è¡æåæ¨è¨ï¼ç¢çäºä¸åæåç¨±çºè¡çåçæ°ç©ä»¶ï¼è©²ç©ä»¶ç¸½çµäºæç¨¿çæ¸å­¸å§å®¹ãæåå¾¹åºè©ä¼°äºåæååºæ¼ NLP çæ¨¡åï¼ä»¥è©ä¼°å®åè­å¥åæåæ¯ç¯æç« çè¡çéä¿çè½åï¼ä¸¦å°çµæèçå¯¦ææ³é²è¡æ¯è¼ãæåçå¨é¢æ¸¬è©¦ç¼ç¾ï¼åæå NLP æ¨¡åï¼åæ¬ LLMï¼å¨å¾æç« ä¸­æåè¡çåæ¹é¢ç F1 åæ¸åéå° $\sim$40-50%ï¼éè¡¨æèæ´ç°¡å®çåææ¨¡åç¸æ¯ï¼NLP çææ°é²å±ä¸¦æ²æå¨çè§£æ¸å­¸ææ¬æ¹é¢åå¾éå¤§é²å±ãåç®¡ç®åçæ¹æ³çºæåæ¸å­¸è³è¨æä¾äºå å¯¦çåºç¤ï¼ä½ä»éè¦é²ä¸æ­¥çç ç©¶ä¾æé«æ­¤é åçæºç¢ºæ§åæ·±åº¦ã

##### **DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**
2410.19955v1 by Pengfei Hu, Chang Lu, Fei Wang, Yue Ning

Electronic Health Records (EHR) has revolutionized healthcare data management
and prediction in the field of AI and machine learning. Accurate predictions of
diagnosis and medications significantly mitigate health risks and provide
guidance for preventive care. However, EHR driven models often have limited
scope on understanding medical-domain knowledge and mostly rely on
simple-and-sole ontologies. In addition, due to the missing features and
incomplete disease coverage of EHR, most studies only focus on basic analysis
on conditions and medication. We propose DualMAR, a framework that enhances EHR
prediction tasks through both individual observation data and public knowledge
bases. First, we construct a bi-hierarchical Diagnosis Knowledge Graph (KG)
using verified public clinical ontologies and augment this KG via Large
Language Models (LLMs); Second, we design a new proxy-task learning on lab
results in EHR for pretraining, which further enhance KG representation and
patient embeddings. By retrieving radial and angular coordinates upon polar
space, DualMAR enables accurate predictions based on rich hierarchical and
semantic embeddings from KG. Experiments also demonstrate that DualMAR
outperforms state-of-the-art models, validating its effectiveness in EHR
prediction and KG integration in medical domains.

æè¦ï¼é»å­å¥åº·ç´é (EHR) å·²å¾¹åºæ¹è®äºé«çä¿å¥è³æç®¡çï¼ä¸¦é æ¸¬äºäººå·¥æºæ§åæ©å¨å­¸ç¿é åãæºç¢ºé æ¸¬è¨ºæ·åè¥ç©å¯å¤§å¹æ¸è¼å¥åº·é¢¨éªï¼ä¸¦æä¾é é²æ§ç§è­·çæå°æ¹éãç¶èï¼EHR é©åçæ¨¡åå¨çè§£é«çé åç¥è­ä¸éå¸¸å·æå±éæ§ï¼èä¸å¤§å¤ä¾è³´æ¼ç°¡å®ä¸å®ä¸çæ¬ä½ãæ­¤å¤ï¼ç±æ¼ EHR éºæ¼äºåè½ä¸ç¾çæ¶µèä¸å®æ´ï¼å¤§å¤æ¸ç ç©¶åå°æ³¨æ¼ç¾çåè¥ç©çåºæ¬åæãæåæåº DualMARï¼ä¸åééåäººè§å¯è³æåå¬å±ç¥è­åº«å¢å¼· EHR é æ¸¬ä»»åçæ¶æ§ãé¦åï¼æåä½¿ç¨ç¶éé©è­çå¬å±è¨åºæ¬ä½æ§å»ºä¸åéå±¤ç´è¨ºæ·ç¥è­å (KG)ï¼ä¸¦ééå¤§åèªè¨æ¨¡å (LLM) æ´åéå KGï¼å¶æ¬¡ï¼æåè¨­è¨ä¸åæ°çä»£çä»»åå­¸ç¿ï¼éå° EHR ä¸­çå¯¦é©å®¤çµæé²è¡é è¨ç·´ï¼é²ä¸æ­¥å¢å¼· KG è¡¨ç¤ºåæ£èåµå¥ãééæ·åæ¥µåº§æ¨ç©ºéä¸çå¾ååè§ååæ¨ï¼DualMAR è½å¤ æ ¹æ KG ä¸­è±å¯çå±¤ç´åèªæåµå¥é²è¡æºç¢ºçé æ¸¬ãå¯¦é©ä¹è­æ DualMAR åªæ¼æåé²çæ¨¡åï¼é©è­äºå¶å¨ EHR é æ¸¬åé«çé åä¸­ KG æ´åçæææ§ã

##### **FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**
2410.19727v1 by Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson

Financial intelligence generation from vast data sources has typically relied
on traditional methods of knowledge-graph construction or database engineering.
Recently, fine-tuned financial domain-specific Large Language Models (LLMs),
have emerged. While these advancements are promising, limitations such as high
inference costs, hallucinations, and the complexity of concurrently analyzing
high-dimensional financial data, emerge. This motivates our invention FISHNET
(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,
Expert swarming, and Task planning), an agentic architecture that accomplishes
highly complex analytical tasks for more than 98,000 regulatory filings that
vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows
remarkable performance for financial insight generation (61.8% success rate
over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to
empirically prove the success of FISHNET, each agent's importance, and the
optimized performance of assembling all agents. Our modular architecture can be
leveraged for a myriad of use-cases, enabling scalability, flexibility, and
data integrity that are critical for financial tasks.

æè¦ï¼è²¡åæå ±çæéå¸¸ä¾è³´æ¼å³çµ±çç¥è­åè¡¨å»ºæ§æè³æåº«å·¥ç¨æ¹æ³ï¼éäºæ¹æ³ä¾èªæ¼é¾å¤§çè³æä¾æºãæè¿ï¼éå°è²¡åé åé²è¡å¾®èª¿çå¤§åèªè¨æ¨¡å (LLM) å·²æéèçãåç®¡éäºé²å±ä»¤äººæ¯å¥®ï¼ä½ä»å­å¨ä¸äºéå¶ï¼ä¾å¦é«æ¨çææ¬ãå¹»è¦ºï¼ä»¥ååæåæé«ç¶­åº¦è²¡åè³æçè¤éæ§ãéä¿ä½¿æåç¼æäº FISHNETï¼ä¾èªå­æ¥è©¢ãåèª¿ãç¥ç¶æ¢ä»¶åãå°å®¶ç¾¤éåä»»åè¦åçè²¡åæå ±ï¼ï¼éæ¯ä¸ç¨®ä»£çæ¶æ§ï¼å¯éå°è¶é 98,000 ä»½æ³è¦æä»¶å·è¡é«åº¦è¤éçåæä»»åï¼èéäºæä»¶å¨èªç¾©ãè³æéå±¤ææ ¼å¼æ¹é¢å·®ç°æ¥µå¤§ãFISHNET å¨ç¢çè²¡åè¦è§£æ¹é¢è¡¨ç¾åºè²ï¼æåççº 61.8%ï¼è·¯ç±ççº 5.0%ï¼RAG R-Precision çº 45.6%ï¼ãæåé²è¡äºå´æ ¼çæ¶èï¼ä»¥å¯¦è­è­æ FISHNET çæåãæ¯åä»£ççéè¦æ§ï¼ä»¥åçµè£ææä»£ççæä½³åæè½ãæåæ¨¡çµåçæ¶æ§å¯éç¨æ¼åç¨®ä½¿ç¨æ¡ä¾ï¼æä¾è²¡åä»»åè³ééè¦çå¯æ´åæ§ãå½æ§åè³æå®æ´æ§ã

##### **Knowledge Graph Enhanced Language Agents for Recommendation**
2410.19627v1 by Taicheng Guo, Chaochun Liu, Hai Wang, Varun Mannam, Fang Wang, Xin Chen, Xiangliang Zhang, Chandan K. Reddy

Language agents have recently been used to simulate human behavior and
user-item interactions for recommendation systems. However, current language
agent simulations do not understand the relationships between users and items,
leading to inaccurate user profiles and ineffective recommendations. In this
work, we explore the utility of Knowledge Graphs (KGs), which contain extensive
and reliable relationships between users and items, for recommendation. Our key
insight is that the paths in a KG can capture complex relationships between
users and items, eliciting the underlying reasons for user preferences and
enriching user profiles. Leveraging this insight, we propose Knowledge Graph
Enhanced Language Agents(KGLA), a framework that unifies language agents and KG
for recommendation systems. In the simulated recommendation scenario, we
position the user and item within the KG and integrate KG paths as natural
language descriptions into the simulation. This allows language agents to
interact with each other and discover sufficient rationale behind their
interactions, making the simulation more accurate and aligned with real-world
cases, thus improving recommendation performance. Our experimental results show
that KGLA significantly improves recommendation performance (with a 33%-95%
boost in NDCG@1 among three widely used benchmarks) compared to the previous
best baseline method.

æè¦ï¼èªè¨ä»£çæè¿å·²è¢«ç¨æ¼æ¨¡æ¬äººé¡è¡çºåæ¨è¦ç³»çµ±ä¸­çä½¿ç¨èé ç®äºåãç¶èï¼ç®åçèªè¨ä»£çæ¨¡æ¬ä¸¦æªäºè§£ä½¿ç¨èåé ç®ä¹éçéä¿ï¼å°è´ä½¿ç¨èè¼ªå»ä¸æºç¢ºåæ¨è¦ææä¸ä½³ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºç¥è­åè­ (KG) çæç¨ï¼å¶ä¸­åå«ä½¿ç¨èåé ç®ä¹éå»£æ³ä¸å¯é çéä¿ï¼ä»¥ä¾æ¨è¦ãæåçééµè¦è§£æ¯ï¼KG ä¸­çè·¯å¾å¯ä»¥ææä½¿ç¨èåé ç®ä¹éçè¤ééä¿ï¼å¼åºä½¿ç¨èåå¥½çæ ¹æ¬åå ä¸¦è±å¯ä½¿ç¨èè¼ªå»ãå©ç¨æ­¤è¦è§£ï¼æåæåºäºç¥è­åè­å¢å¼·èªè¨ä»£ç (KGLA)ï¼ä¸åçµ±ä¸èªè¨ä»£çå KG ä»¥ç¨æ¼æ¨è¦ç³»çµ±çæ¶æ§ãå¨æ¨¡æ¬æ¨è¦æå¢ä¸­ï¼æåå°ä½¿ç¨èåé ç®å®ä½å¨ KG ä¸­ï¼ä¸¦å° KG è·¯å¾æ´åçºèªç¶èªè¨æè¿°å°æ¨¡æ¬ä¸­ãéåè¨±èªè¨ä»£çå½¼æ­¤äºåä¸¦ç¼ç¾å¶äºåèå¾çååä¾æï¼ä½¿æ¨¡æ¬æ´æºç¢ºä¸èå¯¦éæ¡ä¾ç¸ç¬¦ï¼å¾èæ¹åæ¨è¦æè½ãæåçå¯¦é©çµæé¡¯ç¤ºï¼èååæä½³åºæºæ¹æ³ç¸æ¯ï¼KGLA å¤§å¹æ¹åäºæ¨è¦æè½ï¼å¨ä¸åå»£æ³ä½¿ç¨çåºæºä¸­ï¼NDCG@1 æåäº 33%-95%ï¼ã

##### **Graph Linearization Methods for Reasoning on Graphs with Large Language Models**
2410.19494v1 by Christos Xypolopoulos, Guokan Shang, Xiao Fei, Giannis Nikolentzos, Hadi Abdine, Iakovos Evdaimon, Michail Chatzianastasis, Giorgos Stamou, Michalis Vazirgiannis

Large language models have evolved to process multiple modalities beyond
text, such as images and audio, which motivates us to explore how to
effectively leverage them for graph machine learning tasks. The key question,
therefore, is how to transform graphs into linear sequences of tokens, a
process we term graph linearization, so that LLMs can handle graphs naturally.
We consider that graphs should be linearized meaningfully to reflect certain
properties of natural language text, such as local dependency and global
alignment, in order to ease contemporary LLMs, trained on trillions of textual
tokens, better understand graphs. To achieve this, we developed several graph
linearization methods based on graph centrality, degeneracy, and node
relabeling schemes. We then investigated their effect on LLM performance in
graph reasoning tasks. Experimental results on synthetic graphs demonstrate the
effectiveness of our methods compared to random linearization baselines. Our
work introduces novel graph representations suitable for LLMs, contributing to
the potential integration of graph machine learning with the trend of
multi-modal processing using a unified transformer model.

æè¦ï¼å¤§åèªè¨æ¨¡åå·²æ¼åçºèçæå­ä¹å¤çå¤ç¨®æ¨¡å¼ï¼ä¾å¦å½±ååé³è¨ï¼éä¿ä½¿æåæ¢ç´¢å¦ä½ææå°éç¨å®åæ¼åå½¢æ©å¨å­¸ç¿ä»»åãå æ­¤ï¼ééµåé¡å¨æ¼å¦ä½å°åå½¢è½æçºç·æ§åºåçä»£å¹£ï¼éæ¯ä¸åæåç¨±çºåå½¢ç·æ§åçéç¨ï¼è® LLM è½èªç¶å°èçåå½¢ãæåèªçºåå½¢æææç¾©å°é²è¡ç·æ§åï¼ä»¥åæ èªç¶èªè¨æå­çç¹å®å±¬æ§ï¼ä¾å¦å±é¨ä¾è³´æ§åå¨å±å°é½ï¼ä»¥ä¾¿è®å¨æ¸ååæå­ä»£å¹£ä¸è¨ç·´çç¶ä»£ LLM æ´è½çè§£åå½¢ãçºéææ­¤ç®çï¼æåéç¼äºå¹¾ç¨®åºæ¼åå½¢ä¸­å¿æ§ãç°¡ä½µæ§åç¯é»éæ°æ¨ç±¤æ¶æ§çåå½¢ç·æ§åæ¹æ³ãæ¥èï¼æåæ¢è¨å®åå° LLM å¨åå½¢æ¨çä»»åä¸­çæè½å½±é¿ãåæåå½¢ä¸çå¯¦é©çµæè­æäºæåçæ¹æ³æ¯é¨æ©ç·æ§ååºæºæ´ææãæåçç ç©¶å¼å¥äºé©å LLM çæ°ç©åå½¢è¡¨ç¤ºæ³ï¼æå©æ¼å°åå½¢æ©å¨å­¸ç¿èä½¿ç¨çµ±ä¸Transformeræ¨¡åçå¤æ¨¡å¼èçè¶¨å¢æ´åèµ·ä¾ã

##### **Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**
2410.19225v1 by Weikai Li, Ding Wang, Zijian Ding, Atefeh Sohrabizadeh, Zongyue Qin, Jason Cong, Yizhou Sun

High-level synthesis (HLS) is a widely used tool in designing Field
Programmable Gate Array (FPGA). HLS enables FPGA design with software
programming languages by compiling the source code into an FPGA circuit. The
source code includes a program (called ``kernel'') and several pragmas that
instruct hardware synthesis, such as parallelization, pipeline, etc. While it
is relatively easy for software developers to design the program, it heavily
relies on hardware knowledge to design the pragmas, posing a big challenge for
software developers. Recently, different machine learning algorithms, such as
GNNs, have been proposed to automate the pragma design via performance
prediction. However, when applying the trained model on new kernels, the
significant domain shift often leads to unsatisfactory performance. We propose
a more domain-generalizable model structure: a two-level hierarchical Mixture
of Experts (MoE), that can be flexibly adapted to any GNN model. Different
expert networks can learn to deal with different regions in the representation
space, and they can utilize similar patterns between the old kernels and new
kernels. In the low-level MoE, we apply MoE on three natural granularities of a
program: node, basic block, and graph. The high-level MoE learns to aggregate
the three granularities for the final decision. To stably train the
hierarchical MoE, we further propose a two-stage training method. Extensive
experiments verify the effectiveness of the hierarchical MoE.

æè¦ï¼é«éç¶åï¼HLSï¼æ¯è¨­è¨ç¾å ´å¯ç·¨ç¨éé£åï¼FPGAï¼ä¸­å»£æ³ä½¿ç¨çå·¥å·ãHLS ééå°åå§ç¢¼ç·¨è­¯æ FPGA é»è·¯ï¼ä½¿ç¨è»é«ç¨å¼èªè¨é²è¡ FPGA è¨­è¨ãåå§ç¢¼åå«ä¸åç¨å¼ï¼ç¨±çºãæ ¸å¿ãï¼åå¤åæå°ç¡¬é«ç¶åçæç¤ºï¼ä¾å¦å¹³è¡åãç®¡ç·ç­ãéç¶è»é«éç¼äººå¡è¨­è¨ç¨å¼ç¸å°å®¹æï¼ä½å®æ¥µåº¦ä¾è³´ç¡¬é«ç¥è­ä¾è¨­è¨æç¤ºï¼éå°è»é«éç¼äººå¡ä¾èªªæ¯ä¸å¤§ææ°ãæè¿ï¼ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³ï¼ä¾å¦ GNNï¼å·²è¢«æåºç¨æ¼ééæè½é æ¸¬èªåé²è¡æç¤ºè¨­è¨ãç¶èï¼å¨æ°çæ ¸å¿ä¸æç¨è¨ç·´å¥½çæ¨¡åæï¼é¡¯èçé åè½ç§»éå¸¸æå°è´æè½ä¸ä½³ãæåæåºä¸åæ´å·é åéç¨æ§çæ¨¡åçµæ§ï¼ä¸åäºéå±¤æ··åå°å®¶ï¼MoEï¼ï¼å®å¯ä»¥éæ´»å°é©æä»»ä½ GNN æ¨¡åãä¸åçå°å®¶ç¶²è·¯å¯ä»¥å­¸ç¿èçè¡¨ç¤ºç©ºéä¸­çä¸åååï¼ä¸¦ä¸å®åå¯ä»¥å©ç¨èæ ¸å¿åæ°æ ¸å¿ä¹éçç¸ä¼¼æ¨¡å¼ãå¨ä½é MoE ä¸­ï¼æåå°ç¨å¼çä¸åèªç¶ç²åº¦æç¨ MoEï¼ç¯é»ãåºæ¬åå¡ååãé«é MoE å­¸ç¿å½ç¸½éä¸åç²åº¦ä»¥ååºæçµæ±ºç­ãçºäºç©©å®è¨ç·´éå±¤å¼ MoEï¼æåé²ä¸æ­¥æåºä¸åäºéæ®µè¨ç·´æ¹æ³ãå»£æ³çå¯¦é©é©è­äºéå±¤å¼ MoE çæææ§ã

##### **Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**
2410.19193v1 by Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes

Disinformation on social media poses both societal and technical challenges.
While previous studies have integrated textual information into propagation
networks, they have yet to fully leverage the advancements in Transformer-based
language models for high-quality contextual text representations. This work
investigates the impact of incorporating textual features into Graph Neural
Networks (GNNs) for fake news detection. Our experiments demonstrate that
contextual representations improve performance by 9.3% in Macro F1 over static
ones and 33.8% over GNNs without textual features. However, noisy data
augmentation degrades performance and increases instability. We expect our
methodology to open avenues for further research, and all code is made publicly
available.

æè¦ï¼ç¤¾ç¾¤åªé«ä¸çé¯èª¤è¨æ¯é æç¤¾æåæè¡å±¤é¢çææ°ã
åç®¡éå¾çç ç©¶å·²å°æå­è³è¨æ´åå°å³æ­ç¶²è·¯ä¸­ï¼ä½å°æªååå©ç¨åºæ¼ Transformer çèªè¨æ¨¡åå¨é«åè³ªèçµ¡æå­è¡¨å¾µä¸çé²å±ãéé ç ç©¶æ¢è¨å°æå­ç¹å¾µç´å¥åå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¸­å°æ¼åæ°èåµæ¸¬çå½±é¿ãæåçå¯¦é©çµæé¡¯ç¤ºï¼èçµ¡è¡¨å¾µå°å·¨è§ F1 çæè½æåäº 9.3%ï¼åªæ¼éæè¡¨å¾µï¼ä¸¦æ¯æ²ææå­ç¹å¾µç GNN æåäº 33.8%ãç¶èï¼æéè¨çè³ææ´åæéä½æè½ä¸¦å¢å ä¸ç©©å®æ§ãæåé ææåçç ç©¶æ¹æ³å°éåé²ä¸æ­¥ç ç©¶çéå¾ï¼ææç¨å¼ç¢¼çå¬éæä¾ã

##### **GCoder: Improving Large Language Model for Generalized Graph Problem Solving**
2410.19084v1 by Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li

Large Language Models (LLMs) have demonstrated strong reasoning abilities,
making them suitable for complex tasks such as graph computation. Traditional
reasoning steps paradigm for graph problems is hindered by unverifiable steps,
limited long-term reasoning, and poor generalization to graph variations. To
overcome these limitations, we introduce GCoder, a code-based LLM designed to
enhance problem-solving in generalized graph computation problems. Our method
involves constructing an extensive training dataset, GraphWild, featuring
diverse graph formats and algorithms. We employ a multi-stage training process,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning from Compiler
Feedback (RLCF), to refine model capabilities. For unseen tasks, a hybrid
retrieval technique is used to augment performance. Experiments demonstrate
that GCoder outperforms GPT-4o, with an average accuracy improvement of 16.42%
across various graph computational problems. Furthermore, GCoder efficiently
manages large-scale graphs with millions of nodes and diverse input formats,
overcoming the limitations of previous models focused on the reasoning steps
paradigm. This advancement paves the way for more intuitive and effective graph
problem-solving using LLMs. Code and data are available at here:
https://github.com/Bklight999/WWW25-GCoder/tree/master.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¼·å¤§çæ¨çè½åï¼ä½¿å¶é©ç¨æ¼è¤éä»»åï¼ä¾å¦åå½¢éç®ãå³çµ±åå½¢åé¡çæ¨çæ­¥é©ç¯ä¾åå°ä¸å¯é©è­çæ­¥é©ãæéçé·ææ¨çåå°åå½¢è®åçæ¦æ¬æ§ä¸ä½³çé»ç¤ãçºäºåæéäºéå¶ï¼æåå¼å¥äº GCoderï¼ä¸ç¨®åºæ¼ä»£ç¢¼ç LLMï¼æ¨å¨å¢å¼·å»£ç¾©åå½¢éç®åé¡ä¸­çåé¡è§£æ±ºè½åãæåçæè¡æ¶åæ§å»ºä¸åå»£æ³çè¨ç·´è³æé GraphWildï¼å¶ä¸­åå«å¤æ¨£çåå½¢æ ¼å¼åæ¼ç®æ³ãæåæ¡ç¨å¤éæ®µè¨ç·´æµç¨ï¼åæ¬ç£ç£å¾®èª¿ (SFT) åç·¨è­¯å¨åé¥å¼·åå­¸ç¿ (RLCF)ï¼ä»¥æ¹åæ¨¡åè½åãå°æ¼æªç¥ä»»åï¼ä½¿ç¨æ··åæ·åæè¡ä¾å¢å¼·æè½ãå¯¦é©è­æï¼GCoder åªæ¼ GPT-4oï¼å¨åç¨®åå½¢éç®åé¡ä¸­å¹³åæºç¢ºåº¦æåäº 16.42%ãæ­¤å¤ï¼GCoder ææå°ç®¡çèæææ¸ç¾è¬åç¯é»åå¤æ¨£è¼¸å¥æ ¼å¼çå¤§è¦æ¨¡åå½¢ï¼åæäºååå°æ³¨æ¼æ¨çæ­¥é©ç¯ä¾çæ¨¡åçéå¶ãéé é²å±çºä½¿ç¨ LLM é²è¡æ´ç´è§ä¸ææçåå½¢åé¡è§£æ±ºéªå¹³äºéè·¯ãç¨å¼ç¢¼åè³æå¯æ¼æ­¤èåå¾ï¼https://github.com/Bklight999/WWW25-GCoder/tree/masterã

##### **LLM-based Online Prediction of Time-varying Graph Signals**
2410.18718v1 by Dayu Qin, Yi Yan, Ercan Engin Kuruoglu

In this paper, we propose a novel framework that leverages large language
models (LLMs) for predicting missing values in time-varying graph signals by
exploiting spatial and temporal smoothness. We leverage the power of LLM to
achieve a message-passing scheme. For each missing node, its neighbors and
previous estimates are fed into and processed by LLM to infer the missing
observations. Tested on the task of the online prediction of wind-speed graph
signals, our model outperforms online graph filtering algorithms in terms of
accuracy, demonstrating the potential of LLMs in effectively addressing
partially observed signals in graphs.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çæ¡æ¶ï¼è©²æ¡æ¶å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾é æ¸¬æè®åå½¢ä¿¡èä¸­çç¼ºå¤±å¼ï¼æ¹æ³æ¯å©ç¨ç©ºéåæéå¹³æ»åº¦ãæåå©ç¨ LLM çè½åä¾å¯¦ç¾æ¶æ¯å³éæ¹æ¡ãå°æ¼æ¯åç¼ºå¤±ç¯é»ï¼å¶é°å±åååçä¼°è¨å¼æè¢«è¼¸å¥å° LLM ä¸­ä¸¦ç± LLM é²è¡èçï¼ä»¥æ¨æ·åºç¼ºå¤±çè§æ¸¬å¼ãå¨é¢¨éåå½¢ä¿¡èçç·ä¸é æ¸¬ä»»åä¸­é²è¡æ¸¬è©¦ï¼æåçæ¨¡åå¨æºç¢ºæ§æ¹é¢åªæ¼ç·ä¸åå½¢éæ¿¾æ¼ç®æ³ï¼éè­æäº LLM å¨ææèçåå½¢ä¸­é¨åè§æ¸¬å°çä¿¡èæ¹é¢çæ½åã

##### **Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**
2410.18475v2 by Kexuan Xin, Qingyun Wang, Junyu Chen, Pengfei Yu, Huimin Zhao, Heng Ji

In the rapidly evolving field of metabolic engineering, the quest for
efficient and precise gene target identification for metabolite production
enhancement presents significant challenges. Traditional approaches, whether
knowledge-based or model-based, are notably time-consuming and labor-intensive,
due to the vast scale of research literature and the approximation nature of
genome-scale metabolic model (GEM) simulations. Therefore, we propose a new
task, Gene-Metabolite Association Prediction based on metabolic graphs, to
automate the process of candidate gene discovery for a given pair of metabolite
and candidate-associated genes, as well as presenting the first benchmark
containing 2474 metabolites and 1947 genes of two commonly used microorganisms
Saccharomyces cerevisiae (SC) and Issatchenkia orientalis (IO). This task is
challenging due to the incompleteness of the metabolic graphs and the
heterogeneity among distinct metabolisms. To overcome these limitations, we
propose an Interactive Knowledge Transfer mechanism based on Metabolism Graph
(IKT4Meta), which improves the association prediction accuracy by integrating
the knowledge from different metabolism graphs. First, to build a bridge
between two graphs for knowledge transfer, we utilize Pretrained Language
Models (PLMs) with external knowledge of genes and metabolites to help generate
inter-graph links, significantly alleviating the impact of heterogeneity.
Second, we propagate intra-graph links from different metabolic graphs using
inter-graph links as anchors. Finally, we conduct the gene-metabolite
association prediction based on the enriched metabolism graphs, which integrate
the knowledge from multiple microorganisms. Experiments on both types of
organisms demonstrate that our proposed methodology outperforms baselines by up
to 12.3% across various link prediction frameworks.

æè¦ï¼<paragraph>å¨å¿«éç¼å±çä»£è¬å·¥ç¨é åä¸­ï¼å°æ±ææä¸ç²¾ç¢ºçåºå ç®æ¨è­å¥ä»¥æåä»£è¬ç¢ç©ç¢éï¼æ¯ä¸é éå¤§çææ°ãå³çµ±æ¹æ³ï¼ç¡è«æ¯åºæ¼ç¥è­æåºæ¼æ¨¡åï¼é½ç¸ç¶èæä¸è²»åï¼éæ¯å çºç ç©¶æç»çè¦æ¨¡é¾å¤§ï¼ä¸åºå çµè¦æ¨¡ä»£è¬æ¨¡å (GEM) æ¨¡æ¬çè¿ä¼¼æ§è³ªãå æ­¤ï¼æåæåºäºä¸é æ°çä»»åï¼å³åºæ¼ä»£è¬åçåºå -ä»£è¬ç©éè¯é æ¸¬ï¼ä»¥èªåååé¸åºå ç¼ç¾çéç¨ï¼éå°çµ¦å®çä»£è¬ç©å°ååé¸ç¸éåºå ï¼ä¸¦åç¾ç¬¬ä¸ååºæºï¼å¶ä¸­åå« 2474 ç¨®ä»£è¬ç©å 1947 ååºå ï¼ä¾èªå©ç¨®å¸¸ç¨çå¾®çç©éééµæ¯ (SC) åæ±æ¹ä¼è©ç´ç§éµæ¯ (IO)ãç±æ¼ä»£è¬åçä¸å®æ´æ§åä¸åä»£è¬ç©ä¹éçç°è³ªæ§ï¼éé ä»»åå·æææ°æ§ãçºäºåæéäºéå¶ï¼æåæåºäºä¸ååºæ¼ä»£è¬åçäºåç¥è­å³è¼¸æ©å¶ (IKT4Meta)ï¼å®ééæ´åä¾èªä¸åä»£è¬åçç¥è­ä¾æé«éè¯é æ¸¬çæºç¢ºæ§ãé¦åï¼çºäºå¨å©ååä¹éå»ºç«ç¥è­å³è¼¸çæ©æ¨ï¼æåå©ç¨å·ååºå åä»£è¬ç©å¤é¨ç¥è­çé è¨ç·´èªè¨æ¨¡å (PLM) ä¾å¹«å©ç¢çåéé£çµï¼å¤§å¹æ¸è¼ç°è³ªæ§çå½±é¿ãå¶æ¬¡ï¼æåä½¿ç¨åéé£çµä½çºé¨é»ï¼å¾ä¸åçä»£è¬åå³æ­åå§é£çµãæå¾ï¼æåæ ¹ææ´åäºå¤ç¨®å¾®çç©ç¥è­çè±å¯ä»£è¬åï¼é²è¡åºå -ä»£è¬ç©éè¯é æ¸¬ãå©ç¨®çç©é«çå¯¦é©é½è­æï¼æåæåºçæ¹æ³å¨åç¨®é£çµé æ¸¬æ¶æ§ä¸­ï¼æ¯åºæºé«åº 12.3%ã</paragraph>

##### **ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**
2410.18447v1 by Zezhong Wang, Xingshan Zeng, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong

Supervised fine-tuning (SFT) is a common method to enhance the tool calling
capabilities of Large Language Models (LLMs), with the training data often
being synthesized. The current data synthesis process generally involves
sampling a set of tools, formulating a requirement based on these tools, and
generating the call statements. However, tools sampled randomly lack relevance,
making them difficult to combine and thus reducing the diversity of the data.
Additionally, current work overlooks the coherence between turns of dialogues,
leading to a gap between the synthesized data and real-world scenarios. To
address these issues, we propose a Graph-based Sampling strategy to sample more
relevant tool combinations, and a Planned-generation strategy to create plans
that guide the synthesis of coherent dialogues. We integrate these two
strategies and enable multiple agents to synthesize the dialogue data
interactively, resulting in our tool-calling data synthesis pipeline ToolFlow.
Data quality assessments demonstrate improvements in the naturalness and
coherence of our synthesized dialogues. Finally, we apply SFT on LLaMA-3.1-8B
using 8,000 synthetic dialogues generated with ToolFlow. Results show that the
model achieves tool-calling performance comparable to or even surpassing GPT-4,
while maintaining strong general capabilities.

æè¦ï¼ç£ç£å¾®èª¿ (SFT) æ¯å¢å¼·å¤§åèªè¨æ¨¡å (LLM) å·¥å·å¼å«åè½çå¸¸è¦æ¹æ³ï¼è¨ç·´è³æéå¸¸æ¯åæè³æãç®åçè³æåææµç¨éå¸¸æ¶åæ½æ¨£ä¸çµå·¥å·ãæ ¹æéäºå·¥å·å¶å®éæ±ï¼ä¸¦ç¢çå¼å«é³è¿°ãç¶èï¼é¨æ©æ½æ¨£çå·¥å·ç¼ºä¹éè¯æ§ï¼ä½¿å¾å®åé£ä»¥çµåï¼å¾èéä½è³æçå¤æ¨£æ§ãæ­¤å¤ï¼ç®åçå·¥ä½å¿½ç¥äºå°è©±ååä¹éçé£è²«æ§ï¼å°è´åæè³æèç¾å¯¦ä¸çå ´æ¯ä¹éå­å¨å·®è·ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ååºæ¼åå½¢çæ½æ¨£ç­ç¥ä¾æ½åæ´å¤ç¸éçå·¥å·çµåï¼ä»¥åä¸åè¨ç«çæç­ç¥ä¾å»ºç«è¨ç«ï¼ä»¥å¼å°é£è²«å°è©±çåæãæåæ´åéå©ç¨®ç­ç¥ï¼ä¸¦ä½¿å¤åä»£çè½å¤ äºåå°åæå°è©±è³æï¼å¾èç¢çæåçå·¥å·å¼å«è³æåæç®¡ç· ToolFlowãè³æåè³ªè©ä¼°è­æäºæååæå°è©±çèªç¶æ§åé£è²«æ§æäºæ¹é²ãæå¾ï¼æåä½¿ç¨ ToolFlow çæç 8,000 ååæå°è©±å¨ LLaMA-3.1-8B ä¸æç¨ SFTãçµæè¡¨æï¼è©²æ¨¡åå¯¦ç¾äºè GPT-4 ç¸ç¶çè³è¶è¶ GPT-4 çå·¥å·å¼å«æè½ï¼åæä¿æå¼·å¤§çéç¨è½åã

##### **Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**
2410.18415v1 by Kun Li, Tianhua Zhang, Xixin Wu, Hongyin Luo, James Glass, Helen Meng

Knowledge Graphs (KGs) can serve as reliable knowledge sources for question
answering (QA) due to their structured representation of knowledge. Existing
research on the utilization of KG for large language models (LLMs) prevalently
relies on subgraph retriever or iterative prompting, overlooking the potential
synergy of LLMs' step-wise reasoning capabilities and KGs' structural nature.
In this paper, we present DoG (Decoding on Graphs), a novel framework that
facilitates a deep synergy between LLMs and KGs. We first define a concept,
well-formed chain, which consists of a sequence of interrelated fact triplets
on the KGs, starting from question entities and leading to answers. We argue
that this concept can serve as a principle for making faithful and sound
reasoning for KGQA. To enable LLMs to generate well-formed chains, we propose
graph-aware constrained decoding, in which a constraint derived from the
topology of the KG regulates the decoding process of the LLMs. This constrained
decoding method ensures the generation of well-formed chains while making full
use of the step-wise reasoning capabilities of LLMs. Based on the above, DoG, a
training-free approach, is able to provide faithful and sound reasoning
trajectories grounded on the KGs. Experiments across various KGQA tasks with
different background KGs demonstrate that DoG achieves superior and robust
performance. DoG also shows general applicability with various open-source
LLMs.

æè¦ï¼ç¥è­åè­ (KG) ç±æ¼å¶çµæ§åçç¥è­è¡¨ç¤ºï¼å¯ç¨ä½åç­ (QA) çå¯é ç¥è­ä¾æºãç¾æéæ¼å©ç¨ KG çå¤§åèªè¨æ¨¡å (LLM) çç ç©¶æ®éä¾è³´æ¼å­åæª¢ç´¢å¨æåè¦æç¤ºï¼å¿½è¦äº LLM çéæ­¥æ¨çè½åå KG ççµæ§ç¹æ§çæ½å¨ååä½ç¨ãå¨æ¬æä¸­ï¼æåæåºäº DoGï¼åå½¢è§£ç¢¼ï¼ï¼ä¸åä¿é² LLM å KG ä¹éæ·±åº¦ååä½ç¨çæ°æ¡æ¶ãæåé¦åå®ç¾©äºä¸åæ¦å¿µï¼å³è¯å¥½å½¢æçéï¼å®ç± KG ä¸ä¸ç³»åç¸äºéè¯çäºå¯¦ä¸åçµçµæï¼å¾åé¡å¯¦é«éå§ä¸¦å°è´ç­æ¡ãæåèªçºéåæ¦å¿µå¯ä»¥ä½çºå° KGQA é²è¡å¿ å¯¦ååççæ¨ççååãçºäºä½¿ LLM è½å¤ çæè¯å¥½çéï¼æåæåºäºåæç¥ç´æè§£ç¢¼ï¼å¶ä¸­æºèª KG ææ²çç´æç´æäº LLM çè§£ç¢¼éç¨ãéç¨®åç´æçè§£ç¢¼æ¹æ³ç¢ºä¿äºè¯å¥½å½¢æçéççæï¼åæååå©ç¨äº LLM çéæ­¥æ¨çè½åãåºæ¼ä¸è¿°ï¼DoG æ¯ä¸ç¨®ç¡éè¨ç·´çæ¹æ³ï¼è½å¤ æä¾åºæ¼ KG çå¿ å¯¦ä¸åççæ¨çè»è·¡ãå¨å·æä¸åèæ¯ KG çåç¨® KGQA ä»»åä¸­çå¯¦é©è¡¨æï¼DoG éå°äºåè¶ä¸ç©©å¥çæ§è½ãDoG éé¡¯ç¤ºäºèåç¨®éæº LLM çéç¨é©ç¨æ§ã

##### **Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**
2410.18060v1 by Jaime Sevilla, Nikolay Babakov, Ehud Reiter, Alberto Bugarin

In this paper, we propose a model for building natural language explanations
for Bayesian Network Reasoning in terms of factor arguments, which are
argumentation graphs of flowing evidence, relating the observed evidence to a
target variable we want to learn about. We introduce the notion of factor
argument independence to address the outstanding question of defining when
arguments should be presented jointly or separately and present an algorithm
that, starting from the evidence nodes and a target node, produces a list of
all independent factor arguments ordered by their strength. Finally, we
implemented a scheme to build natural language explanations of Bayesian
Reasoning using this approach. Our proposal has been validated in the medical
domain through a human-driven evaluation study where we compare the Bayesian
Network Reasoning explanations obtained using factor arguments with an
alternative explanation method. Evaluation results indicate that our proposed
explanation approach is deemed by users as significantly more useful for
understanding Bayesian Network Reasoning than another existing explanation
method it is compared to.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸åæ¨¡åï¼ç¨æ¼å»ºæ§è²æ°ç¶²è·¯æ¨ççèªç¶èªè¨è§£éï¼ä»¥å å­è«è­çºåºç¤ï¼å®åæ¯æµåè­æçè«è­åï¼å°è§å¯å°çè­æèæåæ³è¦äºè§£çç®æ¨è®æ¸è¯ç¹«èµ·ä¾ãæåå¼å¥äºå å­è«è­ç¨ç«æ§çæ¦å¿µï¼ä»¥è§£æ±ºå®ç¾©ä½ææå°è«è­è¯åæå®ç¨åç¾çæªæ±ºåé¡ï¼ä¸¦æåºäºä¸ç¨®æ¼ç®æ³ï¼å¾è­æç¯é»åç®æ¨ç¯é»éå§ï¼ç¢çä¸åæå¼·åº¦æåºçææç¨ç«å å­è«è­æ¸å®ãæå¾ï¼æåå¯¦ä½äºä¸åæ¹æ¡ï¼ä½¿ç¨éç¨®æ¹æ³å»ºæ§è²æ°æ¨ççèªç¶èªè¨è§£éãæåçææ¡å·²å¨é«å­¸é åä¸­ééäººçºé©åçè©ä¼°ç ç©¶å¾å°é©è­ï¼å¨è©²ç ç©¶ä¸­ï¼æåå°ä½¿ç¨å å­è«è­ç²å¾çè²æ°ç¶²è·¯æ¨çè§£éèå¦ä¸ç¨®è§£éæ¹æ³é²è¡æ¯è¼ãè©ä¼°çµæè¡¨æï¼èå¦ä¸ç¨®ç¾æçè§£éæ¹æ³ç¸æ¯ï¼æåçæè­°è§£éæ¹æ³è¢«ä½¿ç¨èè¦çºé¡¯èæ´æå©æ¼çè§£è²æ°ç¶²è·¯æ¨çã</paragraph>

##### **Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**
2410.17600v1 by Rui Yang, Boming Yang, Aosong Feng, Sixun Ouyang, Moritz Blum, Tianwei She, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge Graphs (KGs) are crucial in the field of artificial intelligence
and are widely used in downstream tasks, such as question-answering (QA). The
construction of KGs typically requires significant effort from domain experts.
Large Language Models (LLMs) have recently been used for Knowledge Graph
Construction (KGC). However, most existing approaches focus on a local
perspective, extracting knowledge triplets from individual sentences or
documents, missing a fusion process to combine the knowledge in a global KG.
This work introduces Graphusion, a zero-shot KGC framework from free text. It
contains three steps: in Step 1, we extract a list of seed entities using topic
modeling to guide the final KG includes the most relevant entities; in Step 2,
we conduct candidate triplet extraction using LLMs; in Step 3, we design the
novel fusion module that provides a global view of the extracted knowledge,
incorporating entity merging, conflict resolution, and novel triplet discovery.
Results show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for
entity extraction and relation recognition, respectively. Moreover, we showcase
how Graphusion could be applied to the Natural Language Processing (NLP) domain
and validate it in an educational scenario. Specifically, we introduce TutorQA,
a new expert-verified benchmark for QA, comprising six tasks and a total of
1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant
improvement on the benchmark, for example, a 9.2% accuracy improvement on
sub-graph completion.

æè¦ï¼<paragraph>ç¥è­åè­ (KG) å¨äººå·¥æºæ§é åè³ééè¦ï¼å»£æ³ç¨æ¼ä¸æ¸¸ä»»åï¼ä¾å¦åç­ (QA)ãKG çå»ºæ§éå¸¸éè¦é åå°å®¶ä»åºå¤§éå¿åãå¤§åèªè¨æ¨¡å (LLM) è¿ä¾å·²ç¨æ¼ç¥è­åè­å»ºæ§ (KGC)ãç¶èï¼ç¾ææ¹æ³å¤§å¤èéæ¼å±é¨è§é»ï¼å¾åå¥å¥å­ææä»¶æ·åç¥è­ä¸åçµï¼ç¼ºå°ä¸åèåç¨åºä¾å°ç¥è­çµåå¨ä¸åæ´é« KG ä¸­ãæ¬ç ç©¶å¼å¥äº Graphusionï¼ä¸åå¾èªç±æå­é²è¡é¶æ¬¡å­¸ç¿ç KGC æ¡æ¶ãå®åå«ä¸åæ­¥é©ï¼å¨æ­¥é© 1 ä¸­ï¼æåä½¿ç¨ä¸»é¡å»ºæ¨¡æ·åä¸çµç¨®å­å¯¦é«ï¼ä»¥å¼å°æçµç KG ç´å¥æç¸éçå¯¦é«ï¼å¨æ­¥é© 2 ä¸­ï¼æåä½¿ç¨ LLM é²è¡åé¸ä¸åçµæ·åï¼å¨æ­¥é© 3 ä¸­ï¼æåè¨­è¨äºæ°ç©çèåæ¨¡çµï¼æä¾æ·åç¥è­çæ´é«è§é»ï¼åå«å¯¦é«åä½µãè¡çªè§£æ±ºåæ°ä¸åçµç¼ç¾ãçµæé¡¯ç¤º Graphusion å¨å¯¦é«æ·ååéä¿è­å¥æ¹é¢åå¥ç²å¾ 3 åä¸­ç 2.92 åå 2.37 åãæ­¤å¤ï¼æåå±ç¤ºäº Graphusion å¦ä½æç¨æ¼èªç¶èªè¨èç (NLP) é åï¼ä¸¦å¨æè²æå¢ä¸­é©è­å®ãå·é«ä¾èªªï¼æåå¼å¥äº TutorQAï¼ä¸åç±å°å®¶é©è­çæ°å QA åºæºï¼åå«å­é ä»»ååç¸½è¨ 1,200 çµ QAãä½¿ç¨ Graphusion å»ºæ§ç KGï¼æåå¨åºæºä¸åå¾é¡¯èé²æ­¥ï¼ä¾å¦ï¼å¨å­åå®ææ¹é¢æåäº 9.2% çæºç¢ºåº¦ã</paragraph>

##### **Navigate Complex Physical Worlds via Geometrically Constrained LLM**
2410.17529v1 by Yongqiang Huang, Wentao Ye, Liyao Li, Junbo Zhao

This study investigates the potential of Large Language Models (LLMs) for
reconstructing and constructing the physical world solely based on textual
knowledge. It explores the impact of model performance on spatial understanding
abilities. To enhance the comprehension of geometric and spatial relationships
in the complex physical world, the study introduces a set of geometric
conventions and develops a workflow based on multi-layer graphs and multi-agent
system frameworks. It examines how LLMs achieve multi-step and multi-objective
geometric inference in a spatial environment using multi-layer graphs under
unified geometric conventions. Additionally, the study employs a genetic
algorithm, inspired by large-scale model knowledge, to solve geometric
constraint problems. In summary, this work innovatively explores the
feasibility of using text-based LLMs as physical world builders and designs a
workflow to enhance their capabilities.

æè¦ï¼æ¬ç ç©¶æ¢è¨å¤§åèªè¨æ¨¡å (LLM) ååºæ¼æå­ç¥è­éå»ºåå»ºæ§ç©çä¸ççæ½åãæ¢è¨æ¨¡åæè½å°ç©ºéçè§£è½åçå½±é¿ãçºäºå¢å¼·å°è¤éç©çä¸çä¸­å¹¾ä½åç©ºééä¿ççè§£ï¼æ¬ç ç©¶å¼å¥äºä¸çµå¹¾ä½æ£ä¾ï¼ä¸¦åºæ¼å¤å±¤åå½¢åå¤ä»£çç³»çµ±æ¶æ§éç¼äºä¸å¥å·¥ä½æµç¨ãç ç©¶æ¢è¨äº LLM å¦ä½å¨çµ±ä¸çå¹¾ä½æ£ä¾ä¸ï¼ä½¿ç¨å¤å±¤åå½¢å¨ç©ºéç°å¢ä¸­éæå¤æ­¥é©åå¤ç®æ¨çå¹¾ä½æ¨è«ãæ­¤å¤ï¼æ¬ç ç©¶æ¡ç¨åå¤§åæ¨¡åç¥è­åç¼çéºå³æ¼ç®æ³ä¾è§£æ±ºå¹¾ä½ç´æåé¡ãç¸½ä¹ï¼éé å·¥ä½åµæ°å°æ¢è¨äºä½¿ç¨åºæ¼æå­ç LLM ä½çºç©çä¸çå»ºæ§èçå¯è¡æ§ï¼ä¸¦è¨­è¨äºä¸å¥å·¥ä½æµç¨ä¾å¢å¼·å¶è½åã

##### **Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs**
2410.16882v1 by Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Tyler Derr

Node classification on graphs frequently encounters the challenge of class
imbalance, leading to biased performance and posing significant risks in
real-world applications. Although several data-centric solutions have been
proposed, none of them focus on Text-Attributed Graphs (TAGs), and therefore
overlook the potential of leveraging the rich semantics encoded in textual
features for boosting the classification of minority nodes. Given this crucial
gap, we investigate the possibility of augmenting graph data in the text space,
leveraging the textual generation power of Large Language Models (LLMs) to
handle imbalanced node classification on TAGs. Specifically, we propose a novel
approach called LA-TAG (LLM-based Augmentation on Text-Attributed Graphs),
which prompts LLMs to generate synthetic texts based on existing node texts in
the graph. Furthermore, to integrate these synthetic text-attributed nodes into
the graph, we introduce a text-based link predictor to connect the synthesized
nodes with the existing nodes. Our experiments across multiple datasets and
evaluation metrics show that our framework significantly outperforms
traditional non-textual-based data augmentation strategies and specific node
imbalance solutions. This highlights the promise of using LLMs to resolve
imbalance issues on TAGs.

æè¦ï¼åå½¢ç¯é»åé¡ç¶å¸¸æéå°é¡å¥ä¸å¹³è¡¡çææ°ï¼å°è´æåå·®çæè½ï¼ä¸¦å¨å¯¦éæç¨ä¸­é æé¡¯èé¢¨éªãåç®¡å·²æåºå¤é ä»¥è³æçºä¸­å¿çè§£æ±ºæ¹æ¡ï¼ä½æ²æä¸é å°æ³¨æ¼æå­å±¬æ§åå½¢ (TAG)ï¼å æ­¤å¿½ç¥äºå©ç¨æå­ç¹å¾µä¸­ç·¨ç¢¼çè±å¯èªæä¾æåå°æ¸ç¯é»åé¡çå¯è½æ§ãéæ¼éåééµå·®è·ï¼æåæ¢è¨äºå¨æå­ç©ºéä¸­æ´ååå½¢è³æçå¯è½æ§ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) çæå­ç¢çè½åä¾èç TAG ä¸çä¸å¹³è¡¡ç¯é»åé¡ãå·é«ä¾èªªï¼æåæåºäºä¸ç¨®åçº LA-TAGï¼åºæ¼ LLM çæå­å±¬æ§åå½¢æ´åï¼çæ°æ¹æ³ï¼å®æç¤º LLM æ ¹æåå½¢ä¸­ç¾æçç¯é»æå­ç¢çåææå­ãæ­¤å¤ï¼çºäºå°éäºåææå­å±¬æ§ç¯é»æ´åå°åå½¢ä¸­ï¼æåå¼å¥äºä¸ååºæ¼æå­çé£çµé æ¸¬å¨ï¼ä»¥å°åæç¯é»èç¾æç¯é»é£æ¥èµ·ä¾ãæåå¨å¤åè³æéåè©ä¼°ææ¨ä¸çå¯¦é©è¡¨æï¼æåçæ¡æ¶æé¡¯åªæ¼å³çµ±çéæå­è³ææ´åç­ç¥åç¹å®çç¯é»ä¸å¹³è¡¡è§£æ±ºæ¹æ¡ãéçªé¡¯äºä½¿ç¨ LLM ä¾è§£æ±º TAG ä¸çä¸å¹³è¡¡åé¡çæ½åã

##### **Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning**
2410.16803v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Zixing Song, Xuhui Jiang, Jian Guo, Ho-fung Leung, Irwin King

Inductive knowledge graph completion (KGC) aims to predict missing triples
with unseen entities. Recent works focus on modeling reasoning paths between
the head and tail entity as direct supporting evidence. However, these methods
depend heavily on the existence and quality of reasoning paths, which limits
their general applicability in different scenarios. In addition, we observe
that latent type constraints and neighboring facts inherent in KGs are also
vital in inferring missing triples. To effectively utilize all useful
information in KGs, we introduce CATS, a novel context-aware inductive KGC
solution. With sufficient guidance from proper prompts and supervised
fine-tuning, CATS activates the strong semantic understanding and reasoning
capabilities of large language models to assess the existence of query triples,
which consist of two modules. First, the type-aware reasoning module evaluates
whether the candidate entity matches the latent entity type as required by the
query relation. Then, the subgraph reasoning module selects relevant reasoning
paths and neighboring facts, and evaluates their correlation to the query
triple. Experiment results on three widely used datasets demonstrate that CATS
significantly outperforms state-of-the-art methods in 16 out of 18
transductive, inductive, and few-shot settings with an average absolute MRR
improvement of 7.2%.

æè¦ï¼æ­¸ç´ç¥è­åè­å®æ (KGC) æ¨å¨é æ¸¬å·ææªè¦å¯¦é«çç¼ºå¤±ä¸åçµãæè¿çå·¥ä½éé»å¨æ¼å»ºæ¨¡é ­å¯¦é«åå°¾å¯¦é«ä¹éçæ¨çè·¯å¾ä½çºç´æ¥æ¯æè­æãç¶èï¼éäºæ¹æ³é«åº¦ä¾è³´æ¨çè·¯å¾çå­å¨ååè³ªï¼ééå¶äºå®åå¨ä¸åå ´æ¯ä¸­çæ®éé©ç¨æ§ãæ­¤å¤ï¼æåè§å¯å°é±èé¡åç´æå KG ä¸­åºæçé°è¿äºå¯¦å°æ¼æ¨æ·ç¼ºå¤±ä¸åçµä¹è³ééè¦ãçºäºææå©ç¨ KG ä¸­æææç¨çè³è¨ï¼æåå¼å¥äº CATSï¼ä¸ç¨®æ°ç©çå·åæå¢æç¥è½åçæ­¸ç´å¼ KGC è§£å³æ¹æ¡ãå¨é©ç¶æç¤ºåç£ç£å¾®èª¿çååæå°ä¸ï¼CATS ååå¤§åèªè¨æ¨¡åå¼·å¤§çèªç¾©çè§£åæ¨çè½åï¼ä»¥è©ä¼°æ¥è©¢ä¸åçµçå­å¨ï¼å¶ä¸­åå«å©åæ¨¡çµãé¦åï¼é¡åæç¥æ¨çæ¨¡çµè©ä¼°åé¸å¯¦é«æ¯å¦èæ¥è©¢éä¿æéçé±èå¯¦é«é¡åç¸ç¬¦ãç¶å¾ï¼å­åæ¨çæ¨¡çµé¸æç¸éæ¨çè·¯å¾åé°è¿äºå¯¦ï¼ä¸¦è©ä¼°å®åèæ¥è©¢ä¸åçµçéè¯æ§ãå¨ä¸åå»£æ³ä½¿ç¨çè³æéä¸é²è¡çå¯¦é©çµæè¡¨æï¼å¨ 18 åè½å°ãæ­¸ç´åå°æ¬¡åè©¦è¨­å®ä¸­ï¼CATS å¨ 16 åè¨­å®ä¸­é¡¯èåªæ¼æåé²çæ¹æ³ï¼å¹³åçµå° MRR æåäº 7.2%ã

##### **The Scene Language: Representing Scenes with Programs, Words, and Embeddings**
2410.16770v1 by Yunzhi Zhang, Zizhang Li, Matt Zhou, Shangzhe Wu, Jiajun Wu

We introduce the Scene Language, a visual scene representation that concisely
and precisely describes the structure, semantics, and identity of visual
scenes. It represents a scene with three key components: a program that
specifies the hierarchical and relational structure of entities in the scene,
words in natural language that summarize the semantic class of each entity, and
embeddings that capture the visual identity of each entity. This representation
can be inferred from pre-trained language models via a training-free inference
technique, given text or image inputs. The resulting scene can be rendered into
images using traditional, neural, or hybrid graphics renderers. Together, this
forms a robust, automated system for high-quality 3D and 4D scene generation.
Compared with existing representations like scene graphs, our proposed Scene
Language generates complex scenes with higher fidelity, while explicitly
modeling the scene structures to enable precise control and editing.

æè¦ï¼æåå¼å¥äºå ´æ¯èªè¨ï¼éæ¯ä¸ç¨®è¦è¦ºå ´æ¯è¡¨ç¤ºæ³ï¼ç°¡æ½ä¸ç²¾ç¢ºå°æè¿°äºè¦è¦ºå ´æ¯ççµæ§ãèªæåèº«åãå®ä½¿ç¨ä¸åééµçµæé¨åä¾è¡¨ç¤ºå ´æ¯ï¼ä¸åç¨å¼ï¼ç¨æ¼æå®å ´æ¯ä¸­å¯¦é«çéå±¤åéä¿çµæ§ï¼ä»¥èªç¶èªè¨è¡¨ç¤ºçè©å½ï¼ç¨æ¼ç¸½çµæ¯åå¯¦é«çèªæé¡å¥ï¼ä»¥åç¨æ¼æ·åæ¯åå¯¦é«çè¦è¦ºèº«åçåµå¥ãéåè¡¨ç¤ºæ³å¯ä»¥ééç¡è¨ç·´æ¨è«æè¡å¾é åè¨ç·´çèªè¨æ¨¡åæ¨è«åºä¾ï¼çµ¦å®æå­æå½±åè¼¸å¥ãç¢ççå ´æ¯å¯ä»¥ä½¿ç¨å³çµ±ãç¥ç¶ææ··ååå½¢æ¸²æå¨æ¸²ææå½±åãç¸½èè¨ä¹ï¼éå½¢æäºä¸åå¼·å¥çèªååç³»çµ±ï¼ç¨æ¼é«åè³ª 3D å 4D å ´æ¯çæãèç¾æçè¡¨ç¤ºæ³ï¼ä¾å¦å ´æ¯åï¼ç¸æ¯ï¼æåæåºçå ´æ¯èªè¨å¯ä»¥çæå·ææ´é«ä¿çåº¦çè¤éå ´æ¯ï¼åææç¢ºå°å»ºæ¨¡å ´æ¯çµæ§ä»¥å¯¦ç¾ç²¾ç¢ºæ§å¶åç·¨è¼¯ã

##### **Atomic Fact Decomposition Helps Attributed Question Answering**
2410.16708v1 by Zhichao Yan, Jiapu Wang, Jiaoyan Chen, Xiaoli Li, Ru Li, Jeff Z. Pan

Attributed Question Answering (AQA) aims to provide both a trustworthy answer
and a reliable attribution report for a given question. Retrieval is a widely
adopted approach, including two general paradigms: Retrieval-Then-Read (RTR)
and post-hoc retrieval. Recently, Large Language Models (LLMs) have shown
remarkable proficiency, prompting growing interest in AQA among researchers.
However, RTR-based AQA often suffers from irrelevant knowledge and rapidly
changing information, even when LLMs are adopted, while post-hoc
retrieval-based AQA struggles with comprehending long-form answers with complex
logic, and precisely identifying the content needing revision and preserving
the original intent. To tackle these problems, this paper proposes an Atomic
fact decomposition-based Retrieval and Editing (ARE) framework, which
decomposes the generated long-form answers into molecular clauses and atomic
facts by the instruction-tuned LLMs. Notably, the instruction-tuned LLMs are
fine-tuned using a well-constructed dataset, generated from large scale
Knowledge Graphs (KGs). This process involves extracting one-hop neighbors from
a given set of entities and transforming the result into coherent long-form
text. Subsequently, ARE leverages a search engine to retrieve evidences related
to atomic facts, inputting these evidences into an LLM-based verifier to
determine whether the facts require expansion for re-retrieval or editing.
Furthermore, the edited facts are backtracked into the original answer, with
evidence aggregated based on the relationship between molecular clauses and
atomic facts. Extensive evaluations demonstrate the superior performance of our
proposed method over the state-of-the-arts on several datasets, with an
additionally proposed new metric $Attr_{p}$ for evaluating the precision of
evidence attribution.

æè¦ï¼<paragraph>æ­¸å å¼åç­ (AQA) çç®æ¨æ¯éå°ç¹å®åé¡æä¾å¯ä¿¡çç­æ¡åå¯é çæ­¸å å ±åãæ·åæ¯ä¸ç¨®å»£æ³æ¡ç¨çæ¹æ³ï¼åæ¬å©ç¨®ä¸è¬ç¯ä¾ï¼æ·ååé±è® (RTR) åäºå¾æ·åãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºåè¶ççç·´åº¦ï¼ä¿ä½¿ç ç©¶äººå¡å° AQA ç¢çè¶ä¾è¶æ¿åçèè¶£ãç¶èï¼å³ä½¿æ¡ç¨ LLMï¼åºæ¼ RTR ç AQA ä»å¸¸å¸¸æåå°ä¸ç¸éç¥è­åå¿«éè®åçè³è¨å½±é¿ï¼èåºæ¼äºå¾æ·åç AQA åé£ä»¥çè§£å·æè¤ééè¼¯çé·ç¯ç­æ¡ï¼ä¸¦ç²¾ç¢ºæ¾åºéè¦ä¿®æ¹çå§å®¹ï¼åæä¿çåå§æåãçºäºè§£æ±ºéäºåé¡ï¼æ¬ææåºäºä¸ååºæ¼åå­äºå¯¦åè§£çæ·ååç·¨è¼¯ (ARE) æ¶æ§ï¼å®ééæä»¤èª¿æ´ç LLM å°ç¢ççé·ç¯ç­æ¡åè§£çºåå­å­å¥ååå­äºå¯¦ãå¼å¾æ³¨æçæ¯ï¼æä»¤èª¿æ´ç LLM æä½¿ç¨å¾å¤§è¦æ¨¡ç¥è­åè­ (KG) ä¸­ç¢çççµæ§è¯å¥½è³æéé²è¡å¾®èª¿ãæ­¤ç¨åºåå«å¾ç¹å®å¯¦é«éåä¸­æ·åä¸è·³é°å±ï¼ä¸¦å°çµæè½æçºé£è²«çé·ç¯æå­ãé¨å¾ï¼ARE æå©ç¨æå°å¼ææ·åèåå­äºå¯¦ç¸éçè­æï¼å°éäºè­æè¼¸å¥å°åºæ¼ LLM çé©è­å¨ä¸­ï¼ä»¥ç¢ºå®äºå¯¦æ¯å¦éè¦æ´åä»¥ä¾éæ°æ·åæç·¨è¼¯ãæ­¤å¤ï¼ç·¨è¼¯å¾ççµææåæº¯å°åå§ç­æ¡ï¼ä¸¦æ ¹æåå­å­å¥ååå­äºå¯¦ä¹éçéä¿å½æ´è­æãå»£æ³çè©ä¼°é¡¯ç¤ºï¼æåæåºçæ¹æ³å¨å¤åè³æéä¸åªæ¼ç¾ææè¡ï¼ä¸¦é¡å¤æåºäºä¸åæ°çææ¨ $Attr_{p}$ï¼ç¨æ¼è©ä¼°è­ææ­¸å çç²¾æºåº¦ã</paragraph>

##### **PLDR-LLM: Large Language Model from Power Law Decoder Representations**
2410.16703v1 by Burc Gokden

We present the Large Language Model from Power Law Decoder Representations
(PLDR-LLM), a language model that leverages non-linear and linear
transformations through Power Law Graph Attention mechanism to generate
well-defined deductive and inductive outputs. We pretrain the PLDR-LLMs of
varying layer sizes with a small batch size of 32 and $\sim$8B tokens from the
RefinedWeb dataset, and show that they achieve competitive performance in
zero-shot and few-shot settings compared to scaled dot-product LLMs of similar
model size reported in the literature. We show that deductive outputs of
PLDR-LLMs can be used to compare model characteristics or improve the
performance by introducing the Directed Acyclic Graph (DAG) loss as a metric
and regularizer. Our results indicate that the initial maximum learning rate
and warm-up steps have a lasting impact on deductive outputs throughout the
pretraining. We provide a detailed description of PLDR-LLM architecture, its
implementation and the pretraining procedure.

æè¦ï¼æåæåºä½¿ç¨åªå¾è§£ç¢¼å¨è¡¨ç¤ºæ³çå¤§èªè¨æ¨¡å (PLDR-LLM)ï¼éæ¯ä¸åèªè¨æ¨¡åï¼å®ééåªå¾åæ³¨æåæ©å¶ï¼å©ç¨éç·æ§åç·æ§è½æä¾ç¢çå®ç¾©è¯å¥½çæ¼ç¹¹åæ­¸ç´è¼¸åºãæåä½¿ç¨ 32 çå°æ¹æ¬¡å¤§å°å RefinedWeb è³æéä¸­ç $\sim$8B ä»¤çï¼é è¨ç·´ä¸åå±¤å¤§å°ç PLDR-LLMï¼ä¸¦å±ç¤ºåºå®åå¨é¶æ¬¡åå°æ¬¡è¨­å®ä¸­ï¼èæç»ä¸­å ±å°çé¡ä¼¼æ¨¡åå¤§å°çç¸®æ¾é»ç© LLM ç¸æ¯ï¼å®åéå°äºç«¶ç­åè¡¨ç¾ãæåå±ç¤ºäº PLDR-LLM çæ¼ç¹¹è¼¸åºå¯ç¨æ¼æ¯è¼æ¨¡åç¹å¾µæééå¼å¥æåç¡ç°å (DAG) æå¤±ä½çºææ¨åæ­£ååå¨ä¾æ¹åæè½ãæåççµæè¡¨æï¼åå§æå¤§å­¸ç¿çåç±èº«æ­¥é©å°æ´åé è¨ç·´éç¨ä¸­çæ¼ç¹¹è¼¸åºææä¹çå½±é¿ãæåæä¾äº PLDR-LLM æ¶æ§ãå¶å¯¦ç¾åé è¨ç·´ç¨åºçè©³ç´°èªªæã

##### **Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency**
2410.16597v1 by Prafulla Kumar Choubey, Xin Su, Man Luo, Xiangyu Peng, Caiming Xiong, Tiep Le, Shachar Rosenman, Vasudev Lal, Phil Mui, Ricky Ho, Phillip Howard, Chien-Sheng Wu

Knowledge graphs (KGs) generated by large language models (LLMs) are becoming
increasingly valuable for Retrieval-Augmented Generation (RAG) applications
that require knowledge-intensive reasoning. However, existing KG extraction
methods predominantly rely on prompt-based approaches, which are inefficient
for processing large-scale corpora. These approaches often suffer from
information loss, particularly with long documents, due to the lack of
specialized design for KG construction. Additionally, there is a gap in
evaluation datasets and methodologies for ontology-free KG construction. To
overcome these limitations, we propose SynthKG, a multi-step, document-level
ontology-free KG synthesis workflow based on LLMs. By fine-tuning a smaller LLM
on the synthesized document-KG pairs, we streamline the multi-step process into
a single-step KG generation approach called Distill-SynthKG, substantially
reducing the number of LLM inference calls. Furthermore, we re-purpose existing
question-answering datasets to establish KG evaluation datasets and introduce
new evaluation metrics. Using KGs produced by Distill-SynthKG, we also design a
novel graph-based retrieval framework for RAG. Experimental results demonstrate
that Distill-SynthKG not only surpasses all baseline models in KG quality --
including models up to eight times larger -- but also consistently excels in
retrieval and question-answering tasks. Our proposed graph retrieval framework
also outperforms all KG-retrieval methods across multiple benchmark datasets.
We release the SynthKG dataset and Distill-SynthKG model publicly to support
further research and development.

æè¦ï¼ç±å¤§åèªè¨æ¨¡å (LLM) çæçç¥è­åè­ (KG) å°æ¼éè¦ç¥è­å¯éåæ¨ççæª¢ç´¢å¢å¼·çæ (RAG) æç¨ç¨å¼è®å¾è¶ä¾è¶æå¹å¼ãç¶èï¼ç¾æç KG èåæ¹æ³ä¸»è¦ä¾è³´æ¼æç¤ºå¼æ¹æ³ï¼éç¨®æ¹æ³å°æ¼èçå¤§è¦æ¨¡èªæåº«èè¨æçä½ä¸ãç±æ¼ç¼ºä¹éå° KG å»ºæ§çå°éè¨­è¨ï¼éäºæ¹æ³éå¸¸æé­åè³è¨éºå¤±ï¼ç¹å¥æ¯å¨é·ç¯æä»¶çææ³ä¸ãæ­¤å¤ï¼å¨ç¨æ¼å»ºæ§ç¡æ¬ä½ KG çè©ä¼°è³æéåæ¹æ³è«æ¹é¢å­å¨å·®è·ãçºäºåæéäºéå¶ï¼æåæåºäº SynthKGï¼éæ¯ä¸ååºæ¼ LLM çå¤æ­¥é©æä»¶ç´å¥ç¡æ¬ä½ KG åæå·¥ä½æµç¨ãééå¾®èª¿è¼å°ç LLM å¨åæçæä»¶-KG å°ä¸ï¼æåå°å¤æ­¥é©æµç¨ç°¡åçºç¨±çº Distill-SynthKG çå®æ­¥é© KG çææ¹æ³ï¼å¤§å¹æ¸å°äº LLM æ¨è«å¼å«çæ¸éãæ­¤å¤ï¼æåéæ°å©ç¨ç¾æçåç­è³æéä¾å»ºç« KG è©ä¼°è³æéï¼ä¸¦å¼å¥æ°çè©ä¼°ææ¨ãä½¿ç¨ Distill-SynthKG çæç KGï¼æåéçº RAG è¨­è¨äºä¸åæ°ç©çåºæ¼åå½¢çæª¢ç´¢æ¶æ§ãå¯¦é©çµæè¡¨æï¼Distill-SynthKG ä¸åå¨ KG åè³ªæ¹é¢è¶è¶äºææåºæºæ¨¡åï¼åæ¬å¤§å«åçæ¨¡åï¼ï¼èä¸å¨æª¢ç´¢ååç­ä»»åä¸­ä¹å§çµè¡¨ç¾åºè²ãæåæåºçåå½¢æª¢ç´¢æ¶æ§å¨å¤ååºæºè³æéä¸ä¹åªæ¼ææ KG æª¢ç´¢æ¹æ³ãæåå¬ééåº SynthKG è³æéå Distill-SynthKG æ¨¡åï¼ä»¥æ¯æé²ä¸æ­¥çç ç©¶åéç¼ã

##### **Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight**
2410.16397v1 by Oliver Bensch, Leonie Bensch, Tommy Nilsson, Florian Saling, Wafa M. Sadri, Carsten Hartmann, Tobias Hecking, J. Nathan Kutz

As humanity prepares for new missions to the Moon and Mars, astronauts will
need to operate with greater autonomy, given the communication delays that make
real-time support from Earth difficult. For instance, messages between Mars and
Earth can take up to 24 minutes, making quick responses impossible. This
limitation poses a challenge for astronauts who must rely on in-situ tools to
access the large volume of data from spacecraft sensors, rovers, and
satellites, data that is often fragmented and difficult to use. To bridge this
gap, systems like the Mars Exploration Telemetry-Driven Information System
(METIS) are being developed. METIS is an AI assistant designed to handle
routine tasks, monitor spacecraft systems, and detect anomalies, all while
reducing the reliance on mission control. Current Generative Pretrained
Transformer (GPT) Models, while powerful, struggle in safety-critical
environments. They can generate plausible but incorrect responses, a phenomenon
known as "hallucination," which could endanger astronauts. To overcome these
limitations, this paper proposes enhancing systems like METIS by integrating
GPTs, Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and
Augmented Reality (AR). The idea is to allow astronauts to interact with their
data more intuitively, using natural language queries and visualizing real-time
information through AR. KGs will be used to easily access live telemetry and
multimodal data, ensuring that astronauts have the right information at the
right time. By combining AI, KGs, and AR, this new system will empower
astronauts to work more autonomously, safely, and efficiently during future
space missions.

æè¦ï¼é¨èäººé¡æºååå¾æçåç«æå·è¡æ°ä»»åï¼èéå°éè¨å»¶é²è®ä¾èªå°ççå³ææ¯æ´è®å¾å°é£ï¼å¤ªç©ºäººå°éè¦ä»¥æ´é«çèªä¸»æ§å·è¡ä»»åãä¾å¦ï¼ç«æåå°çä¹éçè¨æ¯å³éå¯è½éè¦é·é 24 åéï¼éä½¿å¾å¿«éåæè®å¾ä¸å¯è½ãéåéå¶å°å¿é ä»°è³´ç¾å ´å·¥å·æè½å­åä¾èªå¤ªç©ºè¹ææ¸¬å¨ãæ¢æ¸¬è»åè¡æçå¤§éè³æçå¤ªç©ºäººä¾èªªæ¯ä¸é ææ°ï¼èéäºè³æéå¸¸æ¯çæ®µä¸é£ä»¥ä½¿ç¨çãçºäºå½åéåå·®è·ï¼åç«ææ¢æ¸¬éæ¸¬é©åè³è¨ç³»çµ± (METIS) ä¹é¡çç³»çµ±æ­£å¨éç¼ä¸­ãMETIS æ¯ä¸å AI å©çï¼æ¨å¨èçä¾è¡å·¥ä½ãç£æ§å¤ªç©ºè¹ç³»çµ±ååµæ¸¬ç°å¸¸ï¼åææ¸å°å°ä»»åæ§å¶çä¾è³´ãç¾æççæå¼é è¨ç·´Transformer (GPT) æ¨¡åéç¶å¼·å¤§ï¼ä½å¨å®å¨ééµç°å¢ä¸­å»é£ä»¥ç¼æ®ä½ç¨ãå®åå¯è½æç¢ççä¼¼åçä½é¯èª¤çåæï¼éç¨®ç¾è±¡ç¨±çºãå¹»è¦ºãï¼å¯è½æä½¿å¤ªç©ºäººé·å¥å±éªãçºäºåæéäºéå¶ï¼æ¬ææåºééæ´å GPTãæª¢ç´¢å¢å¼·çæ (RAG)ãç¥è­åè­ (KG) åæ´å¢å¯¦å¢ (AR) ä¾å¢å¼·å METIS ä¹é¡çç³»çµ±ãéåæ³æ³æ¯è®å¤ªç©ºäººè½å¤ æ´ç´è¦ºå°èä»åçè³æäºåï¼ä½¿ç¨èªç¶èªè¨æ¥è©¢ä¸¦éé AR è¦è¦ºåå³æè³è¨ãKG å°ç¨æ¼è¼é¬å­åå³æéæ¸¬åå¤æ¨¡å¼è³æï¼ç¢ºä¿å¤ªç©ºäººå¨é©ç¶çæéåå¾é©ç¶çè³è¨ãééçµå AIãKG å ARï¼éåæ°ç³»çµ±å°è³¦è½å¤ªç©ºäººå¨æªä¾çå¤ªç©ºä»»åä¸­æ´èªä¸»ãå®å¨ä¸ææçå°å·¥ä½ã

##### **A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**
2410.16155v1 by Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao

With the development of large language models, they are widely used as agents
in various fields. A key component of agents is memory, which stores vital
information but is susceptible to jailbreak attacks. Existing research mainly
focuses on single-agent attacks and shared memory attacks. However, real-world
scenarios often involve independent memory. In this paper, we propose the
Troublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale,
multi-agent, multi-topology text-based attack evaluation framework. TMCHT
involves one attacker agent attempting to mislead an entire society of agents.
We identify two major challenges in multi-agent attacks: (1) Non-complete graph
structure, (2) Large-scale systems. We attribute these challenges to a
phenomenon we term toxicity disappearing. To address these issues, we propose
an Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes
the retrieval suffix to make poisoned samples more easily retrieved and
optimizes the replication suffix to make poisoned samples have contagious
ability. We demonstrate the superiority of our approach in TMCHT, with 23.51%,
18.95%, and 52.93% improvements in line topology, star topology, and 100-agent
settings. Encourage community attention to the security of multi-agent systems.

æè¦ï¼éçå¤§åè¯­è¨æ¨¡åçåå±ï¼å®ä»¬è¢«å¹¿æ³ç¨ä½åä¸ªé¢åçä»£çãä»£ççå³é®ç»æé¨åæ¯è®°å¿ï¼å®å­å¨éè¦ä¿¡æ¯ï¼ä½å®¹æåå°è¶ç±æ»å»ãç°æç ç©¶ä¸»è¦éä¸­å¨åä¸ä»£çæ»å»åå±äº«åå­æ»å»ä¸ãç¶èï¼ç°å®ä¸çä¸­çåºæ¯éå¸¸æ¶åç¬ç«çåå­ãå¨æ¬æä¸­ï¼æä»¬æåºäº Troublemaker Makes Chaos in Honest Town (TMCHT) ä»»å¡ï¼è¿æ¯ä¸ä¸ªå¤§è§æ¨¡ãå¤ä»£çãå¤ææåºäºææ¬çæ»å»è¯ä¼°æ¡æ¶ãTMCHT æ¶åä¸ä¸ªæ»å»èä»£çè¯å¾è¯¯å¯¼æ´ä¸ªä»£çç¤¾ä¼ãæä»¬ç¡®å®äºå¤ä»£çæ»å»ä¸­çä¸¤ä¸ªä¸»è¦ææï¼(1) éå®æ´å¾ç»æï¼(2) å¤§è§æ¨¡ç³»ç»ãæä»¬å°è¿äºææå½å äºæä»¬ç§°ä¹ä¸ºæ¯æ§æ¶å¤±çç°è±¡ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºä¸ç§å¯¹ææ§å¤å¶ä¼ ææ§è¶ç± (ARCJ) æ¹æ³ï¼è¯¥æ¹æ³ä¼åäºæ£ç´¢åç¼ä»¥ä½¿ä¸­æ¯æ ·æ¬æ´å®¹æè¢«æ£ç´¢ï¼å¹¶ä¼åäºå¤å¶åç¼ä»¥ä½¿ä¸­æ¯æ ·æ¬å·æä¼ ææ§ãæä»¬å¨ TMCHT ä¸­å±ç¤ºäºæä»¬æ¹æ³çä¼è¶æ§ï¼å¨ç´çº¿ææãæå½¢ææå 100 ä»£çè®¾ç½®ä¸­åå«æé«äº 23.51%ã18.95% å 52.93%ãé¼å±ç¤¾åºå³æ³¨å¤ä»£çç³»ç»çå®å¨æ§ã

##### **CausalGraph2LLM: Evaluating LLMs for Causal Queries**
2410.15939v1 by Ivaxi Sheth, Bahare Fatemi, Mario Fritz

Causality is essential in scientific research, enabling researchers to
interpret true relationships between variables. These causal relationships are
often represented by causal graphs, which are directed acyclic graphs. With the
recent advancements in Large Language Models (LLMs), there is an increasing
interest in exploring their capabilities in causal reasoning and their
potential use to hypothesize causal graphs. These tasks necessitate the LLMs to
encode the causal graph effectively for subsequent downstream tasks. In this
paper, we propose a comprehensive benchmark, \emph{CausalGraph2LLM},
encompassing a variety of causal graph settings to assess the causal graph
understanding capability of LLMs. We categorize the causal queries into two
types: graph-level and node-level queries. We benchmark both open-sourced and
closed models for our study. Our findings reveal that while LLMs show promise
in this domain, they are highly sensitive to the encoding used. Even capable
models like GPT-4 and Gemini-1.5 exhibit sensitivity to encoding, with
deviations of about $60\%$. We further demonstrate this sensitivity for
downstream causal intervention tasks. Moreover, we observe that LLMs can often
display biases when presented with contextual information about a causal graph,
potentially stemming from their parametric memory.

æè¦ï¼å æå³ç³»å¨ç§å­¦ç ç©¶ä¸­è³å³éè¦ï¼å®ä½¿ç ç©¶äººåè½å¤è§£éåéä¹é´ççå®å³ç³»ãè¿äºå æå³ç³»éå¸¸ç¨å æå¾è¡¨ç¤ºï¼å æå¾æ¯æåæ ç¯å¾ãéçå¤§è¯­è¨æ¨¡å (LLM) çææ°è¿å±ï¼äººä»¬è¶æ¥è¶æå´è¶£æ¢ç´¢å®ä»¬å¨å ææ¨çä¸­çè½åä»¥åå®ä»¬å¨åè®¾å æå¾ä¸­çæ½å¨ç¨éãè¿äºä»»å¡éè¦ LLM ææå°å¯¹å æå¾è¿è¡ç¼ç ï¼ä»¥ä¾¿åç»­çä¸æ¸¸ä»»å¡ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ä¸ªç»¼ååºåï¼\emph{CausalGraph2LLM}ï¼å®åå«äºåç§å æå¾è®¾ç½®ï¼ä»¥è¯ä¼° LLM çå æå¾çè§£è½åãæä»¬å°å ææ¥è¯¢åä¸ºä¸¤ç±»ï¼å¾çº§æ¥è¯¢åèç¹çº§æ¥è¯¢ãæä»¬å¯¹å¼æºæ¨¡ååå°é­æ¨¡åè¿è¡äºåºåæµè¯ãæä»¬çç ç©¶ç»æè¡¨æï¼è½ç¶ LLM å¨è¯¥é¢åæ¾ç¤ºåºåæ¯ï¼ä½å®ä»¬å¯¹æä½¿ç¨çç¼ç éå¸¸ææãå³ä½¿å GPT-4 å Gemini-1.5 è¿æ ·çå¼ºå¤§æ¨¡åä¹å¯¹ç¼ç è¡¨ç°åºæææ§ï¼åå·®çº¦ä¸º 60%ãæä»¬è¿ä¸æ­¥è¯æäºè¿ç§å¯¹ä¸æ¸¸å æå¹²é¢ä»»å¡çæææ§ãæ­¤å¤ï¼æä»¬è§å¯å°ï¼å½ LLM è·å¾æå³å æå¾çä¸ä¸æä¿¡æ¯æ¶ï¼å®ä»¬éå¸¸ä¼è¡¨ç°åºåè§ï¼è¿å¯è½æºäºå®ä»¬çåæ°è®°å¿ã

##### **LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**
2410.15828v1 by Tejumade Afonja, Ivaxi Sheth, Ruta Binkyte, Waqar Hanif, Thomas Ulas, Matthias Becker, Mario Fritz

Gene regulatory networks (GRNs) represent the causal relationships between
transcription factors (TFs) and target genes in single-cell RNA sequencing
(scRNA-seq) data. Understanding these networks is crucial for uncovering
disease mechanisms and identifying therapeutic targets. In this work, we
investigate the potential of large language models (LLMs) for GRN discovery,
leveraging their learned biological knowledge alone or in combination with
traditional statistical methods. We develop a task-based evaluation strategy to
address the challenge of unavailable ground truth causal graphs. Specifically,
we use the GRNs suggested by LLMs to guide causal synthetic data generation and
compare the resulting data against the original dataset. Our statistical and
biological assessments show that LLMs can support statistical modeling and data
synthesis for biological research.

æè¦ï¼åºå èª¿æ§ç¶²è·¯ (GRN) ä»£è¡¨å®ç´°è RNA å®åº (scRNA-seq) è³æä¸­è½éå å­ (TF) èç®æ¨åºå ä¹éçå æéä¿ãäºè§£éäºç¶²è·¯å°æ¼æ­é²ç¾çæ©å¶åæ¾åºæ²»çç®æ¨è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) å¨ GRN æ¢ç´¢ä¸­çæ½åï¼å©ç¨å®åå­¸ç¿å°ççç©ç¥è­ï¼å®ç¨æèå³çµ±çµ±è¨æ¹æ³çµåä½¿ç¨ãæåå¶å®äºä¸é åºæ¼ä»»åçè©ä¼°ç­ç¥ï¼ä»¥è§£æ±ºç¡æ³åå¾å°é¢çç¸å æåè¡¨çææ°ãå·é«ä¾èªªï¼æåä½¿ç¨ LLM å»ºè­°ç GRN ä¾å¼å°å æåæè³æç¢çï¼ä¸¦å°ç¢ççè³æèåå§è³æéé²è¡æ¯è¼ãæåççµ±è¨åçç©è©ä¼°é¡¯ç¤ºï¼LLM å¯ä»¥æ¯æ´çç©ç ç©¶ççµ±è¨å»ºæ¨¡åè³æåæã

##### **NetSafe: Exploring the Topological Safety of Multi-agent Networks**
2410.15686v1 by Miao Yu, Shilong Wang, Guibin Zhang, Junyuan Mao, Chenlong Yin, Qijiong Liu, Qingsong Wen, Kun Wang, Yang Wang

Large language models (LLMs) have empowered nodes within multi-agent networks
with intelligence, showing growing applications in both academia and industry.
However, how to prevent these networks from generating malicious information
remains unexplored with previous research on single LLM's safety be challenging
to transfer. In this paper, we focus on the safety of multi-agent networks from
a topological perspective, investigating which topological properties
contribute to safer networks. To this end, we propose a general framework,
NetSafe along with an iterative RelCom interaction to unify existing diverse
LLM-based agent frameworks, laying the foundation for generalized topological
safety research. We identify several critical phenomena when multi-agent
networks are exposed to attacks involving misinformation, bias, and harmful
information, termed as Agent Hallucination and Aggregation Safety. Furthermore,
we find that highly connected networks are more susceptible to the spread of
adversarial attacks, with task performance in a Star Graph Topology decreasing
by 29.7%. Besides, our proposed static metrics aligned more closely with
real-world dynamic evaluations than traditional graph-theoretic metrics,
indicating that networks with greater average distances from attackers exhibit
enhanced safety. In conclusion, our work introduces a new topological
perspective on the safety of LLM-based multi-agent networks and discovers
several unreported phenomena, paving the way for future research to explore the
safety of such networks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è³¦äºäºå¤ä¸»é«ç¶²è·¯ä¸­çç¯é»æºæ§ï¼å¨å­¸è¡çåç¢æ¥­ä¸­å±ç¾åºè¶ä¾è¶å¤çæç¨ãç¶èï¼å¦ä½é²æ­¢éäºç¶²è·¯ç¢çæ¡æè³è¨ä»ç¶æ¯æªç¶æ¢ç´¢çé åï¼ååéå°å®ä¸ LLM å®å¨æ§çç ç©¶é£ä»¥è½ç§»ãå¨æ¬æä¸­ï¼æåå¾ææ²å­¸çè§åº¦æ¢è¨å¤ä¸»é«ç¶²è·¯çå®å¨æ§ï¼ç ç©¶åªäºææ²å±¬æ§æå©æ¼ç¶²è·¯æ´å®å¨ãçºæ­¤ï¼æåæåºäºä¸åéç¨æ¡æ¶ NetSafeï¼ä»¥åä¸ååè¦ç RelCom äºåï¼ä»¥çµ±ä¸ç¾æçåç¨®åºæ¼ LLM çä¸»é«æ¡æ¶ï¼çºå»£ç¾©çææ²å®å¨æ§ç ç©¶å¥ å®åºç¤ãæåå¨å¤ä¸»é«ç¶²è·¯é­åæ¶åé¯èª¤è³è¨ãåè¦åæå®³è³è¨çæ»ææï¼æ¾åºå¹¾åééµç¾è±¡ï¼ç¨±çºä¸»é«å¹»è¦ºåèåå®å¨æ§ãæ­¤å¤ï¼æåç¼ç¾é«åº¦é£æ¥çç¶²è·¯æ´å®¹æåå°å°ææ§æ»æçå½±é¿ï¼æå½¢åå½¢ææ²ä¸­çä»»åæè½ä¸éäº 29.7%ãæ­¤å¤ï¼æåæåºçéæææ¨æ¯å³çµ±çåè«ææ¨æ´è²¼è¿çå¯¦ä¸ççåæè©ä¼°ï¼éè¡¨ç¤ºèæ»æèå¹³åè·é¢è¼å¤§çç¶²è·¯å·ææ´é«çå®å¨æ§ãç¸½ä¹ï¼æåçç ç©¶å¼å¥äºåºæ¼ LLM çå¤ä¸»é«ç¶²è·¯å®å¨æ§çæ°ææ²è§é»ï¼ä¸¦ç¼ç¾äºå¹¾åæªæ¾å ±å°çç¾è±¡ï¼çºæªä¾æ¢ç´¢æ­¤é¡ç¶²è·¯å®å¨æ§çç ç©¶éªè·¯ã

##### **TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models**
2410.15268v1 by Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Liang Zhao

Representation learning of Text-Attributed Graphs (TAGs) has garnered
significant attention due to its applications in various domains, including
recommendation systems and social networks. Despite advancements in TAG
learning methodologies, challenges remain in explainability due to the
black-box nature of existing TAG representation learning models. This paper
presents TAGExplainer, the first method designed to generate natural language
explanations for TAG learning. TAGExplainer employs a generative language model
that maps input-output pairs to explanations reflecting the model's
decision-making process. To address the lack of annotated ground truth
explanations in real-world scenarios, we propose first generating pseudo-labels
that capture the model's decisions from saliency-based explanations, then the
pseudo-label generator is iteratively trained based on three training
objectives focusing on faithfulness and brevity via Expert Iteration, to
improve the quality of generated pseudo-labels. The high-quality pseudo-labels
are finally utilized to train an end-to-end explanation generator model.
Extensive experiments are conducted to demonstrate the effectiveness of
TAGExplainer in producing faithful and concise natural language explanations.

æè¦ï¼ææ¬æ­¸å å (TAG) çè¡¨ç¤ºå­¸ç¿å å¶å¨åç¨®é åï¼åæ¬æ¨è¦ç³»çµ±åç¤¾äº¤ç¶²çµ¡ï¼ä¸­çæç¨èååéæ³¨ãåç®¡ TAG å­¸ç¿æ¹æ³åå¾äºé²å±ï¼ä½ç±æ¼ç¾æ TAG è¡¨ç¤ºå­¸ç¿æ¨¡åçé»ç®±æ§è³ªï¼å¯è§£éæ§ä»ç¶é¢è¨ææ°ãæ¬ææåºäº TAGExplainerï¼éæ¯ä¸ç¨®æ¨å¨çº TAG å­¸ç¿çæèªç¶èªè¨è§£éçç¬¬ä¸ç¨®æ¹æ³ãTAGExplainer æ¡ç¨çæèªè¨æ¨¡åï¼å°è¼¸å¥è¼¸åºå°æå°åæ æ¨¡åæ±ºç­éç¨çè§£éãçºäºè§£æ±ºç¾å¯¦å ´æ¯ä¸­ç¼ºä¹è¨»è§£å°é¢çå¯¦è§£éçåé¡ï¼æåå»ºè­°é¦åå¾åºæ¼é¡¯èæ§çè§£éä¸­çæå½æ¨ç±¤ä¾æææ¨¡åçæ±ºç­ï¼ç¶å¾ééå°å®¶è¿­ä»£åºæ¼ä¸åè¨ç·´ç®æ¨ï¼å´éæ¼å¿ å¯¦åº¦åç°¡æ½æ§ï¼åè¦è¨ç·´å½æ¨ç±¤çæå¨ï¼ä»¥æé«çæå½æ¨ç±¤çåè³ªãæå¾å°é«åè³ªçå½æ¨ç±¤ç¨æ¼è¨ç·´ç«¯å°ç«¯è§£éçæå¨æ¨¡åãé²è¡äºå»£æ³çå¯¦é©ï¼ä»¥è­æ TAGExplainer å¨çæå¿ å¯¦ä¸ç°¡æ½çèªç¶èªè¨è§£éæ¹é¢çæææ§ã

##### **Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction**
2410.15165v1 by Yinhan He, Zaiyi Zheng, Patrick Soga, Yaozhen Zhu, yushun Dong, Jundong Li

In recent years, Graph Neural Networks (GNNs) have become successful in
molecular property prediction tasks such as toxicity analysis. However, due to
the black-box nature of GNNs, their outputs can be concerning in high-stakes
decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph
Counterfactual Explanation (GCE) has emerged as a promising approach to improve
GNN transparency. However, current GCE methods usually fail to take
domain-specific knowledge into consideration, which can result in outputs that
are not easily comprehensible by humans. To address this challenge, we propose
a novel GCE method, LLM-GCE, to unleash the power of large language models
(LLMs) in explaining GNNs for molecular property prediction. Specifically, we
utilize an autoencoder to generate the counterfactual graph topology from a set
of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also
incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which
provides intermediate feedback derived from the generated counterfactuals as an
attempt to give more faithful guidance. Extensive experiments demonstrate the
superior performance of LLM-GCE. Our code is released on
https://github.com/YinhanHe123/new\_LLM4GNNExplanation.

æè¦ï¼è¿å¹´æ¥ï¼å¾ç¥ç»ç½ç» (GNN) å·²æååºç¨äºåå­æ§è´¨é¢æµä»»å¡ï¼ä¾å¦æ¯æ§åæãç¶èï¼ç±äº GNN çé»çæ§è´¨ï¼å¶è¾åºå¨é«é£é©å³ç­åºæ¯ä¸­å¯è½ä¼ä»¤äººæå¿§ï¼ä¾å¦è¯ç©åç°ãéå¯¹è¿ä¸é®é¢ï¼å¾åäºå®è§£é (GCE) å·²æä¸ºæé« GNN éæåº¦çä¸ç§å¾æåæ¯çæ¹æ³ãç¶èï¼å½åç GCE æ¹æ³éå¸¸æ æ³èèç¹å®é¢åçç¥è¯ï¼è¿å¯è½å¯¼è´äººç±»é¾ä»¥çè§£è¾åºãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§æ°é¢ç GCE æ¹æ³ï¼LLM-GCEï¼ä»¥éæ¾å¤§åè¯­è¨æ¨¡å (LLM) å¨è§£é GNN ç¨äºåå­æ§è´¨é¢æµæ¹é¢çè½åãå·ä½æ¥è¯´ï¼æä»¬å©ç¨èªå¨ç¼ç å¨ä»ä¸ç»åºäºè¾å¥å¾çåäºå®ææ¬å¯¹ (CTP) çæåäºå®å¾ææãåæ¶ï¼æä»¬è¿å å¥äºä¸ä¸ª CTP å¨æåé¦æ¨¡åæ¥åè½» LLM å¹»è§ï¼è¯¥æ¨¡åæä¾ä»çæçåäºå®ä¸­æ´¾ççä¸­é´åé¦ï¼ä»¥å°è¯æä¾æ´çå®çæå¯¼ãå¤§éçå®éªè¡¨æäº LLM-GCE çåè¶æ§è½ãæä»¬çä»£ç å·²åå¸å¨ https://github.com/YinhanHe123/new\_LLM4GNNExplanationã

##### **MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science**
2410.15126v1 by Junho Kim, Yeachan Kim, Jun-Hyung Park, Yerim Oh, Suho Kim, SangKeun Lee

We introduce a novel continued pre-training method, MELT (MatEriaLs-aware
continued pre-Training), specifically designed to efficiently adapt the
pre-trained language models (PLMs) for materials science. Unlike previous
adaptation strategies that solely focus on constructing domain-specific corpus,
MELT comprehensively considers both the corpus and the training strategy, given
that materials science corpus has distinct characteristics from other domains.
To this end, we first construct a comprehensive materials knowledge base from
the scientific corpus by building semantic graphs. Leveraging this extracted
knowledge, we integrate a curriculum into the adaptation process that begins
with familiar and generalized concepts and progressively moves toward more
specialized terms. We conduct extensive experiments across diverse benchmarks
to verify the effectiveness and generality of MELT. A comprehensive evaluation
convincingly supports the strength of MELT, demonstrating superior performance
compared to existing continued pre-training methods. The in-depth analysis also
shows that MELT enables PLMs to effectively represent materials entities
compared to the existing adaptation methods, thereby highlighting its broad
applicability across a wide spectrum of materials science.

æè¦ï¼æåä»ç´¹äºä¸ç¨®æ°ç©çæçºé è¨ç·´æ¹æ³ï¼MELTï¼MatEriaLs-awareæçºé è¨ç·´ï¼ï¼å°éè¨­è¨ç¨æ¼ææå°èª¿æ´ææç§å­¸çé è¨ç·´èªè¨æ¨¡å (PLM)ãèåååå°æ³¨æ¼å»ºæ§ç¹å®é åèªæåº«çèª¿æ´ç­ç¥ä¸åï¼MELT å¨é¢èæ®èªæåº«åè¨ç·´ç­ç¥ï¼å çºææç§å­¸èªæåº«å·æä¸åæ¼å¶ä»é åçç¹å¾µãçºæ­¤ï¼æåé¦åééå»ºç«èªç¾©åå¾ç§å­¸èªæåº«æ§å»ºä¸åå¨é¢çææç¥è­åº«ãå©ç¨æåçç¥è­ï¼æåå°èª²ç¨æ´åå°èª¿æ´éç¨ä¸­ï¼å¾çæä¸éç¨çæ¦å¿µéå§ï¼éæ¼¸è½åæ´å°æ¥­çè¡èªãæåå¨ä¸åçåºæºä¸é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é©è­ MELT çæææ§åæ®éæ§ãå¨é¢çè©ä¼°ä»¤äººä¿¡æå°æ¯æäº MELT çåªé»ï¼èç¾æçæçºé è¨ç·´æ¹æ³ç¸æ¯ï¼è¡¨ç¾åºåªç°çæ§è½ãæ·±å¥åæéè¡¨æï¼èç¾æçèª¿æ´æ¹æ³ç¸æ¯ï¼MELT è½è® PLM ææå°è¡¨ç¤ºææå¯¦é«ï¼å¾èçªé¡¯å¶å¨å»£æ³çææç§å­¸é åä¸­çå»£æ³é©ç¨æ§ã

##### **Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models**
2410.15116v1 by Qitan Lv, Jie Wang, Hanzhu Chen, Bin Li, Yongdong Zhang, Feng Wu

Generation of plausible but incorrect factual information, often termed
hallucination, has attracted significant research interest. Retrieval-augmented
language model (RALM) -- which enhances models with up-to-date knowledge --
emerges as a promising method to reduce hallucination. However, existing RALMs
may instead exacerbate hallucination when retrieving lengthy contexts. To
address this challenge, we propose COFT, a novel
\textbf{CO}arse-to-\textbf{F}ine highligh\textbf{T}ing method to focus on
different granularity-level key texts, thereby avoiding getting lost in lengthy
contexts. Specifically, COFT consists of three components: \textit{recaller},
\textit{scorer}, and \textit{selector}. First, \textit{recaller} applies a
knowledge graph to extract potential key entities in a given context. Second,
\textit{scorer} measures the importance of each entity by calculating its
contextual weight. Finally, \textit{selector} selects high contextual weight
entities with a dynamic threshold algorithm and highlights the corresponding
paragraphs, sentences, or words in a coarse-to-fine manner. Extensive
experiments on the knowledge hallucination benchmark demonstrate the
effectiveness of COFT, leading to a superior performance over $30\%$ in the F1
score metric. Moreover, COFT also exhibits remarkable versatility across
various long-form tasks, such as reading comprehension and question answering.

æè¦ï¼çæçä¼¼åçä½å®éä¸ä¸æ­£ç¡®çå®éä¿¡æ¯ï¼éå¸¸ç§°ä¸ºå¹»è§ï¼å¼èµ·äºéè¦çç ç©¶å´è¶£ãæ£ç´¢å¢å¼ºè¯­è¨æ¨¡å (RALM) éè¿ä¸ºæ¨¡åæä¾ææ°çç¥è¯æ¥å¢å¼ºæ¨¡åï¼è¿æ¯ä¸ç§æåéçæ¹æ³ï¼å¯ä»¥åå°å¹»è§ãç¶èï¼ç°æç RALM å¨æ£ç´¢åé¿çä¸ä¸ææ¶å¯è½ä¼å å§å¹»è§ãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäº COFTï¼ä¸ç§æ°é¢ç\textbf{ç²}å°\textbf{ç»}é«äº®\textbf{T}ing æ¹æ³ï¼ä¸æ³¨äºä¸åç²åº¦çº§å«çå³é®ææ¬ï¼ä»èé¿åå¨åé¿çä¸ä¸æä¸­è¿·å¤±ãå·ä½æ¥è¯´ï¼COFT ç±ä¸ä¸ªç»ä»¶ç»æï¼\textit{recaller}ã\textit{scorer} å \textit{selector}ãé¦åï¼\textit{recaller} åºç¨ç¥è¯å¾è°±æ¥æåç»å®ä¸ä¸æä¸­æ½å¨çå³é®å®ä½ãå¶æ¬¡ï¼\textit{scorer} éè¿è®¡ç®æ¯ä¸ªå®ä½çä¸ä¸ææéæ¥è¡¡éå¶éè¦æ§ãæåï¼\textit{selector} ä½¿ç¨å¨æéå¼ç®æ³éæ©å·æé«ä¸ä¸ææéçå®ä½ï¼å¹¶ä»¥ç²å°ç»çæ¹å¼çªåºæ¾ç¤ºç¸åºçæ®µè½ãå¥å­æåè¯ãå¨ç¥è¯å¹»è§åºåä¸çå¹¿æ³å®éªè¯æäº COFT çæææ§ï¼å¨ F1 åæ°ææ ä¸åå¾äºè¶è¿ 30% çåè¶æ§è½ãæ­¤å¤ï¼COFT å¨åç§é¿ç¯ä»»å¡ä¸­ä¹è¡¨ç°åºåè¶çå¤åè½æ§ï¼ä¾å¦éè¯»çè§£åé®é¢è§£ç­ã

##### **A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers**
2410.15064v1 by George Hannah, Rita T. Sousa, Ioannis Dasoulas, Claudia d'Amato

With the recent surge in popularity of Large Language Models (LLMs), there is
the rising risk of users blindly trusting the information in the response, even
in cases where the LLM recommends actions that have potential legal
implications and this may put the user in danger. We provide an empirical
analysis on multiple existing LLMs showing the urgency of the problem. Hence,
we propose a short-term solution consisting in an approach for isolating these
legal issues through prompt re-engineering. We further analyse the outcomes but
also the limitations of the prompt engineering based approach and we highlight
the need of additional resources for fully solving the problem We also propose
a framework powered by a legal knowledge graph (KG) to generate legal citations
for these legal issues, enriching the response of the LLM.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡åï¼LLMï¼è¿ææµè¡æ¿å¢ï¼ä½¿ç¨èç²ç®ç¸ä¿¡åæä¸­è³è¨çé¢¨éªä¹é¨ä¹åé«ï¼å³ä½¿å¨ LLM å»ºè­°æ¡åå¯è½ç¢çæ³å¾å½±é¿çè¡åæäº¦ç¶ï¼éå¯è½æä½¿ä½¿ç¨èé·å¥å±éªä¹ä¸­ãæåéå°å¤åç¾æ LLM æä¾å¯¦è­åæï¼é¡¯ç¤ºæ­¤åé¡çæ¥è¿«æ§ãå æ­¤ï¼æåæåºä¸åç­æè§£æ±ºæ¹æ¡ï¼åæ¬ééæç¤ºéæ°è¨­è¨ä¾å­¤ç«éäºæ³å¾åé¡çæ¹æ³ãæåé²ä¸æ­¥åææç¤ºå·¥ç¨æ¹æ³çææï¼ä½ä¹åæå¶éå¶ï¼ä¸¦å¼·èª¿å®å¨è§£æ±ºåé¡éè¦é¡å¤è³æºãæåéæåºä¸åç±æ³å¾ç¥è­åè­ï¼KGï¼é©åçæ¶æ§ï¼çºéäºæ³å¾åé¡ç¢çæ³å¾å¼æï¼è±å¯ LLM çåæã

##### **LangGFM: A Large Language Model Alone Can be a Powerful Graph Foundation Model**
2410.14961v1 by Tianqianjin Lin, Pengwei Yan, Kaisong Song, Zhuoren Jiang, Yangyang Kang, Jun Lin, Weikang Yuan, Junjie Cao, Changlong Sun, Xiaozhong Liu

Graph foundation models (GFMs) have recently gained significant attention.
However, the unique data processing and evaluation setups employed by different
studies hinder a deeper understanding of their progress. Additionally, current
research tends to focus on specific subsets of graph learning tasks, such as
structural tasks, node-level tasks, or classification tasks. As a result, they
often incorporate specialized modules tailored to particular task types, losing
their applicability to other graph learning tasks and contradicting the
original intent of foundation models to be universal. Therefore, to enhance
consistency, coverage, and diversity across domains, tasks, and research
interests within the graph learning community in the evaluation of GFMs, we
propose GFMBench-a systematic and comprehensive benchmark comprising 26
datasets. Moreover, we introduce LangGFM, a novel GFM that relies entirely on
large language models. By revisiting and exploring the effective graph
textualization principles, as well as repurposing successful techniques from
graph augmentation and graph self-supervised learning within the language
space, LangGFM achieves performance on par with or exceeding the state of the
art across GFMBench, which can offer us new perspectives, experiences, and
baselines to drive forward the evolution of GFMs.

æè¦ï¼åå½¢åºç¤æ¨¡å (GFM) è¿æç²å¾é¡¯èçéæ³¨ã
ç¶èï¼ä¸åç ç©¶æ¡ç¨ç¨ç¹è³æèçåè©ä¼°è¨­å®ï¼é»ç¤äºå°å¶é²å±çæ·±å¥çè§£ãæ­¤å¤ï¼ç®åçç ç©¶å¾åæ¼å°æ³¨æ¼åå½¢å­¸ç¿ä»»åçç¹å®å­éï¼ä¾å¦çµæ§ä»»åãç¯é»å±¤ç´ä»»åæåé¡ä»»åãå æ­¤ï¼å®åç¶å¸¸æ´åå°ééå°ç¹å®ä»»åé¡åéèº«æé çæ¨¡çµï¼å¤±å»å¶å°å¶ä»åå½¢å­¸ç¿ä»»åçé©ç¨æ§ï¼ä¸¦èåºç¤æ¨¡åæçºéç¨çåå§æåç¸çç¾ãå æ­¤ï¼çºäºå¢å¼·åå½¢å­¸ç¿ç¤¾ç¾¤å¨è©ä¼° GFM æè·¨é åãä»»ååç ç©¶èè¶£çä¸è´æ§ãæ¶µèç¯ååå¤æ¨£æ§ï¼æåæåº GFMBenchï¼éæ¯ä¸ååå« 26 åè³æéçç³»çµ±åä¸å¨é¢çåºæºãæ­¤å¤ï¼æåä»ç´¹ LangGFMï¼éæ¯ä¸ç¨®å®å¨ä¾è³´å¤§åèªè¨æ¨¡åçæ°ç© GFMãéééæ°æª¢è¦åæ¢ç´¢ææçåå½¢æå­åååï¼ä»¥åå¨èªè¨ç©ºéä¸­éæ°å©ç¨åå½¢æ´åååå½¢èªç£ç£å­¸ç¿çæåæè¡ï¼LangGFM å¨ GFMBench ä¸å¯¦ç¾èç¾ææè¡åç­æè¶è¶ç¾ææè¡çæè½ï¼éå¯ä»¥çºæåæä¾æ°çè§é»ãç¶é©ååºæºï¼ä»¥æ¨å GFM çæ¼é²ã

##### **TransBox: EL++-closed Ontology Embedding**
2410.14571v1 by Hui Yang, Jiaoyan Chen, Uli Sattler

OWL (Web Ontology Language) ontologies, which are able to represent both
relational and type facts as standard knowledge graphs and complex domain
knowledge in Description Logic (DL) axioms, are widely adopted in domains such
as healthcare and bioinformatics. Inspired by the success of knowledge graph
embeddings, embedding OWL ontologies has gained significant attention in recent
years. Current methods primarily focus on learning embeddings for atomic
concepts and roles, enabling the evaluation based on normalized axioms through
specially designed score functions. However, they often neglect the embedding
of complex concepts, making it difficult to infer with more intricate axioms.
This limitation reduces their effectiveness in advanced reasoning tasks, such
as Ontology Learning and ontology-mediated Query Answering. In this paper, we
propose EL++-closed ontology embeddings which are able to represent any logical
expressions in DL via composition. Furthermore, we develop TransBox, an
effective EL++-closed ontology embedding method that can handle many-to-one,
one-to-many and many-to-many relations. Our extensive experiments demonstrate
that TransBox often achieves state-of-the-art performance across various
real-world datasets for predicting complex axioms.

æè¦ï¼OWLï¼Web Ontology Languageï¼æ¬ä½ï¼è½å¤å°å³ç³»åç±»åäºå®è¡¨ç¤ºä¸ºæ åç¥è¯å¾åæè¿°é»è¾ (DL) å¬çä¸­çå¤æé¢åç¥è¯ï¼å¨å»çä¿å¥åçç©ä¿¡æ¯å­¦ç­é¢åå¾å°å¹¿æ³éç¨ãåç¥è¯å¾åµå¥çæåå¯åï¼åµå¥ OWL æ¬ä½è¿å¹´æ¥å¤åå³æ³¨ãå½åæ¹æ³ä¸»è¦éä¸­å¨å­¦ä¹ åå­æ¦å¿µåè§è²çåµå¥ï¼éè¿ä¸é¨è®¾è®¡çè¯åå½æ°ï¼æ¯æåºäºå½ä¸åå¬ççè¯ä¼°ãç¶èï¼å®ä»¬ç»å¸¸å¿½ç¥å¤ææ¦å¿µçåµå¥ï¼è¿ä½¿å¾é¾ä»¥æ¨æ­åºæ´å¤æçå¬çãè¿ç§éå¶éä½äºå®ä»¬å¨é«çº§æ¨çä»»å¡ï¼ä¾å¦æ¬ä½å­¦ä¹ åæ¬ä½ä»å¯¼æ¥è¯¢åºç­ï¼ä¸­çæææ§ãå¨æ¬æä¸­ï¼æä»¬æåºäº EL++ å°é­æ¬ä½åµå¥ï¼å®è½å¤éè¿ç»åæ¥è¡¨ç¤º DL ä¸­çä»»ä½é»è¾è¡¨è¾¾å¼ãæ­¤å¤ï¼æä»¬å¼åäº TransBoxï¼ä¸ç§ææç EL++ å°é­æ¬ä½åµå¥æ¹æ³ï¼å¯ä»¥å¤çå¤å¯¹ä¸ãä¸å¯¹å¤åå¤å¯¹å¤å³ç³»ãæä»¬å¹¿æ³çå®éªè¡¨æï¼TransBox å¨é¢æµå¤æå¬ççåç§çå®ä¸çæ°æ®éä¸éå¸¸é½è½è¾¾å°æåè¿çæ§è½ã

##### **Enabling Scalable Evaluation of Bias Patterns in Medical LLMs**
2410.14763v1 by Hamed Fayyaz, Raphael Poulain, Rahmatollah Beheshti

Large language models (LLMs) have shown impressive potential in helping with
numerous medical challenges. Deploying LLMs in high-stakes applications such as
medicine, however, brings in many concerns. One major area of concern relates
to biased behaviors of LLMs in medical applications, leading to unfair
treatment of individuals. To pave the way for the responsible and impactful
deployment of Med LLMs, rigorous evaluation is a key prerequisite. Due to the
huge complexity and variability of different medical scenarios, existing work
in this domain has primarily relied on using manually crafted datasets for bias
evaluation. In this study, we present a new method to scale up such bias
evaluations by automatically generating test cases based on rigorous medical
evidence. We specifically target the challenges of a) domain-specificity of
bias characterization, b) hallucinating while generating the test cases, and c)
various dependencies between the health outcomes and sensitive attributes. To
that end, we offer new methods to address these challenges integrated with our
generative pipeline, using medical knowledge graphs, medical ontologies, and
customized general LLM evaluation frameworks in our method. Through a series of
extensive experiments, we show that the test cases generated by our proposed
method can effectively reveal bias patterns in Med LLMs at larger and more
flexible scales than human-crafted datasets. We publish a large bias evaluation
dataset using our pipeline, which is dedicated to a few medical case studies. A
live demo of our application for vignette generation is available at
https://vignette.streamlit.app. Our code is also available at
https://github.com/healthylaife/autofair.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¨åå©è§£æ±º
è¨±å¤é«çææ°æ¹é¢çé©äººæ½åãç¶èï¼å¨é«é¢¨éªæç¨ç¨å¼ï¼ä¾å¦
é«çï¼ä¸­é¨ç½² LLM æå¸¶ä¾è¨±å¤çæ®ãä¸åä¸»è¦ççæ®é åè
é«çæç¨ç¨å¼ä¸­ LLM çåè¦è¡çºæéï¼å°è´å°åäººä¸å¬å¹³ç
å¾éãçºäºçºè² è²¬ä»»ä¸æå½±é¿åç Med LLM é¨ç½²éªè·¯ï¼å´è¬¹ç
è©ä¼°æ¯ä¸é ééµåæãç±æ¼ä¸åé«çå ´æ¯çè¤éæ§åè®ç°æ§æ¥µå¤§ï¼
æ­¤é åç¾æçå·¥ä½ä¸»è¦ä¾è³´ä½¿ç¨äººå·¥è£½ä½çè³æéé²è¡åè¦
è©ä¼°ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼å¯ä»¥æ ¹æå´è¬¹çé«ç
è­æèªåç¢çæ¸¬è©¦æ¡ä¾ï¼ä»¥æ´å¤§æ­¤é¡åè¦è©ä¼°ãæåç¹å¥éå°
a) åè¦ç¹å¾µçé åå°å±¬æ§ãb) å¨ç¢çæ¸¬è©¦æ¡ä¾æåºç¾å¹»è¦ºï¼ä»¥å c)
å¥åº·çµæåææå±¬æ§ä¹éçåç¨®ä¾è³´æ§ç­ææ°ãçºæ­¤ï¼æåæä¾
æ°çæ¹æ³ä¾è§£æ±ºéäºææ°ï¼ä¸¦å°å¶èæåççæç®¡éæ´åï¼å¨æåç
æ¹æ³ä¸­ä½¿ç¨é«çç¥è­åãé«çæ¬ä½åèªè¨çéç¨ LLM è©ä¼°æ¶æ§ãéé
ä¸ç³»åå»£æ³çå¯¦é©ï¼æåè¡¨ææåæåºçæ¹æ³ç¢ççæ¸¬è©¦æ¡ä¾å¯ä»¥ææ
æ­ç¤º Med LLM ä¸­çåè¦æ¨¡å¼ï¼å¶è¦æ¨¡æ¯äººå·¥è£½ä½çè³æéæ´å¤§ä¸æ´å·
å½æ§ãæåä½¿ç¨æåçç®¡éç¼å¸äºä¸åå¤§ååè¦è©ä¼°è³æéï¼è©²è³æé
å°ééå°ä¸äºé«çæ¡ä¾ç ç©¶ãæåçå°æåçææç¨ç¨å¼çç¾å ´ç¤ºç¯
å¯å¨ https://vignette.streamlit.app åå¾ãæåçç¨å¼ç¢¼ä¹å¯å¨
https://github.com/healthylaife/autofair åå¾ã

##### **Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning**
2410.14211v2 by Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Wenjie Zhang

Large Language Models (LLMs) have achieved impressive results in various
tasks but struggle with hallucination problems and lack of relevant knowledge,
especially in deep complex reasoning and knowledge-intensive tasks. Knowledge
Graphs (KGs), which capture vast amounts of facts in a structured format, offer
a reliable source of knowledge for reasoning. However, existing KG-based LLM
reasoning methods face challenges like handling multi-hop reasoning,
multi-entity questions, and effectively utilizing graph structures. To address
these issues, we propose Paths-over-Graph (PoG), a novel method that enhances
LLM reasoning by integrating knowledge reasoning paths from KGs, improving the
interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and
multi-entity questions through a three-phase dynamic multi-hop path
exploration, which combines the inherent knowledge of LLMs with factual
knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant
information from the graph exploration first and introduces efficient
three-step pruning techniques that incorporate graph structures, LLM prompting,
and a pre-trained language model (e.g., SBERT) to effectively narrow down the
explored candidate paths. This ensures all reasoning paths contain highly
relevant information captured from KGs, making the reasoning faithful and
interpretable in problem-solving. PoG innovatively utilizes graph structure to
prune the irrelevant noise and represents the first method to implement
multi-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive
experiments on five benchmark KGQA datasets demonstrate PoG outperforms the
state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an
average accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo
surpasses ToG with GPT-4 by up to 23.9%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­åå¾ä»¤äººå°è±¡æ·±å»çææï¼ä½ä»å­å¨å¹»è¦ºåé¡åç¼ºä¹ç¸éç¥è­ï¼å°¤å¶æ¯å¨æ·±åº¦è¤éæ¨çåç¥è­å¯éåä»»åä¸­ãç¥è­åè­ (KG) ä»¥çµæ§åæ ¼å¼æ·åå¤§éäºå¯¦ï¼çºæ¨çæä¾äºå¯é çç¥è­ä¾æºãç¶èï¼ç¾æçåºæ¼ KG ç LLM æ¨çæ¹æ³é¢è¨èçå¤è·³æ¨çãå¤å¯¦é«åé¡åææå©ç¨åçµæ§ç­ææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºåä¸è·¯å¾ (PoG)ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼ééæ´åä¾èª KG çç¥è­æ¨çè·¯å¾ä¾å¢å¼· LLM æ¨çï¼æé« LLM è¼¸åºçå¯è§£éæ§åä¿çæ§ãPoG ééä¸éæ®µåæå¤è·³è·¯å¾æ¢ç´¢ä¾è§£æ±ºå¤è·³åå¤å¯¦é«åé¡ï¼å° LLM çåºæç¥è­èä¾èª KG çäºå¯¦ç¥è­ç¸çµåãçºäºæé«æçï¼PoG é¦åå¾åæ¢ç´¢ä¸­åªé¤ç¡éä¿¡æ¯ï¼ä¸¦å¼å¥äºä¸æ­¥åªææè¡ï¼éäºæè¡çµåäºåçµæ§ãLLM æç¤ºåé è¨ç·´èªè¨æ¨¡åï¼ä¾å¦ï¼SBERTï¼ä¾ææç¸®å°æ¢ç´¢çåé¸è·¯å¾ãéç¢ºä¿äºæææ¨çè·¯å¾é½åå«å¾ KG æ·åçé«åº¦ç¸éä¿¡æ¯ï¼å¾èä½¿æ¨çå¨åé¡è§£æ±ºä¸­å·æä¿çæ§åå¯è§£éæ§ãPoG åµæ°å°å©ç¨åçµæ§ä¾åªé¤ç¡éåªè²ï¼ä¸¦ä»£è¡¨äºå¨ KG ä¸å¯¦ç¾ LLM æ¨çä»»åçå¤å¯¦é«æ·±åº¦è·¯å¾æª¢æ¸¬çç¬¬ä¸ç¨®æ¹æ³ãå¨äºååºæº KGQA æ¸æéä¸çç¶åå¯¦é©è¡¨æï¼PoG å¨ GPT-3.5-Turbo å GPT-4 ä¸çè¡¨ç¾åªæ¼æåé²çæ¹æ³ ToGï¼å¹³åæºç¢ºçæé«äº 18.9%ãå¼å¾æ³¨æçæ¯ï¼ä½¿ç¨ GPT-3.5-Turbo ç PoG æ¯ä½¿ç¨ GPT-4 ç ToG é«åº 23.9%ã

##### **UniMTS: Unified Pre-training for Motion Time Series**
2410.19818v1 by Xiyuan Zhang, Diyan Teng, Ranak Roy Chowdhury, Shuheng Li, Dezhi Hong, Rajesh K. Gupta, Jingbo Shang

Motion time series collected from mobile and wearable devices such as
smartphones and smartwatches offer significant insights into human behavioral
patterns, with wide applications in healthcare, automation, IoT, and AR/XR due
to their low-power, always-on nature. However, given security and privacy
concerns, building large-scale motion time series datasets remains difficult,
preventing the development of pre-trained models for human activity analysis.
Typically, existing models are trained and tested on the same dataset, leading
to poor generalizability across variations in device location, device mounting
orientation and human activity type. In this paper, we introduce UniMTS, the
first unified pre-training procedure for motion time series that generalizes
across diverse device latent factors and activities. Specifically, we employ a
contrastive learning framework that aligns motion time series with text
descriptions enriched by large language models. This helps the model learn the
semantics of time series to generalize across activities. Given the absence of
large-scale motion time series data, we derive and synthesize time series from
existing motion skeleton data with all-joint coverage. Spatio-temporal graph
networks are utilized to capture the relationships across joints for
generalization across different device locations. We further design
rotation-invariant augmentation to make the model agnostic to changes in device
mounting orientations. Our model shows exceptional generalizability across 18
motion time series classification benchmark datasets, outperforming the best
baselines by 340% in the zero-shot setting, 16.3% in the few-shot setting, and
9.2% in the full-shot setting.

æè¦ï¼å¾æºæ§åææ©èæºæ§åæé¶ç­è¡åè£ç½®åç©¿æ´å¼è£ç½®æ¶éçåä½æéåºåï¼ç±æ¼å¶ä½èé»ãæçºéä½çç¹æ§ï¼å¯æä¾äººé¡è¡çºæ¨¡å¼çéè¦è¦è§£ï¼å¨é«çä¿å¥ãèªååãç©è¯ç¶²å AR/XR ä¸­æå»£æ³çæç¨ãç¶èï¼èéå°å®å¨æ§åé±ç§åé¡ï¼å»ºæ§å¤§è¦æ¨¡çåä½æéåºåè³æéä»ç¶å°é£ï¼é»ç¤äºäººé¡æ´»ååæé åè¨ç·´æ¨¡åçç¼å±ãä¸è¬ä¾èªªï¼ç¾æçæ¨¡åæå¨åä¸åè³æéä¸è¨ç·´åæ¸¬è©¦ï¼å°è´ç¡æ³å°è£ç½®ä½ç½®ãè£ç½®å®è£æ¹ååäººé¡æ´»åé¡åçè®åé²è¡è¯å¥½çæ¦åãå¨æ¬æä¸­ï¼æåä»ç´¹ UniMTSï¼éæ¯ç¬¬ä¸åçµ±ä¸çåä½æéåºåé è¨ç·´ç¨åºï¼å¯æ¦åå°ä¸åçè£ç½®æ½å¨å å­åæ´»åãå·é«ä¾èªªï¼æåæ¡ç¨å°æ¯å­¸ç¿æ¶æ§ï¼å°åä½æéåºåèå¤§åèªè¨æ¨¡åè±å¯çæå­æè¿°å°é½ãéæå©æ¼æ¨¡åå­¸ç¿æéåºåçèªç¾©ï¼ä»¥æ¦åå°åç¨®æ´»åãç±æ¼ç¼ºä¹å¤§è¦æ¨¡çåä½æéåºåè³æï¼æåå¾ç¾æçåä½éª¨æ¶è³æä¸­è¡çååææéåºåï¼ä¸¦æ¶µèææéç¯ãæç©ºåå½¢ç¶²è·¯ç¨æ¼æ·åéç¯ä¹éçéä¿ï¼ä»¥æ¦åå°ä¸åçè£ç½®ä½ç½®ãæåé²ä¸æ­¥è¨­è¨äºæè½ä¸è®å¢å¼·ï¼è®æ¨¡åä¸æåè£ç½®å®è£æ¹åè®åçå½±é¿ãæåçæ¨¡åå¨ 18 ååä½æéåºååé¡åºæºè³æéä¸å±ç¾åºåè¶çæ¦åè½åï¼å¨é¶æ¬¡å­¸ç¿è¨­å®ä¸­åªæ¼æä½³åºæº 340%ï¼å¨å°æ¬¡å­¸ç¿è¨­å®ä¸­åªæ¼æä½³åºæº 16.3%ï¼å¨å¨æ¬¡å­¸ç¿è¨­å®ä¸­åªæ¼æä½³åºæº 9.2%ã

##### **Supervised Chain of Thought**
2410.14198v1 by Xiang Zhang, Dujian Ding

Large Language Models (LLMs) have revolutionized natural language processing
and hold immense potential for advancing Artificial Intelligence. However, the
core architecture of most mainstream LLMs -- the Transformer -- has inherent
limitations in computational depth, rendering them theoretically incapable of
solving many reasoning tasks that demand increasingly deep computations. Chain
of Thought (CoT) prompting has emerged as a technique to address these
architectural limitations, as evidenced by several theoretical studies. It
offers a promising approach to solving complex reasoning tasks that were
previously beyond the capabilities of these models. Despite its successes, CoT
and its variants (such as Tree of Thought, Graph of Thought, etc.) rely on a
"one-prompt-for-all" approach, using a single prompt structure (e.g., "think
step by step") for a wide range of tasks -- from counting and sorting to
solving mathematical and algorithmic problems. This approach poses significant
challenges for models to generate the correct reasoning steps, as the model
must navigate through a vast prompt template space to find the appropriate
template for each task. In this work, we build upon previous theoretical
analyses of CoT to demonstrate how the one-prompt-for-all approach can
negatively affect the computability of LLMs. We partition the solution search
space into two: the prompt space and the answer space. Our findings show that
task-specific supervision is essential for navigating the prompt space
accurately and achieving optimal performance. Through experiments with
state-of-the-art LLMs, we reveal a gap in reasoning performance when
supervision is applied versus when it is not.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¾¹åºæ¹è®äºèªç¶èªè¨èçï¼ä¸¦å·åä¿é²äººå·¥æºæ§ç¼å±çå·¨å¤§æ½åãç¶èï¼å¤§å¤æ¸ä¸»æµ LLM çæ ¸å¿æ¶æ§ï¼Transformerï¼å¨è¨ç®æ·±åº¦æ¹é¢æå¶å§å¨éå¶ï¼çè«ä¸ç¡æ³è§£æ±ºè¨±å¤éè¦è¶ä¾è¶æ·±å¥è¨ç®çæ¨çä»»åãæç¶­é (CoT) æç¤ºå·²æçºè§£æ±ºéäºæ¶æ§éå¶çä¸ç¨®æè¡ï¼éå·²ç±å¹¾é çè«ç ç©¶è­å¯¦ãå®æä¾äºä¸åæåéçæ¹æ³ä¾è§£æ±ºè¤éçæ¨çä»»åï¼éäºä»»åä»¥åè¶åºäºéäºæ¨¡åçè½åãåç®¡åå¾äºæåï¼CoT åå¶è®é«ï¼ä¾å¦æç¶­æ¨¹ãæç¶­åç­ï¼ä¾è³´æ¼ãä¸æç¤ºé©ç¨ææãçæ¹æ³ï¼å°åç¨®ä»»åï¼å¾è¨æ¸åæåºå°è§£æ±ºæ¸å­¸åæ¼ç®æ³åé¡ï¼ä½¿ç¨å®ä¸çæç¤ºçµæ§ï¼ä¾å¦ï¼ãéæ­¥æèãï¼ãéç¨®æ¹æ³å°æ¨¡åç¢çæ­£ç¢ºçæ¨çæ­¥é©æ§æäºéå¤§ææ°ï¼å çºæ¨¡åå¿é å¨å»£æ³çæç¤ºç¯æ¬ç©ºéä¸­å°èªï¼æè½çºæ¯åä»»åæ¾å°é©ç¶çç¯æ¬ãå¨éé å·¥ä½ä¸­ï¼æåå»ºç«å¨ CoT ååççè«åæä¹ä¸ï¼èªªæãä¸æç¤ºé©ç¨ææãçæ¹æ³å¦ä½å° LLM çå¯è¨ç®æ§ç¢çè² é¢å½±é¿ãæåå°è§£çæå°ç©ºéåçºå©é¨åï¼æç¤ºç©ºéåç­æ¡ç©ºéãæåçç ç©¶çµæè¡¨æï¼ç¹å®æ¼ä»»åçç£ç£å°æ¼æºç¢ºå°èªæç¤ºç©ºéä¸¦å¯¦ç¾æä½³æè½è³ééè¦ãééä½¿ç¨æåé²ç LLM é²è¡å¯¦é©ï¼æåæ­ç¤ºäºå¨æç¨ç£ç£èæªæç¨ç£ç£ææ¨çæè½çå·®è·ã

##### **Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs**
2410.14057v1 by Simone Conia, Daniel Lee, Min Li, Umar Farooq Minhas, Saloni Potdar, Yunyao Li

Translating text that contains entity names is a challenging task, as
cultural-related references can vary significantly across languages. These
variations may also be caused by transcreation, an adaptation process that
entails more than transliteration and word-for-word translation. In this paper,
we address the problem of cross-cultural translation on two fronts: (i) we
introduce XC-Translate, the first large-scale, manually-created benchmark for
machine translation that focuses on text that contains potentially
culturally-nuanced entity names, and (ii) we propose KG-MT, a novel end-to-end
method to integrate information from a multilingual knowledge graph into a
neural machine translation model by leveraging a dense retrieval mechanism. Our
experiments and analyses show that current machine translation systems and
large language models still struggle to translate texts containing entity
names, whereas KG-MT outperforms state-of-the-art approaches by a large margin,
obtaining a 129% and 62% relative improvement compared to NLLB-200 and GPT-4,
respectively.

æè¦ï¼ç¿»è­¯åå«å¯¦é«åç¨±çæå­æ¯ä¸é å·æææ°æ§çä»»åï¼å çºèæåç¸éçåèå¨ä¸åèªè¨ä¸­å¯è½ææå¾å¤§å·®ç°ãéäºå·®ç°ä¹å¯è½æ¯ç±è½è­¯é æçï¼è½è­¯æ¯ä¸ç¨®æ¹ç·¨éç¨ï¼ä¸åæ¶åé³è­¯åéå­ç¿»è­¯ãå¨æ¬æä¸­ï¼æåå¾å©åæ¹é¢è§£æ±ºè·¨æåç¿»è­¯çåé¡ï¼(i) æåä»ç´¹ XC-Translateï¼éæ¯ç¬¬ä¸åéå°åå«æ½å¨æåç´°å¾®å·®å¥å¯¦é«åç¨±çæå­çå¤§è¦æ¨¡ãäººå·¥å»ºç«çæ©å¨ç¿»è­¯åºæºæ¸¬è©¦ï¼ä»¥å (ii) æåæåº KG-MTï¼éæ¯ä¸ç¨®æ°çç«¯å°ç«¯æ¹æ³ï¼ééå©ç¨å¯éæª¢ç´¢æ©å¶å°ä¾èªå¤èªè¨ç¥è­åè­çè³è¨æ´åå°ç¥ç¶æ©å¨ç¿»è­¯æ¨¡åä¸­ãæåçå¯¦é©ååæè¡¨æï¼ç®åçæ©å¨ç¿»è­¯ç³»çµ±åå¤§åèªè¨æ¨¡åå¨ç¿»è­¯åå«å¯¦é«åç¨±çæå­æä»å­å¨å°é£ï¼è KG-MT åä»¥å¤§å¹åªæ¼æåé²æ¹æ³çåªå¢ååºï¼è NLLB-200 å GPT-4 ç¸æ¯ï¼åå¥ç²å¾äº 129% å 62% çç¸å°æ¹é²ã

##### **RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs**
2410.13987v1 by Jiatan Huang, Mingchen Li, Zonghai Yao, Zhichao Yang, Yongkang Xiao, Feiyun Ouyang, Xiaohan Li, Shuo Han, Hong Yu

Answering complex real-world questions often requires accurate retrieval from
textual knowledge graphs (TKGs). The scarcity of annotated data, along with
intricate topological structures, makes this task particularly challenging. As
the nature of relational path information could enhance the inference ability
of Large Language Models (LLMs), efficiently retrieving more complex relational
path information from TKGs presents another key challenge. To tackle these
challenges, we first develop a Dataset for LLMs Complex Reasoning over Textual
Knowledge Graphs (RiTeK) with a broad topological structure coverage.We
synthesize realistic user queries that integrate diverse topological
structures, relational information, and complex textual descriptions. We
conduct rigorous expert evaluation to validate the quality of our synthesized
queries. And then, we introduce an enhanced Monte Carlo Tree Search (MCTS)
method, Relational MCTS, to automatically extract relational path information
from textual graphs for specific queries. Our dataset mainly covers the medical
domain as the relation types and entity are complex and publicly available.
Experimental results indicate that RiTeK poses significant challenges for
current retrieval and LLM systems, while the proposed Relational MCTS method
enhances LLM inference ability and achieves state-of-the-art performance on
RiTeK.

æè¦ï¼åç­è¤éçç¾å¯¦ä¸çåé¡éå¸¸éè¦å¾ææ¬ç¥è­å (TKG) ä¸­æºç¢ºæ·åãæ¨è¨»è³æçç¨å°ï¼å ä¸è¤éçææ²çµæ§ï¼ä½¿å¾éé ä»»åç¹å¥å·æææ°æ§ãç±æ¼éä¿è·¯å¾è³è¨çæ§è³ªå¯ä»¥å¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ¨è«è½åï¼å¾ TKG ææå°æ·åæ´è¤éçéä¿è·¯å¾è³è¨æåºäºå¦ä¸åééµææ°ãçºäºæå°éäºææ°ï¼æåé¦åéç¼äºä¸åå·æå»£æ³ææ²çµæ§æ¶µèç¯åçææ¬ç¥è­å (RiTeK) ä¸ç LLM è¤éæ¨çè³æéãæåç¶åäºæ´åäºå¤æ¨£åææ²çµæ§ãéä¿è³è¨åè¤éææ¬æè¿°çç¾å¯¦ä½¿ç¨èæ¥è©¢ãæåé²è¡å´æ ¼çå°å®¶è©ä¼°ï¼ä»¥é©è­æåç¶åæ¥è©¢çåè³ªãç¶å¾ï¼æåå¼å¥ä¸ç¨®å¢å¼·çèå°å¡ç¾æ¨¹æå° (MCTS) æ¹æ³ï¼å³éä¿ MCTSï¼ä»¥èªåå¾ææ¬åä¸­æ·åç¹å®æ¥è©¢çéä¿è·¯å¾è³è¨ãæåçè³æéä¸»è¦æ¶µèé«çé åï¼å çºéä¿é¡ååå¯¦é«å¾è¤éä¸å¬éå¯ç¨ãå¯¦é©çµæè¡¨æï¼RiTeK å°ç®åçæ·åå LLM ç³»çµ±æåºäºéå¤§ææ°ï¼èææåºçéä¿ MCTS æ¹æ³å¢å¼·äº LLM æ¨è«è½åï¼ä¸¦å¨ RiTeK ä¸éå°äºæåé²çæè½ã

##### **The Mystery of the Pathological Path-star Task for Language Models**
2410.13779v1 by Arvid Frydenlund

The recently introduced path-star task is a minimal task designed to
exemplify limitations to the abilities of language models (Bachmann and
Nagarajan, 2024). It involves a path-star graph where multiple arms radiate
from a single starting node and each node is unique. Given the start node and a
specified target node that ends an arm, the task is to generate the arm
containing that target node. This is straightforward for a human but
surprisingly difficult for language models, which did not outperform the random
baseline. The authors hypothesized this is due to a deficiency in
teacher-forcing and the next-token prediction paradigm.
  We demonstrate the task is learnable using teacher-forcing in alternative
settings and that the issue is partially due to representation. We introduce a
regularization method using structured samples of the same graph but with
differing target nodes, improving results across a variety of model types. We
provide RASP proofs showing the task is theoretically solvable. Finally, we
find settings where an encoder-only model can consistently solve the task.

æè¦ï¼æè¿æ¨åºçè·¯å¾æå½¢ä»»åæ¯ä¸åæ¥µç°¡ä»»åï¼æ¨å¨èªªæèªè¨æ¨¡åè½åçéå¶ï¼Bachmann å Nagarajanï¼2024 å¹´ï¼ãå®æ¶åä¸åè·¯å¾æå½¢åï¼å¶ä¸­å¤ååæ¯å¾ä¸åèµ·å§ç¯é»è¼»å°åºå»ï¼æ¯åç¯é»é½æ¯å¯ä¸çãçµ¦å®èµ·å§ç¯é»åçµæä¸ååæ¯çæå®ç®æ¨ç¯é»ï¼ä»»åæ¯çæåå«è©²ç®æ¨ç¯é»çåæ¯ãéå°äººé¡ä¾èªªå¾ç°¡å®ï¼ä½å°èªè¨æ¨¡åä¾èªªå»ç°ä¹å°å¸¸å°å°é£ï¼å çºèªè¨æ¨¡åä¸¦æªåªæ¼é¨æ©åºæºç·ãä½èåè¨­éæ¯ç±æ¼æå¸«å¼·å¶åä¸ä¸åç¬¦èé æ¸¬ç¯ä¾çä¸è¶³ã
æåå±ç¤ºäºè©²ä»»åå¯ä»¥ä½¿ç¨æ¿ä»£è¨­ç½®ä¸­çæå¸«å¼·å¶ä¾å­¸ç¿ï¼ä¸¦ä¸åé¡é¨åæ¯ç±æ¼è¡¨ç¤ºãæåå¼å¥äºä¸ç¨®æ­£ååæ¹æ³ï¼ä½¿ç¨åä¸åå½¢ççµæ§åæ¨£æ¬ï¼ä½ç®æ¨ç¯é»ä¸åï¼å¾èæ¹é²äºåç¨®æ¨¡åé¡åççµæãæåæä¾äº RASP è­æï¼è¡¨æè©²ä»»åå¨çè«ä¸æ¯å¯ä»¥è§£æ±ºçãæå¾ï¼æåæ¾å°äºåç·¨ç¢¼å¨æ¨¡åå¯ä»¥æçºè§£æ±ºä»»åçè¨­ç½®ã

##### **Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**
2410.13765v1 by Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan A. Rossi, Haoliang Wang, Julian McAuley

Large language models (LLMs) have been used to generate query expansions
augmenting original queries for improving information search. Recent studies
also explore providing LLMs with initial retrieval results to generate query
expansions more grounded to document corpus. However, these methods mostly
focus on enhancing textual similarities between search queries and target
documents, overlooking document relations. For queries like "Find me a highly
rated camera for wildlife photography compatible with my Nikon F-Mount lenses",
existing methods may generate expansions that are semantically similar but
structurally unrelated to user intents. To handle such semi-structured queries
with both textual and relational requirements, in this paper we propose a
knowledge-aware query expansion framework, augmenting LLMs with structured
document relations from knowledge graph (KG). To further address the limitation
of entity-based scoring in existing KG-based methods, we leverage document
texts as rich KG node representations and use document-based relation filtering
for our Knowledge-Aware Retrieval (KAR). Extensive experiments on three
datasets of diverse domains show the advantages of our method compared against
state-of-the-art baselines on textual and relational semi-structured retrieval.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ç¨æ¼ç¢çæ¥è©¢æ´åï¼èä»¥æ´ååå§æ¥è©¢ï¼ä»¥æ¹åè³è¨æå°ãæè¿çç ç©¶ä¹æ¢è¨æä¾ LLM åå§æª¢ç´¢çµæï¼ä»¥ç¢çæ´è²¼è¿æä»¶èªæåº«çæ¥è©¢æ´åãç¶èï¼éäºæ¹æ³å¤§å¤èéæ¼å å¼·æå°æ¥è©¢èç®æ¨æä»¶ä¹éçæå­ç¸ä¼¼æ§ï¼èå¿½ç¥äºæä»¶éä¿ãå°æ¼ãå¹«ææ¾ä¸å°èæç Nikon F-Mount é¡é ­ç¸å®¹ãè©å¹å¾é«çéçåç©æå½±ç¸æ©ãç­æ¥è©¢ï¼ç¾ææ¹æ³å¯è½æç¢çèªç¾©ä¸ç¸ä¼¼ä½çµæ§ä¸èä½¿ç¨èæåç¡éçæ´åãçºäºèçå·ææå­åéä¿éæ±çæ­¤é¡åçµæ§åæ¥è©¢ï¼æåå¨æ¬æä¸­æåºä¸åç¥è­æç¥æ¥è©¢æ´åæ¶æ§ï¼å©ç¨ç¥è­åè­ (KG) ä¸­ççµæ§åæä»¶éä¿æ´å LLMãçºäºé²ä¸æ­¥è§£æ±ºç¾æåºæ¼ KG çæ¹æ³ä¸­åºæ¼å¯¦é«çè©åéå¶ï¼æåå©ç¨æä»¶æå­ä½çºè±å¯ç KG ç¯é»è¡¨å¾µï¼ä¸¦ä½¿ç¨åºæ¼æä»¶çéä¿ç¯©é¸ï¼é²è¡æåçç¥è­æç¥æª¢ç´¢ (KAR)ãéå°ä¸åä¸åé åè³æéé²è¡çå»£æ³å¯¦é©é¡¯ç¤ºï¼æåçæ¨¡åèæå­åéä¿åçµæ§åæª¢ç´¢çææ°åºæºç¸æ¯ï¼å·æåªå¢ã

##### **LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models**
2410.13299v1 by David Hoffmann, Kailash Budhathoki, Matthaeus Kleindessner

The evolving capabilities of large language models are accompanied by growing
sizes and deployment costs, necessitating effective inference optimisation
techniques. We propose a novel pruning method utilising centrality measures
from graph theory, reducing both the computational requirements and the memory
footprint of these models. Specifically, we devise a method for creating a
weighted directed acyclical graph representation of multilayer perceptrons to
which we apply a modified version of the weighted PageRank centrality measure
to compute node importance scores. In combination with uniform pruning this
leads to structured sparsity. We call this pruning method MLPRank. Furthermore
we introduce an extension to decoder-only transformer models and call it
LLMRank. For both variants we demonstrate a strong performance. With MLPRank on
average leading to 6.09 % higher accuracy retention than three popular
baselines and 13.42 % with LLMRank compared to two popular baselines.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡ååè½çæ¼é²ï¼æ¨¡åè¦æ¨¡èé¨ç½²ææ¬ä¹é¨ä¹å¢å ï¼å æ­¤éè¦ææçæ¨è«æä½³åæè¡ãæåæåºä¸ååµæ°çä¿®åªæ¹æ³ï¼å©ç¨åè«ä¸­çä¸­å¿æ§æ¸¬éï¼åææ¸å°éäºæ¨¡åçéç®éæ±åè¨æ¶é«ä½¿ç¨éãå·é«ä¾èªªï¼æåè¨­è¨äºä¸ç¨®æ¹æ³ï¼ç¨æ¼å»ºç«å¤å±¤æç¥å¨çå æ¬æåç¡ç°åè¡¨ç¤ºï¼ä¸¦å°å¶å¥ç¨å æ¬ PageRank ä¸­å¿æ§æ¸¬éçä¿®æ¹çæ¬ï¼ä»¥è¨ç®ç¯é»éè¦æ§åæ¸ãçµååå»ä¿®åªï¼éå°å°è´çµæ§åç¨çæ§ãæåç¨±éç¨®ä¿®åªæ¹æ³çº MLPRankãæ­¤å¤ï¼æåéå¼å¥äºåè§£ç¢¼å¨Transformeræ¨¡åçå»¶ä¼¸ï¼ä¸¦ç¨±ä¹çº LLMRankãå°æ¼éå©ç¨®è®é«ï¼æåé½å±ç¤ºäºå¼·å¤§çæè½ãMLPRank å¹³åæ¯ä¸ç¨®æµè¡åºæºé«åº 6.09% çæºç¢ºæ§ä¿ççï¼è LLMRank åæ¯å©ç¨®æµè¡åºæºé«åº 13.42%ã

##### **Trust but Verify: Programmatic VLM Evaluation in the Wild**
2410.13121v1 by Viraj Prabhu, Senthil Purushwalkam, An Yan, Caiming Xiong, Ran Xu

Vision-Language Models (VLMs) often generate plausible but incorrect
responses to visual queries. However, reliably quantifying the effect of such
hallucinations in free-form responses to open-ended queries is challenging as
it requires visually verifying each claim within the response. We propose
Programmatic VLM Evaluation (PROVE), a new benchmarking paradigm for evaluating
VLM responses to open-ended queries. To construct PROVE, we provide a large
language model (LLM) with a high-fidelity scene-graph representation
constructed from a hyper-detailed image caption, and prompt it to generate
diverse question-answer (QA) pairs, as well as programs that can be executed
over the scene graph object to verify each QA pair. We thus construct a
benchmark of 10.5k challenging but visually grounded QA pairs. Next, to
evaluate free-form model responses to queries in PROVE, we propose a
programmatic evaluation strategy that measures both the helpfulness and
truthfulness of a response within a unified scene graph-based framework. We
benchmark the helpfulness-truthfulness trade-offs of a range of VLMs on PROVE,
finding that very few are in-fact able to achieve a good balance between the
two. Project page: \url{https://prove-explorer.netlify.app/}.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) ç¶å¸¸å°è¦è¦ºæ¥è©¢ç¢ççä¼¼åçä½é¯èª¤çåæãç¶èï¼å¯é å°éåæ­¤é¡å¹»è¦ºå¨éæ¾å¼æ¥è©¢çèªç±å½¢å¼åæä¸­çå½±é¿å·æææ°æ§ï¼å çºééè¦è¦è¦ºé©è­åæä¸­çæ¯åèªªæ³ãæåæåºç¨å¼å VLM è©ä¼° (PROVE)ï¼ä¸ç¨®ç¨æ¼è©ä¼° VLM å°éæ¾å¼æ¥è©¢çåæçæ°åºæºç¯ä¾ãçºäºå»ºæ§ PROVEï¼æåæä¾ä¸åå¤§åèªè¨æ¨¡å (LLM) ä¸åç±è¶è©³ç´°å½±åæ¨é¡å»ºæ§çé«ä¿çå ´æ¯åè¡¨ç¤ºï¼ä¸¦æç¤ºå®ç¢çå¤æ¨£åçåç­ (QA) éå°ï¼ä»¥åå¯ä»¥å¨å ´æ¯åç©ä»¶ä¸å·è¡çç¨å¼ï¼ä»¥é©è­æ¯å QA éå°ãå æ­¤ï¼æåå»ºæ§äºä¸åç± 10.5k åå·æææ°æ§ä½è¦è¦ºä¸åçç QA éå°çµæçåºæºãæ¥ä¸ä¾ï¼çºäºè©ä¼° PROVE ä¸­çæ¥è©¢çèªç±å½¢å¼æ¨¡ååæï¼æåæåºäºä¸åç¨å¼åè©ä¼°ç­ç¥ï¼è©²ç­ç¥å¨ä¸åçµ±ä¸çåºæ¼å ´æ¯åçæ¡æ¶ä¸­è¡¡éåæçæç¨æ§åçå¯¦æ§ãæåå¨ PROVE ä¸å°ä¸ç³»å VLM çæç¨æ§-çå¯¦æ§æ¬è¡¡é²è¡åºæºæ¸¬è©¦ï¼ç¼ç¾äºå¯¦ä¸å¾å°æ VLM è½å¨å©èä¹éåå¾è¯å¥½çå¹³è¡¡ãå°æ¡é é¢ï¼\url{https://prove-explorer.netlify.app/}ã

##### **Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models**
2410.13080v1 by Linhao Luo, Zicheng Zhao, Chen Gong, Gholamreza Haffari, Shirui Pan

Large language models (LLMs) have demonstrated impressive reasoning
abilities, but they still struggle with faithful reasoning due to knowledge
gaps and hallucinations. To address these issues, knowledge graphs (KGs) have
been utilized to enhance LLM reasoning through their structured knowledge.
However, existing KG-enhanced methods, either retrieval-based or agent-based,
encounter difficulties in accurately retrieving knowledge and efficiently
traversing KGs at scale. In this work, we introduce graph-constrained reasoning
(GCR), a novel framework that bridges structured knowledge in KGs with
unstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures
faithful KG-grounded reasoning by integrating KG structure into the LLM
decoding process through KG-Trie, a trie-based index that encodes KG reasoning
paths. KG-Trie constrains the decoding process, allowing LLMs to directly
reason on graphs and generate faithful reasoning paths grounded in KGs.
Additionally, GCR leverages a lightweight KG-specialized LLM for
graph-constrained reasoning alongside a powerful general LLM for inductive
reasoning over multiple reasoning paths, resulting in accurate reasoning with
zero reasoning hallucination. Extensive experiments on several KGQA benchmarks
demonstrate that GCR achieves state-of-the-art performance and exhibits strong
zero-shot generalizability to unseen KGs without additional training.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²å±ç¾åºä»¤äººå°è±¡æ·±å»çæ¨çè½åï¼ä½ç±æ¼ç¥è­å·®è·åå¹»è¦ºï¼å®åå¨å¿ å¯¦æ¨çæ¹é¢ä»å­å¨å°é£ãçºäºè§£æ±ºéäºåé¡ï¼ç¥è­åè­ï¼KGï¼å·²è¢«ç¨æ¼ééå¶çµæ§åç¥è­å¢å¼· LLM æ¨çãç¶èï¼ç¾æç KG å¢å¼·æ¹æ³ï¼ç¡è«æ¯åºæ¼æª¢ç´¢æåºæ¼ä»£çï¼å¨æºç¢ºæª¢ç´¢ç¥è­åææéæ­·å¤§è¦æ¨¡ KG æé½æéå°å°é£ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºåç´ææ¨çï¼GCRï¼ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®å° KG ä¸­ççµæ§åç¥è­è LLM ä¸­çéçµæ§åæ¨çè¯ç¹«èµ·ä¾ãçºäºæ¶é¤å¹»è¦ºï¼GCR ééå° KG çµæ§æ´åå° LLM è§£ç¢¼éç¨ä¸­ï¼éé KG-Trieï¼ä¸ç¨®ç·¨ç¢¼ KG æ¨çè·¯å¾çåºæ¼ Trie çç´¢å¼ï¼ä¾ç¢ºä¿å¿ å¯¦çåºæ¼ KG çæ¨çãKG-Trie ç´æäºè§£ç¢¼éç¨ï¼åè¨± LLM ç´æ¥å¨åå½¢ä¸æ¨çï¼ä¸¦çæåºæ¼ KG çå¿ å¯¦æ¨çè·¯å¾ãæ­¤å¤ï¼GCR é¤äºå©ç¨ä¸ååè½å¼·å¤§çéç¨ LLM é²è¡å¤éæ¨çè·¯å¾çæ­¸ç´æ¨çä¹å¤ï¼éå©ç¨äºä¸åè¼éç´ç KG å°ç¨ LLM é²è¡åç´ææ¨çï¼å¾èå¯¦ç¾äºæºç¢ºæ¨çï¼ä¸é¶æ¨çå¹»è¦ºãå¨å¹¾å KGQA åºæºä¸é²è¡çå¤§éå¯¦é©è­æï¼GCR éå°äºæåé²çæè½ï¼ä¸¦å¨æ²æé¡å¤è¨ç·´çææ³ä¸å°æªè¦éç KG è¡¨ç¾åºå¼·å¤§çé¶æ¬¡æ¹æ³åè½åã

##### **Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models**
2410.13051v1 by Tong Liu, Hadi Meidani

Supply chain networks are critical to the operational efficiency of
industries, yet their increasing complexity presents significant challenges in
mapping relationships and identifying the roles of various entities.
Traditional methods for constructing supply chain networks rely heavily on
structured datasets and manual data collection, limiting their scope and
efficiency. In contrast, recent advancements in Natural Language Processing
(NLP) and large language models (LLMs) offer new opportunities for discovering
and analyzing supply chain networks using unstructured text data. This paper
proposes a novel approach that leverages LLMs to extract and process raw
textual information from publicly available sources to construct a
comprehensive supply chain graph. We focus on the civil engineering sector as a
case study, demonstrating how LLMs can uncover hidden relationships among
companies, projects, and other entities. Additionally, we fine-tune an LLM to
classify entities within the supply chain graph, providing detailed insights
into their roles and relationships. The results show that domain-specific
fine-tuning improves classification accuracy, highlighting the potential of
LLMs for industry-specific supply chain analysis. Our contributions include the
development of a supply chain graph for the civil engineering sector, as well
as a fine-tuned LLM model that enhances entity classification and understanding
of supply chain networks.

æè¦ï¼ä¾æéç¶²è·¯å°æ¼ç¢æ¥­ççéæçè³ééè¦ï¼ä½å®åæ¥çå¢å çè¤éæ§å¨ç¹ªè£½éä¿ååæ¾åºååå¯¦é«çè§è²æ¹é¢å¸¶ä¾äºéå¤§çææ°ã
å»ºæ§ä¾æéç¶²è·¯çå³çµ±æ¹æ³æ¥µåº¦ä»°è³´çµæ§åè³æéåæåè³ææ¶éï¼éå¶äºå®åçç¯ååæçãç¸åå°ï¼èªç¶èªè¨èç (NLP) åå¤§åèªè¨æ¨¡å (LLM) çè¿æé²å±çºä½¿ç¨éçµæ§åæå­è³æç¼ç¾ååæä¾æéç¶²è·¯æä¾äºæ°çæ©æãéç¯è«ææåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼å®éç¨ LLM å¾å¬éå¯å¾çä¾æºä¸­èååèçåå§æå­è³è¨ï¼ä»¥å»ºæ§ä¸åå¨é¢çä¾æéåãæåå°æ³¨æ¼åæ¨å·¥ç¨é¨éä½çºä¸åæ¡ä¾ç ç©¶ï¼å±ç¤º LLM å¦ä½æ­ç¤ºå¬å¸ãå°æ¡åå¶ä»å¯¦é«ä¹éçé±èéä¿ãæ­¤å¤ï¼æåå¾®èª¿ä¸å LLM ä»¥åé¡ä¾æéåä¸­çå¯¦é«ï¼æä¾æ·±å¥çè¦è§£ï¼äºè§£å®åçè§è²åéä¿ãçµæé¡¯ç¤ºï¼ç¹å®é åçå¾®èª¿æ¹é²äºåé¡çæºç¢ºæ§ï¼çªé¡¯äº LLM å¨ç¢æ¥­ç¹å®ä¾æéåæä¸­çæ½åãæåçè²¢ç»åæ¬éç¼äºä¸åéå°åæ¨å·¥ç¨é¨éçä¾æéåï¼ä»¥åä¸åå¾®èª¿éç LLM æ¨¡åï¼å®å¢å¼·äºå¯¦é«åé¡åå°ä¾æéç¶²è·¯çäºè§£ã

##### **Learning Representations for Reasoning: Generalizing Across Diverse Structures**
2410.13018v1 by Zhaocheng Zhu

Reasoning, the ability to logically draw conclusions from existing knowledge,
is a hallmark of human. Together with perception, they constitute the two major
themes of artificial intelligence. While deep learning has pushed the limit of
perception beyond human-level performance, the progress in reasoning domains is
way behind. One fundamental reason is that reasoning problems usually have
flexible structures for both knowledge and queries, and many existing models
only perform well on structures seen during training. Here we aim to push the
boundary of reasoning models by devising algorithms that generalize across
knowledge and query structures, as well as systems that accelerate development
on structured data. This thesis consists of three parts. In Part I, we study
models that can inductively generalize to unseen knowledge graphs with new
entity and relation vocabularies. For new entities, we propose a framework that
learns neural operators in a dynamic programming algorithm computing path
representations. For relations, we construct a relation graph to capture the
interactions between relations, thereby converting new relations into new
entities. In Part II, we propose two solutions for generalizing across
multi-step queries on knowledge graphs and text respectively. For knowledge
graphs, we show that multi-step queries can be solved by multiple calls of
graph neural networks and fuzzy logic operations. For text, we devise an
algorithm to learn explicit knowledge as textual rules to improve large
language models on multi-step queries. In Part III, we propose two systems to
facilitate machine learning development on structured data. Our library treats
structured data as first-class citizens and removes the barrier for developing
algorithms on structured data. Our node embedding system solves the GPU memory
bottleneck of embedding matrices and scales to graphs with billion nodes.

æè¦ï¼<paragraph>æ¨çï¼å¾ç¾æç¥è­ä¸­éè¼¯å°å¾åºçµè«çè½åï¼æ¯äººé¡çæ¨èªãå®åèæç¥ä¸èµ·æ§æäººå·¥æºæ§çå©åä¸»è¦ä¸»é¡ãåç®¡æ·±åº¦å­¸ç¿å·²å°æç¥çæ¥µéæ¨è³è¶è¶äººé¡å±¤ç´çè¡¨ç¾ï¼ä½æ¨çé åçé²å±å»é é è½å¾ãä¸ååºæ¬åå æ¯æ¨çåé¡éå¸¸å°ç¥è­åæ¥è©¢é½æéæ´»ççµæ§ï¼èè¨±å¤ç¾ææ¨¡ååªå¨è¨ç·´æéçå°ççµæ§ä¸­è¡¨ç¾è¯å¥½ãå¨éè£¡ï¼æåæ¨å¨ééè¨­è¨è·¨ç¥è­åæ¥è©¢çµæ§é²è¡æ¦æ¬çæ¼ç®æ³ï¼ä»¥åå éçµæ§åè³æéç¼çç³»çµ±ï¼ä¾æ¨åæ¨çæ¨¡åççéãæ¬è«æåçºä¸é¨åãå¨ç¬¬ä¸é¨åï¼æåç ç©¶å¯ä»¥æ­¸ç´æ¦æ¬å°å·ææ°å¯¦é«åéä¿è©å½çæ°ç¥è­åè¡¨çæ¨¡åãå°æ¼æ°å¯¦é«ï¼æåæåºä¸åå¨åæè¦åæ¼ç®æ³ä¸­å­¸ç¿ç¥ç¶éç®å­çæ¡æ¶ï¼è¨ç®è·¯å¾è¡¨ç¤ºãå°æ¼éä¿ï¼æåæ§å»ºä¸åéä¿åä¾ææéä¿ä¹éçäºåï¼å¾èå°æ°éä¿è½æçºæ°å¯¦é«ãå¨ç¬¬äºé¨åï¼æåæåºå©åè§£æ±ºæ¹æ¡ï¼åå¥éå°ç¥è­åè¡¨åææ¬ä¸çå¤æ­¥é©æ¥è©¢é²è¡æ¦æ¬ãå°æ¼ç¥è­åè¡¨ï¼æåè¡¨æå¤æ­¥é©æ¥è©¢å¯ä»¥ééå¤æ¬¡å¼å«åç¥ç¶ç¶²è·¯åæ¨¡ç³éè¼¯éç®ä¾è§£æ±ºãå°æ¼ææ¬ï¼æåè¨­è¨äºä¸ç¨®æ¼ç®æ³ä¾å­¸ç¿æç¢ºçç¥è­ä½çºææ¬è¦åï¼ä»¥æ¹åå¤§åèªè¨æ¨¡åå¨å¤æ­¥é©æ¥è©¢ä¸çè¡¨ç¾ãå¨ç¬¬ä¸é¨åï¼æåæåºå©åç³»çµ±ï¼ä»¥ä¿é²çµæ§åè³æä¸çæ©å¨å­¸ç¿éç¼ãæåçç¨å¼åº«å°çµæ§åè³æè¦çºä¸ç´å¬æ°ï¼ä¸¦æ¶é¤äºå¨çµæ§åè³æä¸éç¼æ¼ç®æ³çéç¤ãæåçç¯é»åµå¥ç³»çµ±è§£æ±ºäºåµå¥ç©é£ç GPU è¨æ¶é«ç¶é ¸ï¼ä¸¦æ´åå°å·æåååç¯é»çåè¡¨ã</paragraph>

##### **Large Language Models as a Tool for Mining Object Knowledge**
2410.12959v1 by Hannah YoungEun An, Lenhart K. Schubert

Commonsense knowledge is essential for machines to reason about the world.
Large language models (LLMs) have demonstrated their ability to perform almost
human-like text generation. Despite this success, they fall short as
trustworthy intelligent systems, due to the opacity of the basis for their
answers and a tendency to confabulate facts when questioned about obscure
entities or technical domains. We hypothesize, however, that their general
knowledge about objects in the everyday world is largely sound. Based on that
hypothesis, this paper investigates LLMs' ability to formulate explicit
knowledge about common physical artifacts, focusing on their parts and
materials. Our work distinguishes between the substances that comprise an
entire object and those that constitute its parts$\unicode{x2014}$a previously
underexplored distinction in knowledge base construction. Using few-shot with
five in-context examples and zero-shot multi-step prompting, we produce a
repository of data on the parts and materials of about 2,300 objects and their
subtypes. Our evaluation demonstrates LLMs' coverage and soundness in
extracting knowledge. This contribution to knowledge mining should prove useful
to AI research on reasoning about object structure and composition and serve as
an explicit knowledge source (analogous to knowledge graphs) for LLMs
performing multi-hop question answering.

æè¦ï¼å¸¸è­ç¥è­å°æ¼æ©å¨æ¨çä¸çæ¯ä¸å¯æç¼ºçã
å¤§åèªè¨æ¨¡å (LLM) å·²ç¶å±ç¤ºåºå®åå·è¡å¹¾ä¹åäººé¡ä¸æ¨£çæå­ç¢ççè½åãåç®¡æéæ¨£çæåï¼å®åä½çºå¯ä¿¡è³´çæºæ§ç³»çµ±ä»ç¶ææä¸è¶³ï¼å çºå®åçç­æ¡åºç¤ä¸éæï¼èä¸å¨è¢«ååæ¨¡ç³å¯¦é«ææè¡é åæï¼å®åææé äºå¯¦çå¾åãç¶èï¼æååè¨­å®åå°æ¼æ¥å¸¸ä¸çä¸­ç©é«çä¸è¬ç¥è­å¨å¾å¤§ç¨åº¦ä¸æ¯åççãåºæ¼è©²åè¨­ï¼æ¬ææ¢è¨äº LLM å°æ¥å¸¸ç©çè£½åçæç¢ºç¥è­å¬å¼åçè½åï¼éé»éæ³¨å®åçé¶ä»¶åææãæåçç ç©¶ååäºæ§ææ´åç©é«çç©è³ªåæ§æå¶é¶ä»¶çç©è³ªï¼éæ¯ä¸åç¥è­åº«å»ºæ§ä¸­ä»¥åæªæ¾æ¢è¨éçåå¥ãä½¿ç¨å°æ¬¡å­¸ç¿ï¼åæ¬äºåæå¢ç¯ä¾åé¶æ¬¡å­¸ç¿å¤æ­¥é©æç¤ºï¼æåç¢çäºä¸åè³æåº«ï¼å¶ä¸­åå«ç´ 2,300 åç©é«åå¶å­é¡åçé¶ä»¶åææãæåçè©ä¼°å±ç¤ºäº LLM å¨æåç¥è­æ¹é¢çæ¶µèç¯ååå¥å¨æ§ãéåç¥è­ææçè²¢ç»å°æ¼ AI ç ç©¶æ¨çç©é«çµæ§åçµææè©²æ¯æç¨çï¼ä¸¦ä½çº LLM å·è¡å¤è·³åé¡è§£ç­çæç¢ºç¥è­ä¾æºï¼é¡ä¼¼æ¼ç¥è­åè­ï¼ã

##### **FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**
2410.12707v1 by Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu

To alleviate hardware scarcity in training large deep neural networks (DNNs),
particularly large language models (LLMs), we present FusionLLM, a
decentralized training system designed and implemented for training DNNs using
geo-distributed GPUs across different computing clusters or individual devices.
Decentralized training faces significant challenges regarding system design and
efficiency, including: 1) the need for remote automatic differentiation (RAD),
2) support for flexible model definitions and heterogeneous software, 3)
heterogeneous hardware leading to low resource utilization or the straggler
problem, and 4) slow network communication. To address these challenges, in the
system design, we represent the model as a directed acyclic graph of operators
(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the
edge represents the data dependency between operators. Based on this design, 1)
users are allowed to customize any DNN without caring low-level operator
implementation; 2) we enable the task scheduling with the more fine-grained
sub-tasks, offering more optimization space; 3) a DAG runtime executor can
implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an
OP-Fence scheduler to cluster devices with similar bandwidths together and
partition the DAG to increase throughput. Additionally, we propose an AdaTopK
compressor to adaptively compress intermediate activations and gradients at the
slowest communication links. To evaluate the convergence and efficiency of our
system and algorithms, we train ResNet-101 and GPT-2 on three real-world
testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental
results demonstrate that our system and method can achieve 1.45 - 9.39x speedup
compared to baseline methods while ensuring convergence.

æè¦ï¼<paragraph>çºäºæ¸è¼è¨ç·´å¤§åæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¡¬é«ç­ç¼ºåé¡ï¼å°¤å¶æ¯å¤§åèªè¨æ¨¡å (LLM)ï¼æåæåºäº FusionLLMï¼ä¸ååæ£å¼è¨ç·´ç³»çµ±ï¼å¶è¨­è¨åå¯¦ä½æ¯ç¨æ¼è¨ç·´è·¨ä¸åéç®å¢éæåå¥è£ç½®çå°çåæ£å¼ GPU ç DNNãåæ£å¼è¨ç·´å¨ç³»çµ±è¨­è¨åæçæ¹é¢é¢è¨éå¤§ææ°ï¼åæ¬ï¼1) éè¦é ç«¯èªåå¾®å (RAD)ï¼2) æ¯æ´å½æ§çæ¨¡åå®ç¾©åç°è³ªè»é«ï¼3) ç°è³ªç¡¬é«å°è´è³æºå©ç¨çä½æè½å¾åé¡ï¼ä»¥å 4) ç¶²è·¯éè¨éåº¦æ¢ãçºäºæå°éäºææ°ï¼å¨ç³»çµ±è¨­è¨ä¸­ï¼æåå°æ¨¡åè¡¨ç¤ºçºä¸åæåéå¾ªç°å (OP-DAG) çéç®å­ãDAG ä¸­çæ¯åç¯é»ä»£è¡¨ DNN ä¸­çéç®å­ï¼èéç·£ä»£è¡¨éç®å­ä¹éçè³æä¾è³´æ§ãåºæ¼æ­¤è¨­è¨ï¼1) ä½¿ç¨èå¯ä»¥èªè¨ä»»ä½ DNNï¼èä¸ç¨èæ®ä½ééç®å­å¯¦ä½ï¼2) æååç¨ä»»åæç¨ï¼ä¸¦ä½¿ç¨æ´ç´°ç·»çå­ä»»åï¼æä¾æ´å¤æä½³åç©ºéï¼3) DAG å·è¡æéå·è¡å¨å¯ä»¥å¯¦ä½ RADï¼èä¸éè¦ä¸è´çä½é ML æ¶æ§çæ¬ãçºäºæåç³»çµ±æçï¼æåå¯¦ä½ä¸åå·¥ä½è² è¼ä¼°è¨å¨ï¼ä¸¦è¨­è¨ä¸å OP-Fence æç¨å¨ï¼å°é »å¯¬é¡ä¼¼çè£ç½®åçµå¨ä¸èµ·ï¼ä¸¦åå² DAG ä»¥å¢å èçéãæ­¤å¤ï¼æåæåºä¸å AdaTopK å£ç¸®å¨ï¼ä»¥èªé©ææ¹å¼å£ç¸®ææ¢éè¨é£çµä¸çä¸­éåååæ¢¯åº¦ãçºäºè©ä¼°æåç³»çµ±åæ¼ç®æ³çæ¶ææ§åæçï¼æåå¨ä¸åçå¯¦ä¸ççæ¸¬è©¦å¹³å°ä¸è¨ç·´ ResNet-101 å GPT-2ï¼ä½¿ç¨ 48 å GPU é£æ¥å° 8 Mbps~10 Gbps ç¶²è·¯ãå¯¦é©çµæè¡¨æï¼æåçç³»çµ±åæ¹æ³å¯ä»¥æ¯åºæºæ¹æ³å¿« 1.45 - 9.39 åï¼åæç¢ºä¿æ¶æã</paragraph>

##### **The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**
2410.12458v1 by Minghao Wu, Thuy-Trang Vu, Lizhen Qu, Gholamreza Haffari

The performance of large language models (LLMs) in natural language
processing (NLP) tasks is significantly influenced by the quality and diversity
of data used for supervised fine-tuning (SFT). Current data selection methods
often focus solely on quality or diversity, leading to underperforming models
due to suboptimal training data. In this paper, we introduce GraphFilter, a
novel method that represents the dataset as a bipartite graph, linking
sentences to their constituent n-grams. This representation effectively
captures the relationships between sentences and linguistic patterns,
facilitating the selection of sentences that enhance n-gram diversity. To
balance quality and diversity during selection, we propose a priority function
that combines the quality metric with the diversity metric in a multiplicative
manner. GraphFilter iteratively selects high-priority sentences, updates the
bipartite graph by removing covered n-grams, and re-calculates priorities to
reflect the evolving data landscape. We conduct extensive experiments using
three model backbones across six widely used benchmarks. The results
demonstrate that GraphFilter outperforms all nine baseline approaches,
achieving superior model performance and computational efficiency. Our analyses
validate the effectiveness of our design choices, examine the subsets selected
by GraphFilter and other methods, highlight the importance of instruction
diversity, and explore the role of quality and diversity in relation to subset
sizes. GraphFilter establishes a new foundation for effective data selection
strategies, encouraging further research in data selection for LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èç (NLP) ä»»åä¸­çè¡¨ç¾ï¼åå°ç¨æ¼ç£ç£å¾®èª¿ (SFT) çè³æåè³ªåå¤æ¨£æ§é¡¯èå½±é¿ãç®åçè³æé¸åæ¹æ³éå¸¸åªéæ³¨åè³ªæå¤æ¨£æ§ï¼å°è´è¨ç·´è³ææ¬¡ä½³ï¼é²èé ææ¨¡åè¡¨ç¾ä¸ä½³ãå¨æ¬æä¸­ï¼æåä»ç´¹ GraphFilterï¼ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å°è³æéè¡¨ç¤ºçºäºé¨åï¼å°å¥å­é£çµå°å¶çµæ n-gramãéç¨®è¡¨ç¤ºæ¹å¼ææææå¥å­åèªè¨æ¨¡å¼ä¹éçéä¿ï¼æå©æ¼é¸æè½æå n-gram å¤æ¨£æ§çå¥å­ãçºäºå¨é¸åéç¨ä¸­å¹³è¡¡åè³ªåå¤æ¨£æ§ï¼æåæåºåªåå½æ¸ï¼ä»¥ä¹æ³æ¹å¼çµååè³ªææ¨åå¤æ¨£æ§ææ¨ãGraphFilter è¿­ä»£é¸åé«åªåç´å¥å­ï¼ééç§»é¤å·²æ¶µè n-gram ä¾æ´æ°äºé¨åï¼ä¸¦éæ°è¨ç®åªåç´ä»¥åæ ä¸æ·è®åçè³ææ¨£è²ãæåä½¿ç¨ä¸åæ¨¡åä¸»å¹¹å¨å­åå»£æ³ä½¿ç¨çåºæºä¸é²è¡å»£æ³çå¯¦é©ãçµæé¡¯ç¤ºï¼GraphFilter åªæ¼ææä¹ç¨®åºç·æ¹æ³ï¼éå°åè¶çæ¨¡åæè½åéç®æçãæåçåæé©è­äºæåè¨­è¨é¸æçæææ§ï¼æª¢é© GraphFilter åå¶ä»æ¹æ³é¸åçå­éï¼å¼·èª¿æä»¤å¤æ¨£æ§çéè¦æ§ï¼ä¸¦æ¢è¨åè³ªåå¤æ¨£æ§èå­éå¤§å°çéä¿ãGraphFilter çºææçè³æé¸åç­ç¥å¥ å®æ°çåºç¤ï¼é¼åµé²ä¸æ­¥ç ç©¶ LLM çè³æé¸åã

##### **PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**
2410.12375v1 by Markus J. Buehler

PRefLexOR (Preference-based Recursive Language Modeling for Exploratory
Optimization of Reasoning) combines preference optimization with concepts from
Reinforcement Learning to enable models to self-teach through iterative
reasoning improvements. We propose a recursive learning approach that engages
the model in multi-step reasoning, revisiting, and refining intermediate steps
before producing a final output in training and inference phases. Through
multiple training stages, the model first learns to align its reasoning with
accurate decision paths by optimizing the log odds between preferred and
non-preferred responses. During this process, PRefLexOR builds a dynamic
knowledge graph by generating questions from random text chunks and
retrieval-augmentation to contextualize relevant details from the entire
training corpus. In the second stage, preference optimization enhances model
performance by using rejection sampling to fine-tune reasoning quality by
continually producing in-situ training data while masking the reasoning steps.
Recursive optimization within a thinking token framework introduces iterative
feedback loops, where the model refines reasoning, achieving deeper coherence,
consistency, and adaptability. Implemented in small language models with only 3
billion parameters, we should that even tiny models can iteratively teach
themselves to reason with greater depth and reflectivity. Our implementation is
straightforward and can be incorporated into any existing pretrained LLM. We
focus our examples on applications in biological materials science and
demonstrate the method in a variety of case studies that range from in-domain
to cross-domain applications. Using reasoning strategies that include thinking
and reflection modalities we build a multi-agent recursive self-improving
inference approach to successively improve responses via repeated sampling in
inference time.

æè¦ï¼PRefLexORï¼ç¨æ¼æ¢ç´¢æ§æ¨çåªåçåºæ¼åå¥½çéè¿´èªè¨å»ºæ¨¡ï¼å°åå¥½åªåèå¼·åå­¸ç¿ä¸­çæ¦å¿µç¸çµåï¼ä½¿æ¨¡åè½å¤ ééåè¦æ¨çæ¹é²ä¾èªææå­¸ãæåæåºäºä¸ç¨®éè¿´å­¸ç¿æ¹æ³ï¼è®æ¨¡ååèå¤æ­¥é©æ¨çãéæ°å¯©è¦åæ¹é²ä¸­éæ­¥é©ï¼ç¶å¾å¨è¨ç·´åæ¨çéæ®µç¢çæçµè¼¸åºãééå¤åè¨ç·´éæ®µï¼æ¨¡åé¦åå­¸ç¿ééåªåé¦é¸åéé¦é¸é¿æä¹éçå°æ¸å¹¾çï¼ä½¿å¶æ¨çèæºç¢ºçæ±ºç­è·¯å¾ä¿æä¸è´ãå¨æ­¤éç¨ä¸­ï¼PRefLexOR ééå¾é¨æ©ææ¬å¡çæåé¡åæª¢ç´¢å¢å¼·ä¾æ§å»ºä¸ååæç¥è­åï¼å¾æ´åè¨ç·´èªæåº«ä¸­æåç¸éç´°ç¯ä»¥é²è¡èªå¢åãå¨ç¬¬äºéæ®µï¼åå¥½åªåééä½¿ç¨æçµæ¡æ¨£ä¾å¾®èª¿æ¨çè³ªéï¼å¾èå¢å¼·æ¨¡åæ§è½ï¼åæé£çºç¢çåä½è¨ç·´æ¸æï¼åææ©èæ¨çæ­¥é©ãå¨æèä»¤çæ¡æ¶å§é²è¡éè¿´åªåæå¼å¥è¿­ä»£åé¥è¿´è·¯ï¼å¶ä¸­æ¨¡åææ¹é²æ¨çï¼å¾èå¯¦ç¾æ´æ·±å¥çé£è²«æ§ãä¸è´æ§åé©ææ§ãå¨åªæ 30 åååæ¸çå°èªè¨æ¨¡åä¸­å¯¦ç¾ï¼æåæè©²è®å³ä½¿æ¯å¾å°çæ¨¡åä¹è½ééè¿­ä»£çæ¹å¼ææèªå·±ä»¥æ´å¤§çæ·±åº¦ååæè½åé²è¡æ¨çãæåçå¯¦ç¾éå¸¸ç´æ¥ï¼å¯ä»¥æ´åå°ä»»ä½ç¾æçé è¨ç·´ LLM ä¸­ãæåå°æåçç¤ºä¾éé»æ¾å¨çç©ææç§å­¸æç¨ä¸ï¼ä¸¦å¨å¾åå§å°è·¨åæç¨ç­åç¨®æ¡ä¾ç ç©¶ä¸­æ¼ç¤ºäºè©²æ¹æ³ãä½¿ç¨åæ¬æèååææ¨¡å¼å¨å§çæ¨çç­ç¥ï¼æåæ§å»ºäºä¸åå¤ä»£çéè¿´èªææ¹é²æ¨çæ¹æ³ï¼ä»¥ééå¨æ¨çæééè¤æ¡æ¨£ä¾é£çºæ¹é²é¿æã

##### **Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs**
2410.12298v2 by Lei Sun, Xinchen Wang, Youdi Li

Large Language Models (LLMs) possess impressive reasoning abilities but are
prone to generating incorrect information, often referred to as hallucinations.
While incorporating external Knowledge Graphs (KGs) can partially mitigate this
issue, existing methods primarily treat KGs as static knowledge repositories,
overlooking the critical disparity between KG and LLM knowledge, and failing to
fully exploit the reasoning capabilities inherent in KGs. To address these
limitations, we propose Pyramid-Driven Alignment (PDA), a novel framework for
seamlessly integrating LLMs with KGs. PDA utilizes Pyramid Principle analysis
to construct a hierarchical pyramid structure. This structure is designed to
reflect the input question and generate more validated deductive knowledge,
thereby enhancing the alignment of LLMs and KGs and ensuring more cohesive
integration. Furthermore, PDA employs a recursive mechanism to harness the
underlying reasoning abilities of KGs, resulting in more accurate knowledge
retrieval for question-answering tasks. Our experimental results reveal a
substantial performance advantage of PDA over state-of-the-art baselines, with
improvements reaching 26.70% and 26.78%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ææä»¤äººå°è±¡æ·±å»çæ¨çè½åï¼ä½å®¹æç¢çä¸æ­£ç¢ºçè³è¨ï¼éå¸¸ç¨±çºå¹»è¦ºã
åç®¡çµåå¤é¨ç¥è­åè­ (KG) å¯ä»¥é¨åç·©è§£éååé¡ï¼ä½ç¾ææ¹æ³ä¸»è¦å° KG è¦çºéæç¥è­å²å­åº«ï¼å¿½è¦ KG å LLM ç¥è­ä¹éçééµå·®ç°ï¼ä¸¦ä¸æªè½ååå©ç¨ KG ä¸­åºæçæ¨çè½åãçºäºè§£æ±ºéäºéå¶ï¼æåæåºéå­å¡é©åå°é½ (PDA)ï¼éæ¯ä¸åå° LLM è KG ç¡ç¸«æ´åçæ°ç©æ¶æ§ãPDA å©ç¨éå­å¡åååæä¾å»ºæ§ä¸åéå±¤å¼éå­å¡çµæ§ãæ­¤çµæ§æ¨å¨åæ è¼¸å¥åé¡ä¸¦ç¢çæ´å¤ç¶éé©è­çæ¼ç¹¹ç¥è­ï¼å¾èå¢å¼· LLM å KG çå°é½ï¼ä¸¦ç¢ºä¿æ´ç·å¯çæ´åãæ­¤å¤ï¼PDA æ¡ç¨éè¿´æ©å¶ä¾å©ç¨ KG çåºå±¤æ¨çè½åï¼å¾èæ´æºç¢ºå°æª¢ç´¢ç¥è­ä»¥é²è¡åç­ä»»åãæåçå¯¦é©çµæé¡¯ç¤ºï¼PDA ç¸è¼æ¼æåé²çåºæºï¼å·æé¡¯èçæè½åªå¢ï¼æ¹é²å¹åº¦éå° 26.70% å 26.78%ã

##### **LLM-based Cognitive Models of Students with Misconceptions**
2410.12294v2 by Shashank Sonkar, Xinghe Chen, Naiming Liu, Richard G. Baraniuk, Mrinmaya Sachan

Accurately modeling student cognition is crucial for developing effective
AI-driven educational technologies. A key challenge is creating realistic
student models that satisfy two essential properties: (1) accurately
replicating specific misconceptions, and (2) correctly solving problems where
these misconceptions are not applicable. This dual requirement reflects the
complex nature of student understanding, where misconceptions coexist with
correct knowledge. This paper investigates whether Large Language Models (LLMs)
can be instruction-tuned to meet this dual requirement and effectively simulate
student thinking in algebra. We introduce MalAlgoPy, a novel Python library
that generates datasets reflecting authentic student solution patterns through
a graph-based representation of algebraic problem-solving. Utilizing MalAlgoPy,
we define and examine Cognitive Student Models (CSMs) - LLMs instruction tuned
to faithfully emulate realistic student behavior. Our findings reveal that LLMs
trained on misconception examples can efficiently learn to replicate errors.
However, the training diminishes the model's ability to solve problems
correctly, particularly for problem types where the misconceptions are not
applicable, thus failing to satisfy second property of CSMs. We demonstrate
that by carefully calibrating the ratio of correct to misconception examples in
the training data - sometimes as low as 0.25 - it is possible to develop CSMs
that satisfy both properties. Our insights enhance our understanding of
AI-based student models and pave the way for effective adaptive learning
systems.

æè¦ï¼æºç¢ºå°æ¨¡æ¬å­¸ççèªç¥å°æ¼éç¼ææç AI é©åæè²æè¡è³ééè¦ãä¸åä¸»è¦çææ°æ¯å»ºç«ç¬¦åå©ååºæ¬å±¬æ§çé¼ççå­¸çæ¨¡åï¼(1) æºç¢ºå°è¤è£½ç¹å®çé¯èª¤è§å¿µï¼ä»¥å (2) æ­£ç¢ºè§£æ±ºéäºé¯èª¤è§å¿µä¸é©ç¨çåé¡ãéåéééæ±åæ äºå­¸ççè§£çè¤éæ§ï¼å¶ä¸­é¯èª¤è§å¿µèæ­£ç¢ºç¥è­ä¸¦å­ãæ¬ææ¢è¨å¤§åèªè¨æ¨¡å (LLM) æ¯å¦å¯ä»¥éå°æä»¤é²è¡èª¿æ´ä»¥æ»¿è¶³éåéééæ±ï¼ä¸¦ææå°æ¨¡æ¬å­¸çå¨ä»£æ¸ä¸­çæèãæåä»ç´¹ MalAlgoPyï¼ä¸åæ°ç©ç Python å½å¼åº«ï¼å®ééä»£æ¸åé¡è§£æ±ºçåå½¢åè¡¨ç¤ºæ³çæåæ çå¯¦å­¸çè§£é¡æ¨¡å¼çè³æéãå©ç¨ MalAlgoPyï¼æåå®ç¾©ä¸¦æª¢è¦èªç¥å­¸çæ¨¡å (CSM) - éå°æä»¤èª¿æ´ç LLMï¼ä»¥å¿ å¯¦å°æ¨¡æ¬ç¾å¯¦å­¸ççè¡çºãæåçç ç©¶çµæé¡¯ç¤ºï¼éå°é¯èª¤è§å¿µç¯ä¾è¨ç·´ç LLM å¯ä»¥ææå°å­¸ç¿è¤è£½é¯èª¤ãç¶èï¼è¨ç·´æéä½æ¨¡åæ­£ç¢ºè§£æ±ºåé¡çè½åï¼ç¹å¥æ¯å°æ¼é¯èª¤è§å¿µä¸é©ç¨çåé¡é¡åï¼å æ­¤ç¡æ³æ»¿è¶³ CSM çç¬¬äºåå±¬æ§ãæåè­æï¼ééä»ç´°æ ¡æºè¨ç·´è³æä¸­æ­£ç¢ºç¯ä¾èé¯èª¤è§å¿µç¯ä¾çæ¯ä¾ - ææä½è³ 0.25 - å¯ä»¥éç¼åææ»¿è¶³å©åå±¬æ§ç CSMãæåçè¦è§£å¢é²äºæåå°åºæ¼ AI çå­¸çæ¨¡åççè§£ï¼ä¸¦çºææçèªé©æå­¸ç¿ç³»çµ±éªå¹³äºéè·¯ã

##### **Comprehending Knowledge Graphs with Large Language Models for Recommender Systems**
2410.12229v1 by Ziqiang Cui, Yunpeng Weng, Xing Tang, Fuyuan Lyu, Dugang Liu, Xiuqiang He, Chen Ma

Recently, the introduction of knowledge graphs (KGs) has significantly
advanced recommender systems by facilitating the discovery of potential
associations between items. However, existing methods still face several
limitations. First, most KGs suffer from missing facts or limited scopes. This
can lead to biased knowledge representations, thereby constraining the model's
performance. Second, existing methods typically convert textual information
into IDs, resulting in the loss of natural semantic connections between
different items. Third, existing methods struggle to capture high-order
relationships in global KGs due to their inefficient layer-by-layer information
propagation mechanisms, which are prone to introducing significant noise. To
address these limitations, we propose a novel method called CoLaKG, which
leverages large language models (LLMs) for knowledge-aware recommendation. The
extensive world knowledge and remarkable reasoning capabilities of LLMs enable
them to supplement KGs. Additionally, the strong text comprehension abilities
of LLMs allow for a better understanding of semantic information. Based on
this, we first extract subgraphs centered on each item from the KG and convert
them into textual inputs for the LLM. The LLM then outputs its comprehension of
these item-centered subgraphs, which are subsequently transformed into semantic
embeddings. Furthermore, to utilize the global information of the KG, we
construct an item-item graph using these semantic embeddings, which can
directly capture higher-order associations between items. Both the semantic
embeddings and the structural information from the item-item graph are
effectively integrated into the recommendation model through our designed
representation alignment and neighbor augmentation modules. Extensive
experiments on four real-world datasets demonstrate the superiority of our
method.

æè¦ï¼<paragraph>æè¿ï¼ç¥è­åè­ (KG) çå¼å¥ééä¿é²é ç®ä¹éæ½å¨éè¯çç¼ç¾ï¼é¡¯èæåæ¨è¦ç³»çµ±ãç¶èï¼ç¾ææ¹æ³ä»é¢è¨å¹¾åéå¶ãé¦åï¼å¤§å¤æ¸ KG é½å­å¨äºå¯¦ç¼ºå¤±æç¯ååéçåé¡ãéå¯è½å°è´æåå·®çç¥è­è¡¨å¾µï¼é²èéå¶æ¨¡åçæè½ãå¶æ¬¡ï¼ç¾ææ¹æ³éå¸¸æå°æå­è³è¨è½æçº IDï¼å°è´ä¸åé ç®ä¹éèªç¶èªç¾©é£çµçéºå¤±ãç¬¬ä¸ï¼ç¾ææ¹æ³é£ä»¥ææå¨ç KG ä¸­çé«ééä¿ï¼åå å¨æ¼å¶ä½æççéå±¤è³è¨å³æ­æ©å¶å®¹æå¼å¥é¡¯èéè¨ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®ç¨±çº CoLaKG çæ°æ¹æ³ï¼å®å©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡ç¥è­æç¥æ¨è¦ãLLM å»£æ³çä¸çç¥è­ååè¶çæ¨çè½åä½¿å®åè½å¤ è£å KGãæ­¤å¤ï¼LLM å¼·å¤§çæå­çè§£è½åæå©æ¼æ´æ·±å¥å°çè§£èªç¾©è³è¨ãåºæ¼æ­¤ï¼æåé¦åå¾ KG ä¸­æ·åä»¥æ¯åé ç®çºä¸­å¿çå­åï¼ä¸¦å°å®åè½æçº LLM çæå­è¼¸å¥ãç¶å¾ï¼LLM æè¼¸åºå¶å°éäºä»¥é ç®çºä¸­å¿çå­åççè§£ï¼éäºçè§£æ¥èæè½æçºèªç¾©åµå¥ãæ­¤å¤ï¼çºäºå©ç¨ KG çå¨çè³è¨ï¼æåä½¿ç¨éäºèªç¾©åµå¥å»ºæ§ä¸åé ç®-é ç®åï¼å®å¯ä»¥ç´æ¥ææé ç®ä¹éçé«ééè¯ãèªç¾©åµå¥åä¾èªé ç®-é ç®åççµæ§è³è¨é½æééæåè¨­è¨çè¡¨å¾µæ¯å°åé°åæ´åæ¨¡çµææå°æ´åå°æ¨è¦æ¨¡åä¸­ãå¨ååçå¯¦ä¸çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æäºæåæ¹æ³çåªè¶æ§ã</paragraph>

##### **Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations**
2410.12228v1 by Luyi Ma, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sushant Kumar, Kannan Achan

Integrating diverse data modalities is crucial for enhancing the performance
of personalized recommendation systems. Traditional models, which often rely on
singular data sources, lack the depth needed to accurately capture the
multifaceted nature of item features and user behaviors. This paper introduces
a novel framework for multi-behavior recommendations, leveraging the fusion of
triple-modality, which is visual, textual, and graph data through alignment
with large language models (LLMs). By incorporating visual information, we
capture contextual and aesthetic item characteristics; textual data provides
insights into user interests and item features in detail; and graph data
elucidates relationships within the item-behavior heterogeneous graphs. Our
proposed model called Triple Modality Fusion (TMF) utilizes the power of LLMs
to align and integrate these three modalities, achieving a comprehensive
representation of user behaviors. The LLM models the user's interactions
including behaviors and item features in natural languages. Initially, the LLM
is warmed up using only natural language-based prompts. We then devise the
modality fusion module based on cross-attention and self-attention mechanisms
to integrate different modalities from other models into the same embedding
space and incorporate them into an LLM. Extensive experiments demonstrate the
effectiveness of our approach in improving recommendation accuracy. Further
ablation studies validate the effectiveness of our model design and benefits of
the TMF.

æè¦ï¼æ´ååç¨®è³æåæå°æ¼æååäººåæ¨è¦ç³»çµ±çæè½è³ééè¦ãå³çµ±æ¨¡åç¶å¸¸ä¾è³´å®ä¸è³æä¾æºï¼ç¼ºä¹ææé ç®ç¹å¾µåä½¿ç¨èè¡çºå¤é¢åæ¬è³ªæéçæ·±åº¦ãæ¬æä»ç´¹äºä¸ååµæ°çå¤è¡çºæ¨è¦æ¶æ§ï¼å©ç¨è¦è¦ºãæå­ååå½¢è³æçä¸éåæèåï¼ééèå¤§åèªè¨æ¨¡å (LLM) å°é½ä¾å¯¦ç¾ãééç´å¥è¦è¦ºè³è¨ï¼æåææèçµ¡åç¾å­¸é ç®ç¹å¾µï¼æå­è³æè©³ç´°æä¾ä½¿ç¨èèè¶£åé ç®ç¹å¾µçè¦è§£ï¼åå½¢è³æé¡æé ç®è¡çºç°è³ªåå½¢ä¸­çéä¿ãæåæåºçæ¨¡åç¨±çºä¸éåæèå (TMF)ï¼å©ç¨ LLM çåéä¾å°é½åæ´åéä¸ç¨®åæï¼éæä½¿ç¨èè¡çºçå¨é¢è¡¨å¾µãLLM ä»¥èªç¶èªè¨å»ºæ¨¡ä½¿ç¨èçäºåï¼åæ¬è¡çºåé ç®ç¹å¾µãæåï¼LLM åä½¿ç¨åºæ¼èªç¶èªè¨çæç¤ºé²è¡ç±èº«ãç¶å¾æåæ ¹æäº¤åæ³¨æååèªææ³¨æåæ©å¶è¨­è¨åæèåæ¨¡çµï¼å°ä¾èªå¶ä»æ¨¡åçä¸ååææ´åå°ç¸åçåµå¥ç©ºéï¼ä¸¦å°å®åç´å¥ LLMãå»£æ³çå¯¦é©è­æäºæåçæ¹æ³å¨æåæ¨è¦æºç¢ºåº¦æ¹é¢çæææ§ãé²ä¸æ­¥çæ¶èç ç©¶é©è­äºæåæ¨¡åè¨­è¨çæææ§ä»¥å TMF çå¥½èã

##### **Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning**
2410.12130v1 by Huiwen Wu, Xiaohan Li, Xiaogang Xu, Jiafei Wu, Deyi Zhang, Zhe Liu

The development of Large Language Models (LLMs) has significantly advanced
various AI applications in commercial and scientific research fields, such as
scientific literature summarization, writing assistance, and knowledge graph
construction. However, a significant challenge is the high risk of
hallucination during LLM inference, which can lead to security concerns like
factual inaccuracies, inconsistent information, and fabricated content. To
tackle this issue, it is essential to develop effective methods for reducing
hallucination while maintaining the original capabilities of the LLM. This
paper introduces a novel approach called Iterative Model-level Contrastive
Learning (Iter-AHMCL) to address hallucination. This method modifies the
representation layers of pre-trained LLMs by using contrastive `positive' and
`negative' models, trained on data with and without hallucinations. By
leveraging the differences between these two models, we create a more
straightforward pathway to eliminate hallucinations, and the iterative nature
of contrastive learning further enhances performance. Experimental validation
on four pre-trained foundation LLMs (LLaMA2, Alpaca, LLaMA3, and Qwen)
finetuning with a specially designed dataset shows that our approach achieves
an average improvement of 10.1 points on the TruthfulQA benchmark.
Comprehensive experiments demonstrate the effectiveness of Iter-AHMCL in
reducing hallucination while maintaining the general capabilities of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çç¼å±å¨åæ¥­åç§å­¸ç ç©¶é åé¡¯èæ¨åäºåç¨® AI æç¨ï¼ä¾å¦ç§å­¸æç»æè¦ãå¯«ä½è¼å©åç¥è­åè­å»ºæ§ãç¶èï¼ä¸åéå¤§çææ°æ¯ LLM æ¨è«ä¸­å¹»è¦ºçé«é¢¨éªï¼éå¯è½æå°è´å®å¨åé¡ï¼ä¾å¦äºå¯¦ä¸æ­£ç¢ºãè³è¨ä¸ä¸è´åæé å§å®¹ãçºäºè§£æ±ºéååé¡ï¼éç¼ææçæ¹æ³ä¾æ¸å°å¹»è¦ºï¼åæä¿æ LLM çåå§åè½è³ééè¦ãæ¬æä»ç´¹äºä¸ç¨®ç¨±çºåè¦æ¨¡åå±¤ç´å°æ¯å­¸ç¿ (Iter-AHMCL) çæ°æ¹æ³ä¾è§£æ±ºå¹»è¦ºãæ­¤æ¹æ³ééä½¿ç¨å°æ¯çãæ­£åãåãè² åãæ¨¡åä¾ä¿®æ¹é åè¨ç·´ç LLM çè¡¨ç¤ºå±¤ï¼éäºæ¨¡åæ¯å¨æåæ²æå¹»è¦ºçè³æä¸è¨ç·´çãééå©ç¨éå©åæ¨¡åä¹éçå·®ç°ï¼æååµé äºä¸æ¢æ´ç´æ¥çéå¾ä¾æ¶é¤å¹»è¦ºï¼èå°æ¯å­¸ç¿çè¿­ä»£æ§è³ªé²ä¸æ­¥å¢å¼·äºæè½ãå¨ååé åè¨ç·´çåºç¤ LLM (LLaMA2ãAlpacaãLLaMA3 å Qwen) ä¸é²è¡çå¯¦é©é©è­ï¼ä½¿ç¨ç¹å¥è¨­è¨çè³æéé²è¡å¾®èª¿ï¼é¡¯ç¤ºæåçåæ³å¨ TruthfulQA åºæºä¸å¹³åæåäº 10.1 åãå¨é¢çå¯¦é©è­æäº Iter-AHMCL å¨æ¸å°å¹»è¦ºçåæï¼ç¶­æ LLM ä¸è¬åè½çæææ§ã

##### **Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning**
2410.12096v1 by Guangxin Su, Yifan Zhu, Wenjie Zhang, Hanchen Wang, Ying Zhang

Graph representation learning, involving both node features and graph
structures, is crucial for real-world applications but often encounters
pervasive noise. State-of-the-art methods typically address noise by focusing
separately on node features with large language models (LLMs) and on graph
structures with graph structure learning models (GSLMs). In this paper, we
introduce LangGSL, a robust framework that integrates the complementary
strengths of pre-trained language models and GSLMs to jointly enhance both node
feature and graph structure learning. In LangGSL, we first leverage LLMs to
filter noise in the raw data and extract valuable cleaned information as
features, enhancing the synergy of downstream models. During the mutual
learning phase in LangGSL, the core idea is to leverage the relatively small
language model (LM) to process local attributes and generate reliable
pseudo-labels and informative node embeddings, which are then integrated into
the GSLM's prediction phase. This approach enriches the global context and
enhances overall performance. Meanwhile, GSLM refines the evolving graph
structure constructed from the LM's output, offering updated labels back to the
LM as additional guidance, thus facilitating a more effective mutual learning
process. The LM and GSLM work synergistically, complementing each other's
strengths and offsetting weaknesses within a variational information-maximizing
framework, resulting in enhanced node features and a more robust graph
structure. Extensive experiments on diverse graph datasets of varying scales
and across different task scenarios demonstrate the scalability and
effectiveness of the proposed approach.

æè¦ï¼åè¡¨è¡¨ç¤ºå­¸ç¿æ¢æ¶åç¯é»ç¹å¾µåæ¶ååå½¢çµæ§ï¼å°æ¼ç¾å¯¦ä¸ççæç¨è³ééè¦ï¼ä½ç¶å¸¸æéå°æ®éçåªé³ãæåé²çæ¹æ³éå¸¸ééåå¥éæ³¨å·æå¤§åèªè¨æ¨¡å (LLM) çç¯é»ç¹å¾µåå·æåå½¢çµæ§å­¸ç¿æ¨¡å (GSLM) çåå½¢çµæ§ä¾è§£æ±ºåªé³åé¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äº LangGSLï¼éæ¯ä¸åå¼·å¤§çæ¡æ¶ï¼å®æ´åäºé è¨ç·´èªè¨æ¨¡åå GSLM çäºè£åªå¢ï¼ä»¥å±åå¢å¼·ç¯é»ç¹å¾µååå½¢çµæ§å­¸ç¿ãå¨ LangGSL ä¸­ï¼æåé¦åå©ç¨ LLM ä¾éæ¿¾åå§æ¸æä¸­çåªé³ï¼ä¸¦æåæå¹å¼çå·²æ¸çä¿¡æ¯ä½çºç¹å¾µï¼å¢å¼·ä¸æ¸¸æ¨¡åçååä½ç¨ãå¨ LangGSL ä¸­çç¸äºå­¸ç¿éæ®µï¼æ ¸å¿ææ³æ¯å©ç¨ç¸å°è¼å°çèªè¨æ¨¡å (LM) ä¾èçå±é¨å±¬æ§ä¸¦çæå¯é çå½æ¨ç±¤åä¿¡æ¯è±å¯çç¯é»åµå¥ï¼ç¶å¾å°å®åéæå° GSLM çé æ¸¬éæ®µãéç¨®æ¹æ³è±å¯äºå¨å±ä¸ä¸æä¸¦å¢å¼·äºæ´é«æ§è½ãåæï¼GSLM åªåäºå¾ LM è¼¸åºæ§å»ºçæ¼ååå½¢çµæ§ï¼å°æ´æ°çæ¨ç±¤ä½çºéå æå°åé¥çµ¦ LMï¼å¾èä¿é²æ´ææçç¸äºå­¸ç¿éç¨ãLM å GSLM ååå·¥ä½ï¼å¨è®åä¿¡æ¯æå¤§åæ¡æ¶å§äºè£åèªçåªå¢ä¸¦å½è£å¼±é»ï¼å¾èå¢å¼·ç¯é»ç¹å¾µä¸¦å½¢ææ´å¼·å¤§çåå½¢çµæ§ãå¨ä¸åè¦æ¨¡åä¸åä»»åå ´æ¯çå¤æ¨£ååå½¢æ¸æéä¸é²è¡çå»£æ³å¯¦é©è­æäºææåºæ¹æ³çå¯æ´å±æ§åæææ§ã

