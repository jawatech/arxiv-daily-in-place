{"2501.17315": {"publish_time": "2025-01-28", "title": "A sketch of an AI control safety case", "paper_summary": "As LLM agents gain a greater capacity to cause harm, AI developers might\nincreasingly rely on control measures such as monitoring to justify that they\nare safe. We sketch how developers could construct a \"control safety case\",\nwhich is a structured argument that models are incapable of subverting control\nmeasures in order to cause unacceptable outcomes. As a case study, we sketch an\nargument that a hypothetical LLM agent deployed internally at an AI company\nwon't exfiltrate sensitive information. The sketch relies on evidence from a\n\"control evaluation,\"' where a red team deliberately designs models to\nexfiltrate data in a proxy for the deployment environment. The safety case then\nhinges on several claims: (1) the red team adequately elicits model\ncapabilities to exfiltrate data, (2) control measures remain at least as\neffective in deployment, and (3) developers conservatively extrapolate model\nperformance to predict the probability of data exfiltration in deployment. This\nsafety case sketch is a step toward more concrete arguments that can be used to\nshow that a dangerously capable LLM agent is safe to deploy.", "paper_summary_zh": "\u96a8\u8457 LLM \u4ee3\u7406\u9020\u6210\u50b7\u5bb3\u7684\u80fd\u529b\u8d8a\u4f86\u8d8a\u5f37\uff0cAI \u958b\u767c\u4eba\u54e1\u53ef\u80fd\u6703\u8d8a\u4f86\u8d8a\u4f9d\u8cf4\u76e3\u63a7\u7b49\u63a7\u5236\u63aa\u65bd\u4f86\u8b49\u660e\u5b83\u5011\u662f\u5b89\u5168\u7684\u3002\u6211\u5011\u6982\u8ff0\u958b\u767c\u4eba\u54e1\u5982\u4f55\u69cb\u5efa\u300c\u63a7\u5236\u5b89\u5168\u6848\u4f8b\u300d\uff0c\u9019\u662f\u4e00\u500b\u7d50\u69cb\u5316\u7684\u8ad6\u8b49\uff0c\u8aaa\u660e\u6a21\u578b\u7121\u6cd5\u985b\u8986\u63a7\u5236\u63aa\u65bd\u4ee5\u9020\u6210\u4e0d\u53ef\u63a5\u53d7\u7684\u7d50\u679c\u3002\u4f5c\u70ba\u4e00\u500b\u6848\u4f8b\u7814\u7a76\uff0c\u6211\u5011\u6982\u8ff0\u4e86\u4e00\u500b\u8ad6\u8b49\uff0c\u5373\u5728 AI \u516c\u53f8\u5167\u90e8\u90e8\u7f72\u7684\u5047\u8a2d LLM \u4ee3\u7406\u4e0d\u6703\u6d29\u9732\u654f\u611f\u8cc7\u8a0a\u3002\u9019\u500b\u6982\u8981\u4f9d\u8cf4\u65bc\u300c\u63a7\u5236\u8a55\u4f30\u300d\u7684\u8b49\u64da\uff0c\u5176\u4e2d\u4e00\u500b\u7d05\u8272\u5c0f\u7d44\u6545\u610f\u8a2d\u8a08\u6a21\u578b\u4f86\u5728\u90e8\u7f72\u74b0\u5883\u7684\u4ee3\u7406\u4e2d\u6d29\u9732\u8cc7\u6599\u3002\u5b89\u5168\u6848\u4f8b\u63a5\u8457\u4f9d\u8cf4\u65bc\u5e7e\u500b\u4e3b\u5f35\uff1a(1) \u7d05\u8272\u5c0f\u7d44\u5145\u5206\u5f15\u51fa\u6a21\u578b\u6d29\u9732\u8cc7\u6599\u7684\u80fd\u529b\uff0c(2) \u63a7\u5236\u63aa\u65bd\u5728\u90e8\u7f72\u4e2d\u81f3\u5c11\u7dad\u6301\u540c\u6a23\u7684\u6548\u529b\uff0c\u4ee5\u53ca (3) \u958b\u767c\u4eba\u54e1\u4fdd\u5b88\u5730\u63a8\u65b7\u6a21\u578b\u6548\u80fd\u4ee5\u9810\u6e2c\u8cc7\u6599\u5728\u90e8\u7f72\u4e2d\u5916\u6d29\u7684\u6a5f\u7387\u3002\u9019\u500b\u5b89\u5168\u6848\u4f8b\u6982\u8981\u662f\u671d\u5411\u66f4\u5177\u9ad4\u7684\u8ad6\u8b49\u9081\u9032\u7684\u4e00\u6b65\uff0c\u53ef\u7528\u65bc\u8b49\u660e\u5177\u6709\u5371\u96aa\u80fd\u529b\u7684 LLM \u4ee3\u7406\u90e8\u7f72\u662f\u5b89\u5168\u7684\u3002", "author": "Tomek Korbak et.al.", "authors": "Tomek Korbak, Joshua Clymer, Benjamin Hilton, Buck Shlegeris, Geoffrey Irving", "id": "2501.17315v1", "paper_url": "http://arxiv.org/abs/2501.17315v1", "repo": "null"}}