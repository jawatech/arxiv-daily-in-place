{"2406.06371": {"publish_time": "2024-06-10", "title": "mHuBERT-147: A Compact Multilingual HuBERT Model", "paper_summary": "We present mHuBERT-147, the first general-purpose massively multilingual\nHuBERT speech representation model trained on 90K hours of clean, open-license\ndata. To scale up the multi-iteration HuBERT approach, we use faiss-based\nclustering, achieving 5.2x faster label assignment than the original method. We\nalso apply a new multilingual batching up-sampling strategy, leveraging both\nlanguage and dataset diversity. After 3 training iterations, our compact 95M\nparameter mHuBERT-147 outperforms larger models trained on substantially more\ndata. We rank second and first on the ML-SUPERB 10min and 1h leaderboards, with\nSOTA scores for 3 tasks. Across ASR/LID tasks, our model consistently surpasses\nXLS-R (300M params; 436K hours) and demonstrates strong competitiveness against\nthe much larger MMS (1B params; 491K hours). Our findings indicate that\nmHuBERT-147 is a promising model for multilingual speech tasks, offering an\nunprecedented balance between high performance and parameter efficiency.", "paper_summary_zh": "\u6211\u5011\u5c55\u793a mHuBERT-147\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u901a\u7528\u7684\u5927\u898f\u6a21\u591a\u8a9e\u8a00 HuBERT \u8a9e\u97f3\u8868\u793a\u6a21\u578b\uff0c\u8a13\u7df4\u65bc 90K \u5c0f\u6642\u7684\u4e7e\u6de8\u958b\u653e\u6388\u6b0a\u8cc7\u6599\u3002\u70ba\u4e86\u64f4\u5c55\u591a\u91cd\u53cd\u8986\u904b\u7b97\u7684 HuBERT \u65b9\u6cd5\uff0c\u6211\u5011\u4f7f\u7528\u57fa\u65bc faiss \u7684\u7fa4\u96c6\uff0c\u5be6\u73fe\u6bd4\u539f\u59cb\u65b9\u6cd5\u5feb 5.2 \u500d\u7684\u6a19\u7c64\u6307\u6d3e\u3002\u6211\u5011\u4e5f\u904b\u7528\u65b0\u7684\u591a\u8a9e\u8a00\u6279\u6b21\u4e0a\u63a1\u6a23\u7b56\u7565\uff0c\u540c\u6642\u5229\u7528\u8a9e\u8a00\u548c\u8cc7\u6599\u96c6\u7684\u591a\u6a23\u6027\u3002\u7d93\u904e 3 \u6b21\u8a13\u7df4\u53cd\u8986\u904b\u7b97\u5f8c\uff0c\u6211\u5011\u7684\u7cbe\u7c21 95M \u53c3\u6578 mHuBERT-147 \u512a\u65bc\u8a13\u7df4\u65bc\u66f4\u591a\u8cc7\u6599\u7684\u5927\u578b\u6a21\u578b\u3002\u6211\u5011\u5728 ML-SUPERB 10 \u5206\u9418\u548c 1 \u5c0f\u6642\u6392\u884c\u699c\u4e0a\u5206\u5225\u6392\u540d\u7b2c\u4e8c\u548c\u7b2c\u4e00\uff0c\u5728 3 \u500b\u4efb\u52d9\u4e2d\u7372\u5f97 SOTA \u5206\u6578\u3002\u5728 ASR/LID \u4efb\u52d9\u4e2d\uff0c\u6211\u5011\u7684\u6a21\u578b\u6301\u7e8c\u8d85\u8d8a XLS-R\uff08300M \u53c3\u6578\uff1b436K \u5c0f\u6642\uff09\uff0c\u4e26\u5c55\u73fe\u8207\u66f4\u5927\u898f\u6a21\u7684 MMS\uff081B \u53c3\u6578\uff1b491K \u5c0f\u6642\uff09\u7684\u5f37\u52c1\u7af6\u722d\u529b\u3002\u6211\u5011\u7684\u767c\u73fe\u6307\u51fa mHuBERT-147 \u662f\u591a\u8a9e\u8a00\u8a9e\u97f3\u4efb\u52d9\u7684\u6709\u524d\u9014\u6a21\u578b\uff0c\u5728\u9ad8\u6027\u80fd\u548c\u53c3\u6578\u6548\u7387\u4e4b\u9593\u63d0\u4f9b\u524d\u6240\u672a\u6709\u7684\u5e73\u8861\u3002", "author": "Marcely Zanon Boito et.al.", "authors": "Marcely Zanon Boito, Vivek Iyer, Nikolaos Lagos, Laurent Besacier, Ioan Calapodescu", "id": "2406.06371v2", "paper_url": "http://arxiv.org/abs/2406.06371v2", "repo": "https://github.com/utter-project/fairseq"}}