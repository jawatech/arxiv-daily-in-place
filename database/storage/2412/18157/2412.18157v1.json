{"2412.18157": {"publish_time": "2024-12-24", "title": "Smooth-Foley: Creating Continuous Sound for Video-to-Audio Generation Under Semantic Guidance", "paper_summary": "The video-to-audio (V2A) generation task has drawn attention in the field of\nmultimedia due to the practicality in producing Foley sound. Semantic and\ntemporal conditions are fed to the generation model to indicate sound events\nand temporal occurrence. Recent studies on synthesizing immersive and\nsynchronized audio are faced with challenges on videos with moving visual\npresence. The temporal condition is not accurate enough while low-resolution\nsemantic condition exacerbates the problem. To tackle these challenges, we\npropose Smooth-Foley, a V2A generative model taking semantic guidance from the\ntextual label across the generation to enhance both semantic and temporal\nalignment in audio. Two adapters are trained to leverage pre-trained\ntext-to-audio generation models. A frame adapter integrates high-resolution\nframe-wise video features while a temporal adapter integrates temporal\nconditions obtained from similarities of visual frames and textual labels. The\nincorporation of semantic guidance from textual labels achieves precise\naudio-video alignment. We conduct extensive quantitative and qualitative\nexperiments. Results show that Smooth-Foley performs better than existing\nmodels on both continuous sound scenarios and general scenarios. With semantic\nguidance, the audio generated by Smooth-Foley exhibits higher quality and\nbetter adherence to physical laws.", "paper_summary_zh": "\u5f71\u7247\u8f49\u97f3\u8a0a (V2A) \u751f\u6210\u4efb\u52d9\u5728\u591a\u5a92\u9ad4\u9818\u57df\u4e2d\u5099\u53d7\u95dc\u6ce8\uff0c\u56e0\u70ba\u5728\u88fd\u4f5c Foley \u97f3\u6548\u65b9\u9762\u5be6\u7528\u3002\u8a9e\u610f\u548c\u6642\u9593\u689d\u4ef6\u6703\u63d0\u4f9b\u7d66\u751f\u6210\u6a21\u578b\uff0c\u4ee5\u8868\u793a\u97f3\u6548\u4e8b\u4ef6\u548c\u6642\u9593\u767c\u751f\u3002\u6700\u8fd1\u95dc\u65bc\u5408\u6210\u6c89\u6d78\u5f0f\u548c\u540c\u6b65\u97f3\u8a0a\u7684\u7814\u7a76\u9762\u81e8\u5f71\u7247\u4e2d\u79fb\u52d5\u8996\u89ba\u5b58\u5728\u6027\u7684\u6311\u6230\u3002\u6642\u9593\u689d\u4ef6\u4e0d\u5920\u6e96\u78ba\uff0c\u800c\u4f4e\u89e3\u6790\u5ea6\u8a9e\u610f\u689d\u4ef6\u6703\u52a0\u5287\u554f\u984c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa Smooth-Foley\uff0c\u4e00\u500b V2A \u751f\u6210\u6a21\u578b\uff0c\u5f9e\u751f\u6210\u904e\u7a0b\u4e2d\u6587\u5b57\u6a19\u7c64\u4e2d\u7372\u53d6\u8a9e\u610f\u6307\u5c0e\uff0c\u4ee5\u589e\u5f37\u97f3\u8a0a\u4e2d\u7684\u8a9e\u610f\u548c\u6642\u9593\u5c0d\u9f4a\u3002\u8a13\u7df4\u5169\u500b\u9069\u914d\u5668\uff0c\u4ee5\u5229\u7528\u9810\u5148\u8a13\u7df4\u7684\u6587\u5b57\u8f49\u97f3\u8a0a\u751f\u6210\u6a21\u578b\u3002\u4e00\u500b\u6846\u67b6\u9069\u914d\u5668\u6574\u5408\u9ad8\u89e3\u6790\u5ea6\u9010\u5e40\u5f71\u7247\u7279\u5fb5\uff0c\u800c\u6642\u9593\u9069\u914d\u5668\u6574\u5408\u5f9e\u8996\u89ba\u5e40\u548c\u6587\u5b57\u6a19\u7c64\u76f8\u4f3c\u6027\u4e2d\u7372\u5f97\u7684\u6642\u9593\u689d\u4ef6\u3002\u5f9e\u6587\u5b57\u6a19\u7c64\u4e2d\u52a0\u5165\u8a9e\u610f\u6307\u5c0e\u53ef\u9054\u6210\u7cbe\u6e96\u7684\u97f3\u8a0a\u8996\u8a0a\u5c0d\u9f4a\u3002\u6211\u5011\u9032\u884c\u5ee3\u6cdb\u7684\u91cf\u5316\u548c\u5b9a\u6027\u5be6\u9a57\u3002\u7d50\u679c\u986f\u793a\uff0cSmooth-Foley \u5728\u9023\u7e8c\u97f3\u8a0a\u5834\u666f\u548c\u4e00\u822c\u5834\u666f\u4e2d\u90fd\u6bd4\u73fe\u6709\u6a21\u578b\u8868\u73fe\u5f97\u66f4\u597d\u3002\u6709\u4e86\u8a9e\u610f\u6307\u5c0e\uff0cSmooth-Foley \u751f\u6210\u7684\u97f3\u8a0a\u54c1\u8cea\u66f4\u9ad8\uff0c\u4e14\u66f4\u7b26\u5408\u7269\u7406\u5b9a\u5f8b\u3002", "author": "Yaoyun Zhang et.al.", "authors": "Yaoyun Zhang, Xuenan Xu, Mengyue Wu", "id": "2412.18157v1", "paper_url": "http://arxiv.org/abs/2412.18157v1", "repo": "null"}}