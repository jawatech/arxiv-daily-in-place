{"2501.01625": {"publish_time": "2025-01-03", "title": "ICPC: In-context Prompt Compression with Faster Inference", "paper_summary": "Despite the recent success of Large Language Models (LLMs), it remains\nchallenging to feed LLMs with long prompts due to the fixed size of LLM inputs.\nAs a remedy, prompt compression becomes a promising solution by removing\nredundant tokens in the prompt. However, using LLM in the existing works\nrequires additional computation resources and leads to memory overheads. To\naddress it, we propose ICPC (In-context Prompt Compression), a novel and\nscalable prompt compression method that adaptively reduces the prompt length.\nThe key idea of ICPC is to calculate the probability of each word appearing in\nthe prompt using encoders and calculate information carried by each word\nthrough the information function, which effectively reduces the information\nloss during prompt compression and increases the speed of compression.\nEmpirically, we demonstrate that ICPC can effectively compress long texts of\ndifferent categories and thus achieve better performance and speed on different\ntypes of NLP tasks.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8fd1\u671f\u7372\u5f97\u6210\u529f\uff0c\u4f46\u7531\u65bc LLM \u8f38\u5165\u5177\u6709\u56fa\u5b9a\u5927\u5c0f\uff0c\u56e0\u6b64\u8981\u4ee5\u9577\u63d0\u793a\u8f38\u5165 LLM \u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u4f5c\u70ba\u88dc\u6551\u63aa\u65bd\uff0c\u63d0\u793a\u58d3\u7e2e\u900f\u904e\u79fb\u9664\u63d0\u793a\u4e2d\u91cd\u8907\u7684\u7b26\u865f\uff0c\u6210\u70ba\u4e00\u500b\u6709\u524d\u9014\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u7136\u800c\uff0c\u5728\u73fe\u6709\u4f5c\u54c1\u4e2d\u4f7f\u7528 LLM \u9700\u8981\u984d\u5916\u7684\u904b\u7b97\u8cc7\u6e90\uff0c\u4e26\u5c0e\u81f4\u8a18\u61b6\u9ad4\u8ca0\u64d4\u904e\u91cd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa ICPC\uff08\u8a9e\u5883\u63d0\u793a\u58d3\u7e2e\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u4e14\u53ef\u64f4\u5145\u7684\u63d0\u793a\u58d3\u7e2e\u65b9\u6cd5\uff0c\u53ef\u4ee5\u81ea\u9069\u61c9\u5730\u7e2e\u77ed\u63d0\u793a\u9577\u5ea6\u3002ICPC \u7684\u95dc\u9375\u601d\u60f3\u662f\u4f7f\u7528\u7de8\u78bc\u5668\u8a08\u7b97\u6bcf\u500b\u5b57\u51fa\u73fe\u5728\u63d0\u793a\u4e2d\u7684\u6a5f\u7387\uff0c\u4e26\u900f\u904e\u8cc7\u8a0a\u51fd\u6578\u8a08\u7b97\u6bcf\u500b\u5b57\u6240\u627f\u8f09\u7684\u8cc7\u8a0a\uff0c\u9019\u6703\u5728\u63d0\u793a\u58d3\u7e2e\u904e\u7a0b\u4e2d\u6709\u6548\u5730\u6e1b\u5c11\u8cc7\u8a0a\u640d\u5931\uff0c\u4e26\u63d0\u9ad8\u58d3\u7e2e\u901f\u5ea6\u3002\u6839\u64da\u7d93\u9a57\uff0c\u6211\u5011\u8b49\u660e ICPC \u53ef\u4ee5\u6709\u6548\u58d3\u7e2e\u4e0d\u540c\u985e\u5225\u7684\u9577\u6587\u5b57\uff0c\u56e0\u6b64\u5728\u4e0d\u540c\u985e\u578b\u7684 NLP \u4efb\u52d9\u4e0a\u7372\u5f97\u66f4\u597d\u7684\u6548\u80fd\u548c\u901f\u5ea6\u3002", "author": "Ziyang Yu et.al.", "authors": "Ziyang Yu, Yuyu Liu", "id": "2501.01625v1", "paper_url": "http://arxiv.org/abs/2501.01625v1", "repo": "null"}}