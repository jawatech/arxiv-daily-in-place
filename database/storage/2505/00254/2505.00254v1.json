{"2505.00254": {"publish_time": "2025-05-01", "title": "Empowering Agentic Video Analytics Systems with Video Language Models", "paper_summary": "AI-driven video analytics has become increasingly pivotal across diverse\ndomains. However, existing systems are often constrained to specific,\npredefined tasks, limiting their adaptability in open-ended analytical\nscenarios. The recent emergence of Video-Language Models (VLMs) as\ntransformative technologies offers significant potential for enabling\nopen-ended video understanding, reasoning, and analytics. Nevertheless, their\nlimited context windows present challenges when processing ultra-long video\ncontent, which is prevalent in real-world applications. To address this, we\nintroduce AVA, a VLM-powered system designed for open-ended, advanced video\nanalytics. AVA incorporates two key innovations: (1) the near real-time\nconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long or\ncontinuous video streams, and (2) an agentic retrieval-generation mechanism\nthat leverages EKGs to handle complex and diverse queries. Comprehensive\nevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that\nAVA achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,\nrespectively, significantly surpassing existing VLM and video\nRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video\nanalytics in ultra-long and open-world video scenarios, we introduce a new\nbenchmark, AVA-100. This benchmark comprises 8 videos, each exceeding 10 hours\nin duration, along with 120 manually annotated, diverse, and complex\nquestion-answer pairs. On AVA-100, AVA achieves top-tier performance with an\naccuracy of 75.8%.", "paper_summary_zh": "<paragraph>\u7531 AI \u9a45\u52d5\u7684\u5f71\u7247\u5206\u6790\u5728\u5404\u500b\u9818\u57df\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u91cd\u8981\u3002\u7136\u800c\uff0c\u73fe\u6709\u7cfb\u7d71\u901a\u5e38\u53d7\u9650\u65bc\u7279\u5b9a\u3001\u9810\u5148\u5b9a\u7fa9\u7684\u4efb\u52d9\uff0c\u9650\u5236\u4e86\u5b83\u5011\u5728\u958b\u653e\u5f0f\u5206\u6790\u5834\u666f\u4e2d\u7684\u9069\u61c9\u6027\u3002\u5f71\u7247-\u8a9e\u8a00\u6a21\u578b (VLM) \u4f5c\u70ba\u8b8a\u9769\u6027\u6280\u8853\u7684\u6700\u65b0\u51fa\u73fe\uff0c\u70ba\u5be6\u73fe\u958b\u653e\u5f0f\u5f71\u7247\u7406\u89e3\u3001\u63a8\u7406\u548c\u5206\u6790\u63d0\u4f9b\u4e86\u5de8\u5927\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u5b83\u5011\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u5728\u8655\u7406\u73fe\u5be6\u4e16\u754c\u61c9\u7528\u4e2d\u666e\u904d\u5b58\u5728\u7684\u8d85\u9577\u5f71\u7247\u5167\u5bb9\u6642\uff0c\u5e36\u4f86\u4e86\u6311\u6230\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u554f\u984c\uff0c\u6211\u5011\u63a8\u51fa\u4e86 AVA\uff0c\u9019\u662f\u4e00\u500b\u7531 VLM \u9a45\u52d5\u7684\u7cfb\u7d71\uff0c\u5c08\u70ba\u958b\u653e\u5f0f\u3001\u9032\u968e\u5f71\u7247\u5206\u6790\u800c\u8a2d\u8a08\u3002AVA \u5305\u542b\u5169\u9805\u95dc\u9375\u5275\u65b0\uff1a(1) \u8fd1\u4e4e\u5373\u6642\u5730\u69cb\u5efa\u4e8b\u4ef6\u77e5\u8b58\u5716\u8b5c (EKG)\uff0c\u4ee5\u4fbf\u6709\u6548\u5730\u7d22\u5f15\u9577\u5f71\u7247\u6216\u9023\u7e8c\u5f71\u7247\u4e32\u6d41\uff1b(2) \u4e00\u7a2e\u4ee3\u7406\u6aa2\u7d22-\u751f\u6210\u6a5f\u5236\uff0c\u5229\u7528 EKG \u4f86\u8655\u7406\u8907\u96dc\u591a\u6a23\u7684\u67e5\u8a62\u3002\u5728\u516c\u958b\u57fa\u6e96\u6e2c\u8a66 LVBench \u548c VideoMME-Long \u4e0a\u7684\u5168\u9762\u8a55\u4f30\u8868\u660e\uff0cAVA \u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6027\u80fd\uff0c\u6e96\u78ba\u7387\u5206\u5225\u9054\u5230 62.3% \u548c 64.1%\uff0c\u986f\u8457\u8d85\u8d8a\u4e86\u73fe\u6709\u7684 VLM \u548c\u5f71\u7247\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u7cfb\u7d71\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u8a55\u4f30\u8d85\u9577\u548c\u958b\u653e\u4e16\u754c\u5f71\u7247\u5834\u666f\u4e2d\u7684\u5f71\u7247\u5206\u6790\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7684\u57fa\u6e96\u6e2c\u8a66 AVA-100\u3002\u8a72\u57fa\u6e96\u6e2c\u8a66\u5305\u542b 8 \u500b\u5f71\u7247\uff0c\u6bcf\u500b\u5f71\u7247\u7684\u6642\u9577\u90fd\u8d85\u904e 10 \u5c0f\u6642\uff0c\u4ee5\u53ca 120 \u500b\u624b\u52d5\u6a19\u8a18\u7684\u3001\u591a\u6a23\u4e14\u8907\u96dc\u7684\u554f\u984c-\u7b54\u6848\u5c0d\u3002\u5728 AVA-100 \u4e0a\uff0cAVA \u4ee5 75.8% \u7684\u6e96\u78ba\u7387\u9054\u5230\u4e86\u9802\u7d1a\u6027\u80fd\u3002</paragraph>\n", "author": "Yuxuan Yan et.al.", "authors": "Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu", "id": "2505.00254v1", "paper_url": "http://arxiv.org/abs/2505.00254v1", "repo": "null"}}