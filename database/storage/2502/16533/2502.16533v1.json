{"2502.16533": {"publish_time": "2025-02-23", "title": "A Survey of Graph Transformers: Architectures, Theories and Applications", "paper_summary": "Graph Transformers (GTs) have demonstrated a strong capability in modeling\ngraph structures by addressing the intrinsic limitations of graph neural\nnetworks (GNNs), such as over-smoothing and over-squashing. Recent studies have\nproposed diverse architectures, enhanced explainability, and practical\napplications for Graph Transformers. In light of these rapid developments, we\nconduct a comprehensive review of Graph Transformers, covering aspects such as\ntheir architectures, theoretical foundations, and applications within this\nsurvey. We categorize the architecture of Graph Transformers according to their\nstrategies for processing structural information, including graph tokenization,\npositional encoding, structure-aware attention and model ensemble. Furthermore,\nfrom the theoretical perspective, we examine the expressivity of Graph\nTransformers in various discussed architectures and contrast them with other\nadvanced graph learning algorithms to discover the connections. Furthermore, we\nprovide a summary of the practical applications where Graph Transformers have\nbeen utilized, such as molecule, protein, language, vision traffic, brain and\nmaterial data. At the end of this survey, we will discuss the current\nchallenges and prospective directions in Graph Transformers for potential\nfuture research.", "paper_summary_zh": "\u5716\u5f62Transformer (GT) \u5df2\u5c55\u73fe\u51fa\u5f37\u5927\u7684\u5efa\u6a21\u5716\u5f62\u7d50\u69cb\u80fd\u529b\uff0c\u85c9\u7531\u89e3\u6c7a\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u7684\u5167\u5728\u9650\u5236\uff0c\u4f8b\u5982\u904e\u5ea6\u5e73\u6ed1\u548c\u904e\u5ea6\u58d3\u7e2e\u3002\u6700\u8fd1\u7684\u7814\u7a76\u63d0\u51fa\u591a\u6a23\u5316\u7684\u67b6\u69cb\u3001\u589e\u5f37\u7684\u53ef\u89e3\u91cb\u6027\uff0c\u4ee5\u53ca\u5716\u5f62Transformer\u7684\u5be6\u7528\u61c9\u7528\u3002\u6709\u9451\u65bc\u9019\u4e9b\u5feb\u901f\u7684\u767c\u5c55\uff0c\u6211\u5011\u5c0d\u5716\u5f62Transformer\u9032\u884c\u5168\u9762\u7684\u56de\u9867\uff0c\u6db5\u84cb\u5176\u67b6\u69cb\u3001\u7406\u8ad6\u57fa\u790e\u548c\u672c\u8abf\u67e5\u4e2d\u7684\u61c9\u7528\u7b49\u9762\u5411\u3002\u6211\u5011\u6839\u64da\u5716\u5f62Transformer\u8655\u7406\u7d50\u69cb\u8cc7\u8a0a\u7684\u7b56\u7565\u5c0d\u5176\u67b6\u69cb\u9032\u884c\u5206\u985e\uff0c\u5305\u62ec\u5716\u5f62\u6a19\u8a18\u5316\u3001\u4f4d\u7f6e\u7de8\u78bc\u3001\u7d50\u69cb\u611f\u77e5\u6ce8\u610f\u529b\u548c\u6a21\u578b\u96c6\u6210\u3002\u6b64\u5916\uff0c\u5f9e\u7406\u8ad6\u89d2\u5ea6\u4f86\u770b\uff0c\u6211\u5011\u63a2\u8a0e\u5404\u7a2e\u8a0e\u8ad6\u67b6\u69cb\u4e2d\u5716\u5f62Transformer\u7684\u8868\u73fe\u529b\uff0c\u4e26\u5c07\u5176\u8207\u5176\u4ed6\u9032\u968e\u5716\u5f62\u5b78\u7fd2\u6f14\u7b97\u6cd5\u9032\u884c\u5c0d\u6bd4\uff0c\u4ee5\u627e\u51fa\u95dc\u806f\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u4f9b\u5716\u5f62Transformer\u5df2\u7528\u65bc\u5be6\u7528\u61c9\u7528\u7a0b\u5f0f\u6458\u8981\uff0c\u4f8b\u5982\u5206\u5b50\u3001\u86cb\u767d\u8cea\u3001\u8a9e\u8a00\u3001\u8996\u89ba\u4ea4\u901a\u3001\u5927\u8166\u548c\u6750\u6599\u8cc7\u6599\u3002\u5728\u672c\u8abf\u67e5\u7684\u6700\u5f8c\uff0c\u6211\u5011\u5c07\u8a0e\u8ad6\u5716\u5f62Transformer\u4e2d\u7576\u524d\u7684\u6311\u6230\u548c\u672a\u4f86\u7814\u7a76\u7684\u6f5b\u5728\u65b9\u5411\u3002", "author": "Chaohao Yuan et.al.", "authors": "Chaohao Yuan, Kangfei Zhao, Ercan Engin Kuruoglu, Liang Wang, Tingyang Xu, Wenbing Huang, Deli Zhao, Hong Cheng, Yu Rong", "id": "2502.16533v1", "paper_url": "http://arxiv.org/abs/2502.16533v1", "repo": "null"}}