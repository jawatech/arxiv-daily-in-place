{"2501.04995": {"publish_time": "2025-01-09", "title": "IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation", "paper_summary": "3D Referring Expression Segmentation (3D-RES) aims to segment point cloud\nscenes based on a given expression. However, existing 3D-RES approaches face\ntwo major challenges: feature ambiguity and intent ambiguity. Feature ambiguity\narises from information loss or distortion during point cloud acquisition due\nto limitations such as lighting and viewpoint. Intent ambiguity refers to the\nmodel's equal treatment of all queries during the decoding process, lacking\ntop-down task-specific guidance. In this paper, we introduce an Image enhanced\nPrompt Decoding Network (IPDN), which leverages multi-view images and\ntask-driven information to enhance the model's reasoning capabilities. To\naddress feature ambiguity, we propose the Multi-view Semantic Embedding (MSE)\nmodule, which injects multi-view 2D image information into the 3D scene and\ncompensates for potential spatial information loss. To tackle intent ambiguity,\nwe designed a Prompt-Aware Decoder (PAD) that guides the decoding process by\nderiving task-driven signals from the interaction between the expression and\nvisual features. Comprehensive experiments demonstrate that IPDN outperforms\nthe state-ofthe-art by 1.9 and 4.2 points in mIoU metrics on the 3D-RES and\n3D-GRES tasks, respectively.", "paper_summary_zh": "3D \u53c3\u8003\u8868\u9054\u5206\u5272 (3D-RES) \u65e8\u5728\u6839\u64da\u7d66\u5b9a\u7684\u8868\u9054\u5f0f\u5c0d\u9ede\u96f2\u5834\u666f\u9032\u884c\u5206\u5272\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 3D-RES \u65b9\u6cd5\u9762\u81e8\u5169\u5927\u6311\u6230\uff1a\u7279\u5fb5\u6a21\u7cca\u548c\u610f\u5716\u6a21\u7cca\u3002\u7279\u5fb5\u6a21\u7cca\u662f\u7531\u65bc\u9ede\u96f2\u63a1\u96c6\u904e\u7a0b\u4e2d\u7531\u65bc\u7167\u660e\u548c\u8996\u9ede\u7b49\u9650\u5236\u800c\u5c0e\u81f4\u7684\u4fe1\u606f\u4e1f\u5931\u6216\u5931\u771f\u3002\u610f\u5716\u6a21\u7cca\u662f\u6307\u6a21\u578b\u5728\u89e3\u78bc\u904e\u7a0b\u4e2d\u5c0d\u6240\u6709\u67e5\u8a62\u9032\u884c\u5e73\u7b49\u8655\u7406\uff0c\u7f3a\u4e4f\u81ea\u4e0a\u800c\u4e0b\u7684\u4efb\u52d9\u7279\u5b9a\u6307\u5c0e\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u5716\u50cf\u589e\u5f37\u63d0\u793a\u89e3\u78bc\u7db2\u7d61 (IPDN)\uff0c\u5b83\u5229\u7528\u591a\u8996\u5716\u5716\u50cf\u548c\u4efb\u52d9\u9a45\u52d5\u4fe1\u606f\u4f86\u589e\u5f37\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u70ba\u4e86\u89e3\u6c7a\u7279\u5fb5\u6a21\u7cca\u7684\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u591a\u8996\u5716\u8a9e\u7fa9\u5d4c\u5165 (MSE) \u6a21\u584a\uff0c\u5b83\u5c07\u591a\u8996\u5716 2D \u5716\u50cf\u4fe1\u606f\u6ce8\u5165\u5230 3D \u5834\u666f\u4e2d\uff0c\u4e26\u5f4c\u88dc\u4e86\u6f5b\u5728\u7684\u7a7a\u9593\u4fe1\u606f\u4e1f\u5931\u3002\u70ba\u4e86\u89e3\u6c7a\u610f\u5716\u6a21\u7cca\u7684\u554f\u984c\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u63d0\u793a\u611f\u77e5\u89e3\u78bc\u5668 (PAD)\uff0c\u5b83\u901a\u904e\u5f9e\u8868\u9054\u5f0f\u548c\u8996\u89ba\u7279\u5fb5\u4e4b\u9593\u7684\u4ea4\u4e92\u4e2d\u63a8\u5c0e\u51fa\u4efb\u52d9\u9a45\u52d5\u4fe1\u865f\u4f86\u6307\u5c0e\u89e3\u78bc\u904e\u7a0b\u3002\u7d9c\u5408\u5be6\u9a57\u8868\u660e\uff0cIPDN \u5728 3D-RES \u548c 3D-GRES \u4efb\u52d9\u7684 mIoU \u6307\u6a19\u4e0a\u5206\u5225\u6bd4\u6700\u5148\u9032\u7684\u6280\u8853\u9ad8\u51fa 1.9 \u548c 4.2 \u500b\u9ede\u3002", "author": "Qi Chen et.al.", "authors": "Qi Chen, Changli Wu, Jiayi Ji, Yiwei Ma, Danni Yang, Xiaoshuai Sun", "id": "2501.04995v1", "paper_url": "http://arxiv.org/abs/2501.04995v1", "repo": "null"}}