{"2411.17170": {"publish_time": "2024-11-26", "title": "Learning Monotonic Attention in Transducer for Streaming Generation", "paper_summary": "Streaming generation models are increasingly utilized across various fields,\nwith the Transducer architecture being particularly popular in industrial\napplications. However, its input-synchronous decoding mechanism presents\nchallenges in tasks requiring non-monotonic alignments, such as simultaneous\ntranslation, leading to suboptimal performance in these contexts. In this\nresearch, we address this issue by tightly integrating Transducer's decoding\nwith the history of input stream via a learnable monotonic attention mechanism.\nOur approach leverages the forward-backward algorithm to infer the posterior\nprobability of alignments between the predictor states and input timestamps,\nwhich is then used to estimate the context representations of monotonic\nattention in training. This allows Transducer models to adaptively adjust the\nscope of attention based on their predictions, avoiding the need to enumerate\nthe exponentially large alignment space. Extensive experiments demonstrate that\nour MonoAttn-Transducer significantly enhances the handling of non-monotonic\nalignments in streaming generation, offering a robust solution for\nTransducer-based frameworks to tackle more complex streaming generation tasks.", "paper_summary_zh": "\u4e32\u6d41\u751f\u6210\u6a21\u578b\u5728\u5404\u500b\u9818\u57df\u4e2d\u4f7f\u7528\u8d8a\u4f86\u8d8a\u5ee3\u6cdb\uff0c\u5176\u4e2d Transducer \u67b6\u69cb\u5728\u7522\u696d\u61c9\u7528\u4e2d\u7279\u5225\u53d7\u5230\u6b61\u8fce\u3002\u7136\u800c\uff0c\u5b83\u7684\u8f38\u5165\u540c\u6b65\u89e3\u78bc\u6a5f\u5236\u5728\u9700\u8981\u975e\u55ae\u8abf\u5c0d\u9f4a\u7684\u4efb\u52d9\u4e2d\uff08\u4f8b\u5982\u540c\u6b65\u7ffb\u8b6f\uff09\u6703\u9047\u5230\u6311\u6230\uff0c\u5c0e\u81f4\u5728\u9019\u4e9b\u60c5\u5883\u4e2d\u8868\u73fe\u4e0d\u4f73\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u900f\u904e\u4e00\u500b\u53ef\u5b78\u7fd2\u7684\u55ae\u8abf\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u7dca\u5bc6\u6574\u5408 Transducer \u7684\u89e3\u78bc\u8207\u8f38\u5165\u4e32\u6d41\u7684\u6b77\u53f2\u8a18\u9304\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u6211\u5011\u7684\u505a\u6cd5\u5229\u7528\u524d\u9032\u5f8c\u9000\u6f14\u7b97\u6cd5\u4f86\u63a8\u8ad6\u9810\u6e2c\u72c0\u614b\u8207\u8f38\u5165\u6642\u9593\u6233\u8a18\u4e4b\u9593\u5c0d\u9f4a\u7684\u5f8c\u9a57\u6a5f\u7387\uff0c\u7136\u5f8c\u7528\u65bc\u4f30\u8a08\u8a13\u7df4\u4e2d\u55ae\u8abf\u6ce8\u610f\u529b\u7684\u80cc\u666f\u8868\u793a\u3002\u9019\u8b93 Transducer \u6a21\u578b\u80fd\u5920\u6839\u64da\u5176\u9810\u6e2c\u52d5\u614b\u8abf\u6574\u6ce8\u610f\u529b\u7684\u7bc4\u570d\uff0c\u907f\u514d\u9700\u8981\u5217\u8209\u6307\u6578\u7d1a\u5927\u7684\u5c0d\u9f4a\u7a7a\u9593\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u6211\u5011\u7684 MonoAttn-Transducer \u5927\u5e45\u63d0\u5347\u4e32\u6d41\u751f\u6210\u4e2d\u975e\u55ae\u8abf\u5c0d\u9f4a\u7684\u8655\u7406\uff0c\u70ba\u57fa\u65bc Transducer \u7684\u67b6\u69cb\u63d0\u4f9b\u4e00\u500b\u5f37\u5065\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4ee5\u61c9\u5c0d\u66f4\u8907\u96dc\u7684\u4e32\u6d41\u751f\u6210\u4efb\u52d9\u3002", "author": "Zhengrui Ma et.al.", "authors": "Zhengrui Ma, Yang Feng, Min Zhang", "id": "2411.17170v1", "paper_url": "http://arxiv.org/abs/2411.17170v1", "repo": "https://github.com/ictnlp/monoattn-transducer"}}