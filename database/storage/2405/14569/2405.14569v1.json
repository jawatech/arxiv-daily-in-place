{"2405.14569": {"publish_time": "2024-05-23", "title": "PrivCirNet: Efficient Private Inference via Block Circulant Transformation", "paper_summary": "Homomorphic encryption (HE)-based deep neural network (DNN) inference\nprotects data and model privacy but suffers from significant computation\noverhead. We observe transforming the DNN weights into circulant matrices\nconverts general matrix-vector multiplications into HE-friendly 1-dimensional\nconvolutions, drastically reducing the HE computation cost. Hence, in this\npaper, we propose \\method, a protocol/network co-optimization framework based\non block circulant transformation. At the protocol level, PrivCirNet customizes\nthe HE encoding algorithm that is fully compatible with the block circulant\ntransformation and reduces the computation latency in proportion to the block\nsize. At the network level, we propose a latency-aware formulation to search\nfor the layer-wise block size assignment based on second-order information.\nPrivCirNet also leverages layer fusion to further reduce the inference cost. We\ncompare PrivCirNet with the state-of-the-art HE-based framework Bolt (IEEE S\\&P\n2024) and the HE-friendly pruning method SpENCNN (ICML 2023). For ResNet-18 and\nVision Transformer (ViT) on Tiny ImageNet, PrivCirNet reduces latency by\n$5.0\\times$ and $1.3\\times$ with iso-accuracy over Bolt, respectively, and\nimproves accuracy by $4.1\\%$ and $12\\%$ over SpENCNN, respectively. For\nMobileNetV2 on ImageNet, PrivCirNet achieves $1.7\\times$ lower latency and\n$4.2\\%$ better accuracy over Bolt and SpENCNN, respectively. Our code and\ncheckpoints are available in the supplementary materials.", "paper_summary_zh": "<paragraph>\u57fa\u65bc\u540c\u614b\u52a0\u5bc6 (HE) \u7684\u6df1\u5ea6\u795e\u7d93\u7db2\u8def (DNN) \u63a8\u8ad6\u4fdd\u8b77\u8cc7\u6599\u548c\u6a21\u578b\u96b1\u79c1\uff0c\u4f46\u6703\u5e36\u4f86\u986f\u8457\u7684\u8a08\u7b97\u958b\u92b7\u3002\u6211\u5011\u89c0\u5bdf\u5230\u5c07 DNN \u6b0a\u91cd\u8f49\u63db\u6210\u5faa\u74b0\u77e9\u9663\uff0c\u6703\u5c07\u4e00\u822c\u77e9\u9663-\u5411\u91cf\u4e58\u6cd5\u8f49\u63db\u6210 HE \u53cb\u597d\u7684 1 \u7dad\u5377\u7a4d\uff0c\u5927\u5e45\u964d\u4f4e HE \u8a08\u7b97\u6210\u672c\u3002\u56e0\u6b64\uff0c\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa PrivCirNet\uff0c\u4e00\u7a2e\u57fa\u65bc\u5340\u584a\u5faa\u74b0\u8f49\u63db\u7684\u5354\u5b9a/\u7db2\u8def\u5171\u540c\u6700\u4f73\u5316\u67b6\u69cb\u3002\u5728\u5354\u5b9a\u5c64\u7d1a\uff0cPrivCirNet \u5ba2\u88fd\u5316 HE \u7de8\u78bc\u6f14\u7b97\u6cd5\uff0c\u8207\u5340\u584a\u5faa\u74b0\u8f49\u63db\u5b8c\u5168\u76f8\u5bb9\uff0c\u4e26\u6839\u64da\u5340\u584a\u5927\u5c0f\u6210\u6bd4\u4f8b\u5730\u6e1b\u5c11\u8a08\u7b97\u5ef6\u9072\u3002\u5728\u7db2\u8def\u5c64\u7d1a\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5ef6\u9072\u611f\u77e5\u516c\u5f0f\uff0c\u6839\u64da\u4e8c\u968e\u8cc7\u8a0a\u641c\u5c0b\u5c64\u7d1a\u5340\u584a\u5927\u5c0f\u914d\u7f6e\u3002PrivCirNet \u4e5f\u5229\u7528\u5c64\u878d\u5408\u9032\u4e00\u6b65\u964d\u4f4e\u63a8\u8ad6\u6210\u672c\u3002\u6211\u5011\u5c07 PrivCirNet \u8207\u6700\u5148\u9032\u7684\u57fa\u65bc HE \u7684\u67b6\u69cb Bolt\uff08IEEE S&P 2024\uff09\u548c HE \u53cb\u597d\u7684\u526a\u679d\u65b9\u6cd5 SpENCNN\uff08ICML 2023\uff09\u9032\u884c\u6bd4\u8f03\u3002\u5c0d\u65bc Tiny ImageNet \u4e0a\u7684 ResNet-18 \u548c Vision Transformer (ViT)\uff0cPrivCirNet \u5206\u5225\u4ee5\u8207 Bolt \u76f8\u540c\u7684\u6e96\u78ba\u5ea6\u5c07\u5ef6\u9072\u964d\u4f4e\u4e86 5.0 \u500d\u548c 1.3 \u500d\uff0c\u4e26\u5206\u5225\u6bd4 SpENCNN \u63d0\u9ad8\u4e86 4.1% \u548c 12% \u7684\u6e96\u78ba\u5ea6\u3002\u5c0d\u65bc ImageNet \u4e0a\u7684 MobileNetV2\uff0cPrivCirNet \u5206\u5225\u6bd4 Bolt \u548c SpENCNN \u964d\u4f4e\u4e86 1.7 \u500d\u7684\u5ef6\u9072\uff0c\u4e26\u63d0\u9ad8\u4e86 4.2% \u7684\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u548c\u6aa2\u67e5\u9ede\u53ef\u5728\u88dc\u5145\u8cc7\u6599\u4e2d\u53d6\u5f97\u3002</paragraph>", "author": "Tianshi Xu et.al.", "authors": "Tianshi Xu, Lemeng Wu, Runsheng Wang, Meng Li", "id": "2405.14569v1", "paper_url": "http://arxiv.org/abs/2405.14569v1", "repo": "null"}}