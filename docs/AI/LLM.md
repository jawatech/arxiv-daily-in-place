
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-25**|**Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?**|Sohee Yang et.al.|[2411.16679v1](http://arxiv.org/abs/2411.16679v1)|null|
|**2024-11-25**|**CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance**|Jiaan Han et.al.|[2411.16666v1](http://arxiv.org/abs/2411.16666v1)|null|
|**2024-11-25**|**DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation**|Zun Wang et.al.|[2411.16657v1](http://arxiv.org/abs/2411.16657v1)|null|
|**2024-11-25**|**Self-Generated Critiques Boost Reward Modeling for Language Models**|Yue Yu et.al.|[2411.16646v1](http://arxiv.org/abs/2411.16646v1)|null|
|**2024-11-25**|**Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters**|Dietmar Jannach et.al.|[2411.16645v1](http://arxiv.org/abs/2411.16645v1)|null|
|**2024-11-25**|**Preventing Jailbreak Prompts as Malicious Tools for Cybercriminals: A Cyber Defense Perspective**|Jean Marie Tshimula et.al.|[2411.16642v1](http://arxiv.org/abs/2411.16642v1)|null|
|**2024-11-25**|**Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation**|Sanjana Ramprasad et.al.|[2411.16638v1](http://arxiv.org/abs/2411.16638v1)|null|
|**2024-11-25**|**Imperceptible Adversarial Examples in the Physical World**|Weilin Xu et.al.|[2411.16622v1](http://arxiv.org/abs/2411.16622v1)|null|
|**2024-11-25**|**StructFormer: Document Structure-based Masked Attention and its Impact on Language Model Pre-Training**|Kaustubh Ponkshe et.al.|[2411.16618v1](http://arxiv.org/abs/2411.16618v1)|null|
|**2024-11-25**|**Recent Trends in Linear Text Segmentation: a Survey**|Iacopo Ghinassi et.al.|[2411.16613v1](http://arxiv.org/abs/2411.16613v1)|null|
|**2024-11-25**|**F -- A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite**|Ansgar Scherp et.al.|[2411.16609v1](http://arxiv.org/abs/2411.16609v1)|[link](https://github.com/ascherp/ontologies)|
|**2024-11-25**|**From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge**|Dawei Li et.al.|[2411.16594v1](http://arxiv.org/abs/2411.16594v1)|[link](https://github.com/llm-as-a-judge/awesome-llm-as-a-judge)|
|**2024-11-25**|**Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision**|Zhiheng Xi et.al.|[2411.16579v1](http://arxiv.org/abs/2411.16579v1)|null|
|**2024-11-25**|**Naive Algorithmic Collusion: When Do Bandit Learners Cooperate and When Do They Compete?**|Connor Douglas et.al.|[2411.16574v1](http://arxiv.org/abs/2411.16574v1)|null|
|**2024-11-25**|**EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code**|Shahriyar Zaman Ridoy et.al.|[2411.16561v1](http://arxiv.org/abs/2411.16561v1)|null|
|**2024-11-25**|**Representation Collapsing Problems in Vector Quantization**|Wenhao Zhao et.al.|[2411.16550v1](http://arxiv.org/abs/2411.16550v1)|null|
|**2024-11-25**|**RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics**|Chan Hee Song et.al.|[2411.16537v1](http://arxiv.org/abs/2411.16537v1)|null|
|**2024-11-25**|**Profiling Bias in LLMs: Stereotype Dimensions in Contextual Word Embeddings**|Carolin M. Schuster et.al.|[2411.16527v1](http://arxiv.org/abs/2411.16527v1)|null|
|**2024-11-25**|**Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency**|Jerry Yao-Chieh Hu et.al.|[2411.16525v1](http://arxiv.org/abs/2411.16525v1)|null|
|**2024-11-25**|**LaB-RAG: Label Boosted Retrieval Augmented Generation for Radiology Report Generation**|Steven Song et.al.|[2411.16523v1](http://arxiv.org/abs/2411.16523v1)|null|
|**2024-11-25**|**All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages**|Ashmal Vayani et.al.|[2411.16508v1](http://arxiv.org/abs/2411.16508v1)|null|
|**2024-11-25**|**Interpreting Language Reward Models via Contrastive Explanations**|Junqi Jiang et.al.|[2411.16502v1](http://arxiv.org/abs/2411.16502v1)|null|
|**2024-11-25**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495v1](http://arxiv.org/abs/2411.16495v1)|null|
|**2024-11-25**|**O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?**|Zhen Huang et.al.|[2411.16489v1](http://arxiv.org/abs/2411.16489v1)|[link](https://github.com/gair-nlp/o1-journey)|
|**2024-11-25**|**When Babies Teach Babies: Can student knowledge sharing outperform Teacher-Guided Distillation on small datasets?**|Srikrishna Iyer et.al.|[2411.16487v1](http://arxiv.org/abs/2411.16487v1)|[link](https://github.com/ai-da-stc/generative-ai-research-babylm)|
|**2024-11-25**|**Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction**|Haoming Li et.al.|[2411.16457v1](http://arxiv.org/abs/2411.16457v1)|null|
|**2024-11-25**|**Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**|Xiaocong Yang et.al.|[2411.16454v1](http://arxiv.org/abs/2411.16454v1)|null|
|**2024-11-25**|**TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment**|Luca Colombo et.al.|[2411.16442v1](http://arxiv.org/abs/2411.16442v1)|[link](https://github.com/ai-tech-research-lab/tifed)|
|**2024-11-25**|**Finding Structure in Language Models**|Jaap Jumelet et.al.|[2411.16433v1](http://arxiv.org/abs/2411.16433v1)|null|
|**2024-11-25**|**TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation**|Linqing Zhong et.al.|[2411.16425v1](http://arxiv.org/abs/2411.16425v1)|null|
|**2024-11-25**|**Turbofan Engine Remaining Useful Life (RUL) Prediction Based on Bi-Directional Long Short-Term Memory (BLSTM)**|Abedin Sherifi et.al.|[2411.16422v1](http://arxiv.org/abs/2411.16422v1)|null|
|**2024-11-25**|**A Study on Unsupervised Domain Adaptation for Semantic Segmentation in the Era of Vision-Language Models**|Manuel Schwonberg et.al.|[2411.16407v1](http://arxiv.org/abs/2411.16407v1)|null|
|**2024-11-25**|**Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN**|Elona Shatri et.al.|[2411.16405v1](http://arxiv.org/abs/2411.16405v1)|null|
|**2024-11-25**|**Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**|Alexander Fichtl et.al.|[2411.16403v1](http://arxiv.org/abs/2411.16403v1)|null|
|**2024-11-25**|**Human-Calibrated Automated Testing and Validation of Generative Language Models**|Agus Sudjianto et.al.|[2411.16391v1](http://arxiv.org/abs/2411.16391v1)|null|
|**2024-11-25**|**FineWeb-zhtw: Scalable Curation of Traditional Chinese Text Data from the Web**|Cheng-Wei Lin et.al.|[2411.16387v1](http://arxiv.org/abs/2411.16387v1)|null|
|**2024-11-25**|**Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**|Yuncheng Jiang et.al.|[2411.16380v1](http://arxiv.org/abs/2411.16380v1)|null|
|**2024-11-25**|**A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation**|M. M. A. Valiuddin et.al.|[2411.16370v1](http://arxiv.org/abs/2411.16370v1)|null|
|**2024-11-25**|**Multi-modal Retrieval Augmented Multi-modal Generation: A Benchmark, Evaluate Metrics and Strong Baselines**|Zi-Ao Ma et.al.|[2411.16365v1](http://arxiv.org/abs/2411.16365v1)|null|
|**2024-11-25**|**Graph Neural Networks-based Parameter Design towards Large-Scale Superconducting Quantum Circuits for Crosstalk Mitigation**|Hao Ai et.al.|[2411.16354v1](http://arxiv.org/abs/2411.16354v1)|null|
|**2024-11-25**|**The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C**|Mikita Balesni et.al.|[2411.16353v1](http://arxiv.org/abs/2411.16353v1)|null|
|**2024-11-25**|**Preference Optimization for Reasoning with Pseudo Feedback**|Fangkai Jiao et.al.|[2411.16345v1](http://arxiv.org/abs/2411.16345v1)|null|
|**2024-11-25**|**Can AI grade your essays? A comparative analysis of large language models and teacher ratings in multidimensional essay scoring**|Kathrin Se√üler et.al.|[2411.16337v1](http://arxiv.org/abs/2411.16337v1)|null|
|**2024-11-25**|**One Diffusion to Generate Them All**|Duong H. Le et.al.|[2411.16318v1](http://arxiv.org/abs/2411.16318v1)|[link](https://github.com/lehduong/onediffusion)|
|**2024-11-25**|**CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning**|Duo Wu et.al.|[2411.16313v1](http://arxiv.org/abs/2411.16313v1)|null|
|**2024-11-25**|**Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems**|Magdalena Kaiser et.al.|[2411.16305v1](http://arxiv.org/abs/2411.16305v1)|null|
|**2024-11-25**|**BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment**|Shaolei Zhang et.al.|[2411.16300v1](http://arxiv.org/abs/2411.16300v1)|[link](https://github.com/ictnlp/bayling)|
|**2024-11-25**|**The SVASR System for Text-dependent Speaker Verification (TdSV) AAIC Challenge 2024**|Mohammadreza Molavi et.al.|[2411.16276v1](http://arxiv.org/abs/2411.16276v1)|null|
|**2024-11-25**|**Probing for Consciousness in Machines**|Mathis Immertreu et.al.|[2411.16262v1](http://arxiv.org/abs/2411.16262v1)|null|
|**2024-11-25**|**Unraveling Arithmetic in Large Language Models: The Role of Algebraic Structures**|Fu-Chieh Chang et.al.|[2411.16260v1](http://arxiv.org/abs/2411.16260v1)|null|
|**2024-11-25**|**NormXLogit: The Head-on-Top Never Lies**|Sina Abbasi et.al.|[2411.16252v1](http://arxiv.org/abs/2411.16252v1)|null|
|**2024-11-25**|**Transparent Neighborhood Approximation for Text Classifier Explanation**|Yi Cai et.al.|[2411.16251v1](http://arxiv.org/abs/2411.16251v1)|null|
|**2024-11-25**|**DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence Embeddings**|Hong Liu et.al.|[2411.16236v1](http://arxiv.org/abs/2411.16236v1)|null|
|**2024-11-25**|**MH-MoE:Multi-Head Mixture-of-Experts**|Shaohan Huang et.al.|[2411.16205v1](http://arxiv.org/abs/2411.16205v1)|null|
|**2024-11-25**|**Video-Text Dataset Construction from Multi-AI Feedback: Promoting Weak-to-Strong Preference Learning for Video Large Language Models**|Hao Yi et.al.|[2411.16201v1](http://arxiv.org/abs/2411.16201v1)|null|
|**2024-11-25**|**Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models**|Zhihua Duan et.al.|[2411.16189v1](http://arxiv.org/abs/2411.16189v1)|null|
|**2024-11-25**|**SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis**|Junho Kim et.al.|[2411.16173v1](http://arxiv.org/abs/2411.16173v1)|null|
|**2024-11-25**|**MixPE: Quantization and Hardware Co-design for Efficient LLM Inference**|Yu Zhang et.al.|[2411.16158v1](http://arxiv.org/abs/2411.16158v1)|null|
|**2024-11-25**|**Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning**|Toyotaro Suzumura et.al.|[2411.16155v1](http://arxiv.org/abs/2411.16155v1)|null|
|**2024-11-25**|**SKQVC: One-Shot Voice Conversion by K-Means Quantization with Self-Supervised Speech Representations**|Youngjun Sim et.al.|[2411.16147v1](http://arxiv.org/abs/2411.16147v1)|null|
|**2024-11-25**|**End-to-End Steering for Autonomous Vehicles via Conditional Imitation Co-Learning**|Mahmoud M. Kishky et.al.|[2411.16131v1](http://arxiv.org/abs/2411.16131v1)|null|
|**2024-11-25**|**Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**|Hangyul Yoon et.al.|[2411.16123v1](http://arxiv.org/abs/2411.16123v1)|null|
|**2024-11-25**|**Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**|Rui Zuo et.al.|[2411.16120v1](http://arxiv.org/abs/2411.16120v1)|null|
|**2024-11-25**|**LLM Augmentations to support Analytical Reasoning over Multiple Documents**|Raquib Bin Yousuf et.al.|[2411.16116v1](http://arxiv.org/abs/2411.16116v1)|[link](https://github.com/discoveryanalyticscenter/speculatores)|
|**2024-11-25**|**LLMPirate: LLMs for Black-box Hardware IP Piracy**|Vasudev Gohil et.al.|[2411.16111v1](http://arxiv.org/abs/2411.16111v1)|null|
|**2024-11-25**|**Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability**|Jatin Nainani et.al.|[2411.16105v1](http://arxiv.org/abs/2411.16105v1)|null|
|**2024-11-25**|**An Empirical Study of Vulnerability Detection using Federated Learning**|Peiheng Zhou et.al.|[2411.16099v1](http://arxiv.org/abs/2411.16099v1)|null|
|**2024-11-25**|**ENCLIP: Ensembling and Clustering-Based Contrastive Language-Image Pretraining for Fashion Multimodal Search with Limited Data and Low-Quality Images**|Prithviraj Purushottam Naik et.al.|[2411.16096v1](http://arxiv.org/abs/2411.16096v1)|null|
|**2024-11-25**|**HiDP: Hierarchical DNN Partitioning for Distributed Inference on Heterogeneous Edge Platforms**|Zain Taufique et.al.|[2411.16086v1](http://arxiv.org/abs/2411.16086v1)|null|
|**2024-11-25**|**Deciphering genomic codes using advanced NLP techniques: a scoping review**|Shuyan Cheng et.al.|[2411.16084v1](http://arxiv.org/abs/2411.16084v1)|null|
|**2024-11-25**|**Boosting 3D Object Generation through PBR Materials**|Yitong Wang et.al.|[2411.16080v1](http://arxiv.org/abs/2411.16080v1)|null|
|**2024-11-25**|**Debiasing Classifiers by Amplifying Bias with Latent Diffusion and Large Language Models**|Donggeun Ko et.al.|[2411.16079v1](http://arxiv.org/abs/2411.16079v1)|null|
|**2024-11-25**|**SAGEval: The frontiers of Satisfactory Agent based NLG Evaluation for reference-free open-ended text**|Reshmi Ghosh et.al.|[2411.16077v1](http://arxiv.org/abs/2411.16077v1)|null|
|**2024-11-25**|**The brain versus AI: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum**|Shogo Ohmae et.al.|[2411.16075v1](http://arxiv.org/abs/2411.16075v1)|null|
|**2024-11-25**|**UnitedVLN: Generalizable Gaussian Splatting for Continuous Vision-Language Navigation**|Guangzhao Dai et.al.|[2411.16053v1](http://arxiv.org/abs/2411.16053v1)|null|
|**2024-11-25**|**Predicting Emergent Capabilities by Finetuning**|Charlie Snell et.al.|[2411.16035v1](http://arxiv.org/abs/2411.16035v1)|null|
|**2024-11-25**|**From Dashcam Videos to Driving Simulations: Stress Testing Automated Vehicles against Rare Events**|Yan Miao et.al.|[2411.16027v1](http://arxiv.org/abs/2411.16027v1)|null|
|**2024-11-25**|**TransCompressor: LLM-Powered Multimodal Data Compression for Smart Transportation**|Huanqi Yang et.al.|[2411.16020v1](http://arxiv.org/abs/2411.16020v1)|null|
|**2024-11-24**|**Performance Implications of Multi-Chiplet Neural Processing Units on Autonomous Driving Perception**|Mohanad Odema et.al.|[2411.16007v1](http://arxiv.org/abs/2411.16007v1)|null|
|**2024-11-24**|**eFedLLM: Efficient LLM Inference Based on Federated Learning**|Shengwen Ding et.al.|[2411.16003v1](http://arxiv.org/abs/2411.16003v1)|null|
|**2024-11-24**|**Exploring Performance Contrasts in TableQA: Step-by-Step Reasoning Boosts Bigger Language Models, Limits Smaller Language Models**|Haoyan Yang et.al.|[2411.16002v1](http://arxiv.org/abs/2411.16002v1)|null|
|**2024-11-24**|**Multi-ToM: Evaluating Multilingual Theory of Mind Capabilities in Large Language Models**|Jayanta Sadhu et.al.|[2411.15999v1](http://arxiv.org/abs/2411.15999v1)|null|
|**2024-11-24**|**PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making**|Jonathan Light et.al.|[2411.15998v1](http://arxiv.org/abs/2411.15998v1)|null|
|**2024-11-24**|**Ensuring Fair LLM Serving Amid Diverse Applications**|Redwan Ibne Seraj Khan et.al.|[2411.15997v1](http://arxiv.org/abs/2411.15997v1)|null|
|**2024-11-24**|**Investigating Factuality in Long-Form Text Generation: The Roles of Self-Known and Self-Unknown**|Lifu Tu et.al.|[2411.15993v1](http://arxiv.org/abs/2411.15993v1)|null|
|**2024-11-24**|**Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format**|Chao Fang et.al.|[2411.15982v1](http://arxiv.org/abs/2411.15982v1)|null|
|**2024-11-24**|**DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**|Ruiqiang Xiao et.al.|[2411.15976v1](http://arxiv.org/abs/2411.15976v1)|null|
|**2024-11-24**|**Partial Identifiability and Misspecification in Inverse Reinforcement Learning**|Joar Skalse et.al.|[2411.15951v1](http://arxiv.org/abs/2411.15951v1)|null|
|**2024-11-24**|**Generative Context Distillation**|Haebin Shin et.al.|[2411.15927v1](http://arxiv.org/abs/2411.15927v1)|null|
|**2024-11-24**|**Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan**|Saba Zahid et.al.|[2411.15923v1](http://arxiv.org/abs/2411.15923v1)|null|
|**2024-11-24**|**A Training-Free Approach for Music Style Transfer with Latent Diffusion Models**|Sooyoung Kim et.al.|[2411.15913v1](http://arxiv.org/abs/2411.15913v1)|null|
|**2024-11-24**|**Bimanual Grasp Synthesis for Dexterous Robot Hands**|Yanming Shao et.al.|[2411.15903v1](http://arxiv.org/abs/2411.15903v1)|null|
|**2024-11-24**|**Distribution-aware Online Continual Learning for Urban Spatio-Temporal Forecasting**|Chengxin Wang et.al.|[2411.15893v1](http://arxiv.org/abs/2411.15893v1)|null|
|**2024-11-24**|**Evaluating Large Language Models for Causal Modeling**|Houssam Razouk et.al.|[2411.15888v1](http://arxiv.org/abs/2411.15888v1)|null|
|**2024-11-24**|**LLMs Do Not Think Step-by-step In Implicit Reasoning**|Yijiong Yu et.al.|[2411.15862v1](http://arxiv.org/abs/2411.15862v1)|null|
|**2024-11-24**|**Unveiling the Superior Paradigm: A Comparative Study of Source-Free Domain Adaptation and Unsupervised Domain Adaptation**|Fan Wang et.al.|[2411.15844v1](http://arxiv.org/abs/2411.15844v1)|null|
|**2024-11-24**|**Efficient and Private: Memorisation under differentially private parameter-efficient fine-tuning in language models**|Olivia Ma et.al.|[2411.15831v1](http://arxiv.org/abs/2411.15831v1)|null|
|**2024-11-24**|**Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?**|Aryan Sajith et.al.|[2411.15821v1](http://arxiv.org/abs/2411.15821v1)|[link](https://github.com/aryan-sajith/urv-data_quantity_vs_data_quality-research)|
|**2024-11-24**|**FastTrackTr:Towards Fast Multi-Object Tracking with Transformers**|Pan Liao et.al.|[2411.15811v1](http://arxiv.org/abs/2411.15811v1)|null|
|**2024-11-24**|**Benchmarking Active Learning for NILM**|Dhruv Patel et.al.|[2411.15805v1](http://arxiv.org/abs/2411.15805v1)|null|

#### Abstracts
##### **Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?**
2411.16679v1 by Sohee Yang, Nora Kassner, Elena Gribovskaya, Sebastian Riedel, Mor Geva

We evaluate how well Large Language Models (LLMs) latently recall and compose
facts to answer multi-hop queries like "In the year Scarlett Johansson was
born, the Summer Olympics were hosted in the country of". One major challenge
in evaluating this ability is that LLMs may have developed shortcuts by
encounters of the head entity "Scarlett Johansson" and the answer entity
"United States" in the same training sequences or merely guess the answer based
on frequency-based priors. To prevent shortcuts, we exclude test queries where
the head and answer entities co-appear in pretraining corpora. Through careful
selection of relations and facts and systematic removal of cases where models
might guess answers or exploit partial matches, we construct an evaluation
dataset SOCRATES (ShOrtCut-fRee lATent rEaSoning). We observe that LLMs
demonstrate promising latent multi-hop reasoning abilities without exploiting
shortcuts, but only for certain types of queries. For queries requiring latent
recall of countries as the intermediate answer, the best models achieve 80%
latent composability, but this drops to just 5% for the recall of years.
Comparisons with Chain-of-Thought composability highlight a significant gap
between the ability of models to reason latently versus explicitly. Analysis
reveals that latent representations of the intermediate answer are constructed
more often in queries with higher latent composability, and shows the emergence
of latent multi-hop reasoning during pretraining.

ÊëòË¶ÅÔºöÊàëÂÄëË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÊΩõÂú®ÂõûÊÜ∂ÂíåÁµÑÂêà‰∫ãÂØ¶ÊñπÈù¢Ë°®ÁèæÂ¶Ç‰ΩïÔºå‰ª•ÂõûÁ≠îÂ§öÈáçË∑≥Ë∫çÊü•Ë©¢Ôºå‰æãÂ¶Ç„ÄåÂè≤ÂòâËïæÂñ¨ÈüìÊ£ÆÂá∫ÁîüÁöÑÈÇ£‰∏ÄÂπ¥ÔºåÂ§èÂ≠£Â•ßÈÅãÊúÉÂú®ÂúãÂÆ∂ËàâËæ¶„Äç„ÄÇË©ï‰º∞Ê≠§ËÉΩÂäõÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞Âú®ÊñºÔºåLLM ÂèØËÉΩÈÄèÈÅéÂú®Áõ∏ÂêåÁöÑË®ìÁ∑¥Â∫èÂàó‰∏≠ÈÅ≠ÈÅáÈ†≠ÈÉ®ÂØ¶È´î„ÄåÂè≤ÂòâËïæÂñ¨ÈüìÊ£Æ„ÄçÂíåÁ≠îÊ°àÂØ¶È´î„ÄåÁæéÂúã„ÄçËÄåÈñãÁôºÂá∫Êç∑ÂæëÔºåÊàñÂÉÖÊ†πÊìöÂü∫ÊñºÈ†ªÁéáÁöÑÂÖàÈ©óÁåúÊ∏¨Á≠îÊ°à„ÄÇÁÇ∫‰∫ÜÈò≤Ê≠¢Êç∑ÂæëÔºåÊàëÂÄëÊéíÈô§‰∫ÜÈ†≠ÈÉ®ÂíåÁ≠îÊ°àÂØ¶È´îÂú®È†êË®ìÁ∑¥Ë™ûÊñôÂ∫´‰∏≠ÂÖ±ÂêåÂá∫ÁèæÁöÑÊ∏¨Ë©¶Êü•Ë©¢„ÄÇÈÄèÈÅé‰ªîÁ¥∞ÈÅ∏ÊìáÈóú‰øÇÂíå‰∫ãÂØ¶Ôºå‰∏¶Á≥ªÁµ±ÊÄßÂú∞ÁßªÈô§Ê®°ÂûãÂèØËÉΩÁåúÊ∏¨Á≠îÊ°àÊàñÂà©Áî®ÈÉ®ÂàÜÂåπÈÖçÁöÑÊ°à‰æãÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãË©ï‰º∞Ë≥áÊñôÈõÜ SOCRATESÔºàShOrtCut-fRee lATent rEaSoningÔºâ„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåLLM Âú®‰∏çÂà©Áî®Êç∑ÂæëÁöÑÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÊΩõÂú®ÁöÑÂ§öÈáçË∑≥Ë∫çÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÂÉÖÈôêÊñºÁâπÂÆöÈ°ûÂûãÁöÑÊü•Ë©¢„ÄÇÂ∞çÊñºÈúÄË¶ÅÊΩõÂú®ÂõûÊÜ∂ÂúãÂÆ∂‰ΩúÁÇ∫‰∏≠ÈñìÁ≠îÊ°àÁöÑÊü•Ë©¢ÔºåÊúÄ‰Ω≥Ê®°ÂûãÈÅîÂà∞ 80% ÁöÑÊΩõÂú®ÂèØÁµÑÂêàÊÄßÔºå‰ΩÜÈÄôÂ∞çÊñºÂõûÊÜ∂Âπ¥‰ªΩ‰æÜË™™ÂÉÖ‰∏ãÈôçÂà∞ 5%„ÄÇËàáÊÄùËÄÉÈèàÂèØÁµÑÂêàÊÄßÁöÑÊØîËºÉÁ™ÅÈ°Ø‰∫ÜÊ®°ÂûãÊΩõÂú®Êé®ÁêÜËàáÊòéÁ¢∫Êé®ÁêÜËÉΩÂäõ‰πãÈñìÁöÑÈ°ØËëóÂ∑ÆË∑ù„ÄÇÂàÜÊûêÈ°ØÁ§∫ÔºåÂú®ÊΩõÂú®ÂèØÁµÑÂêàÊÄßËºÉÈ´òÁöÑÊü•Ë©¢‰∏≠Ôºå‰∏≠ÈñìÁ≠îÊ°àÁöÑÊΩõÂú®Ë°®Á§∫Êõ¥Â∏∏Ë¢´Âª∫ÊßãÔºå‰∏¶È°ØÁ§∫Âú®È†êË®ìÁ∑¥ÊúüÈñìÂá∫ÁèæÊΩõÂú®ÁöÑÂ§öÈáçË∑≥Ë∫çÊé®ÁêÜ„ÄÇ

##### **CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance**
2411.16666v1 by Jiaan Han, Junxiao Chen, Yanzhe Fu

We introduce CatNet, an algorithm that effectively controls False Discovery
Rate (FDR) and selects significant features in LSTM with the Gaussian Mirror
(GM) method. To evaluate the feature importance of LSTM in time series, we
introduce a vector of the derivative of the SHapley Additive exPlanations
(SHAP) to measure feature importance. We also propose a new kernel-based
dependence measure to avoid multicollinearity in the GM algorithm, to make a
robust feature selection with controlled FDR. We use simulated data to evaluate
CatNet's performance in both linear models and LSTM models with different link
functions. The algorithm effectively controls the FDR while maintaining a high
statistical power in all cases. We also evaluate the algorithm's performance in
different low-dimensional and high-dimensional cases, demonstrating its
robustness in various input dimensions. To evaluate CatNet's performance in
real world applications, we construct a multi-factor investment portfolio to
forecast the prices of S\&P 500 index components. The results demonstrate that
our model achieves superior predictive accuracy compared to traditional LSTM
models without feature selection and FDR control. Additionally, CatNet
effectively captures common market-driving features, which helps informed
decision-making in financial markets by enhancing the interpretability of
predictions. Our study integrates of the Gaussian Mirror algorithm with LSTM
models for the first time, and introduces SHAP values as a new feature
importance metric for FDR control methods, marking a significant advancement in
feature selection and error control for neural networks.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥π CatNetÔºå‰∏ÄÁ®ÆÊúâÊïàÊéßÂà∂ÂÅáÈôΩÊÄßÁôºÁèæÁéá (FDR) ÁöÑÊºîÁÆóÊ≥ïÔºå‰∏¶‰ΩøÁî®È´òÊñØÈè°ÂÉè (GM) ÊñπÊ≥ïÈÅ∏Âèñ LSTM ‰∏≠ÁöÑÈáçË¶ÅÁâπÂæµ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ LSTM Âú®ÊôÇÈñìÂ∫èÂàó‰∏≠ÁöÑÁâπÂæµÈáçË¶ÅÊÄßÔºåÊàëÂÄëÂºïÂÖ• SHapley Âä†Ê≥ïËß£Èáã (SHAP) ÁöÑÂ∞éÊï∏ÂêëÈáè‰æÜË°°ÈáèÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÊ†∏ÂøÉÁöÑ‰æùË≥¥ÊÄßÊ∏¨ÈáèÔºå‰ª•ÈÅøÂÖç GM ÊºîÁÆóÊ≥ï‰∏≠ÁöÑÂ§öÈáçÂÖ±Á∑öÊÄßÔºå‰ª•ÈÄ≤Ë°åÂÖ∑ÊúâÂèóÊéß FDR ÁöÑÁ©©ÂÅ•ÁâπÂæµÈÅ∏Âèñ„ÄÇÊàëÂÄë‰ΩøÁî®Ê®°Êì¨Ë≥áÊñô‰æÜË©ï‰º∞ CatNet Âú®ÂÖ∑Êúâ‰∏çÂêåÈÄ£ÁµêÂáΩÊï∏ÁöÑÁ∑öÊÄßÊ®°ÂûãÂíå LSTM Ê®°Âûã‰∏≠ÁöÑÊïàËÉΩ„ÄÇË©≤ÊºîÁÆóÊ≥ïÂú®ÊâÄÊúâÊÉÖÊ≥Å‰∏ãÈÉΩËÉΩÊúâÊïàÊéßÂà∂ FDRÔºåÂêåÊôÇ‰øùÊåÅÈ´òÁµ±Ë®àÂäüÊïà„ÄÇÊàëÂÄëÈÇÑË©ï‰º∞‰∫ÜË©≤ÊºîÁÆóÊ≥ïÂú®‰∏çÂêå‰ΩéÁ∂≠Â∫¶ÂíåÈ´òÁ∂≠Â∫¶ÊÉÖÊ≥Å‰∏ãÁöÑÊïàËÉΩÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®ÂêÑÁ®ÆËº∏ÂÖ•Á∂≠Â∫¶‰∏≠ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ CatNet Âú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÊïàËÉΩÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÂõ†Â≠êÊäïË≥áÁµÑÂêà‰æÜÈ†êÊ∏¨Ê®ôÊôÆ 500 ÊåáÊï∏ÊàêÂàÜÁöÑÂÉπÊ†º„ÄÇÁµêÊûúË°®ÊòéÔºåËàáÊ≤íÊúâÁâπÂæµÈÅ∏ÂèñÂíå FDR ÊéßÂà∂ÁöÑÂÇ≥Áµ± LSTM Ê®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂØ¶Áèæ‰∫ÜÂçìË∂äÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåCatNet ÊúâÊïàÂú∞Êì∑Âèñ‰∫ÜÂÖ±ÂêåÁöÑÂ∏ÇÂ†¥È©ÖÂãïÁâπÂæµÔºåÈÄôÊúâÂä©ÊñºÈÄèÈÅéÂ¢ûÂº∑È†êÊ∏¨ÁöÑÂèØËß£ÈáãÊÄßÔºåÂú®ÈáëËûçÂ∏ÇÂ†¥‰∏≠ÂÅöÂá∫ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È¶ñÊ¨°Â∞áÈ´òÊñØÈè°ÂÉèÊºîÁÆóÊ≥ïËàá LSTM Ê®°ÂûãÊï¥ÂêàÔºå‰∏¶Â∞á SHAP ÂÄº‰ΩúÁÇ∫ FDR ÊéßÂà∂ÊñπÊ≥ïÁöÑÊñ∞ÁâπÂæµÈáçË¶ÅÊÄßÊåáÊ®ôÔºåÊ®ôË™åËëóÁ•ûÁ∂ìÁ∂≤Ë∑ØÁâπÂæµÈÅ∏ÂèñÂíåÈåØË™§ÊéßÂà∂ÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇ</paragraph>

##### **DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation**
2411.16657v1 by Zun Wang, Jialu Li, Han Lin, Jaehong Yoon, Mohit Bansal

Storytelling video generation (SVG) has recently emerged as a task to create
long, multi-motion, multi-scene videos that consistently represent the story
described in the input text script. SVG holds great potential for diverse
content creation in media and entertainment; however, it also presents
significant challenges: (1) objects must exhibit a range of fine-grained,
complex motions, (2) multiple objects need to appear consistently across
scenes, and (3) subjects may require multiple motions with seamless transitions
within a single scene. To address these challenges, we propose DreamRunner, a
novel story-to-video generation method: First, we structure the input script
using a large language model (LLM) to facilitate both coarse-grained scene
planning as well as fine-grained object-level layout and motion planning. Next,
DreamRunner presents retrieval-augmented test-time adaptation to capture target
motion priors for objects in each scene, supporting diverse motion
customization based on retrieved videos, thus facilitating the generation of
new videos with complex, scripted motions. Lastly, we propose a novel
spatial-temporal region-based 3D attention and prior injection module SR3AI for
fine-grained object-motion binding and frame-by-frame semantic control. We
compare DreamRunner with various SVG baselines, demonstrating state-of-the-art
performance in character consistency, text alignment, and smooth transitions.
Additionally, DreamRunner exhibits strong fine-grained condition-following
ability in compositional text-to-video generation, significantly outperforming
baselines on T2V-ComBench. Finally, we validate DreamRunner's robust ability to
generate multi-object interactions with qualitative examples.

ÊëòË¶ÅÔºöÊïÖ‰∫ãÊïòËø∞ÂΩ±ÁâáÁîüÊàê (SVG) ÊúÄËøëÊàêÁÇ∫‰∫ÜÁî¢ÁîüÈï∑ÁØá„ÄÅÂ§öÂãï‰Ωú„ÄÅÂ§öÂ†¥ÊôØÂΩ±ÁâáÁöÑ‰ªªÂãôÔºåÈÄô‰∫õÂΩ±ÁâáËÉΩÊåÅÁ∫åÂëàÁèæËº∏ÂÖ•ÊñáÂ≠óËÖ≥Êú¨‰∏≠ÊâÄÊèèËø∞ÁöÑÊïÖ‰∫ã„ÄÇSVG Âú®Â™íÈ´îÂíåÂ®õÊ®Ç‰∏≠ÊìÅÊúâÂª£Ê≥õÁöÑÂÖßÂÆπÂâµÈÄ†ÊΩõÂäõÔºõÁÑ∂ËÄåÔºåÂÆÉ‰πüÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞Ôºö(1) Áâ©‰ª∂ÂøÖÈ†àÂ±ïÁèæ‰∏ÄÁ≥ªÂàóÁ¥∞Á∑ª„ÄÅË§áÈõúÁöÑÂãï‰ΩúÔºå(2) Â§öÂÄãÁâ©‰ª∂ÈúÄË¶ÅÂú®Â†¥ÊôØ‰∏≠ÊåÅÁ∫åÂá∫ÁèæÔºå(3) ‰∏ªÈ°åÂèØËÉΩÈúÄË¶ÅÂú®ÂñÆ‰∏ÄÂ†¥ÊôØ‰∏≠ÈÄ≤Ë°åÂ§öÂÄãÂãï‰ΩúÔºå‰∏¶ÈÄ≤Ë°åÁÑ°Á∏´ËΩâÊèõ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü DreamRunnerÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊïÖ‰∫ãÂà∞ÂΩ±ÁâáÁîüÊàêÊñπÊ≥ïÔºöÈ¶ñÂÖàÔºåÊàëÂÄë‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÂª∫ÊßãËº∏ÂÖ•ËÖ≥Êú¨Ôºå‰ª•‰øÉÈÄ≤Á≤óÁï•ÁöÑÂ†¥ÊôØË¶èÂäÉ‰ª•ÂèäÁ¥∞Á∑ªÁöÑÁâ©‰ª∂Á¥öÂà•‰ΩàÂ±ÄÂíåÂãï‰ΩúË¶èÂäÉ„ÄÇÊé•‰∏ã‰æÜÔºåDreamRunner ÊèêÂá∫Ê™¢Á¥¢Â¢ûÂº∑ÁöÑÊ∏¨Ë©¶ÊôÇÈñìÈÅ©ÊáâÔºå‰ª•Êì∑ÂèñÊØèÂÄãÂ†¥ÊôØ‰∏≠Áâ©‰ª∂ÁöÑÁõÆÊ®ôÂãï‰ΩúÂÖàÈ©óÔºåÊîØÊè¥Âü∫ÊñºÊ™¢Á¥¢ÂΩ±ÁâáÁöÑÂ§öÊ®£ÂåñÂãï‰ΩúËá™Ë®ÇÔºåÂæûËÄå‰øÉÈÄ≤Áî¢ÁîüÂÖ∑ÊúâË§áÈõú„ÄÅËÖ≥Êú¨Âãï‰ΩúÁöÑÊñ∞ÂΩ±Áâá„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂü∫ÊñºÊôÇÁ©∫ÂçÄÂüüÁöÑ 3D Ê≥®ÊÑèÂäõÂíåÂÖàÈ©óÊ≥®ÂÖ•Ê®°ÁµÑ SR3AIÔºåÁî®ÊñºÁ¥∞Á∑ªÁöÑÁâ©‰ª∂Âãï‰ΩúÁπ´ÁµêÂíåÈÄêÂπÄË™ûÁæ©ÊéßÂà∂„ÄÇÊàëÂÄëÂ∞á DreamRunner ËàáÂêÑÁ®Æ SVG Âü∫Ê∫ñÈÄ≤Ë°åÊØîËºÉÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®ËßíËâ≤‰∏ÄËá¥ÊÄß„ÄÅÊñáÂ≠óÂ∞çÈΩäÂíåÊµÅÊö¢ÈÅéÊ∏°ÊñπÈù¢ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåDreamRunner Âú®ÁµÑÂêàÂºèÊñáÂ≠óÂà∞ÂΩ±ÁâáÁîüÊàê‰∏≠Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÁ¥∞Á∑ªÊ¢ù‰ª∂ÈÅµÂæ™ËÉΩÂäõÔºåÂú® T2V-ComBench ‰∏äÊòéÈ°ØÂÑ™ÊñºÂü∫Ê∫ñ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈ©óË≠â‰∫Ü DreamRunner Áî¢ÁîüÂ§öÁâ©‰ª∂‰∫íÂãïÁöÑÂº∑Â§ßËÉΩÂäõÔºå‰∏¶Êèê‰æõ‰∫ÜÂÆöÊÄßÁØÑ‰æã„ÄÇ

##### **Self-Generated Critiques Boost Reward Modeling for Language Models**
2411.16646v1 by Yue Yu, Zhengxing Chen, Aston Zhang, Liang Tan, Chenguang Zhu, Richard Yuanzhe Pang, Yundi Qian, Xuewei Wang, Suchin Gururangan, Chao Zhang, Melanie Kambadur, Dhruv Mahajan, Rui Hou

Reward modeling is crucial for aligning large language models (LLMs) with
human preferences, especially in reinforcement learning from human feedback
(RLHF). However, current reward models mainly produce scalar scores and
struggle to incorporate critiques in a natural language format. We hypothesize
that predicting both critiques and the scalar reward would improve reward
modeling ability. Motivated by this, we propose Critic-RM, a framework that
improves reward models using self-generated critiques without extra
supervision. Critic-RM employs a two-stage process: generating and filtering
high-quality critiques, followed by joint fine-tuning on reward prediction and
critique generation. Experiments across benchmarks show that Critic-RM improves
reward modeling accuracy by 3.7%-7.3% compared to standard reward models and
LLM judges, demonstrating strong performance and data efficiency. Additional
studies further validate the effectiveness of generated critiques in rectifying
flawed reasoning steps with 2.5%-3.2% gains in improving reasoning accuracy.

ÊëòË¶ÅÔºöÁçéÂãµÂª∫Ê®°Â∞çÊñºÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëàá‰∫∫È°ûÂÅèÂ•Ω‰øùÊåÅ‰∏ÄËá¥Ëá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®‰∫∫È°ûÂõûÈ•ãÁöÑÂº∑ÂåñÂ≠∏Áøí (RLHF) ‰∏≠„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÁçéÂãµÊ®°Âûã‰∏ªË¶ÅÁî¢ÁîüÊ®ôÈáèÂàÜÊï∏Ôºå‰∏¶‰∏îÈõ£‰ª•‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÊ†ºÂºèÁ¥çÂÖ•ÊâπË©ï„ÄÇÊàëÂÄëÂÅáË®≠È†êÊ∏¨ÊâπË©ïÂíåÊ®ôÈáèÁçéÂãµÈÉΩÊúÉÊèêÈ´òÁçéÂãµÂª∫Ê®°ËÉΩÂäõ„ÄÇÂü∫ÊñºÊ≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü Critic-RMÔºåÈÄôÊòØ‰∏ÄÂÄãÂà©Áî®Ëá™ÊàëÁîüÊàêÁöÑÊâπË©ï‰æÜÊîπÈÄ≤ÁçéÂãµÊ®°ÂûãÁöÑÊ°ÜÊû∂ÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñÁöÑÁõ£Áù£„ÄÇCritic-RM Êé°Áî®ÂÖ©ÈöéÊÆµÊµÅÁ®ãÔºöÁîüÊàêÂíåÈÅéÊøæÈ´òÂìÅË≥™ÁöÑÊâπË©ïÔºåÁÑ∂ÂæåÂú®ÁçéÂãµÈ†êÊ∏¨ÂíåÊâπË©ïÁîüÊàê‰∏äÈÄ≤Ë°åËÅØÂêàÂæÆË™ø„ÄÇÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÂØ¶È©óË°®ÊòéÔºåËàáÊ®ôÊ∫ñÁçéÂãµÊ®°ÂûãÂíå LLM Ë©ïÂØ©Áõ∏ÊØîÔºåCritic-RM Â∞áÁçéÂãµÂª∫Ê®°Ê∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 3.7%-7.3%ÔºåÂ±ïÁ§∫‰∫ÜÂº∑Â§ßÁöÑÊÄßËÉΩÂíåÊï∏ÊìöÊïàÁéá„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∫ÜÁîüÊàêÁöÑÊâπË©ïÂú®Á≥æÊ≠£ÊúâÁº∫Èô∑ÁöÑÊé®ÁêÜÊ≠•È©ü‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÊé®ÁêÜÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 2.5%-3.2%„ÄÇ

##### **Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters**
2411.16645v1 by Dietmar Jannach, Alan Said, Marko Tkalƒçiƒç, Markus Zanker

In the area of recommender systems, the vast majority of research efforts is
spent on developing increasingly sophisticated recommendation models, also
using increasingly more computational resources. Unfortunately, most of these
research efforts target a very small set of application domains, mostly
e-commerce and media recommendation. Furthermore, many of these models are
never evaluated with users, let alone put into practice. The scientific,
economic and societal value of much of these efforts by scholars therefore
remains largely unclear. To achieve a stronger positive impact resulting from
these efforts, we posit that we as a research community should more often
address use cases where recommender systems contribute to societal good
(RS4Good). In this opinion piece, we first discuss a number of examples where
the use of recommender systems for problems of societal concern has been
successfully explored in the literature. We then proceed by outlining a
paradigmatic shift that is needed to conduct successful RS4Good research, where
the key ingredients are interdisciplinary collaborations and longitudinal
evaluation approaches with humans in the loop.

ÊëòË¶ÅÔºöÂú®Êé®Ëñ¶Á≥ªÁµ±È†òÂüüÔºåÁµïÂ§ßÂ§öÊï∏ÁöÑÁ†îÁ©∂Â∑•‰ΩúÈÉΩËä±Âú®ÈñãÁôºÊó•ÁõäÁ≤æÂØÜÁöÑÊé®Ëñ¶Ê®°ÂûãÔºåÂêåÊôÇ‰πü‰ΩøÁî®Ë∂ä‰æÜË∂äÂ§öÈÅãÁÆóË≥áÊ∫ê„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÈÄô‰∫õÁ†îÁ©∂Â∑•‰ΩúÂ§ßÂ§öÈáùÂ∞çÈùûÂ∏∏Â∞èÁöÑ‰∏ÄÁµÑÊáâÁî®È†òÂüüÔºå‰∏ªË¶ÅÊòØÈõªÂ≠êÂïÜÂãôÂíåÂ™íÈ´îÊé®Ëñ¶„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊ®°Âûã‰∏≠ÁöÑË®±Â§öÊ®°ÂûãÂæûÊú™Á∂ìÈÅé‰ΩøÁî®ËÄÖË©ï‰º∞ÔºåÊõ¥‰∏çÁî®Ë™™‰ªòË´∏ÂØ¶Ë∏ê‰∫Ü„ÄÇÂõ†Ê≠§ÔºåÂ≠∏ËÄÖÂÄëÂú®ÈÄô‰∫õÂ∑•‰Ωú‰∏äÁöÑÁßëÂ≠∏„ÄÅÁ∂ìÊøüÂíåÁ§æÊúÉÂÉπÂÄºÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªç‰∏çÊ∏ÖÊ•ö„ÄÇÁÇ∫‰∫ÜËÆìÈÄô‰∫õÂ∑•‰ΩúÁî¢ÁîüÊõ¥Âº∑Â§ßÁöÑÊ≠£Èù¢ÂΩ±ÈüøÔºåÊàëÂÄëË™çÁÇ∫ÊàëÂÄë‰ΩúÁÇ∫‰∏ÄÂÄãÁ†îÁ©∂Á§æÁæ§ÊáâË©≤Êõ¥Â∏∏Ëß£Ê±∫Êé®Ëñ¶Á≥ªÁµ±Â∞çÁ§æÊúÉÊúâÁõäÁöÑÁî®‰æãÔºàRS4GoodÔºâ„ÄÇÂú®ÈÄôÁØáÊÑèË¶ãÊñáÁ´†‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàË®éË´ñ‰∫Ü‰∏Ä‰∫õÁØÑ‰æãÔºåÂÖ∂‰∏≠Âú®ÊñáÁçª‰∏≠Â∑≤ÊàêÂäüÊé¢Á¥¢‰∫ÜÂ∞áÊé®Ëñ¶Á≥ªÁµ±Áî®ÊñºÁ§æÊúÉÈóúÊ≥®ÁöÑÂïèÈ°å„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé•ËëóÊ¶ÇËø∞ÈÄ≤Ë°åÊàêÂäüÁöÑ RS4Good Á†îÁ©∂ÊâÄÈúÄÁöÑÂÖ∏ÁØÑËΩâÁßªÔºåÂÖ∂‰∏≠ÈóúÈçµË¶ÅÁ¥†ÊòØË∑®È†òÂüüÂêà‰ΩúÂíå‰∫∫È°ûÂèÉËàáÁöÑÁ∏±ÂêëË©ï‰º∞ÊñπÊ≥ï„ÄÇ

##### **Preventing Jailbreak Prompts as Malicious Tools for Cybercriminals: A Cyber Defense Perspective**
2411.16642v1 by Jean Marie Tshimula, Xavier Ndona, D'Jeff K. Nkashama, Pierre-Martin Tardif, Froduald Kabanza, Marc Frappier, Shengrui Wang

Jailbreak prompts pose a significant threat in AI and cybersecurity, as they
are crafted to bypass ethical safeguards in large language models, potentially
enabling misuse by cybercriminals. This paper analyzes jailbreak prompts from a
cyber defense perspective, exploring techniques like prompt injection and
context manipulation that allow harmful content generation, content filter
evasion, and sensitive information extraction. We assess the impact of
successful jailbreaks, from misinformation and automated social engineering to
hazardous content creation, including bioweapons and explosives. To address
these threats, we propose strategies involving advanced prompt analysis,
dynamic safety protocols, and continuous model fine-tuning to strengthen AI
resilience. Additionally, we highlight the need for collaboration among AI
researchers, cybersecurity experts, and policymakers to set standards for
protecting AI systems. Through case studies, we illustrate these cyber defense
approaches, promoting responsible AI practices to maintain system integrity and
public trust. \textbf{\color{red}Warning: This paper contains content which the
reader may find offensive.}

ÊëòË¶ÅÔºöË∂äÁçÑÊèêÁ§∫Âú® AI ÂíåÁ∂≤Ë∑ØÂÆâÂÖ®È†òÂüü‰∏≠ÊßãÊàêÈáçÂ§ßÂ®ÅËÑÖÔºåÂõ†ÁÇ∫ÂÆÉÂÄëË¢´Ë®≠Ë®àÊàêÁπûÈÅéÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÈÅìÂæ∑Èò≤Ë≠∑Êé™ÊñΩÔºåÈÄôÂèØËÉΩÊúÉËÆìÁ∂≤Ë∑ØÁäØÁΩ™ÂàÜÂ≠êÂæó‰ª•Êø´Áî®„ÄÇÊú¨ÊñáÂæûÁ∂≤Ë∑ØÈò≤Á¶¶ËßíÂ∫¶ÂàÜÊûêË∂äÁçÑÊèêÁ§∫ÔºåÊé¢Ë®éÊèêÁ§∫Ê≥®ÂÖ•ÂíåÂÖßÂÆπÊìçÁ∏±Á≠âÊäÄË°ìÔºåÈÄô‰∫õÊäÄË°ìÂÖÅË®±Áî¢ÁîüÊúâÂÆ≥ÂÖßÂÆπ„ÄÅË¶èÈÅøÂÖßÂÆπÈÅéÊøæÂô®ÂíåÊèêÂèñÊïèÊÑüË≥áË®ä„ÄÇÊàëÂÄëË©ï‰º∞ÊàêÂäüË∂äÁçÑÁöÑÂΩ±ÈüøÔºåÂæûÈåØË™§Ë≥áË®äÂíåËá™ÂãïÂåñÁ§æÊúÉÂ∑•Á®ãÂà∞Âç±Èö™ÂÖßÂÆπÁöÑÂª∫Á´ãÔºåÂåÖÊã¨ÁîüÁâ©Ê≠¶Âô®ÂíåÁÇ∏Ëó•„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÂ®ÅËÑÖÔºåÊàëÂÄëÊèêÂá∫Ê∂âÂèäÈÄ≤ÈöéÊèêÁ§∫ÂàÜÊûê„ÄÅÂãïÊÖãÂÆâÂÖ®ÂçîÂÆöÂíåÊåÅÁ∫åÊ®°ÂûãÂæÆË™øÁöÑÁ≠ñÁï•Ôºå‰ª•Âº∑Âåñ AI ÁöÑÈüåÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™ø AI Á†îÁ©∂‰∫∫Âì°„ÄÅÁ∂≤Ë∑ØÂÆâÂÖ®Â∞àÂÆ∂ÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖ‰πãÈñìÈúÄË¶ÅÂêà‰ΩúÔºå‰ª•Âà∂ÂÆö‰øùË≠∑ AI Á≥ªÁµ±ÁöÑÊ®ôÊ∫ñ„ÄÇÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëË™™ÊòéÈÄô‰∫õÁ∂≤Ë∑ØÈò≤Á¶¶ÊñπÊ≥ïÔºåÊé®Âª£Ë≤†Ë≤¨‰ªªÁöÑ AI ÂØ¶ÂãôÔºå‰ª•Á∂≠Ë≠∑Á≥ªÁµ±ÂÆåÊï¥ÊÄßÂíåÂÖ¨Áúæ‰ø°‰ªª„ÄÇ\textbf{\color{red}Ë≠¶ÂëäÔºöÊú¨ÊñáÂåÖÂê´ËÆÄËÄÖÂèØËÉΩË¶∫Âæó‰ª§‰∫∫ÂèçÊÑüÁöÑÂÖßÂÆπ„ÄÇ}

##### **Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation**
2411.16638v1 by Sanjana Ramprasad, Byron C. Wallace

Modern LLMs can now produce highly readable abstractive summaries, to the
point where traditional automated metrics for evaluating summary quality, such
as ROUGE, have become saturated. However, LLMs still sometimes introduce
unwanted content into summaries, i.e., information inconsistent with or
unsupported by their source. Measuring the occurrence of these often subtle
``hallucinations'' automatically has proved to be challenging. This in turn has
motivated development of a variety of metrics intended to measure the factual
consistency of generated summaries against their source. But are these
approaches measuring what they purport to do? In this work, we stress-test
automatic factuality metrics. Specifically, we investigate whether and to what
degree superficial attributes of summary texts suffice to predict
``factuality'', finding that a (supervised) model using only such shallow
features is reasonably competitive with SOTA factuality scoring methods. We
then evaluate how factuality metrics respond to factual corrections in
inconsistent summaries and find that only a few show meaningful improvements.
In contrast, some metrics are more sensitive to benign, non-factual edits.
Motivated by these insights, we show that one can ``game'' (most) automatic
factuality metrics, i.e., reliably inflate ``factuality'' scores by appending
innocuous sentences to generated summaries.Taken together, our results raise
questions about the degree to which we should rely on existing automated
factuality metrics and what exactly we want ``factuality metrics'' to measure.

ÊëòË¶ÅÔºöÁèæ‰ª£ÁöÑ LLM ÁèæÂú®ÂèØ‰ª•Áî¢ÁîüÈ´òÂ∫¶ÂèØËÆÄÁöÑÊäΩË±°ÊëòË¶ÅÔºå‰ª•Ëá≥ÊñºÁî®ÊñºË©ï‰º∞ÊëòË¶ÅÂìÅË≥™ÁöÑÂÇ≥Áµ±Ëá™ÂãïÂåñÊåáÊ®ôÔºå‰æãÂ¶Ç ROUGEÔºåÂ∑≤ËÆäÂæóÈ£ΩÂíå„ÄÇÁÑ∂ËÄåÔºåLLM ÊúâÊôÇ‰ªçÊúÉÂú®ÊëòË¶Å‰∏≠ÂºïÂÖ•‰∏çÈúÄË¶ÅÁöÑÂÖßÂÆπÔºåÂç≥ËàáÂÖ∂‰æÜÊ∫ê‰∏ç‰∏ÄËá¥Êàñ‰∏çÂèóÂÖ∂‰æÜÊ∫êÊîØÊåÅÁöÑË≥áË®ä„ÄÇË°°ÈáèÈÄô‰∫õÈÄöÂ∏∏ÂæàÂæÆÂ¶ôÁöÑ„ÄåÂπªË¶∫„ÄçÁöÑÁôºÁîüÊÉÖÊ≥ÅÂ∑≤Ë≠âÊòéÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÈÄôÂèçÈÅé‰æÜÂèà‰øÉ‰ΩøÈñãÁôºÂêÑÁ®ÆÊåáÊ®ôÔºåÊó®Âú®Ë°°ÈáèÁî¢ÁîüÁöÑÊëòË¶ÅËàáÂÖ∂‰æÜÊ∫êÁöÑ‰∫ãÂØ¶‰∏ÄËá¥ÊÄß„ÄÇ‰ΩÜÈÄô‰∫õÊñπÊ≥ïÊòØÂê¶Ë°°Èáè‰∫ÜÂÆÉÂÄëËÅ≤Á®±Ë¶ÅÂÅöÁöÑÔºüÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞çËá™Âãï‰∫ãÂØ¶ÊÄßÊåáÊ®ôÈÄ≤Ë°åÂ£ìÂäõÊ∏¨Ë©¶„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË™øÊü•ÊëòË¶ÅÊñáÂ≠óÁöÑË°®Èù¢Â±¨ÊÄßÊòØÂê¶Ë∂≥‰ª•È†êÊ∏¨„Äå‰∫ãÂØ¶ÊÄß„ÄçÔºå‰∏¶ÁôºÁèæÂÉÖ‰ΩøÁî®Ê≠§È°ûÊ∑∫Â±§ÁâπÂæµÁöÑÔºàÁõ£Áù£ÔºâÊ®°ÂûãËàá SOTA ‰∫ãÂØ¶ÊÄßË©ïÂàÜÊñπÊ≥ïÁõ∏Áï∂ÊúâÁ´∂Áà≠Âäõ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË©ï‰º∞‰∫ãÂØ¶ÊÄßÊåáÊ®ôÂ¶Ç‰ΩïÂ∞ç‰∏ç‰∏ÄËá¥ÊëòË¶Å‰∏≠ÁöÑ‰∫ãÂØ¶Êõ¥Ê≠£ÂÅöÂá∫ÂèçÊáâÔºå‰∏¶ÁôºÁèæÂè™ÊúâÂ∞ëÊï∏È°ØÁ§∫Âá∫ÊúâÊÑèÁæ©ÁöÑÊîπÈÄ≤„ÄÇÁõ∏ÂèçÔºå‰∏Ä‰∫õÊåáÊ®ôÂ∞çËâØÊÄßÁöÑÈùû‰∫ãÂØ¶Á∑®ËºØÊõ¥ÊïèÊÑü„ÄÇÂèóÂà∞ÈÄô‰∫õË¶ãËß£ÁöÑÂïüÁôºÔºåÊàëÂÄëË°®Êòé‰∫∫ÂÄëÂèØ‰ª•„ÄåÁé©„ÄçÂ§ßÂ§öÊï∏Ëá™Âãï‰∫ãÂØ¶ÊÄßÊåáÊ®ôÔºåÂç≥ÈÄèÈÅéÂú®Áî¢ÁîüÁöÑÊëòË¶Å‰∏≠ÈôÑÂä†ÁÑ°ÂÆ≥ÁöÑÂè•Â≠ê‰æÜÂèØÈù†Âú∞ÊèêÈ´ò„Äå‰∫ãÂØ¶ÊÄß„ÄçÂàÜÊï∏„ÄÇÁ∂úÂêàËµ∑‰æÜÔºåÊàëÂÄëÁöÑÁµêÊûúÂºïÁôº‰∫ÜÈóúÊñºÊàëÂÄëÊáâÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏ä‰æùË≥¥ÁèæÊúâÁöÑËá™Âãï‰∫ãÂØ¶ÊÄßÊåáÊ®ô‰ª•ÂèäÊàëÂÄëÁ¢∫ÂàáÂ∏åÊúõ„Äå‰∫ãÂØ¶ÊÄßÊåáÊ®ô„ÄçË°°Èáè‰ªÄÈ∫ºÁöÑÂïèÈ°å„ÄÇ

##### **Imperceptible Adversarial Examples in the Physical World**
2411.16622v1 by Weilin Xu, Sebastian Szyller, Cory Cornelius, Luis Murillo Rojas, Marius Arvinte, Alvaro Velasquez, Jason Martin, Nageen Himayat

Adversarial examples in the digital domain against deep learning-based
computer vision models allow for perturbations that are imperceptible to human
eyes. However, producing similar adversarial examples in the physical world has
been difficult due to the non-differentiable image distortion functions in
visual sensing systems. The existing algorithms for generating physically
realizable adversarial examples often loosen their definition of adversarial
examples by allowing unbounded perturbations, resulting in obvious or even
strange visual patterns. In this work, we make adversarial examples
imperceptible in the physical world using a straight-through estimator (STE,
a.k.a. BPDA). We employ STE to overcome the non-differentiability -- applying
exact, non-differentiable distortions in the forward pass of the
backpropagation step, and using the identity function in the backward pass. Our
differentiable rendering extension to STE also enables imperceptible
adversarial patches in the physical world. Using printout photos, and
experiments in the CARLA simulator, we show that STE enables fast generation of
$\ell_\infty$ bounded adversarial examples despite the non-differentiable
distortions. To the best of our knowledge, this is the first work demonstrating
imperceptible adversarial examples bounded by small $\ell_\infty$ norms in the
physical world that force zero classification accuracy in the global
perturbation threat model and cause near-zero ($4.22\%$) AP50 in object
detection in the patch perturbation threat model. We urge the community to
re-evaluate the threat of adversarial examples in the physical world.

ÊëòË¶ÅÔºö<paragraph>ÈáùÂ∞çÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈõªËÖ¶Ë¶ñË¶∫Ê®°ÂûãÁöÑÊï∏‰ΩçÈ†òÂüüÂ∞çÊäóÁØÑ‰æãÂÖÅË®±‰∫∫ÁúºÁÑ°Ê≥ïÂØüË¶∫ÁöÑÊìæÂãï„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË¶ñË¶∫ÊÑüÊ∏¨Á≥ªÁµ±‰∏≠‰∏çÂèØÂæÆÂàÜÁöÑÂΩ±ÂÉèÂ§±ÁúüÂáΩÊï∏ÔºåÂú®Áâ©ÁêÜ‰∏ñÁïå‰∏≠Áî¢ÁîüÈ°û‰ººÁöÑÂ∞çÊäóÁØÑ‰æã‰∏ÄÁõ¥ÂæàÂõ∞Èõ£„ÄÇÁèæÊúâÁöÑÊºîÁÆóÊ≥ïÁî®ÊñºÁî¢ÁîüÁâ©ÁêÜ‰∏äÂèØÂØ¶ÁèæÁöÑÂ∞çÊäóÁØÑ‰æãÔºåÈÄöÂ∏∏ÈÄèÈÅéÂÖÅË®±ÁÑ°ÁïåÁöÑÊìæÂãï‰æÜÊîæÂØ¨Â∞çÊäóÁØÑ‰æãÁöÑÂÆöÁæ©ÔºåÂ∞éËá¥ÊòéÈ°ØÁîöËá≥Â•áÊÄ™ÁöÑË¶ñË¶∫Ê®°Âºè„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®Áõ¥ÈÄö‰º∞Ë®àÂô® (STEÔºåÂèàÁ®± BPDA) Âú®Áâ©ÁêÜ‰∏ñÁïå‰∏≠Ë£Ω‰ΩúÁÑ°Ê≥ïÂØüË¶∫ÁöÑÂ∞çÊäóÁØÑ‰æã„ÄÇÊàëÂÄëÊé°Áî® STE ‰æÜÂÖãÊúç‰∏çÂèØÂæÆÂàÜÊÄßÔºåÂú®ÂèçÂêëÂÇ≥Êí≠Ê≠•È©üÁöÑÂâçÂêëÂÇ≥ÈÅû‰∏≠ÊáâÁî®Á≤æÁ¢∫ÁöÑ‰∏çÂèØÂæÆÂàÜÂ§±ÁúüÔºå‰∏¶Âú®ÂèçÂêëÂÇ≥ÈÅû‰∏≠‰ΩøÁî®ÊÅÜÁ≠âÂáΩÊï∏„ÄÇÊàëÂÄëÂ∞ç STE ÁöÑÂèØÂæÆÂàÜÊ∏≤ÊüìÂª∂‰º∏‰πüËÆìÁâ©ÁêÜ‰∏ñÁïå‰∏≠ÁöÑÂ∞çÊäóÊÄßË≤ºÁâáÁÑ°Ê≥ïÂØüË¶∫„ÄÇÈÄèÈÅéÂàóÂç∞ÁÖßÁâáÔºå‰ª•ÂèäÂú® CARLA Ê®°Êì¨Âô®‰∏≠ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü STE ËÉΩÂ§†Âø´ÈÄüÁî¢Áîü $\ell_\infty$ ÊúâÁïåÂ∞çÊäóÁØÑ‰æãÔºåÂÑòÁÆ°Êúâ‰∏çÂèØÂæÆÂàÜÁöÑÂ§±Áúü„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂú®Áâ©ÁêÜ‰∏ñÁïå‰∏≠Â±ïÁ§∫Áî±Â∞è $\ell_\infty$ Ë¶èÊ†ºÈôêÂà∂ÁöÑÁÑ°Ê≥ïÂØüË¶∫Â∞çÊäóÁØÑ‰æãÁöÑÂ∑•‰ΩúÔºåÂú®ÂÖ®ÂüüÊìæÂãïÂ®ÅËÑÖÊ®°Âûã‰∏≠Âº∑Âà∂Èõ∂ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶Âú®Ë≤ºÁâáÊìæÂãïÂ®ÅËÑÖÊ®°Âûã‰∏≠Â∞éËá¥Êé•ËøëÈõ∂ ($4.22\%$) ÁöÑ AP50 Áâ©‰ª∂ÂÅµÊ∏¨„ÄÇÊàëÂÄëÊï¶‰øÉÁ§æÁæ§ÈáçÊñ∞Ë©ï‰º∞Áâ©ÁêÜ‰∏ñÁïå‰∏≠Â∞çÊäóÁØÑ‰æãÁöÑÂ®ÅËÑÖ„ÄÇ</paragraph>

##### **StructFormer: Document Structure-based Masked Attention and its Impact on Language Model Pre-Training**
2411.16618v1 by Kaustubh Ponkshe, Venkatapathy Subramanian, Natwar Modani, Ganesh Ramakrishnan

Most state-of-the-art techniques for Language Models (LMs) today rely on
transformer-based architectures and their ubiquitous attention mechanism.
However, the exponential growth in computational requirements with longer input
sequences confines Transformers to handling short passages. Recent efforts have
aimed to address this limitation by introducing selective attention mechanisms,
notably local and global attention. While sparse attention mechanisms, akin to
full attention in being Turing-complete, have been theoretically established,
their practical impact on pre-training remains unexplored. This study focuses
on empirically assessing the influence of global attention on BERT
pre-training. The primary steps involve creating an extensive corpus of
structure-aware text through arXiv data, alongside a text-only counterpart. We
carry out pre-training on these two datasets, investigate shifts in attention
patterns, and assess their implications for downstream tasks. Our analysis
underscores the significance of incorporating document structure into LM
models, demonstrating their capacity to excel in more abstract tasks, such as
document understanding.

ÊëòË¶ÅÔºöÁèæ‰ªäÂ§öÊï∏Ë™ûË®ÄÊ®°Âûã (LM) ÁöÑÊúÄÂÖàÈÄ≤ÊäÄË°ì‰ª∞Ë≥¥ÊñºÂü∫ÊñºËΩâÊèõÂô®ÁöÑÊû∂ÊßãÂèäÂÖ∂ÊôÆÈÅçÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂„ÄÇ
ÁÑ∂ËÄåÔºåÈö®ËëóËº∏ÂÖ•Â∫èÂàóËÆäÈï∑ÔºåÈÅãÁÆóÈúÄÊ±ÇÂëàÊåáÊï∏ÊàêÈï∑ÔºåÂ∞áËΩâÊèõÂô®ÈôêÂà∂Âú®ËôïÁêÜÁü≠ÁØáÁ´†ÁØÄ„ÄÇÊúÄËøëÁöÑÂä™ÂäõÊó®Âú®ÈÄèÈÅéÂºïÂÖ•ÈÅ∏ÊìáÊÄßÊ≥®ÊÑèÂäõÊ©üÂà∂‰æÜËß£Ê±∫Ê≠§ÈôêÂà∂ÔºåÁâπÂà•ÊòØÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÊ≥®ÊÑèÂäõ„ÄÇÈõñÁÑ∂Á®ÄÁñèÊ≥®ÊÑèÂäõÊ©üÂà∂È°û‰ººÊñºÂú®ÂúñÈùàÂÆåÂÇôÊÄß‰∏≠ÁöÑÂÆåÊï¥Ê≥®ÊÑèÂäõÔºåÂ∑≤Âú®ÁêÜË´ñ‰∏äÂª∫Á´ãÔºå‰ΩÜÂÖ∂Â∞çÈ†êË®ìÁ∑¥ÁöÑÂØ¶ÈöõÂΩ±Èüø‰ªçÊú™Êé¢Ë®é„ÄÇÊú¨Á†îÁ©∂Â∞àÊ≥®ÊñºÁ∂ìÈ©óË©ï‰º∞ÂÖ®Â±ÄÊ≥®ÊÑèÂäõÂ∞ç BERT È†êË®ìÁ∑¥ÁöÑÂΩ±Èüø„ÄÇ‰∏ªË¶ÅÊ≠•È©üÂåÖÊã¨ÈÄèÈÅé arXiv Ë≥áÊñôÂª∫Á´ãÂª£Ê≥õÁöÑÁµêÊßãÊÑüÁü•ÊñáÂ≠óË™ûÊñôÂ∫´Ôºå‰ª•ÂèäÁ¥îÊñáÂ≠óÂ∞çÊáâÁâàÊú¨„ÄÇÊàëÂÄëÂ∞çÈÄôÂÖ©ÂÄãË≥áÊñôÈõÜÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÔºåÊé¢Ë®éÊ≥®ÊÑèÂäõÊ®°ÂºèÁöÑËΩâËÆäÔºå‰∏¶Ë©ï‰º∞ÂÖ∂Â∞ç‰∏ãÊ∏∏‰ªªÂãôÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™øÂ∞áÊñá‰ª∂ÁµêÊßãÁ¥çÂÖ• LM Ê®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºåË≠âÊòéÂÖ∂Âú®Êõ¥ÊäΩË±°‰ªªÂãôÔºà‰æãÂ¶ÇÊñá‰ª∂ÁêÜËß£Ôºâ‰∏≠Ë°®ÁèæÂÑ™Áï∞ÁöÑËÉΩÂäõ„ÄÇ

##### **Recent Trends in Linear Text Segmentation: a Survey**
2411.16613v1 by Iacopo Ghinassi, Lin Wang, Chris Newell, Matthew Purver

Linear Text Segmentation is the task of automatically tagging text documents
with topic shifts, i.e. the places in the text where the topics change. A
well-established area of research in Natural Language Processing, drawing from
well-understood concepts in linguistic and computational linguistic research,
the field has recently seen a lot of interest as a result of the surge of text,
video, and audio available on the web, which in turn require ways of
summarising and categorizing the mole of content for which linear text
segmentation is a fundamental step. In this survey, we provide an extensive
overview of current advances in linear text segmentation, describing the state
of the art in terms of resources and approaches for the task. Finally, we
highlight the limitations of available resources and of the task itself, while
indicating ways forward based on the most recent literature and under-explored
research directions.

ÊëòË¶ÅÔºöÁ∑öÊÄßÊñáÊú¨ÂàÜÊÆµÊòØËá™ÂãïÊ®ôË®òÊñáÊú¨Êñá‰ª∂
‰∏ªÈ°åËΩâÊèõÔºåÂç≥ÊñáÊú¨‰∏≠‰∏ªÈ°åËÆäÊõ¥ÁöÑÂú∞Êñπ„ÄÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠‰∏ÄÂÄãÂª∫Á´ãËâØÂ•ΩÁöÑÁ†îÁ©∂È†òÂüüÔºåÊ±≤Âèñ
Ë™ûË®ÄÂ≠∏ÂíåË®àÁÆóË™ûË®ÄÂ≠∏Á†îÁ©∂‰∏≠ÁêÜËß£ËâØÂ•ΩÁöÑÊ¶ÇÂøµÔºåË©≤È†òÂüüÊúÄËøëÂõ†Á∂≤Ë∑Ø‰∏äÂ§ßÈáèÊπßÁèæÁöÑÊñáÂ≠ó„ÄÅ
ÂΩ±ÁâáÂíåÈü≥Ë®äËÄåÂÇôÂèóÈóúÊ≥®ÔºåËÄåÈÄô‰∫õÂÖßÂÆπÈúÄË¶ÅÁ∏ΩÁµêÂíåÂàÜÈ°ûÔºåËÄåÁ∑öÊÄßÊñáÊú¨ÂàÜÊÆµÊ≠£ÊòØÂü∫Êú¨Ê≠•È©ü„ÄÇÂú®ÈÄôÈ†ÖË™øÊü•‰∏≠ÔºåÊàëÂÄëÊèê‰æõÁ∑öÊÄßÊñáÊú¨ÂàÜÊÆµÁï∂ÂâçÈÄ≤Â±ïÁöÑÂª£Ê≥õÊ¶ÇËø∞ÔºåË™™Êòé‰ªªÂãôÂú®Ë≥áÊ∫êÂíåÊñπÊ≥ïÊñπÈù¢ÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂº∑Ë™øÂèØÁî®Ë≥áÊ∫êÂíå‰ªªÂãôÊú¨Ë∫´ÁöÑÈôêÂà∂ÔºåÂêåÊôÇÊ†πÊìöÊúÄÊñ∞ÊñáÁçªÂíåÂ∞öÊú™Êé¢Á¥¢ÁöÑÁ†îÁ©∂ÊñπÂêëÊåáÂá∫ÂâçÈÄ≤ÁöÑÊñπÂêë„ÄÇ

##### **F -- A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite**
2411.16609v1 by Ansgar Scherp, Thomas Franz, Carsten Saathoff, Steffen Staab

The lack of a formal model of events hinders interoperability in distributed
event-based systems. In this paper, we present a formal model of events, called
Event-Model-F. The model is based on the foundational ontology DOLCE+DnS
Ultralite (DUL) and provides comprehensive support to represent time and space,
objects and persons, as well as mereological, causal, and correlative
relationships between events. In addition, the Event-Model-F provides a
flexible means for event composition, modeling event causality and event
correlation, and representing different interpretations of the same event. The
Event-Model-F is developed following the pattern-oriented approach of DUL, is
modularized in different ontologies, and can be easily extended by domain
specific ontologies.

ÊëòË¶ÅÔºöÁº∫‰πèÊ≠£ÂºèÁöÑ‰∫ã‰ª∂Ê®°ÂûãÊúÉÈòªÁ§ôÂàÜÊï£Âºè‰∫ã‰ª∂Âü∫Á§éÁ≥ªÁµ±‰∏≠ÁöÑ‰∫íÊìç‰ΩúÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∫ã‰ª∂ÁöÑÊ≠£ÂºèÊ®°ÂûãÔºåÁ®±ÁÇ∫‰∫ã‰ª∂Ê®°Âûã F„ÄÇË©≤Ê®°ÂûãÂü∫ÊñºÂü∫Á§éÊú¨‰Ωì DOLCE+DnS Ultralite (DUL)Ôºå‰∏¶Êèê‰æõÂÖ®Èù¢ÁöÑÊîØÊè¥‰æÜË°®Á§∫ÊôÇÈñìÂíåÁ©∫Èñì„ÄÅÁâ©‰ª∂Âíå‰∫∫Áâ©Ôºå‰ª•Âèä‰∫ã‰ª∂‰πãÈñìÁöÑÂîØË±°Â≠∏„ÄÅÂõ†ÊûúÂíåÁõ∏ÈóúÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºå‰∫ã‰ª∂Ê®°Âûã F Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÈùàÊ¥ªÁöÑÊñπÊ≥ï‰æÜÈÄ≤Ë°å‰∫ã‰ª∂ÁµÑÂêà„ÄÅÂª∫Ê®°‰∫ã‰ª∂Âõ†ÊûúÈóú‰øÇÂíå‰∫ã‰ª∂Áõ∏ÈóúÊÄßÔºå‰ª•ÂèäË°®Á§∫Âêå‰∏ÄÂÄã‰∫ã‰ª∂ÁöÑ‰∏çÂêåËß£Èáã„ÄÇ‰∫ã‰ª∂Ê®°Âûã F ÊòØÈÅµÂæ™ DUL ÁöÑÊ®°ÂºèÂ∞éÂêëÊñπÊ≥ïÈñãÁôºÁöÑÔºåÂú®‰∏çÂêåÁöÑÊú¨‰Ωì‰∏≠Ê®°ÁµÑÂåñÔºå‰∏¶‰∏îÂèØ‰ª•ÈÄèÈÅéÁâπÂÆöÊñºÈ†òÂüüÁöÑÊú¨‰ΩìËºïÈ¨ÜÂª∂‰º∏„ÄÇ

##### **From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge**
2411.16594v1 by Dawei Li, Bohan Jiang, Liangjie Huang, Alimohammad Beigi, Chengshuai Zhao, Zhen Tan, Amrita Bhattacharjee, Yuxuan Jiang, Canyu Chen, Tianhao Wu, Kai Shu, Lu Cheng, Huan Liu

Assessment and evaluation have long been critical challenges in artificial
intelligence (AI) and natural language processing (NLP). However, traditional
methods, whether matching-based or embedding-based, often fall short of judging
subtle attributes and delivering satisfactory results. Recent advancements in
Large Language Models (LLMs) inspire the "LLM-as-a-judge" paradigm, where LLMs
are leveraged to perform scoring, ranking, or selection across various tasks
and applications. This paper provides a comprehensive survey of LLM-based
judgment and assessment, offering an in-depth overview to advance this emerging
field. We begin by giving detailed definitions from both input and output
perspectives. Then we introduce a comprehensive taxonomy to explore
LLM-as-a-judge from three dimensions: what to judge, how to judge and where to
judge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and
highlight key challenges and promising directions, aiming to provide valuable
insights and inspire future research in this promising research area. Paper
list and more resources about LLM-as-a-judge can be found at
\url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} and
\url{https://llm-as-a-judge.github.io}.

ÊëòË¶ÅÔºöË©ï‰º∞ÂíåË©ïÈáèÈï∑Êúü‰ª•‰æÜ‰∏ÄÁõ¥ÊòØ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠ÁöÑÈáçÂ§ßÊåëÊà∞„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÊñπÊ≥ïÔºåÁÑ°Ë´ñÊòØÂü∫ÊñºÊØîÂ∞çÊàñÂµåÂÖ•ÂºèÔºåÈÄöÂ∏∏ÁÑ°Ê≥ïÂà§Êñ∑Á¥∞ÂæÆÂ±¨ÊÄßÂíåÊèê‰æõ‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûú„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂïüÁôº‰∫Ü„ÄåLLM ‰ΩúÁÇ∫Ë©ïÂà§ËÄÖ„ÄçÁöÑÁØÑ‰æãÔºåÂÖ∂‰∏≠ LLM Ë¢´Áî®ÊñºÂü∑Ë°åÂêÑÁ®Æ‰ªªÂãôÂíåÊáâÁî®‰∏≠ÁöÑË©ïÂàÜ„ÄÅÊéíÂêçÊàñÈÅ∏Êìá„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÂü∫Êñº LLM ÁöÑÂà§Êñ∑ÂíåË©ï‰º∞ÁöÑÂÖ®Èù¢Ë™øÊü•ÔºåÊèê‰æõ‰∫ÜÊ∑±ÂÖ•ÁöÑÊ¶ÇËø∞‰ª•Êé®ÈÄ≤ÈÄôÂÄãÊñ∞ËààÈ†òÂüü„ÄÇÊàëÂÄëÂæûËº∏ÂÖ•ÂíåËº∏Âá∫ËßÄÈªûÁµ¶Âá∫Ë©≥Á¥∞ÂÆöÁæ©ÈñãÂßã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂàÜÈ°ûÊ≥ïÔºåÂæû‰∏âÂÄãÈù¢ÂêëÊé¢Ë®é LLM ‰ΩúÁÇ∫Ë©ïÂà§ËÄÖÔºöÂà§Êñ∑‰ªÄÈ∫º„ÄÅÂ¶Ç‰ΩïÂà§Êñ∑ÂíåÂú®Âì™Ë£°Âà§Êñ∑„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁ∑®Âà∂‰∫ÜË©ï‰º∞ LLM ‰ΩúÁÇ∫Ë©ïÂà§ËÄÖÁöÑÂü∫Ê∫ñÔºå‰∏¶ÈáçÈªû‰ªãÁ¥πÈóúÈçµÊåëÊà∞ÂíåÊúâÂ∏åÊúõÁöÑÊñπÂêëÔºåÊó®Âú®Êèê‰æõÊúâÂÉπÂÄºÁöÑË¶ãËß£‰∏¶ÊøÄÂãµÈÄôÂÄãÊúâÂ∏åÊúõÁöÑÁ†îÁ©∂È†òÂüüÁöÑÊú™‰æÜÁ†îÁ©∂„ÄÇLLM ‰ΩúÁÇ∫Ë©ïÂà§ËÄÖÁöÑË´ñÊñáÊ∏ÖÂñÆÂíåÊõ¥Â§öË≥áÊ∫êÂèØ‰ª•Âú® \url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} Âíå \url{https://llm-as-a-judge.github.io} ÊâæÂà∞„ÄÇ

##### **Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision**
2411.16579v1 by Zhiheng Xi, Dingwen Yang, Jixuan Huang, Jiafu Tang, Guanyu Li, Yiwen Ding, Wei He, Boyang Hong, Shihan Do, Wenyu Zhan, Xiao Wang, Rui Zheng, Tao Ji, Xiaowei Shi, Yitao Zhai, Rongxiang Weng, Jingang Wang, Xunliang Cai, Tao Gui, Zuxuan Wu, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Yu-Gang Jiang

Training large language models (LLMs) to spend more time thinking and
reflection before responding is crucial for effectively solving complex
reasoning tasks in fields such as science, coding, and mathematics. However,
the effectiveness of mechanisms like self-reflection and self-correction
depends on the model's capacity to accurately assess its own performance, which
can be limited by factors such as initial accuracy, question difficulty, and
the lack of external feedback. In this paper, we delve into a two-player
paradigm that separates the roles of reasoning and critique models, where the
critique model provides step-level feedback to supervise the reasoning (actor)
model during both test-time and train-time. We first propose AutoMathCritique,
an automated and scalable framework for collecting critique data, resulting in
a dataset of $76,321$ responses paired with step-level feedback. Fine-tuning
language models with this dataset enables them to generate natural language
feedback for mathematical reasoning. We demonstrate that the critique models
consistently improve the actor's performance on difficult queries at test-time,
especially when scaling up inference-time computation. Motivated by these
findings, we introduce the critique-based supervision to the actor's
self-training process, and propose a critique-in-the-loop self-improvement
method. Experiments show that the method improves the actor's exploration
efficiency and solution diversity, especially on challenging queries, leading
to a stronger reasoning model. Lastly, we take the preliminary step to explore
training self-talk reasoning models via critique supervision and showcase its
potential. Our code and datasets are at
\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}.

ÊëòË¶ÅÔºö<paragraph>Ë®ìÁ∑¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂõûÊáâÂâçËä±Êõ¥Â§öÊôÇÈñìÊÄùËÄÉÂíåÂèçÁúÅÔºåÂ∞çÊñºÂú®ÁßëÂ≠∏„ÄÅÁ®ãÂºèÁ∑®ÂØ´ÂíåÊï∏Â≠∏Á≠âÈ†òÂüüÊúâÊïàËß£Ê±∫Ë§áÈõúÊé®ÁêÜ‰ªªÂãôËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåËá™ÊàëÂèçÁúÅÂíåËá™Êàë‰øÆÊ≠£Á≠âÊ©üÂà∂ÁöÑÊúâÊïàÊÄßÂèñÊ±∫ÊñºÊ®°ÂûãÊ∫ñÁ¢∫Ë©ï‰º∞ÂÖ∂Ëá™Ë∫´ÊïàËÉΩÁöÑËÉΩÂäõÔºåËÄåÈÄôÂèØËÉΩÊúÉÂèóÂà∞ÂàùÂßãÊ∫ñÁ¢∫Â∫¶„ÄÅÂïèÈ°åÈõ£Â∫¶ÂíåÁº∫‰πèÂ§ñÈÉ®ÂõûÈ•ãÁ≠âÂõ†Á¥†ÁöÑÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®é‰∏ÄÂÄãÂ∞áÊé®ÁêÜÂíåÊâπÂà§Ê®°ÂûãÁöÑËßíËâ≤ÂàÜÈñãÁöÑÈõô‰∫∫ÈÅäÊà≤ÁØÑ‰æãÔºåÂÖ∂‰∏≠ÊâπÂà§Ê®°ÂûãÊèê‰æõÊ≠•È©üÂ±§Á¥öÁöÑÂõûÈ•ãÔºå‰ª•Áõ£Áù£Êé®ÁêÜ (actor) Ê®°ÂûãÂú®Ê∏¨Ë©¶ÊôÇÈñìÂíåË®ìÁ∑¥ÊôÇÈñì„ÄÇÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫ AutoMathCritiqueÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÊî∂ÈõÜÊâπÂà§Ë≥áÊñôÁöÑËá™ÂãïÂåñ‰∏îÂèØÊì¥ÂÖÖÁöÑÊû∂ÊßãÔºåÁî¢Áîü‰∏ÄÂÄãÂåÖÂê´ 76,321 ÂÄãËàáÊ≠•È©üÂ±§Á¥öÂõûÈ•ãÈÖçÂ∞çÁöÑÂõûÊáâÁöÑË≥áÊñôÈõÜ„ÄÇ‰ΩøÁî®ÈÄôÂÄãË≥áÊñôÈõÜÂæÆË™øË™ûË®ÄÊ®°ÂûãÔºå‰ΩøÂÆÉÂÄëËÉΩÂ§†ÁÇ∫Êï∏Â≠∏Êé®ÁêÜÁî¢ÁîüËá™ÁÑ∂Ë™ûË®ÄÂõûÈ•ã„ÄÇÊàëÂÄëË≠âÊòéÊâπÂà§Ê®°ÂûãÂú®Ê∏¨Ë©¶ÊôÇÈñìÊåÅÁ∫åÊîπÂñÑ actor Âú®Âõ∞Èõ£Êü•Ë©¢‰∏äÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Êì¥ÂÖÖÊé®Ë´ñÊôÇÈñìÈÅãÁÆóÊôÇ„ÄÇÂèóÂà∞ÈÄô‰∫õÁôºÁèæÁöÑÂïüÁôºÔºåÊàëÂÄëÂ∞áÂü∫ÊñºÊâπÂà§ÁöÑÁõ£Áù£ÂºïÂÖ• actor ÁöÑËá™ÊàëË®ìÁ∑¥Á®ãÂ∫èÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãËø¥Âúà‰∏≠ÁöÑÊâπÂà§Ëá™ÊàëÊîπÂñÑÊñπÊ≥ï„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåÊ≠§ÊñπÊ≥ïÊîπÂñÑ‰∫Ü actor Âú®Êé¢Á¥¢ÊïàÁéáÂíåËß£Ê±∫ÊñπÊ°àÂ§öÊ®£ÊÄß‰∏äÁöÑË°®ÁèæÔºåÁâπÂà•ÊòØÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÊü•Ë©¢‰∏äÔºåÈÄ≤ËÄåÁî¢ÁîüÊõ¥Âº∑Â§ßÁöÑÊé®ÁêÜÊ®°Âûã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé°ÂèñÂàùÊ≠•Ê≠•È©üÔºåÈÄèÈÅéÊâπÂà§Áõ£Áù£‰æÜÊé¢Á¥¢Ë®ìÁ∑¥Ëá™ÊàëÂ∞çË©±Êé®ÁêÜÊ®°ÂûãÔºå‰∏¶Â±ïÁ§∫ÂÖ∂ÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜ‰ΩçÊñº
\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}„ÄÇ</paragraph>

##### **Naive Algorithmic Collusion: When Do Bandit Learners Cooperate and When Do They Compete?**
2411.16574v1 by Connor Douglas, Foster Provost, Arun Sundararajan

Algorithmic agents are used in a variety of competitive decision settings,
notably in making pricing decisions in contexts that range from online retail
to residential home rentals. Business managers, algorithm designers, legal
scholars, and regulators alike are all starting to consider the ramifications
of "algorithmic collusion." We study the emergent behavior of multi-armed
bandit machine learning algorithms used in situations where agents are
competing, but they have no information about the strategic interaction they
are engaged in. Using a general-form repeated Prisoner's Dilemma game, agents
engage in online learning with no prior model of game structure and no
knowledge of competitors' states or actions (e.g., no observation of competing
prices). We show that these context-free bandits, with no knowledge of
opponents' choices or outcomes, still will consistently learn collusive
behavior - what we call "naive collusion." We primarily study this system
through an analytical model and examine perturbations to the model through
simulations.
  Our findings have several notable implications for regulators. First, calls
to limit algorithms from conditioning on competitors' prices are insufficient
to prevent algorithmic collusion. This is a direct result of collusion arising
even in the naive setting. Second, symmetry in algorithms can increase
collusion potential. This highlights a new, simple mechanism for
"hub-and-spoke" algorithmic collusion. A central distributor need not imbue its
algorithm with supra-competitive tendencies for apparent collusion to arise; it
can simply arise by using certain (common) machine learning algorithms.
Finally, we highlight that collusive outcomes depend starkly on the specific
algorithm being used, and we highlight market and algorithmic conditions under
which it will be unknown a priori whether collusion occurs.

ÊëòË¶ÅÔºöÊºîÁÆóÊ≥ï‰ª£ÁêÜÁî®ÊñºÂêÑÁ®ÆÁ´∂Áà≠Ê±∫Á≠ñË®≠ÂÆö‰∏≠ÔºåÁâπÂà•ÊòØÂú®ÂæûÁ∑ö‰∏äÈõ∂ÂîÆÂà∞‰ΩèÂÆÖÂá∫ÁßüÁöÑÂêÑÁ®ÆÊÉÖÂ¢É‰∏≠ÂÅöÂá∫ÂÆöÂÉπÊ±∫Á≠ñ„ÄÇ‰ºÅÊ•≠Á∂ìÁêÜ‰∫∫„ÄÅÊºîÁÆóÊ≥ïË®≠Ë®àËÄÖ„ÄÅÊ≥ïÂæãÂ≠∏ËÄÖÂíåÁõ£ÁÆ°Ê©üÊßãÈÉΩÈñãÂßãËÄÉÊÖÆ„ÄåÊºîÁÆóÊ≥ïÂÖ±Ë¨Ä„ÄçÁöÑÂæåÊûú„ÄÇÊàëÂÄëÁ†îÁ©∂Â§öËáÇËÄÅËôéÊ©üÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÂú®‰ª£ÁêÜÁ´∂Áà≠‰ΩÜÂ∞ç‰ªñÂÄëÂèÉËàáÁöÑÁ≠ñÁï•‰∫íÂãïÊØ´ÁÑ°ÊâÄÊÇâÁöÑÊÉÖÊ≥Å‰∏ãÁöÑÊñ∞ËààË°åÁÇ∫„ÄÇ‰ΩøÁî®‰∏ÄËà¨ÂΩ¢ÂºèÁöÑÈáçË§áÂõöÁäØÂõ∞Â¢ÉÂçöÂºàÔºå‰ª£ÁêÜÂú®Ê≤íÊúâÈÅäÊà≤ÁµêÊßãÂÖàÈ©óÊ®°ÂûãÂíåÂ∞çÁ´∂Áà≠ËÄÖÁãÄÊÖãÊàñË°åÂãï‰∏ÄÁÑ°ÊâÄÁü•Ôºà‰æãÂ¶ÇÔºåÊ≤íÊúâËßÄÂØüÂà∞Á´∂Áà≠ÂÉπÊ†ºÔºâÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÁ∑ö‰∏äÂ≠∏Áøí„ÄÇÊàëÂÄëË°®ÊòéÔºåÈÄô‰∫õÁÑ°ËÉåÊôØËÄÅËôéÊ©üÂú®‰∏çÁü•ÈÅìÂ∞çÊâãÈÅ∏ÊìáÊàñÁµêÊûúÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰ªçÁÑ∂ÊúÉÊåÅÁ∫åÂ≠∏ÁøíÂÖ±Ë¨ÄË°åÁÇ∫ÔºåÊàëÂÄëÁ®±‰πãÁÇ∫„ÄåÂ§©ÁúüÂÖ±Ë¨Ä„Äç„ÄÇÊàëÂÄë‰∏ªË¶ÅÈÄèÈÅéÂàÜÊûêÊ®°ÂûãÁ†îÁ©∂ÈÄôÂÄãÁ≥ªÁµ±Ôºå‰∏¶ÈÄèÈÅéÊ®°Êì¨Ê™¢Êü•Ê®°ÂûãÁöÑÊìæÂãï„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂ∞çÁõ£ÁÆ°Ê©üÊßãÊúâÂπæÂÄãÈ°ØËëóÁöÑÂΩ±Èüø„ÄÇÈ¶ñÂÖàÔºåË¶ÅÊ±ÇÈôêÂà∂ÊºîÁÆóÊ≥ï‰ª•Á´∂Áà≠Â∞çÊâãÁöÑÂÉπÊ†ºÁÇ∫Ê¢ù‰ª∂‰∏çË∂≥‰ª•Èò≤Ê≠¢ÊºîÁÆóÊ≥ïÂÖ±Ë¨Ä„ÄÇÈÄôÊòØÂÖ±Ë¨ÄÂç≥‰ΩøÂú®ÂñÆÁ¥îÁöÑË®≠ÂÆö‰∏≠‰πüÊúÉÁî¢ÁîüÁöÑÁõ¥Êé•ÁµêÊûú„ÄÇÂÖ∂Ê¨°ÔºåÊºîÁÆóÊ≥ï‰∏≠ÁöÑÂ∞çÁ®±ÊÄßÊúÉÂ¢ûÂä†ÂÖ±Ë¨ÄÁöÑÂèØËÉΩÊÄß„ÄÇÈÄôÁ™ÅÈ°Ø‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ„ÄÅÁ∞°ÂñÆÁöÑ„ÄåÊ®ûÁ¥êËºªÊ¢ù„ÄçÊºîÁÆóÊ≥ïÂÖ±Ë¨ÄÊ©üÂà∂„ÄÇ‰∏≠Â§ÆÁ∂ìÈä∑ÂïÜ‰∏çÂøÖËÆìÂÖ∂ÊºîÁÆóÊ≥ïÂÖ∑ÊúâË∂ÖÁ´∂Áà≠ÁöÑÂÇæÂêëÔºå‰ª•Ëá¥Áî¢ÁîüÊòéÈ°ØÁöÑÂÖ±Ë¨ÄÔºõÂÆÉÂèØ‰ª•ÈÄèÈÅé‰ΩøÁî®Êüê‰∫õÔºàÂ∏∏Ë¶ãÁöÑÔºâÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïËÄåÁî¢Áîü„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂº∑Ë™øÂÖ±Ë¨ÄÁµêÊûúÊòéÈ°ØÂèñÊ±∫ÊñºÊâÄ‰ΩøÁî®ÁöÑÁâπÂÆöÊºîÁÆóÊ≥ïÔºå‰∏¶‰∏îÊàëÂÄëÂº∑Ë™øÂ∏ÇÂ†¥ÂíåÊºîÁÆóÊ≥ïÊ¢ù‰ª∂ÔºåÂú®ÈÄô‰∫õÊ¢ù‰ª∂‰∏ãÂ∞áÁÑ°Ê≥ïÈ†êÂÖàÂæóÁü•ÊòØÂê¶ÊúÉÁôºÁîüÂÖ±Ë¨Ä„ÄÇ

##### **EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code**
2411.16561v1 by Shahriyar Zaman Ridoy, Md. Shazzad Hossain Shaon, Alfredo Cuzzocrea, Mst Shapna Akter

Automated detection of software vulnerabilities is critical for enhancing
security, yet existing methods often struggle with the complexity and diversity
of modern codebases. In this paper, we introduce EnStack, a novel ensemble
stacking framework that enhances vulnerability detection using natural language
processing (NLP) techniques. Our approach synergizes multiple pre-trained large
language models (LLMs) specialized in code understanding CodeBERT for semantic
analysis, GraphCodeBERT for structural representation, and UniXcoder for
cross-modal capabilities. By fine-tuning these models on the Draper VDISC
dataset and integrating their outputs through meta-classifiers such as Logistic
Regression, Support Vector Machines (SVM), Random Forest, and XGBoost, EnStack
effectively captures intricate code patterns and vulnerabilities that
individual models may overlook. The meta-classifiers consolidate the strengths
of each LLM, resulting in a comprehensive model that excels in detecting subtle
and complex vulnerabilities across diverse programming contexts. Experimental
results demonstrate that EnStack significantly outperforms existing methods,
achieving notable improvements in accuracy, precision, recall, and F1-score.
This work highlights the potential of ensemble LLM approaches in code analysis
tasks and offers valuable insights into applying NLP techniques for advancing
automated vulnerability detection.

ÊëòË¶ÅÔºöËá™ÂãïÂåñÂÅµÊ∏¨ËªüÈ´îÊºèÊ¥ûÂ∞çÊñºÊèêÂçáÂÆâÂÖ®ÊÄßËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁèæÊúâÊñπÊ≥ïÁ∂ìÂ∏∏Èõ£‰ª•ÊáâÂ∞çÁèæ‰ª£Á®ãÂºèÁ¢ºÂ∫´ÁöÑË§áÈõúÊÄßÂíåÂ§öÊ®£ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π EnStackÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÊï¥È´îÂ†ÜÁñäÊ°ÜÊû∂ÔºåÂÆÉ‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊäÄË°ì‰æÜÂ¢ûÂº∑ÊºèÊ¥ûÂÅµÊ∏¨„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÂ§öÂÄãÈ†êÂÖàË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂçîÂêåËµ∑‰æÜÔºåÈÄô‰∫õÊ®°ÂûãÂ∞àÈñÄÁî®ÊñºÁêÜËß£Á®ãÂºèÁ¢ºÔºöCodeBERT Áî®ÊñºË™ûÊÑèÂàÜÊûê„ÄÅGraphCodeBERT Áî®ÊñºÁµêÊßãË°®Á§∫ÔºåËÄå UniXcoder ÂâáÁî®ÊñºË∑®Ê®°ÊÖãËÉΩÂäõ„ÄÇÈÄèÈÅéÂæÆË™øÈÄô‰∫õÊ®°ÂûãÂú® Draper VDISC Ë≥áÊñôÈõÜ‰∏äÔºå‰∏¶ÈÄèÈÅéÂæåË®≠ÂàÜÈ°ûÂô®Ôºà‰æãÂ¶ÇÈÇèËºØËø¥Ê≠∏„ÄÅÊîØÊè¥ÂêëÈáèÊ©ü (SVM)„ÄÅÈö®Ê©üÊ£ÆÊûóÂíå XGBoostÔºâÊï¥ÂêàÂÖ∂Ëº∏Âá∫ÔºåEnStack ÊúâÊïàÂú∞Êì∑Âèñ‰∫ÜÂÄãÂà•Ê®°ÂûãÂèØËÉΩÂøΩÁï•ÁöÑË§áÈõúÁ®ãÂºèÁ¢ºÊ®°ÂºèÂíåÊºèÊ¥û„ÄÇÂæåË®≠ÂàÜÈ°ûÂô®Êï¥Âêà‰∫ÜÊØèÂÄã LLM ÁöÑÂÑ™ÈªûÔºåÁî¢Áîü‰∫Ü‰∏ÄÂÄãÁ∂úÂêàÊ®°ÂûãÔºåÊìÖÈï∑ÂÅµÊ∏¨Ë∑®‰∏çÂêåÁ®ãÂºèË®≠Ë®àËÉåÊôØÁöÑÁ¥∞ÂæÆËÄåË§áÈõúÁöÑÊºèÊ¥û„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåEnStack ÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåÂú®Ê∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏ÊñπÈù¢ÈÉΩÊúâÈ°ØËëóÁöÑÊèêÂçá„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁ™ÅÈ°Ø‰∫ÜÊï¥È´î LLM ÊñπÊ≥ïÂú®Á®ãÂºèÁ¢ºÂàÜÊûê‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõÔºå‰∏¶Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£ÔºåË™™ÊòéÂ¶Ç‰ΩïÊáâÁî® NLP ÊäÄË°ì‰æÜÊé®ÈÄ≤Ëá™ÂãïÂåñÊºèÊ¥ûÂÅµÊ∏¨„ÄÇ

##### **Representation Collapsing Problems in Vector Quantization**
2411.16550v1 by Wenhao Zhao, Qiran Zou, Rushi Shah, Dianbo Liu

Vector quantization is a technique in machine learning that discretizes
continuous representations into a set of discrete vectors. It is widely
employed in tokenizing data representations for large language models,
diffusion models, and other generative models. Despite its prevalence, the
characteristics and behaviors of vector quantization in generative models
remain largely underexplored. In this study, we investigate representation
collapse in vector quantization - a critical degradation where codebook tokens
or latent embeddings lose their discriminative power by converging to a limited
subset of values. This collapse fundamentally compromises the model's ability
to capture diverse data patterns. By leveraging both synthetic and real
datasets, we identify the severity of each type of collapses and triggering
conditions. Our analysis reveals that restricted initialization and limited
encoder capacity result in tokens collapse and embeddings collapse. Building on
these findings, we propose potential solutions aimed at mitigating each
collapse. To the best of our knowledge, this is the first comprehensive study
examining representation collapsing problems in vector quantization.

ÊëòË¶ÅÔºöÂêëÈáèÈáèÂåñÊòØÊú∫Âô®Â≠¶‰π†‰∏≠Â∞ÜËøûÁª≠Ë°®Á§∫Á¶ªÊï£Âåñ‰∏∫‰∏ÄÁªÑÁ¶ªÊï£ÂêëÈáèÁöÑÊäÄÊúØ„ÄÇÂÆÉÂπøÊ≥õÁî®‰∫éÂØπÂ§ßËØ≠Ë®ÄÊ®°Âûã„ÄÅÊâ©Êï£Ê®°ÂûãÂíåÂÖ∂‰ªñÁîüÊàêÊ®°ÂûãÁöÑÊï∞ÊçÆË°®Á§∫ËøõË°åÊ†áËÆ∞Âåñ„ÄÇÂ∞ΩÁÆ°ÂÆÉÂæàÊôÆÈÅçÔºå‰ΩÜÁîüÊàêÊ®°Âûã‰∏≠ÂêëÈáèÈáèÂåñÁöÑÁâπÂæÅÂíåË°å‰∏∫Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÂú®ËøôÈ°πÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨Ë∞ÉÊü•‰∫ÜÂêëÈáèÈáèÂåñ‰∏≠ÁöÑË°®Á§∫ÂùçÁº©‚Äî‚Äî‰∏Ä‰∏™ÂÖ≥ÈîÆÁöÑÈÄÄÂåñÔºåÂÖ∂‰∏≠Á†ÅÊú¨Ê†áËÆ∞ÊàñÊΩúÂú®ÂµåÂÖ•ÈÄöËøáÊî∂ÊïõÂà∞ÊúâÈôêÁöÑÂÄºÂ≠êÈõÜËÄåÂ§±ÂéªÂÖ∂Âà§Âà´ËÉΩÂäõ„ÄÇËøôÁßçÂùçÁº©‰ªéÊ†πÊú¨‰∏äÊçüÂÆ≥‰∫ÜÊ®°ÂûãÊçïËé∑‰∏çÂêåÊï∞ÊçÆÊ®°ÂºèÁöÑËÉΩÂäõ„ÄÇÈÄöËøáÂà©Áî®ÂêàÊàêÂíåÁúüÂÆûÊï∞ÊçÆÈõÜÔºåÊàë‰ª¨Á°ÆÂÆö‰∫ÜÊØèÁßçÁ±ªÂûãÂùçÁº©ÁöÑ‰∏•ÈáçÊÄßÂíåËß¶ÂèëÊù°‰ª∂„ÄÇÊàë‰ª¨ÁöÑÂàÜÊûêË°®ÊòéÔºåÂèóÈôêÁöÑÂàùÂßãÂåñÂíåÊúâÈôêÁöÑÁºñÁ†ÅÂô®ÂÆπÈáè‰ºöÂØºËá¥Ê†áËÆ∞ÂùçÁº©ÂíåÂµåÂÖ•ÂùçÁº©„ÄÇÂü∫‰∫éËøô‰∫õÂèëÁé∞ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊó®Âú®ÂáèËΩªÊØèÊ¨°ÂùçÁº©ÁöÑÊΩúÂú®Ëß£ÂÜ≥ÊñπÊ°à„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåËøôÊòØÁ¨¨‰∏ÄÈ°πÂÖ®Èù¢Á†îÁ©∂ÂêëÈáèÈáèÂåñ‰∏≠ÁöÑË°®Á§∫ÂùçÁº©ÈóÆÈ¢ò„ÄÇ

##### **RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics**
2411.16537v1 by Chan Hee Song, Valts Blukis, Jonathan Tremblay, Stephen Tyree, Yu Su, Stan Birchfield

Spatial understanding is a crucial capability for robots to make grounded
decisions based on their environment. This foundational skill enables robots
not only to perceive their surroundings but also to reason about and interact
meaningfully within the world. In modern robotics, these capabilities are taken
on by visual language models, and they face significant challenges when applied
to spatial reasoning context due to their training data sources. These sources
utilize general-purpose image datasets, and they often lack sophisticated
spatial scene understanding capabilities. For example, the datasets do not
address reference frame comprehension - spatial relationships require clear
contextual understanding, whether from an ego-centric, object-centric, or
world-centric perspective, which allow for effective real-world interaction. To
address this issue, we introduce RoboSpatial, a large-scale spatial
understanding dataset consisting of real indoor and tabletop scenes captured as
3D scans and egocentric images, annotated with rich spatial information
relevant to robotics. The dataset includes 1M images, 5K 3D scans, and 3M
annotated spatial relationships, with paired 2D egocentric images and 3D scans
to make it both 2D and 3D ready. Our experiments show that models trained with
RoboSpatial outperform baselines on downstream tasks such as spatial affordance
prediction, spatial relationship prediction, and robotics manipulation.

ÊëòË¶ÅÔºöÁ©∫ÈñìÁêÜËß£Â∞çÊñºÊ©üÂô®‰∫∫Ê†πÊìöÂÖ∂Áí∞Â¢ÉÂÅöÂá∫Á¥ÆÂØ¶ÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÈÄôÁ®ÆÂü∫Êú¨ÊäÄËÉΩ‰∏çÂÉÖ‰ΩøÊ©üÂô®‰∫∫ËÉΩÂ§†ÊÑüÁü•Âë®ÂúçÁí∞Â¢ÉÔºåÈÇÑËÉΩÂ∞ç‰∏ñÁïåÈÄ≤Ë°åÊé®ÁêÜ‰∏¶ÊúâÊÑèÁæ©Âú∞Ëàá‰πã‰∫íÂãï„ÄÇÂú®Áèæ‰ª£Ê©üÂô®‰∫∫ÊäÄË°ì‰∏≠ÔºåÈÄô‰∫õËÉΩÂäõÁî±Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÊâøÊìîÔºåÁî±ÊñºÂÖ∂Ë®ìÁ∑¥Êï∏ÊìöÊ∫êÔºåÂú®ÊáâÁî®ÊñºÁ©∫ÈñìÊé®ÁêÜÊÉÖÂ¢ÉÊôÇÈù¢Ëá®Âö¥Â≥ªÊåëÊà∞„ÄÇÈÄô‰∫õ‰æÜÊ∫êÂà©Áî®ÈÄöÁî®ÂúñÂÉèÊï∏ÊìöÈõÜÔºåËÄå‰∏îÈÄöÂ∏∏Áº∫‰πèË§áÈõúÁöÑÁ©∫ÈñìÂ†¥ÊôØÁêÜËß£ËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåÈÄô‰∫õÊï∏ÊìöÈõÜ‰∏çËôïÁêÜÂèÉËÄÉÊ°ÜÊû∂ÁêÜËß£‚Äî‚ÄîÁ©∫ÈñìÈóú‰øÇÈúÄË¶ÅÊ∏ÖÊô∞ÁöÑÊÉÖÂ¢ÉÁêÜËß£ÔºåÁÑ°Ë´ñÊòØÂæû‰ª•Ëá™ÊàëÁÇ∫‰∏≠ÂøÉ„ÄÅ‰ª•Â∞çË±°ÁÇ∫‰∏≠ÂøÉÈÇÑÊòØ‰ª•‰∏ñÁïåÁÇ∫‰∏≠ÂøÉÁöÑË¶ñËßíÔºåÈÄôÂÖÅË®±ÈÄ≤Ë°åÊúâÊïàÁöÑÁèæÂØ¶‰∏ñÁïå‰∫íÂãï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü RoboSpatialÔºå‰∏ÄÂÄãÁî±‰ª• 3D ÊéÉÊèèÂíåËá™Êàë‰∏≠ÂøÉÂúñÂÉèÂΩ¢ÂºèÊçïÊçâÁöÑÁúüÂØ¶ÂÆ§ÂÖßÂíåÊ°åÈù¢Â†¥ÊôØÁµÑÊàêÁöÑÂ§ßË¶èÊ®°Á©∫ÈñìÁêÜËß£Êï∏ÊìöÈõÜÔºå‰∏¶ÈôÑÊúâËàáÊ©üÂô®‰∫∫ÊäÄË°ìÁõ∏ÈóúÁöÑË±êÂØåÁ©∫Èñì‰ø°ÊÅØ„ÄÇË©≤Êï∏ÊìöÈõÜÂåÖÊã¨ 100 Ëê¨ÂºµÂúñÂÉè„ÄÅ5K 3D ÊéÉÊèèÂíå 300 Ëê¨ÂÄãÂ∏∂Ë®ªÈáãÁöÑÁ©∫ÈñìÈóú‰øÇÔºå‰∏¶ÈÖçÂ∞ç‰∫Ü 2D Ëá™Êàë‰∏≠ÂøÉÂúñÂÉèÂíå 3D ÊéÉÊèèÔºå‰ª•‰ΩøÂÖ∂ÂêåÊôÇÂÖ∑ÂÇô 2D Âíå 3D ÂäüËÉΩ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºå‰ΩøÁî® RoboSpatial Ë®ìÁ∑¥ÁöÑÊ®°ÂûãÂú®Á©∫ÈñìÂèØ‰æõÊÄßÈ†êÊ∏¨„ÄÅÁ©∫ÈñìÈóú‰øÇÈ†êÊ∏¨ÂíåÊ©üÂô®‰∫∫Êìç‰ΩúÁ≠â‰∏ãÊ∏∏‰ªªÂãô‰∏äÂÑ™ÊñºÂü∫Ê∫ñ„ÄÇ

##### **Profiling Bias in LLMs: Stereotype Dimensions in Contextual Word Embeddings**
2411.16527v1 by Carolin M. Schuster, Maria-Alexandra Dinisor, Shashwat Ghatiwala, Georg Groh

Large language models (LLMs) are the foundation of the current successes of
artificial intelligence (AI), however, they are unavoidably biased. To
effectively communicate the risks and encourage mitigation efforts these models
need adequate and intuitive descriptions of their discriminatory properties,
appropriate for all audiences of AI. We suggest bias profiles with respect to
stereotype dimensions based on dictionaries from social psychology research.
Along these dimensions we investigate gender bias in contextual embeddings,
across contexts and layers, and generate stereotype profiles for twelve
different LLMs, demonstrating their intuition and use case for exposing and
visualizing bias.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÁõÆÂâç‰∫∫Â∑•Êô∫ÊÖß (AI) ÊàêÂäüÁôºÂ±ïÁöÑÂü∫Á§éÔºåÁÑ∂ËÄåÂÆÉÂÄë‰∏çÂèØÈÅøÂÖçÂú∞ÊúâÂÅèË¶ã„ÄÇÁÇ∫‰∫ÜÊúâÊïàÂú∞ÂÇ≥ÈÅîÈ¢®Èö™‰∏¶ÈºìÂãµÊé°ÂèñÁ∑©Ëß£Êé™ÊñΩÔºåÈÄô‰∫õÊ®°ÂûãÈúÄË¶ÅÂ∞çÂÖ∂Ê≠ßË¶ñÊÄßÂ±¨ÊÄßÊèê‰æõÂÖÖÂàÜ‰∏îÁõ¥ËßÄÁöÑÊèèËø∞Ôºå‰ª•ÈÅ©Áî®ÊñºÊâÄÊúâ AI ÂèóÁúæ„ÄÇÊàëÂÄëÂª∫Ë≠∞Ê†πÊìöÁ§æÊúÉÂøÉÁêÜÂ≠∏Á†îÁ©∂ÁöÑÂ≠óÂÖ∏ÔºåÈáùÂ∞çÂàªÊùøÂç∞Ë±°Èù¢ÂêëÊèêÂá∫ÂÅèË¶ãÊ¶ÇÊ≥Å„ÄÇÊàëÂÄëÊ≤øËëóÈÄô‰∫õÈù¢ÂêëÊé¢Ë®éË™ûÂ¢ÉÂµåÂÖ•‰∏≠ÁöÑÊÄßÂà•ÂÅèË¶ãÔºåË∑®Ë∂äË™ûÂ¢ÉÂíåÂ±§Ê¨°Ôºå‰∏¶ÈáùÂ∞ç 12 ÂÄã‰∏çÂêåÁöÑ LLM Áî¢ÁîüÂàªÊùøÂç∞Ë±°Ê¶ÇÊ≥ÅÔºåÂ±ïÁ§∫ÂÖ∂Áõ¥Ë¶∫ÂíåÊè≠Èú≤ÂíåË¶ñË¶∫ÂåñÂÅèË¶ãÁöÑÁî®‰æã„ÄÇ

##### **Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency**
2411.16525v1 by Jerry Yao-Chieh Hu, Wei-Po Wang, Ammar Gilani, Chenyang Li, Zhao Song, Han Liu

We investigate the statistical and computational limits of prompt tuning for
transformer-based foundation models. Our key contributions are prompt tuning on
\textit{single-head} transformers with only a \textit{single} self-attention
layer: (i) is universal, and (ii) supports efficient (even almost-linear time)
algorithms under the Strong Exponential Time Hypothesis (SETH). Statistically,
we prove that prompt tuning on such simplest possible transformers are
universal approximators for sequence-to-sequence Lipschitz functions. In
addition, we provide an exponential-in-$dL$ and -in-$(1/\epsilon)$ lower bound
on the required soft-prompt tokens for prompt tuning to memorize any dataset
with 1-layer, 1-head transformers. Computationally, we identify a phase
transition in the efficiency of prompt tuning, determined by the norm of the
\textit{soft-prompt-induced} keys and queries, and provide an upper bound
criterion. Beyond this criterion, no sub-quadratic (efficient) algorithm for
prompt tuning exists under SETH. Within this criterion, we showcase our theory
by proving the existence of almost-linear time prompt tuning inference
algorithms. These fundamental limits provide important necessary conditions for
designing expressive and efficient prompt tuning methods for practitioners.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Ë®é‰∫ÜÂü∫ÊñºTransformerÁöÑÂü∫Á§éÊ®°ÂûãÊèêÁ§∫Ë™øÊï¥ÁöÑÁµ±Ë®àÂíåË®àÁÆóÈôêÂà∂„ÄÇÊàëÂÄëÁöÑÈóúÈçµË≤¢ÁçªÊòØÂñÆÈ†≠Transformer‰∏äÁöÑÊèêÁ§∫Ë™øÊï¥ÔºåÂÉÖÊúâ‰∏ÄÂÄãÂñÆ‰∏ÄÁöÑËá™Ê≥®ÊÑèÂäõÂ±§Ôºö(i) ÊòØÈÄöÁî®ÁöÑÔºå‰∏¶‰∏î (ii) Âú®Âº∑ÊåáÊï∏ÊôÇÈñìÂÅáË®≠ (SETH) ‰∏ãÊîØÊåÅÈ´òÊïàÔºàÁîöËá≥Âπæ‰πéÁ∑öÊÄßÊôÇÈñìÔºâÊºîÁÆóÊ≥ï„ÄÇÂú®Áµ±Ë®à‰∏äÔºåÊàëÂÄëË≠âÊòé‰∫ÜÂú®ÈÄôÊ®£ÊúÄÁ∞°ÂñÆÁöÑTransformer‰∏äÈÄ≤Ë°åÊèêÁ§∫Ë™øÊï¥ÊòØÂ∫èÂàóÂà∞Â∫èÂàó Lipschitz ÂáΩÊï∏ÁöÑÈÄöÁî®ÈÄºËøëÂô®„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂú® $dL$ Âíå -in-$(1/\epsilon)$ ‰∏≠ÂëàÊåáÊï∏Á¥öÁöÑËºÉ‰ΩéÈÇäÁïåÔºåÁî®ÊñºÊèêÁ§∫Ë™øÊï¥ÊâÄÈúÄÁöÑËªüÊèêÁ§∫Á¨¶ËôüÔºå‰ª•Ë®òÊÜ∂ÂÖ∑Êúâ 1 Â±§„ÄÅ1 È†≠TransformerÁöÑ‰ªª‰ΩïË≥áÊñôÈõÜ„ÄÇÂú®Ë®àÁÆó‰∏äÔºåÊàëÂÄëÂú®ÊèêÁ§∫Ë™øÊï¥ÁöÑÊïàÁéá‰∏≠ÁôºÁèæ‰∫Ü‰∏ÄÂÄãÁõ∏ËÆäÔºåÁî±ËªüÊèêÁ§∫Ë™òÂ∞éÁöÑÈçµÂíåÊü•Ë©¢ÁöÑÁØÑÊï∏Ê±∫ÂÆöÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄã‰∏äÈôêÊ∫ñÂâá„ÄÇÂú®Ê≠§Ê∫ñÂâá‰πãÂ§ñÔºåÂú® SETH ‰∏ã‰∏çÂ≠òÂú®‰ªª‰ΩïÊ¨°‰∫åÊ¨°ÔºàÈ´òÊïàÔºâÁöÑÊèêÁ§∫Ë™øÊï¥ÊºîÁÆóÊ≥ï„ÄÇÂú®Ê≠§Ê∫ñÂâáÂÖßÔºåÊàëÂÄëÈÄöÈÅéË≠âÊòéÂπæ‰πéÁ∑öÊÄßÊôÇÈñìÊèêÁ§∫Ë™øÊï¥Êé®Ë´ñÊºîÁÆóÊ≥ïÁöÑÂ≠òÂú®‰æÜÂ±ïÁ§∫ÊàëÂÄëÁöÑÁêÜË´ñ„ÄÇÈÄô‰∫õÂü∫Êú¨ÈôêÂà∂ÁÇ∫ÂØ¶ÂãôËÄÖË®≠Ë®àÂÖ∑ÊúâË°®ÈÅîÂäõÂíåÈ´òÊïàÁöÑÊèêÁ§∫Ë™øÊï¥ÊñπÊ≥ïÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÂøÖË¶ÅÊ¢ù‰ª∂„ÄÇ

##### **LaB-RAG: Label Boosted Retrieval Augmented Generation for Radiology Report Generation**
2411.16523v1 by Steven Song, Anirudh Subramanyam, Irene Madejski, Robert L. Grossman

In the current paradigm of image captioning, deep learning models are trained
to generate text from image embeddings of latent features. We challenge the
assumption that these latent features ought to be high-dimensional vectors
which require model fine tuning to handle. Here we propose Label Boosted
Retrieval Augmented Generation (LaB-RAG), a text-based approach to image
captioning that leverages image descriptors in the form of categorical labels
to boost standard retrieval augmented generation (RAG) with pretrained large
language models (LLMs). We study our method in the context of radiology report
generation (RRG), where the task is to generate a clinician's report detailing
their observations from a set of radiological images, such as X-rays. We argue
that simple linear classifiers over extracted image embeddings can effectively
transform X-rays into text-space as radiology-specific labels. In combination
with standard RAG, we show that these derived text labels can be used with
general-domain LLMs to generate radiology reports. Without ever training our
generative language model or image feature encoder models, and without ever
directly "showing" the LLM an X-ray, we demonstrate that LaB-RAG achieves
better results across natural language and radiology language metrics compared
with other retrieval-based RRG methods, while attaining competitive results
compared to other fine-tuned vision-language RRG models. We further present
results of our experiments with various components of LaB-RAG to better
understand our method. Finally, we critique the use of a popular RRG metric,
arguing it is possible to artificially inflate its results without true
data-leakage.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂ÂâçÂΩ±ÂÉèÊ®ôÈ°åÁöÑÁØÑ‰æã‰∏≠ÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁ∂ìÈÅéË®ìÁ∑¥ÔºåÂèØÂæûÊΩõÂú®ÁâπÂæµÁöÑÂΩ±ÂÉèÂµåÂÖ•Áî¢ÁîüÊñáÂ≠ó„ÄÇÊàëÂÄëÊåëÊà∞‰∫ÜÈÄô‰∫õÊΩõÂú®ÁâπÂæµÊáâÁÇ∫È´òÁ∂≠ÂêëÈáèÁöÑÂÅáË®≠ÔºåËÄåÈÄô‰∫õÂêëÈáèÈúÄË¶ÅÊ®°ÂûãÂæÆË™øÊâçËÉΩËôïÁêÜ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫Ê®ôÁ±§ÊèêÂçáÊ™¢Á¥¢Êì¥Â¢ûÁîüÊàê (LaB-RAG)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÊñáÂ≠óÁöÑÂΩ±ÂÉèÊ®ôÈ°åÊñπÊ≥ïÔºåÂÆÉÂà©Áî®È°ûÂà•Ê®ôÁ±§ÂΩ¢ÂºèÁöÑÂΩ±ÂÉèÊèèËø∞Á¨¶‰æÜÊèêÂçáÊ®ôÊ∫ñÊ™¢Á¥¢Êì¥Â¢ûÁîüÊàê (RAG) ËàáÈ†êÂÖàË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÊàëÂÄëÂú®ÊîæÂ∞ÑÁßëÂ†±ÂëäÁîüÊàê (RRG) ÁöÑËÑàÁµ°‰∏≠Á†îÁ©∂ÊàëÂÄëÁöÑÊ®°ÂûãÔºå‰ªªÂãôÊòØÊ†πÊìö‰∏ÄÁµÑÊîæÂ∞ÑÁßëÂΩ±ÂÉèÔºà‰æãÂ¶Ç X ÂÖâÔºâ‰∏≠ÁöÑËßÄÂØüÁµêÊûúÔºåÁî¢ÁîüËá®Â∫äÈÜ´Â∏´ÁöÑÂ†±Âëä„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÈáùÂ∞çÊèêÂèñÁöÑÂΩ±ÂÉèÂµåÂÖ•ÊâÄÂÅöÁöÑÁ∞°ÂñÆÁ∑öÊÄßÂàÜÈ°ûÂô®ÂèØ‰ª•ÊúâÊïàÂú∞Â∞á X ÂÖâËΩâÊèõÊàêÊñáÂ≠óÁ©∫ÈñìÔºå‰ΩúÁÇ∫ÊîæÂ∞ÑÁßëÂ∞àÁî®ÁöÑÊ®ôÁ±§„ÄÇÁµêÂêàÊ®ôÊ∫ñ RAGÔºåÊàëÂÄëË≠âÊòéÈÄô‰∫õË°çÁîüÁöÑÊñáÂ≠óÊ®ôÁ±§ÂèØÁî®Êñº‰∏ÄËà¨È†òÂüüÁöÑ LLMÔºå‰ª•Áî¢ÁîüÊîæÂ∞ÑÁßëÂ†±Âëä„ÄÇÊàëÂÄëÂæûÊú™Ë®ìÁ∑¥ÈÅéÊàëÂÄëÁöÑÁîüÊàêÂºèË™ûË®ÄÊ®°ÂûãÊàñÂΩ±ÂÉèÁâπÂæµÁ∑®Á¢ºÂô®Ê®°ÂûãÔºå‰πüÂæûÊú™Áõ¥Êé•„ÄåÂ±ïÁ§∫„ÄçLLM X ÂÖâÔºåÊàëÂÄëË≠âÊòé LaB-RAG Âú®Ëá™ÁÑ∂Ë™ûË®ÄÂíåÊîæÂ∞ÑÁßëË™ûË®ÄÊåáÊ®ô‰∏äÁöÑË°®ÁèæÔºåÂÑ™ÊñºÂÖ∂‰ªñÂü∫ÊñºÊ™¢Á¥¢ÁöÑ RRG ÊñπÊ≥ïÔºåÂêåÊôÇËàáÂÖ∂‰ªñÂæÆË™øÁöÑË¶ñË¶∫Ë™ûË®Ä RRG Ê®°ÂûãÁõ∏ÊØîÔºå‰πüÂèñÂæó‰∫ÜÁ´∂Áà≠ÂäõÁöÑÁµêÊûú„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â±ïÁ§∫‰∫Ü‰ΩøÁî® LaB-RAG ÂêÑÁ®ÆÂÖÉ‰ª∂ÁöÑÂØ¶È©óÁµêÊûúÔºå‰ª•Êõ¥‰∫ÜËß£ÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊâπÂà§‰∫Ü‰ΩøÁî®‰∏ÄÁ®ÆÂª£Ê≥õ‰ΩøÁî®ÁöÑ RRG ÊåáÊ®ôÔºå‰∏¶‰∏ªÂºµÂú®Ê≤íÊúâÁúüÊ≠£Ë≥áÊñôÂ§ñÊ¥©ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞±ÊúâÂèØËÉΩ‰∫∫ÁÇ∫Âú∞ËÜ®ËÑπÂÖ∂ÁµêÊûú„ÄÇ</paragraph>

##### **All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages**
2411.16508v1 by Ashmal Vayani, Dinura Dissanayake, Hasindri Watawana, Noor Ahsan, Nevasini Sasikumar, Omkar Thawakar, Henok Biadglign Ademtew, Yahya Hmaiti, Amandeep Kumar, Kartik Kuckreja, Mykola Maslych, Wafa Al Ghallabi, Mihail Mihaylov, Chao Qin, Abdelrahman M Shaker, Mike Zhang, Mahardika Krisna Ihsani, Amiel Esplana, Monil Gokani, Shachar Mirkin, Harsh Singh, Ashay Srivastava, Endre Hamerlik, Fathinah Asma Izzati, Fadillah Adamsyah Maani, Sebastian Cavada, Jenny Chim, Rohit Gupta, Sanjay Manjunath, Kamila Zhumakhanova, Feno Heriniaina Rabevohitra, Azril Amirudin, Muhammad Ridzuan, Daniya Kareem, Ketan More, Kunyang Li, Pramesh Shakya, Muhammad Saad, Amirpouya Ghasemaghaei, Amirbek Djanibekov, Dilshod Azizov, Branislava Jankovic, Naman Bhatia, Alvaro Cabrera, Johan Obando-Ceron, Olympiah Otieno, Fabian Farestam, Muztoba Rabbani, Sanoojan Baliah, Santosh Sanjeev, Abduragim Shtanchaev, Maheen Fatima, Thao Nguyen, Amrin Kareem, Toluwani Aremu, Nathan Xavier, Amit Bhatkal, Hawau Toyin, Aman Chadha, Hisham Cholakkal, Rao Muhammad Anwer, Michael Felsberg, Jorma Laaksonen, Thamar Solorio, Monojit Choudhury, Ivan Laptev, Mubarak Shah, Salman Khan, Fahad Khan

Existing Large Multimodal Models (LMMs) generally focus on only a few regions
and languages. As LMMs continue to improve, it is increasingly important to
ensure they understand cultural contexts, respect local sensitivities, and
support low-resource languages, all while effectively integrating corresponding
visual cues. In pursuit of culturally diverse global multimodal models, our
proposed All Languages Matter Benchmark (ALM-bench) represents the largest and
most comprehensive effort to date for evaluating LMMs across 100 languages.
ALM-bench challenges existing models by testing their ability to understand and
reason about culturally diverse images paired with text in various languages,
including many low-resource languages traditionally underrepresented in LMM
research. The benchmark offers a robust and nuanced evaluation framework
featuring various question formats, including true/false, multiple choice, and
open-ended questions, which are further divided into short and long-answer
categories. ALM-bench design ensures a comprehensive assessment of a model's
ability to handle varied levels of difficulty in visual and linguistic
reasoning. To capture the rich tapestry of global cultures, ALM-bench carefully
curates content from 13 distinct cultural aspects, ranging from traditions and
rituals to famous personalities and celebrations. Through this, ALM-bench not
only provides a rigorous testing ground for state-of-the-art open and
closed-source LMMs but also highlights the importance of cultural and
linguistic inclusivity, encouraging the development of models that can serve
diverse global populations effectively. Our benchmark is publicly available.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°ÂûãÔºàLMMÔºâÈÄöÂ∏∏Âè™Â∞àÊ≥®ÊñºÂ∞ëÊï∏ÂçÄÂüüÂíåË™ûË®Ä„ÄÇÈö®Ëëó LMM ÊåÅÁ∫åÈÄ≤Ê≠•ÔºåÁ¢∫‰øùÂÆÉÂÄëËÉΩÁêÜËß£ÊñáÂåñËÉåÊôØ„ÄÅÂ∞äÈáçÁï∂Âú∞ÊïèÊÑüÊÄßÔºå‰ª•ÂèäÊîØÊè¥‰ΩéË≥áÊ∫êË™ûË®ÄËÆäÂæóË∂ä‰æÜË∂äÈáçË¶ÅÔºåÂêåÊôÇÈÇÑË¶ÅÊúâÊïàÊï¥ÂêàÂ∞çÊáâÁöÑË¶ñË¶∫ÊèêÁ§∫„ÄÇÁÇ∫‰∫ÜËøΩÊ±ÇÊñáÂåñÂ§öÂÖÉÁöÑÂÖ®ÁêÉÂ§öÊ®°ÊÖãÊ®°ÂûãÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊâÄÊúâË™ûË®ÄÈáçË¶ÅÂü∫Ê∫ñÔºàALM-benchÔºâ‰ª£Ë°®‰∫ÜËøÑ‰ªäÁÇ∫Ê≠¢Ë©ï‰º∞ 100 Á®ÆË™ûË®ÄÁöÑ LMM ÁöÑÊúÄÂ§ßË¶èÊ®°‰∏îÊúÄÂÖ®Èù¢ÁöÑÂä™Âäõ„ÄÇALM-bench ÈÄèÈÅéÊ∏¨Ë©¶ LMM ÁêÜËß£ÂíåÊé®ÁêÜËàáÂêÑÁ®ÆË™ûË®ÄÔºàÂåÖÊã¨ÂÇ≥Áµ±‰∏äÂú® LMM Á†îÁ©∂‰∏≠‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑË®±Â§ö‰ΩéË≥áÊ∫êË™ûË®ÄÔºâÈÖçÂ∞çÁöÑÊñáÂåñÂ§öÂÖÉÂúñÂÉèÁöÑËÉΩÂäõÔºåÂ∞çÁèæÊúâÊ®°ÂûãÊèêÂá∫ÊåëÊà∞„ÄÇÊ≠§Âü∫Ê∫ñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑ÂÅ•‰∏îÁ¥∞Á∑ªÁöÑË©ï‰º∞Êû∂ÊßãÔºåÂÖ∑ÊúâÂêÑÁ®ÆÂïèÈ°åÊ†ºÂºèÔºåÂåÖÊã¨ÊòØÈùûÈ°å„ÄÅÂ§öÈÅ∏È°åÂíåÈñãÊîæÂºèÂïèÈ°åÔºåÈÄ≤‰∏ÄÊ≠•ÂàÜÁÇ∫Á∞°Á≠îÂíåÈï∑Á≠îÈ°ûÂà•„ÄÇALM-bench Ë®≠Ë®àÁ¢∫‰øùÂÖ®Èù¢Ë©ï‰º∞Ê®°ÂûãÂú®Ë¶ñË¶∫ÂíåË™ûË®ÄÊé®ÁêÜ‰∏≠ËôïÁêÜ‰∏çÂêåÈõ£Â∫¶Á≠âÁ¥öÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÊçïÊçâÂÖ®ÁêÉÊñáÂåñÁöÑË±êÂØåÊ®£Ë≤åÔºåALM-bench Á≤æÂøÉÁ≠ñÂäÉ‰∫Ü‰æÜËá™ 13 ÂÄã‰∏çÂêåÊñáÂåñÈù¢ÂêëÁöÑÂÖßÂÆπÔºåÂæûÂÇ≥Áµ±ÂíåÂÑÄÂºèÂà∞Âêç‰∫∫ËàáÊÖ∂ÂÖ∏„ÄÇÈÄèÈÅéÊ≠§ÊñπÂºèÔºåALM-bench ‰∏çÂÉÖÁÇ∫ÊúÄÂÖàÈÄ≤ÁöÑÈñãÊîæÂíåÈñâÊ∫ê LMM Êèê‰æõ‰∫ÜÂö¥Ê†ºÁöÑÊ∏¨Ë©¶Â†¥ÂüüÔºå‰πüÁ™ÅÈ°Ø‰∫ÜÊñáÂåñÂíåË™ûË®ÄÂåÖÂÆπÊÄßÁöÑÈáçË¶ÅÊÄßÔºåÈºìÂãµÈñãÁôºËÉΩÊúâÊïàÊúçÂãôÂÖ®ÁêÉÂ§öÂÖÉ‰∫∫Âè£ÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÊòØÂÖ¨ÈñãÁöÑ„ÄÇ

##### **Interpreting Language Reward Models via Contrastive Explanations**
2411.16502v1 by Junqi Jiang, Tom Bewley, Saumitra Mishra, Freddy Lecue, Manuela Veloso

Reward models (RMs) are a crucial component in the alignment of large
language models' (LLMs) outputs with human values. RMs approximate human
preferences over possible LLM responses to the same prompt by predicting and
comparing reward scores. However, as they are typically modified versions of
LLMs with scalar output heads, RMs are large black boxes whose predictions are
not explainable. More transparent RMs would enable improved trust in the
alignment of LLMs. In this work, we propose to use contrastive explanations to
explain any binary response comparison made by an RM. Specifically, we generate
a diverse set of new comparisons similar to the original one to characterise
the RM's local behaviour. The perturbed responses forming the new comparisons
are generated to explicitly modify manually specified high-level evaluation
attributes, on which analyses of RM behaviour are grounded. In quantitative
experiments, we validate the effectiveness of our method for finding
high-quality contrastive explanations. We then showcase the qualitative
usefulness of our method for investigating global sensitivity of RMs to each
evaluation attribute, and demonstrate how representative examples can be
automatically extracted to explain and compare behaviours of different RMs. We
see our method as a flexible framework for RM explanation, providing a basis
for more interpretable and trustworthy LLM alignment.

ÊëòË¶ÅÔºöÁçéÂãµÊ®°Âûã (RM) ÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëº∏Âá∫Ëàá‰∫∫È°ûÂÉπÂÄºËßÄ‰∏ÄËá¥ÊÄßÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇRM ÈÄèÈÅéÈ†êÊ∏¨ÂíåÊØîËºÉÁçéÂãµÂàÜÊï∏‰æÜËøë‰ºº‰∫∫È°ûÂ∞çÁõ∏ÂêåÊèêÁ§∫ÁöÑ LLM ÂõûÊáâÁöÑÂÅèÂ•Ω„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂÆÉÂÄëÈÄöÂ∏∏ÊòØÂÖ∑ÊúâÊ®ôÈáèËº∏Âá∫È†≠ÁöÑ LLM ÁöÑ‰øÆÊîπÁâàÊú¨ÔºåÂõ†Ê≠§ RM ÊòØÂ§ßÂûãÈªëÁõíÂ≠êÔºåÂÖ∂È†êÊ∏¨ÁÑ°Ê≥ïËß£Èáã„ÄÇÊõ¥ÈÄèÊòéÁöÑ RM ÂèØ‰ª•ÊèêÈ´òÂ∞ç LLM ‰∏ÄËá¥ÊÄßÁöÑ‰ø°‰ªª„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®Â∞çÊØîËß£Èáã‰æÜËß£Èáã RM ÂÅöÂá∫ÁöÑ‰ªª‰Ωï‰∫åÂÖÉÂõûÊáâÊØîËºÉ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁîüÊàê‰∏ÄÁµÑËàáÂéüÂßãÊØîËºÉÈ°û‰ººÁöÑÂ§öÊ®£ÂåñÊñ∞ÊØîËºÉÔºå‰ª•Ë°®Âæµ RM ÁöÑÂ±ÄÈÉ®Ë°åÁÇ∫„ÄÇÂΩ¢ÊàêÊñ∞ÊØîËºÉÁöÑÊìæÂãïÂõûÊáâË¢´ÁîüÊàê‰ª•ÊòéÁ¢∫‰øÆÊîπÊâãÂãïÊåáÂÆöÁöÑË©ï‰º∞È´òÂ±§Á¥öÂ±¨ÊÄßÔºåRM Ë°åÁÇ∫ÂàÜÊûê‰ª•Ê≠§ÁÇ∫Âü∫Á§é„ÄÇÂú®ÂÆöÈáèÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Â∞ãÊâæÈ´òÂìÅË≥™Â∞çÊØîËß£ÈáãÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Á†îÁ©∂ RM Â∞çÊØèÂÄãË©ï‰º∞Â±¨ÊÄßÁöÑÂÖ®Â±ÄÊïèÊÑüÊÄßÊñπÈù¢ÁöÑÂÆöÊÄßÊúâÁî®ÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïËá™ÂãïÊèêÂèñ‰ª£Ë°®ÊÄßÁØÑ‰æã‰æÜËß£ÈáãÂíåÊØîËºÉ‰∏çÂêå RM ÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁöÑÊñπÊ≥ïË¶ñÁÇ∫ RM Ëß£ÈáãÁöÑÂΩàÊÄßÊ°ÜÊû∂ÔºåÁÇ∫Êõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Ë≥¥ÊÄßÁöÑ LLM ‰∏ÄËá¥ÊÄßÊèê‰æõÂü∫Á§é„ÄÇ

##### **AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**
2411.16495v1 by Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Li, Shulin Cao, Lei Hou, Juanzi Li

Recent advancements in large language models (LLMs) have led to significant
improvements in various natural language processing tasks, but it is still
challenging for LLMs to perform knowledge-intensive complex question answering
due to LLMs' inefficacy in reasoning planning and the hallucination problem. A
typical solution is to employ retrieval-augmented generation (RAG) coupled with
chain-of-thought (CoT) reasoning, which decomposes complex questions into
chain-like sub-questions and applies iterative RAG at each sub-question.
However, prior works exhibit sub-optimal reasoning planning and overlook
dynamic knowledge retrieval from heterogeneous sources. In this paper, we
propose AtomR, a novel heterogeneous knowledge reasoning framework that
conducts multi-source reasoning at the atomic level. Drawing inspiration from
the graph modeling of knowledge, AtomR leverages large language models (LLMs)
to decompose complex questions into combinations of three atomic knowledge
operators, significantly enhancing the reasoning process at both the planning
and execution stages. We also introduce BlendQA, a novel evaluation benchmark
tailored to assess complex heterogeneous knowledge reasoning. Experiments show
that AtomR significantly outperforms state-of-the-art baselines across three
single-source and two multi-source reasoning benchmarks, with notable
performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Â§ßÂπÖÊîπÂñÑÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÔºå‰ΩÜÁî±Êñº LLM Âú®Êé®ÁêÜË¶èÂäÉÂíåÂπªË¶∫ÂïèÈ°å‰∏äÁöÑÁÑ°ËÉΩÔºåÂ∞çÊñº LLM Âü∑Ë°åÈúÄË¶ÅÁü•Ë≠òÁöÑË§áÈõúÂïèÈ°åÂõûÁ≠î‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂÖ∏ÂûãÁöÑËß£Ê±∫ÊñπÊ°àÊòØÊé°Áî®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Êê≠ÈÖçÊÄùËÄÉÈèà (CoT) Êé®ÁêÜÔºåÂ∞áË§áÈõúÂïèÈ°åÂàÜËß£ÊàêÈèàÁãÄÂ≠êÂïèÈ°åÔºå‰∏¶Âú®ÊØèÂÄãÂ≠êÂïèÈ°å‰∏äÂ•óÁî®Ëø≠‰ª£ RAG„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑÂ∑•‰ΩúÂ±ïÁèæÂá∫Ê¨°‰Ω≥Êé®ÁêÜË¶èÂäÉÔºå‰∏îÂøΩÁï•‰∫ÜÂæûÁï∞Ë≥™‰æÜÊ∫êÂãïÊÖãÊ™¢Á¥¢Áü•Ë≠ò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ AtomRÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÁï∞Ë≥™Áü•Ë≠òÊé®ÁêÜÊû∂ÊßãÔºåÂú®ÂéüÂ≠êÂ±§Á¥öÂü∑Ë°åÂ§ö‰æÜÊ∫êÊé®ÁêÜ„ÄÇÂæûÁü•Ë≠òÁöÑÂúñÂΩ¢Âª∫Ê®°‰∏≠Ê±≤ÂèñÈùàÊÑüÔºåAtomR Êé°Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞áË§áÈõúÂïèÈ°åÂàÜËß£Êàê‰∏âÁ®ÆÂéüÂ≠êÁü•Ë≠òÈÅãÁÆóÂ≠êÁöÑÁµÑÂêàÔºåÂ§ßÂπÖÂº∑ÂåñË¶èÂäÉÂíåÂü∑Ë°åÈöéÊÆµÁöÑÊé®ÁêÜÁ®ãÂ∫è„ÄÇÊàëÂÄë‰πüÂºïÂÖ•‰∫Ü BlendQAÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑË©ïÈáèÂü∫Ê∫ñÔºåÂ∞àÈñÄÁî®‰æÜË©ï‰º∞Ë§áÈõúÁöÑÁï∞Ë≥™Áü•Ë≠òÊé®ÁêÜ„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåAtomR Âú®‰∏âÂÄãÂñÆ‰∏Ä‰æÜÊ∫êÂíåÂÖ©ÂÄãÂ§ö‰æÜÊ∫êÊé®ÁêÜÂü∫Ê∫ñ‰∏äÂ§ßÂπÖÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Á∑öÔºåÂú® 2WikiMultihop ‰∏äÊúâ 9.4% ÁöÑÈ°ØËëóÊïàËÉΩÊèêÂçáÔºåÂú® BlendQA ‰∏äÂâáÊúâ 9.5%„ÄÇ

##### **O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?**
2411.16489v1 by Zhen Huang, Haoyang Zou, Xuefeng Li, Yixiu Liu, Yuxiang Zheng, Ethan Chern, Shijie Xia, Yiwei Qin, Weizhe Yuan, Pengfei Liu

This paper presents a critical examination of current approaches to
replicating OpenAI's O1 model capabilities, with particular focus on the
widespread but often undisclosed use of knowledge distillation techniques.
While our previous work explored the fundamental technical path to O1
replication, this study reveals how simple distillation from O1's API, combined
with supervised fine-tuning, can achieve superior performance on complex
mathematical reasoning tasks. Through extensive experiments, we show that a
base model fine-tuned on simply tens of thousands of samples O1-distilled
long-thought chains outperforms O1-preview on the American Invitational
Mathematics Examination (AIME) with minimal technical complexity. Moreover, our
investigation extends beyond mathematical reasoning to explore the
generalization capabilities of O1-distilled models across diverse tasks:
hallucination, safety and open-domain QA. Notably, despite training only on
mathematical problem-solving data, our models demonstrated strong
generalization to open-ended QA tasks and became significantly less susceptible
to sycophancy after fine-tuning. We deliberately make this finding public to
promote transparency in AI research and to challenge the current trend of
obscured technical claims in the field. Our work includes: (1) A detailed
technical exposition of the distillation process and its effectiveness, (2) A
comprehensive benchmark framework for evaluating and categorizing O1
replication attempts based on their technical transparency and reproducibility,
(3) A critical discussion of the limitations and potential risks of
over-relying on distillation approaches, our analysis culminates in a crucial
bitter lesson: while the pursuit of more capable AI systems is important, the
development of researchers grounded in first-principles thinking is paramount.

ÊëòË¶ÅÔºöÊú¨Ë´ñÊñáÂ∞çË§áË£Ω OpenAI ÁöÑ O1 Ê®°ÂûãËÉΩÂäõÁöÑÁèæÊúâÊñπÊ≥ïÈÄ≤Ë°åÊâπÂà§ÊÄßÊé¢Ë®éÔºåÁâπÂà•ÈóúÊ≥®Áü•Ë≠òËí∏È§æÊäÄË°ìÁöÑÂª£Ê≥õ‰ΩÜÁ∂ìÂ∏∏Êú™ÂÖ¨ÈñãÁöÑ‰ΩøÁî®„ÄÇÈõñÁÑ∂ÊàëÂÄë‰πãÂâçÁöÑÂ∑•‰ΩúÊé¢Á¥¢‰∫Ü O1 Ë§áË£ΩÁöÑÂü∫Êú¨ÊäÄË°ìË∑ØÂæëÔºå‰ΩÜÊú¨Á†îÁ©∂Êè≠Á§∫‰∫ÜÂæû O1 ÁöÑ API ÈÄ≤Ë°åÁ∞°ÂñÆËí∏È§æÔºåÁµêÂêàÁõ£Áù£ÂæÆË™øÔºåÂèØ‰ª•Âú®Ë§áÈõúÁöÑÊï∏Â≠∏Êé®ÁêÜ‰ªªÂãô‰∏äÂØ¶ÁèæÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇÈÄöÈÅéÂ§ßÈáèÁöÑÂØ¶È©óÔºåÊàëÂÄëË°®ÊòéÂú®ÂÉÖÊï∏Ëê¨ÂÄãÊ®£Êú¨‰∏äÈÄ≤Ë°åÂæÆË™øÁöÑÂü∫Êú¨Ê®°ÂûãÔºåO1 Ëí∏È§æÁöÑÈï∑ÊúüÊÄùËÄÉÈèàÂú®ÁæéÂúãÈÇÄË´ãË≥ΩÊï∏Â≠∏ËÄÉË©¶ (AIME) ‰∏äÂÑ™Êñº O1 È†êË¶ΩÔºå‰∏îÊäÄË°ìË§áÈõúÊÄßÊúÄÂ∞è„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÈôêÊñºÊï∏Â≠∏Êé®ÁêÜÔºåÈÇÑÊé¢Á¥¢‰∫Ü O1 Ëí∏È§æÊ®°ÂûãÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõÔºöÂπªË¶∫„ÄÅÂÆâÂÖ®ÊÄß„ÄÅÈñãÊîæÂüü QA„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂÑòÁÆ°ÂÉÖÊ†πÊìöÊï∏Â≠∏ÂïèÈ°åËß£Ê±∫Êï∏ÊìöÈÄ≤Ë°åË®ìÁ∑¥ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÈñãÊîæÂºè QA ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Âº∑Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºå‰∏¶‰∏îÂú®ÂæÆË™øÂæåÂ∞çÈòøË´õÂ•âÊâøÁöÑÂΩ±ÈüøÈ°ØËëóÈôç‰Ωé„ÄÇÊàëÂÄëÊïÖÊÑèÂÖ¨ÈñãÈÄô‰∏ÄÁôºÁèæÔºå‰ª•‰øÉÈÄ≤‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂ÁöÑÈÄèÊòéÂ∫¶Ôºå‰∏¶ÊåëÊà∞Ë©≤È†òÂüüÁï∂ÂâçÊäÄË°ìËÅ≤ÊòéÊ®°Á≥äÁöÑË∂®Âã¢„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂåÖÊã¨Ôºö(1) Ëí∏È§æÈÅéÁ®ãÂèäÂÖ∂ÊúâÊïàÊÄßÁöÑË©≥Á¥∞ÊäÄË°ìË™™ÊòéÔºå(2) Áî®ÊñºË©ï‰º∞ÂíåÂàÜÈ°û O1 Ë§áË£ΩÂòóË©¶ÁöÑÁ∂úÂêàÂü∫Ê∫ñÊû∂ÊßãÔºåÂü∫ÊñºÂÆÉÂÄëÁöÑÊäÄË°ìÈÄèÊòéÂ∫¶ÂíåÂèØË§áË£ΩÊÄßÔºå(3) ÈÅéÂ∫¶‰æùË≥¥Ëí∏È§æÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄßÂíåÊΩõÂú®È¢®Èö™ÁöÑÊâπÂà§ÊÄßË®éË´ñÔºåÊàëÂÄëÁöÑÂàÜÊûêÊúÄÁµÇÂæóÂá∫‰∏ÄÂÄãËá≥ÈóúÈáçË¶ÅÁöÑÊÖòÁóõÊïôË®ìÔºöÈõñÁÑ∂ËøΩÊ±ÇÊõ¥Âº∑Â§ßÁöÑ AI Á≥ªÁµ±ÂæàÈáçË¶ÅÔºå‰ΩÜÂüπÈ§ä‰ª•Á¨¨‰∏ÄÊÄßÂéüÁêÜÊÄùÁ∂≠ÁÇ∫Âü∫Á§éÁöÑÁ†îÁ©∂‰∫∫Âì°Ëá≥ÈóúÈáçË¶Å„ÄÇ

##### **When Babies Teach Babies: Can student knowledge sharing outperform Teacher-Guided Distillation on small datasets?**
2411.16487v1 by Srikrishna Iyer

We present our submission to the BabyLM challenge, aiming to push the
boundaries of data-efficient language model pretraining. Our method builds upon
deep mutual learning, introducing a student model search for diverse
initialization. We address the limitation of treating students equally by
formulating weighted mutual learning as a bi-level optimization problem. The
inner loop learns compact students through online distillation, while the outer
loop optimizes weights for better knowledge distillation from diverse students.
This dynamic weighting strategy eliminates the need for a teacher model,
reducing computational requirements. Our evaluations show that teacher-less
methods can match or surpass teacher-supervised approaches.

ÊëòË¶ÅÔºöÊàëÂÄëÊèê‰∫§ BabyLM ÊåëÊà∞ÔºåÊó®Âú®Á™ÅÁ†¥Ë≥áÊñôÊúâÊïàË™ûË®ÄÊ®°ÂûãÈ†êË®ìÁ∑¥ÁöÑÁïåÁ∑ö„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÂª∫Á´ãÂú®Ê∑±Â∫¶‰∫íÂ≠∏ÔºåÂºïÂÖ•Â≠∏ÁîüÊ®°ÂûãÊêúÂ∞ã‰ª•ÈÄ≤Ë°åÂ§öÂÖÉÂàùÂßãÂåñ„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áÂä†Ê¨ä‰∫íÂ≠∏Ë°®Ëø∞ÁÇ∫ÈõôÂ±§ÊúÄ‰Ω≥ÂåñÂïèÈ°åÔºå‰æÜËß£Ê±∫Âπ≥Á≠âÂ∞çÂæÖÂ≠∏ÁîüÁöÑÈôêÂà∂„ÄÇÂÖßÂ±§Ëø¥ÂúàÈÄèÈÅéÁ∑ö‰∏äËêÉÂèñÂ≠∏ÁøíÁ≤æÁ∞°ÁöÑÂ≠∏ÁîüÔºåËÄåÂ§ñÂ±§Ëø¥ÂúàÊúÄ‰Ω≥ÂåñÊ¨äÈáçÔºå‰ª•ÂæûÂ§öÂÖÉÂ≠∏Áîü‰∏≠ÈÄ≤Ë°åÊõ¥Â•ΩÁöÑÁü•Ë≠òËêÉÂèñ„ÄÇÈÄôÁ®ÆÂãïÊÖãÂä†Ê¨äÁ≠ñÁï•Ê∂àÈô§‰∫ÜÂ∞çÊïôÂ∏´Ê®°ÂûãÁöÑÈúÄÊ±ÇÔºåÊ∏õÂ∞ë‰∫ÜÈÅãÁÆóÈúÄÊ±Ç„ÄÇÊàëÂÄëÁöÑË©ï‰º∞È°ØÁ§∫ÔºåÁÑ°ÊïôÂ∏´ÊñπÊ≥ïÂèØ‰ª•ÊØîÊì¨ÊàñË∂ÖË∂äÊïôÂ∏´Áõ£Áù£ÊñπÊ≥ï„ÄÇ

##### **Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction**
2411.16457v1 by Haoming Li

In this paper, we present a novel trajectory prediction model for autonomous
driving, combining a Characterized Diffusion Module and a Spatial-Temporal
Interaction Network to address the challenges posed by dynamic and
heterogeneous traffic environments. Our model enhances the accuracy and
reliability of trajectory predictions by incorporating uncertainty estimation
and complex agent interactions. Through extensive experimentation on public
datasets such as NGSIM, HighD, and MoCAD, our model significantly outperforms
existing state-of-the-art methods. We demonstrate its ability to capture the
underlying spatial-temporal dynamics of traffic scenarios and improve
prediction precision, especially in complex environments. The proposed model
showcases strong potential for application in real-world autonomous driving
systems.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî®ÊñºËá™ÂãïÈßïÈßõÁöÑÂÖ®Êñ∞ËªåË∑°È†êÊ∏¨Ê®°ÂûãÔºåÁµêÂêàÁâπÂæµÊì¥Êï£Ê®°ÁµÑÂíåÊôÇÁ©∫‰∫íÂãïÁ∂≤Ë∑ØÔºå‰ª•Ëß£Ê±∫ÂãïÊÖã‰∏îÁï∞Ë≥™ÁöÑ‰∫§ÈÄöÁí∞Â¢ÉÊâÄÂ∏∂‰æÜÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÄèÈÅéÁ¥çÂÖ•‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÂíåË§áÈõúÁöÑ‰ª£ÁêÜ‰∫íÂãïÔºåÂ¢ûÂº∑‰∫ÜËªåË∑°È†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÈÄèÈÅéÂú® NGSIM„ÄÅHighD Âíå MoCAD Á≠âÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈ°ØËëóÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ï„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂÆÉÊçïÊçâ‰∫§ÈÄöÂ†¥ÊôØ‰∏≠Âü∫Á§éÊôÇÁ©∫ÂãïÊÖãÁöÑËÉΩÂäõÔºå‰∏¶ÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Á≤æÂ∫¶ÔºåÁâπÂà•ÊòØÂú®Ë§áÈõúÁöÑÁí∞Â¢É‰∏≠„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá™ÂãïÈßïÈßõÁ≥ªÁµ±‰∏≠ÊáâÁî®ÁöÑÂº∑Â§ßÊΩõÂäõ„ÄÇ

##### **Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**
2411.16454v1 by Xiaocong Yang, Jiacheng Lin, Ziqi Wang, Chengxiang Zhai

Large language models (LLMs) are known to struggle with complicated reasoning
tasks such as math word problems (MWPs). In this paper, we present how analogy
from similarly structured questions can improve LLMs' problem-solving
capabilities for MWPs. Specifically, we rely on the retrieval of problems with
similar computational graphs to the given question to serve as exemplars in the
prompt, providing the correct reasoning path for the generation model to refer
to. Empirical results across six math word problem datasets demonstrate the
effectiveness of our proposed method, which achieves a significant improvement
of up to 6.7 percent on average in absolute value, compared to baseline
methods. These results highlight our method's potential in addressing the
reasoning challenges in current LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Áü•Âú®Ë§áÈõúÊé®ÁêÜ‰ªªÂãôÔºà‰æãÂ¶ÇÊï∏Â≠∏ÊñáÂ≠óÈ°å (MWP)Ôºâ‰∏≠ÊúÉÈÅáÂà∞Âõ∞Èõ£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰æÜËá™ÁµêÊßãÁõ∏‰ººÁöÑÂïèÈ°åÁöÑÈ°ûÊØîÂ¶Ç‰ΩïËÉΩÊîπÂñÑ LLM Â∞ç MWP ÁöÑÂïèÈ°åËß£Ê±∫ËÉΩÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰æùË≥¥ÊñºÊì∑ÂèñËàáÁµ¶ÂÆöÂïèÈ°åÂÖ∑ÊúâÈ°û‰ººÈÅãÁÆóÂúñÂΩ¢ÁöÑÂïèÈ°åÔºå‰ΩúÁÇ∫ÊèêÁ§∫‰∏≠ÁöÑÁØÑ‰æãÔºåÁÇ∫ÁîüÊàêÊ®°ÂûãÊèê‰æõÊ≠£Á¢∫ÁöÑÊé®ÁêÜË∑ØÂæë‰ª•‰æõÂèÉËÄÉ„ÄÇÂÖ≠ÂÄãÊï∏Â≠∏ÊñáÂ≠óÈ°åÊï∏ÊìöÈõÜÁöÑÂØ¶Ë≠âÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåËàáÂü∫Á∑öÊñπÊ≥ïÁõ∏ÊØîÔºåÂπ≥ÂùáÁµïÂ∞çÂÄºÊèêÈ´ò‰∫Ü 6.7 ÂÄãÁôæÂàÜÈªû„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÂá∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Ëß£Ê±∫Áï∂Ââç LLM ‰∏≠ÁöÑÊé®ÁêÜÊåëÊà∞ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment**
2411.16442v1 by Luca Colombo, Alessandro Falcetta, Manuel Roveri

Training machine and deep learning models directly on extremely
resource-constrained devices is the next challenge in the field of tiny machine
learning. The related literature in this field is very limited, since most of
the solutions focus only on on-device inference or model adaptation through
online learning, leaving the training to be carried out on external Cloud
services. An interesting technological perspective is to exploit Federated
Learning (FL), which allows multiple devices to collaboratively train a shared
model in a distributed way. However, the main drawback of state-of-the-art FL
algorithms is that they are not suitable for running on tiny devices. For the
first time in the literature, in this paper we introduce TIFeD, a Tiny
Integer-based Federated learning algorithm with Direct Feedback Alignment (DFA)
entirely implemented by using an integer-only arithmetic and being specifically
designed to operate on devices with limited resources in terms of memory,
computation and energy. Besides the traditional full-network operating
modality, in which each device of the FL setting trains the entire neural
network on its own local data, we propose an innovative single-layer TIFeD
implementation, which enables each device to train only a portion of the neural
network model and opens the door to a new way of distributing the learning
procedure across multiple devices. The experimental results show the
feasibility and effectiveness of the proposed solution. The proposed TIFeD
algorithm, with its full-network and single-layer implementations, is made
available to the scientific community as a public repository.

ÊëòË¶ÅÔºö<paragraph>Âú®Ê•µÂ∫¶ÂèóÈôêË≥áÊ∫êÁöÑË£ùÁΩÆ‰∏äÁõ¥Êé•Ë®ìÁ∑¥Ê©üÂô®ÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÊòØÂæÆÂûãÊ©üÂô®Â≠∏ÁøíÈ†òÂüüÁöÑ‰∏ã‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÊ≠§È†òÂüüÁöÑÁõ∏ÈóúÊñáÁçªÈùûÂ∏∏ÊúâÈôêÔºåÂõ†ÁÇ∫Â§ßÂ§öÊï∏Ëß£Ê±∫ÊñπÊ°àÂÉÖÂ∞àÊ≥®ÊñºÈÄèÈÅéÁ∑ö‰∏äÂ≠∏ÁøíÈÄ≤Ë°åË£ùÁΩÆÂÖßÊé®Ë´ñÊàñÊ®°ÂûãË™øÊï¥ÔºåËÆìË®ìÁ∑¥Âú®Â§ñÈÉ®Èõ≤Á´ØÊúçÂãô‰∏äÂü∑Ë°å„ÄÇ‰∏ÄÂÄãÊúâË∂£ÁöÑÊäÄË°ìËßÄÈªûÊòØÂà©Áî®ËÅØÂêàÂ≠∏Áøí (FL)ÔºåÂÆÉÂÖÅË®±Â§öÂÄãË£ùÁΩÆ‰ª•ÂàÜÊï£ÁöÑÊñπÂºèÂçîÂêåË®ìÁ∑¥‰∏ÄÂÄãÂÖ±‰∫´Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÊúÄÂÖàÈÄ≤ÁöÑ FL ÊºîÁÆóÊ≥ïÁöÑ‰∏ªË¶ÅÁº∫ÈªûÊòØÂÆÉÂÄë‰∏çÈÅ©ÂêàÂú®ÂæÆÂûãË£ùÁΩÆ‰∏äÂü∑Ë°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÊ¨°Âú®ÊñáÁçª‰∏≠‰ªãÁ¥π TIFeDÔºå‰∏ÄÁ®ÆÂæÆÂûãÊï¥Êï∏ËÅØÂêàÂ≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÂÖ∑ÊúâÁõ¥Êé•ÂõûÈ•ãÂ∞çÈΩä (DFA)ÔºåÂÆåÂÖ®ÈÄèÈÅé‰ΩøÁî®ÂÉÖÊï¥Êï∏ÁöÑÁÆóË°ìÂØ¶‰ΩúÔºå‰∏¶Â∞àÈñÄË®≠Ë®àÁî®ÊñºÂú®Ë®òÊÜ∂È´î„ÄÅÈÅãÁÆóÂíåËÉΩÊ∫êÊñπÈù¢Ë≥áÊ∫êÊúâÈôêÁöÑË£ùÁΩÆ‰∏äÂü∑Ë°å„ÄÇÈô§‰∫ÜÂÇ≥Áµ±ÁöÑÂÖ®Á∂≤Ë∑ØÊìç‰ΩúÊ®°ÂºèÔºàÂú®ÂÖ∂‰∏≠ FL Ë®≠ÂÆöÁöÑÊØèÂÄãË£ùÁΩÆÈÉΩÂú®ÂÖ∂Ëá™Â∑±ÁöÑÊú¨Âú∞Ë≥áÊñô‰∏äË®ìÁ∑¥Êï¥ÂÄãÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºâ‰πãÂ§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂñÆÂ±§ TIFeD ÂØ¶‰ΩúÔºåÂÆÉËÆìÊØèÂÄãË£ùÁΩÆÂÉÖË®ìÁ∑¥Á•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁöÑ‰∏ÄÈÉ®ÂàÜÔºå‰∏¶ÈñãÂïü‰∫Ü‰∏ÄÂÄãÂú®Â§öÂÄãË£ùÁΩÆ‰∏äÂàÜÊ¥æÂ≠∏ÁøíÁ®ãÂ∫èÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫‰∫ÜÊâÄÊèêÂá∫Ëß£Ê±∫ÊñπÊ°àÁöÑÂèØË°åÊÄßÂíåÊúâÊïàÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑ TIFeD ÊºîÁÆóÊ≥ïÔºåÈÄ£ÂêåÂÖ∂ÂÖ®Á∂≤Ë∑ØÂíåÂñÆÂ±§ÂØ¶‰ΩúÔºåÂ∑≤‰ΩúÁÇ∫ÂÖ¨ÂÖ±ÂÑ≤Â≠òÂ∫´Êèê‰æõÁµ¶ÁßëÂ≠∏Á§æÁæ§„ÄÇ</paragraph>

##### **Finding Structure in Language Models**
2411.16433v1 by Jaap Jumelet

When we speak, write or listen, we continuously make predictions based on our
knowledge of a language's grammar. Remarkably, children acquire this
grammatical knowledge within just a few years, enabling them to understand and
generalise to novel constructions that have never been uttered before. Language
models are powerful tools that create representations of language by
incrementally predicting the next word in a sentence, and they have had a
tremendous societal impact in recent years. The central research question of
this thesis is whether these models possess a deep understanding of grammatical
structure similar to that of humans. This question lies at the intersection of
natural language processing, linguistics, and interpretability. To address it,
we will develop novel interpretability techniques that enhance our
understanding of the complex nature of large-scale language models. We approach
our research question from three directions. First, we explore the presence of
abstract linguistic information through structural priming, a key paradigm in
psycholinguistics for uncovering grammatical structure in human language
processing. Next, we examine various linguistic phenomena, such as adjective
order and negative polarity items, and connect a model's comprehension of these
phenomena to the data distribution on which it was trained. Finally, we
introduce a controlled testbed for studying hierarchical structure in language
models using various synthetic languages of increasing complexity and examine
the role of feature interactions in modelling this structure. Our findings
offer a detailed account of the grammatical knowledge embedded in language
model representations and provide several directions for investigating
fundamental linguistic questions using computational methods.

ÊëòË¶ÅÔºö<paragraph>Áï∂ÊàëÂÄëË™™Ë©±„ÄÅÂØ´‰ΩúÊàñËÅÜËÅΩÊôÇÔºåÊàëÂÄëÊúÉÊåÅÁ∫åÊ†πÊìöËá™Â∑±Â∞çË™ûË®ÄÊñáÊ≥ïÁöÑÁü•Ë≠òÂÅöÂá∫È†êÊ∏¨„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂ≠©Á´•ÂÉÖÂú®ÂπæÂπ¥ÂÖß‰æøËÉΩÁøíÂæóÈÄôÁ®ÆÊñáÊ≥ïÁü•Ë≠òÔºå‰Ωø‰ªñÂÄëËÉΩÂ§†ÁêÜËß£‰∏¶Ê¶ÇÊã¨Âá∫ÂâçÊâÄÊú™ËÅûÁöÑÊñ∞Âª∫Êßã„ÄÇË™ûË®ÄÊ®°ÂûãÊòØÂº∑Â§ßÁöÑÂ∑•ÂÖ∑ÔºåÂÆÉÈÄèÈÅéÈÄêÊ≠•È†êÊ∏¨Âè•Â≠ê‰∏≠ÁöÑ‰∏ã‰∏ÄÂÄãÂñÆÂ≠ó‰æÜÂª∫Á´ãË™ûË®ÄË°®ÂæµÔºå‰∏îÂú®ËøëÂπ¥‰æÜÂ∞çÁ§æÊúÉÁî¢Áîü‰∫ÜÂ∑®Â§ßÁöÑÂΩ±Èüø„ÄÇÊú¨Ë´ñÊñáÁöÑÊ†∏ÂøÉÁ†îÁ©∂ÂïèÈ°åÂú®ÊñºÈÄô‰∫õÊ®°ÂûãÊòØÂê¶ÂÖ∑ÂÇôËàá‰∫∫È°ûÁõ∏‰ººÁöÑÊñáÊ≥ïÁµêÊßãÊ∑±Â∫¶ÁêÜËß£„ÄÇÊ≠§ÂïèÈ°å‰ΩçÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÅË™ûË®ÄÂ≠∏ÂíåÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑ‰∫§ÊúÉÈªû„ÄÇÁÇ∫‰∫ÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂ∞áÈñãÁôºÊñ∞Á©éÁöÑÂèØËß£ÈáãÊÄßÊäÄË°ìÔºå‰ª•Â¢ûÂº∑ÊàëÂÄëÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°ÂûãË§áÈõúÊú¨Ë≥™ÁöÑÁêÜËß£„ÄÇÊàëÂÄëÂæû‰∏âÂÄãÊñπÂêëÊé¢Ë®éÊàëÂÄëÁöÑÁ†îÁ©∂ÂïèÈ°å„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÈÄèÈÅéÁµêÊßãÂïüÂãïÔºà‰∏ÄÁ®ÆÂøÉÁêÜË™ûË®ÄÂ≠∏‰∏≠Áî®ÊñºÊè≠Á§∫‰∫∫È°ûË™ûË®ÄËôïÁêÜ‰∏≠ÊñáÊ≥ïÁµêÊßãÁöÑ‰∏ªË¶ÅÁØÑ‰æãÔºâ‰æÜÊé¢Á¥¢ÊäΩË±°Ë™ûË®ÄË≥áË®äÁöÑÂ≠òÂú®„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÊ™¢È©óÂêÑÁ®ÆË™ûË®ÄÁèæË±°Ôºå‰æãÂ¶ÇÂΩ¢ÂÆπË©ûÈ†ÜÂ∫èÂíåÂê¶ÂÆöÊ•µÊÄßÈ†ÖÁõÆÔºå‰∏¶Â∞áÊ®°ÂûãÂ∞çÈÄô‰∫õÁèæË±°ÁöÑÁêÜËß£ËàáÂÖ∂ÂèóË®ìÁöÑË≥áÊñôÂàÜ‰ΩàÈÄ£ÁµêËµ∑‰æÜ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÂèóÊéßÊ∏¨Ë©¶Âè∞Ôºå‰ΩøÁî®ÂêÑÁ®ÆË§áÈõúÂ∫¶ÈÅûÂ¢ûÁöÑÂêàÊàêË™ûË®Ä‰æÜÁ†îÁ©∂Ë™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÈöéÂ±§ÁµêÊßãÔºå‰∏¶Ê™¢È©óÁâπÂæµ‰∫íÂãïÂú®Âª∫Ê®°Ê≠§ÁµêÊßã‰∏≠ÁöÑ‰ΩúÁî®„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊèê‰æõ‰∫ÜË™ûË®ÄÊ®°ÂûãË°®Âæµ‰∏≠ÂµåÂÖ•ÁöÑÊñáÊ≥ïÁü•Ë≠òÁöÑË©≥Á¥∞Ë™™ÊòéÔºå‰∏¶Êèê‰æõ‰∫Ü‰ΩøÁî®Ë®àÁÆóÊñπÊ≥ïÊé¢Ë®éÂü∫Êú¨Ë™ûË®ÄÂ≠∏ÂïèÈ°åÁöÑÂπæÂÄãÊñπÂêë„ÄÇ</paragraph>

##### **TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation**
2411.16425v1 by Linqing Zhong, Chen Gao, Zihan Ding, Yue Liao, Si Liu

The Zero-Shot Object Navigation (ZSON) task requires embodied agents to find
a previously unseen object by navigating in unfamiliar environments. Such a
goal-oriented exploration heavily relies on the ability to perceive,
understand, and reason based on the spatial information of the environment.
However, current LLM-based approaches convert visual observations to language
descriptions and reason in the linguistic space, leading to the loss of spatial
information. In this paper, we introduce TopV-Nav, a MLLM-based method that
directly reasons on the top-view map with complete spatial information. To
fully unlock the MLLM's spatial reasoning potential in top-view perspective, we
propose the Adaptive Visual Prompt Generation (AVPG) method to adaptively
construct semantically-rich top-view map. It enables the agent to directly
utilize spatial information contained in the top-view map to conduct thorough
reasoning. Besides, we design a Dynamic Map Scaling (DMS) mechanism to
dynamically zoom top-view map at preferred scales, enhancing local fine-grained
reasoning. Additionally, we devise a Target-Guided Navigation (TGN) mechanism
to predict and to utilize target locations, facilitating global and human-like
exploration. Experiments on MP3D and HM3D benchmarks demonstrate the
superiority of our TopV-Nav, e.g., $+3.9\%$ SR and $+2.0\%$ SPL absolute
improvements on HM3D.

ÊëòË¶ÅÔºöÈõ∂Èè°È†≠Áâ©‰ª∂Â∞éËà™ (ZSON) ‰ªªÂãôË¶ÅÊ±ÇÂÖ∑Ë∫´‰ª£ÁêÜÂú®‰∏çÁÜüÊÇâÁöÑÁí∞Â¢É‰∏≠Â∞éËà™Ôºå‰ª•ÊâæÂà∞ÂÖàÂâçÊú™Ë¶ãÁöÑÁâ©‰ª∂„ÄÇÈÄôÁ®Æ‰ª•ÁõÆÊ®ôÁÇ∫Â∞éÂêëÁöÑÊé¢Á¥¢Ê•µÂ∫¶‰æùË≥¥ÊÑüÁü•„ÄÅÁêÜËß£ÂíåÂü∫ÊñºÁí∞Â¢ÉÁ©∫ÈñìË≥áË®äÈÄ≤Ë°åÊé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂâçÁöÑÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÊúÉÂ∞áË¶ñË¶∫ËßÄÂØüËΩâÊèõÁÇ∫Ë™ûË®ÄÊèèËø∞Ôºå‰∏¶Âú®Ë™ûË®ÄÁ©∫Èñì‰∏≠ÈÄ≤Ë°åÊé®ÁêÜÔºåÂ∞éËá¥Á©∫ÈñìË≥áË®äÈÅ∫Â§±„ÄÇÂú®Êú¨ÁØáË´ñÊñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü TopV-NavÔºå‰∏ÄÁ®ÆÂü∫Êñº MLLM ÁöÑÊñπÊ≥ïÔºåÂÆÉÁõ¥Êé•Âú®ÂÖ∑ÊúâÂÆåÊï¥Á©∫ÈñìË≥áË®äÁöÑ‰øØË¶ñÂúñ‰∏≠ÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÁÇ∫‰∫ÜÂú®‰øØË¶ñÂúñË¶ñËßí‰∏≠ÂÖÖÂàÜÁôºÊèÆ MLLM ÁöÑÁ©∫ÈñìÊé®ÁêÜÊΩõÂäõÔºåÊàëÂÄëÊèêÂá∫‰∫ÜËá™ÈÅ©ÊáâË¶ñË¶∫ÊèêÁ§∫ÁîüÊàê (AVPG) ÊñπÊ≥ïÔºå‰ª•Ëá™ÈÅ©ÊáâÂú∞Âª∫ÊßãË™ûÊÑèË±êÂØåÁöÑ‰øØË¶ñÂúñ„ÄÇÂÆÉ‰Ωø‰ª£ÁêÜËÉΩÂ§†Áõ¥Êé•Âà©Áî®‰øØË¶ñÂúñ‰∏≠ÂåÖÂê´ÁöÑÁ©∫ÈñìË≥áË®ä‰æÜÈÄ≤Ë°åÂæπÂ∫ïÁöÑÊé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂãïÊÖãÂú∞ÂúñÁ∏ÆÊîæ (DMS) Ê©üÂà∂Ôºå‰ª•Âú®È¶ñÈÅ∏ÊØî‰æãÂ∞∫ÂãïÊÖãÁ∏ÆÊîæ‰øØË¶ñÂúñÔºåÂ¢ûÂº∑Â±ÄÈÉ®Á¥∞Á≤íÂ∫¶ÁöÑÊé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁõÆÊ®ôÂ∞éÂºïÂ∞éËà™ (TGN) Ê©üÂà∂Ôºå‰ª•È†êÊ∏¨ÂíåÂà©Áî®ÁõÆÊ®ô‰ΩçÁΩÆÔºå‰øÉÈÄ≤ÂÖ®Â±ÄÂíåÈ°û‰ºº‰∫∫È°ûÁöÑÊé¢Á¥¢„ÄÇÂú® MP3D Âíå HM3D Âü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑ TopV-Nav ÁöÑÂÑ™Ë∂äÊÄßÔºå‰æãÂ¶ÇÔºåÂú® HM3D ‰∏äÁöÑÁµïÂ∞çÊîπÈÄ≤ÁÇ∫ $+3.9\%$ SR Âíå $+2.0\%$ SPL„ÄÇ

##### **Turbofan Engine Remaining Useful Life (RUL) Prediction Based on Bi-Directional Long Short-Term Memory (BLSTM)**
2411.16422v1 by Abedin Sherifi

The aviation industry is rapidly evolving, driven by advancements in
technology. Turbofan engines used in commercial aerospace are very complex
systems. The majority of turbofan engine components are susceptible to
degradation over the life of their operation. Turbofan engine degradation has
an impact to engine performance, operability, and reliability. Predicting
accurate remaining useful life (RUL) of a commercial turbofan engine based on a
variety of complex sensor data is of paramount importance for the safety of the
passengers, safety of flight, and for cost effective operations. That is why it
is essential for turbofan engines to be monitored, controlled, and maintained.
RUL predictions can either come from model-based or data-based approaches. The
model-based approach can be very expensive due to the complexity of the
mathematical models and the deep expertise that is required in the domain of
physical systems. The data-based approach is more frequently used nowadays
thanks to the high computational complexity of computers, the advancements in
Machine Learning (ML) models, and advancements in sensors. This paper is going
to be focused on Bi-Directional Long Short-Term Memory (BLSTM) models but will
also provide a benchmark of several RUL prediction databased models. The
proposed RUL prediction models are going to be evaluated based on engine
failure prediction benchmark dataset Commercial Modular Aero-Propulsion System
Simulation (CMAPSS). The CMAPSS dataset is from NASA which contains turbofan
engine run to failure events.

ÊëòË¶ÅÔºöËà™Á©∫Áî¢Ê•≠Ê≠£Âø´ÈÄüÊºîÈÄ≤ÔºåÂÖ∂È©ÖÂãïÂäõÁÇ∫ÊäÄË°ìÈÄ≤Ê≠•„ÄÇÂïÜÁî®Ëà™Á©∫‰∏≠‰ΩøÁî®ÁöÑÊ∏¶ÊâáÁôºÂãïÊ©üÊòØÈùûÂ∏∏Ë§áÈõúÁöÑÁ≥ªÁµ±„ÄÇÊ∏¶ÊâáÁôºÂãïÊ©üÁµÑ‰ª∂ÁöÑÂ§ßÂ§öÊï∏Âú®‰ΩøÁî®Â£ΩÂëΩÊúüÈñìÂÆπÊòìÂä£Âåñ„ÄÇÊ∏¶ÊâáÁôºÂãïÊ©üÂä£ÂåñÊúÉÂΩ±ÈüøÁôºÂãïÊ©üÊïàËÉΩ„ÄÅÂèØÊìç‰ΩúÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÊ†πÊìöÂêÑÁ®ÆË§áÈõúÁöÑÊÑüÊ∏¨Âô®Ë≥áÊñôÈ†êÊ∏¨ÂïÜÁî®Ê∏¶ÊâáÁôºÂãïÊ©üÊ∫ñÁ¢∫ÁöÑÂâ©È§ò‰ΩøÁî®Â£ΩÂëΩ (RUL)ÔºåÂ∞çÊñº‰πòÂÆ¢ÂÆâÂÖ®„ÄÅÈ£õËà™ÂÆâÂÖ®ÂíåÊàêÊú¨ÊïàÁõäÁáüÈÅãËá≥ÈóúÈáçË¶Å„ÄÇÈÄô‰πüÊòØÊ∏¶ÊâáÁôºÂãïÊ©üÂøÖÈ†àÂèóÂà∞Áõ£Êéß„ÄÅÊéßÂà∂ÂíåÁ∂≠Ë≠∑ÁöÑÂéüÂõ†„ÄÇRUL È†êÊ∏¨ÂèØ‰ª•‰æÜËá™Âü∫ÊñºÊ®°ÂûãÊàñÂü∫ÊñºË≥áÊñôÁöÑÊñπÊ≥ï„ÄÇÂü∫ÊñºÊ®°ÂûãÁöÑÊñπÊ≥ïÁî±ÊñºÊï∏Â≠∏Ê®°ÂûãÁöÑË§áÈõúÊÄßÂíåÂú®Áâ©ÁêÜÁ≥ªÁµ±È†òÂüüÊâÄÈúÄÁöÑÊ∑±ÂéöÂ∞àÊ•≠Áü•Ë≠òÔºåÂèØËÉΩÈùûÂ∏∏ÊòÇË≤¥„ÄÇÂü∫ÊñºË≥áÊñôÁöÑÊñπÊ≥ïÁî±ÊñºÈõªËÖ¶ÁöÑÈ´òÈÅãÁÆóË§áÈõúÊÄß„ÄÅÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÁöÑÈÄ≤Ê≠•ÂíåÊÑüÊ∏¨Âô®ÁöÑÈÄ≤Ê≠•ÔºåÁèæ‰ªä‰ΩøÁî®ÂæóÊõ¥È†ªÁπÅ„ÄÇÊú¨ÊñáÂ∞áÈáçÈªûÊîæÂú®ÈõôÂêëÈï∑Áü≠ÊúüË®òÊÜ∂ (BLSTM) Ê®°ÂûãÔºå‰ΩÜ‰πüÊúÉÊèê‰æõÂ§öÂÄã RUL È†êÊ∏¨Ë≥áÊñôÂ∫´Ê®°ÂûãÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÊâÄÊèêÂá∫ÁöÑ RUL È†êÊ∏¨Ê®°ÂûãÂ∞áÊ†πÊìöÂºïÊìéÊïÖÈöúÈ†êÊ∏¨Âü∫Ê∫ñË≥áÊñôÈõÜÂïÜÊ•≠Ê®°ÁµÑËà™Á©∫Êé®ÈÄ≤Á≥ªÁµ±Ê®°Êì¨ (CMAPSS) ÈÄ≤Ë°åË©ï‰º∞„ÄÇCMAPSS Ë≥áÊñôÈõÜ‰æÜËá™ NASAÔºåÂÖ∂‰∏≠ÂåÖÂê´Ê∏¶ÊâáÁôºÂãïÊ©üÈÅãË°åËá≥ÊïÖÈöúÁöÑ‰∫ã‰ª∂„ÄÇ

##### **A Study on Unsupervised Domain Adaptation for Semantic Segmentation in the Era of Vision-Language Models**
2411.16407v1 by Manuel Schwonberg, Claus Werner, Hanno Gottschalk, Carsten Meyer

Despite the recent progress in deep learning based computer vision, domain
shifts are still one of the major challenges. Semantic segmentation for
autonomous driving faces a wide range of domain shifts, e.g. caused by changing
weather conditions, new geolocations and the frequent use of synthetic data in
model training. Unsupervised domain adaptation (UDA) methods have emerged which
adapt a model to a new target domain by only using unlabeled data of that
domain. The variety of UDA methods is large but all of them use ImageNet
pre-trained models. Recently, vision-language models have demonstrated strong
generalization capabilities which may facilitate domain adaptation. We show
that simply replacing the encoder of existing UDA methods like DACS by a
vision-language pre-trained encoder can result in significant performance
improvements of up to 10.0% mIoU on the GTA5-to-Cityscapes domain shift. For
the generalization performance to unseen domains, the newly employed
vision-language pre-trained encoder provides a gain of up to 13.7% mIoU across
three unseen datasets. However, we find that not all UDA methods can be easily
paired with the new encoder and that the UDA performance does not always
likewise transfer into generalization performance. Finally, we perform our
experiments on an adverse weather condition domain shift to further verify our
findings on a pure real-to-real domain shift.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê∑±Â∫¶Â≠∏ÁøíÂü∫Á§éÈõªËÖ¶Ë¶ñË¶∫ÊúâËøëÊúüÁöÑÈÄ≤Â±ïÔºåÈ†òÂüüËΩâÊèõ‰ªçÁÑ∂ÊòØ‰∏ªË¶ÅÊåëÊà∞‰πã‰∏Ä„ÄÇ
ÈáùÂ∞çËá™ÈßïËªäÁöÑË™ûÊÑèÂàÜÂâ≤Èù¢Ëá®Âª£Ê≥õÁöÑÈ†òÂüüËΩâÊèõÔºå‰æãÂ¶ÇÂõ†Â§©Ê∞£ÁãÄÊ≥ÅÊîπËÆä„ÄÅÊñ∞ÁöÑÂú∞ÁêÜ‰ΩçÁΩÆÂíåÊ®°ÂûãË®ìÁ∑¥‰∏≠È†ªÁπÅ‰ΩøÁî®ÂêàÊàêË≥áÊñôËÄåÈÄ†Êàê„ÄÇ
ÁÑ°Áõ£Áù£È†òÂüüÈÅ©Êáâ (UDA) ÊñπÊ≥ïÊáâÈÅãËÄåÁîüÔºåÈÄèÈÅéÂÉÖ‰ΩøÁî®Ë©≤È†òÂüüÁöÑÊú™Ê®ôÁ±§Ë≥áÊñôÂ∞áÊ®°ÂûãÈÅ©ÊáâÂà∞Êñ∞ÁöÑÁõÆÊ®ôÈ†òÂüü„ÄÇ
UDA ÊñπÊ≥ïÁ®ÆÈ°ûÁπÅÂ§öÔºå‰ΩÜÈÉΩ‰ΩøÁî® ImageNet È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°Âûã„ÄÇ
ËøëÊúüÔºåË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÂ∑≤Â±ïÁèæÂº∑Â§ßÁöÑÊ¶ÇÂåñËÉΩÂäõÔºåÈÄôÂèØËÉΩÊúâÂä©ÊñºÈ†òÂüüÈÅ©Êáâ„ÄÇ
ÊàëÂÄëÈ°ØÁ§∫ÔºåÂÉÖÈÄèÈÅéÂ∞á DACS Á≠âÁèæÊúâ UDA ÊñπÊ≥ïÁöÑÁ∑®Á¢ºÂô®ÊõøÊèõÁÇ∫Ë¶ñË¶∫Ë™ûË®ÄÈ†êÂÖàË®ìÁ∑¥ÁöÑÁ∑®Á¢ºÂô®ÔºåÂ∞±ËÉΩÈ°ØËëóÊèêÂçáÊïàËÉΩÔºåÂú® GTA5 Âà∞ Cityscapes È†òÂüüËΩâÊèõ‰∏≠ÊèêÂçáÈÅî 10.0% mIoU„ÄÇ
Â∞çÊñºÊú™Ë¶ãÈ†òÂüüÁöÑÊ¶ÇÂåñÊïàËÉΩÔºåÊñ∞Êé°Áî®ÁöÑË¶ñË¶∫Ë™ûË®ÄÈ†êÂÖàË®ìÁ∑¥ÁöÑÁ∑®Á¢ºÂô®Âú®‰∏âÂÄãÊú™Ë¶ãË≥áÊñôÈõÜ‰∏äÊèê‰æõ‰∫ÜÈ´òÈÅî 13.7% mIoU ÁöÑÂ¢ûÁõä„ÄÇ
ÁÑ∂ËÄåÔºåÊàëÂÄëÁôºÁèæ‰∏¶ÈùûÊâÄÊúâ UDA ÊñπÊ≥ïÈÉΩËÉΩËºïÊòìËàáÊñ∞Á∑®Á¢ºÂô®ÈÖçÂ∞çÔºåËÄå‰∏î UDA ÊïàËÉΩ‰∏¶ÈùûÁ∏ΩÊòØÂêåÊ®£ËΩâÁßªÂà∞Ê¶ÇÂåñÊïàËÉΩ„ÄÇ
ÊúÄÂæåÔºåÊàëÂÄëÂú®ÊÉ°Âä£Â§©Ê∞£Ê¢ù‰ª∂È†òÂüüËΩâÊèõ‰∏äÂü∑Ë°åÂØ¶È©óÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•È©óË≠âÊàëÂÄëÂú®Á¥îÁ≤πÁúüÂØ¶Âà∞ÁúüÂØ¶È†òÂüüËΩâÊèõ‰∏äÁöÑÁôºÁèæ„ÄÇ

##### **Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN**
2411.16405v1 by Elona Shatri, Kalikidhar Palavala, George Fazekas

The generation of handwritten music sheets is a crucial step toward enhancing
Optical Music Recognition (OMR) systems, which rely on large and diverse
datasets for optimal performance. However, handwritten music sheets, often
found in archives, present challenges for digitisation due to their fragility,
varied handwriting styles, and image quality. This paper addresses the data
scarcity problem by applying Generative Adversarial Networks (GANs) to
synthesise realistic handwritten music sheets. We provide a comprehensive
evaluation of three GAN models - DCGAN, ProGAN, and CycleWGAN - comparing their
ability to generate diverse and high-quality handwritten music images. The
proposed CycleWGAN model, which enhances style transfer and training stability,
significantly outperforms DCGAN and ProGAN in both qualitative and quantitative
evaluations. CycleWGAN achieves superior performance, with an FID score of
41.87, an IS of 2.29, and a KID of 0.05, making it a promising solution for
improving OMR systems.

ÊëòË¶ÅÔºöÊâãÂØ´Ê®ÇË≠úÁöÑÁîüÊàêÊòØÊèêÂçáÂÖâÂ≠∏Èü≥Ê®ÇËæ®Ë≠ò (OMR) Á≥ªÁµ±ÁöÑÈóúÈçµÊ≠•È©üÔºåËÄå OMR Á≥ªÁµ±‰ª∞Ë≥¥ÈæêÂ§ß‰∏îÂ§öÂÖÉÁöÑË≥áÊñôÈõÜÊâçËÉΩÁôºÊèÆÊúÄ‰Ω≥ÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÊâãÂØ´Ê®ÇË≠úÈÄöÂ∏∏Â≠òÊîæÂú®Ê™îÊ°àÈ§®‰∏≠ÔºåÁî±ÊñºÂÖ∂ËÑÜÂº±ÊÄß„ÄÅÊõ∏ÂØ´È¢®Ê†ºÂ§öËÆäÔºå‰ª•ÂèäÂΩ±ÂÉèÂìÅË≥™‰∏ç‰Ω≥ÔºåÂõ†Ê≠§Âú®Êï∏‰ΩçÂåñÈÅéÁ®ã‰∏≠ÊúÉÈù¢Ëá®ÊåëÊà∞„ÄÇÊú¨ÊñáÈÄèÈÅéÊáâÁî®ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN) ‰æÜÂêàÊàêÈÄºÁúüÁöÑÊâãÂØ´Ê®ÇË≠úÔºå‰ª•Ëß£Ê±∫Ë≥áÊñôÁ®ÄÂ∞ëÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÊèê‰æõ‰∏âÁ®Æ GAN Ê®°ÂûãÁöÑÂÖ®Èù¢Ë©ï‰º∞ÔºåÂåÖÊã¨ DCGAN„ÄÅProGAN Âíå CycleWGANÔºå‰∏¶ÊØîËºÉÂÆÉÂÄëÁîüÊàêÂ§öÊ®£Âåñ‰∏îÈ´òÂìÅË≥™ÊâãÂØ´Ê®ÇË≠úÂΩ±ÂÉèÁöÑËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑ CycleWGAN Ê®°ÂûãÂ¢ûÂº∑‰∫ÜÊ®£ÂºèËΩâÁßªÂíåË®ìÁ∑¥Á©©ÂÆöÊÄßÔºåÂú®ÂÆöÊÄßÂíåÂÆöÈáèË©ï‰º∞‰∏≠ÈÉΩÊòéÈ°ØÂÑ™Êñº DCGAN Âíå ProGAN„ÄÇCycleWGAN ÈÅîÂà∞ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåFID ÂàÜÊï∏ÁÇ∫ 41.87ÔºåIS ÁÇ∫ 2.29ÔºåKID ÁÇ∫ 0.05Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫ÊîπÂñÑ OMR Á≥ªÁµ±ÁöÑÊΩõÂú®Ëß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**
2411.16403v1 by Alexander Fichtl, Juraj Vladika, Georg Groh

Knowledge-enhanced language models (KELMs) have emerged as promising tools to
bridge the gap between large-scale language models and domain-specific
knowledge. KELMs can achieve higher factual accuracy and mitigate
hallucinations by leveraging knowledge graphs (KGs). They are frequently
combined with adapter modules to reduce the computational load and risk of
catastrophic forgetting. In this paper, we conduct a systematic literature
review (SLR) on adapter-based approaches to KELMs. We provide a structured
overview of existing methodologies in the field through quantitative and
qualitative analysis and explore the strengths and potential shortcomings of
individual approaches. We show that general knowledge and domain-specific
approaches have been frequently explored along with various adapter
architectures and downstream tasks. We particularly focused on the popular
biomedical domain, where we provided an insightful performance comparison of
existing KELMs. We outline the main trends and propose promising future
directions.

ÊëòË¶ÅÔºöÁü•Ë≠òÂ¢ûÂº∑Ë™ûË®ÄÊ®°ÂûãÔºàKELMÔºâÂ∑≤ÊàêÁÇ∫ÂΩåÂêàÂ§ßË¶èÊ®°Ë™ûË®ÄÊ®°ÂûãËàáÁâπÂÆöÈ†òÂüüÁü•Ë≠òÂ∑ÆË∑ùÁöÑÊúâÂâçÈÄîÁöÑÂ∑•ÂÖ∑„ÄÇKELM ÂèØ‰ª•ÈÄèÈÅéÂà©Áî®Áü•Ë≠òÂúñË≠úÔºàKGÔºâ‰æÜÊèêÈ´ò‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄß‰∏¶Ê∏õÂ∞ëÂπªË¶∫„ÄÇÂÆÉÂÄëÁ∂ìÂ∏∏ËàáÈÅ©ÈÖçÂô®Ê®°ÁµÑÁµêÂêà‰ΩøÁî®Ôºå‰ª•Èôç‰ΩéÈÅãÁÆóË≤†ËºâÂíåÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÁöÑÈ¢®Èö™„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞çÂü∫ÊñºÈÅ©ÈÖçÂô®ÁöÑ KELM ÊñπÊ≥ïÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁöÑÊñáÁçªÂõûÈ°ßÔºàSLRÔºâ„ÄÇÊàëÂÄëÈÄèÈÅéÂÆöÈáèÂíåÂÆöÊÄßÂàÜÊûêÊèê‰æõË©≤È†òÂüüÊó¢ÊúâÊñπÊ≥ïË´ñÁöÑÁµêÊßãÂåñÊ¶ÇËßÄÔºå‰∏¶Êé¢Ë®éÂÄãÂà•ÊñπÊ≥ïÁöÑÂÑ™ÈªûÂíåÊΩõÂú®Áº∫Èªû„ÄÇÊàëÂÄëË°®ÊòéÔºå‰∏ÄËà¨Áü•Ë≠òÂíåÁâπÂÆöÈ†òÂüüÁöÑÊñπÊ≥ïÂ∑≤ËàáÂêÑÁ®ÆÈÅ©ÈÖçÂô®Êû∂ÊßãÂíå‰∏ãÊ∏∏‰ªªÂãô‰∏ÄËµ∑Ë¢´È†ªÁπÅÊé¢Á¥¢„ÄÇÊàëÂÄëÁâπÂà•ÈóúÊ≥®ÁÜ±ÈñÄÁöÑÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÔºåÂú®Ë©≤È†òÂüü‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÁèæÊúâ KELM ÁöÑÊúâË¶ãÂú∞ÊïàËÉΩÊØîËºÉ„ÄÇÊàëÂÄëÊ¶ÇËø∞‰∫Ü‰∏ªË¶ÅË∂®Âã¢Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊúâÂâçÈÄîÁöÑÊú™‰æÜÊñπÂêë„ÄÇ

##### **Human-Calibrated Automated Testing and Validation of Generative Language Models**
2411.16391v1 by Agus Sudjianto, Aijun Zhang, Srinivas Neppalli, Tarun Joshi, Michal Malohlava

This paper introduces a comprehensive framework for the evaluation and
validation of generative language models (GLMs), with a focus on
Retrieval-Augmented Generation (RAG) systems deployed in high-stakes domains
such as banking. GLM evaluation is challenging due to open-ended outputs and
subjective quality assessments. Leveraging the structured nature of RAG
systems, where generated responses are grounded in a predefined document
collection, we propose the Human-Calibrated Automated Testing (HCAT) framework.
HCAT integrates a) automated test generation using stratified sampling, b)
embedding-based metrics for explainable assessment of functionality, risk and
safety attributes, and c) a two-stage calibration approach that aligns
machine-generated evaluations with human judgments through probability
calibration and conformal prediction.
  In addition, the framework includes robustness testing to evaluate model
performance against adversarial, out-of-distribution, and varied input
conditions, as well as targeted weakness identification using marginal and
bivariate analysis to pinpoint specific areas for improvement. This
human-calibrated, multi-layered evaluation framework offers a scalable,
transparent, and interpretable approach to GLM assessment, providing a
practical and reliable solution for deploying GLMs in applications where
accuracy, transparency, and regulatory compliance are paramount.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÊû∂ÊßãÔºåÁî®ÊñºË©ï‰º∞ÂíåÈ©óË≠âÁîüÊàêË™ûË®ÄÊ®°Âûã (GLM)ÔºåÈáçÈªûÂú®ÊñºÈÉ®ÁΩ≤Âú®È´òÈ¢®Èö™È†òÂüüÔºà‰æãÂ¶ÇÈäÄË°åÊ•≠ÔºâÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±„ÄÇÁî±ÊñºËº∏Âá∫ÈñãÊîæÂºè‰∏îÂìÅË≥™Ë©ï‰º∞‰∏ªËßÄÔºåÂõ†Ê≠§ GLM Ë©ï‰º∞ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÂà©Áî® RAG Á≥ªÁµ±ÁöÑÁµêÊßãÂåñÁâπÊÄßÔºåÂÖ∂‰∏≠ÁîüÊàêÁöÑÂõûÊáâÂª∫Á´ãÂú®È†êÂÖàÂÆöÁæ©ÁöÑÊñá‰ª∂ÈõÜÂêà‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∫∫Ê©üÊ†°Ê∫ñËá™ÂãïÂåñÊ∏¨Ë©¶ (HCAT) Êû∂Êßã„ÄÇHCAT Êï¥Âêà‰∫Ü a) ‰ΩøÁî®ÂàÜÂ±§ÊäΩÊ®£ÈÄ≤Ë°åËá™ÂãïÂåñÊ∏¨Ë©¶Áî¢ÁîüÔºåb) Âü∫ÊñºÂµåÂÖ•ÁöÑÊåáÊ®ôÔºåÁî®ÊñºÂ∞çÂäüËÉΩ„ÄÅÈ¢®Èö™ÂíåÂÆâÂÖ®ÊÄßÂ±¨ÊÄßÈÄ≤Ë°åÂèØËß£ÈáãÁöÑË©ï‰º∞Ôºå‰ª•Âèä c) ‰∏ÄÂÄãÂÖ©ÈöéÊÆµÊ†°Ê∫ñÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÈÄèÈÅéÊ©üÁéáÊ†°Ê∫ñÂíåÂÖ±ÂΩ¢È†êÊ∏¨ÔºåÂ∞áÊ©üÂô®Áî¢ÁîüÁöÑË©ï‰º∞Ëàá‰∫∫È°ûÂà§Êñ∑Áõ∏Á¨¶„ÄÇÊ≠§Â§ñÔºåË©≤Êû∂ÊßãÂåÖÊã¨Á©©ÂÅ•ÊÄßÊ∏¨Ë©¶ÔºåÁî®ÊñºË©ï‰º∞Ê®°ÂûãÈáùÂ∞çÂ∞çÊäóÊÄß„ÄÅÂàÜÂ∏ÉÂ§ñÂíåËÆäÁï∞Ëº∏ÂÖ•Ê¢ù‰ª∂ÁöÑÊïàËÉΩÔºå‰ª•Âèä‰ΩøÁî®ÈÇäÈöõÂíå‰∫åËÆäÈáèÂàÜÊûê‰æÜÊâæÂá∫ÁâπÂÆöÊîπÈÄ≤È†òÂüüÁöÑÁõÆÊ®ôÂº±ÈªûË≠òÂà•„ÄÇÈÄôÂÄã‰∫∫Ê©üÊ†°Ê∫ñ„ÄÅÂ§öÂ±§Ë©ï‰º∞Êû∂ÊßãÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ„ÄÅÈÄèÊòé‰∏îÂèØËß£ÈáãÁöÑÊñπÊ≥ï‰æÜÈÄ≤Ë°å GLM Ë©ï‰º∞ÔºåÁÇ∫Âú®Ê∫ñÁ¢∫ÊÄß„ÄÅÈÄèÊòéÊÄßÂíåÊ≥ïË¶èÈÅµÂæ™Ëá≥‰∏äÁöÑÊáâÁî®Á®ãÂºè‰∏≠ÈÉ®ÁΩ≤ GLM Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂØ¶Áî®‰∏îÂèØÈù†ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **FineWeb-zhtw: Scalable Curation of Traditional Chinese Text Data from the Web**
2411.16387v1 by Cheng-Wei Lin, Wan-Hsuan Hsieh, Kai-Xin Guan, Chan-Jan Hsu, Chia-Chen Kuo, Chuan-Lin Lai, Chung-Wei Chung, Ming-Jen Wang, Da-Shan Shiu

The quality and size of a pretraining dataset significantly influence the
performance of large language models (LLMs). While there have been numerous
efforts in the curation of such a dataset for English users, there is a
relative lack of similar initiatives for Traditional Chinese. Building upon
this foundation of FineWeb, we introduce FineWeb-zhtw, a dataset tailored
specifically for Traditional Chinese users. We came up with multiple stages of
meticulously designed filters to cater to the linguistic difference between
English and Traditional Chinese, to ensure comprehensiveness and quality. We
determined effectiveness from querying dataset samples with three main
objectives. Our code and datasets are publicly available.

ÊëòË¶ÅÔºöÈ†êË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑÂìÅË≥™ÂíåË¶èÊ®°ÊúÉÈ°ØËëóÂΩ±ÈüøÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊïàËÉΩ„ÄÇÈõñÁÑ∂Â∑≤Á∂ìÊúâË®±Â§öÈáùÂ∞çËã±Ë™û‰ΩøÁî®ËÄÖÁöÑÊ≠§È°ûË≥áÊñôÈõÜÁ≠ñÂ±ïÂ∑•‰ΩúÔºå‰ΩÜÈáùÂ∞çÁπÅÈ´î‰∏≠ÊñáÁöÑÈ°û‰ººË®àÁï´ÂçªÁõ∏Â∞çÁº∫‰πè„ÄÇÂú® FineWeb ÁöÑÂü∫Á§é‰∏äÔºåÊàëÂÄëÊé®Âá∫‰∫Ü FineWeb-zhtwÔºåÈÄôÊòØ‰∏ÄÂÄãÂ∞àÁÇ∫ÁπÅÈ´î‰∏≠Êñá‰ΩøÁî®ËÄÖÈáèË∫´ÊâìÈÄ†ÁöÑË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂ§öÂÄãÈöéÊÆµÁöÑÁ≤æÁ¥∞Ë®≠Ë®àÈÅéÊøæÂô®Ôºå‰ª•ÊáâÂ∞çËã±Ë™ûÂíåÁπÅÈ´î‰∏≠Êñá‰πãÈñìÁöÑË™ûË®ÄÂ∑ÆÁï∞Ôºå‰ª•Á¢∫‰øùË≥áÊñôÁöÑÂÖ®Èù¢ÊÄßÂíåÂìÅË≥™„ÄÇÊàëÂÄëÈÄèÈÅé‰ª•‰∏âÂÄã‰∏ªË¶ÅÁõÆÊ®ôÊü•Ë©¢Ë≥áÊñôÈõÜÊ®£Êú¨‰æÜÁ¢∫ÂÆöÂÖ∂ÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**
2411.16380v1 by Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li

Ultrasound imaging is widely used in clinical diagnosis due to its
non-invasive nature and real-time capabilities. However, conventional
ultrasound diagnostics face several limitations, including high dependence on
physician expertise and suboptimal image quality, which complicates
interpretation and increases the likelihood of diagnostic errors. Artificial
intelligence (AI) has emerged as a promising solution to enhance clinical
diagnosis, particularly in detecting abnormalities across various biomedical
imaging modalities. Nonetheless, current AI models for ultrasound imaging face
critical challenges. First, these models often require large volumes of labeled
medical data, raising concerns over patient privacy breaches. Second, most
existing models are task-specific, which restricts their broader clinical
utility. To overcome these challenges, we present UltraFedFM, an innovative
privacy-preserving ultrasound foundation model. UltraFedFM is collaboratively
pre-trained using federated learning across 16 distributed medical institutions
in 9 countries, leveraging a dataset of over 1 million ultrasound images
covering 19 organs and 10 ultrasound modalities. This extensive and diverse
data, combined with a secure training framework, enables UltraFedFM to exhibit
strong generalization and diagnostic capabilities. It achieves an average area
under the receiver operating characteristic curve of 0.927 for disease
diagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.
Notably, UltraFedFM surpasses the diagnostic accuracy of mid-level
ultrasonographers and matches the performance of expert-level sonographers in
the joint diagnosis of 8 common systemic diseases. These findings indicate that
UltraFedFM can significantly enhance clinical diagnostics while safeguarding
patient privacy, marking an advancement in AI-driven ultrasound imaging for
future clinical applications.

ÊëòË¶ÅÔºöË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂõ†ÂÖ∂Èùû‰æµÂÖ•ÊÄßËàáÂç≥ÊôÇÊÄßÂª£Ê≥õÊáâÁî®ÊñºËá®Â∫äË®∫Êñ∑„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±Ë∂ÖÈü≥Ê≥¢Ë®∫Êñ∑Èù¢Ëá®Êï∏È†ÖÈôêÂà∂ÔºåÂåÖÊã¨È´òÂ∫¶‰æùË≥¥ÈÜ´Â∏´Â∞àÊ•≠Áü•Ë≠òÂíåÊ¨°‰Ω≥ÂΩ±ÂÉèÂìÅË≥™ÔºåÈÄô‰ΩøÂæóÂΩ±ÂÉèÂà§ËÆÄÊõ¥ÁÇ∫Ë§áÈõúÔºå‰∏¶Â¢ûÂä†Ë®∫Êñ∑ÈåØË™§ÁöÑÂèØËÉΩÊÄß„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) Â∑≤ÊàêÁÇ∫Â¢ûÂº∑Ëá®Â∫äË®∫Êñ∑ÁöÑÊΩõÂú®Ëß£Ê±∫ÊñπÊ°àÔºåÁâπÂà•ÊòØÂú®ÂÅµÊ∏¨ÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏ÂΩ±ÂÉèÊ®°Âºè‰∏≠ÁöÑÁï∞Â∏∏„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁõÆÂâçÁî®ÊñºË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑ AI Ê®°ÂûãÈù¢Ëá®Âö¥Â≥ªÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®ôÁ±§ÈÜ´Â≠∏Ë≥áÊñôÔºåÈÄôÂºïÁôº‰∫ÜÂ∞çÁóÖÊÇ£Èö±ÁßÅÈÅ≠‰æµÁäØÁöÑÁñëÊÖÆ„ÄÇÂÖ∂Ê¨°ÔºåÁèæÊúâÁöÑÂ§ßÈÉ®ÂàÜÊ®°ÂûãÈÉΩÊòØÈáùÂ∞çÁâπÂÆö‰ªªÂãôËÄåË®≠Ë®àÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Êõ¥Âª£Ê≥õÁöÑËá®Â∫äÊáâÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü UltraFedFMÔºå‰∏ÄÂÄãÂâµÊñ∞ÁöÑÈö±ÁßÅ‰øùË≠∑Ë∂ÖÈü≥Ê≥¢Âü∫Á§éÊ®°Âûã„ÄÇUltraFedFM ÈÄèÈÅé 9 ÂÄãÂúãÂÆ∂/Âú∞ÂçÄÁöÑ 16 ÂÄãÂàÜÊï£ÂºèÈÜ´ÁôÇÊ©üÊßãÁöÑËÅØÂêàÂ≠∏ÁøíÈÄ≤Ë°åÂçî‰ΩúÈ†êË®ìÁ∑¥ÔºåÂà©Áî®ÂåÖÂê´Ë∂ÖÈÅé 100 Ëê¨ÂºµË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑË≥áÊñôÈõÜÔºåÊ∂µËìã 19 ÂÄãÂô®ÂÆòÂíå 10 Á®ÆË∂ÖÈü≥Ê≥¢Ê®°Âºè„ÄÇÈÄô‰∫õÂª£Ê≥õ‰∏îÂ§öÊ®£ÂåñÁöÑË≥áÊñôÔºåÁµêÂêàÂÆâÂÖ®ÁöÑË®ìÁ∑¥Êû∂ÊßãÔºå‰Ωø UltraFedFM ËÉΩÂ§†Â±ïÁèæÂº∑Â§ßÁöÑÊ¶ÇÂåñÂíåË®∫Êñ∑ËÉΩÂäõ„ÄÇÂú®ÁñæÁóÖË®∫Êñ∑ÊñπÈù¢ÔºåÂÖ∂ÂèóË©¶ËÄÖÂ∑•‰ΩúÁâπÂæµÊõ≤Á∑ö‰∏ãÁöÑÂπ≥ÂùáÈù¢Á©çÈÅîÂà∞ 0.927ÔºåÂú®ÁóÖÁÅ∂ÂàÜÂâ≤ÊñπÈù¢ÔºåÂÖ∂ Dice Áõ∏‰ºº‰øÇÊï∏ÁÇ∫ 0.878„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåUltraFedFM Ë∂ÖË∂ä‰∫Ü‰∏≠ÈöéË∂ÖÈü≥Ê≥¢Ê™¢Êü•Âì°ÁöÑË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÔºå‰∏¶Âú® 8 Á®ÆÂ∏∏Ë¶ãÂÖ®Ë∫´ÊÄßÁñæÁóÖÁöÑËÅØÂêàË®∫Êñ∑‰∏≠ÈÅîÂà∞Â∞àÂÆ∂Á¥öË∂ÖÈü≥Ê≥¢Ê™¢Êü•Âì°ÁöÑÊ∞¥Ê∫ñ„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåUltraFedFM ÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ëá®Â∫äË®∫Êñ∑ÔºåÂêåÊôÇ‰øùË≠∑ÁóÖÊÇ£Èö±ÁßÅÔºåÈÄôÊ®ôË™åËëó AI È©ÖÂãïË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂú®Êú™‰æÜËá®Â∫äÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÈÄ≤Ê≠•„ÄÇ

##### **A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation**
2411.16370v1 by M. M. A. Valiuddin, R. J. G. van Sloun, C. G. A. Viviers, P. H. N. de With, F. van der Sommen

Advancements in image segmentation play an integral role within the greater
scope of Deep Learning-based computer vision. Furthermore, their widespread
applicability in critical real-world tasks has given rise to challenges related
to the reliability of such algorithms. Hence, uncertainty quantification has
been extensively studied within this context, enabling expression of model
ignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to
prevent uninformed decision making. Due to the rapid adoption of Convolutional
Neural Network (CNN)-based segmentation models in high-stake applications, a
substantial body of research has been published on this very topic, causing its
swift expansion into a distinct field. This work provides a comprehensive
overview of probabilistic segmentation by discussing fundamental concepts in
uncertainty that govern advancements in the field as well as the application to
various tasks. We identify that quantifying aleatoric and epistemic uncertainty
approximates Bayesian inference w.r.t. to either latent variables or model
parameters, respectively. Moreover, literature on both uncertainties trace back
to four key applications; (1) to quantify statistical inconsistencies in the
annotation process due ambiguous images, (2) correlating prediction error with
uncertainty, (3) expanding the model hypothesis space for better
generalization, and (4) active learning. Then, a discussion follows that
includes an overview of utilized datasets for each of the applications and
comparison of the available methods. We also highlight challenges related to
architectures, uncertainty-based active learning, standardization and
benchmarking, and recommendations for future work such as methods based on
single forward passes and models that appropriately leverage volumetric data.

ÊëòË¶ÅÔºöÂΩ±ÂÉèÂàÜÂâ≤ÁöÑÈÄ≤Â±ïÂú®Ê∑±Â∫¶Â≠∏ÁøíÁÇ∫Âü∫Á§éÁöÑÈõªËÖ¶Ë¶ñË¶∫‰∏≠ÊâÆÊºîËëó‰∏çÂèØÊàñÁº∫ÁöÑËßíËâ≤„ÄÇÊ≠§Â§ñÔºåÂÆÉÂÄëÂú®ÈóúÈçµÁèæÂØ¶‰∏ñÁïå‰ªªÂãô‰∏≠Âª£Ê≥õÁöÑÈÅ©Áî®ÊÄßÔºå‰πüÂ∏∂‰æÜ‰∫ÜËàáÊ≠§È°ûÊºîÁÆóÊ≥ïÂèØÈù†ÊÄßÁõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂõ†Ê≠§Ôºå‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÂ∑≤Âú®ÈÄôÂÄãËÑàÁµ°‰∏≠Âª£Ê≥õÂú∞Á†îÁ©∂ÔºåËÆìÊ®°ÂûãÁÑ°Áü•ÔºàË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßÔºâÊàñË≥áÊñôÊ®°Á≥äÊÄßÔºàÈö®Ê©ü‰∏çÁ¢∫ÂÆöÊÄßÔºâÂæó‰ª•Ë°®ÈÅîÔºå‰ª•Èò≤Ê≠¢Êú™Á∂ìÂëäÁü•ÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁî±ÊñºÂü∫ÊñºÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÁöÑÂàÜÂâ≤Ê®°ÂûãÂú®È´òÈ¢®Èö™ÊáâÁî®‰∏≠Âø´ÈÄüÊé°Áî®ÔºåÂ§ßÈáèÁöÑÁ†îÁ©∂Â∑≤ÁôºË°®ÊñºÈÄôÂÄã‰∏ªÈ°å‰∏äÔºåÂ∞éËá¥ÂÖ∂ËøÖÈÄüÊì¥Â±ïÊàê‰∏ÄÂÄã‰∏çÂêåÁöÑÈ†òÂüü„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÈÄèÈÅéË®éË´ñ‰∏çÁ¢∫ÂÆöÊÄßÁöÑÂü∫Êú¨Ê¶ÇÂøµÔºå‰ª•ÂèäÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁöÑÊáâÁî®ÔºåÊèê‰æõ‰∫ÜÊ©üÁéáÂàÜÂâ≤ÁöÑÂÖ®Èù¢Ê¶ÇËßÄÔºåÈÄô‰∫õÊ¶ÇÂøµÊîØÈÖç‰∫ÜË©≤È†òÂüüÁöÑÈÄ≤Â±ï„ÄÇÊàëÂÄëÁôºÁèæÈáèÂåñÈö®Ê©üÂíåË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßËøë‰ººÊñºË≤ùÊ∞èÊé®Ë´ñÔºåÂàÜÂà•ÈáùÂ∞çÊΩõÂú®ËÆäÊï∏ÊàñÊ®°ÂûãÂèÉÊï∏„ÄÇÊ≠§Â§ñÔºåÈóúÊñºÈÄôÂÖ©Á®Æ‰∏çÁ¢∫ÂÆöÊÄßÁöÑÊñáÁçªÂèØËøΩÊ∫ØÂà∞ÂõõÂÄãÈóúÈçµÊáâÁî®Ôºö(1) ÈáèÂåñÊ®ôË®ªÈÅéÁ®ã‰∏≠Áî±ÊñºÊ®°Á≥äÂΩ±ÂÉèËÄåÁî¢ÁîüÁöÑÁµ±Ë®à‰∏ç‰∏ÄËá¥ÊÄßÔºå(2) Â∞áÈ†êÊ∏¨Ë™§Â∑ÆËàá‰∏çÁ¢∫ÂÆöÊÄßÁõ∏ÈóúËÅØÔºå(3) Êì¥Â±ïÊ®°ÂûãÂÅáË®≠Á©∫Èñì‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑÊ¶ÇÊã¨ÂåñÔºå‰ª•Âèä (4) ‰∏ªÂãïÂ≠∏Áøí„ÄÇÊé•ËëóÔºåË®éË´ñÂåÖÊã¨Â∞çÊØèÂÄãÊáâÁî®ÊâÄ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜÁöÑÊ¶ÇËßÄÔºå‰ª•ÂèäÂèØÁî®ÊñπÊ≥ïÁöÑÊØîËºÉ„ÄÇÊàëÂÄë‰πüÂº∑Ë™øËàáÊû∂Êßã„ÄÅÂü∫Êñº‰∏çÁ¢∫ÂÆöÊÄßÁöÑ‰∏ªÂãïÂ≠∏Áøí„ÄÅÊ®ôÊ∫ñÂåñÂíåÂü∫Ê∫ñÊ∏¨Ë©¶Áõ∏ÈóúÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂ∞çÊú™‰æÜÂ∑•‰ΩúÁöÑÂª∫Ë≠∞Ôºå‰æãÂ¶ÇÂü∫ÊñºÂñÆÊ¨°ÂâçÂêëÂÇ≥ÈÅûÂíåÈÅ©Áï∂Âú∞Âà©Áî®È´îÁ©çË≥áÊñôÁöÑÊ®°Âûã„ÄÇ

##### **Multi-modal Retrieval Augmented Multi-modal Generation: A Benchmark, Evaluate Metrics and Strong Baselines**
2411.16365v1 by Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, Heyan Huang, Xian-Ling Mao

This paper investigates an intriguing task of Multi-modal Retrieval Augmented
Multi-modal Generation (M$^2$RAG). This task requires foundation models to
browse multi-modal web pages, with mixed text and images, and generate
multi-modal responses for solving user queries, which exhibits better
information density and readability. Given the early researching stage of
M$^2$RAG task, there is a lack of systematic studies and analysis. To fill this
gap, we construct a benchmark for M$^2$RAG task, equipped with a suite of
text-modal metrics and multi-modal metrics to analyze the capabilities of
existing foundation models. Besides, we also propose several effective methods
for foundation models to accomplish this task, based on the comprehensive
evaluation results on our benchmark. Extensive experimental results reveal
several intriguing phenomena worth further research.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫Ü‰∏ÄÈ†ÖÂºï‰∫∫ÂÖ•ÂãùÁöÑÂ§öÊ®°ÊÖãÊ™¢Á¥¢Â¢ûÂº∑Â§öÊ®°ÊÖãÁîüÊàê (M$^2$RAG) ‰ªªÂãô„ÄÇÊ≠§‰ªªÂãôË¶ÅÊ±ÇÂü∫Á§éÊ®°ÂûãÁÄèË¶ΩÂåÖÂê´ÊñáÂ≠óÂíåÂúñÁâáÁöÑÊ∑∑ÂêàÂ§öÊ®°ÊÖãÁ∂≤È†ÅÔºå‰∏¶ÈáùÂ∞ç‰ΩøÁî®ËÄÖÊü•Ë©¢Áî¢ÁîüÂ§öÊ®°ÊÖãÂõûÊáâÔºå‰ª•Â±ïÁèæÊõ¥Â•ΩÁöÑË≥áË®äÂØÜÂ∫¶ÂíåÂèØËÆÄÊÄß„ÄÇËÄÉÈáèÂà∞ M$^2$RAG ‰ªªÂãô‰ªçËôïÊñºÊó©ÊúüÁ†îÁ©∂ÈöéÊÆµÔºåÂõ†Ê≠§Áº∫‰πèÁ≥ªÁµ±ÊÄßÁöÑÁ†îÁ©∂ÂíåÂàÜÊûê„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÊ≠§‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄã M$^2$RAG ‰ªªÂãôÂü∫Ê∫ñÔºå‰∏¶ÈÖçÂÇô‰∏ÄÁµÑÊñáÂ≠óÊ®°ÊÖãÊåáÊ®ôÂíåÂ§öÊ®°ÊÖãÊåáÊ®ôÔºå‰ª•ÂàÜÊûêÁèæÊúâÂü∫Á§éÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰πüÈáùÂ∞çÂü∫Á§éÊ®°ÂûãÊèêÂá∫ÂπæÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ï‰æÜÂÆåÊàêÊ≠§‰ªªÂãôÔºåÈÄô‰∫õÊñπÊ≥ïÊòØÊ†πÊìöÊàëÂÄëÂü∫Ê∫ñ‰∏äÁöÑÁ∂úÂêàË©ï‰º∞ÁµêÊûúËÄåÂæó„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúÊè≠Èú≤‰∫ÜÂπæÂÄãÂÄºÂæóÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÁöÑÊúâË∂£ÁèæË±°„ÄÇ

##### **Graph Neural Networks-based Parameter Design towards Large-Scale Superconducting Quantum Circuits for Crosstalk Mitigation**
2411.16354v1 by Hao Ai, Yu-xi Liu

To demonstrate supremacy of quantum computing, increasingly large-scale
superconducting quantum computing chips are being designed and fabricated,
sparking the demand for electronic design automation in pursuit of better
efficiency and effectiveness. However, the complexity of simulating quantum
systems poses a significant challenge to computer-aided design of quantum
chips. Harnessing the scalability of graph neural networks (GNNs), we here
propose a parameter designing algorithm for large-scale superconducting quantum
circuits. The algorithm depends on the so-called 'three-stair scaling'
mechanism, which comprises two neural-network models: an evaluator supervisedly
trained on small-scale circuits for applying to medium-scale circuits, and a
designer unsupervisedly trained on medium-scale circuits for applying to
large-scale ones. We demonstrate our algorithm in mitigating quantum crosstalk
errors, which are commonly present and closely related to the graph structures
and parameter assignments of superconducting quantum circuits. Parameters for
both single- and two-qubit gates are considered simultaneously. Numerical
results indicate that the well-trained designer achieves notable advantages not
only in efficiency but also in effectiveness, especially for large-scale
circuits. For example, in superconducting quantum circuits consisting of around
870 qubits, the trained designer requires only 27 seconds to complete the
frequency designing task which necessitates 90 minutes for the traditional
Snake algorithm. More importantly, the crosstalk errors using our algorithm are
only 51% of those produced by the Snake algorithm. Overall, this study
initially demonstrates the advantages of applying graph neural networks to
design parameters in quantum processors, and provides insights for systems
where large-scale numerical simulations are challenging in electronic design
automation.

ÊëòË¶ÅÔºö<paragraph>ÁÇ∫‰∫ÜË≠âÊòéÈáèÂ≠êÈÅãÁÆóÁöÑÂÑ™Ë∂äÊÄßÔºåË¶èÊ®°Ë∂ä‰æÜË∂äÂ§ßÁöÑË∂ÖÂ∞éÈáèÂ≠êÈÅãÁÆóÊô∂ÁâáÊ≠£Ë¢´Ë®≠Ë®àÂíåË£ΩÈÄ†ÔºåÂºïÁôº‰∫ÜÂ∞çÈõªÂ≠êË®≠Ë®àËá™ÂãïÂåñÁöÑÈúÄÊ±ÇÔºå‰ª•ËøΩÊ±ÇÊõ¥Â•ΩÁöÑÊïàÁéáÂíåÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÊ®°Êì¨ÈáèÂ≠êÁ≥ªÁµ±ÁöÑË§áÈõúÊÄßÂ∞çÈáèÂ≠êÊô∂ÁâáÁöÑÈõªËÖ¶ËºîÂä©Ë®≠Ë®àÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂà©Áî®ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÂèØÊì¥ÂÖÖÊÄßÔºåÊàëÂÄëÂú®Ê≠§ÊèêÂá∫‰∏ÄÂÄãÁî®ÊñºÂ§ßË¶èÊ®°Ë∂ÖÂ∞éÈáèÂ≠êÈõªË∑ØÁöÑÂèÉÊï∏Ë®≠Ë®àÊºîÁÆóÊ≥ï„ÄÇË©≤ÊºîÁÆóÊ≥ï‰æùË≥¥ÊñºÊâÄË¨ÇÁöÑ„Äå‰∏âÈöéÁ∏ÆÊîæ„ÄçÊ©üÂà∂ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ©ÂÄãÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºö‰∏ÄÂÄãÁõ£Áù£ÂºèË®ìÁ∑¥ÊñºÂ∞èË¶èÊ®°ÈõªË∑Ø‰∏¶ÊáâÁî®Êñº‰∏≠Ë¶èÊ®°ÈõªË∑ØÁöÑË©ï‰º∞Âô®Ôºå‰ª•Âèä‰∏ÄÂÄãÁÑ°Áõ£Áù£ÂºèË®ìÁ∑¥Êñº‰∏≠Ë¶èÊ®°ÈõªË∑Ø‰∏¶ÊáâÁî®ÊñºÂ§ßË¶èÊ®°ÈõªË∑ØÁöÑË®≠Ë®àÂô®„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂú®Ê∏õËºïÈáèÂ≠ê‰∏≤ÊìæË™§Â∑ÆÊñπÈù¢ÁöÑËÉΩÂäõÔºåÈÄô‰∫õË™§Â∑ÆÈÄöÂ∏∏Â≠òÂú®Ôºå‰∏¶‰∏îËàáË∂ÖÂ∞éÈáèÂ≠êÈõªË∑ØÁöÑÂúñÂΩ¢ÁµêÊßãÂíåÂèÉÊï∏ÂàÜÈÖçÂØÜÂàáÁõ∏Èóú„ÄÇÂêåÊôÇËÄÉÊÖÆ‰∫ÜÂñÆÈáèÂ≠ê‰ΩçÂíåÈõôÈáèÂ≠ê‰ΩçÈñòÁöÑÂèÉÊï∏„ÄÇÊï∏ÂÄºÁµêÊûúË°®ÊòéÔºåË®ìÁ∑¥ÊúâÁ¥†ÁöÑË®≠Ë®àÂô®‰∏çÂÉÖÂú®ÊïàÁéáÊñπÈù¢ÔºåËÄå‰∏îÂú®ÊïàËÉΩÊñπÈù¢ÈÉΩÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÂÑ™Âã¢ÔºåÁâπÂà•ÊòØÂ∞çÊñºÂ§ßË¶èÊ®°ÈõªË∑Ø„ÄÇ‰æãÂ¶ÇÔºåÂú®Áî±Â§ßÁ¥Ñ 870 ÂÄãÈáèÂ≠ê‰ΩçÁµÑÊàêÁöÑË∂ÖÂ∞éÈáèÂ≠êÈõªË∑Ø‰∏≠ÔºåË®ìÁ∑¥ÂæåÁöÑË®≠Ë®àÂô®Âè™ÈúÄ 27 ÁßíÂç≥ÂèØÂÆåÊàêÈ†ªÁéáË®≠Ë®à‰ªªÂãôÔºåËÄåÂÇ≥Áµ±ÁöÑ Snake ÊºîÁÆóÊ≥ïÂâáÈúÄË¶Å 90 ÂàÜÈêò„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºå‰ΩøÁî®ÊàëÂÄëÊºîÁÆóÊ≥ïÁî¢ÁîüÁöÑ‰∏≤ÊìæË™§Â∑ÆÂÉÖÁÇ∫ Snake ÊºîÁÆóÊ≥ïÊâÄÁî¢ÁîüË™§Â∑ÆÁöÑ 51%„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÈÄôÈ†ÖÁ†îÁ©∂ÊúÄÂàùÂ±ïÁ§∫‰∫ÜÂ∞áÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÊáâÁî®ÊñºÈáèÂ≠êËôïÁêÜÂô®Ë®≠Ë®àÂèÉÊï∏ÁöÑÂÑ™ÈªûÔºå‰∏¶ÁÇ∫Âú®ÈõªÂ≠êË®≠Ë®àËá™ÂãïÂåñ‰∏≠Â§ßË¶èÊ®°Êï∏ÂÄºÊ®°Êì¨ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁ≥ªÁµ±Êèê‰æõ‰∫ÜË¶ãËß£„ÄÇ</paragraph>

##### **The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C**
2411.16353v1 by Mikita Balesni, Tomek Korbak, Owain Evans

While LLMs excel at multi-hop questions (e.g. "Who is the spouse of the
performer of Imagine?") when using chain-of-thought reasoning (CoT), they
struggle when forced to reason internally (without CoT). Previous work on the
size and nature of this gap produced mixed evidence with inconclusive results.
In this paper, we introduce a controlled setting for investigating two-hop
reasoning in LLMs, where the above-chance performance constitutes undeniable
evidence for latent reasoning. We fine-tune LLMs (including Llama 3 8B Instruct
and GPT-4o) on fictional facts and confirm that they generalize to answering
two-hop questions about them using CoT. We find that models can perform latent
reasoning when facts appear together during training or in the prompt. However,
to our surprise, models completely fail at two-hop reasoning without CoT when
learned facts only appear in different documents, achieving chance-level
accuracy and chance-level test loss. We call this complete failure to compose
separately learned facts the Two-Hop Curse. Moreover, we evaluate 9 frontier
LLMs on real-world facts, finding that models completely fail at two-hop no-CoT
reasoning for over half of question categories while maintaining partial
success with CoT across most categories. These results suggest that LLMs lack a
general capability for latent multi-hop reasoning independent of the question
type.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Â§öË∑≥ÂïèÈ°åÔºà‰æãÂ¶Ç„ÄåÊºîÂî± Imagine ÁöÑË°®ÊºîËÄÖÁöÑÈÖçÂÅ∂ÊòØË™∞Ôºü„ÄçÔºâ‰∏äË°®ÁèæÂá∫Ëâ≤Ôºå‰ΩøÁî®ÊÄùËÄÉÈèàÔºàCoTÔºâÊé®ÁêÜÊôÇÔºå‰ΩÜÁï∂Ë¢´Ëø´Âú®ÂÖßÈÉ®Êé®ÁêÜÔºàÊ≤íÊúâ CoTÔºâÊôÇÔºåÂÆÉÂÄëÊúÉÈô∑ÂÖ•Âõ∞Â¢É„ÄÇÂÖàÂâçÂ∞çÊ≠§Â∑ÆË∑ùÁöÑÂ§ßÂ∞èÂíåÊÄßË≥™ÁöÑÁ†îÁ©∂Áî¢Áîü‰∫Ü‰∏çÂêåÁöÑË≠âÊìöÔºåÁµêÊûúÊ≤íÊúâÂÆöË´ñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèóÊéßË®≠ÂÆöÔºåÁî®ÊñºË™øÊü•Â§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÂÖ©Ë∑≥Êé®ÁêÜÔºåÂÖ∂‰∏≠È´òÊñºÊ©üÊúÉÁöÑË°®ÁèæÊßãÊàêÊΩõÂú®Êé®ÁêÜÁöÑÁÑ°ÂèØËæØÈßÅÁöÑË≠âÊìö„ÄÇÊàëÂÄëÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàÂåÖÊã¨ Llama 3 8B Instruct Âíå GPT-4oÔºâÁöÑËôõÊßã‰∫ãÂØ¶Ôºå‰∏¶Á¢∫Ë™çÂÆÉÂÄëÂèØ‰ª•Ê¶ÇÊã¨ÁÇ∫‰ΩøÁî® CoT ÂõûÁ≠îÊúâÈóúÂÆÉÂÄëÁöÑÂÖ©Ë∑≥ÂïèÈ°å„ÄÇÊàëÂÄëÁôºÁèæÔºåÁï∂‰∫ãÂØ¶Âá∫ÁèæÂú®Ë®ìÁ∑¥ÊúüÈñìÊàñÊèêÁ§∫‰∏≠ÊôÇÔºåÊ®°ÂûãÂèØ‰ª•Âü∑Ë°åÊΩõÂú®Êé®ÁêÜ„ÄÇÁÑ∂ËÄåÔºå‰ª§ÊàëÂÄëÈ©öË®ùÁöÑÊòØÔºåÁï∂Â≠∏ÁøíÂà∞ÁöÑ‰∫ãÂØ¶ÂÉÖÂá∫ÁèæÂú®‰∏çÂêåÁöÑÊñá‰ª∂‰∏≠ÊôÇÔºåÊ®°ÂûãÂú®Ê≤íÊúâ CoT ÁöÑÊÉÖÊ≥Å‰∏ãÂÆåÂÖ®ÁÑ°Ê≥ïÈÄ≤Ë°åÂÖ©Ë∑≥Êé®ÁêÜÔºåÈÅîÂà∞Ê©üÊúÉÊ∞¥Âπ≥ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊ©üÊúÉÊ∞¥Âπ≥ÁöÑÊ∏¨Ë©¶ÊêçÂ§±„ÄÇÊàëÂÄëÂ∞áÈÄôÁ®ÆÂÆåÂÖ®ÁÑ°Ê≥ïÁµÑÂêàÂñÆÁç®Â≠∏ÁøíÁöÑ‰∫ãÂØ¶Á®±ÁÇ∫ÂÖ©Ë∑≥Ë©õÂíí„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑ‰∫ãÂØ¶‰∏äË©ï‰º∞‰∫Ü 9 ÂÄãÂâçÊ≤øÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÁôºÁèæÊ®°ÂûãÂú®Ë∂ÖÈÅé‰∏ÄÂçäÁöÑÂïèÈ°åÈ°ûÂà•‰∏≠ÂÆåÂÖ®ÁÑ°Ê≥ïÈÄ≤Ë°åÂÖ©Ë∑≥ÁÑ° CoT Êé®ÁêÜÔºåÂêåÊôÇÂú®Â§ßÂ§öÊï∏È°ûÂà•‰∏≠‰ΩøÁî® CoT ‰øùÊåÅÈÉ®ÂàÜÊàêÂäü„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁº∫‰πèÁç®Á´ãÊñºÂïèÈ°åÈ°ûÂûãÁöÑÊΩõÂú®Â§öË∑≥Êé®ÁêÜÁöÑ‰∏ÄËà¨ËÉΩÂäõ„ÄÇ

##### **Preference Optimization for Reasoning with Pseudo Feedback**
2411.16345v1 by Fangkai Jiao, Geyang Guo, Xingxing Zhang, Nancy F. Chen, Shafiq Joty, Furu Wei

Preference optimization techniques, such as Direct Preference Optimization
(DPO), are frequently employed to enhance the reasoning capabilities of large
language models (LLMs) in domains like mathematical reasoning and coding,
typically following supervised fine-tuning. These methods rely on high-quality
labels for reasoning tasks to generate preference pairs; however, the
availability of reasoning datasets with human-verified labels is limited. In
this study, we introduce a novel approach to generate pseudo feedback for
reasoning tasks by framing the labeling of solutions to reason problems as an
evaluation against associated test cases. We explore two forms of pseudo
feedback based on test cases: one generated by frontier LLMs and the other by
extending self-consistency to multi-test-case. We conduct experiments on both
mathematical reasoning and coding tasks using pseudo feedback for preference
optimization, and observe improvements across both tasks. Specifically, using
Mathstral-7B as our base model, we improve MATH results from 58.3 to 68.6,
surpassing both NuminaMath-72B and GPT-4-Turbo-1106-preview. In GSM8K and
College Math, our scores increase from 85.6 to 90.3 and from 34.3 to 42.3,
respectively. Building on Deepseek-coder-7B-v1.5, we achieve a score of 24.6 on
LiveCodeBench (from 21.1), surpassing Claude-3-Haiku.

ÊëòË¶ÅÔºöÂÅèÂ•ΩÂÑ™ÂåñÊäÄË°ìÔºå‰æãÂ¶ÇÁõ¥Êé•ÂÅèÂ•ΩÂÑ™Âåñ (DPO)ÔºåÁ∂ìÂ∏∏Ë¢´Áî®‰æÜÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êï∏Â≠∏Êé®ÁêÜÂíåÁ∑®Á¢ºÁ≠âÈ†òÂüüÁöÑÊé®ÁêÜËÉΩÂäõÔºåÈÄöÂ∏∏ÈÅµÂæ™Áõ£Áù£ÂæÆË™ø„ÄÇÈÄô‰∫õÊñπÊ≥ï‰æùË≥¥ÊñºÊé®ÁêÜ‰ªªÂãôÁöÑÈ´òÂìÅË≥™Ê®ôÁ±§‰æÜÁî¢ÁîüÂÅèÂ•ΩÂ∞çÔºõÁÑ∂ËÄåÔºåÂÖ∑Êúâ‰∫∫Â∑•È©óË≠âÊ®ôÁ±§ÁöÑÊé®ÁêÜÊï∏ÊìöÈõÜÁöÑÂèØÁî®ÊÄßÊòØÊúâÈôêÁöÑ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ï‰æÜÁî¢ÁîüÊé®ÁêÜ‰ªªÂãôÁöÑÂÅΩÂõûÈ•ãÔºåÊñπÊ≥ïÊòØÂ∞áÊé®ÁêÜÂïèÈ°åÁöÑËß£Ê®ôË®òÊßãÂª∫ÁÇ∫ÈáùÂ∞çÈóúËÅØÊ∏¨Ë©¶Ê°à‰æãÁöÑË©ï‰º∞„ÄÇÊàëÂÄëÊé¢Á¥¢‰∫ÜÂÖ©Á®ÆÂü∫ÊñºÊ∏¨Ë©¶Ê°à‰æãÁöÑÂÅΩÂõûÈ•ãÂΩ¢ÂºèÔºö‰∏ÄÁ®ÆÁî±ÈÇäÁ∑£ LLM Áî¢ÁîüÔºåÂè¶‰∏ÄÁ®ÆÈÄöÈÅéÂ∞áËá™Êàë‰∏ÄËá¥ÊÄßÊì¥Â±ïÂà∞Â§öÊ∏¨Ë©¶Ê°à‰æã„ÄÇÊàëÂÄëÂ∞çÊï∏Â≠∏Êé®ÁêÜÂíåÁ∑®Á¢º‰ªªÂãôÈÄ≤Ë°å‰∫ÜÂØ¶È©óÔºå‰ΩøÁî®ÂÅΩÂõûÈ•ãÈÄ≤Ë°åÂÅèÂ•ΩÂÑ™ÂåñÔºå‰∏¶ËßÄÂØüÂà∞ÂÖ©È†Ö‰ªªÂãôÈÉΩÊúâÊîπÈÄ≤„ÄÇÂÖ∑È´î‰æÜË™™Ôºå‰ΩøÁî® Mathstral-7B ‰ΩúÁÇ∫ÊàëÂÄëÁöÑÂü∫Á§éÊ®°ÂûãÔºåÊàëÂÄëÂ∞á MATH ÁµêÊûúÂæû 58.3 ÊèêÈ´òÂà∞ 68.6ÔºåË∂ÖÈÅé‰∫Ü NuminaMath-72B Âíå GPT-4-Turbo-1106-preview„ÄÇÂú® GSM8K Âíå College Math ‰∏≠ÔºåÊàëÂÄëÁöÑÂàÜÊï∏ÂàÜÂà•Âæû 85.6 Â¢ûÂä†Âà∞ 90.3ÔºåÂæû 34.3 Â¢ûÂä†Âà∞ 42.3„ÄÇÂú® Deepseek-coder-7B-v1.5 ÁöÑÂü∫Á§é‰∏äÔºåÊàëÂÄëÂú® LiveCodeBench ‰∏äÈÅîÂà∞‰∫Ü 24.6 ÁöÑÂàÜÊï∏ÔºàÂæû 21.1ÔºâÔºåË∂ÖÈÅé‰∫Ü Claude-3-Haiku„ÄÇ

##### **Can AI grade your essays? A comparative analysis of large language models and teacher ratings in multidimensional essay scoring**
2411.16337v1 by Kathrin Se√üler, Maurice F√ºrstenberg, Babette B√ºhler, Enkelejda Kasneci

The manual assessment and grading of student writing is a time-consuming yet
critical task for teachers. Recent developments in generative AI, such as large
language models, offer potential solutions to facilitate essay-scoring tasks
for teachers. In our study, we evaluate the performance and reliability of both
open-source and closed-source LLMs in assessing German student essays,
comparing their evaluations to those of 37 teachers across 10 pre-defined
criteria (i.e., plot logic, expression). A corpus of 20 real-world essays from
Year 7 and 8 students was analyzed using five LLMs: GPT-3.5, GPT-4, o1, LLaMA
3-70B, and Mixtral 8x7B, aiming to provide in-depth insights into LLMs' scoring
capabilities. Closed-source GPT models outperform open-source models in both
internal consistency and alignment with human ratings, particularly excelling
in language-related criteria. The novel o1 model outperforms all other LLMs,
achieving Spearman's $r = .74$ with human assessments in the overall score, and
an internal consistency of $ICC=.80$. These findings indicate that LLM-based
assessment can be a useful tool to reduce teacher workload by supporting the
evaluation of essays, especially with regard to language-related criteria.
However, due to their tendency for higher scores, the models require further
refinement to better capture aspects of content quality.

ÊëòË¶ÅÔºöÊâãÂãïË©ïÈáèËàáË©ïÂàÜÂ≠∏ÁîüÁöÑÂØ´‰ΩúÊòØ‰∏ÄÈ†ÖËÄóÊôÇ‰ΩÜÂ∞çËÄÅÂ∏´‰æÜË™™Ëá≥ÈóúÈáçË¶ÅÁöÑ‰ªªÂãô„ÄÇÁîüÊàêÂºè AI ÁöÑÊúÄÊñ∞ÁôºÂ±ïÔºå‰æãÂ¶ÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÊèê‰æõ‰∫ÜÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•‰øÉÈÄ≤ÊïôÂ∏´ÁöÑË´ñÊñáË©ïÂàÜ‰ªªÂãô„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÈñãÊ∫êÂíåÈñâÊ∫ê LLM Âú®Ë©ïÈáèÂæ∑ÂúãÂ≠∏ÁîüË´ñÊñáÊôÇÁöÑË°®ÁèæÂíåÂèØÈù†ÊÄßÔºå‰∏¶Â∞áÂÖ∂Ë©ïÂàÜËàá 37 ‰ΩçËÄÅÂ∏´Âú® 10 ÂÄãÈ†êÂÖàÂÆöÁæ©ÁöÑÊ®ôÊ∫ñÔºà‰æãÂ¶ÇÔºåÊÉÖÁØÄÈÇèËºØ„ÄÅË°®ÈÅîÔºâ‰∏äÁöÑË©ïÂàÜÈÄ≤Ë°åÊØîËºÉ„ÄÇ‰ΩøÁî®‰∫îÂÄã LLM ÂàÜÊûê‰∫Ü‰æÜËá™ 7 Âπ¥Á¥öÂíå 8 Âπ¥Á¥öÂ≠∏ÁîüÁöÑ 20 ÁØáÁúüÂØ¶‰∏ñÁïåË´ñÊñáÔºöGPT-3.5„ÄÅGPT-4„ÄÅo1„ÄÅLLaMA 3-70B Âíå Mixtral 8x7BÔºåÊó®Âú®Ê∑±ÂÖ•‰∫ÜËß£ LLM ÁöÑË©ïÂàÜËÉΩÂäõ„ÄÇÈñâÊ∫ê GPT Ê®°ÂûãÂú®ÂÖßÈÉ®‰∏ÄËá¥ÊÄßÂíåËàá‰∫∫È°ûË©ïÂàÜÁöÑÂêªÂêàÂ∫¶ÊñπÈù¢ÈÉΩÂÑ™ÊñºÈñãÊ∫êÊ®°ÂûãÔºåÂ∞§ÂÖ∂Âú®ËàáË™ûË®ÄÁõ∏ÈóúÁöÑÊ®ôÊ∫ñÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤„ÄÇÊñ∞Á©éÁöÑ o1 Ê®°ÂûãÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñ LLMÔºåÂú®Êï¥È´îË©ïÂàÜ‰∏≠ÂØ¶Áèæ‰∫Ü Spearman ÁöÑ r = .74 Ëàá‰∫∫È°ûË©ï‰º∞Ôºå‰ª•Âèä ICC=.80 ÁöÑÂÖßÈÉ®‰∏ÄËá¥ÊÄß„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåÂü∫Êñº LLM ÁöÑË©ï‰º∞ÂèØ‰ª•ÊàêÁÇ∫‰∏ÄÂÄãÊúâÁî®ÁöÑÂ∑•ÂÖ∑ÔºåÈÄöÈÅéÊîØÊåÅË´ñÊñáË©ï‰º∞‰æÜÊ∏õÂ∞ëÊïôÂ∏´ÁöÑÂ∑•‰ΩúÈáèÔºåÁâπÂà•ÊòØÂú®ËàáË™ûË®ÄÁõ∏ÈóúÁöÑÊ®ôÊ∫ñÊñπÈù¢„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂÖ∂ÂÇæÂêëÊñºÁç≤ÂæóÊõ¥È´òÁöÑÂàÜÊï∏ÔºåÈÄô‰∫õÊ®°ÂûãÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤Ôºå‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâÂÖßÂÆπÂìÅË≥™ÁöÑÊñπÈù¢„ÄÇ

##### **One Diffusion to Generate Them All**
2411.16318v1 by Duong H. Le, Tuan Pham, Sangho Lee, Christopher Clark, Aniruddha Kembhavi, Stephan Mandt, Ranjay Krishna, Jiasen Lu

We introduce OneDiffusion, a versatile, large-scale diffusion model that
seamlessly supports bidirectional image synthesis and understanding across
diverse tasks. It enables conditional generation from inputs such as text,
depth, pose, layout, and semantic maps, while also handling tasks like image
deblurring, upscaling, and reverse processes such as depth estimation and
segmentation. Additionally, OneDiffusion allows for multi-view generation,
camera pose estimation, and instant personalization using sequential image
inputs. Our model takes a straightforward yet effective approach by treating
all tasks as frame sequences with varying noise scales during training,
allowing any frame to act as a conditioning image at inference time. Our
unified training framework removes the need for specialized architectures,
supports scalable multi-task training, and adapts smoothly to any resolution,
enhancing both generalization and scalability. Experimental results demonstrate
competitive performance across tasks in both generation and prediction such as
text-to-image, multiview generation, ID preservation, depth estimation and
camera pose estimation despite relatively small training dataset. Our code and
checkpoint are freely available at https://github.com/lehduong/OneDiffusion

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊé®Âá∫ OneDiffusionÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄöÁî®ÁöÑ„ÄÅÂ§ßË¶èÊ®°ÁöÑÊì¥Êï£Ê®°ÂûãÔºåÂèØ‰ª•ÁÑ°Á∏´Âú∞ÊîØÊè¥ÈõôÂêëÂΩ±ÂÉèÂêàÊàêÂíåÁêÜËß£Ôºå‰∏¶‰∏îÈÅ©Áî®ÊñºÂêÑÁ®Æ‰ªªÂãô„ÄÇÂÆÉËÉΩÂ§†ÂæûÊñáÂ≠ó„ÄÅÊ∑±Â∫¶„ÄÅÂßøÂã¢„ÄÅÁâàÈù¢ÂíåË™ûÊÑèÂúñÁ≠âËº∏ÂÖ•ÈÄ≤Ë°åÊ¢ù‰ª∂ÂºèÁîüÊàêÔºåÂêåÊôÇ‰πüËÉΩËôïÁêÜÂΩ±ÂÉèÂéªÊ®°Á≥ä„ÄÅÂçáÈ†ªÂíåÂèçÂêëËôïÁêÜÔºå‰æãÂ¶ÇÊ∑±Â∫¶‰º∞Ë®àÂíåÂàÜÂâ≤„ÄÇÊ≠§Â§ñÔºåOneDiffusion ÈÇÑÂÖÅË®±Â§öË¶ñÂúñÁîüÊàê„ÄÅÁõ∏Ê©üÂßøÂã¢‰º∞Ë®àÂíå‰ΩøÁî®È†ÜÂ∫èÂΩ±ÂÉèËº∏ÂÖ•ÈÄ≤Ë°åÂç≥ÊôÇÂÄã‰∫∫Âåñ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊé°Áî®‰∏ÄÁ®ÆÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂ∞áÊâÄÊúâ‰ªªÂãôË¶ñÁÇ∫Ë®ìÁ∑¥ÊúüÈñìÂÖ∑Êúâ‰∏çÂêåÈõúË®äÊØî‰æãÁöÑÂπÄÂ∫èÂàóÔºåÂÖÅË®±‰ªª‰ΩïÂπÄÂú®Êé®Ë´ñÊôÇÈñì‰ΩúÁÇ∫Ê¢ù‰ª∂ÂΩ±ÂÉè„ÄÇÊàëÂÄëÁµ±‰∏ÄÁöÑË®ìÁ∑¥Ê°ÜÊû∂Ê∂àÈô§‰∫ÜÂ∞çÂ∞àÁî®Êû∂ÊßãÁöÑÈúÄÊ±ÇÔºåÊîØÊè¥ÂèØÊì¥ÂÖÖÁöÑÂ§ö‰ªªÂãôË®ìÁ∑¥Ôºå‰∏¶ËÉΩÈ†ÜÂà©ÈÅ©Êáâ‰ªª‰ΩïËß£ÊûêÂ∫¶ÔºåÂêåÊôÇÊèêÂçáÊ≥õÂåñÊÄßÂíåÂèØÊì¥ÂÖÖÊÄß„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂÑòÁÆ°Ë®ìÁ∑¥Ë≥áÊñôÈõÜÁõ∏Â∞çËºÉÂ∞èÔºå‰ΩÜÂÆÉÂú®ÁîüÊàêÂíåÈ†êÊ∏¨‰ªªÂãôÔºà‰æãÂ¶ÇÊñáÂ≠óËΩâÂΩ±ÂÉè„ÄÅÂ§öË¶ñÂúñÁîüÊàê„ÄÅID ‰øùÁïô„ÄÅÊ∑±Â∫¶‰º∞Ë®àÂíåÁõ∏Ê©üÂßøÂã¢‰º∞Ë®àÔºâ‰∏≠ÈÉΩÂ±ïÁèæÂá∫ÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÊ™¢Êü•ÈªûÂèØÊñº https://github.com/lehduong/OneDiffusion ÂÖçË≤ªÂèñÂæó</paragraph>

##### **CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning**
2411.16313v1 by Duo Wu, Jinghe Wang, Yuan Meng, Yanning Zhang, Le Sun, Zhi Wang

Utilizing large language models (LLMs) for tool planning has emerged as a
promising avenue for developing general AI systems, where LLMs automatically
schedule external tools (e.g. vision models) to tackle complex tasks based on
task descriptions. To push this paradigm toward practical applications, it is
crucial for LLMs to consider tool execution costs (e.g. execution time) for
tool planning. Unfortunately, prior studies overlook the tool execution costs,
leading to the generation of expensive plans of which the costs outweigh task
performance. To fill this gap, we propose the Cost-Aware Tool Planning with
LLMs (CATP-LLM) framework, which for the first time provides a coherent design
to empower LLMs for cost-aware tool planning. Specifically, CATP-LLM
incorporates a tool planning language to enhance the LLM to generate
non-sequential plans of multiple branches for efficient concurrent tool
execution and cost reduction. Moreover, it further designs a cost-aware offline
reinforcement learning algorithm to fine-tune the LLM to optimize the
performance-cost trade-off in tool planning. In lack of public cost-related
datasets, we further present OpenCATP, the first platform for cost-aware
planning evaluation. Experiments on OpenCATP show that CATP-LLM outperforms
GPT-4 even when using Llama2-7B as its backbone, with the average improvement
of 28.2%-30.2% higher plan performance and 24.7%-45.8% lower costs even on the
challenging planning tasks. The codes of CATP-LLM and OpenCATP will be publicly
available.

ÊëòË¶ÅÔºöÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÂ∑•ÂÖ∑Ë¶èÂäÉÂ∑≤ÊàêÁÇ∫ÈñãÁôºÈÄöÁî® AI Á≥ªÁµ±ÁöÑ‰∏ÄÊ¢ùÊúâÂâçÈÄîÁöÑÈÄîÂæëÔºåÂÖ∂‰∏≠ LLM ÊúÉÊ†πÊìö‰ªªÂãôÊèèËø∞Ëá™ÂãïÂÆâÊéíÂ§ñÈÉ®Â∑•ÂÖ∑Ôºà‰æãÂ¶ÇË¶ñË¶∫Ê®°ÂûãÔºâ‰æÜËôïÁêÜË§áÈõúÁöÑ‰ªªÂãô„ÄÇÁÇ∫‰∫ÜÂ∞áÊ≠§ÁØÑ‰æãÊé®ÂêëÂØ¶ÂãôÊáâÁî®ÔºåLLM ÂøÖÈ†àËÄÉÈáèÂ∑•ÂÖ∑Âü∑Ë°åÊàêÊú¨Ôºà‰æãÂ¶ÇÂü∑Ë°åÊôÇÈñìÔºâ‰ª•ÈÄ≤Ë°åÂ∑•ÂÖ∑Ë¶èÂäÉ„ÄÇÈÅ∫ÊÜæÁöÑÊòØÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂøΩÁï•‰∫ÜÂ∑•ÂÖ∑Âü∑Ë°åÊàêÊú¨ÔºåÂ∞éËá¥Áî¢Áîü‰∫ÜÊàêÊú¨Â§ßÊñº‰ªªÂãôÊïàËÉΩÁöÑÊòÇË≤¥Ë®àÁï´„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÊ≠§‰∏ÄÁº∫Âè£ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ∑ÂÇôÊàêÊú¨ÊÑèË≠òÁöÑ LLM Â∑•ÂÖ∑Ë¶èÂäÉ (CATP-LLM) Êû∂ÊßãÔºåË©≤Êû∂ÊßãÈ¶ñÊ¨°Êèê‰æõ‰∫ÜÁõ∏Âπ≤ÁöÑË®≠Ë®àÔºå‰ª•Ë≥¶‰∫à LLM ÊàêÊú¨ÊÑèË≠òÁöÑÂ∑•ÂÖ∑Ë¶èÂäÉËÉΩÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåCATP-LLM ÁµêÂêà‰∫ÜÂ∑•ÂÖ∑Ë¶èÂäÉË™ûË®ÄÔºå‰ª•Â¢ûÂº∑ LLM Áî¢ÁîüÈùûÈ†ÜÂ∫èÁöÑÂ§öÂàÜÊîØË®àÁï´Ôºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∏¶Ë°åÂ∑•ÂÖ∑Âü∑Ë°åÂíåÈôç‰ΩéÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÂÆÉÈÄ≤‰∏ÄÊ≠•Ë®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÂÖ∑ÂÇôÊàêÊú¨ÊÑèË≠òÁöÑÈõ¢Á∑öÂº∑ÂåñÂ≠∏ÁøíÊºîÁÆóÊ≥ïÔºå‰ª•ÂæÆË™ø LLMÔºå‰ª•ÊúÄ‰Ω≥ÂåñÂ∑•ÂÖ∑Ë¶èÂäÉ‰∏≠ÁöÑÊïàËÉΩÊàêÊú¨ÂèñÊç®„ÄÇÁî±ÊñºÁº∫‰πèÂÖ¨ÈñãÁöÑÊàêÊú¨Áõ∏ÈóúË≥áÊñôÈõÜÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫Ü OpenCATPÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÁî®ÊñºÂÖ∑ÂÇôÊàêÊú¨ÊÑèË≠òÁöÑË¶èÂäÉË©ï‰º∞ÁöÑÂπ≥Âè∞„ÄÇÂú® OpenCATP ‰∏äÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÂç≥‰Ωø‰ΩøÁî® Llama2-7B ‰ΩúÁÇ∫ÂÖ∂‰∏ªÂππÔºåCATP-LLM ‰ªçÂÑ™Êñº GPT-4ÔºåÂπ≥ÂùáÊïàËÉΩÊèêÂçá 28.2%-30.2%ÔºåÊàêÊú¨Èôç‰Ωé 24.7%-45.8%ÔºåÂç≥‰ΩøÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑË¶èÂäÉ‰ªªÂãô‰∏ä‰πüÊòØÂ¶ÇÊ≠§„ÄÇCATP-LLM Âíå OpenCATP ÁöÑÁ®ãÂºèÁ¢ºÂ∞áÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems**
2411.16305v1 by Magdalena Kaiser, Patrick Ernst, Gy√∂rgy Szarvas

Task-oriented Dialog (ToD) systems have to solve multiple subgoals to
accomplish user goals, whereas feedback is often obtained only at the end of
the dialog. In this work, we propose SUIT (SUbgoal-aware ITerative Training),
an iterative training approach for improving ToD systems. We sample dialogs
from the model we aim to improve and determine subgoals that contribute to
dialog success using distant supervision to obtain high quality training
samples. We show how this data improves supervised fine-tuning or,
alternatively, preference learning results. SUIT is able to iteratively
generate more data instead of relying on fixed static sets. SUIT reaches new
state-of-the-art performance on a popular ToD benchmark.

ÊëòË¶ÅÔºö‰ªªÂãôÂ∞éÂêëÂ∞çË©± (ToD) Á≥ªÁµ±ÂøÖÈ†àËß£Ê±∫Â§öÂÄãÂ≠êÁõÆÊ®ôÊâçËÉΩÈÅîÊàê‰ΩøÁî®ËÄÖÁõÆÊ®ôÔºåËÄåÂõûÈ•ãÂæÄÂæÄÂè™Âú®Â∞çË©±ÁµêÊùüÊôÇÊâçÊúÉÁç≤Âæó„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ SUITÔºàÂ≠êÁõÆÊ®ôÊÑüÁü•Ëø≠‰ª£Ë®ìÁ∑¥ÔºâÔºå‰∏ÄÁ®ÆÁî®ÊñºÊîπÂñÑ ToD Á≥ªÁµ±ÁöÑËø≠‰ª£Ë®ìÁ∑¥ÊñπÊ≥ï„ÄÇÊàëÂÄëÂæûÊàëÂÄëÊâìÁÆóÊîπÂñÑÁöÑÊ®°Âûã‰∏≠ÊäΩÂèñÂ∞çË©±Ôºå‰∏¶‰ΩøÁî®ÈÅ†Ë∑ùÁõ£Áù£‰æÜÁ¢∫ÂÆöÊúâÂä©ÊñºÂ∞çË©±ÊàêÂäüÁöÑÂ≠êÁõÆÊ®ôÔºå‰ª•ÂèñÂæóÈ´òÂìÅË≥™ÁöÑË®ìÁ∑¥ÁØÑ‰æã„ÄÇÊàëÂÄëÂ±ïÁ§∫ÈÄô‰∫õË≥áÊñôÂ¶Ç‰ΩïÊîπÂñÑÁõ£Áù£ÂæÆË™øÊàñÂÅèÂ•ΩÂ≠∏ÁøíÁµêÊûú„ÄÇSUIT ËÉΩÂ§†Ëø≠‰ª£Áî¢ÁîüÊõ¥Â§öË≥áÊñôÔºåËÄå‰∏çÊòØ‰æùË≥¥ÊñºÂõ∫ÂÆöÁöÑÈùúÊÖãÈõÜÂêà„ÄÇSUIT Âú®‰∏ÄÂÄãÊµÅË°åÁöÑ ToD Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÈÅîÂà∞Êñ∞ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇ

##### **BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment**
2411.16300v1 by Shaolei Zhang, Kehao Zhang, Qingkai Fang, Shoutao Guo, Yan Zhou, Xiaodong Liu, Yang Feng

Large language models (LLMs), with their powerful generative capabilities and
vast knowledge, empower various tasks in everyday life. However, these
abilities are primarily concentrated in high-resource languages, leaving
low-resource languages with weaker generative capabilities and relatively
limited knowledge. Enhancing the multilingual capabilities of LLMs is therefore
crucial for serving over 100 linguistic communities worldwide. An intuitive
approach to enhance the multilingual capabilities would be to construct
instruction data for various languages, but constructing instruction data for
over 100 languages is prohibitively costly. In this paper, we introduce BayLing
2, which efficiently transfers generative capabilities and knowledge from
high-resource languages to low-resource languages through language alignment.
To achieve this, we constructed a dataset of 3.2 million instructions,
comprising high-resource language instructions (Chinese and English) and
cross-lingual instructions for 100+ languages and performed instruction tuning
based on the dataset to facilitate the capability transfer between languages.
Using Llama as the foundation model, we developed BayLing-2-7B, BayLing-2-13B,
and BayLing-3-8B, and conducted a comprehensive evaluation of BayLing. For
multilingual translation across 100+ languages, BayLing shows superior
performance compared to open-source models of similar scale. For multilingual
knowledge and understanding benchmarks, BayLing achieves significant
improvements across over 20 low-resource languages, demonstrating its
capability of effective knowledge transfer from high-resource to low-resource
languages. Furthermore, results on English benchmarks indicate that BayLing
maintains high performance in highresource languages while enhancing the
performance in low-resource languages. Demo, homepage, code and models of
BayLing are available.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂÖ∑ÂÇôÂº∑Â§ßÁöÑÁîüÊàêËÉΩÂäõÂíåË±êÂØåÁöÑÁü•Ë≠òÔºåËÉΩË≥¶ËÉΩÊó•Â∏∏ÁîüÊ¥ªÁöÑÂêÑÁ®Æ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËÉΩÂäõ‰∏ªË¶ÅÈõÜ‰∏≠Âú®È´òË≥áÊ∫êË™ûË®ÄÔºåÂ∞éËá¥‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÁîüÊàêËÉΩÂäõËºÉÂº±Ôºå‰∏îÁü•Ë≠òÁõ∏Â∞çÊúâÈôê„ÄÇÂõ†Ê≠§ÔºåÂ¢ûÂº∑ LLM ÁöÑÂ§öË™ûË®ÄËÉΩÂäõÂ∞çÊñºÊúçÂãôÂÖ®ÁêÉË∂ÖÈÅé 100 ÂÄãË™ûË®ÄÁ§æÁæ§Ëá≥ÈóúÈáçË¶Å„ÄÇÂ¢ûÂº∑Â§öË™ûË®ÄËÉΩÂäõÁöÑ‰∏ÄÁ®ÆÁõ¥ËßÄÊñπÊ≥ïÊòØÁÇ∫ÂêÑÁ®ÆË™ûË®ÄÊßãÂª∫Êåá‰ª§Êï∏ÊìöÔºå‰ΩÜÁÇ∫Ë∂ÖÈÅé 100 Á®ÆË™ûË®ÄÊßãÂª∫Êåá‰ª§Êï∏ÊìöÁöÑÊàêÊú¨È´òÂæó‰ª§‰∫∫ÊúõËÄåÂçªÊ≠•„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü BayLing 2ÔºåÂÆÉÈÄöÈÅéË™ûË®ÄÂ∞çÈΩäÊúâÊïàÂú∞Â∞áÁîüÊàêËÉΩÂäõÂíåÁü•Ë≠òÂæûÈ´òË≥áÊ∫êË™ûË®ÄËΩâÁßªÂà∞‰ΩéË≥áÊ∫êË™ûË®Ä„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 320 Ëê¨Ê¢ùÊåá‰ª§ÁöÑÊï∏ÊìöÈõÜÔºåÂåÖÊã¨È´òË≥áÊ∫êË™ûË®ÄÊåá‰ª§Ôºà‰∏≠ÊñáÂíåËã±ÊñáÔºâ‰ª•Âèä 100 Â§öÁ®ÆË™ûË®ÄÁöÑË∑®Ë™ûË®ÄÊåá‰ª§Ôºå‰∏¶Âü∫ÊñºË©≤Êï∏ÊìöÈõÜÂü∑Ë°åÊåá‰ª§ÂæÆË™øÔºå‰ª•‰øÉÈÄ≤Ë™ûË®Ä‰πãÈñìÁöÑËÉΩÂäõËΩâÁßª„ÄÇÊàëÂÄë‰ΩøÁî® Llama ‰ΩúÁÇ∫Âü∫Á§éÊ®°ÂûãÔºåÈñãÁôº‰∫Ü BayLing-2-7B„ÄÅBayLing-2-13B Âíå BayLing-3-8BÔºå‰∏¶Â∞ç BayLing ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢Ë©ï‰º∞„ÄÇÂ∞çÊñºË∑®Ë∂ä 100 Â§öÁ®ÆË™ûË®ÄÁöÑÂ§öË™ûË®ÄÁøªË≠ØÔºåËàáË¶èÊ®°Áõ∏‰ººÁöÑÈñãÊ∫êÊ®°ÂûãÁõ∏ÊØîÔºåBayLing Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩ„ÄÇÂ∞çÊñºÂ§öË™ûË®ÄÁü•Ë≠òÂíåÁêÜËß£Âü∫Ê∫ñÔºåBayLing Âú® 20 Â§öÁ®Æ‰ΩéË≥áÊ∫êË™ûË®Ä‰∏≠ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤ÔºåË≠âÊòé‰∫ÜÂÖ∂ÂæûÈ´òË≥áÊ∫êË™ûË®ÄÂà∞‰ΩéË≥áÊ∫êË™ûË®ÄÊúâÊïàÁü•Ë≠òËΩâÁßªÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåËã±Ë™ûÂü∫Ê∫ñÁöÑÁµêÊûúË°®ÊòéÔºåBayLing Âú®Â¢ûÂº∑‰ΩéË≥áÊ∫êË™ûË®ÄÊÄßËÉΩÁöÑÂêåÊôÇÔºåÂú®È´òË≥áÊ∫êË™ûË®Ä‰∏≠‰øùÊåÅ‰∫ÜÈ´òÊÄßËÉΩ„ÄÇBayLing ÁöÑÊºîÁ§∫„ÄÅ‰∏ªÈ†Å„ÄÅ‰ª£Á¢ºÂíåÊ®°ÂûãÂùáÂ∑≤Êé®Âá∫„ÄÇ</paragraph>

##### **The SVASR System for Text-dependent Speaker Verification (TdSV) AAIC Challenge 2024**
2411.16276v1 by Mohammadreza Molavi, Reza Khodadadi

This paper introduces an efficient and accurate pipeline for text-dependent
speaker verification (TDSV), designed to address the need for high-performance
biometric systems. The proposed system incorporates a Fast-Conformer-based ASR
module to validate speech content, filtering out Target-Wrong (TW) and
Impostor-Wrong (IW) trials. For speaker verification, we propose a feature
fusion approach that combines speaker embeddings extracted from wav2vec-BERT
and ReDimNet models to create a unified speaker representation. This system
achieves competitive results on the TDSV 2024 Challenge test set, with a
normalized min-DCF of 0.0452 (rank 2), highlighting its effectiveness in
balancing accuracy and robustness.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁî®ÊñºÊñáÊú¨‰æùË≥¥ÂûãË™™Ë©±ËÄÖÈ©óË≠â (TDSV) ÁöÑÈ´òÊïà‰∏îÊ∫ñÁ¢∫ÁöÑÁÆ°ÈÅìÔºåÊó®Âú®ÊªøË∂≥È´òÊÄßËÉΩÁîüÁâ©Ë≠òÂà•Á≥ªÁµ±ÁöÑÈúÄÊ±Ç„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±ÁµêÂêà‰∫Ü‰∏ÄÂÄãÂü∫Êñº Fast-Conformer ÁöÑ ASR Ê®°ÁµÑ‰æÜÈ©óË≠âË™ûÈü≥ÂÖßÂÆπÔºå‰∏¶ÈÅéÊøæÊéâÈåØË™§ÁöÑÁõÆÊ®ô (TW) ÂíåÈåØË™§ÁöÑÂÜíÂÖÖËÄÖ (IW) Ê∏¨Ë©¶„ÄÇÂ∞çÊñºË™™Ë©±ËÄÖÈ©óË≠âÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁâπÂæµËûçÂêàÊñπÊ≥ïÔºåÁµêÂêà‰∫ÜÂæû wav2vec-BERT Âíå ReDimNet Ê®°Âûã‰∏≠ÊèêÂèñÁöÑË™™Ë©±ËÄÖÂµåÂÖ•Ôºå‰ª•Âª∫Á´ãÁµ±‰∏ÄÁöÑË™™Ë©±ËÄÖË°®Á§∫„ÄÇÊ≠§Á≥ªÁµ±Âú® TDSV 2024 ÊåëÊà∞Ê∏¨Ë©¶ÈõÜ‰∏≠ÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÁµêÊûúÔºåÊ≠£Ë¶èÂåñÊúÄÂ∞è DCF ÁÇ∫ 0.0452ÔºàÊéíÂêçÁ¨¨ 2ÔºâÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂Âú®Âπ≥Ë°°Ê∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Probing for Consciousness in Machines**
2411.16262v1 by Mathis Immertreu, Achim Schilling, Andreas Maier, Patrick Krauss

This study explores the potential for artificial agents to develop core
consciousness, as proposed by Antonio Damasio's theory of consciousness.
According to Damasio, the emergence of core consciousness relies on the
integration of a self model, informed by representations of emotions and
feelings, and a world model. We hypothesize that an artificial agent, trained
via reinforcement learning (RL) in a virtual environment, can develop
preliminary forms of these models as a byproduct of its primary task. The
agent's main objective is to learn to play a video game and explore the
environment. To evaluate the emergence of world and self models, we employ
probes-feedforward classifiers that use the activations of the trained agent's
neural networks to predict the spatial positions of the agent itself. Our
results demonstrate that the agent can form rudimentary world and self models,
suggesting a pathway toward developing machine consciousness. This research
provides foundational insights into the capabilities of artificial agents in
mirroring aspects of human consciousness, with implications for future
advancements in artificial intelligence.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü‰∫∫Â∑•‰ª£ÁêÜÈñãÁôºÊ†∏ÂøÉÊÑèË≠òÁöÑÊΩõÂäõÔºåÊ≠£Â¶Ç Antonio Damasio ÁöÑÊÑèË≠òÁêÜË´ñÊâÄÊèêÂá∫ÁöÑ„ÄÇÊ†πÊìö Damasio ÁöÑË™™Ê≥ïÔºåÊ†∏ÂøÉÊÑèË≠òÁöÑÂá∫Áèæ‰æùË≥¥ÊñºËá™ÊàëÊ®°ÂûãÁöÑÊï¥ÂêàÔºåË©≤Ê®°ÂûãÁî±ÊÉÖÁ∑íÂíåÊÑüË¶∫ÁöÑË°®Âæµ‰ª•Âèä‰∏ñÁïåÊ®°ÂûãÂëäÁü•„ÄÇÊàëÂÄëÂÅáË®≠ÔºåÈÄöÈÅéÂú®ËôõÊì¨Áí∞Â¢É‰∏≠ÈÄöÈÅéÂº∑ÂåñÂ≠∏Áøí (RL) Ë®ìÁ∑¥ÁöÑ‰∫∫Â∑•‰ª£ÁêÜÔºåÂèØ‰ª•Â∞áÈÄô‰∫õÊ®°ÂûãÁöÑÂàùÊ≠•ÂΩ¢Âºè‰ΩúÁÇ∫ÂÖ∂‰∏ªË¶Å‰ªªÂãôÁöÑÂâØÁî¢ÂìÅÈÄ≤Ë°åÈñãÁôº„ÄÇ‰ª£ÁêÜÁöÑ‰∏ªË¶ÅÁõÆÊ®ôÊòØÂ≠∏ÁøíÁé©Ë¶ñÈ†ªÈÅäÊà≤‰∏¶Êé¢Á¥¢Áí∞Â¢É„ÄÇÁÇ∫‰∫ÜË©ï‰º∞‰∏ñÁïåÂíåËá™ÊàëÊ®°ÂûãÁöÑÂá∫ÁèæÔºåÊàëÂÄëÊé°Áî®Êé¢ÈáùÂâçÈ•ãÂàÜÈ°ûÂô®ÔºåË©≤ÂàÜÈ°ûÂô®‰ΩøÁî®Ë®ìÁ∑¥‰ª£ÁêÜÁ•ûÁ∂ìÁ∂≤Áµ°ÁöÑÊøÄÊ¥ª‰æÜÈ†êÊ∏¨‰ª£ÁêÜÊú¨Ë∫´ÁöÑÁ©∫Èñì‰ΩçÁΩÆ„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºå‰ª£ÁêÜÂèØ‰ª•ÂΩ¢ÊàêÂü∫Êú¨ÁöÑËá™ÊàëÊ®°ÂûãÔºåÈÄôË°®Êòé‰∫ÜÈñãÁôºÊ©üÂô®ÊÑèË≠òÁöÑÈÄîÂæë„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫‰∫∫Â∑•‰ª£ÁêÜÂú®ÂèçÊò†‰∫∫È°ûÊÑèË≠òÊñπÈù¢ÁöÑËÉΩÂäõÊèê‰æõ‰∫ÜÂü∫Á§éË¶ãËß£ÔºåÂ∞ç‰∫∫Â∑•Êô∫ËÉΩÁöÑÊú™‰æÜÁôºÂ±ïÂÖ∑ÊúâÂΩ±Èüø„ÄÇ

##### **Unraveling Arithmetic in Large Language Models: The Role of Algebraic Structures**
2411.16260v1 by Fu-Chieh Chang, Pei-Yuan Wu

Large language models (LLMs) have demonstrated remarkable mathematical
capabilities, largely driven by chain-of-thought (CoT) prompting, which
decomposes complex reasoning into step-by-step solutions. This approach has
enabled significant advancements, as evidenced by performance on benchmarks
like GSM8K and MATH. However, the mechanisms underlying LLMs' ability to
perform arithmetic in a single step of CoT remain poorly understood. Existing
studies debate whether LLMs encode numerical values or rely on symbolic
reasoning, while others explore attention and multi-layered processing in
arithmetic tasks. In this work, we propose that LLMs learn arithmetic by
capturing algebraic structures, such as \emph{Commutativity} and
\emph{Identity} properties. Since these structures are observable through
input-output relationships, they can generalize to unseen data. We empirically
demonstrate that LLMs can learn algebraic structures using a custom dataset of
arithmetic problems. Our findings indicate that leveraging algebraic structures
can enhance the LLMs' arithmetic capabilities, offering insights into improving
their arithmetic performance.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫ÂçìË∂äÁöÑÊï∏Â≠∏ËÉΩÂäõÔºåÈÄôÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØÁî±ÊÄùËÄÉÈèà (CoT) ÊèêÁ§∫È©ÖÂãïÁöÑÔºåÂÆÉÂ∞áË§áÈõúÁöÑÊé®ÁêÜÂàÜËß£ÁÇ∫ÈÄêÊ≠•Ëß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∑≤ÂØ¶ÁèæÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂ¶Ç GSM8K Âíå MATH Á≠âÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑË°®ÁèæÊâÄË≠âÊòé„ÄÇÁÑ∂ËÄåÔºåLLM Âú® CoT ÁöÑÂñÆ‰∏ÄÊ≠•È©ü‰∏≠Âü∑Ë°åÁÆóË°ìÁöÑËÉΩÂäõËÉåÂæåÊ©üÂà∂‰ªçÈÆÆÁÇ∫‰∫∫Áü•„ÄÇÁèæÊúâÁ†îÁ©∂Áà≠Ë´ñ LLM ÊòØÂê¶Á∑®Á¢ºÊï∏ÂÄºÊàñ‰æùË≥¥ÊñºÁ¨¶ËôüÊé®ÁêÜÔºåËÄåÂè¶‰∏Ä‰∫õÁ†îÁ©∂ÂâáÊé¢Ë®éÁÆóË°ì‰ªªÂãô‰∏≠ÁöÑÊ≥®ÊÑèÂäõÂíåÂ§öÂ±§ËôïÁêÜ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ LLM ÈÄèÈÅéÊì∑Âèñ‰ª£Êï∏ÁµêÊßãÔºà‰æãÂ¶Ç‰∫§ÊèõÂæãÂíåÊÅÜÁ≠âÊÄßÔºâ‰æÜÂ≠∏ÁøíÁÆóË°ì„ÄÇÁî±ÊñºÈÄô‰∫õÁµêÊßãÂèØÈÄèÈÅéËº∏ÂÖ•Ëº∏Âá∫Èóú‰øÇËßÄÂØüÂà∞ÔºåÂõ†Ê≠§ÂÆÉÂÄëÂèØ‰ª•Êé®Âª£Âà∞Êú™Ë¶ãÁöÑÊï∏Êìö„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®ÁÆóË°ìÂïèÈ°åËá™Ë®ÇË≥áÊñôÈõÜÂØ¶Ë≠âË≠âÊòé LLM ÂèØ‰ª•Â≠∏Áøí‰ª£Êï∏ÁµêÊßã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂà©Áî®‰ª£Êï∏ÁµêÊßãÂèØ‰ª•Â¢ûÂº∑ LLM ÁöÑÁÆóË°ìËÉΩÂäõÔºå‰∏¶Êèê‰æõË¶ãËß£‰ª•ÊîπÂñÑÂÖ∂ÁÆóË°ìË°®Áèæ„ÄÇ

##### **NormXLogit: The Head-on-Top Never Lies**
2411.16252v1 by Sina Abbasi, Mohammad Reza Modarres, Mohammad Taher Pilehvar

The Transformer architecture has emerged as the dominant choice for building
large language models (LLMs). However, with new LLMs emerging on a frequent
basis, it is important to consider the potential value of architecture-agnostic
approaches that can provide interpretability across a variety of architectures.
Despite recent successes in the interpretability of LLMs, many existing
approaches rely on complex methods that are often tied to a specific model
design and come with a significant computational cost. To address these
limitations, we propose a novel technique, called NormXLogit, for assessing the
significance of individual input tokens. This method operates based on the
input and output representations associated with each token. First, we
demonstrate that during the pre-training of LLMs, the norms of word embeddings
capture the importance of input tokens. Second, we reveal a significant
relationship between a token's importance and the extent to which its
representation can resemble the model's final prediction. Through extensive
analysis, we show that our approach consistently outperforms existing
gradient-based methods in terms of faithfulness. Additionally, our method
achieves better performance in layer-wise explanations compared to the most
prominent architecture-specific methods.

ÊëòË¶ÅÔºöTransformer Êû∂ÊßãÂ∑≤ÊàêÁÇ∫Âª∫ÊßãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑ‰∏ªÊµÅÈÅ∏Êìá„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊñ∞ÁöÑ LLM ‰∏çÊñ∑Âá∫ÁèæÔºåÂõ†Ê≠§ËÄÉÈáèËàáÊû∂ÊßãÁÑ°ÈóúÁöÑÊñπÊ≥ïÁöÑÊΩõÂú®ÂÉπÂÄºÈùûÂ∏∏ÈáçË¶ÅÔºåÈÄô‰∫õÊñπÊ≥ïÂèØ‰ª•Âú®ÂêÑÁ®ÆÊû∂Êßã‰∏≠Êèê‰æõÂèØËß£ÈáãÊÄß„ÄÇÂÑòÁÆ° LLM ÁöÑÂèØËß£ÈáãÊÄßÊúÄËøëÂèñÂæóÊàêÂäüÔºå‰ΩÜË®±Â§öÁèæÊúâÊñπÊ≥ï‰æùË≥¥ÊñºË§áÈõúÁöÑÊñπÊ≥ïÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ËàáÁâπÂÆöÊ®°ÂûãË®≠Ë®àÁõ∏ÈóúÔºå‰∏îË®àÁÆóÊàêÊú¨ÂæàÈ´ò„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ NormXLogit ÁöÑÊñ∞ÊäÄË°ìÔºåÁî®ÊñºË©ï‰º∞ÂÄãÂà•Ëº∏ÂÖ•Ê®ôË®òÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§ÊñπÊ≥ïÊ†πÊìöËàáÊØèÂÄãÊ®ôË®òÁõ∏ÈóúÁöÑËº∏ÂÖ•ÂíåËº∏Âá∫Ë°®Á§∫ÈÅã‰Ωú„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëË≠âÊòéÂú® LLM ÁöÑÈ†êË®ìÁ∑¥ÊúüÈñìÔºåË©ûÂµåÂÖ•ÁöÑÁØÑÊï∏ÊúÉÊì∑ÂèñËº∏ÂÖ•Ê®ôË®òÁöÑÈáçË¶ÅÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊè≠Á§∫Ê®ôË®òÁöÑÈáçË¶ÅÊÄßËàáÂÖ∂Ë°®Á§∫Âú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÈ°û‰ººÊ®°ÂûãÊúÄÁµÇÈ†êÊ∏¨‰πãÈñìÁöÑÈ°ØËëóÈóú‰øÇ„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂàÜÊûêÔºåÊàëÂÄëË°®ÊòéÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Âø†ÂØ¶Â∫¶ÊñπÈù¢ÂßãÁµÇÂÑ™ÊñºÁèæÊúâÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÂÅöÊ≥ï„ÄÇÊ≠§Â§ñÔºåËàáÊúÄÈ°ØËëóÁöÑÁâπÂÆöÊû∂ÊßãÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÈÄêÂ±§Ëß£Èáã‰∏≠Áç≤ÂæóÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇ

##### **Transparent Neighborhood Approximation for Text Classifier Explanation**
2411.16251v1 by Yi Cai, Arthur Zimek, Eirini Ntoutsi, Gerhard Wunder

Recent literature highlights the critical role of neighborhood construction
in deriving model-agnostic explanations, with a growing trend toward deploying
generative models to improve synthetic instance quality, especially for
explaining text classifiers. These approaches overcome the challenges in
neighborhood construction posed by the unstructured nature of texts, thereby
improving the quality of explanations. However, the deployed generators are
usually implemented via neural networks and lack inherent explainability,
sparking arguments over the transparency of the explanation process itself. To
address this limitation while preserving neighborhood quality, this paper
introduces a probability-based editing method as an alternative to black-box
text generators. This approach generates neighboring texts by implementing
manipulations based on in-text contexts. Substituting the generator-based
construction process with recursive probability-based editing, the resultant
explanation method, XPROB (explainer with probability-based editing), exhibits
competitive performance according to the evaluation conducted on two real-world
datasets. Additionally, XPROB's fully transparent and more controllable
construction process leads to superior stability compared to the
generator-based explainers.

ÊëòË¶ÅÔºöËøëÊúüÁöÑÊñáÁçªÂº∑Ë™ø‰∫ÜÈÑ∞ÂüüÂª∫ÊßãÂú®Êé®Â∞éËàáÊ®°ÂûãÁÑ°ÈóúÁöÑËß£Èáã‰∏≠ÊâÄÊâÆÊºîÁöÑÈáçË¶ÅËßíËâ≤Ôºå‰∏¶ÊúùËëóÈÉ®ÁΩ≤ÁîüÊàêÊ®°Âûã‰ª•ÊîπÂñÑÂêàÊàêÂØ¶‰æãÂìÅË≥™ÁöÑÊñπÂêëÁôºÂ±ïÔºåÁâπÂà•ÊòØÈáùÂ∞çËß£ÈáãÊñáÂ≠óÂàÜÈ°ûÂô®„ÄÇÈÄô‰∫õÊñπÊ≥ïÂÖãÊúç‰∫ÜÊñáÂ≠óÈùûÁµêÊßãÂåñÊÄßË≥™Âú®ÈÑ∞ÂüüÂª∫Êßã‰∏≠Áî¢ÁîüÁöÑÊåëÊà∞ÔºåÈÄ≤ËÄåÊèêÂçá‰∫ÜËß£ÈáãÁöÑÂìÅË≥™„ÄÇÁÑ∂ËÄåÔºåÊâÄÈÉ®ÁΩ≤ÁöÑÁîüÊàêÂô®ÈÄöÂ∏∏ÈÄèÈÅéÁ•ûÁ∂ìÁ∂≤Ë∑ØÂØ¶‰ΩúÔºå‰∏îÁº∫‰πèÂÖßÂú®ÁöÑÂèØËß£ÈáãÊÄßÔºåÂºïÁôº‰∫ÜÂ∞çÊñºËß£ÈáãÈÅéÁ®ãÊú¨Ë∫´ÈÄèÊòéÂ∫¶ÁöÑÁà≠Ë´ñ„ÄÇÁÇ∫‰∫ÜÂú®Á∂≠ÊåÅÈÑ∞ÂüüÂìÅË≥™ÁöÑÂêåÊôÇËß£Ê±∫Ê≠§ÈôêÂà∂ÔºåÊú¨ÊñáÂºïÂÖ•‰∫ÜÂü∫ÊñºÊ©üÁéáÁöÑÁ∑®ËºØÊñπÊ≥ïÔºå‰ΩúÁÇ∫ÈªëÁÆ±ÊñáÂ≠óÁîüÊàêÂô®ÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÂØ¶‰ΩúÂü∫ÊñºÊñáÂ≠óÂÖßÊñáËÑàÁöÑÊìçÊéß‰æÜÁî¢ÁîüÈÑ∞ËøëÊñáÂ≠ó„ÄÇÈÄèÈÅé‰ª•ÈÅûËø¥ÁöÑÂü∫ÊñºÊ©üÁéáÁöÑÁ∑®ËºØÂèñ‰ª£Âü∫ÊñºÁîüÊàêÂô®ÁöÑÂª∫ÊßãÈÅéÁ®ãÔºåÊâÄÁî¢ÁîüÁöÑËß£ÈáãÊñπÊ≥ï XPROBÔºàÂü∫ÊñºÊ©üÁéáÁ∑®ËºØÁöÑËß£ÈáãÂô®ÔºâÂú®ÈáùÂ∞çÂÖ©ÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑË©ï‰º∞‰∏≠Â±ïÁèæ‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåËàáÂü∫ÊñºÁîüÊàêÂô®ÁöÑËß£ÈáãÂô®Áõ∏ÊØîÔºåXPROB ÂÆåÂÖ®ÈÄèÊòé‰∏îÊõ¥ÂèØÊéßÁöÑÂª∫ÊßãÈÅéÁ®ãÔºåÂ∏∂‰æÜ‰∫ÜÂÑ™Áï∞ÁöÑÁ©©ÂÆöÊÄß„ÄÇ

##### **DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence Embeddings**
2411.16236v1 by Hong Liu, Yitong Lu

This paper presents a novel method to improve the robustness of foundation
models to group-based biases. We propose a simple yet effective method, called
DoubleCCA, that leverages random sentences and Canonical Correlation Analysis
(CCA) to enrich the text embeddings of the foundation model. First, we generate
various random sentences that augment the original prompts, which extends the
original prompts with random words or character sequences. Second, we use an
additional sentence embedding model to generate different text embeddings with
respect to these random sentences. We then use CCA double twice to align the
representations and reconstruct them back to the original representation space.
We demonstrate the effectiveness of our method on a variety of tasks and
datasets, showing that it outperforms existing methods in terms of both
performance and robustness. Our method is simple to implement and can be easily
integrated into existing models, making it a practical solution for improving
the robustness of foundation models to group-based biases.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºå‰ª•ÊèêÈ´òÂü∫Á§éÊ®°ÂûãÂ∞çÁæ§È´îÂÅèË¶ãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÔºåÁ®±ÁÇ∫ DoubleCCAÔºåÂÆÉÂà©Áî®Èö®Ê©üÂè•Â≠êÂíåÂÖ∏ÂûãÁõ∏ÈóúÂàÜÊûê (CCA) ‰æÜË±êÂØåÂü∫Á§éÊ®°ÂûãÁöÑÊñáÂ≠óÂµåÂÖ•„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÁîüÊàêÂêÑÁ®ÆÈö®Ê©üÂè•Â≠ê‰æÜÊì¥ÂÖÖÂéüÂßãÊèêÁ§∫ÔºåÂÖ∂‰∏≠Áî®Èö®Ê©üÂ≠óË©ûÊàñÂ≠óÂÖÉÂ∫èÂàó‰æÜÂª∂‰º∏ÂéüÂßãÊèêÁ§∫„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄãÈ°çÂ§ñÁöÑÂè•Â≠êÂµåÂÖ•Ê®°ÂûãÔºåÈáùÂ∞çÈÄô‰∫õÈö®Ê©üÂè•Â≠êÁîüÊàê‰∏çÂêåÁöÑÊñáÂ≠óÂµåÂÖ•„ÄÇÊé•ËëóÔºåÊàëÂÄë‰ΩøÁî® CCA ÂÖ©Ê¨°‰æÜÊØîÂ∞çÈÄô‰∫õË°®ÂæµÔºå‰∏¶Â∞áÂÆÉÂÄëÈáçÂª∫ÂõûÂéüÂßãË°®ÂæµÁ©∫Èñì„ÄÇÊàëÂÄëÂú®ÂêÑÁ®Æ‰ªªÂãôÂíåË≥áÊñôÈõÜ‰∏äÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÁµêÊûúÈ°ØÁ§∫ÔºåÂÆÉÂú®ÊïàËÉΩÂíåÁ©©ÂÅ•ÊÄßÊñπÈù¢ÈÉΩÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÊòìÊñºÂØ¶‰ΩúÔºå‰∏îÂèØ‰ª•ËºïÈ¨ÜÊï¥ÂêàÂà∞ÁèæÊúâÊ®°Âûã‰∏≠Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫‰∏ÄÁ®ÆÂØ¶Áî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºÊèêÈ´òÂü∫Á§éÊ®°ÂûãÂ∞çÁæ§È´îÂÅèË¶ãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇ

##### **MH-MoE:Multi-Head Mixture-of-Experts**
2411.16205v1 by Shaohan Huang, Xun Wu, Shuming Ma, Furu Wei

Multi-Head Mixture-of-Experts (MH-MoE) demonstrates superior performance by
using the multi-head mechanism to collectively attend to information from
various representation spaces within different experts. In this paper, we
present a novel implementation of MH-MoE that maintains both FLOPs and
parameter parity with sparse Mixture of Experts models. Experimental results on
language models show that the new implementation yields quality improvements
over both vanilla MoE and fine-grained MoE models. Additionally, our
experiments demonstrate that MH-MoE is compatible with 1-bit Large Language
Models (LLMs) such as BitNet.

ÊëòË¶ÅÔºöÂ§öÈ†≠Â∞àÂÆ∂Ê∑∑ÂêàÔºàMH-MoEÔºâÈÄèÈÅé‰ΩøÁî®Â§öÈ†≠Ê©üÂà∂‰æÜÂÖ±ÂêåÈóúÊ≥®‰æÜËá™‰∏çÂêåÂ∞àÂÆ∂ÂÖßÈÉ®ÂêÑÁ®ÆË°®Á§∫Á©∫ÈñìÁöÑË≥áË®äÔºåÂ±ïÁ§∫Âá∫ÂÑ™Ë∂äÁöÑÊïàËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ MH-MoE ÁöÑÊñ∞Á©éÂØ¶‰ΩúÔºåÂÆÉÂêåÊôÇÁ∂≠ÊåÅ‰∫ÜÁ®ÄÁñèÂ∞àÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÁöÑ FLOP ÂíåÂèÉÊï∏Âπ≥ÂÉπ„ÄÇË™ûË®ÄÊ®°ÂûãÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊñ∞ÁöÑÂØ¶‰ΩúÂú®ÂÇ≥Áµ± MoE ÂíåÁ¥∞Á≤íÂ∫¶ MoE Ê®°Âûã‰∏äÈÉΩÁî¢Áîü‰∫ÜÂìÅË≥™ÁöÑÊèêÂçá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé MH-MoE Ëàá 1 ‰ΩçÂÖÉÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºå‰æãÂ¶Ç BitNet Áõ∏ÂÆπ„ÄÇ

##### **Video-Text Dataset Construction from Multi-AI Feedback: Promoting Weak-to-Strong Preference Learning for Video Large Language Models**
2411.16201v1 by Hao Yi, Qingyang Li, Yulan Hu, Fuzheng Zhang, Di Zhang, Yong Liu

High-quality video-text preference data is crucial for Multimodal Large
Language Models (MLLMs) alignment. However, existing preference data is very
scarce. Obtaining VQA preference data for preference training is costly, and
manually annotating responses is highly unreliable, which could result in
low-quality pairs. Meanwhile, AI-generated responses controlled by temperature
adjustment lack diversity. To address these issues, we propose a high-quality
VQA preference dataset, called \textit{\textbf{M}ultiple \textbf{M}ultimodal
\textbf{A}rtificial \textbf{I}ntelligence \textbf{P}reference Datasets in
\textbf{V}QA} (\textbf{MMAIP-V}), which is constructed by sampling from the
response distribution set and using an external scoring function for response
evaluation. Furthermore, to fully leverage the preference knowledge in MMAIP-V
and ensure sufficient optimization, we propose \textit{\textbf{Iter}ative
\textbf{W}eak-to-\textbf{S}trong \textbf{R}einforcement \textbf{L}earning from
\textbf{AI} \textbf{F}eedback for video MLLMs} (\textbf{Iter-W2S-RLAIF}), a
framework that gradually enhances MLLMs' alignment capabilities by iteratively
updating the reference model and performing parameter extrapolation. Finally,
we propose an unbiased and information-complete evaluation scheme in VQA
evaluation. Experiments demonstrate that MMAIP-V is beneficial for MLLMs in
preference learning and Iter-W2S-RLAIF fully exploits the alignment information
in MMAIP-V. We believe that the proposed automatic VQA preference data
generation pipeline based on AI feedback can greatly promote future work in the
MLLMs alignment. \textbf{Code and dataset are available}
\href{https://anonymous.4open.science/r/MMAIP-V_Iter-W2S-RLAIF-702F}{MMAIP-V\_Iter-W2S-RLAIF-702F}.

ÊëòË¶ÅÔºöÈ´òË¥®ÈáèÂΩ±ÁâáÊñáÂ≠óÂÅèÂ•ΩË≥áÊñôÂ∞çÊñºÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÊØîÂ∞çËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂÅèÂ•ΩË≥áÊñôÈùûÂ∏∏Á®ÄÂ∞ë„ÄÇÂèñÂæó VQA ÂÅèÂ•ΩË≥áÊñô‰ª•ÈÄ≤Ë°åÂÅèÂ•ΩË®ìÁ∑¥ÁöÑÊàêÊú¨ÂæàÈ´òÔºåËÄåÊâãÂãïË®ªËß£ÂõûÊáâÁöÑÂèØÈù†ÊÄßÊ•µ‰ΩéÔºåÂèØËÉΩÊúÉÂ∞éËá¥‰ΩéÂìÅË≥™ÁöÑÈÖçÂ∞ç„ÄÇÂêåÊôÇÔºåÁî±Ê∫´Â∫¶Ë™øÊï¥ÊéßÂà∂ÁöÑ AI ÁîüÊàêÁöÑÂõûÊáâÁº∫‰πèÂ§öÊ®£ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈ´òÂìÅË≥™ÁöÑ VQA ÂÅèÂ•ΩË≥áÊñôÈõÜÔºåÁ®±ÁÇ∫„ÄåÂ§öÊ®°ÊÖãÂ§öÈáç‰∫∫Â∑•Êô∫ÊÖß VQA ÂÅèÂ•ΩË≥áÊñôÈõÜ„Äç(MMAIP-V)ÔºåÂÖ∂ÈÄèÈÅéÂæûÂõûÊáâÂàÜ‰ΩàÈõÜ‰∏≠ÂèñÊ®£‰∏¶‰ΩøÁî®Â§ñÈÉ®Ë©ïÂàÜÂáΩÊï∏Â∞çÂõûÊáâÈÄ≤Ë°åË©ï‰º∞‰æÜÂª∫Êßã„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÂÖÖÂàÜÂà©Áî® MMAIP-V ‰∏≠ÁöÑÂÅèÂ•ΩÁü•Ë≠ò‰∏¶Á¢∫‰øùÂÖÖÂàÜÁöÑÊúÄ‰Ω≥ÂåñÔºåÊàëÂÄëÊèêÂá∫„ÄåÈÄèÈÅé AI ÂõûÈ•ãÈÄ≤Ë°åÂΩ±Áâá MLLM ÁöÑÂèçË¶ÜÂº±ËΩâÂº∑Âº∑ÂåñÂ≠∏Áøí„Äç(Iter-W2S-RLAIF)ÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄèÈÅéÂèçË¶ÜÊõ¥Êñ∞ÂèÉËÄÉÊ®°Âûã‰∏¶Âü∑Ë°åÂèÉÊï∏Â§ñÊé®‰æÜÈÄêÊº∏ÊèêÂçá MLLM ÊØîÂ∞çËÉΩÂäõÁöÑÊû∂Êßã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂú® VQA Ë©ï‰º∞‰∏≠ÊèêÂá∫‰∏ÄÂÄãÁÑ°ÂÅèË¶ã‰∏îË≥áË®äÂÆåÊï¥ÁöÑË©ï‰º∞ÊñπÊ°à„ÄÇÂØ¶È©óË≠âÊòéÔºåMMAIP-V ÊúâÂä©Êñº MLLM ÈÄ≤Ë°åÂÅèÂ•ΩÂ≠∏ÁøíÔºåËÄå Iter-W2S-RLAIF ÂâáÂÖÖÂàÜÂà©Áî® MMAIP-V ‰∏≠ÁöÑÊØîÂ∞çË≥áË®ä„ÄÇÊàëÂÄëÁõ∏‰ø°ÔºåÈÄôÂÄãÂü∫Êñº AI ÂõûÈ•ãÁöÑËá™Âãï VQA ÂÅèÂ•ΩË≥áÊñôÁî¢ÁîüÁÆ°ÈÅìÔºåÂèØ‰ª•Ê•µÂ§ßÂú∞‰øÉÈÄ≤Êú™‰æÜÂú® MLLM ÊØîÂ∞çÊñπÈù¢ÁöÑÁ†îÁ©∂„ÄÇ**Á®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂ∑≤ÊñºÊ≠§ËôïÊèê‰æõ**\href{https://anonymous.4open.science/r/MMAIP-V_Iter-W2S-RLAIF-702F}{MMAIP-V\_Iter-W2S-RLAIF-702F}„ÄÇ

##### **Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models**
2411.16189v1 by Zhihua Duan, Jialin Wang

Large Language Models (LLMs) still face challenges when dealing with complex
reasoning tasks, often resulting in hallucinations, which limit the practical
application of LLMs. To alleviate this issue, this paper proposes a new method
that integrates different LLMs to expand the knowledge boundary, reduce
dependence on a single model, and promote in-depth debate among agents. The
main contributions include: 1) Introducing third-party LLMs to adjust the
attention weights of agents through uncertainty estimation and confidence
analysis, optimizing consensus formation in multi-agent systems; 2) Experiments
on arithmetic datasets have validated the effectiveness of the method,
surpassing traditional multi-agent baselines. This research provides a new
perspective for large models to alleviate hallucination phenomena when dealing
with complex tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ËôïÁêÜË§áÈõúÊé®ÁêÜ‰ªªÂãôÊôÇ‰ªçÈù¢Ëá®ÊåëÊà∞ÔºåÁ∂ìÂ∏∏Â∞éËá¥ÂπªË¶∫ÔºåÈÄôÈôêÂà∂‰∫Ü LLM ÁöÑÂØ¶ÈöõÊáâÁî®„ÄÇÁÇ∫‰∫ÜÁ∑©Ëß£ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÂ∞á‰∏çÂêåÁöÑ LLM Êï¥ÂêàËµ∑‰æÜ‰ª•Êì¥Â±ïÁü•Ë≠òÈÇäÁïåÔºåÊ∏õÂ∞ëÂ∞çÂñÆ‰∏ÄÊ®°ÂûãÁöÑ‰æùË≥¥Ôºå‰∏¶‰øÉÈÄ≤‰ª£ÁêÜ‰πãÈñìÁöÑÊ∑±ÂÖ•ËæØË´ñ„ÄÇ‰∏ªË¶ÅË≤¢ÁçªÂåÖÊã¨Ôºö1) ÂºïÂÖ•Á¨¨‰∏âÊñπ LLMÔºåÈÄèÈÅé‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÂíå‰ø°ÂøÉÂàÜÊûê‰æÜË™øÊï¥‰ª£ÁêÜÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÔºåÂÑ™ÂåñÂ§ö‰ª£ÁêÜÁ≥ªÁµ±‰∏≠ÁöÑÂÖ±Ë≠òÂΩ¢ÊàêÔºõ2) Âú®ÁÆóË°ìÊï∏ÊìöÈõÜ‰∏äÁöÑÂØ¶È©óÈ©óË≠â‰∫ÜË©≤ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåË∂ÖË∂ä‰∫ÜÂÇ≥Áµ±ÁöÑÂ§ö‰ª£ÁêÜÂü∫Á∑ö„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Â§ßÂûãÊ®°ÂûãÂú®ËôïÁêÜË§áÈõú‰ªªÂãôÊôÇÊ∏õËºïÂπªË¶∫ÁèæË±°Êèê‰æõ‰∫ÜÊñ∞ÁöÑËßÄÈªû„ÄÇ

##### **SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis**
2411.16173v1 by Junho Kim, Hyunjun Kim, Hosu Lee, Yong Man Ro

Despite advances in Large Multi-modal Models, applying them to long and
untrimmed video content remains challenging due to limitations in context
length and substantial memory overhead. These constraints often lead to
significant information loss and reduced relevance in the model responses. With
the exponential growth of video data across web platforms, understanding
long-form video is crucial for advancing generalized intelligence. In this
paper, we introduce SALOVA: Segment-Augmented LOng Video Assistant, a novel
video-LLM framework designed to enhance the comprehension of lengthy video
content through targeted retrieval process. We address two main challenges to
achieve it: (i) We present the SceneWalk dataset, a high-quality collection of
87.8K long videos, each densely captioned at the segment level to enable models
to capture scene continuity and maintain rich descriptive context. (ii) We
develop robust architectural designs integrating dynamic routing mechanism and
spatio-temporal projector to efficiently retrieve and process relevant video
segments based on user queries. Our framework mitigates the limitations of
current video-LMMs by allowing for precise identification and retrieval of
relevant video segments in response to queries, thereby improving the
contextual relevance of the generated responses. Through extensive experiments,
SALOVA demonstrates enhanced capability in processing complex long-form videos,
showing significant capability to maintain contextual integrity across extended
sequences.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãÂ§öÊ®°ÊÖãÊ®°ÂûãÊúâÈÄ≤Â±ïÔºå‰ΩÜÁî±ÊñºËÑàÁµ°Èï∑Â∫¶ÂíåÂ§ßÈáèË®òÊÜ∂È´îÈñãÈä∑ÁöÑÈôêÂà∂ÔºåÂ∞áÂÆÉÂÄëÊáâÁî®ÊñºÈï∑‰∏îÊú™‰øÆÂâ™ÁöÑÂΩ±ÁâáÂÖßÂÆπ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÈÄô‰∫õÈôêÂà∂ÈÄöÂ∏∏ÊúÉÂ∞éËá¥Ê®°ÂûãÂõûÊáâ‰∏≠Â§ßÈáèË≥áË®äÈÅ∫Â§±ÂíåÁõ∏ÈóúÊÄßÈôç‰Ωé„ÄÇÈö®ËëóÁ∂≤Ë∑ØÂπ≥Âè∞‰∏äÂΩ±ÁâáË≥áÊñôÁöÑÊåáÊï∏Á¥öÊàêÈï∑ÔºåÁêÜËß£Èï∑ÁØáÂΩ±ÁâáÂ∞çÊñºÊé®ÈÄ≤Âª£Áæ©Êô∫ÊÖßËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π SALOVAÔºöÂçÄÊÆµÂ¢ûÂº∑Èï∑ÂΩ±ÁâáÂä©ÁêÜÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂΩ±Áâá LLM Êû∂ÊßãÔºåÊó®Âú®ÈÄèÈÅéÁõÆÊ®ôÊì∑ÂèñÊµÅÁ®ãÂ¢ûÂº∑Â∞çÈï∑ÁØáÂΩ±ÁâáÂÖßÂÆπÁöÑÁêÜËß£„ÄÇÊàëÂÄëËß£Ê±∫‰∫ÜÂØ¶ÁèæÊ≠§ÁõÆÊ®ôÁöÑÂÖ©ÂÄã‰∏ªË¶ÅÊåëÊà∞Ôºö(i) ÊàëÂÄëÊèêÂá∫ SceneWalk Ë≥áÊñôÈõÜÔºåÈÄôÊòØ‰∏ÄÂÄãÈ´òÂìÅË≥™ÁöÑ 87.8K Èï∑ÂΩ±ÁâáÈõÜÂêàÔºåÊØèÂÄãÂΩ±ÁâáÈÉΩÂú®ÂçÄÊÆµÂ±§Á¥öÂØÜÈõÜÂä†Ë®ªÂ≠óÂπïÔºå‰ª•‰ΩøÊ®°ÂûãËÉΩÂ§†Êì∑ÂèñÂ†¥ÊôØÈÄ£Á∫åÊÄß‰∏¶Á∂≠ÊåÅË±êÂØåÁöÑÊèèËø∞ÊÄßËÑàÁµ°„ÄÇ(ii) ÊàëÂÄëÈñãÁôºÂº∑ÂÅ•ÁöÑÊû∂ÊßãË®≠Ë®àÔºåÊï¥ÂêàÂãïÊÖãË∑ØÁî±Ê©üÂà∂ÂíåÊôÇÁ©∫ÊäïÂΩ±ÂÑÄÔºå‰ª•ÊúâÊïàÂú∞Ê†πÊìö‰ΩøÁî®ËÄÖÊü•Ë©¢Êì∑ÂèñÂíåËôïÁêÜÁõ∏ÈóúÂΩ±ÁâáÂçÄÊÆµ„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÈÄèÈÅéÂÖÅË®±Á≤æÁ¢∫Ë≠òÂà•ÂíåÊì∑ÂèñÁõ∏ÈóúÂΩ±ÁâáÂçÄÊÆµ‰æÜÂõûÊáâÊü•Ë©¢ÔºåÂæûËÄåÊ∏õËºïÁï∂ÂâçÂΩ±Áâá LMM ÁöÑÈôêÂà∂ÔºåÈÄ≤ËÄåÊîπÂñÑÁîüÊàêÂõûÊáâÁöÑËÑàÁµ°Áõ∏ÈóúÊÄß„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåSALOVA Â±ïÁ§∫‰∫ÜËôïÁêÜË§áÈõúÈï∑ÁØáÂΩ±ÁâáÁöÑÂ¢ûÂº∑ÂäüËÉΩÔºåÈ°ØÁ§∫Âá∫Âú®Âª∂‰º∏Â∫èÂàó‰∏≠Á∂≠ÊåÅËÑàÁµ°ÂÆåÊï¥ÊÄßÁöÑÈ°ØËëóËÉΩÂäõ„ÄÇ

##### **MixPE: Quantization and Hardware Co-design for Efficient LLM Inference**
2411.16158v1 by Yu Zhang, Mingzi Wang, Lancheng Zou, Wulong Liu, Hui-Ling Zhen, Mingxuan Yuan, Bei Yu

Transformer-based large language models (LLMs) have achieved remarkable
success as model sizes continue to grow, yet their deployment remains
challenging due to significant computational and memory demands. Quantization
has emerged as a promising solution, and state-of-the-art quantization
algorithms for LLMs introduce the need for mixed-precision matrix
multiplication (mpGEMM), where lower-precision weights are multiplied with
higher-precision activations. Despite its benefits, current hardware
accelerators such as GPUs and TPUs lack native support for efficient mpGEMM,
leading to inefficient dequantization operations in the main sequential loop.
To address this limitation, we introduce MixPE, a specialized mixed-precision
processing element designed for efficient low-bit quantization in LLM
inference. MixPE leverages two key innovations to minimize dequantization
overhead and unlock the full potential of low-bit quantization. First,
recognizing that scale and zero point are shared within each quantization
group, we propose performing dequantization after per-group mpGEMM,
significantly reducing dequantization overhead. Second, instead of relying on
conventional multipliers, MixPE utilizes efficient shift\&add operations for
multiplication, optimizing both computation and energy efficiency. Our
experimental results demonstrate that MixPE surpasses the state-of-the-art
quantization accelerators by $2.6\times$ speedup and $1.4\times$ energy
reduction.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÊ®°ÂûãË¶èÊ®°ÊåÅÁ∫åÊì¥Â§ßÔºåÂü∫Êñº Transformer ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÁî±ÊñºÂÖ∂ÈæêÂ§ßÁöÑÈÅãÁÆóÂíåË®òÊÜ∂È´îÈúÄÊ±ÇÔºåÈÉ®ÁΩ≤‰ªçÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÈáèÂåñÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂæàÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºåËÄå LLM ÁöÑÊúÄÂÖàÈÄ≤ÈáèÂåñÊºîÁÆóÊ≥ïÂºïÂÖ•‰∫ÜÊ∑∑ÂêàÁ≤æÂ∫¶Áü©Èô£‰πòÊ≥ï (mpGEMM) ÁöÑÈúÄÊ±ÇÔºåÂÖ∂‰∏≠ËºÉ‰ΩéÁ≤æÂ∫¶ÁöÑÊ¨äÈáçÊúÉËàáËºÉÈ´òÁ≤æÂ∫¶ÁöÑÊøÄÊ¥ªÁõ∏‰πò„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÂÑ™ÈªûÔºå‰ΩÜÁõÆÂâçÁöÑÁ°¨È´îÂä†ÈÄüÂô®Ôºà‰æãÂ¶Ç GPU Âíå TPUÔºâÁº∫‰πèÂ∞çÈ´òÊïà mpGEMM ÁöÑÂéüÁîüÊîØÊè¥ÔºåÂ∞éËá¥‰∏ªÂ∫èÂêëËø¥Âúà‰∏≠Âá∫Áèæ‰ΩéÊïàÁéáÁöÑÂéªÈáèÂåñ‰ΩúÊ•≠„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MixPEÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂ∞àÈñÄÁöÑÊ∑∑ÂêàÁ≤æÂ∫¶ËôïÁêÜÂÖÉ‰ª∂ÔºåË®≠Ë®àÁî®ÊñºÂú® LLM Êé®Ë´ñ‰∏≠Âü∑Ë°åÈ´òÊïàÁöÑ‰Ωé‰ΩçÂÖÉÈáèÂåñ„ÄÇMixPE Âà©Áî®ÂÖ©È†ÖÈóúÈçµÂâµÊñ∞‰æÜÊúÄÂ∞èÂåñÂéªÈáèÂåñÈñãÈä∑Ôºå‰∏¶ÁôºÊèÆ‰Ωé‰ΩçÂÖÉÈáèÂåñÁöÑÂÖ®ÈÉ®ÊΩõÂäõ„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëË™çÁü•Âà∞Á∏ÆÊîæÂíåÈõ∂ÈªûÂú®ÊØèÂÄãÈáèÂåñÁæ§ÁµÑ‰∏≠ÈÉΩÊòØÂÖ±Áî®ÁöÑÔºåÂõ†Ê≠§ÊàëÂÄëÂª∫Ë≠∞Âú®ÊØèÂÄãÁæ§ÁµÑÁöÑ mpGEMM ‰πãÂæåÂü∑Ë°åÂéªÈáèÂåñÔºåÂ§ßÂπÖÊ∏õÂ∞ëÂéªÈáèÂåñÈñãÈä∑„ÄÇÂÖ∂Ê¨°ÔºåMixPE ‰∏ç‰æùË≥¥ÂÇ≥Áµ±ÁöÑ‰πòÊ≥ïÂô®ÔºåËÄåÊòØÂà©Áî®È´òÊïàÁöÑ‰ΩçÁßªÂíåÂä†Ê≥ïÈÅãÁÆóÈÄ≤Ë°å‰πòÊ≥ïÔºåÂêåÊôÇÊúÄ‰Ω≥ÂåñÈÅãÁÆóÂíåËÉΩÊ∫êÊïàÁéá„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåMixPE Âú®Âä†ÈÄüÊñπÈù¢ÊØîÊúÄÂÖàÈÄ≤ÁöÑÈáèÂåñÂä†ÈÄüÂô®Âø´‰∫Ü 2.6 ÂÄçÔºåÂú®ËÉΩÊ∫êÊ∂àËÄóÊñπÈù¢Ê∏õÂ∞ë‰∫Ü 1.4 ÂÄç„ÄÇ</paragraph>

##### **Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning**
2411.16155v1 by Toyotaro Suzumura, Hiroki Kanezashi, Shotaro Akahori

In diagnosing mental diseases from electroencephalography (EEG) data, neural
network models such as Transformers have been employed to capture temporal
dynamics. Additionally, it is crucial to learn the spatial relationships
between EEG sensors, for which Graph Neural Networks (GNNs) are commonly used.
However, fine-tuning large-scale complex neural network models simultaneously
to capture both temporal and spatial features increases computational costs due
to the more significant number of trainable parameters. It causes the limited
availability of EEG datasets for downstream tasks, making it challenging to
fine-tune large models effectively. We propose EEG-GraphAdapter (EGA), a
parameter-efficient fine-tuning (PEFT) approach to address these challenges.
EGA is integrated into pre-trained temporal backbone models as a GNN-based
module and fine-tuned itself alone while keeping the backbone model parameters
frozen. This enables the acquisition of spatial representations of EEG signals
for downstream tasks, significantly reducing computational overhead and data
requirements. Experimental evaluations on healthcare-related downstream tasks
of Major Depressive Disorder and Abnormality Detection demonstrate that our EGA
improves performance by up to 16.1% in the F1-score compared with the backbone
BENDR model.

ÊëòË¶ÅÔºöÂú®Âà©Áî®ËÖ¶ÈõªÂúñ (EEG) Ë≥áÊñôË®∫Êñ∑Á≤æÁ•ûÁñæÁóÖÊôÇÔºåÂ∑≤Êé°Áî®TransformerÁ≠âÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°Âûã‰æÜÊçïÊçâÊôÇÈñìÂãïÊÖã„ÄÇÊ≠§Â§ñÔºåÂ≠∏Áøí EEG ÊÑüÊ∏¨Âô®‰πãÈñìÁöÑÁ©∫ÈñìÈóú‰øÇËá≥ÈóúÈáçË¶ÅÔºåËÄåÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÈÄöÂ∏∏Áî®ÊñºÊ≠§ÁõÆÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂêåÊôÇÂæÆË™øÂ§ßÂûãË§áÈõúÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°Âûã‰ª•ÊçïÊçâÊôÇÈñìÂíåÁ©∫ÈñìÁâπÂæµÊúÉÂ¢ûÂä†ÈÅãÁÆóÊàêÊú¨ÔºåÂõ†ÁÇ∫ÂèØË®ìÁ∑¥ÂèÉÊï∏Êï∏ÈáèËºÉÂ§ö„ÄÇÈÄôÂ∞éËá¥‰∏ãÊ∏∏‰ªªÂãôÁöÑ EEG Ë≥áÊñôÈõÜÂèØÁî®ÊÄßÊúâÈôêÔºå‰ΩøÂæóÊúâÊïàÂæÆË™øÂ§ßÂûãÊ®°ÂûãÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ EEG-GraphAdapter (EGA)Ôºå‰∏ÄÁ®ÆÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) ÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞„ÄÇEGA ‰ΩúÁÇ∫Âü∫Êñº GNN ÁöÑÊ®°ÁµÑÊï¥ÂêàÂà∞È†êË®ìÁ∑¥ÁöÑÊôÇÈñì‰∏ªÂππÊ®°Âûã‰∏≠Ôºå‰∏¶Âú®‰øùÊåÅ‰∏ªÂππÊ®°ÂûãÂèÉÊï∏ÂáçÁµêÁöÑÂêåÊôÇËá™Ë°åÂæÆË™ø„ÄÇÈÄô‰ΩøÂæóËÉΩÂ§†ÂèñÂæó EEG Ë®äËôüÁöÑÁ©∫ÈñìË°®Á§∫Ôºå‰ª•Áî®Êñº‰∏ãÊ∏∏‰ªªÂãôÔºåÂ§ßÂπÖÈôç‰ΩéÈÅãÁÆóË≤†ÊìîÂíåË≥áÊñôÈúÄÊ±Ç„ÄÇÂú®ËàáÈÜ´ÁôÇ‰øùÂÅ•Áõ∏ÈóúÁöÑ‰∏ãÊ∏∏‰ªªÂãôÔºàÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÂíåÁï∞Â∏∏ÂÅµÊ∏¨ÔºâÁöÑÂØ¶È©óË©ï‰º∞‰∏≠ÔºåÊàëÂÄëÁöÑ EGA Ë≠âÊòéËàá‰∏ªÂππ BENDR Ê®°ÂûãÁõ∏ÊØîÔºåF1 ÂàÜÊï∏ÁöÑÊïàËÉΩÊèêÂçá‰∫Ü 16.1%„ÄÇ

##### **SKQVC: One-Shot Voice Conversion by K-Means Quantization with Self-Supervised Speech Representations**
2411.16147v1 by Youngjun Sim, Jinsung Yoon, Young-Joo Suh

One-shot voice conversion (VC) is a method that enables the transformation
between any two speakers using only a single target speaker utterance. Existing
methods often rely on complex architectures and pre-trained speaker
verification (SV) models to improve the fidelity of converted speech. Recent
works utilizing K-means quantization (KQ) with self-supervised learning (SSL)
features have proven capable of capturing content information from speech.
However, they often struggle to preserve speaking variation, such as prosodic
detail and phonetic variation, particularly with smaller codebooks. In this
work, we propose a simple yet effective one-shot VC model that utilizes the
characteristics of SSL features and speech attributes. Our approach addresses
the issue of losing speaking variation, enabling high-fidelity voice conversion
trained with only reconstruction losses, without requiring external speaker
embeddings. We demonstrate the performance of our model across 6 evaluation
metrics, with results highlighting the benefits of the speaking variation
compensation method.

ÊëòË¶ÅÔºöÂñÆÊ¨°ËÅ≤Èü≥ËΩâÊèõ (VC) ÊòØ‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂèØ‰ΩøÁî®ÂñÆ‰∏ÄÁõÆÊ®ôË™™Ë©±ËÄÖË™ûÂè•ÔºåÂú®ÂÖ©ÂÄãË™™Ë©±ËÄÖ‰πãÈñìÈÄ≤Ë°åËΩâÊèõ„ÄÇÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºË§áÈõúÁöÑÊû∂ÊßãÂíåÈ†êÂÖàË®ìÁ∑¥ÁöÑË™™Ë©±ËÄÖÈ©óË≠â (SV) Ê®°ÂûãÔºå‰ª•ÊèêÈ´òËΩâÊèõË™ûÈü≥ÁöÑ‰øùÁúüÂ∫¶„ÄÇÊúÄËøëÂà©Áî® K ÂùáÂÄºÈáèÂåñ (KQ) ÂíåËá™Áõ£Áù£Â≠∏Áøí (SSL) ÁâπÂæµÁöÑ‰ΩúÂìÅÂ∑≤Ë¢´Ë≠âÊòéËÉΩÂ§†ÂæûË™ûÈü≥‰∏≠Êì∑ÂèñÂÖßÂÆπË≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈÄöÂ∏∏Èõ£‰ª•‰øùÁïôË™™Ë©±ËÆäÁï∞Ôºå‰æãÂ¶ÇÈü≥Ë™øÁ¥∞ÁØÄÂíåË™ûÈü≥ËÆäÁï∞ÔºåÁâπÂà•ÊòØÂú®ËºÉÂ∞èÁöÑÁ¢ºÊú¨‰∏≠„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÂñÆÊ¨° VC Ê®°ÂûãÔºåÂÆÉÂà©Áî® SSL ÁâπÂæµÂíåË™ûÈü≥Â±¨ÊÄßÁöÑÁâπÂæµ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËß£Ê±∫‰∫ÜÂ§±ÂéªË™™Ë©±ËÆäÁï∞ÁöÑÂïèÈ°åÔºåÂØ¶Áèæ‰∫ÜÂÉÖ‰ΩøÁî®ÈáçÂª∫ÊêçÂ§±Ë®ìÁ∑¥ÁöÑÈ´ò‰øùÁúüË™ûÈü≥ËΩâÊèõÔºåËÄå‰∏çÈúÄË¶ÅÂ§ñÈÉ®Ë™™Ë©±ËÄÖÂµåÂÖ•„ÄÇÊàëÂÄëÂú® 6 È†ÖË©ï‰º∞ÊåáÊ®ô‰∏≠Â±ïÁ§∫‰∫ÜÊàëÂÄëÊ®°ÂûãÁöÑÊïàËÉΩÔºåÁµêÊûúÁ™ÅÂá∫‰∫ÜË™™Ë©±ËÆäÁï∞Ë£úÂÑüÊñπÊ≥ïÁöÑÂÑ™Èªû„ÄÇ

##### **End-to-End Steering for Autonomous Vehicles via Conditional Imitation Co-Learning**
2411.16131v1 by Mahmoud M. Kishky, Hesham M. Eraqi, Khaled F. Elsayed

Autonomous driving involves complex tasks such as data fusion, object and
lane detection, behavior prediction, and path planning. As opposed to the
modular approach which dedicates individual subsystems to tackle each of those
tasks, the end-to-end approach treats the problem as a single learnable task
using deep neural networks, reducing system complexity and minimizing
dependency on heuristics. Conditional imitation learning (CIL) trains the
end-to-end model to mimic a human expert considering the navigational commands
guiding the vehicle to reach its destination, CIL adopts specialist network
branches dedicated to learn the driving task for each navigational command.
Nevertheless, the CIL model lacked generalization when deployed to unseen
environments. This work introduces the conditional imitation co-learning (CIC)
approach to address this issue by enabling the model to learn the relationships
between CIL specialist branches via a co-learning matrix generated by gated
hyperbolic tangent units (GTUs). Additionally, we propose posing the steering
regression problem as classification, we use a classification-regression hybrid
loss to bridge the gap between regression and classification, we also propose
using co-existence probability to consider the spatial tendency between the
steering classes. Our model is demonstrated to improve autonomous driving
success rate in unseen environment by 62% on average compared to the CIL
method.

ÊëòË¶ÅÔºöËá™ÂãïÈßïÈßõÊ∂âÂèäË§áÈõúÁöÑ‰ªªÂãôÔºå‰æãÂ¶ÇË≥áÊñôËûçÂêà„ÄÅÁâ©È´îÂíåËªäÈÅìÂÅµÊ∏¨„ÄÅË°åÁÇ∫È†êÊ∏¨ÂíåË∑ØÂæëË¶èÂäÉ„ÄÇËàáÂ∞áÂÄãÂà•Â≠êÁ≥ªÁµ±Â∞àÁî®ÊñºËôïÁêÜÊØèÂÄã‰ªªÂãôÁöÑÊ®°ÁµÑÂåñÊñπÊ≥ïÁõ∏ÂèçÔºåÁ´ØÂà∞Á´ØÊñπÊ≥ïÂ∞áÂïèÈ°åË¶ñÁÇ∫‰ΩøÁî®Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂñÆ‰∏ÄÂèØÂ≠∏Áøí‰ªªÂãôÔºåÈôç‰ΩéÁ≥ªÁµ±Ë§áÈõúÊÄß‰∏¶ÊúÄÂ∞èÂåñÂ∞çÂïüÁôºÊ≥ïÁöÑ‰æùË≥¥„ÄÇÊ¢ù‰ª∂Ê®°‰ªøÂ≠∏Áøí (CIL) Ë®ìÁ∑¥Á´ØÂà∞Á´ØÊ®°ÂûãÔºå‰ª•Ê®°Êì¨‰∫∫È°ûÂ∞àÂÆ∂ËÄÉÊÖÆÂ∞éËà™ÂëΩ‰ª§ÔºåÂºïÂ∞éËªäËºõÂà∞ÈÅîÁõÆÁöÑÂú∞ÔºåCIL Êé°Áî®Â∞àÈñÄÁ∂≤Ë∑ØÂàÜÊîØÔºåÂ∞àÈñÄÂ≠∏ÁøíÊØèÂÄãÂ∞éËà™ÂëΩ‰ª§ÁöÑÈßïÈßõ‰ªªÂãô„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåCIL Ê®°ÂûãÂú®ÈÉ®ÁΩ≤Âà∞Êú™Ë¶ãÁí∞Â¢ÉÊôÇÁº∫‰πèÊ≥õÂåñÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂºïÂÖ•‰∫ÜÊ¢ù‰ª∂Ê®°‰ªøÂçîÂêåÂ≠∏Áøí (CIC) ÊñπÊ≥ïÔºåÈÄèÈÅéÂïüÁî®Ê®°ÂûãÈÄèÈÅéÈñÄÊéßÈõôÊõ≤Ê≠£ÂàáÂñÆÂÖÉ (GTU) ÁîüÊàêÁöÑÂçîÂêåÂ≠∏ÁøíÁü©Èô£ÔºåÂ≠∏Áøí CIL Â∞àÂÆ∂ÂàÜÊîØ‰πãÈñìÁöÑÈóú‰øÇ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂª∫Ë≠∞Â∞áËΩâÂêëËø¥Ê≠∏ÂïèÈ°åË¶ñÁÇ∫ÂàÜÈ°ûÔºåÊàëÂÄë‰ΩøÁî®ÂàÜÈ°ûËø¥Ê≠∏Ê∑∑ÂêàÊêçÂ§±‰æÜÂΩåÂêàËø¥Ê≠∏ÂíåÂàÜÈ°û‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÊàëÂÄëÈÇÑÂª∫Ë≠∞‰ΩøÁî®ÂÖ±Â≠òÊ©üÁéá‰æÜËÄÉÊÖÆËΩâÂêëÈ°ûÂà•‰πãÈñìÁöÑÁ©∫ÈñìË∂®Âã¢„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãË¢´Ë≠âÊòéÂèØ‰ª•Â∞áÂú®Êú™Ë¶ãÁí∞Â¢É‰∏≠ÁöÑËá™ÂãïÈßïÈßõÊàêÂäüÁéáÂπ≥ÂùáÊèêÈ´ò 62%ÔºåËàá CIL ÊñπÊ≥ïÁõ∏ÊØî„ÄÇ

##### **Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**
2411.16123v1 by Hangyul Yoon, Doohyuk Jang, Jungeun Kim, Eunho Yang

Leveraging pre-trained models with tailored prompts for in-context learning
has proven highly effective in NLP tasks. Building on this success, recent
studies have applied a similar approach to the Segment Anything Model (SAM)
within a ``one-shot" framework, where only a single reference image and its
label are employed. However, these methods face limitations in the medical
domain, primarily due to SAM's essential requirement for visual prompts and the
over-reliance on pixel similarity for generating them. This dependency may lead
to (1) inaccurate prompt generation and (2) clustering of point prompts,
resulting in suboptimal outcomes. To address these challenges, we introduce
\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designed
for the medical domain. Med-PerSAM uses only visual prompt engineering and
eliminates the need for additional training of the pretrained SAM or human
intervention, owing to our novel automated prompt generation process. By
integrating our lightweight warping-based prompt tuning model with SAM, we
enable the extraction and iterative refinement of visual prompts, enhancing the
performance of the pre-trained SAM. This advancement is particularly meaningful
in the medical domain, where creating visual prompts poses notable challenges
for individuals lacking medical expertise. Our model outperforms various
foundational models and previous SAM-based approaches across diverse 2D medical
imaging datasets.

ÊëòË¶ÅÔºöÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºå‰∏¶ÈáùÂ∞çÁâπÂÆöÊèêÁ§∫ÈÄ≤Ë°åÊÉÖÂ¢ÉÂ≠∏ÁøíÔºåÂ∑≤Ë≠âÊòéÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠ÈùûÂ∏∏ÊúâÊïà„ÄÇÂú®Ê≠§ÊàêÂäüÂü∫Á§é‰∏äÔºåÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Â∞áÈ°û‰ººÊñπÊ≥ïÊáâÁî®Êñº„ÄåÁâáÊÆµ‰ªª‰ΩïÊ®°Âûã„Äç(SAM)ÔºåÊé°Áî®„Äå‰∏ÄÊ¨°ÊÄß„ÄçÊû∂ÊßãÔºåÂÖ∂‰∏≠ÂÉÖ‰ΩøÁî®ÂñÆ‰∏ÄÂèÉËÄÉÂΩ±ÂÉèÂèäÂÖ∂Ê®ôÁ±§„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂú®ÈÜ´ÁôÇÈ†òÂüüÈù¢Ëá®ÈôêÂà∂Ôºå‰∏ªË¶ÅÊòØÁî±Êñº SAM Â∞çË¶ñË¶∫ÊèêÁ§∫ÁöÑÂü∫Êú¨ÈúÄÊ±ÇÔºå‰ª•ÂèäÈÅéÂ∫¶‰æùË≥¥ÂÉèÁ¥†Áõ∏‰ººÊÄß‰æÜÁî¢ÁîüÂÆÉÂÄë„ÄÇÈÄôÁ®Æ‰æùË≥¥ÊÄßÂèØËÉΩÊúÉÂ∞éËá¥ (1) ÊèêÁ§∫Áî¢Áîü‰∏çÊ∫ñÁ¢∫Ôºå‰ª•Âèä (2) ÈªûÊèêÁ§∫Áæ§ÈõÜÔºåÂ∞éËá¥ÁµêÊûúÊ¨°‰Ω≥„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü \textbf{Med-PerSAM}ÔºåÈÄôÊòØ‰∏ÄÂÄãÂ∞àÁÇ∫ÈÜ´ÁôÇÈ†òÂüüË®≠Ë®àÁöÑÊñ∞Á©é‰∏îÁõ¥Êé•ÁöÑ‰∏ÄÊ¨°ÊÄßÊû∂Êßã„ÄÇMed-PerSAM ÂÉÖ‰ΩøÁî®Ë¶ñË¶∫ÊèêÁ§∫Â∑•Á®ãÔºå‰∏¶Ê∂àÈô§‰∫ÜÂ∞çÈ†êË®ìÁ∑¥ SAM Êàñ‰∫∫ÁÇ∫Âπ≤È†êÁöÑÈ°çÂ§ñË®ìÁ∑¥ÈúÄÊ±ÇÔºåÈÄôË¶ÅÊ≠∏ÂäüÊñºÊàëÂÄëÊñ∞Á©éÁöÑËá™ÂãïÂåñÊèêÁ§∫Áî¢ÁîüÊµÅÁ®ã„ÄÇÈÄèÈÅéÂ∞áÊàëÂÄëËºïÈáèÁ¥öÂü∫ÊñºËÆäÂΩ¢ÁöÑÊèêÁ§∫Ë™øÊï¥Ê®°ÂûãËàá SAM Êï¥ÂêàÔºåÊàëÂÄëËÉΩÂ§†ÊèêÂèñÂíåÂèçË¶ÜÊîπÂñÑË¶ñË¶∫ÊèêÁ§∫ÔºåÂ¢ûÂº∑È†êË®ìÁ∑¥ SAM ÁöÑÊïàËÉΩ„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïÂú®ÈÜ´ÁôÇÈ†òÂüüÁâπÂà•ÊúâÊÑèÁæ©ÔºåÂõ†ÁÇ∫Â∞çÊñºÁº∫‰πèÈÜ´ÁôÇÂ∞àÊ•≠Áü•Ë≠òÁöÑ‰∫∫‰æÜË™™ÔºåÂª∫Á´ãË¶ñË¶∫ÊèêÁ§∫ÊúÉÊßãÊàêÈ°ØËëóÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂêÑÁ®Æ 2D ÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÂêÑÁ®ÆÂü∫Á§éÊ®°ÂûãÂíåÂÖàÂâçÁöÑÂü∫Êñº SAM ÁöÑÊñπÊ≥ï„ÄÇ

##### **Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**
2411.16120v1 by Rui Zuo, Zifan Wang, Simon Khan, Garrett Ethan Katz, Qinru Qiu

Due to the inherent lack of transparency in deep neural networks, it is
challenging for deep reinforcement learning (DRL) agents to gain trust and
acceptance from users, especially in safety-critical applications such as
medical diagnosis and military operations. Existing methods for explaining an
agent's decision either require to retrain the agent using models that support
explanation generation or rely on perturbation-based techniques to reveal the
significance of different input features in the decision making process.
However, retraining the agent may compromise its integrity and performance,
while perturbation-based methods have limited performance and lack knowledge
accumulation or learning capabilities. Moreover, since each perturbation is
performed independently, the joint state of the perturbed inputs may not be
physically meaningful. To address these challenges, we introduce
$\textbf{VisionMask}$, a standalone explanation model trained end-to-end to
identify the most critical regions in the agent's visual input that can explain
its actions. VisionMask is trained in a self-supervised manner without relying
on human-generated labels. Importantly, its training does not alter the agent
model, hence preserving the agent's performance and integrity. We evaluate
VisionMask on Super Mario Bros (SMB) and three Atari games. Compared to
existing methods, VisionMask achieves a 14.9% higher insertion accuracy and a
30.08% higher F1-Score in reproducing original actions from the selected visual
explanations. We also present examples illustrating how VisionMask can be used
for counterfactual analysis.

ÊëòË¶ÅÔºö<paragraph>Áî±ÊñºÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁº∫‰πèÈÄèÊòéÂ∫¶ÔºåÊ∑±Â∫¶Âº∑ÂåñÂ≠∏Áøí (DRL) ‰ª£ÁêÜÁ®ãÂºèË¶ÅÁç≤Âæó‰ΩøÁî®ËÄÖÁöÑ‰ø°‰ªªÂíåË™çÂèØÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÂÆâÂÖ®ÈóúÈçµÁöÑÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰æãÂ¶ÇÈÜ´ÁôÇË®∫Êñ∑ÂíåËªç‰∫ãË°åÂãï„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïÁî®ÊñºËß£Èáã‰ª£ÁêÜÁ®ãÂºèÁöÑÊ±∫Á≠ñÔºåÈúÄË¶Å‰ΩøÁî®ÊîØÊè¥Ëß£ÈáãÁî¢ÁîüÁöÑÊ®°ÂûãÈáçÊñ∞Ë®ìÁ∑¥‰ª£ÁêÜÁ®ãÂºèÔºåÊàñ‰æùË≥¥ÊñºÂü∫ÊñºÊìæÂãïÁöÑÊäÄË°ì‰æÜÊè≠Á§∫‰∏çÂêåËº∏ÂÖ•ÁâπÂæµÂú®Ê±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ã‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÁÑ∂ËÄåÔºåÈáçÊñ∞Ë®ìÁ∑¥‰ª£ÁêÜÁ®ãÂºèÂèØËÉΩÊúÉÊêçÂÆ≥ÂÖ∂ÂÆåÊï¥ÊÄßÂíåÊïàËÉΩÔºåËÄåÂü∫ÊñºÊìæÂãïÁöÑÊñπÊ≥ïÊïàËÉΩÊúâÈôêÔºå‰∏îÁº∫‰πèÁü•Ë≠òÁ¥ØÁ©çÊàñÂ≠∏ÁøíËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÊØèÂÄãÊìæÂãïÈÉΩÊòØÁç®Á´ãÂü∑Ë°åÁöÑÔºåÂõ†Ê≠§ÊìæÂãïËº∏ÂÖ•ÁöÑËÅØÂêàÁãÄÊÖãÂèØËÉΩÊ≤íÊúâÂØ¶ÈöõÊÑèÁæ©„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü $\textbf{VisionMask}$ÔºåÈÄôÊòØ‰∏ÄÂÄãÁç®Á´ãÁöÑËß£ÈáãÊ®°ÂûãÔºåÁ∂ìÈÅéÁ´ØÂ∞çÁ´ØÁöÑË®ìÁ∑¥Ôºå‰ª•Ë≠òÂà•‰ª£ÁêÜÁ®ãÂºèË¶ñË¶∫Ëº∏ÂÖ•‰∏≠ÊúÄÈóúÈçµÁöÑÂçÄÂüüÔºåÈÄô‰∫õÂçÄÂüüÂèØ‰ª•Ëß£ÈáãÂÖ∂Âãï‰Ωú„ÄÇVisionMask ‰ª•Ëá™Áõ£Áù£ÁöÑÊñπÂºèÈÄ≤Ë°åË®ìÁ∑¥ÔºåËÄå‰∏ç‰æùË≥¥Êñº‰∫∫ÁÇ∫Áî¢ÁîüÁöÑÊ®ôÁ±§„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÂÖ∂Ë®ìÁ∑¥‰∏çÊúÉÊîπËÆä‰ª£ÁêÜÁ®ãÂºèÊ®°ÂûãÔºåÂõ†Ê≠§ÂèØ‰ª•‰øùÁïô‰ª£ÁêÜÁ®ãÂºèÁöÑÊïàËÉΩÂíåÂÆåÊï¥ÊÄß„ÄÇÊàëÂÄëÂú® Super Mario Bros (SMB) Âíå‰∏âÊ¨æ Atari ÈÅäÊà≤‰∏äË©ï‰º∞‰∫Ü VisionMask„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåVisionMask Âú®Ê†πÊìöÊâÄÈÅ∏ÁöÑË¶ñË¶∫Ëß£ÈáãË§áË£ΩÂéüÂßãÂãï‰ΩúÊôÇÔºåÊèíÂÖ•Ê∫ñÁ¢∫ÁéáÊèêÈ´ò‰∫Ü 14.9%ÔºåF1 ÂàÜÊï∏ÊèêÈ´ò‰∫Ü 30.08%„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫ÜÁØÑ‰æã‰æÜË™™ÊòéÂ¶Ç‰Ωï‰ΩøÁî® VisionMask ÈÄ≤Ë°åÂèç‰∫ãÂØ¶ÂàÜÊûê„ÄÇ</paragraph>

##### **LLM Augmentations to support Analytical Reasoning over Multiple Documents**
2411.16116v1 by Raquib Bin Yousuf, Nicholas Defelice, Mandar Sharma, Shengzhe Xu, Naren Ramakrishnan

Building on their demonstrated ability to perform a variety of tasks, we
investigate the application of large language models (LLMs) to enhance in-depth
analytical reasoning within the context of intelligence analysis. Intelligence
analysts typically work with massive dossiers to draw connections between
seemingly unrelated entities, and uncover adversaries' plans and motives. We
explore if and how LLMs can be helpful to analysts for this task and develop an
architecture to augment the capabilities of an LLM with a memory module called
dynamic evidence trees (DETs) to develop and track multiple investigation
threads. Through extensive experiments on multiple datasets, we highlight how
LLMs, as-is, are still inadequate to support intelligence analysts and offer
recommendations to improve LLMs for such intricate reasoning applications.

ÊëòË¶ÅÔºöÂª∫Á´ãÂú®ÂÆÉÂÄëÂü∑Ë°åÂêÑÁ®Æ‰ªªÂãôÁöÑÂ∑≤È©óË≠âËÉΩÂäõ‰∏äÔºåÊàëÂÄëÁ†îÁ©∂Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊáâÁî®Ôºå‰ª•Â¢ûÂº∑ÊÉÖÂ†±ÂàÜÊûêËÉåÊôØ‰∏ãÁöÑÊ∑±ÂÖ•ÂàÜÊûêÊé®ÁêÜ„ÄÇÊÉÖÂ†±ÂàÜÊûêÂ∏´ÈÄöÂ∏∏ÊúÉËôïÁêÜÂ§ßÈáèÊ™îÊ°àÔºå‰ª•ÊâæÂá∫Áúã‰ººÁÑ°ÈóúÂØ¶È´î‰πãÈñìÁöÑÈóúËÅØÔºå‰∏¶Êè≠Èú≤Â∞çÊâãÁöÑË®àÁï´ÂíåÂãïÊ©ü„ÄÇÊàëÂÄëÊé¢Ë®é LLM ÊòØÂê¶‰ª•ÂèäÂ¶Ç‰ΩïËÉΩÂçîÂä©ÂàÜÊûêÂ∏´Âü∑Ë°åÈÄôÈ†Ö‰ªªÂãôÔºå‰∏¶ÈñãÁôº‰∏ÄÁ®ÆÊû∂ÊßãÔºå‰ª•‰∏ÄÂÄãÁ®±ÁÇ∫ÂãïÊÖãË≠âÊìöÊ®π (DET) ÁöÑË®òÊÜ∂È´îÊ®°ÁµÑ‰æÜÊì¥ÂÖÖ LLM ÁöÑÂäüËÉΩÔºå‰ª•ÈñãÁôºÂíåËøΩËπ§Â§öÂÄãË™øÊü•Á∑öÁ¥¢„ÄÇÈÄèÈÅéÂ∞çÂ§öÂÄãË≥áÊñôÈõÜÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÂº∑Ë™øÂá∫ LLM ÂéüÊú¨ÁöÑÁãÄÊÖã‰ªç‰∏çË∂≥‰ª•ÊîØÊè¥ÊÉÖÂ†±ÂàÜÊûêÂ∏´Ôºå‰∏¶Êèê‰æõÂª∫Ë≠∞Ôºå‰ª•ÊîπÂñÑ LLMÔºåÁî®ÊñºÊ≠§È°ûË§áÈõúÁöÑÊé®ÁêÜÊáâÁî®„ÄÇ

##### **LLMPirate: LLMs for Black-box Hardware IP Piracy**
2411.16111v1 by Vasudev Gohil, Matthew DeLorenzo, Veera Vishwa Achuta Sai Venkat Nallam, Joey See, Jeyavijayan Rajendran

The rapid advancement of large language models (LLMs) has enabled the ability
to effectively analyze and generate code nearly instantaneously, resulting in
their widespread adoption in software development. Following this advancement,
researchers and companies have begun integrating LLMs across the hardware
design and verification process. However, these highly potent LLMs can also
induce new attack scenarios upon security vulnerabilities across the hardware
development process. One such attack vector that has not been explored is
intellectual property (IP) piracy. Given that this attack can manifest as
rewriting hardware designs to evade piracy detection, it is essential to
thoroughly evaluate LLM capabilities in performing this task and assess the
mitigation abilities of current IP piracy detection tools.
  Therefore, in this work, we propose LLMPirate, the first LLM-based technique
able to generate pirated variations of circuit designs that successfully evade
detection across multiple state-of-the-art piracy detection tools. We devise
three solutions to overcome challenges related to integration of LLMs for
hardware circuit designs, scalability to large circuits, and effectiveness,
resulting in an end-to-end automated, efficient, and practical formulation. We
perform an extensive experimental evaluation of LLMPirate using eight LLMs of
varying sizes and capabilities and assess their performance in pirating various
circuit designs against four state-of-the-art, widely-used piracy detection
tools. Our experiments demonstrate that LLMPirate is able to consistently evade
detection on 100% of tested circuits across every detection tool. Additionally,
we showcase the ramifications of LLMPirate using case studies on IBEX and
MOR1KX processors and a GPS module, that we successfully pirate. We envision
that our work motivates and fosters the development of better IP piracy
detection tools.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÈÄ≤Ê≠•‰ΩøÂæóËÉΩÂ§†ÊúâÊïàÂàÜÊûêÂíåÁîüÊàê‰ª£Á¢ºÂπæ‰πéÊòØÁû¨ÈñìÂÆåÊàêÔºåÂ∞éËá¥ÂÆÉÂÄëÂú®ËªüÈ´îÈñãÁôº‰∏≠Ë¢´Âª£Ê≥õÊé°Áî®„ÄÇÂú®ÈÄô‰∏ÄÈÄ≤Ê≠•‰πãÂæåÔºåÁ†îÁ©∂‰∫∫Âì°ÂíåÂÖ¨Âè∏Â∑≤Á∂ìÈñãÂßãÂú®Á°¨È´îË®≠Ë®àÂíåÈ©óË≠âÈÅéÁ®ã‰∏≠Êï¥Âêà LLM„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÈ´òÂ∫¶Âº∑Â§ßÁöÑ LLM ‰πüÂèØ‰ª•Âú®Êï¥ÂÄãÁ°¨È´îÈñãÁôºÈÅéÁ®ã‰∏≠Â∞çÂÆâÂÖ®ÊºèÊ¥ûË™òÁôºÊñ∞ÁöÑÊîªÊìäÂ†¥ÊôØ„ÄÇ‰∏ÄÁ®ÆÂ∞öÊú™Êé¢Á¥¢ÁöÑÊ≠§È°ûÊîªÊìäÂ™í‰ªãÊòØÊô∫ÊÖßË≤°Áî¢Ê¨ä (IP) ÁõúÁâà„ÄÇÈëëÊñºÈÄôÁ®ÆÊîªÊìäÂèØ‰ª•Ë°®ÁèæÁÇ∫ÈáçÂØ´Á°¨È´îË®≠Ë®à‰ª•Ë¶èÈÅøÁõúÁâàÊ™¢Ê∏¨ÔºåÂõ†Ê≠§ÂæπÂ∫ïË©ï‰º∞ LLM Âú®Âü∑Ë°åÊ≠§‰ªªÂãô‰∏≠ÁöÑËÉΩÂäõ‰∏¶Ë©ï‰º∞Áï∂Ââç IP ÁõúÁâàÊ™¢Ê∏¨Â∑•ÂÖ∑ÁöÑÁ∑©Ëß£ËÉΩÂäõËá≥ÈóúÈáçË¶Å„ÄÇ
Âõ†Ê≠§ÔºåÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LLMPirateÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫Êñº LLM ÁöÑÈ¶ñÂâµÊäÄË°ìÔºåËÉΩÂ§†ÁîüÊàêÈõªË∑ØË®≠Ë®àÁöÑÁõúÁâàËÆäÈ´îÔºåÊàêÂäüË¶èÈÅøÂ§öÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑÁõúÁâàÊ™¢Ê∏¨Â∑•ÂÖ∑ÁöÑÊ™¢Ê∏¨„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏âÁ®ÆËß£Ê±∫ÊñπÊ°à‰æÜÂÖãÊúçËàá LLM ÈõÜÊàêÂà∞Á°¨È´îÈõªË∑ØË®≠Ë®à„ÄÅÂ§ßÈõªË∑ØÂèØÊì¥Â±ïÊÄßÂíåÊúâÊïàÊÄßÁõ∏ÈóúÁöÑÊåëÊà∞ÔºåÂæûËÄåÂΩ¢ÊàêÁ´ØÂà∞Á´ØËá™ÂãïÂåñ„ÄÅÈ´òÊïà‰∏îÂØ¶Áî®ÁöÑÂÖ¨Âºè„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ´Á®Æ‰∏çÂêåÂ§ßÂ∞èÂíåÂäüËÉΩÁöÑ LLM Â∞ç LLMPirate ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óË©ï‰º∞Ôºå‰∏¶Ë©ï‰º∞‰∫ÜÂÆÉÂÄëÂú®ÈáùÂ∞çÂõõÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑ„ÄÅÂª£Ê≥õ‰ΩøÁî®ÁöÑÁõúÁâàÊ™¢Ê∏¨Â∑•ÂÖ∑ÁõúÁâàÂêÑÁ®ÆÈõªË∑ØË®≠Ë®à‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåLLMPirate ËÉΩÂ§†Âú®ÊØèÂÄãÊ™¢Ê∏¨Â∑•ÂÖ∑‰∏≠Â∞ç 100% ÁöÑÂèóÊ∏¨ÈõªË∑ØÊåÅÁ∫åË¶èÈÅøÊ™¢Ê∏¨„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü LLMPirate Âú® IBEX Âíå MOR1KX ËôïÁêÜÂô®‰ª•Âèä GPS Ê®°ÁµÑÔºàÊàëÂÄëÊàêÂäüÁõúÁâàÔºâÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈ†êË®àÔºåÊàëÂÄëÁöÑËëó‰ΩúÂ∞áÊøÄÂãµÂíå‰øÉÈÄ≤Êõ¥Â•ΩÁöÑ IP ÁõúÁâàÊ™¢Ê∏¨Â∑•ÂÖ∑ÁöÑÈñãÁôº„ÄÇ

##### **Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability**
2411.16105v1 by Jatin Nainani, Sankaran Vaidyanathan, AJ Yeung, Kartik Gupta, David Jensen

Mechanistic interpretability aims to understand the inner workings of large
neural networks by identifying circuits, or minimal subgraphs within the model
that implement algorithms responsible for performing specific tasks. These
circuits are typically discovered and analyzed using a narrowly defined prompt
format. However, given the abilities of large language models (LLMs) to
generalize across various prompt formats for the same task, it remains unclear
how well these circuits generalize. For instance, it is unclear whether the
models generalization results from reusing the same circuit components, the
components behaving differently, or the use of entirely different components.
In this paper, we investigate the generality of the indirect object
identification (IOI) circuit in GPT-2 small, which is well-studied and believed
to implement a simple, interpretable algorithm. We evaluate its performance on
prompt variants that challenge the assumptions of this algorithm. Our findings
reveal that the circuit generalizes surprisingly well, reusing all of its
components and mechanisms while only adding additional input edges. Notably,
the circuit generalizes even to prompt variants where the original algorithm
should fail; we discover a mechanism that explains this which we term S2
Hacking. Our findings indicate that circuits within LLMs may be more flexible
and general than previously recognized, underscoring the importance of studying
circuit generalization to better understand the broader capabilities of these
models.

ÊëòË¶ÅÔºö<paragraph>Ê©üÊ¢∞ÂèØËß£ÈáãÊÄßÊó®Âú®ÈÄèÈÅéË≠òÂà•ÈõªË∑ØÔºåÊàñÊ®°Âûã‰∏≠Ë≤†Ë≤¨Âü∑Ë°åÁâπÂÆö‰ªªÂãôÁöÑÊºîÁÆóÊ≥ïÊâÄÂØ¶‰ΩúÁöÑÊúÄÂ∞èÂ≠êÂúñÂΩ¢Ôºå‰æÜ‰∫ÜËß£Â§ßÂûãÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂÖßÈÉ®ÈÅã‰Ωú„ÄÇÈÄô‰∫õÈõªË∑ØÈÄöÂ∏∏‰ΩøÁî®ÂÆöÁæ©ÁãπÁ™ÑÁöÑÊèêÁ§∫Ê†ºÂºèÈÄ≤Ë°åÁôºÁèæÂíåÂàÜÊûê„ÄÇÁÑ∂ËÄåÔºåËÄÉÈáèÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞çÁõ∏Âêå‰ªªÂãôÁöÑÂêÑÁ®ÆÊèêÁ§∫Ê†ºÂºèÈÄ≤Ë°åÊ¶ÇÂåñÁöÑËÉΩÂäõÔºåÈÄô‰∫õÈõªË∑ØÊ¶ÇÂåñÁöÑÁ®ãÂ∫¶‰ªçÁÑ∂‰∏çÊ∏ÖÊ•ö„ÄÇ‰æãÂ¶ÇÔºåÁõÆÂâç‰∏çÊ∏ÖÊ•öÊ®°ÂûãÊ¶ÇÂåñÊòØÂê¶‰æÜËá™ÈáçË§á‰ΩøÁî®Áõ∏ÂêåÁöÑÈõªË∑ØÂÖÉ‰ª∂ÔºåÂÖÉ‰ª∂Ë°®Áèæ‰∏çÂêåÔºåÊàñ‰ΩøÁî®ÂÆåÂÖ®‰∏çÂêåÁöÑÂÖÉ‰ª∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é GPT-2 small ‰∏≠ÈñìÊé•ÂèóË©ûË≠òÂà• (IOI) ÈõªË∑ØÁöÑÊ¶ÇÊã¨ÊÄßÔºåË©≤ÈõªË∑ØÁ∂ìÈÅéÂÖÖÂàÜÁ†îÁ©∂Ôºå‰∏îË¢´Ë™çÁÇ∫ÂØ¶‰Ωú‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ„ÄÅÂèØËß£ÈáãÁöÑÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄëË©ï‰º∞ÂÆÉÂú®ÊåëÊà∞Ê≠§ÊºîÁÆóÊ≥ïÂÅáË®≠ÁöÑÊèêÁ§∫ËÆäÈ´î‰∏äÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåË©≤ÈõªË∑ØÊ¶ÇÂåñÂæó‰ª§‰∫∫È©öË®ùÂú∞Â•ΩÔºåÈáçË§á‰ΩøÁî®ÂÖ∂ÊâÄÊúâÂÖÉ‰ª∂ÂíåÊ©üÂà∂ÔºåÂêåÊôÇÂÉÖÊñ∞Â¢ûÈ°çÂ§ñÁöÑËº∏ÂÖ•ÈÇäÁ∑£„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂç≥‰ΩøÂú®ÂéüÂßãÊºîÁÆóÊ≥ïÊáâË©≤ÊúÉÂ§±ÊïóÁöÑÊèêÁ§∫ËÆäÈ´î‰∏≠ÔºåË©≤ÈõªË∑Ø‰ªçËÉΩÊ¶ÇÂåñÔºõÊàëÂÄëÁôºÁèæ‰∏ÄÁ®ÆÊ©üÂà∂ÂèØ‰ª•Ëß£ÈáãÈÄôÁ®ÆÊÉÖÊ≥ÅÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ S2 Hacking„ÄÇÊàëÂÄëÁöÑÁôºÁèæË°®ÊòéÔºåLLM ‰∏≠ÁöÑÈõªË∑ØÂèØËÉΩÊØîÂÖàÂâçË™çÁü•ÁöÑÊõ¥ÈùàÊ¥ª‰∏îÊõ¥ÈÄöÁî®ÔºåÈÄôÂº∑Ë™ø‰∫ÜÁ†îÁ©∂ÈõªË∑ØÊ¶ÇÂåñÁöÑÈáçË¶ÅÊÄßÔºå‰ª•‰æøÊõ¥Ê∑±ÂÖ•‰∫ÜËß£ÈÄô‰∫õÊ®°ÂûãÁöÑÂª£Ê≥õÂäüËÉΩ„ÄÇ</paragraph>

##### **An Empirical Study of Vulnerability Detection using Federated Learning**
2411.16099v1 by Peiheng Zhou, Ming Hu, Xingrun Quan, Yawen Peng, Xiaofei Xie, Yanxin Yang, Chengwei Liu, Yueming Wu, Mingsong Chen

Although Deep Learning (DL) methods becoming increasingly popular in
vulnerability detection, their performance is seriously limited by insufficient
training data. This is mainly because few existing software organizations can
maintain a complete set of high-quality samples for DL-based vulnerability
detection. Due to the concerns about privacy leakage, most of them are
reluctant to share data, resulting in the data silo problem. Since enables
collaboratively model training without data sharing, Federated Learning (FL)
has been investigated as a promising means of addressing the data silo problem
in DL-based vulnerability detection. However, since existing FL-based
vulnerability detection methods focus on specific applications, it is still far
unclear i) how well FL adapts to common vulnerability detection tasks and ii)
how to design a high-performance FL solution for a specific vulnerability
detection task. To answer these two questions, this paper first proposes VulFL,
an effective evaluation framework for FL-based vulnerability detection. Then,
based on VulFL, this paper conducts a comprehensive study to reveal the
underlying capabilities of FL in dealing with different types of CWEs,
especially when facing various data heterogeneity scenarios. Our experimental
results show that, compared to independent training, FL can significantly
improve the detection performance of common AI models on all investigated CWEs,
though the performance of FL-based vulnerability detection is limited by
heterogeneous data. To highlight the performance differences between different
FL solutions for vulnerability detection, we extensively investigate the
impacts of different configuration strategies for each framework component of
VulFL. Our study sheds light on the potential of FL in vulnerability detection,
which can be used to guide the design of FL-based solutions for vulnerability
detection.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê∑±Â∫¶Â≠∏Áøí (DL) ÊñπÊ≥ïÂú®ÊºèÊ¥ûÂÅµÊ∏¨ÊñπÈù¢Êó•ÁõäÊôÆÂèäÔºå‰ΩÜÂÖ∂ÊïàËÉΩÂçªÂèóÂà∞Ë®ìÁ∑¥Ë≥áÊñô‰∏çË∂≥ÁöÑÂö¥ÈáçÈôêÂà∂„ÄÇÈÄô‰∏ªË¶ÅÊòØÂõ†ÁÇ∫ÁèæÊúâÁöÑËªüÈ´îÁµÑÁπîÂæàÂ∞ëËÉΩÁ∂≠Ë≠∑‰∏ÄÁµÑÂÆåÊï¥ÁöÑÂÑ™Ë≥™Ê®£Êú¨Ôºå‰ª•ÈÄ≤Ë°åÂü∫Êñº DL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨„ÄÇÁî±ÊñºÊìîÂøÉÈö±ÁßÅÂ§ñÊ¥©Ôºå‰ªñÂÄëÂ§ßÂ§ö‰∏çÈ°òÊÑèÂàÜ‰∫´Ë≥áÊñôÔºåÂ∞éËá¥Ë≥áÊñôÂ≠§Â≥∂ÂïèÈ°å„ÄÇÁî±ÊñºËÅØÂêàÂ≠∏Áøí (FL) ËÉΩÂ§†Âú®‰∏çÂÖ±Áî®Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÂçî‰ΩúÊ®°ÂûãË®ìÁ∑¥ÔºåÂõ†Ê≠§Â∑≤Â∞áÂÖ∂Ë¶ñÁÇ∫Ëß£Ê±∫Âü∫Êñº DL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨‰∏≠Ë≥áÊñôÂ≠§Â≥∂ÂïèÈ°åÁöÑ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁèæÊúâÁöÑÂü∫Êñº FL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨ÊñπÊ≥ïÂ∞àÊ≥®ÊñºÁâπÂÆöÊáâÁî®Á®ãÂºèÔºåÂõ†Ê≠§‰ªç‰∏çÊ∏ÖÊ•ö i) FL Â¶Ç‰ΩïÈÅ©ÊáâÂ∏∏Ë¶ãÁöÑÊºèÊ¥ûÂÅµÊ∏¨‰ªªÂãôÔºå‰ª•Âèä ii) Â¶Ç‰ΩïÁÇ∫ÁâπÂÆöÊºèÊ¥ûÂÅµÊ∏¨‰ªªÂãôË®≠Ë®àÈ´òÊÄßËÉΩÁöÑ FL Ëß£Ê±∫ÊñπÊ°à„ÄÇÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÖ©ÂÄãÂïèÈ°åÔºåÊú¨ÊñáÈ¶ñÂÖàÊèêÂá∫‰∫Ü VulFLÔºå‰∏ÄÂÄãÁî®ÊñºÂü∫Êñº FL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨ÁöÑÊúâÊïàË©ï‰º∞Êû∂Êßã„ÄÇÁÑ∂ÂæåÔºåÊú¨ÊñáÂü∫Êñº VulFL ÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢Á†îÁ©∂Ôºå‰ª•Êè≠Á§∫ FL Âú®ËôïÁêÜ‰∏çÂêåÈ°ûÂûãÁöÑ CWE ÊôÇÁöÑÊΩõÂú®ËÉΩÂäõÔºåÁâπÂà•ÊòØÂú®Èù¢Â∞çÂêÑÁ®ÆË≥áÊñôÁï∞Ë≥™ÊÄßÂ†¥ÊôØÊôÇ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÁç®Á´ãË®ìÁ∑¥Áõ∏ÊØîÔºåFL ÂèØ‰ª•È°ØËëóÊèêÂçáÊâÄÊúâË™øÊü•ÁöÑ CWE ‰∏äÂ∏∏Ë¶ã AI Ê®°ÂûãÁöÑÂÅµÊ∏¨ÊïàËÉΩÔºåÂÑòÁÆ°Âü∫Êñº FL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨ÁöÑÊïàËÉΩÂèóÂà∞Áï∞Ë≥™ÊÄßË≥áÊñôÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÂº∑Ë™ø‰∏çÂêå FL Ëß£Ê±∫ÊñπÊ°àÂú®ÊºèÊ¥ûÂÅµÊ∏¨‰∏äÁöÑÊïàËÉΩÂ∑ÆÁï∞ÔºåÊàëÂÄëÂª£Ê≥õÊé¢Ë®é‰∫Ü VulFL ÂêÑÂÄãÊû∂ÊßãÂÖÉ‰ª∂ÁöÑ‰∏çÂêåÈÖçÁΩÆÁ≠ñÁï•ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Èó°Êòé‰∫Ü FL Âú®ÊºèÊ¥ûÂÅµÊ∏¨ÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂèØÁî®ÊñºÊåáÂ∞éÂü∫Êñº FL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨Ëß£Ê±∫ÊñπÊ°àÁöÑË®≠Ë®à„ÄÇ

##### **ENCLIP: Ensembling and Clustering-Based Contrastive Language-Image Pretraining for Fashion Multimodal Search with Limited Data and Low-Quality Images**
2411.16096v1 by Prithviraj Purushottam Naik, Rohit Agarwal

Multimodal search has revolutionized the fashion industry, providing a
seamless and intuitive way for users to discover and explore fashion items.
Based on their preferences, style, or specific attributes, users can search for
products by combining text and image information. Text-to-image searches enable
users to find visually similar items or describe products using natural
language. This paper presents an innovative approach called ENCLIP, for
enhancing the performance of the Contrastive Language-Image Pretraining (CLIP)
model, specifically in Multimodal Search targeted towards the domain of fashion
intelligence. This method focuses on addressing the challenges posed by limited
data availability and low-quality images. This paper proposes an algorithm that
involves training and ensembling multiple instances of the CLIP model, and
leveraging clustering techniques to group similar images together. The
experimental findings presented in this study provide evidence of the
effectiveness of the methodology. This approach unlocks the potential of CLIP
in the domain of fashion intelligence, where data scarcity and image quality
issues are prevalent. Overall, the ENCLIP method represents a valuable
contribution to the field of fashion intelligence and provides a practical
solution for optimizing the CLIP model in scenarios with limited data and
low-quality images.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÊêúÁ¥¢ÂΩªÂ∫ïÊîπÂèò‰∫ÜÊó∂Â∞ö‰∫ß‰∏öÔºå‰∏∫Áî®Êà∑Êèê‰æõ‰∫Ü‰∏ÄÁßçÊó†Áºù‰∏îÁõ¥ËßÇÁöÑÊñπÂºèÊù•ÂèëÁé∞ÂíåÊé¢Á¥¢Êó∂Â∞öÂçïÂìÅ„ÄÇÂü∫‰∫é‰ªñ‰ª¨ÁöÑÂÅèÂ•Ω„ÄÅÈ£éÊ†ºÊàñÁâπÂÆöÂ±ûÊÄßÔºåÁî®Êà∑ÂèØ‰ª•ÈÄöËøáÁªìÂêàÊñáÊú¨ÂíåÂõæÂÉè‰ø°ÊÅØÊù•ÊêúÁ¥¢‰∫ßÂìÅ„ÄÇÊñáÊú¨Âà∞ÂõæÂÉèÊêúÁ¥¢‰ΩøÁî®Êà∑ËÉΩÂ§üÊâæÂà∞ËßÜËßâ‰∏äÁõ∏‰ººÁöÑÁâ©ÂìÅÊàñ‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞‰∫ßÂìÅ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ ENCLIP ÁöÑÂàõÊñ∞ÊñπÊ≥ïÔºåÁî®‰∫éÂ¢ûÂº∫ÂØπÊØîËØ≠Ë®ÄÂõæÂÉèÈ¢ÑËÆ≠ÁªÉ (CLIP) Ê®°ÂûãÁöÑÊÄßËÉΩÔºåÁâπÂà´ÊòØÂú®ÈíàÂØπÊó∂Â∞öÊô∫ËÉΩÈ¢ÜÂüüÁöÑË∑®Ê®°ÊÄÅÊêúÁ¥¢‰∏≠„ÄÇÊ≠§ÊñπÊ≥ï‰æßÈáç‰∫éËß£ÂÜ≥Êï∞ÊçÆÂèØÁî®ÊÄßÊúâÈôêÂíåÂõæÂÉèË¥®Èáè‰Ωé‰∏ãÁöÑÊåëÊàò„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆóÊ≥ïÔºåËØ•ÁÆóÊ≥ïÊ∂âÂèäËÆ≠ÁªÉÂíåÈõÜÊàê CLIP Ê®°ÂûãÁöÑÂ§ö‰∏™ÂÆû‰æãÔºåÂπ∂Âà©Áî®ËÅöÁ±ªÊäÄÊúØÂ∞ÜÁõ∏‰ººÁöÑÂõæÂÉèÂàÜÁªÑÂú®‰∏ÄËµ∑„ÄÇÊú¨Á†îÁ©∂‰∏≠ÊèêÂá∫ÁöÑÂÆûÈ™åÁªìÊûúËØÅÊòé‰∫ÜËØ•ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇËøôÁßçÊñπÊ≥ïÈáäÊîæ‰∫Ü CLIP Âú®Êó∂Â∞öÊô∫ËÉΩÈ¢ÜÂüü‰∏≠ÁöÑÊΩúÂäõÔºåËÄåÊï∞ÊçÆÁ®ÄÁº∫ÂíåÂõæÂÉèË¥®ÈáèÈóÆÈ¢òÂæàÊôÆÈÅç„ÄÇÊÄª‰ΩìËÄåË®ÄÔºåENCLIP ÊñπÊ≥ï‰ª£Ë°®‰∫ÜÂØπÊó∂Â∞öÊô∫ËÉΩÈ¢ÜÂüüÁöÑÂÆùË¥µË¥°ÁåÆÔºåÂπ∂‰∏∫Âú®Êï∞ÊçÆÊúâÈôêÂíåÂõæÂÉèË¥®Èáè‰Ωé‰∏ãÁöÑÊÉÖÂÜµ‰∏ã‰ºòÂåñ CLIP Ê®°ÂûãÊèê‰æõ‰∫ÜÂÆûÁî®ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

##### **HiDP: Hierarchical DNN Partitioning for Distributed Inference on Heterogeneous Edge Platforms**
2411.16086v1 by Zain Taufique, Aman Vyas, Antonio Miele, Pasi Liljeberg, Anil Kanduri

Edge inference techniques partition and distribute Deep Neural Network (DNN)
inference tasks among multiple edge nodes for low latency inference, without
considering the core-level heterogeneity of edge nodes. Further, default DNN
inference frameworks also do not fully utilize the resources of heterogeneous
edge nodes, resulting in higher inference latency. In this work, we propose a
hierarchical DNN partitioning strategy (HiDP) for distributed inference on
heterogeneous edge nodes. Our strategy hierarchically partitions DNN workloads
at both global and local levels by considering the core-level heterogeneity of
edge nodes. We evaluated our proposed HiDP strategy against relevant
distributed inference techniques over widely used DNN models on commercial edge
devices. On average our strategy achieved 38% lower latency, 46% lower energy,
and 56% higher throughput in comparison with other relevant approaches.

ÊëòË¶ÅÔºöÈÇäÁ∑£Êé®ÁêÜÊäÄË°ìÂ∞áÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) Êé®Ë´ñ‰ªªÂãôÂàÜÂâ≤‰∏¶ÂàÜÈÖçÁµ¶Â§öÂÄãÈÇäÁ∑£ÁØÄÈªû‰ª•ÈÄ≤Ë°å‰ΩéÂª∂ÈÅ≤Êé®ÁêÜÔºåËÄå‰∏çÊúÉËÄÉÊÖÆÈÇäÁ∑£ÁØÄÈªûÁöÑÊ†∏ÂøÉÂ±§Á¥öÁï∞Ë≥™ÊÄß„ÄÇÊ≠§Â§ñÔºåÈ†êË®≠ÁöÑ DNN Êé®Ë´ñÊ°ÜÊû∂‰πü‰∏çÊúÉÂÆåÂÖ®Âà©Áî®Áï∞Ë≥™ÈÇäÁ∑£ÁØÄÈªûÁöÑË≥áÊ∫êÔºåÂ∞éËá¥Êõ¥È´òÁöÑÊé®Ë´ñÂª∂ÈÅ≤„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞çÁï∞Ë≥™ÈÇäÁ∑£ÁØÄÈªûÁöÑÂàÜÂ∏ÉÂºèÊé®Ë´ñÂàÜÂ±§ DNN ÂàÜÂâ≤Á≠ñÁï• (HiDP)„ÄÇÊàëÂÄëÁöÑÁ≠ñÁï•ÈÄèÈÅéËÄÉÊÖÆÈÇäÁ∑£ÁØÄÈªûÁöÑÊ†∏ÂøÉÂ±§Á¥öÁï∞Ë≥™ÊÄßÔºåÂú®ÂÖ®ÁêÉÂíåÂ±ÄÈÉ®Â±§Á¥öÂàÜÂ±§ÂàÜÂâ≤ DNN Â∑•‰ΩúË≤†Ëºâ„ÄÇÊàëÂÄëÈáùÂ∞çÂª£Ê≥õ‰ΩøÁî®ÁöÑ DNN Ê®°ÂûãË©ï‰º∞‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑ HiDP Á≠ñÁï•ËàáÁõ∏ÈóúÁöÑÂàÜÂ∏ÉÂºèÊé®Ë´ñÊäÄË°ìÂú®ÂïÜÁî®ÈÇäÁ∑£Ë£ùÁΩÆ‰∏äÁöÑË°®Áèæ„ÄÇÂπ≥ÂùáËÄåË®ÄÔºåÊàëÂÄëÁöÑÁ≠ñÁï•ËàáÂÖ∂‰ªñÁõ∏ÈóúÊñπÊ≥ïÁõ∏ÊØîÔºåÂª∂ÈÅ≤Èôç‰Ωé‰∫Ü 38%ÔºåËÉΩËÄóÈôç‰Ωé‰∫Ü 46%Ôºå‰∏îÂêûÂêêÈáèÊèêÈ´ò‰∫Ü 56%„ÄÇ

##### **Deciphering genomic codes using advanced NLP techniques: a scoping review**
2411.16084v1 by Shuyan Cheng, Yishu Wei, Yiliang Zhou, Zihan Xu, Drew N Wright, Jinze Liu, Yifan Peng

Objectives: The vast and complex nature of human genomic sequencing data
presents challenges for effective analysis. This review aims to investigate the
application of Natural Language Processing (NLP) techniques, particularly Large
Language Models (LLMs) and transformer architectures, in deciphering genomic
codes, focusing on tokenization, transformer models, and regulatory annotation
prediction. The goal of this review is to assess data and model accessibility
in the most recent literature, gaining a better understanding of the existing
capabilities and constraints of these tools in processing genomic sequencing
data.
  Methods: Following Preferred Reporting Items for Systematic Reviews and
Meta-Analyses (PRISMA) guidelines, our scoping review was conducted across
PubMed, Medline, Scopus, Web of Science, Embase, and ACM Digital Library.
Studies were included if they focused on NLP methodologies applied to genomic
sequencing data analysis, without restrictions on publication date or article
type.
  Results: A total of 26 studies published between 2021 and April 2024 were
selected for review. The review highlights that tokenization and transformer
models enhance the processing and understanding of genomic data, with
applications in predicting regulatory annotations like transcription-factor
binding sites and chromatin accessibility.
  Discussion: The application of NLP and LLMs to genomic sequencing data
interpretation is a promising field that can help streamline the processing of
large-scale genomic data while also providing a better understanding of its
complex structures. It has the potential to drive advancements in personalized
medicine by offering more efficient and scalable solutions for genomic
analysis. Further research is also needed to discuss and overcome current
limitations, enhancing model transparency and applicability.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÊ®ôÔºö‰∫∫È°ûÂü∫Âõ†ÁµÑÂÆöÂ∫èË≥áÊñôÁöÑÂª£Ê≥õ‰∏îË§áÈõúÁöÑÊÄßË≥™ÁÇ∫ÊúâÊïàÂàÜÊûêÂ∏∂‰æÜÊåëÊà∞„ÄÇÊú¨ÁØáË©ïË´ñÊó®Âú®Êé¢Ë®éËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊäÄË°ìÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÂ§ßË™ûË®ÄÊ®°Âûã (LLM) ÂíåTransformerÊû∂ÊßãÔºåÂú®Á†¥Ë≠ØÂü∫Âõ†ÁµÑÂØÜÁ¢º‰∏≠ÁöÑÊáâÁî®ÔºåÈáçÈªûÈóúÊ≥®ÂàÜË©û„ÄÅTransformerÊ®°ÂûãÂíåË™øÊéßË®ªÈáãÈ†êÊ∏¨„ÄÇÊú¨ÁØáË©ïË´ñÁöÑÁõÆÊ®ôÊòØË©ï‰º∞ÊúÄÊñ∞ÊñáÁçª‰∏≠ÁöÑË≥áÊñôÂíåÊ®°ÂûãÂèØÂèäÊÄßÔºå‰ª•Êõ¥Ê∑±ÂÖ•‰∫ÜËß£ÈÄô‰∫õÂ∑•ÂÖ∑Âú®ËôïÁêÜÂü∫Âõ†ÁµÑÂÆöÂ∫èË≥áÊñôÊñπÈù¢ÁöÑÁèæÊúâËÉΩÂäõÂíåÈôêÂà∂„ÄÇ
ÊñπÊ≥ïÔºöÈÅµÂæ™Á≥ªÁµ±ÊÄßÂõûÈ°ßÂíåÂæåË®≠ÂàÜÊûêÁöÑÈ¶ñÈÅ∏Â†±ÂëäÈ†ÖÁõÆ (PRISMA) ÊåáÂçóÔºåÊàëÂÄëÁöÑÁØÑÂúçÂõûÈ°ßÂú® PubMed„ÄÅMedline„ÄÅScopus„ÄÅWeb of Science„ÄÅEmbase Âíå ACM Êï∏‰ΩçÂúñÊõ∏È§®‰∏≠ÈÄ≤Ë°å„ÄÇÂ¶ÇÊûúÁ†îÁ©∂ÈáçÈªûÊòØÊáâÁî®ÊñºÂü∫Âõ†ÁµÑÂÆöÂ∫èË≥áÊñôÂàÜÊûêÁöÑ NLP ÊñπÊ≥ïÔºåÂâáÁ¥çÂÖ•Á†îÁ©∂ÔºåËÄå‰∏çÈôêÂà∂ÁôºË°®Êó•ÊúüÊàñÊñáÁ´†È°ûÂûã„ÄÇ
ÁµêÊûúÔºöÂÖ±ÈÅ∏Âá∫ 2021 Âπ¥Ëá≥ 2024 Âπ¥ 4 ÊúàÈñìÁôºË°®ÁöÑ 26 ÁØáÁ†îÁ©∂ÈÄ≤Ë°åÂõûÈ°ß„ÄÇÂõûÈ°ßÂº∑Ë™øÔºåÂàÜË©ûÂíåTransformerÊ®°ÂûãÂ¢ûÂº∑‰∫ÜÂü∫Âõ†ÁµÑË≥áÊñôÁöÑËôïÁêÜÂíåÁêÜËß£Ôºå‰∏¶ÊáâÁî®ÊñºÈ†êÊ∏¨ËΩâÈåÑÂõ†Â≠êÁµêÂêà‰ΩçÈªûÂíåÊüìËâ≤Ë≥™ÂèØÂèäÊÄßÁ≠âË™øÊéßË®ªÈáã„ÄÇ
Ë®éË´ñÔºöÂ∞á NLP Âíå LLM ÊáâÁî®ÊñºÂü∫Âõ†ÁµÑÂÆöÂ∫èË≥áÊñôËß£ËÆÄÊòØ‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÈ†òÂüüÔºåÊúâÂä©ÊñºÁ∞°ÂåñÂ§ßË¶èÊ®°Âü∫Âõ†ÁµÑË≥áÊñôÁöÑËôïÁêÜÔºåÂêåÊôÇ‰πüÊõ¥Ê∑±ÂÖ•‰∫ÜËß£ÂÖ∂Ë§áÈõúÁµêÊßã„ÄÇÂÆÉÊúâÊΩõÂäõÈÄèÈÅéÊèê‰æõÊõ¥ÊúâÊïàÁéá‰∏îÂèØÊì¥ÂÖÖÁöÑÂü∫Âõ†ÁµÑÂàÜÊûêËß£Ê±∫ÊñπÊ°àÔºåÊé®ÂãïÂÄã‰∫∫ÂåñÈÜ´ÁôÇÁöÑÈÄ≤Ê≠•„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂‰πüÈúÄË¶ÅË®éË´ñ‰∏¶ÂÖãÊúçÁõÆÂâçÁöÑÈôêÂà∂Ôºå‰ª•Â¢ûÂº∑Ê®°ÂûãÁöÑÈÄèÊòéÂ∫¶ÂíåÈÅ©Áî®ÊÄß„ÄÇ</paragraph>

##### **Boosting 3D Object Generation through PBR Materials**
2411.16080v1 by Yitong Wang, Xudong Xu, Li Ma, Haoran Wang, Bo Dai

Automatic 3D content creation has gained increasing attention recently, due
to its potential in various applications such as video games, film industry,
and AR/VR. Recent advancements in diffusion models and multimodal models have
notably improved the quality and efficiency of 3D object generation given a
single RGB image. However, 3D objects generated even by state-of-the-art
methods are still unsatisfactory compared to human-created assets. Considering
only textures instead of materials makes these methods encounter challenges in
photo-realistic rendering, relighting, and flexible appearance editing. And
they also suffer from severe misalignment between geometry and high-frequency
texture details. In this work, we propose a novel approach to boost the quality
of generated 3D objects from the perspective of Physics-Based Rendering (PBR)
materials. By analyzing the components of PBR materials, we choose to consider
albedo, roughness, metalness, and bump maps. For albedo and bump maps, we
leverage Stable Diffusion fine-tuned on synthetic data to extract these values,
with novel usages of these fine-tuned models to obtain 3D consistent albedo UV
and bump UV for generated objects. In terms of roughness and metalness maps, we
adopt a semi-automatic process to provide room for interactive adjustment,
which we believe is more practical. Extensive experiments demonstrate that our
model is generally beneficial for various state-of-the-art generation methods,
significantly boosting the quality and realism of their generated 3D objects,
with natural relighting effects and substantially improved geometry.

ÊëòË¶ÅÔºö<paragraph>Ëá™Âãï 3D ÂÖßÂÆπÂâµ‰ΩúËøëÂπ¥‰æÜÂÇôÂèóÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÂÆÉÂú®ÂêÑÁ®ÆÊáâÁî®‰∏≠ÂÖ∑ÊúâÊΩõÂäõÔºå‰æãÂ¶ÇË¶ñË®äÈÅäÊà≤„ÄÅÈõªÂΩ±Áî¢Ê•≠Âíå AR/VR„ÄÇÊì¥Êï£Ê®°ÂûãÂíåÂ§öÊ®°ÊÖãÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈ°ØËëóÊèêÂçá‰∫ÜÊ†πÊìöÂñÆ‰∏Ä RGB ÂΩ±ÂÉèÁîüÊàê 3D Áâ©‰ª∂ÁöÑÂìÅË≥™ÂíåÊïàÁéá„ÄÇÁÑ∂ËÄåÔºåÂç≥‰ΩøÊòØ‰ΩøÁî®ÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁîüÊàêÁöÑ 3D Áâ©‰ª∂ÔºåËàá‰∫∫Â∑•Âª∫Á´ãÁöÑË≥áÁî¢Áõ∏ÊØî‰ªç‰∏çÁõ°ÁêÜÊÉ≥„ÄÇÈÄô‰∫õÊñπÊ≥ïÂÉÖËÄÉÊÖÆÁ¥ãÁêÜËÄåÈùûÊùêË≥™ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂú®ÂØ´ÂØ¶Ê∏≤Êüì„ÄÅÈáçÊñ∞ÊâìÂÖâÂíåÂΩàÊÄßÂ§ñËßÄÁ∑®ËºØÊñπÈù¢ÈÅ≠ÈÅáÊåëÊà∞„ÄÇËÄå‰∏îÂÆÉÂÄëÈÇÑÂ≠òÂú®Âπæ‰ΩïÂΩ¢ÁãÄÂíåÈ´òÈ†ªÁéáÁ¥ãÁêÜÁ¥∞ÁØÄ‰πãÈñìÂö¥ÈáçÁöÑÈåØ‰Ωç„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂæûÂü∫ÊñºÁâ©ÁêÜÁöÑÊ∏≤Êüì (PBR) ÊùêË≥™ÁöÑËßíÂ∫¶ÊèêÂçáÁîüÊàê 3D Áâ©‰ª∂ÁöÑÂìÅË≥™„ÄÇÈÄèÈÅéÂàÜÊûê PBR ÊùêË≥™ÁöÑÁµÑÊàêÔºåÊàëÂÄëÈÅ∏ÊìáËÄÉÊÖÆÊº´ÂèçÂ∞ÑÁéá„ÄÅÁ≤óÁ≥ôÂ∫¶„ÄÅÈáëÂ±¨Â∫¶ÂíåÂáπÂá∏Ë≤ºÂúñ„ÄÇÂ∞çÊñºÊº´ÂèçÂ∞ÑÁéáÂíåÂáπÂá∏Ë≤ºÂúñÔºåÊàëÂÄëÂà©Áî®Âú®ÂêàÊàêË≥áÊñô‰∏äÂæÆË™øÁöÑ Stable Diffusion ‰æÜÊèêÂèñÈÄô‰∫õÂÄºÔºå‰∏¶ÂâµÊñ∞‰ΩøÁî®ÈÄô‰∫õÂæÆË™øÊ®°Âûã‰æÜÂèñÂæóÁîüÊàêÁâ©‰ª∂ÁöÑ 3D ‰∏ÄËá¥Êº´ÂèçÂ∞ÑÁéá UV ÂíåÂáπÂá∏ UV„ÄÇÂú®Á≤óÁ≥ôÂ∫¶ÂíåÈáëÂ±¨Â∫¶Ë≤ºÂúñÊñπÈù¢ÔºåÊàëÂÄëÊé°Áî®ÂçäËá™ÂãïÁöÑÊµÅÁ®ã‰æÜÊèê‰æõ‰∫íÂãïË™øÊï¥ÁöÑÁ©∫ÈñìÔºåÊàëÂÄëÁõ∏‰ø°ÈÄôÊõ¥ÂØ¶Áî®„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÄöÂ∏∏ÊúâÂà©ÊñºÂêÑÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑÁîüÊàêÊñπÊ≥ïÔºåÈ°ØËëóÊèêÂçáÂÖ∂ÁîüÊàê 3D Áâ©‰ª∂ÁöÑÂìÅË≥™ÂíåÁúüÂØ¶ÊÑüÔºåÂÖ∑ÊúâËá™ÁÑ∂ÁöÑÈáçÊñ∞ÊâìÂÖâÊïàÊûúÂíåÂ§ßÂπÖÊîπÂñÑÁöÑÂπæ‰ΩïÂΩ¢ÁãÄ„ÄÇ</paragraph>

##### **Debiasing Classifiers by Amplifying Bias with Latent Diffusion and Large Language Models**
2411.16079v1 by Donggeun Ko, Dongjun Lee, Namjun Park, Wonkyeong Shim, Jaekwang Kim

Neural networks struggle with image classification when biases are learned
and misleads correlations, affecting their generalization and performance.
Previous methods require attribute labels (e.g. background, color) or utilizes
Generative Adversarial Networks (GANs) to mitigate biases. We introduce
DiffuBias, a novel pipeline for text-to-image generation that enhances
classifier robustness by generating bias-conflict samples, without requiring
training during the generation phase. Utilizing pretrained diffusion and image
captioning models, DiffuBias generates images that challenge the biases of
classifiers, using the top-$K$ losses from a biased classifier ($f_B$) to
create more representative data samples. This method not only debiases
effectively but also boosts classifier generalization capabilities. To the best
of our knowledge, DiffuBias is the first approach leveraging a stable diffusion
model to generate bias-conflict samples in debiasing tasks. Our comprehensive
experimental evaluations demonstrate that DiffuBias achieves state-of-the-art
performance on benchmark datasets. We also conduct a comparative analysis of
various generative models in terms of carbon emissions and energy consumption
to highlight the significance of computational efficiency.

ÊëòË¶ÅÔºöÁ•ûÁ∂ìÁ∂≤Ë∑ØÂú®Â≠∏ÁøíÂÅèÂ∑ÆÊôÇÊúÉÂú®ÂΩ±ÂÉèÂàÜÈ°û‰∏äÈÅ≠ÈÅáÂõ∞Èõ£Ôºå‰∏¶Ë™§Â∞éÁõ∏ÈóúÊÄßÔºåÂΩ±ÈüøÂÖ∂Ê¶ÇÂåñÂíåÊïàËÉΩ„ÄÇ
ÂÖàÂâçÁöÑÂÅöÊ≥ïÈúÄË¶ÅÂ±¨ÊÄßÊ®ôÁ±§Ôºà‰æãÂ¶ÇËÉåÊôØ„ÄÅÈ°èËâ≤ÔºâÊàñÂà©Áî®ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN) ‰æÜÊ∏õËºïÂÅèÂ∑Æ„ÄÇÊàëÂÄëÂºïÈÄ≤ DiffuBiasÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÊñáÂ≠óËΩâÂΩ±ÂÉèÁîüÊàêÁöÑÊñ∞Á©éÁÆ°Á∑öÔºåÈÄèÈÅéÁî¢ÁîüÂÅèÂ∑ÆË°ùÁ™ÅÊ®£Êú¨‰æÜÂ¢ûÂº∑ÂàÜÈ°ûÂô®ÁöÑÁ©©ÂÅ•ÊÄßÔºåËÄå‰∏çÈúÄË¶ÅÂú®ÁîüÊàêÈöéÊÆµÈÄ≤Ë°åË®ìÁ∑¥„ÄÇDiffuBias Âà©Áî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑÊì¥Êï£ÂíåÂΩ±ÂÉèÊ®ôÈ°åÊ®°ÂûãÔºåÁî¢ÁîüÊåëÊà∞ÂàÜÈ°ûÂô®ÂÅèÂ∑ÆÁöÑÂΩ±ÂÉèÔºå‰ΩøÁî®ÊúâÂÅèÂ∑ÆÂàÜÈ°ûÂô® ($f_B$) ‰∏≠ÁöÑÈ†ÇÁ´Ø-$K$ ÊêçÂ§±‰æÜÂª∫Á´ãÊõ¥ÂÖ∑‰ª£Ë°®ÊÄßÁöÑË≥áÊñôÊ®£Êú¨„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰∏çÂÉÖËÉΩÊúâÊïàÊ∂àÈô§ÂÅèÂ∑ÆÔºåÈÇÑËÉΩÊèêÂçáÂàÜÈ°ûÂô®ÁöÑÊ¶ÇÂåñËÉΩÂäõ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåDiffuBias ÊòØÁ¨¨‰∏ÄÂÄãÂà©Áî®Á©©ÂÆöÁöÑÊì¥Êï£Ê®°ÂûãÂú®ÂéªÂÅèÂ∑Æ‰ªªÂãô‰∏≠Áî¢ÁîüÂÅèÂ∑ÆË°ùÁ™ÅÊ®£Êú¨ÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÂÖ®Èù¢ÁöÑÂØ¶È©óË©ï‰º∞Ë≠âÊòéÔºåDiffuBias Âú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÈÇÑÂ∞çÂêÑÁ®ÆÁîüÊàêÊ®°ÂûãÂú®Á¢≥ÊéíÊîæÂíåËÉΩÊ∫êÊ∂àËÄóÊñπÈù¢ÁöÑÈÄ≤Ë°åÊØîËºÉÂàÜÊûêÔºå‰ª•Âº∑Ë™øÈÅãÁÆóÊïàÁéáÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **SAGEval: The frontiers of Satisfactory Agent based NLG Evaluation for reference-free open-ended text**
2411.16077v1 by Reshmi Ghosh, Tianyi Yao, Lizzy Chen, Sadid Hasan, Tianwei Chen, Dario Bernal, Huitian Jiao, H M Sajjad Hossain

Large Language Model (LLM) integrations into applications like Microsoft365
suite and Google Workspace for creating/processing documents, emails,
presentations, etc. has led to considerable enhancements in productivity and
time savings. But as these integrations become more more complex, it is
paramount to ensure that the quality of output from the LLM-integrated
applications are relevant and appropriate for use. Identifying the need to
develop robust evaluation approaches for natural language generation, wherein
references/ground labels doesn't exist or isn't amply available, this paper
introduces a novel framework called "SAGEval" which utilizes a critiquing Agent
to provide feedback on scores generated by LLM evaluators. We show that the
critiquing Agent is able to rectify scores from LLM evaluators, in absence of
references/ground-truth labels, thereby reducing the need for labeled data even
for complex NLG evaluation scenarios, like the generation of JSON-structured
forms/surveys with responses in different styles like multiple choice, likert
ratings, single choice questions, etc.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂà∞ Microsoft365 Â•ó‰ª∂Âíå Google Workspace Á≠âÊáâÁî®Á®ãÂºè‰∏≠ÔºåÁî®ÊñºÂª∫Á´ã/ËôïÁêÜÊñá‰ª∂„ÄÅÈõªÂ≠êÈÉµ‰ª∂„ÄÅÁ∞°Â†±Á≠âÁ≠âÔºåÈÄôÂ∑≤Á∂ìÂ§ßÂπÖÊèêÂçá‰∫ÜÁîüÁî¢Âäõ‰∏¶ÁØÄÁúÅÊôÇÈñì„ÄÇ‰ΩÜÊòØÈö®ËëóÈÄô‰∫õÊï¥ÂêàËÆäÂæóË∂ä‰æÜË∂äË§áÈõúÔºåÊúÄÈáçË¶ÅÁöÑÊòØË¶ÅÁ¢∫‰øù LLM Êï¥ÂêàÊáâÁî®Á®ãÂºèËº∏Âá∫ÁöÑÂìÅË≥™Ëàá‰ΩøÁî®ÁõÆÁöÑÁõ∏Èóú‰∏îÈÅ©Áï∂„ÄÇÊú¨Ë´ñÊñáËæ®Ë≠òÂá∫ÈñãÁôºÂÅ•ÂÖ®Ëá™ÁÑ∂Ë™ûË®ÄÁî¢ÁîüË©ï‰º∞ÊñπÊ≥ïÁöÑÈúÄÊ±ÇÔºåÂÖ∂‰∏≠ÂèÉËÄÉ/Âü∫Á§éÊ®ôÁ±§‰∏çÂ≠òÂú®ÊàñÁÑ°Ê≥ïÂÖÖÂàÜÂèñÂæóÔºåÂõ†Ê≠§‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫„ÄåSAGEval„ÄçÁöÑÊñ∞Êû∂ÊßãÔºåÂÆÉÂà©Áî®ÊâπË©ï‰ª£ÁêÜÊèê‰æõ LLM Ë©ï‰º∞Âô®Áî¢ÁîüÁöÑÂàÜÊï∏ÂõûÈ•ã„ÄÇÊàëÂÄëÂ±ïÁ§∫Âá∫Âú®Ê≤íÊúâÂèÉËÄÉ/Âü∫Á§éÁúüÂØ¶Ê®ôÁ±§ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊâπË©ï‰ª£ÁêÜËÉΩÂ§†‰øÆÊ≠£ LLM Ë©ï‰º∞Âô®ÁöÑÂàÜÊï∏ÔºåÂõ†Ê≠§Âç≥‰ΩøÂ∞çÊñºË§áÈõúÁöÑ NLG Ë©ï‰º∞ÊÉÖÂ¢ÉÔºå‰æãÂ¶ÇÁî¢ÁîüÂÖ∑Êúâ‰∏çÂêåÊ®£ÂºèÁöÑÂõûÊáâÔºà‰æãÂ¶ÇÂ§öÈáçÈÅ∏Êìá„ÄÅÊùéÂÖãÁâπÈáèË°®„ÄÅÂñÆÈÅ∏È°åÁ≠âÁ≠âÔºâÁöÑ JSON ÁµêÊßãÂåñË°®ÂñÆ/Ë™øÊü•Ôºå‰πüËÉΩÊ∏õÂ∞ëÊ®ôË®òË≥áÊñôÁöÑÈúÄÊ±Ç„ÄÇ

##### **The brain versus AI: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum**
2411.16075v1 by Shogo Ohmae, Keiko Ohmae

AI's significant recent advances using general-purpose circuit computations
offer a potential window into how the neocortex and cerebellum of the brain are
able to achieve a diverse range of functions across sensory, cognitive, and
motor domains, despite their uniform circuit structures. However, comparing the
brain and AI is challenging unless clear similarities exist, and past reviews
have been limited to comparison of brain-inspired vision AI and the visual
neocortex. Here, to enable comparisons across diverse functional domains, we
subdivide circuit computation into three elements -- circuit structure,
input/outputs, and the learning algorithm -- and evaluate the similarities for
each element. With this novel approach, we identify wide-ranging similarities
and convergent evolution in the brain and AI, providing new insights into key
concepts in neuroscience. Furthermore, inspired by processing mechanisms of AI,
we propose a new theory that integrates established neuroscience theories,
particularly the theories of internal models and the mirror neuron system. Both
the neocortex and cerebellum predict future world events from past information
and learn from prediction errors, thereby acquiring models of the world. These
models enable three core processes: (1) Prediction -- generating future
information, (2) Understanding -- interpreting the external world via
compressed and abstracted sensory information, and (3) Generation --
repurposing the future-information generation mechanism to produce other types
of outputs. The universal application of these processes underlies the ability
of the neocortex and cerebellum to accomplish diverse functions with uniform
circuits. Our systematic approach, insights, and theory promise groundbreaking
advances in understanding the brain.

ÊëòË¶ÅÔºö<paragraph>AI ËøëÊúüÂú®ÈÄöÁî®ÈõªË∑ØÈÅãÁÆó‰∏äÂèñÂæóÈáçÂ§ßÈÄ≤Â±ïÔºå
Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊΩõÂú®Á™óÂè£ÔºåËÆìÊàëÂÄëÂæó‰ª•‰∫ÜËß£Â§ßËÖ¶ÁöÑÊñ∞ÁöÆË≥™ÂíåÂ∞èËÖ¶Â¶Ç‰Ωï
Âú®ÊÑüÂÆò„ÄÅË™çÁü•ÂíåÈÅãÂãïÈ†òÂüüÂØ¶ÁèæÂêÑÁ®ÆÂäüËÉΩÔºåÂÑòÁÆ°ÂÆÉÂÄëÁöÑÈõªË∑ØÁµêÊßãÊòØÁµ±‰∏ÄÁöÑ„ÄÇÁÑ∂ËÄåÔºåÈô§ÈùûÂ≠òÂú®ÊòéÁ¢∫ÁöÑÁõ∏‰ººÊÄßÔºåÂê¶ÂâáÊØîËºÉÂ§ßËÖ¶Âíå AI ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåËÄå‰∏îÈÅéÂéªÁöÑË©ïË´ñÂÉÖÈôêÊñºÊØîËºÉÂèóÂ§ßËÖ¶ÂïüÁôºÁöÑË¶ñË¶∫ AI ÂíåË¶ñË¶∫Êñ∞ÁöÆË≥™„ÄÇÂú®Ê≠§ÔºåÁÇ∫‰∫ÜËÉΩÂ§†Âú®‰∏çÂêåÁöÑÂäüËÉΩÈ†òÂüüÈÄ≤Ë°åÊØîËºÉÔºåÊàëÂÄëÂ∞áÈõªË∑ØÈÅãÁÆóÁ¥∞ÂàÜÁÇ∫‰∏âÂÄãË¶ÅÁ¥†‚Äî‚ÄîÈõªË∑ØÁµêÊßã„ÄÅËº∏ÂÖ•/Ëº∏Âá∫ÂíåÂ≠∏ÁøíÊºîÁÆóÊ≥ï‚Äî‚Äî‰∏¶Ë©ï‰º∞ÊØèÂÄãË¶ÅÁ¥†ÁöÑÁõ∏‰ººÊÄß„ÄÇÈÄèÈÅéÈÄôÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÁôºÁèæ‰∫ÜÂ§ßËÖ¶Âíå AI ‰πãÈñìÂª£Ê≥õÁöÑÁõ∏‰ººÊÄßÂíåË∂®ÂêåÊºîÂåñÔºåÁÇ∫Á•ûÁ∂ìÁßëÂ≠∏‰∏≠ÁöÑÈóúÈçµÊ¶ÇÂøµÊèê‰æõ‰∫ÜÊñ∞ÁöÑË¶ãËß£„ÄÇÊ≠§Â§ñÔºåÂèóÂà∞ AI ËôïÁêÜÊ©üÂà∂ÁöÑÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁêÜË´ñÔºåÊï¥Âêà‰∫ÜÊó¢ÂÆöÁöÑÁ•ûÁ∂ìÁßëÂ≠∏ÁêÜË´ñÔºåÁâπÂà•ÊòØÂÖßÈÉ®Ê®°ÂûãÁêÜË´ñÂíåÈè°ÂÉèÁ•ûÁ∂ìÂÖÉÁ≥ªÁµ±ÁêÜË´ñ„ÄÇÊñ∞ÁöÆË≥™ÂíåÂ∞èËÖ¶ÈÉΩÊ†πÊìöÈÅéÂéªÁöÑË≥áË®äÈ†êÊ∏¨Êú™‰æÜÁöÑ‰∏ñÁïå‰∫ã‰ª∂Ôºå‰∏¶ÂæûÈ†êÊ∏¨Ë™§Â∑Æ‰∏≠Â≠∏ÁøíÔºåÂæûËÄåÁç≤Âæó‰∏ñÁïåÁöÑÊ®°Âûã„ÄÇÈÄô‰∫õÊ®°ÂûãÂïüÁî®‰∫Ü‰∏âÂÄãÊ†∏ÂøÉÊµÅÁ®ãÔºö(1) È†êÊ∏¨‚Äî‚ÄîÁî¢ÁîüÊú™‰æÜË≥áË®äÔºå(2) ÁêÜËß£‚Äî‚ÄîÈÄèÈÅéÂ£ìÁ∏ÆÂíåÊäΩË±°ÁöÑÊÑüÂÆòË≥áË®ä‰æÜË©ÆÈáãÂ§ñÈÉ®‰∏ñÁïåÔºå‰ª•Âèä (3) ÁîüÊàê‚Äî‚ÄîÈáçÊñ∞Âà©Áî®Êú™‰æÜË≥áË®äÁîüÊàêÊ©üÂà∂‰æÜÁî¢ÁîüÂÖ∂‰ªñÈ°ûÂûãÁöÑËº∏Âá∫„ÄÇÈÄô‰∫õÊµÅÁ®ãÁöÑÈÄöÁî®ÊáâÁî®ÊòØÊñ∞ÁöÆË≥™ÂíåÂ∞èËÖ¶ËÉΩÂ§†‰ΩøÁî®Áµ±‰∏ÄÈõªË∑ØÂÆåÊàêÂ§öÁ®ÆÂäüËÉΩÁöÑÂü∫Á§é„ÄÇÊàëÂÄëÁ≥ªÁµ±ÊÄßÁöÑÊñπÊ≥ï„ÄÅË¶ãËß£ÂíåÁêÜË´ñÊúâÊúõÂú®ÁêÜËß£Â§ßËÖ¶ÊñπÈù¢ÂèñÂæóÁ™ÅÁ†¥ÊÄßÁöÑÈÄ≤Â±ï„ÄÇ</paragraph>

##### **UnitedVLN: Generalizable Gaussian Splatting for Continuous Vision-Language Navigation**
2411.16053v1 by Guangzhao Dai, Jian Zhao, Yuantao Chen, Yusen Qin, Hao Zhao, Guosen Xie, Yazhou Yao, Xiangbo Shu, Xuelong Li

Vision-and-Language Navigation (VLN), where an agent follows instructions to
reach a target destination, has recently seen significant advancements. In
contrast to navigation in discrete environments with predefined trajectories,
VLN in Continuous Environments (VLN-CE) presents greater challenges, as the
agent is free to navigate any unobstructed location and is more vulnerable to
visual occlusions or blind spots. Recent approaches have attempted to address
this by imagining future environments, either through predicted future visual
images or semantic features, rather than relying solely on current
observations. However, these RGB-based and feature-based methods lack intuitive
appearance-level information or high-level semantic complexity crucial for
effective navigation. To overcome these limitations, we introduce a novel,
generalizable 3DGS-based pre-training paradigm, called UnitedVLN, which enables
agents to better explore future environments by unitedly rendering
high-fidelity 360 visual images and semantic features. UnitedVLN employs two
key schemes: search-then-query sampling and separate-then-united rendering,
which facilitate efficient exploitation of neural primitives, helping to
integrate both appearance and semantic information for more robust navigation.
Extensive experiments demonstrate that UnitedVLN outperforms state-of-the-art
methods on existing VLN-CE benchmarks.

ÊëòË¶ÅÔºöË¶ñË¶∫ÂíåË™ûË®ÄÂ∞éËà™ (VLN) ËÆì‰ª£ÁêÜ‰∫∫ÈÅµÂæ™ÊåáÁ§∫ÂâçÂæÄÁõÆÊ®ôÁõÆÁöÑÂú∞ÔºåÊúÄËøëÊúâ‰∫ÜÈ°ØËëóÁöÑÈÄ≤Â±ï„ÄÇËàáÂÖ∑ÊúâÈ†êÂÆöÁæ©ËªåË∑°ÁöÑÈõ¢Êï£Áí∞Â¢É‰∏≠ÁöÑÂ∞éËà™Áõ∏ÊØîÔºåÈÄ£Á∫åÁí∞Â¢É‰∏≠ÁöÑ VLN (VLN-CE) ÊèêÂá∫Êõ¥Â§ßÁöÑÊåëÊà∞ÔºåÂõ†ÁÇ∫‰ª£ÁêÜ‰∫∫ÂèØ‰ª•Ëá™Áî±Â∞éËà™‰ªª‰ΩïÁÑ°ÈöúÁ§ô‰ΩçÁΩÆÔºå‰∏¶‰∏îÊõ¥ÂÆπÊòìÂèóÂà∞Ë¶ñË¶∫ÈÅÆÊìãÊàñÁõ≤ÈªûÁöÑÂΩ±Èüø„ÄÇÊúÄËøëÁöÑÊñπÊ≥ïÂòóË©¶ÈÄöÈÅéÊÉ≥ÂÉèÊú™‰æÜÁöÑÁí∞Â¢ÉÔºàÈÄèÈÅéÈ†êÊ∏¨Êú™‰æÜÁöÑË¶ñË¶∫ÂΩ±ÂÉèÊàñË™ûÁæ©ÁâπÂæµÔºâ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåËÄå‰∏çÊòØÂÉÖ‰æùË≥¥ÁõÆÂâçÁöÑËßÄÂØü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂü∫Êñº RGB ÂíåÂü∫ÊñºÁâπÂæµÁöÑÊñπÊ≥ïÁº∫‰πèÊúâÊïàÁöÑÂ∞éËà™ÊâÄÈúÄÁöÑÁõ¥ËßÄÂ§ñËßÄÂ±§Á¥öË≥áË®äÊàñÈ´òÂ±§Á¥öË™ûÁæ©Ë§áÈõúÊÄß„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©é„ÄÅÂèØÊ¶ÇÊã¨ÁöÑÂü∫Êñº 3DGS ÁöÑÈ†êË®ìÁ∑¥ÁØÑ‰æãÔºåÁ®±ÁÇ∫ UnitedVLNÔºåÂÆÉ‰Ωø‰ª£ÁêÜ‰∫∫ËÉΩÂ§†ÈÄèÈÅéÁµ±‰∏ÄÂëàÁèæÈ´ò‰øùÁúü 360 Ë¶ñË¶∫ÂΩ±ÂÉèÂíåË™ûÁæ©ÁâπÂæµ‰æÜÊõ¥Â•ΩÂú∞Êé¢Á¥¢Êú™‰æÜÁöÑÁí∞Â¢É„ÄÇUnitedVLN Êé°Áî®ÂÖ©ÂÄãÈóúÈçµÊñπÊ°àÔºöÂÖàÊêúÂ∞ãÂÜçÊü•Ë©¢ÁöÑÊäΩÊ®£ÂíåÂÖàÂàÜÈñãÂÜçÁµ±‰∏ÄÁöÑÂëàÁèæÔºåÈÄôÊúâÂä©ÊñºÊúâÊïàÂà©Áî®Á•ûÁ∂ìÂü∫ÂÖÉÔºåÂπ´Âä©Êï¥ÂêàÂ§ñËßÄÂíåË™ûÁæ©Ë≥áË®ä‰ª•ÈÄ≤Ë°åÊõ¥Á©©ÂÅ•ÁöÑÂ∞éËà™„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåUnitedVLN Âú®ÁèæÊúâÁöÑ VLN-CE Âü∫Ê∫ñ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ

##### **Predicting Emergent Capabilities by Finetuning**
2411.16035v1 by Charlie Snell, Eric Wallace, Dan Klein, Sergey Levine

A fundamental open challenge in modern LLM scaling is the lack of
understanding around emergent capabilities. In particular, language model
pretraining loss is known to be highly predictable as a function of compute.
However, downstream capabilities are far less predictable -- sometimes even
exhibiting emergent jumps -- which makes it challenging to anticipate the
capabilities of future models. In this work, we first pose the task of
emergence prediction: given access to current LLMs that have random few-shot
accuracy on a task, can we predict whether future models (GPT-N+1) will have
non-trivial accuracy on that task? We then discover a simple insight for this
problem: finetuning LLMs on a given task can shift the point in scaling at
which emergence occurs towards less capable models. To operationalize this
insight, we can finetune LLMs with varying amounts of data and fit a parametric
function that predicts when emergence will occur (i.e., "emergence laws"). We
validate this approach using four standard NLP benchmarks where large-scale
open-source LLMs already demonstrate emergence (MMLU, GSM8K, CommonsenseQA, and
CoLA). Using only small-scale LLMs, we find that, in some cases, we can
accurately predict whether models trained with up to 4x more compute have
emerged. Finally, we present a case study of two realistic uses for emergence
prediction.

ÊëòË¶ÅÔºöÁèæ‰ª£ LLM Êì¥ÂÖÖÁöÑ‰∏ÄÂÄãÂü∫Êú¨ÂÖ¨ÈñãÊåëÊà∞ÊòØÁº∫‰πèÂ∞çÊñ∞ËààËÉΩÂäõÁöÑÁêÜËß£„ÄÇÁâπÂà•ÊòØÔºåË™ûË®ÄÊ®°ÂûãÈ†êË®ìÁ∑¥ÊêçÂ§±Â∑≤Áü•È´òÂ∫¶ÂèØÈ†êÊ∏¨ÁÇ∫Ë®àÁÆóÂáΩÊï∏„ÄÇÁÑ∂ËÄåÔºå‰∏ãÊ∏∏ËÉΩÂäõÁöÑÂèØÈ†êÊ∏¨ÊÄßÈÅ†‰ΩéÂæóÂ§öÔºåÊúâÊôÇÁîöËá≥Ë°®ÁèæÂá∫Êñ∞ËààË∑≥Ë∫çÔºåÈÄô‰ΩøÂæóÈ†êÊ∏¨Êú™‰æÜÊ®°ÂûãÁöÑËÉΩÂäõÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫Êñ∞ËààÈ†êÊ∏¨‰ªªÂãôÔºöÂú®Ë®™ÂïèÂÖ∑Êúâ‰ªªÂãô‰∏≠Èö®Ê©üÂ∞ëÊ¨°Ê∫ñÁ¢∫Â∫¶ÁöÑÁï∂Ââç LLM ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊàëÂÄëËÉΩÈ†êÊ∏¨Êú™‰æÜÊ®°Âûã (GPT-N+1) ÊòØÂê¶ÊúÉÂú®Ë©≤‰ªªÂãô‰∏≠ÂÖ∑ÊúâÈùûÂπ≥Âá°Ê∫ñÁ¢∫Â∫¶ÔºüÁÑ∂ÂæåÔºåÊàëÂÄëÁôºÁèæ‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆÁöÑË¶ãËß£‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºöÂú®ÁâπÂÆö‰ªªÂãô‰∏äÂæÆË™ø LLM ÂèØ‰ª•Â∞áÂá∫ÁèæÁôºÁîüÊôÇÁöÑÊì¥ÂÖÖÈªûËΩâÁßªÂà∞ÂäüËÉΩËºÉÂº±ÁöÑÊ®°Âûã„ÄÇÁÇ∫‰∫ÜÂ∞áÊ≠§Ë¶ãËß£‰ªòË´∏ÂØ¶ÊñΩÔºåÊàëÂÄëÂèØ‰ª•‰ΩøÁî®‰∏çÂêåÊï∏ÈáèÁöÑÊï∏ÊìöÂæÆË™ø LLMÔºå‰∏¶Êì¨ÂêàÂèÉÊï∏ÂáΩÊï∏‰æÜÈ†êÊ∏¨Êñ∞Ëàà‰ΩïÊôÇÊúÉÁôºÁîüÔºàÂç≥„ÄåÊñ∞ËààÂÆöÂæã„ÄçÔºâ„ÄÇÊàëÂÄë‰ΩøÁî®ÂõõÂÄãÊ®ôÊ∫ñ NLP Âü∫Ê∫ñÈ©óË≠âÊ≠§ÊñπÊ≥ïÔºåÂÖ∂‰∏≠Â§ßË¶èÊ®°ÈñãÊ∫ê LLM Â∑≤Â±ïÁ§∫Êñ∞ËààÔºàMMLU„ÄÅGSM8K„ÄÅÂ∏∏Ë≠òÂïèÁ≠îÂíå CoLAÔºâ„ÄÇÂÉÖ‰ΩøÁî®Â∞èË¶èÊ®° LLMÔºåÊàëÂÄëÁôºÁèæÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåÊàëÂÄëÂèØ‰ª•Ê∫ñÁ¢∫È†êÊ∏¨‰ΩøÁî®Â§öÈÅî 4 ÂÄçË®àÁÆóË®ìÁ∑¥ÁöÑÊ®°ÂûãÊòØÂê¶Â∑≤Âá∫Áèæ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåË™™ÊòéÊñ∞ËààÈ†êÊ∏¨ÁöÑÂÖ©ÂÄãÂØ¶ÈöõÁî®ÈÄî„ÄÇ

##### **From Dashcam Videos to Driving Simulations: Stress Testing Automated Vehicles against Rare Events**
2411.16027v1 by Yan Miao, Georgios Fainekos, Bardh Hoxha, Hideki Okamoto, Danil Prokhorov, Sayan Mitra

Testing Automated Driving Systems (ADS) in simulation with realistic driving
scenarios is important for verifying their performance. However, converting
real-world driving videos into simulation scenarios is a significant challenge
due to the complexity of interpreting high-dimensional video data and the
time-consuming nature of precise manual scenario reconstruction. In this work,
we propose a novel framework that automates the conversion of real-world car
crash videos into detailed simulation scenarios for ADS testing. Our approach
leverages prompt-engineered Video Language Models(VLM) to transform dashcam
footage into SCENIC scripts, which define the environment and driving behaviors
in the CARLA simulator, enabling the generation of realistic simulation
scenarios. Importantly, rather than solely aiming for one-to-one scenario
reconstruction, our framework focuses on capturing the essential driving
behaviors from the original video while offering flexibility in parameters such
as weather or road conditions to facilitate search-based testing. Additionally,
we introduce a similarity metric that helps iteratively refine the generated
scenario through feedback by comparing key features of driving behaviors
between the real and simulated videos. Our preliminary results demonstrate
substantial time efficiency, finishing the real-to-sim conversion in minutes
with full automation and no human intervention, while maintaining high fidelity
to the original driving events.

ÊëòË¶ÅÔºöÂú®Ê®°Êì¨‰∏≠‰ΩøÁî®ÈÄºÁúüÁöÑÈßïÈßõÊÉÖÂ¢ÉÊ∏¨Ë©¶Ëá™ÂãïÈßïÈßõÁ≥ªÁµ± (ADS) Â∞çÊñºÈ©óË≠âÂÖ∂ÊïàËÉΩÈùûÂ∏∏ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈõ£‰ª•Ë©ÆÈáãÈ´òÁ∂≠Â∫¶ÁöÑÂΩ±ÁâáË≥áÊñôÔºå‰ª•ÂèäÁ≤æÁ¢∫ÊâãÂãïÂ†¥ÊôØÈáçÂª∫ËÄóÊôÇÔºåÂ∞áÁúüÂØ¶‰∏ñÁïåÁöÑÈßïÈßõÂΩ±ÁâáËΩâÊèõÊàêÊ®°Êì¨Â†¥ÊôØÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊû∂ÊßãÔºåÂèØËá™ÂãïÂ∞áÁúüÂØ¶‰∏ñÁïåÁöÑÊ±ΩËªäÁ¢∞ÊíûÂΩ±ÁâáËΩâÊèõÊàê ADS Ê∏¨Ë©¶ÁöÑË©≥Á¥∞Ê®°Êì¨Â†¥ÊôØ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®ÊèêÁ§∫Â∑•Á®ãÂåñÂΩ±ÁâáË™ûË®ÄÊ®°Âûã (VLM) Â∞áË°åËªäË®òÈåÑÂô®Áï´Èù¢ËΩâÊèõÊàê SCENIC ËÖ≥Êú¨ÔºåÂÆöÁæ© CARLA Ê®°Êì¨Âô®‰∏≠ÁöÑÁí∞Â¢ÉÂíåÈßïÈßõË°åÁÇ∫ÔºåÈÄ≤ËÄåÁî¢ÁîüÈÄºÁúüÁöÑÊ®°Êì¨Â†¥ÊôØ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑÊû∂Êßã‰∏¶ÈùûÂÉÖ‰ª•‰∏ÄÂ∞ç‰∏ÄÁöÑÂ†¥ÊôØÈáçÂª∫ÁÇ∫ÁõÆÊ®ôÔºåËÄåÊòØÂ∞àÊ≥®ÊñºÊì∑ÂèñÂéüÂßãÂΩ±Áâá‰∏≠ÁöÑÂü∫Êú¨ÈßïÈßõË°åÁÇ∫ÔºåÂêåÊôÇÂú®Â§©Ê∞£ÊàñÈÅìË∑ØÁãÄÊ≥ÅÁ≠âÂèÉÊï∏‰∏≠Êèê‰æõÂΩàÊÄßÔºå‰ª•Âà©ÊñºÊêúÂ∞ãÂºèÊ∏¨Ë©¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁõ∏‰ººÂ∫¶ÈáèÊï∏ÔºåÊúâÂä©ÊñºÈÄèÈÅéÊØîËºÉÁúüÂØ¶ÂíåÊ®°Êì¨ÂΩ±Áâá‰∏≠ÈßïÈßõË°åÁÇ∫ÁöÑÈóúÈçµÁâπÂæµÔºåÂèçË¶ÜÊîπÂñÑÁî¢ÁîüÁöÑÂ†¥ÊôØ„ÄÇÊàëÂÄëÁöÑÂàùÊ≠•ÁµêÊûúË≠âÊòé‰∫ÜÂ§ßÂπÖÁöÑÁúÅÊôÇÊïàÁéáÔºåÂú®ÂÆåÂÖ®Ëá™ÂãïÂåñ‰∏îÁÑ°ÈúÄ‰∫∫Â∑•‰ªãÂÖ•ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊñºÊï∏ÂàÜÈêòÂÖßÂÆåÊàêÁúüÂØ¶Âà∞Ê®°Êì¨ÁöÑËΩâÊèõÔºåÂêåÊôÇÁ∂≠ÊåÅÂ∞çÂéüÂßãÈßïÈßõ‰∫ã‰ª∂ÁöÑÈ´òÂ∫¶‰øùÁúüÂ∫¶„ÄÇ

##### **TransCompressor: LLM-Powered Multimodal Data Compression for Smart Transportation**
2411.16020v1 by Huanqi Yang, Rucheng Wu, Weitao Xu

The incorporation of Large Language Models (LLMs) into smart transportation
systems has paved the way for improving data management and operational
efficiency. This study introduces TransCompressor, a novel framework that
leverages LLMs for efficient compression and decompression of multimodal
transportation sensor data. TransCompressor has undergone thorough evaluation
with diverse sensor data types, including barometer, speed, and altitude
measurements, across various transportation modes like buses, taxis, and MTRs.
Comprehensive evaluation illustrates the effectiveness of TransCompressor in
reconstructing transportation sensor data at different compression ratios. The
results highlight that, with well-crafted prompts, LLMs can utilize their vast
knowledge base to contribute to data compression processes, enhancing data
storage, analysis, and retrieval in smart transportation settings.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Á¥çÂÖ•Êô∫ÊÖßÈÅãËº∏Á≥ªÁµ±Â∑≤ÁÇ∫ÊîπÂñÑË≥áÊñôÁÆ°ÁêÜÂíåÁáüÈÅãÊïàÁéáÈã™Ë∑Ø„ÄÇÊú¨Á†îÁ©∂‰ªãÁ¥π TransCompressorÔºå‰∏ÄÂÄãÂà©Áî® LLM ÊúâÊïàÂ£ìÁ∏ÆÂíåËß£Â£ìÁ∏ÆÂ§öÊ®°ÊÖãÈÅãËº∏ÊÑüÊ∏¨Âô®Ë≥áÊñôÁöÑÊñ∞Á©éÊû∂Êßã„ÄÇTransCompressor Â∑≤ÈáùÂ∞çÂêÑÁ®ÆÊÑüÊ∏¨Âô®Ë≥áÊñôÈ°ûÂûãÈÄ≤Ë°åÂæπÂ∫ïË©ï‰º∞ÔºåÂåÖÊã¨Ê∞£Â£ìË®à„ÄÅÈÄüÂ∫¶ÂíåÈ´òÂ∫¶Ê∏¨ÈáèÔºåÊ∂µËìãÂÖ¨Ëªä„ÄÅË®àÁ®ãËªäÂíåÂú∞ÈêµÁ≠âÂêÑÁ®ÆÈÅãËº∏Ê®°Âºè„ÄÇÂÖ®Èù¢ÁöÑË©ï‰º∞Ë™™Êòé‰∫Ü TransCompressor Âú®‰ª•‰∏çÂêåÂ£ìÁ∏ÆÊØîÈáçÂª∫ÈÅãËº∏ÊÑüÊ∏¨Âô®Ë≥áÊñôÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁµêÊûúÂº∑Ë™øÔºåÈÄèÈÅéÁ≤æÂøÉË®≠Ë®àÁöÑÊèêÁ§∫ÔºåLLM ÂèØ‰ª•Âà©Áî®ÂÖ∂ÈæêÂ§ßÁöÑÁü•Ë≠òÂ∫´‰æÜÂçîÂä©Ë≥áÊñôÂ£ìÁ∏ÆÁ®ãÂ∫èÔºåÈÄ≤ËÄåÂº∑ÂåñÊô∫ÊÖßÈÅãËº∏Ë®≠ÂÆö‰∏≠ÁöÑË≥áÊñôÂÑ≤Â≠ò„ÄÅÂàÜÊûêÂíåÊì∑Âèñ„ÄÇ

##### **Performance Implications of Multi-Chiplet Neural Processing Units on Autonomous Driving Perception**
2411.16007v1 by Mohanad Odema, Luke Chen, Hyoukjun Kwon, Mohammad Abdullah Al Faruque

We study the application of emerging chiplet-based Neural Processing Units to
accelerate vehicular AI perception workloads in constrained automotive
settings. The motivation stems from how chiplets technology is becoming
integral to emerging vehicular architectures, providing a cost-effective
trade-off between performance, modularity, and customization; and from
perception models being the most computationally demanding workloads in a
autonomous driving system. Using the Tesla Autopilot perception pipeline as a
case study, we first breakdown its constituent models and profile their
performance on different chiplet accelerators. From the insights, we propose a
novel scheduling strategy to efficiently deploy perception workloads on
multi-chip AI accelerators. Our experiments using a standard DNN performance
simulator, MAESTRO, show our approach realizes 82% and 2.8x increase in
throughput and processing engines utilization compared to monolithic
accelerator designs.

ÊëòË¶ÅÔºöÊàëÂÄëÁ†îÁ©∂‰∫ÜÊñ∞ËààÊô∂ÁâáÁ¥öÁ•ûÁ∂ìËôïÁêÜÂñÆÂÖÉÂú®ÂèóÈôêÊ±ΩËªäÁí∞Â¢É‰∏≠Âä†ÈÄüËªäËºõ AI ÊÑüÁü•Â∑•‰ΩúË≤†ËºâÁöÑÊáâÁî®„ÄÇÂÖ∂ÂãïÊ©üÊ∫êËá™ÊñºÊô∂ÁâáÊäÄË°ìÂ¶Ç‰ΩïÊàêÁÇ∫Êñ∞ËààÊ±ΩËªäÊû∂ÊßãÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÂú®ÊïàËÉΩ„ÄÅÊ®°ÁµÑÂåñÂíåÂÆ¢Ë£ΩÂåñ‰πãÈñìÊèê‰æõÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊäòË°∑ÊñπÊ°àÔºõ‰ª•ÂèäÊÑüÁü•Ê®°ÂûãÂú®Ëá™ÂãïÈßïÈßõÁ≥ªÁµ±‰∏≠ÊòØÊúÄÈúÄË¶ÅÈÅãÁÆóÁöÑÂ∑•‰ΩúË≤†Ëºâ„ÄÇ‰ΩøÁî® Tesla Autopilot ÊÑüÁü•ÁÆ°Á∑ö‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëÈ¶ñÂÖàÂàÜËß£ÂÖ∂ÁµÑÊàêÊ®°ÂûãÔºå‰∏¶ÂàÜÊûêÂÖ∂Âú®‰∏çÂêåÊô∂ÁâáÂä†ÈÄüÂô®‰∏äÁöÑÊïàËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊéíÁ®ãÁ≠ñÁï•Ôºå‰ª•ÊúâÊïàÁéáÁöÑÊñπÂºèÂú®Â§öÊô∂Áâá AI Âä†ÈÄüÂô®‰∏äÈÉ®ÁΩ≤ÊÑüÁü•Â∑•‰ΩúË≤†Ëºâ„ÄÇÊàëÂÄë‰ΩøÁî®Ê®ôÊ∫ñ DNN ÊïàËÉΩÊ®°Êì¨Âô® MAESTRO ÈÄ≤Ë°åÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåËàáÂñÆ‰∏ÄÂä†ÈÄüÂô®Ë®≠Ë®àÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØÂØ¶ÁèæÂêûÂêêÈáèÂíåËôïÁêÜÂºïÊìé‰ΩøÁî®ÁéáÂàÜÂà•ÊèêÂçá 82% Âíå 2.8 ÂÄç„ÄÇ

##### **eFedLLM: Efficient LLM Inference Based on Federated Learning**
2411.16003v1 by Shengwen Ding, Chenhui Hu

Large Language Models (LLMs) herald a transformative era in artificial
intelligence (AI). However, the expansive scale of data and parameters of LLMs
requires high-demand computational and memory resources, restricting their
accessibility to a broader range of users and researchers. This paper
introduces an effective approach that enhances the operational efficiency and
affordability of LLM inference. By utilizing transformer-based federated
learning (FL) with model-parallel distributed training, our model efficiently
distributes the computational loads and memory requirements across a network of
participants. This strategy permits users, especially those with limited
resources to train state-of-the-art LLMs collaboratively. We also innovate an
incentive mechanism within the FL framework, rewarding constructive
contributions and filtering out malicious activities, thereby safeguarding the
integrity and reliability of the training process. Concurrently, we leverage
memory hierarchy strategies and Singular Value Decomposition (SVD) on weight
matrices to boost computational and memory efficiencies further. Our results,
derived from formulaic analyses and numerical calculations, demonstrate
significant optimization of resource use and democratize access to cutting-edge
LLMs, ensuring that a wide scale of users can both contribute to and benefit
from these advanced models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) È†êÂëäËëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑËÆäÈù©ÊôÇ‰ª£„ÄÇÁÑ∂ËÄåÔºåLLM ÁöÑË≥áÊñôÂíåÂèÉÊï∏Ë¶èÊ®°ÈæêÂ§ßÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑÈÅãÁÆóÂíåË®òÊÜ∂È´îË≥áÊ∫êÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∞çÊõ¥Âª£Ê≥õÁöÑ‰ΩøÁî®ËÄÖÂíåÁ†îÁ©∂‰∫∫Âì°ÁöÑÂèØÂèäÊÄß„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•ÊèêÈ´ò LLM Êé®Ë´ñÁöÑÈÅã‰ΩúÊïàÁéáÂíåË≤†ÊìîËÉΩÂäõ„ÄÇÈÄèÈÅéÂà©Áî®Âü∫Êñº Transformer ÁöÑËÅØÈÇ¶Â≠∏Áøí (FL) ÂíåÊ®°Âûã‰∏¶Ë°åÂàÜÂ∏ÉÂºèË®ìÁ∑¥ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•ÊúâÊïàÂú∞Â∞áÈÅãÁÆóË≤†ËºâÂíåË®òÊÜ∂È´îÈúÄÊ±ÇÂàÜ‰ΩàÂú®ÂèÉËàáËÄÖÁöÑÁ∂≤Ë∑Ø‰∏≠„ÄÇÊ≠§Á≠ñÁï•ÂÖÅË®±‰ΩøÁî®ËÄÖÔºàÁâπÂà•ÊòØÈÇ£‰∫õË≥áÊ∫êÊúâÈôêÁöÑ‰ΩøÁî®ËÄÖÔºâÂêà‰ΩúË®ìÁ∑¥ÊúÄÂÖàÈÄ≤ÁöÑ LLM„ÄÇÊàëÂÄëÈÇÑÂú® FL Êû∂Êßã‰∏≠ÂâµÊñ∞‰∫Ü‰∏ÄÁ®ÆÊøÄÂãµÊ©üÂà∂ÔºåÁçéÂãµÂª∫Ë®≠ÊÄßÁöÑË≤¢Áçª‰∏¶ÈÅéÊøæÊéâÊÉ°ÊÑèÊ¥ªÂãïÔºåÂæûËÄå‰øùË≠∑Ë®ìÁ∑¥ÈÅéÁ®ãÁöÑÂÆåÊï¥ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÂêåÊôÇÔºåÊàëÂÄëÂà©Áî®Ë®òÊÜ∂È´îÈöéÂ±§Á≠ñÁï•ÂíåÊ¨äÈáçÁü©Èô£‰∏äÁöÑÂ•áÁï∞ÂÄºÂàÜËß£ (SVD) ‰æÜÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÈÅãÁÆóÂíåË®òÊÜ∂È´îÊïàÁéá„ÄÇÊàëÂÄëÂæûÂÖ¨ÂºèÂàÜÊûêÂíåÊï∏ÂÄºË®àÁÆó‰∏≠ÂæóÂá∫ÁöÑÁµêÊûúÔºåË≠âÊòé‰∫ÜË≥áÊ∫ê‰ΩøÁî®ÁöÑÈ°ØËëóÊúÄ‰Ω≥ÂåñÔºå‰∏¶‰ΩøÂ∞ñÁ´ØÁöÑ LLM Ê∞ë‰∏ªÂåñÔºåÁ¢∫‰øùÂª£Ê≥õÁöÑ‰ΩøÁî®ËÄÖÊó¢ËÉΩË≤¢ÁçªÈÄô‰∫õÂÖàÈÄ≤Ê®°ÂûãÔºå‰πüËÉΩÂæû‰∏≠ÂèóÁõä„ÄÇ

##### **Exploring Performance Contrasts in TableQA: Step-by-Step Reasoning Boosts Bigger Language Models, Limits Smaller Language Models**
2411.16002v1 by Haoyan Yang, Yixuan Wang, Keyue Tong, Hongjin Zhu, Yuanxin Zhang

This paper proposes a detailed prompting flow, termed Table-Logic, to
investigate the performance contrasts between bigger and smaller language
models (LMs) utilizing step-by-step reasoning methods in the TableQA task. The
method processes tasks by sequentially identifying critical columns and rows
given question and table with its structure, determining necessary
aggregations, calculations, or comparisons, and finally inferring the results
to generate a precise prediction. By deploying this method, we observe a 7.8%
accuracy improvement in bigger LMs like Llama-3-70B compared to the vanilla on
HybridQA, while smaller LMs like Llama-2-7B shows an 11% performance decline.
We empirically investigate the potential causes of performance contrasts by
exploring the capabilities of bigger and smaller LMs from various dimensions in
TableQA task. Our findings highlight the limitations of the step-by-step
reasoning method in small models and provide potential insights for making
improvements.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊèêÂá∫‰∫ÜË©≥Áõ°ÁöÑÊèêÁ§∫ÊµÅÁ®ãÔºåÁ®±ÁÇ∫ Table-LogicÔºå‰ª•Êé¢Ë®éÂú® TableQA ‰ªªÂãô‰∏≠Âà©Áî®ÈÄêÊ≠•Êé®ÁêÜÊñπÊ≥ïÁöÑÂ§ßÂûãÂíåÂ∞èÂûãË™ûË®ÄÊ®°Âûã (LM) ‰πãÈñìÁöÑÊïàËÉΩÂ∞çÊØî„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÊåâÈ†ÜÂ∫èË≠òÂà•ÈóúÈçµÊ¨Ñ‰ΩçÂíåÂàóÔºàÁµ¶ÂÆöÂïèÈ°åÂíåË°®Ê†ºÂèäÂÖ∂ÁµêÊßãÔºâ„ÄÅÊ±∫ÂÆöÂøÖË¶ÅÁöÑÂΩôÁ∏Ω„ÄÅË®àÁÆóÊàñÊØîËºÉÔºåÊúÄÂæåÊé®Ë´ñÁµêÊûú‰ª•Áî¢ÁîüÁ≤æÁ¢∫È†êÊ∏¨Ôºå‰æÜËôïÁêÜ‰ªªÂãô„ÄÇÈÄèÈÅéÈÉ®ÁΩ≤Ê≠§ÊñπÊ≥ïÔºåÊàëÂÄëËßÄÂØüÂà∞ Llama-3-70B Á≠âÂ§ßÂûã LM Âú® HybridQA ‰∏äÁöÑÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 7.8%ÔºåËÄå Llama-2-7B Á≠âÂ∞èÂûã LM ÂâáÈ°ØÁ§∫Âá∫ÊïàËÉΩ‰∏ãÈôç 11%„ÄÇÊàëÂÄëÈÄèÈÅéÊé¢Á¥¢Â§ßÂûãÂíåÂ∞èÂûã LM Âú® TableQA ‰ªªÂãô‰∏≠ÂêÑÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂØ¶Ë≠âË™øÊü•ÊïàËÉΩÂ∞çÊØîÁöÑÊΩõÂú®ÂéüÂõ†„ÄÇÊàëÂÄëÁöÑÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÂ∞èÂûãÊ®°Âûã‰∏≠ÈÄêÊ≠•Êé®ÁêÜÊñπÊ≥ïÁöÑÈôêÂà∂Ôºå‰∏¶Êèê‰æõÊΩõÂú®Ë¶ãËß£‰ª•ÈÄ≤Ë°åÊîπÈÄ≤„ÄÇ

##### **Multi-ToM: Evaluating Multilingual Theory of Mind Capabilities in Large Language Models**
2411.15999v1 by Jayanta Sadhu, Ayan Antik Khan, Noshin Nawal, Sanju Basak, Abhik Bhattacharjee, Rifat Shahriyar

Theory of Mind (ToM) refers to the cognitive ability to infer and attribute
mental states to oneself and others. As large language models (LLMs) are
increasingly evaluated for social and cognitive capabilities, it remains
unclear to what extent these models demonstrate ToM across diverse languages
and cultural contexts. In this paper, we introduce a comprehensive study of
multilingual ToM capabilities aimed at addressing this gap. Our approach
includes two key components: (1) We translate existing ToM datasets into
multiple languages, effectively creating a multilingual ToM dataset and (2) We
enrich these translations with culturally specific elements to reflect the
social and cognitive scenarios relevant to diverse populations. We conduct
extensive evaluations of six state-of-the-art LLMs to measure their ToM
performance across both the translated and culturally adapted datasets. The
results highlight the influence of linguistic and cultural diversity on the
models' ability to exhibit ToM, and questions their social reasoning
capabilities. This work lays the groundwork for future research into enhancing
LLMs' cross-cultural social cognition and contributes to the development of
more culturally aware and socially intelligent AI systems. All our data and
code are publicly available.

ÊëòË¶ÅÔºöÂøÉÊô∫ÁêÜË´ñ (ToM) ÊåáÁöÑÊòØÊé®Ë´ñÂíåÊ≠∏Âõ†ÂøÉÊô∫ÁãÄÊÖãÁµ¶Ëá™Â∑±ÂíåÂà•‰∫∫ÁöÑË™çÁü•ËÉΩÂäõ„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄêÊº∏Ë¢´Ë©ï‰º∞ÂÖ∂Á§æ‰∫§ÂíåË™çÁü•ËÉΩÂäõÔºåÈÄô‰∫õÊ®°ÂûãÂú®‰∏çÂêåË™ûË®ÄÂíåÊñáÂåñËÉåÊôØ‰∏≠Â±ïÁèæ ToM ÁöÑÁ®ãÂ∫¶‰ªç‰∏çÊòéÁ¢∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÈ†ÖÈáùÂ∞çÂ§öË™ûË®Ä ToM ËÉΩÂäõÁöÑÂÖ®Èù¢Á†îÁ©∂ÔºåÊó®Âú®Ëß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºö(1) ÊàëÂÄëÂ∞áÁèæÊúâÁöÑ ToM Ë≥áÊñôÈõÜÁøªË≠ØÊàêÂ§öÁ®ÆË™ûË®ÄÔºåÊúâÊïàÂú∞Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÂ§öË™ûË®Ä ToM Ë≥áÊñôÈõÜÔºå(2) ÊàëÂÄëÁî®ÊñáÂåñÁâπÂÆöÂÖÉÁ¥†Ë±êÂØåÈÄô‰∫õÁøªË≠ØÔºå‰ª•ÂèçÊò†Ëàá‰∏çÂêåÊóèÁæ§Áõ∏ÈóúÁöÑÁ§æÊúÉÂíåË™çÁü•ÊÉÖÂ¢É„ÄÇÊàëÂÄëÂ∞çÂÖ≠ÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLM ÈÄ≤Ë°åÂª£Ê≥õÁöÑË©ï‰º∞Ôºå‰ª•Ë°°ÈáèÂÆÉÂÄëÂú®ÁøªË≠ØÂíåÊñáÂåñÊîπÁ∑®Ë≥áÊñôÈõÜ‰∏≠ÁöÑ ToM Ë°®Áèæ„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜË™ûË®ÄÂíåÊñáÂåñÂ§öÊ®£ÊÄßÂ∞çÊ®°ÂûãÂ±ïÁèæ ToM ËÉΩÂäõÁöÑÂΩ±ÈüøÔºå‰∏¶Ë≥™ÁñëÂÆÉÂÄëÁöÑÁ§æÊúÉÊé®ÁêÜËÉΩÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Êú™‰æÜÂ¢ûÂº∑ LLM ÁöÑË∑®ÊñáÂåñÁ§æÊúÉË™çÁü•ÁöÑÁ†îÁ©∂Â•†ÂÆö‰∫ÜÂü∫Á§éÔºå‰∏¶ÊúâÂä©ÊñºÈñãÁôºÊõ¥ÂÖ∑ÊñáÂåñÊÑèË≠òÂíåÁ§æÊúÉÊô∫ÊÖßÁöÑ AI Á≥ªÁµ±„ÄÇÊàëÂÄëÁöÑË≥áÊñôÂíåÁ®ãÂºèÁ¢ºÁöÜÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making**
2411.15998v1 by Jonathan Light, Sixue Xing, Yuanzhe Liu, Weiqin Chen, Min Cai, Xiusi Chen, Guanzhi Wang, Wei Cheng, Yisong Yue, Ziniu Hu

Effective extraction of the world knowledge in LLMs for complex
decision-making tasks remains a challenge. We propose a framework PIANIST for
decomposing the world model into seven intuitive components conducive to
zero-shot LLM generation. Given only the natural language description of the
game and how input observations are formatted, our method can generate a
working world model for fast and efficient MCTS simulation. We show that our
method works well on two different games that challenge the planning and
decision making skills of the agent for both language and non-language based
action taking, without any training on domain-specific training data or
explicitly defined world model.

ÊëòË¶ÅÔºöÂ∞çÊñºË§áÈõúÁöÑÊ±∫Á≠ñ‰ªªÂãôÔºåÂú® LLM ‰∏≠ÊúâÊïàÊèêÂèñ‰∏ñÁïåÁü•Ë≠ò‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊû∂Êßã PIANISTÔºåÂ∞á‰∏ñÁïåÊ®°ÂûãÂàÜËß£ÁÇ∫‰∏ÉÂÄãÁõ¥ËßÄÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÊúâÂà©ÊñºÈõ∂Ê¨°Â≠∏Áøí LLM ÁîüÊàê„ÄÇÂÉÖÁµ¶ÂÆöÈÅäÊà≤ÁöÑËá™ÁÑ∂Ë™ûË®ÄÊèèËø∞ÂíåËº∏ÂÖ•ËßÄÊ∏¨ÂÄºÁöÑÊ†ºÂºèÂåñÊñπÂºèÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ∞±ËÉΩÁî¢Áîü‰∏ÄÂÄãÈÅã‰ΩúÁöÑ‰∏ñÁïåÊ®°ÂûãÔºåÁî®ÊñºÂø´ÈÄü‰∏îÊúâÊïàÁéáÁöÑ MCTS Ê®°Êì¨„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂÖ©Á®Æ‰∏çÂêåÁöÑÈÅäÊà≤‰∏≠ÈÅã‰ΩúËâØÂ•ΩÔºåÈÄô‰∫õÈÅäÊà≤ÊåëÊà∞‰∫Ü‰ª£ÁêÜ‰∫∫Âú®Ë™ûË®ÄÂíåÈùûË™ûË®ÄÂãï‰ΩúÊé°ÂèñÊñπÈù¢ÁöÑË¶èÂäÉÂíåÊ±∫Á≠ñÂà∂ÂÆöÊäÄËÉΩÔºåËÄåÁÑ°ÈúÄÈáùÂ∞çÁâπÂÆöÈ†òÂüüÁöÑË®ìÁ∑¥Ë≥áÊñôÊàñÊòéÁ¢∫ÂÆöÁæ©ÁöÑ‰∏ñÁïåÊ®°ÂûãÈÄ≤Ë°å‰ªª‰ΩïË®ìÁ∑¥„ÄÇ

##### **Ensuring Fair LLM Serving Amid Diverse Applications**
2411.15997v1 by Redwan Ibne Seraj Khan, Kunal Jain, Haiying Shen, Ankur Mallick, Anjaly Parayil, Anoop Kulkarni, Steve Kofsky, Pankhuri Choudhary, Ren√®e St. Amant, Rujia Wang, Yue Cheng, Ali R. Butt, Victor R√ºhle, Chetan Bansal, Saravan Rajmohan

In a multi-tenant large language model (LLM) serving platform hosting diverse
applications, some users may submit an excessive number of requests, causing
the service to become unavailable to other users and creating unfairness.
Existing fairness approaches do not account for variations in token lengths
across applications and multiple LLM calls, making them unsuitable for such
platforms. To address the fairness challenge, this paper analyzes millions of
requests from thousands of users on MS CoPilot, a real-world multi-tenant LLM
platform hosted by Microsoft. Our analysis confirms the inadequacy of existing
methods and guides the development of FairServe, a system that ensures fair LLM
access across diverse applications. FairServe proposes
application-characteristic aware request throttling coupled with a weighted
service counter based scheduling technique to curb abusive behavior and ensure
fairness. Our experimental results on real-world traces demonstrate FairServe's
superior performance compared to the state-of-the-art method in ensuring
fairness. We are actively working on deploying our system in production,
expecting to benefit millions of customers world-wide.

ÊëòË¶ÅÔºöÂú®‰∏ÄÂÄãÂ§öÁßüÊà∂ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúçÂãôÂπ≥Âè∞‰∏äÔºåË®óÁÆ°ËëóÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÔºå‰∏Ä‰∫õ‰ΩøÁî®ËÄÖÂèØËÉΩÊúÉÊèê‰∫§ÈÅéÂ§öÁöÑË¶ÅÊ±ÇÔºåÂ∞éËá¥ÊúçÂãôÂ∞çÂÖ∂‰ªñ‰ΩøÁî®ËÄÖ‰∏çÂèØÁî®Ôºå‰∏¶ÈÄ†Êàê‰∏çÂÖ¨Âπ≥„ÄÇÁèæÊúâÁöÑÂÖ¨Âπ≥ÊñπÊ≥ïÊ≤íÊúâËÄÉÊÖÆÂà∞‰∏çÂêåÊáâÁî®Á®ãÂºèÈñìÁöÑÁ¨¶ËôüÈï∑Â∫¶Â∑ÆÁï∞ÂíåÂ§öÂÄã LLM ÂëºÂè´ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄë‰∏çÈÅ©ÂêàÊ≠§È°ûÂπ≥Âè∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÂÖ¨Âπ≥ÊÄßÁöÑÊåëÊà∞ÔºåÊú¨ÊñáÂàÜÊûê‰∫Ü‰æÜËá™Êï∏ÂçÉÂêç‰ΩøÁî®ËÄÖÁöÑÊï∏ÁôæËê¨ÂÄãË´ãÊ±ÇÔºåÈÄô‰∫õ‰ΩøÁî®ËÄÖÂú® MS CoPilot ‰∏äÔºåÈÄôÊòØ‰∏ÄÂÄãÁî± Microsoft Ë®óÁÆ°ÁöÑÁúüÂØ¶‰∏ñÁïåÂ§öÁßüÊà∂ LLM Âπ≥Âè∞„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË≠âÂØ¶‰∫ÜÁèæÊúâÊñπÊ≥ïÁöÑ‰∏çË∂≥Ôºå‰∏¶ÊåáÂ∞é‰∫Ü FairServe ÁöÑÈñãÁôºÔºåFairServe ÊòØ‰∏ÄÂÄãÁ≥ªÁµ±ÔºåÂèØÁ¢∫‰øù‰∏çÂêåÊáâÁî®Á®ãÂºè‰πãÈñìÁöÑ LLM ÂÖ¨Âπ≥Â≠òÂèñ„ÄÇFairServe ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊáâÁî®Á®ãÂºèÁâπÂæµÊÑüÁü•Ë´ãÊ±ÇÁØÄÊµÅÔºåÂÜçÂä†‰∏ä‰∏ÄÂÄãÂü∫ÊñºÂä†Ê¨äÊúçÂãôË®àÊï∏Âô®ÁöÑÊéíÁ®ãÊäÄË°ìÔºå‰ª•ÈÅèÂà∂Êø´Áî®Ë°åÁÇ∫‰∏¶Á¢∫‰øùÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÂú®ÁúüÂØ¶‰∏ñÁïåËøΩËπ§‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü FairServe ËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂú®Á¢∫‰øùÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÊ≠£Âú®Á©çÊ•µÂú∞Â∞áÊàëÂÄëÁöÑÁ≥ªÁµ±ÈÉ®ÁΩ≤Âà∞ÁîüÁî¢Áí∞Â¢É‰∏≠ÔºåÈ†êË®àÂ∞á‰ΩøÂÖ®ÁêÉÊï∏ÁôæËê¨ÂÆ¢Êà∂ÂèóÁõä„ÄÇ

##### **Investigating Factuality in Long-Form Text Generation: The Roles of Self-Known and Self-Unknown**
2411.15993v1 by Lifu Tu, Rui Meng, Shafiq Joty, Yingbo Zhou, Semih Yavuz

Large language models (LLMs) have demonstrated strong capabilities in text
understanding and generation. However, they often lack factuality, producing a
mixture of true and false information, especially in long-form generation. In
this work, we investigates the factuality of long-form text generation across
various large language models (LLMs), including GPT-4, Gemini-1.5-Pro,
Claude-3-Opus, Llama-3-70B, and Mistral. Our analysis reveals that factuality
scores tend to decline in later sentences of the generated text, accompanied by
a rise in the number of unsupported claims. Furthermore, we explore the
effectiveness of different evaluation settings to assess whether LLMs can
accurately judge the correctness of their own outputs: Self-Known (the
percentage of supported atomic claims, decomposed from LLM outputs, that the
corresponding LLMs judge as correct) and Self-Unknown (the percentage of
unsupported atomic claims that the corresponding LLMs judge as incorrect). The
results indicate that even advanced models like GPT-4 and Gemini-1.5-Pro fail
to achieve perfect Self-Known scores, while their Self-Unknown scores remain
notably above zero, reflecting ongoing uncertainty in their self-assessments.
Moreover, we find a correlation between higher Self-Known scores and improved
factuality, while higher Self-Unknown scores are associated with lower
factuality. Interestingly, even without significant changes in the models'
self-judgment (Self-Known and Self-Unknown), the number of unsupported claims
can increases, likely as an artifact of long-form generation. These findings
show the limitations of current LLMs in long-form generation, and provide
valuable insights for improving factuality in long-form text generation.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÊñáÂ≠óÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂæÄÂæÄÁº∫‰πè‰∫ãÂØ¶ÊÄßÔºåÁî¢ÁîüÁúüÂÅáË®äÊÅØÊ∑∑ÈõúÁöÑÂÖßÂÆπÔºåÁâπÂà•ÊòØÂú®Èï∑ÁØáÁîüÊàê‰∏≠„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂêÑÁ®ÆÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈï∑ÁØáÊñáÂ≠óÁîüÊàêÁöÑÁúüÂØ¶ÊÄßÔºåÂåÖÊã¨ GPT-4„ÄÅGemini-1.5-Pro„ÄÅClaude-3-Opus„ÄÅLlama-3-70B Âíå Mistral„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÁîüÊàêÊñáÂ≠óÁöÑÂæåÁ∫åÂè•Â≠ê‰∏≠ÁúüÂØ¶ÊÄßÂàÜÊï∏ÂæÄÂæÄ‰∏ãÈôçÔºåÂêåÊôÇÁº∫‰πè‰æùÊìöÁöÑ‰∏ªÂºµÊï∏ÈáèÂ¢ûÂä†„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü‰∏çÂêåË©ï‰º∞Ë®≠ÂÆöÁöÑÊúâÊïàÊÄßÔºå‰ª•Ë©ï‰º∞ LLM ÊòØÂê¶ËÉΩÊ∫ñÁ¢∫Âà§Êñ∑ÂÖ∂Ëá™Ë∫´Ëº∏Âá∫ÁöÑÊ≠£Á¢∫ÊÄßÔºöËá™Áü•ÔºàLLM Ëº∏Âá∫‰∏≠ÂàÜËß£Âá∫ÁöÑÂ∑≤ÊîØÊåÅÂéüÂ≠ê‰∏ªÂºµÁöÑÁôæÂàÜÊØîÔºåÂ∞çÊáâÁöÑ LLM Âà§Êñ∑ÁÇ∫Ê≠£Á¢∫ÔºâÂíåËá™‰∏çÁü•ÔºàLLM Ëº∏Âá∫‰∏≠ÂàÜËß£Âá∫ÁöÑÊú™ÊîØÊåÅÂéüÂ≠ê‰∏ªÂºµÁöÑÁôæÂàÜÊØîÔºåÂ∞çÊáâÁöÑ LLM Âà§Êñ∑ÁÇ∫‰∏çÊ≠£Á¢∫Ôºâ„ÄÇÁµêÊûúË°®ÊòéÔºåÂç≥‰ΩøÊòØ GPT-4 Âíå Gemini-1.5-Pro Á≠âÈÄ≤ÈöéÊ®°Âûã‰πüÁÑ°Ê≥ïÈÅîÂà∞ÂÆåÁæéÁöÑËá™Áü•ÂàÜÊï∏ÔºåËÄåÂÖ∂Ëá™‰∏çÁü•ÂàÜÊï∏‰ªçÈ°ØËëóÈ´òÊñºÈõ∂ÔºåÂèçÊò†Âá∫ÂÖ∂Ëá™ÊàëË©ï‰º∞‰∏≠ÊåÅÁ∫åÂ≠òÂú®ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæËá™Áü•ÂàÜÊï∏ËºÉÈ´òËàáÁúüÂØ¶ÊÄßÊèêÂçá‰πãÈñìÂ≠òÂú®ÈóúËÅØÔºåËÄåËá™‰∏çÁü•ÂàÜÊï∏ËºÉÈ´òÂâáËàáÁúüÂØ¶ÊÄßÈôç‰ΩéÁõ∏Èóú„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂç≥‰ΩøÊ®°ÂûãÁöÑËá™Âà§Êñ∑ÔºàËá™Áü•ÂíåËá™‰∏çÁü•ÔºâÊ≤íÊúâÈ°ØËëóËÆäÂåñÔºåÊú™ÊîØÊåÅ‰∏ªÂºµÁöÑÊï∏Èáè‰ªçÂèØËÉΩÂ¢ûÂä†ÔºåÈÄôÂèØËÉΩÊòØÈï∑ÁØáÁîüÊàêÁöÑÁî¢Áâ©„ÄÇÈÄô‰∫õÁôºÁèæÈ°ØÁ§∫‰∫ÜÁï∂Ââç LLM Âú®Èï∑ÁØáÁîüÊàê‰∏≠ÁöÑÂ±ÄÈôêÊÄßÔºå‰∏¶ÁÇ∫ÊîπÂñÑÈï∑ÁØáÊñáÂ≠óÁîüÊàêÁöÑÁúüÂØ¶ÊÄßÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£„ÄÇ

##### **Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format**
2411.15982v1 by Chao Fang, Man Shi, Robin Geens, Arne Symons, Zhongfeng Wang, Marian Verhelst

The widely-used, weight-only quantized large language models (LLMs), which
leverage low-bit integer (INT) weights and retain floating-point (FP)
activations, reduce storage requirements while maintaining accuracy. However,
this shifts the energy and latency bottlenecks towards the FP activations that
are associated with costly memory accesses and computations. Existing LLM
accelerators focus primarily on computation optimizations, overlooking the
potential of jointly optimizing FP computations and data movement, particularly
for the dominant FP-INT GeMM operations in LLM inference.
  To address these challenges, we investigate the sensitivity of activation
precision across various LLM modules and its impact on overall model accuracy.
Based on our findings, we first propose the Anda data type: an adaptive data
format with group-shared exponent bits and dynamic mantissa bit allocation.
Secondly, we develop an iterative post-training adaptive precision search
algorithm that optimizes the bit-width for different LLM modules to balance
model accuracy, energy efficiency, and inference speed. Lastly, a suite of
hardware optimization techniques is proposed to maximally exploit the benefits
of the Anda format. These include a bit-plane-based data organization scheme,
Anda-enhanced processing units with bit-serial computation, and a runtime
bit-plane Anda compressor to simultaneously optimize storage, computation, and
memory footprints. Our evaluations on FPINT GeMM operations show that Anda
achieves a 2.4x speedup, 4.0x area efficiency, and 3.1x energy efficiency
improvement on average for popular LLMs including OPT, LLaMA, and LLaMA-2
series over the GPU-like FP-FP baseline. Anda demonstrates strong adaptability
across various application scenarios, accuracy requirements, and system
performance, enabling efficient LLM inference across a wide range of deployment
scenarios.

ÊëòË¶ÅÔºöÂª£Ê≥õ‰ΩøÁî®ÁöÑ„ÄÅÂÉÖÊ¨äÈáçÈáèÂåñÁöÑÂ∑®ÈáèË™ûË®ÄÊ®°Âûã (LLM) Âà©Áî®‰Ωé‰ΩçÂÖÉÊï¥Êï∏ (INT) Ê¨äÈáç‰∏¶‰øùÁïôÊµÆÈªû (FP) ÊøÄÊ¥ªÔºåÂú®Á∂≠ÊåÅÁ≤æÊ∫ñÂ∫¶ÁöÑÂêåÊôÇÈôç‰ΩéÂÑ≤Â≠òÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÈÄôÂ∞áËÉΩÈáèÂíåÂª∂ÈÅ≤Áì∂È†∏ËΩâÁßªÂà∞ËàáÊòÇË≤¥ÁöÑË®òÊÜ∂È´îÂ≠òÂèñÂíåÈÅãÁÆóÁõ∏ÈóúÁöÑ FP ÊøÄÊ¥ª„ÄÇÁèæÊúâÁöÑ LLM Âä†ÈÄüÂô®‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÈÅãÁÆóÊúÄ‰Ω≥ÂåñÔºåÂøΩË¶ñ‰∫ÜËÅØÂêàÊúÄ‰Ω≥Âåñ FP ÈÅãÁÆóÂíåË≥áÊñôÁßªÂãïÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÈáùÂ∞ç LLM Êé®Ë´ñ‰∏≠‰Ωî‰∏ªÂ∞éÂú∞‰ΩçÁöÑ FP-INT GeMM ÈÅãÁÆó„ÄÇ
ÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂêÑÁ®Æ LLM Ê®°ÁµÑ‰∏≠ÊøÄÊ¥ªÁ≤æÂ∫¶ÁöÑÊïèÊÑüÊÄßÂèäÂÖ∂Â∞çÊï¥È´îÊ®°ÂûãÁ≤æÂ∫¶ÁöÑÂΩ±Èüø„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÁôºÁèæÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫ Anda Ë≥áÊñôÈ°ûÂûãÔºö‰∏ÄÁ®ÆÂÖ∑ÊúâÁæ§ÁµÑÂÖ±Áî®ÊåáÊï∏‰ΩçÂÖÉÂíåÂãïÊÖãÂ∞æÊï∏‰ΩçÂÖÉÈÖçÁΩÆÁöÑËá™ÈÅ©ÊáâË≥áÊñôÊ†ºÂºè„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂèçË¶ÜË®ìÁ∑¥ÂæåËá™ÈÅ©ÊáâÁ≤æÂ∫¶ÁöÑÊêúÂ∞ãÊºîÁÆóÊ≥ïÔºåÈáùÂ∞ç‰∏çÂêåÁöÑ LLM Ê®°ÁµÑÊúÄ‰Ω≥Âåñ‰ΩçÂÖÉÂØ¨Â∫¶Ôºå‰ª•Âπ≥Ë°°Ê®°ÂûãÁ≤æÂ∫¶„ÄÅËÉΩÊ∫êÊïàÁéáÂíåÊé®Ë´ñÈÄüÂ∫¶„ÄÇÊúÄÂæåÔºåÊèêÂá∫‰∫Ü‰∏ÄÂ•óÁ°¨È´îÊúÄ‰Ω≥ÂåñÊäÄË°ìÔºå‰ª•ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞Âà©Áî® Anda Ê†ºÂºèÁöÑÂÑ™Èªû„ÄÇÈÄô‰∫õÊäÄË°ìÂåÖÊã¨Âü∫Êñº‰ΩçÂÖÉÂπ≥Èù¢ÁöÑË≥áÊñôÁµÑÁπîÊû∂Êßã„ÄÅÂÖ∑Êúâ‰ΩçÂÖÉÂ∫èÂàóÈÅãÁÆóÁöÑ Anda Â¢ûÂº∑ËôïÁêÜÂñÆÂÖÉÔºå‰ª•ÂèäÂêåÊôÇÊúÄ‰Ω≥ÂåñÂÑ≤Â≠ò„ÄÅÈÅãÁÆóÂíåË®òÊÜ∂È´î‰ΩîÁî®Á©∫ÈñìÁöÑÂü∑Ë°åÊôÇÊúü‰ΩçÂÖÉÂπ≥Èù¢ Anda Â£ìÁ∏ÆÂô®„ÄÇÊàëÂÄëÂ∞ç FPINT GeMM ÈÅãÁÆóÁöÑË©ï‰º∞È°ØÁ§∫ÔºåËàáÈ°û GPU ÁöÑ FP-FP Âü∫Ê∫ñÁõ∏ÊØîÔºåAnda Â∞çÂåÖÊã¨ OPT„ÄÅLLaMA Âíå LLaMA-2 Á≥ªÂàóÂú®ÂÖßÁöÑÁÜ±ÈñÄ LLM Âπ≥ÂùáÂèØÂØ¶Áèæ 2.4 ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçá„ÄÅ4.0 ÂÄçÁöÑÈù¢Á©çÊïàÁéáÂíå 3.1 ÂÄçÁöÑËÉΩÊ∫êÊïàÁéáÊèêÂçá„ÄÇAnda Âú®ÂêÑÁ®ÆÊáâÁî®Â†¥ÊôØ„ÄÅÁ≤æÂ∫¶Ë¶ÅÊ±ÇÂíåÁ≥ªÁµ±ÊïàËÉΩ‰∏≠Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÈÅ©ÊáâÊÄßÔºåÂèØÂú®Âª£Ê≥õÁöÑÈÉ®ÁΩ≤Â†¥ÊôØ‰∏≠ÂØ¶ÁèæÈ´òÊïàÁöÑ LLM Êé®Ë´ñ„ÄÇ

##### **DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**
2411.15976v1 by Ruiqiang Xiao, Songning Lai, Yijun Yang, Jiemin Wu, Yutao Yue, Lei Zhu

Adapting machine learning models to new domains without labeled data,
especially when source data is inaccessible, is a critical challenge in
applications like medical imaging, autonomous driving, and remote sensing. This
task, known as Source-Free Unsupervised Domain Adaptation (SFUDA), involves
adapting a pre-trained model to a target domain using only unlabeled target
data, which can lead to issues such as overfitting, underfitting, and poor
generalization due to domain discrepancies and noise. Existing SFUDA methods
often rely on single-model architectures, struggling with uncertainty and
variability in the target domain. To address these challenges, we propose DRIVE
(Dual-Robustness through Information Variability and Entropy), a novel SFUDA
framework leveraging a dual-model architecture. The two models, initialized
with identical weights, work in parallel to capture diverse target domain
characteristics. One model is exposed to perturbations via projection gradient
descent (PGD) guided by mutual information, focusing on high-uncertainty
regions. We also introduce an entropy-aware pseudo-labeling strategy that
adjusts label weights based on prediction uncertainty, ensuring the model
focuses on reliable data while avoiding noisy regions. The adaptation process
has two stages: the first aligns the models on stable features using a mutual
information consistency loss, and the second dynamically adjusts the
perturbation level based on the loss from the first stage, encouraging the
model to explore a broader range of the target domain while preserving existing
performance. This enhances generalization capabilities and robustness against
interference. Evaluations on standard SFUDA benchmarks show that DRIVE
consistently outperforms previous methods, delivering improved adaptation
accuracy and stability across complex target domains.

ÊëòË¶ÅÔºö<paragraph>Âú®Ê≤íÊúâÊ®ôÁ±§Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÂ∞áÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãË™øÊï¥Âà∞Êñ∞ÁöÑÈ†òÂüüÔºåÁâπÂà•ÊòØÂú®ÁÑ°Ê≥ïÂèñÂæóÂéüÂßãË≥áÊñôÊôÇÔºåÊòØÈÜ´ÁôÇÂΩ±ÂÉè„ÄÅËá™ÂãïÈßïÈßõÂíåÈÅôÊ∏¨Á≠âÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÈÄôÈ†Ö‰ªªÂãôÁ®±ÁÇ∫ÁÑ°‰æÜÊ∫êÈùûÁõ£Áù£È†òÂüüÈÅ©Êáâ (SFUDA)ÔºåÊ∂âÂèä‰ΩøÁî®ÂÉÖÊúâÁöÑÊú™Ê®ôÁ±§ÁõÆÊ®ôË≥áÊñôÂ∞áÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãË™øÊï¥Âà∞ÁõÆÊ®ôÈ†òÂüüÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥ÈÅéÂ∫¶Êì¨Âêà„ÄÅÊ¨†Êì¨ÂêàÂíåÂõ†È†òÂüüÂ∑ÆÁï∞ÂíåÈõúË®äËÄåÂ∞éËá¥ÁöÑÊ¶ÇÂåñ‰∏çËâØÁ≠âÂïèÈ°å„ÄÇÁèæÊúâÁöÑ SFUDA ÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºÂñÆ‰∏ÄÊ®°ÂûãÊû∂ÊßãÔºåÈõ£‰ª•ÊáâÂ∞çÁõÆÊ®ôÈ†òÂüü‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåËÆäÁï∞ÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü DRIVEÔºàÈÄèÈÅéË≥áË®äËÆäÁï∞ÊÄßÂíåÁÜµÁöÑÈõôÈáçÁ©©ÂÅ•ÊÄßÔºâÔºå‰∏ÄÁ®ÆÂà©Áî®ÈõôÊ®°ÂûãÊû∂ÊßãÁöÑÊñ∞Á©é SFUDA Êû∂Êßã„ÄÇÈÄôÂÖ©ÂÄãÊ®°Âûã‰ª•Áõ∏ÂêåÁöÑÊ¨äÈáçÂàùÂßãÂåñÔºå‰∏¶Ë°åÂ∑•‰Ωú‰ª•Êì∑Âèñ‰∏çÂêåÁöÑÁõÆÊ®ôÈ†òÂüüÁâπÂæµ„ÄÇÂÖ∂‰∏≠‰∏ÄÂÄãÊ®°ÂûãÈÄèÈÅéÁî±‰∫íË≥áË®äÂºïÂ∞éÁöÑÊäïÂΩ±Ê¢ØÂ∫¶‰∏ãÈôç (PGD) Êö¥Èú≤ÊñºÊìæÂãïÔºåÈáçÈªûÂú®ÊñºÈ´òÂ∫¶‰∏çÁ¢∫ÂÆöÁöÑÂçÄÂüü„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÁÜµÊÑüÁü•ÂÅΩÊ®ôÁ±§Á≠ñÁï•ÔºåË©≤Á≠ñÁï•Ê†πÊìöÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßË™øÊï¥Ê®ôÁ±§Ê¨äÈáçÔºåÁ¢∫‰øùÊ®°ÂûãÂ∞àÊ≥®ÊñºÂèØÈù†ÁöÑË≥áÊñôÔºåÂêåÊôÇÈÅøÂÖçÈõúË®äÂçÄÂüü„ÄÇÈÅ©ÊáâÈÅéÁ®ãÂàÜÁÇ∫ÂÖ©ÂÄãÈöéÊÆµÔºöÁ¨¨‰∏ÄÂÄãÈöéÊÆµ‰ΩøÁî®‰∫íË≥áË®ä‰∏ÄËá¥ÊÄßÊêçÂ§±Âú®Á©©ÂÆöÁâπÂæµ‰∏äÂ∞çÈΩäÊ®°ÂûãÔºåÁ¨¨‰∫åÂÄãÈöéÊÆµÊ†πÊìöÁ¨¨‰∏ÄÂÄãÈöéÊÆµÁöÑÊêçÂ§±ÂãïÊÖãË™øÊï¥ÊìæÂãïÁ¥öÂà•ÔºåÈºìÂãµÊ®°ÂûãÊé¢Á¥¢ÁõÆÊ®ôÈ†òÂüüÁöÑÊõ¥Âª£Ê≥õÁØÑÂúçÔºåÂêåÊôÇ‰øùÁïôÁèæÊúâÁöÑÊïàËÉΩ„ÄÇÈÄôÂ¢ûÂº∑‰∫ÜÊ¶ÇÂåñËÉΩÂäõÂíåÂ∞çÂπ≤ÊìæÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂú®Ê®ôÊ∫ñ SFUDA Âü∫Ê∫ñ‰∏äÁöÑË©ï‰º∞È°ØÁ§∫ÔºåDRIVE ÊåÅÁ∫åÂÑ™ÊñºÂÖàÂâçÁöÑÂêÑÁ®ÆÊñπÊ≥ïÔºåÂú®Ë§áÈõúÁöÑÁõÆÊ®ôÈ†òÂüü‰∏≠Êèê‰æõÊîπÂñÑÁöÑÈÅ©ÊáâÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÆöÊÄß„ÄÇ</paragraph>

##### **Partial Identifiability and Misspecification in Inverse Reinforcement Learning**
2411.15951v1 by Joar Skalse, Alessandro Abate

The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function
$R$ from a policy $\pi$. This problem is difficult, for several reasons. First
of all, there are typically multiple reward functions which are compatible with
a given policy; this means that the reward function is only *partially
identifiable*, and that IRL contains a certain fundamental degree of ambiguity.
Secondly, in order to infer $R$ from $\pi$, an IRL algorithm must have a
*behavioural model* of how $\pi$ relates to $R$. However, the true relationship
between human preferences and human behaviour is very complex, and practically
impossible to fully capture with a simple model. This means that the
behavioural model in practice will be *misspecified*, which raises the worry
that it might lead to unsound inferences if applied to real-world data. In this
paper, we provide a comprehensive mathematical analysis of partial
identifiability and misspecification in IRL. Specifically, we fully
characterise and quantify the ambiguity of the reward function for all of the
behavioural models that are most common in the current IRL literature. We also
provide necessary and sufficient conditions that describe precisely how the
observed demonstrator policy may differ from each of the standard behavioural
models before that model leads to faulty inferences about the reward function
$R$. In addition to this, we introduce a cohesive framework for reasoning about
partial identifiability and misspecification in IRL, together with several
formal tools that can be used to easily derive the partial identifiability and
misspecification robustness of new IRL models, or analyse other kinds of reward
learning algorithms.

ÊëòË¶ÅÔºöÈÄÜÂêëÂº∑ÂåñÂ≠∏Áøí (IRL) ÁöÑÁõÆÊ®ôÊòØÂæûÁ≠ñÁï• $\pi$ Êé®Ë´ñÁçéÂãµÂáΩÊï∏ $R$„ÄÇÈÄôÂÄãÂïèÈ°åÂæàÂõ∞Èõ£ÔºåÂéüÂõ†ÊúâÂπæÂÄã„ÄÇÈ¶ñÂÖàÔºåÈÄöÂ∏∏ÊúâÂ§öÂÄãÁçéÂãµÂáΩÊï∏ËàáÁµ¶ÂÆöÁöÑÁ≠ñÁï•Áõ∏ÂÆπÔºõÈÄôË°®Á§∫ÁçéÂãµÂáΩÊï∏ÂÉÖ *ÈÉ®ÂàÜÂèØË≠òÂà•*ÔºåËÄå IRL ÂåÖÂê´‰∏ÄÂÆöÁ®ãÂ∫¶ÁöÑÂü∫Êú¨Ê®°Á®úÂÖ©ÂèØÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÁÇ∫‰∫ÜÂæû $\pi$ Êé®Ë´ñ $R$ÔºåIRL ÊºîÁÆóÊ≥ïÂøÖÈ†àÂÖ∑ÂÇô $\pi$ Ëàá $R$ Áõ∏ÈóúÊÄßÁöÑ *Ë°åÁÇ∫Ê®°Âºè*„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÂÅèÂ•ΩËàá‰∫∫È°ûË°åÁÇ∫‰πãÈñìÁöÑÁúüÊ≠£Èóú‰øÇÈùûÂ∏∏Ë§áÈõúÔºåËÄå‰∏îÂØ¶Èöõ‰∏ä‰∏çÂèØËÉΩ‰ΩøÁî®Á∞°ÂñÆÊ®°ÂûãÂÆåÂÖ®ÊçïÊçâ„ÄÇÈÄôË°®Á§∫ÂØ¶Èöõ‰∏äÁöÑË°åÁÇ∫Ê®°ÂºèÂ∞áÊúÉ *ÈåØË™§ÊåáÂÆö*ÔºåÈÄôÂºïÁôº‰∫ÜÊìîÊÜÇÔºåÂç≥Â¶ÇÊûúÂ∞áÂÖ∂ÊáâÁî®ÊñºÁúüÂØ¶‰∏ñÁïåË≥áÊñôÔºåÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÂÅ•ÂÖ®ÁöÑÊé®Ë´ñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂ∞ç IRL ‰∏≠ÈÉ®ÂàÜÂèØË≠òÂà•ÊÄßÂíåÈåØË™§ÊåáÂÆöÁöÑÂÖ®Èù¢Êï∏Â≠∏ÂàÜÊûê„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂÖ®Èù¢ÊèèËø∞‰∏¶ÈáèÂåñ‰∫ÜÁï∂Ââç IRL ÊñáÁçª‰∏≠ÊúÄÂ∏∏Ë¶ãÁöÑÊâÄÊúâË°åÁÇ∫Ê®°ÂºèÁöÑÁçéÂãµÂáΩÊï∏ÁöÑÊ®°Á®úÂÖ©ÂèØÊÄß„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫ÜÂøÖË¶Å‰∏îÂÖÖÂàÜÁöÑÊ¢ù‰ª∂ÔºåÁ≤æÁ¢∫ÊèèËø∞‰∫ÜËßÄÂØüÂà∞ÁöÑÁ§∫ÁØÑÁ≠ñÁï•ÂèØËÉΩËàáÊØèÂÄãÊ®ôÊ∫ñË°åÁÇ∫Ê®°ÂºèÊúâ‰Ωï‰∏çÂêåÔºåÁÑ∂ÂæåË©≤Ê®°ÂûãÊâçÊúÉÂ∞çÁçéÂãµÂáΩÊï∏ $R$ Áî¢ÁîüÈåØË™§ÁöÑÊé®Ë´ñ„ÄÇÈô§Ê≠§‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÈóúÊñº IRL ‰∏≠ÈÉ®ÂàÜÂèØË≠òÂà•ÊÄßÂíåÈåØË™§ÊåáÂÆöÁöÑÊé®ÁêÜÁöÑÂÖßËÅöÊ°ÜÊû∂Ôºå‰ª•ÂèäÂπæÂÄãÂèØ‰ª•ËºïÈ¨ÜÊé®Â∞éÊñ∞ IRL Ê®°ÂûãÁöÑÈÉ®ÂàÜÂèØË≠òÂà•ÊÄßÂíåÈåØË™§ÊåáÂÆöÂÅ•ÂÖ®ÊÄßÁöÑÊ≠£ÂºèÂ∑•ÂÖ∑ÔºåÊàñÂàÜÊûêÂÖ∂‰ªñÈ°ûÂûãÁöÑÁçéÂãµÂ≠∏ÁøíÊºîÁÆóÊ≥ï„ÄÇ

##### **Generative Context Distillation**
2411.15927v1 by Haebin Shin, Lei Ji, Yeyun Gong, Sungdong Kim, Eunbi Choi, Minjoon Seo

Prompts used in recent large language model based applications are often
fixed and lengthy, leading to significant computational overhead. To address
this challenge, we propose Generative Context Distillation (GCD), a lightweight
prompt internalization method that employs a joint training approach. This
method not only replicates the behavior of models with prompt inputs but also
generates the content of the prompt along with reasons for why the model's
behavior should change accordingly. We demonstrate that our approach
effectively internalizes complex prompts across various agent-based application
scenarios. For effective training without interactions with the dedicated
environments, we introduce a data synthesis technique that autonomously
collects conversational datasets by swapping the roles of the agent and
environment. This method is especially useful in scenarios where only a
predefined prompt is available without a corresponding training dataset. By
internalizing complex prompts, Generative Context Distillation enables
high-performance and efficient inference without the need for explicit prompts.

ÊëòË¶ÅÔºöÊúÄËøëÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊáâÁî®Á®ãÂºèÊâÄ‰ΩøÁî®ÁöÑÊèêÁ§∫ÈÄöÂ∏∏ÊòØÂõ∫ÂÆöÁöÑ‰∏îÂÜóÈï∑ÁöÑÔºåÂ∞éËá¥È°ØËëóÁöÑÈÅãÁÆóË≤†Êìî„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ÁîüÊàêÂºèËÑàÁµ°Ëí∏È§æ (GCD)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆËºïÈáèÁ¥öÁöÑÊèêÁ§∫ÂÖßÂåñÊñπÊ≥ïÔºåÊé°Áî®ËÅØÂêàË®ìÁ∑¥ÊñπÊ≥ï„ÄÇÊ≠§ÊñπÊ≥ï‰∏çÂÉÖË§áË£Ω‰∫ÜÂÖ∑ÊúâÊèêÁ§∫Ëº∏ÂÖ•ÁöÑÊ®°ÂûãÁöÑË°åÁÇ∫ÔºåÈÇÑÁîüÊàê‰∫ÜÊèêÁ§∫ÁöÑÂÖßÂÆπ‰ª•ÂèäÊ®°ÂûãË°åÁÇ∫ÊáâÁõ∏ÊáâÊîπËÆäÁöÑÂéüÂõ†„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊïàÂú∞Â∞áË§áÈõúÁöÑÊèêÁ§∫ÂÖßÂåñÂà∞ÂêÑÁ®ÆÂü∫Êñº‰ª£ÁêÜÁöÑÊáâÁî®Â†¥ÊôØ‰∏≠„ÄÇÁÇ∫‰∫ÜÂú®‰∏çËàáÂ∞àÁî®Áí∞Â¢É‰∫íÂãïÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÊúâÊïàË®ìÁ∑¥ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆË≥áÊñôÂêàÊàêÊäÄË°ìÔºåË©≤ÊäÄË°ìÈÄöÈÅé‰∫§Êèõ‰ª£ÁêÜÂíåÁí∞Â¢ÉÁöÑËßíËâ≤‰æÜËá™‰∏ªÊî∂ÈõÜÂ∞çË©±Ë≥áÊñôÈõÜ„ÄÇÊ≠§ÊñπÊ≥ïÂú®Âè™ÊúâÈ†êÂÆöÁæ©ÊèêÁ§∫ËÄåÊ≤íÊúâÁõ∏ÊáâË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑÊÉÖÊ≥Å‰∏ãÁâπÂà•ÊúâÁî®„ÄÇÈÄöÈÅéÂÖßÂåñË§áÈõúÁöÑÊèêÁ§∫ÔºåÁîüÊàêÂºèËÑàÁµ°Ëí∏È§æÂèØ‰ª•Âú®‰∏çÈúÄË¶ÅÊòéÁ¢∫ÊèêÁ§∫ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÈ´òÊÄßËÉΩÂíåÊúâÊïàÁöÑÊé®ÁêÜ„ÄÇ

##### **Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan**
2411.15923v1 by Saba Zahid, Sajid Ghuffar, Obaid-ur-Rehman, Syed Roshaan Ali Shah

This study explores the effectiveness of multi-temporal satellite imagery for
better functional field boundary delineation using deep learning semantic
segmentation architecture on two distinct geographical and multi-scale farming
systems of Netherlands and Pakistan. Multidate images of April, August and
October 2022 were acquired for PlanetScope and Sentinel-2 in sub regions of
Netherlands and November 2022, February and March 2023 for selected area of
Dunyapur in Pakistan. For Netherlands, Basic registration crop parcels (BRP)
vector layer was used as labeled training data. while self-crafted field
boundary vector data were utilized for Pakistan. Four deep learning models with
UNET architecture were evaluated using different combinations of multi-date
images and NDVI stacks in the Netherlands subregions. A comparative analysis of
IoU scores assessed the effectiveness of the proposed multi-date NDVI stack
approach. These findings were then applied for transfer learning, using
pre-trained models from the Netherlands on the selected area in Pakistan.
Additionally, separate models were trained using self-crafted field boundary
data for Pakistan, and combined models were developed using data from both the
Netherlands and Pakistan. Results indicate that multi-date NDVI stacks provide
additional temporal context, reflecting crop growth over different times of the
season. The study underscores the critical role of multi-scale ground
information from diverse geographical areas in developing robust and
universally applicable models for field boundary delineation. The results also
highlight the importance of fine spatial resolution for extraction of field
boundaries in regions with small scale framing. The findings can be extended to
multi-scale implementations for improved automatic field boundary delineation
in heterogeneous agricultural environments.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂ§öÊôÇÁõ∏Ë°õÊòüÂΩ±ÂÉèÁöÑÊúâÊïàÊÄßÔºå‰ª•‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíË™ûÁæ©ÂàÜÂâ≤ÁµêÊßãÂú®Ëç∑Ëò≠ÂíåÂ∑¥Âü∫ÊñØÂù¶ÂÖ©ÂÄã‰∏çÂêåÁöÑÂú∞ÁêÜÂíåÂ§öÂ∞∫Â∫¶Ëæ≤Ê•≠Á≥ªÁµ±‰∏≠ÔºåÈÄ≤Ë°åÊõ¥Â•ΩÁöÑÂäüËÉΩÊÄßÁî∞ÈñìÈÇäÁïåÊèèÁπ™„ÄÇ2022 Âπ¥ 4 Êúà„ÄÅ8 ÊúàÂíå 10 ÊúàÁöÑÂ§öÊó•ÊúüÂΩ±ÂÉèÂ∑≤ÈáùÂ∞ç PlanetScope Âíå Sentinel-2 Áç≤ÂèñÔºå‰ΩçÊñºËç∑Ëò≠ÁöÑÊ¨°ÂçÄÂüüÔºå‰ª•Âèä 2022 Âπ¥ 11 Êúà„ÄÅ2023 Âπ¥ 2 ÊúàÂíå 3 ÊúàÔºå‰ΩçÊñºÂ∑¥Âü∫ÊñØÂù¶ Dunyapur ÁöÑÁâπÂÆöÂçÄÂüü„ÄÇÂ∞çÊñºËç∑Ëò≠ÔºåÂü∫Êú¨Ë®ªÂÜä‰ΩúÁâ©Âú∞Â°ä (BRP) ÂêëÈáèÂúñÂ±§Áî®‰ΩúÊ®ôÁ±§Ë®ìÁ∑¥Ë≥áÊñô„ÄÇËÄåËá™Ë£ΩÁöÑÁî∞ÈñìÈÇäÁïåÂêëÈáèË≥áÊñôÂâáÁî®ÊñºÂ∑¥Âü∫ÊñØÂù¶„ÄÇ‰ΩøÁî® UNET ÁµêÊßãÁöÑÂõõÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®Ëç∑Ëò≠Ê¨°ÂçÄÂüü‰∏≠‰ΩøÁî®Â§öÊó•ÊúüÂΩ±ÂÉèÂíå NDVI Â†ÜÁñäÁöÑ‰∏çÂêåÁµÑÂêàÈÄ≤Ë°åË©ï‰º∞„ÄÇIoU ÂàÜÊï∏ÁöÑÊØîËºÉÂàÜÊûêË©ï‰º∞‰∫ÜÊâÄÊèêÂá∫ÁöÑÂ§öÊó•Êúü NDVI Â†ÜÁñäÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ÂæåÂ∞áÈÄô‰∫õÁôºÁèæÊáâÁî®ÊñºÈÅ∑ÁßªÂ≠∏ÁøíÔºå‰ΩøÁî®‰æÜËá™Ëç∑Ëò≠ÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåÊñºÂ∑¥Âü∫ÊñØÂù¶ÁöÑÁâπÂÆöÂçÄÂüü„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®Ëá™Ë£ΩÁöÑÁî∞ÈñìÈÇäÁïåË≥áÊñôÁÇ∫Â∑¥Âü∫ÊñØÂù¶Ë®ìÁ∑¥‰∫ÜÂñÆÁç®ÁöÑÊ®°ÂûãÔºå‰∏¶‰ΩøÁî®‰æÜËá™Ëç∑Ëò≠ÂíåÂ∑¥Âü∫ÊñØÂù¶ÁöÑË≥áÊñôÈñãÁôº‰∫ÜÁµÑÂêàÊ®°Âûã„ÄÇÁµêÊûúË°®ÊòéÔºåÂ§öÊó•Êúü NDVI Â†ÜÁñäÊèê‰æõ‰∫ÜÈ°çÂ§ñÁöÑÊôÇÈñìËÑàÁµ°ÔºåÂèçÊò†‰∫Ü‰∏çÂêåÂ≠£ÁØÄ‰ΩúÁâ©ÁöÑÁîüÈï∑ÊÉÖÊ≥Å„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫Ü‰æÜËá™‰∏çÂêåÂú∞ÁêÜÂçÄÂüüÁöÑÂ§öÂ∞∫Â∫¶Âú∞Èù¢Ë≥áË®äÂú®ÈñãÁôºÁî®ÊñºÁî∞ÈñìÈÇäÁïåÊèèÁπ™ÁöÑÂº∑ÂÅ•‰∏îÊôÆÈÅçÈÅ©Áî®ÁöÑÊ®°Âûã‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÁµêÊûú‰πüÁ™ÅÂá∫‰∫ÜÁ≤æÁ¥∞Á©∫ÈñìËß£ÊûêÂ∫¶Â∞çÊñºÂú®Â∞èË¶èÊ®°ÂèñÊôØÂçÄÂüü‰∏≠ËêÉÂèñÁî∞ÈñìÈÇäÁïåÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄô‰∫õÁôºÁèæÂèØ‰ª•Êì¥Â±ïÂà∞Â§öÂ∞∫Â∫¶ÂØ¶‰ΩúÔºå‰ª•ÊîπÂñÑÁï∞Ë≥™Ëæ≤Ê•≠Áí∞Â¢É‰∏≠ÁöÑËá™ÂãïÁî∞ÈñìÈÇäÁïåÊèèÁπ™„ÄÇ

##### **A Training-Free Approach for Music Style Transfer with Latent Diffusion Models**
2411.15913v1 by Sooyoung Kim, Joonwoo Kwon, Heehwan Wang, Shinjae Yoo, Yuewei Lin, Jiook Cha

Music style transfer, while offering exciting possibilities for personalized
music generation, often requires extensive training or detailed textual
descriptions. This paper introduces a novel training-free approach leveraging
pre-trained Latent Diffusion Models (LDMs). By manipulating the self-attention
features of the LDM, we effectively transfer the style of reference music onto
content music without additional training. Our method achieves superior style
transfer and melody preservation compared to existing methods. This work opens
new creative avenues for personalized music generation.

ÊëòË¶ÅÔºöÈü≥Ê®ÇÈ¢®Ê†ºËΩâÁßªÂú®Êèê‰æõÂÄã‰∫∫ÂåñÈü≥Ê®ÇÁîüÊàêÁöÑ‰ª§‰∫∫ËààÂ•ÆÁöÑÂèØËÉΩÊÄßÊôÇÔºåÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑË®ìÁ∑¥ÊàñË©≥Á¥∞ÁöÑÊñáÂ≠óÊèèËø∞„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂà©Áî®È†êË®ìÁ∑¥ÊΩõÂú®Êì¥Êï£Ê®°Âûã (LDM) ÁöÑÊñ∞ÁÑ°Ë®ìÁ∑¥ÊñπÊ≥ï„ÄÇÈÄöÈÅéÊìçÁ∏± LDM ÁöÑËá™ÊàëÊ≥®ÊÑèÁâπÂæµÔºåÊàëÂÄëÊúâÊïàÂú∞Â∞áÂèÉËÄÉÈü≥Ê®ÇÁöÑÈ¢®Ê†ºËΩâÁßªÂà∞ÂÖßÂÆπÈü≥Ê®Ç‰∏äÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñÁöÑË®ìÁ∑¥„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊäÄË°ìÂØ¶Áèæ‰∫ÜÂá∫Ëâ≤ÁöÑÈ¢®Ê†ºËΩâÁßªÂíåÊóãÂæã‰øùÁïô„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñÈü≥Ê®ÇÁîüÊàêÈñãÂïü‰∫ÜÊñ∞ÁöÑÂâµ‰ΩúÈÄîÂæë„ÄÇ

##### **Bimanual Grasp Synthesis for Dexterous Robot Hands**
2411.15903v1 by Yanming Shao, Chenxi Xiao

Humans naturally perform bimanual skills to handle large and heavy objects.
To enhance robots' object manipulation capabilities, generating effective
bimanual grasp poses is essential. Nevertheless, bimanual grasp synthesis for
dexterous hand manipulators remains underexplored. To bridge this gap, we
propose the BimanGrasp algorithm for synthesizing bimanual grasps on 3D
objects. The BimanGrasp algorithm generates grasp poses by optimizing an energy
function that considers grasp stability and feasibility. Furthermore, the
synthesized grasps are verified using the Isaac Gym physics simulation engine.
These verified grasp poses form the BimanGrasp-Dataset, the first large-scale
synthesized bimanual dexterous hand grasp pose dataset to our knowledge. The
dataset comprises over 150k verified grasps on 900 objects, facilitating the
synthesis of bimanual grasps through a data-driven approach. Last, we propose
BimanGrasp-DDPM, a diffusion model trained on the BimanGrasp-Dataset. This
model achieved a grasp synthesis success rate of 69.87\% and significant
acceleration in computational speed compared to BimanGrasp algorithm.

ÊëòË¶ÅÔºö‰∫∫È°ûËá™ÁÑ∂ÊúÉÂü∑Ë°åÈõôÊâãÊäÄËÉΩ‰æÜËôïÁêÜÂ§ßÂûãÂíåÈáçÂûãÁâ©È´î„ÄÇ
ÁÇ∫‰∫ÜÂ¢ûÂº∑Ê©üÂô®‰∫∫ÁöÑÁâ©È´îÊìç‰ΩúËÉΩÂäõÔºåÁî¢ÁîüÊúâÊïàÁöÑ
ÈõôÊâãÊäìÊè°ÂßøÂã¢Ëá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈùàÂ∑ßÁöÑÊâãÈÉ®ÊìçÁ∏±Âô®ÁöÑ
ÈõôÊâãÊäìÊè°ÂêàÊàê‰ªçÁÑ∂Êú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄë
ÊèêÂá∫‰∫Ü BimanGrasp ÊºîÁÆóÊ≥ïÔºåÁî®ÊñºÂú® 3D
Áâ©È´î‰∏äÂêàÊàêÈõôÊâãÊäìÊè°„ÄÇBimanGrasp ÊºîÁÆóÊ≥ïÈÄèÈÅéÊúÄ‰Ω≥ÂåñËÄÉÈáèÊäìÊè°Á©©ÂÆöÊÄßÂíåÂèØË°åÊÄßÁöÑËÉΩÈáèÂáΩÊï∏‰æÜÁî¢ÁîüÊäìÊè°ÂßøÂã¢„ÄÇÊ≠§Â§ñÔºå
ÂêàÊàêÁöÑÊäìÊè°‰ΩøÁî® Isaac Gym Áâ©ÁêÜÊ®°Êì¨ÂºïÊìéÈÄ≤Ë°åÈ©óË≠â„ÄÇ
ÈÄô‰∫õÁ∂ìÈÅéÈ©óË≠âÁöÑÊäìÊè°ÂßøÂã¢ÊßãÊàê‰∫Ü BimanGrasp-DatasetÔºåÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ§ßË¶èÊ®°ÂêàÊàêÁöÑÈõôÊâãÈùàÂ∑ßÊâãÊäìÊè°ÂßøÂã¢Ë≥áÊñôÈõÜ„ÄÇË©≤
Ë≥áÊñôÈõÜÂåÖÂê´Âú® 900 ÂÄãÁâ©È´î‰∏äÁ∂ìÈÅéÈ©óË≠âÁöÑ 150k ÂÄãÊäìÊè°Ôºå‰øÉÈÄ≤‰∫ÜÈÄèÈÅéË≥áÊñôÈ©ÖÂãïÊñπÊ≥ïÂêàÊàêÈõôÊâãÊäìÊè°„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü
BimanGrasp-DDPMÔºåÈÄôÊòØ‰∏ÄÂÄãÂú® BimanGrasp-Dataset ‰∏äË®ìÁ∑¥ÁöÑÊì¥Êï£Ê®°Âûã„ÄÇËàá BimanGrasp ÊºîÁÆóÊ≥ïÁõ∏ÊØîÔºåÊ≠§
Ê®°ÂûãÂØ¶Áèæ‰∫Ü 69.87% ÁöÑÊäìÊè°ÂêàÊàêÊàêÂäüÁéáÔºå‰∏¶È°ØËëóÂä†ÈÄü‰∫ÜÈÅãÁÆóÈÄüÂ∫¶„ÄÇ

##### **Distribution-aware Online Continual Learning for Urban Spatio-Temporal Forecasting**
2411.15893v1 by Chengxin Wang, Gary Tan, Swagato Barman Roy, Beng Chin Ooi

Urban spatio-temporal (ST) forecasting is crucial for various urban
applications such as intelligent scheduling and trip planning. Previous studies
focus on modeling ST correlations among urban locations in offline settings,
which often neglect the non-stationary nature of urban ST data, particularly,
distribution shifts over time. This oversight can lead to degraded performance
in real-world scenarios. In this paper, we first analyze the distribution
shifts in urban ST data, and then introduce DOST, a novel online continual
learning framework tailored for ST data characteristics. DOST employs an
adaptive ST network equipped with a variable-independent adapter to address the
unique distribution shifts at each urban location dynamically. Further, to
accommodate the gradual nature of these shifts, we also develop an
awake-hibernate learning strategy that intermittently fine-tunes the adapter
during the online phase to reduce computational overhead. This strategy
integrates a streaming memory update mechanism designed for urban ST sequential
data, enabling effective network adaptation to new patterns while preventing
catastrophic forgetting. Experimental results confirm DOST's superiority over
state-of-the-art models on four real-world datasets, providing online forecasts
within an average of 0.1 seconds and achieving a 12.89% reduction in forecast
errors compared to baseline models.

ÊëòË¶ÅÔºöÂüéÂ∏ÇÊôÇÁ©∫ (ST) È†êÊ∏¨Â∞çÊñºÂêÑÈ†ÖÂüéÂ∏ÇÊáâÁî®Ëá≥ÈóúÈáçË¶ÅÔºå‰æãÂ¶ÇÊô∫ÊÖßÊéíÁ®ãÂíåË°åÁ®ãË¶èÂäÉ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÂú®Èõ¢Á∑öË®≠ÂÆö‰∏≠Âª∫Ê®°ÂüéÂ∏Ç‰ΩçÁΩÆ‰πãÈñìÁöÑ ST ÈóúËÅØÊÄßÔºåÈÄôÂ∏∏Â∏∏ÂøΩÁï•‰∫ÜÂüéÂ∏Ç ST Ë≥áÊñôÁöÑÈùûÂπ≥Á©©ÁâπÊÄßÔºåÁâπÂà•ÊòØÈö®ËëóÊôÇÈñìÊé®ÁßªÁöÑÂàÜÈÖçËΩâÁßª„ÄÇÈÄôÁ®ÆÁñèÂøΩÂèØËÉΩÂ∞éËá¥ÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÁöÑÊïàËÉΩ‰∏ãÈôç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÂàÜÊûêÂüéÂ∏Ç ST Ë≥áÊñô‰∏≠ÁöÑÂàÜÈÖçËΩâÁßªÔºåÁÑ∂Âæå‰ªãÁ¥π DOSTÔºå‰∏ÄÂÄãÈáùÂ∞ç ST Ë≥áÊñôÁâπÊÄßÁöÑÊñ∞Á©éÁ∑ö‰∏äÊåÅÁ∫åÂ≠∏ÁøíÊû∂Êßã„ÄÇDOST ‰ΩøÁî®ÈÖçÂÇôÂèØËÆäÁç®Á´ãÈÅ©ÈÖçÂô®ÁöÑËá™ÈÅ©Êáâ ST Á∂≤Ë∑ØÔºå‰ª•ÂãïÊÖãËß£Ê±∫ÊØèÂÄãÂüéÂ∏Ç‰ΩçÁΩÆÁöÑÁç®ÁâπÂàÜÈÖçËΩâÁßª„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÈÅ©ÊáâÈÄô‰∫õËΩâÁßªÁöÑÊº∏ÈÄ≤ÂºèÁâπÊÄßÔºåÊàëÂÄëÈÇÑÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊ∏ÖÈÜí‰ºëÁú†Â≠∏ÁøíÁ≠ñÁï•ÔºåÂú®Á∑ö‰∏äÈöéÊÆµÈñìÊ≠áÊÄßÂú∞ÂæÆË™øÈÅ©ÈÖçÂô®Ôºå‰ª•Èôç‰ΩéÈÅãÁÆóË≤†Êìî„ÄÇÊ≠§Á≠ñÁï•Êï¥Âêà‰∫Ü‰∏ÄÂÄãÂ∞àÁÇ∫ÂüéÂ∏Ç ST È†ÜÂ∫èË≥áÊñôË®≠Ë®àÁöÑ‰∏≤ÊµÅË®òÊÜ∂È´îÊõ¥Êñ∞Ê©üÂà∂ÔºåËÆìÁ∂≤Ë∑ØËÉΩÊúâÊïàÈÅ©ÊáâÊñ∞ÁöÑÊ®°ÂºèÔºåÂêåÊôÇÈò≤Ê≠¢ÁÅΩÈõ£ÊÄßÈÅ∫Âøò„ÄÇÂØ¶È©óÁµêÊûúË≠âÂØ¶ DOST Âú®ÂõõÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåÂú®Âπ≥Âùá 0.1 ÁßíÂÖßÊèê‰æõÁ∑ö‰∏äÈ†êÊ∏¨Ôºå‰∏¶ËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÈ†êÊ∏¨Ë™§Â∑ÆÊ∏õÂ∞ë‰∫Ü 12.89%„ÄÇ

##### **Evaluating Large Language Models for Causal Modeling**
2411.15888v1 by Houssam Razouk, Leonie Benischke, Georg Niess, Roman Kern

In this paper, we consider the process of transforming causal domain
knowledge into a representation that aligns more closely with guidelines from
causal data science. To this end, we introduce two novel tasks related to
distilling causal domain knowledge into causal variables and detecting
interaction entities using LLMs. We have determined that contemporary LLMs are
helpful tools for conducting causal modeling tasks in collaboration with human
experts, as they can provide a wider perspective. Specifically, LLMs, such as
GPT-4-turbo and Llama3-70b, perform better in distilling causal domain
knowledge into causal variables compared to sparse expert models, such as
Mixtral-8x22b. On the contrary, sparse expert models such as Mixtral-8x22b
stand out as the most effective in identifying interaction entities. Finally,
we highlight the dependency between the domain where the entities are generated
and the performance of the chosen LLM for causal modeling.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ËÄÉÊÖÆÂ∞áÂõ†ÊûúÈ†òÂüüÁü•Ë≠òËΩâÊèõÁÇ∫ËàáÂõ†ÊûúÊï∏ÊìöÁßëÂ≠∏ÊåáÂçóÊõ¥Á∑äÂØÜÂ∞çÈΩäÁöÑË°®Á§∫ÂΩ¢ÂºèÁöÑÈÅéÁ®ã„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©ÂÄãÊñ∞‰ªªÂãôÔºåÂàÜÂà•ÊòØÂ∞áÂõ†ÊûúÈ†òÂüüÁü•Ë≠òÊèêÁÖâÁÇ∫Âõ†ÊûúËÆäÊï∏Ôºå‰ª•Âèä‰ΩøÁî® LLM Ê™¢Ê∏¨‰∫§‰∫í‰ΩúÁî®ÂØ¶È´î„ÄÇÊàëÂÄëÂ∑≤Á¢∫ÂÆöÔºåÁï∂‰ª£ LLM ÊòØËàá‰∫∫È°ûÂ∞àÂÆ∂Âêà‰ΩúÈÄ≤Ë°åÂõ†ÊûúÂª∫Ê®°‰ªªÂãôÁöÑÊúâÁî®Â∑•ÂÖ∑ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂèØ‰ª•Êèê‰æõÊõ¥Âª£ÈóäÁöÑËßÄÈªû„ÄÇÂÖ∑È´î‰æÜË™™ÔºåËàáÁ®ÄÁñèÂ∞àÂÆ∂Ê®°ÂûãÔºà‰æãÂ¶Ç Mixtral-8x22bÔºâÁõ∏ÊØîÔºåLLMÔºà‰æãÂ¶Ç GPT-4-turbo Âíå Llama3-70bÔºâÂú®Â∞áÂõ†ÊûúÈ†òÂüüÁü•Ë≠òÊèêÁÖâÁÇ∫Âõ†ÊûúËÆäÊï∏ÊñπÈù¢Ë°®ÁèæÂæóÊõ¥Â•Ω„ÄÇÁõ∏ÂèçÔºåÁ®ÄÁñèÂ∞àÂÆ∂Ê®°ÂûãÔºà‰æãÂ¶Ç Mixtral-8x22bÔºâÂú®Ë≠òÂà•‰∫§‰∫í‰ΩúÁî®ÂØ¶È´îÊñπÈù¢Ë°®ÁèæÊúÄÁÇ∫Âá∫Ëâ≤„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÂØ¶È´îÁîüÊàêÊâÄÂú®ÁöÑÈ†òÂüüËàáÊâÄÈÅ∏ LLM Âú®Âõ†ÊûúÂª∫Ê®°‰∏≠ÁöÑÊïàËÉΩ‰πãÈñìÁöÑ‰æùË≥¥Èóú‰øÇ„ÄÇ

##### **LLMs Do Not Think Step-by-step In Implicit Reasoning**
2411.15862v1 by Yijiong Yu

It has been well-known that Chain-of-Thought can remarkably enhance LLMs'
performance on complex tasks. However, because it also introduces slower
inference speeds and higher computational costs, many researches have attempted
to use implicit CoT, which does not need LLMs to explicitly generate the
intermediate steps. But there is still gap between their efficacy and typical
explicit CoT methods. This leaves us a doubt that, does implicit CoT really
equal to explicit CoT? Therefore, in this study, we address this question
through experiments. We probe the information of intermediate steps from the
model's hidden states when it is performing implicit CoT. The results
surprisingly indicate that LLMs hardly think about intermediate steps,
suggesting they may just rely on experience rather than strict step-by-step
reasoning. Moreover, we find LLMs' implicit reasoning capabilities are
susceptible and unstable, reaffirming the necessity of explicit CoT to
effectively support complex tasks.

ÊëòË¶ÅÔºöÁúæÊâÄÂë®Áü•ÔºåÊÄùÊÉ≥ÈèàÂèØ‰ª•È°ØËëóÂ¢ûÂº∑ LLM Âú®Ë§áÈõú‰ªªÂãô‰∏äÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂÆÉÈÇÑÊúÉÂ∞éËá¥ËºÉÊÖ¢ÁöÑÊé®Ë´ñÈÄüÂ∫¶ÂíåËºÉÈ´òÁöÑË®àÁÆóÊàêÊú¨ÔºåË®±Â§öÁ†îÁ©∂ÂòóË©¶‰ΩøÁî®Èö±Âºè CoTÔºåÂÆÉ‰∏çÈúÄË¶Å LLM ÊòéÁ¢∫ÁîüÊàê‰∏≠ÈñìÊ≠•È©ü„ÄÇ‰ΩÜÂÆÉÂÄëÁöÑÊïàËÉΩËàáÂÖ∏ÂûãÁöÑÈ°ØÂºè CoT ÊñπÊ≥ï‰πãÈñì‰ªçÁÑ∂Â≠òÂú®Â∑ÆË∑ù„ÄÇÈÄôËÆìÊàëÂÄëÁî¢Áîü‰∏ÄÂÄãÁñëÂïèÔºåÈö±Âºè CoT ÊòØÂê¶ÁúüÁöÑÁ≠âÊñºÈ°ØÂºè CoTÔºüÂõ†Ê≠§ÔºåÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂØ¶È©ó‰æÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÂú®Ê®°ÂûãÂü∑Ë°åÈö±Âºè CoT ÊôÇÔºåÊé¢Ë®éÂÖ∂Èö±ËóèÁãÄÊÖã‰∏≠ÈóúÊñº‰∏≠ÈñìÊ≠•È©üÁöÑË≥áË®ä„ÄÇÁµêÊûú‰ª§‰∫∫È©öË®ùÂú∞Ë°®ÊòéÔºåLLM Âπæ‰πé‰∏çÊúÉËÄÉÊÖÆ‰∏≠ÈñìÊ≠•È©üÔºåÈÄôË°®ÊòéÂÆÉÂÄëÂèØËÉΩÂÉÖ‰æùË≥¥ÊñºÁ∂ìÈ©óÔºåËÄå‰∏çÊòØÂö¥Ê†ºÁöÑÈÄêÊ≠•Êé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæ LLM ÁöÑÈö±ÂºèÊé®ÁêÜËÉΩÂäõÊòØÊïèÊÑü‰∏î‰∏çÁ©©ÂÆöÁöÑÔºåÈÄôÂÜçÊ¨°ËÇØÂÆö‰∫ÜÈ°ØÂºè CoT Âú®ÊúâÊïàÊîØÊè¥Ë§áÈõú‰ªªÂãô‰∏≠ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Unveiling the Superior Paradigm: A Comparative Study of Source-Free Domain Adaptation and Unsupervised Domain Adaptation**
2411.15844v1 by Fan Wang, Zhongyi Han, Xingbo Liu, Xin Gao, Yilong Yin

In domain adaptation, there are two popular paradigms: Unsupervised Domain
Adaptation (UDA), which aligns distributions using source data, and Source-Free
Domain Adaptation (SFDA), which leverages pre-trained source models without
accessing source data. Evaluating the superiority of UDA versus SFDA is an open
and timely question with significant implications for deploying adaptive
algorithms in practical applications. In this study, we demonstrate through
predictive coding theory and extensive experiments on multiple benchmark
datasets that SFDA generally outperforms UDA in real-world scenarios.
Specifically, SFDA offers advantages in time efficiency, storage requirements,
targeted learning objectives, reduced risk of negative transfer, and increased
robustness against overfitting. Notably, SFDA is particularly effective in
mitigating negative transfer when there are substantial distribution
discrepancies between source and target domains. Additionally, we introduce a
novel data-model fusion scenario, where data sharing among stakeholders varies
(e.g., some provide raw data while others provide only models), and reveal that
traditional UDA and SFDA methods do not fully exploit their potential in this
context. To address this limitation and capitalize on the strengths of SFDA, we
propose a novel weight estimation method that effectively integrates available
source data into multi-SFDA (MSFDA) approaches, thereby enhancing model
performance within this scenario. This work provides a thorough analysis of UDA
versus SFDA and advances a practical approach to model adaptation across
diverse real-world environments.

ÊëòË¶ÅÔºö<paragraph>Âú®È†òÂüüÈÅ©Êáâ‰∏≠ÔºåÊúâÂÖ©Á®ÆÊµÅË°åÁöÑÁØÑ‰æãÔºöÁÑ°Áõ£Áù£È†òÂüüÈÅ©Êáâ (UDA)ÔºåÂÆÉ‰ΩøÁî®‰æÜÊ∫êÊï∏ÊìöÂ∞çÈΩäÂàÜ‰ΩàÔºå‰ª•ÂèäÁÑ°‰æÜÊ∫êÈ†òÂüüÈÅ©Êáâ (SFDA)ÔºåÂÆÉÂà©Áî®È†êË®ìÁ∑¥ÁöÑ‰æÜÊ∫êÊ®°ÂûãËÄåÁÑ°ÈúÄÂ≠òÂèñ‰æÜÊ∫êÊï∏Êìö„ÄÇË©ï‰º∞ UDA Ëàá SFDA ÁöÑÂÑ™Ë∂äÊÄßÊòØ‰∏ÄÂÄãÈñãÊîæ‰∏îÂèäÊôÇÁöÑÂïèÈ°åÔºåÂ∞çÊñºÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÈÉ®ÁΩ≤ÈÅ©ÊáâÊÄßÊºîÁÆóÊ≥ïÂÖ∑ÊúâÈáçÂ§ßÊÑèÁæ©„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÈ†êÊ∏¨Á∑®Á¢ºÁêÜË´ñÂíåÂú®Â§öÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåSFDA ÈÄöÂ∏∏Âú®ÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÂÑ™Êñº UDA„ÄÇÂÖ∑È´î‰æÜË™™ÔºåSFDA Âú®ÊôÇÈñìÊïàÁéá„ÄÅÂÑ≤Â≠òÈúÄÊ±Ç„ÄÅÁõÆÊ®ôÂ≠∏ÁøíÁõÆÊ®ô„ÄÅÈôç‰ΩéË≤†Èù¢ËΩâÁßªÈ¢®Èö™ÂíåÂ¢ûÂä†Â∞çÈÅéÂ∫¶Êì¨ÂêàÁöÑÁ©©ÂÅ•ÊÄßÊñπÈù¢ÂÖ∑ÊúâÂÑ™Âã¢„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÁï∂‰æÜÊ∫êÂíåÁõÆÊ®ôÈ†òÂüü‰πãÈñìÂ≠òÂú®ÂØ¶Ë≥™ÊÄßÂàÜ‰ΩàÂ∑ÆÁï∞ÊôÇÔºåSFDA Âú®Ê∏õËºïË≤†Èù¢ËΩâÁßªÊñπÈù¢ÁâπÂà•ÊúâÊïà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑË≥áÊñôÊ®°ÂûãËûçÂêàÂ†¥ÊôØÔºåÂÖ∂‰∏≠Âà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÁöÑË≥áÊñôÂÖ±‰∫´ÊúâÊâÄ‰∏çÂêåÔºà‰æãÂ¶ÇÔºå‰∏Ä‰∫õÊèê‰æõÂéüÂßãË≥áÊñôÔºåËÄåÂè¶‰∏Ä‰∫õÂè™Êèê‰æõÊ®°ÂûãÔºâÔºå‰∏¶Êè≠Á§∫ÂÇ≥Áµ±ÁöÑ UDA Âíå SFDA ÊñπÊ≥ï‰∏¶Êú™ÂÖÖÂàÜÁôºÊèÆÂÖ∂Âú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÁöÑÊΩõÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂‰∏¶Âà©Áî® SFDA ÁöÑÂÑ™Âã¢ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ¨äÈáç‰º∞Ë®àÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊúâÊïàÂú∞Â∞áÂèØÁî®ÁöÑ‰æÜÊ∫êÊï∏ÊìöÊï¥ÂêàÂà∞Â§ö SFDA (MSFDA) ÊñπÊ≥ï‰∏≠ÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÂú®ÈÄôÁ®ÆÂ†¥ÊôØ‰∏≠ÁöÑÊïàËÉΩ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂ∞ç UDA Ëàá SFDA ÈÄ≤Ë°å‰∫ÜÂæπÂ∫ïÁöÑÂàÜÊûêÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂØ¶Áî®ÁöÑÊñπÊ≥ï‰æÜÈÅ©Êáâ‰∏çÂêåÂØ¶ÈöõÁí∞Â¢É‰∏≠ÁöÑÊ®°Âûã„ÄÇ</paragraph>

##### **Efficient and Private: Memorisation under differentially private parameter-efficient fine-tuning in language models**
2411.15831v1 by Olivia Ma, Jonathan Passerat-Palmbach, Dmitrii Usynin

Fine-tuning large language models (LLMs) for specific tasks introduces
privacy risks, as models may inadvertently memorise and leak sensitive training
data. While Differential Privacy (DP) offers a solution to mitigate these
risks, it introduces significant computational and performance trade-offs,
particularly with standard fine-tuning approaches. Previous work has primarily
focused on full-parameter updates, which are computationally intensive and may
not fully leverage DPs potential in large models. In this work, we address
these shortcomings by investigating Parameter-Efficient Fine-Tuning (PEFT)
methods under DP constraints. We show that PEFT methods achieve comparable
performance to standard fine-tuning while requiring fewer parameters and
significantly reducing privacy leakage. Furthermore, we incorporate a data
poisoning experiment involving intentional mislabelling to assess model
memorisation and directly measure privacy risks. Our findings indicate that
PEFT methods not only provide a promising alternative but also serve as a
complementary approach for privacy-preserving, resource-efficient fine-tuning
of LLMs.

ÊëòË¶ÅÔºöÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ª•ÊáâÂ∞çÁâπÂÆö‰ªªÂãôÊôÇÊúÉÂºïÁôºÈö±ÁßÅÈ¢®Èö™ÔºåÂõ†ÁÇ∫Ê®°ÂûãÂèØËÉΩÊúÉÁÑ°ÊÑèÈñìË®òÊÜ∂‰∏¶Ê¥©Èú≤ÊïèÊÑüÁöÑË®ìÁ∑¥Ë≥áÊñô„ÄÇÈõñÁÑ∂Â∑ÆÂàÜÈö±ÁßÅ (DP) Êèê‰æõ‰∫ÜËß£Ê±∫ÈÄô‰∫õÈ¢®Èö™ÁöÑÊñπÊ≥ïÔºå‰ΩÜÂÆÉÊúÉÈÄ†ÊàêÈ°ØËëóÁöÑÈÅãÁÆóÂíåÊïàËÉΩÂèñÊç®ÔºåÁâπÂà•ÊòØÊé°Áî®Ê®ôÊ∫ñÂæÆË™øÊñπÊ≥ïÊôÇ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÂÖ®ÂèÉÊï∏Êõ¥Êñ∞ÔºåÈÄôÂú®ÈÅãÁÆó‰∏äÂæàÂØÜÈõÜÔºåËÄå‰∏îÂèØËÉΩÁÑ°Ê≥ïÂÖÖÂàÜÁôºÊèÆÂ§ßÂûãÊ®°Âûã‰∏≠ DP ÁöÑÊΩõÂäõ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÁ†îÁ©∂ DP Á¥ÑÊùü‰∏ãÁöÑÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT) ÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÁº∫Èªû„ÄÇÊàëÂÄëÈ°ØÁ§∫ PEFT ÊñπÊ≥ïÂèØÈÅîÊàêËàáÊ®ôÊ∫ñÂæÆË™øÁõ∏Áï∂ÁöÑÊïàËÉΩÔºåÂêåÊôÇÊâÄÈúÄÂèÉÊï∏ËºÉÂ∞ëÔºå‰∏¶Â§ßÂπÖÈôç‰ΩéÈö±ÁßÅÂ§ñÊ¥©„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ¥çÂÖ•‰∏ÄÈ†ÖË≥áÊñô‰∏≠ÊØíÂØ¶È©óÔºåÂÖ∂‰∏≠Ê∂âÂèäÊïÖÊÑèÈåØË™§Ê®ôÁ±§Ôºå‰ª•Ë©ï‰º∞Ê®°ÂûãË®òÊÜ∂‰∏¶Áõ¥Êé•Ë°°ÈáèÈö±ÁßÅÈ¢®Èö™„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåPEFT ÊñπÊ≥ï‰∏çÂÉÖÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰πü‰ΩúÁÇ∫‰∏ÄÁ®ÆË£úÂÖÖÊñπÊ≥ïÔºåÁî®Êñº LLM ÁöÑÈö±ÁßÅ‰øùË≠∑„ÄÅË≥áÊ∫êÊúâÊïàÂæÆË™ø„ÄÇ

##### **Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?**
2411.15821v1 by Aryan Sajith, Krishna Chaitanya Rao Kathala

This study investigates the relative impact of training data quality versus
quantity on the performance of small language models (SLMs), utilizing the
TinyStories dataset for empirical analysis. Analysis of dataset variations with
respect to size (25% and 50% of the original size) and duplication (controlled
rates of 25%, 50%, 75%, and 100%) were performed. Model performance was
evaluated based on the validation loss, accuracy, and perplexity metrics.
Results indicate training data quality plays a more significant role in the
overall performance of SLMs, especially given scale of this experiment. Minimal
duplication positively impacted model accuracy (+0.87% increase in accuracy at
25% duplication) without significantly increasing perplexity (+0.52% increase
going from 0% to 25% duplication) but excessive duplication led to pronounced
performance degradation (-40% drop in accuracy at 100% duplication). The
implications of this exploration extend beyond just model performance; training
large-scale models imposes significant financial and computational burdens,
which can be prohibitive for organizations, individuals, and the public at
large, especially in developing countries. Additionally, the energy consumption
associated with large-scale training raises environmental concerns.
Understanding the relative importance of data quality versus quantity could
democratize AI technology, making advanced models more accessible and
sustainable for all.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë™øÊü•Ë®ìÁ∑¥Ë≥áÊñôÂìÅË≥™Áõ∏Â∞çÊñºÊï∏ÈáèÂ∞çÂ∞èÂûãË™ûË®ÄÊ®°Âûã (SLM) ÊïàËÉΩÁöÑÁõ∏Â∞çÂΩ±ÈüøÔºå‰∏¶Âà©Áî® TinyStories Ë≥áÊñôÈõÜÈÄ≤Ë°åÂØ¶Ë≠âÂàÜÊûê„ÄÇÂàÜÊûêË≥áÊñôÈõÜËÆäÁï∞ÔºåÂåÖÊã¨Â§ßÂ∞èÔºàÂéüÂßãÂ§ßÂ∞èÁöÑ 25% Âíå 50%ÔºâÂíåÈáçË§áÔºàÂèóÊéßÊØîÁéá 25%„ÄÅ50%„ÄÅ75% Âíå 100%Ôºâ„ÄÇÊ®°ÂûãÊïàËÉΩÊ†πÊìöÈ©óË≠âÊêçÂ§±„ÄÅÊ∫ñÁ¢∫Â∫¶ÂíåÂõ∞ÊÉëÂ∫¶ÊåáÊ®ôÈÄ≤Ë°åË©ï‰º∞„ÄÇÁµêÊûúÈ°ØÁ§∫Ë®ìÁ∑¥Ë≥áÊñôÂìÅË≥™Âú® SLM ÁöÑÊï¥È´îÊïàËÉΩ‰∏≠ÊâÆÊºîÊõ¥ÈáçË¶ÅÁöÑËßíËâ≤ÔºåÁâπÂà•ÊòØÂú®Ê≠§ÂØ¶È©óÁöÑË¶èÊ®°‰∏ã„ÄÇÊúÄÂ∞èÁöÑÈáçË§áÂ∞çÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶Áî¢ÁîüÊ≠£Èù¢ÂΩ±ÈüøÔºàÈáçË§áÁéá 25% ÊôÇÊ∫ñÁ¢∫Â∫¶Â¢ûÂä† +0.87%ÔºâÔºå‰∏î‰∏çÊúÉÈ°ØËëóÂ¢ûÂä†Âõ∞ÊÉëÂ∫¶ÔºàÂæû 0% Âà∞ 25% ÈáçË§áÊôÇÂ¢ûÂä† +0.52%ÔºâÔºå‰ΩÜÈÅéÂ∫¶ÈáçË§áÊúÉÂ∞éËá¥ÊïàËÉΩÈ°ØËëó‰∏ãÈôçÔºàÈáçË§áÁéá 100% ÊôÇÊ∫ñÁ¢∫Â∫¶‰∏ãÈôç -40%Ôºâ„ÄÇÊ≠§Êé¢Ë®éÁöÑÊÑèÁæ©‰∏çÂè™Âú®ÊñºÊ®°ÂûãÊïàËÉΩÔºõË®ìÁ∑¥Â§ßÂûãÊ®°ÂûãÊúÉÈÄ†ÊàêÈ°ØËëóÁöÑË≤°ÂãôÂíåÈÅãÁÆóË≤†ÊìîÔºåÂ∞çÁµÑÁπî„ÄÅÂÄã‰∫∫ÂíåÂª£Â§ßÊ∞ëÁúæËÄåË®ÄÂèØËÉΩÈõ£‰ª•Ë≤†ÊìîÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈñãÁôº‰∏≠ÂúãÂÆ∂„ÄÇÊ≠§Â§ñÔºåËàáÂ§ßÂûãË®ìÁ∑¥Áõ∏ÈóúÁöÑËÉΩÊ∫êÊ∂àËÄó‰πüÂºïÁôºÁí∞Â¢ÉÂïèÈ°å„ÄÇ‰∫ÜËß£Ë≥áÊñôÂìÅË≥™Áõ∏Â∞çÊñºÊï∏ÈáèÁöÑÁõ∏Â∞çÈáçË¶ÅÊÄßÂèØ‰ª•‰Ωø AI ÊäÄË°ìÊ∞ë‰∏ªÂåñÔºåËÆìÂÖàÈÄ≤Ê®°ÂûãÊõ¥ÊòìÊñºÂèñÂæóÔºå‰∏îÂ∞çÊâÄÊúâ‰∫∫ËÄåË®ÄÊõ¥ÂÖ∑Ê∞∏Á∫åÊÄß„ÄÇ

##### **FastTrackTr:Towards Fast Multi-Object Tracking with Transformers**
2411.15811v1 by Pan Liao, Feng Yang, Di Wu, Jinwen Yu, Wenhui Zhao, Bo Liu

Transformer-based multi-object tracking (MOT) methods have captured the
attention of many researchers in recent years. However, these models often
suffer from slow inference speeds due to their structure or other issues. To
address this problem, we revisited the Joint Detection and Tracking (JDT)
method by looking back at past approaches. By integrating the original JDT
approach with some advanced theories, this paper employs an efficient method of
information transfer between frames on the DETR, constructing a fast and novel
JDT-type MOT framework: FastTrackTr. Thanks to the superiority of this
information transfer method, our approach not only reduces the number of
queries required during tracking but also avoids the excessive introduction of
network structures, ensuring model simplicity. Experimental results indicate
that our method has the potential to achieve real-time tracking and exhibits
competitive tracking accuracy across multiple datasets.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂü∫Êñº Transformer ÁöÑÂ§öÁõÆÊ®ôËøΩËπ§ (MOT) ÊñπÊ≥ïÂ∑≤ÂºïËµ∑Ë®±Â§öÁ†îÁ©∂‰∫∫Âì°ÁöÑÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÁî±ÊñºÂÖ∂ÁµêÊßãÊàñÂÖ∂‰ªñÂïèÈ°åÔºåÈÄöÂ∏∏ÊúÉÂ∞éËá¥Êé®Ë´ñÈÄüÂ∫¶ËºÉÊÖ¢„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂõûÈ°ßÈÅéÂéªÁöÑÊñπÊ≥ïÔºåÈáçÊñ∞ÂØ©Ë¶ñ‰∫ÜËÅØÂêàÂÅµÊ∏¨ËàáËøΩËπ§ (JDT) ÊñπÊ≥ï„ÄÇÊú¨ÊñáÈÄèÈÅéÂ∞áÂéüÂßã JDT ÊñπÊ≥ïËàá‰∏Ä‰∫õÂÖàÈÄ≤ÁöÑÁêÜË´ñÊï¥ÂêàÔºåÂú® DETR ‰∏äÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÊúâÊïàÁöÑÂπÄÈñìË≥áË®äÂÇ≥ÈÅûÊñπÊ≥ïÔºåÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂø´ÈÄü‰∏îÊñ∞Á©éÁöÑ JDT È°ûÂûã MOT Ê°ÜÊû∂ÔºöFastTrackTr„ÄÇÁî±ÊñºÈÄôÁ®ÆË≥áË®äÂÇ≥ÈÅûÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄßÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÊ∏õÂ∞ë‰∫ÜËøΩËπ§ÈÅéÁ®ã‰∏≠ÊâÄÈúÄÁöÑÊü•Ë©¢Êï∏ÈáèÔºåÈÇÑÈÅøÂÖç‰∫ÜÈÅéÂ∫¶ÂºïÂÖ•Á∂≤Ë∑ØÁµêÊßãÔºåÁ¢∫‰øù‰∫ÜÊ®°ÂûãÁöÑÁ∞°ÊΩîÊÄß„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÖ∑ÊúâÂØ¶ÁèæÂç≥ÊôÇËøΩËπ§ÁöÑÊΩõÂäõÔºå‰∏¶Âú®Â§öÂÄãË≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫ÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑËøΩËπ§Ê∫ñÁ¢∫Â∫¶„ÄÇ

##### **Benchmarking Active Learning for NILM**
2411.15805v1 by Dhruv Patel, Ankita Kumari Jain, Haikoo Khandor, Xhitij Choudhary, Nipun Batra

Non-intrusive load monitoring (NILM) focuses on disaggregating total
household power consumption into appliance-specific usage. Many advanced NILM
methods are based on neural networks that typically require substantial amounts
of labeled appliance data, which can be challenging and costly to collect in
real-world settings. We hypothesize that appliance data from all households
does not uniformly contribute to NILM model improvements. Thus, we propose an
active learning approach to selectively install appliance monitors in a limited
number of houses. This work is the first to benchmark the use of active
learning for strategically selecting appliance-level data to optimize NILM
performance. We first develop uncertainty-aware neural networks for NILM and
then install sensors in homes where disaggregation uncertainty is highest.
Benchmarking our method on the publicly available Pecan Street Dataport
dataset, we demonstrate that our approach significantly outperforms a standard
random baseline and achieves performance comparable to models trained on the
entire dataset. Using this approach, we achieve comparable NILM accuracy with
approximately 30% of the data, and for a fixed number of sensors, we observe up
to a 2x reduction in disaggregation errors compared to random sampling.

ÊëòË¶ÅÔºöÈùû‰æµÂÖ•ÂºèË≤†ËºâÁõ£Êéß (NILM) Â∞àÊ≥®ÊñºÂ∞áÂÆ∂Â∫≠Á∏ΩÁî®ÈõªÈáèÂàÜËß£ÁÇ∫ÁâπÂÆöÈõªÂô®ÁöÑÁî®Èáè„ÄÇË®±Â§öÂÖàÈÄ≤ÁöÑ NILM ÊñπÊ≥ïÈÉΩÂü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåËÄåÁ•ûÁ∂ìÁ∂≤Ë∑ØÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®ôÁ±§ÈõªÂô®Ë≥áÊñôÔºåÈÄôÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÂèØËÉΩÂæàÈõ£‰∏îÊàêÊú¨È´òÊòÇ„ÄÇÊàëÂÄëÂÅáË®≠‰æÜËá™ÊâÄÊúâÂÆ∂Â∫≠ÁöÑÈõªÂô®Ë≥áÊñô‰∏¶‰∏çÊúÉÂ∞ç NILM Ê®°ÂûãÁöÑÊîπÈÄ≤Áî¢ÁîüÂùáÁ≠âÁöÑË≤¢Áçª„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰∏ªÂãïÂ≠∏ÁøíÊñπÊ≥ïÔºå‰ª•ÈÅ∏ÊìáÊÄßÂú∞ÂÆâË£ùÈõªÂô®Áõ£ÊéßÂô®Âú®ÊúâÈôêÊï∏ÈáèÁöÑÊàøÂ±ã‰∏≠„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÈ¶ñÊ¨°Â∞ç‰∏ªÂãïÂ≠∏ÁøíÁöÑ‰ΩøÁî®ÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰ª•Á≠ñÁï•ÊÄßÂú∞ÈÅ∏ÊìáÈõªÂô®Â±§Á¥öË≥áÊñô‰æÜÊúÄ‰Ω≥Âåñ NILM ÊïàËÉΩ„ÄÇÊàëÂÄëÈ¶ñÂÖàÁÇ∫ NILM ÈñãÁôº‰∫ÜÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÊÑüÁü•ÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÁÑ∂ÂæåÂú®ÂàÜËß£‰∏çÁ¢∫ÂÆöÊÄßÊúÄÈ´òÁöÑÂÆ∂Êà∂‰∏≠ÂÆâË£ùÊÑüÊ∏¨Âô®„ÄÇÂú®ÂÖ¨ÈñãÁöÑ Pecan Street Dataport Ë≥áÊñôÈõÜ‰∏äÂ∞çÊàëÂÄëÁöÑÊ®°ÂûãÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÈ°ØËëóÂÑ™ÊñºÊ®ôÊ∫ñÈö®Ê©üÂü∫Ê∫ñÔºå‰∏¶‰∏îÈÅîÂà∞‰∫ÜËàáÂú®Êï¥ÂÄãË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÁõ∏Áï∂ÁöÑÊïàËÉΩ„ÄÇ‰ΩøÁî®ÈÄôÁ®ÆÊñπÊ≥ïÔºåÊàëÂÄë‰ª•Â§ßÁ¥Ñ 30% ÁöÑË≥áÊñôÈÅîÂà∞‰∫ÜÁõ∏Áï∂ÁöÑ NILM Á≤æÁ¢∫Â∫¶Ôºå‰∏¶‰∏îÂ∞çÊñºÂõ∫ÂÆöÊï∏ÈáèÁöÑÊÑüÊ∏¨Âô®ÔºåÊàëÂÄëËßÄÂØüÂà∞ËàáÈö®Ê©üÊäΩÊ®£Áõ∏ÊØîÔºåÂàÜËß£Ë™§Â∑ÆÊ∏õÂ∞ë‰∫Ü 2 ÂÄç„ÄÇ

