{"2409.03215": {"publish_time": "2024-09-05", "title": "xLAM: A Family of Large Action Models to Empower AI Agent Systems", "paper_summary": "Autonomous agents powered by large language models (LLMs) have attracted\nsignificant research interest. However, the open-source community faces many\nchallenges in developing specialized models for agent tasks, driven by the\nscarcity of high-quality agent datasets and the absence of standard protocols\nin this area. We introduce and publicly release xLAM, a series of large action\nmodels designed for AI agent tasks. The xLAM series includes five models with\nboth dense and mixture-of-expert architectures, ranging from 1B to 8x22B\nparameters, trained using a scalable, flexible pipeline that unifies, augments,\nand synthesizes diverse datasets to enhance AI agents' generalizability and\nperformance across varied environments. Our experimental results demonstrate\nthat xLAM consistently delivers exceptional performance across multiple agent\nability benchmarks, notably securing the 1st position on the Berkeley\nFunction-Calling Leaderboard, outperforming GPT-4, Claude-3, and many other\nmodels in terms of tool use. By releasing the xLAM series, we aim to advance\nthe performance of open-source LLMs for autonomous AI agents, potentially\naccelerating progress and democratizing access to high-performance models for\nagent tasks. Models are available at\nhttps://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4", "paper_summary_zh": "<paragraph>\u7531\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u52d5\u7684\u81ea\u4e3b\u4ee3\u7406\u5df2\u5438\u5f15\u4e86\n\u986f\u8457\u7684\u7814\u7a76\u8208\u8da3\u3002\u7136\u800c\uff0c\u958b\u6e90\u793e\u7fa4\u5728\u958b\u767c\u5c08\u9580\u7528\u65bc\u4ee3\u7406\u4efb\u52d9\u7684\u6a21\u578b\u6642\u9762\u81e8\u8a31\u591a\n\u6311\u6230\uff0c\u9019\u662f\u7531\u65bc\u7f3a\u4e4f\u9ad8\u54c1\u8cea\u7684\u4ee3\u7406\u8cc7\u6599\u96c6\u548c\u8a72\u9818\u57df\u7f3a\u4e4f\u6a19\u6e96\u5354\u5b9a\u7684\u9a45\u4f7f\u3002\u6211\u5011\u4ecb\u7d39\u4e26\u516c\u958b\u767c\u5e03 xLAM\uff0c\u9019\u662f\u4e00\u7cfb\u5217\u5c08\u70ba AI \u4ee3\u7406\u4efb\u52d9\u8a2d\u8a08\u7684\u5927\u578b\u52d5\u4f5c\u6a21\u578b\u3002xLAM \u7cfb\u5217\u5305\u62ec\u4e94\u500b\u6a21\u578b\uff0c\u5177\u6709\u5bc6\u96c6\u548c\u6df7\u5408\u5c08\u5bb6\u67b6\u69cb\uff0c\u7bc4\u570d\u5f9e 1B \u5230 8x22B \u53c3\u6578\uff0c\u4f7f\u7528\u53ef\u64f4\u5c55\u3001\u9748\u6d3b\u7684\u7ba1\u9053\u9032\u884c\u8a13\u7df4\uff0c\u8a72\u7ba1\u9053\u7d71\u4e00\u3001\u64f4\u5145\u548c\u5408\u6210\u4e0d\u540c\u7684\u8cc7\u6599\u96c6\uff0c\u4ee5\u589e\u5f37 AI \u4ee3\u7406\u5728\u5404\u7a2e\u74b0\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6548\u80fd\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cxLAM \u5728\u591a\u500b\u4ee3\u7406\u80fd\u529b\u57fa\u6e96\u4e2d\u6301\u7e8c\u63d0\u4f9b\u5353\u8d8a\u7684\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728 Berkeley \u51fd\u5f0f\u547c\u53eb\u6392\u884c\u699c\u4e0a\u7372\u5f97\u7b2c 1 \u540d\uff0c\u5728\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u512a\u65bc GPT-4\u3001Claude-3 \u548c\u8a31\u591a\u5176\u4ed6\u6a21\u578b\u3002\u901a\u904e\u767c\u5e03 xLAM \u7cfb\u5217\uff0c\u6211\u5011\u65e8\u5728\u63d0\u5347\u958b\u6e90 LLM \u5728\u81ea\u4e3b AI \u4ee3\u7406\u4e2d\u7684\u6548\u80fd\uff0c\u9019\u6709\u53ef\u80fd\u52a0\u901f\u9032\u5ea6\u4e26\u4f7f\u4ee3\u7406\u4efb\u52d9\u7684\u9ad8\u6548\u80fd\u6a21\u578b\u7684\u53d6\u5f97\u6c11\u4e3b\u5316\u3002\u6a21\u578b\u53ef\u65bc\nhttps://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4 \u53d6\u5f97</paragraph>", "author": "Jianguo Zhang et.al.", "authors": "Jianguo Zhang, Tian Lan, Ming Zhu, Zuxin Liu, Thai Hoang, Shirley Kokane, Weiran Yao, Juntao Tan, Akshara Prabhakar, Haolin Chen, Zhiwei Liu, Yihao Feng, Tulika Awalgaonkar, Rithesh Murthy, Eric Hu, Zeyuan Chen, Ran Xu, Juan Carlos Niebles, Shelby Heinecke, Huan Wang, Silvio Savarese, Caiming Xiong", "id": "2409.03215v1", "paper_url": "http://arxiv.org/abs/2409.03215v1", "repo": "null"}}