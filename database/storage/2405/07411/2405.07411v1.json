{"2405.07411": {"publish_time": "2024-05-13", "title": "MoVL:Exploring Fusion Strategies for the Domain-Adaptive Application of Pretrained Models in Medical Imaging Tasks", "paper_summary": "Medical images are often more difficult to acquire than natural images due to\nthe specialism of the equipment and technology, which leads to less medical\nimage datasets. So it is hard to train a strong pretrained medical vision\nmodel. How to make the best of natural pretrained vision model and adapt in\nmedical domain still pends. For image classification, a popular method is\nlinear probe (LP). However, LP only considers the output after feature\nextraction. Yet, there exists a gap between input medical images and natural\npretrained vision model. We introduce visual prompting (VP) to fill in the gap,\nand analyze the strategies of coupling between LP and VP. We design a joint\nlearning loss function containing categorisation loss and discrepancy loss,\nwhich describe the variance of prompted and plain images, naming this joint\ntraining strategy MoVL (Mixture of Visual Prompting and Linear Probe). We\nexperiment on 4 medical image classification datasets, with two mainstream\narchitectures, ResNet and CLIP. Results shows that without changing the\nparameters and architecture of backbone model and with less parameters, there\nis potential for MoVL to achieve full finetune (FF) accuracy (on four medical\ndatasets, average 90.91% for MoVL and 91.13% for FF). On out of distribution\nmedical dataset, our method(90.33%) can outperform FF (85.15%) with absolute\n5.18 % lead.", "paper_summary_zh": "\u533b\u5b66\u5f71\u50cf\u901a\u5e38\u6bd4\u81ea\u7136\u5f71\u50cf\u66f4\u96be\u83b7\u53d6\uff0c\u8fd9\u662f\u56e0\u4e3a\u8bbe\u5907\u548c\u6280\u672f\u7684\u4e13\u4e1a\u6027\uff0c\u5bfc\u81f4\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u8f83\u5c11\u3002\u56e0\u6b64\uff0c\u5f88\u96be\u8bad\u7ec3\u4e00\u4e2a\u5f3a\u5927\u7684\u533b\u5b66\u89c6\u89c9\u6a21\u578b\u3002\u5982\u4f55\u5145\u5206\u5229\u7528\u81ea\u7136\u9884\u8bad\u7ec3\u89c6\u89c9\u6a21\u578b\u5e76\u5728\u533b\u5b66\u9886\u57df\u8fdb\u884c\u8c03\u6574\u4ecd\u7136\u60ac\u800c\u672a\u51b3\u3002\u5bf9\u4e8e\u56fe\u50cf\u5206\u7c7b\uff0c\u4e00\u79cd\u6d41\u884c\u7684\u65b9\u6cd5\u662f\u7ebf\u6027\u63a2\u9488 (LP)\u3002\u7136\u800c\uff0cLP \u4ec5\u8003\u8651\u7279\u5f81\u63d0\u53d6\u540e\u7684\u8f93\u51fa\u3002\u7136\u800c\uff0c\u8f93\u5165\u533b\u5b66\u56fe\u50cf\u548c\u81ea\u7136\u9884\u8bad\u7ec3\u89c6\u89c9\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\u3002\u6211\u4eec\u5f15\u5165\u89c6\u89c9\u63d0\u793a (VP) \u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5e76\u5206\u6790 LP \u548c VP \u4e4b\u95f4\u7684\u8026\u5408\u7b56\u7565\u3002\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b\u5206\u7c7b\u635f\u5931\u548c\u5dee\u5f02\u635f\u5931\u7684\u8054\u5408\u5b66\u4e60\u635f\u5931\u51fd\u6570\uff0c\u63cf\u8ff0\u4e86\u63d0\u793a\u56fe\u50cf\u548c\u666e\u901a\u56fe\u50cf\u7684\u5dee\u5f02\uff0c\u5e76\u5c06\u8fd9\u79cd\u8054\u5408\u8bad\u7ec3\u7b56\u7565\u547d\u540d\u4e3a MoVL\uff08\u89c6\u89c9\u63d0\u793a\u548c\u7ebf\u6027\u63a2\u9488\u7684\u6df7\u5408\uff09\u3002\u6211\u4eec\u5728 4 \u4e2a\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4e24\u79cd\u4e3b\u6d41\u67b6\u6784 ResNet \u548c CLIP\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e0d\u6539\u53d8\u9aa8\u5e72\u6a21\u578b\u7684\u53c2\u6570\u548c\u67b6\u6784\u4e14\u53c2\u6570\u66f4\u5c11\u7684\u60c5\u51b5\u4e0b\uff0cMoVL \u6709\u53ef\u80fd\u8fbe\u5230\u5b8c\u5168\u5fae\u8c03 (FF) \u51c6\u786e\u5ea6\uff08\u5728\u56db\u4e2a\u533b\u5b66\u6570\u636e\u96c6\u4e0a\uff0cMoVL \u5e73\u5747\u4e3a 90.91%\uff0cFF \u4e3a 91.13%\uff09\u3002\u5728\u5206\u5e03\u5916\u7684\u533b\u5b66\u6570\u636e\u96c6\u4e0a\uff0c\u6211\u4eec\u7684\u65b9\u6cd5 (90.33%) \u53ef\u4ee5\u4ee5\u7edd\u5bf9 5.18% \u7684\u9886\u5148\u4f18\u52bf\u4f18\u4e8e FF (85.15%)\u3002", "author": "Haijiang Tian et.al.", "authors": "Haijiang Tian, Jingkun Yue, Xiaohong Liu, Guoxing Yang, Zeyu Jiang, Guangyu Wang", "id": "2405.07411v1", "paper_url": "http://arxiv.org/abs/2405.07411v1", "repo": "null"}}