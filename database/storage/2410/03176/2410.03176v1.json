{"2410.03176": {"publish_time": "2024-10-04", "title": "Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models", "paper_summary": "Large Vision-Language Models (LVLMs) have achieved impressive performance,\nyet research has pointed out a serious issue with object hallucinations within\nthese models. However, there is no clear conclusion as to which part of the\nmodel these hallucinations originate from. In this paper, we present an\nin-depth investigation into the object hallucination problem specifically\nwithin the CLIP model, which serves as the backbone for many state-of-the-art\nvision-language systems. We unveil that even in isolation, the CLIP model is\nprone to object hallucinations, suggesting that the hallucination problem is\nnot solely due to the interaction between vision and language modalities. To\naddress this, we propose a counterfactual data augmentation method by creating\nnegative samples with a variety of hallucination issues. We demonstrate that\nour method can effectively mitigate object hallucinations for CLIP model, and\nwe show the the enhanced model can be employed as a visual encoder, effectively\nalleviating the object hallucination issue in LVLMs.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u5df2\u53d6\u5f97\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u8868\u73fe\uff0c\u4f46\u7814\u7a76\u6307\u51fa\u9019\u4e9b\u6a21\u578b\u4e2d\u5b58\u5728\u56b4\u91cd\u7684\u7269\u4ef6\u5e7b\u89ba\u554f\u984c\u3002\u7136\u800c\uff0c\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u9019\u4e9b\u5e7b\u89ba\u6e90\u81ea\u6a21\u578b\u7684\u54ea\u500b\u90e8\u5206\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c0d CLIP \u6a21\u578b\u4e2d\u7684\u7269\u4ef6\u5e7b\u89ba\u554f\u984c\u9032\u884c\u6df1\u5165\u63a2\u8a0e\uff0c\u8a72\u6a21\u578b\u662f\u8a31\u591a\u6700\u5148\u9032\u7684\u8996\u89ba\u8a9e\u8a00\u7cfb\u7d71\u7684\u9aa8\u5e79\u3002\u6211\u5011\u63ed\u793a\uff0c\u5373\u4f7f\u5728\u5b64\u7acb\u7684\u60c5\u6cc1\u4e0b\uff0cCLIP \u6a21\u578b\u4e5f\u5bb9\u6613\u7522\u751f\u7269\u4ef6\u5e7b\u89ba\uff0c\u9019\u8868\u660e\u5e7b\u89ba\u554f\u984c\u4e26\u975e\u50c5\u50c5\u662f\u7531\u65bc\u8996\u89ba\u548c\u8a9e\u8a00\u6a21\u7d44\u4e4b\u9593\u7684\u4e92\u52d5\u6240\u81f4\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u53cd\u4e8b\u5be6\u8cc7\u6599\u64f4\u5145\u65b9\u6cd5\uff0c\u901a\u904e\u5efa\u7acb\u5177\u6709\u5404\u7a2e\u5e7b\u89ba\u554f\u984c\u7684\u8ca0\u9762\u6a23\u672c\u3002\u6211\u5011\u8b49\u660e\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u6e1b\u8f15 CLIP \u6a21\u578b\u7684\u7269\u4ef6\u5e7b\u89ba\uff0c\u4e26\u4e14\u6211\u5011\u5c55\u793a\u4e86\u589e\u5f37\u5f8c\u7684\u6a21\u578b\u53ef\u4ee5\u7528\u4f5c\u8996\u89ba\u7de8\u78bc\u5668\uff0c\u6709\u6548\u7de9\u89e3 LVLMs \u4e2d\u7684\u7269\u4ef6\u5e7b\u89ba\u554f\u984c\u3002", "author": "Yufang Liu et.al.", "authors": "Yufang Liu, Tao Ji, Changzhi Sun, Yuanbin Wu, Aimin Zhou", "id": "2410.03176v1", "paper_url": "http://arxiv.org/abs/2410.03176v1", "repo": "https://github.com/yufang-liu/clip_hallucination"}}