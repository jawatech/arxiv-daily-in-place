{"2405.15216": {"publish_time": "2024-05-24", "title": "Denoising LM: Pushing the Limits of Error Correction Models for Speech Recognition", "paper_summary": "Language models (LMs) have long been used to improve results of automatic\nspeech recognition (ASR) systems, but they are unaware of the errors that ASR\nsystems make. Error correction models are designed to fix ASR errors, however,\nthey showed little improvement over traditional LMs mainly due to the lack of\nsupervised training data. In this paper, we present Denoising LM (DLM), which\nis a $\\textit{scaled}$ error correction model trained with vast amounts of\nsynthetic data, significantly exceeding prior attempts meanwhile achieving new\nstate-of-the-art ASR performance. We use text-to-speech (TTS) systems to\nsynthesize audio, which is fed into an ASR system to produce noisy hypotheses,\nwhich are then paired with the original texts to train the DLM. DLM has several\n$\\textit{key ingredients}$: (i) up-scaled model and data; (ii) usage of\nmulti-speaker TTS systems; (iii) combination of multiple noise augmentation\nstrategies; and (iv) new decoding techniques. With a Transformer-CTC ASR, DLM\nachieves 1.5% word error rate (WER) on $\\textit{test-clean}$ and 3.3% WER on\n$\\textit{test-other}$ on Librispeech, which to our knowledge are the best\nreported numbers in the setting where no external audio data are used and even\nmatch self-supervised methods which use external audio data. Furthermore, a\nsingle DLM is applicable to different ASRs, and greatly surpassing the\nperformance of conventional LM based beam-search rescoring. These results\nindicate that properly investigated error correction models have the potential\nto replace conventional LMs, holding the key to a new level of accuracy in ASR\nsystems.", "paper_summary_zh": "<paragraph>\u8a9e\u8a00\u6a21\u578b (LM) \u9577\u671f\u4ee5\u4f86\u4e00\u76f4\u7528\u65bc\u6539\u5584\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u7cfb\u7d71\u7684\u7d50\u679c\uff0c\u4f46\u5b83\u5011\u4e0d\u77e5\u9053 ASR \u7cfb\u7d71\u6703\u7522\u751f\u54ea\u4e9b\u932f\u8aa4\u3002\u932f\u8aa4\u4fee\u6b63\u6a21\u578b\u65e8\u5728\u4fee\u6b63 ASR \u932f\u8aa4\uff0c\u7136\u800c\uff0c\u5b83\u5011\u50c5\u6bd4\u50b3\u7d71 LM \u7a0d\u6709\u6539\u5584\uff0c\u4e3b\u8981\u662f\u56e0\u70ba\u7f3a\u4e4f\u76e3\u7763\u5f0f\u8a13\u7df4\u8cc7\u6599\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u964d\u566a LM (DLM)\uff0c\u9019\u662f\u4e00\u500b\u7d93\u904e\u5927\u91cf\u5408\u6210\u8cc7\u6599\u8a13\u7df4\u7684\u300c\u7e2e\u653e\u300d\u932f\u8aa4\u4fee\u6b63\u6a21\u578b\uff0c\u5927\u5e45\u8d85\u8d8a\u5148\u524d\u7684\u5617\u8a66\uff0c\u540c\u6642\u9054\u6210\u65b0\u7684 ASR \u6700\u4f73\u8868\u73fe\u3002\u6211\u5011\u4f7f\u7528\u6587\u5b57\u8f49\u8a9e\u97f3 (TTS) \u7cfb\u7d71\u5408\u6210\u97f3\u8a0a\uff0c\u5c07\u5176\u8f38\u5165 ASR \u7cfb\u7d71\u7522\u751f\u6709\u96dc\u8a0a\u7684\u5047\u8a2d\uff0c\u7136\u5f8c\u5c07\u5176\u8207\u539f\u59cb\u6587\u5b57\u914d\u5c0d\u4f86\u8a13\u7df4 DLM\u3002DLM \u6709\u5e7e\u500b\u300c\u95dc\u9375\u8981\u7d20\u300d\uff1a(i) \u64f4\u5145\u6a21\u578b\u8207\u8cc7\u6599\uff1b(ii) \u4f7f\u7528\u591a\u91cd\u767c\u97f3\u8005 TTS \u7cfb\u7d71\uff1b(iii) \u7d50\u5408\u591a\u7a2e\u96dc\u8a0a\u64f4\u5145\u7b56\u7565\uff1b\u4ee5\u53ca (iv) \u65b0\u7684\u89e3\u78bc\u6280\u8853\u3002\u900f\u904e Transformer-CTC ASR\uff0cDLM \u5728 Librispeech \u7684\u300ctest-clean\u300d\u4e0a\u9054\u6210 1.5% \u7684\u5b57\u5143\u932f\u8aa4\u7387 (WER)\uff0c\u5728\u300ctest-other\u300d\u4e0a\u9054\u6210 3.3% \u7684 WER\uff0c\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u4e9b\u662f\u5728\u672a\u4f7f\u7528\u5916\u90e8\u97f3\u8a0a\u8cc7\u6599\u7684\u8a2d\u5b9a\u4e2d\u6240\u5831\u544a\u7684\u6700\u4f73\u6578\u5b57\uff0c\u751a\u81f3\u8207\u4f7f\u7528\u5916\u90e8\u97f3\u8a0a\u8cc7\u6599\u7684\u81ea\u76e3\u7763\u65b9\u6cd5\u76f8\u7b26\u3002\u6b64\u5916\uff0c\u55ae\u4e00 DLM \u53ef\u7528\u65bc\u4e0d\u540c\u7684 ASR\uff0c\u4e26\u5927\u5e45\u8d85\u8d8a\u57fa\u65bc\u50b3\u7d71 LM \u7684 beam-search rescoring \u7684\u8868\u73fe\u3002\u9019\u4e9b\u7d50\u679c\u986f\u793a\uff0c\u7d93\u904e\u9069\u7576\u7814\u7a76\u7684\u932f\u8aa4\u4fee\u6b63\u6a21\u578b\u6709\u6f5b\u529b\u53d6\u4ee3\u50b3\u7d71 LM\uff0c\u638c\u63e1\u8b93 ASR \u7cfb\u7d71\u9054\u5230\u65b0\u6e96\u78ba\u5ea6\u7b49\u7d1a\u7684\u95dc\u9375\u3002</paragraph>", "author": "Zijin Gu et.al.", "authors": "Zijin Gu, Tatiana Likhomanenko, He Bai, Erik McDermott, Ronan Collobert, Navdeep Jaitly", "id": "2405.15216v1", "paper_url": "http://arxiv.org/abs/2405.15216v1", "repo": "null"}}