{"2407.17911": {"publish_time": "2024-07-25", "title": "ReCorD: Reasoning and Correcting Diffusion for HOI Generation", "paper_summary": "Diffusion models revolutionize image generation by leveraging natural\nlanguage to guide the creation of multimedia content. Despite significant\nadvancements in such generative models, challenges persist in depicting\ndetailed human-object interactions, especially regarding pose and object\nplacement accuracy. We introduce a training-free method named Reasoning and\nCorrecting Diffusion (ReCorD) to address these challenges. Our model couples\nLatent Diffusion Models with Visual Language Models to refine the generation\nprocess, ensuring precise depictions of HOIs. We propose an interaction-aware\nreasoning module to improve the interpretation of the interaction, along with\nan interaction correcting module to refine the output image for more precise\nHOI generation delicately. Through a meticulous process of pose selection and\nobject positioning, ReCorD achieves superior fidelity in generated images while\nefficiently reducing computational requirements. We conduct comprehensive\nexperiments on three benchmarks to demonstrate the significant progress in\nsolving text-to-image generation tasks, showcasing ReCorD's ability to render\ncomplex interactions accurately by outperforming existing methods in HOI\nclassification score, as well as FID and Verb CLIP-Score. Project website is\navailable at https://alberthkyhky.github.io/ReCorD/ .", "paper_summary_zh": "\u64f4\u6563\u6a21\u578b\u900f\u904e\u5229\u7528\u81ea\u7136\u8a9e\u8a00\u4f86\u5f15\u5c0e\u591a\u5a92\u9ad4\u5167\u5bb9\u7684\u5efa\u7acb\uff0c\u9032\u800c\u9769\u65b0\u4e86\u5f71\u50cf\u751f\u6210\u3002\u5118\u7ba1\u6b64\u985e\u751f\u6210\u6a21\u578b\u5df2\u6709\u986f\u8457\u7684\u9032\u5c55\uff0c\u4f46\u5728\u63cf\u7e6a\u8a73\u7d30\u7684\u4eba\u985e-\u7269\u4ef6\u4e92\u52d5\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u59ff\u52e2\u548c\u7269\u4ef6\u653e\u7f6e\u7684\u6e96\u78ba\u6027\u4e0a\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u540d\u70ba\u63a8\u7406\u8207\u4fee\u6b63\u64f4\u6563 (ReCorD) \u7684\u7121\u8a13\u7df4\u65b9\u6cd5\u4f86\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\u3002\u6211\u5011\u7684\u6a21\u578b\u5c07\u6f5b\u5728\u64f4\u6563\u6a21\u578b\u8207\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u7d50\u5408\uff0c\u4ee5\u512a\u5316\u751f\u6210\u904e\u7a0b\uff0c\u78ba\u4fdd\u7cbe\u78ba\u63cf\u7e6a HOI\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u4e92\u52d5\u611f\u77e5\u63a8\u7406\u6a21\u7d44\u4f86\u6539\u5584\u4e92\u52d5\u7684\u8a6e\u91cb\uff0c\u4e26\u63d0\u51fa\u4e86\u4e00\u500b\u4e92\u52d5\u4fee\u6b63\u6a21\u7d44\u4f86\u512a\u5316\u8f38\u51fa\u5f71\u50cf\uff0c\u4ee5\u66f4\u7cbe\u78ba\u5730\u751f\u6210 HOI\u3002\u900f\u904e\u59ff\u52e2\u9078\u64c7\u548c\u7269\u4ef6\u5b9a\u4f4d\u7684\u7d30\u7dfb\u904e\u7a0b\uff0cReCorD \u5728\u751f\u6210\u7684\u5f71\u50cf\u4e2d\u9054\u5230\u4e86\u66f4\u9ad8\u7684\u4fdd\u771f\u5ea6\uff0c\u540c\u6642\u6709\u6548\u5730\u964d\u4f4e\u4e86\u904b\u7b97\u9700\u6c42\u3002\u6211\u5011\u5728\u4e09\u500b\u57fa\u6e96\u4e0a\u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\uff0c\u4ee5\u5c55\u793a\u5728\u89e3\u6c7a\u6587\u5b57\u5230\u5f71\u50cf\u751f\u6210\u4efb\u52d9\u65b9\u9762\u53d6\u5f97\u7684\u986f\u8457\u9032\u5c55\uff0c\u5c55\u793a\u4e86 ReCorD \u5728 HOI \u5206\u985e\u5206\u6578\u4ee5\u53ca FID \u548c\u52d5\u8a5e CLIP \u5206\u6578\u65b9\u9762\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\uff0c\u6e96\u78ba\u5448\u73fe\u8907\u96dc\u4e92\u52d5\u7684\u80fd\u529b\u3002\u5c08\u6848\u7db2\u7ad9\u53ef\u65bc https://alberthkyhky.github.io/ReCorD/ \u53d6\u5f97\u3002", "author": "Jian-Yu Jiang-Lin et.al.", "authors": "Jian-Yu Jiang-Lin, Kang-Yang Huang, Ling Lo, Yi-Ning Huang, Terence Lin, Jhih-Ciang Wu, Hong-Han Shuai, Wen-Huang Cheng", "id": "2407.17911v1", "paper_url": "http://arxiv.org/abs/2407.17911v1", "repo": "null"}}