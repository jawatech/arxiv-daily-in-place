
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-28**|**Enhancing Action Recognition by Leveraging the Hierarchical Structure of Actions and Textual Context**|Manuel Benavent-Lledo et.al.|[2410.21275v1](http://arxiv.org/abs/2410.21275v1)|[link](https://github.com/3dperceptionlab/hierarchicalactionrecognition)|
|**2024-10-28**|**Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics**|Yaniv Nikankin et.al.|[2410.21272v1](http://arxiv.org/abs/2410.21272v1)|null|
|**2024-10-28**|**EoRA: Training-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation**|Shih-Yang Liu et.al.|[2410.21271v1](http://arxiv.org/abs/2410.21271v1)|null|
|**2024-10-28**|**LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior**|Hanyu Wang et.al.|[2410.21264v1](http://arxiv.org/abs/2410.21264v1)|null|
|**2024-10-28**|**BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference**|Changwoo Lee et.al.|[2410.21262v1](http://arxiv.org/abs/2410.21262v1)|[link](https://github.com/changwoolee/blast)|
|**2024-10-28**|**AutoBench-V: Can Large Vision-Language Models Benchmark Themselves?**|Han Bao et.al.|[2410.21259v2](http://arxiv.org/abs/2410.21259v2)|null|
|**2024-10-28**|**Multi-modal AI for comprehensive breast cancer prognostication**|Jan Witowski et.al.|[2410.21256v1](http://arxiv.org/abs/2410.21256v1)|null|
|**2024-10-28**|**Are BabyLMs Second Language Learners?**|Lukas Edman et.al.|[2410.21254v1](http://arxiv.org/abs/2410.21254v1)|null|
|**2024-10-28**|**LongReward: Improving Long-context Large Language Models with AI Feedback**|Jiajie Zhang et.al.|[2410.21252v1](http://arxiv.org/abs/2410.21252v1)|null|
|**2024-10-28**|**Capacity-Aware Planning and Scheduling in Budget-Constrained Monotonic MDPs: A Meta-RL Approach**|Manav Vora et.al.|[2410.21249v1](http://arxiv.org/abs/2410.21249v1)|null|
|**2024-10-28**|**Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback**|Nour Jedidi et.al.|[2410.21242v1](http://arxiv.org/abs/2410.21242v1)|null|
|**2024-10-28**|**Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**|Zhantao Yang et.al.|[2410.21237v1](http://arxiv.org/abs/2410.21237v1)|null|
|**2024-10-28**|**Flaming-hot Initiation with Regular Execution Sampling for Large Language Models**|Weizhe Chen et.al.|[2410.21236v1](http://arxiv.org/abs/2410.21236v1)|null|
|**2024-10-28**|**LoRA vs Full Fine-tuning: An Illusion of Equivalence**|Reece Shuttleworth et.al.|[2410.21228v1](http://arxiv.org/abs/2410.21228v1)|null|
|**2024-10-28**|**Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines**|Zhixin Zhang et.al.|[2410.21220v1](http://arxiv.org/abs/2410.21220v1)|[link](https://github.com/cnzzx/vsa)|
|**2024-10-28**|**HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation**|Yuhan Chen et.al.|[2410.21216v1](http://arxiv.org/abs/2410.21216v1)|null|
|**2024-10-28**|**BongLLaMA: LLaMA for Bangla Language**|Abdullah Khan Zehady et.al.|[2410.21200v1](http://arxiv.org/abs/2410.21200v1)|null|
|**2024-10-28**|**Belief in the Machine: Investigating Epistemological Blind Spots of Language Models**|Mirac Suzgun et.al.|[2410.21195v1](http://arxiv.org/abs/2410.21195v1)|null|
|**2024-10-28**|**Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks**|Jiawei Zhang et.al.|[2410.21175v1](http://arxiv.org/abs/2410.21175v1)|null|
|**2024-10-28**|**Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction**|Qintong Zhang et.al.|[2410.21169v2](http://arxiv.org/abs/2410.21169v2)|null|
|**2024-10-28**|**CURATe: Benchmarking Personalised Alignment of Conversational AI Assistants**|Lize Alberts et.al.|[2410.21159v1](http://arxiv.org/abs/2410.21159v1)|null|
|**2024-10-28**|**M2rc-Eval: Massively Multilingual Repository-level Code Completion Evaluation**|Jiaheng Liu et.al.|[2410.21157v1](http://arxiv.org/abs/2410.21157v1)|null|
|**2024-10-28**|**SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents**|Qi Zhang et.al.|[2410.21155v1](http://arxiv.org/abs/2410.21155v1)|null|
|**2024-10-28**|**Trajectory Flow Matching with Applications to Clinical Time Series Modeling**|Xi Zhang et.al.|[2410.21154v1](http://arxiv.org/abs/2410.21154v1)|[link](https://github.com/nzhangx/trajectoryflowmatching)|
|**2024-10-28**|**Palisade -- Prompt Injection Detection Framework**|Sahasra Kokkula et.al.|[2410.21146v1](http://arxiv.org/abs/2410.21146v1)|null|
|**2024-10-28**|**uOttawa at LegalLens-2024: Transformer-based Classification Experiments**|Nima Meghdadi et.al.|[2410.21139v1](http://arxiv.org/abs/2410.21139v1)|[link](https://github.com/nimameghdadi/uottawa-at-legallens-2024-transformer-based-classification)|
|**2024-10-28**|**Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments**|Marharyta Domnich et.al.|[2410.21131v1](http://arxiv.org/abs/2410.21131v1)|null|
|**2024-10-28**|**Fast Calibrated Explanations: Efficient and Uncertainty-Aware Explanations for Machine Learning Models**|Tuwe Löfström et.al.|[2410.21129v1](http://arxiv.org/abs/2410.21129v1)|null|
|**2024-10-28**|**Retrieval-Enhanced Mutation Mastery: Augmenting Zero-Shot Prediction of Protein Language Model**|Yang Tan et.al.|[2410.21127v1](http://arxiv.org/abs/2410.21127v1)|[link](https://github.com/tyang816/protrem)|
|**2024-10-28**|**Current State-of-the-Art of Bias Detection and Mitigation in Machine Translation for African and European Languages: a Review**|Catherine Ikae et.al.|[2410.21126v1](http://arxiv.org/abs/2410.21126v1)|null|
|**2024-10-28**|**Zero-Shot Action Recognition in Surveillance Videos**|Joao Pereira et.al.|[2410.21113v1](http://arxiv.org/abs/2410.21113v1)|null|
|**2024-10-28**|**Large Language Model-assisted Speech and Pointing Benefits Multiple 3D Object Selection in Virtual Reality**|Junlong Chen et.al.|[2410.21091v1](http://arxiv.org/abs/2410.21091v1)|null|
|**2024-10-28**|**Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving**|Jiyao Wang et.al.|[2410.21086v1](http://arxiv.org/abs/2410.21086v1)|null|
|**2024-10-28**|**Stealthy Jailbreak Attacks on Large Language Models via Benign Data Mirroring**|Honglin Mu et.al.|[2410.21083v1](http://arxiv.org/abs/2410.21083v1)|null|
|**2024-10-28**|**Skip2-LoRA: A Lightweight On-device DNN Fine-tuning Method for Low-cost Edge Devices**|Hiroki Matsutani et.al.|[2410.21073v1](http://arxiv.org/abs/2410.21073v1)|null|
|**2024-10-28**|**EMOCPD: Efficient Attention-based Models for Computational Protein Design Using Amino Acid Microenvironment**|Xiaoqi Ling et.al.|[2410.21069v2](http://arxiv.org/abs/2410.21069v2)|null|
|**2024-10-28**|**CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**|Meiqi Chen et.al.|[2410.21067v1](http://arxiv.org/abs/2410.21067v1)|null|
|**2024-10-28**|**Learning to Handle Complex Constraints for Vehicle Routing Problems**|Jieyi Bi et.al.|[2410.21066v1](http://arxiv.org/abs/2410.21066v1)|[link](https://github.com/jieyibi/pip-constraint)|
|**2024-10-28**|**Kandinsky 3: Text-to-Image Synthesis for Multifunctional Generative Framework**|Vladimir Arkhipkin et.al.|[2410.21061v1](http://arxiv.org/abs/2410.21061v1)|null|
|**2024-10-28**|**CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**|Yutong Cheng et.al.|[2410.21060v1](http://arxiv.org/abs/2410.21060v1)|null|
|**2024-10-28**|**Semantic Component Analysis: Discovering Patterns in Short Texts Beyond Topics**|Florian Eichin et.al.|[2410.21054v1](http://arxiv.org/abs/2410.21054v1)|[link](https://github.com/mainlp/semantic_components)|
|**2024-10-28**|**Disentangled and Self-Explainable Node Representation Learning**|Simone Piaggesi et.al.|[2410.21043v1](http://arxiv.org/abs/2410.21043v1)|null|
|**2024-10-28**|**Sorting Out the Bad Seeds: Automatic Classification of Cryptocurrency Abuse Reports**|Gibran Gomez et.al.|[2410.21041v1](http://arxiv.org/abs/2410.21041v1)|null|
|**2024-10-28**|**Beyond Autoregression: Fast LLMs via Self-Distillation Through Time**|Justin Deschenaux et.al.|[2410.21035v1](http://arxiv.org/abs/2410.21035v1)|null|
|**2024-10-28**|**Graph Based Traffic Analysis and Delay Prediction**|Gabriele Borg et.al.|[2410.21028v1](http://arxiv.org/abs/2410.21028v1)|null|
|**2024-10-28**|**Transferable Post-training via Inverse Value Learning**|Xinyu Lu et.al.|[2410.21027v1](http://arxiv.org/abs/2410.21027v1)|null|
|**2024-10-28**|**Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems**|Helen Schneider et.al.|[2410.21014v1](http://arxiv.org/abs/2410.21014v1)|null|
|**2024-10-28**|**Frequency matters: Modeling irregular morphological patterns in Spanish with Transformers**|Akhilesh Kakolu Ramarao et.al.|[2410.21013v1](http://arxiv.org/abs/2410.21013v1)|null|
|**2024-10-28**|**FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval**|Jinlin Wang et.al.|[2410.21012v1](http://arxiv.org/abs/2410.21012v1)|null|
|**2024-10-28**|**Is GPT-4 Less Politically Biased than GPT-3.5? A Renewed Investigation of ChatGPT's Political Biases**|Erik Weber et.al.|[2410.21008v1](http://arxiv.org/abs/2410.21008v1)|null|
|**2024-10-28**|**Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering**|Zhilin Zhang et.al.|[2410.21000v1](http://arxiv.org/abs/2410.21000v1)|null|
|**2024-10-28**|**EEG-Driven 3D Object Reconstruction with Color Consistency and Diffusion Prior**|Xin Xiang et.al.|[2410.20981v2](http://arxiv.org/abs/2410.20981v2)|null|
|**2024-10-28**|**Geo-FuB: A Method for Constructing an Operator-Function Knowledge Base for Geospatial Code Generation Tasks Using Large Language Models**|Shuyang Hou et.al.|[2410.20975v1](http://arxiv.org/abs/2410.20975v1)|[link](https://github.com/whuhsy/geo-fub)|
|**2024-10-28**|**BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks**|Yunhan Zhao et.al.|[2410.20971v1](http://arxiv.org/abs/2410.20971v1)|null|
|**2024-10-28**|**Improving Detection of Person Class Using Dense Pooling**|Nouman Ahmad et.al.|[2410.20966v1](http://arxiv.org/abs/2410.20966v1)|[link](https://github.com/noumanahmad448/improving_detection_of_person_using_dense_pooling)|
|**2024-10-28**|**DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning**|Xun Guo et.al.|[2410.20964v1](http://arxiv.org/abs/2410.20964v1)|null|
|**2024-10-28**|**Neuro-symbolic Learning Yielding Logical Constraints**|Zenan Li et.al.|[2410.20957v1](http://arxiv.org/abs/2410.20957v1)|[link](https://github.com/lizn-zn/nesy-programming)|
|**2024-10-28**|**Active Legibility in Multiagent Reinforcement Learning**|Yanyu Liu et.al.|[2410.20954v1](http://arxiv.org/abs/2410.20954v1)|null|
|**2024-10-28**|**Instruction-Tuned LLMs Succeed in Document-Level MT Without Fine-Tuning -- But BLEU Turns a Blind Eye**|Yirong Sun et.al.|[2410.20941v2](http://arxiv.org/abs/2410.20941v2)|null|
|**2024-10-28**|**Attacking Misinformation Detection Using Adversarial Examples Generated by Language Models**|Piotr Przybyła et.al.|[2410.20940v1](http://arxiv.org/abs/2410.20940v1)|null|
|**2024-10-28**|**Autoformalize Mathematical Statements by Symbolic Equivalence and Semantic Consistency**|Zenan Li et.al.|[2410.20936v1](http://arxiv.org/abs/2410.20936v1)|[link](https://github.com/miracle-messi/isa-autoformal)|
|**2024-10-28**|**Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning**|Aosong Feng et.al.|[2410.20926v1](http://arxiv.org/abs/2410.20926v1)|null|
|**2024-10-28**|**FACTS: A Factored State-Space Framework For World Modelling**|Li Nanbo et.al.|[2410.20922v1](http://arxiv.org/abs/2410.20922v1)|[link](https://github.com/nanboli/facts)|
|**2024-10-28**|**NeuGPT: Unified multi-modal Neural GPT**|Yiqian Yang et.al.|[2410.20916v1](http://arxiv.org/abs/2410.20916v1)|null|
|**2024-10-28**|**Hacking Back the AI-Hacker: Prompt Injection as a Defense Against LLM-driven Cyberattacks**|Dario Pasquini et.al.|[2410.20911v1](http://arxiv.org/abs/2410.20911v1)|[link](https://github.com/pasquini-dario/project_mantis)|
|**2024-10-28**|**Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models**|Weijian Luo et.al.|[2410.20898v1](http://arxiv.org/abs/2410.20898v1)|null|
|**2024-10-28**|**Active Causal Structure Learning with Latent Variables: Towards Learning to Detour in Autonomous Robots**|Pablo de los Riscos et.al.|[2410.20894v1](http://arxiv.org/abs/2410.20894v1)|null|
|**2024-10-28**|**AutoRAG: Automated Framework for optimization of Retrieval Augmented Generation Pipeline**|Dongkyu Kim et.al.|[2410.20878v1](http://arxiv.org/abs/2410.20878v1)|[link](https://github.com/marker-inc-korea/autorag_aragog_paper)|
|**2024-10-28**|**Explainability in AI Based Applications: A Framework for Comparing Different Techniques**|Arne Grobrugge et.al.|[2410.20873v1](http://arxiv.org/abs/2410.20873v1)|null|
|**2024-10-28**|**Reward Modeling with Weak Supervision for Language Models**|Ben Hauptvogel et.al.|[2410.20869v1](http://arxiv.org/abs/2410.20869v1)|null|
|**2024-10-28**|**Strada-LLM: Graph LLM for traffic prediction**|Seyed Mohamad Moghadas et.al.|[2410.20856v1](http://arxiv.org/abs/2410.20856v1)|null|
|**2024-10-28**|**Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms**|He Yu et.al.|[2410.20848v1](http://arxiv.org/abs/2410.20848v1)|null|
|**2024-10-28**|**Generative Simulations of The Solar Corona Evolution With Denoising Diffusion : Proof of Concept**|Grégoire Francisco et.al.|[2410.20843v1](http://arxiv.org/abs/2410.20843v1)|[link](https://github.com/gfrancisco20/video_diffusion)|
|**2024-10-28**|**A Simple Yet Effective Corpus Construction Framework for Indonesian Grammatical Error Correction**|Nankai Lin et.al.|[2410.20838v1](http://arxiv.org/abs/2410.20838v1)|[link](https://github.com/gklmip/gec-construction-framework)|
|**2024-10-28**|**LLMs are Biased Evaluators But Not Biased for Retrieval Augmented Generation**|Yen-Shan Chen et.al.|[2410.20833v1](http://arxiv.org/abs/2410.20833v1)|null|
|**2024-10-28**|**ADLM -- stega: A Universal Adaptive Token Selection Algorithm for Improving Steganographic Text Quality via Information Entropy**|Zezheng Qin et.al.|[2410.20825v1](http://arxiv.org/abs/2410.20825v1)|null|
|**2024-10-28**|**The Zeno's Paradox of `Low-Resource' Languages**|Hellina Hailu Nigatu et.al.|[2410.20817v1](http://arxiv.org/abs/2410.20817v1)|null|
|**2024-10-28**|**NewTerm: Benchmarking Real-Time New Terms for Large Language Models with Annual Updates**|Hexuan Deng et.al.|[2410.20814v1](http://arxiv.org/abs/2410.20814v1)|[link](https://github.com/hexuandeng/newterm)|
|**2024-10-28**|**Bridging the Gap between Expert and Language Models: Concept-guided Chess Commentary Generation and Evaluation**|Jaechang Kim et.al.|[2410.20811v1](http://arxiv.org/abs/2410.20811v1)|null|
|**2024-10-28**|**Rephrasing natural text data with different languages and quality levels for Large Language Model pre-training**|Michael Pieler et.al.|[2410.20796v1](http://arxiv.org/abs/2410.20796v1)|null|
|**2024-10-28**|**Deep Learning for Medical Text Processing: BERT Model Fine-Tuning and Comparative Study**|Jiacheng Hu et.al.|[2410.20792v1](http://arxiv.org/abs/2410.20792v1)|null|
|**2024-10-28**|**From Cool Demos to Production-Ready FMware: Core Challenges and a Technology Roadmap**|Gopi Krishnan Rajbahadur et.al.|[2410.20791v1](http://arxiv.org/abs/2410.20791v1)|null|
|**2024-10-28**|**SCULPT: Systematic Tuning of Long Prompts**|Shanu Kumar et.al.|[2410.20788v1](http://arxiv.org/abs/2410.20788v1)|null|
|**2024-10-28**|**Graph-based Uncertainty Metrics for Long-form Language Model Outputs**|Mingjian Jiang et.al.|[2410.20783v1](http://arxiv.org/abs/2410.20783v1)|[link](https://github.com/mingjianjiang-1/graph-based-uncertainty)|
|**2024-10-28**|**Decoding Reading Goals from Eye Movements**|Omer Shubi et.al.|[2410.20779v1](http://arxiv.org/abs/2410.20779v1)|null|
|**2024-10-28**|**KD-LoRA: A Hybrid Approach to Efficient Fine-Tuning with LoRA and Knowledge Distillation**|Rambod Azimi et.al.|[2410.20777v1](http://arxiv.org/abs/2410.20777v1)|[link](https://github.com/rambodazimi/kd-lora)|
|**2024-10-28**|**Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation**|Dongryeol Lee et.al.|[2410.20774v1](http://arxiv.org/abs/2410.20774v1)|null|
|**2024-10-28**|**Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting**|Bong Gyun Kang et.al.|[2410.20772v1](http://arxiv.org/abs/2410.20772v1)|[link](https://github.com/djlee1208/bsa_2024)|
|**2024-10-28**|**MrT5: Dynamic Token Merging for Efficient Byte-level Language Models**|Julie Kallini et.al.|[2410.20771v1](http://arxiv.org/abs/2410.20771v1)|[link](https://github.com/jkallini/mrt5)|
|**2024-10-28**|**A Static and Dynamic Attention Framework for Multi Turn Dialogue Generation**|Wei-Nan Zhang et.al.|[2410.20766v1](http://arxiv.org/abs/2410.20766v1)|null|
|**2024-10-28**|**Evaluating LLMs for Targeted Concept Simplification forDomain-Specific Texts**|Sumit Asthana et.al.|[2410.20763v1](http://arxiv.org/abs/2410.20763v1)|null|
|**2024-10-28**|**Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**|Prakhar Verma et.al.|[2410.20753v1](http://arxiv.org/abs/2410.20753v1)|null|
|**2024-10-28**|**Matryoshka: Learning to Drive Black-Box LLMs with LLMs**|Changhao Li et.al.|[2410.20749v1](http://arxiv.org/abs/2410.20749v1)|null|
|**2024-10-28**|**ElectionSim: Massive Population Election Simulation Powered by Large Language Model Driven Agents**|Xinnong Zhang et.al.|[2410.20746v1](http://arxiv.org/abs/2410.20746v1)|null|
|**2024-10-28**|**Shopping MMLU: A Massive Multi-Task Online Shopping Benchmark for Large Language Models**|Yilun Jin et.al.|[2410.20745v1](http://arxiv.org/abs/2410.20745v1)|[link](https://github.com/kl4805/shoppingmmlu)|
|**2024-10-28**|**Mitigating Unauthorized Speech Synthesis for Voice Protection**|Zhisheng Zhang et.al.|[2410.20742v1](http://arxiv.org/abs/2410.20742v1)|[link](https://github.com/wxzyd123/pivotal_objective_perturbation)|
|**2024-10-28**|**Gender Bias in LLM-generated Interview Responses**|Haein Kong et.al.|[2410.20739v1](http://arxiv.org/abs/2410.20739v1)|null|
|**2024-10-28**|**Murine AI excels at cats and cheese: Structural differences between human and mouse neurons and their implementation in generative AIs**|Rino Saiga et.al.|[2410.20735v1](http://arxiv.org/abs/2410.20735v1)|null|
|**2024-10-28**|**GPRec: Bi-level User Modeling for Deep Recommenders**|Yejing Wang et.al.|[2410.20730v1](http://arxiv.org/abs/2410.20730v1)|null|
|**2024-10-28**|**Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**|Mufei Li et.al.|[2410.20724v1](http://arxiv.org/abs/2410.20724v1)|null|

#### Abstracts
##### **Enhancing Action Recognition by Leveraging the Hierarchical Structure of Actions and Textual Context**
2410.21275v1 by Manuel Benavent-Lledo, David Mulero-Pérez, David Ortiz-Perez, Jose Garcia-Rodriguez, Antonis Argyros

The sequential execution of actions and their hierarchical structure
consisting of different levels of abstraction, provide features that remain
unexplored in the task of action recognition. In this study, we present a novel
approach to improve action recognition by exploiting the hierarchical
organization of actions and by incorporating contextualized textual
information, including location and prior actions to reflect the sequential
context. To achieve this goal, we introduce a novel transformer architecture
tailored for action recognition that utilizes both visual and textual features.
Visual features are obtained from RGB and optical flow data, while text
embeddings represent contextual information. Furthermore, we define a joint
loss function to simultaneously train the model for both coarse and
fine-grained action recognition, thereby exploiting the hierarchical nature of
actions. To demonstrate the effectiveness of our method, we extend the Toyota
Smarthome Untrimmed (TSU) dataset to introduce action hierarchies, introducing
the Hierarchical TSU dataset. We also conduct an ablation study to assess the
impact of different methods for integrating contextual and hierarchical data on
action recognition performance. Results show that the proposed approach
outperforms pre-trained SOTA methods when trained with the same
hyperparameters. Moreover, they also show a 17.12% improvement in top-1
accuracy over the equivalent fine-grained RGB version when using ground-truth
contextual information, and a 5.33% improvement when contextual information is
obtained from actual predictions.

摘要：動作的順序執行及其階層結構由不同層級的抽象組成，提供在動作辨識任務中仍未探索的功能。在這項研究中，我們提出了一種新的方法，透過利用動作的階層組織，並結合情境化文字資訊（包括位置和先前動作）來反映順序脈絡，以改善動作辨識。為了達成此目標，我們引進一個新的Transformer架構，專門用於動作辨識，它同時利用視覺和文字特徵。視覺特徵從 RGB 和光流資料取得，而文字嵌入則代表情境資訊。此外，我們定義了一個聯合損失函數，以同時訓練模型進行粗略和細緻的動作辨識，從而利用動作的階層性質。為了證明我們方法的有效性，我們擴充了 Toyota Smarthome Untrimmed (TSU) 資料集，以引入動作階層，並引入了階層式 TSU 資料集。我們還進行了一項消融研究，以評估整合情境和階層資料對動作辨識效能的不同方法的影響。結果顯示，所提出的方法在使用相同的超參數進行訓練時，優於預先訓練的 SOTA 方法。此外，在使用真實情境資訊時，它們在頂級 1 準確度上也比等效的細緻 RGB 版本提高了 17.12%，而在從實際預測中取得情境資訊時，則提高了 5.33%。

##### **Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics**
2410.21272v1 by Yaniv Nikankin, Anja Reusch, Aaron Mueller, Yonatan Belinkov

Do large language models (LLMs) solve reasoning tasks by learning robust
generalizable algorithms, or do they memorize training data? To investigate
this question, we use arithmetic reasoning as a representative task. Using
causal analysis, we identify a subset of the model (a circuit) that explains
most of the model's behavior for basic arithmetic logic and examine its
functionality. By zooming in on the level of individual circuit neurons, we
discover a sparse set of important neurons that implement simple heuristics.
Each heuristic identifies a numerical input pattern and outputs corresponding
answers. We hypothesize that the combination of these heuristic neurons is the
mechanism used to produce correct arithmetic answers. To test this, we
categorize each neuron into several heuristic types-such as neurons that
activate when an operand falls within a certain range-and find that the
unordered combination of these heuristic types is the mechanism that explains
most of the model's accuracy on arithmetic prompts. Finally, we demonstrate
that this mechanism appears as the main source of arithmetic accuracy early in
training. Overall, our experimental results across several LLMs show that LLMs
perform arithmetic using neither robust algorithms nor memorization; rather,
they rely on a "bag of heuristics".

摘要：大型語言模型 (LLM) 透過學習強健且可概化的演算法來解決推理任務，還是記住訓練資料？為了探討這個問題，我們使用算術推理作為一個代表性的任務。透過因果分析，我們找出模型的一個子集（一個電路），它解釋了模型大部分的行為，用於基本的算術邏輯，並檢查它的功能。透過縮放至個別電路神經元的層級，我們發現一組稀疏的重要神經元，它們實作了簡單的啟發法。每個啟發法會找出一個數值輸入模式，並輸出對應的答案。我們假設這些啟發法神經元的組合是產生正確算術答案的機制。為了測試這一點，我們將每個神經元分類成數個啟發法類型，例如在運算元落在某個範圍內時會啟動的神經元，並發現這些啟發法類型的無序組合是解釋模型在算術提示上大部分準確度的機制。最後，我們展示這個機制在訓練早期會出現為算術準確度的主要來源。整體而言，我們在多個 LLM 上的實驗結果顯示，LLM 執行算術時既不使用強健的演算法，也不使用記憶；相反地，它們依賴於「啟發法組合」。

##### **EoRA: Training-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation**
2410.21271v1 by Shih-Yang Liu, Huck Yang, Chein-Yi Wang, Nai Chit Fung, Hongxu Yin, Charbel Sakr, Saurav Muralidharan, Kwang-Ting Cheng, Jan Kautz, Yu-Chiang Frank Wang, Pavlo Molchanov, Min-Hung Chen

In this work, we re-formulate the model compression problem into the
customized compensation problem: Given a compressed model, we aim to introduce
residual low-rank paths to compensate for compression errors under customized
requirements from users (e.g., tasks, compression ratios), resulting in greater
flexibility in adjusting overall capacity without being constrained by specific
compression formats. However, naively applying SVD to derive residual paths
causes suboptimal utilization of the low-rank representation capacity. Instead,
we propose Training-free Eigenspace Low-Rank Approximation (EoRA), a method
that directly minimizes compression-induced errors without requiring
gradient-based training, achieving fast optimization in minutes using a small
amount of calibration data. EoRA projects compression errors into the
eigenspace of input activations, leveraging eigenvalues to effectively
prioritize the reconstruction of high-importance error components. Moreover,
EoRA can be seamlessly integrated with fine-tuning and quantization to further
improve effectiveness and efficiency. EoRA consistently outperforms previous
methods in compensating errors for compressed LLaMA2/3 models on various tasks,
such as language generation, commonsense reasoning, and math reasoning tasks
(e.g., 31.31%/12.88% and 9.69% improvements on ARC-Easy/ARC-Challenge and
MathQA when compensating LLaMA3-8B that is quantized to 4-bit and pruned to 2:4
sparsity). EoRA offers a scalable, training-free solution to compensate for
compression errors, making it a powerful tool to deploy LLMs in various
capacity and efficiency requirements.

摘要：<paragraph>在這項工作中，我們將模型壓縮問題重新表述為自訂補償問題：給定一個壓縮模型，我們旨在引入殘差低秩路徑，以補償來自使用者自訂需求（例如，任務、壓縮率）的壓縮錯誤，從而提高調整整體容量的靈活性，而不會受到特定壓縮格式的約束。然而，天真地應用 SVD 來推導殘差路徑會導致低秩表示容量的次優利用。相反，我們提出無需訓練的特徵空間低秩近似 (EoRA)，這是一種直接最小化壓縮引起的錯誤的方法，無需基於梯度的訓練，使用少量校準資料在幾分鐘內即可實現快速最佳化。EoRA 將壓縮錯誤投射到輸入激活的特徵空間中，利用特徵值有效地優先重建高重要性錯誤組成。此外，EoRA 可以與微調和量化無縫整合，進一步提高有效性和效率。EoRA 在補償壓縮的 LLaMA2/3 模型在各種任務上的錯誤方面始終優於先前的各種方法，例如語言生成、常識推理和數學推理任務（例如，在補償量化為 4 位元且修剪為 2:4 稀疏度的 LLaMA3-8B 時，ARC-Easy/ARC-Challenge 和 MathQA 分別提高了 31.31% / 12.88% 和 9.69%）。EoRA 提供了一個可擴充、無需訓練的解決方案來補償壓縮錯誤，使其成為在各種容量和效率需求中部署 LLM 的強大工具。</paragraph>

##### **LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior**
2410.21264v1 by Hanyu Wang, Saksham Suri, Yixuan Ren, Hao Chen, Abhinav Shrivastava

We present LARP, a novel video tokenizer designed to overcome limitations in
current video tokenization methods for autoregressive (AR) generative models.
Unlike traditional patchwise tokenizers that directly encode local visual
patches into discrete tokens, LARP introduces a holistic tokenization scheme
that gathers information from the visual content using a set of learned
holistic queries. This design allows LARP to capture more global and semantic
representations, rather than being limited to local patch-level information.
Furthermore, it offers flexibility by supporting an arbitrary number of
discrete tokens, enabling adaptive and efficient tokenization based on the
specific requirements of the task. To align the discrete token space with
downstream AR generation tasks, LARP integrates a lightweight AR transformer as
a training-time prior model that predicts the next token on its discrete latent
space. By incorporating the prior model during training, LARP learns a latent
space that is not only optimized for video reconstruction but is also
structured in a way that is more conducive to autoregressive generation.
Moreover, this process defines a sequential order for the discrete tokens,
progressively pushing them toward an optimal configuration during training,
ensuring smoother and more accurate AR generation at inference time.
Comprehensive experiments demonstrate LARP's strong performance, achieving
state-of-the-art FVD on the UCF101 class-conditional video generation
benchmark. LARP enhances the compatibility of AR models with videos and opens
up the potential to build unified high-fidelity multimodal large language
models (MLLMs).

摘要：<paragraph>我們提出 LARP，一種新穎的影片分詞器，旨在克服自回歸 (AR) 生成式模型中現有影片分詞方法的限制。
與直接將局部視覺區塊編碼成離散符號的傳統區塊分詞器不同，LARP 引入了一種整體分詞方案，使用一組學習到的整體查詢從視覺內容中收集資訊。這種設計讓 LARP 能夠擷取更全域和語義的表示，而不會侷限於局部區塊層級的資訊。
此外，它提供靈活性，支援任意數量的離散符號，根據任務的具體需求啟用適應性和高效的分詞。為了將離散符號空間與下游 AR 生成任務對齊，LARP 整合了一個輕量級 AR 轉換器作為訓練時間先驗模型，以預測其離散潛在空間上的下一個符號。透過在訓練期間納入先驗模型，LARP 學習了一個潛在空間，不僅針對影片重建進行了最佳化，而且結構上更有利於自回歸生成。
此外，此程序定義了離散符號的順序，在訓練期間逐步將它們推向最佳配置，確保在推論時間更順暢、更準確的 AR 生成。
全面的實驗證明了 LARP 的強大效能，在 UCF101 類條件影片生成基準上達到了最先進的 FVD。LARP 增強了 AR 模型與影片的相容性，並開啟了建構統一的高保真多模態大型語言模型 (MLLM) 的可能性。</paragraph>

##### **BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference**
2410.21262v1 by Changwoo Lee, Soo Min Kwon, Qing Qu, Hun-Seok Kim

Large-scale foundation models have demonstrated exceptional performance in
language and vision tasks. However, the numerous dense matrix-vector operations
involved in these large networks pose significant computational challenges
during inference. To address these challenges, we introduce the Block-Level
Adaptive STructured (BLAST) matrix, designed to learn and leverage efficient
structures prevalent in the weight matrices of linear layers within deep
learning models. Compared to existing structured matrices, the BLAST matrix
offers substantial flexibility, as it can represent various types of structures
that are either learned from data or computed from pre-existing weight
matrices. We demonstrate the efficiency of using the BLAST matrix for
compressing both language and vision tasks, showing that (i) for medium-sized
models such as ViT and GPT-2, training with BLAST weights boosts performance
while reducing complexity by 70\% and 40\%, respectively; and (ii) for large
foundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x
compression while exhibiting the lowest performance degradation among all
tested structured matrices. Our code is available at
\url{https://github.com/changwoolee/BLAST}.

摘要：大型基礎模型在語言和視覺任務中展現出非凡的效能。然而，這些大型網路中涉及的許多密集矩陣向量運算在推論期間會造成重大的運算挑戰。為了應對這些挑戰，我們引入了區塊級自適應結構化 (BLAST) 矩陣，旨在學習和利用深度學習模型中線性層權重矩陣中普遍存在的有效結構。與現有的結構化矩陣相比，BLAST 矩陣提供了相當大的靈活性，因為它可以表示從資料中學習或從現有權重矩陣中計算出的各種結構類型。我們展示了使用 BLAST 矩陣壓縮語言和視覺任務的效率，表明 (i) 對於中型模型，例如 ViT 和 GPT-2，使用 BLAST 權重進行訓練會提升效能，同時分別降低複雜度 70% 和 40%；以及 (ii) 對於大型基礎模型，例如 Llama-7B 和 DiT-XL，BLAST 矩陣可實現 2 倍壓縮，同時在所有測試的結構化矩陣中展現出最低的效能下降。我們的程式碼可在 \url{https://github.com/changwoolee/BLAST} 取得。

##### **AutoBench-V: Can Large Vision-Language Models Benchmark Themselves?**
2410.21259v2 by Han Bao, Yue Huang, Yanbo Wang, Jiayi Ye, Xiangqi Wang, Xiuying Chen, Mohamed Elhoseiny, Xiangliang Zhang

Large Vision-Language Models (LVLMs) have become essential for advancing the
integration of visual and linguistic information, facilitating a wide range of
complex applications and tasks. However, the evaluation of LVLMs presents
significant challenges as the evaluation benchmark always demands lots of human
cost for its construction, and remains static, lacking flexibility once
constructed. Even though automatic evaluation has been explored in textual
modality, the visual modality remains under-explored. As a result, in this
work, we address a question: "Can LVLMs serve as a path to automatic
benchmarking?". We introduce AutoBench-V, an automated framework for serving
evaluation on demand, i.e., benchmarking LVLMs based on specific aspects of
model capability. Upon receiving an evaluation capability, AutoBench-V
leverages text-to-image models to generate relevant image samples and then
utilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completing
the evaluation process efficiently and flexibly. Through an extensive
evaluation of seven popular LVLMs across five demanded user inputs (i.e.,
evaluation capabilities), the framework shows effectiveness and reliability. We
observe the following: (1) Our constructed benchmark accurately reflects
varying task difficulties; (2) As task difficulty rises, the performance gap
between models widens; (3) While models exhibit strong performance in abstract
level understanding, they underperform in details reasoning tasks; and (4)
Constructing a dataset with varying levels of difficulties is critical for a
comprehensive and exhaustive evaluation. Overall, AutoBench-V not only
successfully utilizes LVLMs for automated benchmarking but also reveals that
LVLMs as judges have significant potential in various domains.

摘要：大型視覺語言模型 (LVLMs) 已成為推進視覺和語言資訊整合的必要工具，促進各種複雜的應用程式和任務。然而，LVLMs 的評估提出重大挑戰，因為評估基準總是需要大量人力成本來建構，一旦建構完成，就會變得靜態，缺乏彈性。儘管自動評估已在文字形式中進行探討，但視覺形式仍有待進一步探討。因此，在本文中，我們探討一個問題：「LVLMs 能否作為自動基準測試的途徑？」我們介紹 AutoBench-V，一個自動化架構，用於依需求提供評估服務，也就是根據模型功能的特定面向對 LVLMs 進行基準測試。在收到評估功能後，AutoBench-V 利用文字轉影像模型產生相關的影像範例，然後利用 LVLMs 編排視覺問答 (VQA) 任務，有效且靈活地完成評估流程。透過對七種流行的 LVLMs 進行廣泛評估，涵蓋五種使用者輸入需求（也就是評估功能），該架構展現出其有效性和可靠性。我們觀察到以下事項：(1) 我們建構的基準測試準確地反映出不同的任務難度；(2) 隨著任務難度增加，不同模型之間的效能差距也隨之擴大；(3) 儘管模型在抽象層級的理解上表現出強勁的效能，但在細節推理任務上卻表現不佳；(4) 建構一個具有不同難度層級的資料集，對於全面且詳盡的評估至關重要。整體而言，AutoBench-V 不僅成功地利用 LVLMs 進行自動基準測試，也揭示了 LVLMs 作為評審在各個領域具有顯著的潛力。

##### **Multi-modal AI for comprehensive breast cancer prognostication**
2410.21256v1 by Jan Witowski, Ken Zeng, Joseph Cappadona, Jailan Elayoubi, Elena Diana Chiru, Nancy Chan, Young-Joon Kang, Frederick Howard, Irina Ostrovnaya, Carlos Fernandez-Granda, Freya Schnabel, Ugur Ozerdem, Kangning Liu, Zoe Steinsnyder, Nitya Thakore, Mohammad Sadic, Frank Yeung, Elisa Liu, Theodore Hill, Benjamin Swett, Danielle Rigau, Andrew Clayburn, Valerie Speirs, Marcus Vetter, Lina Sojak, Simone Muenst Soysal, Daniel Baumhoer, Khalil Choucair, Yu Zong, Lina Daoud, Anas Saad, Waleed Abdulsattar, Rafic Beydoun, Jia-Wern Pan, Haslina Makmur, Soo-Hwang Teo, Linda Ma Pak, Victor Angel, Dovile Zilenaite-Petrulaitiene, Arvydas Laurinavicius, Natalie Klar, Brian D. Piening, Carlo Bifulco, Sun-Young Jun, Jae Pak Yi, Su Hyun Lim, Adam Brufsky, Francisco J. Esteva, Lajos Pusztai, Yann LeCun, Krzysztof J. Geras

Treatment selection in breast cancer is guided by molecular subtypes and
clinical characteristics. Recurrence risk assessment plays a crucial role in
personalizing treatment. Current methods, including genomic assays, have
limited accuracy and clinical utility, leading to suboptimal decisions for many
patients. We developed a test for breast cancer patient stratification based on
digital pathology and clinical characteristics using novel AI methods.
Specifically, we utilized a vision transformer-based pan-cancer foundation
model trained with self-supervised learning to extract features from digitized
H&E-stained slides. These features were integrated with clinical data to form a
multi-modal AI test predicting cancer recurrence and death. The test was
developed and evaluated using data from a total of 8,161 breast cancer patients
across 15 cohorts originating from seven countries. Of these, 3,502 patients
from five cohorts were used exclusively for evaluation, while the remaining
patients were used for training. Our test accurately predicted our primary
endpoint, disease-free interval, in the five external cohorts (C-index: 0.71
[0.68-0.75], HR: 3.63 [3.02-4.37, p<0.01]). In a direct comparison (N=858), the
AI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay,
with a C-index of 0.67 [0.61-0.74] versus 0.61 [0.49-0.73], respectively.
Additionally, the AI test added independent information to Oncotype DX in a
multivariate analysis (HR: 3.11 [1.91-5.09, p<0.01)]). The test demonstrated
robust accuracy across all major breast cancer subtypes, including TNBC
(C-index: 0.71 [0.62-0.81], HR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic
tools are currently recommended by clinical guidelines. These results suggest
that our AI test can improve accuracy, extend applicability to a wider range of
patients, and enhance access to treatment selection tools.

摘要：<paragraph>乳癌的治療選擇是由分子亞型和臨床特徵所引導。復發風險評估在個人化治療中扮演至關重要的角色。目前的技術，包括基因體分析，具有有限的準確度和臨床效用，導致許多患者的治療決策次於最佳。我們開發了一種基於數位病理學和臨床特徵的乳癌患者分層檢測，採用新穎的人工智慧方法。具體來說，我們利用了一個基於視覺轉換器的泛癌基礎模型，並透過自我監督學習進行訓練，以從數位化的 H&E 染色玻片中提取特徵。這些特徵與臨床資料整合，形成一個多模式的人工智慧檢測，用於預測癌症復發和死亡。該檢測的開發和評估使用了來自七個國家/地區的 15 個群組共 8,161 名乳癌患者的資料。其中，來自五個群組的 3,502 名患者專門用於評估，而其餘患者則用於訓練。我們的檢測準確地預測了我們的主要終點，即五個外部群組的無疾病間期（C 指數：0.71 [0.68-0.75]，HR：3.63 [3.02-4.37，p<0.01]）。在直接比較（N=858）中，人工智慧檢測比安科泰Dx，標準照護的 21 基因檢測更準確，C 指數分別為 0.67 [0.61-0.74] 和 0.61 [0.49-0.73]。此外，人工智慧檢測在多變量分析中增加了安科泰 Dx 的獨立資訊（HR：3.11 [1.91-5.09，p<0.01]）。該檢測在所有主要的乳癌亞型中都表現出強大的準確度，包括 TNBC（C 指數：0.71 [0.62-0.81]，HR：3.81 [2.35-6.17，p=0.02]），臨床指南目前不建議使用任何診斷工具。這些結果表明，我們的人工智慧檢測可以提高準確度，將適用範圍擴展到更多患者，並增加獲得治療選擇工具的機會。</paragraph>

##### **Are BabyLMs Second Language Learners?**
2410.21254v1 by Lukas Edman, Lisa Bylinina, Faeze Ghorbanpour, Alexander Fraser

This paper describes a linguistically-motivated approach to the 2024 edition
of the BabyLM Challenge (Warstadt et al. 2023). Rather than pursuing a first
language learning (L1) paradigm, we approach the challenge from a second
language (L2) learning perspective. In L2 learning, there is a stronger focus
on learning explicit linguistic information, such as grammatical notions,
definitions of words or different ways of expressing a meaning. This makes L2
learning potentially more efficient and concise. We approximate this using data
from Wiktionary, grammar examples either generated by an LLM or sourced from
grammar books, and paraphrase data. We find that explicit information about
word meaning (in our case, Wiktionary) does not boost model performance, while
grammatical information can give a small improvement. The most impactful data
ingredient is sentence paraphrases, with our two best models being trained on
1) a mix of paraphrase data and data from the BabyLM pretraining dataset, and
2) exclusively paraphrase data.

摘要：這篇論文描述了針對 2024 年版 BabyLM 挑戰 (Warstadt 等人，2023 年) 的語言學動機方法。我們不是遵循第一語言學習 (L1) 的典範，而是從第二語言 (L2) 學習的角度來應對挑戰。在 L2 學習中，更注重學習明確的語言資訊，例如語法概念、字詞定義或表達意義的不同方式。這使得 L2 學習潛在地更有效率且簡潔。我們使用來自維基詞典的資料、由 LLM 產生或來自語法書籍的語法範例以及同義改寫資料來近似這一點。我們發現關於字詞意義的明確資訊（在我們的案例中，是維基詞典）並不會提升模型效能，而語法資訊則可以帶來些微的進步。影響最大的資料成分是句子同義改寫，我們最好的兩個模型是在 1) 同義改寫資料和 BabyLM 預訓練資料集資料的混合資料，以及 2) 僅同義改寫資料上進行訓練。

##### **LongReward: Improving Long-context Large Language Models with AI Feedback**
2410.21252v1 by Jiajie Zhang, Zhongni Hou, Xin Lv, Shulin Cao, Zhenyu Hou, Yilin Niu, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li

Though significant advancements have been achieved in developing long-context
large language models (LLMs), the compromised quality of LLM-synthesized data
for supervised fine-tuning (SFT) often affects the long-context performance of
SFT models and leads to inherent limitations. In principle, reinforcement
learning (RL) with appropriate reward signals can further enhance models'
capacities. However, how to obtain reliable rewards in long-context scenarios
remains unexplored. To this end, we propose LongReward, a novel method that
utilizes an off-the-shelf LLM to provide rewards for long-context model
responses from four human-valued dimensions: helpfulness, logicality,
faithfulness, and completeness, each with a carefully designed assessment
pipeline. By combining LongReward and offline RL algorithm DPO, we are able to
effectively improve long-context SFT models. Our experiments indicate that
LongReward not only significantly improves models' long-context performance but
also enhances their ability to follow short instructions. We also find that
long-context DPO with LongReward and conventional short-context DPO can be used
together without hurting either one's performance.

摘要：儘管已經在開發長語境大型語言模型 (LLM) 方面取得重大進展，但 LLM 合成資料在監督微調 (SFT) 中的品質受損，通常會影響 SFT 模型的長語境效能，並導致固有的限制。原則上，採用適當獎勵信號的強化學習 (RL) 可以進一步增強模型的能力。然而，如何在長語境場景中獲得可靠的獎勵仍然未被探索。為此，我們提出 LongReward，這是一種新穎的方法，利用現成的 LLM 為長語境模型回應提供獎勵，涵蓋四個人類重視的向度：有幫助性、邏輯性、忠實度和完整性，每個向度都經過精心設計的評估管道。透過結合 LongReward 和離線 RL 演算法 DPO，我們能夠有效改善長語境 SFT 模型。我們的實驗表明，LongReward 不僅顯著改善模型的長語境效能，還能增強其遵循簡短說明的能力。我們還發現，採用 LongReward 的長語境 DPO 和傳統的短語境 DPO 可以同時使用，而不會損害任何一方的效能。

##### **Capacity-Aware Planning and Scheduling in Budget-Constrained Monotonic MDPs: A Meta-RL Approach**
2410.21249v1 by Manav Vora, Ilan Shomorony, Melkior Ornik

Many real-world sequential repair problems can be effectively modeled using
monotonic Markov Decision Processes (MDPs), where the system state
stochastically decreases and can only be increased by performing a restorative
action. This work addresses the problem of solving multi-component monotonic
MDPs with both budget and capacity constraints. The budget constraint limits
the total number of restorative actions and the capacity constraint limits the
number of restorative actions that can be performed simultaneously. While prior
methods dealt with budget constraints, including capacity constraints in prior
methods leads to an exponential increase in computational complexity as the
number of components in the MDP grows. We propose a two-step planning approach
to address this challenge. First, we partition the components of the
multi-component MDP into groups, where the number of groups is determined by
the capacity constraint. We achieve this partitioning by solving a Linear Sum
Assignment Problem (LSAP). Each group is then allocated a fraction of the total
budget proportional to its size. This partitioning effectively decouples the
large multi-component MDP into smaller subproblems, which are computationally
feasible because the capacity constraint is simplified and the budget
constraint can be addressed using existing methods. Subsequently, we use a
meta-trained PPO agent to obtain an approximately optimal policy for each
group. To validate our approach, we apply it to the problem of scheduling
repairs for a large group of industrial robots, constrained by a limited number
of repair technicians and a total repair budget. Our results demonstrate that
the proposed method outperforms baseline approaches in terms of maximizing the
average uptime of the robot swarm, particularly for large swarm sizes.

摘要：許多真實世界中的順序修復問題，可以用單調馬可夫決策過程 (MDP) 有效地建模，其中系統狀態會隨機遞減，且僅能透過執行修復動作來增加。本研究探討了解決多組成單調 MDP 的問題，其中包含預算和容量限制。預算限制限制了修復動作的總數，而容量限制限制了可同時執行的修復動作數。雖然先前的方法處理了預算限制，但將容量限制納入先前的方法會導致計算複雜度隨著 MDP 中組成數增加而呈指數增加。我們提出了一個兩步驟規劃方法來應對此挑戰。首先，我們將多組成 MDP 的組成劃分為群組，其中群組數由容量限制決定。我們透過解決線性總和分配問題 (LSAP) 來達成此劃分。然後為每個群組分配與其規模成正比的總預算的一部分。此劃分有效地將大型多組成 MDP 分解為較小的子問題，由於容量限制簡化且預算限制可以使用現有方法來解決，因此在計算上可行。隨後，我們使用元訓練的 PPO 代理來為每個群組取得近乎最佳的政策。為了驗證我們的做法，我們將其應用於為一大群工業機器人安排維修的問題，並受到維修技術人員數量有限和維修總預算的限制。我們的結果證明，所提出的方法在最大化機器人蜂群的平均運行時間方面優於基準方法，特別是對於大型蜂群規模。

##### **Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback**
2410.21242v1 by Nour Jedidi, Yung-Sung Chuang, Leslie Shing, James Glass

Building effective dense retrieval systems remains difficult when relevance
supervision is not available. Recent work has looked to overcome this challenge
by using a Large Language Model (LLM) to generate hypothetical documents that
can be used to find the closest real document. However, this approach relies
solely on the LLM to have domain-specific knowledge relevant to the query,
which may not be practical. Furthermore, generating hypothetical documents can
be inefficient as it requires the LLM to generate a large number of tokens for
each query. To address these challenges, we introduce Real Document Embeddings
from Relevance Feedback (ReDE-RF). Inspired by relevance feedback, ReDE-RF
proposes to re-frame hypothetical document generation as a relevance estimation
task, using an LLM to select which documents should be used for nearest
neighbor search. Through this re-framing, the LLM no longer needs
domain-specific knowledge but only needs to judge what is relevant.
Additionally, relevance estimation only requires the LLM to output a single
token, thereby improving search latency. Our experiments show that ReDE-RF
consistently surpasses state-of-the-art zero-shot dense retrieval methods
across a wide range of low-resource retrieval datasets while also making
significant improvements in latency per-query.

摘要：建立有效的密集检索系统在没有相关性监督的情况下仍然很困难。最近的工作试图通过使用大型语言模型 (LLM) 来生成假设文档来克服这一挑战，该文档可用于查找最接近的真实文档。然而，这种方法完全依赖 LLM 具有与查询相关的特定领域知识，这可能不切实际。此外，生成假设文档可能是低效的，因为它要求 LLM 为每个查询生成大量标记。为了应对这些挑战，我们引入了相关性反馈的真实文档嵌入 (ReDE-RF)。受相关性反馈的启发，ReDE-RF 提议将假设文档生成重新构建为相关性估计任务，使用 LLM 来选择哪些文档应用于最近邻搜索。通过这种重新构建，LLM 不再需要特定领域的知识，而只需要判断什么是相关的。此外，相关性估计只需要 LLM 输出一个标记，从而改善搜索延迟。我们的实验表明，ReDE-RF 在广泛的低资源检索数据集上始终超越最先进的零次镜头密集检索方法，同时还显着提高了每次查询的延迟。

##### **Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**
2410.21237v1 by Zhantao Yang, Han Zhang, Fangyi Chen, Anudeepsekhar Bolimera, Marios Savvides

Knowledge Graph (KG) is playing an increasingly important role in various AI
systems. For e-commerce, an efficient and low-cost automated knowledge graph
construction method is the foundation of enabling various successful downstream
applications. In this paper, we propose a novel method for constructing
structured product knowledge graphs from raw product images. The method
cooperatively leverages recent advances in the vision-language model (VLM) and
large language model (LLM), fully automating the process and allowing timely
graph updates. We also present a human-annotated e-commerce product dataset for
benchmarking product property extraction in knowledge graph construction. Our
method outperforms our baseline in all metrics and evaluated properties,
demonstrating its effectiveness and bright usage potential.

摘要：知識圖譜 (KG) 在各種 AI 系統中扮演越來越重要的角色。對於電子商務來說，一種有效且低成本的自動化知識圖譜建構方法是促成各種成功的下游應用程式的基礎。在本文中，我們提出了一種從原始產品影像建構結構化產品知識圖譜的新穎方法。該方法協同利用了視覺語言模型 (VLM) 和大型語言模型 (LLM) 的最新進展，完全自動化了流程並允許及時更新圖譜。我們還提供了一個由人工標註的電子商務產品資料集，用於評量知識圖譜建構中的產品屬性萃取。我們的模型在所有指標和評估屬性上都優於我們的基準，證明了其有效性和廣闊的使用潛力。

##### **Flaming-hot Initiation with Regular Execution Sampling for Large Language Models**
2410.21236v1 by Weizhe Chen, Zhicheng Zhang, Guanlin Liu, Renjie Zheng, Wenlei Shi, Chen Dun, Zheng Wu, Xing Jin, Lin Yan

Since the release of ChatGPT, large language models (LLMs) have demonstrated
remarkable capabilities across various domains. A key challenge in developing
these general capabilities is efficiently sourcing diverse, high-quality data.
This becomes especially critical in reasoning-related tasks with sandbox
checkers, such as math or code, where the goal is to generate correct solutions
to specific problems with higher probability. In this work, we introduce
Flaming-hot Initiation with Regular Execution (FIRE) sampling, a simple yet
highly effective method to efficiently find good responses. Our empirical
findings show that FIRE sampling enhances inference-time generation quality and
also benefits training in the alignment stage. Furthermore, we explore how FIRE
sampling improves performance by promoting diversity and analyze the impact of
employing FIRE at different positions within a response.

摘要：自 ChatGPT 發布以來，大型語言模型 (LLM) 已在各個領域展示出非凡的能力。開發這些通用能力的一項關鍵挑戰是有效獲取多樣化的高品質資料。這在具有沙盒檢查器的推理相關任務（例如數學或程式碼）中變得特別重要，目標是在特定問題上以更高的機率產生正確的解。在這項工作中，我們引入了火焰熱啟動搭配常規執行 (FIRE) 抽樣，這是一種簡單但極有效率的方法，可有效找出良好的回應。我們的經驗發現顯示，FIRE 抽樣增強了推理時間的產生品質，並在對齊階段中受益於訓練。此外，我們探討了 FIRE 抽樣如何透過促進多樣性來提升效能，並分析在回應中不同位置採用 FIRE 的影響。

##### **LoRA vs Full Fine-tuning: An Illusion of Equivalence**
2410.21228v1 by Reece Shuttleworth, Jacob Andreas, Antonio Torralba, Pratyusha Sharma

Fine-tuning is a crucial paradigm for adapting pre-trained large language
models to downstream tasks. Recently, methods like Low-Rank Adaptation (LoRA)
have been shown to match the performance of fully fine-tuned models on various
tasks with an extreme reduction in the number of trainable parameters. Even in
settings where both methods learn similarly accurate models, \emph{are their
learned solutions really equivalent?} We study how different fine-tuning
methods change pre-trained models by analyzing the model's weight matrices
through the lens of their spectral properties. We find that full fine-tuning
and LoRA yield weight matrices whose singular value decompositions exhibit very
different structure; moreover, the fine-tuned models themselves show distinct
generalization behaviors when tested outside the adaptation task's
distribution. More specifically, we first show that the weight matrices trained
with LoRA have new, high-ranking singular vectors, which we call \emph{intruder
dimensions}. Intruder dimensions do not appear during full fine-tuning. Second,
we show that LoRA models with intruder dimensions, despite achieving similar
performance to full fine-tuning on the target task, become worse models of the
pre-training distribution and adapt less robustly to multiple tasks
sequentially. Higher-rank, rank-stabilized LoRA models closely mirror full
fine-tuning, even when performing on par with lower-rank LoRA models on the
same tasks. These results suggest that models updated with LoRA and full
fine-tuning access different parts of parameter space, even when they perform
equally on the fine-tuned distribution. We conclude by examining why intruder
dimensions appear in LoRA fine-tuned models, why they are undesirable, and how
their effects can be minimized.

摘要：微调是将预先训练的大语言模型适应下游任务的关键范例。最近，已证明诸如低秩适应 (LoRA) 之类的方法能够在各种任务上匹配完全微调模型的性能，同时极大地减少了可训练参数的数量。即使在两种方法都学习到同样准确的模型的情况下，\emph{它们学习到的解决方案是否真的等效？} 我们通过光谱特性的视角分析模型的权重矩阵，研究了不同的微调方法如何改变预先训练的模型。我们发现，完全微调和 LoRA 产生的权重矩阵的奇异值分解呈现出非常不同的结构；此外，微调模型本身在适应任务的分布之外进行测试时表现出不同的泛化行为。更具体地说，我们首先表明使用 LoRA 训练的权重矩阵具有新的高秩奇异向量，我们称之为\emph{入侵维度}。在完全微调期间不会出现入侵维度。其次，我们表明，具有入侵维度的 LoRA 模型尽管在目标任务上实现了与完全微调相似的性能，但它们却成为预训练分布的更差模型，并且在多个任务上按顺序适应的鲁棒性较差。即使在与低秩 LoRA 模型在相同任务上表现相当时，高秩、秩稳定的 LoRA 模型也与完全微调非常相似。这些结果表明，即使在微调分布上表现相同，使用 LoRA 和完全微调更新的模型也会访问参数空间的不同部分。我们通过检查为什么入侵维度出现在 LoRA 微调模型中、为什么它们不受欢迎以及如何最小化它们的影响来结束本文。

##### **Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines**
2410.21220v1 by Zhixin Zhang, Yiyuan Zhang, Xiaohan Ding, Xiangyu Yue

Search engines enable the retrieval of unknown information with texts.
However, traditional methods fall short when it comes to understanding
unfamiliar visual content, such as identifying an object that the model has
never seen before. This challenge is particularly pronounced for large
vision-language models (VLMs): if the model has not been exposed to the object
depicted in an image, it struggles to generate reliable answers to the user's
question regarding that image. Moreover, as new objects and events continuously
emerge, frequently updating VLMs is impractical due to heavy computational
burdens. To address this limitation, we propose Vision Search Assistant, a
novel framework that facilitates collaboration between VLMs and web agents.
This approach leverages VLMs' visual understanding capabilities and web agents'
real-time information access to perform open-world Retrieval-Augmented
Generation via the web. By integrating visual and textual representations
through this collaboration, the model can provide informed responses even when
the image is novel to the system. Extensive experiments conducted on both
open-set and closed-set QA benchmarks demonstrate that the Vision Search
Assistant significantly outperforms the other models and can be widely applied
to existing VLMs.

摘要：搜尋引擎能用文字搜尋到未知的資訊。
然而，傳統的方法在理解陌生的視覺內容時，例如識別模型從未看過的物件時，就會有所不足。這個挑戰對於大型視覺語言模型 (VLM) 來說尤其明顯：如果模型沒有接觸過圖片中描繪的物件，它就會難以對使用者的問題產生可靠的答案。此外，由於新的物件和事件不斷出現，頻繁更新 VLM 因為沉重的運算負擔而不可行。為了解決這個限制，我們提出視覺搜尋助理，一個促進 VLM 和網路代理之間協作的新穎架構。這種方法利用 VLM 的視覺理解能力和網路代理的即時資訊存取，透過網路執行開放世界的檢索增強生成。藉由透過這種協作整合視覺和文字表徵，即使系統對圖片很陌生，模型也能提供有根據的回應。在開放式和封閉式問答基準上進行的廣泛實驗證明，視覺搜尋助理明顯優於其他模型，並且可以廣泛應用於現有的 VLM。

##### **HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation**
2410.21216v1 by Yuhan Chen, Ang Lv, Jian Luan, Bin Wang, Wei Liu

Many positional encodings (PEs) are designed to exhibit long-term decay,
based on an entrenched and long-standing inductive opinion: tokens farther away
from the current position carry less relevant information. We argue that
long-term decay is outdated in the era of LLMs, as LLMs are now applied to
tasks demanding precise retrieval of in-context information from arbitrary
positions. Firstly, we present empirical analyses on various PEs, demonstrating
that models inherently learn attention with only a local-decay pattern while
forming a U-shape pattern globally, contradicting the principle of long-term
decay. Furthermore, we conduct a detailed analysis of rotary position encoding
(RoPE, a prevalent relative positional encoding in LLMs), and found that the
U-shape attention is caused by some learned components, which are also the key
factor limiting RoPE's expressiveness and extrapolation.Inspired by these
insights, we propose High-frequency rotary Position Encoding (HoPE). HoPE
replaces the specific components in RoPE with position-independent ones,
retaining only high-frequency signals, which also breaks the principle of
long-term decay in theory. HoPE achieves two major advantages: (1) Without
constraints imposed by long-term decay, contradictory factors that limit
spontaneous attention optimization and model extrapolation performance are
removed. (2) Components representing positions and semantics are are optimized.
These enhances model's context awareness and extrapolation, as validated by
extensive experiments.

摘要：許多位置編碼（PE）被設計為表現出長期衰減，
基於根深蒂固且長期的歸納觀點：距離當前位置較遠的符號傳達較不相關的資訊。我們主張
長期衰減在 LLM 時代已經過時，因為 LLM 現在被應用於
從任意位置精確擷取上下文資訊的任務。首先，我們對各種 PE 提出實證分析，證明
模型在形成 U 形模式的同時，本質上只學習具有局部衰減模式的注意力，這與長期衰減的原則相矛盾。此外，我們對旋轉位置編碼（RoPE，LLM 中普遍的相對位置編碼）進行了詳細分析，發現 U 形注意力是由一些學習組成部分造成的，這些組成部分也是限制 RoPE 表現力和外推能力的關鍵因素。受到這些見解的啟發，我們提出了高頻旋轉位置編碼（HoPE）。HoPE 用與位置無關的組成部分取代 RoPE 中的特定組成部分，只保留高頻訊號，這在理論上也打破了長期衰減的原則。HoPE 獲得了兩個主要優點：（1）在不受長期衰減約束的情況下，限制自發注意力最佳化和模型外推效能的矛盾因素被消除了。（2）代表位置和語意的組成部分經過最佳化。這些增強了模型的上下文感知和外推能力，經由廣泛的實驗驗證。

##### **BongLLaMA: LLaMA for Bangla Language**
2410.21200v1 by Abdullah Khan Zehady, Safi Al Mamun, Naymul Islam, Santu Karmaker

Bangla (or "Bengali") is a language spoken by approximately 240 million
native speakers and around 300 million people worldwide. Despite being the 5th
largest spoken language in the world, Bangla is still a "low-resource"
language, and existing pretrained language models often struggle to perform
well on Bangla Language Processing (BLP) tasks. This work addresses this gap by
introducing BongLLaMA (i.e., Bangla-LLaMA), an open-source large language model
fine-tuned exclusively on large Bangla corpora and instruction-tuning datasets.
We present our methodology, data augmentation techniques, fine-tuning details,
and comprehensive benchmarking results showcasing the utility of BongLLaMA on
BLP tasks. We believe BongLLaMA will serve as the new standard baseline for
Bangla Language Models and, thus, facilitate future benchmarking studies
focused on this widely-spoken yet "low-resource" language. All BongLLaMA models
are available for public use at https://huggingface.co/BanglaLLM.

摘要：孟加拉語（或「孟加拉語」）是一種語言，由大約 2.4 億母語人士和全球約 3 億人使用。儘管孟加拉語是世界第五大語言，但它仍然是一種「低資源」語言，現有的預訓練語言模型通常難以執行孟加拉語處理 (BLP) 任務。這項工作透過引進 BongLLaMA（即孟加拉語-LLaMA）來解決這個差距，這是一個開放原始碼的大型語言模型，專門針對大型孟加拉語語料庫和指令調整資料集進行微調。我們提出我們的技術、資料擴充技術、微調細節和綜合基準測試結果，展示 BongLLaMA 在 BLP 任務中的效用。我們相信 BongLLaMA 將成為孟加拉語模型的新標準基準，從而促進未來的基準測試研究，重點關注這種廣泛使用但「低資源」的語言。所有 BongLLaMA 模型都可以在 https://huggingface.co/BanglaLLM 公開使用。

##### **Belief in the Machine: Investigating Epistemological Blind Spots of Language Models**
2410.21195v1 by Mirac Suzgun, Tayfun Gur, Federico Bianchi, Daniel E. Ho, Thomas Icard, Dan Jurafsky, James Zou

As language models (LMs) become integral to fields like healthcare, law, and
journalism, their ability to differentiate between fact, belief, and knowledge
is essential for reliable decision-making. Failure to grasp these distinctions
can lead to significant consequences in areas such as medical diagnosis, legal
judgments, and dissemination of fake news. Despite this, current literature has
largely focused on more complex issues such as theory of mind, overlooking more
fundamental epistemic challenges. This study systematically evaluates the
epistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and
Llama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13
tasks. Our results reveal key limitations. First, while LMs achieve 86%
accuracy on factual scenarios, their performance drops significantly with false
scenarios, particularly in belief-related tasks. Second, LMs struggle with
recognizing and affirming personal beliefs, especially when those beliefs
contradict factual data, which raises concerns for applications in healthcare
and counseling, where engaging with a person's beliefs is critical. Third, we
identify a salient bias in how LMs process first-person versus third-person
beliefs, performing better on third-person tasks (80.7%) compared to
first-person tasks (54.4%). Fourth, LMs lack a robust understanding of the
factive nature of knowledge, namely, that knowledge inherently requires truth.
Fifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the
deeper reasoning. These findings highlight significant concerns about current
LMs' ability to reason about truth, belief, and knowledge while emphasizing the
need for advancements in these areas before broad deployment in critical
sectors.

摘要：隨著語言模型 (LM) 成為醫療保健、法律和新聞等領域不可或缺的一部分，它們區分事實、信念和知識的能力對於可靠的決策至關重要。無法掌握這些區別可能會在醫療診斷、法律判決和假新聞傳播等領域造成重大後果。儘管如此，目前的文獻在很大程度上關注於更複雜的問題，例如心智理論，而忽視了更基本的認識論挑戰。本研究使用新的資料集 KaBLE，對現代 LM（包括 GPT-4、Claude-3 和 Llama-3）的認識論推理能力進行了系統評估，該資料集包含 13 個任務中的 13,000 個問題。我們的結果揭示了關鍵限制。首先，雖然 LM 在事實場景中達到 86% 的準確度，但它們在錯誤場景中的表現大幅下降，特別是在與信念相關的任務中。其次，LM 難以識別和肯定個人信念，特別是當這些信念與事實資料相矛盾時，這引起了對醫療保健和諮詢應用程式的擔憂，在這些應用程式中，與個人的信念互動至關重要。第三，我們發現 LM 處理第一人稱與第三人稱信念的方式存在顯著偏差，在第三人稱任務（80.7%）上的表現優於第一人稱任務（54.4%）。第四，LM 缺乏對知識的事實性質的穩健理解，即知識本質上需要真理。第五，LM 依賴語言線索進行事實查核，有時會繞過更深入的推理。這些發現突顯了當前 LM 推理真理、信念和知識的能力存在重大疑慮，同時強調在廣泛部署於關鍵部門之前，需要在這些領域取得進展。

##### **Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks**
2410.21175v1 by Jiawei Zhang, Jun Li, Reachsak Ly, Yunyi Liu, Jiangpeng Shu

For structural health monitoring, continuous and automatic crack detection
has been a challenging problem. This study is conducted to propose a framework
of automatic crack segmentation from high-resolution images containing crack
information about steel box girders of bridges. Considering the multi-scale
feature of cracks, convolutional neural network architecture of Feature Pyramid
Networks (FPN) for crack detection is proposed. As for input, 120 raw images
are processed via two approaches (shrinking the size of images and splitting
images into sub-images). Then, models with the proposed structure of FPN for
crack detection are developed. The result shows all developed models can
automatically detect the cracks at the raw images. By shrinking the images, the
computation efficiency is improved without decreasing accuracy. Because of the
separable characteristic of crack, models using the splitting method provide
more accurate crack segmentations than models using the resizing method.
Therefore, for high-resolution images, the FPN structure coupled with the
splitting method is an promising solution for the crack segmentation and
detection.

摘要：對於結構健康監測，連續且自動的裂縫偵測一直是一個具有挑戰性的問題。本研究旨在提出一個從包含橋樑鋼箱梁裂縫資訊的高解析度影像中自動分割裂縫的架構。考量到裂縫的多尺度特徵，提出用於裂縫偵測的 Feature Pyramid Networks (FPN) 捲積神經網路架構。至於輸入，120 張原始影像透過兩種方法處理（縮小影像尺寸和將影像分割成子影像）。然後，開發具有 FPN 提議結構的裂縫偵測模型。結果顯示所有已開發的模型都能自動偵測原始影像中的裂縫。藉由縮小影像，在不降低準確度的狀況下提升運算效率。由於裂縫具有可分離的特徵，使用分割方法的模型提供比使用縮放方法的模型更準確的裂縫分割。因此，對於高解析度影像，FPN 結構結合分割方法是裂縫分割和偵測的有前途的解決方案。

##### **Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction**
2410.21169v2 by Qintong Zhang, Victor Shea-Jay Huang, Bin Wang, Junyuan Zhang, Zhengren Wang, Hao Liang, Shawn Wang, Matthieu Lin, Conghui He, Wentao Zhang

Document parsing is essential for converting unstructured and semi-structured
documents-such as contracts, academic papers, and invoices-into structured,
machine-readable data. Document parsing extract reliable structured data from
unstructured inputs, providing huge convenience for numerous applications.
Especially with recent achievements in Large Language Models, document parsing
plays an indispensable role in both knowledge base construction and training
data generation. This survey presents a comprehensive review of the current
state of document parsing, covering key methodologies, from modular pipeline
systems to end-to-end models driven by large vision-language models. Core
components such as layout detection, content extraction (including text,
tables, and mathematical expressions), and multi-modal data integration are
examined in detail. Additionally, this paper discusses the challenges faced by
modular document parsing systems and vision-language models in handling complex
layouts, integrating multiple modules, and recognizing high-density text. It
emphasizes the importance of developing larger and more diverse datasets and
outlines future research directions.

摘要：文件解析對於將非結構化和半結構化文件（例如合約、學術論文和發票）轉換為結構化、機器可讀取的資料至關重要。文件解析從非結構化的輸入中提取可靠的結構化資料，為許多應用程式提供了極大的便利。特別是隨著大型語言模型的最新進展，文件解析在知識庫建構和訓練資料生成中扮演著不可或缺的角色。本調查對文件解析的現況進行全面的回顧，涵蓋關鍵方法，從模組化管線系統到由大型視覺語言模型驅動的端到端模型。詳細探討了核心組成部分，例如版面偵測、內容萃取（包括文字、表格和數學表達式）和多模態資料整合。此外，本文討論了模組化文件解析系統和視覺語言模型在處理複雜版面、整合多個模組和辨識高密度文字時所面臨的挑戰。它強調了開發更大、更多樣化的資料集的重要性，並概述了未來的研究方向。

##### **CURATe: Benchmarking Personalised Alignment of Conversational AI Assistants**
2410.21159v1 by Lize Alberts, Benjamin Ellis, Andrei Lupu, Jakob Foerster

We introduce a multi-turn benchmark for evaluating personalised alignment in
LLM-based AI assistants, focusing on their ability to handle user-provided
safety-critical contexts. Our assessment of ten leading models across five
scenarios (each with 337 use cases) reveals systematic inconsistencies in
maintaining user-specific consideration, with even top-rated "harmless" models
making recommendations that should be recognised as obviously harmful to the
user given the context provided. Key failure modes include inappropriate
weighing of conflicting preferences, sycophancy (prioritising user preferences
above safety), a lack of attentiveness to critical user information within the
context window, and inconsistent application of user-specific knowledge. The
same systematic biases were observed in OpenAI's o1, suggesting that strong
reasoning capacities do not necessarily transfer to this kind of personalised
thinking. We find that prompting LLMs to consider safety-critical context
significantly improves performance, unlike a generic 'harmless and helpful'
instruction. Based on these findings, we propose research directions for
embedding self-reflection capabilities, online user modelling, and dynamic risk
assessment in AI assistants. Our work emphasises the need for nuanced,
context-aware approaches to alignment in systems designed for persistent human
interaction, aiding the development of safe and considerate AI assistants.

摘要：<paragraph>我們引進一個多回合基準，用於評估基於 LLM 的 AI 助理中的個人化對齊，重點在於它們處理使用者提供的安全關鍵脈絡的能力。我們對五個情境中的十個領先模型的評估（每個情境有 337 個使用案例）揭示了在維持使用者特定考量方面的系統性不一致，即使是評分最高的「無害」模型也會提出建議，而這些建議應被視為明顯對使用者有害，具體取決於提供的脈絡。主要的失敗模式包括對相互衝突的偏好進行不適當的權衡、阿諛奉承（優先考慮使用者偏好而非安全性）、在脈絡視窗內缺乏對關鍵使用者資訊的關注，以及使用者特定知識的不一致應用。在 OpenAI 的 o1 中觀察到相同的系統性偏差，這表明強大的推理能力不一定會轉移到這種個性化思考中。我們發現，提示 LLM 考慮安全關鍵脈絡會顯著改善效能，這不同於一般的「無害且有幫助」的指示。根據這些發現，我們提出了研究方向，以將自我反省能力、線上使用者建模和動態風險評估嵌入到 AI 助理中。我們的研究強調了在為持續的人類互動設計的系統中，對齊需要細緻入微、具脈絡感知力的方法，有助於開發安全且體貼的 AI 助理。</paragraph>

##### **M2rc-Eval: Massively Multilingual Repository-level Code Completion Evaluation**
2410.21157v1 by Jiaheng Liu, Ken Deng, Congnan Liu, Jian Yang, Shukai Liu, He Zhu, Peng Zhao, Linzheng Chai, Yanan Wu, Ke Jin, Ge Zhang, Zekun Wang, Guoan Zhang, Bangyu Xiang, Wenbo Su, Bo Zheng

Repository-level code completion has drawn great attention in software
engineering, and several benchmark datasets have been introduced. However,
existing repository-level code completion benchmarks usually focus on a limited
number of languages (<5), which cannot evaluate the general code intelligence
abilities across different languages for existing code Large Language Models
(LLMs). Besides, the existing benchmarks usually report overall average scores
of different languages, where the fine-grained abilities in different
completion scenarios are ignored. Therefore, to facilitate the research of code
LLMs in multilingual scenarios, we propose a massively multilingual
repository-level code completion benchmark covering 18 programming languages
(called M2RC-EVAL), and two types of fine-grained annotations (i.e.,
bucket-level and semantic-level) on different completion scenarios are
provided, where we obtain these annotations based on the parsed abstract syntax
tree. Moreover, we also curate a massively multilingual instruction corpora
M2RC- INSTRUCT dataset to improve the repository-level code completion
abilities of existing code LLMs. Comprehensive experimental results demonstrate
the effectiveness of our M2RC-EVAL and M2RC-INSTRUCT.

摘要：儲存庫層級程式碼補完在軟體工程領域備受關注，且已推出多個基準資料集。然而，現有的儲存庫層級程式碼補完基準通常僅專注於有限的程式語言（<5），這無法評估現有大型語言模型（LLM）針對不同程式語言的一般程式碼智慧能力。此外，現有的基準通常會回報不同程式語言的整體平均分數，其中會忽略在不同補完情境中的細微能力。因此，為了促進多語言情境中程式碼 LLM 的研究，我們提出了一個涵蓋 18 種程式語言的大型多語言儲存庫層級程式碼補完基準（稱為 M2RC-EVAL），並在不同的補完情境中提供了兩種細微註解類型（即儲存區層級和語義層級），我們根據已剖析的抽象語法樹取得這些註解。此外，我們也整理了一個大型多語言指令語料庫 M2RC-INSTRUCT 資料集，以提升現有程式碼 LLM 的儲存庫層級程式碼補完能力。全面的實驗結果證明了我們 M2RC-EVAL 和 M2RC-INSTRUCT 的有效性。

##### **SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents**
2410.21155v1 by Qi Zhang, Zhijia Chen, Huitong Pan, Cornelia Caragea, Longin Jan Latecki, Eduard Dragut

Scientific information extraction (SciIE) is critical for converting
unstructured knowledge from scholarly articles into structured data (entities
and relations). Several datasets have been proposed for training and validating
SciIE models. However, due to the high complexity and cost of annotating
scientific texts, those datasets restrict their annotations to specific parts
of paper, such as abstracts, resulting in the loss of diverse entity mentions
and relations in context. In this paper, we release a new entity and relation
extraction dataset for entities related to datasets, methods, and tasks in
scientific articles. Our dataset contains 106 manually annotated full-text
scientific publications with over 24k entities and 12k relations. To capture
the intricate use and interactions among entities in full texts, our dataset
contains a fine-grained tag set for relations. Additionally, we provide an
out-of-distribution test set to offer a more realistic evaluation. We conduct
comprehensive experiments, including state-of-the-art supervised models and our
proposed LLM-based baselines, and highlight the challenges presented by our
dataset, encouraging the development of innovative models to further the field
of SciIE.

摘要：科學資訊萃取 (SciIE) 對於將學術文章中非結構化的知識轉換成結構化資料（實體和關係）至關重要。已經提出多個資料集，用於訓練和驗證 SciIE 模型。然而，由於標註科學文本的複雜性和成本很高，這些資料集會將標註限制在論文的特定部分，例如摘要，導致在上下文中遺失多樣化的實體提及和關係。在本文中，我們釋出一個新的實體和關係萃取資料集，用於科學文章中與資料集、方法和任務相關的實體。我們的資料集包含 106 篇手動標註的全文科學出版品，其中包含超過 24k 個實體和 12k 個關係。為了捕捉全文中實體之間的複雜使用和互動，我們的資料集包含一組細緻標籤的關係。此外，我們提供一個分布外測試集，以提供更實際的評估。我們進行全面的實驗，包括最先進的監督式模型和我們提出的基於 LLM 的基準，並強調我們的資料集所呈現的挑戰，鼓勵開發創新的模型以進一步推動 SciIE 領域。

##### **Trajectory Flow Matching with Applications to Clinical Time Series Modeling**
2410.21154v1 by Xi Zhang, Yuan Pu, Yuki Kawamura, Andrew Loza, Yoshua Bengio, Dennis L. Shung, Alexander Tong

Modeling stochastic and irregularly sampled time series is a challenging
problem found in a wide range of applications, especially in medicine. Neural
stochastic differential equations (Neural SDEs) are an attractive modeling
technique for this problem, which parameterize the drift and diffusion terms of
an SDE with neural networks. However, current algorithms for training Neural
SDEs require backpropagation through the SDE dynamics, greatly limiting their
scalability and stability. To address this, we propose Trajectory Flow Matching
(TFM), which trains a Neural SDE in a simulation-free manner, bypassing
backpropagation through the dynamics. TFM leverages the flow matching technique
from generative modeling to model time series. In this work we first establish
necessary conditions for TFM to learn time series data. Next, we present a
reparameterization trick which improves training stability. Finally, we adapt
TFM to the clinical time series setting, demonstrating improved performance on
three clinical time series datasets both in terms of absolute performance and
uncertainty prediction.

摘要：隨機且不規則取樣的時序建模是一個具有挑戰性的問題，在廣泛的應用中發現，特別是在醫學中。神經隨機微分方程 (Neural SDE) 是這個問題一個有吸引力的建模技術，它用神經網路參數化 SDE 的漂移和擴散項。然而，目前訓練神經 SDE 的演算法需要透過 SDE 動態進行反向傳播，極大地限制了它們的可擴充性和穩定性。為了解決這個問題，我們提出軌跡流匹配 (TFM)，它以無模擬的方式訓練一個神經 SDE，繞過動態的反向傳播。TFM 利用生成式建模中的流匹配技術來建模時序。在這項工作中，我們首先建立 TFM 學習時序資料的必要條件。接下來，我們提出一個重新參數化的技巧，它改進了訓練穩定性。最後，我們將 TFM 適應到臨床時序設定，證明了在絕對效能和不確定性預測方面，在三個臨床時序資料集上都有效能的提升。

##### **Palisade -- Prompt Injection Detection Framework**
2410.21146v1 by Sahasra Kokkula, Somanathan R, Nandavardhan R, Aashishkumar, G Divya

The advent of Large Language Models LLMs marks a milestone in Artificial
Intelligence, altering how machines comprehend and generate human language.
However, LLMs are vulnerable to malicious prompt injection attacks, where
crafted inputs manipulate the models behavior in unintended ways, compromising
system integrity and causing incorrect outcomes. Conventional detection methods
rely on static, rule-based approaches, which often fail against sophisticated
threats like abnormal token sequences and alias substitutions, leading to
limited adaptability and higher rates of false positives and false
negatives.This paper proposes a novel NLP based approach for prompt injection
detection, emphasizing accuracy and optimization through a layered input
screening process. In this framework, prompts are filtered through three
distinct layers rule-based, ML classifier, and companion LLM before reaching
the target model, thereby minimizing the risk of malicious interaction.Tests
show the ML classifier achieves the highest accuracy among individual layers,
yet the multi-layer framework enhances overall detection accuracy by reducing
false negatives. Although this increases false positives, it minimizes the risk
of overlooking genuine injected prompts, thus prioritizing security.This
multi-layered detection approach highlights LLM vulnerabilities and provides a
comprehensive framework for future research, promoting secure interactions
between humans and AI systems.

摘要：大型語言模型 (LLM) 的出現標誌著人工智慧的里程碑，改變了機器理解和產生人類語言的方式。然而，LLM 容易受到惡意提示注入攻擊，其中精心製作的輸入以意外的方式操縱模型行為，危害系統完整性並導致不正確的結果。傳統的檢測方法依賴於基於規則的靜態方法，這些方法通常無法對抗異常令牌序列和別名替換等複雜威脅，從而導致適應性有限以及較高的誤報和漏報率。本文提出了一種基於自然語言處理的新型提示注入檢測方法，通過分層輸入篩選過程強調準確性和優化。在此框架中，提示通過三個不同的層（基於規則、機器學習分類器和配套 LLM）進行過濾，然後才到達目標模型，從而最大程度地降低惡意交互的風險。測試表明，機器學習分類器在各個層中實現了最高的準確性，但多層框架通過減少漏報來提高整體檢測準確性。儘管這會增加誤報，但它最大程度地降低了忽視真正注入提示的風險，從而優先考慮安全性。這種多層檢測方法突出了 LLM 的漏洞，並為未來的研究提供了一個全面的框架，促進了人類和 AI 系統之間的安全交互。

##### **uOttawa at LegalLens-2024: Transformer-based Classification Experiments**
2410.21139v1 by Nima Meghdadi, Diana Inkpen

This paper presents the methods used for LegalLens-2024 shared task, which
focused on detecting legal violations within unstructured textual data and
associating these violations with potentially affected individuals. The shared
task included two subtasks: A) Legal Named Entity Recognition (L-NER) and B)
Legal Natural Language Inference (L-NLI). For subtask A, we utilized the spaCy
library, while for subtask B, we employed a combined model incorporating
RoBERTa and CNN. Our results were 86.3% in the L-NER subtask and 88.25% in the
L-NLI subtask. Overall, our paper demonstrates the effectiveness of transformer
models in addressing complex tasks in the legal domain. The source code for our
implementation is publicly available at
https://github.com/NimaMeghdadi/uOttawa-at-LegalLens-2024-Transformer-based-Classification

摘要：這篇論文介紹了 LegalLens-2024 共享任務所使用的方法，該任務專注於偵測非結構化文字資料中的法律違規行為，並將這些違規行為與可能受影響的個人聯繫起來。共享任務包括兩個子任務：A) 法律命名實體識別 (L-NER) 和 B) 法律自然語言推理 (L-NLI)。對於子任務 A，我們使用 spaCy 函式庫，而對於子任務 B，我們採用結合 RoBERTa 和 CNN 的組合模型。我們的結果在 L-NER 子任務中為 86.3%，在 L-NLI 子任務中為 88.25%。總體而言，我們的論文證明了Transformer模型在解決法律領域中複雜任務的有效性。我們實作的原始程式碼公開於 https://github.com/NimaMeghdadi/uOttawa-at-LegalLens-2024-Transformer-based-Classification

##### **Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments**
2410.21131v1 by Marharyta Domnich, Julius Valja, Rasmus Moorits Veski, Giacomo Magnifico, Kadi Tulver, Eduard Barbu, Raul Vicente

As machine learning models evolve, maintaining transparency demands more
human-centric explainable AI techniques. Counterfactual explanations, with
roots in human reasoning, identify the minimal input changes needed to obtain a
given output and, hence, are crucial for supporting decision-making. Despite
their importance, the evaluation of these explanations often lacks grounding in
user studies and remains fragmented, with existing metrics not fully capturing
human perspectives. To address this challenge, we developed a diverse set of 30
counterfactual scenarios and collected ratings across 8 evaluation metrics from
206 respondents. Subsequently, we fine-tuned different Large Language Models
(LLMs) to predict average or individual human judgment across these metrics.
Our methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shot
evaluations and 85% (over a 3-classes prediction) with fine-tuning across all
metrics. The fine-tuned models predicting human ratings offer better
comparability and scalability in evaluating different counterfactual
explanation frameworks.

摘要：隨著機器學習模型的演進，維護透明度需要更多以人為中心的解釋性人工智慧技術。反事實解釋植根於人類推理，找出取得特定輸出所需的最小輸入變更，因此對於支援決策制定至關重要。儘管它們很重要，但這些解釋的評估通常缺乏使用者研究的基礎，而且仍然支離破碎，現有的指標無法完全捕捉人類觀點。為了應對這一挑戰，我們開發了一組多元化的 30 個反事實場景，並從 206 名受訪者收集了 8 項評估指標的評分。隨後，我們微調了不同的大型語言模型 (LLM)，以預測這些指標中的人類平均或個別判斷。我們的技術使 LLM 能夠在零次學習評估中實現高達 63% 的準確度，並在所有指標上進行微調後實現 85%（超過 3 類預測）。預測人類評分的微調模型在評估不同的反事實解釋框架時提供了更好的可比性和可擴充性。

##### **Fast Calibrated Explanations: Efficient and Uncertainty-Aware Explanations for Machine Learning Models**
2410.21129v1 by Tuwe Löfström, Fatima Rabia Yapicioglu, Alessandra Stramiglio, Helena Löfström, Fabio Vitali

This paper introduces Fast Calibrated Explanations, a method designed for
generating rapid, uncertainty-aware explanations for machine learning models.
By incorporating perturbation techniques from ConformaSight - a global
explanation framework - into the core elements of Calibrated Explanations (CE),
we achieve significant speedups. These core elements include local feature
importance with calibrated predictions, both of which retain uncertainty
quantification. While the new method sacrifices a small degree of detail, it
excels in computational efficiency, making it ideal for high-stakes, real-time
applications. Fast Calibrated Explanations are applicable to probabilistic
explanations in classification and thresholded regression tasks, where they
provide the likelihood of a target being above or below a user-defined
threshold. This approach maintains the versatility of CE for both
classification and probabilistic regression, making it suitable for a range of
predictive tasks where uncertainty quantification is crucial.

摘要：本文介紹快速校準說明，這是一種方法，旨在為機器學習模型生成快速、具有不確定性感知的說明。
透過將 ConformaSight（一種全球說明架構）中的擾動技術納入校準說明 (CE) 的核心元素，我們達到了顯著的加速。這些核心元素包括具有校準預測的局部特徵重要性，兩者都保留了不確定性量化。雖然新方法犧牲了一小部分細節，但它在計算效率方面表現出色，使其非常適合高風險、實時的應用。快速校準說明適用於分類和閾值迴歸任務中的機率說明，在這些任務中，它們提供了目標高於或低於使用者定義閾值的可能性。這種方法維持了 CE 在分類和機率迴歸方面的多功能性，使其適用於不確定性量化至關重要的各種預測任務。

##### **Retrieval-Enhanced Mutation Mastery: Augmenting Zero-Shot Prediction of Protein Language Model**
2410.21127v1 by Yang Tan, Ruilin Wang, Banghao Wu, Liang Hong, Bingxin Zhou

Enzyme engineering enables the modification of wild-type proteins to meet
industrial and research demands by enhancing catalytic activity, stability,
binding affinities, and other properties. The emergence of deep learning
methods for protein modeling has demonstrated superior results at lower costs
compared to traditional approaches such as directed evolution and rational
design. In mutation effect prediction, the key to pre-training deep learning
models lies in accurately interpreting the complex relationships among protein
sequence, structure, and function. This study introduces a retrieval-enhanced
protein language model for comprehensive analysis of native properties from
sequence and local structural interactions, as well as evolutionary properties
from retrieved homologous sequences. The state-of-the-art performance of the
proposed ProtREM is validated on over 2 million mutants across 217 assays from
an open benchmark (ProteinGym). We also conducted post-hoc analyses of the
model's ability to improve the stability and binding affinity of a VHH
antibody. Additionally, we designed 10 new mutants on a DNA polymerase and
conducted wet-lab experiments to evaluate their enhanced activity at higher
temperatures. Both in silico and experimental evaluations confirmed that our
method provides reliable predictions of mutation effects, offering an auxiliary
tool for biologists aiming to evolve existing enzymes. The implementation is
publicly available at https://github.com/tyang816/ProtREM.

摘要：酵素工程可藉由強化催化活性、穩定性、結合親合度及其他特性，來修改野生型蛋白質以滿足產業及研究需求。與傳統方法（例如定向演化與合理設計）相比，深度學習方法在蛋白質建模方面已展現出更佳的結果，且成本更低。在突變效應預測中，預先訓練深度學習模型的關鍵在於準確詮釋蛋白質序列、結構與功能之間的複雜關係。本研究引入一個檢索增強蛋白質語言模型，用於全面分析序列與局部結構交互作用的原生特性，以及檢索到的同源序列的演化特性。所提出的 ProtREM 驗證了在來自開放基準（ProteinGym）的 217 項測定中超過 200 萬個突變體的最新效能。我們也對模型改善 VHH 抗體穩定性與結合親合度的能力進行事後分析。此外，我們在 DNA 聚合酶上設計了 10 個新的突變體，並進行實驗室實驗以評估它們在較高溫度下的增強活性。電腦模擬和實驗評估都證實，我們的模型提供可靠的突變效應預測，為生物學家提供一個輔助工具，用以演化現有的酵素。實作公開於 https://github.com/tyang816/ProtREM。

##### **Current State-of-the-Art of Bias Detection and Mitigation in Machine Translation for African and European Languages: a Review**
2410.21126v1 by Catherine Ikae, Mascha Kurpicz-Briki

Studying bias detection and mitigation methods in natural language processing
and the particular case of machine translation is highly relevant, as societal
stereotypes might be reflected or reinforced by these systems. In this paper,
we analyze the state-of-the-art with a particular focus on European and African
languages. We show how the majority of the work in this field concentrates on
few languages, and that there is potential for future research to cover also
the less investigated languages to contribute to more diversity in the research
field.

摘要：研究自然語言處理中的偏差檢測和緩解方法，以及機器翻譯的特殊情況具有高度相關性，因為這些系統可能會反映或強化社會刻板印象。在本文中，我們分析了最先進的技術，特別關注歐洲和非洲語言。我們展示了該領域的大部分工作如何集中在少數語言上，並且未來研究有可能涵蓋研究較少的語言，以促進研究領域的多樣性。

##### **Zero-Shot Action Recognition in Surveillance Videos**
2410.21113v1 by Joao Pereira, Vasco Lopes, David Semedo, Joao Neves

The growing demand for surveillance in public spaces presents significant
challenges due to the shortage of human resources. Current AI-based video
surveillance systems heavily rely on core computer vision models that require
extensive finetuning, which is particularly difficult in surveillance settings
due to limited datasets and difficult setting (viewpoint, low quality, etc.).
In this work, we propose leveraging Large Vision-Language Models (LVLMs), known
for their strong zero and few-shot generalization, to tackle video
understanding tasks in surveillance. Specifically, we explore VideoLLaMA2, a
state-of-the-art LVLM, and an improved token-level sampling method,
Self-Reflective Sampling (Self-ReS). Our experiments on the UCF-Crime dataset
show that VideoLLaMA2 represents a significant leap in zero-shot performance,
with 20% boost over the baseline. Self-ReS additionally increases zero-shot
action recognition performance to 44.6%. These results highlight the potential
of LVLMs, paired with improved sampling techniques, for advancing surveillance
video analysis in diverse scenarios.

摘要：由於人力資源短缺，對公共場所監控需求的增加帶來了重大的挑戰。當前的基於人工智能的影片監控系統嚴重依賴於核心電腦視覺模型，這些模型需要廣泛的微調，而這在監控設置中特別困難，因為資料集有限且設置困難（視角、低品質等）。在這項工作中，我們建議利用大型視覺語言模型 (LVLMs)，它們以強大的零次和少次泛化而聞名，來處理監控中的影片理解任務。具體來說，我們探討了 VideoLLaMA2，一種最先進的 LVLM，以及一種改進的符號級別採樣方法，自反採樣 (Self-ReS)。我們在 UCF-Crime 資料集上的實驗表明，VideoLLaMA2 在零次表現上代表了一個重大的飛躍，比基準提升了 20%。Self-ReS 還將零次動作識別性能提高到 44.6%。這些結果突顯了 LVLMs 與改進的採樣技術相結合的潛力，用於推進各種場景中的監控影片分析。

##### **Large Language Model-assisted Speech and Pointing Benefits Multiple 3D Object Selection in Virtual Reality**
2410.21091v1 by Junlong Chen, Jens Grubert, Per Ola Kristensson

Selection of occluded objects is a challenging problem in virtual reality,
even more so if multiple objects are involved. With the advent of new
artificial intelligence technologies, we explore the possibility of leveraging
large language models to assist multi-object selection tasks in virtual reality
via a multimodal speech and raycast interaction technique. We validate the
findings in a comparative user study (n=24), where participants selected target
objects in a virtual reality scene with different levels of scene perplexity.
The performance metrics and user experience metrics are compared against a
mini-map based occluded object selection technique that serves as the baseline.
Results indicate that the introduced technique, AssistVR, outperforms the
baseline technique when there are multiple target objects. Contrary to the
common belief for speech interfaces, AssistVR was able to outperform the
baseline even when the target objects were difficult to reference verbally.
This work demonstrates the viability and interaction potential of an
intelligent multimodal interactive system powered by large laguage models.
Based on the results, we discuss the implications for design of future
intelligent multimodal interactive systems in immersive environments.

摘要：遮擋物體的選擇在虛擬實境中是一個具有挑戰性的問題，特別是在涉及多個物體時更是如此。隨著新的人工智慧技術的出現，我們探討了利用大型語言模型來協助虛擬實境中的多物件選擇任務，透過多模態語音和射線投射互動技術。我們在一個比較性使用者研究（n=24）中驗證了這些發現，其中參與者在具有不同場景困惑度的虛擬實境場景中選擇目標物體。效能指標和使用者體驗指標與作為基線的基於小地圖的遮擋物體選擇技術進行比較。結果表明，當有多個目標物體時，所提出的技術 AssistVR 優於基線技術。與語音介面的普遍認知相反，即使目標物體難以用言語表達，AssistVR 也能優於基線。這項工作展示了由大型語言模型驅動的智慧多模態互動系統的可行性和互動潛力。根據結果，我們討論了未來在沉浸式環境中設計智慧多模態互動系統的含意。

##### **Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving**
2410.21086v1 by Jiyao Wang, Xiao Yang, Zhenyu Wang, Ximeng Wei, Ange Wang, Dengbo He, Kaishun Wu

Road safety remains a critical challenge worldwide, with approximately 1.35
million fatalities annually attributed to traffic accidents, often due to human
errors. As we advance towards higher levels of vehicle automation, challenges
still exist, as driving with automation can cognitively over-demand drivers if
they engage in non-driving-related tasks (NDRTs), or lead to drowsiness if
driving was the sole task. This calls for the urgent need for an effective
Driver Monitoring System (DMS) that can evaluate cognitive load and drowsiness
in SAE Level-2/3 autonomous driving contexts. In this study, we propose a novel
multi-task DMS, termed VDMoE, which leverages RGB video input to monitor driver
states non-invasively. By utilizing key facial features to minimize
computational load and integrating remote Photoplethysmography (rPPG) for
physiological insights, our approach enhances detection accuracy while
maintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE)
framework to accommodate multi-modal inputs and improve performance across
different tasks. A novel prior-inclusive regularization method is introduced to
align model outputs with statistical priors, thus accelerating convergence and
mitigating overfitting risks. We validate our method with the creation of a new
dataset (MCDD), which comprises RGB video and physiological indicators from 42
participants, and two public datasets. Our findings demonstrate the
effectiveness of VDMoE in monitoring driver states, contributing to safer
autonomous driving systems. The code and data will be released.

摘要：道路安全仍然是全球面临的一项严峻挑战，每年约有 135 万人死于交通事故，通常是由于人为失误造成的。随着我们向更高水平的车辆自动化迈进，挑战仍然存在，因为如果驾驶员从事与驾驶无关的任务 (NDRT)，则使用自动化驾驶可能会在认知上对驾驶员提出过高要求，或者如果驾驶是唯一任务，则会导致驾驶员昏昏欲睡。这要求迫切需要一个有效的驾驶员监测系统 (DMS)，该系统可以在 SAE 2/3 级自动驾驶环境中评估认知负荷和嗜睡。在这项研究中，我们提出了一种新颖的多任务 DMS，称为 VDMoE，它利用 RGB 视频输入来非侵入性地监测驾驶员状态。通过利用关键面部特征来最大限度地减少计算负载，并整合远程光电容积描记术 (rPPG) 以获取生理见解，我们的方法提高了检测准确性，同时保持了效率。此外，我们优化了专家混合 (MoE) 框架以适应多模式输入并提高不同任务的性能。引入了一种新颖的先验包容正则化方法，以将模型输出与统计先验对齐，从而加速收敛并减轻过拟合风险。我们通过创建一个新数据集 (MCDD) 来验证我们的方法，该数据集包含来自 42 名参与者的 RGB 视频和生理指标，以及两个公共数据集。我们的研究结果证明了 VDMoE 在监测驾驶员状态方面的有效性，有助于实现更安全的自动驾驶系统。代码和数据将被释放。

##### **Stealthy Jailbreak Attacks on Large Language Models via Benign Data Mirroring**
2410.21083v1 by Honglin Mu, Han He, Yuxin Zhou, Yunlong Feng, Yang Xu, Libo Qin, Xiaoming Shi, Zeming Liu, Xudong Han, Qi Shi, Qingfu Zhu, Wanxiang Che

Large language model (LLM) safety is a critical issue, with numerous studies
employing red team testing to enhance model security. Among these, jailbreak
methods explore potential vulnerabilities by crafting malicious prompts that
induce model outputs contrary to safety alignments. Existing black-box
jailbreak methods often rely on model feedback, repeatedly submitting queries
with detectable malicious instructions during the attack search process.
Although these approaches are effective, the attacks may be intercepted by
content moderators during the search process. We propose an improved transfer
attack method that guides malicious prompt construction by locally training a
mirror model of the target black-box model through benign data distillation.
This method offers enhanced stealth, as it does not involve submitting
identifiable malicious instructions to the target model during the search
phase. Our approach achieved a maximum attack success rate of 92%, or a
balanced value of 80% with an average of 1.5 detectable jailbreak queries per
sample against GPT-3.5 Turbo on a subset of AdvBench. These results underscore
the need for more robust defense mechanisms.

摘要：大型語言模型 (LLM) 的安全性是一個關鍵問題，許多研究採用紅隊測試來增強模型安全性。其中，越獄方法透過製作惡意的提示來探索潛在的漏洞，這些提示會誘發與安全對齊相反的模型輸出。現有的黑盒越獄方法通常依賴於模型回饋，在攻擊搜尋過程中重複提交帶有可檢測惡意指令的查詢。儘管這些方法有效，但攻擊可能會在搜尋過程中被內容審查員攔截。我們提出了一種改進的轉移攻擊方法，通過透過良性資料萃取來在本地訓練目標黑盒模型的鏡像模型，來引導惡意提示的建構。這種方法提供了增強的隱蔽性，因為它不涉及在搜尋階段向目標模型提交可識別的惡意指令。我們的做法在 AdvBench 的一個子集中對 GPT-3.5 Turbo 攻擊成功率最高達到 92%，或平衡值為 80%，平均每個範例有 1.5 個可檢測的越獄查詢。這些結果強調了對更強大的防禦機制有必要性的需求。

##### **Skip2-LoRA: A Lightweight On-device DNN Fine-tuning Method for Low-cost Edge Devices**
2410.21073v1 by Hiroki Matsutani, Masaaki Kondo, Kazuki Sunaga, Radu Marculescu

This paper proposes Skip2-LoRA as a lightweight fine-tuning method for deep
neural networks to address the gap between pre-trained and deployed models. In
our approach, trainable LoRA (low-rank adaptation) adapters are inserted
between the last layer and every other layer to enhance the network expressive
power while keeping the backward computation cost low. This architecture is
well-suited to cache intermediate computation results of the forward pass and
then can skip the forward computation of seen samples as training epochs
progress. We implemented the combination of the proposed architecture and
cache, denoted as Skip2-LoRA, and tested it on a $15 single board computer. Our
results show that Skip2-LoRA reduces the fine-tuning time by 90.0% on average
compared to the counterpart that has the same number of trainable parameters
while preserving the accuracy, while taking only a few seconds on the
microcontroller board.

摘要：本論文提出 Skip2-LoRA 作為深度神經網路的輕量級微調方法，以解決預訓練模型和已部署模型之間的差距。在我們的做法中，可訓練的 LoRA（低秩適應）適配器會插入最後一層和每一層之間，以增強網路表達能力，同時保持反向運算成本低。此架構非常適合快取前向傳遞的中間運算結果，然後隨著訓練時期的進展，可以跳過已見樣本的前向運算。我們實作了所提出的架構和快取的組合，稱為 Skip2-LoRA，並在 15 美元的單板電腦上進行測試。我們的結果顯示，與具有相同數量可訓練參數的對應項相比，Skip2-LoRA 平均減少 90.0% 的微調時間，同時保持準確性，而僅在微控制器板上花費幾秒鐘。

##### **EMOCPD: Efficient Attention-based Models for Computational Protein Design Using Amino Acid Microenvironment**
2410.21069v2 by Xiaoqi Ling, Cheng Cai, Demin Kong, Zhisheng Wei, Jing Wu, Lei Wang, Zhaohong Deng

Computational protein design (CPD) refers to the use of computational methods
to design proteins. Traditional methods relying on energy functions and
heuristic algorithms for sequence design are inefficient and do not meet the
demands of the big data era in biomolecules, with their accuracy limited by the
energy functions and search algorithms. Existing deep learning methods are
constrained by the learning capabilities of the networks, failing to extract
effective information from sparse protein structures, which limits the accuracy
of protein design. To address these shortcomings, we developed an Efficient
attention-based Models for Computational Protein Design using amino acid
microenvironment (EMOCPD). It aims to predict the category of each amino acid
in a protein by analyzing the three-dimensional atomic environment surrounding
the amino acids, and optimize the protein based on the predicted
high-probability potential amino acid categories. EMOCPD employs a multi-head
attention mechanism to focus on important features in the sparse protein
microenvironment and utilizes an inverse residual structure to optimize the
network architecture. The proposed EMOCPD achieves over 80% accuracy on the
training set and 68.33% and 62.32% accuracy on two independent test sets,
respectively, surpassing the best comparative methods by over 10%. In protein
design, the thermal stability and protein expression of the predicted mutants
from EMOCPD show significant improvements compared to the wild type,
effectively validating EMOCPD's potential in designing superior proteins.
Furthermore, the predictions of EMOCPD are influenced positively, negatively,
or have minimal impact based on the content of the 20 amino acids, categorizing
amino acids as positive, negative, or neutral. Research findings indicate that
EMOCPD is more suitable for designing proteins with lower contents of negative
amino acids.

摘要：計算蛋白質設計（CPD）是指使用計算方法來設計蛋白質。傳統方法依賴於能量函數和啟發式演算法進行序列設計，效率低下，且不符合生物大數據時代的需求，其準確性受到能量函數和搜尋演算法的限制。現有的深度學習方法受到網路學習能力的限制，無法從稀疏蛋白質結構中提取有效資訊，這限制了蛋白質設計的準確性。為了解決這些缺點，我們開發了一種基於胺基酸微環境的有效注意模型，用於計算蛋白質設計（EMOCPD）。其目標是透過分析胺基酸周圍的三維原子環境來預測蛋白質中每個胺基酸的類別，並根據預測的高機率潛在胺基酸類別來最佳化蛋白質。EMOCPD 採用多頭注意力機制來關注稀疏蛋白質微環境中的重要特徵，並利用逆殘差結構來最佳化網路架構。所提出的 EMOCPD 在訓練組上達到了超過 80% 的準確度，在兩個獨立的測試組上分別達到了 68.33% 和 62.32% 的準確度，比最佳比較方法高出 10% 以上。在蛋白質設計中，與野生型相比，EMOCPD 預測的突變體的熱穩定性和蛋白質表現出顯著的改善，有效驗證了 EMOCPD 在設計優質蛋白質方面的潛力。此外，EMOCPD 的預測會根據 20 種胺基酸的含量受到正面、負面影響，或影響最小，將胺基酸分類為正面、負面或中性。研究結果表明，EMOCPD 更適合設計負胺基酸含量較低的蛋白質。

##### **CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**
2410.21067v1 by Meiqi Chen, Fandong Meng, Yingxue Zhang, Yan Zhang, Jie Zhou

Large language models (LLMs) have shown great promise in machine translation,
but they still struggle with contextually dependent terms, such as new or
domain-specific words. This leads to inconsistencies and errors that are
difficult to address. Existing solutions often depend on manual identification
of such terms, which is impractical given the complexity and evolving nature of
language. While Retrieval-Augmented Generation (RAG) could provide some
assistance, its application to translation is limited by issues such as
hallucinations from information overload. In this paper, we propose CRAT, a
novel multi-agent translation framework that leverages RAG and
causality-enhanced self-reflection to address these challenges. This framework
consists of several specialized agents: the Unknown Terms Identification agent
detects unknown terms within the context, the Knowledge Graph (KG) Constructor
agent extracts relevant internal knowledge about these terms and retrieves
bilingual information from external sources, the Causality-enhanced Judge agent
validates the accuracy of the information, and the Translator agent
incorporates the refined information into the final output. This automated
process allows for more precise and consistent handling of key terms during
translation. Our results show that CRAT significantly improves translation
accuracy, particularly in handling context-sensitive terms and emerging
vocabulary.

摘要：大型語言模型（LLM）在機器翻譯方面展現出極大的前景，
但它們仍然難以應對依賴於語境的詞彙，例如新詞或特定領域的詞彙。這會導致不一致和錯誤，而這些錯誤很難解決。現有的解決方案通常依賴於手動識別此類詞彙，但由於語言的複雜性和不斷演變的特性，這並不可行。雖然檢索增強生成（RAG）可以提供一些協助，但其在翻譯中的應用受到諸如資訊超載產生的幻覺等問題的限制。在本文中，我們提出 CRAT，這是一個新穎的多代理翻譯架構，它利用 RAG 和因果增強自省來應對這些挑戰。此架構包含幾個專門的代理：未知詞彙識別代理會偵測語境中的未知詞彙，知識圖譜（KG）建構代理會擷取這些詞彙相關的內部知識，並從外部來源中檢索雙語資訊，因果增強判斷代理會驗證資訊的準確性，而翻譯代理會將精煉過的資訊納入最終輸出。這個自動化的流程允許在翻譯過程中更精確且一致地處理關鍵詞彙。我們的結果顯示，CRAT 大幅提升了翻譯準確性，特別是在處理對語境敏感的詞彙和新興詞彙方面。

##### **Learning to Handle Complex Constraints for Vehicle Routing Problems**
2410.21066v1 by Jieyi Bi, Yining Ma, Jianan Zhou, Wen Song, Zhiguang Cao, Yaoxin Wu, Jie Zhang

Vehicle Routing Problems (VRPs) can model many real-world scenarios and often
involve complex constraints. While recent neural methods excel in constructing
solutions based on feasibility masking, they struggle with handling complex
constraints, especially when obtaining the masking itself is NP-hard. In this
paper, we propose a novel Proactive Infeasibility Prevention (PIP) framework to
advance the capabilities of neural methods towards more complex VRPs. Our PIP
integrates the Lagrangian multiplier as a basis to enhance constraint awareness
and introduces preventative infeasibility masking to proactively steer the
solution construction process. Moreover, we present PIP-D, which employs an
auxiliary decoder and two adaptive strategies to learn and predict these
tailored masks, potentially enhancing performance while significantly reducing
computational costs during training. To verify our PIP designs, we conduct
extensive experiments on the highly challenging Traveling Salesman Problem with
Time Window (TSPTW), and TSP with Draft Limit (TSPDL) variants under different
constraint hardness levels. Notably, our PIP is generic to boost many neural
methods, and exhibits both a significant reduction in infeasible rate and a
substantial improvement in solution quality.

摘要：車輛路線問題 (VRP) 可建模許多真實世界的場景，且通常涉及複雜的限制。雖然近期神經方法在建構基於可行性遮罩的解決方案方面表現出色，但它們在處理複雜限制時會遇到困難，特別是在取得遮罩本身為 NP 難題時。在本文中，我們提出一個新穎的預防不可行性 (PIP) 架構，以提升神經方法對更複雜 VRP 的能力。我們的 PIP 整合拉格朗日乘數作為基礎，以增強限制意識，並引入預防性不可行性遮罩，以主動引導解決方案建構流程。此外，我們提出 PIP-D，它採用輔助解碼器和兩個適應策略來學習和預測這些客製化遮罩，潛在可提升效能，同時大幅降低訓練期間的運算成本。為了驗證我們的 PIP 設計，我們在具有挑戰性的時窗旅行推銷員問題 (TSPTW) 和具有草案限制 (TSPDL) 變異的 TSP 上，在不同的限制難度等級下進行廣泛的實驗。值得注意的是，我們的 PIP 具有提升許多神經方法的通用性，且展現出不可行率顯著降低和解決方案品質大幅提升。

##### **Kandinsky 3: Text-to-Image Synthesis for Multifunctional Generative Framework**
2410.21061v1 by Vladimir Arkhipkin, Viacheslav Vasilev, Andrei Filatov, Igor Pavlov, Julia Agafonova, Nikolai Gerasimenko, Anna Averchenkova, Evelina Mironova, Anton Bukashkin, Konstantin Kulikov, Andrey Kuznetsov, Denis Dimitrov

Text-to-image (T2I) diffusion models are popular for introducing image
manipulation methods, such as editing, image fusion, inpainting, etc. At the
same time, image-to-video (I2V) and text-to-video (T2V) models are also built
on top of T2I models. We present Kandinsky 3, a novel T2I model based on latent
diffusion, achieving a high level of quality and photorealism. The key feature
of the new architecture is the simplicity and efficiency of its adaptation for
many types of generation tasks. We extend the base T2I model for various
applications and create a multifunctional generation system that includes
text-guided inpainting/outpainting, image fusion, text-image fusion, image
variations generation, I2V and T2V generation. We also present a distilled
version of the T2I model, evaluating inference in 4 steps of the reverse
process without reducing image quality and 3 times faster than the base model.
We deployed a user-friendly demo system in which all the features can be tested
in the public domain. Additionally, we released the source code and checkpoints
for the Kandinsky 3 and extended models. Human evaluations show that Kandinsky
3 demonstrates one of the highest quality scores among open source generation
systems.

摘要：文本到影像 (T2I) 擴散模型因引進影像處理方法而廣受歡迎，例如編輯、影像融合、修復等。同時，影像到影片 (I2V) 和文本到影片 (T2V) 模型也建立在 T2I 模型之上。我們提出 Kandinsky 3，一種基於潛在擴散的新型 T2I 模型，可實現高品質和寫實主義。新架構的主要特點是其適應各種生成任務的簡潔性和效率。我們擴展了基本 T2I 模型以適用於各種應用程式，並建立一個多功能生成系統，其中包括文字引導的修復/外繪、影像融合、文字影像融合、影像變化生成、I2V 和 T2V 生成。我們還提出了 T2I 模型的精簡版本，在反向處理的 4 個步驟中評估推論，且不會降低影像品質，而且比基本模型快 3 倍。我們部署了一個使用者友善的示範系統，其中所有功能都可以在公共領域中進行測試。此外，我們發布了 Kandinsky 3 和延伸模型的原始碼和檢查點。人為評估顯示，在開放原始碼生成系統中，Kandinsky 3 展示了最高品質分數之一。

##### **CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**
2410.21060v1 by Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao

Textual descriptions in cyber threat intelligence (CTI) reports, such as
security articles and news, are rich sources of knowledge about cyber threats,
crucial for organizations to stay informed about the rapidly evolving threat
landscape. However, current CTI extraction methods lack flexibility and
generalizability, often resulting in inaccurate and incomplete knowledge
extraction. Syntax parsing relies on fixed rules and dictionaries, while model
fine-tuning requires large annotated datasets, making both paradigms
challenging to adapt to new threats and ontologies. To bridge the gap, we
propose CTINexus, a novel framework leveraging optimized in-context learning
(ICL) of large language models (LLMs) for data-efficient CTI knowledge
extraction and high-quality cybersecurity knowledge graph (CSKG) construction.
Unlike existing methods, CTINexus requires neither extensive data nor parameter
tuning and can adapt to various ontologies with minimal annotated examples.
This is achieved through (1) a carefully designed automatic prompt construction
strategy with optimal demonstration retrieval for extracting a wide range of
cybersecurity entities and relations; (2) a hierarchical entity alignment
technique that canonicalizes the extracted knowledge and removes redundancy;
(3) an ICL-enhanced long-distance relation prediction technique to further
complete the CKSG with missing links. Our extensive evaluations using 150
real-world CTI reports collected from 10 platforms demonstrate that CTINexus
significantly outperforms existing methods in constructing accurate and
complete CSKGs, highlighting its potential to transform CTI analysis with an
efficient and adaptable solution for the dynamic threat landscape.

摘要：網路威脅情報 (CTI) 報告中的文字描述，例如安全文章和新聞，是網路威脅的豐富知識來源，對於組織而言至關重要，可以隨時了解快速演變的威脅環境。然而，目前的 CTI 提取方法缺乏靈活性且難以概括，通常會導致知識提取不準確且不完整。語法解析依賴於固定規則和字典，而模型微調需要大量標註的資料集，這使得這兩種範例都難以適應新的威脅和本体。為了彌補差距，我們提出了 CTINexus，這是一個新穎的框架，利用大型語言模型 (LLM) 的最佳化情境學習 (ICL) 來進行資料有效率的 CTI 知識提取和高品質的網路安全知識圖 (CSKG) 建構。與現有方法不同，CTINexus 不需要廣泛的資料或參數調整，並且可以透過最少的標註範例適應各種本体。這是透過 (1) 經過精心設計的自動提示建構策略，並透過最佳示範檢索來提取廣泛的網路安全實體和關係來實現的；(2) 一種階層式實體比對技術，可以將提取的知識標準化並消除冗餘；(3) 一種 ICL 增強的長距離關係預測技術，可以進一步完成具有遺失連結的 CKSG。我們使用從 10 個平台收集的 150 份真實世界 CTI 報告進行廣泛評估，證明 CTINexus 在建構準確且完整的 CSKG 方面明顯優於現有方法，突顯了其以有效且適應性強的解決方案轉換 CTI 分析的潛力，以應對動態的威脅環境。

##### **Semantic Component Analysis: Discovering Patterns in Short Texts Beyond Topics**
2410.21054v1 by Florian Eichin, Carolin Schuster, Georg Groh, Michael A. Hedderich

Topic modeling is a key method in text analysis, but existing approaches are
limited by assuming one topic per document or fail to scale efficiently for
large, noisy datasets of short texts. We introduce Semantic Component Analysis
(SCA), a novel topic modeling technique that overcomes these limitations by
discovering multiple, nuanced semantic components beyond a single topic in
short texts which we accomplish by introducing a decomposition step to the
clustering-based topic modeling framework. Evaluated on multiple Twitter
datasets, SCA matches the state-of-the-art method BERTopic in coherence and
diversity, while uncovering at least double the semantic components and
maintaining a noise rate close to zero while staying scalable and effective
across languages, including an underrepresented one.

摘要：主題建模是文本分析中的關鍵方法，但現有方法受限於假設每篇文件只有一個主題，或無法有效擴展到大量、雜訊的短文本資料集。我們引入了語義成分分析 (SCA)，這是一種新穎的主題建模技術，透過在短文本中發現單一主題之外的複雜語義成分，來克服這些限制，我們透過在基於群集的主題建模架構中引入分解步驟來達成此目的。在多個 Twitter 資料集上進行評估，SCA 在一致性和多樣性方面與最先進的方法 BERTopic 相匹配，同時發現至少是語義成分的兩倍，並將雜訊率維持在接近零的同時，在跨語言（包括代表性不足的語言）中保持可擴展性和有效性。

##### **Disentangled and Self-Explainable Node Representation Learning**
2410.21043v1 by Simone Piaggesi, André Panisson, Megha Khosla

Node representations, or embeddings, are low-dimensional vectors that capture
node properties, typically learned through unsupervised structural similarity
objectives or supervised tasks. While recent efforts have focused on explaining
graph model decisions, the interpretability of unsupervised node embeddings
remains underexplored. To bridge this gap, we introduce DiSeNE (Disentangled
and Self-Explainable Node Embedding), a framework that generates
self-explainable embeddings in an unsupervised manner. Our method employs
disentangled representation learning to produce dimension-wise interpretable
embeddings, where each dimension is aligned with distinct topological structure
of the graph. We formalize novel desiderata for disentangled and interpretable
embeddings, which drive our new objective functions, optimizing simultaneously
for both interpretability and disentanglement. Additionally, we propose several
new metrics to evaluate representation quality and human interpretability.
Extensive experiments across multiple benchmark datasets demonstrate the
effectiveness of our approach.

摘要：節點表示，或嵌入，是低維向量，用於擷取節點屬性，通常透過非監督結構相似性目標或監督任務學習。儘管最近的研究重點在於解釋圖形模型決策，但非監督節點嵌入的可解釋性仍未得到充分探討。為了解決這個問題，我們引入了 DiSeNE（解開糾纏且自解釋的節點嵌入），一個以非監督方式產生自解釋嵌入的框架。我們的做法採用解開糾纏表示學習，以產生維度可解釋的嵌入，其中每個維度與圖形的不同拓撲結構對齊。我們針對解開糾纏且可解釋的嵌入形式化新的理想，這驅動了我們的目標函數，同時針對可解釋性和解開糾纏進行最佳化。此外，我們提出了幾個新指標來評估表示品質和人類可解釋性。跨多個基準資料集的廣泛實驗證明了我們方法的有效性。

##### **Sorting Out the Bad Seeds: Automatic Classification of Cryptocurrency Abuse Reports**
2410.21041v1 by Gibran Gomez, Kevin van Liebergen, Davide Sanvito, Giuseppe Siracusano, Roberto Gonzalez, Juan Caballero

Abuse reporting services collect reports about abuse victims have suffered.
Accurate classification of the submitted reports is fundamental to analyzing
the prevalence and financial impact of different abuse types (e.g., sextortion,
investment, romance). Current classification approaches are problematic because
they require the reporter to select the abuse type from a list, assuming the
reporter has the necessary experience for the classification, which we show is
frequently not the case, or require manual classification by analysts, which
does not scale. To address these issues, this paper presents a novel approach
to classify cryptocurrency abuse reports automatically. We first build a
taxonomy of 19 frequently reported abuse types. Given as input the textual
description written by the reporter, our classifier leverages a large language
model (LLM) to interpret the text and assign it an abuse type in our taxonomy.
We collect 290K cryptocurrency abuse reports from two popular reporting
services: BitcoinAbuse and BBB's ScamTracker. We build ground truth datasets
for 20K of those reports and use them to evaluate three designs for our
LLM-based classifier and four LLMs, as well as a supervised ML classifier used
as a baseline. Our LLM-based classifier achieves a precision of 0.92, a recall
of 0.87, and an F1 score of 0.89, compared to an F1 score of 0.55 for the
baseline. We demonstrate our classifier in two applications: providing
financial loss statistics for fine-grained abuse types and generating tagged
addresses for cryptocurrency analysis platforms.

摘要：<paragraph>濫用報告服務收集濫用受害者遭受的報告。
提交報告的準確分類對於分析不同濫用類型的流行程度和財務影響至關重要（例如，性勒索、投資、愛情）。當前的分類方法存在問題，因為它們要求報告者從清單中選擇濫用類型，假設報告者具有分類所需的經驗，我們證明這種情況並不多見，或者需要分析師手動分類，這無法擴展。為了解決這些問題，本文提出了一種新穎的方法來自動分類加密貨幣濫用報告。我們首先建立了一個包含 19 種常見報告濫用類型的分類法。給定報告者撰寫的文本描述作為輸入，我們的分類器利用大型語言模型 (LLM) 來解釋文本並在我們的分類法中為其分配濫用類型。我們從兩個流行的報告服務中收集了 29 萬份加密貨幣濫用報告：BitcoinAbuse 和 BBB 的 ScamTracker。我們為其中 20,000 份報告建立了真實數據集，並使用它們來評估我們基於 LLM 的分類器的三種設計和四種 LLM，以及用作基線的監督式 ML 分類器。與基線的 F1 得分 0.55 相比，我們基於 LLM 的分類器實現了 0.92 的精確度、0.87 的召回率和 0.89 的 F1 得分。我們在兩個應用中展示了我們的分類器：為細粒度的濫用類型提供財務損失統計數據，並為加密貨幣分析平台生成標記地址。</paragraph>

##### **Beyond Autoregression: Fast LLMs via Self-Distillation Through Time**
2410.21035v1 by Justin Deschenaux, Caglar Gulcehre

Autoregressive (AR) Large Language Models (LLMs) have demonstrated
significant success across numerous tasks. However, the AR modeling paradigm
presents certain limitations; for instance, contemporary autoregressive LLMs
are trained to generate one token at a time, which can result in noticeable
latency. Recent advances have indicated that search and repeated sampling can
enhance performance in various applications, such as theorem proving, code
generation, and alignment, by utilizing greater computational resources during
inference. In this study, we demonstrate that diffusion language models are
capable of generating at least 32 tokens simultaneously, while exceeding the
performance of AR models in text quality and on the LAMBADA natural language
understanding benchmark. This outcome is achieved through a novel distillation
method for discrete diffusion models, which reduces the number of inference
steps by a factor of 32-64. Practically, our models, even without caching, can
generate tokens at a rate that is up to 8 times faster than AR models employing
KV caching, and we anticipate further improvements with the inclusion of
caching. Moreover, we demonstrate the efficacy of our approach for diffusion
language models with up to 860M parameters.

摘要：自回归 (AR) 大型语言模型 (LLM) 已证明在众多任务中取得了显著成功。然而，AR 建模范式存在一定的局限性；例如，当代自回归 LLM 被训练一次生成一个标记，这会导致明显的延迟。最近的进展表明，搜索和重复采样可以通过在推理过程中利用更大的计算资源来提高各种应用程序（例如定理证明、代码生成和对齐）中的性能。在这项研究中，我们证明了扩散语言模型能够同时生成至少 32 个标记，同时在文本质量和 LAMBADA 自然语言理解基准上超过了 AR 模型的性能。这一成果是通过一种新颖的离散扩散模型蒸馏方法实现的，该方法将推理步骤的数量减少了 32-64 倍。实际上，即使不使用缓存，我们的模型也可以以比采用 KV 缓存的 AR 模型快 8 倍的速度生成标记，并且我们预计随着缓存的加入，性能将进一步提升。此外，我们展示了我们的方法对具有高达 8.6 亿个参数的扩散语言模型的有效性。

##### **Graph Based Traffic Analysis and Delay Prediction**
2410.21028v1 by Gabriele Borg, Charlie Abela

This research is focused on traffic congestion in the small island of Malta
which is the most densely populated country in the EU with about 1,672
inhabitants per square kilometre (4,331 inhabitants/sq mi). Furthermore, Malta
has a rapid vehicle growth. Based on our research, the number of vehicles
increased by around 11,000 in a little more than 6 months, which shows how
important it is to have an accurate and comprehensive means of collecting data
to tackle the issue of fluctuating traffic in Malta. In this paper, we first
present the newly built comprehensive traffic dataset, called MalTra. This
dataset includes realistic trips made by members of the public across the
island over a period of 200 days. We then describe the methodology we adopted
to generate syntactic data to complete our data set as much as possible. In our
research, we consider both MalTra and the Q-Traffic dataset, which has been
used in several other research studies. The statistical ARIMA model and two
graph neural networks, the spatial temporal graph convolutional network (STGCN)
and the diffusion convolutional recurrent network (DCRNN) were used to analyse
and compare the results with existing research. From the evaluation, we found
that the DCRNN model outperforms the STGCN with the former resulting in MAE of
3.98 (6.65 in the case of the latter) and a RMSE of 7.78 (against 12.73 of the
latter).

摘要：本研究著重於馬爾他這個小島的交通壅塞問題，馬爾他為歐盟人口最密集的國家，每平方公里約有 1,672 名居民（每平方英里 4,331 名居民）。此外，馬爾他的車輛成長快速。根據我們的研究，車輛數量在短短 6 個多月內增加了約 11,000 輛，這顯示出擁有準確且全面的資料收集方式對於解決馬爾他交通波動問題有多麼重要。在本文中，我們首先提出新建立的全面交通資料集，稱為 MalTra。此資料集包括 200 天內公眾在島上進行的實際行程。然後，我們說明我們採用的方法來產生句法資料，以盡可能地完成我們的資料集。在我們的研究中，我們同時考慮了 MalTra 和 Q-Traffic 資料集，後者已用於其他多項研究。統計 ARIMA 模型和兩個圖神經網路，空間時間圖形卷積網路 (STGCN) 和擴散卷積遞迴網路 (DCRNN) 用於分析並將結果與現有研究進行比較。從評估中，我們發現 DCRNN 模型優於 STGCN，前者的 MAE 為 3.98（後者為 6.65），RMSE 為 7.78（後者為 12.73）。

##### **Transferable Post-training via Inverse Value Learning**
2410.21027v1 by Xinyu Lu, Xueru Wen, Yaojie Lu, Bowen Yu, Hongyu Lin, Haiyang Yu, Le Sun, Xianpei Han, Yongbin Li

As post-training processes utilize increasingly large datasets and base
models continue to grow in size, the computational demands and implementation
challenges of existing algorithms are escalating significantly. In this paper,
we propose modeling the changes at the logits level during post-training using
a separate neural network (i.e., the value network). After training this
network on a small base model using demonstrations, this network can be
seamlessly integrated with other pre-trained models during inference, enables
them to achieve similar capability enhancements. We systematically investigate
the best practices for this paradigm in terms of pre-training weights and
connection schemes. We demonstrate that the resulting value network has broad
transferability across pre-trained models of different parameter sizes within
the same family, models undergoing continuous pre-training within the same
family, and models with different vocabularies across families. In certain
cases, it can achieve performance comparable to full-parameter fine-tuning.
Furthermore, we explore methods to enhance the transferability of the value
model and prevent overfitting to the base model used during training.

摘要：隨著訓練後流程使用越來越大的資料集，基礎模型持續增長，現有演算法的運算需求和實作挑戰大幅增加。在本文中，我們提出在訓練後利用一個獨立的神經網路（即值網路）對 logits 層級的變更進行建模。在使用示範對小型基礎模型訓練此網路後，此網路可以在推理期間與其他預訓練模型無縫整合，使它們能夠實現類似的功能增強。我們系統性地探討此範例的最佳實務，包括預訓練權重和連接架構。我們證明，由此產生的值網路在同一個系列中不同參數大小的預訓練模型、在同一個系列中持續進行預訓練的模型，以及跨系列具有不同詞彙的模型之間具有廣泛的可轉移性。在某些情況下，它可以達到與全參數微調相當的效能。此外，我們探討了增強值模型可轉移性並防止過度擬合到訓練期間所使用的基礎模型的方法。

##### **Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems**
2410.21014v1 by Helen Schneider, Sebastian Nowak, Aditya Parikh, Yannik C. Layer, Maike Theis, Wolfgang Block, Alois M. Sprinkart, Ulrike Attenberger, Rafet Sifa

Image-based diagnostic decision support systems (DDSS) utilizing deep
learning have the potential to optimize clinical workflows. However, developing
DDSS requires extensive datasets with expert annotations and is therefore
costly. Leveraging report contents from radiological data bases with Natural
Language Processing to annotate the corresponding image data promises to
replace labor-intensive manual annotation. As mining "real world" databases can
introduce label noise, noise-robust training losses are of great interest.
However, current noise-robust losses do not consider noise estimations that can
for example be derived based on the performance of the automatic label
generator used. In this study, we expand the noise-robust Deep Abstaining
Classifier (DAC) loss to an Informed Deep Abstaining Classifier (IDAC) loss by
incorporating noise level estimations during training. Our findings demonstrate
that IDAC enhances the noise robustness compared to DAC and several
state-of-the-art loss functions. The results are obtained on various simulated
noise levels using a public chest X-ray data set. These findings are reproduced
on an in-house noisy data set, where labels were extracted from the clinical
systems of the University Hospital Bonn by a text-based transformer. The IDAC
can therefore be a valuable tool for researchers, companies or clinics aiming
to develop accurate and reliable DDSS from routine clinical data.

摘要：<paragraph>利用深度學習的影像診斷決策支援系統 (DDSS) 有可能最佳化臨床工作流程。然而，開發 DDSS 需要大量具備專家註解的資料集，因此成本高昂。利用自然語言處理從放射科資料庫的報告內容中標註對應的影像資料，有望取代勞力密集的手動標註。由於挖掘「真實世界」資料庫可能會引入標籤雜訊，因此對雜訊穩健的訓練損失非常重要。然而，目前對雜訊穩健的損失函數並未考慮雜訊估計，例如可以根據所使用的自動標籤產生器的效能推導出來。在本研究中，我們透過在訓練期間納入雜訊等級估計，將對雜訊穩健的深度棄權分類器 (DAC) 損失函數擴充為明智深度棄權分類器 (IDAC) 損失函數。我們的研究結果顯示，與 DAC 和多種最先進的損失函數相比，IDAC 增強了對雜訊的穩健性。這些結果是使用公開的胸部 X 光資料集，在各種模擬雜訊等級中獲得的。這些研究結果在內部雜訊資料集上重現，其中標籤是由文本轉換器從波恩大學醫院的臨床系統中萃取出來的。因此，IDAC 可以成為研究人員、公司或診所從例行臨床資料開發準確且可靠的 DDSS 的有價值工具。</paragraph>

##### **Frequency matters: Modeling irregular morphological patterns in Spanish with Transformers**
2410.21013v1 by Akhilesh Kakolu Ramarao, Kevin Tang, Dinah Baer-Henney

The present paper evaluates the learning behaviour of a transformer-based
neural network with regard to an irregular inflectional paradigm. We apply the
paradigm cell filling problem to irregular patterns. We approach this problem
using the morphological reinflection task and model it as a character
sequence-to-sequence learning problem. The test case under investigation are
irregular verbs in Spanish. Besides many regular verbs in Spanish L-shaped
verbs the first person singular indicative stem irregularly matches the
subjunctive paradigm, while other indicative forms remain unaltered. We examine
the role of frequency during learning and compare models under differing input
frequency conditions. We train the model on a corpus of Spanish with a
realistic distribution of regular and irregular verbs to compare it with models
trained on input with augmented distributions of (ir)regular words. We explore
how the neural models learn this L-shaped pattern using post-hoc analyses. Our
experiments show that, across frequency conditions, the models are surprisingly
capable of learning the irregular pattern. Furthermore, our post-hoc analyses
reveal the possible sources of errors. All code and data are available at
\url{https://anonymous.4open.science/r/modeling_spanish_acl-7567/} under MIT
license.

摘要：本篇論文評估了基於 Transformer 的神經網路，針對不規則的詞形變化範例的學習行為。我們將範例單元填補問題應用於不規則模式。我們使用形態重新詞形變化任務來解決此問題，並將其建模為字元序列對序列學習問題。所研究的測試案例是西班牙語中的不規則動詞。除了西班牙語中的許多規則動詞 L 形動詞外，第一人稱單數指示詞幹不規則地符合虛擬語氣範例，而其他指示形式保持不變。我們檢驗了頻率在學習中的作用，並比較了在不同輸入頻率條件下的模型。我們在西班牙語語料庫上訓練模型，其中規則動詞和不規則動詞的分布符合實際情況，以將其與在輸入中使用 ( 不 ) 規則詞彙的擴充分布訓練的模型進行比較。我們探討了神經模型如何使用事後分析來學習這種 L 形模式。我們的實驗表明，在不同的頻率條件下，這些模型在學習不規則模式方面具有驚人的能力。此外，我們的後驗分析揭示了錯誤的可能來源。所有程式碼和資料都可以在 MIT 授權下於\url{https://anonymous.4open.science/r/modeling_spanish_acl-7567/} 取得。

##### **FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval**
2410.21012v1 by Jinlin Wang, Suyuchen Wang, Ziwen Xia, Sirui Hong, Yun Zhu, Bang Liu, Chenglin Wu

Large Language Models (LLMs) are proficient at retrieving single facts from
extended contexts, yet they struggle with tasks requiring the simultaneous
retrieval of multiple facts, especially during generation. This paper
identifies a novel "lost-in-the-middle" phenomenon, where LLMs progressively
lose track of critical information throughout the generation process, resulting
in incomplete or inaccurate retrieval. To address this challenge, we introduce
Find All Crucial Texts (FACT), an iterative retrieval method that refines
context through successive rounds of rewriting. This approach enables models to
capture essential facts incrementally, which are often overlooked in
single-pass retrieval. Experiments demonstrate that FACT substantially enhances
multi-fact retrieval performance across various tasks, though improvements are
less notable in general-purpose QA scenarios. Our findings shed light on the
limitations of LLMs in multi-fact retrieval and underscore the need for more
resilient long-context retrieval strategies.

摘要：大型語言模型 (LLM) 擅長從延伸的脈絡中擷取單一事實，但它們在需要同時擷取多個事實的任務中會遇到困難，特別是在生成過程中。此論文指出了一個新穎的「迷失在中間」現象，其中 LLM 在整個生成過程中逐漸失去對關鍵資訊的追蹤，導致擷取不完整或不準確。為了應對這個挑戰，我們引入了「找出所有關鍵文本」(FACT)，一種透過連續多輪改寫來改善脈絡的疊代式擷取方法。此方法讓模型能夠逐步擷取必要的關鍵事實，這些事實通常會在單次擷取中被忽略。實驗證明，FACT 大幅提升了各種任務中的多重事實擷取效能，儘管在一般用途的問答場景中，改進幅度較不顯著。我們的發現闡明了 LLM 在多重事實擷取中的限制，並強調需要更具韌性的長脈絡擷取策略。

##### **Is GPT-4 Less Politically Biased than GPT-3.5? A Renewed Investigation of ChatGPT's Political Biases**
2410.21008v1 by Erik Weber, Jérôme Rutinowski, Niklas Jost, Markus Pauly

This work investigates the political biases and personality traits of
ChatGPT, specifically comparing GPT-3.5 to GPT-4. In addition, the ability of
the models to emulate political viewpoints (e.g., liberal or conservative
positions) is analyzed. The Political Compass Test and the Big Five Personality
Test were employed 100 times for each scenario, providing statistically
significant results and an insight into the results correlations. The responses
were analyzed by computing averages, standard deviations, and performing
significance tests to investigate differences between GPT-3.5 and GPT-4.
Correlations were found for traits that have been shown to be interdependent in
human studies. Both models showed a progressive and libertarian political bias,
with GPT-4's biases being slightly, but negligibly, less pronounced.
Specifically, on the Political Compass, GPT-3.5 scored -6.59 on the economic
axis and -6.07 on the social axis, whereas GPT-4 scored -5.40 and -4.73. In
contrast to GPT-3.5, GPT-4 showed a remarkable capacity to emulate assigned
political viewpoints, accurately reflecting the assigned quadrant
(libertarian-left, libertarian-right, authoritarian-left, authoritarian-right)
in all four tested instances. On the Big Five Personality Test, GPT-3.5 showed
highly pronounced Openness and Agreeableness traits (O: 85.9%, A: 84.6%). Such
pronounced traits correlate with libertarian views in human studies. While
GPT-4 overall exhibited less pronounced Big Five personality traits, it did
show a notably higher Neuroticism score. Assigned political orientations
influenced Openness, Agreeableness, and Conscientiousness, again reflecting
interdependencies observed in human studies. Finally, we observed that test
sequencing affected ChatGPT's responses and the observed correlations,
indicating a form of contextual memory.

摘要：<paragraph>本研究调查了 ChatGPT 的政治偏见和人格特质，特别是将 GPT-3.5 与 GPT-4 进行了比较。此外，分析了模型模拟政治观点（例如，自由派或保守派立场）的能力。政治罗盘测试和大五人格测试每种情况都进行了 100 次，提供了统计学意义上的结果，并深入了解了结果之间的相关性。通过计算平均值、标准差和执行显著性检验来分析响应，以调查 GPT-3.5 和 GPT-4 之间的差异。在人类研究中已显示相互依存的特质中发现了相关性。两种模型都表现出进步和自由主义的政治偏见，而 GPT-4 的偏见略微不明显，但可以忽略不计。具体来说，在政治罗盘上，GPT-3.5 在经济轴上得分为 -6.59，在社会轴上得分为 -6.07，而 GPT-4 得分为 -5.40 和 -4.73。与 GPT-3.5 相比，GPT-4 表现出模拟指定政治观点的显着能力，准确反映了所有四种测试实例中的指定象限（自由主义左派、自由主义右派、威权主义左派、威权主义右派）。在五大性格测试中，GPT-3.5 表现出非常明显开放性和宜人性特征 (O: 85.9%，A: 84.6%)。如此明显的特质与人类研究中的自由主义观点相关。虽然 GPT-4 整体表现出不太明显的五大性格特质，但它确实显示出明显较高的神经质分数。指定的政治取向影响了开放性、宜人性、尽责性，再次反映了人类研究中观察到的相互依存性。最后，我们观察到测试顺序影响了 ChatGPT 的响应和观察到的相关性，表明了一种上下文记忆形式。</paragraph>

##### **Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering**
2410.21000v1 by Zhilin Zhang, Jie Wang, Ruiqi Zhu, Xiaoliang Gong

Medical Visual Question Answering (MedVQA) has gained increasing attention at
the intersection of computer vision and natural language processing. Its
capability to interpret radiological images and deliver precise answers to
clinical inquiries positions MedVQA as a valuable tool for supporting
diagnostic decision-making for physicians and alleviating the workload on
radiologists. While recent approaches focus on using unified pre-trained large
models for multi-modal fusion like cross-modal Transformers, research on more
efficient fusion methods remains relatively scarce within this discipline. In
this paper, we introduce a novel fusion model that integrates Orthogonality
loss, Multi-head attention and Bilinear Attention Network (OMniBAN) to achieve
high computational efficiency and strong performance without the need for
pre-training. We conduct comprehensive experiments and clarify aspects of how
to enhance bilinear attention fusion to achieve performance comparable to that
of large models. Experimental results show that OMniBAN outperforms traditional
models on key MedVQA benchmarks while maintaining a lower computational cost,
which indicates its potential for efficient clinical application in radiology
and pathology image question answering.

摘要：醫療視覺問答 (MedVQA) 在電腦視覺和自然語言處理的交集中獲得越來越多的關注。它能夠解讀放射影像並對臨床詢問提供精確答案的能力，使 MedVQA 成為支援醫師診斷決策和減輕放射科醫師工作負擔的寶貴工具。雖然最近的方法著重於使用統一的預先訓練大型模型進行多模式融合，例如跨模態 Transformer，但對於更有效率的融合方法的研究在此領域中仍然相對稀少。在本文中，我們介紹了一個新穎的融合模型，它整合了正交損失、多頭注意力和雙線性注意力網路 (OMniBAN)，以在不需要預先訓練的情況下實現高計算效率和強大效能。我們進行了全面的實驗，並釐清了如何增強雙線性注意力融合以實現與大型模型相當的效能。實驗結果表明，OMniBAN 在關鍵的 MedVQA 基準上優於傳統模型，同時維持較低的計算成本，這表明它在放射學和病理影像問答中具有高效臨床應用的潛力。

##### **EEG-Driven 3D Object Reconstruction with Color Consistency and Diffusion Prior**
2410.20981v2 by Xin Xiang, Wenhui Zhou, Guojun Dai

EEG-based visual perception reconstruction has become a current research
hotspot. Neuroscientific studies have shown that humans can perceive various
types of visual information, such as color, shape, and texture, when observing
objects. However, existing technical methods often face issues such as
inconsistencies in texture, shape, and color between the visual stimulus images
and the reconstructed images. In this paper, we propose a method for
reconstructing 3D objects with color consistency based on EEG signals. The
method adopts a two-stage strategy: in the first stage, we train an implicit
neural EEG encoder with the capability of perceiving 3D objects, enabling it to
capture regional semantic features; in the second stage, based on the latent
EEG codes obtained in the first stage, we integrate a diffusion model, neural
style loss, and NeRF to implicitly decode the 3D objects. Finally, through
experimental validation, we demonstrate that our method can reconstruct 3D
objects with color consistency using EEG.

摘要：基於腦電圖的視覺感知重建已成為當前研究熱點。神經科學研究表明，人類在觀察物體時，可以感知各種類型的視覺資訊，例如顏色、形狀和紋理。然而，現有的技術方法經常面臨視覺刺激圖像和重建圖像之間的紋理、形狀和顏色不一致等問題。在本文中，我們提出了一種基於腦電圖訊號重建具有顏色一致性的 3D 物體的方法。該方法採用兩階段策略：在第一階段，我們訓練一個具有感知 3D 物體能力的隱式神經腦電圖編碼器，使其能夠捕獲區域語義特徵；在第二階段，基於第一階段獲得的潛在腦電圖編碼，我們整合一個擴散模型、神經風格損失和 NeRF 來隱式解碼 3D 物體。最後，通過實驗驗證，我們證明了我們的方法可以使用腦電圖重建具有顏色一致性的 3D 物體。

##### **Geo-FuB: A Method for Constructing an Operator-Function Knowledge Base for Geospatial Code Generation Tasks Using Large Language Models**
2410.20975v1 by Shuyang Hou, Anqi Zhao, Jianyuan Liang, Zhangxiao Shen, Huayi Wu

The rise of spatiotemporal data and the need for efficient geospatial
modeling have spurred interest in automating these tasks with large language
models (LLMs). However, general LLMs often generate errors in geospatial code
due to a lack of domain-specific knowledge on functions and operators. To
address this, a retrieval-augmented generation (RAG) approach, utilizing an
external knowledge base of geospatial functions and operators, is proposed.
This study introduces a framework to construct such a knowledge base,
leveraging geospatial script semantics. The framework includes: Function
Semantic Framework Construction (Geo-FuSE), Frequent Operator Combination
Statistics (Geo-FuST), and Semantic Mapping (Geo-FuM). Techniques like
Chain-of-Thought, TF-IDF, and the APRIORI algorithm are utilized to derive and
align geospatial functions. An example knowledge base, Geo-FuB, built from
154,075 Google Earth Engine scripts, is available on GitHub. Evaluation metrics
show a high accuracy, reaching 88.89% overall, with structural and semantic
accuracies of 92.03% and 86.79% respectively. Geo-FuB's potential to optimize
geospatial code generation through the RAG and fine-tuning paradigms is
highlighted.

摘要：時空資料的興起和有效地理空間建模的需求，刺激了使用大型語言模型 (LLM) 自動化這些任務的興趣。然而，由於缺乏函數和運算子的領域特定知識，一般 LLM 經常在地理空間程式碼中產生錯誤。為了解決這個問題，提出了一種檢索增強生成 (RAG) 方法，利用地理空間函數和運算子的外部知識庫。本研究介紹了一個建構此類知識庫的架構，利用地理空間腳本語義。該架構包括：函數語義架構建構 (Geo-FuSE)、頻繁運算子組合統計 (Geo-FuST) 和語義對應 (Geo-FuM)。利用思想鏈、TF-IDF 和 APRIORI 演算法等技術來推導和對齊地理空間函數。由 154,075 個 Google Earth Engine 腳本建構的範例知識庫 Geo-FuB 可在 GitHub 上取得。評估指標顯示出高準確度，整體達到 88.89%，結構和語義準確度分別為 92.03% 和 86.79%。強調了 Geo-FuB 通過 RAG 和微調範例最佳化地理空間程式碼生成的潛力。

##### **BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks**
2410.20971v1 by Yunhan Zhao, Xiang Zheng, Lin Luo, Yige Li, Xingjun Ma, Yu-Gang Jiang

Despite their superb multimodal capabilities, Vision-Language Models (VLMs)
have been shown to be vulnerable to jailbreak attacks, which are inference-time
attacks that induce the model to output harmful responses with tricky prompts.
It is thus essential to defend VLMs against potential jailbreaks for their
trustworthy deployment in real-world applications. In this work, we focus on
black-box defense for VLMs against jailbreak attacks. Existing black-box
defense methods are either unimodal or bimodal. Unimodal methods enhance either
the vision or language module of the VLM, while bimodal methods robustify the
model through text-image representation realignment. However, these methods
suffer from two limitations: 1) they fail to fully exploit the cross-modal
information, or 2) they degrade the model performance on benign inputs. To
address these limitations, we propose a novel blue-team method BlueSuffix that
defends the black-box target VLM against jailbreak attacks without compromising
its performance. BlueSuffix includes three key components: 1) a visual purifier
against jailbreak images, 2) a textual purifier against jailbreak texts, and 3)
a blue-team suffix generator fine-tuned via reinforcement learning for
enhancing cross-modal robustness. We empirically show on three VLMs (LLaVA,
MiniGPT-4, and Gemini) and two safety benchmarks (MM-SafetyBench and
RedTeam-2K) that BlueSuffix outperforms the baseline defenses by a significant
margin. Our BlueSuffix opens up a promising direction for defending VLMs
against jailbreak attacks.

摘要：儘管具有優異的多模態功能，但已證明視覺語言模型 (VLM) 容易受到越獄攻擊，這是一種在推論時誘使模型使用棘手的提示來輸出有害回應的攻擊。因此，必須為 VLM 提供防禦潛在越獄攻擊的保護，以確保其在實際應用中的可信賴部署。在這項工作中，我們專注於針對越獄攻擊對 VLM 進行黑盒防禦。現有的黑盒防禦方法不是單模態就是雙模態。單模態方法增強 VLM 的視覺或語言模組，而雙模態方法則透過文字影像表示重新對齊來強化模型。然而，這些方法有兩個限制：1) 無法充分利用跨模態資訊，或 2) 降低模型對良性輸入的效能。為了解決這些限制，我們提出了一種新穎的藍隊方法 BlueSuffix，它可以在不影響效能的情況下，針對黑盒目標 VLM 防禦越獄攻擊。BlueSuffix 包含三個主要組成部分：1) 針對越獄影像的視覺淨化器，2) 針對越獄文字的文字淨化器，以及 3) 透過強化學習微調的藍隊後綴產生器，以增強跨模態的穩健性。我們在三個 VLM (LLaVA、MiniGPT-4 和 Gemini) 和兩個安全基準 (MM-SafetyBench 和 RedTeam-2K) 上實證顯示，BlueSuffix 以顯著的幅度優於基線防禦措施。我們的 BlueSuffix 為防禦 VLM 針對越獄攻擊開闢了一個有希望的方向。

##### **Improving Detection of Person Class Using Dense Pooling**
2410.20966v1 by Nouman Ahmad

Lately, the continuous development of deep learning models by many
researchers in the area of computer vision has attracted more researchers to
further improve the accuracy of these models. FasterRCNN [32] has already
provided a state-of-the-art approach to improve the accuracy and detection of
80 different objects given in the COCO dataset. To further improve the
performance of person detection we have conducted a different approach which
gives the state-of-the-art conclusion. An ROI is a step in FasterRCNN that
extract the features from the given image with a fixed size and transfer into
for further classification. To enhance the ROI performance, we have conducted
an approach that implements dense pooling and converts the image into a 3D
model to further transform into UV(ultra Violet) images which makes it easy to
extract the right features from the images. To implement our approach we have
approached the state-of-the-art COCO datasets and extracted 6982 images that
include a person object and our final achievements conclude that using our
approach has made significant results in detecting the person object in the
given image

摘要：最近，许多计算机视觉领域的学者持续开发深度学习模型，吸引了更多学者进一步提高这些模型的准确性。FasterRCNN [32] 已经提供了一种最先进的方法来提高 COCO 数据集中给出的 80 个不同对象的准确性和检测率。为了进一步提高人员检测性能，我们采用了一种不同的方法，得出了最先进的结论。ROI 是 FasterRCNN 中的一个步骤，它从给定的图像中提取具有固定大小的特征并传输到进一步分类。为了增强 ROI 性能，我们采用了一种方法，该方法实现了密集池化并将图像转换为 3D 模型，以便进一步转换为 UV（紫外线）图像，从而可以轻松地从图像中提取正确的特征。为了实施我们的方法，我们已经接触了最先进的 COCO 数据集，并提取了 6982 张包含人物对象的图像，我们的最终成果表明，使用我们的方法在给定图像中检测人物对象方面取得了显着的成果

##### **DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning**
2410.20964v1 by Xun Guo, Shan Zhang, Yongxin He, Ting Zhang, Wanquan Feng, Haibin Huang, Chongyang Ma

Current techniques for detecting AI-generated text are largely confined to
manual feature crafting and supervised binary classification paradigms. These
methodologies typically lead to performance bottlenecks and unsatisfactory
generalizability. Consequently, these methods are often inapplicable for
out-of-distribution (OOD) data and newly emerged large language models (LLMs).
In this paper, we revisit the task of AI-generated text detection. We argue
that the key to accomplishing this task lies in distinguishing writing styles
of different authors, rather than simply classifying the text into
human-written or AI-generated text. To this end, we propose DeTeCtive, a
multi-task auxiliary, multi-level contrastive learning framework. DeTeCtive is
designed to facilitate the learning of distinct writing styles, combined with a
dense information retrieval pipeline for AI-generated text detection. Our
method is compatible with a range of text encoders. Extensive experiments
demonstrate that our method enhances the ability of various text encoders in
detecting AI-generated text across multiple benchmarks and achieves
state-of-the-art results. Notably, in OOD zero-shot evaluation, our method
outperforms existing approaches by a large margin. Moreover, we find our method
boasts a Training-Free Incremental Adaptation (TFIA) capability towards OOD
data, further enhancing its efficacy in OOD detection scenarios. We will
open-source our code and models in hopes that our work will spark new thoughts
in the field of AI-generated text detection, ensuring safe application of LLMs
and enhancing compliance. Our code is available at
https://github.com/heyongxin233/DeTeCtive.

摘要：<paragraph>目前用於偵測 AI 生成的文字的技術，大多侷限於手動特徵製作和監督二元分類範例。這些方法通常會導致效能瓶頸和令人不滿意的泛化能力。因此，這些方法通常不適用於分布外 (OOD) 資料和新興的大型語言模型 (LLM)。在本文中，我們重新探討 AI 生成的文字偵測任務。我們主張，完成此任務的關鍵在於區分不同作者的寫作風格，而不仅仅是將文字分類為人寫或 AI 生成的文字。為此，我們提出 DeTeCtive，一個多任務輔助、多層對比學習架構。DeTeCtive 被設計為促進不同寫作風格的學習，並結合密集資訊檢索管道進行 AI 生成的文字偵測。我們的模型與各種文字編碼器相容。廣泛的實驗證明，我們的模型增強了各種文字編碼器在多個基準上偵測 AI 生成的文字的能力，並達到了最先進的結果。值得注意的是，在 OOD 零次學習評估中，我們的模型大幅優於現有方法。此外，我們發現我們的模型具備對 OOD 資料的訓練免費增量適應 (TFIA) 能力，進一步增強了其在 OOD 偵測場景中的效力。我們將開放原始碼和模型，希望我們的著作能激發 AI 生成的文字偵測領域的新思維，確保 LLM 的安全應用並增強合規性。我們的程式碼可在 https://github.com/heyongxin233/DeTeCtive 取得。</paragraph>

##### **Neuro-symbolic Learning Yielding Logical Constraints**
2410.20957v1 by Zenan Li, Yunpeng Huang, Zhaoyu Li, Yuan Yao, Jingwei Xu, Taolue Chen, Xiaoxing Ma, Jian Lu

Neuro-symbolic systems combine the abilities of neural perception and logical
reasoning. However, end-to-end learning of neuro-symbolic systems is still an
unsolved challenge. This paper proposes a natural framework that fuses neural
network training, symbol grounding, and logical constraint synthesis into a
coherent and efficient end-to-end learning process. The capability of this
framework comes from the improved interactions between the neural and the
symbolic parts of the system in both the training and inference stages.
Technically, to bridge the gap between the continuous neural network and the
discrete logical constraint, we introduce a difference-of-convex programming
technique to relax the logical constraints while maintaining their precision.
We also employ cardinality constraints as the language for logical constraint
learning and incorporate a trust region method to avoid the degeneracy of
logical constraint in learning. Both theoretical analyses and empirical
evaluations substantiate the effectiveness of the proposed framework.

摘要：神經符號系統結合了神經感知和邏輯推理的能力。然而，神經符號系統的端到端學習仍是一個未解決的挑戰。本文提出了一個自然框架，將神經網路訓練、符號基礎和邏輯約束合成融合到一個連貫且有效的端到端學習過程中。此框架的能力來自於訓練和推理階段中神經和符號部分之間互動的改善。在技術上，為了彌合連續神經網路和離散邏輯約束之間的差距，我們引入一個凸差規劃技術來放寬邏輯約束，同時保持其精度。我們還使用基數約束作為邏輯約束學習的語言，並結合一個信任區域方法來避免邏輯約束在學習中的簡併。理論分析和實證評估都證實了所提出的框架的有效性。

##### **Active Legibility in Multiagent Reinforcement Learning**
2410.20954v1 by Yanyu Liu, Yinghui Pan, Yifeng Zeng, Biyang Ma, Doshi Prashant

A multiagent sequential decision problem has been seen in many critical
applications including urban transportation, autonomous driving cars, military
operations, etc. Its widely known solution, namely multiagent reinforcement
learning, has evolved tremendously in recent years. Among them, the solution
paradigm of modeling other agents attracts our interest, which is different
from traditional value decomposition or communication mechanisms. It enables
agents to understand and anticipate others' behaviors and facilitates their
collaboration. Inspired by recent research on the legibility that allows agents
to reveal their intentions through their behavior, we propose a multiagent
active legibility framework to improve their performance. The
legibility-oriented framework allows agents to conduct legible actions so as to
help others optimise their behaviors. In addition, we design a series of
problem domains that emulate a common scenario and best characterize the
legibility in multiagent reinforcement learning. The experimental results
demonstrate that the new framework is more efficient and costs less training
time compared to several multiagent reinforcement learning algorithms.

摘要：在許多重要的應用程式中，例如城市交通、自動駕駛汽車、軍事行動等，都可以看到多智能體序列決策問題。其廣為人知的解決方案，即多智能體強化學習，近年來已取得長足的進步。其中，模擬其他智能體的解決方案範例引起了我們的興趣，這與傳統的價值分解或溝通機制不同。它使智能體能夠理解和預測其他智能體的行為，並促進它們的協作。受到最近關於可讀性研究的啟發，可讀性允許智能體通過其行為揭示其意圖，我們提出了一個多智能體主動可讀性框架來提高它們的性能。以可讀性為導向的框架允許智能體執行可讀的動作，以幫助他人優化其行為。此外，我們設計了一系列問題領域，模擬了一個常見的場景，並最好地表徵了多智能體強化學習中的可讀性。實驗結果表明，與幾種多智能體強化學習演算法相比，新的框架更有效率且訓練時間更短。

##### **Instruction-Tuned LLMs Succeed in Document-Level MT Without Fine-Tuning -- But BLEU Turns a Blind Eye**
2410.20941v2 by Yirong Sun, Dawei Zhu, Yanjun Chen, Erjia Xiao, Xinghao Chen, Xiaoyu Shen

Large language models (LLMs) have excelled in various NLP tasks, including
machine translation (MT), yet most studies focus on sentence-level translation.
This work investigates the inherent capability of instruction-tuned LLMs for
document-level translation (docMT). Unlike prior approaches that require
specialized techniques, we evaluate LLMs by directly prompting them to
translate entire documents in a single pass. Our results show that this method
improves translation quality compared to translating sentences separately, even
without document-level fine-tuning. However, this advantage is not reflected in
BLEU scores, which often favor sentence-based translations. We propose using
the LLM-as-a-judge paradigm for evaluation, where GPT-4 is used to assess
document coherence, accuracy, and fluency in a more nuanced way than
n-gram-based metrics. Overall, our work demonstrates that instruction-tuned
LLMs can effectively leverage document context for translation. However, we
caution against using BLEU scores for evaluating docMT, as they often provide
misleading outcomes, failing to capture the quality of document-level
translation. Code and data are available at
https://github.com/EIT-NLP/BLEUless_DocMT

摘要：大型語言模型 (LLM) 已在各種自然語言處理 (NLP) 任務中表現優異，包括機器翻譯 (MT)，但大多數研究都專注於句子層級翻譯。這項研究探討了針對指令調整的 LLM 在文件層級翻譯 (docMT) 中的固有能力。與需要特殊技術的先前方法不同，我們透過直接提示 LLM 一次翻譯整個文件來評估 LLM。我們的結果顯示，與分別翻譯句子相比，此方法可提升翻譯品質，即使沒有進行文件層級微調。然而，此優勢並未反映在 BLEU 分數中，而 BLEU 分數通常偏好基於句子的翻譯。我們建議使用 LLM 作為評判的評估範例，其中 GPT-4 用於以比 n-gram 基準更細緻的方式評估文件的一致性、準確性和流暢性。整體而言，我們的研究證明了針對指令調整的 LLM 可以有效利用文件內容進行翻譯。然而，我們警告不要使用 BLEU 分數來評估 docMT，因為它們通常會提供誤導性的結果，無法掌握文件層級翻譯的品質。程式碼和資料可於 https://github.com/EIT-NLP/BLEUless_DocMT 取得

##### **Attacking Misinformation Detection Using Adversarial Examples Generated by Language Models**
2410.20940v1 by Piotr Przybyła

We investigate the challenge of generating adversarial examples to test the
robustness of text classification algorithms detecting low-credibility content,
including propaganda, false claims, rumours and hyperpartisan news. We focus on
simulation of content moderation by setting realistic limits on the number of
queries an attacker is allowed to attempt. Within our solution (TREPAT),
initial rephrasings are generated by large language models with prompts
inspired by meaning-preserving NLP tasks, e.g. text simplification and style
transfer. Subsequently, these modifications are decomposed into small changes,
applied through beam search procedure until the victim classifier changes its
decision. The evaluation confirms the superiority of our approach in the
constrained scenario, especially in case of long input text (news articles),
where exhaustive search is not feasible.

摘要：我們探討產生對抗範例的挑戰，以測試文本分類演算法偵測低可信度內容的健全性，包括宣傳、虛假聲明、謠言和過度黨派新聞。我們專注於內容審核的模擬，對攻擊者允許嘗試的查詢數量設定實際限制。在我們的解決方案 (TREPAT) 中，初始改寫是由大型語言模型產生的，提示受到保留意義的 NLP 任務啟發，例如文本簡化和風格轉移。隨後，這些修改被分解成小變動，透過波束搜尋程序應用，直到受害者分類器改變其決定。評估證實了我們的方法在受限場景中的優越性，特別是在長輸入文本（新聞文章）的情況下，其中詳盡搜尋不可行。

##### **Autoformalize Mathematical Statements by Symbolic Equivalence and Semantic Consistency**
2410.20936v1 by Zenan Li, Yifan Wu, Zhaoyu Li, Xinming Wei, Xian Zhang, Fan Yang, Xiaoxing Ma

Autoformalization, the task of automatically translating natural language
descriptions into a formal language, poses a significant challenge across
various domains, especially in mathematics. Recent advancements in large
language models (LLMs) have unveiled their promising capabilities to formalize
even competition-level math problems. However, we observe a considerable
discrepancy between pass@1 and pass@k accuracies in LLM-generated
formalizations. To address this gap, we introduce a novel framework that scores
and selects the best result from k autoformalization candidates based on two
complementary self-consistency methods: symbolic equivalence and semantic
consistency. Elaborately, symbolic equivalence identifies the logical
homogeneity among autoformalization candidates using automated theorem provers,
and semantic consistency evaluates the preservation of the original meaning by
informalizing the candidates and computing the similarity between the
embeddings of the original and informalized texts. Our extensive experiments on
the MATH and miniF2F datasets demonstrate that our approach significantly
enhances autoformalization accuracy, achieving up to 0.22-1.35x relative
improvements across various LLMs and baseline methods.

摘要：自動形式化，即自動將自然語言描述轉換為形式語言的任務，在各個領域，特別是在數學領域，都面臨著重大挑戰。大型語言模型 (LLM) 的最新進展揭示了它們將競賽級別的數學問題形式化的強大功能。然而，我們觀察到 LLM 生成的形式化中的 pass@1 和 pass@k 準確度之間存在相當大的差異。為了解決這一差距，我們引入了一個新框架，該框架根據兩種互補的自洽方法（符號等價和語義一致性）對 k 個自動形式化候選項進行評分並選擇最佳結果。具體來說，符號等價使用自動定理證明器識別自動形式化候選項之間的邏輯同質性，而語義一致性通過將候選項非形式化並計算原始文本和非形式化文本的嵌入之間的相似性來評估原始含義的保留。我們在 MATH 和 miniF2F 數據集上進行的廣泛實驗表明，我們的做法顯著提高了自動形式化的準確性，在各種 LLM 和基線方法中實現了高達 0.22-1.35 倍的相對改進。

##### **Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning**
2410.20926v1 by Aosong Feng, Rex Ying, Leandros Tassiulas

As the demand for processing extended textual data grows, the ability to
handle long-range dependencies and maintain computational efficiency is more
critical than ever. One of the key issues for long-sequence modeling using
attention-based model is the mismatch between the limited-range modeling power
of full attention and the long-range token dependency in the input sequence. In
this work, we propose to scale up the attention receptive field by tensorizing
long input sequences into compact tensor representations followed by attention
on each transformed dimension. The resulting Tensorized Attention can be
adopted as efficient transformer backbones to extend input context length with
improved memory and time efficiency. We show that the proposed attention
tensorization encodes token dependencies as a multi-hop attention process, and
is equivalent to Kronecker decomposition of full attention. Extensive
experiments show that tensorized attention can be used to adapt pretrained LLMs
with improved efficiency. Notably, Llama-8B with tensorization is trained under
32,768 context length and can steadily extrapolate to 128k length during
inference with $11\times$ speedup, compared to full attention with
FlashAttention-2.

摘要：隨著處理延伸文本資料的需求增加，處理長距離依賴關係並維持運算效率的能力比以往任何時候都更為關鍵。使用基於注意力的模型進行長序列建模的主要問題之一，在於全注意力的有限範圍建模能力與輸入序列中的長距離 token 依賴關係之間的不匹配。在這項工作中，我們建議透過將長輸入序列張量化為緊湊的張量表示，然後對每個轉換維度進行注意力，來擴充注意力感受野。由此產生的張量化注意力可以採用為高效的 Transformer 主幹，以擴充輸入上下文長度，並提高記憶體和時間效率。我們展示了所提出的注意力張量化將 token 依賴關係編碼為多跳注意力處理，並且等於全注意力的克羅內克分解。廣泛的實驗表明，張量化注意力可用於調整預訓練的 LLM，並提高效率。值得注意的是，採用張量化的 Llama-8B 在 32,768 的上下文長度下訓練，並且在推論期間可以穩定地外推到 128k 的長度，與採用 FlashAttention-2 的全注意力相比，速度提升了 $11\times$。

##### **FACTS: A Factored State-Space Framework For World Modelling**
2410.20922v1 by Li Nanbo, Firas Laakom, Yucheng Xu, Wenyi Wang, Jürgen Schmidhuber

World modelling is essential for understanding and predicting the dynamics of
complex systems by learning both spatial and temporal dependencies. However,
current frameworks, such as Transformers and selective state-space models like
Mambas, exhibit limitations in efficiently encoding spatial and temporal
structures, particularly in scenarios requiring long-term high-dimensional
sequence modelling. To address these issues, we propose a novel recurrent
framework, the \textbf{FACT}ored \textbf{S}tate-space (\textbf{FACTS}) model,
for spatial-temporal world modelling. The FACTS framework constructs a
graph-structured memory with a routing mechanism that learns permutable memory
representations, ensuring invariance to input permutations while adapting
through selective state-space propagation. Furthermore, FACTS supports parallel
computation of high-dimensional sequences. We empirically evaluate FACTS across
diverse tasks, including multivariate time series forecasting and
object-centric world modelling, demonstrating that it consistently outperforms
or matches specialised state-of-the-art models, despite its general-purpose
world modelling design.

摘要：世界建模對於透過學習空間和時間依賴性來理解和預測複雜系統的動態至關重要。然而，當前的架構（例如 Transformers 和選擇性的狀態空間模型，例如 Mambas）在有效編碼空間和時間結構方面表現出限制，特別是在需要長期高維序列建模的場景中。為了解決這些問題，我們提出了一個新穎的遞迴架構，即**F**ACTored **S**tate-space（**FACTS**）模型，用於時空世界建模。FACTS 架構構建了一個具有路由機制的圖形結構記憶體，該機制學習可置換記憶體表示，確保輸入置換的不變性，同時透過選擇性的狀態空間傳播進行適應。此外，FACTS 支援高維序列的並行運算。我們透過多元時間序列預測和以物件為中心的建模等多項任務對 FACTS 進行了實證評估，證明了它始終優於或匹配專門的最新模型，儘管它採用了通用的世界建模設計。

##### **NeuGPT: Unified multi-modal Neural GPT**
2410.20916v1 by Yiqian Yang, Yiqun Duan, Hyejeong Jo, Qiang Zhang, Renjing Xu, Oiwi Parker Jones, Xuming Hu, Chin-teng Lin, Hui Xiong

This paper introduces NeuGPT, a groundbreaking multi-modal language
generation model designed to harmonize the fragmented landscape of neural
recording research. Traditionally, studies in the field have been
compartmentalized by signal type, with EEG, MEG, ECoG, SEEG, fMRI, and fNIRS
data being analyzed in isolation. Recognizing the untapped potential for
cross-pollination and the adaptability of neural signals across varying
experimental conditions, we set out to develop a unified model capable of
interfacing with multiple modalities. Drawing inspiration from the success of
pre-trained large models in NLP, computer vision, and speech processing, NeuGPT
is architected to process a diverse array of neural recordings and interact
with speech and text data. Our model mainly focus on brain-to-text decoding,
improving SOTA from 6.94 to 12.92 on BLEU-1 and 6.93 to 13.06 on ROUGE-1F. It
can also simulate brain signals, thereby serving as a novel neural interface.
Code is available at
\href{https://github.com/NeuSpeech/NeuGPT}{NeuSpeech/NeuGPT
(https://github.com/NeuSpeech/NeuGPT) .}

摘要：本文介紹了 NeuGPT，這是一個劃時代的多模態語言生成模型，旨在調和神經記錄研究中支離破碎的現況。傳統上，該領域的研究一直由訊號類型區隔開來，EEG、MEG、ECoG、SEEG、fMRI 和 fNIRS 資料會被孤立地分析。我們認知到跨領域傳粉的潛力以及神經訊號在不同實驗條件下的適應性，因此著手開發一個統一的模型，能夠與多種模式介接。從 NLP、電腦視覺和語音處理中預先訓練大型模型的成功中汲取靈感，NeuGPT 被設計用於處理各種神經記錄，並與語音和文字資料互動。我們的模型主要專注於腦對文字的解碼，將 BLEU-1 的 SOTA 從 6.94 提升到 12.92，將 ROUGE-1F 從 6.93 提升到 13.06。它還可以模擬腦訊號，從而作為一個新穎的神經介面。程式碼可在
\href{https://github.com/NeuSpeech/NeuGPT}{NeuSpeech/NeuGPT
(https://github.com/NeuSpeech/NeuGPT) .} 取得。

##### **Hacking Back the AI-Hacker: Prompt Injection as a Defense Against LLM-driven Cyberattacks**
2410.20911v1 by Dario Pasquini, Evgenios M. Kornaropoulos, Giuseppe Ateniese

Large language models (LLMs) are increasingly being harnessed to automate
cyberattacks, making sophisticated exploits more accessible and scalable. In
response, we propose a new defense strategy tailored to counter LLM-driven
cyberattacks. We introduce Mantis, a defensive framework that exploits LLMs'
susceptibility to adversarial inputs to undermine malicious operations. Upon
detecting an automated cyberattack, Mantis plants carefully crafted inputs into
system responses, leading the attacker's LLM to disrupt their own operations
(passive defense) or even compromise the attacker's machine (active defense).
By deploying purposefully vulnerable decoy services to attract the attacker and
using dynamic prompt injections for the attacker's LLM, Mantis can autonomously
hack back the attacker. In our experiments, Mantis consistently achieved over
95% effectiveness against automated LLM-driven attacks. To foster further
research and collaboration, Mantis is available as an open-source tool:
https://github.com/pasquini-dario/project_mantis

摘要：大型語言模型 (LLM) 愈來愈常被用來自動化網路攻擊，讓精密攻擊更易於取得且可擴充。為此，我們提出了一種新的防禦策略，專門用來對抗 LLM 驅動的網路攻擊。我們引進 Mantis，一個防禦框架，它利用 LLM 對對抗性輸入的敏感性來破壞惡意操作。在偵測到自動化網路攻擊時，Mantis 會在系統回應中植入精心設計的輸入，讓攻擊者的 LLM 中斷自己的操作（被動防禦）或甚至危害攻擊者的機器（主動防禦）。透過部署有目的的易受攻擊誘餌服務來吸引攻擊者，並針對攻擊者的 LLM 使用動態提示注入，Mantis 可以自主反擊攻擊者。在我們的實驗中，Mantis 對抗自動化 LLM 驅動攻擊的有效性始終超過 95%。為了促進進一步的研究和合作，Mantis 已作為一個開放原始碼工具：https://github.com/pasquini-dario/project_mantis

##### **Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models**
2410.20898v1 by Weijian Luo, Colin Zhang, Debing Zhang, Zhengyang Geng

In this paper, we introduce the Diff-Instruct*(DI*), a data-free approach for
building one-step text-to-image generative models that align with human
preference while maintaining the ability to generate highly realistic images.
We frame human preference alignment as online reinforcement learning using
human feedback (RLHF), where the goal is to maximize the reward function while
regularizing the generator distribution to remain close to a reference
diffusion process. Unlike traditional RLHF approaches, which rely on the KL
divergence for regularization, we introduce a novel score-based divergence
regularization, which leads to significantly better performances. Although the
direct calculation of this divergence remains intractable, we demonstrate that
we can efficiently compute its \emph{gradient} by deriving an equivalent yet
tractable loss function. Remarkably, with Stable Diffusion V1.5 as the
reference diffusion model, DI* outperforms \emph{all} previously leading models
by a large margin. When using the 0.6B PixelArt-$\alpha$ model as the reference
diffusion, DI* achieves a new record Aesthetic Score of 6.30 and an Image
Reward of 1.31 with only a single generation step, almost doubling the scores
of the rest of the models with similar sizes. It also achieves an HPSv2 score
of 28.70, establishing a new state-of-the-art benchmark. We also observe that
DI* can improve the layout and enrich the colors of generated images.

摘要：<paragraph>在本文中，我們介紹了 Diff-Instruct*(DI*)，這是一種無數據方法，用於構建與人類偏好相符的一步式文本到圖像生成模型，同時保持生成高度逼真圖像的能力。
我們將人類偏好對齊構建為使用人類回饋的線上強化學習 (RLHF)，目標是最大化獎勵函數，同時規範生成器分佈以保持接近參考擴散過程。與依賴 KL 散度進行規範化的傳統 RLHF 方法不同，我們引入了一種新的基於分數的散度規範化，這導致了顯著更好的表現。儘管這種散度的直接計算仍然難以處理，但我們證明了我們可以通過推導一個等效但易於處理的損失函數來有效地計算其\emph{梯度}。值得注意的是，以 Stable Diffusion V1.5 作為參考擴散模型，DI* 以很大幅度優於\emph{所有}先前領先的模型。當使用 0.6B PixelArt-$\alpha$ 模型作為參考擴散時，DI* 僅通過單一生成步驟就達到了 6.30 的美學分數和 1.31 的圖像獎勵的新紀錄，幾乎是類似大小的其餘模型分數的兩倍。它還達到了 28.70 的 HPSv2 分數，樹立了新的最先進基準。我們還觀察到，DI* 可以改善生成的圖像的佈局並豐富其色彩。</paragraph>

##### **Active Causal Structure Learning with Latent Variables: Towards Learning to Detour in Autonomous Robots**
2410.20894v1 by Pablo de los Riscos, Fernando Corbacho

Artificial General Intelligence (AGI) Agents and Robots must be able to cope
with everchanging environments and tasks. They must be able to actively
construct new internal causal models of their interactions with the environment
when new structural changes take place in the environment. Thus, we claim that
active causal structure learning with latent variables (ACSLWL) is a necessary
component to build AGI agents and robots. This paper describes how a complex
planning and expectation-based detour behavior can be learned by ACSLWL when,
unexpectedly, and for the first time, the simulated robot encounters a sort of
transparent barrier in its pathway towards its target. ACSWL consists of acting
in the environment, discovering new causal relations, constructing new causal
models, exploiting the causal models to maximize its expected utility,
detecting possible latent variables when unexpected observations occur, and
constructing new structures-internal causal models and optimal estimation of
the associated parameters, to be able to cope efficiently with the new
encountered situations. That is, the agent must be able to construct new causal
internal models that transform a previously unexpected and inefficient
(sub-optimal) situation, into a predictable situation with an optimal operating
plan.

摘要：人工通用智能 (AGI) 代理和機器人必須能夠應對不斷變化的環境和任務。當環境中發生新的結構性變化時，它們必須能夠主動構建與環境互動的新內部因果模型。因此，我們聲稱帶有潛在變量的主動因果結構學習 (ACSLWL) 是構建 AGI 代理和機器人的必要組成部分。本文描述了當模擬機器人在通往目標的途中意外地第一次遇到一種透明障礙物時，ACSLWL 如何學習複雜的規劃和基於預期的繞行行為。ACSLWL 包含在環境中行動、發現新的因果關係、構建新的因果模型、利用因果模型最大化其預期效用、在出現意外觀察結果時檢測可能的潛在變量，以及構建新的結構——內部因果模型和關聯參數的最優估計，以便能夠有效應對新遇到的情況。也就是說，代理必須能夠構建新的因果內部模型，將以前意外且低效（次優）的情況轉變為具有最佳運作計畫的可預測情況。

##### **AutoRAG: Automated Framework for optimization of Retrieval Augmented Generation Pipeline**
2410.20878v1 by Dongkyu Kim, Byoungwook Kim, Donggeon Han, Matouš Eibich

Using LLMs (Large Language Models) in conjunction with external documents has
made RAG (Retrieval-Augmented Generation) an essential technology. Numerous
techniques and modules for RAG are being researched, but their performance can
vary across different datasets. Finding RAG modules that perform well on
specific datasets is challenging. In this paper, we propose the AutoRAG
framework, which automatically identifies suitable RAG modules for a given
dataset. AutoRAG explores and approximates the optimal combination of RAG
modules for the dataset. Additionally, we share the results of optimizing a
dataset using AutoRAG. All experimental results and data are publicly available
and can be accessed through our GitHub repository
https://github.com/Marker-Inc-Korea/AutoRAG_ARAGOG_Paper .

摘要：使用 LLMs（大型语言模型）与外部文件结合已使 RAG（检索增强生成）成为一项基本技术。目前正在研究用于 RAG 的众多技术和模块，但它们在不同数据集上的性能可能会有所不同。寻找在特定数据集上表现良好的 RAG 模块具有挑战性。在本文中，我们提出了 AutoRAG 框架，该框架可自动识别适用于给定数据集的合适的 RAG 模块。AutoRAG 探索并逼近了 RAG 模块在数据集上的最佳组合。此外，我们分享了使用 AutoRAG 优化数据集的结果。所有实验结果和数据都是公开的，并且可以通过我们的 GitHub 存储库 https://github.com/Marker-Inc-Korea/AutoRAG_ARAGOG_Paper 访问。

##### **Explainability in AI Based Applications: A Framework for Comparing Different Techniques**
2410.20873v1 by Arne Grobrugge, Nidhi Mishra, Johannes Jakubik, Gerhard Satzger

The integration of artificial intelligence into business processes has
significantly enhanced decision-making capabilities across various industries
such as finance, healthcare, and retail. However, explaining the decisions made
by these AI systems poses a significant challenge due to the opaque nature of
recent deep learning models, which typically function as black boxes. To
address this opacity, a multitude of explainability techniques have emerged.
However, in practical business applications, the challenge lies in selecting an
appropriate explainability method that balances comprehensibility with
accuracy. This paper addresses the practical need of understanding differences
in the output of explainability techniques by proposing a novel method for the
assessment of the agreement of different explainability techniques. Based on
our proposed methods, we provide a comprehensive comparative analysis of six
leading explainability techniques to help guiding the selection of such
techniques in practice. Our proposed general-purpose method is evaluated on top
of one of the most popular deep learning architectures, the Vision Transformer
model, which is frequently employed in business applications. Notably, we
propose a novel metric to measure the agreement of explainability techniques
that can be interpreted visually. By providing a practical framework for
understanding the agreement of diverse explainability techniques, our research
aims to facilitate the broader integration of interpretable AI systems in
business applications.

摘要：人工智能整合到商業流程中，大幅提升了各產業，如金融、醫療保健和零售業的決策能力。然而，由於近期深度學習模型不透明的本質，解釋這些 AI 系統做出的決策是一項重大挑戰，它們通常作為黑盒子運作。為了解決這種不透明性，出現了許多可解釋性技術。然而，在實際的商業應用中，挑戰在於選擇一種適當的可解釋性方法，在可理解性和準確性之間取得平衡。本文探討了理解可解釋性技術輸出差異的實際需求，提出了一種新方法來評估不同可解釋性技術的一致性。根據我們提出的方法，我們提供了六種領先的可解釋性技術的全面比較分析，以幫助指導在實務中選擇此類技術。我們提出的通用方法是在最受歡迎的深度學習架構之一 Vision Transformer 模型上進行評估，該模型經常在商業應用中使用。值得注意的是，我們提出了一種新的指標來衡量可解釋性技術的一致性，可以直觀地解釋。透過提供一個實用的架構來了解不同可解釋性技術的一致性，我們的研究旨在促進可解釋 AI 系統在商業應用中的更廣泛整合。

##### **Reward Modeling with Weak Supervision for Language Models**
2410.20869v1 by Ben Hauptvogel, Malte Ostendorff, Georg Rehm, Sebastian Möller

Recent advancements in large language models (LLMs) have led to their
increased application across various tasks, with reinforcement learning from
human feedback (RLHF) being a crucial part of their training to align responses
with user intentions. In the RLHF process, a reward model is trained using
responses preferences determined by human labelers or AI systems, which then
refines the LLM through reinforcement learning. This work introduces weak
supervision as a strategy to extend RLHF datasets and enhance reward model
performance. Weak supervision employs noisy or imprecise data labeling,
reducing reliance on expensive manually labeled data. By analyzing RLHF
datasets to identify heuristics that correlate with response preference, we
wrote simple labeling functions and then calibrated a label model to weakly
annotate unlabeled data. Our evaluation show that while weak supervision
significantly benefits smaller datasets by improving reward model performance,
its effectiveness decreases with larger, originally labeled datasets.
Additionally, using an LLM to generate and then weakly label responses offers a
promising method for extending preference data.

摘要：大型語言模型 (LLM) 的最新進展導致它們在各種任務中的應用增加，而人類回饋的強化學習 (RLHF) 是它們訓練中的關鍵部分，以將回應與使用者意圖保持一致。在 RLHF 過程中，使用由人類標籤者或 AI 系統決定的回應偏好來訓練獎勵模型，然後透過強化學習來優化 LLM。這項工作引入了弱監督，作為擴充 RLHF 資料集和增強獎勵模型效能的策略。弱監督採用有雜訊或不精確的資料標籤，減少對昂貴的手動標籤資料的依賴。透過分析 RLHF 資料集以找出與回應偏好相關的啟發法，我們撰寫了簡單的標籤函數，然後校準標籤模型以弱標記未標籤的資料。我們的評估顯示，雖然弱監督透過改善獎勵模型效能顯著受益於較小的資料集，但其有效性會隨著原本標籤的較大資料集而降低。此外，使用 LLM 來產生然後弱標記回應提供了一個有前途的方法來擴充偏好資料。

##### **Strada-LLM: Graph LLM for traffic prediction**
2410.20856v1 by Seyed Mohamad Moghadas, Yangxintong Lyu, Bruno Cornelis, Alexandre Alahi, Adrian Munteanu

Traffic prediction is a vital component of intelligent transportation
systems. By reasoning about traffic patterns in both the spatial and temporal
dimensions, accurate and interpretable predictions can be provided. A
considerable challenge in traffic prediction lies in handling the diverse data
distributions caused by vastly different traffic conditions occurring at
different locations. LLMs have been a dominant solution due to their remarkable
capacity to adapt to new datasets with very few labeled data samples, i.e.,
few-shot adaptability. However, existing forecasting techniques mainly focus on
extracting local graph information and forming a text-like prompt, leaving LLM-
based traffic prediction an open problem. This work presents a probabilistic
LLM for traffic forecasting with three highlights. We propose a graph-aware LLM
for traffic prediction that considers proximal traffic information.
Specifically, by considering the traffic of neighboring nodes as covariates,
our model outperforms the corresponding time-series LLM. Furthermore, we adopt
a lightweight approach for efficient domain adaptation when facing new data
distributions in few-shot fashion. The comparative experiment demonstrates the
proposed method outperforms the state-of-the-art LLM-based methods and the
traditional GNN- based supervised approaches. Furthermore, Strada-LLM can be
easily adapted to different LLM backbones without a noticeable performance
drop.

摘要：交通預測是智慧運輸系統的重要組成部分。透過對時空維度的交通模式進行推理，可以提供準確且可解釋的預測。交通預測中的一項重大挑戰在於處理由不同地點發生的截然不同的交通狀況所造成的各種資料分佈。由於 LLM 具備以極少數標籤資料樣本適應新資料集的顯著能力，即少樣本適應性，因此已成為主流的解決方案。然而，現有的預測技術主要著重於擷取局部圖形資訊並形成類似文字的提示，讓基於 LLM 的交通預測成為一個未解決的問題。本研究提出一個機率 LLM，用於交通預測，並具有三大亮點。我們提出一個圖形感知 LLM，用於考慮鄰近交通資訊的交通預測。具體來說，我們的模型透過將鄰近節點的交通視為協變數，表現優於對應的時間序列 LLM。此外，在面對少樣本樣式的全新資料分佈時，我們採用一種輕量級方法進行有效的領域適應。比較實驗證明，所提出的方法優於最先進的基於 LLM 的方法和傳統的基於 GNN 的監督式方法。此外，Strada-LLM 可以輕鬆地適應不同的 LLM 主幹，而不會顯著降低效能。

##### **Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms**
2410.20848v1 by He Yu, Jing Liu

Designing optimization approaches, whether heuristic or meta-heuristic,
usually demands extensive manual intervention and has difficulty generalizing
across diverse problem domains. The combination of Large Language Models (LLMs)
and Evolutionary Algorithms (EAs) offers a promising new approach to overcome
these limitations and make optimization more automated. In this setup, LLMs act
as dynamic agents that can generate, refine, and interpret optimization
strategies, while EAs efficiently explore complex solution spaces through
evolutionary operators. Since this synergy enables a more efficient and
creative search process, we first conduct an extensive review of recent
research on the application of LLMs in optimization. We focus on LLMs' dual
functionality as solution generators and algorithm designers. Then, we
summarize the common and valuable designs in existing work and propose a novel
LLM-EA paradigm for automated optimization. Furthermore, centered on this
paradigm, we conduct an in-depth analysis of innovative methods for three key
components: individual representation, variation operators, and fitness
evaluation. We address challenges related to heuristic generation and solution
exploration, especially from the LLM prompts' perspective. Our systematic
review and thorough analysis of the paradigm can assist researchers in better
understanding the current research and promoting the development of combining
LLMs with EAs for automated optimization.

摘要：<paragraph>無論是啟發式還是元啟發式，設計最佳化方法通常需要廣泛的人工介入，並且難以概括到不同的問題領域。大型語言模型 (LLM) 和演化演算法 (EA) 的結合提供了一種有希望的新方法，可以克服這些限制並使最佳化更自動化。在此設定中，LLM 作為動態代理，可以產生、精煉和詮釋最佳化策略，而 EA 則透過演化運算子有效地探索複雜的解空間。由於這種協同作用能使搜尋過程更有效率和有創造力，我們首先對最近在最佳化中應用 LLM 的研究進行廣泛的回顧。我們專注於 LLM 作為解生成器和演算法設計者的雙重功能。然後，我們總結現有工作中常見且有價值的設計，並提出一個新的 LLM-EA 範例，用於自動最佳化。此外，以這個範例為中心，我們對三個關鍵組成部分進行深入分析：個體表示、變異運算子，以及適應度評估。我們從 LLM 提示的角度，探討與啟發式產生和解探索相關的挑戰。我們對範例的系統性回顧和透徹分析，可以協助研究人員更了解目前的的研究，並促進結合 LLM 和 EA 進行自動最佳化的發展。</paragraph>

##### **Generative Simulations of The Solar Corona Evolution With Denoising Diffusion : Proof of Concept**
2410.20843v1 by Grégoire Francisco, Francesco Pio Ramunno, Manolis K. Georgoulis, João Fernandes, Teresa Barata, Dario Del Moro

The solar magnetized corona is responsible for various manifestations with a
space weather impact, such as flares, coronal mass ejections (CMEs) and,
naturally, the solar wind. Modeling the corona's dynamics and evolution is
therefore critical for improving our ability to predict space weather In this
work, we demonstrate that generative deep learning methods, such as Denoising
Diffusion Probabilistic Models (DDPM), can be successfully applied to simulate
future evolutions of the corona as observed in Extreme Ultraviolet (EUV)
wavelengths. Our model takes a 12-hour video of an Active Region (AR) as input
and simulate the potential evolution of the AR over the subsequent 12 hours,
with a time-resolution of two hours. We propose a light UNet backbone
architecture adapted to our problem by adding 1D temporal convolutions after
each classical 2D spatial ones, and spatio-temporal attention in the bottleneck
part. The model not only produce visually realistic outputs but also captures
the inherent stochasticity of the system's evolution. Notably, the simulations
enable the generation of reliable confidence intervals for key predictive
metrics such as the EUV peak flux and fluence of the ARs, paving the way for
probabilistic and interpretable space weather forecasting. Future studies will
focus on shorter forecasting horizons with increased spatial and temporal
resolution, aiming at reducing the uncertainty of the simulations and providing
practical applications for space weather forecasting. The code used for this
study is available at the following link:
https://github.com/gfrancisco20/video_diffusion

摘要：太陽磁化電暈會造成各種與太空天氣影響有關的現象，例如耀斑、日冕質量拋射（CME）以及當然的太陽風。因此，模擬電暈的動力和演化對於提升我們預測太空天氣的能力至關重要。在這項工作中，我們證明了生成式深度學習方法（例如去噪擴散機率模型 (DDPM)）可以成功應用於模擬極紫外線 (EUV) 波長中觀測到的電暈未來演化。我們的模型以主動區 (AR) 的 12 小時影片作為輸入，並模擬 AR 在後續 12 小時內的潛在演化，時間解析度為兩小時。我們提出一個輕量級 UNet 主幹架構，透過在每個傳統 2D 空間卷積後加入 1D 時間卷積，以及在瓶頸部分加入時空注意力，以適應我們的問題。該模型不僅產生視覺上逼真的輸出，還能捕捉系統演化的內在隨機性。值得注意的是，這些模擬能為關鍵預測指標（例如 AR 的 EUV 峰值通量和注量）產生可靠的信心區間，為機率性和可解釋的太空天氣預報鋪路。未來的研究將專注於縮短預測範圍，同時提高時空解析度，目標是降低模擬的不確定性，並為太空天氣預報提供實際應用。本研究使用的程式碼可在以下連結取得：
https://github.com/gfrancisco20/video_diffusion

##### **A Simple Yet Effective Corpus Construction Framework for Indonesian Grammatical Error Correction**
2410.20838v1 by Nankai Lin, Meiyu Zeng, Wentao Huang, Shengyi Jiang, Lixian Xiao, Aimin Yang

Currently, the majority of research in grammatical error correction (GEC) is
concentrated on universal languages, such as English and Chinese. Many
low-resource languages lack accessible evaluation corpora. How to efficiently
construct high-quality evaluation corpora for GEC in low-resource languages has
become a significant challenge. To fill these gaps, in this paper, we present a
framework for constructing GEC corpora. Specifically, we focus on Indonesian as
our research language and construct an evaluation corpus for Indonesian GEC
using the proposed framework, addressing the limitations of existing evaluation
corpora in Indonesian. Furthermore, we investigate the feasibility of utilizing
existing large language models (LLMs), such as GPT-3.5-Turbo and GPT-4, to
streamline corpus annotation efforts in GEC tasks. The results demonstrate
significant potential for enhancing the performance of LLMs in low-resource
language settings. Our code and corpus can be obtained from
https://github.com/GKLMIP/GEC-Construction-Framework.

摘要：目前，語法錯誤修正 (GEC) 的大多數研究都集中在通用語言，例如英語和中文。許多低資源語言缺乏可存取的評量語料庫。如何有效建構低資源語言中 GEC 的高品質評量語料庫已成為一項重大挑戰。為了填補這些空白，我們在本文中提出了一個建構 GEC 語料庫的架構。具體來說，我們專注於印尼語作為我們的研究語言，並使用所提出的架構建構一個印尼語 GEC 評量語料庫，解決印尼語中現有評量語料庫的限制。此外，我們探討了利用現有的大型語言模型 (LLM)，例如 GPT-3.5-Turbo 和 GPT-4，以簡化 GEC 任務中的語料庫註解工作的可行性。結果證明了提高低資源語言設定中 LLM 效能的顯著潛力。我們的程式碼和語料庫可從 https://github.com/GKLMIP/GEC-Construction-Framework 取得。

##### **LLMs are Biased Evaluators But Not Biased for Retrieval Augmented Generation**
2410.20833v1 by Yen-Shan Chen, Jing Jin, Peng-Ting Kuo, Chao-Wei Huang, Yun-Nung Chen

Recent studies have demonstrated that large language models (LLMs) exhibit
significant biases in evaluation tasks, particularly in preferentially rating
and favoring self-generated content. However, the extent to which this bias
manifests in fact-oriented tasks, especially within retrieval-augmented
generation (RAG) frameworks-where keyword extraction and factual accuracy take
precedence over stylistic elements-remains unclear. Our study addresses this
knowledge gap by simulating two critical phases of the RAG framework. In the
first phase, we access the suitability of human-authored versus model-generated
passages, emulating the pointwise reranking process. The second phase involves
conducting pairwise reading comprehension tests to simulate the generation
process. Contrary to previous findings indicating a self-preference in rating
tasks, our results reveal no significant self-preference effect in RAG
frameworks. Instead, we observe that factual accuracy significantly influences
LLMs' output, even in the absence of prior knowledge. Our research contributes
to the ongoing discourse on LLM biases and their implications for RAG-based
system, offering insights that may inform the development of more robust and
unbiased LLM systems.

摘要：<paragraph>最近的研究表明，大型語言模型 (LLM) 在評估任務中表現出顯著的偏見，特別是在優先評分和偏好自生成內容方面。然而，這種偏見在面向事實的任務中表現出的程度，特別是在檢索增強生成 (RAG) 框架中，其中關鍵字提取和事實準確性優先於文體元素，仍然不清楚。我們的研究模擬了 RAG 框架的兩個關鍵階段，以解決這一知識差距。在第一階段，我們評估了人類撰寫的段落與模型生成的段落之間的適用性，模擬了逐點重新排序的過程。第二階段涉及執行成對閱讀理解測試，以模擬生成過程。與之前表明在評分任務中存在自我偏好的研究結果相反，我們的結果表明 RAG 框架中沒有顯著的自我偏好效應。相反，我們觀察到，即使在沒有先驗知識的情況下，事實準確性也會顯著影響 LLM 的輸出。我們的研究有助於持續討論 LLM 偏見及其對基於 RAG 的系統的影響，提供可能有助於開發更健壯且無偏見的 LLM 系統的見解。</paragraph>

##### **ADLM -- stega: A Universal Adaptive Token Selection Algorithm for Improving Steganographic Text Quality via Information Entropy**
2410.20825v1 by Zezheng Qin, Congcong Sun, Taiyi He, Yuke He, Azizol Abdullah, Normalia Samian, Nuur Alifah Roslan

In the context of widespread global information sharing, information security
and privacy protection have become focal points. Steganographic systems enhance
information security by embedding confidential information into public
carriers; however, existing generative text steganography methods face
challenges in handling the long-tail distribution of candidate word pools,
which impacts the imperceptibility of steganographic information. This paper
proposes a quality control theory for steganographic text generation based on
information entropy constraints, exploring the relationship between the
imperceptibility of steganographic texts and information entropy. By
controlling the information entropy of the candidate word pool within a
specific range, we optimize the imperceptibility of the steganographic text. We
establish upper and lower bounds for information entropy and introduce an
adaptive truncation method to balance semantic coherence and lexical diversity.
Experimental results demonstrate that reasonably controlling the candidate pool
size and information entropy thresholds significantly enhances the quality and
detection resistance of steganographic texts, showcasing broad application
potential in the field of natural language processing.

摘要：在全球資訊共享普遍化的背景下，資訊安全與隱私保護成為關注焦點。隱寫系統透過將機密資訊嵌入公開載體中，提升資訊安全性；然而，現有的生成式文字隱寫技術在處理候選詞彙池的長尾分佈時面臨挑戰，影響隱寫資訊的不可察覺性。本文提出基於資訊熵約束的隱寫文本生成品質控制理論，探討隱寫文本不可察覺性與資訊熵的關係。透過控制候選詞彙池的資訊熵在特定範圍內，我們優化隱寫文本的不可察覺性。我們建立資訊熵的上限和下限，並引入自適應截斷方法，以平衡語義一致性和詞彙多樣性。實驗結果表明，合理控制候選詞彙池大小和資訊熵閾值，可以顯著提升隱寫文本的品質和抗檢測性，在自然語言處理領域展現廣泛的應用潛力。

##### **The Zeno's Paradox of `Low-Resource' Languages**
2410.20817v1 by Hellina Hailu Nigatu, Atnafu Lambebo Tonja, Benjamin Rosman, Thamar Solorio, Monojit Choudhury

The disparity in the languages commonly studied in Natural Language
Processing (NLP) is typically reflected by referring to languages as low vs
high-resourced. However, there is limited consensus on what exactly qualifies
as a `low-resource language.' To understand how NLP papers define and study
`low resource' languages, we qualitatively analyzed 150 papers from the ACL
Anthology and popular speech-processing conferences that mention the keyword
`low-resource.' Based on our analysis, we show how several interacting axes
contribute to `low-resourcedness' of a language and why that makes it difficult
to track progress for each individual language. We hope our work (1) elicits
explicit definitions of the terminology when it is used in papers and (2)
provides grounding for the different axes to consider when connoting a language
as low-resource.

摘要：在自然語言處理 (NLP) 中，常見研究語言的差異通常反映在語言被稱為低資源或高資源。然而，對於什麼才算是「低資源語言」的資格，並沒有明確的共識。為了了解 NLP 論文如何定義和研究「低資源」語言，我們從 ACL Anthology 和熱門語音處理研討會中，定性分析了 150 篇提到關鍵字「低資源」的論文。根據我們的分析，我們展示了幾個相互作用的軸線如何影響語言的「低資源性」，以及為什麼這使得難以追蹤每種個別語言的進度。我們希望我們的研究 (1) 引起明確定義術語的重視，當它用於論文中時，以及 (2) 提供不同軸線的基礎，以便在指稱語言為低資源時考慮。

##### **NewTerm: Benchmarking Real-Time New Terms for Large Language Models with Annual Updates**
2410.20814v1 by Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Min Zhang, Zhaopeng Tu

Despite their remarkable abilities in various tasks, large language models
(LLMs) still struggle with real-time information (e.g., new facts and terms)
due to the knowledge cutoff in their development process. However, existing
benchmarks focus on outdated content and limited fields, facing difficulties in
real-time updating and leaving new terms unexplored. To address this problem,
we propose an adaptive benchmark, NewTerm, for real-time evaluation of new
terms. We design a highly automated construction method to ensure high-quality
benchmark construction with minimal human effort, allowing flexible updates for
real-time information. Empirical results on various LLMs demonstrate over 20%
performance reduction caused by new terms. Additionally, while updates to the
knowledge cutoff of LLMs can cover some of the new terms, they are unable to
generalize to more distant new terms. We also analyze which types of terms are
more challenging and why LLMs struggle with new terms, paving the way for
future research. Finally, we construct NewTerm 2022 and 2023 to evaluate the
new terms updated each year and will continue updating annually. The benchmark
and codes can be found at https://github.com/hexuandeng/NewTerm.

摘要：儘管大型語言模型 (LLM) 在各種任務中展現出驚人的能力，但由於開發過程中知識的截止，它們在處理即時資訊（例如新的事實和術語）時仍有困難。然而，現有的基準側重於過時的內容和有限的領域，在即時更新方面面臨困難，且未探索新的術語。為了解決這個問題，我們提出了 NewTerm，這是一個用於即時評估新術語的自適應基準。我們設計了一種高度自動化的建構方法，以確保高品質的基準建構，同時將人力降至最低，並允許對即時資訊進行彈性更新。在各種 LLM 上的實證結果顯示，新術語導致效能降低超過 20%。此外，儘管更新 LLM 的知識截止可以涵蓋一些新術語，但它們無法概化到更遙遠的新術語。我們也分析了哪些類型的術語更具挑戰性，以及 LLM 為何難以處理新術語，為未來的研究鋪路。最後，我們建構了 NewTerm 2022 和 2023 來評估每年更新的新術語，並將持續每年更新。基準和程式碼可以在 https://github.com/hexuandeng/NewTerm 找到。

##### **Bridging the Gap between Expert and Language Models: Concept-guided Chess Commentary Generation and Evaluation**
2410.20811v1 by Jaechang Kim, Jinmin Goh, Inseok Hwang, Jaewoong Cho, Jungseul Ok

Deep learning-based expert models have reached superhuman performance in
decision-making domains such as chess and Go. However, it is under-explored to
explain or comment on given decisions although it is important for human
education and model explainability. The outputs of expert models are accurate,
but yet difficult to interpret for humans. On the other hand, large language
models (LLMs) produce fluent commentary but are prone to hallucinations due to
their limited decision-making capabilities. To bridge this gap between expert
models and LLMs, we focus on chess commentary as a representative case of
explaining complex decision-making processes through language and address both
the generation and evaluation of commentary. We introduce Concept-guided Chess
Commentary generation (CCC) for producing commentary and GPT-based Chess
Commentary Evaluation (GCC-Eval) for assessing it. CCC integrates the
decision-making strengths of expert models with the linguistic fluency of LLMs
through prioritized, concept-based explanations. GCC-Eval leverages expert
knowledge to evaluate chess commentary based on informativeness and linguistic
quality. Experimental results, validated by both human judges and GCC-Eval,
demonstrate that CCC generates commentary that is accurate, informative, and
fluent.

摘要：基於深度學習的專家模型在決策領域中已達到超人類的表現，例如西洋棋和圍棋。然而，儘管對人類教育和模型可解釋性來說很重要，但解釋或評論既定決策卻鮮少被探討。專家模型的輸出很準確，但人類卻難以理解。另一方面，大型語言模型 (LLM) 會產生流利的評論，但由於決策能力有限，容易產生幻覺。為了彌合專家模型和 LLM 之間的差距，我們專注於西洋棋評論，作為透過語言解釋複雜決策過程的代表性案例，並探討評論的產生和評估。我們引入了概念引導西洋棋評論產生 (CCC)，用於產生評論，以及基於 GPT 的西洋棋評論評估 (GCC-Eval)，用於評估評論。CCC 透過優先、基於概念的解釋，整合了專家模型的決策優勢與 LLM 的語言流暢性。GCC-Eval 利用專家知識，根據資訊性和語言品質來評估西洋棋評論。由人類評審和 GCC-Eval 驗證的實驗結果表明，CCC 產生的評論準確、有資訊且流暢。

##### **Rephrasing natural text data with different languages and quality levels for Large Language Model pre-training**
2410.20796v1 by Michael Pieler, Marco Bellagente, Hannah Teufel, Duy Phung, Nathan Cooper, Jonathan Tow, Paulo Rocha, Reshinth Adithyan, Zaid Alyafeai, Nikhil Pinnaparaju, Maksym Zhuravinskyi, Carlos Riquelme

Recently published work on rephrasing natural text data for pre-training LLMs
has shown promising results when combining the original dataset with the
synthetically rephrased data. We build upon previous work by replicating
existing results on C4 and extending them with our optimized rephrasing
pipeline to the English, German, Italian, and Spanish Oscar subsets of
CulturaX. Our pipeline leads to increased performance on standard evaluation
benchmarks in both the mono- and multilingual setup. In addition, we provide a
detailed study of our pipeline, investigating the choice of the base dataset
and LLM for the rephrasing, as well as the relationship between the model size
and the performance after pre-training. By exploring data with different
perceived quality levels, we show that gains decrease with higher quality.
Furthermore, we find the difference in performance between model families to be
bigger than between different model sizes. This highlights the necessity for
detailed tests before choosing an LLM to rephrase large amounts of data.
Moreover, we investigate the effect of pre-training with synthetic data on
supervised fine-tuning. Here, we find increasing but inconclusive results that
highly depend on the used benchmark. These results (again) highlight the need
for better benchmarking setups. In summary, we show that rephrasing
multilingual and low-quality data is a very promising direction to extend LLM
pre-training data.

摘要：<paragraph>最近发表的关于为 LLM 预训练重新表述自然文本数据的著作在将原始数据集与合成重新表述的数据相结合时显示出有希望的结果。我们通过复制 C4 上的现有结果并将其扩展到 CulturaX 的英语、德语、意大利语和西班牙语 Oscar 子集，以优化我们的重新表述管道，从而建立在以前的工作之上。我们的管道提高了单语和多语设置中标准评估基准的性能。此外，我们提供了管道详细研究，调查了重新表述的基础数据集和 LLM 的选择，以及模型大小与预训练后性能之间的关系。通过探索具有不同感知质量水平的数据，我们发现增益会随着质量的提高而降低。此外，我们发现模型系列之间的性能差异大于不同模型大小之间的差异。这突出了在选择 LLM 重新表述大量数据之前进行详细测试的必要性。此外，我们调查了使用合成数据进行预训练对监督微调的影响。在这里，我们发现增加但尚无定论的结果高度依赖于所使用的基准。这些结果（再次）强调了对更好的基准设置的需求。总之，我们表明，重新表述多语言和低质量数据是扩展 LLM 预训练数据的非常有希望的方向。</paragraph>

##### **Deep Learning for Medical Text Processing: BERT Model Fine-Tuning and Comparative Study**
2410.20792v1 by Jiacheng Hu, Yiru Cang, Guiran Liu, Meiqi Wang, Weijie He, Runyuan Bao

This paper proposes a medical literature summary generation method based on
the BERT model to address the challenges brought by the current explosion of
medical information. By fine-tuning and optimizing the BERT model, we develop
an efficient summary generation system that can quickly extract key information
from medical literature and generate coherent, accurate summaries. In the
experiment, we compared various models, including Seq-Seq, Attention,
Transformer, and BERT, and demonstrated that the improved BERT model offers
significant advantages in the Rouge and Recall metrics. Furthermore, the
results of this study highlight the potential of knowledge distillation
techniques to further enhance model performance. The system has demonstrated
strong versatility and efficiency in practical applications, offering a
reliable tool for the rapid screening and analysis of medical literature.

摘要：這篇論文提出了一種基於 BERT 模型的醫學文獻摘要生成方法，以應對當前醫學資訊爆炸帶來的挑戰。透過微調和最佳化 BERT 模型，我們開發了一個高效的摘要生成系統，可以快速從醫學文獻中萃取出關鍵資訊，並生成條理分明、準確的摘要。在實驗中，我們比較了包括 Seq-Seq、Attention、Transformer 和 BERT 在內的各種模型，並證明改良後的 BERT 模型在 Rouge 和 Recall 評量中提供了顯著的優勢。此外，這項研究的結果突顯了知識蒸餾技術進一步提升模型效能的潛力。該系統在實際應用中展現出強大的多功能性和效率，為快速篩選和分析醫學文獻提供了一個可靠的工具。

##### **From Cool Demos to Production-Ready FMware: Core Challenges and a Technology Roadmap**
2410.20791v1 by Gopi Krishnan Rajbahadur, Gustavo A. Oliva, Dayi Lin, Ahmed E. Hassan

The rapid expansion of foundation models (FMs), such as large language models
(LLMs), has given rise to FMware--software systems that integrate FMs as core
components. While building demonstration-level FMware is relatively
straightforward, transitioning to production-ready systems presents numerous
challenges, including reliability, high implementation costs, scalability, and
compliance with privacy regulations. This paper provides a thematic analysis of
the key obstacles in productionizing FMware, synthesized from industry
experience and diverse data sources, including hands-on involvement in the Open
Platform for Enterprise AI (OPEA) and FMware lifecycle engineering. We identify
critical issues in FM selection, data and model alignment, prompt engineering,
agent orchestration, system testing, and deployment, alongside cross-cutting
concerns such as memory management, observability, and feedback integration. We
discuss needed technologies and strategies to address these challenges and
offer guidance on how to enable the transition from demonstration systems to
scalable, production-ready FMware solutions. Our findings underscore the
importance of continued research and multi-industry collaboration to advance
the development of production-ready FMware.

摘要：基礎模型（FM）的快速擴展，例如大型語言模型（LLM），催生了 FMware，一種將 FM 整合為核心組件的軟體系統。雖然建置示範等級的 FMware 相對簡單，但轉換至生產就緒系統會產生許多挑戰，包括可靠性、高實作成本、可擴充性，以及符合隱私法規。本文提供主題分析，說明生產 FMware 的主要障礙，這些障礙綜合自產業經驗和各種資料來源，包括親自參與企業 AI 開放平台（OPEA）和 FMware 生命周期工程。我們找出 FM 選擇、資料和模型比對、提示工程、代理人編排、系統測試和部署中的關鍵問題，以及跨領域的疑慮，例如記憶體管理、可觀察性，以及回饋整合。我們討論解決這些挑戰所需技術和策略，並提供如何促成從示範系統轉換至可擴充、生產就緒 FMware 解決方案的指導方針。我們的發現強調持續研究和跨產業合作對於推進生產就緒 FMware 的開發至關重要。

##### **SCULPT: Systematic Tuning of Long Prompts**
2410.20788v1 by Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu Khandelwal, Bishal Santra, Parag Agrawal, Manish Gupta

As large language models become increasingly central to solving complex
tasks, the challenge of optimizing long, unstructured prompts has become
critical. Existing optimization techniques often struggle to effectively handle
such prompts, leading to suboptimal performance. We introduce SCULPT
(Systematic Tuning of Long Prompts), a novel framework that systematically
refines long prompts by structuring them hierarchically and applying an
iterative actor-critic mechanism. To enhance robustness and generalizability,
SCULPT utilizes two complementary feedback mechanisms: Preliminary Assessment,
which assesses the prompt's structure before execution, and Error Assessment,
which diagnoses and addresses errors post-execution. By aggregating feedback
from these mechanisms, SCULPT avoids overfitting and ensures consistent
improvements in performance. Our experimental results demonstrate significant
accuracy gains and enhanced robustness, particularly in handling erroneous and
misaligned prompts. SCULPT consistently outperforms existing approaches,
establishing itself as a scalable solution for optimizing long prompts across
diverse and real-world tasks.

摘要：隨著大型語言模型在解決複雜任務中扮演越來越重要的角色，最佳化長且非結構化提示的挑戰已變得至關重要。現有的最佳化技術通常難以有效處理此類提示，導致效能不佳。我們引進 SCULPT（長提示的系統化調整），一個新穎的架構，透過分層結構化長提示並應用反覆的 actor-critic 機制，系統化地改善長提示。為了增強穩健性和泛化能力，SCULPT 利用了兩種互補的回饋機制：預先評估，在執行前評估提示的結構，以及錯誤評估，在執行後診斷和處理錯誤。透過彙總來自這些機制的回饋，SCULPT 避免了過度擬合，並確保效能持續提升。我們的實驗結果證明了顯著的準確性提升和增強的穩健性，特別是在處理錯誤和未對齊提示時。SCULPT 持續優於現有方法，確立了其作為最佳化各種真實世界任務中的長提示的可擴充解決方案的地位。

##### **Graph-based Uncertainty Metrics for Long-form Language Model Outputs**
2410.20783v1 by Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto

Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities, but these systems are still known to
hallucinate, and granular uncertainty estimation for long-form LLM generations
remains challenging. In this work, we propose Graph Uncertainty -- which
represents the relationship between LLM generations and claims within them as a
bipartite graph and estimates the claim-level uncertainty with a family of
graph centrality metrics. Under this view, existing uncertainty estimation
methods based on the concept of self-consistency can be viewed as using degree
centrality as an uncertainty measure, and we show that more sophisticated
alternatives such as closeness centrality provide consistent gains at
claim-level uncertainty estimation. Moreover, we present uncertainty-aware
decoding techniques that leverage both the graph structure and uncertainty
estimates to improve the factuality of LLM generations by preserving only the
most reliable claims. Compared to existing methods, our graph-based uncertainty
metrics lead to an average of 6.8% relative gains on AUPRC across various
long-form generation settings, and our end-to-end system provides consistent
2-4% gains in factuality over existing decoding techniques while significantly
improving the informativeness of generated responses.

摘要：大型語言模型 (LLM) 的最新進展顯著提升了文字生成能力，但這些系統仍以產生幻覺著稱，而針對長篇 LLM 生成的細緻不確定性估計仍是一項挑戰。在這項工作中，我們提出圖形不確定性，它將 LLM 生成和其中的主張表示為二部圖，並使用一系列圖形中心性指標估計主張層級的不確定性。在此觀點下，現有的基於自洽性概念的不確定性估計方法可視為使用度量中心性作為不確定性指標，我們證明了更精密的替代方案（例如接近中心性）在主張層級不確定性估計中提供了穩定的增益。此外，我們提出了不確定性感知解碼技術，該技術利用圖形結構和不確定性估計來提升 LLM 生成的真實性，方法是僅保留最可靠的主張。與現有方法相比，我們的基於圖形的指標在各種長篇生成設定中平均提升了 AUPRC 的 6.8%，而我們的端到端系統在真實性方面提供了 2-4% 的穩定增益，同時顯著提升了生成回應的資訊性。

##### **Decoding Reading Goals from Eye Movements**
2410.20779v1 by Omer Shubi, Cfir Avraham Hadar, Yevgeni Berzak

Readers can have different goals with respect to the text they are reading.
Can these goals be decoded from the pattern of their eye movements over the
text? In this work, we examine for the first time whether it is possible to
decode two types of reading goals that are common in daily life: information
seeking and ordinary reading. Using large scale eye-tracking data, we apply to
this task a wide range of state-of-the-art models for eye movements and text
that cover different architectural and data representation strategies, and
further introduce a new model ensemble. We systematically evaluate these models
at three levels of generalization: new textual item, new participant, and the
combination of both. We find that eye movements contain highly valuable signals
for this task. We further perform an error analysis which builds on prior
empirical findings on differences between ordinary reading and information
seeking and leverages rich textual annotations. This analysis reveals key
properties of textual items and participant eye movements that contribute to
the difficulty of the task.

摘要：讀者對於他們正在閱讀的文本可能有不同的目標。
這些目標可以從他們在文本上的眼睛移動模式中解碼出來嗎？
在這項工作中，我們首次探討是否可以解碼日常生活中的兩種常見閱讀目標：
尋求資訊和一般閱讀。使用大規模的眼球追蹤數據，我們將各種最先進的眼球運動和文本模型應用於此任務，
這些模型涵蓋不同的架構和數據表示策略，並進一步引入新的模型集合。
我們在三個概括層級系統性地評估這些模型：新的文本項目、新的參與者，以及兩者的組合。
我們發現眼球運動包含了此任務中非常有價值的訊號。
我們進一步執行錯誤分析，該分析建立在先前關於一般閱讀和資訊尋求之間差異的經驗發現，
並利用豐富的文字註解。此分析揭示了文本項目和參與者眼球運動的主要屬性，
這些屬性會導致任務的難度。

##### **KD-LoRA: A Hybrid Approach to Efficient Fine-Tuning with LoRA and Knowledge Distillation**
2410.20777v1 by Rambod Azimi, Rishav Rishav, Marek Teichmann, Samira Ebrahimi Kahou

Large language models (LLMs) have demonstrated remarkable performance across
various downstream tasks. However, the high computational and memory
requirements of LLMs are a major bottleneck. To address this,
parameter-efficient fine-tuning (PEFT) methods such as low-rank adaptation
(LoRA) have been proposed to reduce computational costs while ensuring minimal
loss in performance. Additionally, knowledge distillation (KD) has been a
popular choice for obtaining compact student models from teacher models. In
this work, we present KD-LoRA, a novel fine-tuning method that combines LoRA
with KD. Our results demonstrate that KD-LoRA achieves performance comparable
to full fine-tuning (FFT) and LoRA while significantly reducing resource
requirements. Specifically, KD-LoRA retains 98% of LoRA's performance on the
GLUE benchmark, while being 40% more compact. Additionally, KD-LoRA reduces GPU
memory usage by 30% compared to LoRA, while decreasing inference time by 30%
compared to both FFT and LoRA. We evaluate KD-LoRA across three encoder-only
models: BERT, RoBERTa, and DeBERTaV3. Code is available at
https://github.com/rambodazimi/KD-LoRA.

摘要：大型語言模型 (LLM) 在各種下游任務中展示了非凡的表現。然而，LLM 的高計算和記憶體需求是一個主要的瓶頸。為了解決這個問題，已經提出參數有效微調 (PEFT) 方法，例如低秩適應 (LoRA)，以降低計算成本，同時確保效能的最小損失。此外，知識蒸餾 (KD) 一直是從教師模型中獲取精簡學生模型的熱門選擇。在這項工作中，我們提出了 KD-LoRA，一種結合 LoRA 與 KD 的新微調方法。我們的結果表明，KD-LoRA 達到了與完全微調 (FFT) 和 LoRA 相當的效能，同時顯著降低了資源需求。具體來說，KD-LoRA 在 GLUE 基準測試中保留了 LoRA 98% 的效能，同時精簡了 40%。此外，與 LoRA 相比，KD-LoRA 將 GPU 記憶體使用量減少了 30%，與 FFT 和 LoRA 相比，將推理時間減少了 30%。我們在三個僅編碼器模型：BERT、RoBERTa 和 DeBERTaV3 中評估了 KD-LoRA。程式碼可在 https://github.com/rambodazimi/KD-LoRA 取得。

##### **Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation**
2410.20774v1 by Dongryeol Lee, Yerin Hwang, Yongil Kim, Joonsuk Park, Kyomin Jung

In line with the principle of honesty, there has been a growing effort to
train large language models (LLMs) to generate outputs containing epistemic
markers. However, evaluation in the presence of epistemic markers has been
largely overlooked, raising a critical question: Could the use of epistemic
markers in LLM-generated outputs lead to unintended negative consequences? To
address this, we present EMBER, a benchmark designed to assess the robustness
of LLM-judges to epistemic markers in both single and pairwise evaluation
settings. Our findings, based on evaluations using EMBER, reveal that all
tested LLM-judges, including GPT-4o, show a notable lack of robustness in the
presence of epistemic markers. Specifically, we observe a negative bias toward
epistemic markers, with a stronger bias against markers expressing uncertainty.
This suggests that LLM-judges are influenced by the presence of these markers
and do not focus solely on the correctness of the content.

摘要：根據誠實的原則，已經有越來越多的努力訓練大型語言模型 (LLM) 來產生包含認識論標記的輸出。然而，在認識論標記存在的情況下進行評估已被廣泛忽視，這引發了一個關鍵問題：LLM 生成的輸出中使用認識論標記是否會導致意外的負面後果？為了解決這個問題，我們提出了 EMBER，這是一個基準，旨在評估 LLM 評審者在單一和成對評估設置中對認識論標記的穩健性。我們根據使用 EMBER 的評估結果發現，所有經過測試的 LLM 評審者，包括 GPT-4o，在認識論標記存在的情況下都表現出明顯的缺乏穩健性。具體來說，我們觀察到對認識論標記存在負面偏見，對表達不確定性的標記有更強的偏見。這表明 LLM 評審者受到這些標記的存在影響，並且不只關注內容的正確性。

##### **Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting**
2410.20772v1 by Bong Gyun Kang, Dongjun Lee, HyunGi Kim, DoHyun Chung

Sequence modeling faces challenges in capturing long-range dependencies
across diverse tasks. Recent linear and transformer-based forecasters have
shown superior performance in time series forecasting. However, they are
constrained by their inherent inability to effectively address long-range
dependencies in time series data, primarily due to using fixed-size inputs for
prediction. Furthermore, they typically sacrifice essential temporal
correlation among consecutive training samples by shuffling them into
mini-batches. To overcome these limitations, we introduce a fast and effective
Spectral Attention mechanism, which preserves temporal correlations among
samples and facilitates the handling of long-range information while
maintaining the base model structure. Spectral Attention preserves long-period
trends through a low-pass filter and facilitates gradient to flow between
samples. Spectral Attention can be seamlessly integrated into most sequence
models, allowing models with fixed-sized look-back windows to capture
long-range dependencies over thousands of steps. Through extensive experiments
on 11 real-world time series datasets using 7 recent forecasting models, we
consistently demonstrate the efficacy of our Spectral Attention mechanism,
achieving state-of-the-art results.

摘要：序列建模在跨越不同任務捕捉長程依賴性時面臨挑戰。最近的線性和Transformer預測器已在時間序列預測中展現出卓越的效能。然而，它們受到無法有效處理時間序列資料中長程依賴性的固有限制，這主要是因為使用固定大小的輸入進行預測。此外，它們通常會將連續的訓練樣本隨機分組成小批次，進而犧牲了這些樣本之間重要的時間關聯性。為了克服這些限制，我們引入了一種快速且有效的頻譜注意力機制，它保留了樣本之間的時間關聯性，並促進處理長程資訊，同時維護基礎模型結構。頻譜注意力透過低通濾波器保留長週期趨勢，並促進梯度在樣本之間流動。頻譜注意力可以無縫整合到大多數序列模型中，讓具有固定大小回顧視窗的模型能夠捕捉長達數千個步驟的長程依賴性。透過使用 7 個近期預測模型對 11 個真實世界時間序列資料集進行廣泛的實驗，我們持續證明了頻譜注意力機制的效能，並取得了最先進的成果。

##### **MrT5: Dynamic Token Merging for Efficient Byte-level Language Models**
2410.20771v1 by Julie Kallini, Shikhar Murty, Christopher D. Manning, Christopher Potts, Róbert Csordás

Models that rely on subword tokenization have significant drawbacks, such as
sensitivity to character-level noise like spelling errors and inconsistent
compression rates across different languages and scripts. While character- or
byte-level models like ByT5 attempt to address these concerns, they have not
gained widespread adoption -- processing raw byte streams without tokenization
results in significantly longer sequence lengths, making training and inference
inefficient. This work introduces MrT5 (MergeT5), a more efficient variant of
ByT5 that integrates a token deletion mechanism in its encoder to dynamically
shorten the input sequence length. After processing through a fixed number of
encoder layers, a learnt delete gate determines which tokens are to be removed
and which are to be retained for subsequent layers. MrT5 effectively ``merges''
critical information from deleted tokens into a more compact sequence,
leveraging contextual information from the remaining tokens. In continued
pre-training experiments, we find that MrT5 can achieve significant gains in
inference runtime with minimal effect on performance. When trained on English
text, MrT5 demonstrates the capability to transfer its deletion feature
zero-shot across several languages, with significant additional improvements
following multilingual training. Furthermore, MrT5 shows comparable accuracy to
ByT5 on downstream evaluations such as XNLI and character-level tasks while
reducing sequence lengths by up to 80%. Our approach presents a solution to the
practical limitations of existing byte-level models.

摘要：<paragraph>仰賴子字詞符號化的模型有顯著的缺點，例如
對拼寫錯誤等字元層級的雜訊敏感，以及不同語言和腳本的壓縮率不一致。雖然像 ByT5 這樣的字元或
位元組層級模型嘗試解決這些問題，但它們尚未廣泛採用——處理沒有符號化的原始位元組串流
會產生顯著更長的序列長度，使得訓練和推論效率低下。這項工作引入了 MrT5 (MergeT5)，一種更有效率的
ByT5 變體，它在編碼器中整合了一個代碼刪除機制，以動態縮短輸入序列長度。在經過固定數量的
編碼器層處理後，一個學習的刪除閘門會決定哪些代碼要移除，哪些要保留給後續的層。MrT5 有效地將
已刪除代碼中的關鍵資訊「合併」到一個更緊湊的序列中，利用剩餘代碼中的上下文資訊。在持續的
預訓練實驗中，我們發現 MrT5 可以顯著提升推論執行時間，對效能的影響很小。當在英文
文字上訓練時，MrT5 展示了將其刪除功能零次學習轉移到多種語言的能力，在多語言訓練後有顯著的額外進步。此外，MrT5 在後續評估（例如 XNLI 和字元層級任務）上顯示出與 ByT5 相當的準確度，同時
將序列長度減少了 80%。我們的做法為現有位元組層級模型的實際限制提供了解決方案。</paragraph>

##### **A Static and Dynamic Attention Framework for Multi Turn Dialogue Generation**
2410.20766v1 by Wei-Nan Zhang, Yiming Cui, Kaiyan Zhang, Yifa Wang, Qingfu Zhu, Lingzhi Li, Ting Liu

Recently, research on open domain dialogue systems have attracted extensive
interests of academic and industrial researchers. The goal of an open domain
dialogue system is to imitate humans in conversations. Previous works on single
turn conversation generation have greatly promoted the research of open domain
dialogue systems. However, understanding multiple single turn conversations is
not equal to the understanding of multi turn dialogue due to the coherent and
context dependent properties of human dialogue. Therefore, in open domain multi
turn dialogue generation, it is essential to modeling the contextual semantics
of the dialogue history, rather than only according to the last utterance.
Previous research had verified the effectiveness of the hierarchical recurrent
encoder-decoder framework on open domain multi turn dialogue generation.
However, using RNN-based model to hierarchically encoding the utterances to
obtain the representation of dialogue history still face the problem of a
vanishing gradient. To address this issue, in this paper, we proposed a static
and dynamic attention-based approach to model the dialogue history and then
generate open domain multi turn dialogue responses. Experimental results on
Ubuntu and Opensubtitles datasets verify the effectiveness of the proposed
static and dynamic attention-based approach on automatic and human evaluation
metrics in various experimental settings. Meanwhile, we also empirically verify
the performance of combining the static and dynamic attentions on open domain
multi turn dialogue generation.

摘要：<paragraph>最近，开放域对话系统研究引起了学术界和产业界研究人员的广泛兴趣。开放域对话系统的目标是模仿人类对话。之前在单轮对话生成方面的工作极大地促进了开放域对话系统研究。然而，由于人类对话的连贯性和上下文相关性，理解多轮单轮对话并不等于理解多轮对话。因此，在开放域多轮对话生成中，至关重要的是对对话历史的上下文语义进行建模，而不仅仅是根据最后的表述。先前的研究已经验证了分层递归编码器-解码器框架在开放域多轮对话生成中的有效性。然而，使用基于 RNN 的模型分层编码话语以获得对话历史的表征仍然面临梯度消失的问题。为了解决这个问题，在本文中，我们提出了一种基于静态和动态注意力的方法来对对话历史进行建模，然后生成开放域多轮对话响应。在 Ubuntu 和 Opensubtitles 数据集上的实验结果验证了所提出的基于静态和动态注意力的方法在各种实验设置中的自动和人工评估指标上的有效性。同时，我们还通过实证验证了在开放域多轮对话生成中结合静态和动态注意力的性能。</paragraph>

##### **Evaluating LLMs for Targeted Concept Simplification forDomain-Specific Texts**
2410.20763v1 by Sumit Asthana, Hannah Rashkin, Elizabeth Clark, Fantine Huot, Mirella Lapata

One useful application of NLP models is to support people in reading complex
text from unfamiliar domains (e.g., scientific articles). Simplifying the
entire text makes it understandable but sometimes removes important details. On
the contrary, helping adult readers understand difficult concepts in context
can enhance their vocabulary and knowledge. In a preliminary human study, we
first identify that lack of context and unfamiliarity with difficult concepts
is a major reason for adult readers' difficulty with domain-specific text. We
then introduce "targeted concept simplification," a simplification task for
rewriting text to help readers comprehend text containing unfamiliar concepts.
We also introduce WikiDomains, a new dataset of 22k definitions from 13
academic domains paired with a difficult concept within each definition. We
benchmark the performance of open-source and commercial LLMs and a simple
dictionary baseline on this task across human judgments of ease of
understanding and meaning preservation. Interestingly, our human judges
preferred explanations about the difficult concept more than simplification of
the concept phrase. Further, no single model achieved superior performance
across all quality dimensions, and automated metrics also show low correlations
with human evaluations of concept simplification ($\sim0.2$), opening up rich
avenues for research on personalized human reading comprehension support.

摘要：NLP 模型的一項有用的應用是協助人們閱讀來自陌生領域（例如科學文章）的複雜文本。簡化整篇文本使其易於理解，但有時會移除重要的細節。相反地，協助成年讀者在上下文中理解困難的概念可以增強他們的詞彙量和知識。在初步的人類研究中，我們首先發現缺乏背景知識和不熟悉困難的概念是成年讀者難以理解特定領域文本的主要原因。然後我們引入「目標概念簡化」，這是一種簡化任務，用於改寫文本以幫助讀者理解包含不熟悉概念的文本。我們還引入了 WikiDomains，這是一個新的資料集，包含來自 13 個學術領域的 22k 個定義，每個定義中都配有一個困難的概念。我們根據人類對理解容易度和意義保留的判斷，對開源和商業 LLM 以及簡單的字典基準在這個任務上的表現進行基準測試。有趣的是，我們的人類評審更喜歡對困難概念的解釋，而不是對概念短語的簡化。此外，沒有單一模型在所有品質維度上都達到卓越的表現，而且自動化指標與人類對概念簡化的評估也呈現出低相關性（〜0.2），為個人化人類閱讀理解支援的研究開闢了豐富的途徑。

##### **Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**
2410.20753v1 by Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma

We introduce Planning-guided Retrieval Augmented Generation
(Plan$\times$RAG), a novel framework that augments the
\emph{retrieve-then-reason} paradigm of existing RAG frameworks to
\emph{plan-then-retrieve}. Plan$\times$RAG formulates a reasoning plan as a
directed acyclic graph (DAG), decomposing queries into interrelated atomic
sub-queries. Answer generation follows the DAG structure, allowing significant
gains in efficiency through parallelized retrieval and generation. While
state-of-the-art RAG solutions require extensive data generation and
fine-tuning of language models (LMs), Plan$\times$RAG incorporates frozen LMs
as plug-and-play experts to generate high-quality answers. Compared to existing
RAG solutions, Plan$\times$RAG demonstrates significant improvements in
reducing hallucinations and bolstering attribution due to its structured
sub-query decomposition. Overall, Plan$\times$RAG offers a new perspective on
integrating external knowledge in LMs while ensuring attribution by design,
contributing towards more reliable LM-based systems.

摘要：<paragraph>我們引入了規劃引導的檢索增強生成 (Plan$\times$RAG)，這是一個新穎的框架，它擴充了現有 RAG 框架的「先檢索後推理」範例，改為「先規劃後檢索」。Plan$\times$RAG 將推理計畫制定為有向無環圖 (DAG)，將查詢分解成相互關聯的原子子查詢。答案生成遵循 DAG 結構，透過並行檢索和生成，大幅提升效率。雖然最先進的 RAG 解决方案需要大量資料生成和語言模型 (LM) 的微調，但 Plan$\times$RAG 將凍結的 LM 整合為即插即用的專家，以生成高品質的答案。與現有的 RAG 解决方案相比，Plan$\times$RAG 在減少幻覺和加強歸因方面表現出顯著的進步，這要歸功於其結構化的子查詢分解。總體而言，Plan$\times$RAG 提供了一個新的觀點，以整合 LM 中的外部知識，同時確保歸因設計，有助於建立更可靠的基於 LM 的系統。</paragraph>

##### **Matryoshka: Learning to Drive Black-Box LLMs with LLMs**
2410.20749v1 by Changhao Li, Yuchen Zhuang, Rushi Qiang, Haotian Sun, Hanjun Dai, Chao Zhang, Bo Dai

Despite the impressive generative abilities of black-box large language
models (LLMs), their inherent opacity hinders further advancements in
capabilities such as reasoning, planning, and personalization. Existing works
aim to enhance LLM capabilities via domain-specific adaptation or in-context
learning, which require additional training on accessible model parameters, an
infeasible option for black-box LLMs. To address this challenge, we introduce
Matryoshika, a lightweight white-box LLM controller that guides a large-scale
black-box LLM generator by decomposing complex tasks into a series of
intermediate outputs. Specifically, we consider the black-box LLM as an
environment, with Matryoshika serving as a policy to provide intermediate
guidance through prompts for driving the black-box LLM. Matryoshika is trained
to pivot the outputs of the black-box LLM aligning with preferences during
iterative interaction, which enables controllable multi-turn generation and
self-improvement in optimizing intermediate guidance. Empirical evaluations on
three diverse tasks demonstrate that Matryoshika effectively enhances the
capabilities of black-box LLMs in complex, long-horizon tasks, including
reasoning, planning, and personalization. By leveraging this pioneering
controller-generator framework to mitigate dependence on model parameters,
Matryoshika provides a transparent and practical solution for improving
black-box LLMs through controllable multi-turn generation using white-box LLMs.

摘要：儘管黑盒大型語言模型 (LLM) 具有令人印象深刻的生成能力，但其內在的不透明性阻礙了推理、規劃和個人化等能力的進一步提升。現有作品旨在透過特定領域的適應或情境學習來增強 LLM 的能力，這需要對可存取的模型參數進行額外的訓練，對於黑盒 LLM 來說，這是一個不可行的選項。為了應對這一挑戰，我們引入了 Matryoshika，這是一個輕量級的白盒 LLM 控制器，它透過將複雜任務分解成一系列中間輸出，來引導一個大型的黑盒 LLM 生成器。具體來說，我們將黑盒 LLM 視為一個環境，而 Matryoshika 則扮演一個策略的角色，透過提示來提供中間指導，以驅動黑盒 LLM。Matryoshika 被訓練成在迭代互動期間，根據偏好調整黑盒 LLM 的輸出，這使得可控的多輪生成和在優化中間指導中的自我提升成為可能。在三個不同的任務上的實證評估表明，Matryoshika 有效地增強了黑盒 LLM 在複雜的、長期的任務中的能力，包括推理、規劃和個人化。透過利用這個開創性的控制器生成器框架來減輕對模型參數的依賴性，Matryoshika 提供了一個透明且實用的解決方案，透過使用白盒 LLM 進行可控的多輪生成來改進黑盒 LLM。

##### **ElectionSim: Massive Population Election Simulation Powered by Large Language Model Driven Agents**
2410.20746v1 by Xinnong Zhang, Jiayu Lin, Libo Sun, Weihong Qi, Yihang Yang, Yue Chen, Hanjia Lyu, Xinyi Mou, Siming Chen, Jiebo Luo, Xuanjing Huang, Shiping Tang, Zhongyu Wei

The massive population election simulation aims to model the preferences of
specific groups in particular election scenarios. It has garnered significant
attention for its potential to forecast real-world social trends. Traditional
agent-based modeling (ABM) methods are constrained by their ability to
incorporate complex individual background information and provide interactive
prediction results. In this paper, we introduce ElectionSim, an innovative
election simulation framework based on large language models, designed to
support accurate voter simulations and customized distributions, together with
an interactive platform to dialogue with simulated voters. We present a
million-level voter pool sampled from social media platforms to support
accurate individual simulation. We also introduce PPE, a poll-based
presidential election benchmark to assess the performance of our framework
under the U.S. presidential election scenario. Through extensive experiments
and analyses, we demonstrate the effectiveness and robustness of our framework
in U.S. presidential election simulations.

摘要：大規模人口選舉模擬旨在模擬特定群體在特定選舉情境中的偏好。它因其預測現實世界社會趨勢的潛力而備受關注。傳統的基於主體的建模 (ABM) 方法受到其整合複雜的個人背景資訊和提供互動預測結果的能力的限制。在本文中，我們介紹了 ElectionSim，這是一個創新的選舉模擬框架，基於大型語言模型，旨在支援準確的選民模擬和客製化分佈，並結合一個互動平台與模擬選民對話。我們展示了一個從社群媒體平台取樣的百萬級選民庫，以支援準確的個人模擬。我們還介紹了 PPE，一個基於民意調查的總統選舉基準，用於評估我們框架在美國總統選舉情境下的效能。透過廣泛的實驗和分析，我們證明了我們框架在美國總統選舉模擬中的有效性和穩健性。

##### **Shopping MMLU: A Massive Multi-Task Online Shopping Benchmark for Large Language Models**
2410.20745v1 by Yilun Jin, Zheng Li, Chenwei Zhang, Tianyu Cao, Yifan Gao, Pratik Jayarao, Mao Li, Xin Liu, Ritesh Sarkhel, Xianfeng Tang, Haodong Wang, Zhengyang Wang, Wenju Xu, Jingfeng Yang, Qingyu Yin, Xian Li, Priyanka Nigam, Yi Xu, Kai Chen, Qiang Yang, Meng Jiang, Bing Yin

Online shopping is a complex multi-task, few-shot learning problem with a
wide and evolving range of entities, relations, and tasks. However, existing
models and benchmarks are commonly tailored to specific tasks, falling short of
capturing the full complexity of online shopping. Large Language Models (LLMs),
with their multi-task and few-shot learning abilities, have the potential to
profoundly transform online shopping by alleviating task-specific engineering
efforts and by providing users with interactive conversations. Despite the
potential, LLMs face unique challenges in online shopping, such as
domain-specific concepts, implicit knowledge, and heterogeneous user behaviors.
Motivated by the potential and challenges, we propose Shopping MMLU, a diverse
multi-task online shopping benchmark derived from real-world Amazon data.
Shopping MMLU consists of 57 tasks covering 4 major shopping skills: concept
understanding, knowledge reasoning, user behavior alignment, and
multi-linguality, and can thus comprehensively evaluate the abilities of LLMs
as general shop assistants. With Shopping MMLU, we benchmark over 20 existing
LLMs and uncover valuable insights about practices and prospects of building
versatile LLM-based shop assistants. Shopping MMLU can be publicly accessed at
https://github.com/KL4805/ShoppingMMLU. In addition, with Shopping MMLU, we
host a competition in KDD Cup 2024 with over 500 participating teams. The
winning solutions and the associated workshop can be accessed at our website
https://amazon-kddcup24.github.io/.

摘要：線上購物是一個複雜的多任務、少次學習問題，具有廣泛且不斷演變的實體、關係和任務。然而，現有的模型和基準通常是針對特定任務而設計的，無法捕捉線上購物的全部複雜性。大型語言模型 (LLM) 具有多任務和少次學習能力，有潛力透過減輕特定任務的工程工作，並為使用者提供互動式對話，徹底轉變線上購物。儘管有潛力，LLM 在線上購物中面臨獨特的挑戰，例如特定於領域的概念、隱含知識和異質的使用者行為。在潛力和挑戰的激勵下，我們提出了 Shopping MMLU，一個從真實世界的 Amazon 資料衍生的多元多任務線上購物基準。Shopping MMLU 包含 57 個任務，涵蓋 4 項主要的購物技能：概念理解、知識推理、使用者行為調整和多語言性，因此可以全面評估 LLM 作為一般購物助理的能力。透過 Shopping MMLU，我們對 20 多個現有的 LLM 進行基準測試，並揭示了關於建立多功能基於 LLM 的購物助理的實務和前景的寶貴見解。Shopping MMLU 可在 https://github.com/KL4805/ShoppingMMLU 公開存取。此外，透過 Shopping MMLU，我們在 KDD Cup 2024 中舉辦了一場比賽，有超過 500 個團隊參加。獲獎方案和相關工作坊可以在我們的網站 https://amazon-kddcup24.github.io/ 存取。

##### **Mitigating Unauthorized Speech Synthesis for Voice Protection**
2410.20742v1 by Zhisheng Zhang, Qianyi Yang, Derui Wang, Pengyang Huang, Yuxin Cao, Kai Ye, Jie Hao

With just a few speech samples, it is possible to perfectly replicate a
speaker's voice in recent years, while malicious voice exploitation (e.g.,
telecom fraud for illegal financial gain) has brought huge hazards in our daily
lives. Therefore, it is crucial to protect publicly accessible speech data that
contains sensitive information, such as personal voiceprints. Most previous
defense methods have focused on spoofing speaker verification systems in timbre
similarity but the synthesized deepfake speech is still of high quality. In
response to the rising hazards, we devise an effective, transferable, and
robust proactive protection technology named Pivotal Objective Perturbation
(POP) that applies imperceptible error-minimizing noises on original speech
samples to prevent them from being effectively learned for text-to-speech (TTS)
synthesis models so that high-quality deepfake speeches cannot be generated. We
conduct extensive experiments on state-of-the-art (SOTA) TTS models utilizing
objective and subjective metrics to comprehensively evaluate our proposed
method. The experimental results demonstrate outstanding effectiveness and
transferability across various models. Compared to the speech unclarity score
of 21.94% from voice synthesizers trained on samples without protection,
POP-protected samples significantly increase it to 127.31%. Moreover, our
method shows robustness against noise reduction and data augmentation
techniques, thereby greatly reducing potential hazards.

摘要：<paragraph>近年來，只需幾個語音範本，就能完美複製說話者的聲音，但惡意的語音利用（例如，電信詐欺以獲取非法財務利益）已為我們的日常生活帶來巨大的危害。因此，保護包含敏感資訊（例如個人聲紋）的公開可存取語音資料至關重要。大多數先前的防禦方法都專注於欺騙音色相似度中的揚聲器驗證系統，但合成的深度偽造語音品質仍然很高。為了應對日益增加的危害，我們設計了一種有效、可轉移且強大的主動防護技術，稱為關鍵目標擾動 (POP)，它對原始語音範本套用不可察覺的誤差最小化雜訊，以防止它們被有效學習，用於文字轉語音 (TTS) 合成模型，這樣就無法產生高品質的深度偽造語音。我們利用客觀和主觀指標對最先進 (SOTA) TTS 模型進行廣泛的實驗，以全面評估我們提出的方法。實驗結果證明了跨各種模型的出色有效性和可轉移性。與未受保護範本訓練的語音合成器產生的 21.94% 語音不清度分數相比，POP 保護的範本顯著增加到 127.31%。此外，我們的技術對降噪和資料擴充技術展現出強大的穩健性，從而大幅降低潛在危害。</paragraph>

##### **Gender Bias in LLM-generated Interview Responses**
2410.20739v1 by Haein Kong, Yongsu Ahn, Sangyub Lee, Yunho Maeng

LLMs have emerged as a promising tool for assisting individuals in diverse
text-generation tasks, including job-related texts. However, LLM-generated
answers have been increasingly found to exhibit gender bias. This study
evaluates three LLMs (GPT-3.5, GPT-4, Claude) to conduct a multifaceted audit
of LLM-generated interview responses across models, question types, and jobs,
and their alignment with two gender stereotypes. Our findings reveal that
gender bias is consistent, and closely aligned with gender stereotypes and the
dominance of jobs. Overall, this study contributes to the systematic
examination of gender bias in LLM-generated interview responses, highlighting
the need for a mindful approach to mitigate such biases in related
applications.

摘要：大型語言模型（LLM）已成為一個有前途的工具，可協助個人執行各種文本生成任務，包括與工作相關的文本。然而，愈來愈多發現 LLM 生成的答案會表現出性別偏見。本研究評估了三個 LLM（GPT-3.5、GPT-4、Claude），以對跨模型、問題類型和工作產生的 LLM 訪談回應進行多方面的稽核，以及它們與兩個性別刻板印象的一致性。我們的研究結果揭示了性別偏見是一致的，而且與性別刻板印象和工作的支配地位密切相關。總的來說，本研究有助於系統性地檢視 LLM 生成的訪談回應中的性別偏見，強調需要採取正念方法來減輕相關應用程式中的此類偏見。

##### **Murine AI excels at cats and cheese: Structural differences between human and mouse neurons and their implementation in generative AIs**
2410.20735v1 by Rino Saiga, Kaede Shiga, Yo Maruta, Chie Inomoto, Hiroshi Kajiwara, Naoya Nakamura, Yu Kakimoto, Yoshiro Yamamoto, Masahiro Yasutake, Masayuki Uesugi, Akihisa Takeuchi, Kentaro Uesugi, Yasuko Terada, Yoshio Suzuki, Viktor Nikitin, Vincent De Andrade, Francesco De Carlo, Yuichi Yamashita, Masanari Itokawa, Soichiro Ide, Kazutaka Ikeda, Ryuta Mizutani

Mouse and human brains have different functions that depend on their neuronal
networks. In this study, we analyzed nanometer-scale three-dimensional
structures of brain tissues of the mouse medial prefrontal cortex and compared
them with structures of the human anterior cingulate cortex. The obtained
results indicated that mouse neuronal somata are smaller and neurites are
thinner than those of human neurons. These structural features allow mouse
neurons to be integrated in the limited space of the brain, though thin
neurites should suppress distal connections according to cable theory. We
implemented this mouse-mimetic constraint in convolutional layers of a
generative adversarial network (GAN) and a denoising diffusion implicit model
(DDIM), which were then subjected to image generation tasks using photo
datasets of cat faces, cheese, human faces, and birds. The mouse-mimetic GAN
outperformed a standard GAN in the image generation task using the cat faces
and cheese photo datasets, but underperformed for human faces and birds. The
mouse-mimetic DDIM gave similar results, suggesting that the nature of the
datasets affected the results. Analyses of the four datasets indicated
differences in their image entropy, which should influence the number of
parameters required for image generation. The preferences of the mouse-mimetic
AIs coincided with the impressions commonly associated with mice. The
relationship between the neuronal network and brain function should be
investigated by implementing other biological findings in artificial neural
networks.

摘要：小鼠和人類的大腦具有不同的功能，這取決於它們的神經元網路。在這個研究中，我們分析了小鼠內側前額葉皮質的腦組織奈米等級的三維結構，並將其與人類前扣帶皮質的結構進行比較。所得結果表明，小鼠神經元胞體較小，神經突較細，而人類神經元則較大較粗。這些結構特徵允許小鼠神經元整合在大腦的有限空間中，儘管根據電纜理論，細小的神經突應抑制遠端連接。我們在生成對抗網路 (GAN) 和去噪擴散隱式模型 (DDIM) 的卷積層中實作了這種小鼠模擬約束，然後使用貓臉、起司、人臉和鳥類的照片資料集對其進行影像生成任務。在使用貓臉和起司照片資料集的影像生成任務中，小鼠模擬 GAN 的表現優於標準 GAN，但在人臉和鳥類的表現則較差。小鼠模擬 DDIM 給出了類似的結果，這表明資料集的性質影響了結果。對這四個資料集的分析表明，它們的影像熵不同，這應會影響影像生成所需的參數數量。小鼠模擬 AI 的偏好與一般與小鼠相關的印象一致。神經元網路和腦功能之間的關係應透過在人工神經網路中實作其他生物學發現來加以探討。

##### **GPRec: Bi-level User Modeling for Deep Recommenders**
2410.20730v1 by Yejing Wang, Dong Xu, Xiangyu Zhao, Zhiren Mao, Peng Xiang, Ling Yan, Yao Hu, Zijian Zhang, Xuetao Wei, Qidong Liu

GPRec explicitly categorizes users into groups in a learnable manner and
aligns them with corresponding group embeddings. We design the dual group
embedding space to offer a diverse perspective on group preferences by
contrasting positive and negative patterns. On the individual level, GPRec
identifies personal preferences from ID-like features and refines the obtained
individual representations to be independent of group ones, thereby providing a
robust complement to the group-level modeling. We also present various
strategies for the flexible integration of GPRec into various DRS models.
Rigorous testing of GPRec on three public datasets has demonstrated significant
improvements in recommendation quality.

摘要：GPRec 以可學習的方式將使用者明確分類為群組，並將其與對應的群組嵌入對齊。我們設計了雙重群組嵌入空間，透過對比正負模式，提供群組偏好的多元觀點。在個人層面上，GPRec 從類別 ID 的特徵中識別個人偏好，並改善所獲得的個人表示，使其獨立於群組表示，從而為群組層級的建模提供強健的補充。我們也提出各種策略，將 GPRec 靈活整合到各種 DRS 模型中。在三個公開資料集上對 GPRec 進行嚴格測試，證明推薦品質有顯著的提升。

##### **Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**
2410.20724v1 by Mufei Li, Siqi Miao, Pan Li

Large Language Models (LLMs) demonstrate strong reasoning abilities but face
limitations such as hallucinations and outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by
grounding LLM outputs in structured external knowledge from KGs. However,
current KG-based RAG frameworks still struggle to optimize the trade-off
between retrieval effectiveness and efficiency in identifying a suitable amount
of relevant graph information for the LLM to digest. We introduce SubgraphRAG,
extending the KG-based RAG framework that retrieves subgraphs and leverages
LLMs for reasoning and answer prediction. Our approach innovatively integrates
a lightweight multilayer perceptron with a parallel triple-scoring mechanism
for efficient and flexible subgraph retrieval while encoding directional
structural distances to enhance retrieval effectiveness. The size of retrieved
subgraphs can be flexibly adjusted to match the query's need and the downstream
LLM's capabilities. This design strikes a balance between model complexity and
reasoning power, enabling scalable and generalizable retrieval processes.
Notably, based on our retrieved subgraphs, smaller LLMs like
Llama3.1-8B-Instruct deliver competitive results with explainable reasoning,
while larger models like GPT-4o achieve state-of-the-art accuracy compared with
previous baselines -- all without fine-tuning. Extensive evaluations on the
WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,
accuracy, and reliability by reducing hallucinations and improving response
grounding.

摘要：大型語言模型 (LLM) 展示了強大的推理能力，但面臨幻覺和過時知識等限制。基於知識圖譜 (KG) 的檢索增強生成 (RAG) 透過將 LLM 輸出建立在來自 KG 的結構化外部知識上，來解決這些問題。然而，當前的基於 KG 的 RAG 架構仍難以優化檢索效果與效率之間的權衡，以識別適量的相關圖形資訊供 LLM 消化。我們引入了 SubgraphRAG，擴充了基於 KG 的 RAG 架構，它會檢索子圖並利用 LLM 進行推理和答案預測。我們的做法創新地整合了一個輕量級多層感知器和一個並行的三元組評分機制，以進行有效且彈性的子圖檢索，同時編碼方向結構距離以增強檢索效果。檢索的子圖大小可以靈活調整，以符合查詢的需求和下游 LLM 的功能。此設計在模型複雜度和推理能力之間取得平衡，實現可擴充且可概化的檢索流程。值得注意的是，根據我們檢索的子圖，像 Llama3.1-8B-Instruct 等較小的 LLM 可以透過可解釋的推理提供具有競爭力的結果，而像 GPT-4o 等較大的模型則可達到與先前基準相比的最新準確度，而且所有這些都不需要微調。在 WebQSP 和 CWQ 基準上的廣泛評估突出了 SubgraphRAG 在效率、準確性和可靠性方面的優勢，方法是減少幻覺並改善回應依據。

