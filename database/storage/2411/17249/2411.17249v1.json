{"2411.17249": {"publish_time": "2024-11-26", "title": "Buffer Anytime: Zero-Shot Video Depth and Normal from Image Priors", "paper_summary": "We present Buffer Anytime, a framework for estimation of depth and normal\nmaps (which we call geometric buffers) from video that eliminates the need for\npaired video--depth and video--normal training data. Instead of relying on\nlarge-scale annotated video datasets, we demonstrate high-quality video buffer\nestimation by leveraging single-image priors with temporal consistency\nconstraints. Our zero-shot training strategy combines state-of-the-art image\nestimation models based on optical flow smoothness through a hybrid loss\nfunction, implemented via a lightweight temporal attention architecture.\nApplied to leading image models like Depth Anything V2 and Marigold-E2E-FT, our\napproach significantly improves temporal consistency while maintaining\naccuracy. Experiments show that our method not only outperforms image-based\napproaches but also achieves results comparable to state-of-the-art video\nmodels trained on large-scale paired video datasets, despite using no such\npaired video data.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa Buffer Anytime\uff0c\u4e00\u500b\u7528\u65bc\u5f9e\u5f71\u7247\u4e2d\u4f30\u8a08\u6df1\u5ea6\u548c\u6cd5\u7dda\u8cbc\u5716\uff08\u6211\u5011\u7a31\u4e4b\u70ba\u5e7e\u4f55\u7de9\u885d\u5340\uff09\u7684\u67b6\u69cb\uff0c\u5b83\u6d88\u9664\u4e86\u5c0d\u914d\u5c0d\u5f71\u7247\u6df1\u5ea6\u548c\u5f71\u7247\u6cd5\u7dda\u8a13\u7df4\u8cc7\u6599\u7684\u9700\u6c42\u3002\u6211\u5011\u900f\u904e\u5229\u7528\u55ae\u4e00\u5f71\u50cf\u5148\u9a57\u8207\u6642\u9593\u4e00\u81f4\u6027\u7d04\u675f\uff0c\u5c55\u793a\u9ad8\u54c1\u8cea\u5f71\u7247\u7de9\u885d\u5340\u4f30\u8a08\uff0c\u800c\u4e0d\u662f\u4f9d\u8cf4\u65bc\u5927\u898f\u6a21\u6a19\u8a18\u5f71\u7247\u8cc7\u6599\u96c6\u3002\u6211\u5011\u7684\u96f6\u6b21\u5b78\u7fd2\u7b56\u7565\u7d50\u5408\u4e86\u57fa\u65bc\u5149\u6d41\u5e73\u6ed1\u6027\u7684\u6700\u65b0\u5f71\u50cf\u4f30\u8a08\u6a21\u578b\uff0c\u900f\u904e\u4e00\u500b\u6df7\u5408\u640d\u5931\u51fd\u6578\uff0c\u4e26\u900f\u904e\u4e00\u500b\u8f15\u91cf\u7d1a\u6642\u9593\u6ce8\u610f\u529b\u67b6\u69cb\u9032\u884c\u5be6\u4f5c\u3002\u6211\u5011\u7684\u505a\u6cd5\u61c9\u7528\u65bc Depth Anything V2 \u548c Marigold-E2E-FT \u7b49\u9818\u5148\u7684\u5f71\u50cf\u6a21\u578b\uff0c\u5b83\u986f\u8457\u6539\u5584\u4e86\u6642\u9593\u4e00\u81f4\u6027\uff0c\u540c\u6642\u7dad\u6301\u6e96\u78ba\u5ea6\u3002\u5be6\u9a57\u986f\u793a\uff0c\u6211\u5011\u7684\u6a21\u578b\u4e0d\u50c5\u512a\u65bc\u57fa\u65bc\u5f71\u50cf\u7684\u505a\u6cd5\uff0c\u800c\u4e14\u9084\u9054\u5230\u4e86\u8207\u6700\u65b0\u5f71\u7247\u6a21\u578b\u76f8\u7576\u7684\u7d50\u679c\uff0c\u9019\u4e9b\u5f71\u7247\u6a21\u578b\u662f\u5728\u5927\u898f\u6a21\u914d\u5c0d\u5f71\u7247\u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\u7684\uff0c\u5118\u7ba1\u6c92\u6709\u4f7f\u7528\u6b64\u985e\u914d\u5c0d\u5f71\u7247\u8cc7\u6599\u3002", "author": "Zhengfei Kuang et.al.", "authors": "Zhengfei Kuang, Tianyuan Zhang, Kai Zhang, Hao Tan, Sai Bi, Yiwei Hu, Zexiang Xu, Milos Hasan, Gordon Wetzstein, Fujun Luan", "id": "2411.17249v1", "paper_url": "http://arxiv.org/abs/2411.17249v1", "repo": "null"}}