{"2410.18967": {"publish_time": "2024-10-24", "title": "Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms", "paper_summary": "Building a generalist model for user interface (UI) understanding is\nchallenging due to various foundational issues, such as platform diversity,\nresolution variation, and data limitation. In this paper, we introduce\nFerret-UI 2, a multimodal large language model (MLLM) designed for universal UI\nunderstanding across a wide range of platforms, including iPhone, Android,\niPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI\n2 introduces three key innovations: support for multiple platform types,\nhigh-resolution perception through adaptive scaling, and advanced task training\ndata generation powered by GPT-4o with set-of-mark visual prompting. These\nadvancements enable Ferret-UI 2 to perform complex, user-centered interactions,\nmaking it highly versatile and adaptable for the expanding diversity of\nplatform ecosystems. Extensive empirical experiments on referring, grounding,\nuser-centric advanced tasks (comprising 9 subtasks $\\times$ 5 platforms), GUIDE\nnext-action prediction dataset, and GUI-World multi-platform benchmark\ndemonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also\nshows strong cross-platform transfer capabilities.", "paper_summary_zh": "<paragraph>\u5efa\u7acb\u4e00\u500b\u901a\u7528\u7684\u4f7f\u7528\u8005\u4ecb\u9762 (UI) \u7406\u89e3\u6a21\u578b\uff0c\u7531\u65bc\u5404\u7a2e\u57fa\u790e\u554f\u984c\uff08\u4f8b\u5982\u5e73\u53f0\u591a\u6a23\u6027\u3001\u89e3\u6790\u5ea6\u5dee\u7570\u548c\u8cc7\u6599\u9650\u5236\uff09\u800c\u5177\u6709\u6311\u6230\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 Ferret-UI 2\uff0c\u9019\u662f\u4e00\u500b\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM)\uff0c\u65e8\u5728\u8de8\u8d8a\u5ee3\u6cdb\u7684\u5e73\u53f0\uff08\u5305\u62ec iPhone\u3001Android\u3001iPad\u3001\u7db2\u9801\u548c AppleTV\uff09\u9032\u884c\u901a\u7528\u7684 UI \u7406\u89e3\u3002\u5728 Ferret-UI \u7684\u57fa\u790e\u4e0a\uff0cFerret-UI 2 \u5f15\u5165\u4e86\u4e09\u9805\u95dc\u9375\u5275\u65b0\uff1a\u652f\u63f4\u591a\u7a2e\u5e73\u53f0\u985e\u578b\u3001\u900f\u904e\u81ea\u9069\u61c9\u7e2e\u653e\u9032\u884c\u9ad8\u89e3\u6790\u5ea6\u611f\u77e5\uff0c\u4ee5\u53ca\u7531 GPT-4o \u63d0\u4f9b\u652f\u63f4\u7684\u9032\u968e\u4efb\u52d9\u8a13\u7df4\u8cc7\u6599\u7522\u751f\uff0c\u4e26\u642d\u914d\u4e00\u7d44\u8996\u89ba\u63d0\u793a\u3002\u9019\u4e9b\u9032\u5c55\u4f7f Ferret-UI 2 \u80fd\u5920\u57f7\u884c\u8907\u96dc\u4e14\u4ee5\u4f7f\u7528\u8005\u70ba\u4e2d\u5fc3\u7684\u4e92\u52d5\uff0c\u4f7f\u5176\u9ad8\u5ea6\u9748\u6d3b\u4e14\u9069\u61c9\u4e0d\u65b7\u64f4\u5c55\u7684\u591a\u6a23\u5316\u5e73\u53f0\u751f\u614b\u7cfb\u7d71\u3002\u5728\u6307\u6d89\u3001\u57fa\u790e\u3001\u4ee5\u4f7f\u7528\u8005\u70ba\u4e2d\u5fc3\u7684\u9032\u968e\u4efb\u52d9\uff08\u5305\u542b 9 \u500b\u5b50\u4efb\u52d9 $\\times$ 5 \u500b\u5e73\u53f0\uff09\u3001GUIDE \u4e0b\u4e00\u500b\u52d5\u4f5c\u9810\u6e2c\u8cc7\u6599\u96c6\u548c GUI-World \u591a\u5e73\u53f0\u57fa\u6e96\u4e0a\u7684\u5ee3\u6cdb\u5be6\u8b49\u5be6\u9a57\u8b49\u660e\uff0cFerret-UI 2 \u660e\u986f\u512a\u65bc Ferret-UI\uff0c\u4e26\u4e14\u9084\u5c55\u73fe\u4e86\u5f37\u5927\u7684\u8de8\u5e73\u53f0\u50b3\u8f38\u80fd\u529b\u3002</paragraph>", "author": "Zhangheng Li et.al.", "authors": "Zhangheng Li, Keen You, Haotian Zhang, Di Feng, Harsh Agrawal, Xiujun Li, Mohana Prasad Sathya Moorthy, Jeff Nichols, Yinfei Yang, Zhe Gan", "id": "2410.18967v1", "paper_url": "http://arxiv.org/abs/2410.18967v1", "repo": "null"}}