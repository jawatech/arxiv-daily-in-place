{"2502.05252": {"publish_time": "2025-02-07", "title": "GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?", "paper_summary": "Long-context large language models (LLMs) have recently shown strong\nperformance in information retrieval and long-document QA. However, to tackle\nthe most challenging intellectual problems, LLMs must reason effectively in\nlong and complex contexts (e.g., frontier mathematical research). Studying how\nLLMs handle increasing reasoning complexity and context length is essential,\nyet existing benchmarks lack a solid basis for quantitative evaluation.\nInspired by the abstraction of GSM-8K problems as computational graphs, and the\nability to introduce noise by adding unnecessary nodes and edges, we develop a\ngrade school math problem generator capable of producing arithmetic problems\nwith infinite difficulty and context length under fine-grained control. Using\nour newly synthesized GSM-Infinite benchmark, we comprehensively evaluate\nexisting LLMs. We find a consistent sigmoid decline in reasoning performance as\ncomplexity increases, along with a systematic inference scaling trend:\nexponentially increasing inference computation yields only linear performance\ngains. These findings underscore the fundamental limitations of current\nlong-context LLMs and the key challenges in scaling reasoning capabilities. Our\nGSM-Infinite benchmark provides a scalable and controllable testbed for\nsystematically studying and advancing LLM reasoning in long and complex\ncontexts.", "paper_summary_zh": "\u9577\u6587\u672c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6700\u8fd1\u5728\u8cc7\u8a0a\u6aa2\u7d22\u548c\u9577\u6587\u4ef6\u554f\u7b54\u4e2d\u5c55\u793a\u4e86\u5f37\u5927\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u82e5\u8981\u89e3\u6c7a\u6700\u5177\u6311\u6230\u6027\u7684\u667a\u529b\u554f\u984c\uff0cLLM \u5fc5\u9808\u5728\u9577\u4e14\u8907\u96dc\u7684\u8108\u7d61\u4e2d\u6709\u6548\u63a8\u7406\uff08\u4f8b\u5982\uff0c\u524d\u6cbf\u6578\u5b78\u7814\u7a76\uff09\u3002\u7814\u7a76 LLM \u5982\u4f55\u8655\u7406\u589e\u52a0\u7684\u63a8\u7406\u8907\u96dc\u6027\u548c\u8108\u7d61\u9577\u5ea6\u81f3\u95dc\u91cd\u8981\uff0c\u4f46\u73fe\u6709\u7684\u57fa\u6e96\u7f3a\u4e4f\u5b9a\u91cf\u8a55\u4f30\u7684\u7a69\u56fa\u57fa\u790e\u3002\u53d7\u5230 GSM-8K \u554f\u984c\u62bd\u8c61\u5316\u70ba\u8a08\u7b97\u5716\u5f62\u7684\u555f\u767c\uff0c\u4ee5\u53ca\u900f\u904e\u52a0\u5165\u4e0d\u5fc5\u8981\u7684\u7bc0\u9ede\u548c\u908a\u7de3\u4f86\u5f15\u5165\u96dc\u8a0a\u7684\u80fd\u529b\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u5c0f\u5b78\u6578\u5b78\u554f\u984c\u7522\u751f\u5668\uff0c\u80fd\u5920\u5728\u7d30\u7dfb\u7684\u63a7\u5236\u4e0b\u7522\u751f\u5177\u6709\u7121\u9650\u96e3\u5ea6\u548c\u8108\u7d61\u9577\u5ea6\u7684\u7b97\u8853\u554f\u984c\u3002\u4f7f\u7528\u6211\u5011\u65b0\u5408\u6210\u7684 GSM-Infinite \u57fa\u6e96\uff0c\u6211\u5011\u5168\u9762\u8a55\u4f30\u73fe\u6709\u7684 LLM\u3002\u6211\u5011\u767c\u73fe\u63a8\u7406\u6548\u80fd\u6703\u96a8\u8457\u8907\u96dc\u6027\u7684\u589e\u52a0\u800c\u6301\u7e8c\u5448 S \u5f62\u4e0b\u964d\uff0c\u4e26\u4f34\u96a8\u8457\u7cfb\u7d71\u6027\u7684\u63a8\u8ad6\u7e2e\u653e\u8da8\u52e2\uff1a\u6307\u6578\u589e\u52a0\u7684\u63a8\u8ad6\u8a08\u7b97\u50c5\u7522\u751f\u7dda\u6027\u7684\u6548\u80fd\u589e\u76ca\u3002\u9019\u4e9b\u767c\u73fe\u5f37\u8abf\u4e86\u7576\u524d\u9577\u8108\u7d61 LLM \u7684\u57fa\u672c\u9650\u5236\uff0c\u4ee5\u53ca\u64f4\u5c55\u63a8\u7406\u80fd\u529b\u7684\u4e3b\u8981\u6311\u6230\u3002\u6211\u5011\u7684 GSM-Infinite \u57fa\u6e96\u63d0\u4f9b\u4e86\u4e00\u500b\u53ef\u64f4\u5145\u4e14\u53ef\u63a7\u7684\u6e2c\u8a66\u5e73\u53f0\uff0c\u7528\u65bc\u7cfb\u7d71\u6027\u5730\u7814\u7a76\u548c\u63d0\u5347 LLM \u5728\u9577\u4e14\u8907\u96dc\u8108\u7d61\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "author": "Yang Zhou et.al.", "authors": "Yang Zhou, Hongyi Liu, Zhuoming Chen, Yuandong Tian, Beidi Chen", "id": "2502.05252v1", "paper_url": "http://arxiv.org/abs/2502.05252v1", "repo": "null"}}