{"2411.14790": {"publish_time": "2024-11-22", "title": "KBAda: Efficient Self Adaptation on Specific Knowledge Bases", "paper_summary": "Humans can utilize techniques to quickly acquire knowledge from specific\nmaterials in advance, such as creating self-assessment questions, enabling us\nto achieving related tasks more efficiently. In contrast, large language models\n(LLMs) usually relies on retrieval-augmented generation to exploit knowledge\nmaterials in an instant manner, or requires external signals such as human\npreference data and stronger LLM annotations to conduct knowledge adaptation.\nTo unleash the self-learning potential of LLMs, we propose KBAda, an approach\ndesigned for efficient adaptation to downstream tasks involving knowledge\nbases. Our method utilizes iterative training with self-annotated data such as\nQ&A pairs and revision suggestions, enabling the model to grasp the knowledge\ncontent efficiently. Experimental results on multiple datasets demonstrate the\neffectiveness of our approach, significantly boosting model performance in\ndownstream tasks that require specific knowledge at a low cost. Notably, our\napproach achieves over 90% of the performance improvement that can be obtained\nby using GPT-4-turbo annotation, while relying entirely on self-supervision. We\nrelease our experimental data, models, and process analyses to the community\nfor further exploration (https://github.com/thunlp/KBAda).", "paper_summary_zh": "\u4eba\u985e\u53ef\u4ee5\u5229\u7528\u6280\u8853\uff0c\u63d0\u524d\u5f9e\u7279\u5b9a\u6750\u6599\u4e2d\u5feb\u901f\u7372\u53d6\u77e5\u8b58\uff0c\u4f8b\u5982\u5efa\u7acb\u81ea\u6211\u8a55\u91cf\u554f\u984c\uff0c\u8b93\u6211\u5011\u80fd\u5920\u66f4\u6709\u6548\u5730\u9054\u6210\u76f8\u95dc\u4efb\u52d9\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u901a\u5e38\u4f9d\u8cf4\u65bc\u6aa2\u7d22\u589e\u5f37\u751f\u6210\uff0c\u4f86\u5373\u6642\u5229\u7528\u77e5\u8b58\u6750\u6599\uff0c\u6216\u8005\u9700\u8981\u5916\u90e8\u8a0a\u865f\uff0c\u4f8b\u5982\u4eba\u985e\u504f\u597d\u6578\u64da\u548c\u66f4\u5f37\u5927\u7684 LLM \u6ce8\u89e3\uff0c\u4f86\u9032\u884c\u77e5\u8b58\u9069\u61c9\u3002\u70ba\u4e86\u91cb\u653e LLM \u7684\u81ea\u5b78\u6f5b\u529b\uff0c\u6211\u5011\u63d0\u51fa\u4e86 KBAda\uff0c\u4e00\u7a2e\u5c08\u9580\u8a2d\u8a08\u7528\u65bc\u6709\u6548\u9069\u61c9\u6d89\u53ca\u77e5\u8b58\u5eab\u7684\u4e0b\u6e38\u4efb\u52d9\u7684\u65b9\u6cd5\u3002\u6211\u5011\u7684\u6a21\u578b\u5229\u7528\u81ea\u6211\u8a3b\u89e3\u6578\u64da\uff08\u4f8b\u5982\u554f\u7b54\u914d\u5c0d\u548c\u4fee\u8a02\u5efa\u8b70\uff09\u9032\u884c\u53cd\u8986\u8a13\u7df4\uff0c\u8b93\u6a21\u578b\u80fd\u5920\u6709\u6548\u638c\u63e1\u77e5\u8b58\u5167\u5bb9\u3002\u5728\u591a\u500b\u6578\u64da\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u986f\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u9700\u8981\u7279\u5b9a\u77e5\u8b58\u7684\u4e0b\u6e38\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\uff0c\u800c\u4e14\u6210\u672c\u5f88\u4f4e\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684\u6a21\u578b\u50c5\u4f9d\u8cf4\u65bc\u81ea\u6211\u76e3\u7763\uff0c\u5c31\u80fd\u9054\u5230\u4f7f\u7528 GPT-4-turbo \u6ce8\u89e3\u6240\u80fd\u7372\u5f97\u7684 90% \u4ee5\u4e0a\u7684\u6548\u80fd\u63d0\u5347\u3002\u6211\u5011\u5c07\u5be6\u9a57\u6578\u64da\u3001\u6a21\u578b\u548c\u7a0b\u5e8f\u5206\u6790\u767c\u5e03\u5230\u793e\u7fa4\u4e2d\uff0c\u4ee5\u4f9b\u9032\u4e00\u6b65\u63a2\u7d22 (https://github.com/thunlp/KBAda)\u3002", "author": "Zheni Zeng et.al.", "authors": "Zheni Zeng, Yuxuan Chen, Shi Yu, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun", "id": "2411.14790v1", "paper_url": "http://arxiv.org/abs/2411.14790v1", "repo": "null"}}