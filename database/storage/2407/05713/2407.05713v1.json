{"2407.05713": {"publish_time": "2024-07-08", "title": "Short-term Object Interaction Anticipation with Disentangled Object Detection @ Ego4D Short Term Object Interaction Anticipation Challenge", "paper_summary": "Short-term object interaction anticipation is an important task in egocentric\nvideo analysis, including precise predictions of future interactions and their\ntimings as well as the categories and positions of the involved active objects.\nTo alleviate the complexity of this task, our proposed method, SOIA-DOD,\neffectively decompose it into 1) detecting active object and 2) classifying\ninteraction and predicting their timing. Our method first detects all potential\nactive objects in the last frame of egocentric video by fine-tuning a\npre-trained YOLOv9. Then, we combine these potential active objects as query\nwith transformer encoder, thereby identifying the most promising next active\nobject and predicting its future interaction and time-to-contact. Experimental\nresults demonstrate that our method outperforms state-of-the-art models on the\nchallenge test set, achieving the best performance in predicting next active\nobjects and their interactions. Finally, our proposed ranked the third overall\ntop-5 mAP when including time-to-contact predictions. The source code is\navailable at https://github.com/KeenyJin/SOIA-DOD.", "paper_summary_zh": "\u77ed\u671f\u76ee\u6a19\u4e92\u52d5\u9810\u6e2c\u662f\u81ea\u6211\u4e2d\u5fc3\u5f71\u7247\u5206\u6790\u4e2d\u7684\u4e00\u9805\u91cd\u8981\u4efb\u52d9\uff0c\u5305\u62ec\u6e96\u78ba\u9810\u6e2c\u672a\u4f86\u7684\u4e92\u52d5\u53ca\u5176\u6642\u6a5f\uff0c\u4ee5\u53ca\u6240\u6d89\u53ca\u7684\u6d3b\u8e8d\u7269\u9ad4\u7684\u985e\u5225\u548c\u4f4d\u7f6e\u3002\u70ba\u4e86\u6e1b\u8f15\u6b64\u4efb\u52d9\u7684\u8907\u96dc\u6027\uff0c\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5 SOIA-DOD\uff0c\u6709\u6548\u5730\u5c07\u5176\u5206\u89e3\u70ba 1) \u5075\u6e2c\u6d3b\u8e8d\u7269\u9ad4\u548c 2) \u5206\u985e\u4e92\u52d5\u4e26\u9810\u6e2c\u5176\u6642\u6a5f\u3002\u6211\u5011\u7684\u6a21\u578b\u9996\u5148\u900f\u904e\u5fae\u8abf\u9810\u5148\u8a13\u7df4\u7684 YOLOv9\uff0c\u5728\u81ea\u6211\u4e2d\u5fc3\u5f71\u7247\u7684\u6700\u5f8c\u4e00\u5e40\u4e2d\u5075\u6e2c\u6240\u6709\u6f5b\u5728\u7684\u6d3b\u8e8d\u7269\u9ad4\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5c07\u9019\u4e9b\u6f5b\u5728\u7684\u6d3b\u8e8d\u7269\u9ad4\u8207 Transformer \u7de8\u78bc\u5668\u7d50\u5408\u70ba\u67e5\u8a62\uff0c\u5f9e\u800c\u8b58\u5225\u6700\u6709\u5e0c\u671b\u7684\u4e0b\u4e00\u6d3b\u8e8d\u7269\u9ad4\uff0c\u4e26\u9810\u6e2c\u5176\u672a\u4f86\u7684\u4e92\u52d5\u548c\u63a5\u89f8\u6642\u9593\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728\u6311\u6230\u6e2c\u8a66\u96c6\u4e2d\u512a\u65bc\u73fe\u6709\u6a21\u578b\uff0c\u5728\u9810\u6e2c\u4e0b\u4e00\u500b\u6d3b\u8e8d\u7269\u9ad4\u53ca\u5176\u4e92\u52d5\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u4f73\u6548\u80fd\u3002\u6700\u5f8c\uff0c\u7576\u7d0d\u5165\u63a5\u89f8\u6642\u9593\u9810\u6e2c\u6642\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728\u6574\u9ad4\u524d 5 \u540d mAP \u4e2d\u6392\u540d\u7b2c\u4e09\u3002\u539f\u59cb\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/KeenyJin/SOIA-DOD \u53d6\u5f97\u3002", "author": "Hyunjin Cho et.al.", "authors": "Hyunjin Cho, Dong Un Kang, Se Young Chun", "id": "2407.05713v1", "paper_url": "http://arxiv.org/abs/2407.05713v1", "repo": "https://github.com/keenyjin/soia-dod"}}