{"2410.19008": {"publish_time": "2024-10-21", "title": "Teach Multimodal LLMs to Comprehend Electrocardiographic Images", "paper_summary": "The electrocardiogram (ECG) is an essential non-invasive diagnostic tool for\nassessing cardiac conditions. Existing automatic interpretation methods suffer\nfrom limited generalizability, focusing on a narrow range of cardiac\nconditions, and typically depend on raw physiological signals, which may not be\nreadily available in resource-limited settings where only printed or digital\nECG images are accessible. Recent advancements in multimodal large language\nmodels (MLLMs) present promising opportunities for addressing these challenges.\nHowever, the application of MLLMs to ECG image interpretation remains\nchallenging due to the lack of instruction tuning datasets and well-established\nECG image benchmarks for quantitative evaluation. To address these challenges,\nwe introduce ECGInstruct, a comprehensive ECG image instruction tuning dataset\nof over one million samples, covering a wide range of ECG-related tasks from\ndiverse data sources. Using ECGInstruct, we develop PULSE, an MLLM tailored for\nECG image comprehension. In addition, we curate ECGBench, a new evaluation\nbenchmark covering four key ECG image interpretation tasks across nine\ndifferent datasets. Our experiments show that PULSE sets a new\nstate-of-the-art, outperforming general MLLMs with an average accuracy\nimprovement of 15% to 30%. This work highlights the potential of PULSE to\nenhance ECG interpretation in clinical practice.", "paper_summary_zh": "\u5fc3\u96fb\u5716 (ECG) \u662f\u4e00\u7a2e\u8a55\u4f30\u5fc3\u81df\u72c0\u6cc1\u7684\u57fa\u672c\u975e\u4fb5\u5165\u5f0f\u8a3a\u65b7\u5de5\u5177\u3002\u73fe\u6709\u7684\u81ea\u52d5\u89e3\u8b80\u65b9\u6cd5\u666e\u904d\u6027\u6709\u9650\uff0c\u5c08\u6ce8\u65bc\u72f9\u7a84\u7684\u5fc3\u81df\u72c0\u6cc1\u7bc4\u570d\uff0c\u4e14\u901a\u5e38\u4f9d\u8cf4\u539f\u59cb\u751f\u7406\u8a0a\u865f\uff0c\u9019\u5728\u50c5\u80fd\u53d6\u5f97\u5370\u5237\u6216\u6578\u4f4d ECG \u5f71\u50cf\u7684\u8cc7\u6e90\u6709\u9650\u7684\u74b0\u5883\u4e2d\u53ef\u80fd\u7121\u6cd5\u8f15\u6613\u53d6\u5f97\u3002\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u6700\u65b0\u9032\u5c55\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\u63d0\u4f9b\u4e86\u7d55\u4f73\u7684\u6a5f\u6703\u3002\u7136\u800c\uff0c\u7531\u65bc\u7f3a\u4e4f\u6307\u4ee4\u8abf\u6574\u8cc7\u6599\u96c6\u548c\u5b8c\u5584\u7684 ECG \u5f71\u50cf\u57fa\u6e96\uff0c\u5c07 MLLM \u61c9\u7528\u65bc ECG \u5f71\u50cf\u89e3\u8b80\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 ECGInstruct\uff0c\u9019\u662f\u4e00\u500b\u5168\u9762\u7684 ECG \u5f71\u50cf\u6307\u4ee4\u8abf\u6574\u8cc7\u6599\u96c6\uff0c\u5305\u542b\u8d85\u904e\u4e00\u767e\u842c\u500b\u6a23\u672c\uff0c\u6db5\u84cb\u4f86\u81ea\u4e0d\u540c\u8cc7\u6599\u4f86\u6e90\u7684\u5404\u7a2e ECG \u76f8\u95dc\u4efb\u52d9\u3002\u4f7f\u7528 ECGInstruct\uff0c\u6211\u5011\u958b\u767c\u4e86 PULSE\uff0c\u4e00\u7a2e\u5c08\u70ba ECG \u5f71\u50cf\u7406\u89e3\u91cf\u8eab\u6253\u9020\u7684 MLLM\u3002\u6b64\u5916\uff0c\u6211\u5011\u7b56\u5283\u4e86 ECGBench\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7684\u8a55\u4f30\u57fa\u6e96\uff0c\u6db5\u84cb\u4e5d\u500b\u4e0d\u540c\u8cc7\u6599\u96c6\u4e2d\u7684\u56db\u9805\u95dc\u9375 ECG \u5f71\u50cf\u89e3\u8b80\u4efb\u52d9\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0cPULSE \u5275\u4e0b\u4e86\u65b0\u7684\u6280\u8853\u6c34\u6e96\uff0c\u512a\u65bc\u4e00\u822c MLLM\uff0c\u5e73\u5747\u6e96\u78ba\u5ea6\u63d0\u5347\u4e86 15% \u81f3 30%\u3002\u9019\u9805\u5de5\u4f5c\u7a81\u986f\u4e86 PULSE \u5728\u81e8\u5e8a\u5be6\u52d9\u4e2d\u589e\u5f37 ECG \u89e3\u8b80\u7684\u6f5b\u529b\u3002", "author": "Ruoqi Liu et.al.", "authors": "Ruoqi Liu, Yuelin Bai, Xiang Yue, Ping Zhang", "id": "2410.19008v1", "paper_url": "http://arxiv.org/abs/2410.19008v1", "repo": "null"}}