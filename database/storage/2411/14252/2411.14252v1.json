{"2411.14252": {"publish_time": "2024-11-21", "title": "Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification", "paper_summary": "Generating large-scale, domain-specific, multilingual multi-turn dialogue\ndatasets remains a significant hurdle for training effective Multi-Turn Intent\nClassification models in chatbot systems. In this paper, we introduce\nChain-of-Intent, a novel mechanism that combines Hidden Markov Models with\nLarge Language Models (LLMs) to generate contextually aware, intent-driven\nconversations through self-play. By extracting domain-specific knowledge from\ne-commerce chat logs, we estimate conversation turns and intent transitions,\nwhich guide the generation of coherent dialogues. Leveraging LLMs to enhance\nemission probabilities, our approach produces natural and contextually\nconsistent questions and answers. We also propose MINT-CL, a framework for\nmulti-turn intent classification using multi-task contrastive learning,\nimproving classification accuracy without the need for extensive annotated\ndata. Evaluations show that our methods outperform baselines in dialogue\nquality and intent classification accuracy, especially in multilingual\nsettings, while significantly reducing data generation efforts. Furthermore, we\nrelease MINT-E, a multilingual, intent-aware multi-turn e-commerce dialogue\ncorpus to support future research in this area.", "paper_summary_zh": "\u751f\u6210\u5927\u89c4\u6a21\u3001\u7279\u5b9a\u9886\u57df\u3001\u591a\u8bed\u8a00\u7684\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u96c6\u5bf9\u4e8e\u8bad\u7ec3\u804a\u5929\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u591a\u8f6e\u610f\u56fe\u5206\u7c7b\u6a21\u578b\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u969c\u788d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u610f\u56fe\u94fe\uff0c\u8fd9\u662f\u4e00\u79cd\u5c06\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b (LLM) \u76f8\u7ed3\u5408\u7684\u65b0\u673a\u5236\uff0c\u901a\u8fc7\u81ea\u535a\u5f08\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u610f\u56fe\u9a71\u52a8\u7684\u5bf9\u8bdd\u3002\u901a\u8fc7\u4ece\u7535\u5b50\u5546\u52a1\u804a\u5929\u8bb0\u5f55\u4e2d\u63d0\u53d6\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\uff0c\u6211\u4eec\u4f30\u8ba1\u5bf9\u8bdd\u8f6e\u6b21\u548c\u610f\u56fe\u8f6c\u6362\uff0c\u4ece\u800c\u6307\u5bfc\u751f\u6210\u8fde\u8d2f\u7684\u5bf9\u8bdd\u3002\u5229\u7528 LLM \u6765\u63d0\u9ad8\u53d1\u5c04\u6982\u7387\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u4ea7\u751f\u4e86\u81ea\u7136\u4e14\u5728\u4e0a\u4e0b\u6587\u4e0a\u4e00\u81f4\u7684\u95ee\u9898\u548c\u7b54\u6848\u3002\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86 MINT-CL\uff0c\u4e00\u4e2a\u7528\u4e8e\u591a\u4efb\u52a1\u5bf9\u6bd4\u5b66\u4e60\u7684\u591a\u8f6e\u610f\u56fe\u5206\u7c7b\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u800c\u65e0\u9700\u5927\u91cf\u6ce8\u91ca\u6570\u636e\u3002\u8bc4\u4f30\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5bf9\u8bdd\u8d28\u91cf\u548c\u610f\u56fe\u5206\u7c7b\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\uff0c\u7279\u522b\u662f\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\uff0c\u540c\u65f6\u663e\u7740\u51cf\u5c11\u4e86\u6570\u636e\u751f\u6210\u5de5\u4f5c\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u5e03\u4e86 MINT-E\uff0c\u8fd9\u662f\u4e00\u4e2a\u591a\u8bed\u8a00\u3001\u610f\u56fe\u611f\u77e5\u7684\u591a\u8f6e\u7535\u5b50\u5546\u52a1\u5bf9\u8bdd\u8bed\u6599\u5e93\uff0c\u4ee5\u652f\u6301\u8be5\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u3002", "author": "Junhua Liu et.al.", "authors": "Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim", "id": "2411.14252v1", "paper_url": "http://arxiv.org/abs/2411.14252v1", "repo": "null"}}