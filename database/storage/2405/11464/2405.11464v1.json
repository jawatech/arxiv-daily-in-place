{"2405.11464": {"publish_time": "2024-05-19", "title": "Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion", "paper_summary": "Prompt tuning is a promising method to fine-tune a pre-trained language model\nwithout retraining its large-scale parameters. Instead, it attaches a soft\nprompt to the input text, whereby downstream tasks can be well adapted by\nmerely learning the embeddings of prompt tokens. Nevertheless, existing methods\nstill suffer from two challenges: (i) they are hard to balance accuracy and\nefficiency. A longer (shorter) soft prompt generally leads to a better (worse)\naccuracy but at the cost of more (less) training time. (ii) The performance may\nnot be consistent when adapting to different downstream tasks. We attribute it\nto the same embedding space but responsible for different requirements of\ndownstream tasks. To address these issues, we propose an Efficient Prompt\nTuning method (EPT) by multi-space projection and prompt fusion. Specifically,\nit decomposes a given soft prompt into a shorter prompt and two low-rank\nmatrices, whereby the number of parameters is greatly reduced as well as the\ntraining time. The accuracy is also enhanced by leveraging low-rank matrices\nand the short prompt as additional knowledge sources to enrich the semantics of\nthe original short prompt. In addition, we project the soft prompt into\nmultiple subspaces to improve the performance consistency, and then adaptively\nlearn the combination weights of different spaces through a gating network.\nExperimental experiments on 13 natural language processing downstream tasks\nshow that our method significantly and consistently outperforms 11 comparison\nmethods with the relative percentage of improvements up to 28.8%, and training\ntime decreased by 14%.", "paper_summary_zh": "\u63d0\u793a\u5fae\u8c03\u662f\u4e00\u79cd\u5f88\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5fae\u8c03\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5176\u5927\u89c4\u6a21\u53c2\u6570\u3002\u76f8\u53cd\uff0c\u5b83\u5c06\u4e00\u4e2a\u8f6f\u63d0\u793a\u9644\u52a0\u5230\u8f93\u5165\u6587\u672c\uff0c\u4ece\u800c\u53ef\u4ee5\u901a\u8fc7\u4ec5\u4ec5\u5b66\u4e60\u63d0\u793a\u6807\u8bb0\u7684\u5d4c\u5165\u6765\u5f88\u597d\u5730\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u4ecd\u7136\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a(i) \u96be\u4ee5\u5e73\u8861\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\u8f83\u957f\uff08\u8f83\u77ed\uff09\u7684\u8f6f\u63d0\u793a\u901a\u5e38\u4f1a\u5bfc\u81f4\u8f83\u597d\uff08\u8f83\u5dee\uff09\u7684\u51c6\u786e\u6027\uff0c\u4f46\u4ee3\u4ef7\u662f\u8bad\u7ec3\u65f6\u95f4\u66f4\u591a\uff08\u66f4\u5c11\uff09\u3002(ii) \u5728\u9002\u5e94\u4e0d\u540c\u7684\u4e0b\u6e38\u4efb\u52a1\u65f6\uff0c\u6027\u80fd\u53ef\u80fd\u4e0d\u4e00\u81f4\u3002\u6211\u4eec\u5c06\u5176\u5f52\u56e0\u4e8e\u76f8\u540c\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u4f46\u8d1f\u8d23\u4e0d\u540c\u7684\u4e0b\u6e38\u4efb\u52a1\u9700\u6c42\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u901a\u8fc7\u591a\u7a7a\u95f4\u6295\u5f71\u548c\u63d0\u793a\u878d\u5408\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u63d0\u793a\u5fae\u8c03\u65b9\u6cd5 (EPT)\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u5c06\u7ed9\u5b9a\u7684\u8f6f\u63d0\u793a\u5206\u89e3\u4e3a\u4e00\u4e2a\u8f83\u77ed\u7684\u63d0\u793a\u548c\u4e24\u4e2a\u4f4e\u79e9\u77e9\u9635\uff0c\u4ece\u800c\u5927\u5927\u51cf\u5c11\u4e86\u53c2\u6570\u7684\u6570\u91cf\u4ee5\u53ca\u8bad\u7ec3\u65f6\u95f4\u3002\u901a\u8fc7\u5229\u7528\u4f4e\u79e9\u77e9\u9635\u548c\u77ed\u63d0\u793a\u4f5c\u4e3a\u9644\u52a0\u77e5\u8bc6\u6e90\u6765\u4e30\u5bcc\u539f\u59cb\u77ed\u63d0\u793a\u7684\u8bed\u4e49\uff0c\u8fd8\u53ef\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5c06\u8f6f\u63d0\u793a\u6295\u5f71\u5230\u591a\u4e2a\u5b50\u7a7a\u95f4\u4ee5\u63d0\u9ad8\u6027\u80fd\u4e00\u81f4\u6027\uff0c\u7136\u540e\u901a\u8fc7\u95e8\u63a7\u7f51\u7edc\u81ea\u9002\u5e94\u5730\u5b66\u4e60\u4e0d\u540c\u7a7a\u95f4\u7684\u7ec4\u5408\u6743\u91cd\u3002\u5728 13 \u4e2a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u660e\u663e\u4e14\u6301\u7eed\u5730\u4f18\u4e8e 11 \u79cd\u6bd4\u8f83\u65b9\u6cd5\uff0c\u76f8\u5bf9\u6539\u8fdb\u767e\u5206\u6bd4\u9ad8\u8fbe 28.8%\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u4e86 14%\u3002", "author": "Pengxiang Lan et.al.", "authors": "Pengxiang Lan, Enneng Yang, Yuting Liu, Guibing Guo, Linying Jiang, Jianzhe Zhao, Xingwei Wang", "id": "2405.11464v1", "paper_url": "http://arxiv.org/abs/2405.11464v1", "repo": "null"}}