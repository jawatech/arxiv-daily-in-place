{"2410.23031": {"publish_time": "2024-10-30", "title": "Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation", "paper_summary": "Contemporary radio access networks employ link adaption (LA) algorithms to\noptimize the modulation and coding schemes to adapt to the prevailing\npropagation conditions and are near-optimal in terms of the achieved spectral\nefficiency. LA is a challenging task in the presence of mobility, fast fading,\nand imperfect channel quality information and limited knowledge of the receiver\ncharacteristics at the transmitter, which render model-based LA algorithms\ncomplex and suboptimal. Model-based LA is especially difficult as connected\nuser equipment devices become increasingly heterogeneous in terms of receiver\ncapabilities, antenna configurations and hardware characteristics. Recognizing\nthese difficulties, previous works have proposed reinforcement learning (RL)\nfor LA, which faces deployment difficulties due to their potential negative\nimpacts on live performance. To address this challenge, this paper considers\noffline RL to learn LA policies from data acquired in live networks with\nminimal or no intrusive effects on the network operation. We propose three LA\ndesigns based on batch-constrained deep Q-learning, conservative Q-learning,\nand decision transformers, showing that offline RL algorithms can achieve\nperformance of state-of-the-art online RL methods when data is collected with a\nproper behavioral policy.", "paper_summary_zh": "\u73fe\u4ee3\u7121\u7dda\u5b58\u53d6\u7db2\u8def\u63a1\u7528\u9023\u7d50\u9069\u61c9 (LA) \u6f14\u7b97\u6cd5\u4f86\u6700\u4f73\u5316\u8abf\u8b8a\u548c\u7de8\u78bc\u67b6\u69cb\uff0c\u4ee5\u9069\u61c9\u73fe\u884c\u7684\u50b3\u64ad\u689d\u4ef6\uff0c\u4e14\u5728\u9054\u6210\u7684\u983b\u8b5c\u6548\u7387\u65b9\u9762\u63a5\u8fd1\u6700\u4f73\u3002LA \u5728\u6d41\u52d5\u6027\u3001\u5feb\u901f\u8870\u843d\u3001\u4e0d\u5b8c\u7f8e\u7684\u983b\u9053\u54c1\u8cea\u8cc7\u8a0a\u548c\u767c\u5c04\u5668\u5c0d\u63a5\u6536\u5668\u7279\u6027\u4e86\u89e3\u6709\u9650\u7684\u60c5\u6cc1\u4e0b\u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\uff0c\u9019\u4f7f\u5f97\u57fa\u65bc\u6a21\u578b\u7684 LA \u6f14\u7b97\u6cd5\u8907\u96dc\u4e14\u6b21\u6700\u4f73\u3002\u96a8\u8457\u9023\u63a5\u7684\u4f7f\u7528\u8005\u8a2d\u5099\u5728\u63a5\u6536\u5668\u80fd\u529b\u3001\u5929\u7dda\u7d44\u614b\u548c\u786c\u9ad4\u7279\u6027\u65b9\u9762\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u7570\u8cea\uff0c\u57fa\u65bc\u6a21\u578b\u7684 LA \u8b8a\u5f97\u7279\u5225\u56f0\u96e3\u3002\u8a8d\u8b58\u5230\u9019\u4e9b\u56f0\u96e3\uff0c\u5148\u524d\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u7528\u65bc LA \u7684\u5f37\u5316\u5b78\u7fd2 (RL)\uff0c\u7531\u65bc\u5176\u5c0d\u73fe\u5834\u6548\u80fd\u7684\u6f5b\u5728\u8ca0\u9762\u5f71\u97ff\uff0c\u56e0\u6b64\u5728\u90e8\u7f72\u4e0a\u5b58\u5728\u56f0\u96e3\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u672c\u6587\u8003\u616e\u96e2\u7dda RL \u5f9e\u73fe\u5834\u7db2\u8def\u4e2d\u7372\u53d6\u7684\u8cc7\u6599\u4e2d\u5b78\u7fd2 LA \u7b56\u7565\uff0c\u5c0d\u7db2\u8def\u904b\u4f5c\u7684\u4fb5\u5165\u6027\u5f71\u97ff\u6975\u5c0f\u6216\u6c92\u6709\u3002\u6211\u5011\u63d0\u51fa\u4e09\u7a2e\u57fa\u65bc\u6279\u6b21\u7d04\u675f\u6df1\u5ea6 Q \u5b78\u7fd2\u3001\u4fdd\u5b88 Q \u5b78\u7fd2\u548c\u6c7a\u7b56\u8f49\u63db\u5668\u7684 LA \u8a2d\u8a08\uff0c\u8868\u660e\u96e2\u7dda RL \u6f14\u7b97\u6cd5\u5728\u4f7f\u7528\u9069\u7576\u7684\u884c\u70ba\u7b56\u7565\u6536\u96c6\u8cc7\u6599\u6642\uff0c\u53ef\u4ee5\u9054\u5230\u6700\u5148\u9032\u7684\u7dda\u4e0a RL \u65b9\u6cd5\u7684\u6548\u80fd\u3002", "author": "Samuele Peri et.al.", "authors": "Samuele Peri, Alessio Russo, Gabor Fodor, Pablo Soldati", "id": "2410.23031v1", "paper_url": "http://arxiv.org/abs/2410.23031v1", "repo": "null"}}