
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-17**|**ExBody2: Advanced Expressive Humanoid Whole-Body Control**|Mazeyu Ji et.al.|[2412.13196v1](http://arxiv.org/abs/2412.13196v1)|null|
|**2024-12-17**|**Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents**|Yifei Zhou et.al.|[2412.13194v1](http://arxiv.org/abs/2412.13194v1)|null|
|**2024-12-17**|**Tilted Quantile Gradient Updates for Quantile-Constrained Reinforcement Learning**|Chenglin Li et.al.|[2412.13184v1](http://arxiv.org/abs/2412.13184v1)|[link](https://github.com/CharlieLeeeee/TQPO)|
|**2024-12-17**|**SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents**|Sheng Yin et.al.|[2412.13178v1](http://arxiv.org/abs/2412.13178v1)|[link](https://github.com/shengyin1224/safeagentbench)|
|**2024-12-17**|**DnDScore: Decontextualization and Decomposition for Factuality Verification in Long-Form Text Generation**|Miriam Wanner et.al.|[2412.13175v1](http://arxiv.org/abs/2412.13175v1)|null|
|**2024-12-17**|**Compressed Chain of Thought: Efficient Reasoning Through Dense Representations**|Jeffrey Cheng et.al.|[2412.13171v1](http://arxiv.org/abs/2412.13171v1)|null|
|**2024-12-17**|**Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study**|Bolei Ma et.al.|[2412.13169v1](http://arxiv.org/abs/2412.13169v1)|[link](https://github.com/soda-lmu/llm-opinion-german)|
|**2024-12-17**|**Lifting Scheme-Based Implicit Disentanglement of Emotion-Related Facial Dynamics in the Wild**|Xingjian Wang et.al.|[2412.13168v1](http://arxiv.org/abs/2412.13168v1)|[link](https://github.com/CyberPegasus/IFDD)|
|**2024-12-17**|**BanglishRev: A Large-Scale Bangla-English and Code-mixed Dataset of Product Reviews in E-Commerce**|Mohammad Nazmush Shamael et.al.|[2412.13161v1](http://arxiv.org/abs/2412.13161v1)|null|
|**2024-12-17**|**SWAN: Preprocessing SGD Enables Adam-Level Performance On LLM Training With Significant Memory Reduction**|Chao Ma et.al.|[2412.13148v1](http://arxiv.org/abs/2412.13148v1)|null|
|**2024-12-17**|**Are Your LLMs Capable of Stable Reasoning?**|Junnan Liu et.al.|[2412.13147v1](http://arxiv.org/abs/2412.13147v1)|[link](https://github.com/open-compass/gpassk)|
|**2024-12-17**|**Syntactic Transfer to Kyrgyz Using the Treebank Translation Method**|Anton Alekseev et.al.|[2412.13146v1](http://arxiv.org/abs/2412.13146v1)|[link](https://github.com/alexeyev/tratreetra)|
|**2024-12-17**|**Improving Explainability of Sentence-level Metrics via Edit-level Attribution for Grammatical Error Correction**|Takumi Goto et.al.|[2412.13110v1](http://arxiv.org/abs/2412.13110v1)|null|
|**2024-12-17**|**AI PERSONA: Towards Life-long Personalization of LLMs**|Tiannan Wang et.al.|[2412.13103v1](http://arxiv.org/abs/2412.13103v1)|null|
|**2024-12-17**|**AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark**|Jianlyu Chen et.al.|[2412.13102v1](http://arxiv.org/abs/2412.13102v1)|[link](https://github.com/air-bench/air-bench)|
|**2024-12-17**|**Uchaguzi-2022: A Dataset of Citizen Reports on the 2022 Kenyan Election**|Roberto Mondini et.al.|[2412.13098v1](http://arxiv.org/abs/2412.13098v1)|null|
|**2024-12-17**|**LMUnit: Fine-grained Evaluation with Natural Language Unit Tests**|Jon Saad-Falcon et.al.|[2412.13091v1](http://arxiv.org/abs/2412.13091v1)|null|
|**2024-12-17**|**CLASP: Contrastive Language-Speech Pretraining for Multilingual Multimodal Information Retrieval**|Mohammad Mahdi Abootorabi et.al.|[2412.13071v1](http://arxiv.org/abs/2412.13071v1)|null|
|**2024-12-17**|**VidTok: A Versatile and Open-Source Video Tokenizer**|Anni Tang et.al.|[2412.13061v1](http://arxiv.org/abs/2412.13061v1)|[link](https://github.com/microsoft/vidtok)|
|**2024-12-17**|**Modality-Inconsistent Continual Learning of Multimodal Large Language Models**|Weiguo Pian et.al.|[2412.13050v1](http://arxiv.org/abs/2412.13050v1)|null|
|**2024-12-17**|**Harnessing Event Sensory Data for Error Pattern Prediction in Vehicles: A Language Model Approach**|Hugo Math et.al.|[2412.13041v1](http://arxiv.org/abs/2412.13041v1)|[link](https://github.com/Mathugo/AAAI2025-CarFormer-EPredictor)|
|**2024-12-17**|**NAVCON: A Cognitively Inspired and Linguistically Grounded Corpus for Vision and Language Navigation**|Karan Wanchoo et.al.|[2412.13026v1](http://arxiv.org/abs/2412.13026v1)|null|
|**2024-12-17**|**Relational Neurosymbolic Markov Models**|Lennert De Smet et.al.|[2412.13023v1](http://arxiv.org/abs/2412.13023v1)|null|
|**2024-12-17**|**OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in Financial Domain**|Shuting Wang et.al.|[2412.13018v1](http://arxiv.org/abs/2412.13018v1)|[link](https://github.com/ruc-nlpir/omnieval)|
|**2024-12-17**|**RCLMuFN: Relational Context Learning and Multiplex Fusion Network for Multimodal Sarcasm Detection**|Tongguan Wang et.al.|[2412.13008v1](http://arxiv.org/abs/2412.13008v1)|null|
|**2024-12-17**|**Enabling Low-Resource Language Retrieval: Establishing Baselines for Urdu MS MARCO**|Umer Butt et.al.|[2412.12997v1](http://arxiv.org/abs/2412.12997v1)|null|
|**2024-12-17**|**Cluster-guided Contrastive Class-imbalanced Graph Classification**|Wei Ju et.al.|[2412.12984v1](http://arxiv.org/abs/2412.12984v1)|null|
|**2024-12-17**|**Unlocking LLMs: Addressing Scarce Data and Bias Challenges in Mental Health**|Vivek Kumar et.al.|[2412.12981v1](http://arxiv.org/abs/2412.12981v1)|[link](https://github.com/vsrana-ai/IC-AnnoMI)|
|**2024-12-17**|**Adaptations of AI models for querying the LandMatrix database in natural language**|Fatiha Ait Kbir et.al.|[2412.12961v1](http://arxiv.org/abs/2412.12961v1)|[link](https://github.com/tetis-nlp/landmatrix-graphql-python)|
|**2024-12-17**|**SnakModel: Lessons Learned from Training an Open Danish Large Language Model**|Mike Zhang et.al.|[2412.12956v1](http://arxiv.org/abs/2412.12956v1)|[link](https://github.com/nlpnorth/snakmodel)|
|**2024-12-17**|**Learning from Noisy Labels via Self-Taught On-the-Fly Meta Loss Rescaling**|Michael Heck et.al.|[2412.12955v1](http://arxiv.org/abs/2412.12955v1)|null|
|**2024-12-17**|**Recipient Profiling: Predicting Characteristics from Messages**|Martin Borquez et.al.|[2412.12954v1](http://arxiv.org/abs/2412.12954v1)|null|
|**2024-12-17**|**MOPO: Multi-Objective Prompt Optimization for Affective Text Generation**|Yarik Menchaca Resendiz et.al.|[2412.12948v1](http://arxiv.org/abs/2412.12948v1)|null|
|**2024-12-17**|**Improving Fine-grained Visual Understanding in VLMs through Text-Only Training**|Dasol Choi et.al.|[2412.12940v1](http://arxiv.org/abs/2412.12940v1)|null|
|**2024-12-17**|**CoMT: A Novel Benchmark for Chain of Multi-modal Thought on Large Vision-Language Models**|Zihui Cheng et.al.|[2412.12932v1](http://arxiv.org/abs/2412.12932v1)|null|
|**2024-12-17**|**Spectra of Cardinality Queries over Description Logic Knowledge Bases**|Quentin Manière et.al.|[2412.12929v1](http://arxiv.org/abs/2412.12929v1)|null|
|**2024-12-17**|**Truthful Text Sanitization Guided by Inference Attacks**|Ildikó Pilán et.al.|[2412.12928v1](http://arxiv.org/abs/2412.12928v1)|null|
|**2024-12-17**|**Unsupervised Region-Based Image Editing of Denoising Diffusion Models**|Zixiang Li et.al.|[2412.12912v1](http://arxiv.org/abs/2412.12912v1)|null|
|**2024-12-17**|**An Agentic Approach to Automatic Creation of P&ID Diagrams from Natural Language Descriptions**|Shreeyash Gowaikar et.al.|[2412.12898v1](http://arxiv.org/abs/2412.12898v1)|null|
|**2024-12-17**|**Question: How do Large Language Models perform on the Question Answering tasks? Answer:**|Kevin Fischer et.al.|[2412.12893v1](http://arxiv.org/abs/2412.12893v1)|null|
|**2024-12-17**|**SAUGE: Taming SAM for Uncertainty-Aligned Multi-Granularity Edge Detection**|Xing Liufu et.al.|[2412.12892v1](http://arxiv.org/abs/2412.12892v1)|[link](https://github.com/Star-xing1/SAUGE)|
|**2024-12-17**|**ArtAug: Enhancing Text-to-Image Generation through Synthesis-Understanding Interaction**|Zhongjie Duan et.al.|[2412.12888v1](http://arxiv.org/abs/2412.12888v1)|[link](https://github.com/modelscope/DiffSynth-Studio)|
|**2024-12-17**|**A Comparative Study of Pruning Methods in Transformer-based Time Series Forecasting**|Nicholas Kiefer et.al.|[2412.12883v1](http://arxiv.org/abs/2412.12883v1)|null|
|**2024-12-17**|**RAG-Star: Enhancing Deliberative Reasoning with Retrieval Augmented Verification and Refinement**|Jinhao Jiang et.al.|[2412.12881v1](http://arxiv.org/abs/2412.12881v1)|null|
|**2024-12-17**|**Preference-Oriented Supervised Fine-Tuning: Favoring Target Model Over Aligned Large Language Models**|Yuchen Fan et.al.|[2412.12865v1](http://arxiv.org/abs/2412.12865v1)|[link](https://github.com/Savannah120/alignment-handbook-PoFT)|
|**2024-12-17**|**DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check**|Ziheng Qiao et.al.|[2412.12863v1](http://arxiv.org/abs/2412.12863v1)|null|
|**2024-12-17**|**Bayesian Persuasion with Externalities: Exploiting Agent Types**|Jonathan Shaki et.al.|[2412.12859v1](http://arxiv.org/abs/2412.12859v1)|null|
|**2024-12-17**|**Selective Shot Learning for Code Explanation**|Paheli Bhattacharya et.al.|[2412.12852v1](http://arxiv.org/abs/2412.12852v1)|null|
|**2024-12-17**|**Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**|Qingqing Fang et.al.|[2412.12850v1](http://arxiv.org/abs/2412.12850v1)|null|
|**2024-12-17**|**ClarityEthic: Explainable Moral Judgment Utilizing Contrastive Ethical Insights from Large Language Models**|Yuxi Sun et.al.|[2412.12848v1](http://arxiv.org/abs/2412.12848v1)|null|
|**2024-12-17**|**Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks**|Xiaxin Zhu et.al.|[2412.12843v1](http://arxiv.org/abs/2412.12843v1)|null|
|**2024-12-17**|**Benchmarking and Understanding Compositional Relational Reasoning of LLMs**|Ruikang Ni et.al.|[2412.12841v1](http://arxiv.org/abs/2412.12841v1)|[link](https://github.com/caiyun-ai/gar)|
|**2024-12-17**|**From An LLM Swarm To A PDDL-Empowered HIVE: Planning Self-Executed Instructions In A Multi-Modal Jungle**|Kaustubh Vyas et.al.|[2412.12839v1](http://arxiv.org/abs/2412.12839v1)|null|
|**2024-12-17**|**A Survey on Recommendation Unlearning: Fundamentals, Taxonomy, Evaluation, and Open Questions**|Yuyuan Li et.al.|[2412.12836v1](http://arxiv.org/abs/2412.12836v1)|null|
|**2024-12-17**|**DSGram: Dynamic Weighting Sub-Metrics for Grammatical Error Correction in the Era of Large Language Models**|Jinxiang Xie et.al.|[2412.12832v1](http://arxiv.org/abs/2412.12832v1)|[link](https://github.com/jxtse/GEC-Metrics-DSGram)|
|**2024-12-17**|**Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**|Ziqi Qiu et.al.|[2412.12808v1](http://arxiv.org/abs/2412.12808v1)|null|
|**2024-12-17**|**Cross-Dialect Information Retrieval: Information Access in Low-Resource and High-Variance Languages**|Robert Litschko et.al.|[2412.12806v1](http://arxiv.org/abs/2412.12806v1)|null|
|**2024-12-17**|**Breaking the Programming Language Barrier: Multilingual Prompting to Empower Non-Native English Learners**|James Prather et.al.|[2412.12800v1](http://arxiv.org/abs/2412.12800v1)|null|
|**2024-12-17**|**Is it the end of (generative) linguistics as we know it?**|Cristiano Chesi et.al.|[2412.12797v1](http://arxiv.org/abs/2412.12797v1)|null|
|**2024-12-17**|**Implicit Location-Caption Alignment via Complementary Masking for Weakly-Supervised Dense Video Captioning**|Shiping Ge et.al.|[2412.12791v1](http://arxiv.org/abs/2412.12791v1)|[link](https://github.com/ShipingGe/ILCACM)|
|**2024-12-17**|**Predicting change in time production -- A machine learning approach to time perception**|Amrapali Pednekar et.al.|[2412.12781v1](http://arxiv.org/abs/2412.12781v1)|null|
|**2024-12-17**|**Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**|Chengzhou Yu et.al.|[2412.12778v1](http://arxiv.org/abs/2412.12778v1)|null|
|**2024-12-17**|**Guided and Variance-Corrected Fusion with One-shot Style Alignment for Large-Content Image Generation**|Shoukun Sun et.al.|[2412.12771v1](http://arxiv.org/abs/2412.12771v1)|null|
|**2024-12-17**|**A Survey of Calibration Process for Black-Box LLMs**|Liangru Xie et.al.|[2412.12767v1](http://arxiv.org/abs/2412.12767v1)|null|
|**2024-12-17**|**Revealing the impact of synthetic native samples and multi-tasking strategies in Hindi-English code-mixed humour and sarcasm detection**|Debajyoti Mazumder et.al.|[2412.12761v1](http://arxiv.org/abs/2412.12761v1)|null|
|**2024-12-17**|**Your Next State-of-the-Art Could Come from Another Domain: A Cross-Domain Analysis of Hierarchical Text Classification**|Nan Li et.al.|[2412.12744v1](http://arxiv.org/abs/2412.12744v1)|null|
|**2024-12-17**|**GIRAFFE: Design Choices for Extending the Context Length of Visual Language Models**|Mukai Li et.al.|[2412.12735v1](http://arxiv.org/abs/2412.12735v1)|null|
|**2024-12-17**|**EventFull: Complete and Consistent Event Relation Annotation**|Alon Eirew et.al.|[2412.12733v1](http://arxiv.org/abs/2412.12733v1)|[link](https://github.com/AlonEirew/EventGraphAnnot)|
|**2024-12-17**|**SentiQNF: A Novel Approach to Sentiment Analysis Using Quantum Algorithms and Neuro-Fuzzy Systems**|Kshitij Dave et.al.|[2412.12731v1](http://arxiv.org/abs/2412.12731v1)|null|
|**2024-12-17**|**Defending LVLMs Against Vision Attacks through Partial-Perception Supervision**|Qi Zhou et.al.|[2412.12722v1](http://arxiv.org/abs/2412.12722v1)|null|
|**2024-12-17**|**Enhancing Naturalness in LLM-Generated Utterances through Disfluency Insertion**|Syed Zohaib Hassan et.al.|[2412.12710v1](http://arxiv.org/abs/2412.12710v1)|null|
|**2024-12-17**|**More Tokens, Lower Precision: Towards the Optimal Token-Precision Trade-off in KV Cache Compression**|Jiebin Zhang et.al.|[2412.12706v1](http://arxiv.org/abs/2412.12706v1)|null|
|**2024-12-17**|**Trigger$^3$: Refining Query Correction via Adaptive Model Selector**|Kepu Zhang et.al.|[2412.12701v1](http://arxiv.org/abs/2412.12701v1)|null|
|**2024-12-17**|**ParMod: A Parallel and Modular Framework for Learning Non-Markovian Tasks**|Ruixuan Miao et.al.|[2412.12700v1](http://arxiv.org/abs/2412.12700v1)|null|
|**2024-12-17**|**SPHERE: A Hierarchical Evaluation on Spatial Perception and Reasoning for Vision-Language Models**|Wenyu Zhang et.al.|[2412.12693v1](http://arxiv.org/abs/2412.12693v1)|null|
|**2024-12-17**|**XTransplant: A Probe into the Upper Bound Performance of Multilingual Capability and Culture Adaptability in LLMs via Mutual Cross-lingual Feed-forward Transplantation**|Yangfan Ye et.al.|[2412.12686v1](http://arxiv.org/abs/2412.12686v1)|[link](https://github.com/YYF-Tommy/XTransplant)|
|**2024-12-17**|**Detecting Document-level Paraphrased Machine Generated Content: Mimicking Human Writing Style and Involving Discourse Features**|Yupei Li et.al.|[2412.12679v1](http://arxiv.org/abs/2412.12679v1)|null|
|**2024-12-17**|**Train More Parameters But Mind Their Placement: Insights into Language Adaptation with PEFT**|Jenny Kunz et.al.|[2412.12674v1](http://arxiv.org/abs/2412.12674v1)|[link](https://github.com/jekunz/peft-la)|
|**2024-12-17**|**MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**|Hritik Bansal et.al.|[2412.12661v1](http://arxiv.org/abs/2412.12661v1)|[link](https://github.com/Hritikbansal/medmax)|
|**2024-12-17**|**Shared Attention-based Autoencoder with Hierarchical Fusion-based Graph Convolution Network for sEEG SOZ Identification**|Huachao Yan et.al.|[2412.12651v1](http://arxiv.org/abs/2412.12651v1)|null|
|**2024-12-17**|**Neural-Network-Driven Reward Prediction as a Heuristic: Advancing Q-Learning for Mobile Robot Path Planning**|Yiming Ji et.al.|[2412.12650v1](http://arxiv.org/abs/2412.12650v1)|null|
|**2024-12-17**|**iPrOp: Interactive Prompt Optimization for Large Language Models with a Human in the Loop**|Jiahui Li et.al.|[2412.12644v1](http://arxiv.org/abs/2412.12644v1)|null|
|**2024-12-17**|**LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**|Mufan Xu et.al.|[2412.12643v1](http://arxiv.org/abs/2412.12643v1)|null|
|**2024-12-17**|**RDPI: A Refine Diffusion Probability Generation Method for Spatiotemporal Data Imputation**|Zijin Liu et.al.|[2412.12642v1](http://arxiv.org/abs/2412.12642v1)|[link](https://github.com/liuzjin/RDPI)|
|**2024-12-17**|**Lagrangian Index Policy for Restless Bandits with Average Reward**|Konstantin Avrachenkov et.al.|[2412.12641v1](http://arxiv.org/abs/2412.12641v1)|null|
|**2024-12-17**|**Falcon: Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree**|Xiangxiang Gao et.al.|[2412.12639v1](http://arxiv.org/abs/2412.12639v1)|null|
|**2024-12-17**|**What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context**|Zhiyuan Chang et.al.|[2412.12632v1](http://arxiv.org/abs/2412.12632v1)|null|
|**2024-12-17**|**a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**|Pranav Rajpurkar et.al.|[2412.12629v1](http://arxiv.org/abs/2412.12629v1)|null|
|**2024-12-17**|**Make Imagination Clearer! Stable Diffusion-based Visual Imagination for Multimodal Machine Translation**|Andong Chen et.al.|[2412.12627v1](http://arxiv.org/abs/2412.12627v1)|null|
|**2024-12-17**|**Jailbreaking? One Step Is Enough!**|Weixiong Zheng et.al.|[2412.12621v1](http://arxiv.org/abs/2412.12621v1)|null|
|**2024-12-17**|**Phoneme-Level Feature Discrepancies: A Key to Detecting Sophisticated Speech Deepfakes**|Kuiyuan Zhang et.al.|[2412.12619v1](http://arxiv.org/abs/2412.12619v1)|null|
|**2024-12-17**|**SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**|Aman Tiwari et.al.|[2412.12612v1](http://arxiv.org/abs/2412.12612v1)|null|
|**2024-12-17**|**MultiLingPoT: Enhancing Mathematical Reasoning with Multilingual Program Fine-tuning**|Nianqi Li et.al.|[2412.12609v1](http://arxiv.org/abs/2412.12609v1)|[link](https://github.com/nianqi-li/multilingpot)|
|**2024-12-17**|**Multi-Dimensional Insights: Benchmarking Real-World Personalization in Large Multimodal Models**|YiFan Zhang et.al.|[2412.12606v1](http://arxiv.org/abs/2412.12606v1)|null|
|**2024-12-17**|**LLMs are Also Effective Embedding Models: An In-depth Overview**|Chongyang Tao et.al.|[2412.12591v1](http://arxiv.org/abs/2412.12591v1)|null|
|**2024-12-17**|**PerSphere: A Comprehensive Framework for Multi-Faceted Perspective Retrieval and Summarization**|Yun Luo et.al.|[2412.12588v1](http://arxiv.org/abs/2412.12588v1)|[link](https://github.com/LuoXiaoHeics/PerSphere)|
|**2024-12-17**|**Distributed satellite information networks: Architecture, enabling technologies, and trends**|Qinyu Zhang et.al.|[2412.12587v1](http://arxiv.org/abs/2412.12587v1)|null|
|**2024-12-17**|**Process-Supervised Reward Models for Clinical Note Generation: A Scalable Approach Guided by Domain Expertise**|Hanyin Wang et.al.|[2412.12583v1](http://arxiv.org/abs/2412.12583v1)|[link](https://github.com/hanyin88/prm-clinic)|
|**2024-12-17**|**SIDE: Socially Informed Drought Estimation Toward Understanding Societal Impact Dynamics of Environmental Crisis**|Lanyu Shang et.al.|[2412.12575v1](http://arxiv.org/abs/2412.12575v1)|null|
|**2024-12-17**|**License Plate Detection and Character Recognition Using Deep Learning and Font Evaluation**|Zahra Ebrahimi Vargoorani et.al.|[2412.12572v1](http://arxiv.org/abs/2412.12572v1)|null|

#### Abstracts
##### **ExBody2: Advanced Expressive Humanoid Whole-Body Control**
2412.13196v1 by Mazeyu Ji, Xuanbin Peng, Fangchen Liu, Jialong Li, Ge Yang, Xuxin Cheng, Xiaolong Wang

This paper enables real-world humanoid robots to maintain stability while
performing expressive motions like humans do. We propose ExBody2, a generalized
whole-body tracking framework that can take any reference motion inputs and
control the humanoid to mimic the motion. The model is trained in simulation
with Reinforcement Learning and then transferred to the real world. It
decouples keypoint tracking with velocity control, and effectively leverages a
privileged teacher policy to distill precise mimic skills into the target
student policy, which enables high-fidelity replication of dynamic movements
such as running, crouching, dancing, and other challenging motions. We present
a comprehensive qualitative and quantitative analysis of crucial design factors
in the paper. We conduct our experiments on two humanoid platforms and
demonstrate the superiority of our approach against state-of-the-arts,
providing practical guidelines to pursue the extreme of whole-body control for
humanoid robots.

摘要：這篇論文使真實世界的類人機器人在執行人類般的表現動作時能維持穩定。我們提出 ExBody2，一個廣泛化的全身追蹤架構，它可以接收任何參考動作輸入，並控制類人機器人模仿動作。模型在模擬中使用強化學習進行訓練，然後轉移到真實世界。它將關鍵點追蹤與速度控制分離，並有效地利用特權教師策略將精確的模仿技能提煉到目標學生策略中，這使得能夠高保真地複製動態動作，例如跑步、蹲伏、跳舞和其他具有挑戰性的動作。我們在論文中提出了關鍵設計因素的全面定性和定量分析。我們在兩個類人機器人平台上進行實驗，並展示了我們的方法優於現有技術，為追求類人機器人的全身控制極致提供了實用指南。

##### **Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents**
2412.13194v1 by Yifei Zhou, Qianlan Yang, Kaixiang Lin, Min Bai, Xiong Zhou, Yu-Xiong Wang, Sergey Levine, Erran Li

The vision of a broadly capable and goal-directed agent, such as an
Internet-browsing agent in the digital world and a household humanoid in the
physical world, has rapidly advanced, thanks to the generalization capability
of foundation models. Such a generalist agent needs to have a large and diverse
skill repertoire, such as finding directions between two travel locations and
buying specific items from the Internet. If each skill needs to be specified
manually through a fixed set of human-annotated instructions, the agent's skill
repertoire will necessarily be limited due to the quantity and diversity of
human-annotated instructions. In this work, we address this challenge by
proposing Proposer-Agent-Evaluator, an effective learning system that enables
foundation model agents to autonomously discover and practice skills in the
wild. At the heart of PAE is a context-aware task proposer that autonomously
proposes tasks for the agent to practice with context information of the
environment such as user demos or even just the name of the website itself for
Internet-browsing agents. Then, the agent policy attempts those tasks with
thoughts and actual grounded operations in the real world with resulting
trajectories evaluated by an autonomous VLM-based success evaluator. The
success evaluation serves as the reward signal for the agent to refine its
policies through RL. We validate PAE on challenging vision-based web
navigation, using both real-world and self-hosted websites from WebVoyager and
WebArena.To the best of our knowledge, this work represents the first effective
learning system to apply autonomous task proposal with RL for agents that
generalizes real-world human-annotated benchmarks with SOTA performances. Our
open-source checkpoints and code can be found in https://yanqval.github.io/PAE/

摘要：<paragraph>在數位世界中，例如網際網路瀏覽代理，以及在實體世界中，例如家庭人形機器人等，具備廣泛能力且目標導向的代理人的願景，已因基礎模型的泛化能力而快速進展。這種通才代理人需要具備廣泛且多樣化的技能庫，例如在兩個旅遊地點之間尋找方向，以及從網際網路上購買特定物品。如果每個技能都需要透過一組固定的、由人類註解的指令手動指定，那麼由於人類註解指令的數量和多樣性，代理人的技能庫勢必會受到限制。在這項工作中，我們透過提出建議者-代理人-評估者來解決這個挑戰，這是一個有效的學習系統，讓基礎模型代理人能夠在野外自主發現和練習技能。PAE 的核心是一個具備背景感知能力的任務建議者，它會根據環境的背景資訊（例如使用者的示範，甚至只是網際網路瀏覽代理人的網站名稱）自主建議任務讓代理人練習。然後，代理人策略會在真實世界中嘗試這些任務，並進行思考和實際的紮實操作，而產生的軌跡則由一個自主的、基於 VLM 的成功評估器進行評估。成功評估會作為回饋訊號，讓代理人透過 RL 來改善其策略。我們在具挑戰性的、基於視覺的網路導覽中驗證 PAE，使用 WebVoyager 和 WebArena 的真實世界和自架網站。據我們所知，這項工作代表了第一個有效的學習系統，它將自主任務建議與 RL 應用於代理人，並使用 SOTA 效能概化了真實世界的、由人類註解的基準。我們的開源檢查點和程式碼可以在 https://yanqval.github.io/PAE/ 中找到。</paragraph>

##### **Tilted Quantile Gradient Updates for Quantile-Constrained Reinforcement Learning**
2412.13184v1 by Chenglin Li, Guangchun Ruan, Hua Geng

Safe reinforcement learning (RL) is a popular and versatile paradigm to learn
reward-maximizing policies with safety guarantees. Previous works tend to
express the safety constraints in an expectation form due to the ease of
implementation, but this turns out to be ineffective in maintaining safety
constraints with high probability. To this end, we move to the
quantile-constrained RL that enables a higher level of safety without any
expectation-form approximations. We directly estimate the quantile gradients
through sampling and provide the theoretical proofs of convergence. Then a
tilted update strategy for quantile gradients is implemented to compensate the
asymmetric distributional density, with a direct benefit of return performance.
Experiments demonstrate that the proposed model fully meets safety requirements
(quantile constraints) while outperforming the state-of-the-art benchmarks with
higher return.

摘要：安全強化學習 (RL) 是一種流行且通用的範例，用於學習具有安全保證的獎勵最大化政策。由於易於實作，先前的研究傾向於以期望形式表達安全約束，但這在維持高機率的安全約束方面被證明是無效的。為此，我們轉向分位數約束 RL，它可以在沒有任何期望形式近似的情況下實現更高的安全級別。我們直接透過取樣估計分位數梯度，並提供收斂的理論證明。然後實作分位數梯度的傾斜更新策略，以補償非對稱分佈密度，並直接提升回報效能。實驗證明，所提出的模型完全符合安全要求（分位數約束），同時在更高的回報下優於最先進的基準。

##### **SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents**
2412.13178v1 by Sheng Yin, Xianghe Pang, Yuanzhuo Ding, Menglan Chen, Yutong Bi, Yichen Xiong, Wenhao Huang, Zhen Xiang, Jing Shao, Siheng Chen

With the integration of large language models (LLMs), embodied agents have
strong capabilities to execute complicated instructions in natural language,
paving a way for the potential deployment of embodied robots. However, a
foreseeable issue is that those embodied agents can also flawlessly execute
some hazardous tasks, potentially causing damages in real world. To study this
issue, we present SafeAgentBench -- a new benchmark for safety-aware task
planning of embodied LLM agents. SafeAgentBench includes: (1) a new dataset
with 750 tasks, covering 10 potential hazards and 3 task types; (2)
SafeAgentEnv, a universal embodied environment with a low-level controller,
supporting multi-agent execution with 17 high-level actions for 8
state-of-the-art baselines; and (3) reliable evaluation methods from both
execution and semantic perspectives. Experimental results show that the
best-performing baseline gets 69% success rate for safe tasks, but only 5%
rejection rate for hazardous tasks, indicating significant safety risks. More
details and codes are available at
https://github.com/shengyin1224/SafeAgentBench.

摘要：隨著大型語言模型 (LLM) 的整合，具象代理擁有以自然語言執行複雜指令的強大能力，為具象機器人的潛在部署鋪平了道路。然而，一個可預見的問題是，這些具象代理也可以完美執行一些危險的任務，潛在地對現實世界造成損害。為了研究這個問題，我們提出了 SafeAgentBench——一個新的基準，用於具象 LLM 代理的安全感知任務規劃。SafeAgentBench 包括：(1) 一個擁有 750 個任務的新數據集，涵蓋 10 個潛在危害和 3 個任務類型；(2) SafeAgentEnv，一個帶有低級控制器的通用具象環境，支持使用 17 個高級動作對 8 個最先進的基準進行多代理執行；以及 (3) 來自執行和語義角度的可靠評估方法。實驗結果表明，表現最佳的基準在安全任務中獲得了 69% 的成功率，但在危險任務中的拒絕率僅為 5%，表明存在顯著的安全風險。更多詳細信息和代碼可在 https://github.com/shengyin1224/SafeAgentBench 中找到。

##### **DnDScore: Decontextualization and Decomposition for Factuality Verification in Long-Form Text Generation**
2412.13175v1 by Miriam Wanner, Benjamin Van Durme, Mark Dredze

The decompose-then-verify strategy for verification of Large Language Model
(LLM) generations decomposes claims that are then independently verified.
Decontextualization augments text (claims) to ensure it can be verified outside
of the original context, enabling reliable verification. While decomposition
and decontextualization have been explored independently, their interactions in
a complete system have not been investigated. Their conflicting purposes can
create tensions: decomposition isolates atomic facts while decontextualization
inserts relevant information. Furthermore, a decontextualized subclaim presents
a challenge to the verification step: what part of the augmented text should be
verified as it now contains multiple atomic facts? We conduct an evaluation of
different decomposition, decontextualization, and verification strategies and
find that the choice of strategy matters in the resulting factuality scores.
Additionally, we introduce DnDScore, a decontextualization aware verification
method which validates subclaims in the context of contextual information.

摘要：大型語言模型 (LLM) 生成驗證的分解後驗證策略分解聲明，然後獨立驗證這些聲明。
去脈絡化擴充文字（聲明）以確保可以在原始脈絡之外驗證，從而實現可靠的驗證。
儘管分解和去脈絡化已經獨立探索，但它們在一個完整系統中的交互作用尚未得到研究。
它們相互衝突的目的可能會造成緊張：分解孤立原子事實，而去脈絡化插入相關資訊。
此外，去脈絡化的子聲明對驗證步驟提出了挑戰：應驗證擴充文字的哪一部分，因為它現在包含多個原子事實？
我們對不同的分解、去脈絡化和驗證策略進行評估，並發現策略的選擇會影響產生的真實性分數。
此外，我們引入了 DnDScore，這是一種去脈絡化感知驗證方法，它在脈絡資訊的背景下驗證子聲明。

##### **Compressed Chain of Thought: Efficient Reasoning Through Dense Representations**
2412.13171v1 by Jeffrey Cheng, Benjamin Van Durme

Chain-of-thought (CoT) decoding enables language models to improve reasoning
performance at the cost of high generation latency in decoding. Recent
proposals have explored variants of contemplation tokens, a term we introduce
that refers to special tokens used during inference to allow for extra
computation. Prior work has considered fixed-length sequences drawn from a
discrete set of embeddings as contemplation tokens. Here we propose Compressed
Chain-of-Thought (CCoT), a framework to generate contentful and continuous
contemplation tokens of variable sequence length. The generated contemplation
tokens are compressed representations of explicit reasoning chains, and our
method can be applied to off-the-shelf decoder language models. Through
experiments, we illustrate how CCoT enables additional reasoning over dense
contentful representations to achieve corresponding improvements in accuracy.
Moreover, the reasoning improvements can be adaptively modified on demand by
controlling the number of contemplation tokens generated.

摘要：鏈式思考 (CoT) 解碼讓語言模型能夠改善推理效能，代價是解碼時產生較高的生成延遲。最近的提案探索了沉思標記的變體，我們引入了一個術語來指稱在推論期間用於允許額外運算的特殊標記。先前的研究將從離散嵌入集合中抽取的固定長度序列視為沉思標記。在此，我們提出壓縮鏈式思考 (CCoT)，一個用於產生內容豐富且連續的變長沉思標記的架構。產生的沉思標記是明確推理鏈的壓縮表示，而我們的模型可以應用於現成的解碼器語言模型。透過實驗，我們說明 CCoT 如何在密集的內容豐富表示中進行額外的推理，以達成相應的準確性改善。此外，推理改善可以透過控制產生的沉思標記數量，依需求進行適應性修改。

##### **Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study**
2412.13169v1 by Bolei Ma, Berk Yoztyurk, Anna-Carolina Haensch, Xinpeng Wang, Markus Herklotz, Frauke Kreuter, Barbara Plank, Matthias Assenmacher

In recent research, large language models (LLMs) have been increasingly used
to investigate public opinions. This study investigates the algorithmic
fidelity of LLMs, i.e., the ability to replicate the socio-cultural context and
nuanced opinions of human participants. Using open-ended survey data from the
German Longitudinal Election Studies (GLES), we prompt different LLMs to
generate synthetic public opinions reflective of German subpopulations by
incorporating demographic features into the persona prompts. Our results show
that Llama performs better than other LLMs at representing subpopulations,
particularly when there is lower opinion diversity within those groups. Our
findings further reveal that the LLM performs better for supporters of
left-leaning parties like The Greens and The Left compared to other parties,
and matches the least with the right-party AfD. Additionally, the inclusion or
exclusion of specific variables in the prompts can significantly impact the
models' predictions. These findings underscore the importance of aligning LLMs
to more effectively model diverse public opinions while minimizing political
biases and enhancing robustness in representativeness.

摘要：在最近的研究中，大型语言模型（LLM）被越来越多地用于调查公众舆论。本研究调查了 LLM 的算法保真度，即复制人类参与者的社会文化背景和细微意见的能力。使用来自德国纵向选举研究（GLES）的开放式调查数据，我们提示不同的 LLM 通过将人口特征纳入角色提示来生成反映德国亚群的合成公众舆论。我们的结果表明，Llama 在代表亚群方面比其他 LLM 表现得更好，尤其是在这些群体中意见分歧较低的情况下。我们的研究结果进一步表明，与其他政党相比，LLM 对绿党和左翼等左倾政党的支持者表现得更好，并且与右翼政党德国选择党最不匹配。此外，提示中特定变量的包含或排除会显著影响模型的预测。这些发现强调了调整 LLM 以更有效地模拟不同的公众舆论同时最大限度地减少政治偏见并提高代表性的稳健性的重要性。

##### **Lifting Scheme-Based Implicit Disentanglement of Emotion-Related Facial Dynamics in the Wild**
2412.13168v1 by Xingjian Wang, Li Chai

In-the-wild Dynamic facial expression recognition (DFER) encounters a
significant challenge in recognizing emotion-related expressions, which are
often temporally and spatially diluted by emotion-irrelevant expressions and
global context respectively. Most of the prior DFER methods model tightly
coupled spatiotemporal representations which may incorporate weakly relevant
features, leading to information redundancy and emotion-irrelevant context
bias. Several DFER methods have highlighted the significance of dynamic
information, but utilize explicit manners to extract dynamic features with
overly strong prior knowledge. In this paper, we propose a novel Implicit
Facial Dynamics Disentanglement framework (IFDD). Through expanding wavelet
lifting scheme to fully learnable framework, IFDD disentangles emotion-related
dynamic information from emotion-irrelevant global context in an implicit
manner, i.e., without exploit operations and external guidance. The
disentanglement process of IFDD contains two stages, i.e., Inter-frame
Static-dynamic Splitting Module (ISSM) for rough disentanglement estimation and
Lifting-based Aggregation-Disentanglement Module (LADM) for further refinement.
Specifically, ISSM explores inter-frame correlation to generate content-aware
splitting indexes on-the-fly. We preliminarily utilize these indexes to split
frame features into two groups, one with greater global similarity, and the
other with more unique dynamic features. Subsequently, LADM first aggregates
these two groups of features to obtain fine-grained global context features by
an updater, and then disentangles emotion-related facial dynamic features from
the global context by a predictor. Extensive experiments on in-the-wild
datasets have demonstrated that IFDD outperforms prior supervised DFER methods
with higher recognition accuracy and comparable efficiency.

摘要：在自然環境中，動態人臉表情辨識 (DFER) 在辨識情緒相關表情時會遭遇重大挑戰，這些表情通常會被與情緒無關的表情和整體環境在時間和空間上稀釋。大多數先前的 DFER 方法會建模緊密結合的時空表示，這可能會納入相關性較弱的特徵，導致資訊冗餘和與情緒無關的環境偏差。多種 DFER 方法強調動態資訊的重要性，但使用明確的方式來擷取具有過度強先驗知識的動態特徵。在本文中，我們提出了一個新穎的隱式人臉動態分離框架 (IFDD)。透過將小波提升方案擴展到完全可學習的框架，IFDD 以隱式的方式（即不利用運算和外部指導）將與情緒相關的動態資訊從與情緒無關的整體環境中分離出來。IFDD 的分離過程包含兩個階段，即用於粗略分離估計的幀間靜態動態分離模組 (ISSM) 和用於進一步精煉的基於提升的聚合分離模組 (LADM)。具體來說，ISSM 探索幀間關聯性以即時產生內容感知的分離索引。我們初步利用這些索引將幀特徵分成兩組，一組具有較高的整體相似性，另一組具有更多獨特的動態特徵。隨後，LADM 首先聚合這兩組特徵，以透過更新器取得細緻的整體環境特徵，然後透過預測器將與情緒相關的人臉動態特徵從整體環境中分離出來。在自然環境中的資料集上進行的廣泛實驗已證明，IFDD 的表現優於先前的監督式 DFER 方法，具有更高的辨識準確度和可比較的效率。

##### **BanglishRev: A Large-Scale Bangla-English and Code-mixed Dataset of Product Reviews in E-Commerce**
2412.13161v1 by Mohammad Nazmush Shamael, Sabila Nawshin, Swakkhar Shatabda, Salekul Islam

This work presents the BanglishRev Dataset, the largest e-commerce product
review dataset to date for reviews written in Bengali, English, a mixture of
both and Banglish, Bengali words written with English alphabets. The dataset
comprises of 1.74 million written reviews from 3.2 million ratings information
collected from a total of 128k products being sold in online e-commerce
platforms targeting the Bengali population. It includes an extensive array of
related metadata for each of the reviews including the rating given by the
reviewer, date the review was posted and date of purchase, number of likes,
dislikes, response from the seller, images associated with the review etc. With
sentiment analysis being the most prominent usage of review datasets,
experimentation with a binary sentiment analysis model with the review rating
serving as an indicator of positive or negative sentiment was conducted to
evaluate the effectiveness of the large amount of data presented in BanglishRev
for sentiment analysis tasks. A BanglishBERT model is trained on the data from
BanglishRev with reviews being considered labeled positive if the rating is
greater than 3 and negative if the rating is less than or equal to 3. The model
is evaluated by being testing against a previously published manually annotated
dataset for e-commerce reviews written in a mixture of Bangla, English and
Banglish. The experimental model achieved an exceptional accuracy of 94\% and
F1 score of 0.94, demonstrating the dataset's efficacy for sentiment analysis.
Some of the intriguing patterns and observations seen within the dataset and
future research directions where the dataset can be utilized is also discussed
and explored. The dataset can be accessed through
https://huggingface.co/datasets/BanglishRev/bangla-english-and-code-mixed-ecommerce-review-dataset.

摘要：<paragraph>這項工作呈現了 BanglishRev 資料集，這是迄今為止最大的電子商務產品評論資料集，用於以孟加拉語、英語、孟加拉語和英語的混合以及孟加拉語（用英語字母書寫的孟加拉語單字）撰寫的評論。該資料集包含來自 128k 個產品的 320 萬個評分資訊中撰寫的 174 萬個評論，這些產品在針對孟加拉人口的線上電子商務平台上銷售。它包含每個評論的大量相關元資料，包括評論者給出的評分、評論發布日期和購買日期、按讚數、不按讚數、賣方的回應、與評論相關的圖片等。由於情緒分析是評論資料集最突出的用途，因此使用二元情緒分析模型進行實驗，其中評論評分作為正面或負面情緒的指標，以評估 BanglishRev 中呈現的大量資料在情緒分析任務中的有效性。BanglishBERT 模型在 BanglishRev 中的資料上訓練，如果評分大於 3，則評論被視為正面，如果評分小於或等於 3，則被視為負面。該模型的評估方式是針對先前發布的手動註解資料集進行測試，該資料集包含用孟加拉語、英語和孟加拉語混合撰寫的電子商務評論。實驗模型達到了 94% 的出色準確率和 0.94 的 F1 分數，證明了該資料集在情緒分析中的功效。還討論和探討了資料集中看到的一些有趣模式和觀察結果，以及可以利用該資料集的未來研究方向。該資料集可透過 https://huggingface.co/datasets/BanglishRev/bangla-english-and-code-mixed-ecommerce-review-dataset 存取。</paragraph>

##### **SWAN: Preprocessing SGD Enables Adam-Level Performance On LLM Training With Significant Memory Reduction**
2412.13148v1 by Chao Ma, Wenbo Gong, Meyer Scetbon, Edward Meeds

Adaptive optimizers such as Adam (Kingma & Ba, 2015) have been central to the
success of large language models. However, they maintain additional moving
average states throughout training, which results in memory requirements
several times greater than the model. This overhead imposes constraints on
scalability and computational efficiency. On the other hand, while stochastic
gradient descent (SGD) is optimal in terms of memory efficiency, their
capability in LLM training is limited (Zhao et al., 2024b).
  To address this dilemma, we show that pre-processing SGD is sufficient to
reach Adam-level performance on LLMs. Specifically, we propose to preprocess
the instantaneous stochastic gradients with two simple operators:
$\mathtt{GradNorm}$ and $\mathtt{GradWhitening}$. $\mathtt{GradNorm}$
stabilizes gradient distributions, and $\mathtt{GradWhitening}$ counteracts the
local curvature of the loss landscape, respectively. This results in SWAN (SGD
with Whitening And Normalization), a stochastic optimizer that eliminates the
need to store any accumulative state variables. Empirically, SWAN has the same
memory footprint as SGD, achieving $\approx 50\%$ reduction on total end-to-end
memory compared to Adam. In language modeling tasks, SWAN demonstrates the same
or even a substantial improvement over Adam. Specifically, when pre-training
the LLaMa model with 350M and 1.3B parameters, SWAN achieves a 2x speedup by
reaching the same evaluation perplexity in less than half tokens seen.

摘要：自適應優化器，例如 Adam (Kingma & Ba, 2015) 一直是大型語言模型成功的關鍵。然而，它們在整個訓練過程中維護額外的移動平均狀態，這導致記憶體需求比模型大好幾倍。這種負擔對可擴充性和計算效率造成限制。另一方面，雖然隨機梯度下降 (SGD) 在記憶體效率方面是最佳的，但其在 LLM 訓練中的能力有限 (Zhao 等人，2024b)。
為了解決這個兩難困境，我們表明預處理 SGD 足以在 LLM 上達到 Adam 級別的效能。具體來說，我們建議使用兩個簡單的運算子對瞬時隨機梯度進行預處理：
$\mathtt{GradNorm}$ 和 $\mathtt{GradWhitening}$。$\mathtt{GradNorm}$ 穩定梯度分佈，而 $\mathtt{GradWhitening}$ 分別抵消損失景觀的局部曲率。這產生了 SWAN（具有白化和正規化的 SGD），這是一個隨機優化器，消除了儲存任何累積狀態變數的需要。根據經驗，SWAN 與 SGD 具有相同的記憶體佔用空間，與 Adam 相比，總端到端記憶體減少了大約 50%。在語言建模任務中，SWAN 展示出與 Adam 相同甚至大幅改善的效能。具體來說，在使用 350M 和 1.3B 參數預訓練 LLaMa 模型時，SWAN 在觀察到的符號少於一半的情況下達到相同的評估困惑度，從而實現了 2 倍的加速。

##### **Are Your LLMs Capable of Stable Reasoning?**
2412.13147v1 by Junnan Liu, Hongwei Liu, Linchen Xiao, Ziyi Wang, Kuikun Liu, Songyang Gao, Wenwei Zhang, Songyang Zhang, Kai Chen

The rapid advancement of Large Language Models (LLMs) has demonstrated
remarkable progress in complex reasoning tasks. However, a significant
discrepancy persists between benchmark performances and real-world
applications. We identify this gap as primarily stemming from current
evaluation protocols and metrics, which inadequately capture the full spectrum
of LLM capabilities, particularly in complex reasoning tasks where both
accuracy and consistency are crucial. This work makes two key contributions.
First, we introduce G-Pass@k, a novel evaluation metric that provides a
continuous assessment of model performance across multiple sampling attempts,
quantifying both the model's peak performance potential and its stability.
Second, we present LiveMathBench, a dynamic benchmark comprising challenging,
contemporary mathematical problems designed to minimize data leakage risks
during evaluation. Through extensive experiments using G-Pass@k on
state-of-the-art LLMs with LiveMathBench, we provide comprehensive insights
into both their maximum capabilities and operational consistency. Our findings
reveal substantial room for improvement in LLMs' "realistic" reasoning
capabilities, highlighting the need for more robust evaluation methods. The
benchmark and detailed results are available at:
https://github.com/open-compass/GPassK.

摘要：大型語言模型 (LLM) 的快速進步已證明在複雜推理任務中取得顯著進展。然而，基準效能和實際應用之間仍存在顯著差異。我們將此差距主要歸因於當前的評估協定和指標，這些協定和指標未能充分掌握 LLM 能力的全部範圍，特別是在準確性和一致性都很重要的複雜推理任務中。這項工作做出了兩項關鍵貢獻。首先，我們引入了 G-Pass@k，這是一種新穎的評估指標，它提供了對模型效能的持續評估，涵蓋了多次抽樣嘗試，量化了模型的峰值效能潛力及其穩定性。其次，我們提出了 LiveMathBench，這是一個動態基準，包含具有挑戰性的當代數學問題，旨在最大程度地降低評估期間的數據洩露風險。通過在 LiveMathBench 上使用 G-Pass@k 對最先進的 LLM 進行廣泛的實驗，我們對其最大能力和運作一致性提供了全面的見解。我們的發現揭示了 LLM 的「實際」推理能力有很大的改進空間，強調了需要更強大的評估方法。基準和詳細結果可在以下網址獲得：https://github.com/open-compass/GPassK。

##### **Syntactic Transfer to Kyrgyz Using the Treebank Translation Method**
2412.13146v1 by Anton Alekseev, Alina Tillabaeva, Gulnara Dzh. Kabaeva, Sergey I. Nikolenko

The Kyrgyz language, as a low-resource language, requires significant effort
to create high-quality syntactic corpora. This study proposes an approach to
simplify the development process of a syntactic corpus for Kyrgyz. We present a
tool for transferring syntactic annotations from Turkish to Kyrgyz based on a
treebank translation method. The effectiveness of the proposed tool was
evaluated using the TueCL treebank. The results demonstrate that this approach
achieves higher syntactic annotation accuracy compared to a monolingual model
trained on the Kyrgyz KTMU treebank. Additionally, the study introduces a
method for assessing the complexity of manual annotation for the resulting
syntactic trees, contributing to further optimization of the annotation
process.

摘要：吉爾吉斯語作為一種低資源語言，需要大量的努力才能建立高質量的句法語料庫。本研究提出了一種簡化吉爾吉斯語句法語料庫開發過程的方法。我們提出了一個基於樹庫翻譯方法，將土耳其語的句法註解轉移到吉爾吉斯語的工具。使用 TueCL 樹庫評估了所提出工具的有效性。結果表明，與在吉爾吉斯語 KTMU 樹庫上訓練的單語模型相比，這種方法實現了更高的句法註解準確度。此外，本研究還介紹了一種評估所得句法樹手動註解複雜性的方法，有助於進一步優化註解過程。

##### **Improving Explainability of Sentence-level Metrics via Edit-level Attribution for Grammatical Error Correction**
2412.13110v1 by Takumi Goto, Justin Vasselli, Taro Watanabe

Various evaluation metrics have been proposed for Grammatical Error
Correction (GEC), but many, particularly reference-free metrics, lack
explainability. This lack of explainability hinders researchers from analyzing
the strengths and weaknesses of GEC models and limits the ability to provide
detailed feedback for users. To address this issue, we propose attributing
sentence-level scores to individual edits, providing insight into how specific
corrections contribute to the overall performance. For the attribution method,
we use Shapley values, from cooperative game theory, to compute the
contribution of each edit. Experiments with existing sentence-level metrics
demonstrate high consistency across different edit granularities and show
approximately 70\% alignment with human evaluations. In addition, we analyze
biases in the metrics based on the attribution results, revealing trends such
as the tendency to ignore orthographic edits. Our implementation is available
at \url{https://github.com/naist-nlp/gec-attribute}.

摘要：各種評估指標已針對語法錯誤校正 (GEC) 提出，但許多指標，特別是無參考指標，缺乏可解釋性。這種可解釋性的缺乏阻礙研究人員分析 GEC 模型的優缺點，並限制提供詳細使用者回饋的能力。為了解決此問題，我們建議將句子層級分數歸因於個別編輯，提供特定校正如何有助於整體效能的見解。對於歸因方法，我們使用合作博弈論中的 Shapley 值來計算每個編輯的貢獻。使用現有句子層級指標進行的實驗顯示，在不同編輯粒度之間具有一致性，並顯示與人類評估約有 70% 的一致性。此外，我們根據歸因結果分析指標中的偏差，揭示出忽略拼字編輯等趨勢。我們的實作可於\url{https://github.com/naist-nlp/gec-attribute}取得。

##### **AI PERSONA: Towards Life-long Personalization of LLMs**
2412.13103v1 by Tiannan Wang, Meiling Tao, Ruoyu Fang, Huilin Wang, Shuai Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou

In this work, we introduce the task of life-long personalization of large
language models. While recent mainstream efforts in the LLM community mainly
focus on scaling data and compute for improved capabilities of LLMs, we argue
that it is also very important to enable LLM systems, or language agents, to
continuously adapt to the diverse and ever-changing profiles of every distinct
user and provide up-to-date personalized assistance. We provide a clear task
formulation and introduce a simple, general, effective, and scalable framework
for life-long personalization of LLM systems and language agents. To facilitate
future research on LLM personalization, we also introduce methods to synthesize
realistic benchmarks and robust evaluation metrics. We will release all codes
and data for building and benchmarking life-long personalized LLM systems.

摘要：在這項工作中，我們引入了大型語言模型終身個人化的任務。雖然 LLM 社群中近期的主流努力主要集中在擴展資料和運算以提升 LLM 的能力，我們主張讓 LLM 系統或語言代理持續適應每位不同使用者的多元且不斷變化的個人資料，並提供最新的個人化協助，這也十分重要。我們提供了明確的任務表述，並為 LLM 系統和語言代理的終身個人化引入了簡單、通用、有效且可擴充的架構。為了促進未來對 LLM 個人化的研究，我們也引入了合成實際基準和穩健評估指標的方法。我們將釋出所有用於建構和基準化終身個人化 LLM 系統的程式碼和資料。

##### **AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark**
2412.13102v1 by Jianlyu Chen, Nan Wang, Chaofan Li, Bo Wang, Shitao Xiao, Han Xiao, Hao Liao, Defu Lian, Zheng Liu

Evaluation plays a crucial role in the advancement of information retrieval
(IR) models. However, current benchmarks, which are based on predefined domains
and human-labeled data, face limitations in addressing evaluation needs for
emerging domains both cost-effectively and efficiently. To address this
challenge, we propose the Automated Heterogeneous Information Retrieval
Benchmark (AIR-Bench). AIR-Bench is distinguished by three key features: 1)
Automated. The testing data in AIR-Bench is automatically generated by large
language models (LLMs) without human intervention. 2) Heterogeneous. The
testing data in AIR-Bench is generated with respect to diverse tasks, domains
and languages. 3) Dynamic. The domains and languages covered by AIR-Bench are
constantly augmented to provide an increasingly comprehensive evaluation
benchmark for community developers. We develop a reliable and robust data
generation pipeline to automatically create diverse and high-quality evaluation
datasets based on real-world corpora. Our findings demonstrate that the
generated testing data in AIR-Bench aligns well with human-labeled testing
data, making AIR-Bench a dependable benchmark for evaluating IR models. The
resources in AIR-Bench are publicly available at
https://github.com/AIR-Bench/AIR-Bench.

摘要：評估在資訊檢索 (IR) 模型的進步中扮演著至關重要的角色。然而，目前的基準，基於預先定義的網域和人工標記的資料，在以成本效益且有效率的方式滿足新興網域的評估需求方面面臨限制。為了應對這項挑戰，我們提出自動化異質資訊檢索基準 (AIR-Bench)。AIR-Bench 的特點在於三個關鍵特徵：1) 自動化。AIR-Bench 中的測試資料是由大型語言模型 (LLM) 在沒有人工介入的情況下自動產生的。2) 異質性。AIR-Bench 中的測試資料是針對不同的任務、網域和語言產生的。3) 動態性。AIR-Bench 涵蓋的網域和語言不斷增加，為社群開發人員提供越來越全面的評估基準。我們開發出一條可靠且穩健的資料產生管道，以自動建立基於真實世界語料庫的多樣化且高品質的評估資料集。我們的研究結果表明，AIR-Bench 中產生的測試資料與人工標記的測試資料非常吻合，這使得 AIR-Bench 成為評估 IR 模型的可靠基準。AIR-Bench 中的資源可於 https://github.com/AIR-Bench/AIR-Bench 公開取得。

##### **Uchaguzi-2022: A Dataset of Citizen Reports on the 2022 Kenyan Election**
2412.13098v1 by Roberto Mondini, Neema Kotonya, Robert L. Logan IV, Elizabeth M Olson, Angela Oduor Lungati, Daniel Duke Odongo, Tim Ombasa, Hemank Lamba, Aoife Cahill, Joel R. Tetreault, Alejandro Jaimes

Online reporting platforms have enabled citizens around the world to
collectively share their opinions and report in real time on events impacting
their local communities. Systematically organizing (e.g., categorizing by
attributes) and geotagging large amounts of crowdsourced information is crucial
to ensuring that accurate and meaningful insights can be drawn from this data
and used by policy makers to bring about positive change. These tasks, however,
typically require extensive manual annotation efforts. In this paper we present
Uchaguzi-2022, a dataset of 14k categorized and geotagged citizen reports
related to the 2022 Kenyan General Election containing mentions of
election-related issues such as official misconduct, vote count irregularities,
and acts of violence. We use this dataset to investigate whether language
models can assist in scalably categorizing and geotagging reports, thus
highlighting its potential application in the AI for Social Good space.

摘要：線上回報平台讓全球公民得以共同分享意見，並即時回報影響當地社群的事件。系統化地整理（例如依屬性分類）並對大量群眾外包資訊進行地理標記，對於確保能從這些資料中汲取準確且有意義的見解，並供決策者用於帶來正面改變至關重要。然而，這些任務通常需要廣泛的手動標註工作。在本文中，我們將介紹 Uchaguzi-2022，這是一個包含 14k 個分類且帶有地理標記的公民報告資料集，與 2022 年肯亞大選有關，其中包含提及官方不當行為、計票不規則和暴力行為等與選舉相關的問題。我們使用此資料集來調查語言模型是否可以協助擴充分類和地理標記報告，從而突顯其在 AI for Social Good 領域的潛在應用。

##### **LMUnit: Fine-grained Evaluation with Natural Language Unit Tests**
2412.13091v1 by Jon Saad-Falcon, Rajan Vivek, William Berrios, Nandita Shankar Naik, Matija Franklin, Bertie Vidgen, Amanpreet Singh, Douwe Kiela, Shikib Mehri

As language models become integral to critical workflows, assessing their
behavior remains a fundamental challenge -- human evaluation is costly and
noisy, while automated metrics provide only coarse, difficult-to-interpret
signals. We introduce natural language unit tests, a paradigm that decomposes
response quality into explicit, testable criteria, along with a unified scoring
model, LMUnit, which combines multi-objective training across preferences,
direct ratings, and natural language rationales. Through controlled human
studies, we show this paradigm significantly improves inter-annotator agreement
and enables more effective LLM development workflows. LMUnit achieves
state-of-the-art performance on evaluation benchmarks (FLASK, BigGenBench) and
competitive results on RewardBench. These results validate both our proposed
paradigm and scoring model, suggesting a promising path forward for language
model evaluation and development.

摘要：隨著語言模型成為關鍵工作流程中不可或缺的一部分，評估其行為仍然是一項基本挑戰——人工評估成本高昂且嘈雜，而自動化指標僅提供粗略、難以解釋的訊號。我們引入了自然語言單元測試，這是一種將回應品質分解為明確、可測試標準的範例，並結合了統一評分模型 LMUnit，它結合了跨偏好、直接評分和自然語言依據的多目標訓練。透過受控的人類研究，我們表明這個範例顯著改善了標記者間的一致性，並實現了更有效的 LLM 開發工作流程。LMUnit 在評估基準（FLASK、BigGenBench）上取得了最先進的效能，並且在 RewardBench 上取得了具有競爭力的結果。這些結果驗證了我們提出的範例和評分模型，為語言模型評估和開發提出了有希望的前進道路。

##### **CLASP: Contrastive Language-Speech Pretraining for Multilingual Multimodal Information Retrieval**
2412.13071v1 by Mohammad Mahdi Abootorabi, Ehsaneddin Asgari

This study introduces CLASP (Contrastive Language-Speech Pretraining), a
multilingual, multimodal representation tailored for audio-text information
retrieval. CLASP leverages the synergy between spoken content and textual data.
During training, we utilize our newly introduced speech-text dataset, which
encompasses 15 diverse categories ranging from fiction to religion. CLASP's
audio component integrates audio spectrograms with a pre-trained
self-supervised speech model, while its language encoding counterpart employs a
sentence encoder pre-trained on over 100 languages. This unified lightweight
model bridges the gap between various modalities and languages, enhancing its
effectiveness in handling and retrieving multilingual and multimodal data. Our
evaluations across multiple languages demonstrate that CLASP establishes new
benchmarks in HITS@1, MRR, and meanR metrics, outperforming traditional
ASR-based retrieval approaches in specific scenarios.

摘要：本研究介紹了 CLASP（對比語言-語音預訓練），這是一種針對音訊-文字資訊檢索量身打造的多語言、多模態表示方式。CLASP 利用口說內容和文字資料之間的協同效應。在訓練期間，我們利用我們新推出的語音-文字資料集，其中包含從小說到宗教等 15 種不同的類別。CLASP 的音訊組件將音訊語譜圖與預先訓練好的自監督語音模型整合在一起，而其語言編碼對應部分則使用預先在 100 多種語言上訓練好的句子編碼器。這個統一的輕量級模型彌合了各種模態和語言之間的差距，增強了其處理和檢索多語言和多模態資料的效能。我們跨多種語言進行的評估顯示，CLASP 在 HITS@1、MRR 和 meanR 指標中建立了新的基準，在特定場景中優於傳統的基於 ASR 的檢索方法。

##### **VidTok: A Versatile and Open-Source Video Tokenizer**
2412.13061v1 by Anni Tang, Tianyu He, Junliang Guo, Xinle Cheng, Li Song, Jiang Bian

Encoding video content into compact latent tokens has become a fundamental
step in video generation and understanding, driven by the need to address the
inherent redundancy in pixel-level representations. Consequently, there is a
growing demand for high-performance, open-source video tokenizers as
video-centric research gains prominence. We introduce VidTok, a versatile video
tokenizer that delivers state-of-the-art performance in both continuous and
discrete tokenizations. VidTok incorporates several key advancements over
existing approaches: 1) model architecture such as convolutional layers and
up/downsampling modules; 2) to address the training instability and codebook
collapse commonly associated with conventional Vector Quantization (VQ), we
integrate Finite Scalar Quantization (FSQ) into discrete video tokenization; 3)
improved training strategies, including a two-stage training process and the
use of reduced frame rates. By integrating these advancements, VidTok achieves
substantial improvements over existing methods, demonstrating superior
performance across multiple metrics, including PSNR, SSIM, LPIPS, and FVD,
under standardized evaluation settings.

摘要：將影片內容編碼成緊湊的潛在符號已成為影片生成和理解的基本步驟，其驅動力是為了處理畫素級別表示中固有的冗餘。因此，隨著以影片為中心的研究所獲得顯著地位，對於高性能的開放原始碼影片代幣產生器的需求也與日俱增。我們介紹了 VidTok，這是一個多功能的影片代幣產生器，在連續和離散代幣化中都能提供最先進的效能。VidTok 整合了多項關鍵進展，超越了現有的方法：1) 模型架構，例如卷積層和上/下採樣模組；2) 為了處理與傳統向量量化 (VQ) 通常相關的訓練不穩定性和代碼簿崩潰，我們將有限純量量化 (FSQ) 整合到離散影片代幣化中；3) 改良的訓練策略，包括兩階段訓練流程和使用降低的幀率。透過整合這些進展，VidTok 在現有方法上獲得了顯著的改進，在標準化評估設定下，展示了多項指標的卓越效能，包括 PSNR、SSIM、LPIPS 和 FVD。

##### **Modality-Inconsistent Continual Learning of Multimodal Large Language Models**
2412.13050v1 by Weiguo Pian, Shijian Deng, Shentong Mo, Yunhui Guo, Yapeng Tian

In this paper, we introduce Modality-Inconsistent Continual Learning (MICL),
a new continual learning scenario for Multimodal Large Language Models (MLLMs)
that involves tasks with inconsistent modalities (image, audio, or video) and
varying task types (captioning or question-answering). Unlike existing
vision-only or modality-incremental settings, MICL combines modality and task
type shifts, both of which drive catastrophic forgetting. To address these
challenges, we propose MoInCL, which employs a Pseudo Targets Generation Module
to mitigate forgetting caused by task type shifts in previously seen
modalities. It also incorporates Instruction-based Knowledge Distillation to
preserve the model's ability to handle previously learned modalities when new
ones are introduced. We benchmark MICL using a total of six tasks and conduct
experiments to validate the effectiveness of our proposed MoInCL. The
experimental results highlight the superiority of MoInCL, showing significant
improvements over representative and state-of-the-art continual learning
baselines.

摘要：在本文中，我們介紹了模態不一致的持續學習 (MICL)，這是一種新的持續學習情境，適用於多模態大型語言模型 (MLLM)，其中涉及具有不一致模態（圖像、音訊或影片）和不同任務類型（標題或問答）的任務。與現有的僅視覺或模態增量設定不同，MICL 結合了模態和任務類型轉換，這兩者都會導致災難性遺忘。為了應對這些挑戰，我們提出了 MoInCL，它採用偽目標生成模組來減輕先前所見模態中任務類型轉換所造成的遺忘。它還整合了基於指令的知識蒸餾，以在引入新模態時保留模型處理先前學習模態的能力。我們使用總共六項任務對 MICL 進行基準測試，並進行實驗驗證我們提出的 MoInCL 的有效性。實驗結果突出了 MoInCL 的優越性，顯示出比具代表性和最先進的持續學習基準顯著的進步。

##### **Harnessing Event Sensory Data for Error Pattern Prediction in Vehicles: A Language Model Approach**
2412.13041v1 by Hugo Math, Rainer Lienhart, Robin Schön

In this paper, we draw an analogy between processing natural languages and
processing multivariate event streams from vehicles in order to predict
$\textit{when}$ and $\textit{what}$ error pattern is most likely to occur in
the future for a given car. Our approach leverages the temporal dynamics and
contextual relationships of our event data from a fleet of cars. Event data is
composed of discrete values of error codes as well as continuous values such as
time and mileage. Modelled by two causal Transformers, we can anticipate
vehicle failures and malfunctions before they happen. Thus, we introduce
$\textit{CarFormer}$, a Transformer model trained via a new self-supervised
learning strategy, and $\textit{EPredictor}$, an autoregressive Transformer
decoder model capable of predicting $\textit{when}$ and $\textit{what}$ error
pattern will most likely occur after some error code apparition. Despite the
challenges of high cardinality of event types, their unbalanced frequency of
appearance and limited labelled data, our experimental results demonstrate the
excellent predictive ability of our novel model. Specifically, with sequences
of $160$ error codes on average, our model is able with only half of the error
codes to achieve $80\%$ F1 score for predicting $\textit{what}$ error pattern
will occur and achieves an average absolute error of $58.4 \pm 13.2$h
$\textit{when}$ forecasting the time of occurrence, thus enabling confident
predictive maintenance and enhancing vehicle safety.

摘要：<paragraph>在本文中，我們將處理自然語言與處理來自車輛的多變量事件串流之間畫上類比，以便預測給定汽車未來最有可能發生 $\textit{何時}$ 和 $\textit{什麼}$ 錯誤模式。我們的做法利用了來自汽車車隊的事件數據的時間動態和上下文關係。事件數據由錯誤代碼的離散值以及時間和里程數等連續值組成。透過兩個因果 Transformer 建模，我們可以在發生車輛故障和異常之前預測它們。因此，我們引入了 $\textit{CarFormer}$，一個透過新的自我監督學習策略訓練的 Transformer 模型，以及 $\textit{EPredictor}$，一個自迴歸 Transformer 解碼器模型，能夠預測在某些錯誤代碼出現後最有可能發生 $\textit{何時}$ 和 $\textit{什麼}$ 錯誤模式。儘管事件類型的高基數、出現頻率不平衡以及標籤數據有限等挑戰，我們的實驗結果證明了我們新模型出色的預測能力。具體來說，在平均 $160$ 個錯誤代碼的序列中，我們的模型僅使用一半的錯誤代碼就能在預測 $\textit{什麼}$ 錯誤模式將會發生時達到 $80%$ 的 F1 分數，並且在預測發生時間時達到 $58.4 \pm 13.2$ 小時的平均絕對誤差，從而實現可靠的預測性維護並提高車輛安全性。</paragraph>

##### **NAVCON: A Cognitively Inspired and Linguistically Grounded Corpus for Vision and Language Navigation**
2412.13026v1 by Karan Wanchoo, Xiaoye Zuo, Hannah Gonzalez, Soham Dan, Georgios Georgakis, Dan Roth, Kostas Daniilidis, Eleni Miltsakaki

We present NAVCON, a large-scale annotated Vision-Language Navigation (VLN)
corpus built on top of two popular datasets (R2R and RxR). The paper introduces
four core, cognitively motivated and linguistically grounded, navigation
concepts and an algorithm for generating large-scale silver annotations of
naturally occurring linguistic realizations of these concepts in navigation
instructions. We pair the annotated instructions with video clips of an agent
acting on these instructions. NAVCON contains 236, 316 concept annotations for
approximately 30, 0000 instructions and 2.7 million aligned images (from
approximately 19, 000 instructions) showing what the agent sees when executing
an instruction. To our knowledge, this is the first comprehensive resource of
navigation concepts. We evaluated the quality of the silver annotations by
conducting human evaluation studies on NAVCON samples. As further validation of
the quality and usefulness of the resource, we trained a model for detecting
navigation concepts and their linguistic realizations in unseen instructions.
Additionally, we show that few-shot learning with GPT-4o performs well on this
task using large-scale silver annotations of NAVCON.

摘要：我們提出 NAVCON，一個建立在兩個熱門資料集 (R2R 和 RxR) 上的大規模標註視覺語言導航 (VLN) 語料庫。本文介紹了四個核心、認知動機和語言基礎的導航概念，以及一種演算法，用於產生這些概念在導航指令中自然發生的語言實現的大規模銀色標註。我們將帶標註的指令與代理人根據這些指令執行的影片片段配對。NAVCON 包含 236, 316 個概念標註，約 30, 0000 條指令和 270 萬張對齊影像（來自約 19, 000 條指令），顯示代理人在執行指令時所見內容。據我們所知，這是第一個全面的導航概念資源。我們透過對 NAVCON 樣本進行人為評估研究，評估了銀色標註的品質。為了進一步驗證資源的品質和有用性，我們訓練了一個模型，用於在未見過的指令中偵測導航概念及其語言實現。此外，我們表明，使用 NAVCON 的大規模銀色標註，GPT-4o 上的少量學習在此任務上表現良好。

##### **Relational Neurosymbolic Markov Models**
2412.13023v1 by Lennert De Smet, Gabriele Venturato, Luc De Raedt, Giuseppe Marra

Sequential problems are ubiquitous in AI, such as in reinforcement learning
or natural language processing. State-of-the-art deep sequential models, like
transformers, excel in these settings but fail to guarantee the satisfaction of
constraints necessary for trustworthy deployment. In contrast, neurosymbolic AI
(NeSy) provides a sound formalism to enforce constraints in deep probabilistic
models but scales exponentially on sequential problems. To overcome these
limitations, we introduce relational neurosymbolic Markov models (NeSy-MMs), a
new class of end-to-end differentiable sequential models that integrate and
provably satisfy relational logical constraints. We propose a strategy for
inference and learning that scales on sequential settings, and that combines
approximate Bayesian inference, automated reasoning, and gradient estimation.
Our experiments show that NeSy-MMs can solve problems beyond the current
state-of-the-art in neurosymbolic AI and still provide strong guarantees with
respect to desired properties. Moreover, we show that our models are more
interpretable and that constraints can be adapted at test time to
out-of-distribution scenarios.

摘要：序貫問題在 AI 中無處不在，例如在強化學習或自然語言處理中。最先進的深度序列模型，如Transformer，在這些設定中表現出色，但無法保證滿足可信賴部署所需的約束。相比之下，神經符號 AI (NeSy) 提供了一個健全的形式主義來強制約束深度機率模型，但在序列問題上呈指數級擴展。為了克服這些限制，我們引入了關係神經符號馬可夫模型 (NeSy-MMs)，這是一個新的端到端可微分序列模型類別，它整合並證明滿足關係邏輯約束。我們提出了一種在序列設定中擴展的推論和學習策略，它結合了近似貝氏推論、自動推理和梯度估計。我們的實驗表明，NeSy-MMs 可以解決神經符號 AI 中當前最先進技術無法解決的問題，並且仍然提供關於所需屬性的強有力的保證。此外，我們表明我們的模型更具可解釋性，並且約束可以在測試時適應到分布外場景。

##### **OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in Financial Domain**
2412.13018v1 by Shuting Wang, Jiejun Tan, Zhicheng Dou, Ji-Rong Wen

As a typical and practical application of Large Language Models (LLMs),
Retrieval-Augmented Generation (RAG) techniques have gained extensive
attention, particularly in vertical domains where LLMs may lack domain-specific
knowledge. In this paper, we introduce an omnidirectional and automatic RAG
benchmark, OmniEval, in the financial domain. Our benchmark is characterized by
its multi-dimensional evaluation framework, including (1) a matrix-based RAG
scenario evaluation system that categorizes queries into five task classes and
16 financial topics, leading to a structured assessment of diverse query
scenarios; (2) a multi-dimensional evaluation data generation approach, which
combines GPT-4-based automatic generation and human annotation, achieving an
87.47\% acceptance ratio in human evaluations on generated instances; (3) a
multi-stage evaluation system that evaluates both retrieval and generation
performance, result in a comprehensive evaluation on the RAG pipeline; and (4)
robust evaluation metrics derived from rule-based and LLM-based ones, enhancing
the reliability of assessments through manual annotations and supervised
fine-tuning of an LLM evaluator. Our experiments demonstrate the
comprehensiveness of OmniEval, which includes extensive test datasets and
highlights the performance variations of RAG systems across diverse topics and
tasks, revealing significant opportunities for RAG models to improve their
capabilities in vertical domains. We open source the code of our benchmark in
\href{https://github.com/RUC-NLPIR/OmniEval}{https://github.com/RUC-NLPIR/OmniEval}.

摘要：<paragraph>作為大型語言模型 (LLM) 的典型且實際應用，檢索增強生成 (RAG) 技術已獲得廣泛關注，特別是在 LLM 可能缺乏特定領域知識的垂直領域中。在本文中，我們在金融領域中引入了一個全方位且自動化的 RAG 基準 OmniEval。我們的基準的特點在於其多維評估框架，包括：(1) 一個基於矩陣的 RAG 場景評估系統，它將查詢分類為五個任務類別和 16 個財務主題，從而對不同的查詢場景進行結構化評估；(2) 一種多維評估數據生成方法，它結合了基於 GPT-4 的自動生成和人工標註，在生成實例的人工評估中實現了 87.47% 的接受率；(3) 一個多階段評估系統，它評估檢索和生成性能，對 RAG 管道進行全面評估；以及 (4) 從基於規則和基於 LLM 的評估指標中衍生的穩健評估指標，通過人工標註和 LLM 評估器的監督微調來增強評估的可靠性。我們的實驗證明了 OmniEval 的全面性，它包括廣泛的測試數據集，並突出了 RAG 系統在不同主題和任務中的性能差異，揭示了 RAG 模型在垂直領域中改進其能力的重大機會。我們在 \href{https://github.com/RUC-NLPIR/OmniEval}{https://github.com/RUC-NLPIR/OmniEval} 開源了我們基準的代碼。</paragraph>

##### **RCLMuFN: Relational Context Learning and Multiplex Fusion Network for Multimodal Sarcasm Detection**
2412.13008v1 by Tongguan Wang, Junkai Li, Guixin Su, Yongcheng Zhang, Dongyu Su, Yuxue Hu, Ying Sha

Sarcasm typically conveys emotions of contempt or criticism by expressing a
meaning that is contrary to the speaker's true intent. Accurate detection of
sarcasm aids in identifying and filtering undesirable information on the
Internet, thereby reducing malicious defamation and rumor-mongering.
Nonetheless, the task of automatic sarcasm detection remains highly challenging
for machines, as it critically depends on intricate factors such as relational
context. Most existing multimodal sarcasm detection methods focus on
introducing graph structures to establish entity relationships between text and
images while neglecting to learn the relational context between text and
images, which is crucial evidence for understanding the meaning of sarcasm. In
addition, the meaning of sarcasm changes with the evolution of different
contexts, but existing methods may not be accurate in modeling such dynamic
changes, limiting the generalization ability of the models. To address the
above issues, we propose a relational context learning and multiplex fusion
network (RCLMuFN) for multimodal sarcasm detection. Firstly, we employ four
feature extractors to comprehensively extract features from raw text and
images, aiming to excavate potential features that may have been previously
overlooked. Secondly, we utilize the relational context learning module to
learn the contextual information of text and images and capture the dynamic
properties through shallow and deep interactions. Finally, we employ a
multiplex feature fusion module to enhance the generalization of the model by
penetratingly integrating multimodal features derived from various interaction
contexts. Extensive experiments on two multimodal sarcasm detection datasets
show that our proposed method achieves state-of-the-art performance.

摘要：<paragraph>諷刺通常透過表達與說話者真實意圖相反的意義來傳達輕蔑或批評的情緒。準確地偵測諷刺有助於辨識和過濾網路上不適當的資訊，進而減少惡意的誹謗和散播謠言。儘管如此，自動諷刺偵測的任務對於機器來說仍然極具挑戰性，因為它嚴重依賴於關係脈絡等複雜因素。現有的多模態諷刺偵測方法大多著重於引入圖形結構，以建立文字和影像之間的實體關係，卻忽略了學習文字和影像之間的關係脈絡，而這對於理解諷刺的意義至關重要。此外，諷刺的意義會隨著不同脈絡的演變而改變，但現有的方法可能無法準確地建模這種動態變化，進而限制了模型的泛化能力。為了解決上述問題，我們提出了一個關係脈絡學習和多重融合網路 (RCLMuFN)，用於多模態諷刺偵測。首先，我們採用四個特徵萃取器，從原始文字和影像中全面萃取出特徵，目的是挖掘先前可能被忽略的潛在特徵。其次，我們利用關係脈絡學習模組，學習文字和影像的脈絡資訊，並透過淺層和深層互動擷取動態屬性。最後，我們採用多重特徵融合模組，透過深入整合來自各種互動脈絡的多模態特徵，來增強模型的泛化能力。在兩個多模態諷刺偵測資料集上的廣泛實驗顯示，我們提出的方法達到了最先進的效能。</paragraph>

##### **Enabling Low-Resource Language Retrieval: Establishing Baselines for Urdu MS MARCO**
2412.12997v1 by Umer Butt, Stalin Veranasi, Günter Neumann

As the Information Retrieval (IR) field increasingly recognizes the
importance of inclusivity, addressing the needs of low-resource languages
remains a significant challenge. This paper introduces the first large-scale
Urdu IR dataset, created by translating the MS MARCO dataset through machine
translation. We establish baseline results through zero-shot learning for IR in
Urdu and subsequently apply the mMARCO multilingual IR methodology to this
newly translated dataset. Our findings demonstrate that the fine-tuned model
(Urdu-mT5-mMARCO) achieves a Mean Reciprocal Rank (MRR@10) of 0.247 and a
Recall@10 of 0.439, representing significant improvements over zero-shot
results and showing the potential for expanding IR access for Urdu speakers. By
bridging access gaps for speakers of low-resource languages, this work not only
advances multilingual IR research but also emphasizes the ethical and societal
importance of inclusive IR technologies. This work provides valuable insights
into the challenges and solutions for improving language representation and
lays the groundwork for future research, especially in South Asian languages,
which can benefit from the adaptable methods used in this study.

摘要：隨著資訊檢索 (IR) 領域日益重視包容性，滿足低資源語言的需求仍然是一項重大挑戰。本文介紹了第一個大規模的烏爾都語 IR 資料集，該資料集是透過機器翻譯翻譯 MS MARCO 資料集而建立。我們透過烏爾都語 IR 的零次學習建立基準結果，並隨後將 mMARCO 多語言 IR 方法應用於這個新翻譯的資料集。我們的研究結果顯示，微調模型 (Urdu-mT5-mMARCO) 在平均倒數排名 (MRR@10) 中達到 0.247，在召回率@10 中達到 0.439，與零次學習結果相比有顯著的進步，並顯示出擴展烏爾都語使用者 IR 存取的潛力。透過縮小低資源語言使用者之間的存取差距，這項工作不僅推動了多語言 IR 研究，也強調了包容性 IR 技術的道德和社會重要性。這項工作提供了關於改善語言表達的挑戰和解決方案的寶貴見解，並為未來的研究奠定基礎，特別是在南亞語言方面，這些語言可以受益於本研究中使用的可適應方法。

##### **Cluster-guided Contrastive Class-imbalanced Graph Classification**
2412.12984v1 by Wei Ju, Zhengyang Mao, Siyu Yi, Yifang Qin, Yiyang Gu, Zhiping Xiao, Jianhao Shen, Ziyue Qiao, Ming Zhang

This paper studies the problem of class-imbalanced graph classification,
which aims at effectively classifying the categories of graphs in scenarios
with imbalanced class distribution. Despite the tremendous success of graph
neural networks (GNNs), their modeling ability for imbalanced graph-structured
data is inadequate, which typically leads to predictions biased towards the
majority classes. Besides, existing class-imbalanced learning methods in
visions may overlook the rich graph semantic substructures of the majority
classes and excessively emphasize learning from the minority classes. To tackle
this issue, this paper proposes a simple yet powerful approach called C$^3$GNN
that incorporates the idea of clustering into contrastive learning to enhance
class-imbalanced graph classification. Technically, C$^3$GNN clusters graphs
from each majority class into multiple subclasses, ensuring they have similar
sizes to the minority class, thus alleviating class imbalance. Additionally, it
utilizes the Mixup technique to synthesize new samples and enrich the semantic
information of each subclass, and leverages supervised contrastive learning to
hierarchically learn effective graph representations. In this way, we can not
only sufficiently explore the semantic substructures within the majority class
but also effectively alleviate excessive focus on the minority class. Extensive
experiments on real-world graph benchmark datasets verify the superior
performance of our proposed method.

摘要：本文研究類別不平衡圖形分類問題，目標在於在類別分佈不平衡的場景中有效地對圖形的類別進行分類。儘管圖神經網路 (GNN) 取得了巨大的成功，但其對不平衡圖形結構資料的建模能力不足，這通常會導致預測偏向於多數類別。此外，現有的類別不平衡學習方法在視覺上可能會忽略多數類別豐富的圖形語義子結構，並過度強調從少數類別中學習。為了解決這個問題，本文提出了一種簡單但強大的方法，稱為 C$^3$GNN，它將聚類的概念納入對比學習中，以增強類別不平衡圖形分類。在技術上，C$^3$GNN 將每個多數類別的圖形聚類成多個子類，確保它們具有與少數類別相似的規模，從而緩解類別不平衡。此外，它利用 Mixup 技術合成新的樣本並豐富每個子類的語義資訊，並利用監督對比學習分層學習有效的圖形表示。通過這種方式，我們不僅可以充分探索多數類別內的語義子結構，還可以有效地減輕對少數類別的過度關注。在真實世界圖形基準資料集上進行的廣泛實驗驗證了我們提出的方法的優異效能。

##### **Unlocking LLMs: Addressing Scarce Data and Bias Challenges in Mental Health**
2412.12981v1 by Vivek Kumar, Eirini Ntoutsi, Pushpraj Singh Rajawat, Giacomo Medda, Diego Reforgiato Recupero

Large language models (LLMs) have shown promising capabilities in healthcare
analysis but face several challenges like hallucinations, parroting, and bias
manifestation. These challenges are exacerbated in complex, sensitive, and
low-resource domains. Therefore, in this work we introduce IC-AnnoMI, an
expert-annotated motivational interviewing (MI) dataset built upon AnnoMI by
generating in-context conversational dialogues leveraging LLMs, particularly
ChatGPT. IC-AnnoMI employs targeted prompts accurately engineered through cues
and tailored information, taking into account therapy style (empathy,
reflection), contextual relevance, and false semantic change. Subsequently, the
dialogues are annotated by experts, strictly adhering to the Motivational
Interviewing Skills Code (MISC), focusing on both the psychological and
linguistic dimensions of MI dialogues. We comprehensively evaluate the
IC-AnnoMI dataset and ChatGPT's emotional reasoning ability and understanding
of domain intricacies by modeling novel classification tasks employing several
classical machine learning and current state-of-the-art transformer approaches.
Finally, we discuss the effects of progressive prompting strategies and the
impact of augmented data in mitigating the biases manifested in IC-AnnoM. Our
contributions provide the MI community with not only a comprehensive dataset
but also valuable insights for using LLMs in empathetic text generation for
conversational therapy in supervised settings.

摘要：大型語言模型 (LLM) 在醫療保健分析中展現了前景看好的能力，但面臨了幻覺、鸚鵡學舌和偏見表現等多項挑戰。這些挑戰在複雜、敏感和資源不足的領域中會更加嚴重。因此，在這項工作中，我們引入了 IC-AnnoMI，一個由專家註解的動機性訪談 (MI) 資料集，它建立在 AnnoMI 上，透過利用 LLM，特別是 ChatGPT，產生情境對話。IC-AnnoMI 採用了透過提示和客製化資訊準確設計的目標提示，並考量了治療風格（同理心、反思）、情境相關性和錯誤語義變化。隨後，對話由專家註解，嚴格遵守動機性訪談技能準則 (MISC)，重點關注 MI 對話的心理和語言面向。我們透過採用多種經典機器學習和目前最先進的轉換器方法，對 IC-AnnoMI 資料集和 ChatGPT 的情緒推理能力以及對領域複雜性的理解進行全面評估。最後，我們討論了漸進提示策略的影響，以及擴充資料在減輕 IC-AnnoM 中表現出的偏見方面的影響。我們的貢獻不僅為 MI 社群提供了全面的資料集，也提供了在監督式環境中使用 LLM 進行同理心文字生成以進行對話治療的寶貴見解。

##### **Adaptations of AI models for querying the LandMatrix database in natural language**
2412.12961v1 by Fatiha Ait Kbir, Jérémy Bourgoin, Rémy Decoupes, Marie Gradeler, Roberto Interdonato

The Land Matrix initiative (https://landmatrix.org) and its global
observatory aim to provide reliable data on large-scale land acquisitions to
inform debates and actions in sectors such as agriculture, extraction, or
energy in low- and middle-income countries. Although these data are recognized
in the academic world, they remain underutilized in public policy, mainly due
to the complexity of access and exploitation, which requires technical
expertise and a good understanding of the database schema.
  The objective of this work is to simplify access to data from different
database systems. The methods proposed in this article are evaluated using data
from the Land Matrix. This work presents various comparisons of Large Language
Models (LLMs) as well as combinations of LLM adaptations (Prompt Engineering,
RAG, Agents) to query different database systems (GraphQL and REST queries).
The experiments are reproducible, and a demonstration is available online:
https://github.com/tetis-nlp/landmatrix-graphql-python.

摘要：Land Matrix 計畫（https://landmatrix.org）及其全球觀測站旨在提供有關大規模土地收購的可靠數據，以提供資訊給農業、開採或能源等部門在低收入和中等收入國家的辯論和行動。儘管這些數據在學術界獲得認可，但由於取得和利用的複雜性，它們在公共政策中仍未得到充分利用，這需要技術專業知識和對資料庫架構的良好理解。
這項工作的目標是簡化從不同資料庫系統存取資料的方式。本文提出的方法使用 Land Matrix 的資料進行評估。這項工作提供了大型語言模型（LLM）的各種比較，以及 LLM 改編（提示工程、RAG、代理）的組合，以查詢不同的資料庫系統（GraphQL 和 REST 查詢）。這些實驗是可以複製的，並可以在線上取得示範：https://github.com/tetis-nlp/landmatrix-graphql-python。

##### **SnakModel: Lessons Learned from Training an Open Danish Large Language Model**
2412.12956v1 by Mike Zhang, Max Müller-Eberstein, Elisa Bassignana, Rob van der Goot

We present SnakModel, a Danish large language model (LLM) based on Llama2-7B,
which we continuously pre-train on 13.6B Danish words, and further tune on 3.7M
Danish instructions. As best practices for creating LLMs for smaller language
communities have yet to be established, we examine the effects of early
modeling and training decisions on downstream performance throughout the entire
training pipeline, including (1) the creation of a strictly curated corpus of
Danish text from diverse sources; (2) the language modeling and
instruction-tuning training process itself, including the analysis of
intermediate training dynamics, and ablations across different hyperparameters;
(3) an evaluation on eight language and culturally-specific tasks. Across these
experiments SnakModel achieves the highest overall performance, outperforming
multiple contemporary Llama2-7B-based models. By making SnakModel, the majority
of our pre-training corpus, and the associated code available under open
licenses, we hope to foster further research and development in Danish Natural
Language Processing, and establish training guidelines for languages with
similar resource constraints.

摘要：我們提出 SnakModel，一個基於 Llama2-7B 的丹麥大型語言模型 (LLM)，
我們持續對 13.6B 個丹麥語單字進行預訓練，並進一步針對 3.7M
個丹麥語指令進行微調。由於目前尚未建立針對較小語言社群建立 LLM 的最佳實務，我們檢查了早期
建模和訓練決策對整個訓練管線中下游效能的影響，包括 (1) 從不同來源建立嚴格策劃的丹麥語語料庫；(2) 語言建模和
指令微調訓練流程本身，包括對中間訓練動態的分析，以及不同超參數的消融；
(3) 對八種語言和文化特定任務的評估。在這些
實驗中，SnakModel 達到了最高的整體效能，超越了多個當代基於 Llama2-7B 的模型。透過讓 SnakModel、我們大部分的預訓練語料庫，以及相關程式碼在開放
授權下可用，我們希望促進丹麥自然語言處理的進一步研究和開發，並為資源受限的語言建立訓練準則。

##### **Learning from Noisy Labels via Self-Taught On-the-Fly Meta Loss Rescaling**
2412.12955v1 by Michael Heck, Christian Geishauser, Nurul Lubis, Carel van Niekerk, Shutong Feng, Hsien-Chin Lin, Benjamin Matthias Ruppik, Renato Vukovic, Milica Gašić

Correct labels are indispensable for training effective machine learning
models. However, creating high-quality labels is expensive, and even
professionally labeled data contains errors and ambiguities. Filtering and
denoising can be applied to curate labeled data prior to training, at the cost
of additional processing and loss of information. An alternative is on-the-fly
sample reweighting during the training process to decrease the negative impact
of incorrect or ambiguous labels, but this typically requires clean seed data.
In this work we propose unsupervised on-the-fly meta loss rescaling to reweight
training samples. Crucially, we rely only on features provided by the model
being trained, to learn a rescaling function in real time without knowledge of
the true clean data distribution. We achieve this via a novel meta learning
setup that samples validation data for the meta update directly from the noisy
training corpus by employing the rescaling function being trained. Our proposed
method consistently improves performance across various NLP tasks with minimal
computational overhead. Further, we are among the first to attempt on-the-fly
training data reweighting on the challenging task of dialogue modeling, where
noisy and ambiguous labels are common. Our strategy is robust in the face of
noisy and clean data, handles class imbalance, and prevents overfitting to
noisy labels. Our self-taught loss rescaling improves as the model trains,
showing the ability to keep learning from the model's own signals. As training
progresses, the impact of correctly labeled data is scaled up, while the impact
of wrongly labeled data is suppressed.

摘要：正確的標籤對於訓練有效的機器學習模型來說是不可或缺的。然而，建立高品質標籤的成本很高，而且即使專業標記的資料也包含錯誤和模糊性。過濾和去噪可以應用於在訓練前整理標籤資料，但代價是額外的處理和資訊的遺失。另一個替代方案是在訓練過程中進行即時樣本重新加權，以減少不正確或模糊標籤的負面影響，但這通常需要乾淨的種子資料。在這項工作中，我們提出無監督的即時元損失重新調整，以重新加權訓練樣本。至關重要的是，我們僅依賴模型提供的特徵，在不瞭解真實乾淨資料分佈的情況下，即時學習重新調整函數。我們透過一個新穎的元學習設定來實現這一點，該設定直接從嘈雜的訓練語料庫中抽取驗證資料，以進行元更新，方法是採用正在訓練的重新調整函數。我們提出的方法在各種自然語言處理任務中持續改善效能，且運算負擔極小。此外，我們是首批嘗試對話建模這項艱鉅任務進行即時訓練資料重新加權的人員之一，在對話建模中，嘈雜和模糊的標籤很常見。我們的策略在面對嘈雜和乾淨的資料時很穩健，能處理類別不平衡，並防止過度擬合到嘈雜的標籤。我們自學的損失重新調整會隨著模型訓練而改善，顯示出從模型本身訊號持續學習的能力。隨著訓練的進行，正確標記資料的影響會擴大，而錯誤標記資料的影響則會被抑制。

##### **Recipient Profiling: Predicting Characteristics from Messages**
2412.12954v1 by Martin Borquez, Mikaela Keller, Michael Perrot, Damien Sileo

It has been shown in the field of Author Profiling that texts may
inadvertently reveal sensitive information about their authors, such as gender
or age. This raises important privacy concerns that have been extensively
addressed in the literature, in particular with the development of methods to
hide such information. We argue that, when these texts are in fact messages
exchanged between individuals, this is not the end of the story. Indeed, in
this case, a second party, the intended recipient, is also involved and should
be considered. In this work, we investigate the potential privacy leaks
affecting them, that is we propose and address the problem of Recipient
Profiling. We provide empirical evidence that such a task is feasible on
several publicly accessible datasets
(https://huggingface.co/datasets/sileod/recipient_profiling). Furthermore, we
show that the learned models can be transferred to other datasets, albeit with
a loss in accuracy.

摘要：在作者画像領域中，研究已表明文本可能會在無意間揭露作者的敏感資訊，例如性別或年齡。這引發了重要的隱私問題，並已在文獻中廣泛探討，特別是開發了隱藏此類資訊的方法。我們認為，當這些文本實際上是個人之間交換的訊息時，這並非故事的結局。的確，在這種情況下，第二方（預期的收件人）也參與其中，並且應該被考慮在內。在這項工作中，我們調查了影響他們的潛在隱私洩漏，也就是說，我們提出並解決了收件人画像問題。我們提供了經驗證據，證明此類任務在幾個公開可存取的資料集上是可行的（https://huggingface.co/datasets/sileod/recipient_profiling）。此外，我們表明，儘管準確度有所下降，但學習模型仍可轉移到其他資料集。

##### **MOPO: Multi-Objective Prompt Optimization for Affective Text Generation**
2412.12948v1 by Yarik Menchaca Resendiz, Roman Klinger

How emotions are expressed depends on the context and domain. On X (formerly
Twitter), for instance, an author might simply use the hashtag #anger, while in
a news headline, emotions are typically written in a more polite, indirect
manner. To enable conditional text generation models to create emotionally
connotated texts that fit a domain, users need to have access to a parameter
that allows them to choose the appropriate way to express an emotion. To
achieve this, we introduce MOPO, a Multi-Objective Prompt Optimization
methodology. MOPO optimizes prompts according to multiple objectives (which
correspond here to the output probabilities assigned by emotion classifiers
trained for different domains). In contrast to single objective optimization,
MOPO outputs a set of prompts, each with a different weighting of the multiple
objectives. Users can then choose the most appropriate prompt for their
context. We evaluate MOPO using three objectives, determined by various
domain-specific emotion classifiers. MOPO improves performance by up to 15 pp
across all objectives with a minimal loss (1-2 pp) for any single objective
compared to single-objective optimization. These minor performance losses are
offset by a broader generalization across multiple objectives - which is not
possible with single-objective optimization. Additionally, MOPO reduces
computational requirements by simultaneously optimizing for multiple
objectives, eliminating separate optimization procedures for each objective.

摘要：情緒的表達方式取決於脈絡和領域。例如，在 X（前身為 Twitter）上，作者可能只會使用標籤 #憤怒，而在新聞標題中，情緒通常會用更禮貌、間接的方式寫成。為了讓條件式文字生成模型能夠建立符合某個領域的情緒內涵文字，使用者需要存取一個參數，讓他們能夠選擇適當的方式表達情緒。為了達成此目的，我們引入了 MOPO，一種多目標提示最佳化方法。MOPO 會根據多個目標最佳化提示（在此對應於為不同領域訓練的情緒分類器所分配的輸出機率）。與單一目標最佳化不同，MOPO 會輸出一個提示組，每個提示組對多個目標的加權不同。然後，使用者可以選擇最適合其脈絡的提示。我們使用三個目標來評估 MOPO，這些目標由各種特定領域的情緒分類器決定。MOPO 將所有目標的效能提升了 15 pp，與單一目標最佳化相比，任何單一目標的損失都很小（1-2 pp）。這些微小的效能損失會被跨多個目標更廣泛的概化所抵銷，而這在單一目標最佳化中是不可能的。此外，MOPO 透過同時最佳化多個目標來減少運算需求，消除了針對每個目標的個別最佳化程序。

##### **Improving Fine-grained Visual Understanding in VLMs through Text-Only Training**
2412.12940v1 by Dasol Choi, Guijin Son, Soo Yong Kim, Gio Paik, Seunghyeok Hong

Visual-Language Models (VLMs) have become a powerful tool for bridging the
gap between visual and linguistic understanding. However, the conventional
learning approaches for VLMs often suffer from limitations, such as the high
resource requirements of collecting and training image-text paired data. Recent
research has suggested that language understanding plays a crucial role in the
performance of VLMs, potentially indicating that text-only training could be a
viable approach. In this work, we investigate the feasibility of enhancing
fine-grained visual understanding in VLMs through text-only training. Inspired
by how humans develop visual concept understanding, where rich textual
descriptions can guide visual recognition, we hypothesize that VLMs can also
benefit from leveraging text-based representations to improve their visual
recognition abilities. We conduct comprehensive experiments on two distinct
domains: fine-grained species classification and cultural visual understanding
tasks. Our findings demonstrate that text-only training can be comparable to
conventional image-text training while significantly reducing computational
costs. This suggests a more efficient and cost-effective pathway for advancing
VLM capabilities, particularly valuable in resource-constrained environments.

摘要：視覺語言模型 (VLM) 已成為彌合視覺與語言理解之間差距的強大工具。然而，VLM 的傳統學習方法通常會受到限制，例如收集和訓練圖像文字配對資料的高資源需求。最近的研究表明，語言理解在 VLM 的表現中扮演著關鍵角色，這潛在表明僅文字訓練可能是一種可行的途徑。在這項工作中，我們探討了透過僅文字訓練來增強 VLM 中細緻的視覺理解的可行性。受到人類如何發展視覺概念理解的啟發，其中豐富的文字描述可以引導視覺辨識，我們假設 VLM 也可以受益於利用基於文字的表徵來改善其視覺辨識能力。我們在兩個不同的領域進行了全面的實驗：細緻的物種分類和文化視覺理解任務。我們的研究結果表明，僅文字訓練可以與傳統的圖像文字訓練相媲美，同時顯著降低運算成本。這表明了一條更有效率且更具成本效益的途徑來提升 VLM 的能力，特別是在資源受限的環境中。

##### **CoMT: A Novel Benchmark for Chain of Multi-modal Thought on Large Vision-Language Models**
2412.12932v1 by Zihui Cheng, Qiguang Chen, Jin Zhang, Hao Fei, Xiaocheng Feng, Wanxiang Che, Min Li, Libo Qin

Large Vision-Language Models (LVLMs) have recently demonstrated amazing
success in multi-modal tasks, including advancements in Multi-modal
Chain-of-Thought (MCoT) reasoning. Despite these successes, current benchmarks
still follow a traditional paradigm with multi-modal input and text-modal
output, which leads to significant drawbacks such as missing visual operations
and vague expressions. Motivated by this, we introduce a novel Chain of
Multi-modal Thought (CoMT) benchmark to address these limitations. Different
from the traditional MCoT benchmark, CoMT requires both multi-modal input and
multi-modal reasoning output, aiming to mimic human-like reasoning that
inherently integrates visual operation. Specifically, CoMT consists of four
categories: (1) Visual Creation, (2) Visual Deletion, (3) Visual Update, and
(4) Visual Selection to comprehensively explore complex visual operations and
concise expression in real scenarios. We evaluate various LVLMs and strategies
on CoMT, revealing some key insights into the capabilities and limitations of
the current approaches. We hope that CoMT can inspire more research on
introducing multi-modal generation into the reasoning process.

摘要：大型視覺語言模型 (LVLMs) 近期已在多模態任務中展現驚人的成功，包括多模態思考鏈 (MCoT) 推理的進展。儘管有這些成功，目前的基準仍遵循傳統範例，具有多模態輸入和文字模態輸出，這導致了顯著的缺點，例如缺少視覺運算和含糊的表達。基於此，我們引入了一個新穎的多模態思考鏈 (CoMT) 基準，以解決這些限制。不同於傳統的 MCoT 基準，CoMT 需要多模態輸入和多模態推理輸出，目的是模擬人類般的推理，其本質上整合了視覺運算。具體來說，CoMT 包含四個類別：(1) 視覺建立、(2) 視覺刪除、(3) 視覺更新和 (4) 視覺選擇，以全面探索複雜的視覺運算和現實場景中的簡潔表達。我們在 CoMT 上評估了各種 LVLMs 和策略，揭示了對當前方法的能力和限制的一些關鍵見解。我們希望 CoMT 能激勵更多關於將多模態生成引入推理過程的研究。

##### **Spectra of Cardinality Queries over Description Logic Knowledge Bases**
2412.12929v1 by Quentin Manière, Marcin Przybyłko

Recent works have explored the use of counting queries coupled with
Description Logic ontologies. The answer to such a query in a model of a
knowledge base is either an integer or $\infty$, and its spectrum is the set of
its answers over all models. While it is unclear how to compute and manipulate
such a set in general, we identify a class of counting queries whose spectra
can be effectively represented. Focusing on atomic counting queries, we
pinpoint the possible shapes of a spectrum over $\mathcal{ALCIF}$ ontologies:
they are essentially the subsets of $\mathbb{N} \cup \{ \infty \}$ closed under
addition. For most sublogics of $\mathcal{ALCIF}$, we show that possible
spectra enjoy simpler shapes, being $[ m, \infty ]$ or variations thereof. To
obtain our results, we refine constructions used for finite model reasoning and
notably rely on a cycle-reversion technique for the Horn fragment of
$\mathcal{ALCIF}$. We also study the data complexity of computing the proposed
effective representation and establish the
$\mathsf{FP}^{\mathsf{NP}[\log]}$-completeness of this task under several
settings.

摘要：最近的研究探索了使用计数查詢結合描述邏輯本体。在知識庫模型中對此類查詢的答案不是整數就是 $\infty$，其譜是其在所有模型上的答案集合。雖然目前尚不清楚如何一般計算和操作此類集合，但我們識別出一類可以有效表示其譜的計數查詢。專注於原子計數查詢，我們精確指出 $\mathcal{ALCIF}$ 本体上譜的可能形狀：它們基本上是 $\mathbb{N} \cup \{ \infty \}$ 的子集，在加法下封閉。對於 $\mathcal{ALCIF}$ 的大多數子邏輯，我們表明可能的譜具有更簡單的形狀，即 $[ m, \infty ]$ 或其變體。為了獲得我們的結果，我們改進了用於有限模型推理的構造，並特別依賴於 $\mathcal{ALCIF}$ 的 Horn 片段的循環逆轉技術。我們還研究了計算所提出的有效表示的數據複雜性，並在多種設置下建立了此任務的 $\mathsf{FP}^{\mathsf{NP}[\log]}$-完備性。

##### **Truthful Text Sanitization Guided by Inference Attacks**
2412.12928v1 by Ildikó Pilán, Benet Manzanares-Salor, David Sánchez, Pierre Lison

The purpose of text sanitization is to rewrite those text spans in a document
that may directly or indirectly identify an individual, to ensure they no
longer disclose personal information. Text sanitization must strike a balance
between preventing the leakage of personal information (privacy protection)
while also retaining as much of the document's original content as possible
(utility preservation). We present an automated text sanitization strategy
based on generalizations, which are more abstract (but still informative) terms
that subsume the semantic content of the original text spans. The approach
relies on instruction-tuned large language models (LLMs) and is divided into
two stages. The LLM is first applied to obtain truth-preserving replacement
candidates and rank them according to their abstraction level. Those candidates
are then evaluated for their ability to protect privacy by conducting inference
attacks with the LLM. Finally, the system selects the most informative
replacement shown to be resistant to those attacks. As a consequence of this
two-stage process, the chosen replacements effectively balance utility and
privacy. We also present novel metrics to automatically evaluate these two
aspects without the need to manually annotate data. Empirical results on the
Text Anonymization Benchmark show that the proposed approach leads to enhanced
utility, with only a marginal increase in the risk of re-identifying protected
individuals compared to fully suppressing the original information.
Furthermore, the selected replacements are shown to be more truth-preserving
and abstractive than previous methods.

摘要：文字淨化的目的是改寫文件中的文字區段，這些區段可能直接或間接地識別個人，以確保它們不再揭露個人資訊。文字淨化必須在防止個人資訊外洩（隱私保護）和盡可能保留文件的大部分原始內容（實用性保留）之間取得平衡。我們提出了一種自動化文字淨化策略，它基於概括，概括是一種更抽象（但仍然具有資訊性）的詞彙，它概括了原始文字區段的語義內容。這種方法依賴於經過指令調整的大型語言模型 (LLM)，並分為兩個階段。首先應用 LLM 以取得維護真實性的替換候選項，並根據其抽象層級對它們進行排序。然後評估這些候選項保護隱私的能力，方法是使用 LLM 進行推論攻擊。最後，系統選擇最具資訊性的替換項，證明它能抵抗這些攻擊。由於這個兩階段的過程，所選擇的替換項有效地平衡了實用性和隱私性。我們還提出了新穎的指標，可以在不需要手動註解資料的情況下自動評估這兩個方面。在文字匿名化基準上的經驗結果顯示，與完全壓制原始資訊相比，所提出的方法可提升實用性，而重新識別受保護個人的風險僅略有增加。此外，所選的替換項被證明比先前的做法更能維護真實性且更抽象。

##### **Unsupervised Region-Based Image Editing of Denoising Diffusion Models**
2412.12912v1 by Zixiang Li, Yue Song, Renshuai Tao, Xiaohong Jia, Yao Zhao, Wei Wang

Although diffusion models have achieved remarkable success in the field of
image generation, their latent space remains under-explored. Current methods
for identifying semantics within latent space often rely on external
supervision, such as textual information and segmentation masks. In this paper,
we propose a method to identify semantic attributes in the latent space of
pre-trained diffusion models without any further training. By projecting the
Jacobian of the targeted semantic region into a low-dimensional subspace which
is orthogonal to the non-masked regions, our approach facilitates precise
semantic discovery and control over local masked areas, eliminating the need
for annotations. We conducted extensive experiments across multiple datasets
and various architectures of diffusion models, achieving state-of-the-art
performance. In particular, for some specific face attributes, the performance
of our proposed method even surpasses that of supervised approaches,
demonstrating its superior ability in editing local image properties.

摘要：儘管擴散模型在影像生成領域已取得顯著的成功，但其潛在空間仍未被充分探索。目前用於識別潛在空間中語義的方法通常依賴於外部監督，例如文字資訊和分割遮罩。在本文中，我們提出了一種方法，可以在不進一步訓練的情況下識別預先訓練好的擴散模型潛在空間中的語義屬性。透過將目標語義區域的雅可比矩陣投影到與非遮罩區域正交的低維子空間，我們的做法有助於精確發現語義並控制局部遮罩區域，無需註解。我們在多個資料集和各種擴散模型架構上進行了廣泛的實驗，達到了最先進的效能。特別是，對於某些特定的面部屬性，我們提出的方法的效能甚至超越了監督式方法，證明了其在編輯局部影像屬性方面的優異能力。

##### **An Agentic Approach to Automatic Creation of P&ID Diagrams from Natural Language Descriptions**
2412.12898v1 by Shreeyash Gowaikar, Srinivasan Iyengar, Sameer Segal, Shivkumar Kalyanaraman

The Piping and Instrumentation Diagrams (P&IDs) are foundational to the
design, construction, and operation of workflows in the engineering and process
industries. However, their manual creation is often labor-intensive,
error-prone, and lacks robust mechanisms for error detection and correction.
While recent advancements in Generative AI, particularly Large Language Models
(LLMs) and Vision-Language Models (VLMs), have demonstrated significant
potential across various domains, their application in automating generation of
engineering workflows remains underexplored. In this work, we introduce a novel
copilot for automating the generation of P&IDs from natural language
descriptions. Leveraging a multi-step agentic workflow, our copilot provides a
structured and iterative approach to diagram creation directly from Natural
Language prompts. We demonstrate the feasibility of the generation process by
evaluating the soundness and completeness of the workflow, and show improved
results compared to vanilla zero-shot and few-shot generation approaches.

摘要：管路及儀表圖 (P&ID) 是工程和流程產業中工作流程設計、施工和運作的基礎。然而，它們的手動建立通常需要大量人工、容易出錯，而且缺乏健全的錯誤偵測和修正機制。儘管生成式 AI 的最新進展，特別是大型語言模型 (LLM) 和視覺語言模型 (VLM)，已在各種領域中展現出顯著的潛力，它們在自動化工程工作流程生成中的應用仍未被充分探討。在這項工作中，我們引入了一個新穎的副駕駛，用於自動化從自然語言描述中生成 P&ID。透過利用多步驟代理工作流程，我們的副駕駛提供了一個結構化且反覆運算的方法，可直接從自然語言提示建立圖表。我們透過評估工作流程的健全性和完整性，證明了生成過程的可行性，並展示出與傳統的零次學習和少次學習生成方法相比，有顯著的進步。

##### **Question: How do Large Language Models perform on the Question Answering tasks? Answer:**
2412.12893v1 by Kevin Fischer, Darren Fürst, Sebastian Steindl, Jakob Lindner, Ulrich Schäfer

Large Language Models (LLMs) have been showing promising results for various
NLP-tasks without the explicit need to be trained for these tasks by using
few-shot or zero-shot prompting techniques. A common NLP-task is
question-answering (QA). In this study, we propose a comprehensive performance
comparison between smaller fine-tuned models and out-of-the-box
instruction-following LLMs on the Stanford Question Answering Dataset 2.0
(SQuAD2), specifically when using a single-inference prompting technique. Since
the dataset contains unanswerable questions, previous work used a double
inference method. We propose a prompting style which aims to elicit the same
ability without the need for double inference, saving compute time and
resources. Furthermore, we investigate their generalization capabilities by
comparing their performance on similar but different QA datasets, without
fine-tuning neither model, emulating real-world uses where the context and
questions asked may differ from the original training distribution, for example
swapping Wikipedia for news articles.
  Our results show that smaller, fine-tuned models outperform current
State-Of-The-Art (SOTA) LLMs on the fine-tuned task, but recent SOTA models are
able to close this gap on the out-of-distribution test and even outperform the
fine-tuned models on 3 of the 5 tested QA datasets.

摘要：大型語言模型 (LLM) 在各種 NLP 任務中展現出令人滿意的成果，而無需使用少樣本或零樣本提示技術針對這些任務進行明確訓練。常見的 NLP 任務是問答 (QA)。在這項研究中，我們針對較小的微調模型和現成的、遵循指令的 LLM 在史丹佛問答資料集 2.0 (SQuAD2) 上進行全面的效能比較，特別是在使用單一推論提示技術時。由於資料集包含無法回答的問題，因此先前的工作使用雙重推論方法。我們提出了一種提示風格，旨在引出相同的技能，而無需雙重推論，從而節省運算時間和資源。此外，我們透過比較它們在相似但不同的 QA 資料集上的效能，來探討它們的概化能力，而無需微調任一模型，模擬真實世界的使用情況，其中語境和提出的問題可能與原始訓練分佈不同，例如用新聞文章替換維基百科。我們的結果顯示，較小的微調模型在微調任務上優於目前的最新技術 (SOTA) LLM，但最近的 SOTA 模型能夠在分佈外測試中縮小差距，甚至在 5 個測試的 QA 資料集中有 3 個資料集上優於微調模型。

##### **SAUGE: Taming SAM for Uncertainty-Aligned Multi-Granularity Edge Detection**
2412.12892v1 by Xing Liufu, Chaolei Tan, Xiaotong Lin, Yonggang Qi, Jinxuan Li, Jian-Fang Hu

Edge labels are typically at various granularity levels owing to the varying
preferences of annotators, thus handling the subjectivity of per-pixel labels
has been a focal point for edge detection. Previous methods often employ a
simple voting strategy to diminish such label uncertainty or impose a strong
assumption of labels with a pre-defined distribution, e.g., Gaussian. In this
work, we unveil that the segment anything model (SAM) provides strong prior
knowledge to model the uncertainty in edge labels. Our key insight is that the
intermediate SAM features inherently correspond to object edges at various
granularities, which reflects different edge options due to uncertainty.
Therefore, we attempt to align uncertainty with granularity by regressing
intermediate SAM features from different layers to object edges at
multi-granularity levels. In doing so, the model can fully and explicitly
explore diverse ``uncertainties'' in a data-driven fashion. Specifically, we
inject a lightweight module (~ 1.5% additional parameters) into the frozen SAM
to progressively fuse and adapt its intermediate features to estimate edges
from coarse to fine. It is crucial to normalize the granularity level of human
edge labels to match their innate uncertainty. For this, we simply perform
linear blending to the real edge labels at hand to create pseudo labels with
varying granularities. Consequently, our uncertainty-aligned edge detector can
flexibly produce edges at any desired granularity (including an optimal one).
Thanks to SAM, our model uniquely demonstrates strong generalizability for
cross-dataset edge detection. Extensive experimental results on BSDS500,
Muticue and NYUDv2 validate our model's superiority.

摘要：邊緣標籤通常具有不同的粒度等級，這是由於標註者的偏好不同，因此處理每個像素標籤的主觀性一直是邊緣檢測的重點。先前的做法通常採用簡單的投票策略來減少此類標籤的不確定性，或假設標籤具有預定義分佈（例如高斯分布）。在這項工作中，我們揭示了「分段任意模型」（SAM）提供了強大的先驗知識來模擬邊緣標籤中的不確定性。我們的關鍵見解是中間 SAM 特徵本質上對應於不同粒度的物件邊緣，這反映了由於不確定性而產生的不同邊緣選項。因此，我們嘗試通過將不同層的中間 SAM 特徵回歸到多粒度層級的物件邊緣，將不確定性與粒度對齊。這樣一來，模型可以完全且明確地以資料驅動的方式探索多樣化的「不確定性」。具體來說，我們將一個輕量級模組（約 1.5% 的額外參數）注入到凍結的 SAM 中，以逐步融合和調整其中間特徵，從粗略到精細地估計邊緣。將人類邊緣標籤的粒度層級標準化以匹配其內在不確定性至關重要。為此，我們只需對手邊的真實邊緣標籤執行線性混合，即可建立具有不同粒度的偽標籤。因此，我們的不確定性對齊邊緣檢測器可以靈活地產生任何所需粒度的邊緣（包括最佳粒度）。由於 SAM，我們的模型獨特地展示了跨資料集邊緣檢測的強大泛化性。在 BSDS500、Muticue 和 NYUDv2 上的廣泛實驗結果驗證了我們模型的優越性。

##### **ArtAug: Enhancing Text-to-Image Generation through Synthesis-Understanding Interaction**
2412.12888v1 by Zhongjie Duan, Qianyi Zhao, Cen Chen, Daoyuan Chen, Wenmeng Zhou, Yaliang Li, Yingda Chen

The emergence of diffusion models has significantly advanced image synthesis.
The recent studies of model interaction and self-corrective reasoning approach
in large language models offer new insights for enhancing text-to-image models.
Inspired by these studies, we propose a novel method called ArtAug for
enhancing text-to-image models in this paper. To the best of our knowledge,
ArtAug is the first one that improves image synthesis models via model
interactions with understanding models. In the interactions, we leverage human
preferences implicitly learned by image understanding models to provide
fine-grained suggestions for image synthesis models. The interactions can
modify the image content to make it aesthetically pleasing, such as adjusting
exposure, changing shooting angles, and adding atmospheric effects. The
enhancements brought by the interaction are iteratively fused into the
synthesis model itself through an additional enhancement module. This enables
the synthesis model to directly produce aesthetically pleasing images without
any extra computational cost. In the experiments, we train the ArtAug
enhancement module on existing text-to-image models. Various evaluation metrics
consistently demonstrate that ArtAug enhances the generative capabilities of
text-to-image models without incurring additional computational costs. The
source code and models will be released publicly.

摘要：擴散模型的出現顯著地推動了影像合成。
最近對於模型互動與自我修正推理方法的大型語言模型研究為增強文字轉影像模型提供了新的見解。
受這些研究啟發，我們在本文中提出了一種稱為 ArtAug 的新方法，用於增強文字轉影像模型。
據我們所知，ArtAug 是第一個透過模型與理解模型的互動來改善影像合成模型的方法。
在互動過程中，我們利用影像理解模型隱含學習到的人類偏好，為影像合成模型提供細緻的建議。
互動可以修改影像內容以使其美觀，例如調整曝光、改變拍攝角度和增加大氣效果。
互動帶來的增強會透過額外的增強模組反覆融合到合成模型本身中。
這使合成模型能夠直接產生美觀的影像，而無需任何額外的運算成本。
在實驗中，我們在現有的文字轉影像模型上訓練 ArtAug 增強模組。
各種評估指標一致地證明，ArtAug 增強了文字轉影像模型的生成能力，而不會產生額外的運算成本。
原始碼和模型將公開發布。

##### **A Comparative Study of Pruning Methods in Transformer-based Time Series Forecasting**
2412.12883v1 by Nicholas Kiefer, Arvid Weyrauch, Muhammed Öz, Achim Streit, Markus Götz, Charlotte Debus

The current landscape in time-series forecasting is dominated by
Transformer-based models. Their high parameter count and corresponding demand
in computational resources pose a challenge to real-world deployment,
especially for commercial and scientific applications with low-power embedded
devices. Pruning is an established approach to reduce neural network parameter
count and save compute. However, the implications and benefits of pruning
Transformer-based models for time series forecasting are largely unknown. To
close this gap, we provide a comparative benchmark study by evaluating
unstructured and structured pruning on various state-of-the-art multivariate
time series models. We study the effects of these pruning strategies on model
predictive performance and computational aspects like model size, operations,
and inference time. Our results show that certain models can be pruned even up
to high sparsity levels, outperforming their dense counterpart. However,
fine-tuning pruned models is necessary. Furthermore, we demonstrate that even
with corresponding hardware and software support, structured pruning is unable
to provide significant time savings.

摘要：目前時序預測的主流方法是基於 Transformer 的模型。這些模型具有高參數計數，對運算資源的需求也相對應地高，這對實際部署構成了一項挑戰，特別是對於採用低功耗嵌入式裝置的商業和科學應用。剪枝是一種既定的方法，用於減少神經網路參數計數並節省運算。然而，剪枝 Transformer 模型對時序預測的影響和好處在很大程度上仍未知。為了彌補這一差距，我們提供了一項比較基準研究，通過評估各種最先進的多元時序模型上的非結構化和結構化剪枝。我們研究了這些剪枝策略對模型預測效能和運算方面的影響，例如模型大小、運算和推論時間。我們的結果表明，某些模型甚至可以被剪枝到高稀疏度級別，並優於其密集對應項。然而，微調剪枝模型是必要的。此外，我們證明，即使有相應的硬體和軟體支援，結構化剪枝也無法提供顯著的時間節省。

##### **RAG-Star: Enhancing Deliberative Reasoning with Retrieval Augmented Verification and Refinement**
2412.12881v1 by Jinhao Jiang, Jiayi Chen, Junyi Li, Ruiyang Ren, Shijie Wang, Wayne Xin Zhao, Yang Song, Tao Zhang

Existing large language models (LLMs) show exceptional problem-solving
capabilities but might struggle with complex reasoning tasks. Despite the
successes of chain-of-thought and tree-based search methods, they mainly depend
on the internal knowledge of LLMs to search over intermediate reasoning steps,
limited to dealing with simple tasks involving fewer reasoning steps. In this
paper, we propose \textbf{RAG-Star}, a novel RAG approach that integrates the
retrieved information to guide the tree-based deliberative reasoning process
that relies on the inherent knowledge of LLMs. By leveraging Monte Carlo Tree
Search, RAG-Star iteratively plans intermediate sub-queries and answers for
reasoning based on the LLM itself. To consolidate internal and external
knowledge, we propose an retrieval-augmented verification that utilizes query-
and answer-aware reward modeling to provide feedback for the inherent reasoning
of LLMs. Our experiments involving Llama-3.1-8B-Instruct and GPT-4o demonstrate
that RAG-Star significantly outperforms previous RAG and reasoning methods.

摘要：現有的大型語言模型 (LLM) 展現出卓越的問題解決能力，但可能難以應付複雜的推理任務。儘管思考鏈和基於樹狀的搜尋方法獲得成功，它們主要依賴於 LLM 的內部知識來搜尋中間推理步驟，僅限於處理涉及較少推理步驟的簡單任務。在本文中，我們提出一個新穎的 RAG 方法，稱為 \textbf{RAG-Star}，它整合檢索到的資訊來引導基於樹狀的審議推理程序，該程序依賴於 LLM 的內在知識。藉由利用蒙地卡羅樹狀搜尋，RAG-Star 根據 LLM 本身反覆規劃中間子查詢和答案以進行推理。為了整合內部和外部知識，我們提出一個檢索增強驗證，它利用查詢和答案感知獎勵建模來提供 LLM 內在推理的回饋。我們涉及 Llama-3.1-8B-Instruct 和 GPT-4o 的實驗證明，RAG-Star 明顯優於先前的 RAG 和推理方法。

##### **Preference-Oriented Supervised Fine-Tuning: Favoring Target Model Over Aligned Large Language Models**
2412.12865v1 by Yuchen Fan, Yuzhong Hong, Qiushi Wang, Junwei Bao, Hongfei Jiang, Yang Song

Alignment, endowing a pre-trained Large language model (LLM) with the ability
to follow instructions, is crucial for its real-world applications.
Conventional supervised fine-tuning (SFT) methods formalize it as causal
language modeling typically with a cross-entropy objective, requiring a large
amount of high-quality instruction-response pairs. However, the quality of
widely used SFT datasets can not be guaranteed due to the high cost and
intensive labor for the creation and maintenance in practice. To overcome the
limitations associated with the quality of SFT datasets, we introduce a novel
\textbf{p}reference-\textbf{o}riented supervised \textbf{f}ine-\textbf{t}uning
approach, namely PoFT. The intuition is to boost SFT by imposing a particular
preference: \textit{favoring the target model over aligned LLMs on the same SFT
data.} This preference encourages the target model to predict a higher
likelihood than that predicted by the aligned LLMs, incorporating assessment
information on data quality (i.e., predicted likelihood by the aligned LLMs)
into the training process. Extensive experiments are conducted, and the results
validate the effectiveness of the proposed method. PoFT achieves stable and
consistent improvements over the SFT baselines across different training
datasets and base models. Moreover, we prove that PoFT can be integrated with
existing SFT data filtering methods to achieve better performance, and further
improved by following preference optimization procedures, such as DPO.

摘要：對齊是賦予預先訓練的大語言模型 (LLM) 遵循指令的能力，這對其真實世界的應用至關重要。
傳統的監督式微調 (SFT) 方法將其形式化為因果語言模型，通常使用交叉熵目標，需要大量高品質的指令回應對。然而，由於實際中建立和維護的高成本和大量勞動力，廣泛使用的 SFT 資料集的品質無法得到保證。為了克服與 SFT 資料集品質相關的限制，我們引進了一種新穎的 \textbf{p}reference-\textbf{o}riented supervised \textbf{f}ine-\textbf{t}uning 方法，即 PoFT。直覺上，我們透過施加特定的偏好來提升 SFT：\textit{在相同的 SFT 資料上偏好目標模型勝過對齊的 LLM。}此偏好鼓勵目標模型預測比對齊的 LLM 預測更高的可能性，將資料品質的評估資訊（即對齊的 LLM 預測的可能性）納入訓練程序中。我們進行了廣泛的實驗，結果驗證了所提出方法的有效性。PoFT 在不同的訓練資料集和基礎模型中，都獲得了穩定且持續優於 SFT 基準的改進。此外，我們證明 PoFT 可以與現有的 SFT 資料過濾方法整合，以達到更好的效能，並透過遵循偏好最佳化程序（例如 DPO）進一步提升。

##### **DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check**
2412.12863v1 by Ziheng Qiao, Houquan Zhou, Yumeng Liu, Zhenghua Li, Min Zhang, Bo Zhang, Chen Li, Ji Zhang, Fei Huang

One key characteristic of the Chinese spelling check (CSC) task is that
incorrect characters are usually similar to the correct ones in either
phonetics or glyph. To accommodate this, previous works usually leverage
confusion sets, which suffer from two problems, i.e., difficulty in determining
which character pairs to include and lack of probabilities to distinguish items
in the set. In this paper, we propose a light-weight plug-and-play DISC (i.e.,
decoding intervention with similarity of characters) module for CSC models.DISC
measures phonetic and glyph similarities between characters and incorporates
this similarity information only during the inference phase. This method can be
easily integrated into various existing CSC models, such as ReaLiSe, SCOPE, and
ReLM, without additional training costs. Experiments on three CSC benchmarks
demonstrate that our proposed method significantly improves model performance,
approaching and even surpassing the current state-of-the-art models.

摘要：中文拼寫檢查 (CSC) 任務的一個關鍵特徵是，不正確的字元通常在語音或字形上與正確的字元相似。為了適應這一點，先前的作品通常利用混淆集，混淆集有兩個問題，即難以確定要包含哪些字元對，以及缺乏區分集合中項目機率的問題。在本文中，我們提出了一個輕量級的即插即用 DISC（即解碼干預，具有字元相似性）模組，用於 CSC 模型。DISC 測量字元之間的語音和字形相似性，並僅在推論階段納入此相似性資訊。這種方法可以輕鬆整合到各種現有的 CSC 模型中，例如 ReaLiSe、SCOPE 和 ReLM，而無需額外訓練成本。在三個 CSC 基準上的實驗證明，我們提出的方法顯著改善了模型效能，接近甚至超越了現有的最先進模型。

##### **Bayesian Persuasion with Externalities: Exploiting Agent Types**
2412.12859v1 by Jonathan Shaki, Jiarui Gan, Sarit Kraus

We study a Bayesian persuasion problem with externalities. In this model, a
principal sends signals to inform multiple agents about the state of the world.
Simultaneously, due to the existence of externalities in the agents' utilities,
the principal also acts as a correlation device to correlate the agents'
actions. We consider the setting where the agents are categorized into a small
number of types. Agents of the same type share identical utility functions and
are treated equitably in the utility functions of both other agents and the
principal. We study the problem of computing optimal signaling strategies for
the principal, under three different types of signaling channels: public,
private, and semi-private. Our results include revelation-principle-style
characterizations of optimal signaling strategies, linear programming
formulations, and analysis of in/tractability of the optimization problems. It
is demonstrated that when the maximum number of deviating agents is bounded by
a constant, our LP-based formulations compute optimal signaling strategies in
polynomial time. Otherwise, the problems are NP-hard.

摘要：我們研究一個具有外部性的貝氏說服問題。在這個模型中，一個委託人發送訊號，以告知多個代理人關於世界狀態的資訊。同時，由於代理人效用中存在外部性，委託人也作為一個相關性裝置，以關聯代理人的行動。我們考慮代理人被分類為少數類型的設定。相同類型的代理人共享相同的效用函數，並且在其他代理人和委託人的效用函數中受到公平對待。我們研究在三種類型的信號傳遞管道下，為委託人計算最佳信號傳遞策略的問題：公開、私人和半私人。我們的結果包括最佳信號傳遞策略的啟示原則樣式表徵、線性規劃公式，以及最佳化問題的內部/可追溯性分析。證明當最大偏差代理人數量受常數約束時，我們基於 LP 的公式會在多項式時間內計算最佳信號傳遞策略。否則，這些問題是 NP 難的。

##### **Selective Shot Learning for Code Explanation**
2412.12852v1 by Paheli Bhattacharya, Rishabh Gupta

Code explanation plays a crucial role in the software engineering domain,
aiding developers in grasping code functionality efficiently. Recent work shows
that the performance of LLMs for code explanation improves in a few-shot
setting, especially when the few-shot examples are selected intelligently.
State-of-the-art approaches for such Selective Shot Learning (SSL) include
token-based and embedding-based methods. However, these SSL approaches have
been evaluated on proprietary LLMs, without much exploration on open-source
Code-LLMs. Additionally, these methods lack consideration for programming
language syntax. To bridge these gaps, we present a comparative study and
propose a novel SSL method (SSL_ner) that utilizes entity information for
few-shot example selection. We present several insights and show the
effectiveness of SSL_ner approach over state-of-the-art methods across two
datasets. To the best of our knowledge, this is the first systematic
benchmarking of open-source Code-LLMs while assessing the performances of the
various few-shot examples selection approaches for the code explanation task.

摘要：程式碼說明在軟體工程領域中扮演著至關重要的角色，
協助開發人員有效地掌握程式碼功能。最近的研究顯示
LLM 在程式碼說明方面的表現已在少次嘗試的設定中獲得改善，
特別是在少次嘗試的範例經過明智地選擇時。
此類選擇性嘗試學習 (SSL) 的最先進方法包括
基於標記和基於嵌入的方法。然而，這些 SSL 方法已
在專有 LLM 上進行評估，而未對開源
程式碼 LLM 進行太多探索。此外，這些方法缺乏對程式語言
語法的考量。為了彌補這些差距，我們提出了一項比較研究，
並提出了一種新穎的 SSL 方法 (SSL_ner)，該方法利用實體資訊進行
少次嘗試範例選擇。我們提出了幾項見解，並展示了 SSL_ner 方法
在兩個資料集上優於最先進方法的有效性。據我們所知，這是第一個
對開源程式碼 LLM 進行系統性的基準測試，同時評估各種
少次嘗試範例選擇方法在程式碼說明任務中的表現。

##### **Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**
2412.12850v1 by Qingqing Fang, Qinliang Su, Wenxi Lv, Wenchao Xu, Jianxing Yu

Many unsupervised visual anomaly detection methods train an auto-encoder to
reconstruct normal samples and then leverage the reconstruction error map to
detect and localize the anomalies. However, due to the powerful modeling and
generalization ability of neural networks, some anomalies can also be well
reconstructed, resulting in unsatisfactory detection and localization accuracy.
In this paper, a small coarsely-labeled anomaly dataset is first collected.
Then, a coarse-knowledge-aware adversarial learning method is developed to
align the distribution of reconstructed features with that of normal features.
The alignment can effectively suppress the auto-encoder's reconstruction
ability on anomalies and thus improve the detection accuracy. Considering that
anomalies often only occupy very small areas in anomalous images, a patch-level
adversarial learning strategy is further developed. Although no patch-level
anomalous information is available, we rigorously prove that by simply viewing
any patch features from anomalous images as anomalies, the proposed
knowledge-aware method can also align the distribution of reconstructed patch
features with the normal ones. Experimental results on four medical datasets
and two industrial datasets demonstrate the effectiveness of our method in
improving the detection and localization performance.

摘要：許多無監督視覺異常偵測方法會訓練自動編碼器來重建正常樣本，然後利用重建誤差圖來偵測和定位異常。然而，由於神經網路強大的建模和概化能力，一些異常也可以被良好地重建，導致不令人滿意的偵測和定位準確度。在本文中，首先收集了一個小型粗略標記的異常資料集。然後，開發了一個粗略知識感知對抗學習方法，以將重建特徵的分布與正常特徵的分布對齊。對齊可以有效地抑制自動編碼器對異常的重建能力，從而提高偵測準確度。考慮到異常通常只佔異常影像中很小的區域，進一步開發了區塊級對抗學習策略。儘管沒有區塊級異常資訊可用，但我們嚴格證明，只需將異常影像中的任何區塊特徵視為異常，所提出的知識感知方法也可以將重建區塊特徵的分布與正常特徵對齊。在四個醫學資料集和兩個工業資料集上的實驗結果證明了我們的方法在改善偵測和定位效能方面的有效性。

##### **ClarityEthic: Explainable Moral Judgment Utilizing Contrastive Ethical Insights from Large Language Models**
2412.12848v1 by Yuxi Sun, Wei Gao, Jing Ma, Hongzhan Lin, Ziyang Luo, Wenxuan Zhang

With the rise and widespread use of Large Language Models (LLMs), ensuring
their safety is crucial to prevent harm to humans and promote ethical
behaviors. However, directly assessing value valence (i.e., support or oppose)
by leveraging large-scale data training is untrustworthy and inexplainable. We
assume that emulating humans to rely on social norms to make moral decisions
can help LLMs understand and predict moral judgment. However, capturing human
values remains a challenge, as multiple related norms might conflict in
specific contexts. Consider norms that are upheld by the majority and promote
the well-being of society are more likely to be accepted and widely adopted
(e.g., "don't cheat,"). Therefore, it is essential for LLM to identify the
appropriate norms for a given scenario before making moral decisions. To this
end, we introduce a novel moral judgment approach called \textit{ClarityEthic}
that leverages LLMs' reasoning ability and contrastive learning to uncover
relevant social norms for human actions from different perspectives and select
the most reliable one to enhance judgment accuracy. Extensive experiments
demonstrate that our method outperforms state-of-the-art approaches in moral
judgment tasks. Moreover, human evaluations confirm that the generated social
norms provide plausible explanations that support the judgments. This suggests
that modeling human moral judgment with the emulating humans moral strategy is
promising for improving the ethical behaviors of LLMs.

摘要：隨著大型語言模型 (LLM) 的興起和廣泛使用，確保其安全性對於防止對人類造成傷害和促進道德行為至關重要。然而，直接利用大規模數據訓練來評估價值取向（即支持或反對）是不可靠且無法解釋的。我們假設仿效人類依賴社會規範來做出道德決策，可以幫助 LLM 理解和預測道德判斷。然而，捕捉人類價值觀仍然是一個挑戰，因為在特定情況下，多種相關規範可能會發生衝突。考慮到大多數人所堅持並促進社會福祉的規範更可能被接受和廣泛採用（例如，「不要作弊」）。因此，對於 LLM 來說，在做出道德決策之前，識別特定情境的適當規範至關重要。為此，我們引入了一種名為「ClarityEthic」的新型道德判斷方法，它利用 LLM 的推理能力和對比學習，從不同角度揭示人類行為相關的社會規範，並選擇最可靠的一個來增強判斷準確性。大量的實驗表明，我們的模型在道德判斷任務中優於最先進的方法。此外，人類評估證實，生成的社會規範提供了支持判斷的合理解釋。這表明，使用仿效人類道德策略對人類道德判斷進行建模，對於改善 LLM 的道德行為是有希望的。

##### **Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks**
2412.12843v1 by Xiaxin Zhu, Fangming Guo, Xianlei Long, Qingyi Gu, Chao Chen, Fuqiang Gu

Event-based semantic segmentation has great potential in autonomous driving
and robotics due to the advantages of event cameras, such as high dynamic
range, low latency, and low power cost. Unfortunately, current artificial
neural network (ANN)-based segmentation methods suffer from high computational
demands, the requirements for image frames, and massive energy consumption,
limiting their efficiency and application on resource-constrained edge/mobile
platforms. To address these problems, we introduce SLTNet, a spike-driven
lightweight transformer-based network designed for event-based semantic
segmentation. Specifically, SLTNet is built on efficient spike-driven
convolution blocks (SCBs) to extract rich semantic features while reducing the
model's parameters. Then, to enhance the long-range contextural feature
interaction, we propose novel spike-driven transformer blocks (STBs) with
binary mask operations. Based on these basic blocks, SLTNet employs a
high-efficiency single-branch architecture while maintaining the low energy
consumption of the Spiking Neural Network (SNN). Finally, extensive experiments
on DDD17 and DSEC-Semantic datasets demonstrate that SLTNet outperforms
state-of-the-art (SOTA) SNN-based methods by at least 7.30% and 3.30% mIoU,
respectively, with extremely 5.48x lower energy consumption and 1.14x faster
inference speed.

摘要：基於事件的語義分割在自動駕駛和機器人技術中具有巨大的潛力，這是因為事件相機具有高動態範圍、低延遲和低功耗成本等優勢。不幸的是，當前的基於人工神經網路 (ANN) 的分割方法存在計算需求高、對影像幀的要求以及大量耗能等問題，限制了它們在資源受限的邊緣/行動平台上的效率和應用。為了解決這些問題，我們引入了 SLTNet，這是一個以脈衝驅動的輕量級Transformer為基礎的網路，專為基於事件的語義分割而設計。具體來說，SLTNet 建立在高效的脈衝驅動卷積區塊 (SCB) 上，以提取豐富的語義特徵，同時減少模型的參數。然後，為了增強長程脈絡特徵交互，我們提出了結合二進位遮罩運算的新型脈衝驅動Transformer區塊 (STB)。基於這些基本區塊，SLTNet 採用高效率的單分支架構，同時保持脈衝神經網路 (SNN) 的低能耗。最後，在 DDD17 和 DSEC-Semantic 資料集上的廣泛實驗表明，SLTNet 在 mIoU 上分別優於最先進 (SOTA) 的基於 SNN 的方法至少 7.30% 和 3.30%，同時能耗極低，為 5.48 倍，推論速度為 1.14 倍。

##### **Benchmarking and Understanding Compositional Relational Reasoning of LLMs**
2412.12841v1 by Ruikang Ni, Da Xiao, Qingye Meng, Xiangyu Li, Shihui Zheng, Hongliang Liang

Compositional relational reasoning (CRR) is a hallmark of human intelligence,
but we lack a clear understanding of whether and how existing transformer large
language models (LLMs) can solve CRR tasks. To enable systematic exploration of
the CRR capability of LLMs, we first propose a new synthetic benchmark called
Generalized Associative Recall (GAR) by integrating and generalizing the
essence of several tasks in mechanistic interpretability (MI) study in a
unified framework. Evaluation shows that GAR is challenging enough for existing
LLMs, revealing their fundamental deficiency in CRR. Meanwhile, it is easy
enough for systematic MI study. Then, to understand how LLMs solve GAR tasks,
we use attribution patching to discover the core circuits reused by Vicuna-33B
across different tasks and a set of vital attention heads. Intervention
experiments show that the correct functioning of these heads significantly
impacts task performance. Especially, we identify two classes of heads whose
activations represent the abstract notion of true and false in GAR tasks
respectively. They play a fundamental role in CRR across various models and
tasks. The dataset and code are available at https://github.com/Caiyun-AI/GAR.

摘要：組合關係推理 (CRR) 是人類智慧的標誌，但我們對於現有的 transformer 大型語言模型 (LLM) 是否以及如何解決 CRR 任務缺乏明確的理解。為了能系統性地探索 LLM 的 CRR 能力，我們首先提出一個名為廣義聯想召回 (GAR) 的新合成基準，方法是將機制可解釋性 (MI) 研究中多項任務的精髓整合並概括到一個統一的架構中。評估顯示，GAR 對現有的 LLM 來說夠具挑戰性，揭露了它們在 CRR 中的基本缺陷。同時，它對於系統性的 MI 研究來說又夠容易。接著，為了了解 LLM 如何解決 GAR 任務，我們使用歸因修補來發現 Vicuna-33B 在不同任務中重複使用的核心電路和一組重要的注意力頭。介入實驗顯示，這些頭的正確運作會顯著影響任務績效。特別是，我們找出兩類頭，其激活分別代表 GAR 任務中真和假的抽象概念。它們在各種模型和任務中的 CRR 中扮演著基本的角色。資料集和程式碼可於 https://github.com/Caiyun-AI/GAR 取得。

##### **From An LLM Swarm To A PDDL-Empowered HIVE: Planning Self-Executed Instructions In A Multi-Modal Jungle**
2412.12839v1 by Kaustubh Vyas, Damien Graux, Yijun Yang, Sébastien Montella, Chenxin Diao, Wendi Zhou, Pavlos Vougiouklis, Ruofei Lai, Yang Ren, Keshuang Li, Jeff Z. Pan

In response to the call for agent-based solutions that leverage the
ever-increasing capabilities of the deep models' ecosystem, we introduce Hive
-- a comprehensive solution for selecting appropriate models and subsequently
planning a set of atomic actions to satisfy the end-users' instructions. Hive
operates over sets of models and, upon receiving natural language instructions
(i.e. user queries), schedules and executes explainable plans of atomic
actions. These actions can involve one or more of the available models to
achieve the overall task, while respecting end-users specific constraints.
Notably, Hive handles tasks that involve multi-modal inputs and outputs,
enabling it to handle complex, real-world queries. Our system is capable of
planning complex chains of actions while guaranteeing explainability, using an
LLM-based formal logic backbone empowered by PDDL operations. We introduce the
MuSE benchmark in order to offer a comprehensive evaluation of the multi-modal
capabilities of agent systems. Our findings show that our framework redefines
the state-of-the-art for task selection, outperforming other competing systems
that plan operations across multiple models while offering transparency
guarantees while fully adhering to user constraints.

摘要：為了回應利用深度模型生態系統不斷增強的功能的基於代理的解決方案的呼籲，我們引入了 Hive，這是一個用於選擇適當模型並隨後規劃一系列原子動作以滿足最終用戶指令的綜合解決方案。Hive 在模型集合上運作，並且在收到自然語言指令（即用戶查詢）時，會安排和執行可解釋的原子動作計劃。這些動作可以涉及一個或多個可用模型來實現整體任務，同時遵守最終用戶的具體約束。值得注意的是，Hive 處理涉及多模式輸入和輸出的任務，使其能夠處理複雜的現實世界查詢。我們的系統能夠規劃複雜的動作鏈，同時保證可解釋性，使用由 PDDL 操作增強的基於 LLM 的形式邏輯主幹。我們引入了 MuSE 基準，以便對代理系統的多模式功能進行全面評估。我們的研究結果表明，我們的框架重新定義了任務選擇的最新技術，優於其他競爭系統，這些系統跨多個模型規劃操作，同時提供透明度保證，同時完全遵守用戶約束。

##### **A Survey on Recommendation Unlearning: Fundamentals, Taxonomy, Evaluation, and Open Questions**
2412.12836v1 by Yuyuan Li, Xiaohua Feng, Chaochao Chen, Qiang Yang

Recommender systems have become increasingly influential in shaping user
behavior and decision-making, highlighting their growing impact in various
domains. Meanwhile, the widespread adoption of machine learning models in
recommender systems has raised significant concerns regarding user privacy and
security. As compliance with privacy regulations becomes more critical, there
is a pressing need to address the issue of recommendation unlearning, i.e.,
eliminating the memory of specific training data from the learned
recommendation models. Despite its importance, traditional machine unlearning
methods are ill-suited for recommendation unlearning due to the unique
challenges posed by collaborative interactions and model parameters. This
survey offers a comprehensive review of the latest advancements in
recommendation unlearning, exploring the design principles, challenges, and
methodologies associated with this emerging field. We provide a unified
taxonomy that categorizes different recommendation unlearning approaches,
followed by a summary of widely used benchmarks and metrics for evaluation. By
reviewing the current state of research, this survey aims to guide the
development of more efficient, scalable, and robust recommendation unlearning
techniques. Furthermore, we identify open research questions in this field,
which could pave the way for future innovations not only in recommendation
unlearning but also in a broader range of unlearning tasks across different
machine learning applications.

摘要：推薦系統在塑造使用者行為和決策制定上變得越來越有影響力，突顯了它們在各個領域中日益增長的影響力。同時，機器學習模型在推薦系統中的廣泛採用引起了關於使用者隱私和安全的重大疑慮。隨著對隱私法規的遵守變得越來越關鍵，迫切需要解決推薦遺忘的問題，即從已學習的推薦模型中消除特定訓練資料的記憶。儘管它很重要，但傳統的機器遺忘方法並不適合推薦遺忘，因為協作互動和模型參數帶來了獨特的挑戰。這項調查對推薦遺忘的最新進展提供了全面的回顧，探討了與這個新興領域相關的設計原則、挑戰和方法。我們提供了一個統一的分類法，對不同的推薦遺忘方法進行分類，然後總結了廣泛使用的基準和評估指標。透過回顧目前的的研究現況，這項調查旨在引導更有效率、可擴充和穩健的推薦遺忘技術的發展。此外，我們找出這個領域中開放的研究問題，這可能為未來的創新鋪路，不僅在推薦遺忘中，也在不同機器學習應用中更廣泛的遺忘任務中。

##### **DSGram: Dynamic Weighting Sub-Metrics for Grammatical Error Correction in the Era of Large Language Models**
2412.12832v1 by Jinxiang Xie, Yilin Li, Xunjian Yin, Xiaojun Wan

Evaluating the performance of Grammatical Error Correction (GEC) models has
become increasingly challenging, as large language model (LLM)-based GEC
systems often produce corrections that diverge from provided gold references.
This discrepancy undermines the reliability of traditional reference-based
evaluation metrics. In this study, we propose a novel evaluation framework for
GEC models, DSGram, integrating Semantic Coherence, Edit Level, and Fluency,
and utilizing a dynamic weighting mechanism. Our framework employs the Analytic
Hierarchy Process (AHP) in conjunction with large language models to ascertain
the relative importance of various evaluation criteria. Additionally, we
develop a dataset incorporating human annotations and LLM-simulated sentences
to validate our algorithms and fine-tune more cost-effective models.
Experimental results indicate that our proposed approach enhances the
effectiveness of GEC model evaluations.

摘要：評估文法錯誤修正 (GEC) 模型的效能變得越來越有挑戰性，因為基於大型語言模型 (LLM) 的 GEC 系統經常產生與提供的黃金參考不同的修正。這種差異會破壞傳統基於參考的評估指標的可靠性。在本研究中，我們提出了一個新的 GEC 模型評估架構 DSGram，它整合了語義一致性、編輯層級和流暢度，並利用動態加權機制。我們的架構採用層級分析法 (AHP) 結合大型語言模型來確定各種評估標準的相對重要性。此外，我們開發了一個包含人工標註和 LLM 模擬句子的資料集，以驗證我們的演算法並微調更具成本效益的模型。實驗結果表明，我們提出的方法增強了 GEC 模型評估的有效性。

##### **Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**
2412.12808v1 by Ziqi Qiu, Jianxing Yu, Yufeng Zhang, Hanjiang Lai, Yanghui Rao, Qinliang Su, Jian Yin

This paper focuses on sarcasm detection, which aims to identify whether given
statements convey criticism, mockery, or other negative sentiment opposite to
the literal meaning. To detect sarcasm, humans often require a comprehensive
understanding of the semantics in the statement and even resort to external
commonsense to infer the fine-grained incongruity. However, existing methods
lack commonsense inferential ability when they face complex real-world
scenarios, leading to unsatisfactory performance. To address this problem, we
propose a novel framework for sarcasm detection, which conducts incongruity
reasoning based on commonsense augmentation, called EICR. Concretely, we first
employ retrieval-augmented large language models to supplement the missing but
indispensable commonsense background knowledge. To capture complex contextual
associations, we construct a dependency graph and obtain the optimized topology
via graph refinement. We further introduce an adaptive reasoning skeleton that
integrates prior rules to extract sentiment-inconsistent subgraphs explicitly.
To eliminate the possible spurious relations between words and labels, we
employ adversarial contrastive learning to enhance the robustness of the
detector. Experiments conducted on five datasets demonstrate the effectiveness
of EICR.

摘要：本文重點探討諷刺偵測，旨在辨識給定的陳述是否傳達批評、嘲諷或其他與字面意思相反的負面情緒。為了偵測諷刺，人類通常需要全面了解陳述中的語義，甚至訴諸外部常識來推論細微的不一致。然而，現有方法在面對複雜的現實世界場景時缺乏常識推理能力，導致表現不佳。為了解決這個問題，我們提出了一個新的諷刺偵測架構，該架構基於常識擴充進行不一致推理，稱為 EICR。具體來說，我們首先採用檢索擴充大型語言模型來補充遺失但不可或缺的常識背景知識。為了捕捉複雜的上下文關聯，我們構造了一個依賴圖，並透過圖形優化獲得最佳拓撲。我們進一步引入一個自適應推理架構，整合先驗規則來明確提取情緒不一致的子圖。為了消除詞彙和標籤之間可能的虛假關係，我們採用對抗對比學習來增強檢測器的魯棒性。在五個資料集上進行的實驗證明了 EICR 的有效性。

##### **Cross-Dialect Information Retrieval: Information Access in Low-Resource and High-Variance Languages**
2412.12806v1 by Robert Litschko, Oliver Kraus, Verena Blaschke, Barbara Plank

A large amount of local and culture-specific knowledge (e.g., people,
traditions, food) can only be found in documents written in dialects. While
there has been extensive research conducted on cross-lingual information
retrieval (CLIR), the field of cross-dialect retrieval (CDIR) has received
limited attention. Dialect retrieval poses unique challenges due to the limited
availability of resources to train retrieval models and the high variability in
non-standardized languages. We study these challenges on the example of German
dialects and introduce the first German dialect retrieval dataset, dubbed
WikiDIR, which consists of seven German dialects extracted from Wikipedia.
Using WikiDIR, we demonstrate the weakness of lexical methods in dealing with
high lexical variation in dialects. We further show that commonly used
zero-shot cross-lingual transfer approach with multilingual encoders do not
transfer well to extremely low-resource setups, motivating the need for
resource-lean and dialect-specific retrieval models. We finally demonstrate
that (document) translation is an effective way to reduce the dialect gap in
CDIR.

摘要：大量的在地和文化特定知識（例如，人、傳統、食物）只能在以方言寫成的文件中找到。雖然已經對跨語言資訊檢索 (CLIR) 進行了廣泛的研究，但跨方言檢索 (CDIR) 領域受到的關注有限。方言檢索由於用於訓練檢索模型的資源有限以及非標準化語言的高度可變性，因此提出了獨特的挑戰。我們以德語方言為例研究這些挑戰，並介紹了第一個德語方言檢索數據集，稱為 WikiDIR，它包含從維基百科中提取的七種德語方言。使用 WikiDIR，我們展示了詞彙方法在處理方言中高度詞彙變異時的弱點。我們進一步表明，使用多語言編碼器常用的零次跨語言轉移方法無法很好地轉移到極低資源設置，這促使需要資源精簡且特定於方言的檢索模型。我們最終證明（文件）翻譯是縮小 CDIR 中方言差距的有效方法。

##### **Breaking the Programming Language Barrier: Multilingual Prompting to Empower Non-Native English Learners**
2412.12800v1 by James Prather, Brent N. Reeves, Paul Denny, Juho Leinonen, Stephen MacNeil, Andrew Luxton-Reilly, João Orvalho, Amin Alipour, Ali Alfageeh, Thezyrie Amarouche, Bailey Kimmel, Jared Wright, Musa Blake, Gweneth Barbre

Non-native English speakers (NNES) face multiple barriers to learning
programming. These barriers can be obvious, such as the fact that programming
language syntax and instruction are often in English, or more subtle, such as
being afraid to ask for help in a classroom full of native English speakers.
However, these barriers are frustrating because many NNES students know more
about programming than they can articulate in English. Advances in generative
AI (GenAI) have the potential to break down these barriers because state of the
art models can support interactions in multiple languages. Moreover, recent
work has shown that GenAI can be highly accurate at code generation and
explanation. In this paper, we provide the first exploration of NNES students
prompting in their native languages (Arabic, Chinese, and Portuguese) to
generate code to solve programming problems. Our results show that students are
able to successfully use their native language to solve programming problems,
but not without some difficulty specifying programming terminology and
concepts. We discuss the challenges they faced, the implications for practice
in the short term, and how this might transform computing education globally in
the long term.

摘要：非母語英語人士 (NNES) 在學習程式設計時會遇到多重障礙。這些障礙可能是顯而易見的，例如程式語言的語法和指令通常都是英文，或較為隱晦的，例如害怕在充滿母語人士的教室中尋求協助。然而，這些障礙很令人沮喪，因為許多 NNES 學生對程式設計的了解遠超過他們用英文表達的能力。生成式 AI (GenAI) 的進步有潛力打破這些障礙，因為最先進的模型可以支援多種語言的互動。此外，最近的研究顯示，GenAI 在程式碼產生和說明方面可以非常精確。在本文中，我們首次探討 NNES 學生使用其母語 (阿拉伯語、中文和葡萄牙語) 來產生程式碼以解決程式設計問題。我們的結果顯示，學生能夠成功使用其母語來解決程式設計問題，但並非沒有在說明程式設計術語和概念時遇到一些困難。我們討論了他們所面臨的挑戰、對短期實務的影響，以及這如何從長遠來看轉變全球的電腦教育。

##### **Is it the end of (generative) linguistics as we know it?**
2412.12797v1 by Cristiano Chesi

A significant debate has emerged in response to a paper written by Steven
Piantadosi (Piantadosi, 2023) and uploaded to the LingBuzz platform, the open
archive for generative linguistics. Piantadosi's dismissal of Chomsky's
approach is ruthless, but generative linguists deserve it. In this paper, I
will adopt three idealized perspectives -- computational, theoretical, and
experimental -- to focus on two fundamental issues that lend partial support to
Piantadosi's critique: (a) the evidence challenging the Poverty of Stimulus
(PoS) hypothesis and (b) the notion of simplicity as conceived within
mainstream Minimalism. In conclusion, I argue that, to reclaim a central role
in language studies, generative linguistics -- representing a prototypical
theoretical perspective on language -- needs a serious update leading to (i)
more precise, consistent, and complete formalizations of foundational
intuitions and (ii) the establishment and utilization of a standardized dataset
of crucial empirical evidence to evaluate the theory's adequacy. On the other
hand, ignoring the formal perspective leads to major drawbacks in both
computational and experimental approaches. Neither descriptive nor explanatory
adequacy can be easily achieved without the precise formulation of general
principles that can be challenged empirically.

摘要：<paragraph>史蒂文·皮安塔多西（Steven Piantadosi，2023 年）撰寫的一篇論文引起了激烈的爭論，並上傳到開放式生成語言學檔案庫 LingBuzz 平台。皮安塔多西對喬姆斯基方法的駁斥毫不留情，但生成語言學家應得此待遇。在本文中，我將採用三種理想化的觀點——計算、理論和實驗——來關注兩個基本問題，這兩個問題部分支持皮安塔多西的批評：(a) 挑戰刺激貧乏 (PoS) 假說的證據，以及 (b) 在主流極簡主義中構思的簡潔性概念。最後，我認為，為了在語言研究中重新獲得核心地位，生成語言學——代表語言的原型理論觀點——需要進行一項嚴肅的更新，導致 (i) 對基本直覺做出更精確、一致且完整的形式化，以及 (ii) 建立和利用標準化的關鍵實證證據數據集來評估理論的充分性。另一方面，忽視形式觀點會導致計算和實驗方法出現重大缺點。如果沒有精確制定可以通過實證挑戰的一般原則，那麼描述性或解釋性充分性都難以輕易實現。</paragraph>

##### **Implicit Location-Caption Alignment via Complementary Masking for Weakly-Supervised Dense Video Captioning**
2412.12791v1 by Shiping Ge, Qiang Chen, Zhiwei Jiang, Yafeng Yin, Liu Qin, Ziyao Chen, Qing Gu

Weakly-Supervised Dense Video Captioning (WSDVC) aims to localize and
describe all events of interest in a video without requiring annotations of
event boundaries. This setting poses a great challenge in accurately locating
the temporal location of event, as the relevant supervision is unavailable.
Existing methods rely on explicit alignment constraints between event locations
and captions, which involve complex event proposal procedures during both
training and inference. To tackle this problem, we propose a novel implicit
location-caption alignment paradigm by complementary masking, which simplifies
the complex event proposal and localization process while maintaining
effectiveness. Specifically, our model comprises two components: a dual-mode
video captioning module and a mask generation module. The dual-mode video
captioning module captures global event information and generates descriptive
captions, while the mask generation module generates differentiable positive
and negative masks for localizing the events. These masks enable the implicit
alignment of event locations and captions by ensuring that captions generated
from positively and negatively masked videos are complementary, thereby forming
a complete video description. In this way, even under weak supervision, the
event location and event caption can be aligned implicitly. Extensive
experiments on the public datasets demonstrate that our method outperforms
existing weakly-supervised methods and achieves competitive results compared to
fully-supervised methods.

摘要：弱监督密集视频字幕（WSDVC）旨在定位和描述视频中所有感兴趣的事件，而无需事件边界的注释。由于相关监督不可用，此设置对准确定位事件的时间位置提出了巨大挑战。现有方法依赖于事件位置和字幕之间的显式对齐约束，其中涉及在训练和推理期间复杂的事件提议程序。为了解决这个问题，我们提出了一种新的隐式位置-字幕对齐范例，通过互补掩码，它简化了复杂的事件提议和定位过程，同时保持了有效性。具体来说，我们的模型包含两个组件：双模式视频字幕模块和掩码生成模块。双模式视频字幕模块捕获全局事件信息并生成描述性字幕，而掩码生成模块生成可微分的正负掩码以定位事件。这些掩码通过确保从正掩码和负掩码视频生成的字幕是互补的，从而实现事件位置和字幕的隐式对齐，从而形成完整的视频描述。通过这种方式，即使在弱监督下，事件位置和事件字幕也可以隐式对齐。在公共数据集上的大量实验表明，我们的方法优于现有的弱监督方法，并且与完全监督的方法相比取得了有竞争力的结果。

##### **Predicting change in time production -- A machine learning approach to time perception**
2412.12781v1 by Amrapali Pednekar, Alvaro Garrido, Yara Khaluf, Pieter Simoens

Time perception research has advanced significantly over the years. However,
some areas remain largely unexplored. This study addresses two such
under-explored areas in timing research: (1) A quantitative analysis of time
perception at an individual level, and (2) Time perception in an ecological
setting. In this context, we trained a machine learning model to predict the
direction of change in an individual's time production. The model's training
data was collected using an ecologically valid setup. We moved closer to an
ecological setting by conducting an online experiment with 995 participants
performing a time production task that used naturalistic videos (no audio) as
stimuli. The model achieved an accuracy of 61%. This was 10 percentage points
higher than the baseline models derived from cognitive theories of timing. The
model performed equally well on new data from a second experiment, providing
evidence of its generalization capabilities. The model's output analysis
revealed that it also contained information about the magnitude of change in
time production. The predictions were further analysed at both population and
individual level. It was found that a participant's previous timing performance
played a significant role in determining the direction of change in time
production. By integrating attentional-gate theories from timing research with
feature importance techniques from machine learning, we explained model
predictions using cognitive theories of timing. The model and findings from
this study have potential applications in systems involving human-computer
interactions where understanding and predicting changes in user's time
perception can enable better user experience and task performance.

摘要：<paragraph>隨著時間推移，時間知覺研究已取得顯著進展。然而，
一些領域仍未被廣泛探索。本研究探討了時間研究中兩個尚未充分探索的領域：(1) 個體層面的時間知覺量化分析，以及 (2) 生態環境中的時間知覺。在此脈絡中，我們訓練了一個機器學習模型，以預測個人時間產出的變化方向。該模型的訓練數據是使用生態學上有效的設置收集的。我們通過對 995 名參與者進行在線實驗，執行時間製作任務，使用自然主義影片（無音訊）作為刺激，從而更接近生態環境設置。該模型達到了 61% 的準確度。這比源自時間認知理論的基準模型高出 10 個百分點。該模型在第二次實驗的新數據中表現得同樣出色，提供了其泛化能力的證據。該模型的輸出分析顯示，它還包含有關時間產出變化幅度的資訊。預測在人口和個人層面進一步分析。結果發現，參與者先前的計時表現對於確定時間產出變化方向起著重要作用。通過將時間研究中的注意力門控理論與機器學習中的特徵重要性技術相結合，我們使用時間的認知理論解釋了模型預測。本研究的模型和發現具有在涉及人機互動的系統中的潛在應用，在這些系統中，理解和預測使用者時間知覺的變化可以帶來更好的使用者體驗和任務表現。</paragraph>

##### **Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**
2412.12778v1 by Chengzhou Yu, Huihui Fang, Hongqiu Wang, Ting Deng, Qing Du, Yanwu Xu, Weihua Yang

Fundus imaging is a critical tool in ophthalmology, with different imaging
modalities offering unique advantages. For instance, fundus fluorescein
angiography (FFA) can accurately identify eye diseases. However, traditional
invasive FFA involves the injection of sodium fluorescein, which can cause
discomfort and risks. Generating corresponding FFA images from non-invasive
fundus images holds significant practical value but also presents challenges.
First, limited datasets constrain the performance and effectiveness of models.
Second, previous studies have primarily focused on generating FFA for single
diseases or single modalities, often resulting in poor performance for patients
with various ophthalmic conditions. To address these issues, we propose a novel
latent diffusion model-based framework, Diffusion, which introduces a
fine-tuning protocol to overcome the challenge of limited medical data and
unleash the generative capabilities of diffusion models. Furthermore, we
designed a new approach to tackle the challenges of generating across different
modalities and disease types. On limited datasets, our framework achieves
state-of-the-art results compared to existing methods, offering significant
potential to enhance ophthalmic diagnostics and patient care. Our code will be
released soon to support further research in this field.

摘要：眼底成像技術是眼科中的一項重要工具，不同的成像方式各有優勢。例如，眼底螢光素血管攝影 (FFA) 可精準辨識眼部疾病。然而，傳統侵入式的 FFA 會注射螢光素鈉，可能會造成不適和風險。從非侵入式眼底影像中產生相對應的 FFA 影像具有重要的實用價值，但也存在挑戰。首先，有限的資料集會限制模型的效能和效果。其次，先前的研究主要集中在為單一疾病或單一方式產生 FFA，對於患有多種眼科疾病的患者，效能通常不佳。為了解決這些問題，我們提出一個新穎的潛在擴散模型架構，稱為 Diffusion，它引入一個微調協定，以克服醫療資料有限的挑戰，並釋放擴散模型的生成能力。此外，我們設計了一種新方法來應對跨不同方式和疾病類型生成影像的挑戰。在有限的資料集上，與現有方法相比，我們的架構達到了最先進的結果，為增強眼科診斷和患者照護提供了顯著的潛力。我們的程式碼將很快釋出，以支持此領域的進一步研究。

##### **Guided and Variance-Corrected Fusion with One-shot Style Alignment for Large-Content Image Generation**
2412.12771v1 by Shoukun Sun, Min Xian, Tiankai Yao, Fei Xu, Luca Capriotti

Producing large images using small diffusion models is gaining increasing
popularity, as the cost of training large models could be prohibitive. A common
approach involves jointly generating a series of overlapped image patches and
obtaining large images by merging adjacent patches. However, results from
existing methods often exhibit obvious artifacts, e.g., seams and inconsistent
objects and styles. To address the issues, we proposed Guided Fusion (GF),
which mitigates the negative impact from distant image regions by applying a
weighted average to the overlapping regions. Moreover, we proposed
Variance-Corrected Fusion (VCF), which corrects data variance at
post-averaging, generating more accurate fusion for the Denoising Diffusion
Probabilistic Model. Furthermore, we proposed a one-shot Style Alignment (SA),
which generates a coherent style for large images by adjusting the initial
input noise without adding extra computational burden. Extensive experiments
demonstrated that the proposed fusion methods improved the quality of the
generated image significantly. As a plug-and-play module, the proposed method
can be widely applied to enhance other fusion-based methods for large image
generation.

摘要：使用小型扩散模型生成大图像正变得越来越流行，因为训练大型模型的成本可能很高。一种常见的方法包括联合生成一系列重叠的图像块，并通过合并相邻的块来获得大图像。然而，现有方法的结果通常会出现明显的伪影，例如接缝以及不一致的对象和样式。为了解决这些问题，我们提出了引导融合 (GF)，它通过对重叠区域应用加权平均来减轻来自远距离图像区域的负面影响。此外，我们提出了方差校正融合 (VCF)，它在后平均值校正数据方差，为去噪扩散概率模型生成更准确的融合。此外，我们提出了单次样式对齐 (SA)，它通过调整初始输入噪声而为大图像生成一致的样式，而不会增加额外的计算负担。大量实验表明，所提出的融合方法显著提高了生成图像的质量。作为即插即用模块，所提出的方法可以广泛应用于增强其他基于融合的方法以进行大图像生成。

##### **A Survey of Calibration Process for Black-Box LLMs**
2412.12767v1 by Liangru Xie, Hui Liu, Jingying Zeng, Xianfeng Tang, Yan Han, Chen Luo, Jing Huang, Zhen Li, Suhang Wang, Qi He

Large Language Models (LLMs) demonstrate remarkable performance in semantic
understanding and generation, yet accurately assessing their output reliability
remains a significant challenge. While numerous studies have explored
calibration techniques, they primarily focus on White-Box LLMs with accessible
parameters. Black-Box LLMs, despite their superior performance, pose heightened
requirements for calibration techniques due to their API-only interaction
constraints. Although recent researches have achieved breakthroughs in
black-box LLMs calibration, a systematic survey of these methodologies is still
lacking. To bridge this gap, we presents the first comprehensive survey on
calibration techniques for black-box LLMs. We first define the Calibration
Process of LLMs as comprising two interrelated key steps: Confidence Estimation
and Calibration. Second, we conduct a systematic review of applicable methods
within black-box settings, and provide insights on the unique challenges and
connections in implementing these key steps. Furthermore, we explore typical
applications of Calibration Process in black-box LLMs and outline promising
future research directions, providing new perspectives for enhancing
reliability and human-machine alignment. This is our GitHub link:
https://github.com/LiangruXie/Calibration-Process-in-Black-Box-LLMs

摘要：大型語言模型 (LLM) 在語意理解和生成方面表現出色，但準確評估其輸出可靠性仍然是一項重大挑戰。儘管許多研究探索了校準技術，但它們主要關注具有可訪問參數的白盒 LLM。黑盒 LLM 儘管性能優異，但由於其僅限 API 的交互約束，對校準技術提出了更高的要求。儘管最近的研究在黑盒 LLM 校準方面取得了突破，但對這些方法的系統性調查仍然缺乏。為了彌補這一差距，我們提供了針對黑盒 LLM 校準技術的第一份全面調查。我們首先將 LLM 的校準過程定義為包含兩個相互關聯的關鍵步驟：置信度估計和校準。其次，我們對黑盒設置中適用的方法進行了系統性回顧，並提供了關於實施這些關鍵步驟的獨特挑戰和聯繫的見解。此外，我們探討了校準過程在黑盒 LLM 中的典型應用，並概述了有前景的未來研究方向，為提高可靠性和人機對齊提供了新的視角。這是我們的 GitHub 連結：
https://github.com/LiangruXie/Calibration-Process-in-Black-Box-LLMs

##### **Revealing the impact of synthetic native samples and multi-tasking strategies in Hindi-English code-mixed humour and sarcasm detection**
2412.12761v1 by Debajyoti Mazumder, Aakash Kumar, Jasabanta Patro

In this paper, we reported our experiments with various strategies to improve
code-mixed humour and sarcasm detection. We did all of our experiments for
Hindi-English code-mixed scenario, as we have the linguistic expertise for the
same. We experimented with three approaches, namely (i) native sample mixing,
(ii) multi-task learning (MTL), and (iii) prompting very large multilingual
language models (VMLMs). In native sample mixing, we added monolingual task
samples in code-mixed training sets. In MTL learning, we relied on native and
code-mixed samples of a semantically related task (hate detection in our case).
Finally, in our third approach, we evaluated the efficacy of VMLMs via few-shot
context prompting. Some interesting findings we got are (i) adding native
samples improved humor (raising the F1-score up to 6.76%) and sarcasm (raising
the F1-score up to 8.64%) detection, (ii) training MLMs in an MTL framework
boosted performance for both humour (raising the F1-score up to 10.67%) and
sarcasm (increment up to 12.35% in F1-score) detection, and (iii) prompting
VMLMs couldn't outperform the other approaches. Finally, our ablation studies
and error analysis discovered the cases where our model is yet to improve. We
provided our code for reproducibility.

摘要：<paragraph>在這篇論文中，我們報告了我們使用各種策略來改善代碼混合幽默和諷刺偵測的實驗。我們對印地語-英語代碼混合場景進行了所有實驗，因為我們擁有這方面的語言專業知識。我們嘗試了三種方法，分別是 (i) 原生樣本混合、(ii) 多任務學習 (MTL) 和 (iii) 提示非常大的多語言語言模型 (VMLM)。在原生樣本混合中，我們在代碼混合訓練集中添加了單語任務樣本。在 MTL 學習中，我們依賴於語義相關任務（在我們的案例中是仇恨偵測）的原生和代碼混合樣本。最後，在我們的第三種方法中，我們通過少次提示語境提示評估了 VMLM 的功效。我們獲得的一些有趣的發現是 (i) 添加原生樣本改進了幽默（將 F1 分數提高到 6.76%）和諷刺（將 F1 分數提高到 8.64%）偵測，(ii) 在 MTL 框架中訓練 MLM 提升了幽默（將 F1 分數提高到 10.67%）和諷刺（將 F1 分數提高到 12.35%）偵測的效能，以及 (iii) 提示 VMLM 無法優於其他方法。最後，我們的消融研究和錯誤分析發現了我們的模型尚未改進的案例。我們提供了我們的代碼以供重現。</paragraph>

##### **Your Next State-of-the-Art Could Come from Another Domain: A Cross-Domain Analysis of Hierarchical Text Classification**
2412.12744v1 by Nan Li, Bo Kang, Tijl De Bie

Text classification with hierarchical labels is a prevalent and challenging
task in natural language processing. Examples include assigning ICD codes to
patient records, tagging patents into IPC classes, assigning EUROVOC
descriptors to European legal texts, and more. Despite its widespread
applications, a comprehensive understanding of state-of-the-art methods across
different domains has been lacking. In this paper, we provide the first
comprehensive cross-domain overview with empirical analysis of state-of-the-art
methods. We propose a unified framework that positions each method within a
common structure to facilitate research. Our empirical analysis yields key
insights and guidelines, confirming the necessity of learning across different
research areas to design effective methods. Notably, under our unified
evaluation pipeline, we achieved new state-of-the-art results by applying
techniques beyond their original domains.

摘要：階層標籤的文本分類是自然語言處理中普遍且具挑戰性的任務。範例包括將 ICD 代碼指定給病歷、將專利標記為 IPC 類別、將 EUROVOC 描述符指定給歐洲法律文本等等。儘管其應用廣泛，但對於跨不同領域的最新方法的全面理解卻付之闕如。在本文中，我們提供了第一個全面的跨領域概觀，並對最新方法進行了實證分析。我們提出了一個統一的架構，將每種方法置於一個共同的結構中，以利於研究。我們的實證分析產生了關鍵見解和指導方針，證實了在不同研究領域學習的必要性，以設計有效的方法。值得注意的是，在我們的統一評估管道下，我們通過應用超越其原始領域的技術，達到了新的最新結果。

##### **GIRAFFE: Design Choices for Extending the Context Length of Visual Language Models**
2412.12735v1 by Mukai Li, Lei Li, Shansan Gong, Qi Liu

Visual Language Models (VLMs) demonstrate impressive capabilities in
processing multimodal inputs, yet applications such as visual agents, which
require handling multiple images and high-resolution videos, demand enhanced
long-range modeling. Moreover, existing open-source VLMs lack systematic
exploration into extending their context length, and commercial models often
provide limited details. To tackle this, we aim to establish an effective
solution that enhances long context performance of VLMs while preserving their
capacities in short context scenarios. Towards this goal, we make the best
design choice through extensive experiment settings from data curation to
context window extending and utilizing: (1) we analyze data sources and length
distributions to construct ETVLM - a data recipe to balance the performance
across scenarios; (2) we examine existing position extending methods, identify
their limitations and propose M-RoPE++ as an enhanced approach; we also choose
to solely instruction-tune the backbone with mixed-source data; (3) we discuss
how to better utilize extended context windows and propose hybrid-resolution
training. Built on the Qwen-VL series model, we propose Giraffe, which is
effectively extended to 128K lengths. Evaluated on extensive long context VLM
benchmarks such as VideoMME and Viusal Haystacks, our Giraffe achieves
state-of-the-art performance among similarly sized open-source long VLMs and is
competitive with commercial model GPT-4V. We will open-source the code, data,
and models.

摘要：視覺語言模型 (VLM) 在處理多模態輸入方面展現出令人印象深刻的能力，但需要處理多張影像和高解析度影片的視覺代理等應用程式需要增強遠距建模。此外，現有的開放原始碼 VLM 缺乏系統性探索以延伸其內容長度，而商業模式通常提供有限的細節。為了解決這個問題，我們旨在建立一個有效的解決方案，在保留 VLM 在短內容情境中的能力下，增強其在長內容情境中的表現。為了達成這個目標，我們透過廣泛的實驗設定，從資料整理到內容視窗延伸和利用，做出最佳設計選擇：(1) 我們分析資料來源和長度分佈，以建構 ETVLM - 一種資料配方，以平衡不同情境下的表現；(2) 我們檢視現有的位置延伸方法，找出其限制，並提出 M-RoPE++ 作為一種增強的方法；我們也選擇僅使用混合來源資料對主幹進行指令調整；(3) 我們討論如何更好地利用延伸的內容視窗，並提出混合解析度訓練。建構在 Qwen-VL 系列模型上，我們提出 Giraffe，它有效地延伸到 128K 的長度。在廣泛的長內容 VLM 基準上進行評估，例如 VideoMME 和 Viusal Haystacks，我們的 Giraffe 在相似大小的開放原始碼長 VLM 中取得最先進的表現，並且與商業模型 GPT-4V 競爭。我們將開放原始碼、資料和模型。

##### **EventFull: Complete and Consistent Event Relation Annotation**
2412.12733v1 by Alon Eirew, Eviatar Nachshoni, Aviv Slobodkin, Ido Dagan

Event relation detection is a fundamental NLP task, leveraged in many
downstream applications, whose modeling requires datasets annotated with event
relations of various types. However, systematic and complete annotation of
these relations is costly and challenging, due to the quadratic number of event
pairs that need to be considered. Consequently, many current event relation
datasets lack systematicity and completeness. In response, we introduce
\textit{EventFull}, the first tool that supports consistent, complete and
efficient annotation of temporal, causal and coreference relations via a
unified and synergetic process. A pilot study demonstrates that EventFull
accelerates and simplifies the annotation process while yielding high
inter-annotator agreement.

摘要：事件關係偵測是一項基本的 NLP 任務，運用於許多下游應用程式，其建模需要標註有各種類型事件關係的資料集。然而，由於需要考慮的事件對數目為二次方，因此對這些關係進行系統化且完整的標註既昂貴又具挑戰性。因此，許多目前的事件關係資料集缺乏系統化和完整性。為了解決此問題，我們引入了 \textit{EventFull}，這是第一個透過統一且協同的流程支援對時間、因果和共指關係進行一致、完整且有效率的標註的工具。一項試驗研究證明，EventFull 加快並簡化了標註流程，同時產生了很高的標註者間一致性。

##### **SentiQNF: A Novel Approach to Sentiment Analysis Using Quantum Algorithms and Neuro-Fuzzy Systems**
2412.12731v1 by Kshitij Dave, Nouhaila Innan, Bikash K. Behera, Zahid Mumtaz, Saif Al-Kuwari, Ahmed Farouk

Sentiment analysis is an essential component of natural language processing,
used to analyze sentiments, attitudes, and emotional tones in various contexts.
It provides valuable insights into public opinion, customer feedback, and user
experiences. Researchers have developed various classical machine learning and
neuro-fuzzy approaches to address the exponential growth of data and the
complexity of language structures in sentiment analysis. However, these
approaches often fail to determine the optimal number of clusters, interpret
results accurately, handle noise or outliers efficiently, and scale effectively
to high-dimensional data. Additionally, they are frequently insensitive to
input variations. In this paper, we propose a novel hybrid approach for
sentiment analysis called the Quantum Fuzzy Neural Network (QFNN), which
leverages quantum properties and incorporates a fuzzy layer to overcome the
limitations of classical sentiment analysis algorithms. In this study, we test
the proposed approach on two Twitter datasets: the Coronavirus Tweets Dataset
(CVTD) and the General Sentimental Tweets Dataset (GSTD), and compare it with
classical and hybrid algorithms. The results demonstrate that QFNN outperforms
all classical, quantum, and hybrid algorithms, achieving 100% and 90% accuracy
in the case of CVTD and GSTD, respectively. Furthermore, QFNN demonstrates its
robustness against six different noise models, providing the potential to
tackle the computational complexity associated with sentiment analysis on a
large scale in a noisy environment. The proposed approach expedites sentiment
data processing and precisely analyses different forms of textual data, thereby
enhancing sentiment classification and insights associated with sentiment
analysis.

摘要：情緒分析是自然語言處理中一個重要的組成部分，
用於分析各種情境中的情緒、態度和情感語氣。
它提供有價值的見解，了解公眾輿論、客戶回饋和使用者
體驗。研究人員開發了各種經典機器學習和
神經模糊方法來解決情緒分析中資料的指數成長和
語言結構的複雜性。然而，這些
方法通常無法確定最佳群集數量，準確解讀
結果，有效處理雜訊或異常值，以及有效擴充
到高維度資料。此外，它們經常對
輸入變化不敏感。在本文中，我們提出了一種
稱為量子模糊神經網路 (QFNN) 的新混合方法，它
利用量子特性並結合模糊層來克服經典情緒分析演算法的
限制。在這項研究中，我們在兩個 Twitter 資料集上測試
提出的方法：冠狀病毒推文資料集 (CVTD) 和一般情緒推文資料集 (GSTD)，並將其與
經典和混合演算法進行比較。結果表明，QFNN 優於
所有經典、量子和混合演算法，在 CVTD 和 GSTD 的情況下分別達到 100% 和 90% 的準確度。此外，QFNN 展示了其
對六種不同雜訊模型的穩健性，提供了
在雜訊環境中大規模處理情緒分析相關的計算複雜性的潛力。所提出的方法加快了情緒
資料處理，並準確分析不同形式的文字資料，從而
增強情緒分類和與情緒相關的見解
分析。

##### **Defending LVLMs Against Vision Attacks through Partial-Perception Supervision**
2412.12722v1 by Qi Zhou, Tianlin Li, Qing Guo, Dongxia Wang, Yun Lin, Yang Liu, Jin Song Dong

Recent studies have raised significant concerns regarding the vulnerability
of Large Vision Language Models (LVLMs) to maliciously injected or perturbed
input images, which can mislead their responses. Existing defense methods show
that such vision attacks are sensitive to image modifications especially
cropping, using majority voting across responses of modified images as
corrected responses. However, these modifications often result in partial
images and distort the semantics, which reduces response quality on clean
images after voting. Instead of directly using responses from partial images
for voting, we investigate using them to supervise the LVLM's responses to the
original images. We propose a black-box, training-free method called DPS
(Defense through Partial-Perception Supervision). In this approach, the model
is prompted using the responses generated by a model that perceives only a
partial image. With DPS, the model can adjust its response based on partial
image understanding when under attack, while confidently maintaining its
original response for clean input. Our findings show that the weak model can
supervise the strong model: when faced with an attacked input, the strong model
becomes less confident and adjusts its response based on the weak model's
partial understanding, effectively defending against the attack. With clean
input, it confidently maintains its original response. Empirical experiments
show our method outperforms the baseline, cutting the average attack success
rate by 76.3% across six datasets on three popular models.

摘要：最近的研究對於大型視覺語言模型 (LVLMs) 容易受到惡意注入或擾動的輸入影像，進而誤導其回應，提出了重大的疑慮。現有的防禦方法顯示，此類視覺攻擊對於影像修改很敏感，特別是裁切，使用修改影像的回應進行多數決投票作為修正的回應。然而，這些修改通常會導致部分影像和扭曲語意，這會降低投票後乾淨影像的回應品質。我們沒有直接使用部分影像的回應進行投票，而是研究使用它們來監督 LVLM 對原始影像的回應。我們提出一個稱為 DPS（透過部分感知監督進行防禦）的黑盒子、免訓練方法。在這個方法中，模型會使用僅感知部分影像的模型所產生的回應提示。透過 DPS，模型可以在受到攻擊時根據部分影像理解調整其回應，同時自信地維持其對乾淨輸入的原始回應。我們的研究結果顯示，弱模型可以監督強模型：當面對受到攻擊的輸入時，強模型會變得不那麼有信心，並根據弱模型的部分理解調整其回應，有效地防禦攻擊。對於乾淨的輸入，它會自信地維持其原始回應。實證實驗顯示，我們的模型優於基準，在三種熱門模型的六個資料集上，平均攻擊成功率降低了 76.3%。

##### **Enhancing Naturalness in LLM-Generated Utterances through Disfluency Insertion**
2412.12710v1 by Syed Zohaib Hassan, Pierre Lison, Pål Halvorsen

Disfluencies are a natural feature of spontaneous human speech but are
typically absent from the outputs of Large Language Models (LLMs). This absence
can diminish the perceived naturalness of synthesized speech, which is an
important criteria when building conversational agents that aim to mimick human
behaviours. We show how the insertion of disfluencies can alleviate this
shortcoming. The proposed approach involves (1) fine-tuning an LLM with
Low-Rank Adaptation (LoRA) to incorporate various types of disfluencies into
LLM-generated utterances and (2) synthesizing those utterances using a
text-to-speech model that supports the generation of speech phenomena such as
disfluencies. We evaluated the quality of the generated speech across two
metrics: intelligibility and perceived spontaneity. We demonstrate through a
user study that the insertion of disfluencies significantly increase the
perceived spontaneity of the generated speech. This increase came, however,
along with a slight reduction in intelligibility.

摘要：口語失流是人類自發性語言的自然特徵，但大型語言模型 (LLM) 的輸出中通常沒有這種現象。這種現象的缺失會降低合成語音的自然性，而這在建立旨在模仿人類行為的對話式代理時是一個重要的標準。我們將展示如何插入口語失流來緩解這個缺點。所提出的方法包括：(1) 使用低秩適應 (LoRA) 微調 LLM，以將各種類型的口語失流納入 LLM 生成的語句中，以及 (2) 使用支援產生語音現象（例如口語失流）的文字轉語音模型來合成這些語句。我們根據兩個指標評估了所生成語音的品質：清晰度和感知自發性。我們透過使用者研究證明，插入口語失流會顯著增加所生成語音的感知自發性。然而，這種增加伴隨著清晰度的輕微下降。

##### **More Tokens, Lower Precision: Towards the Optimal Token-Precision Trade-off in KV Cache Compression**
2412.12706v1 by Jiebin Zhang, Dawei Zhu, Yifan Song, Wenhao Wu, Chuqiao Kuang, Xiaoguang Li, Lifeng Shang, Qun Liu, Sujian Li

As large language models (LLMs) process increasing context windows, the
memory usage of KV cache has become a critical bottleneck during inference. The
mainstream KV compression methods, including KV pruning and KV quantization,
primarily focus on either token or precision dimension and seldom explore the
efficiency of their combination. In this paper, we comprehensively investigate
the token-precision trade-off in KV cache compression. Experiments demonstrate
that storing more tokens in the KV cache with lower precision, i.e., quantized
pruning, can significantly enhance the long-context performance of LLMs.
Furthermore, in-depth analysis regarding token-precision trade-off from a
series of key aspects exhibit that, quantized pruning achieves substantial
improvements in retrieval-related tasks and consistently performs well across
varying input lengths. Moreover, quantized pruning demonstrates notable
stability across different KV pruning methods, quantization strategies, and
model scales. These findings provide valuable insights into the token-precision
trade-off in KV cache compression. We plan to release our code in the near
future.

摘要：隨著大型語言模型 (LLM) 處理越來越大的內容視窗，KV 快取的記憶體使用量已成為推論期間的關鍵瓶頸。主流的 KV 壓縮方法，包括 KV 剪枝和 KV 量化，主要關注於符號或精確度維度，很少探討它們組合的效率。在本文中，我們全面探討 KV 快取壓縮中的符號精確度權衡。實驗證明，在 KV 快取中儲存更多具有較低精確度（即量化剪枝）的符號，可以顯著提升 LLM 的長內容效能。此外，從一系列關鍵面向深入分析符號精確度權衡，顯示量化剪枝在檢索相關任務中獲得顯著的改善，並且在不同的輸入長度中始終表現良好。此外，量化剪枝在不同的 KV 剪枝方法、量化策略和模型規模中展現出顯著的穩定性。這些發現為 KV 快取壓縮中的符號精確度權衡提供了有價值的見解。我們計畫在不久的將來發布我們的程式碼。

##### **Trigger$^3$: Refining Query Correction via Adaptive Model Selector**
2412.12701v1 by Kepu Zhang, Zhongxiang Sun, Xiao Zhang, Xiaoxue Zang, Kai Zheng, Yang Song, Jun Xu

In search scenarios, user experience can be hindered by erroneous queries due
to typos, voice errors, or knowledge gaps. Therefore, query correction is
crucial for search engines. Current correction models, usually small models
trained on specific data, often struggle with queries beyond their training
scope or those requiring contextual understanding. While the advent of Large
Language Models (LLMs) offers a potential solution, they are still limited by
their pre-training data and inference cost, particularly for complex queries,
making them not always effective for query correction. To tackle these, we
propose Trigger$^3$, a large-small model collaboration framework that
integrates the traditional correction model and LLM for query correction,
capable of adaptively choosing the appropriate correction method based on the
query and the correction results from the traditional correction model and LLM.
Trigger$^3$ first employs a correction trigger to filter out correct queries.
Incorrect queries are then corrected by the traditional correction model. If
this fails, an LLM trigger is activated to call the LLM for correction.
Finally, for queries that no model can correct, a fallback trigger decides to
return the original query. Extensive experiments demonstrate Trigger$^3$
outperforms correction baselines while maintaining efficiency.

摘要：在搜尋情境中，由於拼寫錯誤、語音錯誤或知識差距，錯誤的查詢可能會阻礙使用者體驗。因此，查詢修正對於搜尋引擎至關重要。目前的修正模型通常是針對特定資料訓練的小模型，對於超出其訓練範圍或需要脈絡理解的查詢，通常難以應付。儘管大型語言模型 (LLM) 的出現提供了潛在的解決方案，但它們仍然受到預訓練資料和推論成本的限制，尤其對於複雜的查詢而言，這使得它們並非總是能有效進行查詢修正。為了解決這些問題，我們提出了 Trigger$^3$，一個大型小型模型協作框架，它整合了傳統的修正模型和 LLM 來進行查詢修正，能夠根據查詢以及傳統修正模型和 LLM 的修正結果，自適應地選擇適當的修正方法。Trigger$^3$ 首先使用修正觸發器來過濾正確的查詢。不正確的查詢接著由傳統修正模型修正。如果失敗，則會啟動 LLM 觸發器來呼叫 LLM 進行修正。最後，對於沒有模型可以修正的查詢，備用觸發器決定回傳原始查詢。廣泛的實驗證明，Trigger$^3$ 在維持效率的同時，優於修正基準。

##### **ParMod: A Parallel and Modular Framework for Learning Non-Markovian Tasks**
2412.12700v1 by Ruixuan Miao, Xu Lu, Cong Tian, Bin Yu, Zhenhua Duan

The commonly used Reinforcement Learning (RL) model, MDPs (Markov Decision
Processes), has a basic premise that rewards depend on the current state and
action only. However, many real-world tasks are non-Markovian, which has
long-term memory and dependency. The reward sparseness problem is further
amplified in non-Markovian scenarios. Hence learning a non-Markovian task (NMT)
is inherently more difficult than learning a Markovian one. In this paper, we
propose a novel \textbf{Par}allel and \textbf{Mod}ular RL framework, ParMod,
specifically for learning NMTs specified by temporal logic. With the aid of
formal techniques, the NMT is modulaized into a series of sub-tasks based on
the automaton structure (equivalent to its temporal logic counterpart). On this
basis, sub-tasks will be trained by a group of agents in a parallel fashion,
with one agent handling one sub-task. Besides parallel training, the core of
ParMod lies in: a flexible classification method for modularizing the NMT, and
an effective reward shaping method for improving the sample efficiency. A
comprehensive evaluation is conducted on several challenging benchmark problems
with respect to various metrics. The experimental results show that ParMod
achieves superior performance over other relevant studies. Our work thus
provides a good synergy among RL, NMT and temporal logic.

摘要：廣泛使用的強化學習 (RL) 模型，MDP（馬可夫決策過程），有一個基本前提，即獎勵僅取決於當前的狀態和動作。然而，許多真實世界的任務是非馬可夫的，具有長期記憶和依賴性。在非馬可夫場景中，獎勵稀疏問題進一步擴大。因此，學習非馬可夫任務 (NMT) 本質上比學習馬可夫任務更困難。在本文中，我們提出了一個新穎的**並**行和**模**塊化 RL 框架，ParMod，專門用於學習由時序邏輯指定的 NMT。在形式化技術的幫助下，NMT 被模塊化為一系列子任務，基於自動機結構（等同於其時序邏輯對應結構）。在此基礎上，子任務將由一組代理以並行方式進行訓練，一個代理處理一個子任務。除了並行訓練之外，ParMod 的核心在於：一種用於模塊化 NMT 的靈活分類方法，以及一種用於提高樣本效率的有效獎勵塑造方法。針對各種指標，對幾個具有挑戰性的基準問題進行了全面評估。實驗結果表明，ParMod 比其他相關研究取得了更好的性能。因此，我們的研究在 RL、NMT 和時序邏輯之間提供了良好的協同作用。

##### **SPHERE: A Hierarchical Evaluation on Spatial Perception and Reasoning for Vision-Language Models**
2412.12693v1 by Wenyu Zhang, Wei En Ng, Lixin Ma, Yuwen Wang, Jungqi Zhao, Boyang Li, Lu Wang

Current vision-language models may incorporate single-dimensional spatial
cues, such as depth, object boundary, and basic spatial directions (e.g. left,
right, front, back), yet often lack the multi-dimensional spatial reasoning
necessary for human-like understanding and real-world applications. To address
this gap, we develop SPHERE (Spatial Perception and Hierarchical Evaluation of
REasoning), a hierarchical evaluation framework with a new human-annotated
dataset to pinpoint model strengths and weaknesses, advancing from single-skill
tasks to multi-skill tasks, and ultimately to complex reasoning tasks that
require the integration of multiple spatial and visual cues with logical
reasoning. Benchmark evaluation of state-of-the-art open-source models reveal
significant shortcomings, especially in the abilities to understand distance
and proximity, to reason from both allocentric and egocentric viewpoints, and
to perform complex reasoning in a physical context. This work underscores the
need for more advanced approaches to spatial understanding and reasoning,
paving the way for improvements in vision-language models and their alignment
with human-like spatial capabilities. The dataset will be open-sourced upon
publication.

摘要：目前的視覺語言模型可能結合單維度的空間線索，例如深度、物體邊界和基本的空間方向（例如左、右、前、後），但通常缺乏人類理解和實際應用所需的多維度空間推理。為了解決這個差距，我們開發了 SPHERE（空間感知和推理的分層評估），一個分層評估框架，包含一個新的由人類標註的資料集，用於精確定位模型的優點和缺點，從單技能任務進展到多技能任務，最終到需要整合多種空間和視覺線索與邏輯推理的複雜推理任務。對最先進的開源模型的基準評估揭示了顯著的缺點，特別是在理解距離和接近度、從以自我為中心和以世界為中心的觀點進行推理，以及在物理環境中執行複雜推理的能力方面。這項工作強調了對空間理解和推理需要更先進的方法，為視覺語言模型的改進以及它們與類人空間能力的對齊鋪平了道路。該資料集將在發布後開源。

##### **XTransplant: A Probe into the Upper Bound Performance of Multilingual Capability and Culture Adaptability in LLMs via Mutual Cross-lingual Feed-forward Transplantation**
2412.12686v1 by Yangfan Ye, Xiaocheng Feng, Xiachong Feng, Libo Qin, Yichong Huang, Lei Huang, Weitao Ma, Zhirui Zhang, Yunfei Lu, Xiaohui Yan, Duyu Tang, Dandan Tu, Bing Qin

Current large language models (LLMs) often exhibit imbalances in multilingual
capabilities and cultural adaptability, largely due to their English-centric
pretraining data. To address this imbalance, we propose a probing method named
XTransplant that explores cross-lingual latent interactions via cross-lingual
feed-forward transplantation during inference stage, with the hope of enabling
the model to leverage the strengths of both English and non-English languages.
Through extensive pilot experiments, we empirically prove that both the
multilingual capabilities and cultural adaptability of LLMs hold the potential
to be significantly improved by XTransplant, respectively from En -> non-En and
non-En -> En, highlighting the underutilization of current LLMs' multilingual
potential. And the patterns observed in these pilot experiments further
motivate an offline scaling inference strategy, which demonstrates consistent
performance improvements in multilingual and culture-aware tasks, sometimes
even surpassing multilingual supervised fine-tuning. And we do hope our further
analysis and discussion could help gain deeper insights into XTransplant
mechanism.

摘要：目前的大型語言模型 (LLM) 通常在多語言能力和文化適應性方面表現出不平衡，這主要是由於它們以英語為中心的預訓練數據。為了解決這種不平衡，我們提出了一種探測方法，稱為 XTransplant，它通過在推理階段進行跨語言前饋移植，探索跨語言潛在交互，希望能讓模型同時利用英語和非英語語言的優勢。通過廣泛的試驗實驗，我們憑經驗證明，XTransplant 可以顯著提升 LLM 的多語言能力和文化適應性，分別從英語到非英語和非英語到英語，突顯了當前 LLM 多語言潛力的利用不足。而且在這些試驗實驗中觀察到的模式進一步激勵了離線擴展推理策略，該策略在多語言和文化感知任務中展示了一致的性能提升，有時甚至超越了多語言監督微調。而且我們確實希望我們進一步的分析和討論有助於深入了解 XTransplant 機制。

##### **Detecting Document-level Paraphrased Machine Generated Content: Mimicking Human Writing Style and Involving Discourse Features**
2412.12679v1 by Yupei Li, Manuel Milling, Lucia Specia, Björn W. Schuller

The availability of high-quality APIs for Large Language Models (LLMs) has
facilitated the widespread creation of Machine-Generated Content (MGC), posing
challenges such as academic plagiarism and the spread of misinformation.
Existing MGC detectors often focus solely on surface-level information,
overlooking implicit and structural features. This makes them susceptible to
deception by surface-level sentence patterns, particularly for longer texts and
in texts that have been subsequently paraphrased.
  To overcome these challenges, we introduce novel methodologies and datasets.
Besides the publicly available dataset Plagbench, we developed the paraphrased
Long-Form Question and Answer (paraLFQA) and paraphrased Writing Prompts
(paraWP) datasets using GPT and DIPPER, a discourse paraphrasing tool, by
extending artifacts from their original versions. To address the challenge of
detecting highly similar paraphrased texts, we propose MhBART, an
encoder-decoder model designed to emulate human writing style while
incorporating a novel difference score mechanism. This model outperforms strong
classifier baselines and identifies deceptive sentence patterns. To better
capture the structure of longer texts at document level, we propose
DTransformer, a model that integrates discourse analysis through PDTB
preprocessing to encode structural features. It results in substantial
performance gains across both datasets -- 15.5\% absolute improvement on
paraLFQA, 4\% absolute improvement on paraWP, and 1.5\% absolute improvement on
M4 compared to SOTA approaches.

摘要：大型語言模型 (LLM) 的高品質 API 的可用性促進了機器生成內容 (MGC) 的廣泛創建，這對學術剽竊和錯誤訊息的散布構成了挑戰。現有的 MGC 偵測器通常只專注於表面層級的資訊，忽略了隱含和結構特徵。這使得它們容易被表面層級的句子模式所欺騙，特別是對於較長的文字和經過重新改寫的文字。
為了克服這些挑戰，我們引入了創新的方法和資料集。除了公開的資料集 Plagbench 之外，我們還使用了 GPT 和 DIPPER（一種語篇改寫工具）開發了改寫的長篇問答 (paraLFQA) 和改寫的寫作提示 (paraWP) 資料集，方法是擴充其原始版本的成品。為了應對偵測高度相似改寫文字的挑戰，我們提出了 MhBART，這是一種編碼器-解碼器模型，旨在模擬人類的寫作風格，同時納入一種新穎的差異分數機制。此模型優於強大的分類器基準，並識別出具有欺騙性的句子模式。為了更好地擷取文件層級較長文字的結構，我們提出了 DTransformer，這是一種透過 PDTB 預處理整合語篇分析以編碼結構特徵的模型。與 SOTA 方法相比，它在兩個資料集上都產生了顯著的效能提升——在 paraLFQA 上提升了 15.5% 的絕對值，在 paraWP 上提升了 4% 的絕對值，在 M4 上提升了 1.5% 的絕對值。

##### **Train More Parameters But Mind Their Placement: Insights into Language Adaptation with PEFT**
2412.12674v1 by Jenny Kunz

Smaller LLMs still face significant challenges even in medium-resourced
languages, particularly when it comes to language-specific knowledge -- a
problem not easily resolved with machine-translated data. In this case study on
Icelandic, we aim to enhance the generation performance of an LLM by
specialising it using unstructured text corpora. A key focus is on preventing
interference with the models' capabilities of handling longer context during
this adaptation. Through ablation studies using various parameter-efficient
fine-tuning (PEFT) methods and setups, we find that increasing the number of
trainable parameters leads to better and more robust language adaptation. LoRAs
placed in the feed-forward layers and bottleneck adapters show promising
results with sufficient parameters, while prefix tuning and (IA)3 are not
suitable. Although improvements are consistent in 0-shot summarisation, some
adapted models struggle with longer context lengths, an issue that can be
mitigated by adapting only the final layers.

摘要：較小的 LLM 即使在中資源語言中仍面臨重大挑戰，特別是在語言特定知識方面，而這問題不容易用機器翻譯資料解決。在這個針對冰島語的案例研究中，我們旨在透過使用非結構化文字語料庫，來提升 LLM 的產生效能。一個重點是防止在這個適應過程中，干擾模型處理較長內容的能力。透過使用各種參數有效微調 (PEFT) 方法和設定進行消融研究，我們發現增加可訓練參數的數量會帶來更好且更健全的語言適應。放置在饋送前向層和瓶頸適配器的 LoRA 顯示出有足夠參數時有前景的結果，而前綴微調和 (IA)3 則不適合。儘管在 0-shot 摘要中持續改進，一些適應模型在較長的內容長度中會遇到問題，而這個問題可以透過只適應最後的層來減輕。

##### **MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**
2412.12661v1 by Hritik Bansal, Daniel Israel, Siyan Zhao, Shufan Li, Tung Nguyen, Aditya Grover

Recent advancements in mixed-modal generative models have enabled flexible
integration of information across image-text content. These models have opened
new avenues for developing unified biomedical assistants capable of analyzing
biomedical images, answering complex questions about them, and predicting the
impact of medical procedures on a patient's health. However, existing resources
face challenges such as limited data availability, narrow domain coverage, and
restricted sources (e.g., medical papers). To address these gaps, we present
MedMax, the first large-scale multimodal biomedical instruction-tuning dataset
for mixed-modal foundation models. With 1.47 million instances, MedMax
encompasses a diverse range of tasks, including multimodal content generation
(interleaved image-text data), biomedical image captioning and generation,
visual chatting, and report understanding. These tasks span diverse medical
domains such as radiology and histopathology. Subsequently, we fine-tune a
mixed-modal foundation model on the MedMax dataset, achieving significant
performance improvements: a 26% gain over the Chameleon model and an 18.3%
improvement over GPT-4o across 12 downstream biomedical visual
question-answering tasks. Additionally, we introduce a unified evaluation suite
for biomedical tasks, providing a robust framework to guide the development of
next-generation mixed-modal biomedical AI assistants.

摘要：混合模式生成模型的最新进展使得跨图像文本内容灵活整合信息成为可能。这些模型为开发统一的生物医学助手开辟了新途径，这些助手能够分析生物医学图像、回答有关图像的复杂问题，并预测医疗程序对患者健康的影响。然而，现有资源面临着数据可用性有限、领域覆盖范围狭窄和来源受限（例如医学论文）等挑战。为了解决这些差距，我们提出了 MedMax，这是第一个用于混合模式基础模型的大规模多模态生物医学指令微调数据集。MedMax 拥有 147 万个实例，涵盖了各种任务，包括多模态内容生成（交错图像文本数据）、生物医学图像标题和生成、可视化聊天和报告理解。这些任务跨越了放射学和组织病理学等不同的医学领域。随后，我们在 MedMax 数据集上对混合模式基础模型进行微调，取得了显著的性能提升：在 12 个下游生物医学视觉问答任务中，比 Chameleon 模型提升了 26%，比 GPT-4o 提升了 18.3%。此外，我们还引入了用于生物医学任务的统一评估套件，为指导下一代混合模式生物医学 AI 助手的发展提供了稳健的框架。

##### **Shared Attention-based Autoencoder with Hierarchical Fusion-based Graph Convolution Network for sEEG SOZ Identification**
2412.12651v1 by Huachao Yan, Kailing Guo, Shiwei Song, Yihai Dai, Xiaoqiang Wei, Xiaofen Xing, Xiangmin Xu

Diagnosing seizure onset zone (SOZ) is a challenge in neurosurgery, where
stereoelectroencephalography (sEEG) serves as a critical technique. In sEEG SOZ
identification, the existing studies focus solely on the intra-patient
representation of epileptic information, overlooking the general features of
epilepsy across patients and feature interdependencies between feature elements
in each contact site. In order to address the aforementioned challenges, we
propose the shared attention-based autoencoder (sATAE). sATAE is trained by
sEEG data across all patients, with attention blocks introduced to enhance the
representation of interdependencies between feature elements. Considering the
spatial diversity of sEEG across patients, we introduce graph-based method for
identification SOZ of each patient. However, the current graph-based methods
for sEEG SOZ identification rely exclusively on static graphs to model
epileptic networks. Inspired by the finding of neuroscience that epileptic
network is intricately characterized by the interplay of sophisticated
equilibrium between fluctuating and stable states, we design the hierarchical
fusion-based graph convolution network (HFGCN) to identify the SOZ. HFGCN
integrates the dynamic and static characteristics of epileptic networks through
hierarchical weighting across different hierarchies, facilitating a more
comprehensive learning of epileptic features and enriching node information for
sEEG SOZ identification. Combining sATAE and HFGCN, we perform comprehensive
experiments with sATAE-HFGCN on the self-build sEEG dataset, which includes
sEEG data from 17 patients with temporal lobe epilepsy. The results show that
our method, sATAE-HFGCN, achieves superior performance for identifying the SOZ
of each patient, effectively addressing the aforementioned challenges,
providing an efficient solution for sEEG-based SOZ identification.

摘要：診斷癲癇發作區域 (SOZ) 是神經外科中的一項挑戰，其中立體腦電圖 (sEEG) 是一種關鍵技術。在 sEEG SOZ 識別中，現有研究僅關注癲癇信息的患者內部表現，而忽略了癲癇患者的共同特徵和每個接觸位點特徵元素之間的相互依賴性。為了應對上述挑戰，我們提出了基於共享注意力的自動編碼器 (sATAE)。sATAE 通過所有患者的 sEEG 數據進行訓練，並引入注意力塊來增強特徵元素之間的相互依賴性的表現。考慮到患者之間 sEEG 的空間多樣性，我們引入了基於圖形的方法來識別每個患者的 SOZ。然而，當前基於圖形的方法對於 sEEG SOZ 識別僅依賴於靜態圖形來建模癲癇網絡。受神經科學發現的啟發，即癲癇網絡的複雜特徵在於波動狀態和穩定狀態之間複雜的平衡相互作用，我們設計了基於分層融合的圖形卷積網絡 (HFGCN) 來識別 SOZ。HFGCN 通過跨不同層級的分層加權整合癲癇網絡的動態和靜態特徵，促進對癲癇特徵的更全面學習，並豐富 sEEG SOZ 識別的節點信息。通過結合 sATAE 和 HFGCN，我們對自建 sEEG 數據集進行了全面的 sATAE-HFGCN 實驗，其中包括來自 17 名顳葉癲癇患者的 sEEG 數據。結果表明，我們的 sATAE-HFGCN 方法在識別每個患者的 SOZ 方面取得了卓越的性能，有效應對了上述挑戰，為基於 sEEG 的 SOZ 識別提供了有效的解決方案。

##### **Neural-Network-Driven Reward Prediction as a Heuristic: Advancing Q-Learning for Mobile Robot Path Planning**
2412.12650v1 by Yiming Ji, Kaijie Yun, Yang Liu, Zongwu Xie, Hong Liu

Q-learning is a widely used reinforcement learning technique for solving path
planning problems. It primarily involves the interaction between an agent and
its environment, enabling the agent to learn an optimal strategy that maximizes
cumulative rewards. Although many studies have reported the effectiveness of
Q-learning, it still faces slow convergence issues in practical applications.
To address this issue, we propose the NDR-QL method, which utilizes neural
network outputs as heuristic information to accelerate the convergence process
of Q-learning. Specifically, we improved the dual-output neural network model
by introducing a start-end channel separation mechanism and enhancing the
feature fusion process. After training, the proposed NDR model can output a
narrowly focused optimal probability distribution, referred to as the
guideline, and a broadly distributed suboptimal distribution, referred to as
the region. Subsequently, based on the guideline prediction, we calculate the
continuous reward function for the Q-learning method, and based on the region
prediction, we initialize the Q-table with a bias. We conducted training,
validation, and path planning simulation experiments on public datasets. The
results indicate that the NDR model outperforms previous methods by up to 5\%
in prediction accuracy. Furthermore, the proposed NDR-QL method improves the
convergence speed of the baseline Q-learning method by 90\% and also surpasses
the previously improved Q-learning methods in path quality metrics.

摘要：Q 學習是一種廣泛使用的強化學習技術，用於解決路徑規劃問題。它主要涉及代理和其環境之間的互動，使代理能夠學習一種最佳策略，以最大化累積獎勵。儘管許多研究報告了 Q 學習的有效性，但它在實際應用中仍然面臨收斂速度慢的問題。為了解決這個問題，我們提出了 NDR-QL 方法，它利用神經網路輸出作為啟發式資訊，以加速 Q 學習的收斂過程。具體來說，我們通過引入起始端通道分離機制和增強特徵融合過程，改進了雙輸出神經網路模型。經過訓練後，所提出的 NDR 模型可以輸出一個集中焦點的最佳機率分佈，稱為準則，以及一個廣泛分佈的次佳分佈，稱為區域。隨後，根據準則預測，我們計算 Q 學習方法的連續獎勵函數，並根據區域預測，我們用偏差初始化 Q 表。我們對公共資料集進行了訓練、驗證和路徑規劃模擬實驗。結果表明，NDR 模型在預測準確度上比以前的方法高出 5%。此外，所提出的 NDR-QL 方法將基準 Q 學習方法的收斂速度提高了 90%，並且在路徑品質指標上也超越了以前改進的 Q 學習方法。

##### **iPrOp: Interactive Prompt Optimization for Large Language Models with a Human in the Loop**
2412.12644v1 by Jiahui Li, Roman Klinger

Prompt engineering has made significant contributions to the era of large
language models, yet its effectiveness depends on the skills of a prompt
author. Automatic prompt optimization can support the prompt development
process, but requires annotated data. This paper introduces $\textit{iPrOp}$, a
novel Interactive Prompt Optimization system, to bridge manual prompt
engineering and automatic prompt optimization. With human intervention in the
optimization loop, $\textit{iPrOp}$ offers users the flexibility to assess
evolving prompts. We present users with prompt variations, selected instances,
large language model predictions accompanied by corresponding explanations, and
performance metrics derived from a subset of the training data. This approach
empowers users to choose and further refine the provided prompts based on their
individual preferences and needs. This system not only assists non-technical
domain experts in generating optimal prompts tailored to their specific tasks
or domains, but also enables to study the intrinsic parameters that influence
the performance of prompt optimization. Our evaluation shows that our system
has the capability to generate improved prompts, leading to enhanced task
performance.

摘要：提示工程為大型語言模型時代做出了重大貢獻，但其有效性取決於提示作者的技能。自動提示優化可以支援提示開發流程，但需要有註解資料。本文介紹了一種創新的互動式提示優化系統 $\textit{iPrOp}$，以橋接手動提示工程和自動提示優化。在優化迴圈中加入人工干預，$\textit{iPrOp}$ 使用者可以靈活地評估不斷演變的提示。我們提供提示變體、選定的實例、大型語言模型預測以及對應的說明，以及從訓練資料子集中衍生的效能指標給使用者。此方法使用戶能夠根據自己的偏好和需求選擇並進一步優化提供的提示。此系統不僅協助非技術領域專家產生針對其特定任務或領域量身打造的最佳提示，還能研究影響提示優化效能的內在參數。我們的評估顯示，我們的系統有能力產生更好的提示，進而提升任務效能。

##### **LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**
2412.12643v1 by Mufan Xu, Kehai Chen, Xuefeng Bai, Muyun Yang, Tiejun Zhao, Min Zhang

Large language models (LLMs) based on generative pre-trained Transformer have
achieved remarkable performance on knowledge graph question-answering (KGQA)
tasks. However, LLMs often produce ungrounded subgraph planning or reasoning
results in KGQA due to the hallucinatory behavior brought by the generative
paradigm, which may hinder the advancement of the LLM-based KGQA model. To deal
with the issue, we propose a novel LLM-based Discriminative Reasoning (LDR)
method to explicitly model the subgraph retrieval and answer inference process.
By adopting discriminative strategies, the proposed LDR method not only
enhances the capability of LLMs to retrieve question-related subgraphs but also
alleviates the issue of ungrounded reasoning brought by the generative paradigm
of LLMs. Experimental results show that the proposed approach outperforms
multiple strong comparison methods, along with achieving state-of-the-art
performance on two widely used WebQSP and CWQ benchmarks.

摘要：大型語言模型（LLM）基於生成式預訓練 Transformer，在知識圖譜問答（KGQA）任務上已取得顯著的成效。然而，由於生成式範例帶來的幻覺行為，LLM 在 KGQA 中經常產生無根據的子圖規劃或推理結果，這可能會阻礙基於 LLM 的 KGQA 模型的進展。為了解決這個問題，我們提出了一種新穎的基於 LLM 的判別推理（LDR）方法，以明確建模子圖檢索和答案推論過程。通過採用判別策略，所提出的 LLM 方法不僅增強了 LLM 檢索與問題相關的子圖的能力，而且還緩解了 LLM 的生成式範例帶來的無根據推理問題。實驗結果表明，所提出的方法優於多種強大的比較方法，同時在兩個廣泛使用的 WebQSP 和 CWQ 基準測試中取得了最先進的效能。

##### **RDPI: A Refine Diffusion Probability Generation Method for Spatiotemporal Data Imputation**
2412.12642v1 by Zijin Liu, Xiang Zhao, You Song

Spatiotemporal data imputation plays a crucial role in various fields such as
traffic flow monitoring, air quality assessment, and climate prediction.
However, spatiotemporal data collected by sensors often suffer from temporal
incompleteness, and the sparse and uneven distribution of sensors leads to
missing data in the spatial dimension. Among existing methods, autoregressive
approaches are prone to error accumulation, while simple conditional diffusion
models fail to adequately capture the spatiotemporal relationships between
observed and missing data. To address these issues, we propose a novel
two-stage Refined Diffusion Probability Impuation (RDPI) framework based on an
initial network and a conditional diffusion model. In the initial stage,
deterministic imputation methods are used to generate preliminary estimates of
the missing data. In the refinement stage, residuals are treated as the
diffusion target, and observed values are innovatively incorporated into the
forward process. This results in a conditional diffusion model better suited
for spatiotemporal data imputation, bridging the gap between the preliminary
estimates and the true values. Experiments on multiple datasets demonstrate
that RDPI not only achieves state-of-the-art imputation accuracy but also
significantly reduces sampling computational costs.

摘要：時空資料插補在各種領域中扮演著至關重要的角色，例如交通流量監控、空氣品質評估和氣候預測。然而，由感測器所收集的時空資料通常會遭受時間上的不完整，且感測器的稀疏且不均勻分佈會導致空間維度中的資料遺失。在現有的方法中，自迴歸方法容易發生累積誤差，而簡單的條件擴散模型無法充分捕捉觀測資料和遺失資料之間的時空關係。為了解決這些問題，我們提出了一個基於初始網路和條件擴散模型的新穎兩階段精緻擴散機率插補 (RDPI) 架構。在初始階段，使用確定性插補方法來產生遺失資料的初步估計。在精緻化階段，殘差被視為擴散目標，並且觀測值被創新地納入前向過程中。這產生了一個更適合時空資料插補的條件擴散模型，彌補了初步估計和真實值之間的差距。在多個資料集上的實驗證明，RDPI 不僅達到了最先進的插補準確度，而且還顯著降低了抽樣計算成本。

##### **Lagrangian Index Policy for Restless Bandits with Average Reward**
2412.12641v1 by Konstantin Avrachenkov, Vivek S. Borkar, Pratik Shah

We study the Lagrangian Index Policy (LIP) for restless multi-armed bandits
with long-run average reward. In particular, we compare the performance of LIP
with the performance of the Whittle Index Policy (WIP), both heuristic policies
known to be asymptotically optimal under certain natural conditions. Even
though in most cases their performances are very similar, in the cases when WIP
shows bad performance, LIP continues to perform very well. We then propose
reinforcement learning algorithms, both tabular and NN-based, to obtain online
learning schemes for LIP in the model-free setting. The proposed reinforcement
learning schemes for LIP requires significantly less memory than the analogous
scheme for WIP. We calculate analytically the Lagrangian index for the restart
model, which describes the optimal web crawling and the minimization of the
weighted age of information. We also give a new proof of asymptotic optimality
in case of homogeneous bandits as the number of arms goes to infinity, based on
exchangeability and de Finetti's theorem.

摘要：我們研究具有長期平均獎勵的不安分多臂賭徒的拉格朗日指數政策 (LIP)。特別是，我們將 LIP 的效能與惠特爾指數政策 (WIP) 的效能進行比較，這兩種啟發式政策已知在某些自然條件下在漸近上是最佳的。儘管在大多數情況下它們的效能非常相似，但在 WIP 表現不佳的情況下，LIP 仍能持續表現得很好。然後，我們提出表格和基於 NN 的強化學習演算法，以在無模型設定中取得 LIP 的線上學習方案。LIP 的建議強化學習方案所需的記憶體顯著少於 WIP 的類似方案。我們分析計算重新啟動模型的拉格朗日指數，它描述了最佳網路爬取和加權資訊年齡的最小化。我們還根據可交換性和 de Finetti 定理，給出齊次賭徒在手臂數量趨於無限時漸近最佳性的新證明。

##### **Falcon: Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree**
2412.12639v1 by Xiangxiang Gao, Weisheng Xie, Yiwei Xiang, Feng Ji

Striking an optimal balance between minimal drafting latency and high
speculation accuracy to enhance the inference speed of Large Language Models
remains a significant challenge in speculative decoding. In this paper, we
introduce Falcon, an innovative semi-autoregressive speculative decoding
framework fashioned to augment both the drafter's parallelism and output
quality. Falcon incorporates the Coupled Sequential Glancing Distillation
technique, which fortifies inter-token dependencies within the same block,
leading to increased speculation accuracy. We offer a comprehensive theoretical
analysis to illuminate the underlying mechanisms. Additionally, we introduce a
Custom-Designed Decoding Tree, which permits the drafter to generate multiple
tokens in a single forward pass and accommodates multiple forward passes as
needed, thereby boosting the number of drafted tokens and significantly
improving the overall acceptance rate. Comprehensive evaluations on benchmark
datasets such as MT-Bench, HumanEval, and GSM8K demonstrate Falcon's superior
acceleration capabilities. The framework achieves a lossless speedup ratio
ranging from 2.91x to 3.51x when tested on the Vicuna and LLaMA2-Chat model
series. These results outstrip existing speculative decoding methods for LLMs,
including Eagle, Medusa, Lookahead, SPS, and PLD, while maintaining a compact
drafter architecture equivalent to merely two Transformer layers.

摘要：<paragraph>在推測性解碼中，在最小的起草延遲和高推測準確性之間取得最佳平衡以提高大語言模型的推論速度仍然是一項重大挑戰。在本文中，我們介紹了 Falcon，一個創新的半自迴歸推測性解碼框架，旨在同時增加起草者的並行性和輸出品質。Falcon 結合了耦合順序掃描蒸餾技術，該技術強化了同一個區塊內的令牌間依賴性，從而提高了推測準確性。我們提供了一份全面的理論分析來闡明其底層機制。此外，我們還引入了一個客製化設計的解碼樹，它允許起草者在單一的正向傳遞中生成多個令牌，並根據需要容納多個正向傳遞，從而增加了起草令牌的數量，並顯著提高了整體接受率。在 MT-Bench、HumanEval 和 GSM8K 等基準數據集上的全面評估證明了 Falcon 優越的加速能力。在 Vicuna 和 LLaMA2-Chat 模型系列上進行測試時，該框架實現了 2.91 倍到 3.51 倍的無損加速比。這些結果超越了現有的 LLM 推測性解碼方法，包括 Eagle、Medusa、Lookahead、SPS 和 PLD，同時保持了一個僅等於兩個 Transformer 層的緊湊起草架構。</paragraph>

##### **What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context**
2412.12632v1 by Zhiyuan Chang, Mingyang Li, Xiaojun Jia, Junjie Wang, Yuekai Huang, Qing Wang, Yihao Huang, Yang Liu

Incorporating external knowledge into large language models (LLMs) has
emerged as a promising approach to mitigate outdated knowledge and
hallucination in LLMs. However, external knowledge is often imperfect. In
addition to useful knowledge, external knowledge is rich in irrelevant or
misinformation in the context that can impair the reliability of LLM responses.
This paper focuses on LLMs' preferred external knowledge in imperfect contexts
when handling multi-hop QA. Inspired by criminal procedural law's Chain of
Evidence (CoE), we characterize that knowledge preferred by LLMs should
maintain both relevance to the question and mutual support among knowledge
pieces. Accordingly, we propose an automated CoE discrimination approach and
explore LLMs' preferences from their effectiveness, faithfulness and
robustness, as well as CoE's usability in a naive Retrieval-Augmented
Generation (RAG) case. The evaluation on five LLMs reveals that CoE enhances
LLMs through more accurate generation, stronger answer faithfulness, better
robustness against knowledge conflict, and improved performance in a popular
RAG case.

摘要：將外部知識納入大型語言模型 (LLM) 已成為減輕 LLM 中過時知識和幻覺的一種有前途的方法。然而，外部知識通常並不完美。除了有用的知識外，外部知識在語境中還包含大量不相關或錯誤的資訊，這可能會損害 LLM 回應的可靠性。本文重點探討 LLM 在處理多跳問答時，在不完美的語境中偏好的外部知識。受刑事訴訟法的證據鏈 (CoE) 啟發，我們將 LLM 偏好的知識特徵化為應同時保持與問題相關性和知識片段之間的相互支援。因此，我們提出了一種自動化 CoE 辨別方法，並從其有效性、忠實度和穩健性以及 CoE 在一個樸素的檢索增強生成 (RAG) 案例中的可用性來探討 LLM 的偏好。對五個 LLM 的評估表明，CoE 通過更準確的生成、更強的答案忠實度、更好的抗知識衝突穩健性，以及在一個流行的 RAG 案例中改進的效能來增強 LLM。

##### **a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**
2412.12629v1 by Pranav Rajpurkar, Julian N. Acosta, Siddhant Dogra, Jaehwan Jeong, Deepanshu Jindal, Michael Moritz, Samir Rajpurkar

We present a comprehensive evaluation of a2z-1, an artificial intelligence
(AI) model designed to analyze abdomen-pelvis CT scans for 21 time-sensitive
and actionable findings. Our study focuses on rigorous assessment of the
model's performance and generalizability. Large-scale retrospective analysis
demonstrates an average AUC of 0.931 across 21 conditions. External validation
across two distinct health systems confirms consistent performance (AUC 0.923),
establishing generalizability to different evaluation scenarios, with notable
performance in critical findings such as small bowel obstruction (AUC 0.958)
and acute pancreatitis (AUC 0.961). Subgroup analysis shows consistent accuracy
across patient sex, age groups, and varied imaging protocols, including
different slice thicknesses and contrast administration types. Comparison of
high-confidence model outputs to radiologist reports reveals instances where
a2z-1 identified overlooked findings, suggesting potential for quality
assurance applications.

摘要：我們提出 a2z-1 的全面評估，這是一個人工智慧 (AI) 模型，旨在分析腹部骨盆電腦斷層掃描，以找出 21 項時間敏感且可採取行動的發現。我們的研究重點在於嚴格評估模型的效能和概括性。大規模回顧性分析顯示，21 種疾病的平均 AUC 為 0.931。兩個不同醫療系統的外部驗證確認效能一致（AUC 0.923），建立了對不同評估情境的概括性，在小腸阻塞（AUC 0.958）和急性胰臟炎（AUC 0.961）等關鍵發現中表現出色。次群體分析顯示，在患者性別、年齡組和不同的影像協議（包括不同的切片厚度和對比劑施用類型）中，準確度一致。將高信賴度模型輸出與放射科醫師報告進行比較，揭示了 a2z-1 找出被忽略發現的範例，表示有潛力用於品質保證應用。

##### **Make Imagination Clearer! Stable Diffusion-based Visual Imagination for Multimodal Machine Translation**
2412.12627v1 by Andong Chen, Yuchen Song, Kehai Chen, Muyun Yang, Tiejun Zhao, Min Zhang

Visual information has been introduced for enhancing machine translation
(MT), and its effectiveness heavily relies on the availability of large amounts
of bilingual parallel sentence pairs with manual image annotations. In this
paper, we introduce a stable diffusion-based imagination network into a
multimodal large language model (MLLM) to explicitly generate an image for each
source sentence, thereby advancing the multimodel MT. Particularly, we build
heuristic human feedback with reinforcement learning to ensure the consistency
of the generated image with the source sentence without the supervision of
image annotation, which breaks the bottleneck of using visual information in
MT. Furthermore, the proposed method enables imaginative visual information to
be integrated into large-scale text-only MT in addition to multimodal MT.
Experimental results show that our model significantly outperforms existing
multimodal MT and text-only MT, especially achieving an average improvement of
more than 14 BLEU points on Multi30K multimodal MT benchmarks.

摘要：視覺資訊已導入以增強機器翻譯 (MT)，其有效性極度仰賴大量具手動影像註解的雙語平行句子對。在本文中，我們將一個穩定的基於擴散的想像網路導入一個多模態大型語言模型 (MLLM) 中，以明確地為每個原始句子產生一個影像，從而推進多模態 MT。特別是，我們建構一個具備強化學習的啟發式人類回饋，以確保產生的影像與原始句子的一致性，無需影像註解的監督，這打破了在 MT 中使用視覺資訊的瓶頸。此外，所提出的方法讓富想像力的視覺資訊能夠整合到大型純文字 MT 中，除了多模態 MT 之外。實驗結果顯示，我們的模型顯著優於現有的多模態 MT 和純文字 MT，特別是在 Multi30K 多模態 MT 基準上平均提升了 14 個 BLEU 點以上。

##### **Jailbreaking? One Step Is Enough!**
2412.12621v1 by Weixiong Zheng, Peijian Zeng, Yiwei Li, Hongyan Wu, Nankai Lin, Junhao Chen, Aimin Yang, Yongmei Zhou

Large language models (LLMs) excel in various tasks but remain vulnerable to
jailbreak attacks, where adversaries manipulate prompts to generate harmful
outputs. Examining jailbreak prompts helps uncover the shortcomings of LLMs.
However, current jailbreak methods and the target model's defenses are engaged
in an independent and adversarial process, resulting in the need for frequent
attack iterations and redesigning attacks for different models. To address
these gaps, we propose a Reverse Embedded Defense Attack (REDA) mechanism that
disguises the attack intention as the "defense". intention against harmful
content. Specifically, REDA starts from the target response, guiding the model
to embed harmful content within its defensive measures, thereby relegating
harmful content to a secondary role and making the model believe it is
performing a defensive task. The attacking model considers that it is guiding
the target model to deal with harmful content, while the target model thinks it
is performing a defensive task, creating an illusion of cooperation between the
two. Additionally, to enhance the model's confidence and guidance in
"defensive" intentions, we adopt in-context learning (ICL) with a small number
of attack examples and construct a corresponding dataset of attack examples.
Extensive evaluations demonstrate that the REDA method enables cross-model
attacks without the need to redesign attack strategies for different models,
enables successful jailbreak in one iteration, and outperforms existing methods
on both open-source and closed-source models.

摘要：大型語言模型 (LLM) 在各種任務中表現出色，但仍容易受到越獄攻擊，在這種攻擊中，對手會操縱提示以產生有害的輸出。檢查越獄提示有助於發現 LLM 的缺點。然而，目前的越獄方法和目標模型的防禦措施處於獨立且對抗的過程中，導致需要頻繁的攻擊迭代和針對不同模型重新設計攻擊。為了解決這些差距，我們提出了一種反向嵌入式防禦攻擊 (REDA) 機制，它將攻擊意圖偽裝成「防禦」。意圖對抗有害內容。具體來說，REDA 從目標回應開始，引導模型在其防禦措施中嵌入有害內容，從而將有害內容降級為次要角色，並讓模型相信它正在執行防禦任務。攻擊模型認為它正在引導目標模型處理有害內容，而目標模型則認為它正在執行防禦任務，在兩者之間營造出合作的假象。此外，為了增強模型對「防禦」意圖的信心和指導，我們採用情境學習 (ICL) 以及少量攻擊範例，並構建相應的攻擊範例資料集。廣泛的評估表明，REDA 方法可以在不需為不同模型重新設計攻擊策略的情況下進行跨模型攻擊，能夠在一次迭代中成功越獄，並且在開源和閉源模型上都優於現有方法。

##### **Phoneme-Level Feature Discrepancies: A Key to Detecting Sophisticated Speech Deepfakes**
2412.12619v1 by Kuiyuan Zhang, Zhongyun Hua, Rushi Lan, Yushu Zhang, Yifang Guo

Recent advancements in text-to-speech and speech conversion technologies have
enabled the creation of highly convincing synthetic speech. While these
innovations offer numerous practical benefits, they also cause significant
security challenges when maliciously misused. Therefore, there is an urgent
need to detect these synthetic speech signals. Phoneme features provide a
powerful speech representation for deepfake detection. However, previous
phoneme-based detection approaches typically focused on specific phonemes,
overlooking temporal inconsistencies across the entire phoneme sequence. In
this paper, we develop a new mechanism for detecting speech deepfakes by
identifying the inconsistencies of phoneme-level speech features. We design an
adaptive phoneme pooling technique that extracts sample-specific phoneme-level
features from frame-level speech data. By applying this technique to features
extracted by pre-trained audio models on previously unseen deepfake datasets,
we demonstrate that deepfake samples often exhibit phoneme-level
inconsistencies when compared to genuine speech. To further enhance detection
accuracy, we propose a deepfake detector that uses a graph attention network to
model the temporal dependencies of phoneme-level features. Additionally, we
introduce a random phoneme substitution augmentation technique to increase
feature diversity during training. Extensive experiments on four benchmark
datasets demonstrate the superior performance of our method over existing
state-of-the-art detection methods.

摘要：<paragraph>最近在文字轉語音和語音轉換技術的進展，已經讓高度令人信服的合成語音的創作成為可能。雖然這些創新提供了許多實際的好處，但當惡意使用時，它們也會造成重大的安全挑戰。因此，迫切需要偵測這些合成的語音訊號。音素特徵為深度造假偵測提供了強大的語音表示。然而，先前的基於音素的偵測方法通常專注於特定的音素，而忽略了整個音素序列中的時間不一致性。在本文中，我們開發了一種新的機制來偵測語音深度造假，方法是找出音素級語音特徵的不一致性。我們設計了一種自適應音素池化技術，從幀級語音資料中提取特定於範例的音素級特徵。透過將此技術應用於先前未見的深度造假資料集上，由預先訓練的音訊模型所提取的特徵，我們證明了與真實語音相比，深度造假範例通常會表現出音素級的不一致性。為了進一步增強偵測的準確性，我們提出了一個深度造假偵測器，它使用圖注意力網路來建模音素級特徵的時間依賴性。此外，我們引入了一種隨機音素替換擴充技術，以增加訓練期間的特徵多樣性。在四個基準資料集上的廣泛實驗證明了我們的方法優於現有的最先進偵測方法。</paragraph>

##### **SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**
2412.12612v1 by Aman Tiwari, Shiva Krishna Reddy Malay, Vikas Yadav, Masoud Hashemi, Sathwik Tejaswi Madhusudhan

Cypher, the query language for Neo4j graph databases, plays a critical role
in enabling graph-based analytics and data exploration. While substantial
research has been dedicated to natural language to SQL query generation
(Text2SQL), the analogous problem for graph databases referred to as
Text2Cypher remains underexplored. In this work, we introduce SynthCypher, a
fully synthetic and automated data generation pipeline designed to address this
gap. SynthCypher employs a novel LLMSupervised Generation-Verification
framework, ensuring syntactically and semantically correct Cypher queries
across diverse domains and query complexities. Using this pipeline, we create
SynthCypher Dataset, a large-scale benchmark containing 29.8k Text2Cypher
instances. Fine-tuning open-source large language models (LLMs), including
LLaMa-3.1- 8B, Mistral-7B, and QWEN-7B, on SynthCypher yields significant
performance improvements of up to 40% on the Text2Cypher test set and 30% on
the SPIDER benchmark adapted for graph databases. This work demonstrates that
high-quality synthetic data can effectively advance the state-of-the-art in
Text2Cypher tasks.

摘要：Cypher 是 Neo4j 圖形資料庫的查詢語言，在啟用以圖形為基礎的分析和資料探索方面發揮著至關重要的作用。儘管已經投入大量研究將自然語言轉換為 SQL 查詢生成 (Text2SQL)，但稱為 Text2Cypher 的圖形資料庫類比問題仍未得到充分探討。在這項工作中，我們介紹了 SynthCypher，這是一個完全合成且自動化的資料生成管道，旨在解決這個差距。SynthCypher 採用了一種新穎的 LLMSupervised 生成驗證框架，確保了跨越不同領域和查詢複雜性的 Cypher 查詢在語法和語義上正確。使用這個管道，我們創建了 SynthCypher 資料集，這是一個包含 29.8k Text2Cypher 實例的大規模基準。微調開源大型語言模型 (LLM)，包括 SynthCypher 上的 LLaMa-3.1- 8B、Mistral-7B 和 QWEN-7B，在 Text2Cypher 測試集中產生了高達 40% 的顯著性能提升，在適用於圖形資料庫的 SPIDER 基準上提升了 30%。這項工作證明了高品質的合成資料可以有效地推動 Text2Cypher 任務的最新技術。

##### **MultiLingPoT: Enhancing Mathematical Reasoning with Multilingual Program Fine-tuning**
2412.12609v1 by Nianqi Li, Zujie Liang, Siyu Yuan, Jiaqing Liang, Feng Wei, Yanghua Xiao

Program-of-Thought (PoT), which aims to use programming language instead of
natural language as an intermediate step in reasoning, is an important way for
LLMs to solve mathematical problems. Since different programming languages
excel in different areas, it is natural to use the most suitable language for
solving specific problems. However, current PoT research only focuses on single
language PoT, ignoring the differences between different programming languages.
Therefore, this paper proposes an multilingual program reasoning method,
MultiLingPoT. This method allows the model to answer questions using multiple
programming languages by fine-tuning on multilingual data. Additionally, prior
and posterior hybrid methods are used to help the model select the most
suitable language for each problem. Our experimental results show that the
training of MultiLingPoT improves each program's mathematical reasoning by
about 2.5\%. Moreover, with proper mixing, the performance of MultiLingPoT can
be further improved, achieving a 6\% increase compared to the single-language
PoT with the data augmentation.Resources of this paper can be found at
https://github.com/Nianqi-Li/MultiLingPoT.

摘要：思想程式（PoT）旨在使用程式語言而非自然語言作為推理的步驟，是 LLM 解決數學問題的重要方式。由於不同的程式語言擅長不同的領域，因此使用最適合的語言來解決特定問題是理所當然的。然而，目前的 PoT 研究僅專注於單一語言 PoT，而忽略了不同程式語言之間的差異。因此，本文提出了一種多語言程式推理方法 MultiLingPoT。此方法允許模型透過對多語言資料進行微調，使用多種程式語言來回答問題。此外，使用先驗和後驗混合方法來幫助模型為每個問題選擇最合適的語言。我們的實驗結果表明，MultiLingPoT 的訓練將每個程式的數學推理能力提高了約 2.5%。此外，透過適當的混合，MultiLingPoT 的效能可以進一步提高，與使用資料擴充的單一語言 PoT 相比，提高了 6%。本文的資源可以在 https://github.com/Nianqi-Li/MultiLingPoT 找到。

##### **Multi-Dimensional Insights: Benchmarking Real-World Personalization in Large Multimodal Models**
2412.12606v1 by YiFan Zhang, Shanglin Lei, Runqi Qiao, Zhuoma GongQue, Xiaoshuai Song, Guanting Dong, Qiuna Tan, Zhe Wei, Peiqing Yang, Ye Tian, Yadong Xue, Xiaofei Wang, Honggang Zhang

The rapidly developing field of large multimodal models (LMMs) has led to the
emergence of diverse models with remarkable capabilities. However, existing
benchmarks fail to comprehensively, objectively and accurately evaluate whether
LMMs align with the diverse needs of humans in real-world scenarios. To bridge
this gap, we propose the Multi-Dimensional Insights (MDI) benchmark, which
includes over 500 images covering six common scenarios of human life. Notably,
the MDI-Benchmark offers two significant advantages over existing evaluations:
(1) Each image is accompanied by two types of questions: simple questions to
assess the model's understanding of the image, and complex questions to
evaluate the model's ability to analyze and reason beyond basic content. (2)
Recognizing that people of different age groups have varying needs and
perspectives when faced with the same scenario, our benchmark stratifies
questions into three age categories: young people, middle-aged people, and
older people. This design allows for a detailed assessment of LMMs'
capabilities in meeting the preferences and needs of different age groups. With
MDI-Benchmark, the strong model like GPT-4o achieve 79% accuracy on age-related
tasks, indicating that existing LMMs still have considerable room for
improvement in addressing real-world applications. Looking ahead, we anticipate
that the MDI-Benchmark will open new pathways for aligning real-world
personalization in LMMs. The MDI-Benchmark data and evaluation code are
available at https://mdi-benchmark.github.io/

摘要：大型多模态模型 (LMM) 快速发展的领域已经
导致了具有卓越功能的不同模型的出现。然而，现有的
基准无法全面、客观和准确地评估
LMM 是否符合人类在现实场景中的不同需求。为了弥合
这一差距，我们提出了多维洞察 (MDI) 基准，其中
包括涵盖人类生活六个常见场景的 500 多张图像。值得注意的是，
MDI 基准比现有评估具有两个显着优势：
(1) 每张图像都附带两种类型的问题：简单问题以
评估模型对图像的理解，以及复杂问题以
评估模型分析和推理超越基本内容的能力。(2)
认识到不同年龄组的人在面对相同场景时有不同的需求和
观点，我们的基准将问题分层为三个年龄类别：年轻人、中年人和
老年人。这种设计允许对 LMM 的能力进行详细评估
满足不同年龄组的偏好和需求。使用
MDI 基准，GPT-4o 等强大模型在与年龄相关的
任务上实现了 79% 的准确率，表明现有的 LMM 仍然有很大的
改进空间来解决现实世界的应用程序。展望未来，我们预计
MDI 基准将为在 LMM 中调整现实世界的个性化开辟新途径。MDI 基准数据和评估代码可在 https://mdi-benchmark.github.io/ 获得

##### **LLMs are Also Effective Embedding Models: An In-depth Overview**
2412.12591v1 by Chongyang Tao, Tao Shen, Shen Gao, Junshuo Zhang, Zhen Li, Zhengwei Tao, Shuai Ma

Large language models (LLMs) have revolutionized natural language processing
by achieving state-of-the-art performance across various tasks. Recently, their
effectiveness as embedding models has gained attention, marking a paradigm
shift from traditional encoder-only models like ELMo and BERT to decoder-only,
large-scale LLMs such as GPT, LLaMA, and Mistral. This survey provides an
in-depth overview of this transition, beginning with foundational techniques
before the LLM era, followed by LLM-based embedding models through two main
strategies to derive embeddings from LLMs. 1) Direct prompting: We mainly
discuss the prompt designs and the underlying rationale for deriving
competitive embeddings. 2) Data-centric tuning: We cover extensive aspects that
affect tuning an embedding model, including model architecture, training
objectives, data constructions, etc. Upon the above, we also cover advanced
methods, such as handling longer texts, and multilingual and cross-modal data.
Furthermore, we discuss factors affecting choices of embedding models, such as
performance/efficiency comparisons, dense vs sparse embeddings, pooling
strategies, and scaling law. Lastly, the survey highlights the limitations and
challenges in adapting LLMs for embeddings, including cross-task embedding
quality, trade-offs between efficiency and accuracy, low-resource,
long-context, data bias, robustness, etc. This survey serves as a valuable
resource for researchers and practitioners by synthesizing current
advancements, highlighting key challenges, and offering a comprehensive
framework for future work aimed at enhancing the effectiveness and efficiency
of LLMs as embedding models.

摘要：大型語言模型 (LLM) 透過在各種任務中達成最先進的效能，徹底革新了自然語言處理。最近，它們作為嵌入模型的效能備受矚目，標誌著從傳統的僅編碼器模型（例如 ELMo 和 BERT）轉變為僅解碼器、大規模的 LLM（例如 GPT、LLaMA 和 Mistral）。這項調查深入探討了這項轉變，從 LLM 時代之前的基礎技術開始，接著是透過從 LLM 衍生嵌入的兩種主要策略，探討基於 LLM 的嵌入模型。1) 直接提示：我們主要討論提示設計和衍生競爭力嵌入的基礎原理。2) 以資料為中心的調整：我們涵蓋影響調整嵌入模型的廣泛面向，包括模型架構、訓練目標、資料建構等。在上述基礎上，我們也涵蓋進階方法，例如處理較長的文字，以及多語言和跨模態資料。此外，我們討論影響嵌入模型選擇的因素，例如效能/效率比較、稠密與稀疏嵌入、匯集策略和規模定律。最後，這項調查重點說明了將 LLM 調整為嵌入的限制和挑戰，包括跨任務嵌入品質、效率和準確性之間的權衡、低資源、長語境、資料偏差、穩健性等。這項調查透過綜合目前的進展、強調關鍵挑戰，並提供一個全面的架構，以增強 LLM 作為嵌入模型的效能和效率，進而成為研究人員和實務工作者的寶貴資源。

##### **PerSphere: A Comprehensive Framework for Multi-Faceted Perspective Retrieval and Summarization**
2412.12588v1 by Yun Luo, Yingjie Li, Xiangkun Hu, Qinglin Qi, Fang Guo, Qipeng Guo, Zheng Zhang, Yue Zhang

As online platforms and recommendation algorithms evolve, people are
increasingly trapped in echo chambers, leading to biased understandings of
various issues. To combat this issue, we have introduced PerSphere, a benchmark
designed to facilitate multi-faceted perspective retrieval and summarization,
thus breaking free from these information silos. For each query within
PerSphere, there are two opposing claims, each supported by distinct,
non-overlapping perspectives drawn from one or more documents. Our goal is to
accurately summarize these documents, aligning the summaries with the
respective claims and their underlying perspectives. This task is structured as
a two-step end-to-end pipeline that includes comprehensive document retrieval
and multi-faceted summarization. Furthermore, we propose a set of metrics to
evaluate the comprehensiveness of the retrieval and summarization content.
Experimental results on various counterparts for the pipeline show that recent
models struggle with such a complex task. Analysis shows that the main
challenge lies in long context and perspective extraction, and we propose a
simple but effective multi-agent summarization system, offering a promising
solution to enhance performance on PerSphere.

摘要：隨著線上平台與推薦演算法的演進，人們越來越容易受限於同溫層，導致對各種議題產生偏頗的理解。為了應對這個問題，我們引入了 PerSphere，一個旨在促進多面向觀點擷取與摘要的基準，藉此突破這些資訊孤島。在 PerSphere 中的每個查詢，都有兩個對立的說法，每個說法都受到來自一個或多個文件中的不同、不重疊觀點的支持。我們的目標是準確地摘要這些文件，讓摘要與各自的說法及其背後觀點保持一致。這項任務被建構成一個兩步驟的端對端流程，包括全面的文件擷取和多面向摘要。此外，我們提出了一組指標來評估擷取和摘要內容的全面性。在各種管道對應方的實驗結果顯示，最近的模型難以應付如此複雜的任務。分析顯示，主要的挑戰在於長篇脈絡和觀點的擷取，我們提出了一個簡單但有效的多代理摘要系統，提供了一個有望增強 PerSphere 效能的解決方案。

##### **Distributed satellite information networks: Architecture, enabling technologies, and trends**
2412.12587v1 by Qinyu Zhang, Liang Xu, Jianhao Huang, Tao Yang, Jian Jiao, Ye Wang, Yao Shi, Chiya Zhang, Xingjian Zhang, Ke Zhang, Yupeng Gong, Na Deng, Nan Zhao, Zhen Gao, Shujun Han, Xiaodong Xu, Li You, Dongming Wang, Shan Jiang, Dixian Zhao, Nan Zhang, Liujun Hu, Xiongwen He, Yonghui Li, Xiqi Gao, Xiaohu You

Driven by the vision of ubiquitous connectivity and wireless intelligence,
the evolution of ultra-dense constellation-based satellite-integrated Internet
is underway, now taking preliminary shape. Nevertheless, the entrenched
institutional silos and limited, nonrenewable heterogeneous network resources
leave current satellite systems struggling to accommodate the escalating
demands of next-generation intelligent applications. In this context, the
distributed satellite information networks (DSIN), exemplified by the cohesive
clustered satellites system, have emerged as an innovative architecture,
bridging information gaps across diverse satellite systems, such as
communication, navigation, and remote sensing, and establishing a unified, open
information network paradigm to support resilient space information services.
This survey first provides a profound discussion about innovative network
architectures of DSIN, encompassing distributed regenerative satellite network
architecture, distributed satellite computing network architecture, and
reconfigurable satellite formation flying, to enable flexible and scalable
communication, computing and control. The DSIN faces challenges from network
heterogeneity, unpredictable channel dynamics, sparse resources, and
decentralized collaboration frameworks. To address these issues, a series of
enabling technologies is identified, including channel modeling and estimation,
cloud-native distributed MIMO cooperation, grant-free massive access, network
routing, and the proper combination of all these diversity techniques.
Furthermore, to heighten the overall resource efficiency, the cross-layer
optimization techniques are further developed to meet upper-layer
deterministic, adaptive and secure information services requirements. In
addition, emerging research directions and new opportunities are highlighted on
the way to achieving the DSIN vision.

摘要：<paragraph>在普遍连接和无线智能的愿景推动下，超密集星座卫星集成互联网的演进正在进行中，目前已初具雏形。然而，根深蒂固的机构孤岛和有限的、不可再生的异构网络资源让当前的卫星系统难以适应下一代智能应用不断增长的需求。在此背景下，以协同集群卫星系统为代表的分布式卫星信息网络（DSIN）已成为一种创新架构，弥合了通信、导航和遥感等不同卫星系统之间的信息差距，并建立了一个统一、开放的信息网络范式来支持弹性的空间信息服务。本综述首先对DSIN的创新网络架构进行了深入探讨，包括分布式再生卫星网络架构、分布式卫星计算网络架构和可重构卫星编队飞行，以实现灵活且可扩展的通信、计算和控制。DSIN面临着网络异构性、不可预测的信道动态、稀疏资源和分散协作框架的挑战。为了解决这些问题，确定了一系列使能技术，包括信道建模和估计、云原生分布式MIMO协作、免授权大规模接入、网络路由以及所有这些多样性技术的适当组合。此外，为了提高整体资源效率，进一步开发了跨层优化技术，以满足上层确定性、自适应和安全的信息服务要求。此外，在实现DSIN愿景的道路上，重点介绍了新兴的研究方向和新的机遇。</paragraph>

##### **Process-Supervised Reward Models for Clinical Note Generation: A Scalable Approach Guided by Domain Expertise**
2412.12583v1 by Hanyin Wang, Qiping Xu, Bolun Liu, Guleid Hussein, Hariprasad Korsapati, Mohamad El Labban, Kingsley Iheasirim, Mohamed Hassan, Gokhan Anil, Brian Bartlett, Jimeng Sun

Process-supervised reward models (PRMs), which verify large language model
(LLM) outputs step-by-step, have achieved significant success in mathematical
and coding problems. However, their application to other domains remains
largely unexplored. In this work, we train a PRM to provide step-level reward
signals for clinical notes generated by LLMs from patient-doctor dialogues.
Guided by real-world clinician expertise, we carefully designed step
definitions for clinical notes and utilized Gemini-Pro 1.5 to automatically
generate process supervision data at scale. Our proposed PRM, trained on the
LLaMA-3.1 8B instruct model, demonstrated superior performance compared to
Gemini-Pro 1.5 and an outcome-supervised reward model (ORM) across two key
evaluations: (1) the accuracy of selecting gold-reference samples from
error-containing samples, achieving 98.8% (versus 61.3% for ORM and 93.8% for
Gemini-Pro 1.5), and (2) the accuracy of selecting physician-preferred notes,
achieving 56.2% (compared to 51.2% for ORM and 50.0% for Gemini-Pro 1.5).
Additionally, we conducted ablation studies to determine optimal loss functions
and data selection strategies, along with physician reader studies to explore
predictors of downstream Best-of-N performance. Our promising results suggest
the potential of PRMs to extend beyond the clinical domain, offering a scalable
and effective solution for diverse generative tasks.

摘要：<paragraph>過程監督獎勵模型 (PRM) 會逐步驗證大型語言模型 (LLM) 的輸出，已在數學和編碼問題中取得重大成功。然而，它們在其他領域的應用仍未廣泛探討。在這項工作中，我們訓練了一個 PRM，以提供 LLM 從患者與醫師對話中產生的臨床筆記的步驟層級獎勵訊號。在真實世界的臨床醫師專業知識指導下，我們仔細設計了臨床筆記的步驟定義，並利用 Gemini-Pro 1.5 自動大規模產生過程監督資料。在 LLaMA-3.1 8B 指令模型上訓練的我們提出的 PRM 在兩項關鍵評估中表現出優於 Gemini-Pro 1.5 和結果監督獎勵模型 (ORM) 的效能：(1) 從含錯誤的範例中選取黃金參考範例的準確度，達到 98.8%（相較於 ORM 的 61.3% 和 Gemini-Pro 1.5 的 93.8%），以及 (2) 選取醫師偏好的筆記的準確度，達到 56.2%（相較於 ORM 的 51.2% 和 Gemini-Pro 1.5 的 50.0%）。此外，我們進行了消融研究以確定最佳損失函數和資料選取策略，並與醫師讀者研究一起探討下游最佳 N 效能的預測因子。我們有前景的結果表明 PRM 有可能擴展到臨床領域以外，為各種生成任務提供可擴充且有效的解決方案。</paragraph>

##### **SIDE: Socially Informed Drought Estimation Toward Understanding Societal Impact Dynamics of Environmental Crisis**
2412.12575v1 by Lanyu Shang, Bozhang Chen, Shiwei Liu, Yang Zhang, Ruohan Zong, Anav Vora, Ximing Cai, Na Wei, Dong Wang

Drought has become a critical global threat with significant societal impact.
Existing drought monitoring solutions primarily focus on assessing drought
severity using quantitative measurements, overlooking the diverse societal
impact of drought from human-centric perspectives. Motivated by the collective
intelligence on social media and the computational power of AI, this paper
studies a novel problem of socially informed AI-driven drought estimation that
aims to leverage social and news media information to jointly estimate drought
severity and its societal impact. Two technical challenges exist: 1) How to
model the implicit temporal dynamics of drought societal impact. 2) How to
capture the social-physical interdependence between the physical drought
condition and its societal impact. To address these challenges, we develop
SIDE, a socially informed AI-driven drought estimation framework that
explicitly quantifies the societal impact of drought and effectively models the
social-physical interdependency for joint severity-impact estimation.
Experiments on real-world datasets from California and Texas demonstrate SIDE's
superior performance compared to state-of-the-art baselines in accurately
estimating drought severity and its societal impact. SIDE offers valuable
insights for developing human-centric drought mitigation strategies to foster
sustainable and resilient communities.

摘要：乾旱已成為一個嚴重的全球威脅，對社會造成重大影響。
現有的乾旱監測解決方案主要著重於使用定量測量來評估乾旱嚴重性，而忽略了乾旱從以人為中心的觀點來看對社會造成的不同影響。本論文受到社群媒體的集體智慧和人工智慧的運算能力的啟發，探討了一個新的問題，即由社會訊息驅動的乾旱估計，其目標是利用社群和新聞媒體的資訊來共同估計乾旱的嚴重性和其對社會的影響。存在兩個技術挑戰：1) 如何建模乾旱對社會影響的隱含時間動態。2) 如何捕捉物理乾旱狀況及其對社會影響之間的社會物理相互依存性。為了應對這些挑戰，我們開發了 SIDE，一個由社會訊息驅動的乾旱估計框架，它明確量化了乾旱對社會的影響，並有效地建模了社會物理相互依存性，以進行聯合嚴重性影響估計。對來自加州和德州的真實世界資料集的實驗證明了 SIDE 在準確估計乾旱嚴重性和其對社會的影響方面優於最先進的基準。SIDE 為制定以人為中心的乾旱緩解策略提供了寶貴的見解，以培養可持續和有韌性的社區。

##### **License Plate Detection and Character Recognition Using Deep Learning and Font Evaluation**
2412.12572v1 by Zahra Ebrahimi Vargoorani, Ching Yee Suen

License plate detection (LPD) is essential for traffic management, vehicle
tracking, and law enforcement but faces challenges like variable lighting and
diverse font types, impacting accuracy. Traditionally reliant on image
processing and machine learning, the field is now shifting towards deep
learning for its robust performance in various conditions. Current methods,
however, often require tailoring to specific regional datasets. This paper
proposes a dual deep learning strategy using a Faster R-CNN for detection and a
CNN-RNN model with Connectionist Temporal Classification (CTC) loss and a
MobileNet V3 backbone for recognition. This approach aims to improve model
performance using datasets from Ontario, Quebec, California, and New York
State, achieving a recall rate of 92% on the Centre for Pattern Recognition and
Machine Intelligence (CENPARMI) dataset and 90% on the UFPR-ALPR dataset. It
includes a detailed error analysis to identify the causes of false positives.
Additionally, the research examines the role of font features in license plate
(LP) recognition, analyzing fonts like Driver Gothic, Dreadnought, California
Clarendon, and Zurich Extra Condensed with the OpenALPR system. It discovers
significant performance discrepancies influenced by font characteristics,
offering insights for future LPD system enhancements.
  Keywords: Deep Learning, License Plate, Font Evaluation

摘要：車牌辨識 (LPD) 對於交通管理、車輛追蹤和執法至關重要，但面臨著光線變化和字型種類多樣等挑戰，影響了準確性。傳統上依賴於影像處理和機器學習，該領域現在正轉向深度學習，以在各種條件下發揮其強大的效能。然而，目前的方法通常需要針對特定區域的資料集進行調整。本文提出了一種雙重深度學習策略，使用 Faster R-CNN 進行偵測，以及具有連接式時間分類 (CTC) 損失和 MobileNet V3 主幹的 CNN-RNN 模型進行辨識。這種方法旨在使用來自安大略省、魁北克省、加州和紐約州的資料集來改善模型效能，在模式辨識和機器智慧中心 (CENPARMI) 資料集上達到 92% 的召回率，在 UFPR-ALPR 資料集上達到 90%。它包括詳細的錯誤分析，以找出誤報的原因。此外，該研究探討了字型特徵在車牌 (LP) 辨識中的作用，使用 OpenALPR 系統分析了 Driver Gothic、Dreadnought、California Clarendon 和 Zurich Extra Condensed 等字型。它發現了受字型特徵影響的顯著效能差異，為未來的 LPD 系統增強提供了見解。
關鍵字：深度學習、車牌、字型評估

