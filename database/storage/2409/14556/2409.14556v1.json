{"2409.14556": {"publish_time": "2024-09-22", "title": "RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph", "paper_summary": "As an important component of data exploration and integration, Column Type\nAnnotation (CTA) aims to label columns of a table with one or more semantic\ntypes. With the recent development of Large Language Models (LLMs), researchers\nhave started to explore the possibility of using LLMs for CTA, leveraging their\nstrong zero-shot capabilities. In this paper, we build on this promising work\nand improve on LLM-based methods for CTA by showing how to use a Knowledge\nGraph (KG) to augment the context information provided to the LLM. Our\napproach, called RACOON, combines both pre-trained parametric and\nnon-parametric knowledge during generation to improve LLMs' performance on CTA.\nOur experiments show that RACOON achieves up to a 0.21 micro F-1 improvement\ncompared against vanilla LLM inference.", "paper_summary_zh": "\u4f5c\u70ba\u8cc7\u6599\u63a2\u52d8\u8207\u6574\u5408\u7684\u91cd\u8981\u7d44\u6210\u90e8\u5206\uff0c\u6b04\u4f4d\u985e\u578b\u8a3b\u89e3 (CTA) \u7684\u76ee\u6a19\u662f\u4f7f\u7528\u4e00\u500b\u6216\u591a\u500b\u8a9e\u610f\u985e\u578b\u6a19\u8a18\u8868\u683c\u6b04\u4f4d\u3002\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u8fd1\u671f\u767c\u5c55\uff0c\u7814\u7a76\u4eba\u54e1\u5df2\u958b\u59cb\u63a2\u8a0e\u4f7f\u7528 LLM \u4f86\u9032\u884c CTA \u7684\u53ef\u80fd\u6027\uff0c\u4e26\u5229\u7528\u5176\u5f37\u5927\u7684\u96f6\u6b21\u5b78\u7fd2\u80fd\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5efa\u7acb\u5728\u9019\u500b\u6709\u524d\u666f\u7684\u7814\u7a76\u4e0a\uff0c\u4e26\u900f\u904e\u5c55\u793a\u5982\u4f55\u4f7f\u7528\u77e5\u8b58\u5716\u8b5c (KG) \u4f86\u64f4\u5145\u63d0\u4f9b\u7d66 LLM \u7684\u8108\u7d61\u8cc7\u8a0a\uff0c\u9032\u800c\u6539\u5584\u57fa\u65bc LLM \u7684 CTA \u65b9\u6cd5\u3002\u6211\u5011\u7684\u65b9\u6cd5\u7a31\u70ba RACOON\uff0c\u5b83\u5728\u751f\u6210\u904e\u7a0b\u4e2d\u7d50\u5408\u9810\u5148\u8a13\u7df4\u7684\u53c3\u6578\u5f0f\u548c\u975e\u53c3\u6578\u5f0f\u77e5\u8b58\uff0c\u4ee5\u6539\u5584 LLM \u5728 CTA \u4e0a\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\u8207\u7d14\u7cb9\u7684 LLM \u63a8\u8ad6\u76f8\u6bd4\uff0cRACOON \u5728\u5fae\u578b F-1 \u4e0a\u7684\u9032\u6b65\u9ad8\u9054 0.21\u3002", "author": "Linxi Wei et.al.", "authors": "Linxi Wei, Guorui Xiao, Magdalena Balazinska", "id": "2409.14556v1", "paper_url": "http://arxiv.org/abs/2409.14556v1", "repo": "null"}}