{"2410.21264": {"publish_time": "2024-10-28", "title": "LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior", "paper_summary": "We present LARP, a novel video tokenizer designed to overcome limitations in\ncurrent video tokenization methods for autoregressive (AR) generative models.\nUnlike traditional patchwise tokenizers that directly encode local visual\npatches into discrete tokens, LARP introduces a holistic tokenization scheme\nthat gathers information from the visual content using a set of learned\nholistic queries. This design allows LARP to capture more global and semantic\nrepresentations, rather than being limited to local patch-level information.\nFurthermore, it offers flexibility by supporting an arbitrary number of\ndiscrete tokens, enabling adaptive and efficient tokenization based on the\nspecific requirements of the task. To align the discrete token space with\ndownstream AR generation tasks, LARP integrates a lightweight AR transformer as\na training-time prior model that predicts the next token on its discrete latent\nspace. By incorporating the prior model during training, LARP learns a latent\nspace that is not only optimized for video reconstruction but is also\nstructured in a way that is more conducive to autoregressive generation.\nMoreover, this process defines a sequential order for the discrete tokens,\nprogressively pushing them toward an optimal configuration during training,\nensuring smoother and more accurate AR generation at inference time.\nComprehensive experiments demonstrate LARP's strong performance, achieving\nstate-of-the-art FVD on the UCF101 class-conditional video generation\nbenchmark. LARP enhances the compatibility of AR models with videos and opens\nup the potential to build unified high-fidelity multimodal large language\nmodels (MLLMs).", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u51fa LARP\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u5f71\u7247\u5206\u8a5e\u5668\uff0c\u65e8\u5728\u514b\u670d\u81ea\u56de\u6b78 (AR) \u751f\u6210\u5f0f\u6a21\u578b\u4e2d\u73fe\u6709\u5f71\u7247\u5206\u8a5e\u65b9\u6cd5\u7684\u9650\u5236\u3002\n\u8207\u76f4\u63a5\u5c07\u5c40\u90e8\u8996\u89ba\u5340\u584a\u7de8\u78bc\u6210\u96e2\u6563\u7b26\u865f\u7684\u50b3\u7d71\u5340\u584a\u5206\u8a5e\u5668\u4e0d\u540c\uff0cLARP \u5f15\u5165\u4e86\u4e00\u7a2e\u6574\u9ad4\u5206\u8a5e\u65b9\u6848\uff0c\u4f7f\u7528\u4e00\u7d44\u5b78\u7fd2\u5230\u7684\u6574\u9ad4\u67e5\u8a62\u5f9e\u8996\u89ba\u5167\u5bb9\u4e2d\u6536\u96c6\u8cc7\u8a0a\u3002\u9019\u7a2e\u8a2d\u8a08\u8b93 LARP \u80fd\u5920\u64f7\u53d6\u66f4\u5168\u57df\u548c\u8a9e\u7fa9\u7684\u8868\u793a\uff0c\u800c\u4e0d\u6703\u4fb7\u9650\u65bc\u5c40\u90e8\u5340\u584a\u5c64\u7d1a\u7684\u8cc7\u8a0a\u3002\n\u6b64\u5916\uff0c\u5b83\u63d0\u4f9b\u9748\u6d3b\u6027\uff0c\u652f\u63f4\u4efb\u610f\u6578\u91cf\u7684\u96e2\u6563\u7b26\u865f\uff0c\u6839\u64da\u4efb\u52d9\u7684\u5177\u9ad4\u9700\u6c42\u555f\u7528\u9069\u61c9\u6027\u548c\u9ad8\u6548\u7684\u5206\u8a5e\u3002\u70ba\u4e86\u5c07\u96e2\u6563\u7b26\u865f\u7a7a\u9593\u8207\u4e0b\u6e38 AR \u751f\u6210\u4efb\u52d9\u5c0d\u9f4a\uff0cLARP \u6574\u5408\u4e86\u4e00\u500b\u8f15\u91cf\u7d1a AR \u8f49\u63db\u5668\u4f5c\u70ba\u8a13\u7df4\u6642\u9593\u5148\u9a57\u6a21\u578b\uff0c\u4ee5\u9810\u6e2c\u5176\u96e2\u6563\u6f5b\u5728\u7a7a\u9593\u4e0a\u7684\u4e0b\u4e00\u500b\u7b26\u865f\u3002\u900f\u904e\u5728\u8a13\u7df4\u671f\u9593\u7d0d\u5165\u5148\u9a57\u6a21\u578b\uff0cLARP \u5b78\u7fd2\u4e86\u4e00\u500b\u6f5b\u5728\u7a7a\u9593\uff0c\u4e0d\u50c5\u91dd\u5c0d\u5f71\u7247\u91cd\u5efa\u9032\u884c\u4e86\u6700\u4f73\u5316\uff0c\u800c\u4e14\u7d50\u69cb\u4e0a\u66f4\u6709\u5229\u65bc\u81ea\u56de\u6b78\u751f\u6210\u3002\n\u6b64\u5916\uff0c\u6b64\u7a0b\u5e8f\u5b9a\u7fa9\u4e86\u96e2\u6563\u7b26\u865f\u7684\u9806\u5e8f\uff0c\u5728\u8a13\u7df4\u671f\u9593\u9010\u6b65\u5c07\u5b83\u5011\u63a8\u5411\u6700\u4f73\u914d\u7f6e\uff0c\u78ba\u4fdd\u5728\u63a8\u8ad6\u6642\u9593\u66f4\u9806\u66a2\u3001\u66f4\u6e96\u78ba\u7684 AR \u751f\u6210\u3002\n\u5168\u9762\u7684\u5be6\u9a57\u8b49\u660e\u4e86 LARP \u7684\u5f37\u5927\u6548\u80fd\uff0c\u5728 UCF101 \u985e\u689d\u4ef6\u5f71\u7247\u751f\u6210\u57fa\u6e96\u4e0a\u9054\u5230\u4e86\u6700\u5148\u9032\u7684 FVD\u3002LARP \u589e\u5f37\u4e86 AR \u6a21\u578b\u8207\u5f71\u7247\u7684\u76f8\u5bb9\u6027\uff0c\u4e26\u958b\u555f\u4e86\u5efa\u69cb\u7d71\u4e00\u7684\u9ad8\u4fdd\u771f\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u53ef\u80fd\u6027\u3002</paragraph>", "author": "Hanyu Wang et.al.", "authors": "Hanyu Wang, Saksham Suri, Yixuan Ren, Hao Chen, Abhinav Shrivastava", "id": "2410.21264v1", "paper_url": "http://arxiv.org/abs/2410.21264v1", "repo": "null"}}