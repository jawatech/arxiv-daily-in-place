{"2502.05036": {"publish_time": "2025-02-07", "title": "nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow", "paper_summary": "Natural Language to Visualization (NL2Vis) seeks to convert natural-language\ndescriptions into visual representations of given tables, empowering users to\nderive insights from large-scale data. Recent advancements in Large Language\nModels (LLMs) show promise in automating code generation to transform tabular\ndata into accessible visualizations. However, they often struggle with complex\nqueries that require reasoning across multiple tables. To address this\nlimitation, we propose a collaborative agent workflow, termed nvAgent, for\nNL2Vis. Specifically, nvAgent comprises three agents: a processor agent for\ndatabase processing and context filtering, a composer agent for planning\nvisualization generation, and a validator agent for code translation and output\nverification. Comprehensive evaluations on the new VisEval benchmark\ndemonstrate that nvAgent consistently surpasses state-of-the-art baselines,\nachieving a 7.88% improvement in single-table and a 9.23% improvement in\nmulti-table scenarios. Qualitative analyses further highlight that nvAgent\nmaintains nearly a 20% performance margin over previous models, underscoring\nits capacity to produce high-quality visual representations from complex,\nheterogeneous data sources.", "paper_summary_zh": "\u81ea\u7136\u8a9e\u8a00\u5230\u8996\u89ba\u5316 (NL2Vis) \u65e8\u5728\u5c07\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u8f49\u63db\u70ba\u7d66\u5b9a\u8868\u683c\u7684\u8996\u89ba\u5316\u8868\u793a\uff0c\u4f7f\u7528\u6236\u80fd\u5920\u5f9e\u5927\u898f\u6a21\u6578\u64da\u4e2d\u7372\u53d6\u898b\u89e3\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u986f\u793a\u51fa\u81ea\u52d5\u5316\u7a0b\u5f0f\u78bc\u751f\u6210\u7684\u5e0c\u671b\uff0c\u5c07\u8868\u683c\u6578\u64da\u8f49\u63db\u70ba\u53ef\u8a2a\u554f\u7684\u8996\u89ba\u5316\u3002\u7136\u800c\uff0c\u5b83\u5011\u901a\u5e38\u96e3\u4ee5\u8655\u7406\u9700\u8981\u8de8\u591a\u500b\u8868\u683c\u9032\u884c\u63a8\u7406\u7684\u8907\u96dc\u67e5\u8a62\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5354\u4f5c\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7a31\u70ba nvAgent\uff0c\u7528\u65bc NL2Vis\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cnvAgent \u5305\u542b\u4e09\u500b\u4ee3\u7406\uff1a\u4e00\u500b\u7528\u65bc\u8cc7\u6599\u5eab\u8655\u7406\u548c\u4e0a\u4e0b\u6587\u904e\u6ffe\u7684\u8655\u7406\u5668\u4ee3\u7406\u3001\u4e00\u500b\u7528\u65bc\u898f\u5283\u8996\u89ba\u5316\u751f\u6210\u7684\u4f5c\u66f2\u5668\u4ee3\u7406\u548c\u4e00\u500b\u7528\u65bc\u7a0b\u5f0f\u78bc\u8f49\u63db\u548c\u8f38\u51fa\u9a57\u8b49\u7684\u9a57\u8b49\u5668\u4ee3\u7406\u3002\u5728\u65b0\u7684 VisEval \u57fa\u6e96\u4e0a\u7684\u7d9c\u5408\u8a55\u4f30\u8868\u660e\uff0cnvAgent \u6301\u7e8c\u8d85\u8d8a\u6700\u5148\u9032\u7684\u57fa\u6e96\uff0c\u5728\u55ae\u8868\u4e2d\u5be6\u73fe\u4e86 7.88% \u7684\u6539\u9032\uff0c\u5728\u591a\u8868\u5834\u666f\u4e2d\u5be6\u73fe\u4e86 9.23% \u7684\u6539\u9032\u3002\u5b9a\u6027\u5206\u6790\u9032\u4e00\u6b65\u5f37\u8abf\uff0cnvAgent \u5728\u5148\u524d\u6a21\u578b\u4e0a\u4fdd\u6301\u4e86\u8fd1 20% \u7684\u6548\u80fd\u512a\u52e2\uff0c\u7a81\u986f\u4e86\u5b83\u5f9e\u8907\u96dc\u3001\u7570\u8cea\u6578\u64da\u6e90\u7522\u751f\u9ad8\u54c1\u8cea\u8996\u89ba\u5316\u8868\u793a\u7684\u80fd\u529b\u3002", "author": "Geliang Ouyang et.al.", "authors": "Geliang Ouyang, Jingyao Chen, Zhihe Nie, Yi Gui, Yao Wan, Hongyu Zhang, Dongping Chen", "id": "2502.05036v1", "paper_url": "http://arxiv.org/abs/2502.05036v1", "repo": "null"}}