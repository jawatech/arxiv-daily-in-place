{"2406.19528": {"publish_time": "2024-06-27", "title": "Using Large Language Models to Assist Video Content Analysis: An Exploratory Study of Short Videos on Depression", "paper_summary": "Despite the growing interest in leveraging Large Language Models (LLMs) for\ncontent analysis, current studies have primarily focused on text-based content.\nIn the present work, we explored the potential of LLMs in assisting video\ncontent analysis by conducting a case study that followed a new workflow of\nLLM-assisted multimodal content analysis. The workflow encompasses codebook\ndesign, prompt engineering, LLM processing, and human evaluation. We\nstrategically crafted annotation prompts to get LLM Annotations in structured\nform and explanation prompts to generate LLM Explanations for a better\nunderstanding of LLM reasoning and transparency. To test LLM's video annotation\ncapabilities, we analyzed 203 keyframes extracted from 25 YouTube short videos\nabout depression. We compared the LLM Annotations with those of two human\ncoders and found that LLM has higher accuracy in object and activity\nAnnotations than emotion and genre Annotations. Moreover, we identified the\npotential and limitations of LLM's capabilities in annotating videos. Based on\nthe findings, we explore opportunities and challenges for future research and\nimprovements to the workflow. We also discuss ethical concerns surrounding\nfuture studies based on LLM-assisted video analysis.", "paper_summary_zh": "\u5118\u7ba1\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9032\u884c\u5167\u5bb9\u5206\u6790\u7684\u8208\u8da3\u65e5\u76ca\u6fc3\u539a\uff0c\u4f46\u76ee\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u65bc\u57fa\u65bc\u6587\u5b57\u7684\u5167\u5bb9\u3002\u5728\u76ee\u524d\u7684\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86 LLM \u5728\u5354\u52a9\u5f71\u7247\u5167\u5bb9\u5206\u6790\u65b9\u9762\u7684\u6f5b\u529b\uff0c\u65b9\u6cd5\u662f\u9032\u884c\u4e00\u500b\u6848\u4f8b\u7814\u7a76\uff0c\u9075\u5faa LLM \u8f14\u52a9\u591a\u6a21\u614b\u5167\u5bb9\u5206\u6790\u7684\u65b0\u5de5\u4f5c\u6d41\u7a0b\u3002\u8a72\u5de5\u4f5c\u6d41\u7a0b\u5305\u542b\u4ee3\u78bc\u7c3f\u8a2d\u8a08\u3001\u63d0\u793a\u5de5\u7a0b\u3001LLM \u8655\u7406\u548c\u4eba\u5de5\u8a55\u4f30\u3002\u6211\u5011\u7b56\u7565\u6027\u5730\u88fd\u4f5c\u8a3b\u91cb\u63d0\u793a\uff0c\u4ee5\u7d50\u69cb\u5316\u7684\u5f62\u5f0f\u53d6\u5f97 LLM \u8a3b\u91cb\uff0c\u4e26\u8aaa\u660e\u63d0\u793a\u4ee5\u7522\u751f LLM \u8aaa\u660e\uff0c\u4ee5\u4fbf\u66f4\u4e86\u89e3 LLM \u63a8\u7406\u548c\u900f\u660e\u5ea6\u3002\u70ba\u4e86\u6e2c\u8a66 LLM \u7684\u5f71\u7247\u8a3b\u91cb\u80fd\u529b\uff0c\u6211\u5011\u5206\u6790\u4e86\u5f9e 25 \u500b\u95dc\u65bc\u6182\u9b31\u75c7\u7684 YouTube \u77ed\u7247\u4e2d\u63d0\u53d6\u7684 203 \u500b\u95dc\u9375\u5f71\u683c\u3002\u6211\u5011\u5c07 LLM \u8a3b\u91cb\u8207\u5169\u500b\u4eba\u985e\u7de8\u78bc\u5668\u7684\u8a3b\u91cb\u9032\u884c\u6bd4\u8f03\uff0c\u767c\u73fe LLM \u5728\u7269\u4ef6\u548c\u6d3b\u52d5\u8a3b\u91cb\u65b9\u9762\u7684\u6e96\u78ba\u5ea6\u9ad8\u65bc\u60c5\u7dd2\u548c\u985e\u578b\u8a3b\u91cb\u3002\u6b64\u5916\uff0c\u6211\u5011\u78ba\u5b9a\u4e86 LLM \u5728\u5f71\u7247\u8a3b\u91cb\u65b9\u9762\u7684\u6f5b\u529b\u8207\u9650\u5236\u3002\u6839\u64da\u7814\u7a76\u7d50\u679c\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u672a\u4f86\u7814\u7a76\u548c\u5de5\u4f5c\u6d41\u7a0b\u6539\u9032\u7684\u6a5f\u6703\u548c\u6311\u6230\u3002\u6211\u5011\u4e5f\u8a0e\u8ad6\u4e86\u57fa\u65bc LLM \u8f14\u52a9\u5f71\u7247\u5206\u6790\u7684\u672a\u4f86\u7814\u7a76\u4e2d\u5468\u570d\u7684\u502b\u7406\u554f\u984c\u3002", "author": "Jiaying Liu et.al.", "authors": "Jiaying Liu, Yunlong Wang, Yao Lyu, Yiheng Su, Shuo Niu, Xuhai \"Orson\" Xu, Yan Zhang", "id": "2406.19528v1", "paper_url": "http://arxiv.org/abs/2406.19528v1", "repo": "null"}}