{"2412.09560": {"publish_time": "2024-12-12", "title": "Foundational Large Language Models for Materials Research", "paper_summary": "Materials discovery and development are critical for addressing global\nchallenges. Yet, the exponential growth in materials science literature\ncomprising vast amounts of textual data has created significant bottlenecks in\nknowledge extraction, synthesis, and scientific reasoning. Large Language\nModels (LLMs) offer unprecedented opportunities to accelerate materials\nresearch through automated analysis and prediction. Still, their effective\ndeployment requires domain-specific adaptation for understanding and solving\ndomain-relevant tasks. Here, we present LLaMat, a family of foundational models\nfor materials science developed through continued pretraining of LLaMA models\non an extensive corpus of materials literature and crystallographic data.\nThrough systematic evaluation, we demonstrate that LLaMat excels in\nmaterials-specific NLP and structured information extraction while maintaining\ngeneral linguistic capabilities. The specialized LLaMat-CIF variant\ndemonstrates unprecedented capabilities in crystal structure generation,\npredicting stable crystals with high coverage across the periodic table.\nIntriguingly, despite LLaMA-3's superior performance in comparison to LLaMA-2,\nwe observe that LLaMat-2 demonstrates unexpectedly enhanced domain-specific\nperformance across diverse materials science tasks, including structured\ninformation extraction from text and tables, more particularly in crystal\nstructure generation, a potential adaptation rigidity in overtrained LLMs.\nAltogether, the present work demonstrates the effectiveness of domain\nadaptation towards developing practically deployable LLM copilots for materials\nresearch. Beyond materials science, our findings reveal important\nconsiderations for domain adaptation of LLMs, such as model selection, training\nmethodology, and domain-specific performance, which may influence the\ndevelopment of specialized scientific AI systems.", "paper_summary_zh": "\u6750\u6599\u7684\u767c\u73fe\u8207\u958b\u767c\u5c0d\u65bc\u56e0\u61c9\u5168\u7403\u6311\u6230\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u6750\u6599\u79d1\u5b78\u6587\u737b\u7684\u6307\u6578\u578b\u6210\u9577\u5305\u542b\u5927\u91cf\u7684\u6587\u5b57\u8cc7\u6599\uff0c\u5df2\u5728\u77e5\u8b58\u8403\u53d6\u3001\u7d9c\u5408\u8207\u79d1\u5b78\u63a8\u7406\u65b9\u9762\u9020\u6210\u91cd\u5927\u7684\u74f6\u9838\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u6a5f\u6703\uff0c\u53ef\u900f\u904e\u81ea\u52d5\u5316\u5206\u6790\u8207\u9810\u6e2c\u4f86\u52a0\u901f\u6750\u6599\u7814\u7a76\u3002\u7136\u800c\uff0c\u5176\u6709\u6548\u90e8\u7f72\u9700\u8981\u7279\u5b9a\u9818\u57df\u7684\u9069\u61c9\uff0c\u624d\u80fd\u7406\u89e3\u4e26\u89e3\u6c7a\u8207\u9818\u57df\u76f8\u95dc\u7684\u4efb\u52d9\u3002\u5728\u6b64\uff0c\u6211\u5011\u63d0\u51fa LLaMat\uff0c\u9019\u662f\u4e00\u500b\u57fa\u790e\u6a21\u578b\u7cfb\u5217\uff0c\u7528\u65bc\u6750\u6599\u79d1\u5b78\uff0c\u900f\u904e\u6301\u7e8c\u9810\u8a13\u7df4 LLaMA \u6a21\u578b\u65bc\u5ee3\u6cdb\u7684\u6750\u6599\u6587\u737b\u8207\u6676\u9ad4\u5b78\u8cc7\u6599\u4e2d\u800c\u958b\u767c\u3002\u900f\u904e\u7cfb\u7d71\u6027\u8a55\u4f30\uff0c\u6211\u5011\u8b49\u660e LLaMat \u5728\u7279\u5b9a\u6750\u6599\u7684\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u8207\u7d50\u69cb\u5316\u8cc7\u8a0a\u8403\u53d6\u65b9\u9762\u8868\u73fe\u512a\u7570\uff0c\u540c\u6642\u7dad\u6301\u4e00\u822c\u8a9e\u8a00\u80fd\u529b\u3002\u5c08\u9580\u7684 LLaMat-CIF \u8b8a\u9ad4\u5728\u6676\u9ad4\u7d50\u69cb\u751f\u6210\u65b9\u9762\u5c55\u73fe\u524d\u6240\u672a\u6709\u7684\u80fd\u529b\uff0c\u9810\u6e2c\u9031\u671f\u8868\u4e2d\u5177\u6709\u9ad8\u8986\u84cb\u7387\u7684\u7a69\u5b9a\u6676\u9ad4\u3002\u6709\u8da3\u7684\u662f\uff0c\u5118\u7ba1 LLaMA-3 \u7684\u6548\u80fd\u512a\u65bc LLaMA-2\uff0c\u6211\u5011\u89c0\u5bdf\u5230 LLaMat-2 \u5728\u4e0d\u540c\u7684\u6750\u6599\u79d1\u5b78\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u9810\u671f\u4e4b\u5916\u7684\u589e\u5f37\u9818\u57df\u7279\u5b9a\u6548\u80fd\uff0c\u5305\u62ec\u5f9e\u6587\u5b57\u8207\u8868\u683c\u4e2d\u8403\u53d6\u7d50\u69cb\u5316\u8cc7\u8a0a\uff0c\u66f4\u7279\u5225\u7684\u662f\u5728\u6676\u9ad4\u7d50\u69cb\u751f\u6210\u4e2d\uff0c\u9019\u662f\u4e00\u7a2e\u904e\u5ea6\u8a13\u7df4 LLM \u4e2d\u6f5b\u5728\u7684\u9069\u61c9\u50f5\u5316\u3002\u7e3d\u800c\u8a00\u4e4b\uff0c\u76ee\u524d\u7684\u7814\u7a76\u8b49\u660e\u4e86\u9818\u57df\u9069\u61c9\u5728\u958b\u767c\u5be6\u52d9\u4e0a\u53ef\u90e8\u7f72\u7684 LLM \u526f\u99d5\u99db\u5c0d\u65bc\u6750\u6599\u7814\u7a76\u7684\u6709\u6548\u6027\u3002\u9664\u4e86\u6750\u6599\u79d1\u5b78\u4e4b\u5916\uff0c\u6211\u5011\u7684\u767c\u73fe\u63ed\u793a\u4e86 LLM \u9818\u57df\u9069\u61c9\u7684\u91cd\u8981\u8003\u91cf\uff0c\u4f8b\u5982\u6a21\u578b\u9078\u64c7\u3001\u8a13\u7df4\u65b9\u6cd5\u8207\u7279\u5b9a\u9818\u57df\u7684\u6548\u80fd\uff0c\u9019\u53ef\u80fd\u6703\u5f71\u97ff\u5c08\u9580\u79d1\u5b78 AI \u7cfb\u7d71\u7684\u958b\u767c\u3002", "author": "Vaibhav Mishra et.al.", "authors": "Vaibhav Mishra, Somaditya Singh, Dhruv Ahlawat, Mohd Zaki, Vaibhav Bihani, Hargun Singh Grover, Biswajit Mishra, Santiago Miret, Mausam, N. M. Anoop Krishnan", "id": "2412.09560v1", "paper_url": "http://arxiv.org/abs/2412.09560v1", "repo": "null"}}