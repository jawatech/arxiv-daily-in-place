{"2412.09827": {"publish_time": "2024-12-13", "title": "Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models", "paper_summary": "Fine-tuning pre-trained large language models in a parameter-efficient manner\nis widely studied for its effectiveness and efficiency. LoRA is one of the most\nwidely used methods, which assumes that the optimization process is essentially\nlow dimensional. Although LoRA has demonstrated commendable performance, there\nremains a significant performance gap between LoRA and full fine-tuning when\nlearning new tasks. In this work, we propose Low-Rank Adaptation with\nTask-Relevant Feature Enhancement(LoRATRF) for enhancing task-relevant features\nfrom the perspective of editing neural network representations. To prioritize\ntask-relevant features, a task-aware filter that selectively extracts valuable\nknowledge from hidden representations for the target or current task is\ndesigned. As the experiments on a vareity of datasets including NLU,\ncommonsense reasoning and mathematical reasoning tasks demonstrates, our method\nreduces 33.71% parameters and achieves better performance on a variety of\ndatasets in comparison with SOTA low-rank methods.", "paper_summary_zh": "\u4ee5\u53c3\u6578\u6709\u6548\u7387\u7684\u65b9\u5f0f\u5fae\u8abf\u9810\u5148\u8a13\u7df4\u7684\u5927\u8a9e\u8a00\u6a21\u578b\u56e0\u5176\u6709\u6548\u6027\u548c\u6548\u7387\u800c\u5ee3\u53d7\u7814\u7a76\u3002LoRA \u662f\u5176\u4e2d\u4e00\u7a2e\u6700\u5ee3\u6cdb\u4f7f\u7528\u7684\u65b9\u6cd5\uff0c\u5b83\u5047\u8a2d\u6700\u4f73\u5316\u904e\u7a0b\u672c\u8cea\u4e0a\u662f\u4f4e\u7dad\u5ea6\u7684\u3002\u5118\u7ba1 LoRA \u5df2\u5c55\u73fe\u51fa\u4ee4\u4eba\u7a31\u9053\u7684\u6548\u80fd\uff0c\u4f46\u5728\u5b78\u7fd2\u65b0\u4efb\u52d9\u6642\uff0cLoRA \u548c\u5b8c\u5168\u5fae\u8abf\u4e4b\u9593\u4ecd\u5b58\u5728\u986f\u8457\u7684\u6548\u80fd\u5dee\u8ddd\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u5177\u6709\u4efb\u52d9\u76f8\u95dc\u7279\u5fb5\u589e\u5f37\u7684\u4f4e\u79e9\u9069\u61c9 (LoRATRF)\uff0c\u4ee5\u7de8\u8f2f\u795e\u7d93\u7db2\u8def\u8868\u793a\u7684\u65b9\u5f0f\u589e\u5f37\u8207\u4efb\u52d9\u76f8\u95dc\u7684\u7279\u5fb5\u3002\u70ba\u4e86\u512a\u5148\u8003\u616e\u8207\u4efb\u52d9\u76f8\u95dc\u7684\u7279\u5fb5\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u4efb\u52d9\u611f\u77e5\u7be9\u9078\u5668\uff0c\u7528\u65bc\u6709\u9078\u64c7\u5730\u5f9e\u96b1\u85cf\u8868\u793a\u4e2d\u63d0\u53d6\u6709\u50f9\u503c\u7684\u77e5\u8b58\uff0c\u4ee5\u4f9b\u76ee\u6a19\u6216\u7576\u524d\u4efb\u52d9\u4f7f\u7528\u3002\u6b63\u5982\u5728\u5305\u542b NLU\u3001\u5e38\u8b58\u63a8\u7406\u548c\u6578\u5b78\u63a8\u7406\u4efb\u52d9\u5728\u5167\u7684\u5404\u7a2e\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u6240\u793a\uff0c\u8207 SOTA \u4f4e\u79e9\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6a21\u578b\u6e1b\u5c11\u4e86 33.71% \u7684\u53c3\u6578\uff0c\u4e26\u5728\u5404\u7a2e\u8cc7\u6599\u96c6\u4e0a\u5be6\u73fe\u4e86\u66f4\u597d\u7684\u6548\u80fd\u3002", "author": "Changqun Li et.al.", "authors": "Changqun Li, Chaofan Ding, Kexin Luan, Xinhan Di", "id": "2412.09827v1", "paper_url": "http://arxiv.org/abs/2412.09827v1", "repo": "null"}}