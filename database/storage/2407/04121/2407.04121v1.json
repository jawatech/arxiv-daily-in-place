{"2407.04121": {"publish_time": "2024-07-04", "title": "Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models", "paper_summary": "Large Language Models (LLMs) have gained widespread adoption in various\nnatural language processing tasks, including question answering and dialogue\nsystems. However, a major drawback of LLMs is the issue of hallucination, where\nthey generate unfaithful or inconsistent content that deviates from the input\nsource, leading to severe consequences. In this paper, we propose a robust\ndiscriminator named RelD to effectively detect hallucination in LLMs' generated\nanswers. RelD is trained on the constructed RelQA, a bilingual\nquestion-answering dialogue dataset along with answers generated by LLMs and a\ncomprehensive set of metrics. Our experimental results demonstrate that the\nproposed RelD successfully detects hallucination in the answers generated by\ndiverse LLMs. Moreover, it performs well in distinguishing hallucination in\nLLMs' generated answers from both in-distribution and out-of-distribution\ndatasets. Additionally, we also conduct a thorough analysis of the types of\nhallucinations that occur and present valuable insights. This research\nsignificantly contributes to the detection of reliable answers generated by\nLLMs and holds noteworthy implications for mitigating hallucination in the\nfuture work.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5ee3\u6cdb\u63a1\u7528\uff0c\u5305\u62ec\u554f\u7b54\u548c\u5c0d\u8a71\u7cfb\u7d71\u3002\u7136\u800c\uff0cLLM \u7684\u4e00\u500b\u4e3b\u8981\u7f3a\u9ede\u662f\u5e7b\u89ba\u554f\u984c\uff0c\u5b83\u5011\u6703\u7522\u751f\u8207\u8f38\u5165\u4f86\u6e90\u4e0d\u540c\u7684\u4e0d\u5fe0\u5be6\u6216\u4e0d\u4e00\u81f4\u7684\u5167\u5bb9\uff0c\u5c0e\u81f4\u56b4\u91cd\u7684\u5f8c\u679c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba RelD \u7684\u5f37\u5065\u5224\u5225\u5668\uff0c\u4ee5\u6709\u6548\u6aa2\u6e2c LLM \u751f\u6210\u7684\u7b54\u6848\u4e2d\u7684\u5e7b\u89ba\u3002RelD \u662f\u5728\u69cb\u9020\u7684 RelQA \u4e0a\u8a13\u7df4\u7684\uff0cRelQA \u662f\u96d9\u8a9e\u554f\u7b54\u5c0d\u8a71\u6578\u64da\u96c6\uff0c\u4ee5\u53ca LLM \u751f\u6210\u7684\u7b54\u6848\u548c\u4e00\u7d44\u7d9c\u5408\u6307\u6a19\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684 RelD \u6210\u529f\u6aa2\u6e2c\u4e86\u5404\u7a2e LLM \u751f\u6210\u7684\u7b54\u6848\u4e2d\u7684\u5e7b\u89ba\u3002\u6b64\u5916\uff0c\u5b83\u5728\u5340\u5206 LLM \u751f\u6210\u7684\u7b54\u6848\u4e2d\u7684\u5e7b\u89ba\u8207\u5206\u4f48\u5167\u548c\u5206\u4f48\u5916\u6578\u64da\u96c6\u65b9\u9762\u8868\u73fe\u826f\u597d\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u5c0d\u767c\u751f\u7684\u5e7b\u89ba\u985e\u578b\u9032\u884c\u4e86\u5fb9\u5e95\u7684\u5206\u6790\uff0c\u4e26\u63d0\u51fa\u4e86\u5bf6\u8cb4\u7684\u898b\u89e3\u3002\u9019\u9805\u7814\u7a76\u986f\u8457\u6709\u52a9\u65bc\u6aa2\u6e2c LLM \u751f\u6210\u7684\u53ef\u9760\u7b54\u6848\uff0c\u4e26\u5c0d\u672a\u4f86\u5de5\u4f5c\u4e2d\u6e1b\u8f15\u5e7b\u89ba\u5177\u6709\u91cd\u8981\u7684\u610f\u7fa9\u3002", "author": "Yuyan Chen et.al.", "authors": "Yuyan Chen, Qiang Fu, Yichen Yuan, Zhihao Wen, Ge Fan, Dayiheng Liu, Dongmei Zhang, Zhixu Li, Yanghua Xiao", "id": "2407.04121v1", "paper_url": "http://arxiv.org/abs/2407.04121v1", "repo": "null"}}