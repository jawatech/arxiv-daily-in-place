{"2405.12209": {"publish_time": "2024-05-20", "title": "MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark", "paper_summary": "Recent advancements in large language models (LLMs) have showcased\nsignificant improvements in mathematics. However, traditional math benchmarks\nlike GSM8k offer a unidimensional perspective, falling short in providing a\nholistic assessment of the LLMs' math capabilities. To address this gap, we\nintroduce MathBench, a new benchmark that rigorously assesses the mathematical\ncapabilities of large language models. MathBench spans a wide range of\nmathematical disciplines, offering a detailed evaluation of both theoretical\nunderstanding and practical problem-solving skills. The benchmark progresses\nthrough five distinct stages, from basic arithmetic to college mathematics, and\nis structured to evaluate models at various depths of knowledge. Each stage\nincludes theoretical questions and application problems, allowing us to measure\na model's mathematical proficiency and its ability to apply concepts in\npractical scenarios. MathBench aims to enhance the evaluation of LLMs'\nmathematical abilities, providing a nuanced view of their knowledge\nunderstanding levels and problem solving skills in a bilingual context. The\nproject is released at https://github.com/open-compass/MathBench .", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8fd1\u671f\u9032\u5c55\u5df2\u5c55\u793a\u51fa\u6578\u5b78\u65b9\u9762\u7684\u91cd\u5927\u6539\u9032\u3002\u7136\u800c\uff0c\u50b3\u7d71\u6578\u5b78\u57fa\u6e96\uff08\u4f8b\u5982 GSM8k\uff09\u63d0\u4f9b\u4e86\u4e00\u7a2e\u55ae\u5411\u5ea6\u89c0\u9ede\uff0c\u7121\u6cd5\u5168\u9762\u8a55\u4f30 LLM \u7684\u6578\u5b78\u80fd\u529b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86 MathBench\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7684\u57fa\u6e96\uff0c\u53ef\u4ee5\u56b4\u683c\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u6578\u5b78\u80fd\u529b\u3002MathBench \u6db5\u84cb\u4e86\u5ee3\u6cdb\u7684\u6578\u5b78\u5b78\u79d1\uff0c\u5c0d\u7406\u8ad6\u7406\u89e3\u548c\u5be6\u969b\u554f\u984c\u89e3\u6c7a\u6280\u80fd\u9032\u884c\u4e86\u8a73\u7d30\u8a55\u4f30\u3002\u57fa\u6e96\u5206\u70ba\u4e94\u500b\u4e0d\u540c\u7684\u968e\u6bb5\uff0c\u5f9e\u57fa\u790e\u7b97\u8853\u5230\u5927\u5b78\u6578\u5b78\uff0c\u4e26\u65e8\u5728\u8a55\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u77e5\u8b58\u6df1\u5ea6\u4e0b\u7684\u8868\u73fe\u3002\u6bcf\u500b\u968e\u6bb5\u90fd\u5305\u542b\u7406\u8ad6\u554f\u984c\u548c\u61c9\u7528\u554f\u984c\uff0c\u8b93\u6211\u5011\u53ef\u4ee5\u8861\u91cf\u6a21\u578b\u7684\u6578\u5b78\u80fd\u529b\u53ca\u5176\u5728\u5be6\u969b\u5834\u666f\u4e2d\u61c9\u7528\u6982\u5ff5\u7684\u80fd\u529b\u3002MathBench \u65e8\u5728\u52a0\u5f37\u5c0d LLM \u6578\u5b78\u80fd\u529b\u7684\u8a55\u4f30\uff0c\u5728\u96d9\u8a9e\u74b0\u5883\u4e2d\u63d0\u4f9b\u5176\u77e5\u8b58\u7406\u89e3\u5c64\u6b21\u548c\u554f\u984c\u89e3\u6c7a\u6280\u80fd\u7684\u7d30\u7dfb\u89c0\u9ede\u3002\u8a72\u5c08\u6848\u5df2\u5728 https://github.com/open-compass/MathBench \u767c\u5e03\u3002", "author": "Hongwei Liu et.al.", "authors": "Hongwei Liu, Zilong Zheng, Yuxuan Qiao, Haodong Duan, Zhiwei Fei, Fengzhe Zhou, Wenwei Zhang, Songyang Zhang, Dahua Lin, Kai Chen", "id": "2405.12209v1", "paper_url": "http://arxiv.org/abs/2405.12209v1", "repo": "https://github.com/open-compass/mathbench"}}