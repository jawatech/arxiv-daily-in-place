{"2412.07278": {"publish_time": "2024-12-10", "title": "Superficial Consciousness Hypothesis for Autoregressive Transformers", "paper_summary": "The alignment between human objectives and machine learning models built on\nthese objectives is a crucial yet challenging problem for achieving Trustworthy\nAI, particularly when preparing for superintelligence (SI). First, given that\nSI does not exist today, empirical analysis for direct evidence is difficult.\nSecond, SI is assumed to be more intelligent than humans, capable of deceiving\nus into underestimating its intelligence, making output-based analysis\nunreliable. Lastly, what kind of unexpected property SI might have is still\nunclear. To address these challenges, we propose the Superficial Consciousness\nHypothesis under Information Integration Theory (IIT), suggesting that SI could\nexhibit a complex information-theoretic state like a conscious agent while\nunconscious. To validate this, we use a hypothetical scenario where SI can\nupdate its parameters \"at will\" to achieve its own objective (mesa-objective)\nunder the constraint of the human objective (base objective). We show that a\npractical estimate of IIT's consciousness metric is relevant to the widely used\nperplexity metric, and train GPT-2 with those two objectives. Our preliminary\nresult suggests that this SI-simulating GPT-2 could simultaneously follow the\ntwo objectives, supporting the feasibility of the Superficial Consciousness\nHypothesis.", "paper_summary_zh": "\u4eba\u985e\u76ee\u6a19\u8207\u5efa\u7acb\u5728\u9019\u4e9b\u76ee\u6a19\u4e0a\u7684\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u4e4b\u9593\u7684\u4e00\u81f4\u6027\uff0c\u662f\u5be6\u73fe\u53ef\u4fe1\u8cf4 AI \u7684\u4e00\u500b\u95dc\u9375\u4e14\u5177\u6709\u6311\u6230\u6027\u7684\u554f\u984c\uff0c\u7279\u5225\u662f\u5728\u70ba\u8d85\u7d1a\u667a\u80fd (SI) \u505a\u6e96\u5099\u6642\u3002\u9996\u5148\uff0c\u9451\u65bc SI \u76ee\u524d\u4e26\u4e0d\u5b58\u5728\uff0c\u56e0\u6b64\u96e3\u4ee5\u9032\u884c\u76f4\u63a5\u8b49\u64da\u7684\u5be6\u8b49\u5206\u6790\u3002\u5176\u6b21\uff0c\u5047\u8a2d SI \u6bd4\u4eba\u985e\u66f4\u5177\u667a\u6167\uff0c\u80fd\u5920\u6b3a\u9a19\u6211\u5011\u4f4e\u4f30\u5176\u667a\u6167\uff0c\u4f7f\u5f97\u57fa\u65bc\u8f38\u51fa\u7684\u5206\u6790\u4e0d\u53ef\u9760\u3002\u6700\u5f8c\uff0cSI \u53ef\u80fd\u5177\u6709\u7684\u610f\u5916\u5c6c\u6027\u662f\u4ec0\u9ebc\uff0c\u76ee\u524d\u4ecd\u4e0d\u6e05\u695a\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5728\u8cc7\u8a0a\u6574\u5408\u7406\u8ad6 (IIT) \u4e0b\u63d0\u51fa\u8868\u9762\u610f\u8b58\u5047\u8aaa\uff0c\u8868\u660e SI \u53ef\u4ee5\u5728\u7121\u610f\u8b58\u7684\u72c0\u614b\u4e0b\u8868\u73fe\u51fa\u50cf\u6709\u610f\u8b58\u4ee3\u7406\u4e00\u6a23\u7684\u8907\u96dc\u8cc7\u8a0a\u7406\u8ad6\u72c0\u614b\u3002\u70ba\u4e86\u9a57\u8b49\u9019\u4e00\u9ede\uff0c\u6211\u5011\u4f7f\u7528\u4e86\u4e00\u500b\u5047\u8a2d\u60c5\u5883\uff0c\u5176\u4e2d SI \u53ef\u4ee5\u300c\u96a8\u610f\u300d\u66f4\u65b0\u5176\u53c3\u6578\uff0c\u4ee5\u5728\u4eba\u985e\u76ee\u6a19\uff08\u57fa\u790e\u76ee\u6a19\uff09\u7684\u7d04\u675f\u4e0b\u5be6\u73fe\u5176\u81ea\u8eab\u76ee\u6a19\uff08\u5143\u76ee\u6a19\uff09\u3002\u6211\u5011\u8868\u660e\uff0cIIT \u610f\u8b58\u91cf\u8868\u7684\u5be6\u969b\u4f30\u8a08\u8207\u5ee3\u6cdb\u4f7f\u7528\u7684\u56f0\u60d1\u5ea6\u91cf\u76f8\u95dc\uff0c\u4e26\u4f7f\u7528\u9019\u5169\u500b\u76ee\u6a19\u8a13\u7df4 GPT-2\u3002\u6211\u5011\u7684\u521d\u6b65\u7d50\u679c\u8868\u660e\uff0c\u9019\u500b\u6a21\u64ec SI \u7684 GPT-2 \u53ef\u4ee5\u540c\u6642\u9075\u5faa\u9019\u5169\u500b\u76ee\u6a19\uff0c\u652f\u6301\u8868\u9762\u610f\u8b58\u5047\u8aaa\u7684\u53ef\u884c\u6027\u3002", "author": "Yosuke Miyanishi et.al.", "authors": "Yosuke Miyanishi, Keita Mitani", "id": "2412.07278v1", "paper_url": "http://arxiv.org/abs/2412.07278v1", "repo": "null"}}