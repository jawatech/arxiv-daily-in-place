{"2501.09838": {"publish_time": "2025-01-16", "title": "CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified Intermediate Representation", "paper_summary": "Geospatial imaging leverages data from diverse sensing modalities-such as EO,\nSAR, and LiDAR, ranging from ground-level drones to satellite views. These\nheterogeneous inputs offer significant opportunities for scene understanding\nbut present challenges in interpreting geometry accurately, particularly in the\nabsence of precise ground truth data. To address this, we propose\nCrossModalityDiffusion, a modular framework designed to generate images across\ndifferent modalities and viewpoints without prior knowledge of scene geometry.\nCrossModalityDiffusion employs modality-specific encoders that take multiple\ninput images and produce geometry-aware feature volumes that encode scene\nstructure relative to their input camera positions. The space where the feature\nvolumes are placed acts as a common ground for unifying input modalities. These\nfeature volumes are overlapped and rendered into feature images from novel\nperspectives using volumetric rendering techniques. The rendered feature images\nare used as conditioning inputs for a modality-specific diffusion model,\nenabling the synthesis of novel images for the desired output modality. In this\npaper, we show that jointly training different modules ensures consistent\ngeometric understanding across all modalities within the framework. We validate\nCrossModalityDiffusion's capabilities on the synthetic ShapeNet cars dataset,\ndemonstrating its effectiveness in generating accurate and consistent novel\nviews across multiple imaging modalities and perspectives.", "paper_summary_zh": "\u5730\u7406\u7a7a\u9593\u5f71\u50cf\u5229\u7528\u4f86\u81ea\u4e0d\u540c\u611f\u6e2c\u65b9\u5f0f\u7684\u8cc7\u6599\uff0c\u4f8b\u5982 EO\u3001SAR \u548c LiDAR\uff0c\u7bc4\u570d\u5f9e\u5730\u9762\u7121\u4eba\u6a5f\u5230\u885b\u661f\u5f71\u50cf\u3002\u9019\u4e9b\u7570\u8cea\u8f38\u5165\u70ba\u5834\u666f\u7406\u89e3\u63d0\u4f9b\u4e86\u986f\u8457\u7684\u6a5f\u6703\uff0c\u4f46\u5728\u6e96\u78ba\u89e3\u8b80\u5e7e\u4f55\u5f62\u72c0\u6642\u6703\u7522\u751f\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u7f3a\u4e4f\u7cbe\u78ba\u5730\u9762\u771f\u5be6\u8cc7\u6599\u7684\u60c5\u6cc1\u4e0b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa CrossModalityDiffusion\uff0c\u9019\u662f\u4e00\u500b\u6a21\u7d44\u5316\u67b6\u69cb\uff0c\u65e8\u5728\u8de8\u4e0d\u540c\u65b9\u5f0f\u548c\u89c0\u9ede\u751f\u6210\u5f71\u50cf\uff0c\u800c\u7121\u9700\u4e8b\u5148\u4e86\u89e3\u5834\u666f\u5e7e\u4f55\u5f62\u72c0\u3002CrossModalityDiffusion \u4f7f\u7528\u7279\u5b9a\u65bc\u65b9\u5f0f\u7684\u7de8\u78bc\u5668\uff0c\u5b83\u6703\u64f7\u53d6\u591a\u500b\u8f38\u5165\u5f71\u50cf\uff0c\u4e26\u7522\u751f\u5177\u6709\u5e7e\u4f55\u611f\u77e5\u7279\u5fb5\u91cf\u7684\u7279\u5fb5\u91cf\uff0c\u9019\u4e9b\u7279\u5fb5\u91cf\u6703\u6839\u64da\u5176\u8f38\u5165\u76f8\u6a5f\u4f4d\u7f6e\u5c0d\u5834\u666f\u7d50\u69cb\u9032\u884c\u7de8\u78bc\u3002\u653e\u7f6e\u7279\u5fb5\u91cf\u7684\u7a7a\u9593\u4f5c\u70ba\u7d71\u4e00\u8f38\u5165\u65b9\u5f0f\u7684\u5171\u540c\u57fa\u790e\u3002\u9019\u4e9b\u7279\u5fb5\u91cf\u6703\u91cd\u758a\u4e26\u4f7f\u7528\u9ad4\u7a4d\u6e32\u67d3\u6280\u8853\u5f9e\u65b0\u89c0\u9ede\u6e32\u67d3\u6210\u7279\u5fb5\u5f71\u50cf\u3002\u6e32\u67d3\u7684\u7279\u5fb5\u5f71\u50cf\u7528\u4f5c\u7279\u5b9a\u65bc\u65b9\u5f0f\u7684\u64f4\u6563\u6a21\u578b\u7684\u689d\u4ef6\u8f38\u5165\uff0c\u5f9e\u800c\u80fd\u5920\u70ba\u6240\u9700\u7684\u8f38\u51fa\u65b9\u5f0f\u5408\u6210\u65b0\u5f71\u50cf\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u4e86\u806f\u5408\u8a13\u7df4\u4e0d\u540c\u6a21\u7d44\u53ef\u78ba\u4fdd\u67b6\u69cb\u5167\u6240\u6709\u65b9\u5f0f\u7684\u4e00\u81f4\u5e7e\u4f55\u7406\u89e3\u3002\u6211\u5011\u5728\u5408\u6210 ShapeNet \u6c7d\u8eca\u8cc7\u6599\u96c6\u4e0a\u9a57\u8b49\u4e86 CrossModalityDiffusion \u7684\u529f\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u8de8\u591a\u7a2e\u5f71\u50cf\u65b9\u5f0f\u548c\u89c0\u9ede\u751f\u6210\u6e96\u78ba\u4e14\u4e00\u81f4\u7684\u65b0\u89c0\u9ede\u7684\u6709\u6548\u6027\u3002", "author": "Alex Berian et.al.", "authors": "Alex Berian, Daniel Brignac, JhihYang Wu, Natnael Daba, Abhijit Mahalanobis", "id": "2501.09838v1", "paper_url": "http://arxiv.org/abs/2501.09838v1", "repo": "null"}}