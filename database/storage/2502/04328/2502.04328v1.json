{"2502.04328": {"publish_time": "2025-02-06", "title": "Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment", "paper_summary": "Recent advances in large language models, particularly following GPT-4o, have\nsparked increasing interest in developing omni-modal models capable of\nunderstanding more modalities. While some open-source alternatives have\nemerged, there is still a notable lag behind specialized single-modality models\nin performance. In this paper, we present Ola, an Omni-modal language model\nthat achieves competitive performance across image, video, and audio\nunderstanding compared to specialized counterparts. The core design of Ola lies\nin its progressive modality alignment strategy that extends the supporting\nmodality of the language model progressively. Our training pipeline begins with\nthe most distinct modalities: image and text, then gradually expands the skill\nsets of the model using speech data that connects language and audio knowledge,\nand video data that connects all modalities. The progressive learning pipeline\nalso enables us to maintain a relatively small size of the cross-modal\nalignment data, making developing omni-modal from existing vision-language\nmodels easy and less costly. Moreover, to unlock an advanced interactive\nexperience like GPT-4o, we further design a sentence-wise decoding solution for\nstreaming speech generation. Extensive experiments demonstrate that Ola\nsurpasses existing open omni-modal LLMs across all modalities while achieving\nhighly competitive performance compared to state-of-the-art specialized models\nof similar sizes. We aim to make Ola a fully open omni-modal understanding\nsolution to advance future research in this emerging field. Model weights,\ncode, and data are open-sourced at https://github.com/Ola-Omni/Ola.", "paper_summary_zh": "<paragraph>\u8fd1\u671f\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u9032\u5c55\uff0c\u7279\u5225\u662f\u5728 GPT-4o \u4e4b\u5f8c\uff0c\u6fc0\u767c\u4e86\u4eba\u5011\u5c0d\u958b\u767c\u5168\u6a21\u614b\u6a21\u578b\u7684\u8208\u8da3\uff0c\u9019\u7a2e\u6a21\u578b\u80fd\u5920\u7406\u89e3\u66f4\u591a\u6a21\u614b\u3002\u96d6\u7136\u5df2\u7d93\u51fa\u73fe\u4e86\u4e00\u4e9b\u958b\u6e90\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5728\u6548\u80fd\u4e0a\u4ecd\u986f\u8457\u843d\u5f8c\u65bc\u5c08\u9580\u7684\u55ae\u6a21\u614b\u6a21\u578b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa Ola\uff0c\u9019\u662f\u4e00\u500b\u5168\u6a21\u614b\u8a9e\u8a00\u6a21\u578b\uff0c\u5728\u5f71\u50cf\u3001\u5f71\u7247\u548c\u97f3\u8a0a\u7406\u89e3\u65b9\u9762\uff0c\u8207\u5c08\u9580\u7684\u5c0d\u61c9\u6a21\u578b\u76f8\u6bd4\uff0c\u9054\u5230\u4e86\u5177\u6709\u7af6\u722d\u529b\u7684\u6548\u80fd\u3002Ola \u7684\u6838\u5fc3\u8a2d\u8a08\u5728\u65bc\u5176\u6f38\u9032\u5f0f\u6a21\u614b\u5c0d\u9f4a\u7b56\u7565\uff0c\u8a72\u7b56\u7565\u9010\u6f38\u64f4\u5c55\u8a9e\u8a00\u6a21\u578b\u7684\u652f\u63f4\u6a21\u614b\u3002\u6211\u5011\u7684\u8a13\u7df4\u6d41\u7a0b\u5f9e\u6700\u4e0d\u540c\u7684\u6a21\u614b\u958b\u59cb\uff1a\u5f71\u50cf\u548c\u6587\u5b57\uff0c\u7136\u5f8c\u4f7f\u7528\u9023\u63a5\u8a9e\u8a00\u548c\u97f3\u8a0a\u77e5\u8b58\u7684\u8a9e\u97f3\u8cc7\u6599\uff0c\u4ee5\u53ca\u9023\u63a5\u6240\u6709\u6a21\u614b\u7684\u5f71\u7247\u8cc7\u6599\uff0c\u9010\u6b65\u64f4\u5c55\u6a21\u578b\u7684\u6280\u80fd\u7d44\u3002\u6f38\u9032\u5f0f\u5b78\u7fd2\u6d41\u7a0b\u4e5f\u8b93\u6211\u5011\u80fd\u5920\u7dad\u6301\u76f8\u5c0d\u8f03\u5c0f\u7684\u8de8\u6a21\u614b\u5c0d\u9f4a\u8cc7\u6599\u5927\u5c0f\uff0c\u8b93\u5f9e\u73fe\u6709\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u958b\u767c\u5168\u6a21\u614b\u6a21\u578b\u8b8a\u5f97\u5bb9\u6613\u4e14\u6210\u672c\u8f03\u4f4e\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u89e3\u9396\u985e\u4f3c GPT-4o \u7684\u9032\u968e\u4e92\u52d5\u9ad4\u9a57\uff0c\u6211\u5011\u9032\u4e00\u6b65\u8a2d\u8a08\u4e86\u4e00\u500b\u9010\u53e5\u89e3\u78bc\u89e3\u6c7a\u65b9\u6848\uff0c\u7528\u65bc\u4e32\u6d41\u8a9e\u97f3\u751f\u6210\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0cOla \u5728\u6240\u6709\u6a21\u614b\u4e0a\u90fd\u8d85\u8d8a\u4e86\u73fe\u6709\u7684\u958b\u653e\u5168\u6a21\u614b LLM\uff0c\u540c\u6642\u8207\u985e\u4f3c\u898f\u6a21\u7684\u6700\u65b0\u5c08\u9580\u6a21\u578b\u76f8\u6bd4\uff0c\u9054\u5230\u4e86\u6975\u5177\u7af6\u722d\u529b\u7684\u6548\u80fd\u3002\u6211\u5011\u5e0c\u671b\u8b93 Ola \u6210\u70ba\u4e00\u500b\u5b8c\u5168\u958b\u653e\u7684\u5168\u6a21\u614b\u7406\u89e3\u89e3\u6c7a\u65b9\u6848\uff0c\u4ee5\u63a8\u52d5\u9019\u500b\u65b0\u8208\u9818\u57df\u7684\u672a\u4f86\u7814\u7a76\u3002\u6a21\u578b\u6b0a\u91cd\u3001\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u5df2\u5728 https://github.com/Ola-Omni/Ola \u958b\u6e90\u3002</paragraph>", "author": "Zuyan Liu et.al.", "authors": "Zuyan Liu, Yuhao Dong, Jiahui Wang, Ziwei Liu, Winston Hu, Jiwen Lu, Yongming Rao", "id": "2502.04328v1", "paper_url": "http://arxiv.org/abs/2502.04328v1", "repo": "null"}}