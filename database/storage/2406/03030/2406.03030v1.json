{"2406.03030": {"publish_time": "2024-06-05", "title": "From Tarzan to Tolkien: Controlling the Language Proficiency Level of LLMs for Content Generation", "paper_summary": "We study the problem of controlling the difficulty level of text generated by\nLarge Language Models (LLMs) for contexts where end-users are not fully\nproficient, such as language learners. Using a novel framework, we evaluate the\neffectiveness of several key approaches for this task, including few-shot\nprompting, supervised finetuning, and reinforcement learning (RL), utilising\nboth GPT-4 and open source alternatives like LLama2-7B and Mistral-7B.\n  Our findings reveal a large performance gap between GPT-4 and the open source\nmodels when using prompt-based strategies. However, we show how to bridge this\ngap with a careful combination of finetuning and RL alignment. Our best model,\nCALM (CEFR-Aligned Language Model), surpasses the performance of GPT-4 and\nother strategies, at only a fraction of the cost. We further validate the\nquality of our results through a small-scale human study.", "paper_summary_zh": "\u6211\u5011\u7814\u7a76\u63a7\u5236\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6240\u7522\u751f\u6587\u5b57\u96e3\u5ea6\u7b49\u7d1a\u7684\u554f\u984c\uff0c\u9069\u7528\u65bc\u6700\u7d42\u4f7f\u7528\u8005\u80fd\u529b\u4e0d\u8db3\u7684\u74b0\u5883\uff0c\u4f8b\u5982\u8a9e\u8a00\u5b78\u7fd2\u8005\u3002\u6211\u5011\u4f7f\u7528\u4e00\u500b\u65b0\u67b6\u69cb\uff0c\u8a55\u4f30\u5e7e\u7a2e\u95dc\u9375\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u5c11\u6a23\u672c\u63d0\u793a\u3001\u76e3\u7763\u5fae\u8abf\u548c\u5f37\u5316\u5b78\u7fd2 (RL)\uff0c\u540c\u6642\u4f7f\u7528 GPT-4 \u548c LLama2-7B \u548c Mistral-7B \u7b49\u958b\u6e90\u66ff\u4ee3\u65b9\u6848\u3002\n\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u5728\u4f7f\u7528\u57fa\u65bc\u63d0\u793a\u7684\u7b56\u7565\u6642\uff0cGPT-4 \u548c\u958b\u6e90\u6a21\u578b\u4e4b\u9593\u5b58\u5728\u5f88\u5927\u7684\u6548\u80fd\u5dee\u8ddd\u3002\u7136\u800c\uff0c\u6211\u5011\u5c55\u793a\u5982\u4f55\u900f\u904e\u5fae\u8abf\u548c RL \u5c0d\u9f4a\u7684\u4ed4\u7d30\u7d44\u5408\u4f86\u7e2e\u5c0f\u9019\u500b\u5dee\u8ddd\u3002\u6211\u5011\u6700\u597d\u7684\u6a21\u578b CALM\uff08CEFR \u5c0d\u9f4a\u8a9e\u8a00\u6a21\u578b\uff09\u8d85\u8d8a\u4e86 GPT-4 \u548c\u5176\u4ed6\u7b56\u7565\u7684\u6548\u80fd\uff0c\u800c\u4e14\u6210\u672c\u50c5\u70ba\u4e00\u5c0f\u90e8\u5206\u3002\u6211\u5011\u9032\u4e00\u6b65\u900f\u904e\u5c0f\u898f\u6a21\u7684\u4eba\u985e\u7814\u7a76\u9a57\u8b49\u4e86\u6211\u5011\u7d50\u679c\u7684\u54c1\u8cea\u3002", "author": "Ali Malik et.al.", "authors": "Ali Malik, Stephen Mayhew, Chris Piech, Klinton Bicknell", "id": "2406.03030v1", "paper_url": "http://arxiv.org/abs/2406.03030v1", "repo": "null"}}