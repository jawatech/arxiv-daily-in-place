{"2407.12481": {"publish_time": "2024-07-17", "title": "Pretraining Data and Tokenizer for Indic LLM", "paper_summary": "We present a novel approach to data preparation for developing multilingual\nIndic large language model. Our meticulous data acquisition spans open-source\nand proprietary sources, including Common Crawl, Indic books, news articles,\nand Wikipedia, ensuring a diverse and rich linguistic representation. For each\nIndic language, we design a custom preprocessing pipeline to effectively\neliminate redundant and low-quality text content. Additionally, we perform\ndeduplication on Common Crawl data to address the redundancy present in 70% of\nthe crawled web pages. This study focuses on developing high-quality data,\noptimizing tokenization for our multilingual dataset for Indic large language\nmodels with 3B and 7B parameters, engineered for superior performance in Indic\nlanguages. We introduce a novel multilingual tokenizer training strategy,\ndemonstrating our custom-trained Indic tokenizer outperforms the\nstate-of-the-art OpenAI Tiktoken tokenizer, achieving a superior token-to-word\nratio for Indic languages.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u7528\u65bc\u958b\u767c\u591a\u8a9e\u8a00\u5370\u5ea6\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u8cc7\u6599\u6e96\u5099\u65b0\u65b9\u6cd5\u3002\u6211\u5011\u56b4\u8b39\u7684\u8cc7\u6599\u6536\u96c6\u6db5\u84cb\u958b\u6e90\u548c\u5c08\u6709\u4f86\u6e90\uff0c\u5305\u62ec Common Crawl\u3001\u5370\u5ea6\u66f8\u7c4d\u3001\u65b0\u805e\u6587\u7ae0\u548c\u7dad\u57fa\u767e\u79d1\uff0c\u78ba\u4fdd\u8a9e\u8a00\u8868\u9054\u7684\u591a\u6a23\u6027\u548c\u8c50\u5bcc\u6027\u3002\u5c0d\u65bc\u6bcf\u7a2e\u5370\u5ea6\u8a9e\u8a00\uff0c\u6211\u5011\u8a2d\u8a08\u4e00\u500b\u81ea\u8a02\u7684\u524d\u8655\u7406\u7ba1\u9053\uff0c\u4ee5\u6709\u6548\u6d88\u9664\u5197\u9918\u548c\u4f4e\u54c1\u8cea\u7684\u6587\u5b57\u5167\u5bb9\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c0d Common Crawl \u8cc7\u6599\u57f7\u884c\u91cd\u8907\u8cc7\u6599\u522a\u9664\uff0c\u4ee5\u89e3\u6c7a 70% \u5df2\u722c\u53d6\u7db2\u9801\u4e2d\u5b58\u5728\u7684\u5197\u9918\u554f\u984c\u3002\u672c\u7814\u7a76\u5c08\u6ce8\u65bc\u958b\u767c\u9ad8\u54c1\u8cea\u8cc7\u6599\uff0c\u91dd\u5c0d\u6211\u5011\u7684\u591a\u8a9e\u8a00\u8cc7\u6599\u96c6\u6700\u4f73\u5316\u7528\u65bc\u5370\u5ea6\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u6a19\u8a18\u5316\uff0c\u53c3\u6578\u70ba 3B \u548c 7B\uff0c\u65e8\u5728\u63d0\u5347\u5370\u5ea6\u8a9e\u8a00\u7684\u5353\u8d8a\u6548\u80fd\u3002\u6211\u5011\u5f15\u5165\u4e00\u7a2e\u65b0\u7684\u591a\u8a9e\u8a00\u6a19\u8a18\u5316\u8a13\u7df4\u7b56\u7565\uff0c\u8b49\u660e\u6211\u5011\u81ea\u8a02\u8a13\u7df4\u7684\u5370\u5ea6\u6a19\u8a18\u5316\u5668\u512a\u65bc\u6700\u5148\u9032\u7684 OpenAI Tiktoken \u6a19\u8a18\u5316\u5668\uff0c\u5728\u5370\u5ea6\u8a9e\u8a00\u4e2d\u9054\u6210\u512a\u7570\u7684\u8a5e\u5f59\u6a19\u8a18\u6bd4\u4f8b\u3002", "author": "Rahul Kumar et.al.", "authors": "Rahul Kumar, Shubham Kakde, Divyansh Rajput, Daud Ibrahim, Rishabh Nahata, Pidathala Sowjanya, Deepak Kumar", "id": "2407.12481v1", "paper_url": "http://arxiv.org/abs/2407.12481v1", "repo": "null"}}