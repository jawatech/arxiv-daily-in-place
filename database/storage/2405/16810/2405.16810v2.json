{"2405.16810": {"publish_time": "2024-05-27", "title": "Performance evaluation of Reddit Comments using Machine Learning and Natural Language Processing methods in Sentiment Analysis", "paper_summary": "Sentiment analysis, an increasingly vital field in both academia and\nindustry, plays a pivotal role in machine learning applications, particularly\non social media platforms like Reddit. However, the efficacy of sentiment\nanalysis models is hindered by the lack of expansive and fine-grained emotion\ndatasets. To address this gap, our study leverages the GoEmotions dataset,\ncomprising a diverse range of emotions, to evaluate sentiment analysis methods\nacross a substantial corpus of 58,000 comments. Distinguished from prior\nstudies by the Google team, which limited their analysis to only two models,\nour research expands the scope by evaluating a diverse array of models. We\ninvestigate the performance of traditional classifiers such as Naive Bayes and\nSupport Vector Machines (SVM), as well as state-of-the-art transformer-based\nmodels including BERT, RoBERTa, and GPT. Furthermore, our evaluation criteria\nextend beyond accuracy to encompass nuanced assessments, including hierarchical\nclassification based on varying levels of granularity in emotion\ncategorization. Additionally, considerations such as computational efficiency\nare incorporated to provide a comprehensive evaluation framework. Our findings\nreveal that the RoBERTa model consistently outperforms the baseline models,\ndemonstrating superior accuracy in fine-grained sentiment classification tasks.\nThis underscores the substantial potential and significance of the RoBERTa\nmodel in advancing sentiment analysis capabilities.", "paper_summary_zh": "\u60c5\u7dd2\u5206\u6790\u662f\u5b78\u8853\u754c\u548c\u7522\u696d\u4e2d\u65e5\u76ca\u91cd\u8981\u7684\u9818\u57df\uff0c\u5728\u6a5f\u5668\u5b78\u7fd2\u61c9\u7528\u4e2d\u626e\u6f14\u8457\u95dc\u9375\u89d2\u8272\uff0c\u7279\u5225\u662f\u5728 Reddit \u7b49\u793e\u7fa4\u5a92\u9ad4\u5e73\u53f0\u4e0a\u3002\u7136\u800c\uff0c\u60c5\u7dd2\u5206\u6790\u6a21\u578b\u7684\u6548\u80fd\u53d7\u5230\u5ee3\u6cdb\u4e14\u7d30\u7dfb\u7684\u60c5\u7dd2\u8cc7\u6599\u96c6\u7f3a\u4e4f\u7684\u963b\u7919\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u7684\u7814\u7a76\u5229\u7528 GoEmotions \u8cc7\u6599\u96c6\uff0c\u6db5\u84cb\u5404\u7a2e\u60c5\u7dd2\uff0c\u4ee5\u8a55\u4f30\u8de8\u8d8a 58,000 \u5247\u7559\u8a00\u7684\u5927\u578b\u8a9e\u6599\u5eab\u4e2d\u7684\u60c5\u7dd2\u5206\u6790\u65b9\u6cd5\u3002\u8207 Google \u5718\u968a\u5148\u524d\u50c5\u5c07\u5206\u6790\u9650\u5236\u5728\u5169\u500b\u6a21\u578b\u7684\u7814\u7a76\u4e0d\u540c\uff0c\u6211\u5011\u7684\u7814\u7a76\u64f4\u5927\u4e86\u7bc4\u570d\uff0c\u8a55\u4f30\u4e86\u5404\u7a2e\u6a21\u578b\u3002\u6211\u5011\u63a2\u8a0e\u4e86\u50b3\u7d71\u5206\u985e\u5668\uff08\u4f8b\u5982\u6a38\u7d20\u8c9d\u6c0f\u548c\u652f\u63f4\u5411\u91cf\u6a5f (SVM)\uff09\u7684\u6548\u80fd\uff0c\u4ee5\u53ca\u5305\u62ec BERT\u3001RoBERTa \u548c GPT \u5728\u5167\u7684\u6700\u65b0Transformer\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u8a55\u4f30\u6a19\u6e96\u4e0d\u50c5\u9650\u65bc\u6e96\u78ba\u5ea6\uff0c\u9084\u5305\u62ec\u7d30\u5fae\u7684\u8a55\u4f30\uff0c\u4f8b\u5982\u57fa\u65bc\u60c5\u7dd2\u5206\u985e\u4e2d\u4e0d\u540c\u7c92\u5ea6\u5c64\u7d1a\u7684\u968e\u5c64\u5f0f\u5206\u985e\u3002\u6b64\u5916\uff0c\u9084\u7d0d\u5165\u4e86\u8a08\u7b97\u6548\u7387\u7b49\u8003\u91cf\uff0c\u4ee5\u63d0\u4f9b\u5168\u9762\u7684\u8a55\u4f30\u67b6\u69cb\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0cRoBERTa \u6a21\u578b\u59cb\u7d42\u512a\u65bc\u57fa\u6e96\u6a21\u578b\uff0c\u5728\u7d30\u7dfb\u7684\u60c5\u7dd2\u5206\u985e\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u66f4\u9ad8\u7684\u6e96\u78ba\u5ea6\u3002\u9019\u7a81\u986f\u4e86 RoBERTa \u6a21\u578b\u5728\u63d0\u5347\u60c5\u7dd2\u5206\u6790\u80fd\u529b\u65b9\u9762\u7684\u5de8\u5927\u6f5b\u529b\u548c\u91cd\u8981\u6027\u3002", "author": "Xiaoxia Zhang et.al.", "authors": "Xiaoxia Zhang, Xiuyuan Qi, Zixin Teng", "id": "2405.16810v2", "paper_url": "http://arxiv.org/abs/2405.16810v2", "repo": "null"}}