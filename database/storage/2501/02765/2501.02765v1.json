{"2501.02765": {"publish_time": "2025-01-06", "title": "Visual Large Language Models for Generalized and Specialized Applications", "paper_summary": "Visual-language models (VLM) have emerged as a powerful tool for learning a\nunified embedding space for vision and language. Inspired by large language\nmodels, which have demonstrated strong reasoning and multi-task capabilities,\nvisual large language models (VLLMs) are gaining increasing attention for\nbuilding general-purpose VLMs. Despite the significant progress made in VLLMs,\nthe related literature remains limited, particularly from a comprehensive\napplication perspective, encompassing generalized and specialized applications\nacross vision (image, video, depth), action, and language modalities. In this\nsurvey, we focus on the diverse applications of VLLMs, examining their using\nscenarios, identifying ethics consideration and challenges, and discussing\nfuture directions for their development. By synthesizing these contents, we aim\nto provide a comprehensive guide that will pave the way for future innovations\nand broader applications of VLLMs. The paper list repository is available:\nhttps://github.com/JackYFL/awesome-VLLMs.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5df2\u6210\u70ba\u5b78\u7fd2\u8996\u89ba\u548c\u8a9e\u8a00\u7d71\u4e00\u5d4c\u5165\u7a7a\u9593\u7684\u5f37\u5927\u5de5\u5177\u3002\u53d7\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u555f\u767c\uff0c\u9019\u4e9b\u6a21\u578b\u5df2\u5c55\u73fe\u51fa\u5f37\u5927\u7684\u63a8\u7406\u548c\u591a\u4efb\u52d9\u80fd\u529b\uff0c\u8996\u89ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b (VLLM) \u6b63\u8d8a\u4f86\u8d8a\u53d7\u5230\u95dc\u6ce8\uff0c\u7528\u65bc\u5efa\u69cb\u901a\u7528 VLM\u3002\u5118\u7ba1 VLLM \u5df2\u53d6\u5f97\u986f\u8457\u9032\u5c55\uff0c\u4f46\u76f8\u95dc\u6587\u737b\u4ecd\u7136\u6709\u9650\uff0c\u7279\u5225\u662f\u5f9e\u5168\u9762\u7684\u61c9\u7528\u89c0\u9ede\u4f86\u770b\uff0c\u6db5\u84cb\u8996\u89ba\uff08\u5f71\u50cf\u3001\u5f71\u7247\u3001\u6df1\u5ea6\uff09\u3001\u52d5\u4f5c\u548c\u8a9e\u8a00\u6a21\u5f0f\u7684\u5ee3\u7fa9\u548c\u5c08\u9580\u61c9\u7528\u3002\u5728\u9019\u9805\u8abf\u67e5\u4e2d\uff0c\u6211\u5011\u5c08\u6ce8\u65bc VLLM \u7684\u591a\u6a23\u5316\u61c9\u7528\uff0c\u63a2\u8a0e\u5b83\u5011\u7684\u4f7f\u7528\u60c5\u5883\u3001\u627e\u51fa\u9053\u5fb7\u8003\u91cf\u548c\u6311\u6230\uff0c\u4e26\u8a0e\u8ad6\u5b83\u5011\u672a\u4f86\u7684\u767c\u5c55\u65b9\u5411\u3002\u900f\u904e\u7d9c\u5408\u9019\u4e9b\u5167\u5bb9\uff0c\u6211\u5011\u65e8\u5728\u63d0\u4f9b\u4e00\u4efd\u5168\u9762\u7684\u6307\u5357\uff0c\u70ba VLLM \u672a\u4f86\u7684\u5275\u65b0\u548c\u66f4\u5ee3\u6cdb\u7684\u61c9\u7528\u92ea\u8def\u3002\u8ad6\u6587\u6e05\u55ae\u5132\u5b58\u5eab\u5df2\u63d0\u4f9b\uff1ahttps://github.com/JackYFL/awesome-VLLMs\u3002", "author": "Yifan Li et.al.", "authors": "Yifan Li, Zhixin Lai, Wentao Bao, Zhen Tan, Anh Dao, Kewei Sui, Jiayi Shen, Dong Liu, Huan Liu, Yu Kong", "id": "2501.02765v1", "paper_url": "http://arxiv.org/abs/2501.02765v1", "repo": "https://github.com/jackyfl/awesome-vllms"}}