{"2411.08534": {"publish_time": "2024-11-13", "title": "Neural Topic Modeling with Large Language Models in the Loop", "paper_summary": "Topic modeling is a fundamental task in natural language processing, allowing\nthe discovery of latent thematic structures in text corpora. While Large\nLanguage Models (LLMs) have demonstrated promising capabilities in topic\ndiscovery, their direct application to topic modeling suffers from issues such\nas incomplete topic coverage, misalignment of topics, and inefficiency. To\naddress these limitations, we propose LLM-ITL, a novel LLM-in-the-loop\nframework that integrates LLMs with many existing Neural Topic Models (NTMs).\nIn LLM-ITL, global topics and document representations are learned through the\nNTM, while an LLM refines the topics via a confidence-weighted Optimal\nTransport (OT)-based alignment objective. This process enhances the\ninterpretability and coherence of the learned topics, while maintaining the\nefficiency of NTMs. Extensive experiments demonstrate that LLM-ITL can help\nNTMs significantly improve their topic interpretability while maintaining the\nquality of document representation.", "paper_summary_zh": "\u4e3b\u984c\u6a21\u578b\u5efa\u7acb\u662f\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4e2d\u7684\u4e00\u9805\u57fa\u672c\u4efb\u52d9\uff0c\u5141\u8a31\u5728\u6587\u672c\u8a9e\u6599\u5eab\u4e2d\u767c\u73fe\u6f5b\u5728\u7684\u4e3b\u984c\u7d50\u69cb\u3002\u96d6\u7136\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u4e3b\u984c\u767c\u73fe\u65b9\u9762\u5c55\u73fe\u51fa\u6709\u524d\u9014\u7684\u80fd\u529b\uff0c\u4f46\u5c07\u5176\u76f4\u63a5\u61c9\u7528\u65bc\u4e3b\u984c\u6a21\u578b\u6703\u7522\u751f\u4e0d\u5b8c\u6574\u7684\u4e3b\u984c\u6db5\u84cb\u7bc4\u570d\u3001\u4e3b\u984c\u932f\u4f4d\u548c\u6548\u7387\u4f4e\u843d\u7b49\u554f\u984c\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86 LLM-ITL\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7684 LLM \u5faa\u74b0\u67b6\u69cb\uff0c\u5c07 LLM \u8207\u8a31\u591a\u73fe\u6709\u7684\u795e\u7d93\u4e3b\u984c\u6a21\u578b (NTM) \u6574\u5408\u5728\u4e00\u8d77\u3002\u5728 LLM-ITL \u4e2d\uff0c\u900f\u904e NTM \u5b78\u7fd2\u5168\u5c40\u4e3b\u984c\u548c\u6587\u4ef6\u8868\u793a\uff0c\u800c LLM \u5247\u900f\u904e\u57fa\u65bc\u4fe1\u5fc3\u52a0\u6b0a\u7684\u6700\u9069\u50b3\u8f38 (OT) \u5c0d\u9f4a\u76ee\u6a19\u4f86\u512a\u5316\u9019\u4e9b\u4e3b\u984c\u3002\u6b64\u7a0b\u5e8f\u589e\u5f37\u4e86\u5b78\u7fd2\u4e3b\u984c\u7684\u53ef\u89e3\u91cb\u6027\u548c\u4e00\u81f4\u6027\uff0c\u540c\u6642\u7dad\u6301\u4e86 NTM \u7684\u6548\u7387\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0cLLM-ITL \u53ef\u4ee5\u5e6b\u52a9 NTM \u5927\u5e45\u63d0\u5347\u5176\u4e3b\u984c\u53ef\u89e3\u91cb\u6027\uff0c\u540c\u6642\u7dad\u6301\u6587\u4ef6\u8868\u793a\u7684\u54c1\u8cea\u3002", "author": "Xiaohao Yang et.al.", "authors": "Xiaohao Yang, He Zhao, Weijie Xu, Yuanyuan Qi, Jueqing Lu, Dinh Phung, Lan Du", "id": "2411.08534v1", "paper_url": "http://arxiv.org/abs/2411.08534v1", "repo": "null"}}