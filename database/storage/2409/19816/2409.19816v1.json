{"2409.19816": {"publish_time": "2024-09-29", "title": "Grounded Curriculum Learning", "paper_summary": "The high cost of real-world data for robotics Reinforcement Learning (RL)\nleads to the wide usage of simulators. Despite extensive work on building\nbetter dynamics models for simulators to match with the real world, there is\nanother, often-overlooked mismatch between simulations and the real world,\nnamely the distribution of available training tasks. Such a mismatch is further\nexacerbated by existing curriculum learning techniques, which automatically\nvary the simulation task distribution without considering its relevance to the\nreal world. Considering these challenges, we posit that curriculum learning for\nrobotics RL needs to be grounded in real-world task distributions. To this end,\nwe propose Grounded Curriculum Learning (GCL), which aligns the simulated task\ndistribution in the curriculum with the real world, as well as explicitly\nconsiders what tasks have been given to the robot and how the robot has\nperformed in the past. We validate GCL using the BARN dataset on complex\nnavigation tasks, achieving a 6.8% and 6.5% higher success rate compared to a\nstate-of-the-art CL method and a curriculum designed by human experts,\nrespectively. These results show that GCL can enhance learning efficiency and\nnavigation performance by grounding the simulation task distribution in the\nreal world within an adaptive curriculum.", "paper_summary_zh": "\u6a5f\u5668\u4eba\u5f37\u5316\u5b78\u7fd2 (RL) \u4e2d\u771f\u5be6\u4e16\u754c\u6578\u64da\u7684\u9ad8\u6602\u6210\u672c\u5c0e\u81f4\u5ee3\u6cdb\u4f7f\u7528\u6a21\u64ec\u5668\u3002\u5118\u7ba1\u5728\u5efa\u7acb\u66f4\u597d\u7684\u52d5\u614b\u6a21\u578b\u4ee5\u4f7f\u6a21\u64ec\u5668\u8207\u771f\u5be6\u4e16\u754c\u76f8\u5339\u914d\u65b9\u9762\u505a\u4e86\u5927\u91cf\u5de5\u4f5c\uff0c\u4f46\u6a21\u64ec\u8207\u771f\u5be6\u4e16\u754c\u4e4b\u9593\u9084\u5b58\u5728\u53e6\u4e00\u500b\u7d93\u5e38\u88ab\u5ffd\u8996\u7684\u4e0d\u5339\u914d\uff0c\u5373\u53ef\u7528\u8a13\u7df4\u4efb\u52d9\u7684\u5206\u5e03\u3002\u73fe\u6709\u7684\u8ab2\u7a0b\u5b78\u7fd2\u6280\u8853\u9032\u4e00\u6b65\u52a0\u5287\u4e86\u9019\u7a2e\u4e0d\u5339\u914d\uff0c\u9019\u4e9b\u6280\u8853\u6703\u81ea\u52d5\u6539\u8b8a\u6a21\u64ec\u4efb\u52d9\u5206\u4f48\uff0c\u800c\u4e0d\u6703\u8003\u616e\u5176\u8207\u771f\u5be6\u4e16\u754c\u7684\u76f8\u95dc\u6027\u3002\u8003\u616e\u5230\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5047\u8a2d\u6a5f\u5668\u4eba RL \u7684\u8ab2\u7a0b\u5b78\u7fd2\u9700\u8981\u4ee5\u771f\u5be6\u4e16\u754c\u7684\u4efb\u52d9\u5206\u4f48\u70ba\u57fa\u790e\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u57fa\u65bc\u771f\u5be6\u4e16\u754c\u7684\u8ab2\u7a0b\u5b78\u7fd2 (GCL)\uff0c\u5b83\u5c07\u8ab2\u7a0b\u4e2d\u7684\u6a21\u64ec\u4efb\u52d9\u5206\u4f48\u8207\u771f\u5be6\u4e16\u754c\u4fdd\u6301\u4e00\u81f4\uff0c\u4e26\u660e\u78ba\u8003\u616e\u4e86\u6a5f\u5668\u4eba\u5df2\u7372\u5f97\u54ea\u4e9b\u4efb\u52d9\u4ee5\u53ca\u6a5f\u5668\u4eba\u5728\u904e\u53bb\u7684\u8868\u73fe\u3002\u6211\u5011\u4f7f\u7528 BARN \u8cc7\u6599\u96c6\u9a57\u8b49\u4e86 GCL \u5728\u8907\u96dc\u5c0e\u822a\u4efb\u52d9\u4e2d\uff0c\u8207\u6700\u5148\u9032\u7684 CL \u65b9\u6cd5\u548c\u7531\u4eba\u985e\u5c08\u5bb6\u8a2d\u8a08\u7684\u8ab2\u7a0b\u76f8\u6bd4\uff0c\u5206\u5225\u5be6\u73fe\u4e86 6.8% \u548c 6.5% \u7684\u66f4\u9ad8\u6210\u529f\u7387\u3002\u9019\u4e9b\u7d50\u679c\u8868\u660e\uff0cGCL \u80fd\u5920\u901a\u904e\u5728\u81ea\u9069\u61c9\u8ab2\u7a0b\u4e2d\u5c07\u6a21\u64ec\u4efb\u52d9\u5206\u4f48\u5efa\u7acb\u5728\u771f\u5be6\u4e16\u754c\u4e2d\u4f86\u63d0\u9ad8\u5b78\u7fd2\u6548\u7387\u548c\u5c0e\u822a\u6027\u80fd\u3002", "author": "Linji Wang et.al.", "authors": "Linji Wang, Zifan Xu, Peter Stone, Xuesu Xiao", "id": "2409.19816v1", "paper_url": "http://arxiv.org/abs/2409.19816v1", "repo": "null"}}