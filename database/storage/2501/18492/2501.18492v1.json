{"2501.18492": {"publish_time": "2025-01-30", "title": "GuardReasoner: Towards Reasoning-based LLM Safeguards", "paper_summary": "As LLMs increasingly impact safety-critical applications, ensuring their\nsafety using guardrails remains a key challenge. This paper proposes\nGuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to\nreason. Concretely, we first create the GuardReasonerTrain dataset, which\nconsists of 127K samples with 460K detailed reasoning steps. Then, we introduce\nreasoning SFT to unlock the reasoning capability of guard models. In addition,\nwe present hard sample DPO to further strengthen their reasoning ability. In\nthis manner, GuardReasoner achieves better performance, explainability, and\ngeneralizability. Extensive experiments and analyses on 13 benchmarks of 3\nguardrail tasks demonstrate its superiority. Remarkably, GuardReasoner 8B\nsurpasses GPT-4o+CoT by 5.74% and LLaMA Guard 3 8B by 20.84% F1 score on\naverage. We release the training data, code, and models with different scales\n(1B, 3B, 8B) of GuardReasoner : https://github.com/yueliu1999/GuardReasoner/.", "paper_summary_zh": "\u96a8\u8457 LLM \u5c0d\u5b89\u5168\u95dc\u9375\u61c9\u7528\u7a0b\u5f0f\u7684\u5f71\u97ff\u65e5\u76ca\u589e\u52a0\uff0c\u78ba\u4fdd\u5176\u5b89\u5168\u6027\u7684\u9632\u8b77\u63aa\u65bd\u4ecd\u7136\u662f\u4e00\u9805\u95dc\u9375\u6311\u6230\u3002\u672c\u6587\u63d0\u51fa GuardReasoner\uff0c\u4e00\u7a2e\u65b0\u7684 LLM \u4fdd\u969c\u63aa\u65bd\uff0c\u900f\u904e\u5f15\u5c0e\u9632\u8b77\u6a21\u578b\u5b78\u7fd2\u63a8\u7406\u3002\u5177\u9ad4\u800c\u8a00\uff0c\u6211\u5011\u9996\u5148\u5efa\u7acb GuardReasonerTrain \u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b 127K \u500b\u6a23\u672c\uff0c\u4e26\u6709 460K \u500b\u8a73\u7d30\u7684\u63a8\u7406\u6b65\u9a5f\u3002\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u5f15\u5165\u63a8\u7406 SFT \u4ee5\u89e3\u9396\u9632\u8b77\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u56f0\u96e3\u6a23\u672c DPO \u4ee5\u9032\u4e00\u6b65\u589e\u5f37\u5176\u63a8\u7406\u80fd\u529b\u3002\u900f\u904e\u9019\u7a2e\u65b9\u5f0f\uff0cGuardReasoner \u9054\u5230\u66f4\u597d\u7684\u6548\u80fd\u3001\u53ef\u89e3\u91cb\u6027\u548c\u6982\u62ec\u6027\u3002\u5728 3 \u500b\u9632\u8b77\u4efb\u52d9\u7684 13 \u500b\u57fa\u6e96\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u548c\u5206\u6790\u8b49\u660e\u4e86\u5b83\u7684\u512a\u8d8a\u6027\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cGuardReasoner 8B \u5728\u5e73\u5747 F1 \u5206\u6578\u4e0a\u5206\u5225\u6bd4 GPT-4o+CoT \u9ad8\u51fa 5.74%\uff0c\u6bd4 LLaMA Guard 3 8B \u9ad8\u51fa 20.84%\u3002\u6211\u5011\u767c\u5e03\u4e86\u4e0d\u540c\u898f\u6a21\uff081B\u30013B\u30018B\uff09\u7684 GuardReasoner \u8a13\u7df4\u8cc7\u6599\u3001\u7a0b\u5f0f\u78bc\u548c\u6a21\u578b\uff1ahttps://github.com/yueliu1999/GuardReasoner/\u3002", "author": "Yue Liu et.al.", "authors": "Yue Liu, Hongcheng Gao, Shengfang Zhai, Jun Xia, Tianyi Wu, Zhiwei Xue, Yulin Chen, Kenji Kawaguchi, Jiaheng Zhang, Bryan Hooi", "id": "2501.18492v1", "paper_url": "http://arxiv.org/abs/2501.18492v1", "repo": "null"}}