{"2407.13142": {"publish_time": "2024-07-18", "title": "A light-weight and efficient punctuation and word casing prediction model for on-device streaming ASR", "paper_summary": "Punctuation and word casing prediction are necessary for automatic speech\nrecognition (ASR). With the popularity of on-device end-to-end streaming ASR\nsystems, the on-device punctuation and word casing prediction become a\nnecessity while we found little discussion on this. With the emergence of\nTransformer, Transformer based models have been explored for this scenario.\nHowever, Transformer based models are too large for on-device ASR systems. In\nthis paper, we propose a light-weight and efficient model that jointly predicts\npunctuation and word casing in real time. The model is based on Convolutional\nNeural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM).\nExperimental results on the IWSLT2011 test set show that the proposed model\nobtains 9% relative improvement compared to the best of non-Transformer models\non overall F1-score. Compared to the representative of Transformer based\nmodels, the proposed model achieves comparable results to the representative\nmodel while being only one-fortieth its size and 2.5 times faster in terms of\ninference time. It is suitable for on-device streaming ASR systems. Our code is\npublicly available.", "paper_summary_zh": "\u6a19\u9ede\u7b26\u865f\u548c\u5b57\u8a5e\u5927\u5c0f\u5beb\u9810\u6e2c\u5c0d\u65bc\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u4f86\u8aaa\u662f\u5fc5\u8981\u7684\u3002\u96a8\u8457\u88dd\u7f6e\u4e0a\u7aef\u5c0d\u7aef\u4e32\u6d41 ASR \u7cfb\u7d71\u7684\u666e\u53ca\uff0c\u88dd\u7f6e\u4e0a\u6a19\u9ede\u7b26\u865f\u548c\u5b57\u8a5e\u5927\u5c0f\u5beb\u9810\u6e2c\u8b8a\u5f97\u5fc5\u8981\uff0c\u4f46\u6211\u5011\u767c\u73fe\u5f88\u5c11\u6709\u95dc\u65bc\u9019\u65b9\u9762\u7684\u8a0e\u8ad6\u3002\u96a8\u8457 Transformer \u7684\u51fa\u73fe\uff0c\u57fa\u65bc Transformer \u7684\u6a21\u578b\u5df2\u63a2\u7d22\u7528\u65bc\u6b64\u60c5\u5883\u3002\u7136\u800c\uff0c\u57fa\u65bc Transformer \u7684\u6a21\u578b\u5c0d\u65bc\u88dd\u7f6e\u4e0a ASR \u7cfb\u7d71\u4f86\u8aaa\u904e\u65bc\u9f90\u5927\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u8f15\u91cf\u4e14\u9ad8\u6548\u7684\u6a21\u578b\uff0c\u7528\u65bc\u5728\u5373\u6642\u9810\u6e2c\u6a19\u9ede\u7b26\u865f\u548c\u5b57\u8a5e\u5927\u5c0f\u5beb\u3002\u8a72\u6a21\u578b\u57fa\u65bc\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u548c\u96d9\u5411\u9577\u77ed\u671f\u8a18\u61b6 (BiLSTM)\u3002\u5728 IWSLT2011 \u6e2c\u8a66\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u8207\u975e Transformer \u6a21\u578b\u4e2d\u6700\u597d\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u6574\u9ad4 F1 \u5206\u6578\u4e0a\u7372\u5f97\u4e86 9% \u7684\u76f8\u5c0d\u6539\u9032\u3002\u8207\u57fa\u65bc Transformer \u7684\u6a21\u578b\u7684\u4ee3\u8868\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u50c5\u70ba\u5176\u5927\u5c0f\u7684\u56db\u5341\u5206\u4e4b\u4e00\u4e14\u63a8\u8ad6\u6642\u9593\u5feb 2.5 \u500d\u7684\u60c5\u6cc1\u4e0b\uff0c\u9054\u5230\u4e86\u8207\u4ee3\u8868\u6a21\u578b\u76f8\u7576\u7684\u7d50\u679c\u3002\u5b83\u9069\u7528\u65bc\u88dd\u7f6e\u4e0a\u4e32\u6d41 ASR \u7cfb\u7d71\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u3002", "author": "Jian You et.al.", "authors": "Jian You, Xiangfeng Li", "id": "2407.13142v1", "paper_url": "http://arxiv.org/abs/2407.13142v1", "repo": "null"}}