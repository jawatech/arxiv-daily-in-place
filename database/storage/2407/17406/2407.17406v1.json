{"2407.17406": {"publish_time": "2024-07-24", "title": "Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models", "paper_summary": "Syntactic Transformer language models aim to achieve better generalization\nthrough simultaneously modeling syntax trees and sentences. While prior work\nhas been focusing on adding constituency-based structures to Transformers, we\nintroduce Dependency Transformer Grammars (DTGs), a new class of Transformer\nlanguage model with explicit dependency-based inductive bias. DTGs simulate\ndependency transition systems with constrained attention patterns by modifying\nattention masks, incorporate the stack information through relative positional\nencoding, and augment dependency arc representation with a combination of token\nembeddings and operation embeddings. When trained on a dataset of sentences\nannotated with dependency trees, DTGs achieve better generalization while\nmaintaining comparable perplexity with Transformer language model baselines.\nDTGs also outperform recent constituency-based models, showing that dependency\ncan better guide Transformer language models. Our code is released at\nhttps://github.com/zhaoyd1/Dep_Transformer_Grammars.", "paper_summary_zh": "\u53e5\u6cd5\u8f49\u63db\u8a9e\u8a00\u6a21\u578b\u65e8\u5728\u900f\u904e\u540c\u6642\u5c0d\u53e5\u6cd5\u6a39\u548c\u53e5\u5b50\u9032\u884c\u5efa\u6a21\u4f86\u9054\u6210\u66f4\u597d\u7684\u6982\u62ec\u3002\u96d6\u7136\u5148\u524d\u7684\u7814\u7a76\u4e00\u76f4\u5c08\u6ce8\u65bc\u5728 Transformers \u4e2d\u52a0\u5165\u57fa\u65bc\u6210\u5206\u7684\u7d50\u69cb\uff0c\u4f46\u6211\u5011\u5f15\u5165\u4e86\u4f9d\u8cf4\u8f49\u63db\u8a9e\u6cd5 (DTG)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7684\u8f49\u63db\u8a9e\u8a00\u6a21\u578b\u985e\u5225\uff0c\u5177\u6709\u660e\u78ba\u7684\u57fa\u65bc\u4f9d\u8cf4\u7684\u6b78\u7d0d\u504f\u8aa4\u3002DTG \u6a21\u64ec\u5177\u6709\u7d04\u675f\u6ce8\u610f\u529b\u6a21\u5f0f\u7684\u4f9d\u8cf4\u8f49\u63db\u7cfb\u7d71\uff0c\u900f\u904e\u4fee\u6539\u6ce8\u610f\u529b\u906e\u7f69\u3001\u900f\u904e\u76f8\u5c0d\u4f4d\u7f6e\u7de8\u78bc\u7d0d\u5165\u5806\u758a\u8cc7\u8a0a\uff0c\u4e26\u7d50\u5408\u6a19\u8a18\u5d4c\u5165\u548c\u904b\u7b97\u5d4c\u5165\u4f86\u64f4\u5145\u4f9d\u8cf4\u5f27\u8868\u793a\u3002\u7576\u5728\u6a19\u8a18\u6709\u4f9d\u8cf4\u6a39\u7684\u53e5\u5b50\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u8a13\u7df4\u6642\uff0cDTG \u53ef\u5728\u7dad\u6301\u8207\u8f49\u63db\u8a9e\u8a00\u6a21\u578b\u57fa\u6e96\u76f8\u7576\u7684\u56f0\u60d1\u5ea6\u7684\u540c\u6642\uff0c\u9054\u6210\u66f4\u597d\u7684\u6982\u62ec\u3002DTG \u4e5f\u512a\u65bc\u6700\u8fd1\u57fa\u65bc\u6210\u5206\u7684\u6a21\u578b\uff0c\u986f\u793a\u4f9d\u8cf4\u53ef\u4ee5\u66f4\u597d\u5730\u5f15\u5c0e\u8f49\u63db\u8a9e\u8a00\u6a21\u578b\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u5728 https://github.com/zhaoyd1/Dep_Transformer_Grammars \u767c\u5e03\u3002", "author": "Yida Zhao et.al.", "authors": "Yida Zhao, Chao Lou, Kewei Tu", "id": "2407.17406v1", "paper_url": "http://arxiv.org/abs/2407.17406v1", "repo": "https://github.com/zhaoyd1/dep_transformer_grammars"}}