{"2407.04693": {"publish_time": "2024-07-05", "title": "ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models", "paper_summary": "Large language models (LLMs) exhibit hallucinations in long-form\nquestion-answering tasks across various domains and wide applications. Current\nhallucination detection and mitigation datasets are limited in domains and\nsizes, which struggle to scale due to prohibitive labor costs and insufficient\nreliability of existing hallucination annotators. To facilitate the scalable\noversight of LLM hallucinations, this paper introduces an iterative\nself-training framework that simultaneously and progressively scales up the\nhallucination annotation dataset and improves the accuracy of the hallucination\nannotator. Based on the Expectation Maximization (EM) algorithm, in each\niteration, the framework first applies a hallucination annotation pipeline to\nannotate a scaled dataset and then trains a more accurate hallucination\nannotator on the dataset. This new hallucination annotator is adopted in the\nhallucination annotation pipeline used for the next iteration. Extensive\nexperimental results demonstrate that the finally obtained hallucination\nannotator with only 7B parameters surpasses the performance of GPT-4 and\nobtains new state-of-the-art hallucination detection results on HaluEval and\nHalluQA by zero-shot inference. Such an annotator can not only evaluate the\nhallucination levels of various LLMs on the large-scale dataset but also help\nto mitigate the hallucination of LLMs generations, with the Natural Language\nInference (NLI) metric increasing from 25% to 37% on HaluEval.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u9818\u57df\u548c\u5ee3\u6cdb\u61c9\u7528\u4e2d\u8868\u73fe\u51fa\u9577\u7bc7\u554f\u7b54\u4efb\u52d9\u4e2d\u7684\u5e7b\u89ba\u3002\u7576\u524d\u7684\u5e7b\u89ba\u6aa2\u6e2c\u548c\u7de9\u89e3\u6578\u64da\u96c6\u5728\u9818\u57df\u548c\u898f\u6a21\u4e0a\u53d7\u5230\u9650\u5236\uff0c\u7531\u65bc\u9ad8\u6602\u7684\u4eba\u5de5\u6210\u672c\u548c\u73fe\u6709\u5e7b\u89ba\u8a3b\u89e3\u5668\u7684\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u56e0\u6b64\u96e3\u4ee5\u64f4\u5c55\u3002\u70ba\u4e86\u4fc3\u9032 LLM \u5e7b\u89ba\u7684\u53ef\u64f4\u5c55\u76e3\u7763\uff0c\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u500b\u8fed\u4ee3\u81ea\u8a13\u7df4\u6846\u67b6\uff0c\u8a72\u6846\u67b6\u540c\u6642\u4e14\u9010\u6b65\u64f4\u5c55\u5e7b\u89ba\u8a3b\u89e3\u6578\u64da\u96c6\u4e26\u63d0\u9ad8\u5e7b\u89ba\u8a3b\u89e3\u5668\u7684\u6e96\u78ba\u6027\u3002\u57fa\u65bc\u671f\u671b\u6700\u5927\u5316 (EM) \u6f14\u7b97\u6cd5\uff0c\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0c\u8a72\u6846\u67b6\u9996\u5148\u61c9\u7528\u5e7b\u89ba\u8a3b\u89e3\u7ba1\u9053\u4f86\u8a3b\u89e3\u4e00\u500b\u7e2e\u653e\u7684\u6578\u64da\u96c6\uff0c\u7136\u5f8c\u5728\u6578\u64da\u96c6\u4e0a\u8a13\u7df4\u4e00\u500b\u66f4\u6e96\u78ba\u7684\u5e7b\u89ba\u8a3b\u89e3\u5668\u3002\u9019\u500b\u65b0\u7684\u5e7b\u89ba\u8a3b\u89e3\u5668\u88ab\u63a1\u7528\u5728\u7528\u65bc\u4e0b\u4e00\u6b21\u8fed\u4ee3\u7684\u5e7b\u89ba\u8a3b\u89e3\u7ba1\u9053\u4e2d\u3002\u5927\u91cf\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6700\u7d42\u7372\u5f97\u7684\u5e7b\u89ba\u8a3b\u89e3\u5668\u53ea\u6709 7B \u53c3\u6578\uff0c\u5c31\u8d85\u904e\u4e86 GPT-4 \u7684\u6027\u80fd\uff0c\u4e26\u901a\u904e\u96f6\u6b21\u5b78\u7fd2\u63a8\u7406\u5728 HaluEval \u548c HalluQA \u4e0a\u7372\u5f97\u4e86\u65b0\u7684\u6700\u5148\u9032\u7684\u5e7b\u89ba\u6aa2\u6e2c\u7d50\u679c\u3002\u9019\u6a23\u7684\u8a3b\u89e3\u5668\u4e0d\u50c5\u53ef\u4ee5\u8a55\u4f30\u5404\u7a2e LLM \u5728\u5927\u578b\u6578\u64da\u96c6\u4e0a\u7684\u5e7b\u89ba\u7b49\u7d1a\uff0c\u9084\u53ef\u4ee5\u5e6b\u52a9\u6e1b\u8f15 LLM \u751f\u6210\u7684\u5e7b\u89ba\uff0c\u81ea\u7136\u8a9e\u8a00\u63a8\u7406 (NLI) \u6307\u6a19\u5f9e HaluEval \u4e0a\u7684 25% \u589e\u52a0\u5230 37%\u3002", "author": "Yuzhe Gu et.al.", "authors": "Yuzhe Gu, Ziwei Ji, Wenwei Zhang, Chengqi Lyu, Dahua Lin, Kai Chen", "id": "2407.04693v1", "paper_url": "http://arxiv.org/abs/2407.04693v1", "repo": "null"}}