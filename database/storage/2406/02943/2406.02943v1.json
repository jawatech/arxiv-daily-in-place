{"2406.02943": {"publish_time": "2024-06-05", "title": "The Task-oriented Queries Benchmark (ToQB)", "paper_summary": "Task-oriented queries (e.g., one-shot queries to play videos, order food, or\ncall a taxi) are crucial for assessing the quality of virtual assistants,\nchatbots, and other large language model (LLM)-based services. However, a\nstandard benchmark for task-oriented queries is not yet available, as existing\nbenchmarks in the relevant NLP (Natural Language Processing) fields have\nprimarily focused on task-oriented dialogues. Thus, we present a new\nmethodology for efficiently generating the Task-oriented Queries Benchmark\n(ToQB) using existing task-oriented dialogue datasets and an LLM service. Our\nmethodology involves formulating the underlying NLP task to summarize the\noriginal intent of a speaker in each dialogue, detailing the key steps to\nperform the devised NLP task using an LLM service, and outlining a framework\nfor automating a major part of the benchmark generation process. Through a case\nstudy encompassing three domains (i.e., two single-task domains and one\nmulti-task domain), we demonstrate how to customize the LLM prompts (e.g.,\nomitting system utterances or speaker labels) for those three domains and\ncharacterize the generated task-oriented queries. The generated ToQB dataset is\nmade available to the public. We further discuss new domains that can be added\nto ToQB by community contributors and its practical applications.", "paper_summary_zh": "\u4ee5\u4efb\u52d9\u70ba\u5c0e\u5411\u7684\u67e5\u8a62\uff08\u4f8b\u5982\uff0c\u64ad\u653e\u5f71\u7247\u3001\u8a02\u8cfc\u98df\u7269\u6216\u53eb\u8a08\u7a0b\u8eca\u7684\u4e00\u6b21\u6027\u67e5\u8a62\uff09\u5c0d\u65bc\u8a55\u4f30\u865b\u64ec\u52a9\u7406\u3001\u804a\u5929\u6a5f\u5668\u4eba\u548c\u5176\u4ed6\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u670d\u52d9\u7684\u54c1\u8cea\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u9084\u6c92\u6709\u4ee5\u4efb\u52d9\u70ba\u5c0e\u5411\u7684\u67e5\u8a62\u7684\u6a19\u6e96\u57fa\u6e96\uff0c\u56e0\u70ba\u76f8\u95dc\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u9818\u57df\u73fe\u6709\u7684\u57fa\u6e96\u4e3b\u8981\u96c6\u4e2d\u5728\u4ee5\u4efb\u52d9\u70ba\u5c0e\u5411\u7684\u5c0d\u8a71\u4e0a\u3002\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u73fe\u6709\u7684\u4ee5\u4efb\u52d9\u70ba\u5c0e\u5411\u7684\u5c0d\u8a71\u8cc7\u6599\u96c6\u548c LLM \u670d\u52d9\uff0c\u6709\u6548\u7522\u751f\u4ee5\u4efb\u52d9\u70ba\u5c0e\u5411\u7684\u67e5\u8a62\u57fa\u6e96 (ToQB)\u3002\u6211\u5011\u7684\u505a\u6cd5\u5305\u62ec\u5236\u5b9a\u57fa\u790e\u7684 NLP \u4efb\u52d9\uff0c\u4ee5\u7e3d\u7d50\u6bcf\u500b\u5c0d\u8a71\u4e2d\u8aaa\u8a71\u8005\u7684\u539f\u59cb\u610f\u5716\uff0c\u8a73\u7d30\u8aaa\u660e\u4f7f\u7528 LLM \u670d\u52d9\u57f7\u884c\u6240\u8a2d\u8a08 NLP \u4efb\u52d9\u7684\u4e3b\u8981\u6b65\u9a5f\uff0c\u4e26\u6982\u8ff0\u81ea\u52d5\u5316\u57fa\u6e96\u7522\u751f\u6d41\u7a0b\u5927\u90e8\u5206\u7684\u67b6\u69cb\u3002\u900f\u904e\u4e00\u500b\u6db5\u84cb\u4e09\u500b\u7db2\u57df\uff08\u5373\u5169\u500b\u55ae\u4e00\u4efb\u52d9\u7db2\u57df\u548c\u4e00\u500b\u591a\u4efb\u52d9\u7db2\u57df\uff09\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u6211\u5011\u793a\u7bc4\u5982\u4f55\u81ea\u8a02 LLM \u63d0\u793a\uff08\u4f8b\u5982\uff0c\u7701\u7565\u7cfb\u7d71\u767c\u8a00\u6216\u8aaa\u8a71\u8005\u6a19\u7c64\uff09\u4ee5\u7b26\u5408\u9019\u4e09\u500b\u7db2\u57df\uff0c\u4e26\u63cf\u8ff0\u7522\u751f\u7684\u4ee5\u4efb\u52d9\u70ba\u5c0e\u5411\u7684\u67e5\u8a62\u3002\u7522\u751f\u7684 ToQB \u8cc7\u6599\u96c6\u5df2\u516c\u958b\u63d0\u4f9b\u3002\u6211\u5011\u9032\u4e00\u6b65\u8a0e\u8ad6\u793e\u5340\u8ca2\u737b\u8005\u53ef\u4ee5\u65b0\u589e\u5230 ToQB \u7684\u65b0\u7db2\u57df\uff0c\u4ee5\u53ca\u5176\u5be6\u969b\u61c9\u7528\u3002", "author": "Keun Soo Yim et.al.", "authors": "Keun Soo Yim", "id": "2406.02943v1", "paper_url": "http://arxiv.org/abs/2406.02943v1", "repo": "null"}}