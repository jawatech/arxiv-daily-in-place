{"2410.19353": {"publish_time": "2024-10-25", "title": "Interleaving Text and Number Embeddings to Solve Mathemathics Problems", "paper_summary": "Integrating text and numbers effectively is a crucial step towards enhancing\nLarge Language Models (LLMs) capabilities in assisting in scientific tasks.\nWhile most current approaches rely on discrete tokenization of numbers, for\ninstance, conversion to scientific notation or base 10-decomposition, a recent\napproach proposed a continuous numerical encoding as an inductive bias. In this\npaper, we build upon this approach by introducing more expressive numerical\nembeddings. Our method addresses key shortcomings, including the elimination of\nnumerical artefacts and the ability to handle a wide range of magnitudes\nwithout clipping.\n  Our work presents two key contributions. First, we employ an MLP to assign\ndistinct directions in the embedding space to different numbers. Our second\ncontribution is the introduction of a routing layer that differentiates between\nnumerical and text embeddings. We hypothesise that this combined approach\nenables the model to distinguish between text and number distributions while\nmaintaining its capacity for arithmetic operations.\n  Using only a 45 M parameter encoder-decoder architecture our method achieves\na $R^2$=0.9988 over a wide range of magnitude ($10^{-3},10^{8}$). In addition,\nwe empirically observe a reduction of the numerical artefacts and biases\nobserved compared to the baselines.", "paper_summary_zh": "\u6709\u6548\u6574\u5408\u6587\u5b57\u548c\u6578\u5b57\u662f\u63d0\u5347\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u79d1\u5b78\u4efb\u52d9\u4e2d\u63d0\u4f9b\u5354\u52a9\u7684\u80fd\u529b\u7684\u95dc\u9375\u6b65\u9a5f\u3002\u96d6\u7136\u76ee\u524d\u5927\u591a\u6578\u65b9\u6cd5\u4f9d\u8cf4\u6578\u5b57\u7684\u96e2\u6563\u5316\u6a19\u8a18\uff0c\u4f8b\u5982\u8f49\u63db\u70ba\u79d1\u5b78\u8a18\u865f\u6216 10 \u9032\u4f4d\u5206\u89e3\uff0c\u4f46\u6700\u8fd1\u7684\u65b9\u6cd5\u63d0\u51fa\u9023\u7e8c\u6578\u503c\u7de8\u78bc\u4f5c\u70ba\u6b78\u7d0d\u504f\u5dee\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5f15\u5165\u66f4\u5177\u8868\u9054\u529b\u7684\u6578\u503c\u5d4c\u5165\uff0c\u5efa\u7acb\u5728\u9019\u500b\u65b9\u6cd5\u4e4b\u4e0a\u3002\u6211\u5011\u7684\u505a\u6cd5\u89e3\u6c7a\u4e86\u95dc\u9375\u7f3a\u9ede\uff0c\u5305\u62ec\u6d88\u9664\u6578\u503c\u4eba\u5de5\u88fd\u54c1\uff0c\u4ee5\u53ca\u5728\u4e0d\u526a\u88c1\u7684\u60c5\u6cc1\u4e0b\u8655\u7406\u5ee3\u6cdb\u7684\u6578\u91cf\u7d1a\u7684\u80fd\u529b\u3002\n\u6211\u5011\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u5169\u500b\u95dc\u9375\u8ca2\u737b\u3002\u9996\u5148\uff0c\u6211\u5011\u63a1\u7528 MLP\uff0c\u5728\u5d4c\u5165\u7a7a\u9593\u4e2d\u70ba\u4e0d\u540c\u7684\u6578\u5b57\u6307\u5b9a\u4e0d\u540c\u7684\u65b9\u5411\u3002\u6211\u5011\u7684\u7b2c\u4e8c\u500b\u8ca2\u737b\u662f\u5f15\u5165\u4e00\u500b\u8def\u7531\u5c64\uff0c\u5340\u5206\u6578\u503c\u548c\u6587\u5b57\u5d4c\u5165\u3002\u6211\u5011\u5047\u8a2d\u9019\u7a2e\u7d44\u5408\u65b9\u6cd5\u4f7f\u6a21\u578b\u80fd\u5920\u5340\u5206\u6587\u5b57\u548c\u6578\u5b57\u5206\u4f48\uff0c\u540c\u6642\u4fdd\u6301\u5176\u57f7\u884c\u7b97\u8853\u904b\u7b97\u7684\u80fd\u529b\u3002\n\u50c5\u4f7f\u7528 45M \u53c3\u6578\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u67b6\u69cb\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5728\u5ee3\u6cdb\u7684\u6578\u91cf\u7d1a ($10^{-3},10^{8}$) \u4e0a\u9054\u5230\u4e86 $R^2$=0.9988\u3002\u6b64\u5916\uff0c\u6211\u5011\u6839\u64da\u7d93\u9a57\u89c0\u5bdf\u5230\u8207\u57fa\u6e96\u76f8\u6bd4\uff0c\u6578\u503c\u4eba\u5de5\u88fd\u54c1\u548c\u504f\u5dee\u6709\u6240\u6e1b\u5c11\u3002", "author": "Marvin Alberts et.al.", "authors": "Marvin Alberts, Gianmarco Gabrieli, Irina Espejo Morales", "id": "2410.19353v1", "paper_url": "http://arxiv.org/abs/2410.19353v1", "repo": "null"}}