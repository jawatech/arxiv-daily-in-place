{"2412.20816": {"publish_time": "2024-12-30", "title": "Length-Aware DETR for Robust Moment Retrieval", "paper_summary": "Video Moment Retrieval (MR) aims to localize moments within a video based on\na given natural language query. Given the prevalent use of platforms like\nYouTube for information retrieval, the demand for MR techniques is\nsignificantly growing. Recent DETR-based models have made notable advances in\nperformance but still struggle with accurately localizing short moments.\nThrough data analysis, we identified limited feature diversity in short\nmoments, which motivated the development of MomentMix. MomentMix employs two\naugmentation strategies: ForegroundMix and BackgroundMix, each enhancing the\nfeature representations of the foreground and background, respectively.\nAdditionally, our analysis of prediction bias revealed that short moments\nparticularly struggle with accurately predicting their center positions of\nmoments. To address this, we propose a Length-Aware Decoder, which conditions\nlength through a novel bipartite matching process. Our extensive studies\ndemonstrate the efficacy of our length-aware approach, especially in localizing\nshort moments, leading to improved overall performance. Our method surpasses\nstate-of-the-art DETR-based methods on benchmark datasets, achieving the\nhighest R1 and mAP on QVHighlights and the highest R1@0.7 on TACoS and\nCharades-STA (such as a 2.46% gain in R1@0.7 and a 2.57% gain in mAP average\nfor QVHighlights). The code is available at\nhttps://github.com/sjpark5800/LA-DETR.", "paper_summary_zh": "\u5f71\u7247\u7247\u6bb5\u6aa2\u7d22 (MR) \u65e8\u5728\u6839\u64da\u7d66\u5b9a\u7684\u81ea\u7136\u8a9e\u8a00\u67e5\u8a62\uff0c\u5728\u5f71\u7247\u4e2d\u627e\u51fa\u7247\u6bb5\u3002\u7531\u65bc YouTube \u7b49\u5e73\u53f0\u666e\u904d\u7528\u65bc\u8cc7\u8a0a\u6aa2\u7d22\uff0c\u5c0d MR \u6280\u8853\u7684\u9700\u6c42\u5927\u5e45\u589e\u52a0\u3002\u6700\u8fd1\u57fa\u65bc DETR \u7684\u6a21\u578b\u5728\u6548\u80fd\u65b9\u9762\u6709\u986f\u8457\u9032\u6b65\uff0c\u4f46\u4ecd\u96e3\u4ee5\u6e96\u78ba\u627e\u51fa\u77ed\u7247\u6bb5\u3002\u900f\u904e\u8cc7\u6599\u5206\u6790\uff0c\u6211\u5011\u767c\u73fe\u77ed\u7247\u6bb5\u4e2d\u7684\u7279\u5fb5\u591a\u6a23\u6027\u6709\u9650\uff0c\u9019\u4fc3\u6210\u4e86 MomentMix \u7684\u958b\u767c\u3002MomentMix \u63a1\u7528\u5169\u7a2e\u64f4\u589e\u7b56\u7565\uff1a\u524d\u666f\u6df7\u5408\u548c\u80cc\u666f\u6df7\u5408\uff0c\u5206\u5225\u589e\u5f37\u524d\u666f\u548c\u80cc\u666f\u7684\u7279\u5fb5\u8868\u793a\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c0d\u9810\u6e2c\u504f\u5dee\u7684\u5206\u6790\u986f\u793a\uff0c\u77ed\u7247\u6bb5\u7279\u5225\u96e3\u4ee5\u6e96\u78ba\u9810\u6e2c\u5176\u7247\u6bb5\u4e2d\u5fc3\u4f4d\u7f6e\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u9577\u5ea6\u611f\u77e5\u89e3\u78bc\u5668\uff0c\u900f\u904e\u65b0\u7a4e\u7684\u4e8c\u90e8\u5339\u914d\u7a0b\u5e8f\u4f86\u8a2d\u5b9a\u9577\u5ea6\u3002\u6211\u5011\u5ee3\u6cdb\u7684\u7814\u7a76\u8b49\u660e\u4e86\u6211\u5011\u9577\u5ea6\u611f\u77e5\u65b9\u6cd5\u7684\u6548\u529b\uff0c\u7279\u5225\u662f\u5728\u627e\u51fa\u77ed\u7247\u6bb5\u6642\uff0c\u9032\u800c\u6539\u5584\u6574\u9ad4\u6548\u80fd\u3002\u6211\u5011\u7684\u6a21\u578b\u5728\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u8d85\u8d8a\u4e86\u6700\u5148\u9032\u7684\u57fa\u65bc DETR \u7684\u65b9\u6cd5\uff0c\u5728 QVHighlights \u4e0a\u9054\u5230\u4e86\u6700\u9ad8\u7684 R1 \u548c mAP\uff0c\u5728 TACoS \u548c Charades-STA \u4e0a\u9054\u5230\u4e86\u6700\u9ad8\u7684 R1@0.7\uff08\u4f8b\u5982\u5728 QVHighlights \u4e0a R1@0.7 \u63d0\u5347\u4e86 2.46%\uff0cmAP \u5e73\u5747\u63d0\u5347\u4e86 2.57%\uff09\u3002\u7a0b\u5f0f\u78bc\u53ef\u65bc https://github.com/sjpark5800/LA-DETR \u53d6\u5f97\u3002", "author": "Seojeong Park et.al.", "authors": "Seojeong Park, Jiho Choi, Kyungjune Baek, Hyunjung Shim", "id": "2412.20816v1", "paper_url": "http://arxiv.org/abs/2412.20816v1", "repo": "null"}}