{"2405.13902": {"publish_time": "2024-05-22", "title": "LOGIN: A Large Language Model Consulted Graph Neural Network Training Framework", "paper_summary": "Recent prevailing works on graph machine learning typically follow a similar\nmethodology that involves designing advanced variants of graph neural networks\n(GNNs) to maintain the superior performance of GNNs on different graphs. In\nthis paper, we aim to streamline the GNN design process and leverage the\nadvantages of Large Language Models (LLMs) to improve the performance of GNNs\non downstream tasks. We formulate a new paradigm, coined \"LLMs-as-Consultants,\"\nwhich integrates LLMs with GNNs in an interactive manner. A framework named\nLOGIN (LLM Consulted GNN training) is instantiated, empowering the interactive\nutilization of LLMs within the GNN training process. First, we attentively\ncraft concise prompts for spotted nodes, carrying comprehensive semantic and\ntopological information, and serving as input to LLMs. Second, we refine GNNs\nby devising a complementary coping mechanism that utilizes the responses from\nLLMs, depending on their correctness. We empirically evaluate the effectiveness\nof LOGIN on node classification tasks across both homophilic and heterophilic\ngraphs. The results illustrate that even basic GNN architectures, when employed\nwithin the proposed LLMs-as-Consultants paradigm, can achieve comparable\nperformance to advanced GNNs with intricate designs. Our codes are available at\nhttps://github.com/QiaoYRan/LOGIN.", "paper_summary_zh": "\u8fd1\u671f\u4e3b\u6d41\u7684\u5716\u5f62\u6a5f\u5668\u5b78\u7fd2\u7814\u7a76\u901a\u5e38\u9075\u5faa\u985e\u4f3c\u7684\u65b9\u6cd5\uff0c\u5373\u8a2d\u8a08\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u7684\u9032\u968e\u8b8a\u9ad4\uff0c\u4ee5\u5728\u4e0d\u540c\u5716\u5f62\u4e0a\u7dad\u6301 GNN \u7684\u512a\u7570\u6548\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u65e8\u5728\u7c21\u5316 GNN \u8a2d\u8a08\u6d41\u7a0b\uff0c\u4e26\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u512a\u52e2\u4f86\u63d0\u5347 GNN \u5728\u4e0b\u6e38\u4efb\u52d9\u7684\u6548\u80fd\u3002\u6211\u5011\u5236\u5b9a\u4e86\u4e00\u500b\u65b0\u7684\u7bc4\u4f8b\uff0c\u7a31\u70ba\u300cLLM \u4f5c\u70ba\u9867\u554f\u300d\uff0c\u5b83\u4ee5\u4e92\u52d5\u7684\u65b9\u5f0f\u5c07 LLM \u8207 GNN \u6574\u5408\u5728\u4e00\u8d77\u3002\u6211\u5011\u5be6\u4f8b\u5316\u4e86\u4e00\u500b\u540d\u70ba LOGIN\uff08LLM \u8aee\u8a62 GNN \u8a13\u7df4\uff09\u7684\u67b6\u69cb\uff0c\u8b93 LLM \u80fd\u5728 GNN \u8a13\u7df4\u904e\u7a0b\u4e2d\u4e92\u52d5\u5f0f\u5730\u88ab\u4f7f\u7528\u3002\u9996\u5148\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u70ba\u767c\u73fe\u7684\u7bc0\u9ede\u7cbe\u5fc3\u88fd\u4f5c\u7c21\u6f54\u7684\u63d0\u793a\uff0c\u5305\u542b\u5168\u9762\u7684\u8a9e\u7fa9\u548c\u62d3\u64b2\u8cc7\u8a0a\uff0c\u4e26\u4f5c\u70ba LLM \u7684\u8f38\u5165\u3002\u5176\u6b21\uff0c\u6211\u5011\u900f\u904e\u8a2d\u8a08\u4e00\u7a2e\u88dc\u5145\u6027\u7684\u61c9\u5c0d\u6a5f\u5236\u4f86\u6539\u5584 GNN\uff0c\u8a72\u6a5f\u5236\u6703\u6839\u64da LLM \u56de\u61c9\u7684\u6b63\u78ba\u6027\u4f86\u4f7f\u7528\u9019\u4e9b\u56de\u61c9\u3002\u6211\u5011\u6839\u64da\u540c\u8cea\u6027\u548c\u7570\u8cea\u6027\u5716\u5f62\u4e0a\u7684\u7bc0\u9ede\u5206\u985e\u4efb\u52d9\uff0c\u5be6\u8b49\u8a55\u4f30\u4e86 LOGIN \u7684\u6709\u6548\u6027\u3002\u7d50\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u63d0\u8b70\u7684 LLM \u4f5c\u70ba\u9867\u554f\u7bc4\u4f8b\u4e2d\u4f7f\u7528\u57fa\u672c\u7684 GNN \u67b6\u69cb\uff0c\u4e5f\u80fd\u9054\u5230\u8207\u8a2d\u8a08\u8907\u96dc\u7684\u9032\u968e GNN \u76f8\u7576\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/QiaoYRan/LOGIN \u53d6\u5f97\u3002", "author": "Yiran Qiao et.al.", "authors": "Yiran Qiao, Xiang Ao, Yang Liu, Jiarong Xu, Xiaoqian Sun, Qing He", "id": "2405.13902v2", "paper_url": "http://arxiv.org/abs/2405.13902v2", "repo": "https://github.com/qiaoyran/login"}}