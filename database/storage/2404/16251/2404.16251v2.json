{"2404.16251": {"publish_time": "2024-04-24", "title": "Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions", "paper_summary": "Prompt leakage in large language models (LLMs) poses a significant security\nand privacy threat, particularly in retrieval-augmented generation (RAG)\nsystems. However, leakage in multi-turn LLM interactions along with mitigation\nstrategies has not been studied in a standardized manner. This paper\ninvestigates LLM vulnerabilities against prompt leakage across 4 diverse\ndomains and 10 closed- and open-source LLMs. Our unique multi-turn threat model\nleverages the LLM's sycophancy effect and our analysis dissects task\ninstruction and knowledge leakage in the LLM response. In a multi-turn setting,\nour threat model elevates the average attack success rate (ASR) to 86.2%,\nincluding a 99% leakage with GPT-4 and claude-1.3. We find that some black-box\nLLMs like Gemini show variable susceptibility to leakage across domains - they\nare more likely to leak contextual knowledge in the news domain compared to the\nmedical domain. Our experiments measure specific effects of 6 black-box defense\nstrategies, including a query-rewriter in the RAG scenario. Our proposed\nmulti-tier combination of defenses still has an ASR of 5.3% for black-box LLMs,\nindicating room for enhancement and future direction for LLM security research.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u63d0\u793a\u6d29\u6f0f\u6703\u9020\u6210\u91cd\u5927\u7684\u5b89\u5168\n\u548c\u96b1\u79c1\u5a01\u8105\uff0c\u7279\u5225\u662f\u5728\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG)\n\u7cfb\u7d71\u4e2d\u3002\u7136\u800c\uff0c\u591a\u56de\u5408 LLM \u4e92\u52d5\u4e2d\u7684\u6d29\u6f0f\u4ee5\u53ca\u7de9\u89e3\n\u7b56\u7565\u5c1a\u672a\u4ee5\u6a19\u6e96\u5316\u65b9\u5f0f\u9032\u884c\u7814\u7a76\u3002\u672c\u6587\n\u91dd\u5c0d 4 \u500b\u4e0d\u540c\u7684\u9818\u57df\u548c 10 \u500b\u5c01\u9589\u548c\u958b\u653e\u539f\u59cb\u78bc LLM \u8abf\u67e5 LLM \u91dd\u5c0d\u63d0\u793a\u6d29\u6f0f\u7684\u6f0f\u6d1e\u3002\u6211\u5011\u7368\u7279\u7684\u591a\u56de\u5408\u5a01\u8105\u6a21\u578b\n\u5229\u7528 LLM \u7684\u963f\u8adb\u5949\u627f\u6548\u61c9\uff0c\u6211\u5011\u7684\u5206\u6790\u5256\u6790\u4e86\u4efb\u52d9\n\u6307\u4ee4\u548c LLM \u56de\u61c9\u4e2d\u7684\u77e5\u8b58\u6d29\u6f0f\u3002\u5728\u591a\u56de\u5408\u8a2d\u5b9a\u4e2d\uff0c\n\u6211\u5011\u7684\u5a01\u8105\u6a21\u578b\u5c07\u5e73\u5747\u653b\u64ca\u6210\u529f\u7387 (ASR) \u63d0\u5347\u81f3 86.2%\uff0c\n\u5305\u62ec GPT-4 \u548c claude-1.3 \u7684 99% \u6d29\u6f0f\u3002\u6211\u5011\u767c\u73fe\u67d0\u4e9b\u9ed1\u76d2\nLLM\uff08\u4f8b\u5982 Gemini\uff09\u986f\u793a\u51fa\u5c0d\u4e0d\u540c\u9818\u57df\u6d29\u6f0f\u7684\u6613\u611f\u6027\u5dee\u7570 - \u8207\n\u91ab\u7642\u9818\u57df\u76f8\u6bd4\uff0c\u5b83\u5011\u66f4\u6709\u53ef\u80fd\u5728\u65b0\u805e\u9818\u57df\u6d29\u6f0f\u80cc\u666f\u77e5\u8b58\u3002\u6211\u5011\u7684\u5be6\u9a57\u6e2c\u91cf\u4e86 6 \u7a2e\u9ed1\u76d2\u9632\u79a6\u7b56\u7565\u7684\u5177\u9ad4\u6548\u679c\uff0c\n\u5305\u62ec RAG \u5834\u666f\u4e2d\u7684\u67e5\u8a62\u6539\u5beb\u5668\u3002\u6211\u5011\u63d0\u51fa\u7684\n\u591a\u5c64\u9632\u79a6\u7d44\u5408\u5c0d\u9ed1\u76d2 LLM \u4ecd\u6709 5.3% \u7684 ASR\uff0c\n\u8868\u793a LLM \u5b89\u5168\u7814\u7a76\u7684\u589e\u5f37\u548c\u672a\u4f86\u65b9\u5411\u4ecd\u6709\u9032\u6b65\u7a7a\u9593\u3002</paragraph>", "author": "Divyansh Agarwal et.al.", "authors": "Divyansh Agarwal, Alexander R. Fabbri, Philippe Laban, Ben Risher, Shafiq Joty, Caiming Xiong, Chien-Sheng Wu", "id": "2404.16251v2", "paper_url": "http://arxiv.org/abs/2404.16251v2", "repo": "null"}}