{"2412.02173": {"publish_time": "2024-12-03", "title": "Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models", "paper_summary": "Since the emergence of Large Language Models (LLMs), the challenge of\neffectively leveraging their potential in healthcare has taken center stage. A\ncritical barrier to using LLMs for extracting insights from unstructured\nclinical notes lies in the prompt engineering process. Despite its pivotal role\nin determining task performance, a clear framework for prompt optimization\nremains absent. Current methods to address this gap take either a manual prompt\nrefinement approach, where domain experts collaborate with prompt engineers to\ncreate an optimal prompt, which is time-intensive and difficult to scale, or\nthrough employing automatic prompt optimizing approaches, where the value of\nthe input of domain experts is not fully realized. To address this, we propose\nStructEase, a novel framework that bridges the gap between automation and the\ninput of human expertise in prompt engineering. A core innovation of the\nframework is SamplEase, an iterative sampling algorithm that identifies\nhigh-value cases where expert feedback drives significant performance\nimprovements. This approach minimizes expert intervention, to effectively\nenhance classification outcomes. This targeted approach reduces labeling\nredundancy, mitigates human error, and enhances classification outcomes. We\nevaluated the performance of StructEase using a dataset of de-identified\nclinical narratives from the US National Electronic Injury Surveillance System\n(NEISS), demonstrating significant gains in classification performance compared\nto current methods. Our findings underscore the value of expert integration in\nLLM workflows, achieving notable improvements in F1 score while maintaining\nminimal expert effort. By combining transparency, flexibility, and scalability,\nStructEase sets the foundation for a framework to integrate expert input into\nLLM workflows in healthcare and beyond.", "paper_summary_zh": "\u81ea\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u51fa\u73fe\u4ee5\u4f86\uff0c\u6709\u6548\u5229\u7528\u5176\u5728\u91ab\u7642\u4fdd\u5065\u4e2d\u7684\u6f5b\u529b\u7684\u6311\u6230\u5df2\u6210\u70ba\u91cd\u4e2d\u4e4b\u91cd\u3002\u4f7f\u7528 LLM \u5f9e\u975e\u7d50\u69cb\u5316\u81e8\u5e8a\u7b46\u8a18\u4e2d\u63d0\u53d6\u898b\u89e3\u7684\u4e00\u500b\u95dc\u9375\u969c\u7919\u5728\u65bc\u63d0\u793a\u5de5\u7a0b\u904e\u7a0b\u3002\u5118\u7ba1\u5b83\u5728\u78ba\u5b9a\u4efb\u52d9\u7e3e\u6548\u4e2d\u626e\u6f14\u8457\u8209\u8db3\u8f15\u91cd\u7684\u89d2\u8272\uff0c\u4f46\u4ecd\u7f3a\u4e4f\u660e\u78ba\u7684\u63d0\u793a\u6700\u4f73\u5316\u6846\u67b6\u3002\u76ee\u524d\u89e3\u6c7a\u6b64\u5dee\u8ddd\u7684\u65b9\u6cd5\u63a1\u7528\u624b\u52d5\u63d0\u793a\u512a\u5316\u65b9\u6cd5\uff0c\u5176\u4e2d\u9818\u57df\u5c08\u5bb6\u8207\u63d0\u793a\u5de5\u7a0b\u5e2b\u5408\u4f5c\u5efa\u7acb\u6700\u4f73\u63d0\u793a\uff0c\u9019\u975e\u5e38\u8017\u6642\u4e14\u96e3\u4ee5\u64f4\u5c55\uff0c\u6216\u900f\u904e\u63a1\u7528\u81ea\u52d5\u63d0\u793a\u6700\u4f73\u5316\u65b9\u6cd5\uff0c\u5176\u4e2d\u9818\u57df\u5c08\u5bb6\u7684\u8f38\u5165\u50f9\u503c\u4e26\u672a\u5145\u5206\u5be6\u73fe\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 StructEase\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u6846\u67b6\uff0c\u5b83\u5f4c\u5408\u4e86\u81ea\u52d5\u5316\u8207\u63d0\u793a\u5de5\u7a0b\u4e2d\u4eba\u985e\u5c08\u696d\u77e5\u8b58\u8f38\u5165\u4e4b\u9593\u7684\u5dee\u8ddd\u3002\u8a72\u6846\u67b6\u7684\u6838\u5fc3\u5275\u65b0\u662f SamplEase\uff0c\u9019\u662f\u4e00\u7a2e\u8fed\u4ee3\u5f0f\u62bd\u6a23\u6f14\u7b97\u6cd5\uff0c\u5b83\u8b58\u5225\u51fa\u5c08\u5bb6\u56de\u994b\u80fd\u986f\u8457\u63d0\u5347\u7e3e\u6548\u7684\u9ad8\u50f9\u503c\u6848\u4f8b\u3002\u9019\u7a2e\u65b9\u6cd5\u5c07\u5c08\u5bb6\u4ecb\u5165\u964d\u5230\u6700\u4f4e\uff0c\u4ee5\u6709\u6548\u63d0\u5347\u5206\u985e\u7d50\u679c\u3002\u9019\u7a2e\u6709\u91dd\u5c0d\u6027\u7684\u65b9\u6cd5\u6e1b\u5c11\u4e86\u6a19\u7c64\u5197\u9918\uff0c\u6e1b\u8f15\u4e86\u4eba\u70ba\u932f\u8aa4\uff0c\u4e26\u63d0\u5347\u4e86\u5206\u985e\u7d50\u679c\u3002\u6211\u5011\u4f7f\u7528\u4f86\u81ea\u7f8e\u570b\u570b\u5bb6\u96fb\u5b50\u50b7\u5bb3\u76e3\u6e2c\u7cfb\u7d71 (NEISS) \u7684\u53bb\u8b58\u5225\u5316\u81e8\u5e8a\u6558\u8ff0\u8cc7\u6599\u96c6\u8a55\u4f30\u4e86 StructEase \u7684\u7e3e\u6548\uff0c\u8207\u76ee\u524d\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5206\u985e\u7e3e\u6548\u6709\u4e86\u986f\u8457\u7684\u63d0\u5347\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u5f37\u8abf\u4e86\u5c08\u5bb6\u6574\u5408\u5728 LLM \u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u50f9\u503c\uff0c\u5728\u7dad\u6301\u6700\u5c11\u5c08\u5bb6\u5de5\u4f5c\u91cf\u7684\u540c\u6642\uff0c\u9054\u5230\u4e86 F1 \u5206\u6578\u7684\u986f\u8457\u63d0\u5347\u3002\u900f\u904e\u7d50\u5408\u900f\u660e\u5ea6\u3001\u5f48\u6027\u548c\u53ef\u64f4\u5c55\u6027\uff0cStructEase \u70ba\u4e00\u500b\u6846\u67b6\u5960\u5b9a\u4e86\u57fa\u790e\uff0c\u5c07\u5c08\u5bb6\u8f38\u5165\u6574\u5408\u5230\u91ab\u7642\u4fdd\u5065\u53ca\u5176\u4ed6\u9818\u57df\u7684 LLM \u5de5\u4f5c\u6d41\u7a0b\u4e2d\u3002", "author": "Nader Karayanni et.al.", "authors": "Nader Karayanni, Aya Awwad, Chein-Lien Hsiao, Surish P Shanmugam", "id": "2412.02173v1", "paper_url": "http://arxiv.org/abs/2412.02173v1", "repo": "null"}}