{"2406.05954": {"publish_time": "2024-06-10", "title": "Aligning Large Language Models with Representation Editing: A Control Perspective", "paper_summary": "Aligning large language models (LLMs) with human objectives is crucial for\nreal-world applications. However, fine-tuning LLMs for alignment often suffers\nfrom unstable training and requires substantial computing resources. Test-time\nalignment techniques, such as prompting and guided decoding, do not modify the\nunderlying model, and their performance remains dependent on the original\nmodel's capabilities. To address these challenges, we propose aligning LLMs\nthrough representation editing. The core of our method is to view a pre-trained\nautoregressive LLM as a discrete-time stochastic dynamical system. To achieve\nalignment for specific objectives, we introduce external control signals into\nthe state space of this language dynamical system. We train a value function\ndirectly on the hidden states according to the Bellman equation, enabling\ngradient-based optimization to obtain the optimal control signals at test time.\nOur experiments demonstrate that our method outperforms existing test-time\nalignment techniques while requiring significantly fewer resources compared to\nfine-tuning methods.", "paper_summary_zh": "\u5c0d\u9f4a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u4eba\u985e\u76ee\u6a19\u5c0d\u65bc\u771f\u5be6\u4e16\u754c\u7684\u61c9\u7528\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u5fae\u8abf LLM \u4ee5\u9032\u884c\u5c0d\u9f4a\u901a\u5e38\u6703\u5c0e\u81f4\u8a13\u7df4\u4e0d\u7a69\u5b9a\uff0c\u4e26\u4e14\u9700\u8981\u5927\u91cf\u7684\u904b\u7b97\u8cc7\u6e90\u3002\u6e2c\u8a66\u6642\u9593\u5c0d\u9f4a\u6280\u8853\uff0c\u4f8b\u5982\u63d0\u793a\u548c\u5f15\u5c0e\u89e3\u78bc\uff0c\u4e0d\u6703\u4fee\u6539\u57fa\u790e\u6a21\u578b\uff0c\u4e26\u4e14\u5b83\u5011\u7684\u6027\u80fd\u4ecd\u7136\u4f9d\u8cf4\u65bc\u539f\u59cb\u6a21\u578b\u7684\u529f\u80fd\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5efa\u8b70\u901a\u904e\u8868\u793a\u7de8\u8f2f\u5c0d\u9f4a LLM\u3002\u6211\u5011\u65b9\u6cd5\u7684\u6838\u5fc3\u662f\u5c07\u9810\u5148\u8a13\u7df4\u7684\u81ea\u52d5\u56de\u6b78 LLM \u8996\u70ba\u96e2\u6563\u6642\u9593\u96a8\u6a5f\u52d5\u529b\u7cfb\u7d71\u3002\u70ba\u4e86\u5be6\u73fe\u7279\u5b9a\u76ee\u6a19\u7684\u5c0d\u9f4a\uff0c\u6211\u5011\u5c07\u5916\u90e8\u63a7\u5236\u4fe1\u865f\u5f15\u5165\u6b64\u8a9e\u8a00\u52d5\u529b\u7cfb\u7d71\u7684\u72c0\u614b\u7a7a\u9593\u3002\u6211\u5011\u6839\u64da\u8c9d\u723e\u66fc\u65b9\u7a0b\u5f0f\u76f4\u63a5\u5728\u96b1\u85cf\u72c0\u614b\u4e0a\u8a13\u7df4\u503c\u51fd\u6578\uff0c\u5f9e\u800c\u4f7f\u57fa\u65bc\u68af\u5ea6\u7684\u6700\u4f73\u5316\u80fd\u5920\u5728\u6e2c\u8a66\u6642\u7372\u5f97\u6700\u4f73\u63a7\u5236\u4fe1\u865f\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0c\u8207\u5fae\u8abf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6a21\u578b\u512a\u65bc\u73fe\u6709\u7684\u6e2c\u8a66\u6642\u9593\u5c0d\u9f4a\u6280\u8853\uff0c\u540c\u6642\u6240\u9700\u7684\u8cc7\u6e90\u4e5f\u5c11\u5f97\u591a\u3002", "author": "Lingkai Kong et.al.", "authors": "Lingkai Kong, Haorui Wang, Wenhao Mu, Yuanqi Du, Yuchen Zhuang, Yifei Zhou, Yue Song, Rongzhi Zhang, Kai Wang, Chao Zhang", "id": "2406.05954v1", "paper_url": "http://arxiv.org/abs/2406.05954v1", "repo": "null"}}