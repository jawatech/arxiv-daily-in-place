{"2411.04573": {"publish_time": "2024-11-07", "title": "Multistage Fine-tuning Strategies for Automatic Speech Recognition in Low-resource Languages", "paper_summary": "This paper presents a novel multistage fine-tuning strategy designed to\nenhance automatic speech recognition (ASR) performance in low-resource\nlanguages using OpenAI's Whisper model. In this approach we aim to build ASR\nmodel for languages with limited digital resources by sequentially adapting the\nmodel across linguistically similar languages. We experimented this on the\nMalasar language, a Dravidian language spoken by approximately ten thousand\npeople in the Western Ghats of South India. Malasar language faces critical\nchallenges for technological intervention due to its lack of a native script\nand absence of digital or spoken data resources. Working in collaboration with\nWycliffe India and Malasar community members, we created a spoken Malasar\ncorpus paired with transcription in Tamil script, a closely related major\nlanguage. In our approach to build ASR model for Malasar, we first build an\nintermediate Tamil ASR, leveraging higher data availability for Tamil annotated\nspeech. This intermediate model is subsequently fine-tuned on Malasar data,\nallowing for more effective ASR adaptation despite limited resources. The\nmultistage fine-tuning strategy demonstrated significant improvements over\ndirect fine-tuning on Malasar data alone, achieving a word error rate (WER) of\n51.9%, which is 4.5% absolute reduction when compared to the direct fine-tuning\nmethod. Further a WER reduction to 47.3% was achieved through punctuation\nremoval in post-processing, which addresses formatting inconsistencies that\nimpact evaluation. Our results underscore the effectiveness of sequential\nmultistage fine-tuning combined with targeted post-processing as a scalable\nstrategy for ASR system development in low-resource languages, especially where\nlinguistic similarities can be leveraged to bridge gaps in training data.", "paper_summary_zh": "<paragraph>\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u591a\u968e\u6bb5\u5fae\u8abf\u7b56\u7565\uff0c\u65e8\u5728\u4f7f\u7528 OpenAI \u7684 Whisper \u6a21\u578b\u589e\u5f37\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u4e2d\u7684\u81ea\u52d5\u8a9e\u97f3\u8b58\u5225 (ASR) \u6548\u80fd\u3002\u5728\u6b64\u65b9\u6cd5\u4e2d\uff0c\u6211\u5011\u65e8\u5728\u900f\u904e\u8de8\u8a9e\u8a00\u76f8\u4f3c\u8a9e\u8a00\u5faa\u5e8f\u6f38\u5e45\u5ea6\u5730\u8abf\u6574\u6a21\u578b\uff0c\u70ba\u8cc7\u6e90\u6709\u9650\u7684\u8a9e\u8a00\u5efa\u7acb ASR \u6a21\u578b\u3002\u6211\u5011\u5728\u99ac\u62c9\u85a9\u723e\u8a9e\u4e0a\u9032\u884c\u4e86\u5be6\u9a57\uff0c\u99ac\u62c9\u85a9\u723e\u8a9e\u662f\u4e00\u7a2e\u5fb7\u62c9\u5a01\u8a9e\uff0c\u7531\u5357\u5370\u5ea6\u897f\u9ad8\u6b62\u5c71\u8108\u7d04\u4e00\u842c\u4eba\u4f7f\u7528\u3002\u7531\u65bc\u99ac\u62c9\u85a9\u723e\u8a9e\u7f3a\u4e4f\u539f\u751f\u6587\u5b57\uff0c\u4e14\u6c92\u6709\u6578\u4f4d\u6216\u53e3\u8a9e\u8cc7\u6599\u8cc7\u6e90\uff0c\u56e0\u6b64\u9762\u81e8\u6280\u8853\u4ecb\u5165\u7684\u56b4\u5cfb\u6311\u6230\u3002\u6211\u5011\u8207 Wycliffe India \u548c\u99ac\u62c9\u85a9\u723e\u793e\u5340\u6210\u54e1\u5408\u4f5c\uff0c\u5efa\u7acb\u4e86\u4e00\u500b\u53e3\u8a9e\u99ac\u62c9\u85a9\u723e\u8a9e\u8a9e\u6599\u5eab\uff0c\u4e26\u914d\u4e0a\u4ee5\u6cf0\u7c73\u723e\u6587\uff08\u4e00\u7a2e\u5bc6\u5207\u76f8\u95dc\u7684\u4e3b\u8981\u8a9e\u8a00\uff09\u66f8\u5beb\u7684\u8f49\u9304\u3002\u5728\u6211\u5011\u5efa\u7acb\u99ac\u62c9\u85a9\u723e\u8a9e ASR \u6a21\u578b\u7684\u65b9\u6cd5\u4e2d\uff0c\u6211\u5011\u9996\u5148\u5efa\u7acb\u4e00\u500b\u4e2d\u9593\u6cf0\u7c73\u723e\u8a9e ASR\uff0c\u5229\u7528\u6cf0\u7c73\u723e\u8a9e\u6a19\u8a3b\u8a9e\u97f3\u8f03\u9ad8\u7684\u8cc7\u6599\u53ef\u7528\u6027\u3002\u9019\u500b\u4e2d\u9593\u6a21\u578b\u96a8\u5f8c\u5728\u99ac\u62c9\u85a9\u723e\u8a9e\u8cc7\u6599\u4e0a\u9032\u884c\u5fae\u8abf\uff0c\u5118\u7ba1\u8cc7\u6e90\u6709\u9650\uff0c\u4ecd\u80fd\u66f4\u6709\u6548\u5730\u8abf\u6574 ASR\u3002\u591a\u968e\u6bb5\u5fae\u8abf\u7b56\u7565\u8b49\u660e\u4e86\u8207\u50c5\u5c0d\u99ac\u62c9\u85a9\u723e\u8a9e\u8cc7\u6599\u9032\u884c\u76f4\u63a5\u5fae\u8abf\u76f8\u6bd4\uff0c\u6709\u986f\u8457\u7684\u6539\u5584\uff0c\u9054\u5230 51.9% \u7684\u8a5e\u8a9e\u932f\u8aa4\u7387 (WER)\uff0c\u8207\u76f4\u63a5\u5fae\u8abf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u7d55\u5c0d\u964d\u4f4e\u4e86 4.5%\u3002\u6b64\u5916\uff0c\u900f\u904e\u5f8c\u8655\u7406\u4e2d\u7684\u6a19\u9ede\u7b26\u865f\u79fb\u9664\uff0cWER \u9032\u4e00\u6b65\u964d\u4f4e\u81f3 47.3%\uff0c\u9019\u89e3\u6c7a\u4e86\u5f71\u97ff\u8a55\u4f30\u7684\u683c\u5f0f\u4e0d\u4e00\u81f4\u554f\u984c\u3002\u6211\u5011\u7684\u7d50\u679c\u5f37\u8abf\u4e86\u5faa\u5e8f\u591a\u968e\u6bb5\u5fae\u8abf\u7d50\u5408\u76ee\u6a19\u5f8c\u8655\u7406\u4f5c\u70ba\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u4e2d ASR \u7cfb\u7d71\u958b\u767c\u7684\u53ef\u64f4\u5145\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u7279\u5225\u662f\u5728\u8a9e\u8a00\u76f8\u4f3c\u6027\u53ef\u7528\u65bc\u5f4c\u5408\u8a13\u7df4\u8cc7\u6599\u5dee\u8ddd\u7684\u60c5\u6cc1\u4e0b\u3002</paragraph>", "author": "Leena G Pillai et.al.", "authors": "Leena G Pillai, Kavya Manohar, Basil K Raju, Elizabeth Sherly", "id": "2411.04573v1", "paper_url": "http://arxiv.org/abs/2411.04573v1", "repo": "null"}}