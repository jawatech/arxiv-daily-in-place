{"2410.21662": {"publish_time": "2024-10-29", "title": "$f$-PO: Generalizing Preference Optimization with $f$-divergence Minimization", "paper_summary": "Preference optimization has made significant progress recently, with numerous\nmethods developed to align language models with human preferences. This paper\nintroduces $f$-divergence Preference Optimization ($f$-PO), a novel framework\nthat generalizes and extends existing approaches. $f$-PO minimizes\n$f$-divergences between the optimized policy and the optimal policy,\nencompassing a broad family of alignment methods using various divergences. Our\napproach unifies previous algorithms like DPO and EXO, while offering new\nvariants through different choices of $f$-divergences. We provide theoretical\nanalysis of $f$-PO's properties and conduct extensive experiments on\nstate-of-the-art language models using benchmark datasets. Results demonstrate\n$f$-PO's effectiveness across various tasks, achieving superior performance\ncompared to existing methods on popular benchmarks such as AlpacaEval 2,\nArena-Hard, and MT-Bench. Additionally, we present ablation studies exploring\nthe impact of different $f$-divergences, offering insights into the trade-offs\nbetween regularization and performance in offline preference optimization. Our\nwork contributes both practical algorithms and theoretical understanding to the\nfield of language model alignment. Code is available at\nhttps://github.com/MinkaiXu/fPO.", "paper_summary_zh": "\u504f\u597d\u4f18\u5316\u6700\u8fd1\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u5f00\u53d1\u4e86\u8bb8\u591a\u65b9\u6cd5\u6765\u5c06\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u672c\u6587\u4ecb\u7ecd\u4e86 $f$-\u6563\u5ea6\u504f\u597d\u4f18\u5316 ($f$-PO)\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u6982\u62ec\u548c\u6269\u5c55\u73b0\u6709\u65b9\u6cd5\u3002$f$-PO \u6700\u5c0f\u5316\u4f18\u5316\u7b56\u7565\u548c\u6700\u4f18\u7b56\u7565\u4e4b\u95f4\u7684 $f$-\u6563\u5ea6\uff0c\u6db5\u76d6\u4f7f\u7528\u5404\u79cd\u6563\u5ea6\u7684\u5e7f\u6cdb\u7684\u6821\u51c6\u65b9\u6cd5\u65cf\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u7edf\u4e00\u4e86 DPO \u548c EXO \u7b49\u5148\u524d\u7684\u7b97\u6cd5\uff0c\u540c\u65f6\u901a\u8fc7\u4e0d\u540c\u7684 $f$-\u6563\u5ea6\u9009\u62e9\u63d0\u4f9b\u4e86\u65b0\u7684\u53d8\u4f53\u3002\u6211\u4eec\u63d0\u4f9b\u4e86 $f$-PO \u7279\u6027\u7684\u7406\u8bba\u5206\u6790\uff0c\u5e76\u4f7f\u7528\u57fa\u51c6\u6570\u636e\u96c6\u5bf9\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u3002\u7ed3\u679c\u8868\u660e $f$-PO \u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u90fd\u975e\u5e38\u6709\u6548\uff0c\u4e0e AlpacaEval 2\u3001Arena-Hard \u548c MT-Bench \u7b49\u6d41\u884c\u57fa\u51c6\u4e0a\u7684\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u53d6\u5f97\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63d0\u4f9b\u4e86\u6d88\u878d\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u4e0d\u540c $f$-\u6563\u5ea6\u7684\u5f71\u54cd\uff0c\u6df1\u5165\u4e86\u89e3\u4e86\u79bb\u7ebf\u504f\u597d\u4f18\u5316\u4e2d\u6b63\u5219\u5316\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u4e3a\u8bed\u8a00\u6a21\u578b\u6821\u51c6\u9886\u57df\u505a\u51fa\u4e86\u5b9e\u7528\u7b97\u6cd5\u548c\u7406\u8bba\u7406\u89e3\u7684\u8d21\u732e\u3002\u4ee3\u7801\u53ef\u5728 https://github.com/MinkaiXu/fPO \u83b7\u5f97\u3002", "author": "Jiaqi Han et.al.", "authors": "Jiaqi Han, Mingjian Jiang, Yuxuan Song, Jure Leskovec, Stefano Ermon, Minkai Xu", "id": "2410.21662v1", "paper_url": "http://arxiv.org/abs/2410.21662v1", "repo": "null"}}