{"2409.07114": {"publish_time": "2024-09-11", "title": "A Continual and Incremental Learning Approach for TinyML On-device Training Using Dataset Distillation and Model Size Adaption", "paper_summary": "A new algorithm for incremental learning in the context of Tiny Machine\nlearning (TinyML) is presented, which is optimized for low-performance and\nenergy efficient embedded devices. TinyML is an emerging field that deploys\nmachine learning models on resource-constrained devices such as\nmicrocontrollers, enabling intelligent applications like voice recognition,\nanomaly detection, predictive maintenance, and sensor data processing in\nenvironments where traditional machine learning models are not feasible. The\nalgorithm solve the challenge of catastrophic forgetting through the use of\nknowledge distillation to create a small, distilled dataset. The novelty of the\nmethod is that the size of the model can be adjusted dynamically, so that the\ncomplexity of the model can be adapted to the requirements of the task. This\noffers a solution for incremental learning in resource-constrained\nenvironments, where both model size and computational efficiency are critical\nfactors. Results show that the proposed algorithm offers a promising approach\nfor TinyML incremental learning on embedded devices. The algorithm was tested\non five datasets including: CIFAR10, MNIST, CORE50, HAR, Speech Commands. The\nfindings indicated that, despite using only 43% of Floating Point Operations\n(FLOPs) compared to a larger fixed model, the algorithm experienced a\nnegligible accuracy loss of just 1%. In addition, the presented method is\nmemory efficient. While state-of-the-art incremental learning is usually very\nmemory intensive, the method requires only 1% of the original data set.", "paper_summary_zh": "<paragraph>\u63d0\u51fa\u4e86\u4e00\u7a2e\u91dd\u5c0d\u5c0f\u578b\u6a5f\u5668\u5b78\u7fd2 (TinyML) \u80cc\u666f\u4e2d\u7684\u589e\u91cf\u5b78\u7fd2\u7684\u65b0\u6f14\u7b97\u6cd5\uff0c\u8a72\u6f14\u7b97\u6cd5\u7d93\u904e\u6700\u4f73\u5316\uff0c\u9069\u7528\u65bc\u4f4e\u6548\u80fd\u4e14\u7bc0\u80fd\u7684\u5d4c\u5165\u5f0f\u88dd\u7f6e\u3002TinyML \u662f\u65b0\u8208\u9818\u57df\uff0c\u5b83\u5728\u53d7\u9650\u8cc7\u6e90\u7684\u88dd\u7f6e\u4e0a\u90e8\u7f72\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\uff0c\u4f8b\u5982\u5fae\u63a7\u5236\u5668\uff0c\u8b93\u667a\u6167\u578b\u61c9\u7528\u7a0b\u5f0f\u5f97\u4ee5\u5728\u50b3\u7d71\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u7121\u6cd5\u57f7\u884c\u7684\u74b0\u5883\u4e2d\u57f7\u884c\uff0c\u4f8b\u5982\u8a9e\u97f3\u8fa8\u8b58\u3001\u7570\u5e38\u5075\u6e2c\u3001\u9810\u6e2c\u6027\u7dad\u8b77\u548c\u611f\u6e2c\u5668\u8cc7\u6599\u8655\u7406\u3002\u8a72\u6f14\u7b97\u6cd5\u900f\u904e\u4f7f\u7528\u77e5\u8b58\u8403\u53d6\u4f86\u5efa\u7acb\u5c0f\u578b\u8403\u53d6\u8cc7\u6599\u96c6\uff0c\u89e3\u6c7a\u4e86\u707d\u96e3\u6027\u907a\u5fd8\u7684\u6311\u6230\u3002\u6b64\u65b9\u6cd5\u7684\u5275\u65b0\u4e4b\u8655\u5728\u65bc\u53ef\u4ee5\u52d5\u614b\u8abf\u6574\u6a21\u578b\u5927\u5c0f\uff0c\u4ee5\u4fbf\u6a21\u578b\u8907\u96dc\u5ea6\u53ef\u4ee5\u9069\u61c9\u4efb\u52d9\u9700\u6c42\u3002\u9019\u70ba\u53d7\u9650\u8cc7\u6e90\u74b0\u5883\u4e2d\u7684\u589e\u91cf\u5b78\u7fd2\u63d0\u4f9b\u4e86\u89e3\u6c7a\u65b9\u6848\uff0c\u5176\u4e2d\u6a21\u578b\u5927\u5c0f\u548c\u904b\u7b97\u6548\u7387\u90fd\u662f\u95dc\u9375\u56e0\u7d20\u3002\u7d50\u679c\u986f\u793a\uff0c\u6240\u63d0\u51fa\u7684\u6f14\u7b97\u6cd5\u70ba\u5d4c\u5165\u5f0f\u88dd\u7f6e\u4e0a\u7684 TinyML \u589e\u91cf\u5b78\u7fd2\u63d0\u4f9b\u4e86\u6709\u524d\u9014\u7684\u65b9\u6cd5\u3002\u8a72\u6f14\u7b97\u6cd5\u5728\u4e94\u500b\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u4e86\u6e2c\u8a66\uff0c\u5305\u62ec\uff1aCIFAR10\u3001MNIST\u3001CORE50\u3001HAR\u3001Speech Commands\u3002\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u5118\u7ba1\u8207\u8f03\u5927\u7684\u56fa\u5b9a\u6a21\u578b\u76f8\u6bd4\uff0c\u50c5\u4f7f\u7528\u4e86 43% \u7684\u6d6e\u9ede\u904b\u7b97 (FLOP)\uff0c\u4f46\u8a72\u6f14\u7b97\u6cd5\u7684\u7cbe\u78ba\u5ea6\u640d\u5931\u5fae\u4e4e\u5176\u5fae\uff0c\u50c5 1%\u3002\u6b64\u5916\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5177\u6709\u8a18\u61b6\u9ad4\u6548\u7387\u3002\u96d6\u7136\u6700\u5148\u9032\u7684\u589e\u91cf\u5b78\u7fd2\u901a\u5e38\u975e\u5e38\u8017\u8cbb\u8a18\u61b6\u9ad4\uff0c\u4f46\u8a72\u65b9\u6cd5\u50c5\u9700\u8981 1% \u7684\u539f\u59cb\u8cc7\u6599\u96c6\u3002</paragraph>", "author": "Marcus R\u00fcb et.al.", "authors": "Marcus R\u00fcb, Philipp Tuchel, Axel Sikora, Daniel Mueller-Gritschneder", "id": "2409.07114v1", "paper_url": "http://arxiv.org/abs/2409.07114v1", "repo": "null"}}