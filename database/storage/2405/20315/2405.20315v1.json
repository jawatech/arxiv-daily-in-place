{"2405.20315": {"publish_time": "2024-05-30", "title": "ANAH: Analytical Annotation of Hallucinations in Large Language Models", "paper_summary": "Reducing the `$\\textit{hallucination}$' problem of Large Language Models\n(LLMs) is crucial for their wide applications. A comprehensive and fine-grained\nmeasurement of the hallucination is the first key step for the governance of\nthis issue but is under-explored in the community. Thus, we present\n$\\textbf{ANAH}$, a bilingual dataset that offers $\\textbf{AN}$alytical\n$\\textbf{A}$nnotation of $\\textbf{H}$allucinations in LLMs within Generative\nQuestion Answering. Each answer sentence in our dataset undergoes rigorous\nannotation, involving the retrieval of a reference fragment, the judgment of\nthe hallucination type, and the correction of hallucinated content. ANAH\nconsists of ~12k sentence-level annotations for ~4.3k LLM responses covering\nover 700 topics, constructed by a human-in-the-loop pipeline. Thanks to the\nfine granularity of the hallucination annotations, we can quantitatively\nconfirm that the hallucinations of LLMs progressively accumulate in the answer\nand use ANAH to train and evaluate hallucination annotators. We conduct\nextensive experiments on studying generative and discriminative annotators and\nshow that, although current open-source LLMs have difficulties in fine-grained\nhallucination annotation, the generative annotator trained with ANAH can\nsurpass all open-source LLMs and GPT-3.5, obtain performance competitive with\nGPT-4, and exhibits better generalization ability on unseen questions.", "paper_summary_zh": "<paragraph>\u964d\u4f4e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u300c\u5e7b\u89ba\u300d\u554f\u984c\u5c0d\u65bc\u5176\u5ee3\u6cdb\u61c9\u7528\u81f3\u95dc\u91cd\u8981\u3002\u5c0d\u5e7b\u89ba\u9032\u884c\u5168\u9762\u4e14\u7d30\u7dfb\u7684\u6e2c\u91cf\u662f\u89e3\u6c7a\u6b64\u554f\u984c\u7684\u7b2c\u4e00\u500b\u95dc\u9375\u6b65\u9a5f\uff0c\u4f46\u793e\u7fa4\u5c0d\u6b64\u7684\u63a2\u8a0e\u537b\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86 $\\textbf{ANAH}$\uff0c\u4e00\u500b\u96d9\u8a9e\u8cc7\u6599\u96c6\uff0c\u63d0\u4f9b\u751f\u6210\u5f0f\u554f\u984c\u89e3\u7b54\u4e2d LLM \u5e7b\u89ba\u7684 $\\textbf{AN}$alytical $\\textbf{A}$nnotation of $\\textbf{H}$allucinations\u3002\u6211\u5011\u8cc7\u6599\u96c6\u4e2d\u7684\u6bcf\u500b\u7b54\u6848\u53e5\u5b50\u90fd\u7d93\u904e\u56b4\u683c\u7684\u8a3b\u89e3\uff0c\u5305\u62ec\u6aa2\u7d22\u53c3\u8003\u7247\u6bb5\u3001\u5224\u65b7\u5e7b\u89ba\u985e\u578b\u4ee5\u53ca\u66f4\u6b63\u5e7b\u89ba\u5167\u5bb9\u3002ANAH \u7531\u4eba\u5de5\u8ff4\u8def\u7ba1\u9053\u5efa\u69cb\uff0c\u5305\u542b\u8d85\u904e 700 \u500b\u4e3b\u984c\u7684\u7d04 4.3k \u500b LLM \u56de\u61c9\uff0c\u5171\u7d04 12k \u500b\u53e5\u5b50\u5c64\u7d1a\u8a3b\u89e3\u3002\u7531\u65bc\u5e7b\u89ba\u8a3b\u89e3\u7684\u7d30\u7dfb\u7a0b\u5ea6\uff0c\u6211\u5011\u53ef\u4ee5\u5b9a\u91cf\u78ba\u8a8d LLM \u7684\u5e7b\u89ba\u6703\u9010\u6f38\u7d2f\u7a4d\u5728\u7b54\u6848\u4e2d\uff0c\u4e26\u4f7f\u7528 ANAH \u4f86\u8a13\u7df4\u548c\u8a55\u4f30\u5e7b\u89ba\u8a3b\u89e3\u5668\u3002\u6211\u5011\u5c0d\u751f\u6210\u5f0f\u548c\u5224\u5225\u5f0f\u8a3b\u89e3\u5668\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u4e26\u8868\u660e\uff0c\u5118\u7ba1\u76ee\u524d\u7684\u958b\u6e90 LLM \u96e3\u4ee5\u9032\u884c\u7d30\u7dfb\u7684\u5e7b\u89ba\u8a3b\u89e3\uff0c\u4f46\u4f7f\u7528 ANAH \u8a13\u7df4\u7684\u751f\u6210\u5f0f\u8a3b\u89e3\u5668\u53ef\u4ee5\u8d85\u8d8a\u6240\u6709\u958b\u6e90 LLM \u548c GPT-3.5\uff0c\u7372\u5f97\u8207 GPT-4 \u76f8\u7576\u7684\u6548\u80fd\uff0c\u4e26\u5728\u672a\u898b\u904e\u7684\u554f\u984c\u4e0a\u5c55\u73fe\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002</paragraph>", "author": "Ziwei Ji et.al.", "authors": "Ziwei Ji, Yuzhe Gu, Wenwei Zhang, Chengqi Lyu, Dahua Lin, Kai Chen", "id": "2405.20315v1", "paper_url": "http://arxiv.org/abs/2405.20315v1", "repo": "https://github.com/open-compass/anah"}}