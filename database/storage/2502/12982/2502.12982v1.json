{"2502.12982": {"publish_time": "2025-02-18", "title": "Sailor2: Sailing in South-East Asia with Inclusive Multilingual LLMs", "paper_summary": "Sailor2 is a family of cutting-edge multilingual language models for\nSouth-East Asian (SEA) languages, available in 1B, 8B, and 20B sizes to suit\ndiverse applications. Building on Qwen2.5, Sailor2 undergoes continuous\npre-training on 500B tokens (400B SEA-specific and 100B replay tokens) to\nsupport 13 SEA languages while retaining proficiency in Chinese and English.\nSailor2-20B model achieves a 50-50 win rate against GPT-4o across SEA\nlanguages. We also deliver a comprehensive cookbook on how to develop the\nmultilingual model in an efficient manner, including five key aspects: data\ncuration, pre-training, post-training, model customization and evaluation. We\nhope that Sailor2 model (Apache 2.0 license) will drive language development in\nthe SEA region, and Sailor2 cookbook will inspire researchers to build more\ninclusive LLMs for other under-served languages.", "paper_summary_zh": "Sailor2 \u662f\u4e00\u7cfb\u5217\u91dd\u5c0d\u6771\u5357\u4e9e (SEA) \u8a9e\u8a00\u7684\u5c16\u7aef\u591a\u8a9e\u8a00\u8a9e\u8a00\u6a21\u578b\uff0c\u5099\u6709 1B\u30018B \u548c 20B \u5927\u5c0f\uff0c\u4ee5\u9069\u61c9\u5404\u7a2e\u61c9\u7528\u3002\u5728 Qwen2.5 \u7684\u57fa\u790e\u4e0a\uff0cSailor2 \u6301\u7e8c\u9032\u884c 500B \u4ee3\u5e63\uff08400B SEA \u5c08\u7528\u548c 100B \u91cd\u64ad\u4ee3\u5e63\uff09\u7684\u9810\u8a13\u7df4\uff0c\u4ee5\u652f\u63f4 13 \u7a2e SEA \u8a9e\u8a00\uff0c\u540c\u6642\u4fdd\u7559\u4e2d\u6587\u548c\u82f1\u6587\u7684\u719f\u7df4\u5ea6\u3002Sailor2-20B \u6a21\u578b\u5728 SEA \u8a9e\u8a00\u4e2d\u5c0d\u6297 GPT-4o \u6642\uff0c\u9054\u5230 50-50 \u7684\u7372\u52dd\u7387\u3002\u6211\u5011\u9084\u63d0\u4f9b\u4e00\u672c\u5168\u9762\u7684\u98df\u8b5c\uff0c\u8aaa\u660e\u5982\u4f55\u4ee5\u6709\u6548\u7684\u65b9\u5f0f\u958b\u767c\u591a\u8a9e\u8a00\u6a21\u578b\uff0c\u5305\u62ec\u4e94\u500b\u95dc\u9375\u65b9\u9762\uff1a\u8cc7\u6599\u7b56\u5c55\u3001\u9810\u8a13\u7df4\u3001\u5f8c\u8a13\u7df4\u3001\u6a21\u578b\u81ea\u8a02\u548c\u8a55\u4f30\u3002\u6211\u5011\u5e0c\u671b Sailor2 \u6a21\u578b\uff08Apache 2.0 \u6388\u6b0a\uff09\u5c07\u63a8\u52d5 SEA \u5730\u5340\u7684\u8a9e\u8a00\u767c\u5c55\uff0c\u800c Sailor2 \u98df\u8b5c\u5c07\u6fc0\u52f5\u7814\u7a76\u4eba\u54e1\u70ba\u5176\u4ed6\u670d\u52d9\u4e0d\u8db3\u7684\u8a9e\u8a00\u5efa\u7acb\u66f4\u5177\u5305\u5bb9\u6027\u7684 LLM\u3002", "author": "Longxu Dou et.al.", "authors": "Longxu Dou, Qian Liu, Fan Zhou, Changyu Chen, Zili Wang, Ziqi Jin, Zichen Liu, Tongyao Zhu, Cunxiao Du, Penghui Yang, Haonan Wang, Jiaheng Liu, Yongchi Zhao, Xiachong Feng, Xin Mao, Man Tsung Yeung, Kunat Pipatanakul, Fajri Koto, Min Si Thu, Hynek Kydl\u00ed\u010dek, Zeyi Liu, Qunshu Lin, Sittipong Sripaisarnmongkol, Kridtaphad Sae-Khow, Nirattisai Thongchim, Taechawat Konkaew, Narong Borijindargoon, Anh Dao, Matichon Maneegard, Phakphum Artkaew, Zheng-Xin Yong, Quan Nguyen, Wannaphong Phatthiyaphaibun, Hoang H. Tran, Mike Zhang, Shiqi Chen, Tianyu Pang, Chao Du, Xinyi Wan, Wei Lu, Min Lin", "id": "2502.12982v1", "paper_url": "http://arxiv.org/abs/2502.12982v1", "repo": "null"}}