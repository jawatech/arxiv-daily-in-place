{"2407.10373": {"publish_time": "2024-07-15", "title": "Mutual Learning for Acoustic Matching and Dereverberation via Visual Scene-driven Diffusion", "paper_summary": "Visual acoustic matching (VAM) is pivotal for enhancing the immersive\nexperience, and the task of dereverberation is effective in improving audio\nintelligibility. Existing methods treat each task independently, overlooking\nthe inherent reciprocity between them. Moreover, these methods depend on paired\ntraining data, which is challenging to acquire, impeding the utilization of\nextensive unpaired data. In this paper, we introduce MVSD, a mutual learning\nframework based on diffusion models. MVSD considers the two tasks\nsymmetrically, exploiting the reciprocal relationship to facilitate learning\nfrom inverse tasks and overcome data scarcity. Furthermore, we employ the\ndiffusion model as foundational conditional converters to circumvent the\ntraining instability and over-smoothing drawbacks of conventional GAN\narchitectures. Specifically, MVSD employs two converters: one for VAM called\nreverberator and one for dereverberation called dereverberator. The\ndereverberator judges whether the reverberation audio generated by reverberator\nsounds like being in the conditional visual scenario, and vice versa. By\nforming a closed loop, these two converters can generate informative feedback\nsignals to optimize the inverse tasks, even with easily acquired one-way\nunpaired data. Extensive experiments on two standard benchmarks, i.e.,\nSoundSpaces-Speech and Acoustic AVSpeech, exhibit that our framework can\nimprove the performance of the reverberator and dereverberator and better match\nspecified visual scenarios.", "paper_summary_zh": "\u8996\u89ba\u8072\u5b78\u5339\u914d (VAM) \u5c0d\u65bc\u589e\u5f37\u6c88\u6d78\u5f0f\u9ad4\u9a57\u81f3\u95dc\u91cd\u8981\uff0c\u800c\u6d88\u9664\u6b98\u97ff\u7684\u4efb\u52d9\u5c0d\u65bc\u63d0\u9ad8\u97f3\u8a0a\u6e05\u6670\u5ea6\u6709\u6548\u3002\u73fe\u6709\u65b9\u6cd5\u5c07\u6bcf\u500b\u4efb\u52d9\u7368\u7acb\u8655\u7406\uff0c\u5ffd\u7565\u5b83\u5011\u4e4b\u9593\u56fa\u6709\u7684\u4e92\u60e0\u6027\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u65b9\u6cd5\u4f9d\u8cf4\u65bc\u6210\u5c0d\u7684\u8a13\u7df4\u8cc7\u6599\uff0c\u9019\u5f88\u96e3\u7372\u53d6\uff0c\u963b\u7919\u4e86\u5ee3\u6cdb\u672a\u914d\u5c0d\u8cc7\u6599\u7684\u5229\u7528\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 MVSD\uff0c\u4e00\u500b\u57fa\u65bc\u64f4\u6563\u6a21\u578b\u7684\u76f8\u4e92\u5b78\u7fd2\u6846\u67b6\u3002MVSD \u5c0d\u7a31\u5730\u8003\u616e\u9019\u5169\u500b\u4efb\u52d9\uff0c\u5229\u7528\u4e92\u60e0\u95dc\u4fc2\u4f86\u4fc3\u9032\u5f9e\u9006\u4efb\u52d9\u4e2d\u5b78\u7fd2\u4e26\u514b\u670d\u8cc7\u6599\u7a00\u7f3a\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a1\u7528\u64f4\u6563\u6a21\u578b\u4f5c\u70ba\u57fa\u790e\u689d\u4ef6\u8f49\u63db\u5668\uff0c\u4ee5\u898f\u907f\u50b3\u7d71 GAN \u67b6\u69cb\u7684\u8a13\u7df4\u4e0d\u7a69\u5b9a\u6027\u548c\u904e\u5ea6\u5e73\u6ed1\u7684\u7f3a\u9ede\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cMVSD \u63a1\u7528\u5169\u500b\u8f49\u63db\u5668\uff1a\u4e00\u500b\u7528\u65bc VAM\uff0c\u7a31\u70ba\u6df7\u97ff\u5668\uff0c\u53e6\u4e00\u500b\u7528\u65bc\u6d88\u9664\u6b98\u97ff\uff0c\u7a31\u70ba\u6d88\u9664\u6df7\u97ff\u5668\u3002\u6d88\u9664\u6df7\u97ff\u5668\u5224\u65b7\u6df7\u97ff\u5668\u7522\u751f\u7684\u6df7\u97ff\u97f3\u8a0a\u662f\u5426\u807d\u8d77\u4f86\u50cf\u5728\u689d\u4ef6\u8996\u89ba\u5834\u666f\u4e2d\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\u901a\u904e\u5f62\u6210\u4e00\u500b\u9589\u74b0\uff0c\u9019\u5169\u500b\u8f49\u63db\u5668\u53ef\u4ee5\u7522\u751f\u8cc7\u8a0a\u6027\u7684\u56de\u994b\u8a0a\u865f\u4f86\u6700\u4f73\u5316\u9006\u4efb\u52d9\uff0c\u5373\u4f7f\u4f7f\u7528\u5bb9\u6613\u7372\u5f97\u7684\u55ae\u5411\u672a\u914d\u5c0d\u8cc7\u6599\u3002\u5728\u5169\u500b\u6a19\u6e96\u57fa\u6e96\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\uff0c\u5373 SoundSpaces-Speech \u548c Acoustic AVSpeech\uff0c\u8868\u660e\u6211\u5011\u7684\u6846\u67b6\u53ef\u4ee5\u63d0\u9ad8\u6df7\u97ff\u5668\u548c\u6d88\u9664\u6df7\u97ff\u5668\u7684\u6548\u80fd\uff0c\u4e26\u66f4\u597d\u5730\u5339\u914d\u6307\u5b9a\u7684\u8996\u89ba\u5834\u666f\u3002", "author": "Jian Ma et.al.", "authors": "Jian Ma, Wenguan Wang, Yi Yang, Feng Zheng", "id": "2407.10373v1", "paper_url": "http://arxiv.org/abs/2407.10373v1", "repo": "null"}}