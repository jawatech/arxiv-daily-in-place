{"2406.16479": {"publish_time": "2024-06-24", "title": "Emerging NeoHebbian Dynamics in Forward-Forward Learning: Implications for Neuromorphic Computing", "paper_summary": "Advances in neural computation have predominantly relied on the gradient\nbackpropagation algorithm (BP). However, the recent shift towards\nnon-stationary data modeling has highlighted the limitations of this heuristic,\nexposing that its adaptation capabilities are far from those seen in biological\nbrains. Unlike BP, where weight updates are computed through a reverse error\npropagation path, Hebbian learning dynamics provide synaptic updates using only\ninformation within the layer itself. This has spurred interest in biologically\nplausible learning algorithms, hypothesized to overcome BP's shortcomings. In\nthis context, Hinton recently introduced the Forward-Forward Algorithm (FFA),\nwhich employs local learning rules for each layer and has empirically proven\nits efficacy in multiple data modeling tasks. In this work we argue that when\nemploying a squared Euclidean norm as a goodness function driving the local\nlearning, the resulting FFA is equivalent to a neo-Hebbian Learning Rule. To\nverify this result, we compare the training behavior of FFA in analog networks\nwith its Hebbian adaptation in spiking neural networks. Our experiments\ndemonstrate that both versions of FFA produce similar accuracy and latent\ndistributions. The findings herein reported provide empirical evidence linking\nbiological learning rules with currently used training algorithms, thus paving\nthe way towards extrapolating the positive outcomes from FFA to Hebbian\nlearning rules. Simultaneously, our results imply that analog networks trained\nunder FFA could be directly applied to neuromorphic computing, leading to\nreduced energy usage and increased computational speed.", "paper_summary_zh": "\u795e\u7d93\u904b\u7b97\u7684\u9032\u5c55\u4e3b\u8981\u4f9d\u8cf4\u65bc\u68af\u5ea6\u53cd\u5411\u50b3\u64ad\u6f14\u7b97\u6cd5 (BP)\u3002\u7136\u800c\uff0c\u6700\u8fd1\u671d\u5411\u975e\u5e73\u7a69\u8cc7\u6599\u5efa\u6a21\u7684\u8f49\u8b8a\u7a81\u986f\u4e86\u9019\u7a2e\u555f\u767c\u6cd5\u7684\u9650\u5236\uff0c\u63ed\u9732\u5176\u9069\u61c9\u80fd\u529b\u9060\u4f4e\u65bc\u751f\u7269\u5927\u8166\u3002\u8207 BP \u4e0d\u540c\uff0c\u5176\u4e2d\u6b0a\u91cd\u66f4\u65b0\u662f\u900f\u904e\u53cd\u5411\u8aa4\u5dee\u50b3\u64ad\u8def\u5f91\u8a08\u7b97\uff0c\u8d6b\u5e03\u5b78\u7fd2\u52d5\u614b\u50c5\u4f7f\u7528\u5c64\u672c\u8eab\u5167\u7684\u8cc7\u8a0a\u63d0\u4f9b\u7a81\u89f8\u66f4\u65b0\u3002\u9019\u6fc0\u767c\u4e86\u5c0d\u751f\u7269\u4e0a\u5408\u7406\u7684\u5b78\u7fd2\u6f14\u7b97\u6cd5\u7684\u8208\u8da3\uff0c\u5047\u8a2d\u53ef\u4ee5\u514b\u670d BP \u7684\u7f3a\u9ede\u3002\u5728\u6b64\u8108\u7d61\u4e2d\uff0cHinton \u6700\u8fd1\u5f15\u5165\u4e86\u6b63\u5411\u6b63\u5411\u6f14\u7b97\u6cd5 (FFA)\uff0c\u5b83\u70ba\u6bcf\u4e00\u5c64\u63a1\u7528\u5c40\u90e8\u5b78\u7fd2\u898f\u5247\uff0c\u4e26\u5728\u5176\u6548\u80fd\u4e0a\u7d93\u904e\u591a\u9805\u8cc7\u6599\u5efa\u6a21\u4efb\u52d9\u7684\u5be6\u8b49\u8b49\u660e\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4e3b\u5f35\uff0c\u7576\u63a1\u7528\u5e73\u65b9\u6b50\u5e7e\u91cc\u5f97\u7bc4\u6578\u4f5c\u70ba\u9a45\u52d5\u5c40\u90e8\u5b78\u7fd2\u7684\u9069\u7576\u6027\u51fd\u6578\u6642\uff0c\u6240\u7522\u751f\u7684 FFA \u7b49\u540c\u65bc\u65b0\u8d6b\u5e03\u5b78\u7fd2\u898f\u5247\u3002\u70ba\u4e86\u9a57\u8b49\u6b64\u7d50\u679c\uff0c\u6211\u5011\u6bd4\u8f03\u985e\u6bd4\u7db2\u8def\u4e2d FFA \u7684\u8a13\u7df4\u884c\u70ba\u8207\u5176\u5728\u8108\u885d\u795e\u7d93\u7db2\u8def\u4e2d\u7684\u8d6b\u5e03\u9069\u61c9\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0cFFA \u7684\u5169\u500b\u7248\u672c\u90fd\u7522\u751f\u985e\u4f3c\u7684\u6e96\u78ba\u5ea6\u548c\u6f5b\u5728\u5206\u4f48\u3002\u672c\u6587\u5831\u544a\u7684\u767c\u73fe\u63d0\u4f9b\u5be6\u8b49\uff0c\u5c07\u751f\u7269\u5b78\u7fd2\u898f\u5247\u8207\u76ee\u524d\u4f7f\u7528\u7684\u8a13\u7df4\u6f14\u7b97\u6cd5\u9023\u7d50\uff0c\u56e0\u6b64\u70ba\u5f9e FFA \u63a8\u8ad6\u51fa\u8d6b\u5e03\u5b78\u7fd2\u898f\u5247\u7684\u6b63\u9762\u7d50\u679c\u92ea\u8def\u3002\u540c\u6642\uff0c\u6211\u5011\u7684\u7d50\u679c\u6697\u793a\uff0c\u5728 FFA \u4e0b\u8a13\u7df4\u7684\u985e\u6bd4\u7db2\u8def\u53ef\u4ee5\u76f4\u63a5\u61c9\u7528\u65bc\u985e\u8166\u904b\u7b97\uff0c\u9032\u800c\u6e1b\u5c11\u80fd\u6e90\u4f7f\u7528\u4e26\u63d0\u5347\u904b\u7b97\u901f\u5ea6\u3002", "author": "Erik B. Terres-Escudero et.al.", "authors": "Erik B. Terres-Escudero, Javier Del Ser, Pablo Garc\u00eda-Bringas", "id": "2406.16479v1", "paper_url": "http://arxiv.org/abs/2406.16479v1", "repo": "https://github.com/erikberter/hebbian_ffa"}}