{"2405.10739": {"publish_time": "2024-05-17", "title": "Efficient Multimodal Large Language Models: A Survey", "paper_summary": "In the past year, Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable performance in tasks such as visual question answering, visual\nunderstanding and reasoning. However, the extensive model size and high\ntraining and inference costs have hindered the widespread application of MLLMs\nin academia and industry. Thus, studying efficient and lightweight MLLMs has\nenormous potential, especially in edge computing scenarios. In this survey, we\nprovide a comprehensive and systematic review of the current state of efficient\nMLLMs. Specifically, we summarize the timeline of representative efficient\nMLLMs, research state of efficient structures and strategies, and the\napplications. Finally, we discuss the limitations of current efficient MLLM\nresearch and promising future directions. Please refer to our GitHub repository\nfor more details:\nhttps://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.", "paper_summary_zh": "\u5728\u904e\u53bb\u4e00\u5e74\u4e2d\uff0c\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u5728\u8996\u89ba\u554f\u984c\u89e3\u7b54\u3001\u8996\u89ba\u7406\u89e3\u548c\u63a8\u7406\u7b49\u4efb\u52d9\u4e2d\u5c55\u73fe\u4e86\u5353\u8d8a\u7684\u8868\u73fe\u3002\u7136\u800c\uff0c\u9f90\u5927\u7684\u6a21\u578b\u898f\u6a21\u548c\u9ad8\u6602\u7684\u8a13\u7df4\u548c\u63a8\u8ad6\u6210\u672c\u963b\u7919\u4e86 MLLM \u5728\u5b78\u8853\u754c\u548c\u7522\u696d\u4e2d\u7684\u5ee3\u6cdb\u61c9\u7528\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u9ad8\u6548\u4e14\u8f15\u91cf\u7684 MLLM \u5177\u6709\u5de8\u5927\u7684\u6f5b\u529b\uff0c\u7279\u5225\u662f\u5728\u908a\u7de3\u904b\u7b97\u5834\u666f\u4e2d\u3002\u5728\u9019\u9805\u8abf\u67e5\u4e2d\uff0c\u6211\u5011\u5168\u9762\u4e14\u7cfb\u7d71\u5730\u56de\u9867\u4e86\u7576\u524d\u9ad8\u6548 MLLM \u7684\u73fe\u72c0\u3002\u5177\u9ad4\u800c\u8a00\uff0c\u6211\u5011\u7e3d\u7d50\u4e86\u4ee3\u8868\u6027\u9ad8\u6548 MLLM \u7684\u6642\u9593\u8868\u3001\u9ad8\u6548\u7d50\u69cb\u548c\u7b56\u7565\u7684\u7814\u7a76\u73fe\u72c0\uff0c\u4ee5\u53ca\u61c9\u7528\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8a0e\u8ad6\u4e86\u7576\u524d\u9ad8\u6548 MLLM \u7814\u7a76\u7684\u5c40\u9650\u6027\u4ee5\u53ca\u672a\u4f86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002\u6709\u95dc\u66f4\u591a\u8a73\u7d30\u8cc7\u8a0a\uff0c\u8acb\u53c3\u95b1\u6211\u5011\u7684 GitHub \u5132\u5b58\u5eab\uff1a\nhttps://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey\u3002", "author": "Yizhang Jin et.al.", "authors": "Yizhang Jin, Jian Li, Yexin Liu, Tianjun Gu, Kai Wu, Zhengkai Jiang, Muyang He, Bo Zhao, Xin Tan, Zhenye Gan, Yabiao Wang, Chengjie Wang, Lizhuang Ma", "id": "2405.10739v1", "paper_url": "http://arxiv.org/abs/2405.10739v1", "repo": "https://github.com/lijiannuist/efficient-multimodal-llms-survey"}}