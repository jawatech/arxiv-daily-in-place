{"2409.12183": {"publish_time": "2024-09-18", "title": "To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning", "paper_summary": "Chain-of-thought (CoT) via prompting is the de facto method for eliciting\nreasoning capabilities from large language models (LLMs). But for what kinds of\ntasks is this extra ``thinking'' really helpful? To analyze this, we conducted\na quantitative meta-analysis covering over 100 papers using CoT and ran our own\nevaluations of 20 datasets across 14 models. Our results show that CoT gives\nstrong performance benefits primarily on tasks involving math or logic, with\nmuch smaller gains on other types of tasks. On MMLU, directly generating the\nanswer without CoT leads to almost identical accuracy as CoT unless the\nquestion or model's response contains an equals sign, indicating symbolic\noperations and reasoning. Following this finding, we analyze the behavior of\nCoT on these problems by separating planning and execution and comparing\nagainst tool-augmented LLMs. Much of CoT's gain comes from improving symbolic\nexecution, but it underperforms relative to using a symbolic solver. Our\nresults indicate that CoT can be applied selectively, maintaining performance\nwhile saving inference costs. Furthermore, they suggest a need to move beyond\nprompt-based CoT to new paradigms that better leverage intermediate computation\nacross the whole range of LLM applications.", "paper_summary_zh": "\u900f\u904e\u63d0\u793a\u9032\u884c\u7684\u601d\u8003\u93c8 (CoT) \u662f\u5f9e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5f15\u767c\u63a8\u7406\u80fd\u529b\u7684\u5be6\u969b\u65b9\u6cd5\u3002\u4f46\u5c0d\u65bc\u54ea\u4e9b\u985e\u578b\u7684\u4efb\u52d9\uff0c\u9019\u7a2e\u984d\u5916\u7684\u300c\u601d\u8003\u300d\u771f\u7684\u6709\u5e6b\u52a9\uff1f\u70ba\u4e86\u5206\u6790\u9019\u4e00\u9ede\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u9805\u5b9a\u91cf\u5143\u5206\u6790\uff0c\u6db5\u84cb\u4e86 100 \u591a\u7bc7\u4f7f\u7528 CoT \u7684\u8ad6\u6587\uff0c\u4e26\u5c0d 14 \u500b\u6a21\u578b\u4e2d\u7684 20 \u500b\u8cc7\u6599\u96c6\u57f7\u884c\u4e86\u6211\u5011\u81ea\u5df1\u7684\u8a55\u4f30\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cCoT \u4e3b\u8981\u5728\u6d89\u53ca\u6578\u5b78\u6216\u908f\u8f2f\u7684\u4efb\u52d9\u4e0a\u63d0\u4f9b\u5f37\u5927\u7684\u6548\u80fd\u512a\u52e2\uff0c\u800c\u5728\u5176\u4ed6\u985e\u578b\u7684\u4efb\u52d9\u4e0a\u5247\u7372\u5f97\u7684\u6536\u76ca\u5c0f\u5f97\u591a\u3002\u5728 MMLU \u4e0a\uff0c\u76f4\u63a5\u7522\u751f\u7b54\u6848\u800c\u6c92\u6709 CoT \u6703\u5c0e\u81f4\u8207 CoT \u5e7e\u4e4e\u76f8\u540c\u7684\u6e96\u78ba\u5ea6\uff0c\u9664\u975e\u554f\u984c\u6216\u6a21\u578b\u7684\u56de\u61c9\u5305\u542b\u7b49\u865f\uff0c\u8868\u793a\u7b26\u865f\u904b\u7b97\u548c\u63a8\u7406\u3002\u6839\u64da\u9019\u4e00\u767c\u73fe\uff0c\u6211\u5011\u900f\u904e\u5206\u96e2\u898f\u5283\u548c\u57f7\u884c\uff0c\u4e26\u8207\u5de5\u5177\u589e\u5f37\u7684 LLM \u9032\u884c\u6bd4\u8f03\uff0c\u5206\u6790\u4e86 CoT \u5728\u9019\u4e9b\u554f\u984c\u4e0a\u7684\u884c\u70ba\u3002CoT \u7684\u8a31\u591a\u6536\u76ca\u4f86\u81ea\u65bc\u6539\u9032\u7b26\u865f\u57f7\u884c\uff0c\u4f46\u5b83\u76f8\u5c0d\u65bc\u4f7f\u7528\u7b26\u865f\u6c42\u89e3\u5668\u7684\u57f7\u884c\u6548\u679c\u8f03\u5dee\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cCoT \u53ef\u4ee5\u6709\u9078\u64c7\u5730\u61c9\u7528\uff0c\u5728\u7bc0\u7701\u63a8\u7406\u6210\u672c\u7684\u540c\u6642\u7dad\u6301\u6548\u80fd\u3002\u6b64\u5916\uff0c\u5b83\u5011\u8868\u660e\u9700\u8981\u8d85\u8d8a\u57fa\u65bc\u63d0\u793a\u7684 CoT\uff0c\u8f49\u5411\u65b0\u7684\u7bc4\u4f8b\uff0c\u4ee5\u66f4\u597d\u5730\u5229\u7528 LLM \u61c9\u7528\u7a0b\u5f0f\u7684\u6574\u500b\u7bc4\u570d\u5167\u7684\u4e2d\u9593\u904b\u7b97\u3002", "author": "Zayne Sprague et.al.", "authors": "Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett", "id": "2409.12183v1", "paper_url": "http://arxiv.org/abs/2409.12183v1", "repo": "null"}}