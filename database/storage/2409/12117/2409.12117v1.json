{"2409.12117": {"publish_time": "2024-09-18", "title": "Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference", "paper_summary": "Large language models (LLMs) have significantly advanced audio processing\nthrough audio codecs that convert audio into discrete tokens, enabling the\napplication of language modeling techniques to audio data. However, audio\ncodecs often operate at high frame rates, resulting in slow training and\ninference, especially for autoregressive models. To address this challenge, we\npresent the Low Frame-rate Speech Codec (LFSC): a neural audio codec that\nleverages finite scalar quantization and adversarial training with large speech\nlanguage models to achieve high-quality audio compression with a 1.89 kbps\nbitrate and 21.5 frames per second. We demonstrate that our novel codec can\nmake the inference of LLM-based text-to-speech models around three times faster\nwhile improving intelligibility and producing quality comparable to previous\nmodels.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u900f\u904e\u5c07\u97f3\u8a0a\u8f49\u63db\u70ba\u96e2\u6563\u7b26\u865f\u7684\u97f3\u8a0a\u7de8\u89e3\u78bc\u5668\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u97f3\u8a0a\u8655\u7406\uff0c\u4e26\u80fd\u5c07\u8a9e\u8a00\u6a21\u578b\u6280\u8853\u61c9\u7528\u65bc\u97f3\u8a0a\u8cc7\u6599\u3002\u7136\u800c\uff0c\u97f3\u8a0a\u7de8\u89e3\u78bc\u5668\u901a\u5e38\u4ee5\u9ad8\u5e40\u7387\u904b\u4f5c\uff0c\u5c0e\u81f4\u8a13\u7df4\u548c\u63a8\u8ad6\u901f\u5ea6\u7de9\u6162\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u81ea\u8ff4\u6b78\u6a21\u578b\u800c\u8a00\u3002\u70ba\u4e86\u61c9\u5c0d\u6b64\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4f4e\u5e40\u7387\u8a9e\u97f3\u7de8\u89e3\u78bc\u5668 (LFSC)\uff1a\u4e00\u7a2e\u795e\u7d93\u97f3\u8a0a\u7de8\u89e3\u78bc\u5668\uff0c\u5b83\u5229\u7528\u6709\u9650\u6a19\u91cf\u91cf\u5316\u548c\u5c0d\u6297\u8a13\u7df4\uff0c\u7d50\u5408\u5927\u578b\u8a9e\u97f3\u8a9e\u8a00\u6a21\u578b\uff0c\u4ee5 1.89 kbps \u7684\u6bd4\u7279\u7387\u548c\u6bcf\u79d2 21.5 \u5e40\uff0c\u9054\u6210\u9ad8\u54c1\u8cea\u7684\u97f3\u8a0a\u58d3\u7e2e\u3002\u6211\u5011\u8b49\u660e\u4e86\u6211\u5011\u7684\u65b0\u7a4e\u7de8\u89e3\u78bc\u5668\u53ef\u4ee5\u8b93\u57fa\u65bc LLM \u7684\u6587\u5b57\u8f49\u8a9e\u97f3\u6a21\u578b\u7684\u63a8\u8ad6\u901f\u5ea6\u5feb\u4e0a\u7d04\u4e09\u500d\uff0c\u540c\u6642\u63d0\u5347\u53ef\u61c2\u5ea6\uff0c\u4e26\u7522\u751f\u8207\u5148\u524d\u6a21\u578b\u76f8\u7576\u7684\u54c1\u8cea\u3002", "author": "Edresson Casanova et.al.", "authors": "Edresson Casanova, Ryan Langman, Paarth Neekhara, Shehzeen Hussain, Jason Li, Subhankar Ghosh, Ante Juki\u0107, Sang-gil Lee", "id": "2409.12117v1", "paper_url": "http://arxiv.org/abs/2409.12117v1", "repo": "null"}}