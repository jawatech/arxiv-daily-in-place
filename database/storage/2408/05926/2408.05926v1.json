{"2408.05926": {"publish_time": "2024-08-12", "title": "BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation", "paper_summary": "Multimodal Dialogue Response Generation (MDRG) is a recently proposed task\nwhere the model needs to generate responses in texts, images, or a blend of\nboth based on the dialogue context. Due to the lack of a large-scale dataset\nspecifically for this task and the benefits of leveraging powerful pre-trained\nmodels, previous work relies on the text modality as an intermediary step for\nboth the image input and output of the model rather than adopting an end-to-end\napproach. However, this approach can overlook crucial information about the\nimage, hindering 1) image-grounded text response and 2) consistency of objects\nin the image response. In this paper, we propose BI-MDRG that bridges the\nresponse generation path such that the image history information is utilized\nfor enhanced relevance of text responses to the image content and the\nconsistency of objects in sequential image responses. Through extensive\nexperiments on the multimodal dialogue benchmark dataset, we show that BI-MDRG\ncan effectively increase the quality of multimodal dialogue. Additionally,\nrecognizing the gap in benchmark datasets for evaluating the image consistency\nin multimodal dialogue, we have created a curated set of 300 dialogues\nannotated to track object consistency across conversations.", "paper_summary_zh": "\u591a\u6a21\u6001\u5bf9\u8bdd\u54cd\u5e94\u751f\u6210 (MDRG) \u662f\u4e00\u9879\u6700\u8fd1\u63d0\u51fa\u7684\u4efb\u52a1\uff0c\u5176\u4e2d\u6a21\u578b\u9700\u8981\u6839\u636e\u5bf9\u8bdd\u8bed\u5883\u751f\u6210\u6587\u672c\u3001\u56fe\u50cf\u6216\u4e24\u8005\u7684\u6df7\u5408\u5f62\u5f0f\u7684\u54cd\u5e94\u3002\u7531\u4e8e\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u6b64\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4ee5\u53ca\u5229\u7528\u5f3a\u5927\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u597d\u5904\uff0c\u4ee5\u524d\u7684\u5de5\u4f5c\u4f9d\u8d56\u4e8e\u6587\u672c\u6a21\u6001\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u5165\u548c\u8f93\u51fa\u7684\u4e2d\u95f4\u6b65\u9aa4\uff0c\u800c\u4e0d\u662f\u91c7\u7528\u7aef\u5230\u7aef\u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u4f1a\u5ffd\u7565\u6709\u5173\u56fe\u50cf\u7684\u5173\u952e\u4fe1\u606f\uff0c\u4ece\u800c\u963b\u788d 1) \u4ee5\u56fe\u50cf\u4e3a\u57fa\u7840\u7684\u6587\u672c\u54cd\u5e94\u548c 2) \u56fe\u50cf\u54cd\u5e94\u4e2d\u5bf9\u8c61\u7684\u4e00\u81f4\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 BI-MDRG\uff0c\u5b83\u5f25\u5408\u4e86\u54cd\u5e94\u751f\u6210\u8def\u5f84\uff0c\u4ee5\u4fbf\u56fe\u50cf\u5386\u53f2\u4fe1\u606f\u88ab\u7528\u4e8e\u589e\u5f3a\u6587\u672c\u54cd\u5e94\u4e0e\u56fe\u50cf\u5185\u5bb9\u7684\u76f8\u5173\u6027\u4ee5\u53ca\u987a\u5e8f\u56fe\u50cf\u54cd\u5e94\u4e2d\u5bf9\u8c61\u7684\u4e00\u81f4\u6027\u3002\u901a\u8fc7\u5bf9\u591a\u6a21\u6001\u5bf9\u8bdd\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u6211\u4eec\u8868\u660e BI-MDRG \u53ef\u4ee5\u6709\u6548\u5730\u63d0\u9ad8\u591a\u6a21\u6001\u5bf9\u8bdd\u7684\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u8ba4\u8bc6\u5230\u5728\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5bf9\u8bdd\u4e2d\u56fe\u50cf\u4e00\u81f4\u6027\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u7684\u5dee\u8ddd\uff0c\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u7cbe\u9009\u7684 300 \u4e2a\u5bf9\u8bdd\u96c6\uff0c\u8fd9\u4e9b\u5bf9\u8bdd\u96c6\u7ecf\u8fc7\u6ce8\u91ca\u4ee5\u8ddf\u8e2a\u5bf9\u8bdd\u4e2d\u7684\u5bf9\u8c61\u4e00\u81f4\u6027\u3002", "author": "Hee Suk Yoon et.al.", "authors": "Hee Suk Yoon, Eunseop Yoon, Joshua Tian Jin Tee, Kang Zhang, Yu-Jung Heo, Du-Seong Chang, Chang D. Yoo", "id": "2408.05926v1", "paper_url": "http://arxiv.org/abs/2408.05926v1", "repo": "https://github.com/hee-suk-yoon/bi-mdrg"}}