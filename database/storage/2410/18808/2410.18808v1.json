{"2410.18808": {"publish_time": "2024-10-24", "title": "Delving into the Reversal Curse: How Far Can Large Language Models Generalize?", "paper_summary": "While large language models (LLMs) showcase unprecedented capabilities, they\nalso exhibit certain inherent limitations when facing seemingly trivial tasks.\nA prime example is the recently debated \"reversal curse\", which surfaces when\nmodels, having been trained on the fact \"A is B\", struggle to generalize this\nknowledge to infer that \"B is A\". In this paper, we examine the manifestation\nof the reversal curse across various tasks and delve into both the\ngeneralization abilities and the problem-solving mechanisms of LLMs. This\ninvestigation leads to a series of significant insights: (1) LLMs are able to\ngeneralize to \"B is A\" when both A and B are presented in the context as in the\ncase of a multiple-choice question. (2) This generalization ability is highly\ncorrelated to the structure of the fact \"A is B\" in the training documents. For\nexample, this generalization only applies to biographies structured in \"[Name]\nis [Description]\" but not to \"[Description] is [Name]\". (3) We propose and\nverify the hypothesis that LLMs possess an inherent bias in fact recalling\nduring knowledge application, which explains and underscores the importance of\nthe document structure to successful learning. (4) The negative impact of this\nbias on the downstream performance of LLMs can hardly be mitigated through\ntraining alone. Based on these intriguing findings, our work not only presents\na novel perspective for interpreting LLMs' generalization abilities from their\nintrinsic working mechanism but also provides new insights for the development\nof more effective learning methods for LLMs.", "paper_summary_zh": "<paragraph>\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u73fe\u51fa\u524d\u6240\u672a\u6709\u7684\u80fd\u529b\uff0c\u4f46\u5728\u9762\u5c0d\u770b\u4f3c\u5fae\u4e0d\u8db3\u9053\u7684\u4efb\u52d9\u6642\uff0c\u5b83\u5011\u4e5f\u8868\u73fe\u51fa\u67d0\u4e9b\u56fa\u6709\u7684\u9650\u5236\u3002\u4e00\u500b\u4e3b\u8981\u7684\u4f8b\u5b50\u662f\u6700\u8fd1\u722d\u8ad6\u7684\u300c\u9006\u8f49\u8a5b\u5492\u300d\uff0c\u7576\u6a21\u578b\u5728\u300cA \u662f B\u300d\u7684\u4e8b\u5be6\u4e0a\u53d7\u904e\u8a13\u7df4\u5f8c\uff0c\u537b\u96e3\u4ee5\u5c07\u6b64\u77e5\u8b58\u6982\u62ec\u70ba\u63a8\u8ad6\u300cB \u662f A\u300d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u9006\u8f49\u8a5b\u5492\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\uff0c\u4e26\u6df1\u5165\u63a2\u8a0e\u4e86 LLM \u7684\u6982\u62ec\u80fd\u529b\u548c\u554f\u984c\u89e3\u6c7a\u6a5f\u5236\u3002\u9019\u9805\u8abf\u67e5\u5f97\u51fa\u4e00\u7cfb\u5217\u91cd\u8981\u7684\u898b\u89e3\uff1a(1) \u7576 A \u548c B \u90fd\u5728\u4e0a\u4e0b\u6587\u4e2d\u5448\u73fe\u6642\uff0cLLM \u80fd\u5920\u6982\u62ec\u70ba\u300cB \u662f A\u300d\uff0c\u5c31\u50cf\u5728\u591a\u9078\u984c\u7684\u60c5\u6cc1\u4e0b\u3002(2) \u9019\u7a2e\u6982\u62ec\u80fd\u529b\u8207\u8a13\u7df4\u6587\u4ef6\u4e2d\u300cA \u662f B\u300d\u7684\u4e8b\u5be6\u7d50\u69cb\u9ad8\u5ea6\u76f8\u95dc\u3002\u4f8b\u5982\uff0c\u9019\u7a2e\u6982\u62ec\u50c5\u9069\u7528\u65bc\u7d50\u69cb\u70ba\u300c[\u540d\u7a31] \u662f [\u63cf\u8ff0]\u300d\u7684\u50b3\u8a18\uff0c\u4f46\u4e0d\u9069\u7528\u65bc\u300c[\u63cf\u8ff0] \u662f [\u540d\u7a31]\u300d\u3002(3) \u6211\u5011\u63d0\u51fa\u4e26\u9a57\u8b49\u4e86 LLM \u5728\u77e5\u8b58\u61c9\u7528\u904e\u7a0b\u4e2d\u5177\u6709\u5167\u5728\u4e8b\u5be6\u56de\u61b6\u504f\u5dee\u7684\u5047\u8a2d\uff0c\u9019\u89e3\u91cb\u4e26\u5f37\u8abf\u4e86\u6587\u4ef6\u7d50\u69cb\u5c0d\u6210\u529f\u5b78\u7fd2\u7684\u91cd\u8981\u6027\u3002(4) \u50c5\u900f\u904e\u8a13\u7df4\u5e7e\u4e4e\u7121\u6cd5\u6e1b\u8f15\u9019\u7a2e\u504f\u5dee\u5c0d LLM \u4e0b\u6e38\u6548\u80fd\u7684\u8ca0\u9762\u5f71\u97ff\u3002\u6839\u64da\u9019\u4e9b\u6709\u8da3\u7684\u767c\u73fe\uff0c\u6211\u5011\u7684\u7814\u7a76\u4e0d\u50c5\u5f9e\u5176\u5167\u5728\u5de5\u4f5c\u6a5f\u5236\u70ba\u89e3\u91cb LLM \u7684\u6982\u62ec\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u89c0\u9ede\uff0c\u9084\u70ba LLM \u66f4\u6709\u6548\u7684\u5b78\u7fd2\u65b9\u6cd5\u7684\u958b\u767c\u63d0\u4f9b\u4e86\u65b0\u7684\u898b\u89e3\u3002</paragraph>", "author": "Zhengkai Lin et.al.", "authors": "Zhengkai Lin, Zhihang Fu, Kai Liu, Liang Xie, Binbin Lin, Wenxiao Wang, Deng Cai, Yue Wu, Jieping Ye", "id": "2410.18808v1", "paper_url": "http://arxiv.org/abs/2410.18808v1", "repo": "null"}}