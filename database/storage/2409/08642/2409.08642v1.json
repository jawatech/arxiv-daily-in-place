{"2409.08642": {"publish_time": "2024-09-13", "title": "CPL: Critical Planning Step Learning Boosts LLM Generalization in Reasoning Tasks", "paper_summary": "Post-training large language models (LLMs) to develop reasoning capabilities\nhas proven effective across diverse domains, such as mathematical reasoning and\ncode generation. However, existing methods primarily focus on improving\ntask-specific reasoning but have not adequately addressed the model's\ngeneralization capabilities across a broader range of reasoning tasks. To\ntackle this challenge, we introduce Critical Planning Step Learning (CPL),\nwhich leverages Monte Carlo Tree Search (MCTS) to explore diverse planning\nsteps in multi-step reasoning tasks. Based on long-term outcomes, CPL learns\nstep-level planning preferences to improve the model's planning capabilities\nand, consequently, its general reasoning capabilities. Furthermore, while\neffective in many scenarios for aligning LLMs, existing preference learning\napproaches like Direct Preference Optimization (DPO) struggle with complex\nmulti-step reasoning tasks due to their inability to capture fine-grained\nsupervision at each step. We propose Step-level Advantage Preference\nOptimization (Step-APO), which integrates an advantage estimate for step-level\npreference pairs obtained via MCTS into the DPO. This enables the model to more\neffectively learn critical intermediate planning steps, thereby further\nimproving its generalization in reasoning tasks. Experimental results\ndemonstrate that our method, trained exclusively on GSM8K and MATH, not only\nsignificantly improves performance on GSM8K (+10.5%) and MATH (+6.5%), but also\nenhances out-of-domain reasoning benchmarks, such as ARC-C (+4.0%), BBH\n(+1.8%), MMLU-STEM (+2.2%), and MMLU (+0.9%).", "paper_summary_zh": "<paragraph>\u8a13\u7df4\u5f8c\u7684\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u8b49\u660e\u80fd\u6709\u6548\u958b\u767c\u63a8\u7406\u80fd\u529b\uff0c\u6db5\u84cb\u5404\u7a2e\u9818\u57df\uff0c\u4f8b\u5982\u6578\u5b78\u63a8\u7406\u548c\u7a0b\u5f0f\u78bc\u751f\u6210\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u4e3b\u8981\u8457\u91cd\u65bc\u6539\u5584\u7279\u5b9a\u4efb\u52d9\u7684\u63a8\u7406\uff0c\u4f46\u4e26\u672a\u5145\u5206\u89e3\u6c7a\u6a21\u578b\u5728\u66f4\u5ee3\u6cdb\u63a8\u7406\u4efb\u52d9\u4e2d\u7684\u6982\u5316\u80fd\u529b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86\u300c\u95dc\u9375\u898f\u5283\u6b65\u9a5f\u5b78\u7fd2\u300d(CPL)\uff0c\u5b83\u5229\u7528\u8499\u5730\u5361\u7f85\u6a39\u72c0\u641c\u5c0b (MCTS) \u4f86\u63a2\u7d22\u591a\u6b65\u9a5f\u63a8\u7406\u4efb\u52d9\u4e2d\u7684\u4e0d\u540c\u898f\u5283\u6b65\u9a5f\u3002\u57fa\u65bc\u9577\u671f\u7d50\u679c\uff0cCPL \u5b78\u7fd2\u6b65\u9a5f\u5c64\u7d1a\u7684\u898f\u5283\u504f\u597d\uff0c\u4ee5\u6539\u5584\u6a21\u578b\u7684\u898f\u5283\u80fd\u529b\uff0c\u9032\u800c\u6539\u5584\u5176\u4e00\u822c\u63a8\u7406\u80fd\u529b\u3002\u6b64\u5916\uff0c\u96d6\u7136\u73fe\u6709\u504f\u597d\u5b78\u7fd2\u65b9\u6cd5\uff08\u4f8b\u5982\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO)\uff09\u5728\u8a31\u591a\u60c5\u5883\u4e2d\u80fd\u6709\u6548\u8abf\u6574 LLM\uff0c\u4f46\u5c0d\u65bc\u8907\u96dc\u7684\u591a\u6b65\u9a5f\u63a8\u7406\u4efb\u52d9\u537b\u96e3\u4ee5\u61c9\u4ed8\uff0c\u56e0\u70ba\u5b83\u5011\u7121\u6cd5\u5728\u6bcf\u500b\u6b65\u9a5f\u4e2d\u64f7\u53d6\u7d30\u7dfb\u7684\u76e3\u7763\u3002\u6211\u5011\u63d0\u51fa\u4e86\u300c\u6b65\u9a5f\u5c64\u7d1a\u512a\u52e2\u504f\u597d\u6700\u4f73\u5316\u300d(Step-APO)\uff0c\u5b83\u5c07\u900f\u904e MCTS \u7372\u5f97\u7684\u6b65\u9a5f\u5c64\u7d1a\u504f\u597d\u5c0d\u96c6\u6210\u7684\u512a\u52e2\u4f30\u8a08\u503c\u7d0d\u5165 DPO \u4e2d\u3002\u9019\u4f7f\u6a21\u578b\u80fd\u66f4\u6709\u6548\u5730\u5b78\u7fd2\u95dc\u9375\u7684\u4e2d\u9593\u898f\u5283\u6b65\u9a5f\uff0c\u9032\u800c\u9032\u4e00\u6b65\u6539\u5584\u5176\u5728\u63a8\u7406\u4efb\u52d9\u4e2d\u7684\u6982\u5316\u80fd\u529b\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u50c5\u5728 GSM8K \u548c MATH \u4e0a\u63a5\u53d7\u8a13\u7df4\uff0c\u4e0d\u50c5\u986f\u8457\u63d0\u5347\u4e86 GSM8K (+10.5%) \u548c MATH (+6.5%) \u7684\u6548\u80fd\uff0c\u4e5f\u63d0\u5347\u4e86\u9818\u57df\u5916\u7684\u63a8\u7406\u57fa\u6e96\uff0c\u4f8b\u5982 ARC-C (+4.0%)\u3001BBH (+1.8%)\u3001MMLU-STEM (+2.2%) \u548c MMLU (+0.9%)\u3002</paragraph>", "author": "Tianlong Wang et.al.", "authors": "Tianlong Wang, Xueting Han, Jing Bai", "id": "2409.08642v1", "paper_url": "http://arxiv.org/abs/2409.08642v1", "repo": "null"}}