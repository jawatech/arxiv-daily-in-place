{"2408.16966": {"publish_time": "2024-08-30", "title": "UserSumBench: A Benchmark Framework for Evaluating User Summarization Approaches", "paper_summary": "Large language models (LLMs) have shown remarkable capabilities in generating\nuser summaries from a long list of raw user activity data. These summaries\ncapture essential user information such as preferences and interests, and\ntherefore are invaluable for LLM-based personalization applications, such as\nexplainable recommender systems. However, the development of new summarization\ntechniques is hindered by the lack of ground-truth labels, the inherent\nsubjectivity of user summaries, and human evaluation which is often costly and\ntime-consuming. To address these challenges, we introduce \\UserSumBench, a\nbenchmark framework designed to facilitate iterative development of LLM-based\nsummarization approaches. This framework offers two key components: (1) A\nreference-free summary quality metric. We show that this metric is effective\nand aligned with human preferences across three diverse datasets (MovieLens,\nYelp and Amazon Review). (2) A novel robust summarization method that leverages\ntime-hierarchical summarizer and self-critique verifier to produce high-quality\nsummaries while eliminating hallucination. This method serves as a strong\nbaseline for further innovation in summarization techniques.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u6839\u64da\u5927\u91cf\u539f\u59cb\u4f7f\u7528\u8005\u6d3b\u52d5\u8cc7\u6599\u7522\u751f\u4f7f\u7528\u8005\u6458\u8981\u65b9\u9762\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\u3002\u9019\u4e9b\u6458\u8981\u64f7\u53d6\u4e86\u4f7f\u7528\u8005\u7684\u57fa\u672c\u8cc7\u8a0a\uff0c\u4f8b\u5982\u504f\u597d\u548c\u8208\u8da3\uff0c\u56e0\u6b64\u5c0d\u65bc\u57fa\u65bc LLM \u7684\u500b\u4eba\u5316\u61c9\u7528\u7a0b\u5f0f\u4f86\u8aaa\u975e\u5e38\u6709\u50f9\u503c\uff0c\u4f8b\u5982\u53ef\u89e3\u91cb\u7684\u63a8\u85a6\u7cfb\u7d71\u3002\u7136\u800c\uff0c\u65b0\u7684\u6458\u8981\u6280\u8853\u7684\u767c\u5c55\u53d7\u5230\u7f3a\u4e4f\u57fa\u672c\u4e8b\u5be6\u6a19\u7c64\u3001\u4f7f\u7528\u8005\u6458\u8981\u56fa\u6709\u7684\u4e3b\u89c0\u6027\u4ee5\u53ca\u901a\u5e38\u6210\u672c\u9ad8\u4e14\u8017\u6642\u7684\u8a55\u4f30\u6240\u963b\u7919\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 \\UserSumBench\uff0c\u4e00\u500b\u57fa\u6e96\u67b6\u69cb\uff0c\u65e8\u5728\u4fc3\u9032\u57fa\u65bc LLM \u7684\u6458\u8981\u65b9\u6cd5\u7684\u8fed\u4ee3\u958b\u767c\u3002\u6b64\u67b6\u69cb\u63d0\u4f9b\u4e86\u5169\u500b\u95dc\u9375\u7d44\u6210\u90e8\u5206\uff1a(1) \u7121\u53c3\u8003\u6458\u8981\u54c1\u8cea\u6307\u6a19\u3002\u6211\u5011\u5c55\u793a\u4e86\u6b64\u6307\u6a19\u6709\u6548\u4e14\u8207\u4e09\u500b\u4e0d\u540c\u8cc7\u6599\u96c6 (MovieLens\u3001Yelp \u548c Amazon Review) \u4e2d\u7684\u4eba\u985e\u504f\u597d\u4e00\u81f4\u3002(2) \u4e00\u7a2e\u65b0\u7a4e\u7684\u7a69\u5065\u6458\u8981\u65b9\u6cd5\uff0c\u5229\u7528\u6642\u9593\u968e\u5c64\u6458\u8981\u5668\u548c\u81ea\u6211\u6279\u8a55\u9a57\u8b49\u5668\u4f86\u7522\u751f\u9ad8\u54c1\u8cea\u6458\u8981\uff0c\u540c\u6642\u6d88\u9664\u5e7b\u89ba\u3002\u6b64\u65b9\u6cd5\u4f5c\u70ba\u6458\u8981\u6280\u8853\u9032\u4e00\u6b65\u5275\u65b0\u7684\u5f37\u5927\u57fa\u7dda\u3002", "author": "Chao Wang et.al.", "authors": "Chao Wang, Neo Wu, Lin Ning, Luyang Liu, Jun Xie, Shawn O'Banion, Bradley Green", "id": "2408.16966v1", "paper_url": "http://arxiv.org/abs/2408.16966v1", "repo": "null"}}