{"2407.08989": {"publish_time": "2024-07-12", "title": "Robustness of LLMs to Perturbations in Text", "paper_summary": "Having a clean dataset has been the foundational assumption of most natural\nlanguage processing (NLP) systems. However, properly written text is rarely\nfound in real-world scenarios and hence, oftentimes invalidates the\naforementioned foundational assumption. Recently, Large language models (LLMs)\nhave shown impressive performance, but can they handle the inevitable noise in\nreal-world data? This work tackles this critical question by investigating\nLLMs' resilience against morphological variations in text. To that end, we\nartificially introduce varying levels of noise into a diverse set of datasets\nand systematically evaluate LLMs' robustness against the corrupt variations of\nthe original text. Our findings show that contrary to popular beliefs,\ngenerative LLMs are quiet robust to noisy perturbations in text. This is a\ndeparture from pre-trained models like BERT or RoBERTa whose performance has\nbeen shown to be sensitive to deteriorating noisy text. Additionally, we test\nLLMs' resilience on multiple real-world benchmarks that closely mimic commonly\nfound errors in the wild. With minimal prompting, LLMs achieve a new\nstate-of-the-art on the benchmark tasks of Grammar Error Correction (GEC) and\nLexical Semantic Change (LSC). To empower future research, we also release a\ndataset annotated by humans stating their preference for LLM vs.\nhuman-corrected outputs along with the code to reproduce our results.", "paper_summary_zh": "<paragraph>\u64c1\u6709\u4e7e\u6de8\u7684\u8cc7\u6599\u96c6\u4e00\u76f4\u662f\u5927\u591a\u6578\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u7cfb\u7d71\u7684\u57fa\u672c\u5047\u8a2d\u3002\u7136\u800c\uff0c\u5728\u73fe\u5be6\u4e16\u754c\u7684\u5834\u666f\u4e2d\u5f88\u5c11\u6703\u767c\u73fe\u5beb\u5f97\u5f88\u597d\u7684\u6587\u5b57\uff0c\u56e0\u6b64\uff0c\u9019\u5e38\u5e38\u6703\u4f7f\u4e0a\u8ff0\u7684\u57fa\u672c\u5047\u8a2d\u5931\u6548\u3002\u6700\u8fd1\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u7d93\u5c55\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6548\u80fd\uff0c\u4f46\u662f\u5b83\u5011\u80fd\u8655\u7406\u73fe\u5be6\u4e16\u754c\u8cc7\u6599\u4e2d\u96e3\u4ee5\u907f\u514d\u7684\u96dc\u8a0a\u55ce\uff1f\u9019\u9805\u7814\u7a76\u900f\u904e\u8abf\u67e5 LLM \u5c0d\u6587\u5b57\u5f62\u614b\u8b8a\u5316\u6240\u5c55\u73fe\u7684\u97cc\u6027\uff0c\u4f86\u63a2\u8a0e\u9019\u500b\u95dc\u9375\u554f\u984c\u3002\u70ba\u6b64\uff0c\u6211\u5011\u4eba\u5de5\u5728\u5404\u7a2e\u4e0d\u540c\u7684\u8cc7\u6599\u96c6\u4e2d\u52a0\u5165\u4e0d\u540c\u7a0b\u5ea6\u7684\u96dc\u8a0a\uff0c\u4e26\u7cfb\u7d71\u6027\u5730\u8a55\u4f30 LLM \u5c0d\u539f\u59cb\u6587\u5b57\u7684\u932f\u8aa4\u8b8a\u5f62\u7684\u7a69\u5065\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u8207\u666e\u904d\u7684\u770b\u6cd5\u76f8\u53cd\uff0c\u751f\u6210\u5f0f LLM \u5c0d\u65bc\u6587\u5b57\u4e2d\u7684\u96dc\u8a0a\u64fe\u52d5\u76f8\u7576\u7a69\u5065\u3002\u9019\u8207 BERT \u6216 RoBERTa \u7b49\u9810\u5148\u8a13\u7df4\u7684\u6a21\u578b\u4e0d\u540c\uff0c\u5df2\u8b49\u5be6\u5176\u6548\u80fd\u6703\u53d7\u5230\u96dc\u8a0a\u6587\u5b57\u60e1\u5316\u7684\u5f71\u97ff\u3002\u6b64\u5916\uff0c\u6211\u5011\u5728\u591a\u500b\u73fe\u5be6\u4e16\u754c\u7684\u57fa\u6e96\u4e0a\u6e2c\u8a66 LLM \u7684\u97cc\u6027\uff0c\u9019\u4e9b\u57fa\u6e96\u7dca\u5bc6\u6a21\u64ec\u5728\u91ce\u5916\u5e38\u898b\u7684\u932f\u8aa4\u3002\u5728\u6700\u5c11\u7684\u63d0\u793a\u4e0b\uff0cLLM \u5728\u8a9e\u6cd5\u932f\u8aa4\u6821\u6b63 (GEC) \u548c\u8a5e\u5f59\u8a9e\u7fa9\u6539\u8b8a (LSC) \u7684\u57fa\u6e96\u4efb\u52d9\u4e0a\u9054\u5230\u4e86\u65b0\u7684\u6700\u5148\u9032\u6c34\u6e96\u3002\u70ba\u4e86\u8ce6\u80fd\u672a\u4f86\u7684\u7814\u7a76\uff0c\u6211\u5011\u4e5f\u91cb\u51fa\u4e00\u500b\u7531\u4eba\u985e\u6a19\u8a3b\u7684\u8cc7\u6599\u96c6\uff0c\u8aaa\u660e\u4ed6\u5011\u504f\u597d LLM \u6216\u4eba\u70ba\u6821\u6b63\u7684\u8f38\u51fa\uff0c\u4ee5\u53ca\u7528\u65bc\u91cd\u73fe\u6211\u5011\u7d50\u679c\u7684\u7a0b\u5f0f\u78bc\u3002</paragraph>", "author": "Ayush Singh et.al.", "authors": "Ayush Singh, Navpreet Singh, Shubham Vatsal", "id": "2407.08989v1", "paper_url": "http://arxiv.org/abs/2407.08989v1", "repo": "null"}}