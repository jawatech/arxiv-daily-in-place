{"2408.12575": {"publish_time": "2024-08-22", "title": "Enhanced Parking Perception by Multi-Task Fisheye Cross-view Transformers", "paper_summary": "Current parking area perception algorithms primarily focus on detecting\nvacant slots within a limited range, relying on error-prone homographic\nprojection for both labeling and inference. However, recent advancements in\nAdvanced Driver Assistance System (ADAS) require interaction with end-users\nthrough comprehensive and intelligent Human-Machine Interfaces (HMIs). These\ninterfaces should present a complete perception of the parking area going from\ndistinguishing vacant slots' entry lines to the orientation of other parked\nvehicles. This paper introduces Multi-Task Fisheye Cross View Transformers (MT\nF-CVT), which leverages features from a four-camera fisheye Surround-view\nCamera System (SVCS) with multihead attentions to create a detailed Bird-Eye\nView (BEV) grid feature map. Features are processed by both a segmentation\ndecoder and a Polygon-Yolo based object detection decoder for parking slots and\nvehicles. Trained on data labeled using LiDAR, MT F-CVT positions objects\nwithin a 25m x 25m real open-road scenes with an average error of only 20 cm.\nOur larger model achieves an F-1 score of 0.89. Moreover the smaller model\noperates at 16 fps on an Nvidia Jetson Orin embedded board, with similar\ndetection results to the larger one. MT F-CVT demonstrates robust\ngeneralization capability across different vehicles and camera rig\nconfigurations. A demo video from an unseen vehicle and camera rig is available\nat: https://streamable.com/jjw54x.", "paper_summary_zh": "\u76ee\u524d\u505c\u8eca\u5834\u611f\u77e5\u6f14\u7b97\u6cd5\u4e3b\u8981\u5c08\u6ce8\u65bc\u5075\u6e2c\u6709\u9650\u7bc4\u570d\u5167\u7684\u7a7a\u4f4d\uff0c\u4f9d\u8cf4\u5bb9\u6613\u51fa\u932f\u7684\u540c\u5f62\u6295\u5f71\u9032\u884c\u6a19\u8a18\u548c\u63a8\u8ad6\u3002\u7136\u800c\uff0c\u9032\u968e\u99d5\u99db\u8f14\u52a9\u7cfb\u7d71 (ADAS) \u7684\u6700\u65b0\u9032\u5c55\u9700\u8981\u900f\u904e\u5168\u9762\u4e14\u667a\u6167\u7684\u4eba\u6a5f\u4ecb\u9762 (HMI) \u8207\u4f7f\u7528\u8005\u4e92\u52d5\u3002\u9019\u4e9b\u4ecb\u9762\u61c9\u8a72\u5448\u73fe\u505c\u8eca\u5834\u7684\u5b8c\u6574\u611f\u77e5\uff0c\u5f9e\u8fa8\u5225\u7a7a\u4f4d\u7684\u5165\u53e3\u7dda\u5230\u5176\u4ed6\u505c\u8eca\u8eca\u8f1b\u7684\u65b9\u5411\u3002\u672c\u6587\u4ecb\u7d39\u591a\u4efb\u52d9\u9b5a\u773c\u4ea4\u53c9\u8996\u89d2Transformer (MT F-CVT)\uff0c\u5b83\u5229\u7528\u4f86\u81ea\u56db\u93e1\u982d\u9b5a\u773c\u74b0\u666f\u651d\u5f71\u7cfb\u7d71 (SVCS) \u7684\u7279\u5fb5\u548c\u591a\u982d\u6ce8\u610f\u529b\u4f86\u5efa\u7acb\u8a73\u7d30\u7684\u9ce5\u77b0\u8996\u89d2 (BEV) \u683c\u7dda\u7279\u5fb5\u5716\u3002\u7279\u5fb5\u7531\u5206\u5272\u89e3\u78bc\u5668\u548c\u57fa\u65bc Polygon-Yolo \u7684\u7269\u4ef6\u5075\u6e2c\u89e3\u78bc\u5668\u8655\u7406\uff0c\u7528\u65bc\u505c\u8eca\u4f4d\u548c\u8eca\u8f1b\u3002\u5728\u4f7f\u7528 LiDAR \u6a19\u8a18\u7684\u8cc7\u6599\u4e0a\u9032\u884c\u8a13\u7df4\uff0cMT F-CVT \u5c07\u7269\u4ef6\u5b9a\u4f4d\u5728 25 \u516c\u5c3a x 25 \u516c\u5c3a\u7684\u771f\u5be6\u9732\u5929\u5834\u666f\u4e2d\uff0c\u5e73\u5747\u8aa4\u5dee\u50c5 20 \u516c\u5206\u3002\u6211\u5011\u7684\u8f03\u5927\u6a21\u578b\u9054\u5230 F-1 \u5206\u6578 0.89\u3002\u6b64\u5916\uff0c\u8f03\u5c0f\u7684\u6a21\u578b\u5728 Nvidia Jetson Orin \u5d4c\u5165\u5f0f\u96fb\u8def\u677f\u4e0a\u4ee5 16 fps \u904b\u4f5c\uff0c\u5075\u6e2c\u7d50\u679c\u8207\u8f03\u5927\u7684\u6a21\u578b\u985e\u4f3c\u3002MT F-CVT \u5c55\u793a\u4e86\u5728\u4e0d\u540c\u8eca\u8f1b\u548c\u76f8\u6a5f\u88dd\u7f6e\u7d44\u614b\u4e2d\u5f37\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002\u4f86\u81ea\u672a\u898b\u8eca\u8f1b\u548c\u76f8\u6a5f\u88dd\u7f6e\u7d44\u614b\u7684\u793a\u7bc4\u5f71\u7247\u53ef\u65bc\u6b64\u8655\u53d6\u5f97\uff1ahttps://streamable.com/jjw54x\u3002", "author": "Antonyo Musabini et.al.", "authors": "Antonyo Musabini, Ivan Novikov, Sana Soula, Christel Leonet, Lihao Wang, Rachid Benmokhtar, Fabian Burger, Thomas Boulay, Xavier Perrotton", "id": "2408.12575v1", "paper_url": "http://arxiv.org/abs/2408.12575v1", "repo": "null"}}