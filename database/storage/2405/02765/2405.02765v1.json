{"2405.02765": {"publish_time": "2024-05-04", "title": "Detecting Edited Knowledge in Language Models", "paper_summary": "Knowledge editing techniques (KEs) can update language models' obsolete or\ninaccurate knowledge learned from pre-training. However, KE also faces\npotential malicious applications, e.g. inserting misinformation and toxic\ncontent. Moreover, in the context of responsible AI, it is instructive for\nend-users to know whether a generated output is driven by edited knowledge or\nfirst-hand knowledge from pre-training. To this end, we study detecting edited\nknowledge in language models by introducing a novel task: given an edited model\nand a specific piece of knowledge the model generates, our objective is to\nclassify the knowledge as either \"non-edited\" (based on the pre-training), or\n``edited'' (based on subsequent editing). We initiate the task with two\nstate-of-the-art KEs, two language models, and two datasets. We further propose\na simple classifier, RepReg, a logistic regression model that takes hidden\nstate representations as input features. Our results reveal that RepReg\nestablishes a strong baseline, achieving a peak accuracy of 99.81%, and 97.79%\nin out-of-domain settings. Second, RepReg achieves near-optimal performance\nwith a limited training set (200 training samples), and it maintains its\nperformance even in out-of-domain settings. Last, we find it more challenging\nto separate edited and non-edited knowledge when they contain the same subject\nor object.", "paper_summary_zh": "", "author": "Paul Youssef et.al.", "authors": "Paul Youssef,Zhixue Zhao,J\u00f6rg Schl\u00f6tterer,Christin Seifert", "id": "2405.02765v1", "paper_url": "http://arxiv.org/abs/2405.02765v1", "repo": "null"}}