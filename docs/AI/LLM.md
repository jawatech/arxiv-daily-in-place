
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-07**|**ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning**|David Junhao Zhang et.al.|[2411.05003v1](http://arxiv.org/abs/2411.05003v1)|null|
|**2024-11-07**|**Analyzing The Language of Visual Tokens**|David M. Chan et.al.|[2411.05001v1](http://arxiv.org/abs/2411.05001v1)|null|
|**2024-11-07**|**Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?**|Jonathan Roberts et.al.|[2411.05000v1](http://arxiv.org/abs/2411.05000v1)|null|
|**2024-11-07**|**LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation**|Weiquan Huang et.al.|[2411.04997v1](http://arxiv.org/abs/2411.04997v1)|[link](https://github.com/microsoft/LLM2CLIP)|
|**2024-11-07**|**HourVideo: 1-Hour Video-Language Understanding**|Keshigeyan Chandrasegaran et.al.|[2411.04998v1](http://arxiv.org/abs/2411.04998v1)|null|
|**2024-11-07**|**Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models**|Weixin Liang et.al.|[2411.04996v1](http://arxiv.org/abs/2411.04996v1)|null|
|**2024-11-07**|**Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives**|Hao Sun et.al.|[2411.04991v1](http://arxiv.org/abs/2411.04991v1)|[link](https://github.com/holarissun/rewardmodelingbeyondbradleyterry)|
|**2024-11-07**|**Few-Shot Task Learning through Inverse Generative Modeling**|Aviv Netanyahu et.al.|[2411.04987v1](http://arxiv.org/abs/2411.04987v1)|null|
|**2024-11-07**|**The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities**|Zhaofeng Wu et.al.|[2411.04986v1](http://arxiv.org/abs/2411.04986v1)|[link](https://github.com/ZhaofengWu/semantic-hub)|
|**2024-11-07**|**DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning**|Gaoyue Zhou et.al.|[2411.04983v1](http://arxiv.org/abs/2411.04983v1)|null|
|**2024-11-07**|**Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries**|Dylan Manuel et.al.|[2411.04981v1](http://arxiv.org/abs/2411.04981v1)|null|
|**2024-11-07**|**SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference**|Gabriele Oliaro et.al.|[2411.04975v1](http://arxiv.org/abs/2411.04975v1)|null|
|**2024-11-07**|**BitNet a4.8: 4-bit Activations for 1-bit LLMs**|Hongyu Wang et.al.|[2411.04965v1](http://arxiv.org/abs/2411.04965v1)|null|
|**2024-11-07**|**Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**|Yanjun Gao et.al.|[2411.04962v1](http://arxiv.org/abs/2411.04962v1)|null|
|**2024-11-07**|**Uncovering Hidden Subspaces in Video Diffusion Models Using Re-Identification**|Mischa Dombrowski et.al.|[2411.04956v1](http://arxiv.org/abs/2411.04956v1)|null|
|**2024-11-07**|**M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding**|Jaemin Cho et.al.|[2411.04952v1](http://arxiv.org/abs/2411.04952v1)|null|
|**2024-11-07**|**Estimating the Influence of Sequentially Correlated Literary Properties in Textual Classification: A Data-Centric Hypothesis-Testing Approach**|Gideon Yoffe et.al.|[2411.04950v1](http://arxiv.org/abs/2411.04950v1)|[link](https://github.com/YoffeG/Thematic-nonThematic_Hypothesis_Testing)|
|**2024-11-07**|**DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion**|Wenqiang Sun et.al.|[2411.04928v1](http://arxiv.org/abs/2411.04928v1)|null|
|**2024-11-07**|**StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration**|Panwen Hu et.al.|[2411.04925v1](http://arxiv.org/abs/2411.04925v1)|null|
|**2024-11-07**|**GPTKB: Building Very Large Knowledge Bases from Language Models**|Yujia Hu et.al.|[2411.04920v1](http://arxiv.org/abs/2411.04920v1)|null|
|**2024-11-07**|**Evaluating Robustness of Reinforcement Learning Algorithms for Autonomous Shipping**|Bavo Lesy et.al.|[2411.04915v1](http://arxiv.org/abs/2411.04915v1)|null|
|**2024-11-07**|**GASE: Generatively Augmented Sentence Encoding**|Manuel Frank et.al.|[2411.04914v1](http://arxiv.org/abs/2411.04914v1)|null|
|**2024-11-07**|**OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models**|Siming Huang et.al.|[2411.04905v1](http://arxiv.org/abs/2411.04905v1)|null|
|**2024-11-07**|**GUI Agents with Foundation Models: A Comprehensive Survey**|Shuai Wang et.al.|[2411.04890v1](http://arxiv.org/abs/2411.04890v1)|null|
|**2024-11-07**|**FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI**|Elliot Glazer et.al.|[2411.04872v1](http://arxiv.org/abs/2411.04872v1)|null|
|**2024-11-07**|**Think Smart, Act SMARL! Analyzing Probabilistic Logic Driven Safety in Multi-Agent Reinforcement Learning**|Satchit Chatterji et.al.|[2411.04867v1](http://arxiv.org/abs/2411.04867v1)|[link](https://github.com/satchitchatterji/shieldedmarlthesis)|
|**2024-11-07**|**ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset**|Olaf Wysocki et.al.|[2411.04865v1](http://arxiv.org/abs/2411.04865v1)|[link](https://github.com/oloocki/zaha)|
|**2024-11-07**|**Sentiment Analysis of Spanish Political Party Tweets Using Pre-trained Language Models**|Chuqiao Song et.al.|[2411.04862v1](http://arxiv.org/abs/2411.04862v1)|null|
|**2024-11-07**|**Prompt-Guided Internal States for Hallucination Detection of Large Language Models**|Fujie Zhang et.al.|[2411.04847v1](http://arxiv.org/abs/2411.04847v1)|[link](https://github.com/fujie-math/PRISM)|
|**2024-11-07**|**Machine learning and optimization-based approaches to duality in statistical physics**|Andrea E. V. Ferrari et.al.|[2411.04838v1](http://arxiv.org/abs/2411.04838v1)|null|
|**2024-11-07**|**VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and Benchmark Models**|Ming Cheng et.al.|[2411.04825v1](http://arxiv.org/abs/2411.04825v1)|null|
|**2024-11-07**|**When Does Classical Chinese Help? Quantifying Cross-Lingual Transfer in Hanja and Kanbun**|Seyoung Song et.al.|[2411.04822v1](http://arxiv.org/abs/2411.04822v1)|null|
|**2024-11-07**|**LuxBank: The First Universal Dependency Treebank for Luxembourgish**|Alistair Plum et.al.|[2411.04813v1](http://arxiv.org/abs/2411.04813v1)|null|
|**2024-11-07**|**Defending Deep Regression Models against Backdoor Attacks**|Lingyu Du et.al.|[2411.04811v1](http://arxiv.org/abs/2411.04811v1)|null|
|**2024-11-07**|**Kwai-STaR: Transform LLMs into State-Transition Reasoners**|Xingyu Lu et.al.|[2411.04799v1](http://arxiv.org/abs/2411.04799v1)|null|
|**2024-11-07**|**MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation**|Sayan Paul et.al.|[2411.04796v1](http://arxiv.org/abs/2411.04796v1)|null|
|**2024-11-07**|**AlignXIE: Improving Multilingual Information Extraction by Cross-Lingual Alignment**|Yuxin Zuo et.al.|[2411.04794v1](http://arxiv.org/abs/2411.04794v1)|null|
|**2024-11-07**|**Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research**|Xuewen Han et.al.|[2411.04788v1](http://arxiv.org/abs/2411.04788v1)|[link](https://github.com/ai4finance-foundation/finrobot)|
|**2024-11-07**|**A study of Vietnamese readability assessing through semantic and statistical features**|Hung Tuan Le et.al.|[2411.04756v1](http://arxiv.org/abs/2411.04756v1)|null|
|**2024-11-07**|**RetrieveGPT: Merging Prompts and Mathematical Models for Enhanced Code-Mixed Information Retrieval**|Aniket Deroy et.al.|[2411.04752v1](http://arxiv.org/abs/2411.04752v1)|null|
|**2024-11-07**|**Equivariant Graph Attention Networks with Structural Motifs for Predicting Cell Line-Specific Synergistic Drug Combinations**|Zachary Schwehr et.al.|[2411.04747v1](http://arxiv.org/abs/2411.04747v1)|[link](https://github.com/wetothemoon/egat_drugsynergy)|
|**2024-11-07**|**BhasaAnuvaad: A Speech Translation Dataset for 14 Indian Languages**|Sparsh Jain et.al.|[2411.04699v1](http://arxiv.org/abs/2411.04699v1)|null|
|**2024-11-07**|**The Multiple Dimensions of Spuriousness in Machine Learning**|Samuel J. Bell et.al.|[2411.04696v1](http://arxiv.org/abs/2411.04696v1)|null|
|**2024-11-07**|**Reciprocal Point Learning Network with Large Electromagnetic Kernel for SAR Open-Set Recognition**|Xiayang Xiao et.al.|[2411.04693v1](http://arxiv.org/abs/2411.04693v1)|null|
|**2024-11-07**|**Personalized Federated Learning for Cross-view Geo-localization**|Christos Anagnostopoulos et.al.|[2411.04692v1](http://arxiv.org/abs/2411.04692v1)|null|
|**2024-11-07**|**AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**|Tianyi Zhang et.al.|[2411.04691v1](http://arxiv.org/abs/2411.04691v1)|null|
|**2024-11-07**|**Solving Generalized Grouping Problems in Cellular Manufacturing Systems Using a Network Flow Model**|Md. Kutub Uddin et.al.|[2411.04685v1](http://arxiv.org/abs/2411.04685v1)|null|
|**2024-11-07**|**CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation**|Jie Liu et.al.|[2411.04679v1](http://arxiv.org/abs/2411.04679v1)|null|
|**2024-11-07**|**CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational Agents in XR**|Kadir Burak Buldu et.al.|[2411.04671v1](http://arxiv.org/abs/2411.04671v1)|null|
|**2024-11-07**|**EffiCANet: Efficient Time Series Forecasting with Convolutional Attention**|Xinxing Zhou et.al.|[2411.04669v1](http://arxiv.org/abs/2411.04669v1)|null|
|**2024-11-07**|**DISCO: DISCovering Overfittings as Causal Rules for Text Classification Models**|Zijian Zhang et.al.|[2411.04649v1](http://arxiv.org/abs/2411.04649v1)|null|
|**2024-11-07**|**wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification from Physiological Signals**|Jonathan F. Carter et.al.|[2411.04644v1](http://arxiv.org/abs/2411.04644v1)|null|
|**2024-11-07**|**TAP-VL: Text Layout-Aware Pre-training for Enriched Vision-Language Models**|Jonathan Fhima et.al.|[2411.04642v1](http://arxiv.org/abs/2411.04642v1)|null|
|**2024-11-07**|**Hands-On Tutorial: Labeling with LLM and Human-in-the-Loop**|Ekaterina Artemova et.al.|[2411.04637v1](http://arxiv.org/abs/2411.04637v1)|null|
|**2024-11-07**|**FASSILA: A Corpus for Algerian Dialect Fake News Detection and Sentiment Analysis**|Amin Abdedaiem et.al.|[2411.04604v1](http://arxiv.org/abs/2411.04604v1)|[link](https://github.com/amincoding/fassila)|
|**2024-11-07**|**Self-Calibrated Listwise Reranking with Large Language Models**|Ruiyang Ren et.al.|[2411.04602v1](http://arxiv.org/abs/2411.04602v1)|null|
|**2024-11-07**|**Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction**|Ahlam Alrehili et.al.|[2411.04588v1](http://arxiv.org/abs/2411.04588v1)|null|
|**2024-11-07**|**On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data**|Aitor Martinez-Seras et.al.|[2411.04586v1](http://arxiv.org/abs/2411.04586v1)|null|
|**2024-11-07**|**The State and Fate of Summarization Datasets**|Noam Dahan et.al.|[2411.04585v1](http://arxiv.org/abs/2411.04585v1)|null|
|**2024-11-07**|**Interpreting the Learned Model in MuZero Planning**|Hung Guei et.al.|[2411.04580v1](http://arxiv.org/abs/2411.04580v1)|null|
|**2024-11-07**|**Multistage Fine-tuning Strategies for Automatic Speech Recognition in Low-resource Languages**|Leena G Pillai et.al.|[2411.04573v1](http://arxiv.org/abs/2411.04573v1)|null|
|**2024-11-07**|**Impact of Label Noise on Learning Complex Features**|Rahul Vashisht et.al.|[2411.04569v1](http://arxiv.org/abs/2411.04569v1)|null|
|**2024-11-07**|**A Generalisation of Voter Model: Influential Nodes and Convergence Properties**|Abhiram Manohara et.al.|[2411.04564v1](http://arxiv.org/abs/2411.04564v1)|null|
|**2024-11-07**|**Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning**|Marvin Alles et.al.|[2411.04562v1](http://arxiv.org/abs/2411.04562v1)|null|
|**2024-11-07**|**Pruning Literals for Highly Efficient Explainability at Word Level**|Rohan Kumar Yadav et.al.|[2411.04557v1](http://arxiv.org/abs/2411.04557v1)|null|
|**2024-11-07**|**Vision Language Models are In-Context Value Learners**|Yecheng Jason Ma et.al.|[2411.04549v1](http://arxiv.org/abs/2411.04549v1)|null|
|**2024-11-07**|**Best Practices for Distilling Large Language Models into BERT for Web Search Ranking**|Dezhi Ye et.al.|[2411.04539v1](http://arxiv.org/abs/2411.04539v1)|null|
|**2024-11-07**|**Meta-Reasoning Improves Tool Use in Large Language Models**|Lisa Alazraki et.al.|[2411.04535v1](http://arxiv.org/abs/2411.04535v1)|[link](https://github.com/lisaalaz/tecton)|
|**2024-11-07**|**Tomato, Tomahto, Tomate: Measuring the Role of Shared Semantics among Subwords in Multilingual Language Models**|Xinyu Zhang et.al.|[2411.04530v1](http://arxiv.org/abs/2411.04530v1)|null|
|**2024-11-07**|**GenJoin: Conditional Generative Plan-to-Plan Query Optimizer that Learns from Subplan Hints**|Pavel Sulimov et.al.|[2411.04525v1](http://arxiv.org/abs/2411.04525v1)|null|
|**2024-11-07**|**Continuous Sign Language Recognition System using Deep Learning with MediaPipe Holistic**|Sharvani Srivastava et.al.|[2411.04517v1](http://arxiv.org/abs/2411.04517v1)|null|
|**2024-11-07**|**FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**|Liangrui Pan et.al.|[2411.04509v1](http://arxiv.org/abs/2411.04509v1)|null|
|**2024-11-07**|**Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model**|Young-Jun Lee et.al.|[2411.04496v1](http://arxiv.org/abs/2411.04496v1)|[link](https://github.com/passing2961/thanos)|
|**2024-11-07**|**Series-to-Series Diffusion Bridge Model**|Hao Yang et.al.|[2411.04491v1](http://arxiv.org/abs/2411.04491v1)|null|
|**2024-11-07**|**ML-Promise: A Multilingual Dataset for Corporate Promise Verification**|Yohei Seki et.al.|[2411.04473v1](http://arxiv.org/abs/2411.04473v1)|null|
|**2024-11-07**|**Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks**|Adam Fourney et.al.|[2411.04468v1](http://arxiv.org/abs/2411.04468v1)|null|
|**2024-11-07**|**Can CDT rationalise the ex ante optimal policy via modified anthropics?**|Emery Cooper et.al.|[2411.04462v1](http://arxiv.org/abs/2411.04462v1)|null|
|**2024-11-07**|**Gradient Localization Improves Lifelong Pretraining of Language Models**|Jared Fernandez et.al.|[2411.04448v1](http://arxiv.org/abs/2411.04448v1)|null|
|**2024-11-07**|**ACCIO: Table Understanding Enhanced via Contrastive Learning with Aggregations**|Whanhee Cho et.al.|[2411.04443v1](http://arxiv.org/abs/2411.04443v1)|[link](https://github.com/whnhch/accio)|
|**2024-11-07**|**Scaling Laws for Pre-training Agents and World Models**|Tim Pearce et.al.|[2411.04434v1](http://arxiv.org/abs/2411.04434v1)|null|
|**2024-11-07**|**One fish, two fish, but not the whole sea: Alignment reduces language models' conceptual diversity**|Sonia K. Murthy et.al.|[2411.04427v1](http://arxiv.org/abs/2411.04427v1)|[link](https://github.com/skmur/onefish-twofish)|
|**2024-11-07**|**DELIFT: Data Efficient Language model Instruction Fine Tuning**|Ishika Agarwal et.al.|[2411.04425v1](http://arxiv.org/abs/2411.04425v1)|[link](https://github.com/agarwalishika/delift)|
|**2024-11-07**|**Bayesian Calibration of Win Rate Estimation with LLM Evaluators**|Yicheng Gao et.al.|[2411.04424v1](http://arxiv.org/abs/2411.04424v1)|[link](https://github.com/yale-nlp/bay-calibration-llm-evaluators)|
|**2024-11-07**|**Variational Low-Rank Adaptation Using IVON**|Bai Cong et.al.|[2411.04421v1](http://arxiv.org/abs/2411.04421v1)|[link](https://github.com/team-approx-bayes/ivon-lora)|
|**2024-11-07**|**Towards Competitive Search Relevance For Inference-Free Learned Sparse Retrievers**|Zhichao Geng et.al.|[2411.04403v1](http://arxiv.org/abs/2411.04403v1)|null|
|**2024-11-07**|**A Bayesian Mixture Model of Temporal Point Processes with Determinantal Point Process Prior**|Yiwei Dong et.al.|[2411.04397v1](http://arxiv.org/abs/2411.04397v1)|null|
|**2024-11-07**|**Bridging the Gap: Representation Spaces in Neuro-Symbolic AI**|Xin Zhang et.al.|[2411.04393v1](http://arxiv.org/abs/2411.04393v1)|null|
|**2024-11-07**|**Neuro-Symbolic AI: Explainability, Challenges, and Future Trends**|Xin Zhang et.al.|[2411.04383v1](http://arxiv.org/abs/2411.04383v1)|null|
|**2024-11-07**|**Benchmarking Large Language Models with Integer Sequence Generation Tasks**|Daniel O'Malley et.al.|[2411.04372v1](http://arxiv.org/abs/2411.04372v1)|null|
|**2024-11-07**|**ComFairGNN: Community Fair Graph Neural Network**|Yonas Sium et.al.|[2411.04371v1](http://arxiv.org/abs/2411.04371v1)|null|
|**2024-11-07**|**Measuring short-form factuality in large language models**|Jason Wei et.al.|[2411.04368v1](http://arxiv.org/abs/2411.04368v1)|[link](https://github.com/openai/simple-evals)|
|**2024-11-07**|**Robust and Efficient Fine-tuning of LLMs with Bayesian Reparameterization of Low-Rank Adaptation**|Vaibhav Seth et.al.|[2411.04358v1](http://arxiv.org/abs/2411.04358v1)|[link](https://github.com/lcs2-iiitd/monteclora)|
|**2024-11-07**|**Model and Deep learning based Dynamic Range Compression Inversion**|Haoran Sun et.al.|[2411.04337v1](http://arxiv.org/abs/2411.04337v1)|null|
|**2024-11-07**|**Scaling Laws for Precision**|Tanishq Kumar et.al.|[2411.04330v1](http://arxiv.org/abs/2411.04330v1)|null|
|**2024-11-07**|**CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models**|Jierui Li et.al.|[2411.04329v1](http://arxiv.org/abs/2411.04329v1)|null|
|**2024-11-07**|**Balancing Transparency and Accuracy: A Comparative Analysis of Rule-Based and Deep Learning Models in Political Bias Classification**|Manuel Nunez Martinez et.al.|[2411.04328v1](http://arxiv.org/abs/2411.04328v1)|null|
|**2024-11-06**|**Gradient Boosting Trees and Large Language Models for Tabular Data Few-Shot Learning**|Carlos Huertas et.al.|[2411.04324v1](http://arxiv.org/abs/2411.04324v1)|null|
|**2024-11-06**|**A Multilingual Sentiment Lexicon for Low-Resource Language Translation using Large Languages Models and Explainable AI**|Melusi Malinga et.al.|[2411.04316v1](http://arxiv.org/abs/2411.04316v1)|null|
|**2024-11-06**|**Improving Bilingual Capabilities of Language Models to Support Diverse Linguistic Practices in Education**|Anand Syamkumar et.al.|[2411.04308v1](http://arxiv.org/abs/2411.04308v1)|null|
|**2024-11-06**|**A Capabilities Approach to Studying Bias and Harm in Language Technologies**|Hellina Hailu Nigatu et.al.|[2411.04298v1](http://arxiv.org/abs/2411.04298v1)|null|

#### Abstracts
##### **ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning**
2411.05003v1 by David Junhao Zhang, Roni Paiss, Shiran Zada, Nikhil Karnad, David E. Jacobs, Yael Pritch, Inbar Mosseri, Mike Zheng Shou, Neal Wadhwa, Nataniel Ruiz

Recently, breakthroughs in video modeling have allowed for controllable
camera trajectories in generated videos. However, these methods cannot be
directly applied to user-provided videos that are not generated by a video
model. In this paper, we present ReCapture, a method for generating new videos
with novel camera trajectories from a single user-provided video. Our method
allows us to re-generate the reference video, with all its existing scene
motion, from vastly different angles and with cinematic camera motion. Notably,
using our method we can also plausibly hallucinate parts of the scene that were
not observable in the reference video. Our method works by (1) generating a
noisy anchor video with a new camera trajectory using multiview diffusion
models or depth-based point cloud rendering and then (2) regenerating the
anchor video into a clean and temporally consistent reangled video using our
proposed masked video fine-tuning technique.

摘要：最近，影片建模的突破性進展讓生成影片中的相機軌跡可控。然而，這些方法無法直接應用於非影片模型生成的使用者提供影片。在本文中，我們提出 ReCapture，這是一種方法，可從單一使用者提供的影片中生成具有新穎相機軌跡的新影片。我們的這種方法讓我們能夠從截然不同的角度和電影相機運動中重新生成參考影片，並包含其所有現有的場景動作。值得注意的是，使用我們的方法，我們還可以合理地對參考影片中無法觀察到的場景部分進行幻覺。我們的這種方法運作方式為：(1) 使用多視圖擴散模型或基於深度點雲渲染來生成具有新相機軌跡的雜訊錨定影片，然後 (2) 使用我們提出的遮罩影片微調技術，將錨定影片重新生成為乾淨且時間一致的重新調整角度影片。

##### **Analyzing The Language of Visual Tokens**
2411.05001v1 by David M. Chan, Rodolfo Corona, Joonyong Park, Cheol Jun Cho, Yutong Bai, Trevor Darrell

With the introduction of transformer-based models for vision and language
tasks, such as LLaVA and Chameleon, there has been renewed interest in the
discrete tokenized representation of images. These models often treat image
patches as discrete tokens, analogous to words in natural language, learning
joint alignments between visual and human languages. However, little is known
about the statistical behavior of these visual languages - whether they follow
similar frequency distributions, grammatical structures, or topologies as
natural languages. In this paper, we take a natural-language-centric approach
to analyzing discrete visual languages and uncover striking similarities and
fundamental differences. We demonstrate that, although visual languages adhere
to Zipfian distributions, higher token innovation drives greater entropy and
lower compression, with tokens predominantly representing object parts,
indicating intermediate granularity. We also show that visual languages lack
cohesive grammatical structures, leading to higher perplexity and weaker
hierarchical organization compared to natural languages. Finally, we
demonstrate that, while vision models align more closely with natural languages
than other models, this alignment remains significantly weaker than the
cohesion found within natural languages. Through these experiments, we
demonstrate how understanding the statistical properties of discrete visual
languages can inform the design of more effective computer vision models.

摘要：隨著基於Transformer的視覺和語言任務模型（例如 LLaVA 和 Chameleon）的引入，人們對影像的離散標記化表示法重新產生興趣。這些模型通常將影像區塊視為離散標記，類似於自然語言中的單字，並學習視覺語言和人類語言之間的聯合對齊。然而，對於這些視覺語言的統計行為所知甚少，例如它們是否遵循與自然語言類似的頻率分佈、語法結構或拓撲結構。在本文中，我們採用以自然語言為中心的途徑來分析離散視覺語言，並揭示驚人的相似性和根本差異。我們證明，儘管視覺語言遵循齊夫分布，但較高的標記創新會導致更大的熵和更低的壓縮，而標記主要代表物件部分，表示中間粒度。我們還表明，視覺語言缺乏連貫的語法結構，導致與自然語言相比，困惑度較高且層級組織較弱。最後，我們證明，儘管視覺模型與自然語言的對齊比其他模型更緊密，但這種對齊仍然顯著弱於自然語言中發現的內聚性。透過這些實驗，我們展示了理解離散視覺語言的統計屬性如何為更有效的電腦視覺模型的設計提供資訊。

##### **Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?**
2411.05000v1 by Jonathan Roberts, Kai Han, Samuel Albanie

As the context limits of Large Language Models (LLMs) increase, the range of
possible applications and downstream functions broadens. In many real-world
tasks, decisions depend on details scattered across collections of often
disparate documents containing mostly irrelevant information. Long-context LLMs
appear well-suited to this form of complex information retrieval and reasoning,
which has traditionally proven costly and time-consuming. However, although the
development of longer context models has seen rapid gains in recent years, our
understanding of how effectively LLMs use their context has not kept pace. To
address this, we conduct a set of retrieval experiments designed to evaluate
the capabilities of 17 leading LLMs, such as their ability to follow threads of
information through the context window. Strikingly, we find that many models
are remarkably threadsafe: capable of simultaneously following multiple threads
without significant loss in performance. Still, for many models, we find the
effective context limit is significantly shorter than the supported context
length, with accuracy decreasing as the context window grows. Our study also
highlights the important point that token counts from different tokenizers
should not be directly compared -- they often correspond to substantially
different numbers of written characters. We release our code and long-context
experimental data.

摘要：隨著大型語言模型 (LLM) 的內容限制增加，可能的應用範圍和下游功能也隨之擴展。在許多真實世界的任務中，決策取決於分散在通常包含大量無關訊息的文件集合中的細節。長內容限制的 LLM 似乎很適合這種複雜的資訊檢索和推理形式，而這種形式傳統上被證明既昂貴又耗時。然而，儘管較長內容限制模型的開發在近年來已快速進步，但我們對於 LLM 如何有效使用其內容限制的理解並未跟上腳步。為了解決這個問題，我們進行了一組檢索實驗，旨在評估 17 個領先 LLM 的功能，例如它們透過內容限制視窗追蹤資訊串的能力。令人驚訝的是，我們發現許多模型具有顯著的執行緒安全性：能夠同時追蹤多個執行緒，而不會顯著損失效能。儘管如此，對於許多模型，我們發現有效的內容限制顯著短於受支援的內容限制長度，而且隨著內容限制視窗的增加，準確度也會下降。我們的研究也強調了一個重要觀點，即來自不同分詞器的代碼計數不應直接比較——它們通常對應於大量不同的書面字元。我們發布我們的程式碼和長內容限制的實驗資料。

##### **LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation**
2411.04997v1 by Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, Lili Qiu

CLIP is one of the most important multimodal foundational models today. What
powers CLIP's capabilities? The rich supervision signals provided by natural
language, the carrier of human knowledge, shape a powerful cross-modal
representation space. However, with the rapid advancements in large language
models LLMs like GPT-4 and LLaMA, the boundaries of language comprehension and
generation are continually being pushed. This raises an intriguing question:
can the capabilities of LLMs be harnessed to further improve multimodal
representation learning? The potential benefits of incorporating LLMs into CLIP
are clear. LLMs' strong textual understanding can fundamentally improve CLIP's
ability to handle image captions, drastically enhancing its ability to process
long and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMs
are trained on a vast corpus of text, possessing open-world knowledge. This
allows them to expand on caption information during training, increasing the
efficiency of the learning process. In this paper, we propose LLM2CLIP, a novel
approach that embraces the power of LLMs to unlock CLIP's potential. By
fine-tuning the LLM in the caption space with contrastive learning, we extract
its textual capabilities into the output embeddings, significantly improving
the output layer's textual discriminability. We then design an efficient
training process where the fine-tuned LLM acts as a powerful teacher for CLIP's
visual encoder. Thanks to the LLM's presence, we can now incorporate longer and
more complex captions without being restricted by vanilla CLIP's text encoder's
context window and ability limitations. Our experiments demonstrate that this
approach brings substantial improvements in cross-modal tasks.

摘要：CLIP 是當今最重要的多模態基礎模型之一。是什麼賦予了 CLIP 的能力？自然語言提供的豐富監督訊號，人類知識的載體，塑造了一個強大的跨模態表示空間。然而，隨著 GPT-4 和 LLaMA 等大型語言模型 LLM 的快速進展，語言理解和生成的界限不斷被推動。這引發了一個有趣的問題：LLM 的能力是否可以被利用來進一步改進多模態表示學習？將 LLM 納入 CLIP 的潛在好處很明顯。LLM 強大的文本理解力可以從根本上提高 CLIP 處理圖像標題的能力，大幅增強其處理長而複雜文本的能力，這是香草 CLIP 的一個眾所周知限制。此外，LLM 是在大量的文本語料庫上訓練的，擁有開放世界的知識。這使他們能夠在訓練期間擴展標題信息，從而提高學習過程的效率。在本文中，我們提出了 LLM2CLIP，一種新穎的方法，它利用 LLM 的力量來釋放 CLIP 的潛力。通過在對比學習的標題空間中微調 LLM，我們將其文本能力提取到輸出嵌入中，顯著提高了輸出層的文本可區分性。然後，我們設計了一個高效的訓練過程，其中微調後的 LLM 充當 CLIP 視覺編碼器的強大教師。由於 LLM 的存在，我們現在可以納入更長、更複雜的標題，而不會受到香草 CLIP 的文本編碼器的上下文窗口和能力限制。我們的實驗表明，這種方法在跨模態任務中帶來了顯著的改進。

##### **HourVideo: 1-Hour Video-Language Understanding**
2411.04998v1 by Keshigeyan Chandrasegaran, Agrim Gupta, Lea M. Hadzic, Taran Kota, Jimming He, Cristóbal Eyzaguirre, Zane Durante, Manling Li, Jiajun Wu, Li Fei-Fei

We present HourVideo, a benchmark dataset for hour-long video-language
understanding. Our dataset consists of a novel task suite comprising
summarization, perception (recall, tracking), visual reasoning (spatial,
temporal, predictive, causal, counterfactual), and navigation (room-to-room,
object retrieval) tasks. HourVideo includes 500 manually curated egocentric
videos from the Ego4D dataset, spanning durations of 20 to 120 minutes, and
features 12,976 high-quality, five-way multiple-choice questions. Benchmarking
results reveal that multimodal models, including GPT-4 and LLaVA-NeXT, achieve
marginal improvements over random chance. In stark contrast, human experts
significantly outperform the state-of-the-art long-context multimodal model,
Gemini Pro 1.5 (85.0% vs. 37.3%), highlighting a substantial gap in multimodal
capabilities. Our benchmark, evaluation toolkit, prompts, and documentation are
available at https://hourvideo.stanford.edu

摘要：我們提出 HourVideo，這是長達一小時的影片語言理解基準資料集。我們的資料集包含一系列新穎的任務套件，包含摘要、感知（回憶、追蹤）、視覺推理（空間、時間、預測、因果、反事實）和導航（房間到房間、物件檢索）任務。HourVideo 包含來自 Ego4D 資料集的 500 個手動策劃的第一人稱視角影片，跨越 20 到 120 分鐘的時長，並提供 12,976 個高品質、五選一的選擇題。基準測試結果顯示，包括 GPT-4 和 LLaVA-NeXT 在內的多模態模型，比隨機機會獲得邊際改善。與之形成鮮明對比的是，人類專家顯著優於最先進的長脈絡多模態模型 Gemini Pro 1.5（85.0% 對比 37.3%），突顯出多模態能力的巨大差距。我們的基準、評估工具包、提示和文件可在 https://hourvideo.stanford.edu 取得

##### **Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models**
2411.04996v1 by Weixin Liang, Lili Yu, Liang Luo, Srinivasan Iyer, Ning Dong, Chunting Zhou, Gargi Ghosh, Mike Lewis, Wen-tau Yih, Luke Zettlemoyer, Xi Victoria Lin

The development of large language models (LLMs) has expanded to multi-modal
systems capable of processing text, images, and speech within a unified
framework. Training these models demands significantly larger datasets and
computational resources compared to text-only LLMs. To address the scaling
challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal
transformer architecture that significantly reduces pretraining computational
costs. MoT decouples non-embedding parameters of the model by modality --
including feed-forward networks, attention matrices, and layer normalization --
enabling modality-specific processing with global self-attention over the full
input sequence. We evaluate MoT across multiple settings and model scales. In
the Chameleon 7B setting (autoregressive text-and-image generation), MoT
matches the dense baseline's performance using only 55.8\% of the FLOPs. When
extended to include speech, MoT reaches speech performance comparable to the
dense baseline with only 37.2\% of the FLOPs. In the Transfusion setting, where
text and image are trained with different objectives, a 7B MoT model matches
the image modality performance of the dense baseline with one third of the
FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image
generation metrics. System profiling further highlights MoT's practical
benefits, achieving dense baseline image quality in 47.2\% of the wall-clock
time and text quality in 75.6\% of the wall-clock time (measured on AWS
p4de.24xlarge instances with NVIDIA A100 GPUs).

摘要：大型語言模型 (LLM) 的發展已擴展到多模態系統，能夠在統一的架構內處理文字、影像和語音。訓練這些模型需要比僅文字的 LLM 大得多的資料集和運算資源。為了應對擴充挑戰，我們引進混合Transformer (MoT)，這是一種稀疏多模態Transformer架構，可大幅減少預訓練的運算成本。MoT 透過模態解耦模型的非嵌入參數，包括前饋網路、注意力矩陣和層次標準化，並在完整的輸入序列上啟用具備全局自我注意力的模態特定處理。我們在多種設定和模型規模中評估 MoT。在變色龍 7B 設定（自迴歸文字和影像產生）中，MoT 僅使用 55.8% 的浮點運算次數 (FLOP) 就達到密集基線的效能。當擴充到包含語音時，MoT 達到的語音效能可與密集基線相比，但僅使用 37.2% 的浮點運算次數。在輸血設定中，文字和影像使用不同的目標進行訓練，7B MoT 模型的影像模態效能與密集基線相當，但浮點運算次數只有三分之一，而 760M MoT 模型則在關鍵影像產生指標上優於 1.4B 密集基線。系統分析進一步突顯了 MoT 的實際效益，在 47.2% 的實際時間內達成密集基線影像品質，在 75.6% 的實際時間內達成文字品質（在配備 NVIDIA A100 GPU 的 AWS p4de.24xlarge 實例上測量）。

##### **Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives**
2411.04991v1 by Hao Sun, Yunyi Shen, Jean-Francois Ton

The Bradley-Terry (BT) model is a common and successful practice in reward
modeling for Large Language Model (LLM) alignment. However, it remains unclear
why this model -- originally developed for multi-player stochastic game
matching -- can be adopted to convert pairwise response comparisons to reward
values and make predictions. Especially given the fact that only a limited
number of prompt-response pairs are sparsely compared with others. In this
paper, we first revisit the foundations of using BT models in reward modeling,
and establish the convergence rate of BT reward models based on deep neural
networks using embeddings, providing a theoretical foundation for their use.
Despite theoretically sound, we argue that the BT model is not a necessary
choice from the perspective of downstream optimization. This is because a
reward model only needs to preserve the correct ranking predictions through a
monotonic transformation of the true reward. We highlight the critical concept
of order consistency in reward modeling and demonstrate that the BT model
possesses this property. Consequently, we propose a simple and straightforward
upper-bound algorithm, compatible with off-the-shelf binary classifiers, as an
alternative order-consistent reward modeling objective. To offer practical
insights, we empirically evaluate the performance of these different reward
modeling approaches across more than 12,000 experimental setups, using $6$ base
LLMs, $2$ datasets, and diverse annotation designs that vary in quantity,
quality, and pairing choices in preference annotations.

摘要：Bradley-Terry (BT) 模型是大型語言模型 (LLM) 對齊中獎勵建模的常見且成功的實務。然而，這個模型最初是為多玩家隨機遊戲配對而開發的，為什麼它可以被採用來將成對的回應比較轉換為獎勵值並做出預測，這仍然不清楚。特別是考慮到只有有限數量的提示回應對與其他對稀疏地進行比較。在本文中，我們首先重新探討在獎勵建模中使用 BT 模型的基礎，並使用嵌入建立基於深度神經網路的 BT 獎勵模型的收斂速度，為它們的使用提供理論基礎。儘管在理論上是合理的，我們認為從下游最佳化的角度來看，BT 模型並非必要的選擇。這是因為獎勵模型只需要透過真實獎勵的單調轉換來保留正確的排名預測。我們強調了獎勵建模中訂單一致性的關鍵概念，並證明了 BT 模型具備此特性。因此，我們提出了一個簡單且直接的上界演算法，與現成的二元分類器相容，作為替代的訂單一致獎勵建模目標。為了提供實用的見解，我們根據 6 個基礎 LLM、2 個資料集和在數量、品質和偏好註解中的配對選擇上有所不同的多樣化註解設計，對這些不同的獎勵建模方法在超過 12,000 個實驗設定中的效能進行經驗評估。

##### **Few-Shot Task Learning through Inverse Generative Modeling**
2411.04987v1 by Aviv Netanyahu, Yilun Du, Antonia Bronars, Jyothish Pari, Joshua Tenenbaum, Tianmin Shu, Pulkit Agrawal

Learning the intents of an agent, defined by its goals or motion style, is
often extremely challenging from just a few examples. We refer to this problem
as task concept learning and present our approach, Few-Shot Task Learning
through Inverse Generative Modeling (FTL-IGM), which learns new task concepts
by leveraging invertible neural generative models. The core idea is to pretrain
a generative model on a set of basic concepts and their demonstrations. Then,
given a few demonstrations of a new concept (such as a new goal or a new
action), our method learns the underlying concepts through backpropagation
without updating the model weights, thanks to the invertibility of the
generative model. We evaluate our method in five domains -- object
rearrangement, goal-oriented navigation, motion caption of human actions,
autonomous driving, and real-world table-top manipulation. Our experimental
results demonstrate that via the pretrained generative model, we successfully
learn novel concepts and generate agent plans or motion corresponding to these
concepts in (1) unseen environments and (2) in composition with training
concepts.

摘要：透過其目標或動作風格定義的代理意圖學習，通常僅從幾個範例中學習極具挑戰性。我們將此問題稱為任務概念學習，並提出我們的做法，透過反向生成式建模（FTL-IGM）進行少量任務學習，透過利用可逆神經生成式模型來學習新的任務概念。核心概念是在一組基本概念及其示範上預訓練生成式模型。然後，給定新概念的幾個示範（例如新目標或新動作），我們的模型透過反向傳播學習基礎概念，而無需更新模型權重，這要歸功於生成式模型的可逆性。我們在五個領域評估我們的模型——物體重新排列、目標導向導航、人類動作的動作標題、自動駕駛和現實世界的桌面操作。我們的實驗結果表明，透過預訓練的生成式模型，我們成功學習新概念並產生與這些概念相應的代理計畫或動作，在（1）未見過的環境中，以及（2）與訓練概念的組合中。

##### **The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities**
2411.04986v1 by Zhaofeng Wu, Xinyan Velocity Yu, Dani Yogatama, Jiasen Lu, Yoon Kim

Modern language models can process inputs across diverse languages and
modalities. We hypothesize that models acquire this capability through learning
a shared representation space across heterogeneous data types (e.g., different
languages and modalities), which places semantically similar inputs near one
another, even if they are from different modalities/languages. We term this the
semantic hub hypothesis, following the hub-and-spoke model from neuroscience
(Patterson et al., 2007) which posits that semantic knowledge in the human
brain is organized through a transmodal semantic "hub" which integrates
information from various modality-specific "spokes" regions. We first show that
model representations for semantically equivalent inputs in different languages
are similar in the intermediate layers, and that this space can be interpreted
using the model's dominant pretraining language via the logit lens. This
tendency extends to other data types, including arithmetic expressions, code,
and visual/audio inputs. Interventions in the shared representation space in
one data type also predictably affect model outputs in other data types,
suggesting that this shared representations space is not simply a vestigial
byproduct of large-scale training on broad data, but something that is actively
utilized by the model during input processing.

摘要：現代語言模型可以處理跨越不同語言和模式的輸入。我們假設模型透過學習跨越異質資料類型（例如，不同的語言和模式）的共享表示空間來獲得此能力，這個空間將語義上相似的輸入放置在彼此附近，即使它們來自不同的模式/語言。我們稱之為語義中心假設，遵循神經科學中的樞紐輻射模型（Patterson 等人，2007 年），該模型假設人類大腦中的語義知識是透過跨模式語義「樞紐」組織的，它整合來自各種特定模式「輻條」區域的資訊。我們首先展示不同語言中語義等效輸入的模型表示在中間層中是相似的，並且這個空間可以使用模型的主導預訓練語言透過 logit 透鏡來詮釋。這種趨勢延伸到其他資料類型，包括算術表達式、程式碼以及視覺/音訊輸入。共享表示空間中的一種資料類型的介入也會可預測地影響其他資料類型中的模型輸出，這表明這個共享表示空間不僅僅是大規模訓練廣泛資料的殘餘副產品，而且是模型在輸入處理期間積極利用的東西。

##### **DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning**
2411.04983v1 by Gaoyue Zhou, Hengkai Pan, Yann LeCun, Lerrel Pinto

The ability to predict future outcomes given control actions is fundamental
for physical reasoning. However, such predictive models, often called world
models, have proven challenging to learn and are typically developed for
task-specific solutions with online policy learning. We argue that the true
potential of world models lies in their ability to reason and plan across
diverse problems using only passive data. Concretely, we require world models
to have the following three properties: 1) be trainable on offline,
pre-collected trajectories, 2) support test-time behavior optimization, and 3)
facilitate task-agnostic reasoning. To realize this, we present DINO World
Model (DINO-WM), a new method to model visual dynamics without reconstructing
the visual world. DINO-WM leverages spatial patch features pre-trained with
DINOv2, enabling it to learn from offline behavioral trajectories by predicting
future patch features. This design allows DINO-WM to achieve observational
goals through action sequence optimization, facilitating task-agnostic behavior
planning by treating desired goal patch features as prediction targets. We
evaluate DINO-WM across various domains, including maze navigation, tabletop
pushing, and particle manipulation. Our experiments demonstrate that DINO-WM
can generate zero-shot behavioral solutions at test time without relying on
expert demonstrations, reward modeling, or pre-learned inverse models. Notably,
DINO-WM exhibits strong generalization capabilities compared to prior
state-of-the-art work, adapting to diverse task families such as arbitrarily
configured mazes, push manipulation with varied object shapes, and
multi-particle scenarios.

摘要：預測未來結果的能力是物理推理的基礎。然而，這種預測模型，通常稱為世界模型，已被證明難以學習，並且通常是針對具有線上策略學習的特定任務解決方案而開發的。我們認為，世界模型的真正潛力在於它們僅使用被動數據就能推理和規劃各種問題的能力。具體來說，我們要求世界模型具備以下三個特性：1) 可在離線、預先收集的軌跡上進行訓練，2) 支援測試時間行為最佳化，以及 3) 促進與任務無關的推理。為實現此目標，我們提出了 DINO 世界模型 (DINO-WM)，這是一種在不重建視覺世界的條件下對視覺動態進行建模的新方法。DINO-WM 利用預先使用 DINOv2 訓練的空間區塊特徵，使其能夠透過預測未來的區塊特徵，從離線行為軌跡中學習。此設計允許 DINO-WM 透過動作序列最佳化來實現觀察目標，並將所需的目標區塊特徵視為預測目標，從而促進與任務無關的行為規劃。我們在各種領域評估了 DINO-WM，包括迷宮導航、桌面推動和粒子操作。我們的實驗證明，DINO-WM 能夠在測試時產生零次學習的行為解決方案，而無需依賴專家示範、獎勵建模或預先學習的逆向模型。值得注意的是，與先前的最先進工作相比，DINO-WM 表現出強大的泛化能力，適用於各種任務家族，例如任意配置的迷宮、具有不同物體形狀的推動操作和多粒子場景。

##### **Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries**
2411.04981v1 by Dylan Manuel, Nafis Tanveer Islam, Joseph Khoury, Ana Nunez, Elias Bou-Harb, Peyman Najafirad

Security experts reverse engineer (decompile) binary code to identify
critical security vulnerabilities. The limited access to source code in vital
systems - such as firmware, drivers, and proprietary software used in Critical
Infrastructures (CI) - makes this analysis even more crucial on the binary
level. Even with available source code, a semantic gap persists after
compilation between the source and the binary code executed by the processor.
This gap may hinder the detection of vulnerabilities in source code. That being
said, current research on Large Language Models (LLMs) overlooks the
significance of decompiled binaries in this area by focusing solely on source
code. In this work, we are the first to empirically uncover the substantial
semantic limitations of state-of-the-art LLMs when it comes to analyzing
vulnerabilities in decompiled binaries, largely due to the absence of relevant
datasets. To bridge the gap, we introduce DeBinVul, a novel decompiled binary
code vulnerability dataset. Our dataset is multi-architecture and
multi-optimization, focusing on C/C++ due to their wide usage in CI and
association with numerous vulnerabilities. Specifically, we curate 150,872
samples of vulnerable and non-vulnerable decompiled binary code for the task of
(i) identifying; (ii) classifying; (iii) describing vulnerabilities; and (iv)
recovering function names in the domain of decompiled binaries. Subsequently,
we fine-tune state-of-the-art LLMs using DeBinVul and report on a performance
increase of 19%, 24%, and 21% in the capabilities of CodeLlama, Llama3, and
CodeGen2 respectively, in detecting binary code vulnerabilities. Additionally,
using DeBinVul, we report a high performance of 80-90% on the vulnerability
classification task. Furthermore, we report improved performance in function
name recovery and vulnerability description tasks.

摘要：<paragraph>安全專家逆向工程（反編譯）二進制程式碼，以找出關鍵的安全漏洞。在重要系統（例如韌體、驅動程式和關鍵基礎設施 (CI) 中使用的專有軟體）中，對原始碼的存取有限，這使得在二進制層級進行此分析變得更加重要。即使有原始碼可用，在編譯後，原始碼和處理器執行的二進制程式碼之間仍存在語意差距。此差距可能會阻礙在原始碼中偵測漏洞。話雖如此，目前對大型語言模型 (LLM) 的研究忽略了反編譯二進制程式碼在此領域的重要性，因為它們只專注於原始碼。在這項工作中，我們率先憑經驗揭露最先進的 LLM 在分析反編譯二進制程式碼中的漏洞時存在大量的語意限制，這主要是因為缺乏相關的資料集。為了彌補這個差距，我們引入了 DeBinVul，這是一個新穎的反編譯二進制程式碼漏洞資料集。我們的資料集是多架構和多最佳化的，由於 C/C++ 在 CI 中廣泛使用且與許多漏洞相關，因此我們專注於 C/C++。具體來說，我們策劃了 150,872 個有漏洞和無漏洞的反編譯二進制程式碼範例，用於 (i) 識別；(ii) 分類；(iii) 描述漏洞；以及 (iv) 在反編譯二進制程式碼的領域中復原函式名稱。隨後，我們使用 DeBinVul 微調最先進的 LLM，並報告 CodeLlama、Llama3 和 CodeGen2 在偵測二進制程式碼漏洞方面的能力分別提升了 19%、24% 和 21%。此外，使用 DeBinVul，我們報告了在漏洞分類任務中 80-90% 的高性能。此外，我們報告了函式名稱復原和漏洞描述任務的效能提升。</paragraph>

##### **SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference**
2411.04975v1 by Gabriele Oliaro, Zhihao Jia, Daniel Campos, Aurick Qiao

We present SuffixDecoding, a novel model-free approach to accelerating large
language model (LLM) inference through speculative decoding. Unlike existing
methods that rely on draft models or specialized decoding heads, SuffixDecoding
leverages suffix trees built from previously generated outputs to efficiently
predict candidate token sequences. Our approach enables flexible
tree-structured speculation without the overhead of maintaining and
orchestrating additional models. SuffixDecoding builds and dynamically updates
suffix trees to capture patterns in the generated text, using them to construct
speculation trees through a principled scoring mechanism based on empirical
token frequencies. SuffixDecoding requires only CPU memory which is plentiful
and underutilized on typical LLM serving nodes. We demonstrate that
SuffixDecoding achieves competitive speedups compared to model-based approaches
across diverse workloads including open-domain chat, code generation, and
text-to-SQL tasks. For open-ended chat and code generation tasks,
SuffixDecoding achieves up to $1.4\times$ higher output throughput than
SpecInfer and up to $1.1\times$ lower time-per-token (TPOT) latency. For a
proprietary multi-LLM text-to-SQL application, SuffixDecoding achieves up to
$2.9\times$ higher output throughput and $3\times$ lower latency than
speculative decoding. Our evaluation shows that SuffixDecoding maintains high
acceptance rates even with small reference corpora of 256 examples, while
continuing to improve performance as more historical outputs are incorporated.

摘要：<paragraph>我們提出 SuffixDecoding，一種新穎的無模型方法，通過推測性解碼來加速大型語言模型 (LLM) 推論。與依賴草稿模型或特定解碼頭的現有方法不同，SuffixDecoding 利用從先前生成的輸出構建的後綴樹，以有效預測候選詞彙序列。我們的做法實現了靈活的樹狀結構推測，而無需維護和協調額外模型的開銷。SuffixDecoding 構建並動態更新後綴樹，以擷取生成文本中的模式，並使用它們通過基於經驗詞彙頻率的原則性評分機制構建推測樹。SuffixDecoding 只需要 CPU 記憶體，這在典型的 LLM 服務節點上很豐富且未充分利用。我們證明 SuffixDecoding 與基於模型的方法相比，在包括開放域聊天、程式碼生成和文字到 SQL 任務在內的各種工作負載中實現了具有競爭力的加速。對於開放式聊天和程式碼生成任務，SuffixDecoding 的輸出吞吐量比 SpecInfer 高達 1.4 倍，每令牌時間 (TPOT) 延遲低達 1.1 倍。對於專有的一體多用 LLM 文字到 SQL 應用程式，SuffixDecoding 的輸出吞吐量比推測性解碼高達 2.9 倍，延遲低 3 倍。我們的評估表明，即使只有 256 個範例的小型參考語料庫，SuffixDecoding 仍能維持很高的接受率，同時隨著更多歷史輸出的納入，效能會持續提升。</paragraph>

##### **BitNet a4.8: 4-bit Activations for 1-bit LLMs**
2411.04965v1 by Hongyu Wang, Shuming Ma, Furu Wei

Recent research on the 1-bit Large Language Models (LLMs), such as BitNet
b1.58, presents a promising direction for reducing the inference cost of LLMs
while maintaining their performance. In this work, we introduce BitNet a4.8,
enabling 4-bit activations for 1-bit LLMs. BitNet a4.8 employs a hybrid
quantization and sparsification strategy to mitigate the quantization errors
introduced by the outlier channels. Specifically, we utilize 4-bit activations
for inputs to the attention and feed-forward network layers, while sparsifying
intermediate states followed with 8-bit quantization. Extensive experiments
demonstrate that BitNet a4.8 achieves performance comparable to BitNet b1.58
with equivalent training costs, while being faster in inference with enabling
4-bit (INT4/FP4) kernels. Additionally, BitNet a4.8 activates only 55% of
parameters and supports 3-bit KV cache, further enhancing the efficiency of
large-scale LLM deployment and inference.

摘要：最近對 1 位元大型語言模型 (LLM) 的研究，例如 BitNet b1.58，提出了在維持其效能的同時減少 LLM 推論成本的有希望的方向。在這項工作中，我們引入了 BitNet a4.8，為 1 位元 LLM 啟用 4 位元元激活。BitNet a4.8 採用混合量化與稀疏化策略來減輕異常通道引入的量化誤差。具體來說，我們使用 4 位元元激活作為注意力和前饋網路層的輸入，同時稀疏化中間狀態並進行 8 位元元量化。廣泛的實驗證明，BitNet a4.8 達到與 BitNet b1.58 相當的效能，且訓練成本相當，同時在啟用 4 位元元 (INT4/FP4) 核心時推論速度更快。此外，BitNet a4.8 僅啟用 55% 的參數並支援 3 位元元 KV 快取，進一步提升大規模 LLM 部署和推論的效率。

##### **Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**
2411.04962v1 by Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Guanhua Chen, Anoop Mayampurath, Matthew Churpek, Majid Afshar

Large language models (LLMs) are being explored for diagnostic decision
support, yet their ability to estimate pre-test probabilities, vital for
clinical decision-making, remains limited. This study evaluates two LLMs,
Mistral-7B and Llama3-70B, using structured electronic health record data on
three diagnosis tasks. We examined three current methods of extracting LLM
probability estimations and revealed their limitations. We aim to highlight the
need for improved techniques in LLM confidence estimation.

摘要：大型語言模型 (LLM) 正在被探索用於診斷決策支持，但它們估計臨床決策制定中至關重要的預測試概率的能力仍然有限。本研究使用三個診斷任務的結構化電子健康記錄數據評估了兩個 LLM，Mistral-7B 和 Llama3-70B。我們檢查了提取 LLM 概率估計的三種當前方法並揭示了它們的局限性。我們的目標是強調改進 LLM 置信度估計技術的必要性。

##### **Uncovering Hidden Subspaces in Video Diffusion Models Using Re-Identification**
2411.04956v1 by Mischa Dombrowski, Hadrien Reynaud, Bernhard Kainz

Latent Video Diffusion Models can easily deceive casual observers and domain
experts alike thanks to the produced image quality and temporal consistency.
Beyond entertainment, this creates opportunities around safe data sharing of
fully synthetic datasets, which are crucial in healthcare, as well as other
domains relying on sensitive personal information. However, privacy concerns
with this approach have not fully been addressed yet, and models trained on
synthetic data for specific downstream tasks still perform worse than those
trained on real data. This discrepancy may be partly due to the sampling space
being a subspace of the training videos, effectively reducing the training data
size for downstream models. Additionally, the reduced temporal consistency when
generating long videos could be a contributing factor.
  In this paper, we first show that training privacy-preserving models in
latent space is computationally more efficient and generalize better.
Furthermore, to investigate downstream degradation factors, we propose to use a
re-identification model, previously employed as a privacy preservation filter.
We demonstrate that it is sufficient to train this model on the latent space of
the video generator. Subsequently, we use these models to evaluate the subspace
covered by synthetic video datasets and thus introduce a new way to measure the
faithfulness of generative machine learning models. We focus on a specific
application in healthcare echocardiography to illustrate the effectiveness of
our novel methods. Our findings indicate that only up to 30.8% of the training
videos are learned in latent video diffusion models, which could explain the
lack of performance when training downstream tasks on synthetic data.

摘要：潛在影片擴散模型得益於產生的影像品質和時間一致性，可以輕易欺騙隨意觀察者和領域專家。除了娛樂之外，這創造了安全資料分享的機會，分享完全合成的資料集，這在醫療保健以及其他依賴個人敏感資訊的領域中至關重要。然而，這種方法的隱私問題尚未完全解決，針對特定下游任務訓練的合成資料模型，其表現仍比在真實資料上訓練的模型差。這種差異可能部分是因為取樣空間是訓練影片的子空間，有效減少了下游模型的訓練資料大小。此外，在產生長影片時時間一致性降低，也可能是一個促成因素。在本文中，我們首先表明在潛在空間中訓練隱私保護模型在計算上更有效率，並且能更好地概化。此外，為了調查下游退化的因素，我們建議使用重新識別模型，先前用作隱私保護篩選器。我們證明了在影片生成器的潛在空間上訓練此模型就足夠了。隨後，我們使用這些模型來評估合成影片資料集涵蓋的子空間，從而引入一種衡量生成式機器學習模型忠實度的新方法。我們專注於醫療保健超音波心動圖中的特定應用，以說明我們新方法的有效性。我們的研究結果表明，潛在影片擴散模型僅學習了高達 30.8% 的訓練影片，這可以解釋在合成資料上訓練下游任務時缺乏效能的原因。

##### **M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding**
2411.04952v1 by Jaemin Cho, Debanjan Mahata, Ozan Irsoy, Yujie He, Mohit Bansal

Document visual question answering (DocVQA) pipelines that answer questions
from documents have broad applications. Existing methods focus on handling
single-page documents with multi-modal language models (MLMs), or rely on
text-based retrieval-augmented generation (RAG) that uses text extraction tools
such as optical character recognition (OCR). However, there are difficulties in
applying these methods in real-world scenarios: (a) questions often require
information across different pages or documents, where MLMs cannot handle many
long documents; (b) documents often have important information in visual
elements such as figures, but text extraction tools ignore them. We introduce
M3DocRAG, a novel multi-modal RAG framework that flexibly accommodates various
document contexts (closed-domain and open-domain), question hops (single-hop
and multi-hop), and evidence modalities (text, chart, figure, etc.). M3DocRAG
finds relevant documents and answers questions using a multi-modal retriever
and an MLM, so that it can efficiently handle single or many documents while
preserving visual information. Since previous DocVQA datasets ask questions in
the context of a specific document, we also present M3DocVQA, a new benchmark
for evaluating open-domain DocVQA over 3,000+ PDF documents with 40,000+ pages.
In three benchmarks (M3DocVQA/MMLongBench-Doc/MP-DocVQA), empirical results
show that M3DocRAG with ColPali and Qwen2-VL 7B achieves superior performance
than many strong baselines, including state-of-the-art performance in
MP-DocVQA. We provide comprehensive analyses of different indexing, MLMs, and
retrieval models. Lastly, we qualitatively show that M3DocRAG can successfully
handle various scenarios, such as when relevant information exists across
multiple pages and when answer evidence only exists in images.

摘要：文件视觉问答 (DocVQA) 管道可以回答文档中的问题，具有广泛的应用。现有方法专注于使用多模态语言模型 (MLM) 处理单页文档，或依赖于使用光学字符识别 (OCR) 等文本提取工具的基于文本的检索增强生成 (RAG)。然而，在实际场景中应用这些方法存在困难：(a) 问题通常需要跨不同页面或文档的信息，而 MLM 无法处理许多长文档；(b) 文档通常在视觉元素（如数字）中包含重要信息，但文本提取工具会忽略它们。我们引入了 M3DocRAG，这是一种新颖的多模态 RAG 框架，可以灵活地适应各种文档上下文（封闭域和开放域）、问题跳跃（单跳和多跳）和证据模式（文本、图表、数字等）。M3DocRAG 使用多模态检索器和 MLM 来查找相关文档并回答问题，以便在保留视觉信息的同时有效地处理单个或多个文档。由于之前的 DocVQA 数据集在特定文档的上下文中提问，因此我们还提出了 M3DocVQA，这是一个新的基准，用于评估超过 3000 个 PDF 文档（超过 40000 页）的开放域 DocVQA。在三个基准（M3DocVQA/MMLongBench-Doc/MP-DocVQA）中，实证结果表明，带有 ColPali 和 Qwen2-VL 7B 的 M3DocRAG 比许多强大的基线获得了更好的性能，包括 MP-DocVQA 中的最新性能。我们对不同的索引、MLM 和检索模型进行了全面分析。最后，我们定性地表明 M3DocRAG 可以成功处理各种场景，例如相关信息存在于多个页面中以及答案证据仅存在于图像中的情况。

##### **Estimating the Influence of Sequentially Correlated Literary Properties in Textual Classification: A Data-Centric Hypothesis-Testing Approach**
2411.04950v1 by Gideon Yoffe, Nachum Dershowitz, Ariel Vishne, Barak Sober

Stylometry aims to distinguish authors by analyzing literary traits assumed
to reflect semi-conscious choices distinct from elements like genre or theme.
However, these components often overlap, complicating text classification based
solely on feature distributions. While some literary properties, such as
thematic content, are likely to manifest as correlations between adjacent text
units, others, like authorial style, may be independent thereof. We introduce a
hypothesis-testing approach to evaluate the influence of sequentially
correlated literary properties on text classification, aiming to determine when
these correlations drive classification. Using a multivariate binary
distribution, our method models sequential correlations between text units as a
stochastic process, assessing the likelihood of clustering across varying
adjacency scales. This enables us to examine whether classification is
dominated by sequentially correlated properties or remains independent. In
experiments on a diverse English prose corpus, our analysis integrates
traditional and neural embeddings within supervised and unsupervised
frameworks. Results demonstrate that our approach effectively identifies when
textual classification is not primarily influenced by sequentially correlated
literary properties, particularly in cases where texts differ in authorial
style or genre rather than by a single author within a similar genre.

摘要：風格計量學旨在通過分析假設的反映了半意識選擇的文學特徵來區分作者，這些特徵不同於類型或主題等元素。然而，這些組成部分通常會重疊，這使得僅基於特徵分佈的文本分類變得複雜。雖然一些文學屬性（例如主題內容）可能會表現為相鄰文本單元之間的相關性，但其他屬性（例如作者風格）可能與此無關。我們引入了一個假設檢驗方法來評估序列相關文學屬性對文本分類的影響，旨在確定這些相關性何時驅動分類。使用多元二元分佈，我們的模型將文本單元之間的序列相關性建模為一個隨機過程，評估在不同鄰接尺度上聚類的可能性。這使我們能夠檢查分類是由序列相關屬性主導還是保持獨立。在對多樣化的英語散文語料庫進行的實驗中，我們的分析將傳統嵌入和神經嵌入整合到有監督和無監督的框架中。結果表明，我們的模型有效地識別了何時文本分類不受序列相關文學屬性的主要影響，特別是在文本在作者風格或類型上有所不同的情況下，而不是在類似類型中的單個作者。

##### **DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion**
2411.04928v1 by Wenqiang Sun, Shuo Chen, Fangfu Liu, Zilong Chen, Yueqi Duan, Jun Zhang, Yikai Wang

In this paper, we introduce \textbf{DimensionX}, a framework designed to
generate photorealistic 3D and 4D scenes from just a single image with video
diffusion. Our approach begins with the insight that both the spatial structure
of a 3D scene and the temporal evolution of a 4D scene can be effectively
represented through sequences of video frames. While recent video diffusion
models have shown remarkable success in producing vivid visuals, they face
limitations in directly recovering 3D/4D scenes due to limited spatial and
temporal controllability during generation. To overcome this, we propose
ST-Director, which decouples spatial and temporal factors in video diffusion by
learning dimension-aware LoRAs from dimension-variant data. This controllable
video diffusion approach enables precise manipulation of spatial structure and
temporal dynamics, allowing us to reconstruct both 3D and 4D representations
from sequential frames with the combination of spatial and temporal dimensions.
Additionally, to bridge the gap between generated videos and real-world scenes,
we introduce a trajectory-aware mechanism for 3D generation and an
identity-preserving denoising strategy for 4D generation. Extensive experiments
on various real-world and synthetic datasets demonstrate that DimensionX
achieves superior results in controllable video generation, as well as in 3D
and 4D scene generation, compared with previous methods.

摘要：<paragraph>在本文中，我們介紹了 DimensionX，一個旨在僅使用影片擴散從單一影像生成逼真的 3D 和 4D 場景的架構。我們的做法始於這樣的見解：3D 場景的空間結構和 4D 場景的時間演變都可以透過影片畫面的序列有效地呈現。雖然最近的影片擴散模型在產生生動視覺效果方面展現了顯著的成功，但由於生成過程中受限的空間和時間可控性，它們在直接還原 3D/4D 場景方面面臨限制。為了克服這個問題，我們提出了 ST-Director，它透過從維度變異資料學習具有維度感知能力的 LoRA，將影片擴散中的空間和時間因素解耦。這種可控的影片擴散方法能精確地操作空間結構和時間動態，讓我們能夠從連續畫面的空間和時間維度組合中重建 3D 和 4D 表徵。此外，為了彌合生成的影片和真實場景之間的差距，我們引入了用於 3D 生成的軌跡感知機制和用於 4D 生成的身份保留去噪策略。在各種真實世界和合成資料集上的廣泛實驗證明，與先前的技術相比，DimensionX 在可控影片生成以及 3D 和 4D 場景生成方面都取得了卓越的成果。</paragraph>

##### **StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration**
2411.04925v1 by Panwen Hu, Jin Jiang, Jianqi Chen, Mingfei Han, Shengcai Liao, Xiaojun Chang, Xiaodan Liang

The advent of AI-Generated Content (AIGC) has spurred research into automated
video generation to streamline conventional processes. However, automating
storytelling video production, particularly for customized narratives, remains
challenging due to the complexity of maintaining subject consistency across
shots. While existing approaches like Mora and AesopAgent integrate multiple
agents for Story-to-Video (S2V) generation, they fall short in preserving
protagonist consistency and supporting Customized Storytelling Video Generation
(CSVG). To address these limitations, we propose StoryAgent, a multi-agent
framework designed for CSVG. StoryAgent decomposes CSVG into distinct subtasks
assigned to specialized agents, mirroring the professional production process.
Notably, our framework includes agents for story design, storyboard generation,
video creation, agent coordination, and result evaluation. Leveraging the
strengths of different models, StoryAgent enhances control over the generation
process, significantly improving character consistency. Specifically, we
introduce a customized Image-to-Video (I2V) method, LoRA-BE, to enhance
intra-shot temporal consistency, while a novel storyboard generation pipeline
is proposed to maintain subject consistency across shots. Extensive experiments
demonstrate the effectiveness of our approach in synthesizing highly consistent
storytelling videos, outperforming state-of-the-art methods. Our contributions
include the introduction of StoryAgent, a versatile framework for video
generation tasks, and novel techniques for preserving protagonist consistency.

摘要：人工智能生成內容 (AIGC) 的出現，刺激了自動化影片生成的研究，以簡化傳統流程。然而，自動化說故事影片製作，特別是客製化敘事，由於在鏡頭間維持主題一致性的複雜性，仍然具有挑戰性。雖然現有的方法，如 Mora 和 AesopAgent，整合多個代理，用於故事到影片 (S2V) 生成，但在保留主角一致性和支援客製化說故事影片生成 (CSVG) 方面仍有不足。為了解決這些限制，我們提出了 StoryAgent，一個專為 CSVG 設計的多代理架構。StoryAgent 將 CSVG 分解成分配給專門代理的不同子任務，反映了專業製作流程。值得注意的是，我們的架構包括故事設計、分鏡產生、影片製作、代理協調和結果評估的代理。利用不同模型的優勢，StoryAgent 增強了對生成過程的控制，顯著改善了角色一致性。具體來說，我們引入了一個客製化的影像到影片 (I2V) 方法，LoRA-BE，以增強鏡頭內的時間一致性，同時提出了一個新穎的分鏡生成管道，以在鏡頭間維持主題一致性。廣泛的實驗證明了我們的方法在合成高度一致的說故事影片方面的有效性，優於最先進的方法。我們的貢獻包括引入了 StoryAgent，一個用於影片生成任務的多功能架構，以及保留主角一致性的新技術。

##### **GPTKB: Building Very Large Knowledge Bases from Language Models**
2411.04920v1 by Yujia Hu, Shrestha Ghosh, Tuan-Phong Nugyen, Simon Razniewski

General-domain knowledge bases (KB), in particular the "big three" --
Wikidata, Yago and DBpedia -- are the backbone of many intelligent
applications. While these three have seen steady development, comprehensive KB
construction at large has seen few fresh attempts. In this work, we propose to
build a large general-domain KB entirely from a large language model (LLM). We
demonstrate the feasibility of large-scale KB construction from LLMs, while
highlighting specific challenges arising around entity recognition, entity and
property canonicalization, and taxonomy construction. As a prototype, we use
GPT-4o-mini to construct GPTKB, which contains 105 million triples for more
than 2.9 million entities, at a cost 100x less than previous KBC projects. Our
work is a landmark for two fields: For NLP, for the first time, it provides
\textit{constructive} insights into the knowledge (or beliefs) of LLMs. For the
Semantic Web, it shows novel ways forward for the long-standing challenge of
general-domain KB construction. GPTKB is accessible at https://gptkb.org.

摘要：一般領域知識庫 (KB)，特別是「三大知識庫」-- Wikidata、Yago 和 DBpedia -- 是許多智慧型應用程式的骨幹。儘管這三個知識庫持續發展，但整體而言，全面的知識庫建構鮮少有新的嘗試。在此研究中，我們提議完全從大型語言模型 (LLM) 建立一個大型一般領域知識庫。我們展示了從 LLM 建構大規模知識庫的可行性，同時強調了實體辨識、實體和屬性正規化以及分類法建構等特定挑戰。作為原型，我們使用 GPT-4o-mini 建構 GPTKB，其中包含超過 290 萬個實體的 1.05 億個三元組，成本比先前的 KBC 專案低 100 倍。我們的研究是兩個領域的里程碑：對於自然語言處理 (NLP)，它首次提供了 LLM 的知識（或信念）的「建構性」見解。對於語意網路，它展示了長期存在的一般領域知識庫建構挑戰的新穎方法。GPTKB 可在 https://gptkb.org 取得。

##### **Evaluating Robustness of Reinforcement Learning Algorithms for Autonomous Shipping**
2411.04915v1 by Bavo Lesy, Ali Anwar, Siegfried Mercelis

Recently, there has been growing interest in autonomous shipping due to its
potential to improve maritime efficiency and safety. The use of advanced
technologies, such as artificial intelligence, can address the current
navigational and operational challenges in autonomous shipping. In particular,
inland waterway transport (IWT) presents a unique set of challenges, such as
crowded waterways and variable environmental conditions. In such dynamic
settings, the reliability and robustness of autonomous shipping solutions are
critical factors for ensuring safe operations. This paper examines the
robustness of benchmark deep reinforcement learning (RL) algorithms,
implemented for IWT within an autonomous shipping simulator, and their ability
to generate effective motion planning policies. We demonstrate that a
model-free approach can achieve an adequate policy in the simulator,
successfully navigating port environments never encountered during training. We
focus particularly on Soft-Actor Critic (SAC), which we show to be inherently
more robust to environmental disturbances compared to MuZero, a
state-of-the-art model-based RL algorithm. In this paper, we take a significant
step towards developing robust, applied RL frameworks that can be generalized
to various vessel types and navigate complex port- and inland environments and
scenarios.

摘要：<paragraph>最近，由於自動航運有望提升航海效率和安全性，因此備受關注。使用人工智慧等先進技術，可以解決自動航運中現有的導航和營運挑戰。特別是，內陸水道運輸 (IWT) 提出了一組獨特的挑戰，例如擁擠的水道和多變的環境條件。在這種動態環境中，自動航運解決方案的可靠性和穩健性是確保安全營運的關鍵因素。本文探討了基準深度強化學習 (RL) 演算法的穩健性，這些演算法是在自動航運模擬器中為 IWT 實作，以及它們產生有效運動規劃政策的能力。我們證明了無模型方法可以在模擬器中實現適當的政策，成功導航在訓練期間從未遭遇過的港口環境。我們特別關注 Soft-Actor Critic (SAC)，我們展示它與 MuZero（一種最先進的基於模型的 RL 演算法）相比，本質上對環境干擾更穩健。在本文中，我們邁出了重要一步，開發穩健的應用 RL 架構，可以推廣到各種船舶類型，並導航複雜的港口和內陸環境和場景。</paragraph>

##### **GASE: Generatively Augmented Sentence Encoding**
2411.04914v1 by Manuel Frank, Haithem Afli

We propose an approach to enhance sentence embeddings by applying generative
text models for data augmentation at inference time. Unlike conventional data
augmentation that utilises synthetic training data, our approach does not
require access to model parameters or the computational resources typically
required for fine-tuning state-of-the-art models. Generatively Augmented
Sentence Encoding uses diverse linguistic synthetic variants of input texts
generated by paraphrasing, summarising, or extracting keywords, followed by
pooling the original and synthetic embeddings. Experimental results on the
Massive Text Embedding Benchmark for Semantic Textual Similarity (STS)
demonstrate performance improvements across a range of embedding models using
different generative models for augmentation. We find that generative
augmentation leads to larger performance improvements for embedding models with
lower baseline performance. These findings suggest that integrating generative
augmentation at inference time adds semantic diversity and can enhance the
robustness and generalizability of sentence embeddings for embedding models.
Our results show that the degree to which generative augmentation can improve
STS performance depends not only on the embedding model but also on the
dataset. From a broader perspective, the approach allows trading training for
inference compute.

摘要：我們提出了一種方法，透過在推論時間應用生成式文字模型來增強句子嵌入，以進行資料擴充。與利用合成訓練資料的傳統資料擴充不同，我們的做法不需要存取模型參數或微調最先進模型通常需要的計算資源。生成式增強句子編碼使用由同義改寫、摘要或提取關鍵字產生的輸入文字的不同語言合成變體，然後匯集原始和合成嵌入。在語義文字相似度 (STS) 的大量文字嵌入基準上的實驗結果顯示，使用不同的生成式模型進行擴充，各種嵌入模型的效能都有所提升。我們發現，生成式擴充對於基準效能較低的嵌入模型，會帶來較大的效能提升。這些發現表明，在推論時間整合生成式擴充會增加語義多樣性，並可以增強嵌入模型的句子嵌入的穩健性和概括性。我們的結果顯示，生成式擴充可以改善 STS 效能的程度，不僅取決於嵌入模型，還取決於資料集。從更廣泛的角度來看，這種方法允許在訓練和推論計算之間進行交易。

##### **OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models**
2411.04905v1 by Siming Huang, Tianhao Cheng, Jason Klein Liu, Jiaran Hao, Liuyihan Song, Yang Xu, J. Yang, J. H. Liu, Chenchen Zhang, Linzheng Chai, Ruifeng Yuan, Zhaoxiang Zhang, Jie Fu, Qian Liu, Ge Zhang, Zili Wang, Yuan Qi, Yinghui Xu, Wei Chu

Large language models (LLMs) for code have become indispensable in various
domains, including code generation, reasoning tasks and agent systems.While
open-access code LLMs are increasingly approaching the performance levels of
proprietary models, high-quality code LLMs suitable for rigorous scientific
investigation, particularly those with reproducible data processing pipelines
and transparent training protocols, remain limited. The scarcity is due to
various challenges, including resource constraints, ethical considerations, and
the competitive advantages of keeping models advanced. To address the gap, we
introduce OpenCoder, a top-tier code LLM that not only achieves performance
comparable to leading models but also serves as an ``open cookbook'' for the
research community. Unlike most prior efforts, we release not only model
weights and inference code, but also the reproducible training data, complete
data processing pipeline, rigorous experimental ablation results, and detailed
training protocols for open scientific research. Through this comprehensive
release, we identify the key ingredients for building a top-tier code LLM: (1)
code optimized heuristic rules for data cleaning and methods for data
deduplication, (2) recall of text corpus related to code and (3) high-quality
synthetic data in both annealing and supervised fine-tuning stages. By offering
this level of openness, we aim to broaden access to all aspects of a top-tier
code LLM, with OpenCoder serving as both a powerful model and an open
foundation to accelerate research, and enable reproducible advancements in code
AI.

摘要：大型語言模型 (LLM) 已成為各種領域不可或缺的程式碼，包括程式碼生成、推理任務和代理系統。雖然開放取用的程式碼 LLM 逐漸接近專有模型的效能水準，但適合嚴謹科學調查的高品質程式碼 LLM，特別是那些具有可複製資料處理管線和透明訓練協定的程式碼 LLM，仍然有限。這種稀缺性是由於各種挑戰，包括資源限制、倫理考量以及保持模型先進的競爭優勢。為了解決這個差距，我們引入了 OpenCoder，這是一個頂級程式碼 LLM，不僅能達到與領先模型相當的效能，還能作為研究社群的「開放食譜」。與大多數先前的努力不同，我們不僅釋出模型權重和推論程式碼，還釋出可複製的訓練資料、完整的資料處理管線、嚴謹的實驗消融結果，以及開放科學研究的詳細訓練協定。透過這個全面的釋出，我們找出建立頂級程式碼 LLM 的關鍵要素：(1) 資料清理的最佳化啟發式規則和資料重複消除的方法，(2) 與程式碼相關的文字語料庫的召回，以及 (3) 退火和監督微調階段中的高品質合成資料。透過提供這種程度的開放性，我們旨在擴大對頂級程式碼 LLM 各個方面的使用，讓 OpenCoder 同時成為強大的模型和開放基礎，以加速研究，並促進程式碼 AI 的可複製進展。

##### **GUI Agents with Foundation Models: A Comprehensive Survey**
2411.04890v1 by Shuai Wang, Weiwen Liu, Jingxuan Chen, Weinan Gan, Xingshan Zeng, Shuai Yu, Xinlong Hao, Kun Shao, Yasheng Wang, Ruiming Tang

Recent advances in foundation models, particularly Large Language Models
(LLMs) and Multimodal Large Language Models (MLLMs), facilitate intelligent
agents being capable of performing complex tasks. By leveraging the ability of
(M)LLMs to process and interpret Graphical User Interfaces (GUIs), these agents
can autonomously execute user instructions by simulating human-like
interactions such as clicking and typing. This survey consolidates recent
research on (M)LLM-based GUI agents, highlighting key innovations in data,
frameworks, and applications. We begin by discussing representative datasets
and benchmarks. Next, we summarize a unified framework that captures the
essential components used in prior research, accompanied by a taxonomy.
Additionally, we explore commercial applications of (M)LLM-based GUI agents.
Drawing from existing work, we identify several key challenges and propose
future research directions. We hope this paper will inspire further
developments in the field of (M)LLM-based GUI agents.

摘要：最近在基礎模型的進展，特別是大型語言模型 (LLM) 和多模態大型語言模型 (MLLM)，促進智能代理能夠執行複雜的任務。藉由運用 (M)LLM 處理和詮釋圖形使用者介面 (GUI) 的能力，這些代理可以透過模擬點擊和輸入等類似人類的互動，自動執行使用者的指令。此調查彙整了最近關於 (M)LLM 為基礎的 GUI 代理的研究，重點說明了資料、架構和應用程式的關鍵創新。我們從討論具代表性的資料集和基準開始。接著，我們摘要一個統一的架構，其中包含先前研究中使用的基本元件，並附上分類法。此外，我們探討 (M)LLM 為基礎的 GUI 代理的商業應用。根據現有工作，我們找出幾個關鍵挑戰，並提出未來的研究方向。我們希望這篇論文能激發 (M)LLM 為基礎的 GUI 代理領域的進一步發展。

##### **FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI**
2411.04872v1 by Elliot Glazer, Ege Erdil, Tamay Besiroglu, Diego Chicharro, Evan Chen, Alex Gunning, Caroline Falkman Olsson, Jean-Stanislas Denain, Anson Ho, Emily de Oliveira Santos, Olli Järviniemi, Matthew Barnett, Robert Sandler, Jaime Sevilla, Qiuyu Ren, Elizabeth Pratt, Lionel Levine, Grant Barkley, Natalie Stewart, Bogdan Grechuk, Tetiana Grechuk, Shreepranav Varma Enugandla

We introduce FrontierMath, a benchmark of hundreds of original, exceptionally
challenging mathematics problems crafted and vetted by expert mathematicians.
The questions cover most major branches of modern mathematics -- from
computationally intensive problems in number theory and real analysis to
abstract questions in algebraic geometry and category theory. Solving a typical
problem requires multiple hours of effort from a researcher in the relevant
branch of mathematics, and for the upper end questions, multiple days.
FrontierMath uses new, unpublished problems and automated verification to
reliably evaluate models while minimizing risk of data contamination. Current
state-of-the-art AI models solve under 2% of problems, revealing a vast gap
between AI capabilities and the prowess of the mathematical community. As AI
systems advance toward expert-level mathematical abilities, FrontierMath offers
a rigorous testbed that quantifies their progress.

摘要：我們推出 FrontierMath，這是數百個由專家數學家精心製作和審查的原創、極具挑戰性的數學問題的基準。這些問題涵蓋了現代數學的大多數主要分支——從數論和實分析中的計算密集型問題到代數幾何和範疇論中的抽象問題。解決一個典型問題需要相關數學分支的研究人員花費數小時的精力，而對於較難的問題，則需要數天時間。FrontierMath 使用新的、未發表的題目和自動化驗證來可靠地評估模型，同時最大限度地降低數據污染的風險。當前的最先進 AI 模型只能解決不到 2% 的問題，這揭示了 AI 能力與數學界的實力之間存在巨大差距。隨著 AI 系統向專家級數學能力邁進，FrontierMath 提供了一個嚴格的測試平台，可以量化它們的進度。

##### **Think Smart, Act SMARL! Analyzing Probabilistic Logic Driven Safety in Multi-Agent Reinforcement Learning**
2411.04867v1 by Satchit Chatterji, Erman Acar

An important challenge for enabling the deployment of reinforcement learning
(RL) algorithms in the real world is safety. This has resulted in the recent
research field of Safe RL, which aims to learn optimal policies that are safe.
One successful approach in that direction is probabilistic logic shields (PLS),
a model-based Safe RL technique that uses formal specifications based on
probabilistic logic programming, constraining an agent's policy to comply with
those specifications in a probabilistic sense. However, safety is inherently a
multi-agent concept, since real-world environments often involve multiple
agents interacting simultaneously, leading to a complex system which is hard to
control. Moreover, safe multi-agent RL (Safe MARL) is still underexplored. In
order to address this gap, in this paper we ($i$) introduce Shielded MARL
(SMARL) by extending PLS to MARL -- in particular, we introduce Probabilistic
Logic Temporal Difference Learning (PLTD) to enable shielded independent
Q-learning (SIQL), and introduce shielded independent PPO (SIPPO) using
probabilistic logic policy gradients; ($ii$) show its positive effect and use
as an equilibrium selection mechanism in various game-theoretic environments
including two-player simultaneous games, extensive-form games, stochastic
games, and some grid-world extensions in terms of safety, cooperation, and
alignment with normative behaviors; and ($iii$) look into the asymmetric case
where only one agent is shielded, and show that the shielded agent has a
significant influence on the unshielded one, providing further evidence of
SMARL's ability to enhance safety and cooperation in diverse multi-agent
environments.

摘要：<paragraph>在現實世界中部署強化學習 (RL) 演算法的一項重要挑戰在於安全性。這導致了近期研究領域的安全 RL，其目標是學習安全的最佳策略。朝這個方向發展的一種成功方法是機率邏輯防護 (PLS)，這是一種基於模型的安全 RL 技術，它使用基於機率邏輯程式設計的形式化規範，以機率意義限制代理的策略以符合這些規範。然而，安全性本質上是一個多重代理概念，因為現實世界的環境通常涉及多個代理同時互動，導致一個難以控制的複雜系統。此外，安全多重代理 RL (Safe MARL) 仍未得到充分探索。為了解決這個差距，在本文中我們 ($i$) 透過將 PLS 擴充到 MARL 來介紹防護式 MARL (SMARL) -- 特別是，我們介紹機率邏輯時序差分學習 (PLTD) 以啟用防護式獨立 Q 學習 (SIQL)，並使用機率邏輯策略梯度引入防護式獨立 PPO (SIPPO)；($ii$) 展示其正面效應，並用作各種博弈論環境中的均衡選擇機制，包括雙人同時博弈、廣義型博弈、隨機博弈，以及在安全性、合作和與規範行為一致性方面的某些格狀世界擴充；以及 ($iii$) 探討只有單一代理防護的不對稱案例，並展示防護式代理對未防護式代理有顯著影響，進一步證明 SMARL 能夠增強不同多重代理環境中的安全性與合作。</paragraph>

##### **ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset**
2411.04865v1 by Olaf Wysocki, Yue Tan, Thomas Froech, Yan Xia, Magdalena Wysocki, Ludwig Hoegner, Daniel Cremers, Christoph Holst

Facade semantic segmentation is a long-standing challenge in photogrammetry
and computer vision. Although the last decades have witnessed the influx of
facade segmentation methods, there is a lack of comprehensive facade classes
and data covering the architectural variability. In ZAHA, we introduce Level of
Facade Generalization (LoFG), novel hierarchical facade classes designed based
on international urban modeling standards, ensuring compatibility with
real-world challenging classes and uniform methods' comparison. Realizing the
LoFG, we present to date the largest semantic 3D facade segmentation dataset,
providing 601 million annotated points at five and 15 classes of LoFG2 and
LoFG3, respectively. Moreover, we analyze the performance of baseline semantic
segmentation methods on our introduced LoFG classes and data, complementing it
with a discussion on the unresolved challenges for facade segmentation. We
firmly believe that ZAHA shall facilitate further development of 3D facade
semantic segmentation methods, enabling robust segmentation indispensable in
creating urban digital twins.

摘要：外觀語義分割是攝影測量和電腦視覺中長期存在的挑戰。儘管在過去的幾十年中見證了外觀分割方法的湧入，但仍缺乏涵蓋建築可變性的綜合外觀類別和資料。在 ZAHA 中，我們引入了外觀概括層級 (LoFG)，一種基於國際城市建模標準設計的新階層式外觀類別，確保與現實世界中的挑戰性類別和統一方法的比較相容。實現 LoFG 後，我們迄今為止提供了最大的語義 3D 外觀分割資料集，分別在 LoFG2 和 LoFG3 的五個和 15 個類別中提供了 6 億個註解點。此外，我們分析了基線語義分割方法在其引入的 LoFG 類別和資料上的效能，並補充討論了外觀分割中未解決的挑戰。我們堅信 ZAHA 將促進 3D 外觀語義分割方法的進一步發展，實現強健的分割，這對於建立城市數位雙胞胎至關重要。

##### **Sentiment Analysis of Spanish Political Party Tweets Using Pre-trained Language Models**
2411.04862v1 by Chuqiao Song, Shunzhang Chen, Xinyi Cai, Hao Chen

Title: Sentiment Analysis of Spanish Political Party Communications on
Twitter Using Pre-trained Language Models
  Authors: Chuqiao Song, Shunzhang Chen, Xinyi Cai, Hao Chen
  Comments: 21 pages, 6 figures
  Abstract: This study investigates sentiment patterns within Spanish political
party communications on Twitter by leveraging BETO and RoBERTuito, two
pre-trained language models optimized for Spanish text. Using a dataset of
tweets from major Spanish political parties: PSOE, PP, Vox, Podemos, and
Ciudadanos, spanning 2019 to 2024, this research analyzes sentiment
distributions and explores the relationship between sentiment expression and
party ideology. The findings indicate that both models consistently identify a
predominant Neutral sentiment across all parties, with significant variations
in Negative and Positive sentiments that align with ideological distinctions.
Specifically, Vox exhibits higher levels of Negative sentiment, while PSOE
demonstrates relatively high Positive sentiment, supporting the hypothesis that
emotional appeals in political messaging reflect ideological stances. This
study underscores the potential of pre-trained language models for non-English
sentiment analysis on social media, providing insights into sentiment dynamics
that shape public discourse within Spain's multi-party political system.
  Keywords: Spanish politics, sentiment analysis, pre-trained language models,
Twitter, BETO, RoBERTuito, political ideology, multi-party system

摘要：<paragraph>標題：使用預先訓練語言模型對西班牙政黨在推特上的溝通進行情緒分析
作者：宋楚喬、陳順章、蔡欣怡、陳浩
評論：21 頁、6 張圖
摘要：本研究利用針對西班牙語文本最佳化的兩個預先訓練語言模型 BETO 和 RoBERTuito，探討西班牙政黨在推特上的溝通中的情緒模式。本研究使用 2019 年至 2024 年間西班牙主要政黨（PSOE、PP、Vox、Podemos 和 Ciudadanos）的推文資料集，分析情緒分佈，並探討情緒表達與政黨意識形態之間的關係。研究結果顯示，這兩個模型一致地發現所有政黨的情緒以中立情緒為主，而負面和正面情緒的顯著變化與意識形態區別一致。具體來說，Vox 表現出較高的負面情緒，而 PSOE 表現出較高的正面情緒，這支持了政治訊息中的情緒訴求反映意識形態立場的假設。本研究強調了預先訓練語言模型在非英語社群媒體情緒分析中的潛力，並提供了對情緒動態的見解，這些動態塑造了西班牙多黨政治體系中的公共論述。
關鍵字：西班牙政治、情緒分析、預先訓練語言模型、推特、BETO、RoBERTuito、政治意識形態、多黨制</paragraph>

##### **Prompt-Guided Internal States for Hallucination Detection of Large Language Models**
2411.04847v1 by Fujie Zhang, Peiqi Yu, Biao Yi, Baolei Zhang, Tong Li, Zheli Liu

Large Language Models (LLMs) have demonstrated remarkable capabilities across
a variety of tasks in different domains. However, they sometimes generate
responses that are logically coherent but factually incorrect or misleading,
which is known as LLM hallucinations. Data-driven supervised methods train
hallucination detectors by leveraging the internal states of LLMs, but
detectors trained on specific domains often struggle to generalize well to
other domains. In this paper, we aim to enhance the cross-domain performance of
supervised detectors with only in-domain data. We propose a novel framework,
prompt-guided internal states for hallucination detection of LLMs, namely
PRISM. By utilizing appropriate prompts to guide changes in the structure
related to text truthfulness within the LLM's internal states, we make this
structure more salient and consistent across texts from different domains. We
integrated our framework with existing hallucination detection methods and
conducted experiments on datasets from different domains. The experimental
results indicate that our framework significantly enhances the cross-domain
generalization of existing hallucination detection methods.

摘要：大型語言模型 (LLM) 已展示出在不同領域的各種任務中具有非凡的能力。然而，它們有時會產生在邏輯上連貫但事實上不正確或具有誤導性的回應，這被稱為 LLM 幻覺。數據驅動的監督方法通過利用 LLM 的內部狀態來訓練幻覺檢測器，但針對特定領域訓練的檢測器通常難以很好地推廣到其他領域。在本文中，我們旨在僅使用域內數據來增強監督檢測器的跨域性能。我們提出了一個新框架，即用於 LLM 幻覺檢測的提示引導內部狀態，即 PRISM。通過使用適當的提示來指導與 LLM 內部狀態中與文本真實性相關的結構的變化，我們使該結構更突出，並在來自不同領域的文本中保持一致。我們將我們的框架與現有的幻覺檢測方法集成在一起，並對來自不同領域的數據集進行了實驗。實驗結果表明，我們的框架顯著增強了現有幻覺檢測方法的跨域泛化。

##### **Machine learning and optimization-based approaches to duality in statistical physics**
2411.04838v1 by Andrea E. V. Ferrari, Prateek Gupta, Nabil Iqbal

The notion of duality -- that a given physical system can have two different
mathematical descriptions -- is a key idea in modern theoretical physics.
Establishing a duality in lattice statistical mechanics models requires the
construction of a dual Hamiltonian and a map from the original to the dual
observables. By using simple neural networks to parameterize these maps and
introducing a loss function that penalises the difference between correlation
functions in original and dual models, we formulate the process of duality
discovery as an optimization problem. We numerically solve this problem and
show that our framework can rediscover the celebrated Kramers-Wannier duality
for the 2d Ising model, reconstructing the known mapping of temperatures. We
also discuss an alternative approach which uses known features of the mapping
of topological lines to reduce the problem to optimizing the couplings in a
dual Hamiltonian, and explore next-to-nearest neighbour deformations of the 2d
Ising duality. We discuss future directions and prospects for discovering new
dualities within this framework.

摘要：對偶性的概念——即一個給定的物理系統可以有兩個不同的數學描述——是現代理論物理學中的關鍵思想。在晶格統計力學模型中建立對偶性需要構建一個對偶哈密頓量和一個從原始可觀測量到對偶可觀測量的映射。通過使用簡單的神經網路對這些映射進行參數化，並引入一個損失函數來懲罰原始模型和對偶模型中相關函數之間的差異，我們將對偶性發現過程表述為一個優化問題。我們對這個問題進行數值求解，並表明我們的框架可以重新發現 2d Ising 模型的著名 Kramers-Wannier 對偶性，重建已知的溫度映射。我們還討論了另一種方法，該方法使用拓撲線映射的已知特徵將問題簡化為優化對偶哈密頓量中的耦合，並探索了 2d Ising 對偶性的次近鄰變形。我們討論了在這個框架內發現新對偶性的未來方向和前景。

##### **VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and Benchmark Models**
2411.04825v1 by Ming Cheng, Jiaying Gong, Chenhan Yuan, William A. Ingram, Edward Fox, Hoda Eldardiry

Existing text simplification or paraphrase datasets mainly focus on
sentence-level text generation in a general domain. These datasets are
typically developed without using domain knowledge. In this paper, we release a
novel dataset, VTechAGP, which is the first academic-to-general-audience text
paraphrase dataset consisting of 4,938 document-level these and dissertation
academic and general-audience abstract pairs from 8 colleges authored over 25
years. We also propose a novel dynamic soft prompt generative language model,
DSPT5. For training, we leverage a contrastive-generative loss function to
learn the keyword vectors in the dynamic prompt. For inference, we adopt a
crowd-sampling decoding strategy at both semantic and structural levels to
further select the best output candidate. We evaluate DSPT5 and various
state-of-the-art large language models (LLMs) from multiple perspectives.
Results demonstrate that the SOTA LLMs does not provide satisfactory outcomes,
while the lightweight DSPT5 can achieve competitive results. To the best of our
knowledge, we are the first to build a benchmark dataset and solutions for
academic-to-general-audience text paraphrase dataset.

摘要：現有的文字簡化或改寫資料集主要集中在一般領域的句子級文字產生。這些資料集通常在不使用領域知識的情況下開發。在本文中，我們發布了一個新的資料集 VTechAGP，它是第一個由學術轉向大眾的文字改寫資料集，包含 4,938 個文件級別的論文和論文學術和一般受眾摘要對，來自 8 所大學，撰寫於 25 年以上。我們還提出了一種新的動態軟提示生成語言模型 DSPT5。對於訓練，我們利用對比生成損失函數來學習動態提示中的關鍵字向量。對於推理，我們在語義和結構層級採用群眾採樣解碼策略，進一步選擇最佳輸出候選。我們從多個角度評估了 DSPT5 和各種最先進的大語言模型 (LLM)。結果表明，SOTA LLM 沒有提供令人滿意的結果，而輕量級的 DSPT5 可以實現有競爭力的結果。據我們所知，我們是第一個為學術到一般受眾的文字改寫資料集構建基準資料集和解決方案的人。

##### **When Does Classical Chinese Help? Quantifying Cross-Lingual Transfer in Hanja and Kanbun**
2411.04822v1 by Seyoung Song, Haneul Yoo, Jiho Jin, Kyunghyun Cho, Alice Oh

Historical and linguistic connections within the Sinosphere have led
researchers to use Classical Chinese resources for cross-lingual transfer when
processing historical documents from Korea and Japan. In this paper, we
question the assumption of cross-lingual transferability from Classical Chinese
to Hanja and Kanbun, the ancient written languages of Korea and Japan,
respectively. Our experiments across machine translation, named entity
recognition, and punctuation restoration tasks show minimal impact of Classical
Chinese datasets on language model performance for ancient Korean documents
written in Hanja, with performance differences within $\pm{}0.0068$ F1-score
for sequence labeling tasks and up to $+0.84$ BLEU score for translation. These
limitations persist consistently across various model sizes, architectures, and
domain-specific datasets. Our analysis reveals that the benefits of Classical
Chinese resources diminish rapidly as local language data increases for Hanja,
while showing substantial improvements only in extremely low-resource scenarios
for both Korean and Japanese historical documents. These mixed results
emphasize the need for careful empirical validation rather than assuming
benefits from indiscriminate cross-lingual transfer.

摘要：歷史和語言在漢語圈內的聯繫，導致研究人員在處理韓國和日本的歷史文件時，使用古典中文資源進行跨語言轉移。在本文中，我們質疑了從古典中文到韓文和日文的古代書面語言韓文和漢文，在跨語言可轉移性的假設。我們在機器翻譯、命名實體辨識和標點符號還原任務中的實驗，顯示古典中文資料集對用韓文寫成的古代韓文文件的語言模型效能影響很小，序列標籤任務的效能差異在 $\pm{}0.0068$ F1 分數內，而翻譯的 BLEU 分數最高可達 $+0.84$。這些限制在各種模型大小、架構和特定領域資料集上持續存在。我們的分析顯示，隨著韓文的在地語言資料增加，古典中文資源的優勢迅速下降，而只在韓文和日文歷史文件的極低資源場景中，才顯示出顯著的改善。這些混合的結果強調了仔細實證驗證的必要性，而不是假設不加區別的跨語言轉移的優點。

##### **LuxBank: The First Universal Dependency Treebank for Luxembourgish**
2411.04813v1 by Alistair Plum, Caroline Döhmer, Emilia Milano, Anne-Marie Lutgen, Christoph Purschke

The Universal Dependencies (UD) project has significantly expanded linguistic
coverage across 161 languages, yet Luxembourgish, a West Germanic language
spoken by approximately 400,000 people, has remained absent until now. In this
paper, we introduce LuxBank, the first UD Treebank for Luxembourgish,
addressing the gap in syntactic annotation and analysis for this `low-research'
language. We establish formal guidelines for Luxembourgish language annotation,
providing the foundation for the first large-scale quantitative analysis of its
syntax. LuxBank serves not only as a resource for linguists and language
learners but also as a tool for developing spell checkers and grammar checkers,
organising existing text archives and even training large language models. By
incorporating Luxembourgish into the UD framework, we aim to enhance the
understanding of syntactic variation within West Germanic languages and offer a
model for documenting smaller, semi-standardised languages. This work positions
Luxembourgish as a valuable resource in the broader linguistic and NLP
communities, contributing to the study of languages with limited research and
resources.

摘要：通用依賴關係 (UD) 專案已大幅擴展 161 種語言的語言涵蓋範圍，但盧森堡語，一種約有 40 萬人使用的西日耳曼語，至今仍未納入其中。在本文中，我們將介紹 LuxBank，這是盧森堡語的第一個 UD 樹庫，用於解決這種「低研究」語言在句法註釋和分析方面的差距。我們為盧森堡語註釋建立了正式準則，為其首次大規模量化分析奠定基礎。LuxBank 不僅可用於語言學家和語言學習者，還可用於開發拼寫檢查器和語法檢查器，組織現有文字檔案，甚至訓練大型語言模型。透過將盧森堡語納入 UD 架構，我們旨在加強對西日耳曼語句法變化的理解，並提供一個用於記錄較小的半標準化語言的模型。這項工作將盧森堡語定位為更廣泛的語言學和 NLP 社群中的寶貴資源，有助於研究研究和資源有限的語言。

##### **Defending Deep Regression Models against Backdoor Attacks**
2411.04811v1 by Lingyu Du, Yupei Liu, Jinyuan Jia, Guohao Lan

Deep regression models are used in a wide variety of safety-critical
applications, but are vulnerable to backdoor attacks. Although many defenses
have been proposed for classification models, they are ineffective as they do
not consider the uniqueness of regression models. First, the outputs of
regression models are continuous values instead of discretized labels. Thus,
the potential infected target of a backdoored regression model has infinite
possibilities, which makes it impossible to be determined by existing defenses.
Second, the backdoor behavior of backdoored deep regression models is triggered
by the activation values of all the neurons in the feature space, which makes
it difficult to be detected and mitigated using existing defenses. To resolve
these problems, we propose DRMGuard, the first defense to identify if a deep
regression model in the image domain is backdoored or not. DRMGuard formulates
the optimization problem for reverse engineering based on the unique
output-space and feature-space characteristics of backdoored deep regression
models. We conduct extensive evaluations on two regression tasks and four
datasets. The results show that DRMGuard can consistently defend against
various backdoor attacks. We also generalize four state-of-the-art defenses
designed for classifiers to regression models, and compare DRMGuard with them.
The results show that DRMGuard significantly outperforms all those defenses.

摘要：深度迴歸模型被廣泛應用於各種安全關鍵應用程式中，但容易受到後門攻擊。儘管已提出許多針對分類模型的防禦措施，但它們無效，因為它們沒有考慮迴歸模型的獨特性。首先，迴歸模型的輸出是連續值，而不是離散標籤。因此，後門迴歸模型潛在的受感染目標具有無限可能性，這使得現有防禦措施無法確定。其次，後門深度迴歸模型的後門行為是由特徵空間中所有神經元的激活值觸發的，這使得使用現有防禦措施難以檢測和減輕。為了解決這些問題，我們提出了 DRMGuard，這是第一個用於識別影像域中的深度迴歸模型是否被後門化的防禦措施。DRMGuard 根據後門深度迴歸模型的獨特輸出空間和特徵空間特徵來制定逆向工程的最佳化問題。我們對兩個迴歸任務和四個資料集進行了廣泛的評估。結果表明，DRMGuard 可以持續抵禦各種後門攻擊。我們還將四種針對分類器的最先進防禦措施推廣到迴歸模型，並將 DRMGuard 與它們進行比較。結果表明，DRMGuard 明顯優於所有這些防禦措施。

##### **Kwai-STaR: Transform LLMs into State-Transition Reasoners**
2411.04799v1 by Xingyu Lu, Yuhang Hu, Changyi Liu, Tianke Zhang, Zhenyu Yang, Zhixiang Ding, Shengsheng Qian, Meng Du, Ruiwen Kang, Kaiyu Tang, Fan Yang, Tingting Gao, Di Zhang, Hai-Tao Zheng, Bin Wen

Mathematical reasoning presents a significant challenge to the cognitive
capabilities of LLMs. Various methods have been proposed to enhance the
mathematical ability of LLMs. However, few recognize the value of state
transition for LLM reasoning. In this work, we define mathematical
problem-solving as a process of transiting from an initial unsolved state to
the final resolved state, and propose Kwai-STaR framework, which transforms
LLMs into State-Transition Reasoners to improve their intuitive reasoning
capabilities. Our approach comprises three main steps: (1) Define the state
space tailored to the mathematical reasoning. (2) Generate state-transition
data based on the state space. (3) Convert original LLMs into State-Transition
Reasoners via a curricular training strategy. Our experiments validate the
effectiveness of Kwai-STaR in enhancing mathematical reasoning: After training
on the small-scale Kwai-STaR dataset, general LLMs, including Mistral-7B and
LLaMA-3, achieve considerable performance gain on the GSM8K and GSM-Hard
dataset. Additionally, the state transition-based design endows Kwai-STaR with
remarkable training and inference efficiency. Further experiments are underway
to establish the generality of Kwai-STaR.

摘要：數學推理對 LLM 的認知能力提出重大挑戰。已經提出各種方法來增強 LLM 的數學能力。然而，很少有人認識到狀態轉換對 LLM 推理的價值。在這項工作中，我們將數學問題求解定義為從初始未解決狀態轉換到最終已解決狀態的過程，並提出 Kwai-STaR 框架，它將 LLM 轉換為狀態轉換推理器以提高其直覺推理能力。我們的做法包含三個主要步驟：(1) 定義適合數學推理的狀態空間。(2) 基於狀態空間生成狀態轉換數據。(3) 通過課程訓練策略將原始 LLM 轉換為狀態轉換推理器。我們的實驗驗證了 Kwai-STaR 在增強數學推理方面的有效性：在小規模 Kwai-STaR 數據集上訓練後，包括 Mistral-7B 和 LLaMA-3 在內的通用 LLM 在 GSM8K 和 GSM-Hard 數據集上取得了顯著的性能提升。此外，基於狀態轉換的設計賦予 Kwai-STaR 卓越的訓練和推理效率。進一步的實驗正在進行中，以建立 Kwai-STaR 的普遍性。

##### **MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation**
2411.04796v1 by Sayan Paul, Ruddra dev Roychoudhury, Brojeshwar Bhowmick

Visual odometry (VO) is essential for enabling accurate point-goal navigation
of embodied agents in indoor environments where GPS and compass sensors are
unreliable and inaccurate. However, traditional VO methods face challenges in
wide-baseline scenarios, where fast robot motions and low frames per second
(FPS) during inference hinder their performance, leading to drift and
catastrophic failures in point-goal navigation. Recent deep-learned VO methods
show robust performance but suffer from sample inefficiency during training;
hence, they require huge datasets and compute resources. So, we propose a
robust and sample-efficient VO pipeline based on motion priors available while
an agent is navigating an environment. It consists of a training-free
action-prior based geometric VO module that estimates a coarse relative pose
which is further consumed as a motion prior by a deep-learned VO model, which
finally produces a fine relative pose to be used by the navigation policy. This
strategy helps our pipeline achieve up to 2x sample efficiency during training
and demonstrates superior accuracy and robustness in point-goal navigation
tasks compared to state-of-the-art VO method(s). Realistic indoor environments
of the Gibson dataset is used in the AI-Habitat simulator to evaluate the
proposed approach using navigation metrics (like success/SPL) and pose metrics
(like RPE/ATE). We hope this method further opens a direction of work where
motion priors from various sources can be utilized to improve VO estimates and
achieve better results in embodied navigation tasks.

摘要：視覺里程計 (VO) 對於在 GPS 和指南針感測器不可靠且不準確的室內環境中，讓具身代理執行精確的點目標導航至關重要。然而，傳統的 VO 方法在廣基線場景中會遇到挑戰，其中機器人的快速移動和在推論期間每秒低幀數 (FPS) 會阻礙其效能，導致點目標導航中的漂移和災難性故障。最近深度學習的 VO 方法顯示出穩健的效能，但在訓練期間會遇到樣本效率低下；因此，它們需要大量的資料集和運算資源。因此，我們提出一個穩健且樣本效率高的 VO 管線，基於在代理導航環境時可用的運動先驗。它包含一個免訓練的基於動作先驗的幾何 VO 模組，用於估計粗略的相對位姿，而後由深度學習的 VO 模型將其用作運動先驗，最終產生一個精細的相對位姿，供導航策略使用。此策略有助於我們的管線在訓練期間達到高達 2 倍的樣本效率，並在點目標導航任務中展現出比現有 VO 方法更好的準確度和穩健性。Gibson 資料集的逼真室內環境用於 AI-Habitat 模擬器，以使用導航指標（例如成功/SPL）和位姿指標（例如 RPE/ATE）評估所提出的方法。我們希望此方法進一步開啟一個工作方向，其中可以利用來自各種來源的運動先驗來改善 VO 估計，並在具身導航任務中取得更好的結果。

##### **AlignXIE: Improving Multilingual Information Extraction by Cross-Lingual Alignment**
2411.04794v1 by Yuxin Zuo, Wenxuan Jiang, Wenxuan Liu, Zixuan Li, Long Bai, Hanbin Wang, Yutao Zeng, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng

Empirical evidence suggests that LLMs exhibit spontaneous cross-lingual
alignment. Our findings suggest that although LLMs also demonstrate promising
cross-lingual alignment in Information Extraction, there remains significant
imbalance across languages, revealing an underlying deficiency in the IE
alignment. To address this issue, we propose AlignXIE, a powerful code-based
LLM that significantly enhances cross-lingual IE alignment through two
strategies. Firstly, AlignXIE formulates IE across different languages,
especially non-English ones, as code generation tasks, standardizing the
representation of various schemas using Python classes to ensure consistency of
the same ontology in different languages and align the schema. Secondly, it
incorporates an IE cross-lingual alignment phase through a translated instance
prediction task proposed in this paper to align the extraction process,
utilizing ParallelNER, an IE bilingual parallel dataset with 257,190 samples,
generated by our proposed LLM-based automatic pipeline for IE parallel data
construction, with manual annotation to ensure quality. Ultimately, we obtain
AlignXIE through multilingual IE instruction tuning. Although without training
in 9 unseen languages, AlignXIE surpasses ChatGPT by $30.17\%$ and SoTA by
$20.03\%$, thereby demonstrating superior cross-lingual IE capabilities.
Comprehensive evaluations on 63 IE benchmarks in Chinese and English under
various settings, demonstrate that AlignXIE significantly enhances
cross-lingual and multilingual IE through boosting the IE alignment.

摘要：經驗證據表明，LLM 表現出自發的跨語言對齊。我們的研究結果表明，儘管 LLM 也在資訊擷取中展示出有希望的跨語言對齊，但不同語言之間仍然存在顯著的不平衡，這揭示了 IE 對齊中的潛在缺陷。為了解決這個問題，我們提出了 AlignXIE，一種強大的基於程式碼的 LLM，它通過兩種策略顯著增強了跨語言 IE 對齊。首先，AlignXIE 將不同語言（特別是非英語語言）中的 IE 制定為程式碼生成任務，使用 Python 類標準化各種模式的表示，以確保不同語言中相同本体的一致性並對齊模式。其次，它通過本文提出的翻譯實例預測任務，結合了 IE 跨語言對齊階段，以對齊擷取過程，利用 ParallelNER，一個由我們提出的基於 LLM 的自動管道生成的包含 257,190 個範例的 IE 雙語平行資料集，並通過人工註解確保品質。最終，我們通過多語言 IE 指令調整獲得 AlignXIE。儘管沒有在 9 種未見過的語言中進行訓練，但 AlignXIE 超越了 ChatGPT 30.17%，超越了 SoTA 20.03%，從而展示了卓越的跨語言 IE 能力。在各種設定下對中文和英文中的 63 個 IE 基準進行的綜合評估表明，AlignXIE 通過提升 IE 對齊，顯著增強了跨語言和多語言 IE。

##### **Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research**
2411.04788v1 by Xuewen Han, Neng Wang, Shangkun Che, Hongyang Yang, Kunpeng Zhang, Sean Xin Xu

In recent years, the application of generative artificial intelligence
(GenAI) in financial analysis and investment decision-making has gained
significant attention. However, most existing approaches rely on single-agent
systems, which fail to fully utilize the collaborative potential of multiple AI
agents. In this paper, we propose a novel multi-agent collaboration system
designed to enhance decision-making in financial investment research. The
system incorporates agent groups with both configurable group sizes and
collaboration structures to leverage the strengths of each agent group type. By
utilizing a sub-optimal combination strategy, the system dynamically adapts to
varying market conditions and investment scenarios, optimizing performance
across different tasks. We focus on three sub-tasks: fundamentals, market
sentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30
companies listed on the Dow Jones Index. Our findings reveal significant
performance variations based on the configurations of AI agents for different
tasks. The results demonstrate that our multi-agent collaboration system
outperforms traditional single-agent models, offering improved accuracy,
efficiency, and adaptability in complex financial environments. This study
highlights the potential of multi-agent systems in transforming financial
analysis and investment decision-making by integrating diverse analytical
perspectives.

摘要：近年來，生成式人工智慧 (GenAI) 在財務分析和投資決策中的應用備受矚目。然而，現有的方法大多依賴於單一代理系統，無法充分利用多個 AI 代理的協作潛力。在本文中，我們提出一個新穎的多代理協作系統，旨在增強財務投資研究中的決策制定。該系統結合了具有可配置群組規模和協作結構的代理群組，以利用每個代理群組類型的優勢。通過使用次優組合策略，該系統可動態適應不同的市場條件和投資情境，優化不同任務的績效。我們專注於三項子任務：基本面、市場情緒和風險分析，方法是分析道瓊指數中 30 家公司的 2023 年 SEC 10-K 表格。我們的研究結果顯示，根據不同任務的 AI 代理配置，績效差異顯著。結果表明，我們的多代理協作系統優於傳統的單一代理模型，在複雜的財務環境中提供更高的準確性、效率和適應性。本研究強調了多代理系統在轉變財務分析和投資決策方面的潛力，方法是整合不同的分析觀點。

##### **A study of Vietnamese readability assessing through semantic and statistical features**
2411.04756v1 by Hung Tuan Le, Long Truong To, Manh Trong Nguyen, Quyen Nguyen, Trong-Hop Do

Determining the difficulty of a text involves assessing various textual
features that may impact the reader's text comprehension, yet current research
in Vietnamese has only focused on statistical features. This paper introduces a
new approach that integrates statistical and semantic approaches to assessing
text readability. Our research utilized three distinct datasets: the Vietnamese
Text Readability Dataset (ViRead), OneStopEnglish, and RACE, with the latter
two translated into Vietnamese. Advanced semantic analysis methods were
employed for the semantic aspect using state-of-the-art language models such as
PhoBERT, ViDeBERTa, and ViBERT. In addition, statistical methods were
incorporated to extract syntactic and lexical features of the text. We
conducted experiments using various machine learning models, including Support
Vector Machine (SVM), Random Forest, and Extra Trees and evaluated their
performance using accuracy and F1 score metrics. Our results indicate that a
joint approach that combines semantic and statistical features significantly
enhances the accuracy of readability classification compared to using each
method in isolation. The current study emphasizes the importance of considering
both statistical and semantic aspects for a more accurate assessment of text
difficulty in Vietnamese. This contribution to the field provides insights into
the adaptability of advanced language models in the context of Vietnamese text
readability. It lays the groundwork for future research in this area.

摘要：<paragraph>評量文本難度涉及評估各種可能影響讀者文本理解的文本特徵，然而目前越南語的研究僅關注於統計特徵。本文介紹一種新的方法，將統計方法和語義方法整合起來評估文本可讀性。我們的研究利用了三個不同的資料集：越南語文本可讀性資料集 (ViRead)、OneStopEnglish 和 RACE，後兩個已翻譯成越南語。使用最先進的語言模型（例如 PhoBERT、ViDeBERTa 和 ViBERT）對語義方面採用了先進的語義分析方法。此外，還納入了統計方法來提取文本的句法和詞彙特徵。我們使用各種機器學習模型進行了實驗，包括支持向量機 (SVM)、隨機森林和極端樹，並使用準確度和 F1 分數指標評估了它們的性能。我們的結果表明，與孤立地使用每種方法相比，結合語義和統計特徵的聯合方法顯著提高了可讀性分類的準確度。目前的研究強調了在越南語中更準確評估文本難度時考慮統計和語義方面的同時重要性。對該領域的這項貢獻提供了對越南語文本可讀性背景下先進語言模型的適應性的見解。它為該領域的未來研究奠定了基礎。</paragraph>

##### **RetrieveGPT: Merging Prompts and Mathematical Models for Enhanced Code-Mixed Information Retrieval**
2411.04752v1 by Aniket Deroy, Subhankar Maity

Code-mixing, the integration of lexical and grammatical elements from
multiple languages within a single sentence, is a widespread linguistic
phenomenon, particularly prevalent in multilingual societies. In India, social
media users frequently engage in code-mixed conversations using the Roman
script, especially among migrant communities who form online groups to share
relevant local information. This paper focuses on the challenges of extracting
relevant information from code-mixed conversations, specifically within Roman
transliterated Bengali mixed with English. This study presents a novel approach
to address these challenges by developing a mechanism to automatically identify
the most relevant answers from code-mixed conversations. We have experimented
with a dataset comprising of queries and documents from Facebook, and Query
Relevance files (QRels) to aid in this task. Our results demonstrate the
effectiveness of our approach in extracting pertinent information from complex,
code-mixed digital conversations, contributing to the broader field of natural
language processing in multilingual and informal text environments. We use
GPT-3.5 Turbo via prompting alongwith using the sequential nature of relevant
documents to frame a mathematical model which helps to detect relevant
documents corresponding to a query.

摘要：代碼混合，在單一句子中整合來自多種語言的詞彙和語法元素，是一種廣泛的語言現象，特別普遍存在於多語言社會中。在印度，社交媒體使用者經常使用羅馬字母進行代碼混合對話，尤其是在組成線上群組以分享相關當地資訊的移民社群中。本文重點探討從代碼混合對話中擷取相關資訊的挑戰，特別是在與英文混合的羅馬轉寫孟加拉文中。本研究提出了一種新穎的方法來解決這些挑戰，方法是開發一種機制來自動識別代碼混合對話中最相關的答案。我們已經針對包含來自 Facebook 的查詢和文件以及查詢相關性檔案 (QRels) 的資料集進行實驗，以協助這項任務。我們的結果證明了我們的方法在從複雜的代碼混合數位對話中擷取相關資訊的有效性，有助於多語言和非正式文字環境中的自然語言處理更廣泛的領域。我們透過提示使用 GPT-3.5 Turbo，並利用相關文件順序性質來建構一個數學模型，有助於偵測與查詢相應的相關文件。

##### **Equivariant Graph Attention Networks with Structural Motifs for Predicting Cell Line-Specific Synergistic Drug Combinations**
2411.04747v1 by Zachary Schwehr

Cancer is the second leading cause of death, with chemotherapy as one of the
primary forms of treatment. As a result, researchers are turning to drug
combination therapy to decrease drug resistance and increase efficacy. Current
methods of drug combination screening, such as in vivo and in vitro, are
inefficient due to stark time and monetary costs. In silico methods have become
increasingly important for screening drugs, but current methods are inaccurate
and generalize poorly to unseen anticancer drugs. In this paper, I employ a
geometric deep-learning model utilizing a graph attention network that is
equivariant to 3D rotations, translations, and reflections with structural
motifs. Additionally, the gene expression of cancer cell lines is utilized to
classify synergistic drug combinations specific to each cell line. I compared
the proposed geometric deep learning framework to current state-of-the-art
(SOTA) methods, and the proposed model architecture achieved greater
performance on all 12 benchmark tasks performed on the DrugComb dataset.
Specifically, the proposed framework outperformed other SOTA methods by an
accuracy difference greater than 28%. Based on these results, I believe that
the equivariant graph attention network's capability of learning geometric data
accounts for the large performance improvements. The model's ability to
generalize to foreign drugs is thought to be due to the structural motifs
providing a better representation of the molecule. Overall, I believe that the
proposed equivariant geometric deep learning framework serves as an effective
tool for virtually screening anticancer drug combinations for further
validation in a wet lab environment. The code for this work is made available
online at: https://github.com/WeToTheMoon/EGAT_DrugSynergy.

摘要：癌症是第二大死亡原因，化疗是主要的治疗方式之一。因此，研究人员转向药物联合疗法来降低药物抗性和提高疗效。当前的药物组合筛选方法，如体内和体外，由于时间和金钱成本高昂而效率低下。计算机模拟方法对于药物筛选变得越来越重要，但当前的方法不准确，并且对未见的抗癌药物的概括性较差。在本文中，我采用了一个几何深度学习模型，该模型利用了一个图注意力网络，该网络对 3D 旋转、平移和具有结构基序的反射是等变的。此外，利用癌细胞系的基因表达对特定于每个细胞系的协同药物组合进行分类。我将提出的几何深度学习框架与当前最先进 (SOTA) 方法进行了比较，并且提出的模型架构在 DrugComb 数据集上执行的所有 12 项基准任务上都取得了更好的性能。具体来说，提出的框架比其他 SOTA 方法的准确性差异超过 28%。基于这些结果，我相信等变图注意力网络学习几何数据的能力可以解释巨大的性能提升。该模型对外国药物进行概括的能力被认为是由于结构基序提供了分子的更好表示。总体而言，我相信提出的等变几何深度学习框架作为一种有效的工具，用于虚拟筛选抗癌药物组合，以便在湿实验室环境中进一步验证。这项工作的代码在线提供：https://github.com/WeToTheMoon/EGAT_DrugSynergy。

##### **BhasaAnuvaad: A Speech Translation Dataset for 14 Indian Languages**
2411.04699v1 by Sparsh Jain, Ashwin Sankar, Devilal Choudhary, Dhairya Suman, Nikhil Narasimhan, Mohammed Safi Ur Rahman Khan, Anoop Kunchukuttan, Mitesh M Khapra, Raj Dabre

Automatic Speech Translation (AST) datasets for Indian languages remain
critically scarce, with public resources covering fewer than 10 of the 22
official languages. This scarcity has resulted in AST systems for Indian
languages lagging far behind those available for high-resource languages like
English. In this paper, we first evaluate the performance of widely-used AST
systems on Indian languages, identifying notable performance gaps and
challenges. Our findings show that while these systems perform adequately on
read speech, they struggle significantly with spontaneous speech, including
disfluencies like pauses and hesitations. Additionally, there is a striking
absence of systems capable of accurately translating colloquial and informal
language, a key aspect of everyday communication. To this end, we introduce
BhasaAnuvaad, the largest publicly available dataset for AST involving 14
scheduled Indian languages spanning over 44,400 hours and 17M text segments.
BhasaAnuvaad contains data for English speech to Indic text, as well as Indic
speech to English text. This dataset comprises three key categories: (1)
Curated datasets from existing resources, (2) Large-scale web mining, and (3)
Synthetic data generation. By offering this diverse and expansive dataset, we
aim to bridge the resource gap and promote advancements in AST for low-resource
Indian languages, especially in handling spontaneous and informal speech
patterns.

摘要：印度語言的自動語音翻譯 (AST) 資料集仍然嚴重稀缺，公開資源涵蓋的 22 種官方語言不到 10 種。這種稀缺性導致印度語言的 AST 系統遠遠落後於英語等高資源語言的系統。在本文中，我們首先評估廣泛使用的 AST 系統在印度語言上的效能，找出顯著的效能差距和挑戰。我們的研究結果顯示，雖然這些系統在朗讀語音上表現得很好，但它們在自發語音方面卻有很大的困難，包括停頓和猶豫等不流暢的現象。此外，顯著缺乏能夠準確翻譯口語和非正式語言的系統，而這是日常溝通的一個關鍵方面。為此，我們推出了 BhasaAnuvaad，這是最大的公開 AST 資料集，涉及 14 種印度排程語言，跨越 44,400 小時和 1700 萬個文字區塊。BhasaAnuvaad 包含英語語音轉換為印度文字，以及印度語音轉換為英語文字的資料。此資料集包含三個主要類別：(1) 來自現有資源的策展資料集，(2) 大規模網路挖掘，以及 (3) 合成資料產生。透過提供這個多元且廣泛的資料集，我們旨在彌補資源差距，並促進低資源印度語言 AST 的進步，特別是在處理自發和非正式的語音模式方面。

##### **The Multiple Dimensions of Spuriousness in Machine Learning**
2411.04696v1 by Samuel J. Bell, Skyler Wang

Learning correlations from data forms the foundation of today's machine
learning (ML) and artificial intelligence (AI) research. While such an approach
enables the automatic discovery of patterned relationships within big data
corpora, it is susceptible to failure modes when unintended correlations are
captured. This vulnerability has expanded interest in interrogating
spuriousness, often critiqued as an impediment to model performance, fairness,
and robustness. In this article, we trace deviations from the conventional
definition of statistical spuriousness-which denotes a non-causal observation
arising from either coincidence or confounding variables-to articulate how ML
researchers make sense of spuriousness in practice. Drawing on a broad survey
of ML literature, we conceptualize the "multiple dimensions of spuriousness,"
encompassing: relevance ("Models should only use correlations that are relevant
to the task."), generalizability ("Models should only use correlations that
generalize to unseen data"), human-likeness ("Models should only use
correlations that a human would use to perform the same task"), and harmfulness
("Models should only use correlations that are not harmful"). These dimensions
demonstrate that ML spuriousness goes beyond the causal/non-causal dichotomy
and that the disparate interpretative paths researchers choose could
meaningfully influence the trajectory of ML development. By underscoring how a
fundamental problem in ML is contingently negotiated in research contexts, we
contribute to ongoing debates about responsible practices in AI development.

摘要：從資料中學習關聯性，是當今機器學習 (ML) 和人工智慧 (AI) 研究的基礎。雖然這種方法能自動發現大數據語料庫中模式化的關係，但當擷取到非預期的關聯性時，它容易發生故障模式。這種脆弱性擴大了對審查虛假性的興趣，虛假性通常被批評為模型效能、公平性和穩健性的障礙。在本文中，我們追溯統計虛假性的傳統定義的偏差，該定義表示非因果觀察源自巧合或混淆變數，以闡明 ML 研究人員如何實際理解虛假性。根據 ML 文獻的廣泛調查，我們概念化了「虛假性的多重面向」，包括：相關性（「模型應僅使用與任務相關的關聯性。」）、可概化性（「模型應僅使用可概化到未見數據的關聯性。」）、類人化（「模型應僅使用人類會用來執行相同任務的關聯性。」）和有害性（「模型應僅使用無害的關聯性。」）。這些面向證明了 ML 虛假性超越了因果/非因果二分法，而且研究人員選擇的不同詮釋路徑可能會顯著影響 ML 發展的軌跡。透過強調 ML 中的基本問題如何在研究背景中被偶然協商，我們為 AI 開發中關於負責任實務的持續辯論做出貢獻。

##### **Reciprocal Point Learning Network with Large Electromagnetic Kernel for SAR Open-Set Recognition**
2411.04693v1 by Xiayang Xiao, Zhuoxuan Li, Ruyi Zhang, Jiacheng Chen, Haipeng Wang

The limitations of existing Synthetic Aperture Radar (SAR) Automatic Target
Recognition (ATR) methods lie in their confinement by the closed-environment
assumption, hindering their effective and robust handling of unknown target
categories in open environments. Open Set Recognition (OSR), a pivotal facet
for algorithmic practicality, intends to categorize known classes while
denoting unknown ones as "unknown." The chief challenge in OSR involves
concurrently mitigating risks associated with generalizing features from a
restricted set of known classes to numerous unknown samples and the open space
exposure to potential unknown data. To enhance open-set SAR classification, a
method called scattering kernel with reciprocal learning network is proposed.
Initially, a feature learning framework is constructed based on reciprocal
point learning (RPL), establishing a bounded space for potential unknown
classes. This approach indirectly introduces unknown information into a learner
confined to known classes, thereby acquiring more concise and discriminative
representations. Subsequently, considering the variability in the imaging of
targets at different angles and the discreteness of components in SAR images, a
proposal is made to design convolutional kernels based on large-sized attribute
scattering center models. This enhances the ability to extract intrinsic
non-linear features and specific scattering characteristics in SAR images,
thereby improving the discriminative features of the model and mitigating the
impact of imaging variations on classification performance. Experiments on the
MSTAR datasets substantiate the superior performance of the proposed approach
called ASC-RPL over mainstream methods.

摘要：現有合成孔徑雷達 (SAR) 自動目標識別 (ATR) 方法的限制在於它們受限於封閉環境假設，阻礙它們在開放環境中有效且穩健地處理未知目標類別。開放集識別 (OSR) 是演算法實用性的關鍵面向，旨在對已知類別進行分類，同時將未知類別標示為「未知」。OSR 的主要挑戰涉及同時降低與將特徵從已知類別的受限集合概括到大量未知樣本相關的風險，以及開放空間曝露於潛在未知資料。為了增強開放集 SAR 分類，提出了一種稱為散射核與互惠學習網路的方法。最初，基於互惠點學習 (RPL) 建構特徵學習架構，為潛在未知類別建立有界空間。此方法間接將未知資訊引入受限於已知類別的學習器，從而獲得更簡潔且具區辨力的表示。隨後，考慮目標在不同角度成像的可變性以及 SAR 影像中元件的離散性，提出基於大型屬性散射中心模型設計卷積核。這增強了從 SAR 影像中提取內在非線性特徵和特定散射特徵的能力，從而改善模型的區辨特徵並減輕成像變化對分類效能的影響。MSTAR 資料集上的實驗證實了所提出的 ASC-RPL 方法優於主流方法的卓越效能。

##### **Personalized Federated Learning for Cross-view Geo-localization**
2411.04692v1 by Christos Anagnostopoulos, Alexandros Gkillas, Nikos Piperigkos, Aris S. Lalos

In this paper we propose a methodology combining Federated Learning (FL) with
Cross-view Image Geo-localization (CVGL) techniques. We address the challenges
of data privacy and heterogeneity in autonomous vehicle environments by
proposing a personalized Federated Learning scenario that allows selective
sharing of model parameters. Our method implements a coarse-to-fine approach,
where clients share only the coarse feature extractors while keeping
fine-grained features specific to local environments. We evaluate our approach
against traditional centralized and single-client training schemes using the
KITTI dataset combined with satellite imagery. Results demonstrate that our
federated CVGL method achieves performance close to centralized training while
maintaining data privacy. The proposed partial model sharing strategy shows
comparable or slightly better performance than classical FL, offering
significant reduced communication overhead without sacrificing accuracy. Our
work contributes to more robust and privacy-preserving localization systems for
autonomous vehicles operating in diverse environments

摘要：在本文中，我們提出了一種結合聯邦學習 (FL) 與跨視圖影像地理定位 (CVGL) 技術的方法。我們透過提出允許選擇性分享模型參數的個人化聯邦學習場景，來解決自駕車環境中的資料隱私和異質性挑戰。我們的模型實作一種由粗到細的方法，客戶端僅分享粗略的特徵萃取器，同時保留特定於當地環境的細粒度特徵。我們使用結合了衛星影像的 KITTI 資料集，針對傳統的集中式和單一客戶端訓練架構評估我們的模型。結果證明，我們的聯邦 CVGL 方法達到了接近集中式訓練的效能，同時維護資料隱私。所提出的部分模型分享策略展現出與傳統 FL 相當或略佳的效能，在不犧牲準確度的條件下，大幅減少通訊開銷。我們的研究有助於建立在各種環境中運作的自駕車的更強大且注重隱私的定位系統

##### **AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**
2411.04691v1 by Tianyi Zhang, Miu Kojima, Simon D'Alfonso

Smartphones, equipped with an array of sensors, have become valuable tools
for personal sensing. Particularly in digital health, smartphones facilitate
the tracking of health-related behaviors and contexts, contributing
significantly to digital phenotyping, a process where data from digital
interactions is analyzed to infer behaviors and assess mental health.
Traditional methods process raw sensor data into information features for
statistical and machine learning analyses. In this paper, we introduce a novel
approach that systematically converts smartphone-collected data into
structured, chronological narratives. The AWARE Narrator translates
quantitative smartphone sensing data into English language descriptions,
forming comprehensive narratives of an individual's activities. We apply the
framework to the data collected from university students over a week,
demonstrating the potential of utilizing the narratives to summarize individual
behavior, and analyzing psychological states by leveraging large language
models.

摘要：智慧型手機配備了各式感測器，已成為個人感測的寶貴工具。特別是在數位健康領域，智慧型手機促進了健康相關行為和情境的追蹤，對數位表型分析做出了重大貢獻，數位表型分析是一種從數位互動中分析資料以推論行為和評估心理健康的程序。傳統方法將原始感測器資料處理成資訊特徵，以進行統計和機器學習分析。在本文中，我們介紹一種新穎的方法，該方法系統性地將智慧型手機收集的資料轉換成結構化的時間順序敘事。AWARE Narrator 將定量的智慧型手機感測資料轉換成英文語言描述，形成個人活動的綜合敘事。我們將此架構套用在大學生一週內收集的資料上，證明了利用敘事總結個人行為的潛力，並透過運用大型語言模型來分析心理狀態。

##### **Solving Generalized Grouping Problems in Cellular Manufacturing Systems Using a Network Flow Model**
2411.04685v1 by Md. Kutub Uddin, Md. Saiful Islam, Md Abrar Jahin, Md. Saiful Islam Seam, M. F. Mridha

This paper focuses on the generalized grouping problem in the context of
cellular manufacturing systems (CMS), where parts may have more than one
process route. A process route lists the machines corresponding to each part of
the operation. Inspired by the extensive and widespread use of network flow
algorithms, this research formulates the process route family formation for
generalized grouping as a unit capacity minimum cost network flow model. The
objective is to minimize dissimilarity (based on the machines required) among
the process routes within a family. The proposed model optimally solves the
process route family formation problem without pre-specifying the number of
part families to be formed. The process route of family formation is the first
stage in a hierarchical procedure. For the second stage (machine cell
formation), two procedures, a quadratic assignment programming (QAP)
formulation and a heuristic procedure, are proposed. The QAP simultaneously
assigns process route families and machines to a pre-specified number of cells
in such a way that total machine utilization is maximized. The heuristic
procedure for machine cell formation is hierarchical in nature. Computational
results for some test problems show that the QAP and the heuristic procedure
yield the same results.

摘要：本文重點探討具有多個製程路徑的蜂巢式製造系統 (CMS) 中的廣義群組問題。製程路徑列出對應於作業各部分的機器。受到網路流演算法廣泛使用的啟發，本研究將廣義群組的製程路徑族形成制定為單位容量最小成本網路流模型。目標是將一個族內製程路徑之間的差異性（依據所需的機器）降到最低。所提出的模型可以最佳化解決製程路徑族形成問題，而無須預先指定要形成的零件族數量。製程路徑族形成是階層式程序的第一階段。對於第二階段（機器單元形成），本文提出兩種程序：二次指派規劃 (QAP) 公式和啟發式程序。QAP 同時將製程路徑族和機器指派到預先指定數量的單元中，以使總機器使用率最大化。機器單元形成的啟發式程序本質上是階層式的。一些測試問題的計算結果顯示，QAP 和啟發式程序會產生相同的結果。

##### **CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation**
2411.04679v1 by Jie Liu, Pan Zhou, Yingjun Du, Ah-Hwee Tan, Cees G. M. Snoek, Jan-Jakob Sonke, Efstratios Gavves

In this work, we address the cooperation problem among large language model
(LLM) based embodied agents, where agents must cooperate to achieve a common
goal. Previous methods often execute actions extemporaneously and incoherently,
without long-term strategic and cooperative planning, leading to redundant
steps, failures, and even serious repercussions in complex tasks like
search-and-rescue missions where discussion and cooperative plan are crucial.
To solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance
the cooperation efficiency of LLM-based embodied agents. Inspired by human
cooperation schemes, CaPo improves cooperation efficiency with two phases: 1)
meta-plan generation, and 2) progress-adaptive meta-plan and execution. In the
first phase, all agents analyze the task, discuss, and cooperatively create a
meta-plan that decomposes the task into subtasks with detailed steps, ensuring
a long-term strategic and coherent plan for efficient coordination. In the
second phase, agents execute tasks according to the meta-plan and dynamically
adjust it based on their latest progress (e.g., discovering a target object)
through multi-turn discussions. This progress-based adaptation eliminates
redundant actions, improving the overall cooperation efficiency of agents.
Experimental results on the ThreeDworld Multi-Agent Transport and Communicative
Watch-And-Help tasks demonstrate that CaPo achieves much higher task completion
rate and efficiency compared with state-of-the-arts.

摘要：在這項工作中，我們探討大型語言模型 (LLM) 所依據的具身代理之間的合作問題，其中代理必須合作才能達成共同目標。先前的做法通常臨時且不連貫地執行動作，缺乏長期策略和合作規劃，導致在搜尋和救援任務等複雜任務中出現重複步驟、失敗，甚至嚴重的後果，而討論和合作計畫在這些任務中至關重要。為了解決這個問題，我們提出合作計畫最佳化 (CaPo) 來提升 LLM 所依據的具身代理的合作效率。CaPo 受到人類合作計畫的啟發，透過兩個階段來改善合作效率：1) 元計畫產生，以及 2) 進度適應元計畫和執行。在第一階段，所有代理都會分析任務、討論，並合作建立一個元計畫，將任務分解成具有詳細步驟的子任務，確保長期策略和連貫計畫，以進行有效率的協調。在第二階段，代理會根據元計畫執行任務，並透過多輪討論根據他們的最新進度（例如，發現目標物體）動態調整元計畫。這種基於進度的調整消除了重複的動作，改善了代理的整體合作效率。在 ThreeDworld 多代理運輸和溝通觀察與協助任務上的實驗結果顯示，與現有技術相比，CaPo 達到了更高的任務完成率和效率。

##### **CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational Agents in XR**
2411.04671v1 by Kadir Burak Buldu, Süleyman Özdel, Ka Hei Carrie Lau, Mengdi Wang, Daniel Saad, Sofie Schönborn, Auxane Boch, Enkelejda Kasneci, Efe Bozkir

Recent developments in computer graphics, machine learning, and sensor
technologies enable numerous opportunities for extended reality (XR) setups for
everyday life, from skills training to entertainment. With large corporations
offering consumer-grade head-mounted displays (HMDs) in an affordable way, it
is likely that XR will become pervasive, and HMDs will develop as personal
devices like smartphones and tablets. However, having intelligent spaces and
naturalistic interactions in XR is as important as technological advances so
that users grow their engagement in virtual and augmented spaces. To this end,
large language model (LLM)--powered non-player characters (NPCs) with
speech-to-text (STT) and text-to-speech (TTS) models bring significant
advantages over conventional or pre-scripted NPCs for facilitating more natural
conversational user interfaces (CUIs) in XR. In this paper, we provide the
community with an open-source, customizable, extensible, and privacy-aware
Unity package, CUIfy, that facilitates speech-based NPC-user interaction with
various LLMs, STT, and TTS models. Our package also supports multiple
LLM-powered NPCs per environment and minimizes the latency between different
computational models through streaming to achieve usable interactions between
users and NPCs. We publish our source code in the following repository:
https://gitlab.lrz.de/hctl/cuify

摘要：<paragraph>電腦圖學、機器學習和感測技術的最新發展，為日常生活的擴增實境 (XR) 設定提供了許多機會，從技能訓練到娛樂。隨著大型企業以實惠的方式提供消費者級頭戴式顯示器 (HMD)，XR 很可能會變得普遍，而 HMD 將像智慧型手機和平板電腦一樣發展為個人裝置。然而，在 XR 中擁有智慧空間和自然互動與技術進步一樣重要，以便使用者在虛擬和擴增空間中增加參與度。為此，由大型語言模型 (LLM) 驅動的非玩家角色 (NPC) 具備語音轉文字 (STT) 和文字轉語音 (TTS) 模型，與傳統或預先編寫的 NPC 相比，在促進 XR 中更自然的對話式使用者介面 (CUI) 方面具有顯著優勢。在本文中，我們為社群提供一個開源、可自訂、可擴充和注重隱私的 Unity 套件 CUIfy，它促進了基於語音的 NPC 使用者互動，並支援各種 LLM、STT 和 TTS 模型。我們的套件還支援每個環境中有多個由 LLM 驅動的 NPC，並透過串流將不同運算模型之間的延遲降至最低，以實現使用者和 NPC 之間可用的互動。我們在以下存放庫中發布我們的原始程式碼：
https://gitlab.lrz.de/hctl/cuify</paragraph>

##### **EffiCANet: Efficient Time Series Forecasting with Convolutional Attention**
2411.04669v1 by Xinxing Zhou, Jiaqi Ye, Shubao Zhao, Ming Jin, Chengyi Yang, Yanlong Wen, Xiaojie Yuan

The exponential growth of multivariate time series data from sensor networks
in domains like industrial monitoring and smart cities requires efficient and
accurate forecasting models. Current deep learning methods often fail to
adequately capture long-range dependencies and complex inter-variable
relationships, especially under real-time processing constraints. These
limitations arise as many models are optimized for either short-term
forecasting with limited receptive fields or long-term accuracy at the cost of
efficiency. Additionally, dynamic and intricate interactions between variables
in real-world data further complicate modeling efforts. To address these
limitations, we propose EffiCANet, an Efficient Convolutional Attention Network
designed to enhance forecasting accuracy while maintaining computational
efficiency. EffiCANet integrates three key components: (1) a Temporal
Large-kernel Decomposed Convolution (TLDC) module that captures long-term
temporal dependencies while reducing computational overhead; (2) an
Inter-Variable Group Convolution (IVGC) module that captures complex and
evolving relationships among variables; and (3) a Global Temporal-Variable
Attention (GTVA) mechanism that prioritizes critical temporal and
inter-variable features. Extensive evaluations across nine benchmark datasets
show that EffiCANet achieves the maximum reduction of 10.02% in MAE over
state-of-the-art models, while cutting computational costs by 26.2% relative to
conventional large-kernel convolution methods, thanks to its efficient
decomposition strategy.

摘要：感測器網路中多變量時間序列資料的指數成長，在工業監控和智慧城市等領域，需要有效率且準確的預測模型。現有的深度學習方法通常無法充分捕捉長程依賴關係和複雜的變數間關係，特別是在即時處理的限制下。這些限制會出現，因為許多模型是針對短期預測進行最佳化，具有受限的感受野，或以效率為代價換取長期準確度。此外，現實世界資料中變數之間的動態和複雜互動，進一步使建模工作複雜化。為了解決這些限制，我們提出 EffiCANet，一種高效的卷積注意力網路，旨在提高預測準確度，同時維持運算效率。EffiCANet 整合了三個關鍵元件：(1) 時間大核分解卷積 (TLDC) 模組，可捕捉長期時間依賴關係，同時降低運算負擔；(2) 變數間群組卷積 (IVGC) 模組，可捕捉變數之間複雜且不斷變化的關係；(3) 全域時間變數注意力 (GTVA) 機制，可優先處理關鍵時間和變數間特徵。在九個基準資料集的廣泛評估顯示，EffiCANet 在 MAE 上達到了 10.02% 的最大減少，相較於現有最先進的模型，同時將運算成本降低了 26.2%，這要歸功於其有效率的分解策略。

##### **DISCO: DISCovering Overfittings as Causal Rules for Text Classification Models**
2411.04649v1 by Zijian Zhang, Vinay Setty, Yumeng Wang, Avishek Anand

With the rapid advancement of neural language models, the deployment of
over-parameterized models has surged, increasing the need for interpretable
explanations comprehensible to human inspectors. Existing post-hoc
interpretability methods, which often focus on unigram features of single input
textual instances, fail to capture the models' decision-making process fully.
Additionally, many methods do not differentiate between decisions based on
spurious correlations and those based on a holistic understanding of the input.
Our paper introduces DISCO, a novel method for discovering global, rule-based
explanations by identifying causal n-gram associations with model predictions.
This method employs a scalable sequence mining technique to extract relevant
text spans from training data, associate them with model predictions, and
conduct causality checks to distill robust rules that elucidate model behavior.
These rules expose potential overfitting and provide insights into misleading
feature combinations. We validate DISCO through extensive testing,
demonstrating its superiority over existing methods in offering comprehensive
insights into complex model behaviors. Our approach successfully identifies all
shortcuts manually introduced into the training data (100% detection rate on
the MultiRC dataset), resulting in an 18.8% regression in model performance --
a capability unmatched by any other method. Furthermore, DISCO supports
interactive explanations, enabling human inspectors to distinguish spurious
causes in the rule-based output. This alleviates the burden of abundant
instance-wise explanations and helps assess the model's risk when encountering
out-of-distribution (OOD) data.

摘要：<paragraph>隨著神經語言模型的快速進展，過度參數化模型的部署激增，增加了對人類檢查員可以理解的可解釋解釋的需求。現有的事後可解釋性方法通常關注單個輸入文本實例的單字元特徵，無法完全捕捉模型的決策過程。此外，許多方法無法區分基於虛假相關性的決策和基於對輸入整體理解的決策。我們的論文介紹了 DISCO，這是一種發現全局基於規則的解釋的新方法，通過識別與模型預測相關的因果 n-gram 關聯來實現。此方法採用可擴充的序列挖掘技術從訓練數據中提取相關的文字跨度，將它們與模型預測關聯起來，並進行因果關係檢查以提煉闡明模型行為的強健規則。這些規則揭示了潛在的過擬合，並提供了對誤導性特徵組合的見解。我們通過廣泛的測試驗證了 DISCO，證明了它在提供對複雜模型行為的全面見解方面優於現有方法。我們的做法成功識別了手動引入訓練數據中的所有捷徑（在 MultiRC 數據集上檢測率為 100%），導致模型性能下降 18.8%——這是任何其他方法都無法比擬的能力。此外，DISCO 支持互動式解釋，使人類檢查員能夠區分基於規則的輸出中的虛假原因。這減輕了大量基於實例的解釋的負擔，並有助於評估模型在遇到分布外 (OOD) 數據時的風險。</paragraph>

##### **wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification from Physiological Signals**
2411.04644v1 by Jonathan F. Carter, Lionel Tarassenko

Accurate classification of sleep stages from less obtrusive sensor
measurements such as the electrocardiogram (ECG) or photoplethysmogram (PPG)
could enable important applications in sleep medicine. Existing approaches to
this problem have typically used deep learning models designed and trained to
operate on one or more specific input signals. However, the datasets used to
develop these models often do not contain the same sets of input signals. Some
signals, particularly PPG, are much less prevalent than others, and this has
previously been addressed with techniques such as transfer learning.
Additionally, only training on one or more fixed modalities precludes
cross-modal information transfer from other sources, which has proved valuable
in other problem domains. To address this, we introduce wav2sleep, a unified
model designed to operate on variable sets of input signals during training and
inference. After jointly training on over 10,000 overnight recordings from six
publicly available polysomnography datasets, including SHHS and MESA, wav2sleep
outperforms existing sleep stage classification models across test-time input
combinations including ECG, PPG, and respiratory signals.

摘要：透過較不具侵入性的感測器量測，例如心電圖 (ECG) 或光電容積描記儀 (PPG)，準確分類睡眠階段，能應用於睡眠醫學中。現有的方法通常使用深度學習模型，設計和訓練這些模型以處理一個或多個特定輸入訊號。然而，用於開發這些模型的資料集通常不包含相同的輸入訊號組。有些訊號，特別是 PPG，遠比其他訊號不普遍，而這先前已透過轉移學習等技術來解決。此外，僅訓練一種或多種固定模式會排除來自其他來源的跨模式資訊傳輸，這已證明在其他問題領域中很有價值。為了解決這個問題，我們引入了 wav2sleep，這是一個統一的模型，設計用於在訓練和推論期間處理變數組的輸入訊號。在對來自六個公開可用的多重睡眠生理檢查資料集（包括 SHHS 和 MESA）的 10,000 多個過夜記錄進行聯合訓練後，wav2sleep 在測試時間輸入組合（包括 ECG、PPG 和呼吸訊號）中優於現有的睡眠階段分類模型。

##### **TAP-VL: Text Layout-Aware Pre-training for Enriched Vision-Language Models**
2411.04642v1 by Jonathan Fhima, Elad Ben Avraham, Oren Nuriel, Yair Kittenplon, Roy Ganz, Aviad Aberdam, Ron Litman

Vision-Language (VL) models have garnered considerable research interest;
however, they still face challenges in effectively handling text within images.
To address this limitation, researchers have developed two approaches. The
first method involves utilizing external Optical Character Recognition (OCR)
tools to extract textual information from images, which is then prepended to
other textual inputs. The second strategy focuses on employing extremely
high-resolution images to improve text recognition capabilities. In this paper,
we focus on enhancing the first strategy by introducing a novel method, named
TAP-VL, which treats OCR information as a distinct modality and seamlessly
integrates it into any VL model. TAP-VL employs a lightweight transformer-based
OCR module to receive OCR with layout information, compressing it into a short
fixed-length sequence for input into the LLM. Initially, we conduct
model-agnostic pretraining of the OCR module on unlabeled documents, followed
by its integration into any VL architecture through brief fine-tuning.
Extensive experiments demonstrate consistent performance improvements when
applying TAP-VL to top-performing VL models, across scene-text and
document-based VL benchmarks.

摘要：視覺語言 (VL) 模型引起了相當大的研究興趣；
然而，它們在有效處理影像中的文字時仍面臨挑戰。
為了解決這個限制，研究人員開發了兩種方法。第一種方法涉及利用外部光學字元辨識 (OCR)
工具從影像中擷取文字資訊，然後將其預先加到
其他文字輸入。第二種策略專注於採用極高解析度的影像來改善文字辨識能力。在本文中，
我們專注於透過引入一種名為 TAP-VL 的新方法來增強第一種策略，它將 OCR 資訊視為一種不同的方式，並將其無縫整合到任何 VL 模型中。TAP-VL 採用輕量級的基於轉換器的
OCR 模組來接收具有版面資訊的 OCR，將其壓縮成一個短的固定長度序列，作為輸入到 LLM。最初，我們對 OCR 模組進行與模型無關的預訓練，使用未標記的文檔，然後
透過簡短的微調將其整合到任何 VL 架構中。
廣泛的實驗表明，將 TAP-VL 應用於效能最佳的 VL 模型時，在場景文字和
基於文件的 VL 基準測試中，都能持續改善效能。

##### **Hands-On Tutorial: Labeling with LLM and Human-in-the-Loop**
2411.04637v1 by Ekaterina Artemova, Akim Tsvigun, Dominik Schlechtweg, Natalia Fedorova, Sergei Tilga, Boris Obmoroshev

Training and deploying machine learning models relies on a large amount of
human-annotated data. As human labeling becomes increasingly expensive and
time-consuming, recent research has developed multiple strategies to speed up
annotation and reduce costs and human workload: generating synthetic training
data, active learning, and hybrid labeling. This tutorial is oriented toward
practical applications: we will present the basics of each strategy, highlight
their benefits and limitations, and discuss in detail real-life case studies.
Additionally, we will walk through best practices for managing human annotators
and controlling the quality of the final dataset. The tutorial includes a
hands-on workshop, where attendees will be guided in implementing a hybrid
annotation setup. This tutorial is designed for NLP practitioners from both
research and industry backgrounds who are involved in or interested in
optimizing data labeling projects.

摘要：訓練和部署機器學習模型仰賴大量的
人工標記資料。由於人工標記的成本越來越高昂且耗時，最近的研究已開發出多種策略來加速
標記並降低成本和人力負擔：產生合成訓練
資料、主動學習和混合標記。本教學課程以
實際應用為導向：我們將介紹每種策略的基本原理，強調
它們的優點和限制，並詳細討論實際案例研究。
此外，我們將逐步介紹管理人工標記員和控制最終
資料集品質的最佳實務。本教學課程包括實作工作坊，參與者將在其中接受指導，實作混合
標記設定。本教學課程專為來自
研究和產業背景，且參與或有興趣
最佳化資料標記專案的 NLP 實務人員所設計。

##### **FASSILA: A Corpus for Algerian Dialect Fake News Detection and Sentiment Analysis**
2411.04604v1 by Amin Abdedaiem, Abdelhalim Hafedh Dahou, Mohamed Amine Cheragui, Brigitte Mathiak

In the context of low-resource languages, the Algerian dialect (AD) faces
challenges due to the absence of annotated corpora, hindering its effective
processing, notably in Machine Learning (ML) applications reliant on corpora
for training and assessment. This study outlines the development process of a
specialized corpus for Fake News (FN) detection and sentiment analysis (SA) in
AD called FASSILA. This corpus comprises 10,087 sentences, encompassing over
19,497 unique words in AD, and addresses the significant lack of linguistic
resources in the language and covers seven distinct domains. We propose an
annotation scheme for FN detection and SA, detailing the data collection,
cleaning, and labelling process. Remarkable Inter-Annotator Agreement indicates
that the annotation scheme produces consistent annotations of high quality.
Subsequent classification experiments using BERT-based models and ML models are
presented, demonstrate promising results and highlight avenues for further
research. The dataset is made freely available on GitHub
(https://github.com/amincoding/FASSILA) to facilitate future advancements in
the field.

摘要：在低資源語言的背景下，阿爾及利亞方言 (AD) 因缺乏註解語料庫而面臨挑戰，阻礙了其有效處理，特別是在依賴語料庫進行訓練和評估的機器學習 (ML) 應用中。本研究概述了針對 AD 中的假新聞 (FN) 檢測和情緒分析 (SA) 而開發的專門語料庫 FASSILA 的開發過程。此語料庫包含 10,087 個句子，涵蓋 AD 中超過 19,497 個單詞，並解決了該語言中語言資源的嚴重缺乏，且涵蓋七個不同的領域。我們提出了 FN 檢測和 SA 的註解方案，詳細說明了數據收集、清理和標記過程。顯著的標記間一致性表明註解方案產生了一致且高品質的註解。隨後使用基於 BERT 的模型和 ML 模型進行的後續分類實驗，展示了有希望的結果，並重點介紹了進一步研究的途徑。該數據集已在 GitHub (https://github.com/amincoding/FASSILA) 上免費提供，以促進該領域的未來進展。

##### **Self-Calibrated Listwise Reranking with Large Language Models**
2411.04602v1 by Ruiyang Ren, Yuhao Wang, Kun Zhou, Wayne Xin Zhao, Wenjie Wang, Jing Liu, Ji-Rong Wen, Tat-Seng Chua

Large language models (LLMs), with advanced linguistic capabilities, have
been employed in reranking tasks through a sequence-to-sequence approach. In
this paradigm, multiple passages are reranked in a listwise manner and a
textual reranked permutation is generated. However, due to the limited context
window of LLMs, this reranking paradigm requires a sliding window strategy to
iteratively handle larger candidate sets. This not only increases computational
costs but also restricts the LLM from fully capturing all the comparison
information for all candidates. To address these challenges, we propose a novel
self-calibrated listwise reranking method, which aims to leverage LLMs to
produce global relevance scores for ranking. To achieve it, we first propose
the relevance-aware listwise reranking framework, which incorporates explicit
list-view relevance scores to improve reranking efficiency and enable global
comparison across the entire candidate set. Second, to ensure the comparability
of the computed scores, we propose self-calibrated training that uses
point-view relevance assessments generated internally by the LLM itself to
calibrate the list-view relevance assessments. Extensive experiments and
comprehensive analysis on the BEIR benchmark and TREC Deep Learning Tracks
demonstrate the effectiveness and efficiency of our proposed method.

摘要：大型語言模型（LLM）具有先進的語言能力，已透過序列對序列方法用於重新排序任務。在此範例中，多個段落會以列表方式重新排序，並產生文字重新排序排列。但是，由於 LLM 的內容視窗有限，此重新排序範例需要滑動視窗策略來反覆處理較大的候選集。這不僅會增加運算成本，還會限制 LLM 完整擷取所有候選集的所有比較資訊。為了應對這些挑戰，我們提出了一種新穎的自校準列表重新排序方法，旨在利用 LLM 產生用於排名的整體相關性分數。為達成此目標，我們首先提出與相關性相關的列表重新排序架構，其中包含明確的列表檢視相關性分數，以提高重新排序效率並針對整個候選集啟用整體比較。其次，為了確保計算分數的可比較性，我們提出使用 LLM 本身內部產生的觀點相關性評估的自校準訓練，以校準列表檢視相關性評估。在 BEIR 基準和 TREC 深度學習軌道上的廣泛實驗和全面分析證明了我們提出的方法的有效性和效率。

##### **Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction**
2411.04588v1 by Ahlam Alrehili, Areej Alhothali

Natural language processing (NLP) utilizes text data augmentation to overcome
sample size constraints. Increasing the sample size is a natural and widely
used strategy for alleviating these challenges. In this study, we chose Arabic
to increase the sample size and correct grammatical errors. Arabic is
considered one of the languages with limited resources for grammatical error
correction (GEC). Furthermore, QALB-14 and QALB-15 are the only datasets used
in most Arabic grammatical error correction research, with approximately 20,500
parallel examples, which is considered low compared with other languages.
Therefore, this study aims to develop an Arabic corpus called "Tibyan" for
grammatical error correction using ChatGPT. ChatGPT is used as a data augmenter
tool based on a pair of Arabic sentences containing grammatical errors matched
with a sentence free of errors extracted from Arabic books, called guide
sentences. Multiple steps were involved in establishing our corpus, including
the collection and pre-processing of a pair of Arabic texts from various
sources, such as books and open-access corpora. We then used ChatGPT to
generate a parallel corpus based on the text collected previously, as a guide
for generating sentences with multiple types of errors. By engaging linguistic
experts to review and validate the automatically generated sentences, we
ensured that they were correct and error-free. The corpus was validated and
refined iteratively based on feedback provided by linguistic experts to improve
its accuracy. Finally, we used the Arabic Error Type Annotation tool (ARETA) to
analyze the types of errors in the Tibyan corpus. Our corpus contained 49 of
errors, including seven types: orthography, morphology, syntax, semantics,
punctuation, merge, and split. The Tibyan corpus contains approximately 600 K
tokens.

摘要：自然語言處理 (NLP) 利用文字資料擴充來克服樣本量限制。增加樣本量是緩解這些挑戰的自然且廣泛使用的策略。在本研究中，我們選擇阿拉伯語來增加樣本量並更正語法錯誤。阿拉伯語被認為是語法錯誤更正 (GEC) 資源有限的語言之一。此外，QALB-14 和 QALB-15 是大多數阿拉伯語語法錯誤更正研究中唯一使用的資料集，大約有 20,500 個平行範例，與其他語言相比，這被認為是較少的。因此，本研究旨在開發一個名為「Tibyan」的阿拉伯語語料庫，用於使用 ChatGPT 進行語法錯誤更正。ChatGPT 被用作資料擴充工具，基於一對包含語法錯誤的阿拉伯語句子，並與從阿拉伯語書籍中提取的沒有錯誤的句子（稱為引導句子）相匹配。建立我們的語料庫涉及多個步驟，包括從各種來源（例如書籍和開放獲取語料庫）收集和預處理一對阿拉伯語文本。然後，我們使用 ChatGPT 根據先前收集的文本生成一個平行語料庫，作為生成具有多種類型錯誤的句子的指南。通過聘請語言專家來審查和驗證自動生成的句子，我們確保它們正確無誤。語料庫根據語言專家提供的回饋進行驗證和反覆修改，以提高其準確性。最後，我們使用阿拉伯語錯誤類型註解工具 (ARETA) 來分析 Tibyan 語料庫中的錯誤類型。我們的語料庫包含 49 個錯誤，包括七種類型：正字法、形態、句法、語義、標點符號、合併和拆分。Tibyan 語料庫包含約 600 K 個詞元。

##### **On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data**
2411.04586v1 by Aitor Martinez-Seras, Javier Del Ser, Alain Andres, Pablo Garcia-Bringas

Robustness is a fundamental aspect for developing safe and trustworthy
models, particularly when they are deployed in the open world. In this work we
analyze the inherent capability of one-stage object detectors to robustly
operate in the presence of out-of-distribution (OoD) data. Specifically, we
propose a novel detection algorithm for detecting unknown objects in image
data, which leverages the features extracted by the model from each sample.
Differently from other recent approaches in the literature, our proposal does
not require retraining the object detector, thereby allowing for the use of
pretrained models. Our proposed OoD detector exploits the application of
supervised dimensionality reduction techniques to mitigate the effects of the
curse of dimensionality on the features extracted by the model. Furthermore, it
utilizes high-resolution feature maps to identify potential unknown objects in
an unsupervised fashion. Our experiments analyze the Pareto trade-off between
the performance detecting known and unknown objects resulting from different
algorithmic configurations and inference confidence thresholds. We also compare
the performance of our proposed algorithm to that of logits-based post-hoc OoD
methods, as well as possible fusion strategies. Finally, we discuss on the
competitiveness of all tested methods against state-of-the-art OoD approaches
for object detection models over the recently published Unknown Object
Detection benchmark. The obtained results verify that the performance of
avant-garde post-hoc OoD detectors can be further improved when combined with
our proposed algorithm.

摘要：穩健性是開發安全和值得信賴模型的基本面向，特別是當這些模型部署在開放的世界中。在這項工作中，我們分析了單階段目標偵測器在存在非分布 (OoD) 資料的情況下穩健運作的內在能力。具體來說，我們提出了一種新穎的偵測演算法，用於偵測影像資料中的未知物件，它利用模型從每個樣本中提取的特徵。與文獻中其他近期方法不同，我們的提議不需要重新訓練目標偵測器，從而允許使用預訓練模型。我們提出的 OoD 偵測器利用監督降維技術的應用來減輕維度詛咒對模型提取的特徵的影響。此外，它利用高解析度特徵圖以非監督的方式識別潛在的未知物件。我們的實驗分析了帕累托權衡，在不同演算法組態和推論信心閾值下偵測已知和未知物件的效能。我們還將我們提出的演算法的效能與基於邏輯的後設 OoD 方法以及可能的融合策略進行比較。最後，我們討論了所有測試方法在針對物件偵測模型的最新 OoD 方法的競爭力，以及最近發表的未知物件偵測基準。獲得的結果驗證了當與我們提出的演算法結合時，前衛的後設 OoD 偵測器的效能可以進一步提高。

##### **The State and Fate of Summarization Datasets**
2411.04585v1 by Noam Dahan, Gabriel Stanovsky

Automatic summarization has consistently attracted attention, due to its
versatility and wide application in various downstream tasks. Despite its
popularity, we find that annotation efforts have largely been disjointed, and
have lacked common terminology. Consequently, it is challenging to discover
existing resources or identify coherent research directions. To address this,
we survey a large body of work spanning 133 datasets in over 100 languages,
creating a novel ontology covering sample properties, collection methods and
distribution. With this ontology we make key observations, including the lack
in accessible high-quality datasets for low-resource languages, and the field's
over-reliance on the news domain and on automatically collected distant
supervision. Finally, we make available a web interface that allows users to
interact and explore our ontology and dataset collection, as well as a template
for a summarization data card, which can be used to streamline future research
into a more coherent body of work.

摘要：自動摘要一直備受關注，因為它具有多功能性，且廣泛應用於各種下游任務。儘管它很受歡迎，但我們發現註解工作在很大程度上是脫節的，並且缺乏通用的術語。因此，很難發現現有資源或確定連貫的研究方向。為了解決這個問題，我們調查了涵蓋 100 多種語言的 133 個資料集的大量工作，創建了一個涵蓋範例屬性、收集方法和分佈的新穎本體論。有了這個本體論，我們做出了關鍵觀察，包括缺乏低資源語言的可訪問高品質資料集，以及該領域過度依賴新聞領域和自動收集的遠程監督。最後，我們提供了一個 Web 介面，允許使用者互動並探索我們的本體論和資料集收集，以及一個摘要資料卡範本，可用於簡化未來研究，使其成為一個更連貫的工作主體。

##### **Interpreting the Learned Model in MuZero Planning**
2411.04580v1 by Hung Guei, Yan-Ru Ju, Wei-Yu Chen, Ti-Rong Wu

MuZero has achieved superhuman performance in various games by using a
dynamics network to predict environment dynamics for planning, without relying
on simulators. However, the latent states learned by the dynamics network make
its planning process opaque. This paper aims to demystify MuZero's model by
interpreting the learned latent states. We incorporate observation
reconstruction and state consistency into MuZero training and conduct an
in-depth analysis to evaluate latent states across two board games: 9x9 Go and
Outer-Open Gomoku, and three Atari games: Breakout, Ms. Pacman, and Pong. Our
findings reveal that while the dynamics network becomes less accurate over
longer simulations, MuZero still performs effectively by using planning to
correct errors. Our experiments also show that the dynamics network learns
better latent states in board games than in Atari games. These insights
contribute to a better understanding of MuZero and offer directions for future
research to improve the playing performance, robustness, and interpretability
of the MuZero algorithm.

摘要：MuZero 利用動態網路來預測環境動態以進行規劃，在各種遊戲中達到了超越人類的表現，而無需依賴模擬器。然而，動態網路所學習的潛在狀態使其規劃過程不透明。本文旨在透過解讀學習到的潛在狀態來揭開 MuZero 模型的神秘面紗。我們將觀察重建和狀態一致性納入 MuZero 訓練，並進行深入分析以評估兩個棋盤遊戲（9x9 圍棋和開放式五子棋）和三個 Atari 遊戲（Breakout、Ms. Pacman 和 Pong）中的潛在狀態。我們的發現揭示，儘管動態網路在較長的模擬中變得不那麼準確，但 MuZero 仍能透過規劃來修正錯誤，有效執行。我們的實驗還表明，動態網路在棋盤遊戲中學習的潛在狀態比在 Atari 遊戲中更好。這些見解有助於我們更深入地了解 MuZero，並為未來的研究提供了方向，以改善 MuZero 演算法的遊戲表現、穩健性和可解釋性。

##### **Multistage Fine-tuning Strategies for Automatic Speech Recognition in Low-resource Languages**
2411.04573v1 by Leena G Pillai, Kavya Manohar, Basil K Raju, Elizabeth Sherly

This paper presents a novel multistage fine-tuning strategy designed to
enhance automatic speech recognition (ASR) performance in low-resource
languages using OpenAI's Whisper model. In this approach we aim to build ASR
model for languages with limited digital resources by sequentially adapting the
model across linguistically similar languages. We experimented this on the
Malasar language, a Dravidian language spoken by approximately ten thousand
people in the Western Ghats of South India. Malasar language faces critical
challenges for technological intervention due to its lack of a native script
and absence of digital or spoken data resources. Working in collaboration with
Wycliffe India and Malasar community members, we created a spoken Malasar
corpus paired with transcription in Tamil script, a closely related major
language. In our approach to build ASR model for Malasar, we first build an
intermediate Tamil ASR, leveraging higher data availability for Tamil annotated
speech. This intermediate model is subsequently fine-tuned on Malasar data,
allowing for more effective ASR adaptation despite limited resources. The
multistage fine-tuning strategy demonstrated significant improvements over
direct fine-tuning on Malasar data alone, achieving a word error rate (WER) of
51.9%, which is 4.5% absolute reduction when compared to the direct fine-tuning
method. Further a WER reduction to 47.3% was achieved through punctuation
removal in post-processing, which addresses formatting inconsistencies that
impact evaluation. Our results underscore the effectiveness of sequential
multistage fine-tuning combined with targeted post-processing as a scalable
strategy for ASR system development in low-resource languages, especially where
linguistic similarities can be leveraged to bridge gaps in training data.

摘要：<paragraph>本文提出了一種新穎的多階段微調策略，旨在使用 OpenAI 的 Whisper 模型增強低資源語言中的自動語音識別 (ASR) 效能。在此方法中，我們旨在透過跨語言相似語言循序漸幅度地調整模型，為資源有限的語言建立 ASR 模型。我們在馬拉薩爾語上進行了實驗，馬拉薩爾語是一種德拉威語，由南印度西高止山脈約一萬人使用。由於馬拉薩爾語缺乏原生文字，且沒有數位或口語資料資源，因此面臨技術介入的嚴峻挑戰。我們與 Wycliffe India 和馬拉薩爾社區成員合作，建立了一個口語馬拉薩爾語語料庫，並配上以泰米爾文（一種密切相關的主要語言）書寫的轉錄。在我們建立馬拉薩爾語 ASR 模型的方法中，我們首先建立一個中間泰米爾語 ASR，利用泰米爾語標註語音較高的資料可用性。這個中間模型隨後在馬拉薩爾語資料上進行微調，儘管資源有限，仍能更有效地調整 ASR。多階段微調策略證明了與僅對馬拉薩爾語資料進行直接微調相比，有顯著的改善，達到 51.9% 的詞語錯誤率 (WER)，與直接微調方法相比，絕對降低了 4.5%。此外，透過後處理中的標點符號移除，WER 進一步降低至 47.3%，這解決了影響評估的格式不一致問題。我們的結果強調了循序多階段微調結合目標後處理作為低資源語言中 ASR 系統開發的可擴充策略的有效性，特別是在語言相似性可用於彌合訓練資料差距的情況下。</paragraph>

##### **Impact of Label Noise on Learning Complex Features**
2411.04569v1 by Rahul Vashisht, P. Krishna Kumar, Harsha Vardhan Govind, Harish G. Ramaswamy

Neural networks trained with stochastic gradient descent exhibit an inductive
bias towards simpler decision boundaries, typically converging to a narrow
family of functions, and often fail to capture more complex features. This
phenomenon raises concerns about the capacity of deep models to adequately
learn and represent real-world datasets. Traditional approaches such as
explicit regularization, data augmentation, architectural modifications, etc.,
have largely proven ineffective in encouraging the models to learn diverse
features. In this work, we investigate the impact of pre-training models with
noisy labels on the dynamics of SGD across various architectures and datasets.
We show that pretraining promotes learning complex functions and diverse
features in the presence of noise. Our experiments demonstrate that
pre-training with noisy labels encourages gradient descent to find alternate
minima that do not solely depend upon simple features, rather learns more
complex and broader set of features, without hurting performance.

摘要：神經網路使用隨機梯度下降訓練會展現出對較簡單決策邊界的歸納偏誤，通常會收斂到窄小的函數族，而且經常無法捕捉到較複雜的特徵。此現象引發了對深度模型是否具備足夠能力充分學習和呈現真實世界資料集的疑慮。傳統方法（例如明確正則化、資料擴充、架構修改等）在鼓勵模型學習多樣化特徵方面已普遍被證明無效。在這項工作中，我們探討了使用有雜訊標籤預先訓練模型對各種架構和資料集中的 SGD 動態的影響。我們證明了預先訓練會在有雜訊的情況下促進學習複雜函數和多樣化特徵。我們的實驗證明了使用有雜訊標籤進行預先訓練會鼓勵梯度下降尋找不完全依賴於簡單特徵的替代最小值，而會學習更複雜且更廣泛的特徵集，且不會損害效能。

##### **A Generalisation of Voter Model: Influential Nodes and Convergence Properties**
2411.04564v1 by Abhiram Manohara, Ahad N. Zehmakan

Consider an undirected graph G, representing a social network, where each
node is blue or red, corresponding to positive or negative opinion on a topic.
In the voter model, in discrete time rounds, each node picks a neighbour
uniformly at random and adopts its colour. Despite its significant popularity,
this model does not capture some fundamental real-world characteristics such as
the difference in the strengths of individuals connections, individuals with
neutral opinion on a topic, and individuals who are reluctant to update their
opinion. To address these issues, we introduce and study a generalisation of
the voter model. Motivating by campaigning strategies, we study the problem of
selecting a set of seeds blue nodes to maximise the expected number of blue
nodes after some rounds. We prove that the problem is NP- hard and provide a
polynomial time approximation algorithm with the best possible approximation
guarantee. Our experiments on real-world and synthetic graph data demonstrate
that the proposed algorithm outperforms other algorithms. We also investigate
the convergence properties of the model. We prove that the process could take
an exponential number of rounds to converge. However, if we limit ourselves to
strongly connected graphs, the convergence time is polynomial and the period
(the number of states in convergence) divides the length of all cycles in the
graph.

摘要：<paragraph>考慮一個無向圖 G，表示一個社交網路，其中每個節點為藍色或紅色，對應於對一個主題的正面或負面意見。在投票者模型中，在離散時間回合中，每個節點隨機選擇一個鄰居並採用其顏色。儘管它相當受歡迎，但此模型並未捕捉到一些基本的現實世界特徵，例如個人連接強度、對主題持中立意見的個人以及不願意更新其意見的個人。為了解決這些問題，我們引入並研究了投票者模型的概括。藉由競選策略，我們研究了選擇一組藍色種子節點以最大化多輪後藍色節點的預期數量的問題。我們證明此問題是 NP 難的，並提供了一個具有最佳可能近似保證的多項式時間近似演算法。我們在真實世界和合成圖形資料上的實驗證明，所提出的演算法優於其他演算法。我們也研究了模型的收斂性質。我們證明此程序可能需要指數輪數才能收斂。然而，如果我們將自己限制在強連通圖形，則收斂時間是多項式的，且週期（收斂中的狀態數）除以圖形中所有週期的長度。</paragraph>

##### **Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning**
2411.04562v1 by Marvin Alles, Philip Becker-Ehmck, Patrick van der Smagt, Maximilian Karl

In offline reinforcement learning, a policy is learned using a static dataset
in the absence of costly feedback from the environment. In contrast to the
online setting, only using static datasets poses additional challenges, such as
policies generating out-of-distribution samples. Model-based offline
reinforcement learning methods try to overcome these by learning a model of the
underlying dynamics of the environment and using it to guide policy search. It
is beneficial but, with limited datasets, errors in the model and the issue of
value overestimation among out-of-distribution states can worsen performance.
Current model-based methods apply some notion of conservatism to the Bellman
update, often implemented using uncertainty estimation derived from model
ensembles. In this paper, we propose Constrained Latent Action Policies (C-LAP)
which learns a generative model of the joint distribution of observations and
actions. We cast policy learning as a constrained objective to always stay
within the support of the latent action distribution, and use the generative
capabilities of the model to impose an implicit constraint on the generated
actions. Thereby eliminating the need to use additional uncertainty penalties
on the Bellman update and significantly decreasing the number of gradient steps
required to learn a policy. We empirically evaluate C-LAP on the D4RL and
V-D4RL benchmark, and show that C-LAP is competitive to state-of-the-art
methods, especially outperforming on datasets with visual observations.

摘要：在離線強化學習中，會使用靜態資料集來學習政策，而不會從環境中獲得昂貴的回饋。與線上設定相反，僅使用靜態資料集會產生額外的挑戰，例如政策產生出分佈外的範例。基於模型的離線強化學習方法會嘗試透過學習環境基礎動態的模型並使用該模型來引導政策搜尋來克服這些挑戰。這是有益的，但對於有限的資料集，模型中的錯誤和出分佈狀態的價值高估問題會惡化效能。目前的基於模型的方法會對貝爾曼更新套用一些保守概念，通常會使用從模型整體中衍生的不確定性估計來實作。在本文中，我們提出受約束潛在動作政策 (C-LAP)，它會學習觀測值和動作的聯合分佈的生成模型。我們將政策學習設定為受約束目標，以始終保持在潛在動作分佈的支援範圍內，並使用模型的生成能力對產生的動作施加隱式約束。從而消除了對貝爾曼更新使用額外不確定性懲罰的需求，並大幅減少學習政策所需的梯度步驟數。我們在 D4RL 和 V-D4RL 基準上對 C-LAP 進行經驗評估，並顯示 C-LAP 可與最先進的方法競爭，特別是在具有視覺觀測值的資料集上表現出色。

##### **Pruning Literals for Highly Efficient Explainability at Word Level**
2411.04557v1 by Rohan Kumar Yadav, Bimal Bhattarai, Abhik Jana, Lei Jiao, Seid Muhie Yimam

Designing an explainable model becomes crucial now for Natural Language
Processing(NLP) since most of the state-of-the-art machine learning models
provide a limited explanation for the prediction. In the spectrum of an
explainable model, Tsetlin Machine(TM) is promising because of its capability
of providing word-level explanation using proposition logic. However, concern
rises over the elaborated combination of literals (propositional logic) in the
clause that makes the model difficult for humans to comprehend, despite having
a transparent learning process. In this paper, we design a post-hoc pruning of
clauses that eliminate the randomly placed literals in the clause thereby
making the model more efficiently interpretable than the vanilla TM.
Experiments on the publicly available YELP-HAT Dataset demonstrate that the
proposed pruned TM's attention map aligns more with the human attention map
than the vanilla TM's attention map. In addition, the pairwise similarity
measure also surpasses the attention map-based neural network models. In terms
of accuracy, the proposed pruning method does not degrade the accuracy
significantly but rather enhances the performance up to 4% to 9% in some test
data.

摘要：<paragraph>在自然語言處理（NLP）中，設計一個可解釋的模型現在變得至關重要，因為大多數最先進的機器學習模型對預測提供的解釋有限。在可解釋模型的範疇中，Tsetlin 機器（TM）因其使用命題邏輯提供字元等級解釋的能力而很有前景。然而，儘管學習過程透明，但對子句中精細的字面量（命題邏輯）組合的關注卻讓人類難以理解該模型。在本文中，我們設計了一個子句的後設剪枝，消除了子句中隨機放置的字面量，從而使模型比香草 TM 更容易解釋。在公開的 YELP-HAT 資料集上的實驗表明，所提出的剪枝 TM 的注意力圖比香草 TM 的注意力圖更符合人類的注意力圖。此外，成對相似性測量也超越了基於注意力圖的神經網路模型。在準確性方面，所提出的剪枝方法並未顯著降低準確性，反而在某些測試資料中將效能提高了 4% 到 9%。</paragraph>

##### **Vision Language Models are In-Context Value Learners**
2411.04549v1 by Yecheng Jason Ma, Joey Hejna, Ayzaan Wahid, Chuyuan Fu, Dhruv Shah, Jacky Liang, Zhuo Xu, Sean Kirmani, Peng Xu, Danny Driess, Ted Xiao, Jonathan Tompson, Osbert Bastani, Dinesh Jayaraman, Wenhao Yu, Tingnan Zhang, Dorsa Sadigh, Fei Xia

Predicting temporal progress from visual trajectories is important for
intelligent robots that can learn, adapt, and improve. However, learning such
progress estimator, or temporal value function, across different tasks and
domains requires both a large amount of diverse data and methods which can
scale and generalize. To address these challenges, we present Generative Value
Learning (\GVL), a universal value function estimator that leverages the world
knowledge embedded in vision-language models (VLMs) to predict task progress.
Naively asking a VLM to predict values for a video sequence performs poorly due
to the strong temporal correlation between successive frames. Instead, GVL
poses value estimation as a temporal ordering problem over shuffled video
frames; this seemingly more challenging task encourages VLMs to more fully
exploit their underlying semantic and temporal grounding capabilities to
differentiate frames based on their perceived task progress, consequently
producing significantly better value predictions. Without any robot or task
specific training, GVL can in-context zero-shot and few-shot predict effective
values for more than 300 distinct real-world tasks across diverse robot
platforms, including challenging bimanual manipulation tasks. Furthermore, we
demonstrate that GVL permits flexible multi-modal in-context learning via
examples from heterogeneous tasks and embodiments, such as human videos. The
generality of GVL enables various downstream applications pertinent to
visuomotor policy learning, including dataset filtering, success detection, and
advantage-weighted regression -- all without any model training or finetuning.

摘要：預測視覺軌跡的時間進度對於能學習、適應和改進的智慧型機器人而言十分重要。然而，學習此類進度估計器或時間價值函數，在不同的任務和領域中需要大量多樣化的資料和可擴充且可概括的方法。為了應對這些挑戰，我們提出了生成式價值學習 (\GVL)，這是一個通用價值函數估計器，它利用嵌入在視覺語言模型 (VLM) 中的世界知識來預測任務進度。天真地要求 VLM 預測影片序列的價值會表現不佳，因為連續幀之間有很強的時間相關性。相反地，GVL 將價值估計設定為打亂影片幀的時序排序問題；這個看似更具挑戰性的任務鼓勵 VLM 更充分地利用其底層語義和時序基礎功能，根據感知任務進度來區分幀，從而產生顯著更好的價值預測。GVL 無需任何機器人或任務特定訓練，即可在情境中進行零次學習和少量學習，預測超過 300 個跨越不同機器人平台的真實世界任務的有效價值，包括具有挑戰性的雙手操作任務。此外，我們證明 GVL 允許透過異質任務和具體實例（例如人類影片）中的範例進行靈活的多模式情境學習。GVL 的普遍性支援各種與視動運動策略學習相關的下游應用，包括資料集過濾、成功檢測和優勢加權回歸，所有這些都不需要任何模型訓練或微調。

##### **Best Practices for Distilling Large Language Models into BERT for Web Search Ranking**
2411.04539v1 by Dezhi Ye, Junwei Hu, Jiabin Fan, Bowen Tian, Jie Liu, Haijin Liang, Jin Ma

Recent studies have highlighted the significant potential of Large Language
Models (LLMs) as zero-shot relevance rankers. These methods predominantly
utilize prompt learning to assess the relevance between queries and documents
by generating a ranked list of potential documents. Despite their promise, the
substantial costs associated with LLMs pose a significant challenge for their
direct implementation in commercial search systems. To overcome this barrier
and fully exploit the capabilities of LLMs for text ranking, we explore
techniques to transfer the ranking expertise of LLMs to a more compact model
similar to BERT, using a ranking loss to enable the deployment of less
resource-intensive models. Specifically, we enhance the training of LLMs
through Continued Pre-Training, taking the query as input and the clicked title
and summary as output. We then proceed with supervised fine-tuning of the LLM
using a rank loss, assigning the final token as a representative of the entire
sentence. Given the inherent characteristics of autoregressive language models,
only the final token </s> can encapsulate all preceding tokens. Additionally,
we introduce a hybrid point-wise and margin MSE loss to transfer the ranking
knowledge from LLMs to smaller models like BERT. This method creates a viable
solution for environments with strict resource constraints. Both offline and
online evaluations have confirmed the efficacy of our approach, and our model
has been successfully integrated into a commercial web search engine as of
February 2024.

摘要：最近的研究強調了大型語言模型 (LLM) 作為零次學習相關性排序器的顯著潛力。這些方法主要利用提示學習，透過產生潛在文件的有序清單，來評估查詢與文件之間的相關性。儘管它們很有前途，但與 LLM 相關的龐大成本對它們在商業搜尋系統中的直接實作構成重大挑戰。為了克服此障礙並充分利用 LLM 的文字排序功能，我們探索了將 LLM 的排序專業知識轉移到更精簡的模型（類似於 BERT）的技術，使用排序損失來實現資源密集度較低的模型的部署。具體來說，我們透過持續預訓練來增強 LLM 的訓練，將查詢作為輸入，並將點擊的標題和摘要作為輸出。然後，我們使用排序損失對 LLM 進行監督式微調，將最終代幣指定為整個句子的代表。由於自迴歸語言模型的固有特性，只有最終代幣 </s> 才能囊括所有前一個代幣。此外，我們引入了混合點式和邊際 MSE 損失，將 LLM 的排序知識轉移到較小的模型（如 BERT）中。此方法為資源限制嚴格的環境創造了可行的解決方案。離線和線上評估都證實了我們方法的有效性，而我們的模型已於 2024 年 2 月成功整合到商業網路搜尋引擎中。

##### **Meta-Reasoning Improves Tool Use in Large Language Models**
2411.04535v1 by Lisa Alazraki, Marek Rei

External tools help large language models (LLMs) succeed at tasks where they
would otherwise typically fail. In existing frameworks, LLMs learn tool use
either by in-context demonstrations or via full model fine-tuning on annotated
data. As these approaches do not easily scale, a recent trend is to abandon
them in favor of lightweight, parameter-efficient tuning paradigms. These
methods allow quickly alternating between the frozen LLM and its specialised
fine-tuned version, by switching on or off a handful of additional custom
parameters. Hence, we postulate that the generalization ability of the frozen
model can be leveraged to improve tool selection. We present Tool selECTion via
meta-reasONing (TECTON), a two-phase system that first reasons over a task
using a custom fine-tuned LM head and outputs candidate tools. Then, with the
custom head disabled, it meta-reasons (i.e., it reasons over the previous
reasoning process) to make a final choice. We show that TECTON results in
substantial gains - both in-distribution and out-of-distribution - on a range
of math reasoning datasets.

摘要：外部工具可協助大型語言模型 (LLM) 在其原本通常會失敗的任務中獲得成功。在現有的架構中，LLM 透過情境中的示範或透過針對註解資料進行完整的模型微調來學習使用工具。由於這些方法不易擴展，因此最近的趨勢是放棄它們，轉而採用輕量級、參數高效的微調範例。這些方法允許透過啟用或停用少數額外的自訂參數，在凍結的 LLM 和其經過專門微調的版本之間快速交替。因此，我們假設可以利用凍結模型的泛化能力來改善工具選擇。我們提出了透過元推理進行工具選擇 (TECTON)，這是一個分為兩個階段的系統，它會先使用自訂微調的 LM 頭針對任務進行推理，並輸出候選工具。然後，在停用自訂頭的情況下，它會進行元推理（即對先前的推理過程進行推理）以做出最終選擇。我們表明 TECTON 在一系列數學推理資料集上產生了實質的收益，無論是在分佈內還是分佈外。

##### **Tomato, Tomahto, Tomate: Measuring the Role of Shared Semantics among Subwords in Multilingual Language Models**
2411.04530v1 by Xinyu Zhang, Jing Lu, Vinh Q. Tran, Tal Schuster, Donald Metzler, Jimmy Lin

Human understanding of language is robust to different word choices as far as
they represent similar semantic concepts. To what extent does our human
intuition transfer to language models, which represent all subwords as distinct
embeddings? In this work, we take an initial step on measuring the role of
shared semantics among subwords in the encoder-only multilingual language
models (mLMs). To this end, we form "semantic tokens" by merging the
semantically similar subwords and their embeddings, and evaluate the updated
mLMs on 5 heterogeneous multilingual downstream tasks. Results show that the
general shared semantics could get the models a long way in making the
predictions on mLMs with different tokenizers and model sizes. Inspections on
the grouped subwords show that they exhibit a wide range of semantic
similarities, including synonyms and translations across many languages and
scripts. Lastly, we found the zero-shot results with semantic tokens are on par
or even better than the original models on certain classification tasks,
suggesting that the shared subword-level semantics may serve as the anchors for
cross-lingual transferring.

摘要：人類對語言的理解力對於不同的詞彙選擇是強健的，只要它們代表相似的語義概念。我們的直覺在多大程度上可以轉移到語言模型，而語言模型將所有子詞表示為不同的嵌入？在這項工作中，我們踏出了初步步驟，測量編碼器專用多語言語言模型 (mLMs) 中子詞之間共享語義的角色。為此，我們通過合併語義相似的子詞及其嵌入，形成了「語義標記」，並在 5 個異質多語言下游任務上評估更新的 mLMs。結果表明，通用的共享語義可以讓模型在使用不同標記器和模型大小的 mLMs 上進行預測時走得很遠。對分組子詞的檢查表明，它們展現出廣泛的語義相似性，包括許多語言和腳本中的同義詞和翻譯。最後，我們發現使用語義標記的零次學習結果與原始模型在某些分類任務上相當甚至更好，這表明共享的子詞級語義可以作為跨語言轉移的錨點。

##### **GenJoin: Conditional Generative Plan-to-Plan Query Optimizer that Learns from Subplan Hints**
2411.04525v1 by Pavel Sulimov, Claude Lehmann, Kurt Stockinger

Query optimization has become a research area where classical algorithms are
being challenged by machine learning algorithms. At the same time, recent
trends in learned query optimizers have shown that it is prudent to take
advantage of decades of database research and augment classical query
optimizers by shrinking the plan search space through different types of hints
(e.g. by specifying the join type, scan type or the order of joins) rather than
completely replacing the classical query optimizer with machine learning
models. It is especially relevant for cases when classical optimizers cannot
fully enumerate all logical and physical plans and, as an alternative, need to
rely on less robust approaches like genetic algorithms. However, even
symbiotically learned query optimizers are hampered by the need for vast
amounts of training data, slow plan generation during inference and unstable
results across various workload conditions. In this paper, we present GenJoin -
a novel learned query optimizer that considers the query optimization problem
as a generative task and is capable of learning from a random set of subplan
hints to produce query plans that outperform the classical optimizer. GenJoin
is the first learned query optimizer that significantly and consistently
outperforms PostgreSQL as well as state-of-the-art methods on two well-known
real-world benchmarks across a variety of workloads using rigorous machine
learning evaluations.

摘要：查詢最佳化已成為一個研究領域，其中古典演算法受到機器學習演算法的挑戰。同時，已學習查詢最佳化器的近期趨勢顯示，審慎利用數十年的資料庫研究和透過不同類型的提示（例如，透過指定連接類型、掃描類型或連接順序）來縮小計畫搜尋空間，而非完全以機器學習模型取代古典查詢最佳化器，是明智之舉。這對古典最佳化器無法完全列舉所有邏輯和實體計畫，且需要依賴遺傳演算法等較不穩健的方法作為替代方案的情況尤其相關。然而，即使是共生學習的查詢最佳化器也受到大量訓練資料需求、推論期間的計畫產生緩慢以及在各種工作負載條件下結果不穩定的阻礙。在本文中，我們提出 GenJoin，這是一個新穎的已學習查詢最佳化器，它將查詢最佳化問題視為生成任務，並能夠從一組隨機子計畫提示中學習，以產生優於古典最佳化器的查詢計畫。GenJoin 是第一個已學習查詢最佳化器，它顯著且持續優於 PostgreSQL，以及在使用嚴謹機器學習評估的各種工作負載中，於兩個著名的真實世界基準測試上的最新方法。

##### **Continuous Sign Language Recognition System using Deep Learning with MediaPipe Holistic**
2411.04517v1 by Sharvani Srivastava, Sudhakar Singh, Pooja, Shiv Prakash

Sign languages are the language of hearing-impaired people who use visuals
like the hand, facial, and body movements for communication. There are
different signs and gestures representing alphabets, words, and phrases.
Nowadays approximately 300 sign languages are being practiced worldwide such as
American Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language
(ISL), and many more. Sign languages are dependent on the vocal language of a
place. Unlike vocal or spoken languages, there are no helping words in sign
language like is, am, are, was, were, will, be, etc. As only a limited
population is well-versed in sign language, this lack of familiarity of sign
language hinders hearing-impaired people from communicating freely and easily
with everyone. This issue can be addressed by a sign language recognition (SLR)
system which has the capability to translate the sign language into vocal
language. In this paper, a continuous SLR system is proposed using a deep
learning model employing Long Short-Term Memory (LSTM), trained and tested on
an ISL primary dataset. This dataset is created using MediaPipe Holistic
pipeline for tracking face, hand, and body movements and collecting landmarks.
The system recognizes the signs and gestures in real-time with 88.23% accuracy.

摘要：手語是聽障人士的語言，他們使用視覺
例如手部、面部和身體動作進行溝通。有
不同的符號和手勢代表字母、單詞和短語。
如今，全世界約有 300 種手語正在使用，例如
美國手語 (ASL)、中國手語 (CSL)、印度手語
(ISL) 等。手語依賴於一個地方的口語。與口語不同
語言，手語中沒有幫助詞，例如 is、am、are、was、were、will、be 等。由於只有少數人精通手語，這種對手語的不熟悉會阻礙聽障人士與每個人自由輕鬆地交流。這個問題可以通過手語識別 (SLR) 系統來解決，該系統具有將手語翻譯成口語的能力。在本文中，使用採用長短期記憶 (LSTM) 的深度學習模型提出了一個連續 SLR 系統，並在 ISL 初級數據集上進行了訓練和測試。此數據集使用 MediaPipe Holistic 管道創建，用於跟蹤面部、手部和身體動作並收集地標。該系統實時識別符號和手勢，準確率為 88.23%。

##### **FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**
2411.04509v1 by Liangrui Pan, Mao Huang, Lian Wang, Pinle Qin, Shaoliang Peng

Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is
considered the gold standard for pathologists and medical practitioners for
tumor diagnosis, surgical planning, and post-operative assessment. With the
rapid advancement of deep learning technologies, the development of numerous
models based on convolutional neural networks and transformer-based models has
been applied to the precise segmentation of WSIs. However, due to privacy
regulations and the need to protect patient confidentiality, centralized
storage and processing of image data are impractical. Training a centralized
model directly is challenging to implement in medical settings due to these
privacy concerns.This paper addresses the dispersed nature and privacy
sensitivity of medical image data by employing a federated learning framework,
allowing medical institutions to collaboratively learn while protecting patient
privacy. Additionally, to address the issue of original data reconstruction
through gradient inversion during the federated learning training process,
differential privacy introduces noise into the model updates, preventing
attackers from inferring the contributions of individual samples, thereby
protecting the privacy of the training data.Experimental results show that the
proposed method, FedDP, minimally impacts model accuracy while effectively
safeguarding the privacy of cancer pathology image data, with only a slight
decrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%,
respectively. This approach facilitates cross-institutional collaboration and
knowledge sharing while protecting sensitive data privacy, providing a viable
solution for further research and application in the medical field.

摘要：蘇木精和伊紅（H&E）染色全切片圖像（WSI）被認為是病理學家和醫療從業人員用於腫瘤診斷、手術規劃和術後評估的黃金標準。隨著深度學習技術的快速進展，基於卷積神經網路和基於Transformer的模型的眾多模型已被應用於 WSI 的精確分割。然而，由於隱私法規和保護患者機密性的需要，集中式儲存和處理影像資料是不切實際的。由於這些隱私問題，在醫療環境中直接訓練集中式模型難以實施。本文通過採用聯合學習框架來解決醫療影像資料的分散性質和隱私敏感性，允許醫療機構在保護患者隱私的同時進行協作學習。此外，為了解決聯合學習訓練過程中通過梯度反轉進行原始資料重建的問題，差分隱私會在模型更新中引入雜訊，防止攻擊者推斷個別樣本的貢獻，從而保護訓練資料的隱私。實驗結果表明，所提出的方法 FedDP 對模型準確度的影響最小，同時有效保護了癌症病理影像資料的隱私，Dice、Jaccard 和 Acc 指數分別僅略微下降了 0.55%、0.63% 和 0.42%。這種方法促進了機構間的合作和知識共享，同時保護了敏感資料的隱私，為醫療領域的進一步研究和應用提供了可行的解決方案。

##### **Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model**
2411.04496v1 by Young-Jun Lee, Dokyong Lee, Junyoung Youn, Kyeongjin Oh, Ho-Jin Choi

To increase social bonding with interlocutors, humans naturally acquire the
ability to respond appropriately in a given situation by considering which
conversational skill is most suitable for the response - a process we call
skill-of-mind. For large language model (LLM)-based conversational agents,
planning appropriate conversational skills, as humans do, is challenging due to
the complexity of social dialogue, especially in interactive scenarios. To
address this, we propose a skill-of-mind-annotated conversation dataset, named
Multifaceted Skill-of-Mind, which includes multi-turn and multifaceted
conversational skills across various interactive scenarios (e.g., long-term,
counseling, task-oriented), grounded in diverse social contexts (e.g.,
demographics, persona, rules of thumb). This dataset consists of roughly 100K
conversations. Using this dataset, we introduce a new family of
skill-of-mind-infused LLMs, named Thanos, with model sizes of 1B, 3B, and 8B
parameters. With extensive experiments, these models successfully demonstrate
the skill-of-mind process and exhibit strong generalizability in inferring
multifaceted skills across a variety of domains. Moreover, we show that Thanos
significantly enhances the quality of responses generated by LLM-based
conversational agents and promotes prosocial behavior in human evaluations.

摘要：為了增加與對話者的社交連結，人類自然會習得在特定情況下適當地回應的能力，考量哪種對話技巧最適合回應，這項過程我們稱為心智技巧。對於大型語言模型 (LLM) 為基礎的對話代理來說，規劃適當的對話技巧，就像人類一樣，是一項挑戰，因為社交對話很複雜，尤其是在互動式情境中。為了解決這個問題，我們提出一個心智技巧註解對話資料集，稱為多面向心智技巧，其中包含各種互動式情境（例如長期、諮詢、以任務為導向）的多輪且多面向對話技巧，並奠基於不同的社交脈絡（例如人口統計、角色、經驗法則）。此資料集包含約 100K 對話。使用此資料集，我們引進一個新系列的心智技巧注入式 LLM，稱為 Thanos，模型大小為 1B、3B 和 8B 參數。透過廣泛的實驗，這些模型成功示範心智技巧過程，並展現強大的概括能力，用於推論各種領域的多面向技巧。此外，我們證明 Thanos 大幅提升 LLM 為基礎的對話代理所產生的回應品質，並在人類評估中促進親社會行為。

##### **Series-to-Series Diffusion Bridge Model**
2411.04491v1 by Hao Yang, Zhanbo Feng, Feng Zhou, Robert C Qiu, Zenan Ling

Diffusion models have risen to prominence in time series forecasting,
showcasing their robust capability to model complex data distributions.
However, their effectiveness in deterministic predictions is often constrained
by instability arising from their inherent stochasticity. In this paper, we
revisit time series diffusion models and present a comprehensive framework that
encompasses most existing diffusion-based methods. Building on this theoretical
foundation, we propose a novel diffusion-based time series forecasting model,
the Series-to-Series Diffusion Bridge Model ($\mathrm{S^2DBM}$), which
leverages the Brownian Bridge process to reduce randomness in reverse
estimations and improves accuracy by incorporating informative priors and
conditions derived from historical time series data. Experimental results
demonstrate that $\mathrm{S^2DBM}$ delivers superior performance in
point-to-point forecasting and competes effectively with other diffusion-based
models in probabilistic forecasting.

摘要：擴散模型在時間序列預測中已日益受到重視，展示了其對複雜數據分佈建模的強大能力。然而，它們在確定性預測中的有效性通常受到其固有隨機性所產生的不穩定性的限制。在本文中，我們重新探討了時間序列擴散模型，並提出了涵蓋大多數現有基於擴散的方法的綜合框架。在此理論基礎之上，我們提出了一個新穎的基於擴散的時間序列預測模型，即序列到序列擴散橋模型（$\mathrm{S^2DBM}$），它利用布朗橋過程來減少反向估計中的隨機性，並通過整合從歷史時間序列數據中得出的信息先驗和條件來提高準確性。實驗結果表明，$\mathrm{S^2DBM}$ 在點對點預測中提供了卓越的性能，並在概率預測中與其他基於擴散的模型有效競爭。

##### **ML-Promise: A Multilingual Dataset for Corporate Promise Verification**
2411.04473v1 by Yohei Seki, Hakusen Shu, Anaïs Lhuissier, Hanwool Lee, Juyeon Kang, Min-Yuh Day, Chung-Chi Chen

Promises made by politicians, corporate leaders, and public figures have a
significant impact on public perception, trust, and institutional reputation.
However, the complexity and volume of such commitments, coupled with
difficulties in verifying their fulfillment, necessitate innovative methods for
assessing their credibility. This paper introduces the concept of Promise
Verification, a systematic approach involving steps such as promise
identification, evidence assessment, and the evaluation of timing for
verification. We propose the first multilingual dataset, ML-Promise, which
includes English, French, Chinese, Japanese, and Korean, aimed at facilitating
in-depth verification of promises, particularly in the context of
Environmental, Social, and Governance (ESG) reports. Given the growing emphasis
on corporate environmental contributions, this dataset addresses the challenge
of evaluating corporate promises, especially in light of practices like
greenwashing. Our findings also explore textual and image-based baselines, with
promising results from retrieval-augmented generation (RAG) approaches. This
work aims to foster further discourse on the accountability of public
commitments across multiple languages and domains.

摘要：政客、企業領袖和公眾人物做出的承諾對公眾觀感、信任和機構聲譽有重大影響。然而，此類承諾的複雜性和數量，加上難以驗證其履行的難度，需要創新的方法來評估其可信度。本文介紹了承諾驗證的概念，這是一種系統化的方法，涉及承諾識別、證據評估和驗證時機評估等步驟。我們提出了第一個多語言數據集 ML-Promise，其中包括英語、法語、中文、日語和韓語，旨在促進對承諾的深入驗證，特別是在環境、社會和治理 (ESG) 報告的背景下。鑑於對企業環境貢獻的日益重視，此數據集應對了評估企業承諾的挑戰，特別是考慮到綠色漂白等做法。我們的研究結果還探索了文本和基於圖像的基準，從檢索增強生成 (RAG) 方法中獲得了有希望的結果。這項工作旨在促進對跨多種語言和領域的公開承諾的問責制的進一步討論。

##### **Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks**
2411.04468v1 by Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang, Zhu, Friederike Niedtner, Grace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor Dibia, Ahmed Awadallah, Ece Kamar, Rafah Hosn, Saleema Amershi

Modern AI agents, driven by advances in large foundation models, promise to
enhance our productivity and transform our lives by augmenting our knowledge
and capabilities. To achieve this vision, AI agents must effectively plan,
perform multi-step reasoning and actions, respond to novel observations, and
recover from errors, to successfully complete complex tasks across a wide range
of scenarios. In this work, we introduce Magentic-One, a high-performing
open-source agentic system for solving such tasks. Magentic-One uses a
multi-agent architecture where a lead agent, the Orchestrator, plans, tracks
progress, and re-plans to recover from errors. Throughout task execution, the
Orchestrator directs other specialized agents to perform tasks as needed, such
as operating a web browser, navigating local files, or writing and executing
Python code. We show that Magentic-One achieves statistically competitive
performance to the state-of-the-art on three diverse and challenging agentic
benchmarks: GAIA, AssistantBench, and WebArena. Magentic-One achieves these
results without modification to core agent capabilities or to how they
collaborate, demonstrating progress towards generalist agentic systems.
Moreover, Magentic-One's modular design allows agents to be added or removed
from the team without additional prompt tuning or training, easing development
and making it extensible to future scenarios. We provide an open-source
implementation of Magentic-One, and we include AutoGenBench, a standalone tool
for agentic evaluation. AutoGenBench provides built-in controls for repetition
and isolation to run agentic benchmarks in a rigorous and contained manner --
which is important when agents' actions have side-effects. Magentic-One,
AutoGenBench and detailed empirical performance evaluations of Magentic-One,
including ablations and error analysis are available at
https://aka.ms/magentic-one

摘要：<paragraph>由大型基础模型的进步推动的现代 AI 代理有望通过增强我们的知识和能力来提高我们的生产力并改变我们的生活。为了实现这一愿景，AI 代理必须有效地规划、执行多步骤推理和动作、响应新颖的观察结果以及从错误中恢复，以成功完成广泛场景中的复杂任务。在这项工作中，我们介绍了 Magentic-One，这是一个用于解决此类任务的高性能开源代理系统。Magentic-One 使用多代理架构，其中一个领导代理（Orchestrator）计划、跟踪进度并重新计划以从错误中恢复。在整个任务执行过程中，Orchestrator 指导其他专门代理根据需要执行任务，例如操作网络浏览器、导航本地文件或编写和执行 Python 代码。我们展示了 Magentic-One 在三个不同且具有挑战性的代理基准测试（GAIA、AssistantBench 和 WebArena）上实现了与最先进技术具有统计竞争力的性能。Magentic-One 在不修改核心代理功能或它们如何协作的情况下实现了这些结果，展示了朝着通才代理系统取得的进展。此外，Magentic-One 的模块化设计允许在不进行额外提示调整或培训的情况下向团队添加或删除代理，从而简化开发并使其可扩展到未来的场景。我们提供了 Magentic-One 的开源实现，并且我们包含了 AutoGenBench，这是一个用于代理评估的独立工具。AutoGenBench 提供了内置的重复和隔离控件，以严格且受控的方式运行代理基准测试——当代理的动作产生副作用时这一点非常重要。Magentic-One、AutoGenBench 和 Magentic-One 的详细经验性能评估（包括消融和错误分析）可在 https://aka.ms/magentic-one 获得</paragraph>

##### **Can CDT rationalise the ex ante optimal policy via modified anthropics?**
2411.04462v1 by Emery Cooper, Caspar Oesterheld, Vincent Conitzer

In Newcomb's problem, causal decision theory (CDT) recommends two-boxing and
thus comes apart from evidential decision theory (EDT) and ex ante policy
optimisation (which prescribe one-boxing). However, in Newcomb's problem, you
should perhaps believe that with some probability you are in a simulation run
by the predictor to determine whether to put a million dollars into the opaque
box. If so, then causal decision theory might recommend one-boxing in order to
cause the predictor to fill the opaque box. In this paper, we study
generalisations of this approach. That is, we consider general Newcomblike
problems and try to form reasonable self-locating beliefs under which CDT's
recommendations align with an EDT-like notion of ex ante policy optimisation.
We consider approaches in which we model the world as running simulations of
the agent, and an approach not based on such models (which we call 'Generalised
Generalised Thirding', or GGT). For each approach, we characterise the
resulting CDT policies, and prove that under certain conditions, these include
the ex ante optimal policies.

摘要：在紐康問題中，因果決策理論（CDT）建議雙盒策略，因此與證據決策理論（EDT）和事前策略最佳化（建議單盒策略）有所不同。然而，在紐康問題中，你或許應該相信你有一定機率處於預測者執行的模擬中，以決定是否將一百萬美元放入不透明的盒子中。如果是這樣，那麼因果決策理論可能會建議單盒策略，以促使預測者填滿不透明的盒子。在本文中，我們研究了這種方法的概括。也就是說，我們考慮一般的新康式問題，並嘗試形成合理的自我定位信念，在這些信念下，CDT 的建議與 EDT 式的事前策略最佳化的概念相一致。我們考慮的方法包括將世界建模為執行代理模擬，以及不基於此類模型的方法（我們稱之為「廣義廣義三分法」，或 GGT）。對於每種方法，我們描述了由此產生的 CDT 策略，並證明在特定條件下，這些策略包括事前最佳策略。

##### **Gradient Localization Improves Lifelong Pretraining of Language Models**
2411.04448v1 by Jared Fernandez, Yonatan Bisk, Emma Strubell

Large Language Models (LLMs) trained on web-scale text corpora have been
shown to capture world knowledge in their parameters. However, the mechanism by
which language models store different types of knowledge is poorly understood.
In this work, we examine two types of knowledge relating to temporally
sensitive entities and demonstrate that each type is localized to different
sets of parameters within the LLMs. We hypothesize that the lack of
consideration of the locality of knowledge in existing continual learning
methods contributes to both: the failed uptake of new information, and
catastrophic forgetting of previously learned information. We observe that
sequences containing references to updated and newly mentioned entities exhibit
larger gradient norms in a subset of layers. We demonstrate that targeting
parameter updates to these relevant layers can improve the performance of
continually pretraining on language containing temporal drift.

摘要：大型语言模型 (LLM) 在网络规模文本语料库上进行训练，已显示出在其参数中捕获世界知识。然而，语言模型存储不同类型知识的机制却鲜为人知。在这项工作中，我们检查了与时间敏感实体相关的两种类型的知识，并证明每种类型都定位于 LLM 内的不同参数集。我们假设在现有的持续学习方法中缺乏对知识局部性的考虑，导致了新信息的吸收失败和先前学习信息的灾难性遗忘。我们观察到，包含对更新和新提及实体的引用的序列在子集中表现出更大的梯度范数。我们证明，将参数更新目标定位到这些相关层可以提高在包含时间漂移的语言上持续预训练的性能。

##### **ACCIO: Table Understanding Enhanced via Contrastive Learning with Aggregations**
2411.04443v1 by Whanhee Cho

The attention to table understanding using recent natural language models has
been growing. However, most related works tend to focus on learning the
structure of the table directly. Just as humans improve their understanding of
sentences by comparing them, they can also enhance their understanding by
comparing tables. With this idea, in this paper, we introduce ACCIO, tAble
understanding enhanCed via Contrastive learnIng with aggregatiOns, a novel
approach to enhancing table understanding by contrasting original tables with
their pivot summaries through contrastive learning. ACCIO trains an encoder to
bring these table pairs closer together. Through validation via column type
annotation, ACCIO achieves competitive performance with a macro F1 score of
91.1 compared to state-of-the-art methods. This work represents the first
attempt to utilize pairs of tables for table embedding, promising significant
advancements in table comprehension. Our code is available at
https://github.com/whnhch/ACCIO/.

摘要：近來使用自然語言模型來理解表格的關注度正在增加。然而，大多數相關工作傾向於直接學習表格的結構。就像人類透過比較句子來提升對句子的理解，他們也能透過比較表格來增強對表格的理解。有了這個想法，在本文中，我們引入了 ACCIO，一種透過對比學習，利用聚合來增強表格理解的表格理解增強方法，這是一種透過對比學習將原始表格與其樞紐摘要進行對比的新穎方法。ACCIO 訓練一個編碼器，讓這些表格對更接近。透過欄位類型註解的驗證，ACCIO 達到了競爭力的效能，巨觀 F1 分數為 91.1，與最先進的方法相比。這項工作代表了首次嘗試利用表格對來進行表格嵌入，有望在表格理解方面取得重大進展。我們的程式碼可在 https://github.com/whnhch/ACCIO/ 取得。

##### **Scaling Laws for Pre-training Agents and World Models**
2411.04434v1 by Tim Pearce, Tabish Rashid, Dave Bignell, Raluca Georgescu, Sam Devlin, Katja Hofmann

The performance of embodied agents has been shown to improve by increasing
model parameters, dataset size, and compute. This has been demonstrated in
domains from robotics to video games, when generative learning objectives on
offline datasets (pre-training) are used to model an agent's behavior
(imitation learning) or their environment (world modeling). This paper
characterizes the role of scale in these tasks more precisely. Going beyond the
simple intuition that `bigger is better', we show that the same types of power
laws found in language modeling (e.g. between loss and optimal model size),
also arise in world modeling and imitation learning. However, the coefficients
of these laws are heavily influenced by the tokenizer, task \& architecture --
this has important implications on the optimal sizing of models and data.

摘要：具身代理的效能已證實能透過增加模型參數、資料集大小和運算而提升。這已在機器人技術到電玩遊戲等領域中獲得驗證，當離線資料集（預訓練）上的生成式學習目標用於建模代理行為（模仿學習）或其環境（世界建模）時。本文更精確地描述了規模在這些任務中的角色。除了「越大越好」的直覺之外，我們展示了在語言建模中發現的相同類型的冪律（例如，損失和最佳模型大小之間）也出現在世界建模和模仿學習中。然而，這些定律的係數受到分詞器、任務和架構的極大影響——這對模型和資料的最佳大小有重要的影響。

##### **One fish, two fish, but not the whole sea: Alignment reduces language models' conceptual diversity**
2411.04427v1 by Sonia K. Murthy, Tomer Ullman, Jennifer Hu

Researchers in social science and psychology have recently proposed using
large language models (LLMs) as replacements for humans in behavioral research.
In addition to arguments about whether LLMs accurately capture population-level
patterns, this has raised questions about whether LLMs capture human-like
conceptual diversity. Separately, it is debated whether post-training alignment
(RLHF or RLAIF) affects models' internal diversity. Inspired by human studies,
we use a new way of measuring the conceptual diversity of
synthetically-generated LLM "populations" by relating the internal variability
of simulated individuals to the population-level variability. We use this
approach to evaluate non-aligned and aligned LLMs on two domains with rich
human behavioral data. While no model reaches human-like diversity, aligned
models generally display less diversity than their instruction fine-tuned
counterparts. Our findings highlight potential trade-offs between increasing
models' value alignment and decreasing the diversity of their conceptual
representations.

摘要：社會科學和心理學的研究人員最近提出使用大型語言模型 (LLM) 來取代人類進行行為研究。除了關於 LLM 是否準確捕捉人口層級模式的論點之外，這也引發了 LLM 是否捕捉到類人概念多樣性的問題。另外，爭論的焦點在於訓練後的比對（RLHF 或 RLAIF）是否會影響模型的內部多樣性。受到人類研究的啟發，我們使用一種新的方式來衡量合成產生的 LLM「族群」的概念多樣性，方法是將模擬個體的內部變異與族群層級的變異關聯起來。我們使用這種方法在兩個具有豐富人類行為資料的領域中評估未比對和已比對的 LLM。雖然沒有任何模型達到類人的多樣性，但已比對的模型通常比其微調指令的對應模型顯示出較低的多樣性。我們的研究結果突出了在增加模型價值比對和降低其概念表徵多樣性之間的潛在取捨。

##### **DELIFT: Data Efficient Language model Instruction Fine Tuning**
2411.04425v1 by Ishika Agarwal, Krishna Killamsetty, Lucian Popa, Marina Danilevksy

Fine-tuning large language models (LLMs) is essential for enhancing their
performance on specific tasks but is often resource-intensive due to redundant
or uninformative data. To address this inefficiency, we introduce DELIFT (Data
Efficient Language model Instruction Fine-Tuning), a novel algorithm that
systematically optimizes data selection across the three key stages of
fine-tuning: (1) instruction tuning, (2) task-specific fine-tuning (e.g.,
reasoning, question-answering), and (3) continual fine-tuning (e.g.,
incorporating new data versions). Unlike existing methods that focus on
single-stage optimization or rely on computationally intensive gradient
calculations, DELIFT operates efficiently across all stages. Central to our
approach is a pairwise utility metric that quantifies how beneficial a data
sample is for improving the model's responses to other samples, effectively
measuring the informational value relative to the model's current capabilities.
By leveraging different submodular functions applied to this metric, DELIFT
selects diverse and optimal subsets that are useful across all stages of
fine-tuning. Experiments across various tasks and model scales demonstrate that
DELIFT can reduce the fine-tuning data size by up to 70% without compromising
performance, offering significant computational savings and outperforming
existing methods in both efficiency and efficacy.

摘要：微調大型語言模型 (LLM) 對於提升其在特定任務上的表現至關重要，但由於冗餘或無資訊資料，通常會耗費大量資源。為了解決此低效率問題，我們引入了 DELIFT（資料有效語言模型指令微調），一種新演算法，可系統性地最佳化微調三個關鍵階段的資料選取：(1) 指令微調、(2) 任務特定微調（例如推理、問答），以及 (3) 持續微調（例如納入新資料版本）。與現有方法不同，現有方法專注於單階段最佳化或依賴於計算密集的梯度計算，DELIFT 在所有階段都能有效運作。我們方法的核心是一個成對效用指標，用於量化資料範例對於改善模型對其他範例的回應有多大的好處，有效地衡量相對於模型當前功能的資訊價值。透過對此指標應用不同的次模函數，DELIFT 選取在微調的所有階段都有用的多樣化且最佳子集。在各種任務和模型規模的實驗中顯示，DELIFT 可以將微調資料大小減少多達 70%，同時不影響效能，提供顯著的計算節省，並在效率和效力方面優於現有方法。

##### **Bayesian Calibration of Win Rate Estimation with LLM Evaluators**
2411.04424v1 by Yicheng Gao, Gonghan Xu, Zhe Wang, Arman Cohan

Recent advances in large language models (LLMs) show the potential of using
LLMs as evaluators for assessing the quality of text generations from LLMs.
However, applying LLM evaluators naively to compare or judge between different
systems can lead to unreliable results due to the intrinsic win rate estimation
bias of LLM evaluators. In order to mitigate this problem, we propose two
calibration methods, Bayesian Win Rate Sampling (BWRS) and Bayesian
Dawid-Skene, both of which leverage Bayesian inference to more accurately infer
the true win rate of generative language models. We empirically validate our
methods on six datasets covering story generation, summarization, and
instruction following tasks. We show that both our methods are effective in
improving the accuracy of win rate estimation using LLMs as evaluators,
offering a promising direction for reliable automatic text quality evaluation.

摘要：大型語言模型 (LLM) 的最新進展顯示了使用 LLM 作為評估器評估 LLM 生成的文字品質的潛力。
然而，天真地套用 LLM 評估器來比較或判斷不同的系統會導致不可靠的結果，這是由於 LLM 評估器內在的勝率估計偏差。為了減輕這個問題，我們提出了兩種校準方法，貝氏勝率抽樣 (BWRS) 和貝氏 Dawid-Skene，這兩種方法都利用貝氏推論來更準確地推斷生成語言模型的真實勝率。我們在涵蓋故事生成、摘要和指令遵循任務的六個資料集上實證驗證了我們的這些方法。我們證明了我們的兩種方法都能有效地提高使用 LLM 作為評估器的勝率估計準確度，為可靠的自動文字品質評估提供了有希望的方向。

##### **Variational Low-Rank Adaptation Using IVON**
2411.04421v1 by Bai Cong, Nico Daheim, Yuesong Shen, Daniel Cremers, Rio Yokota, Mohammad Emtiyaz Khan, Thomas Möllenhoff

We show that variational learning can significantly improve the accuracy and
calibration of Low-Rank Adaptation (LoRA) without a substantial increase in the
cost. We replace AdamW by the Improved Variational Online Newton (IVON)
algorithm to finetune large language models. For Llama-2 with 7 billion
parameters, IVON improves the accuracy over AdamW by 2.8% and expected
calibration error by 4.6%. The accuracy is also better than the other Bayesian
alternatives, yet the cost is lower and the implementation is easier. Our work
provides additional evidence for the effectiveness of IVON for large language
models. The code is available at
https://github.com/team-approx-bayes/ivon-lora.

摘要：我們展示變異學習可以顯著提升低階層適應 (LoRA) 的準確度與校準，而不會大幅增加成本。我們用改良變異在線牛頓 (IVON) 演算法取代 AdamW，以微調大型語言模型。對於擁有 70 億個參數的 Llama-2，IVON 將準確度提升 2.8%，預測校準誤差則降低 4.6%。準確度也優於其他貝氏替代方案，但成本較低，且實作也較容易。我們的研究為 IVON 對大型語言模型的有效性提供了額外的證據。程式碼可在 https://github.com/team-approx-bayes/ivon-lora 取得。

##### **Towards Competitive Search Relevance For Inference-Free Learned Sparse Retrievers**
2411.04403v1 by Zhichao Geng, Dongyu Ru, Yang Yang

Learned sparse retrieval, which can efficiently perform retrieval through
mature inverted-index engines, has garnered growing attention in recent years.
Particularly, the inference-free sparse retrievers are attractive as they
eliminate online model inference in the retrieval phase thereby avoids huge
computational cost, offering reasonable throughput and latency. However, even
the state-of-the-art (SOTA) inference-free sparse models lag far behind in
terms of search relevance when compared to both sparse and dense siamese
models. Towards competitive search relevance for inference-free sparse
retrievers, we argue that they deserve dedicated training methods other than
using same ones with siamese encoders. In this paper, we propose two different
approaches for performance improvement. First, we introduce the IDF-aware FLOPS
loss, which introduces Inverted Document Frequency (IDF) to the sparsification
of representations. We find that it mitigates the negative impact of the FLOPS
regularization on search relevance, allowing the model to achieve a better
balance between accuracy and efficiency. Moreover, we propose a heterogeneous
ensemble knowledge distillation framework that combines siamese dense and
sparse retrievers to generate supervisory signals during the pre-training
phase. The ensemble framework of dense and sparse retriever capitalizes on
their strengths respectively, providing a strong upper bound for knowledge
distillation. To concur the diverse feedback from heterogeneous supervisors, we
normalize and then aggregate the outputs of the teacher models to eliminate
score scale differences. On the BEIR benchmark, our model outperforms existing
SOTA inference-free sparse model by \textbf{3.3 NDCG@10 score}. It exhibits
search relevance comparable to siamese sparse retrievers and client-side
latency only \textbf{1.1x that of BM25}.

摘要：<paragraph>近年来，能有效通过成熟的反向索引引擎执行检索的学习稀疏检索备受关注。特别是，无推理稀疏检索器极具吸引力，因为它们消除了检索阶段的在线模型推理，从而避免了巨大的计算成本，提供了合理的吞吐量和延迟。然而，即使是最先进的 (SOTA) 无推理稀疏模型在与稀疏和密集孪生模型相比时，在搜索相关性方面也远远落后。为了提高无推理稀疏检索器的竞争性搜索相关性，我们认为它们应该有专门的训练方法，而不是与孪生编码器使用相同的方法。在本文中，我们提出了两种不同的性能改进方法。首先，我们引入了感知 IDF 的 FLOPS 损失，它将逆向文档频率 (IDF) 引入表示的稀疏化。我们发现它减轻了 FLOPS 正则化对搜索相关性的负面影响，使模型能够在准确性和效率之间取得更好的平衡。此外，我们提出了一个异构集成知识蒸馏框架，该框架结合了孪生密集和稀疏检索器，以在预训练阶段生成监督信号。密集和稀疏检索器的集成框架分别利用了它们的优势，为知识蒸馏提供了强大的上限。为了对来自异构监督者的不同反馈达成共识，我们对教师模型的输出进行归一化，然后进行聚合，以消除评分尺度的差异。在 BEIR 基准测试中，我们的模型在 **3.3 NDCG@10 分数** 上优于现有的 SOTA 无推理稀疏模型。它表现出的搜索相关性与孪生稀疏检索器相当，客户端延迟仅为 **BM25 的 1.1 倍**。</paragraph>

##### **A Bayesian Mixture Model of Temporal Point Processes with Determinantal Point Process Prior**
2411.04397v1 by Yiwei Dong, Shaoxin Ye, Yuwen Cao, Qiyu Han, Hongteng Xu, Hanfang Yang

Asynchronous event sequence clustering aims to group similar event sequences
in an unsupervised manner. Mixture models of temporal point processes have been
proposed to solve this problem, but they often suffer from overfitting, leading
to excessive cluster generation with a lack of diversity. To overcome these
limitations, we propose a Bayesian mixture model of Temporal Point Processes
with Determinantal Point Process prior (TP$^2$DP$^2$) and accordingly an
efficient posterior inference algorithm based on conditional Gibbs sampling.
Our work provides a flexible learning framework for event sequence clustering,
enabling automatic identification of the potential number of clusters and
accurate grouping of sequences with similar features. It is applicable to a
wide range of parametric temporal point processes, including neural
network-based models. Experimental results on both synthetic and real-world
data suggest that our framework could produce moderately fewer yet more diverse
mixture components, and achieve outstanding results across multiple evaluation
metrics.

摘要：非同步事件序列分群旨在以非監督的方式對類似的事件序列進行分組。已經提出時間點過程的混合模型來解決這個問題，但它們經常會過度擬合，導致過度產生分群，且缺乏多樣性。為了克服這些限制，我們提出了一個具有行列式點過程先驗 (TP$^2$DP$^2$) 的時間點過程貝氏混合模型，並相應地提出了一個基於條件 Gibbs 抽樣的有效後驗推論演算法。我們的研究提供了一個用於事件序列分群的彈性學習框架，能夠自動識別分群的潛在數量，並準確地將具有類似特徵的序列分組。它適用於廣泛的參數化時間點過程，包括基於神經網路的模型。在合成資料和真實世界資料上的實驗結果表明，我們的框架可以產生數量適中但更多樣化的混合組成，並在多個評估指標中取得傑出的結果。

##### **Bridging the Gap: Representation Spaces in Neuro-Symbolic AI**
2411.04393v1 by Xin Zhang, Victor S. Sheng

Neuro-symbolic AI is an effective method for improving the overall
performance of AI models by combining the advantages of neural networks and
symbolic learning. However, there are differences between the two in terms of
how they process data, primarily because they often use different data
representation methods, which is often an important factor limiting the overall
performance of the two. From this perspective, we analyzed 191 studies from
2013 by constructing a four-level classification framework. The first level
defines five types of representation spaces, and the second level focuses on
five types of information modalities that the representation space can
represent. Then, the third level describes four symbolic logic methods.
Finally, the fourth-level categories propose three collaboration strategies
between neural networks and symbolic learning. Furthermore, we conducted a
detailed analysis of 46 research based on their representation space.

摘要：神經符號 AI 是一種有效的方法，可以結合神經網路和符號學習的優點來提升 AI 模型的整體效能。然而，兩者在處理資料的方式上存在差異，這主要是因為它們經常使用不同的資料表徵方法，而這通常是限制兩者整體效能的重要因素。從這個角度來看，我們透過建構一個四層級分類架構來分析 2013 年以來的 191 項研究。第一層定義了五種類型的表徵空間，第二層則專注於表徵空間可以表徵的五種類型資訊模式。接著，第三層描述了四種符號邏輯方法。最後，第四層類別提出了神經網路和符號學習之間的三種協作策略。此外，我們對 46 項研究根據其表徵空間進行了詳細分析。

##### **Neuro-Symbolic AI: Explainability, Challenges, and Future Trends**
2411.04383v1 by Xin Zhang, Victor S. Sheng

Explainability is an essential reason limiting the application of neural
networks in many vital fields. Although neuro-symbolic AI hopes to enhance the
overall explainability by leveraging the transparency of symbolic learning, the
results are less evident than imagined. This article proposes a classification
for explainability by considering both model design and behavior of 191 studies
from 2013, focusing on neuro-symbolic AI, hoping to inspire scholars who want
to understand the explainability of neuro-symbolic AI. Precisely, we classify
them into five categories by considering whether the form of bridging the
representation differences is readable as their design factor, if there are
representation differences between neural networks and symbolic logic learning,
and whether a model decision or prediction process is understandable as their
behavior factor: implicit intermediate representations and implicit prediction,
partially explicit intermediate representations and partially explicit
prediction, explicit intermediate representations or explicit prediction,
explicit intermediate representation and explicit prediction, unified
representation and explicit prediction. We also analyzed the research trends
and three significant challenges: unified representations, explainability and
transparency, and sufficient cooperation from neural networks and symbolic
learning. Finally, we put forward suggestions for future research in three
aspects: unified representations, enhancing model explainability, ethical
considerations, and social impact.

摘要：可解釋性是限制神經網路在許多重要領域應用的基本原因。儘管神經符號 AI 希望透過利用符號學習的透明性來增強整體可解釋性，但結果不如想像中明顯。本文提出了一個可解釋性的分類，透過考量 191 篇研究（自 2013 年）的模型設計和行為，專注於神經符號 AI，希望能啟發想要了解神經符號 AI 可解釋性的學者。具體來說，我們將它們分為五類，考量連結表示差異的形式是否可作為設計因素來閱讀，神經網路和符號邏輯學習之間是否存在表示差異，以及模型決策或預測過程是否可作為行為因素來理解：隱含中間表示和隱含預測、部分明確中間表示和部分明確預測、明確中間表示或明確預測、明確中間表示和明確預測、統一表示和明確預測。我們還分析了研究趨勢和三個重大挑戰：統一表示、可解釋性和透明性，以及來自神經網路和符號學習的充分合作。最後，我們在統一表示、增強模型可解釋性、倫理考量和社會影響三個方面提出了未來研究建議。

##### **Benchmarking Large Language Models with Integer Sequence Generation Tasks**
2411.04372v1 by Daniel O'Malley, Manish Bhattarai, Javier Santos

This paper presents a novel benchmark where the large language model (LLM)
must write code that computes integer sequences from the Online Encyclopedia of
Integer Sequences (OEIS), a widely-used resource for mathematical sequences.
The benchmark is designed to evaluate both the correctness of the generated
code and its computational efficiency. Our benchmark reveals that the o1 series
of models outperform other frontier models from OpenAI, Anthropic, Meta, and
Google in accuracy and cheating rates across both easy and hard integer
sequences. In order to ensure models do not exploit memorized sequence values,
we introduce an automated cheating detection mechanism that flags the use of
lookup tables and validated this automation against human cheating evaluations.
This benchmark provides a meaningful challenge for current LLMs, offering
insights into their mathematical reasoning and code writing capabilities, which
can guide future research directions and model development in mathematical
reasoning and code synthesis.

摘要：本文提出了一个新基準，其中大型語言模型 (LLM)
必須撰寫程式碼來計算來自整數序列線上百科全書 (OEIS) 的整數序列，這是一個廣泛用於數學序列的資源。
基準旨在評估所產生程式碼的正確性和其計算效率。我們的基準顯示，o1 系列的模型在準確度和作弊率方面優於 OpenAI、Anthropic、Meta 和 Google 等其他前沿模型，適用於簡單和困難的整數序列。為了確保模型不會利用記憶的序列值，我們引入了一個自動作弊偵測機制，標示使用查詢表，並根據人類作弊評估驗證此自動化。此基準為目前的 LLM 提供了一個有意義的挑戰，提供了對其數學推理和程式碼撰寫能力的見解，這可以引導未來的研究方向和數學推理和程式碼合成中的模型開發。

##### **ComFairGNN: Community Fair Graph Neural Network**
2411.04371v1 by Yonas Sium, Qi Li

Graph Neural Networks (GNNs) have become the leading approach for addressing
graph analytical problems in various real-world scenarios. However, GNNs may
produce biased predictions against certain demographic subgroups due to node
attributes and neighbors surrounding a node. Most current research on GNN
fairness focuses predominantly on debiasing GNNs using oversimplified fairness
evaluation metrics, which can give a misleading impression of fairness.
Understanding the potential evaluation paradoxes due to the complicated nature
of the graph structure is crucial for developing effective GNN debiasing
mechanisms. In this paper, we examine the effectiveness of current GNN
debiasing methods in terms of unfairness evaluation. Specifically, we introduce
a community-level strategy to measure bias in GNNs and evaluate debiasing
methods at this level. Further, We introduce ComFairGNN, a novel framework
designed to mitigate community-level bias in GNNs. Our approach employs a
learnable coreset-based debiasing function that addresses bias arising from
diverse local neighborhood distributions during GNNs neighborhood aggregation.
Comprehensive evaluations on three benchmark datasets demonstrate our model's
effectiveness in both accuracy and fairness metrics.

摘要：圖形神經網路 (GNN) 已成為解決各種實際場景中圖形分析問題的主要方法。然而，由於節點屬性和節點周圍的鄰居，GNN 可能會對某些人口統計子群產生有偏見的預測。目前大多數關於 GNN 公平性的研究主要集中在使用過於簡化的公平性評估指標對 GNN 進行去偏，這可能會給人造成公平性的錯誤印象。了解由於圖形結構的複雜性而導致的潛在評估悖論對於開發有效的 GNN 去偏機制至關重要。在本文中，我們檢查了當前 GNN 去偏方法在不公平評估方面的有效性。具體來說，我們引入了一個社區級策略來衡量 GNN 中的偏差，並在此級別評估去偏方法。此外，我們引入了 ComFairGNN，這是一個旨在減輕 GNN 中社區級偏差的新框架。我們的做法採用了一個可學習的基於核心的去偏函數，該函數解決了 GNN 鄰域聚合過程中來自不同局部鄰域分佈的偏差。在三個基準數據集上的綜合評估證明了我們的模型在準確性和公平性指標方面的有效性。

##### **Measuring short-form factuality in large language models**
2411.04368v1 by Jason Wei, Nguyen Karina, Hyung Won Chung, Yunxin Joy Jiao, Spencer Papay, Amelia Glaese, John Schulman, William Fedus

We present SimpleQA, a benchmark that evaluates the ability of language
models to answer short, fact-seeking questions. We prioritized two properties
in designing this eval. First, SimpleQA is challenging, as it is adversarially
collected against GPT-4 responses. Second, responses are easy to grade, because
questions are created such that there exists only a single, indisputable
answer. Each answer in SimpleQA is graded as either correct, incorrect, or not
attempted. A model with ideal behavior would get as many questions correct as
possible while not attempting the questions for which it is not confident it
knows the correct answer. SimpleQA is a simple, targeted evaluation for whether
models "know what they know," and our hope is that this benchmark will remain
relevant for the next few generations of frontier models. SimpleQA can be found
at https://github.com/openai/simple-evals.

摘要：我們提出 SimpleQA，一個評量語言模型回答簡短事實問題的能力的基準。我們在設計此評量時優先考慮兩個特性。首先，SimpleQA 具有挑戰性，因為它會針對 GPT-4 回應進行對抗收集。其次，回應很容易評分，因為問題的建立方式使得只存在一個無可爭議的答案。SimpleQA 中的每個答案都評分為正確、不正確或未嘗試。理想行為的模型會盡可能回答正確的問題，同時不嘗試它不確定自己知道正確答案的問題。SimpleQA 是針對模型「知道自己知道什麼」的簡單、有針對性的評量，我們希望此基準對於下一代前沿模型來說仍然相關。SimpleQA 可在 https://github.com/openai/simple-evals 找到。

##### **Robust and Efficient Fine-tuning of LLMs with Bayesian Reparameterization of Low-Rank Adaptation**
2411.04358v1 by Vaibhav Seth, Arinjay Pathak, Ayan Sengupta, Natraj Raman, Sriram Gopalakrishnan, Tanmoy Chakraborty

Large Language Models (LLMs) are highly resource-intensive to fine-tune due
to their enormous size. While low-rank adaptation is a prominent
parameter-efficient fine-tuning approach, it suffers from sensitivity to
hyperparameter choices, leading to instability in model performance on
fine-tuning downstream tasks. This paper highlights the importance of effective
parameterization in low-rank fine-tuning to reduce estimator variance and
enhance the stability of final model outputs. We propose MonteCLoRA, an
efficient fine-tuning technique, employing Monte Carlo estimation to learn an
unbiased posterior estimation of low-rank parameters with low expected
variance, which stabilizes fine-tuned LLMs with only O(1) additional
parameters. MonteCLoRA shows significant improvements in accuracy and
robustness, achieving up to 3.8% higher accuracy and 8.6% greater robustness
than existing efficient fine-tuning methods on natural language understanding
tasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with
pre-trained LLaMA-1-7B, MonteCLoRA demonstrates robust zero-shot performance
with 50% lower variance than the contemporary efficient fine-tuning methods.
The theoretical and empirical results presented in the paper underscore how
parameterization and hyperpriors balance exploration-exploitation in the
low-rank parametric space, therefore leading to more optimal and robust
parameter estimation during efficient fine-tuning.

摘要：大型語言模型 (LLM) 因其龐大規模而需要大量資源進行微調。儘管低秩適應是一種突出的參數高效微調方法，但它對超參數選擇很敏感，導致模型在微調下游任務時的效能不穩定。本文強調了在低秩微調中有效參數化的重要性，以減少估計器變異並增強最終模型輸出的穩定性。我們提出了 MonteCLoRA，一種高效的微調技術，採用蒙地卡羅估計來學習低秩參數的無偏後驗估計，且預期變異低，這可以穩定微調後的 LLM，而額外參數僅為 O(1)。MonteCLoRA 在準確性和穩健性方面顯示出顯著的改進，在使用預訓練 RoBERTa-base 的自然語言理解任務中，準確度提高了 3.8%，穩健性提高了 8.6%。此外，在使用預訓練 LLaMA-1-7B 的生成任務中，MonteCLoRA 表現出穩健的零次學習效能，變異比現有的高效微調方法低 50%。本文提出的理論和實證結果強調了參數化和超先驗如何在低秩參數空間中平衡探索與開發，從而導致在高效微調期間進行更佳且穩健的參數估計。

##### **Model and Deep learning based Dynamic Range Compression Inversion**
2411.04337v1 by Haoran Sun, Dominique Fourer, Hichem Maaref

Dynamic Range Compression (DRC) is a popular audio effect used to control the
dynamic range of a signal. Inverting DRC can also help to restore the original
dynamics to produce new mixes and/or to improve the overall quality of the
audio signal. Since, state-of-the-art DRC inversion techniques either ignore
parameters or require precise parameters that are difficult to estimate, we
fill the gap by combining a model-based approach with neural networks for DRC
inversion. To this end, depending on the scenario, we use different neural
networks to estimate DRC parameters. Then, a model-based inversion is completed
to restore the original audio signal. Our experimental results show the
effectiveness and robustness of the proposed method in comparison to several
state-of-the-art methods, when applied on two music datasets.

摘要：動態範圍壓縮 (DRC) 是一種流行的音訊效果，用於控制訊號的動態範圍。反轉 DRC 也可以幫助恢復原始動態，以產生新的混音和/或改善音訊訊號的整體品質。由於最先進的 DRC 反轉技術會忽略參數或需要難以估計的精確參數，因此我們透過結合基於模型的方法與神經網路來填補這個缺口，以進行 DRC 反轉。為此，我們根據場景使用不同的神經網路來估計 DRC 參數。然後，完成基於模型的反轉以恢復原始音訊訊號。我們的實驗結果顯示，與在兩個音樂資料集上應用時，所提出的方法與幾種最先進的方法相比，具有有效性和穩健性。

##### **Scaling Laws for Precision**
2411.04330v1 by Tanishq Kumar, Zachary Ankner, Benjamin F. Spector, Blake Bordelon, Niklas Muennighoff, Mansheej Paul, Cengiz Pehlevan, Christopher Ré, Aditi Raghunathan

Low precision training and inference affect both the quality and cost of
language models, but current scaling laws do not account for this. In this
work, we devise "precision-aware" scaling laws for both training and inference.
We propose that training in lower precision reduces the model's "effective
parameter count," allowing us to predict the additional loss incurred from
training in low precision and post-train quantization. For inference, we find
that the degradation introduced by post-training quantization increases as
models are trained on more data, eventually making additional pretraining data
actively harmful. For training, our scaling laws allow us to predict the loss
of a model with different parts in different precisions, and suggest that
training larger models in lower precision may be compute optimal. We unify the
scaling laws for post and pretraining quantization to arrive at a single
functional form that predicts degradation from training and inference in varied
precisions. We fit on over 465 pretraining runs and validate our predictions on
model sizes up to 1.7B parameters trained on up to 26B tokens.

摘要：低精度训练和推理影响语言模型的质量和成本，但当前的缩放定律并未考虑这一点。在这项工作中，我们为训练和推理设计了“精度感知”缩放定律。我们提出低精度训练会减少模型的“有效参数计数”，让我们能够预测低精度训练和训练后量化带来的额外损失。对于推理，我们发现训练后量化引入的退化随着模型在更多数据上进行训练而增加，最终使额外的预训练数据变得有害。对于训练，我们的缩放定律让我们能够预测具有不同精度不同部分的模型的损失，并表明以较低精度训练较大的模型可能是计算最优的。我们统一训练后和预训练量化的缩放定律，得到一个单一的函数形式，该形式预测了在不同精度下训练和推理的退化。我们对超过 465 次预训练运行进行了拟合，并对在多达 26B 个标记上训练的多达 1.7B 个参数的模型大小进行了预测验证。

##### **CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models**
2411.04329v1 by Jierui Li, Hung Le, Yinbo Zhou, Caiming Xiong, Silvio Savarese, Doyen Sahoo

Pre-trained on massive amounts of code and text data, large language models
(LLMs) have demonstrated remarkable achievements in performing code generation
tasks. With additional execution-based feedback, these models can act as agents
with capabilities to self-refine and improve generated code autonomously.
However, on challenging coding tasks with extremely large search space, current
agentic approaches still struggle with multi-stage planning, generating, and
debugging. To address this problem, we propose CodeTree, a framework for LLM
agents to efficiently explore the search space in different stages of the code
generation process. Specifically, we adopted a unified tree structure to
explicitly explore different coding strategies, generate corresponding coding
solutions, and subsequently refine the solutions. In each stage, critical
decision-making (ranking, termination, expanding) of the exploration process is
guided by both the environmental execution-based feedback and
LLM-agent-generated feedback. We comprehensively evaluated CodeTree on 7 code
generation benchmarks and demonstrated the significant performance gains of
CodeTree against strong baselines. Using GPT-4o as the base model, we
consistently achieved top results of 95.1 on HumanEval, 98.7 on MBPP, and 43.0
on CodeContests. On the challenging SWEBench benchmark, our approach led to
significant performance gains.

摘要：透過大量程式碼和文字資料進行預先訓練，大型語言模型 (LLM) 在執行程式碼產生任務方面展現出卓越的成就。透過額外的執行回饋，這些模型可用作具備自我修正和自主改善產生程式碼能力的代理人。然而，在搜尋空間極大的具挑戰性編碼任務中，目前的代理方法仍難以應付多階段規劃、產生和除錯。為了解決這個問題，我們提出了 CodeTree，一個 LLM 代理架構，可在程式碼產生程序的不同階段有效探索搜尋空間。具體來說，我們採用統一的樹狀結構來明確探索不同的編碼策略、產生對應的編碼解決方案，並隨後修正這些解決方案。在每個階段，探索程序的關鍵決策制定（排序、終止、擴充）都受到環境執行回饋和 LLM 代理產生回饋的指導。我們在 7 個程式碼產生基準上全面評估了 CodeTree，並證明了 CodeTree 相較於強大的基準表現出顯著的效能提升。使用 GPT-4o 作為基礎模型，我們在 HumanEval 上持續獲得 95.1 的頂尖結果、在 MBPP 上獲得 98.7，以及在 CodeContests 上獲得 43.0。在具挑戰性的 SWEBench 基準上，我們的做法帶來了顯著的效能提升。

##### **Balancing Transparency and Accuracy: A Comparative Analysis of Rule-Based and Deep Learning Models in Political Bias Classification**
2411.04328v1 by Manuel Nunez Martinez, Sonja Schmer-Galunder, Zoey Liu, Sangpil Youm, Chathuri Jayaweera, Bonnie J. Dorr

The unchecked spread of digital information, combined with increasing
political polarization and the tendency of individuals to isolate themselves
from opposing political viewpoints, has driven researchers to develop systems
for automatically detecting political bias in media. This trend has been
further fueled by discussions on social media. We explore methods for
categorizing bias in US news articles, comparing rule-based and deep learning
approaches. The study highlights the sensitivity of modern self-learning
systems to unconstrained data ingestion, while reconsidering the strengths of
traditional rule-based systems. Applying both models to left-leaning (CNN) and
right-leaning (FOX) news articles, we assess their effectiveness on data beyond
the original training and test sets.This analysis highlights each model's
accuracy, offers a framework for exploring deep-learning explainability, and
sheds light on political bias in US news media. We contrast the opaque
architecture of a deep learning model with the transparency of a linguistically
informed rule-based model, showing that the rule-based model performs
consistently across different data conditions and offers greater transparency,
whereas the deep learning model is dependent on the training set and struggles
with unseen data.

摘要：數位資訊的散布未受控管，加上政治兩極分化日益嚴重，以及個人傾向於孤立自己，避免接觸對立的政治觀點，促使研究人員開發系統，以自動偵測媒體中的政治偏見。社群媒體上的討論進一步助長了這股趨勢。我們探討了分類美國新聞文章偏見的方法，並比較了基於規則和深度學習的方法。這項研究強調了現代自學系統對不受約束的資料輸入的敏感性，同時重新考慮了傳統基於規則系統的優點。將這兩種模型應用於左傾（CNN）和右傾（FOX）新聞文章，我們評估了它們在原始訓練和測試集之外資料上的有效性。此分析重點說明了每個模型的準確性，提供了一個探索深度學習可解釋性的框架，並闡明了美國新聞媒體中的政治偏見。我們將深度學習模型的不透明架構與基於語言的基於規則模型的透明度進行對比，顯示基於規則的模型在不同的資料條件下表現一致，並提供更高的透明度，而深度學習模型則依賴於訓練集，並且難以處理未見過的資料。

##### **Gradient Boosting Trees and Large Language Models for Tabular Data Few-Shot Learning**
2411.04324v1 by Carlos Huertas

Large Language Models (LLM) have brought numerous of new applications to
Machine Learning (ML). In the context of tabular data (TD), recent studies show
that TabLLM is a very powerful mechanism for few-shot-learning (FSL)
applications, even if gradient boosting decisions trees (GBDT) have
historically dominated the TD field. In this work we demonstrate that although
LLMs are a viable alternative, the evidence suggests that baselines used to
gauge performance can be improved. We replicated public benchmarks and our
methodology improves LightGBM by 290%, this is mainly driven by forcing node
splitting with few samples, a critical step in FSL with GBDT. Our results show
an advantage to TabLLM for 8 or fewer shots, but as the number of samples
increases GBDT provides competitive performance at a fraction of runtime. For
other real-life applications with vast number of samples, we found FSL still
useful to improve model diversity, and when combined with ExtraTrees it
provides strong resilience to overfitting, our proposal was validated in a ML
competition setting ranking first place.

摘要：大型語言模型 (LLM) 為機器學習 (ML) 帶來了許多新的應用。在表格資料 (TD) 的背景下，最近的研究顯示 TabLLM 是一種非常強大的機制，可用於少量樣本學習 (FSL) 應用，即使梯度提升決策樹 (GBDT) 在歷史上一直主導 TD 領域。在這項工作中，我們證明了儘管 LLM 是一個可行的替代方案，但證據表明用於衡量效能的基準線可以得到改進。我們複製了公開基準，我們的技術方法將 LightGBM 提升了 290%，這主要是透過強制使用少量樣本進行節點分割，這是 FSL 中使用 GBDT 的關鍵步驟。我們的結果顯示 TabLLM 在 8 個或更少的樣本中具有優勢，但隨著樣本數量的增加，GBDT 在一小部分執行時間內提供了有競爭力的效能。對於其他具有大量樣本的實際應用，我們發現 FSL 仍然有助於提高模型多樣性，並且與 ExtraTrees 結合使用時，它提供了強大的過擬合復原力，我們的提案在機器學習競賽中獲得第一名，得到驗證。

##### **A Multilingual Sentiment Lexicon for Low-Resource Language Translation using Large Languages Models and Explainable AI**
2411.04316v1 by Melusi Malinga, Isaac Lupanda, Mike Wa Nkongolo, Phil van Deventer

South Africa and the Democratic Republic of Congo (DRC) present a complex
linguistic landscape with languages such as Zulu, Sepedi, Afrikaans, French,
English, and Tshiluba (Ciluba), which creates unique challenges for AI-driven
translation and sentiment analysis systems due to a lack of accurately labeled
data. This study seeks to address these challenges by developing a multilingual
lexicon designed for French and Tshiluba, now expanded to include translations
in English, Afrikaans, Sepedi, and Zulu. The lexicon enhances cultural
relevance in sentiment classification by integrating language-specific
sentiment scores. A comprehensive testing corpus is created to support
translation and sentiment analysis tasks, with machine learning models such as
Random Forest, Support Vector Machine (SVM), Decision Trees, and Gaussian Naive
Bayes (GNB) trained to predict sentiment across low resource languages (LRLs).
Among them, the Random Forest model performed particularly well, capturing
sentiment polarity and handling language-specific nuances effectively.
Furthermore, Bidirectional Encoder Representations from Transformers (BERT), a
Large Language Model (LLM), is applied to predict context-based sentiment with
high accuracy, achieving 99% accuracy and 98% precision, outperforming other
models. The BERT predictions were clarified using Explainable AI (XAI),
improving transparency and fostering confidence in sentiment classification.
Overall, findings demonstrate that the proposed lexicon and machine learning
models significantly enhance translation and sentiment analysis for LRLs in
South Africa and the DRC, laying a foundation for future AI models that support
underrepresented languages, with applications across education, governance, and
business in multilingual contexts.

摘要：南非和剛果民主共和國 (DRC) 呈現出複雜的語言環境，其中包含祖魯語、北索托語、南非荷蘭語、法語、英語和奇盧巴語 (奇盧巴語)，由於缺乏準確標記的資料，這對 AI 驅動的翻譯和情緒分析系統造成了獨特的挑戰。本研究旨在通過開發一種專為法語和奇盧巴語設計的多語言詞彙表來應對這些挑戰，現在已擴展到包括英語、南非荷蘭語、北索托語和祖魯語的翻譯。該詞彙表通過整合特定語言的情緒分數來增強情緒分類中的文化相關性。建立了一個全面的測試語料庫來支持翻譯和情緒分析任務，並訓練了隨機森林、支持向量機 (SVM)、決策樹和高斯樸素貝葉斯 (GNB) 等機器學習模型來預測低資源語言 (LRL) 的情緒。其中，隨機森林模型表現特別出色，有效捕捉情緒極性和處理特定語言的細微差別。此外，來自 Transformer 的雙向編碼器表示 (BERT)，一種大型語言模型 (LLM)，被用於預測基於上下文的語意，具有很高的準確度，達到 99% 的準確度和 98% 的精確度，優於其他模型。BERT 預測使用可解釋 AI (XAI) 進行澄清，提高透明度並增強對情緒分類的信心。總體而言，研究結果表明，所提出的詞彙表和機器學習模型顯著增強了南非和剛果民主共和國的 LRL 的翻譯和情緒分析，為未來支持代表性不足的語言的 AI 模型奠定了基礎，並在多語言環境中的教育、治理和商業中應用。

##### **Improving Bilingual Capabilities of Language Models to Support Diverse Linguistic Practices in Education**
2411.04308v1 by Anand Syamkumar, Nora Tseng, Kaycie Barron, Shanglin Yang, Shamya Karumbaiah, Rheeya Uppal, Junjie Hu

Large language models (LLMs) offer promise in generating educational content,
providing instructor feedback, and reducing teacher workload on assessments.
While prior studies have focused on studying LLM-powered learning analytics,
limited research has examined how effective LLMs are in a bilingual context. In
this paper, we study the effectiveness of multilingual large language models
(MLLMs) across monolingual (English-only, Spanish-only) and bilingual
(Spanglish) student writing. We present a learning analytics use case that
details LLM performance in assessing acceptable and unacceptable explanations
of Science and Social Science concepts. Our findings reveal a significant bias
in the grading performance of pre-trained models for bilingual writing compared
to English-only and Spanish-only writing. Following this, we fine-tune
open-source MLLMs including Llama 3.1 and Mistral NeMo using synthetic datasets
generated in English, Spanish, and Spanglish. Our experiments indicate that the
models perform significantly better for all three languages after fine-tuning
with bilingual data. This study highlights the potential of enhancing MLLM
effectiveness to support authentic language practices amongst bilingual
learners. It also aims to illustrate the value of incorporating non-English
languages into the design and implementation of language models in education.

摘要：大型語言模型 (LLM) 在產生教育內容、提供教師回饋和減少教師評量工作負擔方面很有前景。雖然先前的研究專注於研究由 LLM 驅動的學習分析，但有限的研究探討了 LLM 在雙語環境中的有效性。在本文中，我們研究了多語言大型語言模型 (MLLM) 在單語 (僅英語、僅西班牙語) 和雙語 (Spanglish) 學生寫作中的有效性。我們提出了學習分析使用案例，詳細說明了 LLM 在評估科學和社會科學概念的可接受和不可接受的解釋方面的表現。我們的研究結果揭示了與僅英語和僅西班牙語寫作相比，預訓練模型對雙語寫作的評分表現存在顯著偏差。在此之後，我們使用英語、西班牙語和 Spanglish 生成的合成資料集微調了包括 Llama 3.1 和 Mistral NeMo 在內的開源 MLLM。我們的實驗表明，在使用雙語資料進行微調後，這些模型在所有三種語言中的表現都顯著提升。這項研究強調了增強 MLLM 的有效性以支持雙語學習者的真實語言實踐的潛力。它還旨在說明將非英語語言納入教育中語言模型的設計和實施的價值。

##### **A Capabilities Approach to Studying Bias and Harm in Language Technologies**
2411.04298v1 by Hellina Hailu Nigatu, Zeerak Talat

Mainstream Natural Language Processing (NLP) research has ignored the
majority of the world's languages. In moving from excluding the majority of the
world's languages to blindly adopting what we make for English, we first risk
importing the same harms we have at best mitigated and at least measured for
English. However, in evaluating and mitigating harms arising from adopting new
technologies into such contexts, we often disregard (1) the actual community
needs of Language Technologies, and (2) biases and fairness issues within the
context of the communities. In this extended abstract, we consider fairness,
bias, and inclusion in Language Technologies through the lens of the
Capabilities Approach. The Capabilities Approach centers on what people are
capable of achieving, given their intersectional social, political, and
economic contexts instead of what resources are (theoretically) available to
them. We detail the Capabilities Approach, its relationship to multilingual and
multicultural evaluation, and how the framework affords meaningful
collaboration with community members in defining and measuring the harms of
Language Technologies.

摘要：主流自然語言處理 (NLP) 研究忽略了世界上大部分語言。在從排除世界上大部分語言轉變為盲目採用我們為英語製作的內容時，我們首先冒著輸入我們在英語中至多減輕、至少衡量的相同危害的風險。然而，在評估和減輕因在這些環境中採用新技術而產生的危害時，我們常常忽視 (1) 語言技術的實際社區需求，以及 (2) 社區環境中的偏見和公平性問題。在此延伸摘要中，我們透過能力方法的觀點來考量語言技術中的公平性、偏見和包容性。能力方法著重於人們在交織的社會、政治和經濟背景下能夠達成什麼，而不是他們（理論上）可以獲得什麼資源。我們詳細說明能力方法、它與多語言和多文化評估的關係，以及該框架如何讓社區成員在定義和衡量語言技術的危害時進行有意義的協作。

