{"2412.02467": {"publish_time": "2024-12-03", "title": "DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators", "paper_summary": "Generating tabular data under differential privacy (DP) protection ensures\ntheoretical privacy guarantees but poses challenges for training machine\nlearning models, primarily due to the need to capture complex structures under\nnoisy supervision signals. Recently, pre-trained Large Language Models (LLMs)\n-- even those at the scale of GPT-2 -- have demonstrated great potential in\nsynthesizing tabular data. However, their applications under DP constraints\nremain largely unexplored. In this work, we address this gap by applying DP\ntechniques to the generation of synthetic tabular data. Our findings shows that\nLLMs face difficulties in generating coherent text when fine-tuned with DP, as\nprivacy budgets are inefficiently allocated to non-private elements like table\nstructures. To overcome this, we propose \\ours, a two-stage fine-tuning\nframework for differentially private tabular data generation. The first stage\ninvolves non-private fine-tuning on a pseudo dataset, followed by DP\nfine-tuning on a private dataset. Our empirical results show that this approach\nimproves performance across various settings and metrics compared to directly\nfine-tuned LLMs in DP contexts. We release our code and setup at\nhttps://github.com/tejuafonja/DP-2Stage.", "paper_summary_zh": "\u5728\u5dee\u5206\u9690\u79c1 (DP) \u4fdd\u62a4\u4e0b\u751f\u6210\u8868\u683c\u6570\u636e\u53ef\u786e\u4fdd\u7406\u8bba\u9690\u79c1\u4fdd\u8bc1\uff0c\u4f46\u5bf9\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6784\u6210\u4e86\u6311\u6218\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u9700\u8981\u5728\u6709\u566a\u58f0\u7684\u76d1\u7763\u4fe1\u53f7\u4e0b\u6355\u83b7\u590d\u6742\u7ed3\u6784\u3002\u6700\u8fd1\uff0c\u9884\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b (LLM)\u2014\u2014\u5373\u4f7f\u662f GPT-2 \u89c4\u6a21\u7684\u6a21\u578b\u2014\u2014\u5df2\u5728\u5408\u6210\u8868\u683c\u6570\u636e\u65b9\u9762\u5c55\u793a\u51fa\u5de8\u5927\u6f5c\u529b\u3002\u7136\u800c\uff0c\u5b83\u4eec\u5728 DP \u7ea6\u675f\u4e0b\u7684\u5e94\u7528\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4ecd\u672a\u5f97\u5230\u63a2\u7d22\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u5c06 DP \u6280\u672f\u5e94\u7528\u4e8e\u5408\u6210\u8868\u683c\u6570\u636e\u7684\u751f\u6210\u6765\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u4f7f\u7528 DP \u5fae\u8c03\u65f6\uff0cLLM \u5728\u751f\u6210\u8fde\u8d2f\u6587\u672c\u65b9\u9762\u9762\u4e34\u56f0\u96be\uff0c\u56e0\u4e3a\u9690\u79c1\u9884\u7b97\u88ab\u4f4e\u6548\u5730\u5206\u914d\u7ed9\u8868\u683c\u7ed3\u6784\u7b49\u975e\u79c1\u6709\u5143\u7d20\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 \\ours\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u5dee\u5206\u9690\u79c1\u8868\u683c\u6570\u636e\u751f\u6210\u7684\u4e8c\u9636\u6bb5\u5fae\u8c03\u6846\u67b6\u3002\u7b2c\u4e00\u9636\u6bb5\u6d89\u53ca\u5728\u4f2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u975e\u79c1\u6709\u5fae\u8c03\uff0c\u7136\u540e\u5728\u79c1\u6709\u6570\u636e\u96c6\u4e0a\u8fdb\u884c DP \u5fae\u8c03\u3002\u6211\u4eec\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u5728 DP \u73af\u5883\u4e2d\u76f4\u63a5\u5fae\u8c03\u7684 LLM \u76f8\u6bd4\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u5404\u79cd\u8bbe\u7f6e\u548c\u6307\u6807\u4e0a\u90fd\u63d0\u9ad8\u4e86\u6027\u80fd\u3002\u6211\u4eec\u5728 https://github.com/tejuafonja/DP-2Stage \u4e0a\u53d1\u5e03\u4e86\u6211\u4eec\u7684\u4ee3\u7801\u548c\u8bbe\u7f6e\u3002", "author": "Tejumade Afonja et.al.", "authors": "Tejumade Afonja, Hui-Po Wang, Raouf Kerkouche, Mario Fritz", "id": "2412.02467v1", "paper_url": "http://arxiv.org/abs/2412.02467v1", "repo": "null"}}