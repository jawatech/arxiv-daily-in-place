{"2411.01751": {"publish_time": "2024-11-04", "title": "RAGViz: Diagnose and Visualize Retrieval-Augmented Generation", "paper_summary": "Retrieval-augmented generation (RAG) combines knowledge from domain-specific\nsources into large language models to ground answer generation. Current RAG\nsystems lack customizable visibility on the context documents and the model's\nattentiveness towards such documents. We propose RAGViz, a RAG diagnosis tool\nthat visualizes the attentiveness of the generated tokens in retrieved\ndocuments. With a built-in user interface, retrieval index, and Large Language\nModel (LLM) backbone, RAGViz provides two main functionalities: (1) token and\ndocument-level attention visualization, and (2) generation comparison upon\ncontext document addition and removal. As an open-source toolkit, RAGViz can be\neasily hosted with a custom embedding model and HuggingFace-supported LLM\nbackbone. Using a hybrid ANN (Approximate Nearest Neighbor) index,\nmemory-efficient LLM inference tool, and custom context snippet method, RAGViz\noperates efficiently with a median query time of about 5 seconds on a moderate\nGPU node. Our code is available at https://github.com/cxcscmu/RAGViz. A demo\nvideo of RAGViz can be found at https://youtu.be/cTAbuTu6ur4.", "paper_summary_zh": "\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u5c07\u4f86\u81ea\u7279\u5b9a\u9818\u57df\u4f86\u6e90\u7684\u77e5\u8b58\u7d50\u5408\u5230\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4e2d\uff0c\u4ee5\u5efa\u7acb\u7b54\u6848\u751f\u6210\u3002\u76ee\u524d\u7684 RAG \u7cfb\u7d71\u7f3a\u4e4f\u5c0d\u8108\u7d61\u6587\u4ef6\u548c\u6a21\u578b\u5c0d\u6b64\u985e\u6587\u4ef6\u7684\u95dc\u6ce8\u5ea6\u7684\u53ef\u81ea\u8a02\u53ef\u8996\u5316\u3002\u6211\u5011\u63d0\u51fa RAGViz\uff0c\u9019\u662f\u4e00\u500b RAG \u8a3a\u65b7\u5de5\u5177\uff0c\u7528\u65bc\u8996\u89ba\u5316\u6aa2\u7d22\u6587\u4ef6\u4e2d\u751f\u6210\u4ee3\u78bc\u7684\u95dc\u6ce8\u5ea6\u3002RAGViz \u6709\u4e00\u500b\u5167\u5efa\u4f7f\u7528\u8005\u4ecb\u9762\u3001\u6aa2\u7d22\u7d22\u5f15\u548c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e3b\u5e79\uff0c\u63d0\u4f9b\u5169\u500b\u4e3b\u8981\u529f\u80fd\uff1a(1) \u4ee3\u78bc\u548c\u6587\u4ef6\u5c64\u7d1a\u7684\u95dc\u6ce8\u5ea6\u8996\u89ba\u5316\uff0c\u4ee5\u53ca (2) \u5728\u52a0\u5165\u548c\u79fb\u9664\u8108\u7d61\u6587\u4ef6\u5f8c\u9032\u884c\u751f\u6210\u6bd4\u8f03\u3002\u4f5c\u70ba\u4e00\u500b\u958b\u6e90\u5de5\u5177\u5305\uff0cRAGViz \u53ef\u4ee5\u8f15\u9b06\u5730\u4f7f\u7528\u81ea\u8a02\u5d4c\u5165\u6a21\u578b\u548c HuggingFace \u652f\u63f4\u7684 LLM \u4e3b\u5e79\u9032\u884c\u4e3b\u6a5f\u3002\u900f\u904e\u4f7f\u7528\u6df7\u5408 ANN (\u8fd1\u4f3c\u6700\u8fd1\u9130) \u7d22\u5f15\u3001\u8a18\u61b6\u9ad4\u6548\u7387\u826f\u597d\u7684 LLM \u63a8\u8ad6\u5de5\u5177\u548c\u81ea\u8a02\u8108\u7d61\u7247\u6bb5\u65b9\u6cd5\uff0cRAGViz \u5728\u4e2d\u7b49 GPU \u7bc0\u9ede\u4e0a\u4ee5\u7d04 5 \u79d2\u7684\u4e2d\u4f4d\u6578\u67e5\u8a62\u6642\u9593\u6709\u6548\u7387\u5730\u904b\u4f5c\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/cxcscmu/RAGViz \u53d6\u5f97\u3002RAGViz \u7684\u793a\u7bc4\u5f71\u7247\u53ef\u5728 https://youtu.be/cTAbuTu6ur4 \u627e\u5230\u3002", "author": "Tevin Wang et.al.", "authors": "Tevin Wang, Jingyuan He, Chenyan Xiong", "id": "2411.01751v1", "paper_url": "http://arxiv.org/abs/2411.01751v1", "repo": "https://github.com/cxcscmu/ragviz"}}