{"2211.14736": {"publish_time": "2022-11-27", "title": "Attribution-based XAI Methods in Computer Vision: A Review", "paper_summary": "The advancements in deep learning-based methods for visual perception tasks\nhave seen astounding growth in the last decade, with widespread adoption in a\nplethora of application areas from autonomous driving to clinical decision\nsupport systems. Despite their impressive performance, these deep\nlearning-based models remain fairly opaque in their decision-making process,\nmaking their deployment in human-critical tasks a risky endeavor. This in turn\nmakes understanding the decisions made by these models crucial for their\nreliable deployment. Explainable AI (XAI) methods attempt to address this by\noffering explanations for such black-box deep learning methods. In this paper,\nwe provide a comprehensive survey of attribution-based XAI methods in computer\nvision and review the existing literature for gradient-based,\nperturbation-based, and contrastive methods for XAI, and provide insights on\nthe key challenges in developing and evaluating robust XAI methods.", "paper_summary_zh": "", "author": "Kumar Abhishek et.al.", "authors": "Kumar Abhishek,Deeksha Kamath", "id": "2211.14736v1", "paper_url": "http://arxiv.org/abs/2211.14736v1", "repo": "null"}}