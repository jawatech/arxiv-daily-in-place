{"2502.02362": {"publish_time": "2025-02-04", "title": "Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs", "paper_summary": "Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large\nlanguage models (LLMs) by enabling detailed step-by-step solutions. However,\ndue to the verbosity of LLMs, the resulting reasoning chains can be long,\nmaking it harder to verify the reasoning steps and trace issues resulting from\ndependencies between the steps that may be farther away in the sequence of\nsteps. Importantly, mathematical reasoning allows each step to be derived from\na small set of premises, which are a subset of the preceding steps in the\nreasoning chain. In this paper, we present a framework that identifies the\npremises for each step, to improve the evaluation of reasoning. We restructure\nconventional linear reasoning chains into Premise Augmented Reasoning Chains\n(PARC) by introducing premise links, resulting in a directed acyclic graph\nwhere the nodes are the steps and the edges are the premise links. Through\nexperiments with a PARC-based dataset that we built, namely PERL (Premises and\nERrors identification in LLMs), we demonstrate that LLMs can reliably identify\npremises within complex reasoning chains. In particular, even open-source LLMs\nachieve 90% recall in premise identification. We also show that PARC helps to\nidentify errors in reasoning chains more reliably. The accuracy of error\nidentification improves by 6% to 16% absolute when step-by-step verification is\ncarried out in PARC under the premises. Our findings highlight the utility of\npremise-centric representations in addressing complex problem-solving tasks and\nopen new avenues for improving the reliability of LLM-based reasoning\nevaluations.", "paper_summary_zh": "<paragraph>\u601d\u8003\u93c8\uff08CoT\uff09\u63d0\u793a\u900f\u904e\u63d0\u4f9b\u8a73\u7d30\u7684\u9010\u6b65\u89e3\u6cd5\uff0c\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u3002\u7136\u800c\uff0c\u7531\u65bc LLM \u7684\u5197\u9577\uff0c\u7522\u751f\u7684\u63a8\u7406\u93c8\u53ef\u80fd\u5f88\u9577\uff0c\u9019\u4f7f\u5f97\u9a57\u8b49\u63a8\u7406\u6b65\u9a5f\u548c\u8ffd\u8e64\u7531\u6b65\u9a5f\u4e4b\u9593\u76f8\u4f9d\u95dc\u4fc2\u6240\u7522\u751f\u7684\u554f\u984c\u8b8a\u5f97\u66f4\u52a0\u56f0\u96e3\uff0c\u800c\u9019\u4e9b\u6b65\u9a5f\u53ef\u80fd\u5728\u6b65\u9a5f\u9806\u5e8f\u4e2d\u76f8\u8ddd\u8f03\u9060\u3002\u91cd\u8981\u7684\u662f\uff0c\u6578\u5b78\u63a8\u7406\u5141\u8a31\u6bcf\u500b\u6b65\u9a5f\u5f9e\u4e00\u7d44\u5c0f\u7684\u524d\u63d0\u4e2d\u63a8\u5c0e\u51fa\u4f86\uff0c\u9019\u4e9b\u524d\u63d0\u662f\u63a8\u7406\u93c8\u4e2d\u524d\u4e00\u500b\u6b65\u9a5f\u7684\u5b50\u96c6\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u6846\u67b6\uff0c\u7528\u65bc\u8b58\u5225\u6bcf\u500b\u6b65\u9a5f\u7684\u524d\u63d0\uff0c\u4ee5\u6539\u9032\u63a8\u7406\u8a55\u4f30\u3002\u6211\u5011\u900f\u904e\u5f15\u5165\u524d\u63d0\u9023\u7d50\uff0c\u5c07\u50b3\u7d71\u7684\u7dda\u6027\u63a8\u7406\u93c8\u91cd\u7d44\u70ba\u524d\u63d0\u64f4\u5145\u63a8\u7406\u93c8\uff08PARC\uff09\uff0c\u7522\u751f\u4e00\u500b\u6709\u5411\u7121\u74b0\u5716\uff0c\u5176\u4e2d\u7bc0\u9ede\u662f\u6b65\u9a5f\uff0c\u800c\u908a\u7de3\u662f\u524d\u63d0\u9023\u7d50\u3002\u900f\u904e\u6211\u5011\u5efa\u7acb\u7684\u57fa\u65bc PARC \u7684\u8cc7\u6599\u96c6\uff08\u5373 PERL\uff08LLM \u4e2d\u7684\u524d\u63d0\u548c\u932f\u8aa4\u8b58\u5225\uff09\uff09\u9032\u884c\u7684\u5be6\u9a57\uff0c\u6211\u5011\u8b49\u660e LLM \u80fd\u5920\u5728\u8907\u96dc\u7684\u63a8\u7406\u93c8\u4e2d\u53ef\u9760\u5730\u8b58\u5225\u524d\u63d0\u3002\u7279\u5225\u662f\uff0c\u5373\u4f7f\u662f\u958b\u6e90 LLM \u5728\u524d\u63d0\u8b58\u5225\u4e2d\u4e5f\u80fd\u9054\u5230 90% \u7684\u53ec\u56de\u7387\u3002\u6211\u5011\u9084\u8868\u660e\uff0cPARC \u6709\u52a9\u65bc\u66f4\u53ef\u9760\u5730\u8b58\u5225\u63a8\u7406\u93c8\u4e2d\u7684\u932f\u8aa4\u3002\u5728\u524d\u63d0\u4e0b\u65bc PARC \u4e2d\u57f7\u884c\u9010\u6b65\u9a57\u8b49\u6642\uff0c\u932f\u8aa4\u8b58\u5225\u7684\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 6% \u5230 16%\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u7a81\u986f\u4e86\u4ee5\u524d\u63d0\u70ba\u4e2d\u5fc3\u7684\u8868\u793a\u5728\u89e3\u6c7a\u8907\u96dc\u554f\u984c\u89e3\u6c7a\u4efb\u52d9\u4e2d\u7684\u6548\u7528\uff0c\u4e26\u70ba\u6539\u9032\u57fa\u65bc LLM \u7684\u63a8\u7406\u8a55\u4f30\u7684\u53ef\u9760\u6027\u958b\u95e2\u4e86\u65b0\u9014\u5f91\u3002</paragraph>", "author": "Sagnik Mukherjee et.al.", "authors": "Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani-T\u00fcr", "id": "2502.02362v3", "paper_url": "http://arxiv.org/abs/2502.02362v3", "repo": "null"}}