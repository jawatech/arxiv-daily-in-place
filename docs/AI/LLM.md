
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313v1](http://arxiv.org/abs/2408.08313v1)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310v1](http://arxiv.org/abs/2408.08310v1)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302v1](http://arxiv.org/abs/2408.08302v1)|null|
|**2024-08-15**|**SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training**|Gengwei Zhang et.al.|[2408.08295v1](http://arxiv.org/abs/2408.08295v1)|[link](https://github.com/gengdavid/slca)|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291v1](http://arxiv.org/abs/2408.08291v1)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282v1](http://arxiv.org/abs/2408.08282v1)|null|
|**2024-08-15**|**InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**|Guoxiang Grayson Tong et.al.|[2408.08264v1](http://arxiv.org/abs/2408.08264v1)|[link](https://github.com/desreslab/invaert4cardio)|
|**2024-08-15**|**mhGPT: A Lightweight Generative Pre-Trained Transformer for Mental Health Text Analysis**|Dae-young Kim et.al.|[2408.08261v1](http://arxiv.org/abs/2408.08261v1)|null|
|**2024-08-15**|**Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding**|Xiner Li et.al.|[2408.08252v1](http://arxiv.org/abs/2408.08252v1)|null|
|**2024-08-15**|**A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts**|Zhihao Lin et.al.|[2408.08242v1](http://arxiv.org/abs/2408.08242v1)|null|
|**2024-08-15**|**Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction**|Yuqicheng Zhu et.al.|[2408.08226v1](http://arxiv.org/abs/2408.08226v1)|null|
|**2024-08-15**|**The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation**|Arpan Mahara et.al.|[2408.08216v1](http://arxiv.org/abs/2408.08216v1)|null|
|**2024-08-15**|**Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices**|Tess Watt et.al.|[2408.08215v1](http://arxiv.org/abs/2408.08215v1)|null|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214v1](http://arxiv.org/abs/2408.08214v1)|[link](https://github.com/oscardilley/federated-fairness)|
|**2024-08-15**|**Covert Bias: The Severity of Social Views' Unalignment Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212v1](http://arxiv.org/abs/2408.08212v1)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208v1](http://arxiv.org/abs/2408.08208v1)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188v1](http://arxiv.org/abs/2408.08188v1)|null|
|**2024-08-15**|**Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**|Qiushuo Cheng et.al.|[2408.08182v1](http://arxiv.org/abs/2408.08182v1)|null|
|**2024-08-15**|**Towards flexible perception with visual memory**|Robert Geirhos et.al.|[2408.08172v1](http://arxiv.org/abs/2408.08172v1)|null|
|**2024-08-15**|**General-purpose Clothes Manipulation with Semantic Keypoints**|Yuhong Deng et.al.|[2408.08160v1](http://arxiv.org/abs/2408.08160v1)|null|
|**2024-08-15**|**DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search**|Huajian Xin et.al.|[2408.08152v1](http://arxiv.org/abs/2408.08152v1)|[link](https://github.com/deepseek-ai/deepseek-prover-v1.5)|
|**2024-08-15**|**Winning Snake: Design Choices in Multi-Shot ASP**|Elisa Böhl et.al.|[2408.08150v1](http://arxiv.org/abs/2408.08150v1)|null|
|**2024-08-15**|**P/D-Serve: Serving Disaggregated Large Language Model at Scale**|Yibo Jin et.al.|[2408.08147v1](http://arxiv.org/abs/2408.08147v1)|null|
|**2024-08-15**|**KOALA: Enhancing Speculative Decoding for LLM via Multi-Layer Draft Heads with Adversarial Learning**|Kaiqi Zhang et.al.|[2408.08146v1](http://arxiv.org/abs/2408.08146v1)|null|
|**2024-08-15**|**Model-based Workflow for the Automated Generation of PDDL Descriptions**|Hamied Nabizada et.al.|[2408.08145v1](http://arxiv.org/abs/2408.08145v1)|null|
|**2024-08-15**|**MIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for Multi-turn NLU**|Yan Li et.al.|[2408.08144v1](http://arxiv.org/abs/2408.08144v1)|null|
|**2024-08-15**|**Multimodal Causal Reasoning Benchmark: Challenging Vision Large Language Models to Infer Causal Links Between Siamese Images**|Zhiyuan Li et.al.|[2408.08105v1](http://arxiv.org/abs/2408.08105v1)|[link](https://github.com/zhiyuan-li-john/mucr)|
|**2024-08-15**|**AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents**|Guhong Chen et.al.|[2408.08089v1](http://arxiv.org/abs/2408.08089v1)|null|
|**2024-08-15**|**An Efficient Replay for Class-Incremental Learning with Pre-trained Models**|Weimin Yin et.al.|[2408.08084v1](http://arxiv.org/abs/2408.08084v1)|null|
|**2024-08-15**|**Confidence-weighted integration of human and machine judgments for superior decision-making**|Felipe Yáñez et.al.|[2408.08083v1](http://arxiv.org/abs/2408.08083v1)|null|
|**2024-08-15**|**Extracting Sentence Embeddings from Pretrained Transformer Models**|Lukas Stankevičius et.al.|[2408.08073v1](http://arxiv.org/abs/2408.08073v1)|null|
|**2024-08-15**|**I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm**|Yiming Liang et.al.|[2408.08072v1](http://arxiv.org/abs/2408.08072v1)|null|
|**2024-08-15**|**SPEED: Scalable Preprocessing of EEG Data for Self-Supervised Learning**|Anders Gjølbye et.al.|[2408.08065v1](http://arxiv.org/abs/2408.08065v1)|null|
|**2024-08-15**|**Navigating Data Scarcity using Foundation Models: A Benchmark of Few-Shot and Zero-Shot Learning Approaches in Medical Imaging**|Stefano Woerner et.al.|[2408.08058v1](http://arxiv.org/abs/2408.08058v1)|null|
|**2024-08-15**|**COTODE: COntinuous Trajectory neural Ordinary Differential Equations for modelling event sequences**|Ilya Kuleshov et.al.|[2408.08055v1](http://arxiv.org/abs/2408.08055v1)|null|
|**2024-08-15**|**Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**|Changyu Du et.al.|[2408.08054v1](http://arxiv.org/abs/2408.08054v1)|null|
|**2024-08-15**|**The Clever Hans Effect in Unsupervised Learning**|Jacob Kauffmann et.al.|[2408.08041v1](http://arxiv.org/abs/2408.08041v1)|null|
|**2024-08-15**|**Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words**|Kento Nozawa et.al.|[2408.08027v1](http://arxiv.org/abs/2408.08027v1)|null|
|**2024-08-15**|**Causal Discovery from Time-Series Data with Short-Term Invariance-Based Convolutional Neural Networks**|Rujia Shen et.al.|[2408.08023v1](http://arxiv.org/abs/2408.08023v1)|[link](https://github.com/hitshenrj/stic)|
|**2024-08-15**|**DIVE: Towards Descriptive and Diverse Visual Commonsense Generation**|Jun-Hyung Park et.al.|[2408.08021v1](http://arxiv.org/abs/2408.08021v1)|[link](https://github.com/park-ing-lot/dive)|
|**2024-08-15**|**Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization**|Sang-Hoon Lee et.al.|[2408.08019v1](http://arxiv.org/abs/2408.08019v1)|[link](https://github.com/sh-lee-prml/periodwave)|
|**2024-08-15**|**Asteroid: Resource-Efficient Hybrid Pipeline Parallelism for Collaborative DNN Training on Heterogeneous Edge Devices**|Shengyuan Ye et.al.|[2408.08015v1](http://arxiv.org/abs/2408.08015v1)|null|
|**2024-08-15**|**Leveraging Web-Crawled Data for High-Quality Fine-Tuning**|Jing Zhou et.al.|[2408.08003v1](http://arxiv.org/abs/2408.08003v1)|[link](https://github.com/zhouj8553/Web_to_SFT)|
|**2024-08-15**|**FuseChat: Knowledge Fusion of Chat Models**|Fanqi Wan et.al.|[2408.07990v1](http://arxiv.org/abs/2408.07990v1)|[link](https://github.com/fanqiwan/fuseai)|
|**2024-08-15**|**IIU: Independent Inference Units for Knowledge-based Visual Question Answering**|Yili Li et.al.|[2408.07989v1](http://arxiv.org/abs/2408.07989v1)|[link](https://github.com/lilidamowang/iiu)|
|**2024-08-15**|**ArabLegalEval: A Multitask Benchmark for Assessing Arabic Legal Knowledge in Large Language Models**|Faris Hijazi et.al.|[2408.07983v1](http://arxiv.org/abs/2408.07983v1)|[link](https://github.com/thiqah/arablegaleval)|
|**2024-08-15**|**Toward a Dialogue System Using a Large Language Model to Recognize User Emotions with a Camera**|Hiroki Tanioka et.al.|[2408.07982v1](http://arxiv.org/abs/2408.07982v1)|null|
|**2024-08-15**|**LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning**|Jiajie Li et.al.|[2408.07981v1](http://arxiv.org/abs/2408.07981v1)|null|
|**2024-08-15**|**Coupling without Communication and Drafter-Invariant Speculative Decoding**|Majid Daliri et.al.|[2408.07978v1](http://arxiv.org/abs/2408.07978v1)|null|
|**2024-08-15**|**Polaris: Open-ended Interactive Robotic Manipulation via Syn2Real Visual Grounding and Large Language Models**|Tianyu Wang et.al.|[2408.07975v1](http://arxiv.org/abs/2408.07975v1)|null|
|**2024-08-15**|**Predicting Lung Cancer Patient Prognosis with Large Language Models**|Danqing Hu et.al.|[2408.07971v1](http://arxiv.org/abs/2408.07971v1)|null|
|**2024-08-15**|**Meta SAC-Lag: Towards Deployable Safe Reinforcement Learning via MetaGradient-based Hyperparameter Tuning**|Homayoun Honari et.al.|[2408.07962v1](http://arxiv.org/abs/2408.07962v1)|null|
|**2024-08-15**|**RandomNet: Clustering Time Series Using Untrained Deep Neural Networks**|Xiaosheng Li et.al.|[2408.07956v1](http://arxiv.org/abs/2408.07956v1)|null|
|**2024-08-15**|**GERestaurant: A German Dataset of Annotated Restaurant Reviews for Aspect-Based Sentiment Analysis**|Nils Constantin Hellwig et.al.|[2408.07955v1](http://arxiv.org/abs/2408.07955v1)|null|
|**2024-08-15**|**Conditional Brownian Bridge Diffusion Model for VHR SAR to Optical Image Translation**|Seon-Hoon Kim et.al.|[2408.07947v1](http://arxiv.org/abs/2408.07947v1)|null|
|**2024-08-15**|**Solving a Rubik's Cube Using its Local Graph Structure**|Shunyu Yao et.al.|[2408.07945v1](http://arxiv.org/abs/2408.07945v1)|null|
|**2024-08-15**|**Surgical SAM 2: Real-time Segment Anything in Surgical Video by Efficient Frame Pruning**|Haofeng Liu et.al.|[2408.07931v1](http://arxiv.org/abs/2408.07931v1)|null|
|**2024-08-15**|**MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and Iterative Sub-SQL Refinement for Text-to-SQL**|Wenxuan Xie et.al.|[2408.07930v1](http://arxiv.org/abs/2408.07930v1)|null|
|**2024-08-15**|**CEGRL-TKGR: A Causal Enhanced Graph Representation Learning Framework for Improving Temporal Knowledge Graph Extrapolation Reasoning**|Jinze Sun et.al.|[2408.07911v1](http://arxiv.org/abs/2408.07911v1)|null|
|**2024-08-15**|**DM2RM: Dual-Mode Multimodal Ranking for Target Objects and Receptacles Based on Open-Vocabulary Instructions**|Ryosuke Korekata et.al.|[2408.07910v1](http://arxiv.org/abs/2408.07910v1)|null|
|**2024-08-15**|**Assessing Language Models' Worldview for Fiction Generation**|Aisha Khatun et.al.|[2408.07904v1](http://arxiv.org/abs/2408.07904v1)|[link](https://github.com/tanny411/llm-reliability-and-consistency-evaluation)|
|**2024-08-15**|**Quantum-inspired Interpretable Deep Learning Architecture for Text Sentiment Analysis**|Bingyu Li et.al.|[2408.07891v1](http://arxiv.org/abs/2408.07891v1)|[link](https://github.com/libingyu01/qitsa-quantum-inspired-interpretable-deep-learning-architecture-for-text-sentiment-analysis)|
|**2024-08-15**|**Fine-tuning Large Language Models with Human-inspired Learning Strategies in Medical Question Answering**|Yushi Yang et.al.|[2408.07888v1](http://arxiv.org/abs/2408.07888v1)|[link](https://github.com/Oxford-AI-for-Society/human-learning-strategies)|
|**2024-08-15**|**Instruct Large Language Models to Generate Scientific Literature Survey Step by Step**|Yuxuan Lai et.al.|[2408.07884v1](http://arxiv.org/abs/2408.07884v1)|null|
|**2024-08-15**|**Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models**|Layla Bouzoubaa et.al.|[2408.07873v1](http://arxiv.org/abs/2408.07873v1)|null|
|**2024-08-14**|**CON-FOLD -- Explainable Machine Learning with Confidence**|Lachlan McGinness et.al.|[2408.07854v1](http://arxiv.org/abs/2408.07854v1)|[link](https://github.com/lachlanmcg123/confold)|
|**2024-08-14**|**Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability**|Jiri Hron et.al.|[2408.07852v1](http://arxiv.org/abs/2408.07852v1)|null|
|**2024-08-14**|**SER Evals: In-domain and Out-of-domain Benchmarking for Speech Emotion Recognition**|Mohamed Osman et.al.|[2408.07851v1](http://arxiv.org/abs/2408.07851v1)|[link](https://github.com/spaghettiSystems/serval)|
|**2024-08-14**|**A System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites**|Andrea Lops et.al.|[2408.07846v1](http://arxiv.org/abs/2408.07846v1)|null|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845v1](http://arxiv.org/abs/2408.07845v1)|null|
|**2024-08-14**|**ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model**|Xuanqing Yu et.al.|[2408.07840v1](http://arxiv.org/abs/2408.07840v1)|null|
|**2024-08-14**|**An Efficient and Explanatory Image and Text Clustering System with Multimodal Autoencoder Architecture**|Tiancheng Shi et.al.|[2408.07791v1](http://arxiv.org/abs/2408.07791v1)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702v1](http://arxiv.org/abs/2408.07702v1)|null|
|**2024-08-14**|**Quantifying over Optimum Answer Sets**|Giuseppe Mazzotta et.al.|[2408.07697v1](http://arxiv.org/abs/2408.07697v1)|null|
|**2024-08-14**|**Enhancing Model Interpretability with Local Attribution over Global Exploration**|Zhiyu Zhu et.al.|[2408.07736v1](http://arxiv.org/abs/2408.07736v1)|[link](https://github.com/lmbtough/la)|
|**2024-08-14**|**End-to-end Semantic-centric Video-based Multimodal Affective Computing**|Ronghao Lin et.al.|[2408.07694v1](http://arxiv.org/abs/2408.07694v1)|null|
|**2024-08-14**|**A Spitting Image: Modular Superpixel Tokenization in Vision Transformers**|Marius Aasan et.al.|[2408.07680v2](http://arxiv.org/abs/2408.07680v2)|[link](https://github.com/dsb-ifi/spit)|
|**2024-08-14**|**Enhanced Detection of Conversational Mental Manipulation Through Advanced Prompting Techniques**|Ivory Yang et.al.|[2408.07676v1](http://arxiv.org/abs/2408.07676v1)|null|
|**2024-08-14**|**Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data**|Xia Jiang et.al.|[2408.07673v2](http://arxiv.org/abs/2408.07673v2)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666v2](http://arxiv.org/abs/2408.07666v2)|[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665v1](http://arxiv.org/abs/2408.07665v1)|[link](https://github.com/dlion168/spoken_stereoset)|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663v1](http://arxiv.org/abs/2408.07663v1)|[link](https://github.com/gigabaozi/aed)|
|**2024-08-14**|**Boosting Unconstrained Face Recognition with Targeted Style Adversary**|Mohammad Saeed Ebrahimi Saadabadi et.al.|[2408.07642v1](http://arxiv.org/abs/2408.07642v1)|null|
|**2024-08-14**|**Hierarchical Working Memory and a New Magic Number**|Weishun Zhong et.al.|[2408.07637v1](http://arxiv.org/abs/2408.07637v1)|null|
|**2024-08-14**|**Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding**|Bing Hu et.al.|[2408.07636v1](http://arxiv.org/abs/2408.07636v1)|null|
|**2024-08-14**|**Battery GraphNets : Relational Learning for Lithium-ion Batteries(LiBs) Life Estimation**|Sakhinana Sagar Srinivas et.al.|[2408.07624v1](http://arxiv.org/abs/2408.07624v1)|null|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611v1](http://arxiv.org/abs/2408.07611v1)|null|
|**2024-08-14**|**Assessing the Role of Lexical Semantics in Cross-lingual Transfer through Controlled Manipulations**|Roy Ilani et.al.|[2408.07599v1](http://arxiv.org/abs/2408.07599v1)|[link](https://github.com/roy54x/Lexical_semantics_in_cross-lingual_transfer)|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583v1](http://arxiv.org/abs/2408.07583v1)|null|
|**2024-08-14**|**Graph neural network surrogate for strategic transport planning**|Nikita Makarov et.al.|[2408.07726v1](http://arxiv.org/abs/2408.07726v1)|[link](https://github.com/nikita6187/transportplanningdataset)|
|**2024-08-14**|**Multi-task Heterogeneous Graph Learning on Electronic Health Records**|Tsai Hor Chan et.al.|[2408.07569v1](http://arxiv.org/abs/2408.07569v1)|null|
|**2024-08-14**|**PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation**|Sang-Hoon Lee et.al.|[2408.07547v1](http://arxiv.org/abs/2408.07547v1)|[link](https://github.com/sh-lee-prml/periodwave)|
|**2024-08-14**|**Planning with OWL-DL Ontologies (Extended Version)**|Tobias John et.al.|[2408.07544v1](http://arxiv.org/abs/2408.07544v1)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543v2](http://arxiv.org/abs/2408.07543v2)|null|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542v1](http://arxiv.org/abs/2408.07542v1)|null|
|**2024-08-14**|**DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model**|Erez Yosef et.al.|[2408.07541v1](http://arxiv.org/abs/2408.07541v1)|null|
|**2024-08-14**|**Cross-aware Early Fusion with Stage-divided Vision and Language Transformer Encoders for Referring Image Segmentation**|Yubin Cho et.al.|[2408.07539v1](http://arxiv.org/abs/2408.07539v1)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531v1](http://arxiv.org/abs/2408.07531v1)|null|
|**2024-08-14**|**Evidential Graph Contrastive Alignment for Source-Free Blending-Target Domain Adaptation**|Juepeng Zheng et.al.|[2408.07527v1](http://arxiv.org/abs/2408.07527v1)|null|
|**2024-08-14**|**Fast Inference for Probabilistic Answer Set Programs via the Residual Program**|Damiano Azzolini et.al.|[2408.07524v1](http://arxiv.org/abs/2408.07524v1)|null|

#### Abstracts
##### **Can Large Language Models Understand Symbolic Graphics Programs?**
2408.08313v1 by Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z. Xiao, Katherine M. Collins, Joshua B. Tenenbaum, Adrian Weller, Michael J. Black, Bernhard Schölkopf

Assessing the capabilities of large language models (LLMs) is often
challenging, in part, because it is hard to find tasks to which they have not
been exposed during training. We take one step to address this challenge by
turning to a new task: focusing on symbolic graphics programs, which are a
popular representation for graphics content that procedurally generates visual
data. LLMs have shown exciting promise towards program synthesis, but do they
understand symbolic graphics programs? Unlike conventional programs, symbolic
graphics programs can be translated to graphics content. Here, we characterize
an LLM's understanding of symbolic programs in terms of their ability to answer
questions related to the graphics content. This task is challenging as the
questions are difficult to answer from the symbolic programs alone -- yet, they
would be easy to answer from the corresponding graphics content as we verify
through a human experiment. To understand symbolic programs, LLMs may need to
possess the ability to imagine how the corresponding graphics content would
look without directly accessing the rendered visual content. We use this task
to evaluate LLMs by creating a large benchmark for the semantic understanding
of symbolic graphics programs. This benchmark is built via program-graphics
correspondence, hence requiring minimal human efforts. We evaluate current LLMs
on our benchmark to elucidate a preliminary assessment of their ability to
reason about visual scenes from programs. We find that this task distinguishes
existing LLMs and models considered good at reasoning perform better. Lastly,
we introduce Symbolic Instruction Tuning (SIT) to improve this ability.
Specifically, we query GPT4-o with questions and images generated by symbolic
programs. Such data are then used to finetune an LLM. We also find that SIT
data can improve the general instruction following ability of LLMs.

摘要：<paragraph>評估大型語言模型 (LLM) 的功能通常具有挑戰性，部分原因是難以找到在訓練過程中未接觸過的任務。我們透過專注於符號圖形程式這個新任務來解決此挑戰，符號圖形程式是圖形內容的熱門表示形式，可循序產生視覺資料。LLM 已在程式合成方面展現令人興奮的前景，但它們是否了解符號圖形程式？與傳統程式不同，符號圖形程式可以轉換為圖形內容。在此，我們根據 LLM 回答與圖形內容相關問題的能力，來描述其對符號程式的理解。這項任務具有挑戰性，因為僅從符號程式中很難回答這些問題，但從對應的圖形內容中很容易就能回答，我們透過人體實驗驗證了這一點。若要了解符號程式，LLM 可能需要具備想像對應圖形內容外觀的能力，而無需直接存取已渲染的視覺內容。我們使用此任務透過為符號圖形程式的語意理解建立大型基準，來評估 LLM。此基準是透過程式圖形對應建立，因此需要最少的人力。我們在基準上評估目前的 LLM，以闡明其從程式中推論視覺場景的能力的初步評估。我們發現此任務區分了現有的 LLM，並且被認為擅長推理的模型表現得更好。最後，我們引入了符號指令調整 (SIT) 來提升此能力。具體來說，我們使用符號程式產生的問題和影像查詢 GPT4-o。此類資料隨後用於微調 LLM。我們也發現 SIT 資料可以提升 LLM 的一般指令遵循能力。</paragraph>

##### **ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**
2408.08310v1 by Ruihang Li, Yixuan Wei, Miaosen Zhang, Nenghai Yu, Han Hu, Houwen Peng

High-quality data is crucial for the pre-training performance of large
language models. Unfortunately, existing quality filtering methods rely on a
known high-quality dataset as reference, which can introduce potential bias and
compromise diversity. In this paper, we propose ScalingFilter, a novel approach
that evaluates text quality based on the perplexity difference between two
language models trained on the same data, thereby eliminating the influence of
the reference dataset in the filtering process. An theoretical analysis shows
that ScalingFilter is equivalent to an inverse utilization of scaling laws.
Through training models with 1.3B parameters on the same data source processed
by various quality filters, we find ScalingFilter can improve zero-shot
performance of pre-trained models in downstream tasks. To assess the bias
introduced by quality filtering, we introduce semantic diversity, a metric of
utilizing text embedding models for semantic representations. Extensive
experiments reveal that semantic diversity is a reliable indicator of dataset
diversity, and ScalingFilter achieves an optimal balance between downstream
performance and semantic diversity.

摘要：高质量的数据对于大型语言模型的预训练性能至关重要。不幸的是，现有的质量过滤方法依赖于已知的高质量数据集作为参考，这可能会引入潜在的偏差并损害多样性。在本文中，我们提出了 ScalingFilter，这是一种新颖的方法，它根据在同一数据上训练的两个语言模型之间的困惑度差异来评估文本质量，从而消除了过滤过程中参考数据集的影响。理论分析表明，ScalingFilter 等效于对标度定律的反向利用。通过使用各种质量过滤器处理的相同数据源对具有 1.3B 参数的训练模型，我们发现 ScalingFilter 可以提高预训练模型在下游任务中的零样本性能。为了评估质量过滤引入的偏差，我们引入了语义多样性，这是一种利用文本嵌入模型进行语义表示的度量。大量的实验表明，语义多样性是数据集多样性的可靠指标，而 ScalingFilter 在下游性能和语义多样性之间实现了最佳平衡。

##### **Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**
2408.08302v1 by Usman Syed, Ethan Light, Xingang Guo, Huan Zhang, Lianhui Qin, Yanfeng Ouyang, Bin Hu

In this paper, we explore the capabilities of state-of-the-art large language
models (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini
1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level
transportation engineering problems. We introduce TransportBench, a benchmark
dataset that includes a sample of transportation engineering problems on a wide
range of subjects in the context of planning, design, management, and control
of transportation systems. This dataset is used by human experts to evaluate
the capabilities of various commercial and open-sourced LLMs, especially their
accuracy, consistency, and reasoning behaviors, in solving transportation
engineering problems. Our comprehensive analysis uncovers the unique strengths
and limitations of each LLM, e.g. our analysis shows the impressive accuracy
and some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving
TransportBench problems. Our study marks a thrilling first step toward
harnessing artificial general intelligence for complex transportation
challenges.

摘要：在本文中，我們探討了最先進大型語言模型 (LLM) 的能力，例如 GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3 和 Llama 3.1，以解決一些選定的大學部級交通工程問題。我們引入了 TransportBench，這是一個基準數據集，其中包含在規劃、設計、管理和交通系統控制的廣泛主題中的一系列交通工程問題範例。此數據集由人類專家用於評估各種商業和開源 LLM 的能力，特別是它們在解決交通工程問題時的準確性、一致性和推理行為。我們的全面分析揭示了每種 LLM 獨特的優勢和限制，例如我們的分析顯示了 Claude 3.5 Sonnet 在解決 TransportBench 問題時令人印象深刻的準確性和一些意外的不一致行為。我們的研究標誌著朝著利用人工通用智慧來應對複雜的交通挑戰邁出的令人興奮的第一步。

##### **SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training**
2408.08295v1 by Gengwei Zhang, Liyuan Wang, Guoliang Kang, Ling Chen, Yunchao Wei

In recent years, continual learning with pre-training (CLPT) has received
widespread interest, instead of its traditional focus of training from scratch.
The use of strong pre-trained models (PTMs) can greatly facilitate knowledge
transfer and alleviate catastrophic forgetting, but also suffers from
progressive overfitting of pre-trained knowledge into specific downstream
tasks. A majority of current efforts often keep the PTMs frozen and incorporate
task-specific prompts to instruct representation learning, coupled with a
prompt selection process for inference. However, due to the limited capacity of
prompt parameters, this strategy demonstrates only sub-optimal performance in
continual learning. In comparison, tuning all parameters of PTMs often provides
the greatest potential for representation learning, making sequential
fine-tuning (Seq FT) a fundamental baseline that has been overlooked in CLPT.
To this end, we present an in-depth analysis of the progressive overfitting
problem from the lens of Seq FT. Considering that the overly fast
representation learning and the biased classification layer constitute this
particular problem, we introduce the advanced Slow Learner with Classifier
Alignment (SLCA++) framework to unleash the power of Seq FT, serving as a
strong baseline approach for CLPT. Our approach involves a Slow Learner to
selectively reduce the learning rate of backbone parameters, and a Classifier
Alignment to align the disjoint classification layers in a post-hoc fashion. We
further enhance the efficacy of SL with a symmetric cross-entropy loss, as well
as employ a parameter-efficient strategy to implement Seq FT with SLCA++.
Across a variety of continual learning scenarios on image classification
benchmarks, our approach provides substantial improvements and outperforms
state-of-the-art methods by a large margin. Code:
https://github.com/GengDavid/SLCA.

摘要：近年來，持續學習與預訓練 (CLPT) 受到廣泛關注，取代傳統從頭開始訓練的重點。使用強大的預訓練模型 (PTM) 可以大幅促進知識轉移，並減輕災難性遺忘，但也飽受特定下游任務中預訓練知識的漸進過度擬合所苦。目前大多數方法通常保持 PTM 凍結，並結合特定於任務的提示，以指導表徵學習，再搭配提示選取程序進行推論。然而，由於提示參數的容量有限，此策略在持續學習中僅展現次佳效能。相比之下，調整 PTM 的所有參數通常能提供表徵學習最大的潛力，讓循序漸進微調 (Seq FT) 成為 CLPT 中被忽略的基本基準。為此，我們從 Seq FT 的角度深入分析漸進過度擬合問題。考量到過於快速表徵學習和帶有偏差的分類層構成此特定問題，我們推出進階的慢學習器與分類器校準 (SLCA++) 架構，以發揮 Seq FT 的強大功能，作為 CLPT 的強大基準方法。我們的做法包括慢學習器，以選擇性降低主幹參數的學習率，以及分類器校準，以事後方式校準不相交的分類層。我們進一步透過對稱交叉熵損失增強 SL 的效能，並採用參數有效率的策略，以 SLCA++ 實作 Seq FT。在影像分類基準上的各種持續學習情境中，我們的做法提供了大幅改善，並以極大差距超越現有技術。程式碼：https://github.com/GengDavid/SLCA。

##### **The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**
2408.08291v1 by Shachar Don-Yehiya, Leshem Choshen, Omri Abend

Human-model conversations provide a window into users' real-world scenarios,
behavior, and needs, and thus are a valuable resource for model development and
research. While for-profit companies collect user data through the APIs of
their models, using it internally to improve their own models, the open source
and research community lags behind.
  We introduce the ShareLM collection, a unified set of human conversations
with large language models, and its accompanying plugin, a Web extension for
voluntarily contributing user-model conversations. Where few platforms share
their chats, the ShareLM plugin adds this functionality, thus, allowing users
to share conversations from most platforms. The plugin allows the user to rate
their conversations, both at the conversation and the response levels, and
delete conversations they prefer to keep private before they ever leave the
user's local storage. We release the plugin conversations as part of the
ShareLM collection, and call for more community effort in the field of open
human-model data.
  The code, plugin, and data are available.

摘要：人類與模型的對話提供了使用者真實世界情境、行為和需求的窗口，因此對於模型開發和研究來說，這是一個有價值的資源。雖然營利公司透過其模型的 API 來收集使用者資料，並在內部使用這些資料來改善其自己的模型，但開源和研究社群卻落後了。
我們推出了 ShareLM 蒐集，這是一組與大型語言模型進行的人類對話的統一集合，以及其附屬外掛程式，一個用於自願貢獻使用者模型對話的網路擴充功能。在少數平台分享其對話的情況下，ShareLM 外掛程式增加了此功能，因此允許使用者分享大多數平台的對話。該外掛程式允許使用者評分他們的對話，無論是在對話層級或回應層級，並在對話離開使用者的本機儲存空間之前刪除他們偏好保持私密的對話。我們將外掛程式對話作為 ShareLM 蒐集的一部分釋出，並呼籲在開放人類模型資料領域中進行更多社群努力。
程式碼、外掛程式和資料都已提供。

##### **Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**
2408.08282v1 by Jin Wang, Arturo Laurenzi, Nikos Tsagarakis

Enabling humanoid robots to perform autonomously loco-manipulation in
unstructured environments is crucial and highly challenging for achieving
embodied intelligence. This involves robots being able to plan their actions
and behaviors in long-horizon tasks while using multi-modality to perceive
deviations between task execution and high-level planning. Recently, large
language models (LLMs) have demonstrated powerful planning and reasoning
capabilities for comprehension and processing of semantic information through
robot control tasks, as well as the usability of analytical judgment and
decision-making for multi-modal inputs. To leverage the power of LLMs towards
humanoid loco-manipulation, we propose a novel language-model based framework
that enables robots to autonomously plan behaviors and low-level execution
under given textual instructions, while observing and correcting failures that
may occur during task execution. To systematically evaluate this framework in
grounding LLMs, we created the robot 'action' and 'sensing' behavior library
for task planning, and conducted mobile manipulation tasks and experiments in
both simulated and real environments using the CENTAURO robot, and verified the
effectiveness and application of this approach in robotic tasks with autonomous
behavioral planning.

摘要：讓類人機器人在非結構化環境中執行自主運動操縱對於實現具身智能至關重要且極具挑戰性。這涉及機器人在執行多視角任務時能夠規劃其動作和行為，同時使用多模態來感知任務執行和高層級規劃之間的偏差。最近，大型語言模型 (LLM) 已展示出強大的規劃和推理能力，可用於理解和處理語義信息，通過機器人控制任務，以及分析判斷和決策制定對多模態輸入的可用性。為了將 LLM 的能力運用於類人運動操縱，我們提出了一個基於語言模型的新框架，該框架使機器人能夠在給定的文本指令下自主規劃行為和低層級執行，同時觀察和糾正任務執行期間可能發生的故障。為了系統地評估這個在 LLM 中的框架，我們創建了機器人「動作」和「感測」行為庫用於任務規劃，並使用 CENTAURO 機器人在模擬和真實環境中進行了移動操作任務和實驗，並驗證了這種方法在具有自主行為規劃的機器人任務中的有效性和應用。

##### **InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**
2408.08264v1 by Guoxiang Grayson Tong, Carlos A. Sing Long, Daniele E. Schiavazzi

Estimation of cardiovascular model parameters from electronic health records
(EHR) poses a significant challenge primarily due to lack of identifiability.
Structural non-identifiability arises when a manifold in the space of
parameters is mapped to a common output, while practical non-identifiability
can result due to limited data, model misspecification, or noise corruption. To
address the resulting ill-posed inverse problem, optimization-based or Bayesian
inference approaches typically use regularization, thereby limiting the
possibility of discovering multiple solutions. In this study, we use inVAErt
networks, a neural network-based, data-driven framework for enhanced digital
twin analysis of stiff dynamical systems. We demonstrate the flexibility and
effectiveness of inVAErt networks in the context of physiological inversion of
a six-compartment lumped parameter hemodynamic model from synthetic data to
real data with missing components.

摘要：從電子健康紀錄 (EHR) 估計心血管模型參數主要由於缺乏可識別性而構成重大挑戰。
當參數空間中的流形對應到共同輸出時，會產生結構性不可識別性，而由於資料有限、模型錯誤規範或雜訊破壞，可能會導致實際不可識別性。為了解決由此產生的不適定反問題，基於最佳化的貝氏推論方法通常使用正則化，從而限制發現多重解的可能性。在本研究中，我們使用 inVAErt 網路，這是一種基於神經網路、資料驅動的架構，用於增強僵硬動態系統的數位雙胞胎分析。我們展示了 inVAErt 網路在生理反演中的靈活性與有效性，從合成資料到缺少組成的真實資料，反演六隔間集總參數血流動力模型。

##### **mhGPT: A Lightweight Generative Pre-Trained Transformer for Mental Health Text Analysis**
2408.08261v1 by Dae-young Kim, Rebecca Hwa, Muhammad Mahbubur Rahman

This paper introduces mhGPT, a lightweight generative pre-trained transformer
trained on mental health-related social media and PubMed articles. Fine-tuned
for specific mental health tasks, mhGPT was evaluated under limited hardware
constraints and compared with state-of-the-art models like MentaLLaMA and
Gemma. Despite having only 1.98 billion parameters and using just 5% of the
dataset, mhGPT outperformed larger models and matched the performance of models
trained on significantly more data. The key contributions include integrating
diverse mental health data, creating a custom tokenizer, and optimizing a
smaller architecture for low-resource settings. This research could advance
AI-driven mental health care, especially in areas with limited computing power.

摘要：本文介紹 mhGPT，一種輕量級的生成式預訓練轉換器，經過針對心理健康相關社群媒體和 PubMed 文章的訓練。針對特定心理健康任務進行微調後，mhGPT 在有限的硬體限制下進行評估，並與 MentaLLaMA 和 Gemma 等最先進的模型進行比較。儘管只有 19.8 億個參數，並且僅使用 5% 的資料集，mhGPT 的表現優於較大的模型，並且與在更多資料上訓練的模型的表現相匹配。主要貢獻包括整合多樣的心理健康資料、建立自訂的標記器，以及針對低資源設定最佳化較小的架構。這項研究可以推進人工智慧驅動的心理保健，特別是在運算能力有限的地區。

##### **Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding**
2408.08252v1 by Xiner Li, Yulai Zhao, Chenyu Wang, Gabriele Scalia, Gokcen Eraslan, Surag Nair, Tommaso Biancalani, Aviv Regev, Sergey Levine, Masatoshi Uehara

Diffusion models excel at capturing the natural design spaces of images,
molecules, DNA, RNA, and protein sequences. However, rather than merely
generating designs that are natural, we often aim to optimize downstream reward
functions while preserving the naturalness of these design spaces. Existing
methods for achieving this goal often require ``differentiable'' proxy models
(\textit{e.g.}, classifier guidance or DPS) or involve computationally
expensive fine-tuning of diffusion models (\textit{e.g.}, classifier-free
guidance, RL-based fine-tuning). In our work, we propose a new method to
address these challenges. Our algorithm is an iterative sampling method that
integrates soft value functions, which looks ahead to how intermediate noisy
states lead to high rewards in the future, into the standard inference
procedure of pre-trained diffusion models. Notably, our approach avoids
fine-tuning generative models and eliminates the need to construct
differentiable models. This enables us to (1) directly utilize
non-differentiable features/reward feedback, commonly used in many scientific
domains, and (2) apply our method to recent discrete diffusion models in a
principled way. Finally, we demonstrate the effectiveness of our algorithm
across several domains, including image generation, molecule generation, and
DNA/RNA sequence generation. The code is available at
\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}.

摘要：擴散模型擅長捕捉影像、分子、DNA、RNA 和蛋白質序列的自然設計空間。然而，我們通常不只是產生自然的設計，而是希望在保留這些設計空間的自然性的同時，最佳化下游獎勵函數。現有的達成此目標的方法通常需要「可微分」的代理模型（例如分類器引導或 DPS）或涉及計算成本高的擴散模型微調（例如無分類器引導、基於 RL 的微調）。在我們的研究中，我們提出了一種新的方法來解決這些挑戰。我們的演算法是一種反覆取樣方法，它將軟值函數整合到標準預訓練擴散模型的推論程序中，該函數預測中間雜訊狀態將如何導致未來的高獎勵。值得注意的是，我們的方法避免了生成模型的微調，並消除了構建可微分模型的需要。這使我們能夠 (1) 直接利用在許多科學領域中常用的不可微分特徵/獎勵回饋，以及 (2) 以有原則的方式將我們的模型應用於最近的離散擴散模型。最後，我們在幾個領域展示了我們演算法的有效性，包括影像生成、分子生成以及 DNA/RNA 序列生成。程式碼可在以下網址取得：\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}。

##### **A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts**
2408.08242v1 by Zhihao Lin, Zhen Tian, Qi Zhang, Ziyang Ye, Hanyang Zhuang, Jianglin Lan

Safety and efficiency are crucial for autonomous driving in roundabouts,
especially in the context of mixed traffic where autonomous vehicles (AVs) and
human-driven vehicles coexist. This paper introduces a learning-based algorithm
tailored to foster safe and efficient driving behaviors across varying levels
of traffic flows in roundabouts. The proposed algorithm employs a deep
Q-learning network to effectively learn safe and efficient driving strategies
in complex multi-vehicle roundabouts. Additionally, a KAN (Kolmogorov-Arnold
network) enhances the AVs' ability to learn their surroundings robustly and
precisely. An action inspector is integrated to replace dangerous actions to
avoid collisions when the AV interacts with the environment, and a route
planner is proposed to enhance the driving efficiency and safety of the AVs.
Moreover, a model predictive control is adopted to ensure stability and
precision of the driving actions. The results show that our proposed system
consistently achieves safe and efficient driving whilst maintaining a stable
training process, as evidenced by the smooth convergence of the reward function
and the low variance in the training curves across various traffic flows.
Compared to state-of-the-art benchmarks, the proposed algorithm achieves a
lower number of collisions and reduced travel time to destination.

摘要：在環島中，安全性和效率對於自動駕駛至關重要，特別是在自動駕駛汽車 (AV) 和人類駕駛汽車並存的混合交通環境中。本文介紹了一種基於學習的演算法，專門用於促進在環島中不同交通流量等級的安全且有效的駕駛行為。所提出的演算法採用深度 Q 學習網路，可在複雜的多車輛環島中有效學習安全且有效的駕駛策略。此外，KAN（柯爾莫哥洛夫-阿諾德網路）增強了自動駕駛汽車在環境中穩健且精確學習的能力。整合了動作檢查器，可在自動駕駛汽車與環境互動時取代危險動作，避免碰撞，並提出了路線規劃器，以增強自動駕駛汽車的駕駛效率和安全性。此外，採用了模型預測控制，以確保駕駛動作的穩定性和精確性。結果表明，我們提出的系統始終能實現安全且有效的駕駛，同時保持穩定的訓練過程，這從回報函數的平穩收斂和訓練曲線在各種交通流量中的低變異中可以得到證明。與最先進的基準相比，所提出的演算法可減少碰撞次數並縮短到達目的地的行程時間。

##### **Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction**
2408.08226v1 by Yuqicheng Zhu, Nico Potyka, Mojtaba Nayyeri, Bo Xiong, Yunjie He, Evgeny Kharlamov, Steffen Staab

Knowledge graph embedding (KGE) models are often used to predict missing
links for knowledge graphs (KGs). However, multiple KG embeddings can perform
almost equally well for link prediction yet suggest conflicting predictions for
certain queries, termed \textit{predictive multiplicity} in literature. This
behavior poses substantial risks for KGE-based applications in high-stake
domains but has been overlooked in KGE research. In this paper, we define
predictive multiplicity in link prediction. We introduce evaluation metrics and
measure predictive multiplicity for representative KGE methods on commonly used
benchmark datasets. Our empirical study reveals significant predictive
multiplicity in link prediction, with $8\%$ to $39\%$ testing queries
exhibiting conflicting predictions. To address this issue, we propose
leveraging voting methods from social choice theory, significantly mitigating
conflicts by $66\%$ to $78\%$ according to our experiments.

摘要：知識圖譜嵌入 (KGE) 模型通常用於預測知識圖譜 (KG) 的遺失連結。然而，多個 KG 嵌入在連結預測上可以有近乎相同的表現，卻對某些查詢提出互相矛盾的預測，這在文獻中稱為「預測多樣性」。此行為對高風險領域中以 KGE 為基礎的應用程式構成重大風險，但在 KGE 研究中卻被忽略。在本文中，我們定義了連結預測中的預測多樣性。我們引進評估指標，並針對常用基準資料集，針對具代表性的 KGE 方法測量預測多樣性。我們的實證研究揭露了連結預測中顯著的預測多樣性，其中 8% 至 39% 的測試查詢展現出互相矛盾的預測。為了解決此問題，我們提出利用社會選擇理論中的投票方法，根據我們的實驗，大幅降低了 66% 至 78% 的衝突。

##### **The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation**
2408.08216v1 by Arpan Mahara, Naphtali D. Rishe, Liangdong Deng

Image-to-Image translation in Generative Artificial Intelligence (Generative
AI) has been a central focus of research, with applications spanning
healthcare, remote sensing, physics, chemistry, photography, and more. Among
the numerous methodologies, Generative Adversarial Networks (GANs) with
contrastive learning have been particularly successful. This study aims to
demonstrate that the Kolmogorov-Arnold Network (KAN) can effectively replace
the Multi-layer Perceptron (MLP) method in generative AI, particularly in the
subdomain of image-to-image translation, to achieve better generative quality.
Our novel approach replaces the two-layer MLP with a two-layer KAN in the
existing Contrastive Unpaired Image-to-Image Translation (CUT) model,
developing the KAN-CUT model. This substitution favors the generation of more
informative features in low-dimensional vector representations, which
contrastive learning can utilize more effectively to produce high-quality
images in the target domain. Extensive experiments, detailed in the results
section, demonstrate the applicability of KAN in conjunction with contrastive
learning and GANs in Generative AI, particularly for image-to-image
translation. This work suggests that KAN could be a valuable component in the
broader generative AI domain.

摘要：生成式人工智能 (生成式 AI) 中的图像到图像转换一直是研究的重点，其应用涵盖医疗保健、遥感、物理、化学、摄影等领域。在众多方法中，具有对比学习的生成对抗网络 (GAN) 特别成功。本研究旨在证明 Kolmogorov-Arnold 网络 (KAN) 可以有效取代生成式 AI 中的多层感知器 (MLP) 方法，特别是在图像到图像转换的子领域中，以实现更好的生成质量。我们的新方法用两层 KAN 替换现有对比无配对图像到图像转换 (CUT) 模型中的两层 MLP，开发出 KAN-CUT 模型。这种替换有利于在低维向量表示中生成更多信息特征，对比学习可以更有效地利用这些特征，从而在目标域中生成高质量图像。结果部分中详细介绍的广泛实验表明了 KAN 与对比学习和 GAN 在生成式 AI 中结合使用的适用性，特别是对于图像到图像转换。这项工作表明，KAN 可能是更广泛的生成式 AI 领域中的一个有价值的组成部分。

##### **Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices**
2408.08215v1 by Tess Watt, Christos Chrysoulas, Peter J Barclay

Image classification usually requires connectivity and access to the cloud
which is often limited in many parts of the world, including hard to reach
rural areas. TinyML aims to solve this problem by hosting AI assistants on
constrained devices, eliminating connectivity issues by processing data within
the device itself, without internet or cloud access. This pilot study explores
the use of tinyML to provide healthcare support with low spec devices in low
connectivity environments, focusing on diagnosis of skin diseases and the
ethical use of AI assistants in a healthcare setting. To investigate this,
10,000 images of skin lesions were used to train a model for classifying
visually detectable diseases (VDDs). The model weights were then offloaded to a
Raspberry Pi with a webcam attached, to be used for the classification of skin
lesions without internet access. It was found that the developed prototype
achieved a test accuracy of 78% and a test loss of 1.08.

摘要：影像分類通常需要連線和存取雲端，而這在世界許多地區，包括難以抵達的鄉村地區，通常受到限制。TinyML 旨在透過在受限裝置上架設 AI 助理，在裝置內處理資料，無需網路或雲端存取，來解決這個問題。這項試驗研究探討使用 TinyML 在連線不良的環境中提供低規格裝置的醫療保健支援，重點在皮膚疾病診斷和醫療環境中 AI 助理的道德使用。為此，我們使用 10,000 張皮膚病灶影像訓練一個用於分類可視可偵測疾病 (VDD) 的模型。然後將模型權重卸載到配備網路攝影機的 Raspberry Pi，用於在沒有網路存取的情況下分類皮膚病灶。結果發現，已開發的原型達到 78% 的測試準確度和 1.08 的測試損失。

##### **Federated Fairness Analytics: Quantifying Fairness in Federated Learning**
2408.08214v1 by Oscar Dilley, Juan Marcelo Parra-Ullauri, Rasheed Hussain, Dimitra Simeonidou

Federated Learning (FL) is a privacy-enhancing technology for distributed ML.
By training models locally and aggregating updates - a federation learns
together, while bypassing centralised data collection. FL is increasingly
popular in healthcare, finance and personal computing. However, it inherits
fairness challenges from classical ML and introduces new ones, resulting from
differences in data quality, client participation, communication constraints,
aggregation methods and underlying hardware. Fairness remains an unresolved
issue in FL and the community has identified an absence of succinct definitions
and metrics to quantify fairness; to address this, we propose Federated
Fairness Analytics - a methodology for measuring fairness. Our definition of
fairness comprises four notions with novel, corresponding metrics. They are
symptomatically defined and leverage techniques originating from XAI,
cooperative game-theory and networking engineering. We tested a range of
experimental settings, varying the FL approach, ML task and data settings. The
results show that statistical heterogeneity and client participation affect
fairness and fairness conscious approaches such as Ditto and q-FedAvg
marginally improve fairness-performance trade-offs. Using our techniques, FL
practitioners can uncover previously unobtainable insights into their system's
fairness, at differing levels of granularity in order to address fairness
challenges in FL. We have open-sourced our work at:
https://github.com/oscardilley/federated-fairness.

摘要：<paragraph>聯邦學習 (FL) 是一種增強隱私的分布式機器學習技術。
透過在本地訓練模型並彙總更新，聯盟可以共同學習，同時繞過集中式資料收集。FL 在醫療保健、金融和個人運算中越來越受歡迎。然而，它繼承了傳統機器學習的公平性挑戰，並引入了新的挑戰，這些挑戰源於資料品質、客戶端參與、通訊限制、彙總方法和基礎硬體的差異。公平性仍然是 FL 中一個尚未解決的問題，而社群已發現缺乏簡潔的定義和衡量公平性的指標；為了解決這個問題，我們提出聯邦公平性分析，一種用於衡量公平性的方法。我們對公平性的定義包含四個概念，並有新穎的對應指標。它們被症狀性地定義，並利用源自 XAI、合作博弈論和網路工程的技術。我們測試了一系列實驗設定，改變了 FL 方法、機器學習任務和資料設定。結果表明，統計異質性和客戶端參與會影響公平性，而重視公平性的方法，例如 Ditto 和 q-FedAvg，則會略微改善公平性與效能的權衡。透過使用我們的技術，FL 從業人員可以發掘以前無法獲得的對其系統公平性的見解，在不同的細化層級中，以解決 FL 中的公平性挑戰。我們已在以下位置開放原始碼：
https://github.com/oscardilley/federated-fairness。</paragraph>

##### **Covert Bias: The Severity of Social Views' Unalignment Towards Implicit and Explicit Opinion**
2408.08212v1 by Abeer Aldayel, Areej Alokaili, Rehab Alahmadi

While various approaches have recently been studied for bias identification,
little is known about how implicit language that does not explicitly convey a
viewpoint affects bias amplification in large language models.To examine the
severity of bias toward a view, we evaluated the performance of two downstream
tasks where the implicit and explicit knowledge of social groups were used.
First, we present a stress test evaluation by using a biased model in edge
cases of excessive bias scenarios. Then, we evaluate how LLMs calibrate
linguistically in response to both implicit and explicit opinions when they are
aligned with conflicting viewpoints. Our findings reveal a discrepancy in LLM
performance in identifying implicit and explicit opinions, with a general
tendency of bias toward explicit opinions of opposing stances. Moreover, the
bias-aligned models generate more cautious responses using uncertainty phrases
compared to the unaligned (zero-shot) base models. The direct, incautious
responses of the unaligned models suggest a need for further refinement of
decisiveness by incorporating uncertainty markers to enhance their reliability,
especially on socially nuanced topics with high subjectivity.

摘要：儘管最近已針對偏差辨識研究出各種方法，
但對於未明確傳達觀點的隱含語言如何影響大型語言模型中的偏差放大，目前所知甚少。為檢視觀點偏差的嚴重性，我們評估了兩個下游任務的效能，其中使用了社會群體的隱含和明確知識。
首先，我們使用有偏差模型在過度偏差情境的邊緣案例中，提出壓力測試評估。然後，我們評估 LLM 在與相互衝突的觀點一致時，如何對隱含和明確意見在語言上進行校準。我們的研究結果揭示了 LLM 在辨識隱含和明確意見方面的效能差異，通常傾向於對反對立場的明確意見產生偏差。此外，與未對齊（零次學習）基礎模型相比，偏差對齊模型使用不確定性詞彙產生更謹慎的回應。未對齊模型的直接、魯莽回應表明需要進一步改進決斷力，方法是加入不確定性標記以增強其可靠性，特別是在主觀性高的社會細微差別主題上。

##### **LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**
2408.08208v1 by Bohao Wang, Feng Liu, Jiawei Chen, Yudi Wu, Xingyu Lou, Jun Wang, Yan Feng, Chun Chen, Can Wang

Sequential recommendation systems fundamentally rely on users' historical
interaction sequences, which are often contaminated by noisy interactions.
Identifying these noisy interactions accurately without additional information
is particularly difficult due to the lack of explicit supervisory signals to
denote noise. Large Language Models (LLMs), equipped with extensive open
knowledge and semantic reasoning abilities, present a promising avenue to
bridge this information gap. However, employing LLMs for denoising in
sequential recommendation introduces notable challenges: 1) Direct application
of pretrained LLMs may not be competent for the denoising task, frequently
generating nonsensical responses; 2) Even after fine-tuning, the reliability of
LLM outputs remains questionable, especially given the complexity of the task
and th inherent hallucinatory issue of LLMs.
  To tackle these challenges, we propose LLM4DSR, a tailored approach for
denoising sequential recommendation using LLMs. We constructed a
self-supervised fine-tuning task to activate LLMs' capabilities to identify
noisy items and suggest replacements. Furthermore, we developed an uncertainty
estimation module that ensures only high-confidence responses are utilized for
sequence corrections. Remarkably, LLM4DSR is model-agnostic, allowing the
corrected sequences to be flexibly applied across various recommendation
models. Extensive experiments validate the superiority of LLM4DSR over existing
methods across three datasets and three recommendation backbones.

摘要：序列推薦系統基本上依賴於使用者的歷史互動序列，這些序列通常會受到雜訊互動的污染。由於缺乏明確的監督訊號來表示雜訊，因此在沒有額外資訊的情況下準確識別這些雜訊互動特別困難。具備廣泛開放知識和語義推理能力的大型語言模型 (LLM) 提供了一個有前途的途徑來彌補這個資訊差距。然而，在序列推薦中使用 LLM 來進行去雜訊會產生顯著的挑戰：1) 直接應用預訓練的 LLM 可能不勝任去雜訊任務，經常會產生無意義的回應；2) 即使在微調之後，LLM 輸出的可靠性仍然有待商榷，特別是考慮到任務的複雜性和 LLM 固有的幻覺問題。
為了應對這些挑戰，我們提出了 LLM4DSR，這是一種使用 LLM 對序列推薦進行去雜訊的客製化方法。我們建構了一個自我監督的微調任務，以啟動 LLM 識別雜訊項目並建議替換項目的能力。此外，我們開發了一個不確定性估計模組，以確保只有高信心的回應被用於序列校正。值得注意的是，LLM4DSR 與模型無關，允許在各種推薦模型中靈活地應用校正後的序列。廣泛的實驗驗證了 LLM4DSR 在三個資料集和三個推薦主幹上優於現有方法。

##### **Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**
2408.08188v1 by Shaojun Xu, Xusheng Luo, Yutong Huang, Letian Leng, Ruixuan Liu, Changliu Liu

Long-horizon planning is hindered by challenges such as uncertainty
accumulation, computational complexity, delayed rewards and incomplete
information. This work proposes an approach to exploit the task hierarchy from
human instructions to facilitate multi-robot planning. Using Large Language
Models (LLMs), we propose a two-step approach to translate multi-sentence
instructions into a structured language, Hierarchical Linear Temporal Logic
(LTL), which serves as a formal representation for planning. Initially, LLMs
transform the instructions into a hierarchical representation defined as
Hierarchical Task Tree, capturing the logical and temporal relations among
tasks. Following this, a domain-specific fine-tuning of LLM translates
sub-tasks of each task into flat LTL formulas, aggregating them to form
hierarchical LTL specifications. These specifications are then leveraged for
planning using off-the-shelf planners. Our framework not only bridges the gap
between instructions and algorithmic planning but also showcases the potential
of LLMs in harnessing hierarchical reasoning to automate multi-robot task
planning. Through evaluations in both simulation and real-world experiments
involving human participants, we demonstrate that our method can handle more
complex instructions compared to existing methods. The results indicate that
our approach achieves higher success rates and lower costs in multi-robot task
allocation and plan generation. Demos videos are available at
https://youtu.be/7WOrDKxIMIs .

摘要：長期規劃受到不確定性累積、計算複雜性、獎勵延遲和資訊不完整等挑戰所阻礙。本研究提出一個方法來利用人類指令中的任務階層，以促進多機器人規劃。我們使用大型語言模型 (LLM)，提出一個兩步驟的方法，將多句指令轉換成結構化語言，層級線性時序邏輯 (LTL)，作為規劃的正式表示。最初，LLM 將指令轉換成階層式表示，定義為階層任務樹，捕捉任務之間的邏輯和時間關係。在此之後，LLM 的特定領域微調將每個任務的子任務轉換成扁平 LTL 公式，彙總它們以形成階層式 LTL 規範。然後利用這些規範來使用現成的規劃器進行規劃。我們的框架不僅彌合了指令和演算法規劃之間的差距，還展示了 LLM 在利用階層式推理來自動化多機器人任務規劃中的潛力。透過在涉及人類參與者的模擬和真實世界實驗中進行評估，我們證明了我們的方法可以處理比現有方法更複雜的指令。結果表明，我們的方法在多機器人任務分配和計畫產生中實現了更高的成功率和更低的成本。示範影片可在 https://youtu.be/7WOrDKxIMIs 取得。

##### **Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**
2408.08182v1 by Qiushuo Cheng, Catherine Morgan, Arindam Sikdar, Alessandro Masullo, Alan Whone, Majid Mirmehdi

People with Parkinson's Disease (PD) often experience progressively worsening
gait, including changes in how they turn around, as the disease progresses.
Existing clinical rating tools are not capable of capturing hour-by-hour
variations of PD symptoms, as they are confined to brief assessments within
clinic settings. Measuring real-world gait turning angles continuously and
passively is a component step towards using gait characteristics as sensitive
indicators of disease progression in PD. This paper presents a deep
learning-based approach to automatically quantify turning angles by extracting
3D skeletons from videos and calculating the rotation of hip and knee joints.
We utilise state-of-the-art human pose estimation models, Fastpose and Strided
Transformer, on a total of 1386 turning video clips from 24 subjects (12 people
with PD and 12 healthy control volunteers), trimmed from a PD dataset of
unscripted free-living videos in a home-like setting (Turn-REMAP). We also
curate a turning video dataset, Turn-H3.6M, from the public Human3.6M human
pose benchmark with 3D ground truth, to further validate our method. Previous
gait research has primarily taken place in clinics or laboratories evaluating
scripted gait outcomes, but this work focuses on real-world settings where
complexities exist, such as baggy clothing and poor lighting. Due to
difficulties in obtaining accurate ground truth data in a free-living setting,
we quantise the angle into the nearest bin $45^\circ$ based on the manual
labelling of expert clinicians. Our method achieves a turning calculation
accuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\deg}, and a weighted
precision WPrec of 68.3% for Turn-REMAP. This is the first work to explore the
use of single monocular camera data to quantify turns by PD patients in a home
setting.

摘要：帕金森氏症 (PD) 患者经常会随着疾病的进展而出现步态逐渐恶化的现象，包括转身方式的变化。现有的临床评定工具无法捕捉到 PD 症状逐小时的变化，因为它们仅限于在临床环境中进行短暂的评估。连续被动地测量现实世界中的步态转弯角度是将步态特征用作 PD 疾病进展的敏感指标的组成部分。本文提出了一种基于深度学习的方法，通过从视频中提取 3D 骨架并计算髋关节和膝关节的旋转，自动量化转弯角度。我们对来自 24 个受试者（12 名 PD 患者和 12 名健康对照志愿者）的总共 1386 个转弯视频剪辑使用了最先进的人体姿势估计模型 Fastpose 和 Strided Transformer，这些剪辑是从家庭环境中无脚本自由生活视频的 PD 数据集（Turn-REMAP）中截取的。我们还从具有 3D 真实的公共 Human3.6M 人体姿势基准中整理了一个转弯视频数据集 Turn-H3.6M，以进一步验证我们的方法。以往的步态研究主要在评估脚本化步态结果的诊所或实验室中进行，但这项工作重点关注存在复杂性的现实世界环境，例如宽松的衣服和光线不足。由于在自由生活环境中难以获得准确的真实数据，我们根据专家临床医生的手动标记，将角度量化为最接近的箱 $45^\circ$。我们的方法对 Turn-REMAP 的转弯计算准确度达到 41.6%，平均绝对误差 (MAE) 为 34.7{\deg}，加权精度 WPrec 为 68.3%。这是首次探索使用单目单眼相机数据来量化 PD 患者在家中转弯情况的工作。

##### **Towards flexible perception with visual memory**
2408.08172v1 by Robert Geirhos, Priyank Jaini, Austin Stone, Sourabh Medapati, Xi Yi, George Toderici, Abhijit Ogale, Jonathon Shlens

Training a neural network is a monolithic endeavor, akin to carving knowledge
into stone: once the process is completed, editing the knowledge in a network
is nearly impossible, since all information is distributed across the network's
weights. We here explore a simple, compelling alternative by marrying the
representational power of deep neural networks with the flexibility of a
database. Decomposing the task of image classification into image similarity
(from a pre-trained embedding) and search (via fast nearest neighbor retrieval
from a knowledge database), we build a simple and flexible visual memory that
has the following key capabilities: (1.) The ability to flexibly add data
across scales: from individual samples all the way to entire classes and
billion-scale data; (2.) The ability to remove data through unlearning and
memory pruning; (3.) An interpretable decision-mechanism on which we can
intervene to control its behavior. Taken together, these capabilities
comprehensively demonstrate the benefits of an explicit visual memory. We hope
that it might contribute to a conversation on how knowledge should be
represented in deep vision models -- beyond carving it in ``stone'' weights.

摘要：训练神经网络是一项整体性的工作，就像将知识刻在石头上：一旦完成该过程，就几乎不可能编辑网络中的知识，因为所有信息都分布在网络的权重中。我们在这里通过将深度神经网络的表征能力与数据库的灵活性相结合，探索一种简单而有吸引力的替代方案。将图像分类任务分解为图像相似性（来自预训练嵌入）和搜索（通过从知识数据库中快速检索最近邻），我们构建了一个简单而灵活的视觉记忆，它具有以下关键功能：(1.) 能够灵活地跨尺度添加数据：从单个样本到整个类别和数十亿规模的数据；(2.) 能够通过取消学习和内存剪枝来删除数据；(3.) 一种可解释的决策机制，我们可以干预它以控制其行为。综合起来，这些功能全面展示了显式视觉记忆的好处。我们希望它可以促进关于知识如何在深度视觉模型中表示的对话——不仅仅是将其刻在“石头”权重中。

##### **General-purpose Clothes Manipulation with Semantic Keypoints**
2408.08160v1 by Yuhong Deng, David Hsu

We have seen much recent progress in task-specific clothes manipulation, but
generalizable clothes manipulation is still a challenge. Clothes manipulation
requires sequential actions, making it challenging to generalize to unseen
tasks. Besides, a general clothes state representation method is crucial. In
this paper, we adopt language instructions to specify and decompose clothes
manipulation tasks, and propose a large language model based hierarchical
learning method to enhance generalization. For state representation, we use
semantic keypoints to capture the geometry of clothes and outline their
manipulation methods. Simulation experiments show that the proposed method
outperforms the baseline method in terms of success rate and generalization for
clothes manipulation tasks.

摘要：我們已經在特定任務的服裝操作中看到許多近期的進步，但可概化的服裝操作仍然是一項挑戰。服裝操作需要循序漸進的動作，這使得概化到未見過的任務變得具有挑戰性。此外，一個通用的服裝狀態表示方法至關重要。在本文中，我們採用語言指令來指定和分解服裝操作任務，並提出一個基於大型語言模型的分層學習方法來增強概化。對於狀態表示，我們使用語義關鍵點來捕捉服裝的幾何形狀，並概述其操作方法。模擬實驗表明，所提出的方法在成功率和服裝操作任務的概化方面優於基線方法。

##### **DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search**
2408.08152v1 by Huajian Xin, Z. Z. Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, Wenjun Gao, Qihao Zhu, Dejian Yang, Zhibin Gou, Z. F. Wu, Fuli Luo, Chong Ruan

We introduce DeepSeek-Prover-V1.5, an open-source language model designed for
theorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both
training and inference processes. Pre-trained on DeepSeekMath-Base with
specialization in formal mathematical languages, the model undergoes supervised
fine-tuning using an enhanced formal theorem proving dataset derived from
DeepSeek-Prover-V1. Further refinement is achieved through reinforcement
learning from proof assistant feedback (RLPAF). Beyond the single-pass
whole-proof generation approach of DeepSeek-Prover-V1, we propose RMaxTS, a
variant of Monte-Carlo tree search that employs an intrinsic-reward-driven
exploration strategy to generate diverse proof paths. DeepSeek-Prover-V1.5
demonstrates significant improvements over DeepSeek-Prover-V1, achieving new
state-of-the-art results on the test set of the high school level miniF2F
benchmark ($63.5\%$) and the undergraduate level ProofNet benchmark ($25.3\%$).

摘要：我們推出 DeepSeek-Prover-V1.5，這是一個開放原始碼語言模型，專為 Lean 4 中的定理證明而設計，透過最佳化訓練和推論流程來增強 DeepSeek-Prover-V1。預先訓練於 DeepSeekMath-Base 中，專精於形式化數學語言，該模型使用從 DeepSeek-Prover-V1 衍生的增強式形式化定理證明資料集進行監督式微調。透過證明輔助回饋（RLPAF）中的強化學習進一步精進。除了 DeepSeek-Prover-V1 的單次全證明產生方法外，我們提出 RMaxTS，一種蒙地卡羅樹搜尋的變體，採用內在回饋驅動的探索策略來產生多樣化的證明路徑。DeepSeek-Prover-V1.5 證明了相較於 DeepSeek-Prover-V1 有顯著的進步，在高中程度的 miniF2F 基準測試組中取得新的最先進成果（63.5%），以及大學程度的 ProofNet 基準測試組中（25.3%）。

##### **Winning Snake: Design Choices in Multi-Shot ASP**
2408.08150v1 by Elisa Böhl, Stefan Ellmauthaler, Sarah Alice Gaggl

Answer set programming is a well-understood and established problem-solving
and knowledge representation paradigm. It has become more prominent amongst a
wider audience due to its multiple applications in science and industry. The
constant development of advanced programming and modeling techniques extends
the toolset for developers and users regularly. This paper demonstrates
different techniques to reuse logic program parts (multi-shot) by solving the
arcade game snake. This game is particularly interesting because a victory can
be assured by solving the underlying NP-hard problem of Hamiltonian Cycles. We
will demonstrate five hands-on implementations in clingo and compare their
performance in an empirical evaluation. In addition, our implementation
utilizes clingraph to generate a simple yet informative image representation of
the game's progress.

摘要：答案集程式設計是一種理解良好且已建立的問題解決和知識表徵範例。由於其在科學和工業中的多重應用，它已在更廣泛的受眾中變得更加突出。先進程式設計和建模技術的持續發展定期擴展開發人員和使用者的工具組。本文展示了透過解決街機遊戲貪食蛇來重複使用邏輯程式部分（多重射擊）的不同技術。這個遊戲特別有趣，因為透過解決哈密頓迴路的 NP 難問題，可以確保勝利。我們將展示五個 clingo 的動手實作，並在經驗評估中比較它們的效能。此外，我們的實作利用 clingraph 產生遊戲進度的簡單且有資訊性的影像表徵。

##### **P/D-Serve: Serving Disaggregated Large Language Model at Scale**
2408.08147v1 by Yibo Jin, Tao Wang, Huimin Lin, Mingyang Song, Peiyang Li, Yipeng Ma, Yicheng Shan, Zhengfan Yuan, Cailong Li, Yajing Sun, Tiandeng Wu, Xing Chu, Ruizhi Huan, Li Ma, Xiao You, Wenting Zhou, Yunpeng Ye, Wen Liu, Xiangkun Xu, Yongsheng Zhang, Tiantian Dong, Jiawei Zhu, Zhe Wang, Xijian Ju, Jianxun Song, Haoliang Cheng, Xiaojing Li, Jiandong Ding, Hefei Guo, Zhengyong Zhang

Serving disaggregated large language models (LLMs) over tens of thousands of
xPU devices (GPUs or NPUs) with reliable performance faces multiple challenges.
1) Ignoring the diversity (various prefixes and tidal requests), treating all
the prompts in a mixed pool is inadequate. To facilitate the similarity per
scenario and minimize the inner mismatch on P/D (prefill and decoding)
processing, fine-grained organization is required, dynamically adjusting P/D
ratios for better performance. 2) Due to inaccurate estimation on workload
(queue status or maintained connections), the global scheduler easily incurs
unnecessary timeouts in prefill. 3) Block-fixed device-to-device (D2D) KVCache
transfer over cluster-level RDMA (remote direct memory access) fails to achieve
desired D2D utilization as expected. To overcome previous problems, this paper
proposes an end-to-end system P/D-Serve, complying with the paradigm of MLOps
(machine learning operations), which models end-to-end (E2E) P/D performance
and enables: 1) fine-grained P/D organization, mapping the service with RoCE
(RDMA over converged ethernet) as needed, to facilitate similar processing and
dynamic adjustments on P/D ratios; 2) on-demand forwarding upon rejections for
idle prefill, decoupling the scheduler from regular inaccurate reports and
local queues, to avoid timeouts in prefill; and 3) efficient KVCache transfer
via optimized D2D access. P/D-Serve is implemented upon Ascend and MindSpore,
has been deployed over tens of thousands of NPUs for more than eight months in
commercial use, and further achieves 60\%, 42\% and 46\% improvements on E2E
throughput, time-to-first-token (TTFT) SLO (service level objective) and D2D
transfer time. As the E2E system with optimizations, P/D-Serve achieves 6.7x
increase on throughput, compared with aggregated LLMs.

摘要：<paragraph>在數萬個 xPU 裝置（GPU 或 NPU）上提供具備可靠效能的分散式大型語言模型 (LLM)，會面臨多項挑戰。1) 忽略多樣性（各種前綴和潮汐要求），將所有提示視為混合池是不夠的。為了促進每個場景的相似性並最小化 P/D（預填和解碼）處理中的內部不匹配，需要細緻的組織，動態調整 P/D 比例以獲得更好的效能。2) 由於對工作負載（佇列狀態或維護連線）的估計不準確，因此全域排程器很容易在預填時造成不必要的逾時。3) 區塊固定的裝置對裝置 (D2D) KVCache 傳輸透過叢集層級的 RDMA（遠端直接記憶體存取）無法達到預期的理想 D2D 使用率。為了克服以前的問題，本文提出了一個端對端系統 P/D-Serve，符合 MLOps（機器學習作業）的範例，它建構了端對端 (E2E) P/D 效能，並啟用：1) 細緻的 P/D 組織，根據需要將服務對應到 RoCE（聚合乙太網路上的 RDMA），以促進類似的處理和 P/D 比例的動態調整；2) 在拒絕閒置預填時進行依需求轉發，將排程器從定期不準確的報告和本機佇列中分離出來，以避免預填逾時；3) 透過最佳化的 D2D 存取進行有效的 KVCache 傳輸。P/D-Serve 是在 Ascend 和 MindSpore 上實作的，已在數萬個 NPU 上部署超過八個月，在商業用途上進一步實現了 E2E 吞吐量、首次代幣時間 (TTFT) SLO（服務等級目標）和 D2D 傳輸時間分別提升了 60%、42% 和 46%。作為具備最佳化的 E2E 系統，P/D-Serve 在吞吐量上實現了 6.7 倍的提升，與聚集式 LLM 相比。</paragraph>

##### **KOALA: Enhancing Speculative Decoding for LLM via Multi-Layer Draft Heads with Adversarial Learning**
2408.08146v1 by Kaiqi Zhang, Jing Zhao, Rui Chen

Large Language Models (LLMs) exhibit high inference latency due to their
autoregressive decoding nature. While the draft head in speculative decoding
mitigates this issue, its full potential remains unexplored. In this paper, we
introduce KOALA (K-layer Optimized Adversarial Learning Architecture), an
orthogonal approach to the draft head. By transforming the conventional
single-layer draft head into a multi-layer architecture and incorporating
adversarial learning into the traditional supervised training, KOALA
significantly improves the accuracy of the draft head in predicting subsequent
tokens, thus more closely mirroring the functionality of LLMs. Although this
improvement comes at the cost of slightly increased drafting overhead, KOALA
substantially unlocks the draft head's potential, greatly enhancing speculative
decoding. We conducted comprehensive evaluations of KOALA, including both
autoregressive and non-autoregressive draft heads across various tasks,
demonstrating a latency speedup ratio improvement of 0.24x-0.41x, which is
10.57%-14.09% faster than the original draft heads.

摘要：大型語言模型（LLM）由於其自迴歸解碼性質而展現出高推論延遲。雖然推測解碼中的草稿頭緩解了這個問題，但其全部潛力仍未被探索。在本文中，我們引入了 KOALA（K 層最佳化對抗學習架構），這是一種與草稿頭正交的方法。透過將傳統的單層草稿頭轉換成多層架構，並將對抗學習納入傳統的監督訓練中，KOALA 大幅提升了草稿頭在預測後續符號時的準確度，因此更接近於反映 LLM 的功能。雖然這種改進是以略微增加的草稿開銷為代價，但 KOALA 大幅解鎖了草稿頭的潛力，極大地增強了推測解碼。我們對 KOALA 進行了全面的評估，包括各種任務中的自迴歸和非自迴歸草稿頭，證明延遲加速比改進了 0.24x-0.41x，比原始草稿頭快了 10.57%-14.09%。

##### **Model-based Workflow for the Automated Generation of PDDL Descriptions**
2408.08145v1 by Hamied Nabizada, Tom Jeleniewski, Felix Gehlhoff, Alexander Fay

Manually creating Planning Domain Definition Language (PDDL) descriptions is
difficult, error-prone, and requires extensive expert knowledge. However, this
knowledge is already embedded in engineering models and can be reused.
Therefore, this contribution presents a comprehensive workflow for the
automated generation of PDDL descriptions from integrated system and product
models. The proposed workflow leverages Model-Based Systems Engineering (MBSE)
to organize and manage system and product information, translating it
automatically into PDDL syntax for planning purposes. By connecting system and
product models with planning aspects, it ensures that changes in these models
are quickly reflected in updated PDDL descriptions, facilitating efficient and
adaptable planning processes. The workflow is validated within a use case from
aircraft assembly.

摘要：手動建立規劃領域定義語言 (PDDL) 描述非常困難、容易出錯，且需要廣泛的專業知識。然而，這些知識已經內嵌在工程模型中，且可重複使用。因此，本貢獻提出一個全面的工作流程，用於從整合的系統和產品模型自動產生 PDDL 描述。建議的工作流程利用模型基礎系統工程 (MBSE) 來組織和管理系統和產品資訊，並將其自動轉譯為 PDDL 語法，以進行規劃。藉由將系統和產品模型與規劃面向連結，它確保這些模型的變更能快速反映在更新的 PDDL 描述中，進而促進有效且適應性強的規劃流程。工作流程在飛機組裝的使用案例中得到驗證。

##### **MIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for Multi-turn NLU**
2408.08144v1 by Yan Li, So-Eon Kim, Seong-Bae Park, Soyeon Caren Han

Although Large Language Models(LLMs) can generate coherent and contextually
relevant text, they often struggle to recognise the intent behind the human
user's query. Natural Language Understanding (NLU) models, however, interpret
the purpose and key information of user's input to enable responsive
interactions. Existing NLU models generally map individual utterances to a
dual-level semantic frame, involving sentence-level intent and word-level slot
labels. However, real-life conversations primarily consist of multi-turn
conversations, involving the interpretation of complex and extended dialogues.
Researchers encounter challenges addressing all facets of multi-turn dialogue
conversations using a unified single NLU model. This paper introduces a novel
approach, MIDAS, leveraging a multi-level intent, domain, and slot knowledge
distillation for multi-turn NLU. To achieve this, we construct distinct
teachers for varying levels of conversation knowledge, namely, sentence-level
intent detection, word-level slot filling, and conversation-level domain
classification. These teachers are then fine-tuned to acquire specific
knowledge of their designated levels. A multi-teacher loss is proposed to
facilitate the combination of these multi-level teachers, guiding a student
model in multi-turn dialogue tasks. The experimental results demonstrate the
efficacy of our model in improving the overall multi-turn conversation
understanding, showcasing the potential for advancements in NLU models through
the incorporation of multi-level dialogue knowledge distillation techniques.

摘要：儘管大型語言模型 (LLM) 能產生連貫且與脈絡相關的文字，但它們通常難以辨識人類使用者查詢背後的意圖。然而，自然語言理解 (NLU) 模型會詮釋使用者輸入的目的和關鍵資訊，以促成回應式的互動。現有的 NLU 模型通常會將個別語句對應到雙層語意架構，包含句子層級的意圖和詞彙層級的槽標籤。然而，現實生活中的對話主要由多輪對話組成，包含對複雜且延伸對話的詮釋。研究人員在使用統一的單一 NLU 模型處理多輪對話對話的所有面向時，會遭遇挑戰。本文介紹一種創新的方法，MIDAS，利用多層級意圖、領域和槽知識提煉，進行多輪 NLU。為達成此目的，我們針對不同層級的對話知識建構不同的教師，即句子層級的意圖偵測、詞彙層級的槽填補，以及對話層級的領域分類。接著微調這些教師，以習得其指定層級的特定知識。提出多教師損失，以促進這些多層級教師的結合，在多輪對話任務中引導學生模型。實驗結果證明了我們的模型在改善整體多輪對話理解上的效能，展示了透過整合多層級對話知識提煉技術，在 NLU 模型中進步的潛力。

##### **Multimodal Causal Reasoning Benchmark: Challenging Vision Large Language Models to Infer Causal Links Between Siamese Images**
2408.08105v1 by Zhiyuan Li, Heng Wang, Dongnan Liu, Chaoyi Zhang, Ao Ma, Jieting Long, Weidong Cai

Large Language Models (LLMs) have showcased exceptional ability in causal
reasoning from textual information. However, will these causalities remain
straightforward for Vision Large Language Models (VLLMs) when only visual hints
are provided? Motivated by this, we propose a novel Multimodal Causal Reasoning
benchmark, namely MuCR, to challenge VLLMs to infer semantic cause-and-effect
relationship when solely relying on visual cues such as action, appearance,
clothing, and environment. Specifically, we introduce a prompt-driven image
synthesis approach to create siamese images with embedded semantic causality
and visual cues, which can effectively evaluate VLLMs' causal reasoning
capabilities. Additionally, we develop tailored metrics from multiple
perspectives, including image-level match, phrase-level understanding, and
sentence-level explanation, to comprehensively assess VLLMs' comprehension
abilities. Our extensive experiments reveal that the current state-of-the-art
VLLMs are not as skilled at multimodal causal reasoning as we might have hoped.
Furthermore, we perform a comprehensive analysis to understand these models'
shortcomings from different views and suggest directions for future research.
We hope MuCR can serve as a valuable resource and foundational benchmark in
multimodal causal reasoning research. The project is available at:
https://github.com/Zhiyuan-Li-John/MuCR

摘要：大型語言模型 (LLM) 已展現出從文字資訊進行因果推理的非凡能力。然而，當僅提供視覺提示時，這些因果關係對於視覺大型語言模型 (VLLM) 來說是否仍然直截了當？受此啟發，我們提出了一個新穎的多模態因果推理基準，即 MuCR，以挑戰 VLLM 在僅依賴動作、外觀、服裝和環境等視覺線索時推斷語義因果關係。具體來說，我們引入了一個提示驅動的影像合成方法，以建立具有嵌入式語義因果關係和視覺線索的連體影像，這可以有效評估 VLLM 的因果推理能力。此外，我們從多個角度開發了量身定制的指標，包括影像層級比對、詞組層級理解和句子層級解釋，以全面評估 VLLM 的理解能力。我們廣泛的實驗表明，當前最先進的 VLLM 在多模態因果推理方面並不如我們所希望的那麼熟練。此外，我們進行了全面的分析，以從不同的觀點了解這些模型的缺點，並提出未來研究的方向。我們希望 MuCR 能夠作為多模態因果推理研究中一個有價值的資源和基礎基準。此專案可在以下網址取得：
https://github.com/Zhiyuan-Li-John/MuCR

##### **AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents**
2408.08089v1 by Guhong Chen, Liyang Fan, Zihan Gong, Nan Xie, Zixuan Li, Ziqiang Liu, Chengming Li, Qiang Qu, Shiwen Ni, Min Yang

In this paper, we present a simulation system called AgentCourt that
simulates the entire courtroom process. The judge, plaintiff's lawyer, defense
lawyer, and other participants are autonomous agents driven by large language
models (LLMs). Our core goal is to enable lawyer agents to learn how to argue a
case, as well as improving their overall legal skills, through courtroom
process simulation. To achieve this goal, we propose an adversarial
evolutionary approach for the lawyer-agent. Since AgentCourt can simulate the
occurrence and development of court hearings based on a knowledge base and LLM,
the lawyer agents can continuously learn and accumulate experience from real
court cases. The simulation experiments show that after two lawyer-agents have
engaged in a thousand adversarial legal cases in AgentCourt (which can take a
decade for real-world lawyers), compared to their pre-evolutionary state, the
evolved lawyer agents exhibit consistent improvement in their ability to handle
legal tasks. To enhance the credibility of our experimental results, we
enlisted a panel of professional lawyers to evaluate our simulations. The
evaluation indicates that the evolved lawyer agents exhibit notable
advancements in responsiveness, as well as expertise and logical rigor. This
work paves the way for advancing LLM-driven agent technology in legal
scenarios. Code is available at https://github.com/relic-yuexi/AgentCourt.

摘要：<paragraph>在本文中，我們展示了一個名為 AgentCourt 的模擬系統，它模擬了整個法庭程序。法官、原告律師、辯護律師和其他參與者都是由大型語言模型 (LLM) 驅動的自主代理。我們的核心目標是讓律師代理學習如何論證一個案件，並通過法庭程序模擬來提高他們的整體法律技能。為了實現這一目標，我們提出了律師代理的對抗性進化方法。由於 AgentCourt 可以根據知識庫和 LLM 模擬法庭聽證會的發生和發展，律師代理可以不斷學習和累積來自真實法庭案件的經驗。模擬實驗表明，在兩位律師代理在 AgentCourt 中參與了一千場對抗性法律案件（這可能需要現實世界中的律師十年時間）後，與他們進化前的狀態相比，進化的律師代理在處理法律任務的能力方面表現出持續的改進。為了增強我們實驗結果的可信度，我們聘請了一組專業律師來評估我們的模擬。評估表明，進化的律師代理在響應能力、專業知識和邏輯嚴謹性方面表現出顯著的進步。這項工作為推進法律場景中的 LLM 驅動代理技術鋪平了道路。代碼可在 https://github.com/relic-yuexi/AgentCourt 獲得。</paragraph>

##### **An Efficient Replay for Class-Incremental Learning with Pre-trained Models**
2408.08084v1 by Weimin Yin, Bin Chen adn Chunzhao Xie, Zhenhao Tan

In general class-incremental learning, researchers typically use sample sets
as a tool to avoid catastrophic forgetting during continuous learning. At the
same time, researchers have also noted the differences between
class-incremental learning and Oracle training and have attempted to make
corrections. In recent years, researchers have begun to develop
class-incremental learning algorithms utilizing pre-trained models, achieving
significant results. This paper observes that in class-incremental learning,
the steady state among the weight guided by each class center is disrupted,
which is significantly correlated with catastrophic forgetting. Based on this,
we propose a new method to overcoming forgetting . In some cases, by retaining
only a single sample unit of each class in memory for replay and applying
simple gradient constraints, very good results can be achieved. Experimental
results indicate that under the condition of pre-trained models, our method can
achieve competitive performance with very low computational cost and by simply
using the cross-entropy loss.

摘要：在一般的類別增量學習中，研究人員通常使用樣本集作為一種工具，以避免在持續學習過程中發生災難性遺忘。同時，研究人員也注意到了類別增量學習和 Oracle 訓練之間的差異，並嘗試進行修正。近年來，研究人員已開始開發利用預訓練模型的類別增量學習演算法，並取得了顯著的成果。本文觀察到在類別增量學習中，由每個類別中心引導的權重之間的穩態會被破壞，這與災難性遺忘有顯著相關性。基於此，我們提出了一種克服遺忘的新方法。在某些情況下，通過僅保留每個類別的單個樣本單元進行重播，並應用簡單的梯度約束，就可以取得非常好的結果。實驗結果表明，在預訓練模型的條件下，我們的模型僅通過使用交叉熵損失，就可以在非常低的計算成本下實現具有競爭力的效能。

##### **Confidence-weighted integration of human and machine judgments for superior decision-making**
2408.08083v1 by Felipe Yáñez, Xiaoliang Luo, Omar Valerio Minero, Bradley C. Love

Large language models (LLMs) have emerged as powerful tools in various
domains. Recent studies have shown that LLMs can surpass humans in certain
tasks, such as predicting the outcomes of neuroscience studies. What role does
this leave for humans in the overall decision process? One possibility is that
humans, despite performing worse than LLMs, can still add value when teamed
with them. A human and machine team can surpass each individual teammate when
team members' confidence is well-calibrated and team members diverge in which
tasks they find difficult (i.e., calibration and diversity are needed). We
simplified and extended a Bayesian approach to combining judgments using a
logistic regression framework that integrates confidence-weighted judgments for
any number of team members. Using this straightforward method, we demonstrated
in a neuroscience forecasting task that, even when humans were inferior to
LLMs, their combination with one or more LLMs consistently improved team
performance. Our hope is that this simple and effective strategy for
integrating the judgments of humans and machines will lead to productive
collaborations.

摘要：大型語言模型 (LLM) 已成為各種領域中強大的工具。最近的研究表明，LLM 在某些任務中可以超越人類，例如預測神經科學研究的結果。這對人類在整體決策過程中扮演什麼角色？一種可能性是，儘管人類的表現不如 LLM，但與 LLM 組隊時仍然可以增加價值。當團隊成員的信心經過良好校準，而且團隊成員發現困難的任務各不相同時，人類和機器團隊可以超越每個個別團隊成員（即需要校準和多樣性）。我們簡化並擴展了一種貝氏方法，使用邏輯迴歸框架結合判斷，該框架整合了任意數量的團隊成員的信心加權判斷。使用這種直接的方法，我們在神經科學預測任務中證明，即使人類不如 LLM，但將其與一個或多個 LLM 結合使用，始終可以改善團隊績效。我們希望這種簡單有效的策略，用於整合人類和機器判斷，將帶來富有成效的協作。

##### **Extracting Sentence Embeddings from Pretrained Transformer Models**
2408.08073v1 by Lukas Stankevičius, Mantas Lukoševičius

Background/introduction: Pre-trained transformer models shine in many natural
language processing tasks and therefore are expected to bear the representation
of the input sentence or text meaning. These sentence-level embeddings are also
important in retrieval-augmented generation. But do commonly used plain
averaging or prompt templates surface it enough?
  Methods: Given 110M parameters BERT's hidden representations from multiple
layers and multiple tokens we tried various ways to extract optimal sentence
representations. We tested various token aggregation and representation
post-processing techniques. We also tested multiple ways of using a general
Wikitext dataset to complement BERTs sentence representations. All methods were
tested on 8 Semantic Textual Similarity (STS), 6 short text clustering, and 12
classification tasks. We also evaluated our representation-shaping techniques
on other static models, including random token representations.
  Results: Proposed representation extraction methods improved the performance
on STS and clustering tasks for all models considered. Very high improvements
for static token-based models, especially random embeddings for STS tasks
almost reach the performance of BERT-derived representations.
  Conclusions: Our work shows that for multiple tasks simple baselines with
representation shaping techniques reach or even outperform more complex
BERT-based models or are able to contribute to their performance.

摘要：背景/引言：预训练的 Transformer 模型在许多自然语言处理任务中表现出色，因此有望承载输入句子的表示或文本含义。这些句子级嵌入在检索增强生成中也很重要。但常用的纯平均或提示模板是否足以表述它？
方法：给定 1.1 亿个参数，BERT 从多层和多个标记中隐藏表示，我们尝试了多种方法来提取最佳句子表示。我们测试了各种标记聚合和表示后处理技术。我们还测试了多种使用通用 Wikitext 数据集来补充 BERT 句子表示的方法。所有方法均在 8 个语义文本相似性 (STS)、6 个短文本聚类和 12 个分类任务上进行了测试。我们还对其他静态模型（包括随机标记表示）评估了我们的表示塑造技术。
结果：提出的表示提取方法提高了所有考虑的模型在 STS 和聚类任务上的性能。对于基于静态标记的模型有非常高的改进，特别是 STS 任务的随机嵌入几乎达到 BERT 衍生表示的性能。
结论：我们的工作表明，对于多个任务，带有表示塑造技术的简单基线达到或甚至优于更复杂的基于 BERT 的模型，或者能够提升它们的性能。

##### **I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm**
2408.08072v1 by Yiming Liang, Ge Zhang, Xingwei Qu, Tianyu Zheng, Jiawei Guo, Xinrun Du, Zhenzhu Yang, Jiaheng Liu, Chenghua Lin, Lei Ma, Wenhao Huang, Jiajun Zhang

Large Language Models (LLMs) have achieved significant advancements, however,
the common learning paradigm treats LLMs as passive information repositories,
neglecting their potential for active learning and alignment. Some approaches
train LLMs using their own generated synthetic data, exploring the possibility
of active alignment. However, there is still a huge gap between these one-time
alignment methods and the continuous automatic alignment of humans. In this
paper, we introduce \textbf{I-SHEEP}, an \textbf{I}terative
\textbf{S}elf-En\textbf{H}anc\textbf{E}m\textbf{E}nt \textbf{P}aradigm.This
human-like paradigm enables LLMs to \textbf{continuously self-align from
scratch with nothing}. Compared to the one-time alignment method Dromedary
\cite{sun2023principledriven}, which refers to the first iteration in this
paper, I-SHEEP can significantly enhance capacities on both Qwen and Llama
models. I-SHEEP achieves a maximum relative improvement of 78.2\% in the Alpaca
Eval, 24.0\% in the MT Bench, and an absolute increase of 8.88\% in the IFEval
accuracy over subsequent iterations in Qwen-1.5 72B model. Additionally,
I-SHEEP surpasses the base model in various standard benchmark generation
tasks, achieving an average improvement of 24.77\% in code generation tasks,
12.04\% in TrivialQA, and 20.29\% in SQuAD. We also provide new insights based
on the experiment results. Our codes, datasets, and models are available at
\textbf{https://anonymous.4open.science/r/I-SHEEP}.

摘要：大型語言模型 (LLM) 已取得重大進展，然而，
通用的學習範例將 LLM 視為被動式資訊儲存庫，
忽略它們主動學習和對齊的潛力。一些方法
使用 LLM 自行產生的合成資料訓練 LLM，探索主動對齊的可能性。
然而，這些一次性的對齊方法與人類的持續自動對齊之間仍有很大差距。在本文中，我們介紹了\textbf{I-SHEEP}，一個\textbf{I}terative\textbf{S}elf-En\textbf{H}anc\textbf{E}m\textbf{E}nt \textbf{P}aradigm。這個
類似人類的範例使 LLM 能夠\textbf{從頭開始持續自我對齊，而無需任何東西}。與一次性對齊方法 Dromedary 相比
\cite{sun2023principledriven}，這是本文中的第一次迭代，I-SHEEP 可以顯著提升 Qwen 和 Llama 模型的容量。I-SHEEP 在 Alpaca Eval 中實現了 78.2% 的最大相對改進，在 MT Bench 中實現了 24.0% 的最大相對改進，並且在 Qwen-1.5 72B 模型的後續迭代中，IFEval 的準確度絕對提高了 8.88%。此外，
I-SHEEP 在各種標準基準生成任務中超越了基礎模型，在程式碼生成任務中實現了 24.77% 的平均改進，在 TrivialQA 中實現了 12.04% 的平均改進，在 SQuAD 中實現了 20.29% 的平均改進。我們也根據實驗結果提供了新的見解。我們的程式碼、資料集和模型可以在以下位置取得：
\textbf{https://anonymous.4open.science/r/I-SHEEP}。

##### **SPEED: Scalable Preprocessing of EEG Data for Self-Supervised Learning**
2408.08065v1 by Anders Gjølbye, Lina Skerath, William Lehn-Schiøler, Nicolas Langer, Lars Kai Hansen

Electroencephalography (EEG) research typically focuses on tasks with
narrowly defined objectives, but recent studies are expanding into the use of
unlabeled data within larger models, aiming for a broader range of
applications. This addresses a critical challenge in EEG research. For example,
Kostas et al. (2021) show that self-supervised learning (SSL) outperforms
traditional supervised methods. Given the high noise levels in EEG data, we
argue that further improvements are possible with additional preprocessing.
Current preprocessing methods often fail to efficiently manage the large data
volumes required for SSL, due to their lack of optimization, reliance on
subjective manual corrections, and validation processes or inflexible protocols
that limit SSL. We propose a Python-based EEG preprocessing pipeline optimized
for self-supervised learning, designed to efficiently process large-scale data.
This optimization not only stabilizes self-supervised training but also
enhances performance on downstream tasks compared to training with raw data.

摘要：腦電圖 (EEG) 研究通常專注於目標定義狹隘的任務，但最近的研究正擴展到在較大的模型中使用未標註資料，目標是應用在更廣泛的範圍。這解決了 EEG 研究中一個關鍵的挑戰。例如，Kostas 等人 (2021) 顯示自監督式學習 (SSL) 優於傳統的監督式方法。考量到 EEG 資料中的高雜訊等級，我們認為透過額外的預處理，可以進一步改善。目前的預處理方法通常無法有效管理 SSL 所需的大量資料量，因為它們缺乏最佳化、依賴主觀的手動修正，以及限制 SSL 的驗證流程或不靈活的協定。我們提出一個以 Python 為基礎的 EEG 預處理管線，針對自監督式學習進行最佳化，旨在有效處理大規模資料。這種最佳化不僅能穩定自監督式訓練，還能提升下游任務的效能，優於使用原始資料訓練。

##### **Navigating Data Scarcity using Foundation Models: A Benchmark of Few-Shot and Zero-Shot Learning Approaches in Medical Imaging**
2408.08058v1 by Stefano Woerner, Christian F. Baumgartner

Data scarcity is a major limiting factor for applying modern machine learning
techniques to clinical tasks. Although sufficient data exists for some
well-studied medical tasks, there remains a long tail of clinically relevant
tasks with poor data availability. Recently, numerous foundation models have
demonstrated high suitability for few-shot learning (FSL) and zero-shot
learning (ZSL), potentially making them more accessible to practitioners.
However, it remains unclear which foundation model performs best on FSL medical
image analysis tasks and what the optimal methods are for learning from limited
data. We conducted a comprehensive benchmark study of ZSL and FSL using 16
pretrained foundation models on 19 diverse medical imaging datasets. Our
results indicate that BiomedCLIP, a model pretrained exclusively on medical
data, performs best on average for very small training set sizes, while very
large CLIP models pretrained on LAION-2B perform best with slightly more
training samples. However, simply fine-tuning a ResNet-18 pretrained on
ImageNet performs similarly with more than five training examples per class.
Our findings also highlight the need for further research on foundation models
specifically tailored for medical applications and the collection of more
datasets to train these models.

摘要：資料稀少是將現代機器學習技術應用於臨床任務的主要限制因素。儘管對於一些研究完善的醫療任務而言存在足夠的資料，但仍有許多臨床相關任務的資料可用性不佳。最近，許多基礎模型已展現出非常適合小樣本學習 (FSL) 和零樣本學習 (ZSL)，這有可能讓從業人員更容易使用這些模型。然而，目前仍不清楚哪個基礎模型在 FSL 醫學影像分析任務中的表現最佳，以及從有限資料中學習的最佳方法為何。我們針對 16 個預訓練基礎模型在 19 個不同的醫學影像資料集上執行了一項全面的 ZSL 和 FSL 基準研究。我們的結果顯示，一個專門針對醫療資料進行預訓練的模型 BiomedCLIP 在非常小的訓練集大小下表現最佳，而針對 LAION-2B 進行預訓練的非常大型 CLIP 模型在訓練樣本稍多的情況下表現最佳。然而，針對 ImageNet 進行預訓練的 ResNet-18 只要每類別有超過五個訓練範例，其微調表現就類似。我們的發現也凸顯了進一步針對醫療應用量身打造基礎模型以及收集更多資料集來訓練這些模型的研究需求。

##### **COTODE: COntinuous Trajectory neural Ordinary Differential Equations for modelling event sequences**
2408.08055v1 by Ilya Kuleshov, Galina Boeva, Vladislav Zhuzhel, Evgenia Romanenkova, Evgeni Vorsin, Alexey Zaytsev

Observation of the underlying actors that generate event sequences reveals
that they often evolve continuously. Most modern methods, however, tend to
model such processes through at most piecewise-continuous trajectories. To
address this, we adopt a way of viewing events not as standalone phenomena but
instead as observations of a Gaussian Process, which in turn governs the
actor's dynamics. We propose integrating these obtained dynamics, resulting in
a continuous-trajectory modification of the widely successful Neural ODE model.
Through Gaussian Process theory, we were able to evaluate the uncertainty in an
actor's representation, which arises from not observing them between events.
This estimate led us to develop a novel, theoretically backed negative feedback
mechanism. Empirical studies indicate that our model with Gaussian process
interpolation and negative feedback achieves state-of-the-art performance, with
improvements up to 20% AUROC against similar architectures.

摘要：觀察產生事件序列的底層行為者，可以發現它們經常持續地演化。然而，大多數現代方法傾向於透過至多分段連續的軌跡來建模這些過程。為了解決這個問題，我們採用一種將事件視為高斯過程的觀測，而不是獨立現象的方式，而高斯過程反過來控制行為者的動態。我們建議整合這些獲得的動態，從而對廣泛成功的 Neural ODE 模型進行連續軌跡修改。透過高斯過程理論，我們能夠評估行為者表徵中的不確定性，這源於在事件之間沒有觀察到它們。這個估計讓我們開發出一個新穎的、理論支持的負回饋機制。實證研究表明，我們採用高斯過程插值和負回饋的模型達到了最先進的效能，與類似架構相比，AUROC 提升了 20%。

##### **Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**
2408.08054v1 by Changyu Du, Sebastian Esser, Stavros Nousias, André Borrmann

The conventional BIM authoring process typically requires designers to master
complex and tedious modeling commands in order to materialize their design
intentions within BIM authoring tools. This additional cognitive burden
complicates the design process and hinders the adoption of BIM and model-based
design in the AEC (Architecture, Engineering, and Construction) industry. To
facilitate the expression of design intentions more intuitively, we propose
Text2BIM, an LLM-based multi-agent framework that can generate 3D building
models from natural language instructions. This framework orchestrates multiple
LLM agents to collaborate and reason, transforming textual user input into
imperative code that invokes the BIM authoring tool's APIs, thereby generating
editable BIM models with internal layouts, external envelopes, and semantic
information directly in the software. Furthermore, a rule-based model checker
is introduced into the agentic workflow, utilizing predefined domain knowledge
to guide the LLM agents in resolving issues within the generated models and
iteratively improving model quality. Extensive experiments were conducted to
compare and analyze the performance of three different LLMs under the proposed
framework. The evaluation results demonstrate that our approach can effectively
generate high-quality, structurally rational building models that are aligned
with the abstract concepts specified by user input. Finally, an interactive
software prototype was developed to integrate the framework into the BIM
authoring software Vectorworks, showcasing the potential of modeling by
chatting.

摘要：傳統的 BIM 創作過程通常要求設計師精通複雜且繁瑣的建模指令，才能在 BIM 創作工具中實現他們的設計意圖。這種額外的認知負擔會讓設計過程變得複雜，並阻礙 AEC（建築、工程和營造）產業採用 BIM 和基於模型的設計。為了更直觀地表達設計意圖，我們提出了 Text2BIM，這是一個基於 LLM 的多代理架構，可以從自然語言指令生成 3D 建築模型。此架構組織多個 LLM 代理進行協作和推理，將文本使用者輸入轉換為呼叫 BIM 創作工具 API 的命令式程式碼，從而直接在軟體中生成具有內部佈局、外部包覆和語義資訊的可編輯 BIM 模型。此外，將基於規則的模型檢查器引入代理工作流程，利用預定義的領域知識來引導 LLM 代理解決生成模型中的問題並反覆改善模型品質。進行了廣泛的實驗，以比較和分析在所提出的架構下三個不同 LLM 的效能。評估結果表明，我們的做法可以有效地生成與使用者輸入所指定的抽象概念相符的高品質、結構合理的建築模型。最後，開發了一個互動式軟體原型，將架構整合到 BIM 創作軟體 Vectorworks 中，展示了透過聊天進行建模的潛力。

##### **The Clever Hans Effect in Unsupervised Learning**
2408.08041v1 by Jacob Kauffmann, Jonas Dippel, Lukas Ruff, Wojciech Samek, Klaus-Robert Müller, Grégoire Montavon

Unsupervised learning has become an essential building block of AI systems.
The representations it produces, e.g. in foundation models, are critical to a
wide variety of downstream applications. It is therefore important to carefully
examine unsupervised models to ensure not only that they produce accurate
predictions, but also that these predictions are not "right for the wrong
reasons", the so-called Clever Hans (CH) effect. Using specially developed
Explainable AI techniques, we show for the first time that CH effects are
widespread in unsupervised learning. Our empirical findings are enriched by
theoretical insights, which interestingly point to inductive biases in the
unsupervised learning machine as a primary source of CH effects. Overall, our
work sheds light on unexplored risks associated with practical applications of
unsupervised learning and suggests ways to make unsupervised learning more
robust.

摘要：無監督式學習已成為人工智慧系統的基石。
它產生的表徵（例如在基礎模型中）對於廣泛的下游應用至關重要。因此，仔細檢查無監督式模型以確保它們不僅產生準確的預測，而且這些預測並非「錯誤的原因導致正確的結果」，也就是所謂的克萊佛漢斯 (CH) 效應，這非常重要。我們使用特別開發的可解釋人工智慧技術，首次證明 CH 效應在無監督式學習中普遍存在。我們的實證發現豐富了理論見解，有趣的是，這些見解指出無監督式學習機器中的歸納偏誤是 CH 效應的主要來源。總的來說，我們的研究揭露了與無監督式學習的實際應用相關的未知風險，並提出讓無監督式學習更強健的方法。

##### **Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words**
2408.08027v1 by Kento Nozawa, Takashi Masuko, Toru Taniguchi

We develop a large language model (LLM) based automatic speech recognition
(ASR) system that can be contextualized by providing keywords as prior
information in text prompts. We adopt decoder-only architecture and use our
in-house LLM, PLaMo-100B, pre-trained from scratch using datasets dominated by
Japanese and English texts as the decoder. We adopt a pre-trained Whisper
encoder as an audio encoder, and the audio embeddings from the audio encoder
are projected to the text embedding space by an adapter layer and concatenated
with text embeddings converted from text prompts to form inputs to the decoder.
By providing keywords as prior information in the text prompts, we can
contextualize our LLM-based ASR system without modifying the model architecture
to transcribe ambiguous words in the input audio accurately. Experimental
results demonstrate that providing keywords to the decoder can significantly
improve the recognition performance of rare and ambiguous words.

摘要：我們開發一個大型語言模型 (LLM) 為基礎的自動語音辨識 (ASR) 系統，可以透過提供關鍵字作為文字提示中的先驗資訊來進行情境化。我們採用僅解碼器架構，並使用我們內部的 LLM，PLaMo-100B，使用由日文和英文文本主導的資料集從頭開始預先訓練作為解碼器。我們採用預先訓練的 Whisper 編碼器作為音訊編碼器，而來自音訊編碼器的音訊嵌入會透過適配器層投影到文字嵌入空間，並與從文字提示轉換而來的文字嵌入串聯以形成解碼器的輸入。透過在文字提示中提供關鍵字作為先驗資訊，我們可以對我們的 LLM 為基礎的 ASR 系統進行情境化，而無需修改模型架構，以準確轉錄輸入音訊中的含糊字詞。實驗結果證明，提供關鍵字給解碼器可以顯著提升罕見和含糊字詞的辨識效能。

##### **Causal Discovery from Time-Series Data with Short-Term Invariance-Based Convolutional Neural Networks**
2408.08023v1 by Rujia Shen, Boran Wang, Chao Zhao, Yi Guan, Jingchi Jiang

Causal discovery from time-series data aims to capture both intra-slice
(contemporaneous) and inter-slice (time-lagged) causality between variables
within the temporal chain, which is crucial for various scientific disciplines.
Compared to causal discovery from non-time-series data, causal discovery from
time-series data necessitates more serialized samples with a larger amount of
observed time steps. To address the challenges, we propose a novel
gradient-based causal discovery approach STIC, which focuses on
\textbf{S}hort-\textbf{T}erm \textbf{I}nvariance using \textbf{C}onvolutional
neural networks to uncover the causal relationships from time-series data.
Specifically, STIC leverages both the short-term time and mechanism invariance
of causality within each window observation, which possesses the property of
independence, to enhance sample efficiency. Furthermore, we construct two
causal convolution kernels, which correspond to the short-term time and
mechanism invariance respectively, to estimate the window causal graph. To
demonstrate the necessity of convolutional neural networks for causal discovery
from time-series data, we theoretically derive the equivalence between
convolution and the underlying generative principle of time-series data under
the assumption that the additive noise model is identifiable. Experimental
evaluations conducted on both synthetic and FMRI benchmark datasets demonstrate
that our STIC outperforms baselines significantly and achieves the
state-of-the-art performance, particularly when the datasets contain a limited
number of observed time steps. Code is available at
\url{https://github.com/HITshenrj/STIC}.

摘要：<paragraph>時序資料的因果發現旨在擷取時間鏈中變數之間的切片內（同時）和切片間（時間滯後）因果關係，這對於各種科學領域至關重要。與非時序資料的因果發現相比，時序資料的因果發現需要更多序列化樣本，且觀察到的時間步長數量較多。為了應對這些挑戰，我們提出了一種新的基於梯度的因果發現方法 STIC，其重點在於使用卷積神經網路來利用「短暫時間不變性」，以從時序資料中揭示因果關係。具體來說，STIC 利用每個視窗觀察中因果關係的短期時間和機制不變性，它具有獨立性，以提高樣本效率。此外，我們構建了兩個因果卷積核，它們分別對應於短期時間和機制不變性，以估計視窗因果圖。為了證明卷積神經網路對於時序資料的因果發現的必要性，我們在假設加性雜訊模型可識別的情況下，從理論上推導出卷積與時序資料的底層生成原理之間的等價性。在合成和 FMRI 基準資料集上進行的實驗評估表明，我們的 STIC 明顯優於基準，並達到了最先進的效能，特別是在資料集包含有限數量觀察到的時間步長時。程式碼可在以下網址取得：\url{https://github.com/HITshenrj/STIC}。</paragraph>

##### **DIVE: Towards Descriptive and Diverse Visual Commonsense Generation**
2408.08021v1 by Jun-Hyung Park, Hyuntae Park, Youjin Kang, Eojin Jeon, SangKeun Lee

Towards human-level visual understanding, visual commonsense generation has
been introduced to generate commonsense inferences beyond images. However,
current research on visual commonsense generation has overlooked an important
human cognitive ability: generating descriptive and diverse inferences. In this
work, we propose a novel visual commonsense generation framework, called DIVE,
which aims to improve the descriptiveness and diversity of generated
inferences. DIVE involves two methods, generic inference filtering and
contrastive retrieval learning, which address the limitations of existing
visual commonsense resources and training objectives. Experimental results
verify that DIVE outperforms state-of-the-art models for visual commonsense
generation in terms of both descriptiveness and diversity, while showing a
superior quality in generating unique and novel inferences. Notably, DIVE
achieves human-level descriptiveness and diversity on Visual Commonsense
Graphs. Furthermore, human evaluations confirm that DIVE aligns closely with
human judgments on descriptiveness and diversity\footnote{Our code and dataset
are available at https://github.com/Park-ing-lot/DIVE.

摘要：為了達到人類層級的視覺理解，視覺常識生成已經被引入，以產生超越圖像的常識推論。然而，目前關於視覺常識生成的的研究忽略了一種重要的人類認知能力：產生描述性和多樣性的推論。在這項工作中，我們提出了一個新穎的視覺常識生成框架，稱為 DIVE，其目標是提高生成推論的描述性和多樣性。DIVE 涉及兩種方法，即通用推論過濾和對比檢索學習，它們解決了現有視覺常識資源和訓練目標的限制。實驗結果驗證了 DIVE 在描述性和多樣性方面優於視覺常識生成的最新模型，同時在生成獨特和新穎的推論方面表現出優異的品質。值得注意的是，DIVE 在視覺常識圖上達到了人類層級的描述性和多樣性。此外，人類評估證實，DIVE 在描述性和多樣性方面與人類判斷緊密一致。

##### **Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization**
2408.08019v1 by Sang-Hoon Lee, Ha-Yeong Choi, Seong-Whan Lee

This paper introduces PeriodWave-Turbo, a high-fidelity and high-efficient
waveform generation model via adversarial flow matching optimization. Recently,
conditional flow matching (CFM) generative models have been successfully
adopted for waveform generation tasks, leveraging a single vector field
estimation objective for training. Although these models can generate
high-fidelity waveform signals, they require significantly more ODE steps
compared to GAN-based models, which only need a single generation step.
Additionally, the generated samples often lack high-frequency information due
to noisy vector field estimation, which fails to ensure high-frequency
reproduction. To address this limitation, we enhance pre-trained CFM-based
generative models by incorporating a fixed-step generator modification. We
utilized reconstruction losses and adversarial feedback to accelerate
high-fidelity waveform generation. Through adversarial flow matching
optimization, it only requires 1,000 steps of fine-tuning to achieve
state-of-the-art performance across various objective metrics. Moreover, we
significantly reduce inference speed from 16 steps to 2 or 4 steps.
Additionally, by scaling up the backbone of PeriodWave from 29M to 70M
parameters for improved generalization, PeriodWave-Turbo achieves unprecedented
performance, with a perceptual evaluation of speech quality (PESQ) score of
4.454 on the LibriTTS dataset. Audio samples, source code and checkpoints will
be available at https://github.com/sh-lee-prml/PeriodWave.

摘要：<paragraph>本文介紹 PeriodWave-Turbo，一種透過對抗流匹配最佳化進行高保真、高效率波形生成模型。最近，條件流匹配 (CFM) 生成模型已成功用於波形生成任務，利用單一向量場估計目標進行訓練。儘管這些模型可以產生高保真波形訊號，但與僅需單一生成步驟的基於 GAN 的模型相比，它們需要更多 ODE 步驟。此外，由於有雜訊的向量場估計，產生的樣本通常缺乏高頻資訊，這無法確保高頻再現。為了解決這個限制，我們透過整合固定步長生成器修改來增強預先訓練的基於 CFM 的生成模型。我們利用重建損失和對抗回饋來加速高保真波形生成。透過對抗流匹配最佳化，它只需要 1,000 步驟的微調，即可在各種目標指標中達到最先進的效能。此外，我們將推論速度從 16 步驟大幅減少到 2 或 4 步驟。此外，透過將 PeriodWave 的主幹從 29M 擴展到 70M 參數以改善泛化，PeriodWave-Turbo 達到了前所未有的效能，在 LibriTTS 資料集上語音品質 (PESQ) 分數的感知評估為 4.454。音訊範例、原始碼和檢查點將在 https://github.com/sh-lee-prml/PeriodWave 提供。</paragraph>

##### **Asteroid: Resource-Efficient Hybrid Pipeline Parallelism for Collaborative DNN Training on Heterogeneous Edge Devices**
2408.08015v1 by Shengyuan Ye, Liekang Zeng, Xiaowen Chu, Guoliang Xing, Xu Chen

On-device Deep Neural Network (DNN) training has been recognized as crucial
for privacy-preserving machine learning at the edge. However, the intensive
training workload and limited onboard computing resources pose significant
challenges to the availability and efficiency of model training. While existing
works address these challenges through native resource management optimization,
we instead leverage our observation that edge environments usually comprise a
rich set of accompanying trusted edge devices with idle resources beyond a
single terminal. We propose Asteroid, a distributed edge training system that
breaks the resource walls across heterogeneous edge devices for efficient model
training acceleration. Asteroid adopts a hybrid pipeline parallelism to
orchestrate distributed training, along with a judicious parallelism planning
for maximizing throughput under certain resource constraints. Furthermore, a
fault-tolerant yet lightweight pipeline replay mechanism is developed to tame
the device-level dynamics for training robustness and performance stability. We
implement Asteroid on heterogeneous edge devices with both vision and language
models, demonstrating up to 12.2x faster training than conventional parallelism
methods and 2.1x faster than state-of-the-art hybrid parallelism methods
through evaluations. Furthermore, Asteroid can recover training pipeline 14x
faster than baseline methods while preserving comparable throughput despite
unexpected device exiting and failure.

摘要：<paragraph>在裝置上的深度神經網路 (DNN) 訓練已被視為邊緣隱私保護機器學習的關鍵。然而，密集的訓練工作負載和有限的板載運算資源對模型訓練的可用性和效率構成重大挑戰。雖然現有作品透過原生資源管理最佳化來解決這些挑戰，但我們反而利用我們的觀察，即邊緣環境通常包含一組豐富的隨附受信任邊緣裝置，其閒置資源超出單一終端。我們提出 Asteroid，這是一個分散式邊緣訓練系統，它打破了異質邊緣裝置之間的資源壁壘，以實現高效的模型訓練加速。Asteroid 採用混合管線並行來協調分散式訓練，同時明智地規劃並行性，以在特定資源限制下最大化吞吐量。此外，還開發了一種容錯且輕量級的管線重播機制，以馴服裝置級動態，以提高訓練穩健性和效能穩定性。我們在具有視覺和語言模型的異質邊緣裝置上實作 Asteroid，展示比傳統並行方法快 12.2 倍的訓練速度，並且透過評估比最先進的混合並行方法快 2.1 倍。此外，儘管裝置意外退出和故障，Asteroid 能夠以 14 倍於基準方法的速度恢復訓練管線，同時保持可比較的吞吐量。</paragraph>

##### **Leveraging Web-Crawled Data for High-Quality Fine-Tuning**
2408.08003v1 by Jing Zhou, Chenglin Jiang, Wei Shen, Xiao Zhou, Xiaonan He

Most large language models are fine-tuned using either expensive
human-annotated data or GPT-4 generated data which cannot guarantee performance
in certain domains. We argue that although the web-crawled data often has
formatting errors causing semantic inaccuracies, it can still serve as a
valuable source for high-quality supervised fine-tuning in specific domains
without relying on advanced models like GPT-4. To this end, we create a paired
training dataset automatically by aligning web-crawled data with a smaller set
of high-quality data. By training a language model on this dataset, we can
convert web data with irregular formats into high-quality ones. Our experiments
show that training with the model-transformed data yields better results,
surpassing training with only high-quality data by an average score of 9.4% in
Chinese math problems. Additionally, our 7B model outperforms several
open-source models larger than 32B and surpasses well-known closed-source
models such as GPT-3.5, highlighting the efficacy of our approach.

摘要：大多數大型語言模型都是使用昂貴的人工標註資料或 GPT-4 生成的資料進行微調，這無法保證在特定領域的效能。我們認為，儘管網路爬取的資料通常有格式錯誤，導致語意不準確，但它仍可用作特定領域中高品質監督式微調的寶貴來源，而無需依賴 GPT-4 等進階模型。為此，我們透過將網路爬取的資料與較小的高品質資料集對齊，自動建立配對的訓練資料集。透過在這個資料集上訓練語言模型，我們可以將格式不規則的網路資料轉換為高品質資料。我們的實驗顯示，使用模型轉換的資料進行訓練會產生更好的結果，在中文數學題目上，平均分數比僅使用高品質資料訓練高出 9.4%。此外，我們的 7B 模型優於數個大於 32B 的開源模型，並超越了著名的閉源模型，例如 GPT-3.5，突顯了我們方法的有效性。

##### **FuseChat: Knowledge Fusion of Chat Models**
2408.07990v1 by Fanqi Wan, Longguang Zhong, Ziyi Yang, Ruijun Chen, Xiaojun Quan

While training large language models (LLMs) from scratch can indeed lead to
models with distinct capabilities and strengths, it incurs substantial costs
and may lead to redundancy in competencies. Knowledge fusion aims to integrate
existing LLMs of diverse architectures and capabilities into a more potent LLM
through lightweight continual training, thereby reducing the need for costly
LLM development. In this work, we propose a new framework for the knowledge
fusion of chat LLMs through two main stages, resulting in FuseChat. Firstly, we
conduct pairwise knowledge fusion on source chat LLMs of varying structures and
scales to create multiple target LLMs with identical structure and size via
lightweight fine-tuning. During this process, a statistics-based token
alignment approach is introduced as the cornerstone for fusing LLMs with
different structures. Secondly, we merge these target LLMs within the parameter
space, where we propose a novel method for determining the merging coefficients
based on the magnitude of parameter updates before and after fine-tuning. We
implement and validate FuseChat using six prominent chat LLMs with diverse
architectures and scales, including OpenChat-3.5-7B, Starling-LM-7B-alpha,
NH2-SOLAR-10.7B, InternLM2-Chat-20B, Mixtral-8x7B-Instruct, and
Qwen-1.5-Chat-72B. Experimental results on two instruction-following
benchmarks, AlpacaEval 2.0 and MT-Bench, demonstrate the superiority of
FuseChat-7B over baselines of various sizes. Our model is even comparable to
the larger Mixtral-8x7B-Instruct and approaches GPT-3.5-Turbo-1106 on MT-Bench.
Our code, model weights, and data are public at
\url{https://github.com/fanqiwan/FuseAI}.

摘要：<paragraph>從頭訓練大型語言模型 (LLM) 確實可以產生具有不同功能和優勢的模型，但會產生大量成本，並可能導致能力冗餘。知識融合旨在透過輕量級的持續訓練，將不同架構和功能的現有 LLM 整合到更強大的 LLM 中，從而減少對昂貴 LLM 開發的需求。在這項工作中，我們提出了一個新的聊天 LLM 知識融合架構，分為兩個主要階段，產生 FuseChat。首先，我們對不同結構和規模的原始聊天 LLM 進行成對知識融合，透過輕量級微調，建立多個具有相同結構和大小的目標 LLM。在此過程中，引入了基於統計的代碼對齊方法，作為融合具有不同結構的 LLM 的基石。其次，我們在參數空間中合併這些目標 LLM，我們提出了一種新穎的方法，用於根據微調前後參數更新的幅度來確定合併係數。我們使用六個具有不同架構和規模的著名聊天 LLM 實作並驗證了 FuseChat，包括 OpenChat-3.5-7B、Starling-LM-7B-alpha、NH2-SOLAR-10.7B、InternLM2-Chat-20B、Mixtral-8x7B-Instruct 和 Qwen-1.5-Chat-72B。在兩個指令遵循基準測試 AlpacaEval 2.0 和 MT-Bench 上的實驗結果證明了 FuseChat-7B 優於各種規模的基準。我們的模型甚至可以與較大的 Mixtral-8x7B-Instruct 相媲美，並在 MT-Bench 上接近 GPT-3.5-Turbo-1106。我們的程式碼、模型權重和資料已公開於\url{https://github.com/fanqiwan/FuseAI}。</paragraph>

##### **IIU: Independent Inference Units for Knowledge-based Visual Question Answering**
2408.07989v1 by Yili Li, Jing Yu, Keke Gai, Gang Xiong

Knowledge-based visual question answering requires external knowledge beyond
visible content to answer the question correctly. One limitation of existing
methods is that they focus more on modeling the inter-modal and intra-modal
correlations, which entangles complex multimodal clues by implicit embeddings
and lacks interpretability and generalization ability. The key challenge to
solve the above problem is to separate the information and process it
separately at the functional level. By reusing each processing unit, the
generalization ability of the model to deal with different data can be
increased. In this paper, we propose Independent Inference Units (IIU) for
fine-grained multi-modal reasoning to decompose intra-modal information by the
functionally independent units. Specifically, IIU processes each
semantic-specific intra-modal clue by an independent inference unit, which also
collects complementary information by communication from different units. To
further reduce the impact of redundant information, we propose a memory update
module to maintain semantic-relevant memory along with the reasoning process
gradually. In comparison with existing non-pretrained multi-modal reasoning
models on standard datasets, our model achieves a new state-of-the-art,
enhancing performance by 3%, and surpassing basic pretrained multi-modal
models. The experimental results show that our IIU model is effective in
disentangling intra-modal clues as well as reasoning units to provide
explainable reasoning evidence. Our code is available at
https://github.com/Lilidamowang/IIU.

摘要：<paragraph>基於知識的視覺問題回答需要外部知識，而這些知識超出了可見內容，才能正確回答問題。現有方法的一個限制在於，它們更專注於建模跨模態和模態內相關性，這通過隱式嵌入將複雜的多模態線索糾纏在一起，並且缺乏可解釋性和泛化能力。解決上述問題的關鍵挑戰是分離資訊，並在功能層級上分別處理它。透過重複使用每個處理單元，可以提高模型處理不同資料的泛化能力。在本文中，我們提出了獨立推理單元 (IIU)，用於細粒度的多模態推理，以透過功能獨立的單元分解模態內資訊。具體來說，IIU 透過獨立推理單元處理每個語義特定的模態內線索，該單元還會從不同單元收集互補資訊。為了進一步降低冗餘資訊的影響，我們提出了一個記憶體更新模組，以隨著推理過程逐漸維護語義相關記憶體。與標準資料集上的現有非預訓練多模態推理模型相比，我們的模型達到了新的最佳狀態，將效能提升了 3%，並超越了基本的預訓練多模態模型。實驗結果表明，我們的 IIU 模型在解開模態內線索以及推理單元方面是有效的，以提供可解釋的推理證據。我們的程式碼可在 https://github.com/Lilidamowang/IIU 取得。</paragraph>

##### **ArabLegalEval: A Multitask Benchmark for Assessing Arabic Legal Knowledge in Large Language Models**
2408.07983v1 by Faris Hijazi, Somayah AlHarbi, Abdulaziz AlHussein, Harethah Abu Shairah, Reem AlZahrani, Hebah AlShamlan, Omar Knio, George Turkiyyah

The rapid advancements in Large Language Models (LLMs) have led to
significant improvements in various natural language processing tasks. However,
the evaluation of LLMs' legal knowledge, particularly in non-English languages
such as Arabic, remains under-explored. To address this gap, we introduce
ArabLegalEval, a multitask benchmark dataset for assessing the Arabic legal
knowledge of LLMs. Inspired by the MMLU and LegalBench datasets, ArabLegalEval
consists of multiple tasks sourced from Saudi legal documents and synthesized
questions. In this work, we aim to analyze the capabilities required to solve
legal problems in Arabic and benchmark the performance of state-of-the-art
LLMs. We explore the impact of in-context learning and investigate various
evaluation methods. Additionally, we explore workflows for generating questions
with automatic validation to enhance the dataset's quality. We benchmark
multilingual and Arabic-centric LLMs, such as GPT-4 and Jais, respectively. We
also share our methodology for creating the dataset and validation, which can
be generalized to other domains. We hope to accelerate AI research in the
Arabic Legal domain by releasing the ArabLegalEval dataset and code:
https://github.com/Thiqah/ArabLegalEval

摘要：大型語言模型 (LLM) 的快速進步已經在各種自然語言處理任務中帶來顯著的改進。然而，LLM 的法律知識評估，特別是在阿拉伯語等非英語語言中，仍然處於探索不足的狀態。為了解決這個差距，我們引入了 ArabLegalEval，一個用於評估 LLM 的阿拉伯語法律知識的多任務基準數據集。受 MMLU 和 LegalBench 數據集的啟發，ArabLegalEval 包含了多個任務，這些任務來自沙烏地阿拉伯法律文件和綜合問題。在這項工作中，我們的目標是分析解決阿拉伯語法律問題所需的能力，並對最先進的 LLM 的性能進行基準測試。我們探討了情境學習的影響，並研究了各種評估方法。此外，我們還探討了使用自動驗證生成問題的工作流程，以提高數據集的質量。我們對多語言和以阿拉伯語為中心的 LLM（例如 GPT-4 和 Jais）進行了基準測試。我們還分享了我們用於創建數據集和驗證的方法，該方法可以推廣到其他領域。我們希望通過發布 ArabLegalEval 數據集和代碼來加速阿拉伯語法律領域的人工智慧研究：https://github.com/Thiqah/ArabLegalEval

##### **Toward a Dialogue System Using a Large Language Model to Recognize User Emotions with a Camera**
2408.07982v1 by Hiroki Tanioka, Tetsushi Ueta, Masahiko Sano

The performance of ChatGPT\copyright{} and other LLMs has improved
tremendously, and in online environments, they are increasingly likely to be
used in a wide variety of situations, such as ChatBot on web pages, call center
operations using voice interaction, and dialogue functions using agents. In the
offline environment, multimodal dialogue functions are also being realized,
such as guidance by Artificial Intelligence agents (AI agents) using tablet
terminals and dialogue systems in the form of LLMs mounted on robots. In this
multimodal dialogue, mutual emotion recognition between the AI and the user
will become important. So far, there have been methods for expressing emotions
on the part of the AI agent or for recognizing them using textual or voice
information of the user's utterances, but methods for AI agents to recognize
emotions from the user's facial expressions have not been studied. In this
study, we examined whether or not LLM-based AI agents can interact with users
according to their emotional states by capturing the user in dialogue with a
camera, recognizing emotions from facial expressions, and adding such emotion
information to prompts. The results confirmed that AI agents can have
conversations according to the emotional state for emotional states with
relatively high scores, such as Happy and Angry.

摘要：ChatGPT\copyright{} 和其他 LLM 的效能已大幅提升，在線上環境中，它們愈來愈可能用於各種情況，例如網頁上的聊天機器人、使用語音互動的呼叫中心作業，以及使用代理人的對話功能。在離線環境中，多模態對話功能也正在實現，例如使用平板終端的人工智慧代理人 (AI 代理人) 的指導，以及安裝在機器人上的 LLM 形式的對話系統。在此多模態對話中，AI 與使用者之間的相互情緒辨識將變得重要。到目前為止，已有 AI 代理人表達情緒或使用使用者的話語文字或語音資訊辨識情緒的方法，但 AI 代理人從使用者的面部表情辨識情緒的方法尚未被研究。在本研究中，我們探討了基於 LLM 的 AI 代理人是否能透過相機捕捉與使用者對話、從面部表情辨識情緒，並將此類情緒資訊新增至提示，根據使用者的情緒狀態與使用者互動。結果證實，對於情緒分數相對較高的情緒狀態，例如快樂和生氣，AI 代理人可以根據情緒狀態進行對話。

##### **LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning**
2408.07981v1 by Jiajie Li, Garrett Skinner, Gene Yang, Brian R Quaranto, Steven D Schwaitzberg, Peter C W Kim, Jinjun Xiong

Multimodal large language models (LLMs) have achieved notable success across
various domains, while research in the medical field has largely focused on
unimodal images. Meanwhile, current general-domain multimodal models for videos
still lack the capabilities to understand and engage in conversations about
surgical videos. One major contributing factor is the absence of datasets in
the surgical field. In this paper, we create a new dataset, Surg-QA, consisting
of 102,000 surgical video-instruction pairs, the largest of its kind so far. To
build such a dataset, we propose a novel two-stage question-answer generation
pipeline with LLM to learn surgical knowledge in a structured manner from the
publicly available surgical lecture videos. The pipeline breaks down the
generation process into two stages to significantly reduce the task complexity,
allowing us to use a more affordable, locally deployed open-source LLM than the
premium paid LLM services. It also mitigates the risk of LLM hallucinations
during question-answer generation, thereby enhancing the overall quality of the
generated data. We further train LLaVA-Surg, a novel vision-language
conversational assistant capable of answering open-ended questions about
surgical videos, on this Surg-QA dataset, and conduct comprehensive evaluations
on zero-shot surgical video question-answering tasks. We show that LLaVA-Surg
significantly outperforms all previous general-domain models, demonstrating
exceptional multimodal conversational skills in answering open-ended questions
about surgical videos. We will release our code, model, and the
instruction-tuning dataset.

摘要：多模態大型語言模型 (LLM) 在各個領域都取得了顯著的成功，而醫學領域的研究則主要集中在單模態影像上。同時，目前的影片通用領域多模態模型仍缺乏理解和參與外科影片對話的能力。主要的影響因素之一是外科領域中缺乏資料集。在本文中，我們建立了一個新的資料集 Surg-QA，其中包含 102,000 個外科影片教學配對，是目前同類資料集中規模最大的。為了建立這樣的資料集，我們提出了一個新穎的兩階段問答產生管道，使用 LLM 以結構化的方式從公開的外科教學影片中學習外科知識。該管道將產生過程分為兩個階段，以顯著降低任務複雜性，使我們能夠使用比付費 LLM 服務更實惠的本地部署開源 LLM。它還減輕了問答產生過程中 LLM 產生幻覺的風險，從而提高了產生資料的整體品質。我們進一步訓練 LLaVA-Surg，這是一個新穎的視覺語言對話助理，能夠回答有關外科影片的開放式問題，並在 Surg-QA 資料集上進行全面的零次學習外科影片問答任務評估。我們展示了 LLaVA-Surg 明顯優於所有先前的通用領域模型，證明了在回答有關外科影片的開放式問題時具有卓越的多模態對話技能。我們將發布我們的程式碼、模型和教學調整資料集。

##### **Coupling without Communication and Drafter-Invariant Speculative Decoding**
2408.07978v1 by Majid Daliri, Christopher Musco, Ananda Theertha Suresh

Suppose Alice has a distribution $P$ and Bob has a distribution $Q$. Alice
wants to generate a sample $a\sim P$ and Bob a sample $b \sim Q$ such that $a =
b$ with has as high of probability as possible. It is well-known that, by
sampling from an optimal coupling between the distributions, Alice and Bob can
achieve $Pr[a = b] = 1 - D_{TV}(P,Q)$, where $D_{TV}(P,Q)$ is the total
variation distance. What if Alice and Bob must solve this same problem without
communicating at all? Perhaps surprisingly, with access to public randomness,
they can still achieve $Pr[a = b] \geq \frac{1 - D_{TV}(P,Q)}{1 + D_{TV}(P,Q)}
\geq 1-2D_{TV}(P,Q)$. In fact, this bound can be obtained using a simple
protocol based on the Weighted MinHash algorithm. In this work, we explore the
communication-free coupling in greater depth. First, we show that an equally
simple protocol based on Gumbel sampling matches the worst-case guarantees of
the Weighted MinHash approach, but tends to perform better in practice.
Conversely, we prove that both approaches are actually sharp: no
communication-free protocol can achieve $Pr[a=b]>\frac{1 - D_{TV}(P,Q)}{1 +
D_{TV}(P,Q)}$ in the worst-case. Finally, we prove that, for distributions over
$n$ items, there exists a scheme that uses just $O(\log(n/\epsilon))$ bits of
communication to achieve $Pr[a = b] = 1 - D_{TV}(P,Q) - \epsilon$, i.e. to
essentially match optimal coupling. Beyond our theoretical results, we
demonstrate an application of communication-free coupling to speculative
decoding, a recent method for accelerating autoregressive large language models
[Leviathan, Kalman, Matias, ICML 2023]. We show that communication-free
protocols yield a variant of speculative decoding that we call
Drafter-Invariant Speculative Decoding, which has the desirable property that
the output of the method is fixed given a fixed random seed, regardless of what
drafter is used for speculation.

摘要：<paragraph>假设 Alice 有一个分布 $P$，Bob 有一个分布 $Q$。Alice 希望生成一个样本 $a\sim P$，Bob 生成一个样本 $b \sim Q$，使得 $a = b$ 的概率尽可能高。众所周知，通过从分布之间的最优耦合中进行采样，Alice 和 Bob 可以实现 $Pr[a = b] = 1 - D_{TV}(P,Q)$，其中 $D_{TV}(P,Q)$ 是总变异距离。如果 Alice 和 Bob 必须在完全不通信的情况下解决这个问题呢？也许令人惊讶的是，在可以访问公共随机性的情况下，他们仍然可以实现 $Pr[a = b] \geq \frac{1 - D_{TV}(P,Q)}{1 + D_{TV}(P,Q)} \geq 1-2D_{TV}(P,Q)$。事实上，可以使用基于加权最小哈希算法的简单协议获得此界限。在这项工作中，我们更深入地探讨了无通信耦合。首先，我们表明，基于 Gumbel 采样的同样简单的协议与加权最小哈希方法的最坏情况保证相匹配，但在实践中往往表现得更好。相反，我们证明这两种方法实际上都很严格：在最坏的情况下，没有任何无通信协议可以实现 $Pr[a=b]>\frac{1 - D_{TV}(P,Q)}{1 + D_{TV}(P,Q)}$。最后，我们证明对于 $n$ 个项目的分布，存在一个方案，只需使用 $O(\log(n/\epsilon))$ 位通信即可实现 $Pr[a = b] = 1 - D_{TV}(P,Q) - \epsilon$，即基本上匹配最优耦合。除了我们的理论结果之外，我们还展示了无通信耦合在推测解码中的应用，这是一种加速自回归大语言模型的最新方法 [Leviathan, Kalman, Matias, ICML 2023]。我们表明，无通信协议产生了一种推测解码变体，我们称之为起草者不变推测解码，它具有理想的特性，即该方法的输出在给定固定随机种子时是固定的，无论使用什么起草者进行推测。</paragraph>

##### **Polaris: Open-ended Interactive Robotic Manipulation via Syn2Real Visual Grounding and Large Language Models**
2408.07975v1 by Tianyu Wang, Haitao Lin, Junqiu Yu, Yanwei Fu

This paper investigates the task of the open-ended interactive robotic
manipulation on table-top scenarios. While recent Large Language Models (LLMs)
enhance robots' comprehension of user instructions, their lack of visual
grounding constrains their ability to physically interact with the environment.
This is because the robot needs to locate the target object for manipulation
within the physical workspace. To this end, we introduce an interactive robotic
manipulation framework called Polaris, which integrates perception and
interaction by utilizing GPT-4 alongside grounded vision models. For precise
manipulation, it is essential that such grounded vision models produce detailed
object pose for the target object, rather than merely identifying pixels
belonging to them in the image. Consequently, we propose a novel
Synthetic-to-Real (Syn2Real) pose estimation pipeline. This pipeline utilizes
rendered synthetic data for training and is then transferred to real-world
manipulation tasks. The real-world performance demonstrates the efficacy of our
proposed pipeline and underscores its potential for extension to more general
categories. Moreover, real-robot experiments have showcased the impressive
performance of our framework in grasping and executing multiple manipulation
tasks. This indicates its potential to generalize to scenarios beyond the
tabletop. More information and video results are available here:
https://star-uu-wang.github.io/Polaris/

摘要：這篇論文探討了桌上情境中開放式互動機器人操作的任務。儘管最近的大型語言模型 (LLM) 提升了機器人對使用者指令的理解，但它們缺乏視覺基礎，限制了它們與環境進行物理互動的能力。這是因為機器人在物理工作空間中需要找到用於操作的目標物體。為此，我們引入了稱為 Polaris 的互動機器人操作架構，它通過將 GPT-4 與基礎視覺模型結合使用來整合感知和互動。對於精確操作，這些基礎視覺模型產生目標物體的詳細物體姿勢至關重要，而不仅仅是識別圖像中屬於它們的像素。因此，我們提出了一種新穎的合成到真實 (Syn2Real) 姿勢估計管道。此管道利用渲染的合成數據進行訓練，然後轉移到現實世界的操作任務中。現實世界的表現證明了我們提出的管道的有效性，並強調了其擴展到更一般類別的潛力。此外，真實機器人實驗展示了我們的框架在抓取和執行多項操作任務方面的令人印象深刻的表現。這表明它有可能推廣到桌面之外的場景。更多信息和視頻結果可以在這裡找到：
https://star-uu-wang.github.io/Polaris/

##### **Predicting Lung Cancer Patient Prognosis with Large Language Models**
2408.07971v1 by Danqing Hu, Bing Liu, Xiang Li, Xiaofeng Zhu, Nan Wu

Prognosis prediction is crucial for determining optimal treatment plans for
lung cancer patients. Traditionally, such predictions relied on models
developed from retrospective patient data. Recently, large language models
(LLMs) have gained attention for their ability to process and generate text
based on extensive learned knowledge. In this study, we evaluate the potential
of GPT-4o mini and GPT-3.5 in predicting the prognosis of lung cancer patients.
We collected two prognosis datasets, i.e., survival and post-operative
complication datasets, and designed multiple tasks to assess the models'
performance comprehensively. Logistic regression models were also developed as
baselines for comparison. The experimental results demonstrate that LLMs can
achieve competitive, and in some tasks superior, performance in lung cancer
prognosis prediction compared to data-driven logistic regression models despite
not using additional patient data. These findings suggest that LLMs can be
effective tools for prognosis prediction in lung cancer, particularly when
patient data is limited or unavailable.

摘要：預後預測對於確定肺癌患者的最佳治療計畫至關重要。傳統上，此類預測依賴於從回顧性患者資料開發的模型。最近，大型語言模型 (LLM) 因其根據廣泛學習的知識處理和產生文字的能力而備受關注。在這項研究中，我們評估了 GPT-4o mini 和 GPT-3.5 在預測肺癌患者預後方面的潛力。我們收集了兩個預後資料集，即存活率和術後併發症資料集，並設計了多項任務來全面評估模型的效能。邏輯迴歸模型也作為比較基準而開發。實驗結果表明，與資料驅動的邏輯迴歸模型相比，即使不使用額外的患者資料，LLM 也可以在肺癌預後預測中實現具有競爭力，甚至在某些任務中表現出優異的效能。這些發現表明，LLM 可以成為肺癌預後預測的有效工具，特別是在患者資料有限或無法取得時。

##### **Meta SAC-Lag: Towards Deployable Safe Reinforcement Learning via MetaGradient-based Hyperparameter Tuning**
2408.07962v1 by Homayoun Honari, Amir Mehdi Soufi Enayati, Mehran Ghafarian Tamizi, Homayoun Najjaran

Safe Reinforcement Learning (Safe RL) is one of the prevalently studied
subcategories of trial-and-error-based methods with the intention to be
deployed on real-world systems. In safe RL, the goal is to maximize reward
performance while minimizing constraints, often achieved by setting bounds on
constraint functions and utilizing the Lagrangian method. However, deploying
Lagrangian-based safe RL in real-world scenarios is challenging due to the
necessity of threshold fine-tuning, as imprecise adjustments may lead to
suboptimal policy convergence. To mitigate this challenge, we propose a unified
Lagrangian-based model-free architecture called Meta Soft Actor-Critic
Lagrangian (Meta SAC-Lag). Meta SAC-Lag uses meta-gradient optimization to
automatically update the safety-related hyperparameters. The proposed method is
designed to address safe exploration and threshold adjustment with minimal
hyperparameter tuning requirement. In our pipeline, the inner parameters are
updated through the conventional formulation and the hyperparameters are
adjusted using the meta-objectives which are defined based on the updated
parameters. Our results show that the agent can reliably adjust the safety
performance due to the relatively fast convergence rate of the safety
threshold. We evaluate the performance of Meta SAC-Lag in five simulated
environments against Lagrangian baselines, and the results demonstrate its
capability to create synergy between parameters, yielding better or competitive
results. Furthermore, we conduct a real-world experiment involving a robotic
arm tasked with pouring coffee into a cup without spillage. Meta SAC-Lag is
successfully trained to execute the task, while minimizing effort constraints.

摘要：安全強化學習 (Safe RL) 是基於試錯法的一種普遍研究的子類別，其目的是部署在真實世界的系統中。在安全強化學習中，目標是最大化獎勵績效，同時最小化約束，通常透過設定約束函數的界線並使用拉格朗日方法來達成。然而，由於必須對閾值進行微調，因此在真實世界的場景中部署基於拉格朗日的安全強化學習具有挑戰性，因為不精確的調整可能會導致次佳政策收斂。為了減輕這個挑戰，我們提出一個統一的基於拉格朗日的無模型架構，稱為 Meta Soft Actor-Critic Lagrangian (Meta SAC-Lag)。Meta SAC-Lag 使用元梯度最佳化自動更新與安全相關的超參數。所提出的方法旨在解決安全探索和閾值調整，並將超參數調整需求降到最低。在我們的管線中，內部參數透過傳統公式更新，而超參數則使用基於更新參數定義的元目標進行調整。我們的結果顯示，由於安全閾值的收斂速度相對較快，因此代理程式可以可靠地調整安全績效。我們在五個模擬環境中評估 Meta SAC-Lag 的效能，並針對拉格朗日基準進行比較，結果證明其能夠在參數之間產生協同效應，產生更好或有競爭力的結果。此外，我們進行了一項真實世界的實驗，涉及一個機器手臂，其任務是將咖啡倒進杯子中而不溢出。Meta SAC-Lag 已成功訓練以執行任務，同時將工作量約束降到最低。

##### **RandomNet: Clustering Time Series Using Untrained Deep Neural Networks**
2408.07956v1 by Xiaosheng Li, Wenjie Xi, Jessica Lin

Neural networks are widely used in machine learning and data mining.
Typically, these networks need to be trained, implying the adjustment of
weights (parameters) within the network based on the input data. In this work,
we propose a novel approach, RandomNet, that employs untrained deep neural
networks to cluster time series. RandomNet uses different sets of random
weights to extract diverse representations of time series and then ensembles
the clustering relationships derived from these different representations to
build the final clustering results. By extracting diverse representations, our
model can effectively handle time series with different characteristics. Since
all parameters are randomly generated, no training is required during the
process. We provide a theoretical analysis of the effectiveness of the method.
To validate its performance, we conduct extensive experiments on all of the 128
datasets in the well-known UCR time series archive and perform statistical
analysis of the results. These datasets have different sizes, sequence lengths,
and they are from diverse fields. The experimental results show that the
proposed method is competitive compared with existing state-of-the-art methods.

摘要：神經網路廣泛用於機器學習和資料探勘。
通常，這些網路需要經過訓練，也就是根據輸入資料調整網路內的權重（參數）。在這項工作中，
我們提出了一種新方法，RandomNet，它採用未訓練的深度神經網路來對時間序列進行分群。RandomNet 使用不同的隨機權重集合來提取時間序列的不同表示，然後將從這些不同表示中得出的分群關係進行整合，以建立最終的分群結果。透過提取不同的表示，我們的模型可以有效地處理具有不同特徵的時間序列。由於所有參數都是隨機產生的，因此在過程中不需要訓練。我們提供了該方法有效性的理論分析。
為了驗證其效能，我們對著名的 UCR 時間序列檔案中的所有 128 個資料集進行了廣泛的實驗，並對結果進行了統計分析。這些資料集具有不同的規模、序列長度，而且來自不同的領域。實驗結果表明，所提出的方法與現有的最先進方法相比具有競爭力。

##### **GERestaurant: A German Dataset of Annotated Restaurant Reviews for Aspect-Based Sentiment Analysis**
2408.07955v1 by Nils Constantin Hellwig, Jakob Fehle, Markus Bink, Christian Wolff

We present GERestaurant, a novel dataset consisting of 3,078 German language
restaurant reviews manually annotated for Aspect-Based Sentiment Analysis
(ABSA). All reviews were collected from Tripadvisor, covering a diverse
selection of restaurants, including regional and international cuisine with
various culinary styles. The annotations encompass both implicit and explicit
aspects, including all aspect terms, their corresponding aspect categories, and
the sentiments expressed towards them. Furthermore, we provide baseline scores
for the four ABSA tasks Aspect Category Detection, Aspect Category Sentiment
Analysis, End-to-End ABSA and Target Aspect Sentiment Detection as a reference
point for future advances. The dataset fills a gap in German language resources
and facilitates exploration of ABSA in the restaurant domain.

摘要：我們提出 GERestaurant，這是一個新穎的資料集，包含 3,078 篇德語餐廳評論，並針對基於面向切面的情緒分析 (ABSA) 進行人工註解。所有評論均從 Tripadvisor 收集，涵蓋各種餐廳，包括地區和國際美食，以及各種烹飪風格。註解包含隱含和明確的切面，包括所有切面術語、其對應的切面類別以及對它們表達的情緒。此外，我們提供四項 ABSA 任務的基準分數：切面類別檢測、切面類別情緒分析、端到端 ABSA 和目標切面情緒檢測，作為未來進展的參考點。該資料集填補了德語資源的空白，並促進在餐廳領域探索 ABSA。

##### **Conditional Brownian Bridge Diffusion Model for VHR SAR to Optical Image Translation**
2408.07947v1 by Seon-Hoon Kim, Dae-won Chung

Synthetic Aperture Radar (SAR) imaging technology provides the unique
advantage of being able to collect data regardless of weather conditions and
time. However, SAR images exhibit complex backscatter patterns and speckle
noise, which necessitate expertise for interpretation. To deal with this
challenge, research has been conducted on translating SAR images into
optical-like representations to aid the interpretation of SAR data.
Nevertheless, existing studies have predominantly utilized low-resolution
satellite imagery datasets and have largely been based on Generative
Adversarial Network (GAN) which are known for their training instability and
low fidelity. To overcome these limitations of low-resolution data usage and
GAN-based approaches, this paper introduces a conditional image-to-image
translation approach based on Brownian Bridge Diffusion Model (BBDM). We
conducted comprehensive experiments on the MSAW dataset, a paired SAR and
optical images collection of 0.5m Very-High-Resolution (VHR) images. The
experimental results indicate that our method surpasses both the Conditional
Diffusion Model (CDM) and the GAN-based models in diverse perceptual quality
metrics.

摘要：合成孔徑雷達 (SAR) 影像技術提供了獨特的優勢，無論天氣條件和時間如何，都能收集數據。然而，SAR 影像呈現複雜的後向散射模式和斑點雜訊，這需要專業知識才能解釋。為了應對這一挑戰，研究已經對將 SAR 影像轉換為類光學表示以幫助解釋 SAR 數據進行了研究。儘管如此，現有研究主要利用低解析度衛星影像數據集，並且在很大程度上基於生成對抗網路 (GAN)，而 GAN 以其訓練不穩定性和低保真度而聞名。為了克服低解析度數據使用和基於 GAN 的方法的這些限制，本文介紹了一種基於布朗橋擴散模型 (BBDM) 的條件圖像到圖像轉換方法。我們對 MSAW 數據集進行了全面的實驗，MSAW 數據集是一個配對的 SAR 和光學影像集合，包含 0.5m 超高解析度 (VHR) 影像。實驗結果表明，我們的模型在各種感知質量指標上都優於條件擴散模型 (CDM) 和基於 GAN 的模型。

##### **Solving a Rubik's Cube Using its Local Graph Structure**
2408.07945v1 by Shunyu Yao, Mitchy Lee

The Rubix Cube is a 3-dimensional single-player combination puzzle attracting
attention in the reinforcement learning community. A Rubix Cube has six faces
and twelve possible actions, leading to a small and unconstrained action space
and a very large state space with only one goal state. Modeling such a large
state space and storing the information of each state requires exceptional
computational resources, which makes it challenging to find the shortest
solution to a scrambled Rubix cube with limited resources. The Rubix Cube can
be represented as a graph, where states of the cube are nodes and actions are
edges. Drawing on graph convolutional networks, we design a new heuristic,
weighted convolutional distance, for A star search algorithm to find the
solution to a scrambled Rubix Cube. This heuristic utilizes the information of
neighboring nodes and convolves them with attention-like weights, which creates
a deeper search for the shortest path to the solved state.

摘要：魔術方塊是一個三維單人組合拼圖，在強化學習社群中備受關注。魔術方塊有六個面和十二種可能的動作，導致動作空間小且不受約束，以及只有單一目標狀態的非常大的狀態空間。對如此大的狀態空間建模並儲存每個狀態的資訊需要非凡的運算資源，這使得在有限資源下找到打亂的魔術方塊的最短解法具有挑戰性。魔術方塊可以表示為一個圖形，其中方塊的狀態是節點，動作是邊。利用圖形卷積網路，我們設計了一個新的啟發式方法，加權卷積距離，供 A 星搜尋演算法找到打亂的魔術方塊的解法。此啟發式方法利用鄰近節點的資訊，並透過類似的注意力權重對它們進行卷積，這會為求解狀態尋找更短路徑進行更深入的搜尋。

##### **Surgical SAM 2: Real-time Segment Anything in Surgical Video by Efficient Frame Pruning**
2408.07931v1 by Haofeng Liu, Erli Zhang, Junde Wu, Mingxuan Hong, Yueming Jin

Surgical video segmentation is a critical task in computer-assisted surgery
and is vital for enhancing surgical quality and patient outcomes. Recently, the
Segment Anything Model 2 (SAM2) framework has shown superior advancements in
image and video segmentation. However, SAM2 struggles with efficiency due to
the high computational demands of processing high-resolution images and complex
and long-range temporal dynamics in surgical videos. To address these
challenges, we introduce Surgical SAM 2 (SurgSAM-2), an advanced model to
utilize SAM2 with an Efficient Frame Pruning (EFP) mechanism, to facilitate
real-time surgical video segmentation. The EFP mechanism dynamically manages
the memory bank by selectively retaining only the most informative frames,
reducing memory usage and computational cost while maintaining high
segmentation accuracy. Our extensive experiments demonstrate that SurgSAM-2
significantly improves both efficiency and segmentation accuracy compared to
the vanilla SAM2. Remarkably, SurgSAM-2 achieves a 3$\times$ FPS compared with
SAM2, while also delivering state-of-the-art performance after fine-tuning with
lower-resolution data. These advancements establish SurgSAM-2 as a leading
model for surgical video analysis, making real-time surgical video segmentation
in resource-constrained environments a feasible reality.

摘要：手術影片分割是電腦輔助手術中的一項重要任務，對於提升手術品質和患者預後至關重要。最近，Segment Anything Model 2 (SAM2) 框架在影像和影片分割方面展現出卓越的進步。然而，SAM2 在處理高解析度影像和手術影片中複雜且長程的時間動態時，由於運算需求高，因此在效率方面有所掙扎。為了應對這些挑戰，我們引入了手術 SAM 2 (SurgSAM-2)，這是一個進階模型，結合 SAM2 與高效度影像剔除 (EFP) 機制，以促進即時手術影片分割。EFP 機制透過選擇性地僅保留資訊量最高的影像，動態管理記憶體庫，在維持高分割精確度的同時，減少記憶體使用量和運算成本。我們廣泛的實驗證明，與原始 SAM2 相比，SurgSAM-2 在效率和分割精確度方面都有顯著的提升。值得注意的是，SurgSAM-2 的 FPS 比 SAM2 高出 3 倍，同時在使用低解析度資料進行微調後，也提供了最先進的效能。這些進展確立了 SurgSAM-2 作為手術影片分析的領先模型，使在資源受限的環境中進行即時手術影片分割成為可行的現實。

##### **MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and Iterative Sub-SQL Refinement for Text-to-SQL**
2408.07930v1 by Wenxuan Xie, Gaochen Wu, Bowen Zhou

Recent In-Context Learning based methods have achieved remarkable success in
Text-to-SQL task. However, there is still a large gap between the performance
of these models and human performance on datasets with complex database schema
and difficult questions, such as BIRD. Besides, existing work has neglected to
supervise intermediate steps when solving questions iteratively with question
decomposition methods, and the schema linking methods used in these works are
very rudimentary. To address these issues, we propose MAG-SQL, a multi-agent
generative approach with soft schema linking and iterative Sub-SQL refinement.
In our framework, an entity-based method with tables' summary is used to select
the columns in database, and a novel targets-conditions decomposition method is
introduced to decompose those complex questions. Additionally, we build a
iterative generating module which includes a Sub-SQL Generator and Sub-SQL
Refiner, introducing external oversight for each step of generation. Through a
series of ablation studies, the effectiveness of each agent in our framework
has been demonstrated. When evaluated on the BIRD benchmark with GPT-4, MAG-SQL
achieves an execution accuracy of 61.08\%, compared to the baseline accuracy of
46.35\% for vanilla GPT-4 and the baseline accuracy of 57.56\% for MAC-SQL.
Besides, our approach makes similar progress on Spider.

摘要：<paragraph>最近基於語境學習的方法已在文字轉 SQL 任務中取得顯著的成功。然而，這些模型的效能與人類在具有複雜資料庫架構和困難問題（例如 BIRD）的資料集上的效能之間仍有很大的差距。此外，現有工作在使用問題分解方法反覆解決問題時，忽略了對中間步驟的監督，並且這些工作中使用的架構連結方法非常基本。為了解決這些問題，我們提出了 MAG-SQL，這是一種具有軟架構連結和反覆子 SQL 精煉的多代理生成方法。在我們的框架中，使用具有表格摘要的基於實體的方法來選擇資料庫中的欄位，並引入一種新穎的目標條件分解方法來分解那些複雜的問題。此外，我們建立了一個反覆生成模組，其中包括一個子 SQL 產生器和子 SQL 精煉器，為生成的每一步引入外部監督。通過一系列消融研究，證明了我們框架中每個代理的有效性。在使用 GPT-4 對 BIRD 基準進行評估時，與純粹 GPT-4 的基準準確度 46.35% 和 MAC-SQL 的基準準確度 57.56% 相比，MAG-SQL 達到了 61.08% 的執行準確度。此外，我們的做法在 Spider 上取得了類似的進展。</paragraph>

##### **CEGRL-TKGR: A Causal Enhanced Graph Representation Learning Framework for Improving Temporal Knowledge Graph Extrapolation Reasoning**
2408.07911v1 by Jinze Sun, Yongpan Sheng, Lirong He

Temporal knowledge graph reasoning (TKGR) is increasingly gaining attention
for its ability to extrapolate new events from historical data, thereby
enriching the inherently incomplete temporal knowledge graphs. Existing
graph-based representation learning frameworks have made significant strides in
developing evolving representations for both entities and relational
embeddings. Despite these achievements, there's a notable tendency in these
models to inadvertently learn biased data representations and mine spurious
correlations, consequently failing to discern the causal relationships between
events. This often leads to incorrect predictions based on these false
correlations. To address this, we propose an innovative causal enhanced graph
representation learning framework for TKGR (named CEGRL-TKGR). This framework
introduces causal structures in graph-based representation learning to unveil
the essential causal relationships between events, ultimately enhancing task
performance. Specifically, we first disentangle the evolutionary
representations of entities and relations in a temporal graph sequence into two
distinct components, namely causal representations and confounding
representations. Then, drawing on causal intervention theory, we advocate the
utilization of causal representations for predictions, aiming to mitigate the
effects of erroneous correlations caused by confounding features, thus
achieving more robust and accurate predictions. Finally, extensive experimental
results on six benchmark datasets demonstrate the superior performance of our
model in the link prediction task.

摘要：時序知識圖譜推理 (TKGR) 因其從歷史數據中推斷新事件的能力而備受關注，從而豐富了本質上不完整的時序知識圖譜。現有的基於圖表的表示學習框架在為實體和關係嵌入開發演進表示方面取得了重大進展。儘管取得了這些成就，但這些模型存在一個顯著的趨勢，即無意中學習有偏差的數據表示並挖掘虛假相關性，從而無法辨別事件之間的因果關係。這通常會導致基於這些錯誤相關性的不正確預測。為了解決這個問題，我們提出了一個創新的因果增強圖表表示學習框架，用於 TKGR (名為 CEGRL-TKGR)。此框架在基於圖表的表示學習中引入了因果結構，以揭示事件之間的本質因果關係，最終提高任務性能。具體來說，我們首先將時序圖序列中實體和關係的演化表示解開為兩個不同的組成部分，即因果表示和混雜表示。然後，借鑒因果干預理論，我們提倡利用因果表示進行預測，旨在減輕由混雜特徵引起的錯誤相關性的影響，從而實現更穩健、更準確的預測。最後，在六個基準數據集上的大量實驗結果證明了我們的模型在鏈路預測任務中的優異性能。

##### **DM2RM: Dual-Mode Multimodal Ranking for Target Objects and Receptacles Based on Open-Vocabulary Instructions**
2408.07910v1 by Ryosuke Korekata, Kanta Kaneda, Shunya Nagashima, Yuto Imai, Komei Sugiura

In this study, we aim to develop a domestic service robot (DSR) that, guided
by open-vocabulary instructions, can carry everyday objects to the specified
pieces of furniture. Few existing methods handle mobile manipulation tasks with
open-vocabulary instructions in the image retrieval setting, and most do not
identify both the target objects and the receptacles. We propose the Dual-Mode
Multimodal Ranking model (DM2RM), which enables images of both the target
objects and receptacles to be retrieved using a single model based on
multimodal foundation models. We introduce a switching mechanism that leverages
a mode token and phrase identification via a large language model to switch the
embedding space based on the prediction target. To evaluate the DM2RM, we
construct a novel dataset including real-world images collected from hundreds
of building-scale environments and crowd-sourced instructions with referring
expressions. The evaluation results show that the proposed DM2RM outperforms
previous approaches in terms of standard metrics in image retrieval settings.
Furthermore, we demonstrate the application of the DM2RM on a standardized
real-world DSR platform including fetch-and-carry actions, where it achieves a
task success rate of 82% despite the zero-shot transfer setting. Demonstration
videos, code, and more materials are available at
https://kkrr10.github.io/dm2rm/.

摘要：在這項研究中，我們旨在開發一種家用服務機器人 (DSR)，它在開放式詞彙指令的引導下，可以將日常物品搬運到指定的家具上。現有方法很少在影像擷取設定中處理帶有開放式詞彙指令的行動操作任務，而且大多數方法無法識別目標物件和容器。我們提出雙模式多模態排序模型 (DM2RM)，它能使用基於多模態基礎模型的單一模型來擷取目標物件和容器的影像。我們導入一個切換機制，它利用模式代碼和透過大型語言模型進行的詞組識別，根據預測目標切換嵌入空間。為了評估 DM2RM，我們建構了一個新穎的資料集，其中包括從數百個建築規模環境中收集的真實世界影像，以及帶有參照表達式的群眾外包指令。評估結果顯示，所提出的 DM2RM 在影像擷取設定中的標準指標方面優於先前的做法。此外，我們展示了 DM2RM 在標準化真實世界 DSR 平臺上的應用，包括取放動作，儘管是零次學習轉移設定，它仍達到了 82% 的任務成功率。展示影片、程式碼和更多資料可以在 https://kkrr10.github.io/dm2rm/ 找到。

##### **Assessing Language Models' Worldview for Fiction Generation**
2408.07904v1 by Aisha Khatun, Daniel G. Brown

The use of Large Language Models (LLMs) has become ubiquitous, with abundant
applications in computational creativity. One such application is fictional
story generation. Fiction is a narrative that occurs in a story world that is
slightly different than ours. With LLMs becoming writing partners, we question
how suitable they are to generate fiction. This study investigates the ability
of LLMs to maintain a state of world essential to generate fiction. Through a
series of questions to nine LLMs, we find that only two models exhibit
consistent worldview, while the rest are self-conflicting. Subsequent analysis
of stories generated by four models revealed a strikingly uniform narrative
pattern. This uniformity across models further suggests a lack of `state'
necessary for fiction. We highlight the limitations of current LLMs in fiction
writing and advocate for future research to test and create story worlds for
LLMs to reside in. All code, dataset, and the generated responses can be found
in https://github.com/tanny411/llm-reliability-and-consistency-evaluation.

摘要：大型語言模型 (LLM) 的使用已變得無處不在，在計算創意中擁有豐富的應用。其中一項應用就是虛構故事生成。虛構是一種發生在與我們略有不同的故事世界中的敘述。隨著 LLM 成為寫作夥伴，我們質疑它們是否適合產生虛構作品。本研究調查了 LLM 維持對產生虛構作品至關重要的世界狀態的能力。通過向九個 LLM 提出了一系列問題，我們發現只有兩個模型表現出一致的世界觀，而其餘的則自相矛盾。隨後對四個模型產生的故事進行的分析揭示了一個顯著統一的敘事模式。跨模型的這種統一性進一步表明缺乏虛構所必需的「狀態」。我們強調了當前 LLM 在虛構寫作中的局限性，並提倡未來的研究來測試和創建故事世界，供 LLM 存在。所有代碼、數據集和生成的回應都可以在 https://github.com/tanny411/llm-reliability-and-consistency-evaluation 中找到。

##### **Quantum-inspired Interpretable Deep Learning Architecture for Text Sentiment Analysis**
2408.07891v1 by Bingyu Li, Da Zhang, Zhiyuan Zhao, Junyu Gao, Yuan Yuan

Text has become the predominant form of communication on social media,
embedding a wealth of emotional nuances. Consequently, the extraction of
emotional information from text is of paramount importance. Despite previous
research making some progress, existing text sentiment analysis models still
face challenges in integrating diverse semantic information and lack
interpretability. To address these issues, we propose a quantum-inspired deep
learning architecture that combines fundamental principles of quantum mechanics
(QM principles) with deep learning models for text sentiment analysis.
Specifically, we analyze the commonalities between text representation and QM
principles to design a quantum-inspired text representation method and further
develop a quantum-inspired text embedding layer. Additionally, we design a
feature extraction layer based on long short-term memory (LSTM) networks and
self-attention mechanisms (SAMs). Finally, we calculate the text density matrix
using the quantum complex numbers principle and apply 2D-convolution neural
networks (CNNs) for feature condensation and dimensionality reduction. Through
a series of visualization, comparative, and ablation experiments, we
demonstrate that our model not only shows significant advantages in accuracy
and efficiency compared to previous related models but also achieves a certain
level of interpretability by integrating QM principles. Our code is available
at QISA.

摘要：文字已成為社群媒體上主要的溝通形式，
蘊含豐富的情緒細微差別。因此，從文字中萃取情緒資訊至關重要。儘管先前的
研究已取得一些進展，現有的文字情緒分析模型在整合多樣語意資訊時仍
面臨挑戰，且缺乏可解釋性。為了解決這些問題，我們提出一個受量子啟發的深度
學習架構，將量子力學基本原理 (QM 原理) 與深度學習模型結合，用於文字情緒分析。
具體來說，我們分析文字表示與 QM 原理之間的共性，設計一個受量子啟發的文字表示方法，並進一步
開發一個受量子啟發的文字嵌入層。此外，我們設計一個基於長短期記憶 (LSTM) 網路和
自注意力機制 (SAM) 的特徵萃取層。最後，我們使用量子複數原理計算文字密度矩陣，並應用 2D convolution 神經網路 (CNN) 進行特徵壓縮和降維。透過
一系列視覺化、比較和消融實驗，我們
證明我們的模型不僅在準確度和效率方面比先前的相關模型有顯著優勢，而且透過整合 QM 原理，還達到了某種程度的可解釋性。我們的程式碼可在 QISA 取得。

##### **Fine-tuning Large Language Models with Human-inspired Learning Strategies in Medical Question Answering**
2408.07888v1 by Yushi Yang, Andrew M. Bean, Robert McCraith, Adam Mahdi

Training Large Language Models (LLMs) incurs substantial data-related costs,
motivating the development of data-efficient training methods through optimised
data ordering and selection. Human-inspired learning strategies, such as
curriculum learning, offer possibilities for efficient training by organising
data according to common human learning practices. Despite evidence that
fine-tuning with curriculum learning improves the performance of LLMs for
natural language understanding tasks, its effectiveness is typically assessed
using a single model. In this work, we extend previous research by evaluating
both curriculum-based and non-curriculum-based learning strategies across
multiple LLMs, using human-defined and automated data labels for medical
question answering. Our results indicate a moderate impact of using
human-inspired learning strategies for fine-tuning LLMs, with maximum accuracy
gains of 1.77% per model and 1.81% per dataset. Crucially, we demonstrate that
the effectiveness of these strategies varies significantly across different
model-dataset combinations, emphasising that the benefits of a specific
human-inspired strategy for fine-tuning LLMs do not generalise. Additionally,
we find evidence that curriculum learning using LLM-defined question difficulty
outperforms human-defined difficulty, highlighting the potential of using
model-generated measures for optimal curriculum design.

摘要：訓練大型語言模型 (LLM) 會產生大量的與資料相關的成本，
因此透過最佳化的資料排序和選擇來激勵開發資料效率訓練方法。
受人類啟發的學習策略，例如課程學習，提供透過根據常見人類學習實務來組織資料，進行有效訓練的可能性。
儘管有證據顯示，使用課程學習進行微調會改善 LLM 在自然語言理解任務中的表現，但其有效性通常使用單一模型來評估。
在這項工作中，我們透過評估多個 LLM 中基於課程和非課程的學習策略，使用人類定義和自動化的資料標籤進行醫療問題解答，來擴展先前的研究。
我們的結果顯示，使用受人類啟發的學習策略對微調 LLM 產生中等的影響，每個模型的最大準確度提升 1.77%，每個資料集提升 1.81%。
至關重要的是，我們證明了這些策略的有效性在不同的模型資料集組合中差異很大，強調特定受人類啟發的策略對微調 LLM 的好處並未概括。
此外，我們發現證據表明，使用 LLM 定義的問題難度進行課程學習優於人類定義的難度，突顯了使用模型產生的測量標準進行最佳課程設計的潛力。

##### **Instruct Large Language Models to Generate Scientific Literature Survey Step by Step**
2408.07884v1 by Yuxuan Lai, Yupeng Wu, Yidan Wang, Wenpeng Hu, Chen Zheng

Abstract. Automatically generating scientific literature surveys is a
valuable task that can significantly enhance research efficiency. However, the
diverse and complex nature of information within a literature survey poses
substantial challenges for generative models. In this paper, we design a series
of prompts to systematically leverage large language models (LLMs), enabling
the creation of comprehensive literature surveys through a step-by-step
approach. Specifically, we design prompts to guide LLMs to sequentially
generate the title, abstract, hierarchical headings, and the main content of
the literature survey. We argue that this design enables the generation of the
headings from a high-level perspective. During the content generation process,
this design effectively harnesses relevant information while minimizing costs
by restricting the length of both input and output content in LLM queries. Our
implementation with Qwen-long achieved third place in the NLPCC 2024 Scientific
Literature Survey Generation evaluation task, with an overall score only 0.03%
lower than the second-place team. Additionally, our soft heading recall is
95.84%, the second best among the submissions. Thanks to the efficient prompt
design and the low cost of the Qwen-long API, our method reduces the expense
for generating each literature survey to 0.1 RMB, enhancing the practical value
of our method.

摘要：摘要。自動生成科學文獻調查是一項有價值的任務，可以顯著提高研究效率。然而，文獻調查中資訊的多樣性和複雜性對生成模型構成重大挑戰。在本文中，我們設計了一系列提示，以系統性地利用大型語言模型 (LLM)，通過逐步方法創建全面的文獻調查。具體來說，我們設計提示以引導 LLM 按順序生成標題、摘要、分層標題和文獻調查的主要內容。我們認為，這種設計能夠從高層次的角度生成標題。在內容生成過程中，這種設計有效利用相關資訊，同時通過限制 LLM 查詢中輸入和輸出內容的長度來最小化成本。我們使用 Qwen-long 的實作在 NLPCC 2024 科學文獻調查生成評估任務中獲得第三名，總分僅比第二名團隊低 0.03%。此外，我們的軟標題召回率為 95.84%，在提交的論文中排名第二。由於提示設計高效且 Qwen-long API 成本低，我們的的方法將生成每個文獻調查的費用降低到 0.1 元人民幣，提高了我們的方法的實用價值。

##### **Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models**
2408.07873v1 by Layla Bouzoubaa, Elham Aghakhani, Rezvaneh Rezapour

Stigma is a barrier to treatment for individuals struggling with substance
use disorders (SUD), which leads to significantly lower treatment engagement
rates. With only 7% of those affected receiving any form of help, societal
stigma not only discourages individuals with SUD from seeking help but isolates
them, hindering their recovery journey and perpetuating a cycle of shame and
self-doubt. This study investigates how stigma manifests on social media,
particularly Reddit, where anonymity can exacerbate discriminatory behaviors.
We analyzed over 1.2 million posts, identifying 3,207 that exhibited
stigmatizing language towards people who use substances (PWUS). Using Informed
and Stylized LLMs, we develop a model for de-stigmatization of these
expressions into empathetic language, resulting in 1,649 reformed phrase pairs.
Our paper contributes to the field by proposing a computational framework for
analyzing stigma and destigmatizing online content, and delving into the
linguistic features that propagate stigma towards PWUS. Our work not only
enhances understanding of stigma's manifestations online but also provides
practical tools for fostering a more supportive digital environment for those
affected by SUD. Code and data will be made publicly available upon acceptance.

摘要：污名化是與物質使用障礙 (SUD) 作戰的個人在接受治療時會遇到的障礙，這導致治療參與率顯著降低。在受影響者中只有 7% 的人獲得任何形式的幫助，社會污名不僅會阻止有 SUD 的人尋求幫助，還會孤立他們，阻礙他們的康復之旅，並使羞恥和自我懷疑的循環持續下去。本研究調查了污名化在社交媒體（尤其是 Reddit）上的表現方式，在社交媒體上，匿名性可能會加劇歧視行為。我們分析了超過 120 萬個帖子，找出 3,207 個對使用物質者 (PWUS) 使用污名化語言的帖子。使用見多識廣且風格化的 LLM，我們為這些表達方式去污名化制定了一個模型，並轉換成富有同理心的語言，產生了 1,649 對改革後的短語。我們的論文提出了一個用於分析污名化和對線上內容去污名化的計算框架，並深入探討了對 PWUS 造成污名化的語言特徵，為該領域做出了貢獻。我們的研究不僅增進了對污名化在網路上表現的了解，還提供了實用的工具，用於為受 SUD 影響者營造更具支持性的數位環境。在獲得接受後，程式碼和資料將公開提供。

##### **CON-FOLD -- Explainable Machine Learning with Confidence**
2408.07854v1 by Lachlan McGinness, Peter Baumgartner

FOLD-RM is an explainable machine learning classification algorithm that uses
training data to create a set of classification rules. In this paper we
introduce CON-FOLD which extends FOLD-RM in several ways. CON-FOLD assigns
probability-based confidence scores to rules learned for a classification task.
This allows users to know how confident they should be in a prediction made by
the model. We present a confidence-based pruning algorithm that uses the unique
structure of FOLD-RM rules to efficiently prune rules and prevent overfitting.
Furthermore, CON-FOLD enables the user to provide pre-existing knowledge in the
form of logic program rules that are either (fixed) background knowledge or
(modifiable) initial rule candidates. The paper describes our method in detail
and reports on practical experiments. We demonstrate the performance of the
algorithm on benchmark datasets from the UCI Machine Learning Repository. For
that, we introduce a new metric, Inverse Brier Score, to evaluate the accuracy
of the produced confidence scores. Finally we apply this extension to a real
world example that requires explainability: marking of student responses to a
short answer question from the Australian Physics Olympiad.

摘要：FOLD-RM 是一種可解釋機器學習分類演算法，它利用訓練資料來建立一組分類規則。在本文中，我們介紹了 CON-FOLD，它在多方面擴展了 FOLD-RM。CON-FOLD 會將基於機率的信心評分指派給分類任務所學習的規則。這使用戶能夠知道他們對模型所做的預測有多大的信心。我們提出了一種基於信心的剪枝演算法，它利用 FOLD-RM 規則的獨特結構來有效地剪枝規則並防止過度擬合。此外，CON-FOLD 使用戶能夠以邏輯程式規則的形式提供預先存在的知識，這些規則可能是（固定的）背景知識或（可修改的）初始規則候選。本文詳細描述了我們的程式，並報告了實際實驗。我們在 UCI 機器學習儲存庫的基準資料集上展示了演算法的效能。為此，我們引入了一個新的指標，逆布里爾分數，來評估所產生的信心評分的準確性。最後，我們將此延伸應用於需要可解釋性的真實世界範例：評分澳洲物理奧林匹克競賽中學生對簡答題的回答。

##### **Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability**
2408.07852v1 by Jiri Hron, Laura Culp, Gamaleldin Elsayed, Rosanne Liu, Ben Adlam, Maxwell Bileschi, Bernd Bohnet, JD Co-Reyes, Noah Fiedel, C. Daniel Freeman, Izzeddin Gur, Kathleen Kenealy, Jaehoon Lee, Peter J. Liu, Gaurav Mishra, Igor Mordatch, Azade Nova, Roman Novak, Aaron Parisi, Jeffrey Pennington, Alex Rizkowsky, Isabelle Simpson, Hanie Sedghi, Jascha Sohl-dickstein, Kevin Swersky, Sharad Vikram, Tris Warkentin, Lechao Xiao, Kelvin Xu, Jasper Snoek, Simon Kornblith

While many capabilities of language models (LMs) improve with increased
training budget, the influence of scale on hallucinations is not yet fully
understood. Hallucinations come in many forms, and there is no universally
accepted definition. We thus focus on studying only those hallucinations where
a correct answer appears verbatim in the training set. To fully control the
training data content, we construct a knowledge graph (KG)-based dataset, and
use it to train a set of increasingly large LMs. We find that for a fixed
dataset, larger and longer-trained LMs hallucinate less. However, hallucinating
on $\leq5$% of the training data requires an order of magnitude larger model,
and thus an order of magnitude more compute, than Hoffmann et al. (2022)
reported was optimal. Given this costliness, we study how hallucination
detectors depend on scale. While we see detector size improves performance on
fixed LM's outputs, we find an inverse relationship between the scale of the LM
and the detectability of its hallucinations.

摘要：雖然語言模型 (LM) 的許多能力會隨著訓練預算的增加而有所提升，但規模對幻覺的影響尚未完全了解。幻覺有許多形式，且沒有普遍接受的定義。因此，我們只專注於研究訓練集中出現正確答案的幻覺。為了完全控制訓練資料內容，我們建構了一個基於知識圖譜 (KG) 的資料集，並使用它來訓練一組越來越大的 LM。我們發現對於固定的資料集，規模較大且訓練時間較長的 LM 產生的幻覺較少。然而，在 $\leq5$% 的訓練資料上產生幻覺需要規模大一個數量級的模型，因此比 Hoffmann 等人 (2022) 所報告的最佳規模多一個數量級的運算成本。考量到這種成本，我們研究幻覺偵測器如何取決於規模。雖然我們看到偵測器規模會提升對固定 LM 輸出的效能，但我們發現 LM 的規模與其幻覺的可偵測性之間存在反比關係。

##### **SER Evals: In-domain and Out-of-domain Benchmarking for Speech Emotion Recognition**
2408.07851v1 by Mohamed Osman, Daniel Z. Kaplan, Tamer Nadeem

Speech emotion recognition (SER) has made significant strides with the advent
of powerful self-supervised learning (SSL) models. However, the generalization
of these models to diverse languages and emotional expressions remains a
challenge. We propose a large-scale benchmark to evaluate the robustness and
adaptability of state-of-the-art SER models in both in-domain and out-of-domain
settings. Our benchmark includes a diverse set of multilingual datasets,
focusing on less commonly used corpora to assess generalization to new data. We
employ logit adjustment to account for varying class distributions and
establish a single dataset cluster for systematic evaluation. Surprisingly, we
find that the Whisper model, primarily designed for automatic speech
recognition, outperforms dedicated SSL models in cross-lingual SER. Our results
highlight the need for more robust and generalizable SER models, and our
benchmark serves as a valuable resource to drive future research in this
direction.

摘要：語音情緒辨識 (SER) 已隨著強大的自我監督式學習 (SSL) 模型的出現，取得顯著進展。然而，這些模型在不同語言和情緒表達上的概化能力，仍然是一項挑戰。我們提出一個大規模基準，以評估最先進 SER 模型在領域內和領域外設定中，的穩健性和適應性。我們的基準包含一套多元的多語言資料集，專注於評估對新資料的概化能力，較不常用的語料庫。我們採用邏輯調整來考量不同的類別分佈，並建立一個單一的資料集叢集，進行系統評估。令人驚訝的是，我們發現主要設計用於自動語音辨識的 Whisper 模型，在跨語言 SER 中表現優於專屬的 SSL 模型。我們的結果突顯了對更穩健和更具概化能力的 SER 模型的需求，而我們的基準作為一個有價值的資源，推動了未來在這個方向的研究。

##### **A System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites**
2408.07846v1 by Andrea Lops, Fedelucio Narducci, Azzurra Ragone, Michelantonio Trizio, Claudio Bartolini

Unit tests represent the most basic level of testing within the software
testing lifecycle and are crucial to ensuring software correctness. Designing
and creating unit tests is a costly and labor-intensive process that is ripe
for automation. Recently, Large Language Models (LLMs) have been applied to
various aspects of software development, including unit test generation.
Although several empirical studies evaluating LLMs' capabilities in test code
generation exist, they primarily focus on simple scenarios, such as the
straightforward generation of unit tests for individual methods. These
evaluations often involve independent and small-scale test units, providing a
limited view of LLMs' performance in real-world software development scenarios.
Moreover, previous studies do not approach the problem at a suitable scale for
real-life applications. Generated unit tests are often evaluated via manual
integration into the original projects, a process that limits the number of
tests executed and reduces overall efficiency. To address these gaps, we have
developed an approach for generating and evaluating more real-life complexity
test suites. Our approach focuses on class-level test code generation and
automates the entire process from test generation to test assessment. In this
work, we present \textsc{AgoneTest}: an automated system for generating test
suites for Java projects and a comprehensive and principled methodology for
evaluating the generated test suites. Starting from a state-of-the-art dataset
(i.e., \textsc{Methods2Test}), we built a new dataset for comparing
human-written tests with those generated by LLMs. Our key contributions include
a scalable automated software system, a new dataset, and a detailed methodology
for evaluating test quality.

摘要：單元測試代表軟體測試生命週期中測試的最基本層級，對於確保軟體正確性至關重要。設計和建立單元測試是一項成本高昂且勞力密集的程序，非常適合自動化。最近，大型語言模型 (LLM) 已應用於軟體開發的各個方面，包括單元測試產生。儘管有幾項實證研究評估 LLM 在測試程式碼產生中的能力，但它們主要著重於簡單的場景，例如針對個別方法產生單元測試。這些評估通常涉及獨立且小規模的測試單元，提供 LLM 在真實軟體開發場景中效能的有限視野。此外，先前的研究並未以適合實際應用程式規模的方式來探討問題。產生的單元測試通常透過手動整合到原始專案中來評估，這個程序限制了執行測試的數量，並降低了整體效率。為了解決這些差距，我們已開發出一種方法來產生和評估更真實複雜性的測試套件。我們的做法著重於類別層級的測試程式碼產生，並自動化從測試產生到測試評估的整個程序。在這項工作中，我們提出 \textsc{AgoneTest}：一個用於為 Java 專案產生測試套件的自動化系統，以及一個用於評估產生測試套件的全面且有原則的方法。從最先進的資料集 (即 \textsc{Methods2Test}) 開始，我們建立了一個新的資料集，用於比較人為編寫的測試與 LLM 產生的測試。我們的關鍵貢獻包括一個可擴充的自動化軟體系統、一個新的資料集，以及一個用於評估測試品質的詳細方法。

##### **Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**
2408.07845v1 by Musa Taib, Jiajun Wu, Steve Drew, Geoffrey G. Messier

The top priority of a Housing and Homelessness System of Care (HHSC) is to
connect people experiencing homelessness to supportive housing. An HHSC
typically consists of many agencies serving the same population. Information
technology platforms differ in type and quality between agencies, so their data
are usually isolated from one agency to another. Larger agencies may have
sufficient data to train and test artificial intelligence (AI) tools but
smaller agencies typically do not. To address this gap, we introduce a
Federated Learning (FL) approach enabling all agencies to train a predictive
model collaboratively without sharing their sensitive data. We demonstrate how
FL can be used within an HHSC to provide all agencies equitable access to
quality AI and further assist human decision-makers in the allocation of
resources within HHSC. This is achieved while preserving the privacy of the
people within the data by not sharing identifying information between agencies
without their consent. Our experimental results using real-world HHSC data from
Calgary, Alberta, demonstrate that our FL approach offers comparable
performance with the idealized scenario of training the predictive model with
data fully shared and linked between agencies.

摘要：住房和無家可歸者照護系統 (HHSC) 的首要任務是
將無家可歸者與支持性住房連結起來。HHSC
通常由許多服務於相同族群的機構組成。資訊
技術平台在各個機構之間的類型和品質不同，因此他們的資料
通常彼此孤立。較大型的機構可能擁有足夠的資料來訓練和測試人工智慧 (AI) 工具，但
較小型機構通常沒有。為了解決這個差距，我們引入了一種
聯合式學習 (FL) 方法，讓所有機構都能夠在不分享其敏感資料的情況下共同訓練一個預測
模型。我們展示了 FL 如何在 HHSC 中使用，以提供所有機構公平取得
優質 AI 的機會，並進一步協助人類決策者在 HHSC 內部分配
資源。這是在不經機構同意的情況下，不分享識別資訊的情況下，保護資料中人們的隱私來實現的。我們使用來自
加拿大艾伯塔省卡加利的真實世界 HHSC 資料進行實驗結果顯示，我們的 FL 方法提供與在機構之間完全分享和連結資料的理想預測模型訓練情境相當的
效能。

##### **ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model**
2408.07840v1 by Xuanqing Yu, Wangtao Sun, Jingwei Li, Kang Liu, Chengbao Liu, Jie Tan

In the realm of event prediction, temporal knowledge graph forecasting (TKGF)
stands as a pivotal technique. Previous approaches face the challenges of not
utilizing experience during testing and relying on a single short-term history,
which limits adaptation to evolving data. In this paper, we introduce the
Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by
integrating dynamic causal rule mining (DCRM) and dual history augmented
generation (DHAG). DCRM dynamically constructs causal rules from real-time
data, allowing for swift adaptation to new causal relationships. In parallel,
DHAG merges short-term and long-term historical contexts, leveraging a
bi-branch approach to enrich event prediction. Our framework demonstrates
notable performance enhancements across diverse datasets, with significant
Hit@k (k=1,3,10) improvements, showcasing its ability to augment large language
models (LLMs) for event prediction without necessitating extensive retraining.
The ONSEP framework not only advances the field of TKGF but also underscores
the potential of neural-symbolic approaches in adapting to dynamic data
environments.

摘要：在事件預測領域中，時序知識圖譜預測 (TKGF) 是一個關鍵技術。先前的做法面臨在測試期間不利用經驗以及依賴單一短期歷史的挑戰，這限制了對演化資料的適應性。在本文中，我們介紹了線上神經符號事件預測 (ONSEP) 架構，它透過整合動態因果規則挖掘 (DCRM) 和雙重歷史擴充生成 (DHAG) 來創新。DCRM 從即時資料中動態建構因果規則，允許快速適應新的因果關係。同時，DHAG 合併短期和長期歷史脈絡，利用雙分支方法來豐富事件預測。我們的架構在各種資料集上展示出顯著的效能提升，Hit@k (k=1,3,10) 有顯著的改善，展示了它在無需廣泛重新訓練的情況下擴充大型語言模型 (LLM) 以進行事件預測的能力。ONSEP 架構不僅推動了 TKGF 領域，也強調了神經符號方法在適應動態資料環境中的潛力。

##### **An Efficient and Explanatory Image and Text Clustering System with Multimodal Autoencoder Architecture**
2408.07791v1 by Tiancheng Shi, Yuanchen Wei, John R. Kender

We demonstrate the efficiencies and explanatory abilities of extensions to
the common tools of Autoencoders and LLM interpreters, in the novel context of
comparing different cultural approaches to the same international news event.
We develop a new Convolutional-Recurrent Variational Autoencoder (CRVAE) model
that extends the modalities of previous CVAE models, by using fully-connected
latent layers to embed in parallel the CNN encodings of video frames, together
with the LSTM encodings of their related text derived from audio. We
incorporate the model within a larger system that includes frame-caption
alignment, latent space vector clustering, and a novel LLM-based cluster
interpreter. We measure, tune, and apply this system to the task of summarizing
a video into three to five thematic clusters, with each theme described by ten
LLM-produced phrases. We apply this system to two news topics, COVID-19 and the
Winter Olympics, and five other topics are in progress.

摘要：我們展示了自動編碼器和 LLM 解釋器的常見工具的延伸功能和解釋能力，在比較不同文化對同一國際新聞事件的方法的新穎背景下。我們開發了一個新的卷積遞迴變異自動編碼器 (CRVAE) 模型，它通過使用全連接潛在層並行嵌入影片幀的 CNN 編碼，以及從音訊中衍生的相關文字的 LSTM 編碼，來擴充先前 CVAE 模型的模式。我們將模型整合到一個更大的系統中，其中包括幀標題對齊、潛在空間向量聚類以及一個新穎的基於 LLM 的聚類解釋器。我們測量、調整並將此系統應用於將影片摘要成三到五個主題聚類的任務，每個主題由十個 LLM 產生的短語描述。我們將此系統應用於兩個新聞主題，COVID-19 和冬季奧運會，還有五個其他主題正在進行中。

##### **The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**
2408.07702v1 by Karime Maamari, Fadhil Abubaker, Daniel Jaroslawicz, Amine Mhedhbi

Schema linking is a crucial step in Text-to-SQL pipelines, which translate
natural language queries into SQL. The goal of schema linking is to retrieve
relevant tables and columns (signal) while disregarding irrelevant ones
(noise). However, imperfect schema linking can often exclude essential columns
needed for accurate query generation. In this work, we revisit the need for
schema linking when using the latest generation of large language models
(LLMs). We find empirically that newer models are adept at identifying relevant
schema elements during generation, without the need for explicit schema
linking. This allows Text-to-SQL pipelines to bypass schema linking entirely
and instead pass the full database schema to the LLM, eliminating the risk of
excluding necessary information. Furthermore, as alternatives to schema
linking, we propose techniques that improve Text-to-SQL accuracy without
compromising on essential schema information. Our approach achieves 71.83\%
execution accuracy on the BIRD benchmark, ranking first at the time of
submission.

摘要：模式連結是文字轉 SQL 管線中至關重要的一步，它將自然語言查詢轉換成 SQL。模式連結的目標是擷取相關的表格和欄位（訊號），同時忽略不相關的（雜訊）。然而，不完美的模式連結通常會排除產生精準查詢所需的必要欄位。在這項工作中，我們重新探討在使用最新一代大型語言模型（LLM）時模式連結的必要性。我們在經驗上發現，較新的模型在產生過程中很擅長識別相關的模式元素，而不需要明確的模式連結。這允許文字轉 SQL 管線完全繞過模式連結，而將完整的資料庫模式傳遞給 LLM，消除了排除必要資訊的風險。此外，作為模式連結的替代方案，我們提出了一些技術，可以在不損害必要模式資訊的情況下提高文字轉 SQL 的準確性。我們的做法在 BIRD 基準上達到了 71.83% 的執行準確度，在提交時排名第一。

##### **Quantifying over Optimum Answer Sets**
2408.07697v1 by Giuseppe Mazzotta, Francesco Ricca, Mirek Truszczynski

Answer Set Programming with Quantifiers (ASP(Q)) has been introduced to
provide a natural extension of ASP modeling to problems in the polynomial
hierarchy (PH). However, ASP(Q) lacks a method for encoding in an elegant and
compact way problems requiring a polynomial number of calls to an oracle in
$\Sigma_n^p$ (that is, problems in $\Delta_{n+1}^p$). Such problems include, in
particular, optimization problems. In this paper we propose an extension of
ASP(Q), in which component programs may contain weak constraints. Weak
constraints can be used both for expressing local optimization within
quantified component programs and for modeling global optimization criteria. We
showcase the modeling capabilities of the new formalism through various
application scenarios. Further, we study its computational properties obtaining
complexity results and unveiling non-obvious characteristics of ASP(Q) programs
with weak constraints.

摘要：回答集程式設計與量詞 (ASP(Q)) 已被引入，以提供 ASP 建模到多項式階層 (PH) 問題的自然延伸。然而，ASP(Q) 缺乏一種方法，可以用優雅且簡潔的方式對需要對 $\Sigma_n^p$ 中的預言機進行多項式次數呼叫的問題進行編碼（也就是說，$\Delta_{n+1}^p$ 中的問題）。此類問題特別包括最佳化問題。在本文中，我們提出 ASP(Q) 的延伸，其中組成程式可以包含弱約束。弱約束可以用於表達量化組成程式中的局部最佳化，以及用於建模全域最佳化準則。我們透過各種應用場景展示新形式化的建模能力。此外，我們研究其計算性質，取得複雜度結果，並揭示具有弱約束的 ASP(Q) 程式的非顯著特徵。

##### **Enhancing Model Interpretability with Local Attribution over Global Exploration**
2408.07736v1 by Zhiyu Zhu, Zhibo Jin, Jiayu Zhang, Huaming Chen

In the field of artificial intelligence, AI models are frequently described
as `black boxes' due to the obscurity of their internal mechanisms. It has
ignited research interest on model interpretability, especially in attribution
methods that offers precise explanations of model decisions. Current
attribution algorithms typically evaluate the importance of each parameter by
exploring the sample space. A large number of intermediate states are
introduced during the exploration process, which may reach the model's
Out-of-Distribution (OOD) space. Such intermediate states will impact the
attribution results, making it challenging to grasp the relative importance of
features. In this paper, we firstly define the local space and its relevant
properties, and we propose the Local Attribution (LA) algorithm that leverages
these properties. The LA algorithm comprises both targeted and untargeted
exploration phases, which are designed to effectively generate intermediate
states for attribution that thoroughly encompass the local space. Compared to
the state-of-the-art attribution methods, our approach achieves an average
improvement of 38.21\% in attribution effectiveness. Extensive ablation studies
in our experiments also validate the significance of each component in our
algorithm. Our code is available at: https://github.com/LMBTough/LA/

摘要：在人工智能领域，由于内部机制的不透明性，AI 模型经常被描述为“黑匣子”。这激发了对模型可解释性的研究兴趣，尤其是在提供模型决策精确解释的归因方法中。当前的归因算法通常通过探索样本空间来评估每个参数的重要性。在探索过程中引入了大量的中间状态，这些状态可能达到模型的分布外 (OOD) 空间。此类中间状态会影响归因结果，从而难以掌握特征的相对重要性。在本文中，我们首先定义局部空间及其相关属性，并提出了利用这些属性的局部归因 (LA) 算法。LA 算法包括有针对性和无针对性的探索阶段，这些阶段旨在有效地为归因生成中间状态，以彻底涵盖局部空间。与最先进的归因方法相比，我们的方法在归因有效性方面平均提高了 38.21%。我们实验中的广泛消融研究也验证了我们算法中每个组件的重要性。我们的代码可在以下位置获得：https://github.com/LMBTough/LA/

##### **End-to-end Semantic-centric Video-based Multimodal Affective Computing**
2408.07694v1 by Ronghao Lin, Ying Zeng, Sijie Mai, Haifeng Hu

In the pathway toward Artificial General Intelligence (AGI), understanding
human's affection is essential to enhance machine's cognition abilities. For
achieving more sensual human-AI interaction, Multimodal Affective Computing
(MAC) in human-spoken videos has attracted increasing attention. However,
previous methods are mainly devoted to designing multimodal fusion algorithms,
suffering from two issues: semantic imbalance caused by diverse pre-processing
operations and semantic mismatch raised by inconsistent affection content
contained in different modalities comparing with the multimodal ground truth.
Besides, the usage of manual features extractors make they fail in building
end-to-end pipeline for multiple MAC downstream tasks. To address above
challenges, we propose a novel end-to-end framework named SemanticMAC to
compute multimodal semantic-centric affection for human-spoken videos. We
firstly employ pre-trained Transformer model in multimodal data pre-processing
and design Affective Perceiver module to capture unimodal affective
information. Moreover, we present a semantic-centric approach to unify
multimodal representation learning in three ways, including gated feature
interaction, multi-task pseudo label generation, and intra-/inter-sample
contrastive learning. Finally, SemanticMAC effectively learn specific- and
shared-semantic representations in the guidance of semantic-centric labels.
Extensive experimental results demonstrate that our approach surpass the
state-of-the-art methods on 7 public datasets in four MAC downstream tasks.

摘要：在通往人工通用智能 (AGI) 的道路上，理解人类的情感对于增强机器的认知能力至关重要。为了实现更感性的的人机交互，人类语音视频中的多模态情感计算 (MAC) 吸引了越来越多的关注。然而，以前的方法主要致力于设计多模态融合算法，存在两个问题：由不同的预处理操作导致的语义不平衡以及与多模态基本事实相比，不同模态中包含的不一致情感内容导致的语义不匹配。此外，手动特征提取器的使用使得它们无法为多个 MAC 下游任务构建端到端管道。为了解决上述挑战，我们提出了一种名为 SemanticMAC 的新颖端到端框架，用于计算人类语音视频的多模态语义中心情感。我们首先在多模态数据预处理中采用预训练的 Transformer 模型，并设计情感感知器模块来捕获单模态情感信息。此外，我们提出了一种语义中心方法，通过门控特征交互、多任务伪标签生成以及样本内/样本间对比学习这三种方式来统一多模态表示学习。最后，SemanticMAC 在语义中心标签的指导下有效地学习特定和共享语义表示。广泛的实验结果表明，我们的方法在四个 MAC 下游任务的 7 个公共数据集上超越了最先进的方法。

##### **A Spitting Image: Modular Superpixel Tokenization in Vision Transformers**
2408.07680v2 by Marius Aasan, Odd Kolbjørnsen, Anne Schistad Solberg, Adín Ramirez Rivera

Vision Transformer (ViT) architectures traditionally employ a grid-based
approach to tokenization independent of the semantic content of an image. We
propose a modular superpixel tokenization strategy which decouples tokenization
and feature extraction; a shift from contemporary approaches where these are
treated as an undifferentiated whole. Using on-line content-aware tokenization
and scale- and shape-invariant positional embeddings, we perform experiments
and ablations that contrast our approach with patch-based tokenization and
randomized partitions as baselines. We show that our method significantly
improves the faithfulness of attributions, gives pixel-level granularity on
zero-shot unsupervised dense prediction tasks, while maintaining predictive
performance in classification tasks. Our approach provides a modular
tokenization framework commensurable with standard architectures, extending the
space of ViTs to a larger class of semantically-rich models.

摘要：視覺轉換器 (ViT) 架構傳統上採用基於網格的方法進行標記化，而與影像的語義內容無關。我們提出一個模組化的超像素標記化策略，它解耦了標記化和特徵萃取；與將這些視為一個未區分的整體的當代方法不同。使用線上內容感知標記化和尺度及形狀不變的位置嵌入，我們執行實驗和消融，將我們的方法與基於修補程式的標記化和隨機分割作為基準進行對比。我們展示了我們的方法顯著提升了歸因的保真度，在零次學習無監督密集預測任務中提供了像素級粒度，同時在分類任務中維持預測效能。我們的方法提供了一個模組化的標記化架構，與標準架構相稱，將 ViT 的空間擴展到一類更大的語義豐富模型。

##### **Enhanced Detection of Conversational Mental Manipulation Through Advanced Prompting Techniques**
2408.07676v1 by Ivory Yang, Xiaobo Guo, Sean Xie, Soroush Vosoughi

This study presents a comprehensive, long-term project to explore the
effectiveness of various prompting techniques in detecting dialogical mental
manipulation. We implement Chain-of-Thought prompting with Zero-Shot and
Few-Shot settings on a binary mental manipulation detection task, building upon
existing work conducted with Zero-Shot and Few- Shot prompting. Our primary
objective is to decipher why certain prompting techniques display superior
performance, so as to craft a novel framework tailored for detection of mental
manipulation. Preliminary findings suggest that advanced prompting techniques
may not be suitable for more complex models, if they are not trained through
example-based learning.

摘要：本研究提出了一個全面、長期的專案，以探討各種提示技術在檢測對話式心理操縱中的有效性。我們在二元心理操縱檢測任務中實作了零次學習和少次學習設定下的思想鏈提示，並建立在使用零次學習和少次學習提示進行的既有工作之上。我們的首要目標是解碼為何某些提示技術表現出優異的效能，以便為檢測心理操縱量身打造一個新穎的架構。初步發現表明，如果進階提示技術未透過基於範例的學習進行訓練，則可能不適合更複雜的模型。

##### **Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data**
2408.07673v2 by Xia Jiang, Yijun Zhou, Chuhan Xu, Adam Brufsky, Alan Wells

A grid search, at the cost of training and testing a large number of models,
is an effective way to optimize the prediction performance of deep learning
models. A challenging task concerning grid search is the time management.
Without a good time management scheme, a grid search can easily be set off as a
mission that will not finish in our lifetime. In this study, we introduce a
heuristic three-stage mechanism for managing the running time of low-budget
grid searches, and the sweet-spot grid search (SSGS) and randomized grid search
(RGS) strategies for improving model prediction performance, in predicting the
5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep
feedforward neural network (DFNN) models and optimize them through grid
searches. We conduct eight cycles of grid searches by applying our three-stage
mechanism and SSGS and RGS strategies. We conduct various SHAP analyses
including unique ones that interpret the importance of the DFNN-model
hyperparameters. Our results show that grid search can greatly improve model
prediction. The grid searches we conducted improved the risk prediction of
5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and
17.3% respectively, over the average performance of all corresponding models we
trained using the RGS strategy. We not only demonstrate best model performance
but also characterize grid searches from various aspects such as their
capabilities of discovering decent models and the unit grid search time. The
three-stage mechanism worked effectively. It made our low-budget grid searches
feasible and manageable, and in the meantime helped improve model prediction
performance. Our SHAP analyses identified both clinical risk factors important
for the prediction of future risk of breast cancer metastasis, and DFNN-model
hyperparameters important to the prediction of performance scores.

摘要：<paragraph>網格搜尋以訓練和測試大量模型為代價，是一種優化深度學習模型預測效能的有效方法。網格搜尋中一項具有挑戰性的任務是時間管理。沒有良好的時間管理機制，網格搜尋很容易被設定為一項在我們有生之年都無法完成的任務。在本研究中，我們介紹了一種啟發式三階段機制，用於管理低預算網格搜尋的執行時間，以及用於改善模型預測效能的最佳點網格搜尋 (SSGS) 和隨機網格搜尋 (RGS) 策略，以預測乳癌轉移的 5 年、10 年和 15 年風險。我們開發了深度前饋神經網路 (DFNN) 模型，並透過網格搜尋對它們進行優化。我們透過應用三階段機制和 SSGS 和 RGS 策略進行了八個週期的網格搜尋。我們進行了各種 SHAP 分析，包括解釋 DFNN 模型超參數重要性的獨特分析。我們的結果顯示網格搜尋可以大幅改善模型預測。我們進行的網格搜尋分別將 5 年、10 年和 15 年乳癌轉移的風險預測改善了 18.6%、16.3% 和 17.3%，優於我們使用 RGS 策略訓練的所有對應模型的平均效能。我們不僅展示了最佳模型效能，還從各種面向描述網格搜尋，例如它們發現良好模型的能力和單元網格搜尋時間。三階段機制有效運作。它使我們的低預算網格搜尋可行且易於管理，同時也有助於改善模型預測效能。我們的 SHAP 分析確定了對預測未來乳癌轉移風險很重要的臨床風險因子，以及對預測效能評分很重要的 DFNN 模型超參數。</paragraph>

##### **Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**
2408.07666v2 by Enneng Yang, Li Shen, Guibing Guo, Xingwei Wang, Xiaochun Cao, Jie Zhang, Dacheng Tao

Model merging is an efficient empowerment technique in the machine learning
community that does not require the collection of raw training data and does
not require expensive computation. As model merging becomes increasingly
prevalent across various fields, it is crucial to understand the available
model merging techniques comprehensively. However, there is a significant gap
in the literature regarding a systematic and thorough review of these
techniques. This survey provides a comprehensive overview of model merging
methods and theories, their applications in various domains and settings, and
future research directions. Specifically, we first propose a new taxonomic
approach that exhaustively discusses existing model merging methods. Secondly,
we discuss the application of model merging techniques in large language
models, multimodal large language models, and 10+ machine learning subfields,
including continual learning, multi-task learning, few-shot learning, etc.
Finally, we highlight the remaining challenges of model merging and discuss
future research directions. A comprehensive list of papers about model merging
is available at
\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}.

摘要：模型合併是一種機器學習社群中有效能的賦能技術，不需要收集原始訓練資料，也不需要昂貴的計算。由於模型合併在各個領域日益盛行，因此全面了解現有的模型合併技術至關重要。然而，在對這些技術進行系統化且徹底的回顧方面，文獻中存在著顯著的空白。本調查提供了模型合併方法和理論的全面概述、它們在各種領域和設定中的應用，以及未來的研究方向。具體來說，我們首先提出了一種新的分類方法，對現有的模型合併方法進行了詳盡的討論。其次，我們討論了模型合併技術在大語言模型、多模態大語言模型和 10 多個機器學習子領域中的應用，包括持續學習、多任務學習、少量學習等。最後，我們強調了模型合併的剩餘挑戰，並討論了未來的研究方向。關於模型合併的論文清單可在以下網址取得：\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。

##### **Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**
2408.07665v1 by Yi-Cheng Lin, Wei-Chih Chen, Hung-yi Lee

Warning: This paper may contain texts with uncomfortable content.
  Large Language Models (LLMs) have achieved remarkable performance in various
tasks, including those involving multimodal data like speech. However, these
models often exhibit biases due to the nature of their training data. Recently,
more Speech Large Language Models (SLLMs) have emerged, underscoring the urgent
need to address these biases. This study introduces Spoken Stereoset, a dataset
specifically designed to evaluate social biases in SLLMs. By examining how
different models respond to speech from diverse demographic groups, we aim to
identify these biases. Our experiments reveal significant insights into their
performance and bias levels. The findings indicate that while most models show
minimal bias, some still exhibit slightly stereotypical or anti-stereotypical
tendencies.

摘要：警告：本文可能包含令人不適的內容。
大型語言模型 (LLM) 在各種任務中取得了顯著的表現，包括涉及多模態數據（例如語音）的任務。然而，這些模型由於其訓練數據的性質，往往會表現出偏見。最近，出現了更多語音大型語言模型 (SLLM)，強調了解決這些偏見的迫切需要。本研究引入了 Spoken Stereoset，這是一個專門設計用於評估 SLLM 中社會偏見的數據集。透過檢視不同模型如何回應來自不同人口群體的語音，我們旨在找出這些偏見。我們的實驗揭示了對其效能和偏見程度的重大見解。研究結果表明，儘管大多數模型顯示出最小的偏見，但有些模型仍然表現出輕微的刻板印象或反刻板印象傾向。

##### **Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**
2408.07663v1 by Quan Liu, Zhenhong Zhou, Longzhu He, Yi Liu, Wei Zhang, Sen Su

Large language models are susceptible to jailbreak attacks, which can result
in the generation of harmful content. While prior defenses mitigate these risks
by perturbing or inspecting inputs, they ignore competing objectives, the
underlying cause of alignment failures. In this paper, we propose
Alignment-Enhanced Decoding (AED), a novel defense that employs adaptive
decoding to address the root causes of jailbreak issues. We first define the
Competitive Index to quantify alignment failures and utilize feedback from
self-evaluation to compute post-alignment logits. Then, AED adaptively combines
AED and post-alignment logits with the original logits to obtain harmless and
helpful distributions. Consequently, our method enhances safety alignment while
maintaining helpfulness. We conduct experiments across five models and four
common jailbreaks, with the results validating the effectiveness of our
approach. Code is available at https://github.com/GIGABaozi/AED.git.

摘要：大型語言模型容易受到越獄攻擊，這可能會導致產生有害內容。雖然先前的防禦措施會透過擾動或檢查輸入來減輕這些風險，但它們會忽略競爭目標，也就是對齊失敗的根本原因。在這篇論文中，我們提出增強對齊解碼 (AED)，這是一種新穎的防禦措施，採用自適應解碼來解決越獄問題的根本原因。我們首先定義競爭指數來量化對齊失敗，並利用自我評估的回饋來計算後對齊 logit。然後，AED 自適應地將 AED 和後對齊 logit 與原始 logit 結合，以獲得無害且有用的分佈。因此，我們的模型增強了安全性對齊，同時保持了有益性。我們針對五個模型和四個常見的越獄進行了實驗，結果驗證了我們方法的有效性。程式碼可在 https://github.com/GIGABaozi/AED.git 取得。

##### **Boosting Unconstrained Face Recognition with Targeted Style Adversary**
2408.07642v1 by Mohammad Saeed Ebrahimi Saadabadi, Sahar Rahimi Malakshan, Seyed Rasoul Hosseini, Nasser M. Nasrabadi

While deep face recognition models have demonstrated remarkable performance,
they often struggle on the inputs from domains beyond their training data.
Recent attempts aim to expand the training set by relying on computationally
expensive and inherently challenging image-space augmentation of image
generation modules. In an orthogonal direction, we present a simple yet
effective method to expand the training data by interpolating between
instance-level feature statistics across labeled and unlabeled sets. Our
method, dubbed Targeted Style Adversary (TSA), is motivated by two
observations: (i) the input domain is reflected in feature statistics, and (ii)
face recognition model performance is influenced by style information. Shifting
towards an unlabeled style implicitly synthesizes challenging training
instances. We devise a recognizability metric to constraint our framework to
preserve the inherent identity-related information of labeled instances. The
efficacy of our method is demonstrated through evaluations on unconstrained
benchmarks, outperforming or being on par with its competitors while offering
nearly a 70\% improvement in training speed and 40\% less memory consumption.

摘要：儘管深度人臉辨識模型已展現出卓越的效能，
但它們在訓練資料以外的領域輸入中往往會遇到困難。
最近的嘗試旨在透過依賴於計算成本高且本質上具有挑戰性的影像空間擴充技術，來擴充訓練組，以擴充影像產生模組。在正交方向上，我們提出了一個簡單但有效的方法，透過插補標籤和未標籤組中的實例層級特徵統計資料，來擴充訓練資料。我們的這個方法稱為目標樣式對抗 (TSA)，其動機來自兩個觀察結果：(i) 輸入領域反映在特徵統計資料中，以及 (ii) 人臉辨識模型效能受到樣式資訊的影響。轉移到未標籤樣式會隱含地合成具有挑戰性的訓練實例。我們設計了一個可辨識度量數，以限制我們的架構，以保留標籤實例中與身分相關的固有資訊。我們的方法的效能透過在不受約束的基準上進行評估，證明了其效能，其效能優於或與競爭者不相上下，同時在訓練速度上提升了近 70%，記憶體消耗減少了 40%。

##### **Hierarchical Working Memory and a New Magic Number**
2408.07637v1 by Weishun Zhong, Mikhail Katkov, Misha Tsodyks

The extremely limited working memory span, typically around four items,
contrasts sharply with our everyday experience of processing much larger
streams of sensory information concurrently. This disparity suggests that
working memory can organize information into compact representations such as
chunks, yet the underlying neural mechanisms remain largely unknown. Here, we
propose a recurrent neural network model for chunking within the framework of
the synaptic theory of working memory. We showed that by selectively
suppressing groups of stimuli, the network can maintain and retrieve the
stimuli in chunks, hence exceeding the basic capacity. Moreover, we show that
our model can dynamically construct hierarchical representations within working
memory through hierarchical chunking. A consequence of this proposed mechanism
is a new limit on the number of items that can be stored and subsequently
retrieved from working memory, depending only on the basic working memory
capacity when chunking is not invoked. Predictions from our model were
confirmed by analyzing single-unit responses in epileptic patients and memory
experiments with verbal material. Our work provides a novel conceptual and
analytical framework for understanding the on-the-fly organization of
information in the brain that is crucial for cognition.

摘要：極度有限的工作記憶範圍，通常約為四個項目，與我們日常處理大量感官資訊流的經驗形成鮮明對比。這種差異表明工作記憶可以將資訊組織成緊湊的表示，例如塊，但其背後的神經機制在很大程度上仍然未知。在這裡，我們提出了一個遞迴神經網路模型，用於在工作記憶突觸理論的框架內進行分塊。我們表明，通過選擇性地抑制刺激組，網路可以維護和檢索塊中的刺激，從而超過基本容量。此外，我們表明我們的模型可以通過分層分塊在工作記憶中動態構建分層表示。這種提議機制的後果是對可以儲存並隨後從工作記憶中檢索的項目數量的新限制，僅取決於在未調用分塊時的基本工作記憶容量。通過分析癲癇患者的單元反應和使用言語材料的記憶實驗，證實了我們模型的預測。我們的研究提供了一個新的概念和分析框架，用於理解大腦中即時組織資訊，這對於認知至關重要。

##### **Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding**
2408.07636v1 by Bing Hu, Anita Layton, Helen Chen

Artificial intelligence (AI) is increasingly used in every stage of drug
development. One challenge facing drug discovery AI is that drug
pharmacokinetic (PK) datasets are often collected independently from each
other, often with limited overlap, creating data overlap sparsity. Data
sparsity makes data curation difficult for researchers looking to answer
research questions in poly-pharmacy, drug combination research, and
high-throughput screening. We propose Imagand, a novel
SMILES-to-Pharmacokinetic (S2PK) diffusion model capable of generating an array
of PK target properties conditioned on SMILES inputs. We show that
Imagand-generated synthetic PK data closely resembles real data univariate and
bivariate distributions, and improves performance for downstream tasks. Imagand
is a promising solution for data overlap sparsity and allows researchers to
efficiently generate ligand PK data for drug discovery research. Code is
available at \url{https://github.com/bing1100/Imagand}.

摘要：人工智慧 (AI) 在藥物開發的每個階段中使用越來越廣泛。藥物發現 AI 面臨的其中一項挑戰是藥物藥物動力學 (PK) 資料集通常獨立收集，且重疊有限，造成資料重疊稀疏。資料稀疏性讓研究人員難以整理資料，以回答多重藥物治療、藥物組合研究和高通量篩選中的研究問題。我們提出 Imagand，這是一種新穎的 SMILES 轉藥物動力學 (S2PK) 擴散模型，能夠根據 SMILES 輸入產生一系列 PK 目標屬性。我們展示 Imagand 生成的合成 PK 資料與真實資料的單變量和雙變量分布非常相似，並改善下游任務的效能。Imagand 是一個有望解決資料重疊稀疏性的解決方案，讓研究人員能夠有效率地產生配體 PK 資料，以進行藥物發現研究。程式碼可在 \url{https://github.com/bing1100/Imagand} 取得。

##### **Battery GraphNets : Relational Learning for Lithium-ion Batteries(LiBs) Life Estimation**
2408.07624v1 by Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Venkataramana Runkana

Battery life estimation is critical for optimizing battery performance and
guaranteeing minimal degradation for better efficiency and reliability of
battery-powered systems. The existing methods to predict the Remaining Useful
Life(RUL) of Lithium-ion Batteries (LiBs) neglect the relational dependencies
of the battery parameters to model the nonlinear degradation trajectories. We
present the Battery GraphNets framework that jointly learns to incorporate a
discrete dependency graph structure between battery parameters to capture the
complex interactions and the graph-learning algorithm to model the intrinsic
battery degradation for RUL prognosis. The proposed method outperforms several
popular methods by a significant margin on publicly available battery datasets
and achieves SOTA performance. We report the ablation studies to support the
efficacy of our approach.

摘要：電池壽命估計對於最佳化電池效能和確保最低劣化至關重要，以提升電池供電系統的效率和可靠性。現有的方法用於預測鋰離子電池 (LiB) 的剩餘使用壽命 (RUL)，卻忽略了電池參數的關聯性，無法建立非線性劣化軌跡模型。我們提出 Battery GraphNets 框架，可共同學習納入電池參數之間的離散依賴性圖形結構，以擷取複雜的交互作用，以及圖形學習演算法，以建立內在電池劣化模型，用於 RUL 預後。所提出的方法在公開的電池資料集上大幅優於多種常見方法，並達到 SOTA 效能。我們報告了消融研究，以支持我們方法的效能。

##### **WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**
2408.07611v1 by Weijian Xie, Xuefeng Liang, Yuhui Liu, Kaihua Ni, Hong Cheng, Zetian Hu

Large Language Models (LLMs) have greatly contributed to the development of
adaptive intelligent agents and are positioned as an important way to achieve
Artificial General Intelligence (AGI). However, LLMs are prone to produce
factually incorrect information and often produce "phantom" content that
undermines their reliability, which poses a serious challenge for their
deployment in real-world scenarios. Enhancing LLMs by combining external
databases and information retrieval mechanisms is an effective path. To address
the above challenges, we propose a new approach called WeKnow-RAG, which
integrates Web search and Knowledge Graphs into a "Retrieval-Augmented
Generation (RAG)" system. First, the accuracy and reliability of LLM responses
are improved by combining the structured representation of Knowledge Graphs
with the flexibility of dense vector retrieval. WeKnow-RAG then utilizes
domain-specific knowledge graphs to satisfy a variety of queries and domains,
thereby improving performance on factual information and complex reasoning
tasks by employing multi-stage web page retrieval techniques using both sparse
and dense retrieval methods. Our approach effectively balances the efficiency
and accuracy of information retrieval, thus improving the overall retrieval
process. Finally, we also integrate a self-assessment mechanism for the LLM to
evaluate the trustworthiness of the answers it generates. Our approach proves
its outstanding effectiveness in a wide range of offline experiments and online
submissions.

摘要：大型語言模型 (LLM) 對於自適應智慧代理的發展有很大的貢獻，並且被定位為實現人工通用智慧 (AGI) 的重要途徑。然而，LLM 容易產生事實上不正確的資訊，並且經常產生「幻影」內容，這會破壞它們的可靠性，對它們在現實世界場景中的部署構成嚴峻的挑戰。透過結合外部資料庫和資訊檢索機制來增強 LLM 是一條有效的路徑。為了應對上述挑戰，我們提出了一種稱為 WeKnow-RAG 的新方法，它將網路搜尋和知識圖譜整合到「檢索增強產生 (RAG)」系統中。首先，透過結合知識圖譜的結構化表示和密集向量檢索的靈活性，提高了 LLM 回應的準確性和可靠性。WeKnow-RAG 接著利用特定領域的知識圖譜來滿足各種查詢和領域，從而透過使用稀疏和密集檢索方法的多階段網頁檢索技術，改善事實資訊和複雜推理任務的效能。我們的做法有效地平衡了資訊檢索的效率和準確性，從而改善了整體檢索流程。最後，我們也為 LLM 整合了一個自我評估機制，以評估它所產生答案的可信度。我們的做法在廣泛的離線實驗和線上提交中證明了其傑出的有效性。

##### **Assessing the Role of Lexical Semantics in Cross-lingual Transfer through Controlled Manipulations**
2408.07599v1 by Roy Ilani, Taelin Karidi, Omri Abend

While cross-linguistic model transfer is effective in many settings, there is
still limited understanding of the conditions under which it works. In this
paper, we focus on assessing the role of lexical semantics in cross-lingual
transfer, as we compare its impact to that of other language properties.
Examining each language property individually, we systematically analyze how
differences between English and a target language influence the capacity to
align the language with an English pretrained representation space. We do so by
artificially manipulating the English sentences in ways that mimic specific
characteristics of the target language, and reporting the effect of each
manipulation on the quality of alignment with the representation space. We show
that while properties such as the script or word order only have a limited
impact on alignment quality, the degree of lexical matching between the two
languages, which we define using a measure of translation entropy, greatly
affects it.

摘要：儘管跨語言模型轉移在許多情況下有效，但對於其運作條件的了解仍然有限。在本文中，我們專注於評估詞彙語義在跨語言轉移中的作用，並將其影響與其他語言屬性的影響進行比較。單獨檢視各語言屬性，我們系統性地分析英語和目標語言之間的差異如何影響將語言與英語預訓練表示空間對齊的能力。我們透過人為地操縱英語句子，使其模擬目標語言的特定特徵，並報告每個操縱對與表示空間對齊品質的影響。我們表明，儘管腳本或字序等屬性對對齊品質的影響有限，但我們使用轉譯熵度量定義的兩種語言之間的詞彙匹配程度會對其產生很大影響。

##### **Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**
2408.07583v1 by Hamza Kheddar

With significant advancements in Transformers LLMs, NLP has extended its
reach into many research fields due to its enhanced capabilities in text
generation and user interaction. One field benefiting greatly from these
advancements is cybersecurity. In cybersecurity, many parameters that need to
be protected and exchanged between senders and receivers are in the form of
text and tabular data, making NLP a valuable tool in enhancing the security
measures of communication protocols. This survey paper provides a comprehensive
analysis of the utilization of Transformers and LLMs in cyber-threat detection
systems. The methodology of paper selection and bibliometric analysis is
outlined to establish a rigorous framework for evaluating existing research.
The fundamentals of Transformers are discussed, including background
information on various cyber-attacks and datasets commonly used in this field.
The survey explores the application of Transformers in IDSs, focusing on
different architectures such as Attention-based models, LLMs like BERT and GPT,
CNN/LSTM-Transformer hybrids, emerging approaches like ViTs, among others.
Furthermore, it explores the diverse environments and applications where
Transformers and LLMs-based IDS have been implemented, including computer
networks, IoT devices, critical infrastructure protection, cloud computing,
SDN, as well as in autonomous vehicles. The paper also addresses research
challenges and future directions in this area, identifying key issues such as
interpretability, scalability, and adaptability to evolving threats, and more.
Finally, the conclusion summarizes the findings and highlights the significance
of Transformers and LLMs in enhancing cyber-threat detection capabilities,
while also outlining potential avenues for further research and development.

摘要：<paragraph>隨著 Transformers LLM 的顯著進步，NLP 憑藉其在文本生成和使用者互動方面的增強功能，已將其影響力擴展到許多研究領域。受益於這些進展的一個領域是網路安全。在網路安全中，許多需要在發送者和接收者之間保護和交換的參數都是以文字和表格數據的形式存在的，這使得 NLP 成為增強通信協定安全措施的寶貴工具。這篇調查報告全面分析了 Transformer 和 LLM 在網路威脅偵測系統中的應用。概述了論文選擇和書目分析的方法，以建立一個嚴謹的框架來評估現有的研究。討論了 Transformer 的基礎知識，包括關於各種網路攻擊和此領域常用的資料集的背景資訊。這項調查探討了 Transformer 在 IDS 中的應用，重點關注基於注意力的模型、如 BERT 和 GPT 等 LLM、CNN/LSTM-Transformer 混合模型、ViT 等新興方法。此外，它還探討了 Transformer 和基於 LLM 的 IDS 已被實作的不同環境和應用，包括電腦網路、IoT 裝置、關鍵基礎設施保護、雲端運算、SDN，以及自駕車。這篇論文也探討了這個領域的研究挑戰和未來方向，找出關鍵問題，例如可解釋性、可擴充性、對不斷變化的威脅的適應性，等等。最後，結論總結了研究結果，並強調了 Transformer 和 LLM 在增強網路威脅偵測能力方面的意義，同時也概述了進一步研究和開發的潛在途徑。</paragraph>

##### **Graph neural network surrogate for strategic transport planning**
2408.07726v1 by Nikita Makarov, Santhanakrishnan Narayanan, Constantinos Antoniou

As the complexities of urban environments continue to grow, the modelling of
transportation systems become increasingly challenging. This paper explores the
application of advanced Graph Neural Network (GNN) architectures as surrogate
models for strategic transport planning. Building upon a prior work that laid
the foundation with graph convolution networks (GCN), our study delves into the
comparative analysis of established GCN with the more expressive Graph
Attention Network (GAT). Additionally, we propose a novel GAT variant (namely
GATv3) to address over-smoothing issues in graph-based models. Our
investigation also includes the exploration of a hybrid model combining both
GCN and GAT architectures, aiming to investigate the performance of the
mixture. The three models are applied to various experiments to understand
their limits. We analyse hierarchical regression setups, combining
classification and regression tasks, and introduce fine-grained classification
with a proposal of a method to convert outputs to precise values. Results
reveal the superior performance of the new GAT in classification tasks. To the
best of the authors' knowledge, this is the first GAT model in literature to
achieve larger depths. Surprisingly, the fine-grained classification task
demonstrates the GCN's unexpected dominance with additional training data. This
shows that synthetic data generators can increase the training data, without
overfitting issues whilst improving model performance. In conclusion, this
research advances GNN based surrogate modelling, providing insights for
refining GNN architectures. The findings open avenues for investigating the
potential of the newly proposed GAT architecture and the modelling setups for
other transportation problems.

摘要：<paragraph>隨著都市環境的複雜性持續增加，運輸系統的建模變得越來越具有挑戰性。本文探討了進階圖神經網路 (GNN) 架構在策略性運輸規劃中作為代理模型的應用。建立在先前奠定圖形卷積網路 (GCN) 基礎的研究上，我們的研究深入探討了既有 GCN 與更具表現力的圖形注意力網路 (GAT) 的比較分析。此外，我們提出了一個新穎的 GAT 變體 (即 GATv3) 來解決圖形化模型中的過平滑問題。我們的研究還包括探索結合 GCN 和 GAT 架構的混合模型，旨在研究混合模型的效能。這三個模型被應用於各種實驗，以了解其限制。我們分析階層式回歸設定，結合分類和回歸任務，並透過提出將輸出轉換為精確值的方法來引入細粒度分類。結果顯示新的 GAT 在分類任務中具有優異的效能。據作者所知，這是文獻中第一個達到更大深度的 GAT 模型。令人驚訝的是，細粒度分類任務顯示出 GCN 在有額外訓練資料的情況下具有出乎意料的優勢。這表示合成資料產生器可以在沒有過擬合問題的情況下增加訓練資料，同時改善模型效能。結論而言，這項研究推動了基於 GNN 的代理建模，並為改進 GNN 架構提供了見解。這些發現為研究新提出的 GAT 架構的潛力以及其他運輸問題的建模設定打開了道路。</paragraph>

##### **Multi-task Heterogeneous Graph Learning on Electronic Health Records**
2408.07569v1 by Tsai Hor Chan, Guosheng Yin, Kyongtae Bae, Lequan Yu

Learning electronic health records (EHRs) has received emerging attention
because of its capability to facilitate accurate medical diagnosis. Since the
EHRs contain enriched information specifying complex interactions between
entities, modeling EHRs with graphs is shown to be effective in practice. The
EHRs, however, present a great degree of heterogeneity, sparsity, and
complexity, which hamper the performance of most of the models applied to them.
Moreover, existing approaches modeling EHRs often focus on learning the
representations for a single task, overlooking the multi-task nature of EHR
analysis problems and resulting in limited generalizability across different
tasks. In view of these limitations, we propose a novel framework for EHR
modeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous
graph to mine the complex relations and model the heterogeneity in the EHRs. To
mitigate the large degree of noise, we introduce a denoising module based on
the causal inference framework to adjust for severe confounding effects and
reduce noise in the EHR data. Additionally, since our model adopts a single
graph neural network for simultaneous multi-task prediction, we design a
multi-task learning module to leverage the inter-task knowledge to regularize
the training process. Extensive empirical studies on MIMIC-III and MIMIC-IV
datasets validate that the proposed method consistently outperforms the
state-of-the-art designs in four popular EHR analysis tasks -- drug
recommendation, and predictions of the length of stay, mortality, and
readmission. Thorough ablation studies demonstrate the robustness of our method
upon variations to key components and hyperparameters.

摘要：<paragraph>學習電子健康紀錄（EHR）由於其促進準確醫療診斷的能力而備受關注。由於 EHR 包含豐富資訊，指定實體之間的複雜互動，因此使用圖形建模 EHR 已被證明在實務上很有效。然而，EHR 呈現出高度的異質性、稀疏性和複雜性，這會阻礙應用於它們的大多數模型的效能。此外，現有的建模 EHR 方法通常專注於學習單一任務的表示，忽略 EHR 分析問題的多任務性質，並導致跨不同任務的概括能力有限。有鑑於這些限制，我們提出了 EHR 建模的新架構，即 MulT-EHR（多任務 EHR），它利用異質圖來挖掘複雜關係並建模 EHR 中的異質性。為了減輕大量的雜訊，我們引入了基於因果推論架構的去雜訊模組，以調整嚴重的混淆效應並減少 EHR 資料中的雜訊。此外，由於我們的模型採用單一圖形神經網路進行同時的多任務預測，因此我們設計了一個多任務學習模組，以利用任務間的知識來規範訓練過程。在 MIMIC-III 和 MIMIC-IV 資料集上的廣泛實證研究驗證了所提出的方法在四項流行的 EHR 分析任務中始終優於最先進的設計——藥物推薦以及預測住院時間、死亡率和再入院率。徹底的消融研究證明了我們的方法在關鍵組成部分和超參數變化上的穩健性。</paragraph>

##### **PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation**
2408.07547v1 by Sang-Hoon Lee, Ha-Yeong Choi, Seong-Whan Lee

Recently, universal waveform generation tasks have been investigated
conditioned on various out-of-distribution scenarios. Although GAN-based
methods have shown their strength in fast waveform generation, they are
vulnerable to train-inference mismatch scenarios such as two-stage
text-to-speech. Meanwhile, diffusion-based models have shown their powerful
generative performance in other domains; however, they stay out of the
limelight due to slow inference speed in waveform generation tasks. Above all,
there is no generator architecture that can explicitly disentangle the natural
periodic features of high-resolution waveform signals. In this paper, we
propose PeriodWave, a novel universal waveform generation model. First, we
introduce a period-aware flow matching estimator that can capture the periodic
features of the waveform signal when estimating the vector fields.
Additionally, we utilize a multi-period estimator that avoids overlaps to
capture different periodic features of waveform signals. Although increasing
the number of periods can improve the performance significantly, this requires
more computational costs. To reduce this issue, we also propose a single
period-conditional universal estimator that can feed-forward parallel by
period-wise batch inference. Additionally, we utilize discrete wavelet
transform to losslessly disentangle the frequency information of waveform
signals for high-frequency modeling, and introduce FreeU to reduce the
high-frequency noise for waveform generation. The experimental results
demonstrated that our model outperforms the previous models both in
Mel-spectrogram reconstruction and text-to-speech tasks. All source code will
be available at \url{https://github.com/sh-lee-prml/PeriodWave}.

摘要：<paragraph>最近，针对各种分布外情境，对通用波形生成任务进行了调查。尽管基于 GAN 的方法在快速波形生成方面显示出其优势，但它们容易受到训练推理不匹配的情况的影响，例如两阶段文本到语音。与此同时，基于扩散的模型在其他领域展示了其强大的生成性能；然而，由于在波形生成任务中的推理速度较慢，它们并未受到关注。最重要的是，没有生成器架构可以明确地区分高分辨率波形信号的自然周期性特征。在本文中，我们提出了 PeriodWave，一种新颖的通用波形生成模型。首先，我们引入了一个周期感知流匹配估计器，它可以在估计矢量场时捕获波形信号的周期性特征。此外，我们利用了一个多周期估计器，避免重叠以捕获波形信号的不同周期性特征。尽管增加周期数可以显着提高性能，但这需要更多的计算成本。为了减少这个问题，我们还提出了一个单周期条件通用估计器，它可以通过周期性批处理推理进行前馈并行。此外，我们利用离散小波变换无损地解开波形信号的频率信息以进行高频建模，并引入 FreeU 以减少波形生成的噪声。实验结果表明，我们的模型在 Mel 谱图重建和文本到语音任务中都优于之前的模型。所有源代码都可以在 \url{https://github.com/sh-lee-prml/PeriodWave} 获得。</paragraph>

##### **Planning with OWL-DL Ontologies (Extended Version)**
2408.07544v1 by Tobias John, Patrick Koopmann

We introduce ontology-mediated planning, in which planning problems are
combined with an ontology. Our formalism differs from existing ones in that we
focus on a strong separation of the formalisms for describing planning problems
and ontologies, which are only losely coupled by an interface. Moreover, we
present a black-box algorithm that supports the full expressive power of OWL
DL. This goes beyond what existing approaches combining automated planning with
ontologies can do, which only support limited description logics such as
DL-Lite and description logics that are Horn. Our main algorithm relies on
rewritings of the ontology-mediated planning specifications into PDDL, so that
existing planning systems can be used to solve them. The algorithm relies on
justifications, which allows for a generic approach that is independent of the
expressivity of the ontology language. However, dedicated optimizations for
computing justifications need to be implemented to enable an efficient
rewriting procedure. We evaluated our implementation on benchmark sets from
several domains. The evaluation shows that our procedure works in practice and
that tailoring the reasoning procedure has significant impact on the
performance.

摘要：<paragraph>我們引入了基於本體的規劃，其中規劃問題與本體相結合。我們的形式主義不同於現有的形式主義，因為我們專注於描述規劃問題和本體的形式主義的強分離，它們僅通過介面鬆散耦合。此外，我們提出了一個黑盒演算法，它支援 OWL DL 的完整表達能力。這超出了將自動規劃與本體相結合的現有方法所能做到的，它僅支援有限的描述邏輯，例如 DL-Lite 和 Horn 描述邏輯。我們的演算法主要依賴於將基於本體的規劃規範重寫為 PDDL，以便現有的規劃系統可以用於解決它們。該演算法依賴於證明，這允許一種通用的方法，該方法獨立於本體語言的表達能力。但是，需要實作專門的最佳化來計算證明，以實現有效的重寫程序。我們在來自多個領域的基準集上評估了我們的實作。評估表明，我們的程序在實務上可行，而且調整推理程序對效能有顯著影響。</paragraph>

##### **MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**
2408.07543v2 by Minxuan Zhou, Hao Liang, Tianpeng Li, Zhiyu Wu, Mingan Lin, Linzhuang Sun, Yaqi Zhou, Yan Zhang, Xiaoqin Huang, Yicong Chen, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou

With the development of Multimodal Large Language Models (MLLMs), the
evaluation of multimodal models in the context of mathematical problems has
become a valuable research field. Multimodal visual-textual mathematical
reasoning serves as a critical indicator for evaluating the comprehension and
complex multi-step quantitative reasoning abilities of MLLMs. However, previous
multimodal math benchmarks have not sufficiently integrated visual and textual
information. To address this gap, we proposed MathScape, a new benchmark that
emphasizes the understanding and application of combined visual and textual
information. MathScape is designed to evaluate photo-based math problem
scenarios, assessing the theoretical understanding and application ability of
MLLMs through a categorical hierarchical approach. We conduct a
multi-dimensional evaluation on 11 advanced MLLMs, revealing that our benchmark
is challenging even for the most sophisticated models. By analyzing the
evaluation results, we identify the limitations of MLLMs, offering valuable
insights for enhancing model performance.

摘要：隨著多模態大型語言模型 (MLLM) 的發展，在數學問題背景下對多模態模型的評估已成為一個有價值的研究領域。多模態視覺文本數學推理作為評估 MLLM 的理解力和複雜的多步驟量化推理能力的重要指標。然而，先前的多模態數學基準並未充分整合視覺和文本資訊。為了解決這個差距，我們提出了 MathScape，一個新的基準，強調理解和應用視覺和文本資訊的結合。MathScape 被設計用來評估基於照片的數學問題場景，透過一個分類的階層式方法評估 MLLM 的理論理解和應用能力。我們對 11 個先進的 MLLM 進行多維評估，揭示我們的基準即使對於最精密的模型來說也是具有挑戰性的。透過分析評估結果，我們找出 MLLM 的限制，為提升模型效能提供有價值的見解。

##### **New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**
2408.07542v1 by Simon Kloker, Herbertson Bukoli, Twaha Kateete

Introduction: Poor educational quality in Secondary Schools is still regarded
as one of the major struggles in 21st century Uganda - especially in rural
areas. Research identifies several problems, including low quality or absent
teacher lesson planning. As the government pushes towards the implementation of
a new curriculum, exiting lesson plans become obsolete and the problem is
worsened. Using a Retrieval Augmented Generation approach, we developed a
prototype that generates customized lesson plans based on the
government-accredited textbooks. This helps teachers create lesson plans more
efficiently and with better quality, ensuring they are fully aligned the new
curriculum and the competence-based learning approach.
  Methods: The prototype was created using Cohere LLM and Sentence Embeddings,
and LangChain Framework - and thereafter made available on a public website.
Vector stores were trained for three new curriculum textbooks (ICT,
Mathematics, History), all at Secondary 1 Level. Twenty-four lessons plans were
generated following a pseudo-random generation protocol, based on the suggested
periods in the textbooks. The lesson plans were analyzed regarding their
technical quality by three independent raters following the Lesson Plan
Analysis Protocol (LPAP) by Ndihokubwayo et al. (2022) that is specifically
designed for East Africa and competence-based curriculums.
  Results: Evaluation of 24 lesson plans using the LPAP resulted in an average
quality of between 75 and 80%, corresponding to "very good lesson plan". None
of the lesson plans scored below 65%, although one lesson plan could be argued
to have been missing the topic. In conclusion, the quality of the generated
lesson plans is at least comparable, if not better, than those created by
humans, as demonstrated in a study in Rwanda, whereby no lesson plan even
reached the benchmark of 50%.

摘要：<paragraph>引言：烏干達 21 世紀的二級學校教育品質不佳，至今仍被視為主要難題之一，尤其是在農村地區。研究指出有許多問題，包含品質不佳或缺乏教學計畫。隨著政府推動實施新課程，現有的教學計畫已過時，問題也隨之惡化。我們使用檢索擴充產生方式，開發了一個原型，可根據政府認可的教科書產生客製化教學計畫。這能協助教師更有效率且品質更好的建立教學計畫，確保與新課程和能力基礎學習方式完全一致。
方法：這個原型使用 Cohere LLM 和句子嵌入，以及 LangChain 架構所建立，之後再公開於網站上。針對三本新的課程教科書（資訊與通訊技術、數學、歷史），全部在中學一年級的程度，訓練了向量儲存。根據教科書中建議的時段，遵循偽隨機產生協定產生了 24 個教學計畫。三個獨立評分員根據 Ndihokubwayo 等人（2022 年）的教學計畫分析協定（LPAP）分析教學計畫的技術品質，該協定特別設計用於東非和能力基礎課程。
結果：使用 LPAP 評估 24 個教學計畫，平均品質介於 75% 到 80%，相當於「非常好的教學計畫」。沒有教學計畫的分數低於 65%，儘管有人認為有一個教學計畫遺漏了主題。結論是，產生的教學計畫品質至少與人類建立的相當，甚至更好，正如盧安達的一項研究所示，沒有任何教學計畫達到 50% 的基準。</paragraph>

##### **DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model**
2408.07541v1 by Erez Yosef, Raja Giryes

The flat lensless camera design reduces the camera size and weight
significantly. In this design, the camera lens is replaced by another optical
element that interferes with the incoming light. The image is recovered from
the raw sensor measurements using a reconstruction algorithm. Yet, the quality
of the reconstructed images is not satisfactory. To mitigate this, we propose
utilizing a pre-trained diffusion model with a control network and a learned
separable transformation for reconstruction. This allows us to build a
prototype flat camera with high-quality imaging, presenting state-of-the-art
results in both terms of quality and perceptuality. We demonstrate its ability
to leverage also textual descriptions of the captured scene to further enhance
reconstruction. Our reconstruction method which leverages the strong
capabilities of a pre-trained diffusion model can be used in other imaging
systems for improved reconstruction results.

摘要：扁平無鏡頭相機設計可大幅降低相機尺寸和重量。在此設計中，相機鏡頭由另一個會干擾入射光的元件所取代。影像透過使用重建演算法從原始感測器測量值中還原。然而，重建影像的品質並不令人滿意。為了改善這個問題，我們建議利用預先訓練的擴散模型，搭配控制網路和學習的分離轉換進行重建。這讓我們得以建構具備高品質影像的扁平相機原型，在品質和知覺上均呈現最先進的成果。我們展示其利用場景的文字描述進一步增強重建的能力。我們的重建方法利用預先訓練的擴散模型的強大功能，可應用於其他影像系統以改善重建成果。

##### **Cross-aware Early Fusion with Stage-divided Vision and Language Transformer Encoders for Referring Image Segmentation**
2408.07539v1 by Yubin Cho, Hyunwoo Yu, Suk-ju Kang

Referring segmentation aims to segment a target object related to a natural
language expression. Key challenges of this task are understanding the meaning
of complex and ambiguous language expressions and determining the relevant
regions in the image with multiple objects by referring to the expression.
Recent models have focused on the early fusion with the language features at
the intermediate stage of the vision encoder, but these approaches have a
limitation that the language features cannot refer to the visual information.
To address this issue, this paper proposes a novel architecture, Cross-aware
early fusion with stage-divided Vision and Language Transformer encoders
(CrossVLT), which allows both language and vision encoders to perform the early
fusion for improving the ability of the cross-modal context modeling. Unlike
previous methods, our method enables the vision and language features to refer
to each other's information at each stage to mutually enhance the robustness of
both encoders. Furthermore, unlike the conventional scheme that relies solely
on the high-level features for the cross-modal alignment, we introduce a
feature-based alignment scheme that enables the low-level to high-level
features of the vision and language encoders to engage in the cross-modal
alignment. By aligning the intermediate cross-modal features in all encoder
stages, this scheme leads to effective cross-modal fusion. In this way, the
proposed approach is simple but effective for referring image segmentation, and
it outperforms the previous state-of-the-art methods on three public
benchmarks.

摘要：參考分割旨在區隔與自然語言表達相關的目標物件。此任務的主要挑戰在於理解複雜且模稜兩可的語言表達，並根據表達來決定影像中有多個物件時相關區域。最近的模型專注於在視覺編碼器的中間階段與語言特徵進行早期融合，但這些方法有一個限制，即語言特徵無法參考視覺資訊。為了解決這個問題，本文提出了一種新穎的架構，即在階段劃分的視覺和語言轉換器編碼器（CrossVLT）中進行跨感知的早期融合，這允許語言和視覺編碼器執行早期融合以提升跨模態情境建模的能力。與先前的做法不同，我們的做法使視覺和語言特徵能夠在每個階段參考彼此的資訊，以相互提升兩個編碼器的穩健性。此外，與僅依賴高層級特徵進行跨模態對齊的傳統方案不同，我們引入了一個基於特徵的對齊方案，使視覺和語言編碼器的低層級到高層級特徵能夠參與跨模態對齊。透過在所有編碼器階段對齊中間跨模態特徵，此方案可帶來有效的跨模態融合。透過這種方式，所提出的方法對於參考影像分割來說既簡單又有效，而且在三個公開基準上優於先前的最先進方法。

##### **Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**
2408.07531v1 by Seungjun Han, Wongyung Choi

Emergency department (ED) overcrowding and the complexity of rapid
decision-making in critical care settings pose significant challenges to
healthcare systems worldwide. While clinical decision support systems (CDSS)
have shown promise, the integration of large language models (LLMs) offers new
possibilities for enhancing triage accuracy and clinical decision-making. This
study presents an LLM-driven CDSS designed to assist ED physicians and nurses
in patient triage, treatment planning, and overall emergency care management.
  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,
orchestrated by CrewAI and Langchain. The system comprises four AI agents
emulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED
Coordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for
triage assessment and integrates with the RxNorm API for medication management.
  The model was evaluated using the Asclepius dataset, with performance
assessed by a clinical emergency medicine specialist. The CDSS demonstrated
high accuracy in triage decision-making compared to the baseline of a
single-agent system. Furthermore, the system exhibited strong performance in
critical areas, including primary diagnosis, critical findings identification,
disposition decision-making, treatment planning, and resource allocation.
  Our multi-agent CDSS demonstrates significant potential for supporting
comprehensive emergency care management. By leveraging state-of-the-art AI
technologies, this system offers a scalable and adaptable tool that could
enhance emergency medical care delivery, potentially alleviating ED
overcrowding and improving patient outcomes. This work contributes to the
growing field of AI applications in emergency medicine and offers a promising
direction for future research and clinical implementation.

摘要：<paragraph>急診室（ED）人滿為患，以及在重症照護環境中快速做決定的複雜性對全球的醫療保健系統構成重大挑戰。雖然臨床決策支援系統（CDSS）已展現前景，但大型語言模型（LLM）的整合為提升分流準確度和臨床決策提供了新的可能性。本研究提出一個由 LLM 驅動的 CDSS，旨在協助急診室醫師和護理師進行病人分流、治療計畫和整體緊急照護管理。
  我們開發了一個多重代理 CDSS，利用 Llama-3-70b 作為基礎 LLM，由 CrewAI 和 Langchain 編排。此系統包含四個模擬關鍵急診室角色的 AI 代理：分流護理師、急診醫師、藥師和急診室協調員。它整合韓國分流與嚴重指數量表（KTAS）進行分流評估，並與 RxNorm API 整合進行藥物管理。
  該模型使用 Asclepius 資料集進行評估，由臨床急診醫學專家評估其效能。與單一代理系統的基準相比，CDSS 在分流決策方面展現高準確度。此外，該系統在主要診斷、關鍵發現識別、處置決策、治療計畫和資源分配等關鍵領域表現出色。
  我們的多重代理 CDSS 證明了在支援全面的緊急照護管理方面具有顯著的潛力。透過利用最先進的 AI 技術，此系統提供了一個可擴充且可適應的工具，可以提升緊急醫療照護的提供，進而可能緩解急診室人滿為患的情況並改善病患的預後。這項工作促進了 AI 在急診醫學中的應用領域，並為未來的研究和臨床實作提供了有前景的方向。</paragraph>

##### **Evidential Graph Contrastive Alignment for Source-Free Blending-Target Domain Adaptation**
2408.07527v1 by Juepeng Zheng, Yibin Wen, Jinxiao Zhang, Runmin Dong, Haohuan Fu

In this paper, we firstly tackle a more realistic Domain Adaptation (DA)
setting: Source-Free Blending-Target Domain Adaptation (SF-BTDA), where we can
not access to source domain data while facing mixed multiple target domains
without any domain labels in prior. Compared to existing DA scenarios, SF-BTDA
generally faces the co-existence of different label shifts in different
targets, along with noisy target pseudo labels generated from the source model.
In this paper, we propose a new method called Evidential Contrastive Alignment
(ECA) to decouple the blending target domain and alleviate the effect from
noisy target pseudo labels. First, to improve the quality of pseudo target
labels, we propose a calibrated evidential learning module to iteratively
improve both the accuracy and certainty of the resulting model and adaptively
generate high-quality pseudo target labels. Second, we design a graph
contrastive learning with the domain distance matrix and confidence-uncertainty
criterion, to minimize the distribution gap of samples of a same class in the
blended target domains, which alleviates the co-existence of different label
shifts in blended targets. We conduct a new benchmark based on three standard
DA datasets and ECA outperforms other methods with considerable gains and
achieves comparable results compared with those that have domain labels or
source data in prior.

摘要：在本文中，我们首先解决一个更贴近现实的领域自适应 (DA) 设置：无源混合目标领域自适应 (SF-BTDA)，其中我们无法访问源领域数据，同时面临混合多个目标领域，且事先没有任何领域标签。与现有的 DA 场景相比，SF-BTDA 通常面临不同目标中标签偏移并存的问题，以及从源模型生成的噪声目标伪标签。在本文中，我们提出了一种称为证据对比对齐 (ECA) 的新方法，以解耦混合目标域并减轻噪声目标伪标签的影响。首先，为了提高伪目标标签的质量，我们提出了一种校准的证据学习模块，以迭代方式提高所得模型的准确性和确定性，并自适应地生成高质量的伪目标标签。其次，我们设计了一个具有域距离矩阵和置信度不确定性准则的图对比学习，以最小化混合目标域中同一类样本的分布差距，从而减轻混合目标中不同标签偏移的并存。我们基于三个标准 DA 数据集进行了新的基准测试，ECA 以相当大的增益优于其他方法，并且与事先具有领域标签或源数据的方法相比取得了相当的结果。

##### **Fast Inference for Probabilistic Answer Set Programs via the Residual Program**
2408.07524v1 by Damiano Azzolini, Fabrizio Riguzzi

When we want to compute the probability of a query from a Probabilistic
Answer Set Program, some parts of a program may not influence the probability
of a query, but they impact on the size of the grounding. Identifying and
removing them is crucial to speed up the computation. Algorithms for SLG
resolution offer the possibility of returning the residual program which can be
used for computing answer sets for normal programs that do have a total
well-founded model. The residual program does not contain the parts of the
program that do not influence the probability. In this paper, we propose to
exploit the residual program for performing inference. Empirical results on
graph datasets show that the approach leads to significantly faster inference.

摘要：当我们想要从概率性答案集程序计算查询的概率时，程序的某些部分可能不会影响查询的概率，但它们会影响基础的大小。识别并移除它们对于加快计算至关重要。SLG 分辨率算法提供了返回剩余程序的可能性，该程序可用于计算具有完全良好基础模型的普通程序的答案集。剩余程序不包含不影响概率的程序部分。在本文中，我们建议利用剩余程序来执行推理。在图数据集上的经验结果表明，该方法可以显著加快推理。

