{"2410.11701": {"publish_time": "2024-10-15", "title": "Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions", "paper_summary": "Hallucinations in multimodal large language models (MLLMs) hinder their\npractical applications. To address this, we propose a Magnifier Prompt\n(MagPrompt), a simple yet effective method to tackle hallucinations in MLLMs\nvia extremely simple instructions. MagPrompt is based on the following two key\nprinciples, which guide the design of various effective prompts, demonstrating\nrobustness: (1) MLLMs should focus more on the image. (2) When there are\nconflicts between the image and the model's inner knowledge, MLLMs should\nprioritize the image. MagPrompt is training-free and can be applied to\nopen-source and closed-source models, such as GPT-4o and Gemini-pro. It\nperforms well across many datasets and its effectiveness is comparable or even\nbetter than more complex methods like VCD. Furthermore, our prompt design\nprinciples and experimental analyses provide valuable insights into multimodal\nhallucination.", "paper_summary_zh": "\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u4e2d\u7684\u5e7b\u89c9\u963b\u788d\u4e86\u5b83\u4eec\u7684\u5b9e\u9645\u5e94\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u653e\u5927\u63d0\u793a\uff08MagPrompt\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u7b80\u5355\u4f46\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u901a\u8fc7\u6781\u5176\u7b80\u5355\u7684\u6307\u4ee4\u6765\u89e3\u51b3 MLLM \u4e2d\u7684\u5e7b\u89c9\u3002MagPrompt \u57fa\u4e8e\u4ee5\u4e0b\u4e24\u4e2a\u5173\u952e\u539f\u5219\uff0c\u8fd9\u4e9b\u539f\u5219\u6307\u5bfc\u5404\u79cd\u6709\u6548\u63d0\u793a\u7684\u8bbe\u8ba1\uff0c\u5c55\u793a\u4e86\u9c81\u68d2\u6027\uff1a\uff081\uff09MLLM \u5e94\u8be5\u66f4\u591a\u5730\u5173\u6ce8\u56fe\u50cf\u3002\uff082\uff09\u5f53\u56fe\u50cf\u4e0e\u6a21\u578b\u7684\u5185\u90e8\u77e5\u8bc6\u4e4b\u95f4\u5b58\u5728\u51b2\u7a81\u65f6\uff0cMLLM \u5e94\u4f18\u5148\u8003\u8651\u56fe\u50cf\u3002MagPrompt \u662f\u514d\u8bad\u7ec3\u7684\uff0c\u53ef\u4ee5\u5e94\u7528\u4e8e\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\uff0c\u4f8b\u5982 GPT-4o \u548c Gemini-pro\u3002\u5b83\u5728\u8bb8\u591a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u826f\u597d\uff0c\u5176\u6709\u6548\u6027\u4e0e VCD \u7b49\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u63d0\u793a\u8bbe\u8ba1\u539f\u5219\u548c\u5b9e\u9a8c\u5206\u6790\u4e3a\u591a\u6a21\u6001\u5e7b\u89c9\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u89c1\u89e3\u3002", "author": "Yuhan Fu et.al.", "authors": "Yuhan Fu, Ruobing Xie, Jiazhen Liu, Bangxiang Lan, Xingwu Sun, Zhanhui Kang, Xirong Li", "id": "2410.11701v1", "paper_url": "http://arxiv.org/abs/2410.11701v1", "repo": "null"}}