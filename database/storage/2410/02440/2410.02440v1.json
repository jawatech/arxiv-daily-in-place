{"2410.02440": {"publish_time": "2024-10-03", "title": "Optimizing Adaptive Attacks against Content Watermarks for Language Models", "paper_summary": "Large Language Models (LLMs) can be \\emph{misused} to spread online spam and\nmisinformation. Content watermarking deters misuse by hiding a message in\nmodel-generated outputs, enabling their detection using a secret watermarking\nkey. Robustness is a core security property, stating that evading detection\nrequires (significant) degradation of the content's quality. Many LLM\nwatermarking methods have been proposed, but robustness is tested only against\n\\emph{non-adaptive} attackers who lack knowledge of the watermarking method and\ncan find only suboptimal attacks. We formulate the robustness of LLM\nwatermarking as an objective function and propose preference-based optimization\nto tune \\emph{adaptive} attacks against the specific watermarking method. Our\nevaluation shows that (i) adaptive attacks substantially outperform\nnon-adaptive baselines. (ii) Even in a non-adaptive setting, adaptive attacks\noptimized against a few known watermarks remain highly effective when tested\nagainst other unseen watermarks, and (iii) optimization-based attacks are\npractical and require less than seven GPU hours. Our findings underscore the\nneed to test robustness against adaptive attackers.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u53ef\u80fd\u88ab\u60e1\u610f\u5229\u7528\u4f86\u6563\u64ad\u7dda\u4e0a\u5783\u573e\u90f5\u4ef6\u548c\u932f\u8aa4\u8a0a\u606f\u3002\u5167\u5bb9\u6d6e\u6c34\u5370\u900f\u904e\u5728\u6a21\u578b\u7522\u751f\u7684\u8f38\u51fa\u4e2d\u96b1\u85cf\u8a0a\u606f\u4f86\u963b\u6b62\u60e1\u610f\u4f7f\u7528\uff0c\u4e26\u4f7f\u7528\u79d8\u5bc6\u6d6e\u6c34\u5370\u91d1\u9470\u4f86\u5075\u6e2c\u5b83\u5011\u3002\u7a69\u5065\u6027\u662f\u6838\u5fc3\u5b89\u5168\u5c6c\u6027\uff0c\u8868\u793a\u898f\u907f\u5075\u6e2c\u9700\u8981\uff08\u5927\u5e45\uff09\u964d\u4f4e\u5167\u5bb9\u54c1\u8cea\u3002\u5df2\u7d93\u63d0\u51fa\u8a31\u591a LLM \u6d6e\u6c34\u5370\u65b9\u6cd5\uff0c\u4f46\u7a69\u5065\u6027\u50c5\u91dd\u5c0d\u7f3a\u4e4f\u6d6e\u6c34\u5370\u65b9\u6cd5\u77e5\u8b58\u4e14\u53ea\u80fd\u627e\u5230\u6b21\u4f73\u653b\u64ca\u7684\u975e\u9069\u61c9\u6027\u653b\u64ca\u8005\u9032\u884c\u6e2c\u8a66\u3002\u6211\u5011\u5c07 LLM \u6d6e\u6c34\u5370\u7684\u7a69\u5065\u6027\u5236\u5b9a\u70ba\u76ee\u6a19\u51fd\u6578\uff0c\u4e26\u63d0\u51fa\u57fa\u65bc\u504f\u597d\u7684\u6700\u4f73\u5316\u4f86\u8abf\u6574\u91dd\u5c0d\u7279\u5b9a\u6d6e\u6c34\u5370\u65b9\u6cd5\u7684\u9069\u61c9\u6027\u653b\u64ca\u3002\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff1a(i) \u9069\u61c9\u6027\u653b\u64ca\u5927\u5e45\u512a\u65bc\u975e\u9069\u61c9\u6027\u57fa\u6e96\u3002(ii) \u5373\u4f7f\u5728\u975e\u9069\u61c9\u6027\u8a2d\u5b9a\u4e2d\uff0c\u91dd\u5c0d\u5df2\u77e5\u6d6e\u6c34\u5370\u9032\u884c\u6700\u4f73\u5316\u7684\u9069\u61c9\u6027\u653b\u64ca\u5728\u91dd\u5c0d\u5176\u4ed6\u672a\u898b\u6d6e\u6c34\u5370\u6642\u4ecd\u7136\u975e\u5e38\u6709\u6548\uff0c\u800c\u4e14 (iii) \u57fa\u65bc\u6700\u4f73\u5316\u7684\u653b\u64ca\u5177\u6709\u5be6\u7528\u6027\uff0c\u4e14\u6240\u9700 GPU \u5c0f\u6642\u6578\u4e0d\u5230 7 \u5c0f\u6642\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u5f37\u8abf\u9700\u8981\u91dd\u5c0d\u9069\u61c9\u6027\u653b\u64ca\u8005\u6e2c\u8a66\u7a69\u5065\u6027\u3002", "author": "Abdulrahman Diaa et.al.", "authors": "Abdulrahman Diaa, Toluwani Aremu, Nils Lukas", "id": "2410.02440v1", "paper_url": "http://arxiv.org/abs/2410.02440v1", "repo": "null"}}