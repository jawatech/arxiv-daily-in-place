{"2501.09798": {"publish_time": "2025-01-16", "title": "Computing Optimization-Based Prompt Injections Against Closed-Weights Models By Misusing a Fine-Tuning API", "paper_summary": "We surface a new threat to closed-weight Large Language Models (LLMs) that\nenables an attacker to compute optimization-based prompt injections.\nSpecifically, we characterize how an attacker can leverage the loss-like\ninformation returned from the remote fine-tuning interface to guide the search\nfor adversarial prompts. The fine-tuning interface is hosted by an LLM vendor\nand allows developers to fine-tune LLMs for their tasks, thus providing\nutility, but also exposes enough information for an attacker to compute\nadversarial prompts. Through an experimental analysis, we characterize the\nloss-like values returned by the Gemini fine-tuning API and demonstrate that\nthey provide a useful signal for discrete optimization of adversarial prompts\nusing a greedy search algorithm. Using the PurpleLlama prompt injection\nbenchmark, we demonstrate attack success rates between 65% and 82% on Google's\nGemini family of LLMs. These attacks exploit the classic utility-security\ntradeoff - the fine-tuning interface provides a useful feature for developers\nbut also exposes the LLMs to powerful attacks.", "paper_summary_zh": "\u6211\u5011\u767c\u73fe\u4e86\u4e00\u500b\u5c0d\u5c01\u9589\u6b0a\u91cd\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u65b0\u5a01\u8105\uff0c\u5b83\u4f7f\u653b\u64ca\u8005\u80fd\u5920\u8a08\u7b97\u57fa\u65bc\u6700\u4f73\u5316\u7684\u63d0\u793a\u6ce8\u5165\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63cf\u8ff0\u4e86\u653b\u64ca\u8005\u5982\u4f55\u5229\u7528\u5f9e\u9060\u7a0b\u5fae\u8abf\u4ecb\u9762\u50b3\u56de\u7684\u985e\u4f3c\u640d\u5931\u7684\u8cc7\u8a0a\u4f86\u5f15\u5c0e\u5c0d\u6297\u63d0\u793a\u7684\u641c\u5c0b\u3002\u5fae\u8abf\u4ecb\u9762\u7531 LLM \u4f9b\u61c9\u5546\u8a17\u7ba1\uff0c\u4e26\u5141\u8a31\u958b\u767c\u4eba\u54e1\u91dd\u5c0d\u5176\u4efb\u52d9\u5fae\u8abf LLM\uff0c\u5f9e\u800c\u63d0\u4f9b\u6548\u7528\uff0c\u4f46\u4e5f\u516c\u958b\u4e86\u8db3\u5920\u7684\u8cc7\u8a0a\u4f9b\u653b\u64ca\u8005\u8a08\u7b97\u5c0d\u6297\u63d0\u793a\u3002\u900f\u904e\u5be6\u9a57\u5206\u6790\uff0c\u6211\u5011\u63cf\u8ff0\u4e86 Gemini \u5fae\u8abf API \u50b3\u56de\u7684\u985e\u4f3c\u640d\u5931\u7684\u503c\uff0c\u4e26\u8b49\u660e\u5b83\u5011\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u8a0a\u865f\uff0c\u53ef\u7528\u65bc\u4f7f\u7528\u8caa\u5a6a\u641c\u5c0b\u6f14\u7b97\u6cd5\u5c0d\u6297\u63d0\u793a\u9032\u884c\u96e2\u6563\u6700\u4f73\u5316\u3002\u4f7f\u7528 PurpleLlama \u63d0\u793a\u6ce8\u5165\u57fa\u6e96\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5728 Google \u7684 LLM \u5bb6\u65cf Gemini \u4e0a\u7684\u653b\u64ca\u6210\u529f\u7387\u4ecb\u65bc 65% \u5230 82% \u4e4b\u9593\u3002\u9019\u4e9b\u653b\u64ca\u5229\u7528\u4e86\u7d93\u5178\u7684\u6548\u7528\u5b89\u5168\u6027\u6b0a\u8861 - \u5fae\u8abf\u4ecb\u9762\u70ba\u958b\u767c\u4eba\u54e1\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u529f\u80fd\uff0c\u4f46\u4e5f\u6703\u8b93 LLM \u906d\u53d7\u5f37\u5927\u7684\u653b\u64ca\u3002", "author": "Andrey Labunets et.al.", "authors": "Andrey Labunets, Nishit V. Pandya, Ashish Hooda, Xiaohan Fu, Earlence Fernandes", "id": "2501.09798v1", "paper_url": "http://arxiv.org/abs/2501.09798v1", "repo": "null"}}