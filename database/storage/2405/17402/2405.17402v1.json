{"2405.17402": {"publish_time": "2024-05-27", "title": "THREAD: Thinking Deeper with Recursive Spawning", "paper_summary": "Large language models (LLMs) have shown impressive capabilities across\ndiverse settings, but still struggle as the length and complexity of the\ncontext increases. To address this challenge, we propose Thinking Recursively\nand Dynamically (ThReaD). THREAD frames model generation as a thread of\nexecution that, based on the context, can run to completion or dynamically\nspawn new threads. By spawning, threads can offload work (e.g., thinking,\nretrieving information) to child threads, which only return tokens needed for\nthe parent thread to do its work. In effect, this enables the model to adapt,\nas needed, the amount of intermediate work used to produce tokens. We apply\nTHREAD in the settings of LLM task solving and question answering, where the\ndynamic threading allows the model to recursively decompose the given task or\nquestion into progressively simpler sub-problems that can be solved by separate\nchild threads. We test THREAD, implemented using a few-shot learning approach,\non diverse benchmarks for agent tasks and data-grounded question answering.\nTHREAD achieves state-of-the-art performance with GPT-4 and GPT-3.5 on these\nbenchmarks, including ALFWorld, TextCraft, and WebShop, along with two new\nbenchmarks, DataCommons QA and MIMIC-III ICU QA. In addition, THREAD\noutperforms existing frameworks by 10% to 50% absolute points with smaller\nmodels, including Llama-3-8b and CodeLlama-7b.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u5404\u7a2e\u74b0\u5883\u4e2d\u5c55\u73fe\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4f46\u96a8\u8457\u5167\u5bb9\u9577\u5ea6\u548c\u8907\u96dc\u6027\u7684\u589e\u52a0\uff0c\u5b83\u5011\u4ecd\u6703\u9762\u81e8\u6311\u6230\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u9805\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u601d\u8003\u905e\u8ff4\u548c\u52d5\u614b (ThReaD) \u7684\u6982\u5ff5\u3002THREAD \u5c07\u6a21\u578b\u751f\u6210\u8a2d\u5b9a\u70ba\u4e00\u500b\u57f7\u884c\u7dd2\uff0c\u6839\u64da\u5167\u5bb9\uff0c\u5b83\u53ef\u4ee5\u57f7\u884c\u5230\u5b8c\u6210\u6216\u52d5\u614b\u7522\u751f\u65b0\u7684\u57f7\u884c\u7dd2\u3002\u900f\u904e\u7522\u751f\uff0c\u57f7\u884c\u7dd2\u53ef\u4ee5\u5c07\u5de5\u4f5c (\u4f8b\u5982\u601d\u8003\u3001\u64f7\u53d6\u8cc7\u8a0a) \u8f49\u79fb\u5230\u5b50\u57f7\u884c\u7dd2\uff0c\u5b50\u57f7\u884c\u7dd2\u53ea\u6703\u50b3\u56de\u7236\u57f7\u884c\u7dd2\u57f7\u884c\u5de5\u4f5c\u6240\u9700\u7684\u7b26\u865f\u3002\u5be6\u969b\u4e0a\uff0c\u9019\u8b93\u6a21\u578b\u80fd\u5920\u5728\u9700\u8981\u6642\u8abf\u6574\u7528\u65bc\u7522\u751f\u7b26\u865f\u7684\u4e2d\u9593\u5de5\u4f5c\u91cf\u3002\u6211\u5011\u5728 LLM \u4efb\u52d9\u89e3\u6c7a\u548c\u554f\u984c\u56de\u7b54\u7684\u8a2d\u5b9a\u4e2d\u5957\u7528 THREAD\uff0c\u52d5\u614b\u57f7\u884c\u7dd2\u8b93\u6a21\u578b\u80fd\u5920\u905e\u8ff4\u5206\u89e3\u7d66\u5b9a\u7684\u4efb\u52d9\u6216\u554f\u984c\uff0c\u6210\u70ba\u66f4\u7c21\u55ae\u7684\u5b50\u554f\u984c\uff0c\u9019\u4e9b\u5b50\u554f\u984c\u53ef\u4ee5\u7531\u500b\u5225\u7684\u5b50\u57f7\u884c\u7dd2\u89e3\u6c7a\u3002\u6211\u5011\u4f7f\u7528\u5c11\u91cf\u5b78\u7fd2\u65b9\u6cd5\u5be6\u4f5c THREAD\uff0c\u4e26\u5728\u4ee3\u7406\u4eba\u4efb\u52d9\u548c\u8cc7\u6599\u57fa\u790e\u554f\u984c\u56de\u7b54\u7684\u5404\u7a2e\u57fa\u6e96\u4e0a\u9032\u884c\u6e2c\u8a66\u3002THREAD \u5728\u9019\u4e9b\u57fa\u6e96\u4e0a\u4f7f\u7528 GPT-4 \u548c GPT-3.5 \u9054\u5230\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u5305\u62ec ALFWorld\u3001TextCraft \u548c WebShop\uff0c\u4ee5\u53ca\u5169\u500b\u65b0\u7684\u57fa\u6e96\uff0cDataCommons QA \u548c MIMIC-III ICU QA\u3002\u6b64\u5916\uff0cTHREAD \u4ee5\u8f03\u5c0f\u7684\u6a21\u578b\u8d85\u8d8a\u73fe\u6709\u67b6\u69cb 10% \u5230 50% \u7684\u7d55\u5c0d\u9ede\u6578\uff0c\u5305\u62ec Llama-3-8b \u548c CodeLlama-7b\u3002", "author": "Philip Schroeder et.al.", "authors": "Philip Schroeder, Nathaniel Morgan, Hongyin Luo, James Glass", "id": "2405.17402v1", "paper_url": "http://arxiv.org/abs/2405.17402v1", "repo": "null"}}