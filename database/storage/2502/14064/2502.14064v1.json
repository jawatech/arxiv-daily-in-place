{"2502.14064": {"publish_time": "2025-02-19", "title": "Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging", "paper_summary": "Vision foundation models (VFMs) are pre-trained on extensive image datasets\nto learn general representations for diverse types of data. These models can\nsubsequently be fine-tuned for specific downstream tasks, significantly\nboosting performance across a broad range of applications. However, existing\nvision foundation models that claim to be applicable to various radiology tasks\nare mostly pre-trained on 3D computed tomography (CT), which benefits from the\navailability of extensive 3D CT databases. Significant differences between CT\nand magnetic resonance imaging (MRI) in imaging principles, signal\ncharacteristics, and data distribution may hinder their practical performance\nand versatility in MRI-specific applications. Here, we propose Triad, a vision\nfoundation model for 3D MRI. Triad adopts a widely used autoencoder\narchitecture to learn robust representations from 131,170 3D MRI volumes and\nuses organ-independent imaging descriptions to constrain the semantic\ndistribution of the visual modality. The above pre-training dataset is called\nTriad-131K, which is currently the largest 3D MRI pre-training dataset. We\nevaluate Triad across three tasks, namely, organ/tumor segmentation,\norgan/cancer classification, and medical image registration, in two data\nmodalities (within-domain and out-of-domain) settings using 25 downstream\ndatasets. By initializing models with Triad's pre-trained weights, nnUNet-Triad\nimproves segmentation performance by 6.88% compared to nnUNet-Scratch across 17\ndatasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch in\nclassification tasks across five datasets. SwinUNETR-Triad improves by 4.00%\ncompared to SwinUNETR-Scratch in registration tasks across two datasets. Our\nstudy demonstrates that pre-training can maximize performance when the data\nmodalities and organs of upstream and downstream tasks are consistent.", "paper_summary_zh": "\u8996\u89ba\u57fa\u790e\u6a21\u578b (VFM) \u5728\u5ee3\u6cdb\u7684\u5f71\u50cf\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u9810\u8a13\u7df4\uff0c\u4ee5\u5b78\u7fd2\u5404\u7a2e\u8cc7\u6599\u985e\u578b\u7684\u901a\u7528\u8868\u793a\u3002\u9019\u4e9b\u6a21\u578b\u96a8\u5f8c\u53ef\u4ee5\u91dd\u5c0d\u7279\u5b9a\u7684\u4e0b\u6e38\u4efb\u52d9\u9032\u884c\u5fae\u8abf\uff0c\u5927\u5e45\u63d0\u5347\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u8996\u89ba\u57fa\u790e\u6a21\u578b\u8072\u7a31\u9069\u7528\u65bc\u5404\u7a2e\u653e\u5c04\u5b78\u4efb\u52d9\uff0c\u4f46\u5927\u591a\u662f\u91dd\u5c0d 3D \u96fb\u8166\u65b7\u5c64\u651d\u5f71 (CT) \u9032\u884c\u9810\u8a13\u7df4\uff0c\u9019\u5f97\u5229\u65bc\u5ee3\u6cdb\u7684 3D CT \u8cc7\u6599\u5eab\u3002CT \u548c\u78c1\u632f\u9020\u5f71 (MRI) \u5728\u5f71\u50cf\u539f\u7406\u3001\u8a0a\u865f\u7279\u6027\u548c\u8cc7\u6599\u5206\u4f48\u4e0a\u7684\u986f\u8457\u5dee\u7570\uff0c\u53ef\u80fd\u6703\u963b\u7919\u5176\u5728 MRI \u7279\u5b9a\u61c9\u7528\u4e2d\u7684\u5be6\u969b\u6548\u80fd\u548c\u591a\u529f\u80fd\u6027\u3002\u5728\u6b64\uff0c\u6211\u5011\u63d0\u51fa Triad\uff0c\u4e00\u500b\u9069\u7528\u65bc 3D MRI \u7684\u8996\u89ba\u57fa\u790e\u6a21\u578b\u3002Triad \u63a1\u7528\u5ee3\u6cdb\u4f7f\u7528\u7684\u81ea\u52d5\u7de8\u78bc\u5668\u67b6\u69cb\uff0c\u5f9e 131,170 \u500b 3D MRI \u9ad4\u7a4d\u4e2d\u5b78\u7fd2\u7a69\u5065\u7684\u8868\u793a\uff0c\u4e26\u4f7f\u7528\u8207\u5668\u5b98\u7121\u95dc\u7684\u5f71\u50cf\u63cf\u8ff0\u4f86\u7d04\u675f\u8996\u89ba\u6a21\u5f0f\u7684\u8a9e\u7fa9\u5206\u4f48\u3002\u4e0a\u8ff0\u9810\u8a13\u7df4\u8cc7\u6599\u96c6\u7a31\u70ba Triad-131K\uff0c\u76ee\u524d\u662f\u6700\u5927\u7684 3D MRI \u9810\u8a13\u7df4\u8cc7\u6599\u96c6\u3002\u6211\u5011\u5728\u4e09\u500b\u4efb\u52d9\u4e2d\u8a55\u4f30 Triad\uff0c\u5373\u5668\u5b98/\u816b\u7624\u5206\u5272\u3001\u5668\u5b98/\u764c\u75c7\u5206\u985e\u548c\u91ab\u5b78\u5f71\u50cf\u914d\u6e96\uff0c\u5728\u5169\u500b\u8cc7\u6599\u6a21\u5f0f\uff08\u57df\u5167\u548c\u57df\u5916\uff09\u8a2d\u5b9a\u4e2d\u4f7f\u7528 25 \u500b\u4e0b\u6e38\u8cc7\u6599\u96c6\u3002\u900f\u904e\u4f7f\u7528 Triad \u7684\u9810\u8a13\u7df4\u6b0a\u91cd\u521d\u59cb\u5316\u6a21\u578b\uff0cnnUNet-Triad \u5728 17 \u500b\u8cc7\u6599\u96c6\u4e2d\u7684\u5206\u5272\u6548\u80fd\u6bd4 nnUNet-Scratch \u63d0\u5347\u4e86 6.88%\u3002Swin-B-Triad \u5728\u4e94\u500b\u8cc7\u6599\u96c6\u7684\u5206\u985e\u4efb\u52d9\u4e2d\uff0c\u6bd4 Swin-B-Scratch \u63d0\u5347\u4e86 3.97%\u3002SwinUNETR-Triad \u5728\u5169\u500b\u8cc7\u6599\u96c6\u7684\u914d\u6e96\u4efb\u52d9\u4e2d\uff0c\u6bd4 SwinUNETR-Scratch \u63d0\u5347\u4e86 4.00%\u3002\u6211\u5011\u7684\u7814\u7a76\u8b49\u660e\uff0c\u7576\u4e0a\u6e38\u548c\u4e0b\u6e38\u4efb\u52d9\u7684\u8cc7\u6599\u6a21\u5f0f\u548c\u5668\u5b98\u4e00\u81f4\u6642\uff0c\u9810\u8a13\u7df4\u53ef\u4ee5\u6700\u5927\u5316\u6548\u80fd\u3002", "author": "Shansong Wang et.al.", "authors": "Shansong Wang, Mojtaba Safari, Qiang Li, Chih-Wei Chang, Richard LJ Qiu, Justin Roper, David S. Yu, Xiaofeng Yang", "id": "2502.14064v1", "paper_url": "http://arxiv.org/abs/2502.14064v1", "repo": "null"}}