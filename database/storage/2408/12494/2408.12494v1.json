{"2408.12494": {"publish_time": "2024-08-22", "title": "GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models", "paper_summary": "Large language models (LLMs) have exhibited remarkable capabilities in\nnatural language generation, but they have also been observed to magnify\nsocietal biases, particularly those related to gender. In response to this\nissue, several benchmarks have been proposed to assess gender bias in LLMs.\nHowever, these benchmarks often lack practical flexibility or inadvertently\nintroduce biases. To address these shortcomings, we introduce GenderCARE, a\ncomprehensive framework that encompasses innovative Criteria, bias Assessment,\nReduction techniques, and Evaluation metrics for quantifying and mitigating\ngender bias in LLMs. To begin, we establish pioneering criteria for gender\nequality benchmarks, spanning dimensions such as inclusivity, diversity,\nexplainability, objectivity, robustness, and realisticity. Guided by these\ncriteria, we construct GenderPair, a novel pair-based benchmark designed to\nassess gender bias in LLMs comprehensively. Our benchmark provides standardized\nand realistic evaluations, including previously overlooked gender groups such\nas transgender and non-binary individuals. Furthermore, we develop effective\ndebiasing techniques that incorporate counterfactual data augmentation and\nspecialized fine-tuning strategies to reduce gender bias in LLMs without\ncompromising their overall performance. Extensive experiments demonstrate a\nsignificant reduction in various gender bias benchmarks, with reductions\npeaking at over 90% and averaging above 35% across 17 different LLMs.\nImportantly, these reductions come with minimal variability in mainstream\nlanguage tasks, remaining below 2%. By offering a realistic assessment and\ntailored reduction of gender biases, we hope that our GenderCARE can represent\na significant step towards achieving fairness and equity in LLMs. More details\nare available at https://github.com/kstanghere/GenderCARE-ccs24.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u751f\u6210\u65b9\u9762\u8868\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u4e5f\u88ab\u89c0\u5bdf\u5230\u6703\u653e\u5927\u793e\u6703\u504f\u898b\uff0c\u7279\u5225\u662f\u8207\u6027\u5225\u76f8\u95dc\u7684\u504f\u898b\u3002\u70ba\u4e86\u56de\u61c9\u9019\u500b\u554f\u984c\uff0c\u5df2\u7d93\u63d0\u51fa\u4e86\u5e7e\u500b\u57fa\u6e96\u4f86\u8a55\u4f30 LLM \u4e2d\u7684\u6027\u5225\u504f\u898b\u3002\u7136\u800c\uff0c\u9019\u4e9b\u57fa\u6e96\u901a\u5e38\u7f3a\u4e4f\u5be6\u7528\u7684\u9748\u6d3b\u6027\uff0c\u6216\u8005\u6703\u7121\u610f\u4e2d\u5f15\u5165\u504f\u898b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u7f3a\u9ede\uff0c\u6211\u5011\u5f15\u5165\u4e86 GenderCARE\uff0c\u4e00\u500b\u5168\u9762\u7684\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u542b\u5275\u65b0\u7684\u6a19\u6e96\u3001\u504f\u898b\u8a55\u4f30\u3001\u6e1b\u5c11\u6280\u8853\u548c\u8a55\u4f30\u6307\u6a19\uff0c\u7528\u65bc\u91cf\u5316\u548c\u6e1b\u8f15 LLM \u4e2d\u7684\u6027\u5225\u504f\u898b\u3002\u9996\u5148\uff0c\u6211\u5011\u70ba\u6027\u5225\u5e73\u7b49\u57fa\u6e96\u5236\u5b9a\u4e86\u958b\u5275\u6027\u7684\u6a19\u6e96\uff0c\u6db5\u84cb\u5305\u5bb9\u6027\u3001\u591a\u6a23\u6027\u3001\u53ef\u89e3\u91cb\u6027\u3001\u5ba2\u89c0\u6027\u3001\u7a69\u5065\u6027\u548c\u73fe\u5be6\u6027\u7b49\u9762\u5411\u3002\u5728\u9019\u4e9b\u6a19\u6e96\u7684\u6307\u5c0e\u4e0b\uff0c\u6211\u5011\u69cb\u5efa\u4e86 GenderPair\uff0c\u4e00\u500b\u65b0\u7a4e\u7684\u57fa\u65bc\u914d\u5c0d\u7684\u57fa\u6e96\uff0c\u65e8\u5728\u5168\u9762\u8a55\u4f30 LLM \u4e2d\u7684\u6027\u5225\u504f\u898b\u3002\u6211\u5011\u7684\u57fa\u6e96\u63d0\u4f9b\u4e86\u6a19\u6e96\u5316\u548c\u73fe\u5be6\u7684\u8a55\u4f30\uff0c\u5305\u62ec\u4ee5\u524d\u88ab\u5ffd\u8996\u7684\u6027\u5225\u7fa4\u9ad4\uff0c\u4f8b\u5982\u8de8\u6027\u5225\u8005\u548c\u975e\u4e8c\u5143\u6027\u5225\u8005\u3002\u6b64\u5916\uff0c\u6211\u5011\u958b\u767c\u4e86\u6709\u6548\u7684\u53bb\u504f\u6280\u8853\uff0c\u7d50\u5408\u4e86\u53cd\u4e8b\u5be6\u6578\u64da\u64f4\u5145\u548c\u5c08\u9580\u7684\u5fae\u8abf\u7b56\u7565\uff0c\u4ee5\u6e1b\u5c11 LLM \u4e2d\u7684\u6027\u5225\u504f\u898b\uff0c\u540c\u6642\u4e0d\u640d\u5bb3\u5176\u6574\u9ad4\u6027\u80fd\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u5404\u7a2e\u6027\u5225\u504f\u898b\u57fa\u6e96\u7684\u986f\u8457\u6e1b\u5c11\uff0c\u6e1b\u5c11\u5e45\u5ea6\u6700\u9ad8\u8d85\u904e 90%\uff0c\u5728 17 \u500b\u4e0d\u540c\u7684 LLM \u4e2d\u5e73\u5747\u964d\u4f4e\u4e86 35% \u4ee5\u4e0a\u3002\u91cd\u8981\u7684\u662f\uff0c\u9019\u4e9b\u6e1b\u5c11\u4f34\u96a8\u8457\u4e3b\u6d41\u8a9e\u8a00\u4efb\u52d9\u7684\u6700\u5c0f\u8b8a\u7570\u6027\uff0c\u4fdd\u6301\u5728 2% \u4ee5\u4e0b\u3002\u901a\u904e\u63d0\u4f9b\u5c0d\u6027\u5225\u504f\u898b\u7684\u73fe\u5be6\u8a55\u4f30\u548c\u91cf\u8eab\u5b9a\u5236\u7684\u6e1b\u5c11\uff0c\u6211\u5011\u5e0c\u671b\u6211\u5011\u7684 GenderCARE \u80fd\u4ee3\u8868\u8457\u9081\u5411\u5728 LLM \u4e2d\u5be6\u73fe\u516c\u5e73\u548c\u6b63\u7fa9\u7684\u91cd\u8981\u4e00\u6b65\u3002\u66f4\u591a\u8a73\u60c5\u53ef\u5728 https://github.com/kstanghere/GenderCARE-ccs24 \u627e\u5230\u3002", "author": "Kunsheng Tang et.al.", "authors": "Kunsheng Tang, Wenbo Zhou, Jie Zhang, Aishan Liu, Gelei Deng, Shuai Li, Peigui Qi, Weiming Zhang, Tianwei Zhang, Nenghai Yu", "id": "2408.12494v1", "paper_url": "http://arxiv.org/abs/2408.12494v1", "repo": "https://github.com/kstanghere/gendercare-ccs24"}}