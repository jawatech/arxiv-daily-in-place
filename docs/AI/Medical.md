
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-13**|**RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**|Difei Gu et.al.|[2501.07525v1](http://arxiv.org/abs/2501.07525v1)|[link](https://github.com/difeigu/radalign)|
|**2025-01-13**|**A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**|Yihao Liu et.al.|[2501.07468v1](http://arxiv.org/abs/2501.07468v1)|null|
|**2025-01-13**|**Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**|Xiyue Zhu et.al.|[2501.07430v1](http://arxiv.org/abs/2501.07430v1)|null|
|**2025-01-13**|**Natural Language-Assisted Multi-modal Medication Recommendation**|Jie Tan et.al.|[2501.07166v1](http://arxiv.org/abs/2501.07166v1)|[link](https://github.com/jtan1102/nla-mmr_cikm_2024)|
|**2025-01-13**|**CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**|Jinlin Li et.al.|[2501.07157v1](http://arxiv.org/abs/2501.07157v1)|[link](https://github.com/jinlin2021/curegraph)|
|**2025-01-13**|**UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**|Xuhui Guo et.al.|[2501.07017v1](http://arxiv.org/abs/2501.07017v1)|null|
|**2025-01-13**|**Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**|Karine Karine et.al.|[2501.06980v1](http://arxiv.org/abs/2501.06980v1)|null|
|**2025-01-12**|**Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**|Xinyao Ma et.al.|[2501.06964v1](http://arxiv.org/abs/2501.06964v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-12**|**A Foundational Generative Model for Breast Ultrasound Image Analysis**|Haojun Yu et.al.|[2501.06869v1](http://arxiv.org/abs/2501.06869v1)|null|
|**2025-01-12**|**A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**|Noureldin Zahran et.al.|[2501.06859v1](http://arxiv.org/abs/2501.06859v1)|null|
|**2025-01-12**|**MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**|Yiqing Zhang et.al.|[2501.06823v1](http://arxiv.org/abs/2501.06823v1)|null|
|**2025-01-12**|**PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation**|Zhonghao Yan et.al.|[2501.06692v1](http://arxiv.org/abs/2501.06692v1)|null|
|**2025-01-12**|**Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels**|Erjian Guo et.al.|[2501.06678v1](http://arxiv.org/abs/2501.06678v1)|[link](https://github.com/erjian96/clcs)|
|**2025-01-11**|**MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**|Ye Chen et.al.|[2501.06465v1](http://arxiv.org/abs/2501.06465v1)|null|
|**2025-01-11**|**Deep Learning on Hester Davis Scores for Inpatient Fall Prediction**|Hojjat Salehinejad et.al.|[2501.06432v1](http://arxiv.org/abs/2501.06432v1)|null|
|**2025-01-10**|**Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts**|Elizabeth Schaefer et.al.|[2501.06365v1](http://arxiv.org/abs/2501.06365v1)|null|
|**2025-01-10**|**Scale-up Unlearnable Examples Learning with High-Performance Computing**|Yanfan Zhu et.al.|[2501.06080v1](http://arxiv.org/abs/2501.06080v1)|null|
|**2025-01-10**|**AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**|Johann Wenckstern et.al.|[2501.06039v1](http://arxiv.org/abs/2501.06039v1)|null|
|**2025-01-10**|**DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**|Yongfan Lai et.al.|[2501.05932v1](http://arxiv.org/abs/2501.05932v1)|null|
|**2025-01-10**|**AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India**|Amit Kr Dey et.al.|[2501.05826v2](http://arxiv.org/abs/2501.05826v2)|null|
|**2025-01-10**|**Large Language Models for Bioinformatics**|Wei Ruan et.al.|[2501.06271v1](http://arxiv.org/abs/2501.06271v1)|null|
|**2025-01-09**|**From Simple to Complex Skills: The Case of In-Hand Object Reorientation**|Haozhi Qi et.al.|[2501.05439v1](http://arxiv.org/abs/2501.05439v1)|null|
|**2025-01-09**|**Strategy Masking: A Method for Guardrails in Value-based Reinforcement Learning Agents**|Jonathan Keane et.al.|[2501.05501v1](http://arxiv.org/abs/2501.05501v1)|null|
|**2025-01-09**|**Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics**|Maximilian Alber et.al.|[2501.05409v2](http://arxiv.org/abs/2501.05409v2)|null|
|**2025-01-09**|**An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**|Drago Plecko et.al.|[2501.05197v1](http://arxiv.org/abs/2501.05197v1)|null|
|**2025-01-09**|**Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**|Lei Li et.al.|[2501.04958v1](http://arxiv.org/abs/2501.04958v1)|[link](https://github.com/yinghemedical/imbalance-aware_domain_adaptation)|
|**2025-01-09**|**Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**|Michail Ouroutzoglou et.al.|[2501.04896v1](http://arxiv.org/abs/2501.04896v1)|null|
|**2025-01-08**|**MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**|Daniele Molino et.al.|[2501.04614v2](http://arxiv.org/abs/2501.04614v2)|null|
|**2025-01-08**|**A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**|Zephan M. Enciso et.al.|[2501.04577v1](http://arxiv.org/abs/2501.04577v1)|null|
|**2025-01-08**|**Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**|Ren Tasai et.al.|[2501.04217v1](http://arxiv.org/abs/2501.04217v1)|null|
|**2025-01-07**|**Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**|Rancy Chepchirchir et.al.|[2501.04734v1](http://arxiv.org/abs/2501.04734v1)|[link](https://github.com/CAMERA-MRI/SPARK2023/tree/main/SPARK_BTS_KIFARU)|
|**2025-01-07**|**Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**|Ramya Jonnala et.al.|[2501.03904v1](http://arxiv.org/abs/2501.03904v1)|null|
|**2025-01-07**|**SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**|Runci Bai et.al.|[2501.03836v2](http://arxiv.org/abs/2501.03836v2)|null|
|**2025-01-07**|**SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**|Siyuan Zhao et.al.|[2501.03764v1](http://arxiv.org/abs/2501.03764v1)|null|
|**2025-01-07**|**Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**|Xiaotong Guo et.al.|[2501.03722v1](http://arxiv.org/abs/2501.03722v1)|null|
|**2025-01-07**|**Can Deep Learning Trigger Alerts from Mobile-Captured Images?**|Pritisha Sarkar et.al.|[2501.03499v1](http://arxiv.org/abs/2501.03499v1)|null|
|**2025-01-07**|**Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**|Xiao Wang et.al.|[2501.03458v1](http://arxiv.org/abs/2501.03458v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2025-01-06**|**Existential Crisis: A Social Robot's Reason for Being**|Dora Medgyesy et.al.|[2501.03376v1](http://arxiv.org/abs/2501.03376v1)|null|
|**2025-01-06**|**Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**|Susu Sun et.al.|[2501.02922v1](http://arxiv.org/abs/2501.02922v1)|null|
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2025-01-06**|**IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks by Efficient Human Preference Alignment**|Yiming Zhang et.al.|[2501.02869v1](http://arxiv.org/abs/2501.02869v1)|null|
|**2025-01-06**|**Multi-Modal One-Shot Federated Ensemble Learning for Medical Data with Vision Large Language Model**|Naibo Wang et.al.|[2501.03292v1](http://arxiv.org/abs/2501.03292v1)|null|
|**2025-01-06**|**GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation**|Niloufar Eghbali et.al.|[2501.02788v2](http://arxiv.org/abs/2501.02788v2)|[link](https://github.com/haail/glog-csunet)|
|**2025-01-06**|**Hybrid deep convolution model for lung cancer detection with transfer learning**|Sugandha Saxena et.al.|[2501.02785v1](http://arxiv.org/abs/2501.02785v1)|null|
|**2025-01-06**|**ICFNet: Integrated Cross-modal Fusion Network for Survival Prediction**|Binyu Zhang et.al.|[2501.02778v1](http://arxiv.org/abs/2501.02778v1)|[link](https://github.com/binging512/icfnet)|
|**2025-01-06**|**Tree-based RAG-Agent Recommendation System: A Case Study in Medical Test Data**|Yahe Yang et.al.|[2501.02727v1](http://arxiv.org/abs/2501.02727v1)|null|
|**2025-01-05**|**Representation Learning of Lab Values via Masked AutoEncoder**|David Restrepo et.al.|[2501.02648v2](http://arxiv.org/abs/2501.02648v2)|[link](https://github.com/dsrestrepo/lab-mae-foundation-tabular)|
|**2025-01-05**|**Trust and Dependability in Blockchain & AI Based MedIoT Applications: Research Challenges and Future Directions**|Ellis Solaiman et.al.|[2501.02647v1](http://arxiv.org/abs/2501.02647v1)|null|
|**2025-01-05**|**KM-UNet KAN Mamba UNet for medical image segmentation**|Yibo Zhang et.al.|[2501.02559v1](http://arxiv.org/abs/2501.02559v1)|[link](https://github.com/2760613195/km_unet)|
|**2025-01-05**|**Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine**|Yishen Liu et.al.|[2501.02471v1](http://arxiv.org/abs/2501.02471v1)|null|
|**2025-01-05**|**Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales**|Zijie Cheng et.al.|[2501.02451v1](http://arxiv.org/abs/2501.02451v1)|null|
|**2025-01-04**|**Enhancing Workplace Productivity and Well-being Using AI Agent**|Ravirajan K et.al.|[2501.02368v1](http://arxiv.org/abs/2501.02368v1)|null|
|**2025-01-04**|**Exploring the Capabilities and Limitations of Large Language Models for Radiation Oncology Decision Support**|Florian Putz et.al.|[2501.02346v1](http://arxiv.org/abs/2501.02346v1)|null|
|**2025-01-04**|**Deep Learning-Driven Segmentation of Ischemic Stroke Lesions Using Multi-Channel MRI**|Ashiqur Rahman et.al.|[2501.02287v1](http://arxiv.org/abs/2501.02287v1)|null|
|**2025-01-04**|**The Integration of Blockchain and Artificial Intelligence for Secure Healthcare Systems**|Umar Safdar et.al.|[2501.02169v1](http://arxiv.org/abs/2501.02169v1)|null|
|**2025-01-03**|**Online Detection of Water Contamination Under Concept Drift**|Jin Li et.al.|[2501.02107v1](http://arxiv.org/abs/2501.02107v1)|null|
|**2025-01-03**|**METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring**|Ollie Liu et.al.|[2501.02045v1](http://arxiv.org/abs/2501.02045v1)|null|
|**2025-01-03**|**Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT**|Jianping He et.al.|[2501.02044v1](http://arxiv.org/abs/2501.02044v1)|null|
|**2025-01-03**|**Combined Hyper-Extensible Extremely-Secured Zero-Trust CIAM-PAM architecture**|Shivom Aggarwal et.al.|[2501.01732v1](http://arxiv.org/abs/2501.01732v1)|null|
|**2025-01-03**|**EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical image segmentation**|Wang Lituan et.al.|[2501.01658v1](http://arxiv.org/abs/2501.01658v1)|null|
|**2025-01-03**|**Implications of Artificial Intelligence on Health Data Privacy and Confidentiality**|Ahmad Momani et.al.|[2501.01639v2](http://arxiv.org/abs/2501.01639v2)|null|
|**2025-01-03**|**Merging Context Clustering with Visual State Space Models for Medical Image Segmentation**|Yun Zhu et.al.|[2501.01618v1](http://arxiv.org/abs/2501.01618v1)|[link](https://github.com/zymissy/ccvim)|
|**2025-01-03**|**PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents**|Jingoo Lee et.al.|[2501.01594v1](http://arxiv.org/abs/2501.01594v1)|null|
|**2025-01-02**|**Model Checking in Medical Imaging for Tumor Detection and Segmentation**|Elhoucine Elfatimi et.al.|[2501.02024v2](http://arxiv.org/abs/2501.02024v2)|null|
|**2025-01-02**|**Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**|Yucheng Zhou et.al.|[2501.01377v1](http://arxiv.org/abs/2501.01377v1)|null|
|**2025-01-02**|**ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**|Neda Tavakoli et.al.|[2501.01372v1](http://arxiv.org/abs/2501.01372v1)|[link](https://github.com/nedatavakoli/scarnet)|
|**2025-01-02**|**Contrastive Learning from Exploratory Actions: Leveraging Natural Interactions for Preference Elicitation**|Nathaniel Dennler et.al.|[2501.01367v1](http://arxiv.org/abs/2501.01367v1)|null|
|**2025-01-02**|**Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**|Bohang Sun et.al.|[2501.01311v2](http://arxiv.org/abs/2501.01311v2)|null|
|**2025-01-02**|**Machine Learning-Based Differential Diagnosis of Parkinson's Disease Using Kinematic Feature Extraction and Selection**|Masahiro Matsumoto et.al.|[2501.02014v1](http://arxiv.org/abs/2501.02014v1)|null|
|**2025-01-02**|**Data Augmentation Techniques for Chinese Disease Name Normalization**|Wenqian Cui et.al.|[2501.01195v1](http://arxiv.org/abs/2501.01195v1)|[link](https://github.com/dreamtheater123/disease_name_dataset)|
|**2025-01-02**|**Reasoning based on symbolic and parametric knowledge bases: a survey**|Mayi Xu et.al.|[2501.01030v1](http://arxiv.org/abs/2501.01030v1)|null|
|**2025-01-02**|**Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice**|Federico Ravenda et.al.|[2501.00982v1](http://arxiv.org/abs/2501.00982v1)|[link](https://github.com/fede-stack/adaptive-rag-for-psychological-assessment)|
|**2025-01-01**|**Enhancing Early Diabetic Retinopathy Detection through Synthetic DR1 Image Generation: A StyleGAN3 Approach**|Sagarnil Das et.al.|[2501.00954v1](http://arxiv.org/abs/2501.00954v1)|null|
|**2025-01-01**|**Multi-Center Study on Deep Learning-Assisted Detection and Classification of Fetal Central Nervous System Anomalies Using Ultrasound Imaging**|Yang Qi et.al.|[2501.02000v1](http://arxiv.org/abs/2501.02000v1)|null|
|**2024-12-31**|**Efficient Standardization of Clinical Notes using Large Language Models**|Daniel B. Hier et.al.|[2501.00644v1](http://arxiv.org/abs/2501.00644v1)|null|
|**2024-12-31**|**LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models**|Hang Yang et.al.|[2501.05464v1](http://arxiv.org/abs/2501.05464v1)|null|
|**2024-12-31**|**Pan-infection Foundation Framework Enables Multiple Pathogen Prediction**|Lingrui Zhang et.al.|[2501.01462v1](http://arxiv.org/abs/2501.01462v1)|null|
|**2024-12-31**|**A Hybrid Deep Learning and Model-Checking Framework for Accurate Brain Tumor Detection and Validation**|Lahcen El Fatimi et.al.|[2501.01991v1](http://arxiv.org/abs/2501.01991v1)|null|
|**2024-12-31**|**GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification**|George Yuanji Wang et.al.|[2501.01458v1](http://arxiv.org/abs/2501.01458v1)|[link](https://github.com/george-yuanji-wang/gan-tat)|
|**2024-12-31**|**Autonomous Alignment with Human Value on Altruism through Considerate Self-imagination and Theory of Mind**|Haibo Tong et.al.|[2501.00320v2](http://arxiv.org/abs/2501.00320v2)|[link](https://github.com/braincog-x/brain-cog)|
|**2024-12-31**|**A Fourfold Pathogen Reference Ontology Suite**|Shane Babcock et.al.|[2501.01454v1](http://arxiv.org/abs/2501.01454v1)|null|
|**2024-12-31**|**CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**|Michael Gubanov et.al.|[2501.00223v1](http://arxiv.org/abs/2501.00223v1)|null|
|**2024-12-31**|**An Empirical Evaluation of Large Language Models on Consumer Health Questions**|Moaiz Abrar et.al.|[2501.00208v1](http://arxiv.org/abs/2501.00208v1)|null|
|**2024-12-31**|**GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study**|Giuliano Lorenzoni et.al.|[2501.00199v1](http://arxiv.org/abs/2501.00199v1)|null|
|**2024-12-31**|**SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction**|Changchang Yin et.al.|[2501.00190v2](http://arxiv.org/abs/2501.00190v2)|[link](https://github.com/yinchangchang/sepsiscalc)|
|**2024-12-30**|**DeepLL: Considering Linear Logic for the Analysis of Deep Learning Experiments**|Nick Papoulias et.al.|[2501.00169v1](http://arxiv.org/abs/2501.00169v1)|null|
|**2024-12-30**|**Temporal reasoning for timeline summarisation in social media**|Jiayu Song et.al.|[2501.00152v1](http://arxiv.org/abs/2501.00152v1)|null|
|**2024-12-30**|**A Data-Centric Approach to Detecting and Mitigating Demographic Bias in Pediatric Mental Health Text: A Case Study in Anxiety Detection**|Julia Ive et.al.|[2501.00129v1](http://arxiv.org/abs/2501.00129v1)|null|
|**2024-12-30**|**Leveraging AI for Automatic Classification of PCOS Using Ultrasound Imaging**|Atharva Divekar et.al.|[2501.01984v1](http://arxiv.org/abs/2501.01984v1)|[link](https://github.com/ATHdevs/Auto-PCOS)|
|**2024-12-30**|**Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks**|Abhinav Roy et.al.|[2412.20744v1](http://arxiv.org/abs/2412.20744v1)|null|
|**2024-12-30**|**Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis**|Yousef Yeganeh et.al.|[2412.20651v1](http://arxiv.org/abs/2412.20651v1)|null|
|**2024-12-29**|**HALLUCINOGEN: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models**|Ashish Seth et.al.|[2412.20622v1](http://arxiv.org/abs/2412.20622v1)|[link](https://github.com/AikyamLab/hallucinogen)|
|**2024-12-29**|**Dive into Time-Series Anomaly Detection: A Decade Review**|Paul Boniol et.al.|[2412.20512v1](http://arxiv.org/abs/2412.20512v1)|null|
|**2024-12-29**|**A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data**|Seungyeon Lee et.al.|[2412.20373v1](http://arxiv.org/abs/2412.20373v1)|null|
|**2024-12-28**|**Transforming CCTV cameras into NO$_2$ sensors at city scale for adaptive policymaking**|Mohamed R. Ibrahim et.al.|[2501.00056v1](http://arxiv.org/abs/2501.00056v1)|null|
|**2024-12-28**|**On the Compositional Generalization of Multimodal LLMs for Medical Imaging**|Zhenyang Cai et.al.|[2412.20070v1](http://arxiv.org/abs/2412.20070v1)|[link](https://github.com/freedomintelligence/med-mat)|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-28**|**MobileNetV2: A lightweight classification model for home-based sleep apnea screening**|Hui Pan et.al.|[2412.19967v2](http://arxiv.org/abs/2412.19967v2)|[link](https://github.com/mindspore-lab/models/tree/master/research/arxiv_papers/Easy-MobileNetV2)|
|**2024-12-27**|**ErgoChat: a Visual Query System for the Ergonomic Risk Assessment of Construction Workers**|Chao Fan et.al.|[2412.19954v1](http://arxiv.org/abs/2412.19954v1)|null|

#### Abstracts
##### **RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**
2501.07525v1 by Difei Gu, Yunhe Gao, Yang Zhou, Mu Zhou, Dimitris Metaxas

Automated chest radiographs interpretation requires both accurate disease
classification and detailed radiology report generation, presenting a
significant challenge in the clinical workflow. Current approaches either focus
on classification accuracy at the expense of interpretability or generate
detailed but potentially unreliable reports through image captioning
techniques. In this study, we present RadAlign, a novel framework that combines
the predictive accuracy of vision-language models (VLMs) with the reasoning
capabilities of large language models (LLMs). Inspired by the radiologist's
workflow, RadAlign first employs a specialized VLM to align visual features
with key medical concepts, achieving superior disease classification with an
average AUC of 0.885 across multiple diseases. These recognized medical
conditions, represented as text-based concepts in the aligned visual-language
space, are then used to prompt LLM-based report generation. Enhanced by a
retrieval-augmented generation mechanism that grounds outputs in similar
historical cases, RadAlign delivers superior report quality with a GREEN score
of 0.678, outperforming state-of-the-art methods' 0.634. Our framework
maintains strong clinical interpretability while reducing hallucinations,
advancing automated medical imaging and report analysis through integrated
predictive and generative AI. Code is available at
https://github.com/difeigu/RadAlign.

摘要：自動化胸部 X 光片解讀需要精準的疾病分類和詳細的放射科報告生成，這對臨床工作流程構成重大挑戰。目前的做法要不就是以犧牲可解讀性為代價專注於分類準確性，要不就是透過影像標題技術產生詳細但可能不可靠的報告。在這項研究中，我們提出 RadAlign，一個結合了視覺語言模型 (VLM) 的預測準確性和大型語言模型 (LLM) 的推理能力的新穎架構。受到放射科醫師工作流程的啟發，RadAlign 首先採用專門的 VLM 將視覺特徵與關鍵醫療概念對齊，在多種疾病中達成優異的疾病分類，平均 AUC 為 0.885。這些識別出的醫療狀況會在對齊的視覺語言空間中表示為基於文字的概念，然後用來提示基於 LLM 的報告生成。透過一種將輸出結果建立在類似過往案例中的檢索增強生成機制，RadAlign 提供優異的報告品質，GREEN 分數為 0.678，優於最先進方法的 0.634。我們的架構維持強大的臨床可解讀性，同時減少幻覺，透過整合預測和生成式 AI，推進自動化醫學影像和報告分析。程式碼可於 https://github.com/difeigu/RadAlign 取得。

##### **A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**
2501.07468v1 by Yihao Liu, Xu Cao, Tingting Chen, Yankai Jiang, Junjie You, Minghua Wu, Xiaosong Wang, Mengling Feng, Yaochu Jin, Jintai Chen

Healthcare systems worldwide face persistent challenges in efficiency,
accessibility, and personalization. Powered by modern AI technologies such as
multimodal large language models and world models, Embodied AI (EmAI)
represents a transformative frontier, offering enhanced autonomy and the
ability to interact with the physical world to address these challenges. As an
interdisciplinary and rapidly evolving research domain, "EmAI in healthcare"
spans diverse fields such as algorithms, robotics, and biomedicine. This
complexity underscores the importance of timely reviews and analyses to track
advancements, address challenges, and foster cross-disciplinary collaboration.
In this paper, we provide a comprehensive overview of the "brain" of EmAI for
healthcare, wherein we introduce foundational AI algorithms for perception,
actuation, planning, and memory, and focus on presenting the healthcare
applications spanning clinical interventions, daily care & companionship,
infrastructure support, and biomedical research. Despite its promise, the
development of EmAI for healthcare is hindered by critical challenges such as
safety concerns, gaps between simulation platforms and real-world applications,
the absence of standardized benchmarks, and uneven progress across
interdisciplinary domains. We discuss the technical barriers and explore
ethical considerations, offering a forward-looking perspective on the future of
EmAI in healthcare. A hierarchical framework of intelligent levels for EmAI
systems is also introduced to guide further development. By providing
systematic insights, this work aims to inspire innovation and practical
applications, paving the way for a new era of intelligent, patient-centered
healthcare.

摘要：<paragraph>全球醫療保健系統在效率、可及性和個人化方面持續面臨挑戰。體現式 AI (EmAI) 由多模態大型語言模型和世界模型等現代 AI 技術提供支持，代表了一個轉型前沿，提供增強的自主性，以及與物理世界互動以應對這些挑戰的能力。作為一個跨學科且快速發展的研究領域，「醫療保健中的 EmAI」涵蓋了演算法、機器人和生物醫學等多元領域。這種複雜性突顯了及時審查和分析的重要性，以追蹤進展、應對挑戰並促進跨學科合作。在本文中，我們提供了 EmAI 在醫療保健中的「大腦」的全面概述，我們在其中介紹了感知、執行、規劃和記憶的基本 AI 演算法，並專注於呈現涵蓋臨床干預、日常照護和陪伴、基礎設施支援和生物醫學研究的醫療保健應用。儘管前景看好，但 EmAI 在醫療保健中的發展受到關鍵挑戰的阻礙，例如安全問題、模擬平台和實際應用之間的差距、缺乏標準化基準，以及跨學科領域進展不均。我們討論了技術障礙並探討了道德考量，對 EmAI 在醫療保健中的未來提供了前瞻性的觀點。還引入了 EmAI 系統的智慧層級架構，以指導進一步的發展。透過提供系統性的見解，這項工作旨在激發創新和實用應用，為智慧且以患者為中心的醫療保健新時代鋪路。</paragraph>

##### **Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**
2501.07430v1 by Xiyue Zhu, Dou Hoon Kwark, Ruike Zhu, Kaiwen Hong, Yiqi Tao, Shirui Luo, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko

Despite success in volume-to-volume translations in medical images, most
existing models struggle to effectively capture the inherent volumetric
distribution using 3D representations. The current state-of-the-art approach
combines multiple 2D-based networks through weighted averaging, thereby
neglecting the 3D spatial structures. Directly training 3D models in medical
imaging presents significant challenges due to high computational demands and
the need for large-scale datasets. To address these challenges, we introduce
Diff-Ensembler, a novel hybrid 2D-3D model for efficient and effective
volumetric translations by ensembling perpendicularly trained 2D diffusion
models with a 3D network in each diffusion step. Moreover, our model can
naturally be used to ensemble diffusion models conditioned on different
modalities, allowing flexible and accurate fusion of input conditions.
Extensive experiments demonstrate that Diff-Ensembler attains superior accuracy
and volumetric realism in 3D medical image super-resolution and modality
translation. We further demonstrate the strength of our model's volumetric
realism using tumor segmentation as a downstream task.

摘要：儘管在醫學影像中體積到體積的翻譯取得成功，但現有的模型大多難以有效地使用 3D 呈現來擷取固有的體積分佈。目前最先進的方法是透過加權平均來結合多個基於 2D 的網路，因此忽略了 3D 空間結構。在醫學影像中直接訓練 3D 模型會產生顯著的挑戰，原因在於高運算需求和大規模資料集的需求。為了應對這些挑戰，我們引入了 Diff-Ensembler，這是一個新穎的混合 2D-3D 模型，可透過在每個擴散步驟中將垂直訓練的 2D 擴散模型與 3D 網路結合，來有效率且有效地進行體積轉換。此外，我們的模型可以自然地用於結合基於不同形式的擴散模型，從而靈活且準確地融合輸入條件。廣泛的實驗證明，Diff-Ensembler 在 3D 醫學影像超解析度和形式轉換中達到了更高的準確度和體積真實感。我們進一步使用腫瘤分割作為下游任務，來證明我們模型的體積真實感。

##### **Natural Language-Assisted Multi-modal Medication Recommendation**
2501.07166v1 by Jie Tan, Yu Rong, Kangfei Zhao, Tian Bian, Tingyang Xu, Junzhou Huang, Hong Cheng, Helen Meng

Combinatorial medication recommendation(CMR) is a fundamental task of
healthcare, which offers opportunities for clinical physicians to provide more
precise prescriptions for patients with intricate health conditions,
particularly in the scenarios of long-term medical care. Previous research
efforts have sought to extract meaningful information from electronic health
records (EHRs) to facilitate combinatorial medication recommendations. Existing
learning-based approaches further consider the chemical structures of
medications, but ignore the textual medication descriptions in which the
functionalities are clearly described. Furthermore, the textual knowledge
derived from the EHRs of patients remains largely underutilized. To address
these issues, we introduce the Natural Language-Assisted Multi-modal Medication
Recommendation(NLA-MMR), a multi-modal alignment framework designed to learn
knowledge from the patient view and medication view jointly. Specifically,
NLA-MMR formulates CMR as an alignment problem from patient and medication
modalities. In this vein, we employ pretrained language models(PLMs) to extract
in-domain knowledge regarding patients and medications, serving as the
foundational representation for both modalities. In the medication modality, we
exploit both chemical structures and textual descriptions to create medication
representations. In the patient modality, we generate the patient
representations based on textual descriptions of diagnosis, procedure, and
symptom. Extensive experiments conducted on three publicly accessible datasets
demonstrate that NLA-MMR achieves new state-of-the-art performance, with a
notable average improvement of 4.72% in Jaccard score. Our source code is
publicly available on https://github.com/jtan1102/NLA-MMR_CIKM_2024.

摘要：組合式藥物推薦 (CMR) 是醫療保健的一項基本任務，它為臨床醫生提供了針對具有複雜健康狀況的患者提供更精確處方的機會，特別是在長期醫療保健的情況下。先前的研究工作試圖從電子健康記錄 (EHR) 中提取有意義的資訊，以促進組合式藥物推薦。現有的基於學習的方法進一步考慮了藥物的化學結構，但忽略了功能清楚描述於其中的文本藥物說明。此外，從患者的 EHR 中衍生的文本知識在很大程度上仍未得到充分利用。為了解決這些問題，我們引入了自然語言輔助多模式藥物推薦 (NLA-MMR)，這是一個多模式對齊框架，旨在從患者視角和藥物視角共同學習知識。具體來說，NLA-MMR 將 CMR 構建為患者和藥物模式的對齊問題。在此脈絡中，我們採用預訓練語言模型 (PLM) 來提取有關患者和藥物的領域內知識，作為這兩種模式的基本表示。在藥物模式中，我們利用化學結構和文本說明來建立藥物表示。在患者模式中，我們根據診斷、程序和症狀的文字說明來生成患者表示。在三個公開存取的資料集上進行的廣泛實驗表明，NLA-MMR 達到了新的最先進效能，傑卡德指數平均改進了 4.72%。我們的原始碼公開於 https://github.com/jtan1102/NLA-MMR_CIKM_2024。

##### **CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**
2501.07157v1 by Jinlin Li, Xiao Zhou

The early detection and prediction of health status decline among the elderly
at the neighborhood level are of great significance for urban planning and
public health policymaking. While existing studies affirm the connection
between living environments and health outcomes, most rely on single data
modalities or simplistic feature concatenation of multi-modal information,
limiting their ability to comprehensively profile the health-oriented urban
environments. To fill this gap, we propose CureGraph, a contrastive multi-modal
representation learning framework for urban health prediction that employs
graph-based techniques to infer the prevalence of common chronic diseases among
the elderly within the urban living circles of each neighborhood. CureGraph
leverages rich multi-modal information, including photos and textual reviews of
residential areas and their surrounding points of interest, to generate urban
neighborhood embeddings. By integrating pre-trained visual and textual encoders
with graph modeling techniques, CureGraph captures cross-modal spatial
dependencies, offering a comprehensive understanding of urban environments
tailored to elderly health considerations. Extensive experiments on real-world
datasets demonstrate that CureGraph improves the best baseline by $28\%$ on
average in terms of $R^2$ across elderly disease risk prediction tasks.
Moreover, the model enables the identification of stage-wise chronic disease
progression and supports comparative public health analysis across
neighborhoods, offering actionable insights for sustainable urban development
and enhanced quality of life. The code is publicly available at
https://github.com/jinlin2021/CureGraph.

摘要：在鄰里層級早期偵測和預測老年人的健康狀況下降對城市規劃和公共衛生政策制定具有重大意義。儘管現有研究肯定了生活環境與健康結果之間的關聯性，但大多依賴單一資料模式或多模式資訊的簡化特徵串接，限制了他們全面描繪以健康為導向的城市環境的能力。為了填補這個差距，我們提出了 CureGraph，一個用於城市健康預測的對比式多模式表示學習架構，它採用基於圖形技術來推論每個鄰里城市生活圈中老年人常見慢性疾病的流行率。CureGraph 利用豐富的多模式資訊，包括住宅區及其周圍景點的照片和文字評論，來產生城市鄰里嵌入。透過整合預先訓練的視覺和文字編碼器與圖形建模技術，CureGraph 捕捉跨模式空間依賴性，提供對城市環境的全面理解，專門針對老年人的健康考量。在真實世界資料集上的廣泛實驗證明，CureGraph 在老年人疾病風險預測任務中，平均在 R2 方面將最佳基準線提高了 28%。此外，該模型能夠識別階段性的慢性疾病進程，並支援跨鄰里的比較公共衛生分析，為永續的城市發展和提升生活品質提供可行的見解。程式碼已公開於 https://github.com/jinlin2021/CureGraph。

##### **UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**
2501.07017v1 by Xuhui Guo, Tanmoy Dam, Rohan Dhamdhere, Gourav Modanwal, Anant Madabhushi

3D medical image segmentation has progressed considerably due to
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), yet these
methods struggle to balance long-range dependency acquisition with
computational efficiency. To address this challenge, we propose UNETVL (U-Net
Vision-LSTM), a novel architecture that leverages recent advancements in
temporal information processing. UNETVL incorporates Vision-LSTM (ViL) for
improved scalability and memory functions, alongside an efficient Chebyshev
Kolmogorov-Arnold Networks (KAN) to handle complex and long-range dependency
patterns more effectively. We validated our method on the ACDC and AMOS2022
(post challenge Task 2) benchmark datasets, showing a significant improvement
in mean Dice score compared to recent state-of-the-art approaches, especially
over its predecessor, UNETR, with increases of 7.3% on ACDC and 15.6% on AMOS,
respectively. Extensive ablation studies were conducted to demonstrate the
impact of each component in UNETVL, providing a comprehensive understanding of
its architecture. Our code is available at https://github.com/tgrex6/UNETVL,
facilitating further research and applications in this domain.

摘要：3D 醫學影像分割已因卷積神經網路 (CNN) 和視覺轉換器 (ViT) 而大幅進展，但這些方法難以在遠程依賴取得與運算效率之間取得平衡。為了解決此挑戰，我們提出 UNETVL (U-Net Vision-LSTM)，一種利用時間資訊處理最新進展的新穎架構。UNETVL 結合視覺 LSTM (ViL) 以改善可擴充性和記憶體功能，並結合高效的 Chebyshev Kolmogorov-Arnold 網路 (KAN) 以更有效地處理複雜且遠程的依賴模式。我們在 ACDC 和 AMOS2022（挑戰任務 2）基準資料集上驗證了我們的方法，與最近最先進的方法相比，顯示平均 Dice 分數有顯著改善，特別是與其前身 UNETR 相比，在 ACDC 上增加了 7.3%，在 AMOS 上增加了 15.6%。進行了廣泛的消融研究，以展示 UNETVL 中每個組成的影響，提供對其架構的全面理解。我們的程式碼可在 https://github.com/tgrex6/UNETVL 取得，促進此領域的進一步研究和應用。

##### **Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**
2501.06980v1 by Karine Karine, Benjamin M. Marlin

Reinforcement learning (RL) is increasingly being used in the healthcare
domain, particularly for the development of personalized health adaptive
interventions. Inspired by the success of Large Language Models (LLMs), we are
interested in using LLMs to update the RL policy in real time, with the goal of
accelerating personalization. We use the text-based user preference to
influence the action selection on the fly, in order to immediately incorporate
the user preference. We use the term "user preference" as a broad term to refer
to a user personal preference, constraint, health status, or a statement
expressing like or dislike, etc. Our novel approach is a hybrid method that
combines the LLM response and the RL action selection to improve the RL policy.
Given an LLM prompt that incorporates the user preference, the LLM acts as a
filter in the typical RL action selection. We investigate different prompting
strategies and action selection strategies. To evaluate our approach, we
implement a simulation environment that generates the text-based user
preferences and models the constraints that impact behavioral dynamics. We show
that our approach is able to take into account the text-based user preferences,
while improving the RL policy, thus improving personalization in adaptive
intervention.

摘要：強化學習（RL）在醫療領域的應用日益廣泛，特別是用於開發個人化健康適應性干預措施。受到大型語言模型（LLM）成功的啟發，我們有興趣使用 LLM 即時更新 RL 政策，目標是加速個人化。我們使用基於文字的使用者偏好來影響行動選擇，以便立即納入使用者偏好。我們使用「使用者偏好」一詞作為廣義詞，用來指使用者的個人偏好、限制、健康狀況或表達好惡的陳述等。我們的新穎方法是一種混合方法，結合了 LLM 回應和 RL 行動選擇以改善 RL 政策。給定包含使用者偏好的 LLM 提示，LLM 在典型的 RL 行動選擇中充當過濾器。我們研究了不同的提示策略和行動選擇策略。為了評估我們的做法，我們實作了一個模擬環境，用於產生基於文字的使用者偏好，並對影響行為動態的限制進行建模。我們展示了我們的做法能夠考量基於文字的使用者偏好，同時改善 RL 政策，從而改善適應性干預中的個人化。

##### **Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**
2501.06964v1 by Xinyao Ma, Rui Zhu, Zihao Wang, Jingwei Xiong, Qingyu Chen, Haixu Tang, L. Jean Camp, Lucila Ohno-Machado

Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing scenarios, particularly in simulating domain-specific experts
using tailored prompts. This ability enables LLMs to adopt the persona of
individuals with specific backgrounds, offering a cost-effective and efficient
alternative to traditional, resource-intensive user studies. By mimicking human
behavior, LLMs can anticipate responses based on concrete demographic or
professional profiles. In this paper, we evaluate the effectiveness of LLMs in
simulating individuals with diverse backgrounds and analyze the consistency of
these simulated behaviors compared to real-world outcomes. In particular, we
explore the potential of LLMs to interpret and respond to discharge summaries
provided to patients leaving the Intensive Care Unit (ICU). We evaluate and
compare with human responses the comprehensibility of discharge summaries among
individuals with varying educational backgrounds, using this analysis to assess
the strengths and limitations of LLM-driven simulations. Notably, when LLMs are
primed with educational background information, they deliver accurate and
actionable medical guidance 88% of the time. However, when other information is
provided, performance significantly drops, falling below random chance levels.
This preliminary study shows the potential benefits and pitfalls of
automatically generating patient-specific health information from diverse
populations. While LLMs show promise in simulating health personas, our results
highlight critical gaps that must be addressed before they can be reliably used
in clinical settings. Our findings suggest that a straightforward
query-response model could outperform a more tailored approach in delivering
health information. This is a crucial first step in understanding how LLMs can
be optimized for personalized health communication while maintaining accuracy.

摘要：大型語言模型（LLM）在角色扮演場景中展現了令人印象深刻的能力，特別是在模擬特定領域的專家時，會使用量身打造的提示。這種能力使 LLM 能夠採用具有特定背景的個人角色，提供一種經濟實惠且有效率的替代方案，用於傳統且資源密集的使用者研究。透過模擬人類行為，LLM 能夠根據具體的人口統計或專業特徵預測反應。在本文中，我們評估了 LLM 在模擬具有不同背景的個人方面的有效性，並分析了這些模擬行為與實際結果相比的一致性。特別是，我們探討了 LLM 解釋和回應提供給離開加護病房 (ICU) 患者的出院摘要的潛力。我們評估並與人類的反應比較了不同教育背景的個人對出院摘要的可理解性，並使用此分析來評估 LLM 驅動模擬的優點和限制。值得注意的是，當 LLM 被植入教育背景資訊時，他們在 88% 的時間內都能提供準確且可行的醫療指導。但是，當提供其他資訊時，效能會顯著下降，低於隨機機會的等級。這項初步研究顯示了自動產生來自不同群體的特定於患者的健康資訊的潛在好處和缺點。儘管 LLM 在模擬健康角色方面顯示出前景，但我們的結果突出了在臨床環境中可靠使用之前必須解決的關鍵差距。我們的研究結果表明，在提供健康資訊方面，一個直接的查詢回應模型可以優於一個更量身打造的方法。這是了解如何針對個人化健康溝通優化 LLM 同時維持準確性的第一步。

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

摘要：随着深度学习模型在医学数据中获得关注，确保透明且值得信赖的决策至关重要。在皮肤癌诊断中，虽然病灶检测和分类的进步提高了准确性，但这些方法的黑盒性质对理解其决策过程构成了挑战，导致医生之间的信任问题。本研究利用在不同皮肤病变数据集上训练的 CLIP（对比语言图像预训练）模型，以捕捉视觉特征和诊断标准术语之间的有意义关系。为了进一步提高透明度，我们提出了一种名为 MedGrad E-CLIP 的方法，该方法通过结合专为皮肤病变等复杂医学影像设计的加权熵机制，建立在基于梯度的 E-CLIP 之上。此方法突出了与特定诊断描述相关联的关键图像区域。开发的集成管道不仅通过匹配相应的描述对皮肤病变进行分类，还添加了一层专门为医学数据开发的基本可解释性。通过直观地解释图像中不同特征与诊断标准的关系，这种方法展示了高级视觉语言模型在医学图像分析中的潜力，最终提高了透明度、稳健性和对人工智能驱动的诊断系统的信任。

##### **A Foundational Generative Model for Breast Ultrasound Image Analysis**
2501.06869v1 by Haojun Yu, Youcheng Li, Nan Zhang, Zihan Niu, Xuantong Gong, Yanwen Luo, Haotian Ye, Siyu He, Quanlin Wu, Wangyan Qin, Mengyuan Zhou, Jie Han, Jia Tao, Ziwei Zhao, Di Dai, Di He, Dong Wang, Binghui Tang, Ling Huo, James Zou, Qingli Zhu, Yong Wang, Liwei Wang

Foundational models have emerged as powerful tools for addressing various
tasks in clinical settings. However, their potential development to breast
ultrasound analysis remains untapped. In this paper, we present BUSGen, the
first foundational generative model specifically designed for breast ultrasound
image analysis. Pretrained on over 3.5 million breast ultrasound images, BUSGen
has acquired extensive knowledge of breast structures, pathological features,
and clinical variations. With few-shot adaptation, BUSGen can generate
repositories of realistic and informative task-specific data, facilitating the
development of models for a wide range of downstream tasks. Extensive
experiments highlight BUSGen's exceptional adaptability, significantly
exceeding real-data-trained foundational models in breast cancer screening,
diagnosis, and prognosis. In breast cancer early diagnosis, our approach
outperformed all board-certified radiologists (n=9), achieving an average
sensitivity improvement of 16.5% (P-value<0.0001). Additionally, we
characterized the scaling effect of using generated data which was as effective
as the collected real-world data for training diagnostic models. Moreover,
extensive experiments demonstrated that our approach improved the
generalization ability of downstream models. Importantly, BUSGen protected
patient privacy by enabling fully de-identified data sharing, making progress
forward in secure medical data utilization. An online demo of BUSGen is
available at https://aibus.bio.

摘要：基礎模型已成為解決臨床環境中各種任務的強大工具。然而，它們在乳房超音波分析的潛在發展仍未開發。在本文中，我們提出 BUSGen，這是第一個專門設計用於乳房超音波影像分析的基礎生成模型。BUSGen 在超過 350 萬張乳房超音波影像上進行預訓練，已獲得乳房結構、病理特徵和臨床變異的廣泛知識。透過少量適應，BUSGen 可以產生逼真且具有資訊性的特定任務資料儲存庫，促進開發廣泛的下游任務模型。廣泛的實驗突顯了 BUSGen 的出色適應性，在乳癌篩檢、診斷和預後方面顯著超越以真實資料訓練的基礎模型。在乳癌早期診斷中，我們的做法優於所有通過認證的放射科醫師 (n=9)，平均敏感度提高了 16.5%（P 值 <0.0001）。此外，我們描述了使用生成資料的規模效應，其與收集的真實世界資料一樣有效，可用於訓練診斷模型。此外，廣泛的實驗證明，我們的做法改善了下游模型的泛化能力。重要的是，BUSGen 保護了患者隱私，因為它能夠完全去識別資料共享，在安全醫療資料利用方面取得進展。BUSGen 的線上示範可在 https://aibus.bio 取得。

##### **A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**
2501.06859v1 by Noureldin Zahran, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda

Mental health disorders pose a growing public health concern in the Arab
world, emphasizing the need for accessible diagnostic and intervention tools.
Large language models (LLMs) offer a promising approach, but their application
in Arabic contexts faces challenges including limited labeled datasets,
linguistic complexity, and translation biases. This study comprehensively
evaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual
ones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA),
investigating the impact of prompt design, language configuration (native
Arabic vs. translated English, and vice versa), and few-shot prompting on
diagnostic performance. We find that prompt engineering significantly
influences LLM scores mainly due to reduced instruction following, with our
structured prompt outperforming a less structured variant on multi-class
datasets, with an average difference of 14.5\%. While language influence on
performance was modest, model selection proved crucial: Phi-3.5 MoE excelled in
balanced accuracy, particularly for binary classification, while Mistral NeMo
showed superior performance in mean absolute error for severity prediction
tasks. Few-shot prompting consistently improved performance, with particularly
substantial gains observed for GPT-4o Mini on multi-class classification,
boosting accuracy by an average factor of 1.58. These findings underscore the
importance of prompt optimization, multilingual analysis, and few-shot learning
for developing culturally sensitive and effective LLM-based mental health tools
for Arabic-speaking populations.

摘要：<paragraph>心理健康障礙在阿拉伯世界中構成日益嚴重的公共衛生問題，強調了對可及的診斷和干預工具的需求。大型語言模型 (LLM) 提供了一種有前途的方法，但它們在阿拉伯語環境中的應用面臨著挑戰，包括標記資料集有限、語言複雜性和翻譯偏差。本研究全面評估了 8 個 LLM，包括一般多語言模型和雙語模型，在不同的心理健康資料集（例如 AraDepSu、Dreaddit、MedMCQA）上，探討提示設計、語言配置（阿拉伯語原文與翻譯後的英語，反之亦然）和少次提示對診斷表現的影響。我們發現提示工程顯著影響 LLM 分數，主要是由於減少了說明遵循，我們的結構化提示在多類資料集上優於結構較不嚴謹的變體，平均差異為 14.5%。雖然語言對表現的影響不大，但模型選擇被證明至關重要：Phi-3.5 MoE 在平衡準確度方面表現出色，特別是在二元分類方面，而 Mistral NeMo 在嚴重性預測任務的平均絕對誤差方面表現出優異的表現。少次提示始終改善表現，特別是在 GPT-4o Mini 上觀察到多類分類的顯著增益，將準確度提高了平均 1.58 倍。這些發現強調了提示最佳化、多語言分析和少次學習對於開發適合文化且有效的基於 LLM 的心理健康工具以服務阿拉伯語人口的重要性。</paragraph>

##### **MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**
2501.06823v1 by Yiqing Zhang, Xiaozhong Liu, Fabricio Murai

Clinical trials are the gold standard for assessing the effectiveness and
safety of drugs for treating diseases. Given the vast design space of drug
molecules, elevated financial cost, and multi-year timeline of these trials,
research on clinical trial outcome prediction has gained immense traction.
Accurate predictions must leverage data of diverse modes such as drug
molecules, target diseases, and eligibility criteria to infer successes and
failures. Previous Deep Learning approaches for this task, such as HINT, often
require wet lab data from synthesized molecules and/or rely on prior knowledge
to encode interactions as part of the model architecture. To address these
limitations, we propose a light-weight attention-based model, MEXA-CTP, to
integrate readily-available multi-modal data and generate effective
representations via specialized modules dubbed "mode experts", while avoiding
human biases in model design. We optimize MEXA-CTP with the Cauchy loss to
capture relevant interactions across modes. Our experiments on the Trial
Outcome Prediction (TOP) benchmark demonstrate that MEXA-CTP improves upon
existing approaches by, respectively, up to 11.3% in F1 score, 12.2% in PR-AUC,
and 2.5% in ROC-AUC, compared to HINT. Ablation studies are provided to
quantify the effectiveness of each component in our proposed method.

摘要：臨床試驗是評估治療疾病的藥物有效性和安全性的黃金標準。鑑於藥物分子的廣泛設計空間、高昂的財務成本和這些試驗多年的時間表，臨床試驗結果預測的研究獲得了巨大的關注。準確的預測必須利用藥物分子、目標疾病和符合資格標準等多種模式的數據來推斷成功和失敗。此任務的先前深度學習方法（例如 HINT）通常需要合成分子的濕實驗室數據和/或依賴於先驗知識將交互編碼為模型架構的一部分。為了解決這些限制，我們提出了一個輕量級的基於注意力的模型 MEXA-CTP，以整合現成的多模式數據並通過稱為「模式專家」的專用模組產生有效的表示，同時避免模型設計中的人為偏差。我們使用柯西損失函數最佳化 MEXA-CTP，以捕捉跨模式相關的交互。我們在試驗結果預測 (TOP) 基準上的實驗表明，與 HINT 相比，MEXA-CTP 分別在 F1 分數上提高了 11.3%、PR-AUC 上提高了 12.2%、ROC-AUC 上提高了 2.5%。提供了消融研究來量化我們提出的方法中每個組件的有效性。

##### **PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation**
2501.06692v1 by Zhonghao Yan, Zijin Yin, Tianyu Lin, Xiangzhu Zeng, Kongming Liang, Zhanyu Ma

The Segment Anything Model (SAM) has demonstrated strong and versatile
segmentation capabilities, along with intuitive prompt-based interactions.
However, customizing SAM for medical image segmentation requires massive
amounts of pixel-level annotations and precise point- or box-based prompt
designs. To address these challenges, we introduce PGP-SAM, a novel
prototype-based few-shot tuning approach that uses limited samples to replace
tedious manual prompts. Our key idea is to leverage inter- and intra-class
prototypes to capture class-specific knowledge and relationships. We propose
two main components: (1) a plug-and-play contextual modulation module that
integrates multi-scale information, and (2) a class-guided cross-attention
mechanism that fuses prototypes and features for automatic prompt generation.
Experiments on a public multi-organ dataset and a private ventricle dataset
demonstrate that PGP-SAM achieves superior mean Dice scores compared with
existing prompt-free SAM variants, while using only 10\% of the 2D slices.

摘要：分段任何模型 (SAM) 已展示出强大且多功能的分段能力，以及直观的基于提示的交互。
然而，针对医学影像分段定制 SAM 需要大量像素级注释和精确的基于点或框的提示设计。为了应对这些挑战，我们引入了 PGP-SAM，一种新颖的基于原型的少量镜头微调方法，它使用有限的样本来替换繁琐的手动提示。我们的关键思想是利用类间和类内原型来捕捉特定于类的知识和关系。我们提出了两个主要组件：(1) 一个即插即用的上下文调制模块，它集成了多尺度信息，以及 (2) 一个类指导的交叉注意机制，它融合了原型和特征以进行自动提示生成。在公共多器官数据集和私人心室数据集上的实验表明，PGP-SAM 与现有的无提示 SAM 变体相比实现了卓越的平均 Dice 分数，同时仅使用了 2D 切片的 10%。

##### **Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels**
2501.06678v1 by Erjian Guo, Zicheng Wang, Zhen Zhao, Luping Zhou

Accurate medical image segmentation is often hindered by noisy labels in
training data, due to the challenges of annotating medical images. Prior
research works addressing noisy labels tend to make class-dependent
assumptions, overlooking the pixel-dependent nature of most noisy labels.
Furthermore, existing methods typically apply fixed thresholds to filter out
noisy labels, risking the removal of minority classes and consequently
degrading segmentation performance. To bridge these gaps, our proposed
framework, Collaborative Learning with Curriculum Selection (CLCS), addresses
pixel-dependent noisy labels with class imbalance. CLCS advances the existing
works by i) treating noisy labels as pixel-dependent and addressing them
through a collaborative learning framework, and ii) employing a curriculum
dynamic thresholding approach adapting to model learning progress to select
clean data samples to mitigate the class imbalance issue, and iii) applying a
noise balance loss to noisy data samples to improve data utilization instead of
discarding them outright. Specifically, our CLCS contains two modules:
Curriculum Noisy Label Sample Selection (CNS) and Noise Balance Loss (NBL). In
the CNS module, we designed a two-branch network with discrepancy loss for
collaborative learning so that different feature representations of the same
instance could be extracted from distinct views and used to vote the class
probabilities of pixels. Besides, a curriculum dynamic threshold is adopted to
select clean-label samples through probability voting. In the NBL module,
instead of directly dropping the suspiciously noisy labels, we further adopt a
robust loss to leverage such instances to boost the performance.

摘要：<paragraph>准确的医学影像分割通常会受到训练数据中标签有噪声的阻碍，这是因为对医学影像进行注释具有挑战性。解决标签有噪声的先前研究工作倾向于做出类相关的假设，而忽略了大多数标签有噪声的像素相关性质。此外，现有方法通常应用固定阈值来过滤掉标签有噪声，这有将少数类别的标签移除的风险，从而降低分割性能。为了弥合这些差距，我们提出的框架，即具有课程选择的协作学习 (CLCS)，解决了类别不平衡的像素相关标签有噪声的问题。CLCS 通过以下方式提升了现有工作：i) 将标签有噪声视为像素相关，并通过协作学习框架解决它们，ii) 采用课程动态阈值化方法，适应模型学习进度，选择干净的数据样本以减轻类别不平衡问题，以及 iii) 对标签有噪声的数据样本应用噪声平衡损失，以提高数据利用率，而不是直接丢弃它们。具体而言，我们的 CLCS 包含两个模块：课程标签有噪声样本选择 (CNS) 和噪声平衡损失 (NBL)。在 CNS 模块中，我们设计了一个具有差异损失的两分支网络，用于协作学习，以便可以从不同的视图中提取同一实例的不同特征表示，并用于投票像素的类别概率。此外，采用课程动态阈值通过概率投票选择干净标签样本。在 NBL 模块中，我们没有直接丢弃可疑的标签有噪声，而是进一步采用鲁棒损失来利用此类实例以提升性能。</paragraph>

##### **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**
2501.06465v1 by Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang

We introduce the world's first clinical terminology for the Chinese
healthcare community, namely MedCT, accompanied by a clinical foundation model
MedBERT and an entity linking model MedLink. The MedCT system enables
standardized and programmable representation of Chinese clinical data,
successively stimulating the development of new medicines, treatment pathways,
and better patient outcomes for the populous Chinese community. Moreover, the
MedCT knowledge graph provides a principled mechanism to minimize the
hallucination problem of large language models (LLMs), therefore achieving
significant levels of accuracy and safety in LLM-based clinical applications.
By leveraging the LLMs' emergent capabilities of generativeness and
expressiveness, we were able to rapidly built a production-quality terminology
system and deployed to real-world clinical field within three months, while
classical terminologies like SNOMED CT have gone through more than twenty years
development. Our experiments show that the MedCT system achieves
state-of-the-art (SOTA) performance in semantic matching and entity linking
tasks, not only for Chinese but also for English. We also conducted a
longitudinal field experiment by applying MedCT and LLMs in a representative
spectrum of clinical tasks, including electronic health record (EHR)
auto-generation and medical document search for diagnostic decision making. Our
study shows a multitude of values of MedCT for clinical workflows and patient
outcomes, especially in the new genre of clinical LLM applications. We present
our approach in sufficient engineering detail, such that implementing a
clinical terminology for other non-English societies should be readily
reproducible. We openly release our terminology, models and algorithms, along
with real-world clinical datasets for the development.

摘要：<paragraph>我們為中文醫療社群引進全球首個臨床術語，即 MedCT，並附有臨床基礎模型 MedBERT 和實體連結模型 MedLink。MedCT 系統能標準化並以程式化方式呈現中文臨床資料，進而刺激新藥物、治療途徑的開發，並為人口眾多的華人社群帶來更好的醫療結果。此外，MedCT 知識圖譜提供了一個原則性的機制，用以最小化大型語言模型 (LLM) 的幻覺問題，因此在基於 LLM 的臨床應用中實現了顯著的準確性和安全性。透過利用 LLM 在生成性和表達性方面的顯著能力，我們得以快速建構一個生產品質的術語系統，並在三個月內部署到現實世界的臨床領域，而像 SNOMED CT 等傳統術語已歷經二十多年的發展。我們的實驗顯示，MedCT 系統在語意配對和實體連結任務中達到了最先進 (SOTA) 的效能，不僅適用於中文，也適用於英文。我們還透過在具代表性的臨床任務範圍中應用 MedCT 和 LLM 進行了一項縱向實地實驗，包括電子健康紀錄 (EHR) 自動生成和用於診斷決策的醫療文件搜尋。我們的研究顯示 MedCT 對臨床工作流程和患者結果具有多重價值，特別是在新類型的臨床 LLM 應用中。我們以充分的工程細節呈現我們的做法，因此實作其他非英語社會的臨床術語應易於複製。我們開放發布我們的術語、模型和演算法，以及用於開發的現實世界臨床資料集。</paragraph>

##### **Deep Learning on Hester Davis Scores for Inpatient Fall Prediction**
2501.06432v1 by Hojjat Salehinejad, Ricky Rojas, Kingsley Iheasirim, Mohammed Yousufuddin, Bijan Borah

Fall risk prediction among hospitalized patients is a critical aspect of
patient safety in clinical settings, and accurate models can help prevent
adverse events. The Hester Davis Score (HDS) is commonly used to assess fall
risk, with current clinical practice relying on a threshold-based approach. In
this method, a patient is classified as high-risk when their HDS exceeds a
predefined threshold. However, this approach may fail to capture dynamic
patterns in fall risk over time. In this study, we model the threshold-based
approach and propose two machine learning approaches for enhanced fall
prediction: One-step ahead fall prediction and sequence-to-point fall
prediction. The one-step ahead model uses the HDS at the current timestamp to
predict the risk at the next timestamp, while the sequence-to-point model
leverages all preceding HDS values to predict fall risk using deep learning. We
compare these approaches to assess their accuracy in fall risk prediction,
demonstrating that deep learning can outperform the traditional threshold-based
method by capturing temporal patterns and improving prediction reliability.
These findings highlight the potential for data-driven approaches to enhance
patient safety through more reliable fall prevention strategies.

摘要：住院患者的跌倒風險預測是臨床環境中患者安全的重要面向，精確的模型有助於預防不良事件。Hester Davis 評分 (HDS) 常用於評估跌倒風險，目前的臨床實務依賴於基於閾值的評估方式。在此方法中，當患者的 HDS 超過預先定義的閾值時，會將其歸類為高風險。然而，此方法可能無法捕捉隨著時間推移而產生的動態跌倒風險模式。在本研究中，我們對基於閾值的評估方式進行建模，並提出兩種機器學習評估方式以加強跌倒預測：單步前瞻跌倒預測和序列對點跌倒預測。單步前瞻模型使用當前時間戳記的 HDS 預測下一個時間戳記的風險，而序列對點模型則利用所有前一個 HDS 值使用深度學習來預測跌倒風險。我們比較這些評估方式以評估其在跌倒風險預測中的準確性，證明深度學習可以透過捕捉時間模式和提升預測可靠性，優於傳統的基於閾值的評估方式。這些發現強調了資料驅動評估方式在透過更可靠的跌倒預防策略來加強患者安全方面的潛力。

##### **Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts**
2501.06365v1 by Elizabeth Schaefer, Kirk Roberts

This paper presents a pipeline for mitigating gender bias in large language
models (LLMs) used in medical literature by neutralizing gendered occupational
pronouns. A dataset of 379,000 PubMed abstracts from 1965-1980 was processed to
identify and modify pronouns tied to professions. We developed a BERT-based
model, ``Modern Occupational Bias Elimination with Refined Training,'' or
``MOBERT,'' trained on these neutralized abstracts, and compared its
performance with ``1965Bert,'' trained on the original dataset. MOBERT achieved
a 70\% inclusive replacement rate, while 1965Bert reached only 4\%. A further
analysis of MOBERT revealed that pronoun replacement accuracy correlated with
the frequency of occupational terms in the training data. We propose expanding
the dataset and refining the pipeline to improve performance and ensure more
equitable language modeling in medical applications.

摘要：本文提出了一個管道，用於緩解大型語言模型 (LLM) 中的性別偏見，這些模型透過中和性別職業代名詞，用於醫學文獻中。我們處理了 1965 年至 1980 年間 379,000 篇 PubMed 文摘的資料集，以識別和修改與職業相關的代名詞。我們開發了一個 BERT-based 模型，稱為「採用精緻訓練的現代職業偏見消除」或「MOBERT」，並在這些中和的文摘上進行訓練，並將其效能與在原始資料集上訓練的「1965Bert」進行比較。MOBERT 達到了 70% 的包容性替換率，而 1965Bert 僅達到 4%。進一步分析 MOBERT 顯示，代名詞替換的準確性與訓練資料中職業術語的頻率相關。我們建議擴充資料集並精緻化管道，以提升效能並確保在醫學應用中進行更公平的語言建模。

##### **Scale-up Unlearnable Examples Learning with High-Performance Computing**
2501.06080v1 by Yanfan Zhu, Issac Lyngaas, Murali Gopalakrishnan Meena, Mary Ellen I. Koran, Bradley Malin, Daniel Moyer, Shunxing Bao, Anuj Kapadia, Xiao Wang, Bennett Landman, Yuankai Huo

Recent advancements in AI models are structured to retain user interactions,
which could inadvertently include sensitive healthcare data. In the healthcare
field, particularly when radiologists use AI-driven diagnostic tools hosted on
online platforms, there is a risk that medical imaging data may be repurposed
for future AI training without explicit consent, spotlighting critical privacy
and intellectual property concerns around healthcare data usage. Addressing
these privacy challenges, a novel approach known as Unlearnable Examples (UEs)
has been introduced, aiming to make data unlearnable to deep learning models. A
prominent method within this area, called Unlearnable Clustering (UC), has
shown improved UE performance with larger batch sizes but was previously
limited by computational resources. To push the boundaries of UE performance
with theoretically unlimited resources, we scaled up UC learning across various
datasets using Distributed Data Parallel (DDP) training on the Summit
supercomputer. Our goal was to examine UE efficacy at high-performance
computing (HPC) levels to prevent unauthorized learning and enhance data
security, particularly exploring the impact of batch size on UE's
unlearnability. Utilizing the robust computational capabilities of the Summit,
extensive experiments were conducted on diverse datasets such as Pets,
MedMNist, Flowers, and Flowers102. Our findings reveal that both overly large
and overly small batch sizes can lead to performance instability and affect
accuracy. However, the relationship between batch size and unlearnability
varied across datasets, highlighting the necessity for tailored batch size
strategies to achieve optimal data protection. Our results underscore the
critical role of selecting appropriate batch sizes based on the specific
characteristics of each dataset to prevent learning and ensure data security in
deep learning applications.

摘要：<paragraph>最近在 AI 模型中的進展被建構為保留使用者互動，
這可能無意間包含敏感的醫療保健資料。在醫療保健
領域，特別是當放射科醫師使用線上平台上提供的 AI 驅動診斷工具時，有風險是醫療影像資料可能會被重新用於未來的 AI 訓練，而未經明確同意，這突顯了與醫療保健資料使用相關的隱私和智慧財產權問題。為了應對
這些隱私挑戰，已導入一種稱為不可學習範例 (UE) 的新方法，旨在讓資料對深度學習模型不可學習。這個領域內一種著名的稱為不可學習聚類 (UC) 的方法，已顯示出在較大的批次大小下有改善的 UE 效能，但先前受到運算資源的限制。為了在理論上無限制資源的情況下推動 UE 效能的界線，我們在 Summit 超級電腦上使用分散式資料平行 (DDP) 訓練，擴大了各種資料集的 UC 學習。我們的目標是檢查 UE 在高效能運算 (HPC) 層級的效能，以防止未經授權的學習，並增強資料安全性，特別是探討批次大小對 UE 不可學習性的影響。利用 Summit 強大的運算能力，在各種資料集上進行了廣泛的實驗，例如 Pets、MedMNist、Flowers 和 Flowers102。我們的研究結果顯示，過大或過小的批次大小都可能導致效能不穩定，並影響準確度。然而，批次大小與不可學習性之間的關係在各個資料集之間有所不同，這突顯了根據特定資料集的特徵量身打造批次大小策略以達成最佳資料保護的必要性。我們的結果強調了根據每個資料集的特定特徵選擇適當批次大小以防止學習，並確保深度學習應用程式中資料安全性的關鍵作用。</paragraph>

##### **AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**
2501.06039v1 by Johann Wenckstern, Eeshaan Jain, Kiril Vasilev, Matteo Pariset, Andreas Wicki, Gabriele Gut, Charlotte Bunne

Spatial proteomics technologies have transformed our understanding of complex
tissue architectures by enabling simultaneous analysis of multiple molecular
markers and their spatial organization. The high dimensionality of these data,
varying marker combinations across experiments and heterogeneous study designs
pose unique challenges for computational analysis. Here, we present Virtual
Tissues (VirTues), a foundation model framework for biological tissues that
operates across the molecular, cellular and tissue scale. VirTues introduces
innovations in transformer architecture design, including a novel tokenization
scheme that captures both spatial and marker dimensions, and attention
mechanisms that scale to high-dimensional multiplex data while maintaining
interpretability. Trained on diverse cancer and non-cancer tissue datasets,
VirTues demonstrates strong generalization capabilities without task-specific
fine-tuning, enabling cross-study analysis and novel marker integration. As a
generalist model, VirTues outperforms existing approaches across clinical
diagnostics, biological discovery and patient case retrieval tasks, while
providing insights into tissue function and disease mechanisms.

摘要：空間蛋白質組學技術透過同時分析多個分子標記及其空間組織，轉變了我們對複雜組織結構的理解。這些數據的高維度、實驗中不同的標記組合和異質的研究設計，對計算分析構成了獨特的挑戰。在此，我們提出虛擬組織 (VirTues)，一個適用於分子、細胞和組織層級的生物組織基礎模型架構。VirTues 在Transformer架構設計中引進創新，包括一種新的標記化架構，它捕捉空間和標記維度，以及在維持可解釋性的同時擴展到高維度多重數據的注意力機制。VirTues 在多樣化的癌症和非癌症組織數據集上訓練，展示了強大的泛化能力，無需特定任務微調，從而實現跨研究分析和新的標記整合。作為一個通才模型，VirTues 在臨床診斷、生物發現和患者病例檢索任務中優於現有方法，同時提供了組織功能和疾病機制的見解。

##### **DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**
2501.05932v1 by Yongfan Lai, Jiabo Chen, Deyun Zhang, Yue Wang, Shijia Geng, Hongyan Li, Shenda Hong

Heart disease remains a significant threat to human health. As a non-invasive
diagnostic tool, the electrocardiogram (ECG) is one of the most widely used
methods for cardiac screening. However, the scarcity of high-quality ECG data,
driven by privacy concerns and limited medical resources, creates a pressing
need for effective ECG signal generation. Existing approaches for generating
ECG signals typically rely on small training datasets, lack comprehensive
evaluation frameworks, and overlook potential applications beyond data
augmentation. To address these challenges, we propose DiffuSETS, a novel
framework capable of generating ECG signals with high semantic alignment and
fidelity. DiffuSETS accepts various modalities of clinical text reports and
patient-specific information as inputs, enabling the creation of clinically
meaningful ECG signals. Additionally, to address the lack of standardized
evaluation in ECG generation, we introduce a comprehensive benchmarking
methodology to assess the effectiveness of generative models in this domain.
Our model achieve excellent results in tests, proving its superiority in the
task of ECG generation. Furthermore, we showcase its potential to mitigate data
scarcity while exploring novel applications in cardiology education and medical
knowledge discovery, highlighting the broader impact of our work.

摘要：心脏病仍然是人类健康的一大威胁。作为一种非侵入性诊断工具，心电图 (ECG) 是心脏筛查最广泛使用的方法之一。然而，由于隐私问题和医疗资源有限，高质量 ECG 数据的稀缺对有效的 ECG 信号生成提出了迫切需求。现有用于生成 ECG 信号的方法通常依赖于小型训练数据集，缺乏全面的评估框架，并且忽视了数据增强之外的潜在应用。为了应对这些挑战，我们提出了 DiffuSETS，这是一个能够生成具有高度语义对齐和保真度的 ECG 信号的新框架。DiffuSETS 接受各种形式的临床文本报告和患者特定信息作为输入，从而能够创建具有临床意义的 ECG 信号。此外，为了解决 ECG 生成中缺乏标准化评估的问题，我们引入了一种全面的基准测试方法来评估生成模型在此领域的有效性。我们的模型在测试中取得了优异的成果，证明了其在 ECG 生成任务中的优越性。此外，我们展示了其在缓解数据稀缺的同时在心脏病学教育和医学知识发现中探索新应用的潜力，突出了我们工作的更广泛影响。

##### **AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India**
2501.05826v2 by Amit Kr Dey, Pradeep Walia, Girish Somvanshi, Abrar Ali, Sagarnil Das, Pallabi Paul, Minakhi Ghosh

Purpose: Diabetic retinopathy (DR) is a major cause of vision loss,
particularly in India, where access to retina specialists is limited in rural
areas. This study aims to evaluate the Artificial Intelligence-based Diabetic
Retinopathy Screening System (AIDRSS) for DR detection and prevalence
assessment, addressing the growing need for scalable, automated screening
solutions in resource-limited settings.
  Approach: A multicentric, cross-sectional study was conducted in Kolkata,
India, involving 5,029 participants and 10,058 macula-centric retinal fundus
images. The AIDRSS employed a deep learning algorithm with 50 million trainable
parameters, integrated with Contrast Limited Adaptive Histogram Equalization
(CLAHE) preprocessing for enhanced image quality. DR was graded using the
International Clinical Diabetic Retinopathy (ICDR) Scale, categorizing disease
into five stages (DR0 to DR4). Statistical metrics including sensitivity,
specificity, and prevalence rates were evaluated against expert retina
specialist assessments.
  Results: The prevalence of DR in the general population was 13.7%, rising to
38.2% among individuals with elevated random blood glucose levels. The AIDRSS
achieved an overall sensitivity of 92%, specificity of 88%, and 100%
sensitivity for detecting referable DR (DR3 and DR4). These results demonstrate
the system's robust performance in accurately identifying and grading DR in a
diverse population.
  Conclusions: AIDRSS provides a reliable, scalable solution for early DR
detection in resource-constrained environments. Its integration of advanced AI
techniques ensures high diagnostic accuracy, with potential to significantly
reduce the burden of diabetes-related vision loss in underserved regions.

摘要：<paragraph>目的：糖尿病视网膜病变 (DR) 是视力丧失的主要原因，特别是在印度，那里的农村地区眼科专家数量有限。本研究旨在评估基于人工智能的糖尿病视网膜病变筛查系统 (AIDRSS) 的 DR 检测和流行情况评估，以满足资源有限的环境中对可扩展自动化筛查解决方案不断增长的需求。
方法：在印度加尔各答进行了一项多中心横断面研究，涉及 5,029 名参与者和 10,058 张黄斑中心视网膜眼底图像。AIDRSS 采用了一个深度学习算法，具有 5000 万个可训练参数，并集成了对比度限制自适应直方图均衡化 (CLAHE) 预处理，以提高图像质量。DR 使用国际临床糖尿病视网膜病变 (ICDR) 量表进行分级，将疾病分为五个阶段（DR0 至 DR4）。针对专家视网膜专家评估，评估了包括敏感性、特异性和患病率在内的统计指标。
结果：一般人群中 DR 的患病率为 13.7%，在随机血糖水平升高的个体中上升至 38.2%。AIDRSS 的总体敏感性达到 92%，特异性达到 88%，检测可转诊 DR（DR3 和 DR4）的敏感性达到 100%。这些结果表明该系统在准确识别和分级不同人群中的 DR 方面具有强大的性能。
结论：AIDRSS 为资源受限环境中的早期 DR 检测提供了一种可靠且可扩展的解决方案。它集成了先进的人工智能技术，确保了较高的诊断准确性，有可能显著减少服务不足地区与糖尿病相关的视力丧失负担。</paragraph>

##### **Large Language Models for Bioinformatics**
2501.06271v1 by Wei Ruan, Yanjun Lyu, Jing Zhang, Jiazhang Cai, Peng Shu, Yang Ge, Yao Lu, Shang Gao, Yue Wang, Peilong Wang, Lin Zhao, Tao Wang, Yufang Liu, Luyang Fang, Ziyu Liu, Zhengliang Liu, Yiwei Li, Zihao Wu, Junhao Chen, Hanqi Jiang, Yi Pan, Zhenyuan Yang, Jingyuan Chen, Shizhe Liang, Wei Zhang, Terry Ma, Yuan Dou, Jianli Zhang, Xinyu Gong, Qi Gan, Yusong Zou, Zebang Chen, Yuanxin Qian, Shuo Yu, Jin Lu, Kenan Song, Xianqiao Wang, Andrea Sikora, Gang Li, Xiang Li, Quanzheng Li, Yingfeng Wang, Lu Zhang, Yohannes Abate, Lifang He, Wenxuan Zhong, Rongjie Liu, Chao Huang, Wei Liu, Ye Shen, Ping Ma, Hongtu Zhu, Yajun Yan, Dajiang Zhu, Tianming Liu

With the rapid advancements in large language model (LLM) technology and the
emergence of bioinformatics-specific language models (BioLMs), there is a
growing need for a comprehensive analysis of the current landscape,
computational characteristics, and diverse applications. This survey aims to
address this need by providing a thorough review of BioLMs, focusing on their
evolution, classification, and distinguishing features, alongside a detailed
examination of training methodologies, datasets, and evaluation frameworks. We
explore the wide-ranging applications of BioLMs in critical areas such as
disease diagnosis, drug discovery, and vaccine development, highlighting their
impact and transformative potential in bioinformatics. We identify key
challenges and limitations inherent in BioLMs, including data privacy and
security concerns, interpretability issues, biases in training data and model
outputs, and domain adaptation complexities. Finally, we highlight emerging
trends and future directions, offering valuable insights to guide researchers
and clinicians toward advancing BioLMs for increasingly sophisticated
biological and clinical applications.

摘要：隨著大型語言模型（LLM）技術的快速進展和生物資訊學特定語言模型（BioLM）的出現，對於當前情勢、計算特徵和多元應用進行全面分析的需求日益增加。本調查旨在透過提供對 BioLM 的全面檢視，著重於其演進、分類和區別特徵，以及對訓練方法、資料集和評估架構的詳細探討，來滿足此需求。我們探討 BioLM 在疾病診斷、藥物發現和疫苗開發等關鍵領域的廣泛應用，強調其在生物資訊學中的影響和轉型潛力。我們找出 BioLM 固有的關鍵挑戰和限制，包括資料隱私和安全性問題、可解釋性問題、訓練資料和模型輸出的偏差，以及領域適應的複雜性。最後，我們重點介紹新興趨勢和未來方向，提供有價值的見解，以指導研究人員和臨床醫生將 BioLM 應用於日益複雜的生物和臨床應用。

##### **From Simple to Complex Skills: The Case of In-Hand Object Reorientation**
2501.05439v1 by Haozhi Qi, Brent Yi, Mike Lambeta, Yi Ma, Roberto Calandra, Jitendra Malik

Learning policies in simulation and transferring them to the real world has
become a promising approach in dexterous manipulation. However, bridging the
sim-to-real gap for each new task requires substantial human effort, such as
careful reward engineering, hyperparameter tuning, and system identification.
In this work, we present a system that leverages low-level skills to address
these challenges for more complex tasks. Specifically, we introduce a
hierarchical policy for in-hand object reorientation based on previously
acquired rotation skills. This hierarchical policy learns to select which
low-level skill to execute based on feedback from both the environment and the
low-level skill policies themselves. Compared to learning from scratch, the
hierarchical policy is more robust to out-of-distribution changes and transfers
easily from simulation to real-world environments. Additionally, we propose a
generalizable object pose estimator that uses proprioceptive information,
low-level skill predictions, and control errors as inputs to estimate the
object pose over time. We demonstrate that our system can reorient objects,
including symmetrical and textureless ones, to a desired pose.

摘要：在模擬中學習策略並將其轉移到現實世界已成為靈巧操作中一種有前景的方法。然而，對於每項新任務來說，彌合模擬到現實的差距需要大量的人力，例如仔細的獎勵工程、超參數調整和系統識別。在這項工作中，我們提出了一個利用低層技能來應對更複雜任務的挑戰的系統。具體來說，我們引入了一個基於先前獲得的旋轉技能的手中物體重新定向的分層策略。這種分層策略學習根據環境和低層技能策略本身的回饋選擇執行哪種低層技能。與從頭開始學習相比，分層策略對分佈外變化更強健，並且可以輕鬆地從模擬轉移到現實世界環境。此外，我們提出了一個可泛化的物體姿勢估計器，它使用 proprioceptive 信息、低層技能預測和控制誤差作為輸入來估計物體姿勢。我們證明了我們的系統可以將物體（包括對稱和無紋理的物體）重新定向到所需的姿勢。

##### **Strategy Masking: A Method for Guardrails in Value-based Reinforcement Learning Agents**
2501.05501v1 by Jonathan Keane, Sam Keyser, Jeremy Kedziora

The use of reward functions to structure AI learning and decision making is
core to the current reinforcement learning paradigm; however, without careful
design of reward functions, agents can learn to solve problems in ways that may
be considered ``undesirable" or ``unethical. Without thorough understanding of
the incentives a reward function creates, it can be difficult to impose
principled yet general control mechanisms over its behavior. In this paper, we
study methods for constructing guardrails for AI agents that use reward
functions to learn decision making. We introduce a novel approach, which we
call strategy masking, to explicitly learn and then suppress undesirable AI
agent behavior. We apply our method to study lying in AI agents and show that
strategy masking can effectively modify agent behavior by suppressing, or
actively penalizing, the reward dimension for lying such that agents act more
honestly while not compromising their ability to perform effectively.

摘要：使用獎勵函數來建構 AI 學習和決策制定是當前強化學習範例的核心；然而，若獎勵函數設計不周，代理程式可能會學會以「不可取」或「不道德」的方式解決問題。若不徹底了解獎勵函數所創造的誘因，就難以對其行為施加有原則且通用的控制機制。在本文中，我們研究了建構防護措施的方法，以供使用獎勵函數學習決策制定的 AI 代理程式使用。我們提出了一種新方法，稱為策略遮罩，用於明確學習並抑制不良的 AI 代理程式行為。我們將方法應用於研究 AI 代理程式中的說謊行為，並證明策略遮罩可以有效修改代理程式行為，方法是抑制或主動懲罰說謊的獎勵維度，讓代理程式更誠實，同時不損害其有效執行任務的能力。

##### **Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics**
2501.05409v2 by Maximilian Alber, Stephan Tietz, Jonas Dippel, Timo Milbich, Timothée Lesort, Panos Korfiatis, Moritz Krügener, Beatriz Perez Cancer, Neelay Shah, Alexander Möllers, Philipp Seegerer, Alexandra Carpen-Amarie, Kai Standvoss, Gabriel Dernbach, Edwin de Jong, Simon Schallenberg, Andreas Kunft, Helmut Hoffer von Ankershoffen, Gavin Schaeferle, Patrick Duffy, Matt Redlon, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert Müller, Frederick Klauschen, Andrew Norgan

Recent advances in digital pathology have demonstrated the effectiveness of
foundation models across diverse applications. In this report, we present
Atlas, a novel vision foundation model based on the RudolfV approach. Our model
was trained on a dataset comprising 1.2 million histopathology whole slide
images, collected from two medical institutions: Mayo Clinic and Charit\'e -
Universt\"atsmedizin Berlin. Comprehensive evaluations show that Atlas achieves
state-of-the-art performance across twenty-one public benchmark datasets, even
though it is neither the largest model by parameter count nor by training
dataset size.

摘要：最近在數位病理學的進展已展現基礎模型在各種應用上的有效性。在此報告中，我們提出 Atlas，一種基於 RudolfV 方法的新穎視覺基礎模型。我們的模型訓練於一個包含 120 萬張組織病理全玻片影像的資料集，這些影像收集自兩個醫療機構：梅約診所和柏林夏里特大學醫學中心。全面的評估顯示，Atlas 在 21 個公開基準資料集上達到了最先進的效能，即使它既不是參數數量最大的模型，也不是訓練資料集規模最大的模型。

##### **An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**
2501.05197v1 by Drago Plecko, Paul Secombe, Andrea Clarke, Amelia Fiske, Samarra Toby, Donisha Duff, David Pilcher, Leo Anthony Celi, Rinaldo Bellomo, Elias Bareinboim

The new era of large-scale data collection and analysis presents an
opportunity for diagnosing and understanding the causes of health inequities.
In this study, we describe a framework for systematically analyzing health
disparities using causal inference. The framework is illustrated by
investigating racial and ethnic disparities in intensive care unit (ICU)
outcome between majority and minority groups in Australia (Indigenous vs.
Non-Indigenous) and the United States (African-American vs. White). We
demonstrate that commonly used statistical measures for quantifying inequity
are insufficient, and focus on attributing the observed disparity to the causal
mechanisms that generate it. We find that minority patients are younger at
admission, have worse chronic health, are more likely to be admitted for urgent
and non-elective reasons, and have higher illness severity. At the same time,
however, we find a protective direct effect of belonging to a minority group,
with minority patients showing improved survival compared to their majority
counterparts, with all other variables kept equal. We demonstrate that this
protective effect is related to the increased probability of being admitted to
ICU, with minority patients having an increased risk of ICU admission. We also
find that minority patients, while showing improved survival, are more likely
to be readmitted to ICU. Thus, due to worse access to primary health care,
minority patients are more likely to end up in ICU for preventable conditions,
causing a reduction in the mortality rates and creating an effect that appears
to be protective. Since the baseline risk of ICU admission may serve as proxy
for lack of access to primary care, we developed the Indigenous Intensive Care
Equity (IICE) Radar, a monitoring system for tracking the over-utilization of
ICU resources by the Indigenous population of Australia across geographical
areas.

摘要：大型資料收集和分析的新時代，提供了診斷和了解健康不平等成因的機會。在這項研究中，我們描述了一個使用因果推論系統分析健康差距的架構。這個架構透過調查澳洲（原住民對非原住民）和美國（非裔美國人對白人）中，重症加護病房（ICU）結果在種族和族群上的差異來加以說明。我們證明了通常用於量化不平等的統計測量是不夠的，並專注於將觀察到的差異歸因於產生它的因果機制。我們發現，少數族裔患者在入院時較年輕，慢性健康狀況較差，更有可能因緊急和非選擇性原因而入院，且疾病嚴重程度較高。然而，同時我們發現屬於少數族裔群體具有保護性的直接影響，與多數族裔的對照組相比，少數族裔患者在其他所有變數保持相同的情況下，存活率有所改善。我們證明這種保護效應與被送進 ICU 的機率增加有關，少數族裔患者的 ICU 入院風險增加。我們也發現，少數族裔患者雖然存活率有所改善，但更有可能再次入院到 ICU。因此，由於較難獲得初級醫療保健，少數族裔患者更有可能因可預防的疾病而進入 ICU，導致死亡率降低並產生看似具有保護作用的效應。由於 ICU 入院的基本風險可能作為缺乏初級照護的指標，因此我們開發了原住民重症監護公平性（IICE）雷達，這是一個監控系統，用於追蹤澳洲原住民人口在不同地理區域過度使用 ICU 資源的情況。

##### **Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**
2501.04958v1 by Lei Li, Xinglin Zhang, Jun Liang, Tao Chen

Deep learning models in medical imaging face dual challenges: domain shift,
where models perform poorly when deployed in settings different from their
training environment, and class imbalance, where certain disease conditions are
naturally underrepresented. We present Imbalance-Aware Domain Adaptation
(IADA), a novel framework that simultaneously tackles both challenges through
three key components: (1) adaptive feature learning with class-specific
attention mechanisms, (2) balanced domain alignment with dynamic weighting, and
(3) adaptive threshold optimization. Our theoretical analysis establishes
convergence guarantees and complexity bounds. Through extensive experiments on
embryo development assessment across four imaging modalities, IADA demonstrates
significant improvements over existing methods, achieving up to 25.19\% higher
accuracy while maintaining balanced performance across classes. In challenging
scenarios with low-quality imaging systems, IADA shows robust generalization
with AUC improvements of up to 12.56\%. These results demonstrate IADA's
potential for developing reliable and equitable medical imaging systems for
diverse clinical settings. The code is made public available at
\url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}

摘要：<paragraph>醫療影像中的深度學習模型面臨雙重挑戰：領域轉移，模型在與其訓練環境不同的設定中部署時表現不佳，以及類別不平衡，某些疾病狀況在自然界中代表性不足。我們提出不平衡感知域適應 (IADA)，這是一個新穎的框架，透過三個關鍵組成部分同時應對這兩個挑戰：(1) 具有類別特定注意力機制的自適應特徵學習，(2) 具有動態加權的平衡域對齊，以及 (3) 自適應閾值最佳化。我們的理論分析建立了收斂保證和複雜度界限。透過對四種影像模式的胚胎發育評估進行廣泛的實驗，IADA 證明了對現有方法的顯著改進，在維持類別間平衡性能的同時，準確度提高了 25.19%。在低品質影像系統的挑戰性場景中，IADA 以高達 12.56% 的 AUC 改進顯示出強大的泛化能力。這些結果證明了 IADA 在為不同的臨床設定開發可靠且公平的醫療影像系統方面的潛力。程式碼已公開於 \url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}</paragraph>

##### **Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**
2501.04896v1 by Michail Ouroutzoglou, Mingmin Zhao, Joshua Hellerstein, Hariharan Rahul, Asima Badic, Brian S. Kim, Dina Katabi

Chronic itch affects 13% of the US population, is highly debilitating, and
underlies many medical conditions. A major challenge in clinical care and new
therapeutics development is the lack of an objective measure for quantifying
itch, leading to reliance on subjective measures like patients' self-assessment
of itch severity. In this paper, we show that a home radio device paired with
artificial intelligence (AI) can concurrently capture scratching and evaluate
its impact on sleep quality by analyzing radio signals bouncing in the
environment. The device eliminates the need for wearable sensors or skin
contact, enabling monitoring of chronic itch over extended periods at home
without burdening patients or interfering with their skin condition. To
validate the technology, we conducted an observational clinical study of
chronic pruritus patients, monitored at home for one month using both the radio
device and an infrared camera. Comparing the output of the device to ground
truth data from the camera demonstrates its feasibility and accuracy (ROC AUC =
0.997, sensitivity = 0.825, specificity = 0.997). The results reveal a
significant correlation between scratching and low sleep quality, manifested as
a reduction in sleep efficiency (R = 0.6, p < 0.001) and an increase in sleep
latency (R = 0.68, p < 0.001). Our study underscores the potential of passive,
long-term, at-home monitoring of chronic scratching and its sleep implications,
offering a valuable tool for both clinical care of chronic itch patients and
pharmaceutical clinical trials.

摘要：慢性搔癢影響美國 13% 的人口，會嚴重衰弱，且是許多疾病的根本原因。臨床護理和新療法開發的一大挑戰是缺乏客觀的指標來量化搔癢，導致依賴於患者自我評估搔癢嚴重程度等主觀指標。在本文中，我們展示了一種與人工智慧 (AI) 配對的家用無線電裝置，可透過分析在環境中彈跳的無線電訊號，同時擷取抓撓並評估其對睡眠品質的影響。此裝置消除了對穿戴式感測器或皮膚接觸的需求，讓患者在家中長時間監控慢性搔癢，而不會造成負擔或干擾其皮膚狀況。為了驗證這項技術，我們對慢性搔癢症患者進行了一項觀察性臨床研究，使用無線電裝置和紅外線攝影機在家中監控一個月。將裝置的輸出與攝影機的真實數據進行比較，證明了其可行性和準確性 (ROC AUC = 0.997，靈敏度 = 0.825，特異度 = 0.997)。結果顯示抓撓與睡眠品質低下之間存在顯著相關性，表現為睡眠效率降低 (R = 0.6，p < 0.001) 和睡眠潛伏期增加 (R = 0.68，p < 0.001)。我們的研究強調了被動、長期、在家中監控慢性抓撓及其對睡眠的影響的潛力，為慢性搔癢症患者的臨床護理和藥廠臨床試驗提供了有價值的工具。

##### **MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**
2501.04614v2 by Daniele Molino, Francesco Di Feola, Eliodoro Faiella, Deborah Fazzini, Domiziana Santucci, Linlin Shen, Valerio Guarrasi, Paolo Soda

Artificial Intelligence is revolutionizing medical practice, enhancing
diagnostic accuracy and healthcare delivery. However, its adaptation in medical
settings still faces significant challenges, related to data availability and
privacy constraints. Synthetic data has emerged as a promising solution to
mitigate these issues, addressing data scarcity while preserving privacy.
Recently, Latent Diffusion Models have emerged as a powerful tool for
generating high-quality synthetic data. Meanwhile, the integration of different
modalities has gained interest, emphasizing the need of models capable of
handle multimodal medical data. Existing approaches struggle to integrate
complementary information and lack the ability to generate modalities
simultaneously. To address this challenge, we present MedCoDi-M, a
6.77-billion-parameter model, designed for multimodal medical data generation,
that, following Foundation Model paradigm, exploits contrastive learning and
large quantity of data to build a shared latent space which capture the
relationships between different data modalities. Further, we introduce the
Multi-Prompt training technique, which significantly boosts MedCoDi-M's
generation under different settings. We extensively validate MedCoDi-M: first
we benchmark it against five competitors on the MIMIC-CXR dataset, a
state-of-the-art dataset for Chest X-ray and radiological report generation.
Secondly, we perform a Visual Turing Test with expert radiologists to assess
the realism and clinical relevance of the generated data, ensuring alignment
with real-world scenarios. Finally, we assess the utility of MedCoDi-M in
addressing key challenges in the medical field, such as anonymization, data
scarcity and imbalance learning. The results are promising, demonstrating the
applicability of MedCoDi-M in medical contexts. Project page is at
https://cosbidev.github.io/MedCoDi-M/.

摘要：人工智能正在革新醫療實務，提升診斷準確度和醫療保健服務。然而，它在醫療場景中的應用仍面臨著重大挑戰，這與資料可用性和隱私限制有關。合成資料已成為緩解這些問題的潛在解決方案，它在保護隱私的同時解決了資料短缺的問題。最近，潛在擴散模型已成為產生高品質合成資料的強大工具。同時，整合不同模態已引起興趣，強調了需要能夠處理多模態醫療資料的模型。現有方法難以整合補充資訊，並且缺乏同時產生模態的能力。為了應對這一挑戰，我們提出了 MedCoDi-M，這是一個 67.7 億參數的模型，專為多模態醫療資料產生而設計，它遵循基礎模型範例，利用對比學習和大量的資料來建立一個共享潛在空間，以捕捉不同資料模態之間的關係。此外，我們引入了多提示訓練技術，它顯著提升了 MedCoDi-M 在不同設定下的產生。我們廣泛驗證了 MedCoDi-M：首先，我們在 MIMIC-CXR 資料集上對它與五個競爭者進行了基準測試，這是胸部 X 光和放射報告產生領域的最新資料集。其次，我們與放射科專家進行了視覺圖靈測試，以評估產生資料的真實性和臨床相關性，確保與真實場景保持一致。最後，我們評估了 MedCoDi-M 在解決醫療領域關鍵挑戰中的效用，例如匿名化、資料短缺和不平衡學習。結果令人滿意，證明了 MedCoDi-M 在醫療環境中的適用性。專案頁面位於 https://cosbidev.github.io/MedCoDi-M/。

##### **A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**
2501.04577v1 by Zephan M. Enciso, Boyang Cheng, Likai Pei, Jianbo Liu, Steven Davis, Ningyuan Cao, Michael Niemier

Uncertainty estimation is an indispensable capability for AI-enabled,
safety-critical applications, e.g. autonomous vehicles or medical diagnosis.
Bayesian neural networks (BNNs) use Bayesian statistics to provide both
classification predictions and uncertainty estimation, but they suffer from
high computational overhead associated with random number generation and
repeated sample iterations. Furthermore, BNNs are not immediately amenable to
acceleration through compute-in-memory architectures due to the frequent memory
writes necessary after each RNG operation. To address these challenges, we
present an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into the
SRAM memory words. This integration reduces RNG overhead and enables
fully-parallel compute-in-memory operations for BNNs. The prototype chip
achieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughput
while occupying 0.45 mm2, bringing AI uncertainty estimation to edge
computation.

摘要：不確定性估計對於 AI 驅動、安全關鍵的應用程式來說是不可或缺的能力，例如自動駕駛車輛或醫療診斷。貝氏類神經網路 (BNN) 使用貝氏統計來提供分類預測和不確定性估計，但它們會因隨機數生成和重複樣本迭代而產生高運算負擔。此外，由於每次 RNG 操作後都需要頻繁的記憶體寫入，因此 BNN 無法立即適用於透過記憶體運算架構進行加速。為了應對這些挑戰，我們提出了一款 ASIC，將 360 fJ/Sample Gaussian RNG 直接整合到 SRAM 記憶體字元中。此整合可減少 RNG 負擔，並為 BNN 啟用完全並行的記憶體運算操作。原型晶片可達成 5.12 GSa/s RNG 處理量和 102 GOp/s 神經網路處理量，同時佔用 0.45 mm2，將 AI 不確定性估計帶到邊緣運算。

##### **Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**
2501.04217v1 by Ren Tasai, Guang Li, Ren Togo, Minghui Tang, Takaaki Yoshimura, Hiroyuki Sugimori, Kenji Hirata, Takahiro Ogawa, Kohsuke Kudo, Miki Haseyama

We propose a novel continual self-supervised learning method (CSSL)
considering medical domain knowledge in chest CT images. Our approach addresses
the challenge of sequential learning by effectively capturing the relationship
between previously learned knowledge and new information at different stages.
By incorporating an enhanced DER into CSSL and maintaining both diversity and
representativeness within the rehearsal buffer of DER, the risk of data
interference during pretraining is reduced, enabling the model to learn more
richer and robust feature representations. In addition, we incorporate a mixup
strategy and feature distillation to further enhance the model's ability to
learn meaningful representations. We validate our method using chest CT images
obtained under two different imaging conditions, demonstrating superior
performance compared to state-of-the-art methods.

摘要：我們提出了一種新的持續自我監督學習方法 (CSSL)，考量了胸部電腦斷層影像中的醫學領域知識。我們的做法透過有效捕捉先前學習的知識與不同階段的新資訊之間的關係，來解決循序學習的挑戰。透過將增強的 DER 納入 CSSL，並在 DER 的排練緩衝區內維持多樣性和代表性，預訓練期間資料干擾的風險降低，使模型能夠學習更豐富且強健的特徵表徵。此外，我們納入混淆策略和特徵萃取，進一步增強模型學習有意義表徵的能力。我們使用在兩種不同影像條件下取得的胸部電腦斷層影像驗證我們的模型，證明與現有技術相比具有優異的效能。

##### **Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**
2501.04734v1 by Rancy Chepchirchir, Jill Sunday, Raymond Confidence, Dong Zhang, Talha Chaudhry, Udunna C. Anazodo, Kendi Muchungi, Yujing Zou

In Sub-Saharan Africa (SSA), the utilization of lower-quality Magnetic
Resonance Imaging (MRI) technology raises questions about the applicability of
machine learning methods for clinical tasks. This study aims to provide a
robust deep learning-based brain tumor segmentation (BraTS) method tailored for
the SSA population using a threefold approach. Firstly, the impact of domain
shift from the SSA training data on model efficacy was examined, revealing no
significant effect. Secondly, a comparative analysis of 3D and 2D
full-resolution models using the nnU-Net framework indicates similar
performance of both the models trained for 300 epochs achieving a five-fold
cross-validation score of 0.93. Lastly, addressing the performance gap observed
in SSA validation as opposed to the relatively larger BraTS glioma (GLI)
validation set, two strategies are proposed: fine-tuning SSA cases using the
GLI+SSA best-pretrained 2D fullres model at 300 epochs, and introducing a novel
neural style transfer-based data augmentation technique for the SSA cases. This
investigation underscores the potential of enhancing brain tumor prediction
within SSA's unique healthcare landscape.

摘要：在撒哈拉以南非洲 (SSA)，低质量磁共振成像 (MRI) 技术的使用引发了有关机器学习方法在临床任务中适用性的问题。本研究旨在提供一种针对 SSA 人群量身定制的鲁棒深度学习脑肿瘤分割 (BraTS) 方法，采用三重方法。首先，检查了 SSA 训练数据对模型效能的域偏移影响，结果显示没有显着影响。其次，使用 nnU-Net 框架对 3D 和 2D 全分辨率模型进行比较分析，表明针对 300 个 epoch 训练的两个模型的性能相似，实现了 0.93 的五重交叉验证分数。最后，针对 SSA 验证中观察到的性能差距，而不是相对较大的 BraTS 神经胶质瘤 (GLI) 验证集，提出了两种策略：使用 GLI+SSA 最佳预训练的 2D 全分辨率模型在 300 个 epoch 对 SSA 病例进行微调，并为 SSA 病例引入一种新颖的神经风格迁移数据增强技术。这项调查强调了在 SSA 独特的医疗保健环境中提高脑肿瘤预测潜力的可能性。

##### **Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**
2501.03904v1 by Ramya Jonnala, Gongbo Liang, Jeong Yang, Izzat Alsmadi

The integration of large language models (LLMs) into public transit systems
presents a transformative opportunity to enhance urban mobility. This study
explores the potential of LLMs to revolutionize public transportation
management within the context of San Antonio's transit system. Leveraging the
capabilities of LLMs in natural language processing and data analysis, we
investigate their capabilities to optimize route planning, reduce wait times,
and provide personalized travel assistance. By utilizing the General Transit
Feed Specification (GTFS) and other relevant data, this research aims to
demonstrate how LLMs can potentially improve resource allocation, elevate
passenger satisfaction, and inform data-driven decision-making in transit
operations. A comparative analysis of different ChatGPT models was conducted to
assess their ability to understand transportation information, retrieve
relevant data, and provide comprehensive responses. Findings from this study
suggest that while LLMs hold immense promise for public transit, careful
engineering and fine-tuning are essential to realizing their full potential.
San Antonio serves as a case study to inform the development of LLM-powered
transit systems in other urban environments.

摘要：大型語言模型 (LLM) 整合到公共交通系統中，為提升城市流動性帶來轉型契機。本研究探討 LLM 在聖安東尼奧交通系統脈絡下，革新大眾運輸管理的潛力。利用 LLM 在自然語言處理和資料分析方面的能力，我們探討其在優化路線規劃、縮短等候時間，以及提供個人化旅遊協助方面的能力。透過利用通用大眾運輸資料規範 (GTFS) 和其他相關資料，本研究旨在證明 LLM 如何潛在提升資源配置、提升乘客滿意度，以及在交通營運中提供資料驅動的決策。針對不同的 ChatGPT 模型進行比較分析，以評估其理解交通資訊、擷取相關資料，以及提供全面回應的能力。本研究的發現顯示，儘管 LLM 對大眾運輸極具前景，但精密的工程和微調對於實現其全部潛力至關重要。聖安東尼奧作為一個案例研究，為在其他都市環境中開發由 LLM 驅動的交通系統提供參考。

##### **SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**
2501.03836v2 by Runci Bai

Brain tumors can result in neurological dysfunction, alterations in cognitive
and psychological states, increased intracranial pressure, and the occurrence
of seizures, thereby presenting a substantial risk to human life and health.
The You Only Look Once(YOLO) series models have demonstrated superior accuracy
in object detection for medical imaging. In this paper, we develop a novel
SCC-YOLO architecture by integrating the SCConv attention mechanism into
YOLOv9. The SCConv module reconstructs an efficient convolutional module by
reducing spatial and channel redundancy among features, thereby enhancing the
learning of image features. We investigate the impact of intergrating different
attention mechanisms with the YOLOv9 model on brain tumor image detection using
both the Br35H dataset and our self-made dataset(Brain_Tumor_Dataset).
Experimental results show that on the Br35H dataset, SCC-YOLO achieved a 0.3%
improvement in mAp50 compared to YOLOv9, while on our self-made dataset,
SCC-YOLO exhibited a 0.5% improvement over YOLOv9. SCC-YOLO has reached
state-of-the-art performance in brain tumor detection. Source code is available
at : https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

摘要：腦瘤可能導致神經功能障礙、認知和心理狀態改變、顱內壓升高和癲癇發作，從而對人類生命和健康構成重大風險。You Only Look Once (YOLO) 系列模型已證明在醫學影像的目標檢測中具有優異的準確度。在本文中，我們通過將 SCConv 注意力機制整合到 YOLOv9 中，開發了一種新穎的 SCC-YOLO 架構。SCConv 模組通過減少特徵之間的空間和通道冗餘來重建一個高效的卷積模組，從而增強影像特徵的學習。我們使用 Br35H 資料集和我們自製的資料集 (Brain_Tumor_Dataset) 調查了將不同的注意力機制與 YOLOv9 模型整合對腦瘤影像檢測的影響。實驗結果表明，在 Br35H 資料集上，與 YOLOv9 相比，SCC-YOLO 在 mAP50 上提高了 0.3%，而在我們自製的資料集上，SCC-YOLO 比 YOLOv9 提高了 0.5%。SCC-YOLO 已達到腦瘤檢測的最新效能。原始碼可在以下網址取得：https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

##### **SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**
2501.03764v1 by Siyuan Zhao, Chenyu Liu, Yi Ding, Xinliang Zhou

In practical sleep stage classification, a key challenge is the variability
of EEG data across different subjects and environments. Differences in
physiology, age, health status, and recording conditions can lead to domain
shifts between data. These domain shifts often result in decreased model
accuracy and reliability, particularly when the model is applied to new data
with characteristics different from those it was originally trained on, which
is a typical manifestation of negative transfer. To address this, we propose
SelectiveFinetuning in this paper. Our method utilizes a pretrained Multi
Resolution Convolutional Neural Network (MRCNN) to extract EEG features,
capturing the distinctive characteristics of different sleep stages. To
mitigate the effect of domain shifts, we introduce a domain aligning mechanism
that employs Earth Mover Distance (EMD) to evaluate and select source domain
data closely matching the target domain. By finetuning the model with selective
source data, our SelectiveFinetuning enhances the model's performance on target
domain that exhibits domain shifts compared to the data used for training.
Experimental results show that our method outperforms existing baselines,
offering greater robustness and adaptability in practical scenarios where data
distributions are often unpredictable.

摘要：在實際的睡眠階段分類中，一個關鍵的挑戰是腦電圖數據在不同受試者和環境中的變異性。生理、年齡、健康狀況和記錄條件的差異可能導致數據之間的領域偏移。這些領域偏移通常會導致模型準確度和可靠性下降，特別是當模型應用於與其最初訓練時不同的特徵的新數據時，這是負遷移的典型表現。為了解決這個問題，我們在本文中提出選擇性微調。我們的模型利用預訓練的多解析度卷積神經網路 (MRCNN) 來提取腦電圖特徵，捕捉不同睡眠階段的獨特特徵。為了減輕領域偏移的影響，我們引入了一個領域對齊機制，它採用地球移動距離 (EMD) 來評估和選擇與目標領域緊密匹配的源領域數據。通過使用選擇性源數據微調模型，我們的選擇性微調增強了模型在與用於訓練的數據相比表現出領域偏移的目標領域上的性能。實驗結果表明，我們的模型優於現有的基準，在數據分佈通常不可預測的實際場景中提供了更大的穩健性和適應性。

##### **Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**
2501.03722v1 by Xiaotong Guo, Deqian Yang, Dan Wang, Haochen Zhao, Yuan Li, Zhilin Sui, Tao Zhou, Lijun Zhang, Yanda Meng

Accurate segmentation of pulmonary structures iscrucial in clinical
diagnosis, disease study, and treatment planning. Significant progress has been
made in deep learning-based segmentation techniques, but most require much
labeled data for training. Consequently, developing precise segmentation
methods that demand fewer labeled datasets is paramount in medical image
analysis. The emergence of pre-trained vision-language foundation models, such
as CLIP, recently opened the door for universal computer vision tasks.
Exploiting the generalization ability of these pre-trained foundation models on
downstream tasks, such as segmentation, leads to unexpected performance with a
relatively small amount of labeled data. However, exploring these models for
pulmonary artery-vein segmentation is still limited. This paper proposes a
novel framework called Language-guided self-adaptive Cross-Attention Fusion
Framework. Our method adopts pre-trained CLIP as a strong feature extractor for
generating the segmentation of 3D CT scans, while adaptively aggregating the
cross-modality of text and image representations. We propose a s pecially
designed adapter module to fine-tune pre-trained CLIP with a self-adaptive
learning strategy to effectively fuse the two modalities of embeddings. We
extensively validate our method on a local dataset, which is the largest
pulmonary artery-vein CT dataset to date and consists of 718 labeled data in
total. The experiments show that our method outperformed other state-of-the-art
methods by a large margin. Our data and code will be made publicly available
upon acceptance.

摘要：精確分割肺部結構在臨床診斷、疾病研究和治療計畫中至關重要。基於深度學習的分割技術已取得重大進展，但大多數技術在訓練時需要大量的標記資料。因此，開發精確的分割方法，以減少標記資料集的需求，在醫學影像分析中至關重要。預訓練的視覺語言基礎模型（例如 CLIP）的出現，最近為通用電腦視覺任務開啟了大門。利用這些預訓練基礎模型在分割等下游任務中的泛化能力，即使標記資料量相對較少，也能產生意想不到的效能。然而，探索這些模型在肺動脈靜脈分割中的應用仍然有限。本文提出了一個名為語言引導自適應交叉注意力融合框架的新框架。我們的模型採用預訓練的 CLIP 作為強大的特徵萃取器，用於產生 3D 電腦斷層掃描的分割，同時自適應地聚合文本和影像表徵的跨模態。我們提出了一個特別設計的適配器模組，以自適應學習策略微調預訓練的 CLIP，以有效融合兩種嵌入模態。我們在一個本地資料集上廣泛驗證了我們的模型，這是迄今為止最大的肺動脈靜脈電腦斷層掃描資料集，總共包含 718 個標記資料。實驗表明，我們的模型以大幅優於其他最先進模型。我們的資料和程式碼將在獲得接受後公開。

##### **Can Deep Learning Trigger Alerts from Mobile-Captured Images?**
2501.03499v1 by Pritisha Sarkar, Duranta Durbaar Vishal Saha, Mousumi Saha

Our research presents a comprehensive approach to leveraging mobile camera
image data for real-time air quality assessment and recommendation. We develop
a regression-based Convolutional Neural Network model and tailor it explicitly
for air quality prediction by exploiting the inherent relationship between
output parameters. As a result, the Mean Squared Error of 0.0077 and 0.0112
obtained for 2 and 5 pollutants respectively outperforms existing models.
Furthermore, we aim to verify the common practice of augmenting the original
dataset with a view to introducing more variation in the training phase. It is
one of our most significant contributions that our experimental results
demonstrate minimal accuracy differences between the original and augmented
datasets. Finally, a real-time, user-friendly dashboard is implemented which
dynamically displays the Air Quality Index and pollutant values derived from
captured mobile camera images. Users' health conditions are considered to
recommend whether a location is suitable based on current air quality metrics.
Overall, this research contributes to verification of data augmentation
techniques, CNN-based regression modelling for air quality prediction, and
user-centric air quality monitoring through mobile technology. The proposed
system offers practical solutions for individuals to make informed
environmental health and well-being decisions.

摘要：我們的研究提出了一種利用行動裝置相機影像資料進行即時空氣品質評估和建議的全面性方法。我們開發了一種基於迴歸的卷積神經網路模型，並透過利用輸出參數之間的內在關係，針對空氣品質預測量身打造。因此，分別針對 2 和 5 種污染物取得的平均平方誤差為 0.0077 和 0.0112，優於現有的模型。此外，我們旨在驗證擴充原始資料集的常見做法，以期在訓練階段引入更多變異。我們的實驗結果顯示原始資料集和擴充資料集之間的準確度差異極小，這是我們最重要的貢獻之一。最後，我們實作了一個即時、使用者友善的儀表板，可動態顯示從擷取的行動裝置相機影像中衍生的空氣品質指數和污染物數值。考量使用者的健康狀況，建議是否根據目前的空氣品質指標選擇適合的地點。整體而言，這項研究有助於驗證資料擴充技術、基於 CNN 的迴歸模型（用於空氣品質預測）以及透過行動技術進行以使用者為中心的空氣品質監控。所提出的系統為個人提供實際的解決方案，以便做出明智的環境健康和福祉決策。

##### **Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**
2501.03458v1 by Xiao Wang, Fuling Wang, Haowen Wang, Bo Jiang, Chuanfu Li, Yaowei Wang, Yonghong Tian, Jin Tang

X-ray image based medical report generation achieves significant progress in
recent years with the help of the large language model, however, these models
have not fully exploited the effective information in visual image regions,
resulting in reports that are linguistically sound but insufficient in
describing key diseases. In this paper, we propose a novel associative
memory-enhanced X-ray report generation model that effectively mimics the
process of professional doctors writing medical reports. It considers both the
mining of global and local visual information and associates historical report
information to better complete the writing of the current report. Specifically,
given an X-ray image, we first utilize a classification model along with its
activation maps to accomplish the mining of visual regions highly associated
with diseases and the learning of disease query tokens. Then, we employ a
visual Hopfield network to establish memory associations for disease-related
tokens, and a report Hopfield network to retrieve report memory information.
This process facilitates the generation of high-quality reports based on a
large language model and achieves state-of-the-art performance on multiple
benchmark datasets, including the IU X-ray, MIMIC-CXR, and Chexpert Plus. The
source code of this work is released on
\url{https://github.com/Event-AHU/Medical_Image_Analysis}.

摘要：近年來，在大型語言模型的幫助下，基於 X 光影像的醫療報告生成取得了顯著進展，然而，這些模型並未充分利用視覺影像區域中的有效資訊，導致報告在語言上雖然流暢，但在描述關鍵疾病方面卻不足。在本文中，我們提出了一個新穎的聯想式記憶增強 X 光報告生成模型，有效地模擬專業醫生撰寫醫療報告的過程。它同時考慮了對全局和局部視覺資訊的挖掘，並聯繫歷史報告資訊，以更好地完成當前報告的撰寫。具體來說，給定一張 X 光影像，我們首先利用分類模型及其激活映射來完成與疾病高度相關的視覺區域的挖掘和疾病查詢令牌的學習。然後，我們採用視覺霍普菲爾德網路來建立與疾病相關的令牌的記憶聯繫，並採用報告霍普菲爾德網路來檢索報告記憶資訊。這個過程有助於基於大型語言模型生成高品質的報告，並在包括 IU X 射線、MIMIC-CXR 和 Chexpert Plus 在內的多個基準資料集上實現了最先進的效能。此項工作的原始碼已發佈在\url{https://github.com/Event-AHU/Medical_Image_Analysis}。

##### **Existential Crisis: A Social Robot's Reason for Being**
2501.03376v1 by Dora Medgyesy, Joella Galas, Julian van Pol, Rustam Eynaliyev, Thijs Vollebregt

As Robots become ever more important in our daily lives there's growing need
for understanding how they're perceived by people. This study aims to
investigate how the user perception of robots is influenced by displays of
personality. Using LLMs and speech to text technology, we designed a
within-subject study to compare two conditions: a personality-driven robot and
a purely task-oriented, personality-neutral robot. Twelve participants,
recruited from Socially Intelligent Robotics course at Vrije Universiteit
Amsterdam, interacted with a robot Nao tasked with asking them a set of medical
questions under both conditions. After completing both interactions, the
participants completed a user experience questionnaire measuring their
emotional states and robot perception using standardized questionnaires from
the SRI and Psychology literature.

摘要：隨著機器人在我們日常生活中的重要性日益提升，對於了解人們如何感知機器人的需求也日益增加。本研究旨在探討機器人的使用者感知如何受到人格表現的影響。我們使用大型語言模型 (LLM) 和語音轉文字技術，設計了一項受試者內研究，以比較兩種情況：一種是人格驅動的機器人，另一種是純粹以任務為導向、人格中立的機器人。我們從阿姆斯特丹自由大學的社交智能機器人課程中招募了 12 名參與者，他們與機器人 Nao 互動，在兩種情況下都向他們詢問一系列醫療問題。在完成這兩種互動後，參與者完成了一份使用者體驗問卷，使用來自 SRI 和心理學文獻的標準化問卷測量他們的情緒狀態和機器人感知。

##### **Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**
2501.02922v1 by Susu Sun, Leslie Tessier, Frédérique Meeuwsen, Clément Grisi, Dominique van Midden, Geert Litjens, Christian F. Baumgartner

Multiple Instance Learning (MIL) methods allow for gigapixel Whole-Slide
Image (WSI) analysis with only slide-level annotations. Interpretability is
crucial for safely deploying such algorithms in high-stakes medical domains.
Traditional MIL methods offer explanations by highlighting salient regions.
However, such spatial heatmaps provide limited insights for end users. To
address this, we propose a novel inherently interpretable WSI-classification
approach that uses human-understandable pathology concepts to generate
explanations. Our proposed Concept MIL model leverages recent advances in
vision-language models to directly predict pathology concepts based on image
features. The model's predictions are obtained through a linear combination of
the concepts identified on the top-K patches of a WSI, enabling inherent
explanations by tracing each concept's influence on the prediction. In contrast
to traditional concept-based interpretable models, our approach eliminates the
need for costly human annotations by leveraging the vision-language model. We
validate our method on two widely used pathology datasets: Camelyon16 and
PANDA. On both datasets, Concept MIL achieves AUC and accuracy scores over 0.9,
putting it on par with state-of-the-art models. We further find that 87.1\%
(Camelyon16) and 85.3\% (PANDA) of the top 20 patches fall within the tumor
region. A user study shows that the concepts identified by our model align with
the concepts used by pathologists, making it a promising strategy for
human-interpretable WSI classification.

摘要：多實例學習 (MIL) 方法僅使用玻片層級註解，即可進行吉像素全玻片影像 (WSI) 分析。可解釋性對於在高風險醫療領域安全部署此類演算法至關重要。傳統的 MIL 方法透過強調顯著區域來提供說明。然而，此類空間熱圖為最終使用者提供的見解有限。為了解決此問題，我們提出了一種新穎且本質上可解釋的 WSI 分類方法，該方法使用人類可理解的病理概念來產生說明。我們提出的概念 MIL 模型利用視覺語言模型的最新進展，根據影像特徵直接預測病理概念。該模型的預測是透過線性組合 WSI 頂部 K 個區塊上識別的概念而獲得的，透過追蹤每個概念對預測的影響，可以提供內在說明。與傳統基於概念的可解釋模型相比，我們的做法透過利用視覺語言模型，消除了對昂貴的人工註解的需求。我們在兩個廣泛使用的病理資料集：Camelyon16 和 PANDA 上驗證了我們的模型。在兩個資料集上，概念 MIL 的 AUC 和準確率都超過 0.9，與最先進的模型不相上下。我們進一步發現，前 20 個區塊中有 87.1%（Camelyon16）和 85.3%（PANDA）落在腫瘤區域內。一項使用者研究表明，我們的模型識別的概念與病理學家使用的概念一致，使其成為人類可解釋 WSI 分類的一種有前途的策略。

##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

摘要：幽默風格對幸福感可能產生負面或正面的影響。
鑑於這些風格對心理健康的重要性，已經對其自動識別進行了大量研究。然而，用於此目的的自動機器學習模型是黑盒子，使得其預測決策不透明。清晰度和透明度在心理健康領域至關重要。本文提出了一個可解釋的 AI (XAI) 框架，用於理解幽默風格分類，建立在計算幽默分析的先前工作之上。使用先前研究中表現最好的單一模型 (ALI+XGBoost)，我們應用全面的 XAI 技術來分析語言、情緒和語義特徵如何影響幽默風格分類決策。我們的分析揭示了不同幽默風格如何被表徵和錯誤分類的不同模式，特別強調了區分聯屬幽默與其他風格的挑戰。通過仔細檢查特徵重要性、錯誤模式和錯誤分類案例，我們確定了影響模型決策的關鍵因素，包括情緒模糊、情境誤解和目標識別。該框架展示了在理解模型行為方面的顯著效用，實現了對定義不同幽默風格的特徵之間複雜相互作用的可解釋見解。我們的發現有助於計算幽默分析的理論理解和心理健康、內容審核和數字人文研究中的實際應用。

##### **IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks by Efficient Human Preference Alignment**
2501.02869v1 by Yiming Zhang, Zheng Chang, Wentao Cai, MengXing Ren, Kang Yuan, Yining Sun, Zenghui Ding

Recent researches of large language models(LLM), which is pre-trained on
massive general-purpose corpora, have achieved breakthroughs in responding
human queries. However, these methods face challenges including limited data
insufficiency to support extensive pre-training and can not align responses
with users' instructions. To address these issues, we introduce a medical
instruction dataset, CMedINS, containing six medical instructions derived from
actual medical tasks, which effectively fine-tunes LLM in conjunction with
other data. Subsequently, We launch our medical model, IIMedGPT, employing an
efficient preference alignment method, Direct preference Optimization(DPO). The
results show that our final model outperforms existing medical models in
medical dialogue.Datsets, Code and model checkpoints will be released upon
acceptance.

摘要：最近針對大型語言模型 (LLM) 的研究，該模型預先訓練於龐大的通用語料庫中，已在回應人類查詢方面取得突破。然而，這些方法面臨的挑戰包括資料不足以支援廣泛的預訓練，且無法將回應與使用者的指示保持一致。為了解決這些問題，我們引進一個醫療指示資料集 CMedINS，其中包含六項從實際醫療任務中衍生的醫療指示，與其他資料結合後能有效微調 LLM。隨後，我們推出我們的醫療模型 IIMedGPT，採用一種有效率的偏好對齊方法，直接偏好最佳化 (DPO)。結果顯示，我們的最終模型在醫療對話中優於現有的醫療模型。資料集、程式碼和模型檢查點將在通過驗證後釋出。

##### **Multi-Modal One-Shot Federated Ensemble Learning for Medical Data with Vision Large Language Model**
2501.03292v1 by Naibo Wang, Yuchen Deng, Shichen Fan, Jianwei Yin, See-Kiong Ng

Federated learning (FL) has attracted considerable interest in the medical
domain due to its capacity to facilitate collaborative model training while
maintaining data privacy. However, conventional FL methods typically
necessitate multiple communication rounds, leading to significant communication
overhead and delays, especially in environments with limited bandwidth.
One-shot federated learning addresses these issues by conducting model training
and aggregation in a single communication round, thereby reducing communication
costs while preserving privacy. Among these, one-shot federated ensemble
learning combines independently trained client models using ensemble techniques
such as voting, further boosting performance in non-IID data scenarios. On the
other hand, existing machine learning methods in healthcare predominantly use
unimodal data (e.g., medical images or textual reports), which restricts their
diagnostic accuracy and comprehensiveness. Therefore, the integration of
multi-modal data is proposed to address these shortcomings. In this paper, we
introduce FedMME, an innovative one-shot multi-modal federated ensemble
learning framework that utilizes multi-modal data for medical image analysis.
Specifically, FedMME capitalizes on vision large language models to produce
textual reports from medical images, employs a BERT model to extract textual
features from these reports, and amalgamates these features with visual
features to improve diagnostic accuracy. Experimental results show that our
method demonstrated superior performance compared to existing one-shot
federated learning methods in healthcare scenarios across four datasets with
various data distributions. For instance, it surpasses existing one-shot
federated learning approaches by more than 17.5% in accuracy on the RSNA
dataset when applying a Dirichlet distribution with ($\alpha$ = 0.3).

摘要：联邦学习 (FL) 由于其在维护数据隐私的同时促进协作模型训练的能力，在医学领域引起了极大的兴趣。然而，传统的 FL 方法通常需要多轮通信，这会导致严重的通信开销和延迟，尤其是在带宽受限的环境中。单次联邦学习通过在单次通信轮中进行模型训练和聚合来解决这些问题，从而在保护隐私的同时降低通信成本。其中，单次联邦集成学习使用集成技术（如投票）将独立训练的客户端模型组合起来，进一步提升了在非 IID 数据场景中的性能。另一方面，现有的医疗保健机器学习方法主要使用单模态数据（例如医学图像或文本报告），这限制了它们的诊断准确性和全面性。因此，提出了多模态数据的集成来解决这些缺点。在本文中，我们介绍了 FedMME，一种创新的单次多模态联邦集成学习框架，它利用多模态数据进行医学图像分析。具体来说，FedMME 利用视觉大语言模型从医学图像中生成文本报告，采用 BERT 模型从这些报告中提取文本特征，并将这些特征与视觉特征相结合以提高诊断准确性。实验结果表明，与现有的单次联邦学习方法相比，我们的方法在四个具有不同数据分布的数据集中的医疗保健场景中表现出优越的性能。例如，当应用具有 ($\alpha$ = 0.3) 的 Dirichlet 分布时，它在 RSNA 数据集上的准确率比现有的单次联邦学习方法高出 17.5% 以上。

##### **GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation**
2501.02788v2 by Niloufar Eghbali, Hassan Bagher-Ebadian, Tuka Alhanai, Mohammad M. Ghassemi

Vision Transformers (ViTs) have shown promise in medical image semantic
segmentation (MISS) by capturing long-range correlations. However, ViTs often
struggle to model local spatial information effectively, which is essential for
accurately segmenting fine anatomical details, particularly when applied to
small datasets without extensive pre-training. We introduce Gabor and Laplacian
of Gaussian Convolutional Swin Network (GLoG-CSUnet), a novel architecture
enhancing Transformer-based models by incorporating learnable radiomic
features. This approach integrates dynamically adaptive Gabor and Laplacian of
Gaussian (LoG) filters to capture texture, edge, and boundary information,
enhancing the feature representation processed by the Transformer model. Our
method uniquely combines the long-range dependency modeling of Transformers
with the texture analysis capabilities of Gabor and LoG features. Evaluated on
the Synapse multi-organ and ACDC cardiac segmentation datasets, GLoG-CSUnet
demonstrates significant improvements over state-of-the-art models, achieving a
1.14% increase in Dice score for Synapse and 0.99% for ACDC, with minimal
computational overhead (only 15 and 30 additional parameters, respectively).
GLoG-CSUnet's flexible design allows integration with various base models,
offering a promising approach for incorporating radiomics-inspired feature
extraction in Transformer architectures for medical image analysis. The code
implementation is available on GitHub at: https://github.com/HAAIL/GLoG-CSUnet.

摘要：<paragraph>視覺轉換器 (ViT) 已在醫療影像語意分割 (MISS) 中展現前景，藉由擷取長程關聯性。然而，ViT 經常難以有效地建模局部空間資訊，這對於精確分割精細解剖細節至關重要，特別是在應用於沒有廣泛預先訓練的小型資料集時。我們引入了高斯卷積 Swin 網路 (GLoG-CSUnet) 的 Gabor 和 Laplacian，這是一種新穎的架構，透過整合可學習的放射特徵來增強基於轉換器的模型。此方法整合了動態自適應 Gabor 和高斯 Laplacian (LoG) 濾波器來擷取紋理、邊緣和邊界資訊，增強轉換器模型處理的特徵表示。我們的模型獨特地結合了轉換器的長程依賴性建模與 Gabor 和 LoG 特徵的紋理分析功能。在 Synapse 多器官和 ACDC 心臟分割資料集上進行評估，GLoG-CSUnet 展示出比最先進的模型有顯著的改進，Synapse 的 Dice 分數增加了 1.14%，ACDC 的 Dice 分數增加了 0.99%，計算負擔極小（分別只有 15 和 30 個額外的參數）。GLoG-CSUnet 的彈性設計允許與各種基礎模型整合，為在轉換器架構中整合放射組學啟發的特徵萃取提供了一個有前景的方法，以進行醫療影像分析。程式碼實作可在 GitHub 上取得：https://github.com/HAAIL/GLoG-CSUnet。</paragraph>

##### **Hybrid deep convolution model for lung cancer detection with transfer learning**
2501.02785v1 by Sugandha Saxena, S. N. Prasad, Ashwin M Polnaya, Shweta Agarwala

Advances in healthcare research have significantly enhanced our understanding
of disease mechanisms, diagnostic precision, and therapeutic options. Yet, lung
cancer remains one of the leading causes of cancer-related mortality worldwide
due to challenges in early and accurate diagnosis. While current lung cancer
detection models show promise, there is considerable potential for further
improving the accuracy for timely intervention. To address this challenge, we
introduce a hybrid deep convolution model leveraging transfer learning, named
the Maximum Sensitivity Neural Network (MSNN). MSNN is designed to improve the
precision of lung cancer detection by refining sensitivity and specificity.
This model has surpassed existing deep learning approaches through experimental
validation, achieving an accuracy of 98% and a sensitivity of 97%. By
overlaying sensitivity maps onto lung Computed Tomography (CT) scans, it
enables the visualization of regions most indicative of malignant or benign
classifications. This innovative method demonstrates exceptional performance in
distinguishing lung cancer with minimal false positives, thereby enhancing the
accuracy of medical diagnoses.

摘要：醫療保健研究的進步顯著增進了我們對疾病機制、診斷精準度和治療選擇的了解。然而，由於早期和準確診斷的挑戰，肺癌仍然是全球癌症相關死亡的主要原因之一。雖然目前的肺癌檢測模型顯示出前景，但仍有相當大的潛力可以進一步提高準確性，以便及時介入。為了應對這一挑戰，我們引入了利用遷移學習的混合深度卷積模型，名為最大敏感度神經網路 (MSNN)。MSNN 旨在透過調整敏感度和特異性來提高肺癌檢測的準確性。此模型已透過實驗驗證超越現有的深度學習方法，達到 98% 的準確度和 97% 的敏感度。透過將敏感度圖疊加到肺部電腦斷層掃描 (CT) 上，它可以視覺化出最能代表惡性或良性分類的區域。這種創新方法在區分肺癌時表現出極佳的效能，且誤判為陽性的情況最少，從而提高了醫療診斷的準確性。

##### **ICFNet: Integrated Cross-modal Fusion Network for Survival Prediction**
2501.02778v1 by Binyu Zhang, Zhu Meng, Junhao Dong, Fei Su, Zhicheng Zhao

Survival prediction is a crucial task in the medical field and is essential
for optimizing treatment options and resource allocation. However, current
methods often rely on limited data modalities, resulting in suboptimal
performance. In this paper, we propose an Integrated Cross-modal Fusion Network
(ICFNet) that integrates histopathology whole slide images, genomic expression
profiles, patient demographics, and treatment protocols. Specifically, three
types of encoders, a residual orthogonal decomposition module and a unification
fusion module are employed to merge multi-modal features to enhance prediction
accuracy. Additionally, a balanced negative log-likelihood loss function is
designed to ensure fair training across different patients. Extensive
experiments demonstrate that our ICFNet outperforms state-of-the-art algorithms
on five public TCGA datasets, including BLCA, BRCA, GBMLGG, LUAD, and UCEC, and
shows its potential to support clinical decision-making and advance precision
medicine. The codes are available at: https://github.com/binging512/ICFNet.

摘要：存活預測是醫學領域的一項關鍵任務，對於優化治療選項和資源分配至關重要。然而，目前的技術通常仰賴有限的數據形式，導致次佳的表現。在本文中，我們提出一個整合式跨形式融合網路 (ICFNet)，它整合了組織病理學全幻燈片影像、基因體表現特徵、病患人口統計資料和治療協定。具體來說，使用三種類型的編碼器、一個殘差正交分解模組和一個統一融合模組，以合併多形式特徵，以增強預測準確度。此外，設計了一個平衡的負對數似然損失函數，以確保不同病患之間的公平訓練。廣泛的實驗證明，我們的 ICFNet 在五個公開的 TCGA 資料集上優於最先進的演算法，包括 BLCA、BRCA、GBMLGG、LUAD 和 UCEC，並展示其支援臨床決策和推動精準醫療的潛力。程式碼可在以下網址取得：https://github.com/binging512/ICFNet。

##### **Tree-based RAG-Agent Recommendation System: A Case Study in Medical Test Data**
2501.02727v1 by Yahe Yang, Chengyue Huang

We present HiRMed (Hierarchical RAG-enhanced Medical Test Recommendation), a
novel tree-structured recommendation system that leverages Retrieval-Augmented
Generation (RAG) for intelligent medical test recommendations. Unlike
traditional vector similarity-based approaches, our system performs medical
reasoning at each tree node through a specialized RAG process. Starting from
the root node with initial symptoms, the system conducts step-wise medical
analysis to identify potential underlying conditions and their corresponding
diagnostic requirements. At each level, instead of simple matching, our
RAG-enhanced nodes analyze retrieved medical knowledge to understand
symptom-disease relationships and determine the most appropriate diagnostic
path. The system dynamically adjusts its recommendation strategy based on
medical reasoning results, considering factors such as urgency levels and
diagnostic uncertainty. Experimental results demonstrate that our approach
achieves superior performance in terms of coverage rate, accuracy, and miss
rate compared to conventional retrieval-based methods. This work represents a
significant advance in medical test recommendation by introducing medical
reasoning capabilities into the traditional tree-based retrieval structure.

摘要：我們提出 HiRMed（分層 RAG 增強型醫療檢測建議），一種新穎的樹狀結構建議系統，它利用檢索增強生成 (RAG) 來進行智能醫療檢測建議。與傳統的基於向量相似性的方法不同，我們的系統通過一個專門的 RAG 程序在每個樹節點執行醫療推理。從具有初始症狀的根節點開始，系統執行逐步醫療分析以識別潛在的潛在疾病及其對應的診斷要求。在每個層級，我們的 RAG 增強節點會分析檢索到的醫療知識，以了解症狀與疾病的關係，並確定最合適的診斷路徑，而不是進行簡單的匹配。系統根據醫療推理結果動態調整其建議策略，考慮緊急程度和診斷不確定性等因素。實驗結果表明，與傳統的基於檢索的方法相比，我們的做法在覆蓋率、準確性和遺漏率方面取得了優異的表現。這項工作通過將醫療推理能力引入傳統的基於樹的檢索結構，代表了醫療檢測建議的重大進展。

##### **Representation Learning of Lab Values via Masked AutoEncoder**
2501.02648v2 by David Restrepo, Chenwei Wu, Yueran Jia, Jaden K. Sun, Jack Gallifant, Catherine G. Bielick, Yugang Jia, Leo A. Celi

Accurate imputation of missing laboratory values in electronic health records
(EHRs) is critical to enable robust clinical predictions and reduce biases in
AI systems in healthcare. Existing methods, such as variational autoencoders
(VAEs) and decision tree-based approaches such as XGBoost, struggle to model
the complex temporal and contextual dependencies in EHR data, mainly in
underrepresented groups. In this work, we propose Lab-MAE, a novel
transformer-based masked autoencoder framework that leverages self-supervised
learning for the imputation of continuous sequential lab values. Lab-MAE
introduces a structured encoding scheme that jointly models laboratory test
values and their corresponding timestamps, enabling explicit capturing temporal
dependencies. Empirical evaluation on the MIMIC-IV dataset demonstrates that
Lab-MAE significantly outperforms the state-of-the-art baselines such as
XGBoost across multiple metrics, including root mean square error (RMSE),
R-squared (R2), and Wasserstein distance (WD). Notably, Lab-MAE achieves
equitable performance across demographic groups of patients, advancing fairness
in clinical predictions. We further investigate the role of follow-up
laboratory values as potential shortcut features, revealing Lab-MAE's
robustness in scenarios where such data is unavailable. The findings suggest
that our transformer-based architecture, adapted to the characteristics of the
EHR data, offers a foundation model for more accurate and fair clinical
imputation models. In addition, we measure and compare the carbon footprint of
Lab-MAE with the baseline XGBoost model, highlighting its environmental
requirements.

摘要：<paragraph>準確估算電子健康記錄 (EHR) 中遺失的實驗室值對於啟用穩健的臨床預測和減少醫療保健中 AI 系統的偏差至關重要。現有方法（例如變異自動編碼器 (VAE) 和基於決策樹的方法，例如 XGBoost）難以建模 EHR 資料中複雜的時間和上下文依賴性，特別是在代表性不足的群組中。在這項工作中，我們提出 Lab-MAE，一個新穎的基於 Transformer 的遮罩自動編碼器框架，它利用自我監督學習來估算連續順序實驗室值。Lab-MAE 引入了一個結構化編碼方案，它聯合建模實驗室測試值及其對應的時間戳，從而能夠明確捕捉時間依賴性。在 MIMIC-IV 資料集上的經驗評估表明，Lab-MAE 在包括均方根誤差 (RMSE)、R 平方 (R2) 和 Wasserstein 距離 (WD) 在內的多項指標上顯著優於 XGBoost 等最先進的基準。值得注意的是，Lab-MAE 在患者的人口統計群組中取得了公平的表現，從而提升了臨床預測中的公平性。我們進一步研究了後續實驗室值作為潛在捷徑特徵的作用，揭示了 Lab-MAE 在此類資料不可用的情況下的穩健性。研究結果表明，我們基於 Transformer 的架構（調整為 EHR 資料的特徵）為更準確和公平的臨床估算模型提供了一個基礎模型。此外，我們測量並比較了 Lab-MAE 與基準 XGBoost 模型的碳足跡，突出了其環境需求。</paragraph>

##### **Trust and Dependability in Blockchain & AI Based MedIoT Applications: Research Challenges and Future Directions**
2501.02647v1 by Ellis Solaiman, Christa Awad

This paper critically reviews the integration of Artificial Intelligence (AI)
and blockchain technologies in the context of Medical Internet of Things
(MedIoT) applications, where they collectively promise to revolutionize
healthcare delivery. By examining current research, we underscore AI's
potential in advancing diagnostics and patient care, alongside blockchain's
capacity to bolster data security and patient privacy. We focus particularly on
the imperative to cultivate trust and ensure reliability within these systems.
Our review highlights innovative solutions for managing healthcare data and
challenges such as ensuring scalability, maintaining privacy, and promoting
ethical practices within the MedIoT domain. We present a vision for integrating
AI-driven insights with blockchain security in healthcare, offering a
comprehensive review of current research and future directions. We conclude
with a set of identified research gaps and propose that addressing these is
crucial for achieving the dependable, secure, and patient -centric MedIoT
applications of tomorrow.

摘要：本文批判性地回顧了人工智慧 (AI) 和區塊鏈技術在醫療物聯網 (MedIoT) 應用中的整合，這兩者共同承諾將徹底改變醫療保健服務。透過檢視目前的研究所，我們強調 AI 在推進診斷和患者照護方面的潛力，以及區塊鏈強化資料安全和患者隱私的能力。我們特別關注在這些系統內培養信任和確保可靠性的必要性。我們的回顧重點在於管理醫療保健資料的創新解決方案，以及確保可擴充性、維護隱私和在 MedIoT 領域內推廣道德實務等挑戰。我們提出一個將 AI 驅動的見解與區塊鏈安全整合在醫療保健中的願景，提供目前的研究所和未來方向的全面回顧。我們以一組已識別的研究差距作為結論，並提出解決這些差距對於達成未來可信賴、安全且以患者為中心的 MedIoT 應用至關重要。

##### **KM-UNet KAN Mamba UNet for medical image segmentation**
2501.02559v1 by Yibo Zhang

Medical image segmentation is a critical task in medical imaging analysis.
Traditional CNN-based methods struggle with modeling long-range dependencies,
while Transformer-based models, despite their success, suffer from quadratic
computational complexity. To address these limitations, we propose KM-UNet, a
novel U-shaped network architecture that combines the strengths of
Kolmogorov-Arnold Networks (KANs) and state-space models (SSMs). KM-UNet
leverages the Kolmogorov-Arnold representation theorem for efficient feature
representation and SSMs for scalable long-range modeling, achieving a balance
between accuracy and computational efficiency. We evaluate KM-UNet on five
benchmark datasets: ISIC17, ISIC18, CVC, BUSI, and GLAS. Experimental results
demonstrate that KM-UNet achieves competitive performance compared to
state-of-the-art methods in medical image segmentation tasks. To the best of
our knowledge, KM-UNet is the first medical image segmentation framework
integrating KANs and SSMs. This work provides a valuable baseline and new
insights for the development of more efficient and interpretable medical image
segmentation systems. The code is open source at
https://github.com/2760613195/KM_UNet
  Keywords:KAN,Manba, state-space models,UNet, Medical image segmentation, Deep
learning

摘要：醫學影像分割在醫學影像分析中是一項重要的任務。
傳統基於 CNN 的方法難以模擬長距離依賴性，
而基於 Transformer 的模型儘管成功，卻有二次計算複雜度的問題。為了解決這些限制，我們提出了 KM-UNet，這是一種新穎的 U 形網路架構，結合了 Kolmogorov-Arnold 網路 (KANs) 和狀態空間模型 (SSM) 的優點。KM-UNet 利用 Kolmogorov-Arnold 表示定理進行高效特徵表示，利用 SSM 進行可擴充長距離模擬，在準確度和計算效率之間取得平衡。我們在五個基準資料集上評估 KM-UNet：ISIC17、ISIC18、CVC、BUSI 和 GLAS。實驗結果表明，與醫學影像分割任務中的最先進方法相比，KM-UNet 達到了有競爭力的效能。據我們所知，KM-UNet 是第一個整合 KAN 和 SSM 的醫學影像分割框架。這項工作為開發更有效率且可解釋的醫學影像分割系統提供了有價值的基線和新見解。程式碼在 https://github.com/2760613195/KM_UNet 開源
關鍵字：KAN、Manba、狀態空間模型、UNet、醫學影像分割、深度學習

##### **Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine**
2501.02471v1 by Yishen Liu, Shengda Luo, Zishao Zhong, Tongtong Wu, Jianguo Zhang, Peiyao Ou, Yong Liang, Liang Liu, Hudan Pan

Large language models (LLMs) primarily trained on English texts, often face
biases and inaccuracies in Chinese contexts. Their limitations are pronounced
in fields like Traditional Chinese Medicine (TCM), where cultural and clinical
subtleties are vital, further hindered by a lack of domain-specific data, such
as rheumatoid arthritis (RA). To address these issues, this paper introduces
Hengqin-RA-v1, the first large language model specifically tailored for TCM
with a focus on diagnosing and treating RA. We also present HQ-GCM-RA-C1, a
comprehensive RA-specific dataset curated from ancient Chinese medical
literature, classical texts, and modern clinical studies. This dataset empowers
Hengqin-RA-v1 to deliver accurate and culturally informed responses,
effectively bridging the gaps left by general-purpose models. Extensive
experiments demonstrate that Hengqin-RA-v1 outperforms state-of-the-art models,
even surpassing the diagnostic accuracy of TCM practitioners in certain cases.

摘要：大型語言模型（LLM）主要以英文文本進行訓練，在中文語境中經常面臨偏見和不準確的問題。它們的局限性在中醫等領域尤為明顯，因為中醫涉及文化和臨床上的微妙之處，而且還缺乏特定領域的數據，例如類風濕關節炎（RA）。為了解決這些問題，本文介紹了 Hengqin-RA-v1，這是第一個專門針對中醫的大型語言模型，重點是診斷和治療 RA。我們還提供了 HQ-GCM-RA-C1，這是一個從古代中醫文獻、古典文本和現代臨床研究中整理出來的、全面的 RA 特定數據集。這個數據集讓 Hengqin-RA-v1 能夠提供準確且符合文化背景的回應，有效地彌補了通用模型留下的空白。大量的實驗表明，Hengqin-RA-v1 優於最先進的模型，在某些情況下甚至超過了中醫從業者的診斷準確性。

##### **Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales**
2501.02451v1 by Zijie Cheng, Boxuan Li, André Altmann, Pearse A Keane, Yukun Zhou

Contrastive learning, a prominent approach within self-supervised learning,
has demonstrated significant effectiveness in developing generalizable models
for various applications involving natural images. However, recent research
indicates that these successes do not necessarily extend to the medical imaging
domain. In this paper, we investigate the reasons for this suboptimal
performance and hypothesize that the dense distribution of medical images poses
challenges to the pretext tasks in contrastive learning, particularly in
constructing positive and negative pairs. We explore model performance under
different augmentation strategies and compare the results to those achieved
with strong augmentations. Our study includes six publicly available datasets
covering multiple clinically relevant tasks. We further assess the model's
generalizability through external evaluations. The model pre-trained with weak
augmentation outperforms those with strong augmentation, improving AUROC from
0.838 to 0.848 and AUPR from 0.523 to 0.597 on MESSIDOR2, and showing similar
enhancements across other datasets. Our findings suggest that optimizing the
scale of augmentation is critical for enhancing the efficacy of contrastive
learning in medical imaging.

摘要：對比學習是自監督學習中一種重要的方法，在涉及自然影像的各種應用中，已展現出顯著的有效性，可開發出可概化的模型。然而，最近的研究指出，這些成功並未必然延伸至醫學影像領域。在本文中，我們探討造成這種次佳效能的原因，並假設醫學影像的密集分佈對比學習中的藉口任務造成挑戰，特別是在建構正負對時。我們在不同的擴充策略下探討模型效能，並將結果與強擴充所達成的結果進行比較。我們的研究涵蓋六個公開可用的資料集，涵蓋多項臨床相關任務。我們進一步透過外部評估來評估模型的可概化性。使用弱擴充進行預訓練的模型優於使用強擴充的模型，在 MESSIDOR2 上將 AUROC 從 0.838 提升至 0.848，將 AUPR 從 0.523 提升至 0.597，並在其他資料集上展現類似的提升。我們的研究結果顯示，最佳化擴充規模對於提升對比學習在醫學影像中的效能至關重要。

##### **Enhancing Workplace Productivity and Well-being Using AI Agent**
2501.02368v1 by Ravirajan K, Arvind Sundarajan

This paper discusses the use of Artificial Intelligence (AI) to enhance
workplace productivity and employee well-being. By integrating machine learning
(ML) techniques with neurobiological data, the proposed approaches ensure
alignment with human ethical standards through value alignment models and
Hierarchical Reinforcement Learning (HRL) for autonomous task management. The
system utilizes biometric feedback from employees to generate personalized
health prompts, fostering a supportive work environment that encourages
physical activity. Additionally, we explore decentralized multi-agent systems
for improved collaboration and decision-making frameworks that enhance
transparency. Various approaches using ML techniques in conjunction with AI
implementations are discussed. Together, these innovations aim to create a more
productive and health-conscious workplace. These outcomes assist HR management
and organizations in launching more rational career progression streams for
employees and facilitating organizational transformation.

摘要：本文探討利用人工智慧（AI）來提升職場生產力和員工福祉。透過將機器學習（ML）技術與神經生物學資料整合，所提出的方法確保透過價值對齊模型和用於自主任務管理的分層強化學習（HRL）與人類倫理標準保持一致。該系統利用員工的生物特徵回饋來產生個人化健康提示，營造支持性的工作環境，鼓勵身體活動。此外，我們探討分散式多智能體系統，以改善協作和決策制定架構，進而提升透明度。本文討論了各種結合 ML 技術與 AI 實作的方法。總而言之，這些創新旨在創造一個更具生產力且注重健康的職場。這些成果有助於人力資源管理和組織機構為員工啟動更合理的職涯發展管道，並促進組織轉型。

##### **Exploring the Capabilities and Limitations of Large Language Models for Radiation Oncology Decision Support**
2501.02346v1 by Florian Putz, Marlen Haderleina, Sebastian Lettmaier, Sabine Semrau, Rainer Fietkau, Yixing Huang

Thanks to the rapidly evolving integration of LLMs into decision-support
tools, a significant transformation is happening across large-scale systems.
Like other medical fields, the use of LLMs such as GPT-4 is gaining increasing
interest in radiation oncology as well. An attempt to assess GPT-4's
performance in radiation oncology was made via a dedicated 100-question
examination on the highly specialized topic of radiation oncology physics,
revealing GPT-4's superiority over other LLMs. GPT-4's performance on a broader
field of clinical radiation oncology is further benchmarked by the ACR
Radiation Oncology In-Training (TXIT) exam where GPT-4 achieved a high accuracy
of 74.57%. Its performance on re-labelling structure names in accordance with
the AAPM TG-263 report has also been benchmarked, achieving above 96%
accuracies. Such studies shed light on the potential of LLMs in radiation
oncology. As interest in the potential and constraints of LLMs in general
healthcare applications continues to rise5, the capabilities and limitations of
LLMs in radiation oncology decision support have not yet been fully explored.

摘要：隨著 LLM 快速演進整合到決策支援工具中，大規模系統正在發生重大轉變。
與其他醫療領域一樣，LLM（例如 GPT-4）的使用也在放射腫瘤學中獲得越來越多的興趣。透過針對放射腫瘤學物理學這個高度專業的主題進行 100 題專門考試，試圖評估 GPT-4 在放射腫瘤學中的表現，揭示了 GPT-4 優於其他 LLM。GPT-4 在更廣泛的臨床放射腫瘤學領域的表現進一步由 ACR 放射腫瘤學在職訓練 (TXIT) 考試進行評量，GPT-4 在其中取得 74.57% 的高準確度。它根據 AAPM TG-263 報告重新標記結構名稱的表現也已進行評量，準確度達到 96% 以上。這些研究揭示了 LLM 在放射腫瘤學中的潛力。由於人們持續對 LLM 在一般醫療保健應用中的潛力和限制感興趣5，LLM 在放射腫瘤學決策支援中的功能和限制尚未得到充分探索。

##### **Deep Learning-Driven Segmentation of Ischemic Stroke Lesions Using Multi-Channel MRI**
2501.02287v1 by Ashiqur Rahman, Muhammad E. H. Chowdhury, Md Sharjis Ibne Wadud, Rusab Sarmun, Adam Mushtak, Sohaib Bassam Zoghoul, Israa Al-Hashimi

Ischemic stroke, caused by cerebral vessel occlusion, presents substantial
challenges in medical imaging due to the variability and subtlety of stroke
lesions. Magnetic Resonance Imaging (MRI) plays a crucial role in diagnosing
and managing ischemic stroke, yet existing segmentation techniques often fail
to accurately delineate lesions. This study introduces a novel deep
learning-based method for segmenting ischemic stroke lesions using
multi-channel MRI modalities, including Diffusion Weighted Imaging (DWI),
Apparent Diffusion Coefficient (ADC), and enhanced Diffusion Weighted Imaging
(eDWI). The proposed architecture integrates DenseNet121 as the encoder with
Self-Organized Operational Neural Networks (SelfONN) in the decoder, enhanced
by Channel and Space Compound Attention (CSCA) and Double
Squeeze-and-Excitation (DSE) blocks. Additionally, a custom loss function
combining Dice Loss and Jaccard Loss with weighted averages is introduced to
improve model performance. Trained and evaluated on the ISLES 2022 dataset, the
model achieved Dice Similarity Coefficients (DSC) of 83.88% using DWI alone,
85.86% with DWI and ADC, and 87.49% with the integration of DWI, ADC, and eDWI.
This approach not only outperforms existing methods but also addresses key
limitations in current segmentation practices. These advancements significantly
enhance diagnostic precision and treatment planning for ischemic stroke,
providing valuable support for clinical decision-making.

摘要：缺血性中風是由腦血管阻塞所引起，由於中風病灶的可變性和隱蔽性，在醫學影像中造成相當大的挑戰。磁振造影 (MRI) 在診斷和治療缺血性中風中扮演至關重要的角色，但現有的分割技術常常無法準確地描繪病灶。本研究提出一個新的深度學習方法，使用多通道 MRI 模式對缺血性中風病灶進行分割，包括擴散加權影像 (DWI)、表觀擴散係數 (ADC) 和增強型擴散加權影像 (eDWI)。所提出的架構將 DenseNet121 整合為編碼器，並在解碼器中使用自組織運算神經網路 (SelfONN)，並由通道和空間複合注意力 (CSCA) 和雙重擠壓激勵 (DSE) 區塊進行加強。此外，還引進了一個自訂的損失函數，結合了 Dice 損失和 Jaccard 損失以及加權平均，以提升模型效能。在 ISLES 2022 資料集上進行訓練和評估，該模型使用 DWI 單獨時達到 83.88% 的 Dice 相似性係數 (DSC)，使用 DWI 和 ADC 時達到 85.86%，使用 DWI、ADC 和 eDWI 整合時達到 87.49%。這種方法不僅優於現有方法，還能解決當前分割實務中的主要限制。這些進展顯著提升了缺血性中風的診斷精準度和治療規劃，為臨床決策提供有價值的支援。

##### **The Integration of Blockchain and Artificial Intelligence for Secure Healthcare Systems**
2501.02169v1 by Umar Safdar, Simon Gabrael

Verisign reported a 125 percent increase in data breaches within the
healthcare sector in the United States during 2022, with 18.2 million patient
records being impacted. Growing healthcare data volumes and diversification
mean that medical information is becoming more valuable. Many Health Centers
use various technologies to ease the classification, storage, and exchange of
big data. This use can also make the health data of the users at risk and
vulnerable. AI and blockchain are among the leading technologies at hand. With
AI, data-driven operations and big data efficiency have been improved with
respect to traditional techniques. Due to its potential to bring about
improvements in health services and lower medical costs, this AI technology is
regularly used in healthcare. Blockchain helps protect transactions on sharing
information and private privacy as long as the exchange of knowledge is that of
the standard. The objective of this analysis is to investigate the research and
unique contributions since 2008 regarding blockchain-integrated AI and
healthcare systems. The work sheds light on applied AI-based healthcare schemes
with machine, ballistic, and acrylic learning and disparate blockchain
structures. The use of technology in order to ensure patient data security and
manage medical information effectively in healthcare settings offers a highly
successful position for both healthcare providers and patients. From 2018 to
2021, the best year was 2021 to grow, enhancing everything to examine the
download of the device and the counting of Google Academies, for which the
joining perspective was borrowed; local research experts were asked, identified
articles in recent years, and read reviews of large research grants.

摘要：Verisign 報告 2022 年美國醫療保健部門的資料外洩事件增加了 125%，影響了 1,820 萬筆病歷。醫療保健資料量不斷增加且多元化，這表示醫療資訊變得更有價值。許多醫療中心使用各種技術，以簡化大數據的分類、儲存和交換。這種使用方式也可能使使用者的健康資料面臨風險和脆弱性。人工智慧和區塊鏈是現有的領先技術。透過人工智慧，資料驅動的運作和大數據效率已相較於傳統技術獲得改善。由於人工智慧技術有潛力改善醫療服務並降低醫療成本，因此經常在醫療保健中使用。區塊鏈有助於保護交易，在資訊共享和隱私方面，只要知識的交換是標準的。本分析的目標是調查自 2008 年以來與區塊鏈整合人工智慧和醫療保健系統相關的研究和獨特貢獻。這項工作闡明了應用人工智慧為基礎的醫療保健計畫，包括機器、彈道和丙烯酸學習以及不同的區塊鏈結構。為了確保病患資料安全並在醫療保健環境中有效管理醫療資訊，使用技術為醫療保健提供者和病患提供了極為成功的定位。從 2018 年到 2021 年，最適合成長的是 2021 年，加強所有一切，以檢查裝置的下載和 Google 學術的計數，借用了加入的觀點；詢問了當地研究專家，找出近年來的文章，並閱讀大型研究補助金的評論。

##### **Online Detection of Water Contamination Under Concept Drift**
2501.02107v1 by Jin Li, Kleanthis Malialis, Stelios G. Vrachimis, Marios M. Polycarpou

Water Distribution Networks (WDNs) are vital infrastructures, and
contamination poses serious public health risks. Harmful substances can
interact with disinfectants like chlorine, making chlorine monitoring essential
for detecting contaminants. However, chlorine sensors often become unreliable
and require frequent calibration. This study introduces the Dual-Threshold
Anomaly and Drift Detection (AD&DD) method, an unsupervised approach combining
a dual-threshold drift detection mechanism with an LSTM-based Variational
Autoencoder(LSTM-VAE) for real-time contamination detection. Tested on two
realistic WDNs, AD&DD effectively identifies anomalies with sensor offsets as
concept drift, and outperforms other methods. A proposed decentralized
architecture enables accurate contamination detection and localization by
deploying AD&DD on selected nodes.

摘要：配水網路 (WDN) 是重要的基礎設施，而污染會造成嚴重的公共衛生風險。有害物質可能會與消毒劑（如氯氣）交互作用，因此監測氯氣對於偵測污染物至關重要。然而，氯氣感測器常常變得不可靠，需要頻繁校正。本研究提出雙閾值異常與漂移偵測 (AD&DD) 方法，這是一種非監督式方法，結合雙閾值漂移偵測機制與基於 LSTM 的變異自動編碼器 (LSTM-VAE)，用於即時污染偵測。在兩個實際的 WDN 上進行測試，AD&DD 能有效地將感測器偏移視為概念漂移，並優於其他方法。所提出的分散式架構能透過在選定的節點部署 AD&DD，實現精確的污染偵測與定位。

##### **METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring**
2501.02045v1 by Ollie Liu, Sami Jaghouar, Johannes Hagemann, Shangshang Wang, Jason Wiemels, Jeff Kaufman, Willie Neiswanger

We pretrain METAGENE-1, a 7-billion-parameter autoregressive transformer
model, which we refer to as a metagenomic foundation model, on a novel corpus
of diverse metagenomic DNA and RNA sequences comprising over 1.5 trillion base
pairs. This dataset is sourced from a large collection of human wastewater
samples, processed and sequenced using deep metagenomic (next-generation)
sequencing methods. Unlike genomic models that focus on individual genomes or
curated sets of specific species, the aim of METAGENE-1 is to capture the full
distribution of genomic information present within this wastewater, to aid in
tasks relevant to pandemic monitoring and pathogen detection. We carry out
byte-pair encoding (BPE) tokenization on our dataset, tailored for metagenomic
sequences, and then pretrain our model. In this paper, we first detail the
pretraining dataset, tokenization strategy, and model architecture,
highlighting the considerations and design choices that enable the effective
modeling of metagenomic data. We then show results of pretraining this model on
our metagenomic dataset, providing details about our losses, system metrics,
and training stability over the course of pretraining. Finally, we demonstrate
the performance of METAGENE-1, which achieves state-of-the-art results on a set
of genomic benchmarks and new evaluations focused on human-pathogen detection
and genomic sequence embedding, showcasing its potential for public health
applications in pandemic monitoring, biosurveillance, and early detection of
emerging health threats.

摘要：<paragraph>我們預訓練了一個具有 70 億個參數的自迴歸轉換器模型 METAGENE-1，我們稱之為宏基因組基礎模型，它建立在一個新穎的語料庫上，其中包含超過 1.5 兆個鹼基對的多樣化宏基因組 DNA 和 RNA 序列。此數據集來自大量人類廢水樣本，使用深度宏基因組（下一代）定序方法進行處理和定序。與專注於個別基因組或特定物種策劃集合的基因組模型不同，METAGENE-1 的目標是擷取此廢水中存在的基因組資訊的完整分佈，以協助與大流行監測和病原體檢測相關的任務。我們對數據集執行針對宏基因組序列量身打造的位元組對編碼 (BPE) 標記化，然後預訓練我們的模型。在本文中，我們首先詳細說明預訓練數據集、標記化策略和模型架構，重點說明能有效建模宏基因組數據的考量和設計選擇。然後，我們展示了在我們的宏基因組數據集上預訓練此模型的結果，提供有關我們的損失、系統指標和在預訓練過程中訓練穩定性的詳細資訊。最後，我們展示了 METAGENE-1 的效能，它在針對人類病原體檢測和基因組序列嵌入的一組基因組基準和新評估中達到了最先進的結果，展示了其在公共衛生應用中的潛力，包括大流行監測、生物監控和新興健康威脅的早期檢測。</paragraph>

##### **Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT**
2501.02044v1 by Jianping He, Laila Rasmy, Degui Zhi, Cui Tao

Background: Recently, numerous foundation models pretrained on extensive data
have demonstrated efficacy in disease prediction using Electronic Health
Records (EHRs). However, there remains some unanswered questions on how to best
utilize such models especially with very small fine-tuning cohorts. Methods: We
utilized Med-BERT, an EHR-specific foundation model, and reformulated the
disease binary prediction task into a token prediction task and a next visit
mask token prediction task to align with Med-BERT's pretraining task format in
order to improve the accuracy of pancreatic cancer (PaCa) prediction in both
few-shot and fully supervised settings. Results: The reformulation of the task
into a token prediction task, referred to as Med-BERT-Sum, demonstrates
slightly superior performance in both few-shot scenarios and larger data
samples. Furthermore, reformulating the prediction task as a Next Visit Mask
Token Prediction task (Med-BERT-Mask) significantly outperforms the
conventional Binary Classification (BC) prediction task (Med-BERT-BC) by 3% to
7% in few-shot scenarios with data sizes ranging from 10 to 500 samples. These
findings highlight that aligning the downstream task with Med-BERT's
pretraining objectives substantially enhances the model's predictive
capabilities, thereby improving its effectiveness in predicting both rare and
common diseases. Conclusion: Reformatting disease prediction tasks to align
with the pretraining of foundation models enhances prediction accuracy, leading
to earlier detection and timely intervention. This approach improves treatment
effectiveness, survival rates, and overall patient outcomes for PaCa and
potentially other cancers.

摘要：背景：最近，大量基于广泛数据进行预训练的基础模型已证明在使用电子健康记录 (EHR) 预测疾病方面有效。然而，关于如何最好地利用此类模型（尤其是在极小微调队列中）仍有一些未解决的问题。方法：我们利用了 EHR 特定的基础模型 Med-BERT，并将疾病二元预测任务重新表述为标记预测任务和下次访问掩码标记预测任务，以与 Med-BERT 的预训练任务格式保持一致，从而提高胰腺癌 (PaCa) 预测的准确性，无论是在小样本还是完全监督的设置中。结果：将任务重新表述为标记预测任务（称为 Med-BERT-Sum），在小样本场景和较大数据样本中均表现出略微优越的性能。此外，将预测任务重新表述为下一次访问掩码标记预测任务（Med-BERT-Mask）在小样本场景中明显优于传统的二元分类 (BC) 预测任务（Med-BERT-BC），数据大小从 10 到 500 个样本不等，优越幅度为 3% 到 7%。这些发现强调，将下游任务与 Med-BERT 的预训练目标保持一致，可以显着增强模型的预测能力，从而提高其预测罕见疾病和常见疾病的有效性。结论：重新格式化疾病预测任务以与基础模型的预训练保持一致，可提高预测准确性，从而实现早期检测和及时干预。这种方法提高了 PaCa 和其他癌症的治疗效果、存活率和患者总体预后。

##### **Combined Hyper-Extensible Extremely-Secured Zero-Trust CIAM-PAM architecture**
2501.01732v1 by Shivom Aggarwal, Shourya Mehra, Safeer Sathar

Customer Identity and Access Management (CIAM) systems play a pivotal role in
securing enterprise infrastructures. However, the complexity of implementing
these systems requires careful architectural planning to ensure positive Return
on Investment (RoI) and avoid costly delays. The proliferation of Active
Persistent cyber threats, coupled with advancements in AI, cloud computing, and
geographically distributed customer populations, necessitates a paradigm shift
towards adaptive and zero-trust security frameworks. This paper introduces the
Combined Hyper-Extensible Extremely-Secured Zero-Trust (CHEZ) CIAM-PAM
architecture, designed specifically for large-scale enterprises. The CHEZ PL
CIAM-PAM framework addresses critical security gaps by integrating federated
identity management (private and public identities), password-less
authentication, adaptive multi-factor authentication (MFA), microservice-based
PEP (Policy Entitlement Point), multi-layer RBAC (Role Based Access Control)
and multi-level trust systems. This future-proof design also includes
end-to-end data encryption, and seamless integration with state-of-the-art
AI-based threat detection systems, while ensuring compliance with stringent
regulatory standards.

摘要：客戶身分與存取管理 (CIAM) 系統在確保企業基礎設施安全方面扮演著關鍵角色。然而，實作這些系統的複雜性需要仔細的架構規劃，以確保投資報酬率 (RoI) 為正，並避免成本高昂的延誤。主動持續的網路威脅的擴散，加上人工智慧、雲端運算和地理分布的客戶群的進步，需要朝向適應性和零信任安全架構轉變。本文介紹專為大型企業設計的 Combined Hyper-Extensible Extremely-Secured Zero-Trust (CHEZ) CIAM-PAM 架構。CHEZ PL CIAM-PAM 架構透過整合聯合身分管理（私人和公用身分）、無密碼驗證、適應性多重身分驗證 (MFA)、基於微服務的 PEP（政策授權點）、多層 RBAC（基於角色的存取控制）和多層級信任系統來解決關鍵的安全漏洞。這種具備未來性的設計也包含端對端資料加密，並與最先進的基於人工智慧的威脅偵測系統無縫整合，同時確保符合嚴格的法規標準。

##### **EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical image segmentation**
2501.01658v1 by Wang Lituan, Zhang Lei, Wang Yan, Wang Zhenbin, Zhang Zhenwei, Zhang Yi

Weakly-supervised medical image segmentation is gaining traction as it
requires only rough annotations rather than accurate pixel-to-pixel labels,
thereby reducing the workload for specialists. Although some progress has been
made, there is still a considerable performance gap between the label-efficient
methods and fully-supervised one, which can be attributed to the uncertainty
nature of these weak labels. To address this issue, we propose a novel weak
annotation method coupled with its learning framework EAUWSeg to eliminate the
annotation uncertainty. Specifically, we first propose the Bounded Polygon
Annotation (BPAnno) by simply labeling two polygons for a lesion. Then, the
tailored learning mechanism that explicitly treat bounded polygons as two
separated annotations is proposed to learn invariant feature by providing
adversarial supervision signal for model training. Subsequently, a
confidence-auxiliary consistency learner incorporates with a
classification-guided confidence generator is designed to provide reliable
supervision signal for pixels in uncertain region by leveraging the feature
presentation consistency across pixels within the same category as well as
class-specific information encapsulated in bounded polygons annotation.
Experimental results demonstrate that EAUWSeg outperforms existing
weakly-supervised segmentation methods. Furthermore, compared to
fully-supervised counterparts, the proposed method not only delivers superior
performance but also costs much less annotation workload. This underscores the
superiority and effectiveness of our approach.

摘要：弱监督医学影像分割正获得关注，因为它只需要粗略的注释，而不是精确的像素到像素标签，从而减少了专家的工作量。尽管取得了一些进展，但在标签高效方法和完全监督方法之间仍然存在相当大的性能差距，这可归因于这些弱标签的不确定性。为了解决这个问题，我们提出了一种新的弱注释方法，并结合其学习框架 EAUWSeg 来消除注释的不确定性。具体来说，我们首先通过简单地为病灶标记两个多边形来提出有界多边形注释 (BPAnno)。然后，提出了将有界多边形明确地视为两个分离注释的定制学习机制，以通过为模型训练提供对抗性监督信号来学习不变特征。随后，置信辅助一致性学习器与分类引导置信度生成器结合设计，以通过利用同一类别内像素的特征表示一致性以及有界多边形注释中封装的特定于类的信息，为不确定区域中的像素提供可靠的监督信号。实验结果表明，EAUWSeg 优于现有的弱监督分割方法。此外，与完全监督的对应方法相比，所提出的方法不仅提供了卓越的性能，而且注释工作量也大大减少。这突出了我们方法的优越性和有效性。

##### **Implications of Artificial Intelligence on Health Data Privacy and Confidentiality**
2501.01639v2 by Ahmad Momani

The rapid integration of artificial intelligence (AI) in healthcare is
revolutionizing medical diagnostics, personalized medicine, and operational
efficiency. However, alongside these advancements, significant challenges arise
concerning patient data privacy, ethical considerations, and regulatory
compliance. This paper examines the dual impact of AI on healthcare,
highlighting its transformative potential and the critical need for
safeguarding sensitive health information. It explores the role of the Health
Insurance Portability and Accountability Act (HIPAA) as a regulatory framework
for ensuring data privacy and security, emphasizing the importance of robust
safeguards and ethical standards in AI-driven healthcare. Through case studies,
including AI applications in diabetic retinopathy, oncology, and the
controversies surrounding data sharing, this study underscores the ethical and
legal complexities of AI implementation. A balanced approach that fosters
innovation while maintaining patient trust and privacy is imperative. The
findings emphasize the importance of continuous education, transparency, and
adherence to regulatory frameworks to harness AI's full potential responsibly
and ethically in healthcare.

摘要：人工智慧 (AI) 在醫療保健領域的快速整合，正在徹底變革醫療診斷、個人化醫療和營運效率。然而，隨著這些進步，也出現了關於患者資料隱私、倫理考量和法規遵循的重大挑戰。本文探討了 AI 對醫療保健的雙重影響，強調其轉型潛力以及保護敏感健康資訊的關鍵需求。本文探討了健康保險可攜性和責任法案 (HIPAA) 作為確保資料隱私和安全的法規架構的角色，強調在 AI 驅動的醫療保健中健全保障措施和道德標準的重要性。本研究透過案例研究，包括 AI 在糖尿病視網膜病變、腫瘤學中的應用，以及圍繞資料共享的爭議，強調了 AI 實施的倫理和法律複雜性。一種平衡的方法，在促進創新的同時，維護患者的信任和隱私，至關重要。研究結果強調了持續教育、透明度和遵守法規框架的重要性，以負責任且合乎道德的方式利用 AI 在醫療保健中的全部潛力。

##### **Merging Context Clustering with Visual State Space Models for Medical Image Segmentation**
2501.01618v1 by Yun Zhu, Dong Zhang, Yi Lin, Yifei Feng, Jinhui Tang

Medical image segmentation demands the aggregation of global and local
feature representations, posing a challenge for current methodologies in
handling both long-range and short-range feature interactions. Recently, vision
mamba (ViM) models have emerged as promising solutions for addressing model
complexities by excelling in long-range feature iterations with linear
complexity. However, existing ViM approaches overlook the importance of
preserving short-range local dependencies by directly flattening spatial tokens
and are constrained by fixed scanning patterns that limit the capture of
dynamic spatial context information. To address these challenges, we introduce
a simple yet effective method named context clustering ViM (CCViM), which
incorporates a context clustering module within the existing ViM models to
segment image tokens into distinct windows for adaptable local clustering. Our
method effectively combines long-range and short-range feature interactions,
thereby enhancing spatial contextual representations for medical image
segmentation tasks. Extensive experimental evaluations on diverse public
datasets, i.e., Kumar, CPM17, ISIC17, ISIC18, and Synapse demonstrate the
superior performance of our method compared to current state-of-the-art
methods. Our code can be found at https://github.com/zymissy/CCViM.

摘要：醫療影像分割需要聚合全局和局部特徵表示，對當前方法處理長程和短程特徵交互構成挑戰。最近，視覺曼巴 (ViM) 模型已成為解決模型複雜性的有前途的解決方案，它在線性複雜度下擅長長程特徵迭代。然而，現有的 ViM 方法忽視了透過直接壓平空間標記來保留短程局部依賴性的重要性，並且受到限制的掃描模式的約束，這會限制動態空間背景資訊的擷取。為了解決這些挑戰，我們引入了一種名為背景聚類 ViM (CCViM) 的簡單但有效的方法，它在現有的 ViM 模型中加入了一個背景聚類模組，將影像標記分割成不同的視窗，以進行適應性局部聚類。我們的模型有效地結合了長程和短程特徵交互，從而增強了用於醫療影像分割任務的空間背景表示。在各種公開資料集（即 Kumar、CPM17、ISIC17、ISIC18 和 Synapse）上進行的廣泛實驗評估證明了我們的方法與當前最先進方法相比具有卓越的效能。我們的程式碼可以在 https://github.com/zymissy/CCViM 找到。

##### **PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents**
2501.01594v1 by Jingoo Lee, Kyungho Lim, Young-Chul Jung, Byung-Hoon Kim

Recent advances in large language models (LLMs) have accelerated the
development of conversational agents capable of generating human-like
responses. Since psychiatric assessments typically involve complex
conversational interactions between psychiatrists and patients, there is
growing interest in developing LLM-based psychiatric assessment conversational
agents (PACAs) that aim to simulate the role of psychiatrists in clinical
evaluations. However, standardized methods for benchmarking the clinical
appropriateness of PACAs' interaction with patients still remain underexplored.
Here, we propose PSYCHE, a novel framework designed to enable the 1) clinically
relevant, 2) ethically safe, 3) cost-efficient, and 4) quantitative evaluation
of PACAs. This is achieved by simulating psychiatric patients based on a
multi-faceted psychiatric construct that defines the simulated patients'
profiles, histories, and behaviors, which PACAs are expected to assess. We
validate the effectiveness of PSYCHE through a study with 10 board-certified
psychiatrists, supported by an in-depth analysis of the simulated patient
utterances.

摘要：大型語言模型 (LLM) 的最新進展加速了會話代理的開發，這些代理能夠產生類似人類的回應。由於精神科評估通常涉及精神科醫師和患者之間複雜的會話互動，因此對於開發基於 LLM 的精神科評估會話代理 (PACA) 的興趣與日俱增，這些代理旨在模擬精神科醫師在臨床評估中的角色。然而，用於評量 PACA 與患者互動的臨床適當性的標準化方法仍未被充分探討。在此，我們提出 PSYCHE，一個新穎的框架，旨在實現 1) 臨床相關、2) 道德安全、3) 成本效益，以及 4) PACA 的定量評估。這是透過模擬基於多面向精神科建構的精神科患者來實現的，該建構定義了模擬患者的個人資料、病史和行為，而 PACA 預計會評估這些內容。我們透過一項有 10 位經認證的精神科醫師參與的研究驗證了 PSYCHE 的有效性，並輔以對模擬患者話語的深入分析。

##### **Model Checking in Medical Imaging for Tumor Detection and Segmentation**
2501.02024v2 by Elhoucine Elfatimi, Lahcen El fatimi

Recent advancements in model checking have demonstrated significant potential
across diverse applications, particularly in signal and image analysis. Medical
imaging stands out as a critical domain where model checking can be effectively
applied to design and evaluate robust frameworks. These frameworks facilitate
automatic and semi-automatic delineation of regions of interest within images,
aiding in accurate segmentation. This paper provides a comprehensive analysis
of recent works leveraging spatial logic to develop operators and tools for
identifying regions of interest, including tumorous and non-tumorous areas.
Additionally, we examine the challenges inherent to spatial model-checking
techniques, such as variability in ground truth data and the need for
streamlined procedures suitable for routine clinical practice.

摘要：近來模型檢定的進展顯示出在各種應用中具有顯著的潛力，特別是在訊號和影像分析中。醫療成像作為一個關鍵領域，模型檢定可以有效地應用於設計和評估穩健的架構。這些架構有助於自動和半自動地描繪影像中的感興趣區域，有助於準確的分割。本文對近來利用空間邏輯開發運算子和工具以識別感興趣區域（包括腫瘤和非腫瘤區域）的相關研究進行了全面的分析。此外，我們探討了空間模型檢定技術固有的挑戰，例如基本事實資料的可變性以及對適合常規臨床實務的簡化程序的需求。

##### **Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**
2501.01377v1 by Yucheng Zhou, Lingran Song, Jianbing Shen

Existing Medical Large Vision-Language Models (Med-LVLMs), which encapsulate
extensive medical knowledge, demonstrate excellent capabilities in
understanding medical images and responding to human queries based on these
images. However, there remain challenges in visual localization in medical
images, which is crucial for abnormality detection and interpretation. To
address these issues, we propose a novel UMed-LVLM designed with Unveiling
Medical abnormalities. Specifically, we collect a Medical Abnormalities
Unveiling (MAU) dataset and propose a two-stage training method for UMed-LVLM
training. To collect MAU dataset, we propose a prompt method utilizing the
GPT-4V to generate diagnoses based on identified abnormal areas in medical
images. Moreover, the two-stage training method includes Abnormal-Aware
Instruction Tuning and Abnormal-Aware Rewarding, comprising Abnormal
Localization Rewarding and Vision Relevance Rewarding. Experimental results
demonstrate that our UMed-LVLM surpasses existing Med-LVLMs in identifying and
understanding medical abnormality. In addition, this work shows that enhancing
the abnormality detection capabilities of Med-LVLMs significantly improves
their understanding of medical images and generalization capability.

摘要：現有的醫療大型視覺語言模型 (Med-LVLMs) 封裝了廣泛的醫療知識，在理解醫療影像和根據這些影像回應人類查詢方面表現出色的能力。然而，在醫療影像中進行視覺定位仍存在挑戰，這對於異常偵測和解讀至關重要。為了解決這些問題，我們提出了一種新穎的 UMed-LVLM，其設計用於揭示醫療異常。具體來說，我們收集了一個醫療異常揭示 (MAU) 資料集，並為 UMed-LVLM 訓練提出了一個兩階段訓練方法。為了收集 MAU 資料集，我們提出了一種提示方法，利用 GPT-4V 根據醫療影像中識別出的異常區域生成診斷。此外，兩階段訓練方法包括異常感知指導調整和異常感知獎勵，包括異常定位獎勵和視覺相關性獎勵。實驗結果表明，我們的 UMed-LVLM 在識別和理解醫療異常方面優於現有的 Med-LVLMs。此外，這項工作表明，增強 Med-LVLMs 的異常偵測能力可以顯著提升它們對醫療影像的理解和泛化能力。

##### **ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**
2501.01372v1 by Neda Tavakoli, Amir Ali Rahsepar, Brandon C. Benefield, Daming Shen, Santiago López-Tapia, Florian Schiffers, Jeffrey J. Goldberger, Christine M. Albert, Edwin Wu, Aggelos K. Katsaggelos, Daniel C. Lee, Daniel Kim

Background: Late Gadolinium Enhancement (LGE) imaging is the gold standard
for assessing myocardial fibrosis and scarring, with left ventricular (LV) LGE
extent predicting major adverse cardiac events (MACE). Despite its importance,
routine LGE-based LV scar quantification is hindered by labor-intensive manual
segmentation and inter-observer variability. Methods: We propose ScarNet, a
hybrid model combining a transformer-based encoder from the Medical Segment
Anything Model (MedSAM) with a convolution-based U-Net decoder, enhanced by
tailored attention blocks. ScarNet was trained on 552 ischemic cardiomyopathy
patients with expert segmentations of myocardial and scar boundaries and tested
on 184 separate patients. Results: ScarNet achieved robust scar segmentation in
184 test patients, yielding a median Dice score of 0.912 (IQR: 0.863--0.944),
significantly outperforming MedSAM (median Dice = 0.046, IQR: 0.043--0.047) and
nnU-Net (median Dice = 0.638, IQR: 0.604--0.661). ScarNet demonstrated lower
bias (-0.63%) and coefficient of variation (4.3%) compared to MedSAM (bias:
-13.31%, CoV: 130.3%) and nnU-Net (bias: -2.46%, CoV: 20.3%). In Monte Carlo
simulations with noise perturbations, ScarNet achieved significantly higher
scar Dice (0.892 \pm 0.053, CoV = 5.9%) than MedSAM (0.048 \pm 0.112, CoV =
233.3%) and nnU-Net (0.615 \pm 0.537, CoV = 28.7%). Conclusion: ScarNet
outperformed MedSAM and nnU-Net in accurately segmenting myocardial and scar
boundaries in LGE images. The model exhibited robust performance across diverse
image qualities and scar patterns.

摘要：<paragraph>背景：延迟钆增强（LGE）成像用于评估心肌纤维化和瘢痕的黄金标准，左心室 (LV) LGE 范围预测重大的心脏不良事件 (MACE)。尽管其重要性，但基于 LGE 的常规 LV 瘢痕量化受到劳动密集型手动分割和观察者间差异的阻碍。方法：我们提出 ScarNet，一种混合模型，它将来自医学分割任何模型 (MedSAM) 的基于 Transformer 的编码器与基于卷积的 U-Net 解码器相结合，并通过定制的注意力块进行增强。ScarNet 在 552 例缺血性心肌病患者上接受训练，这些患者的心肌和瘢痕边界由专家分割，并在 184 例单独患者上进行测试。结果：ScarNet 在 184 例测试患者中实现了稳健的瘢痕分割，产生 0.912 的中值 Dice 得分（IQR：0.863--0.944），明显优于 MedSAM（中值 Dice = 0.046，IQR：0.043--0.047）和 nnU-Net（中值 Dice = 0.638，IQR：0.604--0.661）。与 MedSAM（偏差：-13.31%，CoV：130.3%）和 nnU-Net（偏差：-2.46%，CoV：20.3%）相比，ScarNet 表现出较低的偏差（-0.63%）和变异系数（4.3%）。在带有噪声扰动的蒙特卡罗模拟中，ScarNet 实现了明显高于 MedSAM（0.048 ± 0.112，CoV = 233.3%）和 nnU-Net（0.615 ± 0.537，CoV = 28.7%）的瘢痕 Dice（0.892 ± 0.053，CoV = 5.9%）。结论：ScarNet 在准确分割 LGE 图像中的心肌和瘢痕边界方面优于 MedSAM 和 nnU-Net。该模型在不同的图像质量和瘢痕模式下表现出稳健的性能。</paragraph>

##### **Contrastive Learning from Exploratory Actions: Leveraging Natural Interactions for Preference Elicitation**
2501.01367v1 by Nathaniel Dennler, Stefanos Nikolaidis, Maja Matarić

People have a variety of preferences for how robots behave. To understand and
reason about these preferences, robots aim to learn a reward function that
describes how aligned robot behaviors are with a user's preferences. Good
representations of a robot's behavior can significantly reduce the time and
effort required for a user to teach the robot their preferences. Specifying
these representations -- what "features" of the robot's behavior matter to
users -- remains a difficult problem; Features learned from raw data lack
semantic meaning and features learned from user data require users to engage in
tedious labeling processes. Our key insight is that users tasked with
customizing a robot are intrinsically motivated to produce labels through
exploratory search; they explore behaviors that they find interesting and
ignore behaviors that are irrelevant. To harness this novel data source of
exploratory actions, we propose contrastive learning from exploratory actions
(CLEA) to learn trajectory features that are aligned with features that users
care about. We learned CLEA features from exploratory actions users performed
in an open-ended signal design activity (N=25) with a Kuri robot, and evaluated
CLEA features through a second user study with a different set of users (N=42).
CLEA features outperformed self-supervised features when eliciting user
preferences over four metrics: completeness, simplicity, minimality, and
explainability.

摘要：人們對於機器人的行為方式有各種偏好。為了理解和推論這些偏好，機器人旨在學習一個獎勵函數，說明機器人的行為與使用者的偏好有多麼一致。良好的機器人行為表示可以大幅減少使用者教導機器人其偏好所需的時間和精力。說明這些表示——機器人行為的哪些「特徵」對使用者來說很重要——仍然是一個困難的問題；從原始資料學習到的特徵缺乏語意意義，而從使用者資料學習到的特徵需要使用者參與繁瑣的標籤處理程序。我們的關鍵見解是，負責自訂機器人的使用者本質上會透過探索性搜尋產生標籤；他們會探索他們覺得有趣的行為，並忽略不相關的行為。為了利用這個探索性動作的新穎資料來源，我們提出從探索性動作中進行對比學習 (CLEA)，以學習與使用者關心的特徵一致的軌跡特徵。我們從使用者在與 Kuri 機器人的開放式訊號設計活動 (N=25) 中執行的探索性動作中學習了 CLEA 特徵，並透過第二個使用者研究對 CLEA 特徵進行評估，該研究使用了一組不同的使用者 (N=42)。在引出使用者偏好時，CLEA 特徵在四個指標上優於自監督特徵：完整性、簡潔性、最小性、可解釋性。

##### **Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**
2501.01311v2 by Bohang Sun, Pietro Liò

In this study, we introduce the Multi-Head Explainer (MHEX), a versatile and
modular framework that enhances both the explainability and accuracy of
Convolutional Neural Networks (CNNs) and Transformer-based models. MHEX
consists of three core components: an Attention Gate that dynamically
highlights task-relevant features, Deep Supervision that guides early layers to
capture fine-grained details pertinent to the target class, and an Equivalent
Matrix that unifies refined local and global representations to generate
comprehensive saliency maps. Our approach demonstrates superior compatibility,
enabling effortless integration into existing residual networks like ResNet and
Transformer architectures such as BERT with minimal modifications. Extensive
experiments on benchmark datasets in medical imaging and text classification
show that MHEX not only improves classification accuracy but also produces
highly interpretable and detailed saliency scores.

摘要：在本次研究中，我們介紹了多頭解釋器 (MHEX)，這是一個多功能且模組化的架構，可增強卷積神經網路 (CNN) 和 Transformer 模型的可解釋性和準確性。MHEX 包含三個核心組成部分：動態突顯與任務相關特徵的注意力閘門、引導早期層捕捉與目標類別相關的細微細節的深度監督，以及統一精緻局部和全局表示以產生全面顯著性圖的等效矩陣。我們的做法展現出優異的相容性，能輕鬆整合到現有的殘差網路（如 ResNet）和 Transformer 架構（如 BERT），且只需進行最小的修改。在醫學影像和文字分類基準資料集上的廣泛實驗顯示，MHEX 不僅能提升分類準確性，還能產生高度可解釋且詳細的顯著性分數。

##### **Machine Learning-Based Differential Diagnosis of Parkinson's Disease Using Kinematic Feature Extraction and Selection**
2501.02014v1 by Masahiro Matsumoto, Abu Saleh Musa Miah, Nobuyoshi Asai, Jungpil Shin

Parkinson's disease (PD), the second most common neurodegenerative disorder,
is characterized by dopaminergic neuron loss and the accumulation of abnormal
synuclein. PD presents both motor and non-motor symptoms that progressively
impair daily functioning. The severity of these symptoms is typically assessed
using the MDS-UPDRS rating scale, which is subjective and dependent on the
physician's experience. Additionally, PD shares symptoms with other
neurodegenerative diseases, such as progressive supranuclear palsy (PSP) and
multiple system atrophy (MSA), complicating accurate diagnosis. To address
these diagnostic challenges, we propose a machine learning-based system for
differential diagnosis of PD, PSP, MSA, and healthy controls (HC). This system
utilizes a kinematic feature-based hierarchical feature extraction and
selection approach. Initially, 18 kinematic features are extracted, including
two newly proposed features: Thumb-to-index vector velocity and acceleration,
which provide insights into motor control patterns. In addition, 41 statistical
features were extracted here from each kinematic feature, including some new
approaches such as Average Absolute Change, Rhythm, Amplitude, Frequency,
Standard Deviation of Frequency, and Slope. Feature selection is performed
using One-way ANOVA to rank features, followed by Sequential Forward Floating
Selection (SFFS) to identify the most relevant ones, aiming to reduce the
computational complexity. The final feature set is used for classification,
achieving a classification accuracy of 66.67% for each dataset and 88.89% for
each patient, with particularly high performance for the MSA and HC groups
using the SVM algorithm. This system shows potential as a rapid and accurate
diagnostic tool in clinical practice, though further data collection and
refinement are needed to enhance its reliability.

摘要：帕金森氏症（PD）是第二常见的脑神经退化性疾病，
其特征是多巴胺能神经元丧失和异常α-突触核蛋白的积累。PD 同时出现运动和非运动症状，这些症状会逐渐损害日常功能。这些症状的严重程度通常使用 MDS-UPDRS 评定量表进行评估，该量表是主观的，并且依赖于医生的经验。此外，PD 与其他神经退化性疾病（例如进行性核上性麻痹 (PSP) 和多系统萎缩 (MSA)）有相同的症状，这使得准确诊断变得复杂。为了应对这些诊断挑战，我们提出了一种基于机器学习的系统，用于 PD、PSP、MSA 和健康对照 (HC) 的鉴别诊断。该系统利用基于运动学特征的分层特征提取和选择方法。最初，提取了 18 个运动学特征，包括两个新提出的特征：拇指到食指的矢量速度和加速度，它们提供了对运动控制模式的见解。此外，此处从每个运动学特征中提取了 41 个统计特征，包括一些新方法，例如平均绝对变化、节奏、振幅、频率、频率标准差和斜率。使用单向方差分析对特征进行排名，然后使用顺序前向浮动选择 (SFFS) 识别最相关的特征，以降低计算复杂度。最终特征集用于分类，对于每个数据集，分类准确率达到 66.67%，对于每个患者，准确率达到 88.89%，使用 SVM 算法时，MSA 和 HC 组的性能尤其高。该系统显示出作为临床实践中快速且准确的诊断工具的潜力，尽管需要进一步收集数据和改进以增强其可靠性。

##### **Data Augmentation Techniques for Chinese Disease Name Normalization**
2501.01195v1 by Wenqian Cui, Xiangling Fu, Shaohui Liu, Mingjun Gu, Xien Liu, Ji Wu, Irwin King

Disease name normalization is an important task in the medical domain. It
classifies disease names written in various formats into standardized names,
serving as a fundamental component in smart healthcare systems for various
disease-related functions. Nevertheless, the most significant obstacle to
existing disease name normalization systems is the severe shortage of training
data. Consequently, we present a novel data augmentation approach that includes
a series of data augmentation techniques and some supporting modules to help
mitigate the problem. Through extensive experimentation, we illustrate that our
proposed approach exhibits significant performance improvements across various
baseline models and training objectives, particularly in scenarios with limited
training data

摘要：疾病名稱正規化是醫學領域中一項重要的任務。它將以各種格式書寫的疾病名稱分類為標準化名稱，作為智慧醫療系統中各種疾病相關功能的基本組成部分。然而，現有疾病名稱正規化系統最顯著的障礙是訓練資料嚴重短缺。因此，我們提出了一種新穎的資料擴充方法，其中包括一系列資料擴充技術和一些輔助模組，以幫助減輕這個問題。透過廣泛的實驗，我們說明我們提出的方法在各種基線模型和訓練目標中展現出顯著的效能提升，特別是在訓練資料有限的情況下

##### **Reasoning based on symbolic and parametric knowledge bases: a survey**
2501.01030v1 by Mayi Xu, Yunfeng Ning, Yongqi Li, Jianhao Chen, Jintao Wen, Yao Xiao, Shen Zhou, Birong Pan, Zepeng Bao, Xin Miao, Hankun Kang, Ke Sun, Tieyun Qian

Reasoning is fundamental to human intelligence, and critical for
problem-solving, decision-making, and critical thinking. Reasoning refers to
drawing new conclusions based on existing knowledge, which can support various
applications like clinical diagnosis, basic education, and financial analysis.
Though a good number of surveys have been proposed for reviewing
reasoning-related methods, none of them has systematically investigated these
methods from the viewpoint of their dependent knowledge base. Both the
scenarios to which the knowledge bases are applied and their storage formats
are significantly different. Hence, investigating reasoning methods from the
knowledge base perspective helps us better understand the challenges and future
directions. To fill this gap, this paper first classifies the knowledge base
into symbolic and parametric ones. The former explicitly stores information in
human-readable symbols, and the latter implicitly encodes knowledge within
parameters. Then, we provide a comprehensive overview of reasoning methods
using symbolic knowledge bases, parametric knowledge bases, and both of them.
Finally, we identify the future direction toward enhancing reasoning
capabilities to bridge the gap between human and machine intelligence.

摘要：推理是人类智能的基础，对于解决问题、决策和批判性思维至关重要。推理是指根据现有知识得出新的结论，这可以支持各种应用程序，如临床诊断、基础教育和财务分析。尽管已经提出了大量调查来审查与推理相关的各种方法，但没有一种方法从其依赖知识库的角度系统地研究这些方法。知识库被应用到的场景及其存储格式都有显着差异。因此，从知识库的角度研究推理方法有助于我们更好地理解挑战和未来的方向。为了填补这一空白，本文首先将知识库分为符号知识库和参数知识库。前者以人类可读的符号明确存储信息，而后者则在参数中隐式编码知识。然后，我们对使用符号知识库、参数知识库以及两者结合的推理方法进行了全面概述。最后，我们确定了增强推理能力以缩小人和机器智能之间差距的未来方向。

##### **Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice**
2501.00982v1 by Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira, Noriko Kando

In psychological practice, standardized questionnaires serve as essential
tools for assessing mental constructs (e.g., attitudes, traits, and emotions)
through structured questions (aka items). With the increasing prevalence of
social media platforms where users share personal experiences and emotions,
researchers are exploring computational methods to leverage this data for rapid
mental health screening. In this study, we propose a novel adaptive
Retrieval-Augmented Generation (RAG) approach that completes psychological
questionnaires by analyzing social media posts. Our method retrieves the most
relevant user posts for each question in a psychological survey and uses Large
Language Models (LLMs) to predict questionnaire scores in a zero-shot setting.
Our findings are twofold. First we demonstrate that this approach can
effectively predict users' responses to psychological questionnaires, such as
the Beck Depression Inventory II (BDI-II), achieving performance comparable to
or surpassing state-of-the-art models on Reddit-based benchmark datasets
without relying on training data. Second, we show how this methodology can be
generalized as a scalable screening tool, as the final assessment is
systematically derived by completing standardized questionnaires and tracking
how individual item responses contribute to the diagnosis, aligning with
established psychometric practices.

摘要：<paragraph>在心理學實務中，標準化問卷作為評量心理建構（例如態度、特質和情緒）的必要工具，透過結構化問題（又稱項目）來進行評量。隨著社群媒體平台的普及，使用者會在上面分享個人經驗和情緒，研究人員正在探討運算方法，以利用這些資料進行快速的的心理健康篩檢。在這項研究中，我們提出了一種創新的適應性擷取增強生成（RAG）方法，透過分析社群媒體貼文來完成心理問卷。我們的做法是針對心理調查中的每個問題，擷取與之最相關的使用者貼文，並使用大型語言模型（LLM）在零次學習的設定下預測問卷分數。我們的發現有兩方面。首先，我們證明了這種方法可以有效預測使用者對心理問卷的回答，例如貝克憂鬱量表第二版（BDI-II），在基於 Reddit 的基準資料集上達到了與最先進模型相當或超越的表現，而且並未依賴訓練資料。其次，我們展示了這個方法如何能被概括為一種可擴充的篩檢工具，因為最終評量是透過完成標準化問卷並追蹤個別項目回答如何促成診斷而系統性地得出的，這與既定的心理測量實務相符。</paragraph>

##### **Enhancing Early Diabetic Retinopathy Detection through Synthetic DR1 Image Generation: A StyleGAN3 Approach**
2501.00954v1 by Sagarnil Das, Pradeep Walia

Diabetic Retinopathy (DR) is a leading cause of preventable blindness. Early
detection at the DR1 stage is critical but is hindered by a scarcity of
high-quality fundus images. This study uses StyleGAN3 to generate synthetic DR1
images characterized by microaneurysms with high fidelity and diversity. The
aim is to address data scarcity and enhance the performance of supervised
classifiers. A dataset of 2,602 DR1 images was used to train the model,
followed by a comprehensive evaluation using quantitative metrics, including
Frechet Inception Distance (FID), Kernel Inception Distance (KID), and
Equivariance with respect to translation (EQ-T) and rotation (EQ-R).
Qualitative assessments included Human Turing tests, where trained
ophthalmologists evaluated the realism of synthetic images. Spectral analysis
further validated image quality. The model achieved a final FID score of 17.29,
outperforming the mean FID of 21.18 (95 percent confidence interval - 20.83 to
21.56) derived from bootstrap resampling. Human Turing tests demonstrated the
model's ability to produce highly realistic images, though minor artifacts near
the borders were noted. These findings suggest that StyleGAN3-generated
synthetic DR1 images hold significant promise for augmenting training datasets,
enabling more accurate early detection of Diabetic Retinopathy. This
methodology highlights the potential of synthetic data in advancing medical
imaging and AI-driven diagnostics.

摘要：糖尿病視網膜病變 (DR) 是可預防失明的主要原因。在 DR1 階段早期發現至關重要，但由於缺乏高品質眼底圖像而受到阻礙。本研究使用 StyleGAN3 生成合成 DR1 圖像，其特徵是具有高保真度和多樣性的微動脈瘤。目的是解決資料稀少的問題，並提升監督分類器的效能。使用 2,602 張 DR1 圖像的資料集來訓練模型，然後使用量化指標進行全面評估，包括 Fréchet Inception Distance (FID)、Kernel Inception Distance (KID) 以及相對於平移 (EQ-T) 和旋轉 (EQ-R) 的等變異性。定性評估包括人類圖靈測試，其中訓練有素的眼科醫生評估合成圖像的真實性。光譜分析進一步驗證了影像品質。該模型達到了 17.29 的最終 FID 分數，優於從 bootstrap 重抽樣得出的 21.18 的平均 FID（95% 信賴區間 - 20.83 到 21.56）。人類圖靈測試證明了該模型產生高度逼真圖像的能力，儘管注意到邊緣附近有輕微的人工製品。這些發現表明，StyleGAN3 生成的合成 DR1 圖像對於擴充訓練資料集具有顯著的希望，能夠更準確地早期發現糖尿病視網膜病變。這種方法突顯了合成資料在推進醫學影像和 AI 驅動診斷方面的潛力。

##### **Multi-Center Study on Deep Learning-Assisted Detection and Classification of Fetal Central Nervous System Anomalies Using Ultrasound Imaging**
2501.02000v1 by Yang Qi, Jiaxin Cai, Jing Lu, Runqing Xiong, Rongshang Chen, Liping Zheng, Duo Ma

Prenatal ultrasound evaluates fetal growth and detects congenital
abnormalities during pregnancy, but the examination of ultrasound images by
radiologists requires expertise and sophisticated equipment, which would
otherwise fail to improve the rate of identifying specific types of fetal
central nervous system (CNS) abnormalities and result in unnecessary patient
examinations. We construct a deep learning model to improve the overall
accuracy of the diagnosis of fetal cranial anomalies to aid prenatal diagnosis.
In our collected multi-center dataset of fetal craniocerebral anomalies
covering four typical anomalies of the fetal central nervous system (CNS):
anencephaly, encephalocele (including meningocele), holoprosencephaly, and
rachischisis, patient-level prediction accuracy reaches 94.5%, with an AUROC
value of 99.3%. In the subgroup analyzes, our model is applicable to the entire
gestational period, with good identification of fetal anomaly types for any
gestational period. Heatmaps superimposed on the ultrasound images not only
provide a visual interpretation for the algorithm but also provide an intuitive
visual aid to the physician by highlighting key areas that need to be reviewed,
helping the physician to quickly identify and validate key areas. Finally, the
retrospective reader study demonstrates that by combining the automatic
prediction of the DL system with the professional judgment of the radiologist,
the diagnostic accuracy and efficiency can be effectively improved and the
misdiagnosis rate can be reduced, which has an important clinical application
prospect.

摘要：產前超音波評估胎兒生長並在懷孕期間偵測先天異常，但超音波影像的檢查需要放射科醫師的專業知識和精密儀器，否則無法改善特定類型胎兒中樞神經系統 (CNS) 異常的辨識率，並導致不必要的病人檢查。我們建構一個深度學習模型，以改善胎兒顱骨異常診斷的整體準確度，以協助產前診斷。在我們收集的多中心胎兒顱腦異常資料集中，涵蓋胎兒中樞神經系統 (CNS) 的四種典型異常：無腦症、腦膨出（包括腦膜膨出）、全前腦症和脊裂，病人層級的預測準確度達到 94.5%，AUROC 值為 99.3%。在子群分析中，我們的模型適用於整個妊娠期，且能良好辨識任何妊娠期的胎兒異常類型。疊加在超音波影像上的熱圖不僅提供演算法的視覺詮釋，也透過突顯需要檢視的關鍵區域，提供直覺的視覺輔助工具給醫師，協助醫師快速辨識和驗證關鍵區域。最後，回溯性閱讀研究顯示，結合 DL 系統的自動預測和放射科醫師的專業判斷，可以有效改善診斷準確度和效率，並降低誤診率，這具有重要的臨床應用前景。

##### **Efficient Standardization of Clinical Notes using Large Language Models**
2501.00644v1 by Daniel B. Hier, Michael D. Carrithers, Thanh Son Do, Tayo Obafemi-Ajayi

Clinician notes are a rich source of patient information but often contain
inconsistencies due to varied writing styles, colloquialisms, abbreviations,
medical jargon, grammatical errors, and non-standard formatting. These
inconsistencies hinder the extraction of meaningful data from electronic health
records (EHRs), posing challenges for quality improvement, population health,
precision medicine, decision support, and research.
  We present a large language model approach to standardizing a corpus of 1,618
clinical notes. Standardization corrected an average of $4.9 +/- 1.8$
grammatical errors, $3.3 +/- 5.2$ spelling errors, converted $3.1 +/- 3.0$
non-standard terms to standard terminology, and expanded $15.8 +/- 9.1$
abbreviations and acronyms per note. Additionally, notes were re-organized into
canonical sections with standardized headings. This process prepared notes for
key concept extraction, mapping to medical ontologies, and conversion to
interoperable data formats such as FHIR.
  Expert review of randomly sampled notes found no significant data loss after
standardization. This proof-of-concept study demonstrates that standardization
of clinical notes can improve their readability, consistency, and usability,
while also facilitating their conversion into interoperable data formats.

摘要：臨床醫師的筆記是豐富的病人資訊來源，但常常因為書寫風格不同、慣用語、縮寫、醫學術語、文法錯誤和非標準格式而包含不一致的地方。這些不一致會阻礙從電子健康紀錄 (EHR) 中萃取有意義的資料，對品質改善、人口健康、精準醫療、決策支援和研究構成挑戰。
我們提出了一個大型語言模型方法來標準化 1,618 份臨床筆記的語料庫。標準化平均更正了 $4.9 +/- 1.8$ 個文法錯誤、$3.3 +/- 5.2$ 個拼字錯誤，將 $3.1 +/- 3.0$ 個非標準術語轉換為標準術語，並擴充了每份筆記中 $15.8 +/- 9.1$ 個縮寫和首字母縮略字。此外，筆記被重新組織成具有標準標題的正規章節。這個過程準備了筆記，用於關鍵概念萃取、對應到醫學本体，以及轉換為可互操作的資料格式，例如 FHIR。
對隨機抽樣的筆記進行專家審查後發現，在標準化後沒有顯著的資料遺失。這個概念驗證研究證明了臨床筆記的標準化可以改善其可讀性、一致性和可用性，同時也促進其轉換為可互操作的資料格式。

##### **LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models**
2501.05464v1 by Hang Yang, Hao Chen, Hui Guo, Yineng Chen, Ching-Sheng Lin, Shu Hu, Jinrong Hu, Xi Wu, Xin Wang

Accurate and efficient question-answering systems are essential for
delivering high-quality patient care in the medical field. While Large Language
Models (LLMs) have made remarkable strides across various domains, they
continue to face significant challenges in medical question answering,
particularly in understanding domain-specific terminologies and performing
complex reasoning. These limitations undermine their effectiveness in critical
medical applications. To address these issues, we propose a novel approach
incorporating similar case generation within a multi-agent medical
question-answering (MedQA) system. Specifically, we leverage the Llama3.1:70B
model, a state-of-the-art LLM, in a multi-agent architecture to enhance
performance on the MedQA dataset using zero-shot learning. Our method
capitalizes on the model's inherent medical knowledge and reasoning
capabilities, eliminating the need for additional training data. Experimental
results show substantial performance gains over existing benchmark models, with
improvements of 7% in both accuracy and F1-score across various medical QA
tasks. Furthermore, we examine the model's interpretability and reliability in
addressing complex medical queries. This research not only offers a robust
solution for medical question answering but also establishes a foundation for
broader applications of LLMs in the medical domain.

摘要：精準高效的問題解答系統對於提供醫療領域的高品質病人照護至關重要。雖然大型語言模型 (LLM) 在各個領域都有顯著進展，但它們在醫療問題解答中仍面臨重大挑戰，特別是在理解特定領域的術語和執行複雜推理方面。這些限制影響了它們在關鍵醫療應用中的效能。為了解決這些問題，我們提出了一種新方法，將類似案例生成整合到多主體醫療問題解答 (MedQA) 系統中。具體來說，我們在多主體架構中利用最先進的 LLM Llama3.1:70B 模型，以使用零次學習來增強 MedQA 資料集的效能。我們的做法利用了該模型內建的醫療知識和推理能力，消除了對額外訓練資料的需求。實驗結果顯示，與現有的基準模型相比，效能有顯著提升，在各種醫療問答任務中，準確度和 F1 分數都提升了 7%。此外，我們探討了該模型在回答複雜醫療問題時的詮釋性和可靠性。這項研究不僅為醫療問題解答提供了強健的解決方案，也為 LLM 在醫療領域的更廣泛應用奠定了基礎。

##### **Pan-infection Foundation Framework Enables Multiple Pathogen Prediction**
2501.01462v1 by Lingrui Zhang, Haonan Wu, Nana Jin, Chenqing Zheng, Jize Xie, Qitai Cai, Jun Wang, Qin Cao, Xubin Zheng, Jiankun Wang, Lixin Cheng

Host-response-based diagnostics can improve the accuracy of diagnosing
bacterial and viral infections, thereby reducing inappropriate antibiotic
prescriptions. However, the existing cohorts with limited sample size and
coarse infections types are unable to support the exploration of an accurate
and generalizable diagnostic model. Here, we curate the largest infection
host-response transcriptome data, including 11,247 samples across 89 blood
transcriptome datasets from 13 countries and 21 platforms. We build a
diagnostic model for pathogen prediction starting from a pan-infection model as
foundation (AUC = 0.97) based on the pan-infection dataset. Then, we utilize
knowledge distillation to efficiently transfer the insights from this "teacher"
model to four lightweight pathogen "student" models, i.e., staphylococcal
infection (AUC = 0.99), streptococcal infection (AUC = 0.94), HIV infection
(AUC = 0.93), and RSV infection (AUC = 0.94), as well as a sepsis "student"
model (AUC = 0.99). The proposed knowledge distillation framework not only
facilitates the diagnosis of pathogens using pan-infection data, but also
enables an across-disease study from pan-infection to sepsis. Moreover, the
framework enables high-degree lightweight design of diagnostic models, which is
expected to be adaptively deployed in clinical settings.

摘要：基於宿主反應的診斷可以提高細菌和病毒感染的診斷準確度，從而減少不適當的抗生素處方。然而，現有樣本量有限、感染類型粗糙的群組無法支持準確且可概化的診斷模型的探索。在此，我們整理了最大的感染宿主反應轉錄組數據，包括來自 13 個國家和 21 個平台的 89 個血液轉錄組數據集中的 11,247 個樣本。我們從泛感染模型開始建立一個用於病原體預測的診斷模型，作為基礎 (AUC = 0.97)，該模型基於泛感染數據集。然後，我們利用知識蒸餾有效地將這個「教師」模型中的見解轉移到四個輕量級病原體「學生」模型，即葡萄球菌感染 (AUC = 0.99)、鏈球菌感染 (AUC = 0.94)、HIV 感染 (AUC = 0.93) 和 RSV 感染 (AUC = 0.94)，以及一個敗血症「學生」模型 (AUC = 0.99)。所提出的知識蒸餾框架不僅促進了使用泛感染數據診斷病原體，還實現了從泛感染到敗血症的跨疾病研究。此外，該框架使診斷模型能夠進行高度輕量級設計，預計將適應性地部署在臨床環境中。

##### **A Hybrid Deep Learning and Model-Checking Framework for Accurate Brain Tumor Detection and Validation**
2501.01991v1 by Lahcen El Fatimi, Elhoucine Elfatimi, Hanifa Bouchaneb

Model checking, a formal verification technique, ensures systems meet
predefined requirements, playing a crucial role in minimizing errors and
enhancing quality during development. This paper introduces a novel hybrid
framework integrating model checking with deep learning for brain tumor
detection and validation in medical imaging. By combining model-checking
principles with CNN-based feature extraction and K-FCM clustering for
segmentation, the proposed approach enhances the reliability of tumor detection
and segmentation. Experimental results highlight the framework's effectiveness,
achieving 98\% accuracy, 96.15\% precision, and 100\% recall, demonstrating its
potential as a robust tool for advanced medical image analysis.

摘要：模型檢查是一種正式驗證技術，用於確保系統符合預先定義的要求，在開發過程中扮演著極其重要的角色，用於最小化錯誤並提升品質。這篇論文介紹了一個整合模型檢查與深度學習的創新混合框架，用於醫學影像中的腦瘤偵測與驗證。透過結合模型檢查原則與基於 CNN 的特徵萃取以及用於分割的 K-FCM 聚類，所提出的方法提升了腫瘤偵測與分割的可靠度。實驗結果突顯了這個框架的有效性，達到了 98% 的準確度、96.15% 的精確度，以及 100% 的召回率，顯示出其作為進階醫學影像分析的強健工具的潛力。

##### **GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification**
2501.01458v1 by George Yuanji Wang, Srisharan Murugesan, Aditya Prince Rohatgi

Identifying druggable genes is essential for developing effective
pharmaceuticals. With the availability of extensive, high-quality data,
computational methods have become a significant asset. Protein Interaction
Network (PIN) is valuable but challenging to implement due to its high
dimensionality and sparsity. Previous methods relied on indirect integration,
leading to resolution loss. This study proposes GAN-TAT, a framework utilizing
an advanced graph embedding technology, ImGAGN, to directly integrate PIN for
druggable gene inference work. Tested on three Pharos datasets, GAN-TAT
achieved the highest AUC-ROC score of 0.951 on Tclin. Further evaluation shows
that GAN-TAT's predictions are supported by clinical evidence, highlighting its
potential practical applications in pharmacogenomics. This research represents
a methodological attempt with the direct utilization of PIN, expanding
potential new solutions for developing drug targets. The source code of GAN-TAT
is available at (https://github.com/george-yuanji-wang/GAN-TAT).

摘要：識別可藥物化基因對於開發有效的藥物至關重要。隨著大量高品質數據的出現，計算方法已成為一項重要的資產。蛋白質交互網絡 (PIN) 很有價值，但由於其高維度和稀疏性，實作起來具有挑戰性。先前的辦法依賴於間接整合，導致解析度降低。本研究提出 GAN-TAT，一個利用先進圖形嵌入技術 ImGAGN 的架構，直接整合 PIN 以進行可藥物化基因推論工作。在三個 Pharos 資料集上進行測試，GAN-TAT 在 Tclin 上達到了最高的 AUC-ROC 分數 0.951。進一步的評估顯示，GAN-TAT 的預測獲得了臨床證據的支持，突顯了其在藥物基因組學中的潛在實際應用。本研究代表了一種直接利用 PIN 的方法論嘗試，擴展了開發藥物靶標的潛在新解決方案。GAN-TAT 的原始碼可在 (https://github.com/george-yuanji-wang/GAN-TAT) 取得。

##### **Autonomous Alignment with Human Value on Altruism through Considerate Self-imagination and Theory of Mind**
2501.00320v2 by Haibo Tong, Enmeng Lu, Yinqian Sun, Zhengqiang Han, Chao Liu, Feifei Zhao, Yi Zeng

With the widespread application of Artificial Intelligence (AI) in human
society, enabling AI to autonomously align with human values has become a
pressing issue to ensure its sustainable development and benefit to humanity.
One of the most important aspects of aligning with human values is the
necessity for agents to autonomously make altruistic, safe, and ethical
decisions, considering and caring for human well-being. Current AI extremely
pursues absolute superiority in certain tasks, remaining indifferent to the
surrounding environment and other agents, which has led to numerous safety
risks. Altruistic behavior in human society originates from humans' capacity
for empathizing others, known as Theory of Mind (ToM), combined with predictive
imaginative interactions before taking action to produce thoughtful and
altruistic behaviors. Inspired by this, we are committed to endow agents with
considerate self-imagination and ToM capabilities, driving them through
implicit intrinsic motivations to autonomously align with human altruistic
values. By integrating ToM within the imaginative space, agents keep an eye on
the well-being of other agents in real time, proactively anticipate potential
risks to themselves and others, and make thoughtful altruistic decisions that
balance negative effects on the environment. The ancient Chinese story of Sima
Guang Smashes the Vat illustrates the moral behavior of the young Sima Guang
smashed a vat to save a child who had accidentally fallen into it, which is an
excellent reference scenario for this paper. We design an experimental scenario
similar to Sima Guang Smashes the Vat and its variants with different
complexities, which reflects the trade-offs and comprehensive considerations
between self-goals, altruistic rescue, and avoiding negative side effects.

摘要：隨著人工智慧（AI）在人類社會中的廣泛應用，讓 AI 自主與人類價值觀一致已成為確保其永續發展和造福人類的當務之急。與人類價值觀一致最重要的面向之一，在於代理人必須自主做出利他、安全、且合乎道德的決策，考量並關懷人類福祉。目前的 AI 在特定任務中極力追求絕對優越性，對於周遭環境和其它代理人漠不關心，這已導致許多安全風險。人類社會中的利他行為源自於人類同理他人的能力，稱為心智理論（ToM），結合在採取行動前進行預測性的想像互動，以產生周到且利他的行為。受到此啟發，我們致力於賦予代理人體貼的自我想像和 ToM 能力，透過隱含的內在動機驅使他們自主與人類利他價值觀一致。透過將 ToM 整合在想像空間中，代理人能即時關注其他代理人的福祉，主動預測對自身和他人潛在的風險，並做出周到且利他的決策，平衡對環境的負面影響。中國古代故事「司馬光砸缸」說明了年幼的司馬光為了救一個不小心掉進水缸中的孩子而砸破水缸的道德行為，是本文的絕佳參考情境。我們設計了一個與「司馬光砸缸」相似的實驗情境，以及具有不同複雜性的變體，反映了自我目標、利他救援和避免負面副作用之間的權衡和綜合考量。

##### **A Fourfold Pathogen Reference Ontology Suite**
2501.01454v1 by Shane Babcock, Carter Benson, Giacomo De Colle, Sydney Cohen, Alexander D. Diehl, Ram A. N. R. Challa, Anthony Huffman, Yongqun He, John Beverley

Infectious diseases remain a critical global health challenge, and the
integration of standardized ontologies plays a vital role in managing related
data. The Infectious Disease Ontology (IDO) and its extensions, such as the
Coronavirus Infectious Disease Ontology (CIDO), are essential for organizing
and disseminating information related to infectious diseases. The COVID-19
pandemic highlighted the need for updating IDO and its virus-specific
extensions. There is an additional need to update IDO extensions specific to
bacteria, fungus, and parasite infectious diseases. We adopt the "hub and
spoke" methodology to generate pathogen-specific extensions of IDO: Virus
Infectious Disease Ontology (VIDO), Bacteria Infectious Disease Ontology
(BIDO), Mycosis Infectious Disease Ontology (MIDO), and Parasite Infectious
Disease Ontology (PIDO). The creation of pathogen-specific reference ontologies
advances modularization and reusability of infectious disease data within the
IDO ecosystem. Future work will focus on further refining these ontologies,
creating new extensions, and developing application ontologies based on them,
in line with ongoing efforts to standardize biological and biomedical
terminologies for improved data sharing and analysis.

摘要：傳染病仍是一項全球性的健康挑戰，而標準化本體的整合在管理相關數據方面扮演著至關重要的角色。傳染病本體 (IDO) 及其擴充，例如冠狀病毒傳染病本體 (CIDO)，對於組織和傳播與傳染病相關的資訊至關重要。COVID-19 大流行凸顯了更新 IDO 及其特定於病毒的擴充的需求。此外，還有更新特定於細菌、真菌和寄生蟲傳染病的 IDO 擴充的需求。我們採用「樞紐輻條」方法來產生 IDO 的特定於病原體的擴充：病毒傳染病本體 (VIDO)、細菌傳染病本體 (BIDO)、真菌病傳染病本體 (MIDO) 和寄生蟲傳染病本體 (PIDO)。特定於病原體的參考本體的建立，促进了 IDO 生態系統內傳染病數據的模組化和可重複使用性。未來的研究工作將重點放在進一步完善這些本體、建立新的擴充，以及根據這些本體開發應用本體，這與標準化生物和生物醫學術語以改善數據共享和分析的持續努力相一致。

##### **CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**
2501.00223v1 by Michael Gubanov, Anna Pyayt, Aleksandra Karolak

Here, we describe one of the first Web-scale hybrid Knowledge Graph
(KG)-Large Language Model (LLM), populated with the latest peer-reviewed
medical knowledge on colorectal Cancer. It is currently being evaluated to
assist with both medical research and clinical information retrieval tasks at
Moffitt Cancer Center, which is one of the top Cancer centers in the U.S. and
in the world. Our hybrid is remarkable as it serves the user needs better than
just an LLM, KG or a search-engine in isolation. LLMs as is are known to
exhibit hallucinations and catastrophic forgetting as well as are trained on
outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,
ChEMBL, NCBI, and other require manual curation, hence are quickly getting
stale. CancerKG is unsupervised and is capable of automatically ingesting and
organizing the latest medical findings. To alleviate the LLMs shortcomings, the
verified KG serves as a Retrieval Augmented Generation (RAG) guardrail.
CancerKG exhibits 5 different advanced user interfaces, each tailored to serve
different data modalities better and more convenient for the user.

摘要：在此，我们描述了第一个 Web 级混合知识图谱 (KG) - 大型语言模型 (LLM)，其中充斥着有关结直肠癌的最新同行评审医学知识。目前正在评估它以协助 Moffitt 癌症中心进行医学研究和临床信息检索任务，该中心是美国和世界顶级癌症中心之一。我们的混合体非常出色，因为它比孤立的 LLM、KG 或搜索引擎更好地满足用户需求。众所周知，LLM 会出现幻觉和灾难性遗忘，并且是在过时的语料库上进行训练的。最先进的 KG，例如 PrimeKG、cBioPortal、ChEMBL、NCBI 等需要人工整理，因此很快就会过时。CancerKG 无需监督，能够自动摄取和组织最新的医学发现。为了减轻 LLM 的缺点，经过验证的 KG 充当检索增强生成 (RAG) 护栏。CancerKG 展示了 5 种不同的高级用户界面，每种界面都针对服务不同的数据模式，为用户提供更好、更方便的服务。

##### **An Empirical Evaluation of Large Language Models on Consumer Health Questions**
2501.00208v1 by Moaiz Abrar, Yusuf Sermet, Ibrahim Demir

This study evaluates the performance of several Large Language Models (LLMs)
on MedRedQA, a dataset of consumer-based medical questions and answers by
verified experts extracted from the AskDocs subreddit. While LLMs have shown
proficiency in clinical question answering (QA) benchmarks, their effectiveness
on real-world, consumer-based, medical questions remains less understood.
MedRedQA presents unique challenges, such as informal language and the need for
precise responses suited to non-specialist queries. To assess model
performance, responses were generated using five LLMs: GPT-4o mini, Llama 3.1:
70B, Mistral-123B, Mistral-7B, and Gemini-Flash. A cross-evaluation method was
used, where each model evaluated its responses as well as those of others to
minimize bias. The results indicated that GPT-4o mini achieved the highest
alignment with expert responses according to four out of the five models'
judges, while Mistral-7B scored lowest according to three out of five models'
judges. This study highlights the potential and limitations of current LLMs for
consumer health medical question answering, indicating avenues for further
development.

摘要：本研究評估了大型語言模型 (LLM) 在 MedRedQA 上的效能，MedRedQA 是一組消費者醫療問題與答案的資料集，由 AskDocs 子版塊中經過驗證的專家所提出。儘管 LLM 已在臨床問題解答 (QA) 基準中展現出專業知識，但它們在現實世界、消費者為基礎的醫療問題上的有效性仍較不明確。MedRedQA 提出獨特的挑戰，例如非正式語言和對非專家查詢提供精確回應的需求。為了評估模型效能，使用五個 LLM 生成了回應：GPT-4o mini、Llama 3.1：70B、Mistral-123B、Mistral-7B 和 Gemini-Flash。使用了交叉評估方法，其中每個模型評估自己的回應以及其他模型的回應，以最小化偏差。結果顯示，根據五個模型中的四個模型評審，GPT-4o mini 與專家回應的一致性最高，而根據五個模型中的三個模型評審，Mistral-7B 的分數最低。本研究強調了目前 LLM 在消費者健康醫療問題解答方面的潛力和限制，並指出進一步發展的途徑。

##### **GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study**
2501.00199v1 by Giuliano Lorenzoni, Pedro Elkind Velmovitsky, Paulo Alencar, Donald Cowan

Depression has impacted millions of people worldwide and has become one of
the most prevalent mental disorders. Early mental disorder detection can lead
to cost savings for public health agencies and avoid the onset of other major
comorbidities. Additionally, the shortage of specialized personnel is a
critical issue because clinical depression diagnosis is highly dependent on
expert professionals and is time consuming.
  In this study, we explore the use of GPT-4 for clinical depression assessment
based on transcript analysis. We examine the model's ability to classify
patient interviews into binary categories: depressed and not depressed. A
comparative analysis is conducted considering prompt complexity (e.g., using
both simple and complex prompts) as well as varied temperature settings to
assess the impact of prompt complexity and randomness on the model's
performance.
  Results indicate that GPT-4 exhibits considerable variability in accuracy and
F1-Score across configurations, with optimal performance observed at lower
temperature values (0.0-0.2) for complex prompts. However, beyond a certain
threshold (temperature >= 0.3), the relationship between randomness and
performance becomes unpredictable, diminishing the gains from prompt
complexity.
  These findings suggest that, while GPT-4 shows promise for clinical
assessment, the configuration of the prompts and model parameters requires
careful calibration to ensure consistent results. This preliminary study
contributes to understanding the dynamics between prompt engineering and large
language models, offering insights for future development of AI-powered tools
in clinical settings.

摘要：憂鬱症影響全球數百萬人，已成為最普遍的精神疾病之一。提早偵測精神疾病，能為公共衛生機構節省成本，並避免其他主要共病的發生。此外，專業人員短缺是一個關鍵問題，因為臨床憂鬱症的診斷高度依賴於專業人員，且耗時費力。
在這個研究中，我們探討使用 GPT-4 進行臨床憂鬱症評估，基礎是謄本分析。我們檢視模型將病人訪談分類為二元類別（憂鬱症和非憂鬱症）的能力。我們進行比較分析，考量提示複雜度（例如，同時使用簡單和複雜的提示），以及各種溫度設定，以評估提示複雜度和隨機性對模型效能的影響。
結果顯示，GPT-4 在各組態中的準確度和 F1 分數變化很大，在複雜提示的較低溫度值（0.0-0.2）下觀察到最佳效能。然而，超過某個閾值（溫度 >= 0.3）後，隨機性和效能之間的關係變得難以預測，降低了提示複雜度帶來的收益。
這些發現表明，雖然 GPT-4 在臨床評估方面顯示出前景，但提示和模型參數的組態需要仔細校準，以確保結果的一致性。這項初步研究有助於了解提示工程和大型語言模型之間的動態，為未來在臨床環境中開發 AI 驅動工具提供見解。

##### **SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction**
2501.00190v2 by Changchang Yin, Shihan Fu, Bingsheng Yao, Thai-Hoang Pham, Weidan Cao, Dakuo Wang, Jeffrey Caterino, Ping Zhang

Sepsis is an organ dysfunction caused by a deregulated immune response to an
infection. Early sepsis prediction and identification allow for timely
intervention, leading to improved clinical outcomes. Clinical calculators
(e.g., the six-organ dysfunction assessment of SOFA) play a vital role in
sepsis identification within clinicians' workflow, providing evidence-based
risk assessments essential for sepsis diagnosis. However, artificial
intelligence (AI) sepsis prediction models typically generate a single sepsis
risk score without incorporating clinical calculators for assessing organ
dysfunctions, making the models less convincing and transparent to clinicians.
To bridge the gap, we propose to mimic clinicians' workflow with a novel
framework SepsisCalc to integrate clinical calculators into the predictive
model, yielding a clinically transparent and precise model for utilization in
clinical settings. Practically, clinical calculators usually combine
information from multiple component variables in Electronic Health Records
(EHR), and might not be applicable when the variables are (partially) missing.
We mitigate this issue by representing EHRs as temporal graphs and integrating
a learning module to dynamically add the accurately estimated calculator to the
graphs. Experimental results on real-world datasets show that the proposed
model outperforms state-of-the-art methods on sepsis prediction tasks.
Moreover, we developed a system to identify organ dysfunctions and potential
sepsis risks, providing a human-AI interaction tool for deployment, which can
help clinicians understand the prediction outputs and prepare timely
interventions for the corresponding dysfunctions, paving the way for actionable
clinical decision-making support for early intervention.

摘要：敗血症是由對感染的失調免疫反應所造成的器官功能障礙。早期敗血症預測和識別有助於及時介入，進而改善臨床結果。臨床計算器（例如，SOFA 的六器官功能障礙評估）在臨床醫師的工作流程中扮演著敗血症識別的重要角色，提供敗血症診斷必要的證據為基礎的風險評估。然而，人工智慧（AI）敗血症預測模型通常會產生單一的敗血症風險評分，而未納入用於評估器官功能障礙的臨床計算器，使得模型對臨床醫師來說顯得較不具說服力且透明。為了彌合差距，我們提出模擬臨床醫師的工作流程，使用創新的 SepsisCalc 架構將臨床計算器整合到預測模型中，產生一個在臨床環境中使用時具有臨床透明度且精確的模型。實際上，臨床計算器通常會結合電子健康紀錄（EHR）中多個組成變數的資訊，且當變數（部分）遺失時可能不適用。我們透過將 EHR 表示為時間圖形並整合一個學習模組，動態將準確估計的計算器新增到圖形中，來減輕這個問題。在真實世界資料集上的實驗結果顯示，所提出的模型在敗血症預測任務上優於最先進的方法。此外，我們開發了一個系統來識別器官功能障礙和潛在的敗血症風險，提供一個可用於部署的人工智慧互動工具，這有助於臨床醫師了解預測輸出，並針對相應的功能障礙準備及時的介入措施，為早期介入的行動臨床決策支援鋪路。

##### **DeepLL: Considering Linear Logic for the Analysis of Deep Learning Experiments**
2501.00169v1 by Nick Papoulias

Deep Learning experiments have critical requirements regarding the careful
handling of their datasets as well as the efficient and correct usage of APIs
that interact with hardware accelerators. On the one hand, software mistakes
during data handling can contaminate experiments and lead to incorrect results.
On the other hand, poorly coded APIs that interact with the hardware can lead
to sub-optimal usage and untrustworthy conclusions. In this work we investigate
the use of Linear Logic for the analysis of Deep Learning experiments. We show
that primitives and operators of Linear Logic can be used to express: (i) an
abstract representation of the control flow of an experiment, (ii) a set of
available experimental resources, such as API calls to the underlying
data-structures and hardware as well as (iii) reasoning rules about the correct
consumption of resources during experiments. Our proposed model is not only
lightweight but also easy to comprehend having both a symbolic and a visual
component. Finally, its artifacts are themselves proofs in Linear Logic that
can be readily verified by off-the-shelf reasoners.

摘要：深度學習實驗對於資料集的仔細處理以及與硬體加速器互動的 API 的有效且正確使用具有重要的要求。一方面，資料處理過程中的軟體錯誤可能會污染實驗並導致不正確的結果。另一方面，與硬體互動的編碼不良的 API 可能導致次佳使用和不可靠的結論。在這項工作中，我們探討了使用線性邏輯來分析深度學習實驗。我們展示了線性邏輯的基本原理和運算符可用於表達：(i) 實驗控制流程的抽象表示，(ii) 一組可用的實驗資源，例如對底層資料結構和硬體的 API 呼叫以及 (iii) 關於在實驗期間正確消耗資源的推理規則。我們提出的模型不僅輕量級，而且易於理解，既有符號組成，也有視覺組成。最後，其工件本身就是線性邏輯中的證明，可以使用現成的推理器輕鬆驗證。

##### **Temporal reasoning for timeline summarisation in social media**
2501.00152v1 by Jiayu Song, Mahmud Akhter, Dana Atzil Slonim, Maria Liakata

This paper explores whether enhancing temporal reasoning capabilities in
Large Language Models (LLMs) can improve the quality of timeline summarization,
the task of summarising long texts containing sequences of events, particularly
social media threads . We introduce \textit{NarrativeReason}, a novel dataset
focused on temporal relationships among sequential events within narratives,
distinguishing it from existing temporal reasoning datasets that primarily
address pair-wise event relationships. Our approach then combines temporal
reasoning with timeline summarization through a knowledge distillation
framework, where we first fine-tune a teacher model on temporal reasoning tasks
and then distill this knowledge into a student model while simultaneously
training it for the task of timeline summarization. Experimental results
demonstrate that our model achieves superior performance on mental
health-related timeline summarization tasks, which involve long social media
threads with repetitions of events and a mix of emotions, highlighting the
importance of leveraging temporal reasoning to improve timeline summarisation.

摘要：這篇論文探討增強大型語言模型 (LLM) 中的時間推理能力是否能提升時間軸摘要的品質，時間軸摘要是針對包含事件順序的長篇文字進行摘要的任務，尤其是社群媒體串。我們引進了\textit{NarrativeReason}，這個新穎的資料集專注於敘述中順序事件之間的時間關係，並將其與現有的時間推理資料集區分開來，後者主要處理成對的事件關係。我們的做法接著透過知識萃取架構將時間推理與時間軸摘要結合，我們首先針對時間推理任務微調一個教師模型，然後將此知識萃取到一個學生模型中，同時訓練它進行時間軸摘要的任務。實驗結果顯示我們的模型在與心理健康相關的時間軸摘要任務中獲得了卓越的表現，這涉及到包含重複事件和各種情緒的長篇社群媒體串，強調了利用時間推理來提升時間軸摘要的重要性。

##### **A Data-Centric Approach to Detecting and Mitigating Demographic Bias in Pediatric Mental Health Text: A Case Study in Anxiety Detection**
2501.00129v1 by Julia Ive, Paulina Bondaronek, Vishal Yadav, Daniel Santel, Tracy Glauser, Tina Cheng, Jeffrey R. Strawn, Greeshma Agasthya, Jordan Tschida, Sanghyun Choo, Mayanka Chandrashekar, Anuj J. Kapadia, John Pestian

Introduction: Healthcare AI models often inherit biases from their training
data. While efforts have primarily targeted bias in structured data, mental
health heavily depends on unstructured data. This study aims to detect and
mitigate linguistic differences related to non-biological differences in the
training data of AI models designed to assist in pediatric mental health
screening. Our objectives are: (1) to assess the presence of bias by evaluating
outcome parity across sex subgroups, (2) to identify bias sources through
textual distribution analysis, and (3) to develop a de-biasing method for
mental health text data. Methods: We examined classification parity across
demographic groups and assessed how gendered language influences model
predictions. A data-centric de-biasing method was applied, focusing on
neutralizing biased terms while retaining salient clinical information. This
methodology was tested on a model for automatic anxiety detection in pediatric
patients. Results: Our findings revealed a systematic under-diagnosis of female
adolescent patients, with a 4% lower accuracy and a 9% higher False Negative
Rate (FNR) compared to male patients, likely due to disparities in information
density and linguistic differences in patient notes. Notes for male patients
were on average 500 words longer, and linguistic similarity metrics indicated
distinct word distributions between genders. Implementing our de-biasing
approach reduced diagnostic bias by up to 27%, demonstrating its effectiveness
in enhancing equity across demographic groups. Discussion: We developed a
data-centric de-biasing framework to address gender-based content disparities
within clinical text. By neutralizing biased language and enhancing focus on
clinically essential information, our approach demonstrates an effective
strategy for mitigating bias in AI healthcare models trained on text.

摘要：<paragraph>引言：醫療保健 AI 模型通常會從其訓練資料中繼承偏見。雖然努力主要針對結構化資料中的偏見，但心理健康在很大程度上依賴於非結構化資料。本研究旨在檢測並減輕與設計用於協助兒童心理健康篩檢的 AI 模型訓練資料中的非生物差異相關的語言差異。我們的目標是：(1) 透過評估不同性別子群體的結果平價來評估偏見的存在，(2) 透過文本分佈分析來找出偏見來源，以及 (3) 開發一種心理健康文本資料的去偏見方法。方法：我們檢查了不同人口群體的分類平價，並評估了性別語言如何影響模型預測。應用了一種以資料為中心的去偏見方法，專注於在保留顯著臨床資訊的同時中和有偏見的術語。此方法在一個用於兒童患者自動焦慮檢測的模型上進行了測試。結果：我們的研究結果揭示了對女性青少年患者的系統性診斷不足，與男性患者相比，準確率低了 4%，假陰性率 (FNR) 高了 9%，這可能是由於患者備註中資訊密度和語言差異的差異。男性患者的備註平均長 500 個字，語言相似性指標顯示不同性別之間的字詞分佈截然不同。實施我們的去偏見方法將診斷偏見降低了 27%，證明了其在提升不同人口群體之間公平性的有效性。討論：我們開發了一個以資料為中心的去偏見架構，用於解決臨床文本中的基於性別的內容差異。透過中和有偏見的語言和加強對臨床必要資訊的關注，我們的做法展示了一種有效策略，用於減輕在文本上訓練的 AI 醫療保健模型中的偏見。</paragraph>

##### **Leveraging AI for Automatic Classification of PCOS Using Ultrasound Imaging**
2501.01984v1 by Atharva Divekar, Atharva Sonawane

The AUTO-PCOS Classification Challenge seeks to advance the diagnostic
capabilities of artificial intelligence (AI) in identifying Polycystic Ovary
Syndrome (PCOS) through automated classification of healthy and unhealthy
ultrasound frames. This report outlines our methodology for building a robust
AI pipeline utilizing transfer learning with the InceptionV3 architecture to
achieve high accuracy in binary classification. Preprocessing steps ensured the
dataset was optimized for training, validation, and testing, while
interpretability methods like LIME and saliency maps provided valuable insights
into the model's decision-making. Our approach achieved an accuracy of 90.52%,
with precision, recall, and F1-score metrics exceeding 90% on validation data,
demonstrating its efficacy. The project underscores the transformative
potential of AI in healthcare, particularly in addressing diagnostic challenges
like PCOS. Key findings, challenges, and recommendations for future
enhancements are discussed, highlighting the pathway for creating reliable,
interpretable, and scalable AI-driven medical diagnostic tools.

摘要：AUTO-PCOS 分類挑戰旨在透過自動分類健康和不健康的超音波影像，提升人工智慧 (AI) 在辨識多囊性卵巢症候群 (PCOS) 的診斷能力。這份報告概述了我們建構強健 AI 管線的方法，利用 InceptionV3 架構進行遷移學習，以在二元分類中達成高準確度。預處理步驟確保資料集已針對訓練、驗證和測試進行最佳化，而 LIME 和顯著性圖等可解釋性方法則提供了有價值的見解，說明模型的決策制定。我們的做法在驗證資料上達到了 90.52% 的準確度，精確度、召回率和 F1 分數都超過 90%，證明了它的效力。這個專案強調了 AI 在醫療保健中的轉型潛力，特別是在解決 PCOS 等診斷挑戰方面。討論了關鍵發現、挑戰和未來增強建議，突顯了建立可靠、可解釋且可擴充的 AI 驅動醫療診斷工具的途徑。

##### **Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks**
2412.20744v1 by Abhinav Roy, Bhavesh Gyanchandani, Aditya Oza, Abhishek Sharma

Parkinson's Disease (PD) is a degenerative neurological disorder that impairs
motor and non-motor functions, significantly reducing quality of life and
increasing mortality risk. Early and accurate detection of PD progression is
vital for effective management and improved patient outcomes. Current
diagnostic methods, however, are often costly, time-consuming, and require
specialized equipment and expertise. This work proposes an innovative approach
to predicting PD progression using regression methods, Long Short-Term Memory
(LSTM) networks, and Kolmogorov Arnold Networks (KAN). KAN, utilizing
spline-parametrized univariate functions, allows for dynamic learning of
activation patterns, unlike traditional linear models.
  The Movement Disorder Society-Sponsored Revision of the Unified Parkinson's
Disease Rating Scale (MDS-UPDRS) is a comprehensive tool for evaluating PD
symptoms and is commonly used to measure disease progression. Additionally,
protein or peptide abnormalities are linked to PD onset and progression.
Identifying these associations can aid in predicting disease progression and
understanding molecular changes.
  Comparing multiple models, including LSTM and KAN, this study aims to
identify the method that delivers the highest metrics. The analysis reveals
that KAN, with its dynamic learning capabilities, outperforms other approaches
in predicting PD progression. This research highlights the potential of AI and
machine learning in healthcare, paving the way for advanced computational
models to enhance clinical predictions and improve patient care and treatment
strategies in PD management.

摘要：帕金森氏症 (PD) 是一種神經退化性疾病，會損害運動和非運動功能，嚴重降低生活品質並增加死亡風險。早期且準確檢測 PD 進程對於有效管理和改善患者預後至關重要。然而，目前的診斷方法通常成本高昂、耗時且需要專業設備和專業知識。這項研究提出了一種創新的方法，使用迴歸方法、長短期記憶 (LSTM) 網路和 Kolmogorov Arnold 網路 (KAN) 來預測 PD 進程。KAN 利用樣條參數化的單變量函數，可以動態學習激活模式，這與傳統線性模型不同。運動障礙協會贊助的統一帕金森氏症評分量表 (MDS-UPDRS) 是評估 PD 症狀的綜合工具，通常用於測量疾病進程。此外，蛋白質或胜肽異常與 PD 發作和進程有關。找出這些關聯可以幫助預測疾病進程並了解分子變化。這項研究比較了包括 LSTM 和 KAN 在內的多種模型，旨在找出提供最高指標的方法。分析顯示，具有動態學習能力的 KAN 在預測 PD 進程方面優於其他方法。這項研究突顯了 AI 和機器學習在醫療保健中的潛力，為先進的計算模型鋪路，以增強臨床預測並改善 PD 管理中的患者照護和治療策略。

##### **Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis**
2412.20651v1 by Yousef Yeganeh, Ioannis Charisiadis, Marta Hasny, Martin Hartenberger, Björn Ommer, Nassir Navab, Azade Farshad, Ehsan Adeli

Scaling by training on large datasets has been shown to enhance the quality
and fidelity of image generation and manipulation with diffusion models;
however, such large datasets are not always accessible in medical imaging due
to cost and privacy issues, which contradicts one of the main applications of
such models to produce synthetic samples where real data is scarce. Also,
finetuning on pre-trained general models has been a challenge due to the
distribution shift between the medical domain and the pre-trained models. Here,
we propose Latent Drift (LD) for diffusion models that can be adopted for any
fine-tuning method to mitigate the issues faced by the distribution shift or
employed in inference time as a condition. Latent Drifting enables diffusion
models to be conditioned for medical images fitted for the complex task of
counterfactual image generation, which is crucial to investigate how parameters
such as gender, age, and adding or removing diseases in a patient would alter
the medical images. We evaluate our method on three public longitudinal
benchmark datasets of brain MRI and chest X-rays for counterfactual image
generation. Our results demonstrate significant performance gains in various
scenarios when combined with different fine-tuning schemes. The source code of
this work will be publicly released upon its acceptance.

摘要：<paragraph>透過訓練大型資料集來調整比例，已被證明可以提升擴散模型影像產生與操作的品質和保真度；然而，由於成本和隱私問題，在醫學影像中並不總是能取得這麼大型的資料集，這與這些模型的主要應用之一相矛盾，也就是在真實資料稀少的情況下產生合成樣本。此外，由於醫學領域與預訓練模型之間的分布轉移，對預訓練的通用模型進行微調一直是一項挑戰。在此，我們提出擴散模型的潛在漂移 (LD)，可以採用任何微調方法來減輕分布轉移所面臨的問題，或在推理時間作為條件使用。潛在漂移使擴散模型能夠針對適合於反事實影像產生複雜任務的醫學影像進行調整，這對於探討諸如性別、年齡以及在患者中增加或移除疾病等參數將如何改變醫學影像至關重要。我們在三個大腦 MRI 和胸部 X 光的公開縱向基準資料集上評估了我們的方法，以進行反事實影像產生。我們的結果表明，與不同的微調方案結合使用時，在各種情況下都能顯著提升效能。這項工作的原始碼將在獲得接受後公開發布。</paragraph>

##### **HALLUCINOGEN: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models**
2412.20622v1 by Ashish Seth, Dinesh Manocha, Chirag Agarwal

Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
in performing complex multimodal tasks. However, they are still plagued by
object hallucination: the misidentification or misclassification of objects
present in images. To this end, we propose HALLUCINOGEN, a novel visual
question answering (VQA) object hallucination attack benchmark that utilizes
diverse contextual reasoning prompts to evaluate object hallucination in
state-of-the-art LVLMs. We design a series of contextual reasoning
hallucination prompts to evaluate LVLMs' ability to accurately identify objects
in a target image while asking them to perform diverse visual-language tasks
such as identifying, locating or performing visual reasoning around specific
objects. Further, we extend our benchmark to high-stakes medical applications
and introduce MED-HALLUCINOGEN, hallucination attacks tailored to the
biomedical domain, and evaluate the hallucination performance of LVLMs on
medical images, a critical area where precision is crucial. Finally, we conduct
extensive evaluations of eight LVLMs and two hallucination mitigation
strategies across multiple datasets to show that current generic and medical
LVLMs remain susceptible to hallucination attacks.

摘要：大型視覺語言模型 (LVLMs) 在執行複雜的多模態任務方面表現出色。然而，它們仍然受到物體幻覺的困擾：錯誤識別或錯誤分類圖像中存在的物體。為此，我們提出了 HALLUCINOGEN，這是一個新穎的視覺問答 (VQA) 物體幻覺攻擊基準，它利用多樣化的上下文推理提示來評估最先進的 LVLMs 中的物體幻覺。我們設計了一系列上下文推理幻覺提示，以評估 LVLMs 在要求它們執行多樣化的視覺語言任務（例如識別、定位或對特定物體進行視覺推理）的同時準確識別目標圖像中物體的能力。此外，我們將基準擴展到高風險的醫學應用，並引入了專門針對生物醫學領域的幻覺攻擊 MED-HALLUCINOGEN，並評估了 LVLMs 在醫學圖像（一個精確至關重要的關鍵領域）上的幻覺表現。最後，我們對八個 LVLMs 和兩個幻覺緩解策略進行了廣泛的評估，跨多個數據集，以表明當前的通用和醫學 LVLMs 仍然容易受到幻覺攻擊。

##### **Dive into Time-Series Anomaly Detection: A Decade Review**
2412.20512v1 by Paul Boniol, Qinghua Liu, Mingyi Huang, Themis Palpanas, John Paparrizos

Recent advances in data collection technology, accompanied by the ever-rising
volume and velocity of streaming data, underscore the vital need for time
series analytics. In this regard, time-series anomaly detection has been an
important activity, entailing various applications in fields such as cyber
security, financial markets, law enforcement, and health care. While
traditional literature on anomaly detection is centered on statistical
measures, the increasing number of machine learning algorithms in recent years
call for a structured, general characterization of the research methods for
time-series anomaly detection. This survey groups and summarizes anomaly
detection existing solutions under a process-centric taxonomy in the time
series context. In addition to giving an original categorization of anomaly
detection methods, we also perform a meta-analysis of the literature and
outline general trends in time-series anomaly detection research.

摘要：隨著資料收集技術的最新進展，以及串流資料的數量和速度持續上升，強調了時間序列分析的迫切需求。在這方面，時間序列異常偵測一直是一項重要的活動，包含網路安全、金融市場、執法和醫療保健等領域中的各種應用。雖然異常偵測的傳統文獻集中於統計測量，但近年來機器學習演算法的數量不斷增加，因此需要對時間序列異常偵測的研究方法進行結構化、通用的描述。這項調查在時間序列脈絡中，依據以流程為中心的分類法，對異常偵測現有解決方案進行分組和摘要。除了對異常偵測方法進行原始分類外，我們也對文獻進行元分析，並概述時間序列異常偵測研究的一般趨勢。

##### **A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data**
2412.20373v1 by Seungyeon Lee, Ruoqi Liu, Feixiong Cheng, Ping Zhang

Drug repurposing identifies new therapeutic uses for existing drugs, reducing
the time and costs compared to traditional de novo drug discovery. Most
existing drug repurposing studies using real-world patient data often treat the
entire population as homogeneous, ignoring the heterogeneity of treatment
responses across patient subgroups. This approach may overlook promising drugs
that benefit specific subgroups but lack notable treatment effects across the
entire population, potentially limiting the number of repurposable candidates
identified. To address this, we introduce STEDR, a novel drug repurposing
framework that integrates subgroup analysis with treatment effect estimation.
Our approach first identifies repurposing candidates by emulating multiple
clinical trials on real-world patient data and then characterizes patient
subgroups by learning subgroup-specific treatment effects. We deploy \model to
Alzheimer's Disease (AD), a condition with few approved drugs and known
heterogeneity in treatment responses. We emulate trials for over one thousand
medications on a large-scale real-world database covering over 8 million
patients, identifying 14 drug candidates with beneficial effects to AD in
characterized subgroups. Experiments demonstrate STEDR's superior capability in
identifying repurposing candidates compared to existing approaches.
Additionally, our method can characterize clinically relevant patient subgroups
associated with important AD-related risk factors, paving the way for precision
drug repurposing.

摘要：药物再利用为现有药物找出新的治疗用途，与传统的从头药物发现相比，减少了时间和成本。大多数使用真实世界患者数据的现有药物再利用研究通常将整个人群视为同质的，而忽略了不同患者亚组治疗反应的异质性。这种方法可能会忽视对特定亚组有益但整个群体缺乏显着治疗效果的有希望的药物，从而可能限制已识别的可再利用候选药物的数量。为了解决这个问题，我们引入了 STEDR，这是一个新颖的药物再利用框架，它将亚组分析与治疗效果估计相结合。我们的方法首先通过模拟真实世界患者数据的多个临床试验来识别再利用候选药物，然后通过学习亚组特异性治疗效果来表征患者亚组。我们部署\model到阿尔茨海默病 (AD)，这是一种已获批药物较少且治疗反应已知异质性的疾病。我们在一个覆盖超过 800 万患者的大规模真实世界数据库上模拟了超过一千种药物的试验，确定了 14 种在表征的亚组中对 AD 有益的候选药物。实验表明，与现有方法相比，STEDR 在识别再利用候选药物方面具有更强的能力。此外，我们的方法可以表征与重要的 AD 相关危险因素相关的临床相关患者亚组，为精准药物再利用铺平道路。

##### **Transforming CCTV cameras into NO$_2$ sensors at city scale for adaptive policymaking**
2501.00056v1 by Mohamed R. Ibrahim, Terry Lyons

Air pollution in cities, especially NO\textsubscript{2}, is linked to
numerous health problems, ranging from mortality to mental health challenges
and attention deficits in children. While cities globally have initiated
policies to curtail emissions, real-time monitoring remains challenging due to
limited environmental sensors and their inconsistent distribution. This gap
hinders the creation of adaptive urban policies that respond to the sequence of
events and daily activities affecting pollution in cities. Here, we demonstrate
how city CCTV cameras can act as a pseudo-NO\textsubscript{2} sensors. Using a
predictive graph deep model, we utilised traffic flow from London's cameras in
addition to environmental and spatial factors, generating NO\textsubscript{2}
predictions from over 133 million frames. Our analysis of London's mobility
patterns unveiled critical spatiotemporal connections, showing how specific
traffic patterns affect NO\textsubscript{2} levels, sometimes with temporal
lags of up to 6 hours. For instance, if trucks only drive at night, their
effects on NO\textsubscript{2} levels are most likely to be seen in the morning
when people commute. These findings cast doubt on the efficacy of some of the
urban policies currently being implemented to reduce pollution. By leveraging
existing camera infrastructure and our introduced methods, city planners and
policymakers could cost-effectively monitor and mitigate the impact of
NO\textsubscript{2} and other pollutants.

摘要：城市中的空氣污染，特別是二氧化氮，與許多健康問題有關，從死亡率到兒童的精神健康挑戰和注意力缺陷。儘管全球城市已啟動政策來減少排放，但由於環境感測器有限且分佈不均，實時監測仍然具有挑戰性。這個差距阻礙了適應性城市政策的制定，這些政策對影響城市污染的事件順序和日常活動做出回應。在此，我們展示了城市閉路電視攝影機如何充當偽二氧化氮感測器。使用預測圖深度模型，我們利用了倫敦攝影機的交通流量以及環境和空間因素，從超過 1.33 億個畫面中生成了二氧化氮預測。我們對倫敦流動模式的分析揭示了關鍵的時空連接，展示了具體的交通模式如何影響二氧化氮水平，有時時間滯後長達 6 小時。例如，如果卡車只在晚上行駛，它們對二氧化氮水平的影響最有可能在人們通勤的早上顯現。這些發現對目前實施的一些旨在減少污染的城市政策的有效性提出了質疑。通過利用現有的攝影機基礎設施和我們引入的方法，城市規劃者和政策制定者可以經濟有效地監控和減輕二氧化氮和其他污染物的影響。

##### **On the Compositional Generalization of Multimodal LLMs for Medical Imaging**
2412.20070v1 by Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang

Multimodal large language models (MLLMs) hold significant potential in the
medical field, but their capabilities are often limited by insufficient data in
certain medical domains, highlighting the need for understanding what kinds of
images can be used by MLLMs for generalization. Current research suggests that
multi-task training outperforms single-task as different tasks can benefit each
other, but they often overlook the internal relationships within these tasks,
providing limited guidance on selecting datasets to enhance specific tasks. To
analyze this phenomenon, we attempted to employ compositional generalization
(CG)-the ability of models to understand novel combinations by recombining
learned elements-as a guiding framework. Since medical images can be precisely
defined by Modality, Anatomical area, and Task, naturally providing an
environment for exploring CG. Therefore, we assembled 106 medical datasets to
create Med-MAT for comprehensive experiments. The experiments confirmed that
MLLMs can use CG to understand unseen medical images and identified CG as one
of the main drivers of the generalization observed in multi-task training.
Additionally, further studies demonstrated that CG effectively supports
datasets with limited data and delivers consistent performance across different
backbones, highlighting its versatility and broad applicability. Med-MAT is
publicly available at https://github.com/FreedomIntelligence/Med-MAT.

摘要：多模态大型语言模型 (MLLM) 在医疗领域拥有巨大潜力，但其能力往往受到特定医疗领域数据不足的限制，这突出了理解 MLLM 可用于泛化的图像类型的必要性。当前的研究表明，多任务训练优于单任务训练，因为不同的任务可以相互受益，但它们常常忽略这些任务中的内部关系，在选择数据集以增强特定任务方面提供的指导有限。为了分析这种现象，我们尝试采用组合泛化 (CG)——模型通过重新组合学习的元素来理解新组合的能力——作为指导框架。由于医学图像可以通过方式、解剖区域和任务来精确定义，因此自然地为探索 CG 提供了一个环境。因此，我们组装了 106 个医学数据集来创建 Med-MAT 以进行综合实验。实验证实，MLLM 可以使用 CG 来理解看不见的医学图像，并将 CG 确定为多任务训练中观察到的泛化的主要驱动因素之一。此外，进一步的研究表明，CG 有效地支持了数据有限的数据集，并在不同的主干中提供了持续的性能，突出了其多功能性和广泛的适用性。Med-MAT 在 https://github.com/FreedomIntelligence/Med-MAT 公开可用。

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

摘要：隨著對心理健康服務需求的增加，凸顯了創新解決方案的需求，特別是在心理對話式人工智慧領域，那裡缺乏敏感資料。在這項工作中，我們探索了開發一個針對心理健康支持的系統，採用一種基於可解釋的情緒特徵的新方法進行心理評估，結合同理心對話模式，提供了一個有前途的工具，用於擴充傳統照護，特別是在無法立即獲得專業知識的情況下。我們的工作可以分為兩個主要部分，彼此內在相關。首先，我們展示了 RACLETTE，一個對話系統，與最先進的基準相比，在理解使用者情緒狀態和在對話中產生同理心回應方面表現出優越的情緒準確性，同時透過他們的互動逐漸建立使用者的情緒特徵。其次，我們展示了使用者的情緒特徵如何可用作心理健康評估的可解釋標記。這些特徵可以與與不同心理疾病相關的典型情緒模式進行比較，提供了一種初步篩選和支持的新方法。

##### **MobileNetV2: A lightweight classification model for home-based sleep apnea screening**
2412.19967v2 by Hui Pan, Yanxuan Yu, Jilun Ye, Xu Zhang

This study proposes a novel lightweight neural network model leveraging
features extracted from electrocardiogram (ECG) and respiratory signals for
early OSA screening. ECG signals are used to generate feature spectrograms to
predict sleep stages, while respiratory signals are employed to detect
sleep-related breathing abnormalities. By integrating these predictions, the
method calculates the apnea-hypopnea index (AHI) with enhanced accuracy,
facilitating precise OSA diagnosis.
  The method was validated on three publicly available sleep apnea databases:
the Apnea-ECG database, the UCDDB dataset, and the MIT-BIH Polysomnographic
database. Results showed an overall OSA detection accuracy of 0.978,
highlighting the model's robustness. Respiratory event classification achieved
an accuracy of 0.969 and an area under the receiver operating characteristic
curve (ROC-AUC) of 0.98. For sleep stage classification, in UCDDB dataset, the
ROC-AUC exceeded 0.85 across all stages, with recall for Sleep reaching 0.906
and specificity for REM and Wake states at 0.956 and 0.937, respectively.
  This study underscores the potential of integrating lightweight neural
networks with multi-signal analysis for accurate, portable, and cost-effective
OSA screening, paving the way for broader adoption in home-based and wearable
health monitoring systems.

摘要：本研究提出一個新穎的輕量級神經網路模型，利用從心電圖 (ECG) 和呼吸信號中提取的特徵，進行早期 OSA 篩檢。ECG 信號用於產生特徵頻譜圖，以預測睡眠階段，而呼吸信號則用於偵測與睡眠相關的呼吸異常。透過整合這些預測，此方法計算出具有更高精確度的呼吸中止低通氣指數 (AHI)，促進精確的 OSA 診斷。
該方法已在三個公開的睡眠呼吸中止症資料庫中驗證：呼吸中止症-ECG 資料庫、UCDDB 資料集和 MIT-BIH 多重睡眠生理檢查資料庫。結果顯示整體 OSA 檢測準確度為 0.978，突顯了該模型的穩健性。呼吸事件分類的準確度達到 0.969，且在受試者操作特徵曲線 (ROC-AUC) 下方的面積為 0.98。對於睡眠階段分類，在 UCDDB 資料集中，所有階段的 ROC-AUC 均超過 0.85，睡眠的召回率達到 0.906，而 REM 和清醒狀態的特異性分別為 0.956 和 0.937。
本研究強調了將輕量級神經網路與多信號分析整合的潛力，以進行準確、可攜式且具成本效益的 OSA 篩檢，為在居家和穿戴式健康監測系統中更廣泛採用鋪路。

##### **ErgoChat: a Visual Query System for the Ergonomic Risk Assessment of Construction Workers**
2412.19954v1 by Chao Fan, Qipei Mei, Xiaonan Wang, Xinming Li

In the construction sector, workers often endure prolonged periods of
high-intensity physical work and prolonged use of tools, resulting in injuries
and illnesses primarily linked to postural ergonomic risks, a longstanding
predominant health concern. To mitigate these risks, researchers have applied
various technological methods to identify the ergonomic risks that construction
workers face. However, traditional ergonomic risk assessment (ERA) techniques
do not offer interactive feedback. The rapidly developing vision-language
models (VLMs), capable of generating textual descriptions or answering
questions about ergonomic risks based on image inputs, have not yet received
widespread attention. This research introduces an interactive visual query
system tailored to assess the postural ergonomic risks of construction workers.
The system's capabilities include visual question answering (VQA), which
responds to visual queries regarding workers' exposure to postural ergonomic
risks, and image captioning (IC), which generates textual descriptions of these
risks from images. Additionally, this study proposes a dataset designed for
training and testing such methodologies. Systematic testing indicates that the
VQA functionality delivers an accuracy of 96.5%. Moreover, evaluations using
nine metrics for IC and assessments from human experts indicate that the
proposed approach surpasses the performance of a method using the same
architecture trained solely on generic datasets. This study sets a new
direction for future developments in interactive ERA using generative
artificial intelligence (AI) technologies.

摘要：在建築業中，工人經常忍受長時間高強度體力勞動和長時間使用工具，導致受傷和疾病，這些問題主要與姿勢人體工學風險有關，這是一個長期的主要健康問題。為了減輕這些風險，研究人員應用各種技術方法來識別建築工人面臨的人體工學風險。然而，傳統的人體工學風險評估 (ERA) 技術並不能提供互動式回饋。快速發展的視覺語言模型 (VLM) 能夠根據影像輸入產生文字描述或回答有關人體工學風險的問題，但尚未受到廣泛關注。本研究介紹了一個互動式視覺查詢系統，專門用於評估建築工人的姿勢人體工學風險。該系統的功能包括視覺問答 (VQA)，它可以回答有關工人接觸姿勢人體工學風險的視覺查詢，以及影像標題 (IC)，它可以根據影像產生這些風險的文字描述。此外，本研究提出了一個專門用於訓練和測試此類方法的資料集。系統性測試表明，VQA 功能的準確度為 96.5%。此外，使用九個 IC 指標進行的評估和來自人類專家的評估表明，所提出的方法超越了使用相同架構僅在通用資料集上訓練的方法的效能。本研究為使用生成式人工智慧 (AI) 技術的互動式 ERA 未來發展設定了一個新方向。

