{"2411.16345": {"publish_time": "2024-11-25", "title": "Preference Optimization for Reasoning with Pseudo Feedback", "paper_summary": "Preference optimization techniques, such as Direct Preference Optimization\n(DPO), are frequently employed to enhance the reasoning capabilities of large\nlanguage models (LLMs) in domains like mathematical reasoning and coding,\ntypically following supervised fine-tuning. These methods rely on high-quality\nlabels for reasoning tasks to generate preference pairs; however, the\navailability of reasoning datasets with human-verified labels is limited. In\nthis study, we introduce a novel approach to generate pseudo feedback for\nreasoning tasks by framing the labeling of solutions to reason problems as an\nevaluation against associated test cases. We explore two forms of pseudo\nfeedback based on test cases: one generated by frontier LLMs and the other by\nextending self-consistency to multi-test-case. We conduct experiments on both\nmathematical reasoning and coding tasks using pseudo feedback for preference\noptimization, and observe improvements across both tasks. Specifically, using\nMathstral-7B as our base model, we improve MATH results from 58.3 to 68.6,\nsurpassing both NuminaMath-72B and GPT-4-Turbo-1106-preview. In GSM8K and\nCollege Math, our scores increase from 85.6 to 90.3 and from 34.3 to 42.3,\nrespectively. Building on Deepseek-coder-7B-v1.5, we achieve a score of 24.6 on\nLiveCodeBench (from 21.1), surpassing Claude-3-Haiku.", "paper_summary_zh": "\u504f\u597d\u512a\u5316\u6280\u8853\uff0c\u4f8b\u5982\u76f4\u63a5\u504f\u597d\u512a\u5316 (DPO)\uff0c\u7d93\u5e38\u88ab\u7528\u4f86\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u6578\u5b78\u63a8\u7406\u548c\u7de8\u78bc\u7b49\u9818\u57df\u7684\u63a8\u7406\u80fd\u529b\uff0c\u901a\u5e38\u9075\u5faa\u76e3\u7763\u5fae\u8abf\u3002\u9019\u4e9b\u65b9\u6cd5\u4f9d\u8cf4\u65bc\u63a8\u7406\u4efb\u52d9\u7684\u9ad8\u54c1\u8cea\u6a19\u7c64\u4f86\u7522\u751f\u504f\u597d\u5c0d\uff1b\u7136\u800c\uff0c\u5177\u6709\u4eba\u5de5\u9a57\u8b49\u6a19\u7c64\u7684\u63a8\u7406\u6578\u64da\u96c6\u7684\u53ef\u7528\u6027\u662f\u6709\u9650\u7684\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7684\u65b9\u6cd5\u4f86\u7522\u751f\u63a8\u7406\u4efb\u52d9\u7684\u507d\u56de\u994b\uff0c\u65b9\u6cd5\u662f\u5c07\u63a8\u7406\u554f\u984c\u7684\u89e3\u6a19\u8a18\u69cb\u5efa\u70ba\u91dd\u5c0d\u95dc\u806f\u6e2c\u8a66\u6848\u4f8b\u7684\u8a55\u4f30\u3002\u6211\u5011\u63a2\u7d22\u4e86\u5169\u7a2e\u57fa\u65bc\u6e2c\u8a66\u6848\u4f8b\u7684\u507d\u56de\u994b\u5f62\u5f0f\uff1a\u4e00\u7a2e\u7531\u908a\u7de3 LLM \u7522\u751f\uff0c\u53e6\u4e00\u7a2e\u901a\u904e\u5c07\u81ea\u6211\u4e00\u81f4\u6027\u64f4\u5c55\u5230\u591a\u6e2c\u8a66\u6848\u4f8b\u3002\u6211\u5011\u5c0d\u6578\u5b78\u63a8\u7406\u548c\u7de8\u78bc\u4efb\u52d9\u9032\u884c\u4e86\u5be6\u9a57\uff0c\u4f7f\u7528\u507d\u56de\u994b\u9032\u884c\u504f\u597d\u512a\u5316\uff0c\u4e26\u89c0\u5bdf\u5230\u5169\u9805\u4efb\u52d9\u90fd\u6709\u6539\u9032\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u4f7f\u7528 Mathstral-7B \u4f5c\u70ba\u6211\u5011\u7684\u57fa\u790e\u6a21\u578b\uff0c\u6211\u5011\u5c07 MATH \u7d50\u679c\u5f9e 58.3 \u63d0\u9ad8\u5230 68.6\uff0c\u8d85\u904e\u4e86 NuminaMath-72B \u548c GPT-4-Turbo-1106-preview\u3002\u5728 GSM8K \u548c College Math \u4e2d\uff0c\u6211\u5011\u7684\u5206\u6578\u5206\u5225\u5f9e 85.6 \u589e\u52a0\u5230 90.3\uff0c\u5f9e 34.3 \u589e\u52a0\u5230 42.3\u3002\u5728 Deepseek-coder-7B-v1.5 \u7684\u57fa\u790e\u4e0a\uff0c\u6211\u5011\u5728 LiveCodeBench \u4e0a\u9054\u5230\u4e86 24.6 \u7684\u5206\u6578\uff08\u5f9e 21.1\uff09\uff0c\u8d85\u904e\u4e86 Claude-3-Haiku\u3002", "author": "Fangkai Jiao et.al.", "authors": "Fangkai Jiao, Geyang Guo, Xingxing Zhang, Nancy F. Chen, Shafiq Joty, Furu Wei", "id": "2411.16345v1", "paper_url": "http://arxiv.org/abs/2411.16345v1", "repo": "null"}}