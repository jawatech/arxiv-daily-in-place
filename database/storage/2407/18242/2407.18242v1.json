{"2407.18242": {"publish_time": "2024-07-25", "title": "LoRA-Pro: Are Low-Rank Adapters Properly Optimized?", "paper_summary": "Low-Rank Adaptation, also known as LoRA, has emerged as a prominent method\nfor parameter-efficient fine-tuning foundation models by re-parameterizing the\noriginal matrix into the product of two low-rank matrices. Despite its\nefficiency, LoRA often yields inferior performance compared to full\nfine-tuning. In this paper, we propose LoRA-Pro to bridge this performance gap.\nFirstly, we delve into the optimization processes in LoRA and full fine-tuning.\nWe reveal that while LoRA employs low-rank approximation, it neglects to\napproximate the optimization process of full fine-tuning. To address this, we\nintroduce a novel concept called the \"equivalent gradient.\" This virtual\ngradient makes the optimization process on the re-parameterized matrix\nequivalent to LoRA, which can be used to quantify the differences between LoRA\nand full fine-tuning. The equivalent gradient is derived from the gradients of\nmatrices $A$ and $B$. To narrow the performance gap, our approach minimizes the\ndifferences between the equivalent gradient and the gradient obtained from full\nfine-tuning during the optimization process. By solving this objective, we\nderive optimal closed-form solutions for updating matrices $A$ and $B$. Our\nmethod constrains the optimization process, shrinking the performance gap\nbetween LoRA and full fine-tuning. Extensive experiments on natural language\nprocessing tasks validate the effectiveness of our method.", "paper_summary_zh": "\u4f4e\u79e9\u9069\u61c9\uff08LoRA\uff09\u5df2\u6210\u70ba\u4e00\u7a2e\u91cd\u8981\u7684\u65b9\u6cd5\uff0c\u53ef\u900f\u904e\u5c07\u539f\u59cb\u77e9\u9663\u91cd\u65b0\u53c3\u6578\u5316\u70ba\u5169\u500b\u4f4e\u79e9\u77e9\u9663\u7684\u4e58\u7a4d\uff0c\u5c0d\u53c3\u6578\u6709\u6548\u7387\u7684\u5fae\u8abf\u57fa\u790e\u6a21\u578b\u3002\u5118\u7ba1 LoRA \u5177\u6709\u6548\u7387\uff0c\u4f46\u8207\u5b8c\u6574\u5fae\u8abf\u76f8\u6bd4\uff0c\u5176\u6548\u80fd\u901a\u5e38\u8f03\u5dee\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa LoRA-Pro \u4f86\u5f4c\u5408\u6b64\u6548\u80fd\u5dee\u8ddd\u3002\u9996\u5148\uff0c\u6211\u5011\u6df1\u5165\u63a2\u8a0e LoRA \u548c\u5b8c\u6574\u5fae\u8abf\u4e2d\u7684\u6700\u4f73\u5316\u7a0b\u5e8f\u3002\u6211\u5011\u63ed\u793a\uff0c\u5118\u7ba1 LoRA \u63a1\u7528\u4f4e\u79e9\u8fd1\u4f3c\uff0c\u4f46\u5b83\u5ffd\u7565\u4e86\u5b8c\u6574\u5fae\u8abf\u7684\u6700\u4f73\u5316\u7a0b\u5e8f\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u540d\u70ba\u300c\u7b49\u6548\u68af\u5ea6\u300d\u7684\u65b0\u6982\u5ff5\u3002\u9019\u500b\u865b\u64ec\u68af\u5ea6\u4f7f\u91cd\u65b0\u53c3\u6578\u5316\u77e9\u9663\u4e0a\u7684\u6700\u4f73\u5316\u7a0b\u5e8f\u7b49\u540c\u65bc LoRA\uff0c\u53ef\u7528\u6765\u91cf\u5316 LoRA \u548c\u5b8c\u6574\u5fae\u8abf\u4e4b\u9593\u7684\u5dee\u7570\u3002\u7b49\u6548\u68af\u5ea6\u4f86\u81ea\u77e9\u9663 A \u548c B \u7684\u68af\u5ea6\u3002\u70ba\u4e86\u7e2e\u5c0f\u6548\u80fd\u5dee\u8ddd\uff0c\u6211\u5011\u7684\u505a\u6cd5\u662f\u5728\u6700\u4f73\u5316\u7a0b\u5e8f\u4e2d\u6700\u5c0f\u5316\u7b49\u6548\u68af\u5ea6\u548c\u5f9e\u5b8c\u6574\u5fae\u8abf\u4e2d\u7372\u5f97\u7684\u68af\u5ea6\u4e4b\u9593\u7684\u5dee\u7570\u3002\u900f\u904e\u89e3\u6c7a\u9019\u500b\u76ee\u6a19\uff0c\u6211\u5011\u63a8\u5c0e\u51fa\u66f4\u65b0\u77e9\u9663 A \u548c B \u7684\u6700\u4f73\u9589\u5f0f\u89e3\u3002\u6211\u5011\u7684\u505a\u6cd5\u7d04\u675f\u4e86\u6700\u4f73\u5316\u7a0b\u5e8f\uff0c\u7e2e\u5c0f\u4e86 LoRA \u548c\u5b8c\u6574\u5fae\u8abf\u4e4b\u9593\u7684\u6548\u80fd\u5dee\u8ddd\u3002\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e0a\u7684\u5927\u91cf\u5be6\u9a57\u9a57\u8b49\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "author": "Zhengbo Wang et.al.", "authors": "Zhengbo Wang, Jian Liang", "id": "2407.18242v1", "paper_url": "http://arxiv.org/abs/2407.18242v1", "repo": "https://github.com/mrflogs/LoRA-Pro"}}