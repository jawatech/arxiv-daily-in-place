{"2405.20606": {"publish_time": "2024-05-31", "title": "Vision-Language Meets the Skeleton: Progressively Distillation with Cross-Modal Knowledge for 3D Action Representation Learning", "paper_summary": "Supervised and self-supervised learning are two main training paradigms for\nskeleton-based human action recognition. However, the former one-hot\nclassification requires labor-intensive predefined action categories\nannotations, while the latter involves skeleton transformations (e.g.,\ncropping) in the pretext tasks that may impair the skeleton structure. To\naddress these challenges, we introduce a novel skeleton-based training\nframework (C$^2$VL) based on Cross-modal Contrastive learning that uses the\nprogressive distillation to learn task-agnostic human skeleton action\nrepresentation from the Vision-Language knowledge prompts. Specifically, we\nestablish the vision-language action concept space through vision-language\nknowledge prompts generated by pre-trained large multimodal models (LMMs),\nwhich enrich the fine-grained details that the skeleton action space lacks.\nMoreover, we propose the intra-modal self-similarity and inter-modal\ncross-consistency softened targets in the cross-modal contrastive process to\nprogressively control and guide the degree of pulling vision-language knowledge\nprompts and corresponding skeletons closer. These soft instance discrimination\nand self-knowledge distillation strategies contribute to the learning of better\nskeleton-based action representations from the noisy skeleton-vision-language\npairs. During the inference phase, our method requires only the skeleton data\nas the input for action recognition and no longer for vision-language prompts.\nExtensive experiments show that our method achieves state-of-the-art results on\nNTU RGB+D 60, NTU RGB+D 120, and PKU-MMD datasets. The code will be available\nin the future.", "paper_summary_zh": "<paragraph>\u76e3\u7763\u5f0f\u548c\u81ea\u76e3\u7763\u5f0f\u5b78\u7fd2\u662f\u57fa\u65bc\u9aa8\u67b6\u7684\u4eba\u985e\u52d5\u4f5c\u8fa8\u8b58\u7684\u5169\u7a2e\u4e3b\u8981\u8a13\u7df4\u7bc4\u4f8b\u3002\u7136\u800c\uff0c\u524d\u8005\u7684\u4e00\u71b1\u7de8\u78bc\u5206\u985e\u9700\u8981\u5927\u91cf\u4eba\u5de5\u9810\u5b9a\u7fa9\u7684\u52d5\u4f5c\u985e\u5225\u8a3b\u89e3\uff0c\u800c\u5f8c\u8005\u5247\u6d89\u53ca\u5728\u53ef\u80fd\u640d\u5bb3\u9aa8\u67b6\u7d50\u69cb\u7684\u85c9\u53e3\u4efb\u52d9\u4e2d\u9032\u884c\u9aa8\u67b6\u8f49\u63db\uff08\u4f8b\u5982\uff0c\u88c1\u526a\uff09\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u57fa\u65bc\u8de8\u6a21\u614b\u5c0d\u6bd4\u5b78\u7fd2\u7684\u65b0\u578b\u57fa\u65bc\u9aa8\u67b6\u7684\u8a13\u7df4\u6846\u67b6\uff08C$^2$VL\uff09\uff0c\u8a72\u6846\u67b6\u4f7f\u7528\u6f38\u9032\u5f0f\u84b8\u993e\u5f9e\u8996\u89ba\u8a9e\u8a00\u77e5\u8b58\u63d0\u793a\u4e2d\u5b78\u7fd2\u8207\u4efb\u52d9\u7121\u95dc\u7684\u4eba\u9ad4\u9aa8\u67b6\u52d5\u4f5c\u8868\u793a\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u901a\u904e\u9810\u5148\u8a13\u7df4\u7684\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b\uff08LMM\uff09\u7522\u751f\u7684\u8996\u89ba\u8a9e\u8a00\u77e5\u8b58\u63d0\u793a\u5efa\u7acb\u4e86\u8996\u89ba\u8a9e\u8a00\u52d5\u4f5c\u6982\u5ff5\u7a7a\u9593\uff0c\u9019\u8c50\u5bcc\u4e86\u9aa8\u67b6\u52d5\u4f5c\u7a7a\u9593\u6240\u7f3a\u4e4f\u7684\u7d30\u7c92\u5ea6\u7d30\u7bc0\u3002\u6b64\u5916\uff0c\u6211\u5011\u5728\u8de8\u6a21\u614b\u5c0d\u6bd4\u904e\u7a0b\u4e2d\u63d0\u51fa\u4e86\u6a21\u614b\u5167\u81ea\u76f8\u4f3c\u6027\u548c\u6a21\u614b\u9593\u4ea4\u53c9\u4e00\u81f4\u6027\u8edf\u5316\u76ee\u6a19\uff0c\u4ee5\u6f38\u9032\u5f0f\u5730\u63a7\u5236\u548c\u5f15\u5c0e\u62c9\u52d5\u8996\u89ba\u8a9e\u8a00\u77e5\u8b58\u63d0\u793a\u548c\u76f8\u61c9\u9aa8\u67b6\u66f4\u63a5\u8fd1\u7684\u7a0b\u5ea6\u3002\u9019\u4e9b\u8edf\u5be6\u4f8b\u5340\u5206\u548c\u81ea\u6211\u77e5\u8b58\u84b8\u993e\u7b56\u7565\u6709\u52a9\u65bc\u5f9e\u5608\u96dc\u7684\u9aa8\u67b6\u8996\u89ba\u8a9e\u8a00\u5c0d\u4e2d\u5b78\u7fd2\u66f4\u597d\u7684\u57fa\u65bc\u9aa8\u67b6\u7684\u52d5\u4f5c\u8868\u793a\u3002\u5728\u63a8\u7406\u968e\u6bb5\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u53ea\u9700\u8981\u9aa8\u67b6\u6578\u64da\u4f5c\u70ba\u52d5\u4f5c\u8b58\u5225\u7684\u8f38\u5165\uff0c\u4e0d\u518d\u9700\u8981\u8996\u89ba\u8a9e\u8a00\u63d0\u793a\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u7684\u65b9\u6cd5\u5728 NTU RGB+D 60\u3001NTU RGB+D 120 \u548c PKU-MMD \u6578\u64da\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u7d50\u679c\u3002\u4ee3\u78bc\u5c07\u5728\u672a\u4f86\u63d0\u4f9b\u3002</paragraph>", "author": "Yang Chen et.al.", "authors": "Yang Chen, Tian He, Junfeng Fu, Ling Wang, Jingcai Guo, Hong Cheng", "id": "2405.20606v1", "paper_url": "http://arxiv.org/abs/2405.20606v1", "repo": "null"}}