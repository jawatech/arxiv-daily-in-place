
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-16**|**4D Panoptic Scene Graph Generation**|Jingkang Yang et.al.|[2405.10305v1](http://arxiv.org/abs/2405.10305v1)|[link](https://github.com/jingkang50/psg4d)|
|**2024-05-16**|**Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees**|Yu Gui et.al.|[2405.10301v1](http://arxiv.org/abs/2405.10301v1)|null|
|**2024-05-16**|**HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models**|Rhea Sanjay Sukthanker et.al.|[2405.10299v1](http://arxiv.org/abs/2405.10299v1)|[link](https://github.com/automl/hw-aware-llm-bench)|
|**2024-05-16**|**Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning**|Yuexiang Zhai et.al.|[2405.10292v1](http://arxiv.org/abs/2405.10292v1)|null|
|**2024-05-16**|**Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction**|Jianhao Chen et.al.|[2405.10288v1](http://arxiv.org/abs/2405.10288v1)|null|
|**2024-05-16**|**FFF: Fixing Flawed Foundations in contrastive pre-training results in very strong Vision-Language models**|Adrian Bulat et.al.|[2405.10286v1](http://arxiv.org/abs/2405.10286v1)|null|
|**2024-05-16**|**Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers**|Tuo Zhang et.al.|[2405.10276v1](http://arxiv.org/abs/2405.10276v1)|null|
|**2024-05-16**|**Faces that Speak: Jointly Synthesising Talking Face and Speech from Text**|Youngjoon Jang et.al.|[2405.10272v1](http://arxiv.org/abs/2405.10272v1)|null|
|**2024-05-16**|**Automated Federated Learning via Informed Pruning**|Christian Internò et.al.|[2405.10271v1](http://arxiv.org/abs/2405.10271v1)|[link](https://github.com/christianinterno/autoflip)|
|**2024-05-16**|**A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision**|Charles Raude et.al.|[2405.10266v1](http://arxiv.org/abs/2405.10266v1)|null|
|**2024-05-16**|**Keep It Private: Unsupervised Privatization of Online Text**|Calvin Bao et.al.|[2405.10260v1](http://arxiv.org/abs/2405.10260v1)|[link](https://github.com/csbao/kip-privatization)|
|**2024-05-16**|**A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks**|Xuanfan Ni et.al.|[2405.10251v1](http://arxiv.org/abs/2405.10251v1)|null|
|**2024-05-16**|**ENADPool: The Edge-Node Attention-based Differentiable Pooling for Graph Neural Networks**|Zhehan Zhao et.al.|[2405.10218v1](http://arxiv.org/abs/2405.10218v1)|null|
|**2024-05-16**|**Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting**|Divij Gupta et.al.|[2405.10216v1](http://arxiv.org/abs/2405.10216v1)|null|
|**2024-05-16**|**SMLP: Symbolic Machine Learning Prover (User Manual)**|Franz Brauße et.al.|[2405.10215v1](http://arxiv.org/abs/2405.10215v1)|[link](https://github.com/fbrausse/smlp)|
|**2024-05-16**|**CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations**|Jiahao Zhao et.al.|[2405.10212v1](http://arxiv.org/abs/2405.10212v1)|null|
|**2024-05-16**|**Building a Luganda Text-to-Speech Model From Crowdsourced Data**|Sulaiman Kagumire et.al.|[2405.10211v1](http://arxiv.org/abs/2405.10211v1)|null|
|**2024-05-16**|**Hierarchical Attention Graph for Scientific Document Summarization in Global and Local Level**|Chenlong Zhao et.al.|[2405.10202v1](http://arxiv.org/abs/2405.10202v1)|[link](https://github.com/molichenxi/haesum)|
|**2024-05-16**|**LFED: A Literary Fiction Evaluation Dataset for Large Language Models**|Linhao Yu et.al.|[2405.10166v1](http://arxiv.org/abs/2405.10166v1)|[link](https://github.com/tjunlp-lab/lfed)|
|**2024-05-16**|**PIR: Remote Sensing Image-Text Retrieval with Prior Instruction Representation Learning**|Jiancheng Pan et.al.|[2405.10160v1](http://arxiv.org/abs/2405.10160v1)|[link](https://github.com/jaychempan/pir-clip)|
|**2024-05-16**|**Speaker Verification in Agent-Generated Conversations**|Yizhe Yang et.al.|[2405.10150v1](http://arxiv.org/abs/2405.10150v1)|null|
|**2024-05-16**|**PL-MTEB: Polish Massive Text Embedding Benchmark**|Rafał Poświata et.al.|[2405.10138v1](http://arxiv.org/abs/2405.10138v1)|[link](https://github.com/rafalposwiata/pl-mteb)|
|**2024-05-16**|**Turkronicles: Diachronic Resources for the Fast Evolving Turkish Language**|Togay Yazar et.al.|[2405.10133v1](http://arxiv.org/abs/2405.10133v1)|null|
|**2024-05-16**|**StyloAI: Distinguishing AI-Generated Content with Stylometric Analysis**|Chidimma Opara et.al.|[2405.10129v1](http://arxiv.org/abs/2405.10129v1)|null|
|**2024-05-16**|**Red Teaming Language Models for Contradictory Dialogues**|Xiaofei Wen et.al.|[2405.10128v1](http://arxiv.org/abs/2405.10128v1)|null|
|**2024-05-16**|**Distilling Implicit Multimodal Knowledge into LLMs for Zero-Resource Dialogue Generation**|Bo Zhang et.al.|[2405.10121v1](http://arxiv.org/abs/2405.10121v1)|null|
|**2024-05-16**|**A novel Reservoir Architecture for Periodic Time Series Prediction**|Zhongju Yuan et.al.|[2405.10102v1](http://arxiv.org/abs/2405.10102v1)|null|
|**2024-05-16**|**LaT-PFN: A Joint Embedding Predictive Architecture for In-context Time-series Forecasting**|Stijn Verdenius et.al.|[2405.10093v1](http://arxiv.org/abs/2405.10093v1)|null|
|**2024-05-16**|**An Integrated Framework for Multi-Granular Explanation of Video Summarization**|Konstantinos Tsigos et.al.|[2405.10082v1](http://arxiv.org/abs/2405.10082v1)|null|
|**2024-05-16**|**HecVL: Hierarchical Video-Language Pretraining for Zero-shot Surgical Phase Recognition**|Kun Yuan et.al.|[2405.10075v1](http://arxiv.org/abs/2405.10075v1)|null|
|**2024-05-16**|**MarkLLM: An Open-Source Toolkit for LLM Watermarking**|Leyi Pan et.al.|[2405.10051v1](http://arxiv.org/abs/2405.10051v1)|[link](https://github.com/thu-bpm/markllm)|
|**2024-05-16**|**Global Benchmark Database**|Markus Iser et.al.|[2405.10045v1](http://arxiv.org/abs/2405.10045v1)|null|
|**2024-05-16**|**SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation**|Abhishek Divekar et.al.|[2405.10040v1](http://arxiv.org/abs/2405.10040v1)|null|
|**2024-05-16**|**Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models**|Yuchen Hu et.al.|[2405.10025v1](http://arxiv.org/abs/2405.10025v1)|null|
|**2024-05-16**|**Natural Language Can Help Bridge the Sim2Real Gap**|Albert Yu et.al.|[2405.10020v1](http://arxiv.org/abs/2405.10020v1)|null|
|**2024-05-16**|**Histopathology Foundation Models Enable Accurate Ovarian Cancer Subtype Classification**|Jack Breen et.al.|[2405.09990v1](http://arxiv.org/abs/2405.09990v1)|[link](https://github.com/scjjb/ovarian_features)|
|**2024-05-16**|**Zero-Shot Hierarchical Classification on the Common Procurement Vocabulary Taxonomy**|Federico Moiraghi et.al.|[2405.09983v1](http://arxiv.org/abs/2405.09983v1)|null|
|**2024-05-16**|**FinTextQA: A Dataset for Long-form Financial Question Answering**|Jian Chen et.al.|[2405.09980v1](http://arxiv.org/abs/2405.09980v1)|null|
|**2024-05-16**|**Predicting Solar Heat Production to Optimize Renewable Energy Usage**|Tatiana Boura et.al.|[2405.09972v1](http://arxiv.org/abs/2405.09972v1)|null|
|**2024-05-16**|**Mitigating Text Toxicity with Counterfactual Generation**|Milan Bhan et.al.|[2405.09948v1](http://arxiv.org/abs/2405.09948v1)|null|
|**2024-05-16**|**SciQAG: A Framework for Auto-Generated Scientific Question Answering Dataset with Fine-grained Evaluation**|Yuwei Wan et.al.|[2405.09939v1](http://arxiv.org/abs/2405.09939v1)|null|
|**2024-05-16**|**DEBATE: Devil's Advocate-Based Assessment and Text Evaluation**|Alex Kim et.al.|[2405.09935v1](http://arxiv.org/abs/2405.09935v1)|null|
|**2024-05-16**|**Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance**|Milda Pocevičiūtė et.al.|[2405.09934v1](http://arxiv.org/abs/2405.09934v1)|null|
|**2024-05-16**|**MiniMaxAD: A Lightweight Autoencoder for Feature-Rich Anomaly Detection**|Fengjie Wang et.al.|[2405.09933v1](http://arxiv.org/abs/2405.09933v1)|null|
|**2024-05-16**|**TransMI: A Framework to Create Strong Baselines from Multilingual Pretrained Language Models for Transliterated Data**|Yihong Liu et.al.|[2405.09913v1](http://arxiv.org/abs/2405.09913v1)|[link](https://github.com/cisnlp/transmi)|
|**2024-05-16**|**Unveiling the Potential: Harnessing Deep Metric Learning to Circumvent Video Streaming Encryption**|Arwin Gansekoele et.al.|[2405.09902v1](http://arxiv.org/abs/2405.09902v1)|null|
|**2024-05-16**|**Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models**|Ziyu Wang et.al.|[2405.09901v1](http://arxiv.org/abs/2405.09901v1)|[link](https://github.com/zzwaang/melody-reduction-algo)|
|**2024-05-16**|**"Hunt Takes Hare": Theming Games Through Game-Word Vector Translation**|Rabii Younès et.al.|[2405.09893v1](http://arxiv.org/abs/2405.09893v1)|null|
|**2024-05-16**|**DiffAM: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection**|Yuhao Sun et.al.|[2405.09882v1](http://arxiv.org/abs/2405.09882v1)|[link](https://github.com/hanssuny/diffam)|
|**2024-05-16**|**Generative Unlearning for Any Identity**|Juwon Seo et.al.|[2405.09879v1](http://arxiv.org/abs/2405.09879v1)|[link](https://github.com/khu-agi/guide)|
|**2024-05-16**|**Risk Management for Medical Devices via the Riskman Ontology & Shapes**|Piotr Gorczyca et.al.|[2405.09875v1](http://arxiv.org/abs/2405.09875v1)|null|
|**2024-05-16**|**Box-Free Model Watermarks Are Prone to Black-Box Removal Attacks**|Haonan An et.al.|[2405.09863v1](http://arxiv.org/abs/2405.09863v1)|null|
|**2024-05-16**|**IGOT: Information Gain Optimized Tokenizer on Domain Adaptive Pretraining**|Dawei Feng et.al.|[2405.09857v1](http://arxiv.org/abs/2405.09857v1)|null|
|**2024-05-16**|**On the relevance of pre-neural approaches in natural language processing pedagogy**|Aditya Joshi et.al.|[2405.09854v1](http://arxiv.org/abs/2405.09854v1)|null|
|**2024-05-16**|**Enhancing Semantics in Multimodal Chain of Thought via Soft Negative Sampling**|Guangmin Zheng et.al.|[2405.09848v1](http://arxiv.org/abs/2405.09848v1)|[link](https://github.com/zgmin/snse-cot)|
|**2024-05-16**|**Chameleon: Mixed-Modal Early-Fusion Foundation Models**|Chameleon Team et.al.|[2405.09818v1](http://arxiv.org/abs/2405.09818v1)|null|
|**2024-05-16**|**MediSyn: Text-Guided Diffusion Models for Broad Medical 2D and 3D Image Synthesis**|Joseph Cho et.al.|[2405.09806v1](http://arxiv.org/abs/2405.09806v1)|null|
|**2024-05-16**|**SecureLLM: Using Compositionality to Build Provably Secure Language Models for Private, Sensitive, and Secret Data**|Abdulrahman Alabdulakreem et.al.|[2405.09805v1](http://arxiv.org/abs/2405.09805v1)|[link](https://github.com/scuwr/securellm)|
|**2024-05-16**|**Analysis and Predictive Modeling of Solar Coronal Holes Using Computer Vision and LSTM Networks**|Juyoung Yun et.al.|[2405.09802v1](http://arxiv.org/abs/2405.09802v1)|null|
|**2024-05-16**|**Many-Shot In-Context Learning in Multimodal Foundation Models**|Yixing Jiang et.al.|[2405.09798v1](http://arxiv.org/abs/2405.09798v1)|[link](https://github.com/stanfordmlgroup/ManyICL)|
|**2024-05-16**|**Human-AI Safety: A Descendant of Generative AI and Control Systems Safety**|Andrea Bajcsy et.al.|[2405.09794v1](http://arxiv.org/abs/2405.09794v1)|null|
|**2024-05-16**|**Online bipartite matching with imperfect advice**|Davin Choo et.al.|[2405.09784v1](http://arxiv.org/abs/2405.09784v1)|null|
|**2024-05-16**|**LLM and Simulation as Bilevel Optimizers: A New Paradigm to Advance Physical Scientific Discovery**|Pingchuan Ma et.al.|[2405.09783v1](http://arxiv.org/abs/2405.09783v1)|null|
|**2024-05-16**|**Optimization Techniques for Sentiment Analysis Based on LLM (GPT-3)**|Tong Zhan et.al.|[2405.09770v1](http://arxiv.org/abs/2405.09770v1)|null|
|**2024-05-16**|**Many Hands Make Light Work: Task-Oriented Dialogue System with Module-Based Mixture-of-Experts**|Ruolin Su et.al.|[2405.09744v1](http://arxiv.org/abs/2405.09744v1)|null|
|**2024-05-15**|**SCI 3.0: A Web-based Schema Curation Interface for Graphical Event Representations**|Reece Suchocki et.al.|[2405.09733v1](http://arxiv.org/abs/2405.09733v1)|null|
|**2024-05-15**|**Spectral Editing of Activations for Large Language Model Alignment**|Yifu Qiu et.al.|[2405.09719v1](http://arxiv.org/abs/2405.09719v1)|null|
|**2024-05-15**|**SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge**|Andong Wang et.al.|[2405.09713v1](http://arxiv.org/abs/2405.09713v1)|null|
|**2024-05-15**|**STAR: A Benchmark for Situated Reasoning in Real-World Videos**|Bo Wu et.al.|[2405.09711v1](http://arxiv.org/abs/2405.09711v1)|null|
|**2024-05-15**|**No More Mumbles: Enhancing Robot Intelligibility through Speech Adaptation**|Qiaoqiao Ren et.al.|[2405.09708v1](http://arxiv.org/abs/2405.09708v1)|[link](https://github.com/qiaoqiao2323/robot-speech-intelligibility)|
|**2024-05-15**|**Modeling User Preferences via Brain-Computer Interfacing**|Luis A. Leiva et.al.|[2405.09691v1](http://arxiv.org/abs/2405.09691v1)|null|
|**2024-05-15**|**Simulating Policy Impacts: Developing a Generative Scenario Writing Method to Evaluate the Perceived Effects of Regulation**|Julia Barnett et.al.|[2405.09679v1](http://arxiv.org/abs/2405.09679v1)|null|
|**2024-05-15**|**LoRA Learns Less and Forgets Less**|Dan Biderman et.al.|[2405.09673v1](http://arxiv.org/abs/2405.09673v1)|null|
|**2024-05-15**|**Detecting Continuous Integration Skip : A Reinforcement Learning-based Approach**|Hajer Mhalla et.al.|[2405.09657v1](http://arxiv.org/abs/2405.09657v1)|null|
|**2024-05-15**|**Elements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic world knowledge in language models**|Anna A. Ivanova et.al.|[2405.09605v1](http://arxiv.org/abs/2405.09605v1)|null|
|**2024-05-15**|**Modeling Bilingual Sentence Processing: Evaluating RNN and Transformer Architectures for Cross-Language Structural Priming**|Bushi Xiao et.al.|[2405.09508v1](http://arxiv.org/abs/2405.09508v1)|null|
|**2024-05-15**|**QueryNER: Segmentation of E-commerce Queries**|Chester Palen-Michel et.al.|[2405.09507v1](http://arxiv.org/abs/2405.09507v1)|[link](https://github.com/bltlab/query-ner)|
|**2024-05-15**|**ParaNames 1.0: Creating an Entity Name Corpus for 400+ Languages using Wikidata**|Jonne Sälevä et.al.|[2405.09496v1](http://arxiv.org/abs/2405.09496v1)|null|
|**2024-05-15**|**Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts**|Donya Rooein et.al.|[2405.09482v1](http://arxiv.org/abs/2405.09482v1)|null|
|**2024-05-15**|**Harmonizing Human Insights and AI Precision: Hand in Hand for Advancing Knowledge Graph Task**|Shurong Wang et.al.|[2405.09477v1](http://arxiv.org/abs/2405.09477v1)|null|
|**2024-05-15**|**Tell Me Why: Explainable Public Health Fact-Checking with Large Language Models**|Majid Zarharan et.al.|[2405.09454v1](http://arxiv.org/abs/2405.09454v1)|[link](https://github.com/Zarharan/NLE-for-fact-checking)|
|**2024-05-15**|**Desk-AId: Humanitarian Aid Desk Assessment with Geospatial AI for Predicting Landmine Areas**|Flavio Cirillo et.al.|[2405.09444v1](http://arxiv.org/abs/2405.09444v1)|null|
|**2024-05-15**|**Facilitating Opinion Diversity through Hybrid NLP Approaches**|Michiel van der Meer et.al.|[2405.09439v1](http://arxiv.org/abs/2405.09439v1)|null|
|**2024-05-15**|**Improving Label Error Detection and Elimination with Uncertainty Quantification**|Johannes Jakubik et.al.|[2405.09602v1](http://arxiv.org/abs/2405.09602v1)|null|
|**2024-05-15**|**On the Correspondence of Non-flat Assumption-based Argumentation and Logic Programming with Negation as Failure in the Head**|Anna Rapberger et.al.|[2405.09415v1](http://arxiv.org/abs/2405.09415v1)|null|
|**2024-05-15**|**$O_2$ is a multiple context-free grammar: an implementation-, formalisation-friendly proof**|Marco B. Caminati et.al.|[2405.09396v1](http://arxiv.org/abs/2405.09396v1)|null|
|**2024-05-15**|**Matching domain experts by training from scratch on domain knowledge**|Xiaoliang Luo et.al.|[2405.09395v1](http://arxiv.org/abs/2405.09395v1)|null|
|**2024-05-15**|**PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models**|Devansh Jain et.al.|[2405.09373v1](http://arxiv.org/abs/2405.09373v1)|null|
|**2024-05-15**|**Aggregate Representation Measure for Predictive Model Reusability**|Vishwesh Sangarya et.al.|[2405.09600v1](http://arxiv.org/abs/2405.09600v1)|null|
|**2024-05-15**|**Vision-Based Neurosurgical Guidance: Unsupervised Localization and Camera-Pose Prediction**|Gary Sarwin et.al.|[2405.09355v1](http://arxiv.org/abs/2405.09355v1)|null|
|**2024-05-15**|**Properties that allow or prohibit transferability of adversarial attacks among quantized networks**|Abhishek Shrestha et.al.|[2405.09598v1](http://arxiv.org/abs/2405.09598v1)|[link](https://github.com/Abhishek2271/TransferabilityAnalysis)|
|**2024-05-15**|**When AI Eats Itself: On the Caveats of Data Pollution in the Era of Generative AI**|Xiaodan Xing et.al.|[2405.09597v1](http://arxiv.org/abs/2405.09597v1)|null|
|**2024-05-15**|**Large Language Model Bias Mitigation from the Perspective of Knowledge Editing**|Ruizhe Chen et.al.|[2405.09341v1](http://arxiv.org/abs/2405.09341v1)|null|
|**2024-05-15**|**Enhancing Maritime Trajectory Forecasting via H3 Index and Causal Language Modelling (CLM)**|Nicolas Drapier et.al.|[2405.09596v1](http://arxiv.org/abs/2405.09596v1)|null|
|**2024-05-15**|**Prompting-based Synthetic Data Generation for Few-Shot Question Answering**|Maximilian Schmidt et.al.|[2405.09335v1](http://arxiv.org/abs/2405.09335v1)|null|
|**2024-05-15**|**Content-Based Image Retrieval for Multi-Class Volumetric Radiology Images: A Benchmark Study**|Farnaz Khun Jush et.al.|[2405.09334v1](http://arxiv.org/abs/2405.09334v1)|null|
|**2024-05-15**|**Simplicity within biological complexity**|Natasa Przulj et.al.|[2405.09595v1](http://arxiv.org/abs/2405.09595v1)|null|
|**2024-05-15**|**ReconBoost: Boosting Can Achieve Modality Reconcilement**|Cong Hua et.al.|[2405.09321v1](http://arxiv.org/abs/2405.09321v1)|[link](https://github.com/huacong/reconboost)|
|**2024-05-15**|**TimeX++: Learning Time-Series Explanations with Information Bottleneck**|Zichuan Liu et.al.|[2405.09308v1](http://arxiv.org/abs/2405.09308v1)|[link](https://github.com/zichuan-liu/timexplusplus)|
|**2024-05-15**|**Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support**|Birger Moell et.al.|[2405.09300v1](http://arxiv.org/abs/2405.09300v1)|null|

#### Abstracts
##### **4D Panoptic Scene Graph Generation**
2405.10305v1 by Jingkang Yang, Jun Cen, Wenxuan Peng, Shuai Liu, Fangzhou Hong, Xiangtai Li, Kaiyang Zhou, Qifeng Chen, Ziwei Liu

We are living in a three-dimensional space while moving forward through a
fourth dimension: time. To allow artificial intelligence to develop a
comprehensive understanding of such a 4D environment, we introduce 4D Panoptic
Scene Graph (PSG-4D), a new representation that bridges the raw visual data
perceived in a dynamic 4D world and high-level visual understanding.
Specifically, PSG-4D abstracts rich 4D sensory data into nodes, which represent
entities with precise location and status information, and edges, which capture
the temporal relations. To facilitate research in this new area, we build a
richly annotated PSG-4D dataset consisting of 3K RGB-D videos with a total of
1M frames, each of which is labeled with 4D panoptic segmentation masks as well
as fine-grained, dynamic scene graphs. To solve PSG-4D, we propose PSG4DFormer,
a Transformer-based model that can predict panoptic segmentation masks, track
masks along the time axis, and generate the corresponding scene graphs via a
relation component. Extensive experiments on the new dataset show that our
method can serve as a strong baseline for future research on PSG-4D. In the
end, we provide a real-world application example to demonstrate how we can
achieve dynamic scene understanding by integrating a large language model into
our PSG-4D system.

摘要：我們生活在三維空間中，同時在第四維度：時間中前進。為了讓人工智慧發展對這種 4D 環境的全面理解，我們引入了 4D 全景場景圖 (PSG-4D)，這是一種新的表示方式，它彌合了在動態 4D 世界中感知到的原始視覺數據和高層級視覺理解。具體來說，PSG-4D 將豐富的 4D 感測數據抽象為節點，這些節點表示具有精確位置和狀態信息的實體，以及邊緣，這些邊緣捕獲時間關係。為了促進這一新領域的研究，我們構建了一個豐富註釋的 PSG-4D 數據集，其中包含 3K RGB-D 視頻，總共 1M 幀，每個幀都標記有 4D 全景分割蒙版以及細粒度、動態場景圖。為了解決 PSG-4D，我們提出了 PSG4DFormer，這是一個基於 Transformer 的模型，它可以預測全景分割蒙版、沿時間軸追蹤蒙版，並通過關係組成產生對應的場景圖。在新的數據集上進行的廣泛實驗表明，我們的模型可以用作未來 PSG-4D 研究的強大基線。最後，我們提供了一個真實世界的應用範例，以展示如何通過將大型語言模型整合到我們的 PSG-4D 系統中來實現動態場景理解。

##### **Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees**
2405.10301v1 by Yu Gui, Ying Jin, Zhimei Ren

Before deploying outputs from foundation models in high-stakes tasks, it is
imperative to ensure that they align with human values. For instance, in
radiology report generation, reports generated by a vision-language model must
align with human evaluations before their use in medical decision-making. This
paper presents Conformal Alignment, a general framework for identifying units
whose outputs meet a user-specified alignment criterion. It is guaranteed that
on average, a prescribed fraction of selected units indeed meet the alignment
criterion, regardless of the foundation model or the data distribution. Given
any pre-trained model and new units with model-generated outputs, Conformal
Alignment leverages a set of reference data with ground-truth alignment status
to train an alignment predictor. It then selects new units whose predicted
alignment scores surpass a data-dependent threshold, certifying their
corresponding outputs as trustworthy. Through applications to question
answering and radiology report generation, we demonstrate that our method is
able to accurately identify units with trustworthy outputs via lightweight
training over a moderate amount of reference data. En route, we investigate the
informativeness of various features in alignment prediction and combine them
with standard models to construct the alignment predictor.

摘要：在將基礎模型的輸出部署到高風險任務之前，必須確保它們與人類價值觀保持一致。例如，在放射學報告生成中，在將視覺語言模型生成的報告用於醫療決策之前，必須與人類評估保持一致。本文提出了共形校準，這是一個用於識別輸出符合使用者指定校準準則的單元的通用框架。無論基礎模型或資料分佈如何，平均而言，一定比例的選定單元確實符合校準準則。給定任何預先訓練的模型和具有模型生成輸出的新單元，共形校準利用一組具有真實校準狀態的參考資料來訓練校準預測器。然後，它選擇預測校準分數超過資料依賴性閾值的單元，並將其對應的輸出認證為可信賴的。透過應用於問題解答和放射學報告生成，我們證明了我們的方法能夠透過對適量的參考資料進行輕量化訓練，準確地識別具有可信賴輸出的單元。在途中，我們研究了校準預測中各種特徵的信息量，並將它們與標準模型結合起來，以構建校準預測器。

##### **HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models**
2405.10299v1 by Rhea Sanjay Sukthanker, Arber Zela, Benedikt Staffler, Jorg K. H. Franke, Frank Hutter

The expanding size of language models has created the necessity for a
comprehensive examination across various dimensions that reflect the desiderata
with respect to the tradeoffs between various hardware metrics, such as
latency, energy consumption, GPU memory usage, and performance. There is a
growing interest in establishing Pareto frontiers for different language model
configurations to identify optimal models with specified hardware constraints.
Notably, architectures that excel in latency on one device may not perform
optimally on another. However, exhaustive training and evaluation of numerous
architectures across diverse hardware configurations is computationally
prohibitive. To this end, we propose HW-GPT-Bench, a hardware-aware language
model surrogate benchmark, where we leverage weight-sharing techniques from
Neural Architecture Search (NAS) to efficiently train a supernet proxy,
encompassing language models of varying scales in a single model. We conduct
profiling of these models across 13 devices, considering 5 hardware metrics and
3 distinct model scales. Finally, we showcase the usability of HW-GPT-Bench
using 8 different multi-objective NAS algorithms and evaluate the quality of
the resultant Pareto fronts. Through this benchmark, our objective is to propel
and expedite research in the advancement of multi-objective methods for NAS and
structural pruning in large language models.

摘要：<paragraph>語言模型的規模擴大，讓人有必要從各種面向進行全面檢視，這些面向反映了在各種硬體指標（例如延遲、能源消耗、GPU 記憶體使用量和效能）之間的折衷考量。對於建立不同語言模型組態的 Pareto 前緣，以找出符合特定硬體限制的最佳模型，人們的興趣與日俱增。值得注意的是，在一個裝置上延遲表現優異的架構，在另一個裝置上可能無法達到最佳效能。然而，在各種硬體組態中對眾多架構進行窮舉式訓練和評估，在運算上是禁止的。為此，我們提出了 HW-GPT-Bench，這是一個硬體感知語言模型替代基準，我們在其中利用神經架構搜尋 (NAS) 的權重共用技術，有效率地訓練一個超級網路代理，在單一模型中涵蓋各種規模的語言模型。我們在 13 個裝置上對這些模型進行分析，考量 5 個硬體指標和 3 個不同的模型規模。最後，我們展示了 HW-GPT-Bench 的可用性，使用了 8 種不同的多目標 NAS 演算法，並評估所得 Pareto 前緣的品質。透過這個基準，我們的目標是推動和加速在 NAS 和大型語言模型結構化剪枝的多目標方法的進展。</paragraph>

##### **Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning**
2405.10292v1 by Yuexiang Zhai, Hao Bai, Zipeng Lin, Jiayi Pan, Shengbang Tong, Yifei Zhou, Alane Suhr, Saining Xie, Yann LeCun, Yi Ma, Sergey Levine

Large vision-language models (VLMs) fine-tuned on specialized visual
instruction-following data have exhibited impressive language reasoning
capabilities across various scenarios. However, this fine-tuning paradigm may
not be able to efficiently learn optimal decision-making agents in multi-step
goal-directed tasks from interactive environments. To address this challenge,
we propose an algorithmic framework that fine-tunes VLMs with reinforcement
learning (RL). Specifically, our framework provides a task description and then
prompts the VLM to generate chain-of-thought (CoT) reasoning, enabling the VLM
to efficiently explore intermediate reasoning steps that lead to the final
text-based action. Next, the open-ended text output is parsed into an
executable action to interact with the environment to obtain goal-directed task
rewards. Finally, our framework uses these task rewards to fine-tune the entire
VLM with RL. Empirically, we demonstrate that our proposed framework enhances
the decision-making capabilities of VLM agents across various tasks, enabling
7b models to outperform commercial models such as GPT4-V or Gemini.
Furthermore, we find that CoT reasoning is a crucial component for performance
improvement, as removing the CoT reasoning results in a significant decrease in
the overall performance of our method.

摘要：大型视觉语言模型 (VLM) 在经过专门的视觉指令遵循数据的微调后，在各种场景中表现出令人印象深刻的语言推理能力。然而，这种微调范式可能无法有效地从交互式环境中学习多步骤目标导向任务中的最优决策代理。为了应对这一挑战，我们提出了一种使用强化学习 (RL) 对 VLM 进行微调的算法框架。具体来说，我们的框架提供了一个任务描述，然后提示 VLM 生成思维链 (CoT) 推理，使 VLM 能够有效地探索导致最终基于文本的动作的中间推理步骤。接下来，将开放式文本输出解析为可执行动作，以与环境交互以获得目标导向的任务奖励。最后，我们的框架使用这些任务奖励对整个 VLM 进行 RL 微调。根据经验，我们证明了我们提出的框架增强了 VLM 代理在各种任务中的决策能力，使 7b 模型能够优于 GPT4-V 或 Gemini 等商业模型。此外，我们发现 CoT 推理是性能改进的关键组成部分，因为移除 CoT 推理会导致我们方法的整体性能显着下降。

##### **Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction**
2405.10288v1 by Jianhao Chen, Haoyuan Ouyang, Junyang Ren, Wentao Ding, Wei Hu, Yuzhong Qu

Facts extraction is pivotal for constructing knowledge graphs. Recently, the
increasing demand for temporal facts in downstream tasks has led to the
emergence of the task of temporal fact extraction. In this paper, we
specifically address the extraction of temporal facts from natural language
text. Previous studies fail to handle the challenge of establishing
time-to-fact correspondences in complex sentences. To overcome this hurdle, we
propose a timeline-based sentence decomposition strategy using large language
models (LLMs) with in-context learning, ensuring a fine-grained understanding
of the timeline associated with various facts. In addition, we evaluate the
performance of LLMs for direct temporal fact extraction and get unsatisfactory
results. To this end, we introduce TSDRE, a method that incorporates the
decomposition capabilities of LLMs into the traditional fine-tuning of smaller
pre-trained language models (PLMs). To support the evaluation, we construct
ComplexTRED, a complex temporal fact extraction dataset. Our experiments show
that TSDRE achieves state-of-the-art results on both HyperRED-Temporal and
ComplexTRED datasets.

摘要：事實抽取對於建構知識圖譜至關重要。最近，下游任務對時間事實的需求增加，導致了時間事實抽取任務的出現。在本文中，我們特別探討從自然語言文本中抽取時間事實。先前的研究無法處理在複雜句子中建立時間到事實對應的挑戰。為了克服這個障礙，我們提出了一個基於時間軸的句子分解策略，使用具備上下文學習功能的大語言模型 (LLM)，確保對與各種事實相關的時間軸進行細粒度的理解。此外，我們評估了 LLM 直接時間事實抽取的效能，並獲得了不令人滿意的結果。為此，我們引入了 TSDRE，一種將 LLM 的分解能力整合到較小預訓練語言模型 (PLM) 的傳統微調中的方法。為了支援評估，我們構建了 ComplexTRED，一個複雜的時間事實抽取資料集。我們的實驗表明，TSDRE 在 HyperRED-Temporal 和 ComplexTRED 資料集上都達到了最先進的結果。

##### **FFF: Fixing Flawed Foundations in contrastive pre-training results in very strong Vision-Language models**
2405.10286v1 by Adrian Bulat, Yassine Ouali, Georgios Tzimiropoulos

Despite noise and caption quality having been acknowledged as important
factors impacting vision-language contrastive pre-training, in this paper, we
show that the full potential of improving the training process by addressing
such issues is yet to be realized. Specifically, we firstly study and analyze
two issues affecting training: incorrect assignment of negative pairs, and low
caption quality and diversity. Then, we devise effective solutions for
addressing both problems, which essentially require training with multiple true
positive pairs. Finally, we propose training with sigmoid loss to address such
a requirement. We show very large gains over the current state-of-the-art for
both image recognition ($\sim +6\%$ on average over 11 datasets) and image
retrieval ($\sim +19\%$ on Flickr30k and $\sim +15\%$ on MSCOCO).

摘要：儘管噪音和標題品質已被確認為影響視覺語言對比預訓練的重要因素，在本文中，我們表明透過解決此類問題來改善訓練流程的全部潛力尚未實現。具體來說，我們首先研究和分析影響訓練的兩個問題：負對的錯誤分配，以及標題品質和多樣性低。然後，我們為解決這兩個問題設計了有效的解決方案，這本質上需要使用多個真實正對進行訓練。最後，我們提出使用 sigmoid 損失進行訓練以滿足這樣的要求。我們展示了在當前最先進的技術中，無論是影像辨識（在 11 個資料集上平均高出約 +6%）還是影像檢索（在 Flickr30k 上高出約 +19%，在 MSCOCO 上高出約 +15%）都獲得了非常大的收益。

##### **Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers**
2405.10276v1 by Tuo Zhang, Jinyue Yuan, Salman Avestimehr

Numerous recent works aim to enhance the efficacy of Large Language Models
(LLMs) through strategic prompting. In particular, the Optimization by
PROmpting (OPRO) approach provides state-of-the-art performance by leveraging
LLMs as optimizers where the optimization task is to find instructions that
maximize the task accuracy. In this paper, we revisit OPRO for automated
prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral
7B. Our investigation reveals that OPRO shows limited effectiveness in
small-scale LLMs, with limited inference capabilities constraining optimization
ability. We suggest future automatic prompting engineering to consider both
model capabilities and computational costs. Additionally, for small-scale LLMs,
we recommend direct instructions that clearly outline objectives and
methodologies as robust prompt baselines, ensuring efficient and effective
prompt engineering in ongoing research.

摘要：許多最近的研究旨在透過策略性提示來增強大型語言模型 (LLM) 的效能。特別是，透過最佳化提示 (OPRO) 方法，可將 LLM 作為最佳化器，而最佳化任務是找出可最大化任務精確度的指令，進而提供最先進的效能。在本文中，我們重新檢視 OPRO，以自動提示相對小規模的 LLM，例如 LLaMa-2 系列和 Mistral 7B。我們的調查顯示，OPRO 在小規模 LLM 中展現的效能有限，原因是有限的推論能力限制了最佳化能力。我們建議未來的自動提示工程應考量模型能力和運算成本。此外，對於小規模 LLM，我們建議直接提供明確說明目標和方法的指令，作為穩健的提示基準，以確保持續研究中的提示工程能有效率且有效。

##### **Faces that Speak: Jointly Synthesising Talking Face and Speech from Text**
2405.10272v1 by Youngjoon Jang, Ji-Hoon Kim, Junseok Ahn, Doyeop Kwak, Hong-Sun Yang, Yoon-Cheol Ju, Il-Hwan Kim, Byeong-Yeol Kim, Joon Son Chung

The goal of this work is to simultaneously generate natural talking faces and
speech outputs from text. We achieve this by integrating Talking Face
Generation (TFG) and Text-to-Speech (TTS) systems into a unified framework. We
address the main challenges of each task: (1) generating a range of head poses
representative of real-world scenarios, and (2) ensuring voice consistency
despite variations in facial motion for the same identity. To tackle these
issues, we introduce a motion sampler based on conditional flow matching, which
is capable of high-quality motion code generation in an efficient way.
Moreover, we introduce a novel conditioning method for the TTS system, which
utilises motion-removed features from the TFG model to yield uniform speech
outputs. Our extensive experiments demonstrate that our method effectively
creates natural-looking talking faces and speech that accurately match the
input text. To our knowledge, this is the first effort to build a multimodal
synthesis system that can generalise to unseen identities.

摘要：本研究的目标是同时从文本生成自然对话人脸和语音输出。我们通过将Talking Face Generation (TFG) 和 Text-to-Speech (TTS) 系统整合到一个统一的框架中来实现这一目标。我们解决了每项任务的主要挑战：(1) 生成一系列代表真实场景的头部姿势，以及 (2) 确保语音一致性，尽管同一身份的面部动作有所不同。为了解决这些问题，我们引入了一个基于条件流匹配的运动采样器，它能够高效地生成高质量的运动代码。此外，我们为 TTS 系统引入了一种新颖的条件化方法，它利用 TFG 模型中去除运动的特征来产生统一的语音输出。我们广泛的实验表明，我们的方法有效地创建了自然逼真的对话人脸和与输入文本准确匹配的语音。据我们所知，这是构建多模态合成系统的首次尝试，该系统可以推广到看不见的身份。

##### **Automated Federated Learning via Informed Pruning**
2405.10271v1 by Christian Internò, Elena Raponi, Niki van Stein, Thomas Bäck, Markus Olhofer, Yaochu Jin, Barbara Hammer

Federated learning (FL) represents a pivotal shift in machine learning (ML)
as it enables collaborative training of local ML models coordinated by a
central aggregator, all without the need to exchange local data. However, its
application on edge devices is hindered by limited computational capabilities
and data communication challenges, compounded by the inherent complexity of
Deep Learning (DL) models. Model pruning is identified as a key technique for
compressing DL models on devices with limited resources. Nonetheless,
conventional pruning techniques typically rely on manually crafted heuristics
and demand human expertise to achieve a balance between model size, speed, and
accuracy, often resulting in sub-optimal solutions.
  In this study, we introduce an automated federated learning approach
utilizing informed pruning, called AutoFLIP, which dynamically prunes and
compresses DL models within both the local clients and the global server. It
leverages a federated loss exploration phase to investigate model gradient
behavior across diverse datasets and losses, providing insights into parameter
significance. Our experiments showcase notable enhancements in scenarios with
strong non-IID data, underscoring AutoFLIP's capacity to tackle computational
constraints and achieve superior global convergence.

摘要：聯邦學習 (FL) 代表機器學習 (ML) 的關鍵轉變，因為它能讓由中央聚合器協調的本地 ML 模型進行協作訓練，而無需交換本地數據。然而，其在邊緣裝置上的應用受到有限的運算能力和資料傳輸挑戰的阻礙，而深度學習 (DL) 模型的內在複雜性更讓問題雪上加霜。模型剪枝被視為在資源有限的裝置上壓縮 DL 模型的一項關鍵技術。儘管如此，傳統的剪枝技術通常依賴於人工製作的啟發法，並需要人類專家才能在模型大小、速度和準確性之間取得平衡，這常常導致次優的解決方案。
在本研究中，我們引入一種自動化的聯邦學習方法，利用稱為 AutoFLIP 的知情剪枝，它會動態剪枝並壓縮本地用戶端和全球伺服器中的 DL 模型。它利用聯邦損失探索階段來探討各種資料集和損失中的模型梯度行為，提供對參數重要性的見解。我們的實驗展示了在具有強非 IID 資料的情況下顯著的改進，突顯了 AutoFLIP 處理運算限制和實現優越的整體收斂的能力。

##### **A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision**
2405.10266v1 by Charles Raude, K R Prajwal, Liliane Momeni, Hannah Bull, Samuel Albanie, Andrew Zisserman, Gül Varol

In this work, our goals are two fold: large-vocabulary continuous sign
language recognition (CSLR), and sign language retrieval. To this end, we
introduce a multi-task Transformer model, CSLR2, that is able to ingest a
signing sequence and output in a joint embedding space between signed language
and spoken language text. To enable CSLR evaluation in the large-vocabulary
setting, we introduce new dataset annotations that have been manually
collected. These provide continuous sign-level annotations for six hours of
test videos, and will be made publicly available. We demonstrate that by a
careful choice of loss functions, training the model for both the CSLR and
retrieval tasks is mutually beneficial in terms of performance -- retrieval
improves CSLR performance by providing context, while CSLR improves retrieval
with more fine-grained supervision. We further show the benefits of leveraging
weak and noisy supervision from large-vocabulary datasets such as BOBSL, namely
sign-level pseudo-labels, and English subtitles. Our model significantly
outperforms the previous state of the art on both tasks.

摘要：在這項工作中，我們的目標有兩個：大詞彙量連續手語辨識 (CSLR) 和手語檢索。為此，我們提出了一個多任務 Transformer 模型 CSLR2，它能夠攝取手語序列並在手語和口語文本之間的聯合嵌入空間中輸出。為了在大量詞彙的設定中啟用 CSLR 評估，我們引入了已手動收集的新資料集註解。這些註解為六小時的測試影片提供了連續的手語級別註解，並將公開提供。我們證明，透過仔細選擇損失函數，針對 CSLR 和檢索任務訓練模型在效能方面是互利的——檢索透過提供上下文來改善 CSLR 效能，而 CSLR 則透過更細緻的監督來改善檢索。我們進一步展示了利用來自大詞彙量資料集（例如 BOBSL）的弱監督和雜訊監督的好處，即手語級別的偽標籤和英文字幕。我們的模型在兩個任務上都顯著優於先前的技術水準。

##### **Keep It Private: Unsupervised Privatization of Online Text**
2405.10260v1 by Calvin Bao, Marine Carpuat

Authorship obfuscation techniques hold the promise of helping people protect
their privacy in online communications by automatically rewriting text to hide
the identity of the original author. However, obfuscation has been evaluated in
narrow settings in the NLP literature and has primarily been addressed with
superficial edit operations that can lead to unnatural outputs. In this work,
we introduce an automatic text privatization framework that fine-tunes a large
language model via reinforcement learning to produce rewrites that balance
soundness, sense, and privacy. We evaluate it extensively on a large-scale test
set of English Reddit posts by 68k authors composed of short-medium length
texts. We study how the performance changes among evaluative conditions
including authorial profile length and authorship detection strategy. Our
method maintains high text quality according to both automated metrics and
human evaluation, and successfully evades several automated authorship attacks.

摘要：作者模糊化技术有望帮助人们通过自动改写文本来隐藏原始作者的身份，从而保护他们在网络通信中的隐私。然而，在 NLP 文献中，混淆已在狭窄的环境中得到评估，并且主要通过表面编辑操作来解决，这可能导致不自然的结果。在这项工作中，我们引入了一个自动文本私有化框架，该框架通过强化学习对大型语言模型进行微调，以生成平衡健全性、意义和隐私性的改写。我们对由 68k 位作者撰写的英语 Reddit 帖子的大规模测试集进行了广泛的评估，该测试集由中短篇文本组成。我们研究了在评估条件（包括作者个人资料长度和作者身份检测策略）之间性能如何变化。我们的方法根据自动指标和人工评估保持了较高的文本质量，并成功规避了几次自动作者攻击。

##### **A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks**
2405.10251v1 by Xuanfan Ni, Piji Li

Recent efforts have evaluated large language models (LLMs) in areas such as
commonsense reasoning, mathematical reasoning, and code generation. However, to
the best of our knowledge, no work has specifically investigated the
performance of LLMs in natural language generation (NLG) tasks, a pivotal
criterion for determining model excellence. Thus, this paper conducts a
comprehensive evaluation of well-known and high-performing LLMs, namely
ChatGPT, ChatGLM, T5-based models, LLaMA-based models, and Pythia-based models,
in the context of NLG tasks. We select English and Chinese datasets
encompassing Dialogue Generation and Text Summarization. Moreover, we propose a
common evaluation setting that incorporates input templates and post-processing
strategies. Our study reports both automatic results, accompanied by a detailed
analysis.

摘要：近期的研究已評估大型語言模型 (LLM) 在常識推理、數學推理和程式碼生成等領域的表現。然而，據我們所知，目前尚未有研究特別探討 LLM 在自然語言生成 (NLG) 任務中的表現，而這項任務是評量模型優異性的關鍵標準。因此，本論文針對廣為人知且表現優異的 LLM 進行全面的評估，包括 ChatGPT、ChatGLM、基於 T5 的模型、基於 LLaMA 的模型和基於 Pythia 的模型，並以 NLG 任務為背景。我們選擇涵蓋對話生成和文字摘要的英文和中文資料集。此外，我們提出一個通用的評估設定，其中包含輸入範本和後處理策略。我們的研究報告了自動化結果，並附有詳細的分析。

##### **ENADPool: The Edge-Node Attention-based Differentiable Pooling for Graph Neural Networks**
2405.10218v1 by Zhehan Zhao, Lu Bai, Lixin Cui, Ming Li, Yue Wang, Lixiang Xu, Edwin R. Hancock

Graph Neural Networks (GNNs) are powerful tools for graph classification. One
important operation for GNNs is the downsampling or pooling that can learn
effective embeddings from the node representations. In this paper, we propose a
new hierarchical pooling operation, namely the Edge-Node Attention-based
Differentiable Pooling (ENADPool), for GNNs to learn effective graph
representations. Unlike the classical hierarchical pooling operation that is
based on the unclear node assignment and simply computes the averaged feature
over the nodes of each cluster, the proposed ENADPool not only employs a hard
clustering strategy to assign each node into an unique cluster, but also
compress the node features as well as their edge connectivity strengths into
the resulting hierarchical structure based on the attention mechanism after
each pooling step. As a result, the proposed ENADPool simultaneously identifies
the importance of different nodes within each separated cluster and edges
between corresponding clusters, that significantly addresses the shortcomings
of the uniform edge-node based structure information aggregation arising in the
classical hierarchical pooling operation. Moreover, to mitigate the
over-smoothing problem arising in existing GNNs, we propose a Multi-distance
GNN (MD-GNN) model associated with the proposed ENADPool operation, allowing
the nodes to actively and directly receive the feature information from
neighbors at different random walk steps. Experiments demonstrate the
effectiveness of the MD-GNN associated with the proposed ENADPool.

摘要：圖形神經網路 (GNN) 是用於圖形分類的強大工具。GNN 的一個重要操作是降採樣或池化，它可以從節點表示中學習有效的嵌入。在本文中，我們提出了一個新的分層池化操作，即基於邊緣節點注意力的可微池化 (ENADPool)，供 GNN 學習有效的圖形表示。與基於不明確節點分配並僅計算每個群集節點的平均特徵的經典分層池化操作不同，所提出的 ENADPool 不僅採用硬群集策略將每個節點分配到一個唯一的群集，而且還將節點特徵及其邊緣連接強度壓縮到在每個池化步驟之後基於注意力機制的結果分層結構中。因此，所提出的 ENADPool 同時識別了每個分隔群集內不同節點的重要性以及對應群集之間的邊緣，這顯著地解決了經典分層池化操作中出現的基於均勻邊緣節點的結構信息聚合的缺點。此外，為了減輕現有 GNN 中出現的過度平滑問題，我們提出了一個與所提出的 ENADPool 操作相關的多距離 GNN (MD-GNN) 模型，允許節點主動直接接收來自不同隨機遊走步驟的鄰居的特徵信息。實驗證明了與所提出的 ENADPool 相關的 MD-GNN 的有效性。

##### **Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting**
2405.10216v1 by Divij Gupta, Anubhav Bhatti, Suraj Parmar, Chen Dan, Yuwei Liu, Bingjie Shen, San Lee

Low-Rank Adaptation (LoRA) is a widely used technique for fine-tuning large
pre-trained or foundational models across different modalities and tasks.
However, its application to time series data, particularly within foundational
models, remains underexplored. This paper examines the impact of LoRA on
contemporary time series foundational models: Lag-Llama, MOIRAI, and Chronos.
We demonstrate LoRA's fine-tuning potential for forecasting the vital signs of
sepsis patients in intensive care units (ICUs), emphasizing the models'
adaptability to previously unseen, out-of-domain modalities. Integrating LoRA
aims to enhance forecasting performance while reducing inefficiencies
associated with fine-tuning large models on limited domain-specific data. Our
experiments show that LoRA fine-tuning of time series foundational models
significantly improves forecasting, achieving results comparable to
state-of-the-art models trained from scratch on similar modalities. We conduct
comprehensive ablation studies to demonstrate the trade-offs between the number
of tunable parameters and forecasting performance and assess the impact of
varying LoRA matrix ranks on model performance.

摘要：低秩適應 (LoRA) 是一種廣泛用於微調不同模態和任務的大型預訓練或基礎模型的技術。
然而，它在時間序列數據中的應用，特別是在基礎模型中，仍然處於探索不足的階段。本文探討了 LoRA 對當代時間序列基礎模型的影響：Lag-Llama、MOIRAI 和 Chronos。
我們展示了 LoRA 在預測重症監護病房 (ICU) 中敗血症患者生命體徵方面的微調潛力，強調了模型對以前未見的、超出領域模式的適應性。
整合 LoRA 旨在增強預測性能，同時減少與在有限的特定領域數據上微調大型模型相關的低效率。我們的實驗表明，時間序列基礎模型的 LoRA 微調顯著改善了預測，實現了與從類似模式中從頭訓練的最新模型相當的結果。我們進行了全面的消融研究，以展示可調參數數量和預測性能之間的權衡，並評估不同 LoRA 矩陣秩對模型性能的影響。

##### **SMLP: Symbolic Machine Learning Prover (User Manual)**
2405.10215v1 by Franz Brauße, Zurab Khasidashvili, Konstantin Korovin

SMLP: Symbolic Machine Learning Prover an open source tool for exploration
and optimization of systems represented by machine learning models. SMLP uses
symbolic reasoning for ML model exploration and optimization under verification
and stability constraints, based on SMT, constraint and NN solvers. In addition
its exploration methods are guided by probabilistic and statistical methods.
SMLP is a general purpose tool that requires only data suitable for ML
modelling in the csv format (usually samples of the system's input/output).
SMLP has been applied at Intel for analyzing and optimizing hardware designs at
the analog level. Currently SMLP supports NNs, polynomial and tree models, and
uses SMT solvers for reasoning and optimization at the backend, integration of
specialized NN solvers is in progress.

摘要：SMLP：符號機器學習證明器，一個用於探索和最佳化機器學習模型所表示系統的開源工具。SMLP 使用符號推理來探索和最佳化 ML 模型，在驗證和穩定性約束下，基於 SMT、約束和 NN 求解器。此外，它的探索方法由機率和統計方法引導。SMLP 是通用目的工具，僅需要適合以 csv 格式進行 ML 建模的資料（通常是系統輸入/輸出的範例）。SMLP 已應用於英特爾，用於分析和最佳化類比層級的硬體設計。目前 SMLP 支援 NN、多項式和樹狀模型，並使用 SMT 求解器進行後端的推理和最佳化，目前正在整合專門的 NN 求解器。

##### **CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations**
2405.10212v1 by Jiahao Zhao, Jingwei Zhu, Minghuan Tan, Min Yang, Di Yang, Chenhao Zhang, Guancheng Ye, Chengming Li, Xiping Hu

In this paper, we introduce a novel psychological benchmark, CPsyExam,
constructed from questions sourced from Chinese language examinations. CPsyExam
is designed to prioritize psychological knowledge and case analysis separately,
recognizing the significance of applying psychological knowledge to real-world
scenarios. From the pool of 22k questions, we utilize 4k to create the
benchmark that offers balanced coverage of subjects and incorporates a diverse
range of case analysis techniques.Furthermore, we evaluate a range of existing
large language models~(LLMs), spanning from open-sourced to API-based models.
Our experiments and analysis demonstrate that CPsyExam serves as an effective
benchmark for enhancing the understanding of psychology within LLMs and enables
the comparison of LLMs across various granularities.

摘要：在本文中，我們介紹了一個新穎的心理基准 CPsyExam，
它是從中文考試中提取的問題構成的。CPsyExam
旨在優先考慮心理知識和案例分析，
認識到將心理知識應用於現實世界
場景的重要性。從 22k 個問題中，我們利用 4k 來創建
基準，提供平衡的主題涵蓋範圍，並結合各種
案例分析技術。此外，我們評估了一系列現有的
大型語言模型 (LLM)，從開源模型到基於 API 的模型。
我們的實驗和分析表明，CPsyExam 是一個有效的
基準，用於增強 LLM 中對心理學的理解，並允許
比較 LLM 跨各種粒度。

##### **Building a Luganda Text-to-Speech Model From Crowdsourced Data**
2405.10211v1 by Sulaiman Kagumire, Andrew Katumba, Joyce Nakatumba-Nabende, John Quinn

Text-to-speech (TTS) development for African languages such as Luganda is
still limited, primarily due to the scarcity of high-quality, single-speaker
recordings essential for training TTS models. Prior work has focused on
utilizing the Luganda Common Voice recordings of multiple speakers aged between
20-49. Although the generated speech is intelligible, it is still of lower
quality than the model trained on studio-grade recordings. This is due to the
insufficient data preprocessing methods applied to improve the quality of the
Common Voice recordings. Furthermore, speech convergence is more difficult to
achieve due to varying intonations, as well as background noise. In this paper,
we show that the quality of Luganda TTS from Common Voice can improve by
training on multiple speakers of close intonation in addition to further
preprocessing of the training data. Specifically, we selected six female
speakers with close intonation determined by subjectively listening and
comparing their voice recordings. In addition to trimming out silent portions
from the beginning and end of the recordings, we applied a pre-trained speech
enhancement model to reduce background noise and enhance audio quality. We also
utilized a pre-trained, non-intrusive, self-supervised Mean Opinion Score (MOS)
estimation model to filter recordings with an estimated MOS over 3.5,
indicating high perceived quality. Subjective MOS evaluations from nine native
Luganda speakers demonstrate that our TTS model achieves a significantly better
MOS of 3.55 compared to the reported 2.5 MOS of the existing model. Moreover,
for a fair comparison, our model trained on six speakers outperforms models
trained on a single-speaker (3.13 MOS) or two speakers (3.22 MOS). This
showcases the effectiveness of compensating for the lack of data from one
speaker with data from multiple speakers of close intonation to improve TTS
quality.

摘要：盧干達語等非洲語言的文字轉語音 (TTS) 開發仍受限，主要是因為缺乏訓練 TTS 模型不可或缺的高品質單一講者錄音。先前研究專注於利用多位 20 至 49 歲講者的盧干達語 Common Voice 錄音。儘管產生的語音可以理解，但品質仍低於使用錄音室等級錄音訓練的模型。這是因為應用於提升 Common Voice 錄音品質的資料前處理方法不足。此外，由於語調變化和背景噪音，更難達成語音收斂。在本文中，我們展示透過訓練語調接近的多位講者，以及進一步前處理訓練資料，可以提升 Common Voice 的盧干達語 TTS 品質。具體來說，我們根據主觀聆聽和比較他們的語音錄音，選出六位語調接近的女性講者。除了修剪錄音開頭和結尾的靜音部分，我們還應用預先訓練的語音增強模型，以降低背景噪音和提升音訊品質。我們還利用預先訓練的、非侵入式、自我監督平均意見分數 (MOS) 估計模型，過濾估計 MOS 超過 3.5 的錄音，這表示感知品質高。九位盧干達語母語人士的主觀 MOS 評估顯示，我們的 TTS 模型達到了顯著更好的 MOS 3.55，而現有模型的報告 MOS 為 2.5。此外，為了公平比較，我們訓練於六位講者的模型優於訓練於單一講者 (3.13 MOS) 或兩位講者 (3.22 MOS) 的模型。這展示了透過使用語調接近的多位講者的資料來彌補單一講者資料不足，進而提升 TTS 品質的有效性。

##### **Hierarchical Attention Graph for Scientific Document Summarization in Global and Local Level**
2405.10202v1 by Chenlong Zhao, Xiwen Zhou, Xiaopeng Xie, Yong Zhang

Scientific document summarization has been a challenging task due to the long
structure of the input text. The long input hinders the simultaneous effective
modeling of both global high-order relations between sentences and local
intra-sentence relations which is the most critical step in extractive
summarization. However, existing methods mostly focus on one type of relation,
neglecting the simultaneous effective modeling of both relations, which can
lead to insufficient learning of semantic representations. In this paper, we
propose HAESum, a novel approach utilizing graph neural networks to locally and
globally model documents based on their hierarchical discourse structure.
First, intra-sentence relations are learned using a local heterogeneous graph.
Subsequently, a novel hypergraph self-attention layer is introduced to further
enhance the characterization of high-order inter-sentence relations. We
validate our approach on two benchmark datasets, and the experimental results
demonstrate the effectiveness of HAESum and the importance of considering
hierarchical structures in modeling long scientific documents. Our code will be
available at \url{https://github.com/MoLICHENXI/HAESum}

摘要：<paragraph>科學文件摘要一直是一項具有挑戰性的任務，因為輸入文字的結構很長。長的輸入會阻礙同時有效地對句子之間的整體高階關係和句子內部的局部關係進行建模，這是萃取式摘要中最關鍵的步驟。然而，現有的方法大多只關注一種關係，忽視了對兩種關係的同時有效建模，這可能會導致語義表示的學習不足。在本文中，我們提出了 HAESum，這是一種利用圖神經網路在局部和整體上根據其層次化話語結構對文件進行建模的新方法。首先，使用局部異質圖學習句子內部關係。隨後，引入了一個新穎的超圖自注意力層，以進一步增強高階句子間關係的表徵。我們在兩個基準資料集上驗證了我們的做法，實驗結果證明了 HAESum 的有效性，以及在對長科學文件進行建模時考慮層次結構的重要性。我們的程式碼將可以在 \url{https://github.com/MoLICHENXI/HAESum} 取得</paragraph>

##### **LFED: A Literary Fiction Evaluation Dataset for Large Language Models**
2405.10166v1 by Linhao Yu, Qun Liu, Deyi Xiong

The rapid evolution of large language models (LLMs) has ushered in the need
for comprehensive assessments of their performance across various dimensions.
In this paper, we propose LFED, a Literary Fiction Evaluation Dataset, which
aims to evaluate the capability of LLMs on the long fiction comprehension and
reasoning. We collect 95 literary fictions that are either originally written
in Chinese or translated into Chinese, covering a wide range of topics across
several centuries. We define a question taxonomy with 8 question categories to
guide the creation of 1,304 questions. Additionally, we conduct an in-depth
analysis to ascertain how specific attributes of literary fictions (e.g., novel
types, character numbers, the year of publication) impact LLM performance in
evaluations. Through a series of experiments with various state-of-the-art
LLMs, we demonstrate that these models face considerable challenges in
effectively addressing questions related to literary fictions, with ChatGPT
reaching only 57.08% under the zero-shot setting. The dataset will be publicly
available at https://github.com/tjunlp-lab/LFED.git

摘要：大型語言模型 (LLM) 的快速發展，讓評估其在各方面表現的全面性需求應運而生。在本文中，我們提出了一個文學小說評估資料集 (LFED)，旨在評估 LLM 在長篇小說理解和推理的能力。我們收集了 95 部文學小說，這些小說原本以中文寫成或翻譯成中文，涵蓋了幾個世紀以來廣泛的主題。我們定義了一個包含 8 個問題類別的問題分類法，以指導 1,304 個問題的建立。此外，我們進行了深入分析，以確定文學小說的特定屬性（例如，小說類型、角色數量、出版年份）如何影響 LLM 在評估中的表現。透過一系列使用各種最先進 LLM 進行的實驗，我們證明了這些模型在有效回答與文學小說相關的問題時面臨相當大的挑戰，其中 ChatGPT 在零次學習設定下僅達到 57.08%。該資料集將在 https://github.com/tjunlp-lab/LFED.git 公開。

##### **PIR: Remote Sensing Image-Text Retrieval with Prior Instruction Representation Learning**
2405.10160v1 by Jiancheng Pan, Muyuan Ma, Qing Ma, Cong Bai, Shengyong Chen

Remote sensing image-text retrieval constitutes a foundational aspect of
remote sensing interpretation tasks, facilitating the alignment of vision and
language representations. This paper introduces a prior instruction
representation (PIR) learning paradigm that draws on prior knowledge to
instruct adaptive learning of vision and text representations. Based on PIR, a
domain-adapted remote sensing image-text retrieval framework PIR-ITR is
designed to address semantic noise issues in vision-language understanding
tasks. However, with massive additional data for pre-training the
vision-language foundation model, remote sensing image-text retrieval is
further developed into an open-domain retrieval task. Continuing with the
above, we propose PIR-CLIP, a domain-specific CLIP-based framework for remote
sensing image-text retrieval, to address semantic noise in remote sensing
vision-language representations and further improve open-domain retrieval
performance. In vision representation, Vision Instruction Representation (VIR)
based on Spatial-PAE utilizes the prior-guided knowledge of the remote sensing
scene recognition by building a belief matrix to select key features for
reducing the impact of semantic noise. In text representation, Language Cycle
Attention (LCA) based on Temporal-PAE uses the previous time step to cyclically
activate the current time step to enhance text representation capability. A
cluster-wise Affiliation Loss (AL) is proposed to constrain the inter-classes
and to reduce the semantic confusion zones in the common subspace.
Comprehensive experiments demonstrate that PIR could enhance vision and text
representations and outperform the state-of-the-art methods of closed-domain
and open-domain retrieval on two benchmark datasets, RSICD and RSITMD.

摘要：遙感影像文字檢索構成遙感解譯任務的基礎層面，促進視覺與語言表徵的一致性。本文介紹一種事前指令表徵 (PIR) 學習範例，利用事前知識指導視覺與文字表徵的自適應學習。根據 PIR，設計了一個領域適應的遙感影像文字檢索架構 PIR-ITR，用於解決視覺語言理解任務中的語義雜訊問題。然而，隨著預訓練視覺語言基礎模型的大量額外資料，遙感影像文字檢索進一步發展成開放領域檢索任務。延續上述，我們提出 PIR-CLIP，一個基於領域特定 CLIP 的遙感影像文字檢索架構，用於解決遙感視覺語言表徵中的語義雜訊，並進一步提升開放領域檢索效能。在視覺表徵中，基於空間 PAE 的視覺指令表徵 (VIR) 透過建立一個信念矩陣，利用遙感場景辨識的事前引導知識，來選擇關鍵特徵，以降低語義雜訊的影響。在文字表徵中，基於時間 PAE 的語言循環注意力 (LCA) 使用前一個時間步驟，以循環方式啟動當前時間步驟，以增強文字表徵能力。提出一個群集式關聯損失 (AL)，用於約束類間，並減少共同子空間中的語義混淆區域。全面的實驗證明，PIR 可以增強視覺和文字表徵，並在兩個基準資料集 RSICD 和 RSITMD 上優於封閉領域和開放領域檢索的最新方法。

##### **Speaker Verification in Agent-Generated Conversations**
2405.10150v1 by Yizhe Yang, Heyan Huang, Palakorn Achananuparp, Jing Jiang, Ee-Peng Lim

The recent success of large language models (LLMs) has attracted widespread
interest to develop role-playing conversational agents personalized to the
characteristics and styles of different speakers to enhance their abilities to
perform both general and special purpose dialogue tasks. However, the ability
to personalize the generated utterances to speakers, whether conducted by human
or LLM, has not been well studied. To bridge this gap, our study introduces a
novel evaluation challenge: speaker verification in agent-generated
conversations, which aimed to verify whether two sets of utterances originate
from the same speaker. To this end, we assemble a large dataset collection
encompassing thousands of speakers and their utterances. We also develop and
evaluate speaker verification models under experiment setups. We further
utilize the speaker verification models to evaluate the personalization
abilities of LLM-based role-playing models. Comprehensive experiments suggest
that the current role-playing models fail in accurately mimicking speakers,
primarily due to their inherent linguistic characteristics.

摘要：大型語言模型 (LLM) 近期的成功，吸引了廣泛的興趣，以開發角色扮演對話代理，針對不同說話者的特徵和風格進行個人化，以增強他們執行一般和特殊目的對話任務的能力。然而，無論是由人類或 LLM 進行，將生成的對話個人化為說話者的能力尚未得到很好的研究。為了彌補這個差距，我們的研究引入了一個新的評估挑戰：代理生成對話中的說話者驗證，旨在驗證兩組對話是否來自同一個說話者。為此，我們彙編了一個大型的資料集，包含數千名說話者及其對話。我們還開發並評估了實驗設置下的說話者驗證模型。我們進一步利用說話者驗證模型來評估基於 LLM 的角色扮演模型的個人化能力。綜合實驗表明，目前的扮演模型無法準確地模仿說話者，主要是由於其固有的語言特徵。

##### **PL-MTEB: Polish Massive Text Embedding Benchmark**
2405.10138v1 by Rafał Poświata, Sławomir Dadas, Michał Perełkiewicz

In this paper, we introduce the Polish Massive Text Embedding Benchmark
(PL-MTEB), a comprehensive benchmark for text embeddings in Polish. The PL-MTEB
consists of 28 diverse NLP tasks from 5 task types. We adapted the tasks based
on previously used datasets by the Polish NLP community. In addition, we
created a new PLSC (Polish Library of Science Corpus) dataset consisting of
titles and abstracts of scientific publications in Polish, which was used as
the basis for two novel clustering tasks. We evaluated 15 publicly available
models for text embedding, including Polish and multilingual ones, and
collected detailed results for individual tasks and aggregated results for each
task type and the entire benchmark. PL-MTEB comes with open-source code at
https://github.com/rafalposwiata/pl-mteb.

摘要：在本文中，我們介紹了波蘭語大規模文本嵌入基準 (PL-MTEB)，這是一個針對波蘭語文本嵌入的全面基準。PL-MTEB 包含來自 5 種任務類型的 28 項不同的 NLP 任務。我們根據波蘭 NLP 社群先前使用的資料集調整了任務。此外，我們建立了一個新的 PLSC (波蘭科學語料庫) 資料集，其中包含波蘭語科學出版品的標題和摘要，並將其用作兩個新分群任務的基礎。我們評估了 15 個公開的文本嵌入模型，包括波蘭語和多語言模型，並收集了各個任務的詳細結果，以及每個任務類型和整個基準的彙總結果。PL-MTEB 附帶開源程式碼，網址為 https://github.com/rafalposwiata/pl-mteb。

##### **Turkronicles: Diachronic Resources for the Fast Evolving Turkish Language**
2405.10133v1 by Togay Yazar, Mucahid Kutlu, İsa Kerem Bayırlı

Over the past century, the Turkish language has undergone substantial
changes, primarily driven by governmental interventions. In this work, our goal
is to investigate the evolution of the Turkish language since the establishment
of T\"urkiye in 1923. Thus, we first introduce Turkronicles which is a
diachronic corpus for Turkish derived from the Official Gazette of T\"urkiye.
Turkronicles contains 45,375 documents, detailing governmental actions, making
it a pivotal resource for analyzing the linguistic evolution influenced by the
state policies. In addition, we expand an existing diachronic Turkish corpus
which consists of the records of the Grand National Assembly of T\"urkiye by
covering additional years. Next, combining these two diachronic corpora, we
seek answers for two main research questions: How have the Turkish vocabulary
and the writing conventions changed since the 1920s? Our analysis reveals that
the vocabularies of two different time periods diverge more as the time between
them increases, and newly coined Turkish words take the place of their old
counterparts. We also observe changes in writing conventions. In particular,
the use of circumflex noticeably decreases and words ending with the letters
"-b" and "-d" are successively replaced with "-p" and "-t" letters,
respectively. Overall, this study quantitatively highlights the dramatic
changes in Turkish from various aspects of the language in a diachronic
perspective.

摘要：<paragraph>在過去一個世紀以來，土耳其語經歷了重大的變化，主要是受到政府干預的影響。在這項研究中，我們的目標是探討自 1923 年土耳其共和國成立以來土耳其語的演變。因此，我們首先介紹 Turkronicles，這是一個源自土耳其共和國官方公報的土耳其語歷時語料庫。Turkronicles 包含 45,375 份文件，詳述政府行動，使其成為分析受國家政策影響的語言演變的關鍵資源。此外，我們擴展了一個現有的歷時土耳其語語料庫，其中包含土耳其共和國大國民議會的記錄，涵蓋了額外的年份。接下來，結合這兩個歷時語料庫，我們尋求回答兩個主要的研究問題：自 1920 年代以來，土耳其語的詞彙和書寫慣例發生了怎樣的變化？我們的分析表明，兩個不同時期的詞彙隨著它們之間時間的增加而出現更多分歧，新創造的土耳其語詞彙取代了它們舊的對應詞。我們還觀察到書寫慣例的變化。特別是，抑揚符的使用明顯減少，以字母“-b”和“-d”結尾的詞分別被“-p”和“-t”字母取代。總的來說，這項研究從語言的各個方面定量地突出了土耳其語在歷時觀點下的巨大變化。</paragraph>

##### **StyloAI: Distinguishing AI-Generated Content with Stylometric Analysis**
2405.10129v1 by Chidimma Opara

The emergence of large language models (LLMs) capable of generating realistic
texts and images has sparked ethical concerns across various sectors. In
response, researchers in academia and industry are actively exploring methods
to distinguish AI-generated content from human-authored material. However, a
crucial question remains: What are the unique characteristics of AI-generated
text? Addressing this gap, this study proposes StyloAI, a data-driven model
that uses 31 stylometric features to identify AI-generated texts by applying a
Random Forest classifier on two multi-domain datasets. StyloAI achieves
accuracy rates of 81% and 98% on the test set of the AuTextification dataset
and the Education dataset, respectively. This approach surpasses the
performance of existing state-of-the-art models and provides valuable insights
into the differences between AI-generated and human-authored texts.

摘要：隨著能夠產生逼真文本和圖像的大語言模型 (LLM) 的出現，在各個領域中引起了道德問題。作為回應，學術界和產業中的研究人員正在積極探索區分 AI 生成的內容和人類編寫的材料的方法。然而，一個關鍵問題仍然存在：AI 生成的文本有哪些獨特特徵？為了解決這個差距，本研究提出了 StyloAI，這是一個數據驅動的模型，它使用 31 個文體特徵來識別 AI 生成的文本，方法是在兩個多領域數據集上應用隨機森林分類器。StyloAI 在 AuTextification 數據集和 Education 數據集的測試集上分別達到了 81% 和 98% 的準確率。這種方法超越了現有最先進模型的性能，並提供了對 AI 生成的文本和人類編寫的文本之間差異的寶貴見解。

##### **Red Teaming Language Models for Contradictory Dialogues**
2405.10128v1 by Xiaofei Wen, Bangzheng Li, Tenghao Huang, Muhao Chen

Most language models currently available are prone to self-contradiction
during dialogues. To mitigate this issue, this study explores a novel
contradictory dialogue processing task that aims to detect and modify
contradictory statements in a conversation. This task is inspired by research
on context faithfulness and dialogue comprehension, which have demonstrated
that the detection and understanding of contradictions often necessitate
detailed explanations. We develop a dataset comprising contradictory dialogues,
in which one side of the conversation contradicts itself. Each dialogue is
accompanied by an explanatory label that highlights the location and details of
the contradiction. With this dataset, we present a Red Teaming framework for
contradictory dialogue processing. The framework detects and attempts to
explain the dialogue, then modifies the existing contradictory content using
the explanation. Our experiments demonstrate that the framework improves the
ability to detect contradictory dialogues and provides valid explanations.
Additionally, it showcases distinct capabilities for modifying such dialogues.
Our study highlights the importance of the logical inconsistency problem in
conversational AI.

摘要：目前大多數語言模型在對話中容易產生自我矛盾。為了減輕這個問題，本研究探討了一項新穎的矛盾對話處理任務，旨在偵測和修改對話中的矛盾陳述。此任務的靈感來自於對語境忠實度和對話理解的研究，這些研究已證明，矛盾的偵測和理解通常需要詳細的說明。我們開發了一個包含矛盾對話的資料集，其中對話的一方自相矛盾。每個對話都附有一個說明標籤，用以強調矛盾的位置和細節。有了這個資料集，我們提出了一個用於矛盾對話處理的紅隊架構。此架構會偵測對話並嘗試解釋，然後使用說明修改現有的矛盾內容。我們的實驗證明，此架構能提升偵測矛盾對話的能力，並提供有效的說明。此外，它還展示了修改此類對話的不同功能。我們的研究強調了邏輯不一致問題在對話式 AI 中的重要性。

##### **Distilling Implicit Multimodal Knowledge into LLMs for Zero-Resource Dialogue Generation**
2405.10121v1 by Bo Zhang, Hui Ma, Jian Ding, Jian Wang, Bo Xu, Hongfei Lin

Integrating multimodal knowledge into large language models (LLMs) represents
a significant advancement in dialogue generation capabilities. However, the
effective incorporation of such knowledge in zero-resource scenarios remains a
substantial challenge due to the scarcity of diverse, high-quality dialogue
datasets. To address this, we propose the Visual Implicit Knowledge
Distillation Framework (VIKDF), an innovative approach aimed at enhancing LLMs
for enriched dialogue generation in zero-resource contexts by leveraging
implicit multimodal knowledge. VIKDF comprises two main stages: knowledge
distillation, using an Implicit Query Transformer to extract and encode visual
implicit knowledge from image-text pairs into knowledge vectors; and knowledge
integration, employing a novel Bidirectional Variational Information Fusion
technique to seamlessly integrate these distilled vectors into LLMs. This
enables the LLMs to generate dialogues that are not only coherent and engaging
but also exhibit a deep understanding of the context through implicit
multimodal cues, effectively overcoming the limitations of zero-resource
scenarios. Our extensive experimentation across two dialogue datasets shows
that VIKDF outperforms existing state-of-the-art models in generating
high-quality dialogues. The code will be publicly available following
acceptance.

摘要：將多模式知識整合到大型語言模型 (LLM) 中，代表對話產生能力的重大進展。然而，由於缺乏多樣化、高品質的對話資料集，在零資源場景中有效整合此類知識仍然是一項重大挑戰。為了解決這個問題，我們提出了視覺隱含知識蒸餾框架 (VIKDF)，這是一種創新的方法，旨在通過利用隱含的多模式知識，增強 LLM 在零資源場景中的豐富對話產生。VIKDF 包含兩個主要階段：知識蒸餾，使用隱含查詢轉換器從影像文字對中萃取和編碼視覺隱含知識成知識向量；以及知識整合，採用新穎的雙向變異資訊融合技術，將這些蒸餾向量無縫整合到 LLM 中。這使 LLM 能夠產生不僅連貫且引人入勝的對話，而且還能透過隱含的多模式提示，對脈絡有深入的理解，有效克服零資源場景的限制。我們在兩個對話資料集上進行的廣泛實驗表明，VIKDF 在產生高品質對話方面優於現有的最先進模型。在接受後，程式碼將公開提供。

##### **A novel Reservoir Architecture for Periodic Time Series Prediction**
2405.10102v1 by Zhongju Yuan, Geraint Wiggins, Dick Botteldooren

This paper introduces a novel approach to predicting periodic time series
using reservoir computing. The model is tailored to deliver precise forecasts
of rhythms, a crucial aspect for tasks such as generating musical rhythm.
Leveraging reservoir computing, our proposed method is ultimately oriented
towards predicting human perception of rhythm. Our network accurately predicts
rhythmic signals within the human frequency perception range. The model
architecture incorporates primary and intermediate neurons tasked with
capturing and transmitting rhythmic information. Two parameter matrices,
denoted as c and k, regulate the reservoir's overall dynamics. We propose a
loss function to adapt c post-training and introduce a dynamic selection (DS)
mechanism that adjusts $k$ to focus on areas with outstanding contributions.
Experimental results on a diverse test set showcase accurate predictions,
further improved through real-time tuning of the reservoir via c and k.
Comparative assessments highlight its superior performance compared to
conventional models.

摘要：本文介紹了一種使用儲存器運算預測週期性時間序列的新穎方法。此模型經過量身打造，可提供節奏的精準預測，這是產生音樂節奏等任務的關鍵面向。我們的建議方法利用儲存器運算，最終目標是預測人類對節奏的感知。我們的網路準確預測人類頻率感知範圍內的節奏訊號。模型架構包含負責擷取和傳遞節奏資訊的主要神經元和中間神經元。兩個參數矩陣，表示為 c 和 k，用來調節儲存器的整體動態。我們提出一個損失函數來調整 c 後訓練，並引入一個動態選擇 (DS) 機制，調整 k 以專注於有傑出貢獻的區域。在多樣化測試集上的實驗結果展示了準確的預測，透過 c 和 k 即時調整儲存器後進一步改進。比較評估突顯其與傳統模型相比的卓越效能。

##### **LaT-PFN: A Joint Embedding Predictive Architecture for In-context Time-series Forecasting**
2405.10093v1 by Stijn Verdenius, Andrea Zerio, Roy L. M. Wang

We introduce LatentTimePFN (LaT-PFN), a foundational Time Series model with a
strong embedding space that enables zero-shot forecasting. To achieve this, we
perform in-context learning in latent space utilizing a novel integration of
the Prior-data Fitted Networks (PFN) and Joint Embedding Predictive
Architecture (JEPA) frameworks. We leverage the JEPA framework to create a
prediction-optimized latent representation of the underlying stochastic process
that generates time series and combines it with contextual learning, using a
PFN. Furthermore, we improve on preceding works by utilizing related time
series as a context and introducing an abstract time axis. This drastically
reduces training time and increases the versatility of the model by allowing
any time granularity and forecast horizon. We show that this results in
superior zero-shot predictions compared to established baselines. We also
demonstrate our latent space produces informative embeddings of both individual
time steps and fixed-length summaries of entire series. Finally, we observe the
emergence of multi-step patch embeddings without explicit training, suggesting
the model actively learns discrete tokens that encode local structures in the
data, analogous to vision transformers.

摘要：我們引入 LatentTimePFN (LaT-PFN)，一個具有強大嵌入空間的基本時間序列模型，支援零次預測。為達成此目的，我們在潛在空間中執行情境學習，利用先驗資料擬合網路 (PFN) 和聯合嵌入預測架構 (JEPA) 框架的創新整合。我們運用 JEPA 框架，建立產生時間序列的底層隨機過程的預測最佳化潛在表示，並使用 PFN 將其與情境學習結合。此外，我們透過利用相關時間序列作為情境，並引入抽象時間軸，來改進前人的研究。這大幅縮短訓練時間，並允許任何時間粒度和預測範圍，進而提升模型的多功能性。我們證明，相較於既定的基準，這會產生優異的零次預測。我們也證明我們的潛在空間產生個別時間步驟和整個序列的固定長度摘要的資訊性嵌入。最後，我們觀察到多步驟修補嵌入的出現，而無需明確訓練，這表示模型主動學習編碼資料中局部結構的離散符號，類似於視覺Transformer。

##### **An Integrated Framework for Multi-Granular Explanation of Video Summarization**
2405.10082v1 by Konstantinos Tsigos, Evlampios Apostolidis, Vasileios Mezaris

In this paper, we propose an integrated framework for multi-granular
explanation of video summarization. This framework integrates methods for
producing explanations both at the fragment level (indicating which video
fragments influenced the most the decisions of the summarizer) and the more
fine-grained visual object level (highlighting which visual objects were the
most influential for the summarizer). To build this framework, we extend our
previous work on this field, by investigating the use of a model-agnostic,
perturbation-based approach for fragment-level explanation of the video
summarization results, and introducing a new method that combines the results
of video panoptic segmentation with an adaptation of a perturbation-based
explanation approach to produce object-level explanations. The performance of
the developed framework is evaluated using a state-of-the-art summarization
method and two datasets for benchmarking video summarization. The findings of
the conducted quantitative and qualitative evaluations demonstrate the ability
of our framework to spot the most and least influential fragments and visual
objects of the video for the summarizer, and to provide a comprehensive set of
visual-based explanations about the output of the summarization process.

摘要：<paragraph>在本文中，我們提出了一個用於多粒度解釋影片摘要的整合架構。此架構整合了在片段層級（指出哪些影片片段最影響摘要器的決策）和更細粒度的視覺物件層級（強調哪些視覺物件對摘要器最有影響力）產生解釋的方法。為了建立這個架構，我們擴展了我們之前在這方面的研究，探討使用與模型無關的、基於擾動的方法來解釋片段層級的影片摘要結果，並引入一種新方法，將影片全景分割的結果與基於擾動的解釋方法的改編相結合，以產生物件層級的解釋。已開發架構的效能使用最先進的摘要方法和兩個用於基準測試影片摘要的資料集進行評估。所進行的量化和質化評估的結果證明了我們的架構能夠找出摘要器中影響最大和最小的片段和視覺物件，並提供一組關於摘要過程輸出的基於視覺的全面解釋。</paragraph>

##### **HecVL: Hierarchical Video-Language Pretraining for Zero-shot Surgical Phase Recognition**
2405.10075v1 by Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy

Natural language could play an important role in developing generalist
surgical models by providing a broad source of supervision from raw texts. This
flexible form of supervision can enable the model's transferability across
datasets and tasks as natural language can be used to reference learned visual
concepts or describe new ones. In this work, we present HecVL, a novel
hierarchical video-language pretraining approach for building a generalist
surgical model. Specifically, we construct a hierarchical video-text paired
dataset by pairing the surgical lecture video with three hierarchical levels of
texts: at clip-level, atomic actions using transcribed audio texts; at
phase-level, conceptual text summaries; and at video-level, overall abstract
text of the surgical procedure. Then, we propose a novel fine-to-coarse
contrastive learning framework that learns separate embedding spaces for the
three video-text hierarchies using a single model. By disentangling embedding
spaces of different hierarchical levels, the learned multi-modal
representations encode short-term and long-term surgical concepts in the same
model. Thanks to the injected textual semantics, we demonstrate that the HecVL
approach can enable zero-shot surgical phase recognition without any human
annotation. Furthermore, we show that the same HecVL model for surgical phase
recognition can be transferred across different surgical procedures and medical
centers.

摘要：自然語言可以在開發通用的外科模型中扮演重要角色，它可以提供廣泛的原始文本監督來源。這種靈活的監督形式可以使用自然語言來參考已學習的視覺概念或描述新的概念，從而使模型能夠跨數據集和任務進行轉移。在這項工作中，我們提出了 HecVL，這是一種新穎的分層視頻語言預訓練方法，用於構建通用的外科模型。具體來說，我們構建了一個分層視頻文本配對數據集，通過將外科手術講解視頻與三級分層文本配對：在片段級別，使用轉錄的音頻文本進行原子操作；在階段級別，概念文本摘要；在視頻級別，外科手術的整體摘要文本。然後，我們提出了一個新穎的精到粗略對比學習框架，該框架使用單個模型為三個視頻文本層次結構學習單獨的嵌入空間。通過解開不同層次結構的嵌入空間，學習到的多模態表示在同一個模型中編碼了短期和長期的外科概念。由於注入了文本語義，我們證明了 HecVL 方法可以在沒有任何人工註解的情況下實現零次外科手術階段識別。此外，我們表明，用於外科手術階段識別的相同 HecVL 模型可以轉移到不同的外科手術和醫療中心。

##### **MarkLLM: An Open-Source Toolkit for LLM Watermarking**
2405.10051v1 by Leyi Pan, Aiwei Liu, Zhiwei He, Zitian Gao, Xuandong Zhao, Yijian Lu, Binglin Zhou, Shuliang Liu, Xuming Hu, Lijie Wen, Irwin King

LLM watermarking, which embeds imperceptible yet algorithmically detectable
signals in model outputs to identify LLM-generated text, has become crucial in
mitigating the potential misuse of large language models. However, the
abundance of LLM watermarking algorithms, their intricate mechanisms, and the
complex evaluation procedures and perspectives pose challenges for researchers
and the community to easily experiment with, understand, and assess the latest
advancements. To address these issues, we introduce MarkLLM, an open-source
toolkit for LLM watermarking. MarkLLM offers a unified and extensible framework
for implementing LLM watermarking algorithms, while providing user-friendly
interfaces to ensure ease of access. Furthermore, it enhances understanding by
supporting automatic visualization of the underlying mechanisms of these
algorithms. For evaluation, MarkLLM offers a comprehensive suite of 12 tools
spanning three perspectives, along with two types of automated evaluation
pipelines. Through MarkLLM, we aim to support researchers while improving the
comprehension and involvement of the general public in LLM watermarking
technology, fostering consensus and driving further advancements in research
and application. Our code is available at https://github.com/THU-BPM/MarkLLM.

摘要：LLM 浮水印，它會將難以察覺但演算法可偵測到的訊號嵌入在模型輸出中，以識別 LLM 生成的文字，已成為減輕大型語言模型可能被濫用的關鍵。然而，LLM 浮水印演算法的豐富性、其複雜的機制，以及複雜的評估程序和觀點，對研究人員和社群來說，在輕鬆地實驗、理解和評估最新進展方面構成挑戰。為了解決這些問題，我們引入了 MarkLLM，一個 LLM 浮水印的開源工具包。MarkLLM 提供了一個統一且可擴充的架構，用於實作 LLM 浮水印演算法，同時提供使用者友善的介面，以確保易於存取。此外，它透過支援這些演算法的底層機制的自動視覺化來增強理解。在評估方面，MarkLLM 提供了一套包含 12 個工具的全面套件，涵蓋了三個觀點，以及兩種自動化評估管道。透過 MarkLLM，我們旨在支援研究人員，同時提高一般大眾對 LLM 浮水印技術的理解和參與，促成共識並推動研究和應用進一步的進展。我們的程式碼可在 https://github.com/THU-BPM/MarkLLM 取得。

##### **Global Benchmark Database**
2405.10045v1 by Markus Iser, Christoph Jabs

This paper presents Global Benchmark Database (GBD), a comprehensive suite of
tools for provisioning and sustainably maintaining benchmark instances and
their metadata. The availability of benchmark metadata is essential for many
tasks in empirical research, e.g., for the data-driven compilation of
benchmarks, the domain-specific analysis of runtime experiments, or the
instance-specific selection of solvers. In this paper, we introduce the data
model of GBD as well as its interfaces and provide examples of how to interact
with them. We also demonstrate the integration of custom data sources and
explain how to extend GBD with additional problem domains, instance formats and
feature extractors.

摘要：本論文提出全球基準資料庫 (GBD)，這是一個全面的工具組，用於提供和永續維護基準實例及其元資料。基準元資料的可用性對於實證研究中的許多任務至關重要，例如，用於基準的資料驅動編譯、執行時間實驗的特定領域分析或求解器的特定實例選擇。在本文中，我們介紹 GBD 的資料模型及其介面，並提供如何與它們互動的範例。我們也示範自訂資料來源的整合，並說明如何使用其他問題領域、實例格式和特徵萃取器來延伸 GBD。

##### **SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation**
2405.10040v1 by Abhishek Divekar, Greg Durrett

Large language models (LLMs) are versatile and can address many tasks, but
for computational efficiency, it is often desirable to distill their
capabilities into smaller student models. One way to do this for classification
tasks is via dataset synthesis, which can be accomplished by generating
examples of each label from the LLM. Prior approaches to synthesis use few-shot
prompting, which relies on the LLM's parametric knowledge to generate usable
examples. However, this leads to issues of repetition, bias towards popular
entities, and stylistic differences from human text. In this work, we propose
Synthesize by Retrieval and Refinement (SynthesizRR), which uses retrieval
augmentation to introduce variety into the dataset synthesis process: as
retrieved passages vary, the LLM is "seeded" with different content to generate
its examples. We empirically study the synthesis of six datasets, covering
topic classification, sentiment analysis, tone detection, and humor, requiring
complex synthesis strategies. We find SynthesizRR greatly improves lexical and
semantic diversity, similarity to human-written text, and distillation
performance, when compared to standard 32-shot prompting and six baseline
approaches.

摘要：大型語言模型 (LLM) 具有多功能性，可處理多項任務，但為了運算效率，通常會希望將其能力提煉到較小的學生模型中。對於分類任務，一種做法是透過資料集合成，這可透過從 LLM 產生每個標籤的範例來完成。先前的合成方法使用少次提示，這依賴 LLM 的參數化知識來產生可用的範例。然而，這會導致重複、偏向熱門實體，以及與人類文字在風格上的差異。在這項工作中，我們提出透過檢索和精煉進行合成 (SynthesizRR)，它使用檢索擴充來在資料集合成過程中引入多樣性：由於檢索到的段落有所不同，因此 LLM 會「植入」不同的內容來產生範例。我們實證研究了六個資料集的合成，涵蓋主題分類、情緒分析、語氣偵測和幽默，需要複雜的合成策略。與標準的 32 次提示和六種基準方法相比，我們發現 SynthesizRR 大幅提升了詞彙和語義的多樣性、與人類撰寫文字的相似性，以及提煉效能。

##### **Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models**
2405.10025v1 by Yuchen Hu, Chen Chen, Chengwei Qin, Qiushi Zhu, Eng Siong Chng, Ruizhe Li

Recent advances in large language models (LLMs) have promoted generative
error correction (GER) for automatic speech recognition (ASR), which aims to
predict the ground-truth transcription from the decoded N-best hypotheses.
Thanks to the strong language generation ability of LLMs and rich information
in the N-best list, GER shows great effectiveness in enhancing ASR results.
However, it still suffers from two limitations: 1) LLMs are unaware of the
source speech during GER, which may lead to results that are grammatically
correct but violate the source speech content, 2) N-best hypotheses usually
only vary in a few tokens, making it redundant to send all of them for GER,
which could confuse LLM about which tokens to focus on and thus lead to
increased miscorrection. In this paper, we propose ClozeGER, a new paradigm for
ASR generative error correction. First, we introduce a multimodal LLM (i.e.,
SpeechGPT) to receive source speech as extra input to improve the fidelity of
correction output. Then, we reformat GER as a cloze test with logits
calibration to remove the input information redundancy and simplify GER with
clear instructions. Experiments show that ClozeGER achieves a new breakthrough
over vanilla GER on 9 popular ASR datasets.

摘要：最近大型语言模型 (LLM) 的进步促进了生成式错误校正 (GER)，用于自动语音识别 (ASR)，其目标是从解码后的 N 个最佳假设中预测真实转录。
由于 LLM 强大的语言生成能力和 N 个最佳列表中的丰富信息，GER 在增强 ASR 结果方面显示出极佳的有效性。
然而，它仍然存在两个限制：1) LLM 在 GER 期间不知道源语音，这可能导致结果在语法上正确，但违反源语音内容，2) N 个最佳假设通常只在几个标记中有所不同，因此将它们全部发送到 GER 是多余的，这可能会混淆 LLM 应该关注哪些标记，从而导致错误校正增加。在本文中，我们提出了 ClozeGER，这是一种用于 ASR 生成式错误校正的新范例。首先，我们引入了一个多模态 LLM（即 SpeechGPT）来接收源语音作为额外的输入，以提高校正输出的保真度。然后，我们将 GER 重新格式化为完形填空测试，并进行 logit 校准，以消除输入信息冗余并简化 GER，并提供明确的说明。实验表明，ClozeGER 在 9 个流行的 ASR 数据集上实现了对香草 GER 的新突破。

##### **Natural Language Can Help Bridge the Sim2Real Gap**
2405.10020v1 by Albert Yu, Adeline Foote, Raymond Mooney, Roberto Martín-Martín

The main challenge in learning image-conditioned robotic policies is
acquiring a visual representation conducive to low-level control. Due to the
high dimensionality of the image space, learning a good visual representation
requires a considerable amount of visual data. However, when learning in the
real world, data is expensive. Sim2Real is a promising paradigm for overcoming
data scarcity in the real-world target domain by using a simulator to collect
large amounts of cheap data closely related to the target task. However, it is
difficult to transfer an image-conditioned policy from sim to real when the
domains are very visually dissimilar. To bridge the sim2real visual gap, we
propose using natural language descriptions of images as a unifying signal
across domains that captures the underlying task-relevant semantics. Our key
insight is that if two image observations from different domains are labeled
with similar language, the policy should predict similar action distributions
for both images. We demonstrate that training the image encoder to predict the
language description or the distance between descriptions of a sim or real
image serves as a useful, data-efficient pretraining step that helps learn a
domain-invariant image representation. We can then use this image encoder as
the backbone of an IL policy trained simultaneously on a large amount of
simulated and a handful of real demonstrations. Our approach outperforms widely
used prior sim2real methods and strong vision-language pretraining baselines
like CLIP and R3M by 25 to 40%.

摘要：影像條件機器人政策學習中的主要挑戰在於取得有助於低階控制的視覺表示。由於影像空間的高維度，學習良好的視覺表示需要大量的視覺資料。然而，在現實世界中學習時，資料是昂貴的。Sim2Real 是一種有前途的範例，可透過使用模擬器來收集大量與目標任務密切相關的廉價資料，以克服現實世界目標領域中的資料稀少問題。然而，當領域在視覺上非常不同時，要將影像條件政策從模擬轉移到真實世界是很困難的。為了彌合 sim2real 視覺差距，我們建議使用影像的自然語言描述作為跨領域的統一訊號，以擷取基礎的與任務相關的語義。我們的關鍵見解是，如果來自不同領域的兩個影像觀察被標記為類似的語言，則政策應預測兩張影像類似的動作分佈。我們證明訓練影像編碼器來預測語言描述或模擬或真實影像描述之間的距離，作為一個有用的、資料有效率的預訓練步驟，有助於學習領域不變的影像表示。然後，我們可以使用此影像編碼器作為 IL 政策的主幹，同時在大量的模擬和少量的真實示範中進行訓練。我們的做法優於廣泛使用的先前 sim2real 方法和強大的視覺語言預訓練基準，例如 CLIP 和 R3M，達 25% 至 40%。

##### **Histopathology Foundation Models Enable Accurate Ovarian Cancer Subtype Classification**
2405.09990v1 by Jack Breen, Katie Allen, Kieran Zucker, Lucy Godson, Nicolas M. Orsi, Nishant Ravikumar

Large pretrained transformers are increasingly being developed as generalised
foundation models which can underpin powerful task-specific artificial
intelligence models. Histopathology foundation models show promise across many
tasks, but analyses have been limited by arbitrary hyperparameters that were
not tuned to the specific task/dataset. We report the most rigorous single-task
validation conducted to date of a histopathology foundation model, and the
first performed in ovarian cancer subtyping. Attention-based multiple instance
learning classifiers were compared using vision transformer and ResNet features
generated through varied preprocessing and pretraining procedures. The training
set consisted of 1864 whole slide images from 434 ovarian carcinoma cases at
Leeds Hospitals. Five-class classification performance was evaluated through
five-fold cross-validation, and these cross-validation models were ensembled
for evaluation on a hold-out test set and an external set from the
Transcanadian study. Reporting followed the TRIPOD+AI checklist. The vision
transformer-based histopathology foundation model, UNI, performed best in every
evaluation, with five-class balanced accuracies of 88% and 93% in hold-out
internal and external testing, compared to the best ResNet model scores of 68%
and 81%, respectively. Normalisations and augmentations aided the
generalisability of ResNet-based models, but these still did not match the
performance of UNI, which gave the best external performance in any ovarian
cancer subtyping study to date. Histopathology foundation models offer a clear
benefit to subtyping, improving classification performance to a degree where
clinical utility is tangible, albeit with an increased computational burden.
Such models could provide a second opinion in challenging cases and may improve
the accuracy, objectivity, and efficiency of pathological diagnoses overall.

摘要：<paragraph>大型预训练 Transformer 正日益作为通用基础模型而开发，它可以支撑强大的特定任务人工智能模型。组织病理学基础模型在许多任务中显示出前景，但分析受到未针对特定任务/数据集进行调整的任意超参数的限制。我们报告了迄今为止对组织病理学基础模型进行的最严格的单任务验证，以及在卵巢癌亚型分类中进行的首次验证。基于注意力的多实例学习分类器使用通过不同的预处理和预训练过程生成的视觉 Transformer 和 ResNet 特征进行了比较。训练集由利兹医院 434 例卵巢癌病例的 1864 张全幻灯片图像组成。五类分类性能通过五折交叉验证进行评估，这些交叉验证模型被集成用于在保留测试集和 Transcanadian 研究的外部集上进行评估。报告遵循 TRIPOD+AI 清单。基于视觉 Transformer 的组织病理学基础模型 UNI 在每次评估中表现最佳，在保留内部和外部测试中的五类平衡准确率分别为 88% 和 93%，而最佳 ResNet 模型得分分别为 68% 和 81%。归一化和增强有助于基于 ResNet 的模型的泛化能力，但这些仍然无法与 UNI 的性能相匹配，UNI 在迄今为止的任何卵巢癌亚型分类研究中都给出了最佳的外部性能。组织病理学基础模型为亚型分类提供了明显的好处，将分类性能提高到临床效用切实可行的程度，尽管增加了计算负担。此类模型可以在具有挑战性的病例中提供第二意见，并可能提高病理诊断的准确性、客观性和效率。</paragraph>

##### **Zero-Shot Hierarchical Classification on the Common Procurement Vocabulary Taxonomy**
2405.09983v1 by Federico Moiraghi, Matteo Palmonari, Davide Allavena, Federico Morando

Classifying public tenders is a useful task for both companies that are
invited to participate and for inspecting fraudulent activities. To facilitate
the task for both participants and public administrations, the European Union
presented a common taxonomy (\textit{Common Procurement Vocabulary}, CPV) which
is mandatory for tenders of certain importance; however, the contracts in which
a CPV label is mandatory are the minority compared to all the Public
Administrations activities. Classifying over a real-world taxonomy introduces
some difficulties that can not be ignored. First of all, some fine-grained
classes have an insufficient (if any) number of observations in the training
set, while other classes are far more frequent (even thousands of times) than
the average. To overcome those difficulties, we present a zero-shot approach,
based on a pre-trained language model that relies only on label description and
respects the label taxonomy. To train our proposed model, we used industrial
data, which comes from \url{contrattipubblici.org}, a service by
\href{https://spaziodati.eu}{SpazioDati s.r.l}. that collects public contracts
stipulated in Italy in the last 25 years. Results show that the proposed model
achieves better performance in classifying low-frequent classes compared to
three different baselines, and is also able to predict never-seen classes.

摘要：公共標案分類是一項對受邀參與的企業和檢查詐騙活動都有用的任務。為了方便參與者和公共行政部門執行這項任務，歐盟提出了一個共同分類法（「共同採購詞彙」，CPV），對於一定重要性的標案而言，CPV 標籤是強制性的；然而，與所有公共行政部門的活動相比，強制使用 CPV 標籤的合約僅佔少數。使用真實世界的分類法進行分類會產生一些不容忽視的困難。首先，一些細緻的類別在訓練集中沒有足夠（如果有）的觀察次數，而其他類別的頻率則比平均值高出許多（甚至高出數千倍）。為了克服這些困難，我們提出了一種零次學習方法，這種方法基於預先訓練好的語言模型，僅依賴標籤描述並遵循標籤分類法。為了訓練我們提出的模型，我們使用了產業資料，這些資料來自 \url{contrattipubblici.org}，這是 \href{https://spaziodati.eu}{SpazioDati s.r.l} 提供的一項服務，它收集了義大利在過去 25 年內簽訂的公共合約。結果顯示，與三個不同的基準相比，所提出的模型在對低頻率類別進行分類時能達到更好的效能，而且也能預測從未看過的類別。

##### **FinTextQA: A Dataset for Long-form Financial Question Answering**
2405.09980v1 by Jian Chen, Peilin Zhou, Yining Hua, Yingxin Loh, Kehui Chen, Ziyuan Li, Bing Zhu, Junwei Liang

Accurate evaluation of financial question answering (QA) systems necessitates
a comprehensive dataset encompassing diverse question types and contexts.
However, current financial QA datasets lack scope diversity and question
complexity. This work introduces FinTextQA, a novel dataset for long-form
question answering (LFQA) in finance. FinTextQA comprises 1,262 high-quality,
source-attributed QA pairs extracted and selected from finance textbooks and
government agency websites.Moreover, we developed a Retrieval-Augmented
Generation (RAG)-based LFQA system, comprising an embedder, retriever,
reranker, and generator. A multi-faceted evaluation approach, including human
ranking, automatic metrics, and GPT-4 scoring, was employed to benchmark the
performance of different LFQA system configurations under heightened noisy
conditions. The results indicate that: (1) Among all compared generators,
Baichuan2-7B competes closely with GPT-3.5-turbo in accuracy score; (2) The
most effective system configuration on our dataset involved setting the
embedder, retriever, reranker, and generator as Ada2, Automated Merged
Retrieval, Bge-Reranker-Base, and Baichuan2-7B, respectively; (3) models are
less susceptible to noise after the length of contexts reaching a specific
threshold.

摘要：準確評估財務問答 (QA) 系統需要一個包含各種問題類型和背景的綜合資料集。然而，當前的財務 QA 資料集缺乏範圍的多樣性和問題的複雜性。這項工作引入了 FinTextQA，一個用於財務中的長篇問答 (LFQA) 的新穎資料集。FinTextQA 包含 1,262 個高品質、來源明確的 QA 對，從財務教科書和政府機構網站中提取和選取。此外，我們開發了一個基於檢索增強生成 (RAG) 的 LFQA 系統，包括嵌入器、檢索器、重新排序器和生成器。採用了一個多方面的評估方法，包括人工排名、自動化指標和 GPT-4 評分，用於在加強的雜訊條件下對不同 LFQA 系統組態的效能進行基準測試。結果表明：(1) 在所有比較過的生成器中，Baichuan2-7B 在準確度分數上與 GPT-3.5-turbo 競爭激烈；(2) 在我們的資料集上最有效的系統組態涉及將嵌入器、檢索器、重新排序器和生成器分別設定為 Ada2、自動合併檢索、Bge-Reranker-Base 和 Baichuan2-7B；(3) 在背景長度達到特定閾值後，模型對雜訊的影響較小。

##### **Predicting Solar Heat Production to Optimize Renewable Energy Usage**
2405.09972v1 by Tatiana Boura, Natalia Koliou, George Meramveliotakis, Stasinos Konstantopoulos, George Kosmadakis

Utilizing solar energy to meet space heating and domestic hot water demand is
very efficient (in terms of environmental footprint as well as cost), but in
order to ensure that user demand is entirely covered throughout the year needs
to be complemented with auxiliary heating systems, typically boilers and heat
pumps. Naturally, the optimal control of such a system depends on an accurate
prediction of solar thermal production.
  Experimental testing and physics-based numerical models are used to find a
collector's performance curve - the mapping from solar radiation and other
external conditions to heat production - but this curve changes over time once
the collector is exposed to outdoor conditions. In order to deploy advanced
control strategies in small domestic installations, we present an approach that
uses machine learning to automatically construct and continuously adapt a model
that predicts heat production. Our design is driven by the need to (a)
construct and adapt models using supervision that can be extracted from
low-cost instrumentation, avoiding extreme accuracy and reliability
requirements; and (b) at inference time, use inputs that are typically provided
in publicly available weather forecasts.
  Recent developments in attention-based machine learning, as well as careful
adaptation of the training setup to the specifics of the task, have allowed us
to design a machine learning-based solution that covers our requirements. We
present positive empirical results for the predictive accuracy of our solution,
and discuss the impact of these results on the end-to-end system.

摘要：利用太陽能來滿足空間加熱和生活熱水需求非常有效率（無論在環境足跡或成本方面），但為了確保使用者需求全年都能滿足，需要輔助加熱系統，通常是鍋爐和熱泵。自然地，此類系統的最佳控制取決於太陽熱能生產的準確預測。
實驗測試和基於物理的數值模型用於找到集熱器的效能曲線，即從太陽輻射和其他外部條件到熱能生產的對應關係，但此曲線在集熱器暴露於戶外條件後會隨時間而改變。為了在小型家用裝置中部署先進的控制策略，我們提出了一種使用機器學習自動構建和持續調整模型的方法，該模型可以預測熱能生產。我們的設計是由以下需求驅動的：(a) 使用可從低成本儀器中提取的監督來構建和調整模型，避免極高的準確度和可靠性要求；(b) 在推理時，使用通常在公開天氣預報中提供的輸入。
基於注意力的機器學習的最新發展，以及對訓練設置進行仔細調整以適應任務的具體情況，使我們能夠設計出滿足我們要求的基於機器學習的解決方案。我們展示了我們解決方案的預測準確度的正面經驗結果，並討論了這些結果對端到端系統的影響。

##### **Mitigating Text Toxicity with Counterfactual Generation**
2405.09948v1 by Milan Bhan, Jean-Noel Vittaut, Nina Achache, Victor Legrand, Nicolas Chesneau, Annabelle Blangero, Juliette Murris, Marie-Jeanne Lesot

Toxicity mitigation consists in rephrasing text in order to remove offensive
or harmful meaning. Neural natural language processing (NLP) models have been
widely used to target and mitigate textual toxicity. However, existing methods
fail to detoxify text while preserving the initial non-toxic meaning at the
same time. In this work, we propose to apply counterfactual generation methods
from the eXplainable AI (XAI) field to target and mitigate textual toxicity. In
particular, we perform text detoxification by applying local feature importance
and counterfactual generation methods to a toxicity classifier distinguishing
between toxic and non-toxic texts. We carry out text detoxification through
counterfactual generation on three datasets and compare our approach to three
competitors. Automatic and human evaluations show that recently developed NLP
counterfactual generators can mitigate toxicity accurately while better
preserving the meaning of the initial text as compared to classical
detoxification methods. Finally, we take a step back from using automated
detoxification tools, and discuss how to manage the polysemous nature of
toxicity and the risk of malicious use of detoxification tools. This work is
the first to bridge the gap between counterfactual generation and text
detoxification and paves the way towards more practical application of XAI
methods.

摘要：毒性緩解包含改寫文字以移除冒犯或有害的意義。神經自然語言處理 (NLP) 模型已被廣泛用於鎖定和緩解文字毒性。然而，現有方法無法在同時保留最初非毒性意義的情況下對文字進行解毒。在這項工作中，我們提議應用來自可解釋 AI (XAI) 領域的反事實生成方法來鎖定和緩解文字毒性。特別是，我們透過將局部特徵重要性和反事實生成方法應用於區分有毒和無毒文字的毒性分類器來執行文字解毒。我們透過在三個資料集上進行反事實生成來執行文字解毒，並將我們的方法與三個競爭者進行比較。自動和人工評估顯示，最新開發的 NLP 反事實生成器可以準確地緩解毒性，同時比傳統的解毒方法更好地保留原始文字的意義。最後，我們不再使用自動解毒工具，並討論如何管理毒性的多義性以及解毒工具被惡意使用的風險。這項工作首次橋接了反事實生成和文字解毒之間的差距，並為 XAI 方法的更實際應用鋪平了道路。

##### **SciQAG: A Framework for Auto-Generated Scientific Question Answering Dataset with Fine-grained Evaluation**
2405.09939v1 by Yuwei Wan, Aswathy Ajith, Yixuan Liu, Ke Lu, Clara Grazian, Bram Hoex, Wenjie Zhang, Chunyu Kit, Tong Xie, Ian Foster

The use of question-answer (QA) pairs for training and evaluating large
language models (LLMs) has attracted considerable attention. Yet few available
QA datasets are based on knowledge from the scientific literature. Here we
bridge this gap by presenting Automatic Generation of Scientific Question
Answers (SciQAG), a framework for automatic generation and evaluation of
scientific QA pairs sourced from published scientific literature. We fine-tune
an open-source LLM to generate \num{960000} scientific QA pairs from full-text
scientific papers and propose a five-dimensional metric to evaluate the quality
of the generated QA pairs. We show via LLM-based evaluation that the generated
QA pairs consistently achieve an average score of 2.5 out of 3 across five
dimensions, indicating that our framework can distill key knowledge from papers
into high-quality QA pairs at scale. We make the dataset, models, and
evaluation codes publicly available.

摘要：使用問題解答 (QA) 成對資料來訓練和評估大型語言模型 (LLM) 已引起廣泛關注。然而，現有的 QA 資料集很少基於科學文獻中的知識。在此，我們通過提出科學問題答案的自動生成 (SciQAG)，一個用於從已發表的科學文獻中自動生成和評估科學 QA 成對資料的框架，來彌補這一差距。我們微調了一個開源 LLM，從全文科學論文中生成了 960000 個科學 QA 成對資料，並提出了五維度指標來評估生成的 QA 成對資料的品質。我們透過基於 LLM 的評估顯示，生成的 QA 成對資料在五個維度上始終如一地獲得 3 分中的 2.5 分，這表明我們的框架可以大規模地從論文中提取關鍵知識，並轉換成高品質的 QA 成對資料。我們公開提供資料集、模型和評估程式碼。

##### **DEBATE: Devil's Advocate-Based Assessment and Text Evaluation**
2405.09935v1 by Alex Kim, Keonwoo Kim, Sangwon Yoon

As natural language generation (NLG) models have become prevalent,
systematically assessing the quality of machine-generated texts has become
increasingly important. Recent studies introduce LLM-based evaluators that
operate as reference-free metrics, demonstrating their capability to adeptly
handle novel tasks. However, these models generally rely on a single-agent
approach, which, we argue, introduces an inherent limit to their performance.
This is because there exist biases in LLM agent's responses, including
preferences for certain text structure or content. In this work, we propose
DEBATE, an NLG evaluation framework based on multi-agent scoring system
augmented with a concept of Devil's Advocate. Within the framework, one agent
is instructed to criticize other agents' arguments, potentially resolving the
bias in LLM agent's answers. DEBATE substantially outperforms the previous
state-of-the-art methods in two meta-evaluation benchmarks in NLG evaluation,
SummEval and TopicalChat. We also show that the extensiveness of debates among
agents and the persona of an agent can influence the performance of evaluators.

摘要：随着自然语言生成 (NLG) 模型的普及，系统地评估机器生成的文本质量变得越来越重要。最近的研究引入了基于 LLM 的评估器，它们作为无参考指标运行，展示了它们熟练处理新任务的能力。然而，这些模型通常依赖于单一代理方法，我们认为，这会给它们的性能带来固有的限制。这是因为 LLM 代理的响应中存在偏差，包括对某些文本结构或内容的偏好。在这项工作中，我们提出了 DEBATE，一种基于多代理评分系统的 NLG 评估框架，并增强了魔鬼辩护人的概念。在该框架内，一名代理被指示批评其他代理的论点，从而有可能解决 LLM 代理答案中的偏差。DEBATE 在 NLG 评估的两个元评估基准 SummEval 和 TopicalChat 中明显优于以前最先进的方法。我们还表明，代理之间的辩论的广泛性和代理的角色会影响评估器的性能。

##### **Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance**
2405.09934v1 by Milda Pocevičiūtė, Gabriel Eilertsen, Stina Garvin, Claes Lundström

Multiple-instance learning (MIL) is an attractive approach for digital
pathology applications as it reduces the costs related to data collection and
labelling. However, it is not clear how sensitive MIL is to clinically
realistic domain shifts, i.e., differences in data distribution that could
negatively affect performance, and if already existing metrics for detecting
domain shifts work well with these algorithms. We trained an attention-based
MIL algorithm to classify whether a whole-slide image of a lymph node contains
breast tumour metastases. The algorithm was evaluated on data from a hospital
in a different country and various subsets of this data that correspond to
different levels of domain shift. Our contributions include showing that MIL
for digital pathology is affected by clinically realistic differences in data,
evaluating which features from a MIL model are most suitable for detecting
changes in performance, and proposing an unsupervised metric named Fr\'echet
Domain Distance (FDD) for quantification of domain shifts. Shift measure
performance was evaluated through the mean Pearson correlation to change in
classification performance, where FDD achieved 0.70 on 10-fold cross-validation
models. The baselines included Deep ensemble, Difference of Confidence, and
Representation shift which resulted in 0.45, -0.29, and 0.56 mean Pearson
correlation, respectively. FDD could be a valuable tool for care providers and
vendors who need to verify if a MIL system is likely to perform reliably when
implemented at a new site, without requiring any additional annotations from
pathologists.

摘要：多實例學習 (MIL) 是一種對數位病理應用而言具有吸引力的方法，因為它降低了與資料蒐集和標籤相關的成本。然而，MIL 對臨床現實領域轉移的敏感度並不清楚，也就是說，資料分佈的差異可能會對效能造成負面影響，而且現有的領域轉移偵測指標是否能順利與這些演算法搭配使用。我們訓練了一個基於注意力的 MIL 演算法，用於分類淋巴結的整張幻燈片影像是否包含乳房腫瘤轉移。該演算法在不同國家的醫院資料和對應於不同程度領域轉移的各種資料子集中進行評估。我們的貢獻包括顯示用於數位病理的 MIL 會受到資料在臨床上實際的差異影響，評估 MIL 模型中的哪些特徵最適合用於偵測效能變化，並提出一個名為 Fr\'echet 領域距離 (FDD) 的非監督式指標，用於量化領域轉移。轉移測量效能透過與分類效能變化的平均皮爾森相關性進行評估，其中 FDD 在 10 倍交叉驗證模型中達到 0.70。基準線包括深度整體、信心差異和表示轉移，分別產生 0.45、-0.29 和 0.56 的平均皮爾森相關性。FDD 可能是一個有價值的工具，供照護提供者和供應商在實施新的場域時驗證 MIL 系統是否可能執行可靠的效能，而不需要病理學家的任何額外註解。

##### **MiniMaxAD: A Lightweight Autoencoder for Feature-Rich Anomaly Detection**
2405.09933v1 by Fengjie Wang, Chengming Liu, Lei Shi, Pang Haibo

Previous unsupervised anomaly detection (UAD) methods often struggle with
significant intra-class diversity; i.e., a class in a dataset contains multiple
subclasses, which we categorize as Feature-Rich Anomaly Detection Datasets
(FRADs). This is evident in applications such as unified setting and unmanned
supermarket scenarios. To address this challenge, we developed MiniMaxAD: a
lightweight autoencoder designed to efficiently compress and memorize extensive
information from normal images. Our model utilizes a large kernel convolutional
network equipped with a Global Response Normalization (GRN) unit and employs a
multi-scale feature reconstruction strategy. The GRN unit significantly
increases the upper limit of the network's capacity, while the large kernel
convolution facilitates the extraction of highly abstract patterns, leading to
compact normal feature modeling. Additionally, we introduce an Adaptive
Contraction Loss (ADCLoss), tailored to FRADs to overcome the limitations of
global cosine distance loss. MiniMaxAD was comprehensively tested across six
challenging UAD benchmarks, achieving state-of-the-art results in four and
highly competitive outcomes in the remaining two. Notably, our model achieved a
detection AUROC of up to 97.0\% in ViSA under the unified setting. Moreover, it
not only achieved state-of-the-art performance in unmanned supermarket tasks
but also exhibited an inference speed 37 times faster than the previous best
method, demonstrating its effectiveness in complex UAD tasks.

摘要：先前的無監督異常偵測 (UAD) 方法通常難以應付顯著的類內多樣性；亦即資料集中的類別包含多個子類別，我們將其歸類為特徵豐富異常偵測資料集 (FRAD)。這在統一設定和無人超市場景等應用中很明顯。為了應對這個挑戰，我們開發了 MiniMaxAD：一種輕量級自動編碼器，旨在有效壓縮和記憶正常影像的大量資訊。我們的模型利用配備全局回應正規化 (GRN) 單元的卷積網路，並採用多尺度特徵重建策略。GRN 單元顯著增加了網路容量的上限，而大核卷積有助於提取高度抽象的模式，從而實現緊湊的正常特徵建模。此外，我們引入了一個適應性收縮損失 (ADCLoss)，專門針對 FRAD，以克服全局餘弦距離損失的限制。MiniMaxAD 在六個具有挑戰性的 UAD 基準測試中進行了全面測試，在四個測試中取得了最先進的結果，而在另外兩個測試中取得了極具競爭力的結果。值得注意的是，我們的模型在統一設定下，在 ViSA 中實現了高達 97.0% 的偵測 AUROC。此外，它不僅在無人超市任務中實現了最先進的效能，而且推理速度比先前的最佳方法快了 37 倍，證明了它在複雜 UAD 任務中的有效性。

##### **TransMI: A Framework to Create Strong Baselines from Multilingual Pretrained Language Models for Transliterated Data**
2405.09913v1 by Yihong Liu, Chunlan Ma, Haotian Ye, Hinrich Schütze

Transliterating related languages that use different scripts into a common
script shows effectiveness in improving crosslingual transfer in downstream
tasks. However, this methodology often makes pretraining a model from scratch
unavoidable, as transliteration brings about new subwords not covered in
existing multilingual pretrained language models (mPLMs). This is not desired
because it takes a lot of computation budget for pretraining. A more promising
way is to make full use of available mPLMs. To this end, this paper proposes a
simple but effective framework: Transliterate-Merge-Initialize (TransMI), which
can create a strong baseline well-suited for data that is transliterated into a
common script by exploiting an mPLM and its accompanied tokenizer. TransMI has
three stages: (a) transliterate the vocabulary of an mPLM into a common script;
(b) merge the new vocabulary with the original vocabulary; and (c) initialize
the embeddings of the new subwords. We applied TransMI to three recent strong
mPLMs, and our experiments demonstrate that TransMI not only preserves their
ability to handle non-transliterated data, but also enables the models to
effectively process transliterated data: the results show a consistent
improvement of 3% to 34%, varying across different models and tasks. We make
our code and models publicly available at
\url{https://github.com/cisnlp/TransMI}.

摘要：將使用不同腳本的相關語言轉錄成通用腳本，在改善下游任務中的跨語言轉移方面顯示出有效性。然而，這種方法通常會使從頭開始預訓練模型變得不可避免，因為轉錄會產生現有 mPLM（多語言預訓練語言模型）中未涵蓋的新子詞。這並非理想，因為預訓練需要大量的計算預算。一個更有前景的方法是充分利用現有的 mPLM。為此，本文提出了一個簡單但有效的框架：轉錄-合併-初始化（TransMI），它可以創建一個強大的基線，非常適合通過利用 mPLM 及其附帶的 tokenizer 轉錄成通用腳本的數據。TransMI 有三個階段：(a) 將 mPLM 的詞彙轉錄成通用腳本；(b) 將新詞彙與原始詞彙合併；(c) 初始化新子詞的嵌入。我們將 TransMI 應用於三個最近的強大 mPLM，我們的實驗表明 TransMI 不僅保留了它們處理未轉錄數據的能力，而且使模型能夠有效處理轉錄數據：結果顯示在不同的模型和任務中，一致地改進了 3% 到 34%。我們在 \url{https://github.com/cisnlp/TransMI} 公開我們的代碼和模型。

##### **Unveiling the Potential: Harnessing Deep Metric Learning to Circumvent Video Streaming Encryption**
2405.09902v1 by Arwin Gansekoele, Tycho Bot, Rob van der Mei, Sandjai Bhulai, Mark Hoogendoorn

Encryption on the internet with the shift to HTTPS has been an important step
to improve the privacy of internet users. However, there is an increasing body
of work about extracting information from encrypted internet traffic without
having to decrypt it. Such attacks bypass security guarantees assumed to be
given by HTTPS and thus need to be understood. Prior works showed that the
variable bitrates of video streams are sufficient to identify which video
someone is watching. These works generally have to make trade-offs in aspects
such as accuracy, scalability, robustness, etc. These trade-offs complicate the
practical use of these attacks. To that end, we propose a deep metric learning
framework based on the triplet loss method. Through this framework, we achieve
robust, generalisable, scalable and transferable encrypted video stream
detection. First, the triplet loss is better able to deal with video streams
not seen during training. Second, our approach can accurately classify videos
not seen during training. Third, we show that our method scales well to a
dataset of over 1000 videos. Finally, we show that a model trained on video
streams over Chrome can also classify streams over Firefox. Our results suggest
that this side-channel attack is more broadly applicable than originally
thought. We provide our code alongside a diverse and up-to-date dataset for
future research.

摘要：透過轉移至 HTTPS 的網路加密，已成為提升網路使用者隱私的重要一步。然而，關於在不需解密的情況下從加密網路流量中擷取資訊的研究正逐漸增加。此類攻擊會繞過 HTTPS 假設提供的安全保證，因此需要加以了解。先前研究顯示，影片串流的變動位元率足以用來識別某人正在觀看哪部影片。這些研究通常必須在準確度、可擴充性、穩健性等面向做出權衡。這些權衡讓這些攻擊的實際應用變得複雜。有鑑於此，我們提出一個基於三元組損失方法的深度度量學習架構。透過此架構，我們達成穩健、具泛化能力、可擴充且可轉移的加密影片串流偵測。首先，三元組損失更能處理在訓練期間未見過的影片串流。其次，我們的做法可以準確分類在訓練期間未見過的影片。第三，我們顯示我們的做法可以很好地擴充至包含超過 1000 個影片的資料集。最後，我們顯示在 Chrome 上訓練的模型也可以分類 Firefox 上的串流。我們的結果顯示，此旁通道攻擊的適用範圍比原本想像的更廣泛。我們提供我們的程式碼，以及一個多元且最新的資料集，供後續研究使用。

##### **Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models**
2405.09901v1 by Ziyu Wang, Lejun Min, Gus Xia

Recent deep music generation studies have put much emphasis on long-term
generation with structures. However, we are yet to see high-quality,
well-structured whole-song generation. In this paper, we make the first attempt
to model a full music piece under the realization of compositional hierarchy.
With a focus on symbolic representations of pop songs, we define a hierarchical
language, in which each level of hierarchy focuses on the semantics and context
dependency at a certain music scope. The high-level languages reveal whole-song
form, phrase, and cadence, whereas the low-level languages focus on notes,
chords, and their local patterns. A cascaded diffusion model is trained to
model the hierarchical language, where each level is conditioned on its upper
levels. Experiments and analysis show that our model is capable of generating
full-piece music with recognizable global verse-chorus structure and cadences,
and the music quality is higher than the baselines. Additionally, we show that
the proposed model is controllable in a flexible way. By sampling from the
interpretable hierarchical languages or adjusting pre-trained external
representations, users can control the music flow via various features such as
phrase harmonic structures, rhythmic patterns, and accompaniment texture.

摘要：近期的深度音乐生成研究非常重视具有结构的长程生成。然而，我们尚未看到高质量、结构良好的整首歌曲生成。在本文中，我们在作曲层次结构的实现下首次尝试对完整音乐作品进行建模。我们专注于流行歌曲的符号表示，定义了一种分层语言，其中每一层层次都专注于特定音乐范围内的语义和上下文依赖性。高级语言揭示了整首歌曲的形式、乐句和终止，而低级语言则专注于音符、和弦及其局部模式。级联扩散模型经过训练以对分层语言进行建模，其中每一层都以其上层为条件。实验和分析表明，我们的模型能够生成具有可识别的全局主歌-副歌结构和终止的全曲音乐，并且音乐质量高于基准。此外，我们表明所提出的模型以灵活的方式可控。通过从可解释的分层语言中采样或调整预训练的外部表示，用户可以通过各种特征（例如乐句和声结构、节奏模式和伴奏纹理）来控制音乐流。

##### **"Hunt Takes Hare": Theming Games Through Game-Word Vector Translation**
2405.09893v1 by Rabii Younès, Cook Michael

A game's theme is an important part of its design -- it conveys narrative
information, rhetorical messages, helps the player intuit strategies, aids in
tutorialisation and more. Thematic elements of games are notoriously difficult
for AI systems to understand and manipulate, however, and often rely on large
amounts of hand-written interpretations and knowledge. In this paper we present
a technique which connects game embeddings, a recent method for modelling game
dynamics from log data, and word embeddings, which models semantic information
about language. We explain two different approaches for using game embeddings
in this way, and show evidence that game embeddings enhance the linguistic
translations of game concepts from one theme to another, opening up exciting
new possibilities for reasoning about the thematic elements of games in the
future.

摘要：遊戲的主題是其設計中重要的一部分，它傳達敘事資訊、修辭訊息，有助於玩家直覺策略、輔助教學等。然而，遊戲的主題元素對於 AI 系統來說，出了名的難以理解和操作，而且常常依賴大量的親筆書寫詮釋和知識。在本文中，我們提出了一種技術，它連結了遊戲嵌入，一種從日誌資料建模遊戲動態的最新方法，以及字詞嵌入，一種建模語言語義資訊的方法。我們說明了兩種不同的方法，使用遊戲嵌入的方式，並展示了遊戲嵌入增強了遊戲概念從一個主題到另一個主題的語言翻譯的證據，為未來對遊戲主題元素的推理開啟了令人興奮的新可能性。

##### **DiffAM: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection**
2405.09882v1 by Yuhao Sun, Lingyun Yu, Hongtao Xie, Jiaming Li, Yongdong Zhang

With the rapid development of face recognition (FR) systems, the privacy of
face images on social media is facing severe challenges due to the abuse of
unauthorized FR systems. Some studies utilize adversarial attack techniques to
defend against malicious FR systems by generating adversarial examples.
However, the generated adversarial examples, i.e., the protected face images,
tend to suffer from subpar visual quality and low transferability. In this
paper, we propose a novel face protection approach, dubbed DiffAM, which
leverages the powerful generative ability of diffusion models to generate
high-quality protected face images with adversarial makeup transferred from
reference images. To be specific, we first introduce a makeup removal module to
generate non-makeup images utilizing a fine-tuned diffusion model with guidance
of textual prompts in CLIP space. As the inverse process of makeup transfer,
makeup removal can make it easier to establish the deterministic relationship
between makeup domain and non-makeup domain regardless of elaborate text
prompts. Then, with this relationship, a CLIP-based makeup loss along with an
ensemble attack strategy is introduced to jointly guide the direction of
adversarial makeup domain, achieving the generation of protected face images
with natural-looking makeup and high black-box transferability. Extensive
experiments demonstrate that DiffAM achieves higher visual quality and attack
success rates with a gain of 12.98% under black-box setting compared with the
state of the arts. The code will be available at
https://github.com/HansSunY/DiffAM.

摘要：隨著人臉辨識 (FR) 系統的快速發展，社群媒體上人臉影像的隱私，正因未經授權的 FR 系統濫用而面臨嚴峻的挑戰。有些研究利用對抗攻擊技術，透過產生對抗範例來抵禦惡意的 FR 系統。然而，產生的對抗範例，也就是受保護的人臉影像，往往有視覺品質不佳和低傳輸率的問題。在本文中，我們提出了一種新穎的人臉保護方法，稱為 DiffAM，它利用擴散模型強大的生成能力，從參考影像傳輸對抗化妝，來產生高品質的受保護人臉影像。具體來說，我們首先引入一個化妝移除模組，利用在 CLIP 空間中以文字提示為指導的微調擴散模型，來產生非化妝影像。化妝移除作為化妝傳輸的逆過程，可以更輕易地建立化妝領域和非化妝領域之間的確定性關係，而與精細的文字提示無關。然後，利用這種關係，引入一個基於 CLIP 的化妝損失以及一個整體攻擊策略，來共同引導對抗化妝領域的方向，實現產生具有自然外觀化妝和高黑盒傳輸率的受保護人臉影像。廣泛的實驗證明，與現有技術相比，DiffAM 在黑盒設定下獲得了更高的視覺品質和攻擊成功率，增益為 12.98%。程式碼將於 https://github.com/HansSunY/DiffAM 提供。

##### **Generative Unlearning for Any Identity**
2405.09879v1 by Juwon Seo, Sung-Hoon Lee, Tae-Young Lee, Seungjun Moon, Gyeong-Moon Park

Recent advances in generative models trained on large-scale datasets have
made it possible to synthesize high-quality samples across various domains.
Moreover, the emergence of strong inversion networks enables not only a
reconstruction of real-world images but also the modification of attributes
through various editing methods. However, in certain domains related to privacy
issues, e.g., human faces, advanced generative models along with strong
inversion methods can lead to potential misuses. In this paper, we propose an
essential yet under-explored task called generative identity unlearning, which
steers the model not to generate an image of a specific identity. In the
generative identity unlearning, we target the following objectives: (i)
preventing the generation of images with a certain identity, and (ii)
preserving the overall quality of the generative model. To satisfy these goals,
we propose a novel framework, Generative Unlearning for Any Identity (GUIDE),
which prevents the reconstruction of a specific identity by unlearning the
generator with only a single image. GUIDE consists of two parts: (i) finding a
target point for optimization that un-identifies the source latent code and
(ii) novel loss functions that facilitate the unlearning procedure while less
affecting the learned distribution. Our extensive experiments demonstrate that
our proposed method achieves state-of-the-art performance in the generative
machine unlearning task. The code is available at
https://github.com/KHU-AGI/GUIDE.

摘要：<paragraph>最近在大型資料集上訓練的生成式模型的進展，已讓各種領域的高品質樣本合成成為可能。此外，強大的反演網路的出現，不僅能重建真實世界的影像，還能透過各種編輯方法修改屬性。然而，在某些與隱私問題相關的領域，例如人臉，先進的生成式模型與強大的反演方法可能會導致潛在的誤用。在本文中，我們提出了一項基本但未充分探討的任務，稱為生成式身分去學習，它引導模型不要生成特定身分的影像。在生成式身分去學習中，我們針對以下目標：(i) 防止生成具有特定身分的影像，以及 (ii) 保留生成式模型的整體品質。為了滿足這些目標，我們提出了一個新的架構，適用於任何身分的生成式去學習 (GUIDE)，它透過僅使用單一影像去學習生成器，來防止重建特定身分。GUIDE 包含兩個部分：(i) 尋找最佳化的目標點，以取消識別來源潛在代碼，以及 (ii) 新穎的損失函數，在較少影響已學習分配的情況下，促進去學習程序。我們廣泛的實驗證明，我們提出的方法在生成式機器去學習任務中實現了最先進的效能。程式碼可在 https://github.com/KHU-AGI/GUIDE 取得。</paragraph>

##### **Risk Management for Medical Devices via the Riskman Ontology & Shapes**
2405.09875v1 by Piotr Gorczyca, Dörthe Arndt, Martin Diller, Pascal Kettmann, Stephan Mennicke, Hannes Strass

We introduce the Riskman ontology & shapes for representing and analysing
information about risk management for medical devices. Risk management is
concerned with taking necessary precautions so a medical device does not cause
harms for users or the environment. To date, risk management documentation is
submitted to notified bodies (for certification) in the form of semi-structured
natural language text. We propose to use classes from the Riskman ontology to
logically model risk management documentation and to use the included SHACL
constraints to check for syntactic completeness and conformity to relevant
standards. In particular, the ontology is modelled after ISO 14971 and the
recently published VDE Spec 90025. Our proposed methodology has the potential
to save many person-hours for both manufacturers (when creating risk management
documentation) as well as notified bodies (when assessing submitted
applications for certification), and thus offers considerable benefits for
healthcare and, by extension, society as a whole.

摘要：我們引入了 Riskman ontology 和形狀，用於表示和分析醫療器材風險管理的資訊。風險管理關注於採取必要的預防措施，讓醫療器材不會對使用者或環境造成傷害。迄今為止，風險管理文件是以半結構化的自然語言文字形式提交給公告機構（用於認證）。我們建議使用 Riskman ontology 中的類別來邏輯建模風險管理文件，並使用包含的 SHACL 約束來檢查語法完整性和是否符合相關標準。特別是，ontology 是根據 ISO 14971 和最近發布的 VDE Spec 90025 建模的。我們提出的方法有潛力為製造商（在建立風險管理文件時）和公告機構（在評估提交的認證申請時）節省大量的人力，因此為醫療保健和進一步推廣到整個社會帶來可觀的利益。

##### **Box-Free Model Watermarks Are Prone to Black-Box Removal Attacks**
2405.09863v1 by Haonan An, Guang Hua, Zhiping Lin, Yuguang Fang

Box-free model watermarking is an emerging technique to safeguard the
intellectual property of deep learning models, particularly those for low-level
image processing tasks. Existing works have verified and improved its
effectiveness in several aspects. However, in this paper, we reveal that
box-free model watermarking is prone to removal attacks, even under the
real-world threat model such that the protected model and the watermark
extractor are in black boxes. Under this setting, we carry out three studies.
1) We develop an extractor-gradient-guided (EGG) remover and show its
effectiveness when the extractor uses ReLU activation only. 2) More generally,
for an unknown extractor, we leverage adversarial attacks and design the EGG
remover based on the estimated gradients. 3) Under the most stringent condition
that the extractor is inaccessible, we design a transferable remover based on a
set of private proxy models. In all cases, the proposed removers can
successfully remove embedded watermarks while preserving the quality of the
processed images, and we also demonstrate that the EGG remover can even replace
the watermarks. Extensive experimental results verify the effectiveness and
generalizability of the proposed attacks, revealing the vulnerabilities of the
existing box-free methods and calling for further research.

摘要：無框模型浮水印是一種新興技術，用於保護深度學習模型的智慧財產權，特別是那些用於低階影像處理任務的模型。現有作品已經驗證並改進了它的有效性。然而，在本文中，我們揭示了無框模型浮水印容易受到移除攻擊，即使在受保護模型和浮水印提取器在黑盒子中的真實世界威脅模型下也是如此。在此設置下，我們進行了三項研究。1) 我們開發了一個提取器梯度引導 (EGG) 移除器，並展示了它在提取器僅使用 ReLU 激活時的有效性。2) 更一般地說，對於一個未知的提取器，我們利用對抗攻擊並根據估計的梯度設計 EGG 移除器。3) 在提取器無法訪問的最嚴格條件下，我們設計了一個基於一組私有代理模型的可轉移移除器。在所有情況下，所提出的移除器都可以成功移除嵌入的浮水印，同時保持處理影像的品質，我們還展示了 EGG 移除器甚至可以替換浮水印。廣泛的實驗結果驗證了所提出的攻擊的有效性和泛化性，揭示了現有無框方法的漏洞，並呼籲進一步研究。

##### **IGOT: Information Gain Optimized Tokenizer on Domain Adaptive Pretraining**
2405.09857v1 by Dawei Feng, Yihai Zhang, Zhixuan Xu

Pretrained Large Language Models (LLM) such as ChatGPT, Claude, etc. have
demonstrated strong capabilities in various fields of natural language
generation. However, there are still many problems when using LLM in
specialized domain-specific fields. When using generative AI to process
downstream tasks, a common approach is to add new knowledge (e.g., private
domain knowledge, cutting-edge information) to a pretrained model through
continued training or fine-tuning. However, whether there is a universal
paradigm for domain adaptation training is still an open question. In this
article, we proposed Information Gain Optimized Tokenizer (IGOT), which
analyzes the special token set of downstream tasks, constructs a new subset
using heuristic function $\phi$ with the special token and its information
gain, to build new domain-specific tokenizer, and continues pretraining on the
downstream task data. We explored the many positive effects of this method's
customized tokenizer on domain-adaptive pretraining and verified this method
can perform better than the ordinary method of just collecting data and
fine-tuning. Based on our experiment, the continued pretraining process of IGOT
with LLaMA-7B achieved 11.9\% token saving, 12.2\% training time saving, and
5.8\% maximum GPU VRAM usage saving, combined with the T5 model, we can even
reach a 31.5\% of training time saving, making porting general generative AI to
specific domains more effective than before. In domain-specific tasks,
supervised $IGOT_\tau$ shows great performance on reducing both the convergence
radius and convergence point during keep pretraining.

摘要：<paragraph>大型預訓練語言模型（LLM），例如 ChatGPT、Claude 等，已在自然語言生成的各個領域展現出強大的能力。然而，在特定領域中使用 LLM 時，仍存在許多問題。使用生成式 AI 處理下游任務時，一個常見的方法是透過持續訓練或微調，將新知識（例如私人領域知識、前沿資訊）新增到預訓練模型中。然而，是否有一個通用範例適用於領域適應訓練，仍是一個開放性的問題。在本文中，我們提出了資訊增益最佳化標記器 (IGOT)，它分析下游任務的特殊標記集，使用啟發式函數 $\phi$ 和特殊標記及其資訊增益建構一個新的子集，以建構新的特定領域標記器，並繼續在下游任務資料上進行預訓練。我們探討了這種方法的客製化標記器對領域適應預訓練的許多正面影響，並驗證此方法的表現優於僅收集資料和微調的傳統方法。根據我們的實驗，IGOT 與 LLaMA-7B 的持續預訓練過程節省了 11.9% 的標記、12.2% 的訓練時間，以及 5.8% 的最大 GPU VRAM 使用量，結合 T5 模型，我們甚至可以節省 31.5% 的訓練時間，使將通用生成式 AI 移植到特定領域比以前更有效。在特定領域任務中，監督式 $IGOT_\tau$ 在持續預訓練期間展現出極佳的效能，可減少收斂半徑和收斂點。</paragraph>

##### **On the relevance of pre-neural approaches in natural language processing pedagogy**
2405.09854v1 by Aditya Joshi, Jake Renzella, Pushpak Bhattacharyya, Saurav Jha, Xiangyu Zhang

While neural approaches using deep learning are the state-of-the-art for
natural language processing (NLP) today, pre-neural algorithms and approaches
still find a place in NLP textbooks and courses of recent years. In this paper,
we compare two introductory NLP courses taught in Australia and India, and
examine how Transformer and pre-neural approaches are balanced within the
lecture plan and assessments of the courses. We also draw parallels with the
objects-first and objects-later debate in CS1 education. We observe that
pre-neural approaches add value to student learning by building an intuitive
understanding of NLP problems, potential solutions and even Transformer-based
models themselves. Despite pre-neural approaches not being state-of-the-art,
the paper makes a case for their inclusion in NLP courses today.

摘要：雖然使用深度學習的神經方法是當今自然語言處理 (NLP) 的最先進技術，但前神經演算法和方法在近年來的 NLP 教科書和課程中仍佔有一席之地。在本文中，我們比較了在澳洲和印度教授的兩門 NLP 入門課程，並探討了 Transformer 和前神經方法如何在課程的講授計畫和評量中取得平衡。我們也與 CS1 教育中的物件優先和物件後辯論進行了比較。我們觀察到，前神經方法透過建立對 NLP 問題、潛在解決方案甚至基於 Transformer 的模型本身的直觀理解，為學生的學習增添了價值。儘管前神經方法並非最先進技術，但本文主張將它們納入當今的 NLP 課程中。

##### **Enhancing Semantics in Multimodal Chain of Thought via Soft Negative Sampling**
2405.09848v1 by Guangmin Zheng, Jin Wang, Xiaobing Zhou, Xuejie Zhang

Chain of thought (CoT) has proven useful for problems requiring complex
reasoning. Many of these problems are both textual and multimodal. Given the
inputs in different modalities, a model generates a rationale and then uses it
to answer a question. Because of the hallucination issue, the generated soft
negative rationales with high textual quality but illogical semantics do not
always help improve answer accuracy. This study proposes a rationale generation
method using soft negative sampling (SNSE-CoT) to mitigate hallucinations in
multimodal CoT. Five methods were applied to generate soft negative samples
that shared highly similar text but had different semantics from the original.
Bidirectional margin loss (BML) was applied to introduce them into the
traditional contrastive learning framework that involves only positive and
negative samples. Extensive experiments on the ScienceQA dataset demonstrated
the effectiveness of the proposed method. Code and data are released at
https://github.com/zgMin/SNSE-CoT.

摘要：思想鏈（CoT）已被證明對於需要複雜推理的問題很有用。其中許多問題既是文本性的，又是多模態的。給定不同模態的輸入，模型會生成一個基本原理，然後使用它來回答問題。由於幻覺問題，生成具有高文本品質但非邏輯語義的軟負基本原理並不總是能幫助提高答案準確性。本研究提出了一種使用軟負採樣（SNSE-CoT）的基本原理生成方法，以減輕多模態 CoT 中的幻覺。應用五種方法生成軟負樣本，這些樣本共享高度相似的文本，但與原始文本具有不同的語義。應用雙向邊際損失（BML）將它們引入傳統對比學習框架，該框架僅涉及正樣本和負樣本。在 ScienceQA 資料集上進行的廣泛實驗證明了所提出方法的有效性。程式碼和資料已發布在 https://github.com/zgMin/SNSE-CoT。

##### **Chameleon: Mixed-Modal Early-Fusion Foundation Models**
2405.09818v1 by Chameleon Team

We present Chameleon, a family of early-fusion token-based mixed-modal models
capable of understanding and generating images and text in any arbitrary
sequence. We outline a stable training approach from inception, an alignment
recipe, and an architectural parameterization tailored for the early-fusion,
token-based, mixed-modal setting. The models are evaluated on a comprehensive
range of tasks, including visual question answering, image captioning, text
generation, image generation, and long-form mixed modal generation. Chameleon
demonstrates broad and general capabilities, including state-of-the-art
performance in image captioning tasks, outperforms Llama-2 in text-only tasks
while being competitive with models such as Mixtral 8x7B and Gemini-Pro, and
performs non-trivial image generation, all in a single model. It also matches
or exceeds the performance of much larger models, including Gemini Pro and
GPT-4V, according to human judgments on a new long-form mixed-modal generation
evaluation, where either the prompt or outputs contain mixed sequences of both
images and text. Chameleon marks a significant step forward in a unified
modeling of full multimodal documents.

摘要：我們展示 Chameleon，一種早期融合的基於 token 的混合模式模型家族，
能夠理解和生成任意順序的圖像和文字。我們概述了從開始時的穩定訓練方法、對齊配方和專為早期融合、基於 token 的混合模式設置量身打造的架構參數化。這些模型在廣泛的任務上進行了評估，包括視覺問答、圖像標題、文字生成、圖像生成和長篇混合模式生成。Chameleon 展示了廣泛且通用的能力，包括在圖像標題任務中達到最先進的性能，在僅文字任務中優於 Llama-2，同時與 Mixtral 8x7B 和 Gemini-Pro 等模型競爭，並執行非平凡的圖像生成，所有這些都在一個模型中。根據人類對新的長篇混合模式生成評估的判斷，它也匹配或超過了更大的模型的性能，包括 Gemini Pro 和 GPT-4V，其中提示或輸出包含圖像和文字的混合序列。Chameleon 標誌著在統一建模完整的多模態文件中邁出了重要一步。

##### **MediSyn: Text-Guided Diffusion Models for Broad Medical 2D and 3D Image Synthesis**
2405.09806v1 by Joseph Cho, Cyril Zakka, Rohan Shad, Ross Wightman, Akshay Chaudhari, William Hiesinger

Diffusion models have recently gained significant traction due to their
ability to generate high-fidelity and diverse images and videos conditioned on
text prompts. In medicine, this application promises to address the critical
challenge of data scarcity, a consequence of barriers in data sharing,
stringent patient privacy regulations, and disparities in patient population
and demographics. By generating realistic and varying medical 2D and 3D images,
these models offer a rich, privacy-respecting resource for algorithmic training
and research. To this end, we introduce MediSyn, a pair of instruction-tuned
text-guided latent diffusion models with the ability to generate high-fidelity
and diverse medical 2D and 3D images across specialties and modalities. Through
established metrics, we show significant improvement in broad medical image and
video synthesis guided by text prompts.

摘要：擴散模型最近獲得顯著的關注，因為它們能夠根據文字提示產生高保真且多樣的圖像和影片。在醫學中，此應用程式承諾解決資料稀少性的重大挑戰，這是由於資料共用、嚴格的患者隱私法規以及患者族群和人口統計資料的差異所造成的後果。透過產生逼真且多變的醫學 2D 和 3D 圖像，這些模型提供了豐富且尊重隱私的資源，可用於演算法訓練和研究。為此，我們引入了 MediSyn，這是一種成對的指令調整文字引導潛在擴散模型，能夠跨專業和方式產生高保真且多樣的醫學 2D 和 3D 圖像。透過既定的指標，我們展示了在文字提示引導下，廣泛的醫學影像和影片合成有了顯著的進步。

##### **SecureLLM: Using Compositionality to Build Provably Secure Language Models for Private, Sensitive, and Secret Data**
2405.09805v1 by Abdulrahman Alabdulakreem, Christian M Arnold, Yerim Lee, Pieter M Feenstra, Boris Katz, Andrei Barbu

Traditional security mechanisms isolate resources from users who should not
access them. We reflect the compositional nature of such security mechanisms
back into the structure of LLMs to build a provably secure LLM; that we term
SecureLLM. Other approaches to LLM safety attempt to protect against bad actors
or bad outcomes, but can only do so to an extent making them inappropriate for
sensitive data. SecureLLM blends access security with fine-tuning methods. Each
data silo has associated with it a separate fine-tuning and a user has access
only to the collection of fine-tunings that they have permission for. The model
must then perform on compositional tasks at the intersection of those data
silos with the combination of those individual fine-tunings. While applicable
to any task like document QA or making API calls, in this work we concern
ourselves with models that learn the layouts of new SQL databases to provide
natural-language-to-SQL translation capabilities. Existing fine-tuning
composition methods fail in this challenging environment, as they are not
well-equipped for handling compositional tasks. Compositionality remains a
challenge for LLMs. We contribute both a difficult new compositional
natural-language-to-SQL translation task and a new perspective on LLM security
that allows models to be deployed to secure environments today.

摘要：傳統的安全機制將資源與不應存取資源的使用者隔離。我們將此類安全機制的組合性質反映回 LLM 的結構，以建構一個可證明安全的 LLM；我們稱之為 SecureLLM。其他 LLM 安全方法嘗試防範不良行為者或不良結果，但只能做到一定程度，這使得它們不適合處理敏感資料。SecureLLM 將存取安全與微調方法結合在一起。每個資料筒倉都與一個單獨的微調相關聯，而使用者只能存取他們有權限的微調集合。然後，模型必須在那些資料筒倉的交集處執行組合任務，並結合那些個別的微調。雖然適用於任何任務，例如文件問答或執行 API 呼叫，但在這項工作中，我們關注的是學習新 SQL 資料庫的佈局以提供自然語言轉換為 SQL 的翻譯功能的模型。現有的微調組合方法無法在此具有挑戰性的環境中成功，因為它們不適合處理組合任務。組合性仍然是 LLM 的一項挑戰。我們貢獻了一個困難的新組合自然語言轉換為 SQL 的翻譯任務，以及一個關於 LLM 安全性的新觀點，允許模型部署到當今的安全環境中。

##### **Analysis and Predictive Modeling of Solar Coronal Holes Using Computer Vision and LSTM Networks**
2405.09802v1 by Juyoung Yun, Jungmin Shin

In the era of space exploration, coronal holes on the sun play a significant
role due to their impact on satellites and aircraft through their open magnetic
fields and increased solar wind emissions. This study employs computer vision
techniques to detect coronal hole regions and estimate their sizes using
imagery from the Solar Dynamics Observatory (SDO). Additionally, we utilize
deep learning methods, specifically Long Short-Term Memory (LSTM) networks, to
analyze trends in the area of coronal holes and predict their areas across
various solar regions over a span of seven days. By examining time series data,
we aim to identify patterns in coronal hole behavior and understand their
potential effects on space weather. This research enhances our ability to
anticipate and prepare for space weather events that could affect Earth's
technological systems.

摘要：在太空探索的時代中，太陽上的冕洞因為其開放的磁場和增加的太陽風排放而對衛星和飛機產生影響，因此扮演著重要的角色。這項研究採用電腦視覺技術，使用太陽動力學天文台 (SDO) 的影像來偵測冕洞區域並估計其大小。此外，我們利用深度學習方法，特別是長短期記憶 (LSTM) 網路，來分析冕洞區域的趨勢，並預測它們在七天內於各種太陽區域中的面積。透過檢查時間序列資料，我們旨在找出冕洞行為的模式，並了解它們對太空天氣的潛在影響。這項研究增強了我們預測和準備太空天氣事件的能力，這些事件可能影響地球的科技系統。

##### **Many-Shot In-Context Learning in Multimodal Foundation Models**
2405.09798v1 by Yixing Jiang, Jeremy Irvin, Ji Hun Wang, Muhammad Ahmed Chaudhry, Jonathan H. Chen, Andrew Y. Ng

Large language models are well-known to be effective at few-shot in-context
learning (ICL). Recent advancements in multimodal foundation models have
enabled unprecedentedly long context windows, presenting an opportunity to
explore their capability to perform ICL with many more demonstrating examples.
In this work, we evaluate the performance of multimodal foundation models
scaling from few-shot to many-shot ICL. We benchmark GPT-4o and Gemini 1.5 Pro
across 10 datasets spanning multiple domains (natural imagery, medical imagery,
remote sensing, and molecular imagery) and tasks (multi-class, multi-label, and
fine-grained classification). We observe that many-shot ICL, including up to
almost 2,000 multimodal demonstrating examples, leads to substantial
improvements compared to few-shot (<100 examples) ICL across all of the
datasets. Further, Gemini 1.5 Pro performance continues to improve log-linearly
up to the maximum number of tested examples on many datasets. Given the high
inference costs associated with the long prompts required for many-shot ICL, we
also explore the impact of batching multiple queries in a single API call. We
show that batching up to 50 queries can lead to performance improvements under
zero-shot and many-shot ICL, with substantial gains in the zero-shot setting on
multiple datasets, while drastically reducing per-query cost and latency.
Finally, we measure ICL data efficiency of the models, or the rate at which the
models learn from more demonstrating examples. We find that while GPT-4o and
Gemini 1.5 Pro achieve similar zero-shot performance across the datasets,
Gemini 1.5 Pro exhibits higher ICL data efficiency than GPT-4o on most
datasets. Our results suggest that many-shot ICL could enable users to
efficiently adapt multimodal foundation models to new applications and domains.
Our codebase is publicly available at
https://github.com/stanfordmlgroup/ManyICL .

摘要：<paragraph>大型語言模型以在少量範例的語境學習 (ICL) 中有效著稱。多模態基礎模型的最新進展使得前所未有的長語境窗口成為可能，提供了一個機會來探索它們在更多示範範例下執行 ICL 的能力。在這項工作中，我們評估了從少量範例到大量範例 ICL 的多模態基礎模型的效能。我們在跨越多個領域（自然影像、醫學影像、遙測和分子影像）和任務（多類別、多標籤和細粒度分類）的 10 個資料集上對 GPT-4o 和 Gemini 1.5 Pro 進行了基準測試。我們觀察到，大量範例 ICL，包括多達近 2,000 個多模態示範範例，與所有資料集中的少量範例 (<100 個範例) ICL 相比，帶來了顯著的改進。此外，Gemini 1.5 Pro 的效能持續在許多資料集上隨著測試範例的最大數量對數線性地提升。鑑於大量範例 ICL 所需的長提示相關的高推論成本，我們也探討了在單一 API 呼叫中批次處理多個查詢的影響。我們展示了批次處理多達 50 個查詢可以在零範例和大量範例 ICL 下導致效能提升，在多個資料集上的零範例設定中獲得顯著的收益，同時大幅降低每個查詢的成本和延遲。最後，我們測量了模型的 ICL 資料效率，或模型從更多示範範例中學習的速率。我們發現，雖然 GPT-4o 和 Gemini 1.5 Pro 在各個資料集上都達到了類似的零範例效能，但 Gemini 1.5 Pro 在大多數資料集上展現出比 GPT-4o 更高的 ICL 資料效率。我們的結果表明，大量範例 ICL 可以讓使用者有效地將多模態基礎模型調整到新的應用程式和領域。我們的程式碼庫已公開於 https://github.com/stanfordmlgroup/ManyICL。</paragraph>

##### **Human-AI Safety: A Descendant of Generative AI and Control Systems Safety**
2405.09794v1 by Andrea Bajcsy, Jaime F. Fisac

Generative artificial intelligence (AI) is interacting with people at an
unprecedented scale, offering new avenues for immense positive impact, but also
raising widespread concerns around the potential for individual and societal
harm. Today, the predominant paradigm for human-AI safety focuses on
fine-tuning the generative model's outputs to better agree with human-provided
examples or feedback. In reality, however, the consequences of an AI model's
outputs cannot be determined in an isolated context: they are tightly entangled
with the responses and behavior of human users over time. In this position
paper, we argue that meaningful safety assurances for these AI technologies can
only be achieved by reasoning about how the feedback loop formed by the AI's
outputs and human behavior may drive the interaction towards different
outcomes. To this end, we envision a high-value window of opportunity to bridge
the rapidly growing capabilities of generative AI and the dynamical safety
frameworks from control theory, laying a new foundation for human-centered AI
safety in the coming decades.

摘要：生成式人工智慧 (AI) 正以前所未有的規模與人類互動，為帶來巨大正面影響提供了新途徑，但也對個人和社會潛在危害引發了廣泛的擔憂。當今，人類與人工智慧安全的主要模式著重於微調生成模型的輸出，以更好地符合人類提供的範例或回饋。然而，在現實中，人工智慧模型輸出的後果無法在孤立的環境中確定：它們與人類使用者的回應和行為緊密交織。在本文中，我們認為對這些人工智慧技術有意義的安全保證只能透過推理人工智慧輸出和人類行為形成的回饋迴路如何驅動互動走向不同的結果來實現。為此，我們預見了一個高價值的機會之窗，可以彌合生成式人工智慧快速增長的機能和控制理論中的動態安全架構，為未來數十年以人類為中心的人工智慧安全奠定新的基礎。

##### **Online bipartite matching with imperfect advice**
2405.09784v1 by Davin Choo, Themis Gouleakis, Chun Kai Ling, Arnab Bhattacharyya

We study the problem of online unweighted bipartite matching with $n$ offline
vertices and $n$ online vertices where one wishes to be competitive against the
optimal offline algorithm. While the classic RANKING algorithm of Karp et al.
[1990] provably attains competitive ratio of $1-1/e > 1/2$, we show that no
learning-augmented method can be both 1-consistent and strictly better than
$1/2$-robust under the adversarial arrival model. Meanwhile, under the random
arrival model, we show how one can utilize methods from distribution testing to
design an algorithm that takes in external advice about the online vertices and
provably achieves competitive ratio interpolating between any ratio attainable
by advice-free methods and the optimal ratio of 1, depending on the advice
quality.

摘要：我們研究具有 $n$ 個離線頂點和 $n$ 個線上頂點的線上非加權二部匹配問題，在該問題中，我們希望與最佳離線演算法競爭。雖然 Karp 等人的經典 RANKING 演算法 [1990] 可證明地達到 $1-1/e > 1/2$ 的競爭比率，但我們表明，在對抗性到達模型下，沒有任何學習增強方法既可以 1-一致，又可以嚴格優於 $1/2$-穩健。同時，在隨機到達模型下，我們展示了如何利用分佈測試中的方法來設計一種演算法，它會採用有關線上頂點的外部建議，並可證明地實現競爭比率，在任何無建議方法可達到的比率和最佳比率 1 之間插值，具體取決於建議品質。

##### **LLM and Simulation as Bilevel Optimizers: A New Paradigm to Advance Physical Scientific Discovery**
2405.09783v1 by Pingchuan Ma, Tsun-Hsuan Wang, Minghao Guo, Zhiqing Sun, Joshua B. Tenenbaum, Daniela Rus, Chuang Gan, Wojciech Matusik

Large Language Models have recently gained significant attention in
scientific discovery for their extensive knowledge and advanced reasoning
capabilities. However, they encounter challenges in effectively simulating
observational feedback and grounding it with language to propel advancements in
physical scientific discovery. Conversely, human scientists undertake
scientific discovery by formulating hypotheses, conducting experiments, and
revising theories through observational analysis. Inspired by this, we propose
to enhance the knowledge-driven, abstract reasoning abilities of LLMs with the
computational strength of simulations. We introduce Scientific Generative Agent
(SGA), a bilevel optimization framework: LLMs act as knowledgeable and
versatile thinkers, proposing scientific hypotheses and reason about discrete
components, such as physics equations or molecule structures; meanwhile,
simulations function as experimental platforms, providing observational
feedback and optimizing via differentiability for continuous parts, such as
physical parameters. We conduct extensive experiments to demonstrate our
framework's efficacy in constitutive law discovery and molecular design,
unveiling novel solutions that differ from conventional human expectations yet
remain coherent upon analysis.

摘要：大型语言模型因其广泛的知识和先进的推理能力在科学发现中最近获得了极大的关注。然而，它们在有效模拟观测反馈并将其与语言联系起来以推动物理科学发现的进步方面遇到了挑战。相反，人类科学家通过制定假设、进行实验和通过观测分析修改理论来进行科学发现。受此启发，我们提议利用模拟的计算能力来增强 LLM 的知识驱动、抽象推理能力。我们引入了科学生成代理 (SGA)，这是一个双层优化框架：LLM 充当知识渊博且多才多艺的思想家，提出科学假设并推理离散组件，例如物理方程或分子结构；同时，模拟充当实验平台，提供观测反馈并通过可微性优化连续部分，例如物理参数。我们进行了广泛的实验来证明我们框架在本构律发现和分子设计中的功效，揭示了与传统人类预期不同的新颖解决方案，但在分析后仍然保持连贯性。

##### **Optimization Techniques for Sentiment Analysis Based on LLM (GPT-3)**
2405.09770v1 by Tong Zhan, Chenxi Shi, Yadong Shi, Huixiang Li, Yiyu Lin

With the rapid development of natural language processing (NLP) technology,
large-scale pre-trained language models such as GPT-3 have become a popular
research object in NLP field. This paper aims to explore sentiment analysis
optimization techniques based on large pre-trained language models such as
GPT-3 to improve model performance and effect and further promote the
development of natural language processing (NLP). By introducing the importance
of sentiment analysis and the limitations of traditional methods, GPT-3 and
Fine-tuning techniques are introduced in this paper, and their applications in
sentiment analysis are explained in detail. The experimental results show that
the Fine-tuning technique can optimize GPT-3 model and obtain good performance
in sentiment analysis task. This study provides an important reference for
future sentiment analysis using large-scale language models.

摘要：隨著自然語言處理（NLP）技術的快速發展，
GPT-3 等大規模預訓練語言模型已成為 NLP 領域中熱門的研究對象。本文旨在探討基於 GPT-3 等大型預訓練語言模型的情感分析優化技術，以提升模型效能和效果，進一步促進自然語言處理（NLP）的發展。本文透過介紹情感分析的重要性及傳統方法的限制，進一步介紹 GPT-3 與 Fine-tuning 技術，並詳細說明其在情感分析中的應用。實驗結果顯示，Fine-tuning 技術能優化 GPT-3 模型，並在情感分析任務中獲得良好的表現。本研究為未來利用大型語言模型進行情感分析提供重要的參考依據。

##### **Many Hands Make Light Work: Task-Oriented Dialogue System with Module-Based Mixture-of-Experts**
2405.09744v1 by Ruolin Su, Biing-Hwang Juang

Task-oriented dialogue systems are broadly used in virtual assistants and
other automated services, providing interfaces between users and machines to
facilitate specific tasks. Nowadays, task-oriented dialogue systems have
greatly benefited from pre-trained language models (PLMs). However, their
task-solving performance is constrained by the inherent capacities of PLMs, and
scaling these models is expensive and complex as the model size becomes larger.
To address these challenges, we propose Soft Mixture-of-Expert Task-Oriented
Dialogue system (SMETOD) which leverages an ensemble of Mixture-of-Experts
(MoEs) to excel at subproblems and generate specialized outputs for
task-oriented dialogues. SMETOD also scales up a task-oriented dialogue system
with simplicity and flexibility while maintaining inference efficiency. We
extensively evaluate our model on three benchmark functionalities: intent
prediction, dialogue state tracking, and dialogue response generation.
Experimental results demonstrate that SMETOD achieves state-of-the-art
performance on most evaluated metrics. Moreover, comparisons against existing
strong baselines show that SMETOD has a great advantage in the cost of
inference and correctness in problem-solving.

摘要：任務導向對話系統廣泛用於虛擬助理和其他自動化服務中，提供使用者與機器之間的介面，以利特定任務的進行。如今，任務導向對話系統已從預先訓練的語言模型 (PLM) 中受益良多。然而，它們的任務解決效能受到 PLM 內建容量的限制，而且隨著模型規模變大，擴充這些模型的成本高昂且複雜。為了應對這些挑戰，我們提出 Soft Mixture-of-Expert 任務導向對話系統 (SMETOD)，它利用 Mixture-of-Experts (MoE) 的合奏在子問題中表現出色，並為任務導向對話產生專業輸出。SMETOD 也能以簡單且彈性的方式擴充任務導向對話系統，同時維持推論效率。我們廣泛評估我們的模型在三個基準功能性：意圖預測、對話狀態追蹤和對話回應產生。實驗結果顯示，SMETOD 在大多數評估指標上都達到最先進的效能。此外，與現有強大的基準比較，SMETOD 在推論成本和問題解決的正確性方面有很大的優勢。

##### **SCI 3.0: A Web-based Schema Curation Interface for Graphical Event Representations**
2405.09733v1 by Reece Suchocki, Mary Martin, Martha Palmer, Susan Brown

To understand the complexity of global events, one must navigate a web of
interwoven sub-events, identifying those most impactful elements within the
larger, abstract macro-event framework at play. This concept can be extended to
the field of natural language processing (NLP) % original: by defining abstract
event representations as structured event schemas. through the creation of
structured event schemas which can serve as representations of these abstract
events. Central to our approach is the Schema Curation Interface 3.0 (SCI 3.0),
a web application that facilitates real-time editing of event schema properties
within a generated graph e.g., adding, removing, or editing sub-events,
entities, and relations directly through an interface.

摘要：要了解全球事件的复杂性，必须浏览交织的子事件网络，找出在更大的抽象宏观事件框架中影响最大的元素。这个概念可以扩展到自然语言处理 (NLP) 领域，方法是将抽象事件表述定义为结构化事件模式。通过创建结构化事件模式，可以作为这些抽象事件的表述。我们方法的核心是模式整理界面 3.0 (SCI 3.0)，这是一个 Web 应用程序，可通过生成的图形实时编辑事件模式属性，例如，直接通过界面添加、移除或编辑子事件、实体和关系。

##### **Spectral Editing of Activations for Large Language Model Alignment**
2405.09719v1 by Yifu Qiu, Zheng Zhao, Yftah Ziser, Anna Korhonen, Edoardo M. Ponti, Shay B. Cohen

Large language models (LLMs) often exhibit undesirable behaviours, such as
generating untruthful or biased content. Editing their internal representations
has been shown to be effective in mitigating such behaviours on top of the
existing alignment methods. We propose a novel inference-time editing method,
namely spectral editing of activations (SEA), to project the input
representations into directions with maximal covariance with the positive
demonstrations (e.g., truthful) while minimising covariance with the negative
demonstrations (e.g., hallucinated). We also extend our method to non-linear
editing using feature functions. We run extensive experiments on benchmarks
concerning truthfulness and bias with six open-source LLMs of different sizes
and model families. The results demonstrate the superiority of SEA in
effectiveness, generalisation to similar tasks, as well as inference and data
efficiency. We also show that SEA editing only has a limited negative impact on
other model capabilities.

摘要：大型語言模型（LLM）通常會表現出不良行為，例如產生不真實或有偏差的內容。編輯其內部表示已被證明可以有效減輕這些行為，並建立在現有對齊方法之上。我們提出了一種新穎的推理時間編輯方法，即激活光譜編輯（SEA），將輸入表示投影到與正向示範（例如真實）最大協方差的方向，同時最小化與負向示範（例如幻覺）的協方差。我們還將我們的非線性編輯方法擴展到使用特徵函數。我們對六個不同大小和模型系列的開源 LLM 進行了關於真實性和偏見的基準廣泛實驗。結果證明了 SEA 在有效性、對類似任務的概括性以及推理和數據效率方面的優越性。我們還表明，SEA 編輯對其他模型功能的負面影響很小。

##### **SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge**
2405.09713v1 by Andong Wang, Bo Wu, Sunli Chen, Zhenfang Chen, Haotian Guan, Wei-Ning Lee, Li Erran Li, Joshua B Tenenbaum, Chuang Gan

Learning commonsense reasoning from visual contexts and scenes in real-world
is a crucial step toward advanced artificial intelligence. However, existing
video reasoning benchmarks are still inadequate since they were mainly designed
for factual or situated reasoning and rarely involve broader knowledge in the
real world. Our work aims to delve deeper into reasoning evaluations,
specifically within dynamic, open-world, and structured context knowledge. We
propose a new benchmark (SOK-Bench), consisting of 44K questions and 10K
situations with instance-level annotations depicted in the videos. The
reasoning process is required to understand and apply situated knowledge and
general knowledge for problem-solving. To create such a dataset, we propose an
automatic and scalable generation method to generate question-answer pairs,
knowledge graphs, and rationales by instructing the combinations of LLMs and
MLLMs. Concretely, we first extract observable situated entities, relations,
and processes from videos for situated knowledge and then extend to open-world
knowledge beyond the visible content. The task generation is facilitated
through multiple dialogues as iterations and subsequently corrected and refined
by our designed self-promptings and demonstrations. With a corpus of both
explicit situated facts and implicit commonsense, we generate associated
question-answer pairs and reasoning processes, finally followed by manual
reviews for quality assurance. We evaluated recent mainstream large
vision-language models on the benchmark and found several insightful
conclusions. For more information, please refer to our benchmark at
www.bobbywu.com/SOKBench.

摘要：從真實世界的視覺脈絡和場景中學習常識推理是邁向先進人工智慧的關鍵一步。然而，現有的影片推理基準仍不充足，因為它們主要設計用於事實或情境推理，而且很少涉及現實世界中的廣泛知識。我們的研究旨在深入探討推理評估，特別是在動態、開放世界和結構化脈絡知識中。我們提出一個新的基準 (SOK-Bench)，包含 44K 個問題和 10K 個情況，並在影片中以實例層級註解呈現。推理過程需要理解並應用情境知識和一般知識來解決問題。為了建立這樣的資料集，我們提出一個自動且可擴充的產生方法，透過指導 LLM 和 MLLM 的組合來產生問答對、知識圖譜和依據。具體來說，我們首先從影片中萃取可觀察的情境實體、關係和過程，以取得情境知識，然後擴展到可見內容之外的開放世界知識。任務產生透過多重對話作為反覆運算進行，隨後由我們設計的自提示和示範進行修正和改善。透過包含明確情境事實和隱含常識的語料庫，我們產生相關的問答對和推理過程，最後進行人工審查以確保品質。我們在基準上評估了近期主流的大型視覺語言模型，並發現了幾個有見地的結論。如需更多資訊，請參閱我們的基準：www.bobbywu.com/SOKBench。

##### **STAR: A Benchmark for Situated Reasoning in Real-World Videos**
2405.09711v1 by Bo Wu, Shoubin Yu, Zhenfang Chen, Joshua B Tenenbaum, Chuang Gan

Reasoning in the real world is not divorced from situations. How to capture
the present knowledge from surrounding situations and perform reasoning
accordingly is crucial and challenging for machine intelligence. This paper
introduces a new benchmark that evaluates the situated reasoning ability via
situation abstraction and logic-grounded question answering for real-world
videos, called Situated Reasoning in Real-World Videos (STAR Benchmark). This
benchmark is built upon the real-world videos associated with human actions or
interactions, which are naturally dynamic, compositional, and logical. The
dataset includes four types of questions, including interaction, sequence,
prediction, and feasibility. We represent the situations in real-world videos
by hyper-graphs connecting extracted atomic entities and relations (e.g.,
actions, persons, objects, and relationships). Besides visual perception,
situated reasoning also requires structured situation comprehension and logical
reasoning. Questions and answers are procedurally generated. The answering
logic of each question is represented by a functional program based on a
situation hyper-graph. We compare various existing video reasoning models and
find that they all struggle on this challenging situated reasoning task. We
further propose a diagnostic neuro-symbolic model that can disentangle visual
perception, situation abstraction, language understanding, and functional
reasoning to understand the challenges of this benchmark.

摘要：現實世界中的推理並非脫離情境。如何從周遭情境中擷取當前知識並據此進行推理，對機器智能而言至關重要且具有挑戰性。本文介紹了一個新的基準，透過情境抽象和以邏輯為基礎的問答，評估真實世界影片中的情境推理能力，稱為真實世界影片中的情境推理（STAR基準）。此基準建立於與人類動作或互動相關的真實世界影片之上，這些影片本質上是動態、組合且合乎邏輯的。該資料集包含四種類型的問題，包括互動、順序、預測和可行性。我們透過連接提取的原子實體和關係（例如動作、人物、物件和關係）的超圖形，來表示真實世界影片中的情境。除了視覺感知之外，情境推理還需要結構化的情境理解和邏輯推理。問題和答案是程序化產生的。每個問題的回答邏輯由基於情境超圖形的函式程式表示。我們比較了現有的各種影片推理模型，發現它們在這個具有挑戰性的情境推理任務中都表現不佳。我們進一步提出了一個診斷性神經符號模型，它可以解開視覺感知、情境抽象、語言理解和函式推理，以了解此基準的挑戰。

##### **No More Mumbles: Enhancing Robot Intelligibility through Speech Adaptation**
2405.09708v1 by Qiaoqiao Ren, Yuanbo Hou, Dick Botteldooren, Tony Belpaeme

Spoken language interaction is at the heart of interpersonal communication,
and people flexibly adapt their speech to different individuals and
environments. It is surprising that robots, and by extension other digital
devices, are not equipped to adapt their speech and instead rely on fixed
speech parameters, which often hinder comprehension by the user. We conducted a
speech comprehension study involving 39 participants who were exposed to
different environmental and contextual conditions. During the experiment, the
robot articulated words using different vocal parameters, and the participants
were tasked with both recognising the spoken words and rating their subjective
impression of the robot's speech. The experiment's primary outcome shows that
spaces with good acoustic quality positively correlate with intelligibility and
user experience. However, increasing the distance between the user and the
robot exacerbated the user experience, while distracting background sounds
significantly reduced speech recognition accuracy and user satisfaction. We
next built an adaptive voice for the robot. For this, the robot needs to know
how difficult it is for a user to understand spoken language in a particular
setting. We present a prediction model that rates how annoying the ambient
acoustic environment is and, consequentially, how hard it is to understand
someone in this setting. Then, we develop a convolutional neural network model
to adapt the robot's speech parameters to different users and spaces, while
taking into account the influence of ambient acoustics on intelligibility.
Finally, we present an evaluation with 27 users, demonstrating superior
intelligibility and user experience with adaptive voice parameters compared to
fixed voice.

摘要：<paragraph>口語互動是人際溝通的核心，
人們會靈活地調整自己的言論以適應不同的人和
環境。令人驚訝的是，機器人，以及其他數位
裝置，並未具備調整其言論的能力，反而依賴固定的
語音參數，這通常會阻礙使用者的理解。我們進行了一項
語音理解研究，涉及 39 位參與者，他們暴露在
不同的環境和情境條件下。在實驗期間，機器人
使用不同的語音參數來表達詞彙，而參與者
被要求辨識所說的詞彙並評分他們對機器人語音的主觀
印象。實驗的主要結果顯示，具有良好音響品質的空間
與清晰度和使用者體驗呈正相關。然而，增加使用者與
機器人之間的距離會惡化使用者體驗，而分散注意力的背景
聲音會顯著降低語音辨識準確度和使用者滿意度。接下來
我們為機器人建立了一個自適應的語音。為此，機器人需要知道
使用者在特定設定中理解口語有多困難。我們提出一個預測模型，評分環境
的聲學環境有多惱人，以及因此在這個設定中理解某人有多困難。然後，我們開發一個卷積神經網路模型
來調整機器人的語音參數以適應不同的使用者和空間，同時
考量環境聲學對清晰度的影響。最後，我們提出一個包含 27 位使用者的評估，展示出與固定語音相比，自適應語音參數具有優異的
清晰度和使用者體驗。</paragraph>

##### **Modeling User Preferences via Brain-Computer Interfacing**
2405.09691v1 by Luis A. Leiva, Javier Ttraver, Alexandra Kawala-Sterniuk, Tuukka Ruotsalo

Present Brain-Computer Interfacing (BCI) technology allows inference and
detection of cognitive and affective states, but fairly little has been done to
study scenarios in which such information can facilitate new applications that
rely on modeling human cognition. One state that can be quantified from various
physiological signals is attention. Estimates of human attention can be used to
reveal preferences and novel dimensions of user experience. Previous approaches
have tackled these incredibly challenging tasks using a variety of behavioral
signals, from dwell-time to click-through data, and computational models of
visual correspondence to these behavioral signals. However, behavioral signals
are only rough estimations of the real underlying attention and affective
preferences of the users. Indeed, users may attend to some content simply
because it is salient, but not because it is really interesting, or simply
because it is outrageous. With this paper, we put forward a research agenda and
example work using BCI to infer users' preferences, their attentional
correlates towards visual content, and their associations with affective
experience. Subsequently, we link these to relevant applications, such as
information retrieval, personalized steering of generative models, and
crowdsourcing population estimates of affective experiences.

摘要：目前的腦機介面 (BCI) 技術可推論和偵測認知和情感狀態，但鮮少研究此類資訊如何促進仰賴人類認知建模的新應用。一種可從各種生理訊號量化的狀態是注意力。可利用人類注意力的估計值，揭露使用者的偏好和使用者體驗的新面向。先前的做法使用各種行為訊號來處理這些極具挑戰性的任務，從停留時間到點閱資料，以及這些行為訊號的視覺對應運算模型。然而，行為訊號僅為使用者真實潛在注意力和情感偏好的粗略估計。事實上，使用者可能只會注意某些內容，僅是因為它們顯著，而非因為它們真的有趣，或僅是因為它們令人髮指。在本文中，我們提出一個研究議程和範例工作，使用 BCI 推論使用者的偏好、他們對視覺內容的注意力相關性，以及他們與情感體驗的關聯性。隨後，我們將這些連結到相關應用程式，例如資訊檢索、生成模型的個人化導引，以及眾包情感體驗的族群估計。

##### **Simulating Policy Impacts: Developing a Generative Scenario Writing Method to Evaluate the Perceived Effects of Regulation**
2405.09679v1 by Julia Barnett, Kimon Kieslich, Nicholas Diakopoulos

The rapid advancement of AI technologies yields numerous future impacts on
individuals and society. Policy-makers are therefore tasked to react quickly
and establish policies that mitigate those impacts. However, anticipating the
effectiveness of policies is a difficult task, as some impacts might only be
observable in the future and respective policies might not be applicable to the
future development of AI. In this work we develop a method for using large
language models (LLMs) to evaluate the efficacy of a given piece of policy at
mitigating specified negative impacts. We do so by using GPT-4 to generate
scenarios both pre- and post-introduction of policy and translating these vivid
stories into metrics based on human perceptions of impacts. We leverage an
already established taxonomy of impacts of generative AI in the media
environment to generate a set of scenario pairs both mitigated and
non-mitigated by the transparency legislation of Article 50 of the EU AI Act.
We then run a user study (n=234) to evaluate these scenarios across four
risk-assessment dimensions: severity, plausibility, magnitude, and specificity
to vulnerable populations. We find that this transparency legislation is
perceived to be effective at mitigating harms in areas such as labor and
well-being, but largely ineffective in areas such as social cohesion and
security. Through this case study on generative AI harms we demonstrate the
efficacy of our method as a tool to iterate on the effectiveness of policy on
mitigating various negative impacts. We expect this method to be useful to
researchers or other stakeholders who want to brainstorm the potential utility
of different pieces of policy or other mitigation strategies.

摘要：人工智慧技術的快速發展對個人和社會產生了許多未來的影響。因此，政策制定者必須迅速做出反應並制定政策來減輕這些影響。然而，預測政策的有效性是一項艱鉅的任務，因為有些影響可能只有在未來才能觀察到，而相關政策可能不適用於人工智慧的未來發展。在這項工作中，我們開發了一種使用大型語言模型 (LLM) 來評估特定政策在減輕特定負面影響方面的效力的方法。我們這樣做的方法是使用 GPT-4 在政策提出前後產生場景，並將這些生動的故事轉換為基於人類影響感知的指標。我們利用媒體環境中生成式人工智慧影響的既定分類法，產生了一組由歐盟人工智慧法案第 50 條的透明度立法減輕和未減輕的場景對。然後，我們進行了一項使用者研究 (n=234) 來評估這些場景在四個風險評估面向：嚴重性、可能性、規模和對弱勢群體的特殊性。我們發現，這項透明度立法被認為可以有效減輕勞工和福祉等領域的危害，但在社會凝聚力和安全等領域卻幾乎沒有效果。透過這個關於生成式人工智慧危害的案例研究，我們證明了我們的方法作為一種工具的有效性，可以反覆探討政策在減輕各種負面影響方面的有效性。我們預計這種方法對希望集思廣益討論不同政策或其他緩解策略的潛在效用的研究人員或其他利害關係人會很有用。

##### **LoRA Learns Less and Forgets Less**
2405.09673v1 by Dan Biderman, Jose Gonzalez Ortiz, Jacob Portes, Mansheej Paul, Philip Greengard, Connor Jennings, Daniel King, Sam Havens, Vitaliy Chiley, Jonathan Frankle, Cody Blakeney, John P. Cunningham

Low-Rank Adaptation (LoRA) is a widely-used parameter-efficient finetuning
method for large language models. LoRA saves memory by training only low rank
perturbations to selected weight matrices. In this work, we compare the
performance of LoRA and full finetuning on two target domains, programming and
mathematics. We consider both the instruction finetuning ($\approx$100K
prompt-response pairs) and continued pretraining ($\approx$10B unstructured
tokens) data regimes. Our results show that, in most settings, LoRA
substantially underperforms full finetuning. Nevertheless, LoRA exhibits a
desirable form of regularization: it better maintains the base model's
performance on tasks outside the target domain. We show that LoRA provides
stronger regularization compared to common techniques such as weight decay and
dropout; it also helps maintain more diverse generations. We show that full
finetuning learns perturbations with a rank that is 10-100X greater than
typical LoRA configurations, possibly explaining some of the reported gaps. We
conclude by proposing best practices for finetuning with LoRA.

摘要：低秩適應 (LoRA) 是一種廣泛使用的參數有效微調方法，適用於大型語言模型。LoRA 僅通過訓練選定權重矩陣的低秩擾動來節省記憶體。在這項工作中，我們比較了 LoRA 和完全微調在兩個目標領域（程式設計和數學）上的效能。我們同時考慮了指令微調（$\approx$100K 提示回應對）和持續預訓練（$\approx$10B 非結構化代幣）資料模式。我們的結果顯示，在大多數設定中，LoRA 的效能遠低於完全微調。儘管如此，LoRA 展現了一種理想的正則化形式：它能更好地維持基礎模型在目標領域以外任務上的效能。我們證明與權重衰減和中斷等常見技術相比，LoRA 提供了更強大的正則化；它也有助於維持更多樣化的生成。我們證明完全微調學習到的擾動秩比典型的 LoRA 組態大 10-100 倍，這可能解釋了一些報告的差距。最後，我們提出使用 LoRA 進行微調的最佳實務。

##### **Detecting Continuous Integration Skip : A Reinforcement Learning-based Approach**
2405.09657v1 by Hajer Mhalla, Mohamed Aymen Saied

The software industry is experiencing a surge in the adoption of Continuous
Integration (CI) practices, both in commercial and open-source environments. CI
practices facilitate the seamless integration of code changes by employing
automated building and testing processes. Some frameworks, such as Travis CI
and GitHub Actions have significantly contributed to simplifying and enhancing
the CI process, rendering it more accessible and efficient for development
teams. Despite the availability these CI tools , developers continue to
encounter difficulties in accurately flagging commits as either suitable for CI
execution or as candidates for skipping especially for large projects with many
dependencies. Inaccurate flagging of commits can lead to resource-intensive
test and build processes, as even minor commits may inadvertently trigger the
Continuous Integration process. The problem of detecting CI-skip commits, can
be modeled as binary classification task where we decide to either build a
commit or to skip it. This study proposes a novel solution that leverages Deep
Reinforcement Learning techniques to construct an optimal Decision Tree
classifier that addresses the imbalanced nature of the data. We evaluate our
solution by running a within and a cross project validation benchmark on
diverse range of Open-Source projects hosted on GitHub which showcased superior
results when compared with existing state-of-the-art methods.

摘要：軟體產業正經歷著持續整合 (CI) 實務的採用激增，無論是在商業或開放原始碼環境中皆然。CI 實務透過採用自動建置與測試流程，促進程式碼變更的無縫整合。一些架構，例如 Travis CI 和 GitHub Actions，已對簡化和增強 CI 流程做出重大貢獻，使其對於開發團隊來說更易於使用且更有效率。儘管有這些 CI 工具可用，開發人員在準確地將提交標記為適合 CI 執行或適合跳過時仍然會遇到困難，特別是對於具有許多依賴項目的大型專案。提交標記不準確可能會導致耗費資源的測試和建置流程，因為即使是微小的提交也可能無意中觸發持續整合流程。偵測 CI 跳過提交的問題可以建模為二元分類任務，在其中我們決定建置提交或跳過提交。本研究提出了一種新穎的解決方案，該解決方案利用深度強化學習技術來建構一個最佳決策樹分類器，以解決資料的不平衡性質。我們透過在 GitHub 上託管的各種開放原始碼專案上執行專案內和跨專案驗證基準測試來評估我們的解決方案，與現有的最先進方法相比，展示出優異的結果。

##### **Elements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic world knowledge in language models**
2405.09605v1 by Anna A. Ivanova, Aalok Sathe, Benjamin Lipkin, Unnathi Kumar, Setayesh Radkani, Thomas H. Clark, Carina Kauf, Jennifer Hu, R. T. Pramod, Gabriel Grand, Vivian Paulun, Maria Ryskina, Ekin Akyurek, Ethan Wilcox, Nafisa Rashid, Leshem Choshen, Roger Levy, Evelina Fedorenko, Joshua Tenenbaum, Jacob Andreas

The ability to build and leverage world models is essential for a
general-purpose AI agent. Testing such capabilities is hard, in part because
the building blocks of world models are ill-defined. We present Elements of
World Knowledge (EWOK), a framework for evaluating world modeling in language
models by testing their ability to use knowledge of a concept to match a target
text with a plausible/implausible context. EWOK targets specific concepts from
multiple knowledge domains known to be vital for world modeling in humans.
Domains range from social interactions (help/hinder) to spatial relations
(left/right). Both, contexts and targets are minimal pairs. Objects, agents,
and locations in the items can be flexibly filled in enabling easy generation
of multiple controlled datasets. We then introduce EWOK-CORE-1.0, a dataset of
4,374 items covering 11 world knowledge domains. We evaluate 20 openweights
large language models (1.3B--70B parameters) across a battery of evaluation
paradigms along with a human norming study comprising 12,480 measurements. The
overall performance of all tested models is worse than human performance, with
results varying drastically across domains. These data highlight simple cases
where even large models fail and present rich avenues for targeted research on
LLM world modeling capabilities.

摘要：建立和利用世界模型的能力对于通用人工智能代理至关重要。测试此类能力很困难，部分原因是世界模型的构建模块定义不明确。我们提出了世界知识元素 (EWOK)，这是一个通过测试语言模型使用概念知识匹配目标文本与合理/不合理语境的能力来评估世界建模的框架。EWOK 针对已知对人类世界建模至关重要的多个知识领域中的特定概念。领域范围从社会互动（帮助/阻碍）到空间关系（左/右）。语境和目标都是极小对。项目中的对象、代理和位置可以灵活填充，从而可以轻松生成多个受控数据集。然后我们介绍 EWOK-CORE-1.0，这是一个包含 4,374 个项目的数据集，涵盖 11 个世界知识领域。我们在一系列评估范例中评估了 20 个开放权重大型语言模型（1.3B--70B 参数），同时进行了一项包括 12,480 次测量的人类规范研究。所有测试模型的整体性能都比人类性能差，结果在不同领域差异很大。这些数据突出了即使是大模型也会失败的简单案例，并为针对 LLM 世界建模能力的定向研究提供了丰富的途径。

##### **Modeling Bilingual Sentence Processing: Evaluating RNN and Transformer Architectures for Cross-Language Structural Priming**
2405.09508v1 by Bushi Xiao, Chao Gao, Demi Zhang

This study evaluates the performance of Recurrent Neural Network (RNN) and
Transformer in replicating cross-language structural priming: a key indicator
of abstract grammatical representations in human language processing. Focusing
on Chinese-English priming, which involves two typologically distinct
languages, we examine how these models handle the robust phenomenon of
structural priming, where exposure to a particular sentence structure increases
the likelihood of selecting a similar structure subsequently. Additionally, we
utilize large language models (LLM) to measure the cross-lingual structural
priming effect. Our findings indicate that Transformer outperform RNN in
generating primed sentence structures, challenging the conventional belief that
human sentence processing primarily involves recurrent and immediate processing
and suggesting a role for cue-based retrieval mechanisms. Overall, this work
contributes to our understanding of how computational models may reflect human
cognitive processes in multilingual contexts.

摘要：本研究評估遞迴神經網路 (RNN) 和 Transformer 在複製跨語言結構啟動中的表現：人類語言處理中抽象語法表徵的一個關鍵指標。專注於中英啟動，其中涉及兩種類型學上不同的語言，我們探討這些模型如何處理結構啟動的強大現象，其中接觸特定句子結構會增加隨後選擇類似結構的可能性。此外，我們利用大型語言模型 (LLM) 來衡量跨語言結構啟動效應。我們的研究結果表明，Transformer 在生成啟動句子的結構上優於 RNN，挑戰了人類句子處理主要涉及遞迴和立即處理的傳統觀念，並暗示了基於提示的檢索機制的角色。總體而言，這項工作有助於我們了解計算模型如何在多語言環境中反映人類認知過程。

##### **QueryNER: Segmentation of E-commerce Queries**
2405.09507v1 by Chester Palen-Michel, Lizzie Liang, Zhe Wu, Constantine Lignos

We present QueryNER, a manually-annotated dataset and accompanying model for
e-commerce query segmentation. Prior work in sequence labeling for e-commerce
has largely addressed aspect-value extraction which focuses on extracting
portions of a product title or query for narrowly defined aspects. Our work
instead focuses on the goal of dividing a query into meaningful chunks with
broadly applicable types. We report baseline tagging results and conduct
experiments comparing token and entity dropping for null and low recall query
recovery. Challenging test sets are created using automatic transformations and
show how simple data augmentation techniques can make the models more robust to
noise. We make the QueryNER dataset publicly available.

摘要：我們提出 QueryNER，一個手動註解的資料集和電子商務查詢分段的附帶模型。先前在電子商務序列標記中的工作已廣泛探討面向特定面向提取產品標題或查詢部分的方面價值萃取。我們的研究反而專注於將查詢劃分為具有廣泛適用類型的有意義區塊。我們報告基準標記結果，並進行實驗，比較令牌和實體刪除以進行空值和低召回查詢復原。使用自動轉換建立具挑戰性的測試集，並展示簡單的資料擴充技術如何讓模型更能抵抗雜訊。我們公開 QueryNER 資料集。

##### **ParaNames 1.0: Creating an Entity Name Corpus for 400+ Languages using Wikidata**
2405.09496v1 by Jonne Sälevä, Constantine Lignos

We introduce ParaNames, a massively multilingual parallel name resource
consisting of 140 million names spanning over 400 languages. Names are provided
for 16.8 million entities, and each entity is mapped from a complex type
hierarchy to a standard type (PER/LOC/ORG). Using Wikidata as a source, we
create the largest resource of this type to date. We describe our approach to
filtering and standardizing the data to provide the best quality possible.
ParaNames is useful for multilingual language processing, both in defining
tasks for name translation/transliteration and as supplementary data for tasks
such as named entity recognition and linking. We demonstrate the usefulness of
ParaNames on two tasks. First, we perform canonical name translation between
English and 17 other languages. Second, we use it as a gazetteer for
multilingual named entity recognition, obtaining performance improvements on
all 10 languages evaluated.

摘要：我們推出 ParaNames，這是一個龐大的多語言平行名稱資源，包含超過 400 種語言的 1.4 億個名稱。這些名稱提供給 1680 萬個實體，每個實體都從複雜的類型層次結構對應到一個標準類型 (PER/LOC/ORG)。使用 Wikidata 作為來源，我們建立了迄今為止此類型最大的資源。我們描述了我們過濾和標準化資料的方法，以提供最佳品質。ParaNames 對於多語言語言處理很有用，既可用於定義名稱翻譯/轉寫任務，也可用於命名實體辨識和連結等任務的補充資料。我們在兩個任務中展示了 ParaNames 的實用性。首先，我們在英語和另外 17 種語言之間執行標準名稱翻譯。其次，我們將其用作多語言命名實體辨識的辭典，在評估的所有 10 種語言中獲得效能提升。

##### **Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts**
2405.09482v1 by Donya Rooein, Paul Rottger, Anastassia Shaitarova, Dirk Hovy

Using large language models (LLMs) for educational applications like
dialogue-based teaching is a hot topic. Effective teaching, however, requires
teachers to adapt the difficulty of content and explanations to the education
level of their students. Even the best LLMs today struggle to do this well. If
we want to improve LLMs on this adaptation task, we need to be able to measure
adaptation success reliably. However, current Static metrics for text
difficulty, like the Flesch-Kincaid Reading Ease score, are known to be crude
and brittle. We, therefore, introduce and evaluate a new set of Prompt-based
metrics for text difficulty. Based on a user study, we create Prompt-based
metrics as inputs for LLMs. They leverage LLM's general language understanding
capabilities to capture more abstract and complex features than Static metrics.
Regression experiments show that adding our Prompt-based metrics significantly
improves text difficulty classification over Static metrics alone. Our results
demonstrate the promise of using LLMs to evaluate text adaptation to different
education levels.

摘要：使用大型語言模型 (LLM) 進行教育應用，例如基於對話的教學，是一個熱門話題。然而，有效的教學要求教師根據學生的教育程度調整內容和說明的難度。即使是當今最好的 LLM 也難以做到這一點。如果我們希望在這種適應任務上改進 LLM，我們需要能夠可靠地衡量適應的成功。然而，當前文本難度的靜態指標（例如 Flesch-Kincaid 閱讀簡便度評分）已知粗糙且脆弱。因此，我們引入並評估了一組新的基於提示的文本難度指標。基於用戶研究，我們創建了基於提示的指標作為 LLM 的輸入。它們利用 LLM 的一般語言理解能力來捕捉比靜態指標更抽象和複雜的特徵。回歸實驗表明，添加我們的基於提示的指標可以顯著提高僅使用靜態指標的文本難度分類。我們的結果證明了使用 LLM 評估文本適應不同教育程度的潛力。

##### **Harmonizing Human Insights and AI Precision: Hand in Hand for Advancing Knowledge Graph Task**
2405.09477v1 by Shurong Wang, Yufei Zhang, Xuliang Huang, Hongwei Wang

Knowledge graph embedding (KGE) has caught significant interest for its
effectiveness in knowledge graph completion (KGC), specifically link prediction
(LP), with recent KGE models cracking the LP benchmarks. Despite the rapidly
growing literature, insufficient attention has been paid to the cooperation
between humans and AI on KG. However, humans' capability to analyze graphs
conceptually may further improve the efficacy of KGE models with semantic
information. To this effect, we carefully designed a human-AI team (HAIT)
system dubbed KG-HAIT, which harnesses the human insights on KG by leveraging
fully human-designed ad-hoc dynamic programming (DP) on KG to produce human
insightful feature (HIF) vectors that capture the subgraph structural feature
and semantic similarities. By integrating HIF vectors into the training of KGE
models, notable improvements are observed across various benchmarks and
metrics, accompanied by accelerated model convergence. Our results underscore
the effectiveness of human-designed DP in the task of LP, emphasizing the
pivotal role of collaboration between humans and AI on KG. We open avenues for
further exploration and innovation through KG-HAIT, paving the way towards more
effective and insightful KG analysis techniques.

摘要：知識圖譜嵌入（KGE）因其在知識圖譜完成（KGC）中的有效性而引起極大興趣，特別是連結預測（LP），最近的 KGE 模型破解了 LP 基準。儘管文獻快速增長，但對於人類與 AI 在 KG 上的合作卻關注不足。然而，人類分析圖形概念的能力可能會進一步提高具有語義資訊的 KGE 模型的功效。為此，我們仔細設計了一個人類-AI 團隊（HAIT）系統，稱為 KG-HAIT，它透過充分利用人類設計的臨時動態規劃（DP）在 KG 上來利用人類對 KG 的見解，以產生擷取子圖結構特徵和語義相似性的具有人類洞察力的特徵（HIF）向量。透過將 HIF 向量整合到 KGE 模型的訓練中，在各種基準和指標中觀察到顯著的改進，並伴隨著模型收斂速度加快。我們的結果強調了人類設計的 DP 在 LP 任務中的有效性，強調了人類與 AI 在 KG 上協作的关键作用。我們透過 KG-HAIT 開闢了進一步探索和創新的途徑，為更有效且有見地的 KG 分析技術鋪路。

##### **Tell Me Why: Explainable Public Health Fact-Checking with Large Language Models**
2405.09454v1 by Majid Zarharan, Pascal Wullschleger, Babak Behkam Kia, Mohammad Taher Pilehvar, Jennifer Foster

This paper presents a comprehensive analysis of explainable fact-checking
through a series of experiments, focusing on the ability of large language
models to verify public health claims and provide explanations or
justifications for their veracity assessments. We examine the effectiveness of
zero/few-shot prompting and parameter-efficient fine-tuning across various open
and closed-source models, examining their performance in both isolated and
joint tasks of veracity prediction and explanation generation. Importantly, we
employ a dual evaluation approach comprising previously established automatic
metrics and a novel set of criteria through human evaluation. Our automatic
evaluation indicates that, within the zero-shot scenario, GPT-4 emerges as the
standout performer, but in few-shot and parameter-efficient fine-tuning
contexts, open-source models demonstrate their capacity to not only bridge the
performance gap but, in some instances, surpass GPT-4. Human evaluation reveals
yet more nuance as well as indicating potential problems with the gold
explanations.

摘要：本論文透過一系列實驗，對可解釋事實查核進行全面分析，重點關注大型語言模型驗證公共健康聲明並提供其真實性評估的解釋或理由的能力。我們檢視了零次/少次提示和參數有效微調在各種開放和閉源模型中的有效性，檢視了它們在真實性預測和解釋生成的孤立和聯合任務中的表現。重要的是，我們採用了雙重評估方法，包括先前建立的自動化指標和通過人類評估的一組新標準。我們的自動評估表明，在零次場景中，GPT-4 成為傑出表現者，但在少次和參數有效微調的背景下，開放源碼模型證明了它們不僅能夠縮小性能差距，而且在某些情況下，還能超越 GPT-4。人類評估揭示了更多細微差別，並指出了黃金解釋中潛在的問題。

##### **Desk-AId: Humanitarian Aid Desk Assessment with Geospatial AI for Predicting Landmine Areas**
2405.09444v1 by Flavio Cirillo, Gürkan Solmaz, Yi-Hsuan Peng, Christian Bizer, Martin Jebens

The process of clearing areas, namely demining, starts by assessing and
prioritizing potential hazardous areas (i.e., desk assessment) to go under
thorough investigation of experts, who confirm the risk and proceed with the
mines clearance operations. This paper presents Desk-AId that supports the desk
assessment phase by estimating landmine risks using geospatial data and
socioeconomic information. Desk-AId uses a Geospatial AI approach specialized
to landmines. The approach includes mixed data sampling strategies and
context-enrichment by historical conflicts and key multi-domain facilities
(e.g., buildings, roads, health sites). The proposed system addresses the issue
of having only ground-truth for confirmed hazardous areas by implementing a new
hard-negative data sampling strategy, where negative points are sampled in the
vicinity of hazardous areas. Experiments validate Desk-Aid in two domains for
landmine risk assessment: 1) country-wide, and 2) uncharted study areas). The
proposed approach increases the estimation accuracies up to 92%, for different
classification models such as RandomForest (RF), Feedforward Neural Networks
(FNN), and Graph Neural Networks (GNN).

摘要：清除區域的過程，即排雷，始於評估和優先處理潛在危險區域（即桌面評估），由專家進行徹底調查，確認風險並繼續進行排雷行動。本文提出 Desk-AId，它透過使用地理空間資料和社會經濟資訊來估計地雷風險，以支援桌面評估階段。Desk-AId 使用專門針對地雷的地理空間 AI 方法。此方法包括混合資料抽樣策略和透過歷史衝突和關鍵多重領域設施（例如建築物、道路、醫療場所）進行脈絡豐富化。所提出的系統透過實施新的困難負面資料抽樣策略來解決僅對已確認危險區域進行地面真實性驗證的問題，其中負面點會在危險區域附近進行抽樣。實驗在兩個領域驗證 Desk-Aid 以進行地雷風險評估：1) 全國範圍，以及 2) 未標示的研究區域。對於不同的分類模型，例如隨機森林 (RF)、前饋神經網路 (FNN) 和圖神經網路 (GNN)，所提出的方法將估計準確度提高到 92%。

##### **Facilitating Opinion Diversity through Hybrid NLP Approaches**
2405.09439v1 by Michiel van der Meer

Modern democracies face a critical issue of declining citizen participation
in decision-making. Online discussion forums are an important avenue for
enhancing citizen participation. This thesis proposal 1) identifies the
challenges involved in facilitating large-scale online discussions with Natural
Language Processing (NLP), 2) suggests solutions to these challenges by
incorporating hybrid human-AI technologies, and 3) investigates what these
technologies can reveal about individual perspectives in online discussions. We
propose a three-layered hierarchy for representing perspectives that can be
obtained by a mixture of human intelligence and large language models. We
illustrate how these representations can draw insights into the diversity of
perspectives and allow us to investigate interactions in online discussions.

摘要：現代民主面臨公民參與決策下降的關鍵問題。線上討論論壇是提升公民參與的重要途徑。本論文提案 1) 找出使用自然語言處理 (NLP) 促進大規模線上討論所涉及的挑戰，2) 透過整合混合式人機智慧技術提出解決這些挑戰的方案，以及 3) 調查這些技術如何揭露線上討論中個人的觀點。我們提出一個三層式階層來表示觀點，這些觀點可以透過人類智慧與大型語言模型的結合而獲得。我們說明這些表示如何深入探討觀點的多樣性，並讓我們調查線上討論中的互動。

##### **Improving Label Error Detection and Elimination with Uncertainty Quantification**
2405.09602v1 by Johannes Jakubik, Michael Vössing, Manil Maskey, Christopher Wölfle, Gerhard Satzger

Identifying and handling label errors can significantly enhance the accuracy
of supervised machine learning models. Recent approaches for identifying label
errors demonstrate that a low self-confidence of models with respect to a
certain label represents a good indicator of an erroneous label. However,
latest work has built on softmax probabilities to measure self-confidence. In
this paper, we argue that -- as softmax probabilities do not reflect a model's
predictive uncertainty accurately -- label error detection requires more
sophisticated measures of model uncertainty. Therefore, we develop a range of
novel, model-agnostic algorithms for Uncertainty Quantification-Based Label
Error Detection (UQ-LED), which combine the techniques of confident learning
(CL), Monte Carlo Dropout (MCD), model uncertainty measures (e.g., entropy),
and ensemble learning to enhance label error detection. We comprehensively
evaluate our algorithms on four image classification benchmark datasets in two
stages. In the first stage, we demonstrate that our UQ-LED algorithms
outperform state-of-the-art confident learning in identifying label errors. In
the second stage, we show that removing all identified errors from the training
data based on our approach results in higher accuracies than training on all
available labeled data. Importantly, besides our contributions to the detection
of label errors, we particularly propose a novel approach to generate
realistic, class-dependent label errors synthetically. Overall, our study
demonstrates that selectively cleaning datasets with UQ-LED algorithms leads to
more accurate classifications than using larger, noisier datasets.

摘要：<paragraph>識別和處理標籤錯誤能顯著提升監督式機器學習模型的準確性。最近用於識別標籤錯誤的方法顯示，模型對於某個標籤的低自信心代表錯誤標籤的良好指標。然而，最新研究建立在 softmax 機率上來衡量自信心。在本文中，我們主張，由於 softmax 機率無法準確反映模型的預測不確定性，因此標籤錯誤偵測需要更精密的模型不確定性測量。因此，我們開發了一系列創新、與模型無關的演算法，用於基於不確定性量化的標籤錯誤偵測 (UQ-LED)，它結合了自信學習 (CL)、蒙地卡羅輟學 (MCD)、模型不確定性測量（例如，熵）和整體學習的技術來增強標籤錯誤偵測。我們在兩個階段對四個影像分類基準資料集全面評估我們的演算法。在第一階段，我們證明我們的 UQ-LED 演算法在識別標籤錯誤方面優於最先進的自信學習。在第二階段，我們證明從訓練資料中移除所有根據我們方法識別的錯誤，會比在所有可用的標籤資料上進行訓練產生更高的準確度。重要的是，除了我們對標籤錯誤偵測的貢獻之外，我們特別提出了一種創新的方法來合成產生逼真、依類別而定的標籤錯誤。總的來說，我們的研究證明，使用 UQ-LED 演算法選擇性地清理資料集會比使用更大、更雜訊的資料集產生更準確的分類。</paragraph>

##### **On the Correspondence of Non-flat Assumption-based Argumentation and Logic Programming with Negation as Failure in the Head**
2405.09415v1 by Anna Rapberger, Markus Ulbricht, Francesca Toni

The relation between (a fragment of) assumption-based argumentation (ABA) and
logic programs (LPs) under stable model semantics is well-studied. However, for
obtaining this relation, the ABA framework needs to be restricted to being
flat, i.e., a fragment where the (defeasible) assumptions can never be
entailed, only assumed to be true or false. Here, we remove this restriction
and show a correspondence between non-flat ABA and LPs with negation as failure
in their head. We then extend this result to so-called set-stable ABA
semantics, originally defined for the fragment of non-flat ABA called bipolar
ABA. We showcase how to define set-stable semantics for LPs with negation as
failure in their head and show the correspondence to set-stable ABA semantics.

摘要：（片段式）假设论证（ABA）与稳定模型语义下的逻辑程序（LP）之间的关系已得到充分研究。然而，为了获得这种关系，ABA 框架需要被限制为扁平的，即片段中（可反驳的）假设永远不能被蕴含，只能被假定为真或假。在这里，我们移除了此限制，并展示了非扁平 ABA 与否定即失败作为其头部的 LP 之间的对应关系。然后，我们将此结果扩展到所谓的集合稳定 ABA 语义，最初定义为非扁平 ABA 片段，称为双极 ABA。我们展示了如何为否定即失败作为其头部的 LP 定义集合稳定语义，并展示了与集合稳定 ABA 语义的对应关系。

##### **$O_2$ is a multiple context-free grammar: an implementation-, formalisation-friendly proof**
2405.09396v1 by Marco B. Caminati

Classifying formal languages according to the expressiveness of grammars able
to generate them is a fundamental problem in computational linguistics and,
therefore, in the theory of computation. Furthermore, such kind of analysis can
give insight into the classification of abstract algebraic structure such as
groups, for example through the correspondence given by the word problem. While
many such classification problems remain open, others have been settled.
Recently, it was proved that $n$-balanced languages (i.e., whose strings
contain the same occurrences of letters $a_i$ and $A_i$ with $1\leq i \leq n$)
can be generated by multiple context-free grammars (MCFGs), which are one of
the several slight extensions of context free grammars added to the classical
Chomsky hierarchy to make the mentioned classification more precise. This paper
analyses the existing proofs from the computational and the proof-theoretical
point of views, systematically studying whether each proof can lead to a
verified (i.e., checked by a proof assistant) algorithm parsing balanced
languages via MCFGs. We conclude that none of the existing proofs is
realistically suitable against this practical goal, and proceed to provide a
radically new, elementary, extremely short proof for the crucial case $n \leq
2$. A comparative analysis with respect to the existing proofs is finally
performed to justify why the proposed proof is a substantial step towards
concretely obtaining a verified parsing algorithm for $O_2$.

摘要：對形式語言進行分類，根據語法的表現力來產生它們，這是計算語言學中的基本問題，因此，也是計算理論中的基本問題。此外，這種分析可以洞察抽象代數結構的分類，例如群，例如通過字問題給出的對應關係。雖然許多這樣的分類問題仍然懸而未決，但其他問題已經得到解決。最近，證明了 $n$ 平衡語言（即，其字串包含相同出現次數的字母 $a_i$ 和 $A_i$，其中 $1\leq i \leq n$）可以由多個上下文無關文法 (MCFG) 產生，這是上下文無關文法在經典喬姆斯基層次結構中新增的幾個輕微擴充之一，用於使所述分類更精確。本文從計算和證明理論的角度分析現有證明，系統地研究每個證明是否可以導致通過 MCFG 解析平衡語言的驗證（即由證明助理檢查）演算法。我們得出結論，現有的證明沒有任何一個現實上適合這個實際目標，並繼續提供一個全新的、基礎的、極短的證明，用於關鍵情況 $n \leq 2$。最後執行相對於現有證明的比較分析，以證明所提出的證明是朝著具體獲得 $O_2$ 的驗證解析演算法邁出的重要一步。

##### **Matching domain experts by training from scratch on domain knowledge**
2405.09395v1 by Xiaoliang Luo, Guangzhi Sun, Bradley C. Love

Recently, large language models (LLMs) have outperformed human experts in
predicting the results of neuroscience experiments (Luo et al., 2024). What is
the basis for this performance? One possibility is that statistical patterns in
that specific scientific literature, as opposed to emergent reasoning abilities
arising from broader training, underlie LLMs' performance. To evaluate this
possibility, we trained (next word prediction) a relatively small
124M-parameter GPT-2 model on 1.3 billion tokens of domain-specific knowledge.
Despite being orders of magnitude smaller than larger LLMs trained on trillions
of tokens, small models achieved expert-level performance in predicting
neuroscience results. Small models trained on the neuroscience literature
succeeded when they were trained from scratch using a tokenizer specifically
trained on neuroscience text or when the neuroscience literature was used to
finetune a pretrained GPT-2. Our results indicate that expert-level performance
may be attained by even small LLMs through domain-specific, auto-regressive
training approaches.

摘要：<paragraph>最近，大型语言模型 (LLM) 在预测神经科学实验结果方面优于人类专家（Luo 等人，2024 年）。这种表现的基础是什么？一种可能性是特定科学文献中的统计模式，而不是源自更广泛训练的新兴推理能力，是 LLM 表现的基础。为了评估这种可能性，我们训练了一个相对较小的 1.24 亿参数 GPT-2 模型（下一个单词预测）在 13 亿个领域特定知识标记上。尽管比在数万亿个标记上训练的较大 LLM 小几个数量级，但小型模型在预测神经科学结果方面达到了专家级表现。在神经科学文献上训练的小型模型在使用专门针对神经科学文本训练的分词器从头开始训练时取得了成功，或者当神经科学文献用于微调预训练的 GPT-2 时取得了成功。我们的结果表明，即使是小型 LLM 也可以通过领域特定的自回归训练方法获得专家级表现。</paragraph>

##### **PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models**
2405.09373v1 by Devansh Jain, Priyanshu Kumar, Samuel Gehman, Xuhui Zhou, Thomas Hartvigsen, Maarten Sap

Recent advances in large language models (LLMs) have led to their extensive
global deployment, and ensuring their safety calls for comprehensive and
multilingual toxicity evaluations. However, existing toxicity benchmarks are
overwhelmingly focused on English, posing serious risks to deploying LLMs in
other languages. We address this by introducing PolygloToxicityPrompts (PTP),
the first large-scale multilingual toxicity evaluation benchmark of 425K
naturally occurring prompts spanning 17 languages. We overcome the scarcity of
naturally occurring toxicity in web-text and ensure coverage across languages
with varying resources by automatically scraping over 100M web-text documents.
Using PTP, we investigate research questions to study the impact of model size,
prompt language, and instruction and preference-tuning methods on toxicity by
benchmarking over 60 LLMs. Notably, we find that toxicity increases as language
resources decrease or model size increases. Although instruction- and
preference-tuning reduce toxicity, the choice of preference-tuning method does
not have any significant impact. Our findings shed light on crucial
shortcomings of LLM safeguarding and highlight areas for future research.

摘要：大型語言模型 (LLM) 的最新進展已導致其廣泛的全球部署，而確保其安全性需要進行全面且多語言的毒性評估。然而，現有的毒性基準過於重視英語，對使用其他語言部署 LLM 構成嚴重風險。我們通過引入 PolygloToxicityPrompts (PTP) 來解決這個問題，PTP 是第一個大規模多語言毒性評估基準，包含 425K 個自然發生的提示，涵蓋 17 種語言。我們克服了網路文本中自然發生的毒性稀少性，並通過自動擷取超過 1 億個網路文本文件來確保跨語言的涵蓋範圍，即使這些語言的資源不同。使用 PTP，我們探討研究問題，以研究模型大小、提示語言以及說明和偏好調整方法對毒性的影響，方法是對超過 60 個 LLM 進行基準測試。值得注意的是，我們發現毒性會隨著語言資源的減少或模型大小的增加而增加。儘管說明和偏好調整可以降低毒性，但偏好調整方法的選擇並未產生任何顯著影響。我們的發現揭示了 LLM 保障的關鍵缺點，並強調了未來研究領域。

##### **Aggregate Representation Measure for Predictive Model Reusability**
2405.09600v1 by Vishwesh Sangarya, Richard Bradford, Jung-Eun Kim

In this paper, we propose a predictive quantifier to estimate the retraining
cost of a trained model in distribution shifts. The proposed Aggregated
Representation Measure (ARM) quantifies the change in the model's
representation from the old to new data distribution. It provides, before
actually retraining the model, a single concise index of resources - epochs,
energy, and carbon emissions - required for the retraining. This enables reuse
of a model with a much lower cost than training a new model from scratch. The
experimental results indicate that ARM reasonably predicts retraining costs for
varying noise intensities and enables comparisons among multiple model
architectures to determine the most cost-effective and sustainable option.

摘要：在本文中，我们提出了一种预测量化器，以估计分布变化中训练模型的重新训练成本。所提出的聚合表示度量（ARM）量化了模型表示从旧数据分布到新数据分布的变化。它在实际重新训练模型之前，提供了重新训练所需资源（时代、能源和碳排放）的单一简洁指标。这使得以比从头开始训练新模型低得多的成本重新使用模型成为可能。实验结果表明，ARM 合理地预测了不同噪声强度下的重新训练成本，并能够在多个模型架构之间进行比较，以确定最具成本效益和可持续性的选项。

##### **Vision-Based Neurosurgical Guidance: Unsupervised Localization and Camera-Pose Prediction**
2405.09355v1 by Gary Sarwin, Alessandro Carretta, Victor Staartjes, Matteo Zoli, Diego Mazzatenta, Luca Regli, Carlo Serra, Ender Konukoglu

Localizing oneself during endoscopic procedures can be problematic due to the
lack of distinguishable textures and landmarks, as well as difficulties due to
the endoscopic device such as a limited field of view and challenging lighting
conditions. Expert knowledge shaped by years of experience is required for
localization within the human body during endoscopic procedures. In this work,
we present a deep learning method based on anatomy recognition, that constructs
a surgical path in an unsupervised manner from surgical videos, modelling
relative location and variations due to different viewing angles. At inference
time, the model can map an unseen video's frames on the path and estimate the
viewing angle, aiming to provide guidance, for instance, to reach a particular
destination. We test the method on a dataset consisting of surgical videos of
transsphenoidal adenomectomies, as well as on a synthetic dataset. An online
tool that lets researchers upload their surgical videos to obtain anatomy
detections and the weights of the trained YOLOv7 model are available at:
https://surgicalvision.bmic.ethz.ch.

摘要：在內視鏡手術過程中，由於缺乏可區分的紋理和地標，以及內視鏡裝置（例如視野有限和照明條件具有挑戰性）造成的困難，因此自我定位可能會出現問題。在內視鏡手術過程中，需要由多年經驗塑造的專家知識才能在人體內進行定位。在這項工作中，我們提出了一種基於解剖識別的深度學習方法，該方法從手術影片中以無監督的方式建構一條手術路徑，對由於不同視角造成的相對位置和變化進行建模。在推理時間，模型可以在路徑上對應一個未見影片的畫面，並估計視角，目的是提供指導，例如，到達特定目的地。我們在由蝶骨體腺瘤切除術手術影片組成的資料集以及合成資料集上測試了該方法。一個線上工具，讓研究人員可以上傳他們的手術影片以取得解剖偵測和訓練好的 YOLOv7 模型的權重：https://surgicalvision.bmic.ethz.ch。

##### **Properties that allow or prohibit transferability of adversarial attacks among quantized networks**
2405.09598v1 by Abhishek Shrestha, Jürgen Großmann

Deep Neural Networks (DNNs) are known to be vulnerable to adversarial
examples. Further, these adversarial examples are found to be transferable from
the source network in which they are crafted to a black-box target network. As
the trend of using deep learning on embedded devices grows, it becomes relevant
to study the transferability properties of adversarial examples among
compressed networks. In this paper, we consider quantization as a network
compression technique and evaluate the performance of transfer-based attacks
when the source and target networks are quantized at different bitwidths. We
explore how algorithm specific properties affect transferability by considering
various adversarial example generation algorithms. Furthermore, we examine
transferability in a more realistic scenario where the source and target
networks may differ in bitwidth and other model-related properties like
capacity and architecture. We find that although quantization reduces
transferability, certain attack types demonstrate an ability to enhance it.
Additionally, the average transferability of adversarial examples among
quantized versions of a network can be used to estimate the transferability to
quantized target networks with varying capacity and architecture.

摘要：深度神经網路 (DNN) 已知容易受到對抗性範例的攻擊。此外，這些對抗性範例被發現可以從它們被製作出來的原始網路傳輸到一個黑箱目標網路。隨著在嵌入式裝置上使用深度學習的趨勢增長，研究對抗性範例在壓縮網路之間的可傳輸性變得相關。在本文中，我們將量化視為一種網路壓縮技術，並評估當原始網路和目標網路以不同的位寬進行量化時，基於傳輸的攻擊的效能。我們探討演算法特定屬性如何影響可傳輸性，方法是考慮各種對抗性範例生成演算法。此外，我們在一個更實際的場景中檢查可傳輸性，在這個場景中，原始網路和目標網路在位寬和其他與模型相關的屬性（如容量和架構）上可能有所不同。我們發現，儘管量化會降低可傳輸性，但某些攻擊類型表現出增強它的能力。此外，對抗性範例在網路量化版本之間的平均可傳輸性可被用於估計對具有不同容量和架構的量化目標網路的可傳輸性。

##### **When AI Eats Itself: On the Caveats of Data Pollution in the Era of Generative AI**
2405.09597v1 by Xiaodan Xing, Fadong Shi, Jiahao Huang, Yinzhe Wu, Yang Nan, Sheng Zhang, Yingying Fang, Mike Roberts, Carola-Bibiane Schönlieb, Javier Del Ser, Guang Yang

Generative artificial intelligence (AI) technologies and large models are
producing realistic outputs across various domains, such as images, text,
speech, and music. Creating these advanced generative models requires
significant resources, particularly large and high-quality datasets. To
minimize training expenses, many algorithm developers use data created by the
models themselves as a cost-effective training solution. However, not all
synthetic data effectively improve model performance, necessitating a strategic
balance in the use of real versus synthetic data to optimize outcomes.
  Currently, the previously well-controlled integration of real and synthetic
data is becoming uncontrollable. The widespread and unregulated dissemination
of synthetic data online leads to the contamination of datasets traditionally
compiled through web scraping, now mixed with unlabeled synthetic data. This
trend portends a future where generative AI systems may increasingly rely
blindly on consuming self-generated data, raising concerns about model
performance and ethical issues. What will happen if generative AI continuously
consumes itself without discernment? What measures can we take to mitigate the
potential adverse effects?
  There is a significant gap in the scientific literature regarding the impact
of synthetic data use in generative AI, particularly in terms of the fusion of
multimodal information. To address this research gap, this review investigates
the consequences of integrating synthetic data blindly on training generative
AI on both image and text modalities and explores strategies to mitigate these
effects. The goal is to offer a comprehensive view of synthetic data's role,
advocating for a balanced approach to its use and exploring practices that
promote the sustainable development of generative AI technologies in the era of
large models.

摘要：生成式人工智能 (AI) 技術和大模型正在各種領域產生逼真的輸出，例如圖像、文字、語音和音樂。建立這些先進的生成式模型需要大量的資源，尤其是龐大且高品質的資料集。為了將訓練費用降到最低，許多演算法開發人員使用模型本身建立的資料作為經濟實惠的訓練解決方案。然而，並非所有合成資料都能有效提升模型效能，這使得在使用真實資料和合成資料之間取得策略性平衡以最佳化結果變得非常必要。
目前，先前控制良好的真實資料和合成資料整合正變得難以控制。合成資料在網路上廣泛且不受規範地散布，導致傳統上透過網路擷取編譯的資料集遭到污染，現在與未標記的合成資料混在一起。這個趨勢預示著一個未來，生成式 AI 系統可能會越來越依賴盲目消耗自我產生的資料，這引發了對模型效能和道德問題的擔憂。如果生成式 AI 持續不斷地不加辨別地消耗自己，會發生什麼事？我們可以採取哪些措施來減輕潛在的不利影響？
在科學文獻中，關於合成資料在生成式 AI 中使用的影響存在顯著的差距，特別是在多模態資訊的融合方面。為了填補這個研究空白，本篇評論探討了盲目整合合成資料對訓練生成式 AI 在圖像和文字模態上的後果，並探討了減輕這些影響的策略。目標是提供合成資料角色的全面觀點，提倡對其使用採取平衡的方法，並探討在大型模型時代促進生成式 AI 技術永續發展的做法。

##### **Large Language Model Bias Mitigation from the Perspective of Knowledge Editing**
2405.09341v1 by Ruizhe Chen, Yichen Li, Zikai Xiao, Zuozhu Liu

Existing debiasing methods inevitably make unreasonable or undesired
predictions as they are designated and evaluated to achieve parity across
different social groups but leave aside individual facts, resulting in modified
existing knowledge. In this paper, we first establish a new bias mitigation
benchmark BiasKE leveraging existing and additional constructed datasets, which
systematically assesses debiasing performance by complementary metrics on
fairness, specificity, and generalization. Meanwhile, we propose a novel
debiasing method, Fairness Stamp (FAST), which enables editable fairness
through fine-grained calibration on individual biased knowledge. Comprehensive
experiments demonstrate that FAST surpasses state-of-the-art baselines with
remarkable debiasing performance while not hampering overall model capability
for knowledge preservation, highlighting the prospect of fine-grained debiasing
strategies for editable fairness in LLMs.

摘要：現有的去偏見方法不可避免地會做出不合理或不受歡迎的預測，因為它們被指定和評估為在不同的社會群體中實現平等，但卻忽略了個別事實，導致修改現有知識。在本文中，我們首先建立一個新的偏見緩解基準 BiasKE，利用現有和額外構造的數據集，通過互補的公平性、特異性和泛化指標系統地評估去偏見性能。同時，我們提出了一種新的去偏見方法，公平標籤 (FAST)，它通過對個別偏見知識進行細粒度校準來實現可編輯的公平性。綜合實驗表明，FAST 超越了最先進的基準，具有顯著的去偏見性能，同時不損害知識保存的整體模型能力，突出了可編輯公平性中細粒度去偏見策略的前景。

##### **Enhancing Maritime Trajectory Forecasting via H3 Index and Causal Language Modelling (CLM)**
2405.09596v1 by Nicolas Drapier, Aladine Chetouani, Aurélien Chateigner

The prediction of ship trajectories is a growing field of study in artificial
intelligence. Traditional methods rely on the use of LSTM, GRU networks, and
even Transformer architectures for the prediction of spatio-temporal series.
This study proposes a viable alternative for predicting these trajectories
using only GNSS positions. It considers this spatio-temporal problem as a
natural language processing problem. The latitude/longitude coordinates of AIS
messages are transformed into cell identifiers using the H3 index. Thanks to
the pseudo-octal representation, it becomes easier for language models to learn
the spatial hierarchy of the H3 index. The method is compared with a classical
Kalman filter, widely used in the maritime domain, and introduces the Fr\'echet
distance as the main evaluation metric. We show that it is possible to predict
ship trajectories quite precisely up to 8 hours with 30 minutes of context. We
demonstrate that this alternative works well enough to predict trajectories
worldwide.

摘要：船舶軌跡預測是人工智慧領域中一個新興的研究領域。傳統方法依賴於使用 LSTM、GRU 網路，甚至 Transformer 架構來預測時空序列。這項研究提出了一個可行的替代方案，僅使用 GNSS 定位來預測這些軌跡。它將這個時空問題視為自然語言處理問題。使用 H3 索引將 AIS 訊息的緯度/經度座標轉換為儲存格識別碼。由於採用了偽八進制表示法，語言模型可以更輕鬆地學習 H3 索引的空間層級。將此方法與海上領域廣泛使用的經典卡爾曼濾波器進行比較，並引入 Fr\'echet 距離作為主要的評估指標。我們表明，在 30 分鐘的背景下，可以相當精確地預測長達 8 小時的船舶軌跡。我們證明了這個替代方案足夠好，可以預測全球的軌跡。

##### **Prompting-based Synthetic Data Generation for Few-Shot Question Answering**
2405.09335v1 by Maximilian Schmidt, Andrea Bartezzaghi, Ngoc Thang Vu

Although language models (LMs) have boosted the performance of Question
Answering, they still need plenty of data. Data annotation, in contrast, is a
time-consuming process. This especially applies to Question Answering, where
possibly large documents have to be parsed and annotated with questions and
their corresponding answers. Furthermore, Question Answering models often only
work well for the domain they were trained on. Since annotation is costly, we
argue that domain-agnostic knowledge from LMs, such as linguistic
understanding, is sufficient to create a well-curated dataset. With this
motivation, we show that using large language models can improve Question
Answering performance on various datasets in the few-shot setting compared to
state-of-the-art approaches. For this, we perform data generation leveraging
the Prompting framework, suggesting that language models contain valuable
task-agnostic knowledge that can be used beyond the common
pre-training/fine-tuning scheme. As a result, we consistently outperform
previous approaches on few-shot Question Answering.

摘要：儘管語言模型 (LM) 提升了問答的效能，但它們仍需要大量的資料。相較之下，資料標註是一個耗時的程序。這特別適用於問答，其中可能必須解析大型文件，並使用問題及其對應答案進行標註。此外，問答模型通常只適用於它們受訓的領域。由於標註的成本很高，我們主張來自 LM 的與領域無關的知識，例如語言理解，就足以建立一個經過精心策劃的資料集。基於這個動機，我們展示了在小樣本設定中，與最先進的方法相比，使用大型語言模型可以提升各種資料集上的問答效能。為此，我們執行資料產生，利用提示架構，這表示語言模型包含有價值的與任務無關的知識，可以用於常見的預訓練/微調架構之外。因此，我們在小樣本問答中始終優於先前的做法。

##### **Content-Based Image Retrieval for Multi-Class Volumetric Radiology Images: A Benchmark Study**
2405.09334v1 by Farnaz Khun Jush, Steffen Vogler, Tuan Truong, Matthias Lenga

While content-based image retrieval (CBIR) has been extensively studied in
natural image retrieval, its application to medical images presents ongoing
challenges, primarily due to the 3D nature of medical images. Recent studies
have shown the potential use of pre-trained vision embeddings for CBIR in the
context of radiology image retrieval. However, a benchmark for the retrieval of
3D volumetric medical images is still lacking, hindering the ability to
objectively evaluate and compare the efficiency of proposed CBIR approaches in
medical imaging. In this study, we extend previous work and establish a
benchmark for region-based and multi-organ retrieval using the TotalSegmentator
dataset (TS) with detailed multi-organ annotations. We benchmark embeddings
derived from pre-trained supervised models on medical images against embeddings
derived from pre-trained unsupervised models on non-medical images for 29
coarse and 104 detailed anatomical structures in volume and region levels. We
adopt a late interaction re-ranking method inspired by text matching for image
retrieval, comparing it against the original method proposed for volume and
region retrieval achieving retrieval recall of 1.0 for diverse anatomical
regions with a wide size range. The findings and methodologies presented in
this paper provide essential insights and benchmarks for the development and
evaluation of CBIR approaches in the context of medical imaging.

摘要：儘管基於內容的影像擷取 (CBIR) 已廣泛研究於自然影像擷取，其應用於醫學影像仍存在持續性的挑戰，這主要是因為醫學影像的 3D 特性。最近的研究顯示預先訓練好的視覺嵌入式可於放射影像擷取中用於 CBIR。然而，3D 體積醫學影像的擷取基準仍有所欠缺，這妨礙了客觀評估和比較所提出的 CBIR 方法在醫學影像中的效率。在這項研究中，我們延伸了先前的研究，並建立了一個基於區域和多器官擷取的基準，使用 TotalSegmentator 資料集 (TS) 與詳細的多器官標註。我們對照從非醫學影像的預先訓練無監督模型衍生的嵌入式，對從醫學影像的預先訓練監督模型衍生的嵌入式，對 29 個粗略的和 104 個詳細的體積和區域層級的解剖結構進行基準測試。我們採用一種受文字比對啟發的晚期互動重新排序方法進行影像擷取，並將其與為體積和區域擷取提出的原始方法進行比較，針對範圍廣泛的解剖區域達成 1.0 的擷取召回率。本文提出的發現和方法論為醫學影像中 CBIR 方法的發展和評估提供了重要的見解和基準。

##### **Simplicity within biological complexity**
2405.09595v1 by Natasa Przulj, Noel Malod-Dognin

Heterogeneous, interconnected, systems-level, molecular data have become
increasingly available and key in precision medicine. We need to utilize them
to better stratify patients into risk groups, discover new biomarkers and
targets, repurpose known and discover new drugs to personalize medical
treatment. Existing methodologies are limited and a paradigm shift is needed to
achieve quantitative and qualitative breakthroughs. In this perspective paper,
we survey the literature and argue for the development of a comprehensive,
general framework for embedding of multi-scale molecular network data that
would enable their explainable exploitation in precision medicine in linear
time. Network embedding methods map nodes to points in low-dimensional space,
so that proximity in the learned space reflects the network's topology-function
relationships. They have recently achieved unprecedented performance on hard
problems of utilizing few omic data in various biomedical applications.
However, research thus far has been limited to special variants of the problems
and data, with the performance depending on the underlying topology-function
network biology hypotheses, the biomedical applications and evaluation metrics.
The availability of multi-omic data, modern graph embedding paradigms and
compute power call for a creation and training of efficient, explainable and
controllable models, having no potentially dangerous, unexpected behaviour,
that make a qualitative breakthrough. We propose to develop a general,
comprehensive embedding framework for multi-omic network data, from models to
efficient and scalable software implementation, and to apply it to biomedical
informatics. It will lead to a paradigm shift in computational and biomedical
understanding of data and diseases that will open up ways to solving some of
the major bottlenecks in precision medicine and other domains.

摘要：異質、相互連接、系統層級的分子資料已變得越來越容易取得，並成為精準醫療的關鍵。我們需要利用它們將患者更精確地分層到風險群組中，發現新的生物標記和目標，重新利用已知的藥物並發現新的藥物以個人化醫療治療。現有的方法論有限，需要範式轉移才能實現量化和質化的突破。在這篇觀點文章中，我們調查了文獻並主張開發一個全面的通用框架，用於嵌入多尺度分子網路資料，這將使它們能夠在線性時間內在精準醫療中進行可解釋的利用。網路嵌入方法將節點映射到低維空間中的點，以便在學習空間中的接近度反映網路的拓撲功能關係。它們最近在利用少數組學資料解決各種生物醫學應用中的困難問題方面取得了前所未有的效能。然而，迄今為止的研究僅限於問題和資料的特殊變體，其效能取決於基礎的拓撲功能網路生物學假設、生物醫學應用和評估指標。多組學資料、現代圖形嵌入範例和運算能力的可用性要求建立和訓練有效、可解釋和可控的模型，這些模型沒有潛在的危險、意外的行為，並能取得質化的突破。我們建議開發一個通用的、全面的嵌入框架，用於多組學網路資料，從模型到高效且可擴充的軟體實作，並將其應用於生物醫學資訊學。這將導致對資料和疾病的計算和生物醫學理解的範式轉移，這將開啟解決精準醫療和其他領域中一些主要瓶頸的方法。

##### **ReconBoost: Boosting Can Achieve Modality Reconcilement**
2405.09321v1 by Cong Hua, Qianqian Xu, Shilong Bao, Zhiyong Yang, Qingming Huang

This paper explores a novel multi-modal alternating learning paradigm
pursuing a reconciliation between the exploitation of uni-modal features and
the exploration of cross-modal interactions. This is motivated by the fact that
current paradigms of multi-modal learning tend to explore multi-modal features
simultaneously. The resulting gradient prohibits further exploitation of the
features in the weak modality, leading to modality competition, where the
dominant modality overpowers the learning process. To address this issue, we
study the modality-alternating learning paradigm to achieve reconcilement.
Specifically, we propose a new method called ReconBoost to update a fixed
modality each time. Herein, the learning objective is dynamically adjusted with
a reconcilement regularization against competition with the historical models.
By choosing a KL-based reconcilement, we show that the proposed method
resembles Friedman's Gradient-Boosting (GB) algorithm, where the updated
learner can correct errors made by others and help enhance the overall
performance. The major difference with the classic GB is that we only preserve
the newest model for each modality to avoid overfitting caused by ensembling
strong learners. Furthermore, we propose a memory consolidation scheme and a
global rectification scheme to make this strategy more effective. Experiments
over six multi-modal benchmarks speak to the efficacy of the method. We release
the code at https://github.com/huacong/ReconBoost.

摘要：本文探討了一種新穎的多模態交替學習範例，旨在調和單模態特徵的利用和跨模態互動的探索。這項研究的動機來自於目前的多模態學習範例往往傾向於同時探索多模態特徵。所產生的梯度會阻礙進一步利用弱模態中的特徵，導致模態競爭，其中主要模態會壓制學習過程。為了解決此問題，我們研究了模態交替學習範例以達成調和。具體來說，我們提出了一種名為 ReconBoost 的新方法，每次更新一個固定的模態。在此，學習目標會根據與歷史模型競爭的調和正則化而動態調整。藉由選擇基於 KL 的調和，我們證明了所提出的方法類似於 Friedman 的梯度提升 (GB) 演算法，其中更新的學習器可以修正其他學習器所犯的錯誤，並有助於提升整體效能。與經典 GB 的主要差異在於，我們只保留每個模態最新的模型，以避免由整合強學習器所造成的過度擬合。此外，我們提出了一個記憶整合架構和一個全域修正架構，以使此策略更有效。針對六個多模態基準所做的實驗證明了此方法的效能。我們在 https://github.com/huacong/ReconBoost 釋出程式碼。

##### **TimeX++: Learning Time-Series Explanations with Information Bottleneck**
2405.09308v1 by Zichuan Liu, Tianchun Wang, Jimeng Shi, Xu Zheng, Zhuomin Chen, Lei Song, Wenqian Dong, Jayantha Obeysekera, Farhad Shirani, Dongsheng Luo

Explaining deep learning models operating on time series data is crucial in
various applications of interest which require interpretable and transparent
insights from time series signals. In this work, we investigate this problem
from an information theoretic perspective and show that most existing measures
of explainability may suffer from trivial solutions and distributional shift
issues. To address these issues, we introduce a simple yet practical objective
function for time series explainable learning. The design of the objective
function builds upon the principle of information bottleneck (IB), and modifies
the IB objective function to avoid trivial solutions and distributional shift
issues. We further present TimeX++, a novel explanation framework that
leverages a parametric network to produce explanation-embedded instances that
are both in-distributed and label-preserving. We evaluate TimeX++ on both
synthetic and real-world datasets comparing its performance against leading
baselines, and validate its practical efficacy through case studies in a
real-world environmental application. Quantitative and qualitative evaluations
show that TimeX++ outperforms baselines across all datasets, demonstrating a
substantial improvement in explanation quality for time series data. The source
code is available at \url{https://github.com/zichuan-liu/TimeXplusplus}.

摘要：說明運作於時間序列資料的深度學習模型，對於各種需要從時間序列訊號中取得可解釋且透明見解的應用程式至關重要。在本文中，我們從資訊理論的角度探討這個問題，並說明大多數現有的可解釋性測量方法都可能受到平凡解和分佈轉移問題的影響。為了解決這些問題，我們為時間序列可解釋式學習引入了簡單卻實用的目標函數。目標函數的設計建立在資訊瓶頸 (IB) 原理之上，並修改 IB 目標函數以避免平凡解和分佈轉移問題。我們進一步提出了 TimeX++，一種新穎的說明架構，它利用參數網路產生說明內嵌的實例，這些實例同時在分佈中且保留標籤。我們在合成和真實世界資料集上評估 TimeX++，將其效能與領先基準進行比較，並透過實際環境應用中的案例研究驗證其實用效能。定量和定性評估顯示，TimeX++ 在所有資料集上都優於基準，證明時間序列資料的說明品質有顯著改善。原始碼可在 \url{https://github.com/zichuan-liu/TimeXplusplus} 取得。

##### **Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support**
2405.09300v1 by Birger Moell

Background: Rapid advancements in natural language processing have led to the
development of large language models with the potential to revolutionize mental
health care. These models have shown promise in assisting clinicians and
providing support to individuals experiencing various psychological challenges.
  Objective: This study aims to compare the performance of two large language
models, GPT-4 and Chat-GPT, in responding to a set of 18 psychological prompts,
to assess their potential applicability in mental health care settings.
  Methods: A blind methodology was employed, with a clinical psychologist
evaluating the models' responses without knowledge of their origins. The
prompts encompassed a diverse range of mental health topics, including
depression, anxiety, and trauma, to ensure a comprehensive assessment.
  Results: The results demonstrated a significant difference in performance
between the two models (p > 0.05). GPT-4 achieved an average rating of 8.29 out
of 10, while Chat-GPT received an average rating of 6.52. The clinical
psychologist's evaluation suggested that GPT-4 was more effective at generating
clinically relevant and empathetic responses, thereby providing better support
and guidance to potential users.
  Conclusions: This study contributes to the growing body of literature on the
applicability of large language models in mental health care settings. The
findings underscore the importance of continued research and development in the
field to optimize these models for clinical use. Further investigation is
necessary to understand the specific factors underlying the performance
differences between the two models and to explore their generalizability across
various populations and mental health conditions.

摘要：<paragraph>背景：自然語言處理的快速進展帶動了大型語言模型的發展，這些模型有潛力革新心理健康照護。這些模型已展現出在協助臨床醫師和提供支援給經歷各種心理挑戰的個人方面的前景。
目標：本研究旨在比較兩個大型語言模型，GPT-4 和 Chat-GPT，在回應一組 18 個心理提示時的表現，以評估其在心理健康照護環境中的潛在適用性。
方法：採用盲法方法，由臨床心理師在不知其來源的情況下評估模型的回應。這些提示涵蓋了廣泛的心理健康主題，包括憂鬱症、焦慮症和創傷，以確保進行全面的評估。
結果：結果顯示兩個模型之間的表現有顯著差異 (p > 0.05)。GPT-4 的平均評分為 10 分中的 8.29 分，而 Chat-GPT 的平均評分為 6.52 分。臨床心理師的評估顯示，GPT-4 在產生與臨床相關且同理心的回應方面更有效，進而為潛在使用者提供更好的支持和指導。
結論：本研究有助於擴充大型語言模型在心理健康照護環境中適用性的文獻。這些發現強調了持續研究和發展在該領域的重要性，以最佳化這些模型以供臨床使用。進一步的調查對於了解導致兩個模型之間表現差異的特定因素，以及探索其在各種族群和心理健康狀況中的概括性，至關重要。</paragraph>

