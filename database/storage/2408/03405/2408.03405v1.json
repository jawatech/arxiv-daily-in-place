{"2408.03405": {"publish_time": "2024-08-06", "title": "Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents", "paper_summary": "Stochastic multi-agent multi-armed bandits typically assume that the rewards\nfrom each arm follow a fixed distribution, regardless of which agent pulls the\narm. However, in many real-world settings, rewards can depend on the\nsensitivity of each agent to their environment. In medical screening, disease\ndetection rates can vary by test type; in preference matching, rewards can\ndepend on user preferences; and in environmental sensing, observation quality\ncan vary across sensors. Since past work does not specify how to allocate\nagents of heterogeneous but known sensitivity of these types in a stochastic\nbandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates\ninformation from diverse agents. In doing so, we address the joint challenges\nof (i) aggregating the rewards, which follow different distributions for each\nagent-arm pair, and (ii) coordinating the assignments of agents to arms.\nMin-Width facilitates efficient collaboration among heterogeneous agents,\nexploiting the known structure in the agents' reward functions to weight their\nrewards accordingly. We analyze the regret of Min-Width and conduct\npseudo-synthetic and fully synthetic experiments to study the performance of\ndifferent levels of information sharing. Our results confirm that the gains to\nmodeling agent heterogeneity tend to be greater when the sensitivities are more\nvaried across agents, while combining more information does not always improve\nperformance.", "paper_summary_zh": "\u96a8\u6a5f\u591a\u667a\u80fd\u9ad4\u591a\u81c2\u8ced\u5f92\u901a\u5e38\u5047\u8a2d\u6bcf\u500b\u624b\u81c2\u7684\u56de\u5831\u9075\u5faa\u56fa\u5b9a\u5206\u4f48\uff0c\u7121\u8ad6\u54ea\u500b\u667a\u80fd\u9ad4\u62c9\u52d5\u624b\u81c2\u3002\u7136\u800c\uff0c\u5728\u8a31\u591a\u771f\u5be6\u4e16\u754c\u8a2d\u5b9a\u4e2d\uff0c\u56de\u5831\u53ef\u80fd\u53d6\u6c7a\u65bc\u6bcf\u500b\u667a\u80fd\u9ad4\u5c0d\u5176\u74b0\u5883\u7684\u654f\u611f\u5ea6\u3002\u5728\u91ab\u5b78\u7be9\u6aa2\u4e2d\uff0c\u75be\u75c5\u6aa2\u6e2c\u7387\u6703\u56e0\u6e2c\u8a66\u985e\u578b\u800c\u7570\uff1b\u5728\u504f\u597d\u5339\u914d\u4e2d\uff0c\u56de\u5831\u53ef\u80fd\u53d6\u6c7a\u65bc\u4f7f\u7528\u8005\u504f\u597d\uff1b\u5728\u74b0\u5883\u611f\u6e2c\u4e2d\uff0c\u89c0\u5bdf\u54c1\u8cea\u53ef\u80fd\u56e0\u611f\u6e2c\u5668\u800c\u7570\u3002\u7531\u65bc\u904e\u53bb\u7684\u5de5\u4f5c\u672a\u8aaa\u660e\u5982\u4f55\u914d\u7f6e\u9019\u4e9b\u985e\u578b\u7570\u8cea\u4f46\u5df2\u77e5\u654f\u611f\u5ea6\u7684\u667a\u80fd\u9ad4\u5728\u96a8\u6a5f\u8ced\u5f92\u8a2d\u5b9a\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e00\u7a2e UCB \u98a8\u683c\u6f14\u7b97\u6cd5\uff0cMin-Width\uff0c\u5b83\u6703\u5f59\u7e3d\u4f86\u81ea\u4e0d\u540c\u667a\u80fd\u9ad4\u7684\u8cc7\u8a0a\u3002\u5728\u9019\u6a23\u505a\u7684\u904e\u7a0b\u4e2d\uff0c\u6211\u5011\u89e3\u6c7a\u4e86 (i) \u5f59\u7e3d\u56de\u5831\u7684\u5171\u540c\u6311\u6230\uff0c\u9019\u4e9b\u56de\u5831\u9075\u5faa\u6bcf\u500b\u667a\u80fd\u9ad4\u624b\u81c2\u914d\u5c0d\u7684\u4e0d\u540c\u5206\u4f48\uff0c\u4ee5\u53ca (ii) \u5354\u8abf\u5c07\u667a\u80fd\u9ad4\u6307\u5b9a\u7d66\u624b\u81c2\u3002Min-Width \u4fc3\u9032\u7570\u8cea\u667a\u80fd\u9ad4\u4e4b\u9593\u7684\u6709\u6548\u5354\u4f5c\uff0c\u5229\u7528\u667a\u80fd\u9ad4\u56de\u5831\u51fd\u6578\u4e2d\u7684\u5df2\u77e5\u7d50\u69cb\u4f86\u9069\u7576\u5730\u52a0\u6b0a\u5176\u56de\u5831\u3002\u6211\u5011\u5206\u6790 Min-Width \u7684\u907a\u61be\uff0c\u4e26\u9032\u884c\u507d\u5408\u6210\u548c\u5b8c\u5168\u5408\u6210\u5be6\u9a57\u4f86\u7814\u7a76\u4e0d\u540c\u5c64\u7d1a\u8cc7\u8a0a\u5171\u4eab\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u7d50\u679c\u8b49\u5be6\uff0c\u7576\u654f\u611f\u5ea6\u5728\u4e0d\u540c\u667a\u80fd\u9ad4\u9593\u5dee\u7570\u8f03\u5927\u6642\uff0c\u5c0d\u667a\u80fd\u9ad4\u7570\u8cea\u6027\u5efa\u6a21\u7684\u6536\u76ca\u5f80\u5f80\u8f03\u9ad8\uff0c\u800c\u7d50\u5408\u66f4\u591a\u8cc7\u8a0a\u4e26\u4e0d\u7e3d\u662f\u6703\u6539\u5584\u6548\u80fd\u3002", "author": "Lucia Gordon et.al.", "authors": "Lucia Gordon, Esther Rolf, Milind Tambe", "id": "2408.03405v1", "paper_url": "http://arxiv.org/abs/2408.03405v1", "repo": "https://github.com/lgordon99/heterogeneous-stochastic-bandits"}}