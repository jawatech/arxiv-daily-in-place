{"2409.18395": {"publish_time": "2024-09-27", "title": "Code Vulnerability Repair with Large Language Model using Context-Aware Prompt Tuning", "paper_summary": "Large Language Models (LLMs) have shown significant challenges in detecting\nand repairing vulnerable code, particularly when dealing with vulnerabilities\ninvolving multiple aspects, such as variables, code flows, and code structures.\nIn this study, we utilize GitHub Copilot as the LLM and focus on buffer\noverflow vulnerabilities. Our experiments reveal a notable gap in Copilot's\nabilities when dealing with buffer overflow vulnerabilities, with a 76%\nvulnerability detection rate but only a 15% vulnerability repair rate. To\naddress this issue, we propose context-aware prompt tuning techniques designed\nto enhance LLM performance in repairing buffer overflow. By injecting a\nsequence of domain knowledge about the vulnerability, including various\nsecurity and code contexts, we demonstrate that Copilot's successful repair\nrate increases to 63%, representing more than four times the improvement\ncompared to repairs without domain knowledge.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5075\u6e2c\u548c\u4fee\u5fa9\u6709\u6f0f\u6d1e\u7684\u7a0b\u5f0f\u78bc\u6642\u986f\u793a\u51fa\u986f\u8457\u7684\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u8655\u7406\u6d89\u53ca\u591a\u500b\u9762\u5411\uff08\u4f8b\u5982\u8b8a\u6578\u3001\u7a0b\u5f0f\u78bc\u6d41\u7a0b\u548c\u7a0b\u5f0f\u78bc\u7d50\u69cb\uff09\u7684\u6f0f\u6d1e\u6642\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u5229\u7528 GitHub Copilot \u4f5c\u70ba LLM\uff0c\u4e26\u5c08\u6ce8\u65bc\u7de9\u885d\u5340\u6ea2\u4f4d\u6f0f\u6d1e\u3002\u6211\u5011\u7684\u5be6\u9a57\u63ed\u793a\u4e86 Copilot \u5728\u8655\u7406\u7de9\u885d\u5340\u6ea2\u4f4d\u6f0f\u6d1e\u6642\u80fd\u529b\u4e0a\u7684\u986f\u8457\u5dee\u8ddd\uff0c\u6f0f\u6d1e\u5075\u6e2c\u7387\u70ba 76%\uff0c\u4f46\u6f0f\u6d1e\u4fee\u5fa9\u7387\u50c5\u70ba 15%\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u60c5\u5883\u611f\u77e5\u63d0\u793a\u8abf\u6574\u6280\u8853\uff0c\u65e8\u5728\u589e\u5f37 LLM \u5728\u4fee\u5fa9\u7de9\u885d\u5340\u6ea2\u4f4d\u6642\u7684\u6548\u80fd\u3002\u900f\u904e\u6ce8\u5165\u4e00\u7cfb\u5217\u95dc\u65bc\u6f0f\u6d1e\u7684\u9818\u57df\u77e5\u8b58\uff0c\u5305\u62ec\u5404\u7a2e\u5b89\u5168\u6027\u548c\u7a0b\u5f0f\u78bc\u60c5\u5883\uff0c\u6211\u5011\u8b49\u660e Copilot \u7684\u6210\u529f\u4fee\u5fa9\u7387\u589e\u52a0\u5230 63%\uff0c\u8207\u6c92\u6709\u9818\u57df\u77e5\u8b58\u7684\u4fee\u5fa9\u76f8\u6bd4\uff0c\u6539\u9032\u5e45\u5ea6\u8d85\u904e\u56db\u500d\u3002", "author": "Arshiya Khan et.al.", "authors": "Arshiya Khan, Guannan Liu, Xing Gao", "id": "2409.18395v1", "paper_url": "http://arxiv.org/abs/2409.18395v1", "repo": "null"}}