{"2409.05405": {"publish_time": "2024-09-09", "title": "A Survey of Multimodal Composite Editing and Retrieval", "paper_summary": "In the real world, where information is abundant and diverse across different\nmodalities, understanding and utilizing various data types to improve retrieval\nsystems is a key focus of research. Multimodal composite retrieval integrates\ndiverse modalities such as text, image and audio, etc. to provide more\naccurate, personalized, and contextually relevant results. To facilitate a\ndeeper understanding of this promising direction, this survey explores\nmultimodal composite editing and retrieval in depth, covering image-text\ncomposite editing, image-text composite retrieval, and other multimodal\ncomposite retrieval. In this survey, we systematically organize the application\nscenarios, methods, benchmarks, experiments, and future directions. Multimodal\nlearning is a hot topic in large model era, and have also witnessed some\nsurveys in multimodal learning and vision-language models with transformers\npublished in the PAMI journal. To the best of our knowledge, this survey is the\nfirst comprehensive review of the literature on multimodal composite retrieval,\nwhich is a timely complement of multimodal fusion to existing reviews. To help\nreaders' quickly track this field, we build the project page for this survey,\nwhich can be found at\nhttps://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval.", "paper_summary_zh": "\u5728\u771f\u5be6\u4e16\u754c\u4e2d\uff0c\u8cc7\u8a0a\u8c50\u5bcc\u4e14\u591a\u5143\uff0c\u8de8\u8d8a\u4e0d\u540c\u7684\u5f62\u5f0f\uff0c\u7406\u89e3\u548c\u5229\u7528\u5404\u7a2e\u8cc7\u6599\u985e\u578b\u4f86\u6539\u5584\u6aa2\u7d22\u7cfb\u7d71\u662f\u7814\u7a76\u7684\u4e3b\u8981\u91cd\u9ede\u3002\u591a\u6a21\u614b\u8907\u5408\u6aa2\u7d22\u6574\u5408\u4e86\u6587\u5b57\u3001\u5f71\u50cf\u548c\u97f3\u8a0a\u7b49\u591a\u7a2e\u6a21\u614b\uff0c\u4ee5\u63d0\u4f9b\u66f4\u6e96\u78ba\u3001\u500b\u4eba\u5316\u548c\u8207\u60c5\u5883\u76f8\u95dc\u7684\u7d50\u679c\u3002\u70ba\u4e86\u4fc3\u9032\u5c0d\u9019\u500b\u6709\u524d\u9014\u7684\u65b9\u5411\u6709\u66f4\u6df1\u5165\u7684\u4e86\u89e3\uff0c\u672c\u8abf\u67e5\u6df1\u5165\u63a2\u8a0e\u4e86\u591a\u6a21\u614b\u8907\u5408\u7de8\u8f2f\u548c\u6aa2\u7d22\uff0c\u6db5\u84cb\u4e86\u5f71\u50cf\u6587\u5b57\u8907\u5408\u7de8\u8f2f\u3001\u5f71\u50cf\u6587\u5b57\u8907\u5408\u6aa2\u7d22\uff0c\u4ee5\u53ca\u5176\u4ed6\u591a\u6a21\u614b\u8907\u5408\u6aa2\u7d22\u3002\u5728\u672c\u8abf\u67e5\u4e2d\uff0c\u6211\u5011\u7cfb\u7d71\u6027\u5730\u6574\u7406\u4e86\u61c9\u7528\u5834\u666f\u3001\u65b9\u6cd5\u3001\u57fa\u6e96\u3001\u5be6\u9a57\u548c\u672a\u4f86\u65b9\u5411\u3002\u591a\u6a21\u614b\u5b78\u7fd2\u662f\u5927\u6a21\u578b\u6642\u4ee3\u7684\u71b1\u9580\u8a71\u984c\uff0c\u4e26\u4e14\u4e5f\u898b\u8b49\u4e86 PAMI \u671f\u520a\u4e0a\u767c\u8868\u7684\u4e00\u4e9b\u95dc\u65bc\u591a\u6a21\u614b\u5b78\u7fd2\u548c\u5177\u6709Transformer\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u7684\u8abf\u67e5\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u672c\u8abf\u67e5\u662f\u5c0d\u591a\u6a21\u614b\u8907\u5408\u6aa2\u7d22\u6587\u737b\u7684\u9996\u6b21\u5168\u9762\u56de\u9867\uff0c\u9019\u5c0d\u73fe\u6709\u8a55\u8ad6\u4e2d\u7684\u591a\u6a21\u614b\u878d\u5408\u662f\u4e00\u500b\u53ca\u6642\u7684\u88dc\u5145\u3002\u70ba\u4e86\u5e6b\u52a9\u8b80\u8005\u5feb\u901f\u8ffd\u8e64\u9019\u500b\u9818\u57df\uff0c\u6211\u5011\u5efa\u7acb\u4e86\u9019\u500b\u8abf\u67e5\u7684\u5c08\u6848\u9801\u9762\uff0c\u53ef\u4ee5\u5728 https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval \u627e\u5230\u3002", "author": "Suyan Li et.al.", "authors": "Suyan Li, Fuxiang Huang, Lei Zhang", "id": "2409.05405v1", "paper_url": "http://arxiv.org/abs/2409.05405v1", "repo": "null"}}