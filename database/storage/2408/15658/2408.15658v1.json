{"2408.15658": {"publish_time": "2024-08-28", "title": "An Empirical Study on Self-correcting Large Language Models for Data Science Code Generation", "paper_summary": "Large Language Models (LLMs) have recently advanced many applications on\nsoftware engineering tasks, particularly the potential for code generation.\nAmong contemporary challenges, code generated by LLMs often suffers from\ninaccuracies and hallucinations, requiring external inputs to correct. One\nrecent strategy to fix these issues is to refine the code generated from LLMs\nusing the input from the model itself (self-augmented). In this work, we\nproposed a novel method, namely CoT-SelfEvolve. CoT-SelfEvolve iteratively and\nautomatically refines code through a self-correcting process, guided by a chain\nof thought constructed from real-world programming problem feedback. Focusing\non data science code, including Python libraries such as NumPy and Pandas, our\nevaluations on the DS-1000 dataset demonstrate that CoT-SelfEvolve\nsignificantly outperforms existing models in solving complex problems. The\nframework shows substantial improvements in both initial code generation and\nsubsequent iterations, with the model's accuracy increasing significantly with\neach additional iteration. This highlights the effectiveness of using\nchain-of-thought prompting to address complexities revealed by program executor\ntraceback error messages. We also discuss how CoT-SelfEvolve can be integrated\ninto continuous software engineering environments, providing a practical\nsolution for improving LLM-based code generation.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8fd1\u671f\u5728\u8edf\u9ad4\u5de5\u7a0b\u4efb\u52d9\u4e2d\u63a8\u9032\u8a31\u591a\u61c9\u7528\u7a0b\u5f0f\uff0c\u7279\u5225\u662f\u7a0b\u5f0f\u78bc\u7522\u751f\u7684\u6f5b\u529b\u3002\u5728\u7576\u4ee3\u6311\u6230\u4e2d\uff0cLLM \u751f\u6210\u7684\u7a0b\u5f0f\u78bc\u5e38\u5e38\u6709\u932f\u8aa4\u548c\u5e7b\u89ba\uff0c\u9700\u8981\u5916\u90e8\u8f38\u5165\u4f86\u4fee\u6b63\u3002\u6700\u8fd1\u4e00\u7a2e\u4fee\u6b63\u9019\u4e9b\u554f\u984c\u7684\u7b56\u7565\u662f\u4f7f\u7528\u6a21\u578b\u672c\u8eab\u7684\u8f38\u5165 (\u81ea\u6211\u589e\u5f37) \u4f86\u6539\u5584 LLM \u751f\u6210\u7684\u7a0b\u5f0f\u78bc\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5275\u65b0\u7684\u65b9\u6cd5\uff0c\u4e5f\u5c31\u662f CoT-SelfEvolve\u3002CoT-SelfEvolve \u900f\u904e\u81ea\u6211\u4fee\u6b63\u7684\u904e\u7a0b\uff0c\u8fed\u4ee3\u4e14\u81ea\u52d5\u6539\u5584\u7a0b\u5f0f\u78bc\uff0c\u4e26\u7531\u5f9e\u771f\u5be6\u4e16\u754c\u7a0b\u5f0f\u8a2d\u8a08\u554f\u984c\u56de\u994b\u5efa\u69cb\u7684\u601d\u8003\u93c8\u5f15\u5c0e\u3002\u6211\u5011\u91dd\u5c0d\u8cc7\u6599\u79d1\u5b78\u7a0b\u5f0f\u78bc\u9032\u884c\u8a55\u4f30\uff0c\u5305\u62ec NumPy \u548c Pandas \u7b49 Python \u51fd\u5f0f\u5eab\uff0c\u5728 DS-1000 \u8cc7\u6599\u96c6\u4e0a\u7684\u8a55\u4f30\u8b49\u660e\uff0cCoT-SelfEvolve \u5728\u89e3\u6c7a\u8907\u96dc\u554f\u984c\u4e0a\u986f\u8457\u512a\u65bc\u73fe\u6709\u6a21\u578b\u3002\u9019\u500b\u67b6\u69cb\u5728\u521d\u59cb\u7a0b\u5f0f\u78bc\u7522\u751f\u548c\u5f8c\u7e8c\u8fed\u4ee3\u4e2d\u90fd\u986f\u793a\u51fa\u5927\u5e45\u9032\u6b65\uff0c\u6a21\u578b\u7684\u6e96\u78ba\u5ea6\u6703\u96a8\u8457\u6bcf\u6b21\u984d\u5916\u7684\u8fed\u4ee3\u800c\u986f\u8457\u589e\u52a0\u3002\u9019\u7a81\u986f\u4e86\u4f7f\u7528\u601d\u8003\u93c8\u63d0\u793a\u4f86\u89e3\u6c7a\u7a0b\u5f0f\u57f7\u884c\u5668\u8ffd\u8e64\u932f\u8aa4\u8a0a\u606f\u6240\u63ed\u9732\u7684\u8907\u96dc\u6027\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u4e5f\u8a0e\u8ad6 CoT-SelfEvolve \u5982\u4f55\u6574\u5408\u5230\u6301\u7e8c\u8edf\u9ad4\u5de5\u7a0b\u74b0\u5883\u4e2d\uff0c\u63d0\u4f9b\u4e00\u500b\u6539\u5584\u57fa\u65bc LLM \u7684\u7a0b\u5f0f\u78bc\u7522\u751f\u7684\u5be6\u969b\u89e3\u6c7a\u65b9\u6848\u3002", "author": "Thai Tang Quoc et.al.", "authors": "Thai Tang Quoc, Duc Ha Minh, Tho Quan Thanh, Anh Nguyen-Duc", "id": "2408.15658v1", "paper_url": "http://arxiv.org/abs/2408.15658v1", "repo": "null"}}