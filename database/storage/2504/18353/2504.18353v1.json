{"2504.18353": {"publish_time": "2025-04-25", "title": "Testing Individual Fairness in Graph Neural Networks", "paper_summary": "The biases in artificial intelligence (AI) models can lead to automated\ndecision-making processes that discriminate against groups and/or individuals\nbased on sensitive properties such as gender and race. While there are many\nstudies on diagnosing and mitigating biases in various AI models, there is\nlittle research on individual fairness in Graph Neural Networks (GNNs). Unlike\ntraditional models, which treat data features independently and overlook their\ninter-relationships, GNNs are designed to capture graph-based structure where\nnodes are interconnected. This relational approach enables GNNs to model\ncomplex dependencies, but it also means that biases can propagate through these\nconnections, complicating the detection and mitigation of individual fairness\nviolations. This PhD project aims to develop a testing framework to assess and\nensure individual fairness in GNNs. It first systematically reviews the\nliterature on individual fairness, categorizing existing approaches to define,\nmeasure, test, and mitigate model biases, creating a taxonomy of individual\nfairness. Next, the project will develop a framework for testing and ensuring\nfairness in GNNs by adapting and extending current fairness testing and\nmitigation techniques. The framework will be evaluated through industrial case\nstudies, focusing on graph-based large language models.", "paper_summary_zh": "\u4eba\u5de5\u667a\u6167 (AI) \u6a21\u578b\u4e2d\u7684\u504f\u5dee\u53ef\u80fd\u5c0e\u81f4\u81ea\u52d5\u6c7a\u7b56\u904e\u7a0b\uff0c\u57fa\u65bc\u6027\u5225\u548c\u7a2e\u65cf\u7b49\u654f\u611f\u5c6c\u6027\u6b67\u8996\u7fa4\u9ad4\u548c/\u6216\u500b\u4eba\u3002\u96d6\u7136\u6709\u8a31\u591a\u95dc\u65bc\u8a3a\u65b7\u548c\u6e1b\u8f15\u5404\u7a2e AI \u6a21\u578b\u504f\u5dee\u7684\u7814\u7a76\uff0c\u4f46\u95dc\u65bc\u5716\u795e\u7d93\u7db2\u8def (GNN) \u4e2d\u500b\u9ad4\u516c\u5e73\u6027\u7684\u7814\u7a76\u537b\u5f88\u5c11\u3002\u8207\u7368\u7acb\u8655\u7406\u6578\u64da\u7279\u5fb5\u4e26\u5ffd\u7565\u5176\u76f8\u4e92\u95dc\u4fc2\u7684\u50b3\u7d71\u6a21\u578b\u4e0d\u540c\uff0cGNN \u65e8\u5728\u6355\u7372\u7bc0\u9ede\u76f8\u4e92\u9023\u63a5\u7684\u57fa\u65bc\u5716\u7684\u7d50\u69cb\u3002\u9019\u7a2e\u95dc\u4fc2\u65b9\u6cd5\u4f7f GNN \u80fd\u5920\u5c0d\u8907\u96dc\u7684\u4f9d\u8cf4\u95dc\u4fc2\u9032\u884c\u5efa\u6a21\uff0c\u4f46\u9019\u4e5f\u610f\u5473\u8457\u504f\u5dee\u53ef\u4ee5\u901a\u904e\u9019\u4e9b\u9023\u63a5\u50b3\u64ad\uff0c\u5f9e\u800c\u4f7f\u6aa2\u6e2c\u548c\u6e1b\u8f15\u500b\u9ad4\u516c\u5e73\u6027\u9055\u898f\u884c\u70ba\u8b8a\u5f97\u66f4\u52a0\u8907\u96dc\u3002\u9019\u500b\u535a\u58eb\u7814\u7a76\u9805\u76ee\u65e8\u5728\u958b\u767c\u4e00\u500b\u6e2c\u8a66\u6846\u67b6\u4f86\u8a55\u4f30\u548c\u78ba\u4fdd GNN \u4e2d\u7684\u500b\u9ad4\u516c\u5e73\u6027\u3002\u5b83\u9996\u5148\u7cfb\u7d71\u5730\u56de\u9867\u4e86\u95dc\u65bc\u500b\u9ad4\u516c\u5e73\u6027\u7684\u6587\u737b\uff0c\u5c07\u73fe\u6709\u7684\u5b9a\u7fa9\u3001\u6e2c\u91cf\u3001\u6e2c\u8a66\u548c\u6e1b\u8f15\u6a21\u578b\u504f\u5dee\u7684\u65b9\u6cd5\u9032\u884c\u5206\u985e\uff0c\u5275\u5efa\u4e86\u4e00\u500b\u500b\u9ad4\u516c\u5e73\u6027\u5206\u985e\u6cd5\u3002\u63a5\u4e0b\u4f86\uff0c\u8a72\u9805\u76ee\u5c07\u901a\u904e\u8abf\u6574\u548c\u64f4\u5c55\u73fe\u6709\u7684\u516c\u5e73\u6027\u6e2c\u8a66\u548c\u6e1b\u8f15\u6280\u8853\u4f86\u958b\u767c\u4e00\u500b\u6e2c\u8a66\u548c\u78ba\u4fdd GNN \u516c\u5e73\u6027\u7684\u6846\u67b6\u3002\u8a72\u6846\u67b6\u5c07\u901a\u904e\u7522\u696d\u6848\u4f8b\u7814\u7a76\u9032\u884c\u8a55\u4f30\uff0c\u91cd\u9ede\u95dc\u6ce8\u57fa\u65bc\u5716\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u3002\n", "author": "Roya Nasiri et.al.", "authors": "Roya Nasiri", "id": "2504.18353v1", "paper_url": "http://arxiv.org/abs/2504.18353v1", "repo": "null"}}