{"2407.10377": {"publish_time": "2024-07-15", "title": "Enhanced Self-supervised Learning for Multi-modality MRI Segmentation and Classification: A Novel Approach Avoiding Model Collapse", "paper_summary": "Multi-modality magnetic resonance imaging (MRI) can provide complementary\ninformation for computer-aided diagnosis. Traditional deep learning algorithms\nare suitable for identifying specific anatomical structures segmenting lesions\nand classifying diseases with magnetic resonance images. However, manual labels\nare limited due to high expense, which hinders further improvement of model\naccuracy. Self-supervised learning (SSL) can effectively learn feature\nrepresentations from unlabeled data by pre-training and is demonstrated to be\neffective in natural image analysis. Most SSL methods ignore the similarity of\nmulti-modality MRI, leading to model collapse. This limits the efficiency of\npre-training, causing low accuracy in downstream segmentation and\nclassification tasks. To solve this challenge, we establish and validate a\nmulti-modality MRI masked autoencoder consisting of hybrid mask pattern (HMP)\nand pyramid barlow twin (PBT) module for SSL on multi-modality MRI analysis.\nThe HMP concatenates three masking steps forcing the SSL to learn the semantic\nconnections of multi-modality images by reconstructing the masking patches. We\nhave proved that the proposed HMP can avoid model collapse. The PBT module\nexploits the pyramidal hierarchy of the network to construct barlow twin loss\nbetween masked and original views, aligning the semantic representations of\nimage patches at different vision scales in latent space. Experiments on\nBraTS2023, PI-CAI, and lung gas MRI datasets further demonstrate the\nsuperiority of our framework over the state-of-the-art. The performance of the\nsegmentation and classification is substantially enhanced, supporting the\naccurate detection of small lesion areas. The code is available at\nhttps://github.com/LinxuanHan/M2-MAE.", "paper_summary_zh": "\u591a\u6a21\u614b\u78c1\u5171\u632f\u6210\u50cf (MRI) \u80fd\u70ba\u96fb\u8166\u8f14\u52a9\u8a3a\u65b7\u63d0\u4f9b\u4e92\u88dc\u8cc7\u8a0a\u3002\u50b3\u7d71\u6df1\u5ea6\u5b78\u7fd2\u6f14\u7b97\u6cd5\u9069\u7528\u65bc\u8b58\u5225\u7279\u5b9a\u7684\u89e3\u5256\u7d50\u69cb\u3001\u5206\u5272\u75c5\u7076\u4e26\u4f7f\u7528\u78c1\u5171\u632f\u5f71\u50cf\u5c0d\u75be\u75c5\u9032\u884c\u5206\u985e\u3002\u7136\u800c\uff0c\u624b\u52d5\u6a19\u7c64\u7531\u65bc\u8cbb\u7528\u9ad8\u6602\u800c\u53d7\u5230\u9650\u5236\uff0c\u9019\u963b\u7919\u4e86\u6a21\u578b\u7cbe\u78ba\u5ea6\u7684\u9032\u4e00\u6b65\u63d0\u5347\u3002\u81ea\u76e3\u7763\u5b78\u7fd2 (SSL) \u80fd\u900f\u904e\u9810\u8a13\u7df4\u6709\u6548\u5730\u5f9e\u672a\u6a19\u7c64\u7684\u8cc7\u6599\u4e2d\u5b78\u7fd2\u7279\u5fb5\u8868\u5fb5\uff0c\u4e26\u8b49\u660e\u5176\u5728\u81ea\u7136\u5f71\u50cf\u5206\u6790\u4e2d\u662f\u6709\u6548\u7684\u3002\u5927\u591a\u6578 SSL \u65b9\u6cd5\u5ffd\u7565\u4e86\u591a\u6a21\u614b MRI \u7684\u76f8\u4f3c\u6027\uff0c\u5c0e\u81f4\u6a21\u578b\u5d29\u6f70\u3002\u9019\u9650\u5236\u4e86\u9810\u8a13\u7df4\u7684\u6548\u7387\uff0c\u5c0e\u81f4\u4e0b\u6e38\u5206\u5272\u548c\u5206\u985e\u4efb\u52d9\u7684\u6e96\u78ba\u5ea6\u964d\u4f4e\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u6311\u6230\uff0c\u6211\u5011\u5efa\u7acb\u4e26\u9a57\u8b49\u4e86\u4e00\u500b\u591a\u6a21\u614b MRI \u906e\u7f69\u81ea\u52d5\u7de8\u78bc\u5668\uff0c\u5b83\u7531\u6df7\u5408\u906e\u7f69\u6a21\u5f0f (HMP) \u548c\u91d1\u5b57\u5854 Barlow \u96d9\u80de\u80ce (PBT) \u6a21\u7d44\u7d44\u6210\uff0c\u7528\u65bc\u591a\u6a21\u614b MRI \u5206\u6790\u7684 SSL\u3002HMP \u4e32\u63a5\u4e09\u500b\u906e\u7f69\u6b65\u9a5f\uff0c\u5f37\u8feb SSL \u900f\u904e\u91cd\u5efa\u906e\u7f69\u8cbc\u7247\u4f86\u5b78\u7fd2\u591a\u6a21\u614b\u5f71\u50cf\u7684\u8a9e\u7fa9\u9023\u63a5\u3002\u6211\u5011\u5df2\u7d93\u8b49\u660e\uff0c\u6240\u63d0\u51fa\u7684 HMP \u80fd\u907f\u514d\u6a21\u578b\u5d29\u6f70\u3002PBT \u6a21\u7d44\u5229\u7528\u7db2\u8def\u7684\u91d1\u5b57\u5854\u5c64\u7d1a\u4f86\u5efa\u69cb\u906e\u7f69\u548c\u539f\u59cb\u6aa2\u8996\u4e4b\u9593\u7684 Barlow \u96d9\u80de\u80ce\u640d\u5931\uff0c\u5728\u6f5b\u5728\u7a7a\u9593\u4e2d\u5c0d\u9f4a\u4e0d\u540c\u8996\u89ba\u5c3a\u5ea6\u5f71\u50cf\u8cbc\u7247\u7684\u8a9e\u7fa9\u8868\u5fb5\u3002\u5728 BraTS2023\u3001PI-CAI \u548c\u80ba\u90e8\u6c23\u9ad4 MRI \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u9032\u4e00\u6b65\u8b49\u660e\u4e86\u6211\u5011\u6846\u67b6\u512a\u65bc\u73fe\u6709\u6280\u8853\u3002\u5206\u5272\u548c\u5206\u985e\u7684\u6548\u80fd\u986f\u8457\u63d0\u5347\uff0c\u652f\u63f4\u6e96\u78ba\u5075\u6e2c\u5c0f\u75c5\u7076\u5340\u57df\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/LinxuanHan/M2-MAE \u53d6\u5f97\u3002", "author": "Linxuan Han et.al.", "authors": "Linxuan Han, Sa Xiao, Zimeng Li, Haidong Li, Xiuchao Zhao, Fumin Guo, Yeqing Han, Xin Zhou", "id": "2407.10377v1", "paper_url": "http://arxiv.org/abs/2407.10377v1", "repo": "https://github.com/linxuanhan/m2-mae"}}