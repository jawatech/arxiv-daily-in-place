{"2411.18038": {"publish_time": "2024-11-27", "title": "VLM-HOI: Vision Language Models for Interpretable Human-Object Interaction Analysis", "paper_summary": "The Large Vision Language Model (VLM) has recently addressed remarkable\nprogress in bridging two fundamental modalities. VLM, trained by a sufficiently\nlarge dataset, exhibits a comprehensive understanding of both visual and\nlinguistic to perform diverse tasks. To distill this knowledge accurately, in\nthis paper, we introduce a novel approach that explicitly utilizes VLM as an\nobjective function form for the Human-Object Interaction (HOI) detection task\n(\\textbf{VLM-HOI}). Specifically, we propose a method that quantifies the\nsimilarity of the predicted HOI triplet using the Image-Text matching\ntechnique. We represent HOI triplets linguistically to fully utilize the\nlanguage comprehension of VLMs, which are more suitable than CLIP models due to\ntheir localization and object-centric nature. This matching score is used as an\nobjective for contrastive optimization. To our knowledge, this is the first\nutilization of VLM language abilities for HOI detection. Experiments\ndemonstrate the effectiveness of our method, achieving state-of-the-art HOI\ndetection accuracy on benchmarks. We believe integrating VLMs into HOI\ndetection represents important progress towards more advanced and interpretable\nanalysis of human-object interactions.", "paper_summary_zh": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM) \u6700\u8fd1\u5728\u6865\u63a5\u4e24\u79cd\u57fa\u672c\u6a21\u6001\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u7740\u8fdb\u5c55\u3002\u7531\u8db3\u591f\u5927\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u7684 VLM\uff0c\u5c55\u793a\u4e86\u5bf9\u89c6\u89c9\u548c\u8bed\u8a00\u7684\u5168\u9762\u7406\u89e3\uff0c\u4ee5\u6267\u884c\u5404\u79cd\u4efb\u52a1\u3002\u4e3a\u4e86\u51c6\u786e\u5730\u63d0\u70bc\u51fa\u8fd9\u79cd\u77e5\u8bc6\uff0c\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u660e\u786e\u5730\u5c06 VLM \u7528\u4f5c\u4eba\u7c7b-\u7269\u4f53\u4ea4\u4e92 (HOI) \u68c0\u6d4b\u4efb\u52a1\u7684\u76ee\u6807\u51fd\u6570\u5f62\u5f0f\uff08VLM-HOI\uff09\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u56fe\u50cf-\u6587\u672c\u5339\u914d\u6280\u672f\u91cf\u5316\u9884\u6d4b\u7684 HOI \u4e09\u5143\u7ec4\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u7528\u8bed\u8a00\u8868\u793a HOI \u4e09\u5143\u7ec4\uff0c\u4ee5\u5145\u5206\u5229\u7528 VLM \u7684\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff0c\u7531\u4e8e\u5176\u5b9a\u4f4d\u548c\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u7279\u70b9\uff0c\u6bd4 CLIP \u6a21\u578b\u66f4\u5408\u9002\u3002\u8fd9\u4e2a\u5339\u914d\u5206\u6570\u88ab\u7528\u4f5c\u5bf9\u6bd4\u4f18\u5316\u76ee\u6807\u3002\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u662f\u9996\u6b21\u5c06 VLM \u8bed\u8a00\u80fd\u529b\u7528\u4e8e HOI \u68c0\u6d4b\u3002\u5b9e\u9a8c\u8868\u660e\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684 HOI \u68c0\u6d4b\u51c6\u786e\u5ea6\u3002\u6211\u4eec\u76f8\u4fe1\u5c06 VLM \u96c6\u6210\u5230 HOI \u68c0\u6d4b\u4e2d\u4ee3\u8868\u4e86\u671d\u5411\u66f4\u9ad8\u7ea7\u548c\u66f4\u53ef\u89e3\u91ca\u7684\u4eba\u7c7b-\u7269\u4f53\u4ea4\u4e92\u5206\u6790\u7684\u91cd\u8981\u8fdb\u6b65\u3002", "author": "Donggoo Kang et.al.", "authors": "Donggoo Kang, Dasol Jeong, Hyunmin Lee, Sangwoo Park, Hasil Park, Sunkyu Kwon, Yeongjoon Kim, Joonki Paik", "id": "2411.18038v1", "paper_url": "http://arxiv.org/abs/2411.18038v1", "repo": "null"}}