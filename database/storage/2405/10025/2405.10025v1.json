{"2405.10025": {"publish_time": "2024-05-16", "title": "Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models", "paper_summary": "Recent advances in large language models (LLMs) have promoted generative\nerror correction (GER) for automatic speech recognition (ASR), which aims to\npredict the ground-truth transcription from the decoded N-best hypotheses.\nThanks to the strong language generation ability of LLMs and rich information\nin the N-best list, GER shows great effectiveness in enhancing ASR results.\nHowever, it still suffers from two limitations: 1) LLMs are unaware of the\nsource speech during GER, which may lead to results that are grammatically\ncorrect but violate the source speech content, 2) N-best hypotheses usually\nonly vary in a few tokens, making it redundant to send all of them for GER,\nwhich could confuse LLM about which tokens to focus on and thus lead to\nincreased miscorrection. In this paper, we propose ClozeGER, a new paradigm for\nASR generative error correction. First, we introduce a multimodal LLM (i.e.,\nSpeechGPT) to receive source speech as extra input to improve the fidelity of\ncorrection output. Then, we reformat GER as a cloze test with logits\ncalibration to remove the input information redundancy and simplify GER with\nclear instructions. Experiments show that ClozeGER achieves a new breakthrough\nover vanilla GER on 9 popular ASR datasets.", "paper_summary_zh": "\u6700\u8fd1\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u8fdb\u6b65\u4fc3\u8fdb\u4e86\u751f\u6210\u5f0f\u9519\u8bef\u6821\u6b63 (GER)\uff0c\u7528\u4e8e\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b (ASR)\uff0c\u5176\u76ee\u6807\u662f\u4ece\u89e3\u7801\u540e\u7684 N \u4e2a\u6700\u4f73\u5047\u8bbe\u4e2d\u9884\u6d4b\u771f\u5b9e\u8f6c\u5f55\u3002\n\u7531\u4e8e LLM \u5f3a\u5927\u7684\u8bed\u8a00\u751f\u6210\u80fd\u529b\u548c N \u4e2a\u6700\u4f73\u5217\u8868\u4e2d\u7684\u4e30\u5bcc\u4fe1\u606f\uff0cGER \u5728\u589e\u5f3a ASR \u7ed3\u679c\u65b9\u9762\u663e\u793a\u51fa\u6781\u4f73\u7684\u6709\u6548\u6027\u3002\n\u7136\u800c\uff0c\u5b83\u4ecd\u7136\u5b58\u5728\u4e24\u4e2a\u9650\u5236\uff1a1) LLM \u5728 GER \u671f\u95f4\u4e0d\u77e5\u9053\u6e90\u8bed\u97f3\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u7ed3\u679c\u5728\u8bed\u6cd5\u4e0a\u6b63\u786e\uff0c\u4f46\u8fdd\u53cd\u6e90\u8bed\u97f3\u5185\u5bb9\uff0c2) N \u4e2a\u6700\u4f73\u5047\u8bbe\u901a\u5e38\u53ea\u5728\u51e0\u4e2a\u6807\u8bb0\u4e2d\u6709\u6240\u4e0d\u540c\uff0c\u56e0\u6b64\u5c06\u5b83\u4eec\u5168\u90e8\u53d1\u9001\u5230 GER \u662f\u591a\u4f59\u7684\uff0c\u8fd9\u53ef\u80fd\u4f1a\u6df7\u6dc6 LLM \u5e94\u8be5\u5173\u6ce8\u54ea\u4e9b\u6807\u8bb0\uff0c\u4ece\u800c\u5bfc\u81f4\u9519\u8bef\u6821\u6b63\u589e\u52a0\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 ClozeGER\uff0c\u8fd9\u662f\u4e00\u79cd\u7528\u4e8e ASR \u751f\u6210\u5f0f\u9519\u8bef\u6821\u6b63\u7684\u65b0\u8303\u4f8b\u3002\u9996\u5148\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u591a\u6a21\u6001 LLM\uff08\u5373 SpeechGPT\uff09\u6765\u63a5\u6536\u6e90\u8bed\u97f3\u4f5c\u4e3a\u989d\u5916\u7684\u8f93\u5165\uff0c\u4ee5\u63d0\u9ad8\u6821\u6b63\u8f93\u51fa\u7684\u4fdd\u771f\u5ea6\u3002\u7136\u540e\uff0c\u6211\u4eec\u5c06 GER \u91cd\u65b0\u683c\u5f0f\u5316\u4e3a\u5b8c\u5f62\u586b\u7a7a\u6d4b\u8bd5\uff0c\u5e76\u8fdb\u884c logit \u6821\u51c6\uff0c\u4ee5\u6d88\u9664\u8f93\u5165\u4fe1\u606f\u5197\u4f59\u5e76\u7b80\u5316 GER\uff0c\u5e76\u63d0\u4f9b\u660e\u786e\u7684\u8bf4\u660e\u3002\u5b9e\u9a8c\u8868\u660e\uff0cClozeGER \u5728 9 \u4e2a\u6d41\u884c\u7684 ASR \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u5bf9\u9999\u8349 GER \u7684\u65b0\u7a81\u7834\u3002", "author": "Yuchen Hu et.al.", "authors": "Yuchen Hu, Chen Chen, Chengwei Qin, Qiushi Zhu, Eng Siong Chng, Ruizhe Li", "id": "2405.10025v1", "paper_url": "http://arxiv.org/abs/2405.10025v1", "repo": "null"}}