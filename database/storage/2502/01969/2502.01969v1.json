{"2502.01969": {"publish_time": "2025-02-04", "title": "Mitigating Object Hallucinations in Large Vision-Language Models via Attention Calibration", "paper_summary": "Large Vision-Language Models (LVLMs) exhibit impressive multimodal reasoning\ncapabilities but remain highly susceptible to object hallucination, where\nmodels generate responses that are not factually aligned with the visual\ncontent. Recent works attribute this issue to an inherent bias of LVLMs where\nvision token attention map has a fixed correlation with spatial position, and\npropose to mitigate this issue by reordering visual tokens. However, we find\nthat different LVLMs exhibit different correlations between attention and\nspatial position, which makes the existing solution difficult to generalize to\nother LVLMs. To address this issue, we first introduce a training-free\nsolution, Uniform Attention Calibration (UAC), that estimates the bias from\nsingle meaningless input image and applies a calibration matrix to rectify\nattention imbalances. To further alleviate the bias, we relax the assumption of\nsingle meaningless input in UAC and introduce a fine-tuning solution, Dynamic\nAttention Calibration (DAC), that enforces the consistent outputs wherever the\nobject locates in the image via a plug-and-plays module. Comprehensive\nexperiments across multiple benchmarks demonstrate that UAC and DAC\nsignificantly reduce object hallucination while improving general multimodal\nalignment. Our methods achieve state-of-the-art performance across diverse LVLM\narchitectures on various metrics.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u5c55\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u591a\u6a21\u614b\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4ecd\u6975\u6613\u53d7\u5230\u7269\u4ef6\u5e7b\u89ba\u7684\u5f71\u97ff\uff0c\u5176\u4e2d\u6a21\u578b\u6703\u7522\u751f\u8207\u8996\u89ba\u5167\u5bb9\u5728\u4e8b\u5be6\u4e0a\u4e0d\u4e00\u81f4\u7684\u56de\u61c9\u3002\u6700\u8fd1\u7684\u7814\u7a76\u5c07\u6b64\u554f\u984c\u6b78\u56e0\u65bc LVLMs \u7684\u5167\u5728\u504f\u5dee\uff0c\u5176\u4e2d\u8996\u89ba\u6a19\u8a18\u6ce8\u610f\u529b\u5716\u8207\u7a7a\u9593\u4f4d\u7f6e\u5177\u6709\u56fa\u5b9a\u7684\u95dc\u806f\u6027\uff0c\u4e26\u63d0\u51fa\u900f\u904e\u91cd\u65b0\u6392\u5e8f\u8996\u89ba\u6a19\u8a18\u4f86\u6e1b\u8f15\u6b64\u554f\u984c\u3002\u7136\u800c\uff0c\u6211\u5011\u767c\u73fe\u4e0d\u540c\u7684 LVLMs \u5728\u6ce8\u610f\u529b\u548c\u7a7a\u9593\u4f4d\u7f6e\u4e4b\u9593\u5c55\u73fe\u51fa\u4e0d\u540c\u7684\u95dc\u806f\u6027\uff0c\u9019\u4f7f\u5f97\u73fe\u6709\u7684\u89e3\u6c7a\u65b9\u6848\u96e3\u4ee5\u6982\u62ec\u5230\u5176\u4ed6 LVLMs\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u9996\u5148\u5f15\u5165\u4e86\u4e00\u500b\u514d\u8a13\u7df4\u89e3\u6c7a\u65b9\u6848\uff0c\u5373\u5747\u52fb\u6ce8\u610f\u529b\u6821\u6e96 (UAC)\uff0c\u5b83\u5f9e\u55ae\u4e00\u7684\u7121\u610f\u7fa9\u8f38\u5165\u5f71\u50cf\u4e2d\u4f30\u8a08\u504f\u5dee\uff0c\u4e26\u5957\u7528\u6821\u6e96\u77e9\u9663\u4f86\u4fee\u6b63\u6ce8\u610f\u529b\u5931\u8861\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u6e1b\u8f15\u504f\u5dee\uff0c\u6211\u5011\u653e\u5bec\u4e86 UAC \u4e2d\u55ae\u4e00\u7121\u610f\u7fa9\u8f38\u5165\u7684\u5047\u8a2d\uff0c\u4e26\u5f15\u5165\u4e86\u4e00\u500b\u5fae\u8abf\u89e3\u6c7a\u65b9\u6848\uff0c\u5373\u52d5\u614b\u6ce8\u610f\u529b\u6821\u6e96 (DAC)\uff0c\u5b83\u900f\u904e\u4e00\u500b\u5373\u63d2\u5373\u7528\u7684\u6a21\u7d44\uff0c\u5728\u7269\u4ef6\u4f4d\u65bc\u5f71\u50cf\u4e2d\u7684\u4efb\u4f55\u4f4d\u7f6e\uff0c\u5f37\u5236\u57f7\u884c\u4e00\u81f4\u7684\u8f38\u51fa\u3002\u8de8\u591a\u500b\u57fa\u6e96\u7684\u5168\u9762\u5be6\u9a57\u8b49\u660e\uff0cUAC \u548c DAC \u5728\u6539\u5584\u4e00\u822c\u591a\u6a21\u614b\u5c0d\u9f4a\u7684\u540c\u6642\uff0c\u986f\u8457\u6e1b\u5c11\u4e86\u7269\u4ef6\u5e7b\u89ba\u3002\u6211\u5011\u7684\u6280\u8853\u5728\u5404\u7a2e\u6307\u6a19\u4e0a\uff0c\u65bc\u4e0d\u540c\u7684 LVLM \u67b6\u69cb\u4e2d\uff0c\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\u3002", "author": "Younan Zhu et.al.", "authors": "Younan Zhu, Linwei Tao, Minjing Dong, Chang Xu", "id": "2502.01969v1", "paper_url": "http://arxiv.org/abs/2502.01969v1", "repo": "null"}}