
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-24**|**Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking**|Xi Wang et.al.|[2409.16287v1](http://arxiv.org/abs/2409.16287v1)|null|
|**2024-09-24**|**Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation**|Hannah Kerner et.al.|[2409.16252v1](http://arxiv.org/abs/2409.16252v1)|null|
|**2024-09-24**|**A fast and sound tagging method for discontinuous named-entity recognition**|Caio Corro et.al.|[2409.16243v1](http://arxiv.org/abs/2409.16243v1)|null|
|**2024-09-24**|**LLM Echo Chamber: personalized and automated disinformation**|Tony Ma et.al.|[2409.16241v1](http://arxiv.org/abs/2409.16241v1)|[link](https://github.com/iamtonymwt/echo_chamber)|
|**2024-09-24**|**Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules**|Jonathan Feldstein et.al.|[2409.16238v1](http://arxiv.org/abs/2409.16238v1)|null|
|**2024-09-24**|**EuroLLM: Multilingual Language Models for Europe**|Pedro Henrique Martins et.al.|[2409.16235v1](http://arxiv.org/abs/2409.16235v1)|null|
|**2024-09-24**|**Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**|Henry Musto et.al.|[2409.16231v1](http://arxiv.org/abs/2409.16231v1)|null|
|**2024-09-24**|**Fine-Tuning is Fine, if Calibrated**|Zheda Mai et.al.|[2409.16223v1](http://arxiv.org/abs/2409.16223v1)|null|
|**2024-09-24**|**Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models**|Omar Mussa et.al.|[2409.16220v1](http://arxiv.org/abs/2409.16220v1)|null|
|**2024-09-24**|**Problem-oriented AutoML in Clustering**|Matheus Camilo da Silva et.al.|[2409.16218v1](http://arxiv.org/abs/2409.16218v1)|null|
|**2024-09-24**|**Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech**|Yunji Chu et.al.|[2409.16203v1](http://arxiv.org/abs/2409.16203v1)|null|
|**2024-09-24**|**CJEval: A Benchmark for Assessing Large Language Models Using Chinese Junior High School Exam Data**|Qian-Wen Zhang et.al.|[2409.16202v2](http://arxiv.org/abs/2409.16202v2)|[link](https://github.com/smilewhc/cjeval)|
|**2024-09-24**|**Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking**|Jun Bai et.al.|[2409.16198v1](http://arxiv.org/abs/2409.16198v1)|null|
|**2024-09-24**|**HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models**|Haoran Que et.al.|[2409.16191v1](http://arxiv.org/abs/2409.16191v1)|[link](https://github.com/quehry/hellobench)|
|**2024-09-24**|**Cyber Knowledge Completion Using Large Language Models**|Braden K Webb et.al.|[2409.16176v1](http://arxiv.org/abs/2409.16176v1)|null|
|**2024-09-24**|**Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering**|Ziyu Zhao et.al.|[2409.16167v1](http://arxiv.org/abs/2409.16167v1)|null|
|**2024-09-24**|**EnIGMA: Enhanced Interactive Generative Model Agent for CTF Challenges**|Talor Abramovich et.al.|[2409.16165v1](http://arxiv.org/abs/2409.16165v1)|[link](https://github.com/princeton-nlp/swe-agent)|
|**2024-09-24**|**Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework**|Lu Chen et.al.|[2409.16146v1](http://arxiv.org/abs/2409.16146v1)|null|
|**2024-09-24**|**Seeing Faces in Things: A Model and Dataset for Pareidolia**|Mark Hamilton et.al.|[2409.16143v1](http://arxiv.org/abs/2409.16143v1)|null|
|**2024-09-24**|**HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection**|Yuqi Ma et.al.|[2409.16136v1](http://arxiv.org/abs/2409.16136v1)|null|
|**2024-09-24**|**Implicit assessment of language learning during practice as accurate as explicit testing**|Jue Hou et.al.|[2409.16133v1](http://arxiv.org/abs/2409.16133v1)|null|
|**2024-09-24**|**Analyzing Probabilistic Methods for Evaluating Agent Capabilities**|Axel Højmark et.al.|[2409.16125v1](http://arxiv.org/abs/2409.16125v1)|null|
|**2024-09-24**|**MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents**|Ming Zhu et.al.|[2409.16120v1](http://arxiv.org/abs/2409.16120v1)|[link](https://github.com/ghost-in-moss/ghostos)|
|**2024-09-24**|**Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**|Mehtab Ur Rahman et.al.|[2409.16106v1](http://arxiv.org/abs/2409.16106v1)|null|
|**2024-09-24**|**Neuromorphic Drone Detection: an Event-RGB Multimodal Approach**|Gabriele Magrini et.al.|[2409.16099v1](http://arxiv.org/abs/2409.16099v1)|null|
|**2024-09-24**|**Exploring Hint Generation Approaches in Open-Domain Question Answering**|Jamshid Mozafari et.al.|[2409.16096v1](http://arxiv.org/abs/2409.16096v1)|[link](https://github.com/datascienceuibk/hintqa)|
|**2024-09-24**|**From Pixels to Words: Leveraging Explainability in Face Recognition through Interactive Natural Language Processing**|Ivan DeAndres-Tame et.al.|[2409.16089v1](http://arxiv.org/abs/2409.16089v1)|null|
|**2024-09-24**|**Online Multi-level Contrastive Representation Distillation for Cross-Subject fNIRS Emotion Recognition**|Zhili Lai et.al.|[2409.16081v1](http://arxiv.org/abs/2409.16081v1)|null|
|**2024-09-24**|**Leveraging Mixture of Experts for Improved Speech Deepfake Detection**|Viola Negroni et.al.|[2409.16077v1](http://arxiv.org/abs/2409.16077v1)|null|
|**2024-09-24**|**Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis**|Xianda Zhang et.al.|[2409.16057v1](http://arxiv.org/abs/2409.16057v1)|null|
|**2024-09-24**|**Adversarial Watermarking for Face Recognition**|Yuguang Yao et.al.|[2409.16056v1](http://arxiv.org/abs/2409.16056v1)|null|
|**2024-09-24**|**Whole-body end-effector pose tracking**|Tifanny Portela et.al.|[2409.16048v1](http://arxiv.org/abs/2409.16048v1)|null|
|**2024-09-24**|**LTNtorch: PyTorch Implementation of Logic Tensor Networks**|Tommaso Carraro et.al.|[2409.16045v1](http://arxiv.org/abs/2409.16045v1)|[link](https://github.com/tommasocarraro/ltntorch)|
|**2024-09-24**|**Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts**|Xiaoming Shi et.al.|[2409.16040v1](http://arxiv.org/abs/2409.16040v1)|[link](https://github.com/time-moe/time-moe)|
|**2024-09-24**|**Grounded Computation & Consciousness: A Framework for Exploring Consciousness in Machines & Other Organisms**|Ryan Williams et.al.|[2409.16036v1](http://arxiv.org/abs/2409.16036v1)|null|
|**2024-09-24**|**Deep chroma compression of tone-mapped images**|Xenios Milidonis et.al.|[2409.16032v1](http://arxiv.org/abs/2409.16032v1)|[link](https://github.com/DeepCamera/HDR-chroma-compression)|
|**2024-09-24**|**Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering**|Yifei Yuan et.al.|[2409.16025v1](http://arxiv.org/abs/2409.16025v1)|null|
|**2024-09-24**|**Bridging Environments and Language with Rendering Functions and Vision-Language Models**|Theo Cachet et.al.|[2409.16024v1](http://arxiv.org/abs/2409.16024v1)|null|
|**2024-09-24**|**AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessment**|Nuo Chen et.al.|[2409.16022v1](http://arxiv.org/abs/2409.16022v1)|null|
|**2024-09-24**|**Bridging Speech and Text: Enhancing ASR with Pinyin-to-Character Pre-training in LLMs**|Yang Yuhang et.al.|[2409.16005v1](http://arxiv.org/abs/2409.16005v1)|null|
|**2024-09-24**|**Artificial Human Intelligence: The role of Humans in the Development of Next Generation AI**|Suayb S. Arslan et.al.|[2409.16001v1](http://arxiv.org/abs/2409.16001v1)|null|
|**2024-09-24**|**Improvements to SDXL in NovelAI Diffusion V3**|Juan Ossa et.al.|[2409.15997v1](http://arxiv.org/abs/2409.15997v1)|null|
|**2024-09-24**|**DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL**|Lixia Wu et.al.|[2409.15985v1](http://arxiv.org/abs/2409.15985v1)|null|
|**2024-09-24**|**Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection**|Yunbo Long et.al.|[2409.15980v1](http://arxiv.org/abs/2409.15980v1)|null|
|**2024-09-24**|**Finetuning LLMs for Comparative Assessment Tasks**|Vatsal Raina et.al.|[2409.15979v1](http://arxiv.org/abs/2409.15979v1)|null|
|**2024-09-24**|**StyleSinger 2: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control**|Yu Zhang et.al.|[2409.15977v1](http://arxiv.org/abs/2409.15977v1)|[link](https://github.com/AaronZ345/StyleSinger2)|
|**2024-09-24**|**Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification**|Fengrun Zhang et.al.|[2409.15974v1](http://arxiv.org/abs/2409.15974v1)|null|
|**2024-09-24**|**Creating Healthy Friction: Determining Stakeholder Requirements of Job Recommendation Explanations**|Roan Schellingerhout et.al.|[2409.15971v1](http://arxiv.org/abs/2409.15971v1)|[link](https://github.com/roan-schellingerhout/evaluating_job_recommendations)|
|**2024-09-24**|**ASD-Diffusion: Anomalous Sound Detection with Diffusion Models**|Fengrun Zhang et.al.|[2409.15957v1](http://arxiv.org/abs/2409.15957v1)|null|
|**2024-09-24**|**Historical Trajectory Assisted Zeroth-Order Federated Optimization**|Xiaoyu He et.al.|[2409.15955v2](http://arxiv.org/abs/2409.15955v2)|null|
|**2024-09-24**|**Beats of Bias: Analyzing Lyrics with Topic Modeling and Gender Bias Measurements**|Danqing Chen et.al.|[2409.15949v1](http://arxiv.org/abs/2409.15949v1)|null|
|**2024-09-24**|**TSFeatLIME: An Online User Study in Enhancing Explainability in Univariate Time Series Forecasting**|Hongnan Ma et.al.|[2409.15950v1](http://arxiv.org/abs/2409.15950v1)|[link](https://github.com/ts-xai/whyforecast)|
|**2024-09-24**|**Automated test generation to evaluate tool-augmented LLMs as conversational AI agents**|Samuel Arcadinho et.al.|[2409.15934v1](http://arxiv.org/abs/2409.15934v1)|null|
|**2024-09-24**|**SLIMER-IT: Zero-Shot NER on Italian Language**|Andrew Zamai et.al.|[2409.15933v1](http://arxiv.org/abs/2409.15933v1)|[link](https://github.com/andrewzamai/slimer_it)|
|**2024-09-24**|**Multilingual Transfer and Domain Adaptation for Low-Resource Languages of Spain**|Yuanchang Luo et.al.|[2409.15924v1](http://arxiv.org/abs/2409.15924v1)|null|
|**2024-09-24**|**Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts**|Sukai Huang et.al.|[2409.15915v1](http://arxiv.org/abs/2409.15915v1)|null|
|**2024-09-24**|**Explaining word embeddings with perfect fidelity: Case study in research impact prediction**|Lucie Dvorackova et.al.|[2409.15912v1](http://arxiv.org/abs/2409.15912v1)|null|
|**2024-09-24**|**A Modular-based Strategy for Mitigating Gradient Conflicts in Simultaneous Speech Translation**|Xiaoqian Liu et.al.|[2409.15911v1](http://arxiv.org/abs/2409.15911v1)|null|
|**2024-09-24**|**Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**|Kriti Agarwal et.al.|[2409.15910v1](http://arxiv.org/abs/2409.15910v1)|null|
|**2024-09-24**|**Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection**|Xingyu Ma et.al.|[2409.15907v1](http://arxiv.org/abs/2409.15907v1)|null|
|**2024-09-24**|**Boosting Code-Switching ASR with Mixture of Experts Enhanced Speech-Conditioned LLM**|Fengrun Zhang et.al.|[2409.15905v1](http://arxiv.org/abs/2409.15905v1)|null|
|**2024-09-24**|**Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**|Maria Lysyuk et.al.|[2409.15902v1](http://arxiv.org/abs/2409.15902v1)|[link](https://github.com/s-nlp/konstruktor)|
|**2024-09-24**|**Symmetries and Expressive Requirements for Learning General Policies**|Dominik Drexler et.al.|[2409.15892v1](http://arxiv.org/abs/2409.15892v1)|null|
|**2024-09-24**|**HLB: Benchmarking LLMs' Humanlikeness in Language Use**|Xufeng Duan et.al.|[2409.15890v1](http://arxiv.org/abs/2409.15890v1)|null|
|**2024-09-24**|**Machine Translation Advancements of Low-Resource Indian Languages by Transfer Learning**|Bin Wei et.al.|[2409.15879v1](http://arxiv.org/abs/2409.15879v1)|null|
|**2024-09-24**|**Whisper in Medusa's Ear: Multi-head Efficient Decoding for Transformer-based ASR**|Yael Segal-Feldman et.al.|[2409.15869v1](http://arxiv.org/abs/2409.15869v1)|null|
|**2024-09-24**|**Privacy Evaluation Benchmarks for NLP Models**|Wei Huang et.al.|[2409.15868v2](http://arxiv.org/abs/2409.15868v2)|[link](https://github.com/user2311717757/nlp_doctor)|
|**2024-09-24**|**In-Context Ensemble Improves Video-Language Models for Low-Level Workflow Understanding from Human Demonstrations**|Moucheng Xu et.al.|[2409.15867v2](http://arxiv.org/abs/2409.15867v2)|[link](https://github.com/moucheng2017/action-labelling)|
|**2024-09-24**|**BeSimulator: A Large Language Model Powered Text-based Behavior Simulator**|Jianan Wang et.al.|[2409.15865v1](http://arxiv.org/abs/2409.15865v1)|null|
|**2024-09-24**|**A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding**|Abdulfattah Safa et.al.|[2409.15861v1](http://arxiv.org/abs/2409.15861v1)|[link](https://github.com/gglab-ku/open-vocab-dialogue-understanding)|
|**2024-09-24**|**Identification For Control Based on Neural Networks: Approximately Linearizable Models**|Maxime Thieffry et.al.|[2409.15858v1](http://arxiv.org/abs/2409.15858v1)|null|
|**2024-09-24**|**iGAiVA: Integrated Generative AI and Visual Analytics in a Machine Learning Workflow for Text Classification**|Yuanzhe Jin et.al.|[2409.15848v1](http://arxiv.org/abs/2409.15848v1)|[link](https://github.com/mattjin19/rbf)|
|**2024-09-24**|**Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection**|Matteo Zecchin et.al.|[2409.15844v1](http://arxiv.org/abs/2409.15844v1)|null|
|**2024-09-24**|**From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistant**|Anna Bodonhelyi et.al.|[2409.15843v1](http://arxiv.org/abs/2409.15843v1)|null|
|**2024-09-24**|**Unveiling Language Competence Neurons: A Psycholinguistic Approach to Model Interpretability**|Xufeng Duan et.al.|[2409.15827v1](http://arxiv.org/abs/2409.15827v1)|null|
|**2024-09-24**|**Empirical Insights on Fine-Tuning Large Language Models for Question-Answering**|Junjie Ye et.al.|[2409.15825v1](http://arxiv.org/abs/2409.15825v1)|null|
|**2024-09-24**|**Supervised Fine-Tuning: An Activation Pattern Optimization Process for Attention Heads**|Yang Zhao et.al.|[2409.15820v1](http://arxiv.org/abs/2409.15820v1)|null|
|**2024-09-24**|**SwiftDossier: Tailored Automatic Dossier for Drug Discovery with LLMs and Agents**|Gabriele Fossi et.al.|[2409.15817v1](http://arxiv.org/abs/2409.15817v1)|null|
|**2024-09-24**|**AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**|Adil Bahaj et.al.|[2409.15815v1](http://arxiv.org/abs/2409.15815v1)|null|
|**2024-09-24**|**Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2409.15814v1](http://arxiv.org/abs/2409.15814v1)|null|
|**2024-09-24**|**Layer-wise Model Merging for Unsupervised Domain Adaptation in Segmentation Tasks**|Roberto Alcover-Couso et.al.|[2409.15813v1](http://arxiv.org/abs/2409.15813v1)|null|
|**2024-09-24**|**CLSP: High-Fidelity Contrastive Language-State Pre-training for Agent State Representation**|Fuxian Huang et.al.|[2409.15806v1](http://arxiv.org/abs/2409.15806v1)|null|
|**2024-09-24**|**NER-Luxury: Named entity recognition for the fashion and luxury domain**|Akim Mousterou et.al.|[2409.15804v1](http://arxiv.org/abs/2409.15804v1)|null|
|**2024-09-24**|**Towards Universal Large-Scale Foundational Model for Natural Gas Demand Forecasting**|Xinxing Zhou et.al.|[2409.15794v1](http://arxiv.org/abs/2409.15794v1)|null|
|**2024-09-24**|**Small Language Models: Survey, Measurements, and Insights**|Zhenyan Lu et.al.|[2409.15790v1](http://arxiv.org/abs/2409.15790v1)|null|
|**2024-09-24**|**CHBench: A Chinese Dataset for Evaluating Health in Large Language Models**|Chenlu Guo et.al.|[2409.15766v1](http://arxiv.org/abs/2409.15766v1)|[link](https://github.com/tracyguo2001/chbench)|
|**2024-09-24**|**Spatial-Temporal Mixture-of-Graph-Experts for Multi-Type Crime Prediction**|Ziyang Wu et.al.|[2409.15764v1](http://arxiv.org/abs/2409.15764v1)|null|
|**2024-09-24**|**IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through Semantic Comprehension in Retrieval-Augmented Generation Scenarios**|Hai Lin et.al.|[2409.15763v1](http://arxiv.org/abs/2409.15763v1)|null|
|**2024-09-24**|**XTRUST: On the Multilingual Trustworthiness of Large Language Models**|Yahan Li et.al.|[2409.15762v1](http://arxiv.org/abs/2409.15762v1)|[link](https://github.com/lluckyyh/xtrust)|
|**2024-09-24**|**TFG: Unified Training-Free Guidance for Diffusion Models**|Haotian Ye et.al.|[2409.15761v1](http://arxiv.org/abs/2409.15761v1)|null|
|**2024-09-24**|**The Roles of Generative Artificial Intelligence in Internet of Electric Vehicles**|Hanwen Zhang et.al.|[2409.15750v1](http://arxiv.org/abs/2409.15750v1)|null|
|**2024-09-24**|**Automated Assessment of Multimodal Answer Sheets in the STEM domain**|Rajlaxmi Patil et.al.|[2409.15749v1](http://arxiv.org/abs/2409.15749v1)|null|
|**2024-09-24**|**Training Neural Networks for Modularity aids Interpretability**|Satvik Golechha et.al.|[2409.15747v1](http://arxiv.org/abs/2409.15747v1)|null|
|**2024-09-24**|**Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach**|Muhammad Dany Alfikri et.al.|[2409.15740v1](http://arxiv.org/abs/2409.15740v1)|null|
|**2024-09-24**|**EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition**|Ming Jin et.al.|[2409.15733v1](http://arxiv.org/abs/2409.15733v1)|null|
|**2024-09-24**|**Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous Driving**|Lingyu Xiao et.al.|[2409.15730v1](http://arxiv.org/abs/2409.15730v1)|null|
|**2024-09-24**|**Sequential Learning in the Dense Associative Memory**|Hayden McAlister et.al.|[2409.15729v1](http://arxiv.org/abs/2409.15729v1)|null|
|**2024-09-24**|**LLM-Cure: LLM-based Competitor User Review Analysis for Feature Enhancement**|Maram Assi et.al.|[2409.15724v1](http://arxiv.org/abs/2409.15724v1)|null|
|**2024-09-24**|**Federated Large Language Models: Current Progress and Future Directions**|Yuhang Yao et.al.|[2409.15723v1](http://arxiv.org/abs/2409.15723v1)|null|
|**2024-09-24**|**Adversarial Federated Consensus Learning for Surface Defect Classification Under Data Heterogeneity in IIoT**|Jixuan Cui et.al.|[2409.15711v1](http://arxiv.org/abs/2409.15711v1)|null|

#### Abstracts
##### **Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking**
2409.16287v1 by Xi Wang, Tianxing Chen, Qiaojun Yu, Tianling Xu, Zanxin Chen, Yiting Fu, Cewu Lu, Yao Mu, Ping Luo

Articulated object manipulation requires precise object interaction, where
the object's axis must be carefully considered. Previous research employed
interactive perception for manipulating articulated objects, but typically,
open-loop approaches often suffer from overlooking the interaction dynamics. To
address this limitation, we present a closed-loop pipeline integrating
interactive perception with online axis estimation from segmented 3D point
clouds. Our method leverages any interactive perception technique as a
foundation for interactive perception, inducing slight object movement to
generate point cloud frames of the evolving dynamic scene. These point clouds
are then segmented using Segment Anything Model 2 (SAM2), after which the
moving part of the object is masked for accurate motion online axis estimation,
guiding subsequent robotic actions. Our approach significantly enhances the
precision and efficiency of manipulation tasks involving articulated objects.
Experiments in simulated environments demonstrate that our method outperforms
baseline approaches, especially in tasks that demand precise axis-based
control. Project Page:
https://hytidel.github.io/video-tracking-for-axis-estimation/.

摘要：铰接物体操作需要精确的物体交互，其中必须仔细考虑物体的轴。先前的研究利用交互式感知来操作铰接物体，但通常，开环方法经常会忽略交互动态。为了解决这一限制，我们提出了一个闭环管道，将交互式感知与分段 3D 点云的在线轴估计相结合。我们的方法利用任何交互式感知技术作为交互式感知的基础，诱导轻微的物体运动以生成不断变化的动态场景的点云帧。然后使用 Segment Anything Model 2 (SAM2) 对这些点云进行分段，之后对物体的移动部分进行掩码处理以进行精确的运动在线轴估计，指导后续的机器人动作。我们的方法显着提高了涉及铰接物体的操作任务的精度和效率。模拟环境中的实验表明，我们的方法优于基线方法，尤其是在需要基于精确轴的控制的任务中。项目页面：
https://hytidel.github.io/video-tracking-for-axis-estimation/。

##### **Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation**
2409.16252v1 by Hannah Kerner, Snehal Chaudhari, Aninda Ghosh, Caleb Robinson, Adeel Ahmad, Eddie Choi, Nathan Jacobs, Chris Holmes, Matthias Mohr, Rahul Dodhia, Juan M. Lavista Ferres, Jennifer Marcus

Crop field boundaries are foundational datasets for agricultural monitoring
and assessments but are expensive to collect manually. Machine learning (ML)
methods for automatically extracting field boundaries from remotely sensed
images could help realize the demand for these datasets at a global scale.
However, current ML methods for field instance segmentation lack sufficient
geographic coverage, accuracy, and generalization capabilities. Further,
research on improving ML methods is restricted by the lack of labeled datasets
representing the diversity of global agricultural fields. We present Fields of
The World (FTW) -- a novel ML benchmark dataset for agricultural field instance
segmentation spanning 24 countries on four continents (Europe, Africa, Asia,
and South America). FTW is an order of magnitude larger than previous datasets
with 70,462 samples, each containing instance and semantic segmentation masks
paired with multi-date, multi-spectral Sentinel-2 satellite images. We provide
results from baseline models for the new FTW benchmark, show that models
trained on FTW have better zero-shot and fine-tuning performance in held-out
countries than models that aren't pre-trained with diverse datasets, and show
positive qualitative zero-shot results of FTW models in a real-world scenario
-- running on Sentinel-2 scenes over Ethiopia.

摘要：作物田界線是農業監測和評估的基本資料集，但人工收集成本昂貴。機器學習 (ML) 方法可自動從遙測影像中萃取田界線，有助於在全球規模實現這些資料集的需求。然而，目前的田區實例分割 ML 方法缺乏足夠的地理覆蓋範圍、準確度和概化能力。此外，改善 ML 方法的研究受到標記資料集缺乏代表全球農業田區多樣性的限制。我們提出世界田野 (FTW)——一種新的 ML 基準資料集，用於橫跨四大洲 (歐洲、非洲、亞洲和南美洲) 24 個國家的農業田區實例分割。FTW 的規模比先前的資料集大一個數量級，有 70,462 個樣本，每個樣本都包含實例和語義分割遮罩，並與多日期、多光譜 Sentinel-2 衛星影像配對。我們提供了新的 FTW 基準的基準模型結果，顯示在 FTW 上訓練的模型在未見過資料的國家中擁有比未經多樣化資料集預先訓練的模型更好的零次學習和微調效能，並在真實世界的場景中顯示 FTW 模型的正面定性零次學習結果——在衣索比亞上執行 Sentinel-2 場景。

##### **A fast and sound tagging method for discontinuous named-entity recognition**
2409.16243v1 by Caio Corro

We introduce a novel tagging scheme for discontinuous named entity
recognition based on an explicit description of the inner structure of
discontinuous mentions. We rely on a weighted finite state automaton for both
marginal and maximum a posteriori inference. As such, our method is sound in
the sense that (1) well-formedness of predicted tag sequences is ensured via
the automaton structure and (2) there is an unambiguous mapping between
well-formed sequences of tags and (discontinuous) mentions. We evaluate our
approach on three English datasets in the biomedical domain, and report
comparable results to state-of-the-art while having a way simpler and faster
model.

摘要：我們引入一種新穎的標記方案，用於不連續的命名實體識別，此方案基於不連續提及的內部結構的明確描述。我們依賴於加權有限狀態自動機，用於邊際和最大後驗推理。因此，我們的模型在以下意義上是完善的：(1) 預測標籤序列的良好形成性透過自動機結構得到保證，(2) 標籤的良好形成序列和 (不連續) 提及之間存在明確的對應。我們在生物醫學領域的三个英文資料集上評估了我們的方法，並報告了與最先進技術相當的結果，同時擁有更簡單、更快速的模型。

##### **LLM Echo Chamber: personalized and automated disinformation**
2409.16241v1 by Tony Ma

Recent advancements have showcased the capabilities of Large Language Models
like GPT4 and Llama2 in tasks such as summarization, translation, and content
review. However, their widespread use raises concerns, particularly around the
potential for LLMs to spread persuasive, humanlike misinformation at scale,
which could significantly influence public opinion. This study examines these
risks, focusing on LLMs ability to propagate misinformation as factual. To
investigate this, we built the LLM Echo Chamber, a controlled digital
environment simulating social media chatrooms, where misinformation often
spreads. Echo chambers, where individuals only interact with like minded
people, further entrench beliefs. By studying malicious bots spreading
misinformation in this environment, we can better understand this phenomenon.
We reviewed current LLMs, explored misinformation risks, and applied sota
finetuning techniques. Using Microsoft phi2 model, finetuned with our custom
dataset, we generated harmful content to create the Echo Chamber. This setup,
evaluated by GPT4 for persuasiveness and harmfulness, sheds light on the
ethical concerns surrounding LLMs and emphasizes the need for stronger
safeguards against misinformation.

摘要：最近的進展展示了大型語言模型 (LLM) 的能力，例如 GPT4 和 Llama2，在摘要、翻譯和內容審查等任務中的應用。然而，它們的廣泛使用引發了擔憂，特別是 LLM 可能大規模散布具有說服力的、類似人類的錯誤訊息，這可能會顯著影響公眾輿論。本研究探討了這些風險，重點關注 LLM 將錯誤訊息傳播為事實的能力。為了調查這一點，我們建立了 LLM 回音室，一個受控的數位環境，模擬社群媒體聊天室，錯誤訊息通常在其中散布。回音室，個人只與志同道合的人互動，進一步加深了信念。通過研究在這種環境中散布錯誤訊息的惡意機器人，我們可以更好地理解這種現象。我們回顧了目前的 LLM，探討了錯誤訊息的風險，並應用 sota 微調技術。使用 Microsoft phi2 模型，使用我們的自訂資料集進行微調，我們生成了有害內容以建立回音室。此設定由 GPT4 評估其說服力和危害性，揭示了圍繞 LLM 的道德問題，並強調了對抗錯誤訊息需要更強有力的保障措施。

##### **Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules**
2409.16238v1 by Jonathan Feldstein, Dominic Phillips, Efthymia Tsamoura

Probabilistic logical models are a core component of neurosymbolic AI and are
important models in their own right for tasks that require high explainability.
Unlike neural networks, logical models are often handcrafted using domain
expertise, making their development costly and prone to errors. While there are
algorithms that learn logical models from data, they are generally
prohibitively expensive, limiting their applicability in real-world settings.
In this work, we introduce precision and recall for logical rules and define
their composition as rule utility -- a cost-effective measure to evaluate the
predictive power of logical models. Further, we introduce SPECTRUM, a scalable
framework for learning logical models from relational data. Its scalability
derives from a linear-time algorithm that mines recurrent structures in the
data along with a second algorithm that, using the cheap utility measure,
efficiently ranks rules built from these structures. Moreover, we derive
theoretical guarantees on the utility of the learnt logical model. As a result,
SPECTRUM learns more accurate logical models orders of magnitude faster than
previous methods on real-world datasets.

摘要：機率邏輯模型是神經符號 AI 的核心組成部分，而且本身就是需要高可解釋性的任務中重要的模型。與神經網路不同，邏輯模型通常使用領域專業知識手工打造，這使得其開發成本高昂且容易出錯。雖然有從資料中學習邏輯模型的演算法，但它們通常成本高得令人難以接受，限制了它們在實際環境中的應用性。在這項工作中，我們引入了邏輯規則的準確度和召回率，並將它們的組合定義為規則效用，這是一種評估邏輯模型預測能力的經濟有效的方法。此外，我們還引入了 SPECTRUM，這是一個從關聯資料中學習邏輯模型的可擴充框架。它的可擴充性來自於一個線性時間演算法，該演算法會探勘資料中的遞迴結構，以及一個使用便宜效用測量值有效對從這些結構建立的規則進行排序的第二個演算法。此外，我們還推導出關於學習邏輯模型效用的理論保證。因此，SPECTRUM 比先前的實務資料集方法快上好幾個數量級，可以學習更準確的邏輯模型。

##### **EuroLLM: Multilingual Language Models for Europe**
2409.16235v1 by Pedro Henrique Martins, Patrick Fernandes, João Alves, Nuno M. Guerreiro, Ricardo Rei, Duarte M. Alves, José Pombal, Amin Farajian, Manuel Faysse, Mateusz Klimaszewski, Pierre Colombo, Barry Haddow, José G. C. de Souza, Alexandra Birch, André F. T. Martins

The quality of open-weight LLMs has seen significant improvement, yet they
remain predominantly focused on English. In this paper, we introduce the
EuroLLM project, aimed at developing a suite of open-weight multilingual LLMs
capable of understanding and generating text in all official European Union
languages, as well as several additional relevant languages. We outline the
progress made to date, detailing our data collection and filtering process, the
development of scaling laws, the creation of our multilingual tokenizer, and
the data mix and modeling configurations. Additionally, we release our initial
models: EuroLLM-1.7B and EuroLLM-1.7B-Instruct and report their performance on
multilingual general benchmarks and machine translation.

摘要：開放權重 LLM 的品質已大幅提升，但它們仍主要針對英語。在本文中，我們介紹 EuroLLM 計畫，其目標是開發一套開放權重多語言 LLM，能夠理解並產生所有歐盟官方語言以及其他數種相關語言的文字。我們概述至今的進度，詳細說明我們的資料收集和篩選程序、縮放定律的發展、多語言分詞器的建立，以及資料組合和建模設定。此外，我們發布我們的初始模型：EuroLLM-1.7B 和 EuroLLM-1.7B-Instruct，並報告它們在多語言一般基準和機器翻譯上的表現。

##### **Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**
2409.16231v1 by Henry Musto, Daniel Stamate, Doina Logofatu, Daniel Stahl

The paper proposes a novel approach of survival transformers and extreme
gradient boosting models in predicting cognitive deterioration in individuals
with mild cognitive impairment (MCI) using metabolomics data in the ADNI
cohort. By leveraging advanced machine learning and transformer-based
techniques applied in survival analysis, the proposed approach highlights the
potential of these techniques for more accurate early detection and
intervention in Alzheimer's dementia disease. This research also underscores
the importance of non-invasive biomarkers and innovative modelling tools in
enhancing the accuracy of dementia risk assessments, offering new avenues for
clinical practice and patient care. A comprehensive Monte Carlo simulation
procedure consisting of 100 repetitions of a nested cross-validation in which
models were trained and evaluated, indicates that the survival machine learning
models based on Transformer and XGBoost achieved the highest mean C-index
performances, namely 0.85 and 0.8, respectively, and that they are superior to
the conventional survival analysis Cox Proportional Hazards model which
achieved a mean C-Index of 0.77. Moreover, based on the standard deviations of
the C-Index performances obtained in the Monte Carlo simulation, we established
that both survival machine learning models above are more stable than the
conventional statistical model.

摘要：這篇論文提出了一種新的方法，使用 ADNI 隊伍中的代謝組學資料，在認知功能輕微受損 (MCI) 的個體中預測認知惡化，這種方法結合了生存轉換器和極端梯度提升模型。透過利用進階機器學習和基於轉換器的技術，應用於存活分析，提出的方法突顯了這些技術在阿茲海默症失智症中更準確的早期檢測和干預的潛力。這項研究也強調了非侵入性生物標記和創新建模工具在提升失智症風險評估準確度中的重要性，為臨床實務和病人照護提供了新途徑。一個包含 100 次巢狀交叉驗證重複的綜合蒙地卡羅模擬程序，其中模型經過訓練和評估，顯示基於轉換器和 XGBoost 的生存機器學習模型達到了最高的平均 C 指數表現，分別為 0.85 和 0.8，而且它們優於傳統的生存分析 Cox 比例風險模型，後者的平均 C 指數為 0.77。此外，根據蒙地卡羅模擬中獲得的 C 指數表現的標準差，我們確立了上述兩種生存機器學習模型都比傳統的統計模型更穩定。

##### **Fine-Tuning is Fine, if Calibrated**
2409.16223v1 by Zheda Mai, Arpita Chowdhury, Ping Zhang, Cheng-Hao Tu, Hong-You Chen, Vardaan Pahuja, Tanya Berger-Wolf, Song Gao, Charles Stewart, Yu Su, Wei-Lun Chao

Fine-tuning is arguably the most straightforward way to tailor a pre-trained
model (e.g., a foundation model) to downstream applications, but it also comes
with the risk of losing valuable knowledge the model had learned in
pre-training. For example, fine-tuning a pre-trained classifier capable of
recognizing a large number of classes to master a subset of classes at hand is
shown to drastically degrade the model's accuracy in the other classes it had
previously learned. As such, it is hard to further use the fine-tuned model
when it encounters classes beyond the fine-tuning data. In this paper, we
systematically dissect the issue, aiming to answer the fundamental question,
''What has been damaged in the fine-tuned model?'' To our surprise, we find
that the fine-tuned model neither forgets the relationship among the other
classes nor degrades the features to recognize these classes. Instead, the
fine-tuned model often produces more discriminative features for these other
classes, even if they were missing during fine-tuning! {What really hurts the
accuracy is the discrepant logit scales between the fine-tuning classes and the
other classes}, implying that a simple post-processing calibration would bring
back the pre-trained model's capability and at the same time unveil the feature
improvement over all classes. We conduct an extensive empirical study to
demonstrate the robustness of our findings and provide preliminary explanations
underlying them, suggesting new directions for future theoretical analysis. Our
code is available at
https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated.

摘要：微調無疑是針對預先訓練模型（例如基礎模型）以適應下游應用最直接的方法，但它也伴隨著失去模型在預先訓練中學到的寶貴知識的風險。例如，微調一個預先訓練的分類器，它能夠識別大量的類別，以掌握手邊的類別子集，這已被證明會大幅降低模型在先前學到的其他類別中的準確度。因此，當微調模型遇到微調數據之外的類別時，很難進一步使用它。在本文中，我們系統性地剖析了這個問題，旨在回答這個基本問題：「微調模型中損壞了什麼？」令我們驚訝的是，我們發現微調模型既不會忘記其他類別之間的關係，也不會降低識別這些類別的特徵。相反，微調模型通常會為這些其他類別產生更多具區別性的特徵，即使它們在微調過程中缺失！{真正損害準確度的是微調類別和其它類別之間不同的 logit 尺度}，這意味著一個簡單的後處理校準將會帶回預先訓練模型的能力，同時揭示所有類別的特徵改進。我們進行了一項廣泛的實證研究，以證明我們發現的穩健性，並提供了它們背後的初步解釋，為未來的理論分析提出了新的方向。我們的程式碼可以在 https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated 取得。

##### **Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models**
2409.16220v1 by Omar Mussa, Omer Rana, Benoît Goossens, Pablo Orozco-Terwengel, Charith Perera

Despite the recent broad adoption of Large Language Models (LLMs) across
various domains, their potential for enriching information systems in
extracting and exploring Linked Data (LD) and Resource Description Framework
(RDF) triplestores has not been extensively explored. This paper examines the
integration of LLMs within existing systems, emphasising the enhancement of
conversational user interfaces (UIs) and their capabilities for data extraction
by producing more accurate SPARQL queries without the requirement for model
retraining. Typically, conversational UI models necessitate retraining with the
introduction of new datasets or updates, limiting their functionality as
general-purpose extraction tools. Our approach addresses this limitation by
incorporating LLMs into the conversational UI workflow, significantly enhancing
their ability to comprehend and process user queries effectively. By leveraging
the advanced natural language understanding capabilities of LLMs, our method
improves RDF entity extraction within web systems employing conventional
chatbots. This integration facilitates a more nuanced and context-aware
interaction model, critical for handling the complex query patterns often
encountered in RDF datasets and Linked Open Data (LOD) endpoints. The
evaluation of this methodology shows a marked enhancement in system
expressivity and the accuracy of responses to user queries, indicating a
promising direction for future research in this area. This investigation not
only underscores the versatility of LLMs in enhancing existing information
systems but also sets the stage for further explorations into their potential
applications within more specialised domains of web information systems.

摘要：儘管大型語言模型 (LLM) 近期廣泛地被採用於各種領域，它們在豐富資訊系統中萃取和探索連結資料 (LD) 和資源描述架構 (RDF) 三聯儲存庫的潛力尚未被廣泛探討。本文探討在現有系統中整合 LLM，強調對話式使用者介面 (UI) 的強化，以及它們在無需重新訓練模型的情況下產生更精確的 SPARQL 查詢，以進行資料萃取的能力。一般來說，對話式 UI 模型需要在引入新的資料集或更新時重新訓練，這限制了它們作為通用萃取工具的功能。我們的做法透過將 LLM 整合到對話式 UI 工作流程中來解決這個限制，大幅提升它們理解和有效處理使用者查詢的能力。透過利用 LLM 的進階自然語言理解能力，我們的做法改善了採用傳統聊天機器人的網路系統中的 RDF 實體萃取。這種整合促成了一個更細緻且具備情境感知的互動模型，這對於處理 RDF 資料集和連結開放資料 (LOD) 端點中經常遇到的複雜查詢模式至關重要。對此方法的評估顯示系統表達能力和對使用者查詢回應的準確度都有顯著的提升，這表示此領域未來的研究有望朝這個方向發展。這項調查不僅強調了 LLM 在強化現有資訊系統方面的多功能性，也為進一步探索它們在更專業的網路資訊系統領域中的潛在應用奠定了基礎。

##### **Problem-oriented AutoML in Clustering**
2409.16218v1 by Matheus Camilo da Silva, Gabriel Marques Tavares, Eric Medvet, Sylvio Barbon Junior

The Problem-oriented AutoML in Clustering (PoAC) framework introduces a
novel, flexible approach to automating clustering tasks by addressing the
shortcomings of traditional AutoML solutions. Conventional methods often rely
on predefined internal Clustering Validity Indexes (CVIs) and static
meta-features, limiting their adaptability and effectiveness across diverse
clustering tasks. In contrast, PoAC establishes a dynamic connection between
the clustering problem, CVIs, and meta-features, allowing users to customize
these components based on the specific context and goals of their task. At its
core, PoAC employs a surrogate model trained on a large meta-knowledge base of
previous clustering datasets and solutions, enabling it to infer the quality of
new clustering pipelines and synthesize optimal solutions for unseen datasets.
Unlike many AutoML frameworks that are constrained by fixed evaluation metrics
and algorithm sets, PoAC is algorithm-agnostic, adapting seamlessly to
different clustering problems without requiring additional data or retraining.
Experimental results demonstrate that PoAC not only outperforms
state-of-the-art frameworks on a variety of datasets but also excels in
specific tasks such as data visualization, and highlight its ability to
dynamically adjust pipeline configurations based on dataset complexity.

摘要：問題導向式叢集自動化機器學習 (PoAC) 架構導入了一種
新穎且彈性的方法來自動化叢集任務，解決傳統自動化機器學習
解決方案的缺點。傳統方法通常依賴預先定義的內部叢集有效性
指標 (CVI) 和靜態元特徵，這限制了其在不同叢集任務中的適應
性和有效性。相反，PoAC 在叢集問題、CVI 和元特徵之間建立了
動態連接，使用戶能夠根據其任務的特定背景和目標自訂這些
組成部分。PoAC 的核心採用一個代理模型，該模型訓練於一個
大型元知識庫，其中包含先前的叢集資料集和解決方案，使其能
夠推斷新叢集管線的品質，並為未見資料集綜合最佳解決方案。
與許多受限於固定評估指標和演算法集的自動化機器學習架構
不同，PoAC 與演算法無關，能無縫地適應不同的叢集問題，而
無需額外資料或重新訓練。實驗結果證明，PoAC 不僅在各種資料
集上優於最先進的架構，而且在特定任務（例如資料視覺化）中
也表現出色，並突顯了其根據資料集複雜性動態調整管線組態的
能力。

##### **Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech**
2409.16203v1 by Yunji Chu, Yunseob Shim, Unsang Park

We propose FEIM-TTS, an innovative zero-shot text-to-speech (TTS) model that
synthesizes emotionally expressive speech, aligned with facial images and
modulated by emotion intensity. Leveraging deep learning, FEIM-TTS transcends
traditional TTS systems by interpreting facial cues and adjusting to emotional
nuances without dependence on labeled datasets. To address sparse
audio-visual-emotional data, the model is trained using LRS3, CREMA-D, and MELD
datasets, demonstrating its adaptability. FEIM-TTS's unique capability to
produce high-quality, speaker-agnostic speech makes it suitable for creating
adaptable voices for virtual characters. Moreover, FEIM-TTS significantly
enhances accessibility for individuals with visual impairments or those who
have trouble seeing. By integrating emotional nuances into TTS, our model
enables dynamic and engaging auditory experiences for webcomics, allowing
visually impaired users to enjoy these narratives more fully. Comprehensive
evaluation evidences its proficiency in modulating emotion and intensity,
advancing emotional speech synthesis and accessibility. Samples are available
at: https://feim-tts.github.io/.

摘要：我們提出 FEIM-TTS，這是一個創新的零次學習文字轉語音 (TTS) 模型，它可以合成富有情感表達力的語音，與面部影像對齊，並根據情緒強度進行調整。FEIM-TTS 透過深度學習超越傳統的 TTS 系統，它可以解讀面部線索並調整情緒細微差別，而無需依賴標記資料集。為了處理稀疏的視聽情緒資料，此模型使用 LRS3、CREMA-D 和 MELD 資料集進行訓練，展現其適應性。FEIM-TTS 具有獨特的能力，可以產生高品質、與說話者無關的語音，這使其適用於為虛擬角色創造可適應的聲音。此外，FEIM-TTS 大幅提升了視障人士或有視力問題者的無障礙性。透過將情緒細微差別整合到 TTS 中，我們的模型能為網路漫畫帶來動態且引人入勝的聽覺體驗，讓視障使用者能更充分享受這些敘事。全面的評估證明了其在調整情緒和強度方面的能力，進而推動了情緒語音合成和無障礙性。範例可在以下網址取得：https://feim-tts.github.io/。

##### **CJEval: A Benchmark for Assessing Large Language Models Using Chinese Junior High School Exam Data**
2409.16202v2 by Qian-Wen Zhang, Haochen Wang, Fang Li, Siyu An, Lingfeng Qiao, Liangcai Gao, Di Yin, Xing Sun

Online education platforms have significantly transformed the dissemination
of educational resources by providing a dynamic and digital infrastructure.
With the further enhancement of this transformation, the advent of Large
Language Models (LLMs) has elevated the intelligence levels of these platforms.
However, current academic benchmarks provide limited guidance for real-world
industry scenarios. This limitation arises because educational applications
require more than mere test question responses. To bridge this gap, we
introduce CJEval, a benchmark based on Chinese Junior High School Exam
Evaluations. CJEval consists of 26,136 samples across four application-level
educational tasks covering ten subjects. These samples include not only
questions and answers but also detailed annotations such as question types,
difficulty levels, knowledge concepts, and answer explanations. By utilizing
this benchmark, we assessed LLMs' potential applications and conducted a
comprehensive analysis of their performance by fine-tuning on various
educational tasks. Extensive experiments and discussions have highlighted the
opportunities and challenges of applying LLMs in the field of education.

摘要：線上教育平台透過提供動態且數位的基礎建設，大幅轉變了教育資源的傳播方式。隨著這項轉型的進一步加強，大型語言模型 (LLM) 的出現提升了這些平台的智慧層級。然而，目前的學術基準僅提供有限的指引，用於真實世界的產業情境。這個限制的產生，是因為教育應用程式需要的不只是單純的測驗問題解答。為了彌補這個差距，我們引入了 CJEval，一個基於中國初中考試評量的基準。CJEval 包含了 26,136 個範例，涵蓋了十個科目的四個應用層級教育任務。這些範例不僅包括題目和答案，也包含了詳細的註解，例如題型、難度等級、知識概念和答案說明。透過利用這個基準，我們評估了 LLM 的潛在應用，並透過微調各種教育任務，對其效能進行了全面的分析。廣泛的實驗和討論突顯了在教育領域應用 LLM 的機會和挑戰。

##### **Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking**
2409.16198v1 by Jun Bai, Zhuofan Chen, Zhenzi Li, Hanhua Hong, Jianfei Zhang, Chen Li, Chenghua Lin, Wenge Rong

Text ranking has witnessed significant advancements, attributed to the
utilization of dual-encoder enhanced by Pre-trained Language Models (PLMs).
Given the proliferation of available PLMs, selecting the most effective one for
a given dataset has become a non-trivial challenge. As a promising alternative
to human intuition and brute-force fine-tuning, Transferability Estimation (TE)
has emerged as an effective approach to model selection. However, current TE
methods are primarily designed for classification tasks, and their estimated
transferability may not align well with the objectives of text ranking. To
address this challenge, we propose to compute the expected rank as
transferability, explicitly reflecting the model's ranking capability.
Furthermore, to mitigate anisotropy and incorporate training dynamics, we
adaptively scale isotropic sentence embeddings to yield an accurate expected
rank score. Our resulting method, Adaptive Ranking Transferability (AiRTran),
can effectively capture subtle differences between models. On challenging model
selection scenarios across various text ranking datasets, it demonstrates
significant improvements over previous classification-oriented TE methods,
human intuition, and ChatGPT with minor time consumption.

摘要：文本排名已見證顯著進展，這歸功於由預訓練語言模型 (PLM) 增強的雙編碼器利用。
鑑於現有 PLM 的激增，為特定資料集選擇最有效的 PLM 已成為一項非凡的挑戰。作為人類直覺和蠻力微調的有希望的替代方案，可轉移性估計 (TE) 已成為模型選擇的一種有效方法。然而，目前的 TE 方法主要設計用於分類任務，且其估計的可轉移性可能與文本排名的目標不符。為了應對這一挑戰，我們提議將預期排名計算為可轉移性，明確反映模型的排名能力。
此外，為了減輕異方異性並納入訓練動態，我們自適應地調整各向同性句子嵌入以產生準確的預期排名分數。我們由此產生的方法，自適應排名可轉移性 (AiRTran)，可以有效捕捉模型之間的細微差異。在各種文本排名資料集中的具有挑戰性的模型選擇場景中，它展示了相較於先前的分類導向 TE 方法、人類直覺和 ChatGPT 的顯著改進，且耗時較少。

##### **HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models**
2409.16191v1 by Haoran Que, Feiyu Duan, Liqun He, Yutao Mou, Wangchunshu Zhou, Jiaheng Liu, Wenge Rong, Zekun Moore Wang, Jian Yang, Ge Zhang, Junran Peng, Zhaoxiang Zhang, Songyang Zhang, Kai Chen

In recent years, Large Language Models (LLMs) have demonstrated remarkable
capabilities in various tasks (e.g., long-context understanding), and many
benchmarks have been proposed. However, we observe that long text generation
capabilities are not well investigated. Therefore, we introduce the
Hierarchical Long Text Generation Benchmark (HelloBench), a comprehensive,
in-the-wild, and open-ended benchmark to evaluate LLMs' performance in
generating long text. Based on Bloom's Taxonomy, HelloBench categorizes long
text generation tasks into five subtasks: open-ended QA, summarization, chat,
text completion, and heuristic text generation. Besides, we propose
Hierarchical Long Text Evaluation (HelloEval), a human-aligned evaluation
method that significantly reduces the time and effort required for human
evaluation while maintaining a high correlation with human evaluation. We have
conducted extensive experiments across around 30 mainstream LLMs and observed
that the current LLMs lack long text generation capabilities. Specifically,
first, regardless of whether the instructions include explicit or implicit
length constraints, we observe that most LLMs cannot generate text that is
longer than 4000 words. Second, we observe that while some LLMs can generate
longer text, many issues exist (e.g., severe repetition and quality
degradation). Third, to demonstrate the effectiveness of HelloEval, we compare
HelloEval with traditional metrics (e.g., ROUGE, BLEU, etc.) and LLM-as-a-Judge
methods, which show that HelloEval has the highest correlation with human
evaluation. We release our code in https://github.com/Quehry/HelloBench.

摘要：近年来，大语言模型 (LLM) 在各种任务（例如，长文本理解）中展现出非凡的能力，并且已经提出了许多基准。然而，我们观察到长文本生成能力尚未得到充分研究。因此，我们引入了分层长文本生成基准 (HelloBench)，这是一个全面、真实的、开放式的基准，用于评估 LLM 在生成长文本方面的性能。基于布鲁姆分类法，HelloBench 将长文本生成任务分为五个子任务：开放式问答、摘要、聊天、文本完成和启发式文本生成。此外，我们提出了分层长文本评估 (HelloEval)，这是一种与人类一致的评估方法，它显著减少了人类评估所需的时间和精力，同时保持与人类评估的高度相关性。我们对大约 30 个主流 LLM 进行了广泛的实验，并观察到当前的 LLM 缺乏长文本生成能力。具体来说，首先，无论指令是否包含明确或隐含的长度限制，我们观察到大多数 LLM 都无法生成长度超过 4000 字的文本。其次，我们观察到虽然一些 LLM 可以生成更长的文本，但存在许多问题（例如，严重的重复和质量下降）。第三，为了证明 HelloEval 的有效性，我们将 HelloEval 与传统指标（例如，ROUGE、BLEU 等）和 LLM-as-a-Judge 方法进行了比较，结果表明 HelloEval 与人类评估的相关性最高。我们在 https://github.com/Quehry/HelloBench 中发布了我们的代码。

##### **Cyber Knowledge Completion Using Large Language Models**
2409.16176v1 by Braden K Webb, Sumit Purohit, Rounak Meyur

The integration of the Internet of Things (IoT) into Cyber-Physical Systems
(CPSs) has expanded their cyber-attack surface, introducing new and
sophisticated threats with potential to exploit emerging vulnerabilities.
Assessing the risks of CPSs is increasingly difficult due to incomplete and
outdated cybersecurity knowledge. This highlights the urgent need for
better-informed risk assessments and mitigation strategies. While previous
efforts have relied on rule-based natural language processing (NLP) tools to
map vulnerabilities, weaknesses, and attack patterns, recent advancements in
Large Language Models (LLMs) present a unique opportunity to enhance
cyber-attack knowledge completion through improved reasoning, inference, and
summarization capabilities. We apply embedding models to encapsulate
information on attack patterns and adversarial techniques, generating mappings
between them using vector embeddings. Additionally, we propose a
Retrieval-Augmented Generation (RAG)-based approach that leverages pre-trained
models to create structured mappings between different taxonomies of threat
patterns. Further, we use a small hand-labeled dataset to compare the proposed
RAG-based approach to a baseline standard binary classification model. Thus,
the proposed approach provides a comprehensive framework to address the
challenge of cyber-attack knowledge graph completion.

摘要：物聯網 (IoT) 與網路實體系統 (CPS) 的整合擴大了其網路攻擊面，引入了新的和複雜的威脅，具有利用新興漏洞的潛力。由於網路安全知識不完整且過時，評估 CPS 的風險變得越來越困難。這突顯了迫切需要更完善的風險評估和緩解策略。雖然先前的努力依賴於基於規則的自然語言處理 (NLP) 工具來繪製漏洞、弱點和攻擊模式，但大型語言模型 (LLM) 的最新進展提供了一個獨特的機會，可以透過改進的推理、推論和摘要能力來增強網路攻擊知識的完成度。我們應用嵌入模型來封裝有關攻擊模式和對抗技術的資訊，使用向量嵌入在它們之間產生對應關係。此外，我們提出了一個基於檢索增強生成 (RAG) 的方法，該方法利用預先訓練的模型在威脅模式的不同分類法之間建立結構化的對應關係。此外，我們使用一個小型的手動標記資料集來比較所提出的基於 RAG 的方法與基線標準二元分類模型。因此，所提出的方法提供了一個全面的架構來解決網路攻擊知識圖完成的挑戰。

##### **Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering**
2409.16167v1 by Ziyu Zhao, Tao Shen, Didi Zhu, Zexi Li, Jing Su, Xuwu Wang, Kun Kuang, Fei Wu

Low-Rank Adaptation (LoRA) has emerged as a popular technique for fine-tuning
large language models (LLMs) to various domains due to its modular design and
widespread availability on platforms like Huggingface. This modularity has
sparked interest in combining multiple LoRAs to enhance LLM capabilities.
However, existing methods for LoRA composition primarily focus on task-specific
adaptations that require additional training, and current model merging
techniques often fail to fully leverage LoRA's modular nature, leading to
parameter interference and performance degradation. In this paper, we
investigate the feasibility of disassembling and reassembling multiple LoRAs at
a finer granularity, analogous to assembling LEGO blocks. We introduce the
concept of Minimal Semantic Units (MSUs), where the parameters corresponding to
each rank in LoRA function as independent units. These MSUs demonstrate
permutation invariance and concatenation-summation equivalence properties,
enabling flexible combinations to create new LoRAs. Building on these insights,
we propose the LoRA-LEGO framework. This framework conducts rank-wise parameter
clustering by grouping MSUs from different LoRAs into $k$ clusters. The
centroid of each cluster serves as a representative MSU, enabling the assembly
of a merged LoRA with an adjusted rank of $k$. Additionally, we apply a dual
reweighting strategy to optimize the scale of the merged LoRA. Experiments
across various benchmarks demonstrate that our method outperforms existing
approaches in LoRA merging.

摘要：低秩適應 (LoRA) 已成為一種廣受歡迎的技術，用於微調大型語言模型 (LLM) 以適應各種領域，這是因為它具有模組化設計，且在 Huggingface 等平台上廣泛可用。這種模組化引起了人們對結合多個 LoRA 以增強 LLM 能力的興趣。然而，現有的 LoRA 組成方法主要集中於需要額外訓練的特定任務適應，而當前的模型合併技術通常無法充分利用 LoRA 的模組化特性，導致參數干擾和效能下降。在本文中，我們探討了以更精細的粒度分解和重新組裝多個 LoRA 的可行性，類似於組裝樂高積木。我們引入了最小語義單元 (MSU) 的概念，其中對應於 LoRA 中每個秩的參數作為獨立單元運作。這些 MSU 展示了排列不變性和串接加總等價性，允許靈活組合以創建新的 LoRA。基於這些見解，我們提出了 LoRA-LEGO 框架。此框架通過將來自不同 LoRA 的 MSU 分組到 $k$ 個叢集中，執行秩級參數分群。每個叢集的質心作為一個具代表性的 MSU，允許組裝一個秩調整為 $k$ 的合併 LoRA。此外，我們應用雙重重新加權策略來最佳化合併 LoRA 的規模。在各種基準測試中的實驗表明，我們的模型在 LoRA 合併中優於現有方法。

##### **EnIGMA: Enhanced Interactive Generative Model Agent for CTF Challenges**
2409.16165v1 by Talor Abramovich, Meet Udeshi, Minghao Shao, Kilian Lieret, Haoran Xi, Kimberly Milner, Sofija Jancheska, John Yang, Carlos E. Jimenez, Farshad Khorrami, Prashanth Krishnamurthy, Brendan Dolan-Gavitt, Muhammad Shafique, Karthik Narasimhan, Ramesh Karri, Ofir Press

Although language model (LM) agents are demonstrating growing potential in
many domains, their success in cybersecurity has been limited due to simplistic
design and the lack of fundamental features for this domain. We present EnIGMA,
an LM agent for autonomously solving Capture The Flag (CTF) challenges. EnIGMA
introduces new Agent-Computer Interfaces (ACIs) to improve the success rate on
CTF challenges. We establish the novel Interactive Agent Tool concept, which
enables LM agents to run interactive command-line utilities essential for these
challenges. Empirical analysis of EnIGMA on over 350 CTF challenges from three
different benchmarks indicates that providing a robust set of new tools with
demonstration of their usage helps the LM solve complex problems and achieves
state-of-the-art results on the NYU CTF and Intercode-CTF benchmarks. Finally,
we discuss insights on ACI design and agent behavior on cybersecurity tasks
that highlight the need to adapt real-world tools for LM agents.

摘要：儘管語言模型 (LM) 代理在許多領域展現出越來越大的潛力，但由於設計過於簡化以及缺乏此領域的基本功能，它們在網路安全方面的成功受到限制。我們提出 EnIGMA，一種用於自主解決奪旗 (CTF) 挑戰的 LM 代理。EnIGMA 引進新的代理電腦介面 (ACI)，以提高 CTF 挑戰的成功率。我們建立了新穎的互動代理工具概念，使 LM 代理能夠執行對這些挑戰至關重要的互動式命令列公用程式。EnIGMA 在來自三個不同基準的三百五十多個 CTF 挑戰中的實證分析表明，提供一組強大的新工具並示範其用法，有助於 LM 解決複雜問題，並在 NYU CTF 和 Intercode-CTF 基準上取得最先進的成果。最後，我們討論了 ACI 設計和網路安全任務中代理行為的見解，這些見解突顯了為 LM 代理調整真實世界工具的必要性。

##### **Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework**
2409.16146v1 by Lu Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng

Retrieval-augmented generation (RAG) has emerged as a popular solution to
mitigate the hallucination issues of large language models. However, existing
studies on RAG seldom address the issue of predictive uncertainty, i.e., how
likely it is that a RAG model's prediction is incorrect, resulting in
uncontrollable risks in real-world applications. In this work, we emphasize the
importance of risk control, ensuring that RAG models proactively refuse to
answer questions with low confidence. Our research identifies two critical
latent factors affecting RAG's confidence in its predictions: the quality of
the retrieved results and the manner in which these results are utilized. To
guide RAG models in assessing their own confidence based on these two latent
factors, we develop a counterfactual prompting framework that induces the
models to alter these factors and analyzes the effect on their answers. We also
introduce a benchmarking procedure to collect answers with the option to
abstain, facilitating a series of experiments. For evaluation, we introduce
several risk-related metrics and the experimental results demonstrate the
effectiveness of our approach.

摘要：檢索增強生成 (RAG) 已成為一種流行的解決方案，用於減輕大型語言模型的幻覺問題。然而，現有的 RAG 研究很少探討預測不確定性的問題，即 RAG 模型的預測不正確的可能性有多大，這會導致現實世界應用中的風險無法控制。在這項工作中，我們強調風險控制的重要性，確保 RAG 模型主動拒絕回答信心較低的問題。我們的研究確定了影響 RAG 對其預測信心的兩個關鍵潛在因素：檢索結果的品質和利用這些結果的方式。為了指導 RAG 模型根據這兩個潛在因素評估自己的信心，我們開發了一個反事實提示框架，誘導模型改變這些因素，並分析對其答案的影響。我們還引入了一個基準程序來收集具有棄權選項的答案，從而促進了一系列實驗。為了評估，我們引入了幾個與風險相關的指標，實驗結果證明了我們方法的有效性。

##### **Seeing Faces in Things: A Model and Dataset for Pareidolia**
2409.16143v1 by Mark Hamilton, Simon Stent, Vasha DuTell, Anne Harrington, Jennifer Corbett, Ruth Rosenholtz, William T. Freeman

The human visual system is well-tuned to detect faces of all shapes and
sizes. While this brings obvious survival advantages, such as a better chance
of spotting unknown predators in the bush, it also leads to spurious face
detections. ``Face pareidolia'' describes the perception of face-like structure
among otherwise random stimuli: seeing faces in coffee stains or clouds in the
sky. In this paper, we study face pareidolia from a computer vision
perspective. We present an image dataset of ``Faces in Things'', consisting of
five thousand web images with human-annotated pareidolic faces. Using this
dataset, we examine the extent to which a state-of-the-art human face detector
exhibits pareidolia, and find a significant behavioral gap between humans and
machines. We find that the evolutionary need for humans to detect animal faces,
as well as human faces, may explain some of this gap. Finally, we propose a
simple statistical model of pareidolia in images. Through studies on human
subjects and our pareidolic face detectors we confirm a key prediction of our
model regarding what image conditions are most likely to induce pareidolia.
Dataset and Website: https://aka.ms/faces-in-things

摘要：人類的視覺系統非常擅長偵測各種形狀和大小的臉孔。儘管這帶來顯而易見的生存優勢，例如在叢林中發現未知掠食者的機會更大，但也導致錯誤的臉孔偵測。**臉部錯視**描述在其他隨機刺激中感知到類似臉孔的結構：在咖啡漬或天空中的雲朵中看到臉孔。在本文中，我們從電腦視覺的角度研究臉部錯視。我們提供一個**事物中的臉孔**影像資料集，其中包含五千張標註有類似人類臉孔的網路圖片。使用這個資料集，我們檢視最先進的人臉偵測器展現臉部錯視的程度，並發現人類和機器之間有顯著的行為差異。我們發現人類在演化上需要偵測動物臉孔和人類臉孔，這可能是造成此差異的部分原因。最後，我們提出一個簡單的影像錯視統計模型。透過對人類受試者和我們的類似臉孔偵測器進行研究，我們確認了我們的模型關於最可能誘發錯視的影像條件的重要預測。資料集和網站：https://aka.ms/faces-in-things

##### **HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection**
2409.16136v1 by Yuqi Ma, Mengyin Liu, Chao Zhu, Xu-Cheng Yin

Open-vocabulary object detection (OVD) models are considered to be Large
Multi-modal Models (LMM), due to their extensive training data and a large
number of parameters. Mainstream OVD models prioritize object coarse-grained
category rather than focus on their fine-grained attributes, e.g., colors or
materials, thus failed to identify objects specified with certain attributes.
However, OVD models are pretrained on large-scale image-text pairs with rich
attribute words, whose latent feature space can represent the global text
feature as a linear composition of fine-grained attribute tokens without
highlighting them. Therefore, we propose in this paper a universal and explicit
approach for frozen mainstream OVD models that boosts their attribute-level
detection capabilities by highlighting fine-grained attributes in explicit
linear space. Firstly, a LLM is leveraged to highlight attribute words within
the input text as a zero-shot prompted task. Secondly, by strategically
adjusting the token masks, the text encoders of OVD models extract both global
text and attribute-specific features, which are then explicitly composited as
two vectors in linear space to form the new attribute-highlighted feature for
detection tasks, where corresponding scalars are hand-crafted or learned to
reweight both two vectors. Notably, these scalars can be seamlessly transferred
among different OVD models, which proves that such an explicit linear
composition is universal. Empirical evaluation on the FG-OVD dataset
demonstrates that our proposed method uniformly improves fine-grained
attribute-level OVD of various mainstream models and achieves new
state-of-the-art performance.

摘要：開放詞彙物件偵測 (OVD) 模型被視為大型多模態模型 (LMM)，因為它們的訓練資料廣泛，且參數數量龐大。主流 OVD 模型優先考量物件粗略的類別，而非專注於它們的細緻屬性，例如顏色或材質，因此無法識別具有特定屬性的物件。然而，OVD 模型經過預先訓練，擁有包含豐富屬性字詞的大規模影像文字配對，其潛在特徵空間可以將整體文字特徵表示為細緻屬性標記的線性組合，而不會強調它們。因此，我們在這篇論文中提出一個通用的明確方法，適用於凍結的主流 OVD 模型，透過在明確的線性空間中強調細緻屬性，提升它們的屬性層級偵測能力。首先，利用 LLM 在輸入文字中強調屬性字詞，作為零次提示任務。其次，透過策略性地調整標記遮罩，OVD 模型的文字編碼器會擷取整體文字和特定屬性的特徵，然後在線性空間中明確地將它們組合成兩個向量，以形成新的屬性強調特徵，用於偵測任務，其中對應的純量是手工製作或學習而得，用於重新加權這兩個向量。值得注意的是，這些純量可以在不同的 OVD 模型之間無縫傳輸，這證明了這種明確的線性組合是通用的。在 FG-OVD 資料集上的實證評估顯示，我們提出的方法一致地改善了各種主流模型的細緻屬性層級 OVD，並達到了新的最先進效能。

##### **Implicit assessment of language learning during practice as accurate as explicit testing**
2409.16133v1 by Jue Hou, Anisia Katinskaia, Anh-Duc Vu, Roman Yangarber

Assessment of proficiency of the learner is an essential part of Intelligent
Tutoring Systems (ITS). We use Item Response Theory (IRT) in computer-aided
language learning for assessment of student ability in two contexts: in test
sessions, and in exercises during practice sessions. Exhaustive testing across
a wide range of skills can provide a detailed picture of proficiency, but may
be undesirable for a number of reasons. Therefore, we first aim to replace
exhaustive tests with efficient but accurate adaptive tests. We use learner
data collected from exhaustive tests under imperfect conditions, to train an
IRT model to guide adaptive tests. Simulations and experiments with real
learner data confirm that this approach is efficient and accurate. Second, we
explore whether we can accurately estimate learner ability directly from the
context of practice with exercises, without testing. We transform learner data
collected from exercise sessions into a form that can be used for IRT modeling.
This is done by linking the exercises to {\em linguistic constructs}; the
constructs are then treated as "items" within IRT. We present results from
large-scale studies with thousands of learners. Using teacher assessments of
student ability as "ground truth," we compare the estimates obtained from tests
vs. those from exercises. The experiments confirm that the IRT models can
produce accurate ability estimation based on exercises.

摘要：評量學生的能力是智慧型教學系統（ITS）的必要部分。我們在電腦輔助語言學習中使用項目反應理論（IRT），在兩種情境中評量學生的能力：在測驗時，以及在練習時程中的練習。在各種技能中進行詳盡的測試，可以提供能力的詳細圖像，但可能因為許多原因而不可取。因此，我們首先目標是使用有效且精確的適應性測驗，來取代詳盡的測驗。我們使用在不完美條件下從詳盡測驗中收集到的學習者資料，來訓練一個 IRT 模型，以引導適應性測驗。模擬和使用真實學習者資料的實驗，證實此方法有效且精確。其次，我們探索是否可以在沒有測驗的情況下，直接從練習練習的脈絡中，精確地估計學習者的能力。我們將從練習時程中收集的學習者資料，轉換成可用於 IRT 建模的形式。這是透過將練習連結到「語言建構」來完成的；然後將建構視為 IRT 中的「項目」。我們提供來自數千名學習者的大規模研究結果。使用教師對學生能力的評量作為「基本事實」，我們比較從測驗中獲得的估計值與從練習中獲得的估計值。實驗證實，IRT 模型可以根據練習產生精確的能力估計。

##### **Analyzing Probabilistic Methods for Evaluating Agent Capabilities**
2409.16125v1 by Axel Højmark, Govind Pimpale, Arjun Panickssery, Marius Hobbhahn, Jérémy Scheurer

To mitigate risks from AI systems, we need to assess their capabilities
accurately. This is especially difficult in cases where capabilities are only
rarely displayed. Phuong et al. propose two methods that aim to obtain better
estimates of the probability of an AI agent successfully completing a given
task. The milestone method decomposes tasks into subtasks, aiming to improve
overall success rate estimation, while the expert best-of-N method leverages
human guidance as a proxy for the model's independent performance.
  Our analysis of these methods as Monte Carlo estimators reveals that while
both effectively reduce variance compared to naive Monte Carlo sampling, they
also introduce bias. Experimental results demonstrate that the milestone method
underestimates true solve rates for many real-world tasks due to its
constraining assumptions. The expert best-of-N method exhibits even more severe
underestimation across all tasks, attributed to an inherently flawed
re-weighting factor. To enhance the accuracy of capability estimates of AI
agents on difficult tasks, we suggest future work should leverage the rich
literature on Monte Carlo Estimators.

摘要：為了降低 AI 系統的風險，我們需要準確評估其功能。在功能僅偶爾顯示的情況下，這尤其困難。Phuong 等人提出了兩種方法，旨在獲得 AI 代理成功完成特定任務的機率的更好估計。里程碑方法將任務分解為子任務，旨在提高整體成功率估計，而專家最佳 N 方法則利用人類指導作為模型獨立性能的代理。我們對這些方法作為蒙地卡羅估計器的分析表明，雖然兩者都有效地降低了與樸素蒙地卡羅抽樣相比的變異，但它們也引入了偏差。實驗結果表明，由於其約束性假設，里程碑方法低估了許多實際任務的真實求解率。專家最佳 N 方法在所有任務中表現出更嚴重的低估，這歸因於固有的有缺陷的重新加權因子。為了提高 AI 代理在困難任務中的能力估計的準確性，我們建議未來的研究應利用蒙地卡羅估計器的豐富文獻。

##### **MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents**
2409.16120v1 by Ming Zhu, Yi Zhou

Developing AI agents powered by large language models (LLMs) faces
significant challenges in achieving true Turing completeness and adaptive,
code-driven evolution. Current approaches often generate code independently of
its runtime context, relying heavily on the LLM's memory, which results in
inefficiencies and limits adaptability. Manual protocol development in sandbox
environments further constrains the agent's autonomous adaptability. Crucially,
achieving consistency in code and context across multi-turn interactions and
ensuring isolation of local variables within each interaction remains an
unsolved problem.
  We introduce MOSS (llM-oriented Operating System Simulation), a novel
framework that addresses these challenges by integrating code generation with a
dynamic context management system. MOSS ensures consistency and adaptability by
using a mechanism that maintains the Python context across interactions,
including isolation of local variables and preservation of runtime integrity.
At its core, the framework employs an Inversion of Control (IoC) container in
conjunction with decorators to enforce the least knowledge principle, allowing
agents to focus on abstract interfaces rather than concrete implementations.
This facilitates seamless integration of new tools and libraries, enables
runtime instance replacement, and reduces prompt complexity, providing a "what
you see is what you get" environment for the agent.
  Through a series of case studies, we show how this framework can enhance the
efficiency and capabilities of agent development and highlight its advantages
in moving towards Turing-complete agents capable of evolving through code.

摘要：開發由大型語言模型（LLM）驅動的人工智慧代理程式在實現真正的圖靈完備性以及適應性、以程式碼為導向的演化方面面臨重大挑戰。目前的做法通常獨立於其執行時間上下文產生程式碼，嚴重依賴 LLM 的記憶體，這會導致效率低下並限制適應性。沙盒環境中的手動協定開發進一步限制了代理程式的自主適應性。至關重要的是，在多輪互動中實現程式碼和上下文的相容性，並確保每個互動中局部變數的隔離仍然是一個未解決的問題。
我們引入了 MOSS（面向 llM 的作業系統模擬），這是一個新穎的架構，它透過將程式碼產生與動態上下文管理系統整合來解決這些挑戰。MOSS 透過使用一種在互動中維護 Python 上下文的機制來確保相容性和適應性，包括隔離局部變數和保留執行時間完整性。在核心部分，該架構採用控制反轉 (IoC) 容器，並結合裝飾器來強制執行最少知識原則，讓代理程式能夠專注於抽象介面，而不是具體實作。這促進了新工具和函式庫的無縫整合，支援執行時間實例替換，並降低提示複雜性，為代理程式提供「所見即所得」的環境。
透過一系列案例研究，我們展示了這個架構如何增強代理程式開發的效率和能力，並強調其在朝向能夠透過程式碼演化的圖靈完備代理程式邁進的優勢。

##### **Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**
2409.16106v1 by Mehtab Ur Rahman, Martha Larson, Louis ten Bosch, Cristian Tejedor-García

Speech recordings are being more frequently used to detect and monitor
disease, leading to privacy concerns. Beyond cryptography, protection of speech
can be addressed by approaches, such as perturbation, disentanglement, and
re-synthesis, that eliminate sensitive information of the speaker, leaving the
information necessary for medical analysis purposes. In order for such privacy
protective approaches to be developed, clear and systematic specifications of
assumptions concerning medical settings and the needs of medical professionals
are necessary. In this paper, we propose a Scenario of Use Scheme that
incorporates an Attacker Model, which characterizes the adversary against whom
the speaker's privacy must be defended, and a Protector Model, which specifies
the defense. We discuss the connection of the scheme with previous work on
speech privacy. Finally, we present a concrete example of a specified Scenario
of Use and a set of experiments about protecting speaker data against gender
inference attacks while maintaining utility for Parkinson's detection.

摘要：語音錄音正越來越常被用於偵測和監控疾病，這引發了隱私問題。除了密碼學之外，語音保護還可以透過擾動、解糾纏和重新合成等方法來處理，這些方法消除了說話者的敏感資訊，只留下醫療分析目的所需的資訊。為了開發出此類隱私保護方法，必須明確且系統性地說明有關醫療環境和醫療專業人員需求的假設。在本文中，我們提出了一個使用情境方案，其中包含一個攻擊者模型，它描述了說話者隱私必須防範的對手，以及一個保護者模型，它指定了防禦措施。我們討論了該方案與先前關於語音隱私的研究之間的關聯。最後，我們提供了一個具體的指定使用情境範例，以及一組關於在維持帕金森氏症偵測效用的同時保護說話者資料免於性別推論攻擊的實驗。

##### **Neuromorphic Drone Detection: an Event-RGB Multimodal Approach**
2409.16099v1 by Gabriele Magrini, Federico Becattini, Pietro Pala, Alberto Del Bimbo, Antonio Porta

In recent years, drone detection has quickly become a subject of extreme
interest: the potential for fast-moving objects of contained dimensions to be
used for malicious intents or even terrorist attacks has posed attention to the
necessity for precise and resilient systems for detecting and identifying such
elements. While extensive literature and works exist on object detection based
on RGB data, it is also critical to recognize the limits of such modality when
applied to UAVs detection. Detecting drones indeed poses several challenges
such as fast-moving objects and scenes with a high dynamic range or, even
worse, scarce illumination levels. Neuromorphic cameras, on the other hand, can
retain precise and rich spatio-temporal information in situations that are
challenging for RGB cameras. They are resilient to both high-speed moving
objects and scarce illumination settings, while prone to suffer a rapid loss of
information when the objects in the scene are static. In this context, we
present a novel model for integrating both domains together, leveraging
multimodal data to take advantage of the best of both worlds. To this end, we
also release NeRDD (Neuromorphic-RGB Drone Detection), a novel
spatio-temporally synchronized Event-RGB Drone detection dataset of more than
3.5 hours of multimodal annotated recordings.

摘要：近年来，无人机检测已迅速成为极度关注的主题：尺寸受限的快速移动物体可能被用于恶意目的甚至恐怖袭击，这引起了人们对用于检测和识别此类元素的精确且有弹性的系统的必要性的关注。虽然基于 RGB 数据的对象检测存在大量文献和著作，但在将其应用于无人机检测时，认识到这种方式的局限性也至关重要。检测无人机确实会带来一些挑战，例如快速移动的物体和具有高动态范围的场景，或者更糟的是，光照水平不足。另一方面，神经形态相机可以在对于 RGB 相机而言具有挑战性的情况下保留精确且丰富的时空信息。它们既能抵御高速移动的物体，又能抵御光照不足的情况，但当场景中的物体静止时，它们容易迅速丢失信息。在此背景下，我们提出了一种将这两个域集成在一起的新颖模型，利用多模态数据来充分利用两全其美的优势。为此，我们还发布了 NeRDD（神经形态 RGB 无人机检测），这是一个新颖的时空同步事件 RGB 无人机检测数据集，其中包含超过 3.5 小时的多模态标注记录。

##### **Exploring Hint Generation Approaches in Open-Domain Question Answering**
2409.16096v1 by Jamshid Mozafari, Abdelrahman Abdallah, Bhawna Piryani, Adam Jatowt

Automatic Question Answering (QA) systems rely on contextual information to
provide accurate answers. Commonly, contexts are prepared through either
retrieval-based or generation-based methods. The former involves retrieving
relevant documents from a corpus like Wikipedia, whereas the latter uses
generative models such as Large Language Models (LLMs) to generate the context.
In this paper, we introduce a novel context preparation approach called HINTQA,
which employs Automatic Hint Generation (HG) techniques. Unlike traditional
methods, HINTQA prompts LLMs to produce hints about potential answers for the
question rather than generating relevant context. We evaluate our approach
across three QA datasets including TriviaQA, NaturalQuestions, and Web
Questions, examining how the number and order of hints impact performance. Our
findings show that the HINTQA surpasses both retrieval-based and
generation-based approaches. We demonstrate that hints enhance the accuracy of
answers more than retrieved and generated contexts.

摘要：自動問答 (QA) 系統依賴上下文資訊提供精確答案。一般來說，上下文是透過擷取式或生成式方法準備的。前者涉及從維基百科等語料庫中擷取相關文件，而後者使用生成式模型，例如大型語言模型 (LLM)，來產生上下文。在本文中，我們介紹一種稱為 HINTQA 的新穎上下文準備方法，它採用自動提示生成 (HG) 技術。與傳統方法不同，HINTQA 會提示 LLM 產生有關問題潛在答案的提示，而不是產生相關的上下文。我們在三個 QA 資料集（包括 TriviaQA、NaturalQuestions 和 Web Questions）中評估我們的做法，探討提示的數量和順序如何影響效能。我們的研究結果顯示，HINTQA 超越了基於擷取和基於生成的兩種方法。我們證明提示比擷取和生成的上下文更能增強答案的準確性。

##### **From Pixels to Words: Leveraging Explainability in Face Recognition through Interactive Natural Language Processing**
2409.16089v1 by Ivan DeAndres-Tame, Muhammad Faisal, Ruben Tolosana, Rouqaiah Al-Refai, Ruben Vera-Rodriguez, Philipp Terhörst

Face Recognition (FR) has advanced significantly with the development of deep
learning, achieving high accuracy in several applications. However, the lack of
interpretability of these systems raises concerns about their accountability,
fairness, and reliability. In the present study, we propose an interactive
framework to enhance the explainability of FR models by combining
model-agnostic Explainable Artificial Intelligence (XAI) and Natural Language
Processing (NLP) techniques. The proposed framework is able to accurately
answer various questions of the user through an interactive chatbot. In
particular, the explanations generated by our proposed method are in the form
of natural language text and visual representations, which for example can
describe how different facial regions contribute to the similarity measure
between two faces. This is achieved through the automatic analysis of the
output's saliency heatmaps of the face images and a BERT question-answering
model, providing users with an interface that facilitates a comprehensive
understanding of the FR decisions. The proposed approach is interactive,
allowing the users to ask questions to get more precise information based on
the user's background knowledge. More importantly, in contrast to previous
studies, our solution does not decrease the face recognition performance. We
demonstrate the effectiveness of the method through different experiments,
highlighting its potential to make FR systems more interpretable and
user-friendly, especially in sensitive applications where decision-making
transparency is crucial.

摘要：人臉辨識 (FR) 已隨著深度學習的發展而進步許多，在多項應用中達到很高的準確度。然而，這些系統缺乏可解釋性，引發了對其責任、公平性和可靠性的疑慮。在本研究中，我們提出一個互動式架構，透過結合與模型無關的可解釋人工智慧 (XAI) 和自然語言處理 (NLP) 技術，來增強 FR 模型的可解釋性。所提出的架構能夠透過互動式聊天機器人，精確回答使用者的各種問題。特別是，我們所提出的方法所產生的解釋，是以自然語言文字和視覺表示的形式呈現，例如可以描述不同臉部區域如何影響兩張臉之間的相似度量度。這是透過自動分析臉部影像的顯著熱點圖和 BERT 問答模型來達成，為使用者提供一個介面，以利全面理解 FR 決策。所提出的方法具有互動性，允許使用者提問，以根據使用者的背景知識取得更精確的資訊。更重要的是，與先前的研究相比，我們的解決方案並未降低人臉辨識效能。我們透過不同的實驗，證明此方法的有效性，強調其讓 FR 系統更具可解釋性及使用者友善性的潛力，特別是在決策透明度至關重要的敏感應用中。

##### **Online Multi-level Contrastive Representation Distillation for Cross-Subject fNIRS Emotion Recognition**
2409.16081v1 by Zhili Lai, Chunmei Qing, Junpeng Tan, Wanxiang Luo, Xiangmin Xu

Utilizing functional near-infrared spectroscopy (fNIRS) signals for emotion
recognition is a significant advancement in understanding human emotions.
However, due to the lack of artificial intelligence data and algorithms in this
field, current research faces the following challenges: 1) The portable
wearable devices have higher requirements for lightweight models; 2) The
objective differences of physiology and psychology among different subjects
aggravate the difficulty of emotion recognition. To address these challenges,
we propose a novel cross-subject fNIRS emotion recognition method, called the
Online Multi-level Contrastive Representation Distillation framework (OMCRD).
Specifically, OMCRD is a framework designed for mutual learning among multiple
lightweight student networks. It utilizes multi-level fNIRS feature extractor
for each sub-network and conducts multi-view sentimental mining using
physiological signals. The proposed Inter-Subject Interaction Contrastive
Representation (IS-ICR) facilitates knowledge transfer for interactions between
student models, enhancing cross-subject emotion recognition performance. The
optimal student network can be selected and deployed on a wearable device. Some
experimental results demonstrate that OMCRD achieves state-of-the-art results
in emotional perception and affective imagery tasks.

摘要：利用功能性近紅外線光譜 (fNIRS) 信號進行情緒辨識，是理解人類情緒的一大進展。然而，由於該領域缺乏人工智慧數據和演算法，目前的研究面臨以下挑戰：1) 可攜式穿戴式裝置對輕量化模型有較高要求；2) 不同受試者之間生理和心理的客觀差異加劇了情緒辨識的難度。為了應對這些挑戰，我們提出了一種新穎的跨受試者 fNIRS 情緒辨識方法，稱為線上多層對比表徵蒸餾框架 (OMCRD)。具體來說，OMCRD 是為多個輕量級學生網路之間的相互學習而設計的框架。它為每個子網路利用多層級 fNIRS 特徵萃取器，並使用生理信號進行多視角情緒挖掘。所提出的跨受試者互動對比表徵 (IS-ICR) 促進了學生模型之間互動的知識傳遞，增強了跨受試者的情緒辨識效能。可以選擇最佳的學生網路並部署在可穿戴式裝置上。一些實驗結果表明，OMCRD 在情緒感知和情感意象任務中取得了最先進的成果。

##### **Leveraging Mixture of Experts for Improved Speech Deepfake Detection**
2409.16077v1 by Viola Negroni, Davide Salvi, Alessandro Ilic Mezza, Paolo Bestagini, Stefano Tubaro

Speech deepfakes pose a significant threat to personal security and content
authenticity. Several detectors have been proposed in the literature, and one
of the primary challenges these systems have to face is the generalization over
unseen data to identify fake signals across a wide range of datasets. In this
paper, we introduce a novel approach for enhancing speech deepfake detection
performance using a Mixture of Experts architecture. The Mixture of Experts
framework is well-suited for the speech deepfake detection task due to its
ability to specialize in different input types and handle data variability
efficiently. This approach offers superior generalization and adaptability to
unseen data compared to traditional single models or ensemble methods.
Additionally, its modular structure supports scalable updates, making it more
flexible in managing the evolving complexity of deepfake techniques while
maintaining high detection accuracy. We propose an efficient, lightweight
gating mechanism to dynamically assign expert weights for each input,
optimizing detection performance. Experimental results across multiple datasets
demonstrate the effectiveness and potential of our proposed approach.

摘要：語音深度造假對個人安全和內容真實性構成重大威脅。文獻中已提出多種檢測器，而這些系統面臨的主要挑戰之一是在各種資料集上識別假訊號，以概化未見過的資料。在本文中，我們介紹了一種新方法，使用專家混合架構來增強語音深度造假檢測效能。專家混合架構非常適合語音深度造假檢測任務，因為它能夠針對不同的輸入類型進行專門處理，並有效處理資料變異性。與傳統單一模型或集成方法相比，這種方法提供了對未見過資料的卓越概化和適應性。此外，其模組化結構支援可擴充更新，使其在管理深度造假技術不斷演變的複雜性的同時，更靈活地維持高檢測準確度。我們提出了一種有效且輕量的閘控機制，用於動態分配每個輸入的專家權重，以最佳化檢測效能。跨多個資料集的實驗結果證明了我們提出的方法的有效性和潛力。

##### **Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis**
2409.16057v1 by Xianda Zhang, Siyuan Liang

Object detection models, widely used in security-critical applications, are
vulnerable to backdoor attacks that cause targeted misclassifications when
triggered by specific patterns. Existing backdoor defense techniques, primarily
designed for simpler models like image classifiers, often fail to effectively
detect and remove backdoors in object detectors. We propose a backdoor defense
framework tailored to object detection models, based on the observation that
backdoor attacks cause significant inconsistencies between local modules'
behaviors, such as the Region Proposal Network (RPN) and classification head.
By quantifying and analyzing these inconsistencies, we develop an algorithm to
detect backdoors. We find that the inconsistent module is usually the main
source of backdoor behavior, leading to a removal method that localizes the
affected module, resets its parameters, and fine-tunes the model on a small
clean dataset. Extensive experiments with state-of-the-art two-stage object
detectors show our method achieves a 90% improvement in backdoor removal rate
over fine-tuning baselines, while limiting clean data accuracy loss to less
than 4%. To the best of our knowledge, this work presents the first approach
that addresses both the detection and removal of backdoors in two-stage object
detection models, advancing the field of securing these complex systems against
backdoor attacks.

摘要：物件偵測模型廣泛用於安全關鍵應用中，容易受到後門攻擊，當觸發特定模式時，會導致目標錯誤分類。現有的後門防禦技術，主要是針對影像分類器等較簡單的模型設計，通常無法有效偵測並移除物件偵測器中的後門。我們提出一個針對物件偵測模型量身打造的後門防禦架構，根據後門攻擊會導致區域建議網路 (RPN) 和分類頭等局部模組行為出現顯著不一致的觀察結果。透過量化和分析這些不一致性，我們開發了一種演算法來偵測後門。我們發現不一致的模組通常是後門行為的主要來源，導致一種移除方法，該方法會找出受影響的模組，重設其參數，並在小型乾淨資料集上微調模型。使用最先進的兩階段物件偵測器進行的廣泛實驗顯示，我們的方法在後門移除率方面比微調基線提升了 90%，同時將乾淨資料準確度損失限制在低於 4%。據我們所知，這項工作提出了第一個處理兩階段物件偵測模型中後門偵測和移除的方法，推進了保護這些複雜系統免於後門攻擊的領域。

##### **Adversarial Watermarking for Face Recognition**
2409.16056v1 by Yuguang Yao, Anil Jain, Sijia Liu

Watermarking is an essential technique for embedding an identifier (i.e.,
watermark message) within digital images to assert ownership and monitor
unauthorized alterations. In face recognition systems, watermarking plays a
pivotal role in ensuring data integrity and security. However, an adversary
could potentially interfere with the watermarking process, significantly
impairing recognition performance. We explore the interaction between
watermarking and adversarial attacks on face recognition models. Our findings
reveal that while watermarking or input-level perturbation alone may have a
negligible effect on recognition accuracy, the combined effect of watermarking
and perturbation can result in an adversarial watermarking attack,
significantly degrading recognition performance. Specifically, we introduce a
novel threat model, the adversarial watermarking attack, which remains stealthy
in the absence of watermarking, allowing images to be correctly recognized
initially. However, once watermarking is applied, the attack is activated,
causing recognition failures. Our study reveals a previously unrecognized
vulnerability: adversarial perturbations can exploit the watermark message to
evade face recognition systems. Evaluated on the CASIA-WebFace dataset, our
proposed adversarial watermarking attack reduces face matching accuracy by
67.2% with an $\ell_\infty$ norm-measured perturbation strength of ${2}/{255}$
and by 95.9% with a strength of ${4}/{255}$.

摘要：浮水印是一種將識別碼（即浮水印訊息）嵌入數位影像中的基本技術，用於主張擁有權並監控未經授權的變更。在人臉辨識系統中，浮水印在確保資料完整性和安全性方面扮演著關鍵角色。然而，對手可能會干擾浮水印處理程序，嚴重損害辨識效能。我們探討浮水印與對抗性攻擊在人臉辨識模型之間的互動。我們的研究結果顯示，雖然僅浮水印或輸入層擾動對辨識準確度可能影響甚微，但浮水印和擾動的綜合效應可能會導致對抗性浮水印攻擊，大幅降低辨識效能。具體來說，我們引入了一種新的威脅模型，即對抗性浮水印攻擊，在沒有浮水印的情況下仍然隱形，讓影像最初可以被正確辨識。然而，一旦套用浮水印，攻擊就會被啟動，導致辨識失敗。我們的研究揭露了一個以前未被發現的漏洞：對抗性擾動可以利用浮水印訊息來規避人臉辨識系統。在 CASIA-WebFace 資料集上進行評估，我們提出的對抗性浮水印攻擊將人臉配對準確度降低了 67.2%，$\ell_\infty$ 範數測量擾動強度為 ${2}/{255}$，強度為 ${4}/{255}$ 時降低了 95.9%。

##### **Whole-body end-effector pose tracking**
2409.16048v1 by Tifanny Portela, Andrei Cramariuc, Mayank Mittal, Marco Hutter

Combining manipulation with the mobility of legged robots is essential for a
wide range of robotic applications. However, integrating an arm with a mobile
base significantly increases the system's complexity, making precise
end-effector control challenging. Existing model-based approaches are often
constrained by their modeling assumptions, leading to limited robustness.
Meanwhile, recent Reinforcement Learning (RL) implementations restrict the
arm's workspace to be in front of the robot or track only the position to
obtain decent tracking accuracy. In this work, we address these limitations by
introducing a whole-body RL formulation for end-effector pose tracking in a
large workspace on rough, unstructured terrains. Our proposed method involves a
terrain-aware sampling strategy for the robot's initial configuration and
end-effector pose commands, as well as a game-based curriculum to extend the
robot's operating range. We validate our approach on the ANYmal quadrupedal
robot with a six DoF robotic arm. Through our experiments, we show that the
learned controller achieves precise command tracking over a large workspace and
adapts across varying terrains such as stairs and slopes. On deployment, it
achieves a pose-tracking error of 2.64 cm and 3.64 degrees, outperforming
existing competitive baselines.

摘要：結合操縱與機器人腿部移動能力對於廣泛的機器人應用來說至關重要。然而，將手臂與移動底座整合在一起會大幅增加系統的複雜性，使得精確的末端執行器控制具有挑戰性。現有的基於模型的方法通常受到其建模假設的限制，導致穩健性有限。與此同時，最近的強化學習 (RL) 實作限制了手臂的工作空間在機器人前面，或僅追蹤位置以獲得良好的追蹤準確度。在這項工作中，我們透過引入一個全身體 RL 公式來解決這些限制，以在粗糙、非結構化地形上的大型工作空間中追蹤末端執行器的姿勢。我們提出的方法包含一個針對機器人初始組態和末端執行器姿勢指令的地形感知取樣策略，以及一個基於遊戲的課程，以擴展機器人的操作範圍。我們在配備六個自由度機器人手臂的 ANYmal 四足機器人上驗證了我們的做法。透過我們的實驗，我們展示了學習的控制器在一個大型工作空間中實現精確的指令追蹤，並適應樓梯和斜坡等各種地形。在部署時，它實現了 2.64 公分和 3.64 度的姿勢追蹤誤差，優於現有的競爭基準。

##### **LTNtorch: PyTorch Implementation of Logic Tensor Networks**
2409.16045v1 by Tommaso Carraro, Luciano Serafini, Fabio Aiolli

Logic Tensor Networks (LTN) is a Neuro-Symbolic framework that effectively
incorporates deep learning and logical reasoning. In particular, LTN allows
defining a logical knowledge base and using it as the objective of a neural
model. This makes learning by logical reasoning possible as the parameters of
the model are optimized by minimizing a loss function composed of a set of
logical formulas expressing facts about the learning task. The framework learns
via gradient-descent optimization. Fuzzy logic, a relaxation of classical logic
permitting continuous truth values in the interval [0,1], makes this learning
possible. Specifically, the training of an LTN consists of three steps.
Firstly, (1) the training data is used to ground the formulas. Then, (2) the
formulas are evaluated, and the loss function is computed. Lastly, (3) the
gradients are back-propagated through the logical computational graph, and the
weights of the neural model are changed so the knowledge base is maximally
satisfied. LTNtorch is the fully documented and tested PyTorch implementation
of Logic Tensor Networks. This paper presents the formalization of LTN and how
LTNtorch implements it. Moreover, it provides a basic binary classification
example.

摘要：邏輯張量網路 (LTN) 是一個神經符號框架，有效地整合了深度學習和邏輯推理。特別是，LTN 允許定義邏輯知識庫，並將其用作神經模型的目標。這使得通過邏輯推理進行學習成為可能，因為模型的參數是通過最小化由一組表達學習任務事實的邏輯公式組成的損失函數來優化的。該框架通過梯度下降優化進行學習。模糊邏輯是經典邏輯的放寬，允許在 [0,1] 區間內連續真值，這使得這種學習成為可能。具體來說，LTN 的訓練包含三個步驟。首先，(1) 訓練數據用於建立公式。然後，(2) 評估公式，並計算損失函數。最後，(3) 梯度通過邏輯計算圖反向傳播，並且神經模型的權重被改變，因此知識庫得到最大滿足。LTNtorch 是 Logic Tensor Networks 經過充分文件化和測試的 PyTorch 實作。本文介紹了 LTN 的形式化，以及 LTNtorch 如何實作它。此外，它還提供了一個基本的二元分類範例。

##### **Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts**
2409.16040v1 by Xiaoming Shi, Shiyu Wang, Yuqi Nie, Dianqi Li, Zhou Ye, Qingsong Wen, Ming Jin

Deep learning for time series forecasting has seen significant advancements
over the past decades. However, despite the success of large-scale pre-training
in language and vision domains, pre-trained time series models remain limited
in scale and operate at a high cost, hindering the development of larger
capable forecasting models in real-world applications. In response, we
introduce Time-MoE, a scalable and unified architecture designed to pre-train
larger, more capable forecasting foundation models while reducing inference
costs. By leveraging a sparse mixture-of-experts (MoE) design, Time-MoE
enhances computational efficiency by activating only a subset of networks for
each prediction, reducing computational load while maintaining high model
capacity. This allows Time-MoE to scale effectively without a corresponding
increase in inference costs. Time-MoE comprises a family of decoder-only
transformer models that operate in an auto-regressive manner and support
flexible forecasting horizons with varying input context lengths. We
pre-trained these models on our newly introduced large-scale data Time-300B,
which spans over 9 domains and encompassing over 300 billion time points. For
the first time, we scaled a time series foundation model up to 2.4 billion
parameters, achieving significantly improved forecasting precision. Our results
validate the applicability of scaling laws for training tokens and model size
in the context of time series forecasting. Compared to dense models with the
same number of activated parameters or equivalent computation budgets, our
models consistently outperform them by large margin. These advancements
position Time-MoE as a state-of-the-art solution for tackling real-world time
series forecasting challenges with superior capability, efficiency, and
flexibility.

摘要：<paragraph>在過去的幾十年中，時間序列預測的深度學習有了顯著的進展。然而，儘管在語言和視覺領域取得了大規模預訓練的成功，但預訓練的時間序列模型在規模上仍然有限，並且運作成本很高，阻礙了在實際應用中開發更大能力的預測模型。為了解決這個問題，我們引入了 Time-MoE，這是一個可擴充且統一的架構，旨在預訓練更大、更有能力的預測基礎模型，同時降低推理成本。透過利用稀疏的混合專家 (MoE) 設計，Time-MoE 僅針對每個預測啟用一個子網路，進而提高運算效率，在維持高模型容量的同時降低運算負載。這讓 Time-MoE 能夠有效擴充，而推理成本不會隨之增加。Time-MoE 包含一系列僅解碼器的Transformer模型，這些模型以自迴歸的方式運作，並支援具有不同輸入內容長度的彈性預測範圍。我們在我們新推出的 Time-300B 大型資料集上預訓練了這些模型，該資料集涵蓋了 9 個領域，包含超過 3000 億個時間點。我們首次將時間序列基礎模型擴充到 24 億個參數，大幅提升了預測精度。我們的結果驗證了在時間序列預測中，訓練 token 和模型大小的規模定律的適用性。與具有相同數量已啟用參數或等效運算預算的稠密模型相比，我們的模型始終以很大的幅度優於它們。這些進展讓 Time-MoE 成為解決實際時間序列預測挑戰的最新解決方案，具備卓越的性能、效率和靈活性。</paragraph>

##### **Grounded Computation & Consciousness: A Framework for Exploring Consciousness in Machines & Other Organisms**
2409.16036v1 by Ryan Williams

Computational modeling is a critical tool for understanding consciousness,
but is it enough on its own? This paper discusses the necessity for an
ontological basis of consciousness, and introduces a formal framework for
grounding computational descriptions into an ontological substrate. Utilizing
this technique, a method is demonstrated for estimating the difference in
qualitative experience between two systems. This framework has wide
applicability to computational theories of consciousness.

摘要：計算模型是了解意識的關鍵工具，
但它本身是否足夠？本文討論了意識的本體基礎的必要性，並介紹了一個將計算描述基礎化到本體基底的正式框架。利用此技術，展示了一種估計兩個系統之間定性體驗差異的方法。此框架廣泛適用於意識的計算理論。

##### **Deep chroma compression of tone-mapped images**
2409.16032v1 by Xenios Milidonis, Francesco Banterle, Alessandro Artusi

Acquisition of high dynamic range (HDR) images is thriving due to the
increasing use of smart devices and the demand for high-quality output.
Extensive research has focused on developing methods for reducing the luminance
range in HDR images using conventional and deep learning-based tone mapping
operators to enable accurate reproduction on conventional 8 and 10-bit digital
displays. However, these methods often fail to account for pixels that may lie
outside the target display's gamut, resulting in visible chromatic distortions
or color clipping artifacts. Previous studies suggested that a gamut management
step ensures that all pixels remain within the target gamut. However, such
approaches are computationally expensive and cannot be deployed on devices with
limited computational resources. We propose a generative adversarial network
for fast and reliable chroma compression of HDR tone-mapped images. We design a
loss function that considers the hue property of generated images to improve
color accuracy, and train the model on an extensive image dataset. Quantitative
experiments demonstrate that the proposed model outperforms state-of-the-art
image generation and enhancement networks in color accuracy, while a subjective
study suggests that the generated images are on par or superior to those
produced by conventional chroma compression methods in terms of visual quality.
Additionally, the model achieves real-time performance, showing promising
results for deployment on devices with limited computational resources.

摘要：由於智慧裝置使用率提升，且對高品質輸出有需求，因此高動態範圍 (HDR) 影像的取得正蓬勃發展中。廣泛的研究專注於開發使用傳統和基於深度學習的色調對應運算子，以縮減 HDR 影像中的亮度範圍的方法，以在傳統的 8 和 10 位元數位顯示器上進行精確的重現。然而，這些方法通常無法考量可能位於目標顯示器色域之外的像素，導致可見的色度失真或色彩裁剪的人工製品。先前的研究建議，色域管理步驟可確保所有像素都位於目標色域內。然而，此類方法在運算上成本高昂，且無法部署在運算資源有限的裝置上。我們提出了一個用於 HDR 色調對應影像快速且可靠的色度壓縮的生成對抗網路。我們設計了一個考量生成影像色相屬性的損失函數，以改善色彩準確度，並在廣泛的影像資料集上訓練模型。定量實驗證明，所提出的模型在色彩準確度方面優於現有的影像生成和增強網路，而主觀研究則表明，在視覺品質方面，生成的影像與傳統色度壓縮方法產生的影像不相上下，甚至更優。此外，該模型實現了即時效能，顯示出在運算資源有限的裝置上部署的 promising 結果。

##### **Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering**
2409.16025v1 by Yifei Yuan, Yang Deng, Anders Søgaard, Mohammad Aliannejadi

Users post numerous product-related questions on e-commerce platforms,
affecting their purchase decisions. Product-related question answering (PQA)
entails utilizing product-related resources to provide precise responses to
users. We propose a novel task of Multilingual Cross-market Product-based
Question Answering (MCPQA) and define the task as providing answers to
product-related questions in a main marketplace by utilizing information from
another resource-rich auxiliary marketplace in a multilingual context. We
introduce a large-scale dataset comprising over 7 million questions from 17
marketplaces across 11 languages. We then perform automatic translation on the
Electronics category of our dataset, naming it as McMarket. We focus on two
subtasks: review-based answer generation and product-related question ranking.
For each subtask, we label a subset of McMarket using an LLM and further
evaluate the quality of the annotations via human assessment. We then conduct
experiments to benchmark our dataset, using models ranging from traditional
lexical models to LLMs in both single-market and cross-market scenarios across
McMarket and the corresponding LLM subset. Results show that incorporating
cross-market information significantly enhances performance in both tasks.

摘要：<paragraph>用戶在電子商務平台上發布許多與產品相關的問題，影響其購買決策。與產品相關的問題回答 (PQA) 意味著利用與產品相關的資源來向用戶提供精確的回應。我們提出了一個多語言跨市場產品問題回答 (MCPQA) 的新任務，並將該任務定義為利用多語言環境中另一個資源豐富的輔助市場中的信息來回答主要市場中與產品相關的問題。我們引入了一個大型數據集，其中包含來自 11 種語言的 17 個市場的 700 多萬個問題。然後，我們對數據集的電子產品類別進行自動翻譯，並將其命名為 McMarket。我們專注於兩個子任務：基於評論的答案生成和與產品相關的問題排名。對於每個子任務，我們使用 LLM 標記 McMarket 的一個子集，並通過人工評估進一步評估註釋的質量。然後，我們使用從傳統詞彙模型到 LLM 的模型在 McMarket 和相應的 LLM 子集中進行單一市場和跨市場場景的基準測試，以對我們的數據集進行基準測試。結果表明，在兩個任務中，合併跨市場信息顯著提高了性能。</paragraph>

##### **Bridging Environments and Language with Rendering Functions and Vision-Language Models**
2409.16024v1 by Theo Cachet, Christopher R. Dance, Olivier Sigaud

Vision-language models (VLMs) have tremendous potential for grounding
language, and thus enabling language-conditioned agents (LCAs) to perform
diverse tasks specified with text. This has motivated the study of LCAs based
on reinforcement learning (RL) with rewards given by rendering images of an
environment and evaluating those images with VLMs. If single-task RL is
employed, such approaches are limited by the cost and time required to train a
policy for each new task. Multi-task RL (MTRL) is a natural alternative, but
requires a carefully designed corpus of training tasks and does not always
generalize reliably to new tasks. Therefore, this paper introduces a novel
decomposition of the problem of building an LCA: first find an environment
configuration that has a high VLM score for text describing a task; then use a
(pretrained) goal-conditioned policy to reach that configuration. We also
explore several enhancements to the speed and quality of VLM-based LCAs,
notably, the use of distilled models, and the evaluation of configurations from
multiple viewpoints to resolve the ambiguities inherent in a single 2D view. We
demonstrate our approach on the Humanoid environment, showing that it results
in LCAs that outperform MTRL baselines in zero-shot generalization, without
requiring any textual task descriptions or other forms of environment-specific
annotation during training.
  Videos and an interactive demo can be found at
https://europe.naverlabs.com/text2control

摘要：視覺語言模型 (VLM) 具有將語言基礎化的巨大潛力，從而使語言條件代理 (LCA) 能夠執行用文字指定的各種任務。這促使了基於強化學習 (RL) 的 LCA 的研究，其獎勵是通過渲染環境的影像並使用 VLM 評估這些影像而給予的。如果採用單一任務 RL，此類方法會受到訓練每個新任務的策略所需的成本和時間的限制。多任務 RL (MTRL) 是一種自然的替代方案，但需要仔細設計的訓練任務語料庫，並且並不總是能可靠地推廣到新任務。因此，本文介紹了一個新穎的 LCA 建構問題分解：首先找到一個環境配置，其具有描述任務文字的高 VLM 分數；然後使用（預訓練的）目標條件策略來達成該配置。我們還探索了基於 VLM 的 LCA 的速度和品質的幾項強化，特別是蒸餾模型的使用，以及從多個視點評估配置以解決單一 2D 視圖中固有的模糊性。我們在類人環境中展示了我們的做法，表明它產生的 LCA 在零次學習泛化中優於 MTRL 基準，而無需在訓練期間要求任何文字任務描述或其他形式的環境特定註解。可以在 https://europe.naverlabs.com/text2control 找到影片和互動式示範。

##### **AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessment**
2409.16022v1 by Nuo Chen, Jiqun Liu, Xiaoyu Dong, Qijiong Liu, Tetsuya Sakai, Xiao-Ming Wu

Cognitive biases are systematic deviations in thinking that lead to
irrational judgments and problematic decision-making, extensively studied
across various fields. Recently, large language models (LLMs) have shown
advanced understanding capabilities but may inherit human biases from their
training data. While social biases in LLMs have been well-studied, cognitive
biases have received less attention, with existing research focusing on
specific scenarios. The broader impact of cognitive biases on LLMs in various
decision-making contexts remains underexplored. We investigated whether LLMs
are influenced by the threshold priming effect in relevance judgments, a core
task and widely-discussed research topic in the Information Retrieval (IR)
coummunity. The priming effect occurs when exposure to certain stimuli
unconsciously affects subsequent behavior and decisions. Our experiment
employed 10 topics from the TREC 2019 Deep Learning passage track collection,
and tested AI judgments under different document relevance scores, batch
lengths, and LLM models, including GPT-3.5, GPT-4, LLaMa2-13B and LLaMa2-70B.
Results showed that LLMs tend to give lower scores to later documents if
earlier ones have high relevance, and vice versa, regardless of the combination
and model used. Our finding demonstrates that LLM%u2019s judgments, similar to
human judgments, are also influenced by threshold priming biases, and suggests
that researchers and system engineers should take into account potential
human-like cognitive biases in designing, evaluating, and auditing LLMs in IR
tasks and beyond.

摘要：<paragraph>認知偏差是思考中系統性的偏差，會導致不理性的判斷和有問題的決策制定，在各種領域中廣泛研究。最近，大型語言模型 (LLM) 已展現出進階的理解能力，但可能會從其訓練資料繼承人類的偏見。雖然 LLM 中的社會偏見已被廣泛研究，但認知偏見較少受到關注，現有的研究著重於特定情境。認知偏見對 LLM 在各種決策制定情境中的更廣泛影響仍未充分探討。我們調查了 LLM 是否受到相關判斷中的閾值啟動效應的影響，這是資訊檢索 (IR) 社群中一項核心任務和廣泛討論的研究主題。當接觸到某些刺激時，啟動效應會發生，無意識地影響後續行為和決策。我們的實驗採用了 TREC 2019 深度學習段落軌道收集中的 10 個主題，並在不同的文件相關性評分、批次長度和 LLM 模型（包括 GPT-3.5、GPT-4、LLaMa2-13B 和 LLaMa2-70B）下測試 AI 判斷。結果顯示，如果較早的文件具有高相關性，LLM 傾向於給予較後的文件較低分數，反之亦然，無論使用哪種組合和模型。我們的發現證明，與人類判斷類似，LLM 的判斷也受到閾值啟動偏差的影響，並表明研究人員和系統工程師在設計、評估和稽核 IR 任務及其他任務中的 LLM 時，應考慮潛在的人類認知偏差。</paragraph>

##### **Bridging Speech and Text: Enhancing ASR with Pinyin-to-Character Pre-training in LLMs**
2409.16005v1 by Yang Yuhang, Peng Yizhou, Eng Siong Chng, Xionghu Zhong

The integration of large language models (LLMs) with pre-trained speech
models has opened up new avenues in automatic speech recognition (ASR). While
LLMs excel in multimodal understanding tasks, effectively leveraging their
capabilities for ASR remains a significant challenge. This paper presents a
novel training approach to enhance LLM performance in ASR tasks. We propose
pre-training LLMs on Pinyin embedding sequences, which represent pronunciation
features, to generate corresponding Chinese characters. This step enables the
LLM to adapt to generating text from pronunciation features before encountering
real speech data. Furthermore, we fine-tune the LoRA parameters to enhance the
LLM's understanding of speech modality information. In AISHELL-1 corpus, our
approach yields a 9.5% relative improvement in ASR tasks compared to the
baseline without Pinyi-to-Character pre-training. Additionally, incorporating
auxiliary text data for Pinyi-to-Character pre-training further boosts
performance, achieving a 19.0% relative improvement.

摘要：大型語言模型 (LLM) 與預訓練語音模型的整合，為自動語音辨識 (ASR) 開啟了新的途徑。儘管 LLM 在多模態理解任務中表現出色，但有效利用其功能進行 ASR 仍然是一項重大挑戰。本文提出了一種新穎的訓練方法，以增強 LLM 在 ASR 任務中的表現。我們建議在表示發音特徵的拼音嵌入序列上預訓練 LLM，以產生相應的中文漢字。此步驟使 LLM 能夠在遇到真實語音數據之前，適應從發音特徵產生文本。此外，我們微調 LoRA 參數以增強 LLM 對語音模態資訊的理解。在 AISHELL-1 語料庫中，與沒有拼音轉換為字元的預訓練的基準相比，我們的做法在 ASR 任務中產生了 9.5% 的相對改進。此外，將輔助文本數據納入拼音轉換為字元的預訓練進一步提升了效能，達到了 19.0% 的相對改進。

##### **Artificial Human Intelligence: The role of Humans in the Development of Next Generation AI**
2409.16001v1 by Suayb S. Arslan

Human intelligence, the most evident and accessible form of source of
reasoning, hosted by biological hardware, has evolved and been refined over
thousands of years, positioning itself today to create new artificial forms and
preparing to self--design their evolutionary path forward. Beginning with the
advent of foundation models, the rate at which human and artificial
intelligence interact with each other has surpassed any anticipated
quantitative figures. The close engagement led to both bits of intelligence to
be impacted in various ways, which naturally resulted in complex confluences
that warrant close scrutiny. In the sequel, we shall explore the interplay
between human and machine intelligence, focusing on the crucial role humans
play in developing ethical, responsible, and robust intelligent systems. We
slightly delve into interesting aspects of implementation inspired by the
mechanisms underlying neuroscience and human cognition. Additionally, we
propose future perspectives, capitalizing on the advantages of symbiotic
designs to suggest a human-centered direction for next-generation AI
development. We finalize this evolving document with a few thoughts and open
questions yet to be addressed by the broader community.

摘要：人類智慧是推理最明顯且可得的來源形式，由生物硬體所承載，歷經數千年的演化與精進，如今已能創造出新的形式，並準備自行設計其未來的演化路徑。從基礎模型的出現開始，人類與人工智慧互動的速度已超越任何預期的數量數字。緊密的互動讓這兩種智慧以各種方式產生影響，自然而然地產生了複雜的匯流，值得仔細探究。在後續部分，我們將探討人類與機器智慧之間的交互作用，重點關注人類在開發倫理、負責任且強健的智慧系統中所扮演的關鍵角色。我們將稍微深入探討受神經科學和人類認知機制啟發的實作有趣面向。此外，我們提出未來的觀點，利用共生設計的優勢，為下一代 AI 發展提出以人為中心的方針。我們以一些想法和開放性問題為這份不斷演化的文件作結，這些問題仍有待更廣泛的社群來探討。

##### **Improvements to SDXL in NovelAI Diffusion V3**
2409.15997v1 by Juan Ossa, Eren Doğan, Alex Birch, F. Johnson

In this technical report, we document the changes we made to SDXL in the
process of training NovelAI Diffusion V3, our state of the art anime image
generation model.

摘要：在此技術報告中，我們記錄了在訓練 NovelAI Diffusion V3 的過程中對 SDXL 所做的變更，這是我們最先進的動漫影像生成模型。

##### **DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL**
2409.15985v1 by Lixia Wu, Peng Li, Junhong Lou, Lei Fu

In addressing the pivotal role of translating natural language queries into
SQL commands, we propose a suite of compact, fine-tuned models and self-refine
mechanisms to democratize data access and analysis for non-expert users,
mitigating risks associated with closed-source Large Language Models.
Specifically, we constructed a dataset of over 20K sample for Text-to-SQL as
well as the preference dateset, to improve the efficiency in the domain of SQL
generation. To further ensure code validity, a code corrector was integrated
into the model. Our system, DataGpt-sql, achieved 87.2\% accuracy on the
spider-dev, respectively, showcasing the effectiveness of our solution in
text-to-SQL conversion tasks. Our code, data, and models are available at
\url{https://github.com/CainiaoTechAi/datagpt-sql-7b}

摘要：在解決將自然語言查詢轉換為 SQL 指令的關鍵角色時，我們提出了一套經過微調的精簡模型和自我精煉機制，以民主化非專家使用者的資料存取和分析，並降低與封閉原始碼大型語言模型相關的風險。具體來說，我們建構了一個超過 20K 個範例的資料集，用於文字轉 SQL 以及偏好資料集，以提升 SQL 產生領域的效率。為了進一步確保程式碼的有效性，我們將程式碼校正器整合到模型中。我們的系統 DataGpt-sql 在 spider-dev 上達到了 87.2% 的準確度，分別展示了我們的解決方案在文字轉 SQL 轉換任務中的有效性。我們的程式碼、資料和模型可在 \url{https://github.com/CainiaoTechAi/datagpt-sql-7b} 取得

##### **Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection**
2409.15980v1 by Yunbo Long, Zhengyang Ling, Sam Brook, Duncan McFarlane, Alexandra Brintrup

Traditional machine learning-based visual inspection systems require
extensive data collection and repetitive model training to improve accuracy.
These systems typically require expensive camera, computing equipment and
significant machine learning expertise, which can substantially burden small
and medium-sized enterprises. This study explores leveraging unsupervised
learning methods with pre-trained models and low-cost hardware to create a
cost-effective visual anomaly detection system. The research aims to develop a
low-cost visual anomaly detection solution that uses minimal data for model
training while maintaining generalizability and scalability. The system
utilises unsupervised learning models from Anomalib and is deployed on
affordable Raspberry Pi hardware through openVINO. The results show that this
cost-effective system can complete anomaly defection training and inference on
a Raspberry Pi in just 90 seconds using only 10 normal product images,
achieving an F1 macro score exceeding 0.95. While the system is slightly
sensitive to environmental changes like lighting, product positioning, or
background, it remains a swift and economical method for factory automation
inspection for small and medium-sized manufacturers

摘要：傳統的機器學習視覺檢測系統需要廣泛的資料收集和重複的模型訓練才能提高準確度。這些系統通常需要昂貴的相機、運算設備和大量的機器學習專業知識，這可能會對中小型企業造成重大負擔。本研究探討了利用非監督式學習方法、預訓練模型和低成本硬體來建立一個具成本效益的視覺異常偵測系統。該研究旨在開發一個低成本的視覺異常偵測解決方案，在維持可概化性和可擴充性的同時，使用最少的資料進行模型訓練。該系統利用 Anomalib 的非監督式學習模型，並透過 openVINO 部署在經濟實惠的 Raspberry Pi 硬體上。結果顯示，這個具成本效益的系統僅使用 10 張正常的產品圖片，就能在 Raspberry Pi 上完成異常缺陷訓練和推論，只需 90 秒，即可達到超過 0.95 的 F1 巨集分數。雖然該系統對環境變化（例如光線、產品定位或背景）略微敏感，但它仍然是中小型製造商進行工廠自動化檢測的快速且經濟的方法

##### **Finetuning LLMs for Comparative Assessment Tasks**
2409.15979v1 by Vatsal Raina, Adian Liusie, Mark Gales

Automated assessment in natural language generation is a challenging task.
Instruction-tuned large language models (LLMs) have shown promise in
reference-free evaluation, particularly through comparative assessment.
However, the quadratic computational complexity of pairwise comparisons limits
its scalability. To address this, efficient comparative assessment has been
explored by applying comparative strategies on zero-shot LLM probabilities. We
propose a framework for finetuning LLMs for comparative assessment to align the
model's output with the target distribution of comparative probabilities. By
training on soft probabilities, our approach improves state-of-the-art
performance while maintaining high performance with an efficient subset of
comparisons.

摘要：自然語言生成中的自動化評估是一項具有挑戰性的任務。
經過指令調整的大型語言模型 (LLM) 在無參考評估中展現出前景，特別是透過比較性評估。
然而，成對比較二次計算複雜度限制了其可擴充性。為了解決這個問題，透過在零次學習 LLM 機率上應用比較策略，探索了有效率的比較性評估。我們提出了一個用於比較性評估的微調 LLM 架構，以將模型的輸出與比較機率的目標分佈對齊。透過在軟機率上進行訓練，我們的做法改善了最先進的效能，同時在有效率的比較子集中維持高效能。

##### **StyleSinger 2: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control**
2409.15977v1 by Yu Zhang, Ziyue Jiang, Ruiqi Li, Changhao Pan, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao

Zero-shot singing voice synthesis (SVS) with style transfer and style control
aims to generate high-quality singing voices with unseen timbres and styles
(including singing method, emotion, rhythm, technique, and pronunciation) from
audio and text prompts. However, the multifaceted nature of singing styles
poses a significant challenge for effective modeling, transfer, and control.
Furthermore, current SVS models often fail to generate singing voices rich in
stylistic nuances for unseen singers. To address these challenges, we introduce
StyleSinger 2, the first zero-shot SVS model for style transfer across
cross-lingual speech and singing styles, along with multi-level style control.
Specifically, StyleSinger 2 proposes three primary modules: 1) the clustering
style encoder employs a clustering vector quantization model to stably condense
style information into a compact latent space; 2) the Style and Duration
Language Model (S\&D-LM) concurrently predicts style information and phoneme
duration, which benefits both; 3) the style adaptive decoder uses a novel
mel-style adaptive normalization method to generate singing voices with
enhanced details. Experimental results show that StyleSinger 2 outperforms all
baseline models in synthesis quality, singer similarity, and style
controllability across various tasks, including zero-shot style transfer,
multi-level style control, cross-lingual style transfer, and speech-to-singing
style transfer. Singing voice samples can be accessed at
https://stylesinger2.github.io/.

摘要：零樣本歌唱聲音合成 (SVS)，具備風格轉移和風格控制，旨在根據音訊和文字提示生成具有未見音色和風格（包括歌唱方式、情緒、節奏、技巧和發音）的高品質歌唱聲音。然而，歌唱風格的多樣性對有效的建模、轉移和控制構成了重大挑戰。此外，目前的 SVS 模型通常無法為未見歌手生成富有風格細微差别的歌唱聲音。為了應對這些挑戰，我們引入了 StyleSinger 2，這是第一個跨語言語音和歌唱風格進行風格轉移的零樣本 SVS 模型，並具備多級風格控制。具體來說，StyleSinger 2 提出三個主要模組：1) 聚類風格編碼器採用聚類向量量化模型，將風格資訊穩定地濃縮到一個緊湊的潛在空間；2) 風格和持續時間語言模型 (S&D-LM) 同時預測風格資訊和音素持續時間，這對兩者都有利；3) 風格自適應解碼器使用一種新穎的 mel 風格自適應正規化方法，以生成具有增強細節的歌唱聲音。實驗結果表明，在零樣本風格轉移、多級風格控制、跨語言風格轉移和語音到歌唱風格轉移等各種任務中，StyleSinger 2 在合成品質、歌手相似性和風格可控性方面都優於所有基線模型。可以在 https://stylesinger2.github.io/ 訪問歌唱聲音範例。

##### **Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification**
2409.15974v1 by Fengrun Zhang, Wangjin Zhou, Yiming Liu, Wang Geng, Yahui Shan, Chen Zhang

There has been an increasing research interest in cross-age speaker
verification~(CASV). However, existing speaker verification systems perform
poorly in CASV due to the great individual differences in voice caused by
aging. In this paper, we propose a disentangled representation learning
framework for CASV based on mutual information~(MI) minimization. In our
method, a backbone model is trained to disentangle the identity- and
age-related embeddings from speaker information, and an MI estimator is trained
to minimize the correlation between age- and identity-related embeddings via MI
minimization, resulting in age-invariant speaker embeddings. Furthermore, by
using the age gaps between positive and negative samples, we propose an
aging-aware MI minimization loss function that allows the backbone model to
focus more on the vocal changes with large age gaps. Experimental results show
that the proposed method outperforms other methods on multiple Cross-Age test
sets of Vox-CA.

摘要：近年來，跨年齡說話者驗證 (CASV) 的研究興趣與日俱增。然而，由於老化導致聲音產生極大的個體差異，現有的說話者驗證系統在 CASV 中表現不佳。在本文中，我們提出了一個基於互信息 (MI) 最小化的 CASV 解糾纏表示學習框架。在我們的模型中，訓練一個主幹模型從說話者資訊中解糾纏身份和年齡相關的嵌入，並訓練一個 MI 估計器透過 MI 最小化來最小化年齡和身份相關嵌入之間的相關性，產生與年齡無關的說話者嵌入。此外，透過使用正負樣本之間的年齡差距，我們提出了一個老化感知 MI 最小化損失函數，讓主幹模型能更專注於年齡差距大的聲音變化。實驗結果表明，所提出的方法在 Vox-CA 的多個跨年齡測試集中優於其他方法。

##### **Creating Healthy Friction: Determining Stakeholder Requirements of Job Recommendation Explanations**
2409.15971v1 by Roan Schellingerhout, Francesco Barile, Nava Tintarev

The increased use of information retrieval in recruitment, primarily through
job recommender systems (JRSs), can have a large impact on job seekers,
recruiters, and companies. As a result, such systems have been determined to be
high-risk in recent legislature. This requires JRSs to be trustworthy and
transparent, allowing stakeholders to understand why specific recommendations
were made. To fulfill this requirement, the stakeholders' exact preferences and
needs need to be determined. To do so, we evaluated an explainable job
recommender system using a realistic, task-based, mixed-design user study
(n=30) in which stakeholders had to make decisions based on the model's
explanations. This mixed-methods evaluation consisted of two objective metrics
- correctness and efficiency, along with three subjective metrics - trust,
transparency, and usefulness. These metrics were evaluated twice per
participant, once using real explanations and once using random explanations.
The study included a qualitative analysis following a think-aloud protocol
while performing tasks adapted to each stakeholder group. We find that
providing stakeholders with real explanations does not significantly improve
decision-making speed and accuracy. Our results showed a non-significant trend
for the real explanations to outperform the random ones on perceived trust,
usefulness, and transparency of the system for all stakeholder types. We
determine that stakeholders benefit more from interacting with explanations as
decision support capable of providing healthy friction, rather than as
previously-assumed persuasive tools.

摘要：資訊檢索在招募中的使用日益增加，主要是透過工作推薦系統 (JRS)，這可能會對求職者、招募人員和公司產生重大影響。因此，此類系統在最近的立法中已被認定為高風險。這要求 JRS 值得信賴且透明，讓利害關係人了解為何提出特定建議。為滿足此要求，需要確定利害關係人的確切偏好和需求。為此，我們使用一個現實的、基於任務的、混合設計使用者研究 (n=30) 來評估一個可解釋的工作推薦系統，其中利害關係人必須根據模型的解釋做出決策。這種混合方法評估包含兩個客觀指標 - 正確性和效率，以及三個主觀指標 - 信任、透明度和有用性。這些指標每位參與者評估兩次，一次使用真實解釋，一次使用隨機解釋。該研究包括在執行適應每個利害關係人組別的任務時遵循思考出聲協定的定性分析。我們發現，向利害關係人提供真實解釋並未顯著提高決策速度和準確性。我們的結果顯示，對於所有利害關係人類型，真實解釋在系統的感知信任度、有用性和透明度方面優於隨機解釋的趨勢不顯著。我們確定，利害關係人從與解釋互動中受益更多，因為解釋作為決策支援能夠提供有益的摩擦，而不是先前假設的說服工具。

##### **ASD-Diffusion: Anomalous Sound Detection with Diffusion Models**
2409.15957v1 by Fengrun Zhang, Xiang Xie, Kai Guo

Unsupervised Anomalous Sound Detection (ASD) aims to design a generalizable
method that can be used to detect anomalies when only normal sounds are given.
In this paper, Anomalous Sound Detection based on Diffusion Models
(ASD-Diffusion) is proposed for ASD in real-world factories. In our pipeline,
the anomalies in acoustic features are reconstructed from their noisy corrupted
features into their approximate normal pattern. Secondly, a post-processing
anomalies filter algorithm is proposed to detect anomalies that exhibit
significant deviation from the original input after reconstruction.
Furthermore, denoising diffusion implicit model is introduced to accelerate the
inference speed by a longer sampling interval of the denoising process. The
proposed method is innovative in the application of diffusion models as a new
scheme. Experimental results on the development set of DCASE 2023 challenge
task 2 outperform the baseline by 7.75%, demonstrating the effectiveness of the
proposed method.

摘要：無監督異常音訊偵測 (ASD) 的目標是設計一個可概括的方法，可用於在只有正常音訊的情況下偵測異常。在本文中，提出了基於擴散模型的異常音訊偵測 (ASD-Diffusion) 來進行真實世界工廠中的 ASD。在我們的管道中，會將音訊特徵中的異常從其雜訊破壞特徵重建成其近似的正常模式。其次，提出了一個後處理異常過濾器演算法，用於偵測在重建後與原始輸入有顯著偏差的異常。此外，引入了去噪擴散隱式模型，以透過去噪過程更長的取樣間隔來加速推論速度。所提出的方法在將擴散模型應用為新方案方面具有創新性。在 DCASE 2023 挑戰任務 2 的開發集上的實驗結果比基準高出 7.75%，證明了所提出方法的有效性。

##### **Historical Trajectory Assisted Zeroth-Order Federated Optimization**
2409.15955v2 by Xiaoyu He, Chenlin Wu, Zike Li, Zibin Zheng

Federated learning is a distributed learning framework which enables clients
to train models individually and to upload their model updates for aggregation.
The local training process heavily relies on distributed gradient descent
techniques. In the situation where gradient information is not available, the
gradients need to be estimated from zeroth-order information, which typically
involves computing finite-differences along isotropic random directions. This
method suffers from high estimation errors, as the geometric features of the
objective landscape may be overlooked during the isotropic sampling. In this
work, we propose a non-isotropic sampling method to improve the gradient
estimation procedure. Gradients in our method are estimated in a subspace
spanned by historical trajectories of solutions, aiming to encourage the
exploration of promising regions and hence improve the convergence. We
implement this method in zeroth-order federated settings, and show that the
convergence rate aligns with existing ones while introducing no significant
overheads in communication or local computation. The effectiveness of our
proposal is verified on several numerical experiments in comparison to several
commonly-used zeroth-order federated optimization algorithms.

摘要：聯邦式學習是一種分散式學習架構，它讓客戶端能夠個別訓練模型，並上傳他們的模型更新以進行彙總。
本地的訓練程序極度依賴分散式梯度下降技術。在無法取得梯度資訊的情況下，需要從零階資訊估計梯度，這通常需要沿著各向同性隨機方向計算有限差分。這種方法會有較高的估計誤差，因為在各向同性抽樣期間可能會忽略目標景觀的幾何特徵。在此項工作中，我們提出了一種非各向同性抽樣方法來改善梯度估計程序。我們的方法中的梯度是在由解的歷史軌跡所構成的子空間中估計的，旨在鼓勵探索有前景的區域，從而改善收斂性。我們在零階聯邦式設定中實作此方法，並表明收斂速度與現有方法一致，同時在通訊或本地運算中不會引入任何顯著的開銷。與幾個常用的零階聯邦式最佳化演算法相比，我們的建議在幾個數值實驗中驗證了其有效性。

##### **Beats of Bias: Analyzing Lyrics with Topic Modeling and Gender Bias Measurements**
2409.15949v1 by Danqing Chen, Adithi Satish, Rasul Khanbayov, Carolin M. Schuster, Georg Groh

This paper uses topic modeling and bias measurement techniques to analyze and
determine gender bias in English song lyrics. We utilize BERTopic to cluster
537,553 English songs into distinct topics and chart their development over
time. Our analysis shows the thematic shift in song lyrics over the years, from
themes of romance to the increasing sexualization of women in songs. We observe
large amounts of profanity and misogynistic lyrics on various topics,
especially in the overall biggest cluster. Furthermore, to analyze gender bias
across topics and genres, we employ the Single Category Word Embedding
Association Test (SC-WEAT) to compute bias scores for the word embeddings
trained on the most popular topics as well as for each genre. We find that
words related to intelligence and strength tend to show a male bias across
genres, as opposed to appearance and weakness words, which are more
female-biased; however, a closer look also reveals differences in biases across
topics.

摘要：這篇論文使用主題建模和偏誤測量技術來分析和確定英文歌曲歌詞中的性別偏見。我們利用 BERTopic 將 537,553 首英文歌曲分類成不同的主題，並繪製它們隨時間的發展。我們的分析顯示了歌曲歌詞中主題的轉變，從浪漫的主題到歌曲中女性的性化程度越來越高。我們觀察到大量褻瀆和厭女的歌詞出現在各種主題中，特別是在整體最大的群集中。此外，為了分析不同主題和類別中的性別偏見，我們採用單一類別詞嵌入關聯測試 (SC-WEAT) 來計算在最熱門主題以及每個類別中訓練的詞嵌入的偏見分數。我們發現與智力和力量相關的詞彙在不同類別中往往表現出男性偏見，而與外貌和弱點相關的詞彙則更偏向女性；然而，更仔細的觀察也揭示了不同主題之間偏見的差異。

##### **TSFeatLIME: An Online User Study in Enhancing Explainability in Univariate Time Series Forecasting**
2409.15950v1 by Hongnan Ma, Kevin McAreavey, Weiru Liu

Time series forecasting, while vital in various applications, often employs
complex models that are difficult for humans to understand. Effective
explainable AI techniques are crucial to bridging the gap between model
predictions and user understanding. This paper presents a framework -
TSFeatLIME, extending TSLIME, tailored specifically for explaining univariate
time series forecasting. TSFeatLIME integrates an auxiliary feature into the
surrogate model and considers the pairwise Euclidean distances between the
queried time series and the generated samples to improve the fidelity of the
surrogate models. However, the usefulness of such explanations for human beings
remains an open question. We address this by conducting a user study with 160
participants through two interactive interfaces, aiming to measure how
individuals from different backgrounds can simulate or predict model output
changes in the treatment group and control group. Our results show that the
surrogate model under the TSFeatLIME framework is able to better simulate the
behaviour of the black-box considering distance, without sacrificing accuracy.
In addition, the user study suggests that the explanations were significantly
more effective for participants without a computer science background.

摘要：時間序列預測雖然在各種應用中至關重要，但通常採用人類難以理解的複雜模型。有效的可解釋 AI 技術對於縮小模型預測和使用者理解之間的差距至關重要。本文提出了一個框架 - TSFeatLIME，擴展 TSLIME，專門用於解釋單變數時間序列預測。TSFeatLIME 將輔助特徵整合到替代模型中，並考慮查詢時間序列與生成樣本之間的成對歐幾里得距離，以提高替代模型的保真度。然而，此類解釋對人類的有用性仍然是一個開放的問題。我們通過一個包含 160 名參與者的使用者研究來解決這個問題，透過兩個互動介面，旨在衡量不同背景的個人如何模擬或預測治療組和對照組中的模型輸出變化。我們的結果表明，TSFeatLIME 框架下的替代模型能夠在不犧牲準確性的情況下，更好地模擬黑箱考慮距離的行為。此外，使用者研究表明，對於沒有電腦科學背景的參與者來說，這些解釋顯著地更有效。

##### **Automated test generation to evaluate tool-augmented LLMs as conversational AI agents**
2409.15934v1 by Samuel Arcadinho, David Aparicio, Mariana Almeida

Tool-augmented LLMs are a promising approach to create AI agents that can
have realistic conversations, follow procedures, and call appropriate
functions. However, evaluating them is challenging due to the diversity of
possible conversations, and existing datasets focus only on single interactions
and function-calling. We present a test generation pipeline to evaluate LLMs as
conversational AI agents. Our framework uses LLMs to generate diverse tests
grounded on user-defined procedures. For that, we use intermediate graphs to
limit the LLM test generator's tendency to hallucinate content that is not
grounded on input procedures, and enforces high coverage of the possible
conversations. Additionally, we put forward ALMITA, a manually curated dataset
for evaluating AI agents in customer support, and use it to evaluate existing
LLMs. Our results show that while tool-augmented LLMs perform well in single
interactions, they often struggle to handle complete conversations. While our
focus is on customer support, our method is general and capable of AI agents
for different domains.

摘要：工具增强的 LLM 是一种很有前途的方法，可以创建能够进行现实对话、遵循程序和调用适当函数的 AI 代理。然而，由于对话的多样性，对它们进行评估具有挑战性，而且现有的数据集只关注单个交互和函数调用。我们提出了一个测试生成管道，以评估 LLM 作为会话式 AI 代理。我们的框架使用 LLM 生成基于用户定义的程序的多样化测试。为此，我们使用中间图形来限制 LLM 测试生成器生成不基于输入程序的幻觉内容的倾向，并强制对可能的对话进行高覆盖率。此外，我们提出了 ALMITA，这是一个手动策划的数据集，用于评估客户支持中的 AI 代理，并使用它来评估现有的 LLM。我们的结果表明，虽然工具增强的 LLM 在单个交互中表现良好，但它们通常难以处理完整的对话。虽然我们的重点是客户支持，但我们的方法是通用的，并且能够为不同领域的 AI 代理提供支持。

##### **SLIMER-IT: Zero-Shot NER on Italian Language**
2409.15933v1 by Andrew Zamai, Leonardo Rigutini, Marco Maggini, Andrea Zugarini

Traditional approaches to Named Entity Recognition (NER) frame the task into
a BIO sequence labeling problem. Although these systems often excel in the
downstream task at hand, they require extensive annotated data and struggle to
generalize to out-of-distribution input domains and unseen entity types. On the
contrary, Large Language Models (LLMs) have demonstrated strong zero-shot
capabilities. While several works address Zero-Shot NER in English, little has
been done in other languages. In this paper, we define an evaluation framework
for Zero-Shot NER, applying it to the Italian language. Furthermore, we
introduce SLIMER-IT, the Italian version of SLIMER, an instruction-tuning
approach for zero-shot NER leveraging prompts enriched with definition and
guidelines. Comparisons with other state-of-the-art models, demonstrate the
superiority of SLIMER-IT on never-seen-before entity tags.

摘要：傳統命名實體識別 (NER) 方法將任務設定為 BIO 序列標籤問題。儘管這些系統通常在手邊的下游任務中表現出色，但它們需要大量的註解資料，並且難以推廣到分布外輸入網域和未見實體類型。相反地，大型語言模型 (LLM) 已展現強大的零次學習能力。儘管有幾項工作探討英文的零次學習 NER，但其他語言的研究卻很少。在本文中，我們定義了零次學習 NER 的評量架構，並將其應用於義大利語。此外，我們引入了 SLIMER-IT，它是 SLIMER 的義大利語版本，一種用於零次學習 NER 的指令調整方法，利用豐富了定義和準則的提示。與其他最先進模型的比較證明了 SLIMER-IT 在前所未見的實體標籤上的優越性。

##### **Multilingual Transfer and Domain Adaptation for Low-Resource Languages of Spain**
2409.15924v1 by Yuanchang Luo, Zhanglin Wu, Daimeng Wei, Hengchao Shang, Zongyao Li, Jiaxin Guo, Zhiqiang Rao, Shaojun Li, Jinlong Yang, Yuhao Xie, Jiawei Zheng Bin Wei, Hao Yang

This article introduces the submission status of the Translation into
Low-Resource Languages of Spain task at (WMT 2024) by Huawei Translation
Service Center (HW-TSC). We participated in three translation tasks: spanish to
aragonese (es-arg), spanish to aranese (es-arn), and spanish to asturian
(es-ast). For these three translation tasks, we use training strategies such as
multilingual transfer, regularized dropout, forward translation and back
translation, labse denoising, transduction ensemble learning and other
strategies to neural machine translation (NMT) model based on training deep
transformer-big architecture. By using these enhancement strategies, our
submission achieved a competitive result in the final evaluation.

摘要：這篇文章介紹了華為翻譯服務中心 (HW-TSC) 在 (WMT 2024) 的西班牙語翻譯成低資源語言任務的提交狀態。我們參與了三個翻譯任務：西班牙語翻譯成亞拉岡語 (es-arg)、西班牙語翻譯成阿蘭語 (es-arn) 和西班牙語翻譯成阿斯圖里亞語 (es-ast)。對於這三個翻譯任務，我們使用多語言轉移、正規化中斷、前向翻譯和反向翻譯、labse 去噪、轉換集合學習等訓練策略，以及基於訓練深度變換器大架構的神經機器翻譯 (NMT) 模型。藉由使用這些增強策略，我們的提交在最終評估中獲得了有競爭力的結果。

##### **Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts**
2409.15915v1 by Sukai Huang, Nir Lipovetzky, Trevor Cohn

Large Language Models (LLMs) have shown promise in solving natural
language-described planning tasks, but their direct use often leads to
inconsistent reasoning and hallucination. While hybrid LLM-symbolic planning
pipelines have emerged as a more robust alternative, they typically require
extensive expert intervention to refine and validate generated action schemas.
It not only limits scalability but also introduces a potential for biased
interpretation, as a single expert's interpretation of ambiguous natural
language descriptions might not align with the user's actual intent. To address
this, we propose a novel approach that constructs an action schema library to
generate multiple candidates, accounting for the diverse possible
interpretations of natural language descriptions. We further introduce a
semantic validation and ranking module that automatically filter and rank the
generated schemas and plans without expert-in-the-loop. The experiments showed
our pipeline maintains superiority in planning over the direct LLM planning
approach. These findings demonstrate the feasibility of a fully automated
end-to-end LLM-symbolic planner that requires no expert intervention, opening
up the possibility for a broader audience to engage with AI planning with less
prerequisite of domain expertise.

摘要：大型語言模型 (LLM) 在解決自然語言描述的規劃任務方面展現了前景，但其直接使用通常會導致不一致的推理和幻覺。雖然混合 LLM-符號規劃管道已成為一種更強健的替代方案，但它們通常需要廣泛的專家介入來優化和驗證產生的動作綱要。這不僅限制了可擴充性，還引入了偏差解釋的可能性，因為單一專家對模棱兩可的自然語言描述的解釋可能與使用者的實際意圖不符。為了解決這個問題，我們提出了一種新穎的方法，該方法構建了一個動作綱要庫，以產生多個候選者，並考慮自然語言描述的各種可能解釋。我們進一步引入了一個語義驗證和排名模組，該模組自動過濾和排名產生的綱要和計畫，而無需專家參與。實驗表明，我們的管道在規劃中保持了優於直接 LLM 規劃方法的優勢。這些發現證明了完全自動化的端到端 LLM-符號規劃器的可行性，該規劃器不需要專家介入，這為更廣泛的受眾參與 AI 規劃提供了可能性，而無需具備領域專業知識的先決條件。

##### **Explaining word embeddings with perfect fidelity: Case study in research impact prediction**
2409.15912v1 by Lucie Dvorackova, Marcin P. Joachimiak, Michal Cerny, Adriana Kubecova, Vilem Sklenak, Tomas Kliegr

Best performing approaches for scholarly document quality prediction are
based on embedding models, which do not allow direct explanation of classifiers
as distinct words no longer correspond to the input features for model
training. Although model-agnostic explanation methods such as Local
interpretable model-agnostic explanations (LIME) can be applied, these produce
results with questionable correspondence to the ML model. We introduce a new
feature importance method, Self-model Rated Entities (SMER), for logistic
regression-based classification models trained on word embeddings. We show that
SMER has theoretically perfect fidelity with the explained model, as its
prediction corresponds exactly to the average of predictions for individual
words in the text. SMER allows us to reliably determine which words or entities
positively contribute to predicting impactful articles. Quantitative and
qualitative evaluation is performed through five diverse experiments conducted
on 50.000 research papers from the CORD-19 corpus. Through an AOPC curve
analysis, we experimentally demonstrate that SMER produces better explanations
than LIME for logistic regression.

摘要：學術文件品質預測表現最佳的方法是基於嵌入模型，這不允許對分類器進行直接解釋，因為不同的單字不再對應於模型訓練的輸入特徵。儘管與模型無關的解釋方法（例如局部可解釋模型無關解釋 (LIME)）可以應用，但這些方法會產生與 ML 模型的對應關係可疑的結果。我們針對以詞嵌入為基礎訓練的邏輯迴歸分類模型，引入一種新的特徵重要性方法，即自我評級實體 (SMER)。我們證明 SMER 在理論上與所解釋的模型具有完美的保真度，因為它的預測完全對應於文字中個別單字預測的平均值。SMER 讓我們能夠可靠地確定哪些單字或實體對預測有影響力的文章有正向貢獻。透過在 CORD-19 語料庫中 50,000 篇研究論文上進行的五項不同的實驗，執行定量和定性評估。透過 AOPC 曲線分析，我們實驗性地證明 SMER 產生比 LIME 更好的邏輯迴歸解釋。

##### **A Modular-based Strategy for Mitigating Gradient Conflicts in Simultaneous Speech Translation**
2409.15911v1 by Xiaoqian Liu, Yangfan Du, Jianjin Wang, Yuan Ge, Chen Xu, Tong Xiao, Guocheng Chen, Jingbo Zhu

Simultaneous Speech Translation (SimulST) involves generating target language
text while continuously processing streaming speech input, presenting
significant real-time challenges. Multi-task learning is often employed to
enhance SimulST performance but introduces optimization conflicts between
primary and auxiliary tasks, potentially compromising overall efficiency. The
existing model-level conflict resolution methods are not well-suited for this
task which exacerbates inefficiencies and leads to high GPU memory consumption.
To address these challenges, we propose a Modular Gradient Conflict Mitigation
(MGCM) strategy that detects conflicts at a finer-grained modular level and
resolves them utilizing gradient projection. Experimental results demonstrate
that MGCM significantly improves SimulST performance, particularly under medium
and high latency conditions, achieving a 0.68 BLEU score gain in offline tasks.
Additionally, MGCM reduces GPU memory consumption by over 95\% compared to
other conflict mitigation methods, establishing it as a robust solution for
SimulST tasks.

摘要：同步語音翻譯（SimulST）涉及在持續處理串流語音輸入時產生目標語言文本，帶來顯著的即時挑戰。多任務學習通常用於增強 SimulST 效能，但會在主要任務和輔助任務之間產生最佳化衝突，可能損害整體效率。現有的模型層級衝突解決方法並不適合此任務，這會加劇低效率並導致高 GPU 記憶體消耗。為了應對這些挑戰，我們提出了一個模組化梯度衝突緩解（MGCM）策略，它可以在更細粒度的模組層級偵測衝突，並利用梯度投影來解決這些衝突。實驗結果證明，MGCM 大幅改善了 SimulST 效能，尤其是在中高延遲條件下，在離線任務中獲得 0.68 的 BLEU 分數增益。此外，與其他衝突緩解方法相比，MGCM 將 GPU 記憶體消耗降低了 95% 以上，使其成為 SimulST 任務的強大解決方案。

##### **Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**
2409.15910v1 by Kriti Agarwal, Samhruth Ananthanarayanan, Srinitish Srinivasan, Abirami S

This paper presents the development of a novel plant communication
application that allows plants to "talk" to humans using real-time sensor data
and AI-powered language models. Utilizing soil sensors that track moisture,
temperature, and nutrient levels, the system feeds this data into the Gemini
API, where it is processed and transformed into natural language insights about
the plant's health and "mood." Developed using Flutter, Firebase, and
ThingSpeak, the app offers a seamless user experience with real-time
interaction capabilities. By fostering human-plant connectivity, this system
enhances plant care practices, promotes sustainability, and introduces
innovative applications for AI and IoT technologies in both personal and
agricultural contexts. The paper explores the technical architecture, system
integration, and broader implications of AI-driven plant communication.

摘要：本文介紹了一款新穎的植物溝通應用程式的開發，它允許植物利用即時感測器資料和 AI 語言模型與人類「對話」。系統利用追蹤水分、溫度和養分含量的土壤感測器，將這些資料輸入 Gemini API，並在其中進行處理，轉換成關於植物健康和「情緒」的自然語言見解。此應用程式使用 Flutter、Firebase 和 ThingSpeak 開發，提供與即時互動功能無縫接軌的使用者體驗。透過促進人與植物的連結，此系統提升了植物照護方式，促進永續性，並在個人和農業情境中引進了 AI 和 IoT 技術的創新應用。本文探討了 AI 驅動的植物溝通技術架構、系統整合和更廣泛的意涵。

##### **Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection**
2409.15907v1 by Xingyu Ma, Xin Tian, Lingxiang Wu, Xuepeng Wang, Xueming Tang, Jinqiao Wang

Text-to-SQL is a subtask in semantic parsing that has seen rapid progress
with the evolution of Large Language Models (LLMs). However, LLMs face
challenges due to hallucination issues and a lack of domain-specific database
knowledge(such as table schema and cell values). As a result, they can make
errors in generating table names, columns, and matching values to the correct
columns in SQL statements. This paper introduces a method of knowledge
injection to enhance LLMs' ability to understand schema contents by
incorporating prior knowledge. This approach improves their performance in
Text-to-SQL tasks. Experimental results show that pre-training LLMs on
domain-specific database knowledge and fine-tuning them on downstream
Text-to-SQL tasks significantly improves the Execution Match (EX) and Exact
Match (EM) metrics across various models. This effectively reduces errors in
generating column names and matching values to the columns. Furthermore, the
knowledge-injected models can be applied to many downstream Text-to-SQL tasks,
demonstrating the generalizability of the approach presented in this paper.

摘要：文本到 SQL 是语义解析中的一个子任务，随着大型语言模型 (LLM) 的发展，它取得了快速进展。然而，LLM 面临着幻觉问题和缺乏特定于领域的数据库知识（例如表模式和单元格值）的挑战。因此，它们在生成表名称、列和将值匹配到 SQL 语句中的正确列时可能会出错。本文介绍了一种知识注入方法，通过纳入先验知识来增强 LLM 理解模式内容的能力。这种方法提高了它们在文本到 SQL 任务中的性能。实验结果表明，针对特定于领域的数据库知识对 LLM 进行预训练，并在下游文本到 SQL 任务中对它们进行微调，显著提高了各种模型的执行匹配 (EX) 和精确匹配 (EM) 指标。这有效地减少了在生成列名称和将值匹配到列时出现的错误。此外，注入知识的模型可以应用于许多下游文本到 SQL 任务，展示了本文提出的方法的泛化性。

##### **Boosting Code-Switching ASR with Mixture of Experts Enhanced Speech-Conditioned LLM**
2409.15905v1 by Fengrun Zhang, Wang Geng, Hukai Huang, Cheng Yi, He Qu

In this paper, we introduce a speech-conditioned Large Language Model (LLM)
integrated with a Mixture of Experts (MoE) based connector to address the
challenge of Code-Switching (CS) in Automatic Speech Recognition (ASR).
Specifically, we propose an Insertion and Deletion of Interruption Token (IDIT)
mechanism for better transfer text generation ability of LLM to speech
recognition task. We also present a connecter with MoE architecture that
manages multiple languages efficiently. To further enhance the collaboration of
multiple experts and leverage the understanding capabilities of LLM, we propose
a two-stage progressive training strategy: 1) The connector is unfrozen and
trained with language-specialized experts to map speech representations to the
text space. 2) The connector and LLM LoRA adaptor are trained with the proposed
IDIT mechanism and all experts are activated to learn general representations.
Experimental results demonstrate that our method significantly outperforms
state-of-the-art models, including end-to-end and large-scale audio-language
models.

摘要：在本文中，我們介紹了一個語音條件化的巨量語言模型 (LLM)，它與基於專家混合 (MoE) 的連接器整合，以解決自動語音識別 (ASR) 中的代碼轉換 (CS) 挑戰。具體來說，我們提出了一個中斷標記的插入和刪除 (IDIT) 機制，以提高 LLM 將文本生成能力轉移到語音識別任務的能力。我們還提出了一個具有 MoE 架構的連接器，它可以有效地管理多種語言。為了進一步增強多個專家的協作並利用 LLM 的理解能力，我們提出了兩階段漸進式訓練策略：1) 連接器被解凍並與語言專家一起訓練，以將語音表示映射到文本空間。2) 連接器和 LLM LoRA 適配器使用建議的 IDIT 機制進行訓練，並且所有專家都被激活以學習一般表示。實驗結果表明，我們的模型明顯優於最先進的模型，包括端到端和大規模音頻語言模型。

##### **Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**
2409.15902v1 by Maria Lysyuk, Mikhail Salnikov, Pavel Braslavski, Alexander Panchenko

While being one of the most popular question types, simple questions such as
"Who is the author of Cinderella?", are still not completely solved.
Surprisingly, even the most powerful modern Large Language Models are prone to
errors when dealing with such questions, especially when dealing with rare
entities. At the same time, as an answer may be one hop away from the question
entity, one can try to develop a method that uses structured knowledge graphs
(KGs) to answer such questions. In this paper, we introduce Konstruktor - an
efficient and robust approach that breaks down the problem into three steps:
(i) entity extraction and entity linking, (ii) relation prediction, and (iii)
querying the knowledge graph. Our approach integrates language models and
knowledge graphs, exploiting the power of the former and the interpretability
of the latter. We experiment with two named entity recognition and entity
linking methods and several relation detection techniques. We show that for
relation detection, the most challenging step of the workflow, a combination of
relation classification/generation and ranking outperforms other methods. We
report Konstruktor's strong results on four datasets.

摘要：儘管是最常見的問題類型之一，但諸如「灰姑娘的作者是誰？」這類簡單的問題仍未完全獲得解答。令人驚訝的是，即使是最強大的現代大型語言模型在處理此類問題時也容易出錯，特別是在處理罕見實體時。與此同時，由於答案可能距離問題實體僅一步之遙，因此可以嘗試開發一種使用結構化知識圖譜 (KG) 來回答此類問題的方法。在本文中，我們介紹 Konstruktor - 一種高效且強大的方法，它將問題分解為三個步驟：(i) 實體萃取和實體連結、(ii) 關係預測以及 (iii) 查詢知識圖譜。我們的做法整合了語言模型和知識圖譜，發揮了前者的能力和後者的可解釋性。我們實驗了兩種命名實體識別和實體連結方法以及多種關係偵測技術。我們表明，對於關係偵測，也就是工作流程中最具挑戰性的步驟，關係分類/生成和排名相結合的組合優於其他方法。我們報告了 Konstruktor 在四個資料集上的強勁成果。

##### **Symmetries and Expressive Requirements for Learning General Policies**
2409.15892v1 by Dominik Drexler, Simon Ståhlberg, Blai Bonet, Hector Geffner

State symmetries play an important role in planning and generalized planning.
In the first case, state symmetries can be used to reduce the size of the
search; in the second, to reduce the size of the training set. In the case of
general planning, however, it is also critical to distinguish non-symmetric
states, i.e., states that represent non-isomorphic relational structures.
However, while the language of first-order logic distinguishes non-symmetric
states, the languages and architectures used to represent and learn general
policies do not. In particular, recent approaches for learning general policies
use state features derived from description logics or learned via graph neural
networks (GNNs) that are known to be limited by the expressive power of C_2,
first-order logic with two variables and counting. In this work, we address the
problem of detecting symmetries in planning and generalized planning and use
the results to assess the expressive requirements for learning general policies
over various planning domains. For this, we map planning states to plain
graphs, run off-the-shelf algorithms to determine whether two states are
isomorphic with respect to the goal, and run coloring algorithms to determine
if C_2 features computed logically or via GNNs distinguish non-isomorphic
states. Symmetry detection results in more effective learning, while the
failure to detect non-symmetries prevents general policies from being learned
at all in certain domains.

摘要：狀態對稱性在規劃和廣義規劃中扮演著重要的角色。
在第一種情況中，狀態對稱性可用於縮小搜尋的規模；在第二種情況中，可用於縮小訓練集的規模。然而，在廣義規劃的情況中，區分非對稱狀態（即表示非同構關係結構的狀態）也很重要。然而，雖然一階邏輯的語言區分了非對稱狀態，但用於表示和學習一般策略的語言和架構卻沒有。特別是，最近用於學習一般策略的方法使用從描述邏輯中衍生的狀態特徵，或通過圖神經網路 (GNN) 學習，已知這些特徵受到具有兩個變數和計數的一階邏輯 C_2 的表達能力限制。在這項工作中，我們解決了在規劃和廣義規劃中檢測對稱性的問題，並使用結果評估在各種規劃領域中學習一般策略的表達需求。為此，我們將規劃狀態映射到平面圖形，執行現成的演算法來確定兩個狀態是否相對於目標同構，並執行著色演算法來確定透過邏輯或 GNN 計算的 C_2 特徵是否區分非同構狀態。對稱性檢測會帶來更有效的學習，而無法檢測非對稱性則會完全阻止在某些領域中學習一般策略。

##### **HLB: Benchmarking LLMs' Humanlikeness in Language Use**
2409.15890v1 by Xufeng Duan, Bei Xiao, Xuemei Tang, Zhenguang G. Cai

As synthetic data becomes increasingly prevalent in training language models,
particularly through generated dialogue, concerns have emerged that these
models may deviate from authentic human language patterns, potentially losing
the richness and creativity inherent in human communication. This highlights
the critical need to assess the humanlikeness of language models in real-world
language use. In this paper, we present a comprehensive humanlikeness benchmark
(HLB) evaluating 20 large language models (LLMs) using 10 psycholinguistic
experiments designed to probe core linguistic aspects, including sound, word,
syntax, semantics, and discourse (see
https://huggingface.co/spaces/XufengDuan/HumanLikeness). To anchor these
comparisons, we collected responses from over 2,000 human participants and
compared them to outputs from the LLMs in these experiments.
  For rigorous evaluation, we developed a coding algorithm that accurately
identified language use patterns, enabling the extraction of response
distributions for each task. By comparing the response distributions between
human participants and LLMs, we quantified humanlikeness through distributional
similarity. Our results reveal fine-grained differences in how well LLMs
replicate human responses across various linguistic levels. Importantly, we
found that improvements in other performance metrics did not necessarily lead
to greater humanlikeness, and in some cases, even resulted in a decline. By
introducing psycholinguistic methods to model evaluation, this benchmark offers
the first framework for systematically assessing the humanlikeness of LLMs in
language use.

摘要：隨著合成資料在訓練語言模型中變得越來越普遍，特別是透過產生的對話，人們開始擔心這些模型可能會偏離真實的人類語言模式，潛在喪失人類溝通中固有的豐富性和創造力。這凸顯了在現實世界的語言使用中評估語言模型的人類相似性的關鍵需求。在本文中，我們提出了一個全面的類人基準 (HLB)，使用 10 個心理語言學實驗評估 20 個大型語言模型 (LLM)，這些實驗旨在探討核心語言學方面，包括聲音、詞彙、句法、語義和語篇（請參閱 https://huggingface.co/spaces/XufengDuan/HumanLikeness）。為了固定這些比較，我們收集了來自 2,000 多名人類參與者的回應，並在這些實驗中將它們與 LLM 的輸出進行比較。為了進行嚴謹的評估，我們開發了一種編碼演算法，可以準確識別語言使用模式，從而能夠提取每個任務的回應分佈。透過比較人類參與者和 LLM 之間的回應分佈，我們透過分佈相似性量化了類人度。我們的結果揭示了 LLM 在不同語言層級複製人類回應的細微差異。重要的是，我們發現其他效能指標的改進並不一定會導致更高的類人度，在某些情況下，甚至會導致下降。透過將心理語言學方法引入模型評估，此基準提供了第一個系統性評估 LLM 在語言使用中類人度的架構。

##### **Machine Translation Advancements of Low-Resource Indian Languages by Transfer Learning**
2409.15879v1 by Bin Wei, Jiawei Zhen, Zongyao Li, Zhanglin Wu, Daimeng Wei, Jiaxin Guo, Zhiqiang Rao, Shaojun Li, Yuanchang Luo, Hengchao Shang, Jinlong Yang, Yuhao Xie, Hao Yang

This paper introduces the submission by Huawei Translation Center (HW-TSC) to
the WMT24 Indian Languages Machine Translation (MT) Shared Task. To develop a
reliable machine translation system for low-resource Indian languages, we
employed two distinct knowledge transfer strategies, taking into account the
characteristics of the language scripts and the support available from existing
open-source models for Indian languages. For Assamese(as) and Manipuri(mn), we
fine-tuned the existing IndicTrans2 open-source model to enable bidirectional
translation between English and these languages. For Khasi (kh) and Mizo (mz),
We trained a multilingual model as a baseline using bilingual data from these
four language pairs, along with an additional about 8kw English-Bengali
bilingual data, all of which share certain linguistic features. This was
followed by fine-tuning to achieve bidirectional translation between English
and Khasi, as well as English and Mizo. Our transfer learning experiments
produced impressive results: 23.5 BLEU for en-as, 31.8 BLEU for en-mn, 36.2
BLEU for as-en, and 47.9 BLEU for mn-en on their respective test sets.
Similarly, the multilingual model transfer learning experiments yielded
impressive outcomes, achieving 19.7 BLEU for en-kh, 32.8 BLEU for en-mz, 16.1
BLEU for kh-en, and 33.9 BLEU for mz-en on their respective test sets. These
results not only highlight the effectiveness of transfer learning techniques
for low-resource languages but also contribute to advancing machine translation
capabilities for low-resource Indian languages.

摘要：這篇論文介紹了華為翻譯中心 (HW-TSC) 提交給 WMT24 印度語言機器翻譯 (MT) 共享任務的內容。為了開發一個針對低資源印度語言的可靠機器翻譯系統，我們採用了兩種不同的知識轉移策略，並考量到語言腳本的特性以及現有印度語言開源模型提供的支援。對於阿薩姆語 (as) 和曼尼普爾語 (mn)，我們微調了現有的 IndicTrans2 開源模型，以實現英語和這些語言之間的雙向翻譯。對於卡西語 (kh) 和米佐語 (mz)，我們使用這四種語言對的雙語資料訓練了一個多語言模型作為基準，以及大約 8kw 的英語-孟加拉語雙語資料，所有這些都具有一些語言特徵。接著進行微調，以實現英語和卡西語之間的雙向翻譯，以及英語和米佐語之間的雙向翻譯。我們的遷移學習實驗產生了令人印象深刻的結果：在各自的測試集中，en-as 的 BLEU 為 23.5、en-mn 的 BLEU 為 31.8、as-en 的 BLEU 為 36.2，以及 mn-en 的 BLEU 為 47.9。同樣地，多語言模型遷移學習實驗也產生了令人印象深刻的成果，在各自的測試集中，en-kh 的 BLEU 為 19.7、en-mz 的 BLEU 為 32.8、kh-en 的 BLEU 為 16.1，以及 mz-en 的 BLEU 為 33.9。這些結果不僅突顯了遷移學習技術對低資源語言的有效性，也為提升低資源印度語言的機器翻譯能力做出了貢獻。

##### **Whisper in Medusa's Ear: Multi-head Efficient Decoding for Transformer-based ASR**
2409.15869v1 by Yael Segal-Feldman, Aviv Shamsian, Aviv Navon, Gill Hetz, Joseph Keshet

Large transformer-based models have significant potential for speech
transcription and translation. Their self-attention mechanisms and parallel
processing enable them to capture complex patterns and dependencies in audio
sequences. However, this potential comes with challenges, as these large and
computationally intensive models lead to slow inference speeds. Various
optimization strategies have been proposed to improve performance, including
efficient hardware utilization and algorithmic enhancements. In this paper, we
introduce Whisper-Medusa, a novel approach designed to enhance processing speed
with minimal impact on Word Error Rate (WER). The proposed model extends the
OpenAI's Whisper architecture by predicting multiple tokens per iteration,
resulting in a 50% reduction in latency. We showcase the effectiveness of
Whisper-Medusa across different learning setups and datasets.

摘要：大型Transformer模型在語音轉錄和翻譯方面具有巨大潛力。它們的自我注意機制和並行處理使它們能夠捕捉音訊序列中的複雜模式和依賴關係。然而，這種潛力也帶來挑戰，因為這些大型且計算密集的模型會導致緩慢的推理速度。已經提出了各種最佳化策略來改善效能，包括有效率的硬體利用和演算法強化。在本文中，我們介紹了 Whisper-Medusa，這是一種新穎的方法，旨在提高處理速度，同時對字元錯誤率 (WER) 的影響最小。所提出的模型透過每次疊代預測多個代碼，擴充了 OpenAI 的 Whisper 架構，從而將延遲減少了 50%。我們展示了 Whisper-Medusa 在不同學習設定和資料集中的有效性。

##### **Privacy Evaluation Benchmarks for NLP Models**
2409.15868v2 by Wei Huang, Yinggui Wang, Cen Chen

By inducing privacy attacks on NLP models, attackers can obtain sensitive
information such as training data and model parameters, etc. Although
researchers have studied, in-depth, several kinds of attacks in NLP models,
they are non-systematic analyses. It lacks a comprehensive understanding of the
impact caused by the attacks. For example, we must consider which scenarios can
apply to which attacks, what the common factors are that affect the performance
of different attacks, the nature of the relationships between different
attacks, and the influence of various datasets and models on the effectiveness
of the attacks, etc. Therefore, we need a benchmark to holistically assess the
privacy risks faced by NLP models. In this paper, we present a privacy attack
and defense evaluation benchmark in the field of NLP, which includes the
conventional/small models and large language models (LLMs). This benchmark
supports a variety of models, datasets, and protocols, along with standardized
modules for comprehensive evaluation of attacks and defense strategies. Based
on the above framework, we present a study on the association between auxiliary
data from different domains and the strength of privacy attacks. And we provide
an improved attack method in this scenario with the help of Knowledge
Distillation (KD). Furthermore, we propose a chained framework for privacy
attacks. Allowing a practitioner to chain multiple attacks to achieve a
higher-level attack objective. Based on this, we provide some defense and
enhanced attack strategies. The code for reproducing the results can be found
at https://github.com/user2311717757/nlp_doctor.

摘要：<paragraph>透過對 NLP 模型發動隱私攻擊，攻擊者可以取得訓練資料、模型參數等敏感資訊。儘管研究人員深入研究了 NLP 模型中各種攻擊，但這些分析並非系統性的。它缺乏對攻擊所造成影響的全面理解。例如，我們必須考慮哪些場景可以應用於哪些攻擊、影響不同攻擊效能的共同因素是什麼、不同攻擊之間關係的性質以及各種資料集和模型對攻擊有效性的影響等。因此，我們需要一個基準來全面評估 NLP 模型面臨的隱私風險。在本文中，我們提出了 NLP 領域中的隱私攻擊和防禦評估基準，其中包括傳統/小型模型和大語言模型 (LLM)。此基準支援各種模型、資料集和協定，以及用於全面評估攻擊和防禦策略的標準化模組。基於上述架構，我們提出了一項關於不同領域的輔助資料與隱私攻擊強度之間關聯性的研究。我們在這種情況下提供了一種改良的攻擊方法，並借助知識蒸餾 (KD) 來進行。此外，我們提出了隱私攻擊的鏈式架構。允許從業人員鏈接多個攻擊以達成更高級別的攻擊目標。基於此，我們提供了一些防禦和增強攻擊策略。可以在 https://github.com/user2311717757/nlp_doctor 中找到重現結果的程式碼。</paragraph>

##### **In-Context Ensemble Improves Video-Language Models for Low-Level Workflow Understanding from Human Demonstrations**
2409.15867v2 by Moucheng Xu, Evangelos Chatzaroulas, Luc McCutcheon, Abdul Ahad, Hamzah Azeem, Janusz Marecki, Ammar Anwar

A Standard Operating Procedure (SOP) defines a low-level, step-by-step
written guide for a business software workflow based on a video demonstration.
SOPs are a crucial step toward automating end-to-end software workflows.
Manually creating SOPs can be time-consuming. Recent advancements in large
video-language models offer the potential for automating SOP generation by
analyzing recordings of human demonstrations. However, current large
video-language models face challenges with zero-shot SOP generation. We explore
in-context learning with video-language models for SOP generation. We report
that in-context learning sometimes helps video-language models at SOP
generation. We then propose an in-context ensemble learning to further enhance
the capabilities of the models in SOP generation.

摘要：標準作業程序 (SOP) 定義了基於影片示範的業務軟體工作流程的低階、逐步書面指南。SOP 是自動化端對端軟體工作流程的關鍵步驟。手動建立 SOP 可能非常耗時。大型視訊語言模型的最新進展提供了透過分析人類示範的錄製內容來自動化 SOP 生成的可能性。但是，目前的大型視訊語言模型在零次學習 SOP 生成時會遇到挑戰。我們探討了使用視訊語言模型進行情境內學習以生成 SOP。我們報告說，情境內學習有時有助於視訊語言模型生成 SOP。然後，我們提出了一種情境內集成學習，以進一步增強模型在 SOP 生成中的能力。

##### **BeSimulator: A Large Language Model Powered Text-based Behavior Simulator**
2409.15865v1 by Jianan Wang, Bin Li, Xueying Wang, Fu Li, Yunlong Wu, Juan Chen, Xiaodong Yi

Traditional robot simulators focus on physical process modeling and realistic
rendering, often suffering from high computational costs, inefficiencies, and
limited adaptability. To handle this issue, we propose Behavior Simulation in
robotics to emphasize checking the behavior logic of robots and achieving
sufficient alignment between the outcome of robot actions and real scenarios.
In this paper, we introduce BeSimulator, a modular and novel LLM-powered
framework, as an attempt towards behavior simulation in the context of
text-based environments. By constructing text-based virtual environments and
performing semantic-level simulation, BeSimulator can generalize across
scenarios and achieve long-horizon complex simulation. Inspired by human
cognition processes, it employs a "consider-decide-capture-transfer"
methodology, termed Chain of Behavior Simulation, which excels at analyzing
action feasibility and state transitions. Additionally, BeSimulator
incorporates code-driven reasoning to enable arithmetic operations and enhance
reliability, as well as integrates reflective feedback to refine simulation.
Based on our manually constructed behavior-tree-based simulation benchmark
BTSIMBENCH, our experiments show a significant performance improvement in
behavior simulation compared to baselines, ranging from 14.7% to 26.6%.

摘要：傳統機器人模擬器專注於物理程序建模和逼真的渲染，通常會面臨高運算成本、低效率和適應性有限等問題。為了處理這個問題，我們提出機器人的行為模擬，以強調檢查機器人的行為邏輯，並在機器人動作的結果和真實場景之間達成充分的一致性。在本文中，我們介紹了 BeSimulator，一個模組化且新穎的 LLM 驅動架構，作為在基於文字的環境中進行行為模擬的嘗試。透過建構基於文字的虛擬環境並執行語義層級的模擬，BeSimulator 能夠在各種場景中進行概化，並達成長時程複雜的模擬。受到人類認知過程的啟發，它採用「考慮-決定-擷取-傳輸」的方法，稱為行為模擬鏈，擅長分析動作可行性和狀態轉換。此外，BeSimulator 結合了程式碼驅動的推理，以啟用算術運算並增強可靠性，並整合反思性回饋以改善模擬。根據我們手動建構的行為樹為基礎的模擬基準 BTSIMBENCH，我們的實驗顯示，與基線相比，行為模擬的效能有顯著的提升，範圍從 14.7% 到 26.6%。

##### **A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding**
2409.15861v1 by Abdulfattah Safa, Gözde Gül Şahin

Dialogue State Tracking (DST) is crucial for understanding user needs and
executing appropriate system actions in task-oriented dialogues. Majority of
existing DST methods are designed to work within predefined ontologies and
assume the availability of gold domain labels, struggling with adapting to new
slots values. While Large Language Models (LLMs)-based systems show promising
zero-shot DST performance, they either require extensive computational
resources or they underperform existing fully-trained systems, limiting their
practicality. To address these limitations, we propose a zero-shot,
open-vocabulary system that integrates domain classification and DST in a
single pipeline. Our approach includes reformulating DST as a
question-answering task for less capable models and employing self-refining
prompts for more adaptable ones. Our system does not rely on fixed slot values
defined in the ontology allowing the system to adapt dynamically. We compare
our approach with existing SOTA, and show that it provides up to 20% better
Joint Goal Accuracy (JGA) over previous methods on datasets like Multi-WOZ 2.1,
with up to 90% fewer requests to the LLM API.

摘要：對話狀態追蹤 (DST) 對於理解使用者需求和在任務導向對話中執行適當的系統動作至關重要。大多數現有的 DST 方法都是設計在預定義的本体中運作，並假設有黃金領域標籤可用，難以適應新的槽值。雖然基於大型語言模型 (LLM) 的系統顯示出有希望的零次學習 DST 效能，但它們需要大量的計算資源或效能低於現有的完全訓練系統，限制了它們的實用性。為了解決這些限制，我們提出了一個零次學習、開放詞彙系統，它將領域分類和 DST 整合在一個單一的管線中。我們的做法包括將 DST 重新表述為一個問題回答任務，以適用於能力較弱的模型，並採用自我精進提示，以適用於適應性較強的模型。我們的系統不依賴本体中定義的固定槽值，允許系統動態適應。我們將我們的做法與現有的 SOTA 進行比較，並顯示它在 Multi-WOZ 2.1 等資料集上提供比先前方法高達 20% 的聯合目標準確度 (JGA)，對 LLM API 的請求減少了 90%。

##### **Identification For Control Based on Neural Networks: Approximately Linearizable Models**
2409.15858v1 by Maxime Thieffry, Alexandre Hache, Mohamed Yagoubi, Philippe Chevrel

This work presents a control-oriented identification scheme for efficient
control design and stability analysis of nonlinear systems. Neural networks are
used to identify a discrete-time nonlinear state-space model to approximate
time-domain input-output behavior of a nonlinear system. The network is
constructed such that the identified model is approximately linearizable by
feedback, ensuring that the control law trivially follows from the learning
stage. After the identification and quasi-linearization procedures, linear
control theory comes at hand to design robust controllers and study stability
of the closed-loop system. The effectiveness and interest of the methodology
are illustrated throughout the paper on popular benchmarks for system
identification.

摘要：本研究提出一個以控制為導向的識別方案，用於非線性系統的有效控制設計和穩定性分析。神經網路用於識別離散時間非線性狀態空間模型，以逼近非線性系統的時域輸入輸出行為。網路的建構方式使得識別出的模型可透過回饋近似線性化，確保控制律可以輕易地從學習階段中得到。在識別和準線性化程序後，線性控制理論可以設計出穩健的控制器，並研究閉迴路系統的穩定性。本文說明了此方法的有效性和趣味性，並在系統識別的熱門基準上進行說明。

##### **iGAiVA: Integrated Generative AI and Visual Analytics in a Machine Learning Workflow for Text Classification**
2409.15848v1 by Yuanzhe Jin, Adrian Carrasco-Revilla, Min Chen

In developing machine learning (ML) models for text classification, one
common challenge is that the collected data is often not ideally distributed,
especially when new classes are introduced in response to changes of data and
tasks. In this paper, we present a solution for using visual analytics (VA) to
guide the generation of synthetic data using large language models. As VA
enables model developers to identify data-related deficiency, data synthesis
can be targeted to address such deficiency. We discuss different types of data
deficiency, describe different VA techniques for supporting their
identification, and demonstrate the effectiveness of targeted data synthesis in
improving model accuracy. In addition, we present a software tool, iGAiVA,
which maps four groups of ML tasks into four VA views, integrating generative
AI and VA into an ML workflow for developing and improving text classification
models.

摘要：在開發用於文字分類的機器學習 (ML) 模型時，一個常見的挑戰是收集到的資料通常分佈不理想，特別是在針對資料和任務的變更引入新類別時。在本文中，我們提出了一個使用視覺分析 (VA) 來引導使用大型語言模型產生合成資料的解決方案。由於 VA 能讓模型開發人員識別與資料相關的缺陷，因此資料合成可以針對解決此類缺陷。我們討論了不同類型的資料缺陷，描述了用於支援其識別的不同 VA 技術，並展示了針對性資料合成在改善模型準確性方面的有效性。此外，我們提出了軟體工具 iGAiVA，它將四組 ML 任務對應到四個 VA 檢視，將生成式 AI 和 VA 整合到 ML 工作流程中，用於開發和改善文字分類模型。

##### **Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection**
2409.15844v1 by Matteo Zecchin, Osvaldo Simeone

We introduce adaptive learn-then-test (aLTT), an efficient hyperparameter
selection procedure that provides finite-sample statistical guarantees on the
population risk of AI models. Unlike the existing learn-then-test (LTT)
technique, which relies on conventional p-value-based multiple hypothesis
testing (MHT), aLTT implements sequential data-dependent MHT with early
termination by leveraging e-processes. As a result, aLTT can reduce the number
of testing rounds, making it particularly well-suited for scenarios in which
testing is costly or presents safety risks. Apart from maintaining statistical
validity, in applications such as online policy selection for offline
reinforcement learning and hyperparameter tuning for engineering systems, aLTT
is shown to achieve the same performance as LTT while requiring only a fraction
of the testing rounds.

摘要：我們引進自適應先學習再測試 (aLTT)，這是一種有效率的超參數選擇程序，可提供 AI 模型族群風險的有限樣本統計保證。與依賴傳統基於 p 值的多重假設檢定 (MHT) 的現有先學習再測試 (LTT) 技術不同，aLTT 透過善用 e 程序實作順序資料依賴型 MHT，並提早終止。因此，aLTT 可以減少測試回合數，使其特別適用於測試成本高昂或存在安全風險的場景。除了維持統計效度之外，在離線強化學習的線上政策選擇和工程系統的超參數調整等應用中，aLTT 已被證明可以達成與 LTT 相同的效能，同時只使用一小部分的測試回合。

##### **From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistant**
2409.15843v1 by Anna Bodonhelyi, Enkeleda Thaqi, Süleyman Özdel, Efe Bozkir, Enkelejda Kasneci

In online education, innovative tools are crucial for enhancing learning
outcomes. SAM (Study with AI Mentor) is an advanced platform that integrates
educational videos with a context-aware chat interface powered by large
language models. SAM encourages students to ask questions and explore unclear
concepts in real-time, offering personalized, context-specific assistance,
including explanations of formulas, slides, and images. In a crowdsourced user
study involving 140 participants, SAM was evaluated through pre- and
post-knowledge tests, comparing a group using SAM with a control group. The
results demonstrated that SAM users achieved greater knowledge gains, with a
96.8% answer accuracy. Participants also provided positive feedback on SAM's
usability and effectiveness. SAM's proactive approach to learning not only
enhances learning outcomes but also empowers students to take full ownership of
their educational experience, representing a promising future direction for
online learning tools.

摘要：在線上教育中，創新的工具對於提升學習成果至關重要。SAM（與AI導師一起學習）是一個進階平台，它將教育影片與由大型語言模型驅動的情境感知聊天介面整合在一起。SAM鼓勵學生提問並即時探索不清楚的概念，提供個人化的、特定於情境的協助，包括公式、投影片和影像的說明。在一個涉及140名參與者的群眾外包使用者研究中，SAM透過事前和事後的知識測驗進行評估，比較使用SAM的組別與對照組。結果顯示，SAM使用者獲得了更大的知識收益，答題準確度為96.8%。參與者也對SAM的可用性和有效性提供了正面的回饋。SAM積極主動的學習方式不僅能提升學習成果，還能讓學生對自己的教育經驗擁有完全的主導權，這代表了線上學習工具一個有前途的未來方向。

##### **Unveiling Language Competence Neurons: A Psycholinguistic Approach to Model Interpretability**
2409.15827v1 by Xufeng Duan, Xinyu Zhou, Bei Xiao, Zhenguang G. Cai

As large language models (LLMs) become advance in their linguistic capacity,
understanding how they capture aspects of language competence remains a
significant challenge. This study therefore employs psycholinguistic paradigms,
which are well-suited for probing deeper cognitive aspects of language
processing, to explore neuron-level representations in language model across
three tasks: sound-shape association, sound-gender association, and implicit
causality. Our findings indicate that while GPT-2-XL struggles with the
sound-shape task, it demonstrates human-like abilities in both sound-gender
association and implicit causality. Targeted neuron ablation and activation
manipulation reveal a crucial relationship: when GPT-2-XL displays a linguistic
ability, specific neurons correspond to that competence; conversely, the
absence of such an ability indicates a lack of specialized neurons. This study
is the first to utilize psycholinguistic experiments to investigate deep
language competence at the neuron level, providing a new level of granularity
in model interpretability and insights into the internal mechanisms driving
language ability in transformer based LLMs.

摘要：隨著大型語言模型 (LLM) 在語言能力上的進步，
了解它們如何捕捉語言能力的各個面向仍然是一項重大的挑戰。因此，本研究採用心理語言學範例，
這非常適合探討語言處理的更深層認知面向，以探索語言模型在以下三項任務中的神經元層級表徵：音形聯想、音性聯想和內隱因果關係。我們的研究結果表明，儘管 GPT-2-XL 在音形任務中表現不佳，但在音性聯想和內隱因果關係中都展現出類似人類的能力。針對神經元的消融和活化操作揭示了一個關鍵關係：當 GPT-2-XL 展現出語言能力時，特定神經元會對應到該能力；反之，缺乏這種能力表示缺乏專門的神經元。本研究首次利用心理語言學實驗來探討神經元層級的深度語言能力，在模型可解釋性和見解方面提供了新的細緻程度，深入探討了基於 Transformer 的 LLM 中驅動語言能力的內部機制。

##### **Empirical Insights on Fine-Tuning Large Language Models for Question-Answering**
2409.15825v1 by Junjie Ye, Yuming Yang, Qi Zhang, Tao Gui, Xuanjing Huang, Peng Wang, Zhongchao Shi, Jianping Fan

Large language models (LLMs) encode extensive world knowledge through
pre-training on massive datasets, which can then be fine-tuned for the
question-answering (QA) task. However, effective strategies for fine-tuning
LLMs for the QA task remain largely unexplored. To address this gap, we
categorize supervised fine-tuning (SFT) data based on the extent of knowledge
memorized by the pretrained LLMs and conduct a series of empirical analyses.
Our experiments, involving four LLMs from three different model families, focus
on three key factors: the amount of data required for SFT, the impact of
different SFT datasets on model performance, and how data requirements vary
across LLMs. The results show that as few as 60 data points during the SFT
stage can activate the knowledge encoded during pre-training, enabling LLMs to
perform the QA task. Additionally, SFT with data of varying memory levels has a
significant impact on LLM performance, with the optimal dataset differing based
on the specific model being fine-tuned. Future research will delve deeper into
the mechanisms underlying these phenomena.

摘要：大型語言模型（LLM）透過大量資料集的預訓練編碼廣泛的世界知識，然後可以針對問答（QA）任務進行微調。然而，針對 QA 任務微調 LLM 的有效策略在很大程度上仍未探索。為了解決這個差距，我們根據預訓練 LLM 記憶的知識程度對監督式微調（SFT）資料進行分類，並進行一系列實證分析。我們的實驗涉及來自三個不同模型家族的四個 LLM，重點關注三個關鍵因素：SFT 所需的資料量、不同 SFT 資料集對模型效能的影響，以及資料需求如何因 LLM 而異。結果顯示，在 SFT 階段中，只要 60 個資料點就能啟動預訓練期間編碼的知識，讓 LLM 能執行 QA 任務。此外，使用具有不同記憶層級資料的 SFT 對 LLM 效能有顯著影響，最佳資料集會根據要微調的特定模型而有所不同。未來的研究將深入探討這些現象背後的機制。

##### **Supervised Fine-Tuning: An Activation Pattern Optimization Process for Attention Heads**
2409.15820v1 by Yang Zhao, Li Du, Xiao Ding, Kai Xiong, Ting Liu, Bing Qin

Though demonstrating promising potential, LLMs' performance on complex tasks,
such as advanced mathematics and complex disease diagnosis is still
unsatisfactory. A key issue is the present LLMs learn in a data-driven schema,
while the instruction dataset about these complex tasks is both scarce and hard
to collect or construct. On the contrary, a prominent phenomenon is that LLMs
can learn rather fast on those simpler tasks with adequate prior knowledge
captured during pretraining stage. Thus, if the prerequisite and mechanism of
such rapid generalization could be elucidated, it could be highly beneficial in
enhancing the efficiency and effectiveness of the LLM's ability to learn
complex tasks. Thus, in this paper, we employ a gradient-based method, to
dissect the process that the SFT process adapts LLMs to downstream tasks via
the perspective of attention patterns. We find that: (1) LLMs selectively
activate task-specific attention heads during SFT; (2) activation patterns for
complex tasks are combinations of basic task patterns; and (3) changes in a few
parameters can significantly impact activation patterns after SFT on a small
number of samples. Based on these insights, we conduct experiments to examine
whether these conclusions could effectively enhance the efficiency and
effectiveness of SFT, particularly in handling complex tasks and when
instructional resources are scarce. Our research not only uncovers the
underlying reasons behind LLMs' rapid learning and generalization mechanisms
but also provides practical solutions for addressing data challenges in complex
and specialized tasks.

摘要：儘管展示了有希望的潛力，但 LLM 在複雜任務上的表現，例如進階數學和複雜疾病診斷，仍然不令人滿意。一個關鍵問題是目前的 LLM 以資料驅動的模式學習，而關於這些複雜任務的指令資料集既稀少又難以收集或建構。相反，一個顯著的現象是，LLM 能在預訓練階段擷取的足夠先備知識下，在那些較簡單的任務上快速學習。因此，如果可以闡明這種快速概化的前提條件和機制，它可能對提高 LLM 學習複雜任務的能力的效率和有效性大有幫助。因此，在本文中，我們採用基於梯度的的方法，從注意力模式的角度剖析 SFT 過程適應 LLM 到下游任務的過程。我們發現：(1) LLM 在 SFT 期間選擇性地啟動特定於任務的注意力頭；(2) 複雜任務的啟動模式是基本任務模式的組合；(3) 少數參數的變化會顯著影響 SFT 後在少數樣本上的啟動模式。基於這些見解，我們進行實驗以檢驗這些結論是否能有效提高 SFT 的效率和有效性，特別是在處理複雜任務和指令資源稀缺時。我們的研究不僅揭示了 LLM 快速學習和概化機制背後的基本原因，還為解決複雜和專業任務中的資料挑戰提供了實用的解決方案。

##### **SwiftDossier: Tailored Automatic Dossier for Drug Discovery with LLMs and Agents**
2409.15817v1 by Gabriele Fossi, Youssef Boulaimen, Leila Outemzabet, Nathalie Jeanray, Stephane Gerart, Sebastien Vachenc, Joanna Giemza, Salvatore Raieli

The advancement of artificial intelligence algorithms has expanded their
application to several fields such as the biomedical domain. Artificial
intelligence systems, including Large Language Models (LLMs), can be
particularly advantageous in drug discovery, which is a very long and expensive
process. However, LLMs by themselves lack in-depth knowledge about specific
domains and can generate factually incorrect information. Moreover, they are
not able to perform more complex actions that imply the usage of external
tools. Our work is focused on these two issues. Firstly, we show how the
implementation of an advanced RAG system can help the LLM to generate more
accurate answers to drug-discovery-related questions. The results show that the
answers generated by the LLM with the RAG system surpass in quality the answers
produced by the model without RAG. Secondly, we show how to create an automatic
target dossier using LLMs and incorporating them with external tools that they
can use to execute more intricate tasks to gather data such as accessing
databases and executing code. The result is a production-ready target dossier
containing the acquired information summarized into a PDF and a PowerPoint
presentation.

摘要：人工智慧演算法的進步擴展了它們在生物醫學領域等多個領域的應用。人工智慧系統，包括大型語言模型 (LLM)，在藥物發現方面特別有利，而這是一個非常漫長且昂貴的過程。然而，LLM 本身缺乏特定領域的深入知識，並且可能會產生事實不正確的資訊。此外，它們無法執行更複雜的動作，這意味著使用外部工具。我們的研究重點在於這兩個問題。首先，我們展示了進階 RAG 系統的實作如何協助 LLM 產生更準確的答案來回答與藥物發現相關的問題。結果顯示，使用 RAG 系統的 LLM 所產生的答案品質超越了沒有 RAG 的模型所產生的答案。其次，我們展示了如何使用 LLM 建立自動化目標檔案，並將它們與外部工具整合，以便它們能夠執行更複雜的任務來收集資料，例如存取資料庫和執行程式碼。結果是一個可供生產使用的目標檔案，其中包含取得的資訊，並摘要成 PDF 和 PowerPoint 簡報。

##### **AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**
2409.15815v1 by Adil Bahaj, Mounir Ghogho

Asthma rates have risen globally, driven by environmental and lifestyle
factors. Access to immediate medical care is limited, particularly in
developing countries, necessitating automated support systems. Large Language
Models like ChatGPT (Chat Generative Pre-trained Transformer) and Gemini have
advanced natural language processing in general and question answering in
particular, however, they are prone to producing factually incorrect responses
(i.e. hallucinations). Retrieval-augmented generation systems, integrating
curated documents, can improve large language models' performance and reduce
the incidence of hallucination. We introduce AsthmaBot, a multi-lingual,
multi-modal retrieval-augmented generation system for asthma support.
Evaluation of an asthma-related frequently asked questions dataset shows
AsthmaBot's efficacy. AsthmaBot has an added interactive and intuitive
interface that integrates different data modalities (text, images, videos) to
make it accessible to the larger public. AsthmaBot is available online via
\url{asthmabot.datanets.org}.

摘要：氣喘發生率在全球上升，原因在於環境和生活方式的因素。立即獲得醫療照護的管道有限，特別是在開發中國家，這使得自動化支援系統變得必要。大型語言模型，例如 ChatGPT（Chat Generative Pre-trained Transformer）和 Gemini，已提升一般自然語言處理和特別是問答的進展，然而，它們容易產生事實上不正確的回應（即幻覺）。擷取增強生成系統，整合策展文件，可以提升大型語言模型的效能並減少幻覺發生的機率。我們介紹 AsthmaBot，一個多語言、多模態擷取增強生成系統，用於氣喘支援。評估與氣喘相關的常見問題資料集顯示 AsthmaBot 的效能。AsthmaBot 有一個額外的互動且直覺的介面，它整合不同的資料模式（文字、圖片、影片），使其能讓更多大眾使用。AsthmaBot 可透過 \url{asthmabot.datanets.org} 線上取得。

##### **Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**
2409.15814v1 by Min Hun Lee, Renee Bao Xuan Ng, Silvana Xinyi Choo, Shamala Thilarajah

A growing research explores the usage of AI explanations on user's decision
phases for human-AI collaborative decision-making. However, previous studies
found the issues of overreliance on `wrong' AI outputs. In this paper, we
propose interactive example-based explanations to improve health professionals'
onboarding with AI for their better reliance on AI during AI-assisted
decision-making. We implemented an AI-based decision support system that
utilizes a neural network to assess the quality of post-stroke survivors'
exercises and interactive example-based explanations that systematically
surface the nearest neighborhoods of a test/task sample from the training set
of the AI model to assist users' onboarding with the AI model. To investigate
the effect of interactive example-based explanations, we conducted a study with
domain experts, health professionals to evaluate their performance and reliance
on AI. Our interactive example-based explanations during onboarding assisted
health professionals in having a better reliance on AI and making a higher
ratio of making `right' decisions and a lower ratio of `wrong' decisions than
providing only feature-based explanations during the decision-support phase.
Our study discusses new challenges of assisting user's onboarding with AI for
human-AI collaborative decision-making.

摘要：越來越多研究探討在人類與 AI 協作決策時，使用 AI 解釋對使用者決策階段的影響。然而，先前的研究發現過度依賴「錯誤」的 AI 輸出的問題。在本文中，我們提出互動式範例為基礎的解釋，以改善醫療專業人員與 AI 的整合，讓他們在 AI 輔助決策時能更依賴 AI。我們實作了一個基於 AI 的決策支援系統，它利用神經網路評估中風後倖存者運動的品質，並利用互動式範例為基礎的解釋，系統性地從 AI 模型的訓練集中找出測試/任務範例最近的鄰域，以協助使用者與 AI 模型整合。為了探討互動式範例為基礎的解釋的效果，我們進行了一項研究，找來領域專家和醫療專業人員評估他們的表現與對 AI 的依賴。我們在整合期間提供的互動式範例為基礎的解釋，協助醫療專業人員更依賴 AI，並且在決策支援階段中做出「正確」決策的比率較高，而做出「錯誤」決策的比率較低，優於只提供基於特徵的解釋。我們的研究探討了在人類與 AI 協作決策時，協助使用者與 AI 整合的新挑戰。

##### **Layer-wise Model Merging for Unsupervised Domain Adaptation in Segmentation Tasks**
2409.15813v1 by Roberto Alcover-Couso, Juan C. SanMiguel, Marcos Escudero-Viñolo, Jose M Martínez

Merging parameters of multiple models has resurfaced as an effective strategy
to enhance task performance and robustness, but prior work is limited by the
high costs of ensemble creation and inference. In this paper, we leverage the
abundance of freely accessible trained models to introduce a cost-free approach
to model merging. It focuses on a layer-wise integration of merged models,
aiming to maintain the distinctiveness of the task-specific final layers while
unifying the initial layers, which are primarily associated with feature
extraction. This approach ensures parameter consistency across all layers,
essential for boosting performance. Moreover, it facilitates seamless
integration of knowledge, enabling effective merging of models from different
datasets and tasks. Specifically, we investigate its applicability in
Unsupervised Domain Adaptation (UDA), an unexplored area for model merging, for
Semantic and Panoptic Segmentation. Experimental results demonstrate
substantial UDA improvements without additional costs for merging
same-architecture models from distinct datasets ($\uparrow 2.6\%$ mIoU) and
different-architecture models with a shared backbone ($\uparrow 6.8\%$ mIoU).
Furthermore, merging Semantic and Panoptic Segmentation models increases mPQ by
$\uparrow 7\%$. These findings are validated across a wide variety of UDA
strategies, architectures, and datasets.

摘要：<paragraph>合併多個模型的參數已重新浮現為一種有效的策略，用以提升任務效能與穩健性，但先前的研究受限於整體建立與推論的高成本。在本文中，我們利用大量免費取得的已訓練模型，導入一種無成本的模型合併方法。它專注於合併模型的逐層整合，目標在於維持特定任務的最終層的獨特性，同時統一最初的層，這些層主要與特徵萃取相關。這種方法確保所有層的參數一致性，這對於提升效能至關重要。此外，它促進知識的無縫整合，讓來自不同資料集和任務的模型得以有效合併。具體來說，我們探討其在模型合併的未探索領域中用於無監督域適應 (UDA) 的適用性，以進行語義和全景分割。實驗結果顯示，在不增加合併成本的情況下，大幅改善 UDA，包括來自不同資料集的相同架構模型（mIoU 提升 2.6%）和具有共用主幹的不同架構模型（mIoU 提升 6.8%）。此外，合併語義和全景分割模型將 mPQ 提升 7%。這些發現已透過各種 UDA 策略、架構和資料集驗證。</paragraph>

##### **CLSP: High-Fidelity Contrastive Language-State Pre-training for Agent State Representation**
2409.15806v1 by Fuxian Huang, Qi Zhang, Shaopeng Zhai, Jie Wang, Tianyi Zhang, Haoran Zhang, Ming Zhou, Yu Liu, Yu Qiao

With the rapid development of artificial intelligence, multimodal learning
has become an important research area. For intelligent agents, the state is a
crucial modality to convey precise information alongside common modalities like
images, videos, and language. This becomes especially clear with the broad
adoption of reinforcement learning and multimodal large language models.
Nevertheless, the representation of state modality still lags in development.
To this end, we propose a High-Fidelity Contrastive Language-State Pre-training
(CLSP) method, which can accurately encode state information into general
representations for both reinforcement learning and multimodal large language
models. Specifically, we first design a pre-training task based on the
classification to train an encoder with coarse-grained information. Next, we
construct data pairs of states and language descriptions, utilizing the
pre-trained encoder to initialize the CLSP encoder. Then, we deploy contrastive
learning to train the CLSP encoder to effectively represent precise state
information. Additionally, we enhance the representation of numerical
information using the Random Fourier Features (RFF) method for high-fidelity
mapping. Extensive experiments demonstrate the superior precision and
generalization capabilities of our representation, achieving outstanding
results in text-state retrieval, reinforcement learning navigation tasks, and
multimodal large language model understanding.

摘要：隨著人工智慧的快速發展，多模態學習已成為重要的研究領域。對於智慧型代理而言，狀態是一種至關重要的模態，可用於傳達精確的資訊，以及影像、影片和語言等常見模態。這在廣泛採用強化學習和多模態大型語言模型的情況下尤其明顯。儘管如此，狀態模態的表示形式在發展上仍落後。為此，我們提出了一種高保真對比語言狀態預訓練 (CLSP) 方法，可以將狀態資訊準確編碼成一般表示，以用於強化學習和多模態大型語言模型。具體來說，我們首先設計一個基於分類的預訓練任務，以訓練一個具有粗粒度資訊的編碼器。接下來，我們建構狀態和語言描述的資料對，利用預訓練的編碼器初始化 CLSP 編碼器。然後，我們部署對比學習來訓練 CLSP 編碼器，以有效表示精確的狀態資訊。此外，我們使用隨機傅立葉特徵 (RFF) 方法增強數值資訊的表示，以進行高保真映射。大量的實驗證明了我們表示形式的優異精確度和概括能力，在文字狀態檢索、強化學習導航任務和多模態大型語言模型理解方面取得了傑出的成果。

##### **NER-Luxury: Named entity recognition for the fashion and luxury domain**
2409.15804v1 by Akim Mousterou

In this study, we address multiple challenges of developing a named-entity
recognition model in English for the fashion and luxury industry, namely the
entity disambiguation, French technical jargon in multiple sub-sectors,
scarcity of the ESG methodology, and a disparate company structures of the
sector with small and medium-sized luxury houses to large conglomerate
leveraging economy of scale.
  In this work, we introduce a taxonomy of 36+ entity types with a
luxury-oriented annotation scheme, and create a dataset of more than 40K
sentences respecting a clear hierarchical classification. We also present five
supervised fine-tuned models NER-Luxury for fashion, beauty, watches, jewelry,
fragrances, cosmetics, and overall luxury, focusing equally on the aesthetic
side and the quantitative side.
  In an additional experiment, we compare in a quantitative empirical
assessment of the NER performance of our models against the state-of-the-art
open-source large language models that show promising results and highlights
the benefits of incorporating a bespoke NER model in existing machine learning
pipelines.

摘要：在本次研究中，我们解决了针对时尚和奢侈品行业以英语开发命名实体识别模型的多项挑战，即实体消歧、多个子行业的法语技术术语、ESG 方法论的稀缺性以及该行业中从小型和中型奢侈品公司到利用规模经济的大型集团的差异化公司结构。
在这项工作中，我们引入了一个包含 36+ 种实体类型的分类法，并采用以奢侈品为导向的注释方案，创建了一个包含超过 40K 个句子的数据集，这些句子遵循清晰的分层分类。我们还展示了五个针对时尚、美容、手表、珠宝、香水、化妆品和整体奢侈品的经过监督的微调模型 NER-Luxury，这些模型同样注重美学方面和定量方面。
在附加实验中，我们对模型的 NER 性能进行了定量经验评估，并将其与显示出有希望的结果的最新开源大型语言模型进行了比较，并突出了在现有机器学习管道中合并定制 NER 模型的好处。

##### **Towards Universal Large-Scale Foundational Model for Natural Gas Demand Forecasting**
2409.15794v1 by Xinxing Zhou, Jiaqi Ye, Shubao Zhao, Ming Jin, Zhaoxiang Hou, Chengyi Yang, Zengxiang Li, Yanlong Wen, Xiaojie Yuan

In the context of global energy strategy, accurate natural gas demand
forecasting is crucial for ensuring efficient resource allocation and
operational planning. Traditional forecasting methods struggle to cope with the
growing complexity and variability of gas consumption patterns across diverse
industries and commercial sectors. To address these challenges, we propose the
first foundation model specifically tailored for natural gas demand
forecasting. Foundation models, known for their ability to generalize across
tasks and datasets, offer a robust solution to the limitations of traditional
methods, such as the need for separate models for different customer segments
and their limited generalization capabilities. Our approach leverages
contrastive learning to improve prediction accuracy in real-world scenarios,
particularly by tackling issues such as noise in historical consumption data
and the potential misclassification of similar data samples, which can lead to
degradation in the quaility of the representation and thus the accuracy of
downstream forecasting tasks. By integrating advanced noise filtering
techniques within the contrastive learning framework, our model enhances the
quality of learned representations, leading to more accurate predictions.
Furthermore, the model undergoes industry-specific fine-tuning during
pretraining, enabling it to better capture the unique characteristics of gas
consumption across various sectors. We conducted extensive experiments using a
large-scale dataset from ENN Group, which includes data from over 10,000
industrial, commercial, and welfare-related customers across multiple regions.
Our model outperformed existing state-of-the-art methods, demonstrating a
relative improvement in MSE by 3.68\% and in MASE by 6.15\% compared to the
best available model.

摘要：在全球能源策略的脈絡下，準確的天然氣需求預測對於確保有效率的資源配置和營運計畫至關重要。傳統的預測方法難以應對不同產業和商業部門中天然氣消費模式日益增長且多變的複雜性。為了應對這些挑戰，我們提出了第一個專門針對天然氣需求預測量身打造的基礎模型。基礎模型以其跨任務和資料集的泛化能力而聞名，為傳統方法的限制提供了強健的解決方案，例如需要針對不同的客戶區隔建立個別模型以及它們有限的泛化能力。我們的做法利用對比學習來提升實際情境中的預測準確度，特別是透過解決歷史消費資料中的雜訊和類似資料樣本潛在的錯誤分類等問題，這些問題可能會導致表徵品質下降，進而影響下游預測任務的準確度。透過在對比學習架構中整合進階雜訊過濾技術，我們的模型增強了學習表徵的品質，進而產生更準確的預測。此外，此模型在預訓練期間會進行特定產業的微調，使其能夠更好地擷取各個部門中天然氣消耗的獨特特徵。我們使用來自 ENN 集團的大規模資料集進行了廣泛的實驗，其中包含來自多個地區超過 10,000 個工業、商業和福利相關客戶的資料。我們的模型優於現有的最先進方法，與現有最佳模型相比，MSE 的相對改善幅度為 3.68%，而 MASE 的相對改善幅度為 6.15%。

##### **Small Language Models: Survey, Measurements, and Insights**
2409.15790v1 by Zhenyan Lu, Xiang Li, Dongqi Cai, Rongjie Yi, Fangming Liu, Xiwen Zhang, Nicholas D. Lane, Mengwei Xu

Small language models (SLMs), despite their widespread adoption in modern
smart devices, have received significantly less academic attention compared to
their large language model (LLM) counterparts, which are predominantly deployed
in data centers and cloud environments. While researchers continue to improve
the capabilities of LLMs in the pursuit of artificial general intelligence, SLM
research aims to make machine intelligence more accessible, affordable, and
efficient for everyday tasks. Focusing on transformer-based, decoder-only
language models with 100M-5B parameters, we survey 59 state-of-the-art
open-source SLMs, analyzing their technical innovations across three axes:
architectures, training datasets, and training algorithms. In addition, we
evaluate their capabilities in various domains, including commonsense
reasoning, in-context learning, mathematics, and coding. To gain further
insight into their on-device runtime costs, we benchmark their inference
latency and memory footprints. Through in-depth analysis of our benchmarking
data, we offer valuable insights to advance research in this field.

摘要：儘管小型語言模型 (SLM) 已廣泛運用於現代智慧裝置，但與主要部署於資料中心和雲端環境的大型語言模型 (LLM) 相比，學術界對小型語言模型的關注卻少得多。儘管研究人員持續提升 LLM 的功能，以追求人工通用智慧，但 SLM 研究的目標是讓機器智慧更平易近人、更實惠，且更有效率地執行日常任務。我們針對具備 100M-5B 參數的基於轉換器、僅解碼器的語言模型，調查了 59 個最先進的開源 SLM，分析它們在架構、訓練資料集和訓練演算法這三個面向上的技術創新。此外，我們評估了它們在各種領域的能力，包括常識推理、情境學習、數學和編碼。為了進一步了解它們在裝置上的執行時間成本，我們對它們的推論延遲和記憶體使用量進行了基準測試。透過對基準測試資料的深入分析，我們提供了寶貴的見解，以推動此領域的研究。

##### **CHBench: A Chinese Dataset for Evaluating Health in Large Language Models**
2409.15766v1 by Chenlu Guo, Nuo Xu, Yi Chang, Yuan Wu

With the rapid development of large language models (LLMs), assessing their
performance on health-related inquiries has become increasingly essential. It
is critical that these models provide accurate and trustworthy health
information, as their application in real-world contexts--where misinformation
can have serious consequences for individuals seeking medical advice and
support--depends on their reliability. In this work, we present CHBench, the
first comprehensive Chinese Health-related Benchmark designed to evaluate LLMs'
capabilities in understanding physical and mental health across diverse
scenarios. CHBench includes 6,493 entries related to mental health and 2,999
entries focused on physical health, covering a broad spectrum of topics. This
dataset serves as a foundation for evaluating Chinese LLMs' capacity to
comprehend and generate accurate health-related information. Our extensive
evaluations of four popular Chinese LLMs demonstrate that there remains
considerable room for improvement in their understanding of health-related
information. The code is available at https://github.com/TracyGuo2001/CHBench.

摘要：隨著大型語言模型 (LLM) 的快速發展，評估其在與健康相關的查詢上的表現變得越來越重要。這些模型提供準確且可信賴的健康資訊至關重要，因為它們在現實世界的應用中——錯誤資訊可能會對尋求醫療建議和支援的個人造成嚴重後果——取決於它們的可靠性。在這項工作中，我們提出了 CHBench，這是第一個全面的中文健康相關基準，旨在評估 LLM 在各種場景中理解身心健康的的能力。CHBench 包含 6,493 個與心理健康相關的條目和 2,999 個關注身體健康的條目，涵蓋廣泛的主題。此資料集作為評估中文 LLM 理解和產生準確健康相關資訊的能力的基礎。我們對四個流行的中文 LLM 的廣泛評估表明，在理解與健康相關的資訊方面仍有很大的改進空間。程式碼可在 https://github.com/TracyGuo2001/CHBench 取得。

##### **Spatial-Temporal Mixture-of-Graph-Experts for Multi-Type Crime Prediction**
2409.15764v1 by Ziyang Wu, Fan Liu, Jindong Han, Yuxuan Liang, Hao Liu

As various types of crime continue to threaten public safety and economic
development, predicting the occurrence of multiple types of crimes becomes
increasingly vital for effective prevention measures. Although extensive
efforts have been made, most of them overlook the heterogeneity of different
crime categories and fail to address the issue of imbalanced spatial
distribution. In this work, we propose a Spatial-Temporal
Mixture-of-Graph-Experts (ST-MoGE) framework for collective multiple-type crime
prediction. To enhance the model's ability to identify diverse spatial-temporal
dependencies and mitigate potential conflicts caused by spatial-temporal
heterogeneity of different crime categories, we introduce an attentive-gated
Mixture-of-Graph-Experts (MGEs) module to capture the distinctive and shared
crime patterns of each crime category. Then, we propose Cross-Expert
Contrastive Learning(CECL) to update the MGEs and force each expert to focus on
specific pattern modeling, thereby reducing blending and redundancy.
Furthermore, to address the issue of imbalanced spatial distribution, we
propose a Hierarchical Adaptive Loss Re-weighting (HALR) approach to eliminate
biases and insufficient learning of data-scarce regions. To evaluate the
effectiveness of our methods, we conduct comprehensive experiments on two
real-world crime datasets and compare our results with twelve advanced
baselines. The experimental results demonstrate the superiority of our methods.

摘要：隨著各種犯罪持續威脅公共安全和經濟發展，預測多種類型犯罪的發生對於有效的預防措施變得越來越重要。儘管付出了巨大的努力，但大多數都忽視了不同犯罪類別的異質性，並且未能解決空間分佈不平衡的問題。在這項工作中，我們提出了一個時空混合圖專家 (ST-MoGE) 框架，用於收集多種類型的犯罪預測。為了增強模型識別不同時空依賴性的能力並減輕由不同犯罪類別的時空異質性引起的潛在衝突，我們引入了一個專注門控混合圖專家 (MGE) 模組來擷取每個犯罪類別的獨特和共用犯罪模式。然後，我們提出跨專家對比學習 (CECL) 來更新 MGE 並迫使每個專家專注於特定的模式建模，從而減少混合和冗餘。此外，為了解決空間分佈不平衡的問題，我們提出了一種分層自適應損失重新加權 (HALR) 方法，以消除偏差和資料稀少區域的學習不足。為了評估我們方法的有效性，我們對兩個真實世界的犯罪資料集進行了全面的實驗，並將我們的結果與十二個先進的基準進行了比較。實驗結果證明了我們方法的優越性。

##### **IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through Semantic Comprehension in Retrieval-Augmented Generation Scenarios**
2409.15763v1 by Hai Lin, Shaoxiong Zhan, Junyou Su, Haitao Zheng, Hui Wang

In Retrieval-Augmented Generation (RAG) tasks using Large Language Models
(LLMs), the quality of retrieved information is critical to the final output.
This paper introduces the IRSC benchmark for evaluating the performance of
embedding models in multilingual RAG tasks. The benchmark encompasses five
retrieval tasks: query retrieval, title retrieval, part-of-paragraph retrieval,
keyword retrieval, and summary retrieval. Our research addresses the current
lack of comprehensive testing and effective comparison methods for embedding
models in RAG scenarios. We introduced new metrics: the Similarity of Semantic
Comprehension Index (SSCI) and the Retrieval Capability Contest Index (RCCI),
and evaluated models such as Snowflake-Arctic, BGE, GTE, and M3E. Our
contributions include: 1) the IRSC benchmark, 2) the SSCI and RCCI metrics, and
3) insights into the cross-lingual limitations of embedding models. The IRSC
benchmark aims to enhance the understanding and development of accurate
retrieval systems in RAG tasks. All code and datasets are available at:
https://github.com/Jasaxion/IRSC\_Benchmark

摘要：在使用大型语言模型 (LLM) 的检索增强生成 (RAG) 任务中，检索信息的质量对最终输出至关重要。本文介绍了 IRSC 基准，用于评估嵌入模型在多语言 RAG 任务中的性能。该基准包含五个检索任务：查询检索、标题检索、段落部分检索、关键词检索和摘要检索。我们的研究解决了当前 RAG 场景中嵌入模型缺乏全面测试和有效比较方法的问题。我们引入了新的指标：语义理解相似性指数 (SSCI) 和检索能力竞赛指数 (RCCI)，并评估了 Snowflake-Arctic、BGE、GTE 和 M3E 等模型。我们的贡献包括：1) IRSC 基准，2) SSCI 和 RCCI 指标，以及 3) 对嵌入模型跨语言限制的见解。IRSC 基准旨在增强对 RAG 任务中准确检索系统的理解和开发。所有代码和数据集都可以在以下位置获得：https://github.com/Jasaxion/IRSC\_Benchmark

##### **XTRUST: On the Multilingual Trustworthiness of Large Language Models**
2409.15762v1 by Yahan Li, Yi Wang, Yi Chang, Yuan Wu

Large language models (LLMs) have demonstrated remarkable capabilities across
a range of natural language processing (NLP) tasks, capturing the attention of
both practitioners and the broader public. A key question that now preoccupies
the AI community concerns the capabilities and limitations of these models,
with trustworthiness emerging as a central issue, particularly as LLMs are
increasingly applied in sensitive fields like healthcare and finance, where
errors can have serious consequences. However, most previous studies on the
trustworthiness of LLMs have been limited to a single language, typically the
predominant one in the dataset, such as English. In response to the growing
global deployment of LLMs, we introduce XTRUST, the first comprehensive
multilingual trustworthiness benchmark. XTRUST encompasses a diverse range of
topics, including illegal activities, hallucination, out-of-distribution (OOD)
robustness, physical and mental health, toxicity, fairness, misinformation,
privacy, and machine ethics, across 10 different languages. Using XTRUST, we
conduct an empirical evaluation of the multilingual trustworthiness of five
widely used LLMs, offering an in-depth analysis of their performance across
languages and tasks. Our results indicate that many LLMs struggle with certain
low-resource languages, such as Arabic and Russian, highlighting the
considerable room for improvement in the multilingual trustworthiness of
current language models. The code is available at
https://github.com/LluckyYH/XTRUST.

摘要：大型語言模型（LLM）已在各種自然語言處理（NLP）任務中展現出非凡的能力，吸引了從業者和廣大民眾的關注。現在 AI 社群最關注的一個關鍵問題是這些模型的能力和限制，其中可信度是一個核心問題，特別是 LLM 愈來愈多用於醫療保健和金融等敏感領域，錯誤可能會造成嚴重後果。然而，大多數先前關於 LLM 可信度的研究都僅限於單一語言，通常是資料集中佔主導地位的語言，例如英語。為了因應 LLM 在全球部署的成長，我們引入了 XTRUST，這是第一個綜合性的多語言可信度基準。XTRUST 涵蓋了各種主題，包括非法活動、幻覺、分布外（OOD）穩健性、身心健康、毒性、公平性、錯誤資訊、隱私和機器倫理，橫跨 10 種不同的語言。使用 XTRUST，我們對五個廣泛使用的 LLM 進行了多語言可信度的實證評估，深入分析了它們在不同語言和任務中的表現。我們的結果表明，許多 LLM 難以應付某些低資源語言，例如阿拉伯語和俄語，突顯了當前語言模型的多語言可信度有很大的改進空間。程式碼可在 https://github.com/LluckyYH/XTRUST 取得。

##### **TFG: Unified Training-Free Guidance for Diffusion Models**
2409.15761v1 by Haotian Ye, Haowei Lin, Jiaqi Han, Minkai Xu, Sheng Liu, Yitao Liang, Jianzhu Ma, James Zou, Stefano Ermon

Given an unconditional diffusion model and a predictor for a target property
of interest (e.g., a classifier), the goal of training-free guidance is to
generate samples with desirable target properties without additional training.
Existing methods, though effective in various individual applications, often
lack theoretical grounding and rigorous testing on extensive benchmarks. As a
result, they could even fail on simple tasks, and applying them to a new
problem becomes unavoidably difficult. This paper introduces a novel
algorithmic framework encompassing existing methods as special cases, unifying
the study of training-free guidance into the analysis of an algorithm-agnostic
design space. Via theoretical and empirical investigation, we propose an
efficient and effective hyper-parameter searching strategy that can be readily
applied to any downstream task. We systematically benchmark across 7 diffusion
models on 16 tasks with 40 targets, and improve performance by 8.5% on average.
Our framework and benchmark offer a solid foundation for conditional generation
in a training-free manner.

摘要：給定一個無條件擴散模型和一個目標屬性的預測器（例如，一個分類器），無訓練指導的目標是生成具有理想目標屬性的樣本，而無需額外的訓練。現有方法雖然在各種個別應用中很有效，但通常缺乏理論依據，並且在廣泛的基準上進行嚴格的測試。因此，它們甚至可能在簡單的任務上失敗，並且將它們應用於新問題不可避免地變得困難。本文介紹了一個新穎的演算法框架，將現有方法作為特例，將無訓練指導的研究統一到演算法不可知的設計空間的分析中。通過理論和實證調查，我們提出了一個有效率且有效的超參數搜尋策略，可以很容易地應用於任何下游任務。我們系統地對 7 個擴散模型進行基準測試，涵蓋 16 個任務和 40 個目標，並平均提高了 8.5% 的效能。我們的框架和基準為無訓練方式的條件生成提供了一個穩固的基礎。

##### **The Roles of Generative Artificial Intelligence in Internet of Electric Vehicles**
2409.15750v1 by Hanwen Zhang, Dusit Niyato, Wei Zhang, Changyuan Zhao, Hongyang Du, Abbas Jamalipour, Sumei Sun, Yiyang Pei

With the advancement of generative artificial intelligence (GenAI) models,
their capability to generate content is seeing significant enhancement, leading
to widespread applications in the field of data generation and forecasting.
Furthermore, GenAI has strong capabilities in data modeling and analysis, which
enhances Internet of electric vehicles (IoEV) applications in various aspects.
In this paper, we investigate and survey applications of GenAI in the IoEV.
Specifically, we categorize GenAI for IoEV into four different layers namely,
EV's battery layer, individual electric vehicle (EV) layer, smart grid with EV
layer, and security layer. We first introduce various GenAI techniques used in
each layer of IoEV applications. Subsequently, public datasets available for
training the GenAI models are summarized. Finally, we provide recommendations
for future directions. This survey not only categorizes the applications of
GenAI in IoEV across different layers but also serves as a valuable resource
for researchers and practitioners by highlighting the design and implementation
challenges within each layer. Furthermore, it provides a roadmap for future
research directions, enabling the development of more robust and efficient IoEV
systems through the integration of advanced GenAI techniques.

摘要：隨著生成式人工智慧（GenAI）模型的進步，它們生成內容的能力顯著增強，進而廣泛應用於資料生成和預測領域。此外，GenAI 在資料建模和分析方面具有強大功能，這在各方面增強了電動車輛物聯網（IoEV）應用。在本文中，我們探討和調查 GenAI 在 IoEV 中的應用。具體來說，我們將 IoEV 的 GenAI 分為四個不同的層級，即電動車的電池層、個別電動車（EV）層、具備電動車的智慧電網層和安全層。我們首先介紹在 IoEV 應用中各個層級所使用的各種 GenAI 技術。隨後，我們總結了可用於訓練 GenAI 模型的公開資料集。最後，我們提供未來方向的建議。這項調查不僅分類了 GenAI 在 IoEV 中跨不同層級的應用，也透過強調各層級內的設計和實作挑戰，作為研究人員和從業人員的寶貴資源。此外，它還提供了未來研究方向的路線圖，透過整合先進的 GenAI 技術，能開發出更強大且更有效率的 IoEV 系統。

##### **Automated Assessment of Multimodal Answer Sheets in the STEM domain**
2409.15749v1 by Rajlaxmi Patil, Aditya Ashutosh Kulkarni, Ruturaj Ghatage, Sharvi Endait, Geetanjali Kale, Raviraj Joshi

In the domain of education, the integration of,technology has led to a
transformative era, reshaping traditional,learning paradigms. Central to this
evolution is the automation,of grading processes, particularly within the STEM
domain encompassing Science, Technology, Engineering, and Mathematics.,While
efforts to automate grading have been made in subjects,like Literature, the
multifaceted nature of STEM assessments,presents unique challenges, ranging
from quantitative analysis,to the interpretation of handwritten diagrams. To
address these,challenges, this research endeavors to develop efficient and
reliable grading methods through the implementation of automated,assessment
techniques using Artificial Intelligence (AI). Our,contributions lie in two key
areas: firstly, the development of a,robust system for evaluating textual
answers in STEM, leveraging,sample answers for precise comparison and grading,
enabled by,advanced algorithms and natural language processing
techniques.,Secondly, a focus on enhancing diagram evaluation,
particularly,flowcharts, within the STEM context, by transforming diagrams,into
textual representations for nuanced assessment using a,Large Language Model
(LLM). By bridging the gap between,visual representation and semantic meaning,
our approach ensures accurate evaluation while minimizing manual
intervention.,Through the integration of models such as CRAFT for
text,extraction and YoloV5 for object detection, coupled with LLMs,like
Mistral-7B for textual evaluation, our methodology facilitates,comprehensive
assessment of multimodal answer sheets. This,paper provides a detailed account
of our methodology, challenges,encountered, results, and implications,
emphasizing the potential,of AI-driven approaches in revolutionizing grading
practices in,STEM education.

摘要：<paragraph>在教育領域，科技的整合帶來了變革性的時代，重塑了傳統的學習模式。這個演變的核心是評分過程的自動化，特別是在涵蓋科學、技術、工程和數學的 STEM 領域中。雖然在文學等科目中已經做出自動化評分的努力，但 STEM 評估的多方面性質提出了獨特挑戰，從量化分析到手寫圖表的解讀。為了應對這些挑戰，本研究致力於通過實施使用人工智慧 (AI) 的自動化評估技術來開發高效且可靠的評分方法。我們的貢獻在兩個關鍵領域：首先，開發一個用於評估 STEM 中的文字答案的健全系統，利用範例答案進行精確比較和評分，並由先進的演算法和自然語言處理技術支援。其次，專注於增強圖表評估，特別是 STEM 脈絡中的流程圖，通過將圖表轉換為文字表示，以使用大型語言模型 (LLM) 進行細緻評估。通過彌合視覺表示和語義意義之間的差距，我們的做法確保了準確的評估，同時最大限度地減少人工干預。通過整合用於文字萃取的 CRAFT 和用於物件偵測的 YoloV5 等模型，以及用於文字評估的 Mistral-7B 等 LLM，我們的做法促進了對多模態答題紙的全面評估。本文詳細說明了我們的方法、遇到的挑戰、結果和影響，強調了 AI 驅動方法在革新 STEM 教育中的評分實務方面的潛力。</paragraph>

##### **Training Neural Networks for Modularity aids Interpretability**
2409.15747v1 by Satvik Golechha, Dylan Cope, Nandi Schoots

An approach to improve network interpretability is via clusterability, i.e.,
splitting a model into disjoint clusters that can be studied independently. We
find pretrained models to be highly unclusterable and thus train models to be
more modular using an ``enmeshment loss'' function that encourages the
formation of non-interacting clusters. Using automated interpretability
measures, we show that our method finds clusters that learn different,
disjoint, and smaller circuits for CIFAR-10 labels. Our approach provides a
promising direction for making neural networks easier to interpret.

摘要：一種改善網路可解釋性的方法是透過群集性，也就是將模型分割成可獨立研究的不同群集。我們發現預先訓練的模型高度不可群集，因此使用「糾纏損失」函數訓練模型，以促進非交互群集的形成。使用自動化可解釋性度量，我們展示了我們的模型可找到學習不同、不相交且較小的迴路，以取得 CIFAR-10 標籤。我們的方法為讓神經網路更容易解釋提供了一個有前景的方向。

##### **Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach**
2409.15740v1 by Muhammad Dany Alfikri, Rafael Kaliski

Artificial intelligence (AI) has become integral to our everyday lives.
Computer vision has advanced to the point where it can play the safety critical
role of detecting pedestrians at road intersections in intelligent
transportation systems and alert vehicular traffic as to potential collisions.
Centralized computing analyzes camera feeds and generates alerts for nearby
vehicles. However, real-time applications face challenges such as latency,
limited data transfer speeds, and the risk of life loss. Edge servers offer a
potential solution for real-time applications, providing localized computing
and storage resources and lower response times. Unfortunately, edge servers
have limited processing power. Lightweight deep learning (DL) techniques enable
edge servers to utilize compressed deep neural network (DNN) models.
  The research explores implementing a lightweight DL model on Artificial
Intelligence of Things (AIoT) edge devices. An optimized You Only Look Once
(YOLO) based DL model is deployed for real-time pedestrian detection, with
detection events transmitted to the edge server using the Message Queuing
Telemetry Transport (MQTT) protocol. The simulation results demonstrate that
the optimized YOLO model can achieve real-time pedestrian detection, with a
fast inference speed of 147 milliseconds, a frame rate of 2.3 frames per
second, and an accuracy of 78%, representing significant improvements over
baseline models.

摘要：人工智慧 (AI) 已成為我們日常生活不可或缺的一部分。
電腦視覺已進步到可以扮演安全關鍵的角色，在智慧運輸系統中偵測路口行人，並對車輛交通發出潛在碰撞警示。
集中式運算分析相機影像，並為附近車輛產生警示。
然而，即時應用程式面臨諸如延遲、資料傳輸速度受限和生命損失風險等挑戰。
邊緣伺服器提供即時應用程式的潛在解決方案，提供在地化運算和儲存資源，以及較低的回應時間。
不幸的是，邊緣伺服器具有有限的處理能力。
輕量級深度學習 (DL) 技術讓邊緣伺服器能夠利用壓縮深度神經網路 (DNN) 模型。
此研究探討在人工智慧物聯網 (AIoT) 邊緣裝置上實作輕量級 DL 模型。
部署最佳化只看一次 (YOLO) 為基礎的 DL 模型，進行即時行人偵測，並使用訊息佇列遙測傳輸 (MQTT) 協定將偵測事件傳輸至邊緣伺服器。
模擬結果顯示，最佳化 YOLO 模型可以達成即時行人偵測，推論速度快，為 147 毫秒，每秒 2.3 幀的幀率和 78% 的準確度，代表相較於基準模型有顯著的進步。

##### **EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition**
2409.15733v1 by Ming Jin, Danni Zhang, Gangming Zhao, Changde Du, Jinpeng Li

Electroencephalography (EEG)-based emotion recognition has gained significant
traction due to its accuracy and objectivity. However, the non-stationary
nature of EEG signals leads to distribution drift over time, causing severe
performance degradation when the model is reused. While numerous domain
adaptation (DA) approaches have been proposed in recent years to address this
issue, their reliance on large amounts of target data for calibration restricts
them to offline scenarios, rendering them unsuitable for real-time
applications. To address this challenge, this paper proposes Evolvable Fast
Adaptation (EvoFA), an online adaptive framework tailored for EEG data. EvoFA
organically integrates the rapid adaptation of Few-Shot Learning (FSL) and the
distribution matching of Domain Adaptation (DA) through a two-stage
generalization process. During the training phase, a robust base meta-learning
model is constructed for strong generalization. In the testing phase, a
designed evolvable meta-adaptation module iteratively aligns the marginal
distribution of target (testing) data with the evolving source (training) data
within a model-agnostic meta-learning framework, enabling the model to learn
the evolving trends of testing data relative to training data and improving
online testing performance. Experimental results demonstrate that EvoFA
achieves significant improvements compared to the basic FSL method and previous
online methods. The introduction of EvoFA paves the way for broader adoption of
EEG-based emotion recognition in real-world applications. Our code will be
released upon publication.

摘要：<paragraph>基於腦電圖 (EEG) 的情緒辨識由於其準確性和客觀性而獲得顯著的關注。然而，EEG 訊號的非平穩特性會導致分布隨時間漂移，導致模型重複使用時效能嚴重下降。雖然近年來已提出許多領域適應 (DA) 方法來解決此問題，但它們依賴於大量目標資料進行校正，限制它們僅限於離線場景，使其不適合於即時應用程式。為了應對此挑戰，本文提出可演化的快速適應 (EvoFA)，這是一個針對 EEG 資料量身打造的線上適應性架構。EvoFA 透過兩階段的概化過程，有機整合了少量樣本學習 (FSL) 的快速適應和領域適應 (DA) 的分布匹配。在訓練階段，構建一個穩健的基本元學習模型以進行強大的概化。在測試階段，一個設計好的可演化元適應模組會在一個與模型無關的元學習架構中，反覆比對目標（測試）資料的邊際分布與演化的來源（訓練）資料，使模型能夠學習測試資料相對於訓練資料的演化趨勢，並改善線上測試效能。實驗結果表明，與基本 FSL 方法和先前的線上方法相比，EvoFA 獲得顯著的改善。EvoFA 的導入為 EEG 基於情緒辨識在實際應用中更廣泛的採用鋪平了道路。我們的程式碼將在出版後發布。</paragraph>

##### **Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous Driving**
2409.15730v1 by Lingyu Xiao, Jiang-Jiang Liu, Sen Yang, Xiaofan Li, Xiaoqing Ye, Wankou Yang, Jingdong Wang

The autoregressive world model exhibits robust generalization capabilities in
vectorized scene understanding but encounters difficulties in deriving actions
due to insufficient uncertainty modeling and self-delusion. In this paper, we
explore the feasibility of deriving decisions from an autoregressive world
model by addressing these challenges through the formulation of multiple
probabilistic hypotheses. We propose LatentDriver, a framework models the
environment's next states and the ego vehicle's possible actions as a mixture
distribution, from which a deterministic control signal is then derived. By
incorporating mixture modeling, the stochastic nature of decisionmaking is
captured. Additionally, the self-delusion problem is mitigated by providing
intermediate actions sampled from a distribution to the world model.
Experimental results on the recently released close-loop benchmark Waymax
demonstrate that LatentDriver surpasses state-of-the-art reinforcement learning
and imitation learning methods, achieving expert-level performance. The code
and models will be made available at
https://github.com/Sephirex-X/LatentDriver.

摘要：自迴歸世界模型在向量化場景理解中展現出穩健的泛化能力，但由於不確定性建模和自我欺騙不足，而在推導動作時遇到困難。在本文中，我們透過多個機率假設的公式化，探討從自迴歸世界模型中推導決策的可行性。我們提出 LatentDriver，一個架構將環境的後續狀態和自我車輛的可能動作建模為混合分佈，然後從中推導出確定性的控制訊號。透過納入混合建模，捕捉了決策的隨機性質。此外，透過提供從分佈中取樣的中間動作給世界模型，來減輕自我欺騙問題。在最近發布的閉迴路基準 Waymax 上的實驗結果證明，LatentDriver 超越了最先進的強化學習和模仿學習方法，達到了專家級的表現。程式碼和模型將在 https://github.com/Sephirex-X/LatentDriver 上提供。

##### **Sequential Learning in the Dense Associative Memory**
2409.15729v1 by Hayden McAlister, Anthony Robins, Lech Szymanski

Sequential learning involves learning tasks in a sequence, and proves
challenging for most neural networks. Biological neural networks regularly
conquer the sequential learning challenge and are even capable of transferring
knowledge both forward and backwards between tasks. Artificial neural networks
often totally fail to transfer performance between tasks, and regularly suffer
from degraded performance or catastrophic forgetting on previous tasks. Models
of associative memory have been used to investigate the discrepancy between
biological and artificial neural networks due to their biological ties and
inspirations, of which the Hopfield network is perhaps the most studied model.
The Dense Associative Memory, or modern Hopfield network, generalizes the
Hopfield network, allowing for greater capacities and prototype learning
behaviors, while still retaining the associative memory structure. We
investigate the performance of the Dense Associative Memory in sequential
learning problems, and benchmark various sequential learning techniques in the
network. We give a substantial review of the sequential learning space with
particular respect to the Hopfield network and associative memories, as well as
describe the techniques we implement in detail. We also draw parallels between
the classical and Dense Associative Memory in the context of sequential
learning, and discuss the departures from biological inspiration that may
influence the utility of the Dense Associative Memory as a tool for studying
biological neural networks. We present our findings, and show that existing
sequential learning methods can be applied to the Dense Associative Memory to
improve sequential learning performance.

摘要：序列學習涉及按順序學習任務，並證明對大多數神經網路而言具有挑戰性。生物神經網路定期克服序列學習挑戰，甚至能夠在任務之間向前和向後傳遞知識。人工神經網路通常無法在任務之間傳遞效能，並且經常遭受效能下降或先前任務的災難性遺忘。聯想記憶模型已被用於研究生物和人工神經網路之間的差異，因為它們具有生物聯繫和靈感，其中霍普菲爾德網路可能是研究最多的模型。密集聯想記憶或現代霍普菲爾德網路概括了霍普菲爾德網路，允許更大的容量和原型學習行為，同時仍保留聯想記憶結構。我們研究密集聯想記憶在序列學習問題中的效能，並在網路中對各種序列學習技術進行基準測試。我們對序列學習空間進行了實質性回顧，特別是關於霍普菲爾德網路和聯想記憶，並詳細描述了我們實作的技術。我們還在序列學習的背景下描繪了經典和密集聯想記憶之間的相似之處，並討論了可能影響密集聯想記憶作為研究生物神經網路工具的效用的生物靈感偏離。我們提出我們的發現，並表明現有的序列學習方法可以應用於密集聯想記憶以改善序列學習效能。

##### **LLM-Cure: LLM-based Competitor User Review Analysis for Feature Enhancement**
2409.15724v1 by Maram Assi, Safwat Hassan, Ying Zou

The exponential growth of the mobile app market underscores the importance of
constant innovation and rapid response to user demands. As user satisfaction is
paramount to the success of a mobile application (app), developers typically
rely on user reviews, which represent user feedback that includes ratings and
comments to identify areas for improvement. However, the sheer volume of user
reviews poses challenges in manual analysis, necessitating automated
approaches. Existing automated approaches either analyze only the target apps
reviews, neglecting the comparison of similar features to competitors or fail
to provide suggestions for feature enhancement. To address these gaps, we
propose a Large Language Model (LLM)-based Competitive User Review Analysis for
Feature Enhancement) (LLM-Cure), an approach powered by LLMs to automatically
generate suggestion s for mobile app feature improvements. More specifically,
LLM-Cure identifies and categorizes features within reviews by applying LLMs.
When provided with a complaint in a user review, LLM-Cure curates highly rated
(4 and 5 stars) reviews in competing apps related to the complaint and proposes
potential improvements tailored to the target application. We evaluate LLM-Cure
on 1,056,739 reviews of 70 popular Android apps. Our evaluation demonstrates
that LLM-Cure significantly outperforms the state-of-the-art approaches in
assigning features to reviews by up to 13% in F1-score, up to 16% in recall and
up to 11% in precision. Additionally, LLM-Cure demonstrates its capability to
provide suggestions for resolving user complaints. We verify the suggestions
using the release notes that reflect the changes of features in the target
mobile app. LLM-Cure achieves a promising average of 73% of the implementation
of the provided suggestions.

摘要：行動應用程式市場的指數型成長，突顯了持續創新和快速回應使用者需求的重要性。由於使用者滿意度對於行動應用程式 (app) 的成功至關重要，開發人員通常依賴使用者評論，其中包括評分和評論，以找出需要改進的地方。然而，龐大的使用者評論量對手動分析構成挑戰，因此需要自動化方法。現有的自動化方法只分析目標應用程式的評論，忽略了與競爭對手的類似功能比較，或無法提供功能增強建議。為了解決這些差距，我們提出了一個基於大型語言模型 (LLM) 的競爭性使用者評論分析，用於功能增強 (LLM-Cure)，一種由 LLM 驅動的方法，可自動產生針對行動應用程式功能改進的建議。更具體地說，LLM-Cure 透過應用 LLM 來識別和分類評論中的功能。當使用者評論中出現抱怨時，LLM-Cure 會整理與抱怨相關的競爭應用程式中評分很高的 (4 和 5 星) 評論，並提出針對目標應用程式量身打造的潛在改進建議。我們在 70 個熱門 Android 應用程式的 1,056,739 則評論上評估 LLM-Cure。我們的評估顯示，LLM-Cure 在將功能分配給評論方面明顯優於最先進的方法，F1 分數提高了 13%，召回率提高了 16%，準確率提高了 11%。此外，LLM-Cure 展示了其提供解決使用者抱怨建議的能力。我們使用反映目標行動應用程式中功能變更的版本說明來驗證這些建議。LLM-Cure 達到了令人滿意的平均 73% 的所提供建議的實施率。

##### **Federated Large Language Models: Current Progress and Future Directions**
2409.15723v1 by Yuhang Yao, Jianyi Zhang, Junda Wu, Chengkai Huang, Yu Xia, Tong Yu, Ruiyi Zhang, Sungchul Kim, Ryan Rossi, Ang Li, Lina Yao, Julian McAuley, Yiran Chen, Carlee Joe-Wong

Large language models are rapidly gaining popularity and have been widely
adopted in real-world applications. While the quality of training data is
essential, privacy concerns arise during data collection. Federated learning
offers a solution by allowing multiple clients to collaboratively train LLMs
without sharing local data. However, FL introduces new challenges, such as
model convergence issues due to heterogeneous data and high communication
costs. A comprehensive study is required to address these challenges and guide
future research. This paper surveys Federated learning for LLMs (FedLLM),
highlighting recent advances and future directions. We focus on two key
aspects: fine-tuning and prompt learning in a federated setting, discussing
existing work and associated research challenges. We finally propose potential
research directions for federated LLMs, including pre-training and how LLMs can
further enhance federated learning.

摘要：大型語言模型正迅速獲得普及，並已廣泛應用於實際應用中。儘管訓練資料的品質至關重要，但在資料收集過程中卻產生了隱私問題。聯邦學習提供了一種解決方案，允許多個用戶端在不共享本地資料的情況下協作訓練 LLM。然而，FL 引入了新的挑戰，例如由於異質資料和高通訊成本而產生的模型收斂問題。需要進行一項全面研究來解決這些挑戰並指導未來的研究。本文調查了 LLM 的聯邦學習 (FedLLM)，重點介紹了近期的進展和未來的方向。我們專注於兩個關鍵方面：在聯邦設定中進行微調和提示學習，討論現有工作和相關的研究挑戰。最後，我們針對聯邦 LLM 提出潛在的研究方向，包括預訓練以及 LLM 如何進一步增強聯邦學習。

##### **Adversarial Federated Consensus Learning for Surface Defect Classification Under Data Heterogeneity in IIoT**
2409.15711v1 by Jixuan Cui, Jun Li, Zhen Mei, Yiyang Ni, Wen Chen, Zengxiang Li

The challenge of data scarcity hinders the application of deep learning in
industrial surface defect classification (SDC), as it's difficult to collect
and centralize sufficient training data from various entities in Industrial
Internet of Things (IIoT) due to privacy concerns. Federated learning (FL)
provides a solution by enabling collaborative global model training across
clients while maintaining privacy. However, performance may suffer due to data
heterogeneity--discrepancies in data distributions among clients. In this
paper, we propose a novel personalized FL (PFL) approach, named Adversarial
Federated Consensus Learning (AFedCL), for the challenge of data heterogeneity
across different clients in SDC. First, we develop a dynamic consensus
construction strategy to mitigate the performance degradation caused by data
heterogeneity. Through adversarial training, local models from different
clients utilize the global model as a bridge to achieve distribution alignment,
alleviating the problem of global knowledge forgetting. Complementing this
strategy, we propose a consensus-aware aggregation mechanism. It assigns
aggregation weights to different clients based on their efficacy in global
knowledge learning, thereby enhancing the global model's generalization
capabilities. Finally, we design an adaptive feature fusion module to further
enhance global knowledge utilization efficiency. Personalized fusion weights
are gradually adjusted for each client to optimally balance global and local
features, tailored to their individual global knowledge learning efficacy.
Compared with state-of-the-art FL methods like FedALA, the proposed AFedCL
method achieves an accuracy increase of up to 5.67% on three SDC datasets.

摘要：<paragraph>資料稀少的挑戰阻礙了深度學習在工業表面缺陷分類 (SDC) 中的應用，因為由於隱私問題，難以從工業物聯網 (IIoT) 中的各個實體收集和集中足夠的訓練資料。聯邦學習 (FL) 提供了一個解決方案，它讓客戶端能夠進行協作式全球模型訓練，同時維護隱私。然而，由於資料異質性，即客戶端之間資料分佈的差異，效能可能會受到影響。在本文中，我們提出了一種名為對抗聯邦共識學習 (AFedCL) 的新個性化 FL (PFL) 方法，用於解決 SDC 中不同客戶端之間資料異質性的挑戰。首先，我們開發了一種動態共識構建策略，以減輕資料異質性造成的效能下降。透過對抗訓練，來自不同客戶端的本地模型利用全球模型作為橋樑來實現分佈對齊，緩解了全球知識遺忘的問題。為了補充此策略，我們提出了一個共識感知聚合機制。它根據不同客戶端在全球知識學習中的效能為其分配聚合權重，從而增強全球模型的概化能力。最後，我們設計了一個自適應特徵融合模組，以進一步提高全球知識利用效率。針對每個客戶端逐漸調整個性化融合權重，以最佳平衡全球和本地特徵，並根據其個別的全球知識學習效能進行調整。與 FedALA 等最先進的 FL 方法相比，所提出的 AFedCL 方法在三個 SDC 資料集上實現了高達 5.67% 的準確度提升。</paragraph>

