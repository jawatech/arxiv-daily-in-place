{"2501.07853": {"publish_time": "2025-01-14", "title": "Optimizing Language Models for Grammatical Acceptability: A Comparative Study of Fine-Tuning Techniques", "paper_summary": "This study explores the fine-tuning (FT) of the Open Pre-trained Transformer\n(OPT-125M) for grammatical acceptability tasks using the CoLA dataset. By\ncomparing Vanilla-Fine-Tuning (VFT), Pattern-Based-Fine-Tuning (PBFT), and\nParameter-Efficient Fine-Tuning techniques (PEFT) like Low-Rank Adaptation\n(LoRA), we demonstrate significant improvements in computational efficiency\nwhile maintaining high accuracy. Our experiments reveal that while VFT achieves\nthe highest accuracy (81.2%), LoRA enhancing FT by reducing memory usage and\niteration time by more than 50%, and increases accuracy in PBFT case. Context\nDistillation (CD), though computationally efficient, underperformed with\naccuracy around 31%. Our findings contribute to democratizing access to large\nlanguage models (LLM) by reducing computational barriers.", "paper_summary_zh": "\u672c\u7814\u7a76\u63a2\u8a0e\u4e86\u4f7f\u7528 CoLA \u8cc7\u6599\u96c6\u91dd\u5c0d\u8a9e\u6cd5\u53ef\u63a5\u53d7\u6027\u4efb\u52d9\u5c0d\u958b\u653e\u5f0f\u9810\u8a13\u7df4Transformer (OPT-125M) \u9032\u884c\u5fae\u8abf (FT)\u3002\u900f\u904e\u6bd4\u8f03\u9999\u8349\u5fae\u8abf (VFT)\u3001\u57fa\u65bc\u6a21\u5f0f\u7684\u5fae\u8abf (PBFT) \u548c\u53c3\u6578\u6709\u6548\u5fae\u8abf\u6280\u8853 (PEFT)\uff08\u4f8b\u5982\u4f4e\u79e9\u9069\u61c9 (LoRA)\uff09\uff0c\u6211\u5011\u8b49\u660e\u4e86\u5728\u7dad\u6301\u9ad8\u6e96\u78ba\u5ea6\u7684\u540c\u6642\uff0c\u986f\u8457\u63d0\u9ad8\u4e86\u904b\u7b97\u6548\u7387\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\u5118\u7ba1 VFT \u9054\u5230\u4e86\u6700\u9ad8\u7684\u6e96\u78ba\u5ea6 (81.2%)\uff0c\u4f46 LoRA \u900f\u904e\u6e1b\u5c11\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u548c\u8fed\u4ee3\u6642\u9593\u8d85\u904e 50% \u4f86\u589e\u5f37 FT\uff0c\u4e26\u63d0\u9ad8\u4e86 PBFT \u6848\u4f8b\u7684\u6e96\u78ba\u5ea6\u3002\u8108\u7d61\u84b8\u993e (CD) \u96d6\u7136\u904b\u7b97\u6548\u7387\u9ad8\uff0c\u4f46\u6e96\u78ba\u5ea6\u50c5\u7d04 31%\uff0c\u8868\u73fe\u4e0d\u4f73\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u6709\u52a9\u65bc\u900f\u904e\u964d\u4f4e\u904b\u7b97\u969c\u7919\uff0c\u8b93\u66f4\u591a\u4eba\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\u3002", "author": "Shobhit Ratan et.al.", "authors": "Shobhit Ratan, Farley Knight, Ghada Jerfel, Sze Chung Ho", "id": "2501.07853v1", "paper_url": "http://arxiv.org/abs/2501.07853v1", "repo": "null"}}