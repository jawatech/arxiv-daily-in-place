{"2405.02917": {"publish_time": "2024-05-05", "title": "Overconfidence is Key: Verbalized Uncertainty Evaluation in Large Language and Vision-Language Models", "paper_summary": "Language and Vision-Language Models (LLMs/VLMs) have revolutionized the field\nof AI by their ability to generate human-like text and understand images, but\nensuring their reliability is crucial. This paper aims to evaluate the ability\nof LLMs (GPT4, GPT-3.5, LLaMA2, and PaLM 2) and VLMs (GPT4V and Gemini Pro\nVision) to estimate their verbalized uncertainty via prompting. We propose the\nnew Japanese Uncertain Scenes (JUS) dataset, aimed at testing VLM capabilities\nvia difficult queries and object counting, and the Net Calibration Error (NCE)\nto measure direction of miscalibration. Results show that both LLMs and VLMs\nhave a high calibration error and are overconfident most of the time,\nindicating a poor capability for uncertainty estimation. Additionally we\ndevelop prompts for regression tasks, and we show that VLMs have poor\ncalibration when producing mean/standard deviation and 95% confidence\nintervals.", "paper_summary_zh": "", "author": "Tobias Groot et.al.", "authors": "Tobias Groot,Matias Valdenegro-Toro", "id": "2405.02917v1", "paper_url": "http://arxiv.org/abs/2405.02917v1", "repo": "null"}}