{"2501.18794": {"publish_time": "2025-01-30", "title": "Survey and Improvement Strategies for Gene Prioritization with Large Language Models", "paper_summary": "Rare diseases are challenging to diagnose due to limited patient data and\ngenetic diversity. Despite advances in variant prioritization, many cases\nremain undiagnosed. While large language models (LLMs) have performed well in\nmedical exams, their effectiveness in diagnosing rare genetic diseases has not\nbeen assessed. To identify causal genes, we benchmarked various LLMs for gene\nprioritization. Using multi-agent and Human Phenotype Ontology (HPO)\nclassification, we categorized patients based on phenotypes and solvability\nlevels. As gene set size increased, LLM performance deteriorated, so we used a\ndivide-and-conquer strategy to break the task into smaller subsets. At\nbaseline, GPT-4 outperformed other LLMs, achieving near 30% accuracy in ranking\ncausal genes correctly. The multi-agent and HPO approaches helped distinguish\nconfidently solved cases from challenging ones, highlighting the importance of\nknown gene-phenotype associations and phenotype specificity. We found that\ncases with specific phenotypes or clear associations were more accurately\nsolved. However, we observed biases toward well-studied genes and input order\nsensitivity, which hindered gene prioritization. Our divide-and-conquer\nstrategy improved accuracy by overcoming these biases. By utilizing HPO\nclassification, novel multi-agent techniques, and our LLM strategy, we improved\ncausal gene identification accuracy compared to our baseline evaluation. This\napproach streamlines rare disease diagnosis, facilitates reanalysis of unsolved\ncases, and accelerates gene discovery, supporting the development of targeted\ndiagnostics and therapies.", "paper_summary_zh": "\u7f55\u898b\u75be\u75c5\u7531\u65bc\u60a3\u8005\u6578\u64da\u6709\u9650\u548c\u907a\u50b3\u591a\u6a23\u6027\uff0c\u8a3a\u65b7\u8d77\u4f86\u5177\u6709\u6311\u6230\u6027\u3002\u5118\u7ba1\u8b8a\u7570\u512a\u5148\u7d1a\u6392\u5e8f\u6280\u8853\u9032\u6b65\uff0c\u4f46\u8a31\u591a\u75c5\u4f8b\u4ecd\u672a\u5f97\u5230\u8a3a\u65b7\u3002\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u91ab\u5b78\u8003\u8a66\u4e2d\u8868\u73fe\u826f\u597d\uff0c\u4f46\u5b83\u5011\u5728\u8a3a\u65b7\u7f55\u898b\u907a\u50b3\u75be\u75c5\u65b9\u9762\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u8a55\u4f30\u3002\u70ba\u4e86\u8b58\u5225\u81f4\u75c5\u57fa\u56e0\uff0c\u6211\u5011\u5c0d\u5404\u7a2e LLM \u9032\u884c\u4e86\u57fa\u56e0\u512a\u5148\u7d1a\u6392\u5e8f\u57fa\u6e96\u6e2c\u8a66\u3002\u4f7f\u7528\u591a\u667a\u80fd\u9ad4\u548c\u4eba\u985e\u8868\u578b\u672c\u4f53 (HPO) \u5206\u985e\uff0c\u6211\u5011\u6839\u64da\u8868\u578b\u548c\u53ef\u89e3\u6c7a\u6027\u5c0d\u60a3\u8005\u9032\u884c\u4e86\u5206\u985e\u3002\u96a8\u8457\u57fa\u56e0\u7d44\u5927\u5c0f\u7684\u589e\u52a0\uff0cLLM \u6027\u80fd\u4e0b\u964d\uff0c\u56e0\u6b64\u6211\u5011\u4f7f\u7528\u5206\u800c\u6cbb\u4e4b\u7b56\u7565\u5c07\u4efb\u52d9\u5206\u89e3\u70ba\u66f4\u5c0f\u7684\u5b50\u96c6\u3002\u5728\u57fa\u7dda\u4e2d\uff0cGPT-4 \u512a\u65bc\u5176\u4ed6 LLM\uff0c\u5728\u6b63\u78ba\u6392\u5e8f\u81f4\u75c5\u57fa\u56e0\u65b9\u9762\u9054\u5230\u8fd1 30% \u7684\u6e96\u78ba\u5ea6\u3002\u591a\u667a\u80fd\u9ad4\u548c HPO \u65b9\u6cd5\u6709\u52a9\u65bc\u5340\u5206\u89e3\u6c7a\u6709\u4fe1\u5fc3\u7684\u75c5\u4f8b\u548c\u5177\u6709\u6311\u6230\u6027\u7684\u75c5\u4f8b\uff0c\u5f37\u8abf\u5df2\u77e5\u57fa\u56e0-\u8868\u578b\u95dc\u806f\u548c\u8868\u578b\u7279\u7570\u6027\u7684\u91cd\u8981\u6027\u3002\u6211\u5011\u767c\u73fe\u5177\u6709\u7279\u5b9a\u8868\u578b\u6216\u660e\u78ba\u95dc\u806f\u7684\u75c5\u4f8b\u5f97\u5230\u66f4\u6e96\u78ba\u7684\u89e3\u6c7a\u3002\u7136\u800c\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u5c0d\u7814\u7a76\u5145\u5206\u7684\u57fa\u56e0\u548c\u8f38\u5165\u9806\u5e8f\u654f\u611f\u6027\u7684\u504f\u5dee\uff0c\u9019\u963b\u7919\u4e86\u57fa\u56e0\u512a\u5148\u7d1a\u6392\u5e8f\u3002\u6211\u5011\u7684\u5206\u800c\u6cbb\u4e4b\u7b56\u7565\u901a\u904e\u514b\u670d\u9019\u4e9b\u504f\u5dee\u4f86\u63d0\u9ad8\u6e96\u78ba\u6027\u3002\u901a\u904e\u5229\u7528 HPO \u5206\u985e\u3001\u65b0\u7a4e\u7684\u591a\u667a\u80fd\u9ad4\u6280\u8853\u548c\u6211\u5011\u7684 LLM \u7b56\u7565\uff0c\u6211\u5011\u8207\u6211\u5011\u7684\u57fa\u7dda\u8a55\u4f30\u76f8\u6bd4\u63d0\u9ad8\u4e86\u81f4\u75c5\u57fa\u56e0\u8b58\u5225\u6e96\u78ba\u6027\u3002\u9019\u7a2e\u65b9\u6cd5\u7c21\u5316\u4e86\u7f55\u898b\u75be\u75c5\u7684\u8a3a\u65b7\uff0c\u4fc3\u9032\u4e86\u5c0d\u672a\u89e3\u6c7a\u75c5\u4f8b\u7684\u91cd\u65b0\u5206\u6790\uff0c\u4e26\u52a0\u901f\u4e86\u57fa\u56e0\u767c\u73fe\uff0c\u652f\u6301\u4e86\u9776\u5411\u8a3a\u65b7\u548c\u6cbb\u7642\u7684\u958b\u767c\u3002", "author": "Matthew Neeley et.al.", "authors": "Matthew Neeley, Guantong Qi, Guanchu Wang, Ruixiang Tang, Dongxue Mao, Chaozhong Liu, Sasidhar Pasupuleti, Bo Yuan, Fan Xia, Pengfei Liu, Zhandong Liu, Xia Hu", "id": "2501.18794v1", "paper_url": "http://arxiv.org/abs/2501.18794v1", "repo": "null"}}