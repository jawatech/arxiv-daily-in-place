{"2411.12000": {"publish_time": "2024-11-18", "title": "ByteScience: Bridging Unstructured Scientific Literature and Structured Data with Auto Fine-tuned Large Language Model in Token Granularity", "paper_summary": "Natural Language Processing (NLP) is widely used to supply summarization\nability from long context to structured information. However, extracting\nstructured knowledge from scientific text by NLP models remains a challenge\nbecause of its domain-specific nature to complex data preprocessing and the\ngranularity of multi-layered device-level information. To address this, we\nintroduce ByteScience, a non-profit cloud-based auto fine-tuned Large Language\nModel (LLM) platform, which is designed to extract structured scientific data\nand synthesize new scientific knowledge from vast scientific corpora. The\nplatform capitalizes on DARWIN, an open-source, fine-tuned LLM dedicated to\nnatural science. The platform was built on Amazon Web Services (AWS) and\nprovides an automated, user-friendly workflow for custom model development and\ndata extraction. The platform achieves remarkable accuracy with only a small\namount of well-annotated articles. This innovative tool streamlines the\ntransition from the science literature to structured knowledge and data and\nbenefits the advancements in natural informatics.", "paper_summary_zh": "\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u5ee3\u6cdb\u7528\u65bc\u63d0\u4f9b\u5f9e\u9577\u6587\u5230\u7d50\u69cb\u5316\u8cc7\u8a0a\u7684\u6458\u8981\u80fd\u529b\u3002\u7136\u800c\uff0c\u7531\u65bc\u5176\u7279\u5b9a\u9818\u57df\u7684\u6027\u8cea\uff0c\u8907\u96dc\u7684\u8cc7\u6599\u524d\u8655\u7406\u548c\u591a\u5c64\u7d1a\u88dd\u7f6e\u5c64\u7d1a\u8cc7\u8a0a\u7684\u7c92\u5ea6\uff0c\u900f\u904e NLP \u6a21\u578b\u5f9e\u79d1\u5b78\u6587\u672c\u4e2d\u8403\u53d6\u7d50\u69cb\u5316\u77e5\u8b58\u4ecd\u7136\u662f\u4e00\u500b\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u9032\u4e86 ByteScience\uff0c\u4e00\u500b\u975e\u71df\u5229\u7684\u96f2\u7aef\u81ea\u52d5\u5fae\u8abf\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5e73\u53f0\uff0c\u5b83\u88ab\u8a2d\u8a08\u7528\u4f86\u5f9e\u5927\u91cf\u7684\u79d1\u5b78\u8a9e\u6599\u5eab\u4e2d\u8403\u53d6\u7d50\u69cb\u5316\u7684\u79d1\u5b78\u8cc7\u6599\uff0c\u4e26\u7d9c\u5408\u65b0\u7684\u79d1\u5b78\u77e5\u8b58\u3002\u9019\u500b\u5e73\u53f0\u5229\u7528\u4e86 DARWIN\uff0c\u4e00\u500b\u958b\u653e\u539f\u59cb\u78bc\u7684\u5fae\u8abf LLM\uff0c\u5c08\u9580\u7528\u65bc\u81ea\u7136\u79d1\u5b78\u3002\u9019\u500b\u5e73\u53f0\u5efa\u7f6e\u65bc\u4e9e\u99ac\u905c\u7db2\u8def\u670d\u52d9 (AWS) \u4e0a\uff0c\u4e26\u63d0\u4f9b\u4e86\u4e00\u500b\u81ea\u52d5\u5316\u3001\u4f7f\u7528\u8005\u53cb\u5584\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7528\u65bc\u81ea\u8a02\u6a21\u578b\u958b\u767c\u548c\u8cc7\u6599\u8403\u53d6\u3002\u9019\u500b\u5e73\u53f0\u50c5\u900f\u904e\u5c11\u91cf\u7684\u826f\u597d\u8a3b\u89e3\u6587\u7ae0\u5c31\u9054\u5230\u4e86\u986f\u8457\u7684\u6e96\u78ba\u5ea6\u3002\u9019\u500b\u5275\u65b0\u7684\u5de5\u5177\u7c21\u5316\u4e86\u5f9e\u79d1\u5b78\u6587\u737b\u5230\u7d50\u69cb\u5316\u77e5\u8b58\u548c\u8cc7\u6599\u7684\u8f49\u63db\uff0c\u4e26\u5c0d\u81ea\u7136\u8cc7\u8a0a\u5b78\u7684\u9032\u5c55\u6709\u76ca\u3002", "author": "Tong Xie et.al.", "authors": "Tong Xie, Hanzhi Zhang, Shaozhou Wang, Yuwei Wan, Imran Razzak, Chunyu Kit, Wenjie Zhangand Bram Hoex", "id": "2411.12000v1", "paper_url": "http://arxiv.org/abs/2411.12000v1", "repo": "null"}}