{"2501.01926": {"publish_time": "2025-01-03", "title": "Mitigating Hallucination for Large Vision Language Model by Inter-Modality Correlation Calibration Decoding", "paper_summary": "Large vision-language models (LVLMs) have shown remarkable capabilities in\nvisual-language understanding for downstream multi-modal tasks. Despite their\nsuccess, LVLMs still suffer from generating hallucinations in complex\ngeneration tasks, leading to inconsistencies between visual inputs and\ngenerated content. To address this issue, some approaches have introduced\ninference-time interventions, such as contrastive decoding and attention\nrectification, to reduce overreliance on language priors. However, these\napproaches overlook hallucinations stemming from spurious inter-modality\ncorrelations. In this paper, we propose an Inter-Modality Correlation\nCalibration Decoding (IMCCD) method to mitigate hallucinations in LVLMs in a\ntraining-free manner. In this method, we design a Cross-Modal Value-Enhanced\nDecoding(CMVED) module to alleviate hallucination by a novel contrastive\ndecoding mechanism. During the estimation of distorted distribution, CMVED\nmasks the value vectors associated with significant cross-modal attention\nweights, which address both uni-modality overreliance and misleading\ninter-modality correlations. Additionally, a Content-Driven Attention\nRefinement(CDAR) module refines cross-modal attention weights, guiding LVLMs to\nfocus on important visual content. Experimental results on diverse\nhallucination benchmarks validate the superiority of our method over existing\nstate-of-the-art techniques in reducing hallucinations in LVLM text generation.\nOur code will be available at https://github.com/lijm48/IMCCD.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u5df2\u5728\u8996\u89ba\u8a9e\u8a00\u7406\u89e3\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u53ef\u7528\u65bc\u4e0b\u6e38\u591a\u6a21\u5f0f\u4efb\u52d9\u3002\u5118\u7ba1\u5b83\u5011\u5f88\u6210\u529f\uff0c\u4f46 LVLMs \u5728\u8907\u96dc\u7684\u751f\u6210\u4efb\u52d9\u4e2d\u4ecd\u7136\u6703\u7522\u751f\u5e7b\u89ba\uff0c\u5c0e\u81f4\u8996\u89ba\u8f38\u5165\u548c\u751f\u6210\u5167\u5bb9\u4e4b\u9593\u51fa\u73fe\u4e0d\u4e00\u81f4\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u4e00\u4e9b\u65b9\u6cd5\u5f15\u5165\u4e86\u63a8\u7406\u6642\u9593\u5e72\u9810\uff0c\u4f8b\u5982\u5c0d\u6bd4\u89e3\u78bc\u548c\u6ce8\u610f\u529b\u6821\u6b63\uff0c\u4ee5\u6e1b\u5c11\u5c0d\u8a9e\u8a00\u5148\u9a57\u7684\u904e\u5ea6\u4f9d\u8cf4\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u5ffd\u8996\u4e86\u6e90\u81ea\u865b\u5047\u6a21\u614b\u9593\u95dc\u806f\u7684\u5e7b\u89ba\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u6a21\u614b\u9593\u95dc\u806f\u6821\u6b63\u89e3\u78bc (IMCCD) \u65b9\u6cd5\uff0c\u4ee5\u5728\u4e0d\u9700\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\u6e1b\u8f15 LVLMs \u4e2d\u7684\u5e7b\u89ba\u3002\u5728\u6b64\u65b9\u6cd5\u4e2d\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u8de8\u6a21\u614b\u503c\u589e\u5f37\u89e3\u78bc (CMVED) \u6a21\u7d44\uff0c\u900f\u904e\u4e00\u7a2e\u65b0\u7a4e\u7684\u5c0d\u6bd4\u89e3\u78bc\u6a5f\u5236\u4f86\u6e1b\u8f15\u5e7b\u89ba\u3002\u5728\u5931\u771f\u5206\u4f48\u7684\u4f30\u8a08\u904e\u7a0b\u4e2d\uff0cCMVED \u6703\u906e\u853d\u8207\u986f\u8457\u8de8\u6a21\u614b\u6ce8\u610f\u529b\u6b0a\u91cd\u76f8\u95dc\u7684\u503c\u5411\u91cf\uff0c\u9019\u53ef\u4ee5\u89e3\u6c7a\u55ae\u4e00\u6a21\u614b\u904e\u5ea6\u4f9d\u8cf4\u548c\u8aa4\u5c0e\u6027\u7684\u6a21\u614b\u9593\u95dc\u806f\u3002\u6b64\u5916\uff0c\u5167\u5bb9\u9a45\u52d5\u6ce8\u610f\u529b\u7cbe\u7149 (CDAR) \u6a21\u7d44\u6703\u7cbe\u7149\u8de8\u6a21\u614b\u6ce8\u610f\u529b\u6b0a\u91cd\uff0c\u5f15\u5c0e LVLMs \u5c08\u6ce8\u65bc\u91cd\u8981\u7684\u8996\u89ba\u5167\u5bb9\u3002\u5728\u5404\u7a2e\u5e7b\u89ba\u57fa\u6e96\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u9a57\u8b49\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u512a\u65bc\u73fe\u6709\u6700\u5148\u9032\u6280\u8853\uff0c\u53ef\u4ee5\u6e1b\u5c11 LVLM \u6587\u672c\u751f\u6210\u4e2d\u7684\u5e7b\u89ba\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5c07\u5728 https://github.com/lijm48/IMCCD \u4e2d\u63d0\u4f9b\u3002", "author": "Jiaming Li et.al.", "authors": "Jiaming Li, Jiacheng Zhang, Zequn Jie, Lin Ma, Guanbin Li", "id": "2501.01926v1", "paper_url": "http://arxiv.org/abs/2501.01926v1", "repo": "null"}}