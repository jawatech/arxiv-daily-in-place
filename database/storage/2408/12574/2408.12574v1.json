{"2408.12574": {"publish_time": "2024-08-22", "title": "MuMA-ToM: Multi-modal Multi-Agent Theory of Mind", "paper_summary": "Understanding people's social interactions in complex real-world scenarios\noften relies on intricate mental reasoning. To truly understand how and why\npeople interact with one another, we must infer the underlying mental states\nthat give rise to the social interactions, i.e., Theory of Mind reasoning in\nmulti-agent interactions. Additionally, social interactions are often\nmulti-modal -- we can watch people's actions, hear their conversations, and/or\nread about their past behaviors. For AI systems to successfully and safely\ninteract with people in real-world environments, they also need to understand\npeople's mental states as well as their inferences about each other's mental\nstates based on multi-modal information about their interactions. For this, we\nintroduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark.\nMuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluates\nmental reasoning in embodied multi-agent interactions. In MuMA-ToM, we provide\nvideo and text descriptions of people's multi-modal behavior in realistic\nhousehold environments. Based on the context, we then ask questions about\npeople's goals, beliefs, and beliefs about others' goals. We validated MuMA-ToM\nin a human experiment and provided a human baseline. We also proposed a novel\nmulti-modal, multi-agent ToM model, LIMP (Language model-based Inverse\nMulti-agent Planning). Our experimental results show that LIMP significantly\noutperforms state-of-the-art methods, including large multi-modal models (e.g.,\nGPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.", "paper_summary_zh": "\u7406\u89e3\u4eba\u5011\u5728\u8907\u96dc\u7684\u73fe\u5be6\u4e16\u754c\u5834\u666f\u4e2d\u7684\u793e\u4ea4\u4e92\u52d5\u901a\u5e38\u4f9d\u8cf4\u65bc\u8907\u96dc\u7684\u5fc3\u667a\u63a8\u7406\u3002\u70ba\u4e86\u771f\u6b63\u4e86\u89e3\u4eba\u5011\u5982\u4f55\u4ee5\u53ca\u70ba\u4f55\u5f7c\u6b64\u4e92\u52d5\uff0c\u6211\u5011\u5fc5\u9808\u63a8\u8ad6\u51fa\u5c0e\u81f4\u793e\u4ea4\u4e92\u52d5\u7684\u5e95\u5c64\u5fc3\u667a\u72c0\u614b\uff0c\u5373\u591a\u4e3b\u9ad4\u4e92\u52d5\u4e2d\u7684\u5fc3\u667a\u7406\u8ad6\u63a8\u7406\u3002\u6b64\u5916\uff0c\u793e\u4ea4\u4e92\u52d5\u901a\u5e38\u662f\u591a\u6a21\u614b\u7684\u2014\u2014\u6211\u5011\u53ef\u4ee5\u89c0\u5bdf\u4eba\u5011\u7684\u884c\u70ba\u3001\u50be\u807d\u4ed6\u5011\u7684\u5c0d\u8a71\u548c/\u6216\u95b1\u8b80\u4ed6\u5011\u904e\u53bb\u7684\u884c\u70ba\u3002\u70ba\u4e86\u8b93\u4eba\u5de5\u667a\u6167\u7cfb\u7d71\u5728\u73fe\u5be6\u4e16\u754c\u74b0\u5883\u4e2d\u6210\u529f\u4e14\u5b89\u5168\u5730\u8207\u4eba\u4e92\u52d5\uff0c\u4ed6\u5011\u9084\u9700\u8981\u4e86\u89e3\u4eba\u5011\u7684\u5fc3\u667a\u72c0\u614b\uff0c\u4ee5\u53ca\u4ed6\u5011\u6839\u64da\u95dc\u65bc\u4e92\u52d5\u7684\u591a\u6a21\u614b\u8cc7\u8a0a\u5c0d\u5f7c\u6b64\u5fc3\u667a\u72c0\u614b\u7684\u63a8\u8ad6\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86 MuMA-ToM\uff0c\u4e00\u500b\u591a\u6a21\u614b\u591a\u4e3b\u9ad4\u5fc3\u667a\u7406\u8ad6\u57fa\u6e96\u3002MuMA-ToM \u662f\u7b2c\u4e00\u500b\u591a\u6a21\u614b\u5fc3\u667a\u7406\u8ad6\u57fa\u6e96\uff0c\u5b83\u8a55\u4f30\u4e86\u5177\u9ad4\u5316\u591a\u4e3b\u9ad4\u4e92\u52d5\u4e2d\u7684\u5fc3\u667a\u63a8\u7406\u3002\u5728 MuMA-ToM \u4e2d\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u4eba\u5011\u5728\u73fe\u5be6\u5bb6\u5ead\u74b0\u5883\u4e2d\u7684\u591a\u6a21\u614b\u884c\u70ba\u7684\u5f71\u7247\u548c\u6587\u5b57\u63cf\u8ff0\u3002\u7136\u5f8c\uff0c\u6839\u64da\u80cc\u666f\uff0c\u6211\u5011\u8a62\u554f\u6709\u95dc\u4eba\u5011\u7684\u76ee\u6a19\u3001\u4fe1\u5ff5\u548c\u5c0d\u4ed6\u4eba\u76ee\u6a19\u7684\u4fe1\u5ff5\u7684\u554f\u984c\u3002\u6211\u5011\u5728\u4eba\u985e\u5be6\u9a57\u4e2d\u9a57\u8b49\u4e86 MuMA-ToM \u4e26\u63d0\u4f9b\u4e86\u4eba\u985e\u57fa\u6e96\u3002\u6211\u5011\u9084\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u591a\u6a21\u614b\u3001\u591a\u4e3b\u9ad4\u5fc3\u667a\u7406\u8ad6\u6a21\u578b LIMP\uff08\u57fa\u65bc\u8a9e\u8a00\u6a21\u578b\u7684\u53cd\u5411\u591a\u4e3b\u9ad4\u898f\u5283\uff09\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cLIMP \u660e\u986f\u512a\u65bc\u6700\u5148\u9032\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b\uff08\u4f8b\u5982 GPT-4o\u3001Gemini-1.5 Pro\uff09\u548c\u6700\u8fd1\u7684\u591a\u6a21\u614b\u5fc3\u667a\u7406\u8ad6\u6a21\u578b BIP-ALM\u3002", "author": "Haojun Shi et.al.", "authors": "Haojun Shi, Suyu Ye, Xinyu Fang, Chuanyang Jin, Layla Isik, Yen-Ling Kuo, Tianmin Shu", "id": "2408.12574v1", "paper_url": "http://arxiv.org/abs/2408.12574v1", "repo": "null"}}