{"2407.03211": {"publish_time": "2024-07-03", "title": "How Does Quantization Affect Multilingual LLMs?", "paper_summary": "Quantization techniques are widely used to improve inference speed and\ndeployment of large language models. While a wide body of work examines the\nimpact of quantized LLMs on English tasks, none have examined the effect of\nquantization across languages. We conduct a thorough analysis of quantized\nmultilingual LLMs, focusing on their performance across languages and at\nvarying scales. We use automatic benchmarks, LLM-as-a-Judge methods, and human\nevaluation, finding that (1) harmful effects of quantization are apparent in\nhuman evaluation, and automatic metrics severely underestimate the detriment: a\n1.7% average drop in Japanese across automatic tasks corresponds to a 16.0%\ndrop reported by human evaluators on realistic prompts; (2) languages are\ndisparately affected by quantization, with non-Latin script languages impacted\nworst; and (3) challenging tasks such as mathematical reasoning degrade\nfastest. As the ability to serve low-compute models is critical for wide global\nadoption of NLP technologies, our results urge consideration of multilingual\nperformance as a key evaluation criterion for efficient models.", "paper_summary_zh": "\u91cf\u5316\u6280\u8853\u5ee3\u6cdb\u7528\u65bc\u6539\u5584\u63a8\u8ad6\u901f\u5ea6\u548c\u90e8\u7f72\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u3002\u96d6\u7136\u6709\u5927\u91cf\u7814\u7a76\u63a2\u8a0e\u91cf\u5316 LLM \u5c0d\u82f1\u6587\u4efb\u52d9\u7684\u5f71\u97ff\uff0c\u4f46\u6c92\u6709\u4efb\u4f55\u7814\u7a76\u63a2\u8a0e\u91cf\u5316\u5c0d\u8de8\u8a9e\u8a00\u7684\u5f71\u97ff\u3002\u6211\u5011\u5c0d\u91cf\u5316\u7684\u591a\u8a9e\u8a00 LLM \u9032\u884c\u4e86\u5fb9\u5e95\u7684\u5206\u6790\uff0c\u91cd\u9ede\u95dc\u6ce8\u5b83\u5011\u5728\u4e0d\u540c\u8a9e\u8a00\u548c\u4e0d\u540c\u898f\u6a21\u4e0a\u7684\u8868\u73fe\u3002\u6211\u5011\u4f7f\u7528\u81ea\u52d5\u57fa\u6e96\u3001LLM \u4f5c\u70ba\u8a55\u5224\u65b9\u6cd5\u548c\u4eba\u5de5\u8a55\u4f30\uff0c\u767c\u73fe (1) \u91cf\u5316\u7684\u6709\u5bb3\u5f71\u97ff\u5728\u4eba\u5de5\u8a55\u4f30\u4e2d\u5f88\u660e\u986f\uff0c\u800c\u81ea\u52d5\u6307\u6a19\u56b4\u91cd\u4f4e\u4f30\u4e86\u640d\u5bb3\uff1a\u81ea\u52d5\u4efb\u52d9\u4e2d\u65e5\u8a9e\u5e73\u5747\u4e0b\u964d 1.7%\uff0c\u800c\u4eba\u5de5\u8a55\u4f30\u54e1\u5728\u73fe\u5be6\u63d0\u793a\u4e2d\u5831\u544a\u4e0b\u964d\u4e86 16.0%\uff1b(2) \u8a9e\u8a00\u53d7\u5230\u91cf\u5316\u7684\u5f71\u97ff\u4e0d\u540c\uff0c\u975e\u62c9\u4e01\u8a9e\u7cfb\u8a9e\u8a00\u53d7\u5230\u7684\u5f71\u97ff\u6700\u56b4\u91cd\uff1b(3) \u6578\u5b78\u63a8\u7406\u7b49\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\u4e0b\u964d\u6700\u5feb\u3002\u7531\u65bc\u63d0\u4f9b\u4f4e\u904b\u7b97\u6a21\u578b\u7684\u80fd\u529b\u5c0d\u65bc NLP \u6280\u8853\u7684\u5ee3\u6cdb\u5168\u7403\u63a1\u7528\u81f3\u95dc\u91cd\u8981\uff0c\u6211\u5011\u7684\u7d50\u679c\u6566\u4fc3\u5c07\u591a\u8a9e\u8a00\u6027\u80fd\u8996\u70ba\u9ad8\u6548\u6a21\u578b\u7684\u4e3b\u8981\u8a55\u4f30\u6a19\u6e96\u3002", "author": "Kelly Marchisio et.al.", "authors": "Kelly Marchisio, Saurabh Dash, Hongyu Chen, Dennis Aumiller, Ahmet \u00dcst\u00fcn, Sara Hooker, Sebastian Ruder", "id": "2407.03211v1", "paper_url": "http://arxiv.org/abs/2407.03211v1", "repo": "null"}}