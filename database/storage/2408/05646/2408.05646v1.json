{"2408.05646": {"publish_time": "2024-08-10", "title": "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression", "paper_summary": "Large language models (LLMs) represent a groundbreaking advancement in the\ndomain of natural language processing due to their impressive reasoning\nabilities. Recently, there has been considerable interest in increasing the\ncontext lengths for these models to enhance their applicability to complex\ntasks. However, at long context lengths and large batch sizes, the key-value\n(KV) cache, which stores the attention keys and values, emerges as the new\nbottleneck in memory usage during inference. To address this, we propose Eigen\nAttention, which performs the attention operation in a low-rank space, thereby\nreducing the KV cache memory overhead. Our proposed approach is orthogonal to\nexisting KV cache compression techniques and can be used synergistically with\nthem. Through extensive experiments over OPT, MPT, and Llama model families, we\ndemonstrate that Eigen Attention results in up to 40% reduction in KV cache\nsizes and up to 60% reduction in attention operation latency with minimal drop\nin performance.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7531\u65bc\u5176\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4ee3\u8868\u4e86\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u9818\u57df\u7684\u7a81\u7834\u6027\u9032\u5c55\u3002\u6700\u8fd1\uff0c\u4eba\u5011\u76f8\u7576\u6709\u8208\u8da3\u589e\u52a0\u9019\u4e9b\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u9577\u5ea6\uff0c\u4ee5\u589e\u5f37\u5176\u5c0d\u8907\u96dc\u4efb\u52d9\u7684\u9069\u7528\u6027\u3002\u7136\u800c\uff0c\u5728\u8f03\u9577\u7684\u4e0a\u4e0b\u6587\u9577\u5ea6\u548c\u8f03\u5927\u7684\u6279\u6b21\u5927\u5c0f\u4e0b\uff0c\u5132\u5b58\u6ce8\u610f\u529b\u9375\u548c\u503c\u7684\u5feb\u53d6\u8a18\u61b6\u9ad4 (KV) \u6210\u70ba\u63a8\u8ad6\u671f\u9593\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u7684\u65b0\u74f6\u9838\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u7279\u5fb5\u503c\u6ce8\u610f\u529b\uff0c\u5b83\u5728\u4f4e\u79e9\u7a7a\u9593\u4e2d\u57f7\u884c\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u5f9e\u800c\u6e1b\u5c11\u4e86 KV \u5feb\u53d6\u8a18\u61b6\u9ad4\u7684\u958b\u92b7\u3002\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u8207\u73fe\u6709\u7684 KV \u5feb\u53d6\u58d3\u7e2e\u6280\u8853\u6b63\u4ea4\uff0c\u4e26\u4e14\u53ef\u4ee5\u8207\u5b83\u5011\u5354\u540c\u4f7f\u7528\u3002\u901a\u904e\u5c0d OPT\u3001MPT \u548c Llama \u6a21\u578b\u7cfb\u5217\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6211\u5011\u8b49\u660e\u7279\u5fb5\u503c\u6ce8\u610f\u529b\u53ef\u4f7f KV \u5feb\u53d6\u5927\u5c0f\u6e1b\u5c11\u591a\u9054 40%\uff0c\u6ce8\u610f\u529b\u64cd\u4f5c\u5ef6\u9072\u6e1b\u5c11\u591a\u9054 60%\uff0c\u800c\u6548\u80fd\u4e0b\u964d\u5e45\u5ea6\u5f88\u5c0f\u3002", "author": "Utkarsh Saxena et.al.", "authors": "Utkarsh Saxena, Gobinda Saha, Sakshi Choudhary, Kaushik Roy", "id": "2408.05646v1", "paper_url": "http://arxiv.org/abs/2408.05646v1", "repo": "null"}}