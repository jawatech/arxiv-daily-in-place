{"2406.19807": {"publish_time": "2024-06-28", "title": "Deceptive Diffusion: Generating Synthetic Adversarial Examples", "paper_summary": "We introduce the concept of deceptive diffusion -- training a generative AI\nmodel to produce adversarial images. Whereas a traditional adversarial attack\nalgorithm aims to perturb an existing image to induce a misclassificaton, the\ndeceptive diffusion model can create an arbitrary number of new, misclassified\nimages that are not directly associated with training or test images. Deceptive\ndiffusion offers the possibility of strengthening defence algorithms by\nproviding adversarial training data at scale, including types of\nmisclassification that are otherwise difficult to find. In our experiments, we\nalso investigate the effect of training on a partially attacked data set. This\nhighlights a new type of vulnerability for generative diffusion models: if an\nattacker is able to stealthily poison a portion of the training data, then the\nresulting diffusion model will generate a similar proportion of misleading\noutputs.", "paper_summary_zh": "\u6211\u5011\u5f15\u5165\u4e86\u6b3a\u9a19\u6027\u64f4\u6563\u7684\u6982\u5ff5 -- \u8a13\u7df4\u751f\u6210\u5f0f AI \u6a21\u578b\u4f86\u7522\u751f\u5c0d\u6297\u6027\u5f71\u50cf\u3002\u50b3\u7d71\u7684\u5c0d\u6297\u6027\u653b\u64ca\u6f14\u7b97\u6cd5\u65e8\u5728\u64fe\u52d5\u73fe\u6709\u5f71\u50cf\u4ee5\u8a98\u767c\u932f\u8aa4\u5206\u985e\uff0c\u800c\u6b3a\u9a19\u6027\u64f4\u6563\u6a21\u578b\u53ef\u4ee5\u7522\u751f\u4efb\u610f\u6578\u91cf\u7684\u5168\u65b0\u3001\u932f\u8aa4\u5206\u985e\u7684\u5f71\u50cf\uff0c\u9019\u4e9b\u5f71\u50cf\u8207\u8a13\u7df4\u6216\u6e2c\u8a66\u5f71\u50cf\u6c92\u6709\u76f4\u63a5\u95dc\u806f\u3002\u6b3a\u9a19\u6027\u64f4\u6563\u63d0\u4f9b\u4e86\u900f\u904e\u5927\u898f\u6a21\u63d0\u4f9b\u5c0d\u6297\u6027\u8a13\u7df4\u8cc7\u6599\u4f86\u5f37\u5316\u9632\u79a6\u6f14\u7b97\u6cd5\u7684\u53ef\u80fd\u6027\uff0c\u5305\u62ec\u5176\u4ed6\u96e3\u4ee5\u627e\u5230\u7684\u932f\u8aa4\u5206\u985e\u985e\u578b\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u4e5f\u7814\u7a76\u4e86\u5728\u90e8\u5206\u53d7\u653b\u64ca\u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\u7684\u6548\u679c\u3002\u9019\u7a81\u986f\u4e86\u751f\u6210\u5f0f\u64f4\u6563\u6a21\u578b\u7684\u4e00\u7a2e\u985e\u578b\u65b0\u6f0f\u6d1e\uff1a\u5982\u679c\u653b\u64ca\u8005\u80fd\u5920\u79d8\u5bc6\u6bd2\u5bb3\u8a13\u7df4\u8cc7\u6599\u7684\u4e00\u90e8\u5206\uff0c\u5247\u7522\u751f\u7684\u64f4\u6563\u6a21\u578b\u5c07\u7522\u751f\u985e\u4f3c\u6bd4\u4f8b\u7684\u8aa4\u5c0e\u8f38\u51fa\u3002", "author": "Lucas Beerens et.al.", "authors": "Lucas Beerens, Catherine F. Higham, Desmond J. Higham", "id": "2406.19807v1", "paper_url": "http://arxiv.org/abs/2406.19807v1", "repo": "null"}}