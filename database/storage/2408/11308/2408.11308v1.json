{"2408.11308": {"publish_time": "2024-08-21", "title": "EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models", "paper_summary": "Large Language Models (LLMs) are increasingly attracting attention in various\napplications. Nonetheless, there is a growing concern as some users attempt to\nexploit these models for malicious purposes, including the synthesis of\ncontrolled substances and the propagation of disinformation. In an effort to\nmitigate such risks, the concept of \"Alignment\" technology has been developed.\nHowever, recent studies indicate that this alignment can be undermined using\nsophisticated prompt engineering or adversarial suffixes, a technique known as\n\"Jailbreak.\" Our research takes cues from the human-like generate process of\nLLMs. We identify that while jailbreaking prompts may yield output logits\nsimilar to benign prompts, their initial embeddings within the model's latent\nspace tend to be more analogous to those of malicious prompts. Leveraging this\nfinding, we propose utilizing the early transformer outputs of LLMs as a means\nto detect malicious inputs, and terminate the generation immediately. Built\nupon this idea, we introduce a simple yet significant defense approach called\nEEG-Defender for LLMs. We conduct comprehensive experiments on ten jailbreak\nmethods across three models. Our results demonstrate that EEG-Defender is\ncapable of reducing the Attack Success Rate (ASR) by a significant margin,\nroughly 85\\% in comparison with 50\\% for the present SOTAs, with minimal impact\non the utility and effectiveness of LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u61c9\u7528\u4e2d\u8d8a\u4f86\u8d8a\u53d7\u5230\u95dc\u6ce8\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u96a8\u8457\u4e00\u4e9b\u4f7f\u7528\u8005\u5617\u8a66\u5c07\u9019\u4e9b\u6a21\u578b\u7528\u65bc\u60e1\u610f\u76ee\u7684\uff0c\u5305\u62ec\u5408\u6210\u53d7\u63a7\u7269\u8cea\u548c\u6563\u5e03\u932f\u8aa4\u8a0a\u606f\uff0c\u64d4\u6182\u4e5f\u8207\u65e5\u4ff1\u589e\u3002\u70ba\u4e86\u6e1b\u8f15\u6b64\u985e\u98a8\u96aa\uff0c\u300c\u6bd4\u5c0d\u300d\u6280\u8853\u7684\u6982\u5ff5\u61c9\u904b\u800c\u751f\u3002\u7136\u800c\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u9019\u7a2e\u6bd4\u5c0d\u53ef\u4ee5\u4f7f\u7528\u7cbe\u5bc6\u7684\u63d0\u793a\u5de5\u7a0b\u6216\u5c0d\u6297\u6027\u5f8c\u7db4\uff08\u4e00\u7a2e\u7a31\u70ba\u300c\u8d8a\u7344\u300d\u7684\u6280\u8853\uff09\u4f86\u7834\u58de\u3002\u6211\u5011\u7684\u7814\u7a76\u5f9e LLM \u985e\u4f3c\u4eba\u985e\u7684\u751f\u6210\u904e\u7a0b\u6c72\u53d6\u9748\u611f\u3002\u6211\u5011\u767c\u73fe\uff0c\u5118\u7ba1\u8d8a\u7344\u63d0\u793a\u53ef\u80fd\u6703\u7522\u751f\u985e\u4f3c\u65bc\u826f\u6027\u63d0\u793a\u7684\u8f38\u51fa logit\uff0c\u4f46\u5b83\u5011\u5728\u6a21\u578b\u6f5b\u5728\u7a7a\u9593\u4e2d\u7684\u521d\u59cb\u5d4c\u5165\u901a\u5e38\u66f4\u985e\u4f3c\u65bc\u60e1\u610f\u63d0\u793a\u7684\u5d4c\u5165\u3002\u5229\u7528\u9019\u4e00\u767c\u73fe\uff0c\u6211\u5011\u5efa\u8b70\u5229\u7528 LLM \u7684\u65e9\u671f\u8b8a\u63db\u5668\u8f38\u51fa\u4f5c\u70ba\u5075\u6e2c\u60e1\u610f\u8f38\u5165\u4e26\u7acb\u5373\u7d42\u6b62\u751f\u6210\u7684\u624b\u6bb5\u3002\u57fa\u65bc\u9019\u500b\u60f3\u6cd5\uff0c\u6211\u5011\u70ba LLM \u4ecb\u7d39\u4e86\u4e00\u7a2e\u7c21\u55ae\u4f46\u91cd\u8981\u7684\u9632\u79a6\u65b9\u6cd5\uff0c\u7a31\u70ba EEG-Defender\u3002\u6211\u5011\u5c0d\u4e09\u500b\u6a21\u578b\u4e2d\u7684\u5341\u7a2e\u8d8a\u7344\u65b9\u6cd5\u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cEEG-Defender \u80fd\u5920\u5c07\u653b\u64ca\u6210\u529f\u7387 (ASR) \u5927\u5e45\u964d\u4f4e\uff0c\u8207\u73fe\u6709\u7684 SOTA \u76f8\u6bd4\uff0c\u5927\u7d04\u964d\u4f4e\u4e86 85%\uff0c\u800c\u5c0d LLM \u7684\u6548\u7528\u548c\u6709\u6548\u6027\u7684\u5f71\u97ff\u6700\u5c0f\u3002", "author": "Chongwen Zhao et.al.", "authors": "Chongwen Zhao, Zhihao Dou, Kaizhu Huang", "id": "2408.11308v1", "paper_url": "http://arxiv.org/abs/2408.11308v1", "repo": "null"}}