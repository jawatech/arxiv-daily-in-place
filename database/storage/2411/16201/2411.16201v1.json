{"2411.16201": {"publish_time": "2024-11-25", "title": "Video-Text Dataset Construction from Multi-AI Feedback: Promoting Weak-to-Strong Preference Learning for Video Large Language Models", "paper_summary": "High-quality video-text preference data is crucial for Multimodal Large\nLanguage Models (MLLMs) alignment. However, existing preference data is very\nscarce. Obtaining VQA preference data for preference training is costly, and\nmanually annotating responses is highly unreliable, which could result in\nlow-quality pairs. Meanwhile, AI-generated responses controlled by temperature\nadjustment lack diversity. To address these issues, we propose a high-quality\nVQA preference dataset, called \\textit{\\textbf{M}ultiple \\textbf{M}ultimodal\n\\textbf{A}rtificial \\textbf{I}ntelligence \\textbf{P}reference Datasets in\n\\textbf{V}QA} (\\textbf{MMAIP-V}), which is constructed by sampling from the\nresponse distribution set and using an external scoring function for response\nevaluation. Furthermore, to fully leverage the preference knowledge in MMAIP-V\nand ensure sufficient optimization, we propose \\textit{\\textbf{Iter}ative\n\\textbf{W}eak-to-\\textbf{S}trong \\textbf{R}einforcement \\textbf{L}earning from\n\\textbf{AI} \\textbf{F}eedback for video MLLMs} (\\textbf{Iter-W2S-RLAIF}), a\nframework that gradually enhances MLLMs' alignment capabilities by iteratively\nupdating the reference model and performing parameter extrapolation. Finally,\nwe propose an unbiased and information-complete evaluation scheme in VQA\nevaluation. Experiments demonstrate that MMAIP-V is beneficial for MLLMs in\npreference learning and Iter-W2S-RLAIF fully exploits the alignment information\nin MMAIP-V. We believe that the proposed automatic VQA preference data\ngeneration pipeline based on AI feedback can greatly promote future work in the\nMLLMs alignment. \\textbf{Code and dataset are available}\n\\href{https://anonymous.4open.science/r/MMAIP-V_Iter-W2S-RLAIF-702F}{MMAIP-V\\_Iter-W2S-RLAIF-702F}.", "paper_summary_zh": "\u9ad8\u8d28\u91cf\u5f71\u7247\u6587\u5b57\u504f\u597d\u8cc7\u6599\u5c0d\u65bc\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u6bd4\u5c0d\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u504f\u597d\u8cc7\u6599\u975e\u5e38\u7a00\u5c11\u3002\u53d6\u5f97 VQA \u504f\u597d\u8cc7\u6599\u4ee5\u9032\u884c\u504f\u597d\u8a13\u7df4\u7684\u6210\u672c\u5f88\u9ad8\uff0c\u800c\u624b\u52d5\u8a3b\u89e3\u56de\u61c9\u7684\u53ef\u9760\u6027\u6975\u4f4e\uff0c\u53ef\u80fd\u6703\u5c0e\u81f4\u4f4e\u54c1\u8cea\u7684\u914d\u5c0d\u3002\u540c\u6642\uff0c\u7531\u6eab\u5ea6\u8abf\u6574\u63a7\u5236\u7684 AI \u751f\u6210\u7684\u56de\u61c9\u7f3a\u4e4f\u591a\u6a23\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u9ad8\u54c1\u8cea\u7684 VQA \u504f\u597d\u8cc7\u6599\u96c6\uff0c\u7a31\u70ba\u300c\u591a\u6a21\u614b\u591a\u91cd\u4eba\u5de5\u667a\u6167 VQA \u504f\u597d\u8cc7\u6599\u96c6\u300d(MMAIP-V)\uff0c\u5176\u900f\u904e\u5f9e\u56de\u61c9\u5206\u4f48\u96c6\u4e2d\u53d6\u6a23\u4e26\u4f7f\u7528\u5916\u90e8\u8a55\u5206\u51fd\u6578\u5c0d\u56de\u61c9\u9032\u884c\u8a55\u4f30\u4f86\u5efa\u69cb\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u5145\u5206\u5229\u7528 MMAIP-V \u4e2d\u7684\u504f\u597d\u77e5\u8b58\u4e26\u78ba\u4fdd\u5145\u5206\u7684\u6700\u4f73\u5316\uff0c\u6211\u5011\u63d0\u51fa\u300c\u900f\u904e AI \u56de\u994b\u9032\u884c\u5f71\u7247 MLLM \u7684\u53cd\u8986\u5f31\u8f49\u5f37\u5f37\u5316\u5b78\u7fd2\u300d(Iter-W2S-RLAIF)\uff0c\u9019\u662f\u4e00\u500b\u900f\u904e\u53cd\u8986\u66f4\u65b0\u53c3\u8003\u6a21\u578b\u4e26\u57f7\u884c\u53c3\u6578\u5916\u63a8\u4f86\u9010\u6f38\u63d0\u5347 MLLM \u6bd4\u5c0d\u80fd\u529b\u7684\u67b6\u69cb\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5728 VQA \u8a55\u4f30\u4e2d\u63d0\u51fa\u4e00\u500b\u7121\u504f\u898b\u4e14\u8cc7\u8a0a\u5b8c\u6574\u7684\u8a55\u4f30\u65b9\u6848\u3002\u5be6\u9a57\u8b49\u660e\uff0cMMAIP-V \u6709\u52a9\u65bc MLLM \u9032\u884c\u504f\u597d\u5b78\u7fd2\uff0c\u800c Iter-W2S-RLAIF \u5247\u5145\u5206\u5229\u7528 MMAIP-V \u4e2d\u7684\u6bd4\u5c0d\u8cc7\u8a0a\u3002\u6211\u5011\u76f8\u4fe1\uff0c\u9019\u500b\u57fa\u65bc AI \u56de\u994b\u7684\u81ea\u52d5 VQA \u504f\u597d\u8cc7\u6599\u7522\u751f\u7ba1\u9053\uff0c\u53ef\u4ee5\u6975\u5927\u5730\u4fc3\u9032\u672a\u4f86\u5728 MLLM \u6bd4\u5c0d\u65b9\u9762\u7684\u7814\u7a76\u3002**\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u5df2\u65bc\u6b64\u8655\u63d0\u4f9b**\\href{https://anonymous.4open.science/r/MMAIP-V_Iter-W2S-RLAIF-702F}{MMAIP-V\\_Iter-W2S-RLAIF-702F}\u3002", "author": "Hao Yi et.al.", "authors": "Hao Yi, Qingyang Li, Yulan Hu, Fuzheng Zhang, Di Zhang, Yong Liu", "id": "2411.16201v1", "paper_url": "http://arxiv.org/abs/2411.16201v1", "repo": "null"}}