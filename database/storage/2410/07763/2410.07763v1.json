{"2410.07763": {"publish_time": "2024-10-10", "title": "HARIVO: Harnessing Text-to-Image Models for Video Generation", "paper_summary": "We present a method to create diffusion-based video models from pretrained\nText-to-Image (T2I) models. Recently, AnimateDiff proposed freezing the T2I\nmodel while only training temporal layers. We advance this method by proposing\na unique architecture, incorporating a mapping network and frame-wise tokens,\ntailored for video generation while maintaining the diversity and creativity of\nthe original T2I model. Key innovations include novel loss functions for\ntemporal smoothness and a mitigating gradient sampling technique, ensuring\nrealistic and temporally consistent video generation despite limited public\nvideo data. We have successfully integrated video-specific inductive biases\ninto the architecture and loss functions. Our method, built on the frozen\nStableDiffusion model, simplifies training processes and allows for seamless\nintegration with off-the-shelf models like ControlNet and DreamBooth. project\npage: https://kwonminki.github.io/HARIVO", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5f9e\u9810\u8a13\u7df4\u7684\u6587\u5b57\u8f49\u5716\u50cf (T2I) \u6a21\u578b\u4e2d\u5efa\u7acb\u57fa\u65bc\u64f4\u6563\u7684\u5f71\u7247\u6a21\u578b\u3002\u6700\u8fd1\uff0cAnimateDiff \u63d0\u8b70\u51cd\u7d50 T2I \u6a21\u578b\uff0c\u540c\u6642\u50c5\u8a13\u7df4\u6642\u9593\u5c64\u3002\u6211\u5011\u900f\u904e\u63d0\u51fa\u4e00\u500b\u7368\u7279\u7684\u67b6\u69cb\u4f86\u63a8\u9032\u6b64\u65b9\u6cd5\uff0c\u7d50\u5408\u4e00\u500b\u5c0d\u61c9\u7db2\u8def\u548c\u9010\u5e40\u4ee3\u5e63\uff0c\u5c08\u9580\u7528\u65bc\u5f71\u7247\u751f\u6210\uff0c\u540c\u6642\u7dad\u6301\u539f\u59cb T2I \u6a21\u578b\u7684\u591a\u6a23\u6027\u548c\u5275\u9020\u529b\u3002\u95dc\u9375\u5275\u65b0\u5305\u62ec\u6642\u9593\u5e73\u6ed1\u5ea6\u7684\u65b0\u640d\u5931\u51fd\u6578\u548c\u7de9\u89e3\u68af\u5ea6\u53d6\u6a23\u6280\u8853\uff0c\u78ba\u4fdd\u903c\u771f\u4e14\u6642\u9593\u4e00\u81f4\u7684\u5f71\u7247\u751f\u6210\uff0c\u5118\u7ba1\u53d7\u9650\u65bc\u516c\u958b\u5f71\u7247\u8cc7\u6599\u3002\u6211\u5011\u5df2\u6210\u529f\u5c07\u5f71\u7247\u7279\u5b9a\u7684\u6b78\u7d0d\u504f\u5dee\u6574\u5408\u5230\u67b6\u69cb\u548c\u640d\u5931\u51fd\u6578\u4e2d\u3002\u6211\u5011\u7684\u6a21\u578b\u5efa\u7acb\u5728\u51cd\u7d50\u7684 StableDiffusion \u6a21\u578b\u4e0a\uff0c\u7c21\u5316\u4e86\u8a13\u7df4\u6d41\u7a0b\uff0c\u4e26\u5141\u8a31\u8207 ControlNet \u548c DreamBooth \u7b49\u73fe\u6210\u6a21\u578b\u7121\u7e2b\u6574\u5408\u3002\u5c08\u6848\u9801\u9762\uff1ahttps://kwonminki.github.io/HARIVO", "author": "Mingi Kwon et.al.", "authors": "Mingi Kwon, Seoung Wug Oh, Yang Zhou, Difan Liu, Joon-Young Lee, Haoran Cai, Baqiao Liu, Feng Liu, Youngjung Uh", "id": "2410.07763v1", "paper_url": "http://arxiv.org/abs/2410.07763v1", "repo": "null"}}