{"2412.08285": {"publish_time": "2024-12-11", "title": "Adaptive Prompting for Continual Relation Extraction: A Within-Task Variance Perspective", "paper_summary": "To address catastrophic forgetting in Continual Relation Extraction (CRE),\nmany current approaches rely on memory buffers to rehearse previously learned\nknowledge while acquiring new tasks. Recently, prompt-based methods have\nemerged as potent alternatives to rehearsal-based strategies, demonstrating\nstrong empirical performance. However, upon analyzing existing prompt-based\napproaches for CRE, we identified several critical limitations, such as\ninaccurate prompt selection, inadequate mechanisms for mitigating forgetting in\nshared parameters, and suboptimal handling of cross-task and within-task\nvariances. To overcome these challenges, we draw inspiration from the\nrelationship between prefix-tuning and mixture of experts, proposing a novel\napproach that employs a prompt pool for each task, capturing variations within\neach task while enhancing cross-task variances. Furthermore, we incorporate a\ngenerative model to consolidate prior knowledge within shared parameters,\neliminating the need for explicit data storage. Extensive experiments validate\nthe efficacy of our approach, demonstrating superior performance over\nstate-of-the-art prompt-based and rehearsal-free methods in continual relation\nextraction.", "paper_summary_zh": "\u70ba\u4e86\u89e3\u6c7a\u6301\u7e8c\u95dc\u4fc2\u8403\u53d6 (CRE) \u4e2d\u7684\u707d\u96e3\u6027\u907a\u5fd8\uff0c\u8a31\u591a\u73fe\u6709\u65b9\u6cd5\u4f9d\u8cf4\u8a18\u61b6\u9ad4\u7de9\u885d\u5340\u4f86\u6392\u7df4\u5148\u524d\u5b78\u7fd2\u7684\u77e5\u8b58\uff0c\u540c\u6642\u7372\u53d6\u65b0\u4efb\u52d9\u3002\u6700\u8fd1\uff0c\u57fa\u65bc\u63d0\u793a\u7684\u65b9\u6cd5\u5df2\u6210\u70ba\u57fa\u65bc\u6392\u7df4\u7b56\u7565\u7684\u6709\u529b\u66ff\u4ee3\u65b9\u6848\uff0c\u5c55\u793a\u51fa\u5f37\u5927\u7684\u7d93\u9a57\u6548\u80fd\u3002\u7136\u800c\uff0c\u5728\u5206\u6790\u73fe\u6709\u7684\u57fa\u65bc\u63d0\u793a\u7684 CRE \u65b9\u6cd5\u5f8c\uff0c\u6211\u5011\u767c\u73fe\u4e86\u5e7e\u500b\u95dc\u9375\u9650\u5236\uff0c\u4f8b\u5982\u4e0d\u6e96\u78ba\u7684\u63d0\u793a\u9078\u64c7\u3001\u6e1b\u8f15\u5171\u4eab\u53c3\u6578\u4e2d\u907a\u5fd8\u7684\u4e0d\u5145\u5206\u6a5f\u5236\uff0c\u4ee5\u53ca\u5c0d\u8de8\u4efb\u52d9\u548c\u4efb\u52d9\u5167\u8b8a\u7570\u7684\u6b21\u512a\u8655\u7406\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5f9e\u524d\u7db4\u8abf\u6574\u548c\u5c08\u5bb6\u6df7\u5408\u4e4b\u9593\u7684\u95dc\u4fc2\u4e2d\u6c72\u53d6\u9748\u611f\uff0c\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u70ba\u6bcf\u500b\u4efb\u52d9\u63a1\u7528\u63d0\u793a\u6c60\uff0c\u6355\u6349\u6bcf\u500b\u4efb\u52d9\u5167\u7684\u8b8a\u7570\uff0c\u540c\u6642\u589e\u5f37\u8de8\u4efb\u52d9\u8b8a\u7570\u3002\u6b64\u5916\uff0c\u6211\u5011\u7d50\u5408\u4e86\u4e00\u500b\u751f\u6210\u6a21\u578b\u4f86\u6574\u5408\u5171\u4eab\u53c3\u6578\u5167\u7684\u5148\u524d\u77e5\u8b58\uff0c\u6d88\u9664\u4e86\u5c0d\u660e\u78ba\u8cc7\u6599\u5132\u5b58\u7684\u9700\u6c42\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u9a57\u8b49\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6548\u529b\uff0c\u5c55\u793a\u4e86\u5728\u6301\u7e8c\u95dc\u4fc2\u8403\u53d6\u4e2d\u512a\u65bc\u6700\u5148\u9032\u7684\u57fa\u65bc\u63d0\u793a\u548c\u7121\u6392\u7df4\u65b9\u6cd5\u7684\u5353\u8d8a\u6548\u80fd\u3002", "author": "Minh Le et.al.", "authors": "Minh Le, Tien Ngoc Luu, An Nguyen The, Thanh-Thien Le, Trang Nguyen, Thanh Tung Nguyen, Linh Ngo Van, Thien Huu Nguyen", "id": "2412.08285v1", "paper_url": "http://arxiv.org/abs/2412.08285v1", "repo": "null"}}