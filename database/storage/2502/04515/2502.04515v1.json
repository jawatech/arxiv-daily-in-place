{"2502.04515": {"publish_time": "2025-02-06", "title": "MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification", "paper_summary": "Medical time series has been playing a vital role in real-world healthcare\nsystems as valuable information in monitoring health conditions of patients.\nAccurate classification for medical time series, e.g., Electrocardiography\n(ECG) signals, can help for early detection and diagnosis. Traditional methods\ntowards medical time series classification rely on handcrafted feature\nextraction and statistical methods; with the recent advancement of artificial\nintelligence, the machine learning and deep learning methods have become more\npopular. However, existing methods often fail to fully model the complex\nspatial dynamics under different scales, which ignore the dynamic\nmulti-resolution spatial and temporal joint inter-dependencies. Moreover, they\nare less likely to consider the special baseline wander problem as well as the\nmulti-view characteristics of medical time series, which largely hinders their\nprediction performance. To address these limitations, we propose a\nMulti-resolution Spatiotemporal Graph Learning framework, MedGNN, for medical\ntime series classification. Specifically, we first propose to construct\nmulti-resolution adaptive graph structures to learn dynamic multi-scale\nembeddings. Then, to address the baseline wander problem, we propose Difference\nAttention Networks to operate self-attention mechanisms on the finite\ndifference for temporal modeling. Moreover, to learn the multi-view\ncharacteristics, we utilize the Frequency Convolution Networks to capture\ncomplementary information of medical time series from the frequency domain. In\naddition, we introduce the Multi-resolution Graph Transformer architecture to\nmodel the dynamic dependencies and fuse the information from different\nresolutions. Finally, we have conducted extensive experiments on multiple\nmedical real-world datasets that demonstrate the superior performance of our\nmethod. Our Code is available.", "paper_summary_zh": "<paragraph>\u91ab\u7642\u6642\u9593\u5e8f\u5217\u5728\u771f\u5be6\u4e16\u754c\u7684\u91ab\u7642\u4fdd\u5065\u7cfb\u7d71\u4e2d\u626e\u6f14\u8457\u81f3\u95dc\u91cd\u8981\u7684\u89d2\u8272\uff0c\u4f5c\u70ba\u76e3\u63a7\u60a3\u8005\u5065\u5eb7\u72c0\u6cc1\u7684\u5bf6\u8cb4\u8cc7\u8a0a\u3002\n\u6e96\u78ba\u5206\u985e\u91ab\u7642\u6642\u9593\u5e8f\u5217\uff0c\u4f8b\u5982\u5fc3\u96fb\u5716 (ECG) \u8a0a\u865f\uff0c\u6709\u52a9\u65bc\u65e9\u671f\u5075\u6e2c\u548c\u8a3a\u65b7\u3002\u50b3\u7d71\u7684\u91ab\u7642\u6642\u9593\u5e8f\u5217\u5206\u985e\u65b9\u6cd5\u4ef0\u8cf4\u624b\u5de5\u7279\u5fb5\u8403\u53d6\u548c\u7d71\u8a08\u65b9\u6cd5\uff1b\u96a8\u8457\u4eba\u5de5\u667a\u6167\u7684\u6700\u65b0\u9032\u5c55\uff0c\u6a5f\u5668\u5b78\u7fd2\u548c\u6df1\u5ea6\u5b78\u7fd2\u65b9\u6cd5\u8b8a\u5f97\u66f4\u70ba\u666e\u53ca\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u901a\u5e38\u7121\u6cd5\u5b8c\u5168\u5efa\u6a21\u4e0d\u540c\u5c3a\u5ea6\u4e0b\u7684\u8907\u96dc\u7a7a\u9593\u52d5\u614b\uff0c\u5ffd\u7565\u4e86\u52d5\u614b\u591a\u89e3\u6790\u5ea6\u7a7a\u9593\u548c\u6642\u9593\u95dc\u7bc0\u76f8\u4e92\u4f9d\u8cf4\u6027\u3002\u6b64\u5916\uff0c\u5b83\u5011\u4e0d\u592a\u53ef\u80fd\u8003\u616e\u7279\u6b8a\u7684\u57fa\u7dda\u6f02\u79fb\u554f\u984c\u4ee5\u53ca\u91ab\u7642\u6642\u9593\u5e8f\u5217\u7684\u591a\u8996\u89d2\u7279\u6027\uff0c\u9019\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u963b\u7919\u4e86\u5b83\u5011\u7684\u9810\u6e2c\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u591a\u89e3\u6790\u5ea6\u6642\u7a7a\u5716\u5f62\u5b78\u7fd2\u67b6\u69cb MedGNN\uff0c\u7528\u65bc\u91ab\u7642\u6642\u9593\u5e8f\u5217\u5206\u985e\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u9996\u5148\u63d0\u51fa\u69cb\u5efa\u591a\u89e3\u6790\u5ea6\u81ea\u9069\u61c9\u5716\u5f62\u7d50\u69cb\u4ee5\u5b78\u7fd2\u52d5\u614b\u591a\u5c3a\u5ea6\u5d4c\u5165\u3002\u7136\u5f8c\uff0c\u70ba\u4e86\u89e3\u6c7a\u57fa\u7dda\u6f02\u79fb\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u5dee\u5206\u6ce8\u610f\u529b\u7db2\u8def\uff0c\u5c0d\u6642\u9593\u5efa\u6a21\u7684\u6709\u9650\u5dee\u5206\u904b\u7b97\u81ea\u6ce8\u610f\u529b\u6a5f\u5236\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u5b78\u7fd2\u591a\u8996\u89d2\u7279\u6027\uff0c\u6211\u5011\u5229\u7528\u983b\u7387\u5377\u7a4d\u7db2\u8def\u5f9e\u983b\u57df\u64f7\u53d6\u91ab\u7642\u6642\u9593\u5e8f\u5217\u7684\u4e92\u88dc\u8cc7\u8a0a\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e86\u591a\u89e3\u6790\u5ea6\u5716\u5f62Transformer\u67b6\u69cb\u4f86\u5efa\u6a21\u52d5\u614b\u4f9d\u8cf4\u6027\uff0c\u4e26\u878d\u5408\u4f86\u81ea\u4e0d\u540c\u89e3\u6790\u5ea6\u7684\u8cc7\u8a0a\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c0d\u591a\u500b\u91ab\u7642\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u512a\u7570\u6548\u80fd\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u3002</paragraph>", "author": "Wei Fan et.al.", "authors": "Wei Fan, Jingru Fei, Dingyu Guo, Kun Yi, Xiaozhuang Song, Haolong Xiang, Hangting Ye, Min Li", "id": "2502.04515v1", "paper_url": "http://arxiv.org/abs/2502.04515v1", "repo": "null"}}