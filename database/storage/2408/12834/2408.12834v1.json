{"2408.12834": {"publish_time": "2024-08-23", "title": "CLLMFS: A Contrastive Learning enhanced Large Language Model Framework for Few-Shot Named Entity Recognition", "paper_summary": "Few-shot Named Entity Recognition (NER), the task of identifying named\nentities with only a limited amount of labeled data, has gained increasing\nsignificance in natural language processing. While existing methodologies have\nshown some effectiveness, such as enriching label semantics through various\nprompting modes or employing metric learning techniques, their performance\nexhibits limited robustness across diverse domains due to the lack of rich\nknowledge in their pre-trained models. To address this issue, we propose\nCLLMFS, a Contrastive Learning enhanced Large Language Model (LLM) Framework\nfor Few-Shot Named Entity Recognition, achieving promising results with limited\ntraining data. Considering the impact of LLM's internal representations on\ndownstream tasks, CLLMFS integrates Low-Rank Adaptation (LoRA) and contrastive\nlearning mechanisms specifically tailored for few-shot NER. By enhancing the\nmodel's internal representations, CLLMFS effectively improves both entity\nboundary awareness ability and entity recognition accuracy. Our method has\nachieved state-of-the-art performance improvements on F1-score ranging from\n2.58\\% to 97.74\\% over existing best-performing methods across several\nrecognized benchmarks. Furthermore, through cross-domain NER experiments\nconducted on multiple datasets, we have further validated the robust\ngeneralization capability of our method. Our code will be released in the near\nfuture.", "paper_summary_zh": "<paragraph>\u5c11\u6837\u672c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b (NER)\uff0c\u4ec5\u4f7f\u7528\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u8bc6\u522b\u547d\u540d\u5b9e\u4f53\u7684\u4efb\u52a1\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u867d\u7136\u73b0\u6709\u65b9\u6cd5\u5df2\u7ecf\u663e\u793a\u51fa\u4e00\u5b9a\u7684\u6709\u6548\u6027\uff0c\u4f8b\u5982\u901a\u8fc7\u5404\u79cd\u63d0\u793a\u6a21\u5f0f\u4e30\u5bcc\u6807\u7b7e\u8bed\u4e49\u6216\u91c7\u7528\u5ea6\u91cf\u5b66\u4e60\u6280\u672f\uff0c\u4f46\u7531\u4e8e\u5176\u9884\u8bad\u7ec3\u6a21\u578b\u7f3a\u4e4f\u4e30\u5bcc\u7684\u77e5\u8bc6\uff0c\u5176\u6027\u80fd\u5728\u4e0d\u540c\u9886\u57df\u8868\u73b0\u51fa\u6709\u9650\u7684\u9c81\u68d2\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 CLLMFS\uff0c\u4e00\u4e2a\u7528\u4e8e\u5c11\u6837\u672c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u5bf9\u6bd4\u5b66\u4e60\u589e\u5f3a\u578b\u5927\u8bed\u8a00\u6a21\u578b (LLM) \u6846\u67b6\uff0c\u5728\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002\u8003\u8651\u5230 LLM \u7684\u5185\u90e8\u8868\u793a\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u5f71\u54cd\uff0cCLLMFS \u96c6\u6210\u4e86\u4f4e\u79e9\u81ea\u9002\u5e94 (LoRA) \u548c\u5bf9\u6bd4\u5b66\u4e60\u673a\u5236\uff0c\u4e13\u95e8\u9488\u5bf9\u5c11\u6837\u672c NER \u91cf\u8eab\u5b9a\u5236\u3002\u901a\u8fc7\u589e\u5f3a\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\uff0cCLLMFS \u6709\u6548\u5730\u63d0\u9ad8\u4e86\u5b9e\u4f53\u8fb9\u754c\u611f\u77e5\u80fd\u529b\u548c\u5b9e\u4f53\u8bc6\u522b\u51c6\u786e\u6027\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5728 F1 \u5f97\u5206\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u51e0\u4e2a\u516c\u8ba4\u7684\u57fa\u51c6\u4e0a\uff0c\u4e0e\u73b0\u6709\u7684\u6700\u4f73\u65b9\u6cd5\u76f8\u6bd4\uff0c\u63d0\u5347\u5e45\u5ea6\u4ece 2.58% \u5230 97.74%\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8de8\u57df NER \u5b9e\u9a8c\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u7a33\u5065\u6cdb\u5316\u80fd\u529b\u3002\u6211\u4eec\u7684\u4ee3\u7801\u5c06\u5728\u4e0d\u4e45\u7684\u5c06\u6765\u53d1\u5e03\u3002</paragraph>", "author": "Yafeng Zhang et.al.", "authors": "Yafeng Zhang, Zilan Yu, Yuang Huang, Jing Tang", "id": "2408.12834v1", "paper_url": "http://arxiv.org/abs/2408.12834v1", "repo": "null"}}