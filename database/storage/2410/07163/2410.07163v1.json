{"2410.07163": {"publish_time": "2024-10-09", "title": "Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning", "paper_summary": "In this work, we address the problem of large language model (LLM)\nunlearning, aiming to remove unwanted data influences and associated model\ncapabilities (e.g., copyrighted data or harmful content generation) while\npreserving essential model utilities, without the need for retraining from\nscratch. Despite the growing need for LLM unlearning, a principled optimization\nframework remains lacking. To this end, we revisit the state-of-the-art\napproach, negative preference optimization (NPO), and identify the issue of\nreference model bias, which could undermine NPO's effectiveness, particularly\nwhen unlearning forget data of varying difficulty. Given that, we propose a\nsimple yet effective unlearning optimization framework, called SimNPO, showing\nthat 'simplicity' in removing the reliance on a reference model (through the\nlens of simple preference optimization) benefits unlearning. We also provide\ndeeper insights into SimNPO's advantages, supported by analysis using mixtures\nof Markov chains. Furthermore, we present extensive experiments validating\nSimNPO's superiority over existing unlearning baselines in benchmarks like TOFU\nand MUSE, and robustness against relearning attacks. Codes are available at\nhttps://github.com/OPTML-Group/Unlearn-Simple.", "paper_summary_zh": "\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u907a\u5fd8\u554f\u984c\uff0c\u65e8\u5728\u79fb\u9664\u4e0d\u9700\u8981\u7684\u8cc7\u6599\u5f71\u97ff\u548c\u76f8\u95dc\u7684\u6a21\u578b\u529f\u80fd\uff08\u4f8b\u5982\uff0c\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u8cc7\u6599\u6216\u6709\u5bb3\u5167\u5bb9\u7522\u751f\uff09\uff0c\u540c\u6642\u4fdd\u7559\u5fc5\u8981\u7684\u6a21\u578b\u5be6\u7528\u7a0b\u5f0f\uff0c\u800c\u7121\u9700\u5f9e\u982d\u958b\u59cb\u91cd\u65b0\u8a13\u7df4\u3002\u5118\u7ba1\u5c0d LLM \u907a\u5fd8\u7684\u9700\u6c42\u8d8a\u4f86\u8d8a\u5927\uff0c\u4f46\u4ecd\u7136\u7f3a\u4e4f\u4e00\u500b\u6709\u539f\u5247\u7684\u6700\u4f73\u5316\u67b6\u69cb\u3002\u70ba\u6b64\uff0c\u6211\u5011\u91cd\u65b0\u63a2\u8a0e\u4e86\u6700\u5148\u9032\u7684\u65b9\u6cd5\uff0c\u8ca0\u504f\u597d\u6700\u4f73\u5316 (NPO)\uff0c\u4e26\u627e\u51fa\u53c3\u8003\u6a21\u578b\u504f\u5dee\u7684\u554f\u984c\uff0c\u5b83\u53ef\u80fd\u6703\u7834\u58de NPO \u7684\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728\u907a\u5fd8\u4e0d\u540c\u96e3\u5ea6\u7684\u907a\u5fd8\u8cc7\u6599\u6642\u3002\u6709\u9451\u65bc\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u6709\u6548\u7684\u907a\u5fd8\u6700\u4f73\u5316\u67b6\u69cb\uff0c\u7a31\u70ba SimNPO\uff0c\u986f\u793a\u79fb\u9664\u5c0d\u53c3\u8003\u6a21\u578b\u7684\u4f9d\u8cf4\uff08\u900f\u904e\u7c21\u55ae\u504f\u597d\u6700\u4f73\u5316\u7684\u89c0\u9ede\uff09\u7684\u300c\u7c21\u55ae\u6027\u300d\u6709\u52a9\u65bc\u907a\u5fd8\u3002\u6211\u5011\u4e5f\u63d0\u4f9b\u4e86\u5c0d SimNPO \u512a\u9ede\u7684\u66f4\u6df1\u5165\u898b\u89e3\uff0c\u4e26\u4ee5\u4f7f\u7528\u99ac\u53ef\u592b\u93c8\u6df7\u5408\u7269\u7684\u5206\u6790\u4f5c\u70ba\u652f\u6301\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u9a57\u8b49\u4e86 SimNPO \u512a\u65bc\u73fe\u6709\u7684\u907a\u5fd8\u57fa\u6e96\uff0c\u4f8b\u5982 TOFU \u548c MUSE\uff0c\u4ee5\u53ca\u5c0d\u91cd\u65b0\u5b78\u7fd2\u653b\u64ca\u7684\u7a69\u5065\u6027\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/OPTML-Group/Unlearn-Simple \u53d6\u5f97\u3002", "author": "Chongyu Fan et.al.", "authors": "Chongyu Fan, Jiancheng Liu, Licong Lin, Jinghan Jia, Ruiqi Zhang, Song Mei, Sijia Liu", "id": "2410.07163v1", "paper_url": "http://arxiv.org/abs/2410.07163v1", "repo": "null"}}