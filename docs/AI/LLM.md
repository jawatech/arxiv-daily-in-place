
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-07**|**3D-GRAND: Towards Better Grounding and Less Hallucination for 3D-LLMs**|Jianing Yang et.al.|[2406.05132v1](http://arxiv.org/abs/2406.05132v1)|null|
|**2024-06-07**|**An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models**|Xiongtao Zhou et.al.|[2406.05130v1](http://arxiv.org/abs/2406.05130v1)|null|
|**2024-06-07**|**LLavaGuard: VLM-based Safeguards for Vision Dataset Curation and Safety Assessment**|Lukas Helff et.al.|[2406.05113v1](http://arxiv.org/abs/2406.05113v1)|null|
|**2024-06-07**|**Provably Better Explanations with Optimized Aggregation of Feature Attributions**|Thomas Decker et.al.|[2406.05090v1](http://arxiv.org/abs/2406.05090v1)|null|
|**2024-06-07**|**Robust Reward Design for Markov Decision Processes**|Shuo Wu et.al.|[2406.05086v1](http://arxiv.org/abs/2406.05086v1)|null|
|**2024-06-07**|**Multi-Head RAG: Solving Multi-Aspect Problems with LLMs**|Maciej Besta et.al.|[2406.05085v1](http://arxiv.org/abs/2406.05085v1)|[link](https://github.com/spcl/mrag)|
|**2024-06-07**|**On Ambiguity and the Expressive Function of Law: The Role of Pragmatics in Smart Legal Ecosystems**|Pompeu Casanovas et.al.|[2406.05084v1](http://arxiv.org/abs/2406.05084v1)|null|
|**2024-06-07**|**I2EDL: Interactive Instruction Error Detection and Localization**|Francesco Taioli et.al.|[2406.05080v1](http://arxiv.org/abs/2406.05080v1)|null|
|**2024-06-07**|**SUMIE: A Synthetic Benchmark for Incremental Entity Summarization**|Eunjeong Hwang et.al.|[2406.05079v1](http://arxiv.org/abs/2406.05079v1)|null|
|**2024-06-07**|**Classification Metrics for Image Explanations: Towards Building Reliable XAI-Evaluations**|Benjamin Fresz et.al.|[2406.05068v1](http://arxiv.org/abs/2406.05068v1)|[link](https://github.com/lelo204/classificationmetricsforimageexplanations)|
|**2024-06-07**|**Are Large Language Models More Empathetic than Humans?**|Anuradha Welivita et.al.|[2406.05063v1](http://arxiv.org/abs/2406.05063v1)|null|
|**2024-06-07**|**Robustness Assessment of Mathematical Reasoning in the Presence of Missing and Contradictory Conditions**|Shi-Yu Tian et.al.|[2406.05055v1](http://arxiv.org/abs/2406.05055v1)|null|
|**2024-06-07**|**Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation**|Nachiket Kotalwar et.al.|[2406.05053v1](http://arxiv.org/abs/2406.05053v1)|null|
|**2024-06-07**|**Bootstrapping Referring Multi-Object Tracking**|Yani Zhang et.al.|[2406.05039v1](http://arxiv.org/abs/2406.05039v1)|null|
|**2024-06-07**|**Efficient 3D Shape Generation via Diffusion Mamba with Bidirectional SSMs**|Shentong Mo et.al.|[2406.05038v1](http://arxiv.org/abs/2406.05038v1)|null|
|**2024-06-07**|**TimeSieve: Extracting Temporal Dynamics through Information Bottlenecks**|Ninghui Feng et.al.|[2406.05036v1](http://arxiv.org/abs/2406.05036v1)|[link](https://github.com/xll0328/timesieve)|
|**2024-06-07**|**Scenarios and Approaches for Situated Natural Language Explanations**|Pengshuo Qiu et.al.|[2406.05035v1](http://arxiv.org/abs/2406.05035v1)|null|
|**2024-06-07**|**Adaptively Learning to Select-Rank in Online Platforms**|Jingyuan Wang et.al.|[2406.05017v1](http://arxiv.org/abs/2406.05017v1)|null|
|**2024-06-07**|**Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study**|Deepa Tilwani et.al.|[2406.05002v1](http://arxiv.org/abs/2406.05002v1)|[link](https://github.com/lina-usc/jansen-rit-model-benchmarking-deep-learning)|
|**2024-06-07**|**ADBA:Approximation Decision Boundary Approach for Black-Box Adversarial Attacks**|Feiyang Wang et.al.|[2406.04998v1](http://arxiv.org/abs/2406.04998v1)|null|
|**2024-06-07**|**Compositional Generalization with Grounded Language Models**|Sondre Wold et.al.|[2406.04989v1](http://arxiv.org/abs/2406.04989v1)|null|
|**2024-06-07**|**Language models emulate certain cognitive profiles: An investigation of how predictability measures interact with individual differences**|Patrick Haller et.al.|[2406.04988v1](http://arxiv.org/abs/2406.04988v1)|null|
|**2024-06-07**|**MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter**|Jitai Hao et.al.|[2406.04984v1](http://arxiv.org/abs/2406.04984v1)|[link](https://github.com/currentf/meft)|
|**2024-06-07**|**UniTST: Effectively Modeling Inter-Series and Intra-Series Dependencies for Multivariate Time Series Forecasting**|Juncheng Liu et.al.|[2406.04975v1](http://arxiv.org/abs/2406.04975v1)|null|
|**2024-06-07**|**Neural Laplace for learning Stochastic Differential Equations**|Adrien Carrel et.al.|[2406.04964v1](http://arxiv.org/abs/2406.04964v1)|null|
|**2024-06-07**|**Learning Divergence Fields for Shift-Robust Graph Representations**|Qitian Wu et.al.|[2406.04963v1](http://arxiv.org/abs/2406.04963v1)|[link](https://github.com/fannie1208/glind)|
|**2024-06-07**|**Experimental Evaluation of ROS-Causal in Real-World Human-Robot Spatial Interaction Scenarios**|Luca Castri et.al.|[2406.04955v1](http://arxiv.org/abs/2406.04955v1)|null|
|**2024-06-07**|**Quantifying Geospatial in the Common Crawl Corpus**|Ilya Ilyankou et.al.|[2406.04952v1](http://arxiv.org/abs/2406.04952v1)|null|
|**2024-06-07**|**BAMO at SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense**|Baktash Ansari et.al.|[2406.04947v1](http://arxiv.org/abs/2406.04947v1)|null|
|**2024-06-07**|**TCMD: A Traditional Chinese Medicine QA Dataset for Evaluating Large Language Models**|Ping Yu et.al.|[2406.04941v1](http://arxiv.org/abs/2406.04941v1)|null|
|**2024-06-07**|**CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling**|Matthew Fortier et.al.|[2406.04940v1](http://arxiv.org/abs/2406.04940v1)|null|
|**2024-06-07**|**SpanGNN: Towards Memory-Efficient Graph Neural Networks via Spanning Subgraph Training**|Xizhi Gu et.al.|[2406.04938v1](http://arxiv.org/abs/2406.04938v1)|[link](https://github.com/guxizhi/spangnn)|
|**2024-06-07**|**Optimal Recurrent Network Topologies for Dynamical Systems Reconstruction**|Christoph Jürgen Hemmer et.al.|[2406.04934v1](http://arxiv.org/abs/2406.04934v1)|[link](https://github.com/durstewitzlab/rnntopodsr)|
|**2024-06-07**|**LLM-based speaker diarization correction: A generalizable approach**|Georgios Efstathiadis et.al.|[2406.04927v1](http://arxiv.org/abs/2406.04927v1)|null|
|**2024-06-07**|**Through the Thicket: A Study of Number-Oriented LLMs derived from Random Forest Models**|Michał Romaszewski et.al.|[2406.04926v1](http://arxiv.org/abs/2406.04926v1)|null|
|**2024-06-07**|**Online Adaptation for Enhancing Imitation Learning Policies**|Federico Malato et.al.|[2406.04913v1](http://arxiv.org/abs/2406.04913v1)|[link](https://github.com/fmalato/online_adaptation)|
|**2024-06-07**|**PolyLUT-Add: FPGA-based LUT Inference with Wide Inputs**|Binglei Lou et.al.|[2406.04910v1](http://arxiv.org/abs/2406.04910v1)|[link](https://github.com/bingleilou/PolyLUT-Add)|
|**2024-06-07**|**RU-AI: A Large Multimodal Dataset for Machine Generated Content Detection**|Liting Huang et.al.|[2406.04906v1](http://arxiv.org/abs/2406.04906v1)|[link](https://github.com/zhihaozhang97/ru-ai)|
|**2024-06-07**|**XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model**|Edresson Casanova et.al.|[2406.04904v1](http://arxiv.org/abs/2406.04904v1)|null|
|**2024-06-07**|**Sliding Window 3-Objective Pareto Optimization for Problems with Chance Constraints**|Frank Neumann et.al.|[2406.04899v1](http://arxiv.org/abs/2406.04899v1)|null|
|**2024-06-07**|**Sexism Detection on a Data Diet**|Rabiraj Bandyopadhyay et.al.|[2406.04892v1](http://arxiv.org/abs/2406.04892v1)|null|
|**2024-06-07**|**Enhancing Indoor Temperature Forecasting through Synthetic Data in Low-Data Environments**|Zachari Thiry et.al.|[2406.04890v1](http://arxiv.org/abs/2406.04890v1)|null|
|**2024-06-07**|**Seeing the Unseen: Visual Metaphor Captioning for Videos**|Abisek Rajakumar Kalarani et.al.|[2406.04886v1](http://arxiv.org/abs/2406.04886v1)|null|
|**2024-06-07**|**InstructNav: Zero-shot System for Generic Instruction Navigation in Unexplored Environment**|Yuxing Long et.al.|[2406.04882v1](http://arxiv.org/abs/2406.04882v1)|null|
|**2024-06-07**|**A Deep Dive into the Trade-Offs of Parameter-Efficient Preference Alignment Techniques**|Megh Thakkar et.al.|[2406.04879v1](http://arxiv.org/abs/2406.04879v1)|null|
|**2024-06-07**|**HateDebias: On the Diversity and Variability of Hate Speech Debiasing**|Nankai Lin et.al.|[2406.04876v1](http://arxiv.org/abs/2406.04876v1)|null|
|**2024-06-07**|**Ada-VE: Training-Free Consistent Video Editing Using Adaptive Motion Prior**|Tanvir Mahmud et.al.|[2406.04873v1](http://arxiv.org/abs/2406.04873v1)|null|
|**2024-06-07**|**Deep learning for precipitation nowcasting: A survey from the perspective of time series forecasting**|Sojung An et.al.|[2406.04867v1](http://arxiv.org/abs/2406.04867v1)|null|
|**2024-06-07**|**ComplexTempQA: A Large-Scale Dataset for Complex Temporal Question Answering**|Raphael Gruber et.al.|[2406.04866v1](http://arxiv.org/abs/2406.04866v1)|[link](https://github.com/datascienceuibk/complextempqa)|
|**2024-06-07**|**Uncertainty Aware Learning for Language Model Alignment**|Yikun Wang et.al.|[2406.04854v1](http://arxiv.org/abs/2406.04854v1)|null|
|**2024-06-07**|**Do Language Models Exhibit Human-like Structural Priming Effects?**|Jaap Jumelet et.al.|[2406.04847v1](http://arxiv.org/abs/2406.04847v1)|null|
|**2024-06-07**|**FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models**|Rui Ye et.al.|[2406.04845v1](http://arxiv.org/abs/2406.04845v1)|null|
|**2024-06-07**|**Algorithms for learning value-aligned policies considering admissibility relaxation**|Andrés Holgado-Sánchez et.al.|[2406.04838v1](http://arxiv.org/abs/2406.04838v1)|null|
|**2024-06-07**|**Revisiting Catastrophic Forgetting in Large Language Model Tuning**|Hongyu Li et.al.|[2406.04836v1](http://arxiv.org/abs/2406.04836v1)|null|
|**2024-06-07**|**Annotating FrameNet via Structure-Conditioned Language Generation**|Xinyue Cui et.al.|[2406.04834v1](http://arxiv.org/abs/2406.04834v1)|null|
|**2024-06-07**|**Graph Mining under Data scarcity**|Appan Rakaraddi et.al.|[2406.04825v1](http://arxiv.org/abs/2406.04825v1)|null|
|**2024-06-07**|**BERTs are Generative In-Context Learners**|David Samuel et.al.|[2406.04823v1](http://arxiv.org/abs/2406.04823v1)|[link](https://github.com/ltgoslo/bert-in-context)|
|**2024-06-07**|**Navigating Efficiency in MobileViT through Gaussian Process on Global Architecture Factors**|Ke Meng et.al.|[2406.04820v1](http://arxiv.org/abs/2406.04820v1)|null|
|**2024-06-07**|**Generating Piano Practice Policy with a Gaussian Process**|Alexandra Moringen et.al.|[2406.04812v1](http://arxiv.org/abs/2406.04812v1)|[link](https://github.com/jasonfriedman/piano_gp)|
|**2024-06-07**|**Fragile Model Watermarking: A Comprehensive Survey of Evolution, Characteristics, and Classification**|Zhenzhe Gao et.al.|[2406.04809v1](http://arxiv.org/abs/2406.04809v1)|null|
|**2024-06-07**|**TEDi Policy: Temporally Entangled Diffusion for Robotic Control**|Sigmund H. Høeg et.al.|[2406.04806v1](http://arxiv.org/abs/2406.04806v1)|null|
|**2024-06-07**|**Zero, Finite, and Infinite Belief History of Theory of Mind Reasoning in Large Language Models**|Weizhi Tang et.al.|[2406.04800v1](http://arxiv.org/abs/2406.04800v1)|null|
|**2024-06-07**|**Learning-Augmented Priority Queues**|Ziyad Benomar et.al.|[2406.04793v1](http://arxiv.org/abs/2406.04793v1)|null|
|**2024-06-07**|**SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals**|Ruihan Yang et.al.|[2406.04784v1](http://arxiv.org/abs/2406.04784v1)|null|
|**2024-06-07**|**Mobile Network Configuration Recommendation using Deep Generative Graph Neural Network**|Shirwan Piroti et.al.|[2406.04779v1](http://arxiv.org/abs/2406.04779v1)|null|
|**2024-06-07**|**REP: Resource-Efficient Prompting for On-device Continual Learning**|Sungho Jeon et.al.|[2406.04772v1](http://arxiv.org/abs/2406.04772v1)|null|
|**2024-06-07**|**WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild**|Bill Yuchen Lin et.al.|[2406.04770v1](http://arxiv.org/abs/2406.04770v1)|[link](https://github.com/allenai/wildbench)|
|**2024-06-07**|**Think out Loud: Emotion Deducing Explanation in Dialogues**|Jiangnan Li et.al.|[2406.04758v1](http://arxiv.org/abs/2406.04758v1)|null|
|**2024-06-07**|**Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations**|Weiran Lin et.al.|[2406.04755v1](http://arxiv.org/abs/2406.04755v1)|null|
|**2024-06-07**|**CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models**|Ling Shi et.al.|[2406.04752v1](http://arxiv.org/abs/2406.04752v1)|null|
|**2024-06-07**|**PQPP: A Joint Benchmark for Text-to-Image Prompt and Query Performance Prediction**|Eduard Poesina et.al.|[2406.04746v1](http://arxiv.org/abs/2406.04746v1)|[link](https://github.com/eduard6421/pqpp)|
|**2024-06-07**|**CRAG -- Comprehensive RAG Benchmark**|Xiao Yang et.al.|[2406.04744v1](http://arxiv.org/abs/2406.04744v1)|null|
|**2024-06-07**|**Generative AI Models: Opportunities and Risks for Industry and Authorities**|Tobias Alt et.al.|[2406.04734v1](http://arxiv.org/abs/2406.04734v1)|null|
|**2024-06-07**|**Probabilistic Perspectives on Error Minimization in Adversarial Reinforcement Learning**|Roman Belaire et.al.|[2406.04724v1](http://arxiv.org/abs/2406.04724v1)|null|
|**2024-06-07**|**FlowMM: Generating Materials with Riemannian Flow Matching**|Benjamin Kurt Miller et.al.|[2406.04713v1](http://arxiv.org/abs/2406.04713v1)|null|
|**2024-06-07**|**AICoderEval: Improving AI Domain Code Generation of Large Language Models**|Yinghui Xia et.al.|[2406.04712v1](http://arxiv.org/abs/2406.04712v1)|null|
|**2024-06-07**|**Morescient GAI for Software Engineering**|Marcus Kessel et.al.|[2406.04710v1](http://arxiv.org/abs/2406.04710v1)|null|
|**2024-06-07**|**Logic Synthesis with Generative Deep Neural Networks**|Xihan Li et.al.|[2406.04699v1](http://arxiv.org/abs/2406.04699v1)|null|
|**2024-06-07**|**LLM-Vectorizer: LLM-based Verified Loop Vectorizer**|Jubi Taneja et.al.|[2406.04693v1](http://arxiv.org/abs/2406.04693v1)|null|
|**2024-06-07**|**Mixture-of-Agents Enhances Large Language Model Capabilities**|Junlin Wang et.al.|[2406.04692v1](http://arxiv.org/abs/2406.04692v1)|null|
|**2024-06-07**|**MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models**|Sanjoy Chowdhury et.al.|[2406.04673v1](http://arxiv.org/abs/2406.04673v1)|null|
|**2024-06-07**|**The Reasonable Person Standard for AI**|Sunayana Rane et.al.|[2406.04671v1](http://arxiv.org/abs/2406.04671v1)|null|
|**2024-06-07**|**MATTER: Memory-Augmented Transformer Using Heterogeneous Knowledge Sources**|Dongkyu Lee et.al.|[2406.04670v1](http://arxiv.org/abs/2406.04670v1)|null|
|**2024-06-07**|**DiNeR: a Large Realistic Dataset for Evaluating Compositional Generalization**|Chengang Hu et.al.|[2406.04669v1](http://arxiv.org/abs/2406.04669v1)|[link](https://github.com/jumpy-pku/diner)|
|**2024-06-07**|**Advanced Payment Security System:XGBoost, CatBoost and SMOTE Integrated**|Qi Zheng et.al.|[2406.04658v1](http://arxiv.org/abs/2406.04658v1)|null|
|**2024-06-07**|**Crafting Heavy-Tails in Weight Matrix Spectrum without Gradient Noise**|Vignesh Kothapalli et.al.|[2406.04657v1](http://arxiv.org/abs/2406.04657v1)|null|
|**2024-06-07**|**More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play**|Wichayaporn Wongkamjan et.al.|[2406.04643v1](http://arxiv.org/abs/2406.04643v1)|null|
|**2024-06-07**|**Cooperative Meta-Learning with Gradient Augmentation**|Jongyun Shin et.al.|[2406.04639v1](http://arxiv.org/abs/2406.04639v1)|[link](https://github.com/jjongyn/cml)|
|**2024-06-07**|**Large Language Model-guided Document Selection**|Xiang Kong et.al.|[2406.04638v1](http://arxiv.org/abs/2406.04638v1)|null|
|**2024-06-07**|**Scaling Automatic Extraction of Pseudocode**|Levent Toksoz et.al.|[2406.04635v1](http://arxiv.org/abs/2406.04635v1)|null|
|**2024-06-07**|**Low-Resource Cross-Lingual Summarization through Few-Shot Learning with Large Language Models**|Gyutae Park et.al.|[2406.04630v1](http://arxiv.org/abs/2406.04630v1)|null|
|**2024-06-07**|**Denoising-Aware Contrastive Learning for Noisy Time Series**|Shuang Zhou et.al.|[2406.04627v1](http://arxiv.org/abs/2406.04627v1)|[link](https://github.com/betterzhou/DECL)|
|**2024-06-07**|**Key-Element-Informed sLLM Tuning for Document Summarization**|Sangwon Ryu et.al.|[2406.04625v1](http://arxiv.org/abs/2406.04625v1)|null|
|**2024-06-07**|**What do MLLMs hear? Examining reasoning with text and sound components in Multimodal Large Language Models**|Enis Berk Çoban et.al.|[2406.04615v1](http://arxiv.org/abs/2406.04615v1)|null|
|**2024-06-07**|**LawGPT: A Chinese Legal Knowledge-Enhanced Large Language Model**|Zhi Zhou et.al.|[2406.04614v1](http://arxiv.org/abs/2406.04614v1)|[link](https://github.com/pengxiao-song/lawgpt)|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-07**|**Diverse Intra- and Inter-Domain Activity Style Fusion for Cross-Person Generalization in Activity Recognition**|Junru Zhang et.al.|[2406.04609v1](http://arxiv.org/abs/2406.04609v1)|null|
|**2024-06-07**|**MeGA: Merging Multiple Independently Trained Neural Networks Based on Genetic Algorithm**|Daniel Yun et.al.|[2406.04607v1](http://arxiv.org/abs/2406.04607v1)|[link](https://github.com/yunblak/mega-merging-multiple-independently-trained-neural-networks-based-on-genetic-algorithm)|
|**2024-06-07**|**Helpful or Harmful Data? Fine-tuning-free Shapley Attribution for Explaining Language Model Predictions**|Jingtan Wang et.al.|[2406.04606v1](http://arxiv.org/abs/2406.04606v1)|[link](https://github.com/jtwang2000/freeshap)|
|**2024-06-07**|**Learning Task Decomposition to Assist Humans in Competitive Programming**|Jiaxin Wen et.al.|[2406.04604v1](http://arxiv.org/abs/2406.04604v1)|null|

#### Abstracts
##### **3D-GRAND: Towards Better Grounding and Less Hallucination for 3D-LLMs**
2406.05132v1 by Jianing Yang, Xuweiyi Chen, Nikhil Madaan, Madhavan Iyengar, Shengyi Qian, David F. Fouhey, Joyce Chai

The integration of language and 3D perception is crucial for developing
embodied agents and robots that comprehend and interact with the physical
world. While large language models (LLMs) have demonstrated impressive language
understanding and generation capabilities, their adaptation to 3D environments
(3D-LLMs) remains in its early stages. A primary challenge is the absence of
large-scale datasets that provide dense grounding between language and 3D
scenes. In this paper, we introduce 3D-GRAND, a pioneering large-scale dataset
comprising 40,087 household scenes paired with 6.2 million densely-grounded
scene-language instructions. Our results show that instruction tuning with
3D-GRAND significantly enhances grounding capabilities and reduces
hallucinations in 3D-LLMs. As part of our contributions, we propose a
comprehensive benchmark 3D-POPE to systematically evaluate hallucination in
3D-LLMs, enabling fair comparisons among future models. Our experiments
highlight a scaling effect between dataset size and 3D-LLM performance,
emphasizing the critical role of large-scale 3D-text datasets in advancing
embodied AI research. Notably, our results demonstrate early signals for
effective sim-to-real transfer, indicating that models trained on large
synthetic data can perform well on real-world 3D scans. Through 3D-GRAND and
3D-POPE, we aim to equip the embodied AI community with essential resources and
insights, setting the stage for more reliable and better-grounded 3D-LLMs.
Project website: https://3d-grand.github.io

摘要：語言和 3D 感知的整合對於開發理解並與物理世界互動的具身代理和機器人至關重要。雖然大型語言模型 (LLM) 已展現出令人印象深刻的語言理解和生成能力，但它們對 3D 環境 (3D-LLM) 的適應仍處於早期階段。一個主要的挑戰是缺乏提供語言和 3D 場景之間密集基礎的大規模資料集。在本文中，我們介紹了 3D-GRAND，一個由 40,087 個家庭場景配對 620 萬個密集基礎場景語言指令組成的開創性大型資料集。我們的結果表明，使用 3D-GRAND 進行指令調整顯著增強了基礎能力，並減少了 3D-LLM 中的幻覺。作為我們貢獻的一部分，我們提出了一個全面的基準 3D-POPE，以系統地評估 3D-LLM 中的幻覺，使未來的模型之間能夠進行公平的比較。我們的實驗強調了資料集大小和 3D-LLM 性能之間的規模效應，強調了大規模 3D-text 資料集在推進具身 AI 研究中的關鍵作用。值得注意的是，我們的結果展示了有效模擬到真實傳輸的早期信號，表明在大型合成資料上訓練的模型可以在真實世界的 3D 掃描中表現良好。透過 3D-GRAND 和 3D-POPE，我們旨在為具身 AI 社群提供必要的資源和見解，為更可靠且基礎更好的 3D-LLM 奠定基礎。專案網站：https://3d-grand.github.io

##### **An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models**
2406.05130v1 by Xiongtao Zhou, Jie He, Yuhua Ke, Guangyao Zhu, Víctor Gutiérrez-Basulto, Jeff Z. Pan

Multimodal large language models (MLLMs) fine-tuned with multimodal
instruction datasets have demonstrated remarkable capabilities in multimodal
tasks. However, fine-tuning all parameters of MLLMs has become challenging as
they usually contain billions of parameters. To address this issue, we study
parameter-efficient fine-tuning (PEFT) methods for MLLMs. We aim to identify
effective methods for enhancing the performance of MLLMs in scenarios where
only a limited number of parameters are trained. This paper conducts empirical
studies using four popular PEFT methods to fine-tune the LLM component of
open-source MLLMs. We present a comprehensive analysis that encompasses various
aspects, including the impact of PEFT methods on various models, parameters and
location of the PEFT module, size of fine-tuning data, model stability based on
PEFT methods, MLLM's generalization, and hallucination. We evaluated four PEFT
methods on seven datasets from two different categories: unseen and seen
datasets. Across all experiments, we show that the adapter is the
best-performing PEFT method. At the same time, fine-tuning the connector layers
leads to improved performance in most MLLMs. Code and data are available at
https://github.com/alenai97/PEFT-MLLM.git.

摘要：多模态大型语言模型 (MLLM) 经过多模态指令数据集的微调，在多模态任务中表现出非凡的能力。然而，微调 MLLM 的所有参数已变得具有挑战性，因为它们通常包含数十亿个参数。为了解决这个问题，我们研究了 MLLM 的参数高效微调 (PEFT) 方法。我们的目标是找出在仅训练有限数量参数的情况下增强 MLLM 性能的有效方法。本文使用四种流行的 PEFT 方法对开源 MLLM 的 LLM 组件进行微调，并进行了实证研究。我们提出了一个全面的分析，涵盖各个方面，包括 PEFT 方法对各种模型、参数和 PEFT 模块的位置、微调数据的大小、基于 PEFT 方法的模型稳定性、MLLM 的泛化和幻觉的影响。我们对来自两个不同类别的七个数据集（看不见的数据集和可见数据集）评估了四种 PEFT 方法。在所有实验中，我们表明适配器是性能最好的 PEFT 方法。同时，微调连接层会导致大多数 MLLM 的性能提高。代码和数据可在 https://github.com/alenai97/PEFT-MLLM.git 获得。

##### **LLavaGuard: VLM-based Safeguards for Vision Dataset Curation and Safety Assessment**
2406.05113v1 by Lukas Helff, Felix Friedrich, Manuel Brack, Kristian Kersting, Patrick Schramowski

We introduce LlavaGuard, a family of VLM-based safeguard models, offering a
versatile framework for evaluating the safety compliance of visual content.
Specifically, we designed LlavaGuard for dataset annotation and generative
model safeguarding. To this end, we collected and annotated a high-quality
visual dataset incorporating a broad safety taxonomy, which we use to tune VLMs
on context-aware safety risks. As a key innovation, LlavaGuard's new responses
contain comprehensive information, including a safety rating, the violated
safety categories, and an in-depth rationale. Further, our introduced
customizable taxonomy categories enable the context-specific alignment of
LlavaGuard to various scenarios. Our experiments highlight the capabilities of
LlavaGuard in complex and real-world applications. We provide checkpoints
ranging from 7B to 34B parameters demonstrating state-of-the-art performance,
with even the smallest models outperforming baselines like GPT-4. We make our
dataset and model weights publicly available and invite further research to
address the diverse needs of communities and contexts.

摘要：我們介紹 LlavaGuard，一個基於 VLM 的保障模型家族，提供了一個多功能框架，用於評估視覺內容的安全性合規性。具體來說，我們設計 LlavaGuard 用於資料集註解和生成模型保障。為此，我們收集並註解了一個包含廣泛安全分類法的高品質視覺資料集，我們使用它來調整 VLM 以應對與情境相關的安全風險。作為一項關鍵創新，LlavaGuard 的新回應包含綜合資訊，包括安全評級、違規的安全類別和深入的依據。此外，我們引入的可自訂分類法類別能讓 LlavaGuard 與各種情境進行情境特定的比對。我們的實驗突顯了 LlavaGuard 在複雜和真實世界應用中的能力。我們提供從 7B 到 34B 參數的檢查點，展示了最先進的效能，即使是最小的模型也優於 GPT-4 等基準。我們公開我們的資料集和模型權重，並邀請進一步的研究，以滿足社群和情境的各種需求。

##### **Provably Better Explanations with Optimized Aggregation of Feature Attributions**
2406.05090v1 by Thomas Decker, Ananta R. Bhattarai, Jindong Gu, Volker Tresp, Florian Buettner

Using feature attributions for post-hoc explanations is a common practice to
understand and verify the predictions of opaque machine learning models.
Despite the numerous techniques available, individual methods often produce
inconsistent and unstable results, putting their overall reliability into
question. In this work, we aim to systematically improve the quality of feature
attributions by combining multiple explanations across distinct methods or
their variations. For this purpose, we propose a novel approach to derive
optimal convex combinations of feature attributions that yield provable
improvements of desired quality criteria such as robustness or faithfulness to
the model behavior. Through extensive experiments involving various model
architectures and popular feature attribution techniques, we demonstrate that
our combination strategy consistently outperforms individual methods and
existing baselines.

摘要：使用特徵歸因進行事後解釋是理解和驗證不透明機器學習模型預測的常見做法。儘管有許多可用技術，但個別方法通常會產生不一致且不穩定的結果，對其整體可靠性提出質疑。在這項工作中，我們旨在透過結合跨不同方法或其變異的各種解釋，系統性地提升特徵歸因的品質。為此，我們提出了一種新穎的方法，用於推導特徵歸因的最佳凸組合，從而產生可證明地改善期望品質標準（例如對模型行為的穩健性或忠實度）。透過涉及各種模型架構和流行特徵歸因技術的廣泛實驗，我們證明我們的組合策略始終優於個別方法和現有基準。

##### **Robust Reward Design for Markov Decision Processes**
2406.05086v1 by Shuo Wu, Haoxiang Ma, Jie Fu, Shuo Han

The problem of reward design examines the interaction between a leader and a
follower, where the leader aims to shape the follower's behavior to maximize
the leader's payoff by modifying the follower's reward function. Current
approaches to reward design rely on an accurate model of how the follower
responds to reward modifications, which can be sensitive to modeling
inaccuracies. To address this issue of sensitivity, we present a solution that
offers robustness against uncertainties in modeling the follower, including 1)
how the follower breaks ties in the presence of nonunique best responses, 2)
inexact knowledge of how the follower perceives reward modifications, and 3)
bounded rationality of the follower. Our robust solution is guaranteed to exist
under mild conditions and can be obtained numerically by solving a
mixed-integer linear program. Numerical experiments on multiple test cases
demonstrate that our solution improves robustness compared to the standard
approach without incurring significant additional computing costs.

摘要：獎勵設計問題探討領導者與追隨者之間的互動，其中領導者旨在透過修改追隨者的獎勵功能來塑造追隨者的行為，以最大化領導者的報酬。目前獎勵設計的方法依賴於追隨者如何回應獎勵修改的準確模型，而這可能會受到建模不準確的影響。為了解決這個敏感性問題，我們提出了一個解決方案，它提供對追隨者建模的不確定性具有穩健性，包括 1) 追隨者在存在非唯一最佳回應時如何打破平手，2) 對追隨者如何感知獎勵修改的不準確知識，以及 3) 追隨者的有限理性。我們的穩健解決方案保證在溫和的條件下存在，並且可以通過求解混合整數線性規劃來數值獲得。在多個測試案例上的數值實驗表明，我們的解決方案與標準方法相比提高了穩健性，而不會產生顯著的額外計算成本。

##### **Multi-Head RAG: Solving Multi-Aspect Problems with LLMs**
2406.05085v1 by Maciej Besta, Ales Kubicek, Roman Niggli, Robert Gerstenberger, Lucas Weitzendorf, Mingyuan Chi, Patrick Iff, Joanna Gajda, Piotr Nyczyk, Jürgen Müller, Hubert Niewiadomski, Marcin Chrapek, Michał Podstawski, Torsten Hoefler

Retrieval Augmented Generation (RAG) enhances the abilities of Large Language
Models (LLMs) by enabling the retrieval of documents into the LLM context to
provide more accurate and relevant responses. Existing RAG solutions do not
focus on queries that may require fetching multiple documents with
substantially different contents. Such queries occur frequently, but are
challenging because the embeddings of these documents may be distant in the
embedding space, making it hard to retrieve them all. This paper introduces
Multi-Head RAG (MRAG), a novel scheme designed to address this gap with a
simple yet powerful idea: leveraging activations of Transformer's multi-head
attention layer, instead of the decoder layer, as keys for fetching
multi-aspect documents. The driving motivation is that different attention
heads can learn to capture different data aspects. Harnessing the corresponding
activations results in embeddings that represent various facets of data items
and queries, improving the retrieval accuracy for complex queries. We provide
an evaluation methodology and metrics, synthetic datasets, and real-world use
cases to demonstrate MRAG's effectiveness, showing improvements of up to 20% in
relevance over standard RAG baselines. MRAG can be seamlessly integrated with
existing RAG frameworks and benchmarking tools like RAGAS as well as different
classes of data stores.

摘要：檢索增強生成（RAG）透過將文件檢索至 LLM 背景中，加強大型語言模型（LLM）的能力，提供更準確且相關的回應。現有的 RAG 解決方案並未專注於可能需要擷取多個文件且內容差異極大的查詢。此類查詢時常發生，但具有挑戰性，因為這些文件的內嵌可能在內嵌空間中相距甚遠，使得難以全部檢索。本文介紹多頭 RAG（MRAG），這是一種新穎的架構，旨在透過一個簡單而強大的概念來解決此差距：利用 Transformer 多頭注意層的活化，而非解碼器層，作為擷取多面向文件的金鑰。其驅動力是不同的注意頭部可以學習擷取不同的資料面向。利用對應的活化會產生表示資料項目和查詢的各種面向的內嵌，進而提升複雜查詢的檢索準確性。我們提供評估方法和指標、合成資料集，以及實際使用案例，以展示 MRAG 的效能，顯示與標準 RAG 基準相比，相關性提升幅度最高可達 20%。MRAG 可以無縫整合至現有的 RAG 架構和基準工具，例如 RAGAS，以及不同的資料儲存類別。

##### **On Ambiguity and the Expressive Function of Law: The Role of Pragmatics in Smart Legal Ecosystems**
2406.05084v1 by Pompeu Casanovas

This is a long paper, an essay, on ambiguity, pragmatics, legal ecosystems,
and the expressive function of law. It is divided into two parts and fifteen
sections. The first part (Pragmatics) addresses ambiguity from the perspective
of linguistic and cognitive pragmatics in the legal field. The second part
(Computing) deals with this issue from the point of view of human-centered
design and artificial intelligence, specifically focusing on the notion and
modelling of rules and what it means to comply with the rules. This is
necessary for the scaffolding of smart legal ecosystems (SLE). I will develop
this subject with the example of the architecture, information flows, and smart
ecosystem of OPTIMAI, an EU project of Industry 4.0 for zero-defect
manufacturing (Optimizing Manufacturing Processes through Artificial
Intelligence and Virtualization).

摘要：這是一篇關於模稜兩可、語用學、法律生態系統和法律的表達功能的長篇論文和散文。它分為兩部分和十五個部分。第一部分（語用學）從法律領域的語言學和認知語用學角度探討了模稜兩可性。第二部分（運算）從以人為中心的設計和人工智能的角度處理這個問題，特別關注規則的概念和建模以及遵守規則的含義。這對於構建智慧法律生態系統 (SLE) 是必要的。我將以歐盟工業 4.0 專案 OPTIMAI 的架構、資訊流和智慧生態系統為例來探討這個主題，該專案透過人工智慧和虛擬化來最佳化製造流程，以達成零缺陷製造。

##### **I2EDL: Interactive Instruction Error Detection and Localization**
2406.05080v1 by Francesco Taioli, Stefano Rosa, Alberto Castellini, Lorenzo Natale, Alessio Del Bue, Alessandro Farinelli, Marco Cristani, Yiming Wang

In the Vision-and-Language Navigation in Continuous Environments (VLN-CE)
task, the human user guides an autonomous agent to reach a target goal via a
series of low-level actions following a textual instruction in natural
language. However, most existing methods do not address the likely case where
users may make mistakes when providing such instruction (e.g. "turn left"
instead of "turn right"). In this work, we address a novel task of Interactive
VLN in Continuous Environments (IVLN-CE), which allows the agent to interact
with the user during the VLN-CE navigation to verify any doubts regarding the
instruction errors. We propose an Interactive Instruction Error Detector and
Localizer (I2EDL) that triggers the user-agent interaction upon the detection
of instruction errors during the navigation. We leverage a pre-trained module
to detect instruction errors and pinpoint them in the instruction by
cross-referencing the textual input and past observations. In such way, the
agent is able to query the user for a timely correction, without demanding the
user's cognitive load, as we locate the probable errors to a precise part of
the instruction. We evaluate the proposed I2EDL on a dataset of instructions
containing errors, and further devise a novel metric, the Success weighted by
Interaction Number (SIN), to reflect both the navigation performance and the
interaction effectiveness. We show how the proposed method can ask focused
requests for corrections to the user, which in turn increases the navigation
success, while minimizing the interactions.

摘要：<paragraph>在連續環境中進行視覺與語言導航 (VLN-CE) 任務時，人類使用者會透過一系列低層級動作來引導自主代理程式，以達成目標，並遵循自然語言中的文字說明。然而，現有的方法大多未處理使用者在提供說明時可能犯錯的情況 (例如：「左轉」而非「右轉」)。在這項工作中，我們處理了連續環境中的互動式 VLN (IVLN-CE) 這項新任務，讓代理程式可以在 VLN-CE 導航過程中與使用者互動，以驗證說明錯誤的任何疑慮。我們提出互動式說明錯誤偵測器和定位器 (I2EDL)，它會在導航過程中偵測到說明錯誤時觸發使用者與代理程式的互動。我們利用預先訓練的模組來偵測說明錯誤，並透過交叉參照文字輸入和過去的觀察結果，將說明中的錯誤精確指出。如此一來，代理程式就能在不增加使用者認知負擔的情況下，向使用者查詢及時更正，因為我們將可能的錯誤定位在說明的精確部分。我們在包含錯誤的說明資料集上評估所提出的 I2EDL，並進一步設計出新的指標，即依互動次數加權的成功率 (SIN)，以反映導航效能和互動成效。我們展示所提出的方法如何向使用者提出有針對性的更正請求，進而提高導航成功率，同時將互動次數降到最低。</paragraph>

##### **SUMIE: A Synthetic Benchmark for Incremental Entity Summarization**
2406.05079v1 by Eunjeong Hwang, Yichao Zhou, Beliz Gunel, James Bradley Wendt, Sandeep Tata

No existing dataset adequately tests how well language models can
incrementally update entity summaries - a crucial ability as these models
rapidly advance. The Incremental Entity Summarization (IES) task is vital for
maintaining accurate, up-to-date knowledge. To address this, we introduce
SUMIE, a fully synthetic dataset designed to expose real-world IES challenges.
This dataset effectively highlights problems like incorrect entity association
and incomplete information presentation. Unlike common synthetic datasets, ours
captures the complexity and nuances found in real-world data. We generate
informative and diverse attributes, summaries, and unstructured paragraphs in
sequence, ensuring high quality. The alignment between generated summaries and
paragraphs exceeds 96%, confirming the dataset's quality. Extensive experiments
demonstrate the dataset's difficulty - state-of-the-art LLMs struggle to update
summaries with an F1 higher than 80.4%. We will open source the benchmark and
the evaluation metrics to help the community make progress on IES tasks.

摘要：現有資料集並未充分測試語言模型在何種程度上能逐步更新實體摘要，而這項能力對於這些模型的快速進步至關重要。逐步實體摘要 (IES) 任務對於維護準確、最新的知識至關重要。為了解決這個問題，我們引進了 SUMIE，這是一個完全合成的資料集，旨在揭露真實世界的 IES 挑戰。此資料集有效突出了不正確的實體關聯和不完整的資訊呈現等問題。與常見的合成資料集不同，我們的資料集捕捉到了真實世界資料中的複雜性和細微差別。我們依序產生有意義且多樣化的屬性、摘要和非結構化段落，以確保高品質。產生的摘要和段落之間的對齊度超過 96%，確認了該資料集的品質。廣泛的實驗證明了資料集的難度 - 最先進的 LLM 難以更新 F1 高於 80.4% 的摘要。我們將開放基準測試和評估指標的原始碼，以協助社群在 IES 任務上取得進展。

##### **Classification Metrics for Image Explanations: Towards Building Reliable XAI-Evaluations**
2406.05068v1 by Benjamin Fresz, Lena Lörcher, Marco Huber

Decision processes of computer vision models - especially deep neural
networks - are opaque in nature, meaning that these decisions cannot be
understood by humans. Thus, over the last years, many methods to provide
human-understandable explanations have been proposed. For image classification,
the most common group are saliency methods, which provide (super-)pixelwise
feature attribution scores for input images. But their evaluation still poses a
problem, as their results cannot be simply compared to the unknown ground
truth. To overcome this, a slew of different proxy metrics have been defined,
which are - as the explainability methods themselves - often built on intuition
and thus, are possibly unreliable. In this paper, new evaluation metrics for
saliency methods are developed and common saliency methods are benchmarked on
ImageNet. In addition, a scheme for reliability evaluation of such metrics is
proposed that is based on concepts from psychometric testing. The used code can
be found at
https://github.com/lelo204/ClassificationMetricsForImageExplanations .

摘要：電腦視覺模型的決策過程，尤其是深度神經網路，本質上是不透明的，表示人類無法理解這些決策。因此，在過去幾年中，已經提出了許多提供人類可理解的解釋方法。對於影像分類，最常見的群組是顯著性方法，它提供輸入影像的（超）像素級特徵歸因分數。但其評估仍是一個問題，因為其結果無法簡單地與未知的真實情況進行比較。為了克服這個問題，已經定義了一系列不同的代理指標，這些指標與可解釋性方法本身一樣，通常建立在直覺之上，因此可能不可靠。在本文中，開發了顯著性方法的新評估指標，並在 ImageNet 上對常見的顯著性方法進行了基準測試。此外，還提出了一種基於心理測驗概念的此類指標的可靠性評估方案。使用的程式碼可以在 https://github.com/lelo204/ClassificationMetricsForImageExplanations 找到。

##### **Are Large Language Models More Empathetic than Humans?**
2406.05063v1 by Anuradha Welivita, Pearl Pu

With the emergence of large language models (LLMs), investigating if they can
surpass humans in areas such as emotion recognition and empathetic responding
has become a focal point of research. This paper presents a comprehensive study
exploring the empathetic responding capabilities of four state-of-the-art LLMs:
GPT-4, LLaMA-2-70B-Chat, Gemini-1.0-Pro, and Mixtral-8x7B-Instruct in
comparison to a human baseline. We engaged 1,000 participants in a
between-subjects user study, assessing the empathetic quality of responses
generated by humans and the four LLMs to 2,000 emotional dialogue prompts
meticulously selected to cover a broad spectrum of 32 distinct positive and
negative emotions. Our findings reveal a statistically significant superiority
of the empathetic responding capability of LLMs over humans. GPT-4 emerged as
the most empathetic, marking approximately 31% increase in responses rated as
"Good" compared to the human benchmark. It was followed by LLaMA-2,
Mixtral-8x7B, and Gemini-Pro, which showed increases of approximately 24%, 21%,
and 10% in "Good" ratings, respectively. We further analyzed the response
ratings at a finer granularity and discovered that some LLMs are significantly
better at responding to specific emotions compared to others. The suggested
evaluation framework offers a scalable and adaptable approach for assessing the
empathy of new LLMs, avoiding the need to replicate this study's findings in
future research.

摘要：<paragraph>隨著大型語言模型 (LLM) 的出現，探討它們是否能在情緒辨識和同理回應等領域超越人類已成為研究重點。本文提出了一項綜合性研究，探討四種最先進的 LLM 的同理回應能力：GPT-4、LLaMA-2-70B-Chat、Gemini-1.0-Pro 和 Mixtral-8x7B-Instruct，並將它們與人類基準進行比較。我們在一個受試者間用戶研究中聘請了 1,000 名參與者，評估人類和四種 LLM 對 2,000 個情緒對話提示所產生的回應的同理品質，這些提示經過精心挑選，涵蓋了 32 種不同的正面和負面情緒。我們的研究結果顯示，LLM 的同理回應能力在統計上顯著優於人類。GPT-4 脫穎而出，成為最具同理心的，與人類基準相比，被評為「好」的回應增加了約 31%。其次是 LLaMA-2、Mixtral-8x7B 和 Gemini-Pro，它們的「好」評分分別增加了約 24%、21% 和 10%。我們進一步分析了回應評分，發現有些 LLM 在回應特定情緒方面顯著優於其他 LLM。建議的評估架構提供了一個可擴充且可適應的方法來評估新 LLM 的同理心，避免在未來的研究中複製本研究的發現。</paragraph>

##### **Robustness Assessment of Mathematical Reasoning in the Presence of Missing and Contradictory Conditions**
2406.05055v1 by Shi-Yu Tian, Zhi Zhou, Lin-Han Jia, Lan-Zhe Guo, Yu-Feng Li

Large language models (LLMs) have demonstrated impressive performance on
reasoning tasks, which can be further improved through few-shot prompting
techniques. However, the current evaluation primarily focuses on carefully
constructed benchmarks and neglects the consideration of real-world reasoning
problems that present missing and contradictory conditions, known as
ill-defined problems. Our observations suggest that existing few-shot prompting
techniques are ineffective in such scenarios, often providing overconfident
answers or hallucination. To further study this problem, we develop a benchmark
called Problems with Missing and Contradictory conditions (PMC) and introduce
two novel metrics to evaluate the performance of few-shot prompting methods in
these scenarios. Our analysis using the PMC benchmark reveals a trade-off
dilemma between the performance of mathematical reasoning for well-defined
problems and the ability to recognize ill-defined problems. To address the
challenges posed by PMC, we propose a novel few-shot prompting method called
SMT-LIB Prompting (SLP), which utilizes the SMT-LIB language to model the
problems instead of solving them directly. Subsequently, a double-check solving
strategy checks the satisfiability and uniqueness of the solution and provides
final feedback. Extensive experiments demonstrate the superiority of our SLP
approach compared to existing few-shot prompting methods when dealing with
problems with missing and contradictory conditions. We will open-source our
benchmark and code to facilitate future research.

摘要：大型語言模型 (LLM) 在推理任務中表現出令人印象深刻的效能，這可以用少量提示技術進一步改善。然而，目前的評估主要集中在仔細建構的基準上，而忽略了對現實世界推理問題的考量，這些問題會出現遺漏和矛盾的條件，稱為定義不明確的問題。我們的觀察結果表明，現有的少量提示技術在這種情況下是無效的，通常會提供過於自信的答案或幻覺。為了進一步研究這個問題，我們開發了一個名為「遺漏和矛盾條件問題」(PMC) 的基準，並引入了兩個新指標來評估在這些情況下少量提示方法的效能。我們使用 PMC 基準進行的分析揭示了針對定義明確的問題進行數學推理的效能與辨識定義不明確問題的能力之間的權衡困境。為了應對 PMC 造成的挑戰，我們提出了一種稱為 SMT-LIB 提示 (SLP) 的新少量提示方法，它利用 SMT-LIB 語言對問題進行建模，而不是直接解決它們。隨後，雙重檢查求解策略會檢查解的可滿足性和唯一性，並提供最終回饋。廣泛的實驗證明，與現有的少量提示方法相比，我們的 SLP 方法在處理遺漏和矛盾條件的問題時具有優越性。我們將開放原始碼我們的基準和程式碼，以利未來的研究。

##### **Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation**
2406.05053v1 by Nachiket Kotalwar, Alkis Gotovos, Adish Singla

Generative AI and large language models hold great promise in enhancing
programming education by generating individualized feedback and hints for
learners. Recent works have primarily focused on improving the quality of
generated feedback to achieve human tutors' quality. While quality is an
important performance criterion, it is not the only criterion to optimize for
real-world educational deployments. In this paper, we benchmark language models
for programming feedback generation across several performance criteria,
including quality, cost, time, and data privacy. The key idea is to leverage
recent advances in the new paradigm of in-browser inference that allow running
these models directly in the browser, thereby providing direct benefits across
cost and data privacy. To boost the feedback quality of small models compatible
with in-browser inference engines, we develop a fine-tuning pipeline based on
GPT-4 generated synthetic data. We showcase the efficacy of fine-tuned
Llama3-8B and Phi3-3.8B 4-bit quantized models using WebLLM's in-browser
inference engine on three different Python programming datasets. We will
release the full implementation along with a web app and datasets to facilitate
further research on in-browser language models.

摘要：生成式 AI 和大型语言模型在通过为学习者生成个性化反馈和提示，从而增强编程教育方面具有巨大的潜力。最近的研究主要集中于提高生成反馈的质量，以达到人类导师的质量。虽然质量是一个重要的性能标准，但它并不是现实世界教育部署中唯一需要优化的标准。在本文中，我们根据几个性能标准对用于编程反馈生成的语言模型进行了基准测试，包括质量、成本、时间和数据隐私。关键思想是利用浏览器内推理新范式的最新进展，该进展允许直接在浏览器中运行这些模型，从而在成本和数据隐私方面提供直接的好处。为了提高与浏览器内推理引擎兼容的小模型的反馈质量，我们基于 GPT-4 生成的合成数据开发了一个微调管道。我们展示了使用 WebLLM 的浏览器内推理引擎在三个不同的 Python 编程数据集上微调过的 Llama3-8B 和 Phi3-3.8B 4 位量化模型的功效。我们将发布完整的实现以及一个 web 应用程序和数据集，以促进对浏览器内语言模型的进一步研究。

##### **Bootstrapping Referring Multi-Object Tracking**
2406.05039v1 by Yani Zhang, Dongming Wu, Wencheng Han, Xingping Dong

Referring multi-object tracking (RMOT) aims at detecting and tracking
multiple objects following human instruction represented by a natural language
expression. Existing RMOT benchmarks are usually formulated through manual
annotations, integrated with static regulations. This approach results in a
dearth of notable diversity and a constrained scope of implementation. In this
work, our key idea is to bootstrap the task of referring multi-object tracking
by introducing discriminative language words as much as possible. In specific,
we first develop Refer-KITTI into a large-scale dataset, named Refer-KITTI-V2.
It starts with 2,719 manual annotations, addressing the issue of class
imbalance and introducing more keywords to make it closer to real-world
scenarios compared to Refer-KITTI. They are further expanded to a total of
9,758 annotations by prompting large language models, which create 617
different words, surpassing previous RMOT benchmarks. In addition, the
end-to-end framework in RMOT is also bootstrapped by a simple yet elegant
temporal advancement strategy, which achieves better performance than previous
approaches. The source code and dataset is available at
https://github.com/zyn213/TempRMOT.

摘要：多目標追蹤（RMOT）旨在偵測和追蹤多個目標，並遵循以自然語言表達的人類指令。現有的 RMOT 基準通常透過手動註解制定，並與靜態法規整合。此方法導致顯著的多樣性不足，且實作範圍受限。在這項工作中，我們的關鍵想法是盡可能引入有區別的語言詞彙，以啟動多目標追蹤任務。具體來說，我們首先將 Refer-KITTI 開發成一個大規模資料集，命名為 Refer-KITTI-V2。它從 2,719 個手動註解開始，解決類別不平衡的問題，並引入更多關鍵字，以使其與現實世界場景更接近，而這也是 Refer-KITTI 所沒有的。它們進一步擴展到總共 9,758 個註解，透過提示大型語言模型，創造出 617 個不同的詞彙，超越先前的 RMOT 基準。此外，RMOT 中的端到端架構也透過一個簡單但優雅的時間推進策略啟動，其效能優於先前的做法。原始碼和資料集可在 https://github.com/zyn213/TempRMOT 取得。

##### **Efficient 3D Shape Generation via Diffusion Mamba with Bidirectional SSMs**
2406.05038v1 by Shentong Mo

Recent advancements in sequence modeling have led to the development of the
Mamba architecture, noted for its selective state space approach, offering a
promising avenue for efficient long sequence handling. However, its application
in 3D shape generation, particularly at high resolutions, remains
underexplored. Traditional diffusion transformers (DiT) with self-attention
mechanisms, despite their potential, face scalability challenges due to the
cubic complexity of attention operations as input length increases. This
complexity becomes a significant hurdle when dealing with high-resolution voxel
sizes. To address this challenge, we introduce a novel diffusion architecture
tailored for 3D point clouds generation-Diffusion Mamba (DiM-3D). This
architecture forgoes traditional attention mechanisms, instead utilizing the
inherent efficiency of the Mamba architecture to maintain linear complexity
with respect to sequence length. DiM-3D is characterized by fast inference
times and substantially lower computational demands, quantified in reduced
Gflops, thereby addressing the key scalability issues of prior models. Our
empirical results on the ShapeNet benchmark demonstrate that DiM-3D achieves
state-of-the-art performance in generating high-fidelity and diverse 3D shapes.
Additionally, DiM-3D shows superior capabilities in tasks like 3D point cloud
completion. This not only proves the model's scalability but also underscores
its efficiency in generating detailed, high-resolution voxels necessary for
advanced 3D shape modeling, particularly excelling in environments requiring
high-resolution voxel sizes. Through these findings, we illustrate the
exceptional scalability and efficiency of the Diffusion Mamba framework in 3D
shape generation, setting a new standard for the field and paving the way for
future explorations in high-resolution 3D modeling technologies.

摘要：<paragraph>序列建模的最新进展促成了 Mamba 架构的发展，它以其选择性状态空间方法著称，为高效处理长序列提供了有前景的途径。然而，它在 3D 形状生成中的应用，尤其是在高分辨率下，仍然未得到充分探索。传统的具有自注意力机制的扩散变压器 (DiT)，尽管有其潜力，但由于输入长度增加时注意操作的三次复杂度，而面临可扩展性挑战。在处理高分辨率体素大小时，这种复杂度成为一个重大障碍。为了应对这一挑战，我们引入了一种针对 3D 点云生成量身定制的新型扩散架构——扩散 Mamba (DiM-3D)。此架构放弃了传统的注意力机制，而是利用 Mamba 架构的固有效率来保持相对于序列长度的线性复杂度。DiM-3D 的特点是推理时间快，计算需求大大降低，以减少的 Gflops 量化为特征，从而解决了先前模型的关键可扩展性问题。我们在 ShapeNet 基准上的经验结果表明，DiM-3D 在生成高保真度和多样化的 3D 形状方面实现了最先进的性能。此外，DiM-3D 在 3D 点云完成等任务中表现出卓越的能力。这不仅证明了该模型的可扩展性，还强调了它在生成用于高级 3D 形状建模所需的详细、高分辨率体素方面的效率，尤其擅长需要高分辨率体素大小的环境。通过这些发现，我们展示了扩散 Mamba 框架在 3D 形状生成中的出色可扩展性和效率，为该领域设定了新标准，并为未来在高分辨率 3D 建模技术中的探索铺平了道路。</paragraph>

##### **TimeSieve: Extracting Temporal Dynamics through Information Bottlenecks**
2406.05036v1 by Ninghui Feng, Songning Lai, Fobao Zhou, Zhenxiao Yin, Hang Zhao

Time series forecasting has become an increasingly popular research area due
to its critical applications in various real-world domains such as traffic
management, weather prediction, and financial analysis. Despite significant
advancements, existing models face notable challenges, including the necessity
of manual hyperparameter tuning for different datasets, and difficulty in
effectively distinguishing signal from redundant features in data characterized
by strong seasonality. These issues hinder the generalization and practical
application of time series forecasting models. To solve this issues, we propose
an innovative time series forecasting model TimeSieve designed to address these
challenges. Our approach employs wavelet transforms to preprocess time series
data, effectively capturing multi-scale features without the need for
additional parameters or manual hyperparameter tuning. Additionally, we
introduce the information bottleneck theory that filters out redundant features
from both detail and approximation coefficients, retaining only the most
predictive information. This combination reduces significantly improves the
model's accuracy. Extensive experiments demonstrate that our model outperforms
existing state-of-the-art methods on 70\% of the datasets, achieving higher
predictive accuracy and better generalization across diverse datasets. Our
results validate the effectiveness of our approach in addressing the key
challenges in time series forecasting, paving the way for more reliable and
efficient predictive models in practical applications. The code for our model
is available at https://github.com/xll0328/TimeSieve.

摘要：時序預測已成為一個越來越受歡迎的研究領域，因為它在各種現實世界的領域中具有關鍵應用，例如交通管理、天氣預測和財務分析。儘管有顯著進展，現有模型面臨著顯著的挑戰，包括為不同數據集進行手動超參數調整的必要性，以及難以有效區分具有強季節性的數據中的信號和冗餘特徵。這些問題阻礙了時序預測模型的概括化和實際應用。為了解決這些問題，我們提出了一種創新的時序預測模型 TimeSieve，旨在應對這些挑戰。我們的做法採用小波轉換來預處理時序數據，有效地捕捉多尺度特徵，而不需要額外的參數或手動超參數調整。此外，我們引入了信息瓶頸理論，它從細節和近似係數中濾出冗餘特徵，只保留最具預測性的信息。這種組合顯著提高了模型的準確率。大量的實驗表明，我們的模型在 70% 的數據集上優於現有的最先進方法，在不同的數據集上實現了更高的預測準確率和更好的概括化。我們的結果驗證了我們的方法在應對時序預測中的關鍵挑戰方面的有效性，為實際應用中更可靠和高效的預測模型鋪平了道路。我們模型的代碼可在 https://github.com/xll0328/TimeSieve 中獲得。

##### **Scenarios and Approaches for Situated Natural Language Explanations**
2406.05035v1 by Pengshuo Qiu, Frank Rudzicz, Zining Zhu

Large language models (LLMs) can be used to generate natural language
explanations (NLE) that are adapted to different users' situations. However,
there is yet to be a quantitative evaluation of the extent of such adaptation.
To bridge this gap, we collect a benchmarking dataset, Situation-Based
Explanation. This dataset contains 100 explanandums. Each explanandum is paired
with explanations targeted at three distinct audience types-such as educators,
students, and professionals-enabling us to assess how well the explanations
meet the specific informational needs and contexts of these diverse groups e.g.
students, teachers, and parents. For each "explanandum paired with an audience"
situation, we include a human-written explanation. These allow us to compute
scores that quantify how the LLMs adapt the explanations to the situations. On
an array of pretrained language models with varying sizes, we examine three
categories of prompting methods: rule-based prompting, meta-prompting, and
in-context learning prompting. We find that 1) language models can generate
prompts that result in explanations more precisely aligned with the target
situations, 2) explicitly modeling an "assistant" persona by prompting "You are
a helpful assistant..." is not a necessary prompt technique for situated NLE
tasks, and 3) the in-context learning prompts only can help LLMs learn the
demonstration template but can't improve their inference performance. SBE and
our analysis facilitate future research towards generating situated natural
language explanations.

摘要：大型語言模型 (LLM) 可用於產生自然語言說明 (NLE)，這些說明適應於不同的使用者情況。然而，對於此類適應的程度尚未有量化評估。為了彌合這個差距，我們收集了一個基準資料集，即基於情境的說明。這個資料集包含 100 個被解釋物。每個被解釋物都配對了針對三種類型的不同受眾的說明，例如教育者、學生和專業人士，讓我們能夠評估說明如何滿足這些不同群體，例如學生、老師和家長，具體的資訊需求和情境。對於每個「配對了受眾的被解釋物」情境，我們都包含一個人類撰寫的說明。這些說明讓我們能夠計算分數，量化 LLM 如何將說明適應到情境。在具備不同規模的預訓練語言模型陣列上，我們檢驗了三種類型的提示方法：基於規則的提示、元提示和情境學習提示。我們發現 1) 語言模型可以產生提示，讓說明更精確地與目標情境對齊，2) 明確地透過提示「您是一位有幫助的助理...」來建構一個「助理」角色，並非情境 NLE 任務的必要提示技巧，以及 3) 情境學習提示只能協助 LLM 學習示範範本，但無法提升它們的推論效能。SBE 和我們的分析促進了未來在產生情境式自然語言說明方面的研究。

##### **Adaptively Learning to Select-Rank in Online Platforms**
2406.05017v1 by Jingyuan Wang, Perry Dong, Ying Jin, Ruohan Zhan, Zhengyuan Zhou

Ranking algorithms are fundamental to various online platforms across
e-commerce sites to content streaming services. Our research addresses the
challenge of adaptively ranking items from a candidate pool for heterogeneous
users, a key component in personalizing user experience. We develop a user
response model that considers diverse user preferences and the varying effects
of item positions, aiming to optimize overall user satisfaction with the ranked
list. We frame this problem within a contextual bandits framework, with each
ranked list as an action. Our approach incorporates an upper confidence bound
to adjust predicted user satisfaction scores and selects the ranking action
that maximizes these adjusted scores, efficiently solved via maximum weight
imperfect matching. We demonstrate that our algorithm achieves a cumulative
regret bound of $O(d\sqrt{NKT})$ for ranking $K$ out of $N$ items in a
$d$-dimensional context space over $T$ rounds, under the assumption that user
responses follow a generalized linear model. This regret alleviates dependence
on the ambient action space, whose cardinality grows exponentially with $N$ and
$K$ (thus rendering direct application of existing adaptive learning algorithms
-- such as UCB or Thompson sampling -- infeasible). Experiments conducted on
both simulated and real-world datasets demonstrate our algorithm outperforms
the baseline.

摘要：排名演算法是從電子商務網站到內容串流服務等各種線上平台的基礎。我們的研究探討了從候選池中針對異質使用者自適應排名項目，這是個人化使用者體驗的關鍵組成部分，的挑戰。我們開發了一個使用者回應模型，考量了不同的使用者偏好和項目位置的各種影響，旨在最佳化使用者對排名清單的整體滿意度。我們在一個情境強盜架構中建構這個問題，其中每個排名清單作為一個動作。我們的做法納入一個上限置信界限來調整預測的使用者滿意度分數，並選擇能最大化這些調整分數的排名動作，透過最大權重不完美匹配有效率地解決。我們證明，我們的演算法在 $T$ 輪中，在 $d$ 維度情境空間中對 $N$ 個項目中的 $K$ 個項目進行排名，達到 $O(d\sqrt{NKT})$ 的累積後悔界限，假設使用者回應遵循廣義線性模型。這個後悔減輕了對環境動作空間的依賴，其基數隨著 $N$ 和 $K$ 指數成長（因此使現有自適應學習演算法的直接應用——例如 UCB 或 Thompson 採樣——不可行）。在模擬和真實世界資料集上進行的實驗證明，我們的演算法優於基準。

##### **Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study**
2406.05002v1 by Deepa Tilwani, Christian O'Reilly

The study of effective connectivity (EC) is essential in understanding how
the brain integrates and responds to various sensory inputs. Model-driven
estimation of EC is a powerful approach that requires estimating global and
local parameters of a generative model of neural activity. Insights gathered
through this process can be used in various applications, such as studying
neurodevelopmental disorders. However, accurately determining EC through
generative models remains a significant challenge due to the complexity of
brain dynamics and the inherent noise in neural recordings, e.g., in
electroencephalography (EEG). Current model-driven methods to study EC are
computationally complex and cannot scale to all brain regions as required by
whole-brain analyses. To facilitate EC assessment, an inference algorithm must
exhibit reliable prediction of parameters in the presence of noise. Further,
the relationship between the model parameters and the neural recordings must be
learnable. To progress toward these objectives, we benchmarked the performance
of a Bi-LSTM model for parameter inference from the Jansen-Rit neural mass
model (JR-NMM) simulated EEG under various noise conditions. Additionally, our
study explores how the JR-NMM reacts to changes in key biological parameters
(i.e., sensitivity analysis) like synaptic gains and time constants, a crucial
step in understanding the connection between neural mechanisms and observed
brain activity. Our results indicate that we can predict the local JR-NMM
parameters from EEG, supporting the feasibility of our deep-learning-based
inference approach. In future work, we plan to extend this framework to
estimate local and global parameters from real EEG in clinically relevant
applications.

摘要：有效连通性 (EC) 的研究对于理解大脑如何整合和响应各种感官输入至关重要。EC 的模型驱动估计是一种强大的方法，需要估计神经活动生成模型的全局和局部参数。通过此过程收集的见解可用于各种应用中，例如研究神经发育障碍。然而，由于大脑动力学复杂且神经记录中固有噪声（例如脑电图 (EEG) 中的噪声），通过生成模型准确确定 EC 仍然是一项重大挑战。当前用于研究 EC 的模型驱动方法计算复杂，并且无法扩展到全脑分析所需的所有大脑区域。为了促进 EC 评估，推理算法必须在存在噪声的情况下对参数进行可靠预测。此外，模型参数与神经记录之间的关系必须是可学习的。为了实现这些目标，我们对双向 LSTM 模型在各种噪声条件下从 Jansen-Rit 神经质量模型 (JR-NMM) 模拟脑电图中进行参数推理的性能进行了基准测试。此外，我们的研究探索了 JR-NMM 如何对关键生物学参数（即敏感性分析）的变化做出反应，例如突触增益和时间常数，这是理解神经机制与观察到的脑活动之间联系的关键步骤。我们的结果表明，我们可以从脑电图中预测局部 JR-NMM 参数，从而支持我们基于深度学习的推理方法的可行性。在未来的工作中，我们计划将此框架扩展到从临床相关应用中的真实脑电图估计局部和全局参数。

##### **ADBA:Approximation Decision Boundary Approach for Black-Box Adversarial Attacks**
2406.04998v1 by Feiyang Wang, Xingquan Zuo, Hai Huang, Gang Chen

Many machine learning models are susceptible to adversarial attacks, with
decision-based black-box attacks representing the most critical threat in
real-world applications. These attacks are extremely stealthy, generating
adversarial examples using hard labels obtained from the target machine
learning model. This is typically realized by optimizing perturbation
directions, guided by decision boundaries identified through query-intensive
exact search, significantly limiting the attack success rate. This paper
introduces a novel approach using the Approximation Decision Boundary (ADB) to
efficiently and accurately compare perturbation directions without precisely
determining decision boundaries. The effectiveness of our ADB approach (ADBA)
hinges on promptly identifying suitable ADB, ensuring reliable differentiation
of all perturbation directions. For this purpose, we analyze the probability
distribution of decision boundaries, confirming that using the distribution's
median value as ADB can effectively distinguish different perturbation
directions, giving rise to the development of the ADBA-md algorithm. ADBA-md
only requires four queries on average to differentiate any pair of perturbation
directions, which is highly query-efficient. Extensive experiments on six
well-known image classifiers clearly demonstrate the superiority of ADBA and
ADBA-md over multiple state-of-the-art black-box attacks.

摘要：許多機器學習模型容易受到對抗性攻擊，其中基於決策的黑盒攻擊在實際應用中構成最嚴重的威脅。這些攻擊極其隱蔽，使用從目標機器學習模型獲得的硬標籤來產生對抗性範例。這通常是通過最佳化擾動方向來實現的，由通過查詢密集型精確搜索識別的決策邊界引導，顯著限制了攻擊成功率。本文介紹了一種使用近似決策邊界 (ADB) 的新方法，以有效且準確地比較擾動方向，而無需精確確定決策邊界。我們的 ADB 方法 (ADBA) 的有效性取決於及時識別合適的 ADB，確保所有擾動方向的可靠區分。為此，我們分析了決策邊界的機率分布，確認使用分布的中值作為 ADB 可以有效區分不同的擾動方向，從而推動了 ADBA-md 演算法的開發。ADBA-md 平均只需要四次查詢即可區分任何一對擾動方向，這非常節省查詢。對六個著名的影像分類器進行的廣泛實驗清楚地證明了 ADBA 和 ADBA-md 優於多種最先進的黑盒攻擊。

##### **Compositional Generalization with Grounded Language Models**
2406.04989v1 by Sondre Wold, Étienne Simon, Lucas Georges Gabriel Charpentier, Egor V. Kostylev, Erik Velldal, Lilja Øvrelid

Grounded language models use external sources of information, such as
knowledge graphs, to meet some of the general challenges associated with
pre-training. By extending previous work on compositional generalization in
semantic parsing, we allow for a controlled evaluation of the degree to which
these models learn and generalize from patterns in knowledge graphs. We develop
a procedure for generating natural language questions paired with knowledge
graphs that targets different aspects of compositionality and further avoids
grounding the language models in information already encoded implicitly in
their weights. We evaluate existing methods for combining language models with
knowledge graphs and find them to struggle with generalization to sequences of
unseen lengths and to novel combinations of seen base components. While our
experimental results provide some insight into the expressive power of these
models, we hope our work and released datasets motivate future research on how
to better combine language models with structured knowledge representations.

摘要：接地語言模型使用外部資訊來源，例如知識圖譜，以因應與預訓練相關的一些一般挑戰。藉由擴展語意剖析中組合概括的先前工作，我們允許對這些模型從知識圖譜中的模式學習和概括的程度進行受控評估。我們開發了一個程序，用於產生與知識圖譜配對的自然語言問題，針對組合性的不同面向，並進一步避免將語言模型接地到其權重中已隱含編碼的資訊。我們評估了將語言模型與知識圖譜結合的現有方法，發現它們難以概括到長度未見的序列和已見基礎組件的新組合。雖然我們的實驗結果提供了一些見解，說明了這些模型的表達能力，但我們希望我們的工作和發布的資料集能激勵未來研究如何將語言模型與結構化知識表徵更好地結合。

##### **Language models emulate certain cognitive profiles: An investigation of how predictability measures interact with individual differences**
2406.04988v1 by Patrick Haller, Lena S. Bolliger, Lena A. Jäger

To date, most investigations on surprisal and entropy effects in reading have
been conducted on the group level, disregarding individual differences. In this
work, we revisit the predictive power of surprisal and entropy measures
estimated from a range of language models (LMs) on data of human reading times
as a measure of processing effort by incorporating information of language
users' cognitive capacities. To do so, we assess the predictive power of
surprisal and entropy estimated from generative LMs on reading data obtained
from individuals who also completed a wide range of psychometric tests.
Specifically, we investigate if modulating surprisal and entropy relative to
cognitive scores increases prediction accuracy of reading times, and we examine
whether LMs exhibit systematic biases in the prediction of reading times for
cognitively high- or low-performing groups, revealing what type of
psycholinguistic subject a given LM emulates. Our study finds that in most
cases, incorporating cognitive capacities increases predictive power of
surprisal and entropy on reading times, and that generally, high performance in
the psychometric tests is associated with lower sensitivity to predictability
effects. Finally, our results suggest that the analyzed LMs emulate readers
with lower verbal intelligence, suggesting that for a given target group (i.e.,
individuals with high verbal intelligence), these LMs provide less accurate
predictability estimates.

摘要：迄今為止，大多數關於驚訝和熵效應在閱讀中的研究都針對群體層面進行，而忽略了個體差異。在這項工作中，我們重新探討了從一系列語言模型 (LM) 中估計出的驚訝和熵測量的預測能力，將人類閱讀時間的數據作為處理工作量的衡量標準，方法是納入語言使用者認知能力的信息。為此，我們評估了從生成式 LM 中估計出的驚訝和熵對從完成廣泛心理測驗的個體獲得的閱讀數據的預測能力。具體來說，我們研究了相對於認知分數調整驚訝和熵是否會提高閱讀時間的預測準確度，並探討了 LM 在對認知表現高或表現低的群體的閱讀時間預測中是否表現出系統性偏差，從而揭示了給定的 LM 模仿哪種類型的語言心理學主體。我們的研究發現，在大多數情況下，將認知能力納入考量會提高驚訝和熵對閱讀時間的預測能力，並且通常，心理測驗中的高表現與對可預測性效應的較低敏感性有關。最後，我們的結果表明，所分析的 LM 模仿了語言理解能力較低的讀者，這表明對於給定的目標群體（即語言理解能力較高的個體），這些 LM 提供的預測性估計準確度較低。

##### **MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter**
2406.04984v1 by Jitai Hao, WeiWei Sun, Xin Xin, Qi Meng, Zhumin Chen, Pengjie Ren, Zhaochun Ren

Parameter-Efficient Fine-tuning (PEFT) facilitates the fine-tuning of Large
Language Models (LLMs) under limited resources. However, the fine-tuning
performance with PEFT on complex, knowledge-intensive tasks is limited due to
the constrained model capacity, which originates from the limited number of
additional trainable parameters. To overcome this limitation, we introduce a
novel mechanism that fine-tunes LLMs with adapters of larger size yet
memory-efficient. This is achieved by leveraging the inherent activation
sparsity in the Feed-Forward Networks (FFNs) of LLMs and utilizing the larger
capacity of Central Processing Unit (CPU) memory compared to Graphics
Processing Unit (GPU). We store and update the parameters of larger adapters on
the CPU. Moreover, we employ a Mixture of Experts (MoE)-like architecture to
mitigate unnecessary CPU computations and reduce the communication volume
between the GPU and CPU. This is particularly beneficial over the limited
bandwidth of PCI Express (PCIe). Our method can achieve fine-tuning results
comparable to those obtained with larger memory capacities, even when operating
under more limited resources such as a 24GB memory single GPU setup, with
acceptable loss in training efficiency. Our codes are available at
https://github.com/CURRENTF/MEFT.

摘要：參數高效微調 (PEFT) 可在有限資源下，協助微調大型語言模型 (LLM)。然而，由於模型容量受限，且源自於有限的可訓練參數數量，因此 PEFT 在複雜、知識密集型任務上的微調效能受到限制。為了克服這個限制，我們引入了一種新機制，使用較大但記憶體效率高的適配器來微調 LLM。這是透過利用 LLM 的前饋網路 (FFN) 中固有的激活稀疏性，並利用中央處理單元 (CPU) 記憶體比圖形處理單元 (GPU) 更大的容量來實現。我們在 CPU 上儲存和更新較大適配器的參數。此外，我們採用類似混合專家 (MoE) 的架構，以減輕不必要的 CPU 計算，並減少 GPU 和 CPU 之間的通訊量。這對於 PCI Express (PCIe) 的有限頻寬特別有益。我們的模型即使在較有限的資源（例如 24GB 記憶體單 GPU 設定）下運作，也能達到與較大記憶體容量所取得的微調結果相當的表現，同時在訓練效率上可接受的損失。我們的程式碼可在 https://github.com/CURRENTF/MEFT 取得。

##### **UniTST: Effectively Modeling Inter-Series and Intra-Series Dependencies for Multivariate Time Series Forecasting**
2406.04975v1 by Juncheng Liu, Chenghao Liu, Gerald Woo, Yiwei Wang, Bryan Hooi, Caiming Xiong, Doyen Sahoo

Transformer-based models have emerged as powerful tools for multivariate time
series forecasting (MTSF). However, existing Transformer models often fall
short of capturing both intricate dependencies across variate and temporal
dimensions in MTS data. Some recent models are proposed to separately capture
variate and temporal dependencies through either two sequential or parallel
attention mechanisms. However, these methods cannot directly and explicitly
learn the intricate inter-series and intra-series dependencies. In this work,
we first demonstrate that these dependencies are very important as they usually
exist in real-world data. To directly model these dependencies, we propose a
transformer-based model UniTST containing a unified attention mechanism on the
flattened patch tokens. Additionally, we add a dispatcher module which reduces
the complexity and makes the model feasible for a potentially large number of
variates. Although our proposed model employs a simple architecture, it offers
compelling performance as shown in our extensive experiments on several
datasets for time series forecasting.

摘要：基於 Transformer 的模型已成為多變量時間序列預測 (MTSF) 的強大工具。然而，現有的 Transformer 模型常常無法捕捉 MTS 資料中變量和時間維度之間的複雜依賴性。最近提出了一些模型，透過兩個順序或並行注意力機制分別捕捉變量和時間依賴性。然而，這些方法無法直接且明確地學習複雜的序列間和序列內依賴性。在這項工作中，我們首先證明這些依賴性非常重要，因為它們通常存在於真實世界的資料中。為了直接建模這些依賴性，我們提出一個基於 Transformer 的模型 UniTST，在扁平化的區塊代碼上包含一個統一的注意力機制。此外，我們新增一個調度器模組，它可以降低複雜性，並使模型適用於大量的變量。儘管我們提出的模型採用了簡單的架構，但它在針對時間序列預測的幾個資料集進行的廣泛實驗中展現了令人信服的效能。

##### **Neural Laplace for learning Stochastic Differential Equations**
2406.04964v1 by Adrien Carrel

Neural Laplace is a unified framework for learning diverse classes of
differential equations (DE). For different classes of DE, this framework
outperforms other approaches relying on neural networks that aim to learn
classes of ordinary differential equations (ODE). However, many systems can't
be modelled using ODEs. Stochastic differential equations (SDE) are the
mathematical tool of choice when modelling spatiotemporal DE dynamics under the
influence of randomness. In this work, we review the potential applications of
Neural Laplace to learn diverse classes of SDE, both from a theoretical and a
practical point of view.

摘要：神經拉普拉斯是一種統一框架，用於學習各種微分方程 (DE) 類別。對於不同的 DE 類別，此框架優於依賴神經網路的其他方法，這些方法旨在學習常微分方程 (ODE) 類別。然而，許多系統無法使用 ODE 建模。隨機微分方程 (SDE) 是在隨機性影響下對時空 DE 動態進行建模的首選數學工具。在這項工作中，我們回顧了神經拉普拉斯在學習各種 SDE 類別中的潛在應用，無論是從理論上還是實務上。

##### **Learning Divergence Fields for Shift-Robust Graph Representations**
2406.04963v1 by Qitian Wu, Fan Nie, Chenxiao Yang, Junchi Yan

Real-world data generation often involves certain geometries (e.g., graphs)
that induce instance-level interdependence. This characteristic makes the
generalization of learning models more difficult due to the intricate
interdependent patterns that impact data-generative distributions and can vary
from training to testing. In this work, we propose a geometric diffusion model
with learnable divergence fields for the challenging generalization problem
with interdependent data. We generalize the diffusion equation with stochastic
diffusivity at each time step, which aims to capture the multi-faceted
information flows among interdependent data. Furthermore, we derive a new
learning objective through causal inference, which can guide the model to learn
generalizable patterns of interdependence that are insensitive across domains.
Regarding practical implementation, we introduce three model instantiations
that can be considered as the generalized versions of GCN, GAT, and
Transformers, respectively, which possess advanced robustness against
distribution shifts. We demonstrate their promising efficacy for
out-of-distribution generalization on diverse real-world datasets.

摘要：現實世界資料產生通常涉及某些幾何（例如圖形），會引發例項級別的相互依賴。這個特徵會讓學習模型的概化變得更困難，因為複雜的相互依賴模式會影響資料產生分佈，並且會在訓練和測試之間產生變化。在這項工作中，我們提出一個幾何擴散模型，其具有可學習的散度場，以解決具有相互依賴資料的挑戰性概化問題。我們使用隨機擴散率對擴散方程式進行概化，其目標是捕捉相互依賴資料之間的多面向資訊流。此外，我們透過因果推理推導出一個新的學習目標，可以引導模型學習對不同領域不敏感的相互依賴可概化模式。關於實際實作，我們介紹了三個模型實例，分別可以視為 GCN、GAT 和 Transformers 的概化版本，具有針對分佈轉移的進階穩健性。我們展示了它們在各種真實世界資料集上對分佈外概化的有望效能。

##### **Experimental Evaluation of ROS-Causal in Real-World Human-Robot Spatial Interaction Scenarios**
2406.04955v1 by Luca Castri, Gloria Beraldo, Sariah Mghames, Marc Hanheide, Nicola Bellotto

Deploying robots in human-shared environments requires a deep understanding
of how nearby agents and objects interact. Employing causal inference to model
cause-and-effect relationships facilitates the prediction of human behaviours
and enables the anticipation of robot interventions. However, a significant
challenge arises due to the absence of implementation of existing causal
discovery methods within the ROS ecosystem, the standard de-facto framework in
robotics, hindering effective utilisation on real robots. To bridge this gap,
in our previous work we proposed ROS-Causal, a ROS-based framework designed for
onboard data collection and causal discovery in human-robot spatial
interactions. In this work, we present an experimental evaluation of ROS-Causal
both in simulation and on a new dataset of human-robot spatial interactions in
a lab scenario, to assess its performance and effectiveness. Our analysis
demonstrates the efficacy of this approach, showcasing how causal models can be
extracted directly onboard by robots during data collection. The online causal
models generated from the simulation are consistent with those from lab
experiments. These findings can help researchers to enhance the performance of
robotic systems in shared environments, firstly by studying the causal
relations between variables in simulation without real people, and then
facilitating the actual robot deployment in real human environments.
ROS-Causal: https://lcastri.github.io/roscausal

摘要：在人類共享的環境中部署機器人需要深入了解附近的代理和物體如何相互作用。利用因果推論來建模因果關係有助於預測人類行為，並能預期機器人的干預。然而，由於在機器人標準的實際框架 ROS 生態系統中缺乏現有因果發現方法的實施，因此出現了一個重大的挑戰，這阻礙了在真實機器人上的有效利用。為了彌補這一差距，我們在之前的工作中提出了 ROS-Causal，一個基於 ROS 的框架，專門用於機載數據收集和人類機器人空間交互中的因果發現。在這項工作中，我們在模擬和一個新的實驗室場景中的人類機器人空間交互數據集中對 ROS-Causal 進行了實驗評估，以評估其性能和有效性。我們的分析證明了這種方法的有效性，展示了機器人在數據收集期間如何直接在機載中提取因果模型。從模擬中生成的線上因果模型與實驗室實驗中的因果模型一致。這些發現可以幫助研究人員提高機器人在共享環境中的系統性能，首先通過在沒有真人參與的情況下研究模擬中的變量之間的因果關係，然後促進實際機器人在真實人類環境中的部署。ROS-Causal：https://lcastri.github.io/roscausal

##### **Quantifying Geospatial in the Common Crawl Corpus**
2406.04952v1 by Ilya Ilyankou, Meihui Wang, James Haworth, Stefano Cavazzi

Large language models (LLMs) exhibit emerging geospatial capabilities,
stemming from their pre-training on vast unlabelled text datasets that are
often derived from the Common Crawl corpus. However, the geospatial content
within CC remains largely unexplored, impacting our understanding of LLMs'
spatial reasoning. This paper investigates the prevalence of geospatial data in
recent Common Crawl releases using Gemini, a powerful language model. By
analyzing a sample of documents and manually revising the results, we estimate
that between 1 in 5 and 1 in 6 documents contain geospatial information such as
coordinates and street addresses. Our findings provide quantitative insights
into the nature and extent of geospatial data within Common Crawl, and web
crawl data in general. Furthermore, we formulate questions to guide future
investigations into the geospatial content of available web crawl datasets and
its influence on LLMs.

摘要：大型語言模型（LLM）展現出新興的地理空間能力，
源自於它們在海量的未標記文字資料集上進行預訓練，這些資料集
通常來自於 Common Crawl 資料庫。然而，地理空間內容
在 CC 中仍然很大程度上未被探索，影響了我們對 LLM
空間推理的理解。本文使用強大的語言模型 Gemini 調查了近期 Common Crawl 發布中地理空間資料的普遍性。藉由
分析文件範例並手動修改結果，我們估計 5 到 6 份文件中有 1 份包含地理空間資訊，例如
座標和街道地址。我們的發現提供了關於 Common Crawl 中地理空間資料性質和範圍的定量見解，以及
網路爬取資料的概況。此外，我們制定問題以引導對可用網路爬取資料集的地理空間內容及其對 LLM 的影響進行後續調查。

##### **BAMO at SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense**
2406.04947v1 by Baktash Ansari, Mohammadmostafa Rostamkhani, Sauleh Eetemadi

This paper outlines our approach to SemEval 2024 Task 9, BRAINTEASER: A Novel
Task Defying Common Sense. The task aims to evaluate the ability of language
models to think creatively. The dataset comprises multi-choice questions that
challenge models to think "outside of the box". We fine-tune 2 models, BERT and
RoBERTa Large. Next, we employ a Chain of Thought (CoT) zero-shot prompting
approach with 6 large language models, such as GPT-3.5, Mixtral, and Llama2.
Finally, we utilize ReConcile, a technique that employs a "round table
conference" approach with multiple agents for zero-shot learning, to generate
consensus answers among 3 selected language models. Our best method achieves an
overall accuracy of 85 percent on the sentence puzzles subtask.

摘要：本論文概述我們對 SemEval 2024 任務 9 的方法，BRAINTEASER：一個挑戰常識的新任務。該任務旨在評估語言模型進行創造性思考的能力。該數據集包含多選題，挑戰模型進行「跳脫框架」思考。我們微調了 2 個模型，BERT 和 RoBERTa Large。接下來，我們採用了帶有 6 個大型語言模型（例如 GPT-3.5、Mixtral 和 Llama2）的思考鏈 (CoT) 零次提示方法。最後，我們利用 ReConcile，一種採用「圓桌會議」方法與多個代理進行零次學習的技術，在 3 個選定的語言模型之間產生共識答案。我們最好的方法在句子謎題子任務上達到了 85% 的整體準確度。

##### **TCMD: A Traditional Chinese Medicine QA Dataset for Evaluating Large Language Models**
2406.04941v1 by Ping Yu, Kaitao Song, Fengchen He, Ming Chen, Jianfeng Lu

The recently unprecedented advancements in Large Language Models (LLMs) have
propelled the medical community by establishing advanced medical-domain models.
However, due to the limited collection of medical datasets, there are only a
few comprehensive benchmarks available to gauge progress in this area. In this
paper, we introduce a new medical question-answering (QA) dataset that contains
massive manual instruction for solving Traditional Chinese Medicine examination
tasks, called TCMD. Specifically, our TCMD collects massive questions across
diverse domains with their annotated medical subjects and thus supports us in
comprehensively assessing the capability of LLMs in the TCM domain. Extensive
evaluation of various general LLMs and medical-domain-specific LLMs is
conducted. Moreover, we also analyze the robustness of current LLMs in solving
TCM QA tasks by introducing randomness. The inconsistency of the experimental
results also reveals the shortcomings of current LLMs in solving QA tasks. We
also expect that our dataset can further facilitate the development of LLMs in
the TCM area.

摘要：近期大型語言模型 (LLM) 前所未有的進展，已透過建立先進的醫療領域模型推進了醫療界。然而，由於醫療資料集的收集有限，因此只有少數綜合評量可供衡量此領域的進度。在本文中，我們介紹了一個新的醫療問答 (QA) 資料集，其中包含大量手動說明，以解決中醫考試任務，稱為 TCMD。具體來說，我們的 TCMD 收集了不同領域的大量問題，並附有其註解的醫療主題，因此支持我們全面評估 LLM 在中醫領域的能力。對各種一般 LLM 和特定於醫療領域的 LLM 進行了廣泛評估。此外，我們還通過引入隨機性來分析當前 LLM 在解決中醫 QA 任務中的穩健性。實驗結果的不一致性也揭示了當前 LLM 在解決 QA 任務中的缺點。我們也期待我們的資料集能進一步促進中醫領域 LLM 的發展。

##### **CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling**
2406.04940v1 by Matthew Fortier, Mats L. Richter, Oliver Sonnentag, Chris Pal

Terrestrial carbon fluxes provide vital information about our biosphere's
health and its capacity to absorb anthropogenic CO$_2$ emissions. The
importance of predicting carbon fluxes has led to the emerging field of
data-driven carbon flux modelling (DDCFM), which uses statistical techniques to
predict carbon fluxes from biophysical data. However, the field lacks a
standardized dataset to promote comparisons between models. To address this
gap, we present CarbonSense, the first machine learning-ready dataset for
DDCFM. CarbonSense integrates measured carbon fluxes, meteorological
predictors, and satellite imagery from 385 locations across the globe, offering
comprehensive coverage and facilitating robust model training. Additionally, we
provide a baseline model using a current state-of-the-art DDCFM approach and a
novel transformer based model. Our experiments illustrate the potential gains
that multimodal deep learning techniques can bring to this domain. By providing
these resources, we aim to lower the barrier to entry for other deep learning
researchers to develop new models and drive new advances in carbon flux
modelling.

摘要：陸地碳通量提供我們生物圈健康和吸收人為 CO$_2$ 排放的能力的重要資訊。預測碳通量的重要性導致資料驅動碳通量建模 (DDCFM) 新興領域的出現，它使用統計技術從生物物理資料預測碳通量。然而，該領域缺乏標準化資料集來促進模型之間的比較。為了解決這個差距，我們提出 CarbonSense，這是第一個適用於 DDCFM 的機器學習準備資料集。CarbonSense 整合了來自全球 385 個地點的測量碳通量、氣象預測因子和衛星影像，提供全面的涵蓋範圍並促進穩健的模型訓練。此外，我們使用當前最先進的 DDCFM 方法和基於新穎Transformer的模型提供基準模型。我們的實驗說明了多模態深度學習技術可以為這個領域帶來的潛在收益。透過提供這些資源，我們旨在降低其他深度學習研究人員進入門檻，以開發新模型並推動碳通量建模的新進展。

##### **SpanGNN: Towards Memory-Efficient Graph Neural Networks via Spanning Subgraph Training**
2406.04938v1 by Xizhi Gu, Hongzheng Li, Shihong Gao, Xinyan Zhang, Lei Chen, Yingxia Shao

Graph Neural Networks (GNNs) have superior capability in learning graph data.
Full-graph GNN training generally has high accuracy, however, it suffers from
large peak memory usage and encounters the Out-of-Memory problem when handling
large graphs. To address this memory problem, a popular solution is mini-batch
GNN training. However, mini-batch GNN training increases the training variance
and sacrifices the model accuracy. In this paper, we propose a new
memory-efficient GNN training method using spanning subgraph, called SpanGNN.
SpanGNN trains GNN models over a sequence of spanning subgraphs, which are
constructed from empty structure. To overcome the excessive peak memory
consumption problem, SpanGNN selects a set of edges from the original graph to
incrementally update the spanning subgraph between every epoch. To ensure the
model accuracy, we introduce two types of edge sampling strategies (i.e.,
variance-reduced and noise-reduced), and help SpanGNN select high-quality edges
for the GNN learning. We conduct experiments with SpanGNN on widely used
datasets, demonstrating SpanGNN's advantages in the model performance and low
peak memory usage.

摘要：圖形神經網路 (GNN) 在學習圖形資料方面具有優異的能力。
全圖形 GNN 訓練通常具有很高的準確度，然而，它會消耗大量的峰值記憶體，並且在處理大型圖形時會遇到記憶體不足的問題。為了解決這個記憶體問題，一個流行的解決方案是迷你批次 GNN 訓練。然而，迷你批次 GNN 訓練會增加訓練變異，並犧牲模型的準確度。在本文中，我們提出了一種新的使用跨越子圖的記憶體高效 GNN 訓練方法，稱為 SpanGNN。SpanGNN 在一系列跨越子圖上訓練 GNN 模型，這些子圖是由空結構建構的。為了克服過度的峰值記憶體消耗問題，SpanGNN 從原始圖形中選擇一組邊緣，以在每個時期之間遞增更新跨越子圖。為了確保模型的準確性，我們引入了兩種邊緣取樣策略（即變異減少和雜訊減少），並協助 SpanGNN 為 GNN 學習選擇高品質的邊緣。我們在廣泛使用的資料集上使用 SpanGNN 進行實驗，證明了 SpanGNN 在模型效能和低峰值記憶體使用方面的優勢。

##### **Optimal Recurrent Network Topologies for Dynamical Systems Reconstruction**
2406.04934v1 by Christoph Jürgen Hemmer, Manuel Brenner, Florian Hess, Daniel Durstewitz

In dynamical systems reconstruction (DSR) we seek to infer from time series
measurements a generative model of the underlying dynamical process. This is a
prime objective in any scientific discipline, where we are particularly
interested in parsimonious models with a low parameter load. A common strategy
here is parameter pruning, removing all parameters with small weights. However,
here we find this strategy does not work for DSR, where even low magnitude
parameters can contribute considerably to the system dynamics. On the other
hand, it is well known that many natural systems which generate complex
dynamics, like the brain or ecological networks, have a sparse topology with
comparatively few links. Inspired by this, we show that geometric pruning,
where in contrast to magnitude-based pruning weights with a low contribution to
an attractor's geometrical structure are removed, indeed manages to reduce
parameter load substantially without significantly hampering DSR quality. We
further find that the networks resulting from geometric pruning have a specific
type of topology, and that this topology, and not the magnitude of weights, is
what is most crucial to performance. We provide an algorithm that automatically
generates such topologies which can be used as priors for generative modeling
of dynamical systems by RNNs, and compare it to other well studied topologies
like small-world or scale-free networks.

摘要：在动态系统重建 (DSR) 中，我们试图从时间序列测量中推断出底层动态过程的生成模型。这是任何科学学科中的首要目标，我们特别感兴趣的是具有低参数负载的简约模型。这里的一个常见策略是参数修剪，移除所有权重小的参数。然而，我们发现此策略不适用于 DSR，即使是幅度小的参数也可能极大地影响系统动态。另一方面，众所周知，许多产生复杂动态的自然系统（如大脑或生态网络）具有稀疏拓扑，且链接相对较少。受此启发，我们表明几何修剪（与基于幅度的修剪相反，其中权重对吸引子的几何结构贡献较小），确实设法大幅减少了参数负载，而不会显着妨碍 DSR 质量。我们进一步发现，几何修剪产生的网络具有特定类型的拓扑，并且这种拓扑（而不是权重的幅度）是性能最关键的因素。我们提供了一种算法，该算法自动生成此类拓扑，可用作 RNN 对动态系统进行生成建模的先验，并将其与其他经过充分研究的拓扑（如小世界或无标度网络）进行比较。

##### **LLM-based speaker diarization correction: A generalizable approach**
2406.04927v1 by Georgios Efstathiadis, Vijay Yadav, Anzar Abbas

Speaker diarization is necessary for interpreting conversations transcribed
using automated speech recognition (ASR) tools. Despite significant
developments in diarization methods, diarization accuracy remains an issue.
Here, we investigate the use of large language models (LLMs) for diarization
correction as a post-processing step. LLMs were fine-tuned using the Fisher
corpus, a large dataset of transcribed conversations. The ability of the models
to improve diarization accuracy in a holdout dataset was measured. We report
that fine-tuned LLMs can markedly improve diarization accuracy. However, model
performance is constrained to transcripts produced using the same ASR tool as
the transcripts used for fine-tuning, limiting generalizability. To address
this constraint, an ensemble model was developed by combining weights from
three separate models, each fine-tuned using transcripts from a different ASR
tool. The ensemble model demonstrated better overall performance than each of
the ASR-specific models, suggesting that a generalizable and ASR-agnostic
approach may be achievable. We hope to make these models accessible through
public-facing APIs for use by third-party applications.

摘要：說話人日記化對於使用自動語音辨識 (ASR) 工具轉錄對話來說是必要的。儘管在日記化方法上有顯著的發展，但日記化準確度仍然是一個問題。在此，我們研究使用大型語言模型 (LLM) 進行日記化校正作為後處理步驟。LLM 使用 Fisher 語料庫進行微調，Fisher 語料庫是一個大型的轉錄對話資料集。測量了模型在暫留資料集中改善日記化準確度的能力。我們報告說，微調後的 LLM 可以顯著提高日記化準確度。然而，模型效能受到使用與微調轉錄相同的 ASR 工具產生的轉錄的限制，這會限制通用性。為了解決這個限制，透過結合來自三個不同模型的權重來開發一個整體模型，每個模型都使用來自不同 ASR 工具的轉錄進行微調。整體模型展示出比每個特定於 ASR 的模型更好的整體效能，這表明可以實現可概括且與 ASR 無關的方法。我們希望透過公開的 API 讓第三方應用程式可以使用這些模型。

##### **Through the Thicket: A Study of Number-Oriented LLMs derived from Random Forest Models**
2406.04926v1 by Michał Romaszewski, Przemysław Sekuła, Przemysław Głomb, Michał Cholewa, Katarzyna Kołodziej

Large Language Models (LLMs) have shown exceptional performance in text
processing. Notably, LLMs can synthesize information from large datasets and
explain their decisions similarly to human reasoning through a chain of thought
(CoT). An emerging application of LLMs is the handling and interpreting of
numerical data, where fine-tuning enhances their performance over basic
inference methods. This paper proposes a novel approach to training LLMs using
knowledge transfer from a random forest (RF) ensemble, leveraging its
efficiency and accuracy. By converting RF decision paths into natural language
statements, we generate outputs for LLM fine-tuning, enhancing the model's
ability to classify and explain its decisions. Our method includes verifying
these rules through established classification metrics, ensuring their
correctness. We also examine the impact of preprocessing techniques on the
representation of numerical data and their influence on classification accuracy
and rule correctness

摘要：大型語言模型 (LLM) 在文本處理方面展現出非凡的效能。值得注意的是，LLM 可以從大型資料集綜合資訊，並透過一連串的想法 (CoT) 來解釋其決策，類似於人類的推理。LLM 的一個新興應用是處理和詮釋數值資料，其中微調會提升其效能，優於基本的推論方法。本文提出一個創新的訓練 LLM 方法，利用隨機森林 (RF) 整合的知識轉移，發揮其效率和準確性。透過將 RF 決策路徑轉換為自然語言陳述，我們產生 LLM 微調的輸出，增強模型分類和解釋其決策的能力。我們的做法包括透過已建立的分類指標驗證這些規則，以確保其正確性。我們也探討預處理技術對數值資料表示的影響，以及其對分類準確性和規則正確性的影響

##### **Online Adaptation for Enhancing Imitation Learning Policies**
2406.04913v1 by Federico Malato, Ville Hautamaki

Imitation learning enables autonomous agents to learn from human examples,
without the need for a reward signal. Still, if the provided dataset does not
encapsulate the task correctly, or when the task is too complex to be modeled,
such agents fail to reproduce the expert policy. We propose to recover from
these failures through online adaptation. Our approach combines the action
proposal coming from a pre-trained policy with relevant experience recorded by
an expert. The combination results in an adapted action that closely follows
the expert. Our experiments show that an adapted agent performs better than its
pure imitation learning counterpart. Notably, adapted agents can achieve
reasonable performance even when the base, non-adapted policy catastrophically
fails.

摘要：模仿學習讓自主代理人能從人類的範例中學習，
而不需要回饋訊號。然而，如果提供的資料集無法正確地封裝任務，或當任務太過複雜而無法建模時，
這些代理人便無法複製專家的策略。我們建議透過線上改編來從這些失敗中復原。我們的做法結合了來自預先訓練的策略的動作提案，以及由專家記錄下來的相關經驗。這個組合產生了一個改編後的動作，緊密地追隨專家。我們的實驗顯示，改編後的代理人表現優於純粹的模仿學習對應物。值得注意的是，即使基礎的、未改編的策略災難性地失敗，改編後的代理人也能達成合理的表現。

##### **PolyLUT-Add: FPGA-based LUT Inference with Wide Inputs**
2406.04910v1 by Binglei Lou, Richard Rademacher, David Boland, Philip H. W. Leong

FPGAs have distinct advantages as a technology for deploying deep neural
networks (DNNs) at the edge. Lookup Table (LUT) based networks, where neurons
are directly modelled using LUTs, help maximize this promise of offering
ultra-low latency and high area efficiency on FPGAs. Unfortunately, LUT
resource usage scales exponentially with the number of inputs to the LUT,
restricting PolyLUT to small LUT sizes. This work introduces PolyLUT-Add, a
technique that enhances neuron connectivity by combining $A$ PolyLUT
sub-neurons via addition to improve accuracy. Moreover, we describe a novel
architecture to improve its scalability. We evaluated our implementation over
the MNIST, Jet Substructure classification and Network Intrusion Detection
benchmark and found that for similar accuracy, PolyLUT-Add achieves a LUT
reduction of $1.3-7.7\times$ with a $1.2-2.2\times$ decrease in latency.

摘要：FPGA 具有作為技術的顯著優勢，可將深度神經網路 (DNN) 部署在邊緣。基於查詢表 (LUT) 的網路，其中神經元直接使用 LUT 建模，有助於最大化此承諾，在 FPGA 上提供超低延遲和高面積效率。不幸的是，LUT 資源使用會隨著 LUT 輸入數量呈指數級增長，將 PolyLUT 限制在較小的 LUT 大小。這項工作引入了 PolyLUT-Add，這是一種透過加法結合 $A$ PolyLUT 子神經元來增強神經元連接性的技術，以提高準確度。此外，我們描述了一種新穎的架構來改善其可擴充性。我們在 MNIST、Jet 子結構分類和網路入侵偵測基準上評估了我們的實作，發現對於類似的準確度，PolyLUT-Add 可將 LUT 減少 $1.3-7.7\times$，而延遲減少 $1.2-2.2\times$。

##### **RU-AI: A Large Multimodal Dataset for Machine Generated Content Detection**
2406.04906v1 by Liting Huang, Zhihao Zhang, Yiran Zhang, Xiyue Zhou, Shoujin Wang

The recent advancements in generative AI models, which can create realistic
and human-like content, are significantly transforming how people communicate,
create, and work. While the appropriate use of generative AI models can benefit
the society, their misuse poses significant threats to data reliability and
authentication. However, due to a lack of aligned multimodal datasets,
effective and robust methods for detecting machine-generated content are still
in the early stages of development. In this paper, we introduce RU-AI, a new
large-scale multimodal dataset designed for the robust and efficient detection
of machine-generated content in text, image, and voice. Our dataset is
constructed from three large publicly available datasets: Flickr8K, COCO, and
Places205, by combining the original datasets and their corresponding
machine-generated pairs. Additionally, experimental results show that our
proposed unified model, which incorporates a multimodal embedding module with a
multilayer perceptron network, can effectively determine the origin of the data
(i.e., original data samples or machine-generated ones) from RU-AI. However,
future work is still required to address the remaining challenges posed by
RU-AI. The source code and dataset are available at
https://github.com/ZhihaoZhang97/RU-AI.

摘要：生成式 AI 模型的最新進展可以創造出逼真且擬人的內容，大幅改變了人們溝通、創作和工作的方式。儘管適當使用生成式 AI 模型可以使社會受益，但其濫用對資料可靠性和驗證構成重大威脅。然而，由於缺乏一致的多模態資料集，用於檢測機器產生的內容的有效且穩健的方法仍處於開發的早期階段。在本文中，我們介紹 RU-AI，這是一個新的大型多模態資料集，旨在強健且有效地檢測文字、影像和語音中的機器產生的內容。我們的資料集由三個大型公開資料集建構而成：Flickr8K、COCO 和 Places205，透過結合原始資料集及其對應的機器產生配對。此外，實驗結果顯示，我們提出的統一模型結合了多模態嵌入模組和多層感知器網路，可以有效地從 RU-AI 中確定資料的來源（即原始資料樣本或機器產生的樣本）。然而，仍然需要後續工作來解決 RU-AI 構成的其餘挑戰。原始程式碼和資料集可在 https://github.com/ZhihaoZhang97/RU-AI 取得。

##### **XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model**
2406.04904v1 by Edresson Casanova, Kelly Davis, Eren Gölge, Görkem Göknar, Iulian Gulea, Logan Hart, Aya Aljafari, Joshua Meyer, Reuben Morais, Samuel Olayemi, Julian Weber

Most Zero-shot Multi-speaker TTS (ZS-TTS) systems support only a single
language. Although models like YourTTS, VALL-E X, Mega-TTS 2, and Voicebox
explored Multilingual ZS-TTS they are limited to just a few high/medium
resource languages, limiting the applications of these models in most of the
low/medium resource languages. In this paper, we aim to alleviate this issue by
proposing and making publicly available the XTTS system. Our method builds upon
the Tortoise model and adds several novel modifications to enable multilingual
training, improve voice cloning, and enable faster training and inference. XTTS
was trained in 16 languages and achieved state-of-the-art (SOTA) results in
most of them.

摘要：大多數零範例多講者文字轉語音（ZS-TTS）系統僅支援單一語言。儘管 YourTTS、VALL-E X、Mega-TTS 2 和 Voicebox 等模型探索了多語言 ZS-TTS，但它們僅限於少數高/中資源語言，限制了這些模型在大多數低/中資源語言中的應用。在本文中，我們旨在透過提出並公開 XTTS 系統來解決此問題。我們的模型建立在 Tortoise 模型之上，並新增了多項創新修改，以支援多語言訓練、改善語音複製，並加快訓練和推論。XTTS 以 16 種語言進行訓練，並在其中大多數語言中獲得了最先進（SOTA）的成果。

##### **Sliding Window 3-Objective Pareto Optimization for Problems with Chance Constraints**
2406.04899v1 by Frank Neumann, Carsten Witt

Constrained single-objective problems have been frequently tackled by
evolutionary multi-objective algorithms where the constraint is relaxed into an
additional objective. Recently, it has been shown that Pareto optimization
approaches using bi-objective models can be significantly sped up using sliding
windows (Neumann and Witt, ECAI 2023). In this paper, we extend the sliding
window approach to $3$-objective formulations for tackling chance constrained
problems. On the theoretical side, we show that our new sliding window approach
improves previous runtime bounds obtained in (Neumann and Witt, GECCO 2023)
while maintaining the same approximation guarantees. Our experimental
investigations for the chance constrained dominating set problem show that our
new sliding window approach allows one to solve much larger instances in a much
more efficient way than the 3-objective approach presented in (Neumann and
Witt, GECCO 2023).

摘要：受約束單目標問題經常由演化多目標演算法解決，其中約束放寬為額外的目標。最近已證明，使用滑動視窗（Neumann 和 Witt，ECAI 2023）的帕雷托最佳化方法可以顯著加速。在本文中，我們將滑動視窗方法擴展到 $3$-目標公式，以解決機會受約束問題。在理論方面，我們展示了我們新的滑動視窗方法改進了 (Neumann 和 Witt，GECCO 2023) 中獲得的先前執行時間界限，同時維持相同的近似保證。我們對機會受約束支配集合問題的實驗調查顯示，我們新的滑動視窗方法允許人們以比 (Neumann 和 Witt，GECCO 2023) 中提出的 3 目標方法更有效率的方式解決更大的實例。

##### **Sexism Detection on a Data Diet**
2406.04892v1 by Rabiraj Bandyopadhyay, Dennis Assenmacher, Jose M. Alonso Moral, Claudia Wagner

There is an increase in the proliferation of online hate commensurate with
the rise in the usage of social media. In response, there is also a significant
advancement in the creation of automated tools aimed at identifying harmful
text content using approaches grounded in Natural Language Processing and Deep
Learning. Although it is known that training Deep Learning models require a
substantial amount of annotated data, recent line of work suggests that models
trained on specific subsets of the data still retain performance comparable to
the model that was trained on the full dataset. In this work, we show how we
can leverage influence scores to estimate the importance of a data point while
training a model and designing a pruning strategy applied to the case of sexism
detection. We evaluate the model performance trained on data pruned with
different pruning strategies on three out-of-domain datasets and find, that in
accordance with other work a large fraction of instances can be removed without
significant performance drop. However, we also discover that the strategies for
pruning data, previously successful in Natural Language Inference tasks, do not
readily apply to the detection of harmful content and instead amplify the
already prevalent class imbalance even more, leading in the worst-case to a
complete absence of the hateful class.

摘要：隨著社群媒體使用率的增加，網路上的仇恨言論也隨之增加。作為回應，使用自然語言處理與深度學習方法來識別有害文字內容的自動化工具也大幅進步。雖然已知訓練深度學習模型需要大量的註解資料，但最近的研究顯示，在特定子集資料上訓練的模型，其效能仍可與在完整資料集上訓練的模型相提並論。在這項研究中，我們展示如何利用影響力分數來評估資料點在訓練模型和設計應用於性別歧視偵測的剪枝策略時的重要性。我們評估在採用不同剪枝策略剪枝的資料上訓練的模型效能，使用三個領域外資料集，發現與其他研究一致，可以移除大量實例而不會顯著降低效能。然而，我們也發現，先前在自然語言推論任務中成功的資料剪枝策略，並不適用於有害內容的偵測，反而會進一步擴大已經普遍存在的類別不平衡，在最壞的情況下，會完全沒有仇恨類別。

##### **Enhancing Indoor Temperature Forecasting through Synthetic Data in Low-Data Environments**
2406.04890v1 by Zachari Thiry, Massimiliano Ruocco, Alessandro Nocente, Michail Spitieris

Forecasting indoor temperatures is important to achieve efficient control of
HVAC systems. In this task, the limited data availability presents a challenge
as most of the available data is acquired during standard operation where
extreme scenarios and transitory regimes such as major temperature increases or
decreases are de-facto excluded. Acquisition of such data requires significant
energy consumption and a dedicated facility, hindering the quantity and
diversity of available data. Cost related constraints however do not allow for
continuous year-around acquisition. To address this, we investigate the
efficacy of data augmentation techniques leveraging SoTA AI-based methods for
synthetic data generation. Inspired by practical and experimental motivations,
we explore fusion strategies of real and synthetic data to improve forecasting
models. This approach alleviates the need for continuously acquiring extensive
time series data, especially in contexts involving repetitive heating and
cooling cycles in buildings. In our evaluation 1) we assess the performance of
synthetic data generators independently, particularly focusing on SoTA AI-based
methods; 2) we measure the utility of incorporating synthetically augmented
data in a subsequent forecasting tasks where we employ a simple model in two
distinct scenarios: 1) we first examine an augmentation technique that combines
real and synthetically generated data to expand the training dataset, 2) we
delve into utilizing synthetic data to tackle dataset imbalances. Our results
highlight the potential of synthetic data augmentation in enhancing forecasting
accuracy while mitigating training variance. Through empirical experiments, we
show significant improvements achievable by integrating synthetic data, thereby
paving the way for more robust forecasting models in low-data regime.

摘要：預測室內溫度對於有效控制 HVAC 系統非常重要。在此任務中，有限的資料可用性是一個挑戰，因為大多數可用資料是在標準操作期間取得的，其中極端情況和暫態狀態（例如溫度大幅升高或降低）實際上已被排除在外。取得此類資料需要大量能源消耗和專用設施，這會妨礙可用資料的數量和多樣性。然而，與成本相關的限制不允許持續全年取得資料。為了解決這個問題，我們探討了資料擴充技術的功效，並利用了用於合成資料生成的 SoTA AI 方法。受到實際和實驗動機的啟發，我們探索了真實資料和合成資料的融合策略，以改善預測模型。這種方法減輕了持續取得廣泛時間序列資料的需求，特別是在涉及建築物中重複加熱和冷卻週期的情況中。在我們的評估中，1) 我們獨立評估合成資料生成器的效能，特別著重於基於 SoTA AI 的方法；2) 我們測量在後續預測任務中加入合成擴充資料的效用，我們在兩個不同的情境中採用一個簡單的模型：1) 我們首先檢查一種擴充技術，該技術結合真實資料和合成產生的資料來擴充訓練資料集，2) 我們深入探討利用合成資料來解決資料集不平衡的問題。我們的結果突出了合成資料擴充在提高預測準確度方面的潛力，同時減輕了訓練變異。透過實證實驗，我們展示了透過整合合成資料可以實現顯著的改善，從而為低資料量狀態下的更強健預測模型鋪平道路。

##### **Seeing the Unseen: Visual Metaphor Captioning for Videos**
2406.04886v1 by Abisek Rajakumar Kalarani, Pushpak Bhattacharyya, Sumit Shekhar

Metaphors are a common communication tool used in our day-to-day life. The
detection and generation of metaphors in textual form have been studied
extensively but metaphors in other forms have been under-explored. Recent
studies have shown that Vision-Language (VL) models cannot understand visual
metaphors in memes and adverts. As of now, no probing studies have been done
that involve complex language phenomena like metaphors with videos. Hence, we
introduce a new VL task of describing the metaphors present in the videos in
our work. To facilitate this novel task, we construct and release a manually
created dataset with 705 videos and 2115 human-written captions, along with a
new metric called Average Concept Distance (ACD), to automatically evaluate the
creativity of the metaphors generated. We also propose a novel low-resource
video metaphor captioning system: GIT-LLaVA, which obtains comparable
performance to SoTA video language models on the proposed task. We perform a
comprehensive analysis of existing video language models on this task and
publish our dataset, models, and benchmark results to enable further research.

摘要：隱喻是我們日常生活中常見的溝通工具。
文字形式的隱喻偵測和生成已被廣泛研究，但其他形式的隱喻卻鮮少被探討。最近的研究顯示，視覺語言 (VL) 模型無法理解迷因和廣告中的視覺隱喻。目前尚未進行任何探討研究涉及複雜的語言現象，例如影片中的隱喻。因此，我們的工作中介紹了一項新的 VL 任務，用於描述影片中存在的隱喻。為了促進這項新任務，我們構建並發布了一個手動建立的資料集，其中包含 705 部影片和 2115 個由人撰寫的字幕，以及一個稱為平均概念距離 (ACD) 的新指標，用於自動評估所生成隱喻的創意性。我們還提出了一個新穎的低資源影片隱喻字幕系統：GIT-LLaVA，它在所提出的任務上獲得了與 SoTA 影片語言模型相當的效能。我們對現有的影片語言模型進行了全面的分析，並發布了我們的資料集、模型和基準測試結果，以促進進一步的研究。

##### **InstructNav: Zero-shot System for Generic Instruction Navigation in Unexplored Environment**
2406.04882v1 by Yuxing Long, Wenzhe Cai, Hongcheng Wang, Guanqi Zhan, Hao Dong

Enabling robots to navigate following diverse language instructions in
unexplored environments is an attractive goal for human-robot interaction.
However, this goal is challenging because different navigation tasks require
different strategies. The scarcity of instruction navigation data hinders
training an instruction navigation model with varied strategies. Therefore,
previous methods are all constrained to one specific type of navigation
instruction. In this work, we propose InstructNav, a generic instruction
navigation system. InstructNav makes the first endeavor to handle various
instruction navigation tasks without any navigation training or pre-built maps.
To reach this goal, we introduce Dynamic Chain-of-Navigation (DCoN) to unify
the planning process for different types of navigation instructions.
Furthermore, we propose Multi-sourced Value Maps to model key elements in
instruction navigation so that linguistic DCoN planning can be converted into
robot actionable trajectories. With InstructNav, we complete the R2R-CE task in
a zero-shot way for the first time and outperform many task-training methods.
Besides, InstructNav also surpasses the previous SOTA method by 10.48% on the
zero-shot Habitat ObjNav and by 86.34% on demand-driven navigation DDN. Real
robot experiments on diverse indoor scenes further demonstrate our method's
robustness in coping with the environment and instruction variations.

摘要：讓機器人在未探索的環境中遵循不同的語言指令進行導航，是人機互動的一個有吸引力的目標。然而，這個目標具有挑戰性，因為不同的導航任務需要不同的策略。指令導航數據的稀缺性阻礙了訓練具有不同策略的指令導航模型。因此，先前的所有方法都受到一種特定類型的導航指令的約束。在這項工作中，我們提出了 InstructNav，一個通用的指令導航系統。InstructNav 首次嘗試處理各種指令導航任務，而無需任何導航訓練或預建地圖。為了實現這個目標，我們引入了動態導航鏈 (DCoN)，以統一不同類型導航指令的規劃過程。此外，我們提出了多來源值映射，用於對指令導航中的關鍵元素進行建模，以便將語言 DCoN 規劃轉換為機器人可操作的軌跡。使用 InstructNav，我們首次以零次學習的方式完成了 R2R-CE 任務，並且優於許多任務訓練方法。此外，InstructNav 在零次學習 Habitat ObjNav 上也比先前的 SOTA 方法高出 10.48%，在需求驅動導航 DDN 上高出 86.34%。在不同室內場景中的真實機器人實驗進一步證明了我們的方法在應對環境和指令變化方面的魯棒性。

##### **A Deep Dive into the Trade-Offs of Parameter-Efficient Preference Alignment Techniques**
2406.04879v1 by Megh Thakkar, Quentin Fournier, Matthew D Riemer, Pin-Yu Chen, Amal Zouaq, Payel Das, Sarath Chandar

Large language models are first pre-trained on trillions of tokens and then
instruction-tuned or aligned to specific preferences. While pre-training
remains out of reach for most researchers due to the compute required,
fine-tuning has become affordable thanks to parameter-efficient methods such as
LoRA and QLoRA. Alignment is known to be sensitive to the many factors
involved, including the quantity and quality of data, the alignment method, and
the adapter rank. However, there has not yet been an extensive study of their
effect on downstream performance. To address this gap, we conduct an in-depth
investigation of the impact of popular choices for three crucial axes: (i) the
alignment dataset (HH-RLHF and BeaverTails), (ii) the alignment technique (SFT
and DPO), and (iii) the model (LLaMA-1, Vicuna-v1.3, Mistral-7b, and
Mistral-7b-Instruct). Our extensive setup spanning over 300 experiments reveals
consistent trends and unexpected findings. We observe how more informative data
helps with preference alignment, cases where supervised fine-tuning outperforms
preference optimization, and how aligning to a distinct preference boosts
performance on downstream tasks. Through our in-depth analyses, we put forward
key guidelines to help researchers perform more effective parameter-efficient
LLM alignment.

摘要：大型語言模型首先在數兆個代幣上進行預訓練，然後進行指令調整或針對特定偏好進行調整。雖然預訓練由於所需的運算而對大多數研究人員來說遙不可及，但由於參數高效的方法（例如 LoRA 和 QLoRA），微調已變得負擔得起。眾所周知，對齊對所涉及的許多因素很敏感，包括數據的數量和質量、對齊方法和適配器等級。然而，尚未對它們對下游性能的影響進行廣泛的研究。為了解決這一差距，我們對三項關鍵軸的流行選擇的影響進行了深入調查：(i) 對齊數據集（HH-RLHF 和 BeaverTails），(ii) 對齊技術（SFT 和 DPO），以及 (iii) 模型（LLaMA-1、Vicuna-v1.3、Mistral-7b 和 Mistral-7b-Instruct）。我們涵蓋 300 多個實驗的廣泛設置揭示了一致的趨勢和意外的發現。我們觀察到更多信息豐富的數據如何幫助偏好對齊、監督微調優於偏好優化的案例，以及對齊不同的偏好如何提升下游任務的性能。通過我們的深入分析，我們提出了關鍵指南，以幫助研究人員執行更有效的參數高效 LLM 對齊。

##### **HateDebias: On the Diversity and Variability of Hate Speech Debiasing**
2406.04876v1 by Nankai Lin, Hongyan Wu, Zhengming Chen, Zijian Li, Lianxi Wang, Shengyi Jiang, Dong Zhou, Aimin Yang

Hate speech on social media is ubiquitous but urgently controlled. Without
detecting and mitigating the biases brought by hate speech, different types of
ethical problems. While a number of datasets have been proposed to address the
problem of hate speech detection, these datasets seldom consider the diversity
and variability of bias, making it far from real-world scenarios. To fill this
gap, we propose a benchmark, named HateDebias, to analyze the model ability of
hate speech detection under continuous, changing environments. Specifically, to
meet the diversity of biases, we collect existing hate speech detection
datasets with different types of biases. To further meet the variability (i.e.,
the changing of bias attributes in datasets), we reorganize datasets to follow
the continuous learning setting. We evaluate the detection accuracy of models
trained on the datasets with a single type of bias with the performance on the
HateDebias, where a significant performance drop is observed. To provide a
potential direction for debiasing, we further propose a debiasing framework
based on continuous learning and bias information regularization, as well as
the memory replay strategies to ensure the debiasing ability of the model.
Experiment results on the proposed benchmark show that the aforementioned
method can improve several baselines with a distinguished margin, highlighting
its effectiveness in real-world applications.

摘要：社群媒體上的仇恨言論無所不在，但迫切需要加以管制。如果不偵測並減輕仇恨言論帶來的偏見，就會產生各種不同的倫理問題。雖然已經提出許多資料集來解決仇恨言論偵測的問題，但這些資料集很少考慮偏見的多樣性和可變性，這使得它們遠離真實世界的場景。為了填補這個差距，我們提出了一個名為 HateDebias 的基準，用於分析在持續變化的環境下仇恨言論偵測模型的能力。具體來說，為了滿足偏見的多樣性，我們收集了具有不同類型偏見的現有仇恨言論偵測資料集。為了進一步滿足可變性（即資料集中偏見屬性的變化），我們重新組織資料集以遵循持續學習設定。我們評估在單一類型偏見資料集上訓練的模型的偵測準確度，以及在 HateDebias 上的表現，其中觀察到顯著的效能下降。為了提供一個去偏見的潛在方向，我們進一步提出一個基於持續學習和偏見資訊正規化的去偏見架構，以及記憶體重播策略，以確保模型的去偏見能力。在所提出的基準上進行的實驗結果表明，上述方法可以顯著改善幾個基準，突顯其在實際應用中的有效性。

##### **Ada-VE: Training-Free Consistent Video Editing Using Adaptive Motion Prior**
2406.04873v1 by Tanvir Mahmud, Mustafa Munir, Radu Marculescu, Diana Marculescu

Video-to-video synthesis models face significant challenges, such as ensuring
consistent character generation across frames, maintaining smooth temporal
transitions, and preserving quality during fast motion. The introduction of
joint fully cross-frame self-attention mechanisms has improved character
consistency, but this comes at the cost of increased computational complexity.
This full cross-frame self-attention mechanism also incorporates redundant
details and limits the number of frames that can be jointly edited due to its
computational cost. Moreover, the lack of frames in cross-frame attention
adversely affects temporal consistency and visual quality. To address these
limitations, we propose a new adaptive motion-guided cross-frame attention
mechanism that drastically reduces complexity while preserving semantic details
and temporal consistency. Specifically, we selectively incorporate the moving
regions of successive frames in cross-frame attention and sparsely include
stationary regions based on optical flow sampling. This technique allows for an
increased number of jointly edited frames without additional computational
overhead. For longer duration of video editing, existing methods primarily
focus on frame interpolation or flow-warping from jointly edited keyframes,
which often results in blurry frames or reduced temporal consistency. To
improve this, we introduce KV-caching of jointly edited frames and reuse the
same KV across all intermediate frames, significantly enhancing both
intermediate frame quality and temporal consistency. Overall, our
motion-sampling method enables the use of around three times more keyframes
than existing joint editing methods while maintaining superior prediction
quality. Ada-VE achieves up to 4x speed-up when using fully-extended
self-attention across 40 frames for joint editing, without compromising visual
quality or temporal consistency.

摘要：影片到影片的合成模型面临着重大的挑战，例如确保整个帧中角色生成的一致性、维持流畅的时间转换，以及在快速移动过程中保持质量。引入联合全帧自注意力机制改善了角色一致性，但这以增加计算复杂性为代价。这种全帧自注意力机制还纳入了冗余的细节，并由于其计算成本而限制了可以联合编辑的帧数。此外，跨帧注意力中缺少帧对时间一致性和视觉质量产生不利影响。为了解决这些限制，我们提出了一种新的自适应运动引导的跨帧注意力机制，该机制大幅降低了复杂性，同时保留了语义细节和时间一致性。具体来说，我们在跨帧注意力中选择性地纳入连续帧的移动区域，并基于光流采样稀疏地包含静止区域。此技术允许增加联合编辑的帧数，而不会增加额外的计算开销。对于较长时间的影片编辑，现有方法主要集中在从联合编辑的关键帧进行帧插值或流变形，这通常会导致模糊的帧或降低的时间一致性。为了改善这一点，我们在联合编辑的帧中引入了 KV 缓存，并在所有中间帧中重复使用相同的 KV，从而显著提高了中间帧质量和时间一致性。总体而言，我们的运动采样方法能够比现有的联合编辑方法使用大约三倍的关键帧，同时保持卓越的预测质量。Ada-VE 在联合编辑 40 帧时使用完全扩展的自注意力时实现了高达 4 倍的加速，而不会损害视觉质量或时间一致性。

##### **Deep learning for precipitation nowcasting: A survey from the perspective of time series forecasting**
2406.04867v1 by Sojung An, Tae-Jin Oh, Eunha Sohn, Donghyun Kim

Deep learning-based time series forecasting has dominated the short-term
precipitation forecasting field with the help of its ability to estimate motion
flow in high-resolution datasets. The growing interest in precipitation
nowcasting offers substantial opportunities for the advancement of current
forecasting technologies. Nevertheless, there has been a scarcity of in-depth
surveys of time series precipitation forecasting using deep learning. Thus,
this paper systemically reviews recent progress in time series precipitation
forecasting models. Specifically, we investigate the following key points
within background components, covering: i) preprocessing, ii) objective
functions, and iii) evaluation metrics. We then categorize forecasting models
into \textit{recursive} and \textit{multiple} strategies based on their
approaches to predict future frames, investigate the impacts of models using
the strategies, and performance assessments. Finally, we evaluate current deep
learning-based models for precipitation forecasting on a public benchmark,
discuss their limitations and challenges, and present some promising research
directions. Our contribution lies in providing insights for a better
understanding of time series precipitation forecasting and in aiding the
development of robust AI solutions for the future.

摘要：<paragraph>基於深度學習的時間序列預測，在高解析度資料集估計運動流動的能力幫助下，已主導了短期降水預測領域。對降水臨近預測日益增長的需求，為當前預測技術的進步提供了大量的機會。儘管如此，使用深度學習進行時間序列降水預測的深入調查卻很稀少。因此，本文系統性地回顧了時間序列降水預測模型的最新進展。具體來說，我們針對背景組成部分探討以下重點：i) 前處理、ii) 目標函數和 iii) 評估指標。然後，我們根據預測未來幀的方法，將預測模型分類為\textit{遞迴}和\textit{多重}策略，探討使用這些策略的模型的影響，以及效能評估。最後，我們在公開基準上評估了當前基於深度學習的降水預測模型，討論它們的限制和挑戰，並提出一些有希望的研究方向。我們的貢獻在於提供見解，以更好地理解時間序列降水預測，並協助開發未來穩健的人工智慧解決方案。</paragraph>

##### **ComplexTempQA: A Large-Scale Dataset for Complex Temporal Question Answering**
2406.04866v1 by Raphael Gruber, Abdelrahman Abdallah, Michael Färber, Adam Jatowt

We introduce ComplexTempQA,a large-scale dataset consisting of over 100
million question-answer pairs designed to tackle the challenges in temporal
question answering. ComplexTempQA significantly surpasses existing benchmarks
like HOTPOTQA, TORQUE, and TEQUILA in scale and scope. Utilizing data from
Wikipedia and Wikidata, the dataset covers questions spanning over two decades
and offers an unmatched breadth of topics. We introduce a unique taxonomy that
categorizes questions as attributes, comparisons, and counting questions, each
revolving around events, entities, and time periods. One standout feature of
ComplexTempQA is the high complexity of its questions, which demand effective
capabilities for answering such as across-time comparison, temporal
aggregation, and multi-hop reasoning involving temporal event ordering and
entity recognition. Additionally, each question is accompanied by detailed
metadata, including specific time scopes, allowing for comprehensive evaluation
and enhancement of the temporal reasoning abilities of large language models.
ComplexTempQA serves both as a testing ground for developing sophisticated AI
models and as a foundation for advancing research in question answering,
information retrieval, and language understanding. Dataset and code are freely
available at: https://github.com/DataScienceUIBK/ComplexTempQA.

摘要：我們引入了 ComplexTempQA，一個由超過 1 億個問答對組成的大規模資料集，旨在解決時序問答中的挑戰。ComplexTempQA 在規模和範圍上都顯著超越了現有的基準，例如 HOTPOTQA、TORQUE 和 TEQUILA。利用來自維基百科和 Wikidata 的資料，該資料集涵蓋了跨越二十年的問題，並提供了無與倫比的主題廣度。我們引入了獨特的分類法，將問題分類為屬性、比較和計數問題，每個問題都圍繞事件、實體和時間段展開。ComplexTempQA 的一個突出特點是其問題的高度複雜性，這需要有效的回答能力，例如跨時間比較、時間聚合以及涉及時間事件排序和實體識别的多跳推理。此外，每個問題都附有詳細的元資料，包括具體的時間範圍，允許對大型語言模型的時間推理能力進行全面的評估和增強。ComplexTempQA 既可用作開發複雜 AI 模型的測試場域，也可用作推進問答、資訊檢索和語言理解研究的基礎。資料集和程式碼可免費取得：https://github.com/DataScienceUIBK/ComplexTempQA。

##### **Uncertainty Aware Learning for Language Model Alignment**
2406.04854v1 by Yikun Wang, Rui Zheng, Liang Ding, Qi Zhang, Dahua Lin, Dacheng Tao

As instruction-tuned large language models (LLMs) evolve, aligning pretrained
foundation models presents increasing challenges. Existing alignment
strategies, which typically leverage diverse and high-quality data sources,
often overlook the intrinsic uncertainty of tasks, learning all data samples
equally. This may lead to suboptimal data efficiency and model performance. In
response, we propose uncertainty-aware learning (UAL) to improve the model
alignment of different task scenarios, by introducing the sample uncertainty
(elicited from more capable LLMs). We implement UAL in a simple fashion --
adaptively setting the label smoothing value of training according to the
uncertainty of individual samples. Analysis shows that our UAL indeed
facilitates better token clustering in the feature space, validating our
hypothesis. Extensive experiments on widely used benchmarks demonstrate that
our UAL significantly and consistently outperforms standard supervised
fine-tuning. Notably, LLMs aligned in a mixed scenario have achieved an average
improvement of 10.62\% on high-entropy tasks (i.e., AlpacaEval leaderboard),
and 1.81\% on complex low-entropy tasks (i.e., MetaMath and GSM8K).

摘要：隨著指令微調大型語言模型 (LLM) 的演進，比對預訓練基礎模型面臨的挑戰越來越大。現有的比對策略通常利用多樣且高品質的資料來源，卻常常忽略任務的內在不確定性，一視同仁地學習所有資料樣本。這可能會導致次佳的資料效率和模型效能。為了解決這個問題，我們提出不確定性感知學習 (UAL)，透過引入樣本不確定性（從更強大的 LLM 獲得），來改善不同任務場景的模型比對。我們以一種簡單的方式實作 UAL，根據個別樣本的不確定性，自適應地設定訓練的標籤平滑值。分析顯示，我們的 UAL 確實促進了特徵空間中更好的標記聚類，驗證了我們的假設。在廣泛使用的基準上進行的大量實驗證明，我們的 UAL 明顯且持續地優於標準監督微調。值得注意的是，在混合場景中比對的 LLM 在高熵任務（即 AlpacaEval 排行榜）上平均提升了 10.62%，在複雜低熵任務（即 MetaMath 和 GSM8K）上提升了 1.81%。

##### **Do Language Models Exhibit Human-like Structural Priming Effects?**
2406.04847v1 by Jaap Jumelet, Willem Zuidema, Arabella Sinclair

We explore which linguistic factors -- at the sentence and token level --
play an important role in influencing language model predictions, and
investigate whether these are reflective of results found in humans and human
corpora (Gries and Kootstra, 2017). We make use of the structural priming
paradigm, where recent exposure to a structure facilitates processing of the
same structure. We don't only investigate whether, but also where priming
effects occur, and what factors predict them. We show that these effects can be
explained via the inverse frequency effect, known in human priming, where rarer
elements within a prime increase priming effects, as well as lexical dependence
between prime and target. Our results provide an important piece in the puzzle
of understanding how properties within their context affect structural
prediction in language models.

摘要：我們探討了哪些語言因素——在句子和詞彙層面——在影響語言模型預測中扮演重要角色，並探討這些因素是否反映了人類和人類語料庫中發現的結果（Gries 和 Kootstra，2017 年）。我們利用結構啟動範式，其中最近接觸結構有助於處理相同結構。我們不僅探討啟動效應是否發生，還探討它們發生在哪裡，以及哪些因素預測它們。我們表明，這些效應可以用人類啟動中已知的逆頻率效應來解釋，其中啟動中的較罕見元素會增加啟動效應，以及啟動和目標之間的詞彙依賴性。我們的結果為理解上下文中的屬性如何影響語言模型中的結構預測提供了拼圖中的一塊重要部分。

##### **FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models**
2406.04845v1 by Rui Ye, Rui Ge, Xinyu Zhu, Jingyi Chai, Yaxin Du, Yang Liu, Yanfeng Wang, Siheng Chen

Federated learning has enabled multiple parties to collaboratively train
large language models without directly sharing their data (FedLLM). Following
this training paradigm, the community has put massive efforts from diverse
aspects including framework, performance, and privacy. However, an unpleasant
fact is that there are currently no realistic datasets and benchmarks for
FedLLM and previous works all rely on artificially constructed datasets,
failing to capture properties in real-world scenarios. Addressing this, we
propose FedLLM-Bench, which involves 8 training methods, 4 training datasets,
and 6 evaluation metrics, to offer a comprehensive testbed for the FedLLM
community. FedLLM-Bench encompasses three datasets (e.g., user-annotated
multilingual dataset) for federated instruction tuning and one dataset (e.g.,
user-annotated preference dataset) for federated preference alignment, whose
scale of client number ranges from 38 to 747. Our datasets incorporate several
representative diversities: language, quality, quantity, instruction, length,
embedding, and preference, capturing properties in real-world scenarios. Based
on FedLLM-Bench, we conduct experiments on all datasets to benchmark existing
FL methods and provide empirical insights (e.g., multilingual collaboration).
We believe that our FedLLM-Bench can benefit the FedLLM community by reducing
required efforts, providing a practical testbed, and promoting fair
comparisons. Code and datasets are available at
https://github.com/rui-ye/FedLLM-Bench.

摘要：<paragraph>聯合學習讓多方能夠在不直接分享資料的情況下，共同訓練大型語言模型（FedLLM）。遵循此訓練範例，社群從架構、效能和隱私等不同面向投入大量心力。然而，令人不悅的事實是，目前沒有 FedLLM 的實際資料集和基準，而先前的研究都依賴人工建構的資料集，無法捕捉真實世界場景中的屬性。為了解決這個問題，我們提出了 FedLLM-Bench，其中包含 8 種訓練方法、4 個訓練資料集和 6 個評估指標，為 FedLLM 社群提供一個全面的測試平台。FedLLM-Bench 涵蓋了三個資料集（例如，使用者標註的多語言資料集），用於聯合式指令調整，以及一個資料集（例如，使用者標註的偏好資料集），用於聯合式偏好比對，其客戶端數量規模介於 38 到 747 之間。我們的資料集包含了多種代表性的多樣性：語言、品質、數量、指令、長度、嵌入和偏好，捕捉了真實世界場景中的屬性。基於 FedLLM-Bench，我們對所有資料集進行實驗，以評量現有的聯合學習方法，並提供實證見解（例如，多語言協作）。我們相信我們的 FedLLM-Bench 可以透過減少所需的工作、提供實用的測試平台和促進公平的比較，對 FedLLM 社群有益。程式碼和資料集可在 https://github.com/rui-ye/FedLLM-Bench 取得。</paragraph>

##### **Algorithms for learning value-aligned policies considering admissibility relaxation**
2406.04838v1 by Andrés Holgado-Sánchez, Joaquín Arias, Holger Billhardt, Sascha Ossowski

The emerging field of \emph{value awareness engineering} claims that software
agents and systems should be value-aware, i.e. they must make decisions in
accordance with human values. In this context, such agents must be capable of
explicitly reasoning as to how far different courses of action are aligned with
these values. For this purpose, values are often modelled as preferences over
states or actions, which are then aggregated to determine the sequences of
actions that are maximally aligned with a certain value. Recently, additional
value admissibility constraints at this level have been considered as well.
  However, often relaxed versions of these constraints are needed, and this
increases considerably the complexity of computing value-aligned policies. To
obtain efficient algorithms that make value-aligned decisions considering
admissibility relaxation, we propose the use of learning techniques, in
particular, we have used constrained reinforcement learning algorithms. In this
paper, we present two algorithms, $\epsilon\text{-}ADQL$ for strategies based
on local alignment and its extension $\epsilon\text{-}CADQL$ for a sequence of
decisions. We have validated their efficiency in a water distribution problem
in a drought scenario.

摘要：<paragraph>新興的「價值意識工程」領域主張軟體代理和系統應具備價值意識，也就是說，他們必須根據人類價值觀做出決策。在此脈絡下，這些代理必須有能力明確推論不同行動方案與這些價值觀的一致性。為此，價值通常會被建模為對狀態或行動的偏好，然後進行彙總，以確定與特定價值最一致的行動順序。最近，此層級中也考慮了額外的價值可容許性約束。
然而，通常需要這些約束的放寬版本，而這會大幅增加計算價值對齊政策的複雜性。為了取得在考量可容許性放寬的情況下做出價值對齊決策的高效演算法，我們建議使用學習技術，特別是，我們使用了受限強化學習演算法。在本文中，我們提出兩種演算法，$\epsilon\text{-}ADQL$ 適用於基於局部對齊的策略，而其延伸 $\epsilon\text{-}CADQL$ 適用於一系列決策。我們在乾旱情境中的配水問題中驗證了它們的效率。</paragraph>

##### **Revisiting Catastrophic Forgetting in Large Language Model Tuning**
2406.04836v1 by Hongyu Li, Liang Ding, Meng Fang, Dacheng Tao

Catastrophic Forgetting (CF) means models forgetting previously acquired
knowledge when learning new data. It compromises the effectiveness of large
language models (LLMs) during fine-tuning, yet the underlying causes have not
been thoroughly investigated. This paper takes the first step to reveal the
direct link between the flatness of the model loss landscape and the extent of
CF in the field of LLMs. Based on this, we introduce the sharpness-aware
minimization to mitigate CF by flattening the loss landscape. Experiments on
three widely-used fine-tuning datasets, spanning different model scales,
demonstrate the effectiveness of our method in alleviating CF. Analyses show
that we nicely complement the existing anti-forgetting strategies, further
enhancing the resistance of LLMs to CF.

摘要：災難性遺忘 (CF) 意指模型在學習新資料時，遺忘先前已習得的知識。它會影響大型語言模型 (LLM) 在微調期間的效能，但其背後原因尚未徹底探究。本文採取第一步，揭露模型損失函數曲面的平坦度與 LLM 領域中 CF 程度之間的直接關聯。基於此，我們引進銳利度感知最小化，藉由平坦化損失函數曲面來減輕 CF。針對三個廣泛使用的微調資料集進行的實驗，涵蓋不同模型規模，證明了我們的方法在減輕 CF 方面的效能。分析顯示，我們很好地補充了現有的反遺忘策略，進一步增強 LLM 對 CF 的抵抗力。

##### **Annotating FrameNet via Structure-Conditioned Language Generation**
2406.04834v1 by Xinyue Cui, Swabha Swayamdipta

Despite the remarkable generative capabilities of language models in
producing naturalistic language, their effectiveness on explicit manipulation
and generation of linguistic structures remain understudied. In this paper, we
investigate the task of generating new sentences preserving a given semantic
structure, following the FrameNet formalism. We propose a framework to produce
novel frame-semantically annotated sentences following an
overgenerate-and-filter approach. Our results show that conditioning on rich,
explicit semantic information tends to produce generations with high human
acceptance, under both prompting and finetuning. Our generated frame-semantic
structured annotations are effective at training data augmentation for
frame-semantic role labeling in low-resource settings; however, we do not see
benefits under higher resource settings. Our study concludes that while
generating high-quality, semantically rich data might be within reach, the
downstream utility of such generations remains to be seen, highlighting the
outstanding challenges with automating linguistic annotation tasks.

摘要：儘管語言模型在產生自然語言方面具有顯著的生成能力，但它們在語言結構的明確操作和生成方面的效能仍未受到充分的研究。在本文中，我們探討了根據 FrameNet 形式主義，生成保留既定語義結構的新句子的任務。我們提出了一個框架來產生新的框架語義註解句子，遵循過度生成和過濾方法。我們的結果表明，在提示和微調下，以豐富、明確的語義資訊為條件往往會產生人類高度接受的生成。我們生成的框架語義結構化註解對於在低資源環境中訓練用於框架語義角色標記的資料擴充非常有效；然而，我們在較高資源環境下並未看到好處。我們的研究結論是，儘管生成高品質、語義豐富的資料可能觸手可及，但此類生成的後續效用仍有待觀察，突顯了自動化語言註解任務的傑出挑戰。

##### **Graph Mining under Data scarcity**
2406.04825v1 by Appan Rakaraddi, Lam Siew-Kei, Mahardhika Pratama, Marcus de Carvalho

Multitude of deep learning models have been proposed for node classification
in graphs. However, they tend to perform poorly under labeled-data scarcity.
Although Few-shot learning for graphs has been introduced to overcome this
problem, the existing models are not easily adaptable for generic graph
learning frameworks like Graph Neural Networks (GNNs). Our work proposes an
Uncertainty Estimator framework that can be applied on top of any generic GNN
backbone network (which are typically designed for supervised/semi-supervised
node classification) to improve the node classification performance. A neural
network is used to model the Uncertainty Estimator as a probability
distribution rather than probabilistic discrete scalar values. We train these
models under the classic episodic learning paradigm in the $n$-way, $k$-shot
fashion, in an end-to-end setting.
  Our work demonstrates that implementation of the uncertainty estimator on a
GNN backbone network improves the classification accuracy under Few-shot
setting without any meta-learning specific architecture. We conduct experiments
on multiple datasets under different Few-shot settings and different GNN-based
backbone networks. Our method outperforms the baselines, which demonstrates the
efficacy of the Uncertainty Estimator for Few-shot node classification on
graphs with a GNN.

摘要：在圖表中，已經提出了大量的深度學習模型用於節點分類。然而，它們在標記資料稀少的情況下往往表現不佳。儘管已經引入圖形少發學習來克服這個問題，但現有的模型不易適應通用圖形學習框架，例如圖形神經網路 (GNN)。我們的研究提出了一個不確定性估計器框架，可以應用於任何通用 GNN 主幹網路（通常設計用於監督式/半監督式節點分類）之上，以改善節點分類性能。神經網路用於將不確定性估計器建模為機率分佈，而不是機率離散標量值。我們在 $n$ 路，$k$ 發的經典情節學習範例中，以端到端設定訓練這些模型。我們的研究表明，在 GNN 主幹網路中實施不確定性估計器可以改善少發設定下的分類準確度，而無需任何特定於元學習的架構。我們在不同的少發設定和不同的基於 GNN 的主幹網路下，對多個資料集進行實驗。我們的模型優於基準，這證明了不確定性估計器在 GNN 上的圖形少發節點分類中的效能。

##### **BERTs are Generative In-Context Learners**
2406.04823v1 by David Samuel

This paper explores the in-context learning capabilities of masked language
models, challenging the common view that this ability does not 'emerge' in
them. We present an embarrassingly simple inference technique that enables
DeBERTa to operate as a generative model without any additional training. Our
findings demonstrate that DeBERTa can match and even surpass GPT-3, its
contemporary that famously introduced the paradigm of in-context learning. The
comparative analysis reveals that the masked and causal language models behave
very differently, as they clearly outperform each other on different categories
of tasks. This suggests that there is great potential for a hybrid training
approach that takes advantage of the strengths of both training objectives.

摘要：本文探討了遮蔽語言模型的語境學習能力，挑戰了此項能力並未「浮現」於此類模型中的普遍觀點。我們提出了一種令人尷尬的簡單推論技術，讓 DeBERTa 能夠在沒有任何額外訓練的情況下作為生成模型運作。我們的研究結果證明，DeBERTa 能夠匹敵甚至超越 GPT-3，後者是著名的語境學習典範。比較分析顯示，遮蔽語言模型和因果語言模型的行為非常不同，因為它們在不同類別的任務上明顯表現得比對方出色。這表明，一種利用兩種訓練目標優勢的混合訓練方法具有巨大的潛力。

##### **Navigating Efficiency in MobileViT through Gaussian Process on Global Architecture Factors**
2406.04820v1 by Ke Meng, Kai Chen

Numerous techniques have been meticulously designed to achieve optimal
architectures for convolutional neural networks (CNNs), yet a comparable focus
on vision transformers (ViTs) has been somewhat lacking. Despite the remarkable
success of ViTs in various vision tasks, their heavyweight nature presents
challenges of computational costs. In this paper, we leverage the Gaussian
process to systematically explore the nonlinear and uncertain relationship
between performance and global architecture factors of MobileViT, such as
resolution, width, and depth including the depth of in-verted residual blocks
and the depth of ViT blocks, and joint factors including resolution-depth and
resolution-width. We present design principles twisting magic 4D cube of the
global architecture factors that minimize model sizes and computational costs
with higher model accuracy. We introduce a formula for downsizing architectures
by iteratively deriving smaller MobileViT V2, all while adhering to a specified
constraint of multiply-accumulate operations (MACs). Experiment results show
that our formula significantly outperforms CNNs and mobile ViTs across
diversified datasets

摘要：為達成卷積神經網路 (CNN) 的最佳架構，已精心設計出許多技術，但對視覺Transformer (ViT) 的關注卻相對不足。儘管 ViT 在各種視覺任務中取得顯著的成功，但其龐大特性對運算成本構成挑戰。在本文中，我們利用高斯過程系統性地探討 MobileViT 的效能與整體架構因子之間的非線性和不確定關係，例如解析度、寬度和深度，包括反轉殘差區塊的深度和 ViT 區塊的深度，以及解析度深度和解析度寬度等聯合因子。我們提出設計原則，扭曲整體架構因子的 4D 魔術方塊，以最小化模型大小和運算成本，同時提高模型準確度。我們引入一個公式，透過反覆推導較小的 MobileViT V2 來縮小架構，同時遵守乘加運算 (MAC) 的指定限制。實驗結果顯示，我們的公式在多元化的資料集上明顯優於 CNN 和行動裝置 ViT

##### **Generating Piano Practice Policy with a Gaussian Process**
2406.04812v1 by Alexandra Moringen, Elad Vromen, Helge Ritter, Jason Friedman

A typical process of learning to play a piece on a piano consists of a
progression through a series of practice units that focus on individual
dimensions of the skill, the so-called practice modes. Practice modes in
learning to play music comprise a particularly large set of possibilities, such
as hand coordination, posture, articulation, ability to read a music score,
correct timing or pitch, etc. Self-guided practice is known to be suboptimal,
and a model that schedules optimal practice to maximize a learner's progress
still does not exist. Because we each learn differently and there are many
choices for possible piano practice tasks and methods, the set of practice
modes should be dynamically adapted to the human learner, a process typically
guided by a teacher. However, having a human teacher guide individual practice
is not always feasible since it is time-consuming, expensive, and often
unavailable. In this work, we present a modeling framework to guide the human
learner through the learning process by choosing the practice modes generated
by a policy model. To this end, we present a computational architecture
building on a Gaussian process that incorporates 1) the learner state, 2) a
policy that selects a suitable practice mode, 3) performance evaluation, and 4)
expert knowledge. The proposed policy model is trained to approximate the
expert-learner interaction during a practice session. In our future work, we
will test different Bayesian optimization techniques, e.g., different
acquisition functions, and evaluate their effect on the learning progress.

摘要：<paragraph>學習彈奏鋼琴曲目的典型過程包含一系列練習單元的進展，這些練習單元專注於技能的個別面向，也就是所謂的練習模式。在學習演奏音樂時，練習模式包含一組特別大量的可能性，例如手部協調、姿勢、發音、閱讀樂譜的能力、正確的時機或音高等等。眾所周知，自我指導的練習並非最佳選擇，而且一種可以安排最佳練習以最大化學習者進度的模型仍然不存在。由於我們每個人學習的方式都不同，而且有許多可能的鋼琴練習任務和方法可供選擇，因此練習模式的設定應該動態地適應人類學習者，這是一個通常由老師指導的過程。然而，讓真人老師指導個別練習並非總是可行，因為這很耗時、昂貴，而且常常無法做到。在這項工作中，我們提出一個建模架構，透過選擇由政策模型產生的練習模式，來引導人類學習者完成學習過程。為此，我們提出一個建構於高斯過程的計算架構，它包含 1) 學習者狀態、2) 選擇適當練習模式的政策、3) 績效評估，以及 4) 專家知識。所提出的政策模型經過訓練，以近似於練習過程中專家與學習者的互動。在我們未來的研究中，我們將測試不同的貝氏最佳化技術，例如不同的獲取函數，並評估它們對學習進度的影響。</paragraph>

##### **Fragile Model Watermarking: A Comprehensive Survey of Evolution, Characteristics, and Classification**
2406.04809v1 by Zhenzhe Gao, Yu Cheng, Zhaoxia Yin

Model fragile watermarking, inspired by both the field of adversarial attacks
on neural networks and traditional multimedia fragile watermarking, has
gradually emerged as a potent tool for detecting tampering, and has witnessed
rapid development in recent years. Unlike robust watermarks, which are widely
used for identifying model copyrights, fragile watermarks for models are
designed to identify whether models have been subjected to unexpected
alterations such as backdoors, poisoning, compression, among others. These
alterations can pose unknown risks to model users, such as misidentifying stop
signs as speed limit signs in classic autonomous driving scenarios. This paper
provides an overview of the relevant work in the field of model fragile
watermarking since its inception, categorizing them and revealing the
developmental trajectory of the field, thus offering a comprehensive survey for
future endeavors in model fragile watermarking.

摘要：受到对抗性攻擊在神經網路和傳統多媒體脆弱浮水印領域的啟發，模型脆弱浮水印逐漸成為一種強有力的篡改檢測工具，並在近年來見證了快速發展。與廣泛用於識別模型版權的強健浮水印不同，模型的脆弱浮水印旨在識別模型是否遭受了後門、中毒、壓縮等意外變更。這些變更會對模型使用者造成未知的風險，例如在經典的自動駕駛場景中將停止標誌誤認為限速標誌。本文概述了模型脆弱浮水印領域自成立以來的相關工作，對它們進行分類並揭示該領域的發展軌跡，從而為模型脆弱浮水印的未來工作提供全面的調查。

##### **TEDi Policy: Temporally Entangled Diffusion for Robotic Control**
2406.04806v1 by Sigmund H. Høeg, Lars Tingelstad

Diffusion models have been shown to excel in robotic imitation learning by
mastering the challenge of modeling complex distributions. However, sampling
speed has traditionally not been a priority due to their popularity for image
generation, limiting their application to dynamical tasks. While recent work
has improved the sampling speed of diffusion-based robotic policies, they are
restricted to techniques from the image generation domain. We adapt Temporally
Entangled Diffusion (TEDi), a framework specific for trajectory generation, to
speed up diffusion-based policies for imitation learning. We introduce TEDi
Policy, with novel regimes for training and sampling, and show that it
drastically improves the sampling speed while remaining performant when applied
to state-of-the-art diffusion-based imitation learning policies.

摘要：擴散模型已證明在機器人模仿學習中表現出色，因為它們掌握了建模複雜分佈的挑戰。然而，由於它們在影像生成方面的普及性，取樣速度傳統上並非優先事項，這限制了它們在動態任務中的應用。儘管最近的研究改進了基於擴散的機器人策略的取樣速度，但它們僅限於影像生成領域的技術。我們調整了時間糾纏擴散 (TEDi)，這是一個專門用於軌跡生成的框架，以加速基於擴散的策略以進行模仿學習。我們引入了 TEDi 策略，並採用了新的訓練和取樣方案，並展示了它在應用於最先進的基於擴散的模仿學習策略時，大幅提升了取樣速度，同時仍保持效能。

##### **Zero, Finite, and Infinite Belief History of Theory of Mind Reasoning in Large Language Models**
2406.04800v1 by Weizhi Tang, Vaishak Belle

Large Language Models (LLMs) have recently shown a promise and emergence of
Theory of Mind (ToM) ability and even outperform humans in certain ToM tasks.
To evaluate and extend the boundaries of the ToM reasoning ability of LLMs, we
propose a novel concept, taxonomy, and framework, the ToM reasoning with Zero,
Finite, and Infinite Belief History and develop a multi-round text-based game,
called $\textit{Pick the Right Stuff}$, as a benchmark. We have evaluated six
LLMs with this game and found their performance on Zero Belief History is
consistently better than on Finite Belief History. In addition, we have found
two of the models with small parameter sizes outperform all the evaluated
models with large parameter sizes. We expect this work to pave the way for
future ToM benchmark development and also for the promotion and development of
more complex AI agents or systems which are required to be equipped with more
complex ToM reasoning ability.

摘要：大型語言模型 (LLM) 近期展現出心智理論 (ToM) 能力的承諾和興起，甚至在某些 ToM 任務中表現優於人類。
為了評估和擴展 LLM 的 ToM 推理能力的界限，我們提出了一個新的概念、分類法和架構，即零、有限和無限信念歷史的 ToM 推理，並開發了一個名為「選擇正確物品」的多輪文字遊戲作為基準。我們使用這個遊戲評估了六個 LLM，發現它們在零信念歷史上的表現始終優於有限信念歷史。此外，我們發現兩個參數規模較小的模型優於所有評估過的參數規模較大的模型。我們預期這項工作將為未來的 ToM 基準開發以及推廣和開發需要具備更複雜 ToM 推理能力的更複雜 AI 代理或系統鋪路。

##### **Learning-Augmented Priority Queues**
2406.04793v1 by Ziyad Benomar, Christian Coester

Priority queues are one of the most fundamental and widely used data
structures in computer science. Their primary objective is to efficiently
support the insertion of new elements with assigned priorities and the
extraction of the highest priority element. In this study, we investigate the
design of priority queues within the learning-augmented framework, where
algorithms use potentially inaccurate predictions to enhance their worst-case
performance. We examine three prediction models spanning different use cases,
and show how the predictions can be leveraged to enhance the performance of
priority queue operations. Moreover, we demonstrate the optimality of our
solution and discuss some possible applications.

摘要：優先佇列是電腦科學中最基本且廣泛使用的一種資料結構。它們的主要目標是有效支援帶有指定優先權的新元素插入，以及最高優先權元素的提取。在本研究中，我們探討了學習增強框架內的優先佇列設計，其中演算法使用潛在不準確的預測來增強它們最差情況下的效能。我們檢驗了涵蓋不同使用案例的三個預測模型，並展示了如何利用預測來增強優先佇列操作的效能。此外，我們展示了我們解決方案的最佳性，並討論了一些可能的應用。

##### **SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals**
2406.04784v1 by Ruihan Yang, Jiangjie Chen, Yikai Zhang, Siyu Yuan, Aili Chen, Kyle Richardson, Yanghua Xiao, Deqing Yang

Language agents powered by large language models (LLMs) are increasingly
valuable as decision-making tools in domains such as gaming and programming.
However, these agents often face challenges in achieving high-level goals
without detailed instructions and in adapting to environments where feedback is
delayed. In this paper, we present SelfGoal, a novel automatic approach
designed to enhance agents' capabilities to achieve high-level goals with
limited human prior and environmental feedback. The core concept of SelfGoal
involves adaptively breaking down a high-level goal into a tree structure of
more practical subgoals during the interaction with environments while
identifying the most useful subgoals and progressively updating this structure.
Experimental results demonstrate that SelfGoal significantly enhances the
performance of language agents across various tasks, including competitive,
cooperative, and deferred feedback environments. Project page:
https://selfgoal-agent.github.io.

摘要：由大型語言模型 (LLM) 提供支援的語言代理在遊戲和程式設計等領域中，作為決策工具的價值越來越高。然而，這些代理在沒有詳細指示的情況下，通常會面臨達成高層級目標的挑戰，而且在回饋延遲的環境中難以適應。在本文中，我們提出 SelfGoal，這是一種新穎的自動化方法，旨在增強代理在有限的人類先驗和環境回饋下達成高層級目標的能力。SelfGoal 的核心概念涉及在與環境互動期間，將高層級目標自適應地分解成更實用的子目標樹狀結構，同時找出最有用的子目標並逐步更新這個結構。實驗結果證明，SelfGoal 大幅提升語言代理在各種任務中的表現，包括競爭、合作和延遲回饋的環境。專案頁面：https://selfgoal-agent.github.io。

##### **Mobile Network Configuration Recommendation using Deep Generative Graph Neural Network**
2406.04779v1 by Shirwan Piroti, Ashima Chawla, Tahar Zanouda

There are vast number of configurable parameters in a Radio Access Telecom
Network. A significant amount of these parameters is configured by Radio Node
or cell based on their deployment setting. Traditional methods rely on domain
knowledge for individual parameter configuration, often leading to sub-optimal
results. To improve this, a framework using a Deep Generative Graph Neural
Network (GNN) is proposed. It encodes the network into a graph, extracts
subgraphs for each RAN node, and employs a Siamese GNN (S-GNN) to learn
embeddings. The framework recommends configuration parameters for a multitude
of parameters and detects misconfigurations, handling both network expansion
and existing cell reconfiguration. Tested on real-world data, the model
surpasses baselines, demonstrating accuracy, generalizability, and robustness
against concept drift.

摘要：無線接取電信網路中有大量的可設定參數。其中大量的參數是由無線網路節點或基站根據其部署設定來設定的。傳統的方法依賴於個別參數設定的領域知識，這通常會導致次佳結果。為了改善這一點，提出了一個使用深度生成圖神經網路 (GNN) 的框架。它將網路編碼成一個圖，為每個 RAN 節點提取子圖，並使用 Siamese GNN (S-GNN) 來學習嵌入。該框架建議了大量的參數設定參數，並檢測錯誤設定，處理網路擴充和現有單元格重新設定。在真實世界的資料上進行測試，該模型優於基準，展示了準確性、可概括性和對概念漂移的穩健性。

##### **REP: Resource-Efficient Prompting for On-device Continual Learning**
2406.04772v1 by Sungho Jeon, Xinyue Ma, Kwang In Kim, Myeongjae Jeon

On-device continual learning (CL) requires the co-optimization of model
accuracy and resource efficiency to be practical. This is extremely challenging
because it must preserve accuracy while learning new tasks with continuously
drifting data and maintain both high energy and memory efficiency to be
deployable on real-world devices. Typically, a CL method leverages one of two
types of backbone networks: CNN or ViT. It is commonly believed that CNN-based
CL excels in resource efficiency, whereas ViT-based CL is superior in model
performance, making each option attractive only for a single aspect. In this
paper, we revisit this comparison while embracing powerful pre-trained ViT
models of various sizes, including ViT-Ti (5.8M parameters). Our detailed
analysis reveals that many practical options exist today for making ViT-based
methods more suitable for on-device CL, even when accuracy, energy, and memory
are all considered. To further expand this impact, we introduce REP, which
improves resource efficiency specifically targeting prompt-based rehearsal-free
methods. Our key focus is on avoiding catastrophic trade-offs with accuracy
while trimming computational and memory costs throughout the training process.
We achieve this by exploiting swift prompt selection that enhances input data
using a carefully provisioned model, and by developing two novel
algorithms-adaptive token merging (AToM) and adaptive layer dropping (ALD)-that
optimize the prompt updating stage. In particular, AToM and ALD perform
selective skipping across the data and model-layer dimensions without
compromising task-specific features in vision transformer models. Extensive
experiments on three image classification datasets validate REP's superior
resource efficiency over current state-of-the-art methods.

摘要：<paragraph>裝置內連續學習 (CL) 需要模型精確度與資源效率的共同最佳化，才能實用。這極具挑戰性，因為它必須在學習新任務的同時，保持準確性，並持續調整資料，同時維持高能源和記憶體效率，才能部署在真實世界的裝置上。通常，CL 方法會利用兩種主幹網路之一：CNN 或 ViT。一般認為，基於 CNN 的 CL 在資源效率方面表現出色，而基於 ViT 的 CL 在模型效能方面則更勝一籌，這使得每個選項只對單一層面具有吸引力。在本文中，我們重新探討這個比較，同時採用各種尺寸的強大預先訓練的 ViT 模型，包括 ViT-Ti（5.8M 參數）。我們的詳細分析顯示，目前有許多實用的選項可以讓基於 ViT 的方法更適合裝置內 CL，即使在考慮精確度、能源和記憶體的情況下也是如此。為了進一步擴大這個影響，我們引入了 REP，它特別針對基於提示的無彩排方法改進資源效率。我們的重點在於避免在整個訓練過程中減少運算和記憶體成本時，出現精確度的災難性權衡。我們透過利用增強輸入資料的快速提示選取，並透過開發兩種新的演算法——自適應代號合併 (AToM) 和自適應層捨棄 (ALD)——來達成此目標，這些演算法最佳化了提示更新階段。特別是，AToM 和 ALD 在資料和模型層維度上執行選擇性跳躍，而不會損害視覺轉換器模型中的特定任務功能。在三個影像分類資料集上的廣泛實驗驗證了 REP 優於目前最先進方法的資源效率。</paragraph>

##### **WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild**
2406.04770v1 by Bill Yuchen Lin, Yuntian Deng, Khyathi Chandu, Faeze Brahman, Abhilasha Ravichander, Valentina Pyatkin, Nouha Dziri, Ronan Le Bras, Yejin Choi

We introduce WildBench, an automated evaluation framework designed to
benchmark large language models (LLMs) using challenging, real-world user
queries. WildBench consists of 1,024 tasks carefully selected from over one
million human-chatbot conversation logs. For automated evaluation with
WildBench, we have developed two metrics, WB-Reward and WB-Score, which are
computable using advanced LLMs such as GPT-4-turbo. WildBench evaluation uses
task-specific checklists to evaluate model outputs systematically and provides
structured explanations that justify the scores and comparisons, resulting in
more reliable and interpretable automatic judgments. WB-Reward employs
fine-grained pairwise comparisons between model responses, generating five
potential outcomes: much better, slightly better, slightly worse, much worse,
or a tie. Unlike previous evaluations that employed a single baseline model, we
selected three baseline models at varying performance levels to ensure a
comprehensive pairwise evaluation. Additionally, we propose a simple method to
mitigate length bias, by converting outcomes of ``slightly better/worse'' to
``tie'' if the winner response exceeds the loser one by more than $K$
characters. WB-Score evaluates the quality of model outputs individually,
making it a fast and cost-efficient evaluation metric. WildBench results
demonstrate a strong correlation with the human-voted Elo ratings from Chatbot
Arena on hard tasks. Specifically, WB-Reward achieves a Pearson correlation of
0.98 with top-ranking models. Additionally, WB-Score reaches 0.95, surpassing
both ArenaHard's 0.91 and AlpacaEval2.0's 0.89 for length-controlled win rates,
as well as the 0.87 for regular win rates.

摘要：<paragraph>我們推出 WildBench，一個自動化評估框架，旨在使用具有挑戰性的真實世界使用者查詢來對大型語言模型 (LLM) 進行基準測試。WildBench 包含 1,024 項任務，從超過一百萬筆人機對話記錄中仔細挑選。對於使用 WildBench 進行自動化評估，我們開發了兩個指標，WB-Reward 和 WB-Score，可以使用 GPT-4-turbo 等先進 LLM 進行運算。WildBench 評估使用特定於任務的檢查清單來系統性地評估模型輸出，並提供結構化的說明來證明評分和比較，從而產生更可靠且可解釋的自動判斷。WB-Reward 採用模型回應之間的細緻成對比較，產生五種潛在結果：好很多、稍好、稍差、差很多或平手。與採用單一基準模型的先前評估不同，我們選擇了三個效能等級不同的基準模型，以確保全面的成對評估。此外，我們提出一個簡單的方法來減輕長度偏差，方法是將「稍好/稍差」的結果轉換為「平手」，如果獲勝回應超過失敗者超過 $K$ 個字元。WB-Score 個別評估模型輸出的品質，使其成為快速且具有成本效益的評估指標。WildBench 結果顯示與 Chatbot Arena 中由人類投票的 Elo 評分在困難任務中具有強烈的相關性。具體來說，WB-Reward 與排名最高的模型達到 0.98 的 Pearson 相關性。此外，WB-Score 達到 0.95，在長度控制獲勝率方面超越了 ArenaHard 的 0.91 和 AlpacaEval2.0 的 0.89，以及常規獲勝率的 0.87。</paragraph>

##### **Think out Loud: Emotion Deducing Explanation in Dialogues**
2406.04758v1 by Jiangnan Li, Zheng Lin, Lanrui Wang, Qingyi Si, Yanan Cao, Mo Yu, Peng Fu, Weiping Wang, Jie Zhou

Humans convey emotions through daily dialogues, making emotion understanding
a crucial step of affective intelligence. To understand emotions in dialogues,
machines are asked to recognize the emotion for an utterance (Emotion
Recognition in Dialogues, ERD); based on the emotion, then find causal
utterances for the emotion (Emotion Cause Extraction in Dialogues, ECED). The
setting of the two tasks requires first ERD and then ECED, ignoring the mutual
complement between emotion and cause. To fix this, some new tasks are proposed
to extract them simultaneously. Although the current research on these tasks
has excellent achievements, simply identifying emotion-related factors by
classification modeling lacks realizing the specific thinking process of causes
stimulating the emotion in an explainable way. This thinking process especially
reflected in the reasoning ability of Large Language Models (LLMs) is
under-explored. To this end, we propose a new task "Emotion Deducing
Explanation in Dialogues" (EDEN). EDEN recognizes emotion and causes in an
explicitly thinking way. That is, models need to generate an explanation text,
which first summarizes the causes; analyzes the inner activities of the
speakers triggered by the causes using common sense; then guesses the emotion
accordingly. To support the study of EDEN, based on the existing resources in
ECED, we construct two EDEN datasets by human effort. We further evaluate
different models on EDEN and find that LLMs are more competent than
conventional PLMs. Besides, EDEN can help LLMs achieve better recognition of
emotions and causes, which explores a new research direction of explainable
emotion understanding in dialogues.

摘要：人類透過日常對話傳達情緒，使情緒理解成為情感智能的關鍵一步。為了理解對話中的情緒，機器被要求辨識一段話的情緒（對話中的情緒辨識，ERD）；接著根據情緒，找出造成該情緒的因果話語（對話中的情緒原因萃取，ECED）。這兩個任務的設定需要先進行 ERD，再進行 ECED，忽略了情緒與原因之間的相互補充。為了修正這個問題，一些新的任務被提出來同時萃取它們。儘管目前對這些任務的研究已有卓越的成就，但僅透過分類模型辨識與情緒相關的因素，無法以可解釋的方式實現導致情緒的具體思考過程。這個思考過程特別反映在大型語言模型 (LLM) 的推理能力中，卻未被充分探討。為此，我們提出一個新的任務「對話中的情緒推理解釋」（EDEN）。EDEN 以一種明確思考的方式辨識情緒和原因。也就是說，模型需要生成一個解釋文字，它首先總結原因；使用常識分析原因觸發說話者的內在活動；然後據此猜測情緒。為了支持 EDEN 的研究，我們根據 ECED 中現有的資源，透過人力建構了兩個 EDEN 資料集。我們進一步評估了 EDEN 上的不同模型，發現 LLM 比傳統的 PLM 更勝任。此外，EDEN 可以幫助 LLM 更準確地辨識情緒和原因，這探索了對話中可解釋情緒理解的新研究方向。

##### **Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations**
2406.04755v1 by Weiran Lin, Anna Gerchanovsky, Omer Akgul, Lujo Bauer, Matt Fredrikson, Zifan Wang

Large language model (LLM) users might rely on others (e.g., prompting
services), to write prompts. However, the risks of trusting prompts written by
others remain unstudied. In this paper, we assess the risk of using such
prompts on brand recommendation tasks when shopping. First, we found that
paraphrasing prompts can result in LLMs mentioning given brands with
drastically different probabilities, including a pair of prompts where the
probability changes by 100%. Next, we developed an approach that can be used to
perturb an original base prompt to increase the likelihood that an LLM mentions
a given brand. We designed a human-inconspicuous algorithm that perturbs
prompts, which empirically forces LLMs to mention strings related to a brand
more often, by absolute improvements up to 78.3%. Our results suggest that our
perturbed prompts, 1) are inconspicuous to humans, 2) force LLMs to recommend a
target brand more often, and 3) increase the perceived chances of picking
targeted brands.

摘要：大型語言模型 (LLM) 使用者可能會依賴他人（例如提示服務）來撰寫提示。然而，相信他人撰寫的提示的風險仍未被研究。在本文中，我們評估在購物時使用此類提示對品牌推薦任務的風險。首先，我們發現重新表述提示可能會導致 LLM 以極不同的機率提及給定的品牌，包括一對機率變化達 100% 的提示。接下來，我們開發了一種方法，可用於擾動原始基本提示，以增加 LLM 提及給定品牌的可能性。我們設計了一種對人類不顯眼的演算法來擾動提示，根據經驗，這會強迫 LLM 更頻繁地提及與品牌相關的字串，絕對改善幅度高達 78.3%。我們的結果表明，我們擾動的提示 1) 對人類不顯眼，2) 強迫 LLM 更頻繁地推薦目標品牌，以及 3) 增加選擇目標品牌的感知機會。

##### **CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models**
2406.04752v1 by Ling Shi, Deyi Xiong

Large language models (LLMs) are possessed of numerous beneficial
capabilities, yet their potential inclination harbors unpredictable risks that
may materialize in the future. We hence propose CRiskEval, a Chinese dataset
meticulously designed for gauging the risk proclivities inherent in LLMs such
as resource acquisition and malicious coordination, as part of efforts for
proactive preparedness. To curate CRiskEval, we define a new risk taxonomy with
7 types of frontier risks and 4 safety levels, including extremely
hazardous,moderately hazardous, neutral and safe. We follow the philosophy of
tendency evaluation to empirically measure the stated desire of LLMs via
fine-grained multiple-choice question answering. The dataset consists of 14,888
questions that simulate scenarios related to predefined 7 types of frontier
risks. Each question is accompanied with 4 answer choices that state opinions
or behavioral tendencies corresponding to the question. All answer choices are
manually annotated with one of the defined risk levels so that we can easily
build a fine-grained frontier risk profile for each assessed LLM. Extensive
evaluation with CRiskEval on a spectrum of prevalent Chinese LLMs has unveiled
a striking revelation: most models exhibit risk tendencies of more than 40%
(weighted tendency to the four risk levels). Furthermore, a subtle increase in
the model's inclination toward urgent self-sustainability, power seeking and
other dangerous goals becomes evident as the size of models increase. To
promote further research on the frontier risk evaluation of LLMs, we publicly
release our dataset at https://github.com/lingshi6565/Risk_eval.

摘要：大型語言模型 (LLM) 擁有許多有益的功能，但其潛在傾向卻隱藏著難以預測的風險，這些風險可能會在未來實現。因此，我們提出了 CRiskEval，這是一個精心設計的中文資料集，用於評量 LLM 中固有的風險傾向，例如資源獲取和惡意協調，作為積極準備工作的一部分。為了策劃 CRiskEval，我們定義了一個新的風險分類法，其中包含 7 種類型的邊緣風險和 4 個安全級別，包括極度危險、中度危險、中立和安全。我們遵循傾向評估的理念，通過細粒度的多選題回答來實證測量 LLM 的既定願望。該資料集包含 14,888 個問題，模擬與預定義的 7 種類型邊緣風險相關的情境。每個問題都附有 4 個答案選項，這些選項陳述了與問題相應的意見或行為傾向。所有答案選項都經過人工註解，並標示為已定義風險級別之一，以便我們可以輕鬆為每個評估的 LLM 建立細粒度的邊緣風險概況。在各種流行的中文 LLM 上使用 CRiskEval 進行廣泛評估後，揭示了一個驚人的發現：大多數模型表現出超過 40% 的風險傾向（對四個風險級別的加權傾向）。此外，隨著模型規模的增加，模型傾向於緊急自我維持、尋求權力和其他危險目標的趨勢會變得明顯。為了促進對 LLM 邊緣風險評估的進一步研究，我們在 https://github.com/lingshi6565/Risk_eval 上公開發布我們的資料集。

##### **PQPP: A Joint Benchmark for Text-to-Image Prompt and Query Performance Prediction**
2406.04746v1 by Eduard Poesina, Adriana Valentina Costache, Adrian-Gabriel Chifu, Josiane Mothe, Radu Tudor Ionescu

Text-to-image generation has recently emerged as a viable alternative to
text-to-image retrieval, due to the visually impressive results of generative
diffusion models. Although query performance prediction is an active research
topic in information retrieval, to the best of our knowledge, there is no prior
study that analyzes the difficulty of queries (prompts) in text-to-image
generation, based on human judgments. To this end, we introduce the first
dataset of prompts which are manually annotated in terms of image generation
performance. In order to determine the difficulty of the same prompts in image
retrieval, we also collect manual annotations that represent retrieval
performance. We thus propose the first benchmark for joint text-to-image prompt
and query performance prediction, comprising 10K queries. Our benchmark
enables: (i) the comparative assessment of the difficulty of prompts/queries in
image generation and image retrieval, and (ii) the evaluation of prompt/query
performance predictors addressing both generation and retrieval. We present
results with several pre-generation/retrieval and post-generation/retrieval
performance predictors, thus providing competitive baselines for future
research. Our benchmark and code is publicly available under the CC BY 4.0
license at https://github.com/Eduard6421/PQPP.

摘要：文本到图像生成最近已成为文本到图像检索的可行替代方案，这是由于生成扩散模型在视觉上令人印象深刻的结果。尽管查询性能预测是信息检索中的一个活跃研究课题，但据我们所知，没有先前的研究基于人类判断分析文本到图像生成中查询（提示）的难度。为此，我们引入了第一个提示数据集，该数据集在图像生成性能方面经过人工注释。为了确定图像检索中相同提示的难度，我们还收集了表示检索性能的手动注释。因此，我们提出了第一个联合文本到图像提示和查询性能预测基准，包括 10K 个查询。我们的基准能够：(i) 比较图像生成和图像检索中提示/查询难度的评估，以及 (ii) 评估解决生成和检索的提示/查询性能预测器。我们展示了几个生成前/检索前和生成后/检索后性能预测器的结果，从而为未来的研究提供了有竞争力的基线。我们的基准和代码在 https://github.com/Eduard6421/PQPP 下以 CC BY 4.0 许可证公开提供。

##### **CRAG -- Comprehensive RAG Benchmark**
2406.04744v1 by Xiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla, Xiangsen Chen, Sajal Choudhary, Rongze Daniel Gui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong, Brian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan, Chenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang, Lei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah, Rakesh Wanga, Anuj Kumar, Wen-tau Yih, Xin Luna Dong

Retrieval-Augmented Generation (RAG) has recently emerged as a promising
solution to alleviate Large Language Model (LLM)'s deficiency in lack of
knowledge. Existing RAG datasets, however, do not adequately represent the
diverse and dynamic nature of real-world Question Answering (QA) tasks. To
bridge this gap, we introduce the Comprehensive RAG Benchmark (CRAG), a factual
question answering benchmark of 4,409 question-answer pairs and mock APIs to
simulate web and Knowledge Graph (KG) search. CRAG is designed to encapsulate a
diverse array of questions across five domains and eight question categories,
reflecting varied entity popularity from popular to long-tail, and temporal
dynamisms ranging from years to seconds. Our evaluation on this benchmark
highlights the gap to fully trustworthy QA. Whereas most advanced LLMs achieve
<=34% accuracy on CRAG, adding RAG in a straightforward manner improves the
accuracy only to 44%. State-of-the-art industry RAG solutions only answer 63%
questions without any hallucination. CRAG also reveals much lower accuracy in
answering questions regarding facts with higher dynamism, lower popularity, or
higher complexity, suggesting future research directions. The CRAG benchmark
laid the groundwork for a KDD Cup 2024 challenge, attracting thousands of
participants and submissions within the first 50 days of the competition. We
commit to maintaining CRAG to serve research communities in advancing RAG
solutions and general QA solutions.

摘要：檢索增強生成 (RAG) 最近作為一種有前途的解決方案出現，以緩解大型語言模型 (LLM) 在知識缺乏方面的缺陷。然而，現有的 RAG 資料集並不能充分代表現實世界問答 (QA) 任務的多樣性和動態性。為了彌補這一差距，我們引入了綜合 RAG 基準 (CRAG)，這是一個由 4,409 個問答對和模擬網路和知識圖譜 (KG) 搜尋的模擬 API 組成的基於事實的問答基準。CRAG 被設計成囊括跨越五個領域和八個問題類別的各種問題，反映了從流行到長尾的各種實體流行度，以及從年到秒的時間動態。我們對此基準的評估突出了完全值得信賴的 QA 的差距。儘管大多數先進的 LLM 在 CRAG 上的準確率低於等於 34%，但以一種直接的方式添加 RAG 僅將準確率提高到 44%。最先進的產業 RAG 解決方案僅回答 63% 的問題，且沒有任何幻覺。CRAG 還顯示在回答具有更高動態性、較低流行度或更高複雜性的事實相關問題時準確率要低得多，這表明了未來的研究方向。CRAG 基準為 2024 年 KDD 杯挑戰賽奠定了基礎，在比賽開始後的前 50 天內吸引了數千名參與者和提交。我們承諾維護 CRAG，以服務於研究社群，推進 RAG 解決方案和一般 QA 解決方案。

##### **Generative AI Models: Opportunities and Risks for Industry and Authorities**
2406.04734v1 by Tobias Alt, Andrea Ibisch, Clemens Meiser, Anna Wilhelm, Raphael Zimmer, Christian Berghoff, Christoph Droste, Jens Karschau, Friederike Laus, Rainer Plaga, Carola Plesch, Britta Sennewald, Thomas Thaeren, Kristina Unverricht, Steffen Waurick

Generative AI models are capable of performing a wide range of tasks that
traditionally require creativity and human understanding. They learn patterns
from existing data during training and can subsequently generate new content
such as texts, images, and music that follow these patterns. Due to their
versatility and generally high-quality results, they, on the one hand,
represent an opportunity for digitalization. On the other hand, the use of
generative AI models introduces novel IT security risks that need to be
considered for a comprehensive analysis of the threat landscape in relation to
IT security. In response to this risk potential, companies or authorities using
them should conduct an individual risk analysis before integrating generative
AI into their workflows. The same applies to developers and operators, as many
risks in the context of generative AI have to be taken into account at the time
of development or can only be influenced by the operating company. Based on
this, existing security measures can be adjusted, and additional measures can
be taken.

摘要：生成式 AI 模型能夠執行廣泛的任務，這些任務傳統上需要創造力和人類理解力。它們在訓練過程中從現有數據中學習模式，並且隨後可以生成遵循這些模式的新內容，例如文本、圖像和音樂。由於它們的多功能性和通常的高品質結果，它們一方面代表了數位化的機會。另一方面，生成式 AI 模型的使用引入了新的 IT 安全風險，需要考慮這些風險才能全面分析與 IT 安全相關的威脅環境。為了應對這種風險潛力，使用它們的公司或當局應在將生成式 AI 整合到其工作流程之前進行個別風險分析。開發人員和操作員也適用相同的做法，因為生成式 AI 背景中的許多風險必須在開發時考慮，或者只能由運營公司來影響。基於此，可以調整現有的安全措施，並採取額外的措施。

##### **Probabilistic Perspectives on Error Minimization in Adversarial Reinforcement Learning**
2406.04724v1 by Roman Belaire, Arunesh Sinha, Pradeep Varakantham

Deep Reinforcement Learning (DRL) policies are critically vulnerable to
adversarial noise in observations, posing severe risks in safety-critical
scenarios. For example, a self-driving car receiving manipulated sensory inputs
about traffic signs could lead to catastrophic outcomes. Existing strategies to
fortify RL algorithms against such adversarial perturbations generally fall
into two categories: (a) using regularization methods that enhance robustness
by incorporating adversarial loss terms into the value objectives, and (b)
adopting "maximin" principles, which focus on maximizing the minimum value to
ensure robustness. While regularization methods reduce the likelihood of
successful attacks, their effectiveness drops significantly if an attack does
succeed. On the other hand, maximin objectives, although robust, tend to be
overly conservative. To address this challenge, we introduce a novel objective
called Adversarial Counterfactual Error (ACoE), which naturally balances
optimizing value and robustness against adversarial attacks. To optimize ACoE
in a scalable manner in model-free settings, we propose a theoretically
justified surrogate objective known as Cumulative-ACoE (C-ACoE). The core idea
of optimizing C-ACoE is utilizing the belief about the underlying true state
given the adversarially perturbed observation. Our empirical evaluations
demonstrate that our method outperforms current state-of-the-art approaches for
addressing adversarial RL problems across all established benchmarks (MuJoCo,
Atari, and Highway) used in the literature.

摘要：深度強化學習 (DRL) 政策極容易受到觀察中的對抗性雜訊影響，在安全關鍵情境中造成嚴重風險。例如，自駕車接收有關交通標誌的操縱感官輸入可能會導致災難性後果。現有的策略是用來強化 RL 演算法對抗此類對抗性擾動，通常分為兩類：(a) 使用正規化方法，透過將對抗性損失項納入價值目標來增強穩健性，以及 (b) 採用「最大最小」原則，專注於最大化最小值以確保穩健性。雖然正規化方法降低了攻擊成功的可能性，但如果攻擊成功，其有效性會大幅下降。另一方面，最大最小目標雖然穩健，但往往過於保守。為了應對此挑戰，我們引入了一個名為對抗性反事實誤差 (ACoE) 的新目標，它自然平衡了優化價值和對抗攻擊的穩健性。為了在無模型設定中以可擴充的方式優化 ACoE，我們提出了理論上合理的替代目標，稱為累積 ACoE (C-ACoE)。優化 C-ACoE 的核心概念是利用對給定對抗性擾動觀察的底層真實狀態的信念。我們的經驗評估表明，我們的方法優於當前最先進的方法，可解決所有在文獻中使用的已建立基準 (MuJoCo、Atari 和 Highway) 的對抗性 RL 問題。

##### **FlowMM: Generating Materials with Riemannian Flow Matching**
2406.04713v1 by Benjamin Kurt Miller, Ricky T. Q. Chen, Anuroop Sriram, Brandon M Wood

Crystalline materials are a fundamental component in next-generation
technologies, yet modeling their distribution presents unique computational
challenges. Of the plausible arrangements of atoms in a periodic lattice only a
vanishingly small percentage are thermodynamically stable, which is a key
indicator of the materials that can be experimentally realized. Two fundamental
tasks in this area are to (a) predict the stable crystal structure of a known
composition of elements and (b) propose novel compositions along with their
stable structures. We present FlowMM, a pair of generative models that achieve
state-of-the-art performance on both tasks while being more efficient and more
flexible than competing methods. We generalize Riemannian Flow Matching to suit
the symmetries inherent to crystals: translation, rotation, permutation, and
periodic boundary conditions. Our framework enables the freedom to choose the
flow base distributions, drastically simplifying the problem of learning
crystal structures compared with diffusion models. In addition to standard
benchmarks, we validate FlowMM's generated structures with quantum chemistry
calculations, demonstrating that it is about 3x more efficient, in terms of
integration steps, at finding stable materials compared to previous open
methods.

摘要：晶體材料是下一代技術的基礎組成部分，但對其分佈進行建模會帶來獨特的計算挑戰。在週期晶格中，原子合理排列的比例僅有極小的一部分是熱力學穩定的，這是可以通過實驗實現的材料的一個關鍵指標。該領域的兩項基本任務是：(a) 預測已知元素組成的穩定晶體結構，以及 (b) 提出新的組成及其穩定結構。我們提出了 FlowMM，這是一種生成模型對，在兩項任務上都達到了最先進的效能，同時比競爭方法更有效率、更靈活。我們將黎曼流匹配推廣到適應晶體固有的對稱性：平移、旋轉、排列和週期性邊界條件。我們的框架使我們可以自由選擇流基分佈，與擴散模型相比，大大簡化了學習晶體結構的問題。除了標準基準外，我們還使用量子化學計算驗證了 FlowMM 生成的結構，證明與以前開放的方法相比，它在積分步長方面約高效 3 倍，可以找到穩定的材料。

##### **AICoderEval: Improving AI Domain Code Generation of Large Language Models**
2406.04712v1 by Yinghui Xia, Yuyan Chen, Tianyu Shi, Jun Wang, Jinsong Yang

Automated code generation is a pivotal capability of large language models
(LLMs). However, assessing this capability in real-world scenarios remains
challenging. Previous methods focus more on low-level code generation, such as
model loading, instead of generating high-level codes catering for real-world
tasks, such as image-to-text, text classification, in various domains.
Therefore, we construct AICoderEval, a dataset focused on real-world tasks in
various domains based on HuggingFace, PyTorch, and TensorFlow, along with
comprehensive metrics for evaluation and enhancing LLMs' task-specific code
generation capability. AICoderEval contains test cases and complete programs
for automated evaluation of these tasks, covering domains such as natural
language processing, computer vision, and multimodal learning. To facilitate
research in this area, we open-source the AICoderEval dataset at
\url{https://huggingface.co/datasets/vixuowis/AICoderEval}. After that, we
propose CoderGen, an agent-based framework, to help LLMs generate codes related
to real-world tasks on the constructed AICoderEval. Moreover, we train a more
powerful task-specific code generation model, named AICoder, which is refined
on llama-3 based on AICoderEval. Our experiments demonstrate the effectiveness
of CoderGen in improving LLMs' task-specific code generation capability (by
12.00\% on pass@1 for original model and 9.50\% on pass@1 for ReAct Agent).
AICoder also outperforms current code generation LLMs, indicating the great
quality of the AICoderEval benchmark.

摘要：<paragraph>自動程式碼產生是大語言模型 (LLM) 的關鍵能力。然而，在現實世界的場景中評估此能力仍然具有挑戰性。先前的做法更專注於低層級程式碼產生，例如模型載入，而不是產生適用於現實世界任務的高層級程式碼，例如影像轉文字、文字分類等，涵蓋各種領域。因此，我們建構了 AICoderEval，一個專注於各種領域的現實世界任務的資料集，基於 HuggingFace、PyTorch 和 TensorFlow，以及用於評估和增強 LLM 任務特定程式碼產生能力的綜合指標。AICoderEval 包含測試案例和完整程式，用於自動評估這些任務，涵蓋自然語言處理、電腦視覺和多模態學習等領域。為了促進這方面的研究，我們在 \url{https://huggingface.co/datasets/vixuowis/AICoderEval} 開源了 AICoderEval 資料集。在那之後，我們提出了基於代理的架構 CoderGen，以幫助 LLM 在建構的 AICoderEval 上產生與現實世界任務相關的程式碼。此外，我們訓練了一個更強大的任務特定程式碼產生模型，稱為 AICoder，它根據 AICoderEval 在 llama-3 上進行了改進。我們的實驗證明了 CoderGen 在改進 LLM 的任務特定程式碼產生能力方面的有效性（對於原始模型，pass@1 提高了 12.00%，對於 ReAct Agent，pass@1 提高了 9.50%）。AICoder 也超越了目前的程式碼產生 LLM，這表示 AICoderEval 基準的品質極佳。</paragraph>

##### **Morescient GAI for Software Engineering**
2406.04710v1 by Marcus Kessel, Colin Atkinson

The ability of Generative AI (GAI) technology to automatically check,
synthesize and modify software engineering artifacts promises to revolutionize
all aspects of software engineering. Using GAI for software engineering tasks
is consequently one of the most rapidly expanding fields of software
engineering research, with dozens of LLM-based code models having been
published since 2021. However, the overwhelming majority of existing code
models share a major weakness - they are exclusively trained on the syntactic
facet of software, significantly lowering their trustworthiness in tasks
dependent on software semantics. To address this problem, a new class of
"Morescient" GAI is needed that is "aware" of (i.e., trained on) both the
semantic and static facets of software. This, in turn, will require a new
generation of software observation platforms capable of generating ultra-large
quantities of execution observations in a structured and readily analyzable
way. In this paper, we present a vision for how such "Morescient" GAI models
can be engineered, evolved and disseminated according to the principles of open
science.

摘要：生成式人工智能 (GAI) 技術自動檢查、綜合和修改軟體工程成品的能力，有望徹底改變軟體工程的各個方面。因此，將 GAI 用於軟體工程任務是軟體工程研究中發展最快速的領域之一，自 2021 年以來，已經發布了數十個基於 LLM 的程式碼模型。然而，絕大多數現有的程式碼模型有一個主要缺點 - 它們僅訓練於軟體的語法方面，這大大降低了它們在依賴軟體語義的任務中的可信度。為了解決這個問題，需要一種新的「莫爾」GAI，它「知道」(即訓練於) 軟體的語義和靜態方面。這反過來又需要新一代的軟體觀察平台，能夠以結構化且易於分析的方式產生大量的執行觀察。在本文中，我們提出了一個願景，說明如何根據開放科學的原則來設計、演化和傳播這樣的「莫爾」GAI 模型。

##### **Logic Synthesis with Generative Deep Neural Networks**
2406.04699v1 by Xihan Li, Xing Li, Lei Chen, Xing Zhang, Mingxuan Yuan, Jun Wang

While deep learning has achieved significant success in various domains, its
application to logic circuit design has been limited due to complex constraints
and strict feasibility requirement. However, a recent generative deep neural
model, "Circuit Transformer", has shown promise in this area by enabling
equivalence-preserving circuit transformation on a small scale. In this paper,
we introduce a logic synthesis rewriting operator based on the Circuit
Transformer model, named "ctrw" (Circuit Transformer Rewriting), which
incorporates the following techniques: (1) a two-stage training scheme for the
Circuit Transformer tailored for logic synthesis, with iterative improvement of
optimality through self-improvement training; (2) integration of the Circuit
Transformer with state-of-the-art rewriting techniques to address scalability
issues, allowing for guided DAG-aware rewriting. Experimental results on the
IWLS 2023 contest benchmark demonstrate the effectiveness of our proposed
rewriting methods.

摘要：雖然深度學習在各種領域都取得了顯著的成功，但由於複雜的約束和嚴格的可行性要求，其在邏輯電路設計中的應用受到限制。然而，最近的生成式深度神經網路模型「電路轉換器」已在此領域顯示出前景，它可以在小規模上實現等效電路轉換。在本文中，我們介紹了一個基於電路轉換器模型的邏輯合成重寫運算子，名為「ctrw」（電路轉換器重寫），它包含以下技術：(1) 針對邏輯合成量身打造的電路轉換器兩階段訓練方案，通過自我改進訓練反覆改進最佳化；(2) 將電路轉換器與最先進的重寫技術整合，以解決可擴充性問題，允許進行引導式 DAG 感知重寫。在 IWLS 2023 競賽基準上的實驗結果證明了我們提出的重寫方法的有效性。

##### **LLM-Vectorizer: LLM-based Verified Loop Vectorizer**
2406.04693v1 by Jubi Taneja, Avery Laird, Cong Yan, Madan Musuvathi, Shuvendu K. Lahiri

Vectorization is a powerful optimization technique that significantly boosts
the performance of high performance computing applications operating on large
data arrays. Despite decades of research on auto-vectorization, compilers
frequently miss opportunities to vectorize code. On the other hand, writing
vectorized code manually using compiler intrinsics is still a complex,
error-prone task that demands deep knowledge of specific architecture and
compilers.
  In this paper, we evaluate the potential of large-language models (LLMs) to
generate vectorized (Single Instruction Multiple Data) code from scalar
programs that process individual array elements. We propose a novel
finite-state machine multi-agents based approach that harnesses LLMs and
test-based feedback to generate vectorized code. Our findings indicate that
LLMs are capable of producing high performance vectorized code with run-time
speedup ranging from 1.1x to 9.4x as compared to the state-of-the-art compilers
such as Intel Compiler, GCC, and Clang.
  To verify the correctness of vectorized code, we use Alive2, a leading
bounded translation validation tool for LLVM IR. We describe a few
domain-specific techniques to improve the scalability of Alive2 on our
benchmark dataset. Overall, our approach is able to verify 38.2% of
vectorizations as correct on the TSVC benchmark dataset.

摘要：向量化是一種強大的最佳化技術，能大幅提升處理大型資料陣列的高效能運算應用程式效能。儘管數十年來自動向量化研究不斷，編譯器經常錯失向量化程式碼的機會。另一方面，手動使用編譯器內建函數撰寫向量化程式碼仍是一項複雜、容易出錯的任務，需要深入了解特定架構和編譯器。
  在本文中，我們評估大型語言模型 (LLM) 將處理個別陣列元素的純量程式轉換為向量化 (單一指令多重資料) 程式碼的潛力。我們提出一個新穎的基於有限狀態機的多代理人方法，利用 LLM 和基於測試的回饋產生向量化程式碼。我們的研究結果表明，與 Intel Compiler、GCC 和 Clang 等最先進的編譯器相比，LLM 能夠產生高性能向量化程式碼，執行時間加速從 1.1 倍到 9.4 倍不等。
  為了驗證向量化程式碼的正確性，我們使用 Alive2，這是一個領先的 LLVM IR 繫結轉譯驗證工具。我們描述了一些特定領域的技術，以改善 Alive2 在我們的基準資料集上的可擴充性。總體而言，我們的方法能夠在 TSVC 基準資料集上驗證 38.2% 的向量化正確無誤。

##### **Mixture-of-Agents Enhances Large Language Model Capabilities**
2406.04692v1 by Junlin Wang, Jue Wang, Ben Athiwaratkun, Ce Zhang, James Zou

Recent advances in large language models (LLMs) demonstrate substantial
capabilities in natural language understanding and generation tasks. With the
growing number of LLMs, how to harness the collective expertise of multiple
LLMs is an exciting open direction. Toward this goal, we propose a new approach
that leverages the collective strengths of multiple LLMs through a
Mixture-of-Agents (MoA) methodology. In our approach, we construct a layered
MoA architecture wherein each layer comprises multiple LLM agents. Each agent
takes all the outputs from agents in the previous layer as auxiliary
information in generating its response. MoA models achieves state-of-art
performance on AlpacaEval 2.0, MT-Bench and FLASK, surpassing GPT-4 Omni. For
example, our MoA using only open-source LLMs is the leader of AlpacaEval 2.0 by
a substantial gap, achieving a score of 65.1% compared to 57.5% by GPT-4 Omni.

摘要：大型語言模型（LLM）的最新進展在自然語言理解和生成任務中展現了強大的能力。隨著 LLM 數量的增加，如何利用多個 LLM 的集體專業知識是一個令人興奮的開放方向。為了實現這一目標，我們提出了一種新方法，該方法通過混合代理（MoA）方法利用多個 LLM 的集體優勢。在我們的做法中，我們構建了一個分層的 MoA 架構，其中每一層都包含多個 LLM 代理。每個代理都將前一層代理的所有輸出作為輔助信息，以生成其響應。MoA 模型在 AlpacaEval 2.0、MT-Bench 和 FLASK 上實現了最先進的性能，超越了 GPT-4 Omni。例如，我們僅使用開源 LLM 的 MoA 以大幅差距領先 AlpacaEval 2.0，與 GPT-4 Omni 的 57.5% 相比，達到 65.1% 的分數。

##### **MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models**
2406.04673v1 by Sanjoy Chowdhury, Sayan Nag, K J Joseph, Balaji Vasan Srinivasan, Dinesh Manocha

Music is a universal language that can communicate emotions and feelings. It
forms an essential part of the whole spectrum of creative media, ranging from
movies to social media posts. Machine learning models that can synthesize music
are predominantly conditioned on textual descriptions of it. Inspired by how
musicians compose music not just from a movie script, but also through
visualizations, we propose MeLFusion, a model that can effectively use cues
from a textual description and the corresponding image to synthesize music.
MeLFusion is a text-to-music diffusion model with a novel "visual synapse",
which effectively infuses the semantics from the visual modality into the
generated music. To facilitate research in this area, we introduce a new
dataset MeLBench, and propose a new evaluation metric IMSM. Our exhaustive
experimental evaluation suggests that adding visual information to the music
synthesis pipeline significantly improves the quality of generated music,
measured both objectively and subjectively, with a relative gain of up to
67.98% on the FAD score. We hope that our work will gather attention to this
pragmatic, yet relatively under-explored research area.

摘要：音樂是一種可以傳達情緒和感受的通用語言。它構成了整個創意媒體範圍中不可或缺的一部分，從電影到社群媒體貼文皆是如此。能合成音樂的機器學習模型主要以文字描述為條件。受音樂家不只從電影腳本創作音樂，也透過視覺化來創作音樂的方式所啟發，我們提出 MeLFusion，這是一個能有效使用文字描述和對應影像中的提示來合成音樂的模型。MeLFusion 是一個文字轉音樂擴散模型，具有一個新穎的「視覺突觸」，能有效地將視覺模式中的語義融入到生成的音樂中。為了促進這方面的研究，我們引進一個新的資料集 MeLBench，並提出一個新的評量指標 IMSM。我們詳盡的實驗評量顯示，將視覺資訊加入到音樂合成管道中，能大幅提升生成音樂的品質，透過 FAD 評分客觀且主觀的測量，相對增益高達 67.98%。我們希望我們的作品能引起對這個實用但相對未被探索的研究領域的關注。

##### **The Reasonable Person Standard for AI**
2406.04671v1 by Sunayana Rane

As AI systems are increasingly incorporated into domains where human behavior
has set the norm, a challenge for AI governance and AI alignment research is to
regulate their behavior in a way that is useful and constructive for society.
One way to answer this question is to ask: how do we govern the human behavior
that the models are emulating? To evaluate human behavior, the American legal
system often uses the "Reasonable Person Standard." The idea of "reasonable"
behavior comes up in nearly every area of law. The legal system often judges
the actions of parties with respect to what a reasonable person would have done
under similar circumstances. This paper argues that the reasonable person
standard provides useful guidelines for the type of behavior we should develop,
probe, and stress-test in models. It explains how reasonableness is defined and
used in key areas of the law using illustrative cases, how the reasonable
person standard could apply to AI behavior in each of these areas and contexts,
and how our societal understanding of "reasonable" behavior provides useful
technical goals for AI researchers.

摘要：隨著 AI 系統日益融入人類行為已設下規範的領域，AI 治理和 AI 對齊研究的一項挑戰是要以對社會有益且具建設性的方式規範其行為。回答這個問題的方法之一是詢問：我們要如何治理模型所模擬的人類行為？為了評估人類行為，美國法律體系通常使用「合理人標準」。「合理」行為的概念出現在幾乎每個法律領域。法律體系通常根據合理人在類似情況下會採取的行動來判斷當事人的行為。本文認為，合理人標準為我們應在模型中開發、探討和進行壓力測試的行為類型提供了有用的準則。本文說明了在法律關鍵領域中如何定義和使用合理性，並使用說明性案例說明了合理人標準如何適用於這些領域和背景中的 AI 行為，以及我們對「合理」行為的社會理解如何為 AI 研究人員提供有用的技術目標。

##### **MATTER: Memory-Augmented Transformer Using Heterogeneous Knowledge Sources**
2406.04670v1 by Dongkyu Lee, Chandana Satya Prakash, Jack FitzGerald, Jens Lehmann

Leveraging external knowledge is crucial for achieving high performance in
knowledge-intensive tasks, such as question answering. The retrieve-and-read
approach is widely adopted for integrating external knowledge into a language
model. However, this approach suffers from increased computational cost and
latency due to the long context length, which grows proportionally with the
number of retrieved knowledge. Furthermore, existing retrieval-augmented models
typically retrieve information from a single type of knowledge source, limiting
their scalability to diverse knowledge sources with varying structures. In this
work, we introduce an efficient memory-augmented transformer called MATTER,
designed to retrieve relevant knowledge from multiple heterogeneous knowledge
sources. Specifically, our model retrieves and reads from both unstructured
sources (paragraphs) and semi-structured sources (QA pairs) in the form of
fixed-length neural memories. We demonstrate that our model outperforms
existing efficient retrieval-augmented models on popular QA benchmarks in terms
of both accuracy and speed. Furthermore, MATTER achieves competitive results
compared to conventional read-and-retrieve models while having 100x throughput
during inference.

摘要：利用外部知識對於在知識密集型任務（例如問答）中取得高性能至關重要。擷取並讀取的方法廣泛用於將外部知識整合到語言模型中。然而，由於長篇的內容長度（會隨著擷取知識的數量成正比增加），這種方法會造成運算成本和延遲增加。此外，現有的擷取增強模型通常會從單一類型的知識來源擷取資訊，這會限制其擴充到具有不同結構的各種知識來源。在這項工作中，我們引進了一種稱為 MATTER 的高效記憶體增強Transformer，旨在從多個異質知識來源中擷取相關知識。具體來說，我們的模型會從非結構化來源（段落）和半結構化來源（問答配對）中擷取並讀取固定長度的神經記憶體。我們證明了我們的模型在準確度和速度方面都優於現有的高效擷取增強模型，且表現優於熱門的問答基準。此外，MATTER 與傳統的讀取和擷取模型相比，在推論期間具有 100 倍的處理量，同時達到了具有競爭力的結果。

##### **DiNeR: a Large Realistic Dataset for Evaluating Compositional Generalization**
2406.04669v1 by Chengang Hu, Xiao Liu, Yansong Feng

Most of the existing compositional generalization datasets are
synthetically-generated, resulting in a lack of natural language variation.
While there have been recent attempts to introduce non-synthetic datasets for
compositional generalization, they suffer from either limited data scale or a
lack of diversity in the forms of combinations. To better investigate
compositional generalization with more linguistic phenomena and compositional
diversity, we propose the DIsh NamE Recognition (DiNeR) task and create a large
realistic Chinese dataset. Given a recipe instruction, models are required to
recognize the dish name composed of diverse combinations of food, actions, and
flavors. Our dataset consists of 3,811 dishes and 228,114 recipes, and involves
plenty of linguistic phenomena such as anaphora, omission and ambiguity. We
provide two strong baselines based on T5 and large language models (LLMs). This
work contributes a challenging task, baseline methods to tackle the task, and
insights into compositional generalization in the context of dish name
recognition. Code and data are available at https://github.com/Jumpy-pku/DiNeR.

摘要：現有的組合概化資料集大多是合成產生的，導致缺乏自然語言變化。雖然最近已嘗試引入非合成資料集以進行組合概化，但這些資料集的資料規模有限，或者組合形式缺乏多樣性。為了使用更多語言現象和組合多樣性更好地研究組合概化，我們提出了菜餚名稱辨識 (DiNeR) 任務，並建立了一個大型且逼真的中文資料集。在給定食譜說明的情況下，模型需要辨識由各種食物、動作和口味組合而成的菜餚名稱。我們的資料集包含 3,811 道菜和 228,114 個食譜，並涉及大量語言現象，例如指代、省略和歧義。我們根據 T5 和大型語言模型 (LLM) 提供了兩個強大的基準線。這項工作提供了一項艱鉅的任務、處理任務的基準方法，以及菜餚名稱辨識背景中組合概化的見解。程式碼和資料可在 https://github.com/Jumpy-pku/DiNeR 取得。

##### **Advanced Payment Security System:XGBoost, CatBoost and SMOTE Integrated**
2406.04658v1 by Qi Zheng, Chang Yu, Jin Cao, Yongshun Xu, Qianwen Xing, Yinxin Jin

With the rise of various online and mobile payment systems, transaction fraud
has become a significant threat to financial security. This study explores the
application of advanced machine learning models, specifically XGBoost and
LightGBM, for developing a more accurate and robust Payment Security Protection
Model.To enhance data reliability, we meticulously processed the data sources
and used SMOTE (Synthetic Minority Over-sampling Technique) to address class
imbalance and improve data representation. By selecting highly correlated
features, we aimed to strengthen the training process and boost model
performance.We conducted thorough performance evaluations of our proposed
models, comparing them against traditional methods including Random Forest,
Neural Network, and Logistic Regression. Key metrics such as Precision, Recall,
and F1 Score were used to rigorously assess their effectiveness.Our detailed
analyses and comparisons reveal that the combination of SMOTE with XGBoost and
LightGBM offers a highly efficient and powerful mechanism for payment security
protection. The results show that these models not only outperform traditional
approaches but also hold significant promise for advancing the field of
transaction fraud prevention.

摘要：隨著各種線上和行動支付系統的興起，交易詐騙已成為金融安全的重大威脅。本研究探討了先進機器學習模型（特別是 XGBoost 和 LightGBM）在開發更準確且穩健的支付安全防護模型中的應用。為了提升資料可靠性，我們仔細處理了資料來源，並使用 SMOTE（合成少數過採樣技術）來解決類別不平衡並改善資料表示。透過選擇高度相關的特性，我們旨在加強訓練流程並提升模型效能。我們對提出的模型進行了徹底的效能評估，並將它們與傳統方法（包括隨機森林、神經網路和邏輯迴歸）進行比較。我們使用準確度、召回率和 F1 分數等關鍵指標來嚴格評估它們的有效性。我們的詳細分析和比較顯示，SMOTE 與 XGBoost 和 LightGBM 的結合提供了一個高效且強大的支付安全防護機制。結果表明，這些模型不僅優於傳統方法，而且對於推進交易詐騙防範領域也具有重大意義。

##### **Crafting Heavy-Tails in Weight Matrix Spectrum without Gradient Noise**
2406.04657v1 by Vignesh Kothapalli, Tianyu Pang, Shenyang Deng, Zongmin Liu, Yaoqing Yang

Modern training strategies of deep neural networks (NNs) tend to induce a
heavy-tailed (HT) spectra of layer weights. Extensive efforts to study this
phenomenon have found that NNs with HT weight spectra tend to generalize well.
A prevailing notion for the occurrence of such HT spectra attributes gradient
noise during training as a key contributing factor. Our work shows that
gradient noise is unnecessary for generating HT weight spectra: two-layer NNs
trained with full-batch Gradient Descent/Adam can exhibit HT spectra in their
weights after finite training steps. To this end, we first identify the scale
of the learning rate at which one step of full-batch Adam can lead to feature
learning in the shallow NN, particularly when learning a single index teacher
model. Next, we show that multiple optimizer steps with such (sufficiently)
large learning rates can transition the bulk of the weight's spectra into an HT
distribution. To understand this behavior, we present a novel perspective based
on the singular vectors of the weight matrices and optimizer updates. We show
that the HT weight spectrum originates from the `spike', which is generated
from feature learning and interacts with the main bulk to generate an HT
spectrum. Finally, we analyze the correlations between the HT weight spectra
and generalization after multiple optimizer updates with varying learning
rates.

摘要：現代深度神經網路 (NN) 的訓練策略傾向於誘發層權重的重尾 (HT) 頻譜。針對此現象進行廣泛研究發現，具有 HT 權重頻譜的 NN 傾向於泛化良好。對於此類 HT 頻譜發生的普遍概念將訓練期間的梯度雜訊歸因於一個關鍵的促成因素。我們的研究表明，梯度雜訊對於產生 HT 權重頻譜並非必要：使用全批次梯度下降/Adam 訓練的兩層 NN 在經過有限的訓練步驟後，其權重中可能會出現 HT 頻譜。為此，我們首先找出全批次 Adam 的一步可以導致淺層 NN 中的特徵學習的學習率規模，特別是在學習單一索引教師模型時。接下來，我們展示了具有此類（足夠）大學習率的多個最佳化步驟可以將權重頻譜的大部分轉換為 HT 分布。為了理解此行為，我們根據權重矩陣和最佳化更新的奇異向量提出了一個新觀點。我們展示了 HT 權重頻譜源自於「尖峰」，該尖峰是由特徵學習產生的，並與主體交互以產生 HT 頻譜。最後，我們分析了在具有不同學習率的多個最佳化更新後，HT 權重頻譜與泛化之間的關聯性。

##### **More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play**
2406.04643v1 by Wichayaporn Wongkamjan, Feng Gu, Yanze Wang, Ulf Hermjakob, Jonathan May, Brandon M. Stewart, Jonathan K. Kummerfeld, Denis Peskoff, Jordan Lee Boyd-Graber

The boardgame Diplomacy is a challenging setting for communicative and
cooperative artificial intelligence. The most prominent communicative Diplomacy
AI, Cicero, has excellent strategic abilities, exceeding human players.
However, the best Diplomacy players master communication, not just tactics,
which is why the game has received attention as an AI challenge. This work
seeks to understand the degree to which Cicero succeeds at communication.
First, we annotate in-game communication with abstract meaning representation
to separate in-game tactics from general language. Second, we run two dozen
games with humans and Cicero, totaling over 200 human-player hours of
competition. While AI can consistently outplay human players, AI-Human
communication is still limited because of AI's difficulty with deception and
persuasion. This shows that Cicero relies on strategy and has not yet reached
the full promise of communicative and cooperative AI.

摘要：桌遊 Diplomacy 是溝通與合作人工智慧的挑戰性設定。最著名的溝通型 Diplomacy AI，Cicero，擁有絕佳的策略能力，超越人類玩家。然而，最好的 Diplomacy 玩家精通溝通，而非僅是戰術，這也是遊戲作為 AI 挑戰受到關注的原因。這項工作旨在了解 Cicero 在溝通方面成功的程度。首先，我們使用抽象意義表徵為遊戲內溝通加上註解，以將遊戲內戰術與一般語言區分開來。其次，我們與人類和 Cicero 進行了 20 多場遊戲，總計超過 200 小時的人類玩家競賽。儘管 AI 能夠持續勝過人類玩家，但由於 AI 難以進行欺騙和說服，因此 AI 與人類的溝通仍然受到限制。這顯示 Cicero 依賴於策略，尚未達到溝通與合作 AI 的全部承諾。

##### **Cooperative Meta-Learning with Gradient Augmentation**
2406.04639v1 by Jongyun Shin, Seunjin Han, Jangho Kim

Model agnostic meta-learning (MAML) is one of the most widely used
gradient-based meta-learning, consisting of two optimization loops: an inner
loop and outer loop. MAML learns the new task from meta-initialization
parameters with an inner update and finds the meta-initialization parameters in
the outer loop. In general, the injection of noise into the gradient of the
model for augmenting the gradient is one of the widely used regularization
methods. In this work, we propose a novel cooperative meta-learning framework
dubbed CML which leverages gradient-level regularization with gradient
augmentation. We inject learnable noise into the gradient of the model for the
model generalization. The key idea of CML is introducing the co-learner which
has no inner update but the outer loop update to augment gradients for finding
better meta-initialization parameters. Since the co-learner does not update in
the inner loop, it can be easily deleted after meta-training. Therefore, CML
infers with only meta-learner without additional cost and performance
degradation. We demonstrate that CML is easily applicable to gradient-based
meta-learning methods and CML leads to increased performance in few-shot
regression, few-shot image classification and few-shot node classification
tasks. Our codes are at https://github.com/JJongyn/CML.

摘要：模型不可知元學習 (MAML) 是一種最廣泛使用的基於梯度的元學習，包含兩個優化迴圈：一個內部迴圈和一個外部迴圈。MAML 從元初始化參數中學習新任務，並使用內部更新，並在外部迴圈中找到元初始化參數。一般來說，將雜訊注入模型梯度以擴充梯度是廣泛使用的正則化方法之一。在這項工作中，我們提出了一個新穎的協作元學習框架，稱為 CML，它利用梯度層級正則化和梯度擴充。我們將可學習的雜訊注入模型梯度中，以進行模型泛化。CML 的關鍵思想是引入共同學習器，它沒有內部更新，但外部迴圈更新可以擴充梯度，以找到更好的元初始化參數。由於共同學習器不會在內部迴圈中更新，因此可以在元訓練後輕鬆刪除它。因此，CML 推斷僅使用元學習器，而沒有額外的成本和效能下降。我們證明 CML 容易應用於基於梯度的元學習方法，並且 CML 可以在少次數迴歸、少次數影像分類和少次數節點分類任務中提升效能。我們的程式碼在 https://github.com/JJongyn/CML。

##### **Large Language Model-guided Document Selection**
2406.04638v1 by Xiang Kong, Tom Gunter, Ruoming Pang

Large Language Model (LLM) pre-training exhausts an ever growing compute
budget, yet recent research has demonstrated that careful document selection
enables comparable model quality with only a fraction of the FLOPs. Inspired by
efforts suggesting that domain-specific training document selection is in fact
an interpretable process [Gunasekar et al., 2023], as well as research showing
that instruction-finetuned LLMs are adept zero-shot data labelers [Gilardi et
al.,2023], we explore a promising direction for scalable general-domain
document selection; employing a prompted LLM as a document grader, we distill
quality labels into a classifier model, which is applied at scale to a large,
and already heavily-filtered, web-crawl-derived corpus autonomously. Following
the guidance of this classifier, we drop 75% of the corpus and train LLMs on
the remaining data. Results across multiple benchmarks show that: 1. Filtering
allows us to quality-match a model trained on the full corpus across diverse
benchmarks with at most 70% of the FLOPs, 2. More capable LLM labelers and
classifier models lead to better results that are less sensitive to the
labeler's prompt, 3. In-context learning helps to boost the performance of
less-capable labeling models. In all cases we use open-source datasets, models,
recipes, and evaluation frameworks, so that results can be reproduced by the
community.

摘要：<paragraph>大型語言模型 (LLM) 預訓練耗盡了不斷增長的運算預算，但最近的研究表明，仔細的文件選取僅需一小部分 FLOP 就能實現相當的模型品質。受到以下努力的啟發：建議特定領域訓練文件選取實際上是一個可詮釋的過程 [Gunasekar 等人，2023]，以及研究表明經過指令微調的 LLM 是熟練的零次資料標籤器 [Gilardi 等人，2023]，我們探索了一個有望用於可擴充一般領域文件選取的方向；使用提示式 LLM 作為文件評分員，我們將品質標籤提煉成一個分類器模型，大規模應用於一個大型且經過大量篩選的網路爬取衍生語料庫中，而且是自動化的。遵循這個分類器的指導，我們捨棄了語料庫的 75%，並使用剩餘的資料訓練 LLM。多個基準測試的結果顯示：1. 透過篩選，我們能夠在最多 70% 的 FLOP 中，針對不同基準測試比對訓練完整語料庫的模型品質，2. 更有能力的 LLM 標籤器和分類器模型會產生更好的結果，且這些結果對標籤器的提示較不敏感，3. 情境學習有助於提升較不具備能力的標籤模型的效能。在所有情況下，我們都使用開源資料集、模型、範例和評估架構，以便社群可以複製結果。</paragraph>

##### **Scaling Automatic Extraction of Pseudocode**
2406.04635v1 by Levent Toksoz, Gang Tan, C. Lee Giles

Pseudocode in a scholarly paper provides a concise way to express the
algorithms implemented therein. Pseudocode can also be thought of as an
intermediary representation that helps bridge the gap between programming
languages and natural languages. Having access to a large collection of
pseudocode can provide various benefits ranging from enhancing algorithmic
understanding, facilitating further algorithmic design, to empowering NLP or
computer vision based models for tasks such as automated code generation and
optical character recognition (OCR). We have created a large pseudocode
collection by extracting nearly 320,000 pseudocode examples from arXiv papers.
This process involved scanning over $2.2$ million scholarly papers, with 1,000
of them being manually inspected and labeled. Our approach encompasses an
extraction mechanism tailored to optimize the coverage and a validation
mechanism based on random sampling to check its accuracy and reliability, given
the inherent heterogeneity of the collection. In addition, we offer insights
into common pseudocode structures, supported by clustering and statistical
analyses. Notably, these analyses indicate an exponential-like growth in the
usage of pseudocodes, highlighting their increasing significance.

摘要：在學術論文中，偽代碼提供了一種簡潔的方式來表達其中實作的演算法。偽代碼也可以被視為一種中間表示，有助於彌合程式語言和自然語言之間的差距。存取大量的偽代碼可以提供各種好處，從增強演算法理解、促進進一步的演算法設計，到賦能 NLP 或基於電腦視覺的模型，以執行自動化程式碼產生和光學字元辨識 (OCR) 等任務。我們從 arXiv 論文中萃取了近 320,000 個偽代碼範例，建立了一個大型偽代碼集合。這個程序包括掃描超過 220 萬篇學術論文，並手動檢查和標記其中的 1,000 篇。我們的做法包含了一個萃取機制，專門用於最佳化涵蓋範圍，以及一個基於隨機抽樣的驗證機制，以檢查其準確性和可靠性，考量到這個集合的內在異質性。此外，我們提供了對常見偽代碼結構的見解，並輔以分群和統計分析。值得注意的是，這些分析顯示偽代碼的使用呈指數成長，突顯出它們日益重要的意義。

##### **Low-Resource Cross-Lingual Summarization through Few-Shot Learning with Large Language Models**
2406.04630v1 by Gyutae Park, Seojin Hwang, Hwanhee Lee

Cross-lingual summarization (XLS) aims to generate a summary in a target
language different from the source language document. While large language
models (LLMs) have shown promising zero-shot XLS performance, their few-shot
capabilities on this task remain unexplored, especially for low-resource
languages with limited parallel data. In this paper, we investigate the
few-shot XLS performance of various models, including Mistral-7B-Instruct-v0.2,
GPT-3.5, and GPT-4. Our experiments demonstrate that few-shot learning
significantly improves the XLS performance of LLMs, particularly GPT-3.5 and
GPT-4, in low-resource settings. However, the open-source model
Mistral-7B-Instruct-v0.2 struggles to adapt effectively to the XLS task with
limited examples. Our findings highlight the potential of few-shot learning for
improving XLS performance and the need for further research in designing LLM
architectures and pre-training objectives tailored for this task. We provide a
future work direction to explore more effective few-shot learning strategies
and to investigate the transfer learning capabilities of LLMs for cross-lingual
summarization.

摘要：跨語言摘要 (XLS) 旨在以與原始語言文件不同的目標語言產生摘要。儘管大型語言模型 (LLM) 已展現出有前景的零次學習 XLS 效能，但它們在這個任務上的少量學習能力仍未被探索，特別是對於平行資料有限的低資源語言。在本文中，我們探討各種模型的少量學習 XLS 效能，包括 Mistral-7B-Instruct-v0.2、GPT-3.5 和 GPT-4。我們的實驗證明，少量學習顯著提升了 LLM 的 XLS 效能，特別是在低資源設定中的 GPT-3.5 和 GPT-4。然而，開源模型 Mistral-7B-Instruct-v0.2 難以有效適應範例有限的 XLS 任務。我們的研究結果突顯了少量學習在提升 XLS 效能方面的潛力，以及進一步研究設計針對此任務量身打造的 LLM 架構和預訓練目標的必要性。我們提供了一個未來的研究方向，以探索更有效的少量學習策略，並探討 LLM 在跨語言摘要中的轉移學習能力。

##### **Denoising-Aware Contrastive Learning for Noisy Time Series**
2406.04627v1 by Shuang Zhou, Daochen Zha, Xiao Shen, Xiao Huang, Rui Zhang, Fu-Lai Chung

Time series self-supervised learning (SSL) aims to exploit unlabeled data for
pre-training to mitigate the reliance on labels. Despite the great success in
recent years, there is limited discussion on the potential noise in the time
series, which can severely impair the performance of existing SSL methods. To
mitigate the noise, the de facto strategy is to apply conventional denoising
methods before model training. However, this pre-processing approach may not
fully eliminate the effect of noise in SSL for two reasons: (i) the diverse
types of noise in time series make it difficult to automatically determine
suitable denoising methods; (ii) noise can be amplified after mapping raw data
into latent space. In this paper, we propose denoising-aware contrastive
learning (DECL), which uses contrastive learning objectives to mitigate the
noise in the representation and automatically selects suitable denoising
methods for every sample. Extensive experiments on various datasets verify the
effectiveness of our method. The code is open-sourced.

摘要：時間序列自我監督學習 (SSL) 旨在利用未標籤資料進行預訓練，以減輕對標籤的依賴。儘管近年來取得了巨大的成功，但對於時間序列中潛在的雜訊討論有限，這可能會嚴重損害現有 SSL 方法的效能。為了減輕雜訊，事實上的策略是在模型訓練之前應用傳統的去雜訊方法。然而，這種預處理方法可能無法完全消除 SSL 中雜訊的影響，原因有二：(i) 時間序列中種類繁多的雜訊使得難以自動確定合適的去雜訊方法；(ii) 在將原始資料對應到潛在空間後，雜訊可能會被放大。在本文中，我們提出具備去雜訊意識的對比學習 (DECL)，它使用對比學習目標來減輕表示式中的雜訊，並自動為每個樣本選擇合適的去雜訊方法。在各種資料集上進行的廣泛實驗驗證了我們方法的有效性。程式碼已開源。

##### **Key-Element-Informed sLLM Tuning for Document Summarization**
2406.04625v1 by Sangwon Ryu, Heejin Do, Yunsu Kim, Gary Geunbae Lee, Jungseul Ok

Remarkable advances in large language models (LLMs) have enabled high-quality
text summarization. However, this capability is currently accessible only
through LLMs of substantial size or proprietary LLMs with usage fees. In
response, smaller-scale LLMs (sLLMs) of easy accessibility and low costs have
been extensively studied, yet they often suffer from missing key information
and entities, i.e., low relevance, in particular, when input documents are
long. We hence propose a key-element-informed instruction tuning for
summarization, so-called KEITSum, which identifies key elements in documents
and instructs sLLM to generate summaries capturing these key elements.
Experimental results on dialogue and news datasets demonstrate that sLLM with
KEITSum indeed provides high-quality summarization with higher relevance and
less hallucinations, competitive to proprietary LLM.

摘要：大型語言模型 (LLM) 的顯著進展實現了高品質的文字摘要。然而，此功能目前只能透過規模龐大的 LLM 或具有使用費用的專有 LLM 來存取。為了回應此問題，容易存取且成本低的小型 LLM (sLLM) 已廣泛研究，但它們經常會遺漏關鍵資訊和實體，即相關性低，特別是在輸入文件很長時。因此，我們提出一個關鍵元素知情說明調整，用於摘要，稱為 KEITSum，它會識別文件中關鍵元素並指示 sLLM 產生擷取這些關鍵元素的摘要。對話和新聞資料集的實驗結果證明，具備 KEITSum 的 sLLM 確實提供了高品質的摘要，具有更高的相關性和更少的幻覺，可與專有 LLM 相媲美。

##### **What do MLLMs hear? Examining reasoning with text and sound components in Multimodal Large Language Models**
2406.04615v1 by Enis Berk Çoban, Michael I. Mandel, Johanna Devaney

Large Language Models (LLMs) have demonstrated remarkable reasoning
capabilities, notably in connecting ideas and adhering to logical rules to
solve problems. These models have evolved to accommodate various data
modalities, including sound and images, known as multimodal LLMs (MLLMs), which
are capable of describing images or sound recordings. Previous work has
demonstrated that when the LLM component in MLLMs is frozen, the audio or
visual encoder serves to caption the sound or image input facilitating
text-based reasoning with the LLM component. We are interested in using the
LLM's reasoning capabilities in order to facilitate classification. In this
paper, we demonstrate through a captioning/classification experiment that an
audio MLLM cannot fully leverage its LLM's text-based reasoning when generating
audio captions. We also consider how this may be due to MLLMs separately
representing auditory and textual information such that it severs the reasoning
pathway from the LLM to the audio encoder.

摘要：大型語言模型 (LLM) 已展示出非凡的推理能力，尤其是在連接想法和遵守邏輯規則以解決問題方面。這些模型已演變為適應各種數據模式，包括聲音和圖像，稱為多模態 LLM (MLLM)，它們能夠描述圖像或聲音記錄。先前的研究表明，當 MLLM 中的 LLM 組件被凍結時，音訊或視覺編碼器用於標註聲音或圖像輸入，從而促進與 LLM 組件的基於文本的推理。我們有興趣利用 LLM 的推理能力來促進分類。在本文中，我們通過標題/分類實驗證明，音訊 MLLM 在生成音訊標題時無法充分利用其 LLM 的基於文本的推理。我們還考慮這可能是由於 MLLM 分別表示聽覺和文本信息，從而切斷了 LLM 到音訊編碼器的推理路徑。

##### **LawGPT: A Chinese Legal Knowledge-Enhanced Large Language Model**
2406.04614v1 by Zhi Zhou, Jiang-Xin Shi, Peng-Xiao Song, Xiao-Wen Yang, Yi-Xuan Jin, Lan-Zhe Guo, Yu-Feng Li

Large language models (LLMs), including both proprietary and open-source
models, have showcased remarkable capabilities in addressing a wide range of
downstream tasks. Nonetheless, when it comes to practical Chinese legal tasks,
these models fail to meet the actual requirements. Proprietary models do not
ensure data privacy for sensitive legal cases, while open-source models
demonstrate unsatisfactory performance due to their lack of legal knowledge. To
address this problem, we introduce LawGPT, the first open-source model
specifically designed for Chinese legal applications. LawGPT comprises two key
components: legal-oriented pre-training and legal supervised fine-tuning.
Specifically, we employ large-scale Chinese legal documents for legal-oriented
pre-training to incorporate legal domain knowledge. To further improve the
model's performance on downstream legal tasks, we create a knowledge-driven
instruction dataset for legal supervised fine-tuning. Our experimental results
demonstrate that LawGPT outperforms the open-source LLaMA 7B model. Our code
and resources are publicly available at https://github.com/pengxiao-song/LaWGPT
and have received 5.7K stars on GitHub.

摘要：大型語言模型 (LLM)，包括專有和開源模型，已展現出在處理廣泛的下游任務中非凡的能力。儘管如此，當涉及到實際的中國法律任務時，這些模型未能滿足實際要求。專有模型無法確保敏感法律案件的數據隱私，而開源模型由於缺乏法律知識而表現不佳。為了解決這個問題，我們介紹了 LawGPT，這是第一個專門為中國法律應用設計的開源模型。LawGPT 包含兩個關鍵組成部分：面向法律的預訓練和法律監督微調。具體來說，我們採用了大規模的中國法律文件進行面向法律的預訓練，以納入法律領域知識。為了進一步提高模型在下游法律任務上的表現，我們為法律監督微調創建了一個知識驅動的指令數據集。我們的實驗結果表明，LawGPT 優於開源 LLaMA 7B 模型。我們的代碼和資源已在 https://github.com/pengxiao-song/LaWGPT 上公開，並已在 GitHub 上獲得 5.7K 星。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Diverse Intra- and Inter-Domain Activity Style Fusion for Cross-Person Generalization in Activity Recognition**
2406.04609v1 by Junru Zhang, Lang Feng, Zhidan Liu, Yuhan Wu, Yang He, Yabo Dong, Duanqing Xu

Existing domain generalization (DG) methods for cross-person generalization
tasks often face challenges in capturing intra- and inter-domain style
diversity, resulting in domain gaps with the target domain. In this study, we
explore a novel perspective to tackle this problem, a process conceptualized as
domain padding. This proposal aims to enrich the domain diversity by
synthesizing intra- and inter-domain style data while maintaining robustness to
class labels. We instantiate this concept using a conditional diffusion model
and introduce a style-fused sampling strategy to enhance data generation
diversity. In contrast to traditional condition-guided sampling, our
style-fused sampling strategy allows for the flexible use of one or more random
styles to guide data synthesis. This feature presents a notable advancement: it
allows for the maximum utilization of possible permutations and combinations
among existing styles to generate a broad spectrum of new style instances.
Empirical evaluations on a board of datasets demonstrate that our generated
data achieves remarkable diversity within the domain space. Both intra- and
inter-domain generated data have proven to be significant and valuable,
contributing to varying degrees of performance enhancements. Notably, our
approach outperforms state-of-the-art DG methods in all human activity
recognition tasks.

摘要：現有的跨人泛化任務的網域泛化 (DG) 方法通常在捕捉網域內和網域間的樣式多樣性時面臨挑戰，導致與目標網域出現網域差距。在本研究中，我們探索一種解決此問題的新觀點，一個概念化為網域填充的過程。此提案旨在透過合成網域內和網域間樣式資料，同時維持對類別標籤的穩健性，來豐富網域多樣性。我們使用條件擴散模型實例化此概念，並引入一種樣式融合抽樣策略來增強資料產生多樣性。與傳統條件引導抽樣相反，我們的樣式融合抽樣策略允許靈活使用一個或多個隨機樣式來引導資料合成。此功能呈現顯著進步：它允許最大程度地利用現有樣式中可能的排列組合來產生廣泛的新樣式實例。在資料集委員會上的經驗評估表明，我們產生的資料在網域空間內實現了顯著的多樣性。網域內和網域間產生的資料已被證明具有重要性和價值，在不同程度的效能提升中有所貢獻。值得注意的是，我們的做法在所有人類活動辨識任務中都優於最先進的 DG 方法。

##### **MeGA: Merging Multiple Independently Trained Neural Networks Based on Genetic Algorithm**
2406.04607v1 by Daniel Yun

In this paper, we introduce a novel method for merging the weights of
multiple pre-trained neural networks using a genetic algorithm called MeGA.
Traditional techniques, such as weight averaging and ensemble methods, often
fail to fully harness the capabilities of pre-trained networks. Our approach
leverages a genetic algorithm with tournament selection, crossover, and
mutation to optimize weight combinations, creating a more effective fusion.
This technique allows the merged model to inherit advantageous features from
both parent models, resulting in enhanced accuracy and robustness. Through
experiments on the CIFAR-10 dataset, we demonstrate that our genetic
algorithm-based weight merging method improves test accuracy compared to
individual models and conventional methods. This approach provides a scalable
solution for integrating multiple pre-trained networks across various deep
learning applications. Github is available at:
https://github.com/YUNBLAK/MeGA-Merging-Multiple-Independently-Trained-Neural-Networks-Based-on-Genetic-Algorithm

摘要：在本文中，我們介紹了一種使用稱為 MeGA 的遺傳演算法來合併多個預訓練神經網路權重的創新方法。傳統技術，例如權重平均和集成方法，通常無法充分利用預訓練網路的能力。我們的方法利用具有錦標賽選擇、交叉和突變的遺傳演算法來最佳化權重組合，創造更有效的融合。此技術允許合併的模型繼承來自兩個父模型的優勢特徵，從而提高準確性和穩健性。透過在 CIFAR-10 資料集上的實驗，我們證明了我們的基於遺傳演算法的權重合併方法與個別模型和傳統方法相比，改進了測試準確性。這種方法提供了一個可擴充的解決方案，用於整合多個預訓練網路，以應用於各種深度學習應用。Github 可在以下網址取得：
https://github.com/YUNBLAK/MeGA-Merging-Multiple-Independently-Trained-Neural-Networks-Based-on-Genetic-Algorithm

##### **Helpful or Harmful Data? Fine-tuning-free Shapley Attribution for Explaining Language Model Predictions**
2406.04606v1 by Jingtan Wang, Xiaoqiang Lin, Rui Qiao, Chuan-Sheng Foo, Bryan Kian Hsiang Low

The increasing complexity of foundational models underscores the necessity
for explainability, particularly for fine-tuning, the most widely used training
method for adapting models to downstream tasks. Instance attribution, one type
of explanation, attributes the model prediction to each training example by an
instance score. However, the robustness of instance scores, specifically
towards dataset resampling, has been overlooked. To bridge this gap, we propose
a notion of robustness on the sign of the instance score. We theoretically and
empirically demonstrate that the popular leave-one-out-based methods lack
robustness, while the Shapley value behaves significantly better, but at a
higher computational cost. Accordingly, we introduce an efficient
fine-tuning-free approximation of the Shapley value (FreeShap) for instance
attribution based on the neural tangent kernel. We empirically demonstrate that
FreeShap outperforms other methods for instance attribution and other
data-centric applications such as data removal, data selection, and wrong label
detection, and further generalize our scale to large language models (LLMs).
Our code is available at https://github.com/JTWang2000/FreeShap.

摘要：基础模型日益复杂，凸显了可解释性的必要性，特别是对于微调，这是用于将模型调整为下游任务的最广泛使用的训练方法。实例归因是一种解释，它通过实例分数将模型预测归因于每个训练示例。然而，实例分数的鲁棒性，特别是对于数据集重新采样，已被忽视。为了弥合这一差距，我们提出了一个关于实例分数符号的鲁棒性概念。我们从理论和经验上证明，流行的留一法缺乏鲁棒性，而 Shapley 值表现得明显更好，但计算成本更高。因此，我们引入了一种基于神经切线核的 Shapley 值（FreeShap）的高效微调自由近似值，用于实例归因。我们通过实验证明，FreeShap 在实例归因和其他以数据为中心的任务（例如数据删除、数据选择和错误标签检测）方面优于其他方法，并进一步将我们的规模推广到大型语言模型 (LLM)。我们的代码可在 https://github.com/JTWang2000/FreeShap 获得。

##### **Learning Task Decomposition to Assist Humans in Competitive Programming**
2406.04604v1 by Jiaxin Wen, Ruiqi Zhong, Pei Ke, Zhihong Shao, Hongning Wang, Minlie Huang

When using language models (LMs) to solve complex problems, humans might
struggle to understand the LM-generated solutions and repair the flawed ones.
To assist humans in repairing them, we propose to automatically decompose
complex solutions into multiple simpler pieces that correspond to specific
subtasks. We introduce a novel objective for learning task decomposition,
termed assistive value (AssistV), which measures the feasibility and speed for
humans to repair the decomposed solution. We collect a dataset of human repair
experiences on different decomposed solutions. Utilizing the collected data as
in-context examples, we then learn to critique, refine, and rank decomposed
solutions to improve AssistV. We validate our method under competitive
programming problems: under 177 hours of human study, our method enables
non-experts to solve 33.3\% more problems, speeds them up by 3.3x, and empowers
them to match unassisted experts.

摘要：在使用语言模型 (LM) 解決複雜問題時，人類可能會難以理解 LM 生成的解決方案並修復有缺陷的解決方案。為了協助人類修復它們，我們建議自動將複雜的解決方案分解為多個較簡單的部分，這些部分對應於特定的子任務。我們引入了一個用於學習任務分解的新目標，稱為輔助值 (AssistV)，它衡量人類修復分解解決方案的可行性和速度。我們收集了一個關於人類在不同分解解決方案上的修復經驗的數據集。利用收集到的數據作為上下文範例，我們接著學習批評、優化和排列分解的解決方案以改善 AssistV。我們在競爭性程式設計問題中驗證了我們的方法：在 177 小時的研究所需時間內，我們的辦法讓非專家解決了 33.3% 以上的問題，讓他們的速度提升了 3.3 倍，並讓他們的能力與未受協助的專家相匹配。

