{"2412.18216": {"publish_time": "2024-12-24", "title": "ICM-Assistant: Instruction-tuning Multimodal Large Language Models for Rule-based Explainable Image Content Moderation", "paper_summary": "Controversial contents largely inundate the Internet, infringing various\ncultural norms and child protection standards. Traditional Image Content\nModeration (ICM) models fall short in producing precise moderation decisions\nfor diverse standards, while recent multimodal large language models (MLLMs),\nwhen adopted to general rule-based ICM, often produce classification and\nexplanation results that are inconsistent with human moderators. Aiming at\nflexible, explainable, and accurate ICM, we design a novel rule-based dataset\ngeneration pipeline, decomposing concise human-defined rules and leveraging\nwell-designed multi-stage prompts to enrich short explicit image annotations.\nOur ICM-Instruct dataset includes detailed moderation explanation and\nmoderation Q-A pairs. Built upon it, we create our ICM-Assistant model in the\nframework of rule-based ICM, making it readily applicable in real practice. Our\nICM-Assistant model demonstrates exceptional performance and flexibility.\nSpecifically, it significantly outperforms existing approaches on various\nsources, improving both the moderation classification (36.8\\% on average) and\nmoderation explanation quality (26.6\\% on average) consistently over existing\nMLLMs. Code/Data is available at https://github.com/zhaoyuzhi/ICM-Assistant.", "paper_summary_zh": "\u6709\u722d\u8b70\u7684\u5167\u5bb9\u5927\u91cf\u5145\u65a5\u5728\u7db2\u8def\u4e0a\uff0c\u4fb5\u72af\u5404\u7a2e\u6587\u5316\u898f\u7bc4\u548c\u5152\u7ae5\u4fdd\u8b77\u6a19\u6e96\u3002\u50b3\u7d71\u7684\u5f71\u50cf\u5167\u5bb9\u5be9\u6838 (ICM) \u6a21\u578b\u7121\u6cd5\u91dd\u5c0d\u4e0d\u540c\u7684\u6a19\u6e96\u63d0\u51fa\u7cbe\u78ba\u7684\u5be9\u6838\u6c7a\u5b9a\uff0c\u800c\u6700\u8fd1\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u5728\u63a1\u7528\u4e00\u822c\u57fa\u65bc\u898f\u5247\u7684 ICM \u6642\uff0c\u901a\u5e38\u6703\u7522\u751f\u8207\u4eba\u5de5\u5be9\u6838\u54e1\u4e0d\u4e00\u81f4\u7684\u5206\u985e\u548c\u8aaa\u660e\u7d50\u679c\u3002\u70ba\u4e86\u5be6\u73fe\u5f48\u6027\u3001\u53ef\u89e3\u91cb\u548c\u7cbe\u78ba\u7684 ICM\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u57fa\u65bc\u898f\u5247\u7684\u8cc7\u6599\u96c6\u751f\u6210\u7ba1\u9053\uff0c\u5206\u89e3\u7c21\u6f54\u7684\u4eba\u985e\u5b9a\u7fa9\u898f\u5247\uff0c\u4e26\u5229\u7528\u8a2d\u8a08\u826f\u597d\u7684\u591a\u968e\u6bb5\u63d0\u793a\u4f86\u8c50\u5bcc\u7c21\u77ed\u7684\u660e\u78ba\u5f71\u50cf\u8a3b\u89e3\u3002\u6211\u5011\u7684 ICM-Instruct \u8cc7\u6599\u96c6\u5305\u542b\u8a73\u7d30\u7684\u5be9\u6838\u8aaa\u660e\u548c\u5be9\u6838\u554f\u7b54\u5c0d\u3002\u5efa\u7acb\u5728\u5b83\u7684\u57fa\u790e\u4e0a\uff0c\u6211\u5011\u5728\u57fa\u65bc\u898f\u5247\u7684 ICM \u7684\u67b6\u69cb\u4e2d\u5efa\u7acb\u4e86\u6211\u5011\u7684 ICM-Assistant \u6a21\u578b\uff0c\u4f7f\u5176\u6613\u65bc\u61c9\u7528\u65bc\u5be6\u969b\u64cd\u4f5c\u4e2d\u3002\u6211\u5011\u7684 ICM-Assistant \u6a21\u578b\u5c55\u793a\u51fa\u5353\u8d8a\u7684\u6548\u80fd\u548c\u5f48\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5b83\u5728\u5404\u7a2e\u4f86\u6e90\u4e0a\u90fd\u986f\u8457\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\uff0c\u6301\u7e8c\u6539\u5584\u5be9\u6838\u5206\u985e\uff08\u5e73\u5747 36.8%\uff09\u548c\u5be9\u6838\u8aaa\u660e\u54c1\u8cea\uff08\u5e73\u5747 26.6%\uff09\uff0c\u512a\u65bc\u73fe\u6709\u7684 MLLM\u3002\u7a0b\u5f0f\u78bc/\u8cc7\u6599\u53ef\u5728 https://github.com/zhaoyuzhi/ICM-Assistant \u53d6\u5f97\u3002", "author": "Mengyang Wu et.al.", "authors": "Mengyang Wu, Yuzhi Zhao, Jialun Cao, Mingjie Xu, Zhongming Jiang, Xuehui Wang, Qinbin Li, Guangneng Hu, Shengchao Qin, Chi-Wing Fu", "id": "2412.18216v1", "paper_url": "http://arxiv.org/abs/2412.18216v1", "repo": "https://github.com/zhaoyuzhi/icm-assistant"}}