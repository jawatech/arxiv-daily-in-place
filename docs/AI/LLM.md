
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-16**|**MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization**|Bhavya Sukhija et.al.|[2412.12098v1](http://arxiv.org/abs/2412.12098v1)|null|
|**2024-12-16**|**SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator**|Guoxuan Chen et.al.|[2412.12094v1](http://arxiv.org/abs/2412.12094v1)|[link](https://github.com/HKUDS/SepLLM)|
|**2024-12-16**|**Stabilizing Reinforcement Learning in Differentiable Multiphysics Simulation**|Eliot Xing et.al.|[2412.12089v1](http://arxiv.org/abs/2412.12089v1)|null|
|**2024-12-16**|**Making FETCH! Happen: Finding Emergent Dog Whistles Through Common Habitats**|Kuleen Sasse et.al.|[2412.12072v1](http://arxiv.org/abs/2412.12072v1)|[link](https://github.com/kuleens/fetch-dog-whistle)|
|**2024-12-16**|**Revelations: A Decidable Class of POMDPs with Omega-Regular Objectives**|Marius Belly et.al.|[2412.12063v1](http://arxiv.org/abs/2412.12063v1)|null|
|**2024-12-16**|**How Private are Language Models in Abstractive Summarization?**|Anthony Hughes et.al.|[2412.12040v1](http://arxiv.org/abs/2412.12040v1)|null|
|**2024-12-16**|**Can LLM Prompting Serve as a Proxy for Static Analysis in Vulnerability Detection**|Ira Ceka et.al.|[2412.12039v1](http://arxiv.org/abs/2412.12039v1)|null|
|**2024-12-16**|**FSFM: A Generalizable Face Security Foundation Model via Self-Supervised Facial Representation Learning**|Gaojian Wang et.al.|[2412.12032v1](http://arxiv.org/abs/2412.12032v1)|null|
|**2024-12-16**|**Learning to Navigate in Mazes with Novel Layouts using Abstract Top-down Maps**|Linfeng Zhao et.al.|[2412.12024v1](http://arxiv.org/abs/2412.12024v1)|null|
|**2024-12-16**|**SpeechPrune: Context-aware Token Pruning for Speech Information Retrieval**|Yueqian Lin et.al.|[2412.12009v1](http://arxiv.org/abs/2412.12009v1)|null|
|**2024-12-16**|**The Open Source Advantage in Large Language Models (LLMs)**|Jiya Manchanda et.al.|[2412.12004v1](http://arxiv.org/abs/2412.12004v1)|null|
|**2024-12-16**|**LLM-RG4: Flexible and Factual Radiology Report Generation across Diverse Input Contexts**|Zhuhao Wang et.al.|[2412.12001v1](http://arxiv.org/abs/2412.12001v1)|null|
|**2024-12-16**|**Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support**|Devika Venugopalan et.al.|[2412.11995v1](http://arxiv.org/abs/2412.11995v1)|[link](https://github.com/devika-prog/caregiver-conversational-support-tool)|
|**2024-12-16**|**ExecRepoBench: Multi-level Executable Code Completion Evaluation**|Jian Yang et.al.|[2412.11990v1](http://arxiv.org/abs/2412.11990v1)|null|
|**2024-12-16**|**SciFaultyQA: Benchmarking LLMs on Faulty Science Question Detection with a GAN-Inspired Approach to Synthetic Dataset Generation**|Debarshi Kundu et.al.|[2412.11988v1](http://arxiv.org/abs/2412.11988v1)|[link](https://github.com/debarshikundupsu/scifaultyqa)|
|**2024-12-16**|**Speak & Improve Corpus 2025: an L2 English Speech Corpus for Language Assessment and Feedback**|Kate Knill et.al.|[2412.11986v1](http://arxiv.org/abs/2412.11986v1)|null|
|**2024-12-16**|**Speak & Improve Challenge 2025: Tasks and Baseline Systems**|Mengjie Qian et.al.|[2412.11985v1](http://arxiv.org/abs/2412.11985v1)|null|
|**2024-12-16**|**Cost-Effective Label-free Node Classification with LLMs**|Taiyan Zhang et.al.|[2412.11983v1](http://arxiv.org/abs/2412.11983v1)|null|
|**2024-12-16**|**Speech Foundation Models and Crowdsourcing for Efficient, High-Quality Data Collection**|Beomseok Lee et.al.|[2412.11978v1](http://arxiv.org/abs/2412.11978v1)|null|
|**2024-12-16**|**Emma-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning**|Qi Sun et.al.|[2412.11974v1](http://arxiv.org/abs/2412.11974v1)|[link](https://github.com/declare-lab/emma-x)|
|**2024-12-16**|**DARWIN 1.5: Large Language Models as Materials Science Adapted Learners**|Tong Xie et.al.|[2412.11970v1](http://arxiv.org/abs/2412.11970v1)|null|
|**2024-12-16**|**Inferring Functionality of Attention Heads from their Parameters**|Amit Elhelo et.al.|[2412.11965v1](http://arxiv.org/abs/2412.11965v1)|[link](https://github.com/amitelhelo/maps)|
|**2024-12-16**|**Gramian Multimodal Representation Learning and Alignment**|Giordano Cicchetti et.al.|[2412.11959v1](http://arxiv.org/abs/2412.11959v1)|null|
|**2024-12-16**|**Advancing Comprehensive Aesthetic Insight with Multi-Scale Text-Guided Self-Supervised Learning**|Yuti Liu et.al.|[2412.11952v1](http://arxiv.org/abs/2412.11952v1)|null|
|**2024-12-16**|**The Impact of Generalization Techniques on the Interplay Among Privacy, Utility, and Fairness in Image Classification**|Ahmad Hassanpour et.al.|[2412.11951v1](http://arxiv.org/abs/2412.11951v1)|null|
|**2024-12-16**|**OpenReviewer: A Specialized Large Language Model for Generating Critical Scientific Paper Reviews**|Maximilian Idahl et.al.|[2412.11948v1](http://arxiv.org/abs/2412.11948v1)|null|
|**2024-12-16**|**The Impact of Token Granularity on the Predictive Power of Language Model Surprisal**|Byung-Doh Oh et.al.|[2412.11940v1](http://arxiv.org/abs/2412.11940v1)|null|
|**2024-12-16**|**Precise Length Control in Large Language Models**|Bradley Butcher et.al.|[2412.11937v1](http://arxiv.org/abs/2412.11937v1)|null|
|**2024-12-16**|**A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges**|Yibo Yan et.al.|[2412.11936v1](http://arxiv.org/abs/2412.11936v1)|null|
|**2024-12-16**|**Stepwise Reasoning Error Disruption Attack of LLMs**|Jingyu Peng et.al.|[2412.11934v1](http://arxiv.org/abs/2412.11934v1)|null|
|**2024-12-16**|**Explainable Procedural Mistake Detection**|Shane Storks et.al.|[2412.11927v1](http://arxiv.org/abs/2412.11927v1)|null|
|**2024-12-16**|**PICLe: Pseudo-Annotations for In-Context Learning in Low-Resource Named Entity Detection**|Sepideh Mamooler et.al.|[2412.11923v1](http://arxiv.org/abs/2412.11923v1)|null|
|**2024-12-16**|**RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation**|Xiaoxi Li et.al.|[2412.11919v1](http://arxiv.org/abs/2412.11919v1)|[link](https://github.com/sunnynexus/retrollm)|
|**2024-12-16**|**CharacterBench: Benchmarking Character Customization of Large Language Models**|Jinfeng Zhou et.al.|[2412.11912v1](http://arxiv.org/abs/2412.11912v1)|[link](https://github.com/thu-coai/characterbench)|
|**2024-12-16**|**Can Language Models Rival Mathematics Students? Evaluating Mathematical Reasoning through Textual Manipulation and Human Experiments**|Andrii Nikolaiev et.al.|[2412.11908v1](http://arxiv.org/abs/2412.11908v1)|null|
|**2024-12-16**|**PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension**|Kun Ouyang et.al.|[2412.11906v1](http://arxiv.org/abs/2412.11906v1)|null|
|**2024-12-16**|**Classification of Spontaneous and Scripted Speech for Multilingual Audio**|Shahar Elisha et.al.|[2412.11896v1](http://arxiv.org/abs/2412.11896v1)|null|
|**2024-12-16**|**GNN Applied to Ego-nets for Friend Suggestions**|Evgeny Zamyatin et.al.|[2412.11888v1](http://arxiv.org/abs/2412.11888v1)|[link](https://github.com/ezamyatin/walk_gnn)|
|**2024-12-16**|**Using Instruction-Tuned Large Language Models to Identify Indicators of Vulnerability in Police Incident Narratives**|Sam Relins et.al.|[2412.11878v1](http://arxiv.org/abs/2412.11878v1)|null|
|**2024-12-16**|**A Variable Occurrence-Centric Framework for Inconsistency Handling (Extended Version)**|Yakoub Salhi et.al.|[2412.11868v1](http://arxiv.org/abs/2412.11868v1)|null|
|**2024-12-16**|**Transformers Use Causal World Models in Maze-Solving Tasks**|Alex F. Spies et.al.|[2412.11867v1](http://arxiv.org/abs/2412.11867v1)|null|
|**2024-12-16**|**Investigating Mixture of Experts in Dense Retrieval**|Effrosyni Sokli et.al.|[2412.11864v1](http://arxiv.org/abs/2412.11864v1)|null|
|**2024-12-16**|**GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training**|Renqiu Xia et.al.|[2412.11863v1](http://arxiv.org/abs/2412.11863v1)|[link](https://github.com/unimodal4reasoning/geox)|
|**2024-12-16**|**A Theory of Formalisms for Representing Knowledge**|Heng Zhang et.al.|[2412.11855v1](http://arxiv.org/abs/2412.11855v1)|null|
|**2024-12-16**|**A Benchmark and Robustness Study of In-Context-Learning with Large Language Models in Music Entity Detection**|Simon Hachmeier et.al.|[2412.11851v1](http://arxiv.org/abs/2412.11851v1)|[link](https://github.com/progsi/ytuncoverllm)|
|**2024-12-16**|**Improved Models for Media Bias Detection and Subcategorization**|Tim Menzner et.al.|[2412.11835v1](http://arxiv.org/abs/2412.11835v1)|null|
|**2024-12-16**|**Wonderful Matrices: Combining for a More Efficient and Effective Foundation Model Architecture**|Jingze Shi et.al.|[2412.11834v1](http://arxiv.org/abs/2412.11834v1)|[link](https://github.com/losercheems/doge)|
|**2024-12-16**|**Are You Doubtful? Oh, It Might Be Difficult Then! Exploring the Use of Model Uncertainty for Question Difficulty Estimation**|Leonidas Zotos et.al.|[2412.11831v1](http://arxiv.org/abs/2412.11831v1)|null|
|**2024-12-16**|**Advancements and Challenges in Bangla Question Answering Models: A Comprehensive Review**|Md Iftekhar Islam Tashik et.al.|[2412.11823v1](http://arxiv.org/abs/2412.11823v1)|null|
|**2024-12-16**|**EventSum: A Large-Scale Event-Centric Summarization Dataset for Chinese Multi-News Documents**|Mengna Zhu et.al.|[2412.11814v1](http://arxiv.org/abs/2412.11814v1)|null|
|**2024-12-16**|**PhysAug: A Physical-guided and Frequency-based Data Augmentation for Single-Domain Generalized Object Detection**|Xiaoran Xu et.al.|[2412.11807v1](http://arxiv.org/abs/2412.11807v1)|[link](https://github.com/startracker0/physaug)|
|**2024-12-16**|**UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models**|Boyang Xue et.al.|[2412.11803v1](http://arxiv.org/abs/2412.11803v1)|null|
|**2024-12-16**|**AMI-Net: Adaptive Mask Inpainting Network for Industrial Anomaly Detection and Localization**|Wei Luo et.al.|[2412.11802v1](http://arxiv.org/abs/2412.11802v1)|[link](https://github.com/luow23/ami-net)|
|**2024-12-16**|**ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible Speech Synthesis**|Xiangheng He et.al.|[2412.11795v1](http://arxiv.org/abs/2412.11795v1)|null|
|**2024-12-16**|**Does it Chug? Towards a Data-Driven Understanding of Guitar Tone Description**|Pratik Sutar et.al.|[2412.11769v1](http://arxiv.org/abs/2412.11769v1)|[link](https://github.com/pratikstar/doesitchug)|
|**2024-12-16**|**No More Adam: Learning Rate Scaling at Initialization is All You Need**|Minghao Xu et.al.|[2412.11768v1](http://arxiv.org/abs/2412.11768v1)|[link](https://github.com/anonymousalethiometer/sgd_sai)|
|**2024-12-16**|**QUENCH: Measuring the gap between Indic and Non-Indic Contextual General Reasoning in LLMs**|Mohammad Aflah Khan et.al.|[2412.11763v1](http://arxiv.org/abs/2412.11763v1)|[link](https://github.com/aflah02/quench)|
|**2024-12-16**|**Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control**|Timothée Anne et.al.|[2412.11761v1](http://arxiv.org/abs/2412.11761v1)|null|
|**2024-12-16**|**Common Ground, Diverse Roots: The Difficulty of Classifying Common Examples in Spanish Varieties**|Javier A. Lopetegui et.al.|[2412.11750v1](http://arxiv.org/abs/2412.11750v1)|null|
|**2024-12-16**|**Beyond Dataset Creation: Critical View of Annotation Variation and Bias Probing of a Dataset for Online Radical Content Detection**|Arij Riabi et.al.|[2412.11745v1](http://arxiv.org/abs/2412.11745v1)|null|
|**2024-12-16**|**CSR:Achieving 1 Bit Key-Value Cache via Sparse Representation**|Hongxuan Zhang et.al.|[2412.11741v1](http://arxiv.org/abs/2412.11741v1)|null|
|**2024-12-16**|**Personalized LLM for Generating Customized Responses to the Same Query from Different Users**|Hang Zeng et.al.|[2412.11736v1](http://arxiv.org/abs/2412.11736v1)|[link](https://github.com/nidryen-zh/questionerawareresponder)|
|**2024-12-16**|**Transferable Adversarial Face Attack with Text Controlled Attribute**|Wenyun Li et.al.|[2412.11735v1](http://arxiv.org/abs/2412.11735v1)|null|
|**2024-12-16**|**Findings of the WMT 2024 Shared Task on Discourse-Level Literary Translation**|Longyue Wang et.al.|[2412.11732v1](http://arxiv.org/abs/2412.11732v1)|[link](https://github.com/longyuewangdcu/guofeng-webnovel)|
|**2024-12-16**|**LLMs Can Simulate Standardized Patients via Agent Coevolution**|Zhuoyun Du et.al.|[2412.11716v1](http://arxiv.org/abs/2412.11716v1)|null|
|**2024-12-16**|**Seeker: Towards Exception Safety Code Generation with Intermediate Language Agents Framework**|Xuanming Zhang et.al.|[2412.11713v1](http://arxiv.org/abs/2412.11713v1)|null|
|**2024-12-16**|**MiMoTable: A Multi-scale Spreadsheet Benchmark with Meta Operations for Table Reasoning**|Zheng Li et.al.|[2412.11711v1](http://arxiv.org/abs/2412.11711v1)|null|
|**2024-12-16**|**Re-Attentional Controllable Video Diffusion Editing**|Yuanzhi Wang et.al.|[2412.11710v1](http://arxiv.org/abs/2412.11710v1)|[link](https://github.com/mdswyz/reatco)|
|**2024-12-16**|**Context Filtering with Reward Modeling in Question Answering**|Sangryul Kim et.al.|[2412.11707v1](http://arxiv.org/abs/2412.11707v1)|null|
|**2024-12-16**|**Vocabulary Expansion of Chat Models with Unlabeled Target Language Data**|Atsuki Yamaguchi et.al.|[2412.11704v1](http://arxiv.org/abs/2412.11704v1)|[link](https://github.com/gucci-j/chat-cve)|
|**2024-12-16**|**CoinMath: Harnessing the Power of Coding Instruction for Math LLMs**|Chengwei Wei et.al.|[2412.11699v1](http://arxiv.org/abs/2412.11699v1)|null|
|**2024-12-16**|**On Large Language Models in Mission-Critical IT Governance: Are We Ready Yet?**|Matteo Esposito et.al.|[2412.11698v1](http://arxiv.org/abs/2412.11698v1)|null|
|**2024-12-16**|**From Specific-MLLM to Omni-MLLM: A Survey about the MLLMs alligned with Multi-Modality**|Shixin Jiang et.al.|[2412.11694v1](http://arxiv.org/abs/2412.11694v1)|null|
|**2024-12-16**|**Multilingual and Explainable Text Detoxification with Parallel Corpora**|Daryna Dementieva et.al.|[2412.11691v1](http://arxiv.org/abs/2412.11691v1)|[link](https://github.com/textdetox/multilingual_explainable_paradetox)|
|**2024-12-16**|**NEST: A Neuromodulated Small-world Hypergraph Trajectory Prediction Model for Autonomous Driving**|Chengyue Wang et.al.|[2412.11682v1](http://arxiv.org/abs/2412.11682v1)|null|
|**2024-12-16**|**Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer detection**|Abdelbaki Souid et.al.|[2412.11681v1](http://arxiv.org/abs/2412.11681v1)|null|
|**2024-12-16**|**Bias Vector: Mitigating Biases in Language Models with Task Arithmetic Approach**|Daiki Shirafuji et.al.|[2412.11679v1](http://arxiv.org/abs/2412.11679v1)|null|
|**2024-12-16**|**UA-PDFL: A Personalized Approach for Decentralized Federated Learning**|Hangyu Zhu et.al.|[2412.11674v1](http://arxiv.org/abs/2412.11674v1)|null|
|**2024-12-16**|**LLM-DaaS: LLM-driven Drone-as-a-Service Operations from Text User Requests**|Lillian Wassim et.al.|[2412.11672v1](http://arxiv.org/abs/2412.11672v1)|null|
|**2024-12-16**|**BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR**|Jangyeong Jeon et.al.|[2412.11671v1](http://arxiv.org/abs/2412.11671v1)|[link](https://github.com/jjy961228/biobridge)|
|**2024-12-16**|**C3oT: Generating Shorter Chain-of-Thought without Compromising Effectiveness**|Yu Kang et.al.|[2412.11664v1](http://arxiv.org/abs/2412.11664v1)|null|
|**2024-12-16**|**Smoothness Really Matters: A Simple yet Effective Approach for Unsupervised Graph Domain Adaptation**|Wei Chen et.al.|[2412.11654v1](http://arxiv.org/abs/2412.11654v1)|[link](https://github.com/cwei01/tdss)|
|**2024-12-16**|**Self-Adaptive Paraphrasing and Preference Learning for Improved Claim Verifiability**|Amelie Wührl et.al.|[2412.11653v1](http://arxiv.org/abs/2412.11653v1)|null|
|**2024-12-16**|**SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**|Tao Meng et.al.|[2412.11652v1](http://arxiv.org/abs/2412.11652v1)|null|
|**2024-12-16**|**A comprehensive GeoAI review: Progress, Challenges and Outlooks**|Anasse Boutayeb et.al.|[2412.11643v1](http://arxiv.org/abs/2412.11643v1)|null|
|**2024-12-16**|**Introduction to AI Planning**|Marco Aiello et.al.|[2412.11642v1](http://arxiv.org/abs/2412.11642v1)|null|
|**2024-12-16**|**Multi-Scale Incremental Modeling for Enhanced Human Motion Prediction in Human-Robot Collaboration**|Juncheng Zou et.al.|[2412.11632v1](http://arxiv.org/abs/2412.11632v1)|null|
|**2024-12-16**|**Fool Me, Fool Me: User Attitudes Toward LLM Falsehoods**|Diana Bar-Or Nirman et.al.|[2412.11625v1](http://arxiv.org/abs/2412.11625v1)|null|
|**2024-12-16**|**Combating Semantic Contamination in Learning with Label Noise**|Wenxiao Fan et.al.|[2412.11620v1](http://arxiv.org/abs/2412.11620v1)|null|
|**2024-12-16**|**EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**|Nuowei Liu et.al.|[2412.11618v1](http://arxiv.org/abs/2412.11618v1)|null|
|**2024-12-16**|**MT-LENS: An all-in-one Toolkit for Better Machine Translation Evaluation**|Javier García Gilabert et.al.|[2412.11615v1](http://arxiv.org/abs/2412.11615v1)|null|
|**2024-12-16**|**SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models**|Jiale Cheng et.al.|[2412.11605v1](http://arxiv.org/abs/2412.11605v1)|[link](https://github.com/thu-coai/spar)|
|**2024-12-16**|**AUEB-Archimedes at RIRAG-2025: Is obligation concatenation really all you need?**|Ioannis Chasandras et.al.|[2412.11567v1](http://arxiv.org/abs/2412.11567v1)|null|
|**2024-12-16**|**The Role of Natural Language Processing Tasks in Automatic Literary Character Network Construction**|Arthur Amalvy et.al.|[2412.11560v1](http://arxiv.org/abs/2412.11560v1)|null|
|**2024-12-16**|**Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs**|Yuchen Fu et.al.|[2412.11556v1](http://arxiv.org/abs/2412.11556v1)|null|
|**2024-12-16**|**TS-SatFire: A Multi-Task Satellite Image Time-Series Dataset for Wildfire Detection and Prediction**|Yu Zhao et.al.|[2412.11555v1](http://arxiv.org/abs/2412.11555v1)|null|
|**2024-12-16**|**Region-Based Optimization in Continual Learning for Audio Deepfake Detection**|Yujie Chen et.al.|[2412.11551v1](http://arxiv.org/abs/2412.11551v1)|[link](https://github.com/cyjie429/rego)|
|**2024-12-16**|**Error Diversity Matters: An Error-Resistant Ensemble Method for Unsupervised Dependency Parsing**|Behzad Shayegh et.al.|[2412.11543v1](http://arxiv.org/abs/2412.11543v1)|null|
|**2024-12-16**|**SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer**|Jiaxu Wan et.al.|[2412.11540v1](http://arxiv.org/abs/2412.11540v1)|[link](https://github.com/terencewallel/sparse-proxy-point-transformer)|
|**2024-12-16**|**Towards a Speech Foundation Model for Singapore and Beyond**|Muhammad Huzaifah et.al.|[2412.11538v1](http://arxiv.org/abs/2412.11538v1)|null|

#### Abstracts
##### **MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization**
2412.12098v1 by Bhavya Sukhija, Stelian Coros, Andreas Krause, Pieter Abbeel, Carmelo Sferrazza

Reinforcement learning (RL) algorithms aim to balance exploiting the current
best strategy with exploring new options that could lead to higher rewards.
Most common RL algorithms use undirected exploration, i.e., select random
sequences of actions. Exploration can also be directed using intrinsic rewards,
such as curiosity or model epistemic uncertainty. However, effectively
balancing task and intrinsic rewards is challenging and often task-dependent.
In this work, we introduce a framework, MaxInfoRL, for balancing intrinsic and
extrinsic exploration. MaxInfoRL steers exploration towards informative
transitions, by maximizing intrinsic rewards such as the information gain about
the underlying task. When combined with Boltzmann exploration, this approach
naturally trades off maximization of the value function with that of the
entropy over states, rewards, and actions. We show that our approach achieves
sublinear regret in the simplified setting of multi-armed bandits. We then
apply this general formulation to a variety of off-policy model-free RL methods
for continuous state-action spaces, yielding novel algorithms that achieve
superior performance across hard exploration problems and complex scenarios
such as visual control tasks.

摘要：強化學習 (RL) 演算法旨在平衡利用目前最佳策略與探索可能帶來更高回饋的新選項。
最常見的 RL 演算法使用非導向探索，即選擇隨機動作序列。探索也可以使用內在回饋進行引導，例如好奇心或模型認識論的不確定性。然而，有效平衡任務和內在回饋具有挑戰性，而且通常取決於任務。
在這項工作中，我們引進了一個框架 MaxInfoRL，用於平衡內在和外在探索。MaxInfoRL 透過最大化內在回饋（例如關於基礎任務的資訊獲取）來引導探索，朝向具有資訊性的轉換。當與 Boltzmann 探索結合時，此方法自然會以狀態、回饋和動作的熵最大化來交換價值函數的最大化。我們證明了我們的方法在多重拉霸機的簡化設定中達到了次線性後悔。然後，我們將此一般公式應用於各種非策略模型免費 RL 方法，用於連續狀態動作空間，產生新穎的演算法，在困難的探索問題和複雜場景（例如視覺控制任務）中實現優異的效能。

##### **SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator**
2412.12094v1 by Guoxuan Chen, Han Shi, Jiawei Li, Yihang Gao, Xiaozhe Ren, Yimeng Chen, Xin Jiang, Zhenguo Li, Weiyang Liu, Chao Huang

Large Language Models (LLMs) have exhibited exceptional performance across a
spectrum of natural language processing tasks. However, their substantial sizes
pose considerable challenges, particularly in computational demands and
inference speed, due to their quadratic complexity. In this work, we have
identified a key pattern: certain seemingly meaningless special tokens (i.e.,
separators) contribute disproportionately to attention scores compared to
semantically meaningful tokens. This observation suggests that information of
the segments between these separator tokens can be effectively condensed into
the separator tokens themselves without significant information loss. Guided by
this insight, we introduce SepLLM, a plug-and-play framework that accelerates
inference by compressing these segments and eliminating redundant tokens.
Additionally, we implement efficient kernels for training acceleration.
Experimental results across training-free, training-from-scratch, and
post-training settings demonstrate SepLLM's effectiveness. Notably, using the
Llama-3-8B backbone, SepLLM achieves over 50% reduction in KV cache on the
GSM8K-CoT benchmark while maintaining comparable performance. Furthermore, in
streaming settings, SepLLM effectively processes sequences of up to 4 million
tokens or more while maintaining consistent language modeling capabilities.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中表現出色的效能。然而，它們龐大的規模帶來相當大的挑戰，特別是在運算需求和推理速度方面，因為它們的複雜度為二次方。在這項工作中，我們發現了一個關鍵模式：某些看似沒有意義的特殊符號（例如分隔符號）與語義有意義的符號相比，對注意力分數的貢獻不成比例。此觀察結果表明，這些分隔符號之間的區段資訊可以有效地壓縮到分隔符號本身，而不會造成顯著的資訊遺失。根據此見解，我們引入了 SepLLM，這是一個即插即用的架構，透過壓縮這些區段並消除重複的符號來加速推理。此外，我們實作了用於訓練加速的有效核心。跨越免訓練、從頭訓練和訓練後設定的實驗結果證明了 SepLLM 的效能。值得注意的是，使用 Llama-3-8B 主幹，SepLLM 在 GSM8K-CoT 基準測試中將 KV 快取減少了 50% 以上，同時維持了相當的效能。此外，在串流設定中，SepLLM 有效地處理多達 400 萬個符號或更多符號的序列，同時維持一致的語言建模能力。

##### **Stabilizing Reinforcement Learning in Differentiable Multiphysics Simulation**
2412.12089v1 by Eliot Xing, Vernon Luk, Jean Oh

Recent advances in GPU-based parallel simulation have enabled practitioners
to collect large amounts of data and train complex control policies using deep
reinforcement learning (RL), on commodity GPUs. However, such successes for RL
in robotics have been limited to tasks sufficiently simulated by fast
rigid-body dynamics. Simulation techniques for soft bodies are comparatively
several orders of magnitude slower, thereby limiting the use of RL due to
sample complexity requirements. To address this challenge, this paper presents
both a novel RL algorithm and a simulation platform to enable scaling RL on
tasks involving rigid bodies and deformables. We introduce Soft Analytic Policy
Optimization (SAPO), a maximum entropy first-order model-based actor-critic RL
algorithm, which uses first-order analytic gradients from differentiable
simulation to train a stochastic actor to maximize expected return and entropy.
Alongside our approach, we develop Rewarped, a parallel differentiable
multiphysics simulation platform that supports simulating various materials
beyond rigid bodies. We re-implement challenging manipulation and locomotion
tasks in Rewarped, and show that SAPO outperforms baselines over a range of
tasks that involve interaction between rigid bodies, articulations, and
deformables.

摘要：最近在基於 GPU 的平行模擬方面取得的進展使從業者
能夠收集大量的資料，並使用深度
強化學習 (RL) 在商品 GPU 上訓練複雜的控制策略。然而，RL
在機器人技術方面的成功僅限於由快速
剛體動力學充分模擬的任務。軟體的模擬技術比較
慢了幾個數量級，從而由於樣本複雜性要求而限制了 RL 的使用。為了應對這一挑戰，本文提出
了一種新的 RL 演算法和一個模擬平台，以便在涉及剛體和可變形的任務中擴展 RL。我們介紹了軟分析策略
優化 (SAPO)，這是一種最大熵一階基於模型的動作-評論 RL
演算法，它使用可微分
模擬的一階分析梯度來訓練隨機動作以最大化預期回報和熵。除了我們的做法之外，我們還開發了 Rewarped，這是一個並行的可微分
多物理場模擬平台，它支援模擬各種超乎剛體的材料。我們在 Rewarped 中重新實作了具有挑戰性的操作和運動任務，並表明 SAPO 在涉及剛體、關節和
可變形之間交互作用的一系列任務中優於基準。

##### **Making FETCH! Happen: Finding Emergent Dog Whistles Through Common Habitats**
2412.12072v1 by Kuleen Sasse, Carlos Aguirre, Isabel Cachola, Sharon Levy, Mark Dredze

WARNING: This paper contains content that maybe upsetting or offensive to
some readers. Dog whistles are coded expressions with dual meanings: one
intended for the general public (outgroup) and another that conveys a specific
message to an intended audience (ingroup). Often, these expressions are used to
convey controversial political opinions while maintaining plausible deniability
and slip by content moderation filters. Identification of dog whistles relies
on curated lexicons, which have trouble keeping up to date. We introduce
\textbf{FETCH!}, a task for finding novel dog whistles in massive social media
corpora. We find that state-of-the-art systems fail to achieve meaningful
results across three distinct social media case studies. We present
\textbf{EarShot}, a novel system that combines the strengths of vector
databases and Large Language Models (LLMs) to efficiently and effectively
identify new dog whistles.

摘要：警告：本文包含可能讓某些讀者感到不安或冒犯的內容。狗哨語是一種具有雙重含義的編碼表達方式：一種是針對一般大眾（外團體），另一種則傳達特定訊息給目標受眾（內團體）。這些表達方式通常用於傳達有爭議的政治觀點，同時保持似是而非的否認，並避開內容審核過濾器。狗哨語的識別依賴於經過整理的詞彙表，但這些詞彙表難以保持最新。我們引入了\textbf{FETCH!}，這項任務是用於在大量的社群媒體語料庫中尋找新的狗哨語。我們發現最先進的系統無法在三個不同的社群媒體案例研究中獲得有意義的結果。我們提出了\textbf{EarShot}，這是一個新穎的系統，它結合了向量資料庫和大型語言模型（LLM）的優點，可以有效率且有效地識別新的狗哨語。

##### **Revelations: A Decidable Class of POMDPs with Omega-Regular Objectives**
2412.12063v1 by Marius Belly, Nathanaël Fijalkow, Hugo Gimbert, Florian Horn, Guillermo A. Pérez, Pierre Vandenhove

Partially observable Markov decision processes (POMDPs) form a prominent
model for uncertainty in sequential decision making. We are interested in
constructing algorithms with theoretical guarantees to determine whether the
agent has a strategy ensuring a given specification with probability 1. This
well-studied problem is known to be undecidable already for very simple
omega-regular objectives, because of the difficulty of reasoning on uncertain
events. We introduce a revelation mechanism which restricts information loss by
requiring that almost surely the agent has eventually full information of the
current state. Our main technical results are to construct exact algorithms for
two classes of POMDPs called weakly and strongly revealing. Importantly, the
decidable cases reduce to the analysis of a finite belief-support Markov
decision process. This yields a conceptually simple and exact algorithm for a
large class of POMDPs.

摘要：部分可觀察馬可夫決策過程 (POMDP) 形成了一個用於順序決策制定中不確定性的顯著模型。我們有興趣建構具有理論保證的演算法，以確定代理是否有一個策略來確保給定規格的機率為 1。這個研究得很透徹的問題已知對於非常簡單的 omega 正規目標是不可判定的，因為在不確定事件上推論很困難。我們引入一個揭示機制，它透過要求代理幾乎肯定最終完全了解當前狀態來限制資訊遺失。我們的技術主要成果是為稱為弱揭示和強揭示的兩類 POMDP 建構精確的演算法。重要的是，可判定的情況會簡化為對有限信念支援馬可夫決策過程的分析。這產生了一個概念上簡單且精確的演算法，適用於一大類 POMDP。

##### **How Private are Language Models in Abstractive Summarization?**
2412.12040v1 by Anthony Hughes, Nikolaos Aletras, Ning Ma

Language models (LMs) have shown outstanding performance in text
summarization including sensitive domains such as medicine and law. In these
settings, it is important that personally identifying information (PII)
included in the source document should not leak in the summary. Prior efforts
have mostly focused on studying how LMs may inadvertently elicit PII from
training data. However, to what extent LMs can provide privacy-preserving
summaries given a non-private source document remains under-explored. In this
paper, we perform a comprehensive study across two closed- and three
open-weight LMs of different sizes and families. We experiment with prompting
and fine-tuning strategies for privacy-preservation across a range of
summarization datasets across three domains. Our extensive quantitative and
qualitative analysis including human evaluation shows that LMs often cannot
prevent PII leakage on their summaries and that current widely-used metrics
cannot capture context dependent privacy risks.

摘要：語言模型 (LM) 在文本摘要中展現出傑出的表現，包括醫學和法律等敏感領域。在這些設定中，原始文件中包含的個人識別資訊 (PII) 不應出現在摘要中。先前的研究大多集中在探討 LM 如何在無意間從訓練資料中引出 PII。然而，LM 在給定非私人原始文件的情況下，可以在多大程度上提供隱私保護摘要，這仍有待探索。在本文中，我們對兩個封閉和三個開放權重，不同大小和系列的 LM 進行全面研究。我們針對三個領域的各種摘要資料集，實驗提示和微調策略，以進行隱私保護。我們廣泛的定量和定性分析，包括人工評估，顯示 LM 通常無法防止摘要中 PII 的洩漏，而且目前廣泛使用的指標無法捕捉依賴於情境的隱私風險。

##### **Can LLM Prompting Serve as a Proxy for Static Analysis in Vulnerability Detection**
2412.12039v1 by Ira Ceka, Feitong Qiao, Anik Dey, Aastha Valechia, Gail Kaiser, Baishakhi Ray

Despite their remarkable success, large language models (LLMs) have shown
limited ability on applied tasks such as vulnerability detection. We
investigate various prompting strategies for vulnerability detection and, as
part of this exploration, propose a prompting strategy that integrates natural
language descriptions of vulnerabilities with a contrastive chain-of-thought
reasoning approach, augmented using contrastive samples from a synthetic
dataset. Our study highlights the potential of LLMs to detect vulnerabilities
by integrating natural language descriptions, contrastive reasoning, and
synthetic examples into a comprehensive prompting framework. Our results show
that this approach can enhance LLM understanding of vulnerabilities. On a
high-quality vulnerability detection dataset such as SVEN, our prompting
strategies can improve accuracies, F1-scores, and pairwise accuracies by 23%,
11%, and 14%, respectively.

摘要：儘管大型語言模型 (LLM) 取得了顯著的成功，但在應用任務（例如漏洞偵測）上仍展現出有限的能力。我們探討了各種漏洞偵測提示策略，並在此探索過程中，提出了一個提示策略，將漏洞的自然語言描述與對比鏈式思考推理方法整合在一起，並使用來自合成資料集的對比範例進行擴充。我們的研究突顯了 LLM 整合自然語言描述、對比推理和合成範例到一個全面的提示架構中，以偵測漏洞的潛力。我們的結果顯示，此方法可以增強 LLM 對漏洞的理解。在 SVEN 等高品質漏洞偵測資料集上，我們的提示策略可以分別將準確率、F1 分數和成對準確率提升 23%、11% 和 14%。

##### **FSFM: A Generalizable Face Security Foundation Model via Self-Supervised Facial Representation Learning**
2412.12032v1 by Gaojian Wang, Feng Lin, Tong Wu, Zhenguang Liu, Zhongjie Ba, Kui Ren

This work asks: with abundant, unlabeled real faces, how to learn a robust
and transferable facial representation that boosts various face security tasks
with respect to generalization performance? We make the first attempt and
propose a self-supervised pretraining framework to learn fundamental
representations of real face images, FSFM, that leverages the synergy between
masked image modeling (MIM) and instance discrimination (ID). We explore
various facial masking strategies for MIM and present a simple yet powerful
CRFR-P masking, which explicitly forces the model to capture meaningful
intra-region consistency and challenging inter-region coherency. Furthermore,
we devise the ID network that naturally couples with MIM to establish
underlying local-to-global correspondence via tailored self-distillation. These
three learning objectives, namely 3C, empower encoding both local features and
global semantics of real faces. After pretraining, a vanilla ViT serves as a
universal vision foundation model for downstream face security tasks:
cross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen
diffusion facial forgery detection. Extensive experiments on 10 public datasets
demonstrate that our model transfers better than supervised pretraining, visual
and facial self-supervised learning arts, and even outperforms task-specialized
SOTA methods.

摘要：本研究提出：面对大量未标记的真实人脸，如何学习稳健且可转移的人脸表征，以提升各种人脸安全任务的泛化性能？我们首次尝试并提出一个自监督预训练框架，以学习真实人脸图像的基本表征，即 FSFM，它利用了掩码图像建模 (MIM) 和实例辨别 (ID) 之间的协同作用。我们探索了各种用于 MIM 的人脸掩码策略，并提出了一种简单但强大的 CRFR-P 掩码，它明确迫使模型捕获有意义的区域内一致性和具有挑战性的区域间连贯性。此外，我们设计了 ID 网络，它自然地与 MIM 耦合，通过定制的自蒸馏建立了底层的局部到全局对应关系。这三个学习目标，即 3C，赋能对真实人脸的局部特征和全局语义进行编码。在预训练后，一个香草 ViT 充当下游人脸安全任务的通用视觉基础模型：跨数据集深度伪造检测、跨域人脸防欺骗和看不见的扩散人脸伪造检测。在 10 个公共数据集上的大量实验表明，与监督式预训练、视觉和人脸自监督学习艺术相比，我们的模型具有更好的迁移性，甚至优于专门针对任务的 SOTA 方法。

##### **Learning to Navigate in Mazes with Novel Layouts using Abstract Top-down Maps**
2412.12024v1 by Linfeng Zhao, Lawson L. S. Wong

Learning navigation capabilities in different environments has long been one
of the major challenges in decision-making. In this work, we focus on zero-shot
navigation ability using given abstract $2$-D top-down maps. Like human
navigation by reading a paper map, the agent reads the map as an image when
navigating in a novel layout, after learning to navigate on a set of training
maps. We propose a model-based reinforcement learning approach for this
multi-task learning problem, where it jointly learns a hypermodel that takes
top-down maps as input and predicts the weights of the transition network. We
use the DeepMind Lab environment and customize layouts using generated maps.
Our method can adapt better to novel environments in zero-shot and is more
robust to noise.

摘要：在不同的環境中學習導航能力一直是決策中的主要挑戰之一。在這項工作中，我們專注於使用給定的抽象 $2$-D 俯瞰地圖的零次學習導航能力。就像人類透過閱讀紙本地圖來導航一樣，代理人在學習在一組訓練地圖上導航後，在新的配置中導航時將地圖視為影像來閱讀。我們提出了一種基於模型的強化學習方法來解決這個多任務學習問題，其中它聯合學習了一個將俯瞰地圖作為輸入並預測傳遞網路權重的超模型。我們使用 DeepMind Lab 環境並使用生成的映射自訂配置。我們的模型可以在零次學習中更好地適應新的環境，並且對雜訊更具魯棒性。

##### **SpeechPrune: Context-aware Token Pruning for Speech Information Retrieval**
2412.12009v1 by Yueqian Lin, Yuzhe Fu, Jingyang Zhang, Yudong Liu, Jianyi Zhang, Jingwei Sun, Hai "Helen" Li, Yiran Chen

We introduce Speech Information Retrieval (SIR), a new long-context task for
Speech Large Language Models (Speech LLMs), and present SPIRAL, a 1,012-sample
benchmark testing models' ability to extract critical details from
approximately 90-second spoken inputs. While current Speech LLMs excel at
short-form tasks, they struggle with the computational and representational
demands of longer audio sequences. To address this limitation, we propose
SpeechPrune, a training-free token pruning strategy that uses speech-text
similarity and approximated attention scores to efficiently discard irrelevant
tokens. In SPIRAL, SpeechPrune achieves accuracy improvements of 29% and up to
47% over the original model and the random pruning model at a pruning rate of
20%, respectively. SpeechPrune can maintain network performance even at a
pruning level of 80%. This approach highlights the potential of token-level
pruning for efficient and scalable long-form speech understanding.

摘要：我們引入了語音資訊檢索 (SIR)，這是一個針對語音大型語言模型 (Speech LLM) 的新長語境任務，並展示了 SPIRAL，一個由 1,012 個範例組成的基準測試模型，能夠從大約 90 秒的語音輸入中提取關鍵細節。儘管目前的語音 LLM 在短篇任務中表現出色，但它們在處理較長音訊序列的計算和表示需求時卻有困難。為了解決此限制，我們提出了 SpeechPrune，這是一種無需訓練的權標剪枝策略，它使用語音與文字的相似性以及近似注意力分數來有效地捨棄不相關的權標。在 SPIRAL 中，SpeechPrune 在 20% 的剪枝率下，分別比原始模型和隨機剪枝模型提高了 29% 和 47% 的準確度。即使在 80% 的剪枝率下，SpeechPrune 仍能維持網路效能。這種方法突顯了權標層級剪枝在有效且可擴充的長篇語音理解中的潛力。

##### **The Open Source Advantage in Large Language Models (LLMs)**
2412.12004v1 by Jiya Manchanda, Laura Boettcher, Matheus Westphalen, Jasser Jasser

Large language models (LLMs) mark a key shift in natural language processing
(NLP), having advanced text generation, translation, and domain-specific
reasoning. Closed-source models like GPT-4, powered by proprietary datasets and
extensive computational resources, lead with state-of-the-art performance
today. However, they face criticism for their "black box" nature and for
limiting accessibility in a manner that hinders reproducibility and equitable
AI development. By contrast, open-source initiatives like LLaMA and BLOOM
prioritize democratization through community-driven development and
computational efficiency. These models have significantly reduced performance
gaps, particularly in linguistic diversity and domain-specific applications,
while providing accessible tools for global researchers and developers.
Notably, both paradigms rely on foundational architectural innovations, such as
the Transformer framework by Vaswani et al. (2017). Closed-source models excel
by scaling effectively, while open-source models adapt to real-world
applications in underrepresented languages and domains. Techniques like
Low-Rank Adaptation (LoRA) and instruction-tuning datasets enable open-source
models to achieve competitive results despite limited resources. To be sure,
the tension between closed-source and open-source approaches underscores a
broader debate on transparency versus proprietary control in AI. Ethical
considerations further highlight this divide. Closed-source systems restrict
external scrutiny, while open-source models promote reproducibility and
collaboration but lack standardized auditing documentation frameworks to
mitigate biases. Hybrid approaches that leverage the strengths of both
paradigms are likely to shape the future of LLM innovation, ensuring
accessibility, competitive technical performance, and ethical deployment.

摘要：<paragraph>大型語言模型 (LLM) 標誌著自然語言處理 (NLP) 的關鍵轉變，進步了文本產生、翻譯和特定領域的推理。由專有資料集和廣泛計算資源支援的封閉原始碼模型，例如 GPT-4，以其最先進的效能領先業界。然而，它們因其「黑盒子」性質和以阻礙可複製性和公平的人工智慧發展的方式限制可及性而受到批評。相反地，LLaMA 和 BLOOM 等開放原始碼計畫透過社群驅動的開發和計算效率優先實現民主化。這些模型已大幅縮小效能差距，特別是在語言多樣性和特定領域應用方面，同時為全球研究人員和開發人員提供了可及的工具。值得注意的是，這兩種範例都依賴於基礎架構創新，例如 Vaswani 等人 (2017) 的 Transformer 框架。封閉原始碼模型透過有效擴充而勝出，而開放原始碼模型則適應於代表性不足的語言和領域中的實際應用。低秩適應 (LoRA) 和指令調整資料集等技術使開放原始碼模型能夠在資源有限的情況下取得具競爭力的結果。可以確定的是，封閉原始碼和開放原始碼方法之間的緊張關係突顯了人工智慧中透明度與專有控制之間更廣泛的辯論。倫理考量進一步突顯了這一分歧。封閉原始碼系統限制外部審查，而開放原始碼模型促進可複製性和協作，但缺乏標準化的稽核文件架構來減輕偏差。利用這兩種範例優勢的混合方法可能會形塑 LLM 創新的未來，確保可及性、具有競爭力的技術效能和合乎道德的部署。</paragraph>

##### **LLM-RG4: Flexible and Factual Radiology Report Generation across Diverse Input Contexts**
2412.12001v1 by Zhuhao Wang, Yihua Sun, Zihan Li, Xuan Yang, Fang Chen, Hongen Liao

Drafting radiology reports is a complex task requiring flexibility, where
radiologists tail content to available information and particular clinical
demands. However, most current radiology report generation (RRG) models are
constrained to a fixed task paradigm, such as predicting the full ``finding''
section from a single image, inherently involving a mismatch between inputs and
outputs. The trained models lack the flexibility for diverse inputs and could
generate harmful, input-agnostic hallucinations. To bridge the gap between
current RRG models and the clinical demands in practice, we first develop a
data generation pipeline to create a new MIMIC-RG4 dataset, which considers
four common radiology report drafting scenarios and has perfectly corresponded
input and output. Secondly, we propose a novel large language model (LLM) based
RRG framework, namely LLM-RG4, which utilizes LLM's flexible
instruction-following capabilities and extensive general knowledge. We further
develop an adaptive token fusion module that offers flexibility to handle
diverse scenarios with different input combinations, while minimizing the
additional computational burden associated with increased input volumes.
Besides, we propose a token-level loss weighting strategy to direct the model's
attention towards positive and uncertain descriptions. Experimental results
demonstrate that LLM-RG4 achieves state-of-the-art performance in both clinical
efficiency and natural language generation on the MIMIC-RG4 and MIMIC-CXR
datasets. We quantitatively demonstrate that our model has minimal
input-agnostic hallucinations, whereas current open-source models commonly
suffer from this problem.

摘要：<paragraph>起草放射科报告是一项复杂的任务，需要灵活性，其中放射科医师根据现有信息和特定的临床需求调整内容。然而，大多数当前的放射科报告生成 (RRG) 模型都受限于固定的任务范式，例如从单张图像预测完整的 ``发现'' 部分，这本质上涉及输入和输出之间的不匹配。训练后的模型缺乏对不同输入的灵活性，并且可能产生有害的、与输入无关的幻觉。为了弥合当前 RRG 模型与实际临床需求之间的差距，我们首先开发了一个数据生成管道来创建一个新的 MIMIC-RG4 数据集，该数据集考虑了四种常见的放射科报告起草场景，并且输入和输出完全对应。其次，我们提出了一种基于新大型语言模型 (LLM) 的 RRG 框架，即 LLM-RG4，它利用了 LLM 灵活的指令遵循能力和广泛的通用知识。我们进一步开发了一个自适应令牌融合模块，该模块提供了处理具有不同输入组合的不同场景的灵活性，同时最大程度地减少了与增加的输入量相关的额外计算负担。此外，我们提出了一个令牌级损失加权策略，以将模型的注意力引导至积极和不确定的描述。实验结果表明，LLM-RG4 在 MIMIC-RG4 和 MIMIC-CXR 数据集上在临床效率和自然语言生成方面都取得了最先进的性能。我们定量证明了我们的模型最少有与输入无关的幻觉，而当前的开源模型通常存在这个问题。</paragraph>

##### **Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support**
2412.11995v1 by Devika Venugopalan, Ziwen Yan, Conrad Borchers, Jionghao Lin, Vincent Aleven

Caregivers (i.e., parents and members of a child's caring community) are
underappreciated stakeholders in learning analytics. Although caregiver
involvement can enhance student academic outcomes, many obstacles hinder
involvement, most notably knowledge gaps with respect to modern school
curricula. An emerging topic of interest in learning analytics is hybrid
tutoring, which includes instructional and motivational support. Caregivers
assert similar roles in homework, yet it is unknown how learning analytics can
support them. Our past work with caregivers suggested that conversational
support is a promising method of providing caregivers with the guidance needed
to effectively support student learning. We developed a system that provides
instructional support to caregivers through conversational recommendations
generated by a Large Language Model (LLM). Addressing known instructional
limitations of LLMs, we use instructional intelligence from tutoring systems
while conducting prompt engineering experiments with the open-source Llama 3
LLM. This LLM generated message recommendations for caregivers supporting their
child's math practice via chat. Few-shot prompting and combining real-time
problem-solving context from tutoring systems with examples of tutoring
practices yielded desirable message recommendations. These recommendations were
evaluated with ten middle school caregivers, who valued recommendations
facilitating content-level support and student metacognition through
self-explanation. We contribute insights into how tutoring systems can best be
merged with LLMs to support hybrid tutoring settings through conversational
assistance, facilitating effective caregiver involvement in tutoring systems.

摘要：照顧者（即父母和兒童照顧社群的成員）是學習分析中未獲充分重視的利害關係人。儘管照顧者的參與可以提升學生的學業成績，但許多障礙阻礙了參與，最顯著的是關於現代學校課程的知識差距。學習分析中一個新興的關注主題是混合式輔導，其中包括教學和動機支持。照顧者在家庭作業中扮演類似的角色，但目前尚不清楚學習分析如何能支持他們。我們過去與照顧者的合作表明，對話式支持是提供照顧者有效支持學生學習所需的指導的一種有前途的方法。我們開發了一個系統，透過大型語言模型 (LLM) 產生的對話式建議，為照顧者提供教學支援。為了解決 LLM 已知的教學限制，我們在對開源 Llama 3 LLM 進行提示工程實驗時，使用了來自輔導系統的教學智慧。此 LLM 為照顧者透過聊天支援其子女的數學練習生成了訊息建議。少量提示並結合來自輔導系統的即時問題解決背景與輔導實務範例，產生了理想的訊息建議。這些建議經過十位國中照顧者的評估，他們重視促進內容層級支援和學生透過自我解釋進行元認知的建議。我們提供見解，說明輔導系統如何能透過對話式協助與 LLM 最佳整合，以支援混合式輔導設定，促進照顧者有效參與輔導系統。

##### **ExecRepoBench: Multi-level Executable Code Completion Evaluation**
2412.11990v1 by Jian Yang, Jiajun Zhang, Jiaxi Yang, Ke Jin, Lei Zhang, Qiyao Peng, Ken Deng, Yibo Miao, Tianyu Liu, Zeyu Cui, Binyuan Hui, Junyang Lin

Code completion has become an essential tool for daily software development.
Existing evaluation benchmarks often employ static methods that do not fully
capture the dynamic nature of real-world coding environments and face
significant challenges, including limited context length, reliance on
superficial evaluation metrics, and potential overfitting to training datasets.
In this work, we introduce a novel framework for enhancing code completion in
software development through the creation of a repository-level benchmark
ExecRepoBench and the instruction corpora Repo-Instruct, aim at improving the
functionality of open-source large language models (LLMs) in real-world coding
scenarios that involve complex interdependencies across multiple files.
ExecRepoBench includes 1.2K samples from active Python repositories. Plus, we
present a multi-level grammar-based completion methodology conditioned on the
abstract syntax tree to mask code fragments at various logical units (e.g.
statements, expressions, and functions). Then, we fine-tune the open-source LLM
with 7B parameters on Repo-Instruct to produce a strong code completion
baseline model Qwen2.5-Coder-Instruct-C based on the open-source model.
Qwen2.5-Coder-Instruct-C is rigorously evaluated against existing benchmarks,
including MultiPL-E and ExecRepoBench, which consistently outperforms prior
baselines across all programming languages. The deployment of \ourmethod{} can
be used as a high-performance, local service for programming
development\footnote{\url{https://execrepobench.github.io/}}.

摘要：<paragraph>程式碼補全已成為日常軟體開發中不可或缺的工具。
現有的評估基準通常採用靜態方法，無法充分捕捉真實世界編碼環境的動態特性，並且面臨重大挑戰，包括受限的內容長度、依賴於浮面的評估指標，以及潛在過度擬合訓練資料集。
在這項工作中，我們引入了一個新穎的架構，透過建立儲存庫層級基準 ExecRepoBench 和指令語料庫 Repo-Instruct，來增強軟體開發中的程式碼補全，旨在改善開源大型語言模型 (LLM) 在涉及多個檔案之間複雜相互依賴關係的真實世界編碼場景中的功能。
ExecRepoBench 包含來自活躍 Python 儲存庫的 1.2K 個範例。此外，我們提出一個多層級基於語法的補全方法，以抽象語法樹為條件，在各種邏輯單元（例如陳述式、表達式和函式）遮罩程式碼片段。然後，我們使用 Repo-Instruct 微調具有 7B 參數的開源 LLM，以建立一個強大的程式碼補全基準模型 Qwen2.5-Coder-Instruct-C，該模型基於開源模型。
Qwen2.5-Coder-Instruct-C 針對現有基準進行嚴格評估，包括 MultiPL-E 和 ExecRepoBench，在所有程式語言中始終優於先前的基準。\ourmethod{} 的部署可以用作程式開發的高效能、本機服務\footnote{\url{https://execrepobench.github.io/}}。</paragraph>

##### **SciFaultyQA: Benchmarking LLMs on Faulty Science Question Detection with a GAN-Inspired Approach to Synthetic Dataset Generation**
2412.11988v1 by Debarshi Kundu

Consider the problem: ``If one man and one woman can produce one child in one
year, how many children will be produced by one woman and three men in 0.5
years?" Current large language models (LLMs) such as GPT-4o, GPT-o1-preview,
and Gemini Flash frequently answer "0.5," which does not make sense. While
these models sometimes acknowledge the unrealistic nature of the question, in
many cases (8 out of 10 trials), they provide the nonsensical answer of "0.5
child." Additionally, temporal variation has been observed: if an LLM answers
correctly once (by recognizing the faulty nature of the question), subsequent
responses are more likely to also reflect this understanding. However, this is
inconsistent.
  These types of questions have motivated us to develop a dataset of science
questions, SciFaultyQA, where the questions themselves are intentionally
faulty. We observed that LLMs often proceed to answer these flawed questions
without recognizing their inherent issues, producing results that are logically
or scientifically invalid. By analyzing such patterns, we developed a novel
method for generating synthetic datasets to evaluate and benchmark the
performance of various LLMs in identifying these flawed questions. We have also
developed novel approaches to reduce the errors.

摘要：<paragraph>考慮這個問題：``如果一個男人和一個女人一年可以生一個孩子，那麼一個女人和三個男人在 0.5 年可以生多少個孩子？" 當前的巨量語言模型 (LLM)，例如 GPT-4o、GPT-o1-preview 和 Gemini Flash，經常回答「0.5」，這沒有道理。雖然這些模型有時會承認這個問題不切實際，但在許多情況下（10 次測試中有 8 次），它們給出了「0.5 個孩子」的無稽之談。此外，已經觀察到時間變化：如果一個 LLM 正確回答一次（通過認識到問題的錯誤性質），後續回答也更有可能反映這種理解。然而，這是不一致的。
  這些類型的問題促使我們開發了一個科學問題數據集 SciFaultyQA，其中問題本身是有意錯誤的。我們觀察到，LLM 經常繼續回答這些有缺陷的問題，而沒有認識到它們固有的問題，產生在邏輯上或科學上無效的結果。通過分析這種模式，我們開發了一種生成合成數據集的新方法，以評估和比較各種 LLM 在識別這些有缺陷問題方面的性能。我們還開發了新的方法來減少錯誤。</paragraph>

##### **Speak & Improve Corpus 2025: an L2 English Speech Corpus for Language Assessment and Feedback**
2412.11986v1 by Kate Knill, Diane Nicholls, Mark J. F. Gales, Mengjie Qian, Pawel Stroinski

We introduce the Speak \& Improve Corpus 2025, a dataset of L2 learner
English data with holistic scores and language error annotation, collected from
open (spontaneous) speaking tests on the Speak \& Improve learning platform
https://speakandimprove.com . The aim of the corpus release is to address a
major challenge to developing L2 spoken language processing systems, the lack
of publicly available data with high-quality annotations. It is being made
available for non-commercial use on the ELiT website. In designing this corpus
we have sought to make it cover a wide-range of speaker attributes, from their
L1 to their speaking ability, as well as providing manual annotations. This
enables a range of language-learning tasks to be examined, such as assessing
speaking proficiency or providing feedback on grammatical errors in a learner's
speech. Additionally, the data supports research into the underlying technology
required for these tasks including automatic speech recognition (ASR) of low
resource L2 learner English, disfluency detection or spoken grammatical error
correction (GEC). The corpus consists of around 340 hours of L2 English
learners audio with holistic scores, and a subset of audio annotated with
transcriptions and error labels.

摘要：<paragraph>我們介紹 Speak & Improve 語料庫 2025，這是 L2 學習者英語資料的資料集，其中包含整體分數和語言錯誤註解，來自 Speak & Improve 學習平台上開放（自發）的口說測驗 https://speakandimprove.com。語料庫發布的目的是為了應對開發 L2 口說語言處理系統的一項重大挑戰，即缺乏帶有高品質註解的公開可用資料。它已在 ELiT 網站上提供非商業用途。在設計此語料庫時，我們力求涵蓋廣泛的說話者屬性，從他們的 L1 到他們的口說能力，並提供手動註解。這能讓一系列語言學習任務得以檢驗，例如評估口說能力或提供對學習者口說中語法錯誤的回饋。此外，資料支援對這些任務所需的基礎技術的研究，包括低資源 L2 學習者英語的自動語音辨識 (ASR)、不流暢偵測或口說語法錯誤更正 (GEC)。語料庫包含約 340 小時的 L2 英語學習者音訊，帶有整體分數，以及一小部分音訊已註解轉錄和錯誤標籤。</paragraph>

##### **Speak & Improve Challenge 2025: Tasks and Baseline Systems**
2412.11985v1 by Mengjie Qian, Kate Knill, Stefano Banno, Siyuan Tang, Penny Karanasou, Mark J. F. Gales, Diane Nicholls

This paper presents the "Speak & Improve Challenge 2025: Spoken Language
Assessment and Feedback" -- a challenge associated with the ISCA SLaTE 2025
Workshop. The goal of the challenge is to advance research on spoken language
assessment and feedback, with tasks associated with both the underlying
technology and language learning feedback. Linked with the challenge, the Speak
& Improve (S&I) Corpus 2025 is being pre-released, a dataset of L2 learner
English data with holistic scores and language error annotation, collected from
open (spontaneous) speaking tests on the Speak & Improve learning platform. The
corpus consists of 340 hours of audio data from second language English
learners with holistic scores, and a 60-hour subset with manual transcriptions
and error labels. The Challenge has four shared tasks: Automatic Speech
Recognition (ASR), Spoken Language Assessment (SLA), Spoken Grammatical Error
Correction (SGEC), and Spoken Grammatical Error Correction Feedback (SGECF).
Each of these tasks has a closed track where a predetermined set of models and
data sources are allowed to be used, and an open track where any public
resource may be used. Challenge participants may do one or more of the tasks.
This paper describes the challenge, the S&I Corpus 2025, and the baseline
systems released for the Challenge.

摘要：本論文提出「2025 年說與改進挑戰：口說語言評量與回饋」-- 一項與 ISCA SLaTE 2025 工作坊相關的挑戰。此挑戰的目標是推進對口說語言評量與回饋的研究，任務與基礎技術和語言學習回饋兩者相關。與此挑戰相關的「2025 年說與改進 (S&I) 語料庫」正在預先發布，這是一個 L2 學習者英語資料的資料集，包含整體分數和語言錯誤註解，從「說與改進」學習平台上的開放式 (自發性) 口說測驗收集而來。此語料庫包含來自第二語言英語學習者的 340 小時音訊資料，並附有整體分數，以及一個包含手動轉錄和錯誤標籤的 60 小時子集。此挑戰有四項共用任務：自動語音辨識 (ASR)、口說語言評量 (SLA)、口說文法錯誤修正 (SGEC) 和口說文法錯誤修正回饋 (SGECF)。每個任務都有封閉軌道，其中允許使用預先決定的模型和資料來源，以及開放軌道，其中可以使用任何公開資源。挑戰參與者可以執行一項或多項任務。本文說明了挑戰、「2025 年說與改進語料庫」以及為挑戰發布的基線系統。

##### **Cost-Effective Label-free Node Classification with LLMs**
2412.11983v1 by Taiyan Zhang, Renchi Yang, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Yurui Lai

Graph neural networks (GNNs) have emerged as go-to models for node
classification in graph data due to their powerful abilities in fusing graph
structures and attributes. However, such models strongly rely on adequate
high-quality labeled data for training, which are expensive to acquire in
practice. With the advent of large language models (LLMs), a promising way is
to leverage their superb zero-shot capabilities and massive knowledge for node
labeling. Despite promising results reported, this methodology either demands
considerable queries to LLMs, or suffers from compromised performance caused by
noisy labels produced by LLMs.
  To remedy these issues, this work presents Cella, an active self-training
framework that integrates LLMs into GNNs in a cost-effective manner. The design
recipe of Cella is to iteratively identify small sets of "critical" samples
using GNNs and extract informative pseudo-labels for them with both LLMs and
GNNs as additional supervision signals to enhance model training. Particularly,
Cella includes three major components: (i) an effective active node selection
strategy for initial annotations; (ii) a judicious sample selection scheme to
sift out the "critical" nodes based on label disharmonicity and entropy; and
(iii) a label refinement module combining LLMs and GNNs with rewired topology.
Our extensive experiments over five benchmark text-attributed graph datasets
demonstrate that Cella significantly outperforms the state of the arts under
the same query budget to LLMs in terms of label-free node classification. In
particular, on the DBLP dataset with 14.3k nodes, Cella is able to achieve an
8.08% conspicuous improvement in accuracy over the state-of-the-art at a cost
of less than one cent.

摘要：圖形神經網路 (GNN) 已成為圖形資料中節點分類的熱門模型，因為它們在融合圖形結構和屬性方面具有強大的能力。然而，此類模型在訓練時高度依賴足夠的高品質標籤資料，而這些資料在實務上取得的成本很高。隨著大型語言模型 (LLM) 的出現，一個有前途的方法是利用其卓越的零次學習能力和海量知識進行節點標籤。儘管報告了有希望的結果，但此方法不是需要大量查詢 LLM，就是會因為 LLM 產生的標籤有雜訊而導致效能受損。
為了解決這些問題，本研究提出 Cella，一個主動自訓練架構，以具有成本效益的方式將 LLM 整合到 GNN 中。Cella 的設計秘訣是使用 GNN 迭代識別小組「關鍵」樣本，並使用 LLM 和 GNN 作為額外的監督訊號，為這些樣本萃取有意義的偽標籤，以增強模型訓練。特別是，Cella 包含三個主要組成部分：(i) 一個有效的節點主動選擇策略，用於初始註解；(ii) 一個明智的樣本選擇方案，根據標籤不協調性和熵篩選出「關鍵」節點；以及 (iii) 一個結合 LLM 和 GNN 以及重新連線拓撲的標籤精緻模組。我們在五個基準文字屬性圖形資料集上進行的廣泛實驗表明，在相同的 LLM 查詢預算下，Cella 在無標籤節點分類方面顯著優於現有技術。特別是在具有 14.3k 個節點的 DBLP 資料集上，Cella 能夠以低於一美分的成本，在準確度上比現有技術顯著提升 8.08%。

##### **Speech Foundation Models and Crowdsourcing for Efficient, High-Quality Data Collection**
2412.11978v1 by Beomseok Lee, Marco Gaido, Ioan Calapodescu, Laurent Besacier, Matteo Negri

While crowdsourcing is an established solution for facilitating and scaling
the collection of speech data, the involvement of non-experts necessitates
protocols to ensure final data quality. To reduce the costs of these essential
controls, this paper investigates the use of Speech Foundation Models (SFMs) to
automate the validation process, examining for the first time the cost/quality
trade-off in data acquisition. Experiments conducted on French, German, and
Korean data demonstrate that SFM-based validation has the potential to reduce
reliance on human validation, resulting in an estimated cost saving of over
40.0% without degrading final data quality. These findings open new
opportunities for more efficient, cost-effective, and scalable speech data
acquisition.

摘要：雖然群眾外包是促進和擴展語音資料收集的既定解決方案，但非專家的參與需要有確保最終資料品質的協定。為了降低這些必要的控制成本，本文探討使用語音基礎模型 (SFM) 來自動化驗證流程，首次探討資料取得中的成本/品質權衡。對法語、德語和韓語資料進行的實驗證明，基於 SFM 的驗證有潛力減少對人工驗證的依賴，估計可節省超過 40.0% 的成本，而不會降低最終資料品質。這些發現為更有效率、更具成本效益和可擴展的語音資料取得開啟了新的契機。

##### **Emma-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning**
2412.11974v1 by Qi Sun, Pengfei Hong, Tej Deep Pala, Vernon Toh, U-Xuan Tan, Deepanway Ghosal, Soujanya Poria

Traditional reinforcement learning-based robotic control methods are often
task-specific and fail to generalize across diverse environments or unseen
objects and instructions. Visual Language Models (VLMs) demonstrate strong
scene understanding and planning capabilities but lack the ability to generate
actionable policies tailored to specific robotic embodiments. To address this,
Visual-Language-Action (VLA) models have emerged, yet they face challenges in
long-horizon spatial reasoning and grounded task planning. In this work, we
propose the Embodied Multimodal Action Model with Grounded Chain of Thought and
Look-ahead Spatial Reasoning, Emma-X. Emma-X leverages our constructed
hierarchical embodiment dataset based on BridgeV2, containing 60,000 robot
manipulation trajectories auto-annotated with grounded task reasoning and
spatial guidance. Additionally, we introduce a trajectory segmentation strategy
based on gripper states and motion trajectories, which can help mitigate
hallucination in grounding subtask reasoning generation. Experimental results
demonstrate that Emma-X achieves superior performance over competitive
baselines, particularly in real-world robotic tasks requiring spatial
reasoning.

摘要：傳統的強化學習機器人控制方法通常是特定於任務的，並且無法推廣到不同的環境或不可見的物體和指令。視覺語言模型 (VLM) 展示了強大的場景理解和規劃能力，但缺乏生成針對特定機器人具體實例的可行策略的能力。為了解決這個問題，視覺語言動作 (VLA) 模型應運而生，但它們在長時域空間推理和基礎任務規劃中面臨挑戰。在這項工作中，我們提出了具有基礎思想鏈和前瞻性空間推理的具體多模態動作模型 Emma-X。Emma-X 利用我們基於 BridgeV2 構建的分層具體化數據集，其中包含 60,000 個機器人操作軌跡，並使用基礎任務推理和空間指導進行自動註解。此外，我們引入了一種基於夾持器狀態和運動軌跡的軌跡分段策略，這有助於減輕基礎子任務推理生成中的幻覺。實驗結果表明，Emma-X 在競爭基準上取得了優異的性能，特別是在需要空間推理的現實世界機器人任務中。

##### **DARWIN 1.5: Large Language Models as Materials Science Adapted Learners**
2412.11970v1 by Tong Xie, Yuwei Wan, Yixuan Liu, Yuchen Zeng, Wenjie Zhang, Chunyu Kit, Dongzhan Zhou, Bram Hoex

Materials discovery and design aim to find components and structures with
desirable properties over highly complex and diverse search spaces. Traditional
solutions, such as high-throughput simulations and machine learning (ML), often
rely on complex descriptors, which hinder generalizability and transferability
across tasks. Moreover, these descriptors may deviate from experimental data
due to inevitable defects and purity issues in the real world, which may reduce
their effectiveness in practical applications. To address these challenges, we
propose Darwin 1.5, an open-source large language model (LLM) tailored for
materials science. By leveraging natural language as input, Darwin eliminates
the need for task-specific descriptors and enables a flexible, unified approach
to material property prediction and discovery. We employ a two-stage training
strategy combining question-answering (QA) fine-tuning with multi-task learning
(MTL) to inject domain-specific knowledge in various modalities and facilitate
cross-task knowledge transfer. Through our strategic approach, we achieved a
significant enhancement in the prediction accuracy of LLMs, with a maximum
improvement of 60\% compared to LLaMA-7B base models. It further outperforms
traditional machine learning models on various tasks in material science,
showcasing the potential of LLMs to provide a more versatile and scalable
foundation model for materials discovery and design.

摘要：材料發現和設計旨在尋找在高度複雜且多樣化的搜尋空間中具有理想特性的組成和結構。傳統的解決方案，例如高通量模擬和機器學習 (ML)，通常依賴於複雜的描述符，這會阻礙任務間的概括性和可傳遞性。此外，這些描述符可能會因現實世界中不可避免的缺陷和純度問題而偏離實驗數據，這可能會降低它們在實際應用中的有效性。為了應對這些挑戰，我們提出了 Darwin 1.5，這是一個針對材料科學量身定制的開源大型語言模型 (LLM)。通過利用自然語言作為輸入，Darwin 消除了對特定任務描述符的需求，並實現了對材料屬性預測和發現的靈活、統一的方法。我們採用結合問題解答 (QA) 微調和多任務學習 (MTL) 的兩階段訓練策略，以注入各種模式的領域特定知識，並促進跨任務知識傳遞。通過我們的策略性方法，我們在 LLM 的預測準確性方面取得了顯著提升，與 LLaMA-7B 基礎模型相比，最大改進了 60%。它在材料科學的各種任務中進一步優於傳統的機器學習模型，展示了 LLM 為材料發現和設計提供更通用、更可擴展基礎模型的潛力。

##### **Inferring Functionality of Attention Heads from their Parameters**
2412.11965v1 by Amit Elhelo, Mor Geva

Attention heads are one of the building blocks of large language models
(LLMs). Prior work on investigating their operation mostly focused on analyzing
their behavior during inference for specific circuits or tasks. In this work,
we seek a comprehensive mapping of the operations they implement in a model. We
propose MAPS (Mapping Attention head ParameterS), an efficient framework that
infers the functionality of attention heads from their parameters, without any
model training or inference. We showcase the utility of MAPS for answering two
types of questions: (a) given a predefined operation, mapping how strongly
heads across the model implement it, and (b) given an attention head, inferring
its salient functionality. Evaluating MAPS on 20 operations across 6 popular
LLMs shows its estimations correlate with the head's outputs during inference
and are causally linked to the model's predictions. Moreover, its mappings
reveal attention heads of certain operations that were overlooked in previous
studies, and valuable insights on function universality and architecture biases
in LLMs. Next, we present an automatic pipeline and analysis that leverage MAPS
to characterize the salient operations of a given head. Our pipeline produces
plausible operation descriptions for most heads, as assessed by human judgment,
while revealing diverse operations.

摘要：注意力頭部是大語言模型 (LLM) 的基本組成部分之一。先前針對其運作的研究主要集中在分析其在特定電路或任務的推理期間的行為。在這項工作中，我們尋求全面地對模型中實作的運算進行對應。我們提出 MAPS (對應注意力頭部參數)，一種有效率的架構，可以從其參數推論注意力頭部的功能，而無需任何模型訓練或推理。我們展示了 MAPS 在回答兩種問題時的效用：(a) 給定一個預定義的運算，對應模型中頭部實作它的強度，以及 (b) 給定一個注意力頭部，推論其顯著功能。在 6 個熱門 LLM 中對 20 個運算評估 MAPS，顯示其估計值與推理期間頭部的輸出相關，並且與模型的預測有因果關係。此外，其對應揭示了先前研究中被忽略的特定運算的注意力頭部，以及關於 LLM 中功能通用性和架構偏差的寶貴見解。接下來，我們提出一個自動化管道和分析，利用 MAPS 來描述給定頭部的顯著運算。我們的管道會產生大多數頭部合理的運算描述，經由人類判斷評估，同時揭示不同的運算。

##### **Gramian Multimodal Representation Learning and Alignment**
2412.11959v1 by Giordano Cicchetti, Eleonora Grassucci, Luigi Sigillo, Danilo Comminiello

Human perception integrates multiple modalities, such as vision, hearing, and
language, into a unified understanding of the surrounding reality. While recent
multimodal models have achieved significant progress by aligning pairs of
modalities via contrastive learning, their solutions are unsuitable when
scaling to multiple modalities. These models typically align each modality to a
designated anchor without ensuring the alignment of all modalities with each
other, leading to suboptimal performance in tasks requiring a joint
understanding of multiple modalities. In this paper, we structurally rethink
the pairwise conventional approach to multimodal learning and we present the
novel Gramian Representation Alignment Measure (GRAM), which overcomes the
above-mentioned limitations. GRAM learns and then aligns $n$ modalities
directly in the higher-dimensional space in which modality embeddings lie by
minimizing the Gramian volume of the $k$-dimensional parallelotope spanned by
the modality vectors, ensuring the geometric alignment of all modalities
simultaneously. GRAM can replace cosine similarity in any downstream method,
holding for 2 to $n$ modality and providing more meaningful alignment with
respect to previous similarity measures. The novel GRAM-based contrastive loss
function enhances the alignment of multimodal models in the higher-dimensional
embedding space, leading to new state-of-the-art performance in downstream
tasks such as video-audio-text retrieval and audio-video classification. The
project page, the code, and the pretrained models are available at
https://ispamm.github.io/GRAM/.

摘要：人類感知整合了多種方式，例如視覺、聽覺和語言，對周圍現實進行統一理解。儘管最近的多模態模型通過對比學習對成對的方式進行對齊，取得了重大進展，但當擴展到多種方式時，它們的解決方案並不適用。這些模型通常將每個方式對齊到指定的錨點，而不確保所有方式彼此對齊，導致在需要對多種方式進行聯合理解的任務中性能不佳。在本文中，我們在結構上重新思考了多模態學習的成對傳統方法，並提出了新的 Gramian 表示對齊度量 (GRAM)，它克服了上述限制。GRAM 直接在方式嵌入所在的更高維度空間中學習並對齊 $n$ 種方式，方法是通過最小化方式向量跨越的 $k$ 維平行六面體的 Gramian 體積，從而同時確保所有方式的幾何對齊。GRAM 可以取代任何下游方法中的餘弦相似性，適用於 2 到 $n$ 種方式，並相對於先前的相似性度量提供更有意義的對齊。基於 GRAM 的新對比損失函數增強了多模態模型在更高維度嵌入空間中的對齊，從而導致了下游任務（例如視頻-音頻-文本檢索和音頻-視頻分類）中新的最先進性能。項目頁面、代碼和預訓練模型可在 https://ispamm.github.io/GRAM/ 獲得。

##### **Advancing Comprehensive Aesthetic Insight with Multi-Scale Text-Guided Self-Supervised Learning**
2412.11952v1 by Yuti Liu, Shice Liu, Junyuan Gao, Pengtao Jiang, Hao Zhang, Jinwei Chen, Bo Li

Image Aesthetic Assessment (IAA) is a vital and intricate task that entails
analyzing and assessing an image's aesthetic values, and identifying its
highlights and areas for improvement. Traditional methods of IAA often
concentrate on a single aesthetic task and suffer from inadequate labeled
datasets, thus impairing in-depth aesthetic comprehension. Despite efforts to
overcome this challenge through the application of Multi-modal Large Language
Models (MLLMs), such models remain underdeveloped for IAA purposes. To address
this, we propose a comprehensive aesthetic MLLM capable of nuanced aesthetic
insight. Central to our approach is an innovative multi-scale text-guided
self-supervised learning technique. This technique features a multi-scale
feature alignment module and capitalizes on a wealth of unlabeled data in a
self-supervised manner to structurally and functionally enhance aesthetic
ability. The empirical evidence indicates that accompanied with extensive
instruct-tuning, our model sets new state-of-the-art benchmarks across multiple
tasks, including aesthetic scoring, aesthetic commenting, and personalized
image aesthetic assessment. Remarkably, it also demonstrates zero-shot learning
capabilities in the emerging task of aesthetic suggesting. Furthermore, for
personalized image aesthetic assessment, we harness the potential of in-context
learning and showcase its inherent advantages.

摘要：影像美學評估 (IAA) 是一項重要且複雜的任務，需要分析和評估影像的美學價值，並找出其亮點和需要改進的地方。傳統的 IAA 方法通常專注於單一美學任務，且受限於標註資料集不足，因此影響深入的美學理解。儘管透過應用多模態大型語言模型 (MLLM) 來克服這項挑戰，但此類模型在 IAA 用途上仍未發展成熟。為了解決這個問題，我們提出一個全面的美學 MLLM，具備細緻入微的美學見解。我們的方法核心是一個創新的多尺度文字引導式自監督學習技術。此技術具備多尺度特徵對齊模組，並利用大量未標註資料以自監督的方式，在結構和功能上提升美學能力。實證證據顯示，在廣泛的指令微調下，我們的模型在多項任務中設定新的最先進基準，包括美學評分、美學評論和個人化影像美學評估。值得注意的是，它還在美學建議的新興任務中展現出零次學習能力。此外，對於個人化影像美學評估，我們利用情境學習的潛力，並展示其固有優勢。

##### **The Impact of Generalization Techniques on the Interplay Among Privacy, Utility, and Fairness in Image Classification**
2412.11951v1 by Ahmad Hassanpour, Amir Zarei, Khawla Mallat, Anderson Santana de Oliveira, Bian Yang

This study investigates the trade-offs between fairness, privacy, and utility
in image classification using machine learning (ML). Recent research suggests
that generalization techniques can improve the balance between privacy and
utility. One focus of this work is sharpness-aware training (SAT) and its
integration with differential privacy (DP-SAT) to further improve this balance.
Additionally, we examine fairness in both private and non-private learning
models trained on datasets with synthetic and real-world biases. We also
measure the privacy risks involved in these scenarios by performing membership
inference attacks (MIAs) and explore the consequences of eliminating
high-privacy risk samples, termed outliers. Moreover, we introduce a new
metric, named \emph{harmonic score}, which combines accuracy, privacy, and
fairness into a single measure.
  Through empirical analysis using generalization techniques, we achieve an
accuracy of 81.11\% under $(8, 10^{-5})$-DP on CIFAR-10, surpassing the 79.5\%
reported by De et al. (2022). Moreover, our experiments show that memorization
of training samples can begin before the overfitting point, and generalization
techniques do not guarantee the prevention of this memorization. Our analysis
of synthetic biases shows that generalization techniques can amplify model bias
in both private and non-private models. Additionally, our results indicate that
increased bias in training data leads to reduced accuracy, greater
vulnerability to privacy attacks, and higher model bias. We validate these
findings with the CelebA dataset, demonstrating that similar trends persist
with real-world attribute imbalances. Finally, our experiments show that
removing outlier data decreases accuracy and further amplifies model bias.

摘要：<paragraph>本研究探討了使用機器學習 (ML) 進行影像分類時，公平性、隱私和效用之間的權衡。最近的研究表明，泛化技術可以改善隱私與效用之間的平衡。本研究重點之一是具備銳利度感知的訓練 (SAT) 及其與差分隱私 (DP-SAT) 的整合，以進一步改善此平衡。此外，我們檢視了在具有合成和真實世界偏差的資料集上訓練的私人和非私人學習模型中的公平性。我們也透過執行成員身分推論攻擊 (MIA) 來衡量這些情境中涉及的隱私風險，並探討消除稱為離群值的隱私風險較高樣本的後果。此外，我們引進了一個名為「調和分數」的新指標，它將準確度、隱私和公平性結合為單一指標。
透過使用泛化技術的實證分析，我們在 CIFAR-10 上以 $(8, 10^{-5})$-DP 達到 81.11% 的準確度，超越了 De 等人 (2022) 所報告的 79.5%。此外，我們的實驗顯示，訓練樣本的記憶可能會在過度擬合點之前開始，而泛化技術無法保證防止這種記憶。我們對合成偏差的分析顯示，泛化技術會在私人和非私人模型中放大模型偏差。此外，我們的結果表明，訓練資料中偏差的增加會導致準確度降低、更容易受到隱私攻擊以及模型偏差更高。我們使用 CelebA 資料集驗證了這些發現，證明了類似的趨勢會持續存在於真實世界的屬性不平衡中。最後，我們的實驗顯示，移除離群資料會降低準確度並進一步放大模型偏差。</paragraph>

##### **OpenReviewer: A Specialized Large Language Model for Generating Critical Scientific Paper Reviews**
2412.11948v1 by Maximilian Idahl, Zahra Ahmadi

We present OpenReviewer, an open-source system for generating high-quality
peer reviews of machine learning and AI conference papers. At its core is
Llama-OpenReviewer-8B, an 8B parameter language model specifically fine-tuned
on 79,000 expert reviews from top ML conferences. Given a PDF paper submission
and review template as input, OpenReviewer extracts the full text, including
technical content like equations and tables, and generates a structured review
following conference-specific guidelines. Our evaluation on 400 test papers
shows that OpenReviewer produces significantly more critical and realistic
reviews compared to general-purpose LLMs like GPT-4 and Claude-3.5. While other
LLMs tend toward overly positive assessments, OpenReviewer's recommendations
closely match the distribution of human reviewer ratings. The system provides
authors with rapid, constructive feedback to improve their manuscripts before
submission, though it is not intended to replace human peer review.
OpenReviewer is available as an online demo and open-source tool.

摘要：<paragraph>我們推出 OpenReviewer，一個用於產生機器學習和 AI 會議論文的高品質同儕評論的開源系統。其核心是 Llama-OpenReviewer-8B，一個專門針對來自頂尖 ML 會議的 79,000 份專家評論進行微調的 8B 參數語言模型。輸入 PDF 論文提交和評論範本後，OpenReviewer 會擷取全文，包括技術內容（例如方程式和表格），並根據特定會議的指南產生結構化的評論。我們對 400 篇測試論文的評估顯示，與 GPT-4 和 Claude-3.5 等通用 LLM 相比，OpenReviewer 產生的評論明顯更具批判性且更貼近現實。雖然其他 LLM 傾向於過度正面的評估，但 OpenReviewer 的建議與人類評論員評分的分布非常吻合。該系統可為作者提供快速且具建設性的回饋，以便在提交前改善其手稿，但並非旨在取代人類同儕評論。OpenReviewer 可作為線上示範和開源工具使用。</paragraph>

##### **The Impact of Token Granularity on the Predictive Power of Language Model Surprisal**
2412.11940v1 by Byung-Doh Oh, William Schuler

Word-by-word language model surprisal is often used to model the incremental
processing of human readers, which raises questions about how various choices
in language modeling influence its predictive power. One factor that has been
overlooked in cognitive modeling is the granularity of subword tokens, which
explicitly encodes information about word length and frequency, and ultimately
influences the quality of vector representations that are learned. This paper
presents experiments that manipulate the token granularity and evaluate its
impact on the ability of surprisal to account for processing difficulty of
naturalistic text and garden-path constructions. Experiments with naturalistic
reading times reveal a substantial influence of token granularity on surprisal,
with tokens defined by a vocabulary size of 8,000 resulting in surprisal that
is most predictive. In contrast, on garden-path constructions, language models
trained on coarser-grained tokens generally assigned higher surprisal to
critical regions, suggesting their increased sensitivity to syntax. Taken
together, these results suggest a large role of token granularity on the
quality of language model surprisal for cognitive modeling.

摘要：字对字语言模型的意外性经常用来模拟人类阅读者的渐进式处理，这引发了关于语言建模中的各种选择如何影响其预测能力的问题。一个在认知建模中被忽视的因素是子词标记的粒度，它明确编码了有关词长和频率的信息，并最终影响所学习的向量表示的质量。本文介绍了操纵标记粒度并评估其对意外性预测自然文本和花园路径结构处理难度的能力的影响的实验。自然阅读时间的实验揭示了标记粒度对意外性的实质性影响，由 8,000 个词汇量大小定义的标记导致意外性最具预测性。相比之下，在花园路径结构中，训练在较粗粒度标记上的语言模型通常会给关键区域分配较高的意外性，表明它们对句法的敏感性增加。综合起来，这些结果表明标记粒度对认知建模的语言模型意外性的质量有很大的作用。

##### **Precise Length Control in Large Language Models**
2412.11937v1 by Bradley Butcher, Michael O'Keefe, James Titchener

Large Language Models (LLMs) are increasingly used in production systems,
powering applications such as chatbots, summarization, and question answering.
Despite their success, controlling the length of their response remains a
significant challenge, particularly for tasks requiring structured outputs or
specific levels of detail. In this work, we propose a method to adapt
pre-trained decoder-only LLMs for precise control of response length. Our
approach incorporates a secondary length-difference positional encoding (LDPE)
into the input embeddings, which counts down to a user-set response termination
length. Fine-tuning with LDPE allows the model to learn to terminate responses
coherently at the desired length, achieving mean token errors of less than 3
tokens. We also introduce Max New Tokens++, an extension that enables flexible
upper-bound length control, rather than an exact target. Experimental results
on tasks such as question answering and document summarization demonstrate that
our method enables precise length control without compromising response
quality.

摘要：大型語言模型 (LLM)  zunehmend in Produktionssystemen eingesetzt werden, die Anwendungen wie Chatbots, Zusammenfassungen und Fragen und Antworten unterstützen. Trotz ihres Erfolgs bleibt die Steuerung der Länge ihrer Antwort eine große Herausforderung, insbesondere für Aufgaben, die strukturierte Ausgaben oder bestimmte Detailstufen erfordern. In dieser Arbeit schlagen wir eine Methode vor, vortrainierte Decoder-only-LLMs für eine präzise Steuerung der Antwortlänge anzupassen. Unser Ansatz integriert eine sekundäre Positionskodierung der Längenunterschiede (LDPE) in die Eingabeembeddings, die bis zu einer vom Benutzer festgelegten Länge der Beendigung der Antwort herunterzählt. Die Feinabstimmung mit LDPE ermöglicht es dem Modell, zu lernen, Antworten zusammenhängend in der gewünschten Länge zu beenden und mittlere Tokenfehler von weniger als 3 Token zu erzielen. Wir stellen außerdem Max New Tokens++ vor, eine Erweiterung, die eine flexible Steuerung der Obergrenze der Länge ermöglicht, anstatt ein genaues Ziel. Experimentelle Ergebnisse zu Aufgaben wie Fragen und Antworten und Dokumentzusammenfassung zeigen, dass unsere Methode eine präzise Längenkontrolle ermöglicht, ohne die Qualität der Antwort zu beeinträchtigen.

##### **A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges**
2412.11936v1 by Yibo Yan, Jiamin Su, Jianxiang He, Fangteng Fu, Xu Zheng, Yuanhuiyi Lyu, Kun Wang, Shen Wang, Qingsong Wen, Xuming Hu

Mathematical reasoning, a core aspect of human cognition, is vital across
many domains, from educational problem-solving to scientific advancements. As
artificial general intelligence (AGI) progresses, integrating large language
models (LLMs) with mathematical reasoning tasks is becoming increasingly
significant. This survey provides the first comprehensive analysis of
mathematical reasoning in the era of multimodal large language models (MLLMs).
We review over 200 studies published since 2021, and examine the
state-of-the-art developments in Math-LLMs, with a focus on multimodal
settings. We categorize the field into three dimensions: benchmarks,
methodologies, and challenges. In particular, we explore multimodal
mathematical reasoning pipeline, as well as the role of (M)LLMs and the
associated methodologies. Finally, we identify five major challenges hindering
the realization of AGI in this domain, offering insights into the future
direction for enhancing multimodal reasoning capabilities. This survey serves
as a critical resource for the research community in advancing the capabilities
of LLMs to tackle complex multimodal reasoning tasks.

摘要：數學推理是人類認知的核心面向，在許多領域中至關重要，從教育問題解決到科學進步。隨著人工通用智慧 (AGI) 的進展，將大型語言模型 (LLM) 與數學推理任務整合變得越來越重要。這項調查提供了第一個對多模態大型語言模型 (MLLM) 時代數學推理的全面分析。我們回顧了自 2021 年以來發表的 200 多項研究，並檢視了數學 LLM 的最新發展，重點放在多模態設定上。我們將該領域分為三個面向：基準、方法和挑戰。特別是，我們探討了多模態數學推理管道，以及 (M)LLM 和相關方法的角色。最後，我們找出阻礙在這個領域實現 AGI 的五項主要挑戰，並提供對未來加強多模態推理能力方向的見解。這項調查可作為研究社群推進 LLM 解決複雜多模態推理任務能力的重要資源。

##### **Stepwise Reasoning Error Disruption Attack of LLMs**
2412.11934v1 by Jingyu Peng, Maolin Wang, Xiangyu Zhao, Kai Zhang, Wanyu Wang, Pengyue Jia, Qidong Liu, Ruocheng Guo, Qi Liu

Large language models (LLMs) have made remarkable strides in complex
reasoning tasks, but their safety and robustness in reasoning processes remain
underexplored. Existing attacks on LLM reasoning are constrained by specific
settings or lack of imperceptibility, limiting their feasibility and
generalizability. To address these challenges, we propose the Stepwise
rEasoning Error Disruption (SEED) attack, which subtly injects errors into
prior reasoning steps to mislead the model into producing incorrect subsequent
reasoning and final answers. Unlike previous methods, SEED is compatible with
zero-shot and few-shot settings, maintains the natural reasoning flow, and
ensures covert execution without modifying the instruction. Extensive
experiments on four datasets across four different models demonstrate SEED's
effectiveness, revealing the vulnerabilities of LLMs to disruptions in
reasoning processes. These findings underscore the need for greater attention
to the robustness of LLM reasoning to ensure safety in practical applications.

摘要：大型語言模型（LLM）在複雜推理任務中取得顯著進展，但其在推理過程中的安全性與穩健性仍未被充分探討。現有的 LLM 推理攻擊受到特定設定或不可察覺性的限制，限制了其可行性和概括性。為了應對這些挑戰，我們提出了逐步推理錯誤破壞（SEED）攻擊，它巧妙地將錯誤注入先前的推理步驟，以誤導模型產生不正確的後續推理和最終答案。與先前的技術不同，SEED 與零次學習和少量學習設定相容，維持了自然的推理流程，並確保在不修改指令的情況下執行隱蔽操作。在四個不同模型的四個資料集上進行的廣泛實驗證明了 SEED 的有效性，揭示了 LLM 在推理過程中容易受到破壞的弱點。這些發現強調需要更加關注 LLM 推理的穩健性，以確保實際應用中的安全性。

##### **Explainable Procedural Mistake Detection**
2412.11927v1 by Shane Storks, Itamar Bar-Yossef, Yayuan Li, Zheyuan Zhang, Jason J. Corso, Joyce Chai

Automated task guidance has recently attracted attention from the AI research
community. Procedural mistake detection (PMD) is a challenging sub-problem of
classifying whether a human user (observed through egocentric video) has
successfully executed the task at hand (specified by a procedural text).
Despite significant efforts in building resources and models for PMD, machine
performance remains nonviable, and the reasoning processes underlying this
performance are opaque. As such, we recast PMD to an explanatory self-dialog of
questions and answers, which serve as evidence for a decision. As this
reformulation enables an unprecedented transparency, we leverage a fine-tuned
natural language inference (NLI) model to formulate two automated coherence
metrics for generated explanations. Our results show that while open-source
VLMs struggle with this task off-the-shelf, their accuracy, coherence, and
dialog efficiency can be vastly improved by incorporating these coherence
metrics into common inference and fine-tuning methods. Furthermore, our
multi-faceted metrics can visualize common outcomes at a glance, highlighting
areas for improvement.

摘要：自動化任務指導最近引起了人工智慧研究社群的關注。程序錯誤偵測 (PMD) 是分類人類使用者 (透過自我中心視訊觀察) 是否已成功執行手邊任務 (由程序文字指定) 的一個具有挑戰性的子問題。儘管在建構 PMD 資源和模型方面投入了大量心力，但機器效能仍無法發揮作用，而此效能背後的推理程序也不透明。因此，我們將 PMD 改寫為一個說明性的自我對話，包含問題和答案，作為決策的證據。由於這種重新表述提供了前所未有的透明度，我們利用微調後的自然語言推理 (NLI) 模型來制定兩個用於生成說明的自動化一致性指標。我們的結果顯示，雖然開放原始碼 VLM 在此任務上現階段仍有困難，但透過將這些一致性指標納入常見的推理和微調方法，它們的準確性、一致性和對話效率可以大幅提升。此外，我們多面向的指標可以一目了然地視覺化常見結果，並強調需要改進的地方。

##### **PICLe: Pseudo-Annotations for In-Context Learning in Low-Resource Named Entity Detection**
2412.11923v1 by Sepideh Mamooler, Syrielle Montariol, Alexander Mathis, Antoine Bosselut

In-context learning (ICL) enables Large Language Models (LLMs) to perform
tasks using few demonstrations, facilitating task adaptation when labeled
examples are hard to obtain. However, ICL is sensitive to the choice of
demonstrations, and it remains unclear which demonstration attributes enable
in-context generalization. In this work, we conduct a perturbation study of
in-context demonstrations for low-resource Named Entity Detection (NED). Our
surprising finding is that in-context demonstrations with partially correct
annotated entity mentions can be as effective for task transfer as fully
correct demonstrations. Based off our findings, we propose Pseudo-annotated
In-Context Learning (PICLe), a framework for in-context learning with noisy,
pseudo-annotated demonstrations. PICLe leverages LLMs to annotate many
demonstrations in a zero-shot first pass. We then cluster these synthetic
demonstrations, sample specific sets of in-context demonstrations from each
cluster, and predict entity mentions using each set independently. Finally, we
use self-verification to select the final set of entity mentions. We evaluate
PICLe on five biomedical NED datasets and show that, with zero human
annotation, PICLe outperforms ICL in low-resource settings where limited gold
examples can be used as in-context demonstrations.

摘要：情境學習 (ICL) 能讓大型語言模型 (LLM) 使用少量示範執行任務，在難以取得標記範例時，能促進任務適應。然而，ICL 對示範的選擇很敏感，而哪些示範屬性能讓情境概化仍不清楚。在這項工作中，我們對低資源命名實體偵測 (NED) 的情境示範進行擾動研究。我們令人驚訝的發現是，帶有部分正確註解實體提及的情境示範，在任務轉移上能與完全正確的示範一樣有效。根據我們的發現，我們提出偽註解情境學習 (PICLe)，一個使用有雜訊、偽註解示範的情境學習架構。PICLe 藉由 LLM 在零次學習的第一階段註解許多示範。然後我們將這些合成示範分群，從每個群集中取樣特定組的情境示範，並使用每個組獨立預測實體提及。最後，我們使用自我驗證來選擇最後一組實體提及。我們在五個生物醫學 NED 資料集上評估 PICLe，並顯示在沒有人工註解的情況下，PICLe 在低資源設定中優於 ICL，其中有限的黃金範例可用作情境示範。

##### **RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation**
2412.11919v1 by Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou

Large language models (LLMs) exhibit remarkable generative capabilities but
often suffer from hallucinations. Retrieval-augmented generation (RAG) offers
an effective solution by incorporating external knowledge, but existing methods
still face several limitations: additional deployment costs of separate
retrievers, redundant input tokens from retrieved text chunks, and the lack of
joint optimization of retrieval and generation. To address these issues, we
propose \textbf{RetroLLM}, a unified framework that integrates retrieval and
generation into a single, cohesive process, enabling LLMs to directly generate
fine-grained evidence from the corpus with constrained decoding. Moreover, to
mitigate false pruning in the process of constrained evidence generation, we
introduce (1) hierarchical FM-Index constraints, which generate
corpus-constrained clues to identify a subset of relevant documents before
evidence generation, reducing irrelevant decoding space; and (2) a
forward-looking constrained decoding strategy, which considers the relevance of
future sequences to improve evidence accuracy. Extensive experiments on five
open-domain QA datasets demonstrate RetroLLM's superior performance across both
in-domain and out-of-domain tasks. The code is available at
\url{https://github.com/sunnynexus/RetroLLM}.

摘要：大型語言模型 (LLM) 展現出卓越的生成能力，但常常會出現幻覺。檢索增強生成 (RAG) 提供了一個有效的解決方案，方法是納入外部知識，但現有方法仍然面臨幾個限制：獨立檢索器的額外部署成本、檢索的文字片段中重複的輸入代碼，以及缺乏檢索和生成的聯合最佳化。為了解決這些問題，我們提出 \textbf{RetroLLM}，一個統一的架構，將檢索和生成整合到一個單一的、有凝聚力的過程中，使 LLM 能夠直接從語料庫中生成細緻的證據，並進行約束解碼。此外，為了減輕受約束證據生成過程中錯誤的修剪，我們引入了 (1) 層級式 FM-Index 約束，在生成證據之前產生語料庫約束的線索，以識別相關文件子集，減少不相關的解碼空間；以及 (2) 前瞻性的約束解碼策略，考慮未來序列的相關性，以提高證據準確性。在五個開放領域 QA 資料集上的大量實驗證明了 RetroLLM 在領域內和領域外任務中的優異性能。程式碼可以在 \url{https://github.com/sunnynexus/RetroLLM} 取得。

##### **CharacterBench: Benchmarking Character Customization of Large Language Models**
2412.11912v1 by Jinfeng Zhou, Yongkang Huang, Bosi Wen, Guanqun Bi, Yuxuan Chen, Pei Ke, Zhuang Chen, Xiyao Xiao, Libiao Peng, Kuntian Tang, Rongsheng Zhang, Le Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

Character-based dialogue (aka role-playing) enables users to freely customize
characters for interaction, which often relies on LLMs, raising the need to
evaluate LLMs' character customization capability. However, existing benchmarks
fail to ensure a robust evaluation as they often only involve a single
character category or evaluate limited dimensions. Moreover, the sparsity of
character features in responses makes feature-focused generative evaluation
both ineffective and inefficient. To address these issues, we propose
CharacterBench, the largest bilingual generative benchmark, with 22,859
human-annotated samples covering 3,956 characters from 25 detailed character
categories. We define 11 dimensions of 6 aspects, classified as sparse and
dense dimensions based on whether character features evaluated by specific
dimensions manifest in each response. We enable effective and efficient
evaluation by crafting tailored queries for each dimension to induce
characters' responses related to specific dimensions. Further, we develop
CharacterJudge model for cost-effective and stable evaluations. Experiments
show its superiority over SOTA automatic judges (e.g., GPT-4) and our
benchmark's potential to optimize LLMs' character customization. Our repository
is at https://github.com/thu-coai/CharacterBench.

摘要：基於字元的對話（又稱角色扮演）允許使用者自由自訂角色以進行互動，這通常仰賴 LLM，並提升了評估 LLM 角色自訂功能的需求。然而，現有的基準並未確保穩健的評估，因為它們通常只涉及單一的角色類別或評估有限的維度。此外，回應中角色特徵的稀疏性使得以特徵為中心的生成式評估既無效又低效。為了解決這些問題，我們提出了 CharacterBench，這是最大的雙語生成式基準，包含 22,859 個由人類註解的範例，涵蓋來自 25 個詳細角色類別的 3,956 個角色。我們定義了 6 個面向的 11 個維度，根據由特定維度評估的角色特徵是否在每個回應中顯現，將其分類為稀疏和稠密維度。我們透過為每個維度制定客製化查詢來誘導與特定維度相關的角色回應，進而實現有效且高效的評估。此外，我們開發了 CharacterJudge 模型以進行具成本效益且穩定的評估。實驗顯示其優於 SOTA 自動評分器（例如 GPT-4），而我們的基準有潛力最佳化 LLM 的角色自訂。我們的儲存庫位於 https://github.com/thu-coai/CharacterBench。

##### **Can Language Models Rival Mathematics Students? Evaluating Mathematical Reasoning through Textual Manipulation and Human Experiments**
2412.11908v1 by Andrii Nikolaiev, Yiannos Stathopoulos, Simone Teufel

In this paper we look at the ability of recent large language models (LLMs)
at solving mathematical problems in combinatorics. We compare models LLaMA-2,
LLaMA-3.1, GPT-4, and Mixtral against each other and against human pupils and
undergraduates with prior experience in mathematical olympiads. To facilitate
these comparisons we introduce the Combi-Puzzles dataset, which contains 125
problem variants based on 25 combinatorial reasoning problems. Each problem is
presented in one of five distinct forms, created by systematically manipulating
the problem statements through adversarial additions, numeric parameter
changes, and linguistic obfuscation. Our variations preserve the mathematical
core and are designed to measure the generalisability of LLM problem-solving
abilities, while also increasing confidence that problems are submitted to LLMs
in forms that have not been seen as training instances. We found that a model
based on GPT-4 outperformed all other models in producing correct responses,
and performed significantly better in the mathematical variation of the
problems than humans. We also found that modifications to problem statements
significantly impact the LLM's performance, while human performance remains
unaffected.

摘要：在本文中，我們探討了近期大型語言模型（LLM）在組合數學問題求解能力。我們比較 LLaMA-2、LLaMA-3.1、GPT-4 和 Mixtral 這幾個模型，並將它們與具有數學奧林匹克競賽經驗的人類學生和大學生進行比較。為了促進這些比較，我們引入了 Combi-Puzzles 資料集，其中包含 125 個基於 25 個組合推理問題的問題變體。每個問題都以五種不同的形式之一呈現，這些形式是透過系統性地透過對抗性添加、數字參數更改和語言混淆來處理問題陳述而建立的。我們的變體保留了數學核心，旨在衡量 LLM 問題解決能力的概括性，同時也增加了信心，即以訓練實例未曾見過的形式將問題提交給 LLM。我們發現基於 GPT-4 的模型在產生正確的回應方面優於所有其他模型，並且在問題的數學變體中表現明顯優於人類。我們還發現，對問題陳述的修改會顯著影響 LLM 的表現，而人類表現則不受影響。

##### **PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension**
2412.11906v1 by Kun Ouyang, Yuanxin Liu, Shicheng Li, Yi Liu, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun

Multimodal punchlines, which involve humor or sarcasm conveyed in
image-caption pairs, are a popular way of communication on online multimedia
platforms. With the rapid development of multimodal large language models
(MLLMs), it is essential to assess their ability to effectively comprehend
these punchlines. However, existing benchmarks on punchline comprehension
suffer from three major limitations: 1) language shortcuts that allow models to
solely rely on text, 2) lack of question diversity, and 3) narrow focus on a
specific domain of multimodal content (e.g., cartoon). To address these
limitations, we introduce a multimodal \textbf{Punch}line comprehension
\textbf{Bench}mark, named \textbf{PunchBench}, which is tailored for accurate
and comprehensive evaluation of punchline comprehension. To enhance the
evaluation accuracy, we generate synonymous and antonymous captions by
modifying original captions, which mitigates the impact of shortcuts in the
captions. To provide a comprehensive evaluation, PunchBench incorporates
diverse question formats and image-captions from various domains. On this
basis, we conduct extensive evaluations and reveal a significant gap between
state-of-the-art MLLMs and humans in punchline comprehension. To improve
punchline comprehension, we propose Simple-to-Complex Chain-of-Question
(SC-CoQ) strategy, enabling the models to incrementally address complicated
questions by first mastering simple ones. SC-CoQ effectively enhances the
performance of various MLLMs on PunchBench, surpassing in-context learning and
chain-of-thought.

摘要：多模态笑料，涉及图像与标题配对中传达的幽默或讽刺，是线上多媒体平台上流行的沟通方式。随着多模态大型语言模型（MLLM）的快速发展，评估其有效理解这些笑料的能力至关重要。然而，现有的笑料理解基准存在三个主要限制：1）语言捷径允许模型仅依赖文本，2）缺乏问题多样性，3）狭隘地专注于多模态内容的特定领域（例如卡通）。为了解决这些限制，我们引入了一个多模态**笑料**理解**基准**，名为**PunchBench**，它专为准确而全面地评估笑料理解而设计。为了提高评估准确性，我们通过修改原始标题生成同义和反义标题，从而减轻标题中捷径的影响。为了提供全面的评估，PunchBench 结合了来自不同领域的多样问题格式和图像标题。在此基础上，我们进行了广泛的评估，揭示了最先进的 MLLM 和人类在笑料理解方面的显着差距。为了提高笑料理解，我们提出了简单到复杂的问答链（SC-CoQ）策略，使模型能够通过首先掌握简单的问题来逐步解决复杂的问题。SC-CoQ 有效地提高了各种 MLLM 在 PunchBench 上的性能，超越了情境学习和思考链。

##### **Classification of Spontaneous and Scripted Speech for Multilingual Audio**
2412.11896v1 by Shahar Elisha, Andrew McDowell, Mariano Beguerisse-Díaz, Emmanouil Benetos

Distinguishing scripted from spontaneous speech is an essential tool for
better understanding how speech styles influence speech processing research. It
can also improve recommendation systems and discovery experiences for media
users through better segmentation of large recorded speech catalogues. This
paper addresses the challenge of building a classifier that generalises well
across different formats and languages. We systematically evaluate models
ranging from traditional, handcrafted acoustic and prosodic features to
advanced audio transformers, utilising a large, multilingual proprietary
podcast dataset for training and validation. We break down the performance of
each model across 11 language groups to evaluate cross-lingual biases. Our
experimental analysis extends to publicly available datasets to assess the
models' generalisability to non-podcast domains. Our results indicate that
transformer-based models consistently outperform traditional feature-based
techniques, achieving state-of-the-art performance in distinguishing between
scripted and spontaneous speech across various languages.

摘要：區分腳本化與自發性演說，是更深入了解演說風格如何影響演說處理研究的重要工具。它還可以透過更佳地分割大型錄製演說目錄，來改善媒體使用者的推薦系統和探索體驗。本文探討了建立一個分類器所面臨的挑戰，該分類器在不同的格式和語言中都能很好地概括。我們系統性地評估了從傳統手動聲學和韻律特徵到先進音訊Transformer的模型，並利用一個大型多語言專有播客資料集進行訓練和驗證。我們分析了每個模型在 11 個語言群組中的表現，以評估跨語言偏見。我們的實驗分析延伸到公開可用的資料集，以評估模型對非播客領域的概括能力。我們的結果表明，基於Transformer的模型始終優於傳統基於特徵的技術，在區分各種語言中的腳本化和自發性演說方面達到了最先進的效能。

##### **GNN Applied to Ego-nets for Friend Suggestions**
2412.11888v1 by Evgeny Zamyatin

A major problem of making friend suggestions in social networks is the large
size of social graphs, which can have hundreds of millions of people and tens
of billions of connections. Classic methods based on heuristics or
factorizations are often used to address the difficulties of scaling more
complex models. However, the unsupervised nature of these methods can lead to
suboptimal results. In this work, we introduce the Generalized Ego-network
Friendship Score framework, which makes it possible to use complex supervised
models without sacrificing scalability. The main principle of the framework is
to reduce the problem of link prediction on a full graph to a series of
low-scale tasks on ego-nets with subsequent aggregation of their results. Here,
the underlying model takes an ego-net as input and produces a pairwise
relevance matrix for its nodes. In addition, we develop the WalkGNN model which
is capable of working effectively in the social network domain, where these
graph-level link prediction tasks are heterogeneous, dynamic and featureless.
To measure the accuracy of this model, we introduce the Ego-VK dataset that
serves as an exact representation of the real-world problem that we are
addressing. Offline experiments on the dataset show that our model outperforms
all baseline methods, and a live A/B test demonstrates the growth of business
metrics as a result of utilizing our approach.

摘要：社群網站中提出好友建議的主要問題在於社群圖形龐大，可能包含數億人與數十億個連結。基於啟發法或因式分解的傳統方法通常用於解決擴充較複雜模型的困難之處。然而，這些方法的非監督性質可能會導致次佳結果。在這項工作中，我們引入了廣義自我網路友誼評分架構，讓使用複雜的監督模型成為可能，而不犧牲擴充性。此架構的主要原則是將完整圖形上的連結預測問題簡化為一系列自我網路的低規模任務，並隨後彙總其結果。在此，基礎模型將自我網路作為輸入，並針對其節點產生成對相關性矩陣。此外，我們開發了 WalkGNN 模型，此模型能夠在社群網路領域中有效運作，其中這些圖形層級連結預測任務是異質、動態且無特徵的。為了衡量此模型的準確性，我們引入了 Ego-VK 資料集，此資料集作為我們所要解決的真實世界問題的精確表示。針對此資料集進行的離線實驗顯示，我們的模型優於所有基線方法，而實況 A/B 測試則證明了利用我們方法所帶來的業務指標成長。

##### **Using Instruction-Tuned Large Language Models to Identify Indicators of Vulnerability in Police Incident Narratives**
2412.11878v1 by Sam Relins, Daniel Birks, Charlie Lloyd

Objectives: Compare qualitative coding of instruction tuned large language
models (IT-LLMs) against human coders in classifying the presence or absence of
vulnerability in routinely collected unstructured text that describes
police-public interactions. Evaluate potential bias in IT-LLM codings. Methods:
Analyzing publicly available text narratives of police-public interactions
recorded by Boston Police Department, we provide humans and IT-LLMs with
qualitative labelling codebooks and compare labels generated by both, seeking
to identify situations associated with (i) mental ill health; (ii) substance
misuse; (iii) alcohol dependence; and (iv) homelessness. We explore multiple
prompting strategies and model sizes, and the variability of labels generated
by repeated prompts. Additionally, to explore model bias, we utilize
counterfactual methods to assess the impact of two protected characteristics -
race and gender - on IT-LLM classification. Results: Results demonstrate that
IT-LLMs can effectively support human qualitative coding of police incident
narratives. While there is some disagreement between LLM and human generated
labels, IT-LLMs are highly effective at screening narratives where no
vulnerabilities are present, potentially vastly reducing the requirement for
human coding. Counterfactual analyses demonstrate that manipulations to both
gender and race of individuals described in narratives have very limited
effects on IT-LLM classifications beyond those expected by chance. Conclusions:
IT-LLMs offer effective means to augment human qualitative coding in a way that
requires much lower levels of resource to analyze large unstructured datasets.
Moreover, they encourage specificity in qualitative coding, promote
transparency, and provide the opportunity for more standardized, replicable
approaches to analyzing large free-text police data sources.

摘要：<paragraph>目標：比較針對人類編碼器，對大型語言模型 (IT-LLM) 的指令調整定性編碼，以分類在常規收集的非結構化文本中描述的警民互動中是否存在漏洞。評估 IT-LLM 編碼中的潛在偏差。方法：分析波士頓警察局記錄的警民互動的公開文本敘述，我們為人類和 IT-LLM 提供定性標籤編碼手冊，並比較兩者產生的標籤，試圖找出與 (i) 心理疾病；(ii) 物質濫用；(iii) 酒精依賴；和 (iv) 無家可歸相關的情況。我們探索多種提示策略和模型大小，以及重複提示產生的標籤的可變性。此外，為了探索模型偏差，我們利用反事實方法來評估兩個受保護特徵（種族和性別）對 IT-LLM 分類的影響。結果：結果表明，IT-LLM 可以有效支持人類對警察事件敘述的定性編碼。雖然 LLM 和人類產生的標籤之間存在一些分歧，但 IT-LLM 在篩選不存在漏洞的敘述方面非常有效，這可能會大大減少對人類編碼的要求。反事實分析表明，對敘述中描述的個體的性別和種族的操縱對 IT-LLM 分類的影響非常有限，超出預期。結論：IT-LLM 提供了有效的方法來擴充人類定性編碼，這種方法需要更低級別的資源來分析大型非結構化數據集。此外，它們鼓勵在定性編碼中具體化，促進透明度，並為分析大型自由文本警察數據源提供了更標準化、可複製的方法。</paragraph>

##### **A Variable Occurrence-Centric Framework for Inconsistency Handling (Extended Version)**
2412.11868v1 by Yakoub Salhi

In this paper, we introduce a syntactic framework for analyzing and handling
inconsistencies in propositional bases. Our approach focuses on examining the
relationships between variable occurrences within conflicts. We propose two
dual concepts: Minimal Inconsistency Relation (MIR) and Maximal Consistency
Relation (MCR). Each MIR is a minimal equivalence relation on variable
occurrences that results in inconsistency, while each MCR is a maximal
equivalence relation designed to prevent inconsistency. Notably, MIRs capture
conflicts overlooked by minimal inconsistent subsets. Using MCRs, we develop a
series of non-explosive inference relations. The main strategy involves
restoring consistency by modifying the propositional base according to each
MCR, followed by employing the classical inference relation to derive
conclusions. Additionally, we propose an unusual semantics that assigns truth
values to variable occurrences instead of the variables themselves. The
associated inference relations are established through Boolean interpretations
compatible with the occurrence-based models.

摘要：在本文中，我們介紹了一個語法框架，用於分析和處理命題基礎中的不一致性。我們的做法專注於檢查衝突中變量出現之間的關係。我們提出了兩個對偶概念：最小不一致關係 (MIR) 和最大一致關係 (MCR)。每個 MIR 都是變量出現上的最小等價關係，導致不一致，而每個 MCR 都是旨在防止不一致的最大等價關係。值得注意的是，MIR 捕捉了最小不一致子集所忽視的衝突。使用 MCR，我們開發了一系列非爆炸性推理關係。主要策略涉及根據每個 MCR 修改命題基礎來恢復一致性，然後使用經典推理關係來推導結論。此外，我們提出了一個不尋常的語義，它將真值賦予變量出現，而不是變量本身。相關的推理關係是通過與基於出現的模型相容的布林解釋建立的。

##### **Transformers Use Causal World Models in Maze-Solving Tasks**
2412.11867v1 by Alex F. Spies, William Edwards, Michael I. Ivanitskiy, Adrians Skapars, Tilman Räuker, Katsumi Inoue, Alessandra Russo, Murray Shanahan

Recent studies in interpretability have explored the inner workings of
transformer models trained on tasks across various domains, often discovering
that these networks naturally develop surprisingly structured representations.
When such representations comprehensively reflect the task domain's structure,
they are commonly referred to as ``World Models'' (WMs). In this work, we
discover such WMs in transformers trained on maze tasks. In particular, by
employing Sparse Autoencoders (SAEs) and analysing attention patterns, we
examine the construction of WMs and demonstrate consistency between the circuit
analysis and the SAE feature-based analysis. We intervene upon the isolated
features to confirm their causal role and, in doing so, find asymmetries
between certain types of interventions. Surprisingly, we find that models are
able to reason with respect to a greater number of active features than they
see during training, even if attempting to specify these in the input token
sequence would lead the model to fail. Futhermore, we observe that varying
positional encodings can alter how WMs are encoded in a model's residual
stream. By analyzing the causal role of these WMs in a toy domain we hope to
make progress toward an understanding of emergent structure in the
representations acquired by Transformers, leading to the development of more
interpretable and controllable AI systems.

摘要：最近在可解释性方面的研究探索了在跨各种领域的任務上訓練的Transformer模型的內部運作，經常發現這些網路自然會發展出令人驚訝的結構化表示形式。當這些表示形式全面反映任務領域的結構時，它們通常稱為「世界模型」(WM)。在這項工作中，我們在訓練於迷宮任務上的Transformer中發現了這些 WM。特別是，透過採用稀疏自動編碼器 (SAE) 和分析注意力模式，我們檢查了 WM 的建構，並證明了電路分析和基於 SAE 特徵的分析之間的一致性。我們對孤立的特徵進行干預以確認它們的因果關係，並在這樣做的過程中，發現了特定類型干預之間的不對稱性。令人驚訝的是，我們發現模型能夠推論比它們在訓練期間看到的更多數量的活動特徵，即使嘗試在輸入令牌序列中指定這些特徵也會導致模型失敗。此外，我們觀察到不同的位置編碼可以改變 WM 在模型的殘差串流中編碼的方式。透過分析這些 WM 在玩具領域中的因果關係，我們希望在理解Transformer獲得的表示形式中出現的結構方面取得進展，從而開發出更具可解釋性和可控性的 AI 系統。

##### **Investigating Mixture of Experts in Dense Retrieval**
2412.11864v1 by Effrosyni Sokli, Pranav Kasela, Georgios Peikos, Gabriella Pasi

While Dense Retrieval Models (DRMs) have advanced Information Retrieval (IR),
one limitation of these neural models is their narrow generalizability and
robustness. To cope with this issue, one can leverage the Mixture-of-Experts
(MoE) architecture. While previous IR studies have incorporated MoE
architectures within the Transformer layers of DRMs, our work investigates an
architecture that integrates a single MoE block (SB-MoE) after the output of
the final Transformer layer. Our empirical evaluation investigates how SB-MoE
compares, in terms of retrieval effectiveness, to standard fine-tuning. In
detail, we fine-tune three DRMs (TinyBERT, BERT, and Contriever) across four
benchmark collections with and without adding the MoE block. Moreover, since
MoE showcases performance variations with respect to its parameters (i.e., the
number of experts), we conduct additional experiments to investigate this
aspect further. The findings show the effectiveness of SB-MoE especially for
DRMs with a low number of parameters (i.e., TinyBERT), as it consistently
outperforms the fine-tuned underlying model on all four benchmarks. For DRMs
with a higher number of parameters (i.e., BERT and Contriever), SB-MoE requires
larger numbers of training samples to yield better retrieval performance.

摘要：在稠密检索模型 (DRM) 提升了信息检索 (IR) 的同时，这些神经模型的一个局限性在于它们较窄的泛化性和稳健性。为了应对这个问题，人们可以利用混合专家 (MoE) 架构。虽然之前的 IR 研究已经将 MoE 架构纳入了 DRM 的 Transformer 层，但我们的工作研究了一种在最终 Transformer 层的输出之后集成单个 MoE 块 (SB-MoE) 的架构。我们的经验评估研究了 SB-MoE 在检索有效性方面如何与标准微调进行比较。具体来说，我们在四个基准集合中对三个 DRM（TinyBERT、BERT 和 Contriever）进行了微调，分别有和没有添加 MoE 块。此外，由于 MoE 在其参数（即专家数量）方面表现出性能差异，我们进行了额外的实验以进一步研究这个方面。结果表明 SB-MoE 特别适用于具有较少参数的 DRM（即 TinyBERT），因为它在所有四个基准上都持续优于微调后的底层模型。对于具有更多参数的 DRM（即 BERT 和 Contriever），SB-MoE 需要更多的训练样本才能产生更好的检索性能。

##### **GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training**
2412.11863v1 by Renqiu Xia, Mingsheng Li, Hancheng Ye, Wenjie Wu, Hongbin Zhou, Jiakang Yuan, Tianshuo Peng, Xinyu Cai, Xiangchao Yan, Bin Wang, Conghui He, Botian Shi, Tao Chen, Junchi Yan, Bo Zhang

Despite their proficiency in general tasks, Multi-modal Large Language Models
(MLLMs) struggle with automatic Geometry Problem Solving (GPS), which demands
understanding diagrams, interpreting symbols, and performing complex reasoning.
This limitation arises from their pre-training on natural images and texts,
along with the lack of automated verification in the problem-solving process.
Besides, current geometric specialists are limited by their task-specific
designs, making them less effective for broader geometric problems. To this
end, we present GeoX, a multi-modal large model focusing on geometric
understanding and reasoning tasks. Given the significant differences between
geometric diagram-symbol and natural image-text, we introduce unimodal
pre-training to develop a diagram encoder and symbol decoder, enhancing the
understanding of geometric images and corpora. Furthermore, we introduce
geometry-language alignment, an effective pre-training paradigm that bridges
the modality gap between unimodal geometric experts. We propose a
Generator-And-Sampler Transformer (GS-Former) to generate discriminative
queries and eliminate uninformative representations from unevenly distributed
geometric signals. Finally, GeoX benefits from visual instruction tuning,
empowering it to take geometric images and questions as input and generate
verifiable solutions. Experiments show that GeoX outperforms both generalists
and geometric specialists on publicly recognized benchmarks, such as GeoQA,
UniGeo, Geometry3K, and PGPS9k.

摘要：儘管多模態大型語言模型 (MLLM) 在一般任務中表現出色，但它們在自動幾何問題求解 (GPS) 方面仍有困難，這需要理解圖表、解釋符號和進行複雜推理。這種限制來自於它們在自然影像和文字上的預訓練，以及在問題求解過程中缺乏自動驗證。此外，目前的幾何專家受到其特定任務設計的限制，這使得它們對於更廣泛的幾何問題效果不佳。為了解決這個問題，我們提出了 GeoX，這是一個專注於幾何理解和推理任務的多模態大型模型。鑑於幾何圖表符號與自然影像文字之間的顯著差異，我們引入了單模態預訓練來開發圖表編碼器和符號解碼器，增強對幾何影像和語料的理解。此外，我們引入了幾何語言對齊，這是一種有效的預訓練範例，可以彌合單模態幾何專家之間的模態差距。我們提出了一個生成器和採樣器Transformer (GS-Former) 來產生區分性的查詢，並從分佈不均的幾何訊號中消除無資訊的表示。最後，GeoX 受益於視覺指令調整，使其能夠將幾何影像和問題作為輸入，並產生可驗證的解決方案。實驗表明，GeoX 在公認的基準上優於通才和幾何專家，例如 GeoQA、UniGeo、Geometry3K 和 PGPS9k。

##### **A Theory of Formalisms for Representing Knowledge**
2412.11855v1 by Heng Zhang, Donghui Quan

There has been a longstanding dispute over which formalism is the best for
representing knowledge in AI. The well-known "declarative vs. procedural
controversy" is concerned with the choice of utilizing declarations or
procedures as the primary mode of knowledge representation. The ongoing debate
between symbolic AI and connectionist AI also revolves around the question of
whether knowledge should be represented implicitly (e.g., as parametric
knowledge in deep learning and large language models) or explicitly (e.g., as
logical theories in traditional knowledge representation and reasoning). To
address these issues, we propose a general framework to capture various
knowledge representation formalisms in which we are interested. Within the
framework, we find a family of universal knowledge representation formalisms,
and prove that all universal formalisms are recursively isomorphic. Moreover,
we show that all pairwise intertranslatable formalisms that admit the padding
property are also recursively isomorphic. These imply that, up to an offline
compilation, all universal (or natural and equally expressive) representation
formalisms are in fact the same, which thus provides a partial answer to the
aforementioned dispute.

摘要：對於哪種形式主義最適合在人工智慧中表示知識，一直存在著長期的爭議。著名的「宣告式 vs. 程序式爭議」關注於選擇將宣告或程序作為知識表示的主要模式。符號式人工智慧與連接式人工智慧之間持續的辯論也圍繞著知識是否應該以內隱的方式（例如，作為深度學習和大語言模型中的參數知識）或以顯式的方式（例如，作為傳統知識表示和推理中的邏輯理論）來表示。為了解決這些問題，我們提出了一個通用的框架來捕捉我們感興趣的各種知識表示形式主義。在這個框架內，我們找到了一個通用的知識表示形式主義家族，並證明所有通用的形式主義都是遞迴同構的。此外，我們表明所有成對可互譯的形式主義（允許填充屬性）也是遞迴同構的。這些暗示著，在離線編譯中，所有通用的（或自然且表達力相等的）表示形式主義實際上是相同的，這因此為上述爭議提供了部分答案。

##### **A Benchmark and Robustness Study of In-Context-Learning with Large Language Models in Music Entity Detection**
2412.11851v1 by Simon Hachmeier, Robert Jäschke

Detecting music entities such as song titles or artist names is a useful
application to help use cases like processing music search queries or analyzing
music consumption on the web. Recent approaches incorporate smaller language
models (SLMs) like BERT and achieve high results. However, further research
indicates a high influence of entity exposure during pre-training on the
performance of the models. With the advent of large language models (LLMs),
these outperform SLMs in a variety of downstream tasks. However, researchers
are still divided if this is applicable to tasks like entity detection in texts
due to issues like hallucination. In this paper, we provide a novel dataset of
user-generated metadata and conduct a benchmark and a robustness study using
recent LLMs with in-context-learning (ICL). Our results indicate that LLMs in
the ICL setting yield higher performance than SLMs. We further uncover the
large impact of entity exposure on the best performing LLM in our study.

摘要：偵測音樂實體（例如歌曲標題或藝術家名稱）是一項有用的應用，有助於處理音樂搜尋查詢或分析網路上的音樂消費等使用案例。最近的方法結合了較小的語言模型（SLM），例如 BERT，並取得了很高的結果。然而，進一步的研究指出，實體曝光在模型的預訓練期間對其效能有很大的影響。隨著大型語言模型（LLM）的出現，它們在各種下游任務中都優於 SLM。然而，研究人員對於這是否適用於文字中的實體偵測等任務仍有分歧，因為存在幻覺等問題。在本文中，我們提供了一個由使用者產生的元資料的新穎資料集，並使用最近的 LLM 與情境中學習（ICL）進行基準測試和穩健性研究。我們的結果表明，ICL 設定中的 LLM 比 SLM 產生更高的效能。我們進一步揭示了實體曝光對我們研究中效能最佳的 LLM 的重大影響。

##### **Improved Models for Media Bias Detection and Subcategorization**
2412.11835v1 by Tim Menzner, Jochen L. Leidner

We present improved models for the granular detection and sub-classification
news media bias in English news articles. We compare the performance of
zero-shot versus fine-tuned large pre-trained neural transformer language
models, explore how the level of detail of the classes affects performance on a
novel taxonomy of 27 news bias-types, and demonstrate how using synthetically
generated example data can be used to improve quality

摘要：我們提出改進的模型，用於精細地偵測和分類英文新聞文章中的新聞媒體偏見。我們比較了零次學習與微調過的預訓練大型神經轉換器語言模型的效能，探討類別的詳細程度如何影響 27 種新聞偏見類型的新分類法上的效能，並展示如何使用合成產生的範例資料來提升品質

##### **Wonderful Matrices: Combining for a More Efficient and Effective Foundation Model Architecture**
2412.11834v1 by Jingze Shi, Bingheng Wu

In order to make the foundation model more efficient and effective, our idea
is combining sequence transformation and state transformation. First, we prove
the availability of rotary position embedding in the state space duality
algorithm, which reduces the perplexity of the hybrid quadratic causal
self-attention and state space duality by more than 4%, to ensure that the
combining sequence transformation unifies position encoding. Second, we propose
dynamic mask attention, which maintains 100% accuracy in the more challenging
multi-query associative recall task, improving by more than 150% compared to
quadratic causal self-attention and state space duality, to ensure that the
combining sequence transformation selectively filters relevant information.
Third, we design cross domain mixture of experts, which makes the computational
speed of expert retrieval with more than 1024 experts 8 to 10 times faster than
the mixture of experts, to ensure that the combining state transformation
quickly retrieval mixture. Finally, we summarize these matrix algorithms that
can form the foundation model: Wonderful Matrices, which can be a competitor to
popular model architectures.

摘要：为了让基础模型更加高效且有效，我们的想法是将序列转换和状态转换结合起来。首先，我们在状态空间对偶算法中证明旋转位置嵌入的可用性，这将混合二次因果自注意力和状态空间对偶的困惑度降低了 4% 以上，以确保组合序列转换统一位置编码。其次，我们提出动态掩码注意力，这在更具挑战性的多查询关联召回任务中保持了 100% 的准确度，与二次因果自注意力和状态空间对偶相比，提高了 150% 以上，以确保组合序列转换有选择地过滤相关信息。第三，我们设计了跨域专家混合，这使得专家检索的计算速度比专家混合快了 8 到 10 倍，专家数量超过 1024 个，以确保组合状态转换快速检索混合。最后，我们总结了这些可以形成基础模型的矩阵算法：Wonderful Matrices，它可以成为流行模型架构的竞争对手。

##### **Are You Doubtful? Oh, It Might Be Difficult Then! Exploring the Use of Model Uncertainty for Question Difficulty Estimation**
2412.11831v1 by Leonidas Zotos, Hedderik van Rijn, Malvina Nissim

In an educational setting, an estimate of the difficulty of multiple-choice
questions (MCQs), a commonly used strategy to assess learning progress,
constitutes very useful information for both teachers and students. Since human
assessment is costly from multiple points of view, automatic approaches to MCQ
item difficulty estimation are investigated, yielding however mixed success
until now. Our approach to this problem takes a different angle from previous
work: asking various Large Language Models to tackle the questions included in
two different MCQ datasets, we leverage model uncertainty to estimate item
difficulty. By using both model uncertainty features as well as textual
features in a Random Forest regressor, we show that uncertainty features
contribute substantially to difficulty prediction, where difficulty is
inversely proportional to the number of students who can correctly answer a
question. In addition to showing the value of our approach, we also observe
that our model achieves state-of-the-art results on the BEA publicly available
dataset.

摘要：在教育環境中，多選題 (MCQ) 的難度評估，是一種普遍用於評量學習進度的策略，對老師和學生而言都是非常有用的資訊。由於人工評量在多方面都具有成本，因此對於 MCQ 題目難度評估的自動化方法進行了調查，然而到目前為止收效不一。我們對此問題採取的方法與以往的研究有不同的角度：要求各種大型語言模型來處理包含在兩個不同 MCQ 資料集中的題目，我們利用模型的不確定性來評估題目難度。透過在隨機森林回歸器中同時使用模型不確定性特徵和文字特徵，我們證明了不確定性特徵對難度預測有很大的貢獻，其中難度與能正確回答問題的學生人數成反比。除了顯示我們方法的價值外，我們還觀察到我們的模型在 BEA 公開資料集上取得了最先進的成果。

##### **Advancements and Challenges in Bangla Question Answering Models: A Comprehensive Review**
2412.11823v1 by Md Iftekhar Islam Tashik, Abdullah Khondoker, Enam Ahmed Taufik, Antara Firoz Parsa, S M Ishtiak Mahmud

The domain of Natural Language Processing (NLP) has experienced notable
progress in the evolution of Bangla Question Answering (QA) systems. This paper
presents a comprehensive review of seven research articles that contribute to
the progress in this domain. These research studies explore different aspects
of creating question-answering systems for the Bangla language. They cover
areas like collecting data, preparing it for analysis, designing models,
conducting experiments, and interpreting results. The papers introduce
innovative methods like using LSTM-based models with attention mechanisms,
context-based QA systems, and deep learning techniques based on prior
knowledge. However, despite the progress made, several challenges remain,
including the lack of well-annotated data, the absence of high-quality reading
comprehension datasets, and difficulties in understanding the meaning of words
in context. Bangla QA models' precision and applicability are constrained by
these challenges. This review emphasizes the significance of these research
contributions by highlighting the developments achieved in creating Bangla QA
systems as well as the ongoing effort required to get past roadblocks and
improve the performance of these systems for actual language comprehension
tasks.

摘要：自然語言處理 (NLP) 領域在孟加拉問答 (QA) 系統的演進中取得顯著進展。本文全面回顧了七篇有助於此領域進展的研究文章。這些研究探討了為孟加拉語建立問答系統的不同面向。它們涵蓋了收集資料、為分析準備資料、設計模型、進行實驗和詮釋結果等領域。這些論文引入了創新的方法，例如使用具注意力機制的 LSTM 模型、基於背景的 QA 系統，以及基於先驗知識的深度學習技術。然而，儘管取得了進展，但仍有許多挑戰，包括缺乏標註良好的資料、缺乏高品質的閱讀理解資料集，以及難以理解文中詞彙的含義。孟加拉 QA 模型的精確度和適用性受到這些挑戰的限制。本回顧強調了這些研究貢獻的重要性，重點介紹了在建立孟加拉 QA 系統方面取得的進展，以及克服障礙和提升這些系統在實際語言理解任務中的效能所需的持續努力。

##### **EventSum: A Large-Scale Event-Centric Summarization Dataset for Chinese Multi-News Documents**
2412.11814v1 by Mengna Zhu, Kaisheng Zeng, Mao Wang, Kaiming Xiao, Lei Hou, Hongbin Huang, Juanzi Li

In real life, many dynamic events, such as major disasters and large-scale
sports events, evolve continuously over time. Obtaining an overview of these
events can help people quickly understand the situation and respond more
effectively. This is challenging because the key information of the event is
often scattered across multiple documents, involving complex event knowledge
understanding and reasoning, which is under-explored in previous work.
Therefore, we proposed the Event-Centric Multi-Document Summarization (ECS)
task, which aims to generate concise and comprehensive summaries of a given
event based on multiple related news documents. Based on this, we constructed
the EventSum dataset, which was constructed using Baidu Baike entries and
underwent extensive human annotation, to facilitate relevant research. It is
the first large scale Chinese multi-document summarization dataset, containing
5,100 events and a total of 57,984 news documents, with an average of 11.4
input news documents and 13,471 characters per event. To ensure data quality
and mitigate potential data leakage, we adopted a multi-stage annotation
approach for manually labeling the test set. Given the complexity of
event-related information, existing metrics struggle to comprehensively assess
the quality of generated summaries. We designed specific metrics including
Event Recall, Argument Recall, Causal Recall, and Temporal Recall along with
corresponding calculation methods for evaluation. We conducted comprehensive
experiments on EventSum to evaluate the performance of advanced long-context
Large Language Models (LLMs) on this task. Our experimental results indicate
that: 1) The event-centric multi-document summarization task remains
challenging for existing long-context LLMs; 2) The recall metrics we designed
are crucial for evaluating the comprehensiveness of the summary information.

摘要：在现实生活中，许多动态事件（例如重大灾难和大型体育赛事）会随着时间的推移而不断发展。获取这些事件的概述可以帮助人们快速了解情况并更有效地做出反应。这是一个挑战，因为事件的关键信息通常分散在多个文档中，涉及复杂的事件知识理解和推理，而这在以前的工作中并未得到充分探索。因此，我们提出了以事件为中心的多分档摘要 (ECS) 任务，其目标是根据多个相关的新闻文档生成给定事件的简洁且全面的摘要。基于此，我们构建了 EventSum 数据集，该数据集使用百度百科条目构建，并经过广泛的人工注释，以促进相关研究。它是第一个大规模的中文多分档摘要数据集，包含 5,100 个事件和总共 57,984 篇新闻文档，平均每个事件有 11.4 篇输入新闻文档和 13,471 个字符。为了确保数据质量并减轻潜在的数据泄露，我们采用多阶段注释方法来手动标记测试集。鉴于与事件相关的信息的复杂性，现有的指标难以全面评估生成摘要的质量。我们设计了包括事件召回、论点召回、因果召回和时间召回在内的特定指标以及相应的计算方法进行评估。我们对 EventSum 进行了全面的实验，以评估高级长上下文大语言模型 (LLM) 在此任务上的性能。我们的实验结果表明：1）以事件为中心的多分档摘要任务对于现有的长上下文 LLM 仍然具有挑战性；2）我们设计的召回指标对于评估摘要信息的全面性至关重要。

##### **PhysAug: A Physical-guided and Frequency-based Data Augmentation for Single-Domain Generalized Object Detection**
2412.11807v1 by Xiaoran Xu, Jiangang Yang, Wenhui Shi, Siyuan Ding, Luqing Luo, Jian Liu

Single-Domain Generalized Object Detection~(S-DGOD) aims to train on a single
source domain for robust performance across a variety of unseen target domains
by taking advantage of an object detector. Existing S-DGOD approaches often
rely on data augmentation strategies, including a composition of visual
transformations, to enhance the detector's generalization ability. However, the
absence of real-world prior knowledge hinders data augmentation from
contributing to the diversity of training data distributions. To address this
issue, we propose PhysAug, a novel physical model-based non-ideal imaging
condition data augmentation method, to enhance the adaptability of the S-DGOD
tasks. Drawing upon the principles of atmospheric optics, we develop a
universal perturbation model that serves as the foundation for our proposed
PhysAug. Given that visual perturbations typically arise from the interaction
of light with atmospheric particles, the image frequency spectrum is harnessed
to simulate real-world variations during training. This approach fosters the
detector to learn domain-invariant representations, thereby enhancing its
ability to generalize across various settings. Without altering the network
architecture or loss function, our approach significantly outperforms the
state-of-the-art across various S-DGOD datasets. In particular, it achieves a
substantial improvement of $7.3\%$ and $7.2\%$ over the baseline on DWD and
Cityscape-C, highlighting its enhanced generalizability in real-world settings.

摘要：單一網域泛用物件偵測 (S-DGOD) 旨在利用物件偵測器，在單一來源網域上進行訓練，以在各種未見目標網域中獲得穩健的效能。現有的 S-DGOD 方法通常仰賴資料擴充策略，包括視覺轉換組合，以增強偵測器的泛化能力。然而，缺乏真實世界的先驗知識，阻礙了資料擴充對訓練資料分佈的多樣性做出貢獻。為了解決這個問題，我們提出 PhysAug，這是一種新穎的基於物理模型的非理想影像條件資料擴充方法，以增強 S-DGOD 任務的適應性。我們利用大氣光學的原理，開發了一個通用擾動模型，作為我們提出的 PhysAug 的基礎。由於視覺擾動通常源於光線與大氣顆粒的交互作用，因此利用影像頻率譜在訓練期間模擬真實世界的變化。這種方法促進偵測器學習與網域無關的表示，從而增強其在各種設定中泛化的能力。在不改變網路架構或損失函數的情況下，我們的做法在各種 S-DGOD 資料集上都明顯優於最先進的技術。特別是，它在 DWD 和 Cityscape-C 上比基線分別提高了 7.3% 和 7.2%，突顯了它在真實世界設定中增強的泛化能力。

##### **UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models**
2412.11803v1 by Boyang Xue, Fei Mi, Qi Zhu, Hongru Wang, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam-Fai Wong

Despite demonstrating impressive capabilities, Large Language Models (LLMs)
still often struggle to accurately express the factual knowledge they possess,
especially in cases where the LLMs' knowledge boundaries are ambiguous. To
improve LLMs' factual expressions, we propose the UAlign framework, which
leverages Uncertainty estimations to represent knowledge boundaries, and then
explicitly incorporates these representations as input features into prompts
for LLMs to Align with factual knowledge. First, we prepare the dataset on
knowledge question-answering (QA) samples by calculating two uncertainty
estimations, including confidence score and semantic entropy, to represent the
knowledge boundaries for LLMs. Subsequently, using the prepared dataset, we
train a reward model that incorporates uncertainty estimations and then employ
the Proximal Policy Optimization (PPO) algorithm for factuality alignment on
LLMs. Experimental results indicate that, by integrating uncertainty
representations in LLM alignment, the proposed UAlign can significantly enhance
the LLMs' capacities to confidently answer known questions and refuse unknown
questions on both in-domain and out-of-domain tasks, showing reliability
improvements and good generalizability over various prompt- and training-based
baselines.

摘要：儘管展示了令人印象深刻的能力，大型語言模型（LLM）
仍然常常難以準確表達他們所擁有的事實知識，
特別是在 LLM 的知識界線模糊的情況下。為了
改善 LLM 的事實表達，我們提出了 UAlign 框架，它
利用不確定性估計來表示知識界線，然後
明確定義這些表示，作為輸入特徵，提示 LLM 與事實知識對齊。首先，我們準備知識問答（QA）範例的資料集，藉由計算兩個不確定性估計，包括信心分數和語義熵，來表示 LLM 的知識界線。隨後，使用準備好的資料集，我們訓練一個結合不確定性估計的獎勵模型，然後使用近端策略最佳化（PPO）演算法在 LLM 上進行事實對齊。實驗結果表明，藉由整合 LLM 對齊中的不確定性表示，所提出的 UAlign 可以顯著增強 LLM 在已知問題上自信回答和拒絕未知問題的能力，無論是在網域內還是網域外任務，在各種提示和基於訓練的基準上顯示出可靠性的改進和良好的泛化性。

##### **AMI-Net: Adaptive Mask Inpainting Network for Industrial Anomaly Detection and Localization**
2412.11802v1 by Wei Luo, Haiming Yao, Wenyong Yu, Zhengyong Li

Unsupervised visual anomaly detection is crucial for enhancing industrial
production quality and efficiency. Among unsupervised methods, reconstruction
approaches are popular due to their simplicity and effectiveness. The key
aspect of reconstruction methods lies in the restoration of anomalous regions,
which current methods have not satisfactorily achieved. To tackle this issue,
we introduce a novel \uline{A}daptive \uline{M}ask \uline{I}npainting
\uline{Net}work (AMI-Net) from the perspective of adaptive mask-inpainting. In
contrast to traditional reconstruction methods that treat non-semantic image
pixels as targets, our method uses a pre-trained network to extract multi-scale
semantic features as reconstruction targets. Given the multiscale nature of
industrial defects, we incorporate a training strategy involving random
positional and quantitative masking. Moreover, we propose an innovative
adaptive mask generator capable of generating adaptive masks that effectively
mask anomalous regions while preserving normal regions. In this manner, the
model can leverage the visible normal global contextual information to restore
the masked anomalous regions, thereby effectively suppressing the
reconstruction of defects. Extensive experimental results on the MVTec AD and
BTAD industrial datasets validate the effectiveness of the proposed method.
Additionally, AMI-Net exhibits exceptional real-time performance, striking a
favorable balance between detection accuracy and speed, rendering it highly
suitable for industrial applications. Code is available at:
https://github.com/luow23/AMI-Net

摘要：無監督視覺異常偵測對於提升產業生產品質與效率至關重要。在無監督方法中，重建方法因其簡潔性與有效性而廣受歡迎。重建方法的關鍵在於異常區域的修復，而現有方法尚未令人滿意地達成此目標。為了解決此問題，我們從自適應遮罩修復的角度，提出了一種新穎的\uline{A}daptive \uline{M}ask \uline{I}npainting \uline{Net}work（AMI-Net）。與將非語意影像像素視為目標的傳統重建方法不同，我們的方法使用預先訓練的網路，以提取多尺度語意特徵作為重建目標。考量到產業缺陷的多尺度特性，我們納入了一種包含隨機位置和量化遮罩的訓練策略。此外，我們提出了一個創新的自適應遮罩生成器，能夠產生自適應遮罩，有效遮蔽異常區域，同時保留正常區域。如此一來，模型便能利用可見的正常全局脈絡資訊來修復被遮蔽的異常區域，進而有效抑制缺陷的重建。在 MVTec AD 和 BTAD 產業資料集上進行的廣泛實驗結果，驗證了所提出方法的有效性。此外，AMI-Net 展現出卓越的即時效能，在偵測準確度和速度之間取得良好的平衡，使其非常適合產業應用。程式碼可於以下網址取得：
https://github.com/luow23/AMI-Net

##### **ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible Speech Synthesis**
2412.11795v1 by Xiangheng He, Junjie Chen, Zixing Zhang, Björn W. Schuller

Prosody contains rich information beyond the literal meaning of words, which
is crucial for the intelligibility of speech. Current models still fall short
in phrasing and intonation; they not only miss or misplace breaks when
synthesizing long sentences with complex structures but also produce unnatural
intonation. We propose ProsodyFM, a prosody-aware text-to-speech synthesis
(TTS) model with a flow-matching (FM) backbone that aims to enhance the
phrasing and intonation aspects of prosody. ProsodyFM introduces two key
components: a Phrase Break Encoder to capture initial phrase break locations,
followed by a Duration Predictor for the flexible adjustment of break
durations; and a Terminal Intonation Encoder which integrates a set of
intonation shape tokens combined with a novel Pitch Processor for more robust
modeling of human-perceived intonation change. ProsodyFM is trained with no
explicit prosodic labels and yet can uncover a broad spectrum of break
durations and intonation patterns. Experimental results demonstrate that
ProsodyFM can effectively improve the phrasing and intonation aspects of
prosody, thereby enhancing the overall intelligibility compared to four
state-of-the-art (SOTA) models. Out-of-distribution experiments show that this
prosody improvement can further bring ProsodyFM superior generalizability for
unseen complex sentences and speakers. Our case study intuitively illustrates
the powerful and fine-grained controllability of ProsodyFM over phrasing and
intonation.

摘要：韻律包含了超越字面意義的豐富資訊，這對於語音的可理解性至關重要。目前的模型在語句和語調方面仍有不足；它們在合成具有複雜結構的長句時，不僅會遺漏或錯置停頓，還會產生不自然的語調。我們提出 ProsodyFM，這是一個具備流匹配 (FM) 主幹的韻律感知文字轉語音合成 (TTS) 模型，旨在增強韻律的語句和語調方面。ProsodyFM 導入了兩個關鍵組成部分：一個語句斷句編碼器，用於擷取初始語句斷句位置，然後是一個持續時間預測器，用於靈活調整斷句持續時間；以及一個終端語調編碼器，它整合了一組語調形狀代碼，並結合了一個新的音高處理器，用於對人類感知的語調變化進行更強大的建模。ProsodyFM 在沒有明確韻律標籤的情況下進行訓練，但仍然可以發現廣泛的斷句持續時間和語調模式。實驗結果表明，與四個最先進 (SOTA) 模型相比，ProsodyFM 可以有效改善韻律的語句和語調方面，從而增強整體可理解性。分佈外實驗表明，這種韻律改進可以進一步為 ProsodyFM 帶來對未見的複雜句子和說話者的卓越泛化能力。我們的案例研究直觀地說明了 ProsodyFM 對語句和語調的強大且細緻的控制能力。

##### **Does it Chug? Towards a Data-Driven Understanding of Guitar Tone Description**
2412.11769v1 by Pratik Sutar, Jason Naradowsky, Yusuke Miyao

Natural language is commonly used to describe instrument timbre, such as a
"warm" or "heavy" sound. As these descriptors are based on human perception,
there can be disagreement over which acoustic features correspond to a given
adjective. In this work, we pursue a data-driven approach to further our
understanding of such adjectives in the context of guitar tone. Our main
contribution is a dataset of timbre adjectives, constructed by processing
single clips of instrument audio to produce varied timbres through adjustments
in EQ and effects such as distortion. Adjective annotations are obtained for
each clip by crowdsourcing experts to complete a pairwise comparison and a
labeling task. We examine the dataset and reveal correlations between adjective
ratings and highlight instances where the data contradicts prevailing theories
on spectral features and timbral adjectives, suggesting a need for a more
nuanced, data-driven understanding of timbre.

摘要：自然語言常被用來描述樂器音色，例如「溫暖」或「厚重」的聲音。由於這些描述詞是基於人類的感知，因此對於哪些聲學特徵對應到某個形容詞，可能會存在分歧。在這項工作中，我們採用資料驅動的方法，以進一步了解在吉他音色脈絡中此類形容詞的含義。我們的貢獻主要是音色形容詞的資料集，透過處理樂器音訊的單一片段來建構，並透過調整 EQ 和失真等效果來產生不同的音色。形容詞註解是透過群眾外包專家來完成成對比較和標籤任務，以取得每個片段的註解。我們檢視資料集並揭露形容詞評分之間的關聯性，並強調資料與關於頻譜特徵和音色形容詞的主流理論相矛盾的實例，這表明需要對音色有更細緻、更資料驅動的理解。

##### **No More Adam: Learning Rate Scaling at Initialization is All You Need**
2412.11768v1 by Minghao Xu, Lichuan Xiang, Xu Cai, Hongkai Wen

In this work, we question the necessity of adaptive gradient methods for
training deep neural networks. SGD-SaI is a simple yet effective enhancement to
stochastic gradient descent with momentum (SGDM). SGD-SaI performs learning
rate Scaling at Initialization (SaI) to distinct parameter groups, guided by
their respective gradient signal-to-noise ratios (g-SNR). By adjusting learning
rates without relying on adaptive second-order momentum, SGD-SaI helps prevent
training imbalances from the very first iteration and cuts the optimizer's
memory usage by half compared to AdamW. Despite its simplicity and efficiency,
SGD-SaI consistently matches or outperforms AdamW in training a variety of
Transformer-based tasks, effectively overcoming a long-standing challenge of
using SGD for training Transformers. SGD-SaI excels in ImageNet-1K
classification with Vision Transformers(ViT) and GPT-2 pretraining for large
language models (LLMs, transformer decoder-only), demonstrating robustness to
hyperparameter variations and practicality for diverse applications. We further
tested its robustness on tasks like LoRA fine-tuning for LLMs and diffusion
models, where it consistently outperforms state-of-the-art optimizers. From a
memory efficiency perspective, SGD-SaI achieves substantial memory savings for
optimizer states, reducing memory usage by 5.93 GB for GPT-2 (1.5B parameters)
and 25.15 GB for Llama2-7B compared to AdamW in full-precision training
settings.

摘要：<paragraph>在這項工作中，我們質疑自適應梯度方法訓練深度神經網路的必要性。SGD-SaI 是一種簡單但有效的增強，可以搭配帶動能的隨機梯度下降法 (SGDM) 使用。SGD-SaI 執行初始化時學習率縮放 (SaI) 至不同的參數群組，並由它們各自的梯度信噪比 (g-SNR) 引導。透過調整學習率，而不依賴自適應二階動能，SGD-SaI 有助於從第一個反覆運算開始防止訓練不平衡，並將最佳化器的記憶體使用量減半，與 AdamW 相比。儘管 SGD-SaI 既簡單又有效率，但在訓練各種基於 Transformer 的任務時，它始終能與 AdamW 相匹配，甚至表現得更好，有效克服了使用 SGD 訓練 Transformer 的長期挑戰。SGD-SaI 在使用視覺 Transformer (ViT) 進行 ImageNet-1K 分類以及大型語言模型 (LLM，僅解碼器 Transformer) 的 GPT-2 預訓練方面表現出色，證明了它對超參數變化的穩健性以及對各種應用程式的實用性。我們進一步測試了它在 LLM 和擴散模型的 LoRA 微調等任務上的穩健性，它始終優於最先進的最佳化器。從記憶體效率的角度來看，SGD-SaI 為最佳化器狀態節省了大量的記憶體，與 AdamW 在全精度訓練設定中相比，GPT-2 (1.5B 參數) 的記憶體使用量減少了 5.93 GB，而 Llama2-7B 則減少了 25.15 GB。</paragraph>

##### **QUENCH: Measuring the gap between Indic and Non-Indic Contextual General Reasoning in LLMs**
2412.11763v1 by Mohammad Aflah Khan, Neemesh Yadav, Sarah Masud, Md. Shad Akhtar

The rise of large language models (LLMs) has created a need for advanced
benchmarking systems beyond traditional setups. To this end, we introduce
QUENCH, a novel text-based English Quizzing Benchmark manually curated and
transcribed from YouTube quiz videos. QUENCH possesses masked entities and
rationales for the LLMs to predict via generation. At the intersection of
geographical context and common sense reasoning, QUENCH helps assess world
knowledge and deduction capabilities of LLMs via a zero-shot, open-domain
quizzing setup. We perform an extensive evaluation on 7 LLMs and 4 metrics,
investigating the influence of model size, prompting style, geographical
context, and gold-labeled rationale generation. The benchmarking concludes with
an error analysis to which the LLMs are prone.

摘要：大型語言模型（LLM）的興起，創造了對超越傳統設定的高級基準系統的需求。為此，我們引入了 QUENCH，一個新穎的基於文本的英文測驗基準，由 YouTube 測驗影片手動策劃和轉錄。QUENCH 擁有遮罩實體和理由，供 LLM 通過生成進行預測。在地理背景和常識推理的交匯處，QUENCH 有助於通過零次學習、開放領域測驗設置評估 LLM 的世界知識和推理能力。我們對 7 個 LLM 和 4 個指標進行了廣泛的評估，調查了模型大小、提示樣式、地理背景和黃金標籤理由生成的影響。基準測試以 LLM 容易出現的錯誤分析作為結尾。

##### **Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control**
2412.11761v1 by Timothée Anne, Noah Syrkis, Meriem Elhosni, Florian Turati, Franck Legendre, Alain Jaquier, Sebastian Risi

Large Language Models (LLMs) have demonstrated remarkable performance across
various tasks. A promising but largely under-explored area is their potential
to facilitate human coordination with many agents. Such capabilities would be
useful in domains including disaster response, urban planning, and real-time
strategy scenarios. In this work, we introduce (1) a real-time strategy game
benchmark designed to evaluate these abilities and (2) a novel framework we
term HIVE. HIVE empowers a single human to coordinate swarms of up to 2,000
agents using natural language dialog with an LLM. We present promising results
on this multi-agent benchmark, with our hybrid approach solving tasks such as
coordinating agent movements, exploiting unit weaknesses, leveraging human
annotations, and understanding terrain and strategic points. However, our
findings also highlight critical limitations of current models, including
difficulties in processing spatial visual information and challenges in
formulating long-term strategic plans. This work sheds light on the potential
and limitations of LLMs in human-swarm coordination, paving the way for future
research in this area. The HIVE project page, which includes videos of the
system in action, can be found here: hive.syrkis.com.

摘要：大型語言模型 (LLM) 在各種任務中展現出卓越的效能。一個有前景但尚未充分探索的領域是它們促進人類與眾多代理人協調的潛力。此類功能將有助於包括災難應變、都市規劃和即時策略情境在內的領域。在這項工作中，我們介紹了 (1) 一個旨在評估這些能力的即時策略遊戲基準，以及 (2) 一個我們稱之為 HIVE 的新穎框架。HIVE 讓單一個人能夠使用與 LLM 的自然語言對話來協調多達 2,000 個代理人的群體。我們在這個多代理人基準上提出了有前景的結果，我們的混合方法解決了協調代理人移動、利用單元弱點、運用人類註解以及理解地形和策略要點等任務。然而，我們的發現也突顯了當前模型的重大限制，包括處理空間視覺資訊的困難，以及制定長期策略計畫的挑戰。這項工作揭示了 LLM 在人類群體協調中的潛力和限制，為這個領域的未來研究鋪路。HIVE 專案頁面包含系統運作的影片，可在此找到：hive.syrkis.com。

##### **Common Ground, Diverse Roots: The Difficulty of Classifying Common Examples in Spanish Varieties**
2412.11750v1 by Javier A. Lopetegui, Arij Riabi, Djamé Seddah

Variations in languages across geographic regions or cultures are crucial to
address to avoid biases in NLP systems designed for culturally sensitive tasks,
such as hate speech detection or dialog with conversational agents. In
languages such as Spanish, where varieties can significantly overlap, many
examples can be valid across them, which we refer to as common examples.
Ignoring these examples may cause misclassifications, reducing model accuracy
and fairness. Therefore, accounting for these common examples is essential to
improve the robustness and representativeness of NLP systems trained on such
data. In this work, we address this problem in the context of Spanish
varieties. We use training dynamics to automatically detect common examples or
errors in existing Spanish datasets. We demonstrate the efficacy of using
predicted label confidence for our Datamaps
\cite{swayamdipta-etal-2020-dataset} implementation for the identification of
hard-to-classify examples, especially common examples, enhancing model
performance in variety identification tasks. Additionally, we introduce a Cuban
Spanish Variety Identification dataset with common examples annotations
developed to facilitate more accurate detection of Cuban and Caribbean Spanish
varieties. To our knowledge, this is the first dataset focused on identifying
the Cuban, or any other Caribbean, Spanish variety.

摘要：語言在不同地理區域或文化中的差異，對於避免在設計用於文化敏感任務（例如仇恨言論偵測或與對話代理的對話）的 NLP 系統中出現偏差至關重要。在西班牙語等語言中，變體可能顯著重疊，許多範例在它們之間可能是有效的，我們稱之為常見範例。忽略這些範例可能會導致錯誤分類，降低模型準確性和公平性。因此，考量這些常見範例對於改善在這些資料上訓練的 NLP 系統的健壯性和代表性至關重要。在這項工作中，我們在西班牙語變體的背景下探討這個問題。我們使用訓練動態來自動偵測西班牙語現有資料集中的常見範例或錯誤。我們展示了使用預測標籤信心對於我們的 Datamaps\cite{swayamdipta-etal-2020-dataset} 實作來識別難以分類的範例（特別是常見範例）的效能，增強了模型在變體識別任務中的表現。此外，我們引進了一個古巴西班牙語變體識別資料集，其中包含常見範例註解，用於促進更準確地偵測古巴和加勒比西班牙語變體。據我們所知，這是第一個專注於識別古巴或任何其他加勒比西班牙語變體的資料集。

##### **Beyond Dataset Creation: Critical View of Annotation Variation and Bias Probing of a Dataset for Online Radical Content Detection**
2412.11745v1 by Arij Riabi, Virginie Mouilleron, Menel Mahamdi, Wissam Antoun, Djamé Seddah

The proliferation of radical content on online platforms poses significant
risks, including inciting violence and spreading extremist ideologies. Despite
ongoing research, existing datasets and models often fail to address the
complexities of multilingual and diverse data. To bridge this gap, we introduce
a publicly available multilingual dataset annotated with radicalization levels,
calls for action, and named entities in English, French, and Arabic. This
dataset is pseudonymized to protect individual privacy while preserving
contextual information. Beyond presenting our
\href{https://gitlab.inria.fr/ariabi/counter-dataset-public}{freely available
dataset}, we analyze the annotation process, highlighting biases and
disagreements among annotators and their implications for model performance.
Additionally, we use synthetic data to investigate the influence of
socio-demographic traits on annotation patterns and model predictions. Our work
offers a comprehensive examination of the challenges and opportunities in
building robust datasets for radical content detection, emphasizing the
importance of fairness and transparency in model development.

摘要：網路上激進內容的激增帶來重大風險，包括煽動暴力和散布極端主義意識形態。儘管持續進行研究，現有的資料集和模型常常無法解決多語言和多元資料的複雜性。為了彌補這個差距，我們引進一個公開可用的多語言資料集，其中標示了激進化程度、行動呼籲以及英文、法文和阿拉伯文的命名實體。這個資料集經過假名化處理，以保護個人隱私，同時保留脈絡資訊。除了展示我們
\href{https://gitlab.inria.fr/ariabi/counter-dataset-public}{免費提供的資料集} 之外，我們還分析標註流程，強調標註者之間的偏見和分歧，以及它們對模型效能的影響。此外，我們使用合成資料來調查社會人口特徵對標註模式和模型預測的影響。我們的研究全面探討建立用於激進內容偵測的穩健資料集時所面臨的挑戰和機會，強調在模型開發中公平性和透明度的重要性。

##### **CSR:Achieving 1 Bit Key-Value Cache via Sparse Representation**
2412.11741v1 by Hongxuan Zhang, Yao Zhao, Jiaqi Zheng, Chenyi Zhuang, Jinjie Gu, Guihai Chen

The emergence of long-context text applications utilizing large language
models (LLMs) has presented significant scalability challenges, particularly in
memory footprint. The linear growth of the Key-Value (KV) cache responsible for
storing attention keys and values to minimize redundant computations can lead
to substantial increases in memory consumption, potentially causing models to
fail to serve with limited memory resources. To address this issue, we propose
a novel approach called Cache Sparse Representation (CSR), which converts the
KV cache by transforming the dense Key-Value cache tensor into sparse indexes
and weights, offering a more memory-efficient representation during LLM
inference. Furthermore, we introduce NeuralDict, a novel neural network-based
method for automatically generating the dictionary used in our sparse
representation. Our extensive experiments demonstrate that CSR achieves
performance comparable to state-of-the-art KV cache quantization algorithms
while maintaining robust functionality in memory-constrained environments.

摘要：隨著採用大型語言模型 (LLM) 的長內容文字應用程式出現，產生了重大的可擴充性挑戰，尤其是在記憶體佔用空間方面。負責儲存注意力鍵和值的快取記憶體 (KV) 的線性成長，以最小化重複運算，可能會導致記憶體消耗大幅增加，可能會導致模型無法在有限的記憶體資源下提供服務。為了解決這個問題，我們提出了一種稱為快取稀疏表示 (CSR) 的新方法，它透過將密集的快取記憶體張量轉換成稀疏索引和權重，將 KV 快取記憶體轉換，在 LLM 推論期間提供更具記憶體效率的表示方式。此外，我們引入了 NeuralDict，這是一種基於神經網路的新方法，用於自動產生我們在稀疏表示中使用的字典。我們廣泛的實驗證明，CSR 達到了與最先進的 KV 快取量化演算法相當的效能，同時在記憶體受限的環境中維持穩健的功能。

##### **Personalized LLM for Generating Customized Responses to the Same Query from Different Users**
2412.11736v1 by Hang Zeng, Chaoyue Niu, Fan Wu, Chengfei Lv, Guihai Chen

Existing work on large language model (LLM) personalization assigned
different responding roles to LLM, but overlooked the diversity of questioners.
In this work, we propose a new form of questioner-aware LLM personalization,
generating different responses even for the same query from different
questioners. We design a dual-tower model architecture with a cross-questioner
general encoder and a questioner-specific encoder. We further apply contrastive
learning with multi-view augmentation, pulling close the dialogue
representations of the same questioner, while pulling apart those of different
questioners. To mitigate the impact of question diversity on
questioner-contrastive learning, we cluster the dialogues based on question
similarity and restrict the scope of contrastive learning within each cluster.
We also build a multi-questioner dataset from English and Chinese scripts and
WeChat records, called MQDialog, containing 173 questioners and 12 responders.
Extensive evaluation with different metrics shows a significant improvement in
the quality of personalized response generation.

摘要：現有針對大型語言模型 (LLM) 個人化的研究，為 LLM 分配了不同的回應角色，但忽略了提問者的多樣性。在這項研究中，我們提出了一種新的問題感知 LLM 個人化形式，即使對於來自不同提問者的相同查詢，也能產生不同的回應。我們設計了一個雙塔模型架構，其中包含一個跨提問者通用編碼器和一個特定於提問者的編碼器。我們進一步應用對比學習與多視角擴充，拉近相同提問者的對話表徵，同時拉開不同提問者的對話表徵。為了減輕問題多樣性對提問者對比學習的影響，我們根據問題相似性對話語進行分群，並將對比學習的範圍限制在每個群集內。我們還從英文和中文腳本以及微信記錄中建立了一個多提問者資料集，稱為 MQDialog，其中包含 173 個提問者和 12 個回應者。使用不同的指標進行廣泛評估，顯示個人化回應產生的品質有顯著提升。

##### **Transferable Adversarial Face Attack with Text Controlled Attribute**
2412.11735v1 by Wenyun Li, Zheng Zhang, Xiangyuan Lan, Dongmei Jiang

Traditional adversarial attacks typically produce adversarial examples under
norm-constrained conditions, whereas unrestricted adversarial examples are
free-form with semantically meaningful perturbations. Current unrestricted
adversarial impersonation attacks exhibit limited control over adversarial face
attributes and often suffer from low transferability. In this paper, we propose
a novel Text Controlled Attribute Attack (TCA$^2$) to generate photorealistic
adversarial impersonation faces guided by natural language. Specifically, the
category-level personal softmax vector is employed to precisely guide the
impersonation attacks. Additionally, we propose both data and model
augmentation strategies to achieve transferable attacks on unknown target
models. Finally, a generative model, \textit{i.e}, Style-GAN, is utilized to
synthesize impersonated faces with desired attributes. Extensive experiments on
two high-resolution face recognition datasets validate that our TCA$^2$ method
can generate natural text-guided adversarial impersonation faces with high
transferability. We also evaluate our method on real-world face recognition
systems, \textit{i.e}, Face++ and Aliyun, further demonstrating the practical
potential of our approach.

摘要：傳統對抗攻擊通常在常態約束條件下產生對抗範例，而無限制對抗範例是具有語義有意義擾動的自由形式。當前無限制對抗模仿攻擊對對抗人臉屬性控制有限，且通常可轉移性低。在本文中，我們提出了一種新穎的文字控制屬性攻擊 (TCA$^2$)，以生成由自然語言引導的逼真對抗模仿人臉。具體來說，類別級別個人 softmax 向量用於精確引導模仿攻擊。此外，我們提出了數據和模型擴充策略，以實現對未知目標模型的可轉移攻擊。最後，生成模型，\textit{i.e}，Style-GAN，用於合成具有所需屬性的模仿人臉。在兩個高解析度人臉辨識資料集上的廣泛實驗驗證了我們的 TCA$^2$ 方法可以生成具有高可轉移性的自然文字引導對抗模仿人臉。我們還對我們的實務在真實世界人臉辨識系統上進行評估，\textit{i.e}，Face++ 和阿里雲，進一步證明了我們方法的實務潛力。

##### **Findings of the WMT 2024 Shared Task on Discourse-Level Literary Translation**
2412.11732v1 by Longyue Wang, Siyou Liu, Chenyang Lyu, Wenxiang Jiao, Xing Wang, Jiahao Xu, Zhaopeng Tu, Yan Gu, Weiyu Chen, Minghao Wu, Liting Zhou, Philipp Koehn, Andy Way, Yulin Yuan

Following last year, we have continued to host the WMT translation shared
task this year, the second edition of the Discourse-Level Literary Translation.
We focus on three language directions: Chinese-English, Chinese-German, and
Chinese-Russian, with the latter two ones newly added. This year, we totally
received 10 submissions from 5 academia and industry teams. We employ both
automatic and human evaluations to measure the performance of the submitted
systems. The official ranking of the systems is based on the overall human
judgments. We release data, system outputs, and leaderboard at
https://www2.statmt.org/wmt24/literary-translation-task.html.

摘要：繼去年之後，我們今年繼續主辦 WMT 翻譯共用任務，也就是 Discourse-Level Literary Translation 的第二版。
我們專注於三種語言方向：中文到英文、中文到德文，以及中文到俄文，後兩者是新增的。今年，我們總共收到來自 5 個學術和產業團隊的 10 份提交。我們採用自動和人工評分來衡量提交系統的表現。系統的官方排名基於整體的人工評分。我們在 https://www2.statmt.org/wmt24/literary-translation-task.html 發布資料、系統輸出和排行榜。

##### **LLMs Can Simulate Standardized Patients via Agent Coevolution**
2412.11716v1 by Zhuoyun Du, Lujie Zheng, Renjun Hu, Yuyang Xu, Xiawei Li, Ying Sun, Wei Chen, Jian Wu, Haolei Cai, Haohao Ying

Training medical personnel using standardized patients (SPs) remains a
complex challenge, requiring extensive domain expertise and role-specific
practice. Most research on Large Language Model (LLM)-based simulated patients
focuses on improving data retrieval accuracy or adjusting prompts through human
feedback. However, this focus has overlooked the critical need for patient
agents to learn a standardized presentation pattern that transforms data into
human-like patient responses through unsupervised simulations. To address this
gap, we propose EvoPatient, a novel simulated patient framework in which a
patient agent and doctor agents simulate the diagnostic process through
multi-turn dialogues, simultaneously gathering experience to improve the
quality of both questions and answers, ultimately enabling human doctor
training. Extensive experiments on various cases demonstrate that, by providing
only overall SP requirements, our framework improves over existing reasoning
methods by more than 10% in requirement alignment and better human preference,
while achieving an optimal balance of resource consumption after evolving over
200 cases for 10 hours, with excellent generalizability. The code will be
available at https://github.com/ZJUMAI/EvoPatient.

摘要：使用标准化患者 (SP) 培训医疗人员仍然是一项复杂的挑战，需要广泛的领域专业知识和针对特定角色的实践。大多数关于基于大语言模型 (LLM) 的模拟患者的研究都集中在提高数据检索准确性或通过人工反馈调整提示上。然而，这种关注忽视了患者代理学习标准化陈述模式的关键需求，该模式通过无监督模拟将数据转换为类人的患者反应。为了解决这一差距，我们提出了 EvoPatient，这是一个新颖的模拟患者框架，其中患者代理和医生代理通过多轮对话模拟诊断过程，同时收集经验以提高问题和答案的质量，最终实现人类医生培训。对各种案例进行的广泛实验表明，通过仅提供整体 SP 要求，我们的框架在需求对齐和更好的人类偏好方面比现有的推理方法提高了 10% 以上，同时在经过 200 个案例演化 10 小时后实现了资源消耗的最佳平衡，具有出色的可概括性。代码可在 https://github.com/ZJUMAI/EvoPatient 获得。

##### **Seeker: Towards Exception Safety Code Generation with Intermediate Language Agents Framework**
2412.11713v1 by Xuanming Zhang, Yuxuan Chen, Yiming Zheng, Zhexin Zhang, Yuan Yuan, Minlie Huang

In real world software development, improper or missing exception handling
can severely impact the robustness and reliability of code. Exception handling
mechanisms require developers to detect, capture, and manage exceptions
according to high standards, but many developers struggle with these tasks,
leading to fragile code. This problem is particularly evident in open-source
projects and impacts the overall quality of the software ecosystem. To address
this challenge, we explore the use of large language models (LLMs) to improve
exception handling in code. Through extensive analysis, we identify three key
issues: Insensitive Detection of Fragile Code, Inaccurate Capture of Exception
Block, and Distorted Handling Solution. These problems are widespread across
real world repositories, suggesting that robust exception handling practices
are often overlooked or mishandled. In response, we propose Seeker, a
multi-agent framework inspired by expert developer strategies for exception
handling. Seeker uses agents: Scanner, Detector, Predator, Ranker, and Handler
to assist LLMs in detecting, capturing, and resolving exceptions more
effectively. Our work is the first systematic study on leveraging LLMs to
enhance exception handling practices in real development scenarios, providing
valuable insights for future improvements in code reliability.

摘要：在真實世界的軟體開發中，不當或遺漏例外處理會嚴重影響程式碼的穩健性和可靠性。例外處理機制要求開發人員根據高標準偵測、擷取和管理例外，但許多開發人員在這些任務上遇到困難，導致程式碼脆弱。這個問題在開源專案中特別明顯，並影響軟體生態系統的整體品質。為了應對這個挑戰，我們探討使用大型語言模型 (LLM) 來改善程式碼中的例外處理。透過廣泛的分析，我們找出三個關鍵問題：脆弱程式碼的偵測不靈敏、例外區塊的擷取不準確，以及處理解決方案的扭曲。這些問題在真實世界的儲存庫中很普遍，這表示穩健的例外處理實務經常被忽略或處理不當。針對此問題，我們提出 Seeker，一個多代理人架構，靈感來自專家開發人員的例外處理策略。Seeker 使用代理人：掃描器、偵測器、掠奪者、排名器和處理器來協助 LLM 更有效地偵測、擷取和解決例外。我們的研究是第一個系統性研究，利用 LLM 來提升真實開發場景中的例外處理實務，為程式碼可靠性的未來改善提供有價值的見解。

##### **MiMoTable: A Multi-scale Spreadsheet Benchmark with Meta Operations for Table Reasoning**
2412.11711v1 by Zheng Li, Yang Du, Mao Zheng, Mingyang Song

Extensive research has been conducted to explore the capability of Large
Language Models (LLMs) for table reasoning and has significantly improved the
performance on existing benchmarks. However, tables and user questions in
real-world applications are more complex and diverse, presenting an unignorable
gap compared to the existing benchmarks. To fill the gap, we propose a
\textbf{M}ult\textbf{i}-scale spreadsheet benchmark with \textbf{M}eta
\textbf{o}perations for \textbf{Table} reasoning, named as MiMoTable.
Specifically, MiMoTable incorporates two key features. First, the tables in
MiMoTable are all spreadsheets used in real-world scenarios, which cover seven
domains and contain different types. Second, we define a new criterion with six
categories of meta operations for measuring the difficulty of each question in
MiMoTable, simultaneously as a new perspective for measuring the difficulty of
the existing benchmarks. Experimental results show that Claude-3.5-Sonnet
achieves the best performance with 77.4\% accuracy, indicating that there is
still significant room to improve for LLMs on MiMoTable. Furthermore, we grade
the difficulty of existing benchmarks according to our new criteria.
Experiments have shown that the performance of LLMs decreases as the difficulty
of benchmarks increases, thereby proving the effectiveness of our proposed new
criterion.

摘要：已進行廣泛的研究來探索大型語言模型 (LLM) 的表格推理能力，並顯著提升現有基準的效能。然而，實際應用中的表格和使用者問題更為複雜且多樣化，與現有基準相比存在無法忽視的差距。為了填補這個差距，我們提出了一個具有元運算的表格推理多尺度試算表基準，稱為 MiMoTable。具體來說，MiMoTable 融合了兩個關鍵特徵。首先，MiMoTable 中的表格都是實際場景中使用的試算表，涵蓋七個領域並包含不同類型。其次，我們定義了一個具有六種類別元運算的新準則，用於衡量 MiMoTable 中每個問題的難度，同時作為衡量現有基準難度的新觀點。實驗結果表明，Claude-3.5-Sonnet 以 77.4% 的準確率取得最佳效能，這表示 LLM 在 MiMoTable 上仍有顯著的進步空間。此外，我們根據新的準則對現有基準的難度進行評分。實驗表明，隨著基準難度的增加，LLM 的效能會下降，從而證明了我們提出的新準則的有效性。

##### **Re-Attentional Controllable Video Diffusion Editing**
2412.11710v1 by Yuanzhi Wang, Yong Li, Mengyi Liu, Xiaoya Zhang, Xin Liu, Zhen Cui, Antoni B. Chan

Editing videos with textual guidance has garnered popularity due to its
streamlined process which mandates users to solely edit the text prompt
corresponding to the source video. Recent studies have explored and exploited
large-scale text-to-image diffusion models for text-guided video editing,
resulting in remarkable video editing capabilities. However, they may still
suffer from some limitations such as mislocated objects, incorrect number of
objects. Therefore, the controllability of video editing remains a formidable
challenge. In this paper, we aim to challenge the above limitations by
proposing a Re-Attentional Controllable Video Diffusion Editing (ReAtCo)
method. Specially, to align the spatial placement of the target objects with
the edited text prompt in a training-free manner, we propose a Re-Attentional
Diffusion (RAD) to refocus the cross-attention activation responses between the
edited text prompt and the target video during the denoising stage, resulting
in a spatially location-aligned and semantically high-fidelity manipulated
video. In particular, to faithfully preserve the invariant region content with
less border artifacts, we propose an Invariant Region-guided Joint Sampling
(IRJS) strategy to mitigate the intrinsic sampling errors w.r.t the invariant
regions at each denoising timestep and constrain the generated content to be
harmonized with the invariant region content. Experimental results verify that
ReAtCo consistently improves the controllability of video diffusion editing and
achieves superior video editing performance.

摘要：透過文字引導編輯影片由於其簡化的流程而獲得歡迎，此流程要求使用者僅編輯與原始影片對應的文字提示。最近的研究已探索並利用大規模文字轉影像擴散模型進行文字引導影片編輯，產生了卓越的影片編輯能力。然而，它們仍可能存在一些限制，例如物件錯置、物件數量不正確。因此，影片編輯的可控性仍然是一項艱鉅的挑戰。在本文中，我們旨在透過提出重新注意可控影片擴散編輯 (ReAtCo) 方法來挑戰上述限制。特別是，為了在無訓練的情況下將目標物件的空間配置與已編輯的文字提示對齊，我們提出重新注意擴散 (RAD) 來重新聚焦在去噪階段中已編輯文字提示與目標影片之間的交叉注意力激活回應，產生空間位置對齊且語意高保真度處理的影片。特別是，為了忠實保留不變區域的內容並減少邊界偽影，我們提出不變區域引導聯合取樣 (IRJS) 策略，以減輕每個去噪時間步長中與不變區域相關的內在取樣誤差，並約束產生的內容與不變區域內容保持一致。實驗結果驗證 ReAtCo 持續改善影片擴散編輯的可控性，並達成優異的影片編輯效能。

##### **Context Filtering with Reward Modeling in Question Answering**
2412.11707v1 by Sangryul Kim, James Thorne

Question Answering (QA) in NLP is the task of finding answers to a query
within a relevant context retrieved by a retrieval system. Yet, the mix of
relevant and irrelevant information in these contexts can hinder performance
enhancements in QA tasks. To address this, we introduce a context filtering
approach that removes non-essential details, summarizing crucial content
through Reward Modeling. This method emphasizes keeping vital data while
omitting the extraneous during summarization model training. We offer a
framework for developing efficient QA models by discerning useful information
from dataset pairs, bypassing the need for costly human evaluation.
Furthermore, we show that our approach can significantly outperform the
baseline, as evidenced by a 6.8-fold increase in the EM Per Token (EPT) metric,
which we propose as a measure of token efficiency, indicating a notable
token-efficiency boost for low-resource settings.

摘要：自然語言處理 (NLP) 中的問答 (QA) 是在檢索系統檢索到的相關內容中尋找查詢答案的任務。然而，這些內容中相關和不相關資訊的混合可能會阻礙 QA 任務中的效能提升。為了解決這個問題，我們提出了一種內容過濾方法，它會移除非必要的細節，並透過獎勵模型來整理關鍵內容。這種方法強調在摘要模型訓練期間保留重要資料，同時省略不必要的資料。我們提供了一個架構，透過辨別資料集對中的有用資訊來開發高效的 QA 模型，進而繞過昂貴的人工評估。此外，我們證明了我們的做法可以顯著優於基準，這可以從 EM Per Token (EPT) 指標的 6.8 倍增加中得到證明，我們提出這個指標來衡量代幣效率，這表示在低資源設定中獲得顯著的代幣效率提升。

##### **Vocabulary Expansion of Chat Models with Unlabeled Target Language Data**
2412.11704v1 by Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras

Chat models (i.e. language models trained to follow instructions through
conversation with humans) outperform base models (i.e. trained solely on
unlabeled data) in both conversation and general task-solving abilities. These
models are generally English-centric and require further adaptation for
languages that are underrepresented in or absent from their training data. A
common technique for adapting base models is to extend the model's vocabulary
with target language tokens, i.e. vocabulary expansion (VE), and then
continually pre-train it on language-specific data. Using chat data is ideal
for chat model adaptation, but often, either this does not exist or is costly
to construct. Alternatively, adapting chat models with unlabeled data is a
possible solution, but it could result in catastrophic forgetting. In this
paper, we investigate the impact of using unlabeled target language data for VE
on chat models for the first time. We first show that off-the-shelf VE
generally performs well across target language tasks and models in 71% of
cases, though it underperforms in scenarios where source chat models are
already strong. To further improve adapted models, we propose post-hoc
techniques that inject information from the source model without requiring any
further training. Experiments reveal the effectiveness of our methods, helping
the adapted models to achieve performance improvements in 87% of cases.

摘要：聊天模型（即通过与人类对话来遵循指令而训练的语言模型）在对话和一般任务解决能力方面都优于基础模型（即仅在未标记数据上训练的模型）。这些模型通常以英语为中心，并且需要针对在其训练数据中代表性不足或缺失的语言进行进一步的调整。调整基础模型的常用技术是使用目标语言令牌扩展模型词汇表，即词汇扩展 (VE)，然后在特定语言数据上持续预训练它。使用聊天数据是聊天模型调整的理想选择，但通常情况下，要么不存在此类数据，要么构建此类数据代价高昂。或者，使用未标记数据调整聊天模型是一种可能的解决方案，但它可能导致灾难性遗忘。在本文中，我们首次研究了使用未标记目标语言数据进行 VE 对聊天模型的影响。我们首先表明，现成的 VE 在 71% 的情况下通常在目标语言任务和模型中表现良好，尽管在源聊天模型已经很强大的情况下，它的表现不佳。为了进一步改进已调整的模型，我们提出了后验技术，这些技术从源模型中注入信息，而无需任何进一步的训练。实验揭示了我们方法的有效性，帮助调整后的模型在 87% 的情况下实现了性能改进。

##### **CoinMath: Harnessing the Power of Coding Instruction for Math LLMs**
2412.11699v1 by Chengwei Wei, Bin Wang, Jung-jae Kim, Guimei Liu, Nancy F. Chen

Large Language Models (LLMs) have shown strong performance in solving
mathematical problems, with code-based solutions proving particularly
effective. However, the best practice to leverage coding instruction data to
enhance mathematical reasoning remains underexplored. This study investigates
three key questions: (1) How do different coding styles of mathematical
code-based rationales impact LLMs' learning performance? (2) Can general-domain
coding instructions improve performance? (3) How does integrating textual
rationales with code-based ones during training enhance mathematical reasoning
abilities? Our findings reveal that code-based rationales with concise
comments, descriptive naming, and hardcoded solutions are beneficial, while
improvements from general-domain coding instructions and textual rationales are
relatively minor. Based on these insights, we propose CoinMath, a learning
strategy designed to enhance mathematical reasoning by diversifying the coding
styles of code-based rationales. CoinMath generates a variety of code-based
rationales incorporating concise comments, descriptive naming conventions, and
hardcoded solutions. Experimental results demonstrate that CoinMath
significantly outperforms its baseline model, MAmmoTH, one of the SOTA math
LLMs.

摘要：大型語言模型 (LLM) 在解決數學問題方面表現出色，其中基於程式碼的解決方案特別有效。然而，利用編碼指令資料來增強數學推理的最佳實務仍有待探討。本研究探討了三個關鍵問題：(1) 數學程式碼式依據的不同編碼風格如何影響 LLM 的學習表現？(2) 一般領域的編碼指令是否可以提升表現？(3) 在訓練期間將文字依據與基於程式碼的依據整合在一起，如何增強數學推理能力？我們的發現顯示，具有簡潔註解、描述性命名和硬編碼解決方案的基於程式碼的依據是有益的，而一般領域編碼指令和文字依據的改進相對較小。根據這些見解，我們提出了 CoinMath，這是一種學習策略，旨在透過分散基於程式碼的依據的編碼風格來增強數學推理。CoinMath 產生各種基於程式碼的依據，包括簡潔的註解、描述性命名慣例和硬編碼解決方案。實驗結果表明，CoinMath 明顯優於其基準模型 MAmmoTH，這是 SOTA 數學 LLM 之一。

##### **On Large Language Models in Mission-Critical IT Governance: Are We Ready Yet?**
2412.11698v1 by Matteo Esposito, Francesco Palagiano, Valentina Lenarduzzi, Davide Taibi

Context. The security of critical infrastructure has been a fundamental
concern since the advent of computers, and this concern has only intensified in
today's cyber warfare landscape. Protecting mission-critical systems (MCSs),
including essential assets like healthcare, telecommunications, and military
coordination, is vital for national security. These systems require prompt and
comprehensive governance to ensure their resilience, yet recent events have
shown that meeting these demands is increasingly challenging. Aim. Building on
prior research that demonstrated the potential of GAI, particularly Large
Language Models (LLMs), in improving risk analysis tasks, we aim to explore
practitioners' perspectives, specifically developers and security personnel, on
using generative AI (GAI) in the governance of IT MCSs seeking to provide
insights and recommendations for various stakeholders, including researchers,
practitioners, and policymakers. Method. We designed a survey to collect
practical experiences, concerns, and expectations of practitioners who develop
and implement security solutions in the context of MCSs. Analyzing this data
will help identify key trends, challenges, and opportunities for introducing
GAIs in this niche domain. Conclusions and Future Works. Our findings highlight
that the safe use of LLMs in MCS governance requires interdisciplinary
collaboration. Researchers should focus on designing regulation-oriented models
and focus on accountability; practitioners emphasize data protection and
transparency, while policymakers must establish a unified AI framework with
global benchmarks to ensure ethical and secure LLMs-based MCS governance.

摘要：<paragraph>背景。自電腦出現以來，關鍵基礎設施的安全一直是基本考量，而此項考量在今日的網路戰爭情勢下只會更加劇烈。保護任務關鍵系統 (MCS)，包括醫療保健、電信和軍事協調等重要資產，對國家安全至關重要。這些系統需要及時且全面的治理才能確保其復原力，但近期事件顯示，要滿足這些需求越來越具挑戰性。目標。建構於先前的研究，該研究展示了 GAI 的潛力，特別是大型語言模型 (LLM)，在改善風險分析任務上的潛力，我們旨在探討實務工作者的觀點，特別是開發人員和安全人員，對於在 IT MCS 治理中使用生成式 AI (GAI)，以提供見解和建議給各個利害關係人，包括研究人員、實務工作者和政策制定者。方法。我們設計了一份調查問卷，以蒐集在 MCS 背景下開發和實施安全解決方案的實務工作者的實際經驗、疑慮和期望。分析這些資料將有助於找出在這個利基領域中導入 GAI 的主要趨勢、挑戰和機會。結論與未來工作。我們的發現強調，安全地在 MCS 治理中使用 LLM 需要跨領域合作。研究人員應專注於設計以法規為導向的模型，並專注於問責制；實務工作者強調資料保護和透明度，而政策制定者必須建立一個統一的 AI 架構，並制定全球基準，以確保基於 LLM 的 MCS 治理符合道德且安全。</paragraph>

##### **From Specific-MLLM to Omni-MLLM: A Survey about the MLLMs alligned with Multi-Modality**
2412.11694v1 by Shixin Jiang, Jiafeng Liang, Ming Liu, Bing Qin

From the Specific-MLLM, which excels in single-modal tasks, to the Omni-MLLM,
which extends the range of general modalities, this evolution aims to achieve
understanding and generation of multimodal information. Omni-MLLM treats the
features of different modalities as different "foreign languages," enabling
cross-modal interaction and understanding within a unified space. To promote
the advancement of related research, we have compiled 47 relevant papers to
provide the community with a comprehensive introduction to Omni-MLLM. We first
explain the four core components of Omni-MLLM for unified modeling and
interaction of multiple modalities. Next, we introduce the effective
integration achieved through "alignment pretraining" and "instruction
fine-tuning," and discuss open-source datasets and testing of interaction
capabilities. Finally, we summarize the main challenges facing current
Omni-MLLM and outline future directions.

摘要：從擅長單模態任務的特定 MLLM，到擴展一般模態範圍的 Omni-MLLM，此演進旨在達成理解和產生多模態資訊。Omni-MLLM 將不同模態的特徵視為不同的「外語」，讓跨模態互動和理解在統一空間內成為可能。為了促進相關研究的進展，我們彙編了 47 篇相關論文，提供社群對 Omni-MLLM 的全面性介紹。我們首先說明 Omni-MLLM 的四個核心組成，用於多模態的統一建模和互動。接著，我們介紹透過「比對預訓練」和「指令微調」達成的有效整合，並討論開源資料集和互動能力的測試。最後，我們總結目前 Omni-MLLM 面臨的主要挑戰，並概述未來的方向。

##### **Multilingual and Explainable Text Detoxification with Parallel Corpora**
2412.11691v1 by Daryna Dementieva, Nikolay Babakov, Amit Ronen, Abinew Ali Ayele, Naquee Rizwan, Florian Schneider, Xintong Wang, Seid Muhie Yimam, Daniil Moskovskiy, Elisei Stakovskii, Eran Kaufman, Ashraf Elnagar, Animesh Mukherjee, Alexander Panchenko

Even with various regulations in place across countries and social media
platforms (Government of India, 2021; European Parliament and Council of the
European Union, 2022, digital abusive speech remains a significant issue. One
potential approach to address this challenge is automatic text detoxification,
a text style transfer (TST) approach that transforms toxic language into a more
neutral or non-toxic form. To date, the availability of parallel corpora for
the text detoxification task (Logachevavet al., 2022; Atwell et al., 2022;
Dementievavet al., 2024a) has proven to be crucial for state-of-the-art
approaches. With this work, we extend parallel text detoxification corpus to
new languages -- German, Chinese, Arabic, Hindi, and Amharic -- testing in the
extensive multilingual setup TST baselines. Next, we conduct the first of its
kind an automated, explainable analysis of the descriptive features of both
toxic and non-toxic sentences, diving deeply into the nuances, similarities,
and differences of toxicity and detoxification across 9 languages. Finally,
based on the obtained insights, we experiment with a novel text detoxification
method inspired by the Chain-of-Thoughts reasoning approach, enhancing the
prompting process through clustering on relevant descriptive attributes.

摘要：儘管各國和社群媒體平台制定了各種法規（印度政府，2021 年；歐洲議會和歐盟理事會，2022 年），數位網路霸凌仍是一個重大問題。解決此挑戰的一種潛在方法是自動文字解毒，一種文字風格轉換 (TST) 方法，可將有毒語言轉換為更中立或無毒的形式。迄今為止，平行語料庫在文字解毒任務中的可用性（Logachevavet al.，2022 年；Atwell et al.，2022 年；Dementievavet al.，2024a 年）已被證明對最先進的方法至關重要。有了這項工作，我們將平行文字解毒語料庫擴展到新的語言——德語、中文、阿拉伯語、印地語和阿姆哈拉語——在廣泛的多語言設置 TST 基準中進行測試。接下來，我們將進行第一個此類自動化、可解釋的分析，分析有毒和無毒句子的描述性特徵，深入探討跨 9 種語言的毒性和解毒的細微差別、相似性和差異。最後，根據獲得的見解，我們嘗試一種新穎的文字解毒方法，該方法受到思想鏈推理方法的啟發，通過對相關描述屬性的聚類來增強提示過程。

##### **NEST: A Neuromodulated Small-world Hypergraph Trajectory Prediction Model for Autonomous Driving**
2412.11682v1 by Chengyue Wang, Haicheng Liao, Bonan Wang, Yanchen Guan, Bin Rao, Ziyuan Pu, Zhiyong Cui, Chengzhong Xu, Zhenning Li

Accurate trajectory prediction is essential for the safety and efficiency of
autonomous driving. Traditional models often struggle with real-time
processing, capturing non-linearity and uncertainty in traffic environments,
efficiency in dense traffic, and modeling temporal dynamics of interactions. We
introduce NEST (Neuromodulated Small-world Hypergraph Trajectory Prediction), a
novel framework that integrates Small-world Networks and hypergraphs for
superior interaction modeling and prediction accuracy. This integration enables
the capture of both local and extended vehicle interactions, while the
Neuromodulator component adapts dynamically to changing traffic conditions. We
validate the NEST model on several real-world datasets, including nuScenes,
MoCAD, and HighD. The results consistently demonstrate that NEST outperforms
existing methods in various traffic scenarios, showcasing its exceptional
generalization capability, efficiency, and temporal foresight. Our
comprehensive evaluation illustrates that NEST significantly improves the
reliability and operational efficiency of autonomous driving systems, making it
a robust solution for trajectory prediction in complex traffic environments.

摘要：準確的軌跡預測對於自動駕駛的安全性和效率至關重要。傳統模型通常難以應對實時處理、捕捉交通環境中的非線性和不確定性、密集交通中的效率，以及建模交互的時間動態。我們引入了 NEST（神經調製小世界超圖軌跡預測），這是一個整合小世界網路和超圖以實現卓越交互建模和預測精度的創新框架。這種整合可以捕捉局部和延伸的車輛交互，而神經調製器組件則會動態適應不斷變化的交通狀況。我們在多個真實世界資料集上驗證了 NEST 模型，包括 nuScenes、MoCAD 和 HighD。結果一致表明，NEST 在各種交通場景中都優於現有方法，展示了其卓越的泛化能力、效率和時間前瞻性。我們的綜合評估表明，NEST 大大提高了自動駕駛系統的可靠性和運營效率，使其成為複雜交通環境中軌跡預測的強大解決方案。

##### **Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer detection**
2412.11681v1 by Abdelbaki Souid, Mohamed Hamroun, Soufiene Ben Othman, Hedi Sakli, Naceur Abdelkarim

Pulmonary pathologies are a significant global health concern, often leading
to fatal outcomes if not diagnosed and treated promptly. Chest radiography
serves as a primary diagnostic tool, but the availability of experienced
radiologists remains limited. Advances in Artificial Intelligence (AI) and
machine learning, particularly in computer vision, offer promising solutions to
address this challenge.
  This research evaluates a deep learning model designed to detect lung cancer,
specifically pulmonary nodules, along with eight other lung pathologies, using
chest radiographs. The study leverages diverse datasets comprising over 135,120
frontal chest radiographs to train a Convolutional Neural Network (CNN). A
two-stage classification system, utilizing ensemble methods and transfer
learning, is employed to first triage images into Normal or Abnormal categories
and then identify specific pathologies, including lung nodules.
  The deep learning model achieves notable results in nodule classification,
with a top-performing accuracy of 77%, a sensitivity of 0.713, a specificity of
0.776 during external validation, and an AUC score of 0.888. Despite these
successes, some misclassifications were observed, primarily false negatives.
  In conclusion, the model demonstrates robust potential for generalization
across diverse patient populations, attributed to the geographic diversity of
the training dataset. Future work could focus on integrating ETL data
distribution strategies and expanding the dataset with additional nodule-type
samples to further enhance diagnostic accuracy.

摘要：肺部病變是全球重要的健康問題，若未及時診斷和治療，常會導致致命後果。胸部 X 光攝影可用作主要的診斷工具，但經驗豐富的放射科醫師數量有限。人工智慧 (AI) 和機器學習的進展，特別是在電腦視覺方面，提供了有望解決此挑戰的方案。
本研究評估了一個深度學習模型，該模型旨在使用胸部 X 光片檢測肺癌，特別是肺結節，以及其他八種肺部病變。此研究利用包含超過 135,120 張正面胸部 X 光片的不同資料集來訓練卷積神經網路 (CNN)。採用兩階段分類系統，利用整體方法和遷移學習，首先將影像分類為正常或異常類別，然後識別特定病變，包括肺結節。
深度學習模型在結節分類方面取得顯著成果，在外部驗證期間，其準確率最高達到 77%，靈敏度為 0.713，特異度為 0.776，AUC 分數為 0.888。儘管有這些成功，但仍觀察到一些錯誤分類，主要是假陰性。
總之，該模型展示了在不同患者族群中概括的強大潛力，這歸功於訓練資料集的地理多樣性。未來的研究可以專注於整合 ETL 資料分佈策略，並使用額外的結節類型樣本擴充資料集，以進一步提高診斷準確性。

##### **Bias Vector: Mitigating Biases in Language Models with Task Arithmetic Approach**
2412.11679v1 by Daiki Shirafuji, Makoto Takenaka, Shinya Taguchi

The use of language models (LMs) has increased considerably in recent years,
and the biases and stereotypes in training data that are reflected in the LM
outputs are causing social problems. In this paper, inspired by the task
arithmetic, we propose the ``Bias Vector'' method for the mitigation of these
LM biases. The Bias Vector method does not require manually created debiasing
data. The three main steps of our approach involve: (1) continual training the
pre-trained LMs on biased data using masked language modeling; (2) constructing
the Bias Vector as the difference between the weights of the biased LMs and
those of pre-trained LMs; and (3) subtracting the Bias Vector from the weights
of the pre-trained LMs for debiasing. We evaluated the Bias Vector method on
the SEAT across three LMs and confirmed an average improvement of 0.177 points.
We demonstrated that the Bias Vector method does not degrade the LM performance
on downstream tasks in the GLUE benchmark. In addition, we examined the impact
of scaling factors, which control the magnitudes of Bias Vectors, with effect
sizes on the SEAT and conducted a comprehensive evaluation of our debiased LMs
across both the SEAT and GLUE benchmarks.

摘要：近年來，語言模型 (LM) 的使用大幅增加，而訓練資料中的偏見和刻板印象反映在 LM 輸出中，並造成社會問題。在本文中，我們受到算術任務的啟發，提出「偏見向量」方法來減輕這些 LM 偏見。偏見向量方法不需要手動建立去偏見資料。我們的做法包含三個主要步驟：(1) 使用遮蔽語言模型在有偏見的資料上持續訓練預先訓練的 LM；(2) 將偏見 LM 的權重與預先訓練的 LM 的權重之間的差異建構為偏見向量；(3) 從預先訓練的 LM 的權重中減去偏見向量以進行去偏見。我們在三個 LM 上的 SEAT 評估偏見向量方法，並確認平均改善 0.177 分。我們證明偏見向量方法不會降低 GLUE 基準中下游任務的 LM 效能。此外，我們檢視了控制偏見向量大小的縮放因子的影響，以及在 SEAT 上的效果大小，並對我們的去偏見 LM 在 SEAT 和 GLUE 基準上進行全面的評估。

##### **UA-PDFL: A Personalized Approach for Decentralized Federated Learning**
2412.11674v1 by Hangyu Zhu, Yuxiang Fan, Zhenping Xie

Federated learning (FL) is a privacy preserving machine learning paradigm
designed to collaboratively learn a global model without data leakage.
Specifically, in a typical FL system, the central server solely functions as an
coordinator to iteratively aggregate the collected local models trained by each
client, potentially introducing single-point transmission bottleneck and
security threats. To mitigate this issue, decentralized federated learning
(DFL) has been proposed, where all participating clients engage in peer-to-peer
communication without a central server. Nonetheless, DFL still suffers from
training degradation as FL does due to the non-independent and identically
distributed (non-IID) nature of client data. And incorporating personalization
layers into DFL may be the most effective solutions to alleviate the side
effects caused by non-IID data. Therefore, in this paper, we propose a novel
unit representation aided personalized decentralized federated learning
framework, named UA-PDFL, to deal with the non-IID challenge in DFL. By
adaptively adjusting the level of personalization layers through the guidance
of the unit representation, UA-PDFL is able to address the varying degrees of
data skew. Based on this scheme, client-wise dropout and layer-wise
personalization are proposed to further enhance the learning performance of
DFL. Extensive experiments empirically prove the effectiveness of our proposed
method.

摘要：聯邦學習 (FL) 是一種注重隱私的機器學習範例，旨在協作學習一個整體模型，而不會發生資料外洩。具體來說，在典型的 FL 系統中，中央伺服器僅作為協調器，反覆彙總每個客戶端訓練的收集到的本地模型，可能會造成單點傳輸瓶頸和安全威脅。為了減輕這個問題，已經提出了去中心化聯邦學習 (DFL)，其中所有參與的客戶端都參與點對點通訊，而沒有中央伺服器。儘管如此，DFL 仍然會像 FL 一樣遭受訓練退化的問題，因為客戶端資料是非獨立且同分布 (non-IID) 的。而將個人化層納入 DFL 可能會是最有效的解決方案，以減輕由非 IID 資料造成的副作用。因此，在本文中，我們提出了一個新穎的單元表示輔助個人化去中心化聯邦學習架構，稱為 UA-PDFL，以應對 DFL 中的非 IID 挑戰。通過單元表示的指導，自適應調整個人化層的層級，UA-PDFL 能夠解決資料偏差的程度不同。基於這個架構，提出了客戶端隨機失活和層級個人化，以進一步增強 DFL 的學習效能。廣泛的實驗經驗證明了我們提出的方法的有效性。

##### **LLM-DaaS: LLM-driven Drone-as-a-Service Operations from Text User Requests**
2412.11672v1 by Lillian Wassim, Kamal Mohamed, Ali Hamdi

We propose LLM-DaaS, a novel Drone-as-a-Service (DaaS) framework that
leverages Large Language Models (LLMs) to transform free-text user requests
into structured, actionable DaaS operation tasks. Our approach addresses the
key challenge of interpreting and structuring natural language input to
automate drone service operations under uncertain conditions. The system is
composed of three main components: free-text request processing, structured
request generation, and dynamic DaaS selection and composition. First, we
fine-tune different LLM models such as Phi-3.5, LLaMA-3.2 7b and Gemma 2b on a
dataset of text user requests mapped to structured DaaS requests. Users
interact with our model in a free conversational style, discussing package
delivery requests, while the fine-tuned LLM extracts DaaS metadata such as
delivery time, source and destination locations, and package weight. The DaaS
service selection model is designed to select the best available drone capable
of delivering the requested package from the delivery point to the nearest
optimal destination. Additionally, the DaaS composition model composes a
service from a set of the best available drones to deliver the package from the
source to the final destination. Second, the system integrates real-time
weather data to optimize drone route planning and scheduling, ensuring safe and
efficient operations. Simulations demonstrate the system's ability to
significantly improve task accuracy, operational efficiency, and establish
LLM-DaaS as a robust solution for DaaS operations in uncertain environments.

摘要：<paragraph>我們提出 LLM-DaaS，一個新穎的無人機即服務 (DaaS) 框架，利用大型語言模型 (LLM) 將自由文字使用者要求轉換為結構化的、可操作的 DaaS 操作任務。我們的做法解決了在不確定的條件下自動化無人機服務操作時，解釋和結構化自然語言輸入的主要挑戰。系統由三個主要組成部分組成：自由文字請求處理、結構化請求產生，以及動態 DaaS 選擇和組合。首先，我們對不同的 LLM 模型（例如 Phi-3.5、LLaMA-3.2 7b 和 Gemma 2b）進行微調，採用一個將文字使用者請求映射到結構化 DaaS 請求的資料集。使用者以自由對話方式與我們的模型互動，討論包裹遞送請求，而微調後的 LLM 會擷取 DaaS 元資料，例如遞送時間、來源和目的地位置，以及包裹重量。DaaS 服務選擇模型旨在選擇最佳可用的無人機，能夠從遞送點將請求的包裹遞送至最近的最佳目的地。此外，DaaS 組合模型會從一組最佳可用無人機中組合一項服務，以將包裹從來源遞送至最終目的地。其次，系統整合即時天氣資料以最佳化無人機路線規劃和排程，確保安全且有效率的操作。模擬證明了系統顯著提升任務準確度、營運效率的能力，並將 LLM-DaaS 建立為不確定環境中 DaaS 操作的穩健解決方案。</paragraph>

##### **BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR**
2412.11671v1 by Jangyeong Jeon, Sangyeon Cho, Dongjoon Lee, Changhee Lee, Junyeong Kim

Pediatric Emergency Department (PED) overcrowding presents a significant
global challenge, prompting the need for efficient solutions. This paper
introduces the BioBridge framework, a novel approach that applies Natural
Language Processing (NLP) to Electronic Medical Records (EMRs) in written
free-text form to enhance decision-making in PED. In non-English speaking
countries, such as South Korea, EMR data is often written in a Code-Switching
(CS) format that mixes the native language with English, with most
code-switched English words having clinical significance. The BioBridge
framework consists of two core modules: "bridging modality in context" and
"unified bio-embedding." The "bridging modality in context" module improves the
contextual understanding of bilingual and code-switched EMRs. In the "unified
bio-embedding" module, the knowledge of the model trained in the medical domain
is injected into the encoder-based model to bridge the gap between the medical
and general domains. Experimental results demonstrate that the proposed
BioBridge significantly performance traditional machine learning and
pre-trained encoder-based models on several metrics, including F1 score, area
under the receiver operating characteristic curve (AUROC), area under the
precision-recall curve (AUPRC), and Brier score. Specifically, BioBridge-XLM
achieved enhancements of 0.85% in F1 score, 0.75% in AUROC, and 0.76% in AUPRC,
along with a notable 3.04% decrease in the Brier score, demonstrating marked
improvements in accuracy, reliability, and prediction calibration over the
baseline XLM model. The source code will be made publicly available.

摘要：<paragraph>小兒急診部（PED）人滿為患是一個重大的全球性挑戰，促使我們需要找出有效率的解決方案。本文介紹 BioBridge 架構，這是一種創新的方法，將自然語言處理（NLP）應用於以自由文字形式撰寫的電子病歷（EMR），以增強在 PED 中的決策制定。在非英語系國家/地區（例如南韓），EMR 資料通常以代碼轉換（CS）格式撰寫，將母語與英語混合，而大多數代碼轉換的英語單字具有臨床意義。BioBridge 架構包含兩個核心模組：「語境中的橋接方式」和「統一生物嵌入」。「語境中的橋接方式」模組改善了雙語和代碼轉換 EMR 的語境理解。在「統一生物嵌入」模組中，將在醫療領域訓練的模型知識注入到基於編碼器的模型中，以彌合醫療和一般領域之間的差距。實驗結果證明，所提出的 BioBridge 在多項指標（包括 F1 分數、受試者操作特徵曲線下面積（AUROC）、精確度召回率曲線下面積（AUPRC）和布賴爾分數）上顯著優於傳統機器學習和預先訓練的基於編碼器的模型。具體來說，BioBridge-XLM 在 F1 分數上提升了 0.85%，在 AUROC 上提升了 0.75%，在 AUPRC 上提升了 0.76%，同時布賴爾分數顯著下降了 3.04%，證明在準確度、可靠性和預測校準方面，與基準 XLM 模型相比都有顯著的改善。原始碼將公開提供。</paragraph>

##### **C3oT: Generating Shorter Chain-of-Thought without Compromising Effectiveness**
2412.11664v1 by Yu Kang, Xianghui Sun, Liangyu Chen, Wei Zou

Generating Chain-of-Thought (CoT) before deriving the answer can effectively
improve the reasoning capabilities of large language models (LLMs) and
significantly improve the accuracy of the generated answer. However, in most
cases, the length of the generated CoT is much longer than the desired final
answer, which results in additional decoding costs. Furthermore, existing
research has discovered that shortening the reasoning steps in CoT, even while
preserving the key information, diminishes LLMs' abilities. These phenomena
make it difficult to use LLMs and CoT in many real-world applications that only
require the final answer and are sensitive to latency, such as search and
recommendation. To reduce the costs of model decoding and shorten the length of
the generated CoT, this paper presents $\textbf{C}$onditioned
$\textbf{C}$ompressed $\textbf{C}$hain-of-$\textbf{T}$hought (C3oT), a CoT
compression framework that involves a compressor to compress an original longer
CoT into a shorter CoT while maintaining key information and interpretability,
a conditioned training method to train LLMs with both longer CoT and shorter
CoT simultaneously to learn the corresponding relationships between them, and a
conditioned inference method to gain the reasoning ability learned from longer
CoT by generating shorter CoT. We conduct experiments over four datasets from
arithmetic and commonsense scenarios, showing that the proposed method is
capable of compressing the length of generated CoT by up to more than 50%
without compromising its effectiveness.

摘要：<paragraph>在推導出答案之前生成思維鏈（CoT）可以有效地提升大型語言模型（LLM）的推理能力，並顯著提升生成答案的準確度。然而，在多數情況下，生成的 CoT 長度遠大於期望的最終答案，這會造成額外的解碼成本。此外，現有研究發現，縮短 CoT 中的推理步驟，即使保留關鍵資訊，也會降低 LLM 的能力。這些現象使得在許多僅需要最終答案且對延遲敏感的實際應用中，難以使用 LLM 和 CoT，例如搜尋和推薦。為了降低模型解碼的成本並縮短生成的 CoT 長度，本文提出了條件壓縮思維鏈（C3oT），這是一個 CoT 壓縮架構，包含一個壓縮器，用於將原始較長的 CoT 壓縮成較短的 CoT，同時保留關鍵資訊和可解釋性，一個條件訓練方法，用於同時訓練具有較長 CoT 和較短 CoT 的 LLM，以學習它們之間的對應關係，以及一個條件推論方法，用於透過生成較短的 CoT，獲得從較長的 CoT 學到的推理能力。我們針對四個來自算術和常識場景的資料集進行實驗，結果顯示所提出的方法能夠將生成的 CoT 長度壓縮超過 50%，同時不損及它的有效性。</paragraph>

##### **Smoothness Really Matters: A Simple yet Effective Approach for Unsupervised Graph Domain Adaptation**
2412.11654v1 by Wei Chen, Guo Ye, Yakun Wang, Zhao Zhang, Libang Zhang, Daxin Wang, Zhiqiang Zhang, Fuzhen Zhuang

Unsupervised Graph Domain Adaptation (UGDA) seeks to bridge distribution
shifts between domains by transferring knowledge from labeled source graphs to
given unlabeled target graphs. Existing UGDA methods primarily focus on
aligning features in the latent space learned by graph neural networks (GNNs)
across domains, often overlooking structural shifts, resulting in limited
effectiveness when addressing structurally complex transfer scenarios. Given
the sensitivity of GNNs to local structural features, even slight discrepancies
between source and target graphs could lead to significant shifts in node
embeddings, thereby reducing the effectiveness of knowledge transfer. To
address this issue, we introduce a novel approach for UGDA called Target-Domain
Structural Smoothing (TDSS). TDSS is a simple and effective method designed to
perform structural smoothing directly on the target graph, thereby mitigating
structural distribution shifts and ensuring the consistency of node
representations. Specifically, by integrating smoothing techniques with
neighborhood sampling, TDSS maintains the structural coherence of the target
graph while mitigating the risk of over-smoothing. Our theoretical analysis
shows that TDSS effectively reduces target risk by improving model smoothness.
Empirical results on three real-world datasets demonstrate that TDSS
outperforms recent state-of-the-art baselines, achieving significant
improvements across six transfer scenarios. The code is available in
https://github.com/cwei01/TDSS.

摘要：無監督圖形領域適應 (UGDA) 旨在透過將標籤來源圖形的知識轉移到給定的未標籤目標圖形來彌合領域之間的分配轉變。現有的 UGDA 方法主要著重於在圖形神經網路 (GNN) 學習的潛在空間中比對跨領域特徵，經常忽略結構轉變，導致在處理結構複雜的轉移情境時有效性受限。鑑於 GNN 對局部結構特徵的敏感度，來源和目標圖形之間即使是輕微的差異都可能導致節點嵌入的顯著轉變，從而降低知識轉移的有效性。為了解決這個問題，我們引進一種新的 UGDA 方法，稱為目標領域結構平滑 (TDSS)。TDSS 是一種簡單且有效的方法，旨在直接在目標圖形上執行結構平滑，從而減輕結構分配轉變並確保節點表示的一致性。特別是，透過將平滑技術與鄰域抽樣整合，TDSS 在減輕过度平滑風險的同時，維持目標圖形的結構一致性。我們的理論分析顯示，TDSS 透過提升模型平滑度來有效降低目標風險。在三個真實世界資料集上的實證結果證明，TDSS 優於最近的最新基準，在六個轉移情境中獲得顯著的改善。程式碼可在 https://github.com/cwei01/TDSS 取得。

##### **Self-Adaptive Paraphrasing and Preference Learning for Improved Claim Verifiability**
2412.11653v1 by Amelie Wührl, Roman Klinger

In fact-checking, structure and phrasing of claims critically influence a
model's ability to predict verdicts accurately. Social media content in
particular rarely serves as optimal input for verification systems, which
necessitates pre-processing to extract the claim from noisy context before fact
checking. Prior work suggests extracting a claim representation that humans
find to be checkworthy and verifiable. This has two limitations: (1) the format
may not be optimal for a fact-checking model, and (2), it requires annotated
data to learn the extraction task from. We address both issues and propose a
method to extract claims that is not reliant on labeled training data. Instead,
our self-adaptive approach only requires a black-box fact checking model and a
generative language model (LM). Given a tweet, we iteratively optimize the LM
to generate a claim paraphrase that increases the performance of a fact
checking model. By learning from preference pairs, we align the LM to the fact
checker using direct preference optimization. We show that this novel setup
extracts a claim paraphrase that is more verifiable than their original social
media formulations, and is on par with competitive baselines. For refuted
claims, our method consistently outperforms all baselines.

摘要：在事實查核中，聲明的結構和措辭會嚴重影響模型準確預測判決的能力。特別是社群媒體內容很少作為驗證系統的最佳輸入，這需要在事實查核之前從雜訊背景中提取聲明進行預處理。先前的研究建議提取人類認為值得查核和可驗證的聲明表示。這有兩個限制：(1) 格式可能不適合事實查核模型，(2) 需要標註的資料才能從中學習提取任務。我們解決這兩個問題，並提出了一種不依賴標籤訓練資料來提取聲明的辦法。相反，我們的自適應方法只需要一個黑盒事實查核模型和一個生成語言模型 (LM)。給定一個推文，我們反覆最佳化 LM 以產生聲明釋義，以提高事實查核模型的效能。透過從偏好配對學習，我們使用直接偏好最佳化將 LM 與事實查核人員對齊。我們展示了這個新穎的設定提取的聲明釋義比其原始社群媒體表述更可驗證，並且與競爭基準不相上下。對於被駁斥的聲明，我們的辦法始終優於所有基準。

##### **SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**
2412.11652v1 by Tao Meng, Wei Ai, Jianbin Li, Ze Wang, Yuntao Shou, Keqin Li

Text representation learning is significant as the cornerstone of natural
language processing. In recent years, graph contrastive learning (GCL) has been
widely used in text representation learning due to its ability to represent and
capture complex text information in a self-supervised setting. However, current
mainstream graph contrastive learning methods often require the incorporation
of domain knowledge or cumbersome computations to guide the data augmentation
process, which significantly limits the application efficiency and scope of
GCL. Additionally, many methods learn text representations only by constructing
word-document relationships, which overlooks the rich contextual semantic
information in the text. To address these issues and exploit representative
textual semantics, we present an event-based, simple, and effective graph
contrastive learning (SE-GCL) for text representation. Precisely, we extract
event blocks from text and construct internal relation graphs to represent
inter-semantic interconnections, which can ensure that the most critical
semantic information is preserved. Then, we devise a streamlined, unsupervised
graph contrastive learning framework to leverage the complementary nature of
the event semantic and structural information for intricate feature data
capture. In particular, we introduce the concept of an event skeleton for core
representation semantics and simplify the typically complex data augmentation
techniques found in existing graph contrastive learning to boost algorithmic
efficiency. We employ multiple loss functions to prompt diverse embeddings to
converge or diverge within a confined distance in the vector space, ultimately
achieving a harmonious equilibrium. We conducted experiments on the proposed
SE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to
verify its effectiveness in text representation learning.

摘要：文本表徵學習作為自然語言處理的基石，具有重要的意義。近年來，圖形對比學習 (GCL) 因其在自我監督設定中表徵和擷取複雜文本資訊的能力，而被廣泛用於文本表徵學習。然而，當前的主流圖形對比學習方法通常需要加入領域知識或繁瑣的運算來引導資料擴充程序，這顯著地限制了 GCL 的應用效率和範圍。此外，許多方法僅透過建構字詞文件關係來學習文本表徵，這忽略了文本中豐富的脈絡語義資訊。為了解決這些問題並運用具代表性的文本語義，我們提出了一種基於事件、簡單且有效的圖形對比學習 (SE-GCL) 來進行文本表徵。具體來說，我們從文本中萃取事件區塊並建構內部關係圖形來表徵語義間的相互連結，這能確保保留最關鍵的語義資訊。接著，我們設計了一個簡化的無監督圖形對比學習架構，以利用事件語義和結構資訊的互補特性來擷取複雜的特徵資料。特別地，我們引入了事件骨架的概念，用於核心表徵語義，並簡化現有圖形對比學習中通常複雜的資料擴充技術，以提升演算法效率。我們採用多重損失函數來促使不同的嵌入在向量空間中受限距離內收斂或發散，最終達成和諧的平衡。我們在四個標準資料集 (AG News、20NG、SougouNews 和 THUCNews) 上對所提出的 SE-GCL 進行了實驗，以驗證其在文本表徵學習中的有效性。

##### **A comprehensive GeoAI review: Progress, Challenges and Outlooks**
2412.11643v1 by Anasse Boutayeb, Iyad Lahsen-cherif, Ahmed El Khadimi

In recent years, Geospatial Artificial Intelligence (GeoAI) has gained
traction in the most relevant research works and industrial applications, while
also becoming involved in various fields of use. This paper offers a
comprehensive review of GeoAI as a synergistic concept applying Artificial
Intelligence (AI) methods and models to geospatial data. A preliminary study is
carried out, identifying the methodology of the work, the research motivations,
the issues and the directions to be tracked, followed by exploring how GeoAI
can be used in various interesting fields of application, such as precision
agriculture, environmental monitoring, disaster management and urban planning.
Next, a statistical and semantic analysis is carried out, followed by a clear
and precise presentation of the challenges facing GeoAI. Then, a concrete
exploration of the future prospects is provided, based on several informations
gathered during the census. To sum up, this paper provides a complete overview
of the correlation between AI and the geospatial domain, while mentioning the
researches conducted in this context, and emphasizing the close relationship
linking GeoAI with other advanced concepts such as geographic information
systems (GIS) and large-scale geospatial data, known as big geodata. This will
enable researchers and scientific community to assess the state of progress in
this promising field, and will help other interested parties to gain a better
understanding of the issues involved.

摘要：近年來，地理空間人工智慧 (GeoAI) 在最相關的研究工作和產業應用中獲得關注，同時也參與到各個不同的使用領域中。本文提供了一個全面的 GeoAI 綜述，作為一個將人工智慧 (AI) 方法和模型應用於地理空間資料的綜效概念。進行了一項初步研究，識別了工作的研究方法、研究動機、問題和待追蹤的方向，接著探討了 GeoAI 如何用於各種有趣的應用領域，例如精準農業、環境監測、災害管理和都市規劃。接下來，進行了統計和語義分析，接著清楚且精確地說明了 GeoAI 面臨的挑戰。然後，根據普查期間收集的若干資訊，具體探討了未來前景。總而言之，本文提供了 AI 與地理空間領域之間關聯性的完整概觀，同時提及在此脈絡下進行的研究，並強調 GeoAI 與其他進階概念（例如地理資訊系統 (GIS) 和稱為巨量地理資料的大規模地理空間資料）之間的緊密關係。這將使研究人員和科學界能夠評估這個有前途的領域的進展狀況，並將幫助其他有興趣的各方更深入了解所涉及的問題。

##### **Introduction to AI Planning**
2412.11642v1 by Marco Aiello, Ilche Georgievski

These are notes for lectures presented at the University of Stuttgart that
provide an introduction to key concepts and techniques in AI Planning.
Artificial Intelligence Planning, also known as Automated Planning, emerged
somewhere in 1966 from the need to give autonomy to a wheeled robot. Since
then, it has evolved into a flourishing research and development discipline,
often associated with scheduling. Over the decades, various approaches to
planning have been developed with characteristics that make them appropriate
for specific tasks and applications. Most approaches represent the world as a
state within a state transition system; then the planning problem becomes that
of searching a path in the state space from the current state to one which
satisfies the goals of the user. The notes begin by introducing the state model
and move on to exploring classical planning, the foundational form of planning,
and present fundamental algorithms for solving such problems. Subsequently, we
examine planning as a constraint satisfaction problem, outlining the mapping
process and describing an approach to solve such problems. The most extensive
section is dedicated to Hierarchical Task Network (HTN) planning, one of the
most widely used and powerful planning techniques in the field. The lecture
notes end with a bonus chapter on the Planning Domain Definition (PDDL)
Language, the de facto standard syntax for representing non-hierarchical
planning problems.

摘要：這些是斯圖加特大學演講的筆記，其中介紹了 AI 規劃中的關鍵概念和技術。人工智慧規劃，也稱為自動化規劃，於 1966 年出現在賦予輪式機器人自主性的需求中。自那時起，它已演變成一個蓬勃發展的研究和開發學科，通常與排程相關。數十年來，已經開發出各種規劃方法，其特點使其適用於特定任務和應用。大多數方法將世界表示為狀態轉換系統中的狀態；然後，規劃問題變成了在狀態空間中從當前狀態搜索一條路徑到滿足使用者目標的狀態。這些筆記從介紹狀態模型開始，然後探討經典規劃，即規劃的基本形式，並提出解決此類問題的基本演算法。隨後，我們將規劃視為約束滿足問題，概述對應程序並描述解決此類問題的方法。最廣泛的部分是階層式任務網路 (HTN) 規劃，這是該領域中最廣泛使用且強大的規劃技術之一。講義筆記以規劃領域定義 (PDDL) 語言的加值章節結束，這是表示非階層化規劃問題的事實標準語法。

##### **Multi-Scale Incremental Modeling for Enhanced Human Motion Prediction in Human-Robot Collaboration**
2412.11632v1 by Juncheng Zou

Accurate human motion prediction is crucial for safe human-robot
collaboration but remains challenging due to the complexity of modeling
intricate and variable human movements. This paper presents Parallel
Multi-scale Incremental Prediction (PMS), a novel framework that explicitly
models incremental motion across multiple spatio-temporal scales to capture
subtle joint evolutions and global trajectory shifts. PMS encodes these
multi-scale increments using parallel sequence branches, enabling iterative
refinement of predictions. A multi-stage training procedure with a
full-timeline loss integrates temporal context. Extensive experiments on four
datasets demonstrate substantial improvements in continuity, biomechanical
consistency, and long-term forecast stability by modeling inter-frame
increments. PMS achieves state-of-the-art performance, increasing prediction
accuracy by 16.3%-64.2% over previous methods. The proposed multi-scale
incremental approach provides a powerful technique for advancing human motion
prediction capabilities critical for seamless human-robot interaction.

摘要：精準的人類動作預測對於安全的人機協作至關重要，但由於建模複雜且多變的人類動作，仍然具有挑戰性。本文提出平行多尺度遞增預測 (PMS)，這是一個新穎的框架，可以明確地跨越多個時空尺度建模遞增動作，以捕捉細微的關節演化和整體軌跡轉移。PMS 使用平行序列分支編碼這些多尺度增量，實現預測的迭代改進。具有全時序損失的多階段訓練程序整合了時間背景。在四個數據集上的廣泛實驗證明，通過對幀間增量建模，在連續性、生物力學一致性和長期預測穩定性方面都有顯著的改進。PMS 達到了最先進的性能，與以前的方法相比，預測準確度提高了 16.3%-64.2%。所提出的多尺度遞增方法為提升人類動作預測能力提供了一種強大的技術，這對於無縫的人機互動至關重要。

##### **Fool Me, Fool Me: User Attitudes Toward LLM Falsehoods**
2412.11625v1 by Diana Bar-Or Nirman, Ariel Weizman, Amos Azaria

While Large Language Models (LLMs) have become central tools in various
fields, they often provide inaccurate or false information. This study examines
user preferences regarding falsehood responses from LLMs. Specifically, we
evaluate preferences for LLM responses where false statements are explicitly
marked versus unmarked responses and preferences for confident falsehoods
compared to LLM disclaimers acknowledging a lack of knowledge. Additionally, we
investigate how requiring users to assess the truthfulness of statements
influences these preferences.
  Surprisingly, 61\% of users prefer unmarked falsehood responses over marked
ones, and 69\% prefer confident falsehoods over LLMs admitting lack of
knowledge. In all our experiments, a total of 300 users participated,
contributing valuable data to our analysis and conclusions. When users are
required to evaluate the truthfulness of statements, preferences for unmarked
and falsehood responses decrease slightly but remain high. These findings
suggest that user preferences, which influence LLM training via feedback
mechanisms, may inadvertently encourage the generation of falsehoods. Future
research should address the ethical and practical implications of aligning LLM
behavior with such preferences.

摘要：儘管大型語言模型 (LLM) 已成為各領域的核心工具，但它們經常提供不準確或錯誤的資訊。本研究探討使用者對於 LLM 虛假回應的偏好。具體來說，我們評估使用者對於 LLM 回應的偏好，其中虛假陳述被明確標記與未標記的回應，以及對於自信的虛假陳述與 LLM 免責聲明承認缺乏知識的偏好。此外，我們調查要求使用者評估陳述的真實性如何影響這些偏好。
令人驚訝的是，61% 的使用者偏好未標記的虛假回應，而 69% 的使用者偏好自信的虛假陳述，而非 LLM 承認缺乏知識。在我們所有的實驗中，共有 300 名使用者參與，為我們的分析和結論提供了有價值的資料。當要求使用者評估陳述的真實性時，對於未標記和虛假回應的偏好會略微下降，但仍保持在高水平。這些發現表明，透過回饋機制影響 LLM 訓練的使用者偏好，可能會無意中鼓勵產生虛假陳述。未來的研究應探討將 LLM 行為與此類偏好相一致的倫理和實務影響。

##### **Combating Semantic Contamination in Learning with Label Noise**
2412.11620v1 by Wenxiao Fan, Kan Li

Noisy labels can negatively impact the performance of deep neural networks.
One common solution is label refurbishment, which involves reconstructing noisy
labels through predictions and distributions. However, these methods may
introduce problematic semantic associations, a phenomenon that we identify as
Semantic Contamination. Through an analysis of Robust LR, a representative
label refurbishment method, we found that utilizing the logits of views for
refurbishment does not adequately balance the semantic information of
individual classes. Conversely, using the logits of models fails to maintain
consistent semantic relationships across models, which explains why label
refurbishment methods frequently encounter issues related to Semantic
Contamination. To address this issue, we propose a novel method called
Collaborative Cross Learning, which utilizes semi-supervised learning on
refurbished labels to extract appropriate semantic associations from embeddings
across views and models. Experimental results show that our method outperforms
existing approaches on both synthetic and real-world noisy datasets,
effectively mitigating the impact of label noise and Semantic Contamination.

摘要：有雜訊的標籤會對深度神經網路的效能造成負面影響。
一種常見的解決方案是標籤修復，它涉及透過預測和分佈重建有雜訊的標籤。然而，這些方法可能會引入有問題的語義關聯，我們將此現象認定為語義污染。透過分析一個具代表性的標籤修復方法 Robust LR，我們發現利用檢視的 logit 進行修復並未適當地平衡各個類別的語義資訊。相反地，使用模型的 logit 無法在模型之間維持一致的語義關係，這解釋了為什麼標籤修復方法經常會遇到與語義污染相關的問題。為了解決這個問題，我們提出了一種稱為協同交叉學習的新方法，它利用半監督學習對修復後的標籤進行學習，以從檢視和模型中的嵌入中提取適當的語義關聯。實驗結果顯示，我們的模型在合成和真實世界雜訊資料集上都優於現有方法，有效減輕了標籤雜訊和語義污染的影響。

##### **EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**
2412.11618v1 by Nuowei Liu, Changzhi Sun, Tao Ji, Junfeng Tian, Jianxin Tang, Yuanbin Wu, Man Lan

Current Large Language Models (LLMs) for understanding proteins primarily
treats amino acid sequences as a text modality. Meanwhile, Protein Language
Models (PLMs), such as ESM-2, have learned massive sequential evolutionary
knowledge from the universe of natural protein sequences. Furthermore,
structure-based encoders like ProteinMPNN learn the structural information of
proteins through Graph Neural Networks. However, whether the incorporation of
protein encoders can enhance the protein understanding of LLMs has not been
explored. To bridge this gap, we propose EvoLlama, a multimodal framework that
connects a structure-based encoder, a sequence-based protein encoder and an LLM
for protein understanding. EvoLlama consists of a ProteinMPNN structure
encoder, an ESM-2 protein sequence encoder, a multimodal projector to align
protein and text representations and a Llama-3 text decoder. To train EvoLlama,
we fine-tune it on protein-oriented instructions and protein property
prediction datasets verbalized via natural language instruction templates. Our
experiments show that EvoLlama's protein understanding capabilities have been
significantly enhanced, outperforming other fine-tuned protein-oriented LLMs in
zero-shot settings by an average of 1%-8% and surpassing the state-of-the-art
baseline with supervised fine-tuning by an average of 6%. On protein property
prediction datasets, our approach achieves promising results that are
competitive with state-of-the-art task-specific baselines. We will release our
code in a future version.

摘要：目前用於理解蛋白質的大型語言模型 (LLM) 主要將胺基酸序列視為文字形式。同時，蛋白質語言模型 (PLM)，例如 ESM-2，已從自然蛋白質序列的宇宙中學習到大量的順序進化知識。此外，像 ProteinMPNN 等基於結構的編碼器透過圖形神經網路學習蛋白質的結構資訊。然而，尚未探討結合蛋白質編碼器是否能增強 LLM 對蛋白質的理解。為了彌合這個差距，我們提出 EvoLlama，一個多模態架構，它結合一個基於結構的編碼器、一個基於序列的蛋白質編碼器和一個用於理解蛋白質的 LLM。EvoLlama 包含一個 ProteinMPNN 結構編碼器、一個 ESM-2 蛋白質序列編碼器、一個多模態投影器，用於對齊蛋白質和文字表徵，以及一個 Llama-3 文字解碼器。為了訓練 EvoLlama，我們針對蛋白質導向的指令和透過自然語言指令範本表達的蛋白質屬性預測資料集微調它。我們的實驗顯示，EvoLlama 的蛋白質理解能力已獲得顯著提升，在零次學習設定中，平均優於其他微調的蛋白質導向 LLM 1%-8%，並在有監督的微調中平均優於最先進的基準 6%。在蛋白質屬性預測資料集上，我們的做法達到了有希望的結果，與最先進的特定任務基準相當。我們將在未來版本中釋出我們的程式碼。

##### **MT-LENS: An all-in-one Toolkit for Better Machine Translation Evaluation**
2412.11615v1 by Javier García Gilabert, Carlos Escolano, Audrey Mash, Xixian Liao, Maite Melero

We introduce MT-LENS, a framework designed to evaluate Machine Translation
(MT) systems across a variety of tasks, including translation quality, gender
bias detection, added toxicity, and robustness to misspellings. While several
toolkits have become very popular for benchmarking the capabilities of Large
Language Models (LLMs), existing evaluation tools often lack the ability to
thoroughly assess the diverse aspects of MT performance. MT-LENS addresses
these limitations by extending the capabilities of LM-eval-harness for MT,
supporting state-of-the-art datasets and a wide range of evaluation metrics. It
also offers a user-friendly platform to compare systems and analyze
translations with interactive visualizations. MT-LENS aims to broaden access to
evaluation strategies that go beyond traditional translation quality
evaluation, enabling researchers and engineers to better understand the
performance of a NMT model and also easily measure system's biases.

摘要：我們推出 MT-LENS，一個旨在評估機器翻譯 (MT) 系統在各種任務中的框架，包括翻譯品質、性別偏差偵測、增加的毒性，以及拼寫錯誤的健全性。雖然有幾個工具包已變得非常流行，用於基準測試大型語言模型 (LLM) 的能力，但現有的評估工具通常缺乏徹底評估 MT 效能不同面向的能力。MT-LENS 透過擴展 LM-eval-harness for MT 的功能來解決這些限制，支援最先進的資料集和廣泛的評估指標。它還提供一個使用者友善的平台，用於比較系統並透過互動式視覺化分析翻譯。MT-LENS 旨在擴大對評估策略的存取，這些策略超越傳統的翻譯品質評估，讓研究人員和工程師能夠更深入瞭解 NMT 模型的效能，也能輕鬆衡量系統的偏差。

##### **SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models**
2412.11605v1 by Jiale Cheng, Xiao Liu, Cunxiang Wang, Xiaotao Gu, Yida Lu, Dan Zhang, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang

Instruction-following is a fundamental capability of language models,
requiring the model to recognize even the most subtle requirements in the
instructions and accurately reflect them in its output. Such an ability is
well-suited for and often optimized by preference learning. However, existing
methods often directly sample multiple independent responses from the model
when creating preference pairs. Such practice can introduce content variations
irrelevant to whether the instruction is precisely followed (e.g., different
expressions about the same semantic), interfering with the goal of teaching
models to recognize the key differences that lead to improved instruction
following. In light of this, we introduce SPaR, a self-play framework
integrating tree-search self-refinement to yield valid and comparable
preference pairs free from distractions. By playing against itself, an LLM
employs a tree-search strategy to refine its previous responses with respect to
the instruction while minimizing unnecessary variations. Our experiments show
that a LLaMA3-8B model, trained over three iterations guided by SPaR, surpasses
GPT-4-Turbo on the IFEval benchmark without losing general capabilities.
Furthermore, SPaR demonstrates promising scalability and transferability,
greatly enhancing models like GLM-4-9B and LLaMA3-70B. We also identify how
inference scaling in tree search would impact model performance. Our code and
data are publicly available at https://github.com/thu-coai/SPaR.

摘要：指令遵循是语言模型的一项基本能力，要求模型识别指令中即使是最细微的要求，并在其输出中准确反映这些要求。这种能力非常适合于偏好学习，并且通常通过偏好学习进行优化。然而，现有方法在创建偏好对时，通常直接从模型中采样多个独立的响应。这种做法可能会引入与指令是否被精确遵循无关的内容变化（例如，关于相同语义的不同表达），从而干扰教导模型识别导致改进指令遵循的关键差异的目标。有鉴于此，我们引入了 SPaR，一个自玩框架，集成了树搜索自优化，以产生有效且可比较的偏好对，不受干扰。通过与自己对战，LLM 采用树搜索策略，针对指令优化其先前的响应，同时最大程度地减少不必要的变化。我们的实验表明，在 SPaR 指导下经过三轮迭代训练的 LLaMA3-8B 模型在 IFEval 基准测试中超越了 GPT-4-Turbo，而没有丧失一般能力。此外，SPaR 展示了有希望的可扩展性和可迁移性，极大地增强了 GLM-4-9B 和 LLaMA3-70B 等模型。我们还确定了树搜索中的推理缩放如何影响模型性能。我们的代码和数据已在 https://github.com/thu-coai/SPaR 上公开。

##### **AUEB-Archimedes at RIRAG-2025: Is obligation concatenation really all you need?**
2412.11567v1 by Ioannis Chasandras, Odysseas S. Chlapanis, Ion Androutsopoulos

This paper presents the systems we developed for RIRAG-2025, a shared task
that requires answering regulatory questions by retrieving relevant passages.
The generated answers are evaluated using RePASs, a reference-free and
model-based metric. Our systems use a combination of three retrieval models and
a reranker. We show that by exploiting a neural component of RePASs that
extracts important sentences ('obligations') from the retrieved passages, we
achieve a dubiously high score (0.947), even though the answers are directly
extracted from the retrieved passages and are not actually generated answers.
We then show that by selecting the answer with the best RePASs among a few
generated alternatives and then iteratively refining this answer by reducing
contradictions and covering more obligations, we can generate readable,
coherent answers that achieve a more plausible and relatively high score
(0.639).

摘要：本文介紹我們為 RIRAG-2025 開發的系統，這是一項共用任務，需要透過擷取相關段落來回答法規問題。產生的答案使用 RePASs 進行評估，這是一個不依賴參考且基於模型的指標。我們的系統使用三個擷取模型和一個重新排序器的組合。我們展示透過利用 RePASs 的神經元組件從擷取的段落中萃取出重要句子（「義務」），我們達到了可疑的高分（0.947），即使答案是直接從擷取的段落中萃取，且實際上並非產生的答案。接著我們展示透過在幾個產生的備選方案中選出 RePASs 最佳的答案，然後透過減少矛盾和涵蓋更多義務來反覆精煉這個答案，我們可以產生可讀、連貫的答案，並達到更合理且相對較高的分數（0.639）。

##### **The Role of Natural Language Processing Tasks in Automatic Literary Character Network Construction**
2412.11560v1 by Arthur Amalvy, Vincent Labatut, Richard Dufour

The automatic extraction of character networks from literary texts is
generally carried out using natural language processing (NLP) cascading
pipelines. While this approach is widespread, no study exists on the impact of
low-level NLP tasks on their performance. In this article, we conduct such a
study on a literary dataset, focusing on the role of named entity recognition
(NER) and coreference resolution when extracting co-occurrence networks. To
highlight the impact of these tasks' performance, we start with gold-standard
annotations, progressively add uniformly distributed errors, and observe their
impact in terms of character network quality. We demonstrate that NER
performance depends on the tested novel and strongly affects character
detection. We also show that NER-detected mentions alone miss a lot of
character co-occurrences, and that coreference resolution is needed to prevent
this. Finally, we present comparison points with 2 methods based on large
language models (LLMs), including a fully end-to-end one, and show that these
models are outperformed by traditional NLP pipelines in terms of recall.

摘要：從文學文本中自動提取角色網路通常使用自然語言處理 (NLP) 串接管線。儘管這種方法廣泛使用，但對於低階 NLP 任務對其效能的影響，目前尚未有研究。在本文中，我們針對文學資料集進行此類研究，重點探討命名實體辨識 (NER) 和共指消解在提取共現網路中的角色。為了強調這些任務效能的影響，我們從黃金標準註解開始，逐步加入均勻分佈的錯誤，並觀察它們對角色網路品質的影響。我們證明，NER 效能取決於受測小說，且對角色偵測有顯著影響。我們也顯示，僅 NER 偵測到的提及遺漏許多角色共現，且需要共指消解來防止這種情況。最後，我們提出與 2 種基於大型語言模型 (LLM) 的方法的比較點，包括一個完全端對端的方法，並顯示在召回率方面，這些模型的表現不如傳統的 NLP 管線。

##### **Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs**
2412.11556v1 by Yuchen Fu, Zifeng Cheng, Zhiwei Jiang, Zhonghui Wang, Yafeng Yin, Zhengliang Li, Qing Gu

Extracting sentence embeddings from large language models (LLMs) is a
promising direction, as LLMs have demonstrated stronger semantic understanding
capabilities. Previous studies typically focus on prompt engineering to elicit
sentence embeddings from LLMs by prompting the model to encode sentence
information into the embedding of the last token. However, LLMs are mostly
decoder-only models with causal attention and the earlier tokens in the
sentence cannot attend to the latter tokens, resulting in biased encoding of
sentence information and cascading effects on the final decoded token. To this
end, we propose a novel Token Prepending (TP) technique that prepends each
layer's decoded sentence embedding to the beginning of the sentence in the next
layer's input, allowing earlier tokens to attend to the complete sentence
information under the causal attention mechanism. The proposed TP technique is
a plug-and-play and training-free technique, which means it can be seamlessly
integrated with various prompt-based sentence embedding methods and
autoregressive LLMs. Extensive experiments on various Semantic Textual
Similarity (STS) tasks and downstream classification tasks demonstrate that our
proposed TP technique can significantly improve the performance of existing
prompt-based sentence embedding methods across different LLMs, while incurring
negligible additional inference cost.

摘要：從大型語言模型（LLM）中提取句子嵌入是一種有前途的方向，因為 LLM 已展現出更強大的語義理解能力。先前的研究通常專注於提示工程，以透過提示模型將句子資訊編碼到最後一個記號的嵌入中，來從 LLM 引出句子嵌入。然而，LLM 主要是具有因果注意力的僅解碼器模型，且句子中較早的記號無法注意後面的記號，導致句子資訊的編碼有偏差，並對最後解碼的記號產生連鎖效應。為此，我們提出了一種新穎的記號前置（TP）技術，將每一層的解碼句子嵌入前置到下一層輸入句子的開頭，讓較早的記號可以在因果注意力機制下注意完整的句子資訊。所提出的 TP 技術是一種即插即用且免訓練的技術，這表示它可以無縫地整合到各種基於提示的句子嵌入方法和自迴歸 LLM 中。在各種語義文字相似度（STS）任務和下游分類任務上的廣泛實驗證明，我們提出的 TP 技術可以顯著改善現有基於提示的句子嵌入方法在不同 LLM 中的效能，同時產生可忽略不計的額外推論成本。

##### **TS-SatFire: A Multi-Task Satellite Image Time-Series Dataset for Wildfire Detection and Prediction**
2412.11555v1 by Yu Zhao, Sebastian Gerard, Yifang Ban

Wildfire monitoring and prediction are essential for understanding wildfire
behaviour. With extensive Earth observation data, these tasks can be integrated
and enhanced through multi-task deep learning models. We present a
comprehensive multi-temporal remote sensing dataset for active fire detection,
daily wildfire monitoring, and next-day wildfire prediction. Covering wildfire
events in the contiguous U.S. from January 2017 to October 2021, the dataset
includes 3552 surface reflectance images and auxiliary data such as weather,
topography, land cover, and fuel information, totalling 71 GB. The lifecycle of
each wildfire is documented, with labels for active fires (AF) and burned areas
(BA), supported by manual quality assurance of AF and BA test labels. The
dataset supports three tasks: a) active fire detection, b) daily burned area
mapping, and c) wildfire progression prediction. Detection tasks use pixel-wise
classification of multi-spectral, multi-temporal images, while prediction tasks
integrate satellite and auxiliary data to model fire dynamics. This dataset and
its benchmarks provide a foundation for advancing wildfire research using deep
learning.

摘要：野火監控和預測對於了解野火行為至關重要。透過廣泛的地球觀測資料，這些任務可以透過多任務深度學習模型整合並增強。我們提供一個全面的多時相遙測資料集，用於主動火災偵測、每日野火監控和隔日野火預測。涵蓋 2017 年 1 月至 2021 年 10 月美國本土的野火事件，該資料集包括 3552 幅表面反射率影像和天氣、地形、土地覆蓋和燃料資訊等輔助資料，總計 71 GB。每個野火的生命週期都有記錄，並標記主動火災 (AF) 和燃燒區域 (BA)，並由 AF 和 BA 測試標籤的手動品質保證支援。該資料集支援三項任務：a) 主動火災偵測，b) 每日燃燒區域繪製，以及 c) 野火進程預測。偵測任務使用多光譜、多時相影像的逐像素分類，而預測任務整合衛星和輔助資料來建模火災動態。此資料集及其基準為使用深度學習推進野火研究奠定了基礎。

##### **Region-Based Optimization in Continual Learning for Audio Deepfake Detection**
2412.11551v1 by Yujie Chen, Jiangyan Yi, Cunhang Fan, Jianhua Tao, Yong Ren, Siding Zeng, Chu Yuan Zhang, Xinrui Yan, Hao Gu, Jun Xue, Chenglong Wang, Zhao Lv, Xiaohui Zhang

Rapid advancements in speech synthesis and voice conversion bring convenience
but also new security risks, creating an urgent need for effective audio
deepfake detection. Although current models perform well, their effectiveness
diminishes when confronted with the diverse and evolving nature of real-world
deepfakes. To address this issue, we propose a continual learning method named
Region-Based Optimization (RegO) for audio deepfake detection. Specifically, we
use the Fisher information matrix to measure important neuron regions for real
and fake audio detection, dividing them into four regions. First, we directly
fine-tune the less important regions to quickly adapt to new tasks. Next, we
apply gradient optimization in parallel for regions important only to real
audio detection, and in orthogonal directions for regions important only to
fake audio detection. For regions that are important to both, we use sample
proportion-based adaptive gradient optimization. This region-adaptive
optimization ensures an appropriate trade-off between memory stability and
learning plasticity. Additionally, to address the increase of redundant neurons
from old tasks, we further introduce the Ebbinghaus forgetting mechanism to
release them, thereby promoting the capability of the model to learn more
generalized discriminative features. Experimental results show our method
achieves a 21.3% improvement in EER over the state-of-the-art continual
learning approach RWM for audio deepfake detection. Moreover, the effectiveness
of RegO extends beyond the audio deepfake detection domain, showing potential
significance in other tasks, such as image recognition. The code is available
at https://github.com/cyjie429/RegO

摘要：<paragraph>語音合成和語音轉換的快速進展帶來便利性，但也帶來新的安全風險，因此迫切需要有效的音訊 Deepfake 偵測。雖然目前的模型表現良好，但它們在面對真實世界 Deepfake 多樣且不斷變化的本質時，其有效性會降低。為了解決這個問題，我們提出了一種名為區域優化 (RegO) 的持續學習方法，用於音訊 Deepfake 偵測。具體來說，我們使用 Fisher 資訊矩陣來衡量真實和假音訊偵測的重要神經元區域，並將其分為四個區域。首先，我們直接微調較不重要的區域，以快速適應新任務。接下來，我們對僅對真實音訊偵測重要的區域並行應用梯度優化，並對僅對假音訊偵測重要的區域應用正交方向。對於對兩者都重要的區域，我們使用基於樣本比例的自適應梯度優化。這種區域自適應優化確保了記憶體穩定性與學習可塑性之間的適當權衡。此外，為了解決舊任務中冗餘神經元的增加，我們進一步引入了艾賓浩斯遺忘機制來釋放它們，從而提升模型學習更廣義區分特徵的能力。實驗結果顯示，我們的方法在音訊 Deepfake 偵測方面，比最先進的持續學習方法 RWM 提升了 21.3% 的 EER。此外，RegO 的有效性不僅限於音訊 Deepfake 偵測領域，在其他任務（例如影像辨識）中也展現了潛在的重要意義。程式碼可在 https://github.com/cyjie429/RegO 取得</paragraph>

##### **Error Diversity Matters: An Error-Resistant Ensemble Method for Unsupervised Dependency Parsing**
2412.11543v1 by Behzad Shayegh, Hobie H. -B. Lee, Xiaodan Zhu, Jackie Chi Kit Cheung, Lili Mou

We address unsupervised dependency parsing by building an ensemble of diverse
existing models through post hoc aggregation of their output dependency parse
structures. We observe that these ensembles often suffer from low robustness
against weak ensemble components due to error accumulation. To tackle this
problem, we propose an efficient ensemble-selection approach that avoids error
accumulation. Results demonstrate that our approach outperforms each individual
model as well as previous ensemble techniques. Additionally, our experiments
show that the proposed ensemble-selection method significantly enhances the
performance and robustness of our ensemble, surpassing previously proposed
strategies, which have not accounted for error diversity.

摘要：我們透過建立一個由多樣化現有模型組成的集合，透過事後彙總其輸出依賴項解析結構，來處理非監督依賴項解析。我們觀察到這些集合通常會因錯誤累積而對弱集合組成部分的低健壯性而受苦。為了解決這個問題，我們提出一個有效的集合選擇方法，以避免錯誤累積。結果證明我們的方法優於每個單獨的模型以及先前的集合技術。此外，我們的實驗表明，所提出的集合選擇方法顯著地增強了我們集合的效能和健壯性，超越了先前提出的策略，而這些策略並未考慮錯誤多樣性。

##### **SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer**
2412.11540v1 by Jiaxu Wan, Hong Zhang, Ziqi He, Qishu Wang, Ding Yuan, Yifan Yang

In 3D understanding, point transformers have yielded significant advances in
broadening the receptive field. However, further enhancement of the receptive
field is hindered by the constraints of grouping attention. The proxy-based
model, as a hot topic in image and language feature extraction, uses global or
local proxies to expand the model's receptive field. But global proxy-based
methods fail to precisely determine proxy positions and are not suited for
tasks like segmentation and detection in the point cloud, and exist local
proxy-based methods for image face difficulties in global-local balance, proxy
sampling in various point clouds, and parallel cross-attention computation for
sparse association. In this paper, we present SP$^2$T, a local proxy-based dual
stream point transformer, which promotes global receptive field while
maintaining a balance between local and global information. To tackle robust 3D
proxy sampling, we propose a spatial-wise proxy sampling with vertex-based
point proxy associations, ensuring robust point-cloud sampling in many scales
of point cloud. To resolve economical association computation, we introduce
sparse proxy attention combined with table-based relative bias, which enables
low-cost and precise interactions between proxy and point features.
Comprehensive experiments across multiple datasets reveal that our model
achieves SOTA performance in downstream tasks. The code has been released in
https://github.com/TerenceWallel/Sparse-Proxy-Point-Transformer .

摘要：在 3D 理解中，點Transformer在擴大感受野方面取得了重大進展。然而，群組注意力的限制阻礙了感受野的進一步增強。代理模型作為影像和語言特徵提取的熱門主題，使用全局或局部代理來擴展模型的感受野。但是，基於全局代理的方法無法準確確定代理位置，不適合點雲中的分割和檢測等任務，並且存在基於局部代理的方法，在全局-局部平衡、各種點雲中的代理採樣以及稀疏關聯的並行交叉注意計算方面存在困難。在本文中，我們提出了 SP$^2$T，一個基於局部代理的雙流點Transformer，它在保持局部和全局資訊平衡的同時促進全局感受野。為了應對穩健的 3D 代理採樣，我們提出了一種基於頂點的點代理關聯的空間感知代理採樣，確保在點雲的許多尺度上進行穩健的點雲採樣。為了解決經濟型關聯計算，我們引入了稀疏代理注意，並結合了基於表格的相對偏差，這使得代理和點特徵之間的交互低成本且精確。跨多個資料集的綜合實驗表明，我們的模型在下游任務中實現了 SOTA 性能。該程式碼已發佈在 https://github.com/TerenceWallel/Sparse-Proxy-Point-Transformer。

##### **Towards a Speech Foundation Model for Singapore and Beyond**
2412.11538v1 by Muhammad Huzaifah, Tianchi Liu, Hardik B. Sailor, Kye Min Tan, Tarun K. Vangani, Qiongqiong Wang, Jeremy H. M. Wong, Nancy F. Chen, Ai Ti Aw

This technical report describes the MERaLiON Speech Encoder, a foundation
model designed to support a wide range of downstream speech applications.
Developed as part of Singapore's National Multimodal Large Language Model
Programme, the MERaLiON Speech Encoder is tailored to address the speech
processing needs in Singapore and the surrounding Southeast Asian region. The
model currently supports mainly English, including the variety spoken in
Singapore. We are actively expanding our datasets to gradually cover other
languages in subsequent releases. The MERaLiON Speech Encoder was pre-trained
from scratch on 200K hours of unlabelled speech data using a self-supervised
learning approach based on masked language modelling. We describe our training
procedure and hyperparameter tuning experiments in detail below. Our evaluation
demonstrates improvements to spontaneous and Singapore speech benchmarks for
speech recognition, while remaining competitive to other state-of-the-art
speech encoders across ten other speech tasks. We commit to releasing our
model, supporting broader research endeavours, both in Singapore and beyond.

摘要：本技術報告描述了 MERaLiON 語音編碼器，這是一個基礎模型，旨在支援廣泛的下游語音應用程式。MERaLiON 語音編碼器作為新加坡國家多模態大型語言模型計畫的一部分而開發，專門用於滿足新加坡和周邊東南亞地區的語音處理需求。此模型目前主要支援英語，包括新加坡口音。我們正積極擴展我們的資料集，以便在後續版本中逐步涵蓋其他語言。MERaLiON 語音編碼器從 20 萬小時的未標記語音資料中從頭開始預先訓練，使用基於遮罩語言建模的自我監督式學習方法。我們在下方詳細說明我們的訓練程序和超參數調整實驗。我們的評估證明，在語音辨識方面，自發性和新加坡語音基準都有所改進，同時在其他十項語音任務中，仍與其他最先進的語音編碼器保持競爭力。我們承諾發布我們的模型，以支援新加坡及其他地區更廣泛的研究工作。

