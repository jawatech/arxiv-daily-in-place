{"2406.02134": {"publish_time": "2024-06-04", "title": "The current status of large language models in summarizing radiology report impressions", "paper_summary": "Large language models (LLMs) like ChatGPT show excellent capabilities in\nvarious natural language processing tasks, especially for text generation. The\neffectiveness of LLMs in summarizing radiology report impressions remains\nunclear. In this study, we explore the capability of eight LLMs on the\nradiology report impression summarization. Three types of radiology reports,\ni.e., CT, PET-CT, and Ultrasound reports, are collected from Peking University\nCancer Hospital and Institute. We use the report findings to construct the\nzero-shot, one-shot, and three-shot prompts with complete example reports to\ngenerate the impressions. Besides the automatic quantitative evaluation\nmetrics, we define five human evaluation metrics, i.e., completeness,\ncorrectness, conciseness, verisimilitude, and replaceability, to evaluate the\nsemantics of the generated impressions. Two thoracic surgeons (ZSY and LB) and\none radiologist (LQ) compare the generated impressions with the reference\nimpressions and score each impression under the five human evaluation metrics.\nExperimental results show that there is a gap between the generated impressions\nand reference impressions. Although the LLMs achieve comparable performance in\ncompleteness and correctness, the conciseness and verisimilitude scores are not\nvery high. Using few-shot prompts can improve the LLMs' performance in\nconciseness and verisimilitude, but the clinicians still think the LLMs can not\nreplace the radiologists in summarizing the radiology impressions.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u4f8b\u5982 ChatGPT\uff0c\u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u8272\u7684\u80fd\u529b\uff0c\u7279\u5225\u662f\u5728\u6587\u672c\u751f\u6210\u65b9\u9762\u3002LLM \u5728\u7e3d\u7d50\u653e\u5c04\u79d1\u5831\u544a\u5370\u8c61\u65b9\u9762\u7684\u6709\u6548\u6027\u4ecd\u4e0d\u6e05\u695a\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u516b\u500b LLM \u5728\u653e\u5c04\u79d1\u5831\u544a\u5370\u8c61\u6458\u8981\u4e2d\u7684\u80fd\u529b\u3002\u5f9e\u5317\u4eac\u5927\u5b78\u816b\u7624\u91ab\u9662\u548c\u7814\u7a76\u6240\u6536\u96c6\u4e86\u4e09\u7a2e\u985e\u578b\u7684\u653e\u5c04\u79d1\u5831\u544a\uff0c\u5373 CT\u3001PET-CT \u548c\u8d85\u97f3\u6ce2\u5831\u544a\u3002\u6211\u5011\u4f7f\u7528\u5831\u544a\u7d50\u679c\u4f86\u5efa\u69cb\u96f6\u6b21\u3001\u4e00\u6b21\u548c\u4e09\u6b21\u63d0\u793a\uff0c\u4e26\u9644\u4e0a\u5b8c\u6574\u7684\u7bc4\u4f8b\u5831\u544a\u4ee5\u7522\u751f\u5370\u8c61\u3002\u9664\u4e86\u81ea\u52d5\u91cf\u5316\u8a55\u4f30\u6307\u6a19\u4e4b\u5916\uff0c\u6211\u5011\u5b9a\u7fa9\u4e86\u4e94\u500b\u4eba\u985e\u8a55\u4f30\u6307\u6a19\uff0c\u5373\u5b8c\u6574\u6027\u3001\u6b63\u78ba\u6027\u3001\u7c21\u6f54\u6027\u3001\u5408\u7406\u6027\u548c\u53ef\u66ff\u63db\u6027\uff0c\u4ee5\u8a55\u4f30\u6240\u7522\u751f\u5370\u8c61\u7684\u8a9e\u7fa9\u3002\u5169\u4f4d\u80f8\u8154\u5916\u79d1\u91ab\u751f (ZSY \u548c LB) \u548c\u4e00\u4f4d\u653e\u5c04\u79d1\u91ab\u751f (LQ) \u5c07\u7522\u751f\u7684\u5370\u8c61\u8207\u53c3\u8003\u5370\u8c61\u9032\u884c\u6bd4\u8f03\uff0c\u4e26\u6839\u64da\u4e94\u500b\u4eba\u985e\u8a55\u4f30\u6307\u6a19\u5c0d\u6bcf\u500b\u5370\u8c61\u9032\u884c\u8a55\u5206\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u7522\u751f\u7684\u5370\u8c61\u8207\u53c3\u8003\u5370\u8c61\u4e4b\u9593\u5b58\u5728\u5dee\u8ddd\u3002\u5118\u7ba1 LLM \u5728\u5b8c\u6574\u6027\u548c\u6b63\u78ba\u6027\u65b9\u9762\u53d6\u5f97\u76f8\u7576\u7684\u8868\u73fe\uff0c\u4f46\u7c21\u6f54\u6027\u548c\u5408\u7406\u6027\u5206\u6578\u4e26\u4e0d\u9ad8\u3002\u4f7f\u7528\u5c11\u6b21\u63d0\u793a\u53ef\u4ee5\u6539\u5584 LLM \u5728\u7c21\u6f54\u6027\u548c\u5408\u7406\u6027\u65b9\u9762\u7684\u8868\u73fe\uff0c\u4f46\u81e8\u5e8a\u91ab\u751f\u4ecd\u7136\u8a8d\u70ba LLM \u7121\u6cd5\u53d6\u4ee3\u653e\u5c04\u79d1\u91ab\u751f\u7e3d\u7d50\u653e\u5c04\u79d1\u5370\u8c61\u3002", "author": "Danqing Hu et.al.", "authors": "Danqing Hu, Shanyuan Zhang, Qing Liu, Xiaofeng Zhu, Bing Liu", "id": "2406.02134v1", "paper_url": "http://arxiv.org/abs/2406.02134v1", "repo": "null"}}