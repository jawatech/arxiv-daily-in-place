
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-29**|**Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing**|Ekaterina Iakovleva et.al.|[2407.20232v1](http://arxiv.org/abs/2407.20232v1)|null|
|**2024-07-29**|**Can Editing LLMs Inject Harm?**|Canyu Chen et.al.|[2407.20224v1](http://arxiv.org/abs/2407.20224v1)|null|
|**2024-07-29**|**SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction**|Çağhan Köksal et.al.|[2407.20214v1](http://arxiv.org/abs/2407.20214v1)|null|
|**2024-07-29**|**QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval**|Hongming Tan et.al.|[2407.20207v1](http://arxiv.org/abs/2407.20207v1)|null|
|**2024-07-29**|**Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search**|Fengran Mo et.al.|[2407.20189v1](http://arxiv.org/abs/2407.20189v1)|null|
|**2024-07-29**|**MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**|Zehui Chen et.al.|[2407.20183v1](http://arxiv.org/abs/2407.20183v1)|[link](https://github.com/internlm/mindsearch)|
|**2024-07-29**|**Theia: Distilling Diverse Vision Foundation Models for Robot Learning**|Jinghuan Shang et.al.|[2407.20179v1](http://arxiv.org/abs/2407.20179v1)|[link](https://github.com/bdaiinstitute/theia)|
|**2024-07-29**|**AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs**|Feiyang Kang et.al.|[2407.20177v1](http://arxiv.org/abs/2407.20177v1)|null|
|**2024-07-29**|**Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation**|Jingyue Huang et.al.|[2407.20176v1](http://arxiv.org/abs/2407.20176v1)|[link](https://github.com/yuer867/emo_harmonizer)|
|**2024-07-29**|**Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning**|Xingchen Zeng et.al.|[2407.20174v1](http://arxiv.org/abs/2407.20174v1)|[link](https://github.com/zengxingchen/chartqa-mllm)|
|**2024-07-29**|**LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework**|Zhenqi He et.al.|[2407.20172v1](http://arxiv.org/abs/2407.20172v1)|[link](https://github.com/bugs-creator/latentartifusion)|
|**2024-07-29**|**Language-Conditioned Offline RL for Multi-Robot Navigation**|Steven Morad et.al.|[2407.20164v1](http://arxiv.org/abs/2407.20164v1)|null|
|**2024-07-29**|**rLLM: Relational Table Learning with LLMs**|Weichen Li et.al.|[2407.20157v1](http://arxiv.org/abs/2407.20157v1)|[link](https://github.com/rllm-project/rllm)|
|**2024-07-29**|**Quantum Machine Learning Architecture Search via Deep Reinforcement Learning**|Xin Dai et.al.|[2407.20147v1](http://arxiv.org/abs/2407.20147v1)|null|
|**2024-07-29**|**ByteCheckpoint: A Unified Checkpointing System for LLM Development**|Borui Wan et.al.|[2407.20143v1](http://arxiv.org/abs/2407.20143v1)|null|
|**2024-07-29**|**To accept or not to accept? An IRT-TOE Framework to Understand Educators' Resistance to Generative AI in Higher Education**|Jan-Erik Kalmus et.al.|[2407.20130v1](http://arxiv.org/abs/2407.20130v1)|null|
|**2024-07-29**|**AxiomVision: Accuracy-Guaranteed Adaptive Visual Model Selection for Perspective-Aware Video Analytics**|Xiangxiang Dai et.al.|[2407.20124v1](http://arxiv.org/abs/2407.20124v1)|[link](https://github.com/zeyuzhangzyz/axiomvision)|
|**2024-07-29**|**EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation**|Lei Huang et.al.|[2407.20121v1](http://arxiv.org/abs/2407.20121v1)|null|
|**2024-07-29**|**Adaptive Self-supervised Robust Clustering for Unstructured Data with Unknown Cluster Number**|Chen-Lu Ding et.al.|[2407.20119v1](http://arxiv.org/abs/2407.20119v1)|null|
|**2024-07-29**|**FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis**|Mikel Williams-Lekuona et.al.|[2407.20114v1](http://arxiv.org/abs/2407.20114v1)|null|
|**2024-07-29**|**Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning**|Liyuan Mao et.al.|[2407.20109v1](http://arxiv.org/abs/2407.20109v1)|null|
|**2024-07-29**|**Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**|Ruochen Li et.al.|[2407.20108v1](http://arxiv.org/abs/2407.20108v1)|null|
|**2024-07-29**|**F-KANs: Federated Kolmogorov-Arnold Networks**|Engin Zeydan et.al.|[2407.20100v1](http://arxiv.org/abs/2407.20100v1)|[link](https://github.com/ezeydan/F-KANs)|
|**2024-07-29**|**An Energy-based Model for Word-level AutoCompletion in Computer-aided Translation**|Cheng Yang et.al.|[2407.20083v1](http://arxiv.org/abs/2407.20083v1)|null|
|**2024-07-29**|**Investigating the Impact of Semi-Supervised Methods with Data Augmentation on Offensive Language Detection in Romanian Language**|Elena Beatrice Nicola et.al.|[2407.20076v1](http://arxiv.org/abs/2407.20076v1)|null|
|**2024-07-29**|**xAI-Drop: Don't Use What You Cannot Explain**|Vincenzo Marco De Luca et.al.|[2407.20067v1](http://arxiv.org/abs/2407.20067v1)|null|
|**2024-07-29**|**SalNAS: Efficient Saliency-prediction Neural Architecture Search with self-knowledge distillation**|Chakkrit Termritthikun et.al.|[2407.20062v1](http://arxiv.org/abs/2407.20062v1)|null|
|**2024-07-29**|**RelBench: A Benchmark for Deep Learning on Relational Databases**|Joshua Robinson et.al.|[2407.20060v1](http://arxiv.org/abs/2407.20060v1)|[link](https://github.com/snap-stanford/relbench)|
|**2024-07-29**|**Exploring Large Language Models to generate Easy to Read content**|Paloma Martínez et.al.|[2407.20046v1](http://arxiv.org/abs/2407.20046v1)|null|
|**2024-07-29**|**Do LLMs Really Adapt to Domains? An Ontology Learning Perspective**|Huu Tan Mai et.al.|[2407.19998v1](http://arxiv.org/abs/2407.19998v1)|[link](https://github.com/boschresearch/llm-vs-gibberish-ontologies)|
|**2024-07-29**|**Reproducibility Study of "ITI-GEN: Inclusive Text-to-Image Generation"**|Daniel Gallo Fernández et.al.|[2407.19996v1](http://arxiv.org/abs/2407.19996v1)|null|
|**2024-07-29**|**A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph**|Cheonsu Jeong et.al.|[2407.19994v1](http://arxiv.org/abs/2407.19994v1)|null|
|**2024-07-29**|**Mixture of Nested Experts: Adaptive Processing of Visual Tokens**|Gagan Jain et.al.|[2407.19985v1](http://arxiv.org/abs/2407.19985v1)|null|
|**2024-07-29**|**Confidence Estimation for Automatic Detection of Depression and Alzheimer's Disease Based on Clinical Interviews**|Wen Wu et.al.|[2407.19984v1](http://arxiv.org/abs/2407.19984v1)|null|
|**2024-07-29**|**A Temporal Psycholinguistics Approach to Identity Resolution of Social Media Users**|Md Touhidul Islam et.al.|[2407.19967v1](http://arxiv.org/abs/2407.19967v1)|null|
|**2024-07-29**|**Simply Trainable Nearest Neighbour Machine Translation with GPU Inference**|Hossam Amer et.al.|[2407.19965v1](http://arxiv.org/abs/2407.19965v1)|null|
|**2024-07-29**|**Can I trust my anomaly detection system? A case study based on explainable AI**|Muhammad Rashid et.al.|[2407.19951v1](http://arxiv.org/abs/2407.19951v1)|[link](https://github.com/rashidrao-pk/anomaly_detection_trust_case_study)|
|**2024-07-29**|**Inference acceleration for large language models using "stairs" assisted greedy generation**|Domas Grigaliūnas et.al.|[2407.19947v1](http://arxiv.org/abs/2407.19947v1)|null|
|**2024-07-29**|**Noise-Resilient Unsupervised Graph Representation Learning via Multi-Hop Feature Quality Estimation**|Shiyuan Li et.al.|[2407.19944v1](http://arxiv.org/abs/2407.19944v1)|null|
|**2024-07-29**|**Robust Conformal Volume Estimation in 3D Medical Images**|Benjamin Lambert et.al.|[2407.19938v1](http://arxiv.org/abs/2407.19938v1)|[link](https://github.com/benolmbrt/wcp_miccai)|
|**2024-07-29**|**AOTree: Aspect Order Tree-based Model for Explainable Recommendation**|Wenxin Zhao et.al.|[2407.19937v1](http://arxiv.org/abs/2407.19937v1)|null|
|**2024-07-29**|**Monetizing Currency Pair Sentiments through LLM Explainability**|Lior Limonad et.al.|[2407.19922v1](http://arxiv.org/abs/2407.19922v1)|null|
|**2024-07-29**|**Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models**|Brigita Vileikytė et.al.|[2407.19914v1](http://arxiv.org/abs/2407.19914v1)|null|
|**2024-07-29**|**Practical and Reproducible Symbolic Music Generation by Large Language Models with Structural Embeddings**|Seungyeon Rhyu et.al.|[2407.19900v1](http://arxiv.org/abs/2407.19900v1)|null|
|**2024-07-29**|**BEExAI: Benchmark to Evaluate Explainable AI**|Samuel Sithakoul et.al.|[2407.19897v1](http://arxiv.org/abs/2407.19897v1)|[link](https://github.com/squareresearchcenter-ai/beexai)|
|**2024-07-29**|**Leveraging Foundation Models for Zero-Shot IoT Sensing**|Dinghao Xue et.al.|[2407.19893v1](http://arxiv.org/abs/2407.19893v1)|[link](https://github.com/schrodingho/fm_zsl_iot)|
|**2024-07-29**|**A Unified Graph Transformer for Overcoming Isolations in Multi-modal Recommendation**|Zixuan Yi et.al.|[2407.19886v1](http://arxiv.org/abs/2407.19886v1)|null|
|**2024-07-29**|**Distances Between Partial Preference Orderings**|Jean Dezert et.al.|[2407.19869v1](http://arxiv.org/abs/2407.19869v1)|null|
|**2024-07-29**|**Anomalous State Sequence Modeling to Enhance Safety in Reinforcement Learning**|Leen Kweider et.al.|[2407.19860v1](http://arxiv.org/abs/2407.19860v1)|null|
|**2024-07-29**|**Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability**|Jorge García-Carrasco et.al.|[2407.19842v1](http://arxiv.org/abs/2407.19842v1)|null|
|**2024-07-29**|**ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to English Translation**|Mohammed Khalil et.al.|[2407.19835v1](http://arxiv.org/abs/2407.19835v1)|null|
|**2024-07-29**|**ML-Mamba: Efficient Multi-Modal Large Language Model Utilizing Mamba-2**|Wenjun Huang et.al.|[2407.19832v1](http://arxiv.org/abs/2407.19832v1)|null|
|**2024-07-29**|**Generative Retrieval with Preference Optimization for E-commerce Search**|Mingming Li et.al.|[2407.19829v1](http://arxiv.org/abs/2407.19829v1)|null|
|**2024-07-29**|**Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost**|Sania Nayab et.al.|[2407.19825v1](http://arxiv.org/abs/2407.19825v1)|null|
|**2024-07-29**|**Comparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies**|Nikita Matkin et.al.|[2407.19816v1](http://arxiv.org/abs/2407.19816v1)|null|
|**2024-07-29**|**Improving Retrieval Augmented Language Model with Self-Reasoning**|Yuan Xia et.al.|[2407.19813v1](http://arxiv.org/abs/2407.19813v1)|null|
|**2024-07-29**|**Twins-PainViT: Towards a Modality-Agnostic Vision Transformer Framework for Multimodal Automatic Pain Assessment using Facial Videos and fNIRS**|Stefanos Gkikas et.al.|[2407.19809v1](http://arxiv.org/abs/2407.19809v1)|null|
|**2024-07-29**|**Cool-Fusion: Fuse Large Language Models without Training**|Cong Liu et.al.|[2407.19807v1](http://arxiv.org/abs/2407.19807v1)|null|
|**2024-07-29**|**Imputation for prediction: beware of diminishing returns**|Marine Le Morvan et.al.|[2407.19804v1](http://arxiv.org/abs/2407.19804v1)|null|
|**2024-07-29**|**Teaching LLMs at Charles University: Assignments and Activities**|Jindřich Helcl et.al.|[2407.19798v1](http://arxiv.org/abs/2407.19798v1)|null|
|**2024-07-29**|**VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks**|Juhwan Choi et.al.|[2407.19795v1](http://arxiv.org/abs/2407.19795v1)|null|
|**2024-07-29**|**Introducing a new hyper-parameter for RAG: Context Window Utilization**|Kush Juvekar et.al.|[2407.19794v1](http://arxiv.org/abs/2407.19794v1)|null|
|**2024-07-29**|**Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time Series Forecasting**|Jingjing Xu et.al.|[2407.19784v1](http://arxiv.org/abs/2407.19784v1)|null|
|**2024-07-29**|**Synthesizing Scientific Summaries: An Extractive and Abstractive Approach**|Grishma Sharma et.al.|[2407.19779v1](http://arxiv.org/abs/2407.19779v1)|null|
|**2024-07-29**|**Multimodal Large Language Models for Bioimage Analysis**|Shanghang Zhang et.al.|[2407.19778v1](http://arxiv.org/abs/2407.19778v1)|null|
|**2024-07-29**|**Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inference**|Claudio Angione et.al.|[2407.19775v1](http://arxiv.org/abs/2407.19775v1)|null|
|**2024-07-29**|**Generating Unseen Code Tests In Infinitum**|Marcel Zalmanovici et.al.|[2407.19772v1](http://arxiv.org/abs/2407.19772v1)|null|
|**2024-07-29**|**Map2Traj: Street Map Piloted Zero-shot Trajectory Generation with Diffusion Model**|Zhenyu Tao et.al.|[2407.19765v1](http://arxiv.org/abs/2407.19765v1)|null|
|**2024-07-29**|**Legal Minds, Algorithmic Decisions: How LLMs Apply Constitutional Principles in Complex Scenarios**|Camilla Bignotti et.al.|[2407.19760v1](http://arxiv.org/abs/2407.19760v1)|null|
|**2024-07-29**|**KNOWCOMP POKEMON Team at DialAM-2024: A Two-Stage Pipeline for Detecting Relations in Dialogical Argument Mining**|Zihao Zheng et.al.|[2407.19740v1](http://arxiv.org/abs/2407.19740v1)|null|
|**2024-07-29**|**Do Text-to-Vis Benchmarks Test Real Use of Visualisations?**|Hy Nguyen et.al.|[2407.19726v1](http://arxiv.org/abs/2407.19726v1)|null|
|**2024-07-29**|**Rina: Enhancing Ring-AllReduce with In-network Aggregation in Distributed Model Training**|Zixuan Chen et.al.|[2407.19721v1](http://arxiv.org/abs/2407.19721v1)|null|
|**2024-07-29**|**Rethinking RGB-D Fusion for Semantic Segmentation in Surgical Datasets**|Muhammad Abdullah Jamal et.al.|[2407.19714v1](http://arxiv.org/abs/2407.19714v1)|null|
|**2024-07-29**|**CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**|Jingwei Zhu et.al.|[2407.19705v1](http://arxiv.org/abs/2407.19705v1)|null|
|**2024-07-29**|**Multiscale Representation Enhanced Temporal Flow Fusion Model for Long-Term Workload Forecasting**|Shiyu Wang et.al.|[2407.19697v1](http://arxiv.org/abs/2407.19697v1)|null|
|**2024-07-29**|**Efficiently and Effectively: A Two-stage Approach to Balance Plaintext and Encrypted Text for Traffic Classification**|Wei Peng et.al.|[2407.19687v1](http://arxiv.org/abs/2407.19687v1)|null|
|**2024-07-29**|**Revisiting the robustness of post-hoc interpretability methods**|Jiawen Wei et.al.|[2407.19683v1](http://arxiv.org/abs/2407.19683v1)|null|
|**2024-07-29**|**Motion Manifold Flow Primitives for Language-Guided Trajectory Generation**|Yonghyeon Lee et.al.|[2407.19681v1](http://arxiv.org/abs/2407.19681v1)|null|
|**2024-07-29**|**Harnessing Large Vision and Language Models in Agriculture: A Review**|Hongyan Zhu et.al.|[2407.19679v1](http://arxiv.org/abs/2407.19679v1)|null|
|**2024-07-29**|**SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages**|Wenxuan Zhang et.al.|[2407.19672v1](http://arxiv.org/abs/2407.19672v1)|null|
|**2024-07-29**|**mGTE: Generalized Long-Context Text Representation and Reranking Models for Multilingual Text Retrieval**|Xin Zhang et.al.|[2407.19669v1](http://arxiv.org/abs/2407.19669v1)|null|
|**2024-07-29**|**Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**|Minxiao Chen et.al.|[2407.19668v1](http://arxiv.org/abs/2407.19668v1)|[link](https://github.com/faceless0124/mghstn)|
|**2024-07-29**|**Smart Language Agents in Real-World Planning**|Annabelle Miin et.al.|[2407.19667v1](http://arxiv.org/abs/2407.19667v1)|[link](https://github.com/llv22/travelplanner_forward)|
|**2024-07-29**|**AI-Driven Healthcare: A Survey on Ensuring Fairness and Mitigating Bias**|Sribala Vidyadhari Chinta et.al.|[2407.19655v1](http://arxiv.org/abs/2407.19655v1)|null|
|**2024-07-29**|**Realizing Unaligned Block-wise Pruning for DNN Acceleration on Mobile Devices**|Hayun Lee et.al.|[2407.19644v1](http://arxiv.org/abs/2407.19644v1)|null|
|**2024-07-29**|**Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**|Yunsheng Wang et.al.|[2407.19643v1](http://arxiv.org/abs/2407.19643v1)|[link](https://github.com/iamryanshengwang/prometheus-chatbot)|
|**2024-07-29**|**From Pre-training Corpora to Large Language Models: What Factors Influence LLM Performance in Causal Discovery Tasks?**|Tao Feng et.al.|[2407.19638v1](http://arxiv.org/abs/2407.19638v1)|null|
|**2024-07-29**|**OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale**|Ali AhmadiTeshnizi et.al.|[2407.19633v1](http://arxiv.org/abs/2407.19633v1)|null|
|**2024-07-29**|**"A Good Bot Always Knows Its Limitations": Assessing Autonomous System Decision-making Competencies through Factorized Machine Self-confidence**|Brett Israelsen et.al.|[2407.19631v1](http://arxiv.org/abs/2407.19631v1)|null|
|**2024-07-29**|**LLMs' Understanding of Natural Language Revealed**|Walid S. Saba et.al.|[2407.19630v1](http://arxiv.org/abs/2407.19630v1)|null|
|**2024-07-29**|**Enhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation**|Manish Bhattarai et.al.|[2407.19619v1](http://arxiv.org/abs/2407.19619v1)|null|
|**2024-07-29**|**TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**|Selma Wanna et.al.|[2407.19616v1](http://arxiv.org/abs/2407.19616v1)|null|
|**2024-07-28**|**Mixture of Modular Experts: Distilling Knowledge from a Multilingual Teacher into Specialized Modular Language Models**|Mohammed Al-Maamari et.al.|[2407.19610v1](http://arxiv.org/abs/2407.19610v1)|[link](https://github.com/padas-lab-de/multi-language-dataset-creator)|
|**2024-07-28**|**You shall know a piece by the company it keeps. Chess plays as a data for word2vec models**|Boris Orekhov et.al.|[2407.19600v1](http://arxiv.org/abs/2407.19600v1)|null|
|**2024-07-28**|**Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge**|Tianhao Wu et.al.|[2407.19594v1](http://arxiv.org/abs/2407.19594v1)|null|
|**2024-07-28**|**Is Generative AI an Existential Threat to Human Creatives? Insights from Financial Economics**|Jiasun Li et.al.|[2407.19586v1](http://arxiv.org/abs/2407.19586v1)|null|
|**2024-07-28**|**SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain**|Pierre Colombo et.al.|[2407.19584v1](http://arxiv.org/abs/2407.19584v1)|null|
|**2024-07-28**|**Memory-efficient Training of LLMs with Larger Mini-batches**|Dang Nguyen et.al.|[2407.19580v1](http://arxiv.org/abs/2407.19580v1)|null|
|**2024-07-28**|**Are LLMs Good Annotators for Discourse-level Event Relation Extraction?**|Kangda Wei et.al.|[2407.19568v1](http://arxiv.org/abs/2407.19568v1)|null|
|**2024-07-28**|**Forecast-PEFT: Parameter-Efficient Fine-Tuning for Pre-trained Motion Forecasting Models**|Jifeng Wang et.al.|[2407.19564v1](http://arxiv.org/abs/2407.19564v1)|[link](https://github.com/csjfwang/forecast-peft)|

#### Abstracts
##### **Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing**
2407.20232v1 by Ekaterina Iakovleva, Fabio Pizzati, Philip Torr, Stéphane Lathuilière

Text-based editing diffusion models exhibit limited performance when the
user's input instruction is ambiguous. To solve this problem, we propose
$\textit{Specify ANd Edit}$ (SANE), a zero-shot inference pipeline for
diffusion-based editing systems. We use a large language model (LLM) to
decompose the input instruction into specific instructions, i.e. well-defined
interventions to apply to the input image to satisfy the user's request. We
benefit from the LLM-derived instructions along the original one, thanks to a
novel denoising guidance strategy specifically designed for the task. Our
experiments with three baselines and on two datasets demonstrate the benefits
of SANE in all setups. Moreover, our pipeline improves the interpretability of
editing models, and boosts the output diversity. We also demonstrate that our
approach can be applied to any edit, whether ambiguous or not. Our code is
public at https://github.com/fabvio/SANE.

摘要：<paragraph>基於文字的編輯擴散模型在使用者的輸入指示不明確時，會展現有限的效能。為了解決這個問題，我們提出 $\textit{Specify ANd Edit}$ (SANE)，一個零次推論管線，適用於基於擴散的編輯系統。我們使用大型語言模型 (LLM) 將輸入指令分解成特定指令，也就是針對輸入影像套用良好定義的介入措施，以滿足使用者的要求。我們受益於 LLM 衍生的指令以及原始指令，這要歸功於專門為此任務設計的新穎去噪引導策略。我們使用三個基準和兩個資料集進行的實驗，證明了 SANE 在所有設定中的優點。此外，我們的管線改善了編輯模型的可解釋性，並提升了輸出多樣性。我們也證明了我們的做法可以應用於任何編輯，無論是否含糊不清。我們的程式碼已公開於 https://github.com/fabvio/SANE。</paragraph>

##### **Can Editing LLMs Inject Harm?**
2407.20224v1 by Canyu Chen, Baixiang Huang, Zekun Li, Zhaorun Chen, Shiyang Lai, Xiongxiao Xu, Jia-Chen Gu, Jindong Gu, Huaxiu Yao, Chaowei Xiao, Xifeng Yan, William Yang Wang, Philip Torr, Dawn Song, Kai Shu

Knowledge editing techniques have been increasingly adopted to efficiently
correct the false or outdated knowledge in Large Language Models (LLMs), due to
the high cost of retraining from scratch. Meanwhile, one critical but
under-explored question is: can knowledge editing be used to inject harm into
LLMs? In this paper, we propose to reformulate knowledge editing as a new type
of safety threat for LLMs, namely Editing Attack, and conduct a systematic
investigation with a newly constructed dataset EditAttack. Specifically, we
focus on two typical safety risks of Editing Attack including Misinformation
Injection and Bias Injection. For the risk of misinformation injection, we
first categorize it into commonsense misinformation injection and long-tail
misinformation injection. Then, we find that editing attacks can inject both
types of misinformation into LLMs, and the effectiveness is particularly high
for commonsense misinformation injection. For the risk of bias injection, we
discover that not only can biased sentences be injected into LLMs with high
effectiveness, but also one single biased sentence injection can cause a high
bias increase in general outputs of LLMs, which are even highly irrelevant to
the injected sentence, indicating a catastrophic impact on the overall fairness
of LLMs. Then, we further illustrate the high stealthiness of editing attacks,
measured by their impact on the general knowledge and reasoning capacities of
LLMs, and show the hardness of defending editing attacks with empirical
evidence. Our discoveries demonstrate the emerging misuse risks of knowledge
editing techniques on compromising the safety alignment of LLMs.

摘要：<paragraph>由於從頭開始重新訓練的成本很高，知識編輯技術已被廣泛採用，以有效修正大型語言模型 (LLM) 中錯誤或過時的知識。與此同時，一個關鍵但未充分探討的問題是：知識編輯是否可用於向 LLM 注入危害？在本文中，我們提議將知識編輯重新表述為 LLM 的一種新型安全威脅，即編輯攻擊，並使用新構建的資料集 EditAttack 進行系統性調查。具體來說，我們專注於編輯攻擊的兩個典型安全風險，包括錯誤訊息注入和偏差注入。對於錯誤訊息注入的風險，我們首先將其分類為常識錯誤訊息注入和長尾錯誤訊息注入。然後，我們發現編輯攻擊可以將這兩種錯誤訊息注入 LLM，且常識錯誤訊息注入的有效性特別高。對於偏差注入的風險，我們發現不僅可以將有偏差的句子以高效率注入 LLM，而且單一有偏差的句子注入會導致 LLM 整體輸出出現高偏差，甚至與注入的句子高度無關，這表示對 LLM 整體公平性的影響是災難性的。然後，我們進一步說明編輯攻擊的高度隱密性，透過其對 LLM 的一般知識和推理能力的影響來衡量，並透過經驗證據顯示防禦編輯攻擊的難度。我們的發現證明了知識編輯技術在危害 LLM 的安全比對方面出現的新興誤用風險。</paragraph>

##### **SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction**
2407.20214v1 by Çağhan Köksal, Ghazal Ghazaei, Felix Holm, Azade Farshad, Nassir Navab

Graph-based holistic scene representations facilitate surgical workflow
understanding and have recently demonstrated significant success. However, this
task is often hindered by the limited availability of densely annotated
surgical scene data. In this work, we introduce an end-to-end framework for the
generation and optimization of surgical scene graphs on a downstream task. Our
approach leverages the flexibility of graph-based spectral clustering and the
generalization capability of foundation models to generate unsupervised scene
graphs with learnable properties. We reinforce the initial spatial graph with
sparse temporal connections using local matches between consecutive frames to
predict temporally consistent clusters across a temporal neighborhood. By
jointly optimizing the spatiotemporal relations and node features of the
dynamic scene graph with the downstream task of phase segmentation, we address
the costly and annotation-burdensome task of semantic scene comprehension and
scene graph generation in surgical videos using only weak surgical phase
labels. Further, by incorporating effective intermediate scene representation
disentanglement steps within the pipeline, our solution outperforms the SOTA on
the CATARACTS dataset by 8% accuracy and 10% F1 score in surgical workflow
recognition

摘要：圖形化全景場景表示有助於了解手術流程，並在近期展現顯著的成就。然而，此任務通常受限於密集標註手術場景資料的有限取得。在此研究中，我們針對下游任務引進一個端對端架構，用於產生和最佳化手術場景圖。我們的做法利用了基於圖形的頻譜聚類的靈活性，以及基礎模型的概化能力，以產生具有可學習特性的非監督式場景圖。我們使用連續幀之間的局部配對，以稀疏時間連接強化初始空間圖，以預測時間一致的群集，跨時間鄰域。透過共同最佳化動態場景圖的時空關係和節點特徵，以及階段分割的下游任務，我們使用僅有的弱手術階段標籤，解決了語意場景理解和場景圖產生成本高且標註負擔大的任務。此外，透過在管道中納入有效的中間場景表示解糾纏步驟，我們的解決方案在 CATARACTS 資料集上，在手術流程識別中，優於 SOTA，準確率高出 8%，F1 分數高出 10%。

##### **QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval**
2407.20207v1 by Hongming Tan, Shaoxiong Zhan, Hai Lin, Hai-Tao Zheng, Wai Kin, Chan

In dense retrieval, embedding long texts into dense vectors can result in
information loss, leading to inaccurate query-text matching. Additionally,
low-quality texts with excessive noise or sparse key information are unlikely
to align well with relevant queries. Recent studies mainly focus on improving
the sentence embedding model or retrieval process. In this work, we introduce a
novel text augmentation framework for dense retrieval. This framework
transforms raw documents into information-dense text formats, which supplement
the original texts to effectively address the aforementioned issues without
modifying embedding or retrieval methodologies. Two text representations are
generated via large language models (LLMs) zero-shot prompting: question-answer
pairs and element-driven events. We term this approach QAEA-DR: unifying
question-answer generation and event extraction in a text augmentation
framework for dense retrieval. To further enhance the quality of generated
texts, a scoring-based evaluation and regeneration mechanism is introduced in
LLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,
supported by both theoretical analysis and empirical experiments.

摘要：在稠密檢索中，將長文本嵌入稠密向量中可能會導致資訊遺失，進而導致不準確的查詢文字配對。此外，品質低劣、雜訊過多或關鍵資訊稀疏的文字不太可能與相關查詢相符。最近的研究主要集中在改進句子嵌入模型或檢索流程。在這項工作中，我們引入了一個用於稠密檢索的新穎文字擴充架構。此架構將原始文件轉換為資訊密集的文字格式，補充原始文字以有效解決上述問題，而無需修改嵌入或檢索方法。透過大型語言模型 (LLM) 零次提示產生兩個文字表徵：問答對和元素驅動事件。我們將此方法稱為 QAEA-DR：統一問答產生和事件萃取，用於稠密檢索的文字擴充架構。為了進一步提升產生文字的品質，在 LLM 提示中引入了基於評分的評估和再生機制。我們的 QAEA-DR 模型對稠密檢索有正面的影響，理論分析和實證實驗都支持這一點。

##### **Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search**
2407.20189v1 by Fengran Mo, Chen Qu, Kelong Mao, Yihong Wu, Zhan Su, Kaiyu Huang, Jian-Yun Nie

Conversational search supports multi-turn user-system interactions to solve
complex information needs. Different from the traditional single-turn ad-hoc
search, conversational search encounters a more challenging problem of
context-dependent query understanding with the lengthy and long-tail
conversational history context. While conversational query rewriting methods
leverage explicit rewritten queries to train a rewriting model to transform the
context-dependent query into a stand-stone search query, this is usually done
without considering the quality of search results. Conversational dense
retrieval methods use fine-tuning to improve a pre-trained ad-hoc query
encoder, but they are limited by the conversational search data available for
training. In this paper, we leverage both rewritten queries and relevance
judgments in the conversational search data to train a better query
representation model. The key idea is to align the query representation with
those of rewritten queries and relevant documents. The proposed model -- Query
Representation Alignment Conversational Dense Retriever, QRACDR, is tested on
eight datasets, including various settings in conversational search and ad-hoc
search. The results demonstrate the strong performance of QRACDR compared with
state-of-the-art methods, and confirm the effectiveness of representation
alignment.

摘要：對話式搜尋支援多輪使用者系統互動，以解決複雜的資訊需求。與傳統的單輪即席搜尋不同，對話式搜尋會遇到一個更具挑戰性的問題，即在冗長且長尾的對話式歷程記錄中，依據脈絡來理解查詢。儘管對話式查詢改寫方法利用明確改寫的查詢，來訓練一個改寫模型，將依據脈絡的查詢轉換為一個獨立的搜尋查詢，但這通常並未考慮搜尋結果的品質。對話式稠密檢索方法使用微調來改善預先訓練的即席查詢編碼器，但它們受到可用於訓練的對話式搜尋資料限制。在本文中，我們利用對話式搜尋資料中的改寫查詢和相關性判斷，來訓練一個更好的查詢表示模型。其關鍵構想是將查詢表示與改寫查詢和相關文件對齊。建議的模型——查詢表示對齊對話式稠密檢索器 QRACDR，在八個資料集上進行測試，包括對話式搜尋和即席搜尋的各種設定。結果顯示 QRACDR 的效能優於現有技術，並確認表示對齊的有效性。

##### **MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**
2407.20183v1 by Zehui Chen, Kuikun Liu, Qiuchen Wang, Jiangning Liu, Wenwei Zhang, Kai Chen, Feng Zhao

Information seeking and integration is a complex cognitive task that consumes
enormous time and effort. Inspired by the remarkable progress of Large Language
Models, recent works attempt to solve this task by combining LLMs and search
engines. However, these methods still obtain unsatisfying performance due to
three challenges: (1) complex requests often cannot be accurately and
completely retrieved by the search engine once (2) corresponding information to
be integrated is spread over multiple web pages along with massive noise, and
(3) a large number of web pages with long contents may quickly exceed the
maximum context length of LLMs. Inspired by the cognitive process when humans
solve these problems, we introduce MindSearch to mimic the human minds in web
information seeking and integration, which can be instantiated by a simple yet
effective LLM-based multi-agent framework. The WebPlanner models the human mind
of multi-step information seeking as a dynamic graph construction process: it
decomposes the user query into atomic sub-questions as nodes in the graph and
progressively extends the graph based on the search result from WebSearcher.
Tasked with each sub-question, WebSearcher performs hierarchical information
retrieval with search engines and collects valuable information for WebPlanner.
The multi-agent design of MindSearch enables the whole framework to seek and
integrate information parallelly from larger-scale (e.g., more than 300) web
pages in 3 minutes, which is worth 3 hours of human effort. MindSearch
demonstrates significant improvement in the response quality in terms of depth
and breadth, on both close-set and open-set QA problems. Besides, responses
from MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web
and Perplexity.ai applications, which implies that MindSearch can already
deliver a competitive solution to the proprietary AI search engine.

摘要：資訊搜尋與整合是一項複雜的認知任務，會耗費大量時間與精力。在大型語言模型顯著進展的啟發下，近期研究嘗試結合大型語言模型與搜尋引擎來解決此任務。然而，這些方法仍因三項挑戰而無法獲得令人滿意的效能：(1) 複雜的查詢通常無法由搜尋引擎一次準確且完整地擷取，(2) 要整合的對應資訊散布在多個網頁中且伴隨著大量雜訊，以及 (3) 大量內容過長的網頁可能會快速超過大型語言模型的最大脈絡長度。在人類解決這些問題的認知過程中獲得靈感，我們引入了 MindSearch 來模擬人類心智在網頁資訊搜尋與整合中的行為，這可以用一個簡單但有效的基於大型語言模型的多代理架構來實例化。WebPlanner 以動態圖形建構過程來建模人類心智的多步驟資訊搜尋：它將使用者查詢分解成圖形中的節點，作為原子化子問題，並根據 WebSearcher 的搜尋結果逐步延伸圖形。WebSearcher 以每個子問題為任務，執行搜尋引擎的分層式資訊擷取，並為 WebPlanner 收集有價值的資訊。MindSearch 的多代理設計讓整個架構可以在 3 分鐘內平行地從更大規模（例如超過 300 個）的網頁中搜尋並整合資訊，這相當於 3 小時的人力。MindSearch 在深度和廣度方面都顯著提升了回應品質，無論是在封閉式或開放式問答問題上。此外，人類更偏好基於 InternLM2.5-7B 的 MindSearch 回應，勝過 ChatGPT-Web 和 Perplexity.ai 應用程式，這表示 MindSearch 已經可以為專有 AI 搜尋引擎提供有競爭力的解決方案。

##### **Theia: Distilling Diverse Vision Foundation Models for Robot Learning**
2407.20179v1 by Jinghuan Shang, Karl Schmeckpeper, Brandon B. May, Maria Vittoria Minniti, Tarik Kelestemur, David Watkins, Laura Herlant

Vision-based robot policy learning, which maps visual inputs to actions,
necessitates a holistic understanding of diverse visual tasks beyond
single-task needs like classification or segmentation. Inspired by this, we
introduce Theia, a vision foundation model for robot learning that distills
multiple off-the-shelf vision foundation models trained on varied vision tasks.
Theia's rich visual representations encode diverse visual knowledge, enhancing
downstream robot learning. Extensive experiments demonstrate that Theia
outperforms its teacher models and prior robot learning models using less
training data and smaller model sizes. Additionally, we quantify the quality of
pre-trained visual representations and hypothesize that higher entropy in
feature norm distributions leads to improved robot learning performance. Code
and models are available at https://github.com/bdaiinstitute/theia.

摘要：基於視覺的機器人策略學習，將視覺輸入對應到動作，需要對多樣化視覺任務有整體的理解，超越單一任務需求，例如分類或分割。受到此啟發，我們介紹 Theia，這是一個機器人學習的視覺基礎模型，它萃取多個針對不同視覺任務訓練的現成視覺基礎模型。Theia 豐富的視覺表徵編碼多樣化的視覺知識，增強下游機器人學習。廣泛的實驗證明，Theia 使用較少的訓練資料和較小的模型大小，就能超越其教師模型和先前的機器人學習模型。此外，我們量化預訓練視覺表徵的品質，並假設特徵範數分佈中較高的熵會帶來改善的機器人學習效能。程式碼和模型可在 https://github.com/bdaiinstitute/theia 取得。

##### **AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs**
2407.20177v1 by Feiyang Kang, Yifan Sun, Bingbing Wen, Si Chen, Dawn Song, Rafid Mahmood, Ruoxi Jia

To ensure performance on a diverse set of downstream tasks, LLMs are
pretrained via data mixtures over different domains. In this work, we
demonstrate that the optimal data composition for a fixed compute budget varies
depending on the scale of the training data, suggesting that the common
practice of empirically determining an optimal composition using small-scale
experiments will not yield the optimal data mixtures when scaling up to the
final model. To address this challenge, we propose *AutoScale*, an automated
tool that finds a compute-optimal data composition for training at any desired
target scale. AutoScale first determines the optimal composition at a small
scale using a novel bilevel optimization framework, Direct Data Optimization
(*DDO*), and then fits a predictor to estimate the optimal composition at
larger scales. The predictor's design is inspired by our theoretical analysis
of scaling laws related to data composition, which could be of independent
interest. In empirical studies with pre-training 774M Decoder-only LMs (GPT-2
Large) on RedPajama dataset, AutoScale decreases validation perplexity at least
25% faster than any baseline with up to 38% speed up compared to without
reweighting, achieving the best overall performance across downstream tasks. On
pre-training Encoder-only LMs (BERT) with masked language modeling, DDO is
shown to decrease loss on all domains while visibly improving average task
performance on GLUE benchmark by 8.7% and on large-scale QA dataset (SQuAD) by
5.9% compared with without reweighting. AutoScale speeds up training by up to
28%. Our codes are open-sourced.

摘要：<paragraph>為了確保在各種下游任務上的效能，LLM 會透過不同領域的資料混合進行預先訓練。在這項工作中，我們證明了在固定的運算預算下，最佳的資料組成會依訓練資料的規模而有所不同，這表示在擴充到最終模型時，使用小規模實驗來經驗性地決定最佳組成的常見做法，將無法產生最佳的資料混合。為了應對這項挑戰，我們提出了「AutoScale」，一個自動化工具，可以為任何所需的目標規模的訓練找到一個運算最佳的資料組成。AutoScale 首先使用一種新穎的雙層次最佳化架構，直接資料最佳化（DDO），來決定小規模的最佳組成，然後擬合一個預測器來估計較大規模的最佳組成。預測器的設計靈感來自我們對與資料組成相關的規模定律的理論分析，這可能是獨立的興趣。在使用預訓練 774M 僅解碼器 LMs（GPT-2 Large）於 RedPajama 資料集進行的實證研究中，AutoScale 驗證困惑度降低的速度比任何基線快至少 25%，與不重新加權相比，速度提升多達 38%，在所有下游任務中都取得最佳的整體效能。在使用遮罩語言模型預訓練僅編碼器 LMs（BERT）時，DDO 已被證明可以減少所有領域的損失，同時在 GLUE 基準上將平均任務效能顯著提升 8.7%，在大型 QA 資料集（SQuAD）上提升 5.9%，與不重新加權相比。AutoScale 將訓練速度提升多達 28%。我們的程式碼是開源的。</paragraph>

##### **Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation**
2407.20176v1 by Jingyue Huang, Yi-Hsuan Yang

Emotion-driven melody harmonization aims to generate diverse harmonies for a
single melody to convey desired emotions. Previous research found it hard to
alter the perceived emotional valence of lead sheets only by harmonizing the
same melody with different chords, which may be attributed to the constraints
imposed by the melody itself and the limitation of existing music
representation. In this paper, we propose a novel functional representation for
symbolic music. This new method takes musical keys into account, recognizing
their significant role in shaping music's emotional character through
major-minor tonality. It also allows for melodic variation with respect to keys
and addresses the problem of data scarcity for better emotion modeling. A
Transformer is employed to harmonize key-adaptable melodies, allowing for keys
determined in rule-based or model-based manner. Experimental results confirm
the effectiveness of our new representation in generating key-aware harmonies,
with objective and subjective evaluations affirming the potential of our
approach to convey specific valence for versatile melody.

摘要：情感驅動的旋律和聲化旨在為單一旋律產生多樣化的和聲，以傳達所需的的情緒。先前的研究發現，僅通過使用不同的和弦來和聲化同一旋律，很難改變主旋律的感知情緒價，這可能歸因於旋律本身的約束和現有音樂表現形式的限制。在本文中，我們提出了一個符號音樂的新功能表示。這種新方法考慮了音樂的調性，承認了它們通過大調小調音調塑造音樂的情感特徵的重要作用。它還允許根據調性進行旋律變化，並解決了數據稀疏的問題，以進行更好的情緒建模。採用 Transformer 來和聲化可調整調性的旋律，允許以基於規則或基於模型的方式確定調性。實驗結果證實了我們的新表示在產生調性感知和聲方面的有效性，客觀和主觀評估肯定了我們的方法在傳達多功能旋律的特定價的潛力。

##### **Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning**
2407.20174v1 by Xingchen Zeng, Haichuan Lin, Yilin Ye, Wei Zeng

Emerging multimodal large language models (MLLMs) exhibit great potential for
chart question answering (CQA). Recent efforts primarily focus on scaling up
training datasets (i.e., charts, data tables, and question-answer (QA) pairs)
through data collection and synthesis. However, our empirical study on existing
MLLMs and CQA datasets reveals notable gaps. First, current data collection and
synthesis focus on data volume and lack consideration of fine-grained visual
encodings and QA tasks, resulting in unbalanced data distribution divergent
from practical CQA scenarios. Second, existing work follows the training recipe
of the base MLLMs initially designed for natural images, under-exploring the
adaptation to unique chart characteristics, such as rich text elements. To fill
the gap, we propose a visualization-referenced instruction tuning approach to
guide the training dataset enhancement and model development. Specifically, we
propose a novel data engine to effectively filter diverse and high-quality data
from existing datasets and subsequently refine and augment the data using
LLM-based generation techniques to better align with practical QA tasks and
visual encodings. Then, to facilitate the adaptation to chart characteristics,
we utilize the enriched data to train an MLLM by unfreezing the vision encoder
and incorporating a mixture-of-resolution adaptation strategy for enhanced
fine-grained recognition. Experimental results validate the effectiveness of
our approach. Even with fewer training examples, our model consistently
outperforms state-of-the-art CQA models on established benchmarks. We also
contribute a dataset split as a benchmark for future research. Source codes and
datasets of this paper are available at
https://github.com/zengxingchen/ChartQA-MLLM.

摘要：新興的多模態大型語言模型 (MLLM) 在圖表問答 (CQA) 方面展現了巨大的潛力。最近的研究主要著重於透過資料收集和綜合，擴充訓練資料集（即圖表、資料表格和問答 (QA) 配對）。然而，我們對現有 MLLM 和 CQA 資料集的實證研究揭露了顯著的差距。首先，目前的資料收集和綜合著重於資料量，而忽略了細微的視覺編碼和 QA 任務，導致不平衡的資料分佈與實際 CQA 情境產生差異。其次，現有研究遵循最初為自然影像設計的基本 MLLM 訓練範例，低估了對圖表獨特特徵（例如豐富的文字元素）的適應性。為了填補這個差距，我們提出了一種以視覺化參考的指令調整方法，以引導訓練資料集的增強和模型開發。具體來說，我們提出了一種新穎的資料引擎，以有效地從現有資料集中過濾多樣化且高品質的資料，並隨後使用基於 LLM 的生成技術精煉和擴充資料，以更好地與實際的 QA 任務和視覺編碼保持一致。然後，為了促進對圖表特徵的適應，我們利用豐富的資料來訓練 MLLM，方法是解凍視覺編碼器，並結合混合解析度適應策略，以增強細微的辨識能力。實驗結果驗證了我們方法的有效性。即使訓練範例較少，我們的模型在既有的基準上仍持續優於最先進的 CQA 模型。我們也貢獻了一個資料集分割，作為未來研究的基準。本文的原始碼和資料集可以在 https://github.com/zengxingchen/ChartQA-MLLM 取得。

##### **LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework**
2407.20172v1 by Zhenqi He, Wenrui Liu, Minghao Yin, Kai Han

Histological artifacts pose challenges for both pathologists and
Computer-Aided Diagnosis (CAD) systems, leading to errors in analysis. Current
approaches for histological artifact restoration, based on Generative
Adversarial Networks (GANs) and pixel-level Diffusion Models, suffer from
performance limitations and computational inefficiencies. In this paper, we
propose a novel framework, LatentArtiFusion, which leverages the latent
diffusion model (LDM) to reconstruct histological artifacts with high
performance and computational efficiency. Unlike traditional pixel-level
diffusion frameworks, LatentArtiFusion executes the restoration process in a
lower-dimensional latent space, significantly improving computational
efficiency. Moreover, we introduce a novel regional artifact reconstruction
algorithm in latent space to prevent mistransfer in non-artifact regions,
distinguishing our approach from GAN-based methods. Through extensive
experiments on real-world histology datasets, LatentArtiFusion demonstrates
remarkable speed, outperforming state-of-the-art pixel-level diffusion
frameworks by more than 30X. It also consistently surpasses GAN-based methods
by at least 5% across multiple evaluation metrics. Furthermore, we evaluate the
effectiveness of our proposed framework in downstream tissue classification
tasks, showcasing its practical utility. Code is available at
https://github.com/bugs-creator/LatentArtiFusion.

摘要：組織病理學製品對病理學家和電腦輔助診斷 (CAD) 系統構成挑戰，導致分析錯誤。目前基於生成對抗網路 (GAN) 和像素級擴散模型的組織病理學製品修復方法，存在效能限制和運算效率低下的問題。在本文中，我們提出一個創新的架構 LatentArtiFusion，它利用潛在擴散模型 (LDM) 以高性能和運算效率重建組織病理學製品。與傳統的像素級擴散架構不同，LatentArtiFusion 在較低維度的潛在空間中執行修復程序，大幅提升運算效率。此外，我們在潛在空間中引入一種新穎的區域製品重建演算法，以防止非製品區域的錯誤傳輸，將我們的方法與基於 GAN 的方法區分開來。透過對真實世界組織病理學資料集進行廣泛的實驗，LatentArtiFusion 展現出驚人的速度，效能優於最先進的像素級擴散架構 30 倍以上。它還透過多項評估指標，始終優於基於 GAN 的方法至少 5%。此外，我們評估了我們提出的架構在下游組織分類任務中的有效性，展示了它的實用性。程式碼可於 https://github.com/bugs-creator/LatentArtiFusion 取得。

##### **Language-Conditioned Offline RL for Multi-Robot Navigation**
2407.20164v1 by Steven Morad, Ajay Shankar, Jan Blumenkamp, Amanda Prorok

We present a method for developing navigation policies for multi-robot teams
that interpret and follow natural language instructions. We condition these
policies on embeddings from pretrained Large Language Models (LLMs), and train
them via offline reinforcement learning with as little as 20 minutes of
randomly-collected data. Experiments on a team of five real robots show that
these policies generalize well to unseen commands, indicating an understanding
of the LLM latent space. Our method requires no simulators or environment
models, and produces low-latency control policies that can be deployed directly
to real robots without finetuning. We provide videos of our experiments at
https://sites.google.com/view/llm-marl.

摘要：我們提出了一種為多機器人團隊開發導航策略的方法，該策略會解譯和遵循自然語言指令。我們根據預訓練大型語言模型 (LLM) 的嵌入來設定這些策略，並透過離線強化學習訓練它們，所需資料少至 20 分鐘的隨機收集資料。對五個真實機器人團隊進行的實驗顯示，這些策略可以很好地概括到未見過的命令，這表示對 LLM 潛在空間的理解。我們的模型不需要模擬器或環境模型，而且產生的低延遲控制策略可以直接部署到真實機器人，而無需微調。我們在 https://sites.google.com/view/llm-marl 提供了我們的實驗影片。

##### **rLLM: Relational Table Learning with LLMs**
2407.20157v1 by Weichen Li, Xiaotong Huang, Jianwu Zheng, Zheng Wang, Chaokun Wang, Li Pan, Jianhua Li

We introduce rLLM (relationLLM), a PyTorch library designed for Relational
Table Learning (RTL) with Large Language Models (LLMs). The core idea is to
decompose state-of-the-art Graph Neural Networks, LLMs, and Table Neural
Networks into standardized modules, to enable the fast construction of novel
RTL-type models in a simple "combine, align, and co-train" manner. To
illustrate the usage of rLLM, we introduce a simple RTL method named
\textbf{BRIDGE}. Additionally, we present three novel relational tabular
datasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hope
rLLM can serve as a useful and easy-to-use development framework for
RTL-related tasks. Our code is available at:
https://github.com/rllm-project/rllm.

摘要：我們引入了 rLLM (relationLLM)，一個專為大型語言模型 (LLM) 的關係表學習 (RTL) 所設計的 PyTorch 函式庫。核心概念是將最先進的圖形神經網路、LLM 和表神經網路分解為標準化模組，以便以簡單的「組合、對齊和共同訓練」方式快速建構新型 RTL 類型模型。為了說明 rLLM 的用法，我們引入了名為 \textbf{BRIDGE} 的簡單 RTL 方法。此外，我們透過強化經典資料集來呈現三個新穎的關係表格資料集 (TML1M、TLF2K 和 TACM12K)。我們希望 rLLM 能夠作為 RTL 相關任務有用的且易於使用的開發架構。我們的程式碼可在以下網址取得：
https://github.com/rllm-project/rllm。

##### **Quantum Machine Learning Architecture Search via Deep Reinforcement Learning**
2407.20147v1 by Xin Dai, Tzu-Chieh Wei, Shinjae Yoo, Samuel Yen-Chi Chen

The rapid advancement of quantum computing (QC) and machine learning (ML) has
given rise to the burgeoning field of quantum machine learning (QML), aiming to
capitalize on the strengths of quantum computing to propel ML forward. Despite
its promise, crafting effective QML models necessitates profound expertise to
strike a delicate balance between model intricacy and feasibility on Noisy
Intermediate-Scale Quantum (NISQ) devices. While complex models offer robust
representation capabilities, their extensive circuit depth may impede seamless
execution on extant noisy quantum platforms. In this paper, we address this
quandary of QML model design by employing deep reinforcement learning to
explore proficient QML model architectures tailored for designated supervised
learning tasks. Specifically, our methodology involves training an RL agent to
devise policies that facilitate the discovery of QML models without
predetermined ansatz. Furthermore, we integrate an adaptive mechanism to
dynamically adjust the learning objectives, fostering continuous improvement in
the agent's learning process. Through extensive numerical simulations, we
illustrate the efficacy of our approach within the realm of classification
tasks. Our proposed method successfully identifies VQC architectures capable of
achieving high classification accuracy while minimizing gate depth. This
pioneering approach not only advances the study of AI-driven quantum circuit
design but also holds significant promise for enhancing performance in the NISQ
era.

摘要：量子運算 (QC) 和機器學習 (ML) 的快速進展已催生出蓬勃發展的量子機器學習 (QML) 領域，旨在利用量子運算的優勢來推動 ML 的進步。儘管前景看好，但打造有效的 QML 模型需要深厚的專業知識，才能在雜訊中型量子 (NISQ) 裝置上，在模型複雜性和可行性之間取得微妙的平衡。雖然複雜的模型提供了強大的表示能力，但其廣泛的電路深度可能會阻礙在現有的雜訊量子平台上進行無縫執行。在本文中，我們通過採用深度強化學習來探索針對指定監督學習任務量身打造的熟練 QML 模型架構，來解決 QML 模型設計的這個難題。具體來說，我們的方法涉及訓練一個 RL 代理，以制定策略，促進在沒有預定 ansatz 的情況下發現 QML 模型。此外，我們整合了一個自適應機制來動態調整學習目標，促進代理學習過程中持續改進。通過廣泛的數值模擬，我們說明了我們的方法在分類任務領域內的功效。我們提出的方法成功識別出 VQC 架構，該架構能夠在最小化閘極深度的情況下實現高分類準確度。這種開創性的方法不僅推動了 AI 驅動的量子電路設計研究，而且也為增強 NISQ 時代的性能提供了重大的前景。

##### **ByteCheckpoint: A Unified Checkpointing System for LLM Development**
2407.20143v1 by Borui Wan, Mingji Han, Yiyao Sheng, Zhichao Lai, Mofan Zhang, Junda Zhang, Yanghua Peng, Haibin Lin, Xin Liu, Chuan Wu

The development of real-world Large Language Models (LLMs) necessitates
checkpointing of training states in persistent storage to mitigate potential
software and hardware failures, as well as to facilitate checkpoint
transferring within the training pipeline and across various tasks. Due to the
immense size of LLMs, saving and loading checkpoints often incur intolerable
minute-level stalls, significantly diminishing training efficiency. Besides,
when transferring checkpoints across tasks, checkpoint resharding, defined as
loading checkpoints into parallel configurations differing from those used for
saving, is often required according to the characteristics and resource quota
of specific tasks. Previous checkpointing systems [16,3,33,6] assume consistent
parallel configurations, failing to address the complexities of checkpoint
transformation during resharding. Furthermore, in the industry platform,
developers create checkpoints from different training frameworks[23,36,21,11],
each with its own unique storage and I/O logic. This diversity complicates the
implementation of unified checkpoint management and optimization. To address
these challenges, we introduce ByteCheckpoint, a PyTorch-native multi-framework
LLM checkpointing system that supports automatic online checkpoint resharding.
ByteCheckpoint employs a data/metadata disaggregated storage architecture,
decoupling checkpoint storage from the adopted parallelism strategies and
training frameworks. We design an efficient asynchronous tensor merging
technique to settle the irregular tensor sharding problem and propose several
I/O performance optimizations to significantly enhance the efficiency of
checkpoint saving and loading. Experimental results demonstrate
ByteCheckpoint's substantial advantages in reducing checkpoint saving (by up to
529.22X) and loading (by up to 3.51X) costs, compared to baseline methods.

摘要：<paragraph>由於軟體和硬體故障的潛在風險，以及為了在訓練流程和各種任務中促進檢查點轉移，現實世界的大型語言模型 (LLM) 的開發需要將訓練狀態檢查點儲存在永久儲存裝置中以減輕風險。由於 LLM 的規模龐大，儲存和載入檢查點通常會造成無法忍受的分鐘級停滯，大幅降低訓練效率。此外，在任務間轉移檢查點時，通常需要根據特定任務的特徵和資源配額，將檢查點重新分片，這定義為將檢查點載入與儲存時不同的平行組態。先前的檢查點系統 [16,3,33,6] 假設一致的平行組態，無法解決重新分片期間檢查點轉換的複雜性。此外，在產業平台中，開發人員會從不同的訓練架構 [23,36,21,11] 建立檢查點，每個架構都有自己獨特的儲存和 I/O 邏輯。這種多樣性讓統一的檢查點管理和最佳化的實作變得複雜。為了應對這些挑戰，我們引入了 ByteCheckpoint，一個 PyTorch 原生的多架構 LLM 檢查點系統，它支援自動線上檢查點重新分片。ByteCheckpoint 使用資料/元資料分離儲存架構，將檢查點儲存與採用的平行處理策略和訓練架構脫鉤。我們設計了一種高效的非同步張量合併技術來解決不規則張量分片問題，並提出多項 I/O 效能最佳化措施，以大幅提升檢查點儲存和載入的效率。實驗結果證明，與基線方法相比，ByteCheckpoint 在減少檢查點儲存 (最多減少 529.22 倍) 和載入 (最多減少 3.51 倍) 成本方面具有顯著優勢。</paragraph>

##### **To accept or not to accept? An IRT-TOE Framework to Understand Educators' Resistance to Generative AI in Higher Education**
2407.20130v1 by Jan-Erik Kalmus, Anastasija Nikiforova

Since the public release of Chat Generative Pre-Trained Transformer
(ChatGPT), extensive discourse has emerged concerning the potential advantages
and challenges of integrating Generative Artificial Intelligence (GenAI) into
education. In the realm of information systems, research on technology adoption
is crucial for understanding the diverse factors influencing the uptake of
specific technologies. Theoretical frameworks, refined and validated over
decades, serve as guiding tools to elucidate the individual and organizational
dynamics, obstacles, and perceptions surrounding technology adoption. However,
while several models have been proposed, they often prioritize elucidating the
factors that facilitate acceptance over those that impede it, typically
focusing on the student perspective and leaving a gap in empirical evidence
regarding educators viewpoints. Given the pivotal role educators play in higher
education, this study aims to develop a theoretical model to empirically
predict the barriers preventing educators from adopting GenAI in their
classrooms. Acknowledging the lack of theoretical models tailored to
identifying such barriers, our approach is grounded in the Innovation
Resistance Theory (IRT) framework and augmented with constructs from the
Technology-Organization-Environment (TOE) framework. This model is transformed
into a measurement instrument employing a quantitative approach, complemented
by a qualitative approach to enrich the analysis and uncover concerns related
to GenAI adoption in the higher education domain.

摘要：自從 Chat Generative Pre-Trained Transformer (ChatGPT) 公開發布以來，關於將生成式人工智慧 (GenAI) 整合到教育中的潛在優點和挑戰，已經出現廣泛的討論。在資訊系統領域中，技術採用研究對於了解影響特定技術採用率的不同因素至關重要。經過數十年提煉和驗證的理論架構，可用作指導工具，用以闡明與技術採用相關的個人和組織動態、障礙和認知。然而，儘管已經提出多種模型，但它們通常優先闡明促進接受的因素，甚於阻礙接受的因素，通常側重於學生的觀點，並在實證證據方面留下有關教育者觀點的空白。鑑於教育者在高等教育中扮演著舉足輕重的角色，本研究旨在開發一個理論模型，以實證預測阻礙教育者在其課堂中採用 GenAI 的障礙。承認缺乏量身打造以找出此類障礙的理論模型，我們的做法以創新抗拒理論 (IRT) 架構為基礎，並結合技術-組織-環境 (TOE) 架構中的構念進行擴充。此模型轉變為採用量化方法的測量工具，並輔以質化方法以豐富分析，並揭露與高等教育領域中採用 GenAI 相關的疑慮。

##### **AxiomVision: Accuracy-Guaranteed Adaptive Visual Model Selection for Perspective-Aware Video Analytics**
2407.20124v1 by Xiangxiang Dai, Zeyu Zhang, Peng Yang, Yuedong Xu, Xutong Liu, John C. S. Lui

The rapid evolution of multimedia and computer vision technologies requires
adaptive visual model deployment strategies to effectively handle diverse tasks
and varying environments. This work introduces AxiomVision, a novel framework
that can guarantee accuracy by leveraging edge computing to dynamically select
the most efficient visual models for video analytics under diverse scenarios.
Utilizing a tiered edge-cloud architecture, AxiomVision enables the deployment
of a broad spectrum of visual models, from lightweight to complex DNNs, that
can be tailored to specific scenarios while considering camera source impacts.
In addition, AxiomVision provides three core innovations: (1) a dynamic visual
model selection mechanism utilizing continual online learning, (2) an efficient
online method that efficiently takes into account the influence of the camera's
perspective, and (3) a topology-driven grouping approach that accelerates the
model selection process. With rigorous theoretical guarantees, these
advancements provide a scalable and effective solution for visual tasks
inherent to multimedia systems, such as object detection, classification, and
counting. Empirically, AxiomVision achieves a 25.7\% improvement in accuracy.

摘要：多媒體和電腦視覺技術的快速演進需要自適應視覺模型部署策略，才能有效處理各種任務和變動的環境。本研究介紹了 AxiomVision，這是一個新穎的架構，它可以透過利用邊緣運算來動態選擇在各種情況下影片分析最有效的視覺模型，從而保證準確度。AxiomVision 利用分層邊緣雲架構，可以部署從輕量級到複雜 DNN 的廣泛視覺模型，這些模型可以根據具體情況進行調整，同時考慮相機來源的影響。此外，AxiomVision 提供了三項核心創新：(1) 利用持續在線學習的動態視覺模型選擇機制，(2) 有效考慮相機視角影響的有效在線方法，以及 (3) 加速模型選擇過程的拓撲驅動分組方法。透過嚴謹的理論保證，這些進展為多媒體系統固有的視覺任務（例如物件偵測、分類和計數）提供了一個可擴充且有效的解決方案。根據經驗，AxiomVision 在準確度方面獲得了 25.7% 的提升。

##### **EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation**
2407.20121v1 by Lei Huang, Weitao Li, Chenrui Zhang, Jinpeng Wang, Xianchun Yi, Sheng Chen

Cross-domain recommendation has attracted substantial interest in industrial
apps such as Meituan, which serves multiple business domains via knowledge
transfer and meets the diverse interests of users. However, existing methods
typically follow an implicit modeling paradigm that blends the knowledge from
both the source and target domains, and design intricate network structures to
share learned embeddings or patterns between domains to improve recommendation
accuracy. Since the transfer of interest signals is unsupervised, these
implicit paradigms often struggle with the negative transfer resulting from
differences in service functions and presentation forms across different
domains. In this paper, we propose a simple and effective EXplicit Interest
Transfer framework named EXIT to address the stated challenge. Specifically, we
propose a novel label combination approach that enables the model to directly
learn beneficial source domain interests through supervised learning, while
excluding inappropriate interest signals. Moreover, we introduce a scene
selector network to model the interest transfer intensity under fine-grained
scenes. Offline experiments conducted on the industrial production dataset and
online A/B tests validate the superiority and effectiveness of our proposed
framework. Without complex network structures or training processes, EXIT can
be easily deployed in the industrial recommendation system. EXIT has been
successfully deployed in the online homepage recommendation system of Meituan
App, serving the main traffic.

摘要：跨域推薦在工業應用中引起了極大的興趣，例如美團，它通過知識轉移服務於多個業務領域，並滿足了用戶的多樣化興趣。然而，現有方法通常遵循隱式建模範例，該範例融合了源域和目標域的知識，並設計複雜的網路結構，以在域之間共享學習的嵌入或模式，以提高推薦準確度。由於興趣信號的傳遞不受監督，因此這些隱式範例通常難以應對由於不同域之間的服務功能和呈現形式的差異而產生的負面傳遞。在本文中，我們提出了一個簡單有效的 EXplicit Interest Transfer 框架，名為 EXIT，以應對所述挑戰。具體來說，我們提出了一種新穎的標籤組合方法，使模型能夠通過監督學習直接學習有益的源域興趣，同時排除不適當的興趣信號。此外，我們引入了一個場景選擇器網路，以在細粒度場景下對興趣傳遞強度進行建模。在工業生產資料集上進行的離線實驗和線上 A/B 測試驗證了我們提出的框架的優越性和有效性。EXIT 可以在沒有複雜網路結構或訓練過程的情況下輕鬆部署在工業推薦系統中。EXIT 已成功部署在美團 App 的線上首頁推薦系統中，服務於主要流量。

##### **Adaptive Self-supervised Robust Clustering for Unstructured Data with Unknown Cluster Number**
2407.20119v1 by Chen-Lu Ding, Jiancan Wu, Wei Lin, Shiyang Shen, Xiang Wang, Yancheng Yuan

We introduce a novel self-supervised deep clustering approach tailored for
unstructured data without requiring prior knowledge of the number of clusters,
termed Adaptive Self-supervised Robust Clustering (ASRC). In particular, ASRC
adaptively learns the graph structure and edge weights to capture both local
and global structural information. The obtained graph enables us to learn
clustering-friendly feature representations by an enhanced graph auto-encoder
with contrastive learning technique. It further leverages the clustering
results adaptively obtained by robust continuous clustering (RCC) to generate
prototypes for negative sampling, which can further contribute to promoting
consistency among positive pairs and enlarging the gap between positive and
negative samples. ASRC obtains the final clustering results by applying RCC to
the learned feature representations with their consistent graph structure and
edge weights. Extensive experiments conducted on seven benchmark datasets
demonstrate the efficacy of ASRC, demonstrating its superior performance over
other popular clustering models. Notably, ASRC even outperforms methods that
rely on prior knowledge of the number of clusters, highlighting its
effectiveness in addressing the challenges of clustering unstructured data.

摘要：我們引入一種新穎的自監督深度聚類方法，專門針對非結構化數據，而無需事先了解群集數，稱為自適應自監督穩健聚類 (ASRC)。特別是，ASRC 自適應地學習圖形結構和邊權重，以擷取局部和全局結構資訊。所獲得的圖形使我們能夠透過增強的圖形自動編碼器與對比學習技術，學習群集友善的特徵表示。它進一步利用穩健連續聚類 (RCC) 自適應獲得的聚類結果，為負面抽樣產生原型，進一步有助於促進正對之間的一致性，並擴大正負樣本之間的差距。ASRC 將 RCC 套用到學習到的特徵表示及其一致的圖形結構和邊權重，以獲得最終的聚類結果。在七個基準資料集上進行的廣泛實驗證明了 ASRC 的功效，證明其效能優於其他流行的聚類模型。值得注意的是，ASRC 甚至優於依賴於群集數事前知識的方法，突顯了其在解決非結構化數據聚類挑戰方面的有效性。

##### **FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis**
2407.20114v1 by Mikel Williams-Lekuona, Georgina Cosma

In the field of Image-Text Retrieval (ITR), recent advancements have
leveraged large-scale Vision-Language Pretraining (VLP) for Fine-Grained (FG)
instance-level retrieval, achieving high accuracy at the cost of increased
computational complexity. For Coarse-Grained (CG) category-level retrieval,
prominent approaches employ Cross-Modal Hashing (CMH) to prioritise efficiency,
albeit at the cost of retrieval performance. Due to differences in
methodologies, FG and CG models are rarely compared directly within evaluations
in the literature, resulting in a lack of empirical data quantifying the
retrieval performance-efficiency tradeoffs between the two. This paper
addresses this gap by introducing the \texttt{FiCo-ITR} library, which
standardises evaluation methodologies for both FG and CG models, facilitating
direct comparisons. We conduct empirical evaluations of representative models
from both subfields, analysing precision, recall, and computational complexity
across varying data scales. Our findings offer new insights into the
performance-efficiency trade-offs between recent representative FG and CG
models, highlighting their respective strengths and limitations. These findings
provide the foundation necessary to make more informed decisions regarding
model selection for specific retrieval tasks and highlight avenues for future
research into hybrid systems that leverage the strengths of both FG and CG
approaches.

摘要：在影像文字檢索 (ITR) 領域，最近的進展已利用大規模視覺語言預訓練 (VLP) 進行細粒度 (FG) 個體層級檢索，以增加運算複雜度為代價，達成高準確度。對於粗粒度 (CG) 類別層級檢索，著名的做法採用跨模態雜湊 (CMH) 優先考量效率，儘管是以犧牲檢索效能為代價。由於方法論不同，FG 與 CG 模型在文獻中的評估中很少直接比較，導致缺乏量化兩者之間檢索效能與效率折衷的經驗數據。本文透過引入 \texttt{FiCo-ITR} 庫來解決這個差距，該庫標準化了 FG 與 CG 模型的評估方法，促成直接比較。我們對兩個子領域的代表性模型進行經驗評估，分析不同數據規模下的精準度、召回率和運算複雜度。我們的發現提供了對近期代表性 FG 和 CG 模型之間效能與效率折衷的新見解，強調它們各自的優點和限制。這些發現提供了必要的基礎，以便針對特定檢索任務做出更明智的模型選擇決策，並強調了未來研究混合系統的途徑，該系統利用 FG 和 CG 方法的優點。

##### **Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning**
2407.20109v1 by Liyuan Mao, Haoran Xu, Weinan Zhang, Xianyuan Zhan, Amy Zhang

One important property of DIstribution Correction Estimation (DICE) methods
is that the solution is the optimal stationary distribution ratio between the
optimized and data collection policy. In this work, we show that DICE-based
methods can be viewed as a transformation from the behavior distribution to the
optimal policy distribution. Based on this, we propose a novel approach,
Diffusion-DICE, that directly performs this transformation using diffusion
models. We find that the optimal policy's score function can be decomposed into
two terms: the behavior policy's score function and the gradient of a guidance
term which depends on the optimal distribution ratio. The first term can be
obtained from a diffusion model trained on the dataset and we propose an
in-sample learning objective to learn the second term. Due to the
multi-modality contained in the optimal policy distribution, the transformation
in Diffusion-DICE may guide towards those local-optimal modes. We thus generate
a few candidate actions and carefully select from them to approach
global-optimum. Different from all other diffusion-based offline RL methods,
the guide-then-select paradigm in Diffusion-DICE only uses in-sample actions
for training and brings minimal error exploitation in the value function. We
use a didatic toycase example to show how previous diffusion-based methods fail
to generate optimal actions due to leveraging these errors and how
Diffusion-DICE successfully avoids that. We then conduct extensive experiments
on benchmark datasets to show the strong performance of Diffusion-DICE.

摘要：分佈修正估計 (DICE) 方法的一個重要屬性是，解為最佳化和資料收集政策之間的最佳穩態分佈比率。在這項工作中，我們展示基於 DICE 的方法可以視為從行為分佈到最佳政策分佈的轉換。基於此，我們提出了一種新穎的方法，擴散-DICE，它使用擴散模型直接執行此轉換。我們發現最佳政策的評分函數可以分解為兩個術語：行為政策的評分函數和依賴於最佳分佈比率的引導項的梯度。第一個術語可以從在資料集上訓練的擴散模型中獲得，我們提出了一個樣本內學習目標來學習第二個術語。由於最佳政策分佈中包含多模態，因此擴散-DICE 中的轉換可能會朝向那些局部最佳模式。因此，我們會產生一些候選動作，並從中仔細選擇以接近全局最優。與所有其他基於擴散的離線 RL 方法不同，擴散-DICE 中的先引導後選擇範例僅使用樣本內動作進行訓練，並在價值函數中帶來最小的錯誤利用。我們使用一個教學玩具案例來說明先前的基於擴散的方法如何因利用這些錯誤而無法產生最佳動作，以及擴散-DICE 如何成功避免這種情況。然後，我們在基準資料集上進行廣泛的實驗，以展示擴散-DICE 的強大效能。

##### **Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**
2407.20108v1 by Ruochen Li, Jiazhen Pan, Youxiang Zhu, Juncheng Ni, Daniel Rueckert

Cardiac Magnetic Resonance Imaging (CMR) is the gold standard for diagnosing
cardiovascular diseases. Clinical diagnoses predominantly rely on
magnitude-only Digital Imaging and Communications in Medicine (DICOM) images,
omitting crucial phase information that might provide additional diagnostic
benefits. In contrast, k-space is complex-valued and encompasses both magnitude
and phase information, while humans cannot directly perceive. In this work, we
propose KMAE, a Transformer-based model specifically designed to process
k-space data directly, eliminating conventional intermediary conversion steps
to the image domain. KMAE can handle critical cardiac disease classification,
relevant phenotype regression, and cardiac morphology segmentation tasks. We
utilize this model to investigate the potential of k-space-based diagnosis in
cardiac MRI. Notably, this model achieves competitive classification and
regression performance compared to image-domain methods e.g. Masked
Autoencoders (MAEs) and delivers satisfactory segmentation performance with a
myocardium dice score of 0.884. Last but not least, our model exhibits robust
performance with consistent results even when the k-space is 8* undersampled.
We encourage the MR community to explore the untapped potential of k-space and
pursue end-to-end, automated diagnosis with reduced human intervention.

摘要：心臟磁振造影 (CMR) 是診斷心血管疾病的黃金標準。臨床診斷主要依賴於醫學數位影像和通訊 (DICOM) 影像的幅度，而忽略了可能提供額外診斷好處的關鍵相位資訊。相較之下，k 空間是複數值且包含幅度和相位資訊，但人類無法直接感知。在這項工作中，我們提出 KMAE，一種特別設計用於直接處理 k 空間資料的 Transformer 基礎模型，消除了轉換到影像領域的傳統中介步驟。KMAE 可以處理關鍵的心臟疾病分類、相關表型回歸和心臟形態分割任務。我們利用此模型探討 k 空間基礎診斷在心臟 MRI 中的潛力。值得注意的是，與影像領域方法（例如遮罩式自動編碼器 (MAE)）相比，此模型達到了競爭性的分類和回歸效能，並以 0.884 的心肌骰子分數提供了令人滿意的分割效能。最後但並非最不重要的一點是，即使在 k 空間不足採樣 8* 時，我們的模型也能展現穩健的效能和一致的結果。我們鼓勵核磁共振社群探索 k 空間的未開發潛力，並追求減少人為干預的端到端自動化診斷。

##### **F-KANs: Federated Kolmogorov-Arnold Networks**
2407.20100v1 by Engin Zeydan, Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, Marius Caus, Abdullah Aydeger

In this paper, we present an innovative federated learning (FL) approach that
utilizes Kolmogorov-Arnold Networks (KANs) for classification tasks. By
utilizing the adaptive activation capabilities of KANs in a federated
framework, we aim to improve classification capabilities while preserving
privacy. The study evaluates the performance of federated KANs (F- KANs)
compared to traditional Multi-Layer Perceptrons (MLPs) on classification task.
The results show that the F-KANs model significantly outperforms the federated
MLP model in terms of accuracy, precision, recall, F1 score and stability, and
achieves better performance, paving the way for more efficient and
privacy-preserving predictive analytics.

摘要：在本文中，我們提出了一種創新的聯邦學習 (FL) 方法，它利用 Kolmogorov-Arnold 網路 (KAN) 進行分類任務。通過在聯邦框架中利用 KAN 的自適應激活能力，我們旨在提高分類能力，同時保護隱私。本研究評估了聯邦 KAN (F-KAN) 與傳統多層感知器 (MLP) 在分類任務上的性能。結果表明，F-KAN 模型在準確性、精確度、召回率、F1 分數和穩定性方面明顯優於聯邦 MLP 模型，並實現了更好的性能，為更有效率和保護隱私的預測分析鋪平了道路。

##### **An Energy-based Model for Word-level AutoCompletion in Computer-aided Translation**
2407.20083v1 by Cheng Yang, Guoping Huang, Mo Yu, Zhirui Zhang, Siheng Li, Mingming Yang, Shuming Shi, Yujiu Yang, Lemao Liu

Word-level AutoCompletion(WLAC) is a rewarding yet challenging task in
Computer-aided Translation. Existing work addresses this task through a
classification model based on a neural network that maps the hidden vector of
the input context into its corresponding label (i.e., the candidate target word
is treated as a label). Since the context hidden vector itself does not take
the label into account and it is projected to the label through a linear
classifier, the model can not sufficiently leverage valuable information from
the source sentence as verified in our experiments, which eventually hinders
its overall performance. To alleviate this issue, this work proposes an
energy-based model for WLAC, which enables the context hidden vector to capture
crucial information from the source sentence. Unfortunately, training and
inference suffer from efficiency and effectiveness challenges, thereby we
employ three simple yet effective strategies to put our model into practice.
Experiments on four standard benchmarks demonstrate that our reranking-based
approach achieves substantial improvements (about 6.07%) over the previous
state-of-the-art model. Further analyses show that each strategy of our
approach contributes to the final performance.

摘要：字級自動完成 (WLAC) 是電腦輔助翻譯中既有回報又有挑戰性的任務。現有工作透過一個基於神經網路的分類模型來處理此任務，該模型將輸入內容的隱藏向量對應到其相應的標籤（亦即，候選目標字詞被視為一個標籤）。由於內容隱藏向量本身並未考量標籤，且它透過線性分類器投影到標籤，因此該模型無法充分利用原始句子的有價值資訊，正如我們在實驗中驗證的那樣，這最終會阻礙其整體效能。為了緩解此問題，本研究提出一個基於能量的 WLAC 模型，讓內容隱藏向量能夠擷取原始句子的關鍵資訊。不幸的是，訓練和推論會遭遇效率和效能的挑戰，因此我們採用三個簡單但有效的策略來實踐我們的模型。在四個標準基準上的實驗證明，我們的重新排序方法比先前的最先進模型獲得顯著的改進（約 6.07%）。進一步的分析顯示，我們方法的每個策略都有助於最終效能。

##### **Investigating the Impact of Semi-Supervised Methods with Data Augmentation on Offensive Language Detection in Romanian Language**
2407.20076v1 by Elena Beatrice Nicola, Dumitru Clementin Cercel, Florin Pop

Offensive language detection is a crucial task in today's digital landscape,
where online platforms grapple with maintaining a respectful and inclusive
environment. However, building robust offensive language detection models
requires large amounts of labeled data, which can be expensive and
time-consuming to obtain. Semi-supervised learning offers a feasible solution
by utilizing labeled and unlabeled data to create more accurate and robust
models. In this paper, we explore a few different semi-supervised methods, as
well as data augmentation techniques. Concretely, we implemented eight
semi-supervised methods and ran experiments for them using only the available
data in the RO-Offense dataset and applying five augmentation techniques before
feeding the data to the models. Experimental results demonstrate that some of
them benefit more from augmentations than others.

摘要：在當今的數位環境中，攻擊性語言偵測是一項至關重要的任務，線上平台致力於維持一個有禮貌且包容的環境。然而，建立強大的攻擊性語言偵測模型需要大量的標籤資料，而取得這些資料可能既昂貴又費時。半監督式學習提供了一個可行的解決方案，利用標籤和未標籤的資料來建立更準確且強大的模型。在本文中，我們探討了幾種不同的半監督式方法，以及資料擴充技術。具體來說，我們實作了八種半監督式方法，並只使用 RO-Offense 資料集中的可用資料為它們執行實驗，並在將資料提供給模型之前套用五種擴充技術。實驗結果顯示，其中一些方法比其他方法更能從擴充中受益。

##### **xAI-Drop: Don't Use What You Cannot Explain**
2407.20067v1 by Vincenzo Marco De Luca, Antonio Longa, Andrea Passerini, Pietro Liò

Graph Neural Networks (GNNs) have emerged as the predominant paradigm for
learning from graph-structured data, offering a wide range of applications from
social network analysis to bioinformatics. Despite their versatility, GNNs face
challenges such as oversmoothing, lack of generalization and poor
interpretability, which hinder their wider adoption and reliability in critical
applications. Dropping has emerged as an effective paradigm for reducing noise
during training and improving robustness of GNNs. However, existing approaches
often rely on random or heuristic-based selection criteria, lacking a
principled method to identify and exclude nodes that contribute to noise and
over-complexity in the model. In this work, we argue that explainability should
be a key indicator of a model's robustness throughout its training phase. To
this end, we introduce xAI-Drop, a novel topological-level dropping regularizer
that leverages explainability to pinpoint noisy network elements to be excluded
from the GNN propagation mechanism. An empirical evaluation on diverse
real-world datasets demonstrates that our method outperforms current
state-of-the-art dropping approaches in accuracy, effectively reduces
over-smoothing, and improves explanation quality.

摘要：圖形神經網路 (GNN) 已成為從圖形結構化資料中學習的主要範例，提供從社群網路分析到生物資訊學的廣泛應用。儘管 GNN 具有多功能性，但仍面臨過度平滑、缺乏概括性以及可解釋性差等挑戰，這些挑戰阻礙了其在關鍵應用中的廣泛採用和可靠性。捨棄已成為一種有效的範例，用於減少訓練期間的雜訊並改善 GNN 的穩健性。然而，現有的方法通常依賴於隨機或基於啟發式的選擇標準，缺乏一種原則性的方法來識別和排除導致雜訊和模型過於複雜的節點。在這項工作中，我們認為可解釋性應該是模型在整個訓練階段中穩健性的關鍵指標。為此，我們引入了 xAI-Drop，這是一種新穎的拓撲級別捨棄正則化器，它利用可解釋性來精確指出要從 GNN 傳播機制中排除的雜訊網路元素。在各種真實世界資料集上的實證評估表明，我們的模型在準確度方面優於當前最先進的捨棄方法，有效減少了過度平滑，並提高了說明品質。

##### **SalNAS: Efficient Saliency-prediction Neural Architecture Search with self-knowledge distillation**
2407.20062v1 by Chakkrit Termritthikun, Ayaz Umer, Suwichaya Suwanwimolkul, Feng Xia, Ivan Lee

Recent advancements in deep convolutional neural networks have significantly
improved the performance of saliency prediction. However, the manual
configuration of the neural network architectures requires domain knowledge
expertise and can still be time-consuming and error-prone. To solve this, we
propose a new Neural Architecture Search (NAS) framework for saliency
prediction with two contributions. Firstly, a supernet for saliency prediction
is built with a weight-sharing network containing all candidate architectures,
by integrating a dynamic convolution into the encoder-decoder in the supernet,
termed SalNAS. Secondly, despite the fact that SalNAS is highly efficient
(20.98 million parameters), it can suffer from the lack of generalization. To
solve this, we propose a self-knowledge distillation approach, termed Self-KD,
that trains the student SalNAS with the weighted average information between
the ground truth and the prediction from the teacher model. The teacher model,
while sharing the same architecture, contains the best-performing weights
chosen by cross-validation. Self-KD can generalize well without the need to
compute the gradient in the teacher model, enabling an efficient training
system. By utilizing Self-KD, SalNAS outperforms other state-of-the-art
saliency prediction models in most evaluation rubrics across seven benchmark
datasets while being a lightweight model. The code will be available at
https://github.com/chakkritte/SalNAS

摘要：近期深度卷積神經網路的進步，大幅提升了顯著性預測的效能。然而，神經網路架構的手動組態需要領域知識專長，且仍可能耗時且容易出錯。為了解決這個問題，我們提出了一個新的神經架構搜尋 (NAS) 架構，用於顯著性預測，並做出兩項貢獻。首先，一個用於顯著性預測的超網路，建立在一個包含所有候選架構的權重共享網路中，透過將動態卷積整合到超網路中的編碼器和解碼器中，稱為 SalNAS。其次，儘管 SalNAS 非常有效率（2098 萬個參數），但它可能會缺乏泛化能力。為了解決這個問題，我們提出了一個自知識萃取方法，稱為 Self-KD，它使用教師模型的預測和基本事實之間的加權平均資訊來訓練學生 SalNAS。教師模型雖然共用相同的架構，但包含透過交叉驗證選出的效能最佳的權重。Self-KD 可以很好地泛化，而不需要在教師模型中計算梯度，從而實現一個有效率的訓練系統。透過使用 Self-KD，SalNAS 在七個基準資料集上的大多數評估指標中都優於其他最先進的顯著性預測模型，同時是一個輕量級模型。程式碼將在 https://github.com/chakkritte/SalNAS 中提供

##### **RelBench: A Benchmark for Deep Learning on Relational Databases**
2407.20060v1 by Joshua Robinson, Rishabh Ranjan, Weihua Hu, Kexin Huang, Jiaqi Han, Alejandro Dobles, Matthias Fey, Jan E. Lenssen, Yiwen Yuan, Zecheng Zhang, Xinwei He, Jure Leskovec

We present RelBench, a public benchmark for solving predictive tasks over
relational databases with graph neural networks. RelBench provides databases
and tasks spanning diverse domains and scales, and is intended to be a
foundational infrastructure for future research. We use RelBench to conduct the
first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024),
which combines graph neural network predictive models with (deep) tabular
models that extract initial entity-level representations from raw tables.
End-to-end learned RDL models fully exploit the predictive signal encoded in
primary-foreign key links, marking a significant shift away from the dominant
paradigm of manual feature engineering combined with tabular models. To
thoroughly evaluate RDL against this prior gold-standard, we conduct an
in-depth user study where an experienced data scientist manually engineers
features for each task. In this study, RDL learns better models whilst reducing
human work needed by more than an order of magnitude. This demonstrates the
power of deep learning for solving predictive tasks over relational databases,
opening up many new research opportunities enabled by RelBench.

摘要：我們提出 RelBench，一個用於解決關係資料庫中預測任務的公共基準，使用圖神經網路。RelBench 提供跨越不同領域和規模的資料庫和任務，並旨在成為未來研究的基本基礎設施。我們使用 RelBench 進行關係深度學習 (RDL) 的首次全面研究 (Fey et al., 2024)，它結合圖神經網路預測模型與（深度）表格模型，從原始表格中提取初始實體級別表示。端到端學習的 RDL 模型充分利用了主外鍵連結中編碼的預測信號，標誌著從結合表格模型的手動特徵工程的主流範例中顯著轉變。為了徹底評估 RDL 與此先前的黃金標準，我們進行了一項深入的使用者研究，其中一位經驗豐富的資料科學家手動為每個任務設計特徵。在這項研究中，RDL 學習更好的模型，同時將所需的人力減少了一個數量級以上。這展示了深度學習在解決關係資料庫預測任務中的強大功能，開啟了 RelBench 啟用的許多新的研究機會。

##### **Exploring Large Language Models to generate Easy to Read content**
2407.20046v1 by Paloma Martínez, Lourdes Moreno, Alberto Ramos

Ensuring text accessibility and understandability are essential goals,
particularly for individuals with cognitive impairments and intellectual
disabilities, who encounter challenges in accessing information across various
mediums such as web pages, newspapers, administrative tasks, or health
documents. Initiatives like Easy to Read and Plain Language guidelines aim to
simplify complex texts; however, standardizing these guidelines remains
challenging and often involves manual processes. This work presents an
exploratory investigation into leveraging Artificial Intelligence (AI) and
Natural Language Processing (NLP) approaches to systematically simplify Spanish
texts into Easy to Read formats, with a focus on utilizing Large Language
Models (LLMs) for simplifying texts, especially in generating Easy to Read
content. The study contributes a parallel corpus of Spanish adapted for Easy To
Read format, which serves as a valuable resource for training and testing text
simplification systems. Additionally, several text simplification experiments
using LLMs and the collected corpus are conducted, involving fine-tuning and
testing a Llama2 model to generate Easy to Read content. A qualitative
evaluation, guided by an expert in text adaptation for Easy to Read content, is
carried out to assess the automatically simplified texts. This research
contributes to advancing text accessibility for individuals with cognitive
impairments, highlighting promising strategies for leveraging LLMs while
responsibly managing energy usage.

摘要：確保文字的可及性和可理解性是必要的目標，
特別是對於有認知障礙和智力障礙的人來說，他們在各種媒體（例如網頁、報紙、管理任務或健康文件）中獲取資訊時會遇到挑戰。易於閱讀和淺顯易懂語言指南等倡議旨在簡化複雜的文字；然而，標準化這些指南仍然具有挑戰性，而且通常涉及手動程序。這項工作提出了一項探索性調查，旨在利用人工智慧 (AI) 和自然語言處理 (NLP) 方法，系統性地將西班牙語文字簡化為易於閱讀的格式，重點在於利用大型語言模型 (LLM) 來簡化文字，特別是在產生易於閱讀的內容方面。這項研究提供了為易於閱讀格式改編的西班牙語平行語料庫，作為訓練和測試文字簡化系統的寶貴資源。此外，還進行了使用 LLM 和收集到的語料庫的幾項文字簡化實驗，包括微調和測試 Llama2 模型以產生易於閱讀的內容。由易於閱讀內容文字改編專家指導的定性評估用於評估自動簡化的文字。這項研究有助於推進認知障礙者的文字可及性，強調了在負責任地管理能源使用的同時利用 LLM 的有希望的策略。

##### **Do LLMs Really Adapt to Domains? An Ontology Learning Perspective**
2407.19998v1 by Huu Tan Mai, Cuong Xuan Chu, Heiko Paulheim

Large Language Models (LLMs) have demonstrated unprecedented prowess across
various natural language processing tasks in various application domains.
Recent studies show that LLMs can be leveraged to perform lexical semantic
tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL).
However, it has not effectively been verified whether their success is due to
their ability to reason over unstructured or semi-structured data, or their
effective learning of linguistic patterns and senses alone. This unresolved
question is particularly crucial when dealing with domain-specific data, where
the lexical senses and their meaning can completely differ from what a LLM has
learned during its training stage. This paper investigates the following
question: Do LLMs really adapt to domains and remain consistent in the
extraction of structured knowledge, or do they only learn lexical senses
instead of reasoning? To answer this question and, we devise a controlled
experiment setup that uses WordNet to synthesize parallel corpora, with English
and gibberish terms. We examine the differences in the outputs of LLMs for each
corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical
results show that, while adapting to the gibberish corpora, off-the-shelf LLMs
do not consistently reason over semantic relationships between concepts, and
instead leverage senses and their frame. However, fine-tuning improves the
performance of LLMs on lexical semantic tasks even when the domain-specific
terms are arbitrary and unseen during pre-training, hinting at the
applicability of pre-trained LLMs for OL.

摘要：大型語言模型 (LLM) 在各種應用領域的各種自然語言處理任務中展現出前所未有的實力。最近的研究表明，LLM 可用於執行詞彙語義任務，例如知識庫完成 (KBC) 或本体學習 (OL)。然而，尚未有效驗證其成功是歸因於它們對非結構化或半結構化數據進行推理的能力，還是僅歸因於它們對語言模式和意義的有效學習。在處理特定領域的數據時，這個未解決的問題尤其關鍵，其中詞彙意義及其含義可能與 LLM 在訓練階段所學習的內容完全不同。本文探討以下問題：LLM 是否真的適應了領域並在結構化知識的提取中保持一致，還是它們只學習詞彙意義而不是推理？為了回答這個問題，我們設計了一個受控實驗設置，該設置使用 WordNet 來合成平行語料庫，其中包含英語和胡言亂語術語。我們檢查了每個語料庫中 LLM 輸出的差異，這在兩個 OL 任務中：關係提取和分類發現。實證結果表明，在適應胡言亂語語料庫的同時，現成的 LLM 沒有對概念之間的語義關係進行一致的推理，而是利用意義及其框架。然而，微調提高了 LLM 在詞彙語義任務上的性能，即使在預訓練期間特定領域的術語是任意的和未見的，這暗示了預訓練 LLM 對 OL 的適用性。

##### **Reproducibility Study of "ITI-GEN: Inclusive Text-to-Image Generation"**
2407.19996v1 by Daniel Gallo Fernández, Răzvan-Andrei Matisan, Alejandro Monroy Muñoz, Janusz Partyka

Text-to-image generative models often present issues regarding fairness with
respect to certain sensitive attributes, such as gender or skin tone. This
study aims to reproduce the results presented in "ITI-GEN: Inclusive
Text-to-Image Generation" by Zhang et al. (2023a), which introduces a model to
improve inclusiveness in these kinds of models. We show that most of the claims
made by the authors about ITI-GEN hold: it improves the diversity and quality
of generated images, it is scalable to different domains, it has plug-and-play
capabilities, and it is efficient from a computational point of view. However,
ITI-GEN sometimes uses undesired attributes as proxy features and it is unable
to disentangle some pairs of (correlated) attributes such as gender and
baldness. In addition, when the number of considered attributes increases, the
training time grows exponentially and ITI-GEN struggles to generate inclusive
images for all elements in the joint distribution. To solve these issues, we
propose using Hard Prompt Search with negative prompting, a method that does
not require training and that handles negation better than vanilla Hard Prompt
Search. Nonetheless, Hard Prompt Search (with or without negative prompting)
cannot be used for continuous attributes that are hard to express in natural
language, an area where ITI-GEN excels as it is guided by images during
training. Finally, we propose combining ITI-GEN and Hard Prompt Search with
negative prompting.

摘要：文本到图像生成模型通常会呈现出有关公平性的问题，例如性别或肤色等敏感属性。本研究旨在重现 Zhang 等人（2023a）在“ITI-GEN：包容性文本到图像生成”中提出的结果，该结果引入了一个模型来提高此类模型的包容性。我们展示了作者对 ITI-GEN 提出的大多数说法都是成立的：它提高了生成图像的多样性和质量，它可以扩展到不同的领域，它具有即插即用的能力，并且从计算的角度来看它是有效的。然而，ITI-GEN 有时会将不需要的属性用作代理特征，并且无法解开一些成对的（相关）属性，例如性别和秃顶。此外，当所考虑属性的数量增加时，训练时间会呈指数增长，ITI-GEN 难以针对联合分布中的所有元素生成包容性图像。为了解决这些问题，我们建议使用带否定提示的 Hard Prompt Search，这是一种不需要训练并且比香草 Hard Prompt Search 更好地处理否定的一种方法。尽管如此，Hard Prompt Search（带或不带否定提示）不能用于难以用自然语言表达的连续属性，这是 ITI-GEN 在训练期间由图像指导而擅长的领域。最后，我们建议将 ITI-GEN 和 Hard Prompt Search 与否定提示相结合。

##### **A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph**
2407.19994v1 by Cheonsu Jeong

This study aims to improve knowledge-based question-answering (QA) systems by
overcoming the limitations of existing Retrieval-Augmented Generation (RAG)
models and implementing an advanced RAG system based on Graph technology to
develop high-quality generative AI services. While existing RAG models
demonstrate high accuracy and fluency by utilizing retrieved information, they
may suffer from accuracy degradation as they generate responses using
pre-loaded knowledge without reprocessing. Additionally, they cannot
incorporate real-time data after the RAG configuration stage, leading to issues
with contextual understanding and biased information. To address these
limitations, this study implemented an enhanced RAG system utilizing Graph
technology. This system is designed to efficiently search and utilize
information. Specifically, it employs LangGraph to evaluate the reliability of
retrieved information and synthesizes diverse data to generate more accurate
and enhanced responses. Furthermore, the study provides a detailed explanation
of the system's operation, key implementation steps, and examples through
implementation code and validation results, thereby enhancing the understanding
of advanced RAG technology. This approach offers practical guidelines for
implementing advanced RAG systems in corporate services, making it a valuable
resource for practical application.

摘要：本研究旨在透過克服現有檢索增強生成 (RAG) 模型的限制，並實作基於圖形技術的進階 RAG 系統，來改善基於知識的問答 (QA) 系統，以開發高品質的生成式 AI 服務。現有的 RAG 模型雖然透過利用檢索到的資訊展現出高準確度和流暢度，但由於使用預載知識來產生回應而沒有重新處理，因此可能會導致準確度下降。此外，它們無法在 RAG 設定階段後納入即時資料，導致情境理解和資訊偏誤的問題。為了解決這些限制，本研究實作了一個利用圖形技術的增強型 RAG 系統。此系統旨在有效搜尋和利用資訊。具體來說，它採用 LangGraph 來評估檢索到的資訊的可信度，並綜合不同的資料來產生更準確且增強的回應。此外，本研究透過實作程式碼和驗證結果，詳細說明系統的操作、主要的實作步驟和範例，進而增進對進階 RAG 技術的理解。這種方法為在企業服務中實作進階 RAG 系統提供了實用的指南，使其成為實務應用的寶貴資源。

##### **Mixture of Nested Experts: Adaptive Processing of Visual Tokens**
2407.19985v1 by Gagan Jain, Nidhi Hegde, Aditya Kusupati, Arsha Nagrani, Shyamal Buch, Prateek Jain, Anurag Arnab, Sujoy Paul

The visual medium (images and videos) naturally contains a large amount of
information redundancy, thereby providing a great opportunity for leveraging
efficiency in processing. While Vision Transformer (ViT) based models scale
effectively to large data regimes, they fail to capitalize on this inherent
redundancy, leading to higher computational costs. Mixture of Experts (MoE)
networks demonstrate scalability while maintaining same inference-time costs,
but they come with a larger parameter footprint. We present Mixture of Nested
Experts (MoNE), which utilizes a nested structure for experts, wherein
individual experts fall on an increasing compute-accuracy curve. Given a
compute budget, MoNE learns to dynamically choose tokens in a priority order,
and thus redundant tokens are processed through cheaper nested experts. Using
this framework, we achieve equivalent performance as the baseline models, while
reducing inference time compute by over two-fold. We validate our approach on
standard image and video datasets - ImageNet-21K, Kinetics400, and
Something-Something-v2. We further highlight MoNE$'$s adaptability by
showcasing its ability to maintain strong performance across different
inference-time compute budgets on videos, using only a single trained model.

摘要：視覺媒體（影像和影片）自然包含大量的資訊冗餘，因此提供了提升處理效率的絕佳機會。雖然基於視覺轉換器 (ViT) 的模型有效地擴展到大型資料模式，但它們未能利用這種固有的冗餘，導致更高的運算成本。專家混合 (MoE) 網路展示了可擴展性，同時維持相同的推論時間成本，但它們伴隨著更大的參數佔用空間。我們提出了嵌套專家混合 (MoNE)，它利用嵌套結構作為專家，其中個別專家落在逐漸增加的運算準確度曲線上。在給定的運算預算下，MoNE 學會以優先順序動態選擇代幣，因此透過較便宜的嵌套專家處理冗餘代幣。使用這個架構，我們達到了與基準模型相當的效能，同時將推論時間運算減少了一倍以上。我們在標準影像和影片資料集（ImageNet-21K、Kinetics400 和 Something-Something-v2）上驗證了我們的做法。我們進一步強調了 MoNE 的適應性，展示了它在影片上跨不同推論時間運算預算維持強大效能的能力，僅使用單一訓練模型。

##### **Confidence Estimation for Automatic Detection of Depression and Alzheimer's Disease Based on Clinical Interviews**
2407.19984v1 by Wen Wu, Chao Zhang, Philip C. Woodland

Speech-based automatic detection of Alzheimer's disease (AD) and depression
has attracted increased attention. Confidence estimation is crucial for a
trust-worthy automatic diagnostic system which informs the clinician about the
confidence of model predictions and helps reduce the risk of misdiagnosis. This
paper investigates confidence estimation for automatic detection of AD and
depression based on clinical interviews. A novel Bayesian approach is proposed
which uses a dynamic Dirichlet prior distribution to model the second-order
probability of the predictive distribution. Experimental results on the
publicly available ADReSS and DAIC-WOZ datasets demonstrate that the proposed
method outperforms a range of baselines for both classification accuracy and
confidence estimation.

摘要：基於語言的阿茲海默症 (AD) 和憂鬱症自動偵測引起了更多關注。對於一個值得信賴的自動診斷系統而言，信心估計至關重要，它會告知臨床醫生模型預測的信心並有助於降低誤診風險。本文探討了基於臨床訪談對 AD 和憂鬱症進行自動偵測的信心估計。提出了一種新的貝氏方法，它使用動態 Dirichlet 先驗分佈來對預測分佈的二階機率進行建模。在公開的 ADReSS 和 DAIC-WOZ 資料集上的實驗結果表明，所提出的方法在分類準確度和信心估計方面優於一系列基準。

##### **A Temporal Psycholinguistics Approach to Identity Resolution of Social Media Users**
2407.19967v1 by Md Touhidul Islam

In this thesis, we propose an approach to identity resolution across social
media platforms using the topics, sentiments, and timings of the posts on the
platforms. After collecting the public posts of around 5000 profiles from
Disqus and Twitter, we analyze their posts to match their profiles across the
two platforms. We pursue both temporal and non-temporal methods in our
analysis. While neither approach proves definitively superior, the temporal
approach generally performs better. We found that the temporal window size
influences results more than the shifting amount. On the other hand, our
sentiment analysis shows that the inclusion of sentiment makes little
difference, probably due to flawed data extraction methods. We also
experimented with a distance-based reward-and-punishment-focused scoring model,
which achieved an accuracy of 24.198% and an average rank of 158.217 out of
2525 in our collected corpus. Future work includes refining sentiment analysis
by evaluating sentiments per topic, extending temporal analysis with additional
phases, and improving the scoring model through weight adjustments and modified
rewards.

摘要：在本文中，我們提出了一種跨社群媒體平台識別解析的方法，使用平台上貼文的議題、情緒和時間。在從 Disqus 和 Twitter 收集了大約 5000 個個人資料的公開貼文後，我們分析他們的貼文以匹配他們在兩個平台上的個人資料。我們在分析中採用時間和非時間方法。雖然這兩種方法都沒有證明明顯的優越性，但時間方法通常表現得更好。我們發現時間窗口大小對結果的影響大於偏移量。另一方面，我們的情緒分析表明，情緒的包含幾乎沒有區別，可能是由於有缺陷的資料擷取方法。我們還嘗試了一個基於距離的獎勵和懲罰為重點的評分模型，在我們收集的語料庫中，其準確率達到 24.198%，平均排名為 158.217/2525。未來的研究包括通過評估每個議題的情緒來優化情緒分析，使用額外的階段來擴充時間分析，並通過權重調整和修改獎勵來改善評分模型。

##### **Simply Trainable Nearest Neighbour Machine Translation with GPU Inference**
2407.19965v1 by Hossam Amer, Abdelrahman Abouelenin, Mohamed Maher, Evram Nairouz, Mohamed Afify, Hany Awadallah

Nearest neighbor machine translation is a successful approach for fast domain
adaption, which interpolates the pre-trained transformers with domain-specific
token-level k-nearest-neighbor (kNN) retrieval without retraining. Despite kNN
MT's success, searching large reference corpus and fixed interpolation between
the kNN and pre-trained model led to computational complexity and translation
quality challenges. Among other papers, Dai et al. proposed methods to obtain a
small number of reference samples dynamically for which they introduced a
distance-aware interpolation method using an equation that includes free
parameters. This paper proposes a simply trainable nearest neighbor machine
translation and carry out inference experiments on GPU. Similar to Dai et al.,
we first adaptively construct a small datastore for each input sentence.
Second, we train a single-layer network for the interpolation coefficient
between the knnMT and pre-trained result to automatically interpolate in
different domains. Experimental results on different domains show that our
proposed method either improves or sometimes maintain the translation quality
of methods in Dai et al. while being automatic. In addition, our GPU inference
results demonstrate that knnMT can be integrated into GPUs with a drop of only
5% in terms of speed.

摘要：最近邻机器翻译是一种成功的快速领域适应方法，它通过域特定标记级 k-最近邻 (kNN) 检索来内插预先训练的转换器，而无需重新训练。尽管 kNN MT 取得了成功，但在 kNN 和预训练模型之间搜索大型参考语料库和固定内插导致了计算复杂性和翻译质量挑战。在其他论文中，Dai 等人提出了获取少量参考样本的方法，他们为此引入了一种使用包含自由参数的方程的距离感知内插方法。本文提出了一种简单可训练的最近邻机器翻译，并在 GPU 上进行推理实验。与 Dai 等人类似，我们首先为每个输入句子自适应地构建一个小数据存储。其次，我们训练一个单层网络，用于 knnMT 和预训练结果之间的内插系数，以在不同的域中自动内插。不同域的实验结果表明，我们提出的方法在自动化的同时，提高了或有时保持了 Dai 等人方法的翻译质量。此外，我们的 GPU 推理结果表明，knnMT 可以集成到 GPU 中，速度仅下降 5%。

##### **Can I trust my anomaly detection system? A case study based on explainable AI**
2407.19951v1 by Muhammad Rashid, Elvio Amparore, Enrico Ferrari, Damiano Verda

Generative models based on variational autoencoders are a popular technique
for detecting anomalies in images in a semi-supervised context. A common
approach employs the anomaly score to detect the presence of anomalies, and it
is known to reach high level of accuracy on benchmark datasets. However, since
anomaly scores are computed from reconstruction disparities, they often obscure
the detection of various spurious features, raising concerns regarding their
actual efficacy. This case study explores the robustness of an anomaly
detection system based on variational autoencoder generative models through the
use of eXplainable AI methods. The goal is to get a different perspective on
the real performances of anomaly detectors that use reconstruction differences.
In our case study we discovered that, in many cases, samples are detected as
anomalous for the wrong or misleading factors.

摘要：基於變異自動編碼器的生成模型是一種流行的技術，用於在半監督環境中檢測影像中的異常。一種常見的方法使用異常分數來檢測異常的存在，並且已知在基準資料集上達到高準確度。然而，由於異常分數是從重建差異中計算出來的，因此它們常常會模糊各種雜散特徵的檢測，對其實際效能提出疑慮。此案例研究透過使用可解釋 AI 方法探討基於變異自動編碼器生成模型的異常檢測系統的穩健性。目標是對於使用重建差異的異常檢測器的實際效能有不同的觀點。在我們的案例研究中，我們發現，在許多情況下，樣本被檢測為異常是因為錯誤或誤導的因素。

##### **Inference acceleration for large language models using "stairs" assisted greedy generation**
2407.19947v1 by Domas Grigaliūnas, Mantas Lukoševičius

Large Language Models (LLMs) with billions of parameters are known for their
impressive predicting capabilities but require lots of resources to run. With
their massive rise in popularity, even a small reduction in required resources
could have an impact on environment. On the other hand, smaller models require
fewer resources but may sacrifice accuracy. In this work, we are proposing an
implementation of ``stairs'' assisted greedy generation. It is a modified
assisted generation methodology that makes use of a smaller model's fast
generation, large model's batch prediction, and "stairs" validation in order to
achieve a speed up in prediction generation. Results show between 9.58 and
17.24 percent inference time reduction compared to a stand-alone large LLM
prediction in a text generation task without a loss in accuracy.

摘要：大型語言模型 (LLM) 擁有數十億個參數，以其令人印象深刻的預測能力而聞名，但需要大量的資源才能運行。隨著它們的普及程度大幅提升，即使在所需資源上進行微小的減少，都可能對環境產生影響。另一方面，較小的模型需要較少的資源，但可能會犧牲準確性。在這項工作中，我們提出了一個由「階梯」輔助的貪婪生成實作。這是一種經過修改的輔助生成方法，利用較小模型的快速生成、大型模型的批次預測和「階梯」驗證來加速預測生成。結果顯示，與獨立的大型 LLM 預測相比，在文字生成任務中，推理時間減少了 9.58% 到 17.24%，而準確性並未下降。

##### **Noise-Resilient Unsupervised Graph Representation Learning via Multi-Hop Feature Quality Estimation**
2407.19944v1 by Shiyuan Li, Yixin Liu, Qingfeng Chen, Geoffrey I. Webb, Shirui Pan

Unsupervised graph representation learning (UGRL) based on graph neural
networks (GNNs), has received increasing attention owing to its efficacy in
handling graph-structured data. However, existing UGRL methods ideally assume
that the node features are noise-free, which makes them fail to distinguish
between useful information and noise when applied to real data with noisy
features, thus affecting the quality of learned representations. This urges us
to take node noisy features into account in real-world UGRL. With empirical
analysis, we reveal that feature propagation, the essential operation in GNNs,
acts as a "double-edged sword" in handling noisy features - it can both denoise
and diffuse noise, leading to varying feature quality across nodes, even within
the same node at different hops. Building on this insight, we propose a novel
UGRL method based on Multi-hop feature Quality Estimation (MQE for short).
Unlike most UGRL models that directly utilize propagation-based GNNs to
generate representations, our approach aims to learn representations through
estimating the quality of propagated features at different hops. Specifically,
we introduce a Gaussian model that utilizes a learnable "meta-representation"
as a condition to estimate the expectation and variance of multi-hop propagated
features via neural networks. In this way, the "meta representation" captures
the semantic and structural information underlying multiple propagated features
but is naturally less susceptible to interference by noise, thereby serving as
high-quality node representations beneficial for downstream tasks. Extensive
experiments on multiple real-world datasets demonstrate that MQE in learning
reliable node representations in scenarios with diverse types of feature noise.

摘要：<paragraph>基於圖神經網路 (GNN) 的無監督圖表示學習 (UGRL) 由於其在處理圖結構資料上的效能而受到越來越多的關注。然而，現有的 UGRL 方法理想地假設節點特徵沒有雜訊，這使得它們在應用於具有雜訊特徵的真實資料時無法區分有用的資訊和雜訊，進而影響學習表示的品質。這促使我們在實際的 UGRL 中考慮節點雜訊特徵。透過實證分析，我們揭示了 GNN 中的基本運算特徵傳播在處理雜訊特徵時扮演「雙面刃」的角色，它既可以去雜訊，也可以擴散雜訊，導致不同節點之間的特徵品質不同，甚至在不同跳數的同一個節點內也會出現這種情況。基於這個見解，我們提出了一種新的 UGRL 方法，它基於多跳特徵品質估計 (簡稱 MQE)。與大多數直接利用基於傳播的 GNN 來產生表示的 UGRL 模型不同，我們的做法旨在透過估計不同跳數的傳播特徵的品質來學習表示。具體來說，我們引入了一個高斯模型，它利用一個可學習的「元表示」作為條件，透過神經網路來估計多跳傳播特徵的期望值和變異數。透過這種方式，「元表示」擷取了多個傳播特徵背後的語義和結構資訊，但自然而然地不易受到雜訊的干擾，因此可用作有利於下游任務的高品質節點表示。在多個真實世界資料集上進行的廣泛實驗證明，MQE 在具有不同類型特徵雜訊的情況下學習可靠的節點表示。</paragraph>

##### **Robust Conformal Volume Estimation in 3D Medical Images**
2407.19938v1 by Benjamin Lambert, Florence Forbes, Senan Doyle, Michel Dojat

Volumetry is one of the principal downstream applications of 3D medical image
segmentation, for example, to detect abnormal tissue growth or for surgery
planning. Conformal Prediction is a promising framework for uncertainty
quantification, providing calibrated predictive intervals associated with
automatic volume measurements. However, this methodology is based on the
hypothesis that calibration and test samples are exchangeable, an assumption
that is in practice often violated in medical image applications. A weighted
formulation of Conformal Prediction can be framed to mitigate this issue, but
its empirical investigation in the medical domain is still lacking. A potential
reason is that it relies on the estimation of the density ratio between the
calibration and test distributions, which is likely to be intractable in
scenarios involving high-dimensional data. To circumvent this, we propose an
efficient approach for density ratio estimation relying on the compressed
latent representations generated by the segmentation model. Our experiments
demonstrate the efficiency of our approach to reduce the coverage error in the
presence of covariate shifts, in both synthetic and real-world settings. Our
implementation is available at https://github.com/benolmbrt/wcp_miccai

摘要：體積測量是 3D 醫學影像分割的主要下游應用之一，例如用於偵測異常組織生長或手術規劃。共形預測是一個有前途的不確定性量化架構，提供與自動體積量測相關的校正預測區間。然而，此方法基於校正和測試樣本可交換的假設，而此假設在實務上經常在醫學影像應用中遭到破壞。共形預測的加權公式可以被建構來減輕此問題，但其在醫學領域的經驗調查仍然不足。一個潛在原因是它依賴於校正和測試分佈之間的密度比估計，這在涉及高維度資料的場景中可能是棘手的。為了迴避此問題，我們提出一個有效率的密度比估計方法，依賴於分割模型產生的壓縮潛在表示。我們的實驗證明了我們的方法在合成和真實世界設定中減少共變異數偏移存在時的覆蓋率誤差的效率。我們的實作可以在 https://github.com/benolmbrt/wcp_miccai 取得

##### **AOTree: Aspect Order Tree-based Model for Explainable Recommendation**
2407.19937v1 by Wenxin Zhao, Peng Zhang, Hansu Gu, Dongsheng Li, Tun Lu, Ning Gu

Recent recommender systems aim to provide not only accurate recommendations
but also explanations that help users understand them better. However, most
existing explainable recommendations only consider the importance of content in
reviews, such as words or aspects, and ignore the ordering relationship among
them. This oversight neglects crucial ordering dimensions in the human
decision-making process, leading to suboptimal performance. Therefore, in this
paper, we propose Aspect Order Tree-based (AOTree) explainable recommendation
method, inspired by the Order Effects Theory from cognitive and decision
psychology, in order to capture the dependency relationships among decisive
factors. We first validate the theory in the recommendation scenario by
analyzing the reviews of the users. Then, according to the theory, the proposed
AOTree expands the construction of the decision tree to capture aspect orders
in users' decision-making processes, and use attention mechanisms to make
predictions based on the aspect orders. Extensive experiments demonstrate our
method's effectiveness on rating predictions, and our approach aligns more
consistently with the user' s decision-making process by displaying
explanations in a particular order, thereby enhancing interpretability.

摘要：最近的推薦系統不僅旨在提供準確的推薦，還旨在提供有助於使用者更了解推薦的解釋。然而，現有的多數可解釋推薦僅考慮評論中內容（例如詞彙或面向）的重要性，而忽略它們之間的排序關係。這種疏忽忽視了人類決策過程中至關重要的排序維度，導致次優的效能。因此，在本文中，我們提出基於面向順序樹 (AOTree) 的可解釋推薦方法，其靈感來自認知和決策心理學中的順序效應理論，目的是捕捉決定性因素之間的依賴關係。我們首先通過分析使用者的評論來驗證推薦情境中的理論。然後，根據理論，所提出的 AOTree 擴展決策樹的建構，以捕捉使用者決策過程中面向順序，並使用注意力機制根據面向順序進行預測。廣泛的實驗證明了我們的方法在評分預測方面的有效性，而且我們的做法透過以特定順序顯示解釋，更一致地與使用者的決策過程保持一致，從而增強了解度。

##### **Monetizing Currency Pair Sentiments through LLM Explainability**
2407.19922v1 by Lior Limonad, Fabiana Fournier, Juan Manuel Vera Díaz, Inna Skarbovsky, Shlomit Gur, Raquel Lazcano

Large language models (LLMs) play a vital role in almost every domain in
today's organizations. In the context of this work, we highlight the use of
LLMs for sentiment analysis (SA) and explainability. Specifically, we
contribute a novel technique to leverage LLMs as a post-hoc model-independent
tool for the explainability of SA. We applied our technique in the financial
domain for currency-pair price predictions using open news feed data merged
with market prices. Our application shows that the developed technique is not
only a viable alternative to using conventional eXplainable AI but can also be
fed back to enrich the input to the machine learning (ML) model to better
predict future currency-pair values. We envision our results could be
generalized to employing explainability as a conventional enrichment for ML
input for better ML predictions in general.

摘要：大型語言模型 (LLM) 在當今組織的幾乎每個領域都扮演著至關重要的角色。在這個工作的脈絡中，我們強調使用 LLM 進行情緒分析 (SA) 和可解釋性。具體來說，我們貢獻了一種新穎的技術，將 LLM 作為一個事後模型無關的工具，用於 SA 的可解釋性。我們在金融領域應用我們的技術，使用公開新聞饋送數據合併市場價格來預測貨幣對價格。我們的應用表明，所開發的技術不僅是使用傳統可解釋 AI 的可行替代方案，還可以反饋以豐富機器學習 (ML) 模型的輸入，以更好地預測未來的貨幣對價值。我們預計我們的結果可以推廣到將可解釋性用作 ML 輸入的傳統豐富化，以一般來說獲得更好的 ML 預測。

##### **Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models**
2407.19914v1 by Brigita Vileikytė, Mantas Lukoševičius, Lukas Stankevičius

Sentiment analysis is a widely researched area within Natural Language
Processing (NLP), attracting significant interest due to the advent of
automated solutions. Despite this, the task remains challenging because of the
inherent complexity of languages and the subjective nature of sentiments. It is
even more challenging for less-studied and less-resourced languages such as
Lithuanian. Our review of existing Lithuanian NLP research reveals that
traditional machine learning methods and classification algorithms have limited
effectiveness for the task. In this work, we address sentiment analysis of
Lithuanian five-star-based online reviews from multiple domains that we collect
and clean. We apply transformer models to this task for the first time,
exploring the capabilities of pre-trained multilingual Large Language Models
(LLMs), specifically focusing on fine-tuning BERT and T5 models. Given the
inherent difficulty of the task, the fine-tuned models perform quite well,
especially when the sentiments themselves are less ambiguous: 80.74% and 89.61%
testing recognition accuracy of the most popular one- and five-star reviews
respectively. They significantly outperform current commercial state-of-the-art
general-purpose LLM GPT-4. We openly share our fine-tuned LLMs online.

摘要：情緒分析是自然語言處理 (NLP) 中廣泛研究的領域，由於自動化解決方案的出現而引起極大的興趣。儘管如此，由於語言的固有複雜性和情緒的主觀性質，這項任務仍然具有挑戰性。對於立陶宛語等研究較少且資源較少的語言來說，這更具挑戰性。我們對現有立陶宛語 NLP 研究的回顧表明，傳統機器學習方法和分類演算法對於這項任務的有效性有限。在這項工作中，我們解決了我們收集並清理的來自多個領域的立陶宛語五星級線上評論的情緒分析。我們首次將Transformer模型應用於此任務，探索預訓練多語言大型語言模型 (LLM) 的能力，特別關注微調 BERT 和 T5 模型。鑑於任務的固有難度，微調模型表現得非常好，特別是當情緒本身不那麼模稜兩可時：80.74% 和 89.61% 分別測試了最受歡迎的一星級和五星級評論的識別準確度。它們顯著優於當前商業最先進的通用 LLM GPT-4。我們公開分享我們微調的 LLM。

##### **Practical and Reproducible Symbolic Music Generation by Large Language Models with Structural Embeddings**
2407.19900v1 by Seungyeon Rhyu, Kichang Yang, Sungjun Cho, Jaehyeon Kim, Kyogu Lee, Moontae Lee

Music generation introduces challenging complexities to large language
models. Symbolic structures of music often include vertical harmonization as
well as horizontal counterpoint, urging various adaptations and enhancements
for large-scale Transformers. However, existing works share three major
drawbacks: 1) their tokenization requires domain-specific annotations, such as
bars and beats, that are typically missing in raw MIDI data; 2) the pure impact
of enhancing token embedding methods is hardly examined without domain-specific
annotations; and 3) existing works to overcome the aforementioned drawbacks,
such as MuseNet, lack reproducibility. To tackle such limitations, we develop a
MIDI-based music generation framework inspired by MuseNet, empirically studying
two structural embeddings that do not rely on domain-specific annotations. We
provide various metrics and insights that can guide suitable encoding to
deploy. We also verify that multiple embedding configurations can selectively
boost certain musical aspects. By providing open-source implementations via
HuggingFace, our findings shed light on leveraging large language models toward
practical and reproducible music generation.

摘要：音樂生成為大型語言模型帶來了具有挑戰性的複雜性。音樂的符號結構通常包括垂直和聲以及水平對位法，促使對大型 Transformer 進行各種改編和增強。然而，現有作品存在三個主要缺點：1) 它們的標記化需要特定領域的註解，例如在原始 MIDI 數據中通常缺失的小節和節拍；2) 在沒有特定領域註解的情況下，很難檢驗增強標記嵌入方法的純粹影響；3) 現有作品克服上述缺點，例如 MuseNet，缺乏可複製性。為了應對這些限制，我們開發了一個受 MuseNet 啟發的基於 MIDI 的音樂生成框架，實證研究了兩種不依賴於特定領域註解的結構嵌入。我們提供了各種指標和見解，可以指導適當的編碼進行部署。我們還驗證了多個嵌入配置可以選擇性地提升某些音樂方面。通過 HuggingFace 提供開源實現，我們的發現闡明了利用大型語言模型朝著實用且可複製的音樂生成邁進。

##### **BEExAI: Benchmark to Evaluate Explainable AI**
2407.19897v1 by Samuel Sithakoul, Sara Meftah, Clément Feutry

Recent research in explainability has given rise to numerous post-hoc
attribution methods aimed at enhancing our comprehension of the outputs of
black-box machine learning models. However, evaluating the quality of
explanations lacks a cohesive approach and a consensus on the methodology for
deriving quantitative metrics that gauge the efficacy of explainability
post-hoc attribution methods. Furthermore, with the development of increasingly
complex deep learning models for diverse data applications, the need for a
reliable way of measuring the quality and correctness of explanations is
becoming critical. We address this by proposing BEExAI, a benchmark tool that
allows large-scale comparison of different post-hoc XAI methods, employing a
set of selected evaluation metrics.

摘要：近年來，可解釋性研究已催生了許多事後歸因方法，旨在加強我們對黑盒子機器學習模型輸出的理解。然而，評估解釋的品質缺乏一個一致的方法，以及對用於衡量可解釋性事後歸因方法有效性的量化指標推導方法的共識。此外，隨著越來越複雜的深度學習模型用於各種資料應用，可靠衡量解釋品質和正確性的方法變得至關重要。我們透過提出 BEExAI 來解決這個問題，這是一個基準工具，允許大規模比較不同的 XAI 事後方法，並採用一組選定的評估指標。

##### **Leveraging Foundation Models for Zero-Shot IoT Sensing**
2407.19893v1 by Dinghao Xue, Xiaoran Fan, Tao Chen, Guohao Lan, Qun Song

Deep learning models are increasingly deployed on edge Internet of Things
(IoT) devices. However, these models typically operate under supervised
conditions and fail to recognize unseen classes different from training. To
address this, zero-shot learning (ZSL) aims to classify data of unseen classes
with the help of semantic information. Foundation models (FMs) trained on
web-scale data have shown impressive ZSL capability in natural language
processing and visual understanding. However, leveraging FMs' generalized
knowledge for zero-shot IoT sensing using signals such as mmWave, IMU, and
Wi-Fi has not been fully investigated. In this work, we align the IoT data
embeddings with the semantic embeddings generated by an FM's text encoder for
zero-shot IoT sensing. To utilize the physics principles governing the
generation of IoT sensor signals to derive more effective prompts for semantic
embedding extraction, we propose to use cross-attention to combine a learnable
soft prompt that is optimized automatically on training data and an auxiliary
hard prompt that encodes domain knowledge of the IoT sensing task. To address
the problem of IoT embeddings biasing to seen classes due to the lack of unseen
class data during training, we propose using data augmentation to synthesize
unseen class IoT data for fine-tuning the IoT feature extractor and embedding
projector. We evaluate our approach on multiple IoT sensing tasks. Results show
that our approach achieves superior open-set detection and generalized
zero-shot learning performance compared with various baselines. Our code is
available at https://github.com/schrodingho/FM\_ZSL\_IoT.

摘要：深度學習模型正越來越廣泛地部署在邊緣物聯網 (IoT) 裝置上。然而，這些模型通常在受監督的條件下運作，而且無法辨識與訓練不同的未見類別。為了解決這個問題，零次學習 (ZSL) 旨在透過語義資訊來分類未見類別的資料。在網際網路規模資料上訓練的基礎模型 (FM) 已在自然語言處理和視覺理解中展現出令人印象深刻的 ZSL 能力。然而，利用 FM 的概括性知識來使用毫米波、IMU 和 Wi-Fi 等訊號進行零次物聯網感測尚未得到充分探討。在這項工作中，我們將物聯網資料嵌入與 FM 的文字編碼器產生的語義嵌入對齊，以進行零次物聯網感測。為了利用支配物聯網感測器訊號產生的物理原理來衍生更有效的提示以進行語義嵌入萃取，我們建議使用交叉注意力來結合在訓練資料上自動最佳化的可學習軟提示和編碼物聯網感測任務領域知識的輔助硬提示。為了解決物聯網嵌入在訓練期間由於缺乏未見類別資料而偏向已見類別的問題，我們建議使用資料擴充來合成未見類別的物聯網資料，以微調物聯網特徵萃取器和嵌入投影器。我們在多項物聯網感測任務上評估我們的做法。結果顯示，與各種基準相比，我們的做法達到了優異的開放式偵測和概括性零次學習效能。我們的程式碼可在 https://github.com/schrodingho/FM\_ZSL\_IoT 取得。

##### **A Unified Graph Transformer for Overcoming Isolations in Multi-modal Recommendation**
2407.19886v1 by Zixuan Yi, Iadh Ounis

With the rapid development of online multimedia services, especially in
e-commerce platforms, there is a pressing need for personalised recommendation
systems that can effectively encode the diverse multi-modal content associated
with each item. However, we argue that existing multi-modal recommender systems
typically use isolated processes for both feature extraction and modality
modelling. Such isolated processes can harm the recommendation performance.
Firstly, an isolated extraction process underestimates the importance of
effective feature extraction in multi-modal recommendations, potentially
incorporating non-relevant information, which is harmful to item
representations. Second, an isolated modality modelling process produces
disjointed embeddings for item modalities due to the individual processing of
each modality, which leads to a suboptimal fusion of user/item representations
for effective user preferences prediction. We hypothesise that the use of a
unified model for addressing both aforementioned isolated processes will enable
the consistent extraction and cohesive fusion of joint multi-modal features,
thereby enhancing the effectiveness of multi-modal recommender systems. In this
paper, we propose a novel model, called Unified Multi-modal Graph Transformer
(UGT), which firstly leverages a multi-way transformer to extract aligned
multi-modal features from raw data for top-k recommendation. Subsequently, we
build a unified graph neural network in our UGT model to jointly fuse the
user/item representations with their corresponding multi-modal features. Using
the graph transformer architecture of our UGT model, we show that the UGT model
can achieve significant effectiveness gains, especially when jointly optimised
with the commonly-used multi-modal recommendation losses.

摘要：<paragraph>隨著線上多媒體服務的快速發展，尤其是在電子商務平台中，對於個人化推薦系統的需求日益迫切，此類系統能有效編碼與每個項目相關的多元多模式內容。然而，我們認為現有的多模式推薦系統通常對特徵提取和模態建模使用孤立的流程。此類孤立的流程會損害推薦效能。首先，孤立的提取流程低估了在多模式推薦中有效特徵提取的重要性，可能納入不相關的資訊，這對項目表示有害。其次，孤立的模態建模流程會產生項目模態的脫節嵌入，這是因為對每個模態進行個別處理，這導致使用者/項目表示的次佳融合，無法有效預測使用者偏好。我們假設，使用統一模型來處理上述兩種孤立的流程，將能讓聯合多模式特徵的一致提取和內聚融合成為可能，進而提升多模式推薦系統的效能。在本文中，我們提出一個新穎的模型，稱為統一多模式圖形轉換器 (UGT)，它首先利用多向轉換器從原始資料中提取對齊的多模式特徵，以進行前 k 名推薦。隨後，我們在 UGT 模型中建構一個統一的圖形神經網路，以將使用者/項目表示與其對應的多模式特徵聯合融合。使用 UGT 模型的圖形轉換器架構，我們顯示 UGT 模型可以達成顯著的效能提升，特別是在與常用的多模式推薦損失聯合最佳化時。</paragraph>

##### **Distances Between Partial Preference Orderings**
2407.19869v1 by Jean Dezert, Andrii Shekhovtsov, Wojciech Salabun

This paper proposes to establish the distance between partial preference
orderings based on two very different approaches. The first approach
corresponds to the brute force method based on combinatorics. It generates all
possible complete preference orderings compatible with the partial preference
orderings and calculates the Frobenius distance between all fully compatible
preference orderings. Unfortunately, this first method is not very efficient in
solving high-dimensional problems because of its big combinatorial complexity.
That is why we propose to circumvent this problem by using a second approach
based on belief functions, which can adequately model the missing information
of partial preference orderings. This second approach to the calculation of
distance does not suffer from combinatorial complexity limitation. We show
through simple examples how these two theoretical methods work.

摘要：本文提出根據兩種截然不同的方法來建立部分偏好排序之間的距離。第一種方法對應於基於組合數學的蠻力法。它會產生所有與部分偏好排序相容的完整偏好排序，並計算所有完全相容偏好排序之間的 Frobenius 距離。遺憾的是，第一種方法由於其龐大的組合複雜度，在解決高維問題時效率不高。這就是我們建議使用基於信念函數的第二種方法來規避此問題的原因，它可以充分模擬部分偏好排序中缺失的資訊。這種計算距離的第二種方法不受組合複雜度限制。我們透過簡單的範例說明這兩種理論方法如何運作。

##### **Anomalous State Sequence Modeling to Enhance Safety in Reinforcement Learning**
2407.19860v1 by Leen Kweider, Maissa Abou Kassem, Ubai Sandouk

The deployment of artificial intelligence (AI) in decision-making
applications requires ensuring an appropriate level of safety and reliability,
particularly in changing environments that contain a large number of unknown
observations. To address this challenge, we propose a novel safe reinforcement
learning (RL) approach that utilizes an anomalous state sequence to enhance RL
safety. Our proposed solution Safe Reinforcement Learning with Anomalous State
Sequences (AnoSeqs) consists of two stages. First, we train an agent in a
non-safety-critical offline 'source' environment to collect safe state
sequences. Next, we use these safe sequences to build an anomaly detection
model that can detect potentially unsafe state sequences in a 'target'
safety-critical environment where failures can have high costs. The estimated
risk from the anomaly detection model is utilized to train a risk-averse RL
policy in the target environment; this involves adjusting the reward function
to penalize the agent for visiting anomalous states deemed unsafe by our
anomaly model. In experiments on multiple safety-critical benchmarking
environments including self-driving cars, our solution approach successfully
learns safer policies and proves that sequential anomaly detection can provide
an effective supervisory signal for training safety-aware RL agents

摘要：在決策制定應用中部署人工智慧 (AI) 需要確保適當的安全性和可靠性，特別是在包含大量未知觀測值的變動環境中。為了應對此挑戰，我們提出了一種新的安全強化學習 (RL) 方法，它利用異常狀態序列來增強 RL 安全性。我們提出的安全強化學習與異常狀態序列 (AnoSeqs) 解決方案包含兩個階段。首先，我們在非安全關鍵的離線「來源」環境中訓練代理程式，以收集安全的狀態序列。接下來，我們使用這些安全序列建立異常偵測模型，該模型可以在「目標」安全關鍵環境中偵測潛在不安全的狀態序列，在該環境中，故障可能造成高成本。來自異常偵測模型的預估風險用於訓練目標環境中的風險規避 RL 政策；這涉及調整獎勵函數，以懲罰代理程式拜訪我們異常模型視為不安全的異常狀態。在包括自駕車在內的許多安全關鍵基準環境中進行的實驗中，我們的解決方案方法成功學習了更安全的政策，並證明序列異常偵測可以為訓練安全感知 RL 代理程式提供有效的監督訊號

##### **Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability**
2407.19842v1 by Jorge García-Carrasco, Alejandro Maté, Juan Trujillo

Large Language Models (LLMs), characterized by being trained on broad amounts
of data in a self-supervised manner, have shown impressive performance across a
wide range of tasks. Indeed, their generative abilities have aroused interest
on the application of LLMs across a wide range of contexts. However, neural
networks in general, and LLMs in particular, are known to be vulnerable to
adversarial attacks, where an imperceptible change to the input can mislead the
output of the model. This is a serious concern that impedes the use of LLMs on
high-stakes applications, such as healthcare, where a wrong prediction can
imply serious consequences. Even though there are many efforts on making LLMs
more robust to adversarial attacks, there are almost no works that study
\emph{how} and \emph{where} these vulnerabilities that make LLMs prone to
adversarial attacks happen. Motivated by these facts, we explore how to
localize and understand vulnerabilities, and propose a method, based on
Mechanistic Interpretability (MI) techniques, to guide this process.
Specifically, this method enables us to detect vulnerabilities related to a
concrete task by (i) obtaining the subset of the model that is responsible for
that task, (ii) generating adversarial samples for that task, and (iii) using
MI techniques together with the previous samples to discover and understand the
possible vulnerabilities. We showcase our method on a pretrained GPT-2 Small
model carrying out the task of predicting 3-letter acronyms to demonstrate its
effectiveness on locating and understanding concrete vulnerabilities of the
model.

摘要：<paragraph>大型語言模型 (LLM) 的特點是透過大量資料進行自我監督訓練，在廣泛的任務中展現出令人印象深刻的表現。事實上，它們的生成能力已引起人們對 LLM 在廣泛情境中應用的興趣。然而，一般的神經網路，尤其是 LLM，已知容易受到對抗性攻擊，其中輸入的難以察覺的變化會誤導模型的輸出。這是阻礙 LLM 用於高風險應用（例如醫療保健）的嚴重問題，因為錯誤的預測可能會造成嚴重的後果。儘管有許多努力讓 LLM 對抗性攻擊更強大，但幾乎沒有研究探討 LLM 容易受到對抗性攻擊的這些漏洞是如何發生的，以及發生在何處。基於這些事實，我們探討如何定位和了解漏洞，並提出一個基於機制可解釋性 (MI) 技術的方法來指導此程序。具體來說，此方法使我們能夠透過 (i) 取得負責該任務的模型子集、(ii) 為該任務產生對抗性樣本，以及 (iii) 使用 MI 技術連同先前的樣本來發現和了解可能的漏洞，來偵測與具體任務相關的漏洞。我們在執行預測 3 個字母縮寫任務的預訓練 GPT-2 小型模型上展示我們的模型，以證明其在定位和了解模型具體漏洞方面的有效性。</paragraph>

##### **ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to English Translation**
2407.19835v1 by Mohammed Khalil, Mohammed Sabry

Classical Arabic represents a significant era, encompassing the golden age of
Arab culture, philosophy, and scientific literature. With a broad consensus on
the importance of translating these literatures to enrich knowledge
dissemination across communities, the advent of large language models (LLMs)
and translation systems offers promising tools to facilitate this goal.
However, we have identified a scarcity of translation datasets in Classical
Arabic, which are often limited in scope and topics, hindering the development
of high-quality translation systems. In response, we present the ATHAR dataset,
comprising 66,000 high-quality Classical Arabic to English translation samples
that cover a wide array of subjects including science, culture, and philosophy.
Furthermore, we assess the performance of current state-of-the-art LLMs under
various settings, concluding that there is a need for such datasets in current
systems. Our findings highlight how models can benefit from fine-tuning or
incorporating this dataset into their pretraining pipelines. The dataset is
publicly available on the HuggingFace Data Hub at
\url{https://huggingface.co/datasets/mohamed-khalil/ATHAR}.

摘要：古典阿拉伯語代表一個重要的時代，涵蓋了阿拉伯文化、哲學和科學文學的黃金時代。對於將這些文學翻譯成豐富知識在各個社群中傳播的重要性，大家達成廣泛共識，大型語言模型（LLM）和翻譯系統的出現提供了有希望的工具，以促進這個目標。
然而，我們發現古典阿拉伯語的翻譯資料集很稀少，它們的範圍和主題通常有限，這阻礙了高品質翻譯系統的發展。為了解決這個問題，我們提出了 ATHAR 資料集，其中包含 66,000 個高品質的古典阿拉伯語到英語翻譯範例，涵蓋了包括科學、文化和哲學在內的廣泛主題。
此外，我們評估了目前最先進的 LLM 在各種設定下的效能，並得出結論，目前的系統需要這樣的資料集。我們的發現重點說明了模型如何從微調中受益，或將此資料集納入其預訓練管道。此資料集在 HuggingFace 資料集中心公開提供，網址為\url{https://huggingface.co/datasets/mohamed-khalil/ATHAR}。

##### **ML-Mamba: Efficient Multi-Modal Large Language Model Utilizing Mamba-2**
2407.19832v1 by Wenjun Huang, Jianguo Hu

Multimodal Large Language Models (MLLMs) have attracted much attention due to
their multifunctionality. However, traditional Transformer architectures incur
significant overhead due to their secondary computational complexity. To
address this issue, we introduce ML-Mamba, a multimodal language model that
utilizes the latest and efficient Mamba-2 model for inference. Mamba-2 is known
for its linear extension and fast processing of long sequences. We replace the
Transformer based backbone with a pre-trained Mamba-2 model and explore methods
for integrating 2D visual selective scanning mechanisms into multimodal
learning. We also try various visual encoders and Mamba-2 model variants. Our
extensive experiments conducted in various multimodal benchmark tests have
demonstrated the competitive performance of ML-Mamba and highlighted the
potential of state space models in multimodal tasks. The experimental results
show that: (1) ML-Mamba achieves performance comparable to state-of-the-art
methods such as TinyLaVA and MobileVLM v2 through its linear sequential
modeling, while also having faster inference speed; (2) ML-Mamba performs well
in visual hallucinations and spatial relationship judgment in closed set
benchmark tests; (3) ML-Mamba achieves performance comparable to LLaVA while
reducing the number of parameters by 40\%.(4) Compared to the multimodal model
using the original Mamba model, the Mamba-2 based large-scale multimodal
language model has stronger inference performance and effectiveness.

摘要：多模态大语言模型 (MLLM) 因其多功能性而备受关注。然而，传统的 Transformer 架构由于其二次计算复杂性而产生大量的开销。为了解决这个问题，我们引入了 ML-Mamba，这是一种多模态语言模型，它利用最新且高效的 Mamba-2 模型进行推理。Mamba-2 以其线性扩展和对长序列的快速处理而闻名。我们用预先训练的 Mamba-2 模型替换了基于 Transformer 的骨干，并探索将二维可视选择性扫描机制集成到多模态学习中的方法。我们还尝试了各种视觉编码器和 Mamba-2 模型变体。我们在各种多模态基准测试中进行的广泛实验已经证明了 ML-Mamba 的竞争性能，并突出了状态空间模型在多模态任务中的潜力。实验结果表明：(1) ML-Mamba 通过其线性顺序建模实现了与 TinyLaVA 和 MobileVLM v2 等最先进方法相当的性能，同时还具有更快的推理速度；(2) ML-Mamba 在封闭集基准测试中在视觉幻觉和空间关系判断方面表现良好；(3) ML-Mamba 在将参数数量减少 40% 的同时，实现了与 LLaVA 相当的性能。(4) 与使用原始 Mamba 模型的多模态模型相比，基于 Mamba-2 的大规模多模态语言模型具有更强的推理性能和有效性。

##### **Generative Retrieval with Preference Optimization for E-commerce Search**
2407.19829v1 by Mingming Li, Huimu Wang, Zuxu Chen, Guangtao Nie, Yiming Qiu, Binbin Wang, Guoyu Tang, Lin Liu, Jingwei Zhuo

Generative retrieval introduces a groundbreaking paradigm to document
retrieval by directly generating the identifier of a pertinent document in
response to a specific query. This paradigm has demonstrated considerable
benefits and potential, particularly in representation and generalization
capabilities, within the context of large language models. However, it faces
significant challenges in E-commerce search scenarios, including the complexity
of generating detailed item titles from brief queries, the presence of noise in
item titles with weak language order, issues with long-tail queries, and the
interpretability of results. To address these challenges, we have developed an
innovative framework for E-commerce search, called generative retrieval with
preference optimization. This framework is designed to effectively learn and
align an autoregressive model with target data, subsequently generating the
final item through constraint-based beam search. By employing multi-span
identifiers to represent raw item titles and transforming the task of
generating titles from queries into the task of generating multi-span
identifiers from queries, we aim to simplify the generation process. The
framework further aligns with human preferences using click data and employs a
constrained search method to identify key spans for retrieving the final item,
thereby enhancing result interpretability. Our extensive experiments show that
this framework achieves competitive performance on a real-world dataset, and
online A/B tests demonstrate the superiority and effectiveness in improving
conversion gains.

摘要：生成式檢索引入了一個創新的典範，透過直接生成與特定查詢相關的文件識別碼來檢索文件。這種典範已展現出顯著的好處和潛力，特別是在大型語言模型的表示和概括能力方面。然而，它在電子商務搜尋情境中面臨重大挑戰，包括從簡短查詢中生成詳細的商品標題的複雜性、商品標題中存在語言順序較弱的雜訊、長尾查詢的問題，以及結果的可解釋性。為了應對這些挑戰，我們開發了一個創新的電子商務搜尋架構，稱為具有偏好最佳化的生成式檢索。此架構旨在有效地學習和調整自迴歸模型與目標資料，隨後透過基於約束的波束搜尋生成最終商品。透過採用多跨距識別碼來表示原始商品標題，並將從查詢中生成標題的任務轉換為從查詢中生成多跨距識別碼的任務，我們旨在簡化生成過程。此架構進一步透過點擊資料與人類偏好保持一致，並採用受約束的搜尋方法來識別用於檢索最終商品的關鍵跨距，從而增強結果的可解釋性。我們廣泛的實驗顯示，此架構在真實世界的資料集上實現了具有競爭力的效能，而線上 A/B 測試則證明了其在改善轉換收益方面的優越性和有效性。

##### **Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost**
2407.19825v1 by Sania Nayab, Giulio Rossolini, Giorgio Buttazzo, Nicolamaria Manes, Fabrizio Giacomelli

Today's large language models (LLMs) can solve challenging question-answering
tasks, and prompt engineering techniques, such as chain-of-thought (CoT), have
gained attention for enhancing the explanation and correctness of outputs.
Nevertheless, models require significant time to generate answers augmented
with lengthy reasoning details. To address this issue, this paper analyzes the
impact of output lengths on LLM inference pipelines and proposes novel metrics
to evaluate them in terms of \textit{correct conciseness}. It also examines the
impact of controlling output length through a refined prompt engineering
strategy, Constrained-CoT (CCoT), which encourages the model to limit output
length. Experiments on pre-trained LLMs demonstrated the benefit of the
proposed metrics and the effectiveness of CCoT across different models. For
instance, constraining the reasoning of LLaMA2-70b to 100 words improves the
accuracy from 36.01\% (CoT) to 41.07\% (CCoT) on the GSM8K dataset, while
reducing the average output length by 28 words.

摘要：今日的大型语言模型 (LLM) 可解决具有挑战性的问答任务，而提示工程技术，例如思想链 (CoT)，因增强输出的解释和正确性而受到关注。然而，模型需要大量时间来生成带有冗长推理细节的答案。为了解决这个问题，本文分析了输出长度对 LLM 推理管道的影响，并提出了新的指标来评估它们在“正确简洁性”方面的表现。它还探讨了通过改进的提示工程策略约束 CoT (CCoT) 来控制输出长度的影响，该策略鼓励模型限制输出长度。对预训练 LLM 的实验表明了所提出的指标的好处和 CCoT 在不同模型中的有效性。例如，将 LLaMA2-70b 的推理限制在 100 个单词内，将 GSM8K 数据集上的准确度从 36.01%（CoT）提高到 41.07%（CCoT），同时将平均输出长度减少了 28 个单词。

##### **Comparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies**
2407.19816v1 by Nikita Matkin, Aleksei Smirnov, Mikhail Usanin, Egor Ivanov, Kirill Sobyanin, Sofiia Paklina, Petr Parshakov

The labor market is undergoing rapid changes, with increasing demands on job
seekers and a surge in job openings. Identifying essential skills and
competencies from job descriptions is challenging due to varying employer
requirements and the omission of key skills. This study addresses these
challenges by comparing traditional Named Entity Recognition (NER) methods
based on encoders with Large Language Models (LLMs) for extracting skills from
Russian job vacancies. Using a labeled dataset of 4,000 job vacancies for
training and 1,472 for testing, the performance of both approaches is
evaluated. Results indicate that traditional NER models, especially DeepPavlov
RuBERT NER tuned, outperform LLMs across various metrics including accuracy,
precision, recall, and inference time. The findings suggest that traditional
NER models provide more effective and efficient solutions for skill extraction,
enhancing job requirement clarity and aiding job seekers in aligning their
qualifications with employer expectations. This research contributes to the
field of natural language processing (NLP) and its application in the labor
market, particularly in non-English contexts.

摘要：勞動市場正經歷快速變遷，求職者面臨越來越高的要求，而職缺激增。由於雇主需求不同，加上關鍵技能遺漏，從職務說明中辨識出必要的技能和能力是一項挑戰。本研究透過比較以編碼器為基礎的傳統命名實體識別 (NER) 方法，和大型語言模型 (LLM) 從俄羅斯職缺中萃取技能來因應這些挑戰。使用標記有 4,000 個職缺的資料集進行訓練，以及 1,472 個職缺進行測試，評估這兩種方法的效能。結果顯示，傳統的 NER 模型，特別是經過調整的 DeepPavlov RuBERT NER，在準確度、精準度、召回率和推論時間等各種指標上都優於 LLM。研究結果表明，傳統的 NER 模型提供更有效率的技能萃取解決方案，可提升職務需求的清晰度，並協助求職者將其資格與雇主期望相符。本研究有助於自然語言處理 (NLP) 領域，以及其在勞動市場中的應用，特別是在非英語語境中。

##### **Improving Retrieval Augmented Language Model with Self-Reasoning**
2407.19813v1 by Yuan Xia, Jingbo Zhou, Zhenhui Shi, Jun Chen, Haifeng Huang

The Retrieval-Augmented Language Model (RALM) has shown remarkable
performance on knowledge-intensive tasks by incorporating external knowledge
during inference, which mitigates the factual hallucinations inherited in large
language models (LLMs). Despite these advancements, challenges persist in the
implementation of RALMs, particularly concerning their reliability and
traceability. To be specific, the irrelevant document retrieval may result in
unhelpful response generation or even deteriorate the performance of LLMs,
while the lack of proper citations in generated outputs complicates efforts to
verify the trustworthiness of the models. To this end, we propose a novel
self-reasoning framework aimed at improving the reliability and traceability of
RALMs, whose core idea is to leverage reasoning trajectories generated by the
LLM itself. The framework involves constructing self-reason trajectories with
three processes: a relevance-aware process, an evidence-aware selective
process, and a trajectory analysis process. We have evaluated our framework
across four public datasets (two short-form QA datasets, one long-form QA
dataset, and one fact verification dataset) to demonstrate the superiority of
our method, which can outperform existing state-of-art models and can achieve
comparable performance with GPT-4, while only using 2,000 training samples.

摘要：檢索增強語言模型 (RALM) 在知識密集型任務中展現出卓越的表現，方法是在推論過程中納入外部知識，這減輕了大型語言模型 (LLM) 中繼承而來的虛構事實。儘管有這些進展，在 RALM 的實作中仍然存在挑戰，特別是關於它們的可靠性和可追溯性。具體來說，不相關的文件檢索可能會導致無益的回應產生，甚至會降低 LLM 的效能，而產生的輸出中缺乏適當的引文，使得驗證模型可信度的努力變得複雜。為此，我們提出了一個新穎的自推理架構，旨在提高 RALM 的可靠性和可追溯性，其核心思想是利用 LLM 本身產生的推理軌跡。該框架涉及使用三個流程來建構自推理軌跡：與相關性相關的流程、與證據相關的選擇性流程和軌跡分析流程。我們已經在四個公開數據集（兩個簡短問答數據集、一個長篇問答數據集和一個事實驗證數據集）中評估了我們的框架，以證明我們的方法的優越性，它可以優於現有的最先進模型，並且可以達到與 GPT-4 相當的效能，而只使用 2,000 個訓練樣本。

##### **Twins-PainViT: Towards a Modality-Agnostic Vision Transformer Framework for Multimodal Automatic Pain Assessment using Facial Videos and fNIRS**
2407.19809v1 by Stefanos Gkikas, Manolis Tsiknakis

Automatic pain assessment plays a critical role for advancing healthcare and
optimizing pain management strategies. This study has been submitted to the
First Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment
(AI4PAIN). The proposed multimodal framework utilizes facial videos and fNIRS
and presents a modality-agnostic approach, alleviating the need for
domain-specific models. Employing a dual ViT configuration and adopting
waveform representations for the fNIRS, as well as for the extracted embeddings
from the two modalities, demonstrate the efficacy of the proposed method,
achieving an accuracy of 46.76% in the multilevel pain assessment task.

摘要：自動疼痛評估對於促進醫療保健和優化疼痛管理策略至關重要。本研究已提交給下一代疼痛評估（AI4PAIN）的第一個多模態感測大挑戰。所提出的多模態框架利用面部影片和 fNIRS，並提出了一種與模態無關的方法，減輕了對特定領域模型的需求。採用雙重 ViT 組態，並針對 fNIRS 採用波形表示，以及針對從這兩個模態中提取的嵌入，證明了所提出方法的功效，在多級疼痛評估任務中達到 46.76% 的準確率。

##### **Cool-Fusion: Fuse Large Language Models without Training**
2407.19807v1 by Cong Liu, Xiaojun Quan, Yan Pan, Liang Lin, Weigang Wu, Xu Chen

We focus on the problem of fusing two or more heterogeneous large language
models (LLMs) to facilitate their complementary strengths. One of the
challenges on model fusion is high computational load, i.e. to fine-tune or to
align vocabularies via combinatorial optimization. To this end, we propose
\emph{Cool-Fusion}, a simple yet effective approach that fuses the knowledge of
heterogeneous source LLMs to leverage their complementary strengths.
\emph{Cool-Fusion} is the first method that does not require any type of
training like the ensemble approaches. But unlike ensemble methods, it is
applicable to any set of source LLMs that have different vocabularies. The
basic idea is to have each source LLM individually generate tokens until the
tokens can be decoded into a text segment that ends at word boundaries common
to all source LLMs. Then, the source LLMs jointly rerank the generated text
segment and select the best one, which is the fused text generation in one
step. Extensive experiments are conducted across a variety of benchmark
datasets. On \emph{GSM8K}, \emph{Cool-Fusion} increases accuracy from three
strong source LLMs by a significant 8\%-17.8\%.

摘要：<paragraph>我们专注于融合两个或多个异构大语言模型 (LLM)，以促进其互补优势。模型融合面临的挑战之一是高计算负载，即通过组合优化微调或对齐词汇表。为此，我们提出了“Cool-Fusion”，这是一种简单但有效的方法，它融合了异构源 LLM 的知识，以利用其互补优势。“Cool-Fusion”是第一种不需要任何类型训练（如集成方法）的方法。但与集成方法不同，它适用于任何具有不同词汇表的源 LLM 集合。基本思想是让每个源 LLM 单独生成标记，直到标记可以解码成文本段落，该段落以所有源 LLM 共有的单词边界结束。然后，源 LLM 联合重新对生成的文本段落进行排名，并选择最佳文本段落，这是单步融合文本生成。在各种基准数据集上进行了广泛的实验。在“GSM8K”上，“Cool-Fusion”将三个强大的源 LLM 的准确性提高了显著的 8%-17.8%。</paragraph>

##### **Imputation for prediction: beware of diminishing returns**
2407.19804v1 by Marine Le Morvan, Gaël Varoquaux

Missing values are prevalent across various fields, posing challenges for
training and deploying predictive models. In this context, imputation is a
common practice, driven by the hope that accurate imputations will enhance
predictions. However, recent theoretical and empirical studies indicate that
simple constant imputation can be consistent and competitive. This empirical
study aims at clarifying if and when investing in advanced imputation methods
yields significantly better predictions. Relating imputation and predictive
accuracies across combinations of imputation and predictive models on 20
datasets, we show that imputation accuracy matters less i) when using
expressive models, ii) when incorporating missingness indicators as
complementary inputs, iii) matters much more for generated linear outcomes than
for real-data outcomes. Interestingly, we also show that the use of the
missingness indicator is beneficial to the prediction performance, even in MCAR
scenarios. Overall, on real-data with powerful models, improving imputation
only has a minor effect on prediction performance. Thus, investing in better
imputations for improved predictions often offers limited benefits.

摘要：缺失值在各个領域中普遍存在，對訓練和部署預測模型構成挑戰。在此背景下，插補是一種常見的做法，其驅動力是希望準確的插補能增強預測。然而，最近的理論和實證研究表明，簡單的常數插補可以是一致且具有競爭力的。這項實證研究旨在釐清投資於先進插補方法是否以及何時會產生顯著更好的預測。在 20 個資料集上，我們展示了插補準確度在以下情況下較不重要：i) 使用表達性模型時，ii) 將缺失指標作為補充輸入納入時，iii) 對產生的線性結果比對實際資料結果重要得多。有趣的是，我們還表明，即使在 MCAR 場景中，使用缺失指標也有利於預測性能。總體而言，在具有強大模型的實際資料中，改進插補對預測性能的影響很小。因此，投資於更好的插補以改善預測通常只能提供有限的好處。

##### **Teaching LLMs at Charles University: Assignments and Activities**
2407.19798v1 by Jindřich Helcl, Zdeněk Kasner, Ondřej Dušek, Tomasz Limisiewicz, Dominik Macháček, Tomáš Musil, Jindřich Libovický

This paper presents teaching materials, particularly assignments and ideas
for classroom activities, from a new course on large language models (LLMs)
taught at Charles University. The assignments include experiments with LLM
inference for weather report generation and machine translation. The classroom
activities include class quizzes, focused research on downstream tasks and
datasets, and an interactive "best paper" session aimed at reading and
comprehension of research papers.

摘要：本文介紹教學材料，特別是作業和課堂活動構想，來自於查爾斯大學教授的大語言模型 (LLM) 新課程。作業包括使用 LLM 推論進行天氣報告生成和機器翻譯的實驗。課堂活動包括測驗、針對下游任務和資料集的重點研究，以及一場互動的「最佳論文」研討會，旨在閱讀和理解研究論文。

##### **VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks**
2407.19795v1 by Juhwan Choi, Junehyoung Kwon, JungMin Yun, Seunguk Yu, YoungBin Kim

Domain generalizability is a crucial aspect of a deep learning model since it
determines the capability of the model to perform well on data from unseen
domains. However, research on the domain generalizability of deep learning
models for vision-language tasks remains limited, primarily because of the lack
of required datasets. To address these challenges, we propose VolDoGer:
Vision-Language Dataset for Domain Generalization, a dedicated dataset designed
for domain generalization that addresses three vision-language tasks: image
captioning, visual question answering, and visual entailment. We constructed
VolDoGer by extending LLM-based data annotation techniques to vision-language
tasks, thereby alleviating the burden of recruiting human annotators. We
evaluated the domain generalizability of various models, ranging from
fine-tuned models to a recent multimodal large language model, through
VolDoGer.

摘要：領域泛化性是深度學習模型的關鍵面向，因為它決定模型在未見領域資料上表現良好的能力。然而，深度學習模型在視覺語言任務上的領域泛化性研究仍然有限，主要是因為缺乏必要的資料集。為了應對這些挑戰，我們提出 VolDoGer：視覺語言領域泛化資料集，一個專門設計用於領域泛化的資料集，它涵蓋三個視覺語言任務：影像標題、視覺問答和視覺蘊涵。我們透過將基於 LLM 的資料標註技術擴充套用到視覺語言任務來建構 VolDoGer，從而減輕招募人工標註者的負擔。我們透過 VolDoGer 評估各種模型的領域泛化性，從微調模型到最近的多模態大型語言模型。

##### **Introducing a new hyper-parameter for RAG: Context Window Utilization**
2407.19794v1 by Kush Juvekar, Anupam Purwar

This paper introduces a new hyper-parameter for Retrieval-Augmented
Generation (RAG) systems called Context Window Utilization. RAG systems enhance
generative models by incorporating relevant information retrieved from external
knowledge bases, improving the factual accuracy and contextual relevance of
generated responses. The size of the text chunks retrieved and processed is a
critical factor influencing RAG performance. This study aims to identify the
optimal chunk size that maximizes answer generation quality. Through systematic
experimentation, we analyze the effects of varying chunk sizes on the
efficiency and effectiveness of RAG frameworks. Our findings reveal that an
optimal chunk size balances the trade-off between providing sufficient context
and minimizing irrelevant information. These insights are crucial for enhancing
the design and implementation of RAG systems, underscoring the importance of
selecting an appropriate chunk size to achieve superior performance.

摘要：本文介紹了一個名為 Context Window Utilization 的檢索增強產生 (RAG) 系統的新超參數。RAG 系統透過納入從外部知識庫檢索到的相關資訊來增強生成模型，進而提升生成回應的事實準確性和脈絡相關性。檢索和處理的文字區塊大小是影響 RAG 效能的關鍵因素。本研究旨在找出能最大化答案產生品質的最佳區塊大小。透過系統性的實驗，我們分析了不同區塊大小對 RAG 架構效率和效能的影響。我們的研究結果顯示，最佳區塊大小取得了提供足夠脈絡和最小化不相關資訊之間的平衡。這些見解對於增強 RAG 系統的設計和實作至關重要，強調了選擇適當區塊大小以達成優異效能的重要性。

##### **Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time Series Forecasting**
2407.19784v1 by Jingjing Xu, Caesar Wu, Yuan-Fang Li, Gregoire Danoy, Pascal Bouvry

Alongside the continuous process of improving AI performance through the
development of more sophisticated models, researchers have also focused their
attention to the emerging concept of data-centric AI, which emphasizes the
important role of data in a systematic machine learning training process.
Nonetheless, the development of models has also continued apace. One result of
this progress is the development of the Transformer Architecture, which
possesses a high level of capability in multiple domains such as Natural
Language Processing (NLP), Computer Vision (CV) and Time Series Forecasting
(TSF). Its performance is, however, heavily dependent on input data
preprocessing and output data evaluation, justifying a data-centric approach to
future research. We argue that data-centric AI is essential for training AI
models, particularly for transformer-based TSF models efficiently. However,
there is a gap regarding the integration of transformer-based TSF and
data-centric AI. This survey aims to pin down this gap via the extensive
literature review based on the proposed taxonomy. We review the previous
research works from a data-centric AI perspective and we intend to lay the
foundation work for the future development of transformer-based architecture
and data-centric AI.

摘要：隨著透過開發更精密的模型持續改善 AI 效能的過程中，研究人員也將注意力集中於資料為中心的人工智慧的新興概念，強調資料在系統化機器學習訓練過程中扮演的重要角色。
儘管如此，模型的開發也持續快速進行。這個進展的其中一項成果是開發出 Transformer 架構，它在自然語言處理 (NLP)、電腦視覺 (CV) 和時間序列預測 (TSF) 等多個領域中都具備高度的能力。然而，它的效能高度依賴於輸入資料的預處理和輸出資料的評估，這證明了資料為中心的方法對於未來的研究至關重要。我們主張，資料為中心的人工智慧對於訓練 AI 模型至關重要，特別是對於基於 Transformer 的 TSF 模型而言。然而，在基於 Transformer 的 TSF 和資料為中心的人工智慧的整合方面存在差距。這項調查旨在透過基於所提出的分類法進行廣泛的文獻回顧來縮小這個差距。我們從資料為中心的人工智慧的角度回顧先前的研究工作，並打算為基於 Transformer 的架構和資料為中心的人工智慧的未來發展奠定基礎。

##### **Synthesizing Scientific Summaries: An Extractive and Abstractive Approach**
2407.19779v1 by Grishma Sharma, Aditi Paretkar, Deepak Sharma

The availability of a vast array of research papers in any area of study,
necessitates the need of automated summarisation systems that can present the
key research conducted and their corresponding findings. Scientific paper
summarisation is a challenging task for various reasons including token length
limits in modern transformer models and corresponding memory and compute
requirements for long text. A significant amount of work has been conducted in
this area, with approaches that modify the attention mechanisms of existing
transformer models and others that utilise discourse information to capture
long range dependencies in research papers. In this paper, we propose a hybrid
methodology for research paper summarisation which incorporates an extractive
and abstractive approach. We use the extractive approach to capture the key
findings of research, and pair it with the introduction of the paper which
captures the motivation for research. We use two models based on unsupervised
learning for the extraction stage and two transformer language models,
resulting in four combinations for our hybrid approach. The performances of the
models are evaluated on three metrics and we present our findings in this
paper. We find that using certain combinations of hyper parameters, it is
possible for automated summarisation systems to exceed the abstractiveness of
summaries written by humans. Finally, we state our future scope of research in
extending this methodology to summarisation of generalised long documents.

摘要：<paragraph>在研究領域中，由於有大量研究論文可用，因此需要自動摘要系統，該系統可以呈現進行中的關鍵研究及其對應的發現。科學論文摘要是一個具有挑戰性的任務，原因有很多，包括現代Transformer模型中的符號長度限制以及長文本對應的記憶體和運算需求。在這個領域中已經進行了大量的研究，其中包括修改現有Transformer模型的注意機制的方法，以及利用話語資訊來擷取研究論文中長程依賴性的其他方法。在本文中，我們提出了一種用於研究論文摘要的混合方法，其中包含萃取和抽象方法。我們使用萃取方法來擷取研究的關鍵發現，並將其與論文的引言配對，該引言擷取了研究的動機。我們在萃取階段使用兩個基於無監督學習的模型和兩個Transformer語言模型，從而為我們的混合方法產生了四種組合。模型的效能會根據三個指標進行評估，我們在本文中呈現我們的發現。我們發現，透過使用某些超參數組合，自動摘要系統可以超越人類撰寫摘要的抽象性。最後，我們說明我們未來在將此方法擴充到概括長文件的摘要中的研究範圍。</paragraph>

##### **Multimodal Large Language Models for Bioimage Analysis**
2407.19778v1 by Shanghang Zhang, Gaole Dai, Tiejun Huang, Jianxu Chen

Rapid advancements in imaging techniques and analytical methods over the past
decade have revolutionized our ability to comprehensively probe the biological
world at multiple scales, pinpointing the type, quantity, location, and even
temporal dynamics of biomolecules. The surge in data complexity and volume
presents significant challenges in translating this wealth of information into
knowledge. The recently emerged Multimodal Large Language Models (MLLMs)
exhibit strong emergent capacities, such as understanding, analyzing,
reasoning, and generalization. With these capabilities, MLLMs hold promise to
extract intricate information from biological images and data obtained through
various modalities, thereby expediting our biological understanding and aiding
in the development of novel computational frameworks. Previously, such
capabilities were mostly attributed to humans for interpreting and summarizing
meaningful conclusions from comprehensive observations and analysis of
biological images. However, the current development of MLLMs shows increasing
promise in serving as intelligent assistants or agents for augmenting human
researchers in biology research

摘要：在過去十年中，影像技術和分析方法的快速進步，徹底改變了我們全面探索多種規模生物世界的能力，精準找出生物分子的類型、數量、位置，甚至時間動態。資料複雜度和大量湧現對將這些豐富的資訊轉化為知識提出了重大挑戰。最近出現的多模態大型語言模型 (MLLM) 展現出強大的新興能力，例如理解、分析、推理和概括。具備這些能力，MLLM 有望從各種方式取得的生物影像和資料中萃取複雜的資訊，從而加速我們的生物理解，並協助開發新型的運算架構。以前，這些能力主要歸因於人類，用於詮釋和總結來自生物影像全面觀察和分析的有意義結論。然而，目前 MLLM 的發展顯示出越來越有希望成為智慧助理或代理，以擴增人類研究員在生物研究中的能力

##### **Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inference**
2407.19775v1 by Claudio Angione, Yue Zhao, Harry Yang, Ahmad Farhan, Fielding Johnston, James Buban, Patrick Colangelo

The rapid growth of large-scale AI models, particularly large language models
has brought significant challenges in data privacy, computational resources,
and accessibility. Traditional centralized architectures often struggle to meet
required data security and scalability needs which hinders the democratization
of AI systems. Nesa introduces a model-agnostic sharding framework designed for
decentralized AI inference. Our framework uses blockchain-based sequential deep
neural network sharding to distribute computational tasks across a diverse
network of nodes based on a personalised heuristic and routing mechanism. This
enables efficient distributed training and inference for recent large-scale
models even on consumer-grade hardware. We use compression techniques like
dynamic blockwise quantization and mixed matrix decomposition to reduce data
transfer and memory needs. We also integrate robust security measures,
including hardware-based trusted execution environments to ensure data
integrity and confidentiality. Evaluating our system across various natural
language processing and vision tasks shows that these compression strategies do
not compromise model accuracy. Our results highlight the potential to
democratize access to cutting-edge AI technologies by enabling secure and
efficient inference on a decentralized network.

摘要：大型 AI 模型，尤其是大型語言模型的快速發展，為資料隱私、運算資源和可及性帶來了重大的挑戰。傳統的集中式架構通常難以滿足所需的資料安全性和可擴充性需求，這阻礙了 AI 系統的民主化。Nesa 引入了專為分散式 AI 推論而設計的與模型無關的分片框架。我們的框架使用基於區塊鏈的序列式深度神經網路分片，根據個人化啟發式和路由機制在不同的節點網路中分配運算任務。這使得即使在消費級硬體上也能對最近的大型模型進行高效的分散式訓練和推論。我們使用動態區塊量化和混合矩陣分解等壓縮技術來減少資料傳輸和記憶體需求。我們還整合了強大的安全措施，包括基於硬體的可信執行環境，以確保資料完整性和機密性。在各種自然語言處理和視覺任務中評估我們的系統表明，這些壓縮策略不會損害模型的準確性。我們的結果突出了通過在分散式網路中實現安全且高效的推論，民主化尖端 AI 技術的可能性。

##### **Generating Unseen Code Tests In Infinitum**
2407.19772v1 by Marcel Zalmanovici, Orna Raz, Eitan Farchi, Iftach Freund

Large Language Models (LLMs) are used for many tasks, including those related
to coding. An important aspect of being able to utilize LLMs is the ability to
assess their fitness for specific usages. The common practice is to evaluate
LLMs against a set of benchmarks. While benchmarks provide a sound foundation
for evaluation and comparison of alternatives, they suffer from the well-known
weakness of leaking into the training data \cite{Xu2024Benchmarking}. We
present a method for creating benchmark variations that generalize across
coding tasks and programming languages, and may also be applied to in-house
code bases. Our approach enables ongoing generation of test-data thus
mitigating the leaking into the training data issue. We implement one
benchmark, called \textit{auto-regression}, for the task of text-to-code
generation in Python. Auto-regression is specifically created to aid in
debugging and in tracking model generation changes as part of the LLM
regression testing process.

摘要：大型語言模型 (LLM) 用於許多任務，包括與編碼相關的任務。能夠利用 LLM 的一個重要方面是評估其適用於特定用途的程度。常見的做法是根據一組基準評估 LLM。儘管基準為評估和比較替代方案提供了穩固的基礎，但它們存在已知的弱點，即洩漏到訓練數據中 \cite{Xu2024Benchmarking}。我們提出了一種創建基準變體的方法，該變體可以推廣到編碼任務和程式語言，並且也可以應用於內部程式碼庫。我們的做法可以持續生成測試數據，從而減輕洩漏到訓練數據中的問題。我們實作了一個基準，稱為「自動迴歸」，用於 Python 中的文字到程式碼生成任務。自動迴歸是專門創建的，用於協助除錯和追蹤模型生成變更，作為 LLM 回歸測試流程的一部分。

##### **Map2Traj: Street Map Piloted Zero-shot Trajectory Generation with Diffusion Model**
2407.19765v1 by Zhenyu Tao, Wei Xu, Xiaohu You

User mobility modeling serves a crucial role in analysis and optimization of
contemporary wireless networks. Typical stochastic mobility models, e.g.,
random waypoint model and Gauss Markov model, can hardly capture the
distribution characteristics of users within real-world areas. State-of-the-art
trace-based mobility models and existing learning-based trajectory generation
methods, however, are frequently constrained by the inaccessibility of
substantial real trajectories due to privacy concerns. In this paper, we
harness the intrinsic correlation between street maps and trajectories and
develop a novel zero-shot trajectory generation method, named Map2Traj, by
exploiting the diffusion model. We incorporate street maps as a condition to
consistently pilot the denoising process and train our model on diverse sets of
real trajectories from various regions in Xi'an, China, and their corresponding
street maps. With solely the street map of an unobserved area, Map2Traj
generates synthetic trajectories that not only closely resemble the real-world
mobility pattern but also offer comparable efficacy. Extensive experiments
validate the efficacy of our proposed method on zero-shot trajectory generation
tasks in terms of both trajectory and distribution similarities. In addition, a
case study of employing Map2Traj in wireless network optimization is presented
to validate its efficacy for downstream applications.

摘要：使用者移動性建模在當代無線網路的分析和最佳化中扮演著至關重要的角色。典型的隨機移動性模型，例如隨機路徑點模型和高斯馬可夫模型，很難捕捉到真實世界區域內使用者的分佈特徵。然而，最先進的基於軌跡的移動性模型和現有的基於學習的軌跡生成方法，經常受到由於隱私問題而無法取得大量真實軌跡的限制。在本文中，我們利用街道地圖和軌跡之間的內在關聯性，並透過利用擴散模型開發出一種名為 Map2Traj 的新零次軌跡生成方法。我們將街道地圖納入作為條件，以持續引導去噪程序，並訓練我們的模型在中國西安不同地區的各種真實軌跡和其對應的街道地圖上。Map2Traj 僅使用未觀察區域的街道地圖，就能產生合成軌跡，這些軌跡不僅與真實世界的移動模式非常相似，而且還提供了相當的效能。廣泛的實驗驗證了我們提出的方法在零次軌跡生成任務中的效能，無論是在軌跡還是分佈相似性方面。此外，還提供了在無線網路最佳化中使用 Map2Traj 的案例研究，以驗證其對下游應用程式的效能。

##### **Legal Minds, Algorithmic Decisions: How LLMs Apply Constitutional Principles in Complex Scenarios**
2407.19760v1 by Camilla Bignotti, Carolina Camassa

In this paper, we conduct an empirical analysis of how large language models
(LLMs), specifically GPT-4, interpret constitutional principles in complex
decision-making scenarios. We examine rulings from the Italian Constitutional
Court on bioethics issues that involve trade-offs between competing values and
compare model-generated legal arguments on these issues to those presented by
the State, the Court, and the applicants. Our results indicate that GPT-4
consistently aligns more closely with progressive interpretations of the
Constitution, often overlooking competing values and mirroring the applicants'
views rather than the more conservative perspectives of the State or the
Court's moderate positions. Our experiments reveal a distinct tendency of GPT-4
to favor progressive legal interpretations, underscoring the influence of
underlying data biases. We thus underscore the importance of testing alignment
in real-world scenarios and considering the implications of deploying LLMs in
decision-making processes.

摘要：在本文中，我們對大型語言模型 (LLM)，特別是 GPT-4，在複雜決策制定情境中如何詮釋憲法原則進行實證分析。我們檢視了義大利憲法法院對涉及競爭價值觀之間權衡取捨的生物倫理議題所做出的裁決，並將模型產生的法律論點與國家、法院和申請人提出的論點進行比較。我們的結果顯示，GPT-4 持續更趨近於憲法進步的詮釋，常常忽略競爭價值觀，且反映申請人的觀點，而非國家較保守的觀點或法院的折衷立場。我們的實驗揭露 GPT-4 明顯傾向於支持進步的法律詮釋，強調基礎資料偏差的影響。因此，我們強調在真實世界情境中測試一致性的重要性，並考量在決策制定過程中部署 LLM 的影響。

##### **KNOWCOMP POKEMON Team at DialAM-2024: A Two-Stage Pipeline for Detecting Relations in Dialogical Argument Mining**
2407.19740v1 by Zihao Zheng, Zhaowei Wang, Qing Zong, Yangqiu Song

Dialogical Argument Mining(DialAM) is an important branch of Argument
Mining(AM). DialAM-2024 is a shared task focusing on dialogical argument
mining, which requires us to identify argumentative relations and illocutionary
relations among proposition nodes and locution nodes. To accomplish this, we
propose a two-stage pipeline, which includes the Two-Step S-Node Prediction
Model in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment
the training data in both stages and introduce context in Stage 2. We
successfully completed the task and achieved good results. Our team Pokemon
ranked 1st in the ARI Focused score and 4th in the Global Focused score.

摘要：對話式論證挖掘（DialAM）是論證挖掘（AM）的重要分支。DialAM-2024 是一項專注於對話式論證挖掘的共用任務，要求我們識別命題節點和發話節點之間的論證關係和言語行為關係。為達成此目的，我們提出了一個兩階段管道，其中包括第 1 階段的兩步驟 S 節點預測模型和第 2 階段的 YA 節點預測模型。我們還在兩個階段中擴充訓練資料，並在第 2 階段中引入背景。我們成功完成任務並取得良好的成果。我們的團隊 Pokemon 在 ARI 專注評分中排名第 1，在全球專注評分中排名第 4。

##### **Do Text-to-Vis Benchmarks Test Real Use of Visualisations?**
2407.19726v1 by Hy Nguyen, Xuefei He, Andrew Reeson, Cecile Paris, Josiah Poon, Jonathan K. Kummerfeld

Large language models are able to generate code for visualisations in
response to user requests. This is a useful application, and an appealing one
for NLP research because plots of data provide grounding for language. However,
there are relatively few benchmarks, and it is unknown whether those that exist
are representative of what people do in practice. This paper aims to answer
that question through an empirical study comparing benchmark datasets and code
from public repositories. Our findings reveal a substantial gap in datasets,
with evaluations not testing the same distribution of chart types, attributes,
and the number of actions. The only representative dataset requires
modification to become an end-to-end and practical benchmark. This shows that
new, more benchmarks are needed to support the development of systems that
truly address users' visualisation needs. These observations will guide future
data creation, highlighting which features hold genuine significance for users.

摘要：大型語言模型能夠根據使用者的要求為視覺化產生程式碼。這是一個有用的應用程式，也是自然語言處理研究的一個有吸引力的應用程式，因為資料圖表為語言提供了基礎。然而，基準很少，而且不知道現有的基準是否代表人們在實際中所做的。本文旨在通過比較基準資料集和來自公共儲存庫的程式碼的實證研究來回答這個問題。我們的發現揭示了資料集中的實質性差距，評估沒有測試圖表類型、屬性和動作數量的相同分佈。唯一的代表性資料集需要修改才能成為端到端的實用基準。這表明需要新的、更多的基準來支援真正滿足使用者視覺化需求的系統開發。這些觀察將指導未來的資料建立，強調哪些功能對使用者具有真正的意義。

##### **Rina: Enhancing Ring-AllReduce with In-network Aggregation in Distributed Model Training**
2407.19721v1 by Zixuan Chen, Xuandong Liu, Minglin Li, Yinfan Hu, Hao Mei, Huifeng Xing, Hao Wang, Wanxin Shi, Sen Liu, Yang Xu

Parameter Server (PS) and Ring-AllReduce (RAR) are two widely utilized
synchronization architectures in multi-worker Deep Learning (DL), also referred
to as Distributed Deep Learning (DDL). However, PS encounters challenges with
the ``incast'' issue, while RAR struggles with problems caused by the long
dependency chain. The emerging In-network Aggregation (INA) has been proposed
to integrate with PS to mitigate its incast issue. However, such PS-based INA
has poor incremental deployment abilities as it requires replacing all the
switches to show significant performance improvement, which is not
cost-effective. In this study, we present the incorporation of INA capabilities
into RAR, called RAR with In-Network Aggregation (Rina), to tackle both the
problems above. Rina features its agent-worker mechanism. When an INA-capable
ToR switch is deployed, all workers in this rack run as one abstracted worker
with the help of the agent, resulting in both excellent incremental deployment
capabilities and better throughput. We conducted extensive testbed and
simulation evaluations to substantiate the throughput advantages of Rina over
existing DDL training synchronization structures. Compared with the
state-of-the-art PS-based INA methods ATP, Rina can achieve more than 50\%
throughput with the same hardware cost.

摘要：參數伺服器 (PS) 和環形全歸約 (RAR) 是多工作者深度學習 (DL) 中廣泛使用的兩種同步架構，也稱為分布式深度學習 (DDL)。然而，PS 在「內投」問題上遇到挑戰，而 RAR 則在長依賴鏈造成的問題上苦苦掙扎。新興的網路內聚合 (INA) 已被提出與 PS 整合以減輕其內投問題。然而，這種基於 PS 的 INA 具有較差的增量部署能力，因為它需要更換所有交換器才能顯示出顯著的效能提升，這並不具有成本效益。在本研究中，我們提出將 INA 功能整合到 RAR 中，稱為具有網路內聚合的 RAR (Rina)，以解決上述兩個問題。Rina 具備其代理工作者機制。當部署了具有 INA 功能的 ToR 交換器時，此機架中的所有工作者在代理的幫助下作為一個抽象工作者執行，從而同時具有出色的增量部署能力和更好的吞吐量。我們進行了廣泛的測試平台和模擬評估，以證實 Rina 在現有 DDL 訓練同步結構中具有吞吐量優勢。與最先進的基於 PS 的 INA 方法 ATP 相比，Rina 在相同的硬體成本下可以實現超過 50% 的吞吐量。

##### **Rethinking RGB-D Fusion for Semantic Segmentation in Surgical Datasets**
2407.19714v1 by Muhammad Abdullah Jamal, Omid Mohareri

Surgical scene understanding is a key technical component for enabling
intelligent and context aware systems that can transform various aspects of
surgical interventions. In this work, we focus on the semantic segmentation
task, propose a simple yet effective multi-modal (RGB and depth) training
framework called SurgDepth, and show state-of-the-art (SOTA) results on all
publicly available datasets applicable for this task. Unlike previous
approaches, which either fine-tune SOTA segmentation models trained on natural
images, or encode RGB or RGB-D information using RGB only pre-trained
backbones, SurgDepth, which is built on top of Vision Transformers (ViTs), is
designed to encode both RGB and depth information through a simple fusion
mechanism. We conduct extensive experiments on benchmark datasets including
EndoVis2022, AutoLapro, LapI2I and EndoVis2017 to verify the efficacy of
SurgDepth. Specifically, SurgDepth achieves a new SOTA IoU of 0.86 on EndoVis
2022 SAR-RARP50 challenge and outperforms the current best method by at least
4%, using a shallow and compute efficient decoder consisting of ConvNeXt
blocks.

摘要：手術場景理解是實現智能且具備情境感知系統的一項關鍵技術組成部分，此類系統能轉換手術介入的各個面向。在本文中，我們專注於語意分割任務，提出一個簡單卻有效的模態多重（RGB 和深度）訓練架構，稱為 SurgDepth，並在所有適用於此任務的公開可用資料集上展示最先進 (SOTA) 的結果。與先前的做法不同，先前的做法不是微調在自然影像上訓練的 SOTA 分割模型，就是使用僅預先訓練 RGB 的主幹編碼 RGB 或 RGB-D 資訊，而 SurgDepth 建構在視覺Transformer (ViT) 之上，旨在透過一個簡單的融合機制編碼 RGB 和深度資訊。我們在包括 EndoVis2022、AutoLapro、LapI2I 和 EndoVis2017 在內的基準資料集上進行廣泛的實驗，以驗證 SurgDepth 的功效。具體而言，SurgDepth 在 EndoVis 2022 SAR-RARP50 挑戰中達成 0.86 的 SOTA IoU，且使用由 ConvNeXt 區塊組成的淺層且計算效率高的解碼器，其效能至少比目前最佳方法高出 4%。

##### **CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**
2407.19705v1 by Jingwei Zhu, Minghuan Tan, Min Yang, Ruixue Li, Hamid Alinejad-Rokny

The rapid progress in Large Language Models (LLMs) has prompted the creation
of numerous benchmarks to evaluate their capabilities.This study focuses on the
Comprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset
diversity and distribution in supervised fine-tuning (SFT) may enhance LLM
performance.Remarkably, We successfully trained a smaller base model to achieve
scores comparable to larger models, indicating that a diverse and
well-distributed dataset can optimize performance regardless of model size.This
study suggests that even smaller models may reach high performance levels with
carefully curated and varied datasets.By integrating a wide range of
instructional content, our approach addresses potential issues such as data
quality inconsistencies. Our results imply that a broader spectrum of training
data may enhance a model's ability to generalize and perform effectively across
different medical scenarios, highlighting the importance of dataset quality and
diversity in fine-tuning processes.

摘要：大型語言模型 (LLM) 的快速進展促成了許多基準的建立，以評估其能力。本研究專注於中文綜合醫療基準 (CMB)，展示了監督微調 (SFT) 中的資料集多樣性和分佈如何增強 LLM 效能。值得注意的是，我們成功訓練了一個較小的基礎模型，以達到與較大模型相當的分數，這表明一個多樣化且分佈良好的資料集可以最佳化效能，而不管模型大小。本研究表明，即使是較小的模型，只要使用經過仔細策劃且多樣化的資料集，也能達到高性能水準。透過整合廣泛的教學內容，我們的做法解決了資料品質不一致等潛在問題。我們的結果表明，更廣泛的訓練資料範圍可能會增強模型在不同醫療場景中概化和有效執行的能力，突顯了資料集品質和多樣性在微調過程中的重要性。

##### **Multiscale Representation Enhanced Temporal Flow Fusion Model for Long-Term Workload Forecasting**
2407.19697v1 by Shiyu Wang, Zhixuan Chu, Yinbo Sun, Yu Liu, Yuliang Guo, Yang Chen, Huiyang Jian, Lintao Ma, Xingyu Lu, Jun Zhou

Accurate workload forecasting is critical for efficient resource management
in cloud computing systems, enabling effective scheduling and autoscaling.
Despite recent advances with transformer-based forecasting models, challenges
remain due to the non-stationary, nonlinear characteristics of workload time
series and the long-term dependencies. In particular, inconsistent performance
between long-term history and near-term forecasts hinders long-range
predictions. This paper proposes a novel framework leveraging self-supervised
multiscale representation learning to capture both long-term and near-term
workload patterns. The long-term history is encoded through multiscale
representations while the near-term observations are modeled via temporal flow
fusion. These representations of different scales are fused using an attention
mechanism and characterized with normalizing flows to handle
non-Gaussian/non-linear distributions of time series. Extensive experiments on
9 benchmarks demonstrate superiority over existing methods.

摘要：準確的工作負載預測對於雲端運算系統中有效率的資源管理至關重要，能進行有效的排程和自動擴展。
儘管Transformer基礎預測模型最近有進展，但由於工作負載時間序列的非平穩、非線性特徵和長期依賴性，仍存在挑戰。特別是，長期歷史和近期預測之間不一致的效能會阻礙長期預測。本文提出一個新穎的架構，利用自我監督的多尺度表示學習來擷取長期和近期的工作負載模式。長期歷史透過多尺度表示進行編碼，而近期觀察則透過時間流動融合進行建模。這些不同尺度的表示使用注意力機制進行融合，並用正規化流進行特徵化，以處理時間序列的非高斯/非線性分佈。在 9 個基準上的廣泛實驗證明了其優於現有方法。

##### **Efficiently and Effectively: A Two-stage Approach to Balance Plaintext and Encrypted Text for Traffic Classification**
2407.19687v1 by Wei Peng

Encrypted traffic classification is the task of identifying the application
or service associated with encrypted network traffic. One effective approach
for this task is to use deep learning methods to encode the raw traffic bytes
directly and automatically extract features for classification (byte-based
models). However, current byte-based models input raw traffic bytes, whether
plaintext or encrypted text, for automated feature extraction, neglecting the
distinct impacts of plaintext and encrypted text on downstream tasks.
Additionally, these models primarily focus on improving classification
accuracy, with little emphasis on the efficiency of models. In this paper, for
the first time, we analyze the impact of plaintext and encrypted text on the
model's effectiveness and efficiency. Based on our observations and findings,
we propose a two-phase approach to balance the trade-off between plaintext and
encrypted text in traffic classification. Specifically, Stage one is to
Determine whether the Plain text is enough to be accurately Classified (DPC)
using the proposed DPC Selector. This stage quickly identifies samples that can
be classified using plaintext, leveraging explicit byte features in plaintext
to enhance model's efficiency. Stage two aims to adaptively make a
classification with the result from stage one. This stage incorporates
encrypted text information for samples that cannot be classified using
plaintext alone, ensuring the model's effectiveness on traffic classification
tasks. Experiments on two datasets demonstrate that our proposed model achieves
state-of-the-art results in both effectiveness and efficiency.

摘要：加密流量分類是識別與加密網路流量相關的應用程式或服務的任務。此任務的其中一種有效方法是使用深度學習方法直接編碼原始流量位元組並自動提取特徵以進行分類（基於位元組的模型）。然而，目前的基於位元組的模型會輸入原始流量位元組（無論是明文或加密文字），以進行自動特徵提取，忽略明文和加密文字對下游任務的顯著影響。此外，這些模型主要著重於提升分類準確度，較少重視模型的效率。在本文中，我們首次分析明文和加密文字對模型效能和效率的影響。根據我們的觀察和發現，我們提出一個兩階段方法來平衡流量分類中明文和加密文字之間的取捨。具體來說，第一階段是使用建議的 DPC 選擇器，確定明文是否足以進行準確分類 (DPC)。此階段會快速識別可以使用明文進行分類的範例，利用明文中的明確位元組特徵來提升模型的效率。第二階段旨在使用第一階段的結果自適應地進行分類。此階段會為無法單獨使用明文進行分類的範例納入加密文字資訊，確保模型在流量分類任務上的效能。在兩個資料集上的實驗顯示，我們提出的模型在效能和效率方面都達到了最先進的結果。

##### **Revisiting the robustness of post-hoc interpretability methods**
2407.19683v1 by Jiawen Wei, Hugues Turbé, Gianmarco Mengaldo

Post-hoc interpretability methods play a critical role in explainable
artificial intelligence (XAI), as they pinpoint portions of data that a trained
deep learning model deemed important to make a decision. However, different
post-hoc interpretability methods often provide different results, casting
doubts on their accuracy. For this reason, several evaluation strategies have
been proposed to understand the accuracy of post-hoc interpretability. Many of
these evaluation strategies provide a coarse-grained assessment -- i.e., they
evaluate how the performance of the model degrades on average by corrupting
different data points across multiple samples. While these strategies are
effective in selecting the post-hoc interpretability method that is most
reliable on average, they fail to provide a sample-level, also referred to as
fine-grained, assessment. In other words, they do not measure the robustness of
post-hoc interpretability methods. We propose an approach and two new metrics
to provide a fine-grained assessment of post-hoc interpretability methods. We
show that the robustness is generally linked to its coarse-grained performance.

摘要：事後可解釋性方法在可解釋的人工智慧 (XAI) 中扮演著關鍵角色，因為它們會找出訓練過的深度學習模型在做決策時視為重要的資料部分。然而，不同的事後可解釋性方法通常會提供不同的結果，讓人質疑其準確性。因此，已提出多種評估策略來了解事後可解釋性的準確性。許多這些評估策略提供粗略的評估，也就是說，它們評估模型在破壞多個樣本中的不同資料點時，其效能平均降低多少。雖然這些策略在選擇平均而言最可靠的事後可解釋性方法時很有效，但它們無法提供樣本層級（也稱為細緻）評估。換句話說，它們無法衡量事後可解釋性方法的穩健性。我們提出一個方法和兩個新指標，以提供事後可解釋性方法的細緻評估。我們證明，穩健性通常與其粗略效能有關。

##### **Motion Manifold Flow Primitives for Language-Guided Trajectory Generation**
2407.19681v1 by Yonghyeon Lee, Byeongho Lee, Seungyeon Kim, Frank C. Park

Developing text-based robot trajectory generation models is made particularly
difficult by the small dataset size, high dimensionality of the trajectory
space, and the inherent complexity of the text-conditional motion distribution.
Recent manifold learning-based methods have partially addressed the
dimensionality and dataset size issues, but struggle with the complex
text-conditional distribution. In this paper we propose a text-based trajectory
generation model that attempts to address all three challenges while relying on
only a handful of demonstration trajectory data. Our key idea is to leverage
recent flow-based models capable of capturing complex conditional
distributions, not directly in the high-dimensional trajectory space, but
rather in the low-dimensional latent coordinate space of the motion manifold,
with deliberately designed regularization terms to ensure smoothness of motions
and robustness to text variations. We show that our {\it Motion Manifold Flow
Primitive (MMFP)} framework can accurately generate qualitatively distinct
motions for a wide range of text inputs, significantly outperforming existing
methods.

摘要：開發基於文字的機器人軌跡生成模型特別困難，因為資料集規模小、軌跡空間維度高，以及文字條件運動分佈的內在複雜性。最近基於流形的學習方法已部分解決了維度和資料集規模問題，但仍難以處理複雜的文字條件分佈。在本文中，我們提出了一個基於文字的軌跡生成模型，試圖解決這三個挑戰，同時僅依賴少數示範軌跡資料。我們的關鍵想法是利用最近的基於流動的模型，它能夠捕捉複雜的條件分佈，不是直接在高維軌跡空間中，而是在運動流形的低維潛在座標空間中，並透過精心設計的正則化項來確保動作的平滑性和對文字變化的魯棒性。我們展示了我們的「運動流形流動基本體 (MMFP)」架構可以準確地為廣泛的文字輸入生成定性上不同的動作，顯著優於現有方法。

##### **Harnessing Large Vision and Language Models in Agriculture: A Review**
2407.19679v1 by Hongyan Zhu, Shuai Qin, Min Su, Chengzhi Lin, Anjie Li, Junfeng Gao

Large models can play important roles in many domains. Agriculture is another
key factor affecting the lives of people around the world. It provides food,
fabric, and coal for humanity. However, facing many challenges such as pests
and diseases, soil degradation, global warming, and food security, how to
steadily increase the yield in the agricultural sector is a problem that humans
still need to solve. Large models can help farmers improve production
efficiency and harvest by detecting a series of agricultural production tasks
such as pests and diseases, soil quality, and seed quality. It can also help
farmers make wise decisions through a variety of information, such as images,
text, etc. Herein, we delve into the potential applications of large models in
agriculture, from large language model (LLM) and large vision model (LVM) to
large vision-language models (LVLM). After gaining a deeper understanding of
multimodal large language models (MLLM), it can be recognized that problems
such as agricultural image processing, agricultural question answering systems,
and agricultural machine automation can all be solved by large models. Large
models have great potential in the field of agriculture. We outline the current
applications of agricultural large models, and aims to emphasize the importance
of large models in the domain of agriculture. In the end, we envisage a future
in which famers use MLLM to accomplish many tasks in agriculture, which can
greatly improve agricultural production efficiency and yield.

摘要：大型模型可以在許多領域扮演重要的角色。農業是另一個影響世界各地人們生活的關鍵因素。它為人類提供食物、衣物和煤炭。然而，面對病蟲害、土壤劣化、全球暖化和糧食安全等許多挑戰，如何穩定提高農業部門的產量，是人類仍然需要解決的問題。大型模型可以幫助農民透過偵測一系列的農業生產任務，例如病蟲害、土壤品質和種子品質，來提高生產效率和收成。它還可以透過各種資訊，例如影像、文字等，幫助農民做出明智的決策。在此，我們深入探討大型模型在農業中的潛在應用，從大型語言模型 (LLM) 和大型視覺模型 (LVM) 到大型視覺語言模型 (LVLM)。在對多模態大型語言模型 (MLLM) 有更深入的了解後，可以了解到農業影像處理、農業問答系統和農業機器自動化等問題都可以透過大型模型來解決。大型模型在農業領域具有巨大的潛力。我們概述了農業大型模型的現有應用，並旨在強調大型模型在農業領域的重要性。最後，我們設想了一個未來，農民使用 MLLM 來完成農業中的許多任務，這可以大幅提高農業生產效率和產量。

##### **SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages**
2407.19672v1 by Wenxuan Zhang, Hou Pong Chan, Yiran Zhao, Mahani Aljunied, Jianyu Wang, Chaoqun Liu, Yue Deng, Zhiqiang Hu, Weiwen Xu, Yew Ken Chia, Xin Li, Lidong Bing

Large Language Models (LLMs) have shown remarkable abilities across various
tasks, yet their development has predominantly centered on high-resource
languages like English and Chinese, leaving low-resource languages underserved.
To address this disparity, we present SeaLLMs 3, the latest iteration of the
SeaLLMs model family, tailored for Southeast Asian languages. This region,
characterized by its rich linguistic diversity, has lacked adequate language
technology support. SeaLLMs 3 aims to bridge this gap by covering a
comprehensive range of languages spoken in this region, including English,
Chinese, Indonesian, Vietnamese, Thai, Tagalog, Malay, Burmese, Khmer, Lao,
Tamil, and Javanese. Leveraging efficient language enhancement techniques and a
specially constructed instruction tuning dataset, SeaLLMs 3 significantly
reduces training costs while maintaining high performance and versatility. Our
model excels in tasks such as world knowledge, mathematical reasoning,
translation, and instruction following, achieving state-of-the-art performance
among similarly sized models. Additionally, we prioritized safety and
reliability by addressing both general and culture-specific considerations and
incorporated mechanisms to reduce hallucinations. This work underscores the
importance of inclusive AI, showing that advanced LLM capabilities can benefit
underserved linguistic and cultural communities.

摘要：大型語言模型 (LLM) 已展現出在各種任務中的卓越能力，但其發展主要集中在英語和中文等高資源語言上，導致低資源語言無法獲得服務。為了解決這種差距，我們提出了 SeaLLMs 3，這是 SeaLLMs 模型系列的最新版本，專門針對東南亞語言設計。這個地區以其豐富的語言多樣性為特徵，但缺乏足夠的語言技術支援。SeaLLMs 3 旨在涵蓋該地區所使用的各種語言，包括英語、中文、印尼語、越南語、泰語、他加祿語、馬來語、緬甸語、高棉語、寮語、泰米爾語和爪哇語，以彌合這一差距。利用高效的語言增強技術和一個特別建構的指令調整資料集，SeaLLMs 3 大幅降低了訓練成本，同時維持高性能和多功能性。我們的模型在世界知識、數學推理、翻譯和指令遵循等任務中表現出色，在同等規模的模型中取得了最先進的效能。此外，我們優先考慮安全性與可靠性，解決了一般性和特定文化的考量，並納入了減少幻覺的機制。這項工作強調了包容性 AI 的重要性，顯示先進的 LLM 能力可以使服務不足的語言和文化社群受益。

##### **mGTE: Generalized Long-Context Text Representation and Reranking Models for Multilingual Text Retrieval**
2407.19669v1 by Xin Zhang, Yanzhao Zhang, Dingkun Long, Wen Xie, Ziqi Dai, Jialong Tang, Huan Lin, Baosong Yang, Pengjun Xie, Fei Huang, Meishan Zhang, Wenjie Li, Min Zhang

We present systematic efforts in building long-context multilingual text
representation model (TRM) and reranker from scratch for text retrieval. We
first introduce a text encoder (base size) enhanced with RoPE and unpadding,
pre-trained in a native 8192-token context (longer than 512 of previous
multilingual encoders). Then we construct a hybrid TRM and a cross-encoder
reranker by contrastive learning. Evaluations show that our text encoder
outperforms the same-sized previous state-of-the-art XLM-R. Meanwhile, our TRM
and reranker match the performance of large-sized state-of-the-art BGE-M3
models and achieve better results on long-context retrieval benchmarks. Further
analysis demonstrate that our proposed models exhibit higher efficiency during
both training and inference. We believe their efficiency and effectiveness
could benefit various researches and industrial applications.

摘要：我們提出了從頭開始建構長語境多語言文字表示模型 (TRM) 和重新排序器的系統性方法，以進行文字檢索。我們首先介紹一個增強了 RoPE 和取消填充功能的文字編碼器 (基本大小)，並在一個原生 8192 個符號的語境中進行預訓練 (比先前的多語言編碼器中 512 個符號更長)。然後，我們通過對比學習來建構一個混合 TRM 和一個跨編碼器重新排序器。評估顯示，我們的文字編碼器優於同等大小的先前最先進技術 XLM-R。同時，我們的 TRM 和重新排序器與大型最先進技術 BGE-M3 模型的效能相匹配，並在長語境檢索基準上取得更好的結果。進一步的分析表明，我們提出的模型在訓練和推論期間都表現出更高的效率。我們相信它們的效率和效能可以使各種研究和產業應用受益。

##### **Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**
2407.19668v1 by Minxiao Chen, Haitao Yuan, Nan Jiang, Zhifeng Bao, Shangguang Wang

Traffic accidents pose a significant risk to human health and property
safety. Therefore, to prevent traffic accidents, predicting their risks has
garnered growing interest. We argue that a desired prediction solution should
demonstrate resilience to the complexity of traffic accidents. In particular,
it should adequately consider the regional background, accurately capture both
spatial proximity and semantic similarity, and effectively address the sparsity
of traffic accidents. However, these factors are often overlooked or difficult
to incorporate. In this paper, we propose a novel multi-granularity
hierarchical spatio-temporal network. Initially, we innovate by incorporating
remote sensing data, facilitating the creation of hierarchical
multi-granularity structure and the comprehension of regional background. We
construct multiple high-level risk prediction tasks to enhance model's ability
to cope with sparsity. Subsequently, to capture both spatial proximity and
semantic similarity, region feature and multi-view graph undergo encoding
processes to distill effective representations. Additionally, we propose
message passing and adaptive temporal attention module that bridges different
granularities and dynamically captures time correlations inherent in traffic
accident patterns. At last, a multivariate hierarchical loss function is
devised considering the complexity of the prediction purpose. Extensive
experiments on two real datasets verify the superiority of our model against
the state-of-the-art methods.

摘要：交通事故對人類健康和財產安全構成重大風險。因此，預測交通事故風險已引起越來越大的興趣。我們認為，理想的預測解決方案應展現出對交通事故複雜性的韌性。具體而言，它應充分考慮區域背景，準確捕捉空間接近度和語義相似性，並有效解決交通事故的稀疏性。然而，這些因素通常被忽視或難以納入。在本文中，我們提出了一個新穎的多粒度分層時空網路。最初，我們創新地納入了遙感數據，促进了分層多粒度結構的創建和區域背景的理解。我們構建了多個高級風險預測任務，以增強模型應對稀疏性的能力。隨後，為了捕捉空間接近度和語義相似性，區域特徵和多視圖圖表經過編碼過程，以提取有效的表示。此外，我們提出了消息傳遞和自適應時間注意力模組，它架起了不同粒度之間的橋樑，並動態捕捉交通事故模式中固有的時間相關性。最後，考慮到預測目的的複雜性，設計了一個多變量分層損失函數。在兩個真實數據集上的大量實驗驗證了我們模型優於最先進方法的優越性。

##### **Smart Language Agents in Real-World Planning**
2407.19667v1 by Annabelle Miin, Timothy Wei

Comprehensive planning agents have been a long term goal in the field of
artificial intelligence. Recent innovations in Natural Language Processing have
yielded success through the advent of Large Language Models (LLMs). We seek to
improve the travel-planning capability of such LLMs by extending upon the work
of the previous paper TravelPlanner. Our objective is to explore a new method
of using LLMs to improve the travel planning experience. We focus specifically
on the "sole-planning" mode of travel planning; that is, the agent is given
necessary reference information, and its goal is to create a comprehensive plan
from the reference information. While this does not simulate the real-world we
feel that an optimization of the sole-planning capability of a travel planning
agent will still be able to enhance the overall user experience. We propose a
semi-automated prompt generation framework which combines the LLM-automated
prompt and "human-in-the-loop" to iteratively refine the prompt to improve the
LLM performance. Our result shows that LLM automated prompt has its limitations
and "human-in-the-loop" greatly improves the performance by $139\%$ with one
single iteration.

摘要：綜合規劃代理一直是人工智慧領域的長期目標。自然語言處理的最新創新已通過大型語言模型 (LLM) 的出現取得成功。我們尋求通過擴展先前論文 TravelPlanner 的工作來改善此類 LLM 的旅遊規劃能力。我們的目標是探索一種新的使用 LLM 來改善旅遊規劃體驗的方法。我們特別關注旅遊規劃的「單獨規劃」模式；也就是說，代理會獲得必要的參考資訊，其目標是根據參考資訊建立一個綜合計畫。雖然這無法模擬現實世界，但我們認為，旅遊規劃代理的單獨規劃能力的最佳化仍將能夠提升整體使用者體驗。我們提出一個半自動提示生成框架，它結合了 LLM 自動化提示和「人機協作」以反覆改善提示，以提升 LLM 效能。我們的結果顯示，LLM 自動化提示有其限制，而「人機協作」透過一次反覆運算大幅提升了 $139%$ 的效能。

##### **AI-Driven Healthcare: A Survey on Ensuring Fairness and Mitigating Bias**
2407.19655v1 by Sribala Vidyadhari Chinta, Zichong Wang, Xingyu Zhang, Thang Doan Viet, Ayesha Kashif, Monique Antoinette Smith, Wenbin Zhang

Artificial intelligence (AI) is rapidly advancing in healthcare, enhancing
the efficiency and effectiveness of services across various specialties,
including cardiology, ophthalmology, dermatology, emergency medicine, etc. AI
applications have significantly improved diagnostic accuracy, treatment
personalization, and patient outcome predictions by leveraging technologies
such as machine learning, neural networks, and natural language processing.
However, these advancements also introduce substantial ethical and fairness
challenges, particularly related to biases in data and algorithms. These biases
can lead to disparities in healthcare delivery, affecting diagnostic accuracy
and treatment outcomes across different demographic groups. This survey paper
examines the integration of AI in healthcare, highlighting critical challenges
related to bias and exploring strategies for mitigation. We emphasize the
necessity of diverse datasets, fairness-aware algorithms, and regulatory
frameworks to ensure equitable healthcare delivery. The paper concludes with
recommendations for future research, advocating for interdisciplinary
approaches, transparency in AI decision-making, and the development of
innovative and inclusive AI applications.

摘要：人工智慧（AI）在醫療保健領域迅速進展，提升各專科的服務效率和成效，包括心臟科、眼科、皮膚科、急診醫學等。AI 應用透過機器學習、神經網路和自然語言處理等技術，顯著提升診斷準確性、治療個人化和預測患者預後。然而，這些進展也帶來重大的倫理和公平挑戰，特別是與資料和演算法中的偏差有關。這些偏差可能導致醫療保健服務的差距，影響不同人口群體的診斷準確性和治療結果。本綜述論文探討 AI 在醫療保健中的整合，重點探討與偏差相關的關鍵挑戰，並探索減輕措施。我們強調多元資料集、具備公平意識的演算法和法規架構的必要性，以確保公平的醫療保健服務。本文最後提出未來研究建議，倡導跨領域方法、AI 決策透明化，以及創新和包容性 AI 應用的開發。

##### **Realizing Unaligned Block-wise Pruning for DNN Acceleration on Mobile Devices**
2407.19644v1 by Hayun Lee, Dongkun Shin

With the recent proliferation of on-device AI, there is an increasing need to
run computationally intensive DNNs directly on mobile devices. However, the
limited computing and memory resources of these devices necessitate effective
pruning techniques. Block-wise pruning is promising due to its low accuracy
drop tradeoff for speedup gains, but it requires block positions to be aligned
with block size, hindering optimal position selection to minimize model
accuracy drop. Unaligned block pruning (UBP) addresses this by allowing blocks
to be selected at arbitrary positions, yet its practical use is limited by a
time-consuming optimal block selection algorithm and lack of efficient
inference kernels. In this paper, we propose a pseudo-optimal yet fast block
selection algorithm called Block Expansion and Division (BED), which can be
integrated into an iterative model training process. Additionally, we introduce
an efficient inference kernel implementation for mobile devices, enabling a
UBP-based model to achieve similar latency to a DNN model compressed by aligned
block pruning. We demonstrate the superiority of our techniques on a real
mobile phone with MobileNet and ResNet models.

摘要：隨著裝置上人工智慧的快速發展，對於直接在行動裝置上執行計算密集型 DNN 的需求也日益增加。然而，這些裝置有限的運算和記憶體資源需要有效的剪枝技術。區塊剪枝由於其低準確度下降的加速收益權衡而很有前途，但它需要區塊位置與區塊大小對齊，這阻礙了最佳位置選擇以最小化模型準確度下降。未對齊區塊剪枝 (UBP) 允許在任意位置選擇區塊來解決此問題，但其實際使用受到耗時的最佳區塊選擇演算法和缺乏有效推論核心的限制。在本文中，我們提出了一種稱為區塊擴充和分割 (BED) 的偽最佳但快速的區塊選擇演算法，它可以整合到反覆模型訓練過程中。此外，我們為行動裝置引入了高效的推論核心實作，使基於 UBP 的模型能夠實現與透過對齊區塊剪枝壓縮的 DNN 模型相似的延遲。我們在搭載 MobileNet 和 ResNet 模型的真實行動電話上展示了我們技術的優越性。

##### **Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**
2407.19643v1 by Yunsheng Wang, Songhao Chen, Kevin Jin

Knowledge graphs (KGs) are essential in applications such as network
alignment, question-answering, and recommender systems (RSs) since they offer
structured relational data that facilitate the inference of indirect
relationships. However, the development of KG-based RSs capable of processing
user inputs in natural language faces significant challenges. Firstly, natural
language processing units must effectively handle the ambiguity and variability
in human language to interpret user intents accurately. Secondly, the system
must precisely identify and link entities, like product names, to their
corresponding nodes in KGs. To overcome these challenges, supported by Lenovo,
we developed a novel chatbot called "Prometheus," which integrates a KG with a
large language model (LLM), specifically designed for recommending computer
components. This chatbot can accurately decode user requests and deliver
personalized recommendations derived from KGs, ensuring precise comprehension
and response to their computer setup needs.

摘要：知識圖譜 (KG) 在網路比對、問答和推薦系統 (RS) 等應用中至關重要，因為它們提供結構化的關係資料，有助於推斷間接關係。然而，開發能夠處理自然語言使用者輸入的基於 KG 的 RS 會面臨重大挑戰。首先，自然語言處理單元必須有效處理人類語言中的歧義和變異性，以準確解讀使用者意圖。其次，系統必須精確識別和連結實體，例如產品名稱，到 KG 中對應的節點。為了克服這些挑戰，在聯想的支援下，我們開發了一個名為「普羅米修斯」的新聊天機器人，它將 KG 與大型語言模型 (LLM) 整合在一起，專門用於推薦電腦組件。這個聊天機器人可以準確解碼使用者的要求，並提供從 KG 中衍生的個人化推薦，確保準確理解和回應他們對電腦設定的需求。

##### **From Pre-training Corpora to Large Language Models: What Factors Influence LLM Performance in Causal Discovery Tasks?**
2407.19638v1 by Tao Feng, Lizhen Qu, Niket Tandon, Zhuang Li, Xiaoxi Kang, Gholamreza Haffari

Recent advances in artificial intelligence have seen Large Language Models
(LLMs) demonstrate notable proficiency in causal discovery tasks. This study
explores the factors influencing the performance of LLMs in causal discovery
tasks. Utilizing open-source LLMs, we examine how the frequency of causal
relations within their pre-training corpora affects their ability to accurately
respond to causal discovery queries. Our findings reveal that a higher
frequency of causal mentions correlates with better model performance,
suggesting that extensive exposure to causal information during training
enhances the models' causal discovery capabilities. Additionally, we
investigate the impact of context on the validity of causal relations. Our
results indicate that LLMs might exhibit divergent predictions for identical
causal relations when presented in different contexts. This paper provides the
first comprehensive analysis of how different factors contribute to LLM
performance in causal discovery tasks.

摘要：近期人工智能的進展已見證大型語言模型 (LLM) 在因果發現任務中展現顯著的熟練度。本研究探討影響 LLM 在因果發現任務中表現的因素。利用開源 LLM，我們探討預訓練語料庫中因果關係的頻率如何影響它們準確回應因果發現查詢的能力。我們的發現顯示，因果提及的頻率越高，與更好的模型表現相關，這表示在訓練期間大量接觸因果資訊會增強模型的因果發現能力。此外，我們調查背景對因果關係有效性的影響。我們的結果顯示，當以不同的背景呈現時，LLM 可能對相同的因果關係展現不同的預測。本文提供了第一個全面的分析，說明不同因素如何影響 LLM 在因果發現任務中的表現。

##### **OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale**
2407.19633v1 by Ali AhmadiTeshnizi, Wenzhi Gao, Herman Brunborg, Shayan Talaei, Madeleine Udell

Optimization problems are pervasive in sectors from manufacturing and
distribution to healthcare. However, most such problems are still solved
heuristically by hand rather than optimally by state-of-the art solvers because
the expertise required to formulate and solve these problems limits the
widespread adoption of optimization tools and techniques. We introduce a Large
Language Model (LLM)-based system designed to formulate and solve (mixed
integer) linear programming problems from their natural language descriptions.
Our system is capable of developing mathematical models, writing and debugging
solver code, evaluating the generated solutions, and improving efficiency and
correctness of its model and code based on these evaluations. OptiMUS-0.3
utilizes a modular structure to process problems, allowing it to handle
problems with long descriptions and complex data without long prompts.
Experiments demonstrate that OptiMUS-0.3 outperforms existing state-of-the-art
methods on easy datasets by more than 12% and on hard datasets (including a new
dataset, NLP4LP, released with this paper that features long and complex
problems) by more than 8%.

摘要：最佳化問題廣泛存在於製造、配送到醫療保健等產業中。然而，大多數此類問題仍以人工啟發式方式解決，而非透過最先進的求解器以最佳方式解決，因為制定和解決這些問題所需的專業知識限制了最佳化工具和技術的廣泛採用。我們引進一個大型語言模型 (LLM) 為基礎的系統，旨在根據自然語言描述制定和解決（混合整數）線性規劃問題。我們的系統能夠開發數學模型、撰寫和除錯求解器程式碼、評估產生的解決方案，並根據這些評估改善其模型和程式碼的效率和正確性。OptiMUS-0.3 使用模組化結構來處理問題，讓它能夠處理描述長且資料複雜的問題，而無需長提示。實驗證明，OptiMUS-0.3 在簡單資料集上比現有的最先進方法高出 12% 以上，而在困難資料集（包括與本文一同發布的新資料集 NLP4LP，其中包含長且複雜的問題）上高出 8% 以上。

##### **"A Good Bot Always Knows Its Limitations": Assessing Autonomous System Decision-making Competencies through Factorized Machine Self-confidence**
2407.19631v1 by Brett Israelsen, Nisar R. Ahmed, Matthew Aitken, Eric W. Frew, Dale A. Lawrence, Brian M. Argrow

How can intelligent machines assess their competencies in completing tasks?
This question has come into focus for autonomous systems that algorithmically
reason and make decisions under uncertainty. It is argued here that machine
self-confidence -- a form of meta-reasoning based on self-assessments of an
agent's knowledge about the state of the world and itself, as well as its
ability to reason about and execute tasks -- leads to many eminently computable
and useful competency indicators for such agents. This paper presents a
culmination of work on this concept in the form of a computational framework
called Factorized Machine Self-confidence (FaMSeC), which provides an
engineering-focused holistic description of factors driving an algorithmic
decision-making process, including outcome assessment, solver quality, model
quality, alignment quality, and past experience. In FaMSeC, self-confidence
indicators are derived from hierarchical `problem-solving statistics' embedded
within broad classes of probabilistic decision-making algorithms such as Markov
decision processes. The problem-solving statistics are obtained by evaluating
and grading probabilistic exceedance margins with respect to given competency
standards, which are specified for each decision-making competency factor by
the informee (e.g. a non-expert user or an expert system designer). This
approach allows `algorithmic goodness of fit' evaluations to be easily
incorporated into the design of many kinds of autonomous agents via
human-interpretable competency self-assessment reports. Detailed descriptions
and running application examples for a Markov decision process agent show how
two FaMSeC factors (outcome assessment and solver quality) can be practically
computed and reported for a range of possible tasking contexts through novel
use of meta-utility functions, behavior simulations, and surrogate prediction
models.

摘要：智能機器如何評估其完成任務的能力？
這個問題已經成為演算法推理並在不確定性下做出決定的自主系統的焦點。本文主張，機器自我信心——一種基於代理人對世界狀態和自身知識的自我評估，以及其推理和執行任務的能力的元推理形式——會導致許多極具可計算性和對此類代理人有用的能力指標。本文以計算框架的形式呈現了關於此概念的工作成果，稱為因子化機器自我信心 (FaMSeC)，它提供了由演算法決策制定過程驅動的因素的以工程為中心的整體描述，包括結果評估、求解器品質、模型品質、對齊品質和過去經驗。在 FaMSeC 中，自我信心指標源自階層式「問題解決統計」中，這些統計嵌入在廣泛類別的機率決策制定演算法中，例如馬可夫決策過程。問題解決統計是透過評估和評分機率超過邊際值來獲得的，相對於給定的能力標準，這些標準是由被告知者（例如非專家使用者或專家系統設計師）為每個決策制定能力因子指定的。這種方法允許將「演算法的擬合優度」評估輕鬆納入各種自主代理人的設計中，透過人類可解讀的能力自我評估報告。馬可夫決策過程代理人的詳細描述和執行應用程式範例顯示，如何透過元效用函數、行為模擬和替代預測模型的新穎使用，實際計算和報告兩個 FaMSeC 因子（結果評估和求解器品質）以及各種可能的任務脈絡。

##### **LLMs' Understanding of Natural Language Revealed**
2407.19630v1 by Walid S. Saba

Large language models (LLMs) are the result of a massive experiment in
bottom-up, data-driven reverse engineering of language at scale. Despite their
utility in a number of downstream NLP tasks, ample research has shown that LLMs
are incapable of performing reasoning in tasks that require quantification over
and the manipulation of symbolic variables (e.g., planning and problem
solving); see for example [25][26]. In this document, however, we will focus on
testing LLMs for their language understanding capabilities, their supposed
forte. As we will show here, the language understanding capabilities of LLMs
have been widely exaggerated. While LLMs have proven to generate human-like
coherent language (since that's how they were designed), their language
understanding capabilities have not been properly tested. In particular, we
believe that the language understanding capabilities of LLMs should be tested
by performing an operation that is the opposite of 'text generation' and
specifically by giving the LLM snippets of text as input and then querying what
the LLM "understood". As we show here, when doing so it will become apparent
that LLMs do not truly understand language, beyond very superficial inferences
that are essentially the byproduct of the memorization of massive amounts of
ingested text.

摘要：大型語言模型 (LLM) 是大規模自下而上、資料驅動反向語言工程實驗的成果。儘管它們在許多下游 NLP 任務中很有用，但充足的研究表明，LLM 無法在需要量化和符號變數操作的任務中進行推理（例如，規劃和問題解決）；例如，請參閱 [25][26]。然而，在本文檔中，我們將重點放在測試 LLM 的語言理解能力，這是它們假設的優勢。正如我們在此處所示，LLM 的語言理解能力已被廣泛誇大。雖然 LLM 已被證明可以產生類似人類的連貫語言（因為這是它們的設計方式），但它們的語言理解能力尚未經過適當測試。特別是，我們相信 LLM 的語言理解能力應該通過執行與「文字生成」相反的操作來測試，特別是通過將 LLM 文字片段作為輸入，然後查詢 LLM「理解」了什麼。正如我們在此處所示，在這樣做的過程中，很明顯 LLM 並不真正理解語言，除了基本上是大量吸收文字的記憶副產品的非常表面的推論。

##### **Enhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation**
2407.19619v1 by Manish Bhattarai, Javier E. Santos, Shawn Jones, Ayan Biswas, Boian Alexandrov, Daniel O'Malley

The advent of large language models (LLMs) has significantly advanced the
field of code translation, enabling automated translation between programming
languages. However, these models often struggle with complex translation tasks
due to inadequate contextual understanding. This paper introduces a novel
approach that enhances code translation through Few-Shot Learning, augmented
with retrieval-based techniques. By leveraging a repository of existing code
translations, we dynamically retrieve the most relevant examples to guide the
model in translating new code segments. Our method, based on
Retrieval-Augmented Generation (RAG), substantially improves translation
quality by providing contextual examples from which the model can learn in
real-time. We selected RAG over traditional fine-tuning methods due to its
ability to utilize existing codebases or a locally stored corpus of code, which
allows for dynamic adaptation to diverse translation tasks without extensive
retraining. Extensive experiments on diverse datasets with open LLM models such
as Starcoder, Llama3-70B Instruct, CodeLlama-34B Instruct, Granite-34B Code
Instruct, and Mixtral-8x22B, as well as commercial LLM models like GPT-3.5
Turbo and GPT-4o, demonstrate our approach's superiority over traditional
zero-shot methods, especially in translating between Fortran and CPP. We also
explored varying numbers of shots i.e. examples provided during inference,
specifically 1, 2, and 3 shots and different embedding models for RAG,
including Nomic-Embed, Starencoder, and CodeBERT, to assess the robustness and
effectiveness of our approach.

摘要：大型語言模型 (LLM) 的出現大幅推動了程式碼翻譯領域，實現了程式語言之間的自動翻譯。然而，這些模型在處理複雜的翻譯任務時常常會遇到困難，原因是對語境的理解不足。本文介紹了一種創新的方法，該方法透過少量次學習增強程式碼翻譯，並輔以基於檢索的技術。透過利用現有程式碼翻譯的儲存庫，我們動態檢索最相關的範例，以指導模型翻譯新的程式碼區段。我們的這項方法以檢索增強生成 (RAG) 為基礎，透過提供模型可以從中即時學習的語境範例，大幅提升翻譯品質。我們選擇 RAG 而非傳統的微調方法，原因在於它能夠利用現有的程式碼庫或本地儲存的程式碼語料庫，這讓我們得以動態適應不同的翻譯任務，而無需進行大量的重新訓練。在使用 Starcoder、Llama3-70B Instruct、CodeLlama-34B Instruct、Granite-34B Code Instruct 和 Mixtral-8x22B 等開放式 LLM 模型，以及 GPT-3.5 Turbo 和 GPT-4o 等商業 LLM 模型的各種資料集上進行的廣泛實驗，證明了我們的方法優於傳統的零次學習方法，特別是在 Fortran 和 CPP 之間的翻譯。我們還探索了在推理過程中提供的範例數量的變化，特別是 1、2 和 3 個範例，以及 RAG 的不同嵌入模型，包括 Nomic-Embed、Starencoder 和 CodeBERT，以評估我們方法的穩健性和有效性。

##### **TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**
2407.19616v1 by Selma Wanna, Ryan Barron, Nick Solovyev, Maksim E. Eren, Manish Bhattarai, Kim Rasmussen, Boian S. Alexandrov

Topic modeling is a technique for organizing and extracting themes from large
collections of unstructured text. Non-negative matrix factorization (NMF) is a
common unsupervised approach that decomposes a term frequency-inverse document
frequency (TF-IDF) matrix to uncover latent topics and segment the dataset
accordingly. While useful for highlighting patterns and clustering documents,
NMF does not provide explicit topic labels, necessitating subject matter
experts (SMEs) to assign labels manually. We present a methodology for
automating topic labeling in documents clustered via NMF with automatic model
determination (NMFk). By leveraging the output of NMFk and employing prompt
engineering, we utilize large language models (LLMs) to generate accurate topic
labels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs
demonstrates the effectiveness of our method in enhancing knowledge management
and document organization.

摘要：主題建模是一種從大量非結構化文本中組織和提取主題的技術。非負矩陣分解 (NMF) 是一種常見的無監督方法，它將詞頻-逆文件頻率 (TF-IDF) 矩陣分解為潛在主題，並據此對數據集進行分段。儘管 NMF 可用於強調模式和群組文件，但它不提供明確的主題標籤，這需要主題專家 (SME) 手動分配標籤。我們提出了一種方法，用於自動標記通過 NMF 進行群組的文件，並自動確定模型 (NMFk)。通過利用 NMFk 的輸出並採用提示工程，我們利用大型語言模型 (LLM) 來生成準確的主題標籤。我們對超過 34,000 篇關於知識圖譜的科學摘要進行的案例研究證明了我們的方法在增強知識管理和文件組織方面的有效性。

##### **Mixture of Modular Experts: Distilling Knowledge from a Multilingual Teacher into Specialized Modular Language Models**
2407.19610v1 by Mohammed Al-Maamari, Mehdi Ben Amor, Michael Granitzer

This research combines Knowledge Distillation (KD) and Mixture of Experts
(MoE) to develop modular, efficient multilingual language models. Key
objectives include evaluating adaptive versus fixed alpha methods in KD and
comparing modular MoE architectures for handling multi-domain inputs and
preventing catastrophic forgetting. KD compresses large language models (LLMs)
into smaller, efficient models, while MoE enhances modularity with specialized
tasks. Experiments showed similar performance for both KD methods, with
marginal improvements from adaptive alpha. A combined loss approach provided
more stable learning. The router, trained to classify input sequences into
English, French, German, or Python, achieved 99.95% precision, recall, and F1
score, with Logistic Regression being the most effective classifier.
Evaluations of modular MoE architectures revealed that Pre-trained Language
Experts (PLE) and Joint Expert Embedding Training (JEET) performed similarly,
while the MoE with Common Expert (MoE-CE) setup showed slightly lower
performance. Including a common expert in MoE-CE improved its performance.
Studies on catastrophic forgetting indicated that sequential training led to
significant forgetting, while single-session training with balanced batches and
the MoE approach mitigated this issue. The MoE architecture preserved knowledge
across multiple languages effectively.
  The research contributes open-sourced resources including the dataset
(https://zenodo.org/doi/10.5281/zenodo.12677631), a balanced dataset creation
tool (https://github.com/padas-lab-de/multi-language-dataset-creator), and the
research codebase (https://github.com/ModMaamari/mixture-modular-experts).

摘要：<paragraph>本研究結合知識蒸餾 (KD) 和專家混合 (MoE) 來開發模組化、高效的多語言語言模型。主要目標包括評估 KD 中的適應性與固定 alpha 方法，以及比較模組化 MoE 架構以處理多領域輸入並防止災難性遺忘。KD 將大型語言模型 (LLM) 壓縮成更小、更有效率的模型，而 MoE 則透過專門任務增強模組化。實驗顯示兩種 KD 方法的效能相似，適應性 alpha 的邊際改善。結合損失法提供了更穩定的學習。經過訓練以將輸入序列分類為英語、法語、德語或 Python 的路由器達到了 99.95% 的精確度、召回率和 F1 分數，其中邏輯迴歸是最有效的分類器。對模組化 MoE 架構的評估顯示，預先訓練的語言專家 (PLE) 和聯合專家嵌入訓練 (JEET) 的表現相似，而具有共同專家 (MoE-CE) 設定的 MoE 顯示出略低的表現。在 MoE-CE 中加入一個共同專家改善了其表現。對災難性遺忘的研究表明，順序訓練導致顯著的遺忘，而使用平衡批次和 MoE 方法的單一課程訓練減輕了這個問題。MoE 架構有效地保留了多種語言的知識。本研究提供了開放原始碼資源，包括資料集 (https://zenodo.org/doi/10.5281/zenodo.12677631)、平衡資料集建立工具 (https://github.com/padas-lab-de/multi-language-dataset-creator) 和研究程式碼庫 (https://github.com/ModMaamari/mixture-modular-experts)。</paragraph>

##### **You shall know a piece by the company it keeps. Chess plays as a data for word2vec models**
2407.19600v1 by Boris Orekhov

In this paper, I apply linguistic methods of analysis to non-linguistic data,
chess plays, metaphorically equating one with the other and seeking analogies.
Chess game notations are also a kind of text, and one can consider the records
of moves or positions of pieces as words and statements in a certain language.
In this article I show how word embeddings (word2vec) can work on chess game
texts instead of natural language texts. I don't see how this representation of
chess data can be used productively. It's unlikely that these vector models
will help engines or people choose the best move. But in a purely academic
sense, it's clear that such methods of information representation capture
something important about the very nature of the game, which doesn't
necessarily lead to a win.

摘要：在本文中，我將語言學方法應用於非語言數據，
將國際象棋棋局比喻為語言，並尋找類比。
國際象棋棋譜也是一種文本，而棋子的移動或位置記錄可以被視為某種語言中的單詞和句子。
在本文中，我展示了詞嵌入（word2vec）如何應用於國際象棋棋譜文本，而不是自然語言文本。我不認為國際象棋數據的這種表示方式可以被有效地使用。這些向量模型不太可能幫助引擎或人類選擇最佳走法。但從純學術的角度來看，很明顯，這種信息表示方法捕捉到了遊戲本身非常重要的東西，這並不一定會導致勝利。

##### **Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge**
2407.19594v1 by Tianhao Wu, Weizhe Yuan, Olga Golovneva, Jing Xu, Yuandong Tian, Jiantao Jiao, Jason Weston, Sainbayar Sukhbaatar

Large Language Models (LLMs) are rapidly surpassing human knowledge in many
domains. While improving these models traditionally relies on costly human
data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs
can improve by judging their own responses instead of relying on human
labelers. However, existing methods have primarily focused on improving model
responses rather than judgment capabilities, resulting in rapid saturation
during iterative training. To address this issue, we introduce a novel
Meta-Rewarding step to the self-improvement process, where the model judges its
own judgements and uses that feedback to refine its judgment skills.
Surprisingly, this unsupervised approach improves the model's ability to judge
{\em and} follow instructions, as demonstrated by a win rate improvement of
Llama-3-8B-Instruct from 22.9% to 39.4% on AlpacaEval 2, and 20.6% to 29.1% on
Arena-Hard. These results strongly suggest the potential for self-improving
models without human supervision.

摘要：大型語言模型 (LLM) 在許多領域迅速超越人類知識。雖然改善這些模型傳統上依賴於昂貴的人類數據，但最近的自我獎勵機制 (Yuan et al., 2024) 顯示，LLM 可以透過判斷自己的回應，而不是依賴人類標籤員來改進。然而，現有方法主要集中在改進模型回應，而不是判斷能力，導致在反覆訓練期間快速飽和。為了解決這個問題，我們在自我改進過程中引入了新穎的元獎勵步驟，模型在其中判斷自己的判斷，並使用該回饋來改進其判斷技能。令人驚訝的是，這種無監督方法改善了模型判斷和遵循指令的能力，正如 Llama-3-8B-Instruct 在 AlpacaEval 2 上的獲勝率從 22.9% 提高到 39.4%，在 Arena-Hard 上從 20.6% 提高到 29.1% 所示範的那樣。這些結果強烈表明了自我改進模型在沒有人類監督下的潛力。

##### **Is Generative AI an Existential Threat to Human Creatives? Insights from Financial Economics**
2407.19586v1 by Jiasun Li

With the phenomenal rise of generative AI models (e.g., large language models
such as GPT or large image models such as Diffusion), there are increasing
concerns about human creatives' futures. Specifically, as generative models'
power further increases, will they eventually replace all human creatives'
jobs? We argue that the answer is "no," even if existing generative AI models'
capabilities reach their theoretical limit. Our theory has a close analogy to a
familiar insight in financial economics on the impossibility of an
informationally efficient market [Grossman and Stiglitz (1980)]: If generative
AI models can provide all the content humans need at low variable costs, then
there is no incentive for humans to spend costly resources on content creation
as they cannot profit from it. But if no human creates new content, then
generative AI can only learn from stale information and be unable to generate
up-to-date content that reflects new happenings in the physical world. This
creates a paradox.

摘要：隨著生成式 AI 模型（例如，大型語言模型，如 GPT 或大型影像模型，如 Diffusion）的驚人崛起，人們對於人類創意工作者的未來越來越感到憂心。具體來說，隨著生成式模型的效能持續提升，它們最終會取代所有人類創意工作者的工作嗎？我們認為答案是否定的，即使現有的生成式 AI 模型的能力達到理論上的極限。我們的理論與金融經濟學中關於資訊有效市場不可能存在的見解有密切的類比 [Grossman and Stiglitz (1980)]：如果生成式 AI 模型能以低變動成本提供人類所需的所有內容，那麼人類就沒有誘因花費昂貴的資源在內容創作上，因為他們無法從中獲利。但是，如果沒有人類創作新內容，那麼生成式 AI 就只能從陳舊的資訊中學習，並且無法產生反映物理世界中新事件的最新內容。這造成了悖論。

##### **SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain**
2407.19584v1 by Pierre Colombo, Telmo Pires, Malik Boudiaf, Rui Melo, Dominic Culver, Sofia Morgado, Etienne Malaboeuf, Gabriel Hautreux, Johanne Charpentier, Michael Desa

In this paper, we introduce SaulLM-54B and SaulLM-141B, two large language
models (LLMs) tailored for the legal sector. These models, which feature
architectures of 54 billion and 141 billion parameters, respectively, are based
on the Mixtral architecture. The development of SaulLM-54B and SaulLM-141B is
guided by large-scale domain adaptation, divided into three strategies: (1) the
exploitation of continued pretraining involving a base corpus that includes
over 540 billion of legal tokens, (2) the implementation of a specialized legal
instruction-following protocol, and (3) the alignment of model outputs with
human preferences in legal interpretations. The integration of synthetically
generated data in the second and third steps enhances the models' capabilities
in interpreting and processing legal texts, effectively reaching
state-of-the-art performance and outperforming previous open-source models on
LegalBench-Instruct. This work explores the trade-offs involved in
domain-specific adaptation at this scale, offering insights that may inform
future studies on domain adaptation using strong decoder models. Building upon
SaulLM-7B, this study refines the approach to produce an LLM better equipped
for legal tasks. We are releasing base, instruct, and aligned versions on top
of SaulLM-54B and SaulLM-141B under the MIT License to facilitate reuse and
collaborative research.

摘要：<paragraph>在本文中，我們介紹了 SaulLM-54B 和 SaulLM-141B，兩種針對法律領域量身打造的大型語言模型 (LLM)。這些模型分別採用 540 億和 1410 億個參數的架構，基於 Mixtral 架構。SaulLM-54B 和 SaulLM-141B 的開發由大規模領域適應引導，分為三種策略：(1) 利用持續預訓練，包含一個基礎語料庫，其中包含超過 5400 億個法律標記，(2) 實施專業法律指令遵循協定，以及 (3) 將模型輸出與人類在法律解釋中的偏好對齊。在第二和第三步驟中整合合成產生的數據，增強了模型在解釋和處理法律文本方面的能力，有效地達到最先進的效能，並在 LegalBench-Instruct 中優於先前的開源模型。這項工作探討了在此規模下涉及領域特定適應的權衡，提供見解，可能為使用強大解碼器模型進行領域適應的未來研究提供資訊。本研究建立在 SaulLM-7B 的基礎上，改進了方法，以產生更適合法律任務的 LLM。我們根據 MIT 許可證在 SaulLM-54B 和 SaulLM-141B 上發布基礎、指令和對齊版本，以促進重複使用和協作研究。</paragraph>

##### **Memory-efficient Training of LLMs with Larger Mini-batches**
2407.19580v1 by Dang Nguyen, Wenhan Yang, Rathul Anand, Yu Yang, Baharan Mirzasoleiman

Training with larger mini-batches improves the performance and convergence
rate of training machine learning models. However, training with large
mini-batches becomes prohibitive for Large Language Models (LLMs) with billions
of parameters, due to the large GPU memory requirement. To address this
problem, we propose finding small mini-batches that simulate the dynamics of
training with larger mini-batches. Specifically, we formulate selecting smaller
mini-batches of examples that closely capture gradients of large mini-batches
as a submodular maximization problem. Nevertheless, the very large
dimensionality of the gradients makes the problem very challenging to solve. To
address this, we leverage ideas from zeroth-order optimization and neural
network pruning to find lower-dimensional gradient estimates that allow finding
high-quality subsets effectively with a limited amount of memory. We prove the
superior convergence rate of training on the small mini-batches found by our
method and empirically show its effectiveness. Our method can effectively
reduce the memory requirement by 2x and speed up training by 1.3x, as we
confirm for fine-tuning Phi-2 on MathInstruct. Our method can be easily stacked
with LoRA and other memory-efficient methods to further reduce the memory
requirements of training LLMs.

摘要：使用較大的迷你批次進行訓練會改善機器學習模型的訓練效能和收斂速度。然而，對於擁有數十億個參數的大型語言模型 (LLM) 來說，使用大型迷你批次進行訓練會受到限制，因為 GPU 記憶體需求很大。為了解決這個問題，我們建議尋找模擬較大型迷你批次訓練動態的小型迷你批次。具體來說，我們將選擇與大型迷你批次的梯度密切相關的小型範例迷你批次，並將其表述為次模組最大化問題。儘管如此，梯度的維度非常大，這使得問題的求解極具挑戰性。為了解決這個問題，我們利用零階最佳化和神經網路剪枝的想法，以尋找低維梯度估計值，並利用有限的記憶體有效地找到高品質子集。我們證明了使用我們的方法找到的小型迷你批次訓練的優異收斂速度，並實證顯示其有效性。我們的確能有效地將記憶體需求減少 2 倍，並將訓練速度提高 1.3 倍，正如我們在 MathInstruct 上對 Phi-2 進行微調所確認的那樣。我們的確能輕鬆地與 LoRA 和其他記憶體效率方法堆疊，以進一步減少 LLM 訓練的記憶體需求。

##### **Are LLMs Good Annotators for Discourse-level Event Relation Extraction?**
2407.19568v1 by Kangda Wei, Aayush Gautam, Ruihong Huang

Large Language Models (LLMs) have demonstrated proficiency in a wide array of
natural language processing tasks. However, its effectiveness over
discourse-level event relation extraction (ERE) tasks remains unexplored. In
this paper, we assess the effectiveness of LLMs in addressing discourse-level
ERE tasks characterized by lengthy documents and intricate relations
encompassing coreference, temporal, causal, and subevent types. Evaluation is
conducted using an commercial model, GPT-3.5, and an open-source model,
LLaMA-2. Our study reveals a notable underperformance of LLMs compared to the
baseline established through supervised learning. Although Supervised
Fine-Tuning (SFT) can improve LLMs performance, it does not scale well compared
to the smaller supervised baseline model. Our quantitative and qualitative
analysis shows that LLMs have several weaknesses when applied for extracting
event relations, including a tendency to fabricate event mentions, and failures
to capture transitivity rules among relations, detect long distance relations,
or comprehend contexts with dense event mentions.

摘要：大型语言模型 (LLM) 已展示出在广泛的自然语言处理任务中具有熟练度。然而，其在话语层面事件关系抽取 (ERE) 任务中的有效性仍未得到探索。在本文中，我们评估了 LLM 在解决话语层面 ERE 任务中的有效性，这些任务的特点是篇幅较长且包含代词、时间、因果和子事件类型等复杂关系。评估使用商业模型 GPT-3.5 和开源模型 LLaMA-2 进行。我们的研究表明，与通过监督学习建立的基线相比，LLM 的表现明显不佳。尽管监督微调 (SFT) 可以提高 LLM 的性能，但与较小的监督基线模型相比，其扩展性不佳。我们的定量和定性分析表明，LLM 在用于提取事件关系时存在若干弱点，包括编造事件提及的倾向，以及未能捕获关系之间的传递性规则、检测长距离关系或理解包含密集事件提及的上下文。

##### **Forecast-PEFT: Parameter-Efficient Fine-Tuning for Pre-trained Motion Forecasting Models**
2407.19564v1 by Jifeng Wang, Kaouther Messaoud, Yuejiang Liu, Juergen Gall, Alexandre Alahi

Recent progress in motion forecasting has been substantially driven by
self-supervised pre-training. However, adapting pre-trained models for specific
downstream tasks, especially motion prediction, through extensive fine-tuning
is often inefficient. This inefficiency arises because motion prediction
closely aligns with the masked pre-training tasks, and traditional full
fine-tuning methods fail to fully leverage this alignment. To address this, we
introduce Forecast-PEFT, a fine-tuning strategy that freezes the majority of
the model's parameters, focusing adjustments on newly introduced prompts and
adapters. This approach not only preserves the pre-learned representations but
also significantly reduces the number of parameters that need retraining,
thereby enhancing efficiency. This tailored strategy, supplemented by our
method's capability to efficiently adapt to different datasets, enhances model
efficiency and ensures robust performance across datasets without the need for
extensive retraining. Our experiments show that Forecast-PEFT outperforms
traditional full fine-tuning methods in motion prediction tasks, achieving
higher accuracy with only 17% of the trainable parameters typically required.
Moreover, our comprehensive adaptation, Forecast-FT, further improves
prediction performance, evidencing up to a 9.6% enhancement over conventional
baseline methods. Code will be available at
https://github.com/csjfwang/Forecast-PEFT.

摘要：最近在運動預測方面的進展主要是由自監督預訓練推動的。然而，通過廣泛的微調來調整預訓練模型以適應特定下游任務，特別是運動預測，通常效率低下。這種低效率是因為運動預測與遮罩預訓練任務密切相關，而傳統的完整微調方法無法充分利用這種對齊。為了解決這個問題，我們引入了 Forecast-PEFT，這是一種微調策略，它凍結了模型的大部分參數，專注於對新引入的提示和適配器的調整。這種方法不僅保留了預先學習的表示，而且還顯著減少了需要重新訓練的參數數量，從而提高了效率。這種量身定制的策略，加上我們的方法有效適應不同數據集的能力，提高了模型效率，並確保了在不同數據集上的穩健性能，而無需進行廣泛的重新訓練。我們的實驗表明，Forecast-PEFT 在運動預測任務中優於傳統的完整微調方法，僅使用通常所需的 17% 的可訓練參數就能實現更高的準確度。此外，我們全面的適應 Forecast-FT 進一步提高了預測性能，證明比傳統的基線方法提高了 9.6%。代碼將在 https://github.com/csjfwang/Forecast-PEFT 上提供。

