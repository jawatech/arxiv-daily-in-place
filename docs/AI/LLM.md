
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-08**|**Recycled Attention: Efficient inference for long-context language models**|Fangyuan Xu et.al.|[2411.05787v1](http://arxiv.org/abs/2411.05787v1)|null|
|**2024-11-08**|**ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles**|Kayo Yin et.al.|[2411.05783v1](http://arxiv.org/abs/2411.05783v1)|null|
|**2024-11-08**|**Using Language Models to Disambiguate Lexical Choices in Translation**|Josh Barua et.al.|[2411.05781v1](http://arxiv.org/abs/2411.05781v1)|null|
|**2024-11-08**|**GazeSearch: Radiology Findings Search Benchmark**|Trong Thang Pham et.al.|[2411.05780v1](http://arxiv.org/abs/2411.05780v1)|null|
|**2024-11-08**|**LLMs as Method Actors: A Model for Prompt Engineering and Architecture**|Colin Doyle et.al.|[2411.05778v1](http://arxiv.org/abs/2411.05778v1)|null|
|**2024-11-08**|**Quantitative Assessment of Intersectional Empathetic Bias and Understanding**|Vojtech Formanek et.al.|[2411.05777v1](http://arxiv.org/abs/2411.05777v1)|null|
|**2024-11-08**|**Fact or Fiction? Can LLMs be Reliable Annotators for Political Truths?**|Veronica Chatrath et.al.|[2411.05775v1](http://arxiv.org/abs/2411.05775v1)|null|
|**2024-11-08**|**FinDVer: Explainable Claim Verification over Long and Hybrid-Content Financial Documents**|Yilun Zhao et.al.|[2411.05764v1](http://arxiv.org/abs/2411.05764v1)|null|
|**2024-11-08**|**Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024**|Christopher Malon et.al.|[2411.05762v1](http://arxiv.org/abs/2411.05762v1)|null|
|**2024-11-08**|**End-to-End Navigation with Vision Language Models: Transforming Spatial Reasoning into Question-Answering**|Dylan Goetting et.al.|[2411.05755v1](http://arxiv.org/abs/2411.05755v1)|null|
|**2024-11-08**|**FisherMask: Enhancing Neural Network Labeling Efficiency in Image Classification Using Fisher Information**|Shreen Gul et.al.|[2411.05752v1](http://arxiv.org/abs/2411.05752v1)|[link](https://github.com/sgchr273/fishermask)|
|**2024-11-08**|**Topology-aware Reinforcement Feature Space Reconstruction for Graph Data**|Wangyang Ying et.al.|[2411.05742v1](http://arxiv.org/abs/2411.05742v1)|null|
|**2024-11-08**|**Aioli: A Unified Optimization Framework for Language Model Data Mixing**|Mayee F. Chen et.al.|[2411.05735v1](http://arxiv.org/abs/2411.05735v1)|null|
|**2024-11-08**|**Image2Text2Image: A Novel Framework for Label-Free Evaluation of Image-to-Text Generation with Text-to-Image Diffusion Models**|Jia-Hong Huang et.al.|[2411.05706v1](http://arxiv.org/abs/2411.05706v1)|null|
|**2024-11-08**|**Asterisk*: Keep it Simple**|Andrew Semenov et.al.|[2411.05691v1](http://arxiv.org/abs/2411.05691v1)|null|
|**2024-11-08**|**Data-Driven Distributed Common Operational Picture from Heterogeneous Platforms using Multi-Agent Reinforcement Learning**|Indranil Sur et.al.|[2411.05683v1](http://arxiv.org/abs/2411.05683v1)|null|
|**2024-11-08**|**Tell What You Hear From What You See -- Video to Audio Generation Through Text**|Xiulong Liu et.al.|[2411.05679v1](http://arxiv.org/abs/2411.05679v1)|null|
|**2024-11-08**|**Improving Molecular Graph Generation with Flow Matching and Optimal Transport**|Xiaoyang Hou et.al.|[2411.05676v1](http://arxiv.org/abs/2411.05676v1)|null|
|**2024-11-08**|**Unmasking the Limits of Large Language Models: A Systematic Evaluation of Masked Text Processing Ability through MskQA and MskCal**|Fuka Matsuzaki et.al.|[2411.05665v1](http://arxiv.org/abs/2411.05665v1)|[link](https://github.com/isfhub/maskcode)|
|**2024-11-08**|**The influence of persona and conversational task on social interactions with a LLM-controlled embodied conversational agent**|Leon O. H. Kroczek et.al.|[2411.05653v1](http://arxiv.org/abs/2411.05653v1)|null|
|**2024-11-08**|**Evaluating Large Language Model Capability in Vietnamese Fact-Checking Data Generation**|Long Truong To et.al.|[2411.05641v1](http://arxiv.org/abs/2411.05641v1)|null|
|**2024-11-08**|**Assessing Open-Source Large Language Models on Argumentation Mining Subtasks**|Mohammad Yeghaneh Abkenar et.al.|[2411.05639v1](http://arxiv.org/abs/2411.05639v1)|null|
|**2024-11-08**|**Impact of Fake News on Social Media Towards Public Users of Different Age Groups**|Kahlil bin Abdul Hakim et.al.|[2411.05638v1](http://arxiv.org/abs/2411.05638v1)|null|
|**2024-11-08**|**SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection**|Tamara R. Lenhard et.al.|[2411.05633v1](http://arxiv.org/abs/2411.05633v1)|null|
|**2024-11-08**|**Knowledge Distillation Neural Network for Predicting Car-following Behaviour of Human-driven and Autonomous Vehicles**|Ayobami Adewale et.al.|[2411.05618v1](http://arxiv.org/abs/2411.05618v1)|null|
|**2024-11-08**|**Expectation vs. Reality: Towards Verification of Psychological Games**|Marta Kwiatkowska et.al.|[2411.05599v1](http://arxiv.org/abs/2411.05599v1)|null|
|**2024-11-08**|**Evaluating and Adapting Large Language Models to Represent Folktales in Low-Resource Languages**|JA Meaney et.al.|[2411.05593v1](http://arxiv.org/abs/2411.05593v1)|null|
|**2024-11-08**|**Open-set object detection: towards unified problem formulation and benchmarking**|Hejer Ammar et.al.|[2411.05564v1](http://arxiv.org/abs/2411.05564v1)|null|
|**2024-11-08**|**Training objective drives the consistency of representational similarity across datasets**|Laure Ciernik et.al.|[2411.05561v1](http://arxiv.org/abs/2411.05561v1)|[link](https://github.com/lciernik/similarity_consistency)|
|**2024-11-08**|**Assessing the Answerability of Queries in Retrieval-Augmented Code Generation**|Geonmin Kim et.al.|[2411.05547v1](http://arxiv.org/abs/2411.05547v1)|null|
|**2024-11-08**|**CRepair: CVAE-based Automatic Vulnerability Repair Technology**|Penghui Liu et.al.|[2411.05540v1](http://arxiv.org/abs/2411.05540v1)|null|
|**2024-11-08**|**How Good is Your Wikipedia?**|Kushal Tatariya et.al.|[2411.05527v1](http://arxiv.org/abs/2411.05527v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v1](http://arxiv.org/abs/2411.05521v1)|null|
|**2024-11-08**|**Towards Scalable Foundation Models for Digital Dermatology**|Fabian Gr√∂ger et.al.|[2411.05514v1](http://arxiv.org/abs/2411.05514v1)|null|
|**2024-11-08**|**An Early FIRST Reproduction and Improvements to Single-Token Decoding for Fast Listwise Reranking**|Zijian Chen et.al.|[2411.05508v1](http://arxiv.org/abs/2411.05508v1)|null|
|**2024-11-08**|**LBPE: Long-token-first Tokenization to Improve Large Language Models**|Haoran Lian et.al.|[2411.05504v1](http://arxiv.org/abs/2411.05504v1)|null|
|**2024-11-08**|**KyrgyzNLP: Challenges, Progress, and Future**|Anton Alekseev et.al.|[2411.05503v1](http://arxiv.org/abs/2411.05503v1)|null|
|**2024-11-08**|**EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**|Abdoul Nasser Hassane Amadou et.al.|[2411.05479v1](http://arxiv.org/abs/2411.05479v1)|[link](https://github.com/jumbo110/eurekha)|
|**2024-11-08**|**Supporting Automated Fact-checking across Topics: Similarity-driven Gradual Topic Learning for Claim Detection**|Amani S. Abumansour et.al.|[2411.05460v1](http://arxiv.org/abs/2411.05460v1)|null|
|**2024-11-08**|**WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models**|Shengda Fan et.al.|[2411.05451v1](http://arxiv.org/abs/2411.05451v1)|[link](https://github.com/openbmb/workflowllm)|
|**2024-11-08**|**ICE-T: A Multi-Faceted Concept for Teaching Machine Learning**|Hendrik Krone et.al.|[2411.05424v1](http://arxiv.org/abs/2411.05424v1)|null|
|**2024-11-08**|**VISTA: Visual Integrated System for Tailored Automation in Math Problem Generation Using LLM**|Jeongwoo Lee et.al.|[2411.05423v1](http://arxiv.org/abs/2411.05423v1)|null|
|**2024-11-08**|**Learning the rules of peptide self-assembly through data mining with large language models**|Zhenze Yang et.al.|[2411.05421v1](http://arxiv.org/abs/2411.05421v1)|[link](https://github.com/lamm-mit/peptideminer)|
|**2024-11-08**|**WeatherGFM: Learning A Weather Generalist Foundation Model via In-context Learning**|Xiangyu Zhao et.al.|[2411.05420v1](http://arxiv.org/abs/2411.05420v1)|null|
|**2024-11-08**|**Web Archives Metadata Generation with GPT-4o: Challenges and Insights**|Abigail Yongping Huang et.al.|[2411.05409v1](http://arxiv.org/abs/2411.05409v1)|[link](https://github.com/masamune-prog/warc2summary)|
|**2024-11-08**|**Gap-Filling Prompting Enhances Code-Assisted Mathematical Reasoning**|Mohammad Ghiasvand Mohammadkhani et.al.|[2411.05407v1](http://arxiv.org/abs/2411.05407v1)|null|
|**2024-11-08**|**Benchmarking Distributional Alignment of Large Language Models**|Nicole Meister et.al.|[2411.05403v1](http://arxiv.org/abs/2411.05403v1)|[link](https://github.com/nicolemeister/benchmarking-distributional-alignment)|
|**2024-11-08**|**Advancing Meteorological Forecasting: AI-based Approach to Synoptic Weather Map Analysis**|Yo-Hwan Choi et.al.|[2411.05384v1](http://arxiv.org/abs/2411.05384v1)|null|
|**2024-11-08**|**Towards Low-Resource Harmful Meme Detection with LMM Agents**|Jianzhao Huang et.al.|[2411.05383v1](http://arxiv.org/abs/2411.05383v1)|[link](https://github.com/jianzhao-huang/lorehm)|
|**2024-11-08**|**Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking**|Mubashara Akhtar et.al.|[2411.05375v1](http://arxiv.org/abs/2411.05375v1)|null|
|**2024-11-08**|**Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks**|Chien-yu Huang et.al.|[2411.05361v1](http://arxiv.org/abs/2411.05361v1)|null|
|**2024-11-08**|**Agricultural Landscape Understanding At Country-Scale**|Radhika Dua et.al.|[2411.05359v1](http://arxiv.org/abs/2411.05359v1)|null|
|**2024-11-08**|**Controlling Grokking with Nonlinearity and Data Symmetry**|Ahmed Salah et.al.|[2411.05353v1](http://arxiv.org/abs/2411.05353v1)|null|
|**2024-11-08**|**Enhancing Cluster Resilience: LLM-agent Based Autonomous Intelligent Cluster Diagnosis System and Evaluation Framework**|Honghao Shi et.al.|[2411.05349v1](http://arxiv.org/abs/2411.05349v1)|null|
|**2024-11-08**|**LLM-PySC2: Starcraft II learning environment for Large Language Models**|Zongyuan Li et.al.|[2411.05348v1](http://arxiv.org/abs/2411.05348v1)|null|
|**2024-11-08**|**Reasoning Robustness of LLMs to Adversarial Typographical Errors**|Esther Gan et.al.|[2411.05345v1](http://arxiv.org/abs/2411.05345v1)|null|
|**2024-11-08**|**Improving Multi-Domain Task-Oriented Dialogue System with Offline Reinforcement Learning**|Dharmendra Prajapat et.al.|[2411.05340v1](http://arxiv.org/abs/2411.05340v1)|null|
|**2024-11-08**|**SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers**|Shruti Singh et.al.|[2411.05338v1](http://arxiv.org/abs/2411.05338v1)|null|
|**2024-11-08**|**Inversion-based Latent Bayesian Optimization**|Jaewon Chu et.al.|[2411.05330v1](http://arxiv.org/abs/2411.05330v1)|[link](https://github.com/mlvlab/invbo)|
|**2024-11-08**|**Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**|Dong Shu et.al.|[2411.05316v1](http://arxiv.org/abs/2411.05316v1)|[link](https://github.com/tizzzzy/llm-gdm-alignment)|
|**2024-11-08**|**On Training of Kolmogorov-Arnold Networks**|Shairoz Sohail et.al.|[2411.05296v1](http://arxiv.org/abs/2411.05296v1)|null|
|**2024-11-08**|**SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding**|Ryan Sun et.al.|[2411.05289v1](http://arxiv.org/abs/2411.05289v1)|[link](https://github.com/mastergodzilla/speculative_decoding_ot)|
|**2024-11-08**|**A Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents**|Liming Dong et.al.|[2411.05285v1](http://arxiv.org/abs/2411.05285v1)|null|
|**2024-11-08**|**MicroScopiQ: Accelerating Foundational Models through Outlier-Aware Microscaling Quantization**|Akshat Ramachandran et.al.|[2411.05282v1](http://arxiv.org/abs/2411.05282v1)|null|
|**2024-11-08**|**Fox-1 Technical Report**|Zijian Hu et.al.|[2411.05281v1](http://arxiv.org/abs/2411.05281v1)|null|
|**2024-11-08**|**Revisiting the Robustness of Watermarking to Paraphrasing Attacks**|Saksham Rastogi et.al.|[2411.05277v1](http://arxiv.org/abs/2411.05277v1)|null|
|**2024-11-08**|**Real-World Offline Reinforcement Learning from Vision Language Model Feedback**|Sreyas Venkataraman et.al.|[2411.05273v1](http://arxiv.org/abs/2411.05273v1)|null|
|**2024-11-08**|**Seeing Through the Fog: A Cost-Effectiveness Analysis of Hallucination Detection Systems**|Alexander Thomas et.al.|[2411.05270v1](http://arxiv.org/abs/2411.05270v1)|null|
|**2024-11-08**|**Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations**|Yingying Fang et.al.|[2411.05261v1](http://arxiv.org/abs/2411.05261v1)|null|
|**2024-11-08**|**QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning**|Md Jueal Mia et.al.|[2411.05260v1](http://arxiv.org/abs/2411.05260v1)|null|
|**2024-11-08**|**What talking you?: Translating Code-Mixed Messaging Texts to English**|Lynnette Hui Xian Ng et.al.|[2411.05253v1](http://arxiv.org/abs/2411.05253v1)|null|
|**2024-11-07**|**Abstract2Appendix: Academic Reviews Enhance LLM Long-Context Capabilities**|Shengzhi Li et.al.|[2411.05232v1](http://arxiv.org/abs/2411.05232v1)|null|
|**2024-11-07**|**Evaluating GPT-4 at Grading Handwritten Solutions in Math Exams**|Adriana Caraeni et.al.|[2411.05231v1](http://arxiv.org/abs/2411.05231v1)|null|
|**2024-11-07**|**CHATTER: A Character Attribution Dataset for Narrative Understanding**|Sabyasachee Baruah et.al.|[2411.05227v1](http://arxiv.org/abs/2411.05227v1)|null|
|**2024-11-07**|**Beyond the Numbers: Transparency in Relation Extraction Benchmark Creation and Leaderboards**|Varvara Arzt et.al.|[2411.05224v1](http://arxiv.org/abs/2411.05224v1)|null|
|**2024-11-07**|**STAND-Guard: A Small Task-Adaptive Content Moderation Model**|Minjia Wang et.al.|[2411.05214v1](http://arxiv.org/abs/2411.05214v1)|null|
|**2024-11-07**|**Alopex: A Computational Framework for Enabling On-Device Function Calls with LLMs**|Yide Ran et.al.|[2411.05209v1](http://arxiv.org/abs/2411.05209v1)|null|
|**2024-11-07**|**Toward Cultural Interpretability: A Linguistic Anthropological Framework for Describing and Evaluating Large Language Models (LLMs)**|Graham M. Jones et.al.|[2411.05200v1](http://arxiv.org/abs/2411.05200v1)|null|
|**2024-11-07**|**CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement**|Leitian Tao et.al.|[2411.05199v1](http://arxiv.org/abs/2411.05199v1)|null|
|**2024-11-07**|**Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method**|Turker Berk Donmez et.al.|[2411.05196v1](http://arxiv.org/abs/2411.05196v1)|null|
|**2024-11-07**|**On Erroneous Agreements of CLIP Image Embeddings**|Siting Li et.al.|[2411.05195v1](http://arxiv.org/abs/2411.05195v1)|null|
|**2024-11-07**|**Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**|Joey Hong et.al.|[2411.05194v1](http://arxiv.org/abs/2411.05194v1)|null|
|**2024-11-07**|**Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning**|Joey Hong et.al.|[2411.05193v1](http://arxiv.org/abs/2411.05193v1)|null|
|**2024-11-07**|**Explaining Mixtures of Sources in News Articles**|Alexander Spangher et.al.|[2411.05192v1](http://arxiv.org/abs/2411.05192v1)|null|
|**2024-11-07**|**Discern-XR: An Online Classifier for Metaverse Network Traffic**|Yoga Suhas Kuruba Manjunath et.al.|[2411.05184v1](http://arxiv.org/abs/2411.05184v1)|null|
|**2024-11-07**|**Inverse Transition Learning: Learning Dynamics from Demonstrations**|Leo Benac et.al.|[2411.05174v1](http://arxiv.org/abs/2411.05174v1)|null|
|**2024-11-07**|**ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Language**|Yuxin Wang et.al.|[2411.05172v1](http://arxiv.org/abs/2411.05172v1)|[link](https://github.com/audreycs/impscore)|
|**2024-11-07**|**Watermarking Language Models through Language Models**|Xin Zhong et.al.|[2411.05091v1](http://arxiv.org/abs/2411.05091v1)|null|
|**2024-11-07**|**Findings of the IWSLT 2024 Evaluation Campaign**|Ibrahim Said Ahmad et.al.|[2411.05088v1](http://arxiv.org/abs/2411.05088v1)|null|
|**2024-11-07**|**PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**|Daniel C. Castro et.al.|[2411.05085v1](http://arxiv.org/abs/2411.05085v1)|null|
|**2024-11-07**|**Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model**|Sheng Cheng et.al.|[2411.05079v1](http://arxiv.org/abs/2411.05079v1)|[link](https://github.com/shengcheng/captions4t2i)|
|**2024-11-07**|**ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning**|David Junhao Zhang et.al.|[2411.05003v1](http://arxiv.org/abs/2411.05003v1)|null|
|**2024-11-07**|**Analyzing The Language of Visual Tokens**|David M. Chan et.al.|[2411.05001v1](http://arxiv.org/abs/2411.05001v1)|null|
|**2024-11-07**|**Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?**|Jonathan Roberts et.al.|[2411.05000v1](http://arxiv.org/abs/2411.05000v1)|null|
|**2024-11-07**|**LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation**|Weiquan Huang et.al.|[2411.04997v1](http://arxiv.org/abs/2411.04997v1)|[link](https://github.com/microsoft/LLM2CLIP)|
|**2024-11-07**|**HourVideo: 1-Hour Video-Language Understanding**|Keshigeyan Chandrasegaran et.al.|[2411.04998v1](http://arxiv.org/abs/2411.04998v1)|null|
|**2024-11-07**|**Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models**|Weixin Liang et.al.|[2411.04996v1](http://arxiv.org/abs/2411.04996v1)|null|
|**2024-11-07**|**Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives**|Hao Sun et.al.|[2411.04991v1](http://arxiv.org/abs/2411.04991v1)|[link](https://github.com/holarissun/rewardmodelingbeyondbradleyterry)|
|**2024-11-07**|**Few-Shot Task Learning through Inverse Generative Modeling**|Aviv Netanyahu et.al.|[2411.04987v1](http://arxiv.org/abs/2411.04987v1)|null|
|**2024-11-07**|**The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities**|Zhaofeng Wu et.al.|[2411.04986v1](http://arxiv.org/abs/2411.04986v1)|null|

#### Abstracts
##### **Recycled Attention: Efficient inference for long-context language models**
2411.05787v1 by Fangyuan Xu, Tanya Goyal, Eunsol Choi

Generating long sequences of tokens given a long-context input imposes a
heavy computational burden for large language models (LLMs). One of the
computational bottleneck comes from computing attention over a long sequence of
input at each generation step. In this paper, we propose Recycled Attention, an
inference-time method which alternates between full context attention and
attention over a subset of input tokens. When performing partial attention, we
recycle the attention pattern of a previous token that has performed full
attention and attend only to the top K most attended tokens, reducing the cost
of data movement and attention computation. Compared to previously proposed
inference-time acceleration method which attends only to local context or
tokens with high accumulative attention scores, our approach flexibly chooses
tokens that are relevant to the current decoding step. We evaluate our methods
on RULER, a suite of tasks designed to comprehensively evaluate long-context
abilities, and long-context language modeling tasks. Applying our method to
off-the-shelf LLMs achieves comparable speedup to baselines which only consider
local context while improving the performance by 2x. We further explore two
ideas to improve performance-efficiency trade-offs: (1) dynamically decide when
to perform recycled or full attention step based on the query similarities and
(2) continued pre-training the model with Recycled Attention.

ÊëòË¶ÅÔºöÂú®Êèê‰æõÈï∑ËÉåÊôØËº∏ÂÖ•ÁöÑÊÉÖÊ≥Å‰∏ãÁî¢ÁîüÈï∑Â∫èÂàóÁöÑÁ¨¶ËôüÊúÉÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ†ÊàêÊ≤âÈáçÁöÑË®àÁÆóË≤†Êìî„ÄÇÂÖ∂‰∏≠‰∏ÄÂÄãË®àÁÆóÁì∂È†∏‰æÜËá™ÊñºÂú®ÊØèÂÄãÁî¢ÁîüÊ≠•È©ü‰∏≠Ë®àÁÆóÈï∑Ëº∏ÂÖ•Â∫èÂàóÁöÑÊ≥®ÊÑèÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Âæ™Áí∞Ê≥®ÊÑèÂäõÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂú®ÂÆåÊï¥ËÉåÊôØÊ≥®ÊÑèÂäõÂíåËº∏ÂÖ•Á¨¶ËôüÂ≠êÈõÜÁöÑÊ≥®ÊÑèÂäõ‰πãÈñì‰∫§ÊõøÁöÑÊé®Ë´ñÊôÇÈñìÊñπÊ≥ï„ÄÇÂú®Âü∑Ë°åÈÉ®ÂàÜÊ≥®ÊÑèÂäõÊôÇÔºåÊàëÂÄëÂæ™Áí∞Âà©Áî®Â∑≤Âü∑Ë°åÂÆåÊï¥Ê≥®ÊÑèÂäõÁöÑÂâç‰∏ÄÂÄãÁ¨¶ËôüÁöÑÊ≥®ÊÑèÂäõÊ®°ÂºèÔºå‰∏¶ÂÉÖÊ≥®ÊÑèÊúÄÂèóÈóúÊ≥®ÁöÑ K ÂÄãÁ¨¶ËôüÔºåÂæûËÄåÈôç‰Ωé‰∫ÜÊï∏ÊìöÁßªÂãïÂíåÊ≥®ÊÑèÂäõË®àÁÆóÁöÑÊàêÊú¨„ÄÇËàáÂÖàÂâçÊèêÂá∫ÁöÑÂÉÖÈóúÊ≥®Â±ÄÈÉ®ËÉåÊôØÊàñÁ¥ØÁ©çÊ≥®ÊÑèÂäõÂàÜÊï∏È´òÁöÑÁ¨¶ËôüÁöÑÊé®Ë´ñÊôÇÈñìÂä†ÈÄüÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈùàÊ¥ªÂú∞ÈÅ∏ÊìáËàáÁï∂ÂâçËß£Á¢ºÊ≠•È©üÁõ∏ÈóúÁöÑÁ¨¶Ëôü„ÄÇÊàëÂÄëÂú® RULER ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÊ®°ÂûãÔºåRULER ÊòØ‰∏ÄÁµÑÊó®Âú®ÂÖ®Èù¢Ë©ï‰º∞Èï∑ËÉåÊôØËÉΩÂäõÁöÑ‰ªªÂãôÔºå‰ª•ÂèäÈï∑ËÉåÊôØË™ûË®ÄÂª∫Ê®°‰ªªÂãô„ÄÇÂ∞áÊàëÂÄëÁöÑÊ®°ÂûãÊáâÁî®ÊñºÁèæÊàêÁöÑ LLMÔºåÂèØÂØ¶ÁèæËàáÂÉÖËÄÉÊÖÆÂ±ÄÈÉ®ËÉåÊôØÁöÑÂü∫Á∑öÁõ∏Áï∂ÁöÑÂä†ÈÄüÔºåÂêåÊôÇÂ∞áÊïàËÉΩÊèêÂçá 2 ÂÄç„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫ÜÂÖ©Á®ÆÊèêÂçáÊïàËÉΩÊïàÁéáÊäòË°∑ÁöÑÊßãÊÉ≥Ôºö(1) Ê†πÊìöÊü•Ë©¢Áõ∏‰ººÊÄßÂãïÊÖãÊ±∫ÂÆö‰ΩïÊôÇÂü∑Ë°åÂæ™Áí∞ÊàñÂÆåÊï¥Ê≥®ÊÑèÂäõÊ≠•È©üÔºå‰ª•Âèä (2) ÊåÅÁ∫å‰ΩøÁî®Âæ™Áí∞Ê≥®ÊÑèÂäõÈ†êË®ìÁ∑¥Ê®°Âûã„ÄÇ

##### **ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles**
2411.05783v1 by Kayo Yin, Chinmay Singh, Fyodor O. Minakov, Vanessa Milan, Hal Daum√© III, Cyril Zhang, Alex X. Lu, Danielle Bragg

Deaf and hard-of-hearing (DHH) students face significant barriers in
accessing science, technology, engineering, and mathematics (STEM) education,
notably due to the scarcity of STEM resources in signed languages. To help
address this, we introduce ASL STEM Wiki: a parallel corpus of 254 Wikipedia
articles on STEM topics in English, interpreted into over 300 hours of American
Sign Language (ASL). ASL STEM Wiki is the first continuous signing dataset
focused on STEM, facilitating the development of AI resources for STEM
education in ASL. We identify several use cases of ASL STEM Wiki with
human-centered applications. For example, because this dataset highlights the
frequent use of fingerspelling for technical concepts, which inhibits DHH
students' ability to learn, we develop models to identify fingerspelled words
-- which can later be used to query for appropriate ASL signs to suggest to
interpreters.

ÊëòË¶ÅÔºöËÅΩÈöúÂíåÈáçËÅΩ (DHH) Â≠∏ÁîüÂú®ÂèñÂæóÁßëÂ≠∏„ÄÅÊäÄË°ì„ÄÅÂ∑•Á®ãÂíåÊï∏Â≠∏ (STEM) ÊïôËÇ≤ÊôÇÔºåÊúÉÈù¢Ëá®ÈáçÂ§ßÁöÑÈöúÁ§ôÔºåÈÄô‰∏ªË¶ÅÊòØÂõ†ÁÇ∫ÊâãË™û‰∏≠Áº∫‰πè STEM Ë≥áÊ∫ê„ÄÇÁÇ∫‰∫ÜÂπ´Âä©Ëß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ASL STEM WikiÔºö‰∏ÄÂÄãÂåÖÂê´ 254 ÁØáËã±Ë™û STEM ‰∏ªÈ°åÁöÑÁ∂≠Âü∫ÁôæÁßëÊ¢ùÁõÆÂπ≥Ë°åË™ûÊñôÂ∫´Ôºå‰∏¶ÁøªË≠ØÊàêË∂ÖÈÅé 300 Â∞èÊôÇÁöÑÁæéÂúãÊâãË™û (ASL)„ÄÇASL STEM Wiki ÊòØÁ¨¨‰∏ÄÂÄãÂ∞àÊ≥®Êñº STEM ÁöÑÈÄ£Á∫åÊâãË™ûË≥áÊñôÈõÜÔºåÊúâÂä©ÊñºÈñãÁôº ASL ‰∏≠ STEM ÊïôËÇ≤ÁöÑ AI Ë≥áÊ∫ê„ÄÇÊàëÂÄëÊâæÂá∫ ASL STEM Wiki ÁöÑÂπæÂÄã‰ΩøÁî®Ê°à‰æãÔºåÈÄô‰∫õÊ°à‰æãÂÖ∑Êúâ‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑÊáâÁî®„ÄÇ‰æãÂ¶ÇÔºåÁî±ÊñºÈÄôÂÄãË≥áÊñôÈõÜÁ™ÅÈ°Ø‰∫ÜÊäÄË°ìÊ¶ÇÂøµ‰∏≠Á∂ìÂ∏∏‰ΩøÁî®ÊâãÊåáÊãºÂØ´ÔºåÈÄôÊúÉÊäëÂà∂ DHH Â≠∏ÁîüÂ≠∏ÁøíÁöÑËÉΩÂäõÔºåÂõ†Ê≠§ÊàëÂÄëÈñãÁôºÊ®°Âûã‰æÜË≠òÂà•ÊâãÊåáÊãºÂØ´ÁöÑÂ≠óË©ûÔºåÈÄô‰∫õÂ≠óË©ûÁ®çÂæåÂèØÊü•Ë©¢ÈÅ©Áï∂ÁöÑ ASL ÊâãÂã¢Ôºå‰ª•Âª∫Ë≠∞Áµ¶Âè£Ë≠ØÂì°„ÄÇ

##### **Using Language Models to Disambiguate Lexical Choices in Translation**
2411.05781v1 by Josh Barua, Sanjay Subramanian, Kayo Yin, Alane Suhr

In translation, a concept represented by a single word in a source language
can have multiple variations in a target language. The task of lexical
selection requires using context to identify which variation is most
appropriate for a source text. We work with native speakers of nine languages
to create DTAiLS, a dataset of 1,377 sentence pairs that exhibit cross-lingual
concept variation when translating from English. We evaluate recent LLMs and
neural machine translation systems on DTAiLS, with the best-performing model,
GPT-4, achieving from 67 to 85% accuracy across languages. Finally, we use
language models to generate English rules describing target-language concept
variations. Providing weaker models with high-quality lexical rules improves
accuracy substantially, in some cases reaching or outperforming GPT-4.

ÊëòË¶ÅÔºöÂú®ÁøªË≠Ø‰∏≠ÔºåÊ∫êË™ûË®Ä‰∏≠ÂñÆÂ≠óÊâÄ‰ª£Ë°®ÁöÑÊ¶ÇÂøµÂú®ÁõÆÊ®ôË™ûË®Ä‰∏≠ÂèØËÉΩÊúâÂ§öÁ®ÆËÆäÂåñ„ÄÇË©ûÂΩôÈÅ∏ÊìáÁöÑ‰ªªÂãôÈúÄË¶Å‰ΩøÁî®‰∏ä‰∏ãÊñá‰æÜË≠òÂà•Âì™ÂÄãËÆäÂåñÊúÄÈÅ©ÂêàÂéüÂßãÊñáÂ≠ó„ÄÇÊàëÂÄëËàá‰πùÁ®ÆË™ûË®ÄÁöÑÊØçË™û‰∫∫Â£´Âêà‰ΩúÔºåÂª∫Á´ã‰∫Ü DTAiLSÔºåÈÄôÊòØ‰∏ÄÂÄãÁî± 1,377 ÂÄãÂè•Â≠êÂ∞çÁµÑÊàêÁöÑË≥áÊñôÈõÜÔºåÂú®ÂæûËã±Ë™ûÁøªË≠ØÊôÇÂ±ïÁèæ‰∫ÜË∑®Ë™ûË®ÄÊ¶ÇÂøµËÆäÂåñ„ÄÇÊàëÂÄëÂú® DTAiLS ‰∏äË©ï‰º∞‰∫ÜÊúÄËøëÁöÑ LLM ÂíåÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÁ≥ªÁµ±ÔºåË°®ÁèæÊúÄ‰Ω≥ÁöÑÊ®°Âûã GPT-4 Âú®ÂêÑÁ®ÆË™ûË®Ä‰∏≠ÈÅîÂà∞‰∫Ü 67% Âà∞ 85% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊúÄÂæåÔºåÊàëÂÄë‰ΩøÁî®Ë™ûË®ÄÊ®°Âûã‰æÜÁî¢ÁîüÊèèËø∞ÁõÆÊ®ôË™ûË®ÄÊ¶ÇÂøµËÆäÂåñÁöÑËã±ÊñáË¶èÂâá„ÄÇÁÇ∫ËºÉÂº±ÁöÑÊ®°ÂûãÊèê‰æõÈ´òÂìÅË≥™ÁöÑË©ûÂΩôË¶èÂâáÂèØ‰ª•Â§ßÂπÖÊèêÂçáÊ∫ñÁ¢∫Â∫¶ÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÁîöËá≥ÈÅîÂà∞ÊàñË∂ÖË∂ä GPT-4„ÄÇ

##### **GazeSearch: Radiology Findings Search Benchmark**
2411.05780v1 by Trong Thang Pham, Tien-Phat Nguyen, Yuki Ikebe, Akash Awasthi, Zhigang Deng, Carol C. Wu, Hien Nguyen, Ngan Le

Medical eye-tracking data is an important information source for
understanding how radiologists visually interpret medical images. This
information not only improves the accuracy of deep learning models for X-ray
analysis but also their interpretability, enhancing transparency in
decision-making. However, the current eye-tracking data is dispersed,
unprocessed, and ambiguous, making it difficult to derive meaningful insights.
Therefore, there is a need to create a new dataset with more focus and
purposeful eyetracking data, improving its utility for diagnostic applications.
In this work, we propose a refinement method inspired by the target-present
visual search challenge: there is a specific finding and fixations are guided
to locate it. After refining the existing eye-tracking datasets, we transform
them into a curated visual search dataset, called GazeSearch, specifically for
radiology findings, where each fixation sequence is purposefully aligned to the
task of locating a particular finding. Subsequently, we introduce a scan path
prediction baseline, called ChestSearch, specifically tailored to GazeSearch.
Finally, we employ the newly introduced GazeSearch as a benchmark to evaluate
the performance of current state-of-the-art methods, offering a comprehensive
assessment for visual search in the medical imaging domain.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÁúºÂãïËøΩËπ§Ë≥áÊñôÊòØ‰∫ÜËß£ÊîæÂ∞ÑÁßëÈÜ´Â∏´Â¶Ç‰ΩïË¶ñË¶∫ÂåñË©ÆÈáãÈÜ´ÁôÇÂΩ±ÂÉèÁöÑÈáçË¶ÅË≥áË®ä‰æÜÊ∫ê„ÄÇÈÄô‰∫õË≥áË®ä‰∏çÂÉÖÊèêÂçá‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú® X ÂÖâÂàÜÊûê‰∏≠ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰πüÊèêÂçá‰∫ÜÂÖ∂ÂèØËß£ÈáãÊÄßÔºåÂ¢ûÈÄ≤Ê±∫Á≠ñÂà∂ÂÆö‰∏≠ÁöÑÈÄèÊòéÂ∫¶„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÈÜ´ÁôÇÁúºÂãïËøΩËπ§Ë≥áÊñôÂàÜÊï£„ÄÅÊú™Á∂ìËôïÁêÜ‰∏î‰∏çÊòéÁ¢∫ÔºåÈÄô‰ΩøÂæóÈõ£‰ª•Êé®Â∞éÂá∫ÊúâÊÑèÁæ©ÁöÑË¶ãËß£„ÄÇÂõ†Ê≠§ÔºåÊúâÂøÖË¶ÅÂª∫Á´ã‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Êõ¥Â§öÁÑ¶ÈªûÂíåÊúâÁõÆÁöÑÁöÑÁúºÂãïËøΩËπ§Ë≥áÊñôÔºå‰ª•ÊèêÂçáÂÖ∂Âú®Ë®∫Êñ∑ÊáâÁî®‰∏≠ÁöÑÊïàÁî®„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊîπËâØÊñπÊ≥ïÔºåÂÖ∂ÈùàÊÑü‰æÜËá™ÁõÆÊ®ôÂëàÁèæË¶ñË¶∫ÊêúÂ∞ãÊåëÊà∞ÔºöÊúâ‰∏ÄÂÄãÁâπÂÆöÁöÑÁôºÁèæÔºåËÄåÂõ∫ÂÆöÂâáÁî®ÊñºÂÆö‰ΩçÂÆÉ„ÄÇÂú®ÊîπËâØÁèæÊúâÁöÑÁúºÂãïËøΩËπ§Ë≥áÊñôÈõÜÂæåÔºåÊàëÂÄëÂ∞áÂÖ∂ËΩâÊèõÁÇ∫‰∏ÄÂÄãÂêçÁÇ∫ GazeSearch ÁöÑÁ≤æÈÅ∏Ë¶ñË¶∫ÊêúÂ∞ãË≥áÊñôÈõÜÔºåÂ∞àÈñÄÁî®ÊñºÊîæÂ∞ÑÁßëÁôºÁèæÔºåÂÖ∂‰∏≠ÊØèÂÄãÂõ∫ÂÆöÂ∫èÂàóÈÉΩÂàªÊÑèËàáÂÆö‰ΩçÁâπÂÆöÁôºÁèæÁöÑ‰ªªÂãôÂ∞çÈΩä„ÄÇÈö®ÂæåÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊéÉÊèèË∑ØÂæëÈ†êÊ∏¨Âü∫Ê∫ñÔºåÁ®±ÁÇ∫ ChestSearchÔºåÂ∞àÈñÄÈáùÂ∞ç GazeSearch ÈáèË∫´ÊâìÈÄ†„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé°Áî®Êñ∞Êé®Âá∫ÁöÑ GazeSearch ‰ΩúÁÇ∫Âü∫Ê∫ñÔºåË©ï‰º∞ÁõÆÂâçÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÊèê‰æõÈÜ´ÁôÇÂΩ±ÂÉèÈ†òÂüü‰∏≠Ë¶ñË¶∫ÊêúÂ∞ãÁöÑÂÖ®Èù¢Ë©ï‰º∞„ÄÇ

##### **LLMs as Method Actors: A Model for Prompt Engineering and Architecture**
2411.05778v1 by Colin Doyle

We introduce "Method Actors" as a mental model for guiding LLM prompt
engineering and prompt architecture. Under this mental model, LLMs should be
thought of as actors; prompts as scripts and cues; and LLM responses as
performances. We apply this mental model to the task of improving LLM
performance at playing Connections, a New York Times word puzzle game that
prior research identified as a challenging benchmark for evaluating LLM
reasoning. Our experiments with GPT-4o show that a "Method Actors" approach can
significantly improve LLM performance over both a vanilla and "Chain of
Thoughts" approach. A vanilla approach solves 27% of Connections puzzles in our
dataset and a "Chain of Thoughts" approach solves 41% of puzzles, whereas our
strongest "Method Actor" approach solves 86% of puzzles. We also test OpenAI's
newest model designed specifically for complex reasoning tasks, o1-preview.
When asked to solve a puzzle all at once, o1-preview solves 79% of Connections
puzzles in our dataset, and when allowed to build puzzle solutions one guess at
a time over multiple API calls, o1-preview solves 100% of the puzzles.
Incorporating a "Method Actor" prompt architecture increases the percentage of
puzzles that o1-preview solves perfectly from 76% to 87%.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÂºïÂÖ•„ÄåÊñπÊ≥ïÊºîÂì°„Äç‰ΩúÁÇ∫ÊåáÂ∞é LLM ÊèêÁ§∫Â∑•Á®ãÂíåÊèêÁ§∫Êû∂ÊßãÁöÑÂøÉÊô∫Ê®°Âûã„ÄÇÂú®ÈÄôÂÄãÂøÉÊô∫Ê®°Âûã‰∏ãÔºåLLM ÊáâË¢´Ë¶ñÁÇ∫ÊºîÂì°ÔºõÊèêÁ§∫ÁÇ∫ËÖ≥Êú¨ÂíåÊèêÁ§∫ÔºõLLM ÂõûÊáâÁÇ∫Ë°®Êºî„ÄÇÊàëÂÄëÂ∞áÈÄôÂÄãÂøÉÊô∫Ê®°ÂûãÊáâÁî®ÊñºÊîπÈÄ≤ LLM Âú®Áé©„ÄåÈÄ£Á∑ö„ÄçÈÅäÊà≤ÊôÇÁöÑË°®ÁèæÔºåÈÄôÊòØ‰∏ÄÊ¨æÁ¥êÁ¥ÑÊôÇÂ†±ÁöÑÊñáÂ≠óÁõäÊô∫ÈÅäÊà≤ÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÊåáÂá∫ÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºË©ï‰º∞ LLM Êé®ÁêÜÁöÑÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÂ∞ç GPT-4o ÈÄ≤Ë°åÁöÑÂØ¶È©óÈ°ØÁ§∫Ôºå„ÄåÊñπÊ≥ïÊºîÂì°„ÄçÊñπÊ≥ïÂèØ‰ª•È°ØËëóÊèêÂçá LLM ÁöÑË°®ÁèæÔºåÂÑ™ÊñºÂÇ≥Áµ±ÊñπÊ≥ïÂíå„ÄåÊÄùËÄÉÈèà„ÄçÊñπÊ≥ï„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏≠Ëß£Èñã‰∫Ü 27% ÁöÑ„ÄåÈÄ£Á∑ö„ÄçÁõäÊô∫ÈÅäÊà≤ÔºåËÄå„ÄåÊÄùËÄÉÈèà„ÄçÊñπÊ≥ïËß£Èñã‰∫Ü 41% ÁöÑÁõäÊô∫ÈÅäÊà≤ÔºåËÄåÊàëÂÄëÊúÄÂº∑Â§ßÁöÑ„ÄåÊñπÊ≥ïÊºîÂì°„ÄçÊñπÊ≥ïËß£Èñã‰∫Ü 86% ÁöÑÁõäÊô∫ÈÅäÊà≤„ÄÇÊàëÂÄë‰πüÊ∏¨Ë©¶‰∫Ü OpenAI ÊúÄÊñ∞Â∞àÈñÄË®≠Ë®àÁî®ÊñºË§áÈõúÊé®ÁêÜ‰ªªÂãôÁöÑÊ®°Âûã o1-preview„ÄÇÁï∂Ë¶ÅÊ±Ç‰∏ÄÊ¨°Ëß£Èñã‰∏ÄÂÄãÁõäÊô∫ÈÅäÊà≤ÊôÇÔºåo1-preview Âú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏≠Ëß£Èñã‰∫Ü 79% ÁöÑ„ÄåÈÄ£Á∑ö„ÄçÁõäÊô∫ÈÅäÊà≤ÔºåËÄåÁï∂ÂÖÅË®±‰∏ÄÊ¨°ÁåúÊ∏¨‰∏ÄÂÄãÊèêÁ§∫ÔºåÈÄèÈÅéÂ§öÊ¨° API ÂëºÂè´‰æÜÂª∫ÊßãÁõäÊô∫ÈÅäÊà≤Ëß£Á≠îÊôÇÔºåo1-preview Ëß£Èñã‰∫Ü 100% ÁöÑÁõäÊô∫ÈÅäÊà≤„ÄÇÊï¥Âêà„ÄåÊñπÊ≥ïÊºîÂì°„ÄçÊèêÁ§∫Êû∂ÊßãÊúÉÂ∞á o1-preview ÂÆåÁæéËß£ÈñãÁöÑÁõäÊô∫ÈÅäÊà≤ÁôæÂàÜÊØîÂæû 76% ÊèêÂçáËá≥ 87%„ÄÇ</paragraph>

##### **Quantitative Assessment of Intersectional Empathetic Bias and Understanding**
2411.05777v1 by Vojtech Formanek, Ondrej Sotolar

A growing amount of literature critiques the current operationalizations of
empathy based on loose definitions of the construct. Such definitions
negatively affect dataset quality, model robustness, and evaluation
reliability. We propose an empathy evaluation framework that operationalizes
empathy close to its psychological origins. The framework measures the variance
in responses of LLMs to prompts using existing metrics for empathy and
emotional valence. The variance is introduced through the controlled generation
of the prompts by varying social biases affecting context understanding, thus
impacting empathetic understanding. The control over generation ensures high
theoretical validity of the constructs in the prompt dataset. Also, it makes
high-quality translation, especially into languages that currently have
little-to-no way of evaluating empathy or bias, such as the Slavonic family,
more manageable. Using chosen LLMs and various prompt types, we demonstrate the
empathy evaluation with the framework, including multiple-choice answers and
free generation. The variance in our initial evaluation sample is small and we
were unable to measure convincing differences between the empathetic
understanding in contexts given by different social groups. However, the
results are promising because the models showed significant alterations their
reasoning chains needed to capture the relatively subtle changes in the
prompts. This provides the basis for future research into the construction of
the evaluation sample and statistical methods for measuring the results.

ÊëòË¶ÅÔºöÈö®ËëóË∂ä‰æÜË∂äÂ§öÊñáÁçªÊé¢Ë®éÂü∫ÊñºÁµêÊßãÈ¨ÜÊï£ÂÆöÁæ©ÁöÑÂêåÁêÜÂøÉÁï∂ÂâçÈÅã‰ΩúÊñπÂºèÔºåÊàëÂÄëÁôºÁèæÈÄô‰∫õÂÆöÁæ©ÊúÉÂ∞çË≥áÊñôÈõÜÂìÅË≥™„ÄÅÊ®°ÂûãÂÅ•ÂÖ®ÊÄß‰ª•ÂèäË©ï‰º∞ÂèØÈù†ÊÄßÈÄ†ÊàêË≤†Èù¢ÂΩ±Èüø„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêåÁêÜÂøÉË©ï‰º∞Êû∂ÊßãÔºåÂ∞áÂêåÁêÜÂøÉÈÅã‰ΩúÂåñÔºå‰ΩøÂÖ∂Êé•ËøëÂÖ∂ÂøÉÁêÜËµ∑Ê∫ê„ÄÇÈÄôÂÄãÊû∂Êßã‰ΩøÁî®ÁèæÊúâÁöÑÂêåÁêÜÂøÉÂíåÊÉÖÁ∑íÊïàÂÉπÈáèÂ∫¶Ôºå‰æÜÊ∏¨ÈáèÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞çÊèêÁ§∫ÁöÑÂõûÊáâÂ∑ÆÁï∞„ÄÇÈÄèÈÅéÊéßÂà∂ÊèêÁ§∫ÁöÑÁî¢ÁîüÔºå‰∏¶ÊîπËÆäÂΩ±ÈüøÊÉÖÂ¢ÉÁêÜËß£ÁöÑÁ§æÊúÉÂÅèË¶ãÔºå‰æÜÂºïÂÖ•Â∑ÆÁï∞ÔºåÈÄ≤ËÄåÂΩ±ÈüøÂêåÁêÜÁêÜËß£„ÄÇÂ∞çÁî¢ÁîüÁöÑÊéßÂà∂Á¢∫‰øùÊèêÁ§∫Ë≥áÊñôÈõÜ‰∏≠ÁµêÊßãÁöÑÈ´òÁêÜË´ñÊïàÂ∫¶„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰ΩøÈ´òÂìÅË≥™ÁöÑÁøªË≠ØËÆäÂæóÊõ¥ÂÆπÊòìÁÆ°ÁêÜÔºåÁâπÂà•ÊòØÂ∞çÊñºÁõÆÂâçÂπæ‰πéÊ≤íÊúâË©ï‰º∞ÂêåÁêÜÂøÉÊàñÂÅèË¶ãÁöÑÊñπÊ≥ïÁöÑË™ûË®ÄÔºå‰æãÂ¶ÇÊñØÊãâÂ§´Ë™ûÁ≥ª„ÄÇÊàëÂÄë‰ΩøÁî®ÊâÄÈÅ∏ÁöÑ LLM ÂíåÂêÑÁ®ÆÊèêÁ§∫È°ûÂûãÔºåÂ±ïÁ§∫‰∫Ü‰ΩøÁî®ÈÄôÂÄãÊû∂ÊßãÈÄ≤Ë°åÂêåÁêÜÂøÉË©ï‰º∞ÔºåÂåÖÊã¨Â§öÈÅ∏È°åÁ≠îÊ°àÂíåËá™Áî±ÁîüÊàê„ÄÇÊàëÂÄëÊúÄÂàùË©ï‰º∞Ê®£Êú¨‰∏≠ÁöÑÂ∑ÆÁï∞ÂæàÂ∞èÔºåÊàëÂÄëÁÑ°Ê≥ïÊ∏¨ÈáèÁî±‰∏çÂêåÁ§æÊúÉÁæ§È´îÁµ¶Âá∫ÁöÑÊÉÖÂ¢É‰∏≠ÁöÑÂêåÁêÜÁêÜËß£‰πãÈñì‰ª§‰∫∫‰ø°ÊúçÁöÑÂ∑ÆÁï∞„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊ®°ÂûãÈ°ØÁ§∫Âá∫ÂÆÉÂÄëÁöÑÊé®ÁêÜÈèàÈ°ØËëóÊîπËÆäÔºåÈúÄË¶ÅÊçïÊçâÊèêÁ§∫‰∏≠Áõ∏Â∞çÁ¥∞ÂæÆÁöÑËÆäÂåñÔºåÂõ†Ê≠§ÁµêÊûúÊòØÊúâÂ∏åÊúõÁöÑ„ÄÇÈÄôÁÇ∫Êú™‰æÜÁ†îÁ©∂Ë©ï‰º∞Ê®£Êú¨ÁöÑÂª∫ÊßãÂíåÊ∏¨ÈáèÁµêÊûúÁöÑÁµ±Ë®àÊñπÊ≥ïÊèê‰æõ‰∫ÜÂü∫Á§é„ÄÇ

##### **Fact or Fiction? Can LLMs be Reliable Annotators for Political Truths?**
2411.05775v1 by Veronica Chatrath, Marcelo Lotif, Shaina Raza

Political misinformation poses significant challenges to democratic
processes, shaping public opinion and trust in media. Manual fact-checking
methods face issues of scalability and annotator bias, while machine learning
models require large, costly labelled datasets. This study investigates the use
of state-of-the-art large language models (LLMs) as reliable annotators for
detecting political factuality in news articles. Using open-source LLMs, we
create a politically diverse dataset, labelled for bias through LLM-generated
annotations. These annotations are validated by human experts and further
evaluated by LLM-based judges to assess the accuracy and reliability of the
annotations. Our approach offers a scalable and robust alternative to
traditional fact-checking, enhancing transparency and public trust in media.

ÊëòË¶ÅÔºöÊîøÊ≤ªÈåØË™§Ë≥áË®äÂ∞çÊ∞ë‰∏ªÁ®ãÂ∫èÈÄ†ÊàêÈáçÂ§ßÊåëÊà∞ÔºåÂΩ¢Â°ëËºøË´ñÂíåÂ∞çÂ™íÈ´îÁöÑ‰ø°‰ªª„ÄÇÊâãÂãïÊü•Ê†∏‰∫ãÂØ¶ÁöÑÊñπÊ≥ïÈù¢Ëá®ÂèØÊì¥ÂÖÖÊÄßÂíåË®ªËß£ËÄÖÂÅèË¶ãÁöÑÂïèÈ°åÔºåËÄåÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÈúÄË¶ÅÈæêÂ§ß‰∏îÊòÇË≤¥ÁöÑÊ®ôÁ±§Ë≥áÊñôÈõÜ„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰ΩøÁî®ÊúÄÂÖàÈÄ≤ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ΩúÁÇ∫ÂèØÈù†ÁöÑË®ªËß£ËÄÖÔºå‰ª•ÂÅµÊ∏¨Êñ∞ËÅûÊñáÁ´†‰∏≠ÁöÑÊîøÊ≤ª‰∫ãÂØ¶„ÄÇ‰ΩøÁî®ÈñãÊ∫ê LLMÔºåÊàëÂÄëÂª∫Á´ã‰∏ÄÂÄãÊîøÊ≤ªÂ§öÂÖÉÁöÑË≥áÊñôÈõÜÔºåÈÄèÈÅé LLM ÁîüÊàêÁöÑË®ªËß£Ê®ôË®òÂÅèÂ∑Æ„ÄÇÈÄô‰∫õË®ªËß£Áî±‰∫∫È°ûÂ∞àÂÆ∂È©óË≠âÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Áî±Âü∫Êñº LLM ÁöÑË©ïÂØ©Ë©ï‰º∞Ôºå‰ª•Ë©ï‰º∞Ë®ªËß£ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ‰∏îÁ©©ÂÅ•ÁöÑÊõø‰ª£ÊñπÊ°àÔºåÁî®ÊñºÂÇ≥Áµ±ÁöÑ‰∫ãÂØ¶Êü•Ê†∏ÔºåÂ¢ûÂº∑ÈÄèÊòéÂ∫¶ÂíåÂÖ¨ÁúæÂ∞çÂ™íÈ´îÁöÑ‰ø°‰ªª„ÄÇ

##### **FinDVer: Explainable Claim Verification over Long and Hybrid-Content Financial Documents**
2411.05764v1 by Yilun Zhao, Yitao Long, Yuru Jiang, Chengye Wang, Weiyuan Chen, Hongjun Liu, Yiming Zhang, Xiangru Tang, Chen Zhao, Arman Cohan

We introduce FinDVer, a comprehensive benchmark specifically designed to
evaluate the explainable claim verification capabilities of LLMs in the context
of understanding and analyzing long, hybrid-content financial documents.
FinDVer contains 2,400 expert-annotated examples, divided into three subsets:
information extraction, numerical reasoning, and knowledge-intensive reasoning,
each addressing common scenarios encountered in real-world financial contexts.
We assess a broad spectrum of LLMs under long-context and RAG settings. Our
results show that even the current best-performing system, GPT-4o, still lags
behind human experts. We further provide in-depth analysis on long-context and
RAG setting, Chain-of-Thought reasoning, and model reasoning errors, offering
insights to drive future advancements. We believe that FinDVer can serve as a
valuable benchmark for evaluating LLMs in claim verification over complex,
expert-domain documents.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•‰∫Ü FinDVerÔºå‰∏ÄÂÄãÂ∞àÈñÄË®≠Ë®àÁöÑÁ∂úÂêàÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ LLM Âú®ÁêÜËß£ÂíåÂàÜÊûêÈï∑ÁØáÊ∑∑ÂêàÂÖßÂÆπË≤°ÂãôÊñá‰ª∂ÊñπÈù¢ÁöÑÂèØËß£ÈáãËÅ≤ÊòéÈ©óË≠âËÉΩÂäõ„ÄÇ
FinDVer ÂåÖÂê´ 2,400 ÂÄãÂ∞àÂÆ∂Ë®ªÈáãÁØÑ‰æãÔºåÂàÜÁÇ∫‰∏âÂÄãÂ≠êÈõÜÔºöË≥áË®äËêÉÂèñ„ÄÅÊï∏ÂÄºÊé®ÁêÜÂíåÁü•Ë≠òÂØÜÈõÜÊé®ÁêÜÔºåÊØèÂÄãÂ≠êÈõÜÈÉΩÈáùÂ∞çÂú®ÁèæÂØ¶‰∏ñÁïåË≤°ÂãôÁí∞Â¢É‰∏≠ÈÅáÂà∞ÁöÑÂ∏∏Ë¶ãÊÉÖÂ¢É„ÄÇ
ÊàëÂÄëÂú®Èï∑Ë™ûÂ¢ÉÂíå RAG Ë®≠ÂÆö‰∏ãË©ï‰º∞‰∫ÜÂª£Ê≥õÁöÑ LLM„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÂç≥‰ΩøÊòØÁõÆÂâçÊïàËÉΩÊúÄ‰Ω≥ÁöÑÁ≥ªÁµ± GPT-4oÔºå‰ªçÁÑ∂ËêΩÂæåÊñº‰∫∫È°ûÂ∞àÂÆ∂„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êèê‰æõÈï∑Ë™ûÂ¢ÉÂíå RAG Ë®≠ÂÆö„ÄÅÊÄùËÄÉÈèàÊé®ÁêÜÂíåÊ®°ÂûãÊé®ÁêÜÈåØË™§ÁöÑÊ∑±ÂÖ•ÂàÜÊûêÔºåÊèê‰æõË¶ãËß£‰ª•Êé®ÂãïÊú™‰æÜÁöÑÈÄ≤Â±ï„ÄÇÊàëÂÄëÁõ∏‰ø° FinDVer ÂèØ‰ª•‰ΩúÁÇ∫‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ LLM Âú®Ë§áÈõúÁöÑÂ∞àÂÆ∂È†òÂüüÊñá‰ª∂‰∏≠ÁöÑËÅ≤ÊòéÈ©óË≠âËÉΩÂäõ„ÄÇ

##### **Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024**
2411.05762v1 by Christopher Malon

Separating disinformation from fact on the web has long challenged both the
search and the reasoning powers of humans. We show that the reasoning power of
large language models (LLMs) and the retrieval power of modern search engines
can be combined to automate this process and explainably verify claims. We
integrate LLMs and search under a multi-hop evidence pursuit strategy. This
strategy generates an initial question based on an input claim using a sequence
to sequence model, searches and formulates an answer to the question, and
iteratively generates follow-up questions to pursue the evidence that is
missing using an LLM. We demonstrate our system on the FEVER 2024 (AVeriTeC)
shared task. Compared to a strategy of generating all the questions at once,
our method obtains .045 higher label accuracy and .155 higher AVeriTeC score
(evaluating the adequacy of the evidence). Through ablations, we show the
importance of various design choices, such as the question generation method,
medium-sized context, reasoning with one document at a time, adding metadata,
paraphrasing, reducing the problem to two classes, and reconsidering the final
verdict. Our submitted system achieves .510 AVeriTeC score on the dev set and
.477 AVeriTeC score on the test set.

ÊëòË¶ÅÔºö<paragraph>Âú®Á∂≤Ë∑Ø‰∏äÂçÄÂàÜÈåØË™§Ë≥áË®äÂíå‰∫ãÂØ¶ÔºåÈï∑Êúü‰ª•‰æÜ‰∏ÄÁõ¥ÊòØ‰∫∫È°ûÂú®ÊêúÂ∞ãÂíåÊé®ÁêÜËÉΩÂäõ‰∏äÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÂ±ïÁ§∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊé®ÁêÜËÉΩÂäõÂíåÁèæ‰ª£ÊêúÂ∞ãÂºïÊìéÁöÑÊ™¢Á¥¢ËÉΩÂäõÂèØ‰ª•ÁµêÂêàËµ∑‰æÜÔºåËá™ÂãïÂåñÈÄôÂÄãÊµÅÁ®ã‰∏¶‰ª•ÂèØËß£ÈáãÁöÑÊñπÂºèÈ©óË≠âÂÆ£Á®±„ÄÇÊàëÂÄëÂú®Â§öÈáçË∑≥Ë∫çË≠âÊìöËøΩËπ§Á≠ñÁï•‰∏ãÊï¥Âêà LLM ÂíåÊêúÂ∞ã„ÄÇÈÄôÂÄãÁ≠ñÁï•ÊúÉ‰ΩøÁî®Â∫èÂàóÂà∞Â∫èÂàóÊ®°ÂûãÊ†πÊìöËº∏ÂÖ•ÂÆ£Á®±Áî¢Áîü‰∏ÄÂÄãÂàùÂßãÂïèÈ°åÔºåÊêúÂ∞ã‰∏¶ÈáùÂ∞çÂïèÈ°åÂà∂ÂÆö‰∏ÄÂÄãÁ≠îÊ°àÔºå‰∏¶ÂèçË¶ÜÁî¢ÁîüÂæåÁ∫åÂïèÈ°åÔºå‰ΩøÁî® LLM ËøΩËπ§ÈÅ∫Â§±ÁöÑË≠âÊìö„ÄÇÊàëÂÄëÂú® FEVER 2024 (AVeriTeC) ÂÖ±‰∫´‰ªªÂãô‰∏≠Â±ïÁ§∫ÊàëÂÄëÁöÑÁ≥ªÁµ±„ÄÇËàá‰∏ÄÊ¨°Áî¢ÁîüÊâÄÊúâÂïèÈ°åÁöÑÁ≠ñÁï•Áõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁç≤Âæó‰∫ÜÈ´òÂá∫ 0.045 ÁöÑÊ®ôÁ±§Ê∫ñÁ¢∫Â∫¶ÂíåÈ´òÂá∫ 0.155 ÁöÑ AVeriTeC ÂàÜÊï∏ÔºàË©ï‰º∞Ë≠âÊìöÁöÑÂÖÖÂàÜÊÄßÔºâ„ÄÇÈÄèÈÅéÊ∂àËûçÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂêÑÁ®ÆË®≠Ë®àÈÅ∏ÊìáÁöÑÈáçË¶ÅÊÄßÔºå‰æãÂ¶ÇÂïèÈ°åÁî¢ÁîüÊñπÊ≥ï„ÄÅ‰∏≠Á≠âÂ§ßÂ∞èÁöÑÂÖßÂÆπ„ÄÅ‰∏ÄÊ¨°‰ΩøÁî®‰∏ÄÂÄãÊñá‰ª∂Êé®ÁêÜ„ÄÅÂä†ÂÖ•ÂÖÉË≥áÊñô„ÄÅÂêåÁæ©ÊîπÂØ´„ÄÅÂ∞áÂïèÈ°åÁ∞°ÂåñÁÇ∫ÂÖ©ÂÄãÈ°ûÂà•Ôºå‰ª•ÂèäÈáçÊñ∞ËÄÉÊÖÆÊúÄÁµÇË£ÅÊ±∫„ÄÇÊàëÂÄëÊèê‰∫§ÁöÑÁ≥ªÁµ±Âú®ÈñãÁôºÁµÑ‰∏äÁç≤Âæó 0.510 ÁöÑ AVeriTeC ÂàÜÊï∏ÔºåÂú®Ê∏¨Ë©¶ÁµÑ‰∏äÁç≤Âæó 0.477 ÁöÑ AVeriTeC ÂàÜÊï∏„ÄÇ</paragraph>

##### **End-to-End Navigation with Vision Language Models: Transforming Spatial Reasoning into Question-Answering**
2411.05755v1 by Dylan Goetting, Himanshu Gaurav Singh, Antonio Loquercio

We present VLMnav, an embodied framework to transform a Vision-Language Model
(VLM) into an end-to-end navigation policy. In contrast to prior work, we do
not rely on a separation between perception, planning, and control; instead, we
use a VLM to directly select actions in one step. Surprisingly, we find that a
VLM can be used as an end-to-end policy zero-shot, i.e., without any
fine-tuning or exposure to navigation data. This makes our approach open-ended
and generalizable to any downstream navigation task. We run an extensive study
to evaluate the performance of our approach in comparison to baseline prompting
methods. In addition, we perform a design analysis to understand the most
impactful design decisions. Visual examples and code for our project can be
found at https://jirl-upenn.github.io/VLMnav/

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ VLMnavÔºå‰∏ÄÂÄãÂÖ∑Ë±°Ê°ÜÊû∂ÔºåÁî®ÊñºÂ∞áË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ËΩâÊèõÁÇ∫Á´ØÂ∞çÁ´ØÂ∞éËà™Á≠ñÁï•„ÄÇËàáÂÖàÂâçÁöÑÁ†îÁ©∂‰∏çÂêåÔºåÊàëÂÄë‰∏ç‰æùË≥¥ÊñºÊÑüÁü•„ÄÅË¶èÂäÉÂíåÊéßÂà∂‰πãÈñìÁöÑÂçÄÂàÜÔºõÁõ∏ÂèçÔºåÊàëÂÄë‰ΩøÁî® VLM Âú®‰∏ÄÂÄãÊ≠•È©ü‰∏≠Áõ¥Êé•ÈÅ∏ÊìáÂãï‰Ωú„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæ VLM ÂèØÁî®‰ΩúÁ´ØÂ∞çÁ´ØÁ≠ñÁï•Èõ∂Ê¨°Â≠∏ÁøíÔºåÂç≥ÁÑ°ÈúÄ‰ªª‰ΩïÂæÆË™øÊàñÊé•Ëß∏Â∞éËà™Êï∏Êìö„ÄÇÈÄô‰ΩøÂæóÊàëÂÄëÁöÑÂÅöÊ≥ïÂÖ∑ÊúâÈñãÊîæÊÄßÔºå‰∏¶‰∏îÂèØ‰ª•Êé®Âª£Âà∞‰ªª‰Ωï‰∏ãÊ∏∏Â∞éËà™‰ªªÂãô„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂª£Ê≥õÁöÑÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ÊàëÂÄëÁöÑÊñπÊ≥ïËàáÂü∫Á∑öÊèêÁ§∫ÊñπÊ≥ïÁõ∏ÊØîÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂü∑Ë°åË®≠Ë®àÂàÜÊûê‰ª•‰∫ÜËß£ÂΩ±ÈüøÊúÄÂ§ßÁöÑË®≠Ë®àÊ±∫Á≠ñ„ÄÇÂèØ‰ª•Âú® https://jirl-upenn.github.io/VLMnav/ ÊâæÂà∞ÊàëÂÄëÈ†ÖÁõÆÁöÑË¶ñË¶∫ÁØÑ‰æãÂíå‰ª£Á¢º„ÄÇ

##### **FisherMask: Enhancing Neural Network Labeling Efficiency in Image Classification Using Fisher Information**
2411.05752v1 by Shreen Gul, Mohamed Elmahallawy, Sanjay Madria, Ardhendu Tripathy

Deep learning (DL) models are popular across various domains due to their
remarkable performance and efficiency. However, their effectiveness relies
heavily on large amounts of labeled data, which are often time-consuming and
labor-intensive to generate manually. To overcome this challenge, it is
essential to develop strategies that reduce reliance on extensive labeled data
while preserving model performance. In this paper, we propose FisherMask, a
Fisher information-based active learning (AL) approach that identifies key
network parameters by masking them based on their Fisher information values.
FisherMask enhances batch AL by using Fisher information to select the most
critical parameters, allowing the identification of the most impactful samples
during AL training. Moreover, Fisher information possesses favorable
statistical properties, offering valuable insights into model behavior and
providing a better understanding of the performance characteristics within the
AL pipeline. Our extensive experiments demonstrate that FisherMask
significantly outperforms state-of-the-art methods on diverse datasets,
including CIFAR-10 and FashionMNIST, especially under imbalanced settings.
These improvements lead to substantial gains in labeling efficiency. Hence
serving as an effective tool to measure the sensitivity of model parameters to
data samples. Our code is available on
\url{https://github.com/sgchr273/FisherMask}.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Ê®°ÂûãÂõ†ÂÖ∂ÂçìË∂äÁöÑÊïàËÉΩÂíåÊïàÁéáËÄåÂª£ÂèóÂêÑÈ†òÂüüÊ≠°Ëøé„ÄÇÁÑ∂ËÄåÔºåÂÖ∂ÊúâÊïàÊÄßÊ•µÂ∫¶‰ª∞Ë≥¥Â§ßÈáèÊ®ôÁ±§Ë≥áÊñôÔºåËÄå‰∫∫Â∑•Áî¢ÁîüÈÄô‰∫õË≥áÊñôÈÄöÂ∏∏ËÄóÊôÇ‰∏îË≤ªÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÊåëÊà∞ÔºåÈñãÁôºÂá∫ËÉΩÈôç‰ΩéÂ∞çÂ§ßÈáèÊ®ôÁ±§Ë≥áÊñôÁöÑ‰æùË≥¥ÔºåÂêåÊôÇÁ∂≠ÊåÅÊ®°ÂûãÊïàËÉΩÁöÑÁ≠ñÁï•Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ FisherMaskÔºå‰∏ÄÁ®ÆÂü∫Êñº Fisher Ë≥áË®äÁöÑ‰∏ªÂãïÂ≠∏Áøí (AL) ÊñπÊ≥ïÔºåÈÄèÈÅéÈÅÆËîΩÁ∂≤Ë∑ØÂèÉÊï∏‰∏¶Ê†πÊìöÂÖ∂ Fisher Ë≥áË®äÂÄº‰æÜË≠òÂà•ÈóúÈçµÁ∂≤Ë∑ØÂèÉÊï∏„ÄÇFisherMask ÈÄèÈÅé‰ΩøÁî® Fisher Ë≥áË®ä‰æÜÈÅ∏ÊìáÊúÄÈóúÈçµÁöÑÂèÉÊï∏ÔºåÂ¢ûÂº∑ÊâπÊ¨° ALÔºåÂú® AL Ë®ìÁ∑¥ÊúüÈñìË≠òÂà•ÂΩ±ÈüøÊúÄÂ§ßÁöÑÊ®£Êú¨„ÄÇÊ≠§Â§ñÔºåFisher Ë≥áË®äÂÖ∑ÊúâËâØÂ•ΩÁöÑÁµ±Ë®àÁâπÊÄßÔºåÊèê‰æõÂ∞çÊ®°ÂûãË°åÁÇ∫ÁöÑÂØ∂Ë≤¥Ë¶ãËß£Ôºå‰∏¶Êèê‰æõÂ∞ç AL ÁÆ°Á∑ö‰∏≠ÊïàËÉΩÁâπÊÄßÁöÑÊõ¥Ê∑±ÂÖ•‰∫ÜËß£„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåFisherMask Âú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äÊòéÈ°ØÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÂåÖÊã¨ CIFAR-10 Âíå FashionMNISTÔºåÁâπÂà•ÊòØÂú®‰∏çÂπ≥Ë°°ÁöÑË®≠ÂÆö‰∏ã„ÄÇÈÄô‰∫õÊîπÈÄ≤Â∞éËá¥Ê®ôÁ±§ÊïàÁéáÂ§ßÂπÖÊèêÂçá„ÄÇÂõ†Ê≠§Ôºå‰ΩúÁÇ∫Ë°°ÈáèÊ®°ÂûãÂèÉÊï∏Â∞çË≥áÊñôÊ®£Êú¨ÊïèÊÑüÊÄßÁöÑÊúâÊïàÂ∑•ÂÖ∑„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® \url{https://github.com/sgchr273/FisherMask} ÂèñÂæó„ÄÇ

##### **Topology-aware Reinforcement Feature Space Reconstruction for Graph Data**
2411.05742v1 by Wangyang Ying, Haoyue Bai, Kunpeng Liu, Yanjie Fu

Feature space is an environment where data points are vectorized to represent
the original dataset. Reconstructing a good feature space is essential to
augment the AI power of data, improve model generalization, and increase the
availability of downstream ML models. Existing literature, such as feature
transformation and feature selection, is labor-intensive (e.g., heavy reliance
on empirical experience) and mostly designed for tabular data. Moreover, these
methods regard data samples as independent, which ignores the unique
topological structure when applied to graph data, thus resulting in a
suboptimal reconstruction feature space. Can we consider the topological
information to automatically reconstruct feature space for graph data without
heavy experiential knowledge? To fill this gap, we leverage topology-aware
reinforcement learning to automate and optimize feature space reconstruction
for graph data. Our approach combines the extraction of core subgraphs to
capture essential structural information with a graph neural network (GNN) to
encode topological features and reduce computing complexity. Then we introduce
three reinforcement agents within a hierarchical structure to systematically
generate meaningful features through an iterative process, effectively
reconstructing the feature space. This framework provides a principled solution
for attributed graph feature space reconstruction. The extensive experiments
demonstrate the effectiveness and efficiency of including topological
awareness.

ÊëòË¶ÅÔºöÁâπÂæµÁ©∫ÈñìÊòØ‰∏ÄÂÄãÁí∞Â¢ÉÔºåÂÖ∂‰∏≠Ë≥áÊñôÈªûË¢´ÂêëÈáèÂåñ‰ª•Ë°®Á§∫ÂéüÂßãË≥áÊñôÈõÜ„ÄÇÈáçÂª∫‰∏ÄÂÄãËâØÂ•ΩÁöÑÁâπÂæµÁ©∫ÈñìÂ∞çÊñºÂ¢ûÂº∑Ë≥áÊñôÁöÑ AI ËÉΩÂäõ„ÄÅÊîπÂñÑÊ®°ÂûãÊ≥õÂåñÔºå‰ª•ÂèäÂ¢ûÂä†‰∏ãÊ∏∏ ML Ê®°ÂûãÁöÑÂèØÁî®ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÁèæÊúâÁöÑÊñáÁçªÔºå‰æãÂ¶ÇÁâπÂæµËΩâÊèõÂíåÁâπÂæµÈÅ∏ÊìáÔºåÊòØÂãûÂäõÂØÜÈõÜÁöÑÔºà‰æãÂ¶ÇÔºåÂö¥Èáç‰æùË≥¥ÊñºÁ∂ìÈ©óÁ∂ìÈ©óÔºâÔºå‰∏¶‰∏î‰∏ªË¶ÅË®≠Ë®àÁî®ÊñºË°®Ê†ºË≥áÊñô„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊñπÊ≥ïÂ∞áË≥áÊñôÊ®£Êú¨Ë¶ñÁÇ∫Áç®Á´ãÁöÑÔºåÈÄôÂú®ÊáâÁî®ÊñºÂúñÂΩ¢Ë≥áÊñôÊôÇÊúÉÂøΩÁï•Áç®ÁâπÁöÑÊãìÊí≤ÁµêÊßãÔºåÂæûËÄåÂ∞éËá¥Ê¨°‰Ω≥ÁöÑÈáçÂª∫ÁâπÂæµÁ©∫Èñì„ÄÇÊàëÂÄëËÉΩËÄÉÊÖÆÊãìÊí≤Ë≥áË®äÔºåÂú®Ê≤íÊúâÂ§ßÈáèÁ∂ìÈ©óÁü•Ë≠òÁöÑÊÉÖÊ≥Å‰∏ãÔºåËá™ÂãïÁÇ∫ÂúñÂΩ¢Ë≥áÊñôÈáçÂª∫ÁâπÂæµÁ©∫ÈñìÂóéÔºüÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩÔºåÊàëÂÄëÂà©Áî®ÂÖ∑ÊúâÊãìÊí≤ÊÑüÁü•ÁöÑÂº∑ÂåñÂ≠∏ÁøíÔºå‰ª•Ëá™ÂãïÂåñÂíåÊúÄ‰Ω≥ÂåñÂúñÂΩ¢Ë≥áÊñôÁöÑÁâπÂæµÁ©∫ÈñìÈáçÂª∫„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÁµêÂêà‰∫ÜÊ†∏ÂøÉÂ≠êÂúñÁöÑËêÉÂèñÔºå‰ª•Êì∑ÂèñÊú¨Ë≥™ÁöÑÁµêÊßãË≥áË®äÔºå‰ª•ÂèäÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN)Ôºå‰ª•Á∑®Á¢ºÊãìÊí≤ÁâπÂæµ‰∏¶Èôç‰ΩéÈÅãÁÆóË§áÈõúÂ∫¶„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÈöéÂ±§ÁµêÊßã‰∏≠ÂºïÂÖ•‰∏âÂÄãÂº∑Âåñ‰ª£ÁêÜÔºå‰ª•ÈÄèÈÅéÂèçË¶ÜÈÅãÁÆóÁöÑÁ®ãÂ∫èÁ≥ªÁµ±ÊÄßÂú∞Áî¢ÁîüÊúâÊÑèÁæ©ÁöÑÁâπÂæµÔºåÊúâÊïàÂú∞ÈáçÂª∫ÁâπÂæµÁ©∫Èñì„ÄÇÈÄôÂÄãÊû∂ÊßãÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁî®ÊñºÂ±¨ÊÄßÂúñÂΩ¢ÁâπÂæµÁ©∫ÈñìÈáçÂª∫ÁöÑÂéüÂâáÊÄßËß£Ê±∫ÊñπÊ°à„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÁ¥çÂÖ•ÊãìÊí≤ÊÑüÁü•ÁöÑÊúâÊïàÊÄßÂíåÊïàÁéá„ÄÇ

##### **Aioli: A Unified Optimization Framework for Language Model Data Mixing**
2411.05735v1 by Mayee F. Chen, Michael Y. Hu, Nicholas Lourie, Kyunghyun Cho, Christopher R√©

Language model performance depends on identifying the optimal mixture of data
groups to train on (e.g., law, code, math). Prior work has proposed a diverse
set of methods to efficiently learn mixture proportions, ranging from fitting
regression models over training runs to dynamically updating proportions
throughout training. Surprisingly, we find that no existing method consistently
outperforms a simple stratified sampling baseline in terms of average test
perplexity per group. In this paper, we study the cause of this inconsistency
by unifying existing methods into a standard optimization framework. We show
that all methods set proportions to minimize total loss, subject to a
method-specific mixing law -- an assumption on how loss is a function of
mixture proportions. We find that existing parameterizations of mixing laws can
express the true loss-proportion relationship empirically, but the methods
themselves often set the mixing law parameters inaccurately, resulting in poor
and inconsistent performance. Finally, we leverage the insights from our
framework to derive a new online method named Aioli, which directly estimates
the mixing law parameters throughout training and uses them to dynamically
adjust proportions. Empirically, Aioli outperforms stratified sampling on 6 out
of 6 datasets by an average of 0.28 test perplexity points, whereas existing
methods fail to consistently beat stratified sampling, doing up to 6.9 points
worse. Moreover, in a practical setting where proportions are learned on
shorter runs due to computational constraints, Aioli can dynamically adjust
these proportions over the full training run, consistently improving
performance over existing methods by up to 12.01 test perplexity points.

ÊëòË¶ÅÔºö<paragraph>Ë™ûË®ÄÊ®°ÂûãÁöÑÊïàËÉΩÂèñÊ±∫ÊñºËæ®Ë≠òÁî®ÊñºË®ìÁ∑¥ÁöÑÊúÄ‰Ω≥Ë≥áÊñôÁæ§ÁµÑÁµÑÂêàÔºà‰æãÂ¶ÇÊ≥ïÂæã„ÄÅÁ®ãÂºèÁ¢º„ÄÅÊï∏Â≠∏Ôºâ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤ÊèêÂá∫ÂêÑÁ®ÆÊñπÊ≥ï‰æÜÊúâÊïàÂ≠∏ÁøíÊ∑∑ÂêàÊØî‰æãÔºåÂæûÊì¨ÂêàË®ìÁ∑¥Âü∑Ë°åÈöéÊÆµÁöÑÂõûÊ≠∏Ê®°ÂûãÂà∞ÂãïÊÖãÊõ¥Êñ∞Ë®ìÁ∑¥ÊúüÈñìÁöÑÊØî‰æã„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæÊ≤íÊúâÁèæÊúâÊñπÊ≥ïÂú®Âπ≥ÂùáÊØèÁµÑÊ∏¨Ë©¶Âõ∞ÊÉëÂ∫¶ÊñπÈù¢ÂßãÁµÇÂÑ™ÊñºÁ∞°ÂñÆÁöÑÂàÜÂ±§ÊäΩÊ®£Âü∫Ê∫ñÁ∑ö„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂ∞áÁèæÊúâÊñπÊ≥ïÁµ±‰∏ÄÂà∞‰∏ÄÂÄãÊ®ôÊ∫ñÁöÑÊúÄ‰Ω≥ÂåñÊû∂Êßã‰∏≠‰æÜÁ†îÁ©∂ÈÄôÁ®Æ‰∏ç‰∏ÄËá¥ÊÄßÁöÑÂéüÂõ†„ÄÇÊàëÂÄëË™™ÊòéÊâÄÊúâÊñπÊ≥ïÈÉΩÊúÉË®≠ÂÆöÊØî‰æã‰ª•ÊúÄÂ∞èÂåñÁ∏ΩÊêçÂ§±Ôºå‰ΩÜÈúÄÈÅµÂÆàÁâπÂÆöÊñºÊñπÊ≥ïÁöÑÊ∑∑ÂêàÂÆöÂæãÔºå‰πüÂ∞±ÊòØÊêçÂ§±Â¶Ç‰ΩïÊàêÁÇ∫Ê∑∑ÂêàÊØî‰æãÁöÑÂáΩÊï∏ÁöÑÂÅáË®≠„ÄÇÊàëÂÄëÁôºÁèæÁèæÊúâÊ∑∑ÂêàÂÆöÂæãÁöÑÂèÉÊï∏ÂåñÂèØ‰ª•Ê†πÊìöÁ∂ìÈ©óË°®ÈÅîÁúüÊ≠£ÁöÑÊêçÂ§±ÊØî‰æãÈóú‰øÇÔºå‰ΩÜÈÄô‰∫õÊñπÊ≥ïÊú¨Ë∫´ÈÄöÂ∏∏ÊúÉ‰∏çÊ∫ñÁ¢∫Âú∞Ë®≠ÂÆöÊ∑∑ÂêàÂÆöÂæãÂèÉÊï∏ÔºåÂ∞éËá¥ÊïàËÉΩ‰∏ç‰Ω≥‰∏î‰∏ç‰∏ÄËá¥„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂà©Áî®ÊàëÂÄëÊû∂Êßã‰∏≠ÁöÑË¶ãËß£ÔºåÊé®Â∞éÂá∫‰∏ÄÁ®ÆÂêçÁÇ∫ Aioli ÁöÑÊñ∞ÁöÑÁ∑ö‰∏äÊñπÊ≥ïÔºåÂÆÉÊúÉÁõ¥Êé•‰º∞Ë®àË®ìÁ∑¥ÊúüÈñìÁöÑÊ∑∑ÂêàÂÆöÂæãÂèÉÊï∏Ôºå‰∏¶‰ΩøÁî®ÈÄô‰∫õÂèÉÊï∏ÂãïÊÖãË™øÊï¥ÊØî‰æã„ÄÇÊ†πÊìöÁ∂ìÈ©óÔºåAioli Âú® 6 ÂÄãË≥áÊñôÈõÜ‰∏≠Êúâ 6 ÂÄãÁöÑË°®ÁèæÂÑ™ÊñºÂàÜÂ±§ÊäΩÊ®£ÔºåÂπ≥ÂùáÊ∏¨Ë©¶Âõ∞ÊÉëÂ∫¶ÈªûÊï∏ÁÇ∫ 0.28ÔºåËÄåÁèæÊúâÊñπÊ≥ïÁÑ°Ê≥ïÂßãÁµÇÂÑ™ÊñºÂàÜÂ±§ÊäΩÊ®£ÔºåË°®ÁèæÊúÄÂ§öÂ∑Æ 6.9 Èªû„ÄÇÊ≠§Â§ñÔºåÂú®Áî±ÊñºË®àÁÆóÈôêÂà∂ËÄåÂøÖÈ†àÂú®ËºÉÁü≠ÁöÑÂü∑Ë°åÈöéÊÆµÂ≠∏ÁøíÊØî‰æãÁöÑÂØ¶ÈöõË®≠ÂÆö‰∏≠ÔºåAioli ÂèØ‰ª•ÂãïÊÖãË™øÊï¥ÈÄô‰∫õÊØî‰æãÔºåÂú®Êï¥ÂÄãË®ìÁ∑¥Âü∑Ë°åÈöéÊÆµÂßãÁµÇÊîπÂñÑÊïàËÉΩÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊúÄÂ§öÂèØÊîπÂñÑ 12.01 ÂÄãÊ∏¨Ë©¶Âõ∞ÊÉëÂ∫¶ÈªûÊï∏„ÄÇ</paragraph>

##### **Image2Text2Image: A Novel Framework for Label-Free Evaluation of Image-to-Text Generation with Text-to-Image Diffusion Models**
2411.05706v1 by Jia-Hong Huang, Hongyi Zhu, Yixian Shen, Stevan Rudinac, Evangelos Kanoulas

Evaluating the quality of automatically generated image descriptions is a
complex task that requires metrics capturing various dimensions, such as
grammaticality, coverage, accuracy, and truthfulness. Although human evaluation
provides valuable insights, its cost and time-consuming nature pose
limitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr
attempt to fill this gap, but they often exhibit weak correlations with human
judgment. To address this challenge, we propose a novel evaluation framework
called Image2Text2Image, which leverages diffusion models, such as Stable
Diffusion or DALL-E, for text-to-image generation. In the Image2Text2Image
framework, an input image is first processed by a selected image captioning
model, chosen for evaluation, to generate a textual description. Using this
generated description, a diffusion model then creates a new image. By comparing
features extracted from the original and generated images, we measure their
similarity using a designated similarity metric. A high similarity score
suggests that the model has produced a faithful textual description, while a
low score highlights discrepancies, revealing potential weaknesses in the
model's performance. Notably, our framework does not rely on human-annotated
reference captions, making it a valuable tool for assessing image captioning
models. Extensive experiments and human evaluations validate the efficacy of
our proposed Image2Text2Image evaluation framework. The code and dataset will
be published to support further research in the community.

ÊëòË¶ÅÔºöË©ï‰º∞Ëá™ÂãïÁî¢ÁîüÂúñÁâáÊèèËø∞ÁöÑÂìÅË≥™ÊòØ‰∏ÄÈ†ÖË§áÈõúÁöÑ‰ªªÂãôÔºåÈúÄË¶ÅÊåáÊ®ô‰æÜÊçïÊçâÂêÑÁ®ÆÈù¢ÂêëÔºå‰æãÂ¶ÇË™ûÊ≥ï„ÄÅÊ∂µËìãÁØÑÂúç„ÄÅÊ∫ñÁ¢∫Â∫¶ÂíåÁúüÂØ¶ÊÄß„ÄÇÂÑòÁÆ°‰∫∫Â∑•Ë©ï‰º∞Êèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£Ôºå‰ΩÜÂÖ∂ÊàêÊú¨ÂíåËÄóÊôÇÊÄßË≥™ÊúÉÈÄ†ÊàêÈôêÂà∂„ÄÇÁèæÊúâÁöÑËá™ÂãïÂåñÊåáÊ®ôÔºå‰æãÂ¶Ç BLEU„ÄÅROUGE„ÄÅMETEOR Âíå CIDErÔºåË©¶ÂúñÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏Ëàá‰∫∫Â∑•Âà§Êñ∑Áõ∏ÈóúÊÄßËºÉÂº±„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÈ†ÖÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ Image2Text2Image ÁöÑÊñ∞Ë©ï‰º∞Ê°ÜÊû∂ÔºåÂÆÉÂà©Áî®Êì¥Êï£Ê®°ÂûãÔºà‰æãÂ¶Ç Stable Diffusion Êàñ DALL-EÔºâÈÄ≤Ë°åÊñáÂ≠óÂà∞ÂúñÁâáÁöÑÁî¢Áîü„ÄÇÂú® Image2Text2Image Ê°ÜÊû∂‰∏≠ÔºåËº∏ÂÖ•ÂúñÁâáÈ¶ñÂÖàÁî±ÈÅ∏ÂÆöÁöÑÂúñÁâáÊ®ôË®ªÊ®°ÂûãÔºàÈÅ∏ÊìáÁî®ÊñºË©ï‰º∞ÔºâËôïÁêÜÔºå‰ª•Áî¢ÁîüÊñáÂ≠óÊèèËø∞„ÄÇ‰ΩøÁî®ÈÄôÂÄãÁî¢ÁîüÁöÑÊèèËø∞ÔºåÊì¥Êï£Ê®°ÂûãÊé•ËëóÊúÉÁî¢Áîü‰∏ÄÂÄãÊñ∞ÂúñÁâá„ÄÇÈÄèÈÅéÊØîËºÉÂæûÂéüÂßãÂúñÁâáÂíåÁî¢ÁîüÂúñÁâá‰∏≠ËêÉÂèñÂá∫ÁöÑÁâπÂæµÔºåÊàëÂÄë‰ΩøÁî®ÊåáÂÆöÁöÑÁõ∏‰ººÊÄßÊåáÊ®ô‰æÜÊ∏¨ÈáèÂÆÉÂÄëÁöÑÁõ∏‰ººÊÄß„ÄÇÈ´òÁõ∏‰ººÂ∫¶ÂàÜÊï∏Ë°®Á§∫Ê®°ÂûãÁî¢Áîü‰∫ÜÂø†ÂØ¶ÁöÑÊñáÂ≠óÊèèËø∞ÔºåËÄå‰ΩéÂàÜÊï∏ÂâáÁ™ÅÈ°ØÂá∫Â∑ÆÁï∞ÔºåÊè≠Á§∫Ê®°ÂûãÊïàËÉΩÁöÑÊΩõÂú®Âº±Èªû„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂‰∏ç‰æùË≥¥‰∫∫Â∑•Ê®ôË®ªÁöÑÂèÉËÄÉÊ®ôÈ°åÔºåÈÄô‰ΩøÂÖ∂ÊàêÁÇ∫Ë©ï‰º∞ÂúñÁâáÊ®ôË®ªÊ®°ÂûãÁöÑÂØ∂Ë≤¥Â∑•ÂÖ∑„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÂíå‰∫∫Â∑•Ë©ï‰º∞È©óË≠â‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑ Image2Text2Image Ë©ï‰º∞Ê°ÜÊû∂ÁöÑÊúâÊïàÊÄß„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂ∞áÊúÉÁôºÂ∏ÉÔºå‰ª•ÊîØÊåÅÁ§æÁæ§‰∏≠ÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

##### **Asterisk*: Keep it Simple**
2411.05691v1 by Andrew Semenov

This paper describes Asterisk, a compact GPT-based model for generating text
embeddings. The model uses a minimalist architecture with two layers, two
attention heads, and 256 embedding dimensions. By applying knowledge
distillation from larger pretrained models, we explore the trade-offs between
model size and performance while minimizing computational and memory
requirements. The model is primarily evaluated and optimized for classification
tasks, with experimental results showing its moderate performance in zero-shot
classification across various downstream applications. With additional
configuration, the model performance can approach or even surpass that of
larger architectures on specific classification tasks.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèèËø∞‰∫Ü AsteriskÔºåËøôÊòØ‰∏Ä‰∏™Âü∫‰∫é GPT ÁöÑÁ¥ßÂáëÊ®°ÂûãÔºåÁî®‰∫éÁîüÊàêÊñáÊú¨ÂµåÂÖ•„ÄÇËØ•Ê®°Âûã‰ΩøÁî®ÂÖ∑Êúâ‰∏§Â±Ç„ÄÅ‰∏§‰∏™Ê≥®ÊÑèÂäõÂ§¥Âíå 256 ‰∏™ÂµåÂÖ•Áª¥Â∫¶ÁöÑÊûÅÁÆÄÊû∂ÊûÑ„ÄÇÈÄöËøáÂ∫îÁî®‰ªéÊõ¥Â§ßÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°Âûã‰∏≠ÊèêÂèñÁöÑÁü•ËØÜÔºåÊàë‰ª¨Âú®Ê®°ÂûãÂ§ßÂ∞èÂíåÊÄßËÉΩ‰πãÈó¥Êé¢Á¥¢ÊùÉË°°ÔºåÂêåÊó∂ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞ÂáèÂ∞ëËÆ°ÁÆóÂíåÂÜÖÂ≠òÈúÄÊ±Ç„ÄÇËØ•Ê®°Âûã‰∏ªË¶ÅÈíàÂØπÂàÜÁ±ª‰ªªÂä°ËøõË°åËØÑ‰º∞Âíå‰ºòÂåñÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÂÖ∂Âú®ÂêÑÁßç‰∏ãÊ∏∏Â∫îÁî®Á®ãÂ∫è‰∏≠ÂÖ∑Êúâ‰∏≠Á≠âÈõ∂Ê†∑Êú¨ÂàÜÁ±ªÊÄßËÉΩ„ÄÇÈÄöËøáÈ¢ùÂ§ñÁöÑÈÖçÁΩÆÔºåËØ•Ê®°ÂûãÊÄßËÉΩÂèØ‰ª•Âú®ÁâπÂÆöÂàÜÁ±ª‰ªªÂä°‰∏äÊé•ËøëÊàñÁîöËá≥Ë∂ÖËøáÊõ¥Â§ßÁöÑÊû∂ÊûÑ„ÄÇ

##### **Data-Driven Distributed Common Operational Picture from Heterogeneous Platforms using Multi-Agent Reinforcement Learning**
2411.05683v1 by Indranil Sur, Aswin Raghavan, Abrar Rahman, James Z Hare, Daniel Cassenti, Carl Busart

The integration of unmanned platforms equipped with advanced sensors promises
to enhance situational awareness and mitigate the "fog of war" in military
operations. However, managing the vast influx of data from these platforms
poses a significant challenge for Command and Control (C2) systems. This study
presents a novel multi-agent learning framework to address this challenge. Our
method enables autonomous and secure communication between agents and humans,
which in turn enables real-time formation of an interpretable Common
Operational Picture (COP). Each agent encodes its perceptions and actions into
compact vectors, which are then transmitted, received and decoded to form a COP
encompassing the current state of all agents (friendly and enemy) on the
battlefield. Using Deep Reinforcement Learning (DRL), we jointly train COP
models and agent's action selection policies. We demonstrate resilience to
degraded conditions such as denied GPS and disrupted communications.
Experimental validation is performed in the Starcraft-2 simulation environment
to evaluate the precision of the COPs and robustness of policies. We report
less than 5% error in COPs and policies resilient to various adversarial
conditions. In summary, our contributions include a method for autonomous COP
formation, increased resilience through distributed prediction, and joint
training of COP models and multi-agent RL policies. This research advances
adaptive and resilient C2, facilitating effective control of heterogeneous
unmanned platforms.

ÊëòË¶ÅÔºöÈÖçÂÇôÂÖàÈÄ≤ÊÑüÊ∏¨Âô®ÁöÑÁÑ°‰∫∫Âπ≥Âè∞ÁöÑÊï¥ÂêàÊâøË´æÂ¢ûÂº∑ÊÉÖÂ¢ÉÊÑüÁü•‰∏¶Ê∏õËºïËªç‰∫ãË°åÂãï‰∏≠ÁöÑ„ÄåÊà∞Áà≠Ëø∑Èúß„Äç„ÄÇÁÑ∂ËÄåÔºåÁÆ°ÁêÜ‰æÜËá™ÈÄô‰∫õÂπ≥Âè∞ÁöÑÈæêÂ§ßË≥áÊñôÊµÅÂÖ•Â∞çÊåáÊèÆÂíåÊéßÂà∂ (C2) Á≥ªÁµ±ÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§ö‰ª£ÁêÜÂ≠∏ÁøíÊ°ÜÊû∂‰æÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂÖÅË®±‰ª£ÁêÜÂíå‰∫∫È°û‰πãÈñìÁöÑËá™‰∏ªÂíåÂÆâÂÖ®ÈÄöË®äÔºåÈÄôÈÄ≤ËÄåÂÖÅË®±Âç≥ÊôÇÂΩ¢ÊàêÂèØËß£ÈáãÁöÑÂÖ±Âêå‰ΩúÊà∞Âúñ (COP)„ÄÇÊØèÂÄã‰ª£ÁêÜÂ∞áÂÖ∂ÊÑüÁü•ÂíåÂãï‰ΩúÁ∑®Á¢ºÊàêÁ∑äÊπäÂêëÈáèÔºåÁÑ∂ÂæåÂÇ≥Ëº∏„ÄÅÊé•Êî∂ÂíåËß£Á¢º‰ª•ÂΩ¢Êàê‰∏ÄÂÄã COPÔºåÊ∂µËìãÊà∞Â†¥‰∏äÊâÄÊúâ‰ª£ÁêÜÔºàÂèãÊñπÂíåÊïµÊñπÔºâÁöÑÁï∂ÂâçÁãÄÊÖã„ÄÇ‰ΩøÁî®Ê∑±Â∫¶Âº∑ÂåñÂ≠∏Áøí (DRL)ÔºåÊàëÂÄëÂÖ±ÂêåË®ìÁ∑¥ COP Ê®°ÂûãÂíå‰ª£ÁêÜÂãï‰ΩúÈÅ∏ÊìáÁ≠ñÁï•„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ∞ç GPS ÊãíÁµïÂíåÈÄöË®ä‰∏≠Êñ∑Á≠âÊÉ°Âä£Ê¢ù‰ª∂ÁöÑÂæ©ÂéüÂäõ„ÄÇÂú® Starcraft-2 Ê®°Êì¨Áí∞Â¢É‰∏≠Âü∑Ë°åÂØ¶È©óÈ©óË≠âÔºå‰ª•Ë©ï‰º∞ COP ÁöÑÁ≤æÂ∫¶ÂíåÁ≠ñÁï•ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÂ†±ÂëäË™™ COP ÁöÑË™§Â∑ÆÂ∞èÊñº 5%Ôºå‰∏¶‰∏îÁ≠ñÁï•Â∞çÂêÑÁ®ÆÂ∞çÊäóÊ¢ù‰ª∂ÂÖ∑ÊúâÂæ©ÂéüÂäõ„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨‰∏ÄÁ®ÆÁî®ÊñºËá™‰∏ª COP ÂΩ¢ÊàêÁöÑÊñπÊ≥ï„ÄÅÈÄöÈÅéÂàÜ‰ΩàÂºèÈ†êÊ∏¨Â¢ûÂä†ÁöÑÂæ©ÂéüÂäõÔºå‰ª•Âèä COP Ê®°ÂûãÂíåÂ§ö‰ª£ÁêÜ RL Á≠ñÁï•ÁöÑËÅØÂêàË®ìÁ∑¥„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Êé®Âãï‰∫ÜÈÅ©ÊáâÊÄßÂíåÂæ©ÂéüÊÄßÁöÑ C2Ôºå‰øÉÈÄ≤‰∫ÜÂ∞çÁï∞Ë≥™ÁÑ°‰∫∫Âπ≥Âè∞ÁöÑÊúâÊïàÊéßÂà∂„ÄÇ

##### **Tell What You Hear From What You See -- Video to Audio Generation Through Text**
2411.05679v1 by Xiulong Liu, Kun Su, Eli Shlizerman

The content of visual and audio scenes is multi-faceted such that a video can
be paired with various audio and vice-versa. Thereby, in video-to-audio
generation task, it is imperative to introduce steering approaches for
controlling the generated audio. While Video-to-Audio generation is a
well-established generative task, existing methods lack such controllability.
In this work, we propose VATT, a multi-modal generative framework that takes a
video and an optional text prompt as input, and generates audio and optional
textual description of the audio. Such a framework has two advantages: i)
Video-to-Audio generation process can be refined and controlled via text which
complements the context of visual information, and ii) The model can suggest
what audio to generate for the video by generating audio captions. VATT
consists of two key modules: VATT Converter, a LLM that is fine-tuned for
instructions and includes a projection layer that maps video features to the
LLM vector space; and VATT Audio, a transformer that generates audio tokens
from visual frames and from optional text prompt using iterative parallel
decoding. The audio tokens are converted to a waveform by pretrained neural
codec. Experiments show that when VATT is compared to existing video-to-audio
generation methods in objective metrics, it achieves competitive performance
when the audio caption is not provided. When the audio caption is provided as a
prompt, VATT achieves even more refined performance (lowest KLD score of 1.41).
Furthermore, subjective studies show that VATT Audio has been chosen as
preferred generated audio than audio generated by existing methods. VATT
enables controllable video-to-audio generation through text as well as
suggesting text prompts for videos through audio captions, unlocking novel
applications such as text-guided video-to-audio generation and video-to-audio
captioning.

ÊëòË¶ÅÔºöË¶ñË¶∫ÂíåÈü≥Ë®äÂ†¥ÊôØÁöÑÂÖßÂÆπÊòØÂ§öÊñπÈù¢ÁöÑÔºå‰æãÂ¶ÇÂΩ±ÁâáÂèØ‰ª•ËàáÂêÑÁ®ÆÈü≥Ë®äÈÖçÂ∞çÔºåÂèç‰πã‰∫¶ÁÑ∂„ÄÇÂõ†Ê≠§ÔºåÂú®ÂΩ±ÁâáËΩâÈü≥Ë®äÁîüÊàê‰ªªÂãô‰∏≠ÔºåÂøÖÈ†àÂºïÂÖ•Â∞éÂºïÊñπÊ≥ï‰æÜÊéßÂà∂ÁîüÊàêÁöÑÈü≥Ë®ä„ÄÇÈõñÁÑ∂ÂΩ±ÁâáËΩâÈü≥Ë®äÁîüÊàêÊòØ‰∏ÄÈ†ÖÊàêÁÜüÁöÑÁîüÊàê‰ªªÂãôÔºå‰ΩÜÁèæÊúâÊñπÊ≥ïÁº∫‰πèÈÄôÁ®ÆÂèØÊéßÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ VATTÔºå‰∏ÄÂÄãÂ§öÊ®°ÊÖãÁîüÊàêÊ°ÜÊû∂ÔºåÂÆÉ‰ª•ÂΩ±ÁâáÂíå‰∏ÄÂÄãÈÅ∏Áî®ÁöÑÊñáÂ≠óÊèêÁ§∫‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰∏¶ÁîüÊàêÈü≥Ë®äÂíåÈü≥Ë®äÁöÑÈÅ∏Áî®ÊñáÂ≠óÊèèËø∞„ÄÇÈÄôÁ®ÆÊ°ÜÊû∂ÊúâÂÖ©ÂÄãÂÑ™ÈªûÔºöi) ÂΩ±ÁâáËΩâÈü≥Ë®äÁîüÊàêÈÅéÁ®ãÂèØ‰ª•ÈÄèÈÅéÊñáÂ≠óÈÄ≤Ë°åÂÑ™ÂåñÂíåÊéßÂà∂ÔºåÈÄôË£úÂÖÖ‰∫ÜË¶ñË¶∫Ë≥áË®äÁöÑËÉåÊôØÔºå‰ª•Âèä ii) ÈÄôÂÄãÊ®°ÂûãÂèØ‰ª•ÈÄèÈÅéÁîüÊàêÈü≥Ë®äÊ®ôÈ°å‰æÜÂª∫Ë≠∞Ë¶ÅÁÇ∫ÂΩ±ÁâáÁîüÊàê‰ªÄÈ∫ºÈü≥Ë®ä„ÄÇVATT ÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÊ®°ÁµÑÔºöVATT ËΩâÊèõÂô®Ôºå‰∏ÄÂÄãÁ∂ìÈÅéÂæÆË™øÁöÑ LLMÔºåÈÅ©Áî®ÊñºÊåá‰ª§Ôºå‰∏¶ÂåÖÂê´‰∏ÄÂÄãÂ∞áÂΩ±ÁâáÁâπÂæµÂ∞çÊáâÂà∞ LLM ÂêëÈáèÁ©∫ÈñìÁöÑÊäïÂΩ±Â±§Ôºõ‰ª•Âèä VATT Èü≥Ë®äÔºå‰∏ÄÂÄãËΩâÊèõÂô®ÔºåÂÆÉ‰ΩøÁî®ÂèçË¶ÜÂπ≥Ë°åËß£Á¢ºÂæûË¶ñË¶∫Ê°ÜÊû∂ÂíåÈÅ∏Áî®ÁöÑÊñáÂ≠óÊèêÁ§∫ÁîüÊàêÈü≥Ë®äË®òËôü„ÄÇÈü≥Ë®äË®òËôüÁî±È†êË®ìÁ∑¥ÁöÑÁ•ûÁ∂ìÁ∑®Ëß£Á¢ºÂô®ËΩâÊèõÁÇ∫Ê≥¢ÂΩ¢„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåÁï∂ VATT ËàáÁèæÊúâÁöÑÂΩ±ÁâáËΩâÈü≥Ë®äÁîüÊàêÊñπÊ≥ïÂú®ÂÆ¢ËßÄÊåáÊ®ô‰∏≠ÈÄ≤Ë°åÊØîËºÉÊôÇÔºåÂÆÉÂú®Ê≤íÊúâÊèê‰æõÈü≥Ë®äÊ®ôÈ°åÊôÇÔºåÈÅîÂà∞‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇÁï∂Èü≥Ë®äÊ®ôÈ°å‰ΩúÁÇ∫ÊèêÁ§∫Êèê‰æõÊôÇÔºåVATT ÈÅîÂà∞‰∫ÜÊõ¥Á≤æÁ∑ªÁöÑÊïàËÉΩÔºàÊúÄ‰Ωé KLD ÂàÜÊï∏ÁÇ∫ 1.41Ôºâ„ÄÇÊ≠§Â§ñÔºå‰∏ªËßÄÁ†îÁ©∂È°ØÁ§∫ÔºåVATT Èü≥Ë®äÂ∑≤Ë¢´ÈÅ∏ÁÇ∫ÊØîÁèæÊúâÊñπÊ≥ïÁîüÊàêÁöÑÈü≥Ë®äÊõ¥‰Ω≥ÁöÑÁîüÊàêÈü≥Ë®ä„ÄÇVATT ËÉΩÂ§†ÈÄèÈÅéÊñáÂ≠óÈÄ≤Ë°åÂèØÊéßÁöÑÂΩ±ÁâáËΩâÈü≥Ë®äÁîüÊàêÔºå‰∏¶ÈÄèÈÅéÈü≥Ë®äÊ®ôÈ°åÁÇ∫ÂΩ±ÁâáÂª∫Ë≠∞ÊñáÂ≠óÊèêÁ§∫ÔºåÈñãÂïü‰∫ÜÊñ∞ÁöÑÊáâÁî®Á®ãÂºèÔºå‰æãÂ¶ÇÊñáÂ≠óÂºïÂ∞éÁöÑÂΩ±ÁâáËΩâÈü≥Ë®äÁîüÊàêÂíåÂΩ±ÁâáËΩâÈü≥Ë®äÊ®ôÈ°å„ÄÇ

##### **Improving Molecular Graph Generation with Flow Matching and Optimal Transport**
2411.05676v1 by Xiaoyang Hou, Tian Zhu, Milong Ren, Dongbo Bu, Xin Gao, Chunming Zhang, Shiwei Sun

Generating molecular graphs is crucial in drug design and discovery but
remains challenging due to the complex interdependencies between nodes and
edges. While diffusion models have demonstrated their potentiality in molecular
graph design, they often suffer from unstable training and inefficient
sampling. To enhance generation performance and training stability, we propose
GGFlow, a discrete flow matching generative model incorporating optimal
transport for molecular graphs and it incorporates an edge-augmented graph
transformer to enable the direct communications among chemical bounds.
Additionally, GGFlow introduces a novel goal-guided generation framework to
control the generative trajectory of our model, aiming to design novel
molecular structures with the desired properties. GGFlow demonstrates superior
performance on both unconditional and conditional molecule generation tasks,
outperforming existing baselines and underscoring its effectiveness and
potential for wider application.

ÊëòË¶ÅÔºöÁîüÊàêÂàÜÂ≠êÂúñÂú®Ëó•Áâ©Ë®≠Ë®àÂíåÁôºÁèæ‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁî±ÊñºÁØÄÈªûÂíåÈÇäÁ∑£‰πãÈñìÁöÑË§áÈõúÁõ∏‰∫í‰æùË≥¥Èóú‰øÇÔºåÈÄô‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂÑòÁÆ°Êì¥Êï£Ê®°ÂûãÂ∑≤Ë≠âÊòé‰∫ÜÂÆÉÂÄëÂú®ÂàÜÂ≠êÂúñË®≠Ë®à‰∏≠ÁöÑÊΩõÂäõÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏ÊúÉÂá∫ÁèæË®ìÁ∑¥‰∏çÁ©©ÂÆöÂíåÊé°Ê®£ÊïàÁéá‰Ωé‰∏ãÁöÑÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑ÁîüÊàêÊÄßËÉΩÂíåË®ìÁ∑¥Á©©ÂÆöÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫Ü GGFlowÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈõ¢Êï£ÊµÅÂåπÈÖçÁîüÊàêÊ®°ÂûãÔºåÂÆÉÁµêÂêà‰∫ÜÂàÜÂ≠êÂúñÁöÑÊúÄÂÑ™ÂÇ≥Ëº∏Ôºå‰∏¶ÁµêÂêà‰∫Ü‰∏ÄÂÄãÈÇäÁ∑£Â¢ûÂº∑ÂúñÂΩ¢ËÆäÊèõÂô®Ôºå‰ª•ÂØ¶ÁèæÂåñÂ≠∏Èçµ‰πãÈñìÁöÑÁõ¥Êé•ÈÄö‰ø°„ÄÇÊ≠§Â§ñÔºåGGFlow ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÁõÆÊ®ôÂºïÂ∞éÁîüÊàêÊ°ÜÊû∂Ôºå‰ª•ÊéßÂà∂ÊàëÂÄëÊ®°ÂûãÁöÑÁîüÊàêËªåË∑°ÔºåÊó®Âú®Ë®≠Ë®àÂÖ∑ÊúâÊâÄÈúÄÂ±¨ÊÄßÁöÑÊñ∞Á©éÂàÜÂ≠êÁµêÊßã„ÄÇGGFlow Âú®ÁÑ°Ê¢ù‰ª∂ÂíåÊ¢ù‰ª∂ÂàÜÂ≠êÁîüÊàê‰ªªÂãô‰∏äÈÉΩË°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩÔºåÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Ê∫ñÔºå‰∏¶Âº∑Ë™ø‰∫ÜÂÖ∂Âú®Êõ¥Âª£Ê≥õÊáâÁî®‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÊΩõÂäõ„ÄÇ

##### **Unmasking the Limits of Large Language Models: A Systematic Evaluation of Masked Text Processing Ability through MskQA and MskCal**
2411.05665v1 by Fuka Matsuzaki, Haru-Tada Sato

This paper sheds light on the limitations of Large Language Models (LLMs) by
rigorously evaluating their ability to process masked text. We introduce two
novel tasks: MskQA, measuring reasoning on masked question-answering datasets
like RealtimeQA, and MskCal, assessing numerical reasoning on masked arithmetic
problems.Testing GPT-4o and 4o-mini reveals that while LLMs exhibit some
resilience to masked text, their performance is highly contingent on masking
rates and semantic cues. Specifically, "solid masking," where semantic clues
are entirely absent, leads to a significant performance drop compared to
"partial lifting," where some semantic information is retained, indicating
LLMs' reliance on surface-level patterns. Interestingly, GPT-4o consistently
outperforms 4o-mini, particularly in MskCal, demonstrating a greater ability to
handle numerical reasoning with masked text. This underscores the crucial role
of semantic cues in the reasoning process of LLMs. Our study illuminates the
interplay between background knowledge and reasoning ability in masked text
processing, paving the way for a deeper understanding of LLM capabilities and
limitations, and highlighting the need for more robust evaluation methods to
accurately assess their true comprehension abilities.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÂö¥Ê†ºË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËôïÁêÜÈÅÆËîΩÊñáÂ≠óÁöÑËÉΩÂäõÔºåÈÄ≤ËÄåÈó°ÊòéÂÖ∂ÈôêÂà∂„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©È†ÖÊñ∞‰ªªÂãôÔºöMskQAÔºåÁî®ÊñºË°°ÈáèÂú®ÈÅÆËîΩÂïèÁ≠îË≥áÊñôÈõÜÔºàÂ¶Ç RealtimeQAÔºâ‰∏äÁöÑÊé®ÁêÜËÉΩÂäõÔºõ‰ª•Âèä MskCalÔºåÁî®ÊñºË©ï‰º∞Âú®ÈÅÆËîΩÁÆóË°ìÂïèÈ°å‰∏äÁöÑÊï∏ÂÄºÊé®ÁêÜËÉΩÂäõ„ÄÇÊ∏¨Ë©¶ GPT-4o Âíå 4o-mini È°ØÁ§∫ÔºåÂÑòÁÆ° LLM Â∞çÈÅÆËîΩÊñáÂ≠óÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÈüåÊÄßÔºå‰ΩÜÂÖ∂ÊïàËÉΩÈ´òÂ∫¶‰æùË≥¥ÊñºÈÅÆËîΩÁéáÂíåË™ûÁæ©Á∑öÁ¥¢„ÄÇÂÖ∑È´î‰æÜË™™Ôºå„ÄåÂÆåÂÖ®ÈÅÆËîΩ„ÄçÔºàË™ûÁæ©Á∑öÁ¥¢ÂÆåÂÖ®‰∏çÂ≠òÂú®ÔºâÊúÉÂ∞éËá¥ÊïàËÉΩÈ°ØËëó‰∏ãÈôçÔºåËÄå„ÄåÈÉ®ÂàÜËß£Èô§„ÄçÔºà‰øùÁïô‰∏Ä‰∫õË™ûÁæ©Ë≥áË®äÔºâÂâá‰∏çÊúÉÔºåÈÄôË°®Á§∫ LLM ‰æùË≥¥ÊñºË°®Èù¢Ê®°Âºè„ÄÇÊúâË∂£ÁöÑÊòØÔºåGPT-4o ÁöÑË°®ÁèæÂßãÁµÇÂÑ™Êñº 4o-miniÔºåÁâπÂà•ÊòØÂú® MskCal ‰∏≠ÔºåÈÄôÈ°ØÁ§∫Âá∫ÂÆÉÂú®ËôïÁêÜÈÅÆËîΩÊñáÂ≠óÊï∏ÂÄºÊé®ÁêÜÊñπÈù¢ÁöÑËÉΩÂäõÊõ¥Âº∑„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜË™ûÁæ©Á∑öÁ¥¢Âú® LLM Êé®ÁêÜÈÅéÁ®ã‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Èó°Êòé‰∫ÜËÉåÊôØÁü•Ë≠òÂíåÊé®ÁêÜËÉΩÂäõÂú®ÈÅÆËîΩÊñáÂ≠óËôïÁêÜ‰∏≠ÁöÑ‰∫§‰∫í‰ΩúÁî®ÔºåÁÇ∫Êõ¥Ê∑±ÂÖ•‰∫ÜËß£ LLM ÁöÑËÉΩÂäõÂíåÈôêÂà∂Èã™Ë∑ØÔºå‰∏¶Âº∑Ë™øÈúÄË¶ÅÊõ¥ÂÅ•ÂÖ®ÁöÑË©ï‰º∞ÊñπÊ≥ï‰æÜÊ∫ñÁ¢∫Ë©ï‰º∞ÂÖ∂ÁúüÊ≠£ÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇ

##### **The influence of persona and conversational task on social interactions with a LLM-controlled embodied conversational agent**
2411.05653v1 by Leon O. H. Kroczek, Alexander May, Selina Hettenkofer, Andreas Ruider, Bernd Ludwig, Andreas M√ºhlberger

Large Language Models (LLMs) have demonstrated remarkable capabilities in
conversational tasks. Embodying an LLM as a virtual human allows users to
engage in face-to-face social interactions in Virtual Reality. However, the
influence of person- and task-related factors in social interactions with
LLM-controlled agents remains unclear. In this study, forty-six participants
interacted with a virtual agent whose persona was manipulated as extravert or
introvert in three different conversational tasks (small talk, knowledge test,
convincing). Social-evaluation, emotional experience, and realism were assessed
using ratings. Interactive engagement was measured by quantifying participants'
words and conversational turns. Finally, we measured participants' willingness
to ask the agent for help during the knowledge test. Our findings show that the
extraverted agent was more positively evaluated, elicited a more pleasant
experience and greater engagement, and was assessed as more realistic compared
to the introverted agent. Whereas persona did not affect the tendency to ask
for help, participants were generally more confident in the answer when they
had help of the LLM. Variation of personality traits of LLM-controlled embodied
virtual agents, therefore, affects social-emotional processing and behavior in
virtual interactions. Embodied virtual agents allow the presentation of
naturalistic social encounters in a virtual environment.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®Â∞çË©±‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈùûÂá°ÁöÑËÉΩÂäõ„ÄÇÂ∞á LLM ÂÖ∑Ë±°ÂåñÁÇ∫ËôõÊì¨‰∫∫È°ûÔºåËÆì‰ΩøÁî®ËÄÖËÉΩÂú®ËôõÊì¨ÂØ¶Â¢É‰∏≠ÈÄ≤Ë°åÈù¢Â∞çÈù¢ÁöÑÁ§æ‰∫§‰∫íÂãï„ÄÇÁÑ∂ËÄåÔºåÂú®Ëàá LLM ÊéßÂà∂ÁöÑ‰ª£ÁêÜÈÄ≤Ë°åÁ§æ‰∫§‰∫íÂãïÊôÇÔºå‰∫∫Ëàá‰ªªÂãôÁõ∏ÈóúÂõ†Á¥†ÁöÑÂΩ±Èüø‰ªç‰∏çÊòéÁ¢∫„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÂõõÂçÅÂÖ≠‰ΩçÂèÉËàáËÄÖËàá‰∏Ä‰ΩçËôõÊì¨‰ª£ÁêÜ‰∫íÂãïÔºåÂÖ∂ËßíËâ≤Âú®‰∏âÁ®Æ‰∏çÂêåÁöÑÂ∞çË©±‰ªªÂãôÔºàÈñíËÅä„ÄÅÁü•Ë≠òÊ∏¨È©ó„ÄÅË™™ÊúçÔºâ‰∏≠Ë¢´Ë®≠ÂÆöÁÇ∫Â§ñÂêëÊàñÂÖßÂêë„ÄÇ‰ΩøÁî®Ë©ïÂàÜË©ï‰º∞Á§æ‰∫§Ë©ïÈáè„ÄÅÊÉÖÁ∑íÈ´îÈ©óÂíåÁúüÂØ¶ÊÄß„ÄÇ‰∫íÂãïÂèÉËàáÂ∫¶ÈÄèÈÅéÈáèÂåñÂèÉËàáËÄÖÁöÑÂ≠óÊï∏ÂíåÂ∞çË©±Ê¨°Êï∏‰æÜË°°Èáè„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ∏¨ÈáèÂèÉËàáËÄÖÂú®Áü•Ë≠òÊ∏¨È©óÊúüÈñìÂêë‰ª£ÁêÜÂ∞ãÊ±ÇÂπ´Âä©ÁöÑÊÑèÈ°ò„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂÖßÂêëÁöÑ‰ª£ÁêÜÁõ∏ÊØîÔºåÂ§ñÂêëÁöÑ‰ª£ÁêÜÁç≤Âæó‰∫ÜÊõ¥Ê≠£Èù¢ÁöÑË©ïÂÉπÔºåÂºïÁôº‰∫ÜÊõ¥ÊÑâÂø´ÁöÑÈ´îÈ©óÂíåÊõ¥È´òÁöÑÂèÉËàáÂ∫¶Ôºå‰∏¶Ë¢´Ë©ïÁÇ∫Êõ¥ÁúüÂØ¶„ÄÇÈõñÁÑ∂ËßíËâ≤‰∏çÊúÉÂΩ±ÈüøÂ∞ãÊ±ÇÂπ´Âä©ÁöÑÂÇæÂêëÔºå‰ΩÜÂèÉËàáËÄÖÂú®Áç≤Âæó LLM ÁöÑÂπ´Âä©ÂæåÈÄöÂ∏∏Â∞çÁ≠îÊ°àÊõ¥Êúâ‰ø°ÂøÉ„ÄÇÂõ†Ê≠§ÔºåÁî± LLM ÊéßÂà∂ÁöÑÂÖ∑Ë±°ËôõÊì¨‰ª£ÁêÜÁöÑ‰∫∫Ê†ºÁâπË≥™ËÆäÂåñÊúÉÂΩ±ÈüøËôõÊì¨‰∫íÂãï‰∏≠ÁöÑÁ§æÊúÉÊÉÖÁ∑íËôïÁêÜÂíåË°åÁÇ∫„ÄÇÂÖ∑Ë±°ËôõÊì¨‰ª£ÁêÜÂèØ‰ª•Âú®ËôõÊì¨Áí∞Â¢É‰∏≠ÂëàÁèæËá™ÁÑ∂ÁöÑÁ§æ‰∫§‰∫íÂãï„ÄÇ

##### **Evaluating Large Language Model Capability in Vietnamese Fact-Checking Data Generation**
2411.05641v1 by Long Truong To, Hung Tuan Le, Dat Van-Thanh Nguyen, Manh Trong Nguyen, Tri Thien Nguyen, Tin Van Huynh, Kiet Van Nguyen

Large Language Models (LLMs), with gradually improving reading comprehension
and reasoning capabilities, are being applied to a range of complex language
tasks, including the automatic generation of language data for various
purposes. However, research on applying LLMs for automatic data generation in
low-resource languages like Vietnamese is still underdeveloped and lacks
comprehensive evaluation. In this paper, we explore the use of LLMs for
automatic data generation for the Vietnamese fact-checking task, which faces
significant data limitations. Specifically, we focus on fact-checking data
where claims are synthesized from multiple evidence sentences to assess the
information synthesis capabilities of LLMs. We develop an automatic data
construction process using simple prompt techniques on LLMs and explore several
methods to improve the quality of the generated data. To evaluate the quality
of the data generated by LLMs, we conduct both manual quality assessments and
performance evaluations using language models. Experimental results and manual
evaluations illustrate that while the quality of the generated data has
significantly improved through fine-tuning techniques, LLMs still cannot match
the data quality produced by humans.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄêÊº∏ÊèêÂçáÈñ±ËÆÄÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõÔºåÊ≠£Ë¢´ÊáâÁî®ÊñºÂêÑÁ®ÆË§áÈõúÁöÑË™ûË®Ä‰ªªÂãôÔºåÂåÖÊã¨Ëá™ÂãïÁî¢ÁîüÂêÑÁ®ÆÁî®ÈÄîÁöÑË™ûË®ÄË≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÈáùÂ∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÔºà‰æãÂ¶ÇË∂äÂçóË™ûÔºâÊáâÁî® LLM Ëá™ÂãïÁî¢ÁîüË≥áÊñôÁöÑÁ†îÁ©∂‰ªçÊú™ÊàêÁÜüÔºå‰∏îÁº∫‰πèÂÖ®Èù¢ÁöÑË©ï‰º∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é LLM Áî®ÊñºË∂äÂçóË™û‰∫ãÂØ¶Êü•Ê†∏‰ªªÂãôÁöÑËá™ÂãïË≥áÊñôÁî¢ÁîüÔºåÊ≠§‰ªªÂãôÈù¢Ëá®Âö¥ÈáçÁöÑË≥áÊñôÈôêÂà∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂæûÂ§öÂÄãË≠âÊìöÂè•Â≠ê‰∏≠Á∂úÂêàËÅ≤ÊòéÁöÑ‰∫ãÂØ¶Êü•Ê†∏Ë≥áÊñôÔºå‰ª•Ë©ï‰º∞ LLM ÁöÑË≥áË®äÁ∂úÂêàËÉΩÂäõ„ÄÇÊàëÂÄë‰ΩøÁî® LLM ‰∏äÁöÑÁ∞°ÂñÆÊèêÁ§∫ÊäÄË°ìÈñãÁôº‰∏ÄÂÄãËá™ÂãïË≥áÊñôÂª∫ÊßãÊµÅÁ®ãÔºå‰∏¶Êé¢Ë®éÂ§öÁ®ÆÊñπÊ≥ï‰æÜÊèêÂçáÁî¢ÁîüË≥áÊñôÁöÑÂìÅË≥™„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ LLM Áî¢ÁîüÁöÑË≥áÊñôÂìÅË≥™ÔºåÊàëÂÄë‰ΩøÁî®Ë™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÊâãÂãïÂìÅË≥™Ë©ï‰º∞ÂíåÊïàËÉΩË©ï‰º∞„ÄÇÂØ¶È©óÁµêÊûúÂíåÊâãÂãïË©ï‰º∞È°ØÁ§∫ÔºåÈõñÁÑ∂ÈÄèÈÅéÂæÆË™øÊäÄË°ìÈ°ØËëóÊèêÂçá‰∫ÜÁî¢ÁîüË≥áÊñôÁöÑÂìÅË≥™Ôºå‰ΩÜ LLM ‰ªçÁÑ°Ê≥ïÊØîÊì¨‰∫∫È°ûÁî¢ÁîüÁöÑË≥áÊñôÂìÅË≥™„ÄÇ

##### **Assessing Open-Source Large Language Models on Argumentation Mining Subtasks**
2411.05639v1 by Mohammad Yeghaneh Abkenar, Weixing Wang, Hendrik Graupner, Manfred Stede

We explore the capability of four open-sourcelarge language models (LLMs) in
argumentation mining (AM). We conduct experiments on three different corpora;
persuasive essays(PE), argumentative microtexts (AMT) Part 1 and Part 2, based
on two argumentation mining sub-tasks: (i) argumentative discourse units
classifications (ADUC), and (ii) argumentative relation classification (ARC).
This work aims to assess the argumentation capability of open-source LLMs,
including Mistral 7B, Mixtral8x7B, LlamA2 7B and LlamA3 8B in both, zero-shot
and few-shot scenarios. Our analysis contributes to further assessing
computational argumentation with open-source LLMs in future research efforts.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Ë®é‰∫ÜÂõõÁ®ÆÈñãÊ∫êÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë´ñË≠âÊåñÊéò (AM) ‰∏≠ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂ∞ç‰∏âÂÄã‰∏çÂêåÁöÑË™ûÊñôÂ∫´ÈÄ≤Ë°å‰∫ÜÂØ¶È©óÔºõÂü∫ÊñºÂÖ©ÂÄãË´ñË≠âÊåñÊéòÂ≠ê‰ªªÂãôÁöÑË™™ÊúçÊÄßÊñáÁ´† (PE)„ÄÅË´ñË≠âÊÄßÂæÆÊñáÊú¨ (AMT) Á¨¨ 1 ÈÉ®ÂàÜÂíåÁ¨¨ 2 ÈÉ®ÂàÜÔºö(i) Ë´ñË≠âÊÄßË©±Ë™ûÂñÆÂÖÉÂàÜÈ°û (ADUC) Âíå (ii) Ë´ñË≠âÈóú‰øÇÂàÜÈ°û (ARC)„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÁõÆÁöÑÊòØË©ï‰º∞ÈñãÊ∫ê LLM ÁöÑË´ñË≠âËÉΩÂäõÔºåÂåÖÊã¨ Mistral 7B„ÄÅMixtral8x7B„ÄÅLlamA2 7B Âíå LlamA3 8BÔºåÁÑ°Ë´ñÊòØÂú®Èõ∂Ê¨°ÂòóË©¶ÈÇÑÊòØÂ∞ëÊ¨°ÂòóË©¶ÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊúâÂä©ÊñºÂú®Êú™‰æÜÁöÑÁ†îÁ©∂Â∑•‰Ωú‰∏≠ÈÄ≤‰∏ÄÊ≠•Ë©ï‰º∞‰ΩøÁî®ÈñãÊ∫ê LLM ÈÄ≤Ë°åÁöÑË®àÁÆóË´ñË≠â„ÄÇ

##### **Impact of Fake News on Social Media Towards Public Users of Different Age Groups**
2411.05638v1 by Kahlil bin Abdul Hakim, Sathishkumar Veerappampalayam Easwaramoorthy

This study examines how fake news affects social media users across a range
of age groups and how machine learning (ML) and artificial intelligence (AI)
can help reduce the spread of false information. The paper evaluates various
machine learning models for their efficacy in identifying and categorizing fake
news and examines current trends in the spread of fake news, including deepfake
technology. The study assesses four models using a Kaggle dataset: Random
Forest, Support Vector Machine (SVM), Neural Networks, and Logistic Regression.
The results show that SVM and neural networks perform better than other models,
with accuracies of 93.29% and 93.69%, respectively. The study also emphasises
how people in the elder age group diminished capacity for critical analysis of
news content makes them more susceptible to disinformation. Natural language
processing (NLP) and deep learning approaches have the potential to improve the
accuracy of false news detection. Biases in AI and ML models and difficulties
in identifying information generated by AI continue to be major problems in
spite of the developments. The study recommends that datasets be expanded to
encompass a wider range of languages and that detection algorithms be
continuously improved to keep up with the latest advancements in disinformation
tactics. In order to combat fake news and promote an informed and resilient
society, this study emphasizes the value of cooperative efforts between AI
researchers, social media platforms, and governments.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÂÅáÊñ∞ËÅûÂ¶Ç‰ΩïÂΩ±ÈüøÂêÑÂπ¥ÈΩ°Â±§ÁöÑÁ§æÁæ§Â™íÈ´î‰ΩøÁî®ËÄÖÔºå‰ª•ÂèäÊ©üÂô®Â≠∏Áøí (ML) Ëàá‰∫∫Â∑•Êô∫ÊÖß (AI) Â¶Ç‰ΩïÊúâÂä©ÊñºÊ∏õÂ∞ëÈåØË™§Ë≥áË®äÁöÑÊï£Â∏É„ÄÇÊú¨ÊñáË©ï‰º∞ÂêÑÁ®ÆÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®Ëæ®Ë≠òÂíåÂàÜÈ°ûÂÅáÊñ∞ËÅûÁöÑÊïàËÉΩÔºå‰∏¶Êé¢Ë®éÂÅáÊñ∞ËÅûÊï£Â∏ÉÁöÑÁèæ‰ªäË∂®Âã¢ÔºåÂåÖÊã¨Ê∑±Â∫¶ÈÄ†ÂÅáÊäÄË°ì„ÄÇÊú¨Á†îÁ©∂‰ΩøÁî® Kaggle Ë≥áÊñôÈõÜË©ï‰º∞ÂõõÁ®ÆÊ®°ÂûãÔºöÈö®Ê©üÊ£ÆÊûó„ÄÅÊîØÊè¥ÂêëÈáèÊ©ü (SVM)„ÄÅÁ•ûÁ∂ìÁ∂≤Ë∑ØÂíåÈÇèËºØËø¥Ê≠∏„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåSVM ÂíåÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑË°®ÁèæÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåÊ∫ñÁ¢∫Â∫¶ÂàÜÂà•ÁÇ∫ 93.29% Âíå 93.69%„ÄÇÊú¨Á†îÁ©∂‰πüÂº∑Ë™øÔºåËÄÅÂπ¥Áæ§È´îÂ∞çÊñ∞ËÅûÂÖßÂÆπÁöÑÊâπÂà§ÊÄßÂàÜÊûêËÉΩÂäõ‰∏ãÈôçÔºåÈÄô‰ΩøÂæó‰ªñÂÄëÊõ¥ÂÆπÊòìÂèóÂà∞ÈåØË™§Ë≥áË®äÁöÑÂΩ±Èüø„ÄÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊúâÂèØËÉΩÊèêÂçáÂÅµÊ∏¨ÂÅáÊñ∞ËÅûÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈÄ≤Â±ïÔºåAI Âíå ML Ê®°Âûã‰∏≠ÁöÑÂÅèË¶ãÂíåÈõ£‰ª•Ëæ®Ë≠ò AI ÊâÄÁî¢ÁîüÁöÑË≥áË®ä‰ªçÁÑ∂ÊòØ‰∏ªË¶ÅÂïèÈ°å„ÄÇÊú¨Á†îÁ©∂Âª∫Ë≠∞Êì¥ÂÖÖË≥áÊñôÈõÜ‰ª•Ê∂µËìãÊõ¥Âª£Ê≥õÁöÑË™ûË®ÄÔºå‰∏¶ÊåÅÁ∫åÊîπÂñÑÂÅµÊ∏¨ÊºîÁÆóÊ≥ïÔºå‰ª•Ë∑ü‰∏äÈåØË™§Ë≥áË®äÁ≠ñÁï•ÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÁÇ∫‰∫ÜÊâìÊìäÂÅáÊñ∞ËÅû‰∏¶‰øÉÈÄ≤‰∏ÄÂÄãÊòéÊô∫‰∏îÊúâÈüåÊÄßÁöÑÁ§æÊúÉÔºåÊú¨Á†îÁ©∂Âº∑Ë™ø AI Á†îÁ©∂‰∫∫Âì°„ÄÅÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞ÂíåÊîøÂ∫ú‰πãÈñìÂêà‰ΩúÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection**
2411.05633v1 by Tamara R. Lenhard, Andreas Weinmann, Kai Franke, Tobias Koch

Developing robust drone detection systems is often constrained by the limited
availability of large-scale annotated training data and the high costs
associated with real-world data collection. However, leveraging synthetic data
generated via game engine-based simulations provides a promising and
cost-effective solution to overcome this issue. Therefore, we present
SynDroneVision, a synthetic dataset specifically designed for RGB-based drone
detection in surveillance applications. Featuring diverse backgrounds, lighting
conditions, and drone models, SynDroneVision offers a comprehensive training
foundation for deep learning algorithms. To evaluate the dataset's
effectiveness, we perform a comparative analysis across a selection of recent
YOLO detection models. Our findings demonstrate that SynDroneVision is a
valuable resource for real-world data enrichment, achieving notable
enhancements in model performance and robustness, while significantly reducing
the time and costs of real-world data acquisition. SynDroneVision will be
publicly released upon paper acceptance.

ÊëòË¶ÅÔºöÈñãÁôºÂº∑Â§ßÁöÑÁÑ°‰∫∫Ê©üÂÅµÊ∏¨Á≥ªÁµ±ÂæÄÂæÄÂèóÂà∞Â§ßÂûãÊ®ôË®ªË®ìÁ∑¥Ë≥áÊñôÊúâÈôêÁöÑÂèØÁî®ÊÄß‰ª•ÂèäËàáÂØ¶ÈöõË≥áÊñôÊî∂ÈõÜÁõ∏ÈóúÁöÑÈ´òÊàêÊú¨ÊâÄÈôêÂà∂„ÄÇÁÑ∂ËÄåÔºåÂà©Áî®ÈÄèÈÅéÈÅäÊà≤ÂºïÊìéÊ®°Êì¨Áî¢ÁîüÁöÑÂêàÊàêË≥áÊñôÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄî‰∏îÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑËß£Ê±∫ÊñπÊ°à‰æÜÂÖãÊúçÈÄôÂÄãÂïèÈ°å„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü SynDroneVisionÔºå‰∏ÄÂÄãÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÁõ£ÊéßÊáâÁî®‰∏≠Âü∫Êñº RGB ÁöÑÁÑ°‰∫∫Ê©üÂÅµÊ∏¨ÁöÑÂêàÊàêË≥áÊñôÈõÜ„ÄÇSynDroneVision ÂÖ∑ÊúâÂ§öÊ®£ÂåñÁöÑËÉåÊôØ„ÄÅÂÖâÁÖßÊ¢ù‰ª∂ÂíåÁÑ°‰∫∫Ê©üÊ®°ÂûãÔºåÁÇ∫Ê∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÊèê‰æõ‰∫ÜÂÖ®Èù¢ÁöÑË®ìÁ∑¥Âü∫Á§é„ÄÇÁÇ∫‰∫ÜË©ï‰º∞Ë≥áÊñôÈõÜÁöÑÊúâÊïàÊÄßÔºåÊàëÂÄëÂú®ÊúÄËøëÁöÑ YOLO ÂÅµÊ∏¨Ê®°Âûã‰∏≠ÈÄ≤Ë°å‰∫ÜÊØîËºÉÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåSynDroneVision ÊòØÁî®ÊñºÂØ¶ÈöõË≥áÊñôË±êÂØåÂåñÁöÑ‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑË≥áÊ∫êÔºåÂú®Ê®°ÂûãÊïàËÉΩÂíåÁ©©ÂÅ•ÊÄßÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊèêÂçáÔºåÂêåÊôÇÈ°ØËëóÊ∏õÂ∞ë‰∫ÜÂØ¶ÈöõË≥áÊñôÊì∑ÂèñÁöÑÊôÇÈñìÂíåÊàêÊú¨„ÄÇSynDroneVision Â∞áÂú®Ë´ñÊñáË¢´Êé•ÂèóÂæåÂÖ¨ÈñãÁôºÂ∏É„ÄÇ

##### **Knowledge Distillation Neural Network for Predicting Car-following Behaviour of Human-driven and Autonomous Vehicles**
2411.05618v1 by Ayobami Adewale, Chris Lee, Amnir Hadachi, Nicolly Lima da Silva

As we move towards a mixed-traffic scenario of Autonomous vehicles (AVs) and
Human-driven vehicles (HDVs), understanding the car-following behaviour is
important to improve traffic efficiency and road safety. Using a real-world
trajectory dataset, this study uses descriptive and statistical analysis to
investigate the car-following behaviours of three vehicle pairs: HDV-AV, AV-HDV
and HDV-HDV in mixed traffic. The ANOVA test showed that car-following
behaviours across different vehicle pairs are statistically significant
(p-value < 0.05).
  We also introduce a data-driven Knowledge Distillation Neural Network (KDNN)
model for predicting car-following behaviour in terms of speed. The KDNN model
demonstrates comparable predictive accuracy to its teacher network, a Long
Short-Term Memory (LSTM) network, and outperforms both the standalone student
network, a Multilayer Perceptron (MLP), and traditional physics-based models
like the Gipps model. Notably, the KDNN model better prevents collisions,
measured by minimum Time-to-Collision (TTC), and operates with lower
computational power, making it ideal for AVs or driving simulators requiring
efficient computing.

ÊëòË¶ÅÔºöÈö®ËëóÊàëÂÄëÊúùÂêëËá™ÂãïÈßïÈßõËªäËºõ (AV) Âíå‰∫∫È°ûÈßïÈßõËªäËºõ (HDV) ÁöÑÊ∑∑Âêà‰∫§ÈÄöÂ†¥ÊôØÈÇÅÈÄ≤Ôºå‰∫ÜËß£Ë∑üËªäË°åÁÇ∫Â∞çÊñºÊèêÂçá‰∫§ÈÄöÊïàÁéáÂíåÈÅìË∑ØÂÆâÂÖ®Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂‰ΩøÁî®ÁúüÂØ¶‰∏ñÁïåÁöÑËªåË∑°Ë≥áÊñôÈõÜÔºåÊé°Áî®ÊèèËø∞ÊÄßÂíåÁµ±Ë®àÂàÜÊûê‰æÜÊé¢Ë®éÊ∑∑Âêà‰∫§ÈÄö‰∏≠‰∏âÁµÑËªäËºõÁµÑÂêàÁöÑË∑üËªäË°åÁÇ∫ÔºöHDV-AV„ÄÅAV-HDV Âíå HDV-HDV„ÄÇANOVA Ê™¢ÂÆöÈ°ØÁ§∫Ôºå‰∏çÂêåËªäËºõÁµÑÂêàÁöÑË∑üËªäË°åÁÇ∫Âú®Áµ±Ë®à‰∏äÂÖ∑ÊúâÈ°ØËëóÂ∑ÆÁï∞Ôºàp ÂÄº < 0.05Ôºâ„ÄÇ
  ÊàëÂÄëÈÇÑÂºïÂÖ•‰∏ÄÂÄãË≥áÊñôÈ©ÖÂãïÁöÑÁü•Ë≠òËí∏È§æÁ•ûÁ∂ìÁ∂≤Ë∑Ø (KDNN) Ê®°ÂûãÔºåÁî®ÊñºÈ†êÊ∏¨Ë∑üËªäË°åÁÇ∫ÁöÑÈÄüÂ∫¶„ÄÇKDNN Ê®°ÂûãÂ±ïÁèæÂá∫ËàáÂÖ∂ÊïôÂ∏´Á∂≤Ë∑ØÔºàÈï∑Áü≠ÊúüË®òÊÜ∂ (LSTM) Á∂≤Ë∑ØÔºâÁõ∏Áï∂ÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶Ôºå‰∏¶‰∏îÂÑ™ÊñºÁç®Á´ãÁöÑÂ≠∏ÁîüÁ∂≤Ë∑ØÔºàÂ§öÂ±§ÊÑüÁü•Âô® (MLP)ÔºâÂíåÂÇ≥Áµ±ÁöÑÂü∫ÊñºÁâ©ÁêÜÊ®°ÂûãÔºå‰æãÂ¶Ç Gipps Ê®°Âûã„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåKDNN Ê®°ÂûãËÉΩÊõ¥Â•ΩÂú∞Èò≤Ê≠¢Á¢∞ÊíûÔºå‰ª•ÊúÄÁü≠Á¢∞ÊíûÊôÇÈñì (TTC) ‰æÜË°°ÈáèÔºå‰∏¶‰∏îÈÅã‰ΩúÊôÇÊâÄÈúÄÁöÑÈÅãÁÆóËÉΩÂäõËºÉ‰ΩéÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÈúÄË¶ÅÈ´òÊïàÈÅãÁÆóÁöÑËá™ÂãïÈßïÈßõËªäËºõÊàñÈßïÈßõÊ®°Êì¨Âô®ÁöÑÁêÜÊÉ≥ÈÅ∏Êìá„ÄÇ

##### **Expectation vs. Reality: Towards Verification of Psychological Games**
2411.05599v1 by Marta Kwiatkowska, Gethin Norman, David Parker, Gabriel Santos

Game theory provides an effective way to model strategic interactions among
rational agents. In the context of formal verification, these ideas can be used
to produce guarantees on the correctness of multi-agent systems, with a diverse
range of applications from computer security to autonomous driving.
Psychological games (PGs) were developed as a way to model and analyse agents
with belief-dependent motivations, opening up the possibility to model how
human emotions can influence behaviour. In PGs, players' utilities depend not
only on what actually happens (which strategies players choose to adopt), but
also on what the players had expected to happen (their belief as to the
strategies that would be played). Despite receiving much attention in fields
such as economics and psychology, very little consideration has been given to
their applicability to problems in computer science, nor to practical
algorithms and tool support. In this paper, we start to bridge that gap,
proposing methods to solve PGs and implementing them within PRISM-games, a
formal verification tool for stochastic games. We discuss how to model these
games, highlight specific challenges for their analysis and illustrate the
usefulness of our approach on several case studies, including human behaviour
in traffic scenarios.

ÊëòË¶ÅÔºöÂçöÂºàËÆ∫Êèê‰æõ‰∫Ü‰∏ÄÁßçÊúâÊïàÁöÑÊñπÊ≥ïÊù•Âª∫Ê®°ÁêÜÊÄßÂçöÂºàËÄÖ‰πãÈó¥ÁöÑÁ≠ñÁï•‰∫íÂä®„ÄÇÂú®ÂΩ¢ÂºèÈ™åËØÅÁöÑËÉåÊôØ‰∏ãÔºåËøô‰∫õÊÉ≥Ê≥ïÂèØÁî®‰∫éÂØπÂ§öÂçöÂºàËÄÖÁ≥ªÁªüÁöÑÊ≠£Á°ÆÊÄßÊèê‰æõ‰øùËØÅÔºåÂÖ∂Â∫îÁî®ËåÉÂõ¥‰ªéËÆ°ÁÆóÊú∫ÂÆâÂÖ®Âà∞Ëá™Âä®È©æÈ©∂„ÄÇÂøÉÁêÜÂçöÂºà (PG) Ë¢´ÂºÄÂèë‰∏∫‰∏ÄÁßçÂª∫Ê®°ÂíåÂàÜÊûêÂÖ∑Êúâ‰ø°Âøµ‰æùËµñÂä®Êú∫ÂçöÂºàËÄÖÁöÑÊñπÂºèÔºåÂºÄËæü‰∫ÜÂØπ‰∫∫Á±ªÊÉÖÁª™Â¶Ç‰ΩïÂΩ±ÂìçË°å‰∏∫ËøõË°åÂª∫Ê®°ÁöÑÂèØËÉΩÊÄß„ÄÇÂú® PG ‰∏≠ÔºåÂçöÂºàËÄÖÁöÑÊïàÁî®‰∏ç‰ªÖÂèñÂÜ≥‰∫éÂÆûÈôÖÂèëÁîüÁöÑ‰∫ãÊÉÖÔºàÂçöÂºàËÄÖÈÄâÊã©ÈááÁî®ÁöÑÁ≠ñÁï•ÔºâÔºåËøòÂèñÂÜ≥‰∫éÂçöÂºàËÄÖÈ¢ÑÊúüÂèëÁîüÁöÑ‰∫ãÊÉÖÔºà‰ªñ‰ª¨ÂØπÂ∞ÜË¶ÅËøõË°åÁöÑÁ≠ñÁï•ÁöÑ‰ø°ÂøµÔºâ„ÄÇÂ∞ΩÁÆ°Âú®ÁªèÊµéÂ≠¶ÂíåÂøÉÁêÜÂ≠¶Á≠âÈ¢ÜÂüüÂèóÂà∞‰∫ÜÂπøÊ≥õÂÖ≥Ê≥®Ôºå‰ΩÜÂæàÂ∞ëÊúâ‰∫∫ËÄÉËôëÂÆÉ‰ª¨ÂØπËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÈóÆÈ¢òÁöÑÈÄÇÁî®ÊÄßÔºå‰πüÊ≤°ÊúâËÄÉËôëÂÆûÈôÖÁÆóÊ≥ïÂíåÂ∑•ÂÖ∑ÊîØÊåÅ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂºÄÂßãÂº•ÂêàËøô‰∏ÄÂ∑ÆË∑ùÔºåÊèêÂá∫‰∫ÜËß£ÂÜ≥ PG ÁöÑÊñπÊ≥ïÔºåÂπ∂Âú® PRISM-games ‰∏≠ÂÆûÁé∞‰∫ÜÂÆÉ‰ª¨ÔºåPRISM-games ÊòØÁî®‰∫éÈöèÊú∫ÂçöÂºàÁöÑÂΩ¢ÂºèÈ™åËØÅÂ∑•ÂÖ∑„ÄÇÊàë‰ª¨ËÆ®ËÆ∫Â¶Ç‰ΩïÂØπËøô‰∫õÂçöÂºàËøõË°åÂª∫Ê®°ÔºåÈáçÁÇπ‰ªãÁªç‰∫ÜÂàÜÊûêÂÆÉ‰ª¨Êó∂ÁöÑÂÖ∑‰ΩìÊåëÊàòÔºåÂπ∂ËØ¥Êòé‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Â§ö‰∏™Ê°à‰æãÁ†îÁ©∂‰∏≠ÁöÑÊúâÁî®ÊÄßÔºåÂåÖÊã¨‰∫§ÈÄöÂú∫ÊôØ‰∏≠ÁöÑ‰∫∫Á±ªË°å‰∏∫„ÄÇ

##### **Evaluating and Adapting Large Language Models to Represent Folktales in Low-Resource Languages**
2411.05593v1 by JA Meaney, Beatrice Alex, William Lamb

Folktales are a rich resource of knowledge about the society and culture of a
civilisation. Digital folklore research aims to use automated techniques to
better understand these folktales, and it relies on abstract representations of
the textual data. Although a number of large language models (LLMs) claim to be
able to represent low-resource langauges such as Irish and Gaelic, we present
two classification tasks to explore how useful these representations are, and
three adaptations to improve the performance of these models. We find that
adapting the models to work with longer sequences, and continuing pre-training
on the domain of folktales improves classification performance, although these
findings are tempered by the impressive performance of a baseline SVM with
non-contextual features.

ÊëòË¶ÅÔºöÊ∞ëÈñìÊïÖ‰∫ãÊòØÈóúÊñºÁ§æÊúÉÂíåÊñáÊòéÊñáÂåñÁöÑË±êÂØåÁü•Ë≠ò‰æÜÊ∫ê„ÄÇÊï∏‰ΩçÊ∞ëÈñìÂÇ≥Ë™™Á†îÁ©∂Êó®Âú®‰ΩøÁî®Ëá™ÂãïÂåñÊäÄË°ì‰æÜÊõ¥Â•ΩÂú∞ÁêÜËß£ÈÄô‰∫õÊ∞ëÈñìÊïÖ‰∫ãÔºå‰∏¶‰∏î‰æùË≥¥ÊñºÊñáÊú¨Ë≥áÊñôÁöÑÊäΩË±°Ë°®Á§∫„ÄÇÂÑòÁÆ°Ë®±Â§öÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÅ≤Á®±ËÉΩÂ§†Ë°®Á§∫‰ΩéË≥áÊ∫êË™ûË®ÄÔºå‰æãÂ¶ÇÊÑõÁàæËò≠Ë™ûÂíåËìãÁàæË™ûÔºå‰ΩÜÊàëÂÄëÊèêÂá∫ÂÖ©ÂÄãÂàÜÈ°û‰ªªÂãô‰æÜÊé¢Ë®éÈÄô‰∫õË°®Á§∫ÊúâÂ§öÈ∫ºÊúâÁî®Ôºå‰ª•Âèä‰∏âÁ®ÆÊîπÁ∑®ÊñπÂºè‰æÜÊîπÂñÑÈÄô‰∫õÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁôºÁèæÔºåË™øÊï¥Ê®°Âûã‰ª•‰ΩøÁî®ËºÉÈï∑ÁöÑÂ∫èÂàóÔºå‰∏¶ÁπºÁ∫åÂú®Ê∞ëÈñìÊïÖ‰∫ãÁöÑÈ†òÂüü‰∏≠ÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÔºåÂèØ‰ª•ÊîπÂñÑÂàÜÈ°ûÊïàËÉΩÔºåÂÑòÁÆ°ÈÄô‰∫õÁôºÁèæÂèóÂà∞ÂÖ∑ÊúâÈùû‰∏ä‰∏ãÊñáÁâπÂæµÁöÑÂü∫Ê∫ñ SVM ÁöÑÂá∫Ëâ≤ÊïàËÉΩÊâÄÂΩ±Èüø„ÄÇ

##### **Open-set object detection: towards unified problem formulation and benchmarking**
2411.05564v1 by Hejer Ammar, Nikita Kiselov, Guillaume Lapouge, Romaric Audigier

In real-world applications where confidence is key, like autonomous driving,
the accurate detection and appropriate handling of classes differing from those
used during training are crucial. Despite the proposal of various unknown
object detection approaches, we have observed widespread inconsistencies among
them regarding the datasets, metrics, and scenarios used, alongside a notable
absence of a clear definition for unknown objects, which hampers meaningful
evaluation. To counter these issues, we introduce two benchmarks: a unified
VOC-COCO evaluation, and the new OpenImagesRoad benchmark which provides clear
hierarchical object definition besides new evaluation metrics. Complementing
the benchmark, we exploit recent self-supervised Vision Transformers
performance, to improve pseudo-labeling-based OpenSet Object Detection (OSOD),
through OW-DETR++. State-of-the-art methods are extensively evaluated on the
proposed benchmarks. This study provides a clear problem definition, ensures
consistent evaluations, and draws new conclusions about effectiveness of OSOD
strategies.

ÊëòË¶ÅÔºöÂú®‰ª•‰ø°ÂøÉÁÇ∫ÈóúÈçµÁöÑÂØ¶ÈöõÊáâÁî®‰∏≠Ôºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõÔºå
Ê∫ñÁ¢∫Ê™¢Ê∏¨ÂíåÈÅ©Áï∂ËôïÁêÜËàáË®ìÁ∑¥ÊúüÈñì‰ΩøÁî®ÁöÑÈ°ûÂà•‰∏çÂêåÁöÑÈ°ûÂà•Ëá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°ÊèêÂá∫‰∫ÜÂêÑÁ®ÆÊú™Áü•Â∞çË±°Ê™¢Ê∏¨ÊñπÊ≥ïÔºå
ÊàëÂÄëËßÄÂØüÂà∞ÂÆÉÂÄëÂú®ÊâÄ‰ΩøÁî®ÁöÑÊï∏ÊìöÈõÜ„ÄÅÊåáÊ®ôÂíåÂ†¥ÊôØÊñπÈù¢Â≠òÂú®Âª£Ê≥õÁöÑ‰∏ç‰∏ÄËá¥ÔºåÂêåÊôÇÈÇÑÊòéÈ°ØÁº∫‰πèÂ∞çÊú™Áü•Â∞çË±°ÁöÑÊòéÁ¢∫ÂÆöÁæ©ÔºåÈÄôÈòªÁ§ô‰∫ÜÊúâÊÑèÁæ©ÁöÑ
Ë©ï‰º∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©ÂÄãÂü∫Ê∫ñÔºöÁµ±‰∏ÄÁöÑ VOC-COCO Ë©ï‰º∞Ôºå‰ª•ÂèäÊñ∞ÁöÑ OpenImagesRoad Âü∫Ê∫ñÔºåÈô§‰∫ÜÊñ∞ÁöÑË©ï‰º∞ÊåáÊ®ôÂ§ñÔºåÈÇÑÊèê‰æõ‰∫ÜÊ∏ÖÊô∞ÁöÑÂàÜÂ±§Â∞çË±°ÂÆöÁæ©„ÄÇË£úÂÖÖ
Âü∫Ê∫ñÔºåÊàëÂÄëÂà©Áî®ÊúÄËøëÁöÑËá™Áõ£Áù£Ë¶ñË¶∫Transformer
ÊÄßËÉΩÔºåÈÄöÈÅé OW-DETR++ ÊîπÈÄ≤Âü∫ÊñºÂÅΩÊ®ôÁ±§ÁöÑÈñãÊîæÈõÜÂ∞çË±°Ê™¢Ê∏¨ (OSOD)„ÄÇÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÂú®
ÊèêÂá∫ÁöÑÂü∫Ê∫ñ‰∏äÂæóÂà∞‰∫ÜÂª£Ê≥õË©ï‰º∞„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊòéÁ¢∫ÁöÑÂïèÈ°åÂÆöÁæ©ÔºåÁ¢∫‰øù
‰∏ÄËá¥ÁöÑË©ï‰º∞Ôºå‰∏¶Â∞ç OSOD
Á≠ñÁï•ÁöÑÊúâÊïàÊÄßÂæóÂá∫Êñ∞ÁöÑÁµêË´ñ„ÄÇ

##### **Training objective drives the consistency of representational similarity across datasets**
2411.05561v1 by Laure Ciernik, Lorenz Linhardt, Marco Morik, Jonas Dippel, Simon Kornblith, Lukas Muttenthaler

The Platonic Representation Hypothesis claims that recent foundation models
are converging to a shared representation space as a function of their
downstream task performance, irrespective of the objectives and data modalities
used to train these models. Representational similarity is generally measured
for individual datasets and is not necessarily consistent across datasets.
Thus, one may wonder whether this convergence of model representations is
confounded by the datasets commonly used in machine learning. Here, we propose
a systematic way to measure how representational similarity between models
varies with the set of stimuli used to construct the representations. We find
that the objective function is the most crucial factor in determining the
consistency of representational similarities across datasets. Specifically,
self-supervised vision models learn representations whose relative pairwise
similarities generalize better from one dataset to another compared to those of
image classification or image-text models. Moreover, the correspondence between
representational similarities and the models' task behavior is
dataset-dependent, being most strongly pronounced for single-domain datasets.
Our work provides a framework for systematically measuring similarities of
model representations across datasets and linking those similarities to
differences in task behavior.

ÊëòË¶ÅÔºöÊüèÊãâÂúñË°®ÂæµÂÅáË™™ËÅ≤Á®±ÔºåÊúÄËøëÁöÑÂü∫Á§éÊ®°ÂûãÊ≠£Âú®Êî∂ÊñÇÂà∞‰∏ÄÂÄãÂÖ±Áî®Ë°®ÂæµÁ©∫ÈñìÔºå‰ΩúÁÇ∫ÂÖ∂‰∏ãÊ∏∏‰ªªÂãôË°®ÁèæÁöÑÂáΩÊï∏ÔºåËÄåËàáÁî®ÊñºË®ìÁ∑¥ÈÄô‰∫õÊ®°ÂûãÁöÑÁõÆÊ®ôÂíåË≥áÊñôÊ®°ÂºèÁÑ°Èóú„ÄÇË°®ÂæµÁõ∏‰ººÊÄßÈÄöÂ∏∏ÈáùÂ∞çÂÄãÂà•Ë≥áÊñôÈõÜÈÄ≤Ë°åÊ∏¨ÈáèÔºå‰∏¶‰∏ç‰∏ÄÂÆöÂú®ÊâÄÊúâË≥áÊñôÈõÜ‰πãÈñì‰øùÊåÅ‰∏ÄËá¥„ÄÇÂõ†Ê≠§Ôºå‰∫∫ÂÄëÂèØËÉΩÊúÉÊá∑ÁñëÊ®°ÂûãË°®ÂæµÁöÑÈÄôÁ®ÆÊî∂ÊñÇÊòØÂê¶ÂèóÂà∞Ê©üÂô®Â≠∏Áøí‰∏≠Â∏∏Áî®ÁöÑË≥áÊñôÈõÜÁöÑÊ∑∑Ê∑Ü„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ≥ªÁµ±ÊÄßÁöÑÊñπÊ≥ï‰æÜÊ∏¨ÈáèÊ®°Âûã‰πãÈñìÁöÑË°®ÂæµÁõ∏‰ººÊÄßÂ¶Ç‰ΩïÈö®Áî®ÊñºÂª∫ÊßãË°®ÂæµÁöÑÂà∫ÊøÄÈõÜËÄåËÆäÂåñ„ÄÇÊàëÂÄëÁôºÁèæÔºåÁõÆÊ®ôÂáΩÊï∏ÊòØÊ±∫ÂÆöË°®ÂæµÁõ∏‰ººÊÄßÂú®‰∏çÂêåË≥áÊñôÈõÜ‰πãÈñì‰∏ÄËá¥ÊÄßÁöÑÊúÄÈáçË¶ÅÂõ†Á¥†„ÄÇÂÖ∑È´î‰æÜË™™ÔºåËá™Áõ£Áù£Ë¶ñË¶∫Ê®°ÂûãÂ≠∏ÁøíÁöÑË°®ÂæµÂÖ∑ÊúâÁõ∏Â∞çÊàêÂ∞çÁõ∏‰ººÊÄßÔºåËàáÂΩ±ÂÉèÂàÜÈ°ûÊàñÂΩ±ÂÉèÊñáÂ≠óÊ®°ÂûãÁõ∏ÊØîÔºåÈÄô‰∫õÁõ∏‰ººÊÄßÂæû‰∏ÄÂÄãË≥áÊñôÈõÜÂà∞Âè¶‰∏ÄÂÄãË≥áÊñôÈõÜÁöÑÊ¶ÇÂåñÊÄßÊõ¥Â•Ω„ÄÇÊ≠§Â§ñÔºåË°®ÂæµÁõ∏‰ººÊÄßËàáÊ®°ÂûãÁöÑ‰ªªÂãôË°åÁÇ∫‰πãÈñìÁöÑÂ∞çÊáâÈóú‰øÇÂèñÊ±∫ÊñºË≥áÊñôÈõÜÔºåÂ∞çÊñºÂñÆ‰∏ÄÈ†òÂüüË≥áÊñôÈõÜ‰æÜË™™ÔºåÈÄôÁ®ÆÂ∞çÊáâÈóú‰øÇÊúÄÁÇ∫È°ØËëó„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±ÊÄßÊ∏¨ÈáèÊ®°ÂûãË°®ÂæµÂú®‰∏çÂêåË≥áÊñôÈõÜ‰πãÈñìÁõ∏‰ººÊÄßÁöÑÊ°ÜÊû∂Ôºå‰∏¶Â∞áÈÄô‰∫õÁõ∏‰ººÊÄßËàá‰ªªÂãôË°åÁÇ∫ÁöÑÂ∑ÆÁï∞ËÅØÁπ´Ëµ∑‰æÜ„ÄÇ

##### **Assessing the Answerability of Queries in Retrieval-Augmented Code Generation**
2411.05547v1 by Geonmin Kim, Jaeyeon Kim, Hancheol Park, Wooksu Shin, Tae-Ho Kim

Thanks to unprecedented language understanding and generation capabilities of
large language model (LLM), Retrieval-augmented Code Generation (RaCG) has
recently been widely utilized among software developers. While this has
increased productivity, there are still frequent instances of incorrect codes
being provided. In particular, there are cases where plausible yet incorrect
codes are generated for queries from users that cannot be answered with the
given queries and API descriptions. This study proposes a task for evaluating
answerability, which assesses whether valid answers can be generated based on
users' queries and retrieved APIs in RaCG. Additionally, we build a benchmark
dataset called Retrieval-augmented Code Generability Evaluation (RaCGEval) to
evaluate the performance of models performing this task. Experimental results
show that this task remains at a very challenging level, with baseline models
exhibiting a low performance of 46.7%. Furthermore, this study discusses
methods that could significantly improve performance.

ÊëòË¶ÅÔºöÁî±ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂâçÊâÄÊú™ÊúâÁöÑË™ûË®ÄÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõÔºåÊ™¢Á¥¢Â¢ûÂº∑ÂºèÁ®ãÂºèÁ¢ºÁîüÊàê (RaCG) Ëøë‰æÜÂú®ËªüÈ´îÈñãÁôº‰∫∫Âì°‰πãÈñìÂª£Ê≥õ‰ΩøÁî®„ÄÇÈõñÁÑ∂ÈÄôÊèêÈ´ò‰∫ÜÁîüÁî¢ÂäõÔºå‰ΩÜ‰ªçÁ∂ìÂ∏∏Êèê‰æõ‰∏çÊ≠£Á¢∫ÁöÑÁ®ãÂºèÁ¢º„ÄÇÁâπÂà•ÊòØÔºåÂ∞çÊñºÁÑ°Ê≥ï‰ΩøÁî®Áµ¶ÂÆöÁöÑÊü•Ë©¢Âíå API ÊèèËø∞‰æÜÂõûÁ≠îÁöÑ‰ΩøÁî®ËÄÖÊü•Ë©¢ÔºåÂèØËÉΩÊúÉÁî¢ÁîüÁúã‰ººÂêàÁêÜ‰ΩÜÂØ¶Èöõ‰∏ä‰∏çÊ≠£Á¢∫ÁöÑÁ®ãÂºèÁ¢º„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖË©ï‰º∞ÂèØÂõûÁ≠îÊÄßÁöÑ‰ªªÂãôÔºåË©≤‰ªªÂãôË©ï‰º∞ÊòØÂê¶ÂèØ‰ª•Ê†πÊìö‰ΩøÁî®ËÄÖÁöÑÊü•Ë©¢Âíå RaCG ‰∏≠Ê™¢Á¥¢ÁöÑ API Áî¢ÁîüÊúâÊïàÁöÑÁ≠îÊ°à„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ê™¢Á¥¢Â¢ûÂº∑ÂºèÁ®ãÂºèÁ¢ºÂèØÁîüÊàêÊÄßË©ï‰º∞ (RaCGEval) ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜÔºå‰ª•Ë©ï‰º∞Âü∑Ë°åÊ≠§‰ªªÂãôÁöÑÊ®°ÂûãÊïàËÉΩ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊ≠§‰ªªÂãô‰ªçËôïÊñºÈùûÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂ±§Á¥öÔºåÂü∫Ê∫ñÊ®°ÂûãË°®ÁèæÂá∫ 46.7% ÁöÑ‰ΩéÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂèØ‰ª•È°ØËëóÊèêÂçáÊïàËÉΩÁöÑÊñπÊ≥ï„ÄÇ

##### **CRepair: CVAE-based Automatic Vulnerability Repair Technology**
2411.05540v1 by Penghui Liu, Yingzhou Bi, Jiangtao Huang, Xinxin Jiang, Lianmei Wang

Software vulnerabilities are flaws in computer software systems that pose
significant threats to the integrity, security, and reliability of modern
software and its application data. These vulnerabilities can lead to
substantial economic losses across various industries. Manual vulnerability
repair is not only time-consuming but also prone to errors. To address the
challenges of vulnerability repair, researchers have proposed various
solutions, with learning-based automatic vulnerability repair techniques
gaining widespread attention. However, existing methods often focus on learning
more vulnerability data to improve repair outcomes, while neglecting the
diverse characteristics of vulnerable code, and suffer from imprecise
vulnerability localization.To address these shortcomings, this paper proposes
CRepair, a CVAE-based automatic vulnerability repair technology aimed at fixing
security vulnerabilities in system code. We first preprocess the vulnerability
data using a prompt-based method to serve as input to the model. Then, we apply
causal inference techniques to map the vulnerability feature data to
probability distributions. By employing multi-sample feature fusion, we capture
diverse vulnerability feature information. Finally, conditional control is used
to guide the model in repairing the vulnerabilities.Experimental results
demonstrate that the proposed method significantly outperforms other benchmark
models, achieving a perfect repair rate of 52%. The effectiveness of the
approach is validated from multiple perspectives, advancing AI-driven code
vulnerability repair and showing promising applications.

ÊëòË¶ÅÔºöËªüÈ´îÊºèÊ¥ûÊòØÈõªËÖ¶ËªüÈ´îÁ≥ªÁµ±‰∏≠ÁöÑÁº∫Èô∑ÔºåÂ∞çÁèæ‰ª£ËªüÈ´îÂèäÂÖ∂ÊáâÁî®Á®ãÂºèË≥áÊñôÁöÑÂÆåÊï¥ÊÄß„ÄÅÂÆâÂÖ®ÊÄßËàáÂèØÈù†ÊÄßÊßãÊàêÈáçÂ§ßÂ®ÅËÑÖ„ÄÇÈÄô‰∫õÊºèÊ¥ûÂèØËÉΩÂ∞éËá¥ÂêÑÁî¢Ê•≠Áî¢ÁîüÈæêÂ§ßÁöÑÁ∂ìÊøüÊêçÂ§±„ÄÇÊâãÂãï‰øÆÂæ©ÊºèÊ¥û‰∏çÂÉÖËÄóÊôÇÔºåÈÇÑÂÆπÊòìÂá∫ÈåØ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊºèÊ¥û‰øÆÂæ©ÁöÑÊåëÊà∞ÔºåÁ†îÁ©∂‰∫∫Âì°ÊèêÂá∫‰∫ÜÂêÑÁ®ÆËß£Ê±∫ÊñπÊ°àÔºåÂÖ∂‰∏≠Âü∫ÊñºÂ≠∏ÁøíÁöÑËá™ÂãïÊºèÊ¥û‰øÆÂæ©ÊäÄË°ìÁç≤ÂæóÂª£Ê≥õÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞àÊ≥®ÊñºÂ≠∏ÁøíÊõ¥Â§öÊºèÊ¥ûË≥áÊñô‰ª•ÊîπÂñÑ‰øÆÂæ©ÁµêÊûúÔºåÂêåÊôÇÂøΩÁï•‰∫ÜÊòìÂèóÊîªÊìäÁ®ãÂºèÁ¢ºÁöÑÂ§öÊ®£ÂåñÁâπÊÄßÔºå‰∏¶ÈÅ≠Âèó‰∏çÁ≤æÁ¢∫ÁöÑÊºèÊ¥ûÂÆö‰Ωç„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÁº∫ÈªûÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü CRepairÔºå‰∏ÄÁ®ÆÂü∫Êñº CVAE ÁöÑËá™ÂãïÊºèÊ¥û‰øÆÂæ©ÊäÄË°ìÔºåÊó®Âú®‰øÆÂæ©Á≥ªÁµ±Á®ãÂºèÁ¢º‰∏≠ÁöÑÂÆâÂÖ®ÊºèÊ¥û„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®Âü∫ÊñºÊèêÁ§∫ÁöÑÊñπÊ≥ïÈ†êËôïÁêÜÊºèÊ¥ûË≥áÊñôÔºå‰ΩúÁÇ∫Ê®°ÂûãÁöÑËº∏ÂÖ•„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊáâÁî®Âõ†ÊûúÊé®Ë´ñÊäÄË°ìÂ∞áÊºèÊ¥ûÁâπÂæµË≥áÊñôÂ∞çÊáâÂà∞Ê©üÁéáÂàÜ‰Ωà„ÄÇÈÄèÈÅéÊé°Áî®Â§öÊ®£Êú¨ÁâπÂæµËûçÂêàÔºåÊàëÂÄëÊì∑ÂèñÂ§öÊ®£ÂåñÁöÑÊºèÊ¥ûÁâπÂæµË≥áË®ä„ÄÇÊúÄÂæåÔºå‰ΩøÁî®Ê¢ù‰ª∂ÊéßÂà∂‰æÜÂºïÂ∞éÊ®°Âûã‰øÆÂæ©ÊºèÊ¥û„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊòéÈ°ØÂÑ™ÊñºÂÖ∂‰ªñÂü∫Ê∫ñÊ®°ÂûãÔºåÈÅîÂà∞ 52% ÁöÑÂÆåÁæé‰øÆÂæ©Áéá„ÄÇÂæûÂ§öÂÄãËßíÂ∫¶È©óË≠â‰∫ÜË©≤ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÊé®Âãï‰∫Ü AI È©ÖÂãïÁöÑÁ®ãÂºèÁ¢ºÊºèÊ¥û‰øÆÂæ©Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÊúâÂâçÊôØÁöÑÊáâÁî®„ÄÇ

##### **How Good is Your Wikipedia?**
2411.05527v1 by Kushal Tatariya, Artur Kulmizev, Wessel Poelman, Esther Ploeger, Marcel Bollmann, Johannes Bjerva, Jiaming Luo, Heather Lent, Miryam de Lhoneux

Wikipedia's perceived high quality and broad language coverage have
established it as a fundamental resource in multilingual NLP. In the context of
low-resource languages, however, these quality assumptions are increasingly
being scrutinised. This paper critically examines the data quality of Wikipedia
in a non-English setting by subjecting it to various quality filtering
techniques, revealing widespread issues such as a high percentage of one-line
articles and duplicate articles. We evaluate the downstream impact of quality
filtering on Wikipedia and find that data quality pruning is an effective means
for resource-efficient training without hurting performance, especially for
low-resource languages. Moreover, we advocate for a shift in perspective from
seeking a general definition of data quality towards a more language- and
task-specific one. Ultimately, we aim for this study to serve as a guide to
using Wikipedia for pretraining in a multilingual setting.

ÊëòË¶ÅÔºöÁ∂≠Âü∫ÁôæÁßëË¢´Ë™çÁÇ∫ÂÖ∑ÊúâÈ´òÂìÅË≥™ÂíåÂª£Ê≥õÁöÑË™ûË®ÄÊ∂µËìãÁØÑÂúçÔºåÈÄô‰ΩøÂÖ∂ÊàêÁÇ∫Â§öË™ûË®ÄËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÁöÑÂü∫Êú¨Ë≥áÊ∫ê„ÄÇÁÑ∂ËÄåÔºåÂú®Ë≥áÊ∫êÂå±‰πèÁöÑË™ûË®ÄËÉåÊôØ‰∏ãÔºåÈÄô‰∫õÂìÅË≥™ÂÅáË®≠Ê≠£ÂèóÂà∞Ë∂ä‰æÜË∂äÂ§öÁöÑÂØ©Êü•„ÄÇÊú¨ÊñáÈÄöÈÅéÂ∞çÁ∂≠Âü∫ÁôæÁßëÈÄ≤Ë°åÂêÑÁ®ÆÂìÅË≥™ÈÅéÊøæÊäÄË°ìÔºåÊâπÂà§ÊÄßÂú∞Ê™¢Ë¶ñ‰∫ÜÂÖ∂Âú®ÈùûËã±Ë™ûÁí∞Â¢É‰∏≠ÁöÑË≥áÊñôÂìÅË≥™ÔºåÊè≠Á§∫‰∫ÜÊôÆÈÅçÂ≠òÂú®ÁöÑÂïèÈ°åÔºå‰æãÂ¶ÇÂñÆË°åÊñáÁ´†ÂíåÈáçË§áÊñáÁ´†ÁöÑÊØî‰æãÂæàÈ´ò„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂìÅË≥™ÈÅéÊøæÂ∞çÁ∂≠Âü∫ÁôæÁßëÁöÑÂæåÁ∫åÂΩ±ÈüøÔºåÁôºÁèæË≥áÊñôÂìÅË≥™‰øÆÂâ™ÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑÊâãÊÆµÔºåÂèØ‰ª•Âú®‰∏çÊêçÂÆ≥ÊïàËÉΩÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åË≥áÊ∫êÊúâÊïàÁéáÁöÑË®ìÁ∑¥ÔºåÁâπÂà•ÊòØÂ∞çÊñºË≥áÊ∫êÂå±‰πèÁöÑË™ûË®Ä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰∏ªÂºµÂæûÂ∞ãÊ±ÇË≥áÊñôÂìÅË≥™ÁöÑÈÄöÁî®ÂÆöÁæ©ËΩâÂêëÊõ¥ÂÖ∑Ë™ûË®ÄÂíå‰ªªÂãôÁâπÊÄßÁöÑÂÆöÁæ©„ÄÇÊúÄÁµÇÔºåÊàëÂÄëÁöÑÁõÆÊ®ôÊòØËÆìÈÄôÈ†ÖÁ†îÁ©∂ÊàêÁÇ∫Âú®Â§öË™ûË®ÄÁí∞Â¢É‰∏≠‰ΩøÁî®Á∂≠Âü∫ÁôæÁßëÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÁöÑÊåáÂçó„ÄÇ

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v1 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ÂÑ≤Â≠òÂú®ÂêÑÁ®ÆË≥áÊñôÂ∫´Á≥ªÁµ±‰∏≠ÔºåÈÄô‰∫õÁ≥ªÁµ±Âú®Áï∞Ë≥™ÂÑ≤Â≠òÊû∂Êßã‰∏äÂÖ∑Êúâ‰∏çÂêåÁöÑË≥áÊñôÂ∫´Ê®°ÂûãÔºå‰æãÂ¶ÇÈóúËÅØÂºèË≥áÊñôÂ∫´„ÄÅÊñá‰ª∂ÂÑ≤Â≠òÊàñÂúñÂΩ¢Ë≥áÊñôÂ∫´„ÄÇÈÄô‰∫õ‰∏çÂêåÁöÑË≥áÊñôÂ∫´Ê®°ÂûãÂ∞çÊü•Ë©¢Ë§áÈõúÂ∫¶ÂíåÊïàËÉΩÊúâÂæàÂ§ßÁöÑÂΩ±Èüø„ÄÇÈõñÁÑ∂ÈÄôÂú®Ë≥áÊñôÂ∫´Á†îÁ©∂‰∏≠Â∑≤Á∂ìÊòØÁúæÊâÄÂë®Áü•ÁöÑ‰∫ãÂØ¶Ôºå‰ΩÜ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÂÆÉÂ∞çÊó•ÁõäÂ¢ûÂä†ÁöÑÊñáÂ≠óËΩâÊü•Ë©¢Á≥ªÁµ±ÁöÑÂΩ±ÈüøËøÑ‰ªäÂ∞öÊú™ÂæóÂà∞Ë™øÊü•„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ SM3-Text-to-QueryÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂü∫Êñº‰æÜËá™ Synthea ÁöÑÂêàÊàêÊÇ£ËÄÖË≥áÊñôÁöÑÂ§öÊ®°ÂûãÈÜ´ÁôÇÊñáÂ≠óËΩâÊü•Ë©¢Âü∫Ê∫ñÔºåÈÅµÂæ™ SNOMED-CT ÂàÜÈ°ûÊ≥ï‚Äî‚Äî‰∏ÄÁ®ÆÂª£Ê≥õ‰ΩøÁî®ÁöÑÊ∂µËìãÈÜ´Â≠∏Ë°ìË™ûÁöÑÁü•Ë≠òÂúñË≠úÊú¨È´î„ÄÇSM3-Text-to-Query Êèê‰æõ‰∫ÜÈóúËÅØÂºèË≥áÊñôÂ∫´ (PostgreSQL)„ÄÅÊñá‰ª∂ÂÑ≤Â≠ò (MongoDB) ÂíåÂúñÂΩ¢Ë≥áÊñôÂ∫´ (Neo4j Âíå GraphDB (RDF)) ÁöÑË≥áÊñôË°®Á§∫ÔºåÂÖÅË®±Ë∑®ÂõõÁ®ÆÊµÅË°åÊü•Ë©¢Ë™ûË®ÄÔºàÂç≥ SQL„ÄÅMQL„ÄÅCypher Âíå SPARQLÔºâÈÄ≤Ë°åË©ï‰º∞„ÄÇÊàëÂÄëÁ≥ªÁµ±‰∏îÊâãÂãïÈñãÁôº‰∫Ü 408 ÂÄãÁØÑÊú¨ÂïèÈ°åÔºåÊàëÂÄëÊì¥ÂÖÖÈÄô‰∫õÂïèÈ°å‰ª•ÊßãÂª∫‰∏ÄÂÄãÂü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ 10K ÂÄãÈáùÂ∞çÈÄôÂõõÁ®ÆÊü•Ë©¢Ë™ûË®ÄÁöÑÂ§öÊ®£ÂåñËá™ÁÑ∂Ë™ûË®ÄÂïèÈ°å/Êü•Ë©¢Â∞çÔºàÁ∏ΩÂÖ± 40K Â∞çÔºâ„ÄÇÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÂπæÁ®ÆÂ∏∏Ë¶ãÁöÑ‰ª£Ë°®ÊÄßÈñâÊ∫êÂíåÈñãÊ∫ê LLM ÁöÑÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑË©ï‰º∞Êè≠Á§∫‰∫Ü‰∏çÂêå ICL Á≠ñÁï•Âíå LLM ÁöÑË≥áÊñôÂ∫´Ê®°ÂûãÂíåÊü•Ë©¢Ë™ûË®Ä‰πãÈñìÁöÑÂèñÊç®„ÄÇÊúÄÂæåÔºåSM3-Text-to-Query ÂèØ‰ª•ËºïÈ¨ÜÊì¥Â±ïÂà∞ÂÖ∂‰ªñÊü•Ë©¢Ë™ûË®ÄÊàñÁúüÂØ¶ÁöÑÂü∫ÊñºÊ®ôÊ∫ñÁöÑÊÇ£ËÄÖË≥áÊñôÂ∫´„ÄÇ

##### **Towards Scalable Foundation Models for Digital Dermatology**
2411.05514v1 by Fabian Gr√∂ger, Philippe Gottfrois, Ludovic Amruthalingam, Alvaro Gonzalez-Jimenez, Simone Lionetti, Luis R. Soenksen-Martinez, Alexander A. Navarini, Marc Pouly

The growing demand for accurate and equitable AI models in digital
dermatology faces a significant challenge: the lack of diverse, high-quality
labeled data. In this work, we investigate the potential of domain-specific
foundation models for dermatology in addressing this challenge. We utilize
self-supervised learning (SSL) techniques to pre-train models on a dataset of
over 240,000 dermatological images from public and private collections. Our
study considers several SSL methods and compares the resulting foundation
models against domain-agnostic models like those pre-trained on ImageNet and
state-of-the-art models such as MONET across 12 downstream tasks. Unlike
previous research, we emphasize the development of smaller models that are more
suitable for resource-limited clinical settings, facilitating easier adaptation
to a broad range of use cases. Results show that models pre-trained in this
work not only outperform general-purpose models but also approach the
performance of models 50 times larger on clinically relevant diagnostic tasks.
To promote further research in this direction, we publicly release both the
training code and the foundation models, which can benefit clinicians in
dermatological applications.

ÊëòË¶ÅÔºöÊï∏‰ΩçÁöÆËÜöÁßëÂ∞çÁ≤æÊ∫ñ‰∏îÂÖ¨Âπ≥ÁöÑ AI Ê®°ÂûãÈúÄÊ±ÇÊó•ÁõäÂ¢ûÂä†Ôºå‰ΩÜÈù¢Ëá®‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞ÔºöÁº∫‰πèÂ§öÂÖÉ‰∏îÈ´òÂìÅË≥™ÁöÑÊ®ôË®òË≥áÊñô„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÁâπÂÆöÈ†òÂüüÁöÑÂü∫Á§éÊ®°ÂûãÂú®ÁöÆËÜöÁßë‰∏≠Ëß£Ê±∫Ê≠§ÊåëÊà∞ÁöÑÂèØËÉΩÊÄß„ÄÇÊàëÂÄëÂà©Áî®Ëá™Áõ£Áù£Â≠∏Áøí (SSL) ÊäÄË°ìÂú®ÂåÖÂê´Ë∂ÖÈÅé 24 Ëê¨Âºµ‰æÜËá™ÂÖ¨ÊúâÂíåÁßÅÊúâË≥áÊñôÂ∫´ÁöÑÁöÆËÜöÁßëÂΩ±ÂÉèÁöÑË≥áÊñôÈõÜ‰∏äÈ†êÂÖàË®ìÁ∑¥Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ËÄÉÈáè‰∫ÜÂ§öÁ®Æ SSL ÊñπÊ≥ïÔºå‰∏¶Â∞áÁî¢ÁîüÁöÑÂü∫Á§éÊ®°ÂûãËàá‰∏çÂèóÈ†òÂüüÈôêÂà∂ÁöÑÊ®°ÂûãÔºà‰æãÂ¶ÇÂú® ImageNet ‰∏äÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºâ‰ª•ÂèäÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºà‰æãÂ¶Ç MONETÔºâÂú® 12 ÂÄã‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÈÄ≤Ë°åÊØîËºÉ„ÄÇËàáÂÖàÂâçÁöÑÁ†îÁ©∂‰∏çÂêåÔºåÊàëÂÄëÂº∑Ë™øÈñãÁôºÊõ¥ÈÅ©ÂêàË≥áÊ∫êÊúâÈôêÁöÑËá®Â∫äÁí∞Â¢ÉÁöÑÂ∞èÂûãÊ®°ÂûãÔºå‰ª•Âà©ÊñºÊõ¥ËºïÈ¨ÜÂú∞ÈÅ©ÊáâÂª£Ê≥õÁöÑÁî®‰æã„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°Âûã‰∏çÂÉÖÂÑ™ÊñºÈÄöÁî®Ê®°ÂûãÔºåËÄå‰∏îÂú®Ëá®Â∫ä‰∏äÁõ∏ÈóúÁöÑË®∫Êñ∑‰ªªÂãô‰∏≠ÔºåÂÖ∂ÊïàËÉΩ‰πüÊé•ËøëÂ§ß 50 ÂÄçÁöÑÊ®°Âûã„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Ê≠§ÊñπÂêëÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÔºåÊàëÂÄëÂÖ¨ÈñãÁôºÂ∏ÉË®ìÁ∑¥Á®ãÂºèÁ¢ºÂíåÂü∫Á§éÊ®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãÂèØËÆìÁöÆËÜöÁßëÊáâÁî®‰∏≠ÁöÑËá®Â∫äÈÜ´ÁîüÂèóÁõä„ÄÇ

##### **An Early FIRST Reproduction and Improvements to Single-Token Decoding for Fast Listwise Reranking**
2411.05508v1 by Zijian Chen, Ronak Pradeep, Jimmy Lin

Recent advances have demonstrated that large language models (LLMs) excel as
listwise rerankers, but their high computational demands remain a barrier to
widespread adoption. Further, the traditional language modeling (LM) objective
is not ideally suited for reranking tasks. FIRST is a novel approach that
addresses these challenges by integrating a learning-to-rank objective and
leveraging the logits of only the first generated token, thereby significantly
reducing inference latency compared to traditional LLM rerankers. In this
study, we extend the evaluation of FIRST to the TREC Deep Learning datasets
(DL19-22), validating its robustness across diverse domains. We investigate the
influence of different first-stage retrievers on FIRST rerankers, observing
diminishing returns and patterns consistent with traditional LLM rerankers.
Through applying the FIRST objective to a broader range of backbone models, we
achieve effectiveness surpassing the original implementation. Our experiments
confirm that fast reranking with single-token logits does not compromise
out-of-domain reranking quality. To better quantify the computational savings
in the original study, we measure and compare latency to find a 21%-42% gain
across various models and benchmarks. Moreover, while LM training implicitly
improves zero-shot single-token reranking, our experiments also raise questions
about whether LM pre-training may hinder subsequent fine-tuning with the FIRST
objective. These findings pave the way for more efficient and effective
listwise reranking in future applications.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÁöÑÈÄ≤Â±ïË°®ÊòéÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂàóË°®ÂºèÈáçÊñ∞ÊéíÂ∫èÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂÆÉÂÄëÁöÑÈ´òÈÅãÁÆóÈúÄÊ±Ç‰ªçÁÑ∂ÊòØÂª£Ê≥õÊé°Áî®ÁöÑÈöúÁ§ô„ÄÇÊ≠§Â§ñÔºåÂÇ≥Áµ±ÁöÑË™ûË®ÄÂª∫Ê®° (LM) ÁõÆÊ®ô‰∏¶‰∏çÈÅ©ÂêàÈáçÊñ∞ÊéíÂ∫è‰ªªÂãô„ÄÇFIRST ÊòØ‰∏ÄÈ†ÖÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂÆÉÈÄöÈÅéÊï¥ÂêàÂ≠∏ÁøíÊéíÂêçÁõÆÊ®ô‰∏¶ÂÉÖÂà©Áî®Á¨¨‰∏ÄÂÄãÁîüÊàêÁ¨¶ËôüÁöÑ logit ‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÂæûËÄåËàáÂÇ≥Áµ±ÁöÑ LLM ÈáçÊñ∞ÊéíÂ∫èÂô®Áõ∏ÊØîÈ°ØËëóÈôç‰Ωé‰∫ÜÊé®ÁêÜÂª∂ÈÅ≤„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞á FIRST ÁöÑË©ï‰º∞Êì¥Â±ïÂà∞ TREC Ê∑±Â∫¶Â≠∏ÁøíÊï∏ÊìöÈõÜ (DL19-22)ÔºåÈ©óË≠â‰∫ÜÂÆÉÂú®‰∏çÂêåÈ†òÂüüÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁ†îÁ©∂‰∫Ü‰∏çÂêåÁ¨¨‰∏ÄÈöéÊÆµÊ™¢Á¥¢Âô®Â∞ç FIRST ÈáçÊñ∞ÊéíÂ∫èÂô®ÁöÑÂΩ±ÈüøÔºåËßÄÂØüÂà∞ËàáÂÇ≥Áµ± LLM ÈáçÊñ∞ÊéíÂ∫èÂô®‰∏ÄËá¥ÁöÑÈÅûÊ∏õÂõûÂ†±ÂíåÊ®°Âºè„ÄÇÈÄöÈÅéÂ∞á FIRST ÁõÆÊ®ôÊáâÁî®ÊñºÊõ¥Âª£Ê≥õÁöÑ‰∏ªÂππÊ®°ÂûãÔºåÊàëÂÄëÂØ¶Áèæ‰∫ÜË∂ÖË∂äÂéüÂßãÂØ¶ÁèæÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÂØ¶Ôºå‰ΩøÁî®ÂñÆÂÄãÁ¨¶Ëôü logit ÈÄ≤Ë°åÂø´ÈÄüÈáçÊñ∞ÊéíÂ∫è‰∏¶‰∏çÊúÉÂΩ±ÈüøÂüüÂ§ñÈáçÊñ∞ÊéíÂ∫èÁöÑÂìÅË≥™„ÄÇÁÇ∫‰∫ÜÊõ¥Â•ΩÂú∞ÈáèÂåñÂéüÂßãÁ†îÁ©∂‰∏≠ÁöÑË®àÁÆóÁØÄÁúÅÔºåÊàëÂÄëÊ∏¨Èáè‰∏¶ÊØîËºÉÂª∂ÈÅ≤ÊôÇÈñìÔºåÁôºÁèæÂêÑÁ®ÆÊ®°ÂûãÂíåÂü∫Ê∫ñÁöÑÂ¢ûÁõäÁÇ∫ 21%-42%„ÄÇÊ≠§Â§ñÔºåÈõñÁÑ∂ LM Ë®ìÁ∑¥Èö±Âê´Âú∞ÊîπÈÄ≤‰∫ÜÈõ∂Ê¨°Â≠∏ÁøíÂñÆÁ¨¶ËôüÈáçÊñ∞ÊéíÂ∫èÔºå‰ΩÜÊàëÂÄëÁöÑÂØ¶È©ó‰πüÊèêÂá∫‰∫ÜÁñëÂïèÔºåÂç≥ LM È†êË®ìÁ∑¥ÊòØÂê¶ÊúÉÈòªÁ§ôÂæåÁ∫å‰ΩøÁî® FIRST ÁõÆÊ®ôÈÄ≤Ë°åÂæÆË™ø„ÄÇÈÄô‰∫õÁôºÁèæÁÇ∫Êú™‰æÜÊáâÁî®‰∏≠Êõ¥ÊúâÊïàÁéáÂíåÊúâÊïàÁöÑÂàóË°®ÂºèÈáçÊñ∞ÊéíÂ∫èÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **LBPE: Long-token-first Tokenization to Improve Large Language Models**
2411.05504v1 by Haoran Lian, Yizhe Xiong, Zijia Lin, Jianwei Niu, Shasha Mo, Hui Chen, Peng Liu, Guiguang Ding

The prevalent use of Byte Pair Encoding (BPE) in Large Language Models (LLMs)
facilitates robust handling of subword units and avoids issues of
out-of-vocabulary words. Despite its success, a critical challenge persists:
long tokens, rich in semantic information, have fewer occurrences in tokenized
datasets compared to short tokens, which can result in imbalanced learning
issue across different tokens. To address that, we propose LBPE, which
prioritizes long tokens during the encoding process. LBPE generates tokens
according to their reverse ranks of token length rather than their ranks in the
vocabulary, granting longer tokens higher priority during the encoding process.
Consequently, LBPE smooths the frequency differences between short and long
tokens, and thus mitigates the learning imbalance. Extensive experiments across
diverse language modeling tasks demonstrate that LBPE consistently outperforms
the original BPE, well demonstrating its effectiveness.

ÊëòË¶ÅÔºöÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÊôÆÈÅç‰ΩøÁî®‰ΩçÂÖÉÁµÑÂ∞çÁ∑®Á¢º (BPE)Ôºå
ÊúâÂä©ÊñºÁ©©ÂÅ•ËôïÁêÜÊ¨°ÂñÆÂ≠óÂÖÉÂñÆ‰ΩçÔºå‰∏¶ÈÅøÂÖçË©ûÂΩôÂ§ñÂñÆÂ≠óÁöÑÂïèÈ°å„ÄÇÂÑòÁÆ°ÂÆÉÂæàÊàêÂäüÔºå‰ΩÜ‰ªçÂ≠òÂú®‰∏ÄÂÄãÂö¥Â≥ªÁöÑÊåëÊà∞Ôºö
Ë™ûÁæ©Ë≥áË®äË±êÂØåÁöÑÈï∑Ê®ôË®òÂú®Ê®ôË®òÂåñË≥áÊñôÈõÜ‰∏≠ÁöÑÂá∫ÁèæÊ¨°Êï∏ÊØîÁü≠Ê®ôË®òÂ∞ëÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÂêåÊ®ôË®ò‰πãÈñìÁöÑÂ≠∏Áøí‰∏çÂπ≥Ë°°
ÂïèÈ°å„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LBPEÔºåÂÆÉÂú®Á∑®Á¢ºÈÅéÁ®ã‰∏≠ÂÑ™ÂÖàËÄÉÊÖÆÈï∑Ê®ôË®ò„ÄÇLBPE Ê†πÊìöÊ®ôË®òÈï∑Â∫¶ÁöÑÂèçÂêëÊéíÂêçËÄå‰∏çÊòØÂÆÉÂÄëÂú®Ë©ûÂΩô‰∏≠ÁöÑÊéíÂêç‰æÜÁî¢ÁîüÊ®ôË®òÔºåÂú®Á∑®Á¢ºÈÅéÁ®ã‰∏≠Ë≥¶‰∫àËºÉÈï∑ÁöÑÊ®ôË®òËºÉÈ´òÁöÑÂÑ™ÂÖàÈ†ÜÂ∫è„ÄÇÂõ†Ê≠§ÔºåLBPE Âπ≥Êªë‰∫ÜÁü≠Ê®ôË®òÂíåÈï∑Ê®ôË®ò‰πãÈñìÁöÑÈ†ªÁéáÂ∑ÆÁï∞ÔºåÂæûËÄåÊ∏õËºï‰∫ÜÂ≠∏Áøí‰∏çÂπ≥Ë°°„ÄÇÂú®ÂêÑÁ®ÆË™ûË®ÄÂª∫Ê®°‰ªªÂãô‰∏≠ÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåLBPE ÊåÅÁ∫åÂÑ™ÊñºÂéüÂßã BPEÔºåÂÖÖÂàÜË≠âÊòé‰∫ÜÂÆÉÁöÑÊúâÊïàÊÄß„ÄÇ

##### **KyrgyzNLP: Challenges, Progress, and Future**
2411.05503v1 by Anton Alekseev, Timur Turatali

Large language models (LLMs) have excelled in numerous benchmarks, advancing
AI applications in both linguistic and non-linguistic tasks. However, this has
primarily benefited well-resourced languages, leaving less-resourced ones
(LRLs) at a disadvantage. In this paper, we highlight the current state of the
NLP field in the specific LRL: kyrgyz tili.
  Human evaluation, including annotated datasets created by native speakers,
remains an irreplaceable component of reliable NLP performance, especially for
LRLs where automatic evaluations can fall short. In recent assessments of the
resources for Turkic languages, Kyrgyz is labeled with the status 'Scraping
By', a severely under-resourced language spoken by millions. This is concerning
given the growing importance of the language, not only in Kyrgyzstan but also
among diaspora communities where it holds no official status.
  We review prior efforts in the field, noting that many of the publicly
available resources have only recently been developed, with few exceptions
beyond dictionaries (the processed data used for the analysis is presented at
https://kyrgyznlp.github.io/). While recent papers have made some headway, much
more remains to be done. Despite interest and support from both business and
government sectors in the Kyrgyz Republic, the situation for Kyrgyz language
resources remains challenging. We stress the importance of community-driven
efforts to build these resources, ensuring the future advancement
sustainability. We then share our view of the most pressing challenges in
Kyrgyz NLP. Finally, we propose a roadmap for future development in terms of
research topics and language resources.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÁúæÂ§öÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Ë°®ÁèæÂÑ™Áï∞ÔºåÂú®Ë™ûË®ÄÂíåÈùûË™ûË®Ä‰ªªÂãô‰∏≠Êé®Âãï AI ÊáâÁî®„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∏ªË¶Å‰ΩøË≥áÊ∫êË±êÂØåÁöÑË™ûË®ÄÂèóÁõäÔºåËÆìË≥áÊ∫êËºÉÂ∞ëÁöÑË™ûË®Ä (LRL) ËôïÊñºÂä£Âã¢„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈáçÈªû‰ªãÁ¥πÁâπÂÆö LRLÔºöÂêâÁàæÂêâÊñØË™û‰∏≠ÁöÑ NLP È†òÂüüÁèæÁãÄ„ÄÇ
  ‰∫∫È°ûË©ï‰º∞ÔºàÂåÖÊã¨Áî±ÊØçË™û‰∫∫Â£´Âª∫Á´ãÁöÑË®ªÈáãË≥áÊñôÈõÜÔºâ‰ªçÁÑ∂ÊòØÂèØÈù† NLP ÊïàËÉΩ‰∏çÂèØÊàñÁº∫ÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÁâπÂà•ÊòØÂ∞çÊñºËá™ÂãïË©ï‰º∞ÂèØËÉΩ‰∏çË∂≥ÁöÑ LRL„ÄÇÂú®ÊúÄËøëÂ∞çÁ™ÅÂé•Ë™ûË≥áÊ∫êÁöÑË©ï‰º∞‰∏≠ÔºåÂêâÁàæÂêâÊñØË™ûË¢´Ê®ôË®òÁÇ∫„ÄåÂãâÂº∑Êáâ‰ªò„ÄçÁãÄÊÖãÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁî±Êï∏ÁôæËê¨‰∫∫‰ΩøÁî®ÁöÑÂö¥ÈáçÁº∫‰πèË≥áÊ∫êÁöÑË™ûË®Ä„ÄÇÈÄô‰ª§‰∫∫ÊìîÊÜÇÔºåÂõ†ÁÇ∫Ë©≤Ë™ûË®Ä‰∏çÂÉÖÂú®ÂêâÁàæÂêâÊñØÊñØÂù¶ÔºåËÄå‰∏îÂú®Ê≤íÊúâÂÆòÊñπÂú∞‰ΩçÁöÑÂÉëÊ∞ëÁ§æÂçÄ‰∏≠ÈÉΩË∂ä‰æÜË∂äÈáçË¶Å„ÄÇ
  ÊàëÂÄëÂõûÈ°ß‰∫ÜË©≤È†òÂüüÂÖàÂâçÁöÑÂä™ÂäõÔºå‰∏¶Ê≥®ÊÑèÂà∞Ë®±Â§öÂÖ¨ÈñãÂèØÁî®ÁöÑË≥áÊ∫êÁõ¥Âà∞ÊúÄËøëÊâçÈñãÁôºÂá∫‰æÜÔºåÈô§‰∫ÜÂ≠óÂÖ∏‰πãÂ§ñÔºåÂπæ‰πéÊ≤íÊúâ‰æãÂ§ñÔºàÁî®ÊñºÂàÜÊûêÁöÑËôïÁêÜË≥áÊñôÈ°ØÁ§∫Âú® https://kyrgyznlp.github.io/Ôºâ„ÄÇÈõñÁÑ∂ÊúÄËøëÁöÑË´ñÊñáÂèñÂæó‰∫Ü‰∏Ä‰∫õÈÄ≤Â±ïÔºå‰ΩÜ‰ªçÊúâË®±Â§öÂ∑•‰ΩúÊúâÂæÖÂÆåÊàê„ÄÇÂÑòÁÆ°ÂêâÁàæÂêâÊñØÂÖ±ÂíåÂúãÁöÑ‰ºÅÊ•≠ÂíåÊîøÂ∫úÈÉ®ÈñÄÈÉΩÊÑüËààË∂£‰∏¶Êèê‰æõÊîØÊè¥Ôºå‰ΩÜÂêâÁàæÂêâÊñØË™ûË≥áÊ∫êÁöÑÁãÄÊ≥Å‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÂº∑Ë™ø‰∫ÜÁî±Á§æÂçÄÊé®ÂãïÁöÑÂä™ÂäõÂ∞çÊñºÂª∫Á´ãÈÄô‰∫õË≥áÊ∫êÁöÑÈáçË¶ÅÊÄßÔºåÁ¢∫‰øùÊú™‰æÜÁöÑÈÄ≤Ê≠•ÂÖ∑ÊúâÂèØÊåÅÁ∫åÊÄß„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂàÜ‰∫´ÊàëÂÄëÂ∞çÂêâÁàæÂêâÊñØË™û NLP ‰∏≠ÊúÄÁ∑äËø´ÊåëÊà∞ÁöÑÁúãÊ≥ï„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂú®Á†îÁ©∂‰∏ªÈ°åÂíåË™ûË®ÄË≥áÊ∫êÊñπÈù¢ÊèêÂá∫‰∫ÜÊú™‰æÜÁôºÂ±ïÁöÑË∑ØÁ∑öÂúñ„ÄÇ

##### **EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**
2411.05479v1 by Abdoul Nasser Hassane Amadou, Anas Motii, Saida Elouardi, EL Houcine Bergou

Underground forums serve as hubs for cybercriminal activities, offering a
space for anonymity and evasion of conventional online oversight. In these
hidden communities, malicious actors collaborate to exchange illicit knowledge,
tools, and tactics, driving a range of cyber threats from hacking techniques to
the sale of stolen data, malware, and zero-day exploits. Identifying the key
instigators (i.e., key hackers), behind these operations is essential but
remains a complex challenge. This paper presents a novel method called EUREKHA
(Enhancing User Representation for Key Hacker Identification in Underground
Forums), designed to identify these key hackers by modeling each user as a
textual sequence. This sequence is processed through a large language model
(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.
These extracted features are then fed into a Graph Neural Network (GNN) to
model user structural relationships, significantly improving identification
accuracy. Furthermore, we employ BERTopic (Bidirectional Encoder
Representations from Transformers Topic Modeling) to extract personalized
topics from user-generated content, enabling multiple textual representations
per user and optimizing the selection of the most representative sequence. Our
study demonstrates that fine-tuned LLMs outperform state-of-the-art methods in
identifying key hackers. Additionally, when combined with GNNs, our model
achieves significant improvements, resulting in approximately 6% and 10%
increases in accuracy and F1-score, respectively, over existing methods.
EUREKHA was tested on the Hack-Forums dataset, and we provide open-source
access to our code.

ÊëòË¶ÅÔºö<paragraph>Âú∞‰∏ãË´ñÂ£áÊòØÁ∂≤Ë∑ØÁäØÁΩ™Ê¥ªÂãïÁöÑÊ®ûÁ¥êÔºåÊèê‰æõÂåøÂêçÂíåË¶èÈÅøÂÇ≥Áµ±Á∂≤Ë∑ØÁõ£Áù£ÁöÑÁ©∫Èñì„ÄÇÂú®ÈÄô‰∫õÈö±ËóèÁöÑÁ§æÁæ§‰∏≠ÔºåÊÉ°ÊÑèË°åÁÇ∫ËÄÖÂêà‰Ωú‰∫§ÊèõÈùûÊ≥ïÁü•Ë≠ò„ÄÅÂ∑•ÂÖ∑ÂíåÁ≠ñÁï•ÔºåÊé®ÂãïÂæûÈß≠ÂÆ¢ÊäÄË°ìÂà∞Èä∑ÂîÆÁ´äÂèñË≥áÊñô„ÄÅÊÉ°ÊÑèËªüÈ´îÂíåÈõ∂ÊôÇÂ∑ÆÊºèÊ¥ûÁöÑÂêÑÁ®ÆÁ∂≤Ë∑ØÂ®ÅËÑÖ„ÄÇÊâæÂá∫ÈÄô‰∫õË°åÂãïËÉåÂæåÁöÑÈóúÈçµÁÖΩÂãïËÄÖÔºàÂç≥ÈóúÈçµÈß≠ÂÆ¢ÔºâËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãË§áÈõúÁöÑÊåëÊà∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ EUREKHAÔºàÂ¢ûÂº∑‰ΩøÁî®ËÄÖË°®Âæµ‰ª•Ë≠òÂà•Âú∞‰∏ãË´ñÂ£á‰∏≠ÁöÑÈóúÈçµÈß≠ÂÆ¢ÔºâÁöÑÊñ∞ÊñπÊ≥ïÔºåÊó®Âú®ÈÄèÈÅéÂ∞áÊØèÂÄã‰ΩøÁî®ËÄÖÂª∫Ê®°ÁÇ∫ÊñáÂ≠óÂ∫èÂàó‰æÜË≠òÂà•ÈÄô‰∫õÈóúÈçµÈß≠ÂÆ¢„ÄÇÊ≠§Â∫èÂàóÈÄèÈÅéÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËôïÁêÜ‰ª•ÈÄ≤Ë°åÁâπÂÆöÈ†òÂüüÁöÑÈÅ©ÊáâÔºåÂÖ∂‰∏≠ LLM ‰ΩúÁÇ∫ÁâπÂæµËêÉÂèñÂô®„ÄÇÁÑ∂ÂæåÂ∞áÈÄô‰∫õËêÉÂèñÁöÑÁâπÂæµËº∏ÂÖ•ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàGNNÔºâ‰ª•Âª∫Ê®°‰ΩøÁî®ËÄÖÁµêÊßãÈóú‰øÇÔºåÂ§ßÂπÖÊèêÂçáË≠òÂà•Ê∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé°Áî® BERTopicÔºà‰æÜËá™ Transformer ‰∏ªÈ°åÂª∫Ê®°ÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®ÂæµÔºâÂæû‰ΩøÁî®ËÄÖÁî¢ÁîüÁöÑÂÖßÂÆπ‰∏≠ËêÉÂèñÂÄã‰∫∫Âåñ‰∏ªÈ°åÔºåÁÇ∫ÊØèÂÄã‰ΩøÁî®ËÄÖÂïüÁî®Â§öÂÄãÊñáÂ≠óË°®ÂæµÔºå‰∏¶ÊúÄ‰Ω≥ÂåñÊúÄÂÖ∑‰ª£Ë°®ÊÄßÂ∫èÂàóÁöÑÈÅ∏Êìá„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂæÆË™øÂæåÁöÑ LLM Âú®Ë≠òÂà•ÈóúÈçµÈß≠ÂÆ¢ÊñπÈù¢ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÁï∂Ëàá GNN ÁµêÂêà‰ΩøÁî®ÊôÇÔºåÊàëÂÄëÁöÑÊ®°ÂûãÁç≤ÂæóÈ°ØËëóÁöÑÊèêÂçáÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊ∫ñÁ¢∫Â∫¶Âíå F1 ÂàÜÊï∏ÂàÜÂà•ÊèêÈ´ò‰∫ÜÁ¥Ñ 6% Âíå 10%„ÄÇEUREKHA Â∑≤Âú® Hack-Forums Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåÊàëÂÄëÊèê‰æõÈñãÊ∫êÊñπÂºèÂ≠òÂèñÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÇ</paragraph>

##### **Supporting Automated Fact-checking across Topics: Similarity-driven Gradual Topic Learning for Claim Detection**
2411.05460v1 by Amani S. Abumansour, Arkaitz Zubiaga

Selecting check-worthy claims for fact-checking is considered a crucial part
of expediting the fact-checking process by filtering out and ranking the
check-worthy claims for being validated among the impressive amount of claims
could be found online. The check-worthy claim detection task, however, becomes
more challenging when the model needs to deal with new topics that differ from
those seen earlier. In this study, we propose a domain-adaptation framework for
check-worthy claims detection across topics for the Arabic language to adopt a
new topic, mimicking a real-life scenario of the daily emergence of events
worldwide. We propose the Gradual Topic Learning (GTL) model, which builds an
ability to learning gradually and emphasizes the check-worthy claims for the
target topic during several stages of the learning process. In addition, we
introduce the Similarity-driven Gradual Topic Learning (SGTL) model that
synthesizes gradual learning with a similarity-based strategy for the target
topic. Our experiments demonstrate the effectiveness of our proposed model,
showing an overall tendency for improving performance over the state-of-the-art
baseline across 11 out of the 14 topics under study.

ÊëòË¶ÅÔºöÈÅ∏ÊìáÂÄºÂæóÊü•Ê†∏ÁöÑÊñ∑Ë®ÄÈÄ≤Ë°åÊü•Ê†∏Ë¢´Ë™çÁÇ∫ÊòØÂä†Âø´Êü•Ê†∏ÊµÅÁ®ãÁöÑÈóúÈçµÈÉ®ÂàÜÔºåÊñπÊ≥ïÊòØÈÅéÊøæ‰∏¶Â∞çÂÄºÂæóÊü•Ê†∏ÁöÑÊñ∑Ë®ÄÈÄ≤Ë°åÊéíÂêçÔºå‰ª•‰æøÂú®Á∂≤Ë∑Ø‰∏äÁôºÁèæÁöÑÂ§ßÈáèÊñ∑Ë®Ä‰∏≠ÈÄ≤Ë°åÈ©óË≠â„ÄÇÁÑ∂ËÄåÔºåÁï∂Ê®°ÂûãÈúÄË¶ÅËôïÁêÜËàáÂÖàÂâçÊâÄË¶ã‰∏çÂêåÁöÑÊñ∞‰∏ªÈ°åÊôÇÔºåÂÄºÂæóÊü•Ê†∏ÁöÑÊñ∑Ë®ÄÂÅµÊ∏¨‰ªªÂãô‰æøÊúÉËÆäÂæóÊõ¥ÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈáùÂ∞çÈòøÊãâ‰ºØË™ûË∑®‰∏ªÈ°åÂÄºÂæóÊü•Ê†∏ÁöÑÊñ∑Ë®ÄÂÅµÊ∏¨ÁöÑÈ†òÂüüÈÅ©ÊáâÊ°ÜÊû∂Ôºå‰ª•Êé°Áî®Êñ∞ÁöÑ‰∏ªÈ°åÔºåÊ®°Êì¨ÂÖ®ÁêÉ‰∫ã‰ª∂ÊØèÊó•Âá∫ÁèæÁöÑÁúüÂØ¶ÊÉÖÊ≥Å„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÊº∏ÈÄ≤Âºè‰∏ªÈ°åÂ≠∏Áøí (GTL) Ê®°ÂûãÔºåË©≤Ê®°ÂûãÂª∫Á´ã‰∫ÜÈÄêÊº∏Â≠∏ÁøíÁöÑËÉΩÂäõÔºå‰∏¶Âú®Â≠∏ÁøíÈÅéÁ®ãÁöÑÂπæÂÄãÈöéÊÆµÂº∑Ë™øÁõÆÊ®ô‰∏ªÈ°åÁöÑÂÄºÂæóÊü•Ê†∏Êñ∑Ë®Ä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁõ∏‰ººÊÄßÈ©ÖÂãïÊº∏ÈÄ≤Âºè‰∏ªÈ°åÂ≠∏Áøí (SGTL) Ê®°ÂûãÔºåË©≤Ê®°ÂûãÂ∞áÊº∏ÈÄ≤ÂºèÂ≠∏ÁøíËàáÂü∫ÊñºÁõ∏‰ººÊÄßÁöÑÁ≠ñÁï•ÁµêÂêàËµ∑‰æÜÔºå‰ª•Áî®ÊñºÁõÆÊ®ô‰∏ªÈ°å„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÁöÑÊúâÊïàÊÄßÔºåÈ°ØÁ§∫Âá∫Âú® 14 ÂÄãÁ†îÁ©∂‰∏ªÈ°å‰∏≠Êúâ 11 ÂÄã‰∏ªÈ°åÁöÑÊïàËÉΩÂÑ™ÊñºÁèæÊúâÊäÄË°ìÂü∫Á∑öÁöÑÊï¥È´îË∂®Âã¢„ÄÇ

##### **WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models**
2411.05451v1 by Shengda Fan, Xin Cong, Yuepeng Fu, Zhong Zhang, Shuyan Zhang, Yuanwei Liu, Yesai Wu, Yankai Lin, Zhiyuan Liu, Maosong Sun

Recent advancements in large language models (LLMs) have driven a
revolutionary paradigm shift in process automation from Robotic Process
Automation to Agentic Process Automation by automating the workflow
orchestration procedure based on LLMs. However, existing LLMs (even the
advanced OpenAI GPT-4o) are confined to achieving satisfactory capability in
workflow orchestration. To address this limitation, we present WorkflowLLM, a
data-centric framework elaborately designed to enhance the capability of LLMs
in workflow orchestration. It first constructs a large-scale fine-tuning
dataset WorkflowBench with 106,763 samples, covering 1,503 APIs from 83
applications across 28 categories. Specifically, the construction process can
be divided into three phases: (1) Data Collection: we collect real-world
workflow data from Apple Shortcuts and RoutineHub, transcribing them into
Python-style code. We further equip them with generated hierarchical thought
via ChatGPT. (2) Query Expansion: we prompt ChatGPT to generate more task
queries to enrich the diversity and complexity of workflows. (3) Workflow
Generation: we leverage an annotator model trained on collected data to
generate workflows for synthesized queries. Finally, we merge the synthetic
samples that pass quality confirmation with the collected samples to obtain the
WorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain
WorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong
capacity to orchestrate complex workflows, while also achieving notable
generalization performance on previously unseen APIs. Additionally,
WorkflowBench exhibits robust zero-shot generalization capabilities on an
out-of-distribution task planning dataset, T-Eval. Our data and code are
available at https://github.com/OpenBMB/WorkflowLLM.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÊé®Âãï‰∫ÜÊµÅÁ®ãËá™ÂãïÂåñÁöÑÈù©ÂëΩÊÄßÂÖ∏ÁØÑËΩâÁßªÔºåÂæûÊ©üÂô®‰∫∫ÊµÅÁ®ãËá™ÂãïÂåñÂà∞‰ª£ÁêÜÊµÅÁ®ãËá™ÂãïÂåñÔºåÈÄèÈÅéÂü∫Êñº LLM Ëá™ÂãïÂåñÂ∑•‰ΩúÊµÅÁ®ãÁ∑®ÊéíÁ®ãÂ∫è„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ LLMÔºàÁîöËá≥ÈÄ≤ÈöéÁöÑ OpenAI GPT-4oÔºâÂÉÖÈôêÊñºÂú®Â∑•‰ΩúÊµÅÁ®ãÁ∑®Êéí‰∏≠ÂØ¶Áèæ‰ª§‰∫∫ÊªøÊÑèÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü WorkflowLLMÔºå‰∏ÄÂÄãÁ≤æÂøÉË®≠Ë®àÁöÑ‰ª•Êï∏ÊìöÁÇ∫‰∏≠ÂøÉÁöÑÊ°ÜÊû∂ÔºåÁî®ÊñºÂ¢ûÂº∑ LLM Âú®Â∑•‰ΩúÊµÅÁ®ãÁ∑®Êéí‰∏≠ÁöÑËÉΩÂäõ„ÄÇÂÆÉÈ¶ñÂÖàÊßãÂª∫‰∏ÄÂÄãÂåÖÂê´ 106,763 ÂÄãÁØÑ‰æãÁöÑÂ§ßË¶èÊ®°ÂæÆË™øË≥áÊñôÈõÜ WorkflowBenchÔºåÊ∂µËìã‰æÜËá™ 28 ÂÄãÈ°ûÂà•ÁöÑ 83 ÂÄãÊáâÁî®Á®ãÂºèÁöÑ 1,503 ÂÄã API„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊßãÂª∫ÈÅéÁ®ãÂèØÂàÜÁÇ∫‰∏âÂÄãÈöéÊÆµÔºö(1) Êï∏ÊìöÊî∂ÈõÜÔºöÊàëÂÄëÂæû Apple Shortcuts Âíå RoutineHub Êî∂ÈõÜÁúüÂØ¶‰∏ñÁïåÁöÑÊµÅÁ®ãÊï∏ÊìöÔºå‰∏¶Â∞áÂÆÉÂÄëËΩâÈåÑÊàê Python È¢®Ê†ºÁöÑÁ®ãÂºèÁ¢º„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅé ChatGPT ÁîüÊàêÁöÑÈöéÂ±§ÂºèÊÄùËÄÉ‰æÜË£ùÂÇôÂÆÉÂÄë„ÄÇ(2) Êü•Ë©¢Êì¥ÂÖÖÔºöÊàëÂÄëÊèêÁ§∫ ChatGPT Áî¢ÁîüÊõ¥Â§ö‰ªªÂãôÊü•Ë©¢Ôºå‰ª•Ë±êÂØåÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂ§öÊ®£ÊÄßÂíåË§áÈõúÊÄß„ÄÇ(3) Â∑•‰ΩúÊµÅÁ®ãÁî¢ÁîüÔºöÊàëÂÄëÂà©Áî®Âú®Êî∂ÈõÜÁöÑÊï∏Êìö‰∏äË®ìÁ∑¥ÁöÑË®ªËß£Âô®Ê®°ÂûãÔºåÁÇ∫ÂêàÊàêÁöÑÊü•Ë©¢Áî¢ÁîüÂ∑•‰ΩúÊµÅÁ®ã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞áÈÄöÈÅéÂìÅË≥™Á¢∫Ë™çÁöÑÂêàÊàêÁØÑ‰æãËàáÊî∂ÈõÜÁöÑÁØÑ‰æãÂêà‰ΩµÔºå‰ª•ÂèñÂæó WorkflowBench„ÄÇÊ†πÊìö WorkflowBenchÔºåÊàëÂÄëÂæÆË™ø Llama-3.1-8B ‰ª•ÂèñÂæó WorkflowLlama„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåWorkflowLlama Â±ïÁ§∫Âá∫Á∑®ÊéíË§áÈõúÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂº∑Â§ßËÉΩÂäõÔºåÂêåÊôÇÂú®‰ª•ÂâçÊú™Ë¶ãÁöÑ API ‰∏äÂØ¶ÁèæÈ°ØËëóÁöÑÊ≥õÂåñÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåWorkflowBench Âú® out-of-distribution ‰ªªÂãôË¶èÂäÉË≥áÊñôÈõÜ T-Eval ‰∏äÂ±ïÁèæ‰∫ÜÂº∑ÂÅ•ÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÂíåÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/OpenBMB/WorkflowLLM ÂèñÂæó„ÄÇ

##### **ICE-T: A Multi-Faceted Concept for Teaching Machine Learning**
2411.05424v1 by Hendrik Krone, Pierre Haritz, Thomas Liebig

The topics of Artificial intelligence (AI) and especially Machine Learning
(ML) are increasingly making their way into educational curricula. To
facilitate the access for students, a variety of platforms, visual tools, and
digital games are already being used to introduce ML concepts and strengthen
the understanding of how AI works. We take a look at didactic principles that
are employed for teaching computer science, define criteria, and, based on
those, evaluate a selection of prominent existing platforms, tools, and games.
Additionally, we criticize the approach of portraying ML mostly as a black-box
and the resulting missing focus on creating an understanding of data,
algorithms, and models that come with it. To tackle this issue, we present a
concept that covers intermodal transfer, computational and explanatory
thinking, ICE-T, as an extension of known didactic principles. With our
multi-faceted concept, we believe that planners of learning units, creators of
learning platforms and educators can improve on teaching ML.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩ (AI) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÁöÑ‰∏ªÈ°åÊ≠£ÈÄêÊº∏ÈÄ≤ÂÖ•ÊïôËÇ≤Ë™≤Á®ã‰∏≠„ÄÇÁÇ∫‰∫ÜÊñπ‰æøÂ≠∏ÁîüÂèñÂæóÈÄô‰∫õË≥áË®äÔºåÂ∑≤Á∂ìÈñãÂßã‰ΩøÁî®ÂêÑÁ®ÆÂπ≥Âè∞„ÄÅË¶ñË¶∫Â∑•ÂÖ∑ÂíåÊï∏‰ΩçÈÅäÊà≤‰æÜ‰ªãÁ¥π ML Ê¶ÇÂøµÔºå‰∏¶Âä†Âº∑Â∞ç AI ÈÅã‰ΩúÊñπÂºèÁöÑÁêÜËß£„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÁî®ÊñºÊïôÊéàÈõªËÖ¶ÁßëÂ≠∏ÁöÑÊïôÂ≠∏ÂéüÂâá„ÄÅÂÆöÁæ©Ê®ôÊ∫ñÔºå‰∏¶Ê†πÊìöÈÄô‰∫õÊ®ôÊ∫ñË©ï‰º∞‰∏ÄÁ≥ªÂàóÁèæÊúâÁöÑÁü•ÂêçÂπ≥Âè∞„ÄÅÂ∑•ÂÖ∑ÂíåÈÅäÊà≤„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊâπË©ïÂ∞á ML ÊèèÁπ™Êàê‰∏ÄÂÄãÈªëÁõíÂ≠êÁöÑÊñπÊ≥ïÔºå‰ª•ÂèäÁî±Ê≠§Áî¢ÁîüÁöÑÂ∞çÂª∫Á´ãÂ∞çË≥áÊñô„ÄÅÊºîÁÆóÊ≥ïÂíåÈö®‰πãËÄå‰æÜÁöÑÊ®°ÂûãÁöÑÁêÜËß£ÁöÑÈóúÊ≥®‰∏çË∂≥„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊ∂µËìãË∑®Ê®°ÊÖãËΩâÁßª„ÄÅÈÅãÁÆóÂíåË™™ÊòéÊÄßÊÄùËÄÉ (ICE-T) ÁöÑÊ¶ÇÂøµÔºå‰ΩúÁÇ∫Â∑≤Áü•ÊïôÂ≠∏ÂéüÂâáÁöÑÂª∂‰º∏„ÄÇÈÄèÈÅéÊàëÂÄëÂ§öÈù¢ÂêëÁöÑÊ¶ÇÂøµÔºåÊàëÂÄëÁõ∏‰ø°Â≠∏ÁøíÂñÆÂÖÉÁöÑË¶èÂäÉËÄÖ„ÄÅÂ≠∏ÁøíÂπ≥Âè∞ÁöÑÂâµÂª∫ËÄÖÂíåÊïôËÇ≤Â∑•‰ΩúËÄÖÂèØ‰ª•ÊîπÈÄ≤ ML ÊïôÂ≠∏„ÄÇ

##### **VISTA: Visual Integrated System for Tailored Automation in Math Problem Generation Using LLM**
2411.05423v1 by Jeongwoo Lee, Kwangsuk Park, Jihyeon Park

Generating accurate and consistent visual aids is a critical challenge in
mathematics education, where visual representations like geometric shapes and
functions play a pivotal role in enhancing student comprehension. This paper
introduces a novel multi-agent framework that leverages Large Language Models
(LLMs) to automate the creation of complex mathematical visualizations
alongside coherent problem text. Our approach not only simplifies the
generation of precise visual aids but also aligns these aids with the problem's
core mathematical concepts, improving both problem creation and assessment. By
integrating multiple agents, each responsible for distinct tasks such as
numeric calculation, geometry validation, and visualization, our system
delivers mathematically accurate and contextually relevant problems with visual
aids. Evaluation across Geometry and Function problem types shows that our
method significantly outperforms basic LLMs in terms of text coherence,
consistency, relevance and similarity, while maintaining the essential
geometrical and functional integrity of the original problems. Although some
challenges remain in ensuring consistent visual outputs, our framework
demonstrates the immense potential of LLMs in transforming the way educators
generate and utilize visual aids in math education.

ÊëòË¶ÅÔºöÂú®Êï∏Â≠∏ÊïôËÇ≤‰∏≠ÔºåÁî¢ÁîüÊ∫ñÁ¢∫‰∏î‰∏ÄËá¥ÁöÑË¶ñË¶∫ËºîÂä©Â∑•ÂÖ∑ÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑÊåëÊà∞ÔºåÂÖ∂‰∏≠Ë¶ñË¶∫Ë°®Á§∫Ôºà‰æãÂ¶ÇÂπæ‰ΩïÂΩ¢ÁãÄÂíåÂáΩÊï∏ÔºâÂú®Â¢ûÂº∑Â≠∏ÁîüÁêÜËß£ÂäõÊñπÈù¢ÁôºÊèÆËëóËá≥ÈóúÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§ö‰ª£ÁêÜÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜËá™ÂãïÂåñË§áÈõúÊï∏Â≠∏Ë¶ñË¶∫ÂåñÁöÑÂâµÂª∫Ôºå‰ª•ÂèäÈÄ£Ë≤´ÁöÑÂïèÈ°åÊñáÊú¨„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÁ∞°Âåñ‰∫ÜÁ≤æÁ¢∫Ë¶ñË¶∫ËºîÂä©Â∑•ÂÖ∑ÁöÑÁîüÊàêÔºåËÄå‰∏îÈÇÑÂ∞áÈÄô‰∫õËºîÂä©Â∑•ÂÖ∑ËàáÂïèÈ°åÁöÑÊ†∏ÂøÉÊï∏Â≠∏Ê¶ÇÂøµ‰øùÊåÅ‰∏ÄËá¥ÔºåÂæûËÄåÊîπÈÄ≤‰∫ÜÂïèÈ°åÁöÑÂâµÂª∫ÂíåË©ï‰º∞„ÄÇÈÄöÈÅéÈõÜÊàêÂ§öÂÄã‰ª£ÁêÜÔºåÊØèÂÄã‰ª£ÁêÜË≤†Ë≤¨‰∏çÂêåÁöÑ‰ªªÂãôÔºå‰æãÂ¶ÇÊï∏Â≠óË®àÁÆó„ÄÅÂπæ‰ΩïÈ©óË≠âÂíåË¶ñË¶∫ÂåñÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±Êèê‰æõ‰∫ÜÊï∏Â≠∏‰∏äÊ∫ñÁ¢∫‰∏îÂú®‰∏ä‰∏ãÊñá‰∏äÁõ∏ÈóúÁöÑÂïèÈ°åÔºå‰∏¶ÈÖçÊúâË¶ñË¶∫ËºîÂä©Â∑•ÂÖ∑„ÄÇÂ∞çÂπæ‰ΩïÂíåÂáΩÊï∏ÂïèÈ°åÈ°ûÂûãÁöÑË©ï‰º∞Ë°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÊñáÊú¨ÈÄ£Ë≤´ÊÄß„ÄÅ‰∏ÄËá¥ÊÄß„ÄÅÁõ∏ÈóúÊÄßÂíåÁõ∏‰ººÊÄßÊñπÈù¢ÊòéÈ°ØÂÑ™ÊñºÂü∫Êú¨ÁöÑ LLMÔºåÂêåÊôÇ‰øùÊåÅ‰∫ÜÂéüÂßãÂïèÈ°åÁöÑÊú¨Ë≥™Âπæ‰ΩïÂíåÂáΩÊï∏ÂÆåÊï¥ÊÄß„ÄÇÂÑòÁÆ°Âú®Á¢∫‰øù‰∏ÄËá¥ÁöÑË¶ñË¶∫Ëº∏Âá∫ÊñπÈù¢‰ªçÂ≠òÂú®‰∏Ä‰∫õÊåëÊà∞Ôºå‰ΩÜÊàëÂÄëÁöÑÊ°ÜÊû∂Ë≠âÊòé‰∫Ü LLM Âú®ËΩâËÆäÊïôËÇ≤ËÄÖÂú®Êï∏Â≠∏ÊïôËÇ≤‰∏≠ÁîüÊàêÂíåÂà©Áî®Ë¶ñË¶∫ËºîÂä©Â∑•ÂÖ∑ÁöÑÊñπÂºèÊñπÈù¢ÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇ

##### **Learning the rules of peptide self-assembly through data mining with large language models**
2411.05421v1 by Zhenze Yang, Sarah K. Yorke, Tuomas P. J. Knowles, Markus J. Buehler

Peptides are ubiquitous and important biologically derived molecules, that
have been found to self-assemble to form a wide array of structures. Extensive
research has explored the impacts of both internal chemical composition and
external environmental stimuli on the self-assembly behaviour of these systems.
However, there is yet to be a systematic study that gathers this rich
literature data and collectively examines these experimental factors to provide
a global picture of the fundamental rules that govern protein self-assembly
behavior. In this work, we curate a peptide assembly database through a
combination of manual processing by human experts and literature mining
facilitated by a large language model. As a result, we collect more than 1,000
experimental data entries with information about peptide sequence, experimental
conditions and corresponding self-assembly phases. Utilizing the collected
data, ML models are trained and evaluated, demonstrating excellent accuracy
(>80\%) and efficiency in peptide assembly phase classification. Moreover, we
fine-tune our GPT model for peptide literature mining with the developed
dataset, which exhibits markedly superior performance in extracting information
from academic publications relative to the pre-trained model. We find that this
workflow can substantially improve efficiency when exploring potential
self-assembling peptide candidates, through guiding experimental work, while
also deepening our understanding of the mechanisms governing peptide
self-assembly. In doing so, novel structures can be accessed for a range of
applications including sensing, catalysis and biomaterials.

ÊëòË¶ÅÔºöËÉúËÇΩÊòØÊôÆÈÅçÂ≠òÂú®ÁöÑ‰∏îÈáçË¶ÅÁöÑÁîüÁâ©Ë°çÁîüÂàÜÂ≠êÔºåÂ∑≤ÂèëÁé∞ÂÆÉ‰ª¨‰ºöËá™ÁªÑË£ÖÂΩ¢ÊàêÂêÑÁßçÁªìÊûÑ„ÄÇÂπøÊ≥õÁöÑÁ†îÁ©∂Êé¢Á¥¢‰∫ÜÂÜÖÂú®ÂåñÂ≠¶ÊàêÂàÜÂíåÂ§ñÂú®ÁéØÂ¢ÉÂà∫ÊøÄÂØπËøô‰∫õÁ≥ªÁªüËá™ÁªÑË£ÖË°å‰∏∫ÁöÑÂΩ±Âìç„ÄÇÁÑ∂ËÄåÔºåÂ∞öÊú™ÊúâÁ≥ªÁªüÊÄßÁ†îÁ©∂Êî∂ÈõÜËøô‰∫õ‰∏∞ÂØåÁöÑÊñáÁåÆÊï∞ÊçÆÔºåÂπ∂ÂÖ±ÂêåÊ£ÄÈ™åËøô‰∫õÂÆûÈ™åÂõ†Á¥†Ôºå‰ª•Êèê‰æõÁÆ°ÁêÜËõãÁôΩË¥®Ëá™ÁªÑË£ÖË°å‰∏∫ÁöÑÂü∫Êú¨ËßÑÂàôÁöÑÂÖ®Â±ÄÂõæÊôØ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÈÄöËøá‰∫∫Â∑•‰∏ìÂÆ∂ÊâãÂä®Â§ÑÁêÜÂíåÁî±Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰øÉËøõÁöÑÊñáÁåÆÊåñÊéòÔºåÁ≠ñÂàí‰∫Ü‰∏Ä‰∏™ËÉúËÇΩÁªÑË£ÖÊï∞ÊçÆÂ∫ì„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨Êî∂ÈõÜ‰∫Ü 1,000 Â§ö‰∏™ÂÆûÈ™åÊï∞ÊçÆÊù°ÁõÆÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊúâÂÖ≥ËÉúËÇΩÂ∫èÂàó„ÄÅÂÆûÈ™åÊù°‰ª∂ÂíåÁõ∏Â∫îÁöÑËá™ÁªÑË£ÖÈò∂ÊÆµÁöÑ‰ø°ÊÅØ„ÄÇÂà©Áî®Êî∂ÈõÜÂà∞ÁöÑÊï∞ÊçÆÔºåÂØπ ML Ê®°ÂûãËøõË°åËÆ≠ÁªÉÂíåËØÑ‰º∞ÔºåÂ±ïÁ§∫‰∫ÜËÉúËÇΩÁªÑË£ÖÈò∂ÊÆµÂàÜÁ±ªÁöÑÂá∫Ëâ≤ÂáÜÁ°ÆÊÄß (>80%) ÂíåÊïàÁéá„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨‰ΩøÁî®ÂºÄÂèëÁöÑÊï∞ÊçÆÈõÜÂØπ GPT Ê®°ÂûãËøõË°åÂæÆË∞ÉÔºåÁî®‰∫éËÉúËÇΩÊñáÁåÆÊåñÊéòÔºåËØ•Ê®°ÂûãÂú®‰ªéÂ≠¶ÊúØÂá∫ÁâàÁâ©‰∏≠ÊèêÂèñ‰ø°ÊÅØÊñπÈù¢Ë°®Áé∞Âá∫ÊòéÊòæ‰ºò‰∫éÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåÊ≠§Â∑•‰ΩúÊµÅÁ®ãÂèØ‰ª•ÈÄöËøáÊåáÂØºÂÆûÈ™åÂ∑•‰ΩúÔºåÂêåÊó∂Âä†Ê∑±Êàë‰ª¨ÂØπÁÆ°ÁêÜËÉúËÇΩËá™ÁªÑË£ÖÁöÑÊú∫Âà∂ÁöÑÁêÜËß£ÔºåÂú®Êé¢Á¥¢ÊΩúÂú®Ëá™ÁªÑË£ÖËÉúËÇΩÂÄôÈÄâÁâ©Êó∂Â§ßÂπÖÊèêÈ´òÊïàÁéá„ÄÇËøôÊ†∑ÂÅöÂèØ‰ª•Ëé∑ÂæóÊñ∞È¢ñÁöÑÁªìÊûÑÔºåÁî®‰∫éÂåÖÊã¨‰º†ÊÑü„ÄÅÂÇ¨ÂåñÂíåÁîüÁâ©ÊùêÊñôÂú®ÂÜÖÁöÑÂêÑÁßçÂ∫îÁî®„ÄÇ

##### **WeatherGFM: Learning A Weather Generalist Foundation Model via In-context Learning**
2411.05420v1 by Xiangyu Zhao, Zhiwang Zhou, Wenlong Zhang, Yihao Liu, Xiangyu Chen, Junchao Gong, Hao Chen, Ben Fei, Shiqi Chen, Wanli Ouyang, Xiao-Ming Wu, Lei Bai

The Earth's weather system encompasses intricate weather data modalities and
diverse weather understanding tasks, which hold significant value to human
life. Existing data-driven models focus on single weather understanding tasks
(e.g., weather forecasting). Although these models have achieved promising
results, they fail to tackle various complex tasks within a single and unified
model. Moreover, the paradigm that relies on limited real observations for a
single scenario hinders the model's performance upper bound. In response to
these limitations, we draw inspiration from the in-context learning paradigm
employed in state-of-the-art visual foundation models and large language
models. In this paper, we introduce the first generalist weather foundation
model (WeatherGFM), designed to address a wide spectrum of weather
understanding tasks in a unified manner. More specifically, we initially unify
the representation and definition of the diverse weather understanding tasks.
Subsequently, we devised weather prompt formats to manage different weather
data modalities, namely single, multiple, and temporal modalities. Finally, we
adopt a visual prompting question-answering paradigm for the training of
unified weather understanding tasks. Extensive experiments indicate that our
WeatherGFM can effectively handle up to ten weather understanding tasks,
including weather forecasting, super-resolution, weather image translation, and
post-processing. Our method also showcases generalization ability on unseen
tasks.

ÊëòË¶ÅÔºöÂú∞ÁêÉÁöÑÂ§©Ê∞£Á≥ªÁµ±ÂåÖÂê´‰∫ÜË§áÈõúÁöÑÂ§©Ê∞£Êï∏ÊìöÊ®°ÂºèÂíåÂêÑÁ®ÆÂ§©Ê∞£ÁêÜËß£‰ªªÂãôÔºåÈÄô‰∫õ‰ªªÂãôÂ∞ç‰∫∫È°ûÁîüÊ¥ªÂÖ∑ÊúâÈáçË¶ÅÂÉπÂÄº„ÄÇÁèæÊúâÁöÑÊï∏ÊìöÈ©ÖÂãïÊ®°ÂûãÂ∞àÊ≥®ÊñºÂñÆ‰∏ÄÁöÑÂ§©Ê∞£ÁêÜËß£‰ªªÂãôÔºà‰æãÂ¶ÇÂ§©Ê∞£È†êÂ†±Ôºâ„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊ®°ÂûãÂ∑≤Á∂ìÂèñÂæó‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºå‰ΩÜÂÆÉÂÄëÁÑ°Ê≥ïÂú®ÂñÆ‰∏Ä‰∏îÁµ±‰∏ÄÁöÑÊ®°Âûã‰∏≠ÊáâÂ∞çÂêÑÁ®ÆË§áÈõúÁöÑ‰ªªÂãô„ÄÇÊ≠§Â§ñÔºå‰æùË≥¥ÊñºÂñÆ‰∏ÄÊÉÖÂ¢É‰∏≠ÊúâÈôêÁöÑÁúüÂØ¶ËßÄÊ∏¨ÁöÑÁØÑ‰æãÈòªÁ§ô‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ‰∏äÈôê„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂæûÊúÄÂÖàÈÄ≤ÁöÑË¶ñË¶∫Âü∫Á§éÊ®°ÂûãÂíåÂ§ßË™ûË®ÄÊ®°Âûã‰∏≠‰ΩøÁî®ÁöÑ‰∏ä‰∏ãÊñáÂ≠∏ÁøíÁØÑ‰æã‰∏≠Ê±≤ÂèñÈùàÊÑü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÁ¨¨‰∏ÄÂÄãÈÄöÊâçÂ§©Ê∞£Âü∫Á§éÊ®°Âûã (WeatherGFM)ÔºåÊó®Âú®‰ª•Áµ±‰∏ÄÁöÑÊñπÂºèËß£Ê±∫Âª£Ê≥õÁöÑÂ§©Ê∞£ÁêÜËß£‰ªªÂãô„ÄÇÊõ¥ÂÖ∑È´îÂú∞Ë™™ÔºåÊàëÂÄëÊúÄÂàùÁµ±‰∏Ä‰∫Ü‰∏çÂêåÂ§©Ê∞£ÁêÜËß£‰ªªÂãôÁöÑË°®Á§∫ÂíåÂÆöÁæ©„ÄÇÈö®ÂæåÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÂ§©Ê∞£ÊèêÁ§∫Ê†ºÂºè‰æÜÁÆ°ÁêÜ‰∏çÂêåÁöÑÂ§©Ê∞£Êï∏ÊìöÊ®°ÂºèÔºåÂç≥ÂñÆ‰∏Ä„ÄÅÂ§öÈáçÂíåÊôÇÈñìÊ®°Âºè„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé°Áî®Ë¶ñË¶∫ÊèêÁ§∫ÂïèÁ≠îÁØÑ‰æã‰æÜË®ìÁ∑¥Áµ±‰∏ÄÁöÑÂ§©Ê∞£ÁêÜËß£‰ªªÂãô„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑ WeatherGFM ÂèØ‰ª•ÊúâÊïàÂú∞ËôïÁêÜÂ§öÈÅîÂçÅÈ†ÖÂ§©Ê∞£ÁêÜËß£‰ªªÂãôÔºåÂåÖÊã¨Â§©Ê∞£È†êÂ†±„ÄÅË∂ÖËß£ÊûêÂ∫¶„ÄÅÂ§©Ê∞£ÂúñÂÉèËΩâÊèõÂíåÂæåËôïÁêÜ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÇÑÂ±ïÁ§∫‰∫ÜÂú®Êú™Ë¶ã‰ªªÂãô‰∏äÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

##### **Web Archives Metadata Generation with GPT-4o: Challenges and Insights**
2411.05409v1 by Abigail Yongping Huang, Ashwin Nair, Zhen Rong Goh, Tianrui Liu

Current metadata creation for web archives is time consuming and costly due
to reliance on human effort. This paper explores the use of gpt-4o for metadata
generation within the Web Archive Singapore, focusing on scalability,
efficiency, and cost effectiveness. We processed 112 Web ARChive (WARC) files
using data reduction techniques, achieving a notable 99.9% reduction in
metadata generation costs. By prompt engineering, we generated titles and
abstracts, which were evaluated both intrinsically using Levenshtein Distance
and BERTScore, and extrinsically with human cataloguers using McNemar's test.
Results indicate that while our method offers significant cost savings and
efficiency gains, human curated metadata maintains an edge in quality. The
study identifies key challenges including content inaccuracies, hallucinations,
and translation issues, suggesting that Large Language Models (LLMs) should
serve as complements rather than replacements for human cataloguers. Future
work will focus on refining prompts, improving content filtering, and
addressing privacy concerns through experimentation with smaller models. This
research advances the integration of LLMs in web archiving, offering valuable
insights into their current capabilities and outlining directions for future
enhancements. The code is available at
https://github.com/masamune-prog/warc2summary for further development and use
by institutions facing similar challenges.

ÊëòË¶ÅÔºöÁõÆÂâçÁ∂≤Ë∑ØÊ™îÊ°àÁöÑÂª∫Á´ãÂÖÉË≥áÊñôÂçÅÂàÜËÄóÊôÇ‰∏îÊòÇË≤¥ÔºåÂõ†ÁÇ∫‰ª∞Ë≥¥‰∫∫Âäõ„ÄÇÊú¨ÊñáÊé¢Ë®éÂú®Êñ∞Âä†Âù°Á∂≤Ë∑ØÊ™îÊ°à‰∏≠‰ΩøÁî® gpt-4o Áî¢ÁîüÂÖÉË≥áÊñôÔºåËëóÈáçÊñºÂèØÊì¥ÂÖÖÊÄß„ÄÅÊïàÁéáÂíåÊàêÊú¨ÊïàÁõä„ÄÇÊàëÂÄë‰ΩøÁî®Ë≥áÊñôÊ∏õÂ∞ëÊäÄË°ìËôïÁêÜ‰∫Ü 112 ÂÄãÁ∂≤Ë∑ØÊ™îÊ°à (WARC) Ê™îÊ°àÔºåÂ§ßÂπÖÈôç‰Ωé‰∫Ü 99.9% ÁöÑÂÖÉË≥áÊñôÁî¢ÁîüÊàêÊú¨„ÄÇÈÄèÈÅéÊèêÁ§∫Â∑•Á®ãÔºåÊàëÂÄëÁî¢Áîü‰∫ÜÊ®ôÈ°åÂíåÊëòË¶ÅÔºå‰∏¶‰ΩøÁî® Levenshtein Ë∑ùÈõ¢Âíå BERTScore ÂÖßÂú®Ë©ï‰º∞Ôºå‰ª•Âèä‰ΩøÁî® McNemar ÁöÑÊ™¢ÂÆöËàá‰∫∫È°ûÂàÜÈ°ûÂì°Â§ñÂú®Ë©ï‰º∞„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÈõñÁÑ∂ÊàëÂÄëÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÈ°ØËëóÁöÑÊàêÊú¨ÁØÄÁúÅÂíåÊïàÁéáÊèêÂçáÔºå‰ΩÜ‰∫∫È°ûÁ≠ñÂ±ïÁöÑÂÖÉË≥áÊñôÂú®ÂìÅË≥™‰∏ä‰ªçÊúâ‰∏ÄÂÆöÂÑ™Âã¢„ÄÇÁ†îÁ©∂ÊâæÂá∫‰∫Ü‰∏Ä‰∫õÈóúÈçµÊåëÊà∞ÔºåÂåÖÊã¨ÂÖßÂÆπ‰∏çÊ≠£Á¢∫„ÄÅÂπªË¶∫ÂíåÁøªË≠ØÂïèÈ°åÔºåÈÄôË°®Á§∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊáâË©≤‰ΩúÁÇ∫‰∫∫È°ûÂàÜÈ°ûÂì°ÁöÑË£úÂÖÖÔºåËÄå‰∏çÊòØÂèñ‰ª£„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∞áÂ∞àÊ≥®ÊñºÊîπÂñÑÊèêÁ§∫„ÄÅÊèêÂçáÂÖßÂÆπÈÅéÊøæÔºå‰∏¶ÈÄèÈÅéÂØ¶È©óËºÉÂ∞èÁöÑÊ®°Âûã‰æÜËß£Ê±∫Èö±ÁßÅÂïèÈ°å„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Êé®Âãï‰∫Ü LLM Âú®Á∂≤Ë∑ØÊ™îÊ°à‰∏≠ÁöÑÊï¥ÂêàÔºåÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£Ôºå‰∫ÜËß£ÂÆÉÂÄëÁõÆÂâçÁöÑÊïàËÉΩÔºå‰∏¶Ê¶ÇËø∞‰∫ÜÊú™‰æÜÂ¢ûÂº∑ÁöÑÊñπÂêë„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/masamune-prog/warc2summary ÂèñÂæóÔºå‰æõÈù¢Ëá®È°û‰ººÊåëÊà∞ÁöÑÊ©üÊßãÈÄ≤‰∏ÄÊ≠•ÈñãÁôºÂíå‰ΩøÁî®„ÄÇ

##### **Gap-Filling Prompting Enhances Code-Assisted Mathematical Reasoning**
2411.05407v1 by Mohammad Ghiasvand Mohammadkhani

Despite the strong performance of large language models (LLMs) in tasks like
mathematical reasoning, their practical use is limited by high computational
demands and proprietary restrictions. Chain-of-thought (CoT) and
program-of-thought (PoT) fine-tuning are common methods to transfer LLM
knowledge to small language models (SLMs). However, CoT often leads to
calculation errors in SLMs, while PoT has shown more promise. While most
PoT-based approaches focus on direct problem-to-code conversion or extracting
only the key information from questions and then providing code solution for
it, this work emphasizes filling the gaps in the question to clearly illustrate
the solution path, which can be challenging for an SLM to understand when such
information is not explicitly provided. Therefore, this paper introduces
Gap-Filling Prompting (GFP), a novel two-step prompting strategy designed to
enhance the problem-solving process for SLMs. The first step identifies these
gaps and provides hints for filling them, while the second step adds the hints
to the question to generate a final code solution. Experimental results on two
benchmark datasets demonstrate that GFP significantly improves the mathematical
reasoning abilities of SLMs.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êï∏Â≠∏Êé®ÁêÜÁ≠â‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂÆÉÂÄëÁöÑÂØ¶ÈöõÁî®ÈÄîÂèóÂà∞È´òÈÅãÁÆóÈúÄÊ±ÇÂíåÂ∞àÊúâÊ¨äÈôêÂà∂„ÄÇÊÄùÊÉ≥Èèà (CoT) ÂíåÊÄùÊÉ≥Á®ãÂºè (PoT) ÂæÆË™øÊòØÂ∞á LLM Áü•Ë≠òËΩâÁßªÂà∞Â∞èÂûãË™ûË®ÄÊ®°Âûã (SLM) ÁöÑÂ∏∏Ë¶ãÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåCoT ÈÄöÂ∏∏ÊúÉÂ∞éËá¥ SLM ‰∏≠ÁöÑË®àÁÆóÈåØË™§ÔºåËÄå PoT ÂâáÈ°ØÁ§∫Âá∫Êõ¥Â§ßÁöÑÂ∏åÊúõ„ÄÇÂÑòÁÆ°Â§ßÂ§öÊï∏Âü∫Êñº PoT ÁöÑÊñπÊ≥ïÂ∞àÊ≥®ÊñºÁõ¥Êé•ÂïèÈ°åÂà∞Á®ãÂºèÁ¢ºËΩâÊèõÊàñÂÉÖÂæûÂïèÈ°å‰∏≠ÊèêÂèñÈóúÈçµË≥áË®äÔºåÁÑ∂ÂæåÊèê‰æõÁ®ãÂºèÁ¢ºËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜÈÄôÈ†ÖÂ∑•‰ΩúÂº∑Ë™øÂ°´Ë£úÂïèÈ°å‰∏≠ÁöÑÁ©∫ÁôΩÔºå‰ª•Ê∏ÖÊ•öË™™ÊòéËß£Ê±∫Ë∑ØÂæëÔºåÈÄôÂ∞çÊñº SLM Âú®Ê≤íÊúâÊòéÁ¢∫Êèê‰æõÊ≠§È°ûË≥áË®äÊôÇÁêÜËß£ÊúÉÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÊú¨Êñá‰ªãÁ¥π‰∫ÜÈñìÈöôÂ°´ÂÖÖÊèêÁ§∫ (GFP)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÖ©Ê≠•È©üÊèêÁ§∫Á≠ñÁï•ÔºåÊó®Âú®Â¢ûÂº∑ SLM ÁöÑÂïèÈ°åËß£Ê±∫ÈÅéÁ®ã„ÄÇÁ¨¨‰∏ÄÊ≠•Ë≠òÂà•ÈÄô‰∫õÈñìÈöô‰∏¶Êèê‰æõÂ°´Ë£úÊèêÁ§∫ÔºåËÄåÁ¨¨‰∫åÊ≠•Â∞áÊèêÁ§∫Êñ∞Â¢ûÂà∞ÂïèÈ°å‰∏≠‰ª•Áî¢ÁîüÊúÄÁµÇÁ®ãÂºèÁ¢ºËß£Ê±∫ÊñπÊ°à„ÄÇÂÖ©ÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåGFP Â§ßÂπÖÊèêÂçá‰∫Ü SLM ÁöÑÊï∏Â≠∏Êé®ÁêÜËÉΩÂäõ„ÄÇ

##### **Benchmarking Distributional Alignment of Large Language Models**
2411.05403v1 by Nicole Meister, Carlos Guestrin, Tatsunori Hashimoto

Language models (LMs) are increasingly used as simulacra for people, yet
their ability to match the distribution of views of a specific demographic
group and be \textit{distributionally aligned} remains uncertain. This notion
of distributional alignment is complex, as there is significant variation in
the types of attributes that are simulated. Prior works have underexplored the
role of three critical variables -- the question domain, steering method, and
distribution expression method -- which motivates our contribution of a
benchmark explicitly addressing these dimensions. We construct a dataset
expanding beyond political values, create human baselines for this task, and
evaluate the extent to which an LM can align with a particular group's opinion
distribution to inform design choices of such simulation systems. Our analysis
reveals open problems regarding if, and how, LMs can be used to simulate
humans, and that LLMs can more accurately describe the opinion distribution
than simulate such distributions.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°Âûã (LM) ÊÑà‰æÜÊÑàÂ∏∏Ë¢´Áî®‰ΩúÊ®°Êì¨‰∫∫È°ûÔºå‰ΩÜÂÆÉÂÄëÊòØÂê¶ËÉΩÁ¨¶ÂêàÁâπÂÆö‰∫∫Âè£Áµ±Ë®àÁæ§È´îÁöÑËßÄÈªûÂàÜ‰ΩàÔºå‰ª•ÂèäÊòØÂê¶ËÉΩ„ÄåÂàÜ‰ΩàÂºèÂ∞çÈΩä„Äç‰ªçÂ≠òÂú®‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÈÄôÂÄãÂàÜ‰ΩàÂºèÂ∞çÈΩäÁöÑÊ¶ÇÂøµÂæàË§áÈõúÔºåÂõ†ÁÇ∫Âú®Ê®°Êì¨ÁöÑÂ±¨ÊÄßÈ°ûÂûã‰∏≠ÊúâÈ°ØËëóÁöÑÂ∑ÆÁï∞„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂‰Ωé‰º∞‰∫Ü‰∏âÂÄãÈóúÈçµËÆäÊï∏ÁöÑ‰ΩúÁî®‚Äî‚ÄîÂïèÈ°åÈ†òÂüü„ÄÅÂºïÂ∞éÊñπÊ≥ïÂíåÂàÜ‰ΩàÂºèË°®ÈÅîÊñπÊ≥ï‚Äî‚ÄîÈÄôÊøÄÂãµÊàëÂÄëË≤¢Áçª‰∫Ü‰∏ÄÂÄãÊòéÁ¢∫Ë™™ÊòéÈÄô‰∫õÈù¢ÂêëÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãË∂ÖË∂äÊîøÊ≤ªÂÉπÂÄºËßÄÁöÑË≥áÊñôÈõÜÔºåÁÇ∫ÈÄôÂÄã‰ªªÂãôÂª∫Á´ã‰∫∫È°ûÂü∫Ê∫ñÔºå‰∏¶Ë©ï‰º∞ LM Âú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äËÉΩËàáÁâπÂÆöÁæ§È´îÁöÑÊÑèË¶ãÂàÜ‰Ωà‰øùÊåÅ‰∏ÄËá¥Ôºå‰ª•ÂëäÁü•Ê≠§È°ûÊ®°Êì¨Á≥ªÁµ±ÁöÑË®≠Ë®àÈÅ∏Êìá„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊè≠Èú≤‰∫ÜÈóúÊñº LM ÊòØÂê¶ËÉΩ‰ª•ÂèäÂ¶Ç‰ΩïÁî®ÊñºÊ®°Êì¨‰∫∫È°ûÁöÑÂÖ¨ÈñãÂïèÈ°åÔºå‰ª•Âèä LLM ËÉΩÊØîÊ®°Êì¨Ê≠§È°ûÂàÜ‰ΩàÊõ¥Ê∫ñÁ¢∫Âú∞ÊèèËø∞ÊÑèË¶ãÂàÜ‰Ωà„ÄÇ

##### **Advancing Meteorological Forecasting: AI-based Approach to Synoptic Weather Map Analysis**
2411.05384v1 by Yo-Hwan Choi, Seon-Yu Kang, Minjong Cheon

As global warming increases the complexity of weather patterns; the precision
of weather forecasting becomes increasingly important. Our study proposes a
novel preprocessing method and convolutional autoencoder model developed to
improve the interpretation of synoptic weather maps. These are critical for
meteorologists seeking a thorough understanding of weather conditions. This
model could recognize historical synoptic weather maps that nearly match
current atmospheric conditions, marking a significant step forward in modern
technology in meteorological forecasting. This comprises unsupervised learning
models like VQ-VQE, as well as supervised learning models like VGG16, VGG19,
Xception, InceptionV3, and ResNet50 trained on the ImageNet dataset, as well as
research into newer models like EfficientNet and ConvNeXt. Our findings proved
that, while these models perform well in various settings, their ability to
identify comparable synoptic weather maps has certain limits. Our research,
motivated by the primary goal of significantly increasing meteorologists'
efficiency in labor-intensive tasks, discovered that cosine similarity is the
most effective metric, as determined by a combination of quantitative and
qualitative assessments to accurately identify relevant historical weather
patterns. This study broadens our understanding by shifting the emphasis from
numerical precision to practical application, ensuring that our model is
effective in theory practical, and accessible in the complex and dynamic field
of meteorology.

ÊëòË¶ÅÔºöÈö®ËëóÂÖ®ÁêÉÊöñÂåñÂä†ÂäáÂ§©Ê∞£ÂûãÊÖãÁöÑË§áÈõúÂ∫¶ÔºåÂ§©Ê∞£È†êÊ∏¨ÁöÑÁ≤æÊ∫ñÂ∫¶ËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈ†êËôïÁêÜÊñπÊ≥ïÂíåÂç∑Á©çËá™Á∑®Á¢ºÂô®Ê®°ÂûãÔºåÁî®ÊñºÊîπÂñÑÂ§©Ê∞£Ê¶ÇÊ≥ÅÂúñÁöÑËß£ËÆÄ„ÄÇÂ∞çÊñºÂ∞ãÊ±ÇÂæπÂ∫ï‰∫ÜËß£Â§©Ê∞£ÁãÄÊ≥ÅÁöÑÊ∞£Ë±°Â≠∏ÂÆ∂‰æÜË™™ÔºåÈÄô‰∫õËá≥ÈóúÈáçË¶Å„ÄÇÊ≠§Ê®°ÂûãÂèØ‰ª•Ë≠òÂà•ËàáÁï∂ÂâçÂ§ßÊ∞£ÁãÄÊ≥ÅÂπæ‰πéÁõ∏Á¨¶ÁöÑÊ≠∑Âè≤Â§©Ê∞£Ê¶ÇÊ≥ÅÂúñÔºåÊ®ôË™åËëóÊ∞£Ë±°È†êÊ∏¨Áèæ‰ª£ÊäÄË°ìÂêëÂâçÈÇÅÂá∫‰∫Ü‰∏ÄÂ§ßÊ≠•„ÄÇÈÄôÂåÖÊã¨ÁÑ°Áõ£Áù£Â≠∏ÁøíÊ®°ÂûãÔºàÂ¶Ç VQ-VQEÔºâÔºå‰ª•ÂèäÂú® ImageNet Ë≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÊúâÁõ£Áù£Â≠∏ÁøíÊ®°ÂûãÔºàÂ¶Ç VGG16„ÄÅVGG19„ÄÅXception„ÄÅInceptionV3 Âíå ResNet50ÔºâÔºå‰ª•ÂèäÂ∞ç EfficientNet Âíå ConvNeXt Á≠âËºÉÊñ∞Ê®°ÂûãÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË≠âÊòéÔºåÂÑòÁÆ°ÈÄô‰∫õÊ®°ÂûãÂú®ÂêÑÁ®ÆË®≠ÂÆö‰∏≠Ë°®ÁèæËâØÂ•ΩÔºå‰ΩÜÂÆÉÂÄëË≠òÂà•ÂèØÊØîËºÉÂ§©Ê∞£Ê¶ÇÊ≥ÅÂúñÁöÑËÉΩÂäõÊúâ‰∏ÄÂÆöÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂãïÊ©üÊòØÂ§ßÂπÖÊèêÂçáÊ∞£Ë±°Â≠∏ÂÆ∂Âú®ÂãûÂäõÂØÜÈõÜÂûã‰ªªÂãô‰∏≠ÁöÑÊïàÁéáÔºåÁôºÁèæÈ§òÂº¶Áõ∏‰ººÂ∫¶ÊòØÊúÄÊúâÊïàÁöÑÊåáÊ®ôÔºåÈÄôÊòØÁî±ÂÆöÈáèÂíåÂÆöÊÄßË©ï‰º∞Áõ∏ÁµêÂêà‰æÜÊ∫ñÁ¢∫Ë≠òÂà•Áõ∏ÈóúÊ≠∑Âè≤Â§©Ê∞£Ê®°ÂºèÊâÄÊ±∫ÂÆöÁöÑ„ÄÇÊú¨Á†îÁ©∂ÈÄèÈÅéÂ∞áÈáçÈªûÂæûÊï∏ÂÄºÁ≤æÁ¢∫Â∫¶ËΩâÁßªÂà∞ÂØ¶ÈöõÊáâÁî®ÔºåÊì¥Â±ï‰∫ÜÊàëÂÄëÁöÑÁêÜËß£ÔºåÁ¢∫‰øùÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÁêÜË´ñ‰∏äÊòØÊúâÊïàÁöÑ„ÄÅÂú®ÂØ¶Âãô‰∏äÊòØÊúâÊïàÁöÑÔºå‰∏¶‰∏îÂú®Ë§áÈõú‰∏îÂãïÊÖãÁöÑÊ∞£Ë±°È†òÂüü‰∏≠ÊòØÂèØ‰ª•‰ΩøÁî®ÁöÑ„ÄÇ

##### **Towards Low-Resource Harmful Meme Detection with LMM Agents**
2411.05383v1 by Jianzhao Huang, Hongzhan Lin, Ziyan Liu, Ziyang Luo, Guang Chen, Jing Ma

The proliferation of Internet memes in the age of social media necessitates
effective identification of harmful ones. Due to the dynamic nature of memes,
existing data-driven models may struggle in low-resource scenarios where only a
few labeled examples are available. In this paper, we propose an agency-driven
framework for low-resource harmful meme detection, employing both outward and
inward analysis with few-shot annotated samples. Inspired by the powerful
capacity of Large Multimodal Models (LMMs) on multimodal reasoning, we first
retrieve relative memes with annotations to leverage label information as
auxiliary signals for the LMM agent. Then, we elicit knowledge-revising
behavior within the LMM agent to derive well-generalized insights into meme
harmfulness. By combining these strategies, our approach enables dialectical
reasoning over intricate and implicit harm-indicative patterns. Extensive
experiments conducted on three meme datasets demonstrate that our proposed
approach achieves superior performance than state-of-the-art methods on the
low-resource harmful meme detection task.

ÊëòË¶ÅÔºöÈö®ËëóÁ§æÁæ§Â™íÈ´îÊôÇ‰ª£Á∂≤Ë∑ØËø∑Âõ†ÁöÑÊøÄÂ¢ûÔºåËø´ÂàáÈúÄË¶ÅÊúâÊïàËæ®Ë≠òÊúâÂÆ≥Ëø∑Âõ†„ÄÇÁî±ÊñºËø∑Âõ†ÁöÑÂãïÊÖãÁâπÊÄßÔºåÁèæÊúâÁöÑË≥áÊñôÈ©ÖÂãïÊ®°ÂûãÂèØËÉΩÈõ£‰ª•Êáâ‰ªòÂÉÖÊúâÂ∞ëÊï∏Ê®ôÁ±§ÁØÑ‰æãÂèØÁî®ÁöÑ‰ΩéË≥áÊ∫êÂ†¥ÊôØ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ª•‰ª£ÁêÜÁÇ∫Âü∫Á§éÁöÑ‰ΩéË≥áÊ∫êÊúâÂÆ≥Ëø∑Âõ†ÂÅµÊ∏¨Êû∂ÊßãÔºåÊé°Áî®Â§ñÂêëÂíåÂÖßÂêëÂàÜÊûêÔºå‰∏¶Êê≠ÈÖçÂ∞ëÊï∏Ë®ªËß£ÁØÑ‰æã„ÄÇÂèóÊÉ†ÊñºÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°Âûã (LMM) Âú®Â§öÊ®°ÊÖãÊé®ÁêÜ‰∏äÁöÑÂº∑Â§ßËÉΩÂäõÔºåÊàëÂÄëÈ¶ñÂÖàÊì∑ÂèñÂ∏∂ÊúâË®ªËß£ÁöÑÁõ∏ÈóúËø∑Âõ†Ôºå‰ª•Âà©Áî®Ê®ôÁ±§Ë≥áË®ä‰ΩúÁÇ∫ LMM ‰ª£ÁêÜÁöÑËºîÂä©Ë®äËôü„ÄÇÊé•ËëóÔºåÊàëÂÄëÂú® LMM ‰ª£ÁêÜÂÖßÂºïÁôºÁü•Ë≠ò‰øÆÊ≠£Ë°åÁÇ∫Ôºå‰ª•Êé®Â∞éÂá∫Â∞çËø∑Âõ†Âç±ÂÆ≥ÊÄßÁöÑËâØÂ•ΩÊ¶ÇÂåñË¶ãËß£„ÄÇÈÄèÈÅéÁµêÂêàÈÄô‰∫õÁ≠ñÁï•ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïËÉΩÂ§†Â∞çË§áÈõú‰∏îÈö±Âê´ÁöÑÂç±ÂÆ≥ÊåáÁ§∫Ê®°ÂºèÈÄ≤Ë°åËæØË≠âÊé®ÁêÜ„ÄÇÂú®‰∏âÂÄãËø∑Âõ†Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®‰ΩéË≥áÊ∫êÊúâÂÆ≥Ëø∑Âõ†ÂÅµÊ∏¨‰ªªÂãô‰∏äÔºåË°®ÁèæÂÑ™ÊñºÁèæÊúâÊäÄË°ì„ÄÇ

##### **Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking**
2411.05375v1 by Mubashara Akhtar, Michael Schlichtkrull, Andreas Vlachos

Current automated fact-checking (AFC) approaches commonly evaluate evidence
either implicitly via the predicted verdicts or by comparing retrieved evidence
with a predefined closed knowledge source, such as Wikipedia. However, these
methods suffer from limitations, resulting from their reliance on evaluation
metrics developed for different purposes and constraints imposed by closed
knowledge sources. Recent advances in natural language generation (NLG)
evaluation offer new possibilities for evidence assessment. In this work, we
introduce Ev2R, an evaluation framework for AFC that comprises three types of
approaches for evidence evaluation: reference-based, proxy-reference, and
reference-less. We evaluate their effectiveness through agreement with human
ratings and adversarial tests, and demonstrate that prompt-based scorers,
particularly those leveraging LLMs and reference evidence, outperform
traditional evaluation approaches.

ÊëòË¶ÅÔºöÁï∂ÂâçËá™Âãï‰∫ãÂØ¶Êü•Ê†∏ (AFC) ÊñπÊ≥ïÈÄöÂ∏∏ÈÄèÈÅéÈ†êÊ∏¨Âà§Ê±∫ÊàñÂ∞áÊ™¢Á¥¢Âà∞ÁöÑË≠âÊìöËàáÈ†êÂÖàÂÆöÁæ©ÁöÑÂ∞ÅÈñâÁü•Ë≠ò‰æÜÊ∫êÔºà‰æãÂ¶ÇÁ∂≠Âü∫ÁôæÁßëÔºâÈÄ≤Ë°åÊØîËºÉÔºå‰æÜÈö±Âê´Âú∞Ë©ï‰º∞Ë≠âÊìö„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂ≠òÂú®ÈôêÂà∂ÔºåÂéüÂõ†Âú®ÊñºÂÆÉÂÄë‰æùË≥¥ÊñºÈáùÂ∞ç‰∏çÂêåÁõÆÁöÑËÄåÈñãÁôºÁöÑË©ï‰º∞ÊåáÊ®ôÔºå‰ª•ÂèäÂ∞ÅÈñâÁü•Ë≠ò‰æÜÊ∫êÊñΩÂä†ÁöÑÈôêÂà∂„ÄÇËá™ÁÑ∂Ë™ûË®ÄÁîüÊàê (NLG) Ë©ï‰º∞ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÁÇ∫Ë≠âÊìöË©ï‰º∞Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Ev2RÔºå‰∏ÄÁ®Æ AFC Ë©ï‰º∞Êû∂ÊßãÔºåÂåÖÂê´‰∏âÁ®ÆÈ°ûÂûãÁöÑË≠âÊìöË©ï‰º∞ÊñπÊ≥ïÔºöÂü∫ÊñºÂèÉËÄÉ„ÄÅ‰ª£ÁêÜÂèÉËÄÉÂíåÁÑ°ÂèÉËÄÉ„ÄÇÊàëÂÄëÈÄèÈÅéËàá‰∫∫È°ûË©ïÂàÜÂíåÂ∞çÊäóÊÄßÊ∏¨Ë©¶ÁöÑ‰∏ÄËá¥ÊÄß‰æÜË©ï‰º∞ÂÆÉÂÄëÁöÑÊúâÊïàÊÄßÔºå‰∏¶Ë≠âÊòéÂü∫ÊñºÊèêÁ§∫ÁöÑË©ïÂàÜËÄÖÔºåÁâπÂà•ÊòØÈÇ£‰∫õÂà©Áî® LLM ÂíåÂèÉËÄÉË≠âÊìöÁöÑË©ïÂàÜËÄÖÔºåÂÑ™ÊñºÂÇ≥Áµ±ÁöÑË©ï‰º∞ÊñπÊ≥ï„ÄÇ

##### **Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks**
2411.05361v1 by Chien-yu Huang, Wei-Chih Chen, Shu-wen Yang, Andy T. Liu, Chen-An Li, Yu-Xiang Lin, Wei-Cheng Tseng, Anuj Diwan, Yi-Jen Shih, Jiatong Shi, William Chen, Xuanjun Chen, Chi-Yuan Hsiao, Puyuan Peng, Shih-Heng Wang, Chun-Yi Kuan, Ke-Han Lu, Kai-Wei Chang, Chih-Kai Yang, Fabian Ritter-Gutierrez, Ming To Chuang, Kuan-Po Huang, Siddhant Arora, You-Kuan Lin, Eunjung Yeo, Kalvin Chang, Chung-Ming Chien, Kwanghee Choi, Cheng-Hsiu Hsieh, Yi-Cheng Lin, Chee-En Yu, I-Hsiang Chiu, Heitor R. Guimar√£es, Jionghao Han, Tzu-Quan Lin, Tzu-Yuan Lin, Homu Chang, Ting-Wu Chang, Chun Wei Chen, Shou-Jen Chen, Yu-Hua Chen, Hsi-Chun Cheng, Kunal Dhawan, Jia-Lin Fang, Shi-Xin Fang, Kuan-Yu Fang Chiang, Chi An Fu, Hsien-Fu Hsiao, Ching Yu Hsu, Shao-Syuan Huang, Lee Chen Wei, Hsi-Che Lin, Hsuan-Hao Lin, Hsuan-Ting Lin, Jian-Ren Lin, Ting-Chun Liu, Li-Chun Lu, Tsung-Min Pai, Ankita Pasad, Shih-Yun Shan Kuan, Suwon Shon, Yuxun Tang, Yun-Shao Tsai, Jui-Chiang Wei, Tzu-Chieh Wei, Chengxi Wu, Dien-Ruei Wu, Chao-Han Huck Yang, Chieh-Chi Yang, Jia Qi Yip, Shao-Xiang Yuan, Vahid Noroozi, Zhehuai Chen, Haibin Wu, Karen Livescu, David Harwath, Shinji Watanabe, Hung-yi Lee

Multimodal foundation models, such as Gemini and ChatGPT, have revolutionized
human-machine interactions by seamlessly integrating various forms of data.
Developing a universal spoken language model that comprehends a wide range of
natural language instructions is critical for bridging communication gaps and
facilitating more intuitive interactions. However, the absence of a
comprehensive evaluation benchmark poses a significant challenge. We present
Dynamic-SUPERB Phase-2, an open and evolving benchmark for the comprehensive
evaluation of instruction-based universal speech models. Building upon the
first generation, this second version incorporates 125 new tasks contributed
collaboratively by the global research community, expanding the benchmark to a
total of 180 tasks, making it the largest benchmark for speech and audio
evaluation. While the first generation of Dynamic-SUPERB was limited to
classification tasks, Dynamic-SUPERB Phase-2 broadens its evaluation
capabilities by introducing a wide array of novel and diverse tasks, including
regression and sequence generation, across speech, music, and environmental
audio. Evaluation results indicate that none of the models performed well
universally. SALMONN-13B excelled in English ASR, while WavLLM demonstrated
high accuracy in emotion recognition, but current models still require further
innovations to handle a broader range of tasks. We will soon open-source all
task data and the evaluation pipeline.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂü∫Á°ÄÊ®°ÂûãÔºå‰æãÂ¶Ç Gemini Âíå ChatGPTÔºåÈÄöËøáÊó†ÁºùÈõÜÊàêÂêÑÁßçÂΩ¢ÂºèÁöÑÊï∞ÊçÆÔºåÂΩªÂ∫ïÊîπÂèò‰∫Ü‰∫∫Êú∫‰∫§‰∫í„ÄÇÂºÄÂèë‰∏Ä‰∏™ÁêÜËß£ÂπøÊ≥õËá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§ÁöÑÈÄöÁî®Âè£ËØ≠ËØ≠Ë®ÄÊ®°ÂûãÂØπ‰∫éÂº•ÂêàÊ≤üÈÄöÈ∏øÊ≤üÂíå‰øÉËøõÊõ¥Áõ¥ËßÇÁöÑ‰∫§‰∫íËá≥ÂÖ≥ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁº∫‰πèÁªºÂêàËØÑ‰º∞Âü∫ÂáÜÊûÑÊàê‰∫ÜÈáçÂ§ßÊåëÊàò„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü Dynamic-SUPERB 2 Èò∂ÊÆµÔºåËøôÊòØ‰∏Ä‰∏™ÂºÄÊîæ‰∏î‰∏çÊñ≠ÂèëÂ±ïÁöÑÂü∫ÂáÜÔºåÁî®‰∫éÂØπÂü∫‰∫éÊåá‰ª§ÁöÑÈÄöÁî®ËØ≠Èü≥Ê®°ÂûãËøõË°åÁªºÂêàËØÑ‰º∞„ÄÇÂú®Ê≠§Á¨¨‰∏Ä‰ª£ÁöÑÂü∫Á°Ä‰∏äÔºåÊ≠§Á¨¨‰∫åÁâàÁ∫≥ÂÖ•‰∫ÜÁî±ÂÖ®ÁêÉÁ†îÁ©∂ÁïåÂçè‰ΩúË¥°ÁåÆÁöÑ 125 È°πÊñ∞‰ªªÂä°ÔºåÂ∞ÜÂü∫ÂáÜÊâ©Â±ïÂà∞ÊÄªÂÖ± 180 È°π‰ªªÂä°Ôºå‰ΩøÂÖ∂Êàê‰∏∫ËØ≠Èü≥ÂíåÈü≥È¢ëËØÑ‰º∞‰∏≠ÊúÄÂ§ßÁöÑÂü∫ÂáÜ„ÄÇËôΩÁÑ∂Á¨¨‰∏Ä‰ª£ Dynamic-SUPERB ‰ªÖÈôê‰∫éÂàÜÁ±ª‰ªªÂä°Ôºå‰ΩÜ Dynamic-SUPERB 2 Èò∂ÊÆµÈÄöËøáÂºïÂÖ•ÂπøÊ≥õÁöÑÊñ∞È¢ñ‰∏îÂ§öÊ†∑ÁöÑ‰ªªÂä°ÔºåÂåÖÊã¨ÂõûÂΩíÂíåÂ∫èÂàóÁîüÊàêÔºåË∑®Ë∂äËØ≠Èü≥„ÄÅÈü≥‰πêÂíåÁéØÂ¢ÉÈü≥È¢ëÔºåÊâ©Â±ï‰∫ÜÂÖ∂ËØÑ‰º∞ËÉΩÂäõ„ÄÇËØÑ‰º∞ÁªìÊûúË°®ÊòéÔºåÊ≤°Êúâ‰∏Ä‰∏™Ê®°ÂûãÂú®ÊâÄÊúâÊñπÈù¢Ë°®Áé∞ËâØÂ•Ω„ÄÇSALMONN-13B Âú®Ëã±ËØ≠ ASR ‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåËÄå WavLLM Âú®ÊÉÖÁª™ËØÜÂà´ÊñπÈù¢Ë°®Áé∞Âá∫ÂæàÈ´òÁöÑÂáÜÁ°ÆÊÄßÔºå‰ΩÜÂΩìÂâçÊ®°Âûã‰ªçÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÂàõÊñ∞ÊâçËÉΩÂ§ÑÁêÜÊõ¥ÂπøÊ≥õÁöÑ‰ªªÂä°„ÄÇÊàë‰ª¨ÂæàÂø´Â∞ÜÂºÄÊ∫êÊâÄÊúâ‰ªªÂä°Êï∞ÊçÆÂíåËØÑ‰º∞ÁÆ°ÈÅì„ÄÇ

##### **Agricultural Landscape Understanding At Country-Scale**
2411.05359v1 by Radhika Dua, Nikita Saxena, Aditi Agarwal, Alex Wilson, Gaurav Singh, Hoang Tran, Ishan Deshpande, Amandeep Kaur, Gaurav Aggarwal, Chandan Nath, Arnab Basu, Vishal Batchu, Sharath Holla, Bindiya Kurle, Olana Missura, Rahul Aggarwal, Shubhika Garg, Nishi Shah, Avneet Singh, Dinesh Tewari, Agata Dondzik, Bharat Adsul, Milind Sohoni, Asim Rama Praveen, Aaryan Dangi, Lisan Kadivar, E Abhishek, Niranjan Sudhansu, Kamlakar Hattekar, Sameer Datar, Musty Krishna Chaithanya, Anumas Ranjith Reddy, Aashish Kumar, Betala Laxmi Tirumala, Alok Talekar

Agricultural landscapes are quite complex, especially in the Global South
where fields are smaller, and agricultural practices are more varied. In this
paper we report on our progress in digitizing the agricultural landscape
(natural and man-made) in our study region of India. We use high resolution
imagery and a UNet style segmentation model to generate the first of its kind
national-scale multi-class panoptic segmentation output. Through this work we
have been able to identify individual fields across 151.7M hectares, and
delineating key features such as water resources and vegetation. We share how
this output was validated by our team and externally by downstream users,
including some sample use cases that can lead to targeted data driven decision
making. We believe this dataset will contribute towards digitizing agriculture
by generating the foundational baselayer.

ÊëòË¶ÅÔºöËæ≤Ê•≠ÊôØËßÄÈùûÂ∏∏Ë§áÈõúÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÖ®ÁêÉÂçóÊñπÔºåÈÇ£Ë£°ÁöÑÁî∞Âú∞ËºÉÂ∞èÔºåËæ≤Ê•≠ÂØ¶Âãô‰πüÊõ¥Â§öÊ®£Âåñ„ÄÇÂú®ÈÄôÁØáË´ñÊñá‰∏≠ÔºåÊàëÂÄëÂ†±Âëä‰∫ÜÊàëÂÄëÂú®Â∞áÂç∞Â∫¶Á†îÁ©∂ÂçÄÂüüÁöÑËæ≤Ê•≠ÊôØËßÄÔºàÂ§©ÁÑ∂Âíå‰∫∫ÈÄ†ÔºâÊï∏‰ΩçÂåñÁöÑÈÄ≤Â±ï„ÄÇÊàëÂÄë‰ΩøÁî®È´òËß£ÊûêÂ∫¶ÂΩ±ÂÉèÂíå UNet È¢®Ê†ºÁöÑÂàÜÂâ≤Ê®°ÂûãÔºåÁî¢Áîü‰∫ÜÈ¶ñÂÄãÂÖ®ÂúãÊÄßÁöÑÂ§öÈ°ûÂà•ÂÖ®ÊôØÂàÜÂâ≤Ëº∏Âá∫„ÄÇÈÄèÈÅéÈÄôÈ†ÖÂ∑•‰ΩúÔºåÊàëÂÄëÂ∑≤Á∂ìËÉΩÂ§†Ë≠òÂà•Âá∫ 151.7M ÂÖ¨È†ÉÁöÑÂÄãÂà•Áî∞Âú∞Ôºå‰∏¶ÊèèÁπ™Âá∫Ê∞¥Ë≥áÊ∫êÂíåÊ§çË¢´Á≠âÈóúÈçµÁâπÂæµ„ÄÇÊàëÂÄëÂàÜ‰∫´‰∫ÜÊàëÂÄëÁöÑÂúòÈöäÂíå‰∏ãÊ∏∏‰ΩøÁî®ËÄÖÂ¶Ç‰ΩïÈ©óË≠âÊ≠§Ëº∏Âá∫ÔºåÂåÖÊã¨‰∏Ä‰∫õÁØÑ‰æã‰ΩøÁî®Ê°à‰æãÔºåÈÄô‰∫õÊ°à‰æãÂèØËÉΩÊúÉÂ∞éËá¥ÊúâÈáùÂ∞çÊÄßÁöÑË≥áÊñôÈ©ÖÂãïÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄôÂÄãË≥áÊñôÈõÜÂ∞áÈÄèÈÅéÁî¢ÁîüÂü∫Á§éÂ∫ïÂ±§ÔºåÊúâÂä©ÊñºÊï∏‰ΩçÂåñËæ≤Ê•≠„ÄÇ

##### **Controlling Grokking with Nonlinearity and Data Symmetry**
2411.05353v1 by Ahmed Salah, David Yevick

This paper demonstrates that grokking behavior in modular arithmetic with a
modulus P in a neural network can be controlled by modifying the profile of the
activation function as well as the depth and width of the model. Plotting the
even PCA projections of the weights of the last NN layer against their odd
projections further yields patterns which become significantly more uniform
when the nonlinearity is increased by incrementing the number of layers. These
patterns can be employed to factor P when P is nonprime. Finally, a metric for
the generalization ability of the network is inferred from the entropy of the
layer weights while the degree of nonlinearity is related to correlations
between the local entropy of the weights of the neurons in the final layer.

ÊëòË¶ÅÔºöÊú¨ÊñáÊºîÁ§∫‰∫ÜÈÄöËøá‰øÆÊîπÊøÄÊ¥ªÂáΩÊï∞ÁöÑËΩÆÂªì‰ª•ÂèäÊ®°ÂûãÁöÑÊ∑±Â∫¶ÂíåÂÆΩÂ∫¶ÔºåÂèØ‰ª•Âú®Á•ûÁªèÁΩëÁªú‰∏≠ÊéßÂà∂Ê®°ÁÆóÊúØ‰∏≠ÁöÑ grokking Ë°å‰∏∫ÔºåÊ®°Êï∞ P„ÄÇÁªòÂà∂ÊúÄÂêé‰∏ÄÂ±Ç NN ÊùÉÈáçÁöÑÂÅ∂ PCA ÊäïÂΩ±‰∏éÂÖ∂Â•áÊäïÂΩ±ÔºåËøõ‰∏ÄÊ≠•‰∫ßÁîü‰∫ÜÊ®°ÂºèÔºåÂΩìÈùûÁ∫øÊÄßÈÄöËøáÂ¢ûÂä†Â±ÇÊï∞ËÄåÂ¢ûÂä†Êó∂ÔºåËøô‰∫õÊ®°ÂºèÂèòÂæóÊõ¥Âä†Áªü‰∏Ä„ÄÇÂΩì P ‰∏∫ÈùûÁ¥†Êï∞Êó∂ÔºåËøô‰∫õÊ®°ÂºèÂèØÁî®‰∫éÂàÜËß£ P„ÄÇÊúÄÂêéÔºå‰ªéÂ±ÇÊùÉÈáçÁöÑÁÜµÊé®Êñ≠Âá∫ÁΩëÁªúÊ≥õÂåñËÉΩÂäõÁöÑÂ∫¶ÈáèÔºåËÄåÈùûÁ∫øÊÄßÁ®ãÂ∫¶‰∏éÊúÄÁªàÂ±Ç‰∏≠Á•ûÁªèÂÖÉÊùÉÈáçÁöÑÂ±ÄÈÉ®ÁÜµ‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄßÊúâÂÖ≥„ÄÇ

##### **Enhancing Cluster Resilience: LLM-agent Based Autonomous Intelligent Cluster Diagnosis System and Evaluation Framework**
2411.05349v1 by Honghao Shi, Longkai Cheng, Wenli Wu, Yuhang Wang, Xuan Liu, Shaokai Nie, Weixv Wang, Xuebin Min, Chunlei Men, Yonghua Lin

Recent advancements in Large Language Models (LLMs) and related technologies
such as Retrieval-Augmented Generation (RAG) and Diagram of Thought (DoT) have
enabled the creation of autonomous intelligent systems capable of performing
cluster diagnostics and troubleshooting. By integrating these technologies with
self-play methodologies, we have developed an LLM-agent system designed to
autonomously diagnose and resolve issues within AI clusters. Our innovations
include a knowledge base tailored for cluster diagnostics, enhanced LLM
algorithms, practical deployment strategies for agents, and a benchmark
specifically designed for evaluating LLM capabilities in this domain. Through
extensive experimentation across multiple dimensions, we have demonstrated the
superiority of our system in addressing the challenges faced in cluster
diagnostics, particularly in detecting and rectifying performance issues more
efficiently and accurately than traditional methods.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁõ∏ÈóúÊäÄË°ìÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºå‰æãÂ¶ÇÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÂíåÊÄùÊÉ≥Âúñ (DoT)ÔºåÂ∑≤Á∂ìËÉΩÂ§†Âª∫Á´ãËá™‰∏ªÊô∫ÊÖßÁ≥ªÁµ±ÔºåÂü∑Ë°åÁæ§ÈõÜË®∫Êñ∑ÂíåÊïÖÈöúÊéíÈô§„ÄÇÈÄèÈÅéÂ∞áÈÄô‰∫õÊäÄË°ìËàáËá™Â∞çÂºàÊñπÊ≥ïÊï¥ÂêàÔºåÊàëÂÄëÈñãÁôºÂá∫ LLM ‰ª£ÁêÜÁ≥ªÁµ±ÔºåÊó®Âú®Ëá™‰∏ªË®∫Êñ∑ÂíåËß£Ê±∫ AI Áæ§ÈõÜ‰∏≠ÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂâµÊñ∞ÂåÖÊã¨ÈáùÂ∞çÁæ§ÈõÜË®∫Êñ∑ÈáèË∫´ÊâìÈÄ†ÁöÑÁü•Ë≠òÂ∫´„ÄÅÂ¢ûÂº∑ÁöÑ LLM ÊºîÁÆóÊ≥ï„ÄÅ‰ª£ÁêÜÂØ¶Áî®ÁöÑÈÉ®ÁΩ≤Á≠ñÁï•Ôºå‰ª•ÂèäÂ∞àÈñÄÁî®ÊñºË©ï‰º∞ LLM Âú®Ê≠§È†òÂüüËÉΩÂäõÁöÑÂü∫Ê∫ñ„ÄÇÈÄèÈÅéÂ§öÂÄãÈù¢ÂêëÁöÑÂª£Ê≥õÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÁ≥ªÁµ±Âú®Ëß£Ê±∫Áæ§ÈõÜË®∫Êñ∑‰∏≠ÊâÄÈù¢Ëá®ÊåëÊà∞ÊñπÈù¢ÁöÑÂÑ™Ë∂äÊÄßÔºåÁâπÂà•ÊòØÂú®ÊØîÂÇ≥Áµ±ÊñπÊ≥ïÊõ¥ÊúâÊïàÁéáÂíåÊ∫ñÁ¢∫Âú∞ÂÅµÊ∏¨Âíå‰øÆÊ≠£ÊïàËÉΩÂïèÈ°åÊñπÈù¢„ÄÇ

##### **LLM-PySC2: Starcraft II learning environment for Large Language Models**
2411.05348v1 by Zongyuan Li, Yanan Ni, Runnan Qi, Lumin Jiang, Chang Lu, Xiaojie Xu, Xiangbei Liu, Pengfei Li, Yunzheng Guo, Zhe Ma, Xian Guo, Kuihua Huang, Xuebo Zhang

This paper introduces a new environment LLM-PySC2 (the Large Language Model
StarCraft II Learning Environment), a platform derived from DeepMind's
StarCraft II Learning Environment that serves to develop Large Language Models
(LLMs) based decision-making methodologies. This environment is the first to
offer the complete StarCraft II action space, multi-modal observation
interfaces, and a structured game knowledge database, which are seamlessly
connected with various LLMs to facilitate the research of LLMs-based
decision-making. To further support multi-agent research, we developed an LLM
collaborative framework that supports multi-agent concurrent queries and
multi-agent communication. In our experiments, the LLM-PySC2 environment is
adapted to be compatible with the StarCraft Multi-Agent Challenge (SMAC) task
group and provided eight new scenarios focused on macro-decision abilities. We
evaluated nine mainstream LLMs in the experiments, and results show that
sufficient parameters are necessary for LLMs to make decisions, but improving
reasoning ability does not directly lead to better decision-making outcomes.
Our findings further indicate the importance of enabling large models to learn
autonomously in the deployment environment through parameter training or
train-free learning techniques. Ultimately, we expect that the LLM-PySC2
environment can promote research on learning methods for LLMs, helping
LLM-based methods better adapt to task scenarios.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞Áí∞Â¢É LLM-PySC2 (Â§ßÂûãË™ûË®ÄÊ®°ÂûãÊòüÊµ∑Áà≠Èú∏ II Â≠∏ÁøíÁí∞Â¢É)Ôºå‰∏ÄÂÄãÊ∫êËá™ DeepMind ÁöÑÊòüÊµ∑Áà≠Èú∏ II Â≠∏ÁøíÁí∞Â¢ÉÁöÑÂπ≥Âè∞ÔºåÁî®ÊñºÈñãÁôºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫Âü∫Á§éÁöÑÊ±∫Á≠ñÂà∂ÂÆöÊñπÊ≥ï„ÄÇÊ≠§Áí∞Â¢ÉÊòØÁ¨¨‰∏ÄÂÄãÊèê‰æõÂÆåÊï¥ÁöÑÊòüÊµ∑Áà≠Èú∏ II Âãï‰ΩúÁ©∫Èñì„ÄÅÂ§öÊ®°ÂºèËßÄÂØü‰ªãÈù¢ÂíåÁµêÊßãÂåñÈÅäÊà≤Áü•Ë≠òË≥áÊñôÂ∫´ÁöÑÁí∞Â¢ÉÔºåÈÄô‰∫õÁí∞Â¢ÉËàáÂêÑÁ®Æ LLM ÁÑ°Á∏´ÈÄ£Êé•Ôºå‰ª•‰æøÊñºÁ†îÁ©∂Âü∫Êñº LLM ÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊîØÊè¥Â§öÈáç‰ª£ÁêÜÁ†îÁ©∂ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄã LLM Âçî‰ΩúÊû∂ÊßãÔºåÊîØÊè¥Â§öÈáç‰ª£ÁêÜ‰∏¶ÁôºÊü•Ë©¢ÂíåÂ§öÈáç‰ª£ÁêÜÊ∫ùÈÄö„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåLLM-PySC2 Áí∞Â¢ÉÁ∂ìÈÅéË™øÊï¥ÔºåËàáÊòüÊµ∑Áà≠Èú∏Â§öÈáç‰ª£ÁêÜÊåëÊà∞ (SMAC) ‰ªªÂãôÁµÑÁõ∏ÂÆπÔºå‰∏¶Êèê‰æõ‰∫ÜÂÖ´ÂÄãÊñ∞ÁöÑÂ†¥ÊôØÔºåÂ∞àÊ≥®ÊñºÂ∑®ËßÄÊ±∫Á≠ñËÉΩÂäõ„ÄÇÊàëÂÄëÂú®ÂØ¶È©ó‰∏≠Ë©ï‰º∞‰∫Ü‰πùÂÄã‰∏ªÊµÅ LLMÔºåÁµêÊûúÈ°ØÁ§∫ÔºåLLM Ë¶ÅÂÅöÂá∫Ê±∫Á≠ñÈúÄË¶ÅË∂≥Â§†ÁöÑÂèÉÊï∏Ôºå‰ΩÜÊîπÂñÑÊé®ÁêÜËÉΩÂäõ‰∏¶‰∏çÊúÉÁõ¥Êé•Â∞éËá¥Êõ¥Â•ΩÁöÑÊ±∫Á≠ñÂà∂ÂÆöÁµêÊûú„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈÄ≤‰∏ÄÊ≠•Ë°®ÊòéÔºåËÆìÂ§ßÂûãÊ®°ÂûãËÉΩÂ§†ÈÄèÈÅéÂèÉÊï∏Ë®ìÁ∑¥ÊàñÂÖçË®ìÁ∑¥Â≠∏ÁøíÊäÄË°ìÂú®ÈÉ®ÁΩ≤Áí∞Â¢É‰∏≠Ëá™‰∏ªÂ≠∏ÁøíÈùûÂ∏∏ÈáçË¶Å„ÄÇÊúÄÁµÇÔºåÊàëÂÄëÈ†êÊúü LLM-PySC2 Áí∞Â¢ÉÂèØ‰ª•‰øÉÈÄ≤ LLM Â≠∏ÁøíÊñπÊ≥ïÁöÑÁ†îÁ©∂ÔºåÂçîÂä©Âü∫Êñº LLM ÁöÑÊñπÊ≥ïÊõ¥Â•ΩÂú∞ÈÅ©Êáâ‰ªªÂãôÂ†¥ÊôØ„ÄÇ

##### **Reasoning Robustness of LLMs to Adversarial Typographical Errors**
2411.05345v1 by Esther Gan, Yiran Zhao, Liying Cheng, Yancan Mao, Anirudh Goyal, Kenji Kawaguchi, Min-Yen Kan, Michael Shieh

Large Language Models (LLMs) have demonstrated impressive capabilities in
reasoning using Chain-of-Thought (CoT) prompting. However, CoT can be biased by
users' instruction. In this work, we study the reasoning robustness of LLMs to
typographical errors, which can naturally occur in users' queries. We design an
Adversarial Typo Attack ($\texttt{ATA}$) algorithm that iteratively samples
typos for words that are important to the query and selects the edit that is
most likely to succeed in attacking. It shows that LLMs are sensitive to
minimal adversarial typographical changes. Notably, with 1 character edit,
Mistral-7B-Instruct's accuracy drops from 43.7% to 38.6% on GSM8K, while with 8
character edits the performance further drops to 19.2%. To extend our
evaluation to larger and closed-source LLMs, we develop the $\texttt{R$^2$ATA}$
benchmark, which assesses models' $\underline{R}$easoning
$\underline{R}$obustness to $\underline{\texttt{ATA}}$. It includes adversarial
typographical questions derived from three widely used reasoning
datasets-GSM8K, BBH, and MMLU-by applying $\texttt{ATA}$ to open-source LLMs.
$\texttt{R$^2$ATA}$ demonstrates remarkable transferability and causes notable
performance drops across multiple super large and closed-source LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®‰ΩøÁî®ÊÄùËÄÉÈèà (CoT) ÊèêÁ§∫ÈÄ≤Ë°åÊé®ÁêÜÊñπÈù¢Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåCoT ÂèØËÉΩÊúÉÂèóÂà∞‰ΩøÁî®ËÄÖÊåá‰ª§ÁöÑÂΩ±Èüø„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü LLM Â∞çÂç∞Âà∑ÈåØË™§ÁöÑÊé®ÁêÜÁ©©ÂÅ•ÊÄßÔºåÈÄôÂèØËÉΩÊúÉËá™ÁÑ∂ÁôºÁîüÂú®‰ΩøÁî®ËÄÖÁöÑÊü•Ë©¢‰∏≠„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÂ∞çÊäóÊÄßÂç∞Âà∑ÊîªÊìä (ATA) ÊºîÁÆóÊ≥ïÔºåË©≤ÊºîÁÆóÊ≥ïÊúÉÂèçË¶ÜÂ∞çÊü•Ë©¢‰∏≠ÈáçË¶ÅÁöÑÂ≠óË©ûÈÄ≤Ë°åÂç∞Âà∑ÈåØË™§ÂèñÊ®£Ôºå‰∏¶ÈÅ∏ÊìáÊúÄÊúâÂèØËÉΩÊàêÂäüÊîªÊìäÁöÑÁ∑®ËºØÂÖßÂÆπ„ÄÇÂÆÉÈ°ØÁ§∫Âá∫ LLM Â∞çÊúÄÂ∞èÁöÑÂ∞çÊäóÊÄßÂç∞Âà∑ËÆäÊõ¥ÂæàÊïèÊÑü„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú® 1 ÂÄãÂ≠óÂÖÉÁ∑®ËºØ‰∏ãÔºåMistral-7B-Instruct Âú® GSM8K ‰∏äÁöÑÊ∫ñÁ¢∫Â∫¶Âæû 43.7% ÈôçËá≥ 38.6%ÔºåËÄåÂú® 8 ÂÄãÂ≠óÂÖÉÁ∑®ËºØ‰∏ãÔºåÊïàËÉΩÈÄ≤‰∏ÄÊ≠•ÈôçËá≥ 19.2%„ÄÇÁÇ∫‰∫ÜÂ∞áÊàëÂÄëÁöÑË©ï‰º∞Êì¥Â±ïÂà∞Êõ¥Â§ß‰∏îÂ∞ÅÈñâÂéüÂßãÁ¢ºÁöÑ LLMÔºåÊàëÂÄëÈñãÁôº‰∫Ü R2ATA Âü∫Ê∫ñÔºåË©≤Âü∫Ê∫ñË©ï‰º∞Ê®°ÂûãÂ∞ç ATA ÁöÑÊé®ÁêÜÁ©©ÂÅ•ÊÄß„ÄÇÂÆÉÂåÖÂê´ÈÄèÈÅéÂ∞á ATA Â•óÁî®ÊñºÈñãÊîæÂéüÂßãÁ¢º LLMÔºåÂæû‰∏âÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÊé®ÁêÜË≥áÊñôÈõÜ (GSM8K„ÄÅBBH Âíå MMLU) ‰∏≠Ë°çÁîüÁöÑÂ∞çÊäóÊÄßÂç∞Âà∑ÂïèÈ°å„ÄÇR2ATA Ë°®ÁèæÂá∫È°ØËëóÁöÑÂèØËΩâÁßªÊÄßÔºå‰∏¶Â∞éËá¥Â§öÂÄãË∂ÖÂ§ßÂûã‰∏îÂ∞ÅÈñâÂéüÂßãÁ¢ºÁöÑ LLM ÊïàËÉΩÂ§ßÂπÖ‰∏ãÈôç„ÄÇ

##### **Improving Multi-Domain Task-Oriented Dialogue System with Offline Reinforcement Learning**
2411.05340v1 by Dharmendra Prajapat, Durga Toshniwal

Task-oriented dialogue (TOD) system is designed to accomplish user-defined
tasks through dialogues. The TOD system has progressed towards end-to-end
modeling by leveraging pre-trained large language models. Fine-tuning the
pre-trained language models using only supervised learning leads to the
exposure bias and token loss problem and it deviates the models from completing
the user's task. To address these issues, we propose a TOD system that
leverages a unified pre-trained language model, GPT2, as a base model. It is
optimized using supervised learning and reinforcement learning (RL). The issues
in the TOD system are mitigated using a non-differentiable reward function. The
reward is calculated using the weighted sum of the success rate and BLEU
evaluation metrics. The success rate and BLEU metrics in reward calculation
guide the language model for user task completion while ensuring a coherent and
fluent response. Our model is acquired by fine-tuning a pre-trained model on
the dialogue-session level which comprises user utterance, belief state, system
act, and system response. Experimental results on MultiWOZ2.1 demonstrate that
our model increases the inform rate by 1.60% and the success rate by 3.17%
compared to the baseline.

ÊëòË¶ÅÔºö‰ªªÂãôÂ∞éÂêëÂ∞çË©±ÔºàTODÔºâÁ≥ªÁµ±Êó®Âú®ÈÄèÈÅéÂ∞çË©±ÂÆåÊàê‰ΩøÁî®ËÄÖÂÆöÁæ©ÁöÑ‰ªªÂãô„ÄÇTOD Á≥ªÁµ±Â∑≤ÈÄèÈÅéÂà©Áî®È†êË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊúùÂêëÁ´ØÂ∞çÁ´ØÂª∫Ê®°ÈÇÅÈÄ≤„ÄÇÂÉÖ‰ΩøÁî®Áõ£Áù£ÂºèÂ≠∏ÁøíÂæÆË™øÈ†êË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°ÂûãÊúÉÂ∞éËá¥Êö¥Èú≤ÂÅèÂ∑ÆÂíåÊ¨äÊùñÊêçÂ§±ÂïèÈ°åÔºå‰∏¶‰ΩøÊ®°ÂûãÂÅèÈõ¢ÂÆåÊàê‰ΩøÁî®ËÄÖÁöÑ‰ªªÂãô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄã TOD Á≥ªÁµ±ÔºåÂÆÉÂà©Áî®Áµ±‰∏ÄÁöÑÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã GPT2 ‰ΩúÁÇ∫Âü∫Á§éÊ®°Âûã„ÄÇÂÆÉÊòØ‰ΩøÁî®Áõ£Áù£ÂºèÂ≠∏ÁøíÂíåÂº∑ÂåñÂ≠∏ÁøíÔºàRLÔºâÈÄ≤Ë°åÊúÄ‰Ω≥ÂåñÁöÑ„ÄÇTOD Á≥ªÁµ±‰∏≠ÁöÑÂïèÈ°åÈÄèÈÅé‰ΩøÁî®‰∏çÂèØÂæÆÂàÜÁöÑÁçéÂãµÂáΩÊï∏‰æÜÊ∏õËºï„ÄÇÁçéÂãµÊòØ‰ΩøÁî®ÊàêÂäüÁéáÂíå BLEU Ë©ï‰º∞ÊåáÊ®ôÁöÑÂä†Ê¨äÁ∏ΩÂíå‰æÜË®àÁÆóÁöÑ„ÄÇÁçéÂãµË®àÁÆó‰∏≠ÁöÑÊàêÂäüÁéáÂíå BLEU ÊåáÊ®ôÂºïÂ∞éË™ûË®ÄÊ®°ÂûãÂÆåÊàê‰ΩøÁî®ËÄÖ‰ªªÂãôÔºåÂêåÊôÇÁ¢∫‰øùÂõûÊáâÈÄ£Ë≤´‰∏îÊµÅÊö¢„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊòØÈÄèÈÅéÂæÆË™øÂ∞çË©±ÊúÉË©±Â±§Á¥öÁöÑÈ†êË®ìÁ∑¥Ê®°Âûã‰æÜÂèñÂæóÔºåÂÖ∂‰∏≠ÂåÖÂê´‰ΩøÁî®ËÄÖÁôºË®Ä„ÄÅ‰ø°ÂøµÁãÄÊÖã„ÄÅÁ≥ªÁµ±Âãï‰ΩúÂíåÁ≥ªÁµ±ÂõûÊáâ„ÄÇMultiWOZ2.1 ÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåËàáÂü∫Ê∫ñÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ∞áÂëäÁü•ÁéáÊèêÈ´ò‰∫Ü 1.60%ÔºåÊàêÂäüÁéáÊèêÈ´ò‰∫Ü 3.17%„ÄÇ

##### **SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers**
2411.05338v1 by Shruti Singh, Nandan Sarkar, Arman Cohan

Scientific literature is typically dense, requiring significant background
knowledge and deep comprehension for effective engagement. We introduce SciDQA,
a new dataset for reading comprehension that challenges LLMs for a deep
understanding of scientific articles, consisting of 2,937 QA pairs. Unlike
other scientific QA datasets, SciDQA sources questions from peer reviews by
domain experts and answers by paper authors, ensuring a thorough examination of
the literature. We enhance the dataset's quality through a process that
carefully filters out lower quality questions, decontextualizes the content,
tracks the source document across different versions, and incorporates a
bibliography for multi-document question-answering. Questions in SciDQA
necessitate reasoning across figures, tables, equations, appendices, and
supplementary materials, and require multi-document reasoning. We evaluate
several open-source and proprietary LLMs across various configurations to
explore their capabilities in generating relevant and factual responses. Our
comprehensive evaluation, based on metrics for surface-level similarity and LLM
judgements, highlights notable performance discrepancies. SciDQA represents a
rigorously curated, naturally derived scientific QA dataset, designed to
facilitate research on complex scientific text understanding.

ÊëòË¶ÅÔºöÁßëÂ≠∏ÊñáÁçªÈÄöÂ∏∏ÂæàÂØÜÈõÜÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑËÉåÊôØÁü•Ë≠òÂíåÊ∑±ÂÖ•ÁöÑÁêÜËß£ÊâçËÉΩÊúâÊïàÂèÉËàá„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü SciDQAÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞ÁöÑÈñ±ËÆÄÁêÜËß£Êï∏ÊìöÈõÜÔºåÂÆÉÊåëÊà∞ LLM Ê∑±ÂÖ•ÁêÜËß£ÁßëÂ≠∏ÊñáÁ´†ÔºåÂåÖÂê´ 2,937 ÂÄã QA Â∞ç„ÄÇËàáÂÖ∂‰ªñÁßëÂ≠∏ QA Êï∏ÊìöÈõÜ‰∏çÂêåÔºåSciDQA ÂæûÈ†òÂüüÂ∞àÂÆ∂ÁöÑÂêåË°åË©ïÂØ©ÂíåË´ñÊñá‰ΩúËÄÖÁöÑÂõûÁ≠î‰∏≠Áç≤ÂèñÂïèÈ°åÔºåÁ¢∫‰øùÂ∞çÊñáÁçªÈÄ≤Ë°åÂæπÂ∫ïÂØ©Êü•„ÄÇÊàëÂÄëÈÄöÈÅé‰∏ÄÂÄãÊµÅÁ®ãÊèêÈ´ò‰∫ÜÊï∏ÊìöÈõÜÁöÑË≥™ÈáèÔºåË©≤ÊµÅÁ®ã‰ªîÁ¥∞ÈÅéÊøæÊéâË≥™ÈáèËºÉ‰ΩéÁöÑÂïèÈ°åÔºåÂ∞çÂÖßÂÆπÈÄ≤Ë°åÂéªÊÉÖÂ¢ÉÂåñÔºåË∑®‰∏çÂêåÁâàÊú¨ËøΩËπ§ÂéüÂßãÊñá‰ª∂Ôºå‰∏¶ÁÇ∫Â§öÊñá‰ª∂ÂïèÁ≠îÁ¥çÂÖ•Êõ∏ÁõÆ„ÄÇSciDQA ‰∏≠ÁöÑÂïèÈ°åÈúÄË¶ÅÂ∞çÂúñË°®„ÄÅË°®Ê†º„ÄÅÊñπÁ®ãÂºè„ÄÅÈôÑÈåÑÂíåË£úÂÖÖÊùêÊñôÈÄ≤Ë°åÊé®ÁêÜÔºå‰∏¶‰∏îÈúÄË¶ÅÂ§öÊñá‰ª∂Êé®ÁêÜ„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂêÑÁ®ÆÈÖçÁΩÆÁöÑÂπæÂÄãÈñãÊ∫êÂíåÂ∞àÊúâ LLMÔºå‰ª•Êé¢Á¥¢ÂÆÉÂÄëÁîüÊàêÁõ∏ÈóúÂíå‰∫ãÂØ¶ÊÄßÂõûÊáâÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂü∫ÊñºË°®Èù¢Áõ∏‰ººÊÄßÂíå LLM Âà§Êñ∑ÁöÑÊåáÊ®ôÈÄ≤Ë°åÁöÑÁ∂úÂêàË©ï‰º∞Á™ÅÂá∫‰∫ÜÈ°ØËëóÁöÑÊÄßËÉΩÂ∑ÆÁï∞„ÄÇSciDQA ‰ª£Ë°®‰∫Ü‰∏ÄÂÄãÁ∂ìÈÅéÂö¥Ê†ºÁ≠ñÂäÉ„ÄÅËá™ÁÑ∂Ë°çÁîüÁöÑÁßëÂ≠∏ QA Êï∏ÊìöÈõÜÔºåÊó®Âú®‰øÉÈÄ≤Â∞çË§áÈõúÁßëÂ≠∏ÊñáÊú¨ÁêÜËß£ÁöÑÁ†îÁ©∂„ÄÇ

##### **Inversion-based Latent Bayesian Optimization**
2411.05330v1 by Jaewon Chu, Jinyoung Park, Seunghun Lee, Hyunwoo J. Kim

Latent Bayesian optimization (LBO) approaches have successfully adopted
Bayesian optimization over a continuous latent space by employing an
encoder-decoder architecture to address the challenge of optimization in a high
dimensional or discrete input space. LBO learns a surrogate model to
approximate the black-box objective function in the latent space. However, we
observed that most LBO methods suffer from the `misalignment problem`, which is
induced by the reconstruction error of the encoder-decoder architecture. It
hinders learning an accurate surrogate model and generating high-quality
solutions. In addition, several trust region-based LBO methods select the
anchor, the center of the trust region, based solely on the objective function
value without considering the trust region`s potential to enhance the
optimization process. To address these issues, we propose Inversion-based
Latent Bayesian Optimization (InvBO), a plug-and-play module for LBO. InvBO
consists of two components: an inversion method and a potential-aware trust
region anchor selection. The inversion method searches the latent code that
completely reconstructs the given target data. The potential-aware trust region
anchor selection considers the potential capability of the trust region for
better local optimization. Experimental results demonstrate the effectiveness
of InvBO on nine real-world benchmarks, such as molecule design and arithmetic
expression fitting tasks. Code is available at https://github.com/mlvlab/InvBO.

ÊëòË¶ÅÔºöÊΩõÂú®Ë≤ùÊ∞èÊúÄ‰Ω≥Âåñ (LBO) ÊñπÊ≥ïÂ∑≤ÊàêÂäüÊé°Áî®Âú®ÈÄ£Á∫åÊΩõÂú®Á©∫Èñì‰∏äÁöÑË≤ùÊ∞èÊúÄ‰Ω≥ÂåñÔºåÈÄèÈÅéÊé°Áî®Á∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Êû∂Êßã‰æÜËß£Ê±∫Âú®È´òÁ∂≠Â∫¶ÊàñÈõ¢Êï£Ëº∏ÂÖ•Á©∫Èñì‰∏≠ÊúÄ‰Ω≥ÂåñÁöÑÊåëÊà∞„ÄÇLBO Â≠∏Áøí‰∏ÄÂÄãÊõø‰ª£Ê®°Âûã‰æÜËøë‰ººÊΩõÂú®Á©∫Èñì‰∏≠ÁöÑÈªëÁõíÁõÆÊ®ôÂáΩÊï∏„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëËßÄÂØüÂà∞ÔºåÂ§ßÂ§öÊï∏ LBO ÊñπÊ≥ïÈÉΩÊúÉÈÅáÂà∞„ÄåÊú™Â∞çÈΩäÂïèÈ°å„ÄçÔºåÈÄôÊòØÁî±Á∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Êû∂ÊßãÁöÑÈáçÂª∫Ë™§Â∑ÆÊâÄÂºïÁôºÁöÑ„ÄÇÂÆÉÊúÉÈòªÁ§ôÂ≠∏ÁøíÊ∫ñÁ¢∫ÁöÑÊõø‰ª£Ê®°ÂûãÂíåÁî¢ÁîüÈ´òÂìÅË≥™ÁöÑËß£„ÄÇÊ≠§Â§ñÔºåË®±Â§öÂü∫Êñº‰ø°‰ªªÂçÄÂüüÁöÑ LBO ÊñπÊ≥ïÊúÉÊ†πÊìöÁõÆÊ®ôÂáΩÊï∏ÂÄº‰æÜÈÅ∏ÊìáÈå®ÈªûÔºà‰ø°‰ªªÂçÄÂüüÁöÑ‰∏≠ÂøÉÔºâÔºåËÄå‰∏çÊúÉËÄÉÊÖÆ‰ø°‰ªªÂçÄÂüüÂ¢ûÂº∑ÊúÄ‰Ω≥ÂåñÁ®ãÂ∫èÁöÑÊΩõÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫Âü∫ÊñºÂèçÊºîÁöÑÊΩõÂú®Ë≤ùÊ∞èÊúÄ‰Ω≥Âåñ (InvBO)Ôºå‰∏ÄÂÄã LBO ÁöÑÂç≥ÊèíÂç≥Áî®Ê®°ÁµÑ„ÄÇInvBO ÂåÖÂê´ÂÖ©ÂÄãÂÖÉ‰ª∂ÔºöÂèçÊºîÊñπÊ≥ïÂíåÂÖ∑ÊΩõÂäõÊÑüÁü•ÁöÑ‰ø°‰ªªÂçÄÂüüÈå®ÈªûÈÅ∏Êìá„ÄÇÂèçÊºîÊñπÊ≥ïÊúÉÊêúÂ∞ãÂÆåÂÖ®ÈáçÂª∫Áµ¶ÂÆöÁõÆÊ®ôË≥áÊñôÁöÑÊΩõÂú®‰ª£Á¢º„ÄÇÂÖ∑ÊΩõÂäõÊÑüÁü•ÁöÑ‰ø°‰ªªÂçÄÂüüÈå®ÈªûÈÅ∏ÊìáÊúÉËÄÉÊÖÆ‰ø°‰ªªÂçÄÂüüÁöÑÊΩõÂú®ËÉΩÂäõÔºå‰ª•ÈÄ≤Ë°åÊõ¥Â•ΩÁöÑÂ±ÄÈÉ®ÊúÄ‰Ω≥Âåñ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ InvBO Âú®‰πùÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÂü∫Ê∫ñ‰∏äÁöÑÊúâÊïàÊÄßÔºå‰æãÂ¶ÇÂàÜÂ≠êË®≠Ë®àÂíåÁÆóË°ìË°®ÈÅîÂºèÊì¨Âêà‰ªªÂãô„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/mlvlab/InvBO ÂèñÂæó„ÄÇ

##### **Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**
2411.05316v1 by Dong Shu, Bingbing Duan, Kai Guo, Kaixiong Zhou, Jiliang Tang, Mengnan Du

Latent representation alignment has become a foundational technique for
constructing multimodal large language models (MLLM) by mapping embeddings from
different modalities into a shared space, often aligned with the embedding
space of large language models (LLMs) to enable effective cross-modal
understanding. While preliminary protein-focused MLLMs have emerged, they have
predominantly relied on heuristic approaches, lacking a fundamental
understanding of optimal alignment practices across representations. In this
study, we explore the alignment of multimodal representations between LLMs and
Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate
three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with
four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines
alignment factors from both model and protein perspectives, identifying
challenges in current alignment methodologies and proposing strategies to
improve the alignment process. Our key findings reveal that GDMs incorporating
both graph and 3D structural information align better with LLMs, larger LLMs
demonstrate improved alignment capabilities, and protein rarity significantly
impacts alignment performance. We also find that increasing GDM embedding
dimensions, using two-layer projection heads, and fine-tuning LLMs on
protein-specific data substantially enhance alignment quality. These strategies
offer potential enhancements to the performance of protein-related multimodal
models. Our code and data are available at
https://github.com/Tizzzzy/LLM-GDM-alignment.

ÊëòË¶ÅÔºöÊΩõÂú®Ë°®ÂæµÂ∞çÈΩäÂ∑≤ÊàêÁÇ∫Âª∫ÊßãÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÂü∫Á§éÊäÄË°ìÔºåÊñπÊ≥ïÊòØÂ∞á‰∏çÂêåÊ®°ÊÖãÁöÑÂµåÂÖ•Êò†Â∞ÑÂà∞ÂÖ±‰∫´Á©∫Èñì‰∏≠ÔºåÈÄöÂ∏∏ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂµåÂÖ•Á©∫ÈñìÂ∞çÈΩäÔºå‰ª•ÂØ¶ÁèæÊúâÊïàÁöÑË∑®Ê®°ÊÖãÁêÜËß£„ÄÇÈõñÁÑ∂ÂàùÊ≠•‰ª•ËõãÁôΩË≥™ÁÇ∫ÈáçÈªûÁöÑ MLLM Â∑≤Âá∫ÁèæÔºå‰ΩÜÂÆÉÂÄë‰∏ªË¶Å‰æùË≥¥ÂïüÁôºÂºèÊñπÊ≥ïÔºåÁº∫‰πèÂ∞çË∑®Ë°®ÂæµÊúÄ‰Ω≥Â∞çÈΩäÂØ¶ÂãôÁöÑÂü∫Êú¨ÁêÜËß£„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜËõãÁôΩË≥™È†òÂüü‰∏≠ LLM ËàáÂπæ‰ΩïÊ∑±Â∫¶Ê®°Âûã (GDM) ‰πãÈñìÁöÑÂ§öÊ®°ÊÖãË°®ÂæµÂ∞çÈΩä„ÄÇÊàëÂÄëÂÖ®Èù¢Ë©ï‰º∞‰∫Ü‰∏âÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLMÔºàGemma2-2B„ÄÅLLaMa3.1-8B Âíå LLaMa3.1-70BÔºâËàáÂõõÂÄãËõãÁôΩË≥™Â∞àÁî® GDMÔºàGearNet„ÄÅGVP„ÄÅScanNet„ÄÅGATÔºâ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂæûÊ®°ÂûãÂíåËõãÁôΩË≥™ËßíÂ∫¶Ê™¢Ë¶ñÂ∞çÈΩäÂõ†Á¥†ÔºåË≠òÂà•Áï∂ÂâçÂ∞çÈΩäÊñπÊ≥ïÁöÑÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫ÊîπÂñÑÂ∞çÈΩäÁ®ãÂ∫èÁöÑÁ≠ñÁï•„ÄÇÊàëÂÄëÁöÑÈóúÈçµÁôºÁèæÈ°ØÁ§∫ÔºåÂêåÊôÇÂåÖÂê´ÂúñÂΩ¢Âíå 3D ÁµêÊßãË≥áË®äÁöÑ GDM Ëàá LLM ÁöÑÂ∞çÈΩäÊïàÊûúËºÉ‰Ω≥ÔºåËºÉÂ§ßÁöÑ LLM Â±ïÁèæÂá∫Êõ¥‰Ω≥ÁöÑÂ∞çÈΩäËÉΩÂäõÔºåËÄåËõãÁôΩË≥™ÁöÑÁ®ÄÊúâÊÄßÈ°ØËëóÂΩ±ÈüøÂ∞çÈΩäÊïàËÉΩ„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÔºåÂ¢ûÂä† GDM ÂµåÂÖ•Á∂≠Â∫¶„ÄÅ‰ΩøÁî®ÂÖ©Â±§ÊäïÂΩ±È†≠Ôºå‰ª•ÂèäÈáùÂ∞çËõãÁôΩË≥™ÁâπÂÆöË≥áÊñôÂæÆË™ø LLMÔºåÂèØ‰ª•Â§ßÂπÖÊèêÂçáÂ∞çÈΩäÂìÅË≥™„ÄÇÈÄô‰∫õÁ≠ñÁï•ÁÇ∫ËõãÁôΩË≥™Áõ∏ÈóúÂ§öÊ®°ÊÖãÊ®°ÂûãÁöÑÊïàËÉΩÊèê‰æõÊΩõÂú®ÁöÑÂº∑Âåñ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/Tizzzzy/LLM-GDM-alignment ÂèñÂæó„ÄÇ

##### **On Training of Kolmogorov-Arnold Networks**
2411.05296v1 by Shairoz Sohail

Kolmogorov-Arnold Networks have recently been introduced as a flexible
alternative to multi-layer Perceptron architectures. In this paper, we examine
the training dynamics of different KAN architectures and compare them with
corresponding MLP formulations. We train with a variety of different
initialization schemes, optimizers, and learning rates, as well as utilize back
propagation free approaches like the HSIC Bottleneck. We find that (when judged
by test accuracy) KANs are an effective alternative to MLP architectures on
high-dimensional datasets and have somewhat better parameter efficiency, but
suffer from more unstable training dynamics. Finally, we provide
recommendations for improving training stability of larger KAN models.

ÊëòË¶ÅÔºöKolmogorov-Arnold Á∂≤Ë∑ØÊúÄËøëË¢´ÂºïÂÖ•‰ΩúÁÇ∫Â§öÂ±§ÊÑüÁü•Âô®Êû∂ÊßãÁöÑÈùàÊ¥ªÊõø‰ª£ÊñπÊ°à„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ™¢È©ó‰∫Ü‰∏çÂêå KAN Êû∂ÊßãÁöÑË®ìÁ∑¥ÂãïÊÖãÔºå‰∏¶Â∞áÂÆÉÂÄëËàáÂ∞çÊáâÁöÑ MLP ÂÖ¨ÂºèÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄë‰ΩøÁî®ÂêÑÁ®Æ‰∏çÂêåÁöÑÂàùÂßãÂåñÊñπÊ°à„ÄÅÂÑ™ÂåñÂô®ÂíåÂ≠∏ÁøíÁéáÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰∏¶Âà©Áî®ÂæåÂêëÂÇ≥Êí≠Ëá™Áî±ÊñπÊ≥ïÔºå‰æãÂ¶Ç HSIC Áì∂È†∏„ÄÇÊàëÂÄëÁôºÁèæÔºà‰ª•Ê∏¨Ë©¶Ê∫ñÁ¢∫Â∫¶‰æÜÂà§Êñ∑ÔºâKAN ÊòØÈ´òÁ∂≠Ë≥áÊñôÈõÜ‰∏ä MLP Êû∂ÊßãÁöÑÊúâÊïàÊõø‰ª£ÊñπÊ°àÔºå‰∏¶‰∏îÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÂèÉÊï∏ÊïàÁéáÔºå‰ΩÜË®ìÁ∑¥ÂãïÊÖãËºÉ‰∏çÁ©©ÂÆö„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÊîπÂñÑËºÉÂ§ß KAN Ê®°ÂûãË®ìÁ∑¥Á©©ÂÆöÊÄßÁöÑÂª∫Ë≠∞„ÄÇ

##### **SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding**
2411.05289v1 by Ryan Sun, Tianyi Zhou, Xun Chen, Lichao Sun

Large Language Models (LLMs) have become essential in advancing natural
language processing (NLP) tasks, but their sequential token generation limits
inference speed. Multi-Draft Speculative Decoding (MDSD) offers a promising
solution by using a smaller draft model to generate multiple token sequences,
which the target LLM verifies in parallel. However, current heuristic
approaches, such as Recursive Rejection Sampling (RRS), suffer from low
acceptance rates in subsequent drafts, limiting the advantages of using
multiple drafts. Meanwhile, Optimal Transport with Membership Cost (OTM) can
theoretically improve acceptance rates, but its computational cost is too high
for real-time use. We present SpecHub, a novel, efficient sampling-verification
method for MDSD that improves acceptance rates with only linear computational
overhead. By simplifying the OTM problem into a compact Linear Programming
model, SpecHub significantly reduces computational complexity. It further
accelerates sampling by leveraging a sparse joint distribution, focusing
computation on high-probability token sequences. In extensive experiments,
Spechub consistently generates 0.05-0.27 and 0.02-0.16 more tokens per step
than RRS and RRS without replacement. We attach our code at
\url{https://github.com/MasterGodzilla/Speculative_decoding_OT}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊàêÁÇ∫Êé®ÈÄ≤Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãôÁöÑÈóúÈçµÔºå‰ΩÜÂÖ∂Â∫èÂàóÊ®ôË®òÁî¢ÁîüÈôêÂà∂‰∫ÜÊé®Ë´ñÈÄüÂ∫¶„ÄÇÂ§öËçâÁ®øÊé®Ê∏¨ÊÄßËß£Á¢º (MDSD) Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂÆÉ‰ΩøÁî®ËºÉÂ∞èÁöÑËçâÁ®øÊ®°Âûã‰æÜÁî¢ÁîüÂ§öÂÄãÊ®ôË®òÂ∫èÂàóÔºåÁõÆÊ®ô LLM ÊúÉ‰∏¶Ë°åÈ©óË≠âÈÄô‰∫õÂ∫èÂàó„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÂïüÁôºÂºèÊñπÊ≥ïÔºà‰æãÂ¶ÇÈÅûËø¥ÊãíÁµïÊé°Ê®£ (RRS)ÔºâÂú®ÂæåÁ∫åËçâÁ®ø‰∏≠Êé•ÂèóÁéá‰ΩéÔºåÈÄôÈôêÂà∂‰∫Ü‰ΩøÁî®Â§öÂÄãËçâÁ®øÁöÑÂÑ™Èªû„ÄÇËàáÊ≠§ÂêåÊôÇÔºåÂÖ∑ÊúâÊàêÂì°ÊàêÊú¨ÁöÑÊúÄÂÑ™ÂÇ≥Ëº∏ (OTM) Âú®ÁêÜË´ñ‰∏äÂèØ‰ª•ÊèêÈ´òÊé•ÂèóÁéáÔºå‰ΩÜÂÖ∂ÈÅãÁÆóÊàêÊú¨Â∞çÊñºÂØ¶ÊôÇ‰ΩøÁî®‰æÜË™™Â§™È´ò„ÄÇÊàëÂÄëÊèêÂá∫ SpecHubÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©é„ÄÅÈ´òÊïàÁöÑ MDSD Êé°Ê®£È©óË≠âÊñπÊ≥ïÔºåÂÆÉÂÉÖÈÄöÈÅéÁ∑öÊÄßÈÅãÁÆóÈñãÈä∑‰æÜÊèêÈ´òÊé•ÂèóÁéá„ÄÇÈÄöÈÅéÂ∞á OTM ÂïèÈ°åÁ∞°ÂåñÁÇ∫‰∏ÄÂÄãÁ∑äÊπäÁöÑÁ∑öÊÄßË¶èÂäÉÊ®°ÂûãÔºåSpecHub Â§ßÂπÖÈôç‰Ωé‰∫ÜÈÅãÁÆóË§áÈõúÂ∫¶„ÄÇÂÆÉÈÄ≤‰∏ÄÊ≠•Âà©Áî®Á®ÄÁñèËÅØÂêàÂàÜ‰Ωà‰æÜÂä†ÈÄüÊé°Ê®£ÔºåÂ∞áÈÅãÁÆóÈõÜ‰∏≠Âú®È´òÊ¶ÇÁéáÊ®ôË®òÂ∫èÂàó‰∏ä„ÄÇÂú®Âª£Ê≥õÁöÑÂØ¶È©ó‰∏≠ÔºåSpechub ÊØèÂÄãÊ≠•È©üÁî¢ÁîüÁöÑÊ®ôË®òÊØî RRS ÂíåÊú™ÊõøÊèõÁöÑ RRS ÊåÅÁ∫åÂ§öÂá∫ 0.05-0.27 Âíå 0.02-0.16 ÂÄã„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑ‰ª£Á¢ºÈôÑÂä†Âú® \url{https://github.com/MasterGodzilla/Speculative_decoding_OT}„ÄÇ

##### **A Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents**
2411.05285v1 by Liming Dong, Qinghua Lu, Liming Zhu

The ever-improving quality of LLMs has fueled the growth of a diverse range
of downstream tasks, leading to an increased demand for AI automation and a
burgeoning interest in developing foundation model (FM)-based autonomous
agents. As AI agent systems tackle more complex tasks and evolve, they involve
a wider range of stakeholders, including agent users, agentic system developers
and deployers, and AI model developers. These systems also integrate multiple
components such as AI agent workflows, RAG pipelines, prompt management, agent
capabilities, and observability features. In this case, obtaining reliable
outputs and answers from these agents remains challenging, necessitating a
dependable execution process and end-to-end observability solutions. To build
reliable AI agents and LLM applications, it is essential to shift towards
designing AgentOps platforms that ensure observability and traceability across
the entire development-to-production life-cycle. To this end, we conducted a
rapid review and identified relevant AgentOps tools from the agentic ecosystem.
Based on this review, we provide an overview of the essential features of
AgentOps and propose a comprehensive overview of observability data/traceable
artifacts across the agent production life-cycle. Our findings provide a
systematic overview of the current AgentOps landscape, emphasizing the critical
role of observability/traceability in enhancing the reliability of autonomous
agent systems.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂìÅË≥™‰∏çÊñ∑ÊèêÂçáÔºåÊé®Âãï‰∏ãÊ∏∏‰ªªÂãôÁöÑÂ§öÂÖÉÂåñÊàêÈï∑ÔºåÈÄ≤ËÄåÊèêÂçáÂ∞ç AI Ëá™ÂãïÂåñÁöÑÈúÄÊ±ÇÔºå‰ª•ÂèäÈñãÁôºÂü∫Á§éÊ®°Âûã (FM) ÁÇ∫Âü∫Á§éÁöÑËá™‰∏ª‰ª£ÁêÜÁöÑÊøÉÂéöËààË∂£„ÄÇÈö®Ëëó AI ‰ª£ÁêÜÁ≥ªÁµ±ËôïÁêÜÊõ¥Ë§áÈõúÁöÑ‰ªªÂãô‰∏¶‰∏çÊñ∑ÊºîÈÄ≤ÔºåÂÆÉÂÄëÊ∂âÂèäÊõ¥Âª£Ê≥õÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÔºåÂåÖÊã¨‰ª£ÁêÜ‰ΩøÁî®ËÄÖ„ÄÅ‰ª£ÁêÜÁ≥ªÁµ±ÈñãÁôº‰∫∫Âì°ÂíåÈÉ®ÁΩ≤ËÄÖÔºå‰ª•Âèä AI Ê®°ÂûãÈñãÁôº‰∫∫Âì°„ÄÇÈÄô‰∫õÁ≥ªÁµ±‰πüÊï¥ÂêàÂ§öÂÄãÂÖÉ‰ª∂Ôºå‰æãÂ¶Ç AI ‰ª£ÁêÜÂ∑•‰ΩúÊµÅÁ®ã„ÄÅRAG ÁÆ°Á∑ö„ÄÅÊèêÁ§∫ÁÆ°ÁêÜ„ÄÅ‰ª£ÁêÜÂäüËÉΩÂíåÂèØËßÄÂØüÊÄßÂäüËÉΩ„ÄÇÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÂæûÈÄô‰∫õ‰ª£ÁêÜÂèñÂæóÂèØÈù†ÁöÑËº∏Âá∫ÂíåÁ≠îÊ°à‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†Ê≠§ÈúÄË¶ÅÂèØÈù†ÁöÑÂü∑Ë°åÁ®ãÂ∫èÂíåÁ´ØÂ∞çÁ´ØÂèØËßÄÂØüÊÄßËß£Ê±∫ÊñπÊ°à„ÄÇÁÇ∫‰∫ÜÂª∫ÁΩÆÂèØÈù†ÁöÑ AI ‰ª£ÁêÜÂíå LLM ÊáâÁî®Á®ãÂºèÔºåËΩâÂêëË®≠Ë®à AgentOps Âπ≥Âè∞Ëá≥ÈóúÈáçË¶ÅÔºå‰ª•Á¢∫‰øùÊï¥ÂÄãÈñãÁôºÂà∞ÁîüÁî¢ÁîüÂëΩÈÄ±ÊúüÁöÑÂèØËßÄÂØüÊÄßÂíåÂèØËøΩÊ∫ØÊÄß„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂø´ÈÄüÊ™¢Ë¶ñÔºå‰∏¶Âæû‰ª£ÁêÜÁîüÊÖãÁ≥ªÁµ±‰∏≠ÊâæÂá∫Áõ∏ÈóúÁöÑ AgentOps Â∑•ÂÖ∑„ÄÇÊ†πÊìöÈÄô‰ªΩÊ™¢Ë¶ñÔºåÊàëÂÄëÊèê‰æõ AgentOps Âü∫Êú¨ÂäüËÉΩÁöÑÊ¶ÇËßÄÔºå‰∏¶ÊèêÂá∫‰ª£ÁêÜÁîüÁî¢ÁîüÂëΩÈÄ±Êúü‰∏≠ÂèØËßÄÂØüÊÄßË≥áÊñô/ÂèØËøΩÊ∫Ø‰∫∫Â∑•Ë£ΩÂìÅÁöÑÂÖ®Èù¢Ê¶ÇËßÄ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊèê‰æõ AgentOps ÁèæÊ≥ÅÁöÑÁ≥ªÁµ±ÊÄßÊ¶ÇËßÄÔºåÂº∑Ë™øÂèØËßÄÂØüÊÄß/ÂèØËøΩÊ∫ØÊÄßÂú®ÊèêÂçáËá™‰∏ª‰ª£ÁêÜÁ≥ªÁµ±ÂèØÈù†ÊÄßÊñπÈù¢ÊâÆÊºîÁöÑÈóúÈçµËßíËâ≤„ÄÇ

##### **MicroScopiQ: Accelerating Foundational Models through Outlier-Aware Microscaling Quantization**
2411.05282v1 by Akshat Ramachandran, Souvik Kundu, Tushar Krishna

Quantization of foundational models (FMs) is significantly more challenging
than traditional DNNs due to the emergence of large magnitude features called
outliers. Existing outlier-aware algorithm/architecture co-design techniques
either use mixed-precision, retaining outliers at high precision but compromise
hardware efficiency, or quantize inliers and outliers at the same precision,
improving hardware efficiency at the cost of accuracy. To address this mutual
exclusivity, in this paper, we propose MicroScopiQ, a novel co-design technique
that leverages pruning to complement outlier-aware quantization. MicroScopiQ
retains outliers at higher precision while pruning a certain fraction of least
important weights to distribute the additional outlier bits; ensuring high
accuracy, aligned memory and hardware efficiency. We design a high-throughput,
low overhead accelerator architecture composed of simple multi-precision INT
processing elements and a novel network-on-chip called ReCoN that efficiently
abstracts the complexity of supporting high-precision outliers. Additionally,
unlike existing alternatives, MicroScopiQ does not assume any locality of
outlier weights, enabling applicability to a broad range of FMs. Extensive
experiments across various quantization settings show that MicroScopiQ achieves
SoTA quantization performance while simultaneously improving inference
performance by 3x and reducing energy by 2x over existing alternatives.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°Âûã (FM) ÁöÑÈáèÂåñÊØîÂÇ≥Áµ± DNN Âõ∞Èõ£ÂæóÂ§öÔºåÂõ†ÁÇ∫Âá∫Áèæ‰∫ÜÁ®±ÁÇ∫Áï∞Â∏∏ÂÄºÁöÑÂ§ßÈáèÁ¥öÁâπÂæµ„ÄÇÁèæÊúâÁöÑÁï∞Â∏∏ÂÄºÊÑüÁü•ÊºîÁÆóÊ≥ï/Êû∂ÊßãÂÖ±ÂêåË®≠Ë®àÊäÄË°ìÔºåÊúÉ‰ΩøÁî®Ê∑∑ÂêàÁ≤æÂ∫¶Ôºå‰øùÁïôÁï∞Â∏∏ÂÄºÁöÑÈ´òÁ≤æÂ∫¶Ôºå‰ΩÜÊúÉÂΩ±ÈüøÁ°¨È´îÊïàÁéáÔºåÊàñ‰ª•Áõ∏ÂêåÁöÑÁ≤æÂ∫¶ÈáèÂåñÂÖßÈªûÂíåÁï∞Â∏∏ÂÄºÔºå‰ª•ÁäßÁâ≤Ê∫ñÁ¢∫Â∫¶‰æÜÊîπÂñÑÁ°¨È´îÊïàÁéá„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÁ®ÆÁõ∏‰∫íÊéíÊñ•ÊÄßÔºåÊàëÂÄëÂú®Êú¨Êñá‰∏≠ÊèêÂá∫ MicroScopiQÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÖ±ÂêåË®≠Ë®àÊäÄË°ìÔºåÂÆÉÂà©Áî®Ââ™Êûù‰æÜË£úÂÖÖÁï∞Â∏∏ÂÄºÊÑüÁü•ÈáèÂåñ„ÄÇMicroScopiQ ‰øùÁïôÁï∞Â∏∏ÂÄºÁöÑÈ´òÁ≤æÂ∫¶ÔºåÂêåÊôÇÂâ™ÊûùÊéâ‰∏ÄÈÉ®ÂàÜÊúÄ‰∏çÈáçË¶ÅÁöÑÊ¨äÈáçÔºå‰ª•ÂàÜÈÖçÈ°çÂ§ñÁöÑÁï∞Â∏∏ÂÄº‰ΩçÂÖÉÔºõÁ¢∫‰øùÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÅÂ∞çÈΩäÁöÑË®òÊÜ∂È´îÂíåÁ°¨È´îÊïàÁéá„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÈ´òÈÄöÈáè„ÄÅ‰ΩéÈñãÈä∑ÁöÑÂä†ÈÄüÂô®Êû∂ÊßãÔºåÂÆÉÁî±Á∞°ÂñÆÁöÑÂ§öÁ≤æÂ∫¶ INT ËôïÁêÜÂÖÉ‰ª∂Âíå‰∏ÄÂÄãÁ®±ÁÇ∫ ReCoN ÁöÑÊñ∞Á©éÁ∂≤Ë∑ØÊô∂ÁâáÁµÑÊàêÔºåÂèØ‰ª•ÊúâÊïàÂú∞ÊäΩË±°ÂåñÊîØÊè¥È´òÁ≤æÂ∫¶Áï∞Â∏∏ÂÄºÁöÑË§áÈõúÊÄß„ÄÇÊ≠§Â§ñÔºåËàáÁèæÊúâÁöÑÊõø‰ª£ÊñπÊ°à‰∏çÂêåÔºåMicroScopiQ ‰∏çÂÅáË®≠Áï∞Â∏∏ÂÄºÊ¨äÈáçÁöÑ‰ªª‰ΩïÂ±ÄÈÉ®ÊÄßÔºåËÆìÂÖ∂ÈÅ©Áî®ÊñºÂª£Ê≥õÁöÑ FM„ÄÇÂú®ÂêÑÁ®ÆÈáèÂåñË®≠ÂÆö‰∏ãÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåMicroScopiQ ÈÅîÂà∞‰∫Ü SoTA ÈáèÂåñÊïàËÉΩÔºåÂêåÊôÇÂ∞áÊé®ÁêÜÊïàËÉΩÊèêÂçá‰∫Ü 3 ÂÄçÔºå‰∏¶Â∞áËÉΩÊ∫êÈôç‰Ωé‰∫Ü 2 ÂÄçÔºåË∂ÖË∂ä‰∫ÜÁèæÊúâÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇ

##### **Fox-1 Technical Report**
2411.05281v1 by Zijian Hu, Jipeng Zhang, Rui Pan, Zhaozhuo Xu, Salman Avestimehr, Chaoyang He, Tong Zhang

We present Fox-1, a series of small language models (SLMs) consisting of
Fox-1-1.6B and Fox-1-1.6B-Instruct-v0.1. These models are pre-trained on 3
trillion tokens of web-scraped document data and fine-tuned with 5 billion
tokens of instruction-following and multi-turn conversation data. Aiming to
improve the pre-training efficiency, Fox-1-1.6B model introduces a novel
3-stage data curriculum across all the training data with 2K-8K sequence
length. In architecture design, Fox-1 features a deeper layer structure, an
expanded vocabulary, and utilizes Grouped Query Attention (GQA), offering a
performant and efficient architecture compared to other SLMs. Fox-1 achieves
better or on-par performance in various benchmarks compared to StableLM-2-1.6B,
Gemma-2B, Qwen1.5-1.8B, and OpenELM1.1B, with competitive inference speed and
throughput. The model weights have been released under the Apache 2.0 license,
where we aim to promote the democratization of LLMs and make them fully
accessible to the whole open-source community.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ Fox-1ÔºåÈÄôÊòØ‰∏ÄÂÄãÁî± Fox-1-1.6B Âíå Fox-1-1.6B-Instruct-v0.1 ÁµÑÊàêÁöÑ‰∏ÄÁ≥ªÂàóÂ∞èÂûãË™ûË®ÄÊ®°Âûã (SLM)„ÄÇÈÄô‰∫õÊ®°ÂûãÁ∂ìÈÅé 3 ÂÖÜÂÄãÁ∂≤Ë∑ØÊì∑ÂèñÊñá‰ª∂Ë≥áÊñôÁöÑÈ†êË®ìÁ∑¥Ôºå‰∏¶‰ΩøÁî® 50 ÂÑÑÂÄãÈÅµÂæ™ÊåáÁ§∫ÂíåÂ§öËº™Â∞çË©±Ë≥áÊñôÈÄ≤Ë°åÂæÆË™ø„ÄÇÁÇ∫‰∫ÜÊèêÈ´òÈ†êË®ìÁ∑¥ÊïàÁéáÔºåFox-1-1.6B Ê®°ÂûãÂú®ÊâÄÊúâË®ìÁ∑¥Ë≥áÊñô‰∏≠ÂºïÂÖ•‰∫ÜÂâµÊñ∞ÁöÑ 3 ÈöéÊÆµË≥áÊñôË™≤Á®ãÔºåÂ∫èÂàóÈï∑Â∫¶ÁÇ∫ 2K-8K„ÄÇÂú®Êû∂ÊßãË®≠Ë®à‰∏≠ÔºåFox-1 Êé°Áî®Êõ¥Ê∑±ÁöÑÂ±§Á¥öÁµêÊßã„ÄÅÊì¥ÂÖÖÁöÑË©ûÂΩôÈáèÔºå‰∏¶Âà©Áî®Áæ§ÁµÑÊü•Ë©¢Ê≥®ÊÑèÂäõ (GQA)ÔºåËàáÂÖ∂‰ªñ SLM Áõ∏ÊØîÔºåÊèê‰æõ‰∫ÜÈ´òÊïàËÉΩ‰∏îÈ´òÊïàÁöÑÊû∂Êßã„ÄÇËàá StableLM-2-1.6B„ÄÅGemma-2B„ÄÅQwen1.5-1.8B Âíå OpenELM1.1B Áõ∏ÊØîÔºåFox-1 Âú®ÂêÑÁ®ÆÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÈÅîÂà∞Êõ¥Â•ΩÊàñÂêåÁ≠âÁöÑÊïàËÉΩÔºåÂêåÊôÇÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊé®Ë´ñÈÄüÂ∫¶ÂíåÂêûÂêêÈáè„ÄÇÊ®°ÂûãÊ¨äÈáçÂ∑≤Âú® Apache 2.0 ÊéàÊ¨ä‰∏ãÁôºÂ∏ÉÔºåÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÊé®Âª£ LLM ÁöÑÊ∞ë‰∏ªÂåñÔºå‰∏¶ËÆìÊï¥ÂÄãÈñãÊ∫êÁ§æÁæ§ÈÉΩËÉΩÂÖÖÂàÜ‰ΩøÁî®„ÄÇ

##### **Revisiting the Robustness of Watermarking to Paraphrasing Attacks**
2411.05277v1 by Saksham Rastogi, Danish Pruthi

Amidst rising concerns about the internet being proliferated with content
generated from language models (LMs), watermarking is seen as a principled way
to certify whether text was generated from a model. Many recent watermarking
techniques slightly modify the output probabilities of LMs to embed a signal in
the generated output that can later be detected. Since early proposals for text
watermarking, questions about their robustness to paraphrasing have been
prominently discussed. Lately, some techniques are deliberately designed and
claimed to be robust to paraphrasing. However, such watermarking schemes do not
adequately account for the ease with which they can be reverse-engineered. We
show that with access to only a limited number of generations from a black-box
watermarked model, we can drastically increase the effectiveness of
paraphrasing attacks to evade watermark detection, thereby rendering the
watermark ineffective.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫ÂÄëË∂ä‰æÜË∂äÊìîÂøÉÁ∂≤Ë∑Ø‰∏äÂÖÖÊñ•ËëóÁî±Ë™ûË®ÄÊ®°ÂûãÔºàLMÔºâÁî¢ÁîüÁöÑÂÖßÂÆπÔºåÊµÆÊ∞¥Âç∞Ë¢´Ë¶ñÁÇ∫‰∏ÄÁ®ÆÁ¢∫Ë™çÊñáÂ≠óÊòØÂê¶Áî±Ê®°ÂûãÁî¢ÁîüÁöÑÂéüÂâáÊÄßÊñπÊ≥ï„ÄÇË®±Â§öÊúÄËøëÁöÑÊµÆÊ∞¥Âç∞ÊäÄË°ìÊúÉËºïÂæÆ‰øÆÊîπ LM ÁöÑËº∏Âá∫Ê©üÁéáÔºå‰ª•‰æøÂú®Áî¢ÁîüÁöÑËº∏Âá∫‰∏≠ÂµåÂÖ•‰∏ÄÂÄãË®äËôüÔºåÁ®çÂæåÂèØ‰ª•ÂÅµÊ∏¨Âà∞ÈÄôÂÄãË®äËôü„ÄÇËá™ÂæûÊèêÂá∫ÊñáÂ≠óÊµÆÊ∞¥Âç∞ÁöÑÊó©ÊúüÊèêÊ°à‰ª•‰æÜÔºåÈóúÊñºÂÆÉÂÄëÂ∞çÊîπÂØ´ÁöÑÁ©©ÂÅ•ÊÄßÂïèÈ°å‰∏ÄÁõ¥ÂÇôÂèóË®éË´ñ„ÄÇÊúÄËøëÔºå‰∏Ä‰∫õÊäÄË°ìÁ∂ìÈÅéÂàªÊÑèË®≠Ë®àÔºå‰∏¶ËÅ≤Á®±Â∞çÊîπÂØ´ÂÖ∑ÊúâÁ©©ÂÅ•ÊÄß„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûÊµÆÊ∞¥Âç∞Êû∂Êßã‰∏¶Êú™ÂÖÖÂàÜËÄÉÈáèÂà∞ÂÆÉÂÄëÂèØ‰ª•ËºïÈ¨ÜÈÄ≤Ë°åÈÄÜÂêëÂ∑•Á®ãÁöÑ‰æøÂà©ÊÄß„ÄÇÊàëÂÄëÂ±ïÁ§∫ÔºåÂè™Ë¶ÅÂèñÂæóÈªëÁõíÊµÆÊ∞¥Âç∞Ê®°ÂûãÁî¢ÁîüÁöÑÂ∞ëÈáè‰∏ñ‰ª£ÔºåÊàëÂÄëÂ∞±ËÉΩÂ§ßÂπÖÊèêÂçáÊîπÂØ´ÊîªÊìäÁöÑÊïàËÉΩÔºå‰ª•Ë¶èÈÅøÊµÆÊ∞¥Âç∞ÂÅµÊ∏¨ÔºåÈÄ≤ËÄåËÆìÊµÆÊ∞¥Âç∞Â§±Êïà„ÄÇ

##### **Real-World Offline Reinforcement Learning from Vision Language Model Feedback**
2411.05273v1 by Sreyas Venkataraman, Yufei Wang, Ziyu Wang, Zackory Erickson, David Held

Offline reinforcement learning can enable policy learning from pre-collected,
sub-optimal datasets without online interactions. This makes it ideal for
real-world robots and safety-critical scenarios, where collecting online data
or expert demonstrations is slow, costly, and risky. However, most existing
offline RL works assume the dataset is already labeled with the task rewards, a
process that often requires significant human effort, especially when
ground-truth states are hard to ascertain (e.g., in the real-world). In this
paper, we build on prior work, specifically RL-VLM-F, and propose a novel
system that automatically generates reward labels for offline datasets using
preference feedback from a vision-language model and a text description of the
task. Our method then learns a policy using offline RL with the reward-labeled
dataset. We demonstrate the system's applicability to a complex real-world
robot-assisted dressing task, where we first learn a reward function using a
vision-language model on a sub-optimal offline dataset, and then we use the
learned reward to employ Implicit Q learning to develop an effective dressing
policy. Our method also performs well in simulation tasks involving the
manipulation of rigid and deformable objects, and significantly outperform
baselines such as behavior cloning and inverse RL. In summary, we propose a new
system that enables automatic reward labeling and policy learning from
unlabeled, sub-optimal offline datasets.

ÊëòË¶ÅÔºöÈõ¢Á∑öÂº∑ÂåñÂ≠∏ÁøíÂèØ‰ª•ËÆìÁ≠ñÁï•Â≠∏ÁøíÂæûÈ†êÂÖàÊî∂ÈõÜÁöÑÊ¨°‰Ω≥Ë≥áÊñôÈõÜÈÄ≤Ë°åÔºåËÄåÁÑ°ÈúÄÁ∑ö‰∏ä‰∫íÂãï„ÄÇÈÄô‰ΩøÂæóÂÆÉÈùûÂ∏∏ÈÅ©ÂêàÊñºÁèæÂØ¶‰∏ñÁïåÁöÑÊ©üÂô®‰∫∫ÂíåÂÆâÂÖ®ÈóúÈçµÊÉÖÂ¢ÉÔºåÂú®ÈÄô‰∫õÊÉÖÂ¢É‰∏≠ÔºåÊî∂ÈõÜÁ∑ö‰∏äË≥áÊñôÊàñÂ∞àÂÆ∂Á§∫ÁØÑÊó¢Á∑©ÊÖ¢„ÄÅÊòÇË≤¥ÂèàÂÜíÈö™„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÈõ¢Á∑ö RL Â∑•‰ΩúÂ§ßÂ§öÂÅáË®≠Ë≥áÊñôÈõÜÂ∑≤Á∂ìÊ®ôË®òÊúâ‰ªªÂãôÁçéÂãµÔºåÈÄôÂÄãÈÅéÁ®ãÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáè‰∫∫ÂäõÔºåÁâπÂà•ÊòØÂú®Èõ£‰ª•Á¢∫ÂÆöÂü∫Êú¨‰∫ãÂØ¶ÁöÑÊÉÖÊ≥Å‰∏ãÔºà‰æãÂ¶ÇÔºåÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠Ôºâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Á´ãÂú®ÂÖàÂâçÁöÑÁ†îÁ©∂ÔºåÁâπÂà•ÊòØ RL-VLM-FÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÁ≥ªÁµ±Ôºå‰ΩøÁî®‰æÜËá™Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑÂÅèÂ•ΩÂõûÈ•ãÂíå‰ªªÂãôÁöÑÊñáÂ≠óÊèèËø∞ÔºåËá™ÂãïÁÇ∫Èõ¢Á∑öË≥áÊñôÈõÜÁîüÊàêÁçéÂãµÊ®ôÁ±§„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊé•Ëëó‰ΩøÁî®Èõ¢Á∑ö RL Â≠∏ÁøíÊúâÁçéÂãµÊ®ôÁ±§ÁöÑË≥áÊñôÈõÜÁöÑÁ≠ñÁï•„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜË©≤Á≥ªÁµ±Â∞çË§áÈõúÁöÑÁèæÂØ¶‰∏ñÁïåÊ©üÂô®‰∫∫ËºîÂä©Á©øË°£‰ªªÂãôÁöÑÈÅ©Áî®ÊÄßÔºåÂú®Ë©≤‰ªªÂãô‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÂú®Ê¨°‰Ω≥Èõ¢Á∑öË≥áÊñôÈõÜ‰∏äÂ≠∏ÁøíÁçéÂãµÂáΩÊï∏ÔºåÁÑ∂Âæå‰ΩøÁî®Â≠∏ÁøíÂà∞ÁöÑÁçéÂãµ‰æÜÊé°Áî®Èö±Âºè Q Â≠∏Áøí‰æÜÈñãÁôºÊúâÊïàÁöÑÁ©øË°£Á≠ñÁï•„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Ê∂âÂèäÊìçÁ∏±ÂâõÊÄßÂíåÂèØËÆäÂΩ¢Áâ©È´îÁöÑÊ®°Êì¨‰ªªÂãô‰∏≠‰πüË°®ÁèæËâØÂ•ΩÔºå‰∏¶‰∏îÊòéÈ°ØÂÑ™ÊñºË°åÁÇ∫Ë§áË£ΩÂíåÈÄÜÂêë RL Á≠âÂü∫Ê∫ñ„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁ≥ªÁµ±ÔºåÂèØ‰ª•ÂæûÊú™Ê®ôË®òÁöÑÊ¨°‰Ω≥Èõ¢Á∑öË≥áÊñôÈõÜ‰∏≠ÈÄ≤Ë°åËá™ÂãïÁçéÂãµÊ®ôË®òÂíåÁ≠ñÁï•Â≠∏Áøí„ÄÇ

##### **Seeing Through the Fog: A Cost-Effectiveness Analysis of Hallucination Detection Systems**
2411.05270v1 by Alexander Thomas, Seth Rosen, Vishnu Vettrivel

This paper presents a comparative analysis of hallucination detection systems
for AI, focusing on automatic summarization and question answering tasks for
Large Language Models (LLMs). We evaluate different hallucination detection
systems using the diagnostic odds ratio (DOR) and cost-effectiveness metrics.
Our results indicate that although advanced models can perform better they come
at a much higher cost. We also demonstrate how an ideal hallucination detection
system needs to maintain performance across different model sizes. Our findings
highlight the importance of choosing a detection system aligned with specific
application needs and resource constraints. Future research will explore hybrid
systems and automated identification of underperforming components to enhance
AI reliability and efficiency in detecting and mitigating hallucinations.

ÊëòË¶ÅÔºöÊú¨ÊñáÈáùÂ∞ç‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂπªË¶∫ÂÅµÊ∏¨Á≥ªÁµ±ÈÄ≤Ë°åÊØîËºÉÂàÜÊûêÔºåÈáçÈªûÂú®ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËá™ÂãïÊëòË¶ÅÂíåÂïèÁ≠î‰ªªÂãô„ÄÇÊàëÂÄë‰ΩøÁî®Ë®∫Êñ∑ÊØîÂÄº (DOR) ÂíåÊàêÊú¨ÊïàÁõäÊåáÊ®ôË©ï‰º∞‰∏çÂêåÁöÑÂπªË¶∫ÂÅµÊ∏¨Á≥ªÁµ±„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÈõñÁÑ∂ÈÄ≤ÈöéÊ®°ÂûãÁöÑË°®ÁèæÂèØËÉΩËºÉ‰Ω≥Ôºå‰ΩÜÂÖ∂ÊàêÊú¨‰πüÈ´òÂá∫Ë®±Â§ö„ÄÇÊàëÂÄë‰πüÂ±ïÁ§∫ÁêÜÊÉ≥ÁöÑÂπªË¶∫ÂÅµÊ∏¨Á≥ªÁµ±ÈúÄË¶ÅÂú®‰∏çÂêåÊ®°ÂûãË¶èÊ®°‰∏≠Á∂≠ÊåÅÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂº∑Ë™øÈÅ∏ÊìáËàáÁâπÂÆöÊáâÁî®ÈúÄÊ±ÇÂíåË≥áÊ∫êÈôêÂà∂Áõ∏Á¨¶ÁöÑÂÅµÊ∏¨Á≥ªÁµ±ÁöÑÈáçË¶ÅÊÄß„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∞áÊé¢Ë®éÊ∑∑ÂêàÁ≥ªÁµ±ÂíåËá™ÂãïË≠òÂà•‰ΩéÊïàËÉΩÂÖÉ‰ª∂Ôºå‰ª•ÊèêÂçá‰∫∫Â∑•Êô∫ÊÖßÂú®ÂÅµÊ∏¨ÂíåÊ∏õËºïÂπªË¶∫ÊñπÈù¢ÁöÑÂèØÈù†ÊÄßÂíåÊïàÁéá„ÄÇ

##### **Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations**
2411.05261v1 by Yingying Fang, Zihao Jin, Shaojie Guo, Jinda Liu, Yijian Gao, Junzhi Ning, Zhiling Yue, Zhi Li, Simon LF Walsh, Guang Yang

Despite significant advancements in report generation methods, a critical
limitation remains: the lack of interpretability in the generated text. This
paper introduces an innovative approach to enhance the explainability of text
generated by report generation models. Our method employs cyclic text
manipulation and visual comparison to identify and elucidate the features in
the original content that influence the generated text. By manipulating the
generated reports and producing corresponding images, we create a comparative
framework that highlights key attributes and their impact on the text
generation process. This approach not only identifies the image features
aligned to the generated text but also improves transparency but also provides
deeper insights into the decision-making mechanisms of the report generation
models. Our findings demonstrate the potential of this method to significantly
enhance the interpretability and transparency of AI-generated reports.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â†±ÂëäÁîüÊàêÊñπÊ≥ïÊúâÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜ‰ªçÂ≠òÂú®‰∏ÄÂÄãÂö¥ÈáçÁöÑÈôêÂà∂ÔºöÊâÄÁî¢ÁîüÊñáÂ≠óÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºå‰ª•Â¢ûÂº∑Â†±ÂëäÁîüÊàêÊ®°ÂûãÊâÄÁî¢ÁîüÊñáÂ≠óÁöÑÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊé°Áî®Âæ™Áí∞ÊñáÂ≠óËôïÁêÜÂíåË¶ñË¶∫ÊØîËºÉÔºå‰ª•Ë≠òÂà•‰∏¶Èó°ÊòéÂéüÂßãÂÖßÂÆπ‰∏≠ÂΩ±ÈüøÊâÄÁî¢ÁîüÊñáÂ≠óÁöÑÂäüËÉΩ„ÄÇËóâÁî±ËôïÁêÜÊâÄÁî¢ÁîüÁöÑÂ†±Âëä‰∏¶Áî¢ÁîüÂ∞çÊáâÁöÑÂΩ±ÂÉèÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊØîËºÉÊû∂ÊßãÔºåÁ™ÅÈ°ØÈóúÈçµÂ±¨ÊÄßÂíåÂÆÉÂÄëÂ∞çÊñáÂ≠óÁîüÊàêÈÅéÁ®ãÁöÑÂΩ±Èüø„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰∏çÂÉÖË≠òÂà•ËàáÊâÄÁî¢ÁîüÊñáÂ≠óÂ∞çÈΩäÁöÑÂΩ±ÂÉèÂäüËÉΩÔºåÈÇÑÊèêÈ´òÈÄèÊòéÂ∫¶Ôºå‰∏¶Êèê‰æõÂ∞çÂ†±ÂëäÁîüÊàêÊ®°ÂûãÊ±∫Á≠ñÊ©üÂà∂ÁöÑÊõ¥Ê∑±ÂÖ•Ë¶ãËß£„ÄÇÊàëÂÄëÁöÑÁôºÁèæË≠âÊòé‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑÊΩõÂäõÔºåÂèØ‰ª•È°ØËëóÂ¢ûÂº∑ AI ÁîüÊàêÁöÑÂ†±ÂëäÁöÑÂèØËß£ÈáãÊÄßÂíåÈÄèÊòéÂ∫¶„ÄÇ

##### **QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning**
2411.05260v1 by Md Jueal Mia, M. Hadi Amini

Federated Learning has emerged as a leading approach for decentralized
machine learning, enabling multiple clients to collaboratively train a shared
model without exchanging private data. While FL enhances data privacy, it
remains vulnerable to inference attacks, such as gradient inversion and
membership inference, during both training and inference phases. Homomorphic
Encryption provides a promising solution by encrypting model updates to protect
against such attacks, but it introduces substantial communication overhead,
slowing down training and increasing computational costs. To address these
challenges, we propose QuanCrypt-FL, a novel algorithm that combines low-bit
quantization and pruning techniques to enhance protection against attacks while
significantly reducing computational costs during training. Further, we propose
and implement mean-based clipping to mitigate quantization overflow or errors.
By integrating these methods, QuanCrypt-FL creates a communication-efficient FL
framework that ensures privacy protection with minimal impact on model
accuracy, thereby improving both computational efficiency and attack
resilience. We validate our approach on MNIST, CIFAR-10, and CIFAR-100
datasets, demonstrating superior performance compared to state-of-the-art
methods. QuanCrypt-FL consistently outperforms existing method and matches
Vanilla-FL in terms of accuracy across varying client. Further, QuanCrypt-FL
achieves up to 9x faster encryption, 16x faster decryption, and 1.5x faster
inference compared to BatchCrypt, with training time reduced by up to 3x.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏ÁøíÂ∑≤ÊàêÁÇ∫ÂàÜÊï£ÂºèÊ©üÂô®Â≠∏ÁøíÁöÑ‰∏ÄÁ®ÆÈ†òÂÖàÊñπÊ≥ïÔºå‰ΩøÂ§öÂÄãÁî®Êà∂Á´ØËÉΩÂ§†Âçî‰ΩúË®ìÁ∑¥ÂÖ±‰∫´Ê®°ÂûãÔºåËÄåÁÑ°ÈúÄ‰∫§ÊèõÁßÅÊúâÊï∏Êìö„ÄÇÈõñÁÑ∂ËÅØÈÇ¶Â≠∏ÁøíÂ¢ûÂº∑‰∫ÜÊï∏ÊìöÈö±ÁßÅÔºå‰ΩÜÂÆÉÂú®Ë®ìÁ∑¥ÂíåÊé®ÁêÜÈöéÊÆµ‰ªçÁÑ∂ÂÆπÊòìÂèóÂà∞Êé®ÁêÜÊîªÊìäÔºå‰æãÂ¶ÇÊ¢ØÂ∫¶ÂèçÊºîÂíåÊàêÂì°Êé®ÁêÜ„ÄÇÂêåÊÖãÂä†ÂØÜÈÄöÈÅéÂä†ÂØÜÊ®°ÂûãÊõ¥Êñ∞‰æÜÈò≤ÁØÑÊ≠§È°ûÊîªÊìäÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜÂÆÉÂºïÂÖ•‰∫ÜÂ§ßÈáèÁöÑÈÄö‰ø°ÈñãÈä∑ÔºåÊ∏õÊÖ¢‰∫ÜË®ìÁ∑¥ÈÄüÂ∫¶‰∏¶Â¢ûÂä†‰∫ÜË®àÁÆóÊàêÊú¨„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü QuanCrypt-FLÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊºîÁÆóÊ≥ïÔºåÂÆÉÁµêÂêà‰∫Ü‰Ωé‰ΩçÂÖÉÈáèÂåñÂíåÂâ™ÊûùÊäÄË°ìÔºå‰ª•Â¢ûÂº∑Â∞çÊîªÊìäÁöÑÈò≤Ë≠∑ÔºåÂêåÊôÇÈ°ØËëóÈôç‰ΩéË®ìÁ∑¥ÊúüÈñìÁöÑË®àÁÆóÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏¶ÂØ¶‰Ωú‰∫ÜÂü∫ÊñºÂπ≥ÂùáÂÄºÁöÑË£ÅÂâ™Ôºå‰ª•Ê∏õËºïÈáèÂåñÊ∫¢‰ΩçÊàñÈåØË™§„ÄÇÈÄöÈÅéÊï¥ÂêàÈÄô‰∫õÊñπÊ≥ïÔºåQuanCrypt-FL ÂâµÂª∫‰∫Ü‰∏ÄÂÄãÈÄö‰ø°ÊïàÁéáÈ´òÁöÑËÅØÈÇ¶Â≠∏ÁøíÊ°ÜÊû∂ÔºåÁ¢∫‰øùÈö±ÁßÅ‰øùË≠∑ÔºåÂ∞çÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÁöÑÂΩ±ÈüøÊúÄÂ∞èÔºåÂæûËÄåÊèêÈ´ò‰∫ÜË®àÁÆóÊïàÁéáÂíåÊîªÊìäÂΩàÊÄß„ÄÇÊàëÂÄëÂú® MNIST„ÄÅCIFAR-10 Âíå CIFAR-100 Ë≥áÊñôÈõÜ‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÊØîÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇQuanCrypt-FL Âú®‰∏çÂêåÁî®Êà∂Á´ØÁöÑÊ∫ñÁ¢∫ÊÄßÊñπÈù¢ÂßãÁµÇÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºå‰∏¶Ëàá Vanilla-FL Áõ∏ÂåπÈÖç„ÄÇÊ≠§Â§ñÔºåËàá BatchCrypt Áõ∏ÊØîÔºåQuanCrypt-FL ÁöÑÂä†ÂØÜÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü 9 ÂÄçÔºåËß£ÂØÜÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü 16 ÂÄçÔºåÊé®ÁêÜÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü 1.5 ÂÄçÔºåË®ìÁ∑¥ÊôÇÈñìÁ∏ÆÁü≠‰∫Ü 3 ÂÄç„ÄÇ

##### **What talking you?: Translating Code-Mixed Messaging Texts to English**
2411.05253v1 by Lynnette Hui Xian Ng, Luo Qi Chan

Translation of code-mixed texts to formal English allow a wider audience to
understand these code-mixed languages, and facilitate downstream analysis
applications such as sentiment analysis. In this work, we look at translating
Singlish, which is colloquial Singaporean English, to formal standard English.
Singlish is formed through the code-mixing of multiple Asian languages and
dialects. We analysed the presence of other Asian languages and variants which
can facilitate translation. Our dataset is short message texts, written as
informal communication between Singlish speakers. We use a multi-step prompting
scheme on five Large Language Models (LLMs) for language detection and
translation. Our analysis show that LLMs do not perform well in this task, and
we describe the challenges involved in translation of code-mixed languages. We
also release our dataset in this link https://github.com/luoqichan/singlish.

ÊëòË¶ÅÔºöÂ∞áÊ∑∑ÂêàË™ûË®ÄÁøªË≠ØÊàêÊ≠£ÂºèËã±ÊñáÔºåËÆìÊõ¥Âª£Ê≥õÁöÑÂèóÁúæÁêÜËß£ÈÄô‰∫õÊ∑∑ÂêàË™ûË®ÄÔºå‰∏¶‰øÉÈÄ≤‰∏ãÊ∏∏ÂàÜÊûêÊáâÁî®Á®ãÂºèÔºà‰æãÂ¶ÇÊÉÖÁ∑íÂàÜÊûêÔºâ„ÄÇÂú®Ê≠§Â∑•‰Ωú‰∏≠ÔºåÊàëÂÄëËëóÁúºÊñºÂ∞áÊñ∞Âä†Âù°Âè£Ë™ûËã±Ë™û Singlish ÁøªË≠ØÊàêÊ≠£ÂºèÊ®ôÊ∫ñËã±Ë™û„ÄÇSinglish ÊòØÈÄèÈÅéÊ∑∑ÂêàÂ§öÁ®Æ‰∫ûÊ¥≤Ë™ûË®ÄÂíåÊñπË®ÄÂΩ¢ÊàêÁöÑ„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÂÖ∂‰ªñ‰∫ûÊ¥≤Ë™ûË®ÄÂíåËÆäÈ´îÁöÑÂ≠òÂú®ÔºåÈÄô‰∫õË™ûË®ÄÂíåËÆäÈ´îÊúâÂä©ÊñºÁøªË≠Ø„ÄÇÊàëÂÄëÁöÑË≥áÊñôÈõÜÊòØÁ∞°Ë®äÔºåÁî± Singlish ‰ΩøÁî®ËÄÖÂØ´ÊàêÈùûÊ≠£ÂºèÁöÑÊ∫ùÈÄöÂÖßÂÆπ„ÄÇÊàëÂÄëÂ∞ç‰∫îÁ®ÆÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ΩøÁî®Â§öÊ≠•È©üÊèêÁ§∫ÊñπÊ°àÈÄ≤Ë°åË™ûË®ÄÂÅµÊ∏¨ÂíåÁøªË≠Ø„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåLLM Âú®ÈÄôÈ†Ö‰ªªÂãô‰∏≠Ë°®Áèæ‰∏ç‰Ω≥ÔºåÊàëÂÄëÊèèËø∞‰∫ÜÊ∑∑ÂêàË™ûË®ÄÁøªË≠ØÊâÄÊ∂âÂèäÁöÑÊåëÊà∞„ÄÇÊàëÂÄë‰πüÊúÉÂú®Ê≠§ÈÄ£Áµê https://github.com/luoqichan/singlish ÈáãÂá∫ÊàëÂÄëÁöÑË≥áÊñôÈõÜ„ÄÇ

##### **Abstract2Appendix: Academic Reviews Enhance LLM Long-Context Capabilities**
2411.05232v1 by Shengzhi Li, Kittipat Kampa, Rongyu Lin, Bohang Li, Shichao Pei

Large language models (LLMs) have shown remarkable performance across various
tasks, yet their ability to handle long-context reading remains challenging.
This study explores the effectiveness of leveraging high-quality academic peer
review data for fine-tuning LLMs to enhance their long-context capabilities. We
compare the Direct Preference Optimization (DPO) method with the Supervised
Fine-Tuning (SFT) method, demonstrating DPO's superiority and data efficiency.
Our experiments show that the fine-tuned model achieves a 4.04-point
improvement over phi-3 and a 2.6\% increase on the Qasper benchmark using only
2000 samples. Despite facing limitations in data scale and processing costs,
this study underscores the potential of DPO and high-quality data in advancing
LLM performance.
  Additionally, the zero-shot benchmark results indicate that aggregated
high-quality human reviews are overwhelmingly preferred over LLM-generated
responses, even for the most capable models like GPT-4o. This suggests that
high-quality human reviews are extremely rich in information, reasoning, and
long-context retrieval, capabilities that even the most advanced models have
not fully captured. These findings highlight the high utility of leveraging
human reviews to further advance the field.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫È°ØËëóÁöÑÊïàËÉΩÔºå‰ΩÜÂÆÉÂÄëËôïÁêÜÈï∑Ë™ûÂ¢ÉÈñ±ËÆÄÁöÑËÉΩÂäõ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂà©Áî®È´òÂìÅË≥™ÁöÑÂ≠∏Ë°ìÂêåË°åË©ïÂØ©Ë≥áÊñôÂæÆË™ø LLMÔºå‰ª•Â¢ûÂº∑ÂÖ∂Èï∑Ë™ûÂ¢ÉËÉΩÂäõÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÂ∞áÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºàDPOÔºâÊñπÊ≥ïËàáÁõ£Áù£ÂæÆË™øÔºàSFTÔºâÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉÔºåË≠âÊòé‰∫Ü DPO ÁöÑÂÑ™Ë∂äÊÄßÂíåË≥áÊñôÊïàÁéá„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÂæÆË™øÂæåÁöÑÊ®°ÂûãÂú® phi-3 ‰∏äÂèñÂæó‰∫Ü 4.04 ÂàÜÁöÑÈÄ≤Ê≠•ÔºåÂú® Qasper Âü∫Ê∫ñ‰∏äÂÉÖ‰ΩøÁî® 2000 ÂÄãÊ®£Êú¨Â∞±Â¢ûÂä†‰∫Ü 2.6%„ÄÇÂÑòÁÆ°Âú®Ë≥áÊñôË¶èÊ®°ÂíåËôïÁêÜÊàêÊú¨ÊñπÈù¢Èù¢Ëá®ÈôêÂà∂Ôºå‰ΩÜÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫Ü DPO ÂíåÈ´òÂìÅË≥™Ë≥áÊñôÂú®ÊèêÂçá LLM ÊïàËÉΩÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÊ≠§Â§ñÔºåÈõ∂Ê¨°Â≠∏ÁøíÂü∫Ê∫ñÁµêÊûúË°®ÊòéÔºåÂç≥‰ΩøÂ∞çÊñºÂÉè GPT-4o ÈÄôÊ®£ÊúÄÂº∑Â§ßÁöÑÊ®°ÂûãÔºåÂΩôÁ∏ΩÁöÑÈ´òÂìÅË≥™‰∫∫È°ûË©ïË´ñ‰πüÊØî LLM ÁîüÊàêÁöÑÂõûÊáâÊõ¥ÂèóÊ≠°Ëøé„ÄÇÈÄôË°®ÊòéÈ´òÂìÅË≥™ÁöÑ‰∫∫È°ûË©ïË´ñÊ•µÂÖ∂Ë±êÂØåÔºåÂåÖÂê´Ë≥áË®ä„ÄÅÊé®ÁêÜÂíåÈï∑Ë™ûÂ¢ÉÊ™¢Á¥¢ÔºåÈÄôÊòØÂç≥‰ΩøÊòØÊúÄÂÖàÈÄ≤ÁöÑÊ®°Âûã‰πüÂ∞öÊú™ÂÆåÂÖ®ÊéåÊè°ÁöÑËÉΩÂäõ„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÂá∫‰∫ÜÂà©Áî®‰∫∫È°ûË©ïË´ñÈÄ≤‰∏ÄÊ≠•Êé®ÂãïË©≤È†òÂüüÁôºÂ±ïÁöÑÈ´òÊïàÁî®ÊÄß„ÄÇ

##### **Evaluating GPT-4 at Grading Handwritten Solutions in Math Exams**
2411.05231v1 by Adriana Caraeni, Alexander Scarlatos, Andrew Lan

Recent advances in generative artificial intelligence (AI) have shown promise
in accurately grading open-ended student responses. However, few prior works
have explored grading handwritten responses due to a lack of data and the
challenge of combining visual and textual information. In this work, we
leverage state-of-the-art multi-modal AI models, in particular GPT-4o, to
automatically grade handwritten responses to college-level math exams. Using
real student responses to questions in a probability theory exam, we evaluate
GPT-4o's alignment with ground-truth scores from human graders using various
prompting techniques. We find that while providing rubrics improves alignment,
the model's overall accuracy is still too low for real-world settings, showing
there is significant room for growth in this task.

ÊëòË¶ÅÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂ∑≤Âú®Ê∫ñÁ¢∫Ë©ïÂàÜÈñãÊîæÂºèÂ≠∏ÁîüÂõûÊáâÊñπÈù¢Â±ïÁèæÂá∫ÂâçÊôØ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁº∫‰πèË≥áÊñôÂíåÁµêÂêàË¶ñË¶∫ËàáÊñáÂ≠óË≥áË®äÁöÑÊåëÊà∞ÔºåÈÆÆÂ∞ëÊúâÂÖàÂâçÁöÑÁ†îÁ©∂Êé¢Ë®éË©ïÂàÜÊâãÂØ´ÂõûÊáâ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂà©Áî®ÊúÄÂÖàÈÄ≤ÁöÑÂ§öÊ®°ÊÖã AI Ê®°ÂûãÔºåÁâπÂà•ÊòØ GPT-4oÔºåËá™ÂãïË©ïÂàÜÂ§ßÂ≠∏Á®ãÂ∫¶Êï∏Â≠∏ËÄÉË©¶ÁöÑÊâãÂØ´ÂõûÊáâ„ÄÇ‰ΩøÁî®ÂØ¶ÈöõÂ≠∏ÁîüÂ∞çÊ©üÁéáË´ñËÄÉË©¶‰∏≠ÂïèÈ°åÁöÑÂõûÊáâÔºåÊàëÂÄë‰ΩøÁî®ÂêÑÁ®ÆÊèêÁ§∫ÊäÄË°ìÔºåË©ï‰º∞ GPT-4o Ëàá‰∫∫È°ûË©ïÂàÜËÄÖÁöÑÁúüÂØ¶ÂàÜÊï∏‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÊàëÂÄëÁôºÁèæÔºåÂÑòÁÆ°Êèê‰æõË©ïÂàÜÊ®ôÊ∫ñËÉΩÊîπÂñÑ‰∏ÄËá¥ÊÄßÔºå‰ΩÜÊ®°ÂûãÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶Â∞çÊñºÂØ¶ÈöõÊÉÖÊ≥Å‰æÜË™™‰ªçÁÑ∂Â§™‰ΩéÔºåÈ°ØÁ§∫Âá∫Ê≠§‰ªªÂãô‰ªçÊúâÂæàÂ§ßÁöÑÊàêÈï∑Á©∫Èñì„ÄÇ

##### **CHATTER: A Character Attribution Dataset for Narrative Understanding**
2411.05227v1 by Sabyasachee Baruah, Shrikanth Narayanan

Computational narrative understanding studies the identification,
description, and interaction of the elements of a narrative: characters,
attributes, events, and relations. Narrative research has given considerable
attention to defining and classifying character types. However, these
character-type taxonomies do not generalize well because they are small, too
simple, or specific to a domain. We require robust and reliable benchmarks to
test whether narrative models truly understand the nuances of the character's
development in the story. Our work addresses this by curating the Chatter
dataset that labels whether a character portrays some attribute for 88148
character-attribute pairs, encompassing 2998 characters, 13324 attributes and
660 movies. We validate a subset of Chatter, called ChatterEval, using human
annotations to serve as an evaluation benchmark for the character attribution
task in movie scripts. ChatterEval assesses narrative understanding and the
long-context modeling capacity of language models.

ÊëòË¶ÅÔºöË®àÁÆóÊïò‰∫ãÁêÜËß£Á†îÁ©∂Êé¢Ë®éÊïò‰∫ãÁöÑÂÖÉÁ¥†Ë≠òÂà•„ÄÅÊèèËø∞Âíå‰∫íÂãïÔºöËßíËâ≤„ÄÅÂ±¨ÊÄß„ÄÅ‰∫ã‰ª∂ÂíåÈóú‰øÇ„ÄÇÊïò‰∫ãÁ†îÁ©∂ÈùûÂ∏∏ÈáçË¶ñËßíËâ≤È°ûÂûãÁöÑÂÆöÁæ©ÂíåÂàÜÈ°û„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËßíËâ≤È°ûÂûãÂàÜÈ°ûÊ≥ïÁÑ°Ê≥ïÂæàÂ•ΩÂú∞Ê¶ÇÊã¨ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëË¶èÊ®°Â∞è„ÄÅÈÅéÊñºÁ∞°ÂñÆÊàñÁâπÂÆöÊñºÊüêÂÄãÈ†òÂüü„ÄÇÊàëÂÄëÈúÄË¶ÅÁ©©ÂÅ•‰∏îÂèØÈù†ÁöÑÂü∫Ê∫ñ‰æÜÊ∏¨Ë©¶Êïò‰∫ãÊ®°ÂûãÊòØÂê¶ÁúüÊ≠£ÁêÜËß£ÊïÖ‰∫ã‰∏≠ËßíËâ≤ÁôºÂ±ïÁöÑÁ¥∞ÂæÆÂ∑ÆÂà•„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄöÈÅéÊï¥ÁêÜ Chatter Ë≥áÊñôÈõÜ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåË©≤Ë≥áÊñôÈõÜÊ®ôË®òËßíËâ≤ÊòØÂê¶ÁÇ∫ 88148 ÂÄãËßíËâ≤Â±¨ÊÄßÂ∞ç‰∏≠ÁöÑÊüêÂÄãÂ±¨ÊÄßÔºåÊ∂µËìã 2998 ÂÄãËßíËâ≤„ÄÅ13324 ÂÄãÂ±¨ÊÄßÂíå 660 ÈÉ®ÈõªÂΩ±„ÄÇÊàëÂÄë‰ΩøÁî®‰∫∫È°ûË®ªÈáãÈ©óË≠â‰∫Ü Chatter ÁöÑ‰∏ÄÂÄãÂ≠êÈõÜÔºåÁ®±ÁÇ∫ ChatterEvalÔºå‰ΩúÁÇ∫ÈõªÂΩ±ËÖ≥Êú¨‰∏≠ËßíËâ≤Ê≠∏Âõ†‰ªªÂãôÁöÑË©ï‰º∞Âü∫Ê∫ñ„ÄÇChatterEval Ë©ï‰º∞Êïò‰∫ãÁêÜËß£ÂíåË™ûË®ÄÊ®°ÂûãÁöÑÈï∑‰∏ä‰∏ãÊñáÂª∫Ê®°ËÉΩÂäõ„ÄÇ

##### **Beyond the Numbers: Transparency in Relation Extraction Benchmark Creation and Leaderboards**
2411.05224v1 by Varvara Arzt, Allan Hanbury

This paper investigates the transparency in the creation of benchmarks and
the use of leaderboards for measuring progress in NLP, with a focus on the
relation extraction (RE) task. Existing RE benchmarks often suffer from
insufficient documentation, lacking crucial details such as data sources,
inter-annotator agreement, the algorithms used for the selection of instances
for datasets, and information on potential biases like dataset imbalance.
Progress in RE is frequently measured by leaderboards that rank systems based
on evaluation methods, typically limited to aggregate metrics like F1-score.
However, the absence of detailed performance analysis beyond these metrics can
obscure the true generalisation capabilities of models. Our analysis reveals
that widely used RE benchmarks, such as TACRED and NYT, tend to be highly
imbalanced and contain noisy labels. Moreover, the lack of class-based
performance metrics fails to accurately reflect model performance across
datasets with a large number of relation types. These limitations should be
carefully considered when reporting progress in RE. While our discussion
centers on the transparency of RE benchmarks and leaderboards, the observations
we discuss are broadly applicable to other NLP tasks as well. Rather than
undermining the significance and value of existing RE benchmarks and the
development of new models, this paper advocates for improved documentation and
more rigorous evaluation to advance the field.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫ÜÂü∫Ê∫ñÂª∫Á´ãÁöÑÈÄèÊòéÂ∫¶Ôºå‰ª•Âèä‰ΩøÁî®ÊéíË°åÊ¶ú‰æÜË°°ÈáèËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÈÄ≤Â∫¶ÁöÑ‰ΩøÁî®ÔºåÈáçÈªûÂú®ÊñºÈóú‰øÇËêÉÂèñ (RE) ‰ªªÂãô„ÄÇÁèæÊúâÁöÑ RE Âü∫Ê∫ñÁ∂ìÂ∏∏ÊúÉÂõ†ÁÇ∫Êñá‰ª∂‰∏çË∂≥ËÄåÊúâÊâÄÁº∫Â§±ÔºåÁº∫Â∞ëÈóúÈçµÁ¥∞ÁØÄÔºå‰æãÂ¶ÇË≥áÊñô‰æÜÊ∫ê„ÄÅÊ®ôË®ªÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÅÁî®ÊñºÈÅ∏ÊìáË≥áÊñôÈõÜÂØ¶‰æãÁöÑÊºîÁÆóÊ≥ïÔºå‰ª•ÂèäÈóúÊñºÊΩõÂú®ÂÅèÂ∑ÆÔºà‰æãÂ¶ÇË≥áÊñôÈõÜ‰∏çÂπ≥Ë°°ÔºâÁöÑË≥áË®ä„ÄÇRE ÁöÑÈÄ≤Â∫¶Á∂ìÂ∏∏ÈÄèÈÅéÊéíË°åÊ¶ú‰æÜË°°ÈáèÔºåÊéíË°åÊ¶úÊúÉÊ†πÊìöË©ï‰º∞ÊñπÊ≥ïÂ∞çÁ≥ªÁµ±ÈÄ≤Ë°åÊéíÂêçÔºåÈÄöÂ∏∏ÂÉÖÈôêÊñº F1 ÂàÜÊï∏Á≠âÂΩôÁ∏ΩÊåáÊ®ô„ÄÇÁÑ∂ËÄåÔºåÈô§‰∫ÜÈÄô‰∫õÊåáÊ®ô‰πãÂ§ñÔºåÁº∫‰πèË©≥Á¥∞ÁöÑÊïàËÉΩÂàÜÊûêÂèØËÉΩÊúÉÊ®°Á≥äÊ®°ÂûãÁúüÊ≠£ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂª£Ê≥õ‰ΩøÁî®ÁöÑ RE Âü∫Ê∫ñÔºà‰æãÂ¶Ç TACRED Âíå NYTÔºâÂæÄÂæÄÈ´òÂ∫¶‰∏çÂπ≥Ë°°ÔºåËÄå‰∏îÂåÖÂê´ÊúâÈõúË®äÁöÑÊ®ôÁ±§„ÄÇÊ≠§Â§ñÔºåÁº∫‰πèÂü∫ÊñºÈ°ûÂà•ÁöÑÊïàËÉΩÊåáÊ®ôÔºåÁÑ°Ê≥ïÊ∫ñÁ¢∫ÂèçÊò†Ê®°ÂûãÂú®ÂÖ∑ÊúâÂ§ßÈáèÈóú‰øÇÈ°ûÂûãÁöÑË≥áÊñôÈõÜ‰∏≠ÁöÑÊïàËÉΩ„ÄÇÂú®ÂõûÂ†± RE ÈÄ≤Â∫¶ÊôÇÔºåÊáâ‰ªîÁ¥∞ËÄÉÊÖÆÈÄô‰∫õÈôêÂà∂„ÄÇÈõñÁÑ∂ÊàëÂÄëÁöÑË®éË´ñÈáçÈªûÂú®Êñº RE Âü∫Ê∫ñÂíåÊéíË°åÊ¶úÁöÑÈÄèÊòéÂ∫¶Ôºå‰ΩÜÊàëÂÄëË®éË´ñÁöÑËßÄÂØüÁµêÊûú‰πüÂª£Ê≥õÈÅ©Áî®ÊñºÂÖ∂‰ªñ NLP ‰ªªÂãô„ÄÇÊú¨Êñá‰∏¶ÈùûË¶ÅÁ†¥Â£ûÁèæÊúâ RE Âü∫Ê∫ñÂíåÊñ∞Ê®°ÂûãÈñãÁôºÁöÑÈáçË¶ÅÊÄßËàáÂÉπÂÄºÔºåËÄåÊòØ‰∏ªÂºµÊîπÂñÑÊñá‰ª∂Ë®òÈåÑÂíåÊõ¥Âö¥Ë¨πÁöÑË©ï‰º∞Ôºå‰ª•Êé®ÈÄ≤Ê≠§È†òÂüü„ÄÇ

##### **STAND-Guard: A Small Task-Adaptive Content Moderation Model**
2411.05214v1 by Minjia Wang, Pingping Lin, Siqi Cai, Shengnan An, Shengjie Ma, Zeqi Lin, Congrui Huang, Bixiong Xu

Content moderation, the process of reviewing and monitoring the safety of
generated content, is important for development of welcoming online platforms
and responsible large language models. Content moderation contains various
tasks, each with its unique requirements tailored to specific scenarios.
Therefore, it is crucial to develop a model that can be easily adapted to novel
or customized content moderation tasks accurately without extensive model
tuning. This paper presents STAND-GUARD, a Small Task-Adaptive coNtent
moDeration model. The basic motivation is: by performing instruct tuning on
various content moderation tasks, we can unleash the power of small language
models (SLMs) on unseen (out-of-distribution) content moderation tasks. We also
carefully study the effects of training tasks and model size on the efficacy of
cross-task fine-tuning mechanism. Experiments demonstrate STAND-Guard is
comparable to GPT-3.5-Turbo across over 40 public datasets, as well as
proprietary datasets derived from real-world business scenarios. Remarkably,
STAND-Guard achieved nearly equivalent results to GPT-4-Turbo on unseen English
binary classification tasks

ÊëòË¶ÅÔºöÂÖßÂÆπÂØ©Ê†∏ÔºåÊ™¢Èñ±ÂíåÁõ£ÊéßÁîüÊàêÂÖßÂÆπÂÆâÂÖ®ÊÄßÁöÑÈÅéÁ®ãÔºåÂ∞çÊñºÈñãÁôºÊ≠°ËøéÁöÑÁ∑ö‰∏äÂπ≥Âè∞ÂíåË≤†Ë≤¨‰ªªÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãËá≥ÈóúÈáçË¶Å„ÄÇÂÖßÂÆπÂØ©Ê†∏ÂåÖÂê´ÂêÑÁ®Æ‰ªªÂãôÔºåÊØèÂÄã‰ªªÂãôÈÉΩÊúâÂÖ∂Áç®ÁâπÁöÑË¶ÅÊ±ÇÔºåÊ†πÊìöÁâπÂÆöÂ†¥ÊôØÈáèË∫´ÂÆöÂà∂„ÄÇÂõ†Ê≠§ÔºåÈñãÁôº‰∏ÄÂÄãÊ®°ÂûãËá≥ÈóúÈáçË¶ÅÔºåË©≤Ê®°ÂûãÂèØ‰ª•ËºïÈ¨ÜÈÅ©ÊáâÊñ∞Á©éÊàñËá™Ë®ÇÁöÑÂÖßÂÆπÂØ©Ê†∏‰ªªÂãôÔºåËÄåÁÑ°ÈúÄÂª£Ê≥õÁöÑÊ®°ÂûãË™øÊï¥„ÄÇÊú¨Êñá‰ªãÁ¥π STAND-GUARDÔºå‰∏ÄÂÄãÂ∞èÂûã‰ªªÂãôÈÅ©ÊáâÊÄßÂÖßÂÆπÂØ©Ê†∏Ê®°Âûã„ÄÇÂü∫Êú¨ÂãïÊ©üÊòØÔºöÈÄöÈÅéÂ∞çÂêÑÁ®ÆÂÖßÂÆπÂØ©Ê†∏‰ªªÂãôÂü∑Ë°åÊåá‰ª§Ë™øÊï¥ÔºåÊàëÂÄëÂèØ‰ª•ÈáãÊîæÂ∞èÂûãË™ûË®ÄÊ®°Âûã (SLM) Âú®Êú™Ë¶ãÔºàÂàÜ‰ΩàÂ§ñÔºâÂÖßÂÆπÂØ©Ê†∏‰ªªÂãô‰∏äÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÈÇÑ‰ªîÁ¥∞Á†îÁ©∂‰∫ÜË®ìÁ∑¥‰ªªÂãôÂíåÊ®°ÂûãÂ§ßÂ∞èÂ∞çË∑®‰ªªÂãôÂæÆË™øÊ©üÂà∂ÁöÑÂäüÊïàÁöÑÂΩ±Èüø„ÄÇÂØ¶È©óË°®ÊòéÔºåSTAND-Guard Âú® 40 Â§öÂÄãÂÖ¨ÂÖ±Êï∏ÊìöÈõÜ‰ª•ÂèäÊ∫êËá™ÁèæÂØ¶‰∏ñÁïåÊ•≠ÂãôÂ†¥ÊôØÁöÑÂ∞àÊúâÊï∏ÊìöÈõÜ‰∏äËàá GPT-3.5-Turbo Áõ∏Áï∂„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåSTAND-Guard Âú®Êú™Ë¶ãÁöÑËã±Ë™û‰∫åÂÖÉÂàÜÈ°û‰ªªÂãô‰∏äÂèñÂæó‰∫ÜËàá GPT-4-Turbo Ëøë‰πéÁõ∏Áï∂ÁöÑÁµêÊûú

##### **Alopex: A Computational Framework for Enabling On-Device Function Calls with LLMs**
2411.05209v1 by Yide Ran, Zhaozhuo Xu, Yuhang Yao, Zijian Hu, Shanshan Han, Han Jin, Alay Dilipbhai Shah, Jipeng Zhang, Dimitris Stripelis, Tong Zhang, Salman Avestimehr, Chaoyang He

The rapid advancement of Large Language Models (LLMs) has led to their
increased integration into mobile devices for personalized assistance, which
enables LLMs to call external API functions to enhance their performance.
However, challenges such as data scarcity, ineffective question formatting, and
catastrophic forgetting hinder the development of on-device LLM agents. To
tackle these issues, we propose Alopex, a framework that enables precise
on-device function calls using the Fox LLM. Alopex introduces a logic-based
method for generating high-quality training data and a novel
``description-question-output'' format for fine-tuning, reducing risks of
function information leakage. Additionally, a data mixing strategy is used to
mitigate catastrophic forgetting, combining function call data with textbook
datasets to enhance performance in various tasks. Experimental results show
that Alopex improves function call accuracy and significantly reduces
catastrophic forgetting, providing a robust solution for integrating function
call capabilities into LLMs without manual intervention.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÈÄ≤Â±ïÂ∑≤Â∞éËá¥ÂÆÉÂÄëÊõ¥Â§öÂú∞Êï¥ÂêàÂà∞Ë°åÂãïË£ùÁΩÆ‰∏≠Ôºå‰ª•Êèê‰æõÂÄã‰∫∫ÂåñÂçîÂä©ÔºåÈÄôËÆì LLM ËÉΩÂ§†ÂëºÂè´Â§ñÈÉ® API ÂäüËÉΩ‰ª•ÊèêÂçáÂÖ∂ÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåË≥áÊñôÁ®ÄÂ∞ë„ÄÅÊèêÂïèÊ†ºÂºèÁÑ°Êïà„ÄÅ‰ª•ÂèäÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÁ≠âÊåëÊà∞ÈòªÁ§ô‰∫ÜË£ùÁΩÆ‰∏ä LLM ‰ª£ÁêÜÁöÑÁôºÂ±ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü AlopexÔºå‰∏ÄÂÄã‰ΩøÁî® Fox LLM ÂïüÁî®Á≤æÊ∫ñË£ùÁΩÆ‰∏äÂäüËÉΩÂëºÂè´ÁöÑÊû∂Êßã„ÄÇAlopex Â∞éÂÖ•‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÈÇèËºØÁöÑÊñπÊ≥ï‰æÜÁî¢ÁîüÈ´òÂìÅË≥™Ë®ìÁ∑¥Ë≥áÊñôÔºå‰ª•Âèä‰∏ÄÁ®ÆÁî®ÊñºÂæÆË™øÁöÑÂâµÊñ∞„ÄåÊèèËø∞-ÂïèÈ°å-Ëº∏Âá∫„ÄçÊ†ºÂºèÔºå‰ª•Èôç‰ΩéÂäüËÉΩË≥áË®äÂ§ñÊ¥©ÁöÑÈ¢®Èö™„ÄÇÊ≠§Â§ñÔºåË≥áÊñôÊ∑∑ÂêàÁ≠ñÁï•Áî®ÊñºÊ∏õËºïÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÔºåÂ∞áÂäüËÉΩÂëºÂè´Ë≥áÊñôËàáÊïôÁßëÊõ∏Ë≥áÊñôÈõÜÁµêÂêàÔºå‰ª•ÊèêÂçáÂêÑÁ®Æ‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåAlopex ÊîπÂñÑ‰∫ÜÂäüËÉΩÂëºÂè´Ê∫ñÁ¢∫ÊÄßÔºå‰∏¶Â§ßÂπÖÈôç‰ΩéÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑ÂÅ•ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂèØ‰ª•Áî®ÊñºÊï¥ÂêàÂäüËÉΩÂëºÂè´ËÉΩÂäõÂà∞ LLMÔºåËÄåÁÑ°ÈúÄÊâãÂãï‰ªãÂÖ•„ÄÇ

##### **Toward Cultural Interpretability: A Linguistic Anthropological Framework for Describing and Evaluating Large Language Models (LLMs)**
2411.05200v1 by Graham M. Jones, Shai Satran, Arvind Satyanarayan

This article proposes a new integration of linguistic anthropology and
machine learning (ML) around convergent interests in both the underpinnings of
language and making language technologies more socially responsible. While
linguistic anthropology focuses on interpreting the cultural basis for human
language use, the ML field of interpretability is concerned with uncovering the
patterns that Large Language Models (LLMs) learn from human verbal behavior.
Through the analysis of a conversation between a human user and an LLM-powered
chatbot, we demonstrate the theoretical feasibility of a new, conjoint field of
inquiry, cultural interpretability (CI). By focusing attention on the
communicative competence involved in the way human users and AI chatbots
co-produce meaning in the articulatory interface of human-computer interaction,
CI emphasizes how the dynamic relationship between language and culture makes
contextually sensitive, open-ended conversation possible. We suggest that, by
examining how LLMs internally "represent" relationships between language and
culture, CI can: (1) provide insight into long-standing linguistic
anthropological questions about the patterning of those relationships; and (2)
aid model developers and interface designers in improving value alignment
between language models and stylistically diverse speakers and culturally
diverse speech communities. Our discussion proposes three critical research
axes: relativity, variation, and indexicality.

ÊëòË¶ÅÔºöÈÄôÁØáÊñáÁ´†ÊèêÂá∫Ë™ûË®Ä‰∫∫È°ûÂ≠∏ËàáÊ©üÂô®Â≠∏ÁøíÔºàMLÔºâÁöÑÊñ∞Êï¥ÂêàÔºåÂúçÁπûË™ûË®ÄÂü∫Á§éÂíåËÆìË™ûË®ÄÊäÄË°ìÊõ¥ÂÖ∑Á§æÊúÉË≤¨‰ªªÁöÑÂÖ±ÂêåËààË∂£„ÄÇË™ûË®Ä‰∫∫È°ûÂ≠∏Â∞àÊ≥®ÊñºË©ÆÈáã‰∫∫È°ûË™ûË®Ä‰ΩøÁî®ÁöÑÊñáÂåñÂü∫Á§éÔºåËÄå ML ÁöÑÂèØËß£ÈáãÊÄßÈ†òÂüüÂâáÈóúÊ≥®Êè≠Á§∫Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂæû‰∫∫È°ûË®ÄË™ûË°åÁÇ∫‰∏≠Â≠∏ÁøíÂà∞ÁöÑÊ®°Âºè„ÄÇÈÄèÈÅéÂàÜÊûê‰∫∫È°û‰ΩøÁî®ËÄÖËàá LLM È©ÖÂãïÁöÑËÅäÂ§©Ê©üÂô®‰∫∫‰πãÈñìÁöÑÂ∞çË©±ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑËÅØÂêàÁ†îÁ©∂È†òÂüü„ÄåÊñáÂåñÂèØËß£ÈáãÊÄß„ÄçÔºàCIÔºâÁöÑÁêÜË´ñÂèØË°åÊÄß„ÄÇCI Â∞àÊ≥®Êñº‰∫∫È°û‰ΩøÁî®ËÄÖÂíå AI ËÅäÂ§©Ê©üÂô®‰∫∫Âú®‰∫∫Ê©ü‰∫íÂãïÁöÑË°®Ëø∞‰ªãÈù¢‰∏≠ÂÖ±ÂêåÂª∫ÊßãÊÑèÁæ©ÊôÇÊâÄÊ∂âÂèäÁöÑÊ∫ùÈÄöËÉΩÂäõÔºåÂº∑Ë™øË™ûË®ÄÂíåÊñáÂåñ‰πãÈñìÁöÑÂãïÊÖãÈóú‰øÇÂ¶Ç‰ΩïËÆìÊÉÖÂ¢ÉÊïèÊÑüÁöÑÈñãÊîæÂºèÂ∞çË©±ÊàêÁÇ∫ÂèØËÉΩ„ÄÇÊàëÂÄëÂª∫Ë≠∞ÔºåÈÄèÈÅéÊ™¢Ë¶ñ LLM Â¶Ç‰ΩïÂú®ÂÖßÈÉ®„ÄåË°®Âæµ„ÄçË™ûË®ÄÂíåÊñáÂåñ‰πãÈñìÁöÑÈóú‰øÇÔºåCI ÂèØ‰ª•ÔºöÔºà1ÔºâÊèê‰æõÂ∞çÈÇ£‰∫õÈóú‰øÇÊ®°ÂºèÁöÑÈï∑ÊúüË™ûË®Ä‰∫∫È°ûÂ≠∏ÂïèÈ°åÁöÑË¶ãËß£Ôºõ‰ª•ÂèäÔºà2ÔºâÂçîÂä©Ê®°ÂûãÈñãÁôº‰∫∫Âì°Âíå‰ªãÈù¢Ë®≠Ë®àÂ∏´ÊîπÂñÑË™ûË®ÄÊ®°ÂûãËàáÈ¢®Ê†ºÂ§öÊ®£ÂåñÁöÑË™™Ë©±ËÄÖÂíåÊñáÂåñÂ§öÊ®£ÂåñÁöÑË™ûË®ÄÁ§æÁæ§‰πãÈñìÁöÑÂÉπÂÄºÂ∞çÈΩä„ÄÇÊàëÂÄëÁöÑË®éË´ñÊèêÂá∫‰∫Ü‰∏âÂÄãÈáçË¶ÅÁöÑÁ†îÁ©∂Ëª∏Á∑öÔºöÁõ∏Â∞çÊÄß„ÄÅËÆäÁï∞ÊÄßÂíåÊåáÁ§∫ÊÄß„ÄÇ

##### **CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement**
2411.05199v1 by Leitian Tao, Xiang Chen, Tong Yu, Tung Mai, Ryan Rossi, Yixuan Li, Saayan Mitra

Large Language Models (LLMs) have significantly advanced code generation but
often require substantial resources and tend to over-generalize, limiting their
efficiency for specific tasks. Fine-tuning smaller, open-source LLMs presents a
viable alternative; however, it typically lags behind cutting-edge models due
to supervised fine-tuning's reliance solely on correct code examples, which
restricts the model's ability to learn from its own mistakes and adapt to
diverse programming challenges. To bridge this gap, we introduce CodeLutra, a
novel framework that enhances low-performing LLMs by leveraging both successful
and failed code generation attempts. Unlike conventional fine-tuning, CodeLutra
employs an iterative preference learning mechanism to compare correct and
incorrect solutions as well as maximize the likelihood of correct codes.
Through continuous iterative refinement, CodeLutra enables smaller LLMs to
match or surpass GPT-4's performance in various code generation tasks without
relying on vast external datasets or larger auxiliary models. On a challenging
data analysis task, using just 500 samples improved Llama-3-8B's accuracy from
28.2% to 48.6%, approaching GPT-4's performance. These results highlight
CodeLutra's potential to close the gap between open-source and closed-source
models, making it a promising approach in the field of code generation.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤È°ØËëóÊèêÂçáÁ®ãÂºèÁ¢ºÁî¢ÁîüÔºå‰ΩÜÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèË≥áÊ∫êÔºå‰∏îÂÇæÂêëÈÅéÂ∫¶Ê¶ÇÂåñÔºåÈôêÂà∂ÂÖ∂Âú®ÁâπÂÆö‰ªªÂãô‰∏≠ÁöÑÊïàÁéá„ÄÇÂæÆË™øËºÉÂ∞è„ÄÅÈñãÊîæÂéüÂßãÁ¢ºÁöÑ LLM Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØË°åÁöÑÊõø‰ª£ÊñπÊ°àÔºõÁÑ∂ËÄåÔºåÁî±ÊñºÁõ£Áù£ÂæÆË™øÂÉÖ‰æùË≥¥ÊñºÊ≠£Á¢∫ÁöÑÁ®ãÂºèÁ¢ºÁØÑ‰æãÔºåÂõ†Ê≠§ÈÄöÂ∏∏ËêΩÂæåÊñºÂ∞ñÁ´ØÊ®°ÂûãÔºåÈÄôÈôêÂà∂‰∫ÜÊ®°ÂûãÂæûÂÖ∂Ëá™Ë∫´ÈåØË™§‰∏≠Â≠∏ÁøíÂíåÈÅ©ÊáâÂêÑÁ®ÆÁ®ãÂºèË®≠Ë®àÊåëÊà∞ÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü CodeLutraÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄöÈÅéÂà©Áî®ÊàêÂäüÂíåÂ§±ÊïóÁöÑÁ®ãÂºèÁ¢ºÁîüÊàêÂòóË©¶‰æÜÂ¢ûÂº∑ÊïàËÉΩ‰∏ç‰Ω≥ÁöÑ LLM ÁöÑÊñ∞Ê°ÜÊû∂„ÄÇËàáÂÇ≥Áµ±ÂæÆË™ø‰∏çÂêåÔºåCodeLutra Êé°Áî®ÂèçË¶ÜÂÅèÂ•ΩÂ≠∏ÁøíÊ©üÂà∂‰æÜÊØîËºÉÊ≠£Á¢∫Âíå‰∏çÊ≠£Á¢∫ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰∏¶ÊúÄÂ§ßÂåñÊ≠£Á¢∫Á®ãÂºèÁ¢ºÁöÑÂèØËÉΩÊÄß„ÄÇÈÄèÈÅéÊåÅÁ∫åÁöÑÂèçË¶ÜÊîπÈÄ≤ÔºåCodeLutra ËÉΩËÆìËºÉÂ∞èÁöÑ LLM Âú®ÂêÑÁ®ÆÁ®ãÂºèÁ¢ºÁîüÊàê‰ªªÂãô‰∏≠ÈÅîÂà∞ÊàñË∂ÖË∂ä GPT-4 ÁöÑÊïàËÉΩÔºåËÄåÁÑ°ÈúÄ‰æùË≥¥ÊñºÈæêÂ§ßÁöÑÂ§ñÈÉ®Ë≥áÊñôÈõÜÊàñËºÉÂ§ßÁöÑËºîÂä©Ê®°Âûã„ÄÇÂú®‰∏ÄÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑË≥áÊñôÂàÜÊûê‰ªªÂãô‰∏≠ÔºåÂÉÖ‰ΩøÁî® 500 ÂÄãÁØÑ‰æãÂ∞±Â∞á Llama-3-8B ÁöÑÊ∫ñÁ¢∫Â∫¶Âæû 28.2% ÊèêÂçáÂà∞ 48.6%ÔºåÊé•Ëøë GPT-4 ÁöÑÊïàËÉΩ„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫Ü CodeLutra Âú®Á∏ÆÂ∞èÈñãÊîæÂéüÂßãÁ¢ºÂíåÈñâÊ∫êÊ®°Âûã‰πãÈñìÂ∑ÆË∑ùÁöÑÊΩõÂäõÔºå‰ΩøÂÖ∂ÊàêÁÇ∫Á®ãÂºèÁ¢ºÁîüÊàêÈ†òÂüü‰∏≠‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇ

##### **Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method**
2411.05196v1 by Turker Berk Donmez

In democratic societies, electoral systems play a crucial role in translating
public preferences into political representation. Among these, the D'Hondt
method is widely used to ensure proportional representation, balancing fair
representation with governmental stability. Recently, there has been a growing
interest in applying similar principles of proportional representation to
enhance interpretability in machine learning, specifically in Explainable AI
(XAI). This study investigates the integration of D'Hondt-based voting
principles in the DhondtXAI method, which leverages resource allocation
concepts to interpret feature importance within AI models. Through a comparison
of SHAP (Shapley Additive Explanations) and DhondtXAI, we evaluate their
effectiveness in feature attribution within CatBoost and XGBoost models for
breast cancer and diabetes prediction, respectively. The DhondtXAI approach
allows for alliance formation and thresholding to enhance interpretability,
representing feature importance as seats in a parliamentary view. Statistical
correlation analyses between SHAP values and DhondtXAI allocations support the
consistency of interpretations, demonstrating DhondtXAI's potential as a
complementary tool for understanding feature importance in AI models. The
results highlight that integrating electoral principles, such as proportional
representation and alliances, into AI explainability can improve user
understanding, especially in high-stakes fields like healthcare.

ÊëòË¶ÅÔºöÂú®Ê∞ë‰∏ªÁ§æÊúÉ‰∏≠ÔºåÈÅ∏ËàâÂà∂Â∫¶Âú®Â∞áÂÖ¨ÁúæÂÅèÂ•ΩËΩâÂåñÁÇ∫ÊîøÊ≤ª‰ª£Ë°®ÊñπÈù¢ÁôºÊèÆËëóËá≥ÈóúÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇÂÖ∂‰∏≠ÔºåD'Hondt ÊñπÊ≥ïË¢´Âª£Ê≥õÁî®ÊñºÁ¢∫‰øùÊØî‰æã‰ª£Ë°®Âà∂ÔºåÂú®ÂÖ¨Âπ≥‰ª£Ë°®ËàáÊîøÂ∫úÁ©©ÂÆöÊÄß‰πãÈñìÂèñÂæóÂπ≥Ë°°„ÄÇÊúÄËøëÔºå‰∫∫ÂÄëË∂ä‰æÜË∂äÊúâËààË∂£Â∞áÈ°û‰ººÁöÑÊØî‰æã‰ª£Ë°®ÂéüÂâáÊáâÁî®ÊñºÂ¢ûÂº∑Ê©üÂô®Â≠∏Áøí‰∏≠ÁöÑÂèØËß£ÈáãÊÄßÔºåÁâπÂà•ÊòØÂú®ÂèØËß£Èáã AI (XAI) ‰∏≠„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂ∞áÂü∫Êñº D'Hondt ÁöÑÊäïÁ•®ÂéüÂâáÊï¥ÂêàÂà∞ DhondtXAI ÊñπÊ≥ï‰∏≠ÁöÑÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂà©Áî®Ë≥áÊ∫êÂàÜÈÖçÊ¶ÇÂøµ‰æÜËß£Èáã AI Ê®°Âûã‰∏≠ÁöÑÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÈÄöÈÅéÊØîËºÉ SHAPÔºàShapley Âä†ÊÄßËß£ÈáãÔºâÂíå DhondtXAIÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÂÆÉÂÄëÂú® CatBoost Âíå XGBoost Ê®°Âûã‰∏≠ÂàÜÂà•Â∞ç‰π≥ËÖ∫ÁôåÂíåÁ≥ñÂ∞øÁóÖÈ†êÊ∏¨ÈÄ≤Ë°åÁâπÂæµÊ≠∏Âõ†ÁöÑÊúâÊïàÊÄß„ÄÇDhondtXAI ÊñπÊ≥ïÂÖÅË®±ËÅØÁõüÂΩ¢ÊàêÂíåÈñæÂÄºÂåñ‰ª•Â¢ûÂº∑ÂèØËß£ÈáãÊÄßÔºåÂ∞áÁâπÂæµÈáçË¶ÅÊÄßË°®Á§∫ÁÇ∫Ë≠∞ÊúÉËßÄÈªû‰∏≠ÁöÑÂ∏≠‰Ωç„ÄÇSHAP ÂÄºÂíå DhondtXAI ÂàÜÈÖç‰πãÈñìÁöÑÁµ±Ë®àÁõ∏ÈóúÊÄßÂàÜÊûêÊîØÊåÅËß£ÈáãÁöÑ‰∏ÄËá¥ÊÄßÔºåË≠âÊòé‰∫Ü DhondtXAI ‰ΩúÁÇ∫ÁêÜËß£ AI Ê®°Âûã‰∏≠ÁâπÂæµÈáçË¶ÅÊÄßÁöÑË£úÂÖÖÂ∑•ÂÖ∑ÁöÑÊΩõÂäõ„ÄÇÁµêÊûúË°®ÊòéÔºåÂ∞áÈÅ∏ËàâÂéüÂâáÔºà‰æãÂ¶ÇÊØî‰æã‰ª£Ë°®Âà∂ÂíåËÅØÁõüÔºâÊï¥ÂêàÂà∞ AI ÂèØËß£ÈáãÊÄß‰∏≠ÂèØ‰ª•ÊèêÈ´òÁî®Êà∂ÁöÑÁêÜËß£ÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≠âÈ´òÈ¢®Èö™È†òÂüü„ÄÇ

##### **On Erroneous Agreements of CLIP Image Embeddings**
2411.05195v1 by Siting Li, Pang Wei Koh, Simon Shaolei Du

Recent research suggests that the failures of Vision-Language Models (VLMs)
at visual reasoning often stem from erroneous agreements -- when semantically
distinct images are ambiguously encoded by the CLIP image encoder into
embeddings with high cosine similarity. In this paper, we show that erroneous
agreements are not always the main culprit, as Multimodal Large Language Models
(MLLMs) can still extract distinct information from them. For instance, when
distinguishing objects on the left vs right in the What'sUp benchmark, the CLIP
image embeddings of the left/right pairs have an average cosine similarity
$>0.99$, and CLIP performs at random chance; but LLaVA-1.5-7B, which uses the
same CLIP image encoder, achieves nearly $100\%$ accuracy. We find that the
extractable information in CLIP image embeddings is likely obscured by CLIP's
inadequate vision-language alignment: Its matching score learned by the
contrastive objective might not capture all diverse image-text correspondences.
We also study the MMVP benchmark, on which prior work has shown that LLaVA-1.5
cannot distinguish image pairs with high cosine similarity. We observe a
performance gain brought by attending more to visual input through an
alternative decoding algorithm. Further, the accuracy significantly increases
if the model can take both images as input to emphasize their nuanced
differences. Both findings indicate that LLaVA-1.5 did not utilize extracted
visual information sufficiently. In conclusion, our findings suggest that while
improving image encoders could benefit VLMs, there is still room to enhance
models with a fixed image encoder by applying better strategies for extracting
and utilizing visual information.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåËßÜËßâËØ≠Ë®ÄÊ®°Âûã (VLM) Âú®ËßÜËßâÊé®ÁêÜ‰∏≠Â§±Ë¥•ÈÄöÂ∏∏Ê∫ê‰∫éÈîôËØØÁöÑÂçèËÆÆ‚Äî‚ÄîÂΩìËØ≠‰πâ‰∏ä‰∏çÂêåÁöÑÂõæÂÉèË¢´ CLIP ÂõæÂÉèÁºñÁ†ÅÂô®Ê®°Á≥äÂú∞ÁºñÁ†ÅÂà∞ÂÖ∑ÊúâÈ´ò‰ΩôÂº¶Áõ∏‰ººÊÄßÁöÑÂµåÂÖ•‰∏≠Êó∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Ë°®ÊòéÈîôËØØÁöÑÂçèËÆÆÂπ∂‰∏çÊÄªÊòØ‰∏ªË¶ÅÂéüÂõ†ÔºåÂõ†‰∏∫Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã (MLLM) ‰ªçÁÑ∂ÂèØ‰ª•‰ªé‰∏≠ÊèêÂèñ‰∏çÂêåÁöÑ‰ø°ÊÅØ„ÄÇ‰æãÂ¶ÇÔºåÂú® What'sUp Âü∫ÂáÜÊµãËØï‰∏≠Âå∫ÂàÜÂ∑¶Âè≥Áâ©‰ΩìÊó∂ÔºåÂ∑¶Âè≥ÂØπÁöÑ CLIP ÂõæÂÉèÂµåÂÖ•ÁöÑÂπ≥Âùá‰ΩôÂº¶Áõ∏‰ººÊÄß$>0.99$ÔºåËÄå CLIP ‰ª•ÈöèÊú∫Êú∫‰ºöÊâßË°åÔºõ‰ΩÜ‰ΩøÁî®Áõ∏Âêå CLIP ÂõæÂÉèÁºñÁ†ÅÂô®ÁöÑ LLaVA-1.5-7B ÂÆûÁé∞‰∫ÜÊé•Ëøë $100\%$ ÁöÑÂáÜÁ°ÆÁéá„ÄÇÊàë‰ª¨ÂèëÁé∞ CLIP ÂõæÂÉèÂµåÂÖ•‰∏≠ÂèØÊèêÂèñÁöÑ‰ø°ÊÅØÂæàÂèØËÉΩË¢´ CLIP ‰∏çÂÖÖÂàÜÁöÑËßÜËßâËØ≠Ë®ÄÂØπÈΩêÊâÄÊé©ÁõñÔºöÂÆÉÈÄöËøáÂØπÊØîÁõÆÊ†áÂ≠¶‰π†ÁöÑÂåπÈÖçÂàÜÊï∞ÂèØËÉΩÊó†Ê≥ïÊçïËé∑ÊâÄÊúâ‰∏çÂêåÁöÑÂõæÂÉèÊñáÊú¨ÂØπÂ∫îÂÖ≥Á≥ª„ÄÇÊàë‰ª¨ËøòÁ†îÁ©∂‰∫Ü MMVP Âü∫ÂáÜÔºå‰πãÂâçÁöÑÂ∑•‰ΩúË°®Êòé LLaVA-1.5 Êó†Ê≥ïÂå∫ÂàÜÂÖ∑ÊúâÈ´ò‰ΩôÂº¶Áõ∏‰ººÊÄßÁöÑÂõæÂÉèÂØπ„ÄÇÊàë‰ª¨ËßÇÂØüÂà∞ÈÄöËøáÊõø‰ª£Ëß£Á†ÅÁÆóÊ≥ïÊõ¥Â§öÂú∞ÂÖ≥Ê≥®ËßÜËßâËæìÂÖ•Â∏¶Êù•ÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÊ≠§Â§ñÔºåÂ¶ÇÊûúÊ®°ÂûãÂèØ‰ª•Â∞Ü‰∏§ÂπÖÂõæÂÉè‰Ωú‰∏∫ËæìÂÖ•‰ª•Âº∫Ë∞ÉÂÖ∂ÁªÜÂæÆÂ∑ÆÂà´ÔºåÂàôÂáÜÁ°ÆÊÄß‰ºöÊòæÁùÄÊèêÈ´ò„ÄÇËøô‰∏§È°πÂèëÁé∞ÈÉΩË°®Êòé LLaVA-1.5 Ê≤°ÊúâÂÖÖÂàÜÂà©Áî®ÊèêÂèñÁöÑËßÜËßâ‰ø°ÊÅØ„ÄÇÊÄª‰πãÔºåÊàë‰ª¨ÁöÑÂèëÁé∞Ë°®ÊòéÔºåËôΩÁÑ∂ÊîπËøõÂõæÂÉèÁºñÁ†ÅÂô®ÂèØ‰ª•‰Ωø VLM ÂèóÁõäÔºå‰ΩÜ‰ªçÊúâÁ©∫Èó¥ÈÄöËøáÂ∫îÁî®Êõ¥Â•ΩÁöÑÁ≠ñÁï•Êù•ÊèêÂèñÂíåÂà©Áî®ËßÜËßâ‰ø°ÊÅØÊù•Â¢ûÂº∫ÂÖ∑ÊúâÂõ∫ÂÆöÂõæÂÉèÁºñÁ†ÅÂô®ÁöÑÊ®°Âûã„ÄÇ

##### **Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**
2411.05194v1 by Joey Hong, Jessica Lin, Anca Dragan, Sergey Levine

Recent progress on large language models (LLMs) has enabled dialogue agents
to generate highly naturalistic and plausible text. However, current LLM
language generation focuses on responding accurately to questions and requests
with a single effective response. In reality, many real dialogues are
interactive, meaning an agent's utterances will influence their conversational
partner, elicit information, or change their opinion. Accounting for how an
agent can effectively steer a conversation is a crucial ability in many
dialogue tasks, from healthcare to preference elicitation. Existing methods for
fine-tuning dialogue agents to accomplish such tasks would rely on curating
some amount of expert data. However, doing so often requires understanding the
underlying cognitive processes of the conversational partner, which is a skill
neither humans nor LLMs trained on human data can reliably do. Our key insight
is that while LLMs may not be adept at identifying effective strategies for
steering conversations a priori, or in the middle of an ongoing conversation,
they can do so post-hoc, or in hindsight, after seeing how their conversational
partner responds. We use this fact to rewrite and augment existing suboptimal
data, and train via offline reinforcement learning (RL) an agent that
outperforms both prompting and learning from unaltered human demonstrations. We
apply our approach to two domains that require understanding human mental
state, intelligent interaction, and persuasion: mental health support, and
soliciting charitable donations. Our results in a user study with real humans
show that our approach greatly outperforms existing state-of-the-art dialogue
agents.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰ΩøÂ∞çË©±‰ª£ÁêÜËÉΩÂ§†ÁîüÊàêÈ´òÂ∫¶Ëá™ÁÑ∂‰∏îÂêàÁêÜÁöÑÊñáÂ≠ó„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑ LLM Ë™ûË®ÄÁîüÊàêËëóÈáçÊñº‰ª•ÂñÆ‰∏ÄÊúâÊïàÁöÑÂõûÊáâÊ∫ñÁ¢∫ÂõûÊáâÂïèÈ°åÂíåË¶ÅÊ±Ç„ÄÇÂú®ÁèæÂØ¶‰∏≠ÔºåË®±Â§öÁúüÂØ¶Â∞çË©±ÈÉΩÊòØ‰∫íÂãïÁöÑÔºåÈÄôË°®Á§∫‰ª£ÁêÜ‰∫∫ÁöÑÁôºË®ÄÊúÉÂΩ±Èüø‰ªñÂÄëÁöÑÂ∞çË©±Â§•‰º¥„ÄÅÂºïÂá∫Ë≥áË®äÊàñÊîπËÆä‰ªñÂÄëÁöÑÊÑèË¶ã„ÄÇËÄÉÈáè‰ª£ÁêÜ‰∫∫Â¶Ç‰ΩïÊúâÊïàÂºïÂ∞éÂ∞çË©±ÁöÑËÉΩÂäõÂú®Ë®±Â§öÂ∞çË©±‰ªªÂãô‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂæûÈÜ´ÁôÇ‰øùÂÅ•Âà∞ÂÅèÂ•ΩÂºïÂ∞éÁöÜÊòØÂ¶ÇÊ≠§„ÄÇÁèæÊúâÁöÑÂæÆË™øÂ∞çË©±‰ª£ÁêÜÊñπÊ≥ï‰ª•ÂÆåÊàêÊ≠§È°û‰ªªÂãôÊúÉ‰æùË≥¥ÊñºÁ≠ñÂäÉ‰∏ÄÂÆöÈáèÁöÑÂ∞àÂÆ∂Ë≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÈÄôÈ∫ºÂÅöÈÄöÂ∏∏ÈúÄË¶Å‰∫ÜËß£Â∞çË©±Â§•‰º¥ÁöÑÂü∫Á§éË™çÁü•Ê≠∑Á®ãÔºåËÄåÈÄôÈ†ÖÊäÄËÉΩÊó¢‰∏çÊòØ‰∫∫È°û‰πü‰∏çÊòØË®ìÁ∑¥ÈÅé‰∫∫È°ûË≥áÊñôÁöÑ LLM ÂèØÈù†ÂÖ∑ÂÇôÁöÑ„ÄÇÊàëÂÄëÁöÑÈóúÈçµË¶ãËß£Âú®ÊñºÔºåÂÑòÁÆ° LLM ÂèØËÉΩ‰∏çÊìÖÈï∑Êñº‰∫ãÂÖàÊàñÂú®Â∞çË©±ÈÄ≤Ë°å‰∏≠Ë≠òÂà•Âá∫ÂºïÂ∞éÂ∞çË©±ÁöÑÊúâÊïàÁ≠ñÁï•Ôºå‰ΩÜ‰ªñÂÄëÂèØ‰ª•Âú®‰∫ãÂæåÊàñÂõûÈ°ßÊôÇÔºåÂú®ÁúãÂà∞‰ªñÂÄëÁöÑÂ∞çË©±Â§•‰º¥Â¶Ç‰ΩïÂõûÊáâÂæåÈÄôÈ∫ºÂÅö„ÄÇÊàëÂÄëÂà©Áî®ÈÄôÂÄã‰∫ãÂØ¶‰æÜÊîπÂØ´‰∏¶Êì¥ÂÖÖÁèæÊúâÁöÑÊ¨°‰Ω≥Ë≥áÊñôÔºå‰∏¶ÈÄèÈÅéÈõ¢Á∑öÂº∑ÂåñÂ≠∏Áøí (RL) Ë®ìÁ∑¥‰∏ÄÂêç‰ª£ÁêÜ‰∫∫ÔºåÂÖ∂Ë°®ÁèæÂÑ™ÊñºÊèêÁ§∫ÂíåÂæûÊú™Á∂ì‰øÆÊîπÁöÑ‰∫∫È°ûÁ§∫ÁØÑ‰∏≠Â≠∏Áøí„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÂÅöÊ≥ïÊáâÁî®ÊñºÈúÄË¶Å‰∫ÜËß£‰∫∫È°ûÂøÉÁêÜÁãÄÊÖã„ÄÅÊô∫ÊÖß‰∫íÂãïÂíåË™™ÊúçÁöÑÂÖ©ÂÄãÈ†òÂüüÔºöÂøÉÁêÜÂÅ•Â∫∑ÊîØÊåÅÂíåÂãüÈõÜÊÖàÂñÑÊçêÊ¨æ„ÄÇÊàëÂÄëÂú®ËàáÁúüÂØ¶‰∫∫È°ûÈÄ≤Ë°åÁöÑ‰ΩøÁî®ËÄÖÁ†îÁ©∂‰∏≠ÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ§ßÂπÖÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤Â∞çË©±‰ª£ÁêÜ„ÄÇ

##### **Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning**
2411.05193v1 by Joey Hong, Anca Dragan, Sergey Levine

Value-based reinforcement learning (RL) can in principle learn effective
policies for a wide range of multi-turn problems, from games to dialogue to
robotic control, including via offline RL from static previously collected
datasets. However, despite the widespread use of policy gradient methods to
train large language models for single turn tasks (e.g., question answering),
value-based methods for multi-turn RL in an off-policy or offline setting have
proven particularly challenging to scale to the setting of large language
models. This setting requires effectively leveraging pretraining, scaling to
large architectures with billions of parameters, and training on large
datasets, all of which represent major challenges for current value-based RL
methods. In this work, we propose a novel offline RL algorithm that addresses
these drawbacks, casting Q-learning as a modified supervised fine-tuning (SFT)
problem where the probabilities of tokens directly translate to Q-values. In
this way we obtain an algorithm that smoothly transitions from maximizing the
likelihood of the data during pretraining to learning a near-optimal Q-function
during finetuning. Our algorithm has strong theoretical foundations, enjoying
performance bounds similar to state-of-the-art Q-learning methods, while in
practice utilizing an objective that closely resembles SFT. Because of this,
our approach can enjoy the full benefits of the pretraining of language models,
without the need to reinitialize any weights before RL finetuning, and without
the need to initialize new heads for predicting values or advantages.
Empirically, we evaluate our method on both pretrained LLMs and VLMs, on a
variety of tasks including both natural language dialogue and robotic
manipulation and navigation from images.

ÊëòË¶ÅÔºöÂü∫ÊñºÂÉπÂÄºÁöÑÂº∑ÂåñÂ≠∏Áøí (RL) ÁêÜË´ñ‰∏äÂèØ‰ª•Â≠∏ÁøíÂêÑÁ®ÆÂ§öËº™ÂïèÈ°åÁöÑÊúâÊïàÊîøÁ≠ñÔºåÂæûÈÅäÊà≤Âà∞Â∞çË©±ÂÜçÂà∞Ê©üÂô®‰∫∫ÊéßÂà∂ÔºåÂåÖÊã¨ÂæûÈùúÊÖãÂÖàÂâçÊî∂ÈõÜÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åÈõ¢Á∑ö RL„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°Âª£Ê≥õ‰ΩøÁî®Á≠ñÁï•Ê¢ØÂ∫¶ÊñπÊ≥ï‰æÜË®ìÁ∑¥ÂñÆËº™‰ªªÂãôÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºà‰æãÂ¶ÇÔºåÂïèÈ°åËß£Á≠îÔºâÔºå‰ΩÜÂ§öËº™ RL Âú®ÈùûÁ≠ñÁï•ÊàñÈõ¢Á∑öË®≠ÂÆö‰∏≠ÁöÑÂü∫ÊñºÂÉπÂÄºÁöÑÊñπÊ≥ïÂ∑≤Ë¢´Ë≠âÊòéÁâπÂà•Èõ£‰ª•Êì¥Â±ïÂà∞Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑË®≠ÂÆö„ÄÇÊ≠§Ë®≠ÂÆöÈúÄË¶ÅÊúâÊïàÂú∞Âà©Áî®È†êË®ìÁ∑¥ÔºåÊì¥Â±ïÂà∞ÂÖ∑ÊúâÊï∏ÂçÅÂÑÑÂÄãÂèÉÊï∏ÁöÑÂ§ßÂûãÊû∂ÊßãÔºå‰∏¶Âú®Â§ßÂûãË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÔºåÊâÄÊúâÈÄô‰∫õÈÉΩÂ∞çÁï∂ÂâçÁöÑÂü∫ÊñºÂÉπÂÄºÁöÑ RL ÊñπÊ≥ïÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈõ¢Á∑ö RL ÊºîÁÆóÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÁº∫ÈªûÔºåÂ∞á Q Â≠∏ÁøíËΩâÊèõÁÇ∫‰øÆÊîπÈÅéÁöÑÁõ£Áù£ÂæÆË™ø (SFT) ÂïèÈ°åÔºåÂÖ∂‰∏≠Á¨¶ËôüÁöÑÊ©üÁéáÁõ¥Êé•ËΩâÊèõÁÇ∫ Q ÂÄº„ÄÇÈÄôÊ®£ÔºåÊàëÂÄëÁç≤Âæó‰∫Ü‰∏ÄÁ®ÆÊºîÁÆóÊ≥ïÔºåË©≤ÊºîÁÆóÊ≥ïÂèØ‰ª•Âú®È†êË®ìÁ∑¥ÊúüÈñìÊúÄÂ§ßÂåñË≥áÊñôÁöÑÂèØËÉΩÊÄßËàáÂæÆË™øÊúüÈñìÂ≠∏ÁøíËøë‰πéÊúÄ‰Ω≥ÁöÑ Q ÂáΩÊï∏‰πãÈñìÈ†ÜÂà©ËΩâÊèõ„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂÖ∑ÊúâÂº∑Â§ßÁöÑÁêÜË´ñÂü∫Á§éÔºå‰∫´ÊúâËàáÊúÄÂÖàÈÄ≤ÁöÑ Q Â≠∏ÁøíÊñπÊ≥ïÈ°û‰ººÁöÑÊïàËÉΩÁïåÈôêÔºåÂêåÊôÇÂú®ÂØ¶Âãô‰∏ä‰ΩøÁî®Ëàá SFT ÈùûÂ∏∏Áõ∏‰ººÁöÑÁõÆÊ®ô„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÂÖÖÂàÜ‰∫´ÂèóË™ûË®ÄÊ®°ÂûãÈ†êË®ìÁ∑¥ÁöÑÂÖ®ÈÉ®Â•ΩËôïÔºåËÄåÁÑ°ÈúÄÂú® RL ÂæÆË™ø‰πãÂâçÈáçÊñ∞ÂàùÂßãÂåñ‰ªª‰ΩïÊ¨äÈáçÔºå‰πüÁÑ°ÈúÄÂàùÂßãÂåñÊñ∞ÁöÑÈ†≠ÈÉ®‰æÜÈ†êÊ∏¨ÂÄºÊàñÂÑ™Âã¢„ÄÇÊ†πÊìöÁ∂ìÈ©óÔºåÊàëÂÄëÂú®È†êË®ìÁ∑¥ÁöÑ LLM Âíå VLM ‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºåÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏äÔºåÂåÖÊã¨Ëá™ÁÑ∂Ë™ûË®ÄÂ∞çË©±ÂíåÊ©üÂô®‰∫∫ÂæûÂΩ±ÂÉèÈÄ≤Ë°åÊìç‰ΩúÂíåÂ∞éËà™„ÄÇ

##### **Explaining Mixtures of Sources in News Articles**
2411.05192v1 by Alexander Spangher, James Youn, Matt DeButts, Nanyun Peng, Emilio Ferrara, Jonathan May

Human writers plan, then write. For large language models (LLMs) to play a
role in longer-form article generation, we must understand the planning steps
humans make before writing. We explore one kind of planning, source-selection
in news, as a case-study for evaluating plans in long-form generation. We ask:
why do specific stories call for specific kinds of sources? We imagine a
generative process for story writing where a source-selection schema is first
selected by a journalist, and then sources are chosen based on categories in
that schema. Learning the article's plan means predicting the schema initially
chosen by the journalist. Working with professional journalists, we adapt five
existing schemata and introduce three new ones to describe journalistic plans
for the inclusion of sources in documents. Then, inspired by Bayesian
latent-variable modeling, we develop metrics to select the most likely plan, or
schema, underlying a story, which we use to compare schemata. We find that two
schemata: stance and social affiliation best explain source plans in most
documents. However, other schemata like textual entailment explain source plans
in factually rich topics like "Science". Finally, we find we can predict the
most suitable schema given just the article's headline with reasonable
accuracy. We see this as an important case-study for human planning, and
provides a framework and approach for evaluating other kinds of plans. We
release a corpora, NewsSources, with annotations for 4M articles.

ÊëòË¶ÅÔºö‰∫∫È°û‰ΩúÂÆ∂ÊúÉÂÖàË¶èÂäÉÔºåÂÜçÂØ´‰Ωú„ÄÇÂ∞çÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Èï∑ÁØáÊñáÁ´†ÁîüÊàê‰∏≠ÊâÆÊºîËßíËâ≤ÔºåÊàëÂÄëÂøÖÈ†à‰∫ÜËß£‰∫∫È°ûÂú®ÂØ´‰ΩúÂâçÈÄ≤Ë°åÁöÑË¶èÂäÉÊ≠•È©ü„ÄÇÊàëÂÄëÊé¢Ë®é‰∏ÄÁ®ÆË¶èÂäÉÔºåÂç≥Êñ∞ËÅû‰∏≠ÁöÑ‰æÜÊ∫êÈÅ∏ÊìáÔºå‰ΩúÁÇ∫Ë©ï‰º∞Èï∑ÁØáÁîüÊàê‰∏≠Ë®àÁï´ÁöÑÊ°à‰æãÁ†îÁ©∂„ÄÇÊàëÂÄëÂïèÔºöÁÇ∫‰ªÄÈ∫ºÁâπÂÆöÊïÖ‰∫ãÈúÄË¶ÅÁâπÂÆöÈ°ûÂûãÁöÑ‰æÜÊ∫êÔºüÊàëÂÄëÊÉ≥ÂÉè‰∏ÄÂÄãÊïÖ‰∫ãÂØ´‰ΩúÁöÑÁîüÊàêÈÅéÁ®ãÔºåÂÖ∂‰∏≠Ë®òËÄÖÈ¶ñÂÖàÈÅ∏Êìá‰æÜÊ∫êÈÅ∏ÊìáÊû∂ÊßãÔºåÁÑ∂ÂæåÊ†πÊìöË©≤Êû∂Êßã‰∏≠ÁöÑÈ°ûÂà•ÈÅ∏Êìá‰æÜÊ∫ê„ÄÇÂ≠∏ÁøíÊñáÁ´†ÁöÑË®àÁï´ÊÑèÂë≥ËëóÈ†êÊ∏¨Ë®òËÄÖÊúÄÂàùÈÅ∏ÊìáÁöÑÊû∂Êßã„ÄÇÊàëÂÄëËàáÂ∞àÊ•≠Ë®òËÄÖÂêà‰ΩúÔºåË™øÊï¥‰∫îÂÄãÁèæÊúâÊû∂Êßã‰∏¶ÂºïÂÖ•‰∏âÂÄãÊñ∞Êû∂Êßã‰æÜÊèèËø∞Êñ∞ËÅûÂ∑•‰ΩúËÄÖÂú®Êñá‰ª∂‰∏≠ÁöÑ‰æÜÊ∫êÁ¥çÂÖ•Ë®àÁï´„ÄÇÁÑ∂ÂæåÔºåÂú®Ë≤ùÊ∞èÊΩõËÆäÊï∏Âª∫Ê®°ÁöÑÂïüÁôº‰∏ãÔºåÊàëÂÄëÈñãÁôºÊåáÊ®ô‰æÜÈÅ∏ÊìáÊúÄÂèØËÉΩÁöÑË®àÁï´ÔºåÊàñÊû∂ÊßãÔºå‰ΩúÁÇ∫ÊïÖ‰∫ãÁöÑÂü∫Á§éÔºåÊàëÂÄëÁî®‰æÜÊØîËºÉÊû∂Êßã„ÄÇÊàëÂÄëÁôºÁèæÂÖ©ÂÄãÊû∂ÊßãÔºöÁ´ãÂ†¥ÂíåÁ§æÊúÉÈóú‰øÇÊúÄËÉΩË™™ÊòéÂ§ßÂ§öÊï∏Êñá‰ª∂‰∏≠‰æÜÊ∫êÁöÑË®àÁï´„ÄÇÁÑ∂ËÄåÔºåÂÖ∂‰ªñÊû∂ÊßãÔºå‰æãÂ¶ÇÊñáÊú¨ËòäÊ∂µÔºåÂèØ‰ª•Ëß£Èáã‰∫ãÂØ¶Ë±êÂØåÁöÑ‰∏ªÈ°åÔºà‰æãÂ¶Ç„ÄåÁßëÂ≠∏„ÄçÔºâ‰∏≠ÁöÑ‰æÜÊ∫êË®àÁï´„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁôºÁèæÊàëÂÄëÂèØ‰ª•ÂÉÖÈÄöÈÅéÊñáÁ´†Ê®ôÈ°åÈ†êÊ∏¨ÊúÄÂêàÈÅ©ÁöÑÊû∂ÊßãÔºåÊ∫ñÁ¢∫ÊÄßÂêàÁêÜ„ÄÇÊàëÂÄëÂ∞áÊ≠§Ë¶ñÁÇ∫‰∫∫È°ûË¶èÂäÉÁöÑÈáçË¶ÅÊ°à‰æãÁ†îÁ©∂Ôºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄãÁî®ÊñºË©ï‰º∞ÂÖ∂‰ªñÈ°ûÂûãÁöÑË®àÁï´ÁöÑÊ°ÜÊû∂ÂíåÊñπÊ≥ï„ÄÇÊàëÂÄëÁôºÂ∏É‰∫Ü‰∏ÄÂÄãË™ûÊñôÂ∫´ NewsSourcesÔºåÂÖ∂‰∏≠ÂåÖÂê´Â∞ç 400 Ëê¨ÁØáÊñáÁ´†ÁöÑË®ªÈáã„ÄÇ

##### **Discern-XR: An Online Classifier for Metaverse Network Traffic**
2411.05184v1 by Yoga Suhas Kuruba Manjunath, Austin Wissborn, Mathew Szymanowski, Mushu Li, Lian Zhao, Xiao-Ping Zhang

In this paper, we design an exclusive Metaverse network traffic classifier,
named Discern-XR, to help Internet service providers (ISP) and router
manufacturers enhance the quality of Metaverse services. Leveraging segmented
learning, the Frame Vector Representation (FVR) algorithm and Frame
Identification Algorithm (FIA) are proposed to extract critical frame-related
statistics from raw network data having only four application-level features. A
novel Augmentation, Aggregation, and Retention Online Training (A2R-OT)
algorithm is proposed to find an accurate classification model through online
training methodology. In addition, we contribute to the real-world Metaverse
dataset comprising virtual reality (VR) games, VR video, VR chat, augmented
reality (AR), and mixed reality (MR) traffic, providing a comprehensive
benchmark. Discern-XR outperforms state-of-the-art classifiers by 7% while
improving training efficiency and reducing false-negative rates. Our work
advances Metaverse network traffic classification by standing as the
state-of-the-art solution.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁç®ÂÆ∂ÁöÑÂÖÉÂÆáÂÆôÁ∂≤Ë∑ØÊµÅÈáèÂàÜÈ°ûÂô®Ôºå
ÂêçÁÇ∫ Discern-XRÔºå‰ª•Âπ´Âä©Á∂≤Ë∑ØÊúçÂãô‰æõÊáâÂïÜ (ISP) ÂíåË∑ØÁî±Âô®
Ë£ΩÈÄ†ÂïÜÊèêÂçáÂÖÉÂÆáÂÆôÊúçÂãôÁöÑÂìÅË≥™„ÄÇÂà©Áî®ÂàÜÊÆµÂ≠∏ÁøíÔºåÊèêÂá∫ÂπÄÂêëÈáèË°®Á§∫ (FVR) ÊºîÁÆóÊ≥ïÂíåÂπÄ
Ë≠òÂà•ÊºîÁÆóÊ≥ï (FIA) ÂæûÂè™ÊúâÂõõÂÄãÊáâÁî®Â±§ÂäüËÉΩÁöÑÂéüÂßãÁ∂≤Ë∑ØË≥áÊñô‰∏≠ËêÉÂèñÈóúÈçµÁöÑÂπÄÁõ∏Èóú
Áµ±Ë®àË≥áÊñô„ÄÇÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊì¥ÂÖÖ„ÄÅÂΩôÁ∏ΩÂíå‰øùÁïôÁ∑ö‰∏äË®ìÁ∑¥ (A2R-OT)
ÊºîÁÆóÊ≥ïÔºåÈÄèÈÅéÁ∑ö‰∏äË®ìÁ∑¥ÊñπÊ≥ïÊâæÂà∞‰∏ÄÂÄãÁ≤æÊ∫ñÁöÑÂàÜÈ°ûÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≤¢Áçª‰∏ÄÂÄãÂåÖÂê´ËôõÊì¨ÂØ¶Â¢É (VR) ÈÅäÊà≤„ÄÅVR ÂΩ±Áâá„ÄÅVR ËÅäÂ§©„ÄÅÊì¥Â¢ûÂØ¶Â¢É (AR) ÂíåÊ∑∑ÂêàÂØ¶Â¢É (MR) ÊµÅÈáèÁöÑÁúüÂØ¶‰∏ñÁïåÂÖÉÂÆáÂÆôË≥áÊñôÈõÜÔºåÊèê‰æõ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑ
Âü∫Ê∫ñ„ÄÇDiscern-XR Âú®ÊèêÂçáË®ìÁ∑¥ÊïàÁéáÂíåÈôç‰ΩéÂÅΩÈô∞ÊÄßÁéáÁöÑÂêåÊôÇÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂàÜÈ°ûÂô® 7%„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéÊàêÁÇ∫
ÊúÄÂÖàÈÄ≤ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÊé®ÂãïÂÖÉÂÆáÂÆôÁ∂≤Ë∑ØÊµÅÈáèÂàÜÈ°û„ÄÇ

##### **Inverse Transition Learning: Learning Dynamics from Demonstrations**
2411.05174v1 by Leo Benac, Abhishek Sharma, Sonali Parbhoo, Finale Doshi-Velez

We consider the problem of estimating the transition dynamics $T^*$ from
near-optimal expert trajectories in the context of offline model-based
reinforcement learning. We develop a novel constraint-based method, Inverse
Transition Learning, that treats the limited coverage of the expert
trajectories as a \emph{feature}: we use the fact that the expert is
near-optimal to inform our estimate of $T^*$. We integrate our constraints into
a Bayesian approach. Across both synthetic environments and real healthcare
scenarios like Intensive Care Unit (ICU) patient management in hypotension, we
demonstrate not only significant improvements in decision-making, but that our
posterior can inform when transfer will be successful.

ÊëòË¶ÅÔºöÊàëÂÄëËÄÉÊÖÆÂú®Èõ¢Á∑öÊ®°ÂûãÂü∫Á§éÂº∑ÂåñÂ≠∏ÁøíÁöÑËÑàÁµ°‰∏≠ÔºåÂæûÊé•ËøëÊúÄ‰Ω≥ÁöÑÂ∞àÂÆ∂ËªåË∑°‰º∞Ë®àËΩâÊèõÂãïÊÖã $T^*$ ÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÈñãÁôº‰∏ÄÁ®ÆÊñ∞ÁöÑÂü∫ÊñºÁ¥ÑÊùüÁöÑÊñπÊ≥ïÔºåÈÄÜËΩâÊèõÂ≠∏ÁøíÔºåÂÆÉÂ∞áÂ∞àÂÆ∂ËªåË∑°ÁöÑÊúâÈôêË¶ÜËìãÁØÑÂúçË¶ñÁÇ∫‰∏ÄÁ®Æ„ÄåÁâπÂæµ„ÄçÔºöÊàëÂÄëÂà©Áî®Â∞àÂÆ∂Êé•ËøëÊúÄ‰Ω≥ÁöÑ‰∫ãÂØ¶‰æÜÂëäÁü•ÊàëÂÄëÂ∞ç $T^*$ ÁöÑ‰º∞Ë®à„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁ¥ÑÊùüÊï¥ÂêàÂà∞Ë≤ùÊ∞èÊñπÊ≥ï‰∏≠„ÄÇÂú®Á∂úÂêàÁí∞Â¢ÉÂíåÂØ¶ÈöõÈÜ´ÁôÇ‰øùÂÅ•Â†¥ÊôØÔºà‰æãÂ¶Ç‰ΩéË°ÄÂ£ìÈáçÁóáÁõ£Ë≠∑ÁóÖÊàø (ICU) ÁóÖÊÇ£ÁÆ°ÁêÜÔºâ‰∏≠ÔºåÊàëÂÄë‰∏çÂÉÖÂ±ïÁ§∫‰∫ÜÊ±∫Á≠ñÂà∂ÂÆöÊñπÈù¢ÁöÑÈ°ØËëóÈÄ≤Ê≠•ÔºåËÄå‰∏îÊàëÂÄëÁöÑÂæåÈ©óÂèØ‰ª•ÂëäÁü•ËΩâÁßª‰ΩïÊôÇÊúÉÊàêÂäü„ÄÇ

##### **ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Language**
2411.05172v1 by Yuxin Wang, Xiaomeng Zhu, Weimin Lyu, Saeed Hassanpour, Soroush Vosoughi

Handling implicit language is essential for natural language processing
systems to achieve precise text understanding and facilitate natural
interactions with users. Despite its importance, the absence of a robust metric
for accurately measuring the implicitness of language significantly constrains
the depth of analysis possible in evaluating models' comprehension
capabilities. This paper addresses this gap by developing a scalar metric that
quantifies the implicitness level of language without relying on external
references. Drawing on principles from traditional linguistics, we define
''implicitness'' as the divergence between semantic meaning and pragmatic
interpretation. To operationalize this definition, we introduce ImpScore, a
novel, reference-free metric formulated through an interpretable regression
model. This model is trained using pairwise contrastive learning on a specially
curated dataset comprising $112,580$ (implicit sentence, explicit sentence)
pairs. We validate ImpScore through a user study that compares its assessments
with human evaluations on out-of-distribution data, demonstrating its accuracy
and strong correlation with human judgments. Additionally, we apply ImpScore to
hate speech detection datasets, illustrating its utility and highlighting
significant limitations in current large language models' ability to understand
highly implicit content. The metric model and its training data are available
at https://github.com/audreycs/ImpScore.

ÊëòË¶ÅÔºöËôïÁêÜÈö±Âê´Ë™ûË®ÄÂ∞çÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶ÅÔºå‰ª•ÈÅîÊàêÁ≤æÁ¢∫ÁöÑÊñáÂ≠óÁêÜËß£‰∏¶‰øÉÈÄ≤Ëàá‰ΩøÁî®ËÄÖÁöÑËá™ÁÑ∂‰∫íÂãï„ÄÇÂÑòÁÆ°ÂÖ∂ÈáçË¶ÅÊÄßÔºå‰ΩÜÁº∫‰πèÁî®ÊñºÁ≤æÁ¢∫Ë°°ÈáèË™ûË®ÄÈö±Âê´ÊÄßÁöÑÂº∑ÂÅ•ÊåáÊ®ôÔºåÈ°ØËëóÂú∞ÈôêÂà∂‰∫ÜÂú®Ë©ï‰º∞Ê®°ÂûãÁêÜËß£ËÉΩÂäõÊôÇÂèØËÉΩÈÄ≤Ë°åÁöÑÂàÜÊûêÊ∑±Â∫¶„ÄÇÊú¨ÊñáÈÄèÈÅéÈñãÁôº‰∏ÄÂÄãÊ®ôÈáèÊåáÊ®ô‰æÜËß£Ê±∫Ê≠§Â∑ÆË∑ùÔºåË©≤ÊåáÊ®ôÈáèÂåñË™ûË®ÄÁöÑÈö±Âê´ÊÄßÂ±§Á¥öÔºåËÄå‰∏ç‰æùË≥¥Â§ñÈÉ®ÂèÉËÄÉ„ÄÇÊ†πÊìöÂÇ≥Áµ±Ë™ûË®ÄÂ≠∏ÁöÑÂéüÂâáÔºåÊàëÂÄëÂ∞á„ÄåÈö±Âê´ÊÄß„ÄçÂÆöÁæ©ÁÇ∫Ë™ûÁæ©ÊÑèÁæ©ËàáË™ûÁî®Ëß£Èáã‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÁÇ∫‰∫ÜÂ∞áÊ≠§ÂÆöÁæ©‰ªòË´∏ÂØ¶Ë°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ImpScoreÔºå‰∏ÄÁ®ÆÈÄèÈÅéÂèØËß£ÈáãËø¥Ê≠∏Ê®°ÂûãÂà∂ÂÆöÂá∫ÁöÑÊñ∞Á©é„ÄÅÁÑ°ÂèÉËÄÉÊåáÊ®ô„ÄÇÊ≠§Ê®°Âûã‰ΩøÁî®ÊàêÂ∞çÂ∞çÊØîÂ≠∏ÁøíÂú®‰∏ÄÂÄãÁâπÂà•Á≠ñÂäÉÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÔºåË©≤Ë≥áÊñôÈõÜÂåÖÂê´ $112,580$ ÂÄãÔºàÈö±Âê´Âè•Â≠ê„ÄÅÊòéÁ¢∫Âè•Â≠êÔºâÂ∞ç„ÄÇÊàëÂÄëÈÄèÈÅé‰∏ÄÈ†Ö‰ΩøÁî®ËÄÖÁ†îÁ©∂È©óË≠â ImpScoreÔºåË©≤Á†îÁ©∂ÊØîËºÉ‰∫ÜÂÖ∂Ë©ï‰º∞Ëàá‰∫∫È°ûÂ∞çÈùûÂàÜ‰ΩàË≥áÊñôÁöÑË©ï‰º∞ÔºåË≠âÊòé‰∫ÜÂÖ∂Ê∫ñÁ¢∫ÊÄßËàáËàá‰∫∫È°ûÂà§Êñ∑ÁöÑÈ´òÂ∫¶Áõ∏ÈóúÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞á ImpScore ÊáâÁî®Êñº‰ªáÊÅ®Ë®ÄË´ñÂÅµÊ∏¨Ë≥áÊñôÈõÜÔºåË™™ÊòéÂÖ∂ÊïàÁî®‰∏¶Âº∑Ë™øÁï∂ÂâçÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÁêÜËß£È´òÂ∫¶Èö±Âê´ÂÖßÂÆπÊñπÈù¢ÁöÑÈ°ØËëóÈôêÂà∂„ÄÇÊåáÊ®ôÊ®°ÂûãÂèäÂÖ∂Ë®ìÁ∑¥Ë≥áÊñôÂèØÂú® https://github.com/audreycs/ImpScore ÂèñÂæó„ÄÇ

##### **Watermarking Language Models through Language Models**
2411.05091v1 by Xin Zhong, Agnibh Dasgupta, Abdullah Tanvir

This paper presents a novel framework for watermarking language models
through prompts generated by language models. The proposed approach utilizes a
multi-model setup, incorporating a Prompting language model to generate
watermarking instructions, a Marking language model to embed watermarks within
generated content, and a Detecting language model to verify the presence of
these watermarks. Experiments are conducted using ChatGPT and Mistral as the
Prompting and Marking language models, with detection accuracy evaluated using
a pretrained classifier model. Results demonstrate that the proposed framework
achieves high classification accuracy across various configurations, with 95%
accuracy for ChatGPT, 88.79% for Mistral. These findings validate the and
adaptability of the proposed watermarking strategy across different language
model architectures. Hence the proposed framework holds promise for
applications in content attribution, copyright protection, and model
authentication.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ°ÜÊû∂ÔºåÁî®Ë™ûË®ÄÊ®°ÂûãÁî¢ÁîüÁöÑÊèêÁ§∫Ôºå‰æÜË£Ω‰ΩúË™ûË®ÄÊ®°ÂûãÊµÆÊ∞¥Âç∞„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂà©Áî®Â§öÊ®°ÂûãË®≠ÁΩÆÔºåÂåÖÂê´‰∏ÄÂÄãÊèêÁ§∫Ë™ûË®ÄÊ®°Âûã‰æÜÁî¢ÁîüÊµÆÊ∞¥Âç∞Êåá‰ª§Ôºå‰∏ÄÂÄãÊ®ôË®òË™ûË®ÄÊ®°Âûã‰æÜÂ∞áÊµÆÊ∞¥Âç∞ÂµåÂÖ•Âà∞Áî¢ÁîüÁöÑÂÖßÂÆπ‰∏≠Ôºå‰ª•Âèä‰∏ÄÂÄãÂÅµÊ∏¨Ë™ûË®ÄÊ®°Âûã‰æÜÈ©óË≠âÈÄô‰∫õÊµÆÊ∞¥Âç∞ÁöÑÂ≠òÂú®„ÄÇÂØ¶È©ó‰ΩøÁî® ChatGPT Âíå Mistral ‰ΩúÁÇ∫ÊèêÁ§∫ÂíåÊ®ôË®òË™ûË®ÄÊ®°ÂûãÔºå‰∏¶‰ΩøÁî®È†êË®ìÁ∑¥ÂàÜÈ°ûÂô®Ê®°ÂûãË©ï‰º∞ÂÅµÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Âú®ÂêÑÁ®ÆÈÖçÁΩÆ‰∏≠ÈÉΩÈÅîÂà∞‰∫ÜÂæàÈ´òÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÔºåChatGPT ÁöÑÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 95%ÔºåMistral ÁöÑÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 88.79%„ÄÇÈÄô‰∫õÁôºÁèæÈ©óË≠â‰∫ÜÊâÄÊèêÂá∫ÁöÑÊµÆÊ∞¥Âç∞Á≠ñÁï•Âú®‰∏çÂêåË™ûË®ÄÊ®°ÂûãÊû∂Êßã‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÂõ†Ê≠§ÔºåÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Âú®ÂÖßÂÆπÊ≠∏Â±¨„ÄÅÁâàÊ¨ä‰øùË≠∑ÂíåÊ®°ÂûãÈ©óË≠âÁ≠âÊáâÁî®‰∏≠ÂÖ∑ÊúâÂª£ÈóäÁöÑÂâçÊôØ„ÄÇ

##### **Findings of the IWSLT 2024 Evaluation Campaign**
2411.05088v1 by Ibrahim Said Ahmad, Antonios Anastasopoulos, Ond≈ôej Bojar, Claudia Borg, Marine Carpuat, Roldano Cattoni, Mauro Cettolo, William Chen, Qianqian Dong, Marcello Federico, Barry Haddow, D√°vid Javorsk√Ω, Mateusz Krubi≈Ñski, Tsz Kin Lam, Xutai Ma, Prashant Mathur, Evgeny Matusov, Chandresh Maurya, John McCrae, Kenton Murray, Satoshi Nakamura, Matteo Negri, Jan Niehues, Xing Niu, Atul Kr. Ojha, John Ortega, Sara Papi, Peter Pol√°k, Adam Posp√≠≈°il, Pavel Pecina, Elizabeth Salesky, Nivedita Sethiya, Balaram Sarkar, Jiatong Shi, Claytone Sikasote, Matthias Sperber, Sebastian St√ºker, Katsuhito Sudoh, Brian Thompson, Marco Turchi, Alex Waibel, Shinji Watanabe, Patrick Wilken, Petr Zem√°nek, Rodolfo Zevallos

This paper reports on the shared tasks organized by the 21st IWSLT
Conference. The shared tasks address 7 scientific challenges in spoken language
translation: simultaneous and offline translation, automatic subtitling and
dubbing, speech-to-speech translation, dialect and low-resource speech
translation, and Indic languages. The shared tasks attracted 18 teams whose
submissions are documented in 26 system papers. The growing interest towards
spoken language translation is also witnessed by the constantly increasing
number of shared task organizers and contributors to the overview paper, almost
evenly distributed across industry and academia.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÂ†±ÂëäÁî±Á¨¨ 21 Â±Ü IWSLT ÊúÉË≠∞ÁµÑÁπîÁöÑÂÖ±‰∫´‰ªªÂãô„ÄÇÂÖ±‰∫´‰ªªÂãôÈáùÂ∞çÂè£Ë™ûÁøªË≠ØÊèêÂá∫‰∫Ü 7 ÂÄãÁßëÂ≠∏ÊåëÊà∞ÔºöÂêåÊ≠•ÂíåÈõ¢Á∑öÁøªË≠Ø„ÄÅËá™ÂãïÂ≠óÂπïÂíåÈÖçÈü≥„ÄÅË™ûÈü≥Â∞çË™ûÈü≥ÁøªË≠Ø„ÄÅÊñπË®ÄÂíå‰ΩéË≥áÊ∫êË™ûÈü≥ÁøªË≠ØÔºå‰ª•ÂèäÂç∞Â∫¶Ë™ûË®Ä„ÄÇÂÖ±‰∫´‰ªªÂãôÂê∏Âºï‰∫Ü 18 ÂÄãÂúòÈöäÔºåÂÖ∂Êèê‰∫§ÂÖßÂÆπË®òÈåÑÂú® 26 ÁØáÁ≥ªÁµ±Ë´ñÊñá‰∏≠„ÄÇÂ∞çÂè£Ë™ûÁøªË≠ØÊó•ÁõäÂ¢ûÈï∑ÁöÑËààË∂£Ôºå‰πüÂæûÂÖ±‰∫´‰ªªÂãôÁµÑÁπîËÄÖÂíåÊ¶ÇËø∞Ë´ñÊñáÁöÑÊäïÁ®øËÄÖÊï∏ÈáèÊåÅÁ∫åÂ¢ûÂä†‰∏≠ÂèØË¶ã‰∏ÄÊñëÔºåËÄåÈÄô‰∫õÁµÑÁπîËÄÖÂíåÊäïÁ®øËÄÖÂπæ‰πéÂùáÂãªÂàÜ‰ΩàÂú®Áî¢Ê•≠ÂíåÂ≠∏Ë°ìÁïå„ÄÇ

##### **PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**
2411.05085v1 by Daniel C. Castro, Aurelia Bustos, Shruthi Bannur, Stephanie L. Hyland, Kenza Bouzid, Maria Teodora Wetscherek, Maria Dolores S√°nchez-Valverde, Lara Jaques-P√©rez, Lourdes P√©rez-Rodr√≠guez, Kenji Takeda, Jos√© Mar√≠a Salinas, Javier Alvarez-Valle, Joaqu√≠n Galant Herrero, Antonio Pertusa

Radiology report generation (RRG) aims to create free-text radiology reports
from clinical imaging. Grounded radiology report generation (GRRG) extends RRG
by including the localisation of individual findings on the image. Currently,
there are no manually annotated chest X-ray (CXR) datasets to train GRRG
models. In this work, we present a dataset called PadChest-GR
(Grounded-Reporting) derived from PadChest aimed at training GRRG models for
CXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with
grounded reports (3,099 abnormal and 1,456 normal), each containing complete
lists of sentences describing individual present (positive) and absent
(negative) findings in English and Spanish. In total, PadChest-GR contains
7,037 positive and 3,422 negative finding sentences. Every positive finding
sentence is associated with up to two independent sets of bounding boxes
labelled by different readers and has categorical labels for finding type,
locations, and progression. To the best of our knowledge, PadChest-GR is the
first manually curated dataset designed to train GRRG models for understanding
and interpreting radiological images and generated text. By including detailed
localization and comprehensive annotations of all clinically relevant findings,
it provides a valuable resource for developing and evaluating GRRG models from
CXR images. PadChest-GR can be downloaded under request from
https://bimcv.cipf.es/bimcv-projects/padchest-gr/

ÊëòË¶ÅÔºö<paragraph>ÊîæÂ∞ÑÂ≠∏Â†±ÂëäÁîüÊàê (RRG) Êó®Âú®ÂæûËá®Â∫äÂΩ±ÂÉèÂª∫Á´ãËá™Áî±ÊñáÂ≠óÁöÑÊîæÂ∞ÑÂ≠∏Â†±Âëä„ÄÇÂü∫Á§éÊîæÂ∞ÑÂ≠∏Â†±ÂëäÁîüÊàê (GRRG) ÈÄèÈÅéÁ¥çÂÖ•ÂΩ±ÂÉè‰∏äÂÄãÂà•ÁôºÁèæÁöÑÂÆö‰ΩçÔºå‰æÜÂª∂‰º∏ RRG„ÄÇÁõÆÂâçÔºåÊ≤íÊúâÊâãÂãïÊ®ôË®òÁöÑËÉ∏ÈÉ® X ÂÖâ (CXR) Ë≥áÊñôÈõÜÔºåÂèØ‰æõË®ìÁ∑¥ GRRG Ê®°Âûã„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ PadChest-GRÔºàÂü∫Á§éÂ†±ÂëäÔºâÁöÑË≥áÊñôÈõÜÔºåÂÖ∂Ê∫êËá™ PadChestÔºåÊó®Âú®Ë®ìÁ∑¥ CXR ÂΩ±ÂÉèÁöÑ GRRG Ê®°Âûã„ÄÇÊàëÂÄëÁ≠ñÂäÉ‰∫Ü‰∏ÄÂÄãÂÖ¨ÈñãÁöÑÈõôË™ûË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 4,555 ‰ªΩ CXR Á†îÁ©∂ÔºåÈôÑÊúâÂü∫Á§éÂ†±ÂëäÔºà3,099 ‰ªΩÁï∞Â∏∏Â†±ÂëäÂíå 1,456 ‰ªΩÊ≠£Â∏∏Â†±ÂëäÔºâÔºåÊØèÂÄãÂ†±ÂëäÈÉΩÂåÖÂê´ÂÆåÊï¥ÁöÑÂè•Â≠êÊ∏ÖÂñÆÔºåÁî®Ëã±ÊñáÂíåË•øÁè≠ÁâôÊñáÊèèËø∞ÂÄãÂà•Â≠òÂú®ÁöÑÔºàÈôΩÊÄßÔºâÂíå‰∏çÂ≠òÂú®ÁöÑÔºàÈô∞ÊÄßÔºâÁôºÁèæ„ÄÇÁ∏ΩË®àÔºåPadChest-GR ÂåÖÂê´ 7,037 ÂÄãÈôΩÊÄßÁôºÁèæÂè•Â≠êÂíå 3,422 ÂÄãÈô∞ÊÄßÁôºÁèæÂè•Â≠ê„ÄÇÊØèÂÄãÈôΩÊÄßÁôºÁèæÂè•Â≠êÊúÄÂ§öËàáÂÖ©ÁµÑÁç®Á´ãÁöÑÈÇäÁïåÊ°ÜÁõ∏ÈóúËÅØÔºåÁî±‰∏çÂêåÁöÑËÆÄËÄÖÊ®ôË®òÔºå‰∏¶ÂÖ∑ÊúâÁôºÁèæÈ°ûÂûã„ÄÅ‰ΩçÁΩÆÂíåÈÄ≤Â±ïÁöÑÂàÜÈ°ûÊ®ôÁ±§„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåPadChest-GR ÊòØÁ¨¨‰∏ÄÂÄãÊâãÂãïÁ≠ñÂäÉÁöÑË≥áÊñôÈõÜÔºåÊó®Âú®Ë®ìÁ∑¥ GRRG Ê®°ÂûãÔºå‰ª•ÁêÜËß£ÂíåË©ÆÈáãÊîæÂ∞ÑÂ≠∏ÂΩ±ÂÉèÂíåÁî¢ÁîüÁöÑÊñáÂ≠ó„ÄÇÈÄèÈÅéÁ¥çÂÖ•ÊâÄÊúâËá®Â∫äÁõ∏ÈóúÁôºÁèæÁöÑË©≥Á¥∞ÂÆö‰ΩçÂíåÁ∂úÂêàË®ªËß£ÔºåÂÆÉÁÇ∫Âæû CXR ÂΩ±ÂÉèÈñãÁôºÂíåË©ï‰º∞ GRRG Ê®°ÂûãÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË≥áÊ∫ê„ÄÇPadChest-GR ÂèØÊáâË¶ÅÊ±ÇÂæû https://bimcv.cipf.es/bimcv-projects/padchest-gr/ ‰∏ãËºâ</paragraph>

##### **Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model**
2411.05079v1 by Sheng Cheng, Maitreya Patel, Yezhou Yang

Despite advancements in text-to-image models, generating images that
precisely align with textual descriptions remains challenging due to
misalignment in training data. In this paper, we analyze the critical role of
caption precision and recall in text-to-image model training. Our analysis of
human-annotated captions shows that both precision and recall are important for
text-image alignment, but precision has a more significant impact. Leveraging
these insights, we utilize Large Vision Language Models to generate synthetic
captions for training. Models trained with these synthetic captions show
similar behavior to those trained on human-annotated captions, underscores the
potential for synthetic data in text-to-image training.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊñáÂ≠óËΩâÂúñÂÉèÊ®°ÂûãÊúâÈÄ≤Â±ïÔºå‰ΩÜÁî±ÊñºË®ìÁ∑¥Ë≥áÊñôÂá∫ÁèæÈåØ‰ΩçÔºåË¶ÅÁî¢ÁîüËàáÊñáÂ≠óÊèèËø∞Á≤æÁ¢∫Â∞çÈΩäÁöÑÂúñÂÉè‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÊ®ôÈ°åÁ≤æÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéáÂú®ÊñáÂ≠óËΩâÂúñÂÉèÊ®°ÂûãË®ìÁ∑¥‰∏≠ÁöÑÈóúÈçµËßíËâ≤„ÄÇÊàëÂÄëÂ∞ç‰∫∫Â∑•Ê®ôË®ªÊ®ôÈ°åÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÁ≤æÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéáÂ∞çÊñºÊñáÂ≠óËàáÂúñÂÉèÂ∞çÈΩäÈÉΩÂæàÈáçË¶ÅÔºå‰ΩÜÁ≤æÁ¢∫Â∫¶ÊúâÊõ¥È°ØËëóÁöÑÂΩ±Èüø„ÄÇÂà©Áî®ÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÂà©Áî®Â§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã‰æÜÁî¢ÁîüÁî®ÊñºË®ìÁ∑¥ÁöÑÂêàÊàêÊ®ôÈ°å„ÄÇ‰ΩøÁî®ÈÄô‰∫õÂêàÊàêÊ®ôÈ°åË®ìÁ∑¥ÁöÑÊ®°ÂûãÈ°ØÁ§∫Âá∫ËàáÂú®‰∫∫Â∑•Ê®ôË®ªÊ®ôÈ°å‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÈ°û‰ººÁöÑË°åÁÇ∫ÔºåÈÄôÂº∑Ë™ø‰∫ÜÂêàÊàêË≥áÊñôÂú®ÊñáÂ≠óËΩâÂúñÂÉèË®ìÁ∑¥‰∏≠ÁöÑÊΩõÂäõ„ÄÇ

##### **ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning**
2411.05003v1 by David Junhao Zhang, Roni Paiss, Shiran Zada, Nikhil Karnad, David E. Jacobs, Yael Pritch, Inbar Mosseri, Mike Zheng Shou, Neal Wadhwa, Nataniel Ruiz

Recently, breakthroughs in video modeling have allowed for controllable
camera trajectories in generated videos. However, these methods cannot be
directly applied to user-provided videos that are not generated by a video
model. In this paper, we present ReCapture, a method for generating new videos
with novel camera trajectories from a single user-provided video. Our method
allows us to re-generate the reference video, with all its existing scene
motion, from vastly different angles and with cinematic camera motion. Notably,
using our method we can also plausibly hallucinate parts of the scene that were
not observable in the reference video. Our method works by (1) generating a
noisy anchor video with a new camera trajectory using multiview diffusion
models or depth-based point cloud rendering and then (2) regenerating the
anchor video into a clean and temporally consistent reangled video using our
proposed masked video fine-tuning technique.

ÊëòË¶ÅÔºöÊúÄËøëÔºåÂΩ±ÁâáÂª∫Ê®°ÁöÑÁ™ÅÁ†¥ÊÄßÈÄ≤Â±ïËÆìÁîüÊàêÂΩ±Áâá‰∏≠ÁöÑÁõ∏Ê©üËªåË∑°ÂèØÊéß„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁÑ°Ê≥ïÁõ¥Êé•ÊáâÁî®ÊñºÈùûÂΩ±ÁâáÊ®°ÂûãÁîüÊàêÁöÑ‰ΩøÁî®ËÄÖÊèê‰æõÂΩ±Áâá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ ReCaptureÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂèØÂæûÂñÆ‰∏Ä‰ΩøÁî®ËÄÖÊèê‰æõÁöÑÂΩ±Áâá‰∏≠ÁîüÊàêÂÖ∑ÊúâÊñ∞Á©éÁõ∏Ê©üËªåË∑°ÁöÑÊñ∞ÂΩ±Áâá„ÄÇÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïËÆìÊàëÂÄëËÉΩÂ§†ÂæûÊà™ÁÑ∂‰∏çÂêåÁöÑËßíÂ∫¶ÂíåÈõªÂΩ±Áõ∏Ê©üÈÅãÂãï‰∏≠ÈáçÊñ∞ÁîüÊàêÂèÉËÄÉÂΩ±ÁâáÔºå‰∏¶ÂåÖÂê´ÂÖ∂ÊâÄÊúâÁèæÊúâÁöÑÂ†¥ÊôØÂãï‰Ωú„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºå‰ΩøÁî®ÊàëÂÄëÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÈÇÑÂèØ‰ª•ÂêàÁêÜÂú∞Â∞çÂèÉËÄÉÂΩ±Áâá‰∏≠ÁÑ°Ê≥ïËßÄÂØüÂà∞ÁöÑÂ†¥ÊôØÈÉ®ÂàÜÈÄ≤Ë°åÂπªË¶∫„ÄÇÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïÈÅã‰ΩúÊñπÂºèÁÇ∫Ôºö(1) ‰ΩøÁî®Â§öË¶ñÂúñÊì¥Êï£Ê®°ÂûãÊàñÂü∫ÊñºÊ∑±Â∫¶ÈªûÈõ≤Ê∏≤Êüì‰æÜÁîüÊàêÂÖ∑ÊúâÊñ∞Áõ∏Ê©üËªåË∑°ÁöÑÈõúË®äÈå®ÂÆöÂΩ±ÁâáÔºåÁÑ∂Âæå (2) ‰ΩøÁî®ÊàëÂÄëÊèêÂá∫ÁöÑÈÅÆÁΩ©ÂΩ±ÁâáÂæÆË™øÊäÄË°ìÔºåÂ∞áÈå®ÂÆöÂΩ±ÁâáÈáçÊñ∞ÁîüÊàêÁÇ∫‰πæÊ∑®‰∏îÊôÇÈñì‰∏ÄËá¥ÁöÑÈáçÊñ∞Ë™øÊï¥ËßíÂ∫¶ÂΩ±Áâá„ÄÇ

##### **Analyzing The Language of Visual Tokens**
2411.05001v1 by David M. Chan, Rodolfo Corona, Joonyong Park, Cheol Jun Cho, Yutong Bai, Trevor Darrell

With the introduction of transformer-based models for vision and language
tasks, such as LLaVA and Chameleon, there has been renewed interest in the
discrete tokenized representation of images. These models often treat image
patches as discrete tokens, analogous to words in natural language, learning
joint alignments between visual and human languages. However, little is known
about the statistical behavior of these visual languages - whether they follow
similar frequency distributions, grammatical structures, or topologies as
natural languages. In this paper, we take a natural-language-centric approach
to analyzing discrete visual languages and uncover striking similarities and
fundamental differences. We demonstrate that, although visual languages adhere
to Zipfian distributions, higher token innovation drives greater entropy and
lower compression, with tokens predominantly representing object parts,
indicating intermediate granularity. We also show that visual languages lack
cohesive grammatical structures, leading to higher perplexity and weaker
hierarchical organization compared to natural languages. Finally, we
demonstrate that, while vision models align more closely with natural languages
than other models, this alignment remains significantly weaker than the
cohesion found within natural languages. Through these experiments, we
demonstrate how understanding the statistical properties of discrete visual
languages can inform the design of more effective computer vision models.

ÊëòË¶ÅÔºöÈö®ËëóÂü∫ÊñºTransformerÁöÑË¶ñË¶∫ÂíåË™ûË®Ä‰ªªÂãôÊ®°ÂûãÔºà‰æãÂ¶Ç LLaVA Âíå ChameleonÔºâÁöÑÂºïÂÖ•Ôºå‰∫∫ÂÄëÂ∞çÂΩ±ÂÉèÁöÑÈõ¢Êï£Ê®ôË®òÂåñË°®Á§∫Ê≥ïÈáçÊñ∞Áî¢ÁîüËààË∂£„ÄÇÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏Â∞áÂΩ±ÂÉèÂçÄÂ°äË¶ñÁÇ∫Èõ¢Êï£Ê®ôË®òÔºåÈ°û‰ººÊñºËá™ÁÑ∂Ë™ûË®Ä‰∏≠ÁöÑÂñÆÂ≠óÔºå‰∏¶Â≠∏ÁøíË¶ñË¶∫Ë™ûË®ÄÂíå‰∫∫È°ûË™ûË®Ä‰πãÈñìÁöÑËÅØÂêàÂ∞çÈΩä„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÈÄô‰∫õË¶ñË¶∫Ë™ûË®ÄÁöÑÁµ±Ë®àË°åÁÇ∫ÊâÄÁü•ÁîöÂ∞ëÔºå‰æãÂ¶ÇÂÆÉÂÄëÊòØÂê¶ÈÅµÂæ™ËàáËá™ÁÑ∂Ë™ûË®ÄÈ°û‰ººÁöÑÈ†ªÁéáÂàÜ‰Ωà„ÄÅË™ûÊ≥ïÁµêÊßãÊàñÊãìÊí≤ÁµêÊßã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé°Áî®‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÁÇ∫‰∏≠ÂøÉÁöÑÈÄîÂæë‰æÜÂàÜÊûêÈõ¢Êï£Ë¶ñË¶∫Ë™ûË®ÄÔºå‰∏¶Êè≠Á§∫È©ö‰∫∫ÁöÑÁõ∏‰ººÊÄßÂíåÊ†πÊú¨Â∑ÆÁï∞„ÄÇÊàëÂÄëË≠âÊòéÔºåÂÑòÁÆ°Ë¶ñË¶∫Ë™ûË®ÄÈÅµÂæ™ÈΩäÂ§´ÂàÜÂ∏ÉÔºå‰ΩÜËºÉÈ´òÁöÑÊ®ôË®òÂâµÊñ∞ÊúÉÂ∞éËá¥Êõ¥Â§ßÁöÑÁÜµÂíåÊõ¥‰ΩéÁöÑÂ£ìÁ∏ÆÔºåËÄåÊ®ôË®ò‰∏ªË¶Å‰ª£Ë°®Áâ©‰ª∂ÈÉ®ÂàÜÔºåË°®Á§∫‰∏≠ÈñìÁ≤íÂ∫¶„ÄÇÊàëÂÄëÈÇÑË°®ÊòéÔºåË¶ñË¶∫Ë™ûË®ÄÁº∫‰πèÈÄ£Ë≤´ÁöÑË™ûÊ≥ïÁµêÊßãÔºåÂ∞éËá¥ËàáËá™ÁÑ∂Ë™ûË®ÄÁõ∏ÊØîÔºåÂõ∞ÊÉëÂ∫¶ËºÉÈ´ò‰∏îÂ±§Á¥öÁµÑÁπîËºÉÂº±„ÄÇÊúÄÂæåÔºåÊàëÂÄëË≠âÊòéÔºåÂÑòÁÆ°Ë¶ñË¶∫Ê®°ÂûãËàáËá™ÁÑ∂Ë™ûË®ÄÁöÑÂ∞çÈΩäÊØîÂÖ∂‰ªñÊ®°ÂûãÊõ¥Á∑äÂØÜÔºå‰ΩÜÈÄôÁ®ÆÂ∞çÈΩä‰ªçÁÑ∂È°ØËëóÂº±ÊñºËá™ÁÑ∂Ë™ûË®Ä‰∏≠ÁôºÁèæÁöÑÂÖßËÅöÊÄß„ÄÇÈÄèÈÅéÈÄô‰∫õÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÁêÜËß£Èõ¢Êï£Ë¶ñË¶∫Ë™ûË®ÄÁöÑÁµ±Ë®àÂ±¨ÊÄßÂ¶Ç‰ΩïÁÇ∫Êõ¥ÊúâÊïàÁöÑÈõªËÖ¶Ë¶ñË¶∫Ê®°ÂûãÁöÑË®≠Ë®àÊèê‰æõË≥áË®ä„ÄÇ

##### **Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?**
2411.05000v1 by Jonathan Roberts, Kai Han, Samuel Albanie

As the context limits of Large Language Models (LLMs) increase, the range of
possible applications and downstream functions broadens. In many real-world
tasks, decisions depend on details scattered across collections of often
disparate documents containing mostly irrelevant information. Long-context LLMs
appear well-suited to this form of complex information retrieval and reasoning,
which has traditionally proven costly and time-consuming. However, although the
development of longer context models has seen rapid gains in recent years, our
understanding of how effectively LLMs use their context has not kept pace. To
address this, we conduct a set of retrieval experiments designed to evaluate
the capabilities of 17 leading LLMs, such as their ability to follow threads of
information through the context window. Strikingly, we find that many models
are remarkably threadsafe: capable of simultaneously following multiple threads
without significant loss in performance. Still, for many models, we find the
effective context limit is significantly shorter than the supported context
length, with accuracy decreasing as the context window grows. Our study also
highlights the important point that token counts from different tokenizers
should not be directly compared -- they often correspond to substantially
different numbers of written characters. We release our code and long-context
experimental data.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂÖßÂÆπÈôêÂà∂Â¢ûÂä†ÔºåÂèØËÉΩÁöÑÊáâÁî®ÁØÑÂúçÂíå‰∏ãÊ∏∏ÂäüËÉΩ‰πüÈö®‰πãÊì¥Â±ï„ÄÇÂú®Ë®±Â§öÁúüÂØ¶‰∏ñÁïåÁöÑ‰ªªÂãô‰∏≠ÔºåÊ±∫Á≠ñÂèñÊ±∫ÊñºÂàÜÊï£Âú®ÈÄöÂ∏∏ÂåÖÂê´Â§ßÈáèÁÑ°ÈóúË®äÊÅØÁöÑÊñá‰ª∂ÈõÜÂêà‰∏≠ÁöÑÁ¥∞ÁØÄ„ÄÇÈï∑ÂÖßÂÆπÈôêÂà∂ÁöÑ LLM ‰ºº‰πéÂæàÈÅ©ÂêàÈÄôÁ®ÆË§áÈõúÁöÑË≥áË®äÊ™¢Á¥¢ÂíåÊé®ÁêÜÂΩ¢ÂºèÔºåËÄåÈÄôÁ®ÆÂΩ¢ÂºèÂÇ≥Áµ±‰∏äË¢´Ë≠âÊòéÊó¢ÊòÇË≤¥ÂèàËÄóÊôÇ„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°ËºÉÈï∑ÂÖßÂÆπÈôêÂà∂Ê®°ÂûãÁöÑÈñãÁôºÂú®ËøëÂπ¥‰æÜÂ∑≤Âø´ÈÄüÈÄ≤Ê≠•Ôºå‰ΩÜÊàëÂÄëÂ∞çÊñº LLM Â¶Ç‰ΩïÊúâÊïà‰ΩøÁî®ÂÖ∂ÂÖßÂÆπÈôêÂà∂ÁöÑÁêÜËß£‰∏¶Êú™Ë∑ü‰∏äËÖ≥Ê≠•„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÁµÑÊ™¢Á¥¢ÂØ¶È©óÔºåÊó®Âú®Ë©ï‰º∞ 17 ÂÄãÈ†òÂÖà LLM ÁöÑÂäüËÉΩÔºå‰æãÂ¶ÇÂÆÉÂÄëÈÄèÈÅéÂÖßÂÆπÈôêÂà∂Ë¶ñÁ™óËøΩËπ§Ë≥áË®ä‰∏≤ÁöÑËÉΩÂäõ„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæË®±Â§öÊ®°ÂûãÂÖ∑ÊúâÈ°ØËëóÁöÑÂü∑Ë°åÁ∑íÂÆâÂÖ®ÊÄßÔºöËÉΩÂ§†ÂêåÊôÇËøΩËπ§Â§öÂÄãÂü∑Ë°åÁ∑íÔºåËÄå‰∏çÊúÉÈ°ØËëóÊêçÂ§±ÊïàËÉΩ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂ∞çÊñºË®±Â§öÊ®°ÂûãÔºåÊàëÂÄëÁôºÁèæÊúâÊïàÁöÑÂÖßÂÆπÈôêÂà∂È°ØËëóÁü≠ÊñºÂèóÊîØÊè¥ÁöÑÂÖßÂÆπÈôêÂà∂Èï∑Â∫¶ÔºåËÄå‰∏îÈö®ËëóÂÖßÂÆπÈôêÂà∂Ë¶ñÁ™óÁöÑÂ¢ûÂä†ÔºåÊ∫ñÁ¢∫Â∫¶‰πüÊúÉ‰∏ãÈôç„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰πüÂº∑Ë™ø‰∫Ü‰∏ÄÂÄãÈáçË¶ÅËßÄÈªûÔºåÂç≥‰æÜËá™‰∏çÂêåÂàÜË©ûÂô®ÁöÑ‰ª£Á¢ºË®àÊï∏‰∏çÊáâÁõ¥Êé•ÊØîËºÉ‚Äî‚ÄîÂÆÉÂÄëÈÄöÂ∏∏Â∞çÊáâÊñºÂ§ßÈáè‰∏çÂêåÁöÑÊõ∏Èù¢Â≠óÂÖÉ„ÄÇÊàëÂÄëÁôºÂ∏ÉÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÈï∑ÂÖßÂÆπÈôêÂà∂ÁöÑÂØ¶È©óË≥áÊñô„ÄÇ

##### **LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation**
2411.04997v1 by Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, Lili Qiu

CLIP is one of the most important multimodal foundational models today. What
powers CLIP's capabilities? The rich supervision signals provided by natural
language, the carrier of human knowledge, shape a powerful cross-modal
representation space. However, with the rapid advancements in large language
models LLMs like GPT-4 and LLaMA, the boundaries of language comprehension and
generation are continually being pushed. This raises an intriguing question:
can the capabilities of LLMs be harnessed to further improve multimodal
representation learning? The potential benefits of incorporating LLMs into CLIP
are clear. LLMs' strong textual understanding can fundamentally improve CLIP's
ability to handle image captions, drastically enhancing its ability to process
long and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMs
are trained on a vast corpus of text, possessing open-world knowledge. This
allows them to expand on caption information during training, increasing the
efficiency of the learning process. In this paper, we propose LLM2CLIP, a novel
approach that embraces the power of LLMs to unlock CLIP's potential. By
fine-tuning the LLM in the caption space with contrastive learning, we extract
its textual capabilities into the output embeddings, significantly improving
the output layer's textual discriminability. We then design an efficient
training process where the fine-tuned LLM acts as a powerful teacher for CLIP's
visual encoder. Thanks to the LLM's presence, we can now incorporate longer and
more complex captions without being restricted by vanilla CLIP's text encoder's
context window and ability limitations. Our experiments demonstrate that this
approach brings substantial improvements in cross-modal tasks.

ÊëòË¶ÅÔºöCLIP ÊòØÁï∂‰ªäÊúÄÈáçË¶ÅÁöÑÂ§öÊ®°ÊÖãÂü∫Á§éÊ®°Âûã‰πã‰∏Ä„ÄÇÊòØ‰ªÄÈ∫ºË≥¶‰∫à‰∫Ü CLIP ÁöÑËÉΩÂäõÔºüËá™ÁÑ∂Ë™ûË®ÄÊèê‰æõÁöÑË±êÂØåÁõ£Áù£Ë®äËôüÔºå‰∫∫È°ûÁü•Ë≠òÁöÑËºâÈ´îÔºåÂ°ëÈÄ†‰∫Ü‰∏ÄÂÄãÂº∑Â§ßÁöÑË∑®Ê®°ÊÖãË°®Á§∫Á©∫Èñì„ÄÇÁÑ∂ËÄåÔºåÈö®Ëëó GPT-4 Âíå LLaMA Á≠âÂ§ßÂûãË™ûË®ÄÊ®°Âûã LLM ÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºåË™ûË®ÄÁêÜËß£ÂíåÁîüÊàêÁöÑÁïåÈôê‰∏çÊñ∑Ë¢´Êé®Âãï„ÄÇÈÄôÂºïÁôº‰∫Ü‰∏ÄÂÄãÊúâË∂£ÁöÑÂïèÈ°åÔºöLLM ÁöÑËÉΩÂäõÊòØÂê¶ÂèØ‰ª•Ë¢´Âà©Áî®‰æÜÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤Â§öÊ®°ÊÖãË°®Á§∫Â≠∏ÁøíÔºüÂ∞á LLM Á¥çÂÖ• CLIP ÁöÑÊΩõÂú®Â•ΩËôïÂæàÊòéÈ°Ø„ÄÇLLM Âº∑Â§ßÁöÑÊñáÊú¨ÁêÜËß£ÂäõÂèØ‰ª•ÂæûÊ†πÊú¨‰∏äÊèêÈ´ò CLIP ËôïÁêÜÂúñÂÉèÊ®ôÈ°åÁöÑËÉΩÂäõÔºåÂ§ßÂπÖÂ¢ûÂº∑ÂÖ∂ËôïÁêÜÈï∑ËÄåË§áÈõúÊñáÊú¨ÁöÑËÉΩÂäõÔºåÈÄôÊòØÈ¶ôËçâ CLIP ÁöÑ‰∏ÄÂÄãÁúæÊâÄÂë®Áü•ÈôêÂà∂„ÄÇÊ≠§Â§ñÔºåLLM ÊòØÂú®Â§ßÈáèÁöÑÊñáÊú¨Ë™ûÊñôÂ∫´‰∏äË®ìÁ∑¥ÁöÑÔºåÊìÅÊúâÈñãÊîæ‰∏ñÁïåÁöÑÁü•Ë≠ò„ÄÇÈÄô‰Ωø‰ªñÂÄëËÉΩÂ§†Âú®Ë®ìÁ∑¥ÊúüÈñìÊì¥Â±ïÊ®ôÈ°å‰ø°ÊÅØÔºåÂæûËÄåÊèêÈ´òÂ≠∏ÁøíÈÅéÁ®ãÁöÑÊïàÁéá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LLM2CLIPÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂÆÉÂà©Áî® LLM ÁöÑÂäõÈáè‰æÜÈáãÊîæ CLIP ÁöÑÊΩõÂäõ„ÄÇÈÄöÈÅéÂú®Â∞çÊØîÂ≠∏ÁøíÁöÑÊ®ôÈ°åÁ©∫Èñì‰∏≠ÂæÆË™ø LLMÔºåÊàëÂÄëÂ∞áÂÖ∂ÊñáÊú¨ËÉΩÂäõÊèêÂèñÂà∞Ëº∏Âá∫ÂµåÂÖ•‰∏≠ÔºåÈ°ØËëóÊèêÈ´ò‰∫ÜËº∏Âá∫Â±§ÁöÑÊñáÊú¨ÂèØÂçÄÂàÜÊÄß„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÈ´òÊïàÁöÑË®ìÁ∑¥ÈÅéÁ®ãÔºåÂÖ∂‰∏≠ÂæÆË™øÂæåÁöÑ LLM ÂÖÖÁï∂ CLIP Ë¶ñË¶∫Á∑®Á¢ºÂô®ÁöÑÂº∑Â§ßÊïôÂ∏´„ÄÇÁî±Êñº LLM ÁöÑÂ≠òÂú®ÔºåÊàëÂÄëÁèæÂú®ÂèØ‰ª•Á¥çÂÖ•Êõ¥Èï∑„ÄÅÊõ¥Ë§áÈõúÁöÑÊ®ôÈ°åÔºåËÄå‰∏çÊúÉÂèóÂà∞È¶ôËçâ CLIP ÁöÑÊñáÊú¨Á∑®Á¢ºÂô®ÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÂíåËÉΩÂäõÈôêÂà∂„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÈÄôÁ®ÆÊñπÊ≥ïÂú®Ë∑®Ê®°ÊÖã‰ªªÂãô‰∏≠Â∏∂‰æÜ‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤„ÄÇ

##### **HourVideo: 1-Hour Video-Language Understanding**
2411.04998v1 by Keshigeyan Chandrasegaran, Agrim Gupta, Lea M. Hadzic, Taran Kota, Jimming He, Crist√≥bal Eyzaguirre, Zane Durante, Manling Li, Jiajun Wu, Li Fei-Fei

We present HourVideo, a benchmark dataset for hour-long video-language
understanding. Our dataset consists of a novel task suite comprising
summarization, perception (recall, tracking), visual reasoning (spatial,
temporal, predictive, causal, counterfactual), and navigation (room-to-room,
object retrieval) tasks. HourVideo includes 500 manually curated egocentric
videos from the Ego4D dataset, spanning durations of 20 to 120 minutes, and
features 12,976 high-quality, five-way multiple-choice questions. Benchmarking
results reveal that multimodal models, including GPT-4 and LLaVA-NeXT, achieve
marginal improvements over random chance. In stark contrast, human experts
significantly outperform the state-of-the-art long-context multimodal model,
Gemini Pro 1.5 (85.0% vs. 37.3%), highlighting a substantial gap in multimodal
capabilities. Our benchmark, evaluation toolkit, prompts, and documentation are
available at https://hourvideo.stanford.edu

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ HourVideoÔºåÈÄôÊòØÈï∑ÈÅî‰∏ÄÂ∞èÊôÇÁöÑÂΩ±ÁâáË™ûË®ÄÁêÜËß£Âü∫Ê∫ñË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑË≥áÊñôÈõÜÂåÖÂê´‰∏ÄÁ≥ªÂàóÊñ∞Á©éÁöÑ‰ªªÂãôÂ•ó‰ª∂ÔºåÂåÖÂê´ÊëòË¶Å„ÄÅÊÑüÁü•ÔºàÂõûÊÜ∂„ÄÅËøΩËπ§Ôºâ„ÄÅË¶ñË¶∫Êé®ÁêÜÔºàÁ©∫Èñì„ÄÅÊôÇÈñì„ÄÅÈ†êÊ∏¨„ÄÅÂõ†Êûú„ÄÅÂèç‰∫ãÂØ¶ÔºâÂíåÂ∞éËà™ÔºàÊàøÈñìÂà∞ÊàøÈñì„ÄÅÁâ©‰ª∂Ê™¢Á¥¢Ôºâ‰ªªÂãô„ÄÇHourVideo ÂåÖÂê´‰æÜËá™ Ego4D Ë≥áÊñôÈõÜÁöÑ 500 ÂÄãÊâãÂãïÁ≠ñÂäÉÁöÑÁ¨¨‰∏Ä‰∫∫Á®±Ë¶ñËßíÂΩ±ÁâáÔºåË∑®Ë∂ä 20 Âà∞ 120 ÂàÜÈêòÁöÑÊôÇÈï∑Ôºå‰∏¶Êèê‰æõ 12,976 ÂÄãÈ´òÂìÅË≥™„ÄÅ‰∫îÈÅ∏‰∏ÄÁöÑÈÅ∏ÊìáÈ°å„ÄÇÂü∫Ê∫ñÊ∏¨Ë©¶ÁµêÊûúÈ°ØÁ§∫ÔºåÂåÖÊã¨ GPT-4 Âíå LLaVA-NeXT Âú®ÂÖßÁöÑÂ§öÊ®°ÊÖãÊ®°ÂûãÔºåÊØîÈö®Ê©üÊ©üÊúÉÁç≤ÂæóÈÇäÈöõÊîπÂñÑ„ÄÇËàá‰πãÂΩ¢ÊàêÈÆÆÊòéÂ∞çÊØîÁöÑÊòØÔºå‰∫∫È°ûÂ∞àÂÆ∂È°ØËëóÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÈï∑ËÑàÁµ°Â§öÊ®°ÊÖãÊ®°Âûã Gemini Pro 1.5Ôºà85.0% Â∞çÊØî 37.3%ÔºâÔºåÁ™ÅÈ°ØÂá∫Â§öÊ®°ÊÖãËÉΩÂäõÁöÑÂ∑®Â§ßÂ∑ÆË∑ù„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñ„ÄÅË©ï‰º∞Â∑•ÂÖ∑ÂåÖ„ÄÅÊèêÁ§∫ÂíåÊñá‰ª∂ÂèØÂú® https://hourvideo.stanford.edu ÂèñÂæó

##### **Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models**
2411.04996v1 by Weixin Liang, Lili Yu, Liang Luo, Srinivasan Iyer, Ning Dong, Chunting Zhou, Gargi Ghosh, Mike Lewis, Wen-tau Yih, Luke Zettlemoyer, Xi Victoria Lin

The development of large language models (LLMs) has expanded to multi-modal
systems capable of processing text, images, and speech within a unified
framework. Training these models demands significantly larger datasets and
computational resources compared to text-only LLMs. To address the scaling
challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal
transformer architecture that significantly reduces pretraining computational
costs. MoT decouples non-embedding parameters of the model by modality --
including feed-forward networks, attention matrices, and layer normalization --
enabling modality-specific processing with global self-attention over the full
input sequence. We evaluate MoT across multiple settings and model scales. In
the Chameleon 7B setting (autoregressive text-and-image generation), MoT
matches the dense baseline's performance using only 55.8\% of the FLOPs. When
extended to include speech, MoT reaches speech performance comparable to the
dense baseline with only 37.2\% of the FLOPs. In the Transfusion setting, where
text and image are trained with different objectives, a 7B MoT model matches
the image modality performance of the dense baseline with one third of the
FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image
generation metrics. System profiling further highlights MoT's practical
benefits, achieving dense baseline image quality in 47.2\% of the wall-clock
time and text quality in 75.6\% of the wall-clock time (measured on AWS
p4de.24xlarge instances with NVIDIA A100 GPUs).

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁôºÂ±ïÂ∑≤Êì¥Â±ïÂà∞Â§öÊ®°ÊÖãÁ≥ªÁµ±ÔºåËÉΩÂ§†Âú®Áµ±‰∏ÄÁöÑÊû∂ÊßãÂÖßËôïÁêÜÊñáÂ≠ó„ÄÅÂΩ±ÂÉèÂíåË™ûÈü≥„ÄÇË®ìÁ∑¥ÈÄô‰∫õÊ®°ÂûãÈúÄË¶ÅÊØîÂÉÖÊñáÂ≠óÁöÑ LLM Â§ßÂæóÂ§öÁöÑË≥áÊñôÈõÜÂíåÈÅãÁÆóË≥áÊ∫ê„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊì¥ÂÖÖÊåëÊà∞ÔºåÊàëÂÄëÂºïÈÄ≤Ê∑∑ÂêàTransformer (MoT)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁ®ÄÁñèÂ§öÊ®°ÊÖãTransformerÊû∂ÊßãÔºåÂèØÂ§ßÂπÖÊ∏õÂ∞ëÈ†êË®ìÁ∑¥ÁöÑÈÅãÁÆóÊàêÊú¨„ÄÇMoT ÈÄèÈÅéÊ®°ÊÖãËß£ËÄ¶Ê®°ÂûãÁöÑÈùûÂµåÂÖ•ÂèÉÊï∏ÔºåÂåÖÊã¨ÂâçÈ•ãÁ∂≤Ë∑Ø„ÄÅÊ≥®ÊÑèÂäõÁü©Èô£ÂíåÂ±§Ê¨°Ê®ôÊ∫ñÂåñÔºå‰∏¶Âú®ÂÆåÊï¥ÁöÑËº∏ÂÖ•Â∫èÂàó‰∏äÂïüÁî®ÂÖ∑ÂÇôÂÖ®Â±ÄËá™ÊàëÊ≥®ÊÑèÂäõÁöÑÊ®°ÊÖãÁâπÂÆöËôïÁêÜ„ÄÇÊàëÂÄëÂú®Â§öÁ®ÆË®≠ÂÆöÂíåÊ®°ÂûãË¶èÊ®°‰∏≠Ë©ï‰º∞ MoT„ÄÇÂú®ËÆäËâ≤Èæç 7B Ë®≠ÂÆöÔºàËá™Ëø¥Ê≠∏ÊñáÂ≠óÂíåÂΩ±ÂÉèÁî¢ÁîüÔºâ‰∏≠ÔºåMoT ÂÉÖ‰ΩøÁî® 55.8% ÁöÑÊµÆÈªûÈÅãÁÆóÊ¨°Êï∏ (FLOP) Â∞±ÈÅîÂà∞ÂØÜÈõÜÂü∫Á∑öÁöÑÊïàËÉΩ„ÄÇÁï∂Êì¥ÂÖÖÂà∞ÂåÖÂê´Ë™ûÈü≥ÊôÇÔºåMoT ÈÅîÂà∞ÁöÑË™ûÈü≥ÊïàËÉΩÂèØËàáÂØÜÈõÜÂü∫Á∑öÁõ∏ÊØîÔºå‰ΩÜÂÉÖ‰ΩøÁî® 37.2% ÁöÑÊµÆÈªûÈÅãÁÆóÊ¨°Êï∏„ÄÇÂú®Ëº∏Ë°ÄË®≠ÂÆö‰∏≠ÔºåÊñáÂ≠óÂíåÂΩ±ÂÉè‰ΩøÁî®‰∏çÂêåÁöÑÁõÆÊ®ôÈÄ≤Ë°åË®ìÁ∑¥Ôºå7B MoT Ê®°ÂûãÁöÑÂΩ±ÂÉèÊ®°ÊÖãÊïàËÉΩËàáÂØÜÈõÜÂü∫Á∑öÁõ∏Áï∂Ôºå‰ΩÜÊµÆÈªûÈÅãÁÆóÊ¨°Êï∏Âè™Êúâ‰∏âÂàÜ‰πã‰∏ÄÔºåËÄå 760M MoT Ê®°ÂûãÂâáÂú®ÈóúÈçµÂΩ±ÂÉèÁî¢ÁîüÊåáÊ®ô‰∏äÂÑ™Êñº 1.4B ÂØÜÈõÜÂü∫Á∑ö„ÄÇÁ≥ªÁµ±ÂàÜÊûêÈÄ≤‰∏ÄÊ≠•Á™ÅÈ°Ø‰∫Ü MoT ÁöÑÂØ¶ÈöõÊïàÁõäÔºåÂú® 47.2% ÁöÑÂØ¶ÈöõÊôÇÈñìÂÖßÈÅîÊàêÂØÜÈõÜÂü∫Á∑öÂΩ±ÂÉèÂìÅË≥™ÔºåÂú® 75.6% ÁöÑÂØ¶ÈöõÊôÇÈñìÂÖßÈÅîÊàêÊñáÂ≠óÂìÅË≥™ÔºàÂú®ÈÖçÂÇô NVIDIA A100 GPU ÁöÑ AWS p4de.24xlarge ÂØ¶‰æã‰∏äÊ∏¨ÈáèÔºâ„ÄÇ

##### **Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives**
2411.04991v1 by Hao Sun, Yunyi Shen, Jean-Francois Ton

The Bradley-Terry (BT) model is a common and successful practice in reward
modeling for Large Language Model (LLM) alignment. However, it remains unclear
why this model -- originally developed for multi-player stochastic game
matching -- can be adopted to convert pairwise response comparisons to reward
values and make predictions. Especially given the fact that only a limited
number of prompt-response pairs are sparsely compared with others. In this
paper, we first revisit the foundations of using BT models in reward modeling,
and establish the convergence rate of BT reward models based on deep neural
networks using embeddings, providing a theoretical foundation for their use.
Despite theoretically sound, we argue that the BT model is not a necessary
choice from the perspective of downstream optimization. This is because a
reward model only needs to preserve the correct ranking predictions through a
monotonic transformation of the true reward. We highlight the critical concept
of order consistency in reward modeling and demonstrate that the BT model
possesses this property. Consequently, we propose a simple and straightforward
upper-bound algorithm, compatible with off-the-shelf binary classifiers, as an
alternative order-consistent reward modeling objective. To offer practical
insights, we empirically evaluate the performance of these different reward
modeling approaches across more than 12,000 experimental setups, using $6$ base
LLMs, $2$ datasets, and diverse annotation designs that vary in quantity,
quality, and pairing choices in preference annotations.

ÊëòË¶ÅÔºöBradley-Terry (BT) Ê®°ÂûãÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞çÈΩä‰∏≠ÁçéÂãµÂª∫Ê®°ÁöÑÂ∏∏Ë¶ã‰∏îÊàêÂäüÁöÑÂØ¶Âãô„ÄÇÁÑ∂ËÄåÔºåÈÄôÂÄãÊ®°ÂûãÊúÄÂàùÊòØÁÇ∫Â§öÁé©ÂÆ∂Èö®Ê©üÈÅäÊà≤ÈÖçÂ∞çËÄåÈñãÁôºÁöÑÔºåÁÇ∫‰ªÄÈ∫ºÂÆÉÂèØ‰ª•Ë¢´Êé°Áî®‰æÜÂ∞áÊàêÂ∞çÁöÑÂõûÊáâÊØîËºÉËΩâÊèõÁÇ∫ÁçéÂãµÂÄº‰∏¶ÂÅöÂá∫È†êÊ∏¨ÔºåÈÄô‰ªçÁÑ∂‰∏çÊ∏ÖÊ•ö„ÄÇÁâπÂà•ÊòØËÄÉÊÖÆÂà∞Âè™ÊúâÊúâÈôêÊï∏ÈáèÁöÑÊèêÁ§∫ÂõûÊáâÂ∞çËàáÂÖ∂‰ªñÂ∞çÁ®ÄÁñèÂú∞ÈÄ≤Ë°åÊØîËºÉ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÈáçÊñ∞Êé¢Ë®éÂú®ÁçéÂãµÂª∫Ê®°‰∏≠‰ΩøÁî® BT Ê®°ÂûãÁöÑÂü∫Á§éÔºå‰∏¶‰ΩøÁî®ÂµåÂÖ•Âª∫Á´ãÂü∫ÊñºÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑ BT ÁçéÂãµÊ®°ÂûãÁöÑÊî∂ÊñÇÈÄüÂ∫¶ÔºåÁÇ∫ÂÆÉÂÄëÁöÑ‰ΩøÁî®Êèê‰æõÁêÜË´ñÂü∫Á§é„ÄÇÂÑòÁÆ°Âú®ÁêÜË´ñ‰∏äÊòØÂêàÁêÜÁöÑÔºåÊàëÂÄëË™çÁÇ∫Âæû‰∏ãÊ∏∏ÊúÄ‰Ω≥ÂåñÁöÑËßíÂ∫¶‰æÜÁúãÔºåBT Ê®°Âûã‰∏¶ÈùûÂøÖË¶ÅÁöÑÈÅ∏Êìá„ÄÇÈÄôÊòØÂõ†ÁÇ∫ÁçéÂãµÊ®°ÂûãÂè™ÈúÄË¶ÅÈÄèÈÅéÁúüÂØ¶ÁçéÂãµÁöÑÂñÆË™øËΩâÊèõ‰æÜ‰øùÁïôÊ≠£Á¢∫ÁöÑÊéíÂêçÈ†êÊ∏¨„ÄÇÊàëÂÄëÂº∑Ë™ø‰∫ÜÁçéÂãµÂª∫Ê®°‰∏≠Ë®ÇÂñÆ‰∏ÄËá¥ÊÄßÁöÑÈóúÈçµÊ¶ÇÂøµÔºå‰∏¶Ë≠âÊòé‰∫Ü BT Ê®°ÂûãÂÖ∑ÂÇôÊ≠§ÁâπÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰∏îÁõ¥Êé•ÁöÑ‰∏äÁïåÊºîÁÆóÊ≥ïÔºåËàáÁèæÊàêÁöÑ‰∫åÂÖÉÂàÜÈ°ûÂô®Áõ∏ÂÆπÔºå‰ΩúÁÇ∫Êõø‰ª£ÁöÑË®ÇÂñÆ‰∏ÄËá¥ÁçéÂãµÂª∫Ê®°ÁõÆÊ®ô„ÄÇÁÇ∫‰∫ÜÊèê‰æõÂØ¶Áî®ÁöÑË¶ãËß£ÔºåÊàëÂÄëÊ†πÊìö 6 ÂÄãÂü∫Á§é LLM„ÄÅ2 ÂÄãË≥áÊñôÈõÜÂíåÂú®Êï∏Èáè„ÄÅÂìÅË≥™ÂíåÂÅèÂ•ΩË®ªËß£‰∏≠ÁöÑÈÖçÂ∞çÈÅ∏Êìá‰∏äÊúâÊâÄ‰∏çÂêåÁöÑÂ§öÊ®£ÂåñË®ªËß£Ë®≠Ë®àÔºåÂ∞çÈÄô‰∫õ‰∏çÂêåÁöÑÁçéÂãµÂª∫Ê®°ÊñπÊ≥ïÂú®Ë∂ÖÈÅé 12,000 ÂÄãÂØ¶È©óË®≠ÂÆö‰∏≠ÁöÑÊïàËÉΩÈÄ≤Ë°åÁ∂ìÈ©óË©ï‰º∞„ÄÇ

##### **Few-Shot Task Learning through Inverse Generative Modeling**
2411.04987v1 by Aviv Netanyahu, Yilun Du, Antonia Bronars, Jyothish Pari, Joshua Tenenbaum, Tianmin Shu, Pulkit Agrawal

Learning the intents of an agent, defined by its goals or motion style, is
often extremely challenging from just a few examples. We refer to this problem
as task concept learning and present our approach, Few-Shot Task Learning
through Inverse Generative Modeling (FTL-IGM), which learns new task concepts
by leveraging invertible neural generative models. The core idea is to pretrain
a generative model on a set of basic concepts and their demonstrations. Then,
given a few demonstrations of a new concept (such as a new goal or a new
action), our method learns the underlying concepts through backpropagation
without updating the model weights, thanks to the invertibility of the
generative model. We evaluate our method in five domains -- object
rearrangement, goal-oriented navigation, motion caption of human actions,
autonomous driving, and real-world table-top manipulation. Our experimental
results demonstrate that via the pretrained generative model, we successfully
learn novel concepts and generate agent plans or motion corresponding to these
concepts in (1) unseen environments and (2) in composition with training
concepts.

ÊëòË¶ÅÔºöÈÄèÈÅéÂÖ∂ÁõÆÊ®ôÊàñÂãï‰ΩúÈ¢®Ê†ºÂÆöÁæ©ÁöÑ‰ª£ÁêÜÊÑèÂúñÂ≠∏ÁøíÔºåÈÄöÂ∏∏ÂÉÖÂæûÂπæÂÄãÁØÑ‰æã‰∏≠Â≠∏ÁøíÊ•µÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÂ∞áÊ≠§ÂïèÈ°åÁ®±ÁÇ∫‰ªªÂãôÊ¶ÇÂøµÂ≠∏ÁøíÔºå‰∏¶ÊèêÂá∫ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÈÄèÈÅéÂèçÂêëÁîüÊàêÂºèÂª∫Ê®°ÔºàFTL-IGMÔºâÈÄ≤Ë°åÂ∞ëÈáè‰ªªÂãôÂ≠∏ÁøíÔºåÈÄèÈÅéÂà©Áî®ÂèØÈÄÜÁ•ûÁ∂ìÁîüÊàêÂºèÊ®°Âûã‰æÜÂ≠∏ÁøíÊñ∞ÁöÑ‰ªªÂãôÊ¶ÇÂøµ„ÄÇÊ†∏ÂøÉÊ¶ÇÂøµÊòØÂú®‰∏ÄÁµÑÂü∫Êú¨Ê¶ÇÂøµÂèäÂÖ∂Á§∫ÁØÑ‰∏äÈ†êË®ìÁ∑¥ÁîüÊàêÂºèÊ®°Âûã„ÄÇÁÑ∂ÂæåÔºåÁµ¶ÂÆöÊñ∞Ê¶ÇÂøµÁöÑÂπæÂÄãÁ§∫ÁØÑÔºà‰æãÂ¶ÇÊñ∞ÁõÆÊ®ôÊàñÊñ∞Âãï‰ΩúÔºâÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÄèÈÅéÂèçÂêëÂÇ≥Êí≠Â≠∏ÁøíÂü∫Á§éÊ¶ÇÂøµÔºåËÄåÁÑ°ÈúÄÊõ¥Êñ∞Ê®°ÂûãÊ¨äÈáçÔºåÈÄôË¶ÅÊ≠∏ÂäüÊñºÁîüÊàêÂºèÊ®°ÂûãÁöÑÂèØÈÄÜÊÄß„ÄÇÊàëÂÄëÂú®‰∫îÂÄãÈ†òÂüüË©ï‰º∞ÊàëÂÄëÁöÑÊ®°Âûã‚Äî‚ÄîÁâ©È´îÈáçÊñ∞ÊéíÂàó„ÄÅÁõÆÊ®ôÂ∞éÂêëÂ∞éËà™„ÄÅ‰∫∫È°ûÂãï‰ΩúÁöÑÂãï‰ΩúÊ®ôÈ°å„ÄÅËá™ÂãïÈßïÈßõÂíåÁèæÂØ¶‰∏ñÁïåÁöÑÊ°åÈù¢Êìç‰Ωú„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÈÄèÈÅéÈ†êË®ìÁ∑¥ÁöÑÁîüÊàêÂºèÊ®°ÂûãÔºåÊàëÂÄëÊàêÂäüÂ≠∏ÁøíÊñ∞Ê¶ÇÂøµ‰∏¶Áî¢ÁîüËàáÈÄô‰∫õÊ¶ÇÂøµÁõ∏ÊáâÁöÑ‰ª£ÁêÜË®àÁï´ÊàñÂãï‰ΩúÔºåÂú®Ôºà1ÔºâÊú™Ë¶ãÈÅéÁöÑÁí∞Â¢É‰∏≠Ôºå‰ª•ÂèäÔºà2ÔºâËàáË®ìÁ∑¥Ê¶ÇÂøµÁöÑÁµÑÂêà‰∏≠„ÄÇ

##### **The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities**
2411.04986v1 by Zhaofeng Wu, Xinyan Velocity Yu, Dani Yogatama, Jiasen Lu, Yoon Kim

Modern language models can process inputs across diverse languages and
modalities. We hypothesize that models acquire this capability through learning
a shared representation space across heterogeneous data types (e.g., different
languages and modalities), which places semantically similar inputs near one
another, even if they are from different modalities/languages. We term this the
semantic hub hypothesis, following the hub-and-spoke model from neuroscience
(Patterson et al., 2007) which posits that semantic knowledge in the human
brain is organized through a transmodal semantic "hub" which integrates
information from various modality-specific "spokes" regions. We first show that
model representations for semantically equivalent inputs in different languages
are similar in the intermediate layers, and that this space can be interpreted
using the model's dominant pretraining language via the logit lens. This
tendency extends to other data types, including arithmetic expressions, code,
and visual/audio inputs. Interventions in the shared representation space in
one data type also predictably affect model outputs in other data types,
suggesting that this shared representations space is not simply a vestigial
byproduct of large-scale training on broad data, but something that is actively
utilized by the model during input processing.

ÊëòË¶ÅÔºöÁèæ‰ª£Ë™ûË®ÄÊ®°ÂûãÂèØ‰ª•ËôïÁêÜË∑®Ë∂ä‰∏çÂêåË™ûË®ÄÂíåÊ®°ÂºèÁöÑËº∏ÂÖ•„ÄÇÊàëÂÄëÂÅáË®≠Ê®°ÂûãÈÄèÈÅéÂ≠∏ÁøíË∑®Ë∂äÁï∞Ë≥™Ë≥áÊñôÈ°ûÂûãÔºà‰æãÂ¶ÇÔºå‰∏çÂêåÁöÑË™ûË®ÄÂíåÊ®°ÂºèÔºâÁöÑÂÖ±‰∫´Ë°®Á§∫Á©∫Èñì‰æÜÁç≤ÂæóÊ≠§ËÉΩÂäõÔºåÈÄôÂÄãÁ©∫ÈñìÂ∞áË™ûÁæ©‰∏äÁõ∏‰ººÁöÑËº∏ÂÖ•ÊîæÁΩÆÂú®ÂΩºÊ≠§ÈôÑËøëÔºåÂç≥‰ΩøÂÆÉÂÄë‰æÜËá™‰∏çÂêåÁöÑÊ®°Âºè/Ë™ûË®Ä„ÄÇÊàëÂÄëÁ®±‰πãÁÇ∫Ë™ûÁæ©‰∏≠ÂøÉÂÅáË®≠ÔºåÈÅµÂæ™Á•ûÁ∂ìÁßëÂ≠∏‰∏≠ÁöÑÊ®ûÁ¥êËºªÂ∞ÑÊ®°ÂûãÔºàPatterson Á≠â‰∫∫Ôºå2007 Âπ¥ÔºâÔºåË©≤Ê®°ÂûãÂÅáË®≠‰∫∫È°ûÂ§ßËÖ¶‰∏≠ÁöÑË™ûÁæ©Áü•Ë≠òÊòØÈÄèÈÅéË∑®Ê®°ÂºèË™ûÁæ©„ÄåÊ®ûÁ¥ê„ÄçÁµÑÁπîÁöÑÔºåÂÆÉÊï¥Âêà‰æÜËá™ÂêÑÁ®ÆÁâπÂÆöÊ®°Âºè„ÄåËºªÊ¢ù„ÄçÂçÄÂüüÁöÑË≥áË®ä„ÄÇÊàëÂÄëÈ¶ñÂÖàÂ±ïÁ§∫‰∏çÂêåË™ûË®Ä‰∏≠Ë™ûÁæ©Á≠âÊïàËº∏ÂÖ•ÁöÑÊ®°ÂûãË°®Á§∫Âú®‰∏≠ÈñìÂ±§‰∏≠ÊòØÁõ∏‰ººÁöÑÔºå‰∏¶‰∏îÈÄôÂÄãÁ©∫ÈñìÂèØ‰ª•‰ΩøÁî®Ê®°ÂûãÁöÑ‰∏ªÂ∞éÈ†êË®ìÁ∑¥Ë™ûË®ÄÈÄèÈÅé logit ÈÄèÈè°‰æÜË©ÆÈáã„ÄÇÈÄôÁ®ÆË∂®Âã¢Âª∂‰º∏Âà∞ÂÖ∂‰ªñË≥áÊñôÈ°ûÂûãÔºåÂåÖÊã¨ÁÆóË°ìË°®ÈÅîÂºè„ÄÅÁ®ãÂºèÁ¢º‰ª•ÂèäË¶ñË¶∫/Èü≥Ë®äËº∏ÂÖ•„ÄÇÂÖ±‰∫´Ë°®Á§∫Á©∫Èñì‰∏≠ÁöÑ‰∏ÄÁ®ÆË≥áÊñôÈ°ûÂûãÁöÑ‰ªãÂÖ•‰πüÊúÉÂèØÈ†êÊ∏¨Âú∞ÂΩ±ÈüøÂÖ∂‰ªñË≥áÊñôÈ°ûÂûã‰∏≠ÁöÑÊ®°ÂûãËº∏Âá∫ÔºåÈÄôË°®ÊòéÈÄôÂÄãÂÖ±‰∫´Ë°®Á§∫Á©∫Èñì‰∏çÂÉÖÂÉÖÊòØÂ§ßË¶èÊ®°Ë®ìÁ∑¥Âª£Ê≥õË≥áÊñôÁöÑÊÆòÈ§òÂâØÁî¢ÂìÅÔºåËÄå‰∏îÊòØÊ®°ÂûãÂú®Ëº∏ÂÖ•ËôïÁêÜÊúüÈñìÁ©çÊ•µÂà©Áî®ÁöÑÊù±Ë•ø„ÄÇ

