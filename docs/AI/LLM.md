
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-28**|**Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs**|Sukmin Yun et.al.|[2406.20098v1](http://arxiv.org/abs/2406.20098v1)|[link](https://github.com/mbzuai-llm/web2code)|
|**2024-06-28**|**LLaRA: Supercharging Robot Learning Data for Vision-Language Policy**|Xiang Li et.al.|[2406.20095v1](http://arxiv.org/abs/2406.20095v1)|[link](https://github.com/lostxine/llara)|
|**2024-06-28**|**Scaling Synthetic Data Creation with 1,000,000,000 Personas**|Xin Chan et.al.|[2406.20094v1](http://arxiv.org/abs/2406.20094v1)|null|
|**2024-06-28**|**ProgressGym: Alignment with a Millennium of Moral Progress**|Tianyi Qiu et.al.|[2406.20087v1](http://arxiv.org/abs/2406.20087v1)|null|
|**2024-06-28**|**Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs**|Sheridan Feucht et.al.|[2406.20086v1](http://arxiv.org/abs/2406.20086v1)|null|
|**2024-06-28**|**AI for Extreme Event Modeling and Understanding: Methodologies and Challenges**|Gustau Camps-Valls et.al.|[2406.20080v1](http://arxiv.org/abs/2406.20080v1)|null|
|**2024-06-28**|**Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification**|Anisha Gunjal et.al.|[2406.20079v1](http://arxiv.org/abs/2406.20079v1)|[link](https://github.com/anisha2102/molecular_facts)|
|**2024-06-28**|**Applying RLAIF for Code Generation with API-usage in Lightweight LLMs**|Sujan Dutta et.al.|[2406.20060v1](http://arxiv.org/abs/2406.20060v1)|null|
|**2024-06-28**|**To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models**|Bastien Liétard et.al.|[2406.20054v1](http://arxiv.org/abs/2406.20054v1)|null|
|**2024-06-28**|**Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation**|Danny Halawi et.al.|[2406.20053v1](http://arxiv.org/abs/2406.20053v1)|null|
|**2024-06-28**|**Understanding and Mitigating Language Confusion in LLMs**|Kelly Marchisio et.al.|[2406.20052v1](http://arxiv.org/abs/2406.20052v1)|null|
|**2024-06-28**|**Electrostatics-based particle sampling and approximate inference**|Yongchao Huang et.al.|[2406.20044v1](http://arxiv.org/abs/2406.20044v1)|[link](https://github.com/yongchaohuang/eparvi)|
|**2024-06-28**|**BMW Agents -- A Framework For Task Automation Through Multi-agent Collaboration**|Noel Crawford et.al.|[2406.20041v1](http://arxiv.org/abs/2406.20041v1)|null|
|**2024-06-28**|**BioMNER: A Dataset for Biomedical Method Entity Recognition**|Chen Tang et.al.|[2406.20038v1](http://arxiv.org/abs/2406.20038v1)|null|
|**2024-06-28**|**LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models**|Renzhi Wang et.al.|[2406.20030v1](http://arxiv.org/abs/2406.20030v1)|null|
|**2024-06-28**|**ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models**|Yuxiang Zhang et.al.|[2406.20015v1](http://arxiv.org/abs/2406.20015v1)|[link](https://github.com/toolbehonest/toolbehonest)|
|**2024-06-28**|**The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models**|Xinyi Chen et.al.|[2406.19999v1](http://arxiv.org/abs/2406.19999v1)|null|
|**2024-06-28**|**Wavelets Are All You Need for Autoregressive Image Generation**|Wael Mattar et.al.|[2406.19997v1](http://arxiv.org/abs/2406.19997v1)|null|
|**2024-06-28**|**Single Parent Family: A Spectrum of Family Members from a Single Pre-Trained Foundation Model**|Habib Hajimolahoseini et.al.|[2406.19995v1](http://arxiv.org/abs/2406.19995v1)|null|
|**2024-06-28**|**Into the Unknown: Generating Geospatial Descriptions for New Environments**|Tzuf Paz-Argaman et.al.|[2406.19967v1](http://arxiv.org/abs/2406.19967v1)|null|
|**2024-06-28**|**Simulating Financial Market via Large Language Model based Agents**|Shen Gao et.al.|[2406.19966v1](http://arxiv.org/abs/2406.19966v1)|null|
|**2024-06-28**|**Text2Robot: Evolutionary Robot Design from Text Descriptions**|Ryan P. Ringel et.al.|[2406.19963v1](http://arxiv.org/abs/2406.19963v1)|null|
|**2024-06-28**|**BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5**|Zhehuai Chen et.al.|[2406.19954v1](http://arxiv.org/abs/2406.19954v1)|null|
|**2024-06-28**|**Uncovering the hidden core-periphery structure in hyperbolic networks**|Imran Ansari et.al.|[2406.19953v1](http://arxiv.org/abs/2406.19953v1)|[link](https://github.com/imran10896/cp_structure_in_hyperbolic_networks)|
|**2024-06-28**|**Mining Reasons For And Against Vaccination From Unstructured Data Using Nichesourcing and AI Data Augmentation**|Damián Ariel Furman et.al.|[2406.19951v1](http://arxiv.org/abs/2406.19951v1)|null|
|**2024-06-28**|**Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring**|Jiazheng Li et.al.|[2406.19949v1](http://arxiv.org/abs/2406.19949v1)|null|
|**2024-06-28**|**From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis**|Chuanqi Cheng et.al.|[2406.19934v1](http://arxiv.org/abs/2406.19934v1)|null|
|**2024-06-28**|**Decoupling General and Personalized Knowledge in Federated Learning via Additive and Low-Rank Decomposition**|Xinghao Wu et.al.|[2406.19931v1](http://arxiv.org/abs/2406.19931v1)|null|
|**2024-06-28**|**Interactive Topic Models with Optimal Transport**|Garima Dhanania et.al.|[2406.19928v1](http://arxiv.org/abs/2406.19928v1)|null|
|**2024-06-28**|**Paraphrase Types Elicit Prompt Engineering Capabilities**|Jan Philip Wahle et.al.|[2406.19898v1](http://arxiv.org/abs/2406.19898v1)|null|
|**2024-06-28**|**AuthAttLyzer-V2: Unveiling Code Authorship Attribution using Enhanced Ensemble Learning Models & Generating Benchmark Dataset**|Bhaskar Joshi et.al.|[2406.19896v1](http://arxiv.org/abs/2406.19896v1)|null|
|**2024-06-28**|**Untangling the Unrestricted Web: Automatic Identification of Multilingual Registers**|Erik Henriksson et.al.|[2406.19892v1](http://arxiv.org/abs/2406.19892v1)|null|
|**2024-06-28**|**Fine-tuning of Geospatial Foundation Models for Aboveground Biomass Estimation**|Michal Muszynski et.al.|[2406.19888v1](http://arxiv.org/abs/2406.19888v1)|null|
|**2024-06-28**|**Investigating the Timescales of Language Processing with EEG and Language Models**|Davide Turco et.al.|[2406.19884v1](http://arxiv.org/abs/2406.19884v1)|null|
|**2024-06-28**|**Detecting Subtle Differences between Human and Model Languages Using Spectrum of Relative Likelihood**|Yang Xu et.al.|[2406.19874v1](http://arxiv.org/abs/2406.19874v1)|[link](https://github.com/clcs-sustech/fouriergpt)|
|**2024-06-28**|**MetaDesigner: Advancing Artistic Typography through AI-Driven, User-Centric, and Multilingual WordArt Synthesis**|Jun-Yan He et.al.|[2406.19859v1](http://arxiv.org/abs/2406.19859v1)|null|
|**2024-06-28**|**YuLan: An Open-source Large Language Model**|Yutao Zhu et.al.|[2406.19853v1](http://arxiv.org/abs/2406.19853v1)|[link](https://github.com/ruc-gsai/yulan-chat)|
|**2024-06-28**|**AnomaLLMy -- Detecting anomalous tokens in black-box LLMs through low-confidence single-token predictions**|Waligóra Witold et.al.|[2406.19840v1](http://arxiv.org/abs/2406.19840v1)|null|
|**2024-06-28**|**BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering**|Zheng Chu et.al.|[2406.19820v1](http://arxiv.org/abs/2406.19820v1)|null|
|**2024-06-28**|**Deceptive Diffusion: Generating Synthetic Adversarial Examples**|Lucas Beerens et.al.|[2406.19807v1](http://arxiv.org/abs/2406.19807v1)|null|
|**2024-06-28**|**Scalable and Domain-General Abstractive Proposition Segmentation**|Mohammad Javad Hosseini et.al.|[2406.19803v1](http://arxiv.org/abs/2406.19803v1)|null|
|**2024-06-28**|**NLPerturbator: Studying the Robustness of Code LLMs to Natural Language Variations**|Junkai Chen et.al.|[2406.19783v1](http://arxiv.org/abs/2406.19783v1)|null|
|**2024-06-28**|**Direct Preference Knowledge Distillation for Large Language Models**|Yixing Li et.al.|[2406.19774v1](http://arxiv.org/abs/2406.19774v1)|null|
|**2024-06-28**|**Self-Supervised Spatial-Temporal Normality Learning for Time Series Anomaly Detection**|Yutong Chen et.al.|[2406.19770v1](http://arxiv.org/abs/2406.19770v1)|null|
|**2024-06-28**|**Belief Revision: The Adaptability of Large Language Models Reasoning**|Bryan Wilie et.al.|[2406.19764v1](http://arxiv.org/abs/2406.19764v1)|null|
|**2024-06-28**|**xSemAD: Explainable Semantic Anomaly Detection in Event Logs Using Sequence-to-Sequence Models**|Kiran Busch et.al.|[2406.19763v1](http://arxiv.org/abs/2406.19763v1)|null|
|**2024-06-28**|**Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation**|Chenlong Deng et.al.|[2406.19760v1](http://arxiv.org/abs/2406.19760v1)|null|
|**2024-06-28**|**Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment**|Orgest Xhelili et.al.|[2406.19759v1](http://arxiv.org/abs/2406.19759v1)|null|
|**2024-06-28**|**Structure-aware World Model for Probe Guidance via Large-scale Self-supervised Pre-train**|Haojun Jiang et.al.|[2406.19756v1](http://arxiv.org/abs/2406.19756v1)|null|
|**2024-06-28**|**Protein Representation Learning with Sequence Information Embedding: Does it Always Lead to a Better Performance?**|Yang Tan et.al.|[2406.19755v1](http://arxiv.org/abs/2406.19755v1)|null|
|**2024-06-28**|**ROS-LLM: A ROS framework for embodied AI with task feedback and structured reasoning**|Christopher E. Mower et.al.|[2406.19741v1](http://arxiv.org/abs/2406.19741v1)|[link](https://github.com/huawei-noah/hebo)|
|**2024-06-28**|**MM-Instruct: Generated Visual Instructions for Large Multimodal Model Alignment**|Jihao Liu et.al.|[2406.19736v1](http://arxiv.org/abs/2406.19736v1)|[link](https://github.com/jihaonew/mm-instruct)|
|**2024-06-28**|**CUPID: Improving Battle Fairness and Position Satisfaction in Online MOBA Games with a Re-matchmaking System**|Ge Fan et.al.|[2406.19720v1](http://arxiv.org/abs/2406.19720v1)|null|
|**2024-06-28**|**Uncertainty Quantification in Large Language Models Through Convex Hull Analysis**|Ferhat Ozgur Catak et.al.|[2406.19712v1](http://arxiv.org/abs/2406.19712v1)|null|
|**2024-06-28**|**A Differentiable Approach to Multi-scale Brain Modeling**|Chaoming Wang et.al.|[2406.19708v1](http://arxiv.org/abs/2406.19708v1)|[link](https://github.com/chaoming0625/differentiable-brain-modeling-workflow)|
|**2024-06-28**|**DISCO: Efficient Diffusion Solver for Large-Scale Combinatorial Optimization Problems**|Kexiong Yu et.al.|[2406.19705v1](http://arxiv.org/abs/2406.19705v1)|null|
|**2024-06-28**|**Deep Fusion Model for Brain Tumor Classification Using Fine-Grained Gradient Preservation**|Niful Islam et.al.|[2406.19690v1](http://arxiv.org/abs/2406.19690v1)|null|
|**2024-06-28**|**Enhancing Radiological Diagnosis: A Collaborative Approach Integrating AI and Human Expertise for Visual Miss Correction**|Akash Awasthi et.al.|[2406.19686v1](http://arxiv.org/abs/2406.19686v1)|null|
|**2024-06-28**|**Less is More: Accurate Speech Recognition & Translation without Web-Scale Data**|Krishna C. Puvvada et.al.|[2406.19674v1](http://arxiv.org/abs/2406.19674v1)|null|
|**2024-06-28**|**Function+Data Flow: A Framework to Specify Machine Learning Pipelines for Digital Twinning**|Eduardo de Conto et.al.|[2406.19670v1](http://arxiv.org/abs/2406.19670v1)|null|
|**2024-06-28**|**ACES: Automatic Cohort Extraction System for Event-Stream Datasets**|Justin Xu et.al.|[2406.19653v1](http://arxiv.org/abs/2406.19653v1)|[link](https://github.com/justin13601/aces)|
|**2024-06-28**|**CANDY: A Benchmark for Continuous Approximate Nearest Neighbor Search with Dynamic Data Ingestion**|Xianzhi Zeng et.al.|[2406.19651v1](http://arxiv.org/abs/2406.19651v1)|[link](https://github.com/intellistream/candy)|
|**2024-06-28**|**DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting**|Xuanming Zhang et.al.|[2406.19650v1](http://arxiv.org/abs/2406.19650v1)|null|
|**2024-06-28**|**Designing and Evaluating Multi-Chatbot Interface for Human-AI Communication: Preliminary Findings from a Persuasion Task**|Sion Yoon et.al.|[2406.19648v1](http://arxiv.org/abs/2406.19648v1)|null|
|**2024-06-28**|**Beyond Human Preferences: Exploring Reinforcement Learning Trajectory Evaluation and Improvement through LLMs**|Zichao Shen et.al.|[2406.19644v1](http://arxiv.org/abs/2406.19644v1)|null|
|**2024-06-28**|**Unlocking Varied Perspectives: A Persona-Based Multi-Agent Framework with Debate-Driven Text Planning for Argument Generation**|Zhe Hu et.al.|[2406.19643v1](http://arxiv.org/abs/2406.19643v1)|null|
|**2024-06-28**|**IDT: Dual-Task Adversarial Attacks for Privacy Protection**|Pedro Faustini et.al.|[2406.19642v1](http://arxiv.org/abs/2406.19642v1)|null|
|**2024-06-28**|**Precision matters: Precision-aware ensemble for weakly supervised semantic segmentation**|Junsung Park et.al.|[2406.19638v1](http://arxiv.org/abs/2406.19638v1)|[link](https://github.com/engineerJPark/ORANDNet)|
|**2024-06-28**|**Optimal Video Compression using Pixel Shift Tracking**|Hitesh Saai Mananchery Panneerselvam et.al.|[2406.19630v1](http://arxiv.org/abs/2406.19630v1)|null|
|**2024-06-28**|**Data-Driven Lipschitz Continuity: A Cost-Effective Approach to Improve Adversarial Robustness**|Erh-Chung Chen et.al.|[2406.19622v1](http://arxiv.org/abs/2406.19622v1)|null|
|**2024-06-28**|**A Survey on Data Quality Dimensions and Tools for Machine Learning**|Yuhan Zhou et.al.|[2406.19614v1](http://arxiv.org/abs/2406.19614v1)|null|
|**2024-06-28**|**Multimodal Data Integration for Precision Oncology: Challenges and Future Directions**|Huajun Zhou et.al.|[2406.19611v1](http://arxiv.org/abs/2406.19611v1)|null|
|**2024-06-28**|**Mixture of In-Context Experts Enhance LLMs' Long Context Awareness**|Hongzhan Lin et.al.|[2406.19598v1](http://arxiv.org/abs/2406.19598v1)|null|
|**2024-06-28**|**Optimizing Cyber Defense in Dynamic Active Directories through Reinforcement Learning**|Diksha Goel et.al.|[2406.19596v1](http://arxiv.org/abs/2406.19596v1)|null|
|**2024-06-28**|**SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs**|Xin Su et.al.|[2406.19593v1](http://arxiv.org/abs/2406.19593v1)|null|
|**2024-06-27**|**PathAlign: A vision-language model for whole slide images in histopathology**|Faruk Ahmed et.al.|[2406.19578v1](http://arxiv.org/abs/2406.19578v1)|null|
|**2024-06-27**|**Synthetic Cancer -- Augmenting Worms with LLMs**|Benjamin Zimmerman et.al.|[2406.19570v1](http://arxiv.org/abs/2406.19570v1)|null|
|**2024-06-27**|**What Matters in Detecting AI-Generated Videos like Sora?**|Chirui Chang et.al.|[2406.19568v1](http://arxiv.org/abs/2406.19568v1)|null|
|**2024-06-27**|**Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects**|Orevaoghene Ahia et.al.|[2406.19564v1](http://arxiv.org/abs/2406.19564v1)|null|
|**2024-06-27**|**Meta-Gradient Search Control: A Method for Improving the Efficiency of Dyna-style Planning**|Bradley Burega et.al.|[2406.19561v1](http://arxiv.org/abs/2406.19561v1)|null|
|**2024-06-27**|**Rethinking harmless refusals when fine-tuning foundation models**|Florin Pop et.al.|[2406.19552v1](http://arxiv.org/abs/2406.19552v1)|null|
|**2024-06-27**|**Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations**|Ritam Dutt et.al.|[2406.19545v1](http://arxiv.org/abs/2406.19545v1)|null|
|**2024-06-27**|**Context Matters: An Empirical Study of the Impact of Contextual Information in Temporal Question Answering Systems**|Dan Schumacher et.al.|[2406.19538v1](http://arxiv.org/abs/2406.19538v1)|null|
|**2024-06-27**|**Handling Ontology Gaps in Semantic Parsing**|Andrea Bacciu et.al.|[2406.19537v1](http://arxiv.org/abs/2406.19537v1)|[link](https://github.com/amazon-science/handling-ontology-gaps-in-semantic-parsing)|
|**2024-06-27**|**Using Large Language Models to Assist Video Content Analysis: An Exploratory Study of Short Videos on Depression**|Jiaying Liu et.al.|[2406.19528v1](http://arxiv.org/abs/2406.19528v1)|null|
|**2024-06-27**|**TocBERT: Medical Document Structure Extraction Using Bidirectional Transformers**|Majd Saleh et.al.|[2406.19526v1](http://arxiv.org/abs/2406.19526v1)|null|
|**2024-06-27**|**Captioning Visualizations with Large Language Models (CVLLM): A Tutorial**|Giuseppe Carenini et.al.|[2406.19512v1](http://arxiv.org/abs/2406.19512v1)|null|
|**2024-06-27**|**Too Good to be True? Turn Any Model Differentially Private With DP-Weights**|David Zagardo et.al.|[2406.19507v1](http://arxiv.org/abs/2406.19507v1)|[link](https://github.com/dzagardo/forgetnet)|
|**2024-06-27**|**Are Generative Language Models Multicultural? A Study on Hausa Culture and Emotions using ChatGPT**|Ibrahim Said Ahmad et.al.|[2406.19504v1](http://arxiv.org/abs/2406.19504v1)|null|
|**2024-06-27**|**Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**|Miyoung Ko et.al.|[2406.19502v1](http://arxiv.org/abs/2406.19502v1)|[link](https://github.com/kaistai/knowledge-reasoning)|
|**2024-06-27**|**Monitoring Latent World States in Language Models with Propositional Probes**|Jiahai Feng et.al.|[2406.19501v1](http://arxiv.org/abs/2406.19501v1)|null|
|**2024-06-27**|**Knowledge acquisition for dialogue agents using reinforcement learning on graph representations**|Selene Baez Santamaria et.al.|[2406.19500v1](http://arxiv.org/abs/2406.19500v1)|null|
|**2024-06-27**|**Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts**|Naseela Pervez et.al.|[2406.19497v1](http://arxiv.org/abs/2406.19497v1)|null|
|**2024-06-27**|**Development and Evaluation of a Retrieval-Augmented Generation Tool for Creating SAPPhIRE Models of Artificial Systems**|Anubhab Majumder et.al.|[2406.19493v1](http://arxiv.org/abs/2406.19493v1)|null|
|**2024-06-27**|**LoPT: Low-Rank Prompt Tuning for Parameter Efficient Language Models**|Shouchang Guo et.al.|[2406.19486v1](http://arxiv.org/abs/2406.19486v1)|null|
|**2024-06-27**|**xTower: A Multilingual LLM for Explaining and Correcting Translation Errors**|Marcos Treviso et.al.|[2406.19482v1](http://arxiv.org/abs/2406.19482v1)|null|
|**2024-06-27**|**Sparse Regression for Machine Translation**|Ergun Biçici et.al.|[2406.19478v1](http://arxiv.org/abs/2406.19478v1)|null|
|**2024-06-27**|**Changing Answer Order Can Decrease MMLU Accuracy**|Vipul Gupta et.al.|[2406.19470v1](http://arxiv.org/abs/2406.19470v1)|null|
|**2024-06-27**|**Can Large Language Models Generate High-quality Patent Claims?**|Lekang Jiang et.al.|[2406.19465v1](http://arxiv.org/abs/2406.19465v1)|null|
|**2024-06-27**|**Taming Data and Transformers for Audio Generation**|Moayed Haji-Ali et.al.|[2406.19388v1](http://arxiv.org/abs/2406.19388v1)|null|

#### Abstracts
##### **Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs**
2406.20098v1 by Sukmin Yun, Haokun Lin, Rusiru Thushara, Mohammad Qazim Bhat, Yongxin Wang, Zutao Jiang, Mingkai Deng, Jinhong Wang, Tianhua Tao, Junbo Li, Haonan Li, Preslav Nakov, Timothy Baldwin, Zhengzhong Liu, Eric P. Xing, Xiaodan Liang, Zhiqiang Shen

Multimodal large language models (MLLMs) have shown impressive success across
modalities such as image, video, and audio in a variety of understanding and
generation tasks. However, current MLLMs are surprisingly poor at understanding
webpage screenshots and generating their corresponding HTML code. To address
this problem, we propose Web2Code, a benchmark consisting of a new large-scale
webpage-to-code dataset for instruction tuning and an evaluation framework for
the webpage understanding and HTML code translation abilities of MLLMs. For
dataset construction, we leverage pretrained LLMs to enhance existing
webpage-to-code datasets as well as generate a diverse pool of new webpages
rendered into images. Specifically, the inputs are webpage images and
instructions, while the responses are the webpage's HTML code. We further
include diverse natural language QA pairs about the webpage content in the
responses to enable a more comprehensive understanding of the web content. To
evaluate model performance in these tasks, we develop an evaluation framework
for testing MLLMs' abilities in webpage understanding and web-to-code
generation. Extensive experiments show that our proposed dataset is beneficial
not only to our proposed tasks but also in the general visual domain, while
previous datasets result in worse performance. We hope our work will contribute
to the development of general MLLMs suitable for web-based content generation
and task automation. Our data and code will be available at
https://github.com/MBZUAI-LLM/web2code.

摘要：多模态大型语言模型 (MLLM) 已在图像、视频和音频等模态中显示出令人印象深刻的成功，涉及各种理解和生成任务。然而，当前的 MLLM 在理解网页截图和生成其对应的 HTML 代码方面却出乎意料地差。为了解决这个问题，我们提出了 Web2Code，这是一个基准，它包含一个用于指令微调的新的大规模网页到代码数据集，以及一个用于评估 MLLM 的网页理解和 HTML 代码翻译能力的评估框架。对于数据集构建，我们利用预训练的 LLM 来增强现有的网页到代码数据集，并生成一组多样化的新网页，将其渲染成图像。具体来说，输入是网页图像和指令，而响应是网页的 HTML 代码。我们进一步在响应中包含了关于网页内容的各种自然语言问答对，以实现对网络内容的更全面理解。为了评估模型在这些任务中的性能，我们开发了一个评估框架，用于测试 MLLM 在网页理解和网络到代码生成方面的能力。大量的实验表明，我们提出的数据集不仅对我们提出的任务有益，而且对通用视觉领域也有益，而以前的数据集会导致更差的性能。我们希望我们的工作将有助于开发适用于基于 Web 的内容生成和任务自动化的通用 MLLM。我们的数据和代码将在 https://github.com/MBZUAI-LLM/web2code 上提供。

##### **LLaRA: Supercharging Robot Learning Data for Vision-Language Policy**
2406.20095v1 by Xiang Li, Cristina Mata, Jongwoo Park, Kumara Kahatapitiya, Yoo Sung Jang, Jinghuan Shang, Kanchana Ranasinghe, Ryan Burgert, Mu Cai, Yong Jae Lee, Michael S. Ryoo

Large Language Models (LLMs) equipped with extensive world knowledge and
strong reasoning skills can tackle diverse tasks across domains, often by
posing them as conversation-style instruction-response pairs. In this paper, we
propose LLaRA: Large Language and Robotics Assistant, a framework which
formulates robot action policy as conversations, and provides improved
responses when trained with auxiliary data that complements policy learning.
LLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity
to process state information as visual-textual prompts and generate optimal
policy decisions in text. To train such action policy VLMs, we first introduce
an automated pipeline to generate diverse high-quality robotics instruction
data from existing behavior cloning data. A VLM finetuned with the resulting
collection of datasets based on a conversation-style formulation tailored for
robotics tasks, can generate meaningful robot action policy decisions. Our
experiments across multiple simulated and real-world environments demonstrate
the state-of-the-art performance of the proposed LLaRA framework. The code,
datasets, and pretrained models are available at
https://github.com/LostXine/LLaRA.

摘要：大型語言模型 (LLM) 具備廣泛的世界知識和強大的推理能力，可處理跨領域的不同任務，通常透過將它們設定為對話式指令回應對話來處理。在本文中，我們提出 LLaRA：大型語言和機器人助理，一個將機器人動作策略制定為對話的框架，並在使用補充策略學習的輔助資料進行訓練時提供改進的回應。具有視覺輸入的 LLM，即視覺語言模型 (VLM)，有能力將狀態資訊處理為視覺文字提示，並以文字產生最佳策略決策。為了訓練此類動作策略 VLM，我們首先引入一個自動化管道，從現有的行為複製資料中產生多樣化的高品質機器人指令資料。針對機器人任務量身打造的對話式制定方式，使用由此產生的資料集集合微調的 VLM，可以產生有意義的機器人動作策略決策。我們在多個模擬和真實世界環境中進行的實驗證明了所提出的 LLaRA 框架的最新技術效能。程式碼、資料集和預訓練模型可在 https://github.com/LostXine/LLaRA 取得。

##### **Scaling Synthetic Data Creation with 1,000,000,000 Personas**
2406.20094v1 by Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, Dong Yu

We propose a novel persona-driven data synthesis methodology that leverages
various perspectives within a large language model (LLM) to create diverse
synthetic data. To fully exploit this methodology at scale, we introduce
Persona Hub -- a collection of 1 billion diverse personas automatically curated
from web data. These 1 billion personas (~13% of the world's total population),
acting as distributed carriers of world knowledge, can tap into almost every
perspective encapsulated within the LLM, thereby facilitating the creation of
diverse synthetic data at scale for various scenarios. By showcasing Persona
Hub's use cases in synthesizing high-quality mathematical and logical reasoning
problems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs
and tools (functions) at scale, we demonstrate persona-driven data synthesis is
versatile, scalable, flexible, and easy to use, potentially driving a paradigm
shift in synthetic data creation and applications in practice, which may have a
profound impact on LLM research and development.

摘要：我們提出了一種新穎的人格驅動資料合成方法，它利用大型語言模型 (LLM) 中的各種觀點來建立多元的合成資料。為了大規模充分利用這種方法，我們引入了 Persona Hub，這是從網路資料自動整理出的 10 億個多元人格的集合。這 10 億個角色（約佔世界總人口的 13%），作為世界知識的分散載體，可以深入了解 LLM 中包含的幾乎每個觀點，從而促進大規模建立多元的合成資料，以應對各種場景。透過展示 Persona Hub 在大規模合成高品質的數學和邏輯推理問題、指令（即使用者提示）、知識豐富的文字、遊戲 NPC 和工具（函式）方面的使用案例，我們證明了人格驅動資料合成具有多功能性、可擴充性、靈活性且易於使用，潛在地推動合成資料建立和應用實務中的典範轉移，這可能對 LLM 研究和開發產生深遠的影響。

##### **ProgressGym: Alignment with a Millennium of Moral Progress**
2406.20087v1 by Tianyi Qiu, Yang Zhang, Xuchuan Huang, Jasmine Xinze Li, Jiaming Ji, Yaodong Yang

Frontier AI systems, including large language models (LLMs), hold increasing
influence over the epistemology of human users. Such influence can reinforce
prevailing societal values, potentially contributing to the lock-in of
misguided moral beliefs and, consequently, the perpetuation of problematic
moral practices on a broad scale. We introduce progress alignment as a
technical solution to mitigate this imminent risk. Progress alignment
algorithms learn to emulate the mechanics of human moral progress, thereby
addressing the susceptibility of existing alignment methods to contemporary
moral blindspots. To empower research in progress alignment, we introduce
ProgressGym, an experimental framework allowing the learning of moral progress
mechanics from history, in order to facilitate future progress in real-world
moral decisions. Leveraging 9 centuries of historical text and 18 historical
LLMs, ProgressGym enables codification of real-world progress alignment
challenges into concrete benchmarks. Specifically, we introduce three core
challenges: tracking evolving values (PG-Follow), preemptively anticipating
moral progress (PG-Predict), and regulating the feedback loop between human and
AI value shifts (PG-Coevolve). Alignment methods without a temporal dimension
are inapplicable to these tasks. In response, we present lifelong and
extrapolative algorithms as baseline methods of progress alignment, and build
an open leaderboard soliciting novel algorithms and challenges. The framework
and the leaderboard are available at
https://github.com/PKU-Alignment/ProgressGym and
https://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard
respectively.

摘要：前沿人工智能系统，包括大型语言模型 (LLM)，对人类用户的认识论影响越来越大。这种影响可以强化现有的社会价值观，可能导致错误的道德信念固化，进而导致有问题的道德实践在大范围内持续存在。我们引入进度对齐作为一种技术解决方案来减轻这种迫在眉睫的风险。进度对齐算法学会模拟人类道德进步的机制，从而解决现有对齐方法对当代道德盲点的敏感性。为了赋能进度对齐的研究，我们引入了 ProgressGym，这是一个实验框架，允许从历史中学习道德进步机制，以便促进现实世界道德决策的未来进步。利用 9 个世纪的历史文本和 18 个历史 LLM，ProgressGym 能够将现实世界的进度对齐挑战编纂成具体的基准。具体来说，我们提出了三个核心挑战：跟踪不断变化的价值观 (PG-Follow)、预先预测道德进步 (PG-Predict) 以及调节人类和人工智能价值观转变之间的反馈回路 (PG-Coevolve)。没有时间维度的对齐方法不适用于这些任务。作为回应，我们提出了终身和外推算法作为进度对齐的基线方法，并建立了一个开放排行榜，征集新算法和挑战。该框架和排行榜分别可在 https://github.com/PKU-Alignment/ProgressGym 和 https://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard 获得。

##### **Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs**
2406.20086v1 by Sheridan Feucht, David Atkinson, Byron Wallace, David Bau

LLMs process text as sequences of tokens that roughly correspond to words,
where less common words are represented by multiple tokens. However, individual
tokens are often semantically unrelated to the meanings of the words/concepts
they comprise. For example, Llama-2-7b's tokenizer splits the word
"northeastern" into the tokens ['_n', 'ort', 'he', 'astern'], none of which
correspond to semantically meaningful units like "north" or "east." Similarly,
the overall meanings of named entities like "Neil Young" and multi-word
expressions like "break a leg" cannot be directly inferred from their
constituent tokens. Mechanistically, how do LLMs convert such arbitrary groups
of tokens into useful higher-level representations? In this work, we find that
last token representations of named entities and multi-token words exhibit a
pronounced "erasure" effect, where information about previous and current
tokens is rapidly forgotten in early layers. Using this observation, we propose
a method to "read out" the implicit vocabulary of an autoregressive LLM by
examining differences in token representations across layers, and present
results of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is
the first attempt to probe the implicit vocabulary of an LLM.

摘要：LLM 將文字處理成大致對應於單字的符號序列，其中不常見的單字會以多個符號表示。然而，個別符號通常在語意上與它們所組成的單字/概念的意義無關。例如，Llama-2-7b 的符號化器將單字「northeastern」拆分為符號 ['_n', 'ort', 'he', 'astern']，其中沒有一個符號對應於「north」或「east」等有語意意義的單位。同樣地，像「Neil Young」這樣的命名實體和像「break a leg」這樣的多字詞表達式的整體意義無法直接從它們的組成符號推斷出來。從機制上來說，LLM 如何將這些任意符號群轉換為有用的較高層級表徵？在這項工作中，我們發現命名實體和多符號單字的最後一個符號表徵表現出明顯的「抹除」效應，在早期層級中，關於先前和當前符號的資訊會迅速被遺忘。利用這個觀察結果，我們提出了一種方法，透過檢查符號表徵在不同層級之間的差異來「讀出」自迴歸 LLM 的隱含詞彙，並針對 Llama-2-7b 和 Llama-3-8B 提出此方法的結果。據我們所知，這是首次嘗試探測 LLM 的隱含詞彙。

##### **AI for Extreme Event Modeling and Understanding: Methodologies and Challenges**
2406.20080v1 by Gustau Camps-Valls, Miguel-Ángel Fernández-Torres, Kai-Hendrik Cohrs, Adrian Höhl, Andrea Castelletti, Aytac Pacal, Claire Robin, Francesco Martinuzzi, Ioannis Papoutsis, Ioannis Prapas, Jorge Pérez-Aracil, Katja Weigel, Maria Gonzalez-Calabuig, Markus Reichstein, Martin Rabel, Matteo Giuliani, Miguel Mahecha, Oana-Iuliana Popescu, Oscar J. Pellicer-Valero, Said Ouala, Sancho Salcedo-Sanz, Sebastian Sippel, Spyros Kondylatos, Tamara Happé, Tristan Williams

In recent years, artificial intelligence (AI) has deeply impacted various
fields, including Earth system sciences. Here, AI improved weather forecasting,
model emulation, parameter estimation, and the prediction of extreme events.
However, the latter comes with specific challenges, such as developing accurate
predictors from noisy, heterogeneous and limited annotated data. This paper
reviews how AI is being used to analyze extreme events (like floods, droughts,
wildfires and heatwaves), highlighting the importance of creating accurate,
transparent, and reliable AI models. We discuss the hurdles of dealing with
limited data, integrating information in real-time, deploying models, and
making them understandable, all crucial for gaining the trust of stakeholders
and meeting regulatory needs. We provide an overview of how AI can help
identify and explain extreme events more effectively, improving disaster
response and communication. We emphasize the need for collaboration across
different fields to create AI solutions that are practical, understandable, and
trustworthy for analyzing and predicting extreme events. Such collaborative
efforts aim to enhance disaster readiness and disaster risk reduction.

摘要：近年来，人工智能 (AI) 已对包括地球系统科学在内的各个领域产生了深远的影响。在此，AI 改进了天气预报、模型仿真、参数估计和极端事件预测。但是，后者面临着特定的挑战，例如从嘈杂、异构且标注数据有限的数据中开发出准确的预测器。本文回顾了 AI 如何用于分析极端事件（如洪水、干旱、野火和热浪），强调了创建准确、透明和可靠的 AI 模型的重要性。我们讨论了处理有限数据、实时集成信息、部署模型以及使模型易于理解的障碍，所有这些对于获得利益相关者的信任和满足监管需求至关重要。我们概述了 AI 如何帮助更有效地识别和解释极端事件，从而改善灾难响应和沟通。我们强调需要跨不同领域合作，以创建实用、易于理解且值得信赖的 AI 解决方案，用于分析和预测极端事件。此类合作旨在提高应对灾害的准备和减少灾害风险。

##### **Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification**
2406.20079v1 by Anisha Gunjal, Greg Durrett

Automatic factuality verification of large language model (LLM) generations
is becoming more and more widely used to combat hallucinations. A major point
of tension in the literature is the granularity of this fact-checking: larger
chunks of text are hard to fact-check, but more atomic facts like propositions
may lack context to interpret correctly. In this work, we assess the role of
context in these atomic facts. We argue that fully atomic facts are not the
right representation, and define two criteria for molecular facts:
decontextuality, or how well they can stand alone, and minimality, or how
little extra information is added to achieve decontexuality. We quantify the
impact of decontextualization on minimality, then present a baseline
methodology for generating molecular facts automatically, aiming to add the
right amount of information. We compare against various methods of
decontextualization and find that molecular facts balance minimality with fact
verification accuracy in ambiguous settings.

摘要：大型語言模型 (LLM) 生成的自動事實驗證正變得越來越廣泛地用於對抗幻覺。文獻中的一個主要爭論點是這個事實查核的粒度：較大的文本塊很難進行事實查核，但像命題這樣的更原子的事實可能缺乏正確解釋的背景。在這項工作中，我們評估了背景在這些原子事實中的作用。我們認為完全原子的事實並不是正確的表示，並定義了分子事實的兩個標準：去脈絡化，或它們可以獨立存在的程度，以及最少化，或為了實現去脈絡化而添加的額外資訊有多少。我們量化了去脈絡化對最少化的影響，然後提出了一種生成分子事實的基準方法，旨在添加適量的資訊。我們與各種去脈絡化方法進行比較，並發現分子事實平衡了最小化和在模棱兩可的環境中進行事實驗證的準確性。

##### **Applying RLAIF for Code Generation with API-usage in Lightweight LLMs**
2406.20060v1 by Sujan Dutta, Sayantan Mahinder, Raviteja Anantha, Bortik Bandyopadhyay

Reinforcement Learning from AI Feedback (RLAIF) has demonstrated significant
potential across various domains, including mitigating harm in LLM outputs,
enhancing text summarization, and mathematical reasoning. This paper introduces
an RLAIF framework for improving the code generation abilities of lightweight
(<1B parameters) LLMs. We specifically focus on code generation tasks that
require writing appropriate API calls, which is challenging due to the
well-known issue of hallucination in LLMs. Our framework extracts AI feedback
from a larger LLM (e.g., GPT-3.5) through a specialized prompting strategy and
uses this data to train a reward model towards better alignment from smaller
LLMs. We run our experiments on the Gorilla dataset and meticulously assess the
quality of the model-generated code across various metrics, including AST,
ROUGE, and Code-BLEU, and develop a pipeline to compute its executability rate
accurately. Our approach significantly enhances the fine-tuned LLM baseline's
performance, achieving a 4.5% improvement in executability rate. Notably, a
smaller LLM model (780M parameters) trained with RLAIF surpasses a much larger
fine-tuned baseline with 7B parameters, achieving a 1.0% higher code
executability rate.

摘要：利用 AI 回饋進行強化學習 (RLAIF) 已在各種領域展示出顯著的潛力，包括減輕 LLM 輸出中的危害、增強文字摘要和數學推理。本文介紹了一個 RLAIF 框架，用於提升輕量級 (<1B 參數) LLM 的程式碼產生能力。我們特別關注需要撰寫適當 API 呼叫的程式碼產生任務，由於 LLM 中眾所周知的幻覺問題，這具有挑戰性。我們的框架透過專門的提示策略從一個較大的 LLM (例如 GPT-3.5) 提取 AI 回饋，並使用這些資料訓練一個獎勵模型，以期從較小的 LLM 中獲得更好的對齊。我們在 Gorilla 資料集上執行我們的實驗，並仔細評估模型產生的程式碼在各種指標（包括 AST、ROUGE 和 Code-BLEU）上的品質，並開發一個管道以準確地計算其可執行率。我們的做法顯著提升了微調後的 LLM 基準的效能，在可執行率上獲得了 4.5% 的提升。值得注意的是，使用 RLAIF 訓練的較小 LLM 模型 (780M 參數) 超越了具有 7B 參數的更大微調基準，達到了高出 1.0% 的程式碼可執行率。

##### **To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models**
2406.20054v1 by Bastien Liétard, Pascal Denis, Mikaella Keller

Polysemy and synonymy are two crucial interrelated facets of lexical
ambiguity. While both phenomena have been studied extensively in NLP, leading
to dedicated systems, they are often been considered independently. While many
tasks dealing with polysemy (e.g. Word Sense Disambiguiation or Induction)
highlight the role of a word's senses, the study of synonymy is rooted in the
study of concepts, i.e. meaning shared across the lexicon. In this paper, we
introduce Concept Induction, the unsupervised task of learning a soft
clustering among words that defines a set of concepts directly from data. This
task generalizes that of Word Sense Induction. We propose a bi-level approach
to Concept Induction that leverages both a local lemma-centric view and a
global cross-lexicon perspective to induce concepts. We evaluate the obtained
clustering on SemCor's annotated data and obtain good performances (BCubed F1
above 0.60). We find that the local and the global levels are mutually
beneficial to induce concepts and also senses in our setting. Finally, we
create static embeddings representing our induced concepts and use them on the
Word-in-Context task, obtaining competitive performances with the
State-of-the-Art.

摘要：多義和同義是詞彙歧義的兩個關鍵相關面相。雖然兩種現象在自然語言處理中已被廣泛研究，並導致專用系統，但它們通常被獨立地考慮。雖然許多處理多義性的任務（例如詞義消歧或歸納）突出了詞彙意義的角色，但同義性的研究植基於概念的研究，即詞彙中共享的意義。在本文中，我們介紹概念歸納，這是一個從資料中直接定義一組概念的詞彙之間學習軟聚類的非監督式任務。此任務概括了詞義歸納。我們提出了一個雙層級的概念歸納方法，它利用了局部詞元中心觀點和全局跨詞彙觀點來歸納概念。我們在 SemCor 的註解資料上評估獲得的聚類，並獲得良好的效能（BCubed F1 高於 0.60）。我們發現局部和全局層級在我們的設定中對於歸納概念和意義都是互利的。最後，我們建立了代表我們歸納概念的靜態嵌入，並將它們用於上下文中的詞彙任務，獲得與最新技術競爭的效能。

##### **Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation**
2406.20053v1 by Danny Halawi, Alexander Wei, Eric Wallace, Tony T. Wang, Nika Haghtalab, Jacob Steinhardt

Black-box finetuning is an emerging interface for adapting state-of-the-art
language models to user needs. However, such access may also let malicious
actors undermine model safety. To demonstrate the challenge of defending
finetuning interfaces, we introduce covert malicious finetuning, a method to
compromise model safety via finetuning while evading detection. Our method
constructs a malicious dataset where every individual datapoint appears
innocuous, but finetuning on the dataset teaches the model to respond to
encoded harmful requests with encoded harmful responses. Applied to GPT-4, our
method produces a finetuned model that acts on harmful instructions 99% of the
time and avoids detection by defense mechanisms such as dataset inspection,
safety evaluations, and input/output classifiers. Our findings question whether
black-box finetuning access can be secured against sophisticated adversaries.

摘要：黑盒微調是一個新興的介面，用於調整最先進的語言模型以符合使用者需求。然而，此類存取也可能讓惡意行為者破壞模型安全性。為了展示防禦微調介面的挑戰，我們引入了隱蔽惡意微調，這是一種透過微調危害模型安全性且同時規避偵測的方法。我們的做法建構了一個惡意資料集，其中每個個別資料點看起來無害，但針對資料集進行微調會教導模型以編碼的惡意回應來回應編碼的惡意要求。應用於 GPT-4，我們的做法產生一個微調模型，在 99% 的時間執行惡意指令，並透過資料集檢查、安全性評估和輸入/輸出分類器等防禦機制規避偵測。我們的研究結果質疑黑盒微調存取是否能對抗老練的對手。

##### **Understanding and Mitigating Language Confusion in LLMs**
2406.20052v1 by Kelly Marchisio, Wei-Yin Ko, Alexandre Bérard, Théo Dehaze, Sebastian Ruder

We investigate a surprising limitation of LLMs: their inability to
consistently generate text in a user's desired language. We create the Language
Confusion Benchmark (LCB) to evaluate such failures, covering 15 typologically
diverse languages with existing and newly-created English and multilingual
prompts. We evaluate a range of LLMs on monolingual and cross-lingual
generation reflecting practical use cases, finding that Llama Instruct and
Mistral models exhibit high degrees of language confusion and even the
strongest models fail to consistently respond in the correct language. We
observe that base and English-centric instruct models are more prone to
language confusion, which is aggravated by complex prompts and high sampling
temperatures. We find that language confusion can be partially mitigated via
few-shot prompting, multilingual SFT and preference tuning. We release our
language confusion benchmark, which serves as a first layer of efficient,
scalable multilingual evaluation at
https://github.com/for-ai/language-confusion.

摘要：我們調查了 LLM 的一個令人驚訝的限制：它們無法持續產生使用者所需語言的文字。我們建立了語言混淆基準 (LCB) 來評估此類失敗，涵蓋 15 種類型不同的語言，並使用現有和新建立的英文和多語言提示。我們評估了各種 LLM 在單語和跨語言生成的表現，反映實際使用案例，發現 Llama Instruct 和 Mistral 模型展現出高度的語言混淆，即使是最強大的模型也無法持續以正確的語言回應。我們觀察到基礎和以英文為中心的指令模型更容易發生語言混淆，而複雜的提示和高取樣溫度會加劇這種情況。我們發現語言混淆可以透過少量提示、多語言 SFT 和偏好調整得到部分緩解。我們發布了我們的語言混淆基準，它作為有效、可擴充的多語言評估的第一層，網址為 https://github.com/for-ai/language-confusion。

##### **Electrostatics-based particle sampling and approximate inference**
2406.20044v1 by Yongchao Huang

A new particle-based sampling and approximate inference method, based on
electrostatics and Newton mechanics principles, is introduced with theoretical
ground, algorithm design and experimental validation. This method simulates an
interacting particle system (IPS) where particles, i.e. the freely-moving
negative charges and spatially-fixed positive charges with magnitudes
proportional to the target distribution, interact with each other via
attraction and repulsion induced by the resulting electric fields described by
Poisson's equation. The IPS evolves towards a steady-state where the
distribution of negative charges conforms to the target distribution. This
physics-inspired method offers deterministic, gradient-free sampling and
inference, achieving comparable performance as other particle-based and MCMC
methods in benchmark tasks of inferring complex densities, Bayesian logistic
regression and dynamical system identification. A discrete-time, discrete-space
algorithmic design, readily extendable to continuous time and space, is
provided for usage in more general inference problems occurring in
probabilistic machine learning scenarios such as Bayesian inference, generative
modelling, and beyond.

摘要：基於靜電學和牛頓力學原理，提出了一種新的基於粒子的抽樣和近似推論方法，並提供了理論依據、演算法設計和實驗驗證。此方法模擬了一個相互作用粒子系統 (IPS)，其中粒子（即自由移動的負電荷和與目標分佈成正比的空間固定正電荷）透過由泊松方程式描述的電場產生的吸引和排斥相互作用。IPS 會演化到一個穩態，其中負電荷的分佈符合目標分佈。這種受物理啟發的方法提供了確定性的、無梯度的抽樣和推論，在推論複雜密度、貝氏邏輯迴歸和動態系統識別的基準任務中，達到了與其他基於粒子和 MCMC 的方法相當的效能。提供了一個離散時間、離散空間的演算法設計，可以輕鬆擴展到連續時間和空間，用於貝氏推論、生成模型等概率機器學習場景中發生的更一般的推論問題。

##### **BMW Agents -- A Framework For Task Automation Through Multi-agent Collaboration**
2406.20041v1 by Noel Crawford, Edward B. Duffy, Iman Evazzade, Torsten Foehr, Gregory Robbins, Debbrata Kumar Saha, Jiya Varma, Marcin Ziolkowski

Autonomous agents driven by Large Language Models (LLMs) offer enormous
potential for automation. Early proof of this technology can be found in
various demonstrations of agents solving complex tasks, interacting with
external systems to augment their knowledge, and triggering actions. In
particular, workflows involving multiple agents solving complex tasks in a
collaborative fashion exemplify their capacity to operate in less strict and
less well-defined environments. Thus, a multi-agent approach has great
potential for serving as a backbone in many industrial applications, ranging
from complex knowledge retrieval systems to next generation robotic process
automation. Given the reasoning abilities within the current generation of
LLMs, complex processes require a multi-step approach that includes a plan of
well-defined and modular tasks. Depending on the level of complexity, these
tasks can be executed either by a single agent or a group of agents. In this
work, we focus on designing a flexible agent engineering framework with careful
attention to planning and execution, capable of handling complex use case
applications across various domains. The proposed framework provides
reliability in industrial applications and presents techniques to ensure a
scalable, flexible, and collaborative workflow for multiple autonomous agents
working together towards solving tasks.

摘要：由大型語言模型 (LLM) 驅動的自主代理提供巨大的自動化潛力。此技術的早期證明可以在代理解決複雜任務、與外部系統互動以擴增其知識，以及觸發動作的各種演示中找到。特別是，涉及多個代理以協作方式解決複雜任務的工作流程，證明了它們在不太嚴格且定義較不完善的環境中運作的能力。因此，多代理方法具有很大的潛力，可用作許多產業應用中的骨幹，從複雜的知識檢索系統到下一代機器人流程自動化。鑑於當前一代 LLM 中的推理能力，複雜的流程需要一個多步驟的方法，其中包括一個由定義明確且模組化的任務組成的計畫。根據複雜程度，這些任務可以由單一代理或一群代理執行。在這項工作中，我們專注於設計一個靈活的代理工程架構，仔細注意規劃和執行，能夠處理跨越各種領域的複雜用例應用。所提出的架構在產業應用中提供可靠性，並提出技術以確保多個自主代理一起工作以解決任務的可擴充性、靈活性，以及協作工作流程。

##### **BioMNER: A Dataset for Biomedical Method Entity Recognition**
2406.20038v1 by Chen Tang, Bohao Yang, Kun Zhao, Bo Lv, Chenghao Xiao, Frank Guerin, Chenghua Lin

Named entity recognition (NER) stands as a fundamental and pivotal task
within the realm of Natural Language Processing. Particularly within the domain
of Biomedical Method NER, this task presents notable challenges, stemming from
the continual influx of domain-specific terminologies in scholarly literature.
Current research in Biomedical Method (BioMethod) NER suffers from a scarcity
of resources, primarily attributed to the intricate nature of methodological
concepts, which necessitate a profound understanding for precise delineation.
In this study, we propose a novel dataset for biomedical method entity
recognition, employing an automated BioMethod entity recognition and
information retrieval system to assist human annotation. Furthermore, we
comprehensively explore a range of conventional and contemporary open-domain
NER methodologies, including the utilization of cutting-edge large-scale
language models (LLMs) customised to our dataset. Our empirical findings reveal
that the large parameter counts of language models surprisingly inhibit the
effective assimilation of entity extraction patterns pertaining to biomedical
methods. Remarkably, the approach, leveraging the modestly sized ALBERT model
(only 11MB), in conjunction with conditional random fields (CRF), achieves
state-of-the-art (SOTA) performance.

摘要：命名實體辨識（NER）在自然語言處理領域中是一個重要且關鍵的任務。特別是在生物醫學方法 NER 領域中，此任務面臨顯著的挑戰，源於學術文獻中不斷湧入的特定領域術語。目前生物醫學方法（BioMethod）NER 的研究因資源匱乏而受阻，這主要歸因於方法論概念的複雜性，需要深入了解才能精確描述。在這項研究中，我們提出了一個新的生物醫學方法實體辨識資料集，採用自動化 BioMethod 實體辨識和資訊檢索系統來協助人工標註。此外，我們全面探討了一系列傳統和當代開放領域 NER 方法，包括利用針對我們資料集自訂的最先進大規模語言模型（LLM）。我們的實證發現顯示，語言模型的大參數數量令人驚訝地抑制了與生物醫學方法相關的實體萃取模式的有效同化。值得注意的是，這種方法利用中等規模的 ALBERT 模型（僅 11MB），結合條件隨機場（CRF），達到了最先進（SOTA）的效能。

##### **LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models**
2406.20030v1 by Renzhi Wang, Piji Li

Large language models (LLMs) require continual knowledge updates to stay
abreast of the ever-changing world facts, prompting the formulation of lifelong
model editing task. While recent years have witnessed the development of
various techniques for single and batch editing, these methods either fail to
apply or perform sub-optimally when faced with lifelong editing. In this paper,
we introduce LEMoE, an advanced Mixture of Experts (MoE) adaptor for lifelong
model editing. We first analyze the factors influencing the effectiveness of
conventional MoE adaptor in lifelong editing, including catastrophic
forgetting, inconsistent routing and order sensitivity. Based on these
insights, we propose a tailored module insertion method to achieve lifelong
editing, incorporating a novel KV anchor routing to enhance routing consistency
between training and inference stage, along with a concise yet effective
clustering-based editing order planning. Experimental results demonstrate the
effectiveness of our method in lifelong editing, surpassing previous model
editing techniques while maintaining outstanding performance in batch editing
task. Our code will be available.

摘要：大型語言模型 (LLM) 需要持續更新知識，以掌握瞬息萬變的世界事實，促使制定終身模型編輯任務。儘管近年來見證了各種單次和批次編輯技術的發展，但這些方法在面對終身編輯時，要不無法應用，要不就是表現不佳。在本文中，我們介紹了 LEMoE，一種先進的專家混合 (MoE) 適配器，用於終身模型編輯。我們首先分析了影響傳統 MoE 適配器在終身編輯中有效性的因素，包括災難性遺忘、不一致的路由和順序敏感性。根據這些見解，我們提出了一種量身打造的模組插入方法來實現終身編輯，結合了一種新穎的 KV錨定路由，以增強訓練和推理階段之間的路由一致性，以及一種簡潔但有效的基於群集的編輯順序規劃。實驗結果證明了我們的方法在終身編輯中的有效性，超越了先前的模型編輯技術，同時在批次編輯任務中保持出色的效能。我們的程式碼將會提供。

##### **ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models**
2406.20015v1 by Yuxiang Zhang, Jing Chen, Junjie Wang, Yaxin Liu, Cheng Yang, Chufan Shi, Xinyu Zhu, Zihao Lin, Hanwen Wan, Yujiu Yang, Tetsuya Sakai, Tian Feng, Hayato Yamana

Tool-augmented large language models (LLMs) are rapidly being integrated into
real-world applications. Due to the lack of benchmarks, the community still
needs to fully understand the hallucination issues within these models. To
address this challenge, we introduce a comprehensive diagnostic benchmark,
ToolBH. Specifically, we assess the LLM's hallucinations through two
perspectives: depth and breadth. In terms of depth, we propose a multi-level
diagnostic process, including (1) solvability detection, (2) solution planning,
and (3) missing-tool analysis. For breadth, we consider three scenarios based
on the characteristics of the toolset: missing necessary tools, potential
tools, and limited functionality tools. Furthermore, we developed seven tasks
and collected 700 evaluation samples through multiple rounds of manual
annotation. The results show the significant challenges presented by the ToolBH
benchmark. The current advanced models Gemini-1.5-Pro and GPT-4o only achieve a
total score of 45.3 and 37.0, respectively, on a scale of 100. In this
benchmark, larger model parameters do not guarantee better performance; the
training data and response strategies also play a crucial role in tool-enhanced
LLM scenarios. Our diagnostic analysis indicates that the primary reason for
model errors lies in assessing task solvability. Additionally, open-weight
models suffer from performance drops with verbose replies, whereas proprietary
models excel with longer reasoning.

摘要：工具增强的语言模型（LLM）正迅速整合到实际应用中。由于缺乏基准，社区仍需要充分了解这些模型中的幻觉问题。为了应对这一挑战，我们引入了一个全面的诊断基准 ToolBH。具体来说，我们从深度和广度的两个角度评估 LLM 的幻觉。在深度方面，我们提出了一个多层次的诊断过程，包括（1）可解决性检测，（2）解决方案规划和（3）缺失工具分析。在广度方面，我们基于工具集的特性考虑了三种场景：缺少必要的工具、潜在的工具和功能受限的工具。此外，我们制定了七项任务，并通过多轮人工注释收集了 700 个评估样本。结果显示了 ToolBH 基准提出的重大挑战。当前的先进模型 Gemini-1.5-Pro 和 GPT-4o 在 100 分制中仅分别达到 45.3 和 37.0 的总分。在此基准中，较大的模型参数并不能保证更好的性能；训练数据和响应策略在工具增强的 LLM 场景中也起着至关重要的作用。我们的诊断分析表明，模型错误的主要原因在于评估任务的可解决性。此外，开放权重模型在冗长的回复中会出现性能下降，而专有模型则在更长的推理中表现出色。

##### **The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models**
2406.19999v1 by Xinyi Chen, Baohao Liao, Jirui Qi, Panagiotis Eustratiadis, Christof Monz, Arianna Bisazza, Maarten de Rijke

Following multiple instructions is a crucial ability for large language
models (LLMs). Evaluating this ability comes with significant challenges: (i)
limited coherence between multiple instructions, (ii) positional bias where the
order of instructions affects model performance, and (iii) a lack of
objectively verifiable tasks. To address these issues, we introduce a benchmark
designed to evaluate models' abilities to follow multiple instructions through
sequential instruction following (SIFo) tasks. In SIFo, the successful
completion of multiple instructions is verifiable by examining only the final
instruction. Our benchmark evaluates instruction following using four tasks
(text modification, question answering, mathematics, and security rule
following), each assessing different aspects of sequential instruction
following. Our evaluation of popular LLMs, both closed-source and open-source,
shows that more recent and larger models significantly outperform their older
and smaller counterparts on the SIFo tasks, validating the benchmark's
effectiveness. All models struggle with following sequences of instructions,
hinting at an important lack of robustness of today's language models.

摘要：對於大型語言模型 (LLM) 而言，遵循多項指令是一項至關重要的能力。評估此能力會面臨重大挑戰：(i) 多項指令之間的連貫性有限，(ii) 指令順序會影響模型效能的位置偏差，以及 (iii) 缺乏客觀可驗證的任務。為了解決這些問題，我們引進一個基準，旨在透過順序指令遵循 (SIFo) 任務來評估模型遵循多項指令的能力。在 SIFo 中，多項指令的成功完成僅透過檢查最後一項指令即可驗證。我們的基準使用四項任務（文字修改、問答、數學和安全規則遵循）來評估指令遵循，每項任務都評估順序指令遵循的不同面向。我們對熱門 LLM（閉源和開源）的評估顯示，較新且較大的模型在 SIFo 任務中明顯優於較舊且較小的模型，驗證了基準的有效性。所有模型都難以遵循指令序列，暗示當今語言模型缺乏穩健性。

##### **Wavelets Are All You Need for Autoregressive Image Generation**
2406.19997v1 by Wael Mattar, Idan Levy, Nir Sharon, Shai Dekel

In this paper, we take a new approach to autoregressive image generation that
is based on two main ingredients. The first is wavelet image coding, which
allows to tokenize the visual details of an image from coarse to fine details
by ordering the information starting with the most significant bits of the most
significant wavelet coefficients. The second is a variant of a language
transformer whose architecture is re-designed and optimized for token sequences
in this 'wavelet language'. The transformer learns the significant statistical
correlations within a token sequence, which are the manifestations of
well-known correlations between the wavelet subbands at various resolutions. We
show experimental results with conditioning on the generation process.

摘要：在本文中，我們採取了一種新的自迴歸影像生成方式，它基於兩個主要元素。第一個是影像小波編碼，它允許從粗略到精細的細節對影像的視覺細節進行標記化，方法是從最重要的波段係數的最重要位元開始對資訊進行排序。第二個是語言轉換器的變體，其架構經過重新設計和最佳化，適用於此「小波語言」中的標記序列。轉換器會學習標記序列中的顯著統計關聯性，這些關聯性是不同解析度的小波子頻帶之間眾所周知關聯性的表現形式。我們展示了對生成過程進行條件化的實驗結果。

##### **Single Parent Family: A Spectrum of Family Members from a Single Pre-Trained Foundation Model**
2406.19995v1 by Habib Hajimolahoseini, Mohammad Hassanpour, Foozhan Ataiefard, Boxing Chen, Yang Liu

This paper introduces a novel method of Progressive Low Rank Decomposition
(PLRD) tailored for the compression of large language models. Our approach
leverages a pre-trained model, which is then incrementally decompressed to
smaller sizes using progressively lower ranks. This method allows for
significant reductions in computational overhead and energy consumption, as
subsequent models are derived from the original without the need for retraining
from scratch. We detail the implementation of PLRD, which strategically
decreases the tensor ranks, thus optimizing the trade-off between model
performance and resource usage. The efficacy of PLRD is demonstrated through
extensive experiments showing that models trained with PLRD method on only 1B
tokens maintain comparable performance with traditionally trained models while
using 0.1% of the tokens. The versatility of PLRD is highlighted by its ability
to generate multiple model sizes from a single foundational model, adapting
fluidly to varying computational and memory budgets. Our findings suggest that
PLRD could set a new standard for the efficient scaling of LLMs, making
advanced AI more feasible on diverse platforms.

摘要：本文介紹一種針對大型語言模型壓縮量身打造的漸進式低秩分解 (PLRD) 新方法。我們的做法利用預先訓練的模型，然後使用漸進式較低秩對其進行增量解壓縮以縮小尺寸。此方法可以顯著減少運算負擔和能源消耗，因為後續模型是從原始模型衍生的，無需從頭開始重新訓練。我們詳細說明了 PLRD 的實作，它策略性地降低張量秩，從而優化模型效能與資源使用之間的權衡。PLRD 的效能透過廣泛的實驗得到證明，這些實驗顯示僅使用 1B 個符號以 PLRD 方法訓練的模型，與傳統訓練的模型保持相當的效能，同時只使用 0.1% 的符號。PLRD 的多功能性在於它能夠從單一基礎模型產生多種模型大小，靈活地適應不同的運算和記憶體預算。我們的研究結果表明，PLRD 可以為 LLM 的高效縮放設定新標準，讓進階 AI 在各種平台上更可行。

##### **Into the Unknown: Generating Geospatial Descriptions for New Environments**
2406.19967v1 by Tzuf Paz-Argaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge

Similar to vision-and-language navigation (VLN) tasks that focus on bridging
the gap between vision and language for embodied navigation, the new Rendezvous
(RVS) task requires reasoning over allocentric spatial relationships
(independent of the observer's viewpoint) using non-sequential navigation
instructions and maps. However, performance substantially drops in new
environments with no training data. Using opensource descriptions paired with
coordinates (e.g., Wikipedia) provides training data but suffers from limited
spatially-oriented text resulting in low geolocation resolution. We propose a
large-scale augmentation method for generating high-quality synthetic data for
new environments using readily available geospatial data. Our method constructs
a grounded knowledge-graph, capturing entity relationships. Sampled entities
and relations (`shop north of school') generate navigation instructions via (i)
generating numerous templates using context-free grammar (CFG) to embed
specific entities and relations; (ii) feeding the entities and relation into a
large language model (LLM) for instruction generation. A comprehensive
evaluation on RVS, showed that our approach improves the 100-meter accuracy by
45.83% on unseen environments. Furthermore, we demonstrate that models trained
with CFG-based augmentation achieve superior performance compared with those
trained with LLM-based augmentation, both in unseen and seen environments.
These findings suggest that the potential advantages of explicitly structuring
spatial information for text-based geospatial reasoning in previously unknown,
can unlock data-scarce scenarios.

摘要：類似於專注於彌合具體導航中視覺與語言差距的視覺語言導航 (VLN) 任務，新的會面 (RVS) 任務需要使用非順序導航指令和地圖推理異中心空間關係（與觀察者的觀點無關）。然而，在沒有訓練資料的新環境中，效能會大幅下降。使用與座標配對的開源說明（例如，維基百科）提供了訓練資料，但由於空間導向文字有限，導致地理位置解析度低。我們提出了一種大規模擴充方法，使用現成的地理空間資料為新環境產生高品質的合成資料。我們的建構方法建立了一個基礎知識圖，擷取實體關係。取樣的實體和關係（「商店在學校北邊」）透過以下方式產生導航指令：(i) 使用無關乎語境的文法 (CFG) 產生許多範本來嵌入特定實體和關係；(ii) 將實體和關係輸入大型語言模型 (LLM) 以產生指令。在 RVS 上的全面評估顯示，我們的做法將未見過環境中的 100 公尺準確度提升了 45.83%。此外，我們證明使用基於 CFG 的擴充所訓練的模型，在未見過和見過環境中，都比使用基於 LLM 的擴充所訓練的模型獲得了更好的效能。這些發現表明，在以前未知的環境中，明確建構用於基於文字的地理空間推理的空間資訊的潛在優勢，可以解鎖資料稀少的場景。

##### **Simulating Financial Market via Large Language Model based Agents**
2406.19966v1 by Shen Gao, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, Shuo Shang

Most economic theories typically assume that financial market participants
are fully rational individuals and use mathematical models to simulate human
behavior in financial markets. However, human behavior is often not entirely
rational and is challenging to predict accurately with mathematical models. In
this paper, we propose \textbf{A}gent-based \textbf{S}imulated
\textbf{F}inancial \textbf{M}arket (ASFM), which first constructs a simulated
stock market with a real order matching system. Then, we propose a large
language model based agent as the stock trader, which contains the profile,
observation, and tool-learning based action module. The trading agent can
comprehensively understand current market dynamics and financial policy
information, and make decisions that align with their trading strategy. In the
experiments, we first verify that the reactions of our ASFM are consistent with
the real stock market in two controllable scenarios. In addition, we also
conduct experiments in two popular economics research directions, and we find
that conclusions drawn in our \model align with the preliminary findings in
economics research. Based on these observations, we believe our proposed ASFM
provides a new paradigm for economic research.

摘要：大多數經濟理論通常假設金融市場參與者是完全理性的個體，並使用數學模型來模擬金融市場中的人類行為。然而，人類行為通常並非完全理性，且難以使用數學模型準確預測。在本文中，我們提出基於代理的模擬金融市場 (ASFM)，它首先構建一個具有真實訂單匹配系統的模擬股票市場。然後，我們提出一個基於大型語言模型的代理作為股票交易者，其中包含個人資料、觀察和基於工具學習的動作模組。交易代理可以全面了解當前的市場動態和財務政策資訊，並根據其交易策略做出決策。在實驗中，我們首先驗證我們的 ASFM 的反應與兩個可控場景中的真實股票市場一致。此外，我們還在兩個流行的經濟學研究方向中進行了實驗，我們發現我們模型中得出的結論與經濟學研究中的初步發現一致。根據這些觀察，我們相信我們提出的 ASFM 為經濟研究提供了新的範例。

##### **Text2Robot: Evolutionary Robot Design from Text Descriptions**
2406.19963v1 by Ryan P. Ringel, Zachary S. Charlick, Jiaxun Liu, Boxi Xia, Boyuan Chen

Robot design has traditionally been costly and labor-intensive. Despite
advancements in automated processes, it remains challenging to navigate a vast
design space while producing physically manufacturable robots. We introduce
Text2Robot, a framework that converts user text specifications and performance
preferences into physical quadrupedal robots. Within minutes, Text2Robot can
use text-to-3D models to provide strong initializations of diverse
morphologies. Within a day, our geometric processing algorithms and
body-control co-optimization produce a walking robot by explicitly considering
real-world electronics and manufacturability. Text2Robot enables rapid
prototyping and opens new opportunities for robot design with generative
models.

摘要：機器人設計傳統上成本高昂且勞力密集。儘管自動化製程有進展，在生產可實際製造的機器人時，在廣大的設計空間中導航仍然具有挑戰性。我們引進 Text2Robot，一種將使用者文字規格和效能偏好轉換為物理四足機器人的框架。在幾分鐘內，Text2Robot 可以使用文字轉 3D 模型來提供各種形態的強大初始化。在一天之內，我們的幾何處理演算法和身體控制共同最佳化，透過明確考慮現實世界的電子產品和可製造性來產生一個會走路的機器人。Text2Robot 能夠快速製作原型，並透過生成模型為機器人設計開啟新的機會。

##### **BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5**
2406.19954v1 by Zhehuai Chen, He Huang, Oleksii Hrinchuk, Krishna C. Puvvada, Nithin Rao Koluguri, Piotr Żelasko, Jagadeesh Balam, Boris Ginsburg

Incorporating speech understanding capabilities into pretrained
large-language models has become a vital research direction (SpeechLLM). The
previous architectures can be categorized as: i) GPT-style, prepend speech
prompts to the text prompts as a sequence of LLM inputs like a decoder-only
model; ii) T5-style, introduce speech cross-attention to each layer of the
pretrained LLMs. We propose BESTOW architecture to bring the BESt features from
TwO Worlds into a single model that is highly efficient and has strong
multitask capabilities. Moreover, there is no clear streaming solution for
either style, especially considering the solution should generalize to speech
multitask. We reformulate streamable SpeechLLM as a read-write policy problem
and unifies the offline and streaming research with BESTOW architecture. Hence
we demonstrate the first open-source SpeechLLM solution that enables Streaming
and Multitask at scale (beyond ASR) at the same time. This streamable solution
achieves very strong performance on a wide range of speech tasks (ASR, AST,
SQA, unseen DynamicSuperb). It is end-to-end optimizable, with lower
training/inference cost, and demonstrates LLM knowledge transferability to
speech.

摘要：將語音理解能力整合到預訓練的大語言模型中已成為一個重要的研究方向 (SpeechLLM)。先前的架構可以分類為：i) GPT 風格，將語音提示作為 LLM 輸入的序列，附加到文字提示之前，就像僅解碼器模型；ii) T5 風格，在預訓練 LLM 的每一層中引入語音交叉注意力。我們提出 BESTOW 架構，將兩個世界的最佳功能帶入一個單一模型中，該模型高效且具有強大的多任務能力。此外，對於這兩種風格都沒有明確的串流解決方案，特別是考慮到該解決方案應概括為語音多任務。我們將可串流 SpeechLLM 重新表述為讀寫策略問題，並使用 BESTOW 架構統一離線和串流研究。因此，我們展示了第一個開放原始碼 SpeechLLM 解決方案，它能同時大規模啟用串流和多任務（超越 ASR）。此可串流解決方案在廣泛的語音任務（ASR、AST、SQA、未見過的 DynamicSuperb）上實現了非常強大的效能。它是端到端可最佳化的，具有較低的訓練/推論成本，並展示了 LLM 知識可轉移到語音。

##### **Uncovering the hidden core-periphery structure in hyperbolic networks**
2406.19953v1 by Imran Ansari, Pawanesh Yadav, Niteesh Sahni

The hyperbolic network models exhibit very fundamental and essential
features, like small-worldness, scale-freeness, high-clustering coefficient,
and community structure. In this paper, we comprehensively explore the presence
of an important feature, the core-periphery structure, in the hyperbolic
network models, which is often exhibited by real-world networks. We focused on
well-known hyperbolic models such as popularity-similarity optimization model
(PSO) and S1/H2 models and studied core-periphery structures using a
well-established method that is based on standard random walk Markov chain
model. The observed core-periphery centralization values indicate that the
core-periphery structure can be very pronounced under certain conditions. We
also validate our findings by statistically testing for the significance of the
observed core-periphery structure in the network geometry. This study extends
network science and reveals core-periphery insights applicable to various
domains, enhancing network performance and resiliency in transportation and
information systems.

摘要：雙曲網路模型展現非常基本且重要的特徵，例如小世界現象、無尺度性、高群聚係數和社群結構。在本文中，我們全面探討雙曲網路模型中一個重要特徵，即核心邊緣結構的存在，這通常由真實世界的網路展現。我們專注於眾所周知的雙曲模型，例如人氣相似性最佳化模型 (PSO) 和 S1/H2 模型，並使用基於標準隨機遊走馬可夫鏈模型的完善方法研究核心邊緣結構。觀察到的核心邊緣中心化值表示，在特定條件下，核心邊緣結構可能會非常明顯。我們也透過統計測試驗證我們的發現，以了解網路幾何中觀察到的核心邊緣結構的重要性。這項研究擴展了網路科學，並揭露了適用於各種領域的核心邊緣見解，進而提升運輸和資訊系統中的網路效能和復原力。

##### **Mining Reasons For And Against Vaccination From Unstructured Data Using Nichesourcing and AI Data Augmentation**
2406.19951v1 by Damián Ariel Furman, Juan Junqueras, Z. Burçe Gümüslü, Edgar Altszyler, Joaquin Navajas, Ophelia Deroy, Justin Sulik

We present Reasons For and Against Vaccination (RFAV), a dataset for
predicting reasons for and against vaccination, and scientific authorities used
to justify them, annotated through nichesourcing and augmented using GPT4 and
GPT3.5-Turbo. We show how it is possible to mine these reasons in
non-structured text, under different task definitions, despite the high level
of subjectivity involved and explore the impact of artificially augmented data
using in-context learning with GPT4 and GPT3.5-Turbo. We publish the dataset
and the trained models along with the annotation manual used to train
annotators and define the task.

摘要：我們提出「疫苗接種的理由和反對理由」(RFAV)，這是一個用於預測疫苗接種的理由和反對理由的資料集，以及用於證明這些理由和反對理由的科學權威，這些資料集透過利基外包進行註解，並使用 GPT4 和 GPT3.5-Turbo 進行擴充。我們展示如何在非結構化文字中挖掘這些理由，在不同的任務定義下，儘管涉及高度主觀性，並探討使用 GPT4 和 GPT3.5-Turbo 的情境學習中人工擴充資料的影響。我們發布資料集和訓練好的模型，以及用於訓練註解者和定義任務的註解手冊。

##### **Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring**
2406.19949v1 by Jiazheng Li, Hainiu Xu, Zhaoyue Sun, Yuxiang Zhou, David West, Cesare Aloisi, Yulan He

Generating rationales that justify scoring decisions has been a promising way
to facilitate explainability in automated scoring systems. However, existing
methods do not match the accuracy of classifier-based methods. Plus, the
generated rationales often contain hallucinated information. To address these
issues, we propose a novel framework capable of generating more faithful
rationales and, more importantly, matching performance with classifier-based
black-box scoring systems. We first mimic the human assessment process by
querying Large Language Models (LLMs) to generate a thought tree. We then
summarise intermediate assessment decisions from each thought tree path for
creating synthetic rationale data and rationale preference data. Finally, we
utilise the generated synthetic data to calibrate LLMs through a two-step
training process: supervised fine-tuning and preference optimization. Extensive
experimental results demonstrate that our framework achieves a 38% assessment
performance improvement in the QWK score compared to prior work while producing
higher-quality rationales, as recognised by human evaluators and LLMs. Our work
sheds light on the effectiveness of performing preference optimization using
synthetic preference data obtained from thought tree paths.

摘要：生成合理化以證明評分決策一直是促進自動化評分系統中可解釋性的一種有前途的方法。然而，現有方法與基於分類器的方法的準確性不符。此外，生成的依據通常包含虛構的資訊。為了解決這些問題，我們提出了一個新穎的架構，能夠生成更忠實的依據，更重要的是，與基於分類器的黑盒評分系統相匹配的效能。我們首先模擬人類評估過程，透過查詢大型語言模型 (LLM) 來產生思維樹。然後，我們總結每個思維樹路徑的中間評估決策，以建立合成依據資料和依據偏好資料。最後，我們利用生成的合成資料透過兩階段訓練過程校準 LLM：監督微調和偏好最佳化。廣泛的實驗結果表明，與先前的研究相比，我們的架構在 QWK 分數中實現了 38% 的評估效能提升，同時產生了更高品質的依據，正如人類評估者和 LLM 所認可的。我們的研究闡明了使用從思維樹路徑中獲得的合成偏好資料執行偏好最佳化的有效性。

##### **From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis**
2406.19934v1 by Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan

We explore multi-step reasoning in vision-language models (VLMs). The problem
is challenging, as reasoning data consisting of multiple steps of visual and
language processing are barely available. To overcome the challenge, we first
introduce a least-to-most visual reasoning paradigm, which interleaves steps of
decomposing a question into sub-questions and invoking external tools for
resolving sub-questions. Based on the paradigm, we further propose a novel data
synthesis approach that can automatically create questions and multi-step
reasoning paths for an image in a bottom-up manner. Our approach divides the
complex synthesis task into a few simple sub-tasks, and (almost entirely)
relies on open-sourced models to accomplish the sub-tasks. Therefore, the
entire synthesis process is reproducible and cost-efficient, and the
synthesized data is quality guaranteed. With the approach, we construct $50$k
visual reasoning examples. Then, we develop a visual reasoner through
supervised fine-tuning, which is capable of generally enhancing the reasoning
abilities of a wide range of existing VLMs in a plug-and-play fashion.
Extensive experiments indicate that the visual reasoner can consistently and
significantly improve four VLMs on four VQA benchmarks. Our code and dataset
are available at https://github.com/steven-ccq/VisualReasoner.

摘要：我們在視覺語言模型 (VLM) 中探索多步驟推理。這個問題具有挑戰性，因為包含多個視覺和語言處理步驟的推理數據幾乎不可用。為了克服這個挑戰，我們首先引入一個由少到多的視覺推理範例，它交織了將問題分解成子問題的步驟，並調用外部工具來解決子問題。基於這個範例，我們進一步提出了一種新穎的數據合成方法，它可以自動為圖像創建問題和多步驟推理路徑，採用由下而上的方式。我們的做法將複雜的合成任務劃分為幾個簡單的子任務，並且（幾乎完全）依賴於開源模型來完成子任務。因此，整個合成過程是可複製且具有成本效益的，並且合成數據的品質有保證。使用這種方法，我們構建了 $50$k 視覺推理範例。然後，我們透過監督微調開發了一個視覺推理器，它能夠以即插即用的方式普遍增強各種現有 VLM 的推理能力。廣泛的實驗表明，視覺推理器可以持續且顯著地改善四個 VQA 基準上的四個 VLM。我們的程式碼和數據集可在 https://github.com/steven-ccq/VisualReasoner 取得。

##### **Decoupling General and Personalized Knowledge in Federated Learning via Additive and Low-Rank Decomposition**
2406.19931v1 by Xinghao Wu, Xuefeng Liu, Jianwei Niu, Haolin Wang, Shaojie Tang, Guogang Zhu, Hao Su

To address data heterogeneity, the key strategy of Personalized Federated
Learning (PFL) is to decouple general knowledge (shared among clients) and
client-specific knowledge, as the latter can have a negative impact on
collaboration if not removed. Existing PFL methods primarily adopt a parameter
partitioning approach, where the parameters of a model are designated as one of
two types: parameters shared with other clients to extract general knowledge
and parameters retained locally to learn client-specific knowledge. However, as
these two types of parameters are put together like a jigsaw puzzle into a
single model during the training process, each parameter may simultaneously
absorb both general and client-specific knowledge, thus struggling to separate
the two types of knowledge effectively. In this paper, we introduce FedDecomp,
a simple but effective PFL paradigm that employs parameter additive
decomposition to address this issue. Instead of assigning each parameter of a
model as either a shared or personalized one, FedDecomp decomposes each
parameter into the sum of two parameters: a shared one and a personalized one,
thus achieving a more thorough decoupling of shared and personalized knowledge
compared to the parameter partitioning method. In addition, as we find that
retaining local knowledge of specific clients requires much lower model
capacity compared with general knowledge across all clients, we let the matrix
containing personalized parameters be low rank during the training process.
Moreover, a new alternating training strategy is proposed to further improve
the performance. Experimental results across multiple datasets and varying
degrees of data heterogeneity demonstrate that FedDecomp outperforms
state-of-the-art methods up to 4.9\%.

摘要：<paragraph>為了處理資料異質性，個人化聯邦學習 (PFL) 的關鍵策略是將一般知識 (在客戶端之間共享) 和客戶端特定的知識分開，因為後者如果沒有移除，可能會對協作產生負面影響。現有的 PFL 方法主要採用參數分割方法，其中模型的參數被指定為兩種類型之一：與其他客戶端共享以提取一般知識的參數和保留在本地以學習客戶端特定知識的參數。然而，由於這兩種類型的參數在訓練過程中會像拼圖一樣組合成單一模型，因此每個參數可能會同時吸收一般和客戶端特定的知識，從而難以有效地將這兩種知識類型分開。在本文中，我們介紹了 FedDecomp，這是一個簡單但有效的 PFL 典範，採用參數加法分解來解決此問題。FedDecomp 沒有將模型的每個參數指定為共享參數或個人化參數，而是將每個參數分解為兩個參數的總和：共享參數和個人化參數，從而實現了與參數分割方法相比更徹底的共享和個人化知識解耦。此外，由於我們發現保留特定客戶端的本地知識所需的模型容量遠低於所有客戶端的一般知識，因此我們讓包含個人化參數的矩陣在訓練過程中保持低秩。此外，提出了一種新的交替訓練策略，以進一步提高性能。跨多個資料集和不同程度資料異質性的實驗結果證明，FedDecomp 的效能優於最先進的方法，最高可達 4.9%。</paragraph>

##### **Interactive Topic Models with Optimal Transport**
2406.19928v1 by Garima Dhanania, Sheshera Mysore, Chau Minh Pham, Mohit Iyyer, Hamed Zamani, Andrew McCallum

Topic models are widely used to analyze document collections. While they are
valuable for discovering latent topics in a corpus when analysts are unfamiliar
with the corpus, analysts also commonly start with an understanding of the
content present in a corpus. This may be through categories obtained from an
initial pass over the corpus or a desire to analyze the corpus through a
predefined set of categories derived from a high level theoretical framework
(e.g. political ideology). In these scenarios analysts desire a topic modeling
approach which incorporates their understanding of the corpus while supporting
various forms of interaction with the model. In this work, we present EdTM, as
an approach for label name supervised topic modeling. EdTM models topic
modeling as an assignment problem while leveraging LM/LLM based document-topic
affinities and using optimal transport for making globally coherent
topic-assignments. In experiments, we show the efficacy of our framework
compared to few-shot LLM classifiers, and topic models based on clustering and
LDA. Further, we show EdTM's ability to incorporate various forms of analyst
feedback and while remaining robust to noisy analyst inputs.

摘要：主题模型被广泛用于分析文件集合。虽然当分析师不熟悉语料库时，它们对于在语料库中发现潜在主题非常有价值，但分析师通常也从对语料库中存在的内容的理解开始。这可能是通过对语料库的初始遍历获得的类别，或者是对语料库进行分析的愿望，通过从高级理论框架（例如政治意识形态）中衍生的预定义类别集合。在这些场景中，分析师希望一种主题建模方法，该方法在支持与模型的各种形式的交互的同时，纳入他们对语料库的理解。在这项工作中，我们提出了 EdTM，作为一种用于标签名称监督主题建模的方法。EdTM 将主题建模建模为一个分配问题，同时利用基于 LM/LLM 的文档主题亲和度，并使用最优传输进行全局连贯的主题分配。在实验中，我们展示了与少样本 LLM 分类器以及基于聚类和 LDA 的主题模型相比，我们框架的有效性。此外，我们展示了 EdTM 融合各种形式的分析师反馈的能力，同时对有噪声的分析师输入保持鲁棒性。

##### **Paraphrase Types Elicit Prompt Engineering Capabilities**
2406.19898v1 by Jan Philip Wahle, Terry Ruas, Yang Xu, Bela Gipp

Much of the success of modern language models depends on finding a suitable
prompt to instruct the model. Until now, it has been largely unknown how
variations in the linguistic expression of prompts affect these models. This
study systematically and empirically evaluates which linguistic features
influence models through paraphrase types, i.e., different linguistic changes
at particular positions. We measure behavioral changes for five models across
120 tasks and six families of paraphrases (i.e., morphology, syntax, lexicon,
lexico-syntax, discourse, and others). We also control for other prompt
engineering factors (e.g., prompt length, lexical diversity, and proximity to
training data). Our results show a potential for language models to improve
tasks when their prompts are adapted in specific paraphrase types (e.g., 6.7%
median gain in Mixtral 8x7B; 5.5% in LLaMA 3 8B). In particular, changes in
morphology and lexicon, i.e., the vocabulary used, showed promise in improving
prompts. These findings contribute to developing more robust language models
capable of handling variability in linguistic expression.

摘要：現代語言模型的成功很大程度取決於找到適當的提示來指導模型。到目前為止，提示的語言表達方式的變化如何影響這些模型在很大程度上仍是未知的。本研究系統且經驗性地評估了哪些語言特徵通過同義詞類型（即特定位置的不同語言變化）影響模型。我們針對五個模型在 120 個任務和六個同義詞家族（即形態、句法、詞彙、詞彙句法、語篇等）中測量行為變化。我們還控制其他提示工程因素（例如提示長度、詞彙多樣性和與訓練數據的接近程度）。我們的結果表明，當提示在特定同義詞類型（例如，Mixtral 8x7B 中 6.7% 的中值增益；LLaMA 3 8B 中 5.5%）中進行調整時，語言模型有改進任務的潛力。特別是，形態和詞彙（即所使用的詞彙）的變化顯示出改進提示的希望。這些發現有助於開發更強大的語言模型，能夠處理語言表達中的變異性。

##### **AuthAttLyzer-V2: Unveiling Code Authorship Attribution using Enhanced Ensemble Learning Models & Generating Benchmark Dataset**
2406.19896v1 by Bhaskar Joshi, Sepideh HajiHossein Khani, Arash HabibiLashkari

Source Code Authorship Attribution (SCAA) is crucial for software
classification because it provides insights into the origin and behavior of
software. By accurately identifying the author or group behind a piece of code,
experts can better understand the motivations and techniques of developers. In
the cybersecurity era, this attribution helps trace the source of malicious
software, identify patterns in the code that may indicate specific threat
actors or groups, and ultimately enhance threat intelligence and mitigation
strategies. This paper presents AuthAttLyzer-V2, a new source code feature
extractor for SCAA, focusing on lexical, semantic, syntactic, and N-gram
features. Our research explores author identification in C++ by examining
24,000 source code samples from 3,000 authors. Our methodology integrates
Random Forest, Gradient Boosting, and XGBoost models, enhanced with SHAP for
interpretability. The study demonstrates how ensemble models can effectively
discern individual coding styles, offering insights into the unique attributes
of code authorship. This approach is pivotal in understanding and interpreting
complex patterns in authorship attribution, especially for malware
classification.

摘要：原始碼作者歸屬（SCAA）對於軟體分類至關重要，因為它提供了對軟體起源和行為的見解。透過準確識別程式碼背後的作者或群組，專家可以更了解開發人員的動機和技術。在網路安全時代，這種歸屬有助於追蹤惡意軟體的來源，識別程式碼中可能表明特定威脅行為者或群組的模式，並最終增強威脅情報和緩解策略。本文提出了 AuthAttLyzer-V2，這是一個新的原始碼特徵萃取器，用於 SCAA，專注於詞彙、語義、句法和 N-gram 特徵。我們的研究透過檢驗來自 3,000 位作者的 24,000 個原始碼範例，探討 C++ 中的作者識別。我們的研究方法整合了隨機森林、梯度提升和 XGBoost 模型，並透過 SHAP 增強了解釋性。這項研究展示了整合模型如何有效區分個別的編碼風格，提供對程式碼作者歸屬的獨特屬性的見解。這種方法對於了解和詮釋作者歸屬中的複雜模式至關重要，特別是對於惡意軟體分類。

##### **Untangling the Unrestricted Web: Automatic Identification of Multilingual Registers**
2406.19892v1 by Erik Henriksson, Amanda Myntti, Anni Eskelinen, Selcen Erten-Johansson, Saara Hellström, Veronika Laippala

This article explores deep learning models for the automatic identification
of registers - text varieties such as news reports and discussion forums - in
web-based datasets across 16 languages. Web register (or genre) identification
would provide a robust solution for understanding the content of web-scale
datasets, which have become crucial in computational linguistics. Despite
recent advances, the potential of register classifiers on the noisy web remains
largely unexplored, particularly in multilingual settings and when targeting
the entire unrestricted web. We experiment with a range of deep learning models
using the new Multilingual CORE corpora, which includes 16 languages annotated
using a detailed, hierarchical taxonomy of 25 registers designed to cover the
entire unrestricted web. Our models achieve state-of-the-art results, showing
that a detailed taxonomy in a hierarchical multi-label setting can yield
competitive classification performance. However, all models hit a glass ceiling
at approximately 80% F1 score, which we attribute to the non-discrete nature of
web registers and the inherent uncertainty in labeling some documents. By
pruning ambiguous examples, we improve model performance to over 90%. Finally,
multilingual models outperform monolingual ones, particularly benefiting
languages with fewer training examples and smaller registers. Although a
zero-shot setting decreases performance by an average of 7%, these drops are
not linked to specific registers or languages. Instead, registers show
surprising similarity across languages.

摘要：這篇文章探討了深度學習模型，以自動識別網路資料集中 16 種語言的註冊資訊，例如新聞報導和討論區等文字種類。網路註冊資訊（或類型）識別將提供一個強大的解決方案，用於了解網路規模資料集的內容，而這在計算語言學中已變得至關重要。儘管最近有進展，但註冊分類器在雜訊網路上的潛力仍未得到充分探索，特別是在多語言環境中以及針對整個不受限制的網路時。我們使用新的多語言 CORE 語料庫對一系列深度學習模型進行實驗，其中包括使用詳細的分層分類法註解的 16 種語言，該分類法旨在涵蓋整個不受限制的網路。我們的模型達到了最先進的結果，表明在分層多標籤設定中詳細的分類法可以產生有競爭力的分類效能。然而，所有模型在約 80% 的 F1 分數時都遇到了瓶頸，我們將其歸因於網路註冊資訊的非離散性質以及標籤某些文件時固有的不確定性。透過修剪模稜兩可的範例，我們將模型效能提升至 90% 以上。最後，多語言模型優於單語言模型，特別是對訓練範例較少和註冊資訊較小的語言有益。儘管零次學習設定平均降低了 7% 的效能，但這些下降與特定的註冊資訊或語言無關。相反地，註冊資訊在不同語言中展現出驚人的相似性。

##### **Fine-tuning of Geospatial Foundation Models for Aboveground Biomass Estimation**
2406.19888v1 by Michal Muszynski, Levente Klein, Ademir Ferreira da Silva, Anjani Prasad Atluri, Carlos Gomes, Daniela Szwarcman, Gurkanwar Singh, Kewen Gu, Maciel Zortea, Naomi Simumba, Paolo Fraccaro, Shraddha Singh, Steve Meliksetian, Campbell Watson, Daiki Kimura, Harini Srinivasan

Global vegetation structure mapping is critical for understanding the global
carbon cycle and maximizing the efficacy of nature-based carbon sequestration
initiatives. Moreover, vegetation structure mapping can help reduce the impacts
of climate change by, for example, guiding actions to improve water security,
increase biodiversity and reduce flood risk. Global satellite measurements
provide an important set of observations for monitoring and managing
deforestation and degradation of existing forests, natural forest regeneration,
reforestation, biodiversity restoration, and the implementation of sustainable
agricultural practices. In this paper, we explore the effectiveness of
fine-tuning of a geospatial foundation model to estimate above-ground biomass
(AGB) using space-borne data collected across different eco-regions in Brazil.
The fine-tuned model architecture consisted of a Swin-B transformer as the
encoder (i.e., backbone) and a single convolutional layer for the decoder head.
All results were compared to a U-Net which was trained as the baseline model
Experimental results of this sparse-label prediction task demonstrate that the
fine-tuned geospatial foundation model with a frozen encoder has comparable
performance to a U-Net trained from scratch. This is despite the fine-tuned
model having 13 times less parameters requiring optimization, which saves both
time and compute resources. Further, we explore the transfer-learning
capabilities of the geospatial foundation models by fine-tuning on satellite
imagery with sparse labels from different eco-regions in Brazil.

摘要：全球植被結構繪製對於了解全球碳循環和最大化基於自然碳封存計畫的效能至關重要。此外，植被結構繪製有助於降低氣候變遷的影響，例如，指導改善水資源安全、增加生物多樣性以及降低洪水風險的行動。全球衛星測量提供了一組重要的觀測資料，用於監控和管理現有森林的森林砍伐和退化、天然森林再生、再造林、生物多樣性恢復以及永續農業實務的實施。在本文中，我們探討微調地理空間基礎模型以估計巴西不同生態區域中收集的太空資料中的地上生物量 (AGB) 的有效性。微調後的模型架構包含一個 Swin-B 轉換器作為編碼器（即，主幹）和一個單一卷積層作為解碼器頭。所有結果都與作為基準模型訓練的 U-Net 進行比較。這個稀疏標籤預測任務的實驗結果證明，凍結編碼器的微調地理空間基礎模型與從頭開始訓練的 U-Net 具有相當的效能。儘管微調模型的參數需要最佳化的數量少了 13 倍，這節省了時間和運算資源。此外，我們透過微調來自巴西不同生態區域的稀疏標籤的衛星影像，探討地理空間基礎模型的遷移學習能力。

##### **Investigating the Timescales of Language Processing with EEG and Language Models**
2406.19884v1 by Davide Turco, Conor Houghton

This study explores the temporal dynamics of language processing by examining
the alignment between word representations from a pre-trained transformer-based
language model, and EEG data. Using a Temporal Response Function (TRF) model,
we investigate how neural activity corresponds to model representations across
different layers, revealing insights into the interaction between artificial
language models and brain responses during language comprehension. Our analysis
reveals patterns in TRFs from distinct layers, highlighting varying
contributions to lexical and compositional processing. Additionally, we used
linear discriminant analysis (LDA) to isolate part-of-speech (POS)
representations, offering insights into their influence on neural responses and
the underlying mechanisms of syntactic processing. These findings underscore
EEG's utility for probing language processing dynamics with high temporal
resolution. By bridging artificial language models and neural activity, this
study advances our understanding of their interaction at fine timescales.

摘要：本研究透過探討字詞表徵與預先訓練的轉換器語言模型之間的對齊，以及 EEG 資料，來探討語言處理的時間動態。我們使用時間反應函數 (TRF) 模型，來探討神經活動如何與不同層級的模型表徵相符，揭露人工語言模型與大腦在語言理解過程中反應之間的互動。我們的分析揭露了不同層級 TRF 的模式，突顯了其對字彙和組合處理的不同貢獻。此外，我們使用線性判別分析 (LDA) 來分離詞性 (POS) 表徵，提供對其對神經反應和句法處理基礎機制的影響的見解。這些發現強調了 EEG 在以高時間解析度探測語言處理動態方面的效用。透過連結人工語言模型和神經活動，本研究增進了我們對其在精細時間尺度上互動的理解。

##### **Detecting Subtle Differences between Human and Model Languages Using Spectrum of Relative Likelihood**
2406.19874v1 by Yang Xu, Yu Wang, Hao An, Zhichen Liu, Yongyuan Li

Human and model-generated texts can be distinguished by examining the
magnitude of likelihood in language. However, it is becoming increasingly
difficult as language model's capabilities of generating human-like texts keep
evolving. This study provides a new perspective by using the relative
likelihood values instead of absolute ones, and extracting useful features from
the spectrum-view of likelihood for the human-model text detection task. We
propose a detection procedure with two classification methods, supervised and
heuristic-based, respectively, which results in competitive performances with
previous zero-shot detection methods and a new state-of-the-art on short-text
detection. Our method can also reveal subtle differences between human and
model languages, which find theoretical roots in psycholinguistics studies. Our
code is available at https://github.com/CLCS-SUSTech/FourierGPT

摘要：人類和模型產生的文本可以透過檢視語言中可能性的大小來加以區分。然而，隨著語言模型產生類人文本的能力不斷演進，這項任務正變得越來越困難。本研究透過使用相對可能性值而非絕對值，並從人類模型文本偵測任務的可能性光譜圖中萃取出有用的特徵，提供了一個新的觀點。我們提出一個偵測程序，包含兩種分類方法，分別是監督式和啟發式，其效能與先前的零次學習偵測方法相近，並在短文本偵測中樹立新的技術標竿。我們的模型也可以揭示人類語言和模型語言之間的細微差異，這些差異在心理語言學研究中具有理論依據。我們的程式碼可在 https://github.com/CLCS-SUSTech/FourierGPT 獲得。

##### **MetaDesigner: Advancing Artistic Typography through AI-Driven, User-Centric, and Multilingual WordArt Synthesis**
2406.19859v1 by Jun-Yan He, Zhi-Qi Cheng, Chenyang Li, Jingdong Sun, Qi He, Wangmeng Xiang, Hanyuan Chen, Jin-Peng Lan, Xianhui Lin, Kang Zhu, Bin Luo, Yifeng Geng, Xuansong Xie, Alexander G. Hauptmann

MetaDesigner revolutionizes artistic typography synthesis by leveraging the
strengths of Large Language Models (LLMs) to drive a design paradigm centered
around user engagement. At the core of this framework lies a multi-agent system
comprising the Pipeline, Glyph, and Texture agents, which collectively enable
the creation of customized WordArt, ranging from semantic enhancements to the
imposition of complex textures. MetaDesigner incorporates a comprehensive
feedback mechanism that harnesses insights from multimodal models and user
evaluations to refine and enhance the design process iteratively. Through this
feedback loop, the system adeptly tunes hyperparameters to align with
user-defined stylistic and thematic preferences, generating WordArt that not
only meets but exceeds user expectations of visual appeal and contextual
relevance. Empirical validations highlight MetaDesigner's capability to
effectively serve diverse WordArt applications, consistently producing
aesthetically appealing and context-sensitive results.

摘要：MetaDesigner 透過運用大型語言模型 (LLM) 的優勢，徹底革新了藝術字體合成，並以使用者參與為核心，驅動設計範例。此架構的核心是一個多代理系統，包含 Pipeline、Glyph 和 Texture 代理，它們共同實現客製化文字藝術的創作，從語義增強到複雜紋理的套用。MetaDesigner 結合了一個全面的回饋機制，利用多模態模型和使用者評估的見解，反覆精進和增強設計流程。透過這個回饋迴路，系統靈活地調整超參數，以符合使用者定義的風格和主題偏好，產生的文字藝術不僅滿足，更超越了使用者對於視覺吸引力和脈絡相關性的期待。實證驗證突顯了 MetaDesigner 有效服務於各種文字藝術應用程式的能力，始終產生美觀且符合脈絡的結果。

##### **YuLan: An Open-source Large Language Model**
2406.19853v1 by Yutao Zhu, Kun Zhou, Kelong Mao, Wentong Chen, Yiding Sun, Zhipeng Chen, Qian Cao, Yihan Wu, Yushuo Chen, Feng Wang, Lei Zhang, Junyi Li, Xiaolei Wang, Lei Wang, Beichen Zhang, Zican Dong, Xiaoxue Cheng, Yuhan Chen, Xinyu Tang, Yupeng Hou, Qiangqiang Ren, Xincheng Pang, Shufang Xie, Wayne Xin Zhao, Zhicheng Dou, Jiaxin Mao, Yankai Lin, Ruihua Song, Jun Xu, Xu Chen, Rui Yan, Zhewei Wei, Di Hu, Wenbing Huang, Ze-Feng Gao, Yueguo Chen, Weizheng Lu, Ji-Rong Wen

Large language models (LLMs) have become the foundation of many applications,
leveraging their extensive capabilities in processing and understanding natural
language. While many open-source LLMs have been released with technical
reports, the lack of training details hinders further research and development.
This paper presents the development of YuLan, a series of open-source LLMs with
$12$ billion parameters. The base model of YuLan is pre-trained on
approximately $1.7$T tokens derived from a diverse corpus, including massive
English, Chinese, and multilingual texts. We design a three-stage pre-training
method to enhance YuLan's overall capabilities. Subsequent phases of training
incorporate instruction-tuning and human alignment, employing a substantial
volume of high-quality synthesized data. To facilitate the learning of complex
and long-tail knowledge, we devise a curriculum-learning framework throughout
across these stages, which helps LLMs learn knowledge in an easy-to-hard
manner. YuLan's training is finished on Jan, 2024 and has achieved performance
on par with state-of-the-art LLMs across various English and Chinese
benchmarks. This paper outlines a comprehensive technical roadmap for
developing LLMs from scratch. Our model and codes are available at
https://github.com/RUC-GSAI/YuLan-Chat.

摘要：大型語言模型 (LLM) 已成為許多應用程式的基礎，
利用它們在處理和理解自然語言方面的廣泛能力。雖然許多開源 LLM 已發布技術報告，但缺乏訓練細節會阻礙進一步的研究和開發。
本文介紹了 YuLan 的開發，YuLan 是一系列具有
$12$ 億個參數的開源 LLM。YuLan 的基礎模型經過預先訓練
約 $1.7$T 個衍生自多元語料庫的 token，包括大量的
英文、中文和多語言文字。我們設計了一個三階段預訓練
方法來增強 YuLan 的整體能力。後續的訓練階段
結合了指令微調和人類對齊，採用大量高品質的合成資料。為促進複雜
和長尾知識的學習，我們在這些階段中設計了一個課程學習架構，這有助於 LLM 以由易到難的方式學習知識。YuLan 的訓練於 2024 年 1 月完成，並已達成與各種英語和中文
基準測試中最先進的 LLM 相當的效能。本文概述了一個全面的技術路線圖，說明如何從頭開始開發 LLM。我們的模型和程式碼可在
https://github.com/RUC-GSAI/YuLan-Chat 取得。

##### **AnomaLLMy -- Detecting anomalous tokens in black-box LLMs through low-confidence single-token predictions**
2406.19840v1 by Waligóra Witold

This paper introduces AnomaLLMy, a novel technique for the automatic
detection of anomalous tokens in black-box Large Language Models (LLMs) with
API-only access. Utilizing low-confidence single-token predictions as a
cost-effective indicator, AnomaLLMy identifies irregularities in model
behavior, addressing the issue of anomalous tokens degrading the quality and
reliability of models. Validated on the cl100k_base dataset, the token set of
GPT-4, AnomaLLMy detected 413 major and 65 minor anomalies, demonstrating the
method's efficiency with just \$24.39 spent in API credits. The insights from
this research are expected to be beneficial for enhancing the robustness of and
accuracy of LLMs, particularly in the development and assessment of tokenizers.

摘要：這篇論文介紹了 AnomaLLMy，這是一種新技術，用於自動偵測黑盒大型語言模型 (LLM) 中異常的標記，且僅使用 API 存取。利用低信心的單一標記預測作為一種具成本效益的指標，AnomaLLMy 能識別模型行為中的異常，解決異常標記會降低模型品質和可靠性的問題。在 cl100k_base 資料集上驗證，GPT-4 的標記集，AnomaLLMy 偵測到 413 個主要異常和 65 個次要異常，證明了這種方法的效率，僅花費 24.39 美元的 API 點數。預期這項研究的見解將有助於增強 LLM 的穩健性和準確性，特別是在標記器的開發和評估方面。

##### **BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering**
2406.19820v1 by Zheng Chu, Jingchang Chen, Qianglong Chen, Haotian Wang, Kun Zhu, Xiyuan Du, Weijiang Yu, Ming Liu, Bing Qin

Large language models (LLMs) have demonstrated strong reasoning capabilities.
Nevertheless, they still suffer from factual errors when tackling
knowledge-intensive tasks. Retrieval-augmented reasoning represents a promising
approach. However, significant challenges still persist, including inaccurate
and insufficient retrieval for complex questions, as well as difficulty in
integrating multi-source knowledge. To address this, we propose Beam
Aggregation Reasoning, BeamAggR, a reasoning framework for knowledge-intensive
multi-hop QA. BeamAggR explores and prioritizes promising answers at each hop
of question. Concretely, we parse the complex questions into trees, which
include atom and composite questions, followed by bottom-up reasoning. For
atomic questions, the LLM conducts reasoning on multi-source knowledge to get
answer candidates. For composite questions, the LLM combines beam candidates,
explores multiple reasoning paths through probabilistic aggregation, and
prioritizes the most promising trajectory. Extensive experiments on four
open-domain multi-hop reasoning datasets show that our method significantly
outperforms SOTA methods by 8.5%. Furthermore, our analysis reveals that
BeamAggR elicits better knowledge collaboration and answer aggregation.

摘要：大型語言模型 (LLM) 已展現強大的推理能力。
然而，在處理知識密集型任務時，它們仍然會出現事實錯誤。檢索增強推理代表一種有前途的方法。然而，仍然存在重大挑戰，包括複雜問題的不準確和不充分檢索，以及整合多來源知識的難度。為了解決此問題，我們提出了 Beam 聚合推理 BeamAggR，這是一個針對知識密集型多跳問答的推理框架。BeamAggR 在問題的每一個跳躍點探索並優先考慮有希望的答案。具體來說，我們將複雜問題解析為樹狀結構，其中包括原子問題和複合問題，然後進行自下而上的推理。對於原子問題，LLM 對多來源知識進行推理以獲取答案候選項。對於複合問題，LLM 結合了 beam 候選項，通過機率聚合探索多個推理路徑，並優先考慮最有希望的軌跡。在四個開放領域多跳推理數據集上進行的廣泛實驗表明，我們的模型比 SOTA 方法顯著優於 8.5%。此外，我們的分析表明 BeamAggR 引發了更好的知識協作和答案聚合。

##### **Deceptive Diffusion: Generating Synthetic Adversarial Examples**
2406.19807v1 by Lucas Beerens, Catherine F. Higham, Desmond J. Higham

We introduce the concept of deceptive diffusion -- training a generative AI
model to produce adversarial images. Whereas a traditional adversarial attack
algorithm aims to perturb an existing image to induce a misclassificaton, the
deceptive diffusion model can create an arbitrary number of new, misclassified
images that are not directly associated with training or test images. Deceptive
diffusion offers the possibility of strengthening defence algorithms by
providing adversarial training data at scale, including types of
misclassification that are otherwise difficult to find. In our experiments, we
also investigate the effect of training on a partially attacked data set. This
highlights a new type of vulnerability for generative diffusion models: if an
attacker is able to stealthily poison a portion of the training data, then the
resulting diffusion model will generate a similar proportion of misleading
outputs.

摘要：我們引入了欺騙性擴散的概念 -- 訓練生成式 AI 模型來產生對抗性影像。傳統的對抗性攻擊演算法旨在擾動現有影像以誘發錯誤分類，而欺騙性擴散模型可以產生任意數量的全新、錯誤分類的影像，這些影像與訓練或測試影像沒有直接關聯。欺騙性擴散提供了透過大規模提供對抗性訓練資料來強化防禦演算法的可能性，包括其他難以找到的錯誤分類類型。在我們的實驗中，我們也研究了在部分受攻擊資料集上訓練的效果。這突顯了生成式擴散模型的一種類型新漏洞：如果攻擊者能夠秘密毒害訓練資料的一部分，則產生的擴散模型將產生類似比例的誤導輸出。

##### **Scalable and Domain-General Abstractive Proposition Segmentation**
2406.19803v1 by Mohammad Javad Hosseini, Yang Gao, Tim Baumgärtner, Alex Fabrikant, Reinald Kim Amplayo

Segmenting text into fine-grained units of meaning is important to a wide
range of NLP applications. The default approach of segmenting text into
sentences is often insufficient, especially since sentences are usually complex
enough to include multiple units of meaning that merit separate treatment in
the downstream task. We focus on the task of abstractive proposition
segmentation: transforming text into simple, self-contained, well-formed
sentences. Several recent works have demonstrated the utility of proposition
segmentation with few-shot prompted LLMs for downstream tasks such as
retrieval-augmented grounding and fact verification. However, this approach
does not scale to large amounts of text and may not always extract all the
facts from the input text. In this paper, we first introduce evaluation metrics
for the task to measure several dimensions of quality. We then propose a
scalable, yet accurate, proposition segmentation model. We model proposition
segmentation as a supervised task by training LLMs on existing annotated
datasets and show that training yields significantly improved results. We
further show that by using the fine-tuned LLMs as teachers for annotating large
amounts of multi-domain synthetic distillation data, we can train smaller
student models with results similar to the teacher LLMs. We then demonstrate
that our technique leads to effective domain generalization, by annotating data
in two domains outside the original training data and evaluating on them.
Finally, as a key contribution of the paper, we share an easy-to-use API for
NLP practitioners to use.

摘要：將文字區分為細緻的意義單位對於廣泛的 NLP 應用非常重要。將文字區分為句子的預設方法通常不夠用，特別是因為句子通常夠複雜，足以包含多個意義單位，這些單位在下游任務中值得分開處理。我們專注於抽象命題區分的任務：將文字轉換為簡單、獨立、格式良好的句子。最近的幾項工作已經證明了命題區分與少樣本提示 LLM 在下游任務（例如檢索增強基礎和事實驗證）中的效用。然而，這種方法無法擴展到大量文字，而且可能無法總是從輸入文字中提取所有事實。在本文中，我們首先介紹任務的評估指標，以衡量品質的幾個面向。然後，我們提出一個可擴展且準確的命題區分模型。我們將命題區分建模為一個監督式任務，方法是在現有的註解資料集上訓練 LLM，並顯示訓練會產生顯著改善的結果。我們進一步表明，透過使用微調後的 LLM 作為教師來註解大量多領域合成蒸餾資料，我們可以使用結果與教師 LLM 類似的較小的學生模型進行訓練。然後，我們證明我們的技術會導致有效的領域概化，方法是在原始訓練資料之外的兩個領域中註解資料並在這些領域進行評估。最後，作為本文的主要貢獻，我們分享一個易於使用的 API，供 NLP 從業者使用。

##### **NLPerturbator: Studying the Robustness of Code LLMs to Natural Language Variations**
2406.19783v1 by Junkai Chen, Zhenhao Li, Xing Hu, Xin Xia

Large language models (LLMs) achieve promising results in code generation
based on a given natural language description. They have been integrated into
open-source projects and commercial products to facilitate daily coding
activities. The natural language description in the prompt is crucial for LLMs
to comprehend users' requirements. Prior studies uncover that LLMs are
sensitive to the changes in the prompts, including slight changes that look
inconspicuous. However, the natural language descriptions often vary in
real-world scenarios (e.g., different formats, grammar, and wording). Prior
studies on the robustness of LLMs are often based on random perturbations and
such perturbations may not actually happen. In this paper, we conduct a
comprehensive study to investigate how are code LLMs robust to variations of
natural language description in real-world scenarios. We summarize 18
categories of perturbations of natural language and 3 combinations of
co-occurred categories based on our literature review and an online survey with
practitioners. We propose an automated framework, NLPerturbator, which can
perform perturbations of each category given a set of prompts. Through a series
of experiments on code generation using six code LLMs, we find that the
perturbed prompts can decrease the performance of code generation by a
considerable margin (e.g., up to 21.2%, and 4.8% to 6.1% on average). Our study
highlights the importance of enhancing the robustness of LLMs to real-world
variations in the prompts, as well as the essentiality of attentively
constructing the prompts.

摘要：大型語言模型 (LLM) 在基於給定的自然語言描述的程式碼生成中取得了令人滿意的成果。它們已被整合到開源專案和商業產品中，以促進日常編碼活動。提示中的自然語言描述對於 LLM 理解使用者的需求至關重要。先前的研究發現，LLM 對提示的變化很敏感，包括看起來不顯眼的細微變化。然而，自然語言描述在實際場景中通常有所不同（例如，不同的格式、語法和措辭）。先前關於 LLM 穩健性的研究通常基於隨機擾動，而這種擾動可能並未實際發生。在本文中，我們進行了一項全面的研究，以調查在實際場景中，程式碼 LLM 如何對自然語言描述的變化保持穩健性。我們根據文獻回顧和從業人員的線上調查，總結了 18 類自然語言擾動和 3 種共現類別的組合。我們提出了一個自動化框架 NLPerturbator，它可以在給定一組提示的情況下對每個類別進行擾動。透過對使用六個程式碼 LLM 進行程式碼生成的系列實驗，我們發現擾動的提示會在相當大的程度上下降程式碼生成的效能（例如，最多 21.2%，平均 4.8% 到 6.1%）。我們的研究強調了增強 LLM 對提示中實際變化的穩健性的重要性，以及仔細建構提示的必要性。

##### **Direct Preference Knowledge Distillation for Large Language Models**
2406.19774v1 by Yixing Li, Yuxian Gu, Li Dong, Dequan Wang, Yu Cheng, Furu Wei

In the field of large language models (LLMs), Knowledge Distillation (KD) is
a critical technique for transferring capabilities from teacher models to
student models. However, existing KD methods face limitations and challenges in
distillation of LLMs, including efficiency and insufficient measurement
capabilities of traditional KL divergence. It is shown that LLMs can serve as
an implicit reward function, which we define as a supplement to KL divergence.
In this work, we propose Direct Preference Knowledge Distillation (DPKD) for
LLMs. DPKD utilizes distribution divergence to represent the preference loss
and implicit reward function. We re-formulate KD of LLMs into two stages: first
optimizing and objective consisting of implicit reward and reverse KL
divergence and then improving the preference probability of teacher outputs
over student outputs. We conducted experiments and analysis on various datasets
with LLM parameters ranging from 120M to 13B and demonstrate the broad
applicability and effectiveness of our DPKD approach. Meanwhile, we prove the
value and effectiveness of the introduced implicit reward and output preference
in KD through experiments and theoretical analysis. The DPKD method outperforms
the baseline method in both output response precision and exact match
percentage. Code and data are available at https://aka.ms/dpkd.

摘要：在大语言模型（LLM）领域，知识蒸馏（KD）是一种将功能从教师模型转移到学生模型的关键技术。然而，现有的 KD 方法在 LLM 的蒸馏中面临着局限性和挑战，包括效率和传统 KL 散度的测量能力不足。结果表明，LLM 可以作为一种隐式奖励函数，我们将其定义为 KL 散度的补充。在这项工作中，我们提出了用于 LLM 的直接偏好知识蒸馏 (DPKD)。DPKD 利用分布散度来表示偏好损失和隐式奖励函数。我们将 LLM 的 KD 重新表述为两个阶段：首先优化由隐式奖励和反向 KL 散度组成的目标，然后提高教师输出相对于学生输出的偏好概率。我们对具有从 120M 到 13B 的 LLM 参数的各种数据集进行了实验和分析，并展示了我们 DPKD 方法的广泛适用性和有效性。同时，我们通过实验和理论分析证明了引入的隐式奖励和输出偏好在 KD 中的价值和有效性。DPKD 方法在输出响应精度和完全匹配百分比方面都优于基线方法。代码和数据可在 https://aka.ms/dpkd 获得。

##### **Self-Supervised Spatial-Temporal Normality Learning for Time Series Anomaly Detection**
2406.19770v1 by Yutong Chen, Hongzuo Xu, Guansong Pang, Hezhe Qiao, Yuan Zhou, Mingsheng Shang

Time Series Anomaly Detection (TSAD) finds widespread applications across
various domains such as financial markets, industrial production, and
healthcare. Its primary objective is to learn the normal patterns of time
series data, thereby identifying deviations in test samples. Most existing TSAD
methods focus on modeling data from the temporal dimension, while ignoring the
semantic information in the spatial dimension. To address this issue, we
introduce a novel approach, called Spatial-Temporal Normality learning (STEN).
STEN is composed of a sequence Order prediction-based Temporal Normality
learning (OTN) module that captures the temporal correlations within sequences,
and a Distance prediction-based Spatial Normality learning (DSN) module that
learns the relative spatial relations between sequences in a feature space. By
synthesizing these two modules, STEN learns expressive spatial-temporal
representations for the normal patterns hidden in the time series data.
Extensive experiments on five popular TSAD benchmarks show that STEN
substantially outperforms state-of-the-art competing methods. Our code is
available at https://github.com/mala-lab/STEN.

摘要：時間序列異常偵測 (TSAD) 在金融市場、工業生產和醫療保健等各種領域中廣泛應用。其主要目的是學習時間序列資料的正常模式，從而識別測試樣本中的偏差。現有的 TSAD 方法大多專注於對時間維度資料進行建模，而忽略了空間維度中的語義資訊。為了解決這個問題，我們提出了一種新的方法，稱為時空常態學習 (STEN)。STEN 由一個基於序列順序預測的時間常態學習 (OTN) 模組組成，它擷取序列中的時間相關性，以及一個基於距離預測的空間常態學習 (DSN) 模組，它學習特徵空間中序列之間的相對空間關係。通過綜合這兩個模組，STEN 學習時間序列資料中隱藏的正常模式的表現性時空表示。在五個流行的 TSAD 基準上進行的廣泛實驗表明，STEN 大幅優於最先進的競爭方法。我們的程式碼可在 https://github.com/mala-lab/STEN 取得。

##### **Belief Revision: The Adaptability of Large Language Models Reasoning**
2406.19764v1 by Bryan Wilie, Samuel Cahyawijaya, Etsuko Ishii, Junxian He, Pascale Fung

The capability to reason from text is crucial for real-world NLP
applications. Real-world scenarios often involve incomplete or evolving data.
In response, individuals update their beliefs and understandings accordingly.
However, most existing evaluations assume that language models (LMs) operate
with consistent information. We introduce Belief-R, a new dataset designed to
test LMs' belief revision ability when presented with new evidence. Inspired by
how humans suppress prior inferences, this task assesses LMs within the newly
proposed delta reasoning ($\Delta R$) framework. Belief-R features sequences of
premises designed to simulate scenarios where additional information could
necessitate prior conclusions drawn by LMs. We evaluate $\sim$30 LMs across
diverse prompting strategies and found that LMs generally struggle to
appropriately revise their beliefs in response to new information. Further,
models adept at updating often underperformed in scenarios without necessary
updates, highlighting a critical trade-off. These insights underscore the
importance of improving LMs' adaptiveness to changing information, a step
toward more reliable AI systems.

摘要：文本推理能力對於真實世界的自然語言處理應用至關重要。真實世界的場景通常涉及不完整或不斷演化的數據。為了解決這個問題，人們會相應地更新他們的信念和理解。然而，現有的評估大多假設語言模型 (LM) 處理的是一致的資訊。我們引入了 Belief-R，這是一個新的數據集，旨在測試 LM 在獲得新證據時修正信念的能力。受人類如何抑制先驗推論的啟發，此任務在我們新提出的 delta 推理（$\Delta R$）框架內評估 LM。Belief-R 具有旨在模擬場景的假設序列，在這些場景中，額外資訊可能會導致 LM 得出的先驗結論。我們在不同的提示策略中評估了 $\sim$30 個 LM，發現 LM 通常難以適當地修正其對新資訊的信念。此外，擅長更新的模型通常在不需要更新的場景中表現不佳，突顯了一個重要的權衡。這些見解強調了提高 LM 適應不斷變化的資訊的重要性，這是邁向更可靠的 AI 系統的一步。

##### **xSemAD: Explainable Semantic Anomaly Detection in Event Logs Using Sequence-to-Sequence Models**
2406.19763v1 by Kiran Busch, Timotheus Kampik, Henrik Leopold

The identification of undesirable behavior in event logs is an important
aspect of process mining that is often addressed by anomaly detection methods.
Traditional anomaly detection methods tend to focus on statistically rare
behavior and neglect the subtle difference between rarity and undesirability.
The introduction of semantic anomaly detection has opened a promising avenue by
identifying semantically deviant behavior. This work addresses a gap in
semantic anomaly detection, which typically indicates the occurrence of an
anomaly without explaining the nature of the anomaly. We propose xSemAD, an
approach that uses a sequence-to-sequence model to go beyond pure
identification and provides extended explanations. In essence, our approach
learns constraints from a given process model repository and then checks
whether these constraints hold in the considered event log. This approach not
only helps understand the specifics of the undesired behavior, but also
facilitates targeted corrective actions. Our experiments demonstrate that our
approach outperforms existing state-of-the-art semantic anomaly detection
methods.

摘要：事件記錄中不良行為的識別是流程探勘中的一個重要面向，通常由異常偵測方法來處理。傳統的異常偵測方法傾向於關注統計上罕見的行為，而忽略了罕見與不良之間的細微差異。語義異常偵測的引入開闢了一條有前景的途徑，透過識別語義偏差行為。這項工作解決了語義異常偵測中的差距，這通常表示異常的發生，但沒有解釋異常的性質。我們提出 xSemAD，這是一種使用序列對序列模型的方法，超越純粹的識別並提供延伸的解釋。從本質上來說，我們的做法從給定的流程模型儲存庫中學習約束，然後檢查這些約束是否在所考慮的事件記錄中成立。這種方法不僅有助於了解不良行為的具體情況，也有助於採取有針對性的矯正措施。我們的實驗證明，我們的做法優於現有的最先進語義異常偵測方法。

##### **Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation**
2406.19760v1 by Chenlong Deng, Kelong Mao, Zhicheng Dou

Legal case retrieval for sourcing similar cases is critical in upholding
judicial fairness. Different from general web search, legal case retrieval
involves processing lengthy, complex, and highly specialized legal documents.
Existing methods in this domain often overlook the incorporation of legal
expert knowledge, which is crucial for accurately understanding and modeling
legal cases, leading to unsatisfactory retrieval performance. This paper
introduces KELLER, a legal knowledge-guided case reformulation approach based
on large language models (LLMs) for effective and interpretable legal case
retrieval. By incorporating professional legal knowledge about crimes and law
articles, we enable large language models to accurately reformulate the
original legal case into concise sub-facts of crimes, which contain the
essential information of the case. Extensive experiments on two legal case
retrieval benchmarks demonstrate superior retrieval performance and robustness
on complex legal case queries of KELLER over existing methods.

摘要：法律案例檢索對於尋找類似的案例至關重要，以維護司法公正。與一般網路檢索不同，法律案例檢索涉及處理冗長、複雜且高度專業的法律文件。此領域現有方法通常忽略納入法律專家知識，而這對於準確理解和建模法律案例至關重要，導致檢索績效不佳。本文介紹 KELLER，一種基於大型語言模型 (LLM) 的法律知識引導案例重述方法，用於有效且可解釋的法律案例檢索。透過納入有關犯罪和法律條文的專業法律知識，我們讓大型語言模型能夠準確地將原始法律案例重新表述為簡潔的犯罪子事實，其中包含案件的基本資訊。在兩個法律案例檢索基準上進行的廣泛實驗，證明了 KELLER 在複雜的法律案例查詢上，比現有方法具有優異的檢索效能和穩健性。

##### **Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment**
2406.19759v1 by Orgest Xhelili, Yihong Liu, Hinrich Schütze

Multilingual pre-trained models (mPLMs) have shown impressive performance on
cross-lingual transfer tasks. However, the transfer performance is often
hindered when a low-resource target language is written in a different script
than the high-resource source language, even though the two languages may be
related or share parts of their vocabularies. Inspired by recent work that uses
transliteration to address this problem, our paper proposes a
transliteration-based post-pretraining alignment (PPA) method aiming to improve
the cross-lingual alignment between languages using diverse scripts. We select
two areal language groups, $\textbf{Mediterranean-Amharic-Farsi}$ and
$\textbf{South+East Asian Languages}$, wherein the languages are mutually
influenced but use different scripts. We apply our method to these language
groups and conduct extensive experiments on a spectrum of downstream tasks. The
results show that after PPA, models consistently outperform the original model
(up to 50% for some tasks) in English-centric transfer. In addition, when we
use languages other than English as sources in transfer, our method obtains
even larger improvements. We will make our code and models publicly available
at \url{https://github.com/cisnlp/Transliteration-PPA}.

摘要：多語言預訓練模型 (mPLM) 在跨語言轉移任務上展現了令人印象深刻的表現。然而，即使兩種語言可能相關或共享部分詞彙，當低資源目標語言以不同於高資源原始語言的文字書寫時，轉移表現通常會受到阻礙。受到近期使用音譯來解決此問題的研究啟發，我們的論文提出了一種基於音譯的後預訓練對齊 (PPA) 方法，旨在改善使用不同文字的語言之間的跨語言對齊。我們選擇了兩個區域語言群，$\textbf{地中海-阿姆哈拉-波斯語}$ 和 $\textbf{南亞+東南亞語言}$，其中語言相互影響但使用不同的文字。我們將方法應用於這些語言群，並對一系列下游任務進行廣泛的實驗。結果顯示，在 PPA 之後，模型在以英語為中心的轉移中持續優於原始模型（某些任務最多可達 50%）。此外，當我們在轉移中使用除英語之外的語言作為來源時，我們的模型獲得了更大的進步。我們將在 \url{https://github.com/cisnlp/Transliteration-PPA} 公開我們的程式碼和模型。

##### **Structure-aware World Model for Probe Guidance via Large-scale Self-supervised Pre-train**
2406.19756v1 by Haojun Jiang, Meng Li, Zhenguo Sun, Ning Jia, Yu Sun, Shaqi Luo, Shiji Song, Gao Huang

The complex structure of the heart leads to significant challenges in
echocardiography, especially in acquisition cardiac ultrasound images.
Successful echocardiography requires a thorough understanding of the structures
on the two-dimensional plane and the spatial relationships between planes in
three-dimensional space. In this paper, we innovatively propose a large-scale
self-supervised pre-training method to acquire a cardiac structure-aware world
model. The core innovation lies in constructing a self-supervised task that
requires structural inference by predicting masked structures on a 2D plane and
imagining another plane based on pose transformation in 3D space. To support
large-scale pre-training, we collected over 1.36 million echocardiograms from
ten standard views, along with their 3D spatial poses. In the downstream probe
guidance task, we demonstrate that our pre-trained model consistently reduces
guidance errors across the ten most common standard views on the test set with
0.29 million samples from 74 routine clinical scans, indicating that
structure-aware pre-training benefits the scanning.

摘要：心脏复杂的结构导致超音波心动图检查面临重大挑战，特别是在获取心脏超音波影像时。成功的超音波心动图检查需要透彻了解二维平面上的结构以及三维空间中各平面之间的空间关系。在本文中，我们创新性地提出了一种大规模自我监督预训练方法，以获取心脏结构感知的世界模型。核心创新在于构建一项自我监督任务，该任务需要通过预测 2D 平面上的遮罩结构并在 3D 空间中基于姿态转换想象另一个平面来进行结构推理。为了支持大规模预训练，我们从十个标准视图中收集了超过 136 万个超音波心动图，以及它们的 3D 空间姿态。在下游探头引导任务中，我们证明了我们的预训练模型在测试集上持续减少了十个最常见标准视图的引导误差，其中包含来自 74 个常规临床扫描的 0.29 百万个样本，表明感知结构的预训练有利于扫描。

##### **Protein Representation Learning with Sequence Information Embedding: Does it Always Lead to a Better Performance?**
2406.19755v1 by Yang Tan, Lirong Zheng, Bozitao Zhong, Liang Hong, Bingxin Zhou

Deep learning has become a crucial tool in studying proteins. While the
significance of modeling protein structure has been discussed extensively in
the literature, amino acid types are typically included in the input as a
default operation for many inference tasks. This study demonstrates with
structure alignment task that embedding amino acid types in some cases may not
help a deep learning model learn better representation. To this end, we propose
ProtLOCA, a local geometry alignment method based solely on amino acid
structure representation. The effectiveness of ProtLOCA is examined by a global
structure-matching task on protein pairs with an independent test dataset based
on CATH labels. Our method outperforms existing sequence- and structure-based
representation learning methods by more quickly and accurately matching
structurally consistent protein domains. Furthermore, in local structure
pairing tasks, ProtLOCA for the first time provides a valid solution to
highlight common local structures among proteins with different overall
structures but the same function. This suggests a new possibility for using
deep learning methods to analyze protein structure to infer function.

摘要：深度学习已成为研究蛋白质的关键工具。虽然在文献中已广泛讨论了蛋白质结构建模的重要性，但氨基酸类型通常作为许多推理任务的默认操作包含在输入中。本研究通过结构比对任务证明，在某些情况下，嵌入氨基酸类型可能无助于深度学习模型学习更好的表示。为此，我们提出了 ProtLOCA，这是一种仅基于氨基酸结构表示的局部几何比对方法。ProtLOCA 的有效性通过基于 CATH 标签的独立测试数据集对蛋白质对进行全局结构匹配任务来检验。我们的方法通过更快速、更准确地匹配结构一致的蛋白质结构域，优于现有的基于序列和结构的表示学习方法。此外，在局部结构配对任务中，ProtLOCA 首次提供了一个有效的解决方案，用于突出具有不同整体结构但相同功能的蛋白质之间的共同局部结构。这为使用深度学习方法分析蛋白质结构以推断功能提出了新的可能性。

##### **ROS-LLM: A ROS framework for embodied AI with task feedback and structured reasoning**
2406.19741v1 by Christopher E. Mower, Yuhui Wan, Hongzhan Yu, Antoine Grosnit, Jonas Gonzalez-Billandon, Matthieu Zimmer, Jinlong Wang, Xinyu Zhang, Yao Zhao, Anbang Zhai, Puze Liu, Davide Tateo, Cesar Cadena, Marco Hutter, Jan Peters, Guangjian Tian, Yuzheng Zhuang, Kun Shao, Xingyue Quan, Jianye Hao, Jun Wang, Haitham Bou-Ammar

We present a framework for intuitive robot programming by non-experts,
leveraging natural language prompts and contextual information from the Robot
Operating System (ROS). Our system integrates large language models (LLMs),
enabling non-experts to articulate task requirements to the system through a
chat interface. Key features of the framework include: integration of ROS with
an AI agent connected to a plethora of open-source and commercial LLMs,
automatic extraction of a behavior from the LLM output and execution of ROS
actions/services, support for three behavior modes (sequence, behavior tree,
state machine), imitation learning for adding new robot actions to the library
of possible actions, and LLM reflection via human and environment feedback.
Extensive experiments validate the framework, showcasing robustness,
scalability, and versatility in diverse scenarios, including long-horizon
tasks, tabletop rearrangements, and remote supervisory control. To facilitate
the adoption of our framework and support the reproduction of our results, we
have made our code open-source. You can access it at:
https://github.com/huawei-noah/HEBO/tree/master/ROSLLM.

摘要：<paragraph>我們提出一個非專家直覺式機器人程式設計架構，
利用自然語言提示和機器人作業系統 (ROS) 的背景資訊。我們的系統整合大型語言模型 (LLM)，
讓非專家能透過聊天介面清楚表達任務需求給系統。架構的主要特色包含：將 ROS 整合到連接大量開源和商業 LLM 的 AI 代理，
自動從 LLM 輸出中萃取行為並執行 ROS 動作/服務，支援三種行為模式（序列、行為樹、狀態機），
模擬學習將新的機器人動作加入到可能的動作庫中，以及透過人類和環境回饋進行 LLM 反思。
廣泛的實驗驗證了這個架構，展示了在各種情境中的穩健性、可擴充性和多功能性，包括長時程任務、桌面重新排列和遠端監督控制。為了促進我們架構的採用並支援我們結果的重現，我們已將我們的程式碼開源。您可以在以下位置取得：
https://github.com/huawei-noah/HEBO/tree/master/ROSLLM。</paragraph>

##### **MM-Instruct: Generated Visual Instructions for Large Multimodal Model Alignment**
2406.19736v1 by Jihao Liu, Xin Huang, Jinliang Zheng, Boxiao Liu, Jia Wang, Osamu Yoshie, Yu Liu, Hongsheng Li

This paper introduces MM-Instruct, a large-scale dataset of diverse and
high-quality visual instruction data designed to enhance the
instruction-following capabilities of large multimodal models (LMMs). While
existing visual instruction datasets often focus on question-answering, they
struggle to generalize to broader application scenarios such as creative
writing, summarization, or image analysis. To address these limitations, we
propose a novel approach to constructing MM-Instruct that leverages the strong
instruction-following capabilities of existing LLMs to generate novel visual
instruction data from large-scale but conventional image captioning datasets.
MM-Instruct first leverages ChatGPT to automatically generate diverse
instructions from a small set of seed instructions through augmenting and
summarization. It then matches these instructions with images and uses an
open-sourced large language model (LLM) to generate coherent answers to the
instruction-image pairs. The LLM is grounded by the detailed text descriptions
of images in the whole answer generation process to guarantee the alignment of
the instruction data. Moreover, we introduce a benchmark based on the generated
instruction data to evaluate the instruction-following capabilities of existing
LMMs. We demonstrate the effectiveness of MM-Instruct by training a LLaVA-1.5
model on the generated data, denoted as LLaVA-Instruct, which exhibits
significant improvements in instruction-following capabilities compared to
LLaVA-1.5 models. The MM-Instruct dataset, benchmark, and pre-trained models
are available at https://github.com/jihaonew/MM-Instruct.

摘要：本文介紹 MM-Instruct，一個大型且多元化的視覺指令資料集，其高品質的資料旨在增強大型多模態模型 (LMM) 的指令遵循能力。現有的視覺指令資料集通常專注於問答，但它們難以推廣到更廣泛的應用場景，例如創意寫作、摘要或影像分析。為了解決這些限制，我們提出了一種構建 MM-Instruct 的新方法，該方法利用現有 LLM 強大的指令遵循能力，從大型但傳統的影像標題資料集中產生新的視覺指令資料。MM-Instruct 首先利用 ChatGPT 從一組小的種子指令中自動產生多樣化的指令，透過擴充和摘要。然後將這些指令與影像配對，並使用開源的大語言模型 (LLM) 為指令影像對產生連貫的答案。LLM 在整個答案生成過程中以影像的詳細文字描述為基礎，以保證指令資料的一致性。此外，我們根據產生的指令資料引入了一個基準，以評估現有 LMM 的指令遵循能力。我們透過在產生的資料上訓練 LLaVA-1.5 模型（表示為 LLaVA-Instruct）展示了 MM-Instruct 的有效性，與 LLaVA-1.5 模型相比，LLaVA-Instruct 在指令遵循能力方面有顯著的提升。MM-Instruct 資料集、基準和預訓練模型可在 https://github.com/jihaonew/MM-Instruct 取得。

##### **CUPID: Improving Battle Fairness and Position Satisfaction in Online MOBA Games with a Re-matchmaking System**
2406.19720v1 by Ge Fan, Chaoyun Zhang, Kai Wang, Yingjie Li, Junyang Chen, Zenglin Xu

The multiplayer online battle arena (MOBA) genre has gained significant
popularity and economic success, attracting considerable research interest
within the Human-Computer Interaction community. Enhancing the gaming
experience requires a deep understanding of player behavior, and a crucial
aspect of MOBA games is matchmaking, which aims to assemble teams of comparable
skill levels. However, existing matchmaking systems often neglect important
factors such as players' position preferences and team assignment, resulting in
imbalanced matches and reduced player satisfaction. To address these
limitations, this paper proposes a novel framework called CUPID, which
introduces a novel process called ``re-matchmaking'' to optimize team and
position assignments to improve both fairness and player satisfaction. CUPID
incorporates a pre-filtering step to ensure a minimum level of matchmaking
quality, followed by a pre-match win-rate prediction model that evaluates the
fairness of potential assignments. By simultaneously considering players'
position satisfaction and game fairness, CUPID aims to provide an enhanced
matchmaking experience. Extensive experiments were conducted on two
large-scale, real-world MOBA datasets to validate the effectiveness of CUPID.
The results surpass all existing state-of-the-art baselines, with an average
relative improvement of 7.18% in terms of win prediction accuracy. Furthermore,
CUPID has been successfully deployed in a popular online mobile MOBA game. The
deployment resulted in significant improvements in match fairness and player
satisfaction, as evidenced by critical Human-Computer Interaction (HCI) metrics
covering usability, accessibility, and engagement, observed through A/B
testing. To the best of our knowledge, CUPID is the first re-matchmaking system
designed specifically for large-scale MOBA games.

摘要：多人線上戰鬥競技場 (MOBA) 類型遊戲獲得顯著的
人氣和經濟上的成功，在人機互動社群中吸引了相當的研究興趣。提升遊戲體驗需要深入了解玩家行為，而 MOBA 遊戲的一個關鍵面向是配對，目標是組成技能等級相近的隊伍。然而，現有的配對系統經常忽略重要因素，例如玩家的位置偏好和隊伍分配，導致比賽不平衡且降低玩家滿意度。為了解決這些限制，本文提出一個名為 CUPID 的新框架，它引進一個名為「重新配對」的新流程，以最佳化團隊和位置分配，提升公平性和玩家滿意度。CUPID 結合一個預先過濾步驟，以確保配對品質的最低水準，接著是一個預先比賽勝率預測模型，用來評估潛在分配的公平性。透過同時考量玩家的位置滿意度和遊戲公平性，CUPID 旨在提供增強的配對體驗。在兩個大型的真實世界 MOBA 資料集上進行廣泛的實驗，以驗證 CUPID 的有效性。結果超越所有現有的最先進基準，在獲勝預測準確度方面平均相對提升 7.18%。此外，CUPID 已成功部署在一個熱門的線上行動 MOBA 遊戲中。部署導致比賽公平性和玩家滿意度顯著提升，這由涵蓋可用性、可及性和參與度的關鍵人機互動 (HCI) 指標證明，並透過 A/B 測試觀察到。據我們所知，CUPID 是第一個專門為大型 MOBA 遊戲設計的重新配對系統。

##### **Uncertainty Quantification in Large Language Models Through Convex Hull Analysis**
2406.19712v1 by Ferhat Ozgur Catak, Murat Kuzlu

Uncertainty quantification approaches have been more critical in large
language models (LLMs), particularly high-risk applications requiring reliable
outputs. However, traditional methods for uncertainty quantification, such as
probabilistic models and ensemble techniques, face challenges when applied to
the complex and high-dimensional nature of LLM-generated outputs. This study
proposes a novel geometric approach to uncertainty quantification using convex
hull analysis. The proposed method leverages the spatial properties of response
embeddings to measure the dispersion and variability of model outputs. The
prompts are categorized into three types, i.e., `easy', `moderate', and
`confusing', to generate multiple responses using different LLMs at varying
temperature settings. The responses are transformed into high-dimensional
embeddings via a BERT model and subsequently projected into a two-dimensional
space using Principal Component Analysis (PCA). The Density-Based Spatial
Clustering of Applications with Noise (DBSCAN) algorithm is utilized to cluster
the embeddings and compute the convex hull for each selected cluster. The
experimental results indicate that the uncertainty of the model for LLMs
depends on the prompt complexity, the model, and the temperature setting.

摘要：不確定量化方法在大型語言模型 (LLM) 中變得更加關鍵，特別是需要可靠輸出的高風險應用。然而，當應用於 LLM 生成的輸出的複雜且高維度性質時，傳統的不確定量化方法，例如機率模型和整體技術，會面臨挑戰。本研究提出了一種新的幾何方法，使用凸包分析進行不確定量化。所提出的方法利用回應嵌入的空間屬性來測量模型輸出的分散和變異性。提示被分為三種類型，即「容易」、「中等」和「混淆」，使用不同 LLM 在不同的溫度設定下產生多重回應。回應透過 BERT 模型轉換為高維度嵌入，然後使用主成分分析 (PCA) 投影到二維空間。基於密度的應用程式空間聚類與雜訊 (DBSCAN) 演算法被用於對嵌入進行聚類，並為每個選定的群集計算凸包。實驗結果表明，LLM 模型的不確定性取決於提示複雜性、模型和溫度設定。

##### **A Differentiable Approach to Multi-scale Brain Modeling**
2406.19708v1 by Chaoming Wang, Muyang Lyu, Tianqiu Zhang, Sichao He, Si Wu

We present a multi-scale differentiable brain modeling workflow utilizing
BrainPy, a unique differentiable brain simulator that combines accurate brain
simulation with powerful gradient-based optimization. We leverage this
capability of BrainPy across different brain scales. At the single-neuron
level, we implement differentiable neuron models and employ gradient methods to
optimize their fit to electrophysiological data. On the network level, we
incorporate connectomic data to construct biologically constrained network
models. Finally, to replicate animal behavior, we train these models on
cognitive tasks using gradient-based learning rules. Experiments demonstrate
that our approach achieves superior performance and speed in fitting
generalized leaky integrate-and-fire and Hodgkin-Huxley single neuron models.
Additionally, training a biologically-informed network of excitatory and
inhibitory spiking neurons on working memory tasks successfully replicates
observed neural activity and synaptic weight distributions. Overall, our
differentiable multi-scale simulation approach offers a promising tool to
bridge neuroscience data across electrophysiological, anatomical, and
behavioral scales.

摘要：我們提出一個多尺度可微分大腦建模工作流程，利用 BrainPy，一個獨特可微分大腦模擬器，結合準確的大腦模擬與強大的基於梯度的最佳化。我們跨不同的大腦尺度利用 BrainPy 的這種能力。在單一神經元層級，我們實作可微分神經元模型，並採用梯度方法來最佳化它們對電生理資料的擬合。在網路層級，我們整合連接組資料來建構生物受限的網路模型。最後，為了複製動物行為，我們使用基於梯度的學習規則在認知任務上訓練這些模型。實驗證明，我們的方法在擬合廣義漏電積分和發射以及 Hodgkin-Huxley 單一神經元模型方面達到了優異的效能和速度。此外，在工作記憶任務上訓練一個由激發性和抑制性尖峰神經元組成的生物資訊網路，成功複製了觀察到的神經活動和突觸權重分佈。總體而言，我們可微分多尺度模擬方法提供了一個有前途的工具，可以橋接電生理、解剖和行為尺度的神經科學資料。

##### **DISCO: Efficient Diffusion Solver for Large-Scale Combinatorial Optimization Problems**
2406.19705v1 by Kexiong Yu, Hang Zhao, Yuhang Huang, Renjiao Yi, Kai Xu, Chenyang Zhu

Combinatorial Optimization (CO) problems are fundamentally crucial in
numerous practical applications across diverse industries, characterized by
entailing enormous solution space and demanding time-sensitive response.
Despite significant advancements made by recent neural solvers, their limited
expressiveness does not conform well to the multi-modal nature of CO
landscapes. While some research has pivoted towards diffusion models, they
require simulating a Markov chain with many steps to produce a sample, which is
time-consuming and does not meet the efficiency requirement of real
applications, especially at scale. We propose DISCO, an efficient DIffusion
Solver for Combinatorial Optimization problems that excels in both solution
quality and inference speed. DISCO's efficacy is two-pronged: Firstly, it
achieves rapid denoising of solutions through an analytically solvable form,
allowing for direct sampling from the solution space with very few reverse-time
steps, thereby drastically reducing inference time. Secondly, DISCO enhances
solution quality by restricting the sampling space to a more constrained,
meaningful domain guided by solution residues, while still preserving the
inherent multi-modality of the output probabilistic distributions. DISCO
achieves state-of-the-art results on very large Traveling Salesman Problems
with 10000 nodes and challenging Maximal Independent Set benchmarks, with its
per-instance denoising time up to 44.8 times faster. Through further combining
a divide-and-conquer strategy, DISCO can be generalized to solve
arbitrary-scale problem instances off the shelf, even outperforming models
trained specifically on corresponding scales.

摘要：組合最佳化 (CO) 問題在各種產業的實際應用中至關重要，其特點是需要廣大的解空間，且需要即時的回應。儘管近期神經求解器有顯著的進展，但其有限的表達能力並不符合 CO 地形的多分位性質。雖然有些研究已轉向擴散模型，但它們需要模擬一個具有許多步驟的馬可夫鏈來產生樣本，這很耗時，且不符合實際應用，特別是在規模化的效率要求。我們提出 DISCO，一個用於組合最佳化問題的有效 DIffusion 求解器，在解的品質和推論速度上都表現優異。DISCO 的效能有兩個要點：首先，它透過一個可解析的形式快速對解進行去噪，允許直接從解空間取樣，且反向時間步驟很少，因此大幅減少了推論時間。其次，DISCO 透過將取樣空間限制在一個更受約束且有意義的領域，由解殘差引導，同時仍保留輸出機率分佈的內在多分位性，來提升解的品質。DISCO 在非常大的旅行商問題上達成最先進的結果，有 10000 個節點和具有挑戰性的最大獨立集基準，其每個實例的去噪時間快達 44.8 倍。透過進一步結合分而治之策略，DISCO 可以廣泛地用於解決任意規模的問題實例，甚至超越在相應規模上特別訓練的模型。

##### **Deep Fusion Model for Brain Tumor Classification Using Fine-Grained Gradient Preservation**
2406.19690v1 by Niful Islam, Mohaiminul Islam Bhuiyan, Jarin Tasnim Raya, Nur Shazwani Kamarudin, Khan Md Hasib, M. F. Mridha, Dewan Md. Farid

Brain tumors are one of the most common diseases that lead to early death if
not diagnosed at an early stage. Traditional diagnostic approaches are
extremely time-consuming and prone to errors. In this context, computer
vision-based approaches have emerged as an effective tool for accurate brain
tumor classification. While some of the existing solutions demonstrate
noteworthy accuracy, the models become infeasible to deploy in areas where
computational resources are limited. This research addresses the need for
accurate and fast classification of brain tumors with a priority of deploying
the model in technologically underdeveloped regions. The research presents a
novel architecture for precise brain tumor classification fusing pretrained
ResNet152V2 and modified VGG16 models. The proposed architecture undergoes a
diligent fine-tuning process that ensures fine gradients are preserved in deep
neural networks, which are essential for effective brain tumor classification.
The proposed solution incorporates various image processing techniques to
improve image quality and achieves an astounding accuracy of 98.36% and 98.04%
in Figshare and Kaggle datasets respectively. This architecture stands out for
having a streamlined profile, with only 2.8 million trainable parameters. We
have leveraged 8-bit quantization to produce a model of size 73.881 MB,
significantly reducing it from the previous size of 289.45 MB, ensuring smooth
deployment in edge devices even in resource-constrained areas. Additionally,
the use of Grad-CAM improves the interpretability of the model, offering
insightful information regarding its decision-making process. Owing to its high
discriminative ability, this model can be a reliable option for accurate brain
tumor classification.

摘要：腦瘤是最常見的疾病之一，如果沒有在早期診斷出來，可能會導致早逝。傳統的診斷方法極為耗時且容易出錯。在此背景下，基於電腦視覺的方法已成為準確分類腦瘤的有效工具。雖然一些現有的解決方案展示出顯著的準確性，但這些模型在計算資源有限的地區部署起來變得不可行。本研究解決了準確快速分類腦瘤的需求，優先在技術落後的地區部署模型。本研究提出了一種新穎的架構，用於精確分類腦瘤，融合預訓練的 ResNet152V2 和修改後的 VGG16 模型。所提出的架構經過了勤奮的微調過程，確保在深度神經網路中保留精細的梯度，這對於有效的腦瘤分類至關重要。所提出的解決方案結合了各種影像處理技術來改善影像品質，並分別在 Figshare 和 Kaggle 資料集中達到了驚人的 98.36% 和 98.04% 的準確度。此架構的特點是簡化的特徵，只有 280 萬個可訓練參數。我們利用 8 位元量化產生大小為 73.881 MB 的模型，從先前的 289.45 MB 大小顯著減少，確保即使在資源受限的地區也能順利部署於邊緣裝置。此外，使用 Grad-CAM 提高了模型的可解釋性，提供了關於其決策過程的見解資訊。由於其高度的判別能力，此模型可以成為準確分類腦瘤的可靠選項。

##### **Enhancing Radiological Diagnosis: A Collaborative Approach Integrating AI and Human Expertise for Visual Miss Correction**
2406.19686v1 by Akash Awasthi, Ngan Le, Zhigang Deng, Carol C. Wu, Hien Van Nguyen

Human-AI collaboration to identify and correct perceptual errors in chest
radiographs has not been previously explored. This study aimed to develop a
collaborative AI system, CoRaX, which integrates eye gaze data and radiology
reports to enhance diagnostic accuracy in chest radiology by pinpointing
perceptual errors and refining the decision-making process. Using public
datasets REFLACX and EGD-CXR, the study retrospectively developed CoRaX,
employing a large multimodal model to analyze image embeddings, eye gaze data,
and radiology reports. The system's effectiveness was evaluated based on its
referral-making process, the quality of referrals, and performance in
collaborative diagnostic settings. CoRaX was tested on a simulated error
dataset of 271 samples with 28% (93 of 332) missed abnormalities. The system
corrected 21% (71 of 332) of these errors, leaving 7% (22 of 312) unresolved.
The Referral-Usefulness score, indicating the accuracy of predicted regions for
all true referrals, was 0.63 (95% CI 0.59, 0.68). The Total-Usefulness score,
reflecting the diagnostic accuracy of CoRaX's interactions with radiologists,
showed that 84% (237 of 280) of these interactions had a score above 0.40. In
conclusion, CoRaX efficiently collaborates with radiologists to address
perceptual errors across various abnormalities, with potential applications in
the education and training of novice radiologists.

摘要：人類與 AI 合作識別並修正胸部 X 光檢查中的感知錯誤，這在過去尚未被探討過。本研究旨在開發一套協作式 AI 系統 CoRaX，它整合了視線注視資料和放射科報告，藉由找出感知錯誤並改善決策流程，以提升胸部放射科的診斷準確度。本研究使用公開的資料集 REFLACX 和 EGD-CXR，回溯式地開發出 CoRaX，並採用大型的多模態模型來分析影像嵌入、視線注視資料和放射科報告。該系統的有效性是根據其轉診流程、轉診品質和協作診斷設定中的表現來評估。CoRaX 在一套模擬錯誤的資料集上進行測試，該資料集包含 271 個樣本，其中有 28%（332 個中的 93 個）漏失異常。系統修正了其中 21%（332 個中的 71 個）的錯誤，留下 7%（312 個中的 22 個）未解決。轉診實用性分數表示所有真正轉診預測區域的準確性，為 0.63（95% CI 0.59、0.68）。總實用性分數反映 CoRaX 與放射科醫師互動的診斷準確性，顯示這些互動中有 84%（280 個中的 237 個）的分數高於 0.40。結論是，CoRaX 能有效地與放射科醫師合作，處理各種異常的感知錯誤，並具有在新手放射科醫師的教育和訓練中應用的潛力。

##### **Less is More: Accurate Speech Recognition & Translation without Web-Scale Data**
2406.19674v1 by Krishna C. Puvvada, Piotr Żelasko, He Huang, Oleksii Hrinchuk, Nithin Rao Koluguri, Kunal Dhawan, Somshubra Majumdar, Elena Rastorgueva, Zhehuai Chen, Vitaly Lavrukhin, Jagadeesh Balam, Boris Ginsburg

Recent advances in speech recognition and translation rely on hundreds of
thousands of hours of Internet speech data. We argue that state-of-the art
accuracy can be reached without relying on web-scale data. Canary -
multilingual ASR and speech translation model, outperforms current
state-of-the-art models - Whisper, OWSM, and Seamless-M4T on English, French,
Spanish, and German languages, while being trained on an order of magnitude
less data than these models. Three key factors enables such data-efficient
model: (1) a FastConformer-based attention encoder-decoder architecture (2)
training on synthetic data generated with machine translation and (3) advanced
training techniques: data-balancing, dynamic data blending, dynamic bucketing
and noise-robust fine-tuning. The model, weights, and training code will be
open-sourced.

摘要：最近在語音辨識和翻譯的進展仰賴數十萬小時的網路語音資料。我們主張，即使不依賴網路規模的資料，也能達到最先進的準確度。Canary - 多語言 ASR 和語音翻譯模型，在英文、法文、西班牙文和德文的表現優於目前最先進的模型 - Whisper、OWSM 和 Seamless-M4T，同時訓練的資料量比這些模型少了一個數量級。有三個關鍵因素讓這種資料有效率的模型成為可能：(1) 基於 FastConformer 的注意力編碼器-解碼器架構 (2) 使用機器翻譯產生的合成資料進行訓練，以及 (3) 進階訓練技巧：資料平衡、動態資料混合、動態分組和抗噪微調。模型、權重和訓練程式碼將會開放原始碼。

##### **Function+Data Flow: A Framework to Specify Machine Learning Pipelines for Digital Twinning**
2406.19670v1 by Eduardo de Conto, Blaise Genest, Arvind Easwaran

The development of digital twins (DTs) for physical systems increasingly
leverages artificial intelligence (AI), particularly for combining data from
different sources or for creating computationally efficient, reduced-dimension
models. Indeed, even in very different application domains, twinning employs
common techniques such as model order reduction and modelization with hybrid
data (that is, data sourced from both physics-based models and sensors).
Despite this apparent generality, current development practices are ad-hoc,
making the design of AI pipelines for digital twinning complex and
time-consuming. Here we propose Function+Data Flow (FDF), a domain-specific
language (DSL) to describe AI pipelines within DTs. FDF aims to facilitate the
design and validation of digital twins. Specifically, FDF treats functions as
first-class citizens, enabling effective manipulation of models learned with
AI. We illustrate the benefits of FDF on two concrete use cases from different
domains: predicting the plastic strain of a structure and modeling the
electromagnetic behavior of a bearing.

摘要：數位分身 (DT) 的發展對於物理系統越來越廣泛地利用人工智慧 (AI)，特別是在結合來自不同來源的資料或建立計算有效率的降維模型。事實上，即使在非常不同的應用領域中，數位分身也採用了常見的技術，例如模型階數簡化和混合資料模式化（也就是，來自於基於物理的模型和感測器的資料）。儘管有這些明顯的普遍性，目前的開發實務仍是臨時性的，這使得數位分身的人工智慧管線設計變得複雜且耗時。在此，我們提出函式 + 資料流程 (FDF)，一種特定領域語言 (DSL) 來描述 DT 中的人工智慧管線。FDF 的目標是促進數位分身的設計和驗證。具體來說，FDF 將函式視為一級公民，讓模型能夠有效地透過人工智慧學習。我們說明了 FDF 在兩個具體使用案例中的好處，這些使用案例來自不同的領域：預測結構的塑性應變和建構軸承的電磁行為模型。

##### **ACES: Automatic Cohort Extraction System for Event-Stream Datasets**
2406.19653v1 by Justin Xu, Jack Gallifant, Alistair E. W. Johnson, Matthew B. A. McDermott

Reproducibility remains a significant challenge in machine learning (ML) for
healthcare. In this field, datasets, model pipelines, and even task/cohort
definitions are often private, leading to a significant barrier in sharing,
iterating, and understanding ML results on electronic health record (EHR)
datasets. In this paper, we address a significant part of this problem by
introducing the Automatic Cohort Extraction System for Event-Stream Datasets
(ACES). This tool is designed to simultaneously simplify the development of
task/cohorts for ML in healthcare and enable the reproduction of these cohorts,
both at an exact level for single datasets and at a conceptual level across
datasets. To accomplish this, ACES provides (1) a highly intuitive and
expressive configuration language for defining both dataset-specific concepts
and dataset-agnostic inclusion/exclusion criteria, and (2) a pipeline to
automatically extract patient records that meet these defined criteria from
real-world data. ACES can be automatically applied to any dataset in either the
Medical Event Data Standard (MEDS) or EventStreamGPT (ESGPT) formats, or to
*any* dataset for which the necessary task-specific predicates can be extracted
in an event-stream form. ACES has the potential to significantly lower the
barrier to entry for defining ML tasks, redefine the way researchers interact
with EHR datasets, and significantly improve the state of reproducibility for
ML studies in this modality. ACES is available at
https://github.com/justin13601/aces.

摘要：機器學習 (ML) 在醫療保健領域中，可複製性仍然是一項重大挑戰。在這個領域中，資料集、模型管線，甚至任務/群組定義通常都是私有的，這導致在電子健康紀錄 (EHR) 資料集上分享、重複和理解 ML 結果時產生重大的障礙。在本文中，我們透過導入事件串流資料集的自動群組萃取系統 (ACES) 來解決這個問題的其中一個重要部分。此工具旨在同時簡化醫療保健中 ML 的任務/群組開發，並讓這些群組得以複製，無論是在單一資料集的精確層級，還是在跨資料集的概念層級上。為達成此目的，ACES 提供了 (1) 一種高度直覺且具表現力的組態語言，用於定義資料集特定的概念和與資料集無關的包含/排除標準，以及 (2) 一個管線，用於自動從真實世界資料中萃取符合這些定義標準的病患記錄。ACES 可以自動套用至醫療事件資料標準 (MEDS) 或 EventStreamGPT (ESGPT) 格式中的任何資料集，或套用至 *任何* 可以以事件串流形式萃取必要的特定任務謂詞的資料集。ACES 有可能大幅降低定義 ML 任務的進入門檻，重新定義研究人員與 EHR 資料集互動的方式，並顯著改善此方式中 ML 研究的可複製性。ACES 可在 https://github.com/justin13601/aces 取得。

##### **CANDY: A Benchmark for Continuous Approximate Nearest Neighbor Search with Dynamic Data Ingestion**
2406.19651v1 by Xianzhi Zeng, Zhuoyan Wu, Xinjing Hu, Xuanhua Shi, Shixuan Sun, Shuhao Zhang

Approximate K Nearest Neighbor (AKNN) algorithms play a pivotal role in
various AI applications, including information retrieval, computer vision, and
natural language processing. Although numerous AKNN algorithms and benchmarks
have been developed recently to evaluate their effectiveness, the dynamic
nature of real-world data presents significant challenges that existing
benchmarks fail to address. Traditional benchmarks primarily assess retrieval
effectiveness in static contexts and often overlook update efficiency, which is
crucial for handling continuous data ingestion. This limitation results in an
incomplete assessment of an AKNN algorithms ability to adapt to changing data
patterns, thereby restricting insights into their performance in dynamic
environments. To address these gaps, we introduce CANDY, a benchmark tailored
for Continuous Approximate Nearest Neighbor Search with Dynamic Data Ingestion.
CANDY comprehensively assesses a wide range of AKNN algorithms, integrating
advanced optimizations such as machine learning-driven inference to supplant
traditional heuristic scans, and improved distance computation methods to
reduce computational overhead. Our extensive evaluations across diverse
datasets demonstrate that simpler AKNN baselines often surpass more complex
alternatives in terms of recall and latency. These findings challenge
established beliefs about the necessity of algorithmic complexity for high
performance. Furthermore, our results underscore existing challenges and
illuminate future research opportunities. We have made the datasets and
implementation methods available at: https://github.com/intellistream/candy.

摘要：近似 K 最近邻 (AKNN) 算法在各种 AI 应用中扮演着关键角色，包括信息检索、计算机视觉和自然语言处理。尽管最近已经开发了众多 AKNN 算法和基准来评估其有效性，但现实世界数据的动态特性提出了现有基准无法解决的重大挑战。传统基准主要评估静态环境中的检索效率，而常常忽略更新效率，这对于处理持续数据摄取至关重要。此限制导致不完全评估 AKNN 算法适应不断变化的数据模式的能力，从而限制了对它们在动态环境中的性能的见解。为了解决这些差距，我们引入了 CANDY，这是一个针对连续近似最近邻搜索（具有动态数据摄取）而定制的基准。CANDY 全面评估了广泛的 AKNN 算法，集成了高级优化，例如机器学习驱动的推理，以取代传统的启发式扫描，以及改进的距离计算方法以减少计算开销。我们对不同数据集进行的广泛评估表明，在召回率和延迟方面，更简单的 AKNN 基线通常优于更复杂的替代方案。这些发现挑战了关于高性能需要算法复杂性的既定观念。此外，我们的结果强调了现有的挑战，并阐明了未来的研究机会。我们已在以下位置提供了数据集和实现方法：https://github.com/intellistream/candy。

##### **DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting**
2406.19650v1 by Xuanming Zhang, Anthony Diaz, Zixun Chen, Qingyang Wu, Kun Qian, Erik Voss, Zhou Yu

Coherence in writing, an aspect that second-language (L2) English learners
often struggle with, is crucial in assessing L2 English writing. Existing
automated writing evaluation systems primarily use basic surface linguistic
features to detect coherence in writing. However, little effort has been made
to correct the detected incoherence, which could significantly benefit L2
language learners seeking to improve their writing. To bridge this gap, we
introduce DECOR, a novel benchmark that includes expert annotations for
detecting incoherence in L2 English writing, identifying the underlying
reasons, and rewriting the incoherent sentences. To our knowledge, DECOR is the
first coherence assessment dataset specifically designed for improving L2
English writing, featuring pairs of original incoherent sentences alongside
their expert-rewritten counterparts. Additionally, we fine-tuned models to
automatically detect and rewrite incoherence in student essays. We find that
incorporating specific reasons for incoherence during fine-tuning consistently
improves the quality of the rewrites, achieving a result that is favored in
both automatic and human evaluations.

摘要：在寫作中，連貫性是第二語言（L2）英語學習者常遇到的問題，在評量 L2 英語寫作時至關重要。現有的自動寫作評量系統主要使用基本的表面語言特徵來偵測寫作中的連貫性。然而，對於更正偵測到的不連貫性，目前的研究並不多，而這對於尋求改進寫作能力的 L2 語言學習者來說，將有顯著的幫助。為了彌補這個差距，我們引進 DECOR，這是一個新的基準，包含專家註解，用於偵測 L2 英語寫作中的不連貫性，找出背後的原因，並改寫不連貫的句子。據我們所知，DECOR 是第一個特別針對改進 L2 英語寫作而設計的連貫性評量資料集，其中包含原始不連貫句子及其由專家改寫的對應句子。此外，我們微調模型以自動偵測及改寫學生文章中的不連貫性。我們發現，在微調過程中加入不連貫性的特定原因，可以持續提升改寫的品質，在自動評量和人工評量中皆獲得較高的評價。

##### **Designing and Evaluating Multi-Chatbot Interface for Human-AI Communication: Preliminary Findings from a Persuasion Task**
2406.19648v1 by Sion Yoon, Tae Eun Kim, Yoo Jung Oh

The dynamics of human-AI communication have been reshaped by language models
such as ChatGPT. However, extant research has primarily focused on dyadic
communication, leaving much to be explored regarding the dynamics of human-AI
communication in group settings. The availability of multiple language model
chatbots presents a unique opportunity for scholars to better understand the
interaction between humans and multiple chatbots. This study examines the
impact of multi-chatbot communication in a specific persuasion setting:
promoting charitable donations. We developed an online environment that enables
multi-chatbot communication and conducted a pilot experiment utilizing two
GPT-based chatbots, Save the Children and UNICEF chatbots, to promote
charitable donations. In this study, we present our development process of the
multi-chatbot interface and present preliminary findings from a pilot
experiment. Analysis of qualitative and quantitative feedback are presented,
and limitations are addressed.

摘要：語言模型，例如 ChatGPT，已重塑人機溝通的動態。然而，現有的研究主要集中在雙邊溝通上，在群組設定中人機溝通的動態方面仍有許多待探索之處。多個語言模型聊天機器人的出現，為學者們提供了一個絕佳的機會，可以更深入地了解人類與多個聊天機器人之間的互動。本研究探討了多聊天機器人溝通在特定說服環境中的影響：促進慈善捐款。我們開發了一個允許多聊天機器人溝通的線上環境，並進行了一個試驗實驗，利用兩個基於 GPT 的聊天機器人，即救助兒童會和聯合國兒童基金會的聊天機器人，來促進慈善捐款。在本研究中，我們展示了多聊天機器人介面的開發過程，並提出了試驗實驗的初步發現。我們提供了對質性和量化回饋的分析，並探討了限制。

##### **Beyond Human Preferences: Exploring Reinforcement Learning Trajectory Evaluation and Improvement through LLMs**
2406.19644v1 by Zichao Shen, Tianchen Zhu, Qingyun Sun, Shiqi Gao, Jianxin Li

Reinforcement learning (RL) faces challenges in evaluating policy
trajectories within intricate game tasks due to the difficulty in designing
comprehensive and precise reward functions. This inherent difficulty curtails
the broader application of RL within game environments characterized by diverse
constraints. Preference-based reinforcement learning (PbRL) presents a
pioneering framework that capitalizes on human preferences as pivotal reward
signals, thereby circumventing the need for meticulous reward engineering.
However, obtaining preference data from human experts is costly and
inefficient, especially under conditions marked by complex constraints. To
tackle this challenge, we propose a LLM-enabled automatic preference generation
framework named LLM4PG , which harnesses the capabilities of large language
models (LLMs) to abstract trajectories, rank preferences, and reconstruct
reward functions to optimize conditioned policies. Experiments on tasks with
complex language constraints demonstrated the effectiveness of our LLM-enabled
reward functions, accelerating RL convergence and overcoming stagnation caused
by slow or absent progress under original reward structures. This approach
mitigates the reliance on specialized human knowledge and demonstrates the
potential of LLMs to enhance RL's effectiveness in complex environments in the
wild.

摘要：強化學習 (RL) 在評估策略軌跡時，由於難以設計全面且精確的獎勵函數，因此在複雜的遊戲任務中面臨挑戰。這種固有的困難限制了 RL 在遊戲環境中更廣泛的應用，而遊戲環境的特點是具有多樣化的約束。基於偏好的強化學習 (PbRL) 提出了一個開創性的框架，該框架利用人類偏好作為關鍵的獎勵信號，從而規避了對細緻的獎勵工程的需求。然而，從人類專家那裡獲取偏好數據既昂貴又低效，尤其是在具有複雜約束的條件下。為了應對這一挑戰，我們提出了一個名為 LLM4PG 的 LLM 啟用的自動偏好生成框架，它利用大型語言模型 (LLM) 的能力來抽象軌跡、對偏好進行排名，並重建獎勵函數以優化條件策略。在具有複雜語言約束的任務上的實驗證明了我們 LLM 啟用的獎勵函數的有效性，加速了 RL 收斂，並克服了在原始獎勵結構下進度緩慢或缺失造成的停滯。這種方法減輕了對專業人類知識的依賴，並展示了 LLM 在增強 RL 在野外複雜環境中的有效性方面的潛力。

##### **Unlocking Varied Perspectives: A Persona-Based Multi-Agent Framework with Debate-Driven Text Planning for Argument Generation**
2406.19643v1 by Zhe Hu, Hou Pong Chan, Jing Li, Yu Yin

Writing persuasive arguments is a challenging task for both humans and
machines. It entails incorporating high-level beliefs from various perspectives
on the topic, along with deliberate reasoning and planning to construct a
coherent narrative. Current language models often generate surface tokens
autoregressively, lacking explicit integration of these underlying controls,
resulting in limited output diversity and coherence. In this work, we propose a
persona-based multi-agent framework for argument writing. Inspired by the human
debate, we first assign each agent a persona representing its high-level
beliefs from a unique perspective, and then design an agent interaction process
so that the agents can collaboratively debate and discuss the idea to form an
overall plan for argument writing. Such debate process enables fluid and
nonlinear development of ideas. We evaluate our framework on argumentative
essay writing. The results show that our framework can generate more diverse
and persuasive arguments through both automatic and human evaluations.

摘要：撰寫具說服力的論點對人類和機器而言都是一項艱鉅的任務。這需要整合來自各種觀點對主題的高層次信念，以及經過深思熟慮的推理和規劃，才能建構出一套連貫的敘述。目前的語言模型通常會自迴歸地產生表面符號，缺乏對這些基礎控制的明確整合，導致輸出多樣性和連貫性受限。在這項工作中，我們提出了一個基於角色的多代理架構，用於論證寫作。受到人類辯論的啟發，我們首先為每個代理分配一個角色，代表其從獨特觀點出發的高層次信念，然後設計一個代理互動過程，讓代理可以合作辯論和討論想法，以形成論證寫作的整體計畫。這種辯論過程能讓想法流暢且非線性地發展。我們對我們的架構進行了論證性散文寫作的評估。結果顯示，我們的架構能透過自動和人工評估產生更多元且更具說服力的論點。

##### **IDT: Dual-Task Adversarial Attacks for Privacy Protection**
2406.19642v1 by Pedro Faustini, Shakila Mahjabin Tonni, Annabelle McIver, Qiongkai Xu, Mark Dras

Natural language processing (NLP) models may leak private information in
different ways, including membership inference, reconstruction or attribute
inference attacks. Sensitive information may not be explicit in the text, but
hidden in underlying writing characteristics. Methods to protect privacy can
involve using representations inside models that are demonstrated not to detect
sensitive attributes or -- for instance, in cases where users might not trust a
model, the sort of scenario of interest here -- changing the raw text before
models can have access to it. The goal is to rewrite text to prevent someone
from inferring a sensitive attribute (e.g. the gender of the author, or their
location by the writing style) whilst keeping the text useful for its original
intention (e.g. the sentiment of a product review). The few works tackling this
have focused on generative techniques. However, these often create extensively
different texts from the original ones or face problems such as mode collapse.
This paper explores a novel adaptation of adversarial attack techniques to
manipulate a text to deceive a classifier w.r.t one task (privacy) whilst
keeping the predictions of another classifier trained for another task
(utility) unchanged. We propose IDT, a method that analyses predictions made by
auxiliary and interpretable models to identify which tokens are important to
change for the privacy task, and which ones should be kept for the utility
task. We evaluate different datasets for NLP suitable for different tasks.
Automatic and human evaluations show that IDT retains the utility of text,
while also outperforming existing methods when deceiving a classifier w.r.t
privacy task.

摘要：自然語言處理 (NLP) 模型可能會以不同的方式洩漏私人資訊，包括成員推論、重建或屬性推論攻擊。敏感資訊可能並未明示在文字中，而是隱藏在底層的書寫特徵中。保護隱私的方法可能涉及在模型內部使用已證實不會偵測到敏感屬性的表示，或者（例如在使用者可能不信任模型的情況下，這裡感興趣的場景類型）在模型可以存取原始文字之前更改原始文字。目標是改寫文字以防止某人推論出敏感屬性（例如作者的性別或其書寫風格的位置），同時保持文字對其原始意圖（例如產品評論的情緒）有用。處理此問題的少數作品都專注於生成技術。然而，這些技術通常會從原始文字中產生截然不同的文字，或面臨模式崩潰等問題。本文探討了對抗攻擊技術的新穎改編，以操縱文字欺騙分類器 w.r.t 一個任務（隱私），同時保持為另一個任務（實用性）訓練的另一個分類器的預測不變。我們提出了 IDT，這是一種方法，它分析輔助和可解釋模型所做的預測，以識別哪些標記對於隱私任務來說很重要而需要更改，以及哪些標記應該保留用於實用任務。我們評估了適合不同任務的 NLP 不同資料集。自動和人工評估表明 IDT 保留了文字的實用性，同時在欺騙分類器 w.r.t 隱私任務時也優於現有方法。

##### **Precision matters: Precision-aware ensemble for weakly supervised semantic segmentation**
2406.19638v1 by Junsung Park, Hyunjung Shim

Weakly Supervised Semantic Segmentation (WSSS) employs weak supervision, such
as image-level labels, to train the segmentation model. Despite the impressive
achievement in recent WSSS methods, we identify that introducing weak labels
with high mean Intersection of Union (mIoU) does not guarantee high
segmentation performance. Existing studies have emphasized the importance of
prioritizing precision and reducing noise to improve overall performance. In
the same vein, we propose ORANDNet, an advanced ensemble approach tailored for
WSSS. ORANDNet combines Class Activation Maps (CAMs) from two different
classifiers to increase the precision of pseudo-masks (PMs). To further
mitigate small noise in the PMs, we incorporate curriculum learning. This
involves training the segmentation model initially with pairs of smaller-sized
images and corresponding PMs, gradually transitioning to the original-sized
pairs. By combining the original CAMs of ResNet-50 and ViT, we significantly
improve the segmentation performance over the single-best model and the naive
ensemble model, respectively. We further extend our ensemble method to CAMs
from AMN (ResNet-like) and MCTformer (ViT-like) models, achieving performance
benefits in advanced WSSS models. It highlights the potential of our ORANDNet
as a final add-on module for WSSS models.

摘要：弱監督語意分割 (WSSS) 採用弱監督，例如影像等級標籤，來訓練分割模型。儘管近期的 WSSS 方法取得令人印象深刻的成就，我們發現，引入平均交集聯集 (mIoU) 較高的弱標籤並不能保證高分割效能。現有研究強調了優先考慮精確度和降低雜訊以提升整體效能的重要性。基於相同的觀點，我們提出 ORANDNet，一種針對 WSSS 量身打造的進階整體方法。ORANDNet 結合來自兩個不同分類器的類別啟動圖 (CAM) 以提升偽遮罩 (PM) 的精確度。為了進一步減輕 PM 中的微小雜訊，我們納入了課程學習。這包括最初使用較小尺寸影像和對應 PM 訓練分割模型，並逐漸過渡到原始尺寸的配對。透過結合 ResNet-50 和 ViT 的原始 CAM，我們分別顯著提升了單一最佳模型和單純整體模型的分割效能。我們進一步將整體方法擴充到來自 AMN (類似 ResNet) 和 MCTformer (類似 ViT) 模型的 CAM，在進階 WSSS 模型中獲得效能優勢。這突顯了我們的 ORANDNet 作為 WSSS 模型最終附加模組的潛力。

##### **Optimal Video Compression using Pixel Shift Tracking**
2406.19630v1 by Hitesh Saai Mananchery Panneerselvam, Smit Anand

The Video comprises approximately ~85\% of all internet traffic, but video
encoding/compression is being historically done with hard coded rules, which
has worked well but only to a certain limit. We have seen a surge in video
compression algorithms using ML-based models in the last few years and many of
them have outperformed several legacy codecs. The models range from encoding
video end to end using an ML approach or replacing some intermediate steps in
legacy codecs using ML models to increase the efficiency of those steps.
  Optimizing video storage is an essential aspect of video processing, so we
are proposing one of the possible approaches to achieve it is by avoiding
redundant data at each frame. In this paper, we want to introduce the approach
of redundancies removal in subsequent frames for a given video as a main
approach for video compression. We call this method Redundancy Removal using
Shift (R\textsuperscript2S). This method can be utilized across various Machine
Learning model algorithms, and make the compression more accessible and
adaptable. In this study, we have utilized a computer vision-based pixel point
tracking method to identify redundant pixels to encode video for optimal
storage.

摘要：影片約佔所有網路流量的 85%，但影片編碼/壓縮一直是使用硬編碼規則完成的，這雖然運作良好，但僅限於一定程度。在過去幾年中，我們已經看到使用基於 ML 的模型進行影片壓縮演算法的激增，其中許多演算法都優於多個舊版編解碼器。這些模型的範圍從使用 ML 方法對影片進行端到端編碼，到使用 ML 模型取代舊版編解碼器中的一些中間步驟，以提高這些步驟的效率。
最佳化影片儲存是影片處理的一個重要面向，因此我們提出一個可能的方法來達成此目標，方法是避免每個畫格的冗餘資料。在本文中，我們要介紹一個方法，即移除給定影片中後續畫格的冗餘，作為影片壓縮的主要方法。我們將此方法稱為使用位移的冗餘移除 (R\textsuperscript2S)。此方法可應用於各種機器學習模型演算法，並使壓縮更易於存取和調整。在本研究中，我們利用基於電腦視覺的像素點追蹤方法來識別冗餘像素，以最佳化儲存空間對影片進行編碼。

##### **Data-Driven Lipschitz Continuity: A Cost-Effective Approach to Improve Adversarial Robustness**
2406.19622v1 by Erh-Chung Chen, Pin-Yu Chen, I-Hsin Chung, Che-Rung Lee

The security and robustness of deep neural networks (DNNs) have become
increasingly concerning. This paper aims to provide both a theoretical
foundation and a practical solution to ensure the reliability of DNNs. We
explore the concept of Lipschitz continuity to certify the robustness of DNNs
against adversarial attacks, which aim to mislead the network with adding
imperceptible perturbations into inputs. We propose a novel algorithm that
remaps the input domain into a constrained range, reducing the Lipschitz
constant and potentially enhancing robustness. Unlike existing adversarially
trained models, where robustness is enhanced by introducing additional examples
from other datasets or generative models, our method is almost cost-free as it
can be integrated with existing models without requiring re-training.
Experimental results demonstrate the generalizability of our method, as it can
be combined with various models and achieve enhancements in robustness.
Furthermore, our method achieves the best robust accuracy for CIFAR10,
CIFAR100, and ImageNet datasets on the RobustBench leaderboard.

摘要：深度神經網路 (DNN) 的安全性與健壯性已日益受到關注。本文旨在提供理論基礎和實務解決方案，以確保 DNN 的可靠性。我們探討了 Lipschitz 連續性的概念，以驗證 DNN 對抗攻擊的健壯性，此攻擊旨在透過在輸入中加入難以察覺的擾動來誤導網路。我們提出了一種創新的演算法，將輸入網域重新映射到受限範圍，以降低 Lipschitz 常數，並潛在地增強健壯性。與現有的對抗訓練模型不同，後者透過引入其他資料集或生成模型中的額外範例來增強健壯性，我們的模型幾乎沒有成本，因為它可以與現有模型整合，而不需要重新訓練。實驗結果證明了我們模型的泛化性，因為它可以與各種模型結合，並在健壯性方面獲得增強。此外，我們的模型在 RobustBench 排行榜上，達到了 CIFAR10、CIFAR100 和 ImageNet 資料集最佳的健壯準確度。

##### **A Survey on Data Quality Dimensions and Tools for Machine Learning**
2406.19614v1 by Yuhan Zhou, Fengjiao Tu, Kewei Sha, Junhua Ding, Haihua Chen

Machine learning (ML) technologies have become substantial in practically all
aspects of our society, and data quality (DQ) is critical for the performance,
fairness, robustness, safety, and scalability of ML models. With the large and
complex data in data-centric AI, traditional methods like exploratory data
analysis (EDA) and cross-validation (CV) face challenges, highlighting the
importance of mastering DQ tools. In this survey, we review 17 DQ evaluation
and improvement tools in the last 5 years. By introducing the DQ dimensions,
metrics, and main functions embedded in these tools, we compare their strengths
and limitations and propose a roadmap for developing open-source DQ tools for
ML. Based on the discussions on the challenges and emerging trends, we further
highlight the potential applications of large language models (LLMs) and
generative AI in DQ evaluation and improvement for ML. We believe this
comprehensive survey can enhance understanding of DQ in ML and could drive
progress in data-centric AI. A complete list of the literature investigated in
this survey is available on GitHub at:
https://github.com/haihua0913/awesome-dq4ml.

摘要：機器學習 (ML) 技術已成為我們社會中幾乎所有方面的實質，而資料品質 (DQ) 對於 ML 模型的效能、公平性、穩健性、安全性與可擴充性至關重要。隨著資料導向 AI 中的資料龐大且複雜，傳統方法（如探索性資料分析 (EDA) 和交叉驗證 (CV)）面臨挑戰，突顯了精通 DQ 工具的重要性。在這項調查中，我們回顧了過去 5 年中的 17 項 DQ 評估和改善工具。透過介紹這些工具中嵌入的 DQ 維度、指標和主要功能，我們比較了它們的優缺點，並提出了開發適用於 ML 的開源 DQ 工具的路線圖。根據對挑戰和新興趨勢的討論，我們進一步強調了大型語言模型 (LLM) 和生成式 AI 在 ML 的 DQ 評估和改善中的潛在應用。我們相信這項全面的調查可以增進對 ML 中 DQ 的理解，並可能推動資料導向 AI 的進展。這項調查中調查的文獻完整清單可在 GitHub 上取得：
https://github.com/haihua0913/awesome-dq4ml。

##### **Multimodal Data Integration for Precision Oncology: Challenges and Future Directions**
2406.19611v1 by Huajun Zhou, Fengtao Zhou, Chenyu Zhao, Yingxue Xu, Luyang Luo, Hao Chen

The essence of precision oncology lies in its commitment to tailor targeted
treatments and care measures to each patient based on the individual
characteristics of the tumor. The inherent heterogeneity of tumors necessitates
gathering information from diverse data sources to provide valuable insights
from various perspectives, fostering a holistic comprehension of the tumor.
Over the past decade, multimodal data integration technology for precision
oncology has made significant strides, showcasing remarkable progress in
understanding the intricate details within heterogeneous data modalities. These
strides have exhibited tremendous potential for improving clinical
decision-making and model interpretation, contributing to the advancement of
cancer care and treatment. Given the rapid progress that has been achieved, we
provide a comprehensive overview of about 300 papers detailing cutting-edge
multimodal data integration techniques in precision oncology. In addition, we
conclude the primary clinical applications that have reaped significant
benefits, including early assessment, diagnosis, prognosis, and biomarker
discovery. Finally, derived from the findings of this survey, we present an
in-depth analysis that explores the pivotal challenges and reveals essential
pathways for future research in the field of multimodal data integration for
precision oncology.

摘要：精準腫瘤學的精髓在於針對每位患者量身打造標靶治療和照護措施，而根據腫瘤的個別特徵。腫瘤的內在異質性需要從不同的資料來源蒐集資訊，以提供來自不同觀點的寶貴見解，促進對腫瘤的整體理解。在過去十年中，精準腫瘤學的多模式資料整合技術已取得顯著進展，在了解異質性資料模式中的複雜細節方面展現出顯著的進展。這些進展已展現出極大的潛力，可改善臨床決策制定和模型詮釋，有助於癌症照護和治療的進步。鑑於已取得的快速進展，我們提供了約 300 篇論文的全面概述，詳細說明精準腫瘤學中尖端的模態資料整合技術。此外，我們總結了已獲得顯著好處的主要臨床應用，包括早期評估、診斷、預後和生物標記發現。最後，根據這項調查結果，我們提出了一項深入分析，探討了關鍵挑戰，並揭示了精準腫瘤學中多模式資料整合領域未來研究的重要途徑。

##### **Mixture of In-Context Experts Enhance LLMs' Long Context Awareness**
2406.19598v1 by Hongzhan Lin, Ang Lv, Yuhan Chen, Chen Zhu, Yang Song, Hengshu Zhu, Rui Yan

Many studies have revealed that large language models (LLMs) exhibit uneven
awareness of different contextual positions.Their limited context awareness can
lead to overlooking critical information and subsequent task failures. While
several approaches have been proposed to enhance LLMs' context awareness,
achieving both effectiveness and efficiency remains challenging.In this paper,
for LLMs utilizing RoPE as position embeddings, we introduce a novel method
called ``Mixture of In-Context Experts'' (MoICE) to address this challenge.
MoICE comprises two key components: a router integrated into each attention
head within LLMs and a lightweight router-only training optimization strategy:
(1) MoICE views each RoPE angle as an `in-context' expert, demonstrated to be
capable of directing the attention of a head to specific contextual positions.
Consequently, each attention head flexibly processes tokens using multiple RoPE
angles dynamically selected by the router to attend to the needed positions.
This approach mitigates the risk of overlooking essential contextual
information. (2) The router-only training strategy entails freezing LLM
parameters and exclusively updating routers for only a few steps. When applied
to open-source LLMs including Llama and Mistral, MoICE surpasses prior methods
across multiple tasks on long context understanding and generation, all while
maintaining commendable inference efficiency.

摘要：許多研究已揭示大型語言模型 (LLM) 展現出對不同脈絡位置的不均等感知。它們受限的脈絡感知可能會導致忽略關鍵資訊和後續的任務失敗。雖然已提出多種方法來增強 LLM 的脈絡感知，但同時達成有效性和效率仍然具有挑戰性。在本文中，對於使用 RoPE 作為位置嵌入的 LLM，我們提出了一種名為「脈絡中專家混合」(MoICE) 的新方法來應對此挑戰。MoICE 包含兩個關鍵組成部分：整合到 LLM 內每個注意力頭中的路由器和輕量級的僅路由器訓練最佳化策略：(1) MoICE 將每個 RoPE 角度視為「脈絡中」的專家，證明有能力將頭部的注意力導向特定的脈絡位置。因此，每個注意力頭使用路由器動態選取的多個 RoPE 角度靈活地處理權杖，以關注所需的職位。此方法減輕了忽略重要脈絡資訊的風險。(2) 僅路由器訓練策略需要凍結 LLM 參數，並僅針對幾個步驟獨家更新路由器。當應用於包括 Llama 和 Mistral 在內的開源 LLM 時，MoICE 在長脈絡理解和生成的多項任務中超越了先前的多種方法，同時維持應有的推論效率。

##### **Optimizing Cyber Defense in Dynamic Active Directories through Reinforcement Learning**
2406.19596v1 by Diksha Goel, Kristen Moore, Mingyu Guo, Derui Wang, Minjune Kim, Seyit Camtepe

This paper addresses a significant gap in Autonomous Cyber Operations (ACO)
literature: the absence of effective edge-blocking ACO strategies in dynamic,
real-world networks. It specifically targets the cybersecurity vulnerabilities
of organizational Active Directory (AD) systems. Unlike the existing literature
on edge-blocking defenses which considers AD systems as static entities, our
study counters this by recognizing their dynamic nature and developing advanced
edge-blocking defenses through a Stackelberg game model between attacker and
defender. We devise a Reinforcement Learning (RL)-based attack strategy and an
RL-assisted Evolutionary Diversity Optimization-based defense strategy, where
the attacker and defender improve each other strategy via parallel gameplay. To
address the computational challenges of training attacker-defender strategies
on numerous dynamic AD graphs, we propose an RL Training Facilitator that
prunes environments and neural networks to eliminate irrelevant elements,
enabling efficient and scalable training for large graphs. We extensively train
the attacker strategy, as a sophisticated attacker model is essential for a
robust defense. Our empirical results successfully demonstrate that our
proposed approach enhances defender's proficiency in hardening dynamic AD
graphs while ensuring scalability for large-scale AD.

摘要：本文探讨了自主网络操作 (ACO) 文献中的一个重大空白：在动态的现实网络中缺乏有效的边缘阻止 ACO 策略。它特别针对组织 Active Directory (AD) 系统的网络安全漏洞。与将 AD 系统视为静态实体的现有边缘阻止防御文献不同，我们的研究通过识别其动态特性并通过攻击者和防御者之间的 Stackelberg 博弈模型开发高级边缘阻止防御来反驳这一点。我们设计了一个基于强化学习 (RL) 的攻击策略和一个 RL 辅助的进化多样性优化防御策略，其中攻击者和防御者通过并行游戏来改进彼此的策略。为了解决在众多动态 AD 图表上训练攻击者-防御者策略的计算挑战，我们提出了一个 RL 训练促进器，它剪除环境和神经网络以消除无关元素，从而实现针对大型图表的高效且可扩展的训练。我们广泛训练攻击者策略，因为一个复杂的攻击者模型对于一个强大的防御至关重要。我们的实证结果成功地证明了我们提出的方法增强了防御者在加固动态 AD 图表方面的能力，同时确保了大规模 AD 的可扩展性。

##### **SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs**
2406.19593v1 by Xin Su, Man Luo, Kris W Pan, Tien Pei Chou, Vasudev Lal, Phillip Howard

Synthetic data generation has gained significant attention recently for its
utility in training large vision and language models. However, the application
of synthetic data to the training of multimodal context-augmented generation
systems has been relatively unexplored. This gap in existing work is important
because existing vision and language models (VLMs) are not trained specifically
for context-augmented generation. Resources for adapting such models are
therefore crucial for enabling their use in retrieval-augmented generation
(RAG) settings, where a retriever is used to gather relevant information that
is then subsequently provided to a generative model via context augmentation.
To address this challenging problem, we generate SK-VQA: a large synthetic
multimodal dataset containing over 2 million question-answer pairs which
require external knowledge to determine the final answer. Our dataset is both
larger and significantly more diverse than existing resources of its kind,
possessing over 11x more unique questions and containing images from a greater
variety of sources than previously-proposed datasets. Through extensive
experiments, we demonstrate that our synthetic dataset can not only serve as a
challenging benchmark, but is also highly effective for adapting existing
generative multimodal models for context-augmented generation.

摘要：合成資料生成最近因其在訓練大型視覺和語言模型中的效用而備受關注。然而，合成資料在多模態上下文擴充生成系統的訓練中的應用相對未經探索。現有工作中的這個差距很重要，因為現有的視覺和語言模型 (VLM) 並非專門針對上下文擴充生成進行訓練。因此，調整此類模型的資源對於讓它們能夠用於檢索擴充生成 (RAG) 設定至關重要，其中檢索器用於收集相關資訊，然後通過上下文擴充提供給生成模型。為了解決這個具有挑戰性的問題，我們生成了 SK-VQA：一個大型合成多模態資料集，包含超過 200 萬個問題解答對，需要外部知識才能確定最終答案。我們的資料集比同類現有資源更大且更為多元，擁有超過 11 倍的獨特問題，且包含來自比先前提出的資料集更多樣化來源的影像。透過廣泛的實驗，我們證明我們的合成資料集不僅可以用作具有挑戰性的基準，而且對於調整現有的生成多模態模型以進行上下文擴充生成也非常有效。

##### **PathAlign: A vision-language model for whole slide images in histopathology**
2406.19578v1 by Faruk Ahmed, Andrew Sellergren, Lin Yang, Shawn Xu, Boris Babenko, Abbi Ward, Niels Olson, Arash Mohtashamian, Yossi Matias, Greg S. Corrado, Quang Duong, Dale R. Webster, Shravya Shetty, Daniel Golden, Yun Liu, David F. Steiner, Ellery Wulczyn

Microscopic interpretation of histopathology images underlies many important
diagnostic and treatment decisions. While advances in vision-language modeling
raise new opportunities for analysis of such images, the gigapixel-scale size
of whole slide images (WSIs) introduces unique challenges. Additionally,
pathology reports simultaneously highlight key findings from small regions
while also aggregating interpretation across multiple slides, often making it
difficult to create robust image-text pairs. As such, pathology reports remain
a largely untapped source of supervision in computational pathology, with most
efforts relying on region-of-interest annotations or self-supervision at the
patch-level. In this work, we develop a vision-language model based on the
BLIP-2 framework using WSIs paired with curated text from pathology reports.
This enables applications utilizing a shared image-text embedding space, such
as text or image retrieval for finding cases of interest, as well as
integration of the WSI encoder with a frozen large language model (LLM) for
WSI-based generative text capabilities such as report generation or
AI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000
WSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure
types, and tissue types. We present pathologist evaluation of text generation
and text retrieval using WSI embeddings, as well as results for WSI
classification and workflow prioritization (slide-level triaging).
Model-generated text for WSIs was rated by pathologists as accurate, without
clinically significant error or omission, for 78% of WSIs on average. This work
demonstrates exciting potential capabilities for language-aligned WSI
embeddings.

摘要：顯微組織病理學影像的微觀詮釋是許多重要的診斷和治療決策的基礎。雖然視覺語言模型的進展為此類影像的分析帶來了新的契機，但全切片影像 (WSI) 的千兆像素等級大小帶來了獨特的挑戰。此外，病理報告同時強調了小區域的關鍵發現，同時也彙總了多個切片的詮釋，這通常使得建立穩健的影像文字對變得困難。因此，病理報告仍然是計算病理學中一個很大程度上未開發的監督來源，大多數工作依賴於感興趣區域註解或在貼片的層級上進行自我監督。在這項工作中，我們基於 BLIP-2 框架開發了一個視覺語言模型，使用與來自病理報告的策展文字配對的 WSI。這使得應用程式能夠使用共享的影像文字嵌入空間，例如文字或影像檢索來尋找感興趣的案例，以及將 WSI 編碼器與凍結的大語言模型 (LLM) 整合，用於 WSI 基於生成文字的能力，例如報告產生或 AI 循環互動。我們利用了一個包含超過 350,000 個 WSI 和診斷文字對的去識別化資料集，涵蓋了廣泛的診斷、程序類型和組織類型。我們展示了病理學家對使用 WSI 嵌入的文字產生和文字檢索的評估，以及 WSI 分類和工作流程優先順序（切片級別分類）的結果。病理學家評估了 WSI 的模型產生的文字，平均而言，78% 的 WSI 準確無臨床顯著錯誤或遺漏。這項工作展示了語言對齊 WSI 嵌入的令人興奮的潛在能力。

##### **Synthetic Cancer -- Augmenting Worms with LLMs**
2406.19570v1 by Benjamin Zimmerman, David Zollikofer

With increasingly sophisticated large language models (LLMs), the potential
for abuse rises drastically. As a submission to the Swiss AI Safety Prize, we
present a novel type of metamorphic malware leveraging LLMs for two key
processes. First, LLMs are used for automatic code rewriting to evade
signature-based detection by antimalware programs. The malware then spreads its
copies via email by utilizing an LLM to socially engineer email replies to
encourage recipients to execute the attached malware. Our submission includes a
functional minimal prototype, highlighting the risks that LLMs pose for
cybersecurity and underscoring the need for further research into intelligent
malware.

摘要：隨著大型語言模型（LLM）日益精進，濫用的可能性也大幅增加。作為提交給瑞士 AI 安全獎的作品，我們提出一種新型態的變形惡意軟體，利用 LLM 進行兩個關鍵程序。首先，LLM 用於自動重寫程式碼，以規避防惡意軟體程式基於簽章的偵測。然後，惡意軟體利用 LLM 透過電子郵件散布其副本，以進行社交工程電子郵件回覆，鼓勵收件人執行所附的惡意軟體。我們的提交包含一個功能性的最小原型，突顯了 LLM 對網路安全的風險，並強調進一步研究智慧型惡意軟體的必要性。

##### **What Matters in Detecting AI-Generated Videos like Sora?**
2406.19568v1 by Chirui Chang, Zhengzhe Liu, Xiaoyang Lyu, Xiaojuan Qi

Recent advancements in diffusion-based video generation have showcased
remarkable results, yet the gap between synthetic and real-world videos remains
under-explored. In this study, we examine this gap from three fundamental
perspectives: appearance, motion, and geometry, comparing real-world videos
with those generated by a state-of-the-art AI model, Stable Video Diffusion. To
achieve this, we train three classifiers using 3D convolutional networks, each
targeting distinct aspects: vision foundation model features for appearance,
optical flow for motion, and monocular depth for geometry. Each classifier
exhibits strong performance in fake video detection, both qualitatively and
quantitatively. This indicates that AI-generated videos are still easily
detectable, and a significant gap between real and fake videos persists.
Furthermore, utilizing the Grad-CAM, we pinpoint systematic failures of
AI-generated videos in appearance, motion, and geometry. Finally, we propose an
Ensemble-of-Experts model that integrates appearance, optical flow, and depth
information for fake video detection, resulting in enhanced robustness and
generalization ability. Our model is capable of detecting videos generated by
Sora with high accuracy, even without exposure to any Sora videos during
training. This suggests that the gap between real and fake videos can be
generalized across various video generative models. Project page:
https://justin-crchang.github.io/3DCNNDetection.github.io/

摘要：近期在基於擴散的影片生成方面的進展展現了顯著的成果，但合成影片與真實影片之間的差距仍有待探索。在這項研究中，我們從三個基本觀點探討這個差距：外觀、動作和幾何，比較真實影片與由最先進的 AI 模型 Stable Video Diffusion 所生成的影片。為此，我們使用 3D 卷積網路訓練三個分類器，每個分類器針對不同的面向：外觀的視覺基礎模型特徵、動作的光流，以及幾何的單眼深度。每個分類器在假影片偵測中都展現出強勁的表現，無論在質量上或量化上皆然。這表示 AI 生成的影片仍然很容易被偵測出來，而且真實影片與假影片之間仍有顯著的差距。此外，利用 Grad-CAM，我們精確指出 AI 生成的影片在外觀、動作和幾何上的系統性失敗。最後，我們提出一個專家整合模型，整合外觀、光流和深度資訊進行假影片偵測，進而增強穩健性和泛化能力。我們的模型能夠偵測由 Sora 生成的影片，準確率很高，即使在訓練過程中沒有接觸過任何 Sora 影片。這表示真實影片與假影片之間的差距可以泛化到各種影片生成模型。專案頁面：https://justin-crchang.github.io/3DCNNDetection.github.io/

##### **Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects**
2406.19564v1 by Orevaoghene Ahia, Anuoluwapo Aremu, Diana Abagyan, Hila Gonen, David Ifeoluwa Adelani, Daud Abolade, Noah A. Smith, Yulia Tsvetkov

Yor\`ub\'a an African language with roughly 47 million speakers encompasses a
continuum with several dialects. Recent efforts to develop NLP technologies for
African languages have focused on their standard dialects, resulting in
disparities for dialects and varieties for which there are little to no
resources or tools. We take steps towards bridging this gap by introducing a
new high-quality parallel text and speech corpus YOR\`ULECT across three
domains and four regional Yor\`ub\'a dialects. To develop this corpus, we
engaged native speakers, travelling to communities where these dialects are
spoken, to collect text and speech data. Using our newly created corpus, we
conducted extensive experiments on (text) machine translation, automatic speech
recognition, and speech-to-text translation. Our results reveal substantial
performance disparities between standard Yor\`ub\'a and the other dialects
across all tasks. However, we also show that with dialect-adaptive finetuning,
we are able to narrow this gap. We believe our dataset and experimental
analysis will contribute greatly to developing NLP tools for Yor\`ub\'a and its
dialects, and potentially for other African languages, by improving our
understanding of existing challenges and offering a high-quality dataset for
further development. We release YOR\`ULECT dataset and models publicly under an
open license.

摘要：<paragraph>Yorùbá 是一種非洲語言，約有 4700 萬名使用者，包含一個連續體和多種方言。最近致力於為非洲語言開發 NLP 技術的努力，都集中在它們的標準方言上，導致方言和變體之間出現差異，而這些方言和變體幾乎沒有或完全沒有資源或工具。我們透過引入一個新的高品質平行文本和語音語料庫 YORÙLECT，跨越三個領域和四種區域 Yorùbá 方言，採取措施來彌合這個差距。為了開發這個語料庫，我們聘請了母語人士，前往這些方言被使用的社群，以收集文本和語音資料。使用我們新建立的語料庫，我們對（文字）機器翻譯、自動語音辨識和語音轉文字翻譯進行了廣泛的實驗。我們的結果揭示了標準 Yorùbá 和所有任務中的其他方言之間的顯著效能差異。然而，我們也表明，透過方言適應微調，我們能夠縮小這個差距。我們相信我們的資料集和實驗分析將透過改善我們對現有挑戰的理解，並提供一個高品質的資料集以供進一步開發，對開發適用於 Yorùbá 及其方言的 NLP 工具，以及其他非洲語言，做出極大的貢獻。我們在開放授權下公開發布 YORÙLECT 資料集和模型。</paragraph>

##### **Meta-Gradient Search Control: A Method for Improving the Efficiency of Dyna-style Planning**
2406.19561v1 by Bradley Burega, John D. Martin, Luke Kapeluck, Michael Bowling

We study how a Reinforcement Learning (RL) system can remain sample-efficient
when learning from an imperfect model of the environment. This is particularly
challenging when the learning system is resource-constrained and in continual
settings, where the environment dynamics change. To address these challenges,
our paper introduces an online, meta-gradient algorithm that tunes a
probability with which states are queried during Dyna-style planning. Our study
compares the aggregate, empirical performance of this meta-gradient method to
baselines that employ conventional sampling strategies. Results indicate that
our method improves efficiency of the planning process, which, as a
consequence, improves the sample-efficiency of the overall learning process. On
the whole, we observe that our meta-learned solutions avoid several pathologies
of conventional planning approaches, such as sampling inaccurate transitions
and those that stall credit assignment. We believe these findings could prove
useful, in future work, for designing model-based RL systems at scale.

摘要：我們研究強化學習 (RL) 系統如何能在從環境的不完美模型中學習時，仍然保持樣本效率。當學習系統資源受限且在環境動態變化的持續設定中時，這項任務特別具有挑戰性。為了應對這些挑戰，我們的論文提出了一種線上元梯度演算法，用來調整在 Dyna 式規劃期間查詢狀態的機率。我們的研究將此元梯度方法的總體經驗效能，與採用傳統抽樣策略的基線方法進行比較。結果顯示，我們的演算法提升了規劃程序的效率，進而提升了整體學習程序的樣本效率。總的來說，我們觀察到我們的元學習解法避免了傳統規劃方法的數種病態，例如抽取不準確的轉換以及阻礙信用指派的轉換。我們相信這些發現對於未來設計大規模的基於模型的 RL 系統很有用。

##### **Rethinking harmless refusals when fine-tuning foundation models**
2406.19552v1 by Florin Pop, Judd Rosenblatt, Diogo Schwerz de Lucena, Michael Vaiana

In this paper, we investigate the degree to which fine-tuning in Large
Language Models (LLMs) effectively mitigates versus merely conceals undesirable
behavior. Through the lens of semi-realistic role-playing exercises designed to
elicit such behaviors, we explore the response dynamics of LLMs post
fine-tuning interventions. Our methodology involves prompting models for
Chain-of-Thought (CoT) reasoning and analyzing the coherence between the
reasoning traces and the resultant outputs. Notably, we identify a pervasive
phenomenon we term \emph{reason-based deception}, where models either stop
producing reasoning traces or produce seemingly ethical reasoning traces that
belie the unethical nature of their final outputs. We further examine the
efficacy of response strategies (polite refusal versus explicit rebuttal) in
curbing the occurrence of undesired behavior in subsequent outputs of
multi-turn interactions. Our findings reveal that explicit rebuttals
significantly outperform polite refusals in preventing the continuation of
undesired outputs and nearly eliminate reason-based deception, challenging
current practices in model fine-tuning. Accordingly, the two key contributions
of this paper are (1) defining and studying reason-based deception, a new type
of hidden behavior, and (2) demonstrating that rebuttals provide a more robust
response model to harmful requests than refusals, thereby highlighting the need
to reconsider the response strategies in fine-tuning approaches.

摘要：<paragraph>在本文中，我們探討大型語言模型 (LLM) 中微調的程度，有效地減輕或僅僅掩蓋不良行為。通過專門引發此類行為的半現實角色扮演練習，我們探討了微調干預後 LLM 的響應動態。我們的研究方法涉及提示模型進行思想鏈 (CoT) 推理，並分析推理軌跡和結果輸出之間的一致性。值得注意的是，我們發現了一個普遍存在的現象，我們稱之為「基於推理的欺騙」，其中模型要么停止產生推理軌跡，要么產生看似合乎道德的推理軌跡，而這些推理軌跡卻掩蓋了其最終輸出的不道德性質。我們進一步檢驗了響應策略（禮貌拒絕與明確反駁）在遏制多輪互動後續輸出中出現不良行為方面的有效性。我們的研究結果表明，明確的反駁在防止不良輸出持續方面明顯優於禮貌的拒絕，並且幾乎消除了基於推理的欺騙，對模型微調中的現行做法提出了挑戰。因此，本文的兩個關鍵貢獻是：(1) 定義和研究基於推理的欺騙，一種新型的隱藏行為，以及 (2) 證明反駁為有害請求提供了一個比拒絕更強大的響應模型，從而強調需要重新考慮微調方法中的響應策略。</paragraph>

##### **Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations**
2406.19545v1 by Ritam Dutt, Zhen Wu, Kelly Shi, Divyanshu Sheth, Prakhar Gupta, Carolyn Penstein Rose

We present a generalizable classification approach that leverages Large
Language Models (LLMs) to facilitate the detection of implicitly encoded social
meaning in conversations. We design a multi-faceted prompt to extract a textual
explanation of the reasoning that connects visible cues to underlying social
meanings. These extracted explanations or rationales serve as augmentations to
the conversational text to facilitate dialogue understanding and transfer. Our
empirical results over 2,340 experimental settings demonstrate the significant
positive impact of adding these rationales. Our findings hold true for
in-domain classification, zero-shot, and few-shot domain transfer for two
different social meaning detection tasks, each spanning two different corpora.

摘要：我們提出了一種可推廣的分類方法，該方法利用大型語言模型 (LLM) 來促進對話中隱含編碼的社會意義的檢測。我們設計了一個多方面的提示，以提取文本說明，說明將可見線索與潛在社會意義聯繫起來的推理。這些提取的解釋或依據作為對話文本的擴充，以促進對話理解和轉移。我們在 2,340 個實驗設置中的實證結果證明了添加這些依據的顯著正面影響。我們的發現對於兩個不同的社會意義檢測任務的領域內分類、零次學習和少量學習領域轉移是成立的，每個任務都跨越兩個不同的語料庫。

##### **Context Matters: An Empirical Study of the Impact of Contextual Information in Temporal Question Answering Systems**
2406.19538v1 by Dan Schumacher, Fatemeh Haji, Tara Grey, Niharika Bandlamudi, Nupoor Karnik, Gagana Uday Kumar, Jason Cho-Yu Chiang, Paul Rad, Nishant Vishwamitra, Anthony Rios

Large language models (LLMs) often struggle with temporal reasoning, crucial
for tasks like historical event analysis and time-sensitive information
retrieval. Despite advancements, state-of-the-art models falter in handling
temporal information, especially when faced with irrelevant or noisy contexts.
This paper addresses this gap by empirically examining the robustness of
temporal question-answering (TQA) systems trained on various context types,
including relevant, irrelevant, slightly altered, and no context. Our findings
indicate that training with a mix of these contexts enhances model robustness
and accuracy. Additionally, we show that the position of context relative to
the question significantly impacts performance, with question-first positioning
yielding better results. We introduce two new context-rich TQA datasets,
ContextAQA and ContextTQE, and provide comprehensive evaluations and guidelines
for training robust TQA models. Our work lays the foundation for developing
reliable and context-aware temporal QA systems, with broader implications for
enhancing LLM robustness against diverse and potentially adversarial
information.

摘要：大型語言模型 (LLM) 經常難以進行時間推理，這對歷史事件分析和時間敏感資訊檢索等任務至關重要。儘管有進展，但最先進的模型在處理時間資訊時仍會出錯，尤其是在面對不相關或有雜訊的背景時。本文透過實證探討在各種背景類型（包括相關、不相關、略有變動和無背景）上訓練的時間問答 (TQA) 系統的穩健性來解決這個差距。我們的研究結果表明，使用這些背景的組合進行訓練可增強模型的穩健性和準確性。此外，我們表明背景相對於問題的位置會顯著影響效能，問題優先定位會產生更好的結果。我們引入了兩個新的富含背景的 TQA 資料集，ContextAQA 和 ContextTQE，並提供了用於訓練穩健 TQA 模型的全面評估和指南。我們的研究為開發可靠且具背景感知的時間問答系統奠定了基礎，並對增強 LLM 對各種潛在對抗資訊的穩健性具有更廣泛的意義。

##### **Handling Ontology Gaps in Semantic Parsing**
2406.19537v1 by Andrea Bacciu, Marco Damonte, Marco Basaldella, Emilio Monti

The majority of Neural Semantic Parsing (NSP) models are developed with the
assumption that there are no concepts outside the ones such models can
represent with their target symbols (closed-world assumption). This assumption
leads to generate hallucinated outputs rather than admitting their lack of
knowledge. Hallucinations can lead to wrong or potentially offensive responses
to users. Hence, a mechanism to prevent this behavior is crucial to build
trusted NSP-based Question Answering agents. To that end, we propose the
Hallucination Simulation Framework (HSF), a general setting for stimulating and
analyzing NSP model hallucinations. The framework can be applied to any NSP
task with a closed-ontology. Using the proposed framework and KQA Pro as the
benchmark dataset, we assess state-of-the-art techniques for hallucination
detection. We then present a novel hallucination detection strategy that
exploits the computational graph of the NSP model to detect the NSP
hallucinations in the presence of ontology gaps, out-of-domain utterances, and
to recognize NSP errors, improving the F1-Score respectively by ~21, ~24% and
~1%. This is the first work in closed-ontology NSP that addresses the problem
of recognizing ontology gaps. We release our code and checkpoints at
https://github.com/amazon-science/handling-ontology-gaps-in-semantic-parsing.

摘要：大多數的神經語意分析 (NSP) 模型都是基於這樣的假設：沒有任何概念在這些模型可以用其目標符號 (封閉世界假設) 表示的範圍之外。這個假設會產生虛構的輸出，而不是承認它們的知識不足。虛構可能會導致對使用者產生錯誤或潛在的冒犯性回應。因此，一種防止這種行為的機制對於建構值得信賴的基於 NSP 的問答代理程式至關重要。為此，我們提出了虛構模擬架構 (HSF)，一個用於刺激和分析 NSP 模型虛構的通用設定。此架構可以應用於任何具有封閉本體論的 NSP 任務。使用提議的架構和 KQA Pro 作為基準資料集，我們評估了最先進的虛構偵測技術。然後，我們提出了一種新穎的虛構偵測策略，利用 NSP 模型的計算圖表來偵測 NSP 虛構，在存在本體論差距、領域外語句的情況下，以及辨識 NSP 錯誤，分別將 F1 分數提升了約 21%、24% 和 1%。這是封閉本體論 NSP 中第一個解決辨識本體論差距問題的研究。我們在 https://github.com/amazon-science/handling-ontology-gaps-in-semantic-parsing 上發布我們的程式碼和檢查點。

##### **Using Large Language Models to Assist Video Content Analysis: An Exploratory Study of Short Videos on Depression**
2406.19528v1 by Jiaying Liu, Yunlong Wang, Yao Lyu, Yiheng Su, Shuo Niu, Xuhai "Orson" Xu, Yan Zhang

Despite the growing interest in leveraging Large Language Models (LLMs) for
content analysis, current studies have primarily focused on text-based content.
In the present work, we explored the potential of LLMs in assisting video
content analysis by conducting a case study that followed a new workflow of
LLM-assisted multimodal content analysis. The workflow encompasses codebook
design, prompt engineering, LLM processing, and human evaluation. We
strategically crafted annotation prompts to get LLM Annotations in structured
form and explanation prompts to generate LLM Explanations for a better
understanding of LLM reasoning and transparency. To test LLM's video annotation
capabilities, we analyzed 203 keyframes extracted from 25 YouTube short videos
about depression. We compared the LLM Annotations with those of two human
coders and found that LLM has higher accuracy in object and activity
Annotations than emotion and genre Annotations. Moreover, we identified the
potential and limitations of LLM's capabilities in annotating videos. Based on
the findings, we explore opportunities and challenges for future research and
improvements to the workflow. We also discuss ethical concerns surrounding
future studies based on LLM-assisted video analysis.

摘要：儘管利用大型語言模型 (LLM) 進行內容分析的興趣日益濃厚，但目前的研究主要集中於基於文字的內容。在目前的工作中，我們探討了 LLM 在協助影片內容分析方面的潛力，方法是進行一個案例研究，遵循 LLM 輔助多模態內容分析的新工作流程。該工作流程包含代碼簿設計、提示工程、LLM 處理和人工評估。我們策略性地製作註釋提示，以結構化的形式取得 LLM 註釋，並說明提示以產生 LLM 說明，以便更了解 LLM 推理和透明度。為了測試 LLM 的影片註釋能力，我們分析了從 25 個關於憂鬱症的 YouTube 短片中提取的 203 個關鍵影格。我們將 LLM 註釋與兩個人類編碼器的註釋進行比較，發現 LLM 在物件和活動註釋方面的準確度高於情緒和類型註釋。此外，我們確定了 LLM 在影片註釋方面的潛力與限制。根據研究結果，我們探討了未來研究和工作流程改進的機會和挑戰。我們也討論了基於 LLM 輔助影片分析的未來研究中周圍的倫理問題。

##### **TocBERT: Medical Document Structure Extraction Using Bidirectional Transformers**
2406.19526v1 by Majd Saleh, Sarra Baghdadi, Stéphane Paquelet

Text segmentation holds paramount importance in the field of Natural Language
Processing (NLP). It plays an important role in several NLP downstream tasks
like information retrieval and document summarization. In this work, we propose
a new solution, namely TocBERT, for segmenting texts using bidirectional
transformers. TocBERT represents a supervised solution trained on the detection
of titles and sub-titles from their semantic representations. This task was
formulated as a named entity recognition (NER) problem. The solution has been
applied on a medical text segmentation use-case where the Bio-ClinicalBERT
model is fine-tuned to segment discharge summaries of the MIMIC-III dataset.
The performance of TocBERT has been evaluated on a human-labeled ground truth
corpus of 250 notes. It achieved an F1-score of 84.6% when evaluated on a
linear text segmentation problem and 72.8% on a hierarchical text segmentation
problem. It outperformed a carefully designed rule-based solution, particularly
in distinguishing titles from subtitles.

摘要：文本分隔在自然語言處理 (NLP) 領域中至關重要。它在多項 NLP 下游任務中扮演著重要的角色，例如資訊檢索和文件摘要。在這項工作中，我們提出了一個新的解決方案，即 TocBERT，用於使用雙向轉換器對文本進行分隔。TocBERT 是一種監督式解決方案，針對從其語義表示中偵測標題和子標題進行訓練。這項任務被表述為命名實體識別 (NER) 問題。該解決方案已應用於醫學文本分隔用例，其中 Bio-ClinicalBERT 模型經過微調以分隔 MIMIC-III 資料集的出院摘要。TocBERT 的效能已在 250 則筆記的人工標記真實語料庫中進行評估。在線性文本分隔問題上進行評估時，它的 F1 分數達到 84.6%，在階層式文本分隔問題上達到 72.8%。它優於精心設計的基於規則的解決方案，特別是在區分標題和子標題方面。

##### **Captioning Visualizations with Large Language Models (CVLLM): A Tutorial**
2406.19512v1 by Giuseppe Carenini, Jordon Johnson, Ali Salamatian

Automatically captioning visualizations is not new, but recent advances in
large language models(LLMs) open exciting new possibilities. In this tutorial,
after providing a brief review of Information Visualization (InfoVis)
principles and past work in captioning, we introduce neural models and the
transformer architecture used in generic LLMs. We then discuss their recent
applications in InfoVis, with a focus on captioning. Additionally, we explore
promising future directions in this field.

摘要：自動為視覺化加上標題並非新事物，但大型語言模型 (LLM) 的最新進展開啟了令人興奮的新可能性。在本教學課程中，在簡要回顧資訊視覺化 (InfoVis) 原則和標題的過去工作後，我們將介紹神經模型和通用 LLM 中使用的轉換器架構。然後，我們將討論其在 InfoVis 中的最新應用，重點放在標題上。此外，我們將探討該領域有希望的未來方向。

##### **Too Good to be True? Turn Any Model Differentially Private With DP-Weights**
2406.19507v1 by David Zagardo

Imagine training a machine learning model with Differentially Private
Stochastic Gradient Descent (DP-SGD), only to discover post-training that the
noise level was either too high, crippling your model's utility, or too low,
compromising privacy. The dreaded realization hits: you must start the lengthy
training process from scratch. But what if you could avoid this retraining
nightmare? In this study, we introduce a groundbreaking approach (to our
knowledge) that applies differential privacy noise to the model's weights after
training. We offer a comprehensive mathematical proof for this novel approach's
privacy bounds, use formal methods to validate its privacy guarantees, and
empirically evaluate its effectiveness using membership inference attacks and
performance evaluations. This method allows for a single training run, followed
by post-hoc noise adjustments to achieve optimal privacy-utility trade-offs. We
compare this novel fine-tuned model (DP-Weights model) to a traditional DP-SGD
model, demonstrating that our approach yields statistically similar performance
and privacy guarantees. Our results validate the efficacy of post-training
noise application, promising significant time savings and flexibility in
fine-tuning differential privacy parameters, making it a practical alternative
for deploying differentially private models in real-world scenarios.

摘要：想像一下訓練一個機器學習模型，使用差分隱私隨機梯度下降 (DP-SGD)，只有在訓練後才發現噪音等級太高，損害模型的效用，或太低，損害隱私。可怕的認知襲來：你必須從頭開始冗長的訓練過程。但是，如果你可以避免這種重新訓練的惡夢呢？在本研究中，我們介紹了一種開創性方法（據我們所知），在訓練後將差分隱私噪音應用於模型的權重。我們為這種新方法的隱私界限提供了一個全面的數學證明，使用形式化方法驗證其隱私保證，並使用成員推論攻擊和效能評估經驗評估其有效性。此方法允許單次訓練運行，然後進行事後噪音調整，以實現最佳的隱私效用權衡。我們將這個新微調模型（DP-Weights 模型）與傳統的 DP-SGD 模型進行比較，證明我們的方法產生統計上相似的效能和隱私保證。我們的結果驗證了訓練後噪音應用程式，承諾在微調差分隱私參數時節省大量時間和靈活性，使其成為在現實世界場景中部署差分隱私模型的實用替代方案。

##### **Are Generative Language Models Multicultural? A Study on Hausa Culture and Emotions using ChatGPT**
2406.19504v1 by Ibrahim Said Ahmad, Shiran Dudy, Resmi Ramachandranpillai, Kenneth Church

Large Language Models (LLMs), such as ChatGPT, are widely used to generate
content for various purposes and audiences. However, these models may not
reflect the cultural and emotional diversity of their users, especially for
low-resource languages. In this paper, we investigate how ChatGPT represents
Hausa's culture and emotions. We compare responses generated by ChatGPT with
those provided by native Hausa speakers on 37 culturally relevant questions. We
conducted experiments using emotion analysis and applied two similarity metrics
to measure the alignment between human and ChatGPT responses. We also collected
human participants ratings and feedback on ChatGPT responses. Our results show
that ChatGPT has some level of similarity to human responses, but also exhibits
some gaps and biases in its knowledge and awareness of the Hausa culture and
emotions. We discuss the implications and limitations of our methodology and
analysis and suggest ways to improve the performance and evaluation of LLMs for
low-resource languages.

摘要：大型語言模型 (LLM)，例如 ChatGPT，廣泛用於為各種目的和受眾產生內容。然而，這些模型可能無法反映其使用者的文化和情感多樣性，特別是對於低資源語言。在本文中，我們探討 ChatGPT 如何呈現豪薩文化和情感。我們將 ChatGPT 產生的回應與豪薩母語人士在 37 個與文化相關的問題上提供的回應進行比較。我們使用情緒分析進行實驗，並應用兩個相似性指標來衡量人類和 ChatGPT 回應之間的一致性。我們還收集了人類參與者對 ChatGPT 回應的評分和回饋。我們的結果表明，ChatGPT 與人類的回應具有一定的相似性，但在其對豪薩文化和情感的知識和認識中也存在一些差距和偏見。我們討論了我們方法和分析的含義和局限性，並提出改進 LLM 對低資源語言的性能和評估的方法。

##### **Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**
2406.19502v1 by Miyoung Ko, Sue Hyun Park, Joonsuk Park, Minjoon Seo

Despite significant advancements, there is a limited understanding of how
large language models (LLMs) utilize knowledge for reasoning. To address this,
we propose a method that deconstructs complex real-world questions into a
graph, representing each question as a node with parent nodes of background
knowledge needed to solve the question. We develop the DepthQA dataset,
deconstructing questions into three depths: (i) recalling conceptual knowledge,
(ii) applying procedural knowledge, and (iii) analyzing strategic knowledge.
Based on a hierarchical graph, we quantify forward discrepancy, discrepancies
in LLMs' performance on simpler sub-problems versus complex questions. We also
measure backward discrepancy, where LLMs answer complex questions but struggle
with simpler ones. Our analysis shows that smaller models have more
discrepancies than larger models. Additionally, guiding models from simpler to
complex questions through multi-turn interactions improves performance across
model sizes, highlighting the importance of structured intermediate steps in
knowledge reasoning. This work enhances our understanding of LLM reasoning and
suggests ways to improve their problem-solving abilities.

摘要：儘管有顯著的進展，但對於大型語言模型 (LLM) 如何利用知識進行推理的理解仍然有限。為了解決這個問題，我們提出了一種方法，將複雜的真實世界問題解構成一個圖形，將每個問題表示為一個節點，其中包含解決問題所需的背景知識的父節點。我們開發了 DepthQA 資料集，將問題解構成三個深度：(i) 回憶概念知識，(ii) 應用程序知識，以及 (iii) 分析策略知識。基於一個階層圖形，我們量化了正向差異，LLM 在較簡單的子問題和複雜問題上的效能差異。我們也測量了反向差異，其中 LLM 能回答複雜問題，但在較簡單的問題上卻有困難。我們的分析顯示，較小的模型比較大的模型有更多的差異。此外，透過多回合互動引導模型從較簡單到複雜的問題，可以改善所有模型規模的效能，突顯了結構化中間步驟在知識推理中的重要性。這項工作增進了我們對 LLM 推理的理解，並提出了改善其問題解決能力的方法。

##### **Monitoring Latent World States in Language Models with Propositional Probes**
2406.19501v1 by Jiahai Feng, Stuart Russell, Jacob Steinhardt

Language models are susceptible to bias, sycophancy, backdoors, and other
tendencies that lead to unfaithful responses to the input context. Interpreting
internal states of language models could help monitor and correct unfaithful
behavior. We hypothesize that language models represent their input contexts in
a latent world model, and seek to extract this latent world state from the
activations. We do so with 'propositional probes', which compositionally probe
tokens for lexical information and bind them into logical propositions
representing the world state. For example, given the input context ''Greg is a
nurse. Laura is a physicist.'', we decode the propositions ''WorksAs(Greg,
nurse)'' and ''WorksAs(Laura, physicist)'' from the model's activations. Key to
this is identifying a 'binding subspace' in which bound tokens have high
similarity (''Greg'' and ''nurse'') but unbound ones do not (''Greg'' and
''physicist''). We validate propositional probes in a closed-world setting with
finitely many predicates and properties. Despite being trained on simple
templated contexts, propositional probes generalize to contexts rewritten as
short stories and translated to Spanish. Moreover, we find that in three
settings where language models respond unfaithfully to the input context --
prompt injections, backdoor attacks, and gender bias -- the decoded
propositions remain faithful. This suggests that language models often encode a
faithful world model but decode it unfaithfully, which motivates the search for
better interpretability tools for monitoring LMs.

摘要：語言模型容易受到偏見、阿諛奉承、後門和其他導致對輸入背景做出不忠實回應的傾向影響。解釋語言模型的內部狀態有助於監控和糾正不忠實的行為。我們假設語言模型在其潛在世界模型中表示其輸入背景，並試圖從激活中提取這個潛在世界狀態。我們使用「命題探針」來做到這一點，它以組合方式探查詞彙資訊的標記，並將它們綁定到表示世界狀態的邏輯命題中。例如，給定輸入背景「葛雷格是護士。蘿拉是物理學家。」，我們從模型的激活中解碼命題「WorksAs(葛雷格，護士)」和「WorksAs(蘿拉，物理學家)」。關鍵是要識別一個「結合子空間」，其中結合的標記具有高度相似性（「葛雷格」和「護士」），但未結合的標記則沒有（「葛雷格」和「物理學家」）。我們在具有有限多謂詞和屬性的封閉世界設定中驗證命題探針。儘管在簡單的範本背景下進行訓練，命題探針仍可概括為改寫成短篇故事並翻譯成西班牙語的背景。此外，我們發現，在語言模型對輸入背景做出不忠實回應的三種情況下——提示注入、後門攻擊和性別偏見——解碼的命題仍然忠實。這表明語言模型通常編碼一個忠實的世界模型，但對它的解碼不忠實，這激勵了尋找更好的可解釋性工具來監控語言模型。

##### **Knowledge acquisition for dialogue agents using reinforcement learning on graph representations**
2406.19500v1 by Selene Baez Santamaria, Shihan Wang, Piek Vossen

We develop an artificial agent motivated to augment its knowledge base beyond
its initial training. The agent actively participates in dialogues with other
agents, strategically acquiring new information. The agent models its knowledge
as an RDF knowledge graph, integrating new beliefs acquired through
conversation. Responses in dialogue are generated by identifying graph patterns
around these new integrated beliefs. We show that policies can be learned using
reinforcement learning to select effective graph patterns during an
interaction, without relying on explicit user feedback. Within this context,
our study is a proof of concept for leveraging users as effective sources of
information.

摘要：我們開發了一種人工代理，其動機是擴充其知識庫，超越其最初的訓練。該代理積極參與與其他代理的對話，策略性地獲取新資訊。該代理將其知識建模為 RDF 知識圖譜，整合透過對話獲取的新信念。對話中的回應是透過識別這些新整合信念周圍的圖形模式而產生的。我們證明了可以在不依賴明確使用者回饋的情況下，使用強化學習來學習政策，以便在互動過程中選擇有效的圖形模式。在此背景下，我們的研究證明了利用使用者作為有效資訊來源的概念。

##### **Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts**
2406.19497v1 by Naseela Pervez, Alexander J. Titus

Large language models (LLMs) are increasingly utilized to assist in
scientific and academic writing, helping authors enhance the coherence of their
articles. Previous studies have highlighted stereotypes and biases present in
LLM outputs, emphasizing the need to evaluate these models for their alignment
with human narrative styles and potential gender biases. In this study, we
assess the alignment of three prominent LLMs - Claude 3 Opus, Mistral AI Large,
and Gemini 1.5 Flash - by analyzing their performance on benchmark
text-generation tasks for scientific abstracts. We employ the Linguistic
Inquiry and Word Count (LIWC) framework to extract lexical, psychological, and
social features from the generated texts. Our findings indicate that, while
these models generally produce text closely resembling human authored content,
variations in stylistic features suggest significant gender biases. This
research highlights the importance of developing LLMs that maintain a diversity
of writing styles to promote inclusivity in academic discourse.

摘要：大型語言模型 (LLM) 愈來愈常被用於協助科學和學術寫作，幫助作者提升文章的條理性。先前的研究強調了 LLM 產出中存在的刻板印象和偏見，強調了評估這些模型與人類敘事風格和潛在性別偏見一致性的必要性。在這項研究中，我們透過分析大型語言模型在科學摘要的基準文本生成任務上的表現，評估了三個著名的 LLM（Claude 3 Opus、Mistral AI Large 和 Gemini 1.5 Flash）的一致性。我們採用語言探究和單字計數 (LIWC) 架構從產生的文本中萃取詞彙、心理和社會特徵。我們的發現顯示，雖然這些模型通常產生的文本與人類撰寫的內容非常相似，但文體特徵的差異顯示出顯著的性別偏見。這項研究強調了開發能維持寫作風格多樣性的 LLM 的重要性，以促進學術論述的包容性。

##### **Development and Evaluation of a Retrieval-Augmented Generation Tool for Creating SAPPhIRE Models of Artificial Systems**
2406.19493v1 by Anubhab Majumder, Kausik Bhattacharya, Amaresh Chakrabarti

Representing systems using the SAPPhIRE causality model is found useful in
supporting design-by-analogy. However, creating a SAPPhIRE model of artificial
or biological systems is an effort-intensive process that requires human
experts to source technical knowledge from multiple technical documents
regarding how the system works. This research investigates how to leverage
Large Language Models (LLMs) in creating structured descriptions of systems
using the SAPPhIRE model of causality. This paper, the second part of the
two-part research, presents a new Retrieval-Augmented Generation (RAG) tool for
generating information related to SAPPhIRE constructs of artificial systems and
reports the results from a preliminary evaluation of the tool's success -
focusing on the factual accuracy and reliability of outcomes.

摘要：使用 SAPPhIRE 因果模型表示系統在支援類比設計方面很有用。然而，建立人工或生物系統的 SAPPhIRE 模型是一個需要大量人力且需要人類專家從多份技術文件取得系統運作方式的技術知識的過程。本研究探討如何利用大型語言模型 (LLM) 在使用 SAPPhIRE 因果模型建立系統的結構化描述。本文是兩部分研究的第二部分，提出了一個新的檢索增強生成 (RAG) 工具，用於產生與人工系統的 SAPPhIRE 建構相關的資訊，並報告工具成功初步評估的結果，重點在於成果的事實準確性和可靠性。

##### **LoPT: Low-Rank Prompt Tuning for Parameter Efficient Language Models**
2406.19486v1 by Shouchang Guo, Sonam Damani, Keng-hao Chang

In prompt tuning, a prefix or suffix text is added to the prompt, and the
embeddings (soft prompts) or token indices (hard prompts) of the prefix/suffix
are optimized to gain more control over language models for specific tasks.
This approach eliminates the need for hand-crafted prompt engineering or
explicit model fine-tuning. Prompt tuning is significantly more
parameter-efficient than model fine-tuning, as it involves optimizing partial
inputs of language models to produce desired outputs.
  In this work, we aim to further reduce the amount of trainable parameters
required for a language model to perform well on specific tasks. We propose
Low-rank Prompt Tuning (LoPT), a low-rank model for prompts that achieves
efficient prompt optimization. The proposed method demonstrates similar
outcomes to full parameter prompt tuning while reducing the number of trainable
parameters by a factor of 5. It also provides promising results compared to the
state-of-the-art methods that would require 10 to 20 times more parameters.

摘要：在提示調整中，會在提示中加入前綴或後綴文字，並且最佳化前綴/後綴的嵌入（軟提示）或符號索引（硬提示），以獲得對特定任務語言模型的更多控制。
這種方法消除了手工提示工程或明確模型微調的需要。提示調整比模型微調顯著更有效率，因為它涉及最佳化語言模型的部分輸入以產生所需的輸出。
在這項工作中，我們旨在進一步減少語言模型在特定任務上表現良好所需的訓練參數量。我們提出低秩提示調整 (LoPT)，一種用於提示的低秩模型，可實現高效的提示最佳化。所提出的方法展示了與完整參數提示調整類似的結果，同時將可訓練參數的數量減少了 5 倍。與需要多 10 到 20 倍參數的最新方法相比，它也提供了有希望的結果。

##### **xTower: A Multilingual LLM for Explaining and Correcting Translation Errors**
2406.19482v1 by Marcos Treviso, Nuno M. Guerreiro, Sweta Agrawal, Ricardo Rei, José Pombal, Tania Vaz, Helena Wu, Beatriz Silva, Daan van Stigt, André F. T. Martins

While machine translation (MT) systems are achieving increasingly strong
performance on benchmarks, they often produce translations with errors and
anomalies. Understanding these errors can potentially help improve the
translation quality and user experience. This paper introduces xTower, an open
large language model (LLM) built on top of TowerBase designed to provide
free-text explanations for translation errors in order to guide the generation
of a corrected translation. The quality of the generated explanations by xTower
are assessed via both intrinsic and extrinsic evaluation. We ask expert
translators to evaluate the quality of the explanations across two dimensions:
relatedness towards the error span being explained and helpfulness in error
understanding and improving translation quality. Extrinsically, we test xTower
across various experimental setups in generating translation corrections,
demonstrating significant improvements in translation quality. Our findings
highlight xTower's potential towards not only producing plausible and helpful
explanations of automatic translations, but also leveraging them to suggest
corrected translations.

摘要：儘管機器翻譯 (MT) 系統在基準測試上表現得越來越強勁，它們產生的翻譯卻常常有錯誤和異常。了解這些錯誤有可能有助於改善翻譯品質和使用者體驗。本文介紹 xTower，一個建立在 TowerBase 上的開放大型語言模型 (LLM)，設計用於提供翻譯錯誤的自由文字說明，以引導產生修正的翻譯。xTower 產生的說明品質是透過內在和外在評量來評估。我們請專業翻譯人員評量說明的品質，包含兩個面向：與說明的錯誤範圍相關性，以及在了解錯誤和改善翻譯品質上的助益。外在而言，我們在產生翻譯修正的各種實驗設定中測試 xTower，證明翻譯品質有顯著的改善。我們的發現強調了 xTower 不僅有潛力產生合情合理且有幫助的自動翻譯說明，還能利用這些說明建議修正的翻譯。

##### **Sparse Regression for Machine Translation**
2406.19478v1 by Ergun Biçici

We use transductive regression techniques to learn mappings between source
and target features of given parallel corpora and use these mappings to
generate machine translation outputs. We show the effectiveness of $L_1$
regularized regression (\textit{lasso}) to learn the mappings between sparsely
observed feature sets versus $L_2$ regularized regression. Proper selection of
training instances plays an important role to learn correct feature mappings
within limited computational resources and at expected accuracy levels. We
introduce \textit{dice} instance selection method for proper selection of
training instances, which plays an important role to learn correct feature
mappings for improving the source and target coverage of the training set. We
show that $L_1$ regularized regression performs better than $L_2$ regularized
regression both in regression measurements and in the translation experiments
using graph decoding. We present encouraging results when translating from
German to English and Spanish to English. We also demonstrate results when the
phrase table of a phrase-based decoder is replaced with the mappings we find
with the regression model.

摘要：我們使用轉導回歸技術來學習給定平行語料庫中源語言和目標語言特徵之間的對應關係，並使用這些對應關係來產生機器翻譯輸出。我們展示了 $L_1$ 正則化回歸（\textit{套索}）在學習稀疏觀察特徵集與 $L_2$ 正則化回歸之間對應關係的有效性。適當選擇訓練實例在學習正確的特徵對應關係方面扮演著重要的角色，在有限的計算資源和預期的準確度等級中。我們引入了 \textit{骰子} 實例選擇方法來適當選擇訓練實例，這在學習正確的特徵對應關係以改善訓練集的源語言和目標語言覆蓋範圍方面扮演著重要的角色。我們展示了 $L_1$ 正則化回歸在回歸測量和使用圖形解碼的翻譯實驗中都比 $L_2$ 正則化回歸表現得更好。當從德語翻譯成英語和西班牙語翻譯成英語時，我們提出了令人鼓舞的結果。當基於短語的解碼器的短語表被我們使用回歸模型找到的對應關係取代時，我們也展示了結果。

##### **Changing Answer Order Can Decrease MMLU Accuracy**
2406.19470v1 by Vipul Gupta, David Pantoja, Candace Ross, Adina Williams, Megan Ung

As large language models (LLMs) have grown in prevalence, particular
benchmarks have become essential for the evaluation of these models and for
understanding model capabilities. Most commonly, we use test accuracy averaged
across multiple subtasks in order to rank models on leaderboards, to determine
which model is best for our purposes. In this paper, we investigate the
robustness of the accuracy measurement on a widely used multiple choice
question answering dataset, MMLU. When shuffling the answer label contents, we
find that all explored models decrease in accuracy on MMLU, but not every model
is equally sensitive. These findings suggest a possible adjustment to the
standard practice of leaderboard testing, where we additionally consider the
percentage of examples each model answers correctly by random chance.

摘要：隨著大型語言模型 (LLM) 的普及，特定基準已成為評估這些模型和了解模型功能的必要條件。最常見的做法是，我們使用在多個子任務中平均的測試準確度，以便在排行榜上對模型進行排名，以確定哪個模型最適合我們的目的。在本文中，我們探討了廣泛使用的多項選擇問答資料集 MMLU 上的準確度測量的穩健性。在洗牌答案標籤內容時，我們發現所有探索的模型在 MMLU 上的準確度都會下降，但並非每個模型都同樣敏感。這些發現表明，我們可以對排行榜測試的標準做法進行可能的調整，其中我們另外考慮每個模型通過隨機機會正確回答的範例百分比。

##### **Can Large Language Models Generate High-quality Patent Claims?**
2406.19465v1 by Lekang Jiang, Caiqi Zhang, Pascal A Scherz, Stephan Goetz

Large language models (LLMs) have shown exceptional performance across
various text generation tasks but remain under-explored in the patent domain,
which offers highly structured and precise language. This paper constructs a
dataset to investigate the performance of current LLMs in patent claim
generation. Our results demonstrate that generating claims based on patent
descriptions outperforms previous research relying on abstracts. Interestingly,
current patent-specific LLMs perform much worse than state-of-the-art general
LLMs, highlighting the necessity for future research on in-domain LLMs. We also
find that LLMs can produce high-quality first independent claims, but their
performances markedly decrease for subsequent dependent claims. Moreover,
fine-tuning can enhance the completeness of inventions' features, conceptual
clarity, and feature linkage. Among the tested LLMs, GPT-4 demonstrates the
best performance in comprehensive human evaluations by patent experts, with
better feature coverage, conceptual clarity, and technical coherence. Despite
these capabilities, comprehensive revision and modification are still necessary
to pass rigorous patent scrutiny and ensure legal robustness.

摘要：大型語言模型（LLM）在各種文本生成任務中表現出色，但在專利領域仍未得到充分探索，而專利領域提供了高度結構化且精確的語言。本文構建了一個數據集，用於調查當前 LLM 在專利權利要求生成中的性能。我們的結果表明，基於專利說明生成權利要求的表現優於依賴摘要的先前研究。有趣的是，當前的專利特定 LLM 的表現遠遜於最先進的通用 LLM，這凸顯了未來對領域內 LLM 研究的必要性。我們還發現，LLM 可以產生高質量的第一個獨立權利要求，但它們的性能對於後續的依賴權利要求會顯著下降。此外，微調可以增強發明的特徵的完整性、概念清晰度和特徵聯繫。在測試的 LLM 中，GPT-4 在專利專家的綜合人類評估中表現出最佳性能，具有更好的特徵覆蓋、概念清晰度和技術連貫性。儘管具有這些能力，但仍需要全面的修改和修改才能通過嚴格的專利審查並確保法律穩健性。

##### **Taming Data and Transformers for Audio Generation**
2406.19388v1 by Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, Vicente Ordonez

Generating ambient sounds and effects is a challenging problem due to data
scarcity and often insufficient caption quality, making it difficult to employ
large-scale generative models for the task. In this work, we tackle the problem
by introducing two new models. First, we propose AutoCap, a high-quality and
efficient automatic audio captioning model. We show that by leveraging metadata
available with the audio modality, we can substantially improve the quality of
captions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from
the best available captioning model at four times faster inference speed. We
then use AutoCap to caption clips from existing datasets, obtaining 761,000
audio clips with high-quality captions, forming the largest available
audio-text dataset. Second, we propose GenAu, a scalable transformer-based
audio generation architecture that we scale up to 1.25B parameters and train
with our new dataset. When compared to state-of-the-art audio generators, GenAu
obtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%
in CLAP score, indicating significantly improved quality of generated audio
compared to previous works. This shows that the quality of data is often as
important as its quantity. Besides, since AutoCap is fully automatic, new audio
samples can be added to the training dataset, unlocking the training of even
larger generative models for audio synthesis.

摘要：<paragraph>由於資料稀少且字幕品質通常不足，產生環境音效是一項具有挑戰性的問題，這使得難以使用大規模生成模型來執行此任務。在這項工作中，我們透過引入兩個新模型來解決這個問題。首先，我們提出 AutoCap，這是一個高品質且高效的自動音訊字幕模型。我們展示透過利用音訊模式中可用的元資料，我們可以大幅提升字幕品質。AutoCap 的 CIDEr 分數達到 83.2，比現有最佳字幕模型進步了 3.2%，而且推論速度快了四倍。然後我們使用 AutoCap 為現有資料集中的片段加上字幕，取得 761,000 個具有高品質字幕的音訊片段，形成最大的可用音訊文字資料集。其次，我們提出 GenAu，這是一個可擴充的基於 Transformer 的音訊生成架構，我們將其擴充到 1.25B 個參數，並使用我們的新資料集進行訓練。與最先進的音訊生成器相比，GenAu 在 FAD 分數方面獲得了 15.7% 的顯著提升，在 IS 方面提升了 22.7%，在 CLAP 分數方面提升了 13.5%，這表示與先前的作品相比，生成的音訊品質有顯著提升。這顯示資料的品質通常與其數量一樣重要。此外，由於 AutoCap 是全自動的，因此可以將新的音訊範例新增到訓練資料集，這將開啟訓練更大音訊合成生成模型的可能性。</paragraph>

