{"2410.19084": {"publish_time": "2024-10-24", "title": "GCoder: Improving Large Language Model for Generalized Graph Problem Solving", "paper_summary": "Large Language Models (LLMs) have demonstrated strong reasoning abilities,\nmaking them suitable for complex tasks such as graph computation. Traditional\nreasoning steps paradigm for graph problems is hindered by unverifiable steps,\nlimited long-term reasoning, and poor generalization to graph variations. To\novercome these limitations, we introduce GCoder, a code-based LLM designed to\nenhance problem-solving in generalized graph computation problems. Our method\ninvolves constructing an extensive training dataset, GraphWild, featuring\ndiverse graph formats and algorithms. We employ a multi-stage training process,\nincluding Supervised Fine-Tuning (SFT) and Reinforcement Learning from Compiler\nFeedback (RLCF), to refine model capabilities. For unseen tasks, a hybrid\nretrieval technique is used to augment performance. Experiments demonstrate\nthat GCoder outperforms GPT-4o, with an average accuracy improvement of 16.42%\nacross various graph computational problems. Furthermore, GCoder efficiently\nmanages large-scale graphs with millions of nodes and diverse input formats,\novercoming the limitations of previous models focused on the reasoning steps\nparadigm. This advancement paves the way for more intuitive and effective graph\nproblem-solving using LLMs. Code and data are available at here:\nhttps://github.com/Bklight999/WWW25-GCoder/tree/master.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u5f37\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u5176\u9069\u7528\u65bc\u8907\u96dc\u4efb\u52d9\uff0c\u4f8b\u5982\u5716\u5f62\u904b\u7b97\u3002\u50b3\u7d71\u5716\u5f62\u554f\u984c\u7684\u63a8\u7406\u6b65\u9a5f\u7bc4\u4f8b\u53d7\u5230\u4e0d\u53ef\u9a57\u8b49\u7684\u6b65\u9a5f\u3001\u6709\u9650\u7684\u9577\u671f\u63a8\u7406\u548c\u5c0d\u5716\u5f62\u8b8a\u5316\u7684\u6982\u62ec\u6027\u4e0d\u4f73\u7684\u963b\u7919\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u5f15\u5165\u4e86 GCoder\uff0c\u4e00\u7a2e\u57fa\u65bc\u4ee3\u78bc\u7684 LLM\uff0c\u65e8\u5728\u589e\u5f37\u5ee3\u7fa9\u5716\u5f62\u904b\u7b97\u554f\u984c\u4e2d\u7684\u554f\u984c\u89e3\u6c7a\u80fd\u529b\u3002\u6211\u5011\u7684\u6280\u8853\u6d89\u53ca\u69cb\u5efa\u4e00\u500b\u5ee3\u6cdb\u7684\u8a13\u7df4\u8cc7\u6599\u96c6 GraphWild\uff0c\u5176\u4e2d\u5305\u542b\u591a\u6a23\u7684\u5716\u5f62\u683c\u5f0f\u548c\u6f14\u7b97\u6cd5\u3002\u6211\u5011\u63a1\u7528\u591a\u968e\u6bb5\u8a13\u7df4\u6d41\u7a0b\uff0c\u5305\u62ec\u76e3\u7763\u5fae\u8abf (SFT) \u548c\u7de8\u8b6f\u5668\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLCF)\uff0c\u4ee5\u6539\u5584\u6a21\u578b\u80fd\u529b\u3002\u5c0d\u65bc\u672a\u77e5\u4efb\u52d9\uff0c\u4f7f\u7528\u6df7\u5408\u64f7\u53d6\u6280\u8853\u4f86\u589e\u5f37\u6548\u80fd\u3002\u5be6\u9a57\u8b49\u660e\uff0cGCoder \u512a\u65bc GPT-4o\uff0c\u5728\u5404\u7a2e\u5716\u5f62\u904b\u7b97\u554f\u984c\u4e2d\u5e73\u5747\u6e96\u78ba\u5ea6\u63d0\u5347\u4e86 16.42%\u3002\u6b64\u5916\uff0cGCoder \u6709\u6548\u5730\u7ba1\u7406\u8457\u64c1\u6709\u6578\u767e\u842c\u500b\u7bc0\u9ede\u548c\u591a\u6a23\u8f38\u5165\u683c\u5f0f\u7684\u5927\u898f\u6a21\u5716\u5f62\uff0c\u514b\u670d\u4e86\u5148\u524d\u5c08\u6ce8\u65bc\u63a8\u7406\u6b65\u9a5f\u7bc4\u4f8b\u7684\u6a21\u578b\u7684\u9650\u5236\u3002\u9019\u9805\u9032\u5c55\u70ba\u4f7f\u7528 LLM \u9032\u884c\u66f4\u76f4\u89c0\u4e14\u6709\u6548\u7684\u5716\u5f62\u554f\u984c\u89e3\u6c7a\u92ea\u5e73\u4e86\u9053\u8def\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u53ef\u65bc\u6b64\u8655\u53d6\u5f97\uff1ahttps://github.com/Bklight999/WWW25-GCoder/tree/master\u3002", "author": "Qifan Zhang et.al.", "authors": "Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li", "id": "2410.19084v1", "paper_url": "http://arxiv.org/abs/2410.19084v1", "repo": "https://github.com/bklight999/www25-gcoder"}}