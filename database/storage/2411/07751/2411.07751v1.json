{"2411.07751": {"publish_time": "2024-11-12", "title": "SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State Space Model", "paper_summary": "Speech enhancement plays an essential role in various applications, and the\nintegration of visual information has been demonstrated to bring substantial\nadvantages. However, the majority of current research concentrates on the\nexamination of facial and lip movements, which can be compromised or entirely\ninaccessible in scenarios where occlusions occur or when the camera view is\ndistant. Whereas contextual visual cues from the surrounding environment have\nbeen overlooked: for example, when we see a dog bark, our brain has the innate\nability to discern and filter out the barking noise. To this end, in this\npaper, we introduce a novel task, i.e. SAV-SE. To our best knowledge, this is\nthe first proposal to use rich contextual information from synchronized video\nas auxiliary cues to indicate the type of noise, which eventually improves the\nspeech enhancement performance. Specifically, we propose the VC-S$^2$E method,\nwhich incorporates the Conformer and Mamba modules for their complementary\nstrengths. Extensive experiments are conducted on public MUSIC, AVSpeech and\nAudioSet datasets, where the results demonstrate the superiority of VC-S$^2$E\nover other competitive methods. We will make the source code publicly\navailable. Project demo page: https://AVSEPage.github.io/", "paper_summary_zh": "\u8a9e\u97f3\u589e\u5f37\u5728\u5404\u7a2e\u61c9\u7528\u4e2d\u626e\u6f14\u8457\u91cd\u8981\u7684\u89d2\u8272\uff0c\u800c\u8996\u89ba\u8cc7\u8a0a\u7684\u6574\u5408\u5df2\u88ab\u8b49\u660e\u80fd\u5e36\u4f86\u986f\u8457\u7684\u512a\u52e2\u3002\u7136\u800c\uff0c\u76ee\u524d\u5927\u591a\u6578\u7684\u7814\u7a76\u90fd\u96c6\u4e2d\u5728\u5c0d\u81c9\u90e8\u548c\u5634\u5507\u52d5\u4f5c\u7684\u6aa2\u8996\u4e0a\uff0c\u9019\u5728\u767c\u751f\u906e\u64cb\u6216\u76f8\u6a5f\u8996\u89d2\u8f03\u9060\u6642\u53ef\u80fd\u6703\u53d7\u5230\u5f71\u97ff\u6216\u5b8c\u5168\u7121\u6cd5\u4f7f\u7528\u3002\u800c\u4f86\u81ea\u5468\u570d\u74b0\u5883\u7684\u8108\u7d61\u8996\u89ba\u7dda\u7d22\u5247\u88ab\u5ffd\u7565\u4e86\uff1a\u4f8b\u5982\uff0c\u7576\u6211\u5011\u770b\u5230\u4e00\u96bb\u72d7\u5420\u53eb\u6642\uff0c\u6211\u5011\u7684\u5927\u8166\u5177\u6709\u8fa8\u5225\u548c\u6ffe\u9664\u5420\u53eb\u566a\u97f3\u7684\u5148\u5929\u6c23\u8cea\u3002\u70ba\u6b64\uff0c\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u4efb\u52d9\uff0c\u5373 SAV-SE\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u63d0\u51fa\u4f7f\u7528\u4f86\u81ea\u540c\u6b65\u8996\u8a0a\u7684\u8c50\u5bcc\u8108\u7d61\u8cc7\u8a0a\u4f5c\u70ba\u8f14\u52a9\u7dda\u7d22\u4f86\u6307\u793a\u566a\u97f3\u985e\u578b\u7684\u63d0\u6848\uff0c\u9019\u6700\u7d42\u6539\u5584\u4e86\u8a9e\u97f3\u589e\u5f37\u6027\u80fd\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63d0\u51fa\u4e86 VC-S$^2$E \u65b9\u6cd5\uff0c\u5b83\u7d50\u5408\u4e86 Conformer \u548c Mamba \u6a21\u7d44\uff0c\u4ee5\u767c\u63ee\u5176\u4e92\u88dc\u512a\u52e2\u3002\u5728\u516c\u958b\u7684 MUSIC\u3001AVSpeech \u548c AudioSet \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u4e86\u5927\u91cf\u7684\u5be6\u9a57\uff0c\u7d50\u679c\u8b49\u660e\u4e86 VC-S$^2$E \u512a\u65bc\u5176\u4ed6\u7af6\u722d\u65b9\u6cd5\u3002\u6211\u5011\u5c07\u516c\u958b\u539f\u59cb\u78bc\u3002\u5c08\u6848\u5c55\u793a\u9801\u9762\uff1ahttps://AVSEPage.github.io/", "author": "Xinyuan Qian et.al.", "authors": "Xinyuan Qian, Jiaran Gao, Yaodan Zhang, Qiquan Zhang, Hexin Liu, Leibny Paola Garcia, Haizhou Li", "id": "2411.07751v1", "paper_url": "http://arxiv.org/abs/2411.07751v1", "repo": "null"}}