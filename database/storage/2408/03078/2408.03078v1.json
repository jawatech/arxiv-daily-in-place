{"2408.03078": {"publish_time": "2024-08-06", "title": "BodySLAM: A Generalized Monocular Visual SLAM Framework for Surgical Applications", "paper_summary": "Endoscopic surgery relies on two-dimensional views, posing challenges for\nsurgeons in depth perception and instrument manipulation. While Simultaneous\nLocalization and Mapping (SLAM) has emerged as a promising solution to address\nthese limitations, its implementation in endoscopic procedures presents\nsignificant challenges due to hardware limitations, such as the use of a\nmonocular camera and the absence of odometry sensors. This study presents a\nrobust deep learning-based SLAM approach that combines state-of-the-art and\nnewly developed models. It consists of three main parts: the Monocular Pose\nEstimation Module that introduces a novel unsupervised method based on the\nCycleGAN architecture, the Monocular Depth Estimation Module that leverages the\nnovel Zoe architecture, and the 3D Reconstruction Module which uses information\nfrom the previous models to create a coherent surgical map. The performance of\nthe procedure was rigorously evaluated using three publicly available datasets\n(Hamlyn, EndoSLAM, and SCARED) and benchmarked against two state-of-the-art\nmethods, EndoSFMLearner and EndoDepth. The integration of Zoe in the MDEM\ndemonstrated superior performance compared to state-of-the-art depth estimation\nalgorithms in endoscopy, whereas the novel approach in the MPEM exhibited\ncompetitive performance and the lowest inference time. The results showcase the\nrobustness of our approach in laparoscopy, gastroscopy, and colonoscopy, three\ndifferent scenarios in endoscopic surgery. The proposed SLAM approach has the\npotential to improve the accuracy and efficiency of endoscopic procedures by\nproviding surgeons with enhanced depth perception and 3D reconstruction\ncapabilities.", "paper_summary_zh": "\u5167\u8996\u93e1\u624b\u8853\u4f9d\u8cf4\u65bc\u4e8c\u7dad\u8996\u5716\uff0c\u5c0d\u5916\u79d1\u91ab\u751f\u5728\u6df1\u5ea6\u611f\u77e5\u548c\u5668\u68b0\u64cd\u4f5c\u65b9\u9762\u69cb\u6210\u6311\u6230\u3002\u96d6\u7136\u540c\u6642\u5b9a\u4f4d\u8207\u5efa\u5716 (SLAM) \u5df2\u6210\u70ba\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\u7684\u6709\u5e0c\u671b\u7684\u65b9\u6848\uff0c\u4f46\u7531\u65bc\u786c\u9ad4\u9650\u5236\uff0c\u4f8b\u5982\u4f7f\u7528\u55ae\u773c\u76f8\u6a5f\u548c\u7f3a\u4e4f\u91cc\u7a0b\u8a08\u611f\u6e2c\u5668\uff0c\u5176\u5728\u5167\u8996\u93e1\u624b\u8853\u4e2d\u7684\u5be6\u65bd\u9762\u81e8\u91cd\u5927\u6311\u6230\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u7a2e\u5f37\u5927\u7684\u6df1\u5ea6\u5b78\u7fd2\u5f0f SLAM \u65b9\u6cd5\uff0c\u7d50\u5408\u4e86\u6700\u5148\u9032\u548c\u65b0\u958b\u767c\u7684\u6a21\u578b\u3002\u5b83\u5305\u542b\u4e09\u500b\u4e3b\u8981\u90e8\u5206\uff1a\u55ae\u773c\u59ff\u52e2\u4f30\u8a08\u6a21\u7d44\uff0c\u5f15\u5165\u4e86\u57fa\u65bc CycleGAN \u67b6\u69cb\u7684\u65b0\u578b\u975e\u76e3\u7763\u5f0f\u65b9\u6cd5\uff1b\u55ae\u773c\u6df1\u5ea6\u4f30\u8a08\u6a21\u7d44\uff0c\u5229\u7528\u4e86\u65b0\u578b Zoe \u67b6\u69cb\uff1b\u4ee5\u53ca 3D \u91cd\u5efa\u6a21\u7d44\uff0c\u5b83\u4f7f\u7528\u524d\u4e00\u6a21\u578b\u4e2d\u7684\u8cc7\u8a0a\u4f86\u5efa\u7acb\u4e00\u500b\u9023\u8cab\u7684\u624b\u8853\u5730\u5716\u3002\u4f7f\u7528\u4e09\u500b\u516c\u958b\u53ef\u7528\u7684\u8cc7\u6599\u96c6\uff08Hamlyn\u3001EndoSLAM \u548c SCARED\uff09\u56b4\u683c\u8a55\u4f30\u4e86\u8a72\u624b\u8853\u7684\u6548\u80fd\uff0c\u4e26\u6839\u64da\u5169\u500b\u6700\u5148\u9032\u7684\u65b9\u6cd5 EndoSFMLearner \u548c EndoDepth \u9032\u884c\u57fa\u6e96\u6e2c\u8a66\u3002\u8207\u5167\u8996\u93e1\u4e2d\u6700\u5148\u9032\u7684\u6df1\u5ea6\u4f30\u8a08\u6f14\u7b97\u6cd5\u76f8\u6bd4\uff0cZoe \u5728 MDEM \u4e2d\u7684\u6574\u5408\u8868\u73fe\u51fa\u512a\u7570\u7684\u6548\u80fd\uff0c\u800c MPEM \u4e2d\u7684\u65b0\u65b9\u6cd5\u8868\u73fe\u51fa\u7af6\u722d\u529b\u4e14\u63a8\u8ad6\u6642\u9593\u6700\u77ed\u3002\u7d50\u679c\u5c55\u793a\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u8179\u8154\u93e1\u6aa2\u67e5\u3001\u80c3\u93e1\u6aa2\u67e5\u548c\u7d50\u8178\u93e1\u6aa2\u67e5\u4e2d\u7684\u7a69\u5065\u6027\uff0c\u9019\u662f\u5167\u8996\u93e1\u624b\u8853\u4e2d\u7684\u4e09\u7a2e\u4e0d\u540c\u5834\u666f\u3002\u6240\u63d0\u51fa\u7684 SLAM \u65b9\u6cd5\u6709\u53ef\u80fd\u900f\u904e\u70ba\u5916\u79d1\u91ab\u751f\u63d0\u4f9b\u589e\u5f37\u7684\u6df1\u5ea6\u611f\u77e5\u548c 3D \u91cd\u5efa\u80fd\u529b\uff0c\u4f86\u63d0\u9ad8\u5167\u8996\u93e1\u624b\u8853\u7684\u6e96\u78ba\u6027\u548c\u6548\u7387\u3002", "author": "G. Manni et.al.", "authors": "G. Manni, C. Lauretti, F. Prata, R. Papalia, L. Zollo, P. Soda", "id": "2408.03078v1", "paper_url": "http://arxiv.org/abs/2408.03078v1", "repo": "null"}}