{"2407.10582": {"publish_time": "2024-07-15", "title": "Boosting Zero-Shot Crosslingual Performance using LLM-Based Augmentations with Effective Data Selection", "paper_summary": "Large language models (LLMs) are very proficient text generators. We leverage\nthis capability of LLMs to generate task-specific data via zero-shot prompting\nand promote cross-lingual transfer for low-resource target languages. Given\ntask-specific data in a source language and a teacher model trained on this\ndata, we propose using this teacher to label LLM generations and employ a set\nof simple data selection strategies that use the teacher's label probabilities.\nOur data selection strategies help us identify a representative subset of\ndiverse generations that help boost zero-shot accuracies while being efficient,\nin comparison to using all the LLM generations (without any subset selection).\nWe also highlight other important design choices that affect cross-lingual\nperformance such as the use of translations of source data and what labels are\nbest to use for the LLM generations. We observe significant performance gains\nacross sentiment analysis and natural language inference tasks (of up to a\nmaximum of 7.13 absolute points and 1.5 absolute points on average) across a\nnumber of target languages (Hindi, Marathi, Urdu, Swahili) and domains.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u975e\u5e38\u719f\u7df4\u7684\u6587\u672c\u751f\u6210\u5668\u3002\u6211\u5011\u5229\u7528 LLM \u7684\u9019\u7a2e\u80fd\u529b\u901a\u904e\u96f6\u6b21\u63d0\u793a\u751f\u6210\u7279\u5b9a\u4efb\u52d9\u7684\u6578\u64da\uff0c\u4e26\u4fc3\u9032\u4f4e\u8cc7\u6e90\u76ee\u6a19\u8a9e\u8a00\u7684\u8de8\u8a9e\u8a00\u50b3\u8f38\u3002\u7d66\u5b9a\u6e90\u8a9e\u8a00\u4e2d\u7684\u7279\u5b9a\u4efb\u52d9\u6578\u64da\u548c\u5728\u6b64\u6578\u64da\u4e0a\u8a13\u7df4\u7684\u6559\u5e2b\u6a21\u578b\uff0c\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u6b64\u6559\u5e2b\u6a19\u8a18 LLM \u751f\u6210\uff0c\u4e26\u63a1\u7528\u4e00\u7d44\u4f7f\u7528\u6559\u5e2b\u6a19\u7c64\u6982\u7387\u7684\u7c21\u55ae\u6578\u64da\u9078\u64c7\u7b56\u7565\u3002\u6211\u5011\u7684\u6578\u64da\u9078\u64c7\u7b56\u7565\u5e6b\u52a9\u6211\u5011\u8b58\u5225\u6709\u52a9\u65bc\u63d0\u9ad8\u96f6\u6b21\u6e96\u78ba\u7387\u7684\u5177\u6709\u4ee3\u8868\u6027\u7684\u591a\u6a23\u5316\u751f\u6210\u5b50\u96c6\uff0c\u540c\u6642\u8207\u4f7f\u7528\u6240\u6709 LLM \u751f\u6210\uff08\u6c92\u6709\u4efb\u4f55\u5b50\u96c6\u9078\u64c7\uff09\u76f8\u6bd4\uff0c\u6548\u7387\u66f4\u9ad8\u3002\u6211\u5011\u9084\u5f37\u8abf\u5f71\u97ff\u8de8\u8a9e\u8a00\u6027\u80fd\u7684\u5176\u4ed6\u91cd\u8981\u8a2d\u8a08\u9078\u64c7\uff0c\u4f8b\u5982\u4f7f\u7528\u6e90\u6578\u64da\u7ffb\u8b6f\u4ee5\u53ca LLM \u751f\u6210\u6700\u9069\u5408\u4f7f\u7528\u54ea\u4e9b\u6a19\u7c64\u3002\u6211\u5011\u89c0\u5bdf\u5230\u8de8\u60c5\u7dd2\u5206\u6790\u548c\u81ea\u7136\u8a9e\u8a00\u63a8\u7406\u4efb\u52d9\uff08\u5e73\u5747\u6700\u591a 7.13 \u500b\u7d55\u5c0d\u9ede\u548c 1.5 \u500b\u7d55\u5c0d\u9ede\uff09\u7684\u986f\u8457\u6027\u80fd\u589e\u76ca\uff0c\u8de8\u591a\u7a2e\u76ee\u6a19\u8a9e\u8a00\uff08\u5370\u5730\u8a9e\u3001\u99ac\u62c9\u5730\u8a9e\u3001\u70cf\u723e\u90fd\u8a9e\u3001\u65af\u74e6\u5e0c\u91cc\u8a9e\uff09\u548c\u9818\u57df\u3002", "author": "Barah Fazili et.al.", "authors": "Barah Fazili, Ashish Sunil Agrawal, Preethi Jyothi", "id": "2407.10582v1", "paper_url": "http://arxiv.org/abs/2407.10582v1", "repo": "https://github.com/csalt-research/llm-based-augmentations-with-effective-data-selection"}}