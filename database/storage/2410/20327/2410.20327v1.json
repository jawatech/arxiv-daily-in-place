{"2410.20327": {"publish_time": "2024-10-27", "title": "R-LLaVA: Improving Med-VQA Understanding through Visual Region of Interest", "paper_summary": "Artificial intelligence has made significant strides in medical visual\nquestion answering (Med-VQA), yet prevalent studies often interpret images\nholistically, overlooking the visual regions of interest that may contain\ncrucial information, potentially aligning with a doctor's prior knowledge that\ncan be incorporated with minimal annotations (e.g., bounding boxes). To address\nthis gap, this paper introduces R-LLaVA, designed to enhance biomedical VQA\nunderstanding by integrating simple medical annotations as prior knowledge\ndirectly into the image space through CLIP. These annotated visual regions of\ninterest are then fed into the LLaVA model during training, aiming to enrich\nthe model's understanding of biomedical queries. Experimental evaluation on\nfour standard Med-VQA datasets demonstrates R-LLaVA's superiority over existing\nstate-of-the-art (SoTA) methods. Additionally, to verify the model's capability\nin visual comprehension, a novel multiple-choice medical visual understanding\ndataset is introduced, confirming the positive impact of focusing on visual\nregions of interest in advancing biomedical VQA understanding.", "paper_summary_zh": "\u4eba\u5de5\u667a\u6167\u5728\u91ab\u5b78\u8996\u89ba\u554f\u7b54 (Med-VQA) \u4e2d\u53d6\u5f97\u986f\u8457\u9032\u5c55\uff0c\u4f46\u666e\u904d\u7684\u7814\u7a76\u901a\u5e38\u6574\u9ad4\u8a6e\u91cb\u5f71\u50cf\uff0c\u5ffd\u7565\u53ef\u80fd\u5305\u542b\u95dc\u9375\u8cc7\u8a0a\u7684\u8996\u89ba\u611f\u8208\u8da3\u5340\u57df\uff0c\u9019\u53ef\u80fd\u6703\u8207\u91ab\u751f\u7684\u5148\u5099\u77e5\u8b58\u4e00\u81f4\uff0c\u800c\u5148\u5099\u77e5\u8b58\u53ef\u4ee5\u900f\u904e\u6700\u5c11\u7684\u8a3b\u89e3\uff08\u4f8b\u5982\u908a\u754c\u6846\uff09\u7d0d\u5165\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u672c\u6587\u63d0\u51fa R-LLaVA\uff0c\u65e8\u5728\u900f\u904e CLIP \u5c07\u7c21\u55ae\u7684\u91ab\u5b78\u8a3b\u89e3\u4f5c\u70ba\u5148\u5099\u77e5\u8b58\u76f4\u63a5\u6574\u5408\u5230\u5f71\u50cf\u7a7a\u9593\u4e2d\uff0c\u4ee5\u589e\u5f37\u751f\u7269\u91ab\u5b78 VQA \u7406\u89e3\u3002\u9019\u4e9b\u5e36\u6709\u8a3b\u89e3\u7684\u8996\u89ba\u611f\u8208\u8da3\u5340\u57df\u6703\u5728\u8a13\u7df4\u671f\u9593\u8f38\u5165 LLaVA \u6a21\u578b\uff0c\u76ee\u6a19\u662f\u8c50\u5bcc\u6a21\u578b\u5c0d\u751f\u7269\u91ab\u5b78\u67e5\u8a62\u7684\u7406\u89e3\u3002\u5728\u56db\u500b\u6a19\u6e96 Med-VQA \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u8a55\u4f30\u8b49\u660e\u4e86 R-LLaVA \u512a\u65bc\u73fe\u6709\u7684\u6700\u5148\u9032 (SoTA) \u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u9a57\u8b49\u6a21\u578b\u5728\u8996\u89ba\u7406\u89e3\u4e2d\u7684\u80fd\u529b\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u591a\u9078\u984c\u91ab\u5b78\u8996\u89ba\u7406\u89e3\u8cc7\u6599\u96c6\uff0c\u8b49\u5be6\u4e86\u5c08\u6ce8\u65bc\u8996\u89ba\u611f\u8208\u8da3\u5340\u57df\u5c0d\u63a8\u52d5\u751f\u7269\u91ab\u5b78 VQA \u7406\u89e3\u7684\u6b63\u9762\u5f71\u97ff\u3002", "author": "Xupeng Chen et.al.", "authors": "Xupeng Chen, Zhixin Lai, Kangrui Ruan, Shichu Chen, Jiaxiang Liu, Zuozhu Liu", "id": "2410.20327v1", "paper_url": "http://arxiv.org/abs/2410.20327v1", "repo": "null"}}