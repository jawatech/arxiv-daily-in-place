{"2408.14467": {"publish_time": "2024-08-26", "title": "Explicit Inductive Inference using Large Language Models", "paper_summary": "Large Language Models (LLMs) are reported to hold undesirable attestation\nbias on inference tasks: when asked to predict if a premise P entails a\nhypothesis H, instead of considering H's conditional truthfulness entailed by\nP, LLMs tend to use the out-of-context truth label of H as a fragile proxy. In\nthis paper, we propose a pipeline that exploits this bias to do explicit\ninductive inference. Our pipeline uses an LLM to transform a premise into a set\nof attested alternatives, and then aggregate answers of the derived new\nentailment inquiries to support the original inference prediction. On a\ndirectional predicate entailment benchmark, we demonstrate that by applying\nthis simple pipeline, we can improve the overall performance of LLMs on\ninference and substantially alleviate the impact of their attestation bias.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u88ab\u5831\u5c0e\u5728\u63a8\u8ad6\u4efb\u52d9\u4e2d\u5b58\u5728\u4e0d\u826f\u7684\u8b49\u660e\u504f\u898b\uff1a\u7576\u88ab\u8981\u6c42\u9810\u6e2c\u524d\u63d0 P \u662f\u5426\u860a\u542b\u5047\u8a2d H \u6642\uff0cLLM \u50be\u5411\u65bc\u4f7f\u7528 H \u7684\u8a9e\u5883\u5916\u771f\u5be6\u6a19\u7c64\u4f5c\u70ba\u4e00\u500b\u8106\u5f31\u7684\u4ee3\u7406\uff0c\u800c\u4e0d\u662f\u8003\u616e H \u7684\u689d\u4ef6\u771f\u5be6\u6027\u7531 P \u860a\u542b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5229\u7528\u9019\u7a2e\u504f\u898b\u4f86\u9032\u884c\u660e\u78ba\u6b78\u7d0d\u63a8\u7406\u7684\u7ba1\u9053\u3002\u6211\u5011\u7684\u7ba1\u9053\u4f7f\u7528 LLM \u5c07\u524d\u63d0\u8f49\u63db\u70ba\u4e00\u7d44\u7d93\u904e\u8b49\u5be6\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7136\u5f8c\u5f59\u7e3d\u884d\u751f\u7684\u65b0\u860a\u542b\u67e5\u8a62\u7684\u7b54\u6848\u4f86\u652f\u6301\u539f\u59cb\u63a8\u7406\u9810\u6e2c\u3002\u5728\u4e00\u500b\u65b9\u5411\u8b02\u8a5e\u860a\u542b\u57fa\u6e96\u4e0a\uff0c\u6211\u5011\u8b49\u660e\u901a\u904e\u61c9\u7528\u9019\u500b\u7c21\u55ae\u7684\u7ba1\u9053\uff0c\u6211\u5011\u53ef\u4ee5\u63d0\u9ad8 LLM \u5728\u63a8\u7406\u4e0a\u7684\u6574\u9ad4\u6027\u80fd\uff0c\u4e26\u5927\u5e45\u6e1b\u8f15\u5176\u8b49\u660e\u504f\u898b\u7684\u5f71\u97ff\u3002", "author": "Tianyang Liu et.al.", "authors": "Tianyang Liu, Tianyi Li, Liang Cheng, Mark Steedman", "id": "2408.14467v1", "paper_url": "http://arxiv.org/abs/2408.14467v1", "repo": "null"}}