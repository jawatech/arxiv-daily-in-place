{"2412.05184": {"publish_time": "2024-12-06", "title": "QueEn: A Large Language Model for Quechua-English Translation", "paper_summary": "Recent studies show that large language models (LLMs) are powerful tools for\nworking with natural language, bringing advances in many areas of computational\nlinguistics. However, these models face challenges when applied to low-resource\nlanguages due to limited training data and difficulty in understanding cultural\nnuances. In this paper, we propose QueEn, a novel approach for Quechua-English\ntranslation that combines Retrieval-Augmented Generation (RAG) with\nparameter-efficient fine-tuning techniques. Our method leverages external\nlinguistic resources through RAG and uses Low-Rank Adaptation (LoRA) for\nefficient model adaptation. Experimental results show that our approach\nsubstantially exceeds baseline models, with a BLEU score of 17.6 compared to\n1.5 for standard GPT models. The integration of RAG with fine-tuning allows our\nsystem to address the challenges of low-resource language translation while\nmaintaining computational efficiency. This work contributes to the broader goal\nof preserving endangered languages through advanced language technologies.", "paper_summary_zh": "\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u662f\u8655\u7406\u81ea\u7136\u8a9e\u8a00\u7684\u5f37\u5927\u5de5\u5177\uff0c\u70ba\u8a08\u7b97\u8a9e\u8a00\u5b78\u7684\u8a31\u591a\u9818\u57df\u5e36\u4f86\u9032\u5c55\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u5728\u61c9\u7528\u65bc\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u6642\u6703\u9762\u81e8\u6311\u6230\uff0c\u539f\u56e0\u662f\u8a13\u7df4\u8cc7\u6599\u6709\u9650\uff0c\u4e14\u96e3\u4ee5\u7406\u89e3\u6587\u5316\u5dee\u7570\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa QueEn\uff0c\u9019\u662f\u4e00\u7a2e Quechua-English \u7ffb\u8b6f\u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u7d50\u5408\u4e86\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u8207\u53c3\u6578\u6709\u6548\u5fae\u8abf\u6280\u8853\u3002\u6211\u5011\u7684\u6a21\u578b\u900f\u904e RAG \u5229\u7528\u5916\u90e8\u8a9e\u8a00\u8cc7\u6e90\uff0c\u4e26\u4f7f\u7528\u4f4e\u79e9\u9069\u61c9 (LoRA) \u9032\u884c\u6709\u6548\u7684\u6a21\u578b\u9069\u61c9\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u5927\u5e45\u8d85\u8d8a\u57fa\u6e96\u6a21\u578b\uff0cBLEU \u5206\u6578\u70ba 17.6\uff0c\u800c\u6a19\u6e96 GPT \u6a21\u578b\u70ba 1.5\u3002RAG \u8207\u5fae\u8abf\u7684\u6574\u5408\u4f7f\u6211\u5011\u7684\u7cfb\u7d71\u80fd\u5920\u89e3\u6c7a\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u7ffb\u8b6f\u7684\u6311\u6230\uff0c\u540c\u6642\u7dad\u6301\u8a08\u7b97\u6548\u7387\u3002\u9019\u9805\u5de5\u4f5c\u6709\u52a9\u65bc\u900f\u904e\u5148\u9032\u7684\u8a9e\u8a00\u6280\u8853\u4f86\u4fdd\u5b58\u7015\u5371\u8a9e\u8a00\u7684\u66f4\u5ee3\u6cdb\u76ee\u6a19\u3002", "author": "Junhao Chen et.al.", "authors": "Junhao Chen, Peng Shu, Yiwei Li, Huaqin Zhao, Hanqi Jiang, Yi Pan, Yifan Zhou, Zhengliang Liu, Lewis C Howe, Tianming Liu", "id": "2412.05184v1", "paper_url": "http://arxiv.org/abs/2412.05184v1", "repo": "null"}}