{"2406.15245": {"publish_time": "2024-06-21", "title": "Unsupervised Morphological Tree Tokenizer", "paper_summary": "As a cornerstone in language modeling, tokenization involves segmenting text\ninputs into pre-defined atomic units. Conventional statistical tokenizers often\ndisrupt constituent boundaries within words, thereby corrupting semantic\ninformation. To address this drawback, we introduce morphological structure\nguidance to tokenization and propose a deep model to induce character-level\nstructures of words. Specifically, the deep model jointly encodes internal\nstructures and representations of words with a mechanism named\n$\\textit{MorphOverriding}$ to ensure the indecomposability of morphemes. By\ntraining the model with self-supervised objectives, our method is capable of\ninducing character-level structures that align with morphological rules without\nannotated training data. Based on the induced structures, our algorithm\ntokenizes words through vocabulary matching in a top-down manner. Empirical\nresults indicate that the proposed method effectively retains complete\nmorphemes and outperforms widely adopted methods such as BPE and WordPiece on\nboth morphological segmentation tasks and language modeling tasks. The code\nwill be released later.", "paper_summary_zh": "\u4f5c\u70ba\u8a9e\u8a00\u6a21\u578b\u7684\u57fa\u77f3\uff0c\u5206\u8a5e\u6d89\u53ca\u5c07\u6587\u5b57\u8f38\u5165\u5206\u6bb5\u6210\u9810\u5148\u5b9a\u7fa9\u7684\u539f\u5b50\u55ae\u4f4d\u3002\u50b3\u7d71\u7684\u7d71\u8a08\u5206\u8a5e\u5668\u7d93\u5e38\u6703\u7834\u58de\u5b57\u8a5e\u5167\u7684\u7d44\u6210\u754c\u7dda\uff0c\u9032\u800c\u640d\u5bb3\u8a9e\u7fa9\u8cc7\u8a0a\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u7f3a\u9ede\uff0c\u6211\u5011\u5728\u5206\u8a5e\u4e2d\u52a0\u5165\u5f62\u614b\u7d50\u69cb\u6307\u5f15\uff0c\u4e26\u63d0\u51fa\u4e00\u500b\u6df1\u5ea6\u6a21\u578b\u4f86\u8a98\u5c0e\u5b57\u8a5e\u7684\u5b57\u5143\u7d1a\u7d50\u69cb\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6df1\u5ea6\u6a21\u578b\u6703\u900f\u904e\u4e00\u7a2e\u7a31\u70ba\u300cMorphOverriding\u300d\u7684\u6a5f\u5236\uff0c\u806f\u5408\u7de8\u78bc\u5b57\u8a5e\u7684\u5167\u90e8\u7d50\u69cb\u8207\u8868\u5fb5\uff0c\u4ee5\u78ba\u4fdd\u5f62\u614b\u7d20\u7684\u4e0d\u53ef\u5206\u89e3\u6027\u3002\u900f\u904e\u4ee5\u81ea\u6211\u76e3\u7763\u76ee\u6a19\u8a13\u7df4\u6a21\u578b\uff0c\u6211\u5011\u7684\u6a21\u578b\u80fd\u5920\u5728\u6c92\u6709\u6a19\u8a3b\u8a13\u7df4\u8cc7\u6599\u7684\u60c5\u6cc1\u4e0b\uff0c\u8a98\u5c0e\u51fa\u8207\u5f62\u614b\u898f\u5247\u76f8\u7b26\u7684\u5b57\u5143\u7d1a\u7d50\u69cb\u3002\u6211\u5011\u7684\u6f14\u7b97\u6cd5\u6839\u64da\u8a98\u5c0e\u51fa\u7684\u7d50\u69cb\uff0c\u5f9e\u4e0a\u800c\u4e0b\u5730\u900f\u904e\u8a5e\u5f59\u6bd4\u5c0d\u5c0d\u5b57\u8a5e\u9032\u884c\u5206\u8a5e\u3002\u5be6\u8b49\u7d50\u679c\u986f\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u4fdd\u7559\u4e86\u5b8c\u6574\u7684\u5f62\u614b\u7d20\uff0c\u4e26\u4e14\u5728\u5f62\u614b\u5206\u8a5e\u4efb\u52d9\u548c\u8a9e\u8a00\u6a21\u578b\u4efb\u52d9\u4e0a\u90fd\u512a\u65bc\u5ee3\u6cdb\u63a1\u7528\u7684\u65b9\u6cd5\uff0c\u4f8b\u5982 BPE \u548c WordPiece\u3002\u7a0b\u5f0f\u78bc\u5c07\u5728\u7a0d\u5f8c\u91cb\u51fa\u3002", "author": "Qingyang Zhu et.al.", "authors": "Qingyang Zhu, Xiang Hu, Pengyu Ji, Wei Wu, Kewei Tu", "id": "2406.15245v1", "paper_url": "http://arxiv.org/abs/2406.15245v1", "repo": "null"}}