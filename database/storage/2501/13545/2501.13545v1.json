{"2501.13545": {"publish_time": "2025-01-23", "title": "LLMs Can Plan Only If We Tell Them", "paper_summary": "Large language models (LLMs) have demonstrated significant capabilities in\nnatural language processing and reasoning, yet their effectiveness in\nautonomous planning has been under debate. While existing studies have utilized\nLLMs with external feedback mechanisms or in controlled environments for\nplanning, these approaches often involve substantial computational and\ndevelopment resources due to the requirement for careful design and iterative\nbackprompting. Moreover, even the most advanced LLMs like GPT-4 struggle to\nmatch human performance on standard planning benchmarks, such as the\nBlocksworld, without additional support. This paper investigates whether LLMs\ncan independently generate long-horizon plans that rival human baselines. Our\nnovel enhancements to Algorithm-of-Thoughts (AoT), which we dub AoT+, help\nachieve state-of-the-art results in planning benchmarks out-competing prior\nmethods and human baselines all autonomously.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u548c\u63a8\u7406\u65b9\u9762\u5c55\u793a\u4e86\u986f\u8457\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u5728\u81ea\u4e3b\u898f\u5283\u4e2d\u7684\u6709\u6548\u6027\u4e00\u76f4\u5b58\u5728\u722d\u8b70\u3002\u5118\u7ba1\u73fe\u6709\u7814\u7a76\u5df2\u5c07 LLM \u8207\u5916\u90e8\u56de\u994b\u6a5f\u5236\u7d50\u5408\u4f7f\u7528\uff0c\u6216\u5728\u53d7\u63a7\u74b0\u5883\u4e2d\u9032\u884c\u898f\u5283\uff0c\u4f46\u7531\u65bc\u9700\u8981\u4ed4\u7d30\u8a2d\u8a08\u548c\u53cd\u8986\u63d0\u793a\uff0c\u9019\u4e9b\u65b9\u6cd5\u901a\u5e38\u6d89\u53ca\u5927\u91cf\u7684\u8a08\u7b97\u548c\u958b\u767c\u8cc7\u6e90\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u662f\u6700\u5148\u9032\u7684 LLM\uff08\u4f8b\u5982 GPT-4\uff09\u5728\u6c92\u6709\u984d\u5916\u652f\u63f4\u7684\u60c5\u6cc1\u4e0b\uff0c\u4e5f\u5f88\u96e3\u5728\u6a19\u6e96\u898f\u5283\u57fa\u6e96\uff08\u4f8b\u5982 Blocksworld\uff09\u4e0a\u9054\u5230\u4eba\u985e\u7684\u8868\u73fe\u3002\u672c\u6587\u63a2\u8a0e LLM \u662f\u5426\u80fd\u7368\u7acb\u751f\u6210\u8207\u4eba\u985e\u57fa\u6e96\u76f8\u5ab2\u7f8e\u7684\u9577\u9060\u8a08\u756b\u3002\u6211\u5011\u5c0d\u601d\u60f3\u6f14\u7b97\u6cd5 (AoT) \u7684\u5275\u65b0\u5f37\u5316\uff08\u6211\u5011\u7a31\u4e4b\u70ba AoT+\uff09\u6709\u52a9\u65bc\u5728\u898f\u5283\u57fa\u6e96\u4e2d\u53d6\u5f97\u6700\u5148\u9032\u7684\u6210\u679c\uff0c\u5728\u5b8c\u5168\u81ea\u4e3b\u7684\u60c5\u6cc1\u4e0b\u52dd\u904e\u5148\u524d\u7684\u5404\u7a2e\u65b9\u6cd5\u548c\u4eba\u985e\u57fa\u6e96\u3002", "author": "Bilgehan Sel et.al.", "authors": "Bilgehan Sel, Ruoxi Jia, Ming Jin", "id": "2501.13545v1", "paper_url": "http://arxiv.org/abs/2501.13545v1", "repo": "null"}}