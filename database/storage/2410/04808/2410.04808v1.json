{"2410.04808": {"publish_time": "2024-10-07", "title": "LPZero: Language Model Zero-cost Proxy Search from Zero", "paper_summary": "In spite of the outstanding performance, Neural Architecture Search (NAS) is\ncriticized for massive computation. Recently, Zero-shot NAS has emerged as a\npromising approach by exploiting Zero-cost (ZC) proxies, which markedly reduce\ncomputational demands. Despite this, existing ZC proxies heavily rely on expert\nknowledge and incur significant trial-and-error costs. Particularly in NLP\ntasks, most existing ZC proxies fail to surpass the performance of the naive\nbaseline. To address these challenges, we introduce a novel framework,\n\\textbf{LPZero}, which is the first to automatically design ZC proxies for\nvarious tasks, achieving higher ranking consistency than human-designed\nproxies. Specifically, we model the ZC proxy as a symbolic equation and\nincorporate a unified proxy search space that encompasses existing ZC proxies,\nwhich are composed of a predefined set of mathematical symbols. To\nheuristically search for the best ZC proxy, LPZero incorporates genetic\nprogramming to find the optimal symbolic composition. We propose a\n\\textit{Rule-based Pruning Strategy (RPS),} which preemptively eliminates\nunpromising proxies, thereby mitigating the risk of proxy degradation.\nExtensive experiments on FlexiBERT, GPT-2, and LLaMA-7B demonstrate LPZero's\nsuperior ranking ability and performance on downstream tasks compared to\ncurrent approaches.", "paper_summary_zh": "\u5118\u7ba1\u795e\u7ecf\u67b6\u6784\u641c\u7d22 (NAS) \u62e5\u6709\u51fa\u8272\u7684\u6027\u80fd\uff0c\u4f46\u5b83\u56e0\u5927\u91cf\u8fd0\u7b97\u800c\u53d7\u5230\u6279\u8bc4\u3002\u6700\u8fd1\uff0c\u96f6\u6b21\u5b66\u4e60 NAS \u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u9014\u7684\u65b9\u6cd5\u51fa\u73b0\uff0c\u5b83\u5229\u7528\u96f6\u6210\u672c (ZC) \u4ee3\u7406\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u8ba1\u7b97\u9700\u6c42\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u73b0\u6709\u7684 ZC \u4ee3\u7406\u4e25\u91cd\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\uff0c\u5e76\u4f1a\u4ea7\u751f\u5927\u91cf\u7684\u8bd5\u9519\u6210\u672c\u3002\u7279\u522b\u662f\u5728 NLP \u4efb\u52a1\u4e2d\uff0c\u5927\u591a\u6570\u73b0\u6709\u7684 ZC \u4ee3\u7406\u90fd\u65e0\u6cd5\u8d85\u8d8a\u6734\u7d20\u57fa\u51c6\u7684\u6027\u80fd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u65b0\u9896\u7684\u6846\u67b6 \\textbf{LPZero}\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u81ea\u52a8\u4e3a\u5404\u79cd\u4efb\u52a1\u8bbe\u8ba1 ZC \u4ee3\u7406\u7684\u6846\u67b6\uff0c\u5176\u6392\u540d\u4e00\u81f4\u6027\u9ad8\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u7684\u4ee3\u7406\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5c06 ZC \u4ee3\u7406\u5efa\u6a21\u4e3a\u4e00\u4e2a\u7b26\u53f7\u65b9\u7a0b\u5f0f\uff0c\u5e76\u7eb3\u5165\u4e86\u7edf\u4e00\u7684\u4ee3\u7406\u641c\u7d22\u7a7a\u95f4\uff0c\u5176\u4e2d\u5305\u542b\u73b0\u6709\u7684 ZC \u4ee3\u7406\uff0c\u8fd9\u4e9b\u4ee3\u7406\u7531\u4e00\u7ec4\u9884\u5b9a\u4e49\u7684\u6570\u5b66\u7b26\u53f7\u7ec4\u6210\u3002\u4e3a\u4e86\u542f\u53d1\u5f0f\u5730\u641c\u7d22\u6700\u4f73 ZC \u4ee3\u7406\uff0cLPZero \u7eb3\u5165\u4e86\u9057\u4f20\u7f16\u7a0b\u4ee5\u627e\u5230\u6700\u4f73\u7b26\u53f7\u7ec4\u5408\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a \\textit{\u57fa\u4e8e\u89c4\u5219\u7684\u4fee\u526a\u7b56\u7565 (RPS)\uff0c}\u5b83\u4f1a\u9884\u5148\u6d88\u9664\u6ca1\u6709\u524d\u9014\u7684\u4ee3\u7406\uff0c\u4ece\u800c\u51cf\u8f7b\u4ee3\u7406\u9000\u5316\u7684\u98ce\u9669\u3002\u5728 FlexiBERT\u3001GPT-2 \u548c LLaMA-7B \u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5f53\u524d\u65b9\u6cd5\u76f8\u6bd4\uff0cLPZero \u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u5177\u6709\u5353\u8d8a\u7684\u6392\u540d\u80fd\u529b\u548c\u6027\u80fd\u3002", "author": "Peijie Dong et.al.", "authors": "Peijie Dong, Lujun Li, Xiang Liu, Zhenheng Tang, Xuebo Liu, Qiang Wang, Xiaowen Chu", "id": "2410.04808v1", "paper_url": "http://arxiv.org/abs/2410.04808v1", "repo": "null"}}