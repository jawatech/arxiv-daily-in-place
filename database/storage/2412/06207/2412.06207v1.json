{"2412.06207": {"publish_time": "2024-12-09", "title": "Skill-Enhanced Reinforcement Learning Acceleration from Demonstrations", "paper_summary": "Learning from Demonstration (LfD) aims to facilitate rapid Reinforcement\nLearning (RL) by leveraging expert demonstrations to pre-train the RL agent.\nHowever, the limited availability of expert demonstration data often hinders\nits ability to effectively aid downstream RL learning. To address this problem,\nwe propose a novel two-stage method dubbed as Skill-enhanced Reinforcement\nLearning Acceleration (SeRLA). SeRLA introduces a skill-level adversarial\nPositive-Unlabeled (PU) learning model to extract useful skill prior knowledge\nby enabling learning from both limited expert data and general low-cost\ndemonstration data in the offline prior learning stage. Subsequently, it\ndeploys a skill-based soft actor-critic algorithm to leverage this acquired\nprior knowledge in the downstream online RL stage for efficient training of a\nskill policy network. Moreover, we develop a simple skill-level data\nenhancement technique to further alleviate data sparsity and improve both skill\nprior learning and downstream skill policy training. Our experimental results\non multiple standard RL environments show the proposed SeRLA method achieves\nstate-of-the-art performance on accelerating reinforcement learning on\ndownstream tasks, especially in the early learning phase.", "paper_summary_zh": "\u793a\u7bc4\u5b78\u7fd2 (LfD) \u65e8\u5728\u900f\u904e\u5229\u7528\u5c08\u5bb6\u793a\u7bc4\u4f86\u9810\u5148\u8a13\u7df4 RL \u4ee3\u7406\uff0c\u4ee5\u4fc3\u9032\u5feb\u901f\u5f37\u5316\u5b78\u7fd2 (RL)\u3002\u7136\u800c\uff0c\u5c08\u5bb6\u793a\u7bc4\u8cc7\u6599\u7684\u53d6\u5f97\u6709\u9650\uff0c\u5f80\u5f80\u6703\u963b\u7919\u5176\u6709\u6548\u5354\u52a9\u4e0b\u6e38 RL \u5b78\u7fd2\u7684\u80fd\u529b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u540d\u70ba\u300c\u6280\u80fd\u589e\u5f37\u5f37\u5316\u5b78\u7fd2\u52a0\u901f (SeRLA)\u300d\u7684\u5275\u65b0\u5169\u968e\u6bb5\u65b9\u6cd5\u3002SeRLA \u5f15\u5165\u4e86\u6280\u80fd\u7b49\u7d1a\u5c0d\u6297\u5f0f\u6b63\u8ca0\u672a\u6a19\u7c64 (PU) \u5b78\u7fd2\u6a21\u578b\uff0c\u85c9\u7531\u5728\u96e2\u7dda\u5148\u9a57\u5b78\u7fd2\u968e\u6bb5\u5f9e\u6709\u9650\u7684\u5c08\u5bb6\u8cc7\u6599\u548c\u4e00\u822c\u4f4e\u6210\u672c\u793a\u7bc4\u8cc7\u6599\u4e2d\u5b78\u7fd2\uff0c\u4f86\u8403\u53d6\u51fa\u6709\u7528\u7684\u6280\u80fd\u5148\u9a57\u77e5\u8b58\u3002\u96a8\u5f8c\uff0c\u5b83\u90e8\u7f72\u4e86\u4e00\u500b\u57fa\u65bc\u6280\u80fd\u7684\u8edf\u6027\u52d5\u4f5c-\u8a55\u8ad6\u6f14\u7b97\u6cd5\uff0c\u4ee5\u5728\u5f8c\u7e8c\u7684\u7dda\u4e0a RL \u968e\u6bb5\u4e2d\u5229\u7528\u9019\u500b\u7372\u5f97\u7684\u5148\u9a57\u77e5\u8b58\uff0c\u6709\u6548\u7387\u5730\u8a13\u7df4\u6280\u80fd\u653f\u7b56\u7db2\u8def\u3002\u6b64\u5916\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u7c21\u55ae\u7684\u6280\u80fd\u7b49\u7d1a\u8cc7\u6599\u589e\u5f37\u6280\u8853\uff0c\u4ee5\u9032\u4e00\u6b65\u6e1b\u8f15\u8cc7\u6599\u7a00\u758f\u6027\uff0c\u4e26\u6539\u5584\u6280\u80fd\u5148\u9a57\u5b78\u7fd2\u548c\u5f8c\u7e8c\u7684\u6280\u80fd\u653f\u7b56\u8a13\u7df4\u3002\u6211\u5011\u5728\u591a\u500b\u6a19\u6e96 RL \u74b0\u5883\u4e2d\u9032\u884c\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6240\u63d0\u51fa\u7684 SeRLA \u65b9\u6cd5\u5728\u52a0\u901f\u4e0b\u6e38\u4efb\u52d9\u7684\u5f37\u5316\u5b78\u7fd2\u65b9\u9762\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728\u65e9\u671f\u5b78\u7fd2\u968e\u6bb5\u3002", "author": "Hanping Zhang et.al.", "authors": "Hanping Zhang, Yuhong Guo", "id": "2412.06207v1", "paper_url": "http://arxiv.org/abs/2412.06207v1", "repo": "null"}}