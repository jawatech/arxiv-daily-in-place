{"2410.05116": {"publish_time": "2024-10-07", "title": "Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning", "paper_summary": "Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback.", "paper_summary_zh": "\u53ef\u63a7\u751f\u6210\u900f\u904e Stable Diffusion (SD) \u5fae\u8abf\uff0c\u65e8\u5728\u63d0\u9ad8\u4fdd\u771f\u5ea6\u3001\u5b89\u5168\u6027\uff0c\u4e26\u8207\u4eba\u985e\u6307\u5c0e\u4e00\u81f4\u3002\u73fe\u6709\u7684\u900f\u904e\u4eba\u985e\u56de\u994b\u65b9\u6cd5\u9032\u884c\u7684\u5f37\u5316\u5b78\u7fd2\u901a\u5e38\u4f9d\u8cf4\u9810\u5148\u5b9a\u7fa9\u7684\u555f\u767c\u5f0f\u734e\u52f5\u51fd\u6578\uff0c\u6216\u5efa\u69cb\u65bc\u5927\u578b\u8cc7\u6599\u96c6\u4e0a\u7684\u9810\u8a13\u7df4\u734e\u52f5\u6a21\u578b\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u6536\u96c6\u6b64\u985e\u8cc7\u6599\u6210\u672c\u9ad8\u6602\u6216\u56f0\u96e3\u7684\u60c5\u6cc1\u4e0b\u7684\u9069\u7528\u6027\u3002\u70ba\u4e86\u6709\u6548\u4e14\u6709\u6548\u5730\u5229\u7528\u4eba\u985e\u56de\u994b\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u67b6\u69cb HERO\uff0c\u5b83\u5229\u7528\u5728\u6a21\u578b\u5b78\u7fd2\u904e\u7a0b\u4e2d\u5373\u6642\u6536\u96c6\u7684\u7dda\u4e0a\u4eba\u985e\u56de\u994b\u3002\u5177\u9ad4\u800c\u8a00\uff0cHERO \u5177\u5099\u5169\u500b\u95dc\u9375\u6a5f\u5236\uff1a(1) \u56de\u994b\u5c0d\u9f4a\u8868\u793a\u5b78\u7fd2\uff0c\u4e00\u7a2e\u7dda\u4e0a\u8a13\u7df4\u65b9\u6cd5\uff0c\u7528\u65bc\u64f7\u53d6\u4eba\u985e\u56de\u994b\u4e26\u63d0\u4f9b\u7528\u65bc\u5fae\u8abf\u7684\u8cc7\u8a0a\u6027\u5b78\u7fd2\u8a0a\u865f\uff0c\u4ee5\u53ca (2) \u56de\u994b\u5f15\u5c0e\u5f71\u50cf\u751f\u6210\uff0c\u9019\u6d89\u53ca\u5f9e SD \u7684\u7cbe\u88fd\u521d\u59cb\u5316\u6a23\u672c\u751f\u6210\u5f71\u50cf\uff0c\u5f9e\u800c\u80fd\u66f4\u5feb\u5730\u671d\u8a55\u4f30\u8005\u7684\u610f\u5716\u6536\u6582\u3002\u6211\u5011\u8b49\u660e\uff0c\u8207\u73fe\u6709\u6700\u4f73\u65b9\u6cd5\u76f8\u6bd4\uff0cHERO \u5728\u7528\u65bc\u8eab\u9ad4\u90e8\u4f4d\u7570\u5e38\u6821\u6b63\u7684\u7dda\u4e0a\u56de\u994b\u4e2d\u6548\u7387\u9ad8\u51fa 4 \u500d\u3002\u6b64\u5916\uff0c\u5be6\u9a57\u8868\u660e\uff0cHERO \u53ef\u4ee5\u6709\u6548\u5730\u8655\u7406\u63a8\u7406\u3001\u8a08\u6578\u3001\u500b\u4eba\u5316\u548c\u6e1b\u5c11 NSFW \u5167\u5bb9\u7b49\u4efb\u52d9\uff0c\u800c\u50c5\u9700 0.5K \u7684\u7dda\u4e0a\u56de\u994b\u3002", "author": "Ayano Hiranaka et.al.", "authors": "Ayano Hiranaka, Shang-Fu Chen, Chieh-Hsin Lai, Dongjun Kim, Naoki Murata, Takashi Shibuya, Wei-Hsiang Liao, Shao-Hua Sun, Yuki Mitsufuji", "id": "2410.05116v1", "paper_url": "http://arxiv.org/abs/2410.05116v1", "repo": "null"}}