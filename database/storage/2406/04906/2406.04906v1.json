{"2406.04906": {"publish_time": "2024-06-07", "title": "RU-AI: A Large Multimodal Dataset for Machine Generated Content Detection", "paper_summary": "The recent advancements in generative AI models, which can create realistic\nand human-like content, are significantly transforming how people communicate,\ncreate, and work. While the appropriate use of generative AI models can benefit\nthe society, their misuse poses significant threats to data reliability and\nauthentication. However, due to a lack of aligned multimodal datasets,\neffective and robust methods for detecting machine-generated content are still\nin the early stages of development. In this paper, we introduce RU-AI, a new\nlarge-scale multimodal dataset designed for the robust and efficient detection\nof machine-generated content in text, image, and voice. Our dataset is\nconstructed from three large publicly available datasets: Flickr8K, COCO, and\nPlaces205, by combining the original datasets and their corresponding\nmachine-generated pairs. Additionally, experimental results show that our\nproposed unified model, which incorporates a multimodal embedding module with a\nmultilayer perceptron network, can effectively determine the origin of the data\n(i.e., original data samples or machine-generated ones) from RU-AI. However,\nfuture work is still required to address the remaining challenges posed by\nRU-AI. The source code and dataset are available at\nhttps://github.com/ZhihaoZhang97/RU-AI.", "paper_summary_zh": "\u751f\u6210\u5f0f AI \u6a21\u578b\u7684\u6700\u65b0\u9032\u5c55\u53ef\u4ee5\u5275\u9020\u51fa\u903c\u771f\u4e14\u64ec\u4eba\u7684\u5167\u5bb9\uff0c\u5927\u5e45\u6539\u8b8a\u4e86\u4eba\u5011\u6e9d\u901a\u3001\u5275\u4f5c\u548c\u5de5\u4f5c\u7684\u65b9\u5f0f\u3002\u5118\u7ba1\u9069\u7576\u4f7f\u7528\u751f\u6210\u5f0f AI \u6a21\u578b\u53ef\u4ee5\u4f7f\u793e\u6703\u53d7\u76ca\uff0c\u4f46\u5176\u6feb\u7528\u5c0d\u8cc7\u6599\u53ef\u9760\u6027\u548c\u9a57\u8b49\u69cb\u6210\u91cd\u5927\u5a01\u8105\u3002\u7136\u800c\uff0c\u7531\u65bc\u7f3a\u4e4f\u4e00\u81f4\u7684\u591a\u6a21\u614b\u8cc7\u6599\u96c6\uff0c\u7528\u65bc\u6aa2\u6e2c\u6a5f\u5668\u7522\u751f\u7684\u5167\u5bb9\u7684\u6709\u6548\u4e14\u7a69\u5065\u7684\u65b9\u6cd5\u4ecd\u8655\u65bc\u958b\u767c\u7684\u65e9\u671f\u968e\u6bb5\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 RU-AI\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7684\u5927\u578b\u591a\u6a21\u614b\u8cc7\u6599\u96c6\uff0c\u65e8\u5728\u5f37\u5065\u4e14\u6709\u6548\u5730\u6aa2\u6e2c\u6587\u5b57\u3001\u5f71\u50cf\u548c\u8a9e\u97f3\u4e2d\u7684\u6a5f\u5668\u7522\u751f\u7684\u5167\u5bb9\u3002\u6211\u5011\u7684\u8cc7\u6599\u96c6\u7531\u4e09\u500b\u5927\u578b\u516c\u958b\u8cc7\u6599\u96c6\u5efa\u69cb\u800c\u6210\uff1aFlickr8K\u3001COCO \u548c Places205\uff0c\u900f\u904e\u7d50\u5408\u539f\u59cb\u8cc7\u6599\u96c6\u53ca\u5176\u5c0d\u61c9\u7684\u6a5f\u5668\u7522\u751f\u914d\u5c0d\u3002\u6b64\u5916\uff0c\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u63d0\u51fa\u7684\u7d71\u4e00\u6a21\u578b\u7d50\u5408\u4e86\u591a\u6a21\u614b\u5d4c\u5165\u6a21\u7d44\u548c\u591a\u5c64\u611f\u77e5\u5668\u7db2\u8def\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5f9e RU-AI \u4e2d\u78ba\u5b9a\u8cc7\u6599\u7684\u4f86\u6e90\uff08\u5373\u539f\u59cb\u8cc7\u6599\u6a23\u672c\u6216\u6a5f\u5668\u7522\u751f\u7684\u6a23\u672c\uff09\u3002\u7136\u800c\uff0c\u4ecd\u7136\u9700\u8981\u5f8c\u7e8c\u5de5\u4f5c\u4f86\u89e3\u6c7a RU-AI \u69cb\u6210\u7684\u5176\u9918\u6311\u6230\u3002\u539f\u59cb\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u53ef\u5728 https://github.com/ZhihaoZhang97/RU-AI \u53d6\u5f97\u3002", "author": "Liting Huang et.al.", "authors": "Liting Huang, Zhihao Zhang, Yiran Zhang, Xiyue Zhou, Shoujin Wang", "id": "2406.04906v1", "paper_url": "http://arxiv.org/abs/2406.04906v1", "repo": "https://github.com/zhihaozhang97/ru-ai"}}