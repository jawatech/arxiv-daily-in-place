{"2406.09961": {"publish_time": "2024-06-14", "title": "ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via Chart-to-Code Generation", "paper_summary": "We introduce a new benchmark, ChartMimic, aimed at assessing the\nvisually-grounded code generation capabilities of large multimodal models\n(LMMs). ChartMimic utilizes information-intensive visual charts and textual\ninstructions as inputs, requiring LMMs to generate the corresponding code for\nchart rendering. ChartMimic includes 1,000 human-curated (figure, instruction,\ncode) triplets, which represent the authentic chart use cases found in\nscientific papers across various domains(e.g., Physics, Computer Science,\nEconomics, etc). These charts span 18 regular types and 4 advanced types,\ndiversifying into 191 subcategories. Furthermore, we propose multi-level\nevaluation metrics to provide an automatic and thorough assessment of the\noutput code and the rendered charts. Unlike existing code generation\nbenchmarks, ChartMimic places emphasis on evaluating LMMs' capacity to\nharmonize a blend of cognitive capabilities, encompassing visual understanding,\ncode generation, and cross-modal reasoning. The evaluation of 3 proprietary\nmodels and 11 open-weight models highlights the substantial challenges posed by\nChartMimic. Even the advanced GPT-4V, Claude-3-opus only achieve an average\nscore of 73.2 and 53.7, respectively, indicating significant room for\nimprovement. We anticipate that ChartMimic will inspire the development of\nLMMs, advancing the pursuit of artificial general intelligence.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63a8\u51fa\u4e86\u65b0\u7684\u57fa\u6e96 ChartMimic\uff0c\u65e8\u5728\u8a55\u4f30\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b (LMM) \u7684\u8996\u89ba\u57fa\u790e\u7a0b\u5f0f\u78bc\u751f\u6210\u80fd\u529b\u3002ChartMimic \u5229\u7528\u8cc7\u8a0a\u5bc6\u96c6\u7684\u8996\u89ba\u5716\u8868\u548c\u6587\u5b57\u8aaa\u660e\u4f5c\u70ba\u8f38\u5165\uff0c\u8981\u6c42 LMM \u7522\u751f\u5c0d\u61c9\u7684\u5716\u8868\u7e6a\u88fd\u7a0b\u5f0f\u78bc\u3002ChartMimic \u5305\u542b 1,000 \u500b\u7531\u4eba\u7b56\u5283\u7684 (\u5716\u5f62\u3001\u8aaa\u660e\u3001\u7a0b\u5f0f\u78bc) \u4e09\u5143\u7d44\uff0c\u4ee3\u8868\u5728\u5404\u500b\u9818\u57df (\u4f8b\u5982\u7269\u7406\u3001\u96fb\u8166\u79d1\u5b78\u3001\u7d93\u6fdf\u5b78\u7b49) \u7684\u79d1\u5b78\u8ad6\u6587\u4e2d\u767c\u73fe\u7684\u771f\u5be6\u5716\u8868\u4f7f\u7528\u6848\u4f8b\u3002\u9019\u4e9b\u5716\u8868\u6db5\u84cb 18 \u7a2e\u5e38\u898f\u985e\u578b\u548c 4 \u7a2e\u9032\u968e\u985e\u578b\uff0c\u5206\u70ba 191 \u500b\u5b50\u985e\u5225\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u591a\u5c64\u7d1a\u8a55\u4f30\u6307\u6a19\uff0c\u4ee5\u81ea\u52d5\u4e14\u5fb9\u5e95\u5730\u8a55\u4f30\u8f38\u51fa\u7a0b\u5f0f\u78bc\u548c\u7e6a\u88fd\u7684\u5716\u8868\u3002\u8207\u73fe\u6709\u7684\u7a0b\u5f0f\u78bc\u751f\u6210\u57fa\u6e96\u4e0d\u540c\uff0cChartMimic \u5f37\u8abf\u8a55\u4f30 LMM \u5c07\u8996\u89ba\u7406\u89e3\u3001\u7a0b\u5f0f\u78bc\u751f\u6210\u548c\u8de8\u6a21\u614b\u63a8\u7406\u7b49\u8a8d\u77e5\u80fd\u529b\u878d\u6703\u8cab\u901a\u7684\u80fd\u529b\u3002\u5c0d 3 \u500b\u5c08\u6709\u6a21\u578b\u548c 11 \u500b\u958b\u653e\u6b0a\u91cd\u6a21\u578b\u7684\u8a55\u4f30\u7a81\u986f\u4e86 ChartMimic \u5e36\u4f86\u7684\u91cd\u5927\u6311\u6230\u3002\u5373\u4f7f\u662f\u9032\u968e\u7684 GPT-4V \u548c Claude-3-opus \u4e5f\u53ea\u5206\u5225\u9054\u5230 73.2 \u548c 53.7 \u7684\u5e73\u5747\u5206\u6578\uff0c\u8868\u793a\u6709\u5f88\u5927\u7684\u9032\u6b65\u7a7a\u9593\u3002\u6211\u5011\u9810\u671f ChartMimic \u5c07\u6fc0\u52f5 LMM \u7684\u767c\u5c55\uff0c\u63a8\u52d5\u4eba\u5de5\u901a\u7528\u667a\u6167\u7684\u7814\u7a76\u3002</paragraph>", "author": "Chufan Shi et.al.", "authors": "Chufan Shi, Cheng Yang, Yaxin Liu, Bo Shui, Junjie Wang, Mohan Jing, Linran Xu, Xinyu Zhu, Siheng Li, Yuxiang Zhang, Gongye Liu, Xiaomei Nie, Deng Cai, Yujiu Yang", "id": "2406.09961v1", "paper_url": "http://arxiv.org/abs/2406.09961v1", "repo": "https://github.com/chartmimic/chartmimic"}}