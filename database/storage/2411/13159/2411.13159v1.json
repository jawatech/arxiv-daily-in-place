{"2411.13159": {"publish_time": "2024-11-20", "title": "Hard-Synth: Synthesizing Diverse Hard Samples for ASR using Zero-Shot TTS and LLM", "paper_summary": "Text-to-speech (TTS) models have been widely adopted to enhance automatic\nspeech recognition (ASR) systems using text-only corpora, thereby reducing the\ncost of labeling real speech data. Existing research primarily utilizes\nadditional text data and predefined speech styles supported by TTS models. In\nthis paper, we propose Hard-Synth, a novel ASR data augmentation method that\nleverages large language models (LLMs) and advanced zero-shot TTS. Our approach\nemploys LLMs to generate diverse in-domain text through rewriting, without\nrelying on additional text data. Rather than using predefined speech styles, we\nintroduce a hard prompt selection method with zero-shot TTS to clone speech\nstyles that the ASR model finds challenging to recognize. Experiments\ndemonstrate that Hard-Synth significantly enhances the Conformer model,\nachieving relative word error rate (WER) reductions of 6.5\\%/4.4\\% on\nLibriSpeech dev/test-other subsets. Additionally, we show that Hard-Synth is\ndata-efficient and capable of reducing bias in ASR.", "paper_summary_zh": "\u6587\u672c\u8f49\u8a9e\u97f3 (TTS) \u6a21\u578b\u5df2\u88ab\u5ee3\u6cdb\u63a1\u7528\uff0c\u4ee5\u5229\u7528\u7d14\u6587\u5b57\u8a9e\u6599\u5eab\u589e\u5f37\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u7cfb\u7d71\uff0c\u5f9e\u800c\u964d\u4f4e\u6a19\u8a18\u771f\u5be6\u8a9e\u97f3\u8cc7\u6599\u7684\u6210\u672c\u3002\u73fe\u6709\u7814\u7a76\u4e3b\u8981\u5229\u7528 TTS \u6a21\u578b\u652f\u63f4\u7684\u984d\u5916\u6587\u5b57\u8cc7\u6599\u548c\u9810\u5148\u5b9a\u7fa9\u7684\u8a9e\u97f3\u98a8\u683c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa Hard-Synth\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684 ASR \u8cc7\u6599\u64f4\u5145\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u9032\u968e\u7684\u96f6\u6b21\u5b78\u7fd2 TTS\u3002\u6211\u5011\u7684\u65b9\u6cd5\u5229\u7528 LLM \u900f\u904e\u6539\u5beb\u4f86\u7522\u751f\u591a\u6a23\u5316\u7684\u9818\u57df\u5167\u6587\u5b57\uff0c\u800c\u4e0d\u4f9d\u8cf4\u984d\u5916\u7684\u6587\u5b57\u8cc7\u6599\u3002\u6211\u5011\u6c92\u6709\u4f7f\u7528\u9810\u5148\u5b9a\u7fa9\u7684\u8a9e\u97f3\u98a8\u683c\uff0c\u800c\u662f\u5f15\u9032\u4e00\u7a2e\u642d\u914d\u96f6\u6b21\u5b78\u7fd2 TTS \u7684\u786c\u63d0\u793a\u9078\u53d6\u65b9\u6cd5\uff0c\u4ee5\u8907\u88fd ASR \u6a21\u578b\u96e3\u4ee5\u8fa8\u8b58\u7684\u8a9e\u97f3\u98a8\u683c\u3002\u5be6\u9a57\u8b49\u660e Hard-Synth \u5927\u5e45\u589e\u5f37 Conformer \u6a21\u578b\uff0c\u5728 LibriSpeech dev/test-other \u5b50\u96c6\u4e2d\u9054\u6210 6.5%/4.4% \u7684\u76f8\u5c0d\u8a5e\u5f59\u932f\u8aa4\u7387 (WER) \u964d\u4f4e\u3002\u6b64\u5916\uff0c\u6211\u5011\u8b49\u660e Hard-Synth \u5177\u6709\u8cc7\u6599\u6548\u7387\uff0c\u4e26\u4e14\u80fd\u5920\u964d\u4f4e ASR \u4e2d\u7684\u504f\u5dee\u3002", "author": "Jiawei Yu et.al.", "authors": "Jiawei Yu, Yuang Li, Xiaosong Qiao, Huan Zhao, Xiaofeng Zhao, Wei Tang, Min Zhang, Hao Yang, Jinsong Su", "id": "2411.13159v1", "paper_url": "http://arxiv.org/abs/2411.13159v1", "repo": "null"}}