
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-25**|**Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?**|Sohee Yang et.al.|[2411.16679v1](http://arxiv.org/abs/2411.16679v1)|null|
|**2024-11-25**|**CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance**|Jiaan Han et.al.|[2411.16666v1](http://arxiv.org/abs/2411.16666v1)|null|
|**2024-11-25**|**DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation**|Zun Wang et.al.|[2411.16657v1](http://arxiv.org/abs/2411.16657v1)|null|
|**2024-11-25**|**Self-Generated Critiques Boost Reward Modeling for Language Models**|Yue Yu et.al.|[2411.16646v1](http://arxiv.org/abs/2411.16646v1)|null|
|**2024-11-25**|**Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters**|Dietmar Jannach et.al.|[2411.16645v1](http://arxiv.org/abs/2411.16645v1)|null|
|**2024-11-25**|**Preventing Jailbreak Prompts as Malicious Tools for Cybercriminals: A Cyber Defense Perspective**|Jean Marie Tshimula et.al.|[2411.16642v1](http://arxiv.org/abs/2411.16642v1)|null|
|**2024-11-25**|**Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation**|Sanjana Ramprasad et.al.|[2411.16638v1](http://arxiv.org/abs/2411.16638v1)|null|
|**2024-11-25**|**Imperceptible Adversarial Examples in the Physical World**|Weilin Xu et.al.|[2411.16622v1](http://arxiv.org/abs/2411.16622v1)|null|
|**2024-11-25**|**StructFormer: Document Structure-based Masked Attention and its Impact on Language Model Pre-Training**|Kaustubh Ponkshe et.al.|[2411.16618v1](http://arxiv.org/abs/2411.16618v1)|null|
|**2024-11-25**|**Recent Trends in Linear Text Segmentation: a Survey**|Iacopo Ghinassi et.al.|[2411.16613v1](http://arxiv.org/abs/2411.16613v1)|null|
|**2024-11-25**|**F -- A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite**|Ansgar Scherp et.al.|[2411.16609v1](http://arxiv.org/abs/2411.16609v1)|[link](https://github.com/ascherp/ontologies)|
|**2024-11-25**|**From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge**|Dawei Li et.al.|[2411.16594v1](http://arxiv.org/abs/2411.16594v1)|[link](https://github.com/llm-as-a-judge/awesome-llm-as-a-judge)|
|**2024-11-25**|**Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision**|Zhiheng Xi et.al.|[2411.16579v1](http://arxiv.org/abs/2411.16579v1)|null|
|**2024-11-25**|**Naive Algorithmic Collusion: When Do Bandit Learners Cooperate and When Do They Compete?**|Connor Douglas et.al.|[2411.16574v1](http://arxiv.org/abs/2411.16574v1)|null|
|**2024-11-25**|**EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code**|Shahriyar Zaman Ridoy et.al.|[2411.16561v1](http://arxiv.org/abs/2411.16561v1)|null|
|**2024-11-25**|**Representation Collapsing Problems in Vector Quantization**|Wenhao Zhao et.al.|[2411.16550v1](http://arxiv.org/abs/2411.16550v1)|null|
|**2024-11-25**|**RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics**|Chan Hee Song et.al.|[2411.16537v1](http://arxiv.org/abs/2411.16537v1)|null|
|**2024-11-25**|**Profiling Bias in LLMs: Stereotype Dimensions in Contextual Word Embeddings**|Carolin M. Schuster et.al.|[2411.16527v1](http://arxiv.org/abs/2411.16527v1)|null|
|**2024-11-25**|**Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency**|Jerry Yao-Chieh Hu et.al.|[2411.16525v1](http://arxiv.org/abs/2411.16525v1)|null|
|**2024-11-25**|**LaB-RAG: Label Boosted Retrieval Augmented Generation for Radiology Report Generation**|Steven Song et.al.|[2411.16523v1](http://arxiv.org/abs/2411.16523v1)|null|
|**2024-11-25**|**All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages**|Ashmal Vayani et.al.|[2411.16508v1](http://arxiv.org/abs/2411.16508v1)|null|
|**2024-11-25**|**Interpreting Language Reward Models via Contrastive Explanations**|Junqi Jiang et.al.|[2411.16502v1](http://arxiv.org/abs/2411.16502v1)|null|
|**2024-11-25**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495v1](http://arxiv.org/abs/2411.16495v1)|null|
|**2024-11-25**|**O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?**|Zhen Huang et.al.|[2411.16489v1](http://arxiv.org/abs/2411.16489v1)|[link](https://github.com/gair-nlp/o1-journey)|
|**2024-11-25**|**When Babies Teach Babies: Can student knowledge sharing outperform Teacher-Guided Distillation on small datasets?**|Srikrishna Iyer et.al.|[2411.16487v1](http://arxiv.org/abs/2411.16487v1)|[link](https://github.com/ai-da-stc/generative-ai-research-babylm)|
|**2024-11-25**|**Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction**|Haoming Li et.al.|[2411.16457v1](http://arxiv.org/abs/2411.16457v1)|null|
|**2024-11-25**|**Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**|Xiaocong Yang et.al.|[2411.16454v1](http://arxiv.org/abs/2411.16454v1)|null|
|**2024-11-25**|**TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment**|Luca Colombo et.al.|[2411.16442v1](http://arxiv.org/abs/2411.16442v1)|[link](https://github.com/ai-tech-research-lab/tifed)|
|**2024-11-25**|**Finding Structure in Language Models**|Jaap Jumelet et.al.|[2411.16433v1](http://arxiv.org/abs/2411.16433v1)|null|
|**2024-11-25**|**TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation**|Linqing Zhong et.al.|[2411.16425v1](http://arxiv.org/abs/2411.16425v1)|null|
|**2024-11-25**|**Turbofan Engine Remaining Useful Life (RUL) Prediction Based on Bi-Directional Long Short-Term Memory (BLSTM)**|Abedin Sherifi et.al.|[2411.16422v1](http://arxiv.org/abs/2411.16422v1)|null|
|**2024-11-25**|**A Study on Unsupervised Domain Adaptation for Semantic Segmentation in the Era of Vision-Language Models**|Manuel Schwonberg et.al.|[2411.16407v1](http://arxiv.org/abs/2411.16407v1)|null|
|**2024-11-25**|**Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN**|Elona Shatri et.al.|[2411.16405v1](http://arxiv.org/abs/2411.16405v1)|null|
|**2024-11-25**|**Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**|Alexander Fichtl et.al.|[2411.16403v1](http://arxiv.org/abs/2411.16403v1)|null|
|**2024-11-25**|**Human-Calibrated Automated Testing and Validation of Generative Language Models**|Agus Sudjianto et.al.|[2411.16391v1](http://arxiv.org/abs/2411.16391v1)|null|
|**2024-11-25**|**FineWeb-zhtw: Scalable Curation of Traditional Chinese Text Data from the Web**|Cheng-Wei Lin et.al.|[2411.16387v1](http://arxiv.org/abs/2411.16387v1)|null|
|**2024-11-25**|**Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**|Yuncheng Jiang et.al.|[2411.16380v1](http://arxiv.org/abs/2411.16380v1)|null|
|**2024-11-25**|**A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation**|M. M. A. Valiuddin et.al.|[2411.16370v1](http://arxiv.org/abs/2411.16370v1)|null|
|**2024-11-25**|**Multi-modal Retrieval Augmented Multi-modal Generation: A Benchmark, Evaluate Metrics and Strong Baselines**|Zi-Ao Ma et.al.|[2411.16365v1](http://arxiv.org/abs/2411.16365v1)|null|
|**2024-11-25**|**Graph Neural Networks-based Parameter Design towards Large-Scale Superconducting Quantum Circuits for Crosstalk Mitigation**|Hao Ai et.al.|[2411.16354v1](http://arxiv.org/abs/2411.16354v1)|null|
|**2024-11-25**|**The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C**|Mikita Balesni et.al.|[2411.16353v1](http://arxiv.org/abs/2411.16353v1)|null|
|**2024-11-25**|**Preference Optimization for Reasoning with Pseudo Feedback**|Fangkai Jiao et.al.|[2411.16345v1](http://arxiv.org/abs/2411.16345v1)|null|
|**2024-11-25**|**Can AI grade your essays? A comparative analysis of large language models and teacher ratings in multidimensional essay scoring**|Kathrin Seßler et.al.|[2411.16337v1](http://arxiv.org/abs/2411.16337v1)|null|
|**2024-11-25**|**One Diffusion to Generate Them All**|Duong H. Le et.al.|[2411.16318v1](http://arxiv.org/abs/2411.16318v1)|[link](https://github.com/lehduong/onediffusion)|
|**2024-11-25**|**CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning**|Duo Wu et.al.|[2411.16313v1](http://arxiv.org/abs/2411.16313v1)|null|
|**2024-11-25**|**Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems**|Magdalena Kaiser et.al.|[2411.16305v1](http://arxiv.org/abs/2411.16305v1)|null|
|**2024-11-25**|**BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment**|Shaolei Zhang et.al.|[2411.16300v1](http://arxiv.org/abs/2411.16300v1)|[link](https://github.com/ictnlp/bayling)|
|**2024-11-25**|**The SVASR System for Text-dependent Speaker Verification (TdSV) AAIC Challenge 2024**|Mohammadreza Molavi et.al.|[2411.16276v1](http://arxiv.org/abs/2411.16276v1)|null|
|**2024-11-25**|**Probing for Consciousness in Machines**|Mathis Immertreu et.al.|[2411.16262v1](http://arxiv.org/abs/2411.16262v1)|null|
|**2024-11-25**|**Unraveling Arithmetic in Large Language Models: The Role of Algebraic Structures**|Fu-Chieh Chang et.al.|[2411.16260v1](http://arxiv.org/abs/2411.16260v1)|null|
|**2024-11-25**|**NormXLogit: The Head-on-Top Never Lies**|Sina Abbasi et.al.|[2411.16252v1](http://arxiv.org/abs/2411.16252v1)|null|
|**2024-11-25**|**Transparent Neighborhood Approximation for Text Classifier Explanation**|Yi Cai et.al.|[2411.16251v1](http://arxiv.org/abs/2411.16251v1)|null|
|**2024-11-25**|**DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence Embeddings**|Hong Liu et.al.|[2411.16236v1](http://arxiv.org/abs/2411.16236v1)|null|
|**2024-11-25**|**MH-MoE:Multi-Head Mixture-of-Experts**|Shaohan Huang et.al.|[2411.16205v1](http://arxiv.org/abs/2411.16205v1)|null|
|**2024-11-25**|**Video-Text Dataset Construction from Multi-AI Feedback: Promoting Weak-to-Strong Preference Learning for Video Large Language Models**|Hao Yi et.al.|[2411.16201v1](http://arxiv.org/abs/2411.16201v1)|null|
|**2024-11-25**|**Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models**|Zhihua Duan et.al.|[2411.16189v1](http://arxiv.org/abs/2411.16189v1)|null|
|**2024-11-25**|**SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis**|Junho Kim et.al.|[2411.16173v1](http://arxiv.org/abs/2411.16173v1)|null|
|**2024-11-25**|**MixPE: Quantization and Hardware Co-design for Efficient LLM Inference**|Yu Zhang et.al.|[2411.16158v1](http://arxiv.org/abs/2411.16158v1)|null|
|**2024-11-25**|**Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning**|Toyotaro Suzumura et.al.|[2411.16155v1](http://arxiv.org/abs/2411.16155v1)|null|
|**2024-11-25**|**SKQVC: One-Shot Voice Conversion by K-Means Quantization with Self-Supervised Speech Representations**|Youngjun Sim et.al.|[2411.16147v1](http://arxiv.org/abs/2411.16147v1)|null|
|**2024-11-25**|**End-to-End Steering for Autonomous Vehicles via Conditional Imitation Co-Learning**|Mahmoud M. Kishky et.al.|[2411.16131v1](http://arxiv.org/abs/2411.16131v1)|null|
|**2024-11-25**|**Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**|Hangyul Yoon et.al.|[2411.16123v1](http://arxiv.org/abs/2411.16123v1)|null|
|**2024-11-25**|**Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**|Rui Zuo et.al.|[2411.16120v1](http://arxiv.org/abs/2411.16120v1)|null|
|**2024-11-25**|**LLM Augmentations to support Analytical Reasoning over Multiple Documents**|Raquib Bin Yousuf et.al.|[2411.16116v1](http://arxiv.org/abs/2411.16116v1)|[link](https://github.com/discoveryanalyticscenter/speculatores)|
|**2024-11-25**|**LLMPirate: LLMs for Black-box Hardware IP Piracy**|Vasudev Gohil et.al.|[2411.16111v1](http://arxiv.org/abs/2411.16111v1)|null|
|**2024-11-25**|**Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability**|Jatin Nainani et.al.|[2411.16105v1](http://arxiv.org/abs/2411.16105v1)|null|
|**2024-11-25**|**An Empirical Study of Vulnerability Detection using Federated Learning**|Peiheng Zhou et.al.|[2411.16099v1](http://arxiv.org/abs/2411.16099v1)|null|
|**2024-11-25**|**ENCLIP: Ensembling and Clustering-Based Contrastive Language-Image Pretraining for Fashion Multimodal Search with Limited Data and Low-Quality Images**|Prithviraj Purushottam Naik et.al.|[2411.16096v1](http://arxiv.org/abs/2411.16096v1)|null|
|**2024-11-25**|**HiDP: Hierarchical DNN Partitioning for Distributed Inference on Heterogeneous Edge Platforms**|Zain Taufique et.al.|[2411.16086v1](http://arxiv.org/abs/2411.16086v1)|null|
|**2024-11-25**|**Deciphering genomic codes using advanced NLP techniques: a scoping review**|Shuyan Cheng et.al.|[2411.16084v1](http://arxiv.org/abs/2411.16084v1)|null|
|**2024-11-25**|**Boosting 3D Object Generation through PBR Materials**|Yitong Wang et.al.|[2411.16080v1](http://arxiv.org/abs/2411.16080v1)|null|
|**2024-11-25**|**Debiasing Classifiers by Amplifying Bias with Latent Diffusion and Large Language Models**|Donggeun Ko et.al.|[2411.16079v1](http://arxiv.org/abs/2411.16079v1)|null|
|**2024-11-25**|**SAGEval: The frontiers of Satisfactory Agent based NLG Evaluation for reference-free open-ended text**|Reshmi Ghosh et.al.|[2411.16077v1](http://arxiv.org/abs/2411.16077v1)|null|
|**2024-11-25**|**The brain versus AI: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum**|Shogo Ohmae et.al.|[2411.16075v1](http://arxiv.org/abs/2411.16075v1)|null|
|**2024-11-25**|**UnitedVLN: Generalizable Gaussian Splatting for Continuous Vision-Language Navigation**|Guangzhao Dai et.al.|[2411.16053v1](http://arxiv.org/abs/2411.16053v1)|null|
|**2024-11-25**|**Predicting Emergent Capabilities by Finetuning**|Charlie Snell et.al.|[2411.16035v1](http://arxiv.org/abs/2411.16035v1)|null|
|**2024-11-25**|**From Dashcam Videos to Driving Simulations: Stress Testing Automated Vehicles against Rare Events**|Yan Miao et.al.|[2411.16027v1](http://arxiv.org/abs/2411.16027v1)|null|
|**2024-11-25**|**TransCompressor: LLM-Powered Multimodal Data Compression for Smart Transportation**|Huanqi Yang et.al.|[2411.16020v1](http://arxiv.org/abs/2411.16020v1)|null|
|**2024-11-24**|**Performance Implications of Multi-Chiplet Neural Processing Units on Autonomous Driving Perception**|Mohanad Odema et.al.|[2411.16007v1](http://arxiv.org/abs/2411.16007v1)|null|
|**2024-11-24**|**eFedLLM: Efficient LLM Inference Based on Federated Learning**|Shengwen Ding et.al.|[2411.16003v1](http://arxiv.org/abs/2411.16003v1)|null|
|**2024-11-24**|**Exploring Performance Contrasts in TableQA: Step-by-Step Reasoning Boosts Bigger Language Models, Limits Smaller Language Models**|Haoyan Yang et.al.|[2411.16002v1](http://arxiv.org/abs/2411.16002v1)|null|
|**2024-11-24**|**Multi-ToM: Evaluating Multilingual Theory of Mind Capabilities in Large Language Models**|Jayanta Sadhu et.al.|[2411.15999v1](http://arxiv.org/abs/2411.15999v1)|null|
|**2024-11-24**|**PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making**|Jonathan Light et.al.|[2411.15998v1](http://arxiv.org/abs/2411.15998v1)|null|
|**2024-11-24**|**Ensuring Fair LLM Serving Amid Diverse Applications**|Redwan Ibne Seraj Khan et.al.|[2411.15997v1](http://arxiv.org/abs/2411.15997v1)|null|
|**2024-11-24**|**Investigating Factuality in Long-Form Text Generation: The Roles of Self-Known and Self-Unknown**|Lifu Tu et.al.|[2411.15993v1](http://arxiv.org/abs/2411.15993v1)|null|
|**2024-11-24**|**Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format**|Chao Fang et.al.|[2411.15982v1](http://arxiv.org/abs/2411.15982v1)|null|
|**2024-11-24**|**DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**|Ruiqiang Xiao et.al.|[2411.15976v1](http://arxiv.org/abs/2411.15976v1)|null|
|**2024-11-24**|**Partial Identifiability and Misspecification in Inverse Reinforcement Learning**|Joar Skalse et.al.|[2411.15951v1](http://arxiv.org/abs/2411.15951v1)|null|
|**2024-11-24**|**Generative Context Distillation**|Haebin Shin et.al.|[2411.15927v1](http://arxiv.org/abs/2411.15927v1)|null|
|**2024-11-24**|**Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan**|Saba Zahid et.al.|[2411.15923v1](http://arxiv.org/abs/2411.15923v1)|null|
|**2024-11-24**|**A Training-Free Approach for Music Style Transfer with Latent Diffusion Models**|Sooyoung Kim et.al.|[2411.15913v1](http://arxiv.org/abs/2411.15913v1)|null|
|**2024-11-24**|**Bimanual Grasp Synthesis for Dexterous Robot Hands**|Yanming Shao et.al.|[2411.15903v1](http://arxiv.org/abs/2411.15903v1)|null|
|**2024-11-24**|**Distribution-aware Online Continual Learning for Urban Spatio-Temporal Forecasting**|Chengxin Wang et.al.|[2411.15893v1](http://arxiv.org/abs/2411.15893v1)|null|
|**2024-11-24**|**Evaluating Large Language Models for Causal Modeling**|Houssam Razouk et.al.|[2411.15888v1](http://arxiv.org/abs/2411.15888v1)|null|
|**2024-11-24**|**LLMs Do Not Think Step-by-step In Implicit Reasoning**|Yijiong Yu et.al.|[2411.15862v1](http://arxiv.org/abs/2411.15862v1)|null|
|**2024-11-24**|**Unveiling the Superior Paradigm: A Comparative Study of Source-Free Domain Adaptation and Unsupervised Domain Adaptation**|Fan Wang et.al.|[2411.15844v1](http://arxiv.org/abs/2411.15844v1)|null|
|**2024-11-24**|**Efficient and Private: Memorisation under differentially private parameter-efficient fine-tuning in language models**|Olivia Ma et.al.|[2411.15831v1](http://arxiv.org/abs/2411.15831v1)|null|
|**2024-11-24**|**Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?**|Aryan Sajith et.al.|[2411.15821v1](http://arxiv.org/abs/2411.15821v1)|[link](https://github.com/aryan-sajith/urv-data_quantity_vs_data_quality-research)|
|**2024-11-24**|**FastTrackTr:Towards Fast Multi-Object Tracking with Transformers**|Pan Liao et.al.|[2411.15811v1](http://arxiv.org/abs/2411.15811v1)|null|
|**2024-11-24**|**Benchmarking Active Learning for NILM**|Dhruv Patel et.al.|[2411.15805v1](http://arxiv.org/abs/2411.15805v1)|null|

#### Abstracts
##### **Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?**
2411.16679v1 by Sohee Yang, Nora Kassner, Elena Gribovskaya, Sebastian Riedel, Mor Geva

We evaluate how well Large Language Models (LLMs) latently recall and compose
facts to answer multi-hop queries like "In the year Scarlett Johansson was
born, the Summer Olympics were hosted in the country of". One major challenge
in evaluating this ability is that LLMs may have developed shortcuts by
encounters of the head entity "Scarlett Johansson" and the answer entity
"United States" in the same training sequences or merely guess the answer based
on frequency-based priors. To prevent shortcuts, we exclude test queries where
the head and answer entities co-appear in pretraining corpora. Through careful
selection of relations and facts and systematic removal of cases where models
might guess answers or exploit partial matches, we construct an evaluation
dataset SOCRATES (ShOrtCut-fRee lATent rEaSoning). We observe that LLMs
demonstrate promising latent multi-hop reasoning abilities without exploiting
shortcuts, but only for certain types of queries. For queries requiring latent
recall of countries as the intermediate answer, the best models achieve 80%
latent composability, but this drops to just 5% for the recall of years.
Comparisons with Chain-of-Thought composability highlight a significant gap
between the ability of models to reason latently versus explicitly. Analysis
reveals that latent representations of the intermediate answer are constructed
more often in queries with higher latent composability, and shows the emergence
of latent multi-hop reasoning during pretraining.

摘要：我們評估大型語言模型 (LLM) 在潛在回憶和組合事實方面表現如何，以回答多重跳躍查詢，例如「史嘉蕾喬韓森出生的那一年，夏季奧運會在國家舉辦」。評估此能力的一項重大挑戰在於，LLM 可能透過在相同的訓練序列中遭遇頭部實體「史嘉蕾喬韓森」和答案實體「美國」而開發出捷徑，或僅根據基於頻率的先驗猜測答案。為了防止捷徑，我們排除了頭部和答案實體在預訓練語料庫中共同出現的測試查詢。透過仔細選擇關係和事實，並系統性地移除模型可能猜測答案或利用部分匹配的案例，我們建構了一個評估資料集 SOCRATES（ShOrtCut-fRee lATent rEaSoning）。我們觀察到，LLM 在不利用捷徑的情況下展現出潛在的多重跳躍推理能力，但僅限於特定類型的查詢。對於需要潛在回憶國家作為中間答案的查詢，最佳模型達到 80% 的潛在可組合性，但這對於回憶年份來說僅下降到 5%。與思考鏈可組合性的比較突顯了模型潛在推理與明確推理能力之間的顯著差距。分析顯示，在潛在可組合性較高的查詢中，中間答案的潛在表示更常被建構，並顯示在預訓練期間出現潛在的多重跳躍推理。

##### **CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance**
2411.16666v1 by Jiaan Han, Junxiao Chen, Yanzhe Fu

We introduce CatNet, an algorithm that effectively controls False Discovery
Rate (FDR) and selects significant features in LSTM with the Gaussian Mirror
(GM) method. To evaluate the feature importance of LSTM in time series, we
introduce a vector of the derivative of the SHapley Additive exPlanations
(SHAP) to measure feature importance. We also propose a new kernel-based
dependence measure to avoid multicollinearity in the GM algorithm, to make a
robust feature selection with controlled FDR. We use simulated data to evaluate
CatNet's performance in both linear models and LSTM models with different link
functions. The algorithm effectively controls the FDR while maintaining a high
statistical power in all cases. We also evaluate the algorithm's performance in
different low-dimensional and high-dimensional cases, demonstrating its
robustness in various input dimensions. To evaluate CatNet's performance in
real world applications, we construct a multi-factor investment portfolio to
forecast the prices of S\&P 500 index components. The results demonstrate that
our model achieves superior predictive accuracy compared to traditional LSTM
models without feature selection and FDR control. Additionally, CatNet
effectively captures common market-driving features, which helps informed
decision-making in financial markets by enhancing the interpretability of
predictions. Our study integrates of the Gaussian Mirror algorithm with LSTM
models for the first time, and introduces SHAP values as a new feature
importance metric for FDR control methods, marking a significant advancement in
feature selection and error control for neural networks.

摘要：<paragraph>我們介紹 CatNet，一種有效控制假陽性發現率 (FDR) 的演算法，並使用高斯鏡像 (GM) 方法選取 LSTM 中的重要特徵。為了評估 LSTM 在時間序列中的特徵重要性，我們引入 SHapley 加法解釋 (SHAP) 的導數向量來衡量特徵重要性。我們還提出一個新的基於核心的依賴性測量，以避免 GM 演算法中的多重共線性，以進行具有受控 FDR 的穩健特徵選取。我們使用模擬資料來評估 CatNet 在具有不同連結函數的線性模型和 LSTM 模型中的效能。該演算法在所有情況下都能有效控制 FDR，同時保持高統計功效。我們還評估了該演算法在不同低維度和高維度情況下的效能，證明了其在各種輸入維度中的穩健性。為了評估 CatNet 在實際應用中的效能，我們建構了一個多因子投資組合來預測標普 500 指數成分的價格。結果表明，與沒有特徵選取和 FDR 控制的傳統 LSTM 模型相比，我們的模型實現了卓越的預測準確度。此外，CatNet 有效地擷取了共同的市場驅動特徵，這有助於透過增強預測的可解釋性，在金融市場中做出明智的決策。我們的研究首次將高斯鏡像演算法與 LSTM 模型整合，並將 SHAP 值作為 FDR 控制方法的新特徵重要性指標，標誌著神經網路特徵選取和錯誤控制的重大進展。</paragraph>

##### **DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation**
2411.16657v1 by Zun Wang, Jialu Li, Han Lin, Jaehong Yoon, Mohit Bansal

Storytelling video generation (SVG) has recently emerged as a task to create
long, multi-motion, multi-scene videos that consistently represent the story
described in the input text script. SVG holds great potential for diverse
content creation in media and entertainment; however, it also presents
significant challenges: (1) objects must exhibit a range of fine-grained,
complex motions, (2) multiple objects need to appear consistently across
scenes, and (3) subjects may require multiple motions with seamless transitions
within a single scene. To address these challenges, we propose DreamRunner, a
novel story-to-video generation method: First, we structure the input script
using a large language model (LLM) to facilitate both coarse-grained scene
planning as well as fine-grained object-level layout and motion planning. Next,
DreamRunner presents retrieval-augmented test-time adaptation to capture target
motion priors for objects in each scene, supporting diverse motion
customization based on retrieved videos, thus facilitating the generation of
new videos with complex, scripted motions. Lastly, we propose a novel
spatial-temporal region-based 3D attention and prior injection module SR3AI for
fine-grained object-motion binding and frame-by-frame semantic control. We
compare DreamRunner with various SVG baselines, demonstrating state-of-the-art
performance in character consistency, text alignment, and smooth transitions.
Additionally, DreamRunner exhibits strong fine-grained condition-following
ability in compositional text-to-video generation, significantly outperforming
baselines on T2V-ComBench. Finally, we validate DreamRunner's robust ability to
generate multi-object interactions with qualitative examples.

摘要：故事敘述影片生成 (SVG) 最近成為了產生長篇、多動作、多場景影片的任務，這些影片能持續呈現輸入文字腳本中所描述的故事。SVG 在媒體和娛樂中擁有廣泛的內容創造潛力；然而，它也帶來了重大的挑戰：(1) 物件必須展現一系列細緻、複雜的動作，(2) 多個物件需要在場景中持續出現，(3) 主題可能需要在單一場景中進行多個動作，並進行無縫轉換。為了應對這些挑戰，我們提出了 DreamRunner，一種新穎的故事到影片生成方法：首先，我們使用大型語言模型 (LLM) 來建構輸入腳本，以促進粗略的場景規劃以及細緻的物件級別佈局和動作規劃。接下來，DreamRunner 提出檢索增強的測試時間適應，以擷取每個場景中物件的目標動作先驗，支援基於檢索影片的多樣化動作自訂，從而促進產生具有複雜、腳本動作的新影片。最後，我們提出了一個新穎的基於時空區域的 3D 注意力和先驗注入模組 SR3AI，用於細緻的物件動作繫結和逐幀語義控制。我們將 DreamRunner 與各種 SVG 基準進行比較，證明了其在角色一致性、文字對齊和流暢過渡方面的最先進效能。此外，DreamRunner 在組合式文字到影片生成中展現出強大的細緻條件遵循能力，在 T2V-ComBench 上明顯優於基準。最後，我們驗證了 DreamRunner 產生多物件互動的強大能力，並提供了定性範例。

##### **Self-Generated Critiques Boost Reward Modeling for Language Models**
2411.16646v1 by Yue Yu, Zhengxing Chen, Aston Zhang, Liang Tan, Chenguang Zhu, Richard Yuanzhe Pang, Yundi Qian, Xuewei Wang, Suchin Gururangan, Chao Zhang, Melanie Kambadur, Dhruv Mahajan, Rui Hou

Reward modeling is crucial for aligning large language models (LLMs) with
human preferences, especially in reinforcement learning from human feedback
(RLHF). However, current reward models mainly produce scalar scores and
struggle to incorporate critiques in a natural language format. We hypothesize
that predicting both critiques and the scalar reward would improve reward
modeling ability. Motivated by this, we propose Critic-RM, a framework that
improves reward models using self-generated critiques without extra
supervision. Critic-RM employs a two-stage process: generating and filtering
high-quality critiques, followed by joint fine-tuning on reward prediction and
critique generation. Experiments across benchmarks show that Critic-RM improves
reward modeling accuracy by 3.7%-7.3% compared to standard reward models and
LLM judges, demonstrating strong performance and data efficiency. Additional
studies further validate the effectiveness of generated critiques in rectifying
flawed reasoning steps with 2.5%-3.2% gains in improving reasoning accuracy.

摘要：獎勵建模對於將大型語言模型 (LLM) 與人類偏好保持一致至關重要，特別是在人類回饋的強化學習 (RLHF) 中。然而，目前的獎勵模型主要產生標量分數，並且難以以自然語言格式納入批評。我們假設預測批評和標量獎勵都會提高獎勵建模能力。基於此，我們提出了 Critic-RM，這是一個利用自我生成的批評來改進獎勵模型的框架，而無需額外的監督。Critic-RM 採用兩階段流程：生成和過濾高品質的批評，然後在獎勵預測和批評生成上進行聯合微調。基準測試的實驗表明，與標準獎勵模型和 LLM 評審相比，Critic-RM 將獎勵建模準確度提高了 3.7%-7.3%，展示了強大的性能和數據效率。進一步的研究進一步驗證了生成的批評在糾正有缺陷的推理步驟中的有效性，推理準確度提高了 2.5%-3.2%。

##### **Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters**
2411.16645v1 by Dietmar Jannach, Alan Said, Marko Tkalčič, Markus Zanker

In the area of recommender systems, the vast majority of research efforts is
spent on developing increasingly sophisticated recommendation models, also
using increasingly more computational resources. Unfortunately, most of these
research efforts target a very small set of application domains, mostly
e-commerce and media recommendation. Furthermore, many of these models are
never evaluated with users, let alone put into practice. The scientific,
economic and societal value of much of these efforts by scholars therefore
remains largely unclear. To achieve a stronger positive impact resulting from
these efforts, we posit that we as a research community should more often
address use cases where recommender systems contribute to societal good
(RS4Good). In this opinion piece, we first discuss a number of examples where
the use of recommender systems for problems of societal concern has been
successfully explored in the literature. We then proceed by outlining a
paradigmatic shift that is needed to conduct successful RS4Good research, where
the key ingredients are interdisciplinary collaborations and longitudinal
evaluation approaches with humans in the loop.

摘要：在推薦系統領域，絕大多數的研究工作都花在開發日益精密的推薦模型，同時也使用越來越多運算資源。不幸的是，這些研究工作大多針對非常小的一組應用領域，主要是電子商務和媒體推薦。此外，這些模型中的許多模型從未經過使用者評估，更不用說付諸實踐了。因此，學者們在這些工作上的科學、經濟和社會價值在很大程度上仍不清楚。為了讓這些工作產生更強大的正面影響，我們認為我們作為一個研究社群應該更常解決推薦系統對社會有益的用例（RS4Good）。在這篇意見文章中，我們首先討論了一些範例，其中在文獻中已成功探索了將推薦系統用於社會關注的問題。然後，我們接著概述進行成功的 RS4Good 研究所需的典範轉移，其中關鍵要素是跨領域合作和人類參與的縱向評估方法。

##### **Preventing Jailbreak Prompts as Malicious Tools for Cybercriminals: A Cyber Defense Perspective**
2411.16642v1 by Jean Marie Tshimula, Xavier Ndona, D'Jeff K. Nkashama, Pierre-Martin Tardif, Froduald Kabanza, Marc Frappier, Shengrui Wang

Jailbreak prompts pose a significant threat in AI and cybersecurity, as they
are crafted to bypass ethical safeguards in large language models, potentially
enabling misuse by cybercriminals. This paper analyzes jailbreak prompts from a
cyber defense perspective, exploring techniques like prompt injection and
context manipulation that allow harmful content generation, content filter
evasion, and sensitive information extraction. We assess the impact of
successful jailbreaks, from misinformation and automated social engineering to
hazardous content creation, including bioweapons and explosives. To address
these threats, we propose strategies involving advanced prompt analysis,
dynamic safety protocols, and continuous model fine-tuning to strengthen AI
resilience. Additionally, we highlight the need for collaboration among AI
researchers, cybersecurity experts, and policymakers to set standards for
protecting AI systems. Through case studies, we illustrate these cyber defense
approaches, promoting responsible AI practices to maintain system integrity and
public trust. \textbf{\color{red}Warning: This paper contains content which the
reader may find offensive.}

摘要：越獄提示在 AI 和網路安全領域中構成重大威脅，因為它們被設計成繞過大型語言模型中的道德防護措施，這可能會讓網路犯罪分子得以濫用。本文從網路防禦角度分析越獄提示，探討提示注入和內容操縱等技術，這些技術允許產生有害內容、規避內容過濾器和提取敏感資訊。我們評估成功越獄的影響，從錯誤資訊和自動化社會工程到危險內容的建立，包括生物武器和炸藥。為了應對這些威脅，我們提出涉及進階提示分析、動態安全協定和持續模型微調的策略，以強化 AI 的韌性。此外，我們強調 AI 研究人員、網路安全專家和政策制定者之間需要合作，以制定保護 AI 系統的標準。透過案例研究，我們說明這些網路防禦方法，推廣負責任的 AI 實務，以維護系統完整性和公眾信任。\textbf{\color{red}警告：本文包含讀者可能覺得令人反感的內容。}

##### **Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation**
2411.16638v1 by Sanjana Ramprasad, Byron C. Wallace

Modern LLMs can now produce highly readable abstractive summaries, to the
point where traditional automated metrics for evaluating summary quality, such
as ROUGE, have become saturated. However, LLMs still sometimes introduce
unwanted content into summaries, i.e., information inconsistent with or
unsupported by their source. Measuring the occurrence of these often subtle
``hallucinations'' automatically has proved to be challenging. This in turn has
motivated development of a variety of metrics intended to measure the factual
consistency of generated summaries against their source. But are these
approaches measuring what they purport to do? In this work, we stress-test
automatic factuality metrics. Specifically, we investigate whether and to what
degree superficial attributes of summary texts suffice to predict
``factuality'', finding that a (supervised) model using only such shallow
features is reasonably competitive with SOTA factuality scoring methods. We
then evaluate how factuality metrics respond to factual corrections in
inconsistent summaries and find that only a few show meaningful improvements.
In contrast, some metrics are more sensitive to benign, non-factual edits.
Motivated by these insights, we show that one can ``game'' (most) automatic
factuality metrics, i.e., reliably inflate ``factuality'' scores by appending
innocuous sentences to generated summaries.Taken together, our results raise
questions about the degree to which we should rely on existing automated
factuality metrics and what exactly we want ``factuality metrics'' to measure.

摘要：現代的 LLM 現在可以產生高度可讀的抽象摘要，以至於用於評估摘要品質的傳統自動化指標，例如 ROUGE，已變得飽和。然而，LLM 有時仍會在摘要中引入不需要的內容，即與其來源不一致或不受其來源支持的資訊。衡量這些通常很微妙的「幻覺」的發生情況已證明具有挑戰性。這反過來又促使開發各種指標，旨在衡量產生的摘要與其來源的事實一致性。但這些方法是否衡量了它們聲稱要做的？在這項工作中，我們對自動事實性指標進行壓力測試。具體來說，我們調查摘要文字的表面屬性是否足以預測「事實性」，並發現僅使用此類淺層特徵的（監督）模型與 SOTA 事實性評分方法相當有競爭力。然後，我們評估事實性指標如何對不一致摘要中的事實更正做出反應，並發現只有少數顯示出有意義的改進。相反，一些指標對良性的非事實編輯更敏感。受到這些見解的啟發，我們表明人們可以「玩」大多數自動事實性指標，即透過在產生的摘要中附加無害的句子來可靠地提高「事實性」分數。綜合起來，我們的結果引發了關於我們應在多大程度上依賴現有的自動事實性指標以及我們確切希望「事實性指標」衡量什麼的問題。

##### **Imperceptible Adversarial Examples in the Physical World**
2411.16622v1 by Weilin Xu, Sebastian Szyller, Cory Cornelius, Luis Murillo Rojas, Marius Arvinte, Alvaro Velasquez, Jason Martin, Nageen Himayat

Adversarial examples in the digital domain against deep learning-based
computer vision models allow for perturbations that are imperceptible to human
eyes. However, producing similar adversarial examples in the physical world has
been difficult due to the non-differentiable image distortion functions in
visual sensing systems. The existing algorithms for generating physically
realizable adversarial examples often loosen their definition of adversarial
examples by allowing unbounded perturbations, resulting in obvious or even
strange visual patterns. In this work, we make adversarial examples
imperceptible in the physical world using a straight-through estimator (STE,
a.k.a. BPDA). We employ STE to overcome the non-differentiability -- applying
exact, non-differentiable distortions in the forward pass of the
backpropagation step, and using the identity function in the backward pass. Our
differentiable rendering extension to STE also enables imperceptible
adversarial patches in the physical world. Using printout photos, and
experiments in the CARLA simulator, we show that STE enables fast generation of
$\ell_\infty$ bounded adversarial examples despite the non-differentiable
distortions. To the best of our knowledge, this is the first work demonstrating
imperceptible adversarial examples bounded by small $\ell_\infty$ norms in the
physical world that force zero classification accuracy in the global
perturbation threat model and cause near-zero ($4.22\%$) AP50 in object
detection in the patch perturbation threat model. We urge the community to
re-evaluate the threat of adversarial examples in the physical world.

摘要：<paragraph>針對基於深度學習的電腦視覺模型的數位領域對抗範例允許人眼無法察覺的擾動。然而，由於視覺感測系統中不可微分的影像失真函數，在物理世界中產生類似的對抗範例一直很困難。現有的演算法用於產生物理上可實現的對抗範例，通常透過允許無界的擾動來放寬對抗範例的定義，導致明顯甚至奇怪的視覺模式。在這項工作中，我們使用直通估計器 (STE，又稱 BPDA) 在物理世界中製作無法察覺的對抗範例。我們採用 STE 來克服不可微分性，在反向傳播步驟的前向傳遞中應用精確的不可微分失真，並在反向傳遞中使用恆等函數。我們對 STE 的可微分渲染延伸也讓物理世界中的對抗性貼片無法察覺。透過列印照片，以及在 CARLA 模擬器中的實驗，我們展示了 STE 能夠快速產生 $\ell_\infty$ 有界對抗範例，儘管有不可微分的失真。據我們所知，這是第一個在物理世界中展示由小 $\ell_\infty$ 規格限制的無法察覺對抗範例的工作，在全域擾動威脅模型中強制零分類準確度，並在貼片擾動威脅模型中導致接近零 ($4.22\%$) 的 AP50 物件偵測。我們敦促社群重新評估物理世界中對抗範例的威脅。</paragraph>

##### **StructFormer: Document Structure-based Masked Attention and its Impact on Language Model Pre-Training**
2411.16618v1 by Kaustubh Ponkshe, Venkatapathy Subramanian, Natwar Modani, Ganesh Ramakrishnan

Most state-of-the-art techniques for Language Models (LMs) today rely on
transformer-based architectures and their ubiquitous attention mechanism.
However, the exponential growth in computational requirements with longer input
sequences confines Transformers to handling short passages. Recent efforts have
aimed to address this limitation by introducing selective attention mechanisms,
notably local and global attention. While sparse attention mechanisms, akin to
full attention in being Turing-complete, have been theoretically established,
their practical impact on pre-training remains unexplored. This study focuses
on empirically assessing the influence of global attention on BERT
pre-training. The primary steps involve creating an extensive corpus of
structure-aware text through arXiv data, alongside a text-only counterpart. We
carry out pre-training on these two datasets, investigate shifts in attention
patterns, and assess their implications for downstream tasks. Our analysis
underscores the significance of incorporating document structure into LM
models, demonstrating their capacity to excel in more abstract tasks, such as
document understanding.

摘要：現今多數語言模型 (LM) 的最先進技術仰賴於基於轉換器的架構及其普遍的注意力機制。
然而，隨著輸入序列變長，運算需求呈指數成長，將轉換器限制在處理短篇章節。最近的努力旨在透過引入選擇性注意力機制來解決此限制，特別是局部和全局注意力。雖然稀疏注意力機制類似於在圖靈完備性中的完整注意力，已在理論上建立，但其對預訓練的實際影響仍未探討。本研究專注於經驗評估全局注意力對 BERT 預訓練的影響。主要步驟包括透過 arXiv 資料建立廣泛的結構感知文字語料庫，以及純文字對應版本。我們對這兩個資料集進行預訓練，探討注意力模式的轉變，並評估其對下游任務的影響。我們的分析強調將文件結構納入 LM 模型的重要性，證明其在更抽象任務（例如文件理解）中表現優異的能力。

##### **Recent Trends in Linear Text Segmentation: a Survey**
2411.16613v1 by Iacopo Ghinassi, Lin Wang, Chris Newell, Matthew Purver

Linear Text Segmentation is the task of automatically tagging text documents
with topic shifts, i.e. the places in the text where the topics change. A
well-established area of research in Natural Language Processing, drawing from
well-understood concepts in linguistic and computational linguistic research,
the field has recently seen a lot of interest as a result of the surge of text,
video, and audio available on the web, which in turn require ways of
summarising and categorizing the mole of content for which linear text
segmentation is a fundamental step. In this survey, we provide an extensive
overview of current advances in linear text segmentation, describing the state
of the art in terms of resources and approaches for the task. Finally, we
highlight the limitations of available resources and of the task itself, while
indicating ways forward based on the most recent literature and under-explored
research directions.

摘要：線性文本分段是自動標記文本文件
主題轉換，即文本中主題變更的地方。自然語言處理中一個建立良好的研究領域，汲取
語言學和計算語言學研究中理解良好的概念，該領域最近因網路上大量湧現的文字、
影片和音訊而備受關注，而這些內容需要總結和分類，而線性文本分段正是基本步驟。在這項調查中，我們提供線性文本分段當前進展的廣泛概述，說明任務在資源和方法方面的最新進展。最後，我們強調可用資源和任務本身的限制，同時根據最新文獻和尚未探索的研究方向指出前進的方向。

##### **F -- A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite**
2411.16609v1 by Ansgar Scherp, Thomas Franz, Carsten Saathoff, Steffen Staab

The lack of a formal model of events hinders interoperability in distributed
event-based systems. In this paper, we present a formal model of events, called
Event-Model-F. The model is based on the foundational ontology DOLCE+DnS
Ultralite (DUL) and provides comprehensive support to represent time and space,
objects and persons, as well as mereological, causal, and correlative
relationships between events. In addition, the Event-Model-F provides a
flexible means for event composition, modeling event causality and event
correlation, and representing different interpretations of the same event. The
Event-Model-F is developed following the pattern-oriented approach of DUL, is
modularized in different ontologies, and can be easily extended by domain
specific ontologies.

摘要：缺乏正式的事件模型會阻礙分散式事件基礎系統中的互操作性。在本文中，我們提出了事件的正式模型，稱為事件模型 F。該模型基於基礎本体 DOLCE+DnS Ultralite (DUL)，並提供全面的支援來表示時間和空間、物件和人物，以及事件之間的唯象學、因果和相關關係。此外，事件模型 F 提供了一種靈活的方法來進行事件組合、建模事件因果關係和事件相關性，以及表示同一個事件的不同解釋。事件模型 F 是遵循 DUL 的模式導向方法開發的，在不同的本体中模組化，並且可以透過特定於領域的本体輕鬆延伸。

##### **From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge**
2411.16594v1 by Dawei Li, Bohan Jiang, Liangjie Huang, Alimohammad Beigi, Chengshuai Zhao, Zhen Tan, Amrita Bhattacharjee, Yuxuan Jiang, Canyu Chen, Tianhao Wu, Kai Shu, Lu Cheng, Huan Liu

Assessment and evaluation have long been critical challenges in artificial
intelligence (AI) and natural language processing (NLP). However, traditional
methods, whether matching-based or embedding-based, often fall short of judging
subtle attributes and delivering satisfactory results. Recent advancements in
Large Language Models (LLMs) inspire the "LLM-as-a-judge" paradigm, where LLMs
are leveraged to perform scoring, ranking, or selection across various tasks
and applications. This paper provides a comprehensive survey of LLM-based
judgment and assessment, offering an in-depth overview to advance this emerging
field. We begin by giving detailed definitions from both input and output
perspectives. Then we introduce a comprehensive taxonomy to explore
LLM-as-a-judge from three dimensions: what to judge, how to judge and where to
judge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and
highlight key challenges and promising directions, aiming to provide valuable
insights and inspire future research in this promising research area. Paper
list and more resources about LLM-as-a-judge can be found at
\url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} and
\url{https://llm-as-a-judge.github.io}.

摘要：評估和評量長期以來一直是人工智慧 (AI) 和自然語言處理 (NLP) 中的重大挑戰。然而，傳統方法，無論是基於比對或嵌入式，通常無法判斷細微屬性和提供令人滿意的結果。大型語言模型 (LLM) 的最新進展啟發了「LLM 作為評判者」的範例，其中 LLM 被用於執行各種任務和應用中的評分、排名或選擇。本文提供了基於 LLM 的判斷和評估的全面調查，提供了深入的概述以推進這個新興領域。我們從輸入和輸出觀點給出詳細定義開始。然後，我們介紹一個全面的分類法，從三個面向探討 LLM 作為評判者：判斷什麼、如何判斷和在哪裡判斷。最後，我們編制了評估 LLM 作為評判者的基準，並重點介紹關鍵挑戰和有希望的方向，旨在提供有價值的見解並激勵這個有希望的研究領域的未來研究。LLM 作為評判者的論文清單和更多資源可以在 \url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} 和 \url{https://llm-as-a-judge.github.io} 找到。

##### **Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision**
2411.16579v1 by Zhiheng Xi, Dingwen Yang, Jixuan Huang, Jiafu Tang, Guanyu Li, Yiwen Ding, Wei He, Boyang Hong, Shihan Do, Wenyu Zhan, Xiao Wang, Rui Zheng, Tao Ji, Xiaowei Shi, Yitao Zhai, Rongxiang Weng, Jingang Wang, Xunliang Cai, Tao Gui, Zuxuan Wu, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Yu-Gang Jiang

Training large language models (LLMs) to spend more time thinking and
reflection before responding is crucial for effectively solving complex
reasoning tasks in fields such as science, coding, and mathematics. However,
the effectiveness of mechanisms like self-reflection and self-correction
depends on the model's capacity to accurately assess its own performance, which
can be limited by factors such as initial accuracy, question difficulty, and
the lack of external feedback. In this paper, we delve into a two-player
paradigm that separates the roles of reasoning and critique models, where the
critique model provides step-level feedback to supervise the reasoning (actor)
model during both test-time and train-time. We first propose AutoMathCritique,
an automated and scalable framework for collecting critique data, resulting in
a dataset of $76,321$ responses paired with step-level feedback. Fine-tuning
language models with this dataset enables them to generate natural language
feedback for mathematical reasoning. We demonstrate that the critique models
consistently improve the actor's performance on difficult queries at test-time,
especially when scaling up inference-time computation. Motivated by these
findings, we introduce the critique-based supervision to the actor's
self-training process, and propose a critique-in-the-loop self-improvement
method. Experiments show that the method improves the actor's exploration
efficiency and solution diversity, especially on challenging queries, leading
to a stronger reasoning model. Lastly, we take the preliminary step to explore
training self-talk reasoning models via critique supervision and showcase its
potential. Our code and datasets are at
\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}.

摘要：<paragraph>訓練大型語言模型 (LLM) 在回應前花更多時間思考和反省，對於在科學、程式編寫和數學等領域有效解決複雜推理任務至關重要。然而，自我反省和自我修正等機制的有效性取決於模型準確評估其自身效能的能力，而這可能會受到初始準確度、問題難度和缺乏外部回饋等因素的限制。在本文中，我們深入探討一個將推理和批判模型的角色分開的雙人遊戲範例，其中批判模型提供步驟層級的回饋，以監督推理 (actor) 模型在測試時間和訓練時間。我們首先提出 AutoMathCritique，這是一個用於收集批判資料的自動化且可擴充的架構，產生一個包含 76,321 個與步驟層級回饋配對的回應的資料集。使用這個資料集微調語言模型，使它們能夠為數學推理產生自然語言回饋。我們證明批判模型在測試時間持續改善 actor 在困難查詢上的效能，特別是在擴充推論時間運算時。受到這些發現的啟發，我們將基於批判的監督引入 actor 的自我訓練程序，並提出一個迴圈中的批判自我改善方法。實驗顯示，此方法改善了 actor 在探索效率和解決方案多樣性上的表現，特別是在具有挑戰性的查詢上，進而產生更強大的推理模型。最後，我們採取初步步驟，透過批判監督來探索訓練自我對話推理模型，並展示其潛力。我們的程式碼和資料集位於
\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}。</paragraph>

##### **Naive Algorithmic Collusion: When Do Bandit Learners Cooperate and When Do They Compete?**
2411.16574v1 by Connor Douglas, Foster Provost, Arun Sundararajan

Algorithmic agents are used in a variety of competitive decision settings,
notably in making pricing decisions in contexts that range from online retail
to residential home rentals. Business managers, algorithm designers, legal
scholars, and regulators alike are all starting to consider the ramifications
of "algorithmic collusion." We study the emergent behavior of multi-armed
bandit machine learning algorithms used in situations where agents are
competing, but they have no information about the strategic interaction they
are engaged in. Using a general-form repeated Prisoner's Dilemma game, agents
engage in online learning with no prior model of game structure and no
knowledge of competitors' states or actions (e.g., no observation of competing
prices). We show that these context-free bandits, with no knowledge of
opponents' choices or outcomes, still will consistently learn collusive
behavior - what we call "naive collusion." We primarily study this system
through an analytical model and examine perturbations to the model through
simulations.
  Our findings have several notable implications for regulators. First, calls
to limit algorithms from conditioning on competitors' prices are insufficient
to prevent algorithmic collusion. This is a direct result of collusion arising
even in the naive setting. Second, symmetry in algorithms can increase
collusion potential. This highlights a new, simple mechanism for
"hub-and-spoke" algorithmic collusion. A central distributor need not imbue its
algorithm with supra-competitive tendencies for apparent collusion to arise; it
can simply arise by using certain (common) machine learning algorithms.
Finally, we highlight that collusive outcomes depend starkly on the specific
algorithm being used, and we highlight market and algorithmic conditions under
which it will be unknown a priori whether collusion occurs.

摘要：演算法代理用於各種競爭決策設定中，特別是在從線上零售到住宅出租的各種情境中做出定價決策。企業經理人、演算法設計者、法律學者和監管機構都開始考慮「演算法共謀」的後果。我們研究多臂老虎機機器學習演算法在代理競爭但對他們參與的策略互動毫無所悉的情況下的新興行為。使用一般形式的重複囚犯困境博弈，代理在沒有遊戲結構先驗模型和對競爭者狀態或行動一無所知（例如，沒有觀察到競爭價格）的情況下進行線上學習。我們表明，這些無背景老虎機在不知道對手選擇或結果的情況下，仍然會持續學習共謀行為，我們稱之為「天真共謀」。我們主要透過分析模型研究這個系統，並透過模擬檢查模型的擾動。我們的發現對監管機構有幾個顯著的影響。首先，要求限制演算法以競爭對手的價格為條件不足以防止演算法共謀。這是共謀即使在單純的設定中也會產生的直接結果。其次，演算法中的對稱性會增加共謀的可能性。這突顯了一個新的、簡單的「樞紐輻條」演算法共謀機制。中央經銷商不必讓其演算法具有超競爭的傾向，以致產生明顯的共謀；它可以透過使用某些（常見的）機器學習演算法而產生。最後，我們強調共謀結果明顯取決於所使用的特定演算法，並且我們強調市場和演算法條件，在這些條件下將無法預先得知是否會發生共謀。

##### **EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code**
2411.16561v1 by Shahriyar Zaman Ridoy, Md. Shazzad Hossain Shaon, Alfredo Cuzzocrea, Mst Shapna Akter

Automated detection of software vulnerabilities is critical for enhancing
security, yet existing methods often struggle with the complexity and diversity
of modern codebases. In this paper, we introduce EnStack, a novel ensemble
stacking framework that enhances vulnerability detection using natural language
processing (NLP) techniques. Our approach synergizes multiple pre-trained large
language models (LLMs) specialized in code understanding CodeBERT for semantic
analysis, GraphCodeBERT for structural representation, and UniXcoder for
cross-modal capabilities. By fine-tuning these models on the Draper VDISC
dataset and integrating their outputs through meta-classifiers such as Logistic
Regression, Support Vector Machines (SVM), Random Forest, and XGBoost, EnStack
effectively captures intricate code patterns and vulnerabilities that
individual models may overlook. The meta-classifiers consolidate the strengths
of each LLM, resulting in a comprehensive model that excels in detecting subtle
and complex vulnerabilities across diverse programming contexts. Experimental
results demonstrate that EnStack significantly outperforms existing methods,
achieving notable improvements in accuracy, precision, recall, and F1-score.
This work highlights the potential of ensemble LLM approaches in code analysis
tasks and offers valuable insights into applying NLP techniques for advancing
automated vulnerability detection.

摘要：自動化偵測軟體漏洞對於提升安全性至關重要，但現有方法經常難以應對現代程式碼庫的複雜性和多樣性。在本文中，我們介紹 EnStack，一個新穎的整體堆疊框架，它使用自然語言處理 (NLP) 技術來增強漏洞偵測。我們的做法將多個預先訓練的大型語言模型 (LLM) 協同起來，這些模型專門用於理解程式碼：CodeBERT 用於語意分析、GraphCodeBERT 用於結構表示，而 UniXcoder 則用於跨模態能力。透過微調這些模型在 Draper VDISC 資料集上，並透過後設分類器（例如邏輯迴歸、支援向量機 (SVM)、隨機森林和 XGBoost）整合其輸出，EnStack 有效地擷取了個別模型可能忽略的複雜程式碼模式和漏洞。後設分類器整合了每個 LLM 的優點，產生了一個綜合模型，擅長偵測跨不同程式設計背景的細微而複雜的漏洞。實驗結果證明，EnStack 明顯優於現有方法，在準確度、精確度、召回率和 F1 分數方面都有顯著的提升。這項工作突顯了整體 LLM 方法在程式碼分析任務中的潛力，並提供了寶貴的見解，說明如何應用 NLP 技術來推進自動化漏洞偵測。

##### **Representation Collapsing Problems in Vector Quantization**
2411.16550v1 by Wenhao Zhao, Qiran Zou, Rushi Shah, Dianbo Liu

Vector quantization is a technique in machine learning that discretizes
continuous representations into a set of discrete vectors. It is widely
employed in tokenizing data representations for large language models,
diffusion models, and other generative models. Despite its prevalence, the
characteristics and behaviors of vector quantization in generative models
remain largely underexplored. In this study, we investigate representation
collapse in vector quantization - a critical degradation where codebook tokens
or latent embeddings lose their discriminative power by converging to a limited
subset of values. This collapse fundamentally compromises the model's ability
to capture diverse data patterns. By leveraging both synthetic and real
datasets, we identify the severity of each type of collapses and triggering
conditions. Our analysis reveals that restricted initialization and limited
encoder capacity result in tokens collapse and embeddings collapse. Building on
these findings, we propose potential solutions aimed at mitigating each
collapse. To the best of our knowledge, this is the first comprehensive study
examining representation collapsing problems in vector quantization.

摘要：向量量化是机器学习中将连续表示离散化为一组离散向量的技术。它广泛用于对大语言模型、扩散模型和其他生成模型的数据表示进行标记化。尽管它很普遍，但生成模型中向量量化的特征和行为在很大程度上仍未得到充分探索。在这项研究中，我们调查了向量量化中的表示坍缩——一个关键的退化，其中码本标记或潜在嵌入通过收敛到有限的值子集而失去其判别能力。这种坍缩从根本上损害了模型捕获不同数据模式的能力。通过利用合成和真实数据集，我们确定了每种类型坍缩的严重性和触发条件。我们的分析表明，受限的初始化和有限的编码器容量会导致标记坍缩和嵌入坍缩。基于这些发现，我们提出了旨在减轻每次坍缩的潜在解决方案。据我们所知，这是第一项全面研究向量量化中的表示坍缩问题。

##### **RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics**
2411.16537v1 by Chan Hee Song, Valts Blukis, Jonathan Tremblay, Stephen Tyree, Yu Su, Stan Birchfield

Spatial understanding is a crucial capability for robots to make grounded
decisions based on their environment. This foundational skill enables robots
not only to perceive their surroundings but also to reason about and interact
meaningfully within the world. In modern robotics, these capabilities are taken
on by visual language models, and they face significant challenges when applied
to spatial reasoning context due to their training data sources. These sources
utilize general-purpose image datasets, and they often lack sophisticated
spatial scene understanding capabilities. For example, the datasets do not
address reference frame comprehension - spatial relationships require clear
contextual understanding, whether from an ego-centric, object-centric, or
world-centric perspective, which allow for effective real-world interaction. To
address this issue, we introduce RoboSpatial, a large-scale spatial
understanding dataset consisting of real indoor and tabletop scenes captured as
3D scans and egocentric images, annotated with rich spatial information
relevant to robotics. The dataset includes 1M images, 5K 3D scans, and 3M
annotated spatial relationships, with paired 2D egocentric images and 3D scans
to make it both 2D and 3D ready. Our experiments show that models trained with
RoboSpatial outperform baselines on downstream tasks such as spatial affordance
prediction, spatial relationship prediction, and robotics manipulation.

摘要：空間理解對於機器人根據其環境做出紮實的決策至關重要。這種基本技能不僅使機器人能夠感知周圍環境，還能對世界進行推理並有意義地與之互動。在現代機器人技術中，這些能力由視覺語言模型承擔，由於其訓練數據源，在應用於空間推理情境時面臨嚴峻挑戰。這些來源利用通用圖像數據集，而且通常缺乏複雜的空間場景理解能力。例如，這些數據集不處理參考框架理解——空間關係需要清晰的情境理解，無論是從以自我為中心、以對象為中心還是以世界為中心的視角，這允許進行有效的現實世界互動。為了解決這個問題，我們引入了 RoboSpatial，一個由以 3D 掃描和自我中心圖像形式捕捉的真實室內和桌面場景組成的大規模空間理解數據集，並附有與機器人技術相關的豐富空間信息。該數據集包括 100 萬張圖像、5K 3D 掃描和 300 萬個帶註釋的空間關係，並配對了 2D 自我中心圖像和 3D 掃描，以使其同時具備 2D 和 3D 功能。我們的實驗表明，使用 RoboSpatial 訓練的模型在空間可供性預測、空間關係預測和機器人操作等下游任務上優於基準。

##### **Profiling Bias in LLMs: Stereotype Dimensions in Contextual Word Embeddings**
2411.16527v1 by Carolin M. Schuster, Maria-Alexandra Dinisor, Shashwat Ghatiwala, Georg Groh

Large language models (LLMs) are the foundation of the current successes of
artificial intelligence (AI), however, they are unavoidably biased. To
effectively communicate the risks and encourage mitigation efforts these models
need adequate and intuitive descriptions of their discriminatory properties,
appropriate for all audiences of AI. We suggest bias profiles with respect to
stereotype dimensions based on dictionaries from social psychology research.
Along these dimensions we investigate gender bias in contextual embeddings,
across contexts and layers, and generate stereotype profiles for twelve
different LLMs, demonstrating their intuition and use case for exposing and
visualizing bias.

摘要：大型語言模型 (LLM) 是目前人工智慧 (AI) 成功發展的基礎，然而它們不可避免地有偏見。為了有效地傳達風險並鼓勵採取緩解措施，這些模型需要對其歧視性屬性提供充分且直觀的描述，以適用於所有 AI 受眾。我們建議根據社會心理學研究的字典，針對刻板印象面向提出偏見概況。我們沿著這些面向探討語境嵌入中的性別偏見，跨越語境和層次，並針對 12 個不同的 LLM 產生刻板印象概況，展示其直覺和揭露和視覺化偏見的用例。

##### **Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency**
2411.16525v1 by Jerry Yao-Chieh Hu, Wei-Po Wang, Ammar Gilani, Chenyang Li, Zhao Song, Han Liu

We investigate the statistical and computational limits of prompt tuning for
transformer-based foundation models. Our key contributions are prompt tuning on
\textit{single-head} transformers with only a \textit{single} self-attention
layer: (i) is universal, and (ii) supports efficient (even almost-linear time)
algorithms under the Strong Exponential Time Hypothesis (SETH). Statistically,
we prove that prompt tuning on such simplest possible transformers are
universal approximators for sequence-to-sequence Lipschitz functions. In
addition, we provide an exponential-in-$dL$ and -in-$(1/\epsilon)$ lower bound
on the required soft-prompt tokens for prompt tuning to memorize any dataset
with 1-layer, 1-head transformers. Computationally, we identify a phase
transition in the efficiency of prompt tuning, determined by the norm of the
\textit{soft-prompt-induced} keys and queries, and provide an upper bound
criterion. Beyond this criterion, no sub-quadratic (efficient) algorithm for
prompt tuning exists under SETH. Within this criterion, we showcase our theory
by proving the existence of almost-linear time prompt tuning inference
algorithms. These fundamental limits provide important necessary conditions for
designing expressive and efficient prompt tuning methods for practitioners.

摘要：我們探討了基於Transformer的基礎模型提示調整的統計和計算限制。我們的關鍵貢獻是單頭Transformer上的提示調整，僅有一個單一的自注意力層：(i) 是通用的，並且 (ii) 在強指數時間假設 (SETH) 下支持高效（甚至幾乎線性時間）演算法。在統計上，我們證明了在這樣最簡單的Transformer上進行提示調整是序列到序列 Lipschitz 函數的通用逼近器。此外，我們提供了一個在 $dL$ 和 -in-$(1/\epsilon)$ 中呈指數級的較低邊界，用於提示調整所需的軟提示符號，以記憶具有 1 層、1 頭Transformer的任何資料集。在計算上，我們在提示調整的效率中發現了一個相變，由軟提示誘導的鍵和查詢的範數決定，並提供了一個上限準則。在此準則之外，在 SETH 下不存在任何次二次（高效）的提示調整演算法。在此準則內，我們通過證明幾乎線性時間提示調整推論演算法的存在來展示我們的理論。這些基本限制為實務者設計具有表達力和高效的提示調整方法提供了重要的必要條件。

##### **LaB-RAG: Label Boosted Retrieval Augmented Generation for Radiology Report Generation**
2411.16523v1 by Steven Song, Anirudh Subramanyam, Irene Madejski, Robert L. Grossman

In the current paradigm of image captioning, deep learning models are trained
to generate text from image embeddings of latent features. We challenge the
assumption that these latent features ought to be high-dimensional vectors
which require model fine tuning to handle. Here we propose Label Boosted
Retrieval Augmented Generation (LaB-RAG), a text-based approach to image
captioning that leverages image descriptors in the form of categorical labels
to boost standard retrieval augmented generation (RAG) with pretrained large
language models (LLMs). We study our method in the context of radiology report
generation (RRG), where the task is to generate a clinician's report detailing
their observations from a set of radiological images, such as X-rays. We argue
that simple linear classifiers over extracted image embeddings can effectively
transform X-rays into text-space as radiology-specific labels. In combination
with standard RAG, we show that these derived text labels can be used with
general-domain LLMs to generate radiology reports. Without ever training our
generative language model or image feature encoder models, and without ever
directly "showing" the LLM an X-ray, we demonstrate that LaB-RAG achieves
better results across natural language and radiology language metrics compared
with other retrieval-based RRG methods, while attaining competitive results
compared to other fine-tuned vision-language RRG models. We further present
results of our experiments with various components of LaB-RAG to better
understand our method. Finally, we critique the use of a popular RRG metric,
arguing it is possible to artificially inflate its results without true
data-leakage.

摘要：<paragraph>在當前影像標題的範例中，深度學習模型經過訓練，可從潛在特徵的影像嵌入產生文字。我們挑戰了這些潛在特徵應為高維向量的假設，而這些向量需要模型微調才能處理。在此，我們提出標籤提升檢索擴增生成 (LaB-RAG)，這是一種基於文字的影像標題方法，它利用類別標籤形式的影像描述符來提升標準檢索擴增生成 (RAG) 與預先訓練的大型語言模型 (LLM)。我們在放射科報告生成 (RRG) 的脈絡中研究我們的模型，任務是根據一組放射科影像（例如 X 光）中的觀察結果，產生臨床醫師的報告。我們認為，針對提取的影像嵌入所做的簡單線性分類器可以有效地將 X 光轉換成文字空間，作為放射科專用的標籤。結合標準 RAG，我們證明這些衍生的文字標籤可用於一般領域的 LLM，以產生放射科報告。我們從未訓練過我們的生成式語言模型或影像特徵編碼器模型，也從未直接「展示」LLM X 光，我們證明 LaB-RAG 在自然語言和放射科語言指標上的表現，優於其他基於檢索的 RRG 方法，同時與其他微調的視覺語言 RRG 模型相比，也取得了競爭力的結果。我們進一步展示了使用 LaB-RAG 各種元件的實驗結果，以更了解我們的模型。最後，我們批判了使用一種廣泛使用的 RRG 指標，並主張在沒有真正資料外洩的情況下，就有可能人為地膨脹其結果。</paragraph>

##### **All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages**
2411.16508v1 by Ashmal Vayani, Dinura Dissanayake, Hasindri Watawana, Noor Ahsan, Nevasini Sasikumar, Omkar Thawakar, Henok Biadglign Ademtew, Yahya Hmaiti, Amandeep Kumar, Kartik Kuckreja, Mykola Maslych, Wafa Al Ghallabi, Mihail Mihaylov, Chao Qin, Abdelrahman M Shaker, Mike Zhang, Mahardika Krisna Ihsani, Amiel Esplana, Monil Gokani, Shachar Mirkin, Harsh Singh, Ashay Srivastava, Endre Hamerlik, Fathinah Asma Izzati, Fadillah Adamsyah Maani, Sebastian Cavada, Jenny Chim, Rohit Gupta, Sanjay Manjunath, Kamila Zhumakhanova, Feno Heriniaina Rabevohitra, Azril Amirudin, Muhammad Ridzuan, Daniya Kareem, Ketan More, Kunyang Li, Pramesh Shakya, Muhammad Saad, Amirpouya Ghasemaghaei, Amirbek Djanibekov, Dilshod Azizov, Branislava Jankovic, Naman Bhatia, Alvaro Cabrera, Johan Obando-Ceron, Olympiah Otieno, Fabian Farestam, Muztoba Rabbani, Sanoojan Baliah, Santosh Sanjeev, Abduragim Shtanchaev, Maheen Fatima, Thao Nguyen, Amrin Kareem, Toluwani Aremu, Nathan Xavier, Amit Bhatkal, Hawau Toyin, Aman Chadha, Hisham Cholakkal, Rao Muhammad Anwer, Michael Felsberg, Jorma Laaksonen, Thamar Solorio, Monojit Choudhury, Ivan Laptev, Mubarak Shah, Salman Khan, Fahad Khan

Existing Large Multimodal Models (LMMs) generally focus on only a few regions
and languages. As LMMs continue to improve, it is increasingly important to
ensure they understand cultural contexts, respect local sensitivities, and
support low-resource languages, all while effectively integrating corresponding
visual cues. In pursuit of culturally diverse global multimodal models, our
proposed All Languages Matter Benchmark (ALM-bench) represents the largest and
most comprehensive effort to date for evaluating LMMs across 100 languages.
ALM-bench challenges existing models by testing their ability to understand and
reason about culturally diverse images paired with text in various languages,
including many low-resource languages traditionally underrepresented in LMM
research. The benchmark offers a robust and nuanced evaluation framework
featuring various question formats, including true/false, multiple choice, and
open-ended questions, which are further divided into short and long-answer
categories. ALM-bench design ensures a comprehensive assessment of a model's
ability to handle varied levels of difficulty in visual and linguistic
reasoning. To capture the rich tapestry of global cultures, ALM-bench carefully
curates content from 13 distinct cultural aspects, ranging from traditions and
rituals to famous personalities and celebrations. Through this, ALM-bench not
only provides a rigorous testing ground for state-of-the-art open and
closed-source LMMs but also highlights the importance of cultural and
linguistic inclusivity, encouraging the development of models that can serve
diverse global populations effectively. Our benchmark is publicly available.

摘要：現有的大型多模態模型（LMM）通常只專注於少數區域和語言。隨著 LMM 持續進步，確保它們能理解文化背景、尊重當地敏感性，以及支援低資源語言變得越來越重要，同時還要有效整合對應的視覺提示。為了追求文化多元的全球多模態模型，我們提出的所有語言重要基準（ALM-bench）代表了迄今為止評估 100 種語言的 LMM 的最大規模且最全面的努力。ALM-bench 透過測試 LMM 理解和推理與各種語言（包括傳統上在 LMM 研究中代表性不足的許多低資源語言）配對的文化多元圖像的能力，對現有模型提出挑戰。此基準提供了一個強健且細緻的評估架構，具有各種問題格式，包括是非題、多選題和開放式問題，進一步分為簡答和長答類別。ALM-bench 設計確保全面評估模型在視覺和語言推理中處理不同難度等級的能力。為了捕捉全球文化的豐富樣貌，ALM-bench 精心策劃了來自 13 個不同文化面向的內容，從傳統和儀式到名人與慶典。透過此方式，ALM-bench 不僅為最先進的開放和閉源 LMM 提供了嚴格的測試場域，也突顯了文化和語言包容性的重要性，鼓勵開發能有效服務全球多元人口的模型。我們的基準是公開的。

##### **Interpreting Language Reward Models via Contrastive Explanations**
2411.16502v1 by Junqi Jiang, Tom Bewley, Saumitra Mishra, Freddy Lecue, Manuela Veloso

Reward models (RMs) are a crucial component in the alignment of large
language models' (LLMs) outputs with human values. RMs approximate human
preferences over possible LLM responses to the same prompt by predicting and
comparing reward scores. However, as they are typically modified versions of
LLMs with scalar output heads, RMs are large black boxes whose predictions are
not explainable. More transparent RMs would enable improved trust in the
alignment of LLMs. In this work, we propose to use contrastive explanations to
explain any binary response comparison made by an RM. Specifically, we generate
a diverse set of new comparisons similar to the original one to characterise
the RM's local behaviour. The perturbed responses forming the new comparisons
are generated to explicitly modify manually specified high-level evaluation
attributes, on which analyses of RM behaviour are grounded. In quantitative
experiments, we validate the effectiveness of our method for finding
high-quality contrastive explanations. We then showcase the qualitative
usefulness of our method for investigating global sensitivity of RMs to each
evaluation attribute, and demonstrate how representative examples can be
automatically extracted to explain and compare behaviours of different RMs. We
see our method as a flexible framework for RM explanation, providing a basis
for more interpretable and trustworthy LLM alignment.

摘要：獎勵模型 (RM) 是大型語言模型 (LLM) 輸出與人類價值觀一致性的關鍵組成部分。RM 透過預測和比較獎勵分數來近似人類對相同提示的 LLM 回應的偏好。然而，由於它們通常是具有標量輸出頭的 LLM 的修改版本，因此 RM 是大型黑盒子，其預測無法解釋。更透明的 RM 可以提高對 LLM 一致性的信任。在這項工作中，我們建議使用對比解釋來解釋 RM 做出的任何二元回應比較。具體來說，我們生成一組與原始比較類似的多樣化新比較，以表徵 RM 的局部行為。形成新比較的擾動回應被生成以明確修改手動指定的評估高層級屬性，RM 行為分析以此為基礎。在定量實驗中，我們驗證了我們的方法在尋找高品質對比解釋方面的有效性。然後，我們展示了我們的方法在研究 RM 對每個評估屬性的全局敏感性方面的定性有用性，並展示了如何自動提取代表性範例來解釋和比較不同 RM 的行為。我們將我們的的方法視為 RM 解釋的彈性框架，為更具可解釋性和可信賴性的 LLM 一致性提供基礎。

##### **AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**
2411.16495v1 by Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Li, Shulin Cao, Lei Hou, Juanzi Li

Recent advancements in large language models (LLMs) have led to significant
improvements in various natural language processing tasks, but it is still
challenging for LLMs to perform knowledge-intensive complex question answering
due to LLMs' inefficacy in reasoning planning and the hallucination problem. A
typical solution is to employ retrieval-augmented generation (RAG) coupled with
chain-of-thought (CoT) reasoning, which decomposes complex questions into
chain-like sub-questions and applies iterative RAG at each sub-question.
However, prior works exhibit sub-optimal reasoning planning and overlook
dynamic knowledge retrieval from heterogeneous sources. In this paper, we
propose AtomR, a novel heterogeneous knowledge reasoning framework that
conducts multi-source reasoning at the atomic level. Drawing inspiration from
the graph modeling of knowledge, AtomR leverages large language models (LLMs)
to decompose complex questions into combinations of three atomic knowledge
operators, significantly enhancing the reasoning process at both the planning
and execution stages. We also introduce BlendQA, a novel evaluation benchmark
tailored to assess complex heterogeneous knowledge reasoning. Experiments show
that AtomR significantly outperforms state-of-the-art baselines across three
single-source and two multi-source reasoning benchmarks, with notable
performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.

摘要：大型語言模型 (LLM) 的最新進展已大幅改善各種自然語言處理任務，但由於 LLM 在推理規劃和幻覺問題上的無能，對於 LLM 執行需要知識的複雜問題回答仍然具有挑戰性。典型的解決方案是採用檢索增強生成 (RAG) 搭配思考鏈 (CoT) 推理，將複雜問題分解成鏈狀子問題，並在每個子問題上套用迭代 RAG。然而，先前的工作展現出次佳推理規劃，且忽略了從異質來源動態檢索知識。在本文中，我們提出 AtomR，一個新穎的異質知識推理架構，在原子層級執行多來源推理。從知識的圖形建模中汲取靈感，AtomR 採用大型語言模型 (LLM) 將複雜問題分解成三種原子知識運算子的組合，大幅強化規劃和執行階段的推理程序。我們也引入了 BlendQA，一個新穎的評量基準，專門用來評估複雜的異質知識推理。實驗顯示，AtomR 在三個單一來源和兩個多來源推理基準上大幅優於現有的基線，在 2WikiMultihop 上有 9.4% 的顯著效能提升，在 BlendQA 上則有 9.5%。

##### **O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?**
2411.16489v1 by Zhen Huang, Haoyang Zou, Xuefeng Li, Yixiu Liu, Yuxiang Zheng, Ethan Chern, Shijie Xia, Yiwei Qin, Weizhe Yuan, Pengfei Liu

This paper presents a critical examination of current approaches to
replicating OpenAI's O1 model capabilities, with particular focus on the
widespread but often undisclosed use of knowledge distillation techniques.
While our previous work explored the fundamental technical path to O1
replication, this study reveals how simple distillation from O1's API, combined
with supervised fine-tuning, can achieve superior performance on complex
mathematical reasoning tasks. Through extensive experiments, we show that a
base model fine-tuned on simply tens of thousands of samples O1-distilled
long-thought chains outperforms O1-preview on the American Invitational
Mathematics Examination (AIME) with minimal technical complexity. Moreover, our
investigation extends beyond mathematical reasoning to explore the
generalization capabilities of O1-distilled models across diverse tasks:
hallucination, safety and open-domain QA. Notably, despite training only on
mathematical problem-solving data, our models demonstrated strong
generalization to open-ended QA tasks and became significantly less susceptible
to sycophancy after fine-tuning. We deliberately make this finding public to
promote transparency in AI research and to challenge the current trend of
obscured technical claims in the field. Our work includes: (1) A detailed
technical exposition of the distillation process and its effectiveness, (2) A
comprehensive benchmark framework for evaluating and categorizing O1
replication attempts based on their technical transparency and reproducibility,
(3) A critical discussion of the limitations and potential risks of
over-relying on distillation approaches, our analysis culminates in a crucial
bitter lesson: while the pursuit of more capable AI systems is important, the
development of researchers grounded in first-principles thinking is paramount.

摘要：本論文對複製 OpenAI 的 O1 模型能力的現有方法進行批判性探討，特別關注知識蒸餾技術的廣泛但經常未公開的使用。雖然我們之前的工作探索了 O1 複製的基本技術路徑，但本研究揭示了從 O1 的 API 進行簡單蒸餾，結合監督微調，可以在複雜的數學推理任務上實現卓越的性能。通過大量的實驗，我們表明在僅數萬個樣本上進行微調的基本模型，O1 蒸餾的長期思考鏈在美國邀請賽數學考試 (AIME) 上優於 O1 預覽，且技術複雜性最小。此外，我們的研究不僅限於數學推理，還探索了 O1 蒸餾模型在各種任務中的泛化能力：幻覺、安全性、開放域 QA。值得注意的是，儘管僅根據數學問題解決數據進行訓練，我們的模型在開放式 QA 任務中表現出強大的泛化能力，並且在微調後對阿諛奉承的影響顯著降低。我們故意公開這一發現，以促進人工智能研究的透明度，並挑戰該領域當前技術聲明模糊的趨勢。我們的研究包括：(1) 蒸餾過程及其有效性的詳細技術說明，(2) 用於評估和分類 O1 複製嘗試的綜合基準架構，基於它們的技術透明度和可複製性，(3) 過度依賴蒸餾方法的局限性和潛在風險的批判性討論，我們的分析最終得出一個至關重要的慘痛教訓：雖然追求更強大的 AI 系統很重要，但培養以第一性原理思維為基礎的研究人員至關重要。

##### **When Babies Teach Babies: Can student knowledge sharing outperform Teacher-Guided Distillation on small datasets?**
2411.16487v1 by Srikrishna Iyer

We present our submission to the BabyLM challenge, aiming to push the
boundaries of data-efficient language model pretraining. Our method builds upon
deep mutual learning, introducing a student model search for diverse
initialization. We address the limitation of treating students equally by
formulating weighted mutual learning as a bi-level optimization problem. The
inner loop learns compact students through online distillation, while the outer
loop optimizes weights for better knowledge distillation from diverse students.
This dynamic weighting strategy eliminates the need for a teacher model,
reducing computational requirements. Our evaluations show that teacher-less
methods can match or surpass teacher-supervised approaches.

摘要：我們提交 BabyLM 挑戰，旨在突破資料有效語言模型預訓練的界線。我們的技術建立在深度互學，引入學生模型搜尋以進行多元初始化。我們透過將加權互學表述為雙層最佳化問題，來解決平等對待學生的限制。內層迴圈透過線上萃取學習精簡的學生，而外層迴圈最佳化權重，以從多元學生中進行更好的知識萃取。這種動態加權策略消除了對教師模型的需求，減少了運算需求。我們的評估顯示，無教師方法可以比擬或超越教師監督方法。

##### **Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction**
2411.16457v1 by Haoming Li

In this paper, we present a novel trajectory prediction model for autonomous
driving, combining a Characterized Diffusion Module and a Spatial-Temporal
Interaction Network to address the challenges posed by dynamic and
heterogeneous traffic environments. Our model enhances the accuracy and
reliability of trajectory predictions by incorporating uncertainty estimation
and complex agent interactions. Through extensive experimentation on public
datasets such as NGSIM, HighD, and MoCAD, our model significantly outperforms
existing state-of-the-art methods. We demonstrate its ability to capture the
underlying spatial-temporal dynamics of traffic scenarios and improve
prediction precision, especially in complex environments. The proposed model
showcases strong potential for application in real-world autonomous driving
systems.

摘要：在本文中，我們提出了一個用於自動駕駛的全新軌跡預測模型，結合特徵擴散模組和時空互動網路，以解決動態且異質的交通環境所帶來的挑戰。我們的模型透過納入不確定性估計和複雜的代理互動，增強了軌跡預測的準確性和可靠性。透過在 NGSIM、HighD 和 MoCAD 等公開資料集上進行廣泛的實驗，我們的模型顯著優於現有的最先進方法。我們展示了它捕捉交通場景中基礎時空動態的能力，並提高了預測精度，特別是在複雜的環境中。所提出的模型展示了在現實世界的自動駕駛系統中應用的強大潛力。

##### **Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**
2411.16454v1 by Xiaocong Yang, Jiacheng Lin, Ziqi Wang, Chengxiang Zhai

Large language models (LLMs) are known to struggle with complicated reasoning
tasks such as math word problems (MWPs). In this paper, we present how analogy
from similarly structured questions can improve LLMs' problem-solving
capabilities for MWPs. Specifically, we rely on the retrieval of problems with
similar computational graphs to the given question to serve as exemplars in the
prompt, providing the correct reasoning path for the generation model to refer
to. Empirical results across six math word problem datasets demonstrate the
effectiveness of our proposed method, which achieves a significant improvement
of up to 6.7 percent on average in absolute value, compared to baseline
methods. These results highlight our method's potential in addressing the
reasoning challenges in current LLMs.

摘要：大型語言模型 (LLM) 已知在複雜推理任務（例如數學文字題 (MWP)）中會遇到困難。在本文中，我們展示了來自結構相似的問題的類比如何能改善 LLM 對 MWP 的問題解決能力。具體來說，我們依賴於擷取與給定問題具有類似運算圖形的問題，作為提示中的範例，為生成模型提供正確的推理路徑以供參考。六個數學文字題數據集的實證結果證明了我們提出的方法的有效性，與基線方法相比，平均絕對值提高了 6.7 個百分點。這些結果突出了我們的方法在解決當前 LLM 中的推理挑戰方面的潛力。

##### **TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment**
2411.16442v1 by Luca Colombo, Alessandro Falcetta, Manuel Roveri

Training machine and deep learning models directly on extremely
resource-constrained devices is the next challenge in the field of tiny machine
learning. The related literature in this field is very limited, since most of
the solutions focus only on on-device inference or model adaptation through
online learning, leaving the training to be carried out on external Cloud
services. An interesting technological perspective is to exploit Federated
Learning (FL), which allows multiple devices to collaboratively train a shared
model in a distributed way. However, the main drawback of state-of-the-art FL
algorithms is that they are not suitable for running on tiny devices. For the
first time in the literature, in this paper we introduce TIFeD, a Tiny
Integer-based Federated learning algorithm with Direct Feedback Alignment (DFA)
entirely implemented by using an integer-only arithmetic and being specifically
designed to operate on devices with limited resources in terms of memory,
computation and energy. Besides the traditional full-network operating
modality, in which each device of the FL setting trains the entire neural
network on its own local data, we propose an innovative single-layer TIFeD
implementation, which enables each device to train only a portion of the neural
network model and opens the door to a new way of distributing the learning
procedure across multiple devices. The experimental results show the
feasibility and effectiveness of the proposed solution. The proposed TIFeD
algorithm, with its full-network and single-layer implementations, is made
available to the scientific community as a public repository.

摘要：<paragraph>在極度受限資源的裝置上直接訓練機器和深度學習模型是微型機器學習領域的下一項挑戰。此領域的相關文獻非常有限，因為大多數解決方案僅專注於透過線上學習進行裝置內推論或模型調整，讓訓練在外部雲端服務上執行。一個有趣的技術觀點是利用聯合學習 (FL)，它允許多個裝置以分散的方式協同訓練一個共享模型。然而，目前最先進的 FL 演算法的主要缺點是它們不適合在微型裝置上執行。在本文中，我們首次在文獻中介紹 TIFeD，一種微型整數聯合學習演算法，具有直接回饋對齊 (DFA)，完全透過使用僅整數的算術實作，並專門設計用於在記憶體、運算和能源方面資源有限的裝置上執行。除了傳統的全網路操作模式（在其中 FL 設定的每個裝置都在其自己的本地資料上訓練整個神經網路）之外，我們提出了一個創新的單層 TIFeD 實作，它讓每個裝置僅訓練神經網路模型的一部分，並開啟了一個在多個裝置上分派學習程序的新方法。實驗結果顯示了所提出解決方案的可行性和有效性。所提出的 TIFeD 演算法，連同其全網路和單層實作，已作為公共儲存庫提供給科學社群。</paragraph>

##### **Finding Structure in Language Models**
2411.16433v1 by Jaap Jumelet

When we speak, write or listen, we continuously make predictions based on our
knowledge of a language's grammar. Remarkably, children acquire this
grammatical knowledge within just a few years, enabling them to understand and
generalise to novel constructions that have never been uttered before. Language
models are powerful tools that create representations of language by
incrementally predicting the next word in a sentence, and they have had a
tremendous societal impact in recent years. The central research question of
this thesis is whether these models possess a deep understanding of grammatical
structure similar to that of humans. This question lies at the intersection of
natural language processing, linguistics, and interpretability. To address it,
we will develop novel interpretability techniques that enhance our
understanding of the complex nature of large-scale language models. We approach
our research question from three directions. First, we explore the presence of
abstract linguistic information through structural priming, a key paradigm in
psycholinguistics for uncovering grammatical structure in human language
processing. Next, we examine various linguistic phenomena, such as adjective
order and negative polarity items, and connect a model's comprehension of these
phenomena to the data distribution on which it was trained. Finally, we
introduce a controlled testbed for studying hierarchical structure in language
models using various synthetic languages of increasing complexity and examine
the role of feature interactions in modelling this structure. Our findings
offer a detailed account of the grammatical knowledge embedded in language
model representations and provide several directions for investigating
fundamental linguistic questions using computational methods.

摘要：<paragraph>當我們說話、寫作或聆聽時，我們會持續根據自己對語言文法的知識做出預測。值得注意的是，孩童僅在幾年內便能習得這種文法知識，使他們能夠理解並概括出前所未聞的新建構。語言模型是強大的工具，它透過逐步預測句子中的下一個單字來建立語言表徵，且在近年來對社會產生了巨大的影響。本論文的核心研究問題在於這些模型是否具備與人類相似的文法結構深度理解。此問題位於自然語言處理、語言學和可解釋性之間的交會點。為了探討這個問題，我們將開發新穎的可解釋性技術，以增強我們對大型語言模型複雜本質的理解。我們從三個方向探討我們的研究問題。首先，我們透過結構啟動（一種心理語言學中用於揭示人類語言處理中文法結構的主要範例）來探索抽象語言資訊的存在。接下來，我們檢驗各種語言現象，例如形容詞順序和否定極性項目，並將模型對這些現象的理解與其受訓的資料分佈連結起來。最後，我們引入一個受控測試台，使用各種複雜度遞增的合成語言來研究語言模型中的階層結構，並檢驗特徵互動在建模此結構中的作用。我們的發現提供了語言模型表徵中嵌入的文法知識的詳細說明，並提供了使用計算方法探討基本語言學問題的幾個方向。</paragraph>

##### **TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation**
2411.16425v1 by Linqing Zhong, Chen Gao, Zihan Ding, Yue Liao, Si Liu

The Zero-Shot Object Navigation (ZSON) task requires embodied agents to find
a previously unseen object by navigating in unfamiliar environments. Such a
goal-oriented exploration heavily relies on the ability to perceive,
understand, and reason based on the spatial information of the environment.
However, current LLM-based approaches convert visual observations to language
descriptions and reason in the linguistic space, leading to the loss of spatial
information. In this paper, we introduce TopV-Nav, a MLLM-based method that
directly reasons on the top-view map with complete spatial information. To
fully unlock the MLLM's spatial reasoning potential in top-view perspective, we
propose the Adaptive Visual Prompt Generation (AVPG) method to adaptively
construct semantically-rich top-view map. It enables the agent to directly
utilize spatial information contained in the top-view map to conduct thorough
reasoning. Besides, we design a Dynamic Map Scaling (DMS) mechanism to
dynamically zoom top-view map at preferred scales, enhancing local fine-grained
reasoning. Additionally, we devise a Target-Guided Navigation (TGN) mechanism
to predict and to utilize target locations, facilitating global and human-like
exploration. Experiments on MP3D and HM3D benchmarks demonstrate the
superiority of our TopV-Nav, e.g., $+3.9\%$ SR and $+2.0\%$ SPL absolute
improvements on HM3D.

摘要：零鏡頭物件導航 (ZSON) 任務要求具身代理在不熟悉的環境中導航，以找到先前未見的物件。這種以目標為導向的探索極度依賴感知、理解和基於環境空間資訊進行推理的能力。然而，當前的基於 LLM 的方法會將視覺觀察轉換為語言描述，並在語言空間中進行推理，導致空間資訊遺失。在本篇論文中，我們引入了 TopV-Nav，一種基於 MLLM 的方法，它直接在具有完整空間資訊的俯視圖中進行推理。為了在俯視圖視角中充分發揮 MLLM 的空間推理潛力，我們提出了自適應視覺提示生成 (AVPG) 方法，以自適應地建構語意豐富的俯視圖。它使代理能夠直接利用俯視圖中包含的空間資訊來進行徹底的推理。此外，我們設計了一個動態地圖縮放 (DMS) 機制，以在首選比例尺動態縮放俯視圖，增強局部細粒度的推理。此外，我們設計了一個目標導引導航 (TGN) 機制，以預測和利用目標位置，促進全局和類似人類的探索。在 MP3D 和 HM3D 基準上的實驗證明了我們的 TopV-Nav 的優越性，例如，在 HM3D 上的絕對改進為 $+3.9\%$ SR 和 $+2.0\%$ SPL。

##### **Turbofan Engine Remaining Useful Life (RUL) Prediction Based on Bi-Directional Long Short-Term Memory (BLSTM)**
2411.16422v1 by Abedin Sherifi

The aviation industry is rapidly evolving, driven by advancements in
technology. Turbofan engines used in commercial aerospace are very complex
systems. The majority of turbofan engine components are susceptible to
degradation over the life of their operation. Turbofan engine degradation has
an impact to engine performance, operability, and reliability. Predicting
accurate remaining useful life (RUL) of a commercial turbofan engine based on a
variety of complex sensor data is of paramount importance for the safety of the
passengers, safety of flight, and for cost effective operations. That is why it
is essential for turbofan engines to be monitored, controlled, and maintained.
RUL predictions can either come from model-based or data-based approaches. The
model-based approach can be very expensive due to the complexity of the
mathematical models and the deep expertise that is required in the domain of
physical systems. The data-based approach is more frequently used nowadays
thanks to the high computational complexity of computers, the advancements in
Machine Learning (ML) models, and advancements in sensors. This paper is going
to be focused on Bi-Directional Long Short-Term Memory (BLSTM) models but will
also provide a benchmark of several RUL prediction databased models. The
proposed RUL prediction models are going to be evaluated based on engine
failure prediction benchmark dataset Commercial Modular Aero-Propulsion System
Simulation (CMAPSS). The CMAPSS dataset is from NASA which contains turbofan
engine run to failure events.

摘要：航空產業正快速演進，其驅動力為技術進步。商用航空中使用的渦扇發動機是非常複雜的系統。渦扇發動機組件的大多數在使用壽命期間容易劣化。渦扇發動機劣化會影響發動機效能、可操作性和可靠性。根據各種複雜的感測器資料預測商用渦扇發動機準確的剩餘使用壽命 (RUL)，對於乘客安全、飛航安全和成本效益營運至關重要。這也是渦扇發動機必須受到監控、控制和維護的原因。RUL 預測可以來自基於模型或基於資料的方法。基於模型的方法由於數學模型的複雜性和在物理系統領域所需的深厚專業知識，可能非常昂貴。基於資料的方法由於電腦的高運算複雜性、機器學習 (ML) 模型的進步和感測器的進步，現今使用得更頻繁。本文將重點放在雙向長短期記憶 (BLSTM) 模型，但也會提供多個 RUL 預測資料庫模型的基準測試。所提出的 RUL 預測模型將根據引擎故障預測基準資料集商業模組航空推進系統模擬 (CMAPSS) 進行評估。CMAPSS 資料集來自 NASA，其中包含渦扇發動機運行至故障的事件。

##### **A Study on Unsupervised Domain Adaptation for Semantic Segmentation in the Era of Vision-Language Models**
2411.16407v1 by Manuel Schwonberg, Claus Werner, Hanno Gottschalk, Carsten Meyer

Despite the recent progress in deep learning based computer vision, domain
shifts are still one of the major challenges. Semantic segmentation for
autonomous driving faces a wide range of domain shifts, e.g. caused by changing
weather conditions, new geolocations and the frequent use of synthetic data in
model training. Unsupervised domain adaptation (UDA) methods have emerged which
adapt a model to a new target domain by only using unlabeled data of that
domain. The variety of UDA methods is large but all of them use ImageNet
pre-trained models. Recently, vision-language models have demonstrated strong
generalization capabilities which may facilitate domain adaptation. We show
that simply replacing the encoder of existing UDA methods like DACS by a
vision-language pre-trained encoder can result in significant performance
improvements of up to 10.0% mIoU on the GTA5-to-Cityscapes domain shift. For
the generalization performance to unseen domains, the newly employed
vision-language pre-trained encoder provides a gain of up to 13.7% mIoU across
three unseen datasets. However, we find that not all UDA methods can be easily
paired with the new encoder and that the UDA performance does not always
likewise transfer into generalization performance. Finally, we perform our
experiments on an adverse weather condition domain shift to further verify our
findings on a pure real-to-real domain shift.

摘要：儘管深度學習基礎電腦視覺有近期的進展，領域轉換仍然是主要挑戰之一。
針對自駕車的語意分割面臨廣泛的領域轉換，例如因天氣狀況改變、新的地理位置和模型訓練中頻繁使用合成資料而造成。
無監督領域適應 (UDA) 方法應運而生，透過僅使用該領域的未標籤資料將模型適應到新的目標領域。
UDA 方法種類繁多，但都使用 ImageNet 預先訓練的模型。
近期，視覺語言模型已展現強大的概化能力，這可能有助於領域適應。
我們顯示，僅透過將 DACS 等現有 UDA 方法的編碼器替換為視覺語言預先訓練的編碼器，就能顯著提升效能，在 GTA5 到 Cityscapes 領域轉換中提升達 10.0% mIoU。
對於未見領域的概化效能，新採用的視覺語言預先訓練的編碼器在三個未見資料集上提供了高達 13.7% mIoU 的增益。
然而，我們發現並非所有 UDA 方法都能輕易與新編碼器配對，而且 UDA 效能並非總是同樣轉移到概化效能。
最後，我們在惡劣天氣條件領域轉換上執行實驗，以進一步驗證我們在純粹真實到真實領域轉換上的發現。

##### **Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN**
2411.16405v1 by Elona Shatri, Kalikidhar Palavala, George Fazekas

The generation of handwritten music sheets is a crucial step toward enhancing
Optical Music Recognition (OMR) systems, which rely on large and diverse
datasets for optimal performance. However, handwritten music sheets, often
found in archives, present challenges for digitisation due to their fragility,
varied handwriting styles, and image quality. This paper addresses the data
scarcity problem by applying Generative Adversarial Networks (GANs) to
synthesise realistic handwritten music sheets. We provide a comprehensive
evaluation of three GAN models - DCGAN, ProGAN, and CycleWGAN - comparing their
ability to generate diverse and high-quality handwritten music images. The
proposed CycleWGAN model, which enhances style transfer and training stability,
significantly outperforms DCGAN and ProGAN in both qualitative and quantitative
evaluations. CycleWGAN achieves superior performance, with an FID score of
41.87, an IS of 2.29, and a KID of 0.05, making it a promising solution for
improving OMR systems.

摘要：手寫樂譜的生成是提升光學音樂辨識 (OMR) 系統的關鍵步驟，而 OMR 系統仰賴龐大且多元的資料集才能發揮最佳效能。然而，手寫樂譜通常存放在檔案館中，由於其脆弱性、書寫風格多變，以及影像品質不佳，因此在數位化過程中會面臨挑戰。本文透過應用生成對抗網路 (GAN) 來合成逼真的手寫樂譜，以解決資料稀少的問題。我們提供三種 GAN 模型的全面評估，包括 DCGAN、ProGAN 和 CycleWGAN，並比較它們生成多樣化且高品質手寫樂譜影像的能力。所提出的 CycleWGAN 模型增強了樣式轉移和訓練穩定性，在定性和定量評估中都明顯優於 DCGAN 和 ProGAN。CycleWGAN 達到優異的效能，FID 分數為 41.87，IS 為 2.29，KID 為 0.05，使其成為改善 OMR 系統的潛在解決方案。

##### **Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**
2411.16403v1 by Alexander Fichtl, Juraj Vladika, Georg Groh

Knowledge-enhanced language models (KELMs) have emerged as promising tools to
bridge the gap between large-scale language models and domain-specific
knowledge. KELMs can achieve higher factual accuracy and mitigate
hallucinations by leveraging knowledge graphs (KGs). They are frequently
combined with adapter modules to reduce the computational load and risk of
catastrophic forgetting. In this paper, we conduct a systematic literature
review (SLR) on adapter-based approaches to KELMs. We provide a structured
overview of existing methodologies in the field through quantitative and
qualitative analysis and explore the strengths and potential shortcomings of
individual approaches. We show that general knowledge and domain-specific
approaches have been frequently explored along with various adapter
architectures and downstream tasks. We particularly focused on the popular
biomedical domain, where we provided an insightful performance comparison of
existing KELMs. We outline the main trends and propose promising future
directions.

摘要：知識增強語言模型（KELM）已成為彌合大規模語言模型與特定領域知識差距的有前途的工具。KELM 可以透過利用知識圖譜（KG）來提高事實準確性並減少幻覺。它們經常與適配器模組結合使用，以降低運算負載和災難性遺忘的風險。在本文中，我們對基於適配器的 KELM 方法進行系統性的文獻回顧（SLR）。我們透過定量和定性分析提供該領域既有方法論的結構化概觀，並探討個別方法的優點和潛在缺點。我們表明，一般知識和特定領域的方法已與各種適配器架構和下游任務一起被頻繁探索。我們特別關注熱門的生物醫學領域，在該領域中，我們提供了現有 KELM 的有見地效能比較。我們概述了主要趨勢，並提出了有前途的未來方向。

##### **Human-Calibrated Automated Testing and Validation of Generative Language Models**
2411.16391v1 by Agus Sudjianto, Aijun Zhang, Srinivas Neppalli, Tarun Joshi, Michal Malohlava

This paper introduces a comprehensive framework for the evaluation and
validation of generative language models (GLMs), with a focus on
Retrieval-Augmented Generation (RAG) systems deployed in high-stakes domains
such as banking. GLM evaluation is challenging due to open-ended outputs and
subjective quality assessments. Leveraging the structured nature of RAG
systems, where generated responses are grounded in a predefined document
collection, we propose the Human-Calibrated Automated Testing (HCAT) framework.
HCAT integrates a) automated test generation using stratified sampling, b)
embedding-based metrics for explainable assessment of functionality, risk and
safety attributes, and c) a two-stage calibration approach that aligns
machine-generated evaluations with human judgments through probability
calibration and conformal prediction.
  In addition, the framework includes robustness testing to evaluate model
performance against adversarial, out-of-distribution, and varied input
conditions, as well as targeted weakness identification using marginal and
bivariate analysis to pinpoint specific areas for improvement. This
human-calibrated, multi-layered evaluation framework offers a scalable,
transparent, and interpretable approach to GLM assessment, providing a
practical and reliable solution for deploying GLMs in applications where
accuracy, transparency, and regulatory compliance are paramount.

摘要：本文介紹了一個全面的架構，用於評估和驗證生成語言模型 (GLM)，重點在於部署在高風險領域（例如銀行業）的檢索增強生成 (RAG) 系統。由於輸出開放式且品質評估主觀，因此 GLM 評估具有挑戰性。我們利用 RAG 系統的結構化特性，其中生成的回應建立在預先定義的文件集合中，我們提出了人機校準自動化測試 (HCAT) 架構。HCAT 整合了 a) 使用分層抽樣進行自動化測試產生，b) 基於嵌入的指標，用於對功能、風險和安全性屬性進行可解釋的評估，以及 c) 一個兩階段校準方法，該方法透過機率校準和共形預測，將機器產生的評估與人類判斷相符。此外，該架構包括穩健性測試，用於評估模型針對對抗性、分布外和變異輸入條件的效能，以及使用邊際和二變量分析來找出特定改進領域的目標弱點識別。這個人機校準、多層評估架構提供了一個可擴充、透明且可解釋的方法來進行 GLM 評估，為在準確性、透明性和法規遵循至上的應用程式中部署 GLM 提供了一個實用且可靠的解決方案。

##### **FineWeb-zhtw: Scalable Curation of Traditional Chinese Text Data from the Web**
2411.16387v1 by Cheng-Wei Lin, Wan-Hsuan Hsieh, Kai-Xin Guan, Chan-Jan Hsu, Chia-Chen Kuo, Chuan-Lin Lai, Chung-Wei Chung, Ming-Jen Wang, Da-Shan Shiu

The quality and size of a pretraining dataset significantly influence the
performance of large language models (LLMs). While there have been numerous
efforts in the curation of such a dataset for English users, there is a
relative lack of similar initiatives for Traditional Chinese. Building upon
this foundation of FineWeb, we introduce FineWeb-zhtw, a dataset tailored
specifically for Traditional Chinese users. We came up with multiple stages of
meticulously designed filters to cater to the linguistic difference between
English and Traditional Chinese, to ensure comprehensiveness and quality. We
determined effectiveness from querying dataset samples with three main
objectives. Our code and datasets are publicly available.

摘要：預訓練資料集的品質和規模會顯著影響大型語言模型 (LLM) 的效能。雖然已經有許多針對英語使用者的此類資料集策展工作，但針對繁體中文的類似計畫卻相對缺乏。在 FineWeb 的基礎上，我們推出了 FineWeb-zhtw，這是一個專為繁體中文使用者量身打造的資料集。我們提出了多個階段的精細設計過濾器，以應對英語和繁體中文之間的語言差異，以確保資料的全面性和品質。我們透過以三個主要目標查詢資料集樣本來確定其有效性。我們的程式碼和資料集公開提供。

##### **Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**
2411.16380v1 by Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li

Ultrasound imaging is widely used in clinical diagnosis due to its
non-invasive nature and real-time capabilities. However, conventional
ultrasound diagnostics face several limitations, including high dependence on
physician expertise and suboptimal image quality, which complicates
interpretation and increases the likelihood of diagnostic errors. Artificial
intelligence (AI) has emerged as a promising solution to enhance clinical
diagnosis, particularly in detecting abnormalities across various biomedical
imaging modalities. Nonetheless, current AI models for ultrasound imaging face
critical challenges. First, these models often require large volumes of labeled
medical data, raising concerns over patient privacy breaches. Second, most
existing models are task-specific, which restricts their broader clinical
utility. To overcome these challenges, we present UltraFedFM, an innovative
privacy-preserving ultrasound foundation model. UltraFedFM is collaboratively
pre-trained using federated learning across 16 distributed medical institutions
in 9 countries, leveraging a dataset of over 1 million ultrasound images
covering 19 organs and 10 ultrasound modalities. This extensive and diverse
data, combined with a secure training framework, enables UltraFedFM to exhibit
strong generalization and diagnostic capabilities. It achieves an average area
under the receiver operating characteristic curve of 0.927 for disease
diagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.
Notably, UltraFedFM surpasses the diagnostic accuracy of mid-level
ultrasonographers and matches the performance of expert-level sonographers in
the joint diagnosis of 8 common systemic diseases. These findings indicate that
UltraFedFM can significantly enhance clinical diagnostics while safeguarding
patient privacy, marking an advancement in AI-driven ultrasound imaging for
future clinical applications.

摘要：超音波影像因其非侵入性與即時性廣泛應用於臨床診斷。然而，傳統超音波診斷面臨數項限制，包括高度依賴醫師專業知識和次佳影像品質，這使得影像判讀更為複雜，並增加診斷錯誤的可能性。人工智慧 (AI) 已成為增強臨床診斷的潛在解決方案，特別是在偵測各種生物醫學影像模式中的異常。儘管如此，目前用於超音波影像的 AI 模型面臨嚴峻挑戰。首先，這些模型通常需要大量的標籤醫學資料，這引發了對病患隱私遭侵犯的疑慮。其次，現有的大部分模型都是針對特定任務而設計，這限制了它們在更廣泛的臨床應用。為了解決這些挑戰，我們提出了 UltraFedFM，一個創新的隱私保護超音波基礎模型。UltraFedFM 透過 9 個國家/地區的 16 個分散式醫療機構的聯合學習進行協作預訓練，利用包含超過 100 萬張超音波影像的資料集，涵蓋 19 個器官和 10 種超音波模式。這些廣泛且多樣化的資料，結合安全的訓練架構，使 UltraFedFM 能夠展現強大的概化和診斷能力。在疾病診斷方面，其受試者工作特徵曲線下的平均面積達到 0.927，在病灶分割方面，其 Dice 相似係數為 0.878。值得注意的是，UltraFedFM 超越了中階超音波檢查員的診斷準確性，並在 8 種常見全身性疾病的聯合診斷中達到專家級超音波檢查員的水準。這些發現表明，UltraFedFM 可以顯著增強臨床診斷，同時保護病患隱私，這標誌著 AI 驅動超音波影像在未來臨床應用中的一項進步。

##### **A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation**
2411.16370v1 by M. M. A. Valiuddin, R. J. G. van Sloun, C. G. A. Viviers, P. H. N. de With, F. van der Sommen

Advancements in image segmentation play an integral role within the greater
scope of Deep Learning-based computer vision. Furthermore, their widespread
applicability in critical real-world tasks has given rise to challenges related
to the reliability of such algorithms. Hence, uncertainty quantification has
been extensively studied within this context, enabling expression of model
ignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to
prevent uninformed decision making. Due to the rapid adoption of Convolutional
Neural Network (CNN)-based segmentation models in high-stake applications, a
substantial body of research has been published on this very topic, causing its
swift expansion into a distinct field. This work provides a comprehensive
overview of probabilistic segmentation by discussing fundamental concepts in
uncertainty that govern advancements in the field as well as the application to
various tasks. We identify that quantifying aleatoric and epistemic uncertainty
approximates Bayesian inference w.r.t. to either latent variables or model
parameters, respectively. Moreover, literature on both uncertainties trace back
to four key applications; (1) to quantify statistical inconsistencies in the
annotation process due ambiguous images, (2) correlating prediction error with
uncertainty, (3) expanding the model hypothesis space for better
generalization, and (4) active learning. Then, a discussion follows that
includes an overview of utilized datasets for each of the applications and
comparison of the available methods. We also highlight challenges related to
architectures, uncertainty-based active learning, standardization and
benchmarking, and recommendations for future work such as methods based on
single forward passes and models that appropriately leverage volumetric data.

摘要：影像分割的進展在深度學習為基礎的電腦視覺中扮演著不可或缺的角色。此外，它們在關鍵現實世界任務中廣泛的適用性，也帶來了與此類演算法可靠性相關的挑戰。因此，不確定性量化已在這個脈絡中廣泛地研究，讓模型無知（認識不確定性）或資料模糊性（隨機不確定性）得以表達，以防止未經告知的決策制定。由於基於卷積神經網路 (CNN) 的分割模型在高風險應用中快速採用，大量的研究已發表於這個主題上，導致其迅速擴展成一個不同的領域。這項工作透過討論不確定性的基本概念，以及在各種任務中的應用，提供了機率分割的全面概觀，這些概念支配了該領域的進展。我們發現量化隨機和認識不確定性近似於貝氏推論，分別針對潛在變數或模型參數。此外，關於這兩種不確定性的文獻可追溯到四個關鍵應用：(1) 量化標註過程中由於模糊影像而產生的統計不一致性，(2) 將預測誤差與不確定性相關聯，(3) 擴展模型假設空間以獲得更好的概括化，以及 (4) 主動學習。接著，討論包括對每個應用所使用的資料集的概觀，以及可用方法的比較。我們也強調與架構、基於不確定性的主動學習、標準化和基準測試相關的挑戰，以及對未來工作的建議，例如基於單次前向傳遞和適當地利用體積資料的模型。

##### **Multi-modal Retrieval Augmented Multi-modal Generation: A Benchmark, Evaluate Metrics and Strong Baselines**
2411.16365v1 by Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, Heyan Huang, Xian-Ling Mao

This paper investigates an intriguing task of Multi-modal Retrieval Augmented
Multi-modal Generation (M$^2$RAG). This task requires foundation models to
browse multi-modal web pages, with mixed text and images, and generate
multi-modal responses for solving user queries, which exhibits better
information density and readability. Given the early researching stage of
M$^2$RAG task, there is a lack of systematic studies and analysis. To fill this
gap, we construct a benchmark for M$^2$RAG task, equipped with a suite of
text-modal metrics and multi-modal metrics to analyze the capabilities of
existing foundation models. Besides, we also propose several effective methods
for foundation models to accomplish this task, based on the comprehensive
evaluation results on our benchmark. Extensive experimental results reveal
several intriguing phenomena worth further research.

摘要：本文探討了一項引人入勝的多模態檢索增強多模態生成 (M$^2$RAG) 任務。此任務要求基礎模型瀏覽包含文字和圖片的混合多模態網頁，並針對使用者查詢產生多模態回應，以展現更好的資訊密度和可讀性。考量到 M$^2$RAG 任務仍處於早期研究階段，因此缺乏系統性的研究和分析。為了填補此一空白，我們建構了一個 M$^2$RAG 任務基準，並配備一組文字模態指標和多模態指標，以分析現有基礎模型的能力。此外，我們也針對基礎模型提出幾種有效的方法來完成此任務，這些方法是根據我們基準上的綜合評估結果而得。廣泛的實驗結果揭露了幾個值得進一步研究的有趣現象。

##### **Graph Neural Networks-based Parameter Design towards Large-Scale Superconducting Quantum Circuits for Crosstalk Mitigation**
2411.16354v1 by Hao Ai, Yu-xi Liu

To demonstrate supremacy of quantum computing, increasingly large-scale
superconducting quantum computing chips are being designed and fabricated,
sparking the demand for electronic design automation in pursuit of better
efficiency and effectiveness. However, the complexity of simulating quantum
systems poses a significant challenge to computer-aided design of quantum
chips. Harnessing the scalability of graph neural networks (GNNs), we here
propose a parameter designing algorithm for large-scale superconducting quantum
circuits. The algorithm depends on the so-called 'three-stair scaling'
mechanism, which comprises two neural-network models: an evaluator supervisedly
trained on small-scale circuits for applying to medium-scale circuits, and a
designer unsupervisedly trained on medium-scale circuits for applying to
large-scale ones. We demonstrate our algorithm in mitigating quantum crosstalk
errors, which are commonly present and closely related to the graph structures
and parameter assignments of superconducting quantum circuits. Parameters for
both single- and two-qubit gates are considered simultaneously. Numerical
results indicate that the well-trained designer achieves notable advantages not
only in efficiency but also in effectiveness, especially for large-scale
circuits. For example, in superconducting quantum circuits consisting of around
870 qubits, the trained designer requires only 27 seconds to complete the
frequency designing task which necessitates 90 minutes for the traditional
Snake algorithm. More importantly, the crosstalk errors using our algorithm are
only 51% of those produced by the Snake algorithm. Overall, this study
initially demonstrates the advantages of applying graph neural networks to
design parameters in quantum processors, and provides insights for systems
where large-scale numerical simulations are challenging in electronic design
automation.

摘要：<paragraph>為了證明量子運算的優越性，規模越來越大的超導量子運算晶片正被設計和製造，引發了對電子設計自動化的需求，以追求更好的效率和效能。然而，模擬量子系統的複雜性對量子晶片的電腦輔助設計構成重大挑戰。利用圖形神經網路 (GNN) 的可擴充性，我們在此提出一個用於大規模超導量子電路的參數設計演算法。該演算法依賴於所謂的「三階縮放」機制，其中包含兩個神經網路模型：一個監督式訓練於小規模電路並應用於中規模電路的評估器，以及一個無監督式訓練於中規模電路並應用於大規模電路的設計器。我們展示了我們的演算法在減輕量子串擾誤差方面的能力，這些誤差通常存在，並且與超導量子電路的圖形結構和參數分配密切相關。同時考慮了單量子位和雙量子位閘的參數。數值結果表明，訓練有素的設計器不僅在效率方面，而且在效能方面都取得了顯著的優勢，特別是對於大規模電路。例如，在由大約 870 個量子位組成的超導量子電路中，訓練後的設計器只需 27 秒即可完成頻率設計任務，而傳統的 Snake 演算法則需要 90 分鐘。更重要的是，使用我們演算法產生的串擾誤差僅為 Snake 演算法所產生誤差的 51%。總的來說，這項研究最初展示了將圖形神經網路應用於量子處理器設計參數的優點，並為在電子設計自動化中大規模數值模擬具有挑戰性的系統提供了見解。</paragraph>

##### **The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C**
2411.16353v1 by Mikita Balesni, Tomek Korbak, Owain Evans

While LLMs excel at multi-hop questions (e.g. "Who is the spouse of the
performer of Imagine?") when using chain-of-thought reasoning (CoT), they
struggle when forced to reason internally (without CoT). Previous work on the
size and nature of this gap produced mixed evidence with inconclusive results.
In this paper, we introduce a controlled setting for investigating two-hop
reasoning in LLMs, where the above-chance performance constitutes undeniable
evidence for latent reasoning. We fine-tune LLMs (including Llama 3 8B Instruct
and GPT-4o) on fictional facts and confirm that they generalize to answering
two-hop questions about them using CoT. We find that models can perform latent
reasoning when facts appear together during training or in the prompt. However,
to our surprise, models completely fail at two-hop reasoning without CoT when
learned facts only appear in different documents, achieving chance-level
accuracy and chance-level test loss. We call this complete failure to compose
separately learned facts the Two-Hop Curse. Moreover, we evaluate 9 frontier
LLMs on real-world facts, finding that models completely fail at two-hop no-CoT
reasoning for over half of question categories while maintaining partial
success with CoT across most categories. These results suggest that LLMs lack a
general capability for latent multi-hop reasoning independent of the question
type.

摘要：大型語言模型在多跳問題（例如「演唱 Imagine 的表演者的配偶是誰？」）上表現出色，使用思考鏈（CoT）推理時，但當被迫在內部推理（沒有 CoT）時，它們會陷入困境。先前對此差距的大小和性質的研究產生了不同的證據，結果沒有定論。在本文中，我們引入了一個受控設定，用於調查大型語言模型中的兩跳推理，其中高於機會的表現構成潛在推理的無可辯駁的證據。我們微調大型語言模型（包括 Llama 3 8B Instruct 和 GPT-4o）的虛構事實，並確認它們可以概括為使用 CoT 回答有關它們的兩跳問題。我們發現，當事實出現在訓練期間或提示中時，模型可以執行潛在推理。然而，令我們驚訝的是，當學習到的事實僅出現在不同的文件中時，模型在沒有 CoT 的情況下完全無法進行兩跳推理，達到機會水平的準確性和機會水平的測試損失。我們將這種完全無法組合單獨學習的事實稱為兩跳詛咒。此外，我們在現實世界的事實上評估了 9 個前沿大型語言模型，發現模型在超過一半的問題類別中完全無法進行兩跳無 CoT 推理，同時在大多數類別中使用 CoT 保持部分成功。這些結果表明，大型語言模型缺乏獨立於問題類型的潛在多跳推理的一般能力。

##### **Preference Optimization for Reasoning with Pseudo Feedback**
2411.16345v1 by Fangkai Jiao, Geyang Guo, Xingxing Zhang, Nancy F. Chen, Shafiq Joty, Furu Wei

Preference optimization techniques, such as Direct Preference Optimization
(DPO), are frequently employed to enhance the reasoning capabilities of large
language models (LLMs) in domains like mathematical reasoning and coding,
typically following supervised fine-tuning. These methods rely on high-quality
labels for reasoning tasks to generate preference pairs; however, the
availability of reasoning datasets with human-verified labels is limited. In
this study, we introduce a novel approach to generate pseudo feedback for
reasoning tasks by framing the labeling of solutions to reason problems as an
evaluation against associated test cases. We explore two forms of pseudo
feedback based on test cases: one generated by frontier LLMs and the other by
extending self-consistency to multi-test-case. We conduct experiments on both
mathematical reasoning and coding tasks using pseudo feedback for preference
optimization, and observe improvements across both tasks. Specifically, using
Mathstral-7B as our base model, we improve MATH results from 58.3 to 68.6,
surpassing both NuminaMath-72B and GPT-4-Turbo-1106-preview. In GSM8K and
College Math, our scores increase from 85.6 to 90.3 and from 34.3 to 42.3,
respectively. Building on Deepseek-coder-7B-v1.5, we achieve a score of 24.6 on
LiveCodeBench (from 21.1), surpassing Claude-3-Haiku.

摘要：偏好優化技術，例如直接偏好優化 (DPO)，經常被用來增強大型語言模型 (LLM) 在數學推理和編碼等領域的推理能力，通常遵循監督微調。這些方法依賴於推理任務的高品質標籤來產生偏好對；然而，具有人工驗證標籤的推理數據集的可用性是有限的。在這項研究中，我們引入了一種新的方法來產生推理任務的偽回饋，方法是將推理問題的解標記構建為針對關聯測試案例的評估。我們探索了兩種基於測試案例的偽回饋形式：一種由邊緣 LLM 產生，另一種通過將自我一致性擴展到多測試案例。我們對數學推理和編碼任務進行了實驗，使用偽回饋進行偏好優化，並觀察到兩項任務都有改進。具體來說，使用 Mathstral-7B 作為我們的基礎模型，我們將 MATH 結果從 58.3 提高到 68.6，超過了 NuminaMath-72B 和 GPT-4-Turbo-1106-preview。在 GSM8K 和 College Math 中，我們的分數分別從 85.6 增加到 90.3，從 34.3 增加到 42.3。在 Deepseek-coder-7B-v1.5 的基礎上，我們在 LiveCodeBench 上達到了 24.6 的分數（從 21.1），超過了 Claude-3-Haiku。

##### **Can AI grade your essays? A comparative analysis of large language models and teacher ratings in multidimensional essay scoring**
2411.16337v1 by Kathrin Seßler, Maurice Fürstenberg, Babette Bühler, Enkelejda Kasneci

The manual assessment and grading of student writing is a time-consuming yet
critical task for teachers. Recent developments in generative AI, such as large
language models, offer potential solutions to facilitate essay-scoring tasks
for teachers. In our study, we evaluate the performance and reliability of both
open-source and closed-source LLMs in assessing German student essays,
comparing their evaluations to those of 37 teachers across 10 pre-defined
criteria (i.e., plot logic, expression). A corpus of 20 real-world essays from
Year 7 and 8 students was analyzed using five LLMs: GPT-3.5, GPT-4, o1, LLaMA
3-70B, and Mixtral 8x7B, aiming to provide in-depth insights into LLMs' scoring
capabilities. Closed-source GPT models outperform open-source models in both
internal consistency and alignment with human ratings, particularly excelling
in language-related criteria. The novel o1 model outperforms all other LLMs,
achieving Spearman's $r = .74$ with human assessments in the overall score, and
an internal consistency of $ICC=.80$. These findings indicate that LLM-based
assessment can be a useful tool to reduce teacher workload by supporting the
evaluation of essays, especially with regard to language-related criteria.
However, due to their tendency for higher scores, the models require further
refinement to better capture aspects of content quality.

摘要：手動評量與評分學生的寫作是一項耗時但對老師來說至關重要的任務。生成式 AI 的最新發展，例如大型語言模型，提供了潛在的解決方案，以促進教師的論文評分任務。在我們的研究中，我們評估了開源和閉源 LLM 在評量德國學生論文時的表現和可靠性，並將其評分與 37 位老師在 10 個預先定義的標準（例如，情節邏輯、表達）上的評分進行比較。使用五個 LLM 分析了來自 7 年級和 8 年級學生的 20 篇真實世界論文：GPT-3.5、GPT-4、o1、LLaMA 3-70B 和 Mixtral 8x7B，旨在深入了解 LLM 的評分能力。閉源 GPT 模型在內部一致性和與人類評分的吻合度方面都優於開源模型，尤其在與語言相關的標準方面表現出色。新穎的 o1 模型優於所有其他 LLM，在整體評分中實現了 Spearman 的 r = .74 與人類評估，以及 ICC=.80 的內部一致性。這些發現表明，基於 LLM 的評估可以成為一個有用的工具，通過支持論文評估來減少教師的工作量，特別是在與語言相關的標準方面。然而，由於其傾向於獲得更高的分數，這些模型需要進一步改進，以更好地捕捉內容品質的方面。

##### **One Diffusion to Generate Them All**
2411.16318v1 by Duong H. Le, Tuan Pham, Sangho Lee, Christopher Clark, Aniruddha Kembhavi, Stephan Mandt, Ranjay Krishna, Jiasen Lu

We introduce OneDiffusion, a versatile, large-scale diffusion model that
seamlessly supports bidirectional image synthesis and understanding across
diverse tasks. It enables conditional generation from inputs such as text,
depth, pose, layout, and semantic maps, while also handling tasks like image
deblurring, upscaling, and reverse processes such as depth estimation and
segmentation. Additionally, OneDiffusion allows for multi-view generation,
camera pose estimation, and instant personalization using sequential image
inputs. Our model takes a straightforward yet effective approach by treating
all tasks as frame sequences with varying noise scales during training,
allowing any frame to act as a conditioning image at inference time. Our
unified training framework removes the need for specialized architectures,
supports scalable multi-task training, and adapts smoothly to any resolution,
enhancing both generalization and scalability. Experimental results demonstrate
competitive performance across tasks in both generation and prediction such as
text-to-image, multiview generation, ID preservation, depth estimation and
camera pose estimation despite relatively small training dataset. Our code and
checkpoint are freely available at https://github.com/lehduong/OneDiffusion

摘要：<paragraph>我們推出 OneDiffusion，這是一個通用的、大規模的擴散模型，可以無縫地支援雙向影像合成和理解，並且適用於各種任務。它能夠從文字、深度、姿勢、版面和語意圖等輸入進行條件式生成，同時也能處理影像去模糊、升頻和反向處理，例如深度估計和分割。此外，OneDiffusion 還允許多視圖生成、相機姿勢估計和使用順序影像輸入進行即時個人化。我們的模型採用一種簡單但有效的方法，將所有任務視為訓練期間具有不同雜訊比例的幀序列，允許任何幀在推論時間作為條件影像。我們統一的訓練框架消除了對專用架構的需求，支援可擴充的多任務訓練，並能順利適應任何解析度，同時提升泛化性和可擴充性。實驗結果顯示，儘管訓練資料集相對較小，但它在生成和預測任務（例如文字轉影像、多視圖生成、ID 保留、深度估計和相機姿勢估計）中都展現出具有競爭力的效能。我們的程式碼和檢查點可於 https://github.com/lehduong/OneDiffusion 免費取得</paragraph>

##### **CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning**
2411.16313v1 by Duo Wu, Jinghe Wang, Yuan Meng, Yanning Zhang, Le Sun, Zhi Wang

Utilizing large language models (LLMs) for tool planning has emerged as a
promising avenue for developing general AI systems, where LLMs automatically
schedule external tools (e.g. vision models) to tackle complex tasks based on
task descriptions. To push this paradigm toward practical applications, it is
crucial for LLMs to consider tool execution costs (e.g. execution time) for
tool planning. Unfortunately, prior studies overlook the tool execution costs,
leading to the generation of expensive plans of which the costs outweigh task
performance. To fill this gap, we propose the Cost-Aware Tool Planning with
LLMs (CATP-LLM) framework, which for the first time provides a coherent design
to empower LLMs for cost-aware tool planning. Specifically, CATP-LLM
incorporates a tool planning language to enhance the LLM to generate
non-sequential plans of multiple branches for efficient concurrent tool
execution and cost reduction. Moreover, it further designs a cost-aware offline
reinforcement learning algorithm to fine-tune the LLM to optimize the
performance-cost trade-off in tool planning. In lack of public cost-related
datasets, we further present OpenCATP, the first platform for cost-aware
planning evaluation. Experiments on OpenCATP show that CATP-LLM outperforms
GPT-4 even when using Llama2-7B as its backbone, with the average improvement
of 28.2%-30.2% higher plan performance and 24.7%-45.8% lower costs even on the
challenging planning tasks. The codes of CATP-LLM and OpenCATP will be publicly
available.

摘要：利用大型語言模型 (LLM) 進行工具規劃已成為開發通用 AI 系統的一條有前途的途徑，其中 LLM 會根據任務描述自動安排外部工具（例如視覺模型）來處理複雜的任務。為了將此範例推向實務應用，LLM 必須考量工具執行成本（例如執行時間）以進行工具規劃。遺憾的是，先前的研究忽略了工具執行成本，導致產生了成本大於任務效能的昂貴計畫。為了填補此一缺口，我們提出了具備成本意識的 LLM 工具規劃 (CATP-LLM) 架構，該架構首次提供了相干的設計，以賦予 LLM 成本意識的工具規劃能力。具體來說，CATP-LLM 結合了工具規劃語言，以增強 LLM 產生非順序的多分支計畫，以進行有效的並行工具執行和降低成本。此外，它進一步設計了一種具備成本意識的離線強化學習演算法，以微調 LLM，以最佳化工具規劃中的效能成本取捨。由於缺乏公開的成本相關資料集，我們進一步提出了 OpenCATP，這是第一個用於具備成本意識的規劃評估的平台。在 OpenCATP 上的實驗顯示，即使使用 Llama2-7B 作為其主幹，CATP-LLM 仍優於 GPT-4，平均效能提升 28.2%-30.2%，成本降低 24.7%-45.8%，即使在具有挑戰性的規劃任務上也是如此。CATP-LLM 和 OpenCATP 的程式碼將公開提供。

##### **Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems**
2411.16305v1 by Magdalena Kaiser, Patrick Ernst, György Szarvas

Task-oriented Dialog (ToD) systems have to solve multiple subgoals to
accomplish user goals, whereas feedback is often obtained only at the end of
the dialog. In this work, we propose SUIT (SUbgoal-aware ITerative Training),
an iterative training approach for improving ToD systems. We sample dialogs
from the model we aim to improve and determine subgoals that contribute to
dialog success using distant supervision to obtain high quality training
samples. We show how this data improves supervised fine-tuning or,
alternatively, preference learning results. SUIT is able to iteratively
generate more data instead of relying on fixed static sets. SUIT reaches new
state-of-the-art performance on a popular ToD benchmark.

摘要：任務導向對話 (ToD) 系統必須解決多個子目標才能達成使用者目標，而回饋往往只在對話結束時才會獲得。在這項工作中，我們提出 SUIT（子目標感知迭代訓練），一種用於改善 ToD 系統的迭代訓練方法。我們從我們打算改善的模型中抽取對話，並使用遠距監督來確定有助於對話成功的子目標，以取得高品質的訓練範例。我們展示這些資料如何改善監督微調或偏好學習結果。SUIT 能夠迭代產生更多資料，而不是依賴於固定的靜態集合。SUIT 在一個流行的 ToD 基準測試中達到新的最先進效能。

##### **BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment**
2411.16300v1 by Shaolei Zhang, Kehao Zhang, Qingkai Fang, Shoutao Guo, Yan Zhou, Xiaodong Liu, Yang Feng

Large language models (LLMs), with their powerful generative capabilities and
vast knowledge, empower various tasks in everyday life. However, these
abilities are primarily concentrated in high-resource languages, leaving
low-resource languages with weaker generative capabilities and relatively
limited knowledge. Enhancing the multilingual capabilities of LLMs is therefore
crucial for serving over 100 linguistic communities worldwide. An intuitive
approach to enhance the multilingual capabilities would be to construct
instruction data for various languages, but constructing instruction data for
over 100 languages is prohibitively costly. In this paper, we introduce BayLing
2, which efficiently transfers generative capabilities and knowledge from
high-resource languages to low-resource languages through language alignment.
To achieve this, we constructed a dataset of 3.2 million instructions,
comprising high-resource language instructions (Chinese and English) and
cross-lingual instructions for 100+ languages and performed instruction tuning
based on the dataset to facilitate the capability transfer between languages.
Using Llama as the foundation model, we developed BayLing-2-7B, BayLing-2-13B,
and BayLing-3-8B, and conducted a comprehensive evaluation of BayLing. For
multilingual translation across 100+ languages, BayLing shows superior
performance compared to open-source models of similar scale. For multilingual
knowledge and understanding benchmarks, BayLing achieves significant
improvements across over 20 low-resource languages, demonstrating its
capability of effective knowledge transfer from high-resource to low-resource
languages. Furthermore, results on English benchmarks indicate that BayLing
maintains high performance in highresource languages while enhancing the
performance in low-resource languages. Demo, homepage, code and models of
BayLing are available.

摘要：<paragraph>大型語言模型（LLM）具備強大的生成能力和豐富的知識，能賦能日常生活的各種任務。然而，這些能力主要集中在高資源語言，導致低資源語言的生成能力較弱，且知識相對有限。因此，增強 LLM 的多語言能力對於服務全球超過 100 個語言社群至關重要。增強多語言能力的一種直觀方法是為各種語言構建指令數據，但為超過 100 種語言構建指令數據的成本高得令人望而卻步。在本文中，我們介紹了 BayLing 2，它通過語言對齊有效地將生成能力和知識從高資源語言轉移到低資源語言。為此，我們構建了一個包含 320 萬條指令的數據集，包括高資源語言指令（中文和英文）以及 100 多種語言的跨語言指令，並基於該數據集執行指令微調，以促進語言之間的能力轉移。我們使用 Llama 作為基礎模型，開發了 BayLing-2-7B、BayLing-2-13B 和 BayLing-3-8B，並對 BayLing 進行了全面評估。對於跨越 100 多種語言的多語言翻譯，與規模相似的開源模型相比，BayLing 表現出優異的性能。對於多語言知識和理解基準，BayLing 在 20 多種低資源語言中取得了顯著的改進，證明了其從高資源語言到低資源語言有效知識轉移的能力。此外，英語基準的結果表明，BayLing 在增強低資源語言性能的同時，在高資源語言中保持了高性能。BayLing 的演示、主頁、代碼和模型均已推出。</paragraph>

##### **The SVASR System for Text-dependent Speaker Verification (TdSV) AAIC Challenge 2024**
2411.16276v1 by Mohammadreza Molavi, Reza Khodadadi

This paper introduces an efficient and accurate pipeline for text-dependent
speaker verification (TDSV), designed to address the need for high-performance
biometric systems. The proposed system incorporates a Fast-Conformer-based ASR
module to validate speech content, filtering out Target-Wrong (TW) and
Impostor-Wrong (IW) trials. For speaker verification, we propose a feature
fusion approach that combines speaker embeddings extracted from wav2vec-BERT
and ReDimNet models to create a unified speaker representation. This system
achieves competitive results on the TDSV 2024 Challenge test set, with a
normalized min-DCF of 0.0452 (rank 2), highlighting its effectiveness in
balancing accuracy and robustness.

摘要：本文介紹了一個用於文本依賴型說話者驗證 (TDSV) 的高效且準確的管道，旨在滿足高性能生物識別系統的需求。所提出的系統結合了一個基於 Fast-Conformer 的 ASR 模組來驗證語音內容，並過濾掉錯誤的目標 (TW) 和錯誤的冒充者 (IW) 測試。對於說話者驗證，我們提出了一種特徵融合方法，結合了從 wav2vec-BERT 和 ReDimNet 模型中提取的說話者嵌入，以建立統一的說話者表示。此系統在 TDSV 2024 挑戰測試集中取得了具有競爭力的結果，正規化最小 DCF 為 0.0452（排名第 2），突顯了其在平衡準確性和穩健性方面的有效性。

##### **Probing for Consciousness in Machines**
2411.16262v1 by Mathis Immertreu, Achim Schilling, Andreas Maier, Patrick Krauss

This study explores the potential for artificial agents to develop core
consciousness, as proposed by Antonio Damasio's theory of consciousness.
According to Damasio, the emergence of core consciousness relies on the
integration of a self model, informed by representations of emotions and
feelings, and a world model. We hypothesize that an artificial agent, trained
via reinforcement learning (RL) in a virtual environment, can develop
preliminary forms of these models as a byproduct of its primary task. The
agent's main objective is to learn to play a video game and explore the
environment. To evaluate the emergence of world and self models, we employ
probes-feedforward classifiers that use the activations of the trained agent's
neural networks to predict the spatial positions of the agent itself. Our
results demonstrate that the agent can form rudimentary world and self models,
suggesting a pathway toward developing machine consciousness. This research
provides foundational insights into the capabilities of artificial agents in
mirroring aspects of human consciousness, with implications for future
advancements in artificial intelligence.

摘要：本研究探討了人工代理開發核心意識的潛力，正如 Antonio Damasio 的意識理論所提出的。根據 Damasio 的說法，核心意識的出現依賴於自我模型的整合，該模型由情緒和感覺的表徵以及世界模型告知。我們假設，通過在虛擬環境中通過強化學習 (RL) 訓練的人工代理，可以將這些模型的初步形式作為其主要任務的副產品進行開發。代理的主要目標是學習玩視頻遊戲並探索環境。為了評估世界和自我模型的出現，我們採用探針前饋分類器，該分類器使用訓練代理神經網絡的激活來預測代理本身的空間位置。我們的結果表明，代理可以形成基本的自我模型，這表明了開發機器意識的途徑。這項研究為人工代理在反映人類意識方面的能力提供了基礎見解，對人工智能的未來發展具有影響。

##### **Unraveling Arithmetic in Large Language Models: The Role of Algebraic Structures**
2411.16260v1 by Fu-Chieh Chang, Pei-Yuan Wu

Large language models (LLMs) have demonstrated remarkable mathematical
capabilities, largely driven by chain-of-thought (CoT) prompting, which
decomposes complex reasoning into step-by-step solutions. This approach has
enabled significant advancements, as evidenced by performance on benchmarks
like GSM8K and MATH. However, the mechanisms underlying LLMs' ability to
perform arithmetic in a single step of CoT remain poorly understood. Existing
studies debate whether LLMs encode numerical values or rely on symbolic
reasoning, while others explore attention and multi-layered processing in
arithmetic tasks. In this work, we propose that LLMs learn arithmetic by
capturing algebraic structures, such as \emph{Commutativity} and
\emph{Identity} properties. Since these structures are observable through
input-output relationships, they can generalize to unseen data. We empirically
demonstrate that LLMs can learn algebraic structures using a custom dataset of
arithmetic problems. Our findings indicate that leveraging algebraic structures
can enhance the LLMs' arithmetic capabilities, offering insights into improving
their arithmetic performance.

摘要：大型語言模型 (LLM) 已展現出卓越的數學能力，這在很大程度上是由思考鏈 (CoT) 提示驅動的，它將複雜的推理分解為逐步解決方案。這種方法已實現顯著的進步，如 GSM8K 和 MATH 等基準測試的表現所證明。然而，LLM 在 CoT 的單一步驟中執行算術的能力背後機制仍鮮為人知。現有研究爭論 LLM 是否編碼數值或依賴於符號推理，而另一些研究則探討算術任務中的注意力和多層處理。在這項工作中，我們提出 LLM 透過擷取代數結構（例如交換律和恆等性）來學習算術。由於這些結構可透過輸入輸出關係觀察到，因此它們可以推廣到未見的數據。我們透過使用算術問題自訂資料集實證證明 LLM 可以學習代數結構。我們的研究結果表明，利用代數結構可以增強 LLM 的算術能力，並提供見解以改善其算術表現。

##### **NormXLogit: The Head-on-Top Never Lies**
2411.16252v1 by Sina Abbasi, Mohammad Reza Modarres, Mohammad Taher Pilehvar

The Transformer architecture has emerged as the dominant choice for building
large language models (LLMs). However, with new LLMs emerging on a frequent
basis, it is important to consider the potential value of architecture-agnostic
approaches that can provide interpretability across a variety of architectures.
Despite recent successes in the interpretability of LLMs, many existing
approaches rely on complex methods that are often tied to a specific model
design and come with a significant computational cost. To address these
limitations, we propose a novel technique, called NormXLogit, for assessing the
significance of individual input tokens. This method operates based on the
input and output representations associated with each token. First, we
demonstrate that during the pre-training of LLMs, the norms of word embeddings
capture the importance of input tokens. Second, we reveal a significant
relationship between a token's importance and the extent to which its
representation can resemble the model's final prediction. Through extensive
analysis, we show that our approach consistently outperforms existing
gradient-based methods in terms of faithfulness. Additionally, our method
achieves better performance in layer-wise explanations compared to the most
prominent architecture-specific methods.

摘要：Transformer 架構已成為建構大型語言模型 (LLM) 的主流選擇。然而，由於新的 LLM 不斷出現，因此考量與架構無關的方法的潛在價值非常重要，這些方法可以在各種架構中提供可解釋性。儘管 LLM 的可解釋性最近取得成功，但許多現有方法依賴於複雜的方法，這些方法通常與特定模型設計相關，且計算成本很高。為了解決這些限制，我們提出了一種稱為 NormXLogit 的新技術，用於評估個別輸入標記的重要性。此方法根據與每個標記相關的輸入和輸出表示運作。首先，我們證明在 LLM 的預訓練期間，詞嵌入的範數會擷取輸入標記的重要性。其次，我們揭示標記的重要性與其表示在多大程度上類似模型最終預測之間的顯著關係。透過廣泛的分析，我們表明我們的做法在忠實度方面始終優於現有的基於梯度的做法。此外，與最顯著的特定架構方法相比，我們的做法在逐層解釋中獲得更好的效能。

##### **Transparent Neighborhood Approximation for Text Classifier Explanation**
2411.16251v1 by Yi Cai, Arthur Zimek, Eirini Ntoutsi, Gerhard Wunder

Recent literature highlights the critical role of neighborhood construction
in deriving model-agnostic explanations, with a growing trend toward deploying
generative models to improve synthetic instance quality, especially for
explaining text classifiers. These approaches overcome the challenges in
neighborhood construction posed by the unstructured nature of texts, thereby
improving the quality of explanations. However, the deployed generators are
usually implemented via neural networks and lack inherent explainability,
sparking arguments over the transparency of the explanation process itself. To
address this limitation while preserving neighborhood quality, this paper
introduces a probability-based editing method as an alternative to black-box
text generators. This approach generates neighboring texts by implementing
manipulations based on in-text contexts. Substituting the generator-based
construction process with recursive probability-based editing, the resultant
explanation method, XPROB (explainer with probability-based editing), exhibits
competitive performance according to the evaluation conducted on two real-world
datasets. Additionally, XPROB's fully transparent and more controllable
construction process leads to superior stability compared to the
generator-based explainers.

摘要：近期的文獻強調了鄰域建構在推導與模型無關的解釋中所扮演的重要角色，並朝著部署生成模型以改善合成實例品質的方向發展，特別是針對解釋文字分類器。這些方法克服了文字非結構化性質在鄰域建構中產生的挑戰，進而提升了解釋的品質。然而，所部署的生成器通常透過神經網路實作，且缺乏內在的可解釋性，引發了對於解釋過程本身透明度的爭論。為了在維持鄰域品質的同時解決此限制，本文引入了基於機率的編輯方法，作為黑箱文字生成器的替代方案。此方法透過實作基於文字內文脈的操控來產生鄰近文字。透過以遞迴的基於機率的編輯取代基於生成器的建構過程，所產生的解釋方法 XPROB（基於機率編輯的解釋器）在針對兩個真實世界資料集進行的評估中展現了具有競爭力的效能。此外，與基於生成器的解釋器相比，XPROB 完全透明且更可控的建構過程，帶來了優異的穩定性。

##### **DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence Embeddings**
2411.16236v1 by Hong Liu, Yitong Lu

This paper presents a novel method to improve the robustness of foundation
models to group-based biases. We propose a simple yet effective method, called
DoubleCCA, that leverages random sentences and Canonical Correlation Analysis
(CCA) to enrich the text embeddings of the foundation model. First, we generate
various random sentences that augment the original prompts, which extends the
original prompts with random words or character sequences. Second, we use an
additional sentence embedding model to generate different text embeddings with
respect to these random sentences. We then use CCA double twice to align the
representations and reconstruct them back to the original representation space.
We demonstrate the effectiveness of our method on a variety of tasks and
datasets, showing that it outperforms existing methods in terms of both
performance and robustness. Our method is simple to implement and can be easily
integrated into existing models, making it a practical solution for improving
the robustness of foundation models to group-based biases.

摘要：本文提出了一種新的方法，以提高基礎模型對群體偏見的穩健性。我們提出了一種簡單但有效的方法，稱為 DoubleCCA，它利用隨機句子和典型相關分析 (CCA) 來豐富基礎模型的文字嵌入。首先，我們生成各種隨機句子來擴充原始提示，其中用隨機字詞或字元序列來延伸原始提示。其次，我們使用一個額外的句子嵌入模型，針對這些隨機句子生成不同的文字嵌入。接著，我們使用 CCA 兩次來比對這些表徵，並將它們重建回原始表徵空間。我們在各種任務和資料集上展示了我們的方法的有效性，結果顯示，它在效能和穩健性方面都優於現有方法。我們的方法易於實作，且可以輕鬆整合到現有模型中，使其成為一種實用的解決方案，用於提高基礎模型對群體偏見的穩健性。

##### **MH-MoE:Multi-Head Mixture-of-Experts**
2411.16205v1 by Shaohan Huang, Xun Wu, Shuming Ma, Furu Wei

Multi-Head Mixture-of-Experts (MH-MoE) demonstrates superior performance by
using the multi-head mechanism to collectively attend to information from
various representation spaces within different experts. In this paper, we
present a novel implementation of MH-MoE that maintains both FLOPs and
parameter parity with sparse Mixture of Experts models. Experimental results on
language models show that the new implementation yields quality improvements
over both vanilla MoE and fine-grained MoE models. Additionally, our
experiments demonstrate that MH-MoE is compatible with 1-bit Large Language
Models (LLMs) such as BitNet.

摘要：多頭專家混合（MH-MoE）透過使用多頭機制來共同關注來自不同專家內部各種表示空間的資訊，展示出優越的效能。在本文中，我們提出了一種 MH-MoE 的新穎實作，它同時維持了稀疏專家混合模型的 FLOP 和參數平價。語言模型的實驗結果顯示，新的實作在傳統 MoE 和細粒度 MoE 模型上都產生了品質的提升。此外，我們的實驗證明 MH-MoE 與 1 位元的大型語言模型（LLM），例如 BitNet 相容。

##### **Video-Text Dataset Construction from Multi-AI Feedback: Promoting Weak-to-Strong Preference Learning for Video Large Language Models**
2411.16201v1 by Hao Yi, Qingyang Li, Yulan Hu, Fuzheng Zhang, Di Zhang, Yong Liu

High-quality video-text preference data is crucial for Multimodal Large
Language Models (MLLMs) alignment. However, existing preference data is very
scarce. Obtaining VQA preference data for preference training is costly, and
manually annotating responses is highly unreliable, which could result in
low-quality pairs. Meanwhile, AI-generated responses controlled by temperature
adjustment lack diversity. To address these issues, we propose a high-quality
VQA preference dataset, called \textit{\textbf{M}ultiple \textbf{M}ultimodal
\textbf{A}rtificial \textbf{I}ntelligence \textbf{P}reference Datasets in
\textbf{V}QA} (\textbf{MMAIP-V}), which is constructed by sampling from the
response distribution set and using an external scoring function for response
evaluation. Furthermore, to fully leverage the preference knowledge in MMAIP-V
and ensure sufficient optimization, we propose \textit{\textbf{Iter}ative
\textbf{W}eak-to-\textbf{S}trong \textbf{R}einforcement \textbf{L}earning from
\textbf{AI} \textbf{F}eedback for video MLLMs} (\textbf{Iter-W2S-RLAIF}), a
framework that gradually enhances MLLMs' alignment capabilities by iteratively
updating the reference model and performing parameter extrapolation. Finally,
we propose an unbiased and information-complete evaluation scheme in VQA
evaluation. Experiments demonstrate that MMAIP-V is beneficial for MLLMs in
preference learning and Iter-W2S-RLAIF fully exploits the alignment information
in MMAIP-V. We believe that the proposed automatic VQA preference data
generation pipeline based on AI feedback can greatly promote future work in the
MLLMs alignment. \textbf{Code and dataset are available}
\href{https://anonymous.4open.science/r/MMAIP-V_Iter-W2S-RLAIF-702F}{MMAIP-V\_Iter-W2S-RLAIF-702F}.

摘要：高质量影片文字偏好資料對於多模態大型語言模型 (MLLM) 的比對至關重要。然而，現有的偏好資料非常稀少。取得 VQA 偏好資料以進行偏好訓練的成本很高，而手動註解回應的可靠性極低，可能會導致低品質的配對。同時，由溫度調整控制的 AI 生成的回應缺乏多樣性。為了解決這些問題，我們提出一個高品質的 VQA 偏好資料集，稱為「多模態多重人工智慧 VQA 偏好資料集」(MMAIP-V)，其透過從回應分佈集中取樣並使用外部評分函數對回應進行評估來建構。此外，為了充分利用 MMAIP-V 中的偏好知識並確保充分的最佳化，我們提出「透過 AI 回饋進行影片 MLLM 的反覆弱轉強強化學習」(Iter-W2S-RLAIF)，這是一個透過反覆更新參考模型並執行參數外推來逐漸提升 MLLM 比對能力的架構。最後，我們在 VQA 評估中提出一個無偏見且資訊完整的評估方案。實驗證明，MMAIP-V 有助於 MLLM 進行偏好學習，而 Iter-W2S-RLAIF 則充分利用 MMAIP-V 中的比對資訊。我們相信，這個基於 AI 回饋的自動 VQA 偏好資料產生管道，可以極大地促進未來在 MLLM 比對方面的研究。**程式碼和資料集已於此處提供**\href{https://anonymous.4open.science/r/MMAIP-V_Iter-W2S-RLAIF-702F}{MMAIP-V\_Iter-W2S-RLAIF-702F}。

##### **Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models**
2411.16189v1 by Zhihua Duan, Jialin Wang

Large Language Models (LLMs) still face challenges when dealing with complex
reasoning tasks, often resulting in hallucinations, which limit the practical
application of LLMs. To alleviate this issue, this paper proposes a new method
that integrates different LLMs to expand the knowledge boundary, reduce
dependence on a single model, and promote in-depth debate among agents. The
main contributions include: 1) Introducing third-party LLMs to adjust the
attention weights of agents through uncertainty estimation and confidence
analysis, optimizing consensus formation in multi-agent systems; 2) Experiments
on arithmetic datasets have validated the effectiveness of the method,
surpassing traditional multi-agent baselines. This research provides a new
perspective for large models to alleviate hallucination phenomena when dealing
with complex tasks.

摘要：大型語言模型 (LLM) 在處理複雜推理任務時仍面臨挑戰，經常導致幻覺，這限制了 LLM 的實際應用。為了緩解這個問題，本文提出了一種新的方法，將不同的 LLM 整合起來以擴展知識邊界，減少對單一模型的依賴，並促進代理之間的深入辯論。主要貢獻包括：1) 引入第三方 LLM，透過不確定性估計和信心分析來調整代理的注意力權重，優化多代理系統中的共識形成；2) 在算術數據集上的實驗驗證了該方法的有效性，超越了傳統的多代理基線。這項研究為大型模型在處理複雜任務時減輕幻覺現象提供了新的觀點。

##### **SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis**
2411.16173v1 by Junho Kim, Hyunjun Kim, Hosu Lee, Yong Man Ro

Despite advances in Large Multi-modal Models, applying them to long and
untrimmed video content remains challenging due to limitations in context
length and substantial memory overhead. These constraints often lead to
significant information loss and reduced relevance in the model responses. With
the exponential growth of video data across web platforms, understanding
long-form video is crucial for advancing generalized intelligence. In this
paper, we introduce SALOVA: Segment-Augmented LOng Video Assistant, a novel
video-LLM framework designed to enhance the comprehension of lengthy video
content through targeted retrieval process. We address two main challenges to
achieve it: (i) We present the SceneWalk dataset, a high-quality collection of
87.8K long videos, each densely captioned at the segment level to enable models
to capture scene continuity and maintain rich descriptive context. (ii) We
develop robust architectural designs integrating dynamic routing mechanism and
spatio-temporal projector to efficiently retrieve and process relevant video
segments based on user queries. Our framework mitigates the limitations of
current video-LMMs by allowing for precise identification and retrieval of
relevant video segments in response to queries, thereby improving the
contextual relevance of the generated responses. Through extensive experiments,
SALOVA demonstrates enhanced capability in processing complex long-form videos,
showing significant capability to maintain contextual integrity across extended
sequences.

摘要：儘管大型多模態模型有進展，但由於脈絡長度和大量記憶體開銷的限制，將它們應用於長且未修剪的影片內容仍然具有挑戰性。這些限制通常會導致模型回應中大量資訊遺失和相關性降低。隨著網路平台上影片資料的指數級成長，理解長篇影片對於推進廣義智慧至關重要。在本文中，我們介紹 SALOVA：區段增強長影片助理，這是一個新穎的影片 LLM 架構，旨在透過目標擷取流程增強對長篇影片內容的理解。我們解決了實現此目標的兩個主要挑戰：(i) 我們提出 SceneWalk 資料集，這是一個高品質的 87.8K 長影片集合，每個影片都在區段層級密集加註字幕，以使模型能夠擷取場景連續性並維持豐富的描述性脈絡。(ii) 我們開發強健的架構設計，整合動態路由機制和時空投影儀，以有效地根據使用者查詢擷取和處理相關影片區段。我們的架構透過允許精確識別和擷取相關影片區段來回應查詢，從而減輕當前影片 LMM 的限制，進而改善生成回應的脈絡相關性。透過廣泛的實驗，SALOVA 展示了處理複雜長篇影片的增強功能，顯示出在延伸序列中維持脈絡完整性的顯著能力。

##### **MixPE: Quantization and Hardware Co-design for Efficient LLM Inference**
2411.16158v1 by Yu Zhang, Mingzi Wang, Lancheng Zou, Wulong Liu, Hui-Ling Zhen, Mingxuan Yuan, Bei Yu

Transformer-based large language models (LLMs) have achieved remarkable
success as model sizes continue to grow, yet their deployment remains
challenging due to significant computational and memory demands. Quantization
has emerged as a promising solution, and state-of-the-art quantization
algorithms for LLMs introduce the need for mixed-precision matrix
multiplication (mpGEMM), where lower-precision weights are multiplied with
higher-precision activations. Despite its benefits, current hardware
accelerators such as GPUs and TPUs lack native support for efficient mpGEMM,
leading to inefficient dequantization operations in the main sequential loop.
To address this limitation, we introduce MixPE, a specialized mixed-precision
processing element designed for efficient low-bit quantization in LLM
inference. MixPE leverages two key innovations to minimize dequantization
overhead and unlock the full potential of low-bit quantization. First,
recognizing that scale and zero point are shared within each quantization
group, we propose performing dequantization after per-group mpGEMM,
significantly reducing dequantization overhead. Second, instead of relying on
conventional multipliers, MixPE utilizes efficient shift\&add operations for
multiplication, optimizing both computation and energy efficiency. Our
experimental results demonstrate that MixPE surpasses the state-of-the-art
quantization accelerators by $2.6\times$ speedup and $1.4\times$ energy
reduction.

摘要：<paragraph>隨著模型規模持續擴大，基於 Transformer 的大型語言模型 (LLM) 已取得顯著成功，但由於其龐大的運算和記憶體需求，部署仍是一項挑戰。量化已成為一種很有前景的解決方案，而 LLM 的最先進量化演算法引入了混合精度矩陣乘法 (mpGEMM) 的需求，其中較低精度的權重會與較高精度的激活相乘。儘管有這些優點，但目前的硬體加速器（例如 GPU 和 TPU）缺乏對高效 mpGEMM 的原生支援，導致主序向迴圈中出現低效率的去量化作業。為了解決這個限制，我們引入了 MixPE，這是一種專門的混合精度處理元件，設計用於在 LLM 推論中執行高效的低位元量化。MixPE 利用兩項關鍵創新來最小化去量化開銷，並發揮低位元量化的全部潛力。首先，我們認知到縮放和零點在每個量化群組中都是共用的，因此我們建議在每個群組的 mpGEMM 之後執行去量化，大幅減少去量化開銷。其次，MixPE 不依賴傳統的乘法器，而是利用高效的位移和加法運算進行乘法，同時最佳化運算和能源效率。我們的實驗結果證明，MixPE 在加速方面比最先進的量化加速器快了 2.6 倍，在能源消耗方面減少了 1.4 倍。</paragraph>

##### **Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning**
2411.16155v1 by Toyotaro Suzumura, Hiroki Kanezashi, Shotaro Akahori

In diagnosing mental diseases from electroencephalography (EEG) data, neural
network models such as Transformers have been employed to capture temporal
dynamics. Additionally, it is crucial to learn the spatial relationships
between EEG sensors, for which Graph Neural Networks (GNNs) are commonly used.
However, fine-tuning large-scale complex neural network models simultaneously
to capture both temporal and spatial features increases computational costs due
to the more significant number of trainable parameters. It causes the limited
availability of EEG datasets for downstream tasks, making it challenging to
fine-tune large models effectively. We propose EEG-GraphAdapter (EGA), a
parameter-efficient fine-tuning (PEFT) approach to address these challenges.
EGA is integrated into pre-trained temporal backbone models as a GNN-based
module and fine-tuned itself alone while keeping the backbone model parameters
frozen. This enables the acquisition of spatial representations of EEG signals
for downstream tasks, significantly reducing computational overhead and data
requirements. Experimental evaluations on healthcare-related downstream tasks
of Major Depressive Disorder and Abnormality Detection demonstrate that our EGA
improves performance by up to 16.1% in the F1-score compared with the backbone
BENDR model.

摘要：在利用腦電圖 (EEG) 資料診斷精神疾病時，已採用Transformer等神經網路模型來捕捉時間動態。此外，學習 EEG 感測器之間的空間關係至關重要，而圖形神經網路 (GNN) 通常用於此目的。然而，同時微調大型複雜神經網路模型以捕捉時間和空間特徵會增加運算成本，因為可訓練參數數量較多。這導致下游任務的 EEG 資料集可用性有限，使得有效微調大型模型具有挑戰性。我們提出 EEG-GraphAdapter (EGA)，一種參數高效微調 (PEFT) 方法來解決這些挑戰。EGA 作為基於 GNN 的模組整合到預訓練的時間主幹模型中，並在保持主幹模型參數凍結的同時自行微調。這使得能夠取得 EEG 訊號的空間表示，以用於下游任務，大幅降低運算負擔和資料需求。在與醫療保健相關的下游任務（重度憂鬱症和異常偵測）的實驗評估中，我們的 EGA 證明與主幹 BENDR 模型相比，F1 分數的效能提升了 16.1%。

##### **SKQVC: One-Shot Voice Conversion by K-Means Quantization with Self-Supervised Speech Representations**
2411.16147v1 by Youngjun Sim, Jinsung Yoon, Young-Joo Suh

One-shot voice conversion (VC) is a method that enables the transformation
between any two speakers using only a single target speaker utterance. Existing
methods often rely on complex architectures and pre-trained speaker
verification (SV) models to improve the fidelity of converted speech. Recent
works utilizing K-means quantization (KQ) with self-supervised learning (SSL)
features have proven capable of capturing content information from speech.
However, they often struggle to preserve speaking variation, such as prosodic
detail and phonetic variation, particularly with smaller codebooks. In this
work, we propose a simple yet effective one-shot VC model that utilizes the
characteristics of SSL features and speech attributes. Our approach addresses
the issue of losing speaking variation, enabling high-fidelity voice conversion
trained with only reconstruction losses, without requiring external speaker
embeddings. We demonstrate the performance of our model across 6 evaluation
metrics, with results highlighting the benefits of the speaking variation
compensation method.

摘要：單次聲音轉換 (VC) 是一種方法，可使用單一目標說話者語句，在兩個說話者之間進行轉換。現有方法通常依賴於複雜的架構和預先訓練的說話者驗證 (SV) 模型，以提高轉換語音的保真度。最近利用 K 均值量化 (KQ) 和自監督學習 (SSL) 特徵的作品已被證明能夠從語音中擷取內容資訊。然而，它們通常難以保留說話變異，例如音調細節和語音變異，特別是在較小的碼本中。在這項工作中，我們提出了一個簡單但有效的單次 VC 模型，它利用 SSL 特徵和語音屬性的特徵。我們的做法解決了失去說話變異的問題，實現了僅使用重建損失訓練的高保真語音轉換，而不需要外部說話者嵌入。我們在 6 項評估指標中展示了我們模型的效能，結果突出了說話變異補償方法的優點。

##### **End-to-End Steering for Autonomous Vehicles via Conditional Imitation Co-Learning**
2411.16131v1 by Mahmoud M. Kishky, Hesham M. Eraqi, Khaled F. Elsayed

Autonomous driving involves complex tasks such as data fusion, object and
lane detection, behavior prediction, and path planning. As opposed to the
modular approach which dedicates individual subsystems to tackle each of those
tasks, the end-to-end approach treats the problem as a single learnable task
using deep neural networks, reducing system complexity and minimizing
dependency on heuristics. Conditional imitation learning (CIL) trains the
end-to-end model to mimic a human expert considering the navigational commands
guiding the vehicle to reach its destination, CIL adopts specialist network
branches dedicated to learn the driving task for each navigational command.
Nevertheless, the CIL model lacked generalization when deployed to unseen
environments. This work introduces the conditional imitation co-learning (CIC)
approach to address this issue by enabling the model to learn the relationships
between CIL specialist branches via a co-learning matrix generated by gated
hyperbolic tangent units (GTUs). Additionally, we propose posing the steering
regression problem as classification, we use a classification-regression hybrid
loss to bridge the gap between regression and classification, we also propose
using co-existence probability to consider the spatial tendency between the
steering classes. Our model is demonstrated to improve autonomous driving
success rate in unseen environment by 62% on average compared to the CIL
method.

摘要：自動駕駛涉及複雜的任務，例如資料融合、物體和車道偵測、行為預測和路徑規劃。與將個別子系統專用於處理每個任務的模組化方法相反，端到端方法將問題視為使用深度神經網路的單一可學習任務，降低系統複雜性並最小化對啟發法的依賴。條件模仿學習 (CIL) 訓練端到端模型，以模擬人類專家考慮導航命令，引導車輛到達目的地，CIL 採用專門網路分支，專門學習每個導航命令的駕駛任務。儘管如此，CIL 模型在部署到未見環境時缺乏泛化性。這項工作引入了條件模仿協同學習 (CIC) 方法，透過啟用模型透過門控雙曲正切單元 (GTU) 生成的協同學習矩陣，學習 CIL 專家分支之間的關係來解決這個問題。此外，我們建議將轉向迴歸問題視為分類，我們使用分類迴歸混合損失來彌合迴歸和分類之間的差距，我們還建議使用共存機率來考慮轉向類別之間的空間趨勢。我們的模型被證明可以將在未見環境中的自動駕駛成功率平均提高 62%，與 CIL 方法相比。

##### **Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**
2411.16123v1 by Hangyul Yoon, Doohyuk Jang, Jungeun Kim, Eunho Yang

Leveraging pre-trained models with tailored prompts for in-context learning
has proven highly effective in NLP tasks. Building on this success, recent
studies have applied a similar approach to the Segment Anything Model (SAM)
within a ``one-shot" framework, where only a single reference image and its
label are employed. However, these methods face limitations in the medical
domain, primarily due to SAM's essential requirement for visual prompts and the
over-reliance on pixel similarity for generating them. This dependency may lead
to (1) inaccurate prompt generation and (2) clustering of point prompts,
resulting in suboptimal outcomes. To address these challenges, we introduce
\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designed
for the medical domain. Med-PerSAM uses only visual prompt engineering and
eliminates the need for additional training of the pretrained SAM or human
intervention, owing to our novel automated prompt generation process. By
integrating our lightweight warping-based prompt tuning model with SAM, we
enable the extraction and iterative refinement of visual prompts, enhancing the
performance of the pre-trained SAM. This advancement is particularly meaningful
in the medical domain, where creating visual prompts poses notable challenges
for individuals lacking medical expertise. Our model outperforms various
foundational models and previous SAM-based approaches across diverse 2D medical
imaging datasets.

摘要：利用預先訓練的模型，並針對特定提示進行情境學習，已證明在自然語言處理任務中非常有效。在此成功基礎上，最近的研究已將類似方法應用於「片段任何模型」(SAM)，採用「一次性」架構，其中僅使用單一參考影像及其標籤。然而，這些方法在醫療領域面臨限制，主要是由於 SAM 對視覺提示的基本需求，以及過度依賴像素相似性來產生它們。這種依賴性可能會導致 (1) 提示產生不準確，以及 (2) 點提示群集，導致結果次佳。為了應對這些挑戰，我們引入了 \textbf{Med-PerSAM}，這是一個專為醫療領域設計的新穎且直接的一次性架構。Med-PerSAM 僅使用視覺提示工程，並消除了對預訓練 SAM 或人為干預的額外訓練需求，這要歸功於我們新穎的自動化提示產生流程。透過將我們輕量級基於變形的提示調整模型與 SAM 整合，我們能夠提取和反覆改善視覺提示，增強預訓練 SAM 的效能。這項進展在醫療領域特別有意義，因為對於缺乏醫療專業知識的人來說，建立視覺提示會構成顯著的挑戰。我們的模型在各種 2D 醫學影像資料集上優於各種基礎模型和先前的基於 SAM 的方法。

##### **Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**
2411.16120v1 by Rui Zuo, Zifan Wang, Simon Khan, Garrett Ethan Katz, Qinru Qiu

Due to the inherent lack of transparency in deep neural networks, it is
challenging for deep reinforcement learning (DRL) agents to gain trust and
acceptance from users, especially in safety-critical applications such as
medical diagnosis and military operations. Existing methods for explaining an
agent's decision either require to retrain the agent using models that support
explanation generation or rely on perturbation-based techniques to reveal the
significance of different input features in the decision making process.
However, retraining the agent may compromise its integrity and performance,
while perturbation-based methods have limited performance and lack knowledge
accumulation or learning capabilities. Moreover, since each perturbation is
performed independently, the joint state of the perturbed inputs may not be
physically meaningful. To address these challenges, we introduce
$\textbf{VisionMask}$, a standalone explanation model trained end-to-end to
identify the most critical regions in the agent's visual input that can explain
its actions. VisionMask is trained in a self-supervised manner without relying
on human-generated labels. Importantly, its training does not alter the agent
model, hence preserving the agent's performance and integrity. We evaluate
VisionMask on Super Mario Bros (SMB) and three Atari games. Compared to
existing methods, VisionMask achieves a 14.9% higher insertion accuracy and a
30.08% higher F1-Score in reproducing original actions from the selected visual
explanations. We also present examples illustrating how VisionMask can be used
for counterfactual analysis.

摘要：<paragraph>由於深度神經網路缺乏透明度，深度強化學習 (DRL) 代理程式要獲得使用者的信任和認可是一項挑戰，特別是在安全關鍵的應用程式中，例如醫療診斷和軍事行動。現有的方法用於解釋代理程式的決策，需要使用支援解釋產生的模型重新訓練代理程式，或依賴於基於擾動的技術來揭示不同輸入特徵在決策制定過程中的重要性。然而，重新訓練代理程式可能會損害其完整性和效能，而基於擾動的方法效能有限，且缺乏知識累積或學習能力。此外，由於每個擾動都是獨立執行的，因此擾動輸入的聯合狀態可能沒有實際意義。為了應對這些挑戰，我們引入了 $\textbf{VisionMask}$，這是一個獨立的解釋模型，經過端對端的訓練，以識別代理程式視覺輸入中最關鍵的區域，這些區域可以解釋其動作。VisionMask 以自監督的方式進行訓練，而不依賴於人為產生的標籤。重要的是，其訓練不會改變代理程式模型，因此可以保留代理程式的效能和完整性。我們在 Super Mario Bros (SMB) 和三款 Atari 遊戲上評估了 VisionMask。與現有方法相比，VisionMask 在根據所選的視覺解釋複製原始動作時，插入準確率提高了 14.9%，F1 分數提高了 30.08%。我們還提供了範例來說明如何使用 VisionMask 進行反事實分析。</paragraph>

##### **LLM Augmentations to support Analytical Reasoning over Multiple Documents**
2411.16116v1 by Raquib Bin Yousuf, Nicholas Defelice, Mandar Sharma, Shengzhe Xu, Naren Ramakrishnan

Building on their demonstrated ability to perform a variety of tasks, we
investigate the application of large language models (LLMs) to enhance in-depth
analytical reasoning within the context of intelligence analysis. Intelligence
analysts typically work with massive dossiers to draw connections between
seemingly unrelated entities, and uncover adversaries' plans and motives. We
explore if and how LLMs can be helpful to analysts for this task and develop an
architecture to augment the capabilities of an LLM with a memory module called
dynamic evidence trees (DETs) to develop and track multiple investigation
threads. Through extensive experiments on multiple datasets, we highlight how
LLMs, as-is, are still inadequate to support intelligence analysts and offer
recommendations to improve LLMs for such intricate reasoning applications.

摘要：建立在它們執行各種任務的已驗證能力上，我們研究大型語言模型 (LLM) 的應用，以增強情報分析背景下的深入分析推理。情報分析師通常會處理大量檔案，以找出看似無關實體之間的關聯，並揭露對手的計畫和動機。我們探討 LLM 是否以及如何能協助分析師執行這項任務，並開發一種架構，以一個稱為動態證據樹 (DET) 的記憶體模組來擴充 LLM 的功能，以開發和追蹤多個調查線索。透過對多個資料集進行廣泛的實驗，我們強調出 LLM 原本的狀態仍不足以支援情報分析師，並提供建議，以改善 LLM，用於此類複雜的推理應用。

##### **LLMPirate: LLMs for Black-box Hardware IP Piracy**
2411.16111v1 by Vasudev Gohil, Matthew DeLorenzo, Veera Vishwa Achuta Sai Venkat Nallam, Joey See, Jeyavijayan Rajendran

The rapid advancement of large language models (LLMs) has enabled the ability
to effectively analyze and generate code nearly instantaneously, resulting in
their widespread adoption in software development. Following this advancement,
researchers and companies have begun integrating LLMs across the hardware
design and verification process. However, these highly potent LLMs can also
induce new attack scenarios upon security vulnerabilities across the hardware
development process. One such attack vector that has not been explored is
intellectual property (IP) piracy. Given that this attack can manifest as
rewriting hardware designs to evade piracy detection, it is essential to
thoroughly evaluate LLM capabilities in performing this task and assess the
mitigation abilities of current IP piracy detection tools.
  Therefore, in this work, we propose LLMPirate, the first LLM-based technique
able to generate pirated variations of circuit designs that successfully evade
detection across multiple state-of-the-art piracy detection tools. We devise
three solutions to overcome challenges related to integration of LLMs for
hardware circuit designs, scalability to large circuits, and effectiveness,
resulting in an end-to-end automated, efficient, and practical formulation. We
perform an extensive experimental evaluation of LLMPirate using eight LLMs of
varying sizes and capabilities and assess their performance in pirating various
circuit designs against four state-of-the-art, widely-used piracy detection
tools. Our experiments demonstrate that LLMPirate is able to consistently evade
detection on 100% of tested circuits across every detection tool. Additionally,
we showcase the ramifications of LLMPirate using case studies on IBEX and
MOR1KX processors and a GPS module, that we successfully pirate. We envision
that our work motivates and fosters the development of better IP piracy
detection tools.

摘要：大型語言模型 (LLM) 的快速進步使得能夠有效分析和生成代碼幾乎是瞬間完成，導致它們在軟體開發中被廣泛採用。在這一進步之後，研究人員和公司已經開始在硬體設計和驗證過程中整合 LLM。然而，這些高度強大的 LLM 也可以在整個硬體開發過程中對安全漏洞誘發新的攻擊場景。一種尚未探索的此類攻擊媒介是智慧財產權 (IP) 盜版。鑑於這種攻擊可以表現為重寫硬體設計以規避盜版檢測，因此徹底評估 LLM 在執行此任務中的能力並評估當前 IP 盜版檢測工具的緩解能力至關重要。
因此，在這項工作中，我們提出了 LLMPirate，這是一種基於 LLM 的首創技術，能夠生成電路設計的盜版變體，成功規避多種最先進的盜版檢測工具的檢測。我們設計了三種解決方案來克服與 LLM 集成到硬體電路設計、大電路可擴展性和有效性相關的挑戰，從而形成端到端自動化、高效且實用的公式。我們使用八種不同大小和功能的 LLM 對 LLMPirate 進行了廣泛的實驗評估，並評估了它們在針對四種最先進的、廣泛使用的盜版檢測工具盜版各種電路設計中的性能。我們的實驗表明，LLMPirate 能夠在每個檢測工具中對 100% 的受測電路持續規避檢測。此外，我們展示了 LLMPirate 在 IBEX 和 MOR1KX 處理器以及 GPS 模組（我們成功盜版）的案例研究中的影響。我們預計，我們的著作將激勵和促進更好的 IP 盜版檢測工具的開發。

##### **Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability**
2411.16105v1 by Jatin Nainani, Sankaran Vaidyanathan, AJ Yeung, Kartik Gupta, David Jensen

Mechanistic interpretability aims to understand the inner workings of large
neural networks by identifying circuits, or minimal subgraphs within the model
that implement algorithms responsible for performing specific tasks. These
circuits are typically discovered and analyzed using a narrowly defined prompt
format. However, given the abilities of large language models (LLMs) to
generalize across various prompt formats for the same task, it remains unclear
how well these circuits generalize. For instance, it is unclear whether the
models generalization results from reusing the same circuit components, the
components behaving differently, or the use of entirely different components.
In this paper, we investigate the generality of the indirect object
identification (IOI) circuit in GPT-2 small, which is well-studied and believed
to implement a simple, interpretable algorithm. We evaluate its performance on
prompt variants that challenge the assumptions of this algorithm. Our findings
reveal that the circuit generalizes surprisingly well, reusing all of its
components and mechanisms while only adding additional input edges. Notably,
the circuit generalizes even to prompt variants where the original algorithm
should fail; we discover a mechanism that explains this which we term S2
Hacking. Our findings indicate that circuits within LLMs may be more flexible
and general than previously recognized, underscoring the importance of studying
circuit generalization to better understand the broader capabilities of these
models.

摘要：<paragraph>機械可解釋性旨在透過識別電路，或模型中負責執行特定任務的演算法所實作的最小子圖形，來了解大型神經網路的內部運作。這些電路通常使用定義狹窄的提示格式進行發現和分析。然而，考量到大型語言模型 (LLM) 對相同任務的各種提示格式進行概化的能力，這些電路概化的程度仍然不清楚。例如，目前不清楚模型概化是否來自重複使用相同的電路元件，元件表現不同，或使用完全不同的元件。在本文中，我們探討 GPT-2 small 中間接受詞識別 (IOI) 電路的概括性，該電路經過充分研究，且被認為實作了一個簡單、可解釋的演算法。我們評估它在挑戰此演算法假設的提示變體上的效能。我們的發現顯示，該電路概化得令人驚訝地好，重複使用其所有元件和機制，同時僅新增額外的輸入邊緣。值得注意的是，即使在原始演算法應該會失敗的提示變體中，該電路仍能概化；我們發現一種機制可以解釋這種情況，我們稱之為 S2 Hacking。我們的發現表明，LLM 中的電路可能比先前認知的更靈活且更通用，這強調了研究電路概化的重要性，以便更深入了解這些模型的廣泛功能。</paragraph>

##### **An Empirical Study of Vulnerability Detection using Federated Learning**
2411.16099v1 by Peiheng Zhou, Ming Hu, Xingrun Quan, Yawen Peng, Xiaofei Xie, Yanxin Yang, Chengwei Liu, Yueming Wu, Mingsong Chen

Although Deep Learning (DL) methods becoming increasingly popular in
vulnerability detection, their performance is seriously limited by insufficient
training data. This is mainly because few existing software organizations can
maintain a complete set of high-quality samples for DL-based vulnerability
detection. Due to the concerns about privacy leakage, most of them are
reluctant to share data, resulting in the data silo problem. Since enables
collaboratively model training without data sharing, Federated Learning (FL)
has been investigated as a promising means of addressing the data silo problem
in DL-based vulnerability detection. However, since existing FL-based
vulnerability detection methods focus on specific applications, it is still far
unclear i) how well FL adapts to common vulnerability detection tasks and ii)
how to design a high-performance FL solution for a specific vulnerability
detection task. To answer these two questions, this paper first proposes VulFL,
an effective evaluation framework for FL-based vulnerability detection. Then,
based on VulFL, this paper conducts a comprehensive study to reveal the
underlying capabilities of FL in dealing with different types of CWEs,
especially when facing various data heterogeneity scenarios. Our experimental
results show that, compared to independent training, FL can significantly
improve the detection performance of common AI models on all investigated CWEs,
though the performance of FL-based vulnerability detection is limited by
heterogeneous data. To highlight the performance differences between different
FL solutions for vulnerability detection, we extensively investigate the
impacts of different configuration strategies for each framework component of
VulFL. Our study sheds light on the potential of FL in vulnerability detection,
which can be used to guide the design of FL-based solutions for vulnerability
detection.

摘要：儘管深度學習 (DL) 方法在漏洞偵測方面日益普及，但其效能卻受到訓練資料不足的嚴重限制。這主要是因為現有的軟體組織很少能維護一組完整的優質樣本，以進行基於 DL 的漏洞偵測。由於擔心隱私外洩，他們大多不願意分享資料，導致資料孤島問題。由於聯合學習 (FL) 能夠在不共用資料的情況下進行協作模型訓練，因此已將其視為解決基於 DL 的漏洞偵測中資料孤島問題的一種有前途的方法。然而，由於現有的基於 FL 的漏洞偵測方法專注於特定應用程式，因此仍不清楚 i) FL 如何適應常見的漏洞偵測任務，以及 ii) 如何為特定漏洞偵測任務設計高性能的 FL 解決方案。為了回答這兩個問題，本文首先提出了 VulFL，一個用於基於 FL 的漏洞偵測的有效評估架構。然後，本文基於 VulFL 進行了一項全面研究，以揭示 FL 在處理不同類型的 CWE 時的潛在能力，特別是在面對各種資料異質性場景時。我們的實驗結果表明，與獨立訓練相比，FL 可以顯著提升所有調查的 CWE 上常見 AI 模型的偵測效能，儘管基於 FL 的漏洞偵測的效能受到異質性資料的限制。為了強調不同 FL 解決方案在漏洞偵測上的效能差異，我們廣泛探討了 VulFL 各個架構元件的不同配置策略的影響。我們的研究闡明了 FL 在漏洞偵測方面的潛力，可用於指導基於 FL 的漏洞偵測解決方案的設計。

##### **ENCLIP: Ensembling and Clustering-Based Contrastive Language-Image Pretraining for Fashion Multimodal Search with Limited Data and Low-Quality Images**
2411.16096v1 by Prithviraj Purushottam Naik, Rohit Agarwal

Multimodal search has revolutionized the fashion industry, providing a
seamless and intuitive way for users to discover and explore fashion items.
Based on their preferences, style, or specific attributes, users can search for
products by combining text and image information. Text-to-image searches enable
users to find visually similar items or describe products using natural
language. This paper presents an innovative approach called ENCLIP, for
enhancing the performance of the Contrastive Language-Image Pretraining (CLIP)
model, specifically in Multimodal Search targeted towards the domain of fashion
intelligence. This method focuses on addressing the challenges posed by limited
data availability and low-quality images. This paper proposes an algorithm that
involves training and ensembling multiple instances of the CLIP model, and
leveraging clustering techniques to group similar images together. The
experimental findings presented in this study provide evidence of the
effectiveness of the methodology. This approach unlocks the potential of CLIP
in the domain of fashion intelligence, where data scarcity and image quality
issues are prevalent. Overall, the ENCLIP method represents a valuable
contribution to the field of fashion intelligence and provides a practical
solution for optimizing the CLIP model in scenarios with limited data and
low-quality images.

摘要：多模态搜索彻底改变了时尚产业，为用户提供了一种无缝且直观的方式来发现和探索时尚单品。基于他们的偏好、风格或特定属性，用户可以通过结合文本和图像信息来搜索产品。文本到图像搜索使用户能够找到视觉上相似的物品或使用自然语言描述产品。本文提出了一种名为 ENCLIP 的创新方法，用于增强对比语言图像预训练 (CLIP) 模型的性能，特别是在针对时尚智能领域的跨模态搜索中。此方法侧重于解决数据可用性有限和图像质量低下的挑战。本文提出了一种算法，该算法涉及训练和集成 CLIP 模型的多个实例，并利用聚类技术将相似的图像分组在一起。本研究中提出的实验结果证明了该方法的有效性。这种方法释放了 CLIP 在时尚智能领域中的潜力，而数据稀缺和图像质量问题很普遍。总体而言，ENCLIP 方法代表了对时尚智能领域的宝贵贡献，并为在数据有限和图像质量低下的情况下优化 CLIP 模型提供了实用的解决方案。

##### **HiDP: Hierarchical DNN Partitioning for Distributed Inference on Heterogeneous Edge Platforms**
2411.16086v1 by Zain Taufique, Aman Vyas, Antonio Miele, Pasi Liljeberg, Anil Kanduri

Edge inference techniques partition and distribute Deep Neural Network (DNN)
inference tasks among multiple edge nodes for low latency inference, without
considering the core-level heterogeneity of edge nodes. Further, default DNN
inference frameworks also do not fully utilize the resources of heterogeneous
edge nodes, resulting in higher inference latency. In this work, we propose a
hierarchical DNN partitioning strategy (HiDP) for distributed inference on
heterogeneous edge nodes. Our strategy hierarchically partitions DNN workloads
at both global and local levels by considering the core-level heterogeneity of
edge nodes. We evaluated our proposed HiDP strategy against relevant
distributed inference techniques over widely used DNN models on commercial edge
devices. On average our strategy achieved 38% lower latency, 46% lower energy,
and 56% higher throughput in comparison with other relevant approaches.

摘要：邊緣推理技術將深度神經網路 (DNN) 推論任務分割並分配給多個邊緣節點以進行低延遲推理，而不會考慮邊緣節點的核心層級異質性。此外，預設的 DNN 推論框架也不會完全利用異質邊緣節點的資源，導致更高的推論延遲。在這項工作中，我們提出了一種針對異質邊緣節點的分布式推論分層 DNN 分割策略 (HiDP)。我們的策略透過考慮邊緣節點的核心層級異質性，在全球和局部層級分層分割 DNN 工作負載。我們針對廣泛使用的 DNN 模型評估了我們提出的 HiDP 策略與相關的分布式推論技術在商用邊緣裝置上的表現。平均而言，我們的策略與其他相關方法相比，延遲降低了 38%，能耗降低了 46%，且吞吐量提高了 56%。

##### **Deciphering genomic codes using advanced NLP techniques: a scoping review**
2411.16084v1 by Shuyan Cheng, Yishu Wei, Yiliang Zhou, Zihan Xu, Drew N Wright, Jinze Liu, Yifan Peng

Objectives: The vast and complex nature of human genomic sequencing data
presents challenges for effective analysis. This review aims to investigate the
application of Natural Language Processing (NLP) techniques, particularly Large
Language Models (LLMs) and transformer architectures, in deciphering genomic
codes, focusing on tokenization, transformer models, and regulatory annotation
prediction. The goal of this review is to assess data and model accessibility
in the most recent literature, gaining a better understanding of the existing
capabilities and constraints of these tools in processing genomic sequencing
data.
  Methods: Following Preferred Reporting Items for Systematic Reviews and
Meta-Analyses (PRISMA) guidelines, our scoping review was conducted across
PubMed, Medline, Scopus, Web of Science, Embase, and ACM Digital Library.
Studies were included if they focused on NLP methodologies applied to genomic
sequencing data analysis, without restrictions on publication date or article
type.
  Results: A total of 26 studies published between 2021 and April 2024 were
selected for review. The review highlights that tokenization and transformer
models enhance the processing and understanding of genomic data, with
applications in predicting regulatory annotations like transcription-factor
binding sites and chromatin accessibility.
  Discussion: The application of NLP and LLMs to genomic sequencing data
interpretation is a promising field that can help streamline the processing of
large-scale genomic data while also providing a better understanding of its
complex structures. It has the potential to drive advancements in personalized
medicine by offering more efficient and scalable solutions for genomic
analysis. Further research is also needed to discuss and overcome current
limitations, enhancing model transparency and applicability.

摘要：<paragraph>目標：人類基因組定序資料的廣泛且複雜的性質為有效分析帶來挑戰。本篇評論旨在探討自然語言處理 (NLP) 技術的應用，特別是大語言模型 (LLM) 和Transformer架構，在破譯基因組密碼中的應用，重點關注分詞、Transformer模型和調控註釋預測。本篇評論的目標是評估最新文獻中的資料和模型可及性，以更深入了解這些工具在處理基因組定序資料方面的現有能力和限制。
方法：遵循系統性回顧和後設分析的首選報告項目 (PRISMA) 指南，我們的範圍回顧在 PubMed、Medline、Scopus、Web of Science、Embase 和 ACM 數位圖書館中進行。如果研究重點是應用於基因組定序資料分析的 NLP 方法，則納入研究，而不限制發表日期或文章類型。
結果：共選出 2021 年至 2024 年 4 月間發表的 26 篇研究進行回顧。回顧強調，分詞和Transformer模型增強了基因組資料的處理和理解，並應用於預測轉錄因子結合位點和染色質可及性等調控註釋。
討論：將 NLP 和 LLM 應用於基因組定序資料解讀是一個有前景的領域，有助於簡化大規模基因組資料的處理，同時也更深入了解其複雜結構。它有潛力透過提供更有效率且可擴充的基因組分析解決方案，推動個人化醫療的進步。進一步的研究也需要討論並克服目前的限制，以增強模型的透明度和適用性。</paragraph>

##### **Boosting 3D Object Generation through PBR Materials**
2411.16080v1 by Yitong Wang, Xudong Xu, Li Ma, Haoran Wang, Bo Dai

Automatic 3D content creation has gained increasing attention recently, due
to its potential in various applications such as video games, film industry,
and AR/VR. Recent advancements in diffusion models and multimodal models have
notably improved the quality and efficiency of 3D object generation given a
single RGB image. However, 3D objects generated even by state-of-the-art
methods are still unsatisfactory compared to human-created assets. Considering
only textures instead of materials makes these methods encounter challenges in
photo-realistic rendering, relighting, and flexible appearance editing. And
they also suffer from severe misalignment between geometry and high-frequency
texture details. In this work, we propose a novel approach to boost the quality
of generated 3D objects from the perspective of Physics-Based Rendering (PBR)
materials. By analyzing the components of PBR materials, we choose to consider
albedo, roughness, metalness, and bump maps. For albedo and bump maps, we
leverage Stable Diffusion fine-tuned on synthetic data to extract these values,
with novel usages of these fine-tuned models to obtain 3D consistent albedo UV
and bump UV for generated objects. In terms of roughness and metalness maps, we
adopt a semi-automatic process to provide room for interactive adjustment,
which we believe is more practical. Extensive experiments demonstrate that our
model is generally beneficial for various state-of-the-art generation methods,
significantly boosting the quality and realism of their generated 3D objects,
with natural relighting effects and substantially improved geometry.

摘要：<paragraph>自動 3D 內容創作近年來備受關注，因為它在各種應用中具有潛力，例如視訊遊戲、電影產業和 AR/VR。擴散模型和多模態模型的最新進展顯著提升了根據單一 RGB 影像生成 3D 物件的品質和效率。然而，即使是使用最先進方法生成的 3D 物件，與人工建立的資產相比仍不盡理想。這些方法僅考慮紋理而非材質，這使得它們在寫實渲染、重新打光和彈性外觀編輯方面遭遇挑戰。而且它們還存在幾何形狀和高頻率紋理細節之間嚴重的錯位。在這項工作中，我們提出了一種新穎的方法，從基於物理的渲染 (PBR) 材質的角度提升生成 3D 物件的品質。透過分析 PBR 材質的組成，我們選擇考慮漫反射率、粗糙度、金屬度和凹凸貼圖。對於漫反射率和凹凸貼圖，我們利用在合成資料上微調的 Stable Diffusion 來提取這些值，並創新使用這些微調模型來取得生成物件的 3D 一致漫反射率 UV 和凹凸 UV。在粗糙度和金屬度貼圖方面，我們採用半自動的流程來提供互動調整的空間，我們相信這更實用。廣泛的實驗證明，我們的模型通常有利於各種最先進的生成方法，顯著提升其生成 3D 物件的品質和真實感，具有自然的重新打光效果和大幅改善的幾何形狀。</paragraph>

##### **Debiasing Classifiers by Amplifying Bias with Latent Diffusion and Large Language Models**
2411.16079v1 by Donggeun Ko, Dongjun Lee, Namjun Park, Wonkyeong Shim, Jaekwang Kim

Neural networks struggle with image classification when biases are learned
and misleads correlations, affecting their generalization and performance.
Previous methods require attribute labels (e.g. background, color) or utilizes
Generative Adversarial Networks (GANs) to mitigate biases. We introduce
DiffuBias, a novel pipeline for text-to-image generation that enhances
classifier robustness by generating bias-conflict samples, without requiring
training during the generation phase. Utilizing pretrained diffusion and image
captioning models, DiffuBias generates images that challenge the biases of
classifiers, using the top-$K$ losses from a biased classifier ($f_B$) to
create more representative data samples. This method not only debiases
effectively but also boosts classifier generalization capabilities. To the best
of our knowledge, DiffuBias is the first approach leveraging a stable diffusion
model to generate bias-conflict samples in debiasing tasks. Our comprehensive
experimental evaluations demonstrate that DiffuBias achieves state-of-the-art
performance on benchmark datasets. We also conduct a comparative analysis of
various generative models in terms of carbon emissions and energy consumption
to highlight the significance of computational efficiency.

摘要：神經網路在學習偏差時會在影像分類上遭遇困難，並誤導相關性，影響其概化和效能。
先前的做法需要屬性標籤（例如背景、顏色）或利用生成對抗網路 (GAN) 來減輕偏差。我們引進 DiffuBias，這是一個用於文字轉影像生成的新穎管線，透過產生偏差衝突樣本來增強分類器的穩健性，而不需要在生成階段進行訓練。DiffuBias 利用預先訓練好的擴散和影像標題模型，產生挑戰分類器偏差的影像，使用有偏差分類器 ($f_B$) 中的頂端-$K$ 損失來建立更具代表性的資料樣本。這種方法不僅能有效消除偏差，還能提升分類器的概化能力。據我們所知，DiffuBias 是第一個利用穩定的擴散模型在去偏差任務中產生偏差衝突樣本的方法。我們全面的實驗評估證明，DiffuBias 在基準資料集上取得了最先進的效能。我們還對各種生成模型在碳排放和能源消耗方面的進行比較分析，以強調運算效率的重要性。

##### **SAGEval: The frontiers of Satisfactory Agent based NLG Evaluation for reference-free open-ended text**
2411.16077v1 by Reshmi Ghosh, Tianyi Yao, Lizzy Chen, Sadid Hasan, Tianwei Chen, Dario Bernal, Huitian Jiao, H M Sajjad Hossain

Large Language Model (LLM) integrations into applications like Microsoft365
suite and Google Workspace for creating/processing documents, emails,
presentations, etc. has led to considerable enhancements in productivity and
time savings. But as these integrations become more more complex, it is
paramount to ensure that the quality of output from the LLM-integrated
applications are relevant and appropriate for use. Identifying the need to
develop robust evaluation approaches for natural language generation, wherein
references/ground labels doesn't exist or isn't amply available, this paper
introduces a novel framework called "SAGEval" which utilizes a critiquing Agent
to provide feedback on scores generated by LLM evaluators. We show that the
critiquing Agent is able to rectify scores from LLM evaluators, in absence of
references/ground-truth labels, thereby reducing the need for labeled data even
for complex NLG evaluation scenarios, like the generation of JSON-structured
forms/surveys with responses in different styles like multiple choice, likert
ratings, single choice questions, etc.

摘要：大型語言模型 (LLM) 整合到 Microsoft365 套件和 Google Workspace 等應用程式中，用於建立/處理文件、電子郵件、簡報等等，這已經大幅提升了生產力並節省時間。但是隨著這些整合變得越來越複雜，最重要的是要確保 LLM 整合應用程式輸出的品質與使用目的相關且適當。本論文辨識出開發健全自然語言產生評估方法的需求，其中參考/基礎標籤不存在或無法充分取得，因此介紹了一個名為「SAGEval」的新架構，它利用批評代理提供 LLM 評估器產生的分數回饋。我們展示出在沒有參考/基礎真實標籤的情況下，批評代理能夠修正 LLM 評估器的分數，因此即使對於複雜的 NLG 評估情境，例如產生具有不同樣式的回應（例如多重選擇、李克特量表、單選題等等）的 JSON 結構化表單/調查，也能減少標記資料的需求。

##### **The brain versus AI: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum**
2411.16075v1 by Shogo Ohmae, Keiko Ohmae

AI's significant recent advances using general-purpose circuit computations
offer a potential window into how the neocortex and cerebellum of the brain are
able to achieve a diverse range of functions across sensory, cognitive, and
motor domains, despite their uniform circuit structures. However, comparing the
brain and AI is challenging unless clear similarities exist, and past reviews
have been limited to comparison of brain-inspired vision AI and the visual
neocortex. Here, to enable comparisons across diverse functional domains, we
subdivide circuit computation into three elements -- circuit structure,
input/outputs, and the learning algorithm -- and evaluate the similarities for
each element. With this novel approach, we identify wide-ranging similarities
and convergent evolution in the brain and AI, providing new insights into key
concepts in neuroscience. Furthermore, inspired by processing mechanisms of AI,
we propose a new theory that integrates established neuroscience theories,
particularly the theories of internal models and the mirror neuron system. Both
the neocortex and cerebellum predict future world events from past information
and learn from prediction errors, thereby acquiring models of the world. These
models enable three core processes: (1) Prediction -- generating future
information, (2) Understanding -- interpreting the external world via
compressed and abstracted sensory information, and (3) Generation --
repurposing the future-information generation mechanism to produce other types
of outputs. The universal application of these processes underlies the ability
of the neocortex and cerebellum to accomplish diverse functions with uniform
circuits. Our systematic approach, insights, and theory promise groundbreaking
advances in understanding the brain.

摘要：<paragraph>AI 近期在通用電路運算上取得重大進展，
提供了一個潛在窗口，讓我們得以了解大腦的新皮質和小腦如何
在感官、認知和運動領域實現各種功能，儘管它們的電路結構是統一的。然而，除非存在明確的相似性，否則比較大腦和 AI 具有挑戰性，而且過去的評論僅限於比較受大腦啟發的視覺 AI 和視覺新皮質。在此，為了能夠在不同的功能領域進行比較，我們將電路運算細分為三個要素——電路結構、輸入/輸出和學習演算法——並評估每個要素的相似性。透過這種新穎的方法，我們發現了大腦和 AI 之間廣泛的相似性和趨同演化，為神經科學中的關鍵概念提供了新的見解。此外，受到 AI 處理機制的啟發，我們提出了一個新理論，整合了既定的神經科學理論，特別是內部模型理論和鏡像神經元系統理論。新皮質和小腦都根據過去的資訊預測未來的世界事件，並從預測誤差中學習，從而獲得世界的模型。這些模型啟用了三個核心流程：(1) 預測——產生未來資訊，(2) 理解——透過壓縮和抽象的感官資訊來詮釋外部世界，以及 (3) 生成——重新利用未來資訊生成機制來產生其他類型的輸出。這些流程的通用應用是新皮質和小腦能夠使用統一電路完成多種功能的基礎。我們系統性的方法、見解和理論有望在理解大腦方面取得突破性的進展。</paragraph>

##### **UnitedVLN: Generalizable Gaussian Splatting for Continuous Vision-Language Navigation**
2411.16053v1 by Guangzhao Dai, Jian Zhao, Yuantao Chen, Yusen Qin, Hao Zhao, Guosen Xie, Yazhou Yao, Xiangbo Shu, Xuelong Li

Vision-and-Language Navigation (VLN), where an agent follows instructions to
reach a target destination, has recently seen significant advancements. In
contrast to navigation in discrete environments with predefined trajectories,
VLN in Continuous Environments (VLN-CE) presents greater challenges, as the
agent is free to navigate any unobstructed location and is more vulnerable to
visual occlusions or blind spots. Recent approaches have attempted to address
this by imagining future environments, either through predicted future visual
images or semantic features, rather than relying solely on current
observations. However, these RGB-based and feature-based methods lack intuitive
appearance-level information or high-level semantic complexity crucial for
effective navigation. To overcome these limitations, we introduce a novel,
generalizable 3DGS-based pre-training paradigm, called UnitedVLN, which enables
agents to better explore future environments by unitedly rendering
high-fidelity 360 visual images and semantic features. UnitedVLN employs two
key schemes: search-then-query sampling and separate-then-united rendering,
which facilitate efficient exploitation of neural primitives, helping to
integrate both appearance and semantic information for more robust navigation.
Extensive experiments demonstrate that UnitedVLN outperforms state-of-the-art
methods on existing VLN-CE benchmarks.

摘要：視覺和語言導航 (VLN) 讓代理人遵循指示前往目標目的地，最近有了顯著的進展。與具有預定義軌跡的離散環境中的導航相比，連續環境中的 VLN (VLN-CE) 提出更大的挑戰，因為代理人可以自由導航任何無障礙位置，並且更容易受到視覺遮擋或盲點的影響。最近的方法嘗試通過想像未來的環境（透過預測未來的視覺影像或語義特徵）來解決這個問題，而不是僅依賴目前的觀察。然而，這些基於 RGB 和基於特徵的方法缺乏有效的導航所需的直觀外觀層級資訊或高層級語義複雜性。為了克服這些限制，我們引入了一個新穎、可概括的基於 3DGS 的預訓練範例，稱為 UnitedVLN，它使代理人能夠透過統一呈現高保真 360 視覺影像和語義特徵來更好地探索未來的環境。UnitedVLN 採用兩個關鍵方案：先搜尋再查詢的抽樣和先分開再統一的呈現，這有助於有效利用神經基元，幫助整合外觀和語義資訊以進行更穩健的導航。廣泛的實驗證明，UnitedVLN 在現有的 VLN-CE 基準上優於最先進的方法。

##### **Predicting Emergent Capabilities by Finetuning**
2411.16035v1 by Charlie Snell, Eric Wallace, Dan Klein, Sergey Levine

A fundamental open challenge in modern LLM scaling is the lack of
understanding around emergent capabilities. In particular, language model
pretraining loss is known to be highly predictable as a function of compute.
However, downstream capabilities are far less predictable -- sometimes even
exhibiting emergent jumps -- which makes it challenging to anticipate the
capabilities of future models. In this work, we first pose the task of
emergence prediction: given access to current LLMs that have random few-shot
accuracy on a task, can we predict whether future models (GPT-N+1) will have
non-trivial accuracy on that task? We then discover a simple insight for this
problem: finetuning LLMs on a given task can shift the point in scaling at
which emergence occurs towards less capable models. To operationalize this
insight, we can finetune LLMs with varying amounts of data and fit a parametric
function that predicts when emergence will occur (i.e., "emergence laws"). We
validate this approach using four standard NLP benchmarks where large-scale
open-source LLMs already demonstrate emergence (MMLU, GSM8K, CommonsenseQA, and
CoLA). Using only small-scale LLMs, we find that, in some cases, we can
accurately predict whether models trained with up to 4x more compute have
emerged. Finally, we present a case study of two realistic uses for emergence
prediction.

摘要：現代 LLM 擴充的一個基本公開挑戰是缺乏對新興能力的理解。特別是，語言模型預訓練損失已知高度可預測為計算函數。然而，下游能力的可預測性遠低得多，有時甚至表現出新興跳躍，這使得預測未來模型的能力具有挑戰性。在這項工作中，我們首先提出新興預測任務：在訪問具有任務中隨機少次準確度的當前 LLM 的情況下，我們能預測未來模型 (GPT-N+1) 是否會在該任務中具有非平凡準確度？然後，我們發現了一個簡單的見解來解決這個問題：在特定任務上微調 LLM 可以將出現發生時的擴充點轉移到功能較弱的模型。為了將此見解付諸實施，我們可以使用不同數量的數據微調 LLM，並擬合參數函數來預測新興何時會發生（即「新興定律」）。我們使用四個標準 NLP 基準驗證此方法，其中大規模開源 LLM 已展示新興（MMLU、GSM8K、常識問答和 CoLA）。僅使用小規模 LLM，我們發現，在某些情況下，我們可以準確預測使用多達 4 倍計算訓練的模型是否已出現。最後，我們提出一個案例研究，說明新興預測的兩個實際用途。

##### **From Dashcam Videos to Driving Simulations: Stress Testing Automated Vehicles against Rare Events**
2411.16027v1 by Yan Miao, Georgios Fainekos, Bardh Hoxha, Hideki Okamoto, Danil Prokhorov, Sayan Mitra

Testing Automated Driving Systems (ADS) in simulation with realistic driving
scenarios is important for verifying their performance. However, converting
real-world driving videos into simulation scenarios is a significant challenge
due to the complexity of interpreting high-dimensional video data and the
time-consuming nature of precise manual scenario reconstruction. In this work,
we propose a novel framework that automates the conversion of real-world car
crash videos into detailed simulation scenarios for ADS testing. Our approach
leverages prompt-engineered Video Language Models(VLM) to transform dashcam
footage into SCENIC scripts, which define the environment and driving behaviors
in the CARLA simulator, enabling the generation of realistic simulation
scenarios. Importantly, rather than solely aiming for one-to-one scenario
reconstruction, our framework focuses on capturing the essential driving
behaviors from the original video while offering flexibility in parameters such
as weather or road conditions to facilitate search-based testing. Additionally,
we introduce a similarity metric that helps iteratively refine the generated
scenario through feedback by comparing key features of driving behaviors
between the real and simulated videos. Our preliminary results demonstrate
substantial time efficiency, finishing the real-to-sim conversion in minutes
with full automation and no human intervention, while maintaining high fidelity
to the original driving events.

摘要：在模擬中使用逼真的駕駛情境測試自動駕駛系統 (ADS) 對於驗證其效能非常重要。然而，由於難以詮釋高維度的影片資料，以及精確手動場景重建耗時，將真實世界的駕駛影片轉換成模擬場景是一項重大的挑戰。在此研究中，我們提出一個創新的架構，可自動將真實世界的汽車碰撞影片轉換成 ADS 測試的詳細模擬場景。我們的做法利用提示工程化影片語言模型 (VLM) 將行車記錄器畫面轉換成 SCENIC 腳本，定義 CARLA 模擬器中的環境和駕駛行為，進而產生逼真的模擬場景。重要的是，我們的架構並非僅以一對一的場景重建為目標，而是專注於擷取原始影片中的基本駕駛行為，同時在天氣或道路狀況等參數中提供彈性，以利於搜尋式測試。此外，我們引入了一個相似度量數，有助於透過比較真實和模擬影片中駕駛行為的關鍵特徵，反覆改善產生的場景。我們的初步結果證明了大幅的省時效率，在完全自動化且無需人工介入的情況下，於數分鐘內完成真實到模擬的轉換，同時維持對原始駕駛事件的高度保真度。

##### **TransCompressor: LLM-Powered Multimodal Data Compression for Smart Transportation**
2411.16020v1 by Huanqi Yang, Rucheng Wu, Weitao Xu

The incorporation of Large Language Models (LLMs) into smart transportation
systems has paved the way for improving data management and operational
efficiency. This study introduces TransCompressor, a novel framework that
leverages LLMs for efficient compression and decompression of multimodal
transportation sensor data. TransCompressor has undergone thorough evaluation
with diverse sensor data types, including barometer, speed, and altitude
measurements, across various transportation modes like buses, taxis, and MTRs.
Comprehensive evaluation illustrates the effectiveness of TransCompressor in
reconstructing transportation sensor data at different compression ratios. The
results highlight that, with well-crafted prompts, LLMs can utilize their vast
knowledge base to contribute to data compression processes, enhancing data
storage, analysis, and retrieval in smart transportation settings.

摘要：大型語言模型 (LLM) 納入智慧運輸系統已為改善資料管理和營運效率鋪路。本研究介紹 TransCompressor，一個利用 LLM 有效壓縮和解壓縮多模態運輸感測器資料的新穎架構。TransCompressor 已針對各種感測器資料類型進行徹底評估，包括氣壓計、速度和高度測量，涵蓋公車、計程車和地鐵等各種運輸模式。全面的評估說明了 TransCompressor 在以不同壓縮比重建運輸感測器資料方面的有效性。結果強調，透過精心設計的提示，LLM 可以利用其龐大的知識庫來協助資料壓縮程序，進而強化智慧運輸設定中的資料儲存、分析和擷取。

##### **Performance Implications of Multi-Chiplet Neural Processing Units on Autonomous Driving Perception**
2411.16007v1 by Mohanad Odema, Luke Chen, Hyoukjun Kwon, Mohammad Abdullah Al Faruque

We study the application of emerging chiplet-based Neural Processing Units to
accelerate vehicular AI perception workloads in constrained automotive
settings. The motivation stems from how chiplets technology is becoming
integral to emerging vehicular architectures, providing a cost-effective
trade-off between performance, modularity, and customization; and from
perception models being the most computationally demanding workloads in a
autonomous driving system. Using the Tesla Autopilot perception pipeline as a
case study, we first breakdown its constituent models and profile their
performance on different chiplet accelerators. From the insights, we propose a
novel scheduling strategy to efficiently deploy perception workloads on
multi-chip AI accelerators. Our experiments using a standard DNN performance
simulator, MAESTRO, show our approach realizes 82% and 2.8x increase in
throughput and processing engines utilization compared to monolithic
accelerator designs.

摘要：我們研究了新興晶片級神經處理單元在受限汽車環境中加速車輛 AI 感知工作負載的應用。其動機源自於晶片技術如何成為新興汽車架構的組成部分，在效能、模組化和客製化之間提供具成本效益的折衷方案；以及感知模型在自動駕駛系統中是最需要運算的工作負載。使用 Tesla Autopilot 感知管線作為案例研究，我們首先分解其組成模型，並分析其在不同晶片加速器上的效能。根據這些見解，我們提出了一種新穎的排程策略，以有效率的方式在多晶片 AI 加速器上部署感知工作負載。我們使用標準 DNN 效能模擬器 MAESTRO 進行的實驗顯示，與單一加速器設計相比，我們的做法可實現吞吐量和處理引擎使用率分別提升 82% 和 2.8 倍。

##### **eFedLLM: Efficient LLM Inference Based on Federated Learning**
2411.16003v1 by Shengwen Ding, Chenhui Hu

Large Language Models (LLMs) herald a transformative era in artificial
intelligence (AI). However, the expansive scale of data and parameters of LLMs
requires high-demand computational and memory resources, restricting their
accessibility to a broader range of users and researchers. This paper
introduces an effective approach that enhances the operational efficiency and
affordability of LLM inference. By utilizing transformer-based federated
learning (FL) with model-parallel distributed training, our model efficiently
distributes the computational loads and memory requirements across a network of
participants. This strategy permits users, especially those with limited
resources to train state-of-the-art LLMs collaboratively. We also innovate an
incentive mechanism within the FL framework, rewarding constructive
contributions and filtering out malicious activities, thereby safeguarding the
integrity and reliability of the training process. Concurrently, we leverage
memory hierarchy strategies and Singular Value Decomposition (SVD) on weight
matrices to boost computational and memory efficiencies further. Our results,
derived from formulaic analyses and numerical calculations, demonstrate
significant optimization of resource use and democratize access to cutting-edge
LLMs, ensuring that a wide scale of users can both contribute to and benefit
from these advanced models.

摘要：大型語言模型 (LLM) 預告著人工智慧 (AI) 的變革時代。然而，LLM 的資料和參數規模龐大，需要大量的運算和記憶體資源，限制了其對更廣泛的使用者和研究人員的可及性。本文介紹了一種有效的方法，可以提高 LLM 推論的運作效率和負擔能力。透過利用基於 Transformer 的聯邦學習 (FL) 和模型並行分布式訓練，我們的模型可以有效地將運算負載和記憶體需求分佈在參與者的網路中。此策略允許使用者（特別是那些資源有限的使用者）合作訓練最先進的 LLM。我們還在 FL 架構中創新了一種激勵機制，獎勵建設性的貢獻並過濾掉惡意活動，從而保護訓練過程的完整性和可靠性。同時，我們利用記憶體階層策略和權重矩陣上的奇異值分解 (SVD) 來進一步提升運算和記憶體效率。我們從公式分析和數值計算中得出的結果，證明了資源使用的顯著最佳化，並使尖端的 LLM 民主化，確保廣泛的使用者既能貢獻這些先進模型，也能從中受益。

##### **Exploring Performance Contrasts in TableQA: Step-by-Step Reasoning Boosts Bigger Language Models, Limits Smaller Language Models**
2411.16002v1 by Haoyan Yang, Yixuan Wang, Keyue Tong, Hongjin Zhu, Yuanxin Zhang

This paper proposes a detailed prompting flow, termed Table-Logic, to
investigate the performance contrasts between bigger and smaller language
models (LMs) utilizing step-by-step reasoning methods in the TableQA task. The
method processes tasks by sequentially identifying critical columns and rows
given question and table with its structure, determining necessary
aggregations, calculations, or comparisons, and finally inferring the results
to generate a precise prediction. By deploying this method, we observe a 7.8%
accuracy improvement in bigger LMs like Llama-3-70B compared to the vanilla on
HybridQA, while smaller LMs like Llama-2-7B shows an 11% performance decline.
We empirically investigate the potential causes of performance contrasts by
exploring the capabilities of bigger and smaller LMs from various dimensions in
TableQA task. Our findings highlight the limitations of the step-by-step
reasoning method in small models and provide potential insights for making
improvements.

摘要：這篇論文提出了詳盡的提示流程，稱為 Table-Logic，以探討在 TableQA 任務中利用逐步推理方法的大型和小型語言模型 (LM) 之間的效能對比。此方法透過按順序識別關鍵欄位和列（給定問題和表格及其結構）、決定必要的彙總、計算或比較，最後推論結果以產生精確預測，來處理任務。透過部署此方法，我們觀察到 Llama-3-70B 等大型 LM 在 HybridQA 上的準確度提升了 7.8%，而 Llama-2-7B 等小型 LM 則顯示出效能下降 11%。我們透過探索大型和小型 LM 在 TableQA 任務中各方面的能力，實證調查效能對比的潛在原因。我們的發現突顯了小型模型中逐步推理方法的限制，並提供潛在見解以進行改進。

##### **Multi-ToM: Evaluating Multilingual Theory of Mind Capabilities in Large Language Models**
2411.15999v1 by Jayanta Sadhu, Ayan Antik Khan, Noshin Nawal, Sanju Basak, Abhik Bhattacharjee, Rifat Shahriyar

Theory of Mind (ToM) refers to the cognitive ability to infer and attribute
mental states to oneself and others. As large language models (LLMs) are
increasingly evaluated for social and cognitive capabilities, it remains
unclear to what extent these models demonstrate ToM across diverse languages
and cultural contexts. In this paper, we introduce a comprehensive study of
multilingual ToM capabilities aimed at addressing this gap. Our approach
includes two key components: (1) We translate existing ToM datasets into
multiple languages, effectively creating a multilingual ToM dataset and (2) We
enrich these translations with culturally specific elements to reflect the
social and cognitive scenarios relevant to diverse populations. We conduct
extensive evaluations of six state-of-the-art LLMs to measure their ToM
performance across both the translated and culturally adapted datasets. The
results highlight the influence of linguistic and cultural diversity on the
models' ability to exhibit ToM, and questions their social reasoning
capabilities. This work lays the groundwork for future research into enhancing
LLMs' cross-cultural social cognition and contributes to the development of
more culturally aware and socially intelligent AI systems. All our data and
code are publicly available.

摘要：心智理論 (ToM) 指的是推論和歸因心智狀態給自己和別人的認知能力。隨著大型語言模型 (LLM) 逐漸被評估其社交和認知能力，這些模型在不同語言和文化背景中展現 ToM 的程度仍不明確。在本文中，我們介紹了一項針對多語言 ToM 能力的全面研究，旨在解決這個問題。我們的做法包含兩個關鍵組成部分：(1) 我們將現有的 ToM 資料集翻譯成多種語言，有效地建立了一個多語言 ToM 資料集，(2) 我們用文化特定元素豐富這些翻譯，以反映與不同族群相關的社會和認知情境。我們對六個最先進的 LLM 進行廣泛的評估，以衡量它們在翻譯和文化改編資料集中的 ToM 表現。結果突顯了語言和文化多樣性對模型展現 ToM 能力的影響，並質疑它們的社會推理能力。這項工作為未來增強 LLM 的跨文化社會認知的研究奠定了基礎，並有助於開發更具文化意識和社會智慧的 AI 系統。我們的資料和程式碼皆公開提供。

##### **PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making**
2411.15998v1 by Jonathan Light, Sixue Xing, Yuanzhe Liu, Weiqin Chen, Min Cai, Xiusi Chen, Guanzhi Wang, Wei Cheng, Yisong Yue, Ziniu Hu

Effective extraction of the world knowledge in LLMs for complex
decision-making tasks remains a challenge. We propose a framework PIANIST for
decomposing the world model into seven intuitive components conducive to
zero-shot LLM generation. Given only the natural language description of the
game and how input observations are formatted, our method can generate a
working world model for fast and efficient MCTS simulation. We show that our
method works well on two different games that challenge the planning and
decision making skills of the agent for both language and non-language based
action taking, without any training on domain-specific training data or
explicitly defined world model.

摘要：對於複雜的決策任務，在 LLM 中有效提取世界知識仍然是一個挑戰。我們提出一個架構 PIANIST，將世界模型分解為七個直觀的組成部分，有利於零次學習 LLM 生成。僅給定遊戲的自然語言描述和輸入觀測值的格式化方式，我們的模型就能產生一個運作的世界模型，用於快速且有效率的 MCTS 模擬。我們展示了我們的模型在兩種不同的遊戲中運作良好，這些遊戲挑戰了代理人在語言和非語言動作採取方面的規劃和決策制定技能，而無需針對特定領域的訓練資料或明確定義的世界模型進行任何訓練。

##### **Ensuring Fair LLM Serving Amid Diverse Applications**
2411.15997v1 by Redwan Ibne Seraj Khan, Kunal Jain, Haiying Shen, Ankur Mallick, Anjaly Parayil, Anoop Kulkarni, Steve Kofsky, Pankhuri Choudhary, Renèe St. Amant, Rujia Wang, Yue Cheng, Ali R. Butt, Victor Rühle, Chetan Bansal, Saravan Rajmohan

In a multi-tenant large language model (LLM) serving platform hosting diverse
applications, some users may submit an excessive number of requests, causing
the service to become unavailable to other users and creating unfairness.
Existing fairness approaches do not account for variations in token lengths
across applications and multiple LLM calls, making them unsuitable for such
platforms. To address the fairness challenge, this paper analyzes millions of
requests from thousands of users on MS CoPilot, a real-world multi-tenant LLM
platform hosted by Microsoft. Our analysis confirms the inadequacy of existing
methods and guides the development of FairServe, a system that ensures fair LLM
access across diverse applications. FairServe proposes
application-characteristic aware request throttling coupled with a weighted
service counter based scheduling technique to curb abusive behavior and ensure
fairness. Our experimental results on real-world traces demonstrate FairServe's
superior performance compared to the state-of-the-art method in ensuring
fairness. We are actively working on deploying our system in production,
expecting to benefit millions of customers world-wide.

摘要：在一個多租戶的大型語言模型 (LLM) 服務平台上，託管著各種應用程式，一些使用者可能會提交過多的要求，導致服務對其他使用者不可用，並造成不公平。現有的公平方法沒有考慮到不同應用程式間的符號長度差異和多個 LLM 呼叫，這使得它們不適合此類平台。為了應對公平性的挑戰，本文分析了來自數千名使用者的數百萬個請求，這些使用者在 MS CoPilot 上，這是一個由 Microsoft 託管的真實世界多租戶 LLM 平台。我們的分析證實了現有方法的不足，並指導了 FairServe 的開發，FairServe 是一個系統，可確保不同應用程式之間的 LLM 公平存取。FairServe 提出了一個應用程式特徵感知請求節流，再加上一個基於加權服務計數器的排程技術，以遏制濫用行為並確保公平性。我們在真實世界追蹤上的實驗結果證明了 FairServe 與最先進的方法相比，在確保公平性方面具有優異的效能。我們正在積極地將我們的系統部署到生產環境中，預計將使全球數百萬客戶受益。

##### **Investigating Factuality in Long-Form Text Generation: The Roles of Self-Known and Self-Unknown**
2411.15993v1 by Lifu Tu, Rui Meng, Shafiq Joty, Yingbo Zhou, Semih Yavuz

Large language models (LLMs) have demonstrated strong capabilities in text
understanding and generation. However, they often lack factuality, producing a
mixture of true and false information, especially in long-form generation. In
this work, we investigates the factuality of long-form text generation across
various large language models (LLMs), including GPT-4, Gemini-1.5-Pro,
Claude-3-Opus, Llama-3-70B, and Mistral. Our analysis reveals that factuality
scores tend to decline in later sentences of the generated text, accompanied by
a rise in the number of unsupported claims. Furthermore, we explore the
effectiveness of different evaluation settings to assess whether LLMs can
accurately judge the correctness of their own outputs: Self-Known (the
percentage of supported atomic claims, decomposed from LLM outputs, that the
corresponding LLMs judge as correct) and Self-Unknown (the percentage of
unsupported atomic claims that the corresponding LLMs judge as incorrect). The
results indicate that even advanced models like GPT-4 and Gemini-1.5-Pro fail
to achieve perfect Self-Known scores, while their Self-Unknown scores remain
notably above zero, reflecting ongoing uncertainty in their self-assessments.
Moreover, we find a correlation between higher Self-Known scores and improved
factuality, while higher Self-Unknown scores are associated with lower
factuality. Interestingly, even without significant changes in the models'
self-judgment (Self-Known and Self-Unknown), the number of unsupported claims
can increases, likely as an artifact of long-form generation. These findings
show the limitations of current LLMs in long-form generation, and provide
valuable insights for improving factuality in long-form text generation.

摘要：大型語言模型 (LLM) 已展現出強大的文字理解和生成能力。然而，它們往往缺乏事實性，產生真假訊息混雜的內容，特別是在長篇生成中。在此研究中，我們探討了各種大型語言模型 (LLM) 的長篇文字生成的真實性，包括 GPT-4、Gemini-1.5-Pro、Claude-3-Opus、Llama-3-70B 和 Mistral。我們的分析顯示，生成文字的後續句子中真實性分數往往下降，同時缺乏依據的主張數量增加。此外，我們探討了不同評估設定的有效性，以評估 LLM 是否能準確判斷其自身輸出的正確性：自知（LLM 輸出中分解出的已支持原子主張的百分比，對應的 LLM 判斷為正確）和自不知（LLM 輸出中分解出的未支持原子主張的百分比，對應的 LLM 判斷為不正確）。結果表明，即使是 GPT-4 和 Gemini-1.5-Pro 等進階模型也無法達到完美的自知分數，而其自不知分數仍顯著高於零，反映出其自我評估中持續存在的不確定性。此外，我們發現自知分數較高與真實性提升之間存在關聯，而自不知分數較高則與真實性降低相關。有趣的是，即使模型的自判斷（自知和自不知）沒有顯著變化，未支持主張的數量仍可能增加，這可能是長篇生成的產物。這些發現顯示了當前 LLM 在長篇生成中的局限性，並為改善長篇文字生成的真實性提供了有價值的見解。

##### **Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format**
2411.15982v1 by Chao Fang, Man Shi, Robin Geens, Arne Symons, Zhongfeng Wang, Marian Verhelst

The widely-used, weight-only quantized large language models (LLMs), which
leverage low-bit integer (INT) weights and retain floating-point (FP)
activations, reduce storage requirements while maintaining accuracy. However,
this shifts the energy and latency bottlenecks towards the FP activations that
are associated with costly memory accesses and computations. Existing LLM
accelerators focus primarily on computation optimizations, overlooking the
potential of jointly optimizing FP computations and data movement, particularly
for the dominant FP-INT GeMM operations in LLM inference.
  To address these challenges, we investigate the sensitivity of activation
precision across various LLM modules and its impact on overall model accuracy.
Based on our findings, we first propose the Anda data type: an adaptive data
format with group-shared exponent bits and dynamic mantissa bit allocation.
Secondly, we develop an iterative post-training adaptive precision search
algorithm that optimizes the bit-width for different LLM modules to balance
model accuracy, energy efficiency, and inference speed. Lastly, a suite of
hardware optimization techniques is proposed to maximally exploit the benefits
of the Anda format. These include a bit-plane-based data organization scheme,
Anda-enhanced processing units with bit-serial computation, and a runtime
bit-plane Anda compressor to simultaneously optimize storage, computation, and
memory footprints. Our evaluations on FPINT GeMM operations show that Anda
achieves a 2.4x speedup, 4.0x area efficiency, and 3.1x energy efficiency
improvement on average for popular LLMs including OPT, LLaMA, and LLaMA-2
series over the GPU-like FP-FP baseline. Anda demonstrates strong adaptability
across various application scenarios, accuracy requirements, and system
performance, enabling efficient LLM inference across a wide range of deployment
scenarios.

摘要：廣泛使用的、僅權重量化的巨量語言模型 (LLM) 利用低位元整數 (INT) 權重並保留浮點 (FP) 激活，在維持精準度的同時降低儲存需求。然而，這將能量和延遲瓶頸轉移到與昂貴的記憶體存取和運算相關的 FP 激活。現有的 LLM 加速器主要專注於運算最佳化，忽視了聯合最佳化 FP 運算和資料移動的潛力，特別是針對 LLM 推論中佔主導地位的 FP-INT GeMM 運算。
為了應對這些挑戰，我們探討了各種 LLM 模組中激活精度的敏感性及其對整體模型精度的影響。根據我們的發現，我們首先提出 Anda 資料類型：一種具有群組共用指數位元和動態尾數位元配置的自適應資料格式。其次，我們開發了一種反覆訓練後自適應精度的搜尋演算法，針對不同的 LLM 模組最佳化位元寬度，以平衡模型精度、能源效率和推論速度。最後，提出了一套硬體最佳化技術，以最大程度地利用 Anda 格式的優點。這些技術包括基於位元平面的資料組織架構、具有位元序列運算的 Anda 增強處理單元，以及同時最佳化儲存、運算和記憶體佔用空間的執行時期位元平面 Anda 壓縮器。我們對 FPINT GeMM 運算的評估顯示，與類 GPU 的 FP-FP 基準相比，Anda 對包括 OPT、LLaMA 和 LLaMA-2 系列在內的熱門 LLM 平均可實現 2.4 倍的速度提升、4.0 倍的面積效率和 3.1 倍的能源效率提升。Anda 在各種應用場景、精度要求和系統效能中展現出強大的適應性，可在廣泛的部署場景中實現高效的 LLM 推論。

##### **DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**
2411.15976v1 by Ruiqiang Xiao, Songning Lai, Yijun Yang, Jiemin Wu, Yutao Yue, Lei Zhu

Adapting machine learning models to new domains without labeled data,
especially when source data is inaccessible, is a critical challenge in
applications like medical imaging, autonomous driving, and remote sensing. This
task, known as Source-Free Unsupervised Domain Adaptation (SFUDA), involves
adapting a pre-trained model to a target domain using only unlabeled target
data, which can lead to issues such as overfitting, underfitting, and poor
generalization due to domain discrepancies and noise. Existing SFUDA methods
often rely on single-model architectures, struggling with uncertainty and
variability in the target domain. To address these challenges, we propose DRIVE
(Dual-Robustness through Information Variability and Entropy), a novel SFUDA
framework leveraging a dual-model architecture. The two models, initialized
with identical weights, work in parallel to capture diverse target domain
characteristics. One model is exposed to perturbations via projection gradient
descent (PGD) guided by mutual information, focusing on high-uncertainty
regions. We also introduce an entropy-aware pseudo-labeling strategy that
adjusts label weights based on prediction uncertainty, ensuring the model
focuses on reliable data while avoiding noisy regions. The adaptation process
has two stages: the first aligns the models on stable features using a mutual
information consistency loss, and the second dynamically adjusts the
perturbation level based on the loss from the first stage, encouraging the
model to explore a broader range of the target domain while preserving existing
performance. This enhances generalization capabilities and robustness against
interference. Evaluations on standard SFUDA benchmarks show that DRIVE
consistently outperforms previous methods, delivering improved adaptation
accuracy and stability across complex target domains.

摘要：<paragraph>在沒有標籤資料的情況下將機器學習模型調整到新的領域，特別是在無法取得原始資料時，是醫療影像、自動駕駛和遙測等應用中的一項關鍵挑戰。這項任務稱為無來源非監督領域適應 (SFUDA)，涉及使用僅有的未標籤目標資料將預先訓練的模型調整到目標領域，這可能會導致過度擬合、欠擬合和因領域差異和雜訊而導致的概化不良等問題。現有的 SFUDA 方法通常依賴於單一模型架構，難以應對目標領域中的不確定性和變異性。為了應對這些挑戰，我們提出了 DRIVE（透過資訊變異性和熵的雙重穩健性），一種利用雙模型架構的新穎 SFUDA 架構。這兩個模型以相同的權重初始化，並行工作以擷取不同的目標領域特徵。其中一個模型透過由互資訊引導的投影梯度下降 (PGD) 暴露於擾動，重點在於高度不確定的區域。我們還引入了一種熵感知偽標籤策略，該策略根據預測不確定性調整標籤權重，確保模型專注於可靠的資料，同時避免雜訊區域。適應過程分為兩個階段：第一個階段使用互資訊一致性損失在穩定特徵上對齊模型，第二個階段根據第一個階段的損失動態調整擾動級別，鼓勵模型探索目標領域的更廣泛範圍，同時保留現有的效能。這增強了概化能力和對干擾的穩健性。在標準 SFUDA 基準上的評估顯示，DRIVE 持續優於先前的各種方法，在複雜的目標領域中提供改善的適應準確性和穩定性。</paragraph>

##### **Partial Identifiability and Misspecification in Inverse Reinforcement Learning**
2411.15951v1 by Joar Skalse, Alessandro Abate

The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function
$R$ from a policy $\pi$. This problem is difficult, for several reasons. First
of all, there are typically multiple reward functions which are compatible with
a given policy; this means that the reward function is only *partially
identifiable*, and that IRL contains a certain fundamental degree of ambiguity.
Secondly, in order to infer $R$ from $\pi$, an IRL algorithm must have a
*behavioural model* of how $\pi$ relates to $R$. However, the true relationship
between human preferences and human behaviour is very complex, and practically
impossible to fully capture with a simple model. This means that the
behavioural model in practice will be *misspecified*, which raises the worry
that it might lead to unsound inferences if applied to real-world data. In this
paper, we provide a comprehensive mathematical analysis of partial
identifiability and misspecification in IRL. Specifically, we fully
characterise and quantify the ambiguity of the reward function for all of the
behavioural models that are most common in the current IRL literature. We also
provide necessary and sufficient conditions that describe precisely how the
observed demonstrator policy may differ from each of the standard behavioural
models before that model leads to faulty inferences about the reward function
$R$. In addition to this, we introduce a cohesive framework for reasoning about
partial identifiability and misspecification in IRL, together with several
formal tools that can be used to easily derive the partial identifiability and
misspecification robustness of new IRL models, or analyse other kinds of reward
learning algorithms.

摘要：逆向強化學習 (IRL) 的目標是從策略 $\pi$ 推論獎勵函數 $R$。這個問題很困難，原因有幾個。首先，通常有多個獎勵函數與給定的策略相容；這表示獎勵函數僅 *部分可識別*，而 IRL 包含一定程度的基本模稜兩可性。其次，為了從 $\pi$ 推論 $R$，IRL 演算法必須具備 $\pi$ 與 $R$ 相關性的 *行為模式*。然而，人類偏好與人類行為之間的真正關係非常複雜，而且實際上不可能使用簡單模型完全捕捉。這表示實際上的行為模式將會 *錯誤指定*，這引發了擔憂，即如果將其應用於真實世界資料，可能會導致不健全的推論。在本文中，我們提供了對 IRL 中部分可識別性和錯誤指定的全面數學分析。具體來說，我們全面描述並量化了當前 IRL 文獻中最常見的所有行為模式的獎勵函數的模稜兩可性。我們還提供了必要且充分的條件，精確描述了觀察到的示範策略可能與每個標準行為模式有何不同，然後該模型才會對獎勵函數 $R$ 產生錯誤的推論。除此之外，我們還引入了一個關於 IRL 中部分可識別性和錯誤指定的推理的內聚框架，以及幾個可以輕鬆推導新 IRL 模型的部分可識別性和錯誤指定健全性的正式工具，或分析其他類型的獎勵學習演算法。

##### **Generative Context Distillation**
2411.15927v1 by Haebin Shin, Lei Ji, Yeyun Gong, Sungdong Kim, Eunbi Choi, Minjoon Seo

Prompts used in recent large language model based applications are often
fixed and lengthy, leading to significant computational overhead. To address
this challenge, we propose Generative Context Distillation (GCD), a lightweight
prompt internalization method that employs a joint training approach. This
method not only replicates the behavior of models with prompt inputs but also
generates the content of the prompt along with reasons for why the model's
behavior should change accordingly. We demonstrate that our approach
effectively internalizes complex prompts across various agent-based application
scenarios. For effective training without interactions with the dedicated
environments, we introduce a data synthesis technique that autonomously
collects conversational datasets by swapping the roles of the agent and
environment. This method is especially useful in scenarios where only a
predefined prompt is available without a corresponding training dataset. By
internalizing complex prompts, Generative Context Distillation enables
high-performance and efficient inference without the need for explicit prompts.

摘要：最近基於大型語言模型的應用程式所使用的提示通常是固定的且冗長的，導致顯著的運算負擔。為了應對這個挑戰，我們提出生成式脈絡蒸餾 (GCD)，這是一種輕量級的提示內化方法，採用聯合訓練方法。此方法不僅複製了具有提示輸入的模型的行為，還生成了提示的內容以及模型行為應相應改變的原因。我們證明了我們的做法有效地將複雜的提示內化到各種基於代理的應用場景中。為了在不與專用環境互動的情況下進行有效訓練，我們引入了一種資料合成技術，該技術通過交換代理和環境的角色來自主收集對話資料集。此方法在只有預定義提示而沒有相應訓練資料集的情況下特別有用。通過內化複雜的提示，生成式脈絡蒸餾可以在不需要明確提示的情況下實現高性能和有效的推理。

##### **Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan**
2411.15923v1 by Saba Zahid, Sajid Ghuffar, Obaid-ur-Rehman, Syed Roshaan Ali Shah

This study explores the effectiveness of multi-temporal satellite imagery for
better functional field boundary delineation using deep learning semantic
segmentation architecture on two distinct geographical and multi-scale farming
systems of Netherlands and Pakistan. Multidate images of April, August and
October 2022 were acquired for PlanetScope and Sentinel-2 in sub regions of
Netherlands and November 2022, February and March 2023 for selected area of
Dunyapur in Pakistan. For Netherlands, Basic registration crop parcels (BRP)
vector layer was used as labeled training data. while self-crafted field
boundary vector data were utilized for Pakistan. Four deep learning models with
UNET architecture were evaluated using different combinations of multi-date
images and NDVI stacks in the Netherlands subregions. A comparative analysis of
IoU scores assessed the effectiveness of the proposed multi-date NDVI stack
approach. These findings were then applied for transfer learning, using
pre-trained models from the Netherlands on the selected area in Pakistan.
Additionally, separate models were trained using self-crafted field boundary
data for Pakistan, and combined models were developed using data from both the
Netherlands and Pakistan. Results indicate that multi-date NDVI stacks provide
additional temporal context, reflecting crop growth over different times of the
season. The study underscores the critical role of multi-scale ground
information from diverse geographical areas in developing robust and
universally applicable models for field boundary delineation. The results also
highlight the importance of fine spatial resolution for extraction of field
boundaries in regions with small scale framing. The findings can be extended to
multi-scale implementations for improved automatic field boundary delineation
in heterogeneous agricultural environments.

摘要：本研究探討了多時相衛星影像的有效性，以使用深度學習語義分割結構在荷蘭和巴基斯坦兩個不同的地理和多尺度農業系統中，進行更好的功能性田間邊界描繪。2022 年 4 月、8 月和 10 月的多日期影像已針對 PlanetScope 和 Sentinel-2 獲取，位於荷蘭的次區域，以及 2022 年 11 月、2023 年 2 月和 3 月，位於巴基斯坦 Dunyapur 的特定區域。對於荷蘭，基本註冊作物地塊 (BRP) 向量圖層用作標籤訓練資料。而自製的田間邊界向量資料則用於巴基斯坦。使用 UNET 結構的四種深度學習模型在荷蘭次區域中使用多日期影像和 NDVI 堆疊的不同組合進行評估。IoU 分數的比較分析評估了所提出的多日期 NDVI 堆疊方法的有效性。然後將這些發現應用於遷移學習，使用來自荷蘭的預訓練模型，於巴基斯坦的特定區域。此外，使用自製的田間邊界資料為巴基斯坦訓練了單獨的模型，並使用來自荷蘭和巴基斯坦的資料開發了組合模型。結果表明，多日期 NDVI 堆疊提供了額外的時間脈絡，反映了不同季節作物的生長情況。本研究強調了來自不同地理區域的多尺度地面資訊在開發用於田間邊界描繪的強健且普遍適用的模型中的關鍵作用。結果也突出了精細空間解析度對於在小規模取景區域中萃取田間邊界的重要性。這些發現可以擴展到多尺度實作，以改善異質農業環境中的自動田間邊界描繪。

##### **A Training-Free Approach for Music Style Transfer with Latent Diffusion Models**
2411.15913v1 by Sooyoung Kim, Joonwoo Kwon, Heehwan Wang, Shinjae Yoo, Yuewei Lin, Jiook Cha

Music style transfer, while offering exciting possibilities for personalized
music generation, often requires extensive training or detailed textual
descriptions. This paper introduces a novel training-free approach leveraging
pre-trained Latent Diffusion Models (LDMs). By manipulating the self-attention
features of the LDM, we effectively transfer the style of reference music onto
content music without additional training. Our method achieves superior style
transfer and melody preservation compared to existing methods. This work opens
new creative avenues for personalized music generation.

摘要：音樂風格轉移在提供個人化音樂生成的令人興奮的可能性時，通常需要大量的訓練或詳細的文字描述。本文介紹了一種利用預訓練潛在擴散模型 (LDM) 的新無訓練方法。通過操縱 LDM 的自我注意特徵，我們有效地將參考音樂的風格轉移到內容音樂上，而無需額外的訓練。與現有方法相比，我們的技術實現了出色的風格轉移和旋律保留。這項工作為個人化音樂生成開啟了新的創作途徑。

##### **Bimanual Grasp Synthesis for Dexterous Robot Hands**
2411.15903v1 by Yanming Shao, Chenxi Xiao

Humans naturally perform bimanual skills to handle large and heavy objects.
To enhance robots' object manipulation capabilities, generating effective
bimanual grasp poses is essential. Nevertheless, bimanual grasp synthesis for
dexterous hand manipulators remains underexplored. To bridge this gap, we
propose the BimanGrasp algorithm for synthesizing bimanual grasps on 3D
objects. The BimanGrasp algorithm generates grasp poses by optimizing an energy
function that considers grasp stability and feasibility. Furthermore, the
synthesized grasps are verified using the Isaac Gym physics simulation engine.
These verified grasp poses form the BimanGrasp-Dataset, the first large-scale
synthesized bimanual dexterous hand grasp pose dataset to our knowledge. The
dataset comprises over 150k verified grasps on 900 objects, facilitating the
synthesis of bimanual grasps through a data-driven approach. Last, we propose
BimanGrasp-DDPM, a diffusion model trained on the BimanGrasp-Dataset. This
model achieved a grasp synthesis success rate of 69.87\% and significant
acceleration in computational speed compared to BimanGrasp algorithm.

摘要：人類自然會執行雙手技能來處理大型和重型物體。
為了增強機器人的物體操作能力，產生有效的
雙手抓握姿勢至關重要。儘管如此，靈巧的手部操縱器的
雙手抓握合成仍然未得到充分探索。為了彌補這一差距，我們
提出了 BimanGrasp 演算法，用於在 3D
物體上合成雙手抓握。BimanGrasp 演算法透過最佳化考量抓握穩定性和可行性的能量函數來產生抓握姿勢。此外，
合成的抓握使用 Isaac Gym 物理模擬引擎進行驗證。
這些經過驗證的抓握姿勢構成了 BimanGrasp-Dataset，據我們所知，這是第一個大規模合成的雙手靈巧手抓握姿勢資料集。該
資料集包含在 900 個物體上經過驗證的 150k 個抓握，促進了透過資料驅動方法合成雙手抓握。最後，我們提出了
BimanGrasp-DDPM，這是一個在 BimanGrasp-Dataset 上訓練的擴散模型。與 BimanGrasp 演算法相比，此
模型實現了 69.87% 的抓握合成成功率，並顯著加速了運算速度。

##### **Distribution-aware Online Continual Learning for Urban Spatio-Temporal Forecasting**
2411.15893v1 by Chengxin Wang, Gary Tan, Swagato Barman Roy, Beng Chin Ooi

Urban spatio-temporal (ST) forecasting is crucial for various urban
applications such as intelligent scheduling and trip planning. Previous studies
focus on modeling ST correlations among urban locations in offline settings,
which often neglect the non-stationary nature of urban ST data, particularly,
distribution shifts over time. This oversight can lead to degraded performance
in real-world scenarios. In this paper, we first analyze the distribution
shifts in urban ST data, and then introduce DOST, a novel online continual
learning framework tailored for ST data characteristics. DOST employs an
adaptive ST network equipped with a variable-independent adapter to address the
unique distribution shifts at each urban location dynamically. Further, to
accommodate the gradual nature of these shifts, we also develop an
awake-hibernate learning strategy that intermittently fine-tunes the adapter
during the online phase to reduce computational overhead. This strategy
integrates a streaming memory update mechanism designed for urban ST sequential
data, enabling effective network adaptation to new patterns while preventing
catastrophic forgetting. Experimental results confirm DOST's superiority over
state-of-the-art models on four real-world datasets, providing online forecasts
within an average of 0.1 seconds and achieving a 12.89% reduction in forecast
errors compared to baseline models.

摘要：城市時空 (ST) 預測對於各項城市應用至關重要，例如智慧排程和行程規劃。先前的研究專注於在離線設定中建模城市位置之間的 ST 關聯性，這常常忽略了城市 ST 資料的非平穩特性，特別是隨著時間推移的分配轉移。這種疏忽可能導致實際場景中的效能下降。在本文中，我們首先分析城市 ST 資料中的分配轉移，然後介紹 DOST，一個針對 ST 資料特性的新穎線上持續學習架構。DOST 使用配備可變獨立適配器的自適應 ST 網路，以動態解決每個城市位置的獨特分配轉移。此外，為了適應這些轉移的漸進式特性，我們還開發了一種清醒休眠學習策略，在線上階段間歇性地微調適配器，以降低運算負擔。此策略整合了一個專為城市 ST 順序資料設計的串流記憶體更新機制，讓網路能有效適應新的模式，同時防止災難性遺忘。實驗結果證實 DOST 在四個真實世界資料集上優於最先進的模型，在平均 0.1 秒內提供線上預測，並與基準模型相比，預測誤差減少了 12.89%。

##### **Evaluating Large Language Models for Causal Modeling**
2411.15888v1 by Houssam Razouk, Leonie Benischke, Georg Niess, Roman Kern

In this paper, we consider the process of transforming causal domain
knowledge into a representation that aligns more closely with guidelines from
causal data science. To this end, we introduce two novel tasks related to
distilling causal domain knowledge into causal variables and detecting
interaction entities using LLMs. We have determined that contemporary LLMs are
helpful tools for conducting causal modeling tasks in collaboration with human
experts, as they can provide a wider perspective. Specifically, LLMs, such as
GPT-4-turbo and Llama3-70b, perform better in distilling causal domain
knowledge into causal variables compared to sparse expert models, such as
Mixtral-8x22b. On the contrary, sparse expert models such as Mixtral-8x22b
stand out as the most effective in identifying interaction entities. Finally,
we highlight the dependency between the domain where the entities are generated
and the performance of the chosen LLM for causal modeling.

摘要：在本文中，我们考慮將因果領域知識轉換為與因果數據科學指南更緊密對齊的表示形式的過程。為此，我們引入了兩個新任務，分別是將因果領域知識提煉為因果變數，以及使用 LLM 檢測交互作用實體。我們已確定，當代 LLM 是與人類專家合作進行因果建模任務的有用工具，因為它們可以提供更廣闊的觀點。具體來說，與稀疏專家模型（例如 Mixtral-8x22b）相比，LLM（例如 GPT-4-turbo 和 Llama3-70b）在將因果領域知識提煉為因果變數方面表現得更好。相反，稀疏專家模型（例如 Mixtral-8x22b）在識別交互作用實體方面表現最為出色。最後，我們強調了實體生成所在的領域與所選 LLM 在因果建模中的效能之間的依賴關係。

##### **LLMs Do Not Think Step-by-step In Implicit Reasoning**
2411.15862v1 by Yijiong Yu

It has been well-known that Chain-of-Thought can remarkably enhance LLMs'
performance on complex tasks. However, because it also introduces slower
inference speeds and higher computational costs, many researches have attempted
to use implicit CoT, which does not need LLMs to explicitly generate the
intermediate steps. But there is still gap between their efficacy and typical
explicit CoT methods. This leaves us a doubt that, does implicit CoT really
equal to explicit CoT? Therefore, in this study, we address this question
through experiments. We probe the information of intermediate steps from the
model's hidden states when it is performing implicit CoT. The results
surprisingly indicate that LLMs hardly think about intermediate steps,
suggesting they may just rely on experience rather than strict step-by-step
reasoning. Moreover, we find LLMs' implicit reasoning capabilities are
susceptible and unstable, reaffirming the necessity of explicit CoT to
effectively support complex tasks.

摘要：眾所周知，思想鏈可以顯著增強 LLM 在複雜任務上的性能。然而，由於它還會導致較慢的推論速度和較高的計算成本，許多研究嘗試使用隱式 CoT，它不需要 LLM 明確生成中間步驟。但它們的效能與典型的顯式 CoT 方法之間仍然存在差距。這讓我們產生一個疑問，隱式 CoT 是否真的等於顯式 CoT？因此，在本研究中，我們透過實驗來探討這個問題。我們在模型執行隱式 CoT 時，探討其隱藏狀態中關於中間步驟的資訊。結果令人驚訝地表明，LLM 幾乎不會考慮中間步驟，這表明它們可能僅依賴於經驗，而不是嚴格的逐步推理。此外，我們發現 LLM 的隱式推理能力是敏感且不穩定的，這再次肯定了顯式 CoT 在有效支援複雜任務中的必要性。

##### **Unveiling the Superior Paradigm: A Comparative Study of Source-Free Domain Adaptation and Unsupervised Domain Adaptation**
2411.15844v1 by Fan Wang, Zhongyi Han, Xingbo Liu, Xin Gao, Yilong Yin

In domain adaptation, there are two popular paradigms: Unsupervised Domain
Adaptation (UDA), which aligns distributions using source data, and Source-Free
Domain Adaptation (SFDA), which leverages pre-trained source models without
accessing source data. Evaluating the superiority of UDA versus SFDA is an open
and timely question with significant implications for deploying adaptive
algorithms in practical applications. In this study, we demonstrate through
predictive coding theory and extensive experiments on multiple benchmark
datasets that SFDA generally outperforms UDA in real-world scenarios.
Specifically, SFDA offers advantages in time efficiency, storage requirements,
targeted learning objectives, reduced risk of negative transfer, and increased
robustness against overfitting. Notably, SFDA is particularly effective in
mitigating negative transfer when there are substantial distribution
discrepancies between source and target domains. Additionally, we introduce a
novel data-model fusion scenario, where data sharing among stakeholders varies
(e.g., some provide raw data while others provide only models), and reveal that
traditional UDA and SFDA methods do not fully exploit their potential in this
context. To address this limitation and capitalize on the strengths of SFDA, we
propose a novel weight estimation method that effectively integrates available
source data into multi-SFDA (MSFDA) approaches, thereby enhancing model
performance within this scenario. This work provides a thorough analysis of UDA
versus SFDA and advances a practical approach to model adaptation across
diverse real-world environments.

摘要：<paragraph>在領域適應中，有兩種流行的範例：無監督領域適應 (UDA)，它使用來源數據對齊分佈，以及無來源領域適應 (SFDA)，它利用預訓練的來源模型而無需存取來源數據。評估 UDA 與 SFDA 的優越性是一個開放且及時的問題，對於在實際應用中部署適應性演算法具有重大意義。在本研究中，我們透過預測編碼理論和在多個基準資料集上的廣泛實驗證明，SFDA 通常在實際場景中優於 UDA。具體來說，SFDA 在時間效率、儲存需求、目標學習目標、降低負面轉移風險和增加對過度擬合的穩健性方面具有優勢。值得注意的是，當來源和目標領域之間存在實質性分佈差異時，SFDA 在減輕負面轉移方面特別有效。此外，我們引入了一個新穎的資料模型融合場景，其中利益相關者之間的資料共享有所不同（例如，一些提供原始資料，而另一些只提供模型），並揭示傳統的 UDA 和 SFDA 方法並未充分發揮其在這種情況下的潛力。為了解決這個限制並利用 SFDA 的優勢，我們提出了一種新穎的權重估計方法，該方法有效地將可用的來源數據整合到多 SFDA (MSFDA) 方法中，從而增強模型在這種場景中的效能。這項工作對 UDA 與 SFDA 進行了徹底的分析，並提出了一種實用的方法來適應不同實際環境中的模型。</paragraph>

##### **Efficient and Private: Memorisation under differentially private parameter-efficient fine-tuning in language models**
2411.15831v1 by Olivia Ma, Jonathan Passerat-Palmbach, Dmitrii Usynin

Fine-tuning large language models (LLMs) for specific tasks introduces
privacy risks, as models may inadvertently memorise and leak sensitive training
data. While Differential Privacy (DP) offers a solution to mitigate these
risks, it introduces significant computational and performance trade-offs,
particularly with standard fine-tuning approaches. Previous work has primarily
focused on full-parameter updates, which are computationally intensive and may
not fully leverage DPs potential in large models. In this work, we address
these shortcomings by investigating Parameter-Efficient Fine-Tuning (PEFT)
methods under DP constraints. We show that PEFT methods achieve comparable
performance to standard fine-tuning while requiring fewer parameters and
significantly reducing privacy leakage. Furthermore, we incorporate a data
poisoning experiment involving intentional mislabelling to assess model
memorisation and directly measure privacy risks. Our findings indicate that
PEFT methods not only provide a promising alternative but also serve as a
complementary approach for privacy-preserving, resource-efficient fine-tuning
of LLMs.

摘要：微調大型語言模型 (LLM) 以應對特定任務時會引發隱私風險，因為模型可能會無意間記憶並洩露敏感的訓練資料。雖然差分隱私 (DP) 提供了解決這些風險的方法，但它會造成顯著的運算和效能取捨，特別是採用標準微調方法時。先前的研究主要集中於全參數更新，這在運算上很密集，而且可能無法充分發揮大型模型中 DP 的潛力。在這項研究中，我們透過研究 DP 約束下的參數有效微調 (PEFT) 方法來解決這些缺點。我們顯示 PEFT 方法可達成與標準微調相當的效能，同時所需參數較少，並大幅降低隱私外洩。此外，我們納入一項資料中毒實驗，其中涉及故意錯誤標籤，以評估模型記憶並直接衡量隱私風險。我們的研究結果顯示，PEFT 方法不僅提供了一個有希望的替代方案，也作為一種補充方法，用於 LLM 的隱私保護、資源有效微調。

##### **Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?**
2411.15821v1 by Aryan Sajith, Krishna Chaitanya Rao Kathala

This study investigates the relative impact of training data quality versus
quantity on the performance of small language models (SLMs), utilizing the
TinyStories dataset for empirical analysis. Analysis of dataset variations with
respect to size (25% and 50% of the original size) and duplication (controlled
rates of 25%, 50%, 75%, and 100%) were performed. Model performance was
evaluated based on the validation loss, accuracy, and perplexity metrics.
Results indicate training data quality plays a more significant role in the
overall performance of SLMs, especially given scale of this experiment. Minimal
duplication positively impacted model accuracy (+0.87% increase in accuracy at
25% duplication) without significantly increasing perplexity (+0.52% increase
going from 0% to 25% duplication) but excessive duplication led to pronounced
performance degradation (-40% drop in accuracy at 100% duplication). The
implications of this exploration extend beyond just model performance; training
large-scale models imposes significant financial and computational burdens,
which can be prohibitive for organizations, individuals, and the public at
large, especially in developing countries. Additionally, the energy consumption
associated with large-scale training raises environmental concerns.
Understanding the relative importance of data quality versus quantity could
democratize AI technology, making advanced models more accessible and
sustainable for all.

摘要：本研究調查訓練資料品質相對於數量對小型語言模型 (SLM) 效能的相對影響，並利用 TinyStories 資料集進行實證分析。分析資料集變異，包括大小（原始大小的 25% 和 50%）和重複（受控比率 25%、50%、75% 和 100%）。模型效能根據驗證損失、準確度和困惑度指標進行評估。結果顯示訓練資料品質在 SLM 的整體效能中扮演更重要的角色，特別是在此實驗的規模下。最小的重複對模型準確度產生正面影響（重複率 25% 時準確度增加 +0.87%），且不會顯著增加困惑度（從 0% 到 25% 重複時增加 +0.52%），但過度重複會導致效能顯著下降（重複率 100% 時準確度下降 -40%）。此探討的意義不只在於模型效能；訓練大型模型會造成顯著的財務和運算負擔，對組織、個人和廣大民眾而言可能難以負擔，尤其是在開發中國家。此外，與大型訓練相關的能源消耗也引發環境問題。了解資料品質相對於數量的相對重要性可以使 AI 技術民主化，讓先進模型更易於取得，且對所有人而言更具永續性。

##### **FastTrackTr:Towards Fast Multi-Object Tracking with Transformers**
2411.15811v1 by Pan Liao, Feng Yang, Di Wu, Jinwen Yu, Wenhui Zhao, Bo Liu

Transformer-based multi-object tracking (MOT) methods have captured the
attention of many researchers in recent years. However, these models often
suffer from slow inference speeds due to their structure or other issues. To
address this problem, we revisited the Joint Detection and Tracking (JDT)
method by looking back at past approaches. By integrating the original JDT
approach with some advanced theories, this paper employs an efficient method of
information transfer between frames on the DETR, constructing a fast and novel
JDT-type MOT framework: FastTrackTr. Thanks to the superiority of this
information transfer method, our approach not only reduces the number of
queries required during tracking but also avoids the excessive introduction of
network structures, ensuring model simplicity. Experimental results indicate
that our method has the potential to achieve real-time tracking and exhibits
competitive tracking accuracy across multiple datasets.

摘要：近年來，基於 Transformer 的多目標追蹤 (MOT) 方法已引起許多研究人員的關注。然而，這些模型由於其結構或其他問題，通常會導致推論速度較慢。為了解決這個問題，我們回顧過去的方法，重新審視了聯合偵測與追蹤 (JDT) 方法。本文透過將原始 JDT 方法與一些先進的理論整合，在 DETR 上採用了一種有效的幀間資訊傳遞方法，建構了一個快速且新穎的 JDT 類型 MOT 框架：FastTrackTr。由於這種資訊傳遞方法的優越性，我們的做法不僅減少了追蹤過程中所需的查詢數量，還避免了過度引入網路結構，確保了模型的簡潔性。實驗結果表明，我們的模型具有實現即時追蹤的潛力，並在多個資料集上展現出具有競爭力的追蹤準確度。

##### **Benchmarking Active Learning for NILM**
2411.15805v1 by Dhruv Patel, Ankita Kumari Jain, Haikoo Khandor, Xhitij Choudhary, Nipun Batra

Non-intrusive load monitoring (NILM) focuses on disaggregating total
household power consumption into appliance-specific usage. Many advanced NILM
methods are based on neural networks that typically require substantial amounts
of labeled appliance data, which can be challenging and costly to collect in
real-world settings. We hypothesize that appliance data from all households
does not uniformly contribute to NILM model improvements. Thus, we propose an
active learning approach to selectively install appliance monitors in a limited
number of houses. This work is the first to benchmark the use of active
learning for strategically selecting appliance-level data to optimize NILM
performance. We first develop uncertainty-aware neural networks for NILM and
then install sensors in homes where disaggregation uncertainty is highest.
Benchmarking our method on the publicly available Pecan Street Dataport
dataset, we demonstrate that our approach significantly outperforms a standard
random baseline and achieves performance comparable to models trained on the
entire dataset. Using this approach, we achieve comparable NILM accuracy with
approximately 30% of the data, and for a fixed number of sensors, we observe up
to a 2x reduction in disaggregation errors compared to random sampling.

摘要：非侵入式負載監控 (NILM) 專注於將家庭總用電量分解為特定電器的用量。許多先進的 NILM 方法都基於神經網路，而神經網路通常需要大量的標籤電器資料，這在現實世界中可能很難且成本高昂。我們假設來自所有家庭的電器資料並不會對 NILM 模型的改進產生均等的貢獻。因此，我們提出了一種主動學習方法，以選擇性地安裝電器監控器在有限數量的房屋中。這項工作首次對主動學習的使用進行基準測試，以策略性地選擇電器層級資料來最佳化 NILM 效能。我們首先為 NILM 開發了具有不確定性感知的神經網路，然後在分解不確定性最高的家戶中安裝感測器。在公開的 Pecan Street Dataport 資料集上對我們的模型進行基準測試，我們證明了我們的方法顯著優於標準隨機基準，並且達到了與在整個資料集上訓練的模型相當的效能。使用這種方法，我們以大約 30% 的資料達到了相當的 NILM 精確度，並且對於固定數量的感測器，我們觀察到與隨機抽樣相比，分解誤差減少了 2 倍。

