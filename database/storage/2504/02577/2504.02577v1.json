{"2504.02577": {"publish_time": "2025-04-03", "title": "Reasoning Inconsistencies and How to Mitigate Them in Deep Learning", "paper_summary": "The recent advancements in Deep Learning models and techniques have led to\nsignificant strides in performance across diverse tasks and modalities.\nHowever, while the overall capabilities of models show promising growth, our\nunderstanding of their internal reasoning processes remains limited,\nparticularly concerning systematic inconsistencies or errors patterns of\nlogical or inferential flaws. These inconsistencies may manifest as\ncontradictory outputs, failure to generalize across similar tasks, or erroneous\nconclusions in specific contexts. Even detecting and measuring such reasoning\ndiscrepancies is challenging, as they may arise from opaque internal\nprocedures, biases and imbalances in training data, or the inherent complexity\nof the task. Without effective methods to detect, measure, and mitigate these\nerrors, there is a risk of deploying models that are biased, exploitable, or\nlogically unreliable. This thesis aims to address these issues by producing\nnovel methods for deep learning models that reason over knowledge graphs,\nnatural language, and images. The thesis contributes two techniques for\ndetecting and quantifying predictive inconsistencies originating from opaque\ninternal procedures in natural language and image processing models. To\nmitigate inconsistencies from biases in training data, this thesis presents a\ndata efficient sampling method to improve fairness and performance and a\nsynthetic dataset generation approach in low resource scenarios. Finally, the\nthesis offers two techniques to optimize the models for complex reasoning\ntasks. These methods enhance model performance while allowing for more faithful\nand interpretable exploration and exploitation during inference. Critically,\nthis thesis provides a comprehensive framework to improve the robustness,\nfairness, and interpretability of deep learning models across diverse tasks and\nmodalities.", "paper_summary_zh": "\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u548c\u6280\u8853\u7684\u6700\u65b0\u9032\u5c55\u5df2\u5728\u5404\u7a2e\u4efb\u52d9\u548c\u6a21\u5f0f\u4e2d\u5e36\u4f86\u4e86\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\u3002\u7136\u800c\uff0c\u5118\u7ba1\u6a21\u578b\u7684\u6574\u9ad4\u80fd\u529b\u5448\u73fe\u51fa\u6709\u5e0c\u671b\u7684\u589e\u9577\uff0c\u4f46\u6211\u5011\u5c0d\u5176\u5167\u90e8\u63a8\u7406\u904e\u7a0b\u7684\u7406\u89e3\u4ecd\u7136\u6709\u9650\uff0c\u5c24\u5176\u662f\u95dc\u65bc\u908f\u8f2f\u6216\u63a8\u7406\u7f3a\u9677\u7684\u7cfb\u7d71\u6027\u4e0d\u4e00\u81f4\u6216\u932f\u8aa4\u6a21\u5f0f\u3002\u9019\u4e9b\u4e0d\u4e00\u81f4\u6027\u53ef\u80fd\u8868\u73fe\u70ba\u77db\u76fe\u7684\u8f38\u51fa\u3001\u7121\u6cd5\u5728\u76f8\u4f3c\u4efb\u52d9\u4e2d\u6cdb\u5316\u6216\u5728\u7279\u5b9a\u60c5\u6cc1\u4e0b\u5f97\u51fa\u932f\u8aa4\u7684\u7d50\u8ad6\u3002\u5373\u4f7f\u6aa2\u6e2c\u548c\u6e2c\u91cf\u6b64\u985e\u63a8\u7406\u5dee\u7570\u4e5f\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u5b83\u5011\u53ef\u80fd\u6e90\u65bc\u4e0d\u900f\u660e\u7684\u5167\u90e8\u7a0b\u5e8f\u3001\u8a13\u7df4\u6578\u64da\u4e2d\u7684\u504f\u5dee\u548c\u4e0d\u5e73\u8861\u6216\u4efb\u52d9\u672c\u8eab\u7684\u8907\u96dc\u6027\u3002\u5982\u679c\u6c92\u6709\u6709\u6548\u7684\u65b9\u6cd5\u4f86\u6aa2\u6e2c\u3001\u6e2c\u91cf\u548c\u6e1b\u8f15\u9019\u4e9b\u932f\u8aa4\uff0c\u5247\u5b58\u5728\u90e8\u7f72\u6709\u504f\u5dee\u3001\u53ef\u5229\u7528\u6216\u908f\u8f2f\u4e0a\u4e0d\u53ef\u9760\u7684\u6a21\u578b\u7684\u98a8\u96aa\u3002\u672c\u8ad6\u6587\u65e8\u5728\u901a\u904e\u70ba\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u751f\u6210\u65b0\u7684\u65b9\u6cd5\u4f86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u9019\u4e9b\u6a21\u578b\u53ef\u4ee5\u5c0d\u77e5\u8b58\u5716\u8b5c\u3001\u81ea\u7136\u8a9e\u8a00\u548c\u5716\u50cf\u9032\u884c\u63a8\u7406\u3002\u672c\u8ad6\u6587\u8ca2\u737b\u4e86\u5169\u7a2e\u6280\u8853\uff0c\u7528\u65bc\u6aa2\u6e2c\u548c\u91cf\u5316\u6e90\u81ea\u81ea\u7136\u8a9e\u8a00\u548c\u5716\u50cf\u8655\u7406\u6a21\u578b\u4e2d\u4e0d\u900f\u660e\u5167\u90e8\u7a0b\u5e8f\u7684\u9810\u6e2c\u4e0d\u4e00\u81f4\u6027\u3002\u70ba\u4e86\u6e1b\u8f15\u8a13\u7df4\u6578\u64da\u4e2d\u504f\u5dee\u9020\u6210\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u672c\u8ad6\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u6578\u64da\u9ad8\u6548\u7684\u63a1\u6a23\u65b9\u6cd5\u4f86\u63d0\u9ad8\u516c\u5e73\u6027\u548c\u6027\u80fd\uff0c\u4ee5\u53ca\u4e00\u7a2e\u5728\u4f4e\u8cc7\u6e90\u60c5\u6cc1\u4e0b\u7684\u5408\u6210\u6578\u64da\u96c6\u751f\u6210\u65b9\u6cd5\u3002\u6700\u5f8c\uff0c\u672c\u8ad6\u6587\u63d0\u4f9b\u4e86\u5169\u7a2e\u6280\u8853\u4f86\u512a\u5316\u6a21\u578b\u4ee5\u57f7\u884c\u8907\u96dc\u7684\u63a8\u7406\u4efb\u52d9\u3002\u9019\u4e9b\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u540c\u6642\u5141\u8a31\u5728\u63a8\u7406\u904e\u7a0b\u4e2d\u9032\u884c\u66f4\u5fe0\u5be6\u4e14\u53ef\u89e3\u91cb\u7684\u63a2\u7d22\u548c\u5229\u7528\u3002\u81f3\u95dc\u91cd\u8981\u7684\u662f\uff0c\u672c\u8ad6\u6587\u63d0\u4f9b\u4e86\u4e00\u500b\u5168\u9762\u7684\u6846\u67b6\u4f86\u63d0\u9ad8\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u5728\u5404\u7a2e\u4efb\u52d9\u548c\u6a21\u5f0f\u4e2d\u7684\u7a69\u5065\u6027\u3001\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91cb\u6027\u3002\n", "author": "Erik Arakelyan et.al.", "authors": "Erik Arakelyan", "id": "2504.02577v1", "paper_url": "http://arxiv.org/abs/2504.02577v1", "repo": "null"}}