{"2309.11196": {"publish_time": "2023-09-20", "title": "When to Trust AI: Advances and Challenges for Certification of Neural Networks", "paper_summary": "Artificial intelligence (AI) has been advancing at a fast pace and it is now\npoised for deployment in a wide range of applications, such as autonomous\nsystems, medical diagnosis and natural language processing. Early adoption of\nAI technology for real-world applications has not been without problems,\nparticularly for neural networks, which may be unstable and susceptible to\nadversarial examples. In the longer term, appropriate safety assurance\ntechniques need to be developed to reduce potential harm due to avoidable\nsystem failures and ensure trustworthiness. Focusing on certification and\nexplainability, this paper provides an overview of techniques that have been\ndeveloped to ensure safety of AI decisions and discusses future challenges.", "paper_summary_zh": "", "author": "Marta Kwiatkowska et.al.", "authors": "Marta Kwiatkowska,Xiyue Zhang", "id": "2309.11196v1", "paper_url": "http://arxiv.org/abs/2309.11196v1", "repo": "null"}}