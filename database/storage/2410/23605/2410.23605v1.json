{"2410.23605": {"publish_time": "2024-10-31", "title": "Dynamic Uncertainty Ranking: Enhancing In-Context Learning for Long-Tail Knowledge in LLMs", "paper_summary": "Large language models (LLMs) can learn vast amounts of knowledge from diverse\ndomains during pre-training. However, long-tail knowledge from specialized\ndomains is often scarce and underrepresented, rarely appearing in the models'\nmemorization. Prior work has shown that in-context learning (ICL) with\nretriever augmentation can help LLMs better capture long-tail knowledge,\nreducing their reliance on pre-trained data. Despite these advances, we observe\nthat LLM predictions for long-tail questions remain uncertain to variations in\nretrieved samples. To take advantage of the uncertainty in ICL for guiding LLM\npredictions toward correct answers on long-tail samples, we propose a\nreinforcement learning-based dynamic uncertainty ranking method for ICL that\naccounts for the varying impact of each retrieved sample on LLM predictions.\nOur approach prioritizes more informative and stable samples while demoting\nmisleading ones, updating rankings based on the feedback from the LLM w.r.t.\neach retrieved sample. To enhance training efficiency and reduce query costs,\nwe introduce a learnable dynamic ranking threshold, adjusted when the model\nencounters negative prediction shifts. Experimental results on various\nquestion-answering datasets from different domains show that our method\noutperforms the best baseline by $2.76\\%$, with a notable $5.96\\%$ boost in\naccuracy on long-tail questions that elude zero-shot inference.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u80fd\u5728\u9810\u8a13\u7df4\u671f\u9593\u5f9e\u591a\u5143\u9818\u57df\u5b78\u7fd2\u5927\u91cf\u7684\u77e5\u8b58\u3002\u7136\u800c\uff0c\u4f86\u81ea\u7279\u5b9a\u9818\u57df\u7684\u9577\u5c3e\u77e5\u8b58\u901a\u5e38\u7a00\u5c11\u4e14\u4ee3\u8868\u6027\u4e0d\u8db3\uff0c\u5f88\u5c11\u51fa\u73fe\u5728\u6a21\u578b\u7684\u8a18\u61b6\u4e2d\u3002\u5148\u524d\u7684\u7814\u7a76\u8868\u660e\uff0c\u7d50\u5408\u6aa2\u7d22\u589e\u5f37\u7684\u8108\u7d61\u4e2d\u5b78\u7fd2 (ICL) \u80fd\u5e6b\u52a9 LLM \u66f4\u4f73\u64f7\u53d6\u9577\u5c3e\u77e5\u8b58\uff0c\u6e1b\u5c11\u5b83\u5011\u5c0d\u9810\u8a13\u7df4\u8cc7\u6599\u7684\u4f9d\u8cf4\u3002\u5118\u7ba1\u6709\u9019\u4e9b\u9032\u5c55\uff0c\u6211\u5011\u89c0\u5bdf\u5230 LLM \u5c0d\u9577\u5c3e\u554f\u984c\u7684\u9810\u6e2c\u4ecd\u4e0d\u78ba\u5b9a\u6aa2\u7d22\u5230\u7684\u6a23\u672c\u8b8a\u5316\u3002\u70ba\u4e86\u5229\u7528 ICL \u4e2d\u7684\u4e0d\u78ba\u5b9a\u6027\u4f86\u5f15\u5c0e LLM \u9810\u6e2c\u9577\u5c3e\u6a23\u672c\u7684\u6b63\u78ba\u7b54\u6848\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u5f37\u5316\u5b78\u7fd2\u7684\u52d5\u614b\u4e0d\u78ba\u5b9a\u6027\u6392\u5e8f\u65b9\u6cd5\uff0c\u7528\u65bc ICL\uff0c\u8a72\u65b9\u6cd5\u8003\u616e\u4e86\u6bcf\u500b\u6aa2\u7d22\u5230\u7684\u6a23\u672c\u5c0d LLM \u9810\u6e2c\u7684\u5f71\u97ff\u3002\u6211\u5011\u7684\u505a\u6cd5\u512a\u5148\u8003\u616e\u66f4\u591a\u8cc7\u8a0a\u4e14\u7a69\u5b9a\u7684\u6a23\u672c\uff0c\u540c\u6642\u964d\u7d1a\u8aa4\u5c0e\u6027\u7684\u6a23\u672c\uff0c\u6839\u64da LLM \u5c0d\u6bcf\u500b\u6aa2\u7d22\u5230\u7684\u6a23\u672c\u7684\u56de\u994b\u66f4\u65b0\u6392\u540d\u3002\u70ba\u4e86\u63d0\u9ad8\u8a13\u7df4\u6548\u7387\u4e26\u964d\u4f4e\u67e5\u8a62\u6210\u672c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u53ef\u5b78\u7fd2\u7684\u52d5\u614b\u6392\u540d\u95be\u503c\uff0c\u5728\u6a21\u578b\u9047\u5230\u8ca0\u9762\u9810\u6e2c\u8f49\u79fb\u6642\u9032\u884c\u8abf\u6574\u3002\u5728\u4f86\u81ea\u4e0d\u540c\u9818\u57df\u7684\u5404\u7a2e\u554f\u7b54\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u6bd4\u6700\u4f73\u57fa\u6e96\u9ad8\u51fa $2.76\\%$\uff0c\u5728\u8ff4\u907f\u96f6\u6b21\u63a8\u8ad6\u7684\u9577\u5c3e\u554f\u984c\u4e0a\uff0c\u6e96\u78ba\u5ea6\u986f\u8457\u63d0\u5347\u4e86 $5.96\\%$\u3002", "author": "Shuyang Yu et.al.", "authors": "Shuyang Yu, Runxue Bao, Parminder Bhatia, Taha Kass-Hout, Jiayu Zhou, Cao Xiao", "id": "2410.23605v1", "paper_url": "http://arxiv.org/abs/2410.23605v1", "repo": "null"}}