{"2409.20089": {"publish_time": "2024-09-30", "title": "Robust LLM safeguarding via refusal feature adversarial training", "paper_summary": "Large language models (LLMs) are vulnerable to adversarial attacks that can\nelicit harmful responses. Defending against such attacks remains challenging\ndue to the opacity of jailbreaking mechanisms and the high computational cost\nof training LLMs robustly. We demonstrate that adversarial attacks share a\nuniversal mechanism for circumventing LLM safeguards that works by ablating a\ndimension in the residual stream embedding space called the refusal feature. We\nfurther show that the operation of refusal feature ablation (RFA) approximates\nthe worst-case perturbation of offsetting model safety. Based on these\nfindings, we propose Refusal Feature Adversarial Training (ReFAT), a novel\nalgorithm that efficiently performs LLM adversarial training by simulating the\neffect of input-level attacks via RFA. Experiment results show that ReFAT\nsignificantly improves the robustness of three popular LLMs against a wide\nrange of adversarial attacks, with considerably less computational overhead\ncompared to existing adversarial training methods.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u653b\u64ca\uff0c\u9019\u4e9b\u653b\u64ca\u6703\u5f15\u767c\u6709\u5bb3\u7684\u56de\u61c9\u3002\u7531\u65bc\u8d8a\u7344\u6a5f\u5236\u7684\u4e0d\u900f\u660e\u6027\u4ee5\u53ca\u8a13\u7df4\u7a69\u5065\u7684 LLM \u7684\u9ad8\u904b\u7b97\u6210\u672c\uff0c\u9632\u79a6\u6b64\u985e\u653b\u64ca\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u6211\u5011\u8b49\u660e\u5c0d\u6297\u6027\u653b\u64ca\u5171\u7528\u4e00\u7a2e\u901a\u7528\u6a5f\u5236\u4f86\u898f\u907f LLM \u4fdd\u969c\u63aa\u65bd\uff0c\u9019\u7a2e\u6a5f\u5236\u901a\u904e\u6d88\u878d\u6b98\u5dee\u4e32\u6d41\u5d4c\u5165\u7a7a\u9593\u4e2d\u7a31\u70ba\u62d2\u7d55\u7279\u5fb5\u7684\u7dad\u5ea6\u4f86\u904b\u4f5c\u3002\u6211\u5011\u9032\u4e00\u6b65\u8868\u660e\uff0c\u62d2\u7d55\u7279\u5fb5\u6d88\u878d (RFA) \u7684\u64cd\u4f5c\u8fd1\u4f3c\u65bc\u62b5\u6d88\u6a21\u578b\u5b89\u5168\u6027\u7684\u6700\u58de\u60c5\u6cc1\u64fe\u52d5\u3002\u57fa\u65bc\u9019\u4e9b\u767c\u73fe\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u62d2\u7d55\u7279\u5fb5\u5c0d\u6297\u6027\u8a13\u7df4 (ReFAT)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u6f14\u7b97\u6cd5\uff0c\u901a\u904e RFA \u6a21\u64ec\u8f38\u5165\u7d1a\u5225\u653b\u64ca\u7684\u5f71\u97ff\uff0c\u6709\u6548\u5730\u57f7\u884c LLM \u5c0d\u6297\u6027\u8a13\u7df4\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u8207\u73fe\u6709\u7684\u5c0d\u6297\u6027\u8a13\u7df4\u65b9\u6cd5\u76f8\u6bd4\uff0cReFAT \u5927\u5e45\u63d0\u9ad8\u4e86\u4e09\u7a2e\u6d41\u884c\u7684 LLM \u5c0d\u5404\u7a2e\u5c0d\u6297\u6027\u653b\u64ca\u7684\u7a69\u5065\u6027\uff0c\u4e14\u904b\u7b97\u8ca0\u64d4\u986f\u8457\u964d\u4f4e\u3002", "author": "Lei Yu et.al.", "authors": "Lei Yu, Virginie Do, Karen Hambardzumyan, Nicola Cancedda", "id": "2409.20089v1", "paper_url": "http://arxiv.org/abs/2409.20089v1", "repo": "null"}}