
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-23**|**How Diffusion Models Learn to Factorize and Compose**|Qiyao Liang et.al.|[2408.13256v1](http://arxiv.org/abs/2408.13256v1)|null|
|**2024-08-23**|**Ensemble Modeling of Multiple Physical Indicators to Dynamically Phenotype Autism Spectrum Disorder**|Marie Huynh et.al.|[2408.13255v1](http://arxiv.org/abs/2408.13255v1)|null|
|**2024-08-23**|**Domain-specific long text classification from sparse relevant information**|Célia D'Cruz et.al.|[2408.13253v1](http://arxiv.org/abs/2408.13253v1)|null|
|**2024-08-23**|**Foundational Model for Electron Micrograph Analysis: Instruction-Tuning Small-Scale Language-and-Vision Assistant for Enterprise Adoption**|Sakhinana Sagar Srinivas et.al.|[2408.13248v1](http://arxiv.org/abs/2408.13248v1)|null|
|**2024-08-23**|**Data Exposure from LLM Apps: An In-depth Investigation of OpenAI's GPTs**|Evin Jaff et.al.|[2408.13247v1](http://arxiv.org/abs/2408.13247v1)|null|
|**2024-08-23**|**Which Prosodic Features Matter Most for Pragmatics?**|Nigel G. Ward et.al.|[2408.13240v1](http://arxiv.org/abs/2408.13240v1)|null|
|**2024-08-23**|**Multi-Layer Transformers Gradient Can be Approximated in Almost Linear Time**|Yingyu Liang et.al.|[2408.13233v1](http://arxiv.org/abs/2408.13233v1)|null|
|**2024-08-23**|**HBIC: A Biclustering Algorithm for Heterogeneous Datasets**|Adán José-García et.al.|[2408.13217v1](http://arxiv.org/abs/2408.13217v1)|null|
|**2024-08-23**|**EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods**|Hongcheng Ding et.al.|[2408.13214v1](http://arxiv.org/abs/2408.13214v1)|null|
|**2024-08-23**|**Optimal Quantum Circuit Design via Unitary Neural Networks**|M. Zomorodi et.al.|[2408.13211v1](http://arxiv.org/abs/2408.13211v1)|null|
|**2024-08-23**|**DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation**|Qiming Zhu et.al.|[2408.13204v1](http://arxiv.org/abs/2408.13204v1)|null|
|**2024-08-23**|**Instruct-DeBERTa: A Hybrid Approach for Aspect-based Sentiment Analysis on Textual Reviews**|Dineth Jayakody et.al.|[2408.13202v1](http://arxiv.org/abs/2408.13202v1)|null|
|**2024-08-23**|**Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating the Hallucination for Path Planning**|Hourui Deng et.al.|[2408.13184v1](http://arxiv.org/abs/2408.13184v1)|null|
|**2024-08-23**|**Lessons in co-creation: the inconvenient truths of inclusive sign language technology development**|Maartje De Meulder et.al.|[2408.13171v1](http://arxiv.org/abs/2408.13171v1)|null|
|**2024-08-23**|**Say No to Freeloader: Protecting Intellectual Property of Your Deep Model**|Lianyu Wang et.al.|[2408.13161v1](http://arxiv.org/abs/2408.13161v1)|null|
|**2024-08-23**|**Causal machine learning for sustainable agroecosystems**|Vasileios Sitokonstantinou et.al.|[2408.13155v1](http://arxiv.org/abs/2408.13155v1)|null|
|**2024-08-23**|**ShapeICP: Iterative Category-level Object Pose and Shape Estimation from Depth**|Yihao Zhang et.al.|[2408.13147v1](http://arxiv.org/abs/2408.13147v1)|null|
|**2024-08-23**|**Deep Learning at the Intersection: Certified Robustness as a Tool for 3D Vision**|Gabriel Pérez S et.al.|[2408.13135v1](http://arxiv.org/abs/2408.13135v1)|null|
|**2024-08-23**|**DeTPP: Leveraging Object Detection for Robust Long-Horizon Event Prediction**|Ivan Karpukhin et.al.|[2408.13131v1](http://arxiv.org/abs/2408.13131v1)|null|
|**2024-08-23**|**Analysis of child development facts and myths using text mining techniques and classification models**|Mehedi Tajrian et.al.|[2408.13091v1](http://arxiv.org/abs/2408.13091v1)|null|
|**2024-08-23**|**Map-Free Visual Relocalization Enhanced by Instance Knowledge and Depth Knowledge**|Mingyu Xiao et.al.|[2408.13085v1](http://arxiv.org/abs/2408.13085v1)|null|
|**2024-08-23**|**Multivariate Time-Series Anomaly Detection based on Enhancing Graph Attention Networks with Topological Analysis**|Zhe Liu et.al.|[2408.13082v1](http://arxiv.org/abs/2408.13082v1)|[link](https://github.com/ljj-cyber/topogdn)|
|**2024-08-23**|**AEMLO: AutoEncoder-Guided Multi-Label Oversampling**|Ao Zhou et.al.|[2408.13078v1](http://arxiv.org/abs/2408.13078v1)|null|
|**2024-08-23**|**Hierarchical Spatio-Temporal State-Space Modeling for fMRI Analysis**|Yuxiang Wei et.al.|[2408.13074v1](http://arxiv.org/abs/2408.13074v1)|null|
|**2024-08-23**|**cc-DRL: a Convex Combined Deep Reinforcement Learning Flight Control Design for a Morphing Quadrotor**|Tao Yang et.al.|[2408.13054v1](http://arxiv.org/abs/2408.13054v1)|null|
|**2024-08-23**|**SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks**|Kai-Wei Chang et.al.|[2408.13040v1](http://arxiv.org/abs/2408.13040v1)|null|
|**2024-08-23**|**VFM-Det: Towards High-Performance Vehicle Detection via Large Foundation Models**|Wentao Wu et.al.|[2408.13031v1](http://arxiv.org/abs/2408.13031v1)|[link](https://github.com/event-ahu/vfm-det)|
|**2024-08-23**|**In-Context Learning with Reinforcement Learning for Incomplete Utterance Rewriting**|Haowei Du et.al.|[2408.13028v1](http://arxiv.org/abs/2408.13028v1)|null|
|**2024-08-23**|**Systematic Evaluation of LLM-as-a-Judge in LLM Alignment Tasks: Explainable Metrics and Diverse Prompt Templates**|Hui Wei et.al.|[2408.13006v1](http://arxiv.org/abs/2408.13006v1)|null|
|**2024-08-23**|**CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution**|Ruiyang Xu et.al.|[2408.13001v1](http://arxiv.org/abs/2408.13001v1)|null|
|**2024-08-23**|**Enhancing Knowledge Tracing with Concept Map and Response Disentanglement**|Soonwook Park et.al.|[2408.12996v1](http://arxiv.org/abs/2408.12996v1)|[link](https://github.com/soonwook34/crkt)|
|**2024-08-23**|**RIFF: Inducing Rules for Fraud Detection from Decision Trees**|João Lucas Martins et.al.|[2408.12989v1](http://arxiv.org/abs/2408.12989v1)|null|
|**2024-08-23**|**Zeoformer: Coarse-Grained Periodic Graph Transformer for OSDA-Zeolite Affinity Prediction**|Xiangxiang Shen et.al.|[2408.12984v2](http://arxiv.org/abs/2408.12984v2)|null|
|**2024-08-23**|**QD-VMR: Query Debiasing with Contextual Understanding Enhancement for Video Moment Retrieval**|Chenghua Gao et.al.|[2408.12981v1](http://arxiv.org/abs/2408.12981v1)|null|
|**2024-08-23**|**MedDec: A Dataset for Extracting Medical Decisions from Discharge Summaries**|Mohamed Elgaar et.al.|[2408.12980v1](http://arxiv.org/abs/2408.12980v1)|[link](https://github.com/clu-uml/meddec)|
|**2024-08-23**|**Internal and External Knowledge Interactive Refinement Framework for Knowledge-Intensive Question Answering**|Haowei Du et.al.|[2408.12979v1](http://arxiv.org/abs/2408.12979v1)|null|
|**2024-08-23**|**Open Llama2 Model for the Lithuanian Language**|Artūras Nakvosas et.al.|[2408.12963v1](http://arxiv.org/abs/2408.12963v1)|null|
|**2024-08-23**|**Multimodal Contrastive In-Context Learning**|Yosuke Miyanishi et.al.|[2408.12959v1](http://arxiv.org/abs/2408.12959v1)|null|
|**2024-08-23**|**Causal-Guided Active Learning for Debiasing Large Language Models**|Zhouhao Sun et.al.|[2408.12942v1](http://arxiv.org/abs/2408.12942v1)|null|
|**2024-08-23**|**Trustworthy, Responsible, and Safe AI: A Comprehensive Architectural Framework for AI Safety with Challenges and Mitigations**|Chen Chen et.al.|[2408.12935v1](http://arxiv.org/abs/2408.12935v1)|null|
|**2024-08-23**|**What Do You Want? User-centric Prompt Generation for Text-to-image Synthesis via Multi-turn Guidance**|Yilun Liu et.al.|[2408.12910v1](http://arxiv.org/abs/2408.12910v1)|null|
|**2024-08-23**|**IAA: Inner-Adaptor Architecture Empowers Frozen Large Language Model with Multimodal Capabilities**|Bin Wang et.al.|[2408.12902v1](http://arxiv.org/abs/2408.12902v1)|null|
|**2024-08-23**|**Multiple Areal Feature Aware Transportation Demand Prediction**|Sumin Han et.al.|[2408.12890v1](http://arxiv.org/abs/2408.12890v1)|null|
|**2024-08-23**|**Spatio-Temporal Road Traffic Prediction using Real-time Regional Knowledge**|Sumin Han et.al.|[2408.12882v1](http://arxiv.org/abs/2408.12882v1)|null|
|**2024-08-23**|**Has Multimodal Learning Delivered Universal Intelligence in Healthcare? A Comprehensive Survey**|Qika Lin et.al.|[2408.12880v1](http://arxiv.org/abs/2408.12880v1)|null|
|**2024-08-23**|**Frequency-aware Feature Fusion for Dense Image Prediction**|Linwei Chen et.al.|[2408.12879v1](http://arxiv.org/abs/2408.12879v1)|null|
|**2024-08-23**|**DeepDelveAI: Identifying AI Related Documents in Large Scale Literature Data**|Zhou Xiaochen et.al.|[2408.12871v1](http://arxiv.org/abs/2408.12871v1)|null|
|**2024-08-23**|**Obfuscated Memory Malware Detection**|Sharmila S P et.al.|[2408.12866v1](http://arxiv.org/abs/2408.12866v1)|null|
|**2024-08-23**|**Memory-Efficient LLM Training with Online Subspace Descent**|Kaizhao Liang et.al.|[2408.12857v1](http://arxiv.org/abs/2408.12857v1)|[link](https://github.com/kyleliang919/online-subspace-descent)|
|**2024-08-23**|**Multi-Faceted Question Complexity Estimation Targeting Topic Domain-Specificity**|Sujay R et.al.|[2408.12850v1](http://arxiv.org/abs/2408.12850v1)|null|
|**2024-08-23**|**Online Fair Division with Contextual Bandits**|Arun Verma et.al.|[2408.12845v1](http://arxiv.org/abs/2408.12845v1)|null|
|**2024-08-23**|**Predicting Affective States from Screen Text Sentiment**|Songyan Teng et.al.|[2408.12844v1](http://arxiv.org/abs/2408.12844v1)|null|
|**2024-08-23**|**COVID-19 Probability Prediction Using Machine Learning: An Infectious Approach**|Mohsen Asghari Ilani et.al.|[2408.12841v1](http://arxiv.org/abs/2408.12841v1)|null|
|**2024-08-23**|**Exploring Machine Learning Models for Lung Cancer Level Classification: A comparative ML Approach**|Mohsen Asghari Ilani et.al.|[2408.12838v1](http://arxiv.org/abs/2408.12838v1)|null|
|**2024-08-23**|**Underwater SONAR Image Classification and Analysis using LIME-based Explainable Artificial Intelligence**|Purushothaman Natarajan et.al.|[2408.12837v1](http://arxiv.org/abs/2408.12837v1)|null|
|**2024-08-23**|**CLLMFS: A Contrastive Learning enhanced Large Language Model Framework for Few-Shot Named Entity Recognition**|Yafeng Zhang et.al.|[2408.12834v1](http://arxiv.org/abs/2408.12834v1)|null|
|**2024-08-23**|**LIMP: Large Language Model Enhanced Intent-aware Mobility Prediction**|Songwei Li et.al.|[2408.12832v1](http://arxiv.org/abs/2408.12832v1)|[link](https://github.com/tsinghua-fib-lab/limp)|
|**2024-08-23**|**Examining the Commitments and Difficulties Inherent in Multimodal Foundation Models for Street View Imagery**|Zhenyuan Yang et.al.|[2408.12821v1](http://arxiv.org/abs/2408.12821v1)|null|
|**2024-08-23**|**Staircase Cascaded Fusion of Lightweight Local Pattern Recognition and Long-Range Dependencies for Structural Crack Segmentation**|Hui Liu et.al.|[2408.12815v1](http://arxiv.org/abs/2408.12815v1)|[link](https://github.com/karl1109/crackscf)|
|**2024-08-23**|**Grounding Fallacies Misrepresenting Scientific Publications in Evidence**|Max Glockner et.al.|[2408.12812v1](http://arxiv.org/abs/2408.12812v1)|null|
|**2024-08-23**|**DutyTTE: Deciphering Uncertainty in Origin-Destination Travel Time Estimation**|Xiaowei Mao et.al.|[2408.12809v1](http://arxiv.org/abs/2408.12809v1)|null|
|**2024-08-23**|**VALE: A Multimodal Visual and Language Explanation Framework for Image Classifiers using eXplainable AI and Language Models**|Purushothaman Natarajan et.al.|[2408.12808v1](http://arxiv.org/abs/2408.12808v1)|null|
|**2024-08-23**|**Is Generative AI the Next Tactical Cyber Weapon For Threat Actors? Unforeseen Implications of AI Generated Cyber Attacks**|Yusuf Usman et.al.|[2408.12806v1](http://arxiv.org/abs/2408.12806v1)|null|
|**2024-08-23**|**A Safe Self-evolution Algorithm for Autonomous Driving Based on Data-Driven Risk Quantification Model**|Shuo Yang et.al.|[2408.12805v1](http://arxiv.org/abs/2408.12805v1)|null|
|**2024-08-23**|**Multi-Treatment Multi-Task Uplift Modeling for Enhancing User Growth**|Yuxiang Wei et.al.|[2408.12803v1](http://arxiv.org/abs/2408.12803v1)|null|
|**2024-08-23**|**Less for More: Enhancing Preference Learning in Generative Language Models with Automated Self-Curation of Training Corpora**|JoonHo Lee et.al.|[2408.12799v1](http://arxiv.org/abs/2408.12799v1)|null|
|**2024-08-23**|**BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks on Large Language Models**|Yige Li et.al.|[2408.12798v1](http://arxiv.org/abs/2408.12798v1)|null|
|**2024-08-23**|**Real-Time Posture Monitoring and Risk Assessment for Manual Lifting Tasks Using MediaPipe and LSTM**|Ereena Bagga et.al.|[2408.12796v1](http://arxiv.org/abs/2408.12796v1)|null|
|**2024-08-23**|**Context-Aware Temporal Embedding of Objects in Video Data**|Ahnaf Farhan et.al.|[2408.12789v1](http://arxiv.org/abs/2408.12789v1)|null|
|**2024-08-23**|**LLM-PBE: Assessing Data Privacy in Large Language Models**|Qinbin Li et.al.|[2408.12787v1](http://arxiv.org/abs/2408.12787v1)|null|
|**2024-08-23**|**The Model Mastery Lifecycle: A Framework for Designing Human-AI Interaction**|Mark Chignell et.al.|[2408.12781v1](http://arxiv.org/abs/2408.12781v1)|null|
|**2024-08-23**|**Quality or Quantity? On Data Scale and Diversity in Adapting Large Language Models for Low-Resource Translation**|Vivek Iyer et.al.|[2408.12780v1](http://arxiv.org/abs/2408.12780v1)|null|
|**2024-08-23**|**Investigating LLM Applications in E-Commerce**|Chester Palen-Michel et.al.|[2408.12779v1](http://arxiv.org/abs/2408.12779v1)|null|
|**2024-08-23**|**Intelligent OPC Engineer Assistant for Semiconductor Manufacturing**|Guojin Chen et.al.|[2408.12775v1](http://arxiv.org/abs/2408.12775v1)|null|
|**2024-08-23**|**Symmetric masking strategy enhances the performance of Masked Image Modeling**|Khanh-Binh Nguyen et.al.|[2408.12772v1](http://arxiv.org/abs/2408.12772v1)|null|
|**2024-08-22**|**Assessing Modality Bias in Video Question Answering Benchmarks with Multimodal Large Language Models**|Jean Park et.al.|[2408.12763v1](http://arxiv.org/abs/2408.12763v1)|null|
|**2024-08-22**|**Visual Verity in AI-Generated Imagery: Computational Metrics and Human-Centric Analysis**|Memoona Aziz et.al.|[2408.12762v1](http://arxiv.org/abs/2408.12762v1)|null|
|**2024-08-22**|**SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination Detection**|Mengya Hu et.al.|[2408.12748v1](http://arxiv.org/abs/2408.12748v1)|[link](https://github.com/microsoft/constrainedreasoner)|
|**2024-08-22**|**TReX- Reusing Vision Transformer's Attention for Efficient Xbar-based Computing**|Abhishek Moitra et.al.|[2408.12742v1](http://arxiv.org/abs/2408.12742v1)|null|
|**2024-08-22**|**Towards measuring fairness in speech recognition: Fair-Speech dataset**|Irina-Elena Veliche et.al.|[2408.12734v1](http://arxiv.org/abs/2408.12734v1)|null|
|**2024-08-22**|**SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And Model Merging**|Mohammadreza Pourreza et.al.|[2408.12733v1](http://arxiv.org/abs/2408.12733v1)|null|
|**2024-08-22**|**Macro-Queries: An Exploration into Guided Chart Generation from High Level Prompts**|Christopher J. Lee et.al.|[2408.12726v1](http://arxiv.org/abs/2408.12726v1)|null|
|**2024-08-22**|**Generating Realistic X-ray Scattering Images Using Stable Diffusion and Human-in-the-loop Annotations**|Zhuowen Zhao et.al.|[2408.12720v1](http://arxiv.org/abs/2408.12720v1)|[link](https://github.com/mlexchange/mlex_scientific_txt2image)|
|**2024-08-22**|**Towards Estimating Personal Values in Song Lyrics**|Andrew M. Demetriou et.al.|[2408.12694v1](http://arxiv.org/abs/2408.12694v1)|null|
|**2024-08-22**|**Unlocking Intrinsic Fairness in Stable Diffusion**|Eunji Kim et.al.|[2408.12692v1](http://arxiv.org/abs/2408.12692v1)|null|
|**2024-08-22**|**MultiMed: Massively Multimodal and Multitask Medical Understanding**|Shentong Mo et.al.|[2408.12682v1](http://arxiv.org/abs/2408.12682v1)|null|
|**2024-08-22**|**Can LLMs Understand Social Norms in Autonomous Driving Games?**|Boxuan Wang et.al.|[2408.12680v1](http://arxiv.org/abs/2408.12680v1)|null|
|**2024-08-22**|**Enhancing Transferability of Adversarial Attacks with GE-AdvGAN+: A Comprehensive Framework for Gradient Editing**|Zhibo Jin et.al.|[2408.12673v1](http://arxiv.org/abs/2408.12673v1)|null|
|**2024-08-22**|**Leveraging Information Consistency in Frequency and Spatial Domain for Adversarial Attacks**|Zhibo Jin et.al.|[2408.12670v1](http://arxiv.org/abs/2408.12670v1)|[link](https://github.com/lmbtough/fsa)|
|**2024-08-22**|**Benchmarking Counterfactual Interpretability in Deep Learning Models for Time Series Classification**|Ziwen Kan et.al.|[2408.12666v1](http://arxiv.org/abs/2408.12666v1)|null|
|**2024-08-22**|**Hierarchical Generative Modeling of Melodic Vocal Contours in Hindustani Classical Music**|Nithya Shikarpur et.al.|[2408.12658v1](http://arxiv.org/abs/2408.12658v1)|null|
|**2024-08-22**|**Controllable Text Generation for Large Language Models: A Survey**|Xun Liang et.al.|[2408.12599v1](http://arxiv.org/abs/2408.12599v1)|[link](https://github.com/iaar-shanghai/ctgsurvey)|
|**2024-08-22**|**ND-SDF: Learning Normal Deflection Fields for High-Fidelity Indoor Reconstruction**|Ziyu Tang et.al.|[2408.12598v1](http://arxiv.org/abs/2408.12598v1)|null|
|**2024-08-22**|**xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations**|Can Qin et.al.|[2408.12590v1](http://arxiv.org/abs/2408.12590v1)|null|
|**2024-08-22**|**AI-driven Transformer Model for Fault Prediction in Non-Linear Dynamic Automotive System**|Priyanka Kumar et.al.|[2408.12638v1](http://arxiv.org/abs/2408.12638v1)|null|
|**2024-08-22**|**Building and better understanding vision-language models: insights and future directions**|Hugo Laurençon et.al.|[2408.12637v1](http://arxiv.org/abs/2408.12637v1)|null|
|**2024-08-22**|**RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment**|Xiaohan Wang et.al.|[2408.12579v1](http://arxiv.org/abs/2408.12579v1)|null|
|**2024-08-22**|**A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language**|Ekdeep Singh Lubana et.al.|[2408.12578v1](http://arxiv.org/abs/2408.12578v1)|[link](https://github.com/ekdeepslubana/conceptpercolation)|
|**2024-08-22**|**Enhanced Parking Perception by Multi-Task Fisheye Cross-view Transformers**|Antonyo Musabini et.al.|[2408.12575v1](http://arxiv.org/abs/2408.12575v1)|null|
|**2024-08-22**|**MuMA-ToM: Multi-modal Multi-Agent Theory of Mind**|Haojun Shi et.al.|[2408.12574v2](http://arxiv.org/abs/2408.12574v2)|null|

#### Abstracts
##### **How Diffusion Models Learn to Factorize and Compose**
2408.13256v1 by Qiyao Liang, Ziming Liu, Mitchell Ostrow, Ila Fiete

Diffusion models are capable of generating photo-realistic images that
combine elements which likely do not appear together in the training set,
demonstrating the ability to compositionally generalize. Nonetheless, the
precise mechanism of compositionality and how it is acquired through training
remains elusive. Inspired by cognitive neuroscientific approaches, we consider
a highly reduced setting to examine whether and when diffusion models learn
semantically meaningful and factorized representations of composable features.
We performed extensive controlled experiments on conditional Denoising
Diffusion Probabilistic Models (DDPMs) trained to generate various forms of 2D
Gaussian data. We found that the models learn factorized but not fully
continuous manifold representations for encoding continuous features of
variation underlying the data. With such representations, models demonstrate
superior feature compositionality but limited ability to interpolate over
unseen values of a given feature. Our experimental results further demonstrate
that diffusion models can attain compositionality with few compositional
examples, suggesting a more efficient way to train DDPMs. Finally, we connect
manifold formation in diffusion models to percolation theory in physics,
offering insight into the sudden onset of factorized representation learning.
Our thorough toy experiments thus contribute a deeper understanding of how
diffusion models capture compositional structure in data.

摘要：擴散模型能夠產生逼真的圖片，結合了訓練集中可能不會同時出現的元素，展現出組合概括的能力。儘管如此，組合性的精確機制以及它是如何透過訓練習得的仍然難以捉摸。受認知神經科學方法的啟發，我們考慮了一個高度簡化的設定，以檢視擴散模型是否以及何時學習可組合特徵的語義有意義且分解的表示。我們對條件式去噪擴散機率模型 (DDPM) 執行了廣泛的受控實驗，訓練這些模型來產生各種形式的 2D 高斯資料。我們發現這些模型學習了分解但並非完全連續流形表示，用於編碼資料中連續變異的特徵。有了這樣的表示，模型展現出優異的特徵組合性，但插補給定特徵中未見值的的能力有限。我們的實驗結果進一步證明擴散模型可以透過少數組合範例達到組合性，這表示訓練 DDPM 的方式更有效率。最後，我們將擴散模型中的流形形成與物理中的滲流理論連結起來，洞察分解表示學習的突然發生。我們徹底的玩具實驗因此有助於更深入地了解擴散模型如何擷取資料中的組合結構。

##### **Ensemble Modeling of Multiple Physical Indicators to Dynamically Phenotype Autism Spectrum Disorder**
2408.13255v1 by Marie Huynh, Aaron Kline, Saimourya Surabhi, Kaitlyn Dunlap, Onur Cezmi Mutlu, Mohammadmahdi Honarmand, Parnian Azizian, Peter Washington, Dennis P. Wall

Early detection of autism, a neurodevelopmental disorder marked by social
communication challenges, is crucial for timely intervention. Recent
advancements have utilized naturalistic home videos captured via the mobile
application GuessWhat. Through interactive games played between children and
their guardians, GuessWhat has amassed over 3,000 structured videos from 382
children, both diagnosed with and without Autism Spectrum Disorder (ASD). This
collection provides a robust dataset for training computer vision models to
detect ASD-related phenotypic markers, including variations in emotional
expression, eye contact, and head movements. We have developed a protocol to
curate high-quality videos from this dataset, forming a comprehensive training
set. Utilizing this set, we trained individual LSTM-based models using eye
gaze, head positions, and facial landmarks as input features, achieving test
AUCs of 86%, 67%, and 78%, respectively. To boost diagnostic accuracy, we
applied late fusion techniques to create ensemble models, improving the overall
AUC to 90%. This approach also yielded more equitable results across different
genders and age groups. Our methodology offers a significant step forward in
the early detection of ASD by potentially reducing the reliance on subjective
assessments and making early identification more accessibly and equitable.

摘要：及早發現自閉症，一種以社交溝通障礙為特徵的神經發育障礙，對於及時介入至關重要。最近的進展利用了通過行動應用程式 GuessWhat 捕捉到的自然居家影片。透過孩童與其監護人之間進行的互動遊戲，GuessWhat 已經累積了來自 382 名孩童的 3,000 多部結構化影片，這些孩童有的被診斷出患有自閉症譜系障礙 (ASD)，有的則沒有。此集合提供了一個強大的資料集，用於訓練電腦視覺模型以偵測與 ASD 相關的表型標記，包括情緒表達、眼神接觸和頭部動作的變化。我們已經開發了一個從此資料集中策劃高品質影片的協定，形成了全面的訓練集。利用此集合，我們使用眼睛注視、頭部位置和臉部標記作為輸入特徵，訓練了個別的 LSTM 基礎模型，分別達到了 86%、67% 和 78% 的測試 AUC。為了提高診斷準確度，我們應用後期融合技術來建立整體模型，將整體 AUC 提升至 90%。此方法也產生了不同性別和年齡組之間更公平的結果。我們的技術為 ASD 的早期偵測提供了顯著的進展，因為它有可能減少對主觀評估的依賴，並讓早期識別更易於取得且更公平。

##### **Domain-specific long text classification from sparse relevant information**
2408.13253v1 by Célia D'Cruz, Jean-Marc Bereder, Frédéric Precioso, Michel Riveill

Large Language Models have undoubtedly revolutionized the Natural Language
Processing field, the current trend being to promote one-model-for-all tasks
(sentiment analysis, translation, etc.). However, the statistical mechanisms at
work in the larger language models struggle to exploit the relevant information
when it is very sparse, when it is a weak signal. This is the case, for
example, for the classification of long domain-specific documents, when the
relevance relies on a single relevant word or on very few relevant words from
technical jargon. In the medical domain, it is essential to determine whether a
given report contains critical information about a patient's condition. This
critical information is often based on one or few specific isolated terms. In
this paper, we propose a hierarchical model which exploits a short list of
potential target terms to retrieve candidate sentences and represent them into
the contextualized embedding of the target term(s) they contain. A pooling of
the term(s) embedding(s) entails the document representation to be classified.
We evaluate our model on one public medical document benchmark in English and
on one private French medical dataset. We show that our narrower hierarchical
model is better than larger language models for retrieving relevant long
documents in a domain-specific context.

摘要：大型語言模型無疑徹底改變了自然語言處理領域，目前的趨勢是推廣一種適用於所有任務的模型（情緒分析、翻譯等）。然而，大型語言模型中運作的統計機制難以利用相關資訊，當資訊非常稀疏時，當它是一個微弱訊號時。例如，在長領域特定文件分類的情況下，當相關性依賴於單一相關字詞或技術術語中極少數的相關字詞時，就是這種情況。在醫療領域，確定特定報告是否包含有關患者病情的關鍵資訊至關重要。這些關鍵資訊通常基於一個或幾個特定的孤立術語。在本文中，我們提出了一個分層模型，它利用潛在目標術語的簡短清單來擷取候選句子，並將它們表示為它們所包含的目標術語的語境化嵌入。術語嵌入的匯集需要對要分類的文件表示進行分類。我們在一個公開的英文醫療文件基準和一個私人的法文醫療資料集上評估我們的模型。我們證明，我們較狹窄的分層模型比大型語言模型更適合在特定領域的語境中擷取相關的長文件。

##### **Foundational Model for Electron Micrograph Analysis: Instruction-Tuning Small-Scale Language-and-Vision Assistant for Enterprise Adoption**
2408.13248v1 by Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana

Semiconductor imaging and analysis are critical yet understudied in deep
learning, limiting our ability for precise control and optimization in
semiconductor manufacturing. We introduce a small-scale multimodal framework
for analyzing semiconductor electron microscopy images (MAEMI) through
vision-language instruction tuning. We generate a customized
instruction-following dataset using large multimodal models on microscopic
image analysis. We perform knowledge transfer from larger to smaller models
through knowledge distillation, resulting in improved accuracy of smaller
models on visual question answering (VQA) tasks. This approach eliminates the
need for expensive, human expert-annotated datasets for microscopic image
analysis tasks. Enterprises can further finetune MAEMI on their intellectual
data, enhancing privacy and performance on low-cost consumer hardware. Our
experiments show that MAEMI outperforms traditional methods, adapts to data
distribution shifts, and supports high-throughput screening.

摘要：半導體成像和分析在深度學習中至關重要，但尚未得到充分研究，這限制了我們在半導體製造中精確控制和最佳化的能力。我們引入了一個小規模多模態框架，通過視覺語言指令調整來分析半導體電子顯微鏡圖像 (MAEMI)。我們使用大型多模態模型在微觀圖像分析上生成一個自訂的指令遵循資料集。我們透過知識蒸餾從較大的模型執行知識轉移到較小的模型，進而提升較小模型在視覺問答 (VQA) 任務上的準確度。此方法消除了對微觀圖像分析任務昂貴的人工專家註解資料集的需求。企業可以在其智慧資料上進一步微調 MAEMI，以增強隱私和低成本消費硬體的效能。我們的實驗表明，MAEMI 優於傳統方法，能適應資料分佈轉移，並支援高通量篩選。

##### **Data Exposure from LLM Apps: An In-depth Investigation of OpenAI's GPTs**
2408.13247v1 by Evin Jaff, Yuhao Wu, Ning Zhang, Umar Iqbal

LLM app ecosystems are quickly maturing and supporting a wide range of use
cases, which requires them to collect excessive user data. Given that the LLM
apps are developed by third-parties and that anecdotal evidence suggests LLM
platforms currently do not strictly enforce their policies, user data shared
with arbitrary third-parties poses a significant privacy risk. In this paper we
aim to bring transparency in data practices of LLM apps. As a case study, we
study OpenAI's GPT app ecosystem. We develop an LLM-based framework to conduct
the static analysis of natural language-based source code of GPTs and their
Actions (external services) to characterize their data collection practices.
Our findings indicate that Actions collect expansive data about users,
including sensitive information prohibited by OpenAI, such as passwords. We
find that some Actions, including related to advertising and analytics, are
embedded in multiple GPTs, which allow them to track user activities across
GPTs. Additionally, co-occurrence of Actions exposes as much as 9.5x more data
to them, than it is exposed to individual Actions. Lastly, we develop an
LLM-based privacy policy analysis framework to automatically check the
consistency of data collection by Actions with disclosures in their privacy
policies. Our measurements indicate that the disclosures for most of the
collected data types are omitted in privacy policies, with only 5.8% of Actions
clearly disclosing their data collection practices.

摘要：LLM 應用程式生態系統快速成熟，並支援廣泛的使用案例，這需要他們收集過多的使用者資料。由於 LLM 應用程式是由第三方開發，而且軼事證據表明 LLM 平台目前並未嚴格執行其政策，因此與任意第三方共用的使用者資料會構成重大的隱私風險。在本文中，我們旨在為 LLM 應用程式的資料實務帶來透明度。作為案例研究，我們研究了 OpenAI 的 GPT 應用程式生態系統。我們開發了一個基於 LLM 的架構來執行 GPT 及其動作（外部服務）的基於自然語言的原始碼靜態分析，以描述其資料收集實務。我們的研究結果表明，動作會收集關於使用者的廣泛資料，包括 OpenAI 禁止的敏感資訊，例如密碼。我們發現，包括與廣告和分析相關的一些動作都內嵌於多個 GPT 中，這讓它們能夠追蹤使用者在 GPT 中的活動。此外，動作的共現會讓它們公開多達 9.5 倍的資料，比公開給個別動作的資料還要多。最後，我們開發了一個基於 LLM 的隱私權政策分析架構，以自動檢查動作的資料收集與其隱私權政策中揭露的資訊是否一致。我們的測量結果表明，大多數收集資料類型的揭露都省略在隱私權政策中，只有 5.8% 的動作明確揭露其資料收集實務。

##### **Which Prosodic Features Matter Most for Pragmatics?**
2408.13240v1 by Nigel G. Ward, Divette Marco, Olac Fuentes

We investigate which prosodic features matter most in conveying prosodic
functions. We use the problem of predicting human perceptions of pragmatic
similarity among utterance pairs to evaluate the utility of prosodic features
of different types. We find, for example, that duration-related features are
more important than pitch-related features, and that utterance-initial features
are more important than utterance-final features. Further, failure analysis
indicates that modeling using pitch features only often fails to handle
important pragmatic functions, and suggests that several generally-neglected
acoustic and prosodic features are pragmatically significant, including
nasality and vibrato. These findings can guide future basic research in
prosody, and suggest how to improve speech synthesis evaluation, among other
applications.

摘要：我們探討在傳達語調功能時，哪些語調特徵最重要。我們使用預測人類對語句對之間語用相似性的感知的問題，來評估不同類型語調特徵的效用。例如，我們發現與音高相關的特徵比與時長相關的特徵更重要，而語句開頭的特徵比語句結尾的特徵更重要。此外，失敗分析表明，僅使用音高特徵進行建模通常無法處理重要的語用功能，並表明幾個通常被忽略的聲學和語調特徵在語用上具有重要意義，包括鼻音和顫音。這些發現可以指導語調的未來基礎研究，並提出如何改進語音合成評估，以及其他應用。

##### **Multi-Layer Transformers Gradient Can be Approximated in Almost Linear Time**
2408.13233v1 by Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Yufa Zhou

The quadratic computational complexity in the self-attention mechanism of
popular transformer architectures poses significant challenges for training and
inference, particularly in terms of efficiency and memory requirements. Towards
addressing these challenges, this paper introduces a novel fast computation
method for gradient calculation in multi-layer transformer models. Our approach
enables the computation of gradients for the entire multi-layer transformer
model in almost linear time $n^{1+o(1)}$, where $n$ is the input sequence
length. This breakthrough significantly reduces the computational bottleneck
associated with the traditional quadratic time complexity. Our theory holds for
any loss function and maintains a bounded approximation error across the entire
model. Furthermore, our analysis can hold when the multi-layer transformer
model contains many practical sub-modules, such as residual connection, casual
mask, and multi-head attention. By improving the efficiency of gradient
computation in large language models, we hope that our work will facilitate the
more effective training and deployment of long-context language models based on
our theoretical results.

摘要：在流行的 Transformer 架構的自注意力機制中的二次計算複雜度對訓練和推論提出了重大挑戰，特別是在效率和記憶體需求方面。為了應對這些挑戰，本文介紹了一種新穎的快速計算方法，用於多層 Transformer 模型中的梯度計算。我們的做法可以在幾乎線性的時間 $n^{1+o(1)}$ 中計算整個多層 Transformer 模型的梯度，其中 $n$ 是輸入序列長度。這項突破大大減少了與傳統二次時間複雜度相關的計算瓶頸。我們的理論適用於任何損失函數，並在整個模型中保持有界的近似誤差。此外，當多層 Transformer 模型包含許多實用的子模組時，例如殘差連接、因果遮罩和多頭注意力，我們的分析也能成立。通過提高大型語言模型中梯度計算的效率，我們希望我們的成果將有助於根據我們的理論結果更有效地訓練和部署基於長語境的語言模型。

##### **HBIC: A Biclustering Algorithm for Heterogeneous Datasets**
2408.13217v1 by Adán José-García, Julie Jacques, Clément Chauvet, Vincent Sobanski, Clarisse Dhaenens

Biclustering is an unsupervised machine-learning approach aiming to cluster
rows and columns simultaneously in a data matrix. Several biclustering
algorithms have been proposed for handling numeric datasets. However,
real-world data mining problems often involve heterogeneous datasets with mixed
attributes. To address this challenge, we introduce a biclustering approach
called HBIC, capable of discovering meaningful biclusters in complex
heterogeneous data, including numeric, binary, and categorical data. The
approach comprises two stages: bicluster generation and bicluster model
selection. In the initial stage, several candidate biclusters are generated
iteratively by adding and removing rows and columns based on the frequency of
values in the original matrix. In the second stage, we introduce two approaches
for selecting the most suitable biclusters by considering their size and
homogeneity. Through a series of experiments, we investigated the suitability
of our approach on a synthetic benchmark and in a biomedical application
involving clinical data of systemic sclerosis patients. The evaluation
comparing our method to existing approaches demonstrates its ability to
discover high-quality biclusters from heterogeneous data. Our biclustering
approach is a starting point for heterogeneous bicluster discovery, leading to
a better understanding of complex underlying data structures.

摘要：雙聚類是一種非監督機器學習方法，旨在同時對資料矩陣中的列和行進行聚類。已提出多種雙聚類演算法來處理數值資料集。然而，現實世界的資料探勘問題通常涉及具有混合屬性的異質資料集。為了應對這一挑戰，我們引入了一種名為 HBIC 的雙聚類方法，它能夠在複雜的異質資料（包括數值、二進制和類別資料）中發現有意義的雙聚類。該方法包括兩個階段：雙聚類生成和雙聚類模型選擇。在初始階段，通過根據原始矩陣中的值頻率新增和移除列和行，反覆生成多個候選雙聚類。在第二階段，我們引入了兩種方法，通過考慮雙聚類的大小和同質性來選擇最合適的雙聚類。通過一系列實驗，我們研究了我們的方法在合成基準和涉及全身性硬化症患者臨床資料的生物醫學應用中的適用性。將我們的演算法與現有方法進行比較，評估結果證明了其從異質資料中發現高品質雙聚類的能力。我們的雙聚類方法是異質雙聚類發現的起點，有助於更好地理解複雜的底層資料結構。

##### **EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods**
2408.13214v1 by Hongcheng Ding, Xuanze Zhao, Zixiao Jiang, Shamsul Nahar Abdullah, Deshinta Arrova Dewi

Accurate forecasting of the EUR/USD exchange rate is crucial for investors,
businesses, and policymakers. This paper proposes a novel framework, IUS, that
integrates unstructured textual data from news and analysis with structured
data on exchange rates and financial indicators to enhance exchange rate
prediction. The IUS framework employs large language models for sentiment
polarity scoring and exchange rate movement classification of texts. These
textual features are combined with quantitative features and input into a
Causality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is then
used to forecast the EUR/USD exchange rate. Experiments demonstrate that the
proposed method outperforms benchmark models, reducing MAE by 10.69% and RMSE
by 9.56% compared to the best performing baseline. Results also show the
benefits of data fusion, with the combination of unstructured and structured
data yielding higher accuracy than structured data alone. Furthermore, feature
selection using the top 12 important quantitative features combined with the
textual features proves most effective. The proposed IUS framework and
Optuna-Bi-LSTM model provide a powerful new approach for exchange rate
forecasting through multi-source data integration.

摘要：歐元/美元匯率的準確預測對投資者、企業和政策制定者至關重要。本文提出了一個新框架 IUS，它將來自新聞和分析的非結構化文本數據與匯率和財務指標的結構化數據整合在一起，以增強匯率預測。IUS 框架採用大型語言模型進行情緒極性評分和文本的匯率變動分類。這些文本特徵與定量特徵相結合，並輸入因果特徵生成器。然後使用 Optuna 優化的雙向 LSTM 模型來預測歐元/美元匯率。實驗表明，所提出的方法優於基準模型，與性能最佳的基線相比，MAE 降低了 10.69%，RMSE 降低了 9.56%。結果還表明了數據融合的好處，非結構化數據和結構化數據的組合比僅使用結構化數據產生更高的準確度。此外，使用最重要的 12 個定量特徵與文本特徵相結合的特徵選擇被證明是最有效的。所提出的 IUS 框架和 Optuna-Bi-LSTM 模型通過多源數據集成提供了一種強大的匯率預測新方法。

##### **Optimal Quantum Circuit Design via Unitary Neural Networks**
2408.13211v1 by M. Zomorodi, H. Amini, M. Abbaszadeh, J. Sohrabi, V. Salari, P. Plawiak

The process of translating a quantum algorithm into a form suitable for
implementation on a quantum computing platform is crucial but yet challenging.
This entails specifying quantum operations with precision, a typically
intricate task. In this paper, we present an alternative approach: an automated
method for synthesizing the functionality of a quantum algorithm into a quantum
circuit model representation. Our methodology involves training a neural
network model using diverse input-output mappings of the quantum algorithm. We
demonstrate that this trained model can effectively generate a quantum circuit
model equivalent to the original algorithm. Remarkably, our observations
indicate that the trained model achieves near-perfect mapping of unseen inputs
to their respective outputs.

摘要：將量子演算法轉換為適合在量子運算平台上執行的形式的過程至關重要，但卻極具挑戰性。
這需要精確地指定量子運算，這通常是一項複雜的任務。在本文中，我們提出了一種替代方法：一種將量子演算法的功能合成到量子電路模型表示中的自動化方法。我們的做法包括使用量子演算法的多樣化輸入輸出對應來訓練神經網路模型。我們證明了這個訓練好的模型可以有效地產生等同於原始演算法的量子電路模型。值得注意的是，我們的觀察結果表明，訓練好的模型可以將未見過的輸入近乎完美地對應到它們各自的輸出。

##### **DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation**
2408.13204v1 by Qiming Zhu, Jialun Cao, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, Shing-Chi Cheung

Code benchmarks such as HumanEval are widely adopted to evaluate the
capabilities of Large Language Models (LLMs), providing insights into their
strengths and weaknesses. However, current benchmarks primarily exercise LLMs'
capability on common coding tasks (e.g., bubble sort, greatest common divisor),
leaving domain-specific coding tasks (e.g., computation, system, cryptography)
unexplored. To fill this gap, we propose a multi-domain code benchmark,
DOMAINEVAL, designed to evaluate LLMs' coding capabilities thoroughly. Our
pipeline works in a fully automated manner, enabling a push-bottom construction
from code repositories into formatted subjects under study. Interesting
findings are observed by evaluating 12 representative LLMs against DOMAINEVAL.
We notice that LLMs are generally good at computation tasks while falling short
on cryptography and system coding tasks. The performance gap can be as much as
68.94% (80.94% - 12.0%) in some LLMs. We also observe that generating more
samples can increase the overall performance of LLMs, while the domain bias may
even increase. The contributions of this study include a code generation
benchmark dataset DOMAINEVAL, encompassing six popular domains, a fully
automated pipeline for constructing code benchmarks, and an identification of
the limitations of LLMs in code generation tasks based on their performance on
DOMAINEVAL, providing directions for future research improvements. The
leaderboard is available at https://domaineval.github.io/.

摘要：<paragraph>例如 HumanEval 等程式碼基準廣泛用於評估大型語言模型 (LLM) 的能力，提供對其優點和缺點的見解。然而，目前的基準主要針對 LLM 在常見編碼任務（例如氣泡排序、最大公因數）上的能力進行評量，而未探討特定領域的編碼任務（例如運算、系統、密碼學）。為了解決這個問題，我們提出了一個多領域程式碼基準 DOMAINEVAL，旨在全面評估 LLM 的編碼能力。我們的管線以全自動化的方式運作，能從程式碼儲存庫中推動建立格式化的研究主題。透過評估 12 個代表性的 LLM 與 DOMAINEVAL，我們觀察到一些有趣的發現。我們注意到 LLM 通常擅長運算任務，但在密碼學和系統編碼任務上表現不佳。在某些 LLM 中，效能差距可能高達 68.94%（80.94% - 12.0%）。我們也觀察到，產生更多範例可以提升 LLM 的整體效能，而領域偏差甚至可能增加。本研究的貢獻包括一個涵蓋六個熱門領域的程式碼產生基準資料集 DOMAINEVAL、一個用於建立程式碼基準的全自動化管線，以及根據 LLM 在 DOMAINEVAL 上的表現來找出其在程式碼產生任務上的限制，為未來的研究改進提供方向。排行榜可在 https://domaineval.github.io/ 取得。</paragraph>

##### **Instruct-DeBERTa: A Hybrid Approach for Aspect-based Sentiment Analysis on Textual Reviews**
2408.13202v1 by Dineth Jayakody, A V A Malkith, Koshila Isuranda, Vishal Thenuwara, Nisansa de Silva, Sachintha Rajith Ponnamperuma, G G N Sandamali, K L K Sudheera

Aspect-based Sentiment Analysis (ABSA) is a critical task in Natural Language
Processing (NLP) that focuses on extracting sentiments related to specific
aspects within a text, offering deep insights into customer opinions.
Traditional sentiment analysis methods, while useful for determining overall
sentiment, often miss the implicit opinions about particular product or service
features. This paper presents a comprehensive review of the evolution of ABSA
methodologies, from lexicon-based approaches to machine learning and deep
learning techniques. We emphasize the recent advancements in Transformer-based
models, particularly Bidirectional Encoder Representations from Transformers
(BERT) and its variants, which have set new benchmarks in ABSA tasks. We
focused on finetuning Llama and Mistral models, building hybrid models using
the SetFit framework, and developing our own model by exploiting the strengths
of state-of-the-art (SOTA) Transformer-based models for aspect term extraction
(ATE) and aspect sentiment classification (ASC). Our hybrid model Instruct -
DeBERTa uses SOTA InstructABSA for aspect extraction and DeBERTa-V3-baseabsa-V1
for aspect sentiment classification. We utilize datasets from different domains
to evaluate our model's performance. Our experiments indicate that the proposed
hybrid model significantly improves the accuracy and reliability of sentiment
analysis across all experimented domains. As per our findings, our hybrid model
Instruct - DeBERTa is the best-performing model for the joint task of ATE and
ASC for both SemEval restaurant 2014 and SemEval laptop 2014 datasets
separately. By addressing the limitations of existing methodologies, our
approach provides a robust solution for understanding detailed consumer
feedback, thus offering valuable insights for businesses aiming to enhance
customer satisfaction and product development.

摘要：<paragraph>面向方面的观点分析 (ABSA) 是自然語言處理 (NLP) 中的一項重要任務，它專注於提取與文本中特定方面相關的觀點，從而深入了解客戶意見。傳統的觀點分析方法雖然有助於確定整體觀點，但往往會遺漏對特定產品或服務特徵的隱含意見。本文全面回顧了 ABSA 方法的演變，從基於詞彙的方法到機器學習和深度學習技術。我們強調了基於 Transformer 的模型的最新進展，特別是 Transformer 的雙向編碼器表示 (BERT) 及其變體，這些模型在 ABSA 任務中樹立了新的基準。我們專注於微調 Llama 和 Mistral 模型，使用 SetFit 框架構建混合模型，並通過利用最先進 (SOTA) 的基於 Transformer 的模型的優勢開發我們自己的模型，用於方面術語提取 (ATE) 和方面觀點分類 (ASC)。我們的混合模型 Instruct - DeBERTa 使用 SOTA InstructABSA 進行方面提取，並使用 DeBERTa-V3-baseabsa-V1 進行方面觀點分類。我們利用來自不同領域的數據集來評估我們模型的性能。我們的實驗表明，所提出的混合模型顯著提高了所有實驗領域的觀點分析的準確性和可靠性。根據我們的發現，我們的混合模型 Instruct - DeBERTa 是 SemEval 餐廳 2014 和 SemEval 筆記本電腦 2014 數據集的 ATE 和 ASC 聯合任務的最佳執行模型。通過解決現有方法的局限性，我們的做法為理解詳細的消費者反饋提供了一個強大的解決方案，從而為旨在提高客戶滿意度和產品開發的企業提供有價值的見解。</paragraph>

##### **Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating the Hallucination for Path Planning**
2408.13184v1 by Hourui Deng, Hongjie Zhang, Jie Ou, Chaosheng Feng

Spatial reasoning in Large Language Models (LLMs) is the foundation for
embodied intelligence. However, even in simple maze environments, LLMs still
encounter challenges in long-term path-planning, primarily influenced by their
spatial hallucination and context inconsistency hallucination by long-term
reasoning. To address this challenge, this study proposes an innovative model,
Spatial-to-Relational Transformation and Curriculum Q-Learning (S2RCQL). To
address the spatial hallucination of LLMs, we propose the Spatial-to-Relational
approach, which transforms spatial prompts into entity relations and paths
representing entity relation chains. This approach fully taps the potential of
LLMs in terms of sequential thinking. As a result, we design a path-planning
algorithm based on Q-learning to mitigate the context inconsistency
hallucination, which enhances the reasoning ability of LLMs. Using the Q-value
of state-action as auxiliary information for prompts, we correct the
hallucinations of LLMs, thereby guiding LLMs to learn the optimal path.
Finally, we propose a reverse curriculum learning technique based on LLMs to
further mitigate the context inconsistency hallucination. LLMs can rapidly
accumulate successful experiences by reducing task difficulty and leveraging
them to tackle more complex tasks. We performed comprehensive experiments based
on Baidu's self-developed LLM: ERNIE-Bot 4.0. The results showed that our
S2RCQL achieved a 23%--40% improvement in both success and optimality rates
compared with advanced prompt engineering.

摘要：大型語言模型 (LLM) 中的空間推理是具身智能的基礎。然而，即使在簡單的迷宮環境中，LLM 仍然在長期路徑規劃中遇到挑戰，這主要是受其長期推理產生的空間幻覺和語境不一致幻覺影響。為了應對這一挑戰，本研究提出了一種創新的模型，即空間到關係轉換和課程 Q 學習 (S2RCQL)。為了解決 LLM 的空間幻覺，我們提出了空間到關係方法，它將空間提示轉換為表示實體關係鏈的實體關係和路徑。這種方法充分發揮了 LLM 在順序思考方面的潛力。因此，我們設計了一個基於 Q 學習的路徑規劃演算法，以減輕語境不一致幻覺，從而增強 LLM 的推理能力。利用狀態動作的 Q 值作為提示的輔助資訊，我們糾正了 LLM 的幻覺，從而引導 LLM 學習最佳路徑。最後，我們提出了一種基於 LLM 的反向課程學習技術，以進一步減輕語境不一致幻覺。LLM 可以通過降低任務難度並利用它們來應對更複雜的任務，從而快速累積成功的經驗。我們基於百度自研的 LLM：ERNIE-Bot 4.0 進行了全面的實驗。結果表明，與先進的提示工程相比，我們的 S2RCQL 在成功率和最優率方面都取得了 23%--40% 的提升。

##### **Lessons in co-creation: the inconvenient truths of inclusive sign language technology development**
2408.13171v1 by Maartje De Meulder, Davy Van Landuyt, Rehana Omardeen

In the era of AI-driven language technologies, there is a growing demand for
the participation and leadership of deaf communities in sign language
technology development, often framed as co-creation. This paper, developed
through collaborative and iterative dialogue between the authors with data from
informal participant observations, examines the involvement of the European
Union of the Deaf in two EU Horizon 2020 projects, EASIER and SignON. These
projects aimed to develop mobile translation applications between signed and
spoken languages, bringing together predominantly hearing, non-signing
technology experts with predominantly hearing sign language academics and
organizations representing deaf end users in large multi-partner consortia.
While co-creation is sometimes presented as the best or required way to do
research or even as emancipatory, it frequently masks systemic issues of power
imbalances and tokenism. Drawing from EUD's experiences of these projects, we
highlight several inconvenient truths of co-creation, and propose seven lessons
for future initiatives: recognizing deaf partners' invisible labour as work,
managing expectations about technologies, cripping co-creation processes,
exploring alternative methods to mitigate co-creation fatigue, seeking
intersectional feedback, ensuring co-creation is not just virtue signalling,
and fostering deaf leadership in AI sign language research. We argue for
co-creation as a transformative activity that fundamentally alters the status
quo and levels the playing field. This necessitates increasing the number of
deaf researchers and enhancing AI literacy among deaf communities. Without
these critical transformative actions, co-creation risks merely paying lip
service to deaf communities.

摘要：在人工智能驅動語言技術的時代，對於聾人社群參與及領導手語科技發展的需求日益增加，這通常被稱為共同創作。本文透過作者之間的協作與反覆對話，以及來自非正式參與者觀察的資料，探討歐洲聾人聯盟參與兩個歐盟地平線 2020 專案，EASIER 和 SignON。這些專案旨在開發手語和口語之間的行動翻譯應用程式，主要結合聽力正常、不會手語的技術專家，以及聽力正常的聾人手語學者和代表眾多合作夥伴聯盟中聾人最終使用者的組織。雖然共同創作有時被認為是進行研究的最佳或必要方式，甚至被視為解放，但它經常掩蓋了系統性的權力失衡和象徵主義問題。我們根據 EUD 對這些專案的經驗，強調了共同創作的幾個不方便的真相，並為未來的倡議提出了七個教訓：承認聾人夥伴的無形勞動是工作、管理對技術的期望、使共同創作過程殘障化、探索減輕共同創作疲勞的替代方法、尋求交叉回饋、確保共同創作不僅僅是美德信號，並促進聾人在 AI 手語研究中的領導地位。我們主張共同創作是一種變革活動，它從根本上改變了現狀並平衡了競爭環境。這需要增加聾人研究人員的數量，並提高聾人社群的 AI 素養。在沒有這些關鍵的變革行動的情況下，共同創作只會淪為對聾人社群的口頭服務。

##### **Say No to Freeloader: Protecting Intellectual Property of Your Deep Model**
2408.13161v1 by Lianyu Wang, Meng Wang, Huazhu Fu, Daoqiang Zhang

Model intellectual property (IP) protection has attracted growing attention
as science and technology advancements stem from human intellectual labor and
computational expenses. Ensuring IP safety for trainers and owners is of utmost
importance, particularly in domains where ownership verification and
applicability authorization are required. A notable approach to safeguarding
model IP involves proactively preventing the use of well-trained models of
authorized domains from unauthorized domains. In this paper, we introduce a
novel Compact Un-transferable Pyramid Isolation Domain (CUPI-Domain) which
serves as a barrier against illegal transfers from authorized to unauthorized
domains. Drawing inspiration from human transitive inference and learning
abilities, the CUPI-Domain is designed to obstruct cross-domain transfers by
emphasizing the distinctive style features of the authorized domain. This
emphasis leads to failure in recognizing irrelevant private style features on
unauthorized domains. To this end, we propose novel CUPI-Domain generators,
which select features from both authorized and CUPI-Domain as anchors. Then, we
fuse the style features and semantic features of these anchors to generate
labeled and style-rich CUPI-Domain. Additionally, we design external
Domain-Information Memory Banks (DIMB) for storing and updating labeled pyramid
features to obtain stable domain class features and domain class-wise style
features. Based on the proposed whole method, the novel style and
discriminative loss functions are designed to effectively enhance the
distinction in style and discriminative features between authorized and
unauthorized domains, respectively. Moreover, we provide two solutions for
utilizing CUPI-Domain based on whether the unauthorized domain is known:
target-specified CUPI-Domain and target-free CUPI-Domain.

摘要：模型智慧財產權 (IP) 保護備受關注，因為科學和技術進步源自人類智慧勞動和運算成本。確保訓練者和所有者的 IP 安全至關重要，特別是在需要所有權驗證和適用性授權的領域。保護模型 IP 的一個顯著方法涉及主動防止未經授權的網域使用經過良好訓練的授權網域模型。在本文中，我們介紹了一種新穎的緊湊不可轉移金字塔隔離網域 (CUPI-Domain)，它作為阻止從授權網域到未經授權網域的非法轉移的屏障。從人類的遞移推理和學習能力中汲取靈感，CUPI-Domain 旨在透過強調授權網域的獨特樣式特徵來阻礙跨網域轉移。這種強調導致無法在未經授權的網域上識別不相關的私人樣式特徵。為此，我們提出了新穎的 CUPI-Domain 生成器，它從授權和 CUPI-Domain 中選擇特徵作為錨點。然後，我們融合這些錨點的樣式特徵和語義特徵，以生成標籤豐富的 CUPI-Domain。此外，我們設計了外部網域資訊記憶體庫 (DIMB)，用於儲存和更新標籤金字塔特徵，以獲取穩定的網域類別特徵和網域類別樣式特徵。基於所提出的整體方法，新穎的樣式和辨別損失函數被設計為分別有效增強授權和未經授權網域之間的樣式和辨別特徵的區別。此外，我們提供了兩種基於未經授權網域是否已知的 CUPI-Domain 使用解決方案：目標指定的 CUPI-Domain 和目標免費的 CUPI-Domain。

##### **Causal machine learning for sustainable agroecosystems**
2408.13155v1 by Vasileios Sitokonstantinou, Emiliano Díaz Salas Porras, Jordi Cerdà Bautista, Maria Piles, Ioannis Athanasiadis, Hannah Kerner, Giulia Martini, Lily-belle Sweet, Ilias Tsoumas, Jakob Zscheischler, Gustau Camps-Valls

In a changing climate, sustainable agriculture is essential for food security
and environmental health. However, it is challenging to understand the complex
interactions among its biophysical, social, and economic components. Predictive
machine learning (ML), with its capacity to learn from data, is leveraged in
sustainable agriculture for applications like yield prediction and weather
forecasting. Nevertheless, it cannot explain causal mechanisms and remains
descriptive rather than prescriptive. To address this gap, we propose causal
ML, which merges ML's data processing with causality's ability to reason about
change. This facilitates quantifying intervention impacts for evidence-based
decision-making and enhances predictive model robustness. We showcase causal ML
through eight diverse applications that benefit stakeholders across the
agri-food chain, including farmers, policymakers, and researchers.

摘要：在氣候變遷的影響下，永續農業對於糧食安全和環境健康至關重要。然而，要了解其生物物理、社會和經濟成分之間的複雜互動卻是一項挑戰。預測機器學習 (ML) 具備從資料中學習的能力，因此被運用於永續農業中，例如產量預測和天氣預報等應用。儘管如此，它無法解釋因果機制，且仍然是描述性的而非規範性的。為了解決這個差距，我們提出了因果 ML，它將 ML 的資料處理與因果關係推理變化的能力結合在一起。這有助於量化干預影響，以利於基於證據的決策制定，並增強預測模型的穩健性。我們透過八個不同的應用展示因果 ML，這些應用惠及農業食品鏈中的利害關係人，包括農民、政策制定者和研究人員。

##### **ShapeICP: Iterative Category-level Object Pose and Shape Estimation from Depth**
2408.13147v1 by Yihao Zhang, John J. Leonard

Category-level object pose and shape estimation from a single depth image has
recently drawn research attention due to its wide applications in robotics and
self-driving. The task is particularly challenging because the three unknowns,
object pose, object shape, and model-to-measurement correspondences, are
compounded together but only a single view of depth measurements is provided.
The vast majority of the prior work heavily relies on data-driven approaches to
obtain solutions to at least one of the unknowns and typically two, running
with the risk of failing to generalize to unseen domains. The shape
representations used in the prior work also mainly focus on point cloud and
signed distance field (SDF). In stark contrast to the prior work, we approach
the problem using an iterative estimation method that does not require learning
from any pose-annotated data. In addition, we adopt a novel mesh-based object
active shape model that has not been explored by the previous literature. Our
algorithm, named ShapeICP, has its foundation in the iterative closest point
(ICP) algorithm but is equipped with additional features for the category-level
pose and shape estimation task. The results show that even without using any
pose-annotated data, ShapeICP surpasses many data-driven approaches that rely
on the pose data for training, opening up new solution space for researchers to
consider.

摘要：<paragraph>從單一深度影像中進行類別層級的物體姿勢和形狀估計，最近因其在機器人和自動駕駛中的廣泛應用而引起研究關注。這項任務特別具有挑戰性，因為三個未知數（物體姿勢、物體形狀和模型到測量的對應關係）是結合在一起的，但只提供了一個深度測量的單一視圖。絕大多數先前的研究都嚴重依賴於資料驅動的方法來獲得至少一個未知數（通常是兩個）的解，這會冒著無法概括到未見領域的風險。先前研究中使用的形狀表示也主要集中在點雲和有號距離場 (SDF) 上。與先前的研究形成鮮明對比的是，我們使用一種迭代估計方法來解決這個問題，這種方法不需要從任何姿勢註解資料中學習。此外，我們採用了一種新的基於網格的物體主動形狀模型，這在先前的文獻中尚未被探索過。我們的演算法稱為 ShapeICP，其基礎是迭代最近點 (ICP) 演算法，但配備了類別層級姿勢和形狀估計任務的其他功能。結果表明，即使不使用任何姿勢註解資料，ShapeICP 也超越了許多依賴姿勢資料進行訓練的資料驅動方法，為研究人員提供了新的解決方案空間。</paragraph>

##### **Deep Learning at the Intersection: Certified Robustness as a Tool for 3D Vision**
2408.13135v1 by Gabriel Pérez S, Juan C. Pérez, Motasem Alfarra, Jesús Zarzar, Sara Rojas, Bernard Ghanem, Pablo Arbeláez

This paper presents preliminary work on a novel connection between certified
robustness in machine learning and the modeling of 3D objects. We highlight an
intriguing link between the Maximal Certified Radius (MCR) of a classifier
representing a space's occupancy and the space's Signed Distance Function
(SDF). Leveraging this relationship, we propose to use the certification method
of randomized smoothing (RS) to compute SDFs. Since RS' high computational cost
prevents its practical usage as a way to compute SDFs, we propose an algorithm
to efficiently run RS in low-dimensional applications, such as 3D space, by
expressing RS' fundamental operations as Gaussian smoothing on pre-computed
voxel grids. Our approach offers an innovative and practical tool to compute
SDFs, validated through proof-of-concept experiments in novel view synthesis.
This paper bridges two previously disparate areas of machine learning, opening
new avenues for further exploration and potential cross-domain advancements.

摘要：本文提出了一項關於機器學習中的認證穩健性與 3D 物件建模之間新穎關聯的初步研究。我們強調了表示空間佔用率的分類器的最大認證半徑 (MCR) 與空間的符號距離函數 (SDF) 之間的有趣連結。利用這種關係，我們建議使用隨機平滑 (RS) 的認證方法來計算 SDF。由於 RS 的高計算成本妨礙了其作為計算 SDF 的方式的實際使用，我們提出了一種演算法，透過將 RS 的基本運算表示為預先計算的體素網格上的高斯平滑，在低維度應用程式（例如 3D 空間）中有效執行 RS。我們的做法提供了一個創新且實用的工具來計算 SDF，並透過新穎視圖合成中的概念驗證實驗進行驗證。本文橋接了機器學習中兩個先前不同的領域，為進一步探索和潛在的跨領域進展開啟了新的途徑。

##### **DeTPP: Leveraging Object Detection for Robust Long-Horizon Event Prediction**
2408.13131v1 by Ivan Karpukhin, Andrey Savchenko

Forecasting future events over extended periods, known as long-horizon
prediction, is a fundamental task in various domains, including retail,
finance, healthcare, and social networks. Traditional methods, such as Marked
Temporal Point Processes (MTPP), typically use autoregressive models to predict
multiple future events. However, these models frequently encounter issues such
as converging to constant or repetitive outputs, which significantly limits
their effectiveness and applicability. To overcome these limitations, we
propose DeTPP (Detection-based Temporal Point Processes), a novel approach
inspired by object detection methods from computer vision. DeTPP utilizes a
novel matching-based loss function that selectively focuses on reliably
predictable events, enhancing both training robustness and inference diversity.
Our method sets a new state-of-the-art in long-horizon event prediction,
significantly outperforming existing MTPP and next-K approaches. The
implementation of DeTPP is publicly available on GitHub.

摘要：預測未來事件的長週期，稱為長期預測，是各種領域的基礎任務，包括零售、金融、醫療保健和社交網路。傳統方法，例如標記時序點過程 (MTPP)，通常使用自迴歸模型來預測多個未來事件。然而，這些模型經常遇到問題，例如收斂到常數或重複的輸出，這顯著限制了它們的有效性和適用性。為了克服這些限制，我們提出 DeTPP（基於檢測的時序點過程），這是一種新穎的方法，靈感來自電腦視覺中的物件檢測方法。DeTPP 利用一種新穎的基於匹配的損失函數，該函數選擇性地關注可預測的事件，增強了訓練的穩健性和推論的多樣性。我們的模型在長期事件預測中樹立了新的最先進標準，大幅優於現有的 MTPP 和下一個 K 種方法。DeTPP 的實作已公開在 GitHub 上。

##### **Analysis of child development facts and myths using text mining techniques and classification models**
2408.13091v1 by Mehedi Tajrian, Azizur Rahman, Muhammad Ashad Kabir, Md Rafiqul Islam

The rapid dissemination of misinformation on the internet complicates the
decision-making process for individuals seeking reliable information,
particularly parents researching child development topics. This misinformation
can lead to adverse consequences, such as inappropriate treatment of children
based on myths. While previous research has utilized text-mining techniques to
predict child abuse cases, there has been a gap in the analysis of child
development myths and facts. This study addresses this gap by applying text
mining techniques and classification models to distinguish between myths and
facts about child development, leveraging newly gathered data from publicly
available websites. The research methodology involved several stages. First,
text mining techniques were employed to pre-process the data, ensuring enhanced
accuracy. Subsequently, the structured data was analysed using six robust
Machine Learning (ML) classifiers and one Deep Learning (DL) model, with two
feature extraction techniques applied to assess their performance across three
different training-testing splits. To ensure the reliability of the results,
cross-validation was performed using both k-fold and leave-one-out methods.
Among the classification models tested, Logistic Regression (LR) demonstrated
the highest accuracy, achieving a 90% accuracy with the Bag-of-Words (BoW)
feature extraction technique. LR stands out for its exceptional speed and
efficiency, maintaining low testing time per statement (0.97 microseconds).
These findings suggest that LR, when combined with BoW, is effective in
accurately classifying child development information, thus providing a valuable
tool for combating misinformation and assisting parents in making informed
decisions.

摘要：<paragraph>網路上錯誤訊息快速傳播，讓尋求可靠資訊的個人難以做決策，特別是正在研究兒童發展主題的父母。這些錯誤訊息可能導致不良後果，例如根據迷思對兒童進行不當的對待。雖然先前的研究已利用文字探勘技術來預測虐待兒童的案例，但在分析兒童發展迷思與事實方面仍有差距。本研究透過應用文字探勘技術與分類模型來區分兒童發展的迷思與事實，並利用從公開網站收集的新資料來解決此差距。研究方法包含幾個階段。首先，採用文字探勘技術來預處理資料，確保精確度。接著，使用六種強大的機器學習 (ML) 分類器和一個深度學習 (DL) 模型來分析結構化的資料，並應用兩種特徵萃取技術來評估它們在三個不同的訓練測試分割中的表現。為了確保結果的可靠性，使用 k 折和留一法執行交叉驗證。在測試的分類模型中，邏輯迴歸 (LR) 展現最高的精確度，使用詞袋 (BoW) 特徵萃取技術時達到 90% 的精確度。LR 以其出色的速度和效率而突出，每個陳述的測試時間很短 (0.97 微秒)。這些發現顯示，LR 與 BoW 結合時，能有效且精確地分類兒童發展資訊，因此提供一個有價值的工具來打擊錯誤訊息，並協助父母做出明智的決定。</paragraph>

##### **Map-Free Visual Relocalization Enhanced by Instance Knowledge and Depth Knowledge**
2408.13085v1 by Mingyu Xiao, Runze Chen, Haiyong Luo, Fang Zhao, Juan Wang, Xuepeng Ma

Map-free relocalization technology is crucial for applications in autonomous
navigation and augmented reality, but relying on pre-built maps is often
impractical. It faces significant challenges due to limitations in matching
methods and the inherent lack of scale in monocular images. These issues lead
to substantial rotational and metric errors and even localization failures in
real-world scenarios. Large matching errors significantly impact the overall
relocalization process, affecting both rotational and translational accuracy.
Due to the inherent limitations of the camera itself, recovering the metric
scale from a single image is crucial, as this significantly impacts the
translation error. To address these challenges, we propose a map-free
relocalization method enhanced by instance knowledge and depth knowledge. By
leveraging instance-based matching information to improve global matching
results, our method significantly reduces the possibility of mismatching across
different objects. The robustness of instance knowledge across the scene helps
the feature point matching model focus on relevant regions and enhance matching
accuracy. Additionally, we use estimated metric depth from a single image to
reduce metric errors and improve scale recovery accuracy. By integrating
methods dedicated to mitigating large translational and rotational errors, our
approach demonstrates superior performance in map-free relocalization
techniques.

摘要：無地圖再定位技術對於自主導航和擴增實境應用至關重要，但依賴預先建置的地圖通常不切實際。由於配對方法的限制和單眼影像中固有的比例不足，因此面臨重大挑戰。這些問題會導致實際場景中的大幅旋轉和度量誤差，甚至定位失敗。大幅配對誤差會顯著影響整體再定位流程，影響旋轉和平移準確度。由於相機本身的固有限制，從單一影像中恢復度量比例至關重要，因為這會顯著影響平移誤差。為了應對這些挑戰，我們提出了一種由實例知識和深度知識增強的無地圖再定位方法。透過利用基於實例的配對資訊來改善整體配對結果，我們的技術大幅降低跨不同物件不匹配的可能性。實例知識在場景中的穩健性有助於特徵點配對模型專注於相關區域並提高配對準確度。此外，我們使用從單一影像估計的度量深度來減少度量誤差並提高比例恢復準確度。透過整合專門用於減輕大幅平移和旋轉誤差的方法，我們的技術在無地圖再定位技術中展現出優異的效能。

##### **Multivariate Time-Series Anomaly Detection based on Enhancing Graph Attention Networks with Topological Analysis**
2408.13082v1 by Zhe Liu, Xiang Huang, Jingyun Zhang, Zhifeng Hao, Li Sun, Hao Peng

Unsupervised anomaly detection in time series is essential in industrial
applications, as it significantly reduces the need for manual intervention.
Multivariate time series pose a complex challenge due to their feature and
temporal dimensions. Traditional methods use Graph Neural Networks (GNNs) or
Transformers to analyze spatial while RNNs to model temporal dependencies.
These methods focus narrowly on one dimension or engage in coarse-grained
feature extraction, which can be inadequate for large datasets characterized by
intricate relationships and dynamic changes. This paper introduces a novel
temporal model built on an enhanced Graph Attention Network (GAT) for
multivariate time series anomaly detection called TopoGDN. Our model analyzes
both time and feature dimensions from a fine-grained perspective. First, we
introduce a multi-scale temporal convolution module to extract detailed
temporal features. Additionally, we present an augmented GAT to manage complex
inter-feature dependencies, which incorporates graph topology into node
features across multiple scales, a versatile, plug-and-play enhancement that
significantly boosts the performance of GAT. Our experimental results confirm
that our approach surpasses the baseline models on four datasets, demonstrating
its potential for widespread application in fields requiring robust anomaly
detection. The code is available at https://github.com/ljj-cyber/TopoGDN.

摘要：在工業應用中，時間序列中的無監督異常偵測非常重要，因為它大幅降低手動介入的需求。多變量時間序列由於其特徵和時間維度而構成複雜的挑戰。傳統方法使用圖神經網路 (GNN) 或 Transformer 來分析空間，同時使用遞迴神經網路 (RNN) 來建模時間依賴性。這些方法狹隘地關注於一個維度，或從事粗粒度特徵提取，這對於以複雜關係和動態變化為特徵的大型資料集來說可能不夠。本文介紹了一個新的時間模型，該模型建立在增強圖注意力網路 (GAT) 之上，用於稱為 TopoGDN 的多變量時間序列異常偵測。我們的模型從細粒度角度分析時間和特徵維度。首先，我們引入一個多尺度時間卷積模組來提取詳細的時間特徵。此外，我們提出了一個擴充的 GAT 來管理複雜的特性間依賴性，它將圖拓撲納入跨多個尺度的節點特徵中，這是一個通用的即插即用增強功能，可以顯著提升 GAT 的效能。我們的實驗結果證實，我們的做法在四個資料集上超越了基準模型，證明了其在需要穩健異常偵測的領域中廣泛應用的潛力。程式碼可在 https://github.com/ljj-cyber/TopoGDN 取得。

##### **AEMLO: AutoEncoder-Guided Multi-Label Oversampling**
2408.13078v1 by Ao Zhou, Bin Liu, Jin Wang, Kaiwei Sun, Kelin Liu

Class imbalance significantly impacts the performance of multi-label
classifiers. Oversampling is one of the most popular approaches, as it augments
instances associated with less frequent labels to balance the class
distribution. Existing oversampling methods generate feature vectors of
synthetic samples through replication or linear interpolation and assign labels
through neighborhood information. Linear interpolation typically generates new
samples between existing data points, which may result in insufficient
diversity of synthesized samples and further lead to the overfitting issue.
Deep learning-based methods, such as AutoEncoders, have been proposed to
generate more diverse and complex synthetic samples, achieving excellent
performance on imbalanced binary or multi-class datasets. In this study, we
introduce AEMLO, an AutoEncoder-guided Oversampling technique specifically
designed for tackling imbalanced multi-label data. AEMLO is built upon two
fundamental components. The first is an encoder-decoder architecture that
enables the model to encode input data into a low-dimensional feature space,
learn its latent representations, and then reconstruct it back to its original
dimension, thus applying to the generation of new data. The second is an
objective function tailored to optimize the sampling task for multi-label
scenarios. We show that AEMLO outperforms the existing state-of-the-art methods
with extensive empirical studies.

摘要：類別不平衡會顯著影響多標籤分類器的效能。過採樣是最普遍的方法之一，因為它會增加與較不常見標籤相關的實例，以平衡類別分佈。現有的過採樣方法會透過複製或線性內插產生合成樣本的特徵向量，並透過鄰近資訊指派標籤。線性內插通常會在現有的資料點之間產生新的樣本，這可能會導致合成樣本的多樣性不足，進而導致過度擬合的問題。已經提出基於深度學習的方法，例如自動編碼器，以產生更多樣化且複雜的合成樣本，在不平衡的二元或多類別資料集上達到極佳的效能。在本研究中，我們介紹了 AEMLO，這是一種自動編碼器導向的過採樣技術，專門用於處理不平衡的多標籤資料。AEMLO 建立在兩個基本組成部分上。第一個是編碼器解碼器架構，它使模型能夠將輸入資料編碼成低維度特徵空間，學習其潛在表示，然後將其重建回其原始維度，從而應用於產生新資料。第二個是針對多標籤場景最佳化抽樣任務而量身打造的目標函數。我們證明了 AEMLO 在廣泛的實證研究中優於現有的最先進方法。

##### **Hierarchical Spatio-Temporal State-Space Modeling for fMRI Analysis**
2408.13074v1 by Yuxiang Wei, Anees Abrol, Reihaneh Hassanzadeh, Vince Calhoun

Recent advances in deep learning structured state space models, especially
the Mamba architecture, have demonstrated remarkable performance improvements
while maintaining linear complexity. In this study, we introduce functional
spatiotemporal Mamba (FST-Mamba), a Mamba-based model designed for discovering
neurological biomarkers using functional magnetic resonance imaging (fMRI). We
focus on dynamic functional network connectivity (dFNC) derived from fMRI and
propose a hierarchical spatiotemporal Mamba-based network that processes
spatial and temporal information separately using Mamba-based encoders.
Leveraging the topological uniqueness of the FNC matrix, we introduce a
component-wise varied-scale aggregation (CVA) mechanism to aggregate
connectivity across individual components within brain networks, enabling the
model to capture both inter-component and inter-network information. To better
handle the FNC data, we develop a new component-specific scanning order.
Additionally, we propose symmetric rotary position encoding (SymRope) to encode
the relative positions of each functional connection while considering the
symmetric nature of the FNC matrix. Experimental results demonstrate
significant improvements in the proposed FST-Mamba model on various brain-based
classification and regression tasks. Our work reveals the substantial potential
of attention-free sequence modeling in brain discovery.

摘要：深度學習結構化狀態空間模型的最新進展，尤其是 Mamba 架構，在維持線性複雜度的同時，展現了顯著的效能提升。在這項研究中，我們介紹了功能性時空 Mamba (FST-Mamba)，這是一個基於 Mamba 的模型，專門用於使用功能性磁共振造影 (fMRI) 發現神經生物標記。我們專注於源自 fMRI 的動態功能網路連接 (dFNC)，並提出一個基於 Mamba 的階層式時空網路，使用基於 Mamba 的編碼器分別處理空間和時間資訊。利用 FNC 矩陣的拓撲獨特性，我們引入了一個組件級可變規模聚合 (CVA) 機制，以聚合腦網路內各個組件之間的連接，讓模型能夠擷取組件間和網路間的資訊。為了更好地處理 FNC 資料，我們開發了一個新的組件特定掃描順序。此外，我們提出了對稱旋轉位置編碼 (SymRope) 來編碼每個功能連接的相對位置，同時考慮 FNC 矩陣的對稱性質。實驗結果顯示，所提出的 FST-Mamba 模型在各種基於大腦的分類和回歸任務中都有顯著的改進。我們的研究揭示了無注意力序列建模在大腦發現中的巨大潛力。

##### **cc-DRL: a Convex Combined Deep Reinforcement Learning Flight Control Design for a Morphing Quadrotor**
2408.13054v1 by Tao Yang, Huai-Ning Wu, Jun-Wei Wang

In comparison to common quadrotors, the shape change of morphing quadrotors
endows it with a more better flight performance but also results in more
complex flight dynamics. Generally, it is extremely difficult or even
impossible for morphing quadrotors to establish an accurate mathematical model
describing their complex flight dynamics. To figure out the issue of flight
control design for morphing quadrotors, this paper resorts to a combination of
model-free control techniques (e.g., deep reinforcement learning, DRL) and
convex combination (CC) technique, and proposes a convex-combined-DRL (cc-DRL)
flight control algorithm for position and attitude of a class of morphing
quadrotors, where the shape change is realized by the length variation of four
arm rods. In the proposed cc-DRL flight control algorithm, proximal policy
optimization algorithm that is a model-free DRL algorithm is utilized to
off-line train the corresponding optimal flight control laws for some selected
representative arm length modes and hereby a cc-DRL flight control scheme is
constructed by the convex combination technique. Finally, simulation results
are presented to show the effectiveness and merit of the proposed flight
control algorithm.

摘要：與一般的四旋翼機相比，變形四旋翼機的形狀變化賦予它更好的飛行性能，但也導致更複雜的飛行力學。一般來說，要為變形四旋翼機建立一個準確的數學模型來描述其複雜的飛行力學極其困難，甚至是不可能的。為了解決變形四旋翼機的飛行控制設計問題，本文採用模型無關控制技術（例如深度強化學習，DRL）和凸組合（CC）技術相結合的方法，並提出了一種凸組合深度強化學習（cc-DRL）飛行控制演算法，用於控制一類變形四旋翼機的位置和姿態，其中形狀變化是由四個臂桿長度的變化來實現的。在所提出的 cc-DRL 飛行控制演算法中，採用近端策略優化演算法（一種模型無關的 DRL 演算法）來離線訓練一些選定的代表性臂長模式對應的最優飛行控制律，並由此通過凸組合技術構造一個 cc-DRL 飛行控制方案。最後，給出模擬結果以展示所提出的飛行控制演算法的有效性和優點。

##### **SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks**
2408.13040v1 by Kai-Wei Chang, Haibin Wu, Yu-Kai Wang, Yuan-Kuei Wu, Hua Shen, Wei-Cheng Tseng, Iu-thing Kang, Shang-Wen Li, Hung-yi Lee

Prompting has become a practical method for utilizing pre-trained language
models (LMs). This approach offers several advantages. It allows an LM to adapt
to new tasks with minimal training and parameter updates, thus achieving
efficiency in both storage and computation. Additionally, prompting modifies
only the LM's inputs and harnesses the generative capabilities of language
models to address various downstream tasks in a unified manner. This
significantly reduces the need for human labor in designing task-specific
models. These advantages become even more evident as the number of tasks served
by the LM scales up. Motivated by the strengths of prompting, we are the first
to explore the potential of prompting speech LMs in the domain of speech
processing. Recently, there has been a growing interest in converting speech
into discrete units for language modeling. Our pioneer research demonstrates
that these quantized speech units are highly versatile within our unified
prompting framework. Not only can they serve as class labels, but they also
contain rich phonetic information that can be re-synthesized back into speech
signals for speech generation tasks. Specifically, we reformulate speech
processing tasks into speech-to-unit generation tasks. As a result, we can
seamlessly integrate tasks such as speech classification, sequence generation,
and speech generation within a single, unified prompting framework. The
experiment results show that the prompting method can achieve competitive
performance compared to the strong fine-tuning method based on self-supervised
learning models with a similar number of trainable parameters. The prompting
method also shows promising results in the few-shot setting. Moreover, with the
advanced speech LMs coming into the stage, the proposed prompting framework
attains great potential.

摘要：提示已成为利用预训练语言模型 (LM) 的实用方法。这种方法提供了几个优点。它允许 LM 以最少的训练和参数更新适应新任务，从而在存储和计算方面实现效率。此外，提示仅修改 LM 的输入，并利用语言模型的生成能力以统一的方式解决各种下游任务。这大大减少了在设计特定任务模型中对人工劳动力的需求。随着 LM 服务的任务数量的增加，这些优势变得更加明显。受提示优势的启发，我们率先探索了在语音处理领域提示语音 LM 的潜力。最近，人们越来越有兴趣将语音转换成离散单元以进行语言建模。我们的先驱研究表明，这些量化的语音单元在我们统一的提示框架内具有高度通用性。它们不仅可以用作类别标签，还包含丰富的语音信息，可以重新合成回语音信号以用于语音生成任务。具体来说，我们将语音处理任务重新表述为语音到单元生成任务。因此，我们可以在一个单一的统一提示框架内无缝地集成语音分类、序列生成和语音生成等任务。实验结果表明，与基于自监督学习模型的强微调方法相比，提示方法可以在具有相似数量的可训练参数的情况下实现具有竞争力的性能。提示方法在小样本设置中也显示出有希望的结果。此外，随着先进的语音 LM 进入阶段，所提出的提示框架具有巨大的潜力。

##### **VFM-Det: Towards High-Performance Vehicle Detection via Large Foundation Models**
2408.13031v1 by Wentao Wu, Fanghua Hong, Xiao Wang, Chenglong Li, Jin Tang

Existing vehicle detectors are usually obtained by training a typical
detector (e.g., YOLO, RCNN, DETR series) on vehicle images based on a
pre-trained backbone (e.g., ResNet, ViT). Some researchers also exploit and
enhance the detection performance using pre-trained large foundation models.
However, we think these detectors may only get sub-optimal results because the
large models they use are not specifically designed for vehicles. In addition,
their results heavily rely on visual features, and seldom of they consider the
alignment between the vehicle's semantic information and visual
representations. In this work, we propose a new vehicle detection paradigm
based on a pre-trained foundation vehicle model (VehicleMAE) and a large
language model (T5), termed VFM-Det. It follows the region proposal-based
detection framework and the features of each proposal can be enhanced using
VehicleMAE. More importantly, we propose a new VAtt2Vec module that predicts
the vehicle semantic attributes of these proposals and transforms them into
feature vectors to enhance the vision features via contrastive learning.
Extensive experiments on three vehicle detection benchmark datasets thoroughly
proved the effectiveness of our vehicle detector. Specifically, our model
improves the baseline approach by $+5.1\%$, $+6.2\%$ on the $AP_{0.5}$,
$AP_{0.75}$ metrics, respectively, on the Cityscapes dataset.The source code of
this work will be released at https://github.com/Event-AHU/VFM-Det.

摘要：現有的車輛偵測器通常是透過在基於預訓練主幹 (例如 ResNet、ViT) 的車輛影像上訓練典型的偵測器 (例如 YOLO、RCNN、DETR 系列) 來取得。一些研究人員也會利用預訓練的大型基礎模型並增強偵測效能。然而，我們認為這些偵測器可能只能獲得次佳結果，因為它們使用的模型並非專門為車輛設計。此外，其結果高度依賴視覺特徵，而且很少考慮車輛的語義資訊與視覺表徵之間的對齊。在這項工作中，我們提出一個新的車輛偵測範例，它基於預訓練的基礎車輛模型 (VehicleMAE) 和大型語言模型 (T5)，稱為 VFM-Det。它遵循基於區域建議的偵測架構，而且每個建議的特徵都可以使用 VehicleMAE 來增強。更重要的是，我們提出一個新的 VAtt2Vec 模組，它可以預測這些建議的車輛語義屬性，並將它們轉換成特徵向量，以透過對比學習來增強視覺特徵。在三個車輛偵測基準資料集上的廣泛實驗徹底證明了我們車輛偵測器的有效性。具體來說，我們的模型在 Cityscapes 資料集上分別在 $AP_{0.5}$、$AP_{0.75}$ 指標上將基準方法提升了 $+5.1\%$、$+6.2\%$。這項工作的原始程式碼將於 https://github.com/Event-AHU/VFM-Det 發布。

##### **In-Context Learning with Reinforcement Learning for Incomplete Utterance Rewriting**
2408.13028v1 by Haowei Du, Dongyan Zhao

In-context learning (ICL) of large language models (LLMs) has attracted
increasing attention in the community where LLMs make predictions only based on
instructions augmented with a few examples. Existing example selection methods
for ICL utilize sparse or dense retrievers and derive effective performance.
However, these methods do not utilize direct feedback of LLM to train the
retriever and the examples selected can not necessarily improve the analogy
ability of LLM. To tackle this, we propose our policy-based reinforcement
learning framework for example selection (RLS), which consists of a language
model (LM) selector and an LLM generator. The LM selector encodes the candidate
examples into dense representations and selects the top-k examples into the
demonstration for LLM. The outputs of LLM are adopted to compute the reward and
policy gradient to optimize the LM selector. We conduct experiments on
different datasets and significantly outperform existing example selection
methods. Moreover, our approach shows advantages over supervised finetuning
(SFT) models in few shot setting. Further experiments show the balance of
abundance and the similarity with the test case of examples is important for
ICL performance of LLM.

摘要：大型語言模型 (LLM) 的語境學習 (ICL) 吸引了社群中越來越多的關注，其中 LLM 僅根據加入少數範例的指示進行預測。現有的 ICL 範例選取方法利用稀疏或密集擷取器，並衍生出有效的效能。然而，這些方法並未利用 LLM 的直接回饋來訓練擷取器，且選取的範例並非一定能提升 LLM 的類比能力。為了解決此問題，我們針對範例選取提出基於政策的強化學習架構 (RLS)，其中包含語言模型 (LM) 選擇器和 LLM 產生器。LM 選擇器將候選範例編碼成密集表示，並選取前 k 個範例作為 LLM 的示範。LLM 的輸出用於計算獎勵和政策梯度，以最佳化 LM 選擇器。我們針對不同的資料集進行實驗，並顯著優於現有的範例選取方法。此外，我們的做法在少量設定中展現出優於監督微調 (SFT) 模型的優勢。進一步的實驗顯示，範例的豐富性和與測試案例的相似性對於 LLM 的 ICL 效能非常重要。

##### **Systematic Evaluation of LLM-as-a-Judge in LLM Alignment Tasks: Explainable Metrics and Diverse Prompt Templates**
2408.13006v1 by Hui Wei, Shenghua He, Tian Xia, Andy Wong, Jingyang Lin, Mei Han

Alignment approaches such as RLHF and DPO are actively investigated to align
large language models (LLMs) with human preferences. Commercial large language
models (LLMs) like GPT-4 have been recently employed to evaluate and compare
different LLM alignment approaches. These models act as surrogates for human
evaluators due to their promising abilities to approximate human preferences
with remarkably faster feedback and lower costs. This methodology is referred
to as LLM-as-a-judge. However, concerns regarding its reliability have emerged,
attributed to LLM judges' biases and inconsistent decision-making. Previous
research has sought to develop robust evaluation frameworks for assessing the
reliability of LLM judges and their alignment with human preferences. However,
the employed evaluation metrics often lack adequate explainability and fail to
address the internal inconsistency of LLMs. Additionally, existing studies
inadequately explore the impact of various prompt templates when applying
LLM-as-a-judge methods, which leads to potentially inconsistent comparisons
between different alignment algorithms. In this work, we systematically
evaluate LLM judges on alignment tasks (e.g. summarization) by defining
evaluation metrics with improved theoretical interpretability and disentangling
reliability metrics with LLM internal inconsistency. We develop a framework to
evaluate, compare, and visualize the reliability and alignment of LLM judges to
provide informative observations that help choose LLM judges for alignment
tasks. Our results indicate a significant impact of prompt templates on LLM
judge performance, as well as a mediocre alignment level between the tested LLM
judges and human evaluators.

摘要：對齊方法，例如 RLHF 和 DPO，正積極地用於將大型語言模型 (LLM) 與人類偏好對齊。商業大型語言模型 (LLM)，例如 GPT-4，最近已被用於評估和比較不同的 LLM 對齊方法。這些模型由於近似人類偏好的能力強大，且反饋速度顯著加快，成本更低，因此充當人類評估者的替代者。這種方法稱為 LLM 作為評判者。然而，由於 LLM 評判者的偏見和不一致的決策，對其可靠性的擔憂已經浮現。先前的研究試圖開發健全的評估架構，用於評估 LLM 評判者的可靠性及其與人類偏好的對齊程度。然而，所採用的評估指標通常缺乏充分的可解釋性，且無法解決 LLM 的內部不一致性。此外，現有研究在應用 LLM 作為評判者方法時，並未充分探討各種提示範本的影響，這導致在不同的對齊演算法之間進行比較時可能會不一致。在這項工作中，我們透過定義具有改進的理論可解釋性，並將可靠性指標與 LLM 內部不一致性區分開來，系統性地評估對齊任務（例如摘要）中的 LLM 評判者。我們開發了一個架構來評估、比較和視覺化 LLM 評判者的可靠性和對齊程度，以提供有助於選擇 LLM 評判者進行對齊任務的見解。我們的結果表明，提示範本對 LLM 評判者表現有顯著影響，且在測試的 LLM 評判者與人類評估者之間的對齊程度普通。

##### **CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution**
2408.13001v1 by Ruiyang Xu, Jialun Cao, Yaojie Lu, Hongyu Lin, Xianpei Han, Ben He, Shing-Chi Cheung, Le Sun

Code benchmarks such as HumanEval are widely adopted to evaluate Large
Language Models' (LLMs) coding capabilities. However, there is an unignorable
programming language bias in existing code benchmarks -- over 95% code
generation benchmarks are dominated by Python, leaving the LLMs' capabilities
in other programming languages such as Java and C/C++ unknown. Moreover, coding
task bias is also crucial. Most benchmarks focus on code generation capability,
while benchmarks for code reasoning (given input, reasoning output; and given
output, reasoning input), an essential coding capability, are insufficient.
Yet, constructing multi-lingual benchmarks can be expensive and
labor-intensive, and codes in contest websites such as Leetcode suffer from
data contamination during training. To fill this gap, we propose CRUXEVAL-X, a
multi-lingual code reasoning benchmark that contains 19 programming languages.
It comprises at least 600 subjects for each language, along with 19K
content-consistent tests in total. In particular, the construction pipeline of
CRUXEVAL-X works in a fully automated and test-guided manner, which iteratively
generates and repairs based on execution feedback. Also, to cross language
barriers (e.g., dynamic/static type systems in Python/C++), we formulated
various transition rules between language pairs to facilitate translation. Our
intensive evaluation of 24 representative LLMs reveals the correlation between
language pairs. For example, TypeScript and JavaScript show a significant
positive correlation, while Racket has less correlation with other languages.
More interestingly, even a model trained solely on Python can achieve at most
34.4% Pass@1 in other languages, revealing the cross-language generalization of
LLMs.

摘要：<paragraph>像 HumanEval 這樣的程式碼基準廣泛用於評估大型語言模型 (LLM) 的編碼能力。然而，現有的程式碼基準中存在無法忽視的程式語言偏見——超過 95% 的程式碼生成基準由 Python 主導，而 LLM 在 Java 和 C/C++ 等其他程式語言中的能力仍未知。此外，編碼任務偏見也至關重要。大多數基準側重於程式碼生成能力，而用於程式碼推理的基準（給定輸入，推理輸出；給定輸出，推理輸入），一種必要的編碼能力，卻不足。然而，構建多語言基準可能既昂貴又費力，而 Leetcode 等競賽網站中的程式碼在訓練期間會受到資料污染。為了填補這一空白，我們提出了 CRUXEVAL-X，這是一個包含 19 種程式語言的多語言程式碼推理基準。它包含每種語言至少 600 個主題，以及總共 19K 個內容一致的測試。特別是，CRUXEVAL-X 的構建管道以完全自動化和測試引導的方式工作，它根據執行反饋反覆生成和修復。此外，為了跨越語言障礙（例如，Python/C++ 中的動態/靜態類型系統），我們制定了語言對之間的各種轉換規則以促進翻譯。我們對 24 個具有代表性的 LLM 進行的深入評估揭示了語言對之間的關聯性。例如，TypeScript 和 JavaScript 顯示出顯著的正相關性，而 Racket 與其他語言的相關性較低。更有趣的是，即使一個僅在 Python 上訓練的模型在其他語言中最多只能達到 34.4% 的 Pass@1，這揭示了 LLM 的跨語言概括能力。</paragraph>

##### **Enhancing Knowledge Tracing with Concept Map and Response Disentanglement**
2408.12996v1 by Soonwook Park, Donghoon Lee, Hogun Park

In the rapidly advancing realm of educational technology, it becomes critical
to accurately trace and understand student knowledge states. Conventional
Knowledge Tracing (KT) models have mainly focused on binary responses (i.e.,
correct and incorrect answers) to questions. Unfortunately, they largely
overlook the essential information in students' actual answer choices,
particularly for Multiple Choice Questions (MCQs), which could help reveal each
learner's misconceptions or knowledge gaps. To tackle these challenges, we
propose the Concept map-driven Response disentanglement method for enhancing
Knowledge Tracing (CRKT) model. CRKT benefits KT by directly leveraging answer
choices--beyond merely identifying correct or incorrect answers--to distinguish
responses with different incorrect choices. We further introduce the novel use
of unchosen responses by employing disentangled representations to get insights
from options not selected by students. Additionally, CRKT tracks the student's
knowledge state at the concept level and encodes the concept map, representing
the relationships between them, to better predict unseen concepts. This
approach is expected to provide actionable feedback, improving the learning
experience. Our comprehensive experiments across multiple datasets demonstrate
CRKT's effectiveness, achieving superior performance in prediction accuracy and
interpretability over state-of-the-art models.

摘要：在快速發展的教育科技領域中，準確追蹤和瞭解學生的知識狀態變得至關重要。傳統的知識追蹤 (KT) 模型主要關注於問題的二元回應（即正確和錯誤答案）。遺憾的是，它們在很大程度上忽視了學生實際答案選擇中的基本資訊，特別是對於多選題 (MCQ)，這有助於揭示每個學習者的誤解或知識差距。為了應對這些挑戰，我們提出了概念圖驅動的回應解開方法，以增強知識追蹤 (CRKT) 模型。CRKT 通過直接利用答案選擇（不僅僅是識別正確或錯誤答案）來區分具有不同錯誤選擇的回應，從而使 KT 受益。我們進一步介紹了未選擇回應的新穎用途，通過使用解開的表示從學生未選擇的選項中獲取見解。此外，CRKT 追蹤學生在概念層面的知識狀態，並編碼概念圖，表示它們之間的關係，以更好地預測未見概念。預計這種方法將提供可行的回饋，改善學習體驗。我們在多個資料集上進行的綜合實驗證明了 CRKT 的有效性，在預測準確性和可解釋性方面取得了優於最先進模型的卓越效能。

##### **RIFF: Inducing Rules for Fraud Detection from Decision Trees**
2408.12989v1 by João Lucas Martins, João Bravo, Ana Sofia Gomes, Carlos Soares, Pedro Bizarro

Financial fraud is the cause of multi-billion dollar losses annually.
Traditionally, fraud detection systems rely on rules due to their transparency
and interpretability, key features in domains where decisions need to be
explained. However, rule systems require significant input from domain experts
to create and tune, an issue that rule induction algorithms attempt to mitigate
by inferring rules directly from data. We explore the application of these
algorithms to fraud detection, where rule systems are constrained to have a low
false positive rate (FPR) or alert rate, by proposing RIFF, a rule induction
algorithm that distills a low FPR rule set directly from decision trees. Our
experiments show that the induced rules are often able to maintain or improve
performance of the original models for low FPR tasks, while substantially
reducing their complexity and outperforming rules hand-tuned by experts.

摘要：金融詐欺每年造成數十億美元的損失。
傳統上，詐欺偵測系統依賴於規則，因為它們具有透明度和可解釋性，這是需要解釋決策的領域中的關鍵特徵。然而，規則系統需要領域專家的大量輸入才能建立和調整，而規則歸納演算法嘗試透過直接從資料推論規則來減輕這個問題。我們探討這些演算法在詐欺偵測中的應用，其中規則系統受到約束，必須具有低誤報率 (FPR) 或警示率，方法是提出 RIFF，這是一種規則歸納演算法，可以從決策樹中直接萃取出低 FPR 規則組。我們的實驗顯示，歸納出的規則通常能夠維持或改善原始模型在低 FPR 任務中的效能，同時大幅降低其複雜性，而且表現優於專家手動調整的規則。

##### **Zeoformer: Coarse-Grained Periodic Graph Transformer for OSDA-Zeolite Affinity Prediction**
2408.12984v2 by Xiangxiang Shen, Zheng Wan, Lingfeng Wen, Licheng Sun, Ou Yang Ming Jie, Xuan Tang, Xian Zeng, Mingsong Chen, Xiao He, Xian Wei

To date, the International Zeolite Association Structure Commission (IZA-SC)
has cataloged merely 255 distinct zeolite structures, with millions of
theoretically possible structures yet to be discovered. The synthesis of a
specific zeolite typically necessitates the use of an organic
structure-directing agent (OSDA), since the selectivity for a particular
zeolite is largely determined by the affinity between the OSDA and the zeolite.
Therefore, finding the best affinity OSDA-zeolite pair is the key to the
synthesis of targeted zeolite. However, OSDA-zeolite pairs frequently exhibit
complex geometric structures, i.e., a complex crystal structure formed by a
large number of atoms. Although some existing machine learning methods can
represent the periodicity of crystals, they cannot accurately represent crystal
structures with local variability. To address this issue, we propose a novel
approach called Zeoformer, which can effectively represent coarse-grained
crystal periodicity and fine-grained local variability. Zeoformer reconstructs
the unit cell centered around each atom and encodes the pairwise distances
between this central atom and other atoms within the reconstructed unit cell.
The introduction of pairwise distances within the reconstructed unit cell more
effectively represents the overall structure of the unit cell and the
differences between different unit cells, enabling the model to more accurately
and efficiently predict the properties of OSDA-zeolite pairs and general
crystal structures. Through comprehensive evaluation, our Zeoformer model
demonstrates the best performance on OSDA-zeolite pair datasets and two types
of crystal material datasets.

摘要：迄今為止，國際沸石協會結構委員會 (IZA-SC)
僅編目了 255 種不同的沸石結構，還有數百萬種理論上可能存在的結構尚未被發現。特定沸石的合成通常需要使用有機結構導向劑 (OSDA)，因為對特定沸石選擇性的決定在很大程度上取決於 OSDA 與沸石之間的親和力。因此，找到最佳親和力的 OSDA-沸石對是合成目標沸石的關鍵。然而，OSDA-沸石對經常表現出複雜的幾何結構，即由大量原子形成的複雜晶體結構。儘管一些現有的機器學習方法可以表示晶體的週期性，但它們無法準確表示具有局部變異性的晶體結構。為了解決這個問題，我們提出了一種稱為 Zeoformer 的新方法，它可以有效地表示粗粒度的晶體週期性和細粒度的局部變異性。Zeoformer 重建以每個原子為中心的晶胞，並編碼該中心原子與重建晶胞內其他原子之間的成對距離。在重建的晶胞內引入成對距離更有效地表示了晶胞的整體結構和不同晶胞之間的差異，使模型能夠更準確、更高效地預測 OSDA-沸石對和一般晶體結構的性質。通過綜合評估，我們的 Zeoformer 模型在 OSDA-沸石對數據集和兩種類型的晶體材料數據集上展示了最佳性能。

##### **QD-VMR: Query Debiasing with Contextual Understanding Enhancement for Video Moment Retrieval**
2408.12981v1 by Chenghua Gao, Min Li, Jianshuo Liu, Junxing Ren, Lin Chen, Haoyu Liu, Bo Meng, Jitao Fu, Wenwen Su

Video Moment Retrieval (VMR) aims to retrieve relevant moments of an
untrimmed video corresponding to the query. While cross-modal interaction
approaches have shown progress in filtering out query-irrelevant information in
videos, they assume the precise alignment between the query semantics and the
corresponding video moments, potentially overlooking the misunderstanding of
the natural language semantics. To address this challenge, we propose a novel
model called \textit{QD-VMR}, a query debiasing model with enhanced contextual
understanding. Firstly, we leverage a Global Partial Aligner module via video
clip and query features alignment and video-query contrastive learning to
enhance the cross-modal understanding capabilities of the model. Subsequently,
we employ a Query Debiasing Module to obtain debiased query features
efficiently, and a Visual Enhancement module to refine the video features
related to the query. Finally, we adopt the DETR structure to predict the
possible target video moments. Through extensive evaluations of three benchmark
datasets, QD-VMR achieves state-of-the-art performance, proving its potential
to improve the accuracy of VMR. Further analytical experiments demonstrate the
effectiveness of our proposed module. Our code will be released to facilitate
future research.

摘要：影片時刻檢索 (VMR) 的目的是檢索與查詢相應的未修剪影片的相關時刻。雖然跨模態互動方法已顯示出在影片中過濾與查詢無關資訊的進展，但它們假設查詢語意與對應的影片時刻之間的精確對齊，可能會忽略對自然語言語意的誤解。為了應對這個挑戰，我們提出了一個名為「QD-VMR」的新穎模型，這是一個具備增強脈絡理解的查詢去偏差模型。首先，我們透過影片片段和查詢特徵對齊以及影片-查詢對比學習，利用一個全局部分對齊器模組來增強模型的跨模態理解能力。隨後，我們採用一個查詢去偏差模組來有效取得去偏差的查詢特徵，並採用一個視覺增強模組來改善與查詢相關的影片特徵。最後，我們採用 DETR 結構來預測可能的目標影片時刻。透過對三個基準資料集的廣泛評估，QD-VMR 達到了最先進的效能，證明了其改善 VMR 精確度的潛力。進一步的分析實驗證明了我們提出的模組的有效性。我們的程式碼將會釋出，以利未來的研究。

##### **MedDec: A Dataset for Extracting Medical Decisions from Discharge Summaries**
2408.12980v1 by Mohamed Elgaar, Jiali Cheng, Nidhi Vakil, Hadi Amiri, Leo Anthony Celi

Medical decisions directly impact individuals' health and well-being.
Extracting decision spans from clinical notes plays a crucial role in
understanding medical decision-making processes. In this paper, we develop a
new dataset called "MedDec", which contains clinical notes of eleven different
phenotypes (diseases) annotated by ten types of medical decisions. We introduce
the task of medical decision extraction, aiming to jointly extract and classify
different types of medical decisions within clinical notes. We provide a
comprehensive analysis of the dataset, develop a span detection model as a
baseline for this task, evaluate recent span detection approaches, and employ a
few metrics to measure the complexity of data samples. Our findings shed light
on the complexities inherent in clinical decision extraction and enable future
work in this area of research. The dataset and code are available through
https://github.com/CLU-UML/MedDec.

摘要：醫療決策會直接影響個人的健康和福祉。
從臨床筆記中擷取決策跨度在理解醫療決策制定過程中扮演著至關重要的角色。在本文中，我們開發了一個名為「MedDec」的新資料集，其中包含由十種類型的醫療決策註釋的十一種不同表型（疾病）的臨床筆記。我們引入了醫療決策擷取的任務，旨在共同擷取和分類臨床筆記中的不同類型的醫療決策。我們提供了對資料集的全面分析，開發了一個跨度偵測模型作為此任務的基準，評估了最近的跨度偵測方法，並採用了一些指標來衡量資料範例的複雜性。我們的研究結果闡明了臨床決策擷取中固有的複雜性，並促成了此研究領域的未來工作。資料集和程式碼可透過 https://github.com/CLU-UML/MedDec 取得。

##### **Internal and External Knowledge Interactive Refinement Framework for Knowledge-Intensive Question Answering**
2408.12979v1 by Haowei Du, Dongyan Zhao

Recent works have attempted to integrate external knowledge into LLMs to
address the limitations and potential factual errors in LLM-generated content.
However, how to retrieve the correct knowledge from the large amount of
external knowledge imposes a challenge. To this end, we empirically observe
that LLMs have already encoded rich knowledge in their pretrained parameters
and utilizing these internal knowledge improves the retrieval of external
knowledge when applying them to knowledge-intensive tasks. In this paper, we
propose a new internal and external knowledge interactive refinement paradigm
dubbed IEKR to utilize internal knowledge in LLM to help retrieve relevant
knowledge from the external knowledge base, as well as exploit the external
knowledge to refine the hallucination of generated internal knowledge. By
simply adding a prompt like 'Tell me something about' to the LLMs, we try to
review related explicit knowledge and insert them with the query into the
retriever for external retrieval. The external knowledge is utilized to
complement the internal knowledge into input of LLM for answers. We conduct
experiments on 3 benchmark datasets in knowledge-intensive question answering
task with different LLMs and domains, achieving the new state-of-the-art.
Further analysis shows the effectiveness of different modules in our approach.

摘要：最近的研究尝试将外部知识整合到 LLM 中，以解决 LLM 生成的内容中存在的局限性和潜在的事实错误。然而，如何从大量的外部知识中检索到正确的知识是一个挑战。为此，我们通过经验观察到，LLM 已在其预训练参数中编码了丰富的知识，利用这些内部知识可以改善在将它们应用于知识密集型任务时检索外部知识。在本文中，我们提出了一种新的内部和外部知识交互式细化范例，称为 IEKR，以利用 LLM 中的内部知识来帮助从外部知识库中检索相关知识，并利用外部知识来细化生成的内部知识的幻觉。通过简单地向 LLM 添加一个提示，如“告诉我一些关于”的内容，我们尝试查看相关的显式知识，并将它们与查询一起插入检索器中以进行外部检索。外部知识被用来补充 LLM 输入中的内部知识以获得答案。我们使用不同的 LLM 和领域对知识密集型问题回答任务中的 3 个基准数据集进行了实验，取得了新的最先进技术。进一步的分析显示了我们方法中不同模块的有效性。

##### **Open Llama2 Model for the Lithuanian Language**
2408.12963v1 by Artūras Nakvosas, Povilas Daniušis, Vytas Mulevičius

In this paper, we propose and describe the first open Llama2 large language
models (LLMs) for the Lithuanian language, including an accompanying
question/answer (Q/A) dataset and translations of popular LLM benchmarks. We
provide a brief review of open regional LLMs and detailed information on the
proposed LLMs and their training process. We also conduct an empirical
evaluation, comparing the perplexities of the proposed LLMs with those of other
modern open LLMs. In addition, benchmarking the proposed LLMs against language
understanding tasks reveals that high-quality pretraining datasets may be
essential for achieving models that perform efficiently on these benchmarks.
The full realisations of the described LLMs are available in the accompanying
open repository~\url{https://huggingface.co/neurotechnology}.

摘要：在本文中，我們提出並描述了第一個開放的立陶宛語 Llama2 大型語言模型 (LLM)，包括附帶的問題/答案 (Q/A) 資料集和流行 LLM 基準的翻譯。我們簡要回顧了開放區域 LLM，並詳細說明了建議的 LLM 及其訓練過程。我們還進行了一項實證評估，將建議的 LLM 的困惑度與其他現代開放 LLM 的困惑度進行比較。此外，將建議的 LLM 與語言理解任務進行基準測試表明，高品質的預訓練資料集對於實現模型在這些基準上有效執行可能至關重要。所述 LLM 的完整實現可以在附帶的開放儲存庫中找到~\url{https://huggingface.co/neurotechnology}。

##### **Multimodal Contrastive In-Context Learning**
2408.12959v1 by Yosuke Miyanishi, Minh Le Nguyen

The rapid growth of Large Language Models (LLMs) usage has highlighted the
importance of gradient-free in-context learning (ICL). However, interpreting
their inner workings remains challenging. This paper introduces a novel
multimodal contrastive in-context learning framework to enhance our
understanding of ICL in LLMs. First, we present a contrastive learning-based
interpretation of ICL in real-world settings, marking the distance of the
key-value representation as the differentiator in ICL. Second, we develop an
analytical framework to address biases in multimodal input formatting for
real-world datasets. We demonstrate the effectiveness of ICL examples where
baseline performance is poor, even when they are represented in unseen formats.
Lastly, we propose an on-the-fly approach for ICL (Anchored-by-Text ICL) that
demonstrates effectiveness in detecting hateful memes, a task where typical ICL
struggles due to resource limitations. Extensive experiments on multimodal
datasets reveal that our approach significantly improves ICL performance across
various scenarios, such as challenging tasks and resource-constrained
environments. Moreover, it provides valuable insights into the mechanisms of
in-context learning in LLMs. Our findings have important implications for
developing more interpretable, efficient, and robust multimodal AI systems,
especially in challenging tasks and resource-constrained environments.

摘要：大型語言模型 (LLM) 使用率的快速增長突顯了無梯度脈絡學習 (ICL) 的重要性。然而，解釋其內部運作仍然具有挑戰性。本文介紹了一個新穎的多模態對比脈絡學習框架，以增強我們對 LLM 中 ICL 的理解。首先，我們提出了基於對比學習的 ICL 在現實世界中的解釋，將鍵值表示的距離標記為 ICL 中的區別因素。其次，我們開發了一個分析框架來解決現實世界資料集中多模態輸入格式中的偏差。我們展示了 ICL 範例的有效性，其中基準效能很差，即使它們以未見過的格式表示也是如此。最後，我們提出了一個即時 ICL 方法（Anchored-by-Text ICL），它證明了在檢測仇恨迷因方面的有效性，這是典型 ICL 由於資源限制而難以應付的一項任務。對多模態資料集的廣泛實驗表明，我們的做法顯著改善了 ICL 在各種場景中的效能，例如具有挑戰性的任務和資源受限的環境。此外，它提供了寶貴的見解，了解 LLM 中脈絡學習的機制。我們的發現對於開發更具可解釋性、效率和強健性的多模態 AI 系統具有重要意義，尤其是在具有挑戰性的任務和資源受限的環境中。

##### **Causal-Guided Active Learning for Debiasing Large Language Models**
2408.12942v1 by Zhouhao Sun, Li Du, Xiao Ding, Yixuan Ma, Kaitao Qiu, Ting Liu, Bing Qin

Although achieving promising performance, recent analyses show that current
generative large language models (LLMs) may still capture dataset biases and
utilize them for generation, leading to poor generalizability and harmfulness
of LLMs. However, due to the diversity of dataset biases and the
over-optimization problem, previous prior-knowledge-based debiasing methods and
fine-tuning-based debiasing methods may not be suitable for current LLMs. To
address this issue, we explore combining active learning with the causal
mechanisms and propose a casual-guided active learning (CAL) framework, which
utilizes LLMs itself to automatically and autonomously identify informative
biased samples and induce the bias patterns. Then a cost-effective and
efficient in-context learning based method is employed to prevent LLMs from
utilizing dataset biases during generation. Experimental results show that CAL
can effectively recognize typical biased instances and induce various bias
patterns for debiasing LLMs.

摘要：儘管取得了可觀的效能，最近的分析顯示，現行的生成式大型語言模型 (LLM) 仍可能擷取資料集偏差，並將其用於生成，導致 LLM 的概括性不佳和有害性。然而，由於資料集偏差的多樣性和過度最佳化問題，先前的基於先驗知識的去偏差方法和基於微調的去偏差方法可能不適合於目前的 LLM。為了解決這個問題，我們探討將主動學習與因果機制結合起來，並提出一個因果引導主動學習 (CAL) 框架，它利用 LLM 本身自動且自主地識別具有資訊性的偏差樣本並誘導偏差模式。然後採用一種經濟且高效的基於情境學習的方法，以防止 LLM 在生成過程中利用資料集偏差。實驗結果表明，CAL 可以有效地識別典型的偏差實例，並誘導出各種偏差模式，以消除 LLM 的偏差。

##### **Trustworthy, Responsible, and Safe AI: A Comprehensive Architectural Framework for AI Safety with Challenges and Mitigations**
2408.12935v1 by Chen Chen, Ziyao Liu, Weifeng Jiang, Goh Si Qi, KwoK-Yan Lam

AI Safety is an emerging area of critical importance to the safe adoption and
deployment of AI systems. With the rapid proliferation of AI and especially
with the recent advancement of Generative AI (or GAI), the technology ecosystem
behind the design, development, adoption, and deployment of AI systems has
drastically changed, broadening the scope of AI Safety to address impacts on
public safety and national security. In this paper, we propose a novel
architectural framework for understanding and analyzing AI Safety; defining its
characteristics from three perspectives: Trustworthy AI, Responsible AI, and
Safe AI. We provide an extensive review of current research and advancements in
AI safety from these perspectives, highlighting their key challenges and
mitigation approaches. Through examples from state-of-the-art technologies,
particularly Large Language Models (LLMs), we present innovative mechanism,
methodologies, and techniques for designing and testing AI safety. Our goal is
to promote advancement in AI safety research, and ultimately enhance people's
trust in digital transformation.

摘要：AI 安全是安全採用和部署 AI 系統的關鍵領域。隨著 AI 的快速擴散，特別是最近生成式 AI (或 GAI) 的進步，設計、開發、採用和部署 AI 系統背後的技術生態系統已發生巨大變化，擴大了 AI 安全的範圍，以解決對公共安全和國家安全的影響。在本文中，我們提出了一個新的架構框架，用於理解和分析 AI 安全；從三個角度定義其特徵：可信賴的 AI、負責任的 AI 和安全的 AI。我們從這些角度對 AI 安全的當前研究和進展進行了廣泛的回顧，重點介紹了它們的主要挑戰和緩解方法。通過最先進技術的範例，特別是大語言模型 (LLM)，我們展示了用於設計和測試 AI 安全的創新機制、方法和技術。我們的目標是促進 AI 安全研究的進展，並最終增強人們對數位轉型的信任。

##### **What Do You Want? User-centric Prompt Generation for Text-to-image Synthesis via Multi-turn Guidance**
2408.12910v1 by Yilun Liu, Minggui He, Feiyu Yao, Yuhe Ji, Shimin Tao, Jingzhou Du, Duan Li, Jian Gao, Li Zhang, Hao Yang, Boxing Chen, Osamu Yoshie

The emergence of text-to-image synthesis (TIS) models has significantly
influenced digital image creation by producing high-quality visuals from
written descriptions. Yet these models heavily rely on the quality and
specificity of textual prompts, posing a challenge for novice users who may not
be familiar with TIS-model-preferred prompt writing. Existing solutions relieve
this via automatic model-preferred prompt generation from user queries.
However, this single-turn manner suffers from limited user-centricity in terms
of result interpretability and user interactivity. To address these issues, we
propose DialPrompt, a multi-turn dialogue-based TIS prompt generation model
that emphasises user-centricity. DialPrompt is designed to follow a multi-turn
guidance workflow, where in each round of dialogue the model queries user with
their preferences on possible optimization dimensions before generating the
final TIS prompt. To achieve this, we mined 15 essential dimensions for
high-quality prompts from advanced users and curated a multi-turn dataset.
Through training on this dataset, DialPrompt can improve interpretability by
allowing users to understand the correlation between specific phrases and image
attributes. Additionally, it enables greater user control and engagement in the
prompt generation process, leading to more personalized and visually satisfying
outputs. Experiments indicate that DialPrompt achieves a competitive result in
the quality of synthesized images, outperforming existing prompt engineering
approaches by 5.7%. Furthermore, in our user evaluation, DialPrompt outperforms
existing approaches by 46.5% in user-centricity score and is rated 7.9/10 by 19
human reviewers.

摘要：文本到圖像合成 (TIS) 模型的出現顯著影響了數位影像創作，能根據書面描述產生高品質的視覺效果。然而，這些模型極度依賴文字提示的品質和具體性，對不熟悉 TIS 模型偏好提示寫作的新手來說，這是一個挑戰。現有的解決方案透過從使用者查詢中自動產生模型偏好的提示來解決這個問題。然而，這種單回合的方式在結果的可解釋性和使用者互動性方面缺乏以使用者為中心的考量。為了解決這些問題，我們提出了 DialPrompt，一個基於多回合對話的 TIS 提示產生模型，強調以使用者為中心。DialPrompt 被設計為遵循多回合指導工作流程，在每一回合的對話中，模型會詢問使用者在可能的最佳化面向上的偏好，然後再產生最終的 TIS 提示。為了達成這個目標，我們從進階使用者中挖掘出 15 個高品質提示的重要面向，並策劃了一個多回合的資料集。透過在這個資料集上進行訓練，DialPrompt 能夠讓使用者了解特定詞組和影像屬性之間的關聯性，進而提升可解釋性。此外，它還能讓使用者在提示產生過程中擁有更大的控制權和參與度，進而產生更個人化且視覺上更令人滿意的輸出。實驗結果顯示，DialPrompt 在合成影像的品質上達到了競爭力的結果，比現有的提示工程方法高出 5.7%。此外，在我們的使用者評估中，DialPrompt 在以使用者為中心的評分上比現有的方法高出 46.5%，並獲得 19 位人類審查者的 7.9/10 評分。

##### **IAA: Inner-Adaptor Architecture Empowers Frozen Large Language Model with Multimodal Capabilities**
2408.12902v1 by Bin Wang, Chunyu Xie, Dawei Leng, Yuhui Yin

In the field of multimodal large language models (MLLMs), common methods
typically involve unfreezing the language model during training to foster
profound visual understanding. However, the fine-tuning of such models with
vision-language data often leads to a diminution of their natural language
processing (NLP) capabilities. To avoid this performance degradation, a
straightforward solution is to freeze the language model while developing
multimodal competencies. Unfortunately, previous works have not attained
satisfactory outcomes. Building on the strategy of freezing the language model,
we conduct thorough structural exploration and introduce the Inner-Adaptor
Architecture (IAA). Specifically, the architecture incorporates multiple
multimodal adaptors at varying depths within the large language model to
facilitate direct interaction with the inherently text-oriented transformer
layers, thereby enabling the frozen language model to acquire multimodal
capabilities. Unlike previous approaches of freezing language models that
require large-scale aligned data, our proposed architecture is able to achieve
superior performance on small-scale datasets. We conduct extensive experiments
to improve the general multimodal capabilities and visual grounding abilities
of the MLLM. Our approach remarkably outperforms previous state-of-the-art
methods across various vision-language benchmarks without sacrificing
performance on NLP tasks. Code and models are available at
https://github.com/360CVGroup/Inner-Adaptor-Architecture.

摘要：在多模態大型語言模型 (MLLM) 領域中，常見的方法通常包括在訓練過程中取消凍結語言模型，以促進深刻的視覺理解。然而，使用視覺語言資料微調此類模型通常會導致其自然語言處理 (NLP) 能力下降。為了避免這種效能下降，一個簡單的解決方案是在開發多模態能力時凍結語言模型。遺憾的是，先前的研究並未達成令人滿意的結果。基於凍結語言模型的策略，我們進行了徹底的結構探索，並引入了內部適配器架構 (IAA)。具體來說，此架構在大型語言模型中不同深度處納入了多個多模態適配器，以促進與本質上以文字為導向的轉換器層直接互動，從而使凍結的語言模型能夠獲得多模態能力。與需要大規模對齊資料的先前凍結語言模型方法不同，我們提出的架構能夠在小規模資料集上實現卓越的效能。我們進行了廣泛的實驗，以改善 MLLM 的一般多模態能力和視覺基礎能力。我們的做法在各種視覺語言基準上都顯著優於先前的最先進方法，同時不犧牲 NLP 任務的效能。程式碼和模型可在 https://github.com/360CVGroup/Inner-Adaptor-Architecture 取得。

##### **Multiple Areal Feature Aware Transportation Demand Prediction**
2408.12890v1 by Sumin Han, Jisun An, Youngjun Park, Suji Kim, Kitae Jang, Dongman Lee

A reliable short-term transportation demand prediction supports the
authorities in improving the capability of systems by optimizing schedules,
adjusting fleet sizes, and generating new transit networks. A handful of
research efforts incorporate one or a few areal features while learning
spatio-temporal correlation, to capture similar demand patterns between similar
areas. However, urban characteristics are polymorphic, and they need to be
understood by multiple areal features such as land use, sociodemographics, and
place-of-interest (POI) distribution. In this paper, we propose a novel
spatio-temporal multi-feature-aware graph convolutional recurrent network
(ST-MFGCRN) that fuses multiple areal features during spatio-temproal
understanding. Inside ST-MFGCRN, we devise sentinel attention to calculate the
areal similarity matrix by allowing each area to take partial attention if the
feature is not useful. We evaluate the proposed model on two real-world
transportation datasets, one with our constructed BusDJ dataset and one with
benchmark TaxiBJ. Results show that our model outperforms the state-of-the-art
baselines up to 7\% on BusDJ and 8\% on TaxiBJ dataset.

摘要：可靠的短期交通需求预测支持当局通过优化时间表、调整车队规模和生成新的交通网络来提高系统的运能。少数研究工作在学习时空相关性时纳入了一个或几个区域特征，以捕捉相似区域之间的相似需求模式。然而，城市特征是多态的，需要通过土地利用、社会人口统计和兴趣点 (POI) 分布等多个区域特征来理解它们。在本文中，我们提出了一种新颖的时空多特征感知图卷积循环网络 (ST-MFGCRN)，它在时空理解期间融合了多个区域特征。在 ST-MFGCRN 内部，我们设计了哨兵注意力，以计算区域相似性矩阵，允许每个区域在特征无用时采取部分注意力。我们在两个真实世界的交通数据集上评估了所提出的模型，一个是我们构建的 BusDJ 数据集，另一个是基准 TaxiBJ。结果表明，我们的模型在 BusDJ 上的性能比最先进的基线高出 7%，在 TaxiBJ 数据集上高出 8%。

##### **Spatio-Temporal Road Traffic Prediction using Real-time Regional Knowledge**
2408.12882v1 by Sumin Han, Jisun An, Dongman Lee

For traffic prediction in transportation services such as car-sharing and
ride-hailing, mid-term road traffic prediction (within a few hours) is
considered essential. However, the existing road-level traffic prediction has
mainly studied how significantly micro traffic events propagate to the adjacent
roads in terms of short-term prediction. On the other hand, recent attempts
have been made to incorporate regional knowledge such as POIs, road
characteristics, and real-time social events to help traffic prediction.
However, these studies lack in understandings of different modalities of
road-level and region-level spatio-temporal correlations and how to combine
such knowledge. This paper proposes a novel method that embeds real-time
region-level knowledge using POIs, satellite images, and real-time LTE access
traces via a regional spatio-temporal module that consists of dynamic
convolution and temporal attention, and conducts bipartite spatial transform
attention to convert into road-level knowledge. Then the model ingests this
embedded knowledge into a road-level attention-based prediction model.
Experimental results on real-world road traffic prediction show that our model
outperforms the baselines.

摘要：對於汽車共享和叫車等運輸服務中的交通預測，中期道路交通預測（數小時內）被認為是必要的。然而，現有的道路級交通預測主要研究微觀交通事件如何以短期預測的方式顯著傳播到相鄰道路。另一方面，最近已嘗試納入區域知識，例如 POI、道路特徵和實時社交活動，以幫助交通預測。然而，這些研究缺乏對道路級和區域級時空關聯的不同模式的理解，以及如何結合這些知識。本文提出了一種新穎的方法，該方法使用 POI、衛星圖像和實時 LTE 訪問軌跡，通過由動態卷積和時間注意組成的區域時空模組嵌入實時區域級知識，並進行二部空間轉換注意以轉換為道路級知識。然後，模型將此嵌入式知識輸入到基於道路級注意力的預測模型中。現實世界道路交通預測的實驗結果表明，我們的模型優於基線。

##### **Has Multimodal Learning Delivered Universal Intelligence in Healthcare? A Comprehensive Survey**
2408.12880v1 by Qika Lin, Yifan Zhu, Xin Mei, Ling Huang, Jingying Ma, Kai He, Zhen Peng, Erik Cambria, Mengling Feng

The rapid development of artificial intelligence has constantly reshaped the
field of intelligent healthcare and medicine. As a vital technology, multimodal
learning has increasingly garnered interest due to data complementarity,
comprehensive modeling form, and great application potential. Currently,
numerous researchers are dedicating their attention to this field, conducting
extensive studies and constructing abundant intelligent systems. Naturally, an
open question arises that has multimodal learning delivered universal
intelligence in healthcare? To answer the question, we adopt three unique
viewpoints for a holistic analysis. Firstly, we conduct a comprehensive survey
of the current progress of medical multimodal learning from the perspectives of
datasets, task-oriented methods, and universal foundation models. Based on
them, we further discuss the proposed question from five issues to explore the
real impacts of advanced techniques in healthcare, from data and technologies
to performance and ethics. The answer is that current technologies have NOT
achieved universal intelligence and there remains a significant journey to
undertake. Finally, in light of the above reviews and discussions, we point out
ten potential directions for exploration towards the goal of universal
intelligence in healthcare.

摘要：人工智能的快速发展持续重塑着智能医疗和医学领域。作为一项至关重要的技术，多模态学习由于数据互补性、综合建模形式和巨大的应用潜力而日益受到关注。目前，众多研究者将注意力投向这一领域，开展了广泛的研究并构建了丰富的智能系统。自然而然地，一个开放的问题出现了，即多模态学习是否在医疗保健中提供了通用智能？为了回答这个问题，我们采用三个独特的视角进行整体分析。首先，我们从数据集、面向任务的方法和通用基础模型的角度对医学多模态学习的当前进展进行了全面的调查。在此基础上，我们进一步从五个问题讨论了提出的问题，以探讨先进技术在医疗保健中的实际影响，从数据和技术到性能和伦理。答案是，当前技术尚未实现通用智能，并且仍有很长的路要走。最后，根据上述回顾和讨论，我们指出了实现医疗保健通用智能目标的十个潜在探索方向。

##### **Frequency-aware Feature Fusion for Dense Image Prediction**
2408.12879v1 by Linwei Chen, Ying Fu, Lin Gu, Chenggang Yan, Tatsuya Harada, Gao Huang

Dense image prediction tasks demand features with strong category information
and precise spatial boundary details at high resolution. To achieve this,
modern hierarchical models often utilize feature fusion, directly adding
upsampled coarse features from deep layers and high-resolution features from
lower levels. In this paper, we observe rapid variations in fused feature
values within objects, resulting in intra-category inconsistency due to
disturbed high-frequency features. Additionally, blurred boundaries in fused
features lack accurate high frequency, leading to boundary displacement.
Building upon these observations, we propose Frequency-Aware Feature Fusion
(FreqFusion), integrating an Adaptive Low-Pass Filter (ALPF) generator, an
offset generator, and an Adaptive High-Pass Filter (AHPF) generator. The ALPF
generator predicts spatially-variant low-pass filters to attenuate
high-frequency components within objects, reducing intra-class inconsistency
during upsampling. The offset generator refines large inconsistent features and
thin boundaries by replacing inconsistent features with more consistent ones
through resampling, while the AHPF generator enhances high-frequency detailed
boundary information lost during downsampling. Comprehensive visualization and
quantitative analysis demonstrate that FreqFusion effectively improves feature
consistency and sharpens object boundaries. Extensive experiments across
various dense prediction tasks confirm its effectiveness. The code is made
publicly available at https://github.com/Linwei-Chen/FreqFusion.

摘要：密集影像預測任務需要具有強類別資訊和高解析度精確空間邊界細節的特徵。為了達成此目標，現代分層模型通常使用特徵融合，直接將來自深層的向上取樣粗糙特徵和來自較低層級的高解析度特徵相加。在本文中，我們觀察到融合特徵值在物件內部快速變化，導致因高頻率特徵受到干擾而產生的類別內不一致性。此外，融合特徵中的模糊邊界缺乏準確的高頻率，導致邊界位移。基於這些觀察，我們提出頻率感知特徵融合 (FreqFusion)，整合自適應低通濾波器 (ALPF) 產生器、偏移產生器和自適應高通濾波器 (AHPF) 產生器。ALPF 產生器預測空間變異低通濾波器，以衰減物件內的頻率元件，減少上取樣期間的類內不一致性。偏移產生器透過重新取樣，以更一致的特徵取代不一致的特徵，來改善大型不一致特徵和細微邊界，而 AHPF 產生器則增強下取樣期間遺失的高頻率詳細邊界資訊。全面的視覺化和量化分析證明，FreqFusion 有效改善特徵一致性並銳化物件邊界。跨各種密集預測任務的大量實驗證實了其有效性。程式碼已公開在 https://github.com/Linwei-Chen/FreqFusion。

##### **DeepDelveAI: Identifying AI Related Documents in Large Scale Literature Data**
2408.12871v1 by Zhou Xiaochen, Liang Xingzhou, Zou Hui, Lu Yi, Qu Jingjing

This paper presents DeepDelveAI, a comprehensive dataset specifically curated
to identify AI-related research papers from a large-scale academic literature
database. The dataset was created using an advanced Long Short-Term Memory
(LSTM) model trained on a binary classification task to distinguish between
AI-related and non-AI-related papers. The model was trained and validated on a
vast dataset, achieving high accuracy, precision, recall, and F1-score. The
resulting DeepDelveAI dataset comprises over 9.4 million AI-related papers
published since Dartmouth Conference, from 1956 to 2024, providing a crucial
resource for analyzing trends, thematic developments, and the evolution of AI
research across various disciplines.

摘要：本文提出了 DeepDelveAI，這是一個專門策劃的綜合資料集，用於從大型學術文獻資料庫中識別與 AI 相關的研究論文。該資料集是使用先進的長短期記憶 (LSTM) 模型建立的，該模型在二元分類任務上進行訓練，以區分與 AI 相關的論文和與 AI 無關的論文。該模型在一個龐大的資料集上進行訓練和驗證，達到了很高的準確度、精確度、召回率和 F1 分數。產生的 DeepDelveAI 資料集包含自 1956 年至 2024 年達特茅斯會議以來發表的 940 萬篇與 AI 相關的論文，為分析趨勢、主題發展和 AI 研究在各個學科中的演變提供了重要的資源。

##### **Obfuscated Memory Malware Detection**
2408.12866v1 by Sharmila S P, Aruna Tiwari, Narendra S Chaudhari

Providing security for information is highly critical in the current era with
devices enabled with smart technology, where assuming a day without the
internet is highly impossible. Fast internet at a cheaper price, not only made
communication easy for legitimate users but also for cybercriminals to induce
attacks in various dimensions to breach privacy and security. Cybercriminals
gain illegal access and breach the privacy of users to harm them in multiple
ways. Malware is one such tool used by hackers to execute their malicious
intent. Development in AI technology is utilized by malware developers to cause
social harm. In this work, we intend to show how Artificial Intelligence and
Machine learning can be used to detect and mitigate these cyber-attacks induced
by malware in specific obfuscated malware. We conducted experiments with memory
feature engineering on memory analysis of malware samples. Binary
classification can identify whether a given sample is malware or not, but
identifying the type of malware will only guide what next step to be taken for
that malware, to stop it from proceeding with its further action. Hence, we
propose a multi-class classification model to detect the three types of
obfuscated malware with an accuracy of 89.07% using the Classic Random Forest
algorithm. To the best of our knowledge, there is very little amount of work
done in classifying multiple obfuscated malware by a single model. We also
compared our model with a few state-of-the-art models and found it
comparatively better.

摘要：在當今時代，為資訊提供安全保障至關重要，因為裝置啟用了智慧技術，假設沒有網路的一天幾乎是不可能的。快速且價格低廉的網路，不僅讓合法使用者能輕鬆溝通，也讓網路犯罪分子得以在各種層面發動攻擊，以破壞隱私和安全。網路犯罪分子取得非法存取權限，破壞使用者的隱私，對他們造成多種傷害。惡意軟體就是駭客用來執行惡意意圖的其中一種工具。惡意軟體開發人員利用人工智慧技術的發展，造成社會危害。在這項工作中，我們打算展示如何利用人工智慧和機器學習，來偵測並減輕惡意軟體引發的這些網路攻擊，特別是混淆惡意軟體。我們對惡意軟體範例的記憶體分析進行記憶體特徵工程，並進行實驗。二元分類可以識別給定的範例是否為惡意軟體，但識別惡意軟體的類型只能指導下一步對該惡意軟體採取哪些措施，以阻止它繼續採取進一步的行動。因此，我們提出一個多類別分類模型，使用經典隨機森林演算法，以 89.07% 的準確度偵測三種類型的混淆惡意軟體。據我們所知，由單一模型對多個混淆惡意軟體進行分類的工作非常少。我們也將我們的模型與幾個最先進的模型進行比較，發現它比較好。

##### **Memory-Efficient LLM Training with Online Subspace Descent**
2408.12857v1 by Kaizhao Liang, Bo Liu, Lizhang Chen, Qiang Liu

Recently, a wide range of memory-efficient LLM training algorithms have
gained substantial popularity. These methods leverage the low-rank structure of
gradients to project optimizer states into a subspace using projection matrix
found by singular value decomposition (SVD). However, convergence of these
algorithms is highly dependent on the update rules of their projection matrix.
In this work, we provide the \emph{first} convergence guarantee for arbitrary
update rules of projection matrix. This guarantee is generally applicable to
optimizers that can be analyzed with Hamiltonian Descent, including most common
ones, such as LION, Adam. Inspired by our theoretical understanding, we propose
Online Subspace Descent, a new family of subspace descent optimizer without
SVD. Instead of updating the projection matrix with eigenvectors, Online
Subspace Descent updates the projection matrix with online PCA. Online Subspace
Descent is flexible and introduces only minimum overhead to training. We show
that for the task of pretraining LLaMA models ranging from 60M to 7B parameters
on the C4 dataset, Online Subspace Descent achieves lower perplexity and better
downstream tasks performance than state-of-the-art low-rank training methods
across different settings and narrows the gap with full-rank baselines.

摘要：<paragraph>最近，一系列高效記憶體 LLM 訓練演算法獲得極大歡迎。這些方法利用梯度的低階結構，使用奇異值分解 (SVD) 找到的投影矩陣將最佳化器狀態投影到子空間中。然而，這些演算法的收斂高度依賴於其投影矩陣的更新規則。在這項工作中，我們提供投影矩陣任意更新規則的\emph{第一個}收斂保證。此保證通常適用於可透過哈密頓下降分析的最佳化器，包括最常見的 LION、Adam 等。受到我們理論理解的啟發，我們提出線上子空間下降，一種沒有 SVD 的新系列子空間下降最佳化器。線上子空間下降並非使用特徵向量更新投影矩陣，而是使用線上 PCA 更新投影矩陣。線上子空間下降具備彈性，且僅會對訓練造成極小額外的負擔。我們展示，對於在 C4 資料集上預訓練 LLaMA 模型（參數範圍從 60M 到 7B）的任務，線上子空間下降在不同設定下均能達成比現有低階訓練方法更低的困惑度和更好的下游任務效能，並縮小與全階基線的差距。</paragraph>

##### **Multi-Faceted Question Complexity Estimation Targeting Topic Domain-Specificity**
2408.12850v1 by Sujay R, Suki Perumal, Yash Nagraj, Anushka Ghei, Srinivas K S

Question difficulty estimation remains a multifaceted challenge in
educational and assessment settings. Traditional approaches often focus on
surface-level linguistic features or learner comprehension levels, neglecting
the intricate interplay of factors contributing to question complexity. This
paper presents a novel framework for domain-specific question difficulty
estimation, leveraging a suite of NLP techniques and knowledge graph analysis.
We introduce four key parameters: Topic Retrieval Cost, Topic Salience, Topic
Coherence, and Topic Superficiality, each capturing a distinct facet of
question complexity within a given subject domain. These parameters are
operationalized through topic modelling, knowledge graph analysis, and
information retrieval techniques. A model trained on these features
demonstrates the efficacy of our approach in predicting question difficulty. By
operationalizing these parameters, our framework offers a novel approach to
question complexity estimation, paving the way for more effective question
generation, assessment design, and adaptive learning systems across diverse
academic disciplines.

摘要：問題難度評估在教育和評量設定中仍然是一個多面向的挑戰。傳統方法通常專注於表面層次的語言特徵或學習者理解程度，忽略了導致問題複雜性的各種因素之間的複雜交互作用。本文提出了一個針對特定領域問題難度評估的新穎架構，利用了一系列自然語言處理技術和知識圖譜分析。我們引入了四個關鍵參數：主題檢索成本、主題顯著性、主題連貫性和主題表層性，每個參數都捕捉到特定主題領域內問題複雜性的不同方面。這些參數通過主題建模、知識圖譜分析和資訊檢索技術進行操作化。根據這些特徵訓練的模型證明了我們的方法在預測問題難度方面的效能。透過操作化這些參數，我們的架構提供了一個問題複雜性評估的新穎方法，為跨越不同學科的更有效問題產生、評量設計和適應性學習系統鋪平了道路。

##### **Online Fair Division with Contextual Bandits**
2408.12845v1 by Arun Verma, Indrajit Saha, Makoto Yokoo, Bryan Kian Hsiang Low

This paper considers a novel online fair division problem involving multiple
agents in which a learner observes an indivisible item that has to be
irrevocably allocated to one of the agents while satisfying a fairness and
efficiency constraint. Existing algorithms assume a small number of items with
a sufficiently large number of copies, which ensures a good utility estimation
for all item-agent pairs. However, such an assumption may not hold in many
real-life applications, e.g., an online platform that has a large number of
users (items) who only use the platform's service providers (agents) a few
times (a few copies of items), which makes it difficult to estimate the utility
for all item-agent pairs. To overcome this challenge, we model the online fair
division problem using contextual bandits, assuming the utility is an unknown
function of the item-agent features. We then propose algorithms for online fair
division with sub-linear regret guarantees. Our experimental results also
verify the different performance aspects of the proposed algorithms.

摘要：本文探討了一個新穎的線上公平分配問題，涉及多個代理，其中學習者觀察一個不可分割的項目，該項目必須不可撤銷地分配給其中一個代理，同時滿足公平性和效率限制。現有演算法假設數量少且副本數量充足的項目，這可確保所有項目代理對的良好效用估計。然而，在許多實際應用中，這樣的假設可能不成立，例如一個擁有大量用戶（項目）的線上平台，他們只使用該平台的服務提供者（代理）幾次（幾個項目的副本），這使得難以估計所有項目代理對的效用。為了克服這個挑戰，我們使用情境強盜對線上公平分配問題進行建模，假設效用是項目代理特徵的未知函數。然後，我們提出具有次線性遺憾保證的線上公平分配演算法。我們的實驗結果也驗證了所提出演算法的不同效能面向。

##### **Predicting Affective States from Screen Text Sentiment**
2408.12844v1 by Songyan Teng, Tianyi Zhang, Simon D'Alfonso, Vassilis Kostakos

The proliferation of mobile sensing technologies has enabled the study of
various physiological and behavioural phenomena through unobtrusive data
collection from smartphone sensors. This approach offers real-time insights
into individuals' physical and mental states, creating opportunities for
personalised treatment and interventions. However, the potential of analysing
the textual content viewed on smartphones to predict affective states remains
underexplored. To better understand how the screen text that users are exposed
to and interact with can influence their affects, we investigated a subset of
data obtained from a digital phenotyping study of Australian university
students conducted in 2023. We employed linear regression, zero-shot, and
multi-shot prompting using a large language model (LLM) to analyse
relationships between screen text and affective states. Our findings indicate
that multi-shot prompting substantially outperforms both linear regression and
zero-shot prompting, highlighting the importance of context in affect
prediction. We discuss the value of incorporating textual and sentiment data
for improving affect prediction, providing a basis for future advancements in
understanding smartphone use and wellbeing.

摘要：行動感測技術的普及，讓研究人員得以透過智慧型手機感測器收集非侵入式資料，來研究各種生理和行為現象。這種方法提供個人身體和心理狀態的即時見解，為個人化治療和介入創造機會。然而，分析智慧型手機上檢視的文字內容以預測情緒狀態的潛力仍未被充分探索。為了更了解使用者接觸和互動的螢幕文字如何影響其情緒，我們調查了 2023 年進行的一項澳洲大學生數位表型研究中獲得的資料子集。我們使用線性迴歸、零次提示和多重提示，並使用大型語言模型 (LLM) 來分析螢幕文字和情緒狀態之間的關係。我們的研究結果表明，多重提示在表現上大幅優於線性迴歸和零次提示，突顯了背景在情緒預測中的重要性。我們討論了將文字和情緒資料納入以改善情緒預測的價值，為未來在理解智慧型手機使用和幸福感方面的進展提供基礎。

##### **COVID-19 Probability Prediction Using Machine Learning: An Infectious Approach**
2408.12841v1 by Mohsen Asghari Ilani, Saba Moftakhar Tehran, Ashkan Kavei, Arian Radmehr

The ongoing COVID-19 pandemic continues to pose significant challenges to
global public health, despite the widespread availability of vaccines. Early
detection of the disease remains paramount in curbing its transmission and
mitigating its impact on public health systems. In response, this study delves
into the application of advanced machine learning (ML) techniques for
predicting COVID-19 infection probability. We conducted a rigorous
investigation into the efficacy of various ML models, including XGBoost, LGBM,
AdaBoost, Logistic Regression, Decision Tree, RandomForest, CatBoost, KNN, and
Deep Neural Networks (DNN). Leveraging a dataset comprising 4000 samples, with
3200 allocated for training and 800 for testing, our experiment offers
comprehensive insights into the performance of these models in COVID-19
prediction. Our findings reveal that Deep Neural Networks (DNN) emerge as the
top-performing model, exhibiting superior accuracy and recall metrics. With an
impressive accuracy rate of 89%, DNN demonstrates remarkable potential in early
COVID-19 detection. This underscores the efficacy of deep learning approaches
in leveraging complex data patterns to identify COVID-19 infections accurately.
This study underscores the critical role of machine learning, particularly deep
learning methodologies, in augmenting early detection efforts amidst the
ongoing pandemic. The success of DNN in accurately predicting COVID-19
infection probability highlights the importance of continued research and
development in leveraging advanced technologies to combat infectious diseases.

摘要：持續進行的 COVID-19 大流行病持續對全球公共衛生構成重大挑戰，儘管疫苗已廣泛提供。早期發現疾病仍然是遏制其傳播和減輕其對公共衛生系統影響的首要任務。為此，本研究深入探討先進機器學習 (ML) 技術在預測 COVID-19 感染機率方面的應用。我們對各種 ML 模型的效能進行了嚴謹的調查，包括 XGBoost、LGBM、AdaBoost、邏輯迴歸、決策樹、隨機森林、CatBoost、KNN 和深度神經網路 (DNN)。利用包含 4000 個樣本的資料集，其中 3200 個分配給訓練，800 個分配給測試，我們的實驗對這些模型在 COVID-19 預測中的效能提供了全面的見解。我們的研究結果顯示，深度神經網路 (DNN) 成為表現最佳的模型，展現出優異的準確度和召回率指標。DNN 以 89% 的驚人準確度，證明了在早期 COVID-19 檢測中的傑出潛力。這突顯了深度學習方法在利用複雜資料模式準確識別 COVID-19 感染方面的效能。本研究強調了機器學習，特別是深度學習方法，在持續的大流行病中擴增早期檢測工作中的關鍵作用。DNN 在準確預測 COVID-19 感染機率方面的成功，突顯了持續研究和開發利用先進技術來對抗傳染病的重要性。

##### **Exploring Machine Learning Models for Lung Cancer Level Classification: A comparative ML Approach**
2408.12838v1 by Mohsen Asghari Ilani, Saba Moftakhar Tehran, Ashkan Kavei, Hamed Alizadegan

This paper explores machine learning (ML) models for classifying lung cancer
levels to improve diagnostic accuracy and prognosis. Through parameter tuning
and rigorous evaluation, we assess various ML algorithms. Techniques like
minimum child weight and learning rate monitoring were used to reduce
overfitting and optimize performance. Our findings highlight the robust
performance of Deep Neural Network (DNN) models across all phases. Ensemble
methods, including voting and bagging, also showed promise in enhancing
predictive accuracy and robustness. However, Support Vector Machine (SVM)
models with the Sigmoid kernel faced challenges, indicating a need for further
refinement. Overall, our study provides insights into ML-based lung cancer
classification, emphasizing the importance of parameter tuning to optimize
model performance and improve diagnostic accuracy in oncological care.

摘要：本論文探討機器學習 (ML) 模型，用於分類肺癌等級以提升診斷準確度和預後。透過參數調整和嚴謹評估，我們評估各種 ML 演算法。使用最小子權重和學習率監控等技術來減少過度擬合並最佳化效能。我們的研究結果強調深度神經網路 (DNN) 模型在所有階段的強健效能。包括投票和 bagging 在內的整體方法，也在提升預測準確度和強健性方面展現優勢。然而，使用 Sigmoid 核心的支援向量機 (SVM) 模型面臨挑戰，顯示需要進一步改良。整體而言，我們的研究提供機器學習為基礎的肺癌分類見解，強調參數調整對於最佳化模型效能和提升腫瘤照護診斷準確度的重要性。

##### **Underwater SONAR Image Classification and Analysis using LIME-based Explainable Artificial Intelligence**
2408.12837v1 by Purushothaman Natarajan, Athira Nambiar

Deep learning techniques have revolutionized image classification by
mimicking human cognition and automating complex decision-making processes.
However, the deployment of AI systems in the wild, especially in high-security
domains such as defence, is curbed by the lack of explainability of the model.
To this end, eXplainable AI (XAI) is an emerging area of research that is
intended to explore the unexplained hidden black box nature of deep neural
networks. This paper explores the application of the eXplainable Artificial
Intelligence (XAI) tool to interpret the underwater image classification
results, one of the first works in the domain to the best of our knowledge. Our
study delves into the realm of SONAR image classification using a custom
dataset derived from diverse sources, including the Seabed Objects KLSG
dataset, the camera SONAR dataset, the mine SONAR images dataset, and the SCTD
dataset. An extensive analysis of transfer learning techniques for image
classification using benchmark Convolutional Neural Network (CNN) architectures
such as VGG16, ResNet50, InceptionV3, DenseNet121, etc. is carried out. On top
of this classification model, a post-hoc XAI technique, viz. Local
Interpretable Model-Agnostic Explanations (LIME) are incorporated to provide
transparent justifications for the model's decisions by perturbing input data
locally to see how predictions change. Furthermore, Submodular Picks LIME
(SP-LIME) a version of LIME particular to images, that perturbs the image based
on the submodular picks is also extensively studied. To this end, two
submodular optimization algorithms i.e. Quickshift and Simple Linear Iterative
Clustering (SLIC) are leveraged towards submodular picks. The extensive
analysis of XAI techniques highlights interpretability of the results in a more
human-compliant way, thus boosting our confidence and reliability.

摘要：深度学习技术通过模仿人类认知和自动执行复杂的决策过程，彻底改变了图像分类。
然而，人工智能系统在实际环境中的部署，尤其是在国防等高度安全领域，受到模型缺乏可解释性的限制。
为此，可解释人工智能 (XAI) 是一个新兴的研究领域，旨在探索深度神经网络无法解释的隐藏黑盒性质。
本文探讨了可解释人工智能 (XAI) 工具在解释水下图像分类结果中的应用，据我们所知，这是该领域最早的作品之一。
我们的研究深入到声纳图像分类领域，使用了一个从不同来源派生的自定义数据集，包括 Seabed Objects KLSG 数据集、照相机声纳数据集、水雷声纳图像数据集和 SCTD 数据集。
对使用基准卷积神经网络 (CNN) 架构（如 VGG16、ResNet50、InceptionV3、DenseNet121 等）进行图像分类的迁移学习技术的广泛分析已完成。
在此分类模型之上，一个事后 XAI 技术，即局部可解释模型不可知解释 (LIME) 被纳入，通过局部扰动输入数据以查看预测如何变化，为模型的决策提供透明的理由。
此外，还广泛研究了 LIME 的一个特定于图像的版本 Submodular Picks LIME (SP-LIME)，它基于子模块选择扰动图像。
为此，两个子模块优化算法，即 Quickshift 和简单线性迭代聚类 (SLIC) 被利用于子模块选择。
对 XAI 技术的广泛分析以更符合人类的方式突出了结果的可解释性，从而增强了我们的信心和可靠性。

##### **CLLMFS: A Contrastive Learning enhanced Large Language Model Framework for Few-Shot Named Entity Recognition**
2408.12834v1 by Yafeng Zhang, Zilan Yu, Yuang Huang, Jing Tang

Few-shot Named Entity Recognition (NER), the task of identifying named
entities with only a limited amount of labeled data, has gained increasing
significance in natural language processing. While existing methodologies have
shown some effectiveness, such as enriching label semantics through various
prompting modes or employing metric learning techniques, their performance
exhibits limited robustness across diverse domains due to the lack of rich
knowledge in their pre-trained models. To address this issue, we propose
CLLMFS, a Contrastive Learning enhanced Large Language Model (LLM) Framework
for Few-Shot Named Entity Recognition, achieving promising results with limited
training data. Considering the impact of LLM's internal representations on
downstream tasks, CLLMFS integrates Low-Rank Adaptation (LoRA) and contrastive
learning mechanisms specifically tailored for few-shot NER. By enhancing the
model's internal representations, CLLMFS effectively improves both entity
boundary awareness ability and entity recognition accuracy. Our method has
achieved state-of-the-art performance improvements on F1-score ranging from
2.58\% to 97.74\% over existing best-performing methods across several
recognized benchmarks. Furthermore, through cross-domain NER experiments
conducted on multiple datasets, we have further validated the robust
generalization capability of our method. Our code will be released in the near
future.

摘要：<paragraph>少样本命名实体识别 (NER)，仅使用少量标注数据识别命名实体的任务，在自然语言处理中变得越来越重要。虽然现有方法已经显示出一定的有效性，例如通过各种提示模式丰富标签语义或采用度量学习技术，但由于其预训练模型缺乏丰富的知识，其性能在不同领域表现出有限的鲁棒性。为了解决这个问题，我们提出了 CLLMFS，一个用于少样本命名实体识别的对比学习增强型大语言模型 (LLM) 框架，在训练数据有限的情况下取得了有希望的结果。考虑到 LLM 的内部表示对下游任务的影响，CLLMFS 集成了低秩自适应 (LoRA) 和对比学习机制，专门针对少样本 NER 量身定制。通过增强模型的内部表示，CLLMFS 有效地提高了实体边界感知能力和实体识别准确性。我们的方法在 F1 得分上取得了最先进的性能提升，在几个公认的基准上，与现有的最佳方法相比，提升幅度从 2.58% 到 97.74%。此外，通过在多个数据集上进行跨域 NER 实验，我们进一步验证了我们方法的稳健泛化能力。我们的代码将在不久的将来发布。</paragraph>

##### **LIMP: Large Language Model Enhanced Intent-aware Mobility Prediction**
2408.12832v1 by Songwei Li, Jie Feng, Jiawei Chi, Xinyuan Hu, Xiaomeng Zhao, Fengli Xu

Human mobility prediction is essential for applications like urban planning
and transportation management, yet it remains challenging due to the complex,
often implicit, intentions behind human behavior. Existing models predominantly
focus on spatiotemporal patterns, paying less attention to the underlying
intentions that govern movements. Recent advancements in large language models
(LLMs) offer a promising alternative research angle for integrating commonsense
reasoning into mobility prediction. However, it is a non-trivial problem
because LLMs are not natively built for mobility intention inference, and they
also face scalability issues and integration difficulties with spatiotemporal
models. To address these challenges, we propose a novel LIMP (LLMs for
Intent-ware Mobility Prediction) framework. Specifically, LIMP introduces an
"Analyze-Abstract-Infer" (A2I) agentic workflow to unleash LLM's commonsense
reasoning power for mobility intention inference. Besides, we design an
efficient fine-tuning scheme to transfer reasoning power from commercial LLM to
smaller-scale, open-source language model, ensuring LIMP's scalability to
millions of mobility records. Moreover, we propose a transformer-based
intention-aware mobility prediction model to effectively harness the intention
inference ability of LLM. Evaluated on two real-world datasets, LIMP
significantly outperforms baseline models, demonstrating improved accuracy in
next-location prediction and effective intention inference. The
interpretability of intention-aware mobility prediction highlights our LIMP
framework's potential for real-world applications. Codes and data can be found
in https://github.com/tsinghua-fib-lab/LIMP .

摘要：<paragraph>人類流動預測對於城市規劃和交通管理等應用至關重要，但由於人類行為背後複雜且通常隱含的意圖，這仍然具有挑戰性。現有模型主要關注時空模式，較少關注支配移動的根本意圖。大型語言模型 (LLM) 的最新進展為整合常識推理到流動預測中提供了有希望的替代研究角度。然而，這是一個非平凡的問題，因為 LLM 並非原生建構用於流動意圖推論，而且它們還面臨可擴充性和與時空模型整合的困難。為了應對這些挑戰，我們提出了一個新穎的 LIMP（用於意圖感知流動預測的 LLM）框架。具體來說，LIMP 引入了一個「分析-抽象-推論」(A2I) 代理工作流程，以釋放 LLM 的常識推理能力，用於流動意圖推論。此外，我們設計了一個高效的微調方案，以將推理能力從商用 LLM 轉移到小規模的開源語言模型，確保 LIMP 可擴充到數百萬條流動記錄。此外，我們提出了一個基於轉換器的意圖感知流動預測模型，以有效利用 LLM 的意圖推論能力。在兩個真實世界資料集上進行評估，LIMP 明顯優於基準模型，展示了在下一位置預測和有效意圖推論中提高的準確性。意圖感知流動預測的可解釋性突出了我們 LIMP 框架在實際應用中的潛力。可以在 https://github.com/tsinghua-fib-lab/LIMP 中找到程式碼和資料。</paragraph>

##### **Examining the Commitments and Difficulties Inherent in Multimodal Foundation Models for Street View Imagery**
2408.12821v1 by Zhenyuan Yang, Xuhui Lin, Qinyi He, Ziye Huang, Zhengliang Liu, Hanqi Jiang, Peng Shu, Zihao Wu, Yiwei Li, Stephen Law, Gengchen Mai, Tianming Liu, Tao Yang

The emergence of Large Language Models (LLMs) and multimodal foundation
models (FMs) has generated heightened interest in their applications that
integrate vision and language. This paper investigates the capabilities of
ChatGPT-4V and Gemini Pro for Street View Imagery, Built Environment, and
Interior by evaluating their performance across various tasks. The assessments
include street furniture identification, pedestrian and car counts, and road
width measurement in Street View Imagery; building function classification,
building age analysis, building height analysis, and building structure
classification in the Built Environment; and interior room classification,
interior design style analysis, interior furniture counts, and interior length
measurement in Interior. The results reveal proficiency in length measurement,
style analysis, question answering, and basic image understanding, but
highlight limitations in detailed recognition and counting tasks. While
zero-shot learning shows potential, performance varies depending on the problem
domains and image complexities. This study provides new insights into the
strengths and weaknesses of multimodal foundation models for practical
challenges in Street View Imagery, Built Environment, and Interior. Overall,
the findings demonstrate foundational multimodal intelligence, emphasizing the
potential of FMs to drive forward interdisciplinary applications at the
intersection of computer vision and language.

摘要：大型語言模型 (LLM) 和多模態基礎模型 (FM) 的出現，引起人們對其整合視覺和語言的應用產生濃厚興趣。本文探討 ChatGPT-4V 和 Gemini Pro 在街景影像、建築環境和室內方面的功能，並評估它們在各種任務中的表現。評估包括街景影像中的街道家具識別、行人和汽車數量，以及道路寬度測量；建築環境中的建築功能分類、建築年齡分析、建築高度分析和建築結構分類；以及室內房間分類、室內設計風格分析、室內家具數量和室內長度測量。結果顯示出在長度測量、風格分析、問題解答和基本影像理解方面的能力，但強調了在詳細識別和計數任務中的限制。儘管零次學習顯示出潛力，但性能會根據問題領域和影像複雜性而有所不同。本研究提供了對多模態基礎模型在街景影像、建築環境和室內實際挑戰中的優缺點的新見解。總體而言，研究結果展示了基礎多模態智能，強調了 FM 在電腦視覺和語言交叉領域推動跨學科應用程式的潛力。

##### **Staircase Cascaded Fusion of Lightweight Local Pattern Recognition and Long-Range Dependencies for Structural Crack Segmentation**
2408.12815v1 by Hui Liu, Chen Jia, Fan Shi, Xu Cheng, Mianzhao Wang, Shengyong Chen

Detecting cracks with pixel-level precision for key structures is a
significant challenge, as existing methods struggle to effectively integrate
local textures and pixel dependencies of cracks. Furthermore, these methods
often possess numerous parameters and substantial computational requirements,
complicating deployment on edge devices. In this paper, we propose a staircase
cascaded fusion crack segmentation network (CrackSCF) that generates
high-quality crack segmentation maps using minimal computational resources. We
constructed a staircase cascaded fusion module that effectively captures local
patterns of cracks and long-range dependencies of pixels, and it can suppress
background noise well. To reduce the computational resources required by the
model, we introduced a lightweight convolution block, which replaces all
convolution operations in the network, significantly reducing the required
computation and parameters without affecting the network's performance. To
evaluate our method, we created a challenging benchmark dataset called TUT and
conducted experiments on this dataset and five other public datasets. The
experimental results indicate that our method offers significant advantages
over existing methods, especially in handling background noise interference and
detailed crack segmentation. The F1 and mIoU scores on the TUT dataset are
0.8382 and 0.8473, respectively, achieving state-of-the-art (SOTA) performance
while requiring the least computational resources. The code and dataset is
available at https://github.com/Karl1109/CrackSCF.

摘要：使用像素級精度檢測關鍵結構的裂縫是一項重大挑戰，因為現有方法難以有效整合裂縫的局部紋理和像素依賴性。此外，這些方法通常擁有眾多參數和大量的計算需求，這使得在邊緣設備上進行部署變得複雜。在本文中，我們提出了一個階梯式級聯融合裂縫分割網路（CrackSCF），它使用最少的計算資源生成高品質的裂縫分割圖。我們構建了一個階梯式級聯融合模組，它有效地捕捉了裂縫的局部模式和像素的長程依賴性，並且可以很好地抑制背景噪聲。為了減少模型所需的計算資源，我們引入了一個輕量級卷積塊，它取代了網路中的所有卷積運算，顯著減少了所需的計算和參數，而不會影響網路的效能。為了評估我們的模型，我們創建了一個具有挑戰性的基準資料集，稱為 TUT，並在這個資料集和另外五個公開資料集上進行了實驗。實驗結果表明，我們的模型在處理背景噪聲干擾和詳細裂縫分割方面，比現有的方法具有顯著的優勢。在 TUT 資料集上的 F1 和 mIoU 分數分別為 0.8382 和 0.8473，在需要最少計算資源的情況下，達到了最先進（SOTA）的效能。程式碼和資料集可在 https://github.com/Karl1109/CrackSCF 取得。

##### **Grounding Fallacies Misrepresenting Scientific Publications in Evidence**
2408.12812v1 by Max Glockner, Yufang Hou, Preslav Nakov, Iryna Gurevych

Health-related misinformation claims often falsely cite a credible biomedical
publication as evidence, which superficially appears to support the false
claim. The publication does not really support the claim, but a reader could
believe it thanks to the use of logical fallacies. Here, we aim to detect and
to highlight such fallacies, which requires carefully assessing the exact
content of the misrepresented publications. To achieve this, we introduce
MissciPlus, an extension of the fallacy detection dataset Missci. MissciPlus
builds on Missci by grounding the applied fallacies in real-world passages from
misrepresented studies. This creates a realistic test-bed for detecting and
verbalizing these fallacies under real-world input conditions, and enables
novel passage-retrieval tasks. MissciPlus is the first logical fallacy dataset
which pairs the real-world misrepresented evidence with incorrect claims,
identical to the input to evidence-based fact-checking models. With MissciPlus,
we i) benchmark retrieval models in identifying passages that support claims
only when fallacies are applied, ii) evaluate how well LLMs articulate
fallacious reasoning from misrepresented scientific passages, and iii) assess
the effectiveness of fact-checking models in refuting claims that misrepresent
biomedical research. Our findings show that current fact-checking models
struggle to use relevant passages from misrepresented publications to refute
misinformation. Moreover, these passages can mislead LLMs into accepting false
claims as true.

摘要：與健康相關的錯誤訊息聲稱，通常會錯誤地引用可信的生物醫學出版物作為證據，表面上似乎支持錯誤的說法。該出版物並未真正支持該說法，但讀者可能會因為使用邏輯謬誤而相信它。在此，我們旨在檢測並強調此類謬誤，這需要仔細評估被錯誤陳述出版物的確切內容。為此，我們引入了 MissciPlus，這是謬誤檢測資料集 Missci 的延伸。MissciPlus 建立在 Missci 的基礎上，將應用謬誤建立在被錯誤陳述研究的真實世界段落中。這為在現實世界的輸入條件下檢測和表達這些謬誤創造了一個現實的測試環境，並啟用了新的段落檢索任務。MissciPlus 是第一個將真實世界中被錯誤陳述的證據與不正確說法配對的邏輯謬誤資料集，與基於證據的事實查核模型的輸入相同。使用 MissciPlus，我們 i) 對檢索模型進行基準測試，以識別僅在應用謬誤時支持說法的段落，ii) 評估 LLM 如何從被錯誤陳述的科學段落中表達謬誤推理，以及 iii) 評估事實查核模型在駁斥錯誤陳述生物醫學研究的說法方面的有效性。我們的研究結果表明，當前的事實查核模型難以使用被錯誤陳述出版物中的相關段落來駁斥錯誤訊息。此外，這些段落可能會誤導 LLM，使其將錯誤的說法視為真實。

##### **DutyTTE: Deciphering Uncertainty in Origin-Destination Travel Time Estimation**
2408.12809v1 by Xiaowei Mao, Yan Lin, Shengnan Guo, Yubin Chen, Xingyu Xian, Haomin Wen, Qisen Xu, Youfang Lin, Huaiyu Wan

Uncertainty quantification in travel time estimation (TTE) aims to estimate
the confidence interval for travel time, given the origin (O), destination (D),
and departure time (T). Accurately quantifying this uncertainty requires
generating the most likely path and assessing travel time uncertainty along the
path. This involves two main challenges: 1) Predicting a path that aligns with
the ground truth, and 2) modeling the impact of travel time in each segment on
overall uncertainty under varying conditions. We propose DutyTTE to address
these challenges. For the first challenge, we introduce a deep reinforcement
learning method to improve alignment between the predicted path and the ground
truth, providing more accurate travel time information from road segments to
improve TTE. For the second challenge, we propose a mixture of experts guided
uncertainty quantification mechanism to better capture travel time uncertainty
for each segment under varying contexts. Additionally, we calibrate our results
using Hoeffding's upper-confidence bound to provide statistical guarantees for
the estimated confidence intervals. Extensive experiments on two real-world
datasets demonstrate the superiority of our proposed method.

摘要：在旅遊時間估計 (TTE) 中的不確定量化旨在估計旅遊時間的信心區間，給定起點 (O)、目的地 (D) 和出發時間 (T)。準確量化此不確定性需要產生最可能的路線並評估沿路線的旅遊時間不確定性。這涉及兩個主要挑戰：1) 預測與地面實況相符的路線，以及 2) 在不同條件下對每個區段的旅遊時間影響進行建模，以了解整體不確定性。我們提出 DutyTTE 來應對這些挑戰。對於第一個挑戰，我們引入深度強化學習方法來改善預測路線與地面實況之間的對齊，從道路區段提供更準確的旅遊時間資訊，以改善 TTE。對於第二個挑戰，我們提出一個由專家引導的不確定性量化機制，以在不同的情境下更好地捕捉每個區段的旅遊時間不確定性。此外，我們使用 Hoeffding 的上置信界校正我們的結果，以提供估計信心區間的統計保證。在兩個真實世界資料集上的廣泛實驗證明了我們提出的方法的優越性。

##### **VALE: A Multimodal Visual and Language Explanation Framework for Image Classifiers using eXplainable AI and Language Models**
2408.12808v1 by Purushothaman Natarajan, Athira Nambiar

Deep Neural Networks (DNNs) have revolutionized various fields by enabling
task automation and reducing human error. However, their internal workings and
decision-making processes remain obscure due to their black box nature.
Consequently, the lack of interpretability limits the application of these
models in high-risk scenarios. To address this issue, the emerging field of
eXplainable Artificial Intelligence (XAI) aims to explain and interpret the
inner workings of DNNs. Despite advancements, XAI faces challenges such as the
semantic gap between machine and human understanding, the trade-off between
interpretability and performance, and the need for context-specific
explanations. To overcome these limitations, we propose a novel multimodal
framework named VALE Visual and Language Explanation. VALE integrates
explainable AI techniques with advanced language models to provide
comprehensive explanations. This framework utilizes visual explanations from
XAI tools, an advanced zero-shot image segmentation model, and a visual
language model to generate corresponding textual explanations. By combining
visual and textual explanations, VALE bridges the semantic gap between machine
outputs and human interpretation, delivering results that are more
comprehensible to users. In this paper, we conduct a pilot study of the VALE
framework for image classification tasks. Specifically, Shapley Additive
Explanations (SHAP) are used to identify the most influential regions in
classified images. The object of interest is then extracted using the Segment
Anything Model (SAM), and explanations are generated using state-of-the-art
pre-trained Vision-Language Models (VLMs). Extensive experimental studies are
performed on two datasets: the ImageNet dataset and a custom underwater SONAR
image dataset, demonstrating VALEs real-world applicability in underwater image
classification.

摘要：深度神經網路 (DNN) 透過實現任務自動化和減少人為錯誤，徹底改變了各個領域。然而，由於其黑箱本質，其內部運作和決策制定過程仍然模糊不清。因此，缺乏可解釋性限制了這些模型在高風險場景中的應用。為了解決這個問題，新興的解釋性人工智慧 (XAI) 領域旨在解釋和詮釋 DNN 的內部運作。儘管有進展，XAI 面臨諸如機器與人類理解之間的語義差距、可解釋性與效能之間的權衡，以及對特定於情境的解釋的需求等挑戰。為了克服這些限制，我們提出了一個名為 VALE 視覺和語言解釋的新多模態架構。VALE 將可解釋的人工智慧技術與先進的語言模型整合，以提供全面的解釋。此架構利用來自 XAI 工具的視覺解釋、先進的零次方影像分割模型和視覺語言模型來產生對應的文字解釋。透過結合視覺和文字解釋，VALE 彌合了機器輸出與人類詮釋之間的語義差距，提供更易於使用者理解的結果。在本文中，我們對 VALE 框架進行了影像分類任務的試驗研究。具體來說，Shapley 加法解釋 (SHAP) 用於識別分類影像中最具影響力的區域。然後使用 Segment Anything Model (SAM) 提取感興趣的物件，並使用最先進的預訓練視覺語言模型 (VLM) 產生解釋。在兩個資料集上進行了廣泛的實驗研究：ImageNet 資料集和自訂水下 SONAR 影像資料集，展示了 VALE 在水下影像分類中的實際應用。

##### **Is Generative AI the Next Tactical Cyber Weapon For Threat Actors? Unforeseen Implications of AI Generated Cyber Attacks**
2408.12806v1 by Yusuf Usman, Aadesh Upadhyay, Prashnna Gyawali, Robin Chataut

In an era where digital threats are increasingly sophisticated, the
intersection of Artificial Intelligence and cybersecurity presents both
promising defenses and potent dangers. This paper delves into the escalating
threat posed by the misuse of AI, specifically through the use of Large
Language Models (LLMs). This study details various techniques like the switch
method and character play method, which can be exploited by cybercriminals to
generate and automate cyber attacks. Through a series of controlled
experiments, the paper demonstrates how these models can be manipulated to
bypass ethical and privacy safeguards to effectively generate cyber attacks
such as social engineering, malicious code, payload generation, and spyware. By
testing these AI generated attacks on live systems, the study assesses their
effectiveness and the vulnerabilities they exploit, offering a practical
perspective on the risks AI poses to critical infrastructure. We also introduce
Occupy AI, a customized, finetuned LLM specifically engineered to automate and
execute cyberattacks. This specialized AI driven tool is adept at crafting
steps and generating executable code for a variety of cyber threats, including
phishing, malware injection, and system exploitation. The results underscore
the urgency for ethical AI practices, robust cybersecurity measures, and
regulatory oversight to mitigate AI related threats. This paper aims to elevate
awareness within the cybersecurity community about the evolving digital threat
landscape, advocating for proactive defense strategies and responsible AI
development to protect against emerging cyber threats.

摘要：在數位威脅日益複雜的時代，人工智慧與網路安全的交集既帶來有希望的防禦措施，也帶來潛在的危險。本文深入探討人工智慧遭濫用的威脅升級，特別是透過使用大型語言模型 (LLM) 的方式。本研究詳細說明各種技術，例如轉換方法和角色扮演方法，網路犯罪分子可利用這些方法來產生並自動化網路攻擊。透過一系列受控實驗，本文示範如何操縱這些模型來繞過道德和隱私保障措施，以有效產生網路攻擊，例如社交工程、惡意程式碼、酬載產生和間諜軟體。透過在實時系統上測試這些人工智慧產生的攻擊，本研究評估其效能和它們所利用的漏洞，提供人工智慧對關鍵基礎設施構成風險的實務觀點。我們也介紹佔領人工智慧，這是一個客製化、微調的 LLM，專門設計用來自動化並執行網路攻擊。這個由人工智慧驅動的特殊工具擅長製作步驟並為各種網路威脅產生可執行的程式碼，包括網路釣魚、惡意軟體注入和系統利用。結果強調了道德人工智慧實務、強健的網路安全措施和法規監督的急迫性，以減輕與人工智慧相關的威脅。本文旨在提升網路安全社群對不斷演變的數位威脅環境的認識，提倡主動防禦策略和負責任的人工智慧開發，以防範新興的網路威脅。

##### **A Safe Self-evolution Algorithm for Autonomous Driving Based on Data-Driven Risk Quantification Model**
2408.12805v1 by Shuo Yang, Shizhen Li, Yanjun Huang, Hong Chen

Autonomous driving systems with self-evolution capabilities have the
potential to independently evolve in complex and open environments, allowing to
handle more unknown scenarios. However, as a result of the safety-performance
trade-off mechanism of evolutionary algorithms, it is difficult to ensure safe
exploration without sacrificing the improvement ability. This problem is
especially prominent in dynamic traffic scenarios. Therefore, this paper
proposes a safe self-evolution algorithm for autonomous driving based on
data-driven risk quantification model. Specifically, a risk quantification
model based on the attention mechanism is proposed by modeling the way humans
perceive risks during driving, with the idea of achieving safety situation
estimation of the surrounding environment through a data-driven approach. To
prevent the impact of over-conservative safety guarding policies on the
self-evolution capability of the algorithm, a safety-evolutionary
decision-control integration algorithm with adjustable safety limits is
proposed, and the proposed risk quantization model is integrated into it.
Simulation and real-vehicle experiments results illustrate the effectiveness of
the proposed method. The results show that the proposed algorithm can generate
safe and reasonable actions in a variety of complex scenarios and guarantee
safety without losing the evolutionary potential of learning-based autonomous
driving systems.

摘要：具有自我演進能力的自動駕駛系統有潛力在複雜且開放的環境中獨立演進，從而能夠處理更多未知場景。然而，由於演算法演化安全效能權衡機制，難以在不犧牲改進能力下確保安全探索。此問題在動態交通場景中尤為突出。因此，本文提出基於數據驅動風險量化模型的自動駕駛安全自我演化演算法。具體而言，提出基於注意力機制的風險量化模型，模擬人類駕駛時感知風險的方式，以期通過數據驅動方式實現對周圍環境的安全態勢評估。為避免過於保守的安全防護策略對演算法自我演化能力的影響，提出具有可調安全邊界的安全演化決策控制整合演算法，並將所提出的風險量化模型整合其中。模擬與實車實驗結果說明了所提方法的有效性。結果表明，所提演算法能在多種複雜場景下產生安全合理的動作，且在不喪失學習型自動駕駛系統演化潛力的前提下保證安全性。

##### **Multi-Treatment Multi-Task Uplift Modeling for Enhancing User Growth**
2408.12803v1 by Yuxiang Wei, Zhaoxin Qiu, Yingjie Li, Yuke Sun, Xiaoling Li

As a key component in boosting online user growth, uplift modeling aims to
measure individual user responses (e.g., whether to play the game) to various
treatments, such as gaming bonuses, thereby enhancing business outcomes.
However, previous research typically considers a single-task, single-treatment
setting, where only one treatment exists and the overall treatment effect is
measured by a single type of user response. In this paper, we propose a
Multi-Treatment Multi-Task (MTMT) uplift network to estimate treatment effects
in a multi-task scenario. We identify the multi-treatment problem as a causal
inference problem with a tiered response, comprising a base effect (from
offering a treatment) and an incremental effect (from offering a specific type
of treatment), where the base effect can be numerically much larger than the
incremental effect. Specifically, MTMT separately encodes user features and
treatments. The user feature encoder uses a multi-gate mixture of experts
(MMOE) network to encode relevant user features, explicitly learning inter-task
relations. The resultant embeddings are used to measure natural responses per
task. Furthermore, we introduce a treatment-user feature interaction module to
model correlations between each treatment and user feature. Consequently, we
separately measure the base and incremental treatment effect for each task
based on the produced treatment-aware representations. Experimental results
based on an offline public dataset and an online proprietary dataset
demonstrate the effectiveness of MTMT in single/multi-treatment and
single/multi-task settings. Additionally, MTMT has been deployed in our gaming
platform to improve user experience.

摘要：<paragraph>作為提升線上用戶成長的重要組成部分，提升建模旨在測量個人用戶對各種處理（例如，是否玩遊戲）的反應，例如遊戲獎勵，從而提升業務成果。然而，先前的研究通常考慮單一任務、單一處理設置，其中僅存在一種處理，並且整體處理效果由單一類型的用戶反應來衡量。在本文中，我們提出了一個多處理多任務 (MTMT) 提升網路，以估計多任務場景中的處理效果。我們將多處理問題識別為具有分層響應的因果推論問題，包括基本效果（來自提供處理）和增量效果（來自提供特定類型的處理），其中基本效果在數值上可能遠大於增量效果。具體來說，MTMT 分別編碼用戶特徵和處理。用戶特徵編碼器使用專家多閘混合 (MMOE) 網路來編碼相關用戶特徵，明確學習任務間關係。所得嵌入用於測量每個任務的自然反應。此外，我們引入了一個處理用戶特徵交互模組來建模每個處理和用戶特徵之間的關聯。因此，我們根據產生的處理感知表徵，分別測量每個任務的基本和增量處理效果。基於離線公共數據集和線上專有數據集的實驗結果證明了 MTMT 在單一/多處理和單一/多任務設置中的有效性。此外，MTMT 已部署在我們的遊戲平台中以改善用戶體驗。</paragraph>

##### **Less for More: Enhancing Preference Learning in Generative Language Models with Automated Self-Curation of Training Corpora**
2408.12799v1 by JoonHo Lee, JuYoun Son, Juree Seok, Wooseok Jang, Yeong-Dae Kwon

Ambiguity in language presents challenges in developing more enhanced
language models, particularly in preference learning, where variability among
annotators results in inconsistently annotated datasets used for model
alignment. To address this issue, we introduce a self-curation method that
preprocesses annotated datasets by leveraging proxy models trained directly on
these datasets. Our method enhances preference learning by automatically
detecting and removing ambiguous annotations within the dataset. The proposed
approach is validated through extensive experiments, demonstrating a marked
improvement in performance across various instruction-following tasks. Our work
provides a straightforward and reliable method to overcome annotation
inconsistencies, serving as an initial step towards the development of more
advanced preference learning techniques.

摘要：語言中的歧義性對於開發更強化的語言模型構成挑戰，特別是在偏好學習中，標記員之間的變異性導致用於模型對齊的標記資料集不一致。為了解決這個問題，我們引入一種自我整理方法，透過利用直接在這些資料集上訓練的代理模型來預處理標記資料集。我們的模型透過自動偵測和移除資料集中有歧義的標記，增強偏好學習。所提出的方法透過廣泛的實驗驗證，證明在各種指令遵循任務中，效能都有顯著的提升。我們的研究提供一種直接且可靠的方法，來克服標記不一致性，作為邁向開發更進階偏好學習技術的初步步驟。

##### **BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks on Large Language Models**
2408.12798v1 by Yige Li, Hanxun Huang, Yunhan Zhao, Xingjun Ma, Jun Sun

Generative Large Language Models (LLMs) have made significant strides across
various tasks, but they remain vulnerable to backdoor attacks, where specific
triggers in the prompt cause the LLM to generate adversary-desired responses.
While most backdoor research has focused on vision or text classification
tasks, backdoor attacks in text generation have been largely overlooked. In
this work, we introduce \textit{BackdoorLLM}, the first comprehensive benchmark
for studying backdoor attacks on LLMs. \textit{BackdoorLLM} features: 1) a
repository of backdoor benchmarks with a standardized training pipeline, 2)
diverse attack strategies, including data poisoning, weight poisoning, hidden
state attacks, and chain-of-thought attacks, 3) extensive evaluations with over
200 experiments on 8 attacks across 7 scenarios and 6 model architectures, and
4) key insights into the effectiveness and limitations of backdoors in LLMs. We
hope \textit{BackdoorLLM} will raise awareness of backdoor threats and
contribute to advancing AI safety. The code is available at
\url{https://github.com/bboylyg/BackdoorLLM}.

摘要：生成式大型語言模型 (LLM) 在各項任務中已取得顯著進展，但它們仍然容易受到後門攻擊，而後門攻擊中提示中的特定觸發因素會導致 LLM 產生對手想要的回應。雖然大多數後門研究都集中在視覺或文本分類任務上，但文本生成中的後門攻擊在很大程度上被忽視了。在這項工作中，我們介紹了 \textit{BackdoorLLM}，這是第一個針對 LLM 上後門攻擊進行研究的綜合基準測試。\textit{BackdoorLLM} 的特點：1) 具有標準化訓練管線的後門基準測試儲存庫，2) 多樣化的攻擊策略，包括資料中毒、權重中毒、隱藏狀態攻擊和思維鏈攻擊，3) 在 7 個場景和 6 個模型架構中對 8 次攻擊進行了 200 多次實驗的廣泛評估，以及 4) 對 LLM 中後門的有效性和限制的主要見解。我們希望 \textit{BackdoorLLM} 能提高人們對後門威脅的認識，並有助於推進 AI 安全。程式碼可在 \url{https://github.com/bboylyg/BackdoorLLM} 取得。

##### **Real-Time Posture Monitoring and Risk Assessment for Manual Lifting Tasks Using MediaPipe and LSTM**
2408.12796v1 by Ereena Bagga, Ang Yang

This research focuses on developing a real-time posture monitoring and risk
assessment system for manual lifting tasks using advanced AI and computer
vision technologies. Musculoskeletal disorders (MSDs) are a significant concern
for workers involved in manual lifting, and traditional methods for posture
correction are often inadequate due to delayed feedback and lack of
personalized assessment. Our proposed solution integrates AI-driven posture
detection, detailed keypoint analysis, risk level determination, and real-time
feedback delivered through a user-friendly web interface. The system aims to
improve posture, reduce the risk of MSDs, and enhance user engagement. The
research involves comprehensive data collection, model training, and iterative
development to ensure high accuracy and user satisfaction. The solution's
effectiveness is evaluated against existing methodologies, demonstrating
significant improvements in real-time feedback and risk assessment. This study
contributes to the field by offering a novel approach to posture correction
that addresses existing gaps and provides practical, immediate benefits to
users.

摘要：本研究重點在於開發一個使用進階 AI 和電腦視覺技術，用於手動搬運任務的即時姿勢監控和風險評估系統。肌肉骨骼疾病 (MSD) 是從事手動搬運的員工的重要問題，而傳統的姿勢矯正方法通常因為回饋延遲和缺乏個人化評估而不足夠。我們提出的解決方案整合了 AI 驅動的姿勢偵測、詳細關鍵點分析、風險等級判定，以及透過使用者友善的網路介面提供的即時回饋。此系統旨在改善姿勢、降低 MSD 風險，並提升使用者參與度。本研究包含全面的資料收集、模型訓練，以及反覆開發，以確保高準確度和使用者滿意度。此解決方案的有效性會根據現有方法進行評估，證明在即時回饋和風險評估方面有顯著的改善。本研究透過提供一種新的姿勢矯正方法來為此領域做出貢獻，這種方法能解決現有的差距，並為使用者提供實際且立即的益處。

##### **Context-Aware Temporal Embedding of Objects in Video Data**
2408.12789v1 by Ahnaf Farhan, M. Shahriar Hossain

In video analysis, understanding the temporal context is crucial for
recognizing object interactions, event patterns, and contextual changes over
time. The proposed model leverages adjacency and semantic similarities between
objects from neighboring video frames to construct context-aware temporal
object embeddings. Unlike traditional methods that rely solely on visual
appearance, our temporal embedding model considers the contextual relationships
between objects, creating a meaningful embedding space where temporally
connected object's vectors are positioned in proximity. Empirical studies
demonstrate that our context-aware temporal embeddings can be used in
conjunction with conventional visual embeddings to enhance the effectiveness of
downstream applications. Moreover, the embeddings can be used to narrate a
video using a Large Language Model (LLM). This paper describes the intricate
details of the proposed objective function to generate context-aware temporal
object embeddings for video data and showcases the potential applications of
the generated embeddings in video analysis and object classification tasks.

摘要：在視訊分析中，了解時間背景對於辨識物件互動、事件模式和時間背景下的脈絡變化至關重要。所提出的模型利用相鄰視訊畫格中物件的鄰接性和語義相似性，來建構具脈絡感知的時間物件嵌入。與僅依賴視覺外觀的傳統方法不同，我們的時間嵌入模型考慮了物件之間的脈絡關係，創造了一個有意義的嵌入空間，其中時間連接的物件向量被放置在鄰近位置。實證研究表明，我們的具脈絡感知的時間嵌入可與傳統的視覺嵌入結合使用，以增強下游應用程式的效能。此外，這些嵌入可用於使用大型語言模型 (LLM) 來敘述影片。本文描述了所提出的目標函數的複雜細節，以產生影片資料的具脈絡感知的時間物件嵌入，並展示了所產生嵌入在影片分析和物件分類任務中的潛在應用。

##### **LLM-PBE: Assessing Data Privacy in Large Language Models**
2408.12787v1 by Qinbin Li, Junyuan Hong, Chulin Xie, Jeffrey Tan, Rachel Xin, Junyi Hou, Xavier Yin, Zhun Wang, Dan Hendrycks, Zhangyang Wang, Bo Li, Bingsheng He, Dawn Song

Large Language Models (LLMs) have become integral to numerous domains,
significantly advancing applications in data management, mining, and analysis.
Their profound capabilities in processing and interpreting complex language
data, however, bring to light pressing concerns regarding data privacy,
especially the risk of unintentional training data leakage. Despite the
critical nature of this issue, there has been no existing literature to offer a
comprehensive assessment of data privacy risks in LLMs. Addressing this gap,
our paper introduces LLM-PBE, a toolkit crafted specifically for the systematic
evaluation of data privacy risks in LLMs. LLM-PBE is designed to analyze
privacy across the entire lifecycle of LLMs, incorporating diverse attack and
defense strategies, and handling various data types and metrics. Through
detailed experimentation with multiple LLMs, LLM-PBE facilitates an in-depth
exploration of data privacy concerns, shedding light on influential factors
such as model size, data characteristics, and evolving temporal dimensions.
This study not only enriches the understanding of privacy issues in LLMs but
also serves as a vital resource for future research in the field. Aimed at
enhancing the breadth of knowledge in this area, the findings, resources, and
our full technical report are made available at https://llm-pbe.github.io/,
providing an open platform for academic and practical advancements in LLM
privacy assessment.

摘要：大型語言模型 (LLM) 已成為許多領域不可或缺的一部分，在數據管理、挖掘和分析方面顯著推動了應用程式。然而，LLM 在處理和詮釋複雜語言資料方面的深厚能力，卻突顯了關於資料隱私的迫切疑慮，特別是無意間訓練資料外洩的風險。儘管這個問題至關重要，但目前還沒有任何文獻提供對 LLM 中資料隱私風險的全面評估。為了解決這個差距，我們的論文引入了 LLM-PBE，這是一個專門為系統性評估 LLM 中資料隱私風險而打造的工具包。LLM-PBE 旨在分析 LLM 整個生命週期的隱私，納入多樣化的攻擊和防禦策略，並處理各種資料類型和指標。透過對多個 LLM 進行詳細的實驗，LLM-PBE 促進了對資料隱私疑慮的深入探討，闡明了模型大小、資料特徵和不斷變化的時間維度等影響因素。這項研究不僅豐富了對 LLM 中隱私問題的理解，也為該領域的未來研究提供了重要的資源。為了擴展這個領域的知識廣度，研究結果、資源和我們的完整技術報告已在 https://llm-pbe.github.io/ 提供，為 LLM 隱私評估的學術和實務進展提供了一個開放的平台。

##### **The Model Mastery Lifecycle: A Framework for Designing Human-AI Interaction**
2408.12781v1 by Mark Chignell, Mu-Huan Miles Chung, Jaturong Kongmanee, Khilan Jerath, Abhay Raman

The utilization of AI in an increasing number of fields is the latest
iteration of a long process, where machines and systems have been replacing
humans, or changing the roles that they play, in various tasks. Although humans
are often resistant to technological innovation, especially in workplaces,
there is a general trend towards increasing automation, and more recently, AI.
AI is now capable of carrying out, or assisting with, many tasks that used to
be regarded as exclusively requiring human expertise. In this paper we consider
the case of tasks that could be performed either by human experts or by AI and
locate them on a continuum running from exclusively human task performance at
one end to AI autonomy on the other, with a variety of forms of human-AI
interaction between those extremes. Implementation of AI is constrained by the
context of the systems and workflows that it will be embedded within. There is
an urgent need for methods to determine how AI should be used in different
situations and to develop appropriate methods of human-AI interaction so that
humans and AI can work together effectively to perform tasks. In response to
the evolving landscape of AI progress and increasing mastery, we introduce an
AI Mastery Lifecycle framework and discuss its implications for human-AI
interaction. The framework provides guidance on human-AI task allocation and
how human-AI interfaces need to adapt to improvements in AI task performance
over time. Within the framework we identify a zone of uncertainty where the
issues of human-AI task allocation and user interface design are likely to be
most challenging.

摘要：隨著 AI 在越來越多領域的應用，這只是機器和系統取代人類或改變人類在各項任務中所扮演角色的漫長過程中最新的一次反覆。儘管人類通常會抗拒技術創新，特別是在工作場所，但自動化和最近的 AI 卻有越來越盛行的趨勢。AI 現在有能力執行或協助許多任務，這些任務過去被認為只能由人類專家來執行。在本文中，我們考慮了可以由人類專家或 AI 執行的任務，並將它們定位在一個連續體上，從一端的完全由人類執行任務到另一端的 AI 自主，在這些極端之間有各種形式的人機互動。AI 的實作受到它將被嵌入其中的系統和工作流程的背景限制。迫切需要方法來確定 AI 應如何在不同情況下使用，並開發適當的人機互動方法，以便人類和 AI 能夠有效地合作執行任務。為了回應 AI 進展和日益精熟的演變態勢，我們引入了 AI 精熟度生命週期架構，並討論了它對人機互動的影響。該架構提供了人機任務分配的指導方針，以及隨著時間推移 AI 任務執行能力的提升，人機介面需要如何適應。在該架構內，我們確定了一個不確定區域，其中人機任務分配和使用者介面設計的問題可能最具挑戰性。

##### **Quality or Quantity? On Data Scale and Diversity in Adapting Large Language Models for Low-Resource Translation**
2408.12780v1 by Vivek Iyer, Bhavitvya Malik, Pavel Stepachev, Pinzhen Chen, Barry Haddow, Alexandra Birch

Despite the recent popularity of Large Language Models (LLMs) in Machine
Translation (MT), their performance in low-resource translation still lags
significantly behind Neural Machine Translation (NMT) models. In this paper, we
explore what it would take to adapt LLMs for low-resource settings. In
particular, we re-examine the role of two factors: a) the importance and
application of parallel data, and b) diversity in Supervised Fine-Tuning (SFT).
Recently, parallel data has been shown to be less important for MT using LLMs
than in previous MT research. Similarly, diversity during SFT has been shown to
promote significant transfer in LLMs across languages and tasks. However, for
low-resource LLM-MT, we show that the opposite is true for both of these
considerations: a) parallel data is critical during both pretraining and SFT,
and b) diversity tends to cause interference, not transfer. Our experiments,
conducted with 3 LLMs across 2 low-resourced language groups - indigenous
American and North-East Indian - reveal consistent patterns in both cases,
underscoring the generalizability of our findings. We believe these insights
will be valuable for scaling to massively multilingual LLM-MT models that can
effectively serve lower-resource languages.

摘要：儘管大型語言模型 (LLM) 在機器翻譯 (MT) 中近期很受歡迎，它們在低資源翻譯中的表現仍遠遠落後於神經機器翻譯 (NMT) 模型。在本文中，我們探討了適應低資源環境的 LLM 需要具備什麼條件。具體來說，我們重新審視了兩個因素的作用：a) 平行資料的重要性及其應用，以及 b) 監督微調 (SFT) 中的多樣性。最近，研究表明，對於使用 LLM 的 MT 而言，平行資料的重要性低於先前的 MT 研究。類似地，在 SFT 過程中，多樣性已被證明可以促進 LLM 在語言和任務之間的顯著轉移。然而，對於低資源 LLM-MT，我們表明這兩個考量恰恰相反：a) 平行資料在預訓練和 SFT 過程中至關重要，b) 多樣性傾向於造成干擾，而不是轉移。我們的實驗使用 3 個 LLM 在 2 個低資源語言組（美洲原住民和印度東北部）中進行，在兩種情況下都揭示了一致的模式，突顯了我們發現的普遍性。我們相信這些見解對於擴展到能夠有效服務於低資源語言的大規模多語言 LLM-MT 模型很有價值。

##### **Investigating LLM Applications in E-Commerce**
2408.12779v1 by Chester Palen-Michel, Ruixiang Wang, Yipeng Zhang, David Yu, Canran Xu, Zhe Wu

The emergence of Large Language Models (LLMs) has revolutionized natural
language processing in various applications especially in e-commerce. One
crucial step before the application of such LLMs in these fields is to
understand and compare the performance in different use cases in such tasks.
This paper explored the efficacy of LLMs in the e-commerce domain, focusing on
instruction-tuning an open source LLM model with public e-commerce datasets of
varying sizes and comparing the performance with the conventional models
prevalent in industrial applications. We conducted a comprehensive comparison
between LLMs and traditional pre-trained language models across specific tasks
intrinsic to the e-commerce domain, namely classification, generation,
summarization, and named entity recognition (NER). Furthermore, we examined the
effectiveness of the current niche industrial application of very large LLM,
using in-context learning, in e-commerce specific tasks. Our findings indicate
that few-shot inference with very large LLMs often does not outperform
fine-tuning smaller pre-trained models, underscoring the importance of
task-specific model optimization.Additionally, we investigated different
training methodologies such as single-task training, mixed-task training, and
LoRA merging both within domain/tasks and between different tasks. Through
rigorous experimentation and analysis, this paper offers valuable insights into
the potential effectiveness of LLMs to advance natural language processing
capabilities within the e-commerce industry.

摘要：大型語言模型 (LLM) 的出現徹底改變了自然語言處理在各種應用中的應用，特別是在電子商務中。在這些領域應用此類 LLM 之前的一個關鍵步驟是了解並比較在這些任務的不同用例中的性能。本文探討了 LLM 在電子商務領域的功效，重點關注使用不同規模的公開電子商務數據集對開源 LLM 模型進行指令微調，並將其性能與工業應用中流行的傳統模型進行比較。我們對 LLM 和傳統預訓練語言模型在電子商務領域固有的特定任務（即分類、生成、摘要和命名實體識別 (NER)）之間進行了全面比較。此外，我們使用情境學習檢查了當前利基產業應用中非常大的 LLM 的有效性，在電子商務特定任務中。我們的研究結果表明，使用非常大的 LLM 進行的少次推論通常不會優於微調較小的預訓練模型，這突顯了特定任務模型優化的重要性。此外，我們研究了不同的訓練方法，例如單任務訓練、混合任務訓練和 LoRA 在域/任務內和不同任務之間的合併。通過嚴謹的實驗和分析，本文提供了有價值的見解，了解 LLM 在電子商務行業內推進自然語言處理能力的潛在有效性。

##### **Intelligent OPC Engineer Assistant for Semiconductor Manufacturing**
2408.12775v1 by Guojin Chen, Haoyu Yang, Haoxing Ren, Bei Yu

Advancements in chip design and manufacturing have enabled the processing of
complex tasks such as deep learning and natural language processing, paving the
way for the development of artificial general intelligence (AGI). AI, on the
other hand, can be leveraged to innovate and streamline semiconductor
technology from planning and implementation to manufacturing. In this paper, we
present \textit{Intelligent OPC Engineer Assistant}, an AI/LLM-powered
methodology designed to solve the core manufacturing-aware optimization problem
known as optical proximity correction (OPC). The methodology involves a
reinforcement learning-based OPC recipe search and a customized multi-modal
agent system for recipe summarization. Experiments demonstrate that our
methodology can efficiently build OPC recipes on various chip designs with
specially handled design topologies, a task that typically requires the
full-time effort of OPC engineers with years of experience.

摘要：晶片設計與製造的進步，使得深度學習與自然語言處理等複雜任務的處理成為可能，為人工通用智慧 (AGI) 的發展鋪路。另一方面，人工智慧可以被用於創新和簡化半導體技術，從規劃和實施到製造。在本文中，我們提出「Intelligent OPC 工程師助理」，這是一種由 AI/LLM 驅動的方法論，旨在解決稱為光學鄰近修正 (OPC) 的核心製造感知最佳化問題。該方法論涉及基於強化學習的 OPC 配方搜尋，以及用於配方摘要的客製化多模態代理系統。實驗證明，我們的方法論可以在各種晶片設計上有效建立 OPC 配方，特別是處理設計拓撲，這項任務通常需要具有多年經驗的 OPC 工程師全職投入。

##### **Symmetric masking strategy enhances the performance of Masked Image Modeling**
2408.12772v1 by Khanh-Binh Nguyen, Chae Jung Park

Masked Image Modeling (MIM) is a technique in self-supervised learning that
focuses on acquiring detailed visual representations from unlabeled images by
estimating the missing pixels in randomly masked sections. It has proven to be
a powerful tool for the preliminary training of Vision Transformers (ViTs),
yielding impressive results across various tasks. Nevertheless, most MIM
methods heavily depend on the random masking strategy to formulate the pretext
task. This strategy necessitates numerous trials to ascertain the optimal
dropping ratio, which can be resource-intensive, requiring the model to be
pre-trained for anywhere between 800 to 1600 epochs. Furthermore, this approach
may not be suitable for all datasets. In this work, we propose a new masking
strategy that effectively helps the model capture global and local features.
Based on this masking strategy, SymMIM, our proposed training pipeline for MIM
is introduced. SymMIM achieves a new SOTA accuracy of 85.9\% on ImageNet using
ViT-Large and surpasses previous SOTA across downstream tasks such as image
classification, semantic segmentation, object detection, instance segmentation
tasks, and so on.

摘要：遮蔽影像建模 (Masked Image Modeling, MIM) 是一種自監督學習技術，其重點在於透過估計隨機遮蔽區段中遺失的畫素，從未標籤影像中獲取詳細的視覺表徵。它已被證明是 Vision Transformers (ViTs) 初步訓練的強大工具，在各種任務中產生令人印象深刻的結果。儘管如此，大多數 MIM 方法都高度依賴隨機遮蔽策略來制定藉口任務。此策略需要進行多次試驗才能確定最佳丟棄率，這可能會消耗大量資源，需要對模型進行 800 到 1600 個世代的預訓練。此外，此方法可能並不適用於所有資料集。在這項工作中，我們提出了一種新的遮蔽策略，可有效幫助模型擷取全局和局部特徵。基於此遮蔽策略，我們引入了用於 MIM 的建議訓練管線 SymMIM。SymMIM 使用 ViT-Large 在 ImageNet 上達到了 85.9% 的新 SOTA 精度，並在影像分類、語意分割、物件偵測、實例分割任務等下游任務中超越了先前的 SOTA。

##### **Assessing Modality Bias in Video Question Answering Benchmarks with Multimodal Large Language Models**
2408.12763v1 by Jean Park, Kuk Jin Jang, Basam Alasaly, Sriharsha Mopidevi, Andrew Zolensky, Eric Eaton, Insup Lee, Kevin Johnson

Multimodal large language models (MLLMs) can simultaneously process visual,
textual, and auditory data, capturing insights that complement human analysis.
However, existing video question-answering (VidQA) benchmarks and datasets
often exhibit a bias toward a single modality, despite the goal of requiring
advanced reasoning skills that integrate diverse modalities to answer the
queries. In this work, we introduce the modality importance score (MIS) to
identify such bias. It is designed to assess which modality embeds the
necessary information to answer the question. Additionally, we propose an
innovative method using state-of-the-art MLLMs to estimate the modality
importance, which can serve as a proxy for human judgments of modality
perception. With this MIS, we demonstrate the presence of unimodal bias and the
scarcity of genuinely multimodal questions in existing datasets. We further
validate the modality importance score with multiple ablation studies to
evaluate the performance of MLLMs on permuted feature sets. Our results
indicate that current models do not effectively integrate information due to
modality imbalance in existing datasets. Our proposed MLLM-derived MIS can
guide the curation of modality-balanced datasets that advance multimodal
learning and enhance MLLMs' capabilities to understand and utilize synergistic
relations across modalities.

摘要：多模态大型语言模型 (MLLM) 可以同时处理视觉、文本和听觉数据，捕捉补充人类分析的见解。然而，现有的视频问答 (VidQA) 基准和数据集通常表现出对单一模态的偏见，尽管目标是需要整合不同模态的高级推理技能来回答查询。在这项工作中，我们引入了模态重要性分数 (MIS) 来识别这种偏见。它旨在评估哪个模态嵌入了回答问题所需的必要信息。此外，我们提出了一种使用最先进的 MLLM 来估计模态重要性的创新方法，它可以作为人类对模态感知判断的代理。通过这个 MIS，我们展示了单模态偏见的出现和现有数据集中真正多模态问题的稀缺性。我们进一步通过多项消融研究验证了模态重要性分数，以评估 MLLM 在置换特征集上的性能。我们的结果表明，由于现有数据集中模态不平衡，当前模型不能有效地整合信息。我们提出的 MLLM 衍生的 MIS 可以指导对模态平衡数据集的整理，从而推进多模态学习并增强 MLLM 跨模态理解和利用协同关系的能力。

##### **Visual Verity in AI-Generated Imagery: Computational Metrics and Human-Centric Analysis**
2408.12762v1 by Memoona Aziz, Umair Rahman, Syed Ali Safi, Amir Zaib Abbasi

The rapid advancements in AI technologies have revolutionized the production
of graphical content across various sectors, including entertainment,
advertising, and e-commerce. These developments have spurred the need for
robust evaluation methods to assess the quality and realism of AI-generated
images. To address this, we conducted three studies. First, we introduced and
validated a questionnaire called Visual Verity, which measures photorealism,
image quality, and text-image alignment. Second, we applied this questionnaire
to assess images from AI models (DALL-E2, DALL-E3, GLIDE, Stable Diffusion) and
camera-generated images, revealing that camera-generated images excelled in
photorealism and text-image alignment, while AI models led in image quality. We
also analyzed statistical properties, finding that camera-generated images
scored lower in hue, saturation, and brightness. Third, we evaluated
computational metrics' alignment with human judgments, identifying MS-SSIM and
CLIP as the most consistent with human assessments. Additionally, we proposed
the Neural Feature Similarity Score (NFSS) for assessing image quality. Our
findings highlight the need for refining computational metrics to better
capture human visual perception, thereby enhancing AI-generated content
evaluation.

摘要：人工智能技術的快速進步，徹底改變了各個領域的圖形內容製作，包括娛樂、廣告和電子商務。這些發展促使需要穩健的評估方法來評估 AI 生成的圖像品質和真實性。為了解決這個問題，我們進行了三項研究。首先，我們介紹並驗證了一個名為 Visual Verity 的問卷，它測量了寫實性、圖像品質和文字與圖像的對齊方式。其次，我們使用這個問卷來評估來自 AI 模型（DALL-E2、DALL-E3、GLIDE、Stable Diffusion）和相機生成的圖像，結果顯示相機生成的圖像在寫實性和文字與圖像的對齊方面表現出色，而 AI 模型在圖像品質方面領先。我們還分析了統計特性，發現相機生成的圖像在色相、飽和度和亮度方面的得分較低。第三，我們評估了計算度量與人類判斷的一致性，發現 MS-SSIM 和 CLIP 與人類評估最一致。此外，我們提出了神經特徵相似度評分（NFSS）來評估圖像品質。我們的研究結果強調了改進計算度量以更好地捕捉人類視覺感知的必要性，從而增強 AI 生成的內容評估。

##### **SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination Detection**
2408.12748v1 by Mengya Hu, Rui Xu, Deren Lei, Yaxi Li, Mingyu Wang, Emily Ching, Eslam Kamal, Alex Deng

Large language models (LLMs) are highly capable but face latency challenges
in real-time applications, such as conducting online hallucination detection.
To overcome this issue, we propose a novel framework that leverages a small
language model (SLM) classifier for initial detection, followed by a LLM as
constrained reasoner to generate detailed explanations for detected
hallucinated content. This study optimizes the real-time interpretable
hallucination detection by introducing effective prompting techniques that
align LLM-generated explanations with SLM decisions. Empirical experiment
results demonstrate its effectiveness, thereby enhancing the overall user
experience.

摘要：大型語言模型 (LLM) 能力強大，但會在實時應用中面臨延遲挑戰，例如進行線上幻覺偵測。為了克服這個問題，我們提出一個創新的架構，它利用一個小型語言模型 (SLM) 分類器進行初始偵測，然後再使用 LLM 作為受限推理器，為偵測到的幻覺內容生成詳細的說明。這項研究透過導入有效提示技術來最佳化實時可解釋幻覺偵測，讓 LLM 生成的說明與 SLM 決策一致。實證實驗結果證明了它的有效性，進而提升整體使用者體驗。

##### **TReX- Reusing Vision Transformer's Attention for Efficient Xbar-based Computing**
2408.12742v1 by Abhishek Moitra, Abhiroop Bhattacharjee, Youngeun Kim, Priyadarshini Panda

Due to the high computation overhead of Vision Transformers (ViTs), In-memory
Computing architectures are being researched towards energy-efficient
deployment in edge-computing scenarios. Prior works have proposed efficient
algorithm-hardware co-design and IMC-architectural improvements to improve the
energy-efficiency of IMC-implemented ViTs. However, all prior works have
neglected the overhead and co-depencence of attention blocks on the
accuracy-energy-delay-area of IMC-implemented ViTs. To this end, we propose
TReX- an attention-reuse-driven ViT optimization framework that effectively
performs attention reuse in ViT models to achieve optimal
accuracy-energy-delay-area tradeoffs. TReX optimally chooses the transformer
encoders for attention reuse to achieve near iso-accuracy performance while
meeting the user-specified delay requirement. Based on our analysis on the
Imagenet-1k dataset, we find that TReX achieves 2.3x (2.19x) EDAP reduction and
1.86x (1.79x) TOPS/mm2 improvement with ~1% accuracy drop in case of DeiT-S
(LV-ViT-S) ViT models. Additionally, TReX achieves high accuracy at high EDAP
reduction compared to state-of-the-art token pruning and weight sharing
approaches. On NLP tasks such as CoLA, TReX leads to 2% higher non-ideal
accuracy compared to baseline at 1.6x lower EDAP.

摘要：由於視覺轉換器 (ViT) 的高運算負擔，內存中運算架構正被研究用於邊緣運算場景中的節能部署。先前的研究提出了高效的演算法硬體協同設計和 IMC 架構改進，以提高 IMC 實作的 ViT 的能效。然而，所有先前的研究都忽略了 IMC 實作的 ViT 的準確度、能耗、延遲和面積上的注意力區塊的負擔和相互依賴性。為此，我們提出了 TReX，一個由注意力重用驅動的 ViT 最佳化架構，它有效地在 ViT 模型中執行注意力重用，以達成最佳的準確度、能耗、延遲和面積折衷。TReX 最佳化地選擇Transformer編碼器進行注意力重用，以達成近似等準確度的效能，同時符合使用者指定的延遲需求。根據我們對 ImageNet-1k 資料集的分析，我們發現 TReX 在 DeiT-S (LV-ViT-S) ViT 模型中達到了 2.3 倍 (2.19 倍) 的 EDAP 減少和 1.86 倍 (1.79 倍) 的 TOPS/mm2 改進，同時準確度下降約 1%。此外，與最先進的代幣剪枝和權重共享方法相比，TReX 在高 EDAP 減少下實現了高準確度。在自然語言處理任務（例如 CoLA）上，TReX 在 EDAP 降低 1.6 倍的情況下，比基準高出 2% 的非理想準確度。

##### **Towards measuring fairness in speech recognition: Fair-Speech dataset**
2408.12734v1 by Irina-Elena Veliche, Zhuangqun Huang, Vineeth Ayyat Kochaniyan, Fuchun Peng, Ozlem Kalinli, Michael L. Seltzer

The current public datasets for speech recognition (ASR) tend not to focus
specifically on the fairness aspect, such as performance across different
demographic groups. This paper introduces a novel dataset, Fair-Speech, a
publicly released corpus to help researchers evaluate their ASR models for
accuracy across a diverse set of self-reported demographic information, such as
age, gender, ethnicity, geographic variation and whether the participants
consider themselves native English speakers. Our dataset includes approximately
26.5K utterances in recorded speech by 593 people in the United States, who
were paid to record and submit audios of themselves saying voice commands. We
also provide ASR baselines, including on models trained on transcribed and
untranscribed social media videos and open source models.

摘要：目前的語音辨識 (ASR) 公開資料集傾向於不特別關注公平性面向，例如不同人口統計群組的表現。這篇論文介紹了一個新資料集 Fair-Speech，這是一個公開發布的語料庫，協助研究人員評估其 ASR 模型在各種自我報告人口統計資訊（例如年齡、性別、種族、地理差異，以及參與者是否認為自己是英語母語人士）的準確性。我們的資料集包含美國 593 人錄製的語音，約 26.5K 個語句，這些人受雇錄製並提交他們說出語音指令的音訊。我們也提供 ASR 基準，包括在轉錄和未轉錄的社群媒體影片以及開放原始碼模型上訓練的模型。

##### **SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And Model Merging**
2408.12733v1 by Mohammadreza Pourreza, Ruoxi Sun, Hailong Li, Lesly Miculicich, Tomas Pfister, Sercan O. Arik

Text-to-SQL systems, which convert natural language queries into SQL
commands, have seen significant progress primarily for the SQLite dialect.
However, adapting these systems to other SQL dialects like BigQuery and
PostgreSQL remains a challenge due to the diversity in SQL syntax and
functions. We introduce SQL-GEN, a framework for generating high-quality
dialect-specific synthetic data guided by dialect-specific tutorials, and
demonstrate its effectiveness in creating training datasets for multiple
dialects. Our approach significantly improves performance, by up to 20\%, over
previous methods and reduces the gap with large-scale human-annotated datasets.
Moreover, combining our synthetic data with human-annotated data provides
additional performance boosts of 3.3\% to 5.6\%. We also introduce a novel
Mixture of Experts (MoE) initialization method that integrates dialect-specific
models into a unified system by merging self-attention layers and initializing
the gates with dialect-specific keywords, further enhancing performance across
different SQL dialects.

摘要：文本到 SQL 系統，將自然語言查詢轉換為 SQL 指令，主要針對 SQLite 方言取得顯著進展。然而，由於 SQL 語法和函數的多樣性，要將這些系統調整到其他 SQL 方言，例如 BigQuery 和 PostgreSQL，仍然是一項挑戰。我們引進 SQL-GEN，一個用於產生高品質特定於方言的合成資料的架構，由特定於方言的教學指引，並展示其在為多個方言建立訓練資料集的效能。我們的做法大幅提升效能，比先前的做法提升達 20%，並縮小與大型人工標註資料集的差距。此外，將我們的合成資料與人工標註資料結合，可進一步提升效能 3.3% 到 5.6%。我們也引進一種新穎的專家混合 (MoE) 初始化方法，透過合併自注意力層，並使用特定於方言的關鍵字初始化閘門，將特定於方言的模型整合到一個統一的系統中，進一步提升不同 SQL 方言的效能。

##### **Macro-Queries: An Exploration into Guided Chart Generation from High Level Prompts**
2408.12726v1 by Christopher J. Lee, Giorgio Tran, Roderick Tabalba, Jason Leigh, Ryan Longman

This paper explores the intersection of data visualization and Large Language
Models (LLMs). Driven by the need to make a broader range of data visualization
types accessible for novice users, we present a guided LLM-based pipeline
designed to transform data, guided by high-level user questions (referred to as
macro-queries), into a diverse set of useful visualizations. This approach
leverages various prompting techniques, fine-tuning inspired by Abela's Chart
Taxonomy, and integrated SQL tool usage.

摘要：本文探討資料視覺化與大型語言模型 (LLM) 的交集。在讓更多種類的資料視覺化類型能被新手使用者存取的需求驅動下，我們提出一個引導式的基於 LLM 的管線，它被設計成能將資料轉換成各種有用的視覺化，而轉換的依據是使用者提出的高階問題（稱為巨量查詢）。這種方法利用了各種提示技術、受 Abela 圖表分類法啟發的微調，以及整合的 SQL 工具使用。

##### **Generating Realistic X-ray Scattering Images Using Stable Diffusion and Human-in-the-loop Annotations**
2408.12720v1 by Zhuowen Zhao, Xiaoya Chong, Tanny Chavez, Alexander Hexemer

We fine-tuned a foundational stable diffusion model using X-ray scattering
images and their corresponding descriptions to generate new scientific images
from given prompts. However, some of the generated images exhibit significant
unrealistic artifacts, commonly known as "hallucinations". To address this
issue, we trained various computer vision models on a dataset composed of 60%
human-approved generated images and 40% experimental images to detect
unrealistic images. The classified images were then reviewed and corrected by
human experts, and subsequently used to further refine the classifiers in next
rounds of training and inference. Our evaluations demonstrate the feasibility
of generating high-fidelity, domain-specific images using a fine-tuned
diffusion model. We anticipate that generative AI will play a crucial role in
enhancing data augmentation and driving the development of digital twins in
scientific research facilities.

摘要：我們使用 X 射線散射影像及其對應描述微調了基礎的穩定擴散模型，以從給定的提示生成新的科學影像。然而，某些生成的影像會出現顯著的不真實人工製品，通常稱為「幻覺」。為了解決這個問題，我們在一個由 60% 人類核准生成的影像和 40% 實驗影像組成的資料集上訓練了各種電腦視覺模型，以偵測不真實的影像。分類後的影像隨後由人類專家檢閱和更正，並進一步用於在下一輪的訓練和推論中進一步優化分類器。我們的評估證明了使用微調擴散模型生成高保真、特定領域影像的可行性。我們預期生成式 AI 將在加強資料擴充和推動科學研究機構中數位雙胞胎的發展中扮演關鍵角色。

##### **Towards Estimating Personal Values in Song Lyrics**
2408.12694v1 by Andrew M. Demetriou, Jaehun Kim, Sandy Manolios, Cynthia C. S. Liem

Most music widely consumed in Western Countries contains song lyrics, with
U.S. samples reporting almost all of their song libraries contain lyrics. In
parallel, social science theory suggests that personal values - the abstract
goals that guide our decisions and behaviors - play an important role in
communication: we share what is important to us to coordinate efforts, solve
problems and meet challenges. Thus, the values communicated in song lyrics may
be similar or different to those of the listener, and by extension affect the
listener's reaction to the song. This suggests that working towards automated
estimation of values in lyrics may assist in downstream MIR tasks, in
particular, personalization. However, as highly subjective text, song lyrics
present a challenge in terms of sampling songs to be annotated, annotation
methods, and in choosing a method for aggregation. In this project, we take a
perspectivist approach, guided by social science theory, to gathering
annotations, estimating their quality, and aggregating them. We then compare
aggregated ratings to estimates based on pre-trained sentence/word embedding
models by employing a validated value dictionary. We discuss conceptually
'fuzzy' solutions to sampling and annotation challenges, promising initial
results in annotation quality and in automated estimations, and future
directions.

摘要：在西方國家廣泛流傳的大部分音樂都包含歌詞，美國的樣本報告指出，他們幾乎所有的歌曲庫都包含歌詞。與此同時，社會科學理論表明，個人價值觀（指導我們決策和行為的抽象目標）在溝通中扮演著重要的角色：我們會分享對我們來說重要的事物，以協調努力、解決問題和應對挑戰。因此，歌詞中傳達的價值觀可能與聽眾的價值觀相似或不同，並進而影響聽眾對歌曲的反應。這表明致力於自動估計歌詞中的價值觀可能有助於下游音樂資訊檢索任務，特別是個人化。然而，作為高度主觀的文字，歌詞在歌曲取樣、註釋方法和選擇聚合方法方面提出了挑戰。在這個專案中，我們採取觀點主義的方法，以社會科學理論為指導，來收集註釋、估計其品質並將其聚合。然後，我們透過採用經過驗證的價值觀詞典，將聚合評分與基於預先訓練的句子/詞彙嵌入模型所做的估計進行比較。我們在概念上討論了取樣和註釋挑戰的「模糊」解決方案，承諾在註釋品質和自動估計方面取得初步成果，並提出未來的方向。

##### **Unlocking Intrinsic Fairness in Stable Diffusion**
2408.12692v1 by Eunji Kim, Siwon Kim, Rahim Entezari, Sungroh Yoon

Recent text-to-image models like Stable Diffusion produce photo-realistic
images but often show demographic biases. Previous debiasing methods focused on
training-based approaches, failing to explore the root causes of bias and
overlooking Stable Diffusion's potential for unbiased image generation. In this
paper, we demonstrate that Stable Diffusion inherently possesses fairness,
which can be unlocked to achieve debiased outputs. Through carefully designed
experiments, we identify the excessive bonding between text prompts and the
diffusion process as a key source of bias. To address this, we propose a novel
approach that perturbs text conditions to unleash Stable Diffusion's intrinsic
fairness. Our method effectively mitigates bias without additional tuning,
while preserving image-text alignment and image quality.

摘要：最近的文本到图像模型，像是 Stable Diffusion，可以产生逼真的图像，但经常出现人口统计偏差。先前的去偏方法专注于基于训练的方法，未能探索偏差的根本原因，并且忽略了 Stable Diffusion 在无偏图像生成方面的潜力。在本文中，我们证明了 Stable Diffusion 本质上具有公平性，可以解锁以实现去偏输出。通过精心设计的实验，我们确定文本提示和扩散过程之间的过度绑定是造成偏差的关键来源。为了解决这个问题，我们提出了一种新颖的方法，该方法扰动文本条件以释放 Stable Diffusion 的内在公平性。我们的方法有效地减轻了偏差，而无需额外的调整，同时保留了图像文本对齐和图像质量。

##### **MultiMed: Massively Multimodal and Multitask Medical Understanding**
2408.12682v1 by Shentong Mo, Paul Pu Liang

Biomedical data is inherently multimodal, consisting of electronic health
records, medical imaging, digital pathology, genome sequencing, wearable
sensors, and more. The application of artificial intelligence tools to these
multifaceted sensing technologies has the potential to revolutionize the
prognosis, diagnosis, and management of human health and disease. However,
current approaches to biomedical AI typically only train and evaluate with one
or a small set of medical modalities and tasks. This limitation hampers the
development of comprehensive tools that can leverage the rich interconnected
information across many heterogeneous biomedical sensors. To address this
challenge, we present MultiMed, a benchmark designed to evaluate and enable
large-scale learning across a wide spectrum of medical modalities and tasks.
MultiMed consists of 2.56 million samples across ten medical modalities such as
medical reports, pathology, genomics, and protein data, and is structured into
eleven challenging tasks, including disease prognosis, protein structure
prediction, and medical question answering. Using MultiMed, we conduct
comprehensive experiments benchmarking state-of-the-art unimodal, multimodal,
and multitask models. Our analysis highlights the advantages of training
large-scale medical models across many related modalities and tasks. Moreover,
MultiMed enables studies of generalization across related medical concepts,
robustness to real-world noisy data and distribution shifts, and novel modality
combinations to improve prediction performance. MultiMed will be publicly
available and regularly updated and welcomes inputs from the community.

摘要：生物医学数据本质上是多模态的，由电子健康记录、医学影像、数字病理学、基因组测序、可穿戴传感器等组成。将人工智能工具应用于这些多方面的传感技术有可能彻底改变人类健康和疾病的预后、诊断和管理。然而，当前对生物医学人工智能的方法通常只针对一种或一小组医学方式和任务进行训练和评估。这种限制阻碍了能够利用许多异构生物医学传感器之间的丰富互联信息来开发综合工具。为了应对这一挑战，我们提出了 MultiMed，这是一个旨在评估和支持跨广泛医学方式和任务进行大规模学习的基准。MultiMed 包含了十种医学方式（例如医学报告、病理学、基因组学和蛋白质数据）中的 256 万个样本，并被构建成十一个具有挑战性的任务，包括疾病预后、蛋白质结构预测和医学问题解答。使用 MultiMed，我们进行了全面的实验，对最先进的单模态、多模态和多任务模型进行了基准测试。我们的分析突出了跨许多相关方式和任务训练大规模医学模型的优势。此外，MultiMed 支持对相关医学概念的泛化、对真实世界噪声数据和分布变化的鲁棒性以及新的方式组合以提高预测性能的研究。MultiMed 将公开提供并定期更新，并欢迎社区的意见。

##### **Can LLMs Understand Social Norms in Autonomous Driving Games?**
2408.12680v1 by Boxuan Wang, Haonan Duan, Yanhao Feng, Xu Chen, Yongjie Fu, Zhaobin Mo, Xuan Di

Social norm is defined as a shared standard of acceptable behavior in a
society. The emergence of social norms fosters coordination among agents
without any hard-coded rules, which is crucial for the large-scale deployment
of AVs in an intelligent transportation system. This paper explores the
application of LLMs in understanding and modeling social norms in autonomous
driving games. We introduce LLMs into autonomous driving games as intelligent
agents who make decisions according to text prompts. These agents are referred
to as LLM-based agents. Our framework involves LLM-based agents playing Markov
games in a multi-agent system (MAS), allowing us to investigate the emergence
of social norms among individual agents. We aim to identify social norms by
designing prompts and utilizing LLMs on textual information related to the
environment setup and the observations of LLM-based agents. Using the OpenAI
Chat API powered by GPT-4.0, we conduct experiments to simulate interactions
and evaluate the performance of LLM-based agents in two driving scenarios:
unsignalized intersection and highway platoon. The results show that LLM-based
agents can handle dynamically changing environments in Markov games, and social
norms evolve among LLM-based agents in both scenarios. In the intersection
game, LLM-based agents tend to adopt a conservative driving policy when facing
a potential car crash. The advantage of LLM-based agents in games lies in their
strong operability and analyzability, which facilitate experimental design.

摘要：社會規範被定義為社會中可接受行為的共同標準。社會規範的出現促進了代理人之間的協調，而無需任何硬編碼規則，這對於在智能交通系統中大規模部署自動駕駛汽車至關重要。本文探討了 LLM 在理解和建模自動駕駛遊戲中的社會規範中的應用。我們將 LLM 引入自動駕駛遊戲中，作為根據文本提示做出決策的智能代理。這些代理稱為基於 LLM 的代理。我們的框架涉及基於 LLM 的代理在多代理系統 (MAS) 中玩馬可夫遊戲，這使我們能夠研究個體代理之間社會規範的出現。我們旨在通過設計提示並利用 LLM 處理與環境設置和基於 LLM 的代理觀察相關的文本信息來識別社會規範。使用由 GPT-4.0 提供支持的 OpenAI 聊天 API，我們進行實驗模擬交互，並評估基於 LLM 的代理在兩種駕駛場景中的性能：無信號交叉路口和高速公路車隊。結果表明，基於 LLM 的代理可以在馬可夫遊戲中處理動態變化的環境，並且社會規範在兩種場景中都在基於 LLM 的代理之間演變。在交叉路口遊戲中，基於 LLM 的代理在面對潛在車禍時傾向於採取保守的駕駛策略。基於 LLM 的代理在遊戲中的優勢在於它們的強大可操作性和可分析性，這有助於實驗設計。

##### **Enhancing Transferability of Adversarial Attacks with GE-AdvGAN+: A Comprehensive Framework for Gradient Editing**
2408.12673v1 by Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Yuchen Zhang, Jiahao Huang, Jianlong Zhou, Fang Chen

Transferable adversarial attacks pose significant threats to deep neural
networks, particularly in black-box scenarios where internal model information
is inaccessible. Studying adversarial attack methods helps advance the
performance of defense mechanisms and explore model vulnerabilities. These
methods can uncover and exploit weaknesses in models, promoting the development
of more robust architectures. However, current methods for transferable attacks
often come with substantial computational costs, limiting their deployment and
application, especially in edge computing scenarios. Adversarial generative
models, such as Generative Adversarial Networks (GANs), are characterized by
their ability to generate samples without the need for retraining after an
initial training phase. GE-AdvGAN, a recent method for transferable adversarial
attacks, is based on this principle. In this paper, we propose a novel general
framework for gradient editing-based transferable attacks, named GE-AdvGAN+,
which integrates nearly all mainstream attack methods to enhance
transferability while significantly reducing computational resource
consumption. Our experiments demonstrate the compatibility and effectiveness of
our framework. Compared to the baseline AdvGAN, our best-performing method,
GE-AdvGAN++, achieves an average ASR improvement of 47.8. Additionally, it
surpasses the latest competing algorithm, GE-AdvGAN, with an average ASR
increase of 5.9. The framework also exhibits enhanced computational efficiency,
achieving 2217.7 FPS, outperforming traditional methods such as BIM and
MI-FGSM. The implementation code for our GE-AdvGAN+ framework is available at
https://github.com/GEAdvGANP

摘要：可傳遞對抗攻擊對深度神經網路構成重大威脅，特別是在無法取得內部模型資訊的黑盒情境中。研究對抗攻擊方法有助於提升防禦機制的效能並探索模型的弱點。這些方法可以找出並利用模型中的弱點，促進更強健架構的發展。然而，當前可傳遞攻擊的方法通常伴隨著龐大的運算成本，限制了它們的部署和應用，特別是在邊緣運算情境中。對抗式生成模型，例如生成對抗網路 (GAN)，其特點是可以產生樣本，而無需在初始訓練階段後重新訓練。GE-AdvGAN 是一種針對可傳遞對抗攻擊的近期方法，其基於此原理。在本文中，我們提出了一個針對基於梯度編輯的可傳遞攻擊的新穎通用架構，稱為 GE-AdvGAN+，它整合了幾乎所有主流攻擊方法，以增強可傳遞性，同時大幅減少運算資源消耗。我們的實驗證明了我們架構的相容性和有效性。與基準 AdvGAN 相比，我們效能最佳的方法 GE-AdvGAN++ 達到了平均 ASR 提升 47.8。此外，它超越了最新的競爭演算法 GE-AdvGAN，平均 ASR 提升了 5.9。該架構還展現了增強的運算效率，達到了 2217.7 FPS，優於傳統方法，例如 BIM 和 MI-FGSM。我們 GE-AdvGAN+ 架構的實作程式碼可於 https://github.com/GEAdvGANP 取得

##### **Leveraging Information Consistency in Frequency and Spatial Domain for Adversarial Attacks**
2408.12670v1 by Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Xinyi Wang, Yiyun Huang, Huaming Chen

Adversarial examples are a key method to exploit deep neural networks. Using
gradient information, such examples can be generated in an efficient way
without altering the victim model. Recent frequency domain transformation has
further enhanced the transferability of such adversarial examples, such as
spectrum simulation attack. In this work, we investigate the effectiveness of
frequency domain-based attacks, aligning with similar findings in the spatial
domain. Furthermore, such consistency between the frequency and spatial domains
provides insights into how gradient-based adversarial attacks induce
perturbations across different domains, which is yet to be explored. Hence, we
propose a simple, effective, and scalable gradient-based adversarial attack
algorithm leveraging the information consistency in both frequency and spatial
domains. We evaluate the algorithm for its effectiveness against different
models. Extensive experiments demonstrate that our algorithm achieves
state-of-the-art results compared to other gradient-based algorithms. Our code
is available at: https://github.com/LMBTough/FSA.

摘要：對抗範例是利用深度神經網路的一種主要方法。使用梯度資訊，可以在不改變受害者模型的情況下以有效率的方式產生此類範例。最近的頻率域轉換進一步增強了此類對抗範例的可傳遞性，例如頻譜模擬攻擊。在本文中，我們研究了基於頻率域的攻擊的有效性，與空間域中的類似發現一致。此外，頻率域和空間域之間的這種一致性提供了深入了解基於梯度的對抗攻擊如何在不同域中誘導擾動的見解，這還有待探索。因此，我們提出了一種簡單、有效且可擴充的基於梯度的對抗攻擊演算法，利用頻率域和空間域中的資訊一致性。我們評估了該演算法對不同模型的有效性。大量的實驗表明，與其他基於梯度的演算法相比，我們的演算法達到了最先進的結果。我們的程式碼可在 https://github.com/LMBTough/FSA 處取得。

##### **Benchmarking Counterfactual Interpretability in Deep Learning Models for Time Series Classification**
2408.12666v1 by Ziwen Kan, Shahbaz Rezaei, Xin liu

The popularity of deep learning methods in the time series domain boosts
interest in interpretability studies, including counterfactual (CF) methods. CF
methods identify minimal changes in instances to alter the model predictions.
Despite extensive research, no existing work benchmarks CF methods in the time
series domain. Additionally, the results reported in the literature are
inconclusive due to the limited number of datasets and inadequate metrics. In
this work, we redesign quantitative metrics to accurately capture desirable
characteristics in CFs. We specifically redesign the metrics for sparsity and
plausibility and introduce a new metric for consistency. Combined with
validity, generation time, and proximity, we form a comprehensive metric set.
We systematically benchmark 6 different CF methods on 20 univariate datasets
and 10 multivariate datasets with 3 different classifiers. Results indicate
that the performance of CF methods varies across metrics and among different
models. Finally, we provide case studies and a guideline for practical usage.

摘要：深度學習方法在時間序列領域的流行提升了對可解釋性研究的興趣，包括反事實 (CF) 方法。CF 方法會找出實例中的最小變更，以改變模型預測。儘管研究廣泛，但目前沒有任何現有工作對時間序列領域中的 CF 方法進行基準測試。此外，由於資料集數量有限和指標不足，文獻中報告的結果並無定論。在這項工作中，我們重新設計了量化指標，以準確掌握 CF 中理想的特徵。我們特別針對稀疏性和合理性重新設計了指標，並引入了新的指標以確保一致性。結合有效性、生成時間和接近性，我們形成了一套全面的指標。我們在 20 個單變量資料集和 10 個多變量資料集上，使用 3 個不同的分類器系統性地對 6 種不同的 CF 方法進行基準測試。結果表明，CF 方法的效能會因指標和不同模型而異。最後，我們提供了個案研究和實用使用指南。

##### **Hierarchical Generative Modeling of Melodic Vocal Contours in Hindustani Classical Music**
2408.12658v1 by Nithya Shikarpur, Krishna Maneesha Dendukur, Yusong Wu, Antoine Caillon, Cheng-Zhi Anna Huang

Hindustani music is a performance-driven oral tradition that exhibits the
rendition of rich melodic patterns. In this paper, we focus on generative
modeling of singers' vocal melodies extracted from audio recordings, as the
voice is musically prominent within the tradition. Prior generative work in
Hindustani music models melodies as coarse discrete symbols which fails to
capture the rich expressive melodic intricacies of singing. Thus, we propose to
use a finely quantized pitch contour, as an intermediate representation for
hierarchical audio modeling. We propose GaMaDHaNi, a modular two-level
hierarchy, consisting of a generative model on pitch contours, and a pitch
contour to audio synthesis model. We compare our approach to non-hierarchical
audio models and hierarchical models that use a self-supervised intermediate
representation, through a listening test and qualitative analysis. We also
evaluate audio model's ability to faithfully represent the pitch contour input
using Pearson correlation coefficient. By using pitch contours as an
intermediate representation, we show that our model may be better equipped to
listen and respond to musicians in a human-AI collaborative setting by
highlighting two potential interaction use cases (1) primed generation, and (2)
coarse pitch conditioning.

摘要：印度斯坦音樂是一種以表演為主的口傳傳統，展現出豐富的旋律模式的演繹。在本文中，我們專注於從音訊錄製中提取的歌手聲樂旋律的生成模型，因為聲音在傳統中具有突出的音樂地位。先前的印度斯坦音樂生成工作將旋律建模為粗略的離散符號，無法捕捉到演唱中豐富而富有表現力的旋律複雜性。因此，我們建議使用精細量化的音高輪廓作為分層音訊建模的中間表示。我們提出了 GaMaDHaNi，這是一個模組化的二級分層結構，包括音高輪廓上的生成模型和音高輪廓到音訊合成模型。我們透過聆聽測試和定性分析，將我們的方法與使用自我監督中間表示的非分層音訊模型和分層模型進行比較。我們還使用皮爾森相關係數評估音訊模型忠實呈現音高輪廓輸入的能力。透過使用音高輪廓作為中間表示，我們表明我們的模型可能更適合在人類與 AI 合作的環境中聆聽和回應音樂家，方法是強調兩個潛在的互動使用案例：(1) 引導生成和 (2) 粗略音高條件化。

##### **Controllable Text Generation for Large Language Models: A Survey**
2408.12599v1 by Xun Liang, Hanyu Wang, Yezhaohui Wang, Shichao Song, Jiawei Yang, Simin Niu, Jie Hu, Dan Liu, Shunyu Yao, Feiyu Xiong, Zhiyu Li

In Natural Language Processing (NLP), Large Language Models (LLMs) have
demonstrated high text generation quality. However, in real-world applications,
LLMs must meet increasingly complex requirements. Beyond avoiding misleading or
inappropriate content, LLMs are also expected to cater to specific user needs,
such as imitating particular writing styles or generating text with poetic
richness. These varied demands have driven the development of Controllable Text
Generation (CTG) techniques, which ensure that outputs adhere to predefined
control conditions--such as safety, sentiment, thematic consistency, and
linguistic style--while maintaining high standards of helpfulness, fluency, and
diversity.
  This paper systematically reviews the latest advancements in CTG for LLMs,
offering a comprehensive definition of its core concepts and clarifying the
requirements for control conditions and text quality. We categorize CTG tasks
into two primary types: content control and attribute control. The key methods
are discussed, including model retraining, fine-tuning, reinforcement learning,
prompt engineering, latent space manipulation, and decoding-time intervention.
We analyze each method's characteristics, advantages, and limitations,
providing nuanced insights for achieving generation control. Additionally, we
review CTG evaluation methods, summarize its applications across domains, and
address key challenges in current research, including reduced fluency and
practicality. We also propose several appeals, such as placing greater emphasis
on real-world applications in future research. This paper aims to offer
valuable guidance to researchers and developers in the field. Our reference
list and Chinese version are open-sourced at
https://github.com/IAAR-Shanghai/CTGSurvey.

摘要：<paragraph>在自然語言處理 (NLP) 中，大型語言模型 (LLM) 已展現出高品質的文字生成能力。然而，在現實世界的應用中，LLM 必須滿足日益複雜的要求。除了避免產生誤導或不適當的內容外，LLM 還預期能迎合特定的使用者需求，例如模仿特定的寫作風格或生成具有詩意豐富性的文字。這些不同的需求推動了可控文字生成 (CTG) 技術的發展，可確保輸出符合預先定義的控制條件（例如安全性、情緒、主題一致性和語言風格），同時維持高標準的實用性、流暢性和多樣性。
本文系統性地回顧了 LLM 中 CTG 的最新進展，提供了其核心概念的全面定義，並釐清了控制條件和文字品質的要求。我們將 CTG 任務分類為兩種主要類型：內容控制和屬性控制。討論了關鍵方法，包括模型再訓練、微調、強化學習、提示工程、潛在空間操作和解碼時介入。我們分析了每種方法的特徵、優點和限制，提供了實現生成控制的細微見解。此外，我們回顧了 CTG 評估方法，總結了其在各個領域的應用，並解決了當前研究中的關鍵挑戰，包括流暢性和實用性的降低。我們還提出了幾項呼籲，例如在未來的研究中更重視現實世界的應用。本文旨在為該領域的研究人員和開發人員提供有價值的指導。我們的參考文獻和中文版本在 https://github.com/IAAR-Shanghai/CTGSurvey 開源。</paragraph>

##### **ND-SDF: Learning Normal Deflection Fields for High-Fidelity Indoor Reconstruction**
2408.12598v1 by Ziyu Tang, Weicai Ye, Yifan Wang, Di Huang, Hujun Bao, Tong He, Guofeng Zhang

Neural implicit reconstruction via volume rendering has demonstrated its
effectiveness in recovering dense 3D surfaces. However, it is non-trivial to
simultaneously recover meticulous geometry and preserve smoothness across
regions with differing characteristics. To address this issue, previous methods
typically employ geometric priors, which are often constrained by the
performance of the prior models. In this paper, we propose ND-SDF, which learns
a Normal Ddeflection field to represent the angular deviation between the scene
normal and the prior normal. Unlike previous methods that uniformly apply
geometric priors on all samples, introducing significant bias in accuracy, our
proposed normal deflection field dynamically learns and adapts the utilization
of samples based on their specific characteristics, thereby improving both the
accuracy and effectiveness of the model. Our method not only obtains smooth
weakly textured regions such as walls and floors but also preserves the
geometric details of complex structures. In addition, we introduce a novel ray
sampling strategy based on the deflection angle to facilitate the unbiased
rendering process, which significantly improves the quality and accuracy of
intricate surfaces, especially on thin structures. Consistent improvements on
various challenging datasets demonstrate the superiority of our method.

摘要：神經隱式重建經由體積渲染已證實其在恢復密集 3D 表面上的效能。然而，要同時恢復細緻的幾何結構並在具有不同特徵的區域中保持平滑度並非易事。為了解決此問題，先前的做法通常採用幾何先驗，這些先驗通常受到先驗模型效能的限制。在本文中，我們提出了 ND-SDF，它學習一個法向量偏移場，以表示場景法向量與先驗法向量之間的角度偏差。與先前在所有範例中均一地套用幾何先驗的方法不同，我們的法向量偏移場會根據範例的特定特徵動態地學習並調整範例的使用，從而提升模型的準確度和效能。我們的做法不僅能獲得平滑的弱紋理區域（例如牆壁和地板），還能保留複雜結構的幾何細節。此外，我們引進了一種基於偏移角的新型光線取樣策略，以利於無偏渲染程序，這顯著提升了複雜表面的品質和準確度，特別是在薄結構上。在各種具有挑戰性的資料集上的一致改進證明了我們方法的優越性。

##### **xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations**
2408.12590v1 by Can Qin, Congying Xia, Krithika Ramakrishnan, Michael Ryoo, Lifu Tu, Yihao Feng, Manli Shu, Honglu Zhou, Anas Awadalla, Jun Wang, Senthil Purushwalkam, Le Xue, Yingbo Zhou, Huan Wang, Silvio Savarese, Juan Carlos Niebles, Zeyuan Chen, Ran Xu, Caiming Xiong

We present xGen-VideoSyn-1, a text-to-video (T2V) generation model capable of
producing realistic scenes from textual descriptions. Building on recent
advancements, such as OpenAI's Sora, we explore the latent diffusion model
(LDM) architecture and introduce a video variational autoencoder (VidVAE).
VidVAE compresses video data both spatially and temporally, significantly
reducing the length of visual tokens and the computational demands associated
with generating long-sequence videos. To further address the computational
costs, we propose a divide-and-merge strategy that maintains temporal
consistency across video segments. Our Diffusion Transformer (DiT) model
incorporates spatial and temporal self-attention layers, enabling robust
generalization across different timeframes and aspect ratios. We have devised a
data processing pipeline from the very beginning and collected over 13M
high-quality video-text pairs. The pipeline includes multiple steps such as
clipping, text detection, motion estimation, aesthetics scoring, and dense
captioning based on our in-house video-LLM model. Training the VidVAE and DiT
models required approximately 40 and 642 H100 days, respectively. Our model
supports over 14-second 720p video generation in an end-to-end way and
demonstrates competitive performance against state-of-the-art T2V models.

摘要：我們提出 xGen-VideoSyn-1，一個文字轉影片 (T2V) 生成模型，能夠根據文字描述產生逼真的場景。在 OpenAI 的 Sora 等近期進展的基礎上，我們探討了潛在擴散模型 (LDM) 架構，並引入了影片變異自編碼器 (VidVAE)。VidVAE 在空間和時間上壓縮影片資料，大幅減少視覺標記的長度，以及產生長序列影片相關的運算需求。為了進一步解決運算成本，我們提出一個分而併之策略，以維持影片片段之間的時間一致性。我們的擴散轉換器 (DiT) 模型整合了空間和時間自我注意層，讓不同時間範圍和長寬比都能穩健地概括。我們從一開始就設計了一個資料處理流程，並收集了超過 1300 萬個高品質影片文字配對。流程包含多個步驟，例如剪輯、文字偵測、動作估計、美學評分，以及基於我們內部影片 LLM 模型的密集式字幕。訓練 VidVAE 和 DiT 模型分別需要大約 40 和 642 個 H100 天。我們的模型支援以端對端的方式產生超過 14 秒的 720p 影片，並展現出與現有 T2V 模型相比具有競爭力的效能。

##### **AI-driven Transformer Model for Fault Prediction in Non-Linear Dynamic Automotive System**
2408.12638v1 by Priyanka Kumar

Fault detection in automotive engine systems is one of the most promising
research areas. Several works have been done in the field of model-based fault
diagnosis. Many researchers have discovered more advanced statistical methods
and algorithms for better fault detection on any automotive dynamic engine
system. The gas turbines/diesel engines produce highly complex and huge data
which are highly non-linear. So, researchers should come up with an automated
system that is more resilient and robust enough to handle this huge, complex
data in highly non-linear dynamic automotive systems. Here, I present an
AI-based fault classification and prediction model in the diesel engine that
can be applied to any highly non-linear dynamic automotive system. The main
contribution of this paper is the AI-based Transformer fault classification and
prediction model in the diesel engine concerning the worldwide harmonic light
vehicle test procedure (WLTP) driving cycle. This model used 27 input
dimensions, 64 hidden dimensions with 2 layers, and 9 heads to create a
classifier with 12 output heads (one for fault-free data and 11 different fault
types). This model was trained on the UTSA Arc High-Performance Compute (HPC)
cluster with 5 NVIDIA V100 GPUs, 40-core CPUs, and 384GB RAM and achieved 70.01
% accuracy on a held test set.

摘要：汽車引擎系統中的故障偵測是最有前景的研究領域之一。在基於模型的故障診斷領域中已經進行了多項研究。許多研究人員已經發現更先進的統計方法和演算法，以便在任何汽車動態引擎系統中進行更好的故障偵測。燃氣渦輪機/柴油引擎會產生高度複雜且龐大的資料，這些資料高度非線性。因此，研究人員應該提出一個自動化系統，這個系統更具韌性和穩健性，足以處理高度非線性動態汽車系統中的這些龐大且複雜的資料。在此，我提出一個柴油引擎中基於 AI 的故障分類和預測模型，這個模型可以應用於任何高度非線性動態汽車系統。本文的主要貢獻是柴油引擎中基於 AI 的 Transformer 故障分類和預測模型，涉及全球輕型車輛和諧測試程序 (WLTP) 駕駛週期。此模型使用 27 個輸入維度、64 個隱藏維度和 2 層，以及 9 個頭部來建立一個具有 12 個輸出頭部的分類器（一個用於無故障資料和 11 種不同的故障類型）。此模型在 UTSA Arc 高效能運算 (HPC) 集群上進行訓練，該集群具有 5 個 NVIDIA V100 GPU、40 個核心 CPU 和 384GB RAM，並且在保留的測試集中達到 70.01% 的準確度。

##### **Building and better understanding vision-language models: insights and future directions**
2408.12637v1 by Hugo Laurençon, Andrés Marafioti, Victor Sanh, Léo Tronchon

The field of vision-language models (VLMs), which take images and texts as
inputs and output texts, is rapidly evolving and has yet to reach consensus on
several key aspects of the development pipeline, including data, architecture,
and training methods. This paper can be seen as a tutorial for building a VLM.
We begin by providing a comprehensive overview of the current state-of-the-art
approaches, highlighting the strengths and weaknesses of each, addressing the
major challenges in the field, and suggesting promising research directions for
underexplored areas. We then walk through the practical steps to build
Idefics3-8B, a powerful VLM that significantly outperforms its predecessor
Idefics2-8B, while being trained efficiently, exclusively on open datasets, and
using a straightforward pipeline. These steps include the creation of Docmatix,
a dataset for improving document understanding capabilities, which is 240 times
larger than previously available datasets. We release the model along with the
datasets created for its training.

摘要：視覺語言模型 (VLM) 領域正在快速演進，它以影像和文字作為輸入，並輸出文字，但對於開發流程中的幾個關鍵面向，包括資料、架構和訓練方法，尚未達成共識。本文可視為建構 VLM 的教學指南。我們從提供現今最先進方法的全面概觀開始，強調各方法的優缺點，探討該領域的主要挑戰，並建議對探索不足領域進行有前景的研究方向。接著我們將逐步說明建構 Idefics3-8B 的實際步驟，這是一個強大的 VLM，其效能顯著優於前代 Idefics2-8B，同時以高效的方式進行訓練，僅使用開放式資料集，並採用簡潔的流程。這些步驟包括建立 Docmatix，這是一個用於提升文件理解能力的資料集，其規模是先前可用資料集的 240 倍。我們將釋出模型以及用於訓練模型的資料集。

##### **RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment**
2408.12579v1 by Xiaohan Wang, Xiaoyan Yang, Yuqi Zhu, Yue Shen, Jian Wang, Peng Wei, Lei Liang, Jinjie Gu, Huajun Chen, Ningyu Zhang

Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieve
performance competitively with human experts across various medical benchmarks.
However, they still face challenges in making professional diagnoses akin to
physicians, particularly in efficiently gathering patient information and
reasoning the final diagnosis. To this end, we introduce the RuleAlign
framework, designed to align LLMs with specific diagnostic rules. We develop a
medical dialogue dataset comprising rule-based communications between patients
and physicians and design an alignment learning approach through preference
learning. Experimental results demonstrate the effectiveness of the proposed
approach. We hope that our work can serve as an inspiration for exploring the
potential of LLMs as AI physicians.

摘要：大型語言模型（LLM），例如 GPT-4、MedPaLM-2 和 Med-Gemini，在各種醫療基準上達到了與人類專家競爭的表現。
然而，他們在做出類似於醫師的專業診斷方面仍面臨挑戰，特別是在有效收集患者資訊和推論最終診斷方面。為此，我們引入了 RuleAlign 框架，旨在將 LLM 與特定診斷規則保持一致。我們開發了一個醫療對話資料集，其中包含患者與醫師之間基於規則的溝通，並透過偏好學習設計了一種比對學習方法。實驗結果證明了所提方法的有效性。我們希望我們的工作能激勵探索 LLM 作為 AI 醫師的潛力。

##### **A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language**
2408.12578v1 by Ekdeep Singh Lubana, Kyogo Kawaguchi, Robert P. Dick, Hidenori Tanaka

Increase in data, size, or compute can lead to sudden learning of specific
capabilities by a neural network -- a phenomenon often called "emergence".
Beyond scientific understanding, establishing the causal factors underlying
such emergent capabilities is crucial to enable risk regulation frameworks for
AI. In this work, we seek inspiration from study of emergent properties in
other fields and propose a phenomenological definition for the concept in the
context of neural networks. Our definition implicates the acquisition of
specific structures underlying the data-generating process as a cause of sudden
performance growth for specific, narrower tasks. We empirically investigate
this definition by proposing an experimental system grounded in a
context-sensitive formal language and find that Transformers trained to perform
tasks on top of strings from this language indeed exhibit emergent
capabilities. Specifically, we show that once the language's underlying grammar
and context-sensitivity inducing structures are learned by the model,
performance on narrower tasks suddenly begins to improve. We then analogize our
network's learning dynamics with the process of percolation on a bipartite
graph, establishing a formal phase transition model that predicts the shift in
the point of emergence observed in experiment when changing the data structure.
Overall, our experimental and theoretical frameworks yield a step towards
better defining, characterizing, and predicting emergence in neural networks.

摘要：隨著資料、規模或運算增加，神經網路可能會突然學會特定功能，這種現象常稱為「湧現」。除了科學理解之外，建立造成這種湧現功能的因果關係，對於建立人工智慧的風險規範架構至關重要。在這項工作中，我們從其他領域對湧現特性的研究中尋求靈感，並提出在神經網路脈絡中對這個概念的現象學定義。我們的定義暗示，取得資料產生流程中特定的基礎結構，是特定、較狹窄任務突然效能提升的原因。我們透過提出一個以情境敏感形式語言為基礎的實驗系統，對這個定義進行實證調查，並發現訓練來執行這個語言中字串頂端任務的 Transformer，確實展現出湧現功能。具體來說，我們顯示出，一旦模型學會語言的基礎文法和引發情境敏感性的結構，執行較狹窄任務的效能就會突然開始提升。然後，我們將網路的學習動態類比為二分圖上的滲流過程，建立一個正式的相變模型，預測在改變資料結構時，實驗中觀察到的湧現點轉變。總體而言，我們的實驗和理論架構朝著在神經網路中更佳定義、描述和預測湧現邁進一步。

##### **Enhanced Parking Perception by Multi-Task Fisheye Cross-view Transformers**
2408.12575v1 by Antonyo Musabini, Ivan Novikov, Sana Soula, Christel Leonet, Lihao Wang, Rachid Benmokhtar, Fabian Burger, Thomas Boulay, Xavier Perrotton

Current parking area perception algorithms primarily focus on detecting
vacant slots within a limited range, relying on error-prone homographic
projection for both labeling and inference. However, recent advancements in
Advanced Driver Assistance System (ADAS) require interaction with end-users
through comprehensive and intelligent Human-Machine Interfaces (HMIs). These
interfaces should present a complete perception of the parking area going from
distinguishing vacant slots' entry lines to the orientation of other parked
vehicles. This paper introduces Multi-Task Fisheye Cross View Transformers (MT
F-CVT), which leverages features from a four-camera fisheye Surround-view
Camera System (SVCS) with multihead attentions to create a detailed Bird-Eye
View (BEV) grid feature map. Features are processed by both a segmentation
decoder and a Polygon-Yolo based object detection decoder for parking slots and
vehicles. Trained on data labeled using LiDAR, MT F-CVT positions objects
within a 25m x 25m real open-road scenes with an average error of only 20 cm.
Our larger model achieves an F-1 score of 0.89. Moreover the smaller model
operates at 16 fps on an Nvidia Jetson Orin embedded board, with similar
detection results to the larger one. MT F-CVT demonstrates robust
generalization capability across different vehicles and camera rig
configurations. A demo video from an unseen vehicle and camera rig is available
at: https://streamable.com/jjw54x.

摘要：目前停車場感知演算法主要專注於偵測有限範圍內的空位，依賴容易出錯的同形投影進行標記和推論。然而，進階駕駛輔助系統 (ADAS) 的最新進展需要透過全面且智慧的人機介面 (HMI) 與使用者互動。這些介面應該呈現停車場的完整感知，從辨別空位的入口線到其他停車車輛的方向。本文介紹多任務魚眼交叉視角Transformer (MT F-CVT)，它利用來自四鏡頭魚眼環景攝影系統 (SVCS) 的特徵和多頭注意力來建立詳細的鳥瞰視角 (BEV) 格線特徵圖。特徵由分割解碼器和基於 Polygon-Yolo 的物件偵測解碼器處理，用於停車位和車輛。在使用 LiDAR 標記的資料上進行訓練，MT F-CVT 將物件定位在 25 公尺 x 25 公尺的真實露天場景中，平均誤差僅 20 公分。我們的較大模型達到 F-1 分數 0.89。此外，較小的模型在 Nvidia Jetson Orin 嵌入式電路板上以 16 fps 運作，偵測結果與較大的模型類似。MT F-CVT 展示了在不同車輛和相機裝置組態中強大的泛化能力。來自未見車輛和相機裝置組態的示範影片可於此處取得：https://streamable.com/jjw54x。

##### **MuMA-ToM: Multi-modal Multi-Agent Theory of Mind**
2408.12574v2 by Haojun Shi, Suyu Ye, Xinyu Fang, Chuanyang Jin, Leyla Isik, Yen-Ling Kuo, Tianmin Shu

Understanding people's social interactions in complex real-world scenarios
often relies on intricate mental reasoning. To truly understand how and why
people interact with one another, we must infer the underlying mental states
that give rise to the social interactions, i.e., Theory of Mind reasoning in
multi-agent interactions. Additionally, social interactions are often
multi-modal -- we can watch people's actions, hear their conversations, and/or
read about their past behaviors. For AI systems to successfully and safely
interact with people in real-world environments, they also need to understand
people's mental states as well as their inferences about each other's mental
states based on multi-modal information about their interactions. For this, we
introduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark.
MuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluates
mental reasoning in embodied multi-agent interactions. In MuMA-ToM, we provide
video and text descriptions of people's multi-modal behavior in realistic
household environments. Based on the context, we then ask questions about
people's goals, beliefs, and beliefs about others' goals. We validated MuMA-ToM
in a human experiment and provided a human baseline. We also proposed a novel
multi-modal, multi-agent ToM model, LIMP (Language model-based Inverse
Multi-agent Planning). Our experimental results show that LIMP significantly
outperforms state-of-the-art methods, including large multi-modal models (e.g.,
GPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.

摘要：<paragraph>理解人們在複雜的現實世界情境中的社交互動，通常仰賴複雜的心理推理。為了真正理解人們如何以及為何彼此互動，我們必須推論出導致社交互動的基本心理狀態，也就是多重代理互動中的心智理論推理。此外，社交互動通常是多模態的——我們可以觀察人們的行為、聆聽他們的對話，和/或閱讀關於他們過去行為的資料。為了讓 AI 系統能夠成功且安全地與現實世界環境中的人們互動，他們也需要理解人們的心理狀態，以及他們根據關於互動的多模態資訊對彼此心理狀態的推論。為此，我們引入了 MuMA-ToM，一個多模態多重代理心智理論基準。MuMA-ToM 是第一個多模態心智理論基準，用於評估具體化多重代理互動中的心理推理。在 MuMA-ToM 中，我們提供了在逼真的家庭環境中人們的多模態行為的影片和文字說明。然後，根據脈絡，我們詢問有關人們的目標、信念以及對他人目標的信念的問題。我們在人類實驗中驗證了 MuMA-ToM，並提供了人類基準。我們還提出了新穎的多模態多重代理 ToM 模型，LIMP（基於語言模型的反向多重代理規劃）。我們的實驗結果顯示，LIMP 明顯優於最先進的方法，包括大型多模態模型（例如 GPT-4o、Gemini-1.5 Pro）和最近的多模態 ToM 模型 BIP-ALM。</paragraph>

