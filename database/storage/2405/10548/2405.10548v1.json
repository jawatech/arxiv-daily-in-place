{"2405.10548": {"publish_time": "2024-05-17", "title": "Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks", "paper_summary": "Large Language Models (LLMs) have transformed NLP with their remarkable\nIn-context Learning (ICL) capabilities. Automated assistants based on LLMs are\ngaining popularity; however, adapting them to novel tasks is still challenging.\nWhile colossal models excel in zero-shot performance, their computational\ndemands limit widespread use, and smaller language models struggle without\ncontext. This paper investigates whether LLMs can generalize from labeled\nexamples of predefined tasks to novel tasks. Drawing inspiration from\nbiological neurons and the mechanistic interpretation of the Transformer\narchitecture, we explore the potential for information sharing across tasks. We\ndesign a cross-task prompting setup with three LLMs and show that LLMs achieve\nsignificant performance improvements despite no examples from the target task\nin the context. Cross-task prompting leads to a remarkable performance boost of\n107% for LLaMA-2 7B, 18.6% for LLaMA-2 13B, and 3.2% for GPT 3.5 on average\nover zero-shot prompting, and performs comparable to standard in-context\nlearning. The effectiveness of generating pseudo-labels for in-task examples is\ndemonstrated, and our analyses reveal a strong correlation between the effect\nof cross-task examples and model activation similarities in source and target\ninput tokens. This paper offers a first-of-its-kind exploration of LLMs'\nability to solve novel tasks based on contextual signals from different task\nexamples.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4ee5\u5176\u5353\u8d8a\u7684\u8a9e\u5883\u5b78\u7fd2 (ICL) \u80fd\u529b\u8f49\u8b8a\u4e86\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u3002\u57fa\u65bc LLM \u7684\u81ea\u52d5\u5316\u52a9\u7406\u6b63\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u6d41\u884c\uff1b\u7136\u800c\uff0c\u5c07\u5b83\u5011\u9069\u61c9\u5230\u65b0\u4efb\u52d9\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u5118\u7ba1\u5927\u578b\u6a21\u578b\u5728\u96f6\u6b21\u5b78\u7fd2\u8868\u73fe\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u5b83\u5011\u7684\u8a08\u7b97\u9700\u6c42\u9650\u5236\u4e86\u5ee3\u6cdb\u4f7f\u7528\uff0c\u800c\u8f03\u5c0f\u7684\u8a9e\u8a00\u6a21\u578b\u5728\u6c92\u6709\u8a9e\u5883\u7684\u60c5\u6cc1\u4e0b\u6703\u9047\u5230\u56f0\u96e3\u3002\u672c\u6587\u63a2\u8a0e\u4e86 LLM \u662f\u5426\u53ef\u4ee5\u5f9e\u9810\u5b9a\u7fa9\u4efb\u52d9\u7684\u6a19\u8a18\u7bc4\u4f8b\u63a8\u5ee3\u5230\u65b0\u4efb\u52d9\u3002\u5f9e\u751f\u7269\u795e\u7d93\u5143\u548c Transformer \u67b6\u69cb\u7684\u6a5f\u68b0\u89e3\u91cb\u4e2d\u6c72\u53d6\u9748\u611f\uff0c\u6211\u5011\u63a2\u7d22\u4e86\u8de8\u4efb\u52d9\u8cc7\u8a0a\u5171\u4eab\u7684\u53ef\u80fd\u6027\u3002\u6211\u5011\u4f7f\u7528\u4e09\u500b LLM \u8a2d\u8a08\u4e86\u4e00\u500b\u8de8\u4efb\u52d9\u63d0\u793a\u8a2d\u5b9a\uff0c\u4e26\u8868\u660e\u5118\u7ba1\u8a9e\u5883\u4e2d\u6c92\u6709\u76ee\u6a19\u4efb\u52d9\u7684\u7bc4\u4f8b\uff0c\u4f46 LLM \u4ecd\u53ef\u5be6\u73fe\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\u3002\u8de8\u4efb\u52d9\u63d0\u793a\u6703\u986f\u8457\u63d0\u5347\u6548\u80fd\uff0c\u5e73\u5747\u800c\u8a00\uff0cLLaMA-2 7B \u63d0\u5347\u4e86 107%\uff0cLLaMA-2 13B \u63d0\u5347\u4e86 18.6%\uff0cGPT 3.5 \u63d0\u5347\u4e86 3.2%\uff0c\u512a\u65bc\u96f6\u6b21\u63d0\u793a\uff0c\u4e26\u8207\u6a19\u6e96\u8a9e\u5883\u5b78\u7fd2\u8868\u73fe\u76f8\u7576\u3002\u8b49\u660e\u4e86\u70ba\u4efb\u52d9\u5167\u7bc4\u4f8b\u7522\u751f\u507d\u6a19\u7c64\u7684\u6709\u6548\u6027\uff0c\u6211\u5011\u7684\u5206\u6790\u63ed\u793a\u4e86\u8de8\u4efb\u52d9\u7bc4\u4f8b\u7684\u6548\u679c\u8207\u4f86\u6e90\u548c\u76ee\u6a19\u8f38\u5165\u6a19\u8a18\u4e2d\u6a21\u578b\u6fc0\u6d3b\u76f8\u4f3c\u6027\u4e4b\u9593\u7684\u5f37\u76f8\u95dc\u6027\u3002\u672c\u6587\u9996\u6b21\u63a2\u8a0e\u4e86 LLM \u57fa\u65bc\u4e0d\u540c\u4efb\u52d9\u7bc4\u4f8b\u7684\u8a9e\u5883\u4fe1\u865f\u89e3\u6c7a\u65b0\u4efb\u52d9\u7684\u80fd\u529b\u3002", "author": "Anwoy Chatterjee et.al.", "authors": "Anwoy Chatterjee, Eshaan Tanwar, Subhabrata Dutta, Tanmoy Chakraborty", "id": "2405.10548v1", "paper_url": "http://arxiv.org/abs/2405.10548v1", "repo": "null"}}