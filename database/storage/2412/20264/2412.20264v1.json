{"2412.20264": {"publish_time": "2024-12-28", "title": "Scoring with Large Language Models: A Study on Measuring Empathy of Responses in Dialogues", "paper_summary": "In recent years, Large Language Models (LLMs) have become increasingly more\npowerful in their ability to complete complex tasks. One such task in which\nLLMs are often employed is scoring, i.e., assigning a numerical value from a\ncertain scale to a subject. In this paper, we strive to understand how LLMs\nscore, specifically in the context of empathy scoring. We develop a novel and\ncomprehensive framework for investigating how effective LLMs are at measuring\nand scoring empathy of responses in dialogues, and what methods can be employed\nto deepen our understanding of LLM scoring. Our strategy is to approximate the\nperformance of state-of-the-art and fine-tuned LLMs with explicit and\nexplainable features. We train classifiers using various features of dialogues\nincluding embeddings, the Motivational Interviewing Treatment Integrity (MITI)\nCode, a set of explicit subfactors of empathy as proposed by LLMs, and a\ncombination of the MITI Code and the explicit subfactors. Our results show that\nwhen only using embeddings, it is possible to achieve performance close to that\nof generic LLMs, and when utilizing the MITI Code and explicit subfactors\nscored by an LLM, the trained classifiers can closely match the performance of\nfine-tuned LLMs. We employ feature selection methods to derive the most crucial\nfeatures in the process of empathy scoring. Our work provides a new perspective\ntoward understanding LLM empathy scoring and helps the LLM community explore\nthe potential of LLM scoring in social science studies.", "paper_summary_zh": "\u8fd1\u5e74\u4f86\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5b8c\u6210\u8907\u96dc\u4efb\u52d9\u7684\u80fd\u529b\u4e0a\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u5f37\u5927\u3002\u5176\u4e2d\u4e00\u9805 LLM \u5e38\u88ab\u7528\u65bc\u57f7\u884c\u7684\u5de5\u4f5c\u4fbf\u662f\u8a55\u5206\uff0c\u4e5f\u5c31\u662f\u5c07\u67d0\u500b\u6a19\u7684\u5f9e\u7279\u5b9a\u7bc4\u570d\u4e2d\u8ce6\u4e88\u4e00\u500b\u6578\u503c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u81f4\u529b\u65bc\u4e86\u89e3 LLM \u5982\u4f55\u8a55\u5206\uff0c\u7279\u5225\u662f\u5728\u540c\u7406\u5fc3\u8a55\u5206\u7684\u60c5\u5883\u4e2d\u3002\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u65b0\u7a4e\u4e14\u5168\u9762\u7684\u67b6\u69cb\uff0c\u7528\u65bc\u63a2\u8a0e LLM \u5728\u5c0d\u8a71\u4e2d\u8861\u91cf\u548c\u8a55\u5206\u540c\u7406\u5fc3\u7684\u53cd\u61c9\u6709\u591a\u6709\u6548\uff0c\u4ee5\u53ca\u53ef\u4ee5\u63a1\u7528\u54ea\u4e9b\u65b9\u6cd5\u4f86\u52a0\u6df1\u6211\u5011\u5c0d LLM \u8a55\u5206\u7684\u7406\u89e3\u3002\u6211\u5011\u7684\u7b56\u7565\u662f\u5229\u7528\u660e\u78ba\u4e14\u53ef\u89e3\u91cb\u7684\u529f\u80fd\u4f86\u8fd1\u4f3c\u6700\u5148\u9032\u4e14\u7d93\u904e\u5fae\u8abf\u7684 LLM \u7684\u6548\u80fd\u3002\u6211\u5011\u4f7f\u7528\u5c0d\u8a71\u7684\u5404\u7a2e\u529f\u80fd\u4f86\u8a13\u7df4\u5206\u985e\u5668\uff0c\u5305\u62ec\u5d4c\u5165\u3001\u52d5\u6a5f\u6027\u8a2a\u8ac7\u6cbb\u7642\u5b8c\u6574\u6027 (MITI) \u6e96\u5247\u3001LLM \u63d0\u51fa\u7684\u540c\u7406\u5fc3\u660e\u78ba\u5b50\u56e0\u5b50\u7d44\uff0c\u4ee5\u53ca MITI \u6e96\u5247\u548c\u660e\u78ba\u5b50\u56e0\u5b50\u7684\u7d44\u5408\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u50c5\u4f7f\u7528\u5d4c\u5165\u6642\uff0c\u5c31\u6709\u53ef\u80fd\u9054\u5230\u63a5\u8fd1\u4e00\u822c LLM \u7684\u6548\u80fd\uff0c\u800c\u7576\u4f7f\u7528 LLM \u8a55\u5206\u7684 MITI \u6e96\u5247\u548c\u660e\u78ba\u5b50\u56e0\u5b50\u6642\uff0c\u8a13\u7df4\u51fa\u7684\u5206\u985e\u5668\u53ef\u4ee5\u7dca\u5bc6\u5339\u914d\u7d93\u904e\u5fae\u8abf\u7684 LLM \u7684\u6548\u80fd\u3002\u6211\u5011\u63a1\u7528\u7279\u5fb5\u9078\u64c7\u65b9\u6cd5\u4f86\u63a8\u5c0e\u540c\u7406\u5fc3\u8a55\u5206\u904e\u7a0b\u4e2d\u6700\u91cd\u8981\u7684\u7279\u5fb5\u3002\u6211\u5011\u7684\u7814\u7a76\u70ba\u7406\u89e3 LLM \u540c\u7406\u5fc3\u8a55\u5206\u63d0\u4f9b\u4e86\u65b0\u7684\u89c0\u9ede\uff0c\u4e26\u5e6b\u52a9 LLM \u793e\u7fa4\u63a2\u7d22 LLM \u8a55\u5206\u5728\u793e\u6703\u79d1\u5b78\u7814\u7a76\u4e2d\u7684\u6f5b\u529b\u3002", "author": "Henry J. Xie et.al.", "authors": "Henry J. Xie, Jinghan Zhang, Xinhao Zhang, Kunpeng Liu", "id": "2412.20264v1", "paper_url": "http://arxiv.org/abs/2412.20264v1", "repo": "null"}}